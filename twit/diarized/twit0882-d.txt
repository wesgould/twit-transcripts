;FFMETADATA1
title=Many Mini Metaverses
artist=Leo Laporte, Christina Warren, Mike Elgan, Glenn Fleishman
album_artist=TWiT
publisher=TWiT
album=This Week in Tech
TRDA=2022-07-03
track=882
language=English
genre=Podcast
comment=Don't Buy Entry Level M2 Macbook Pro, Google To Delete Abortion Clinic Visits	
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf58.76.100
Failed to align segment (" and it walks terribly, and it starts walking."): backtrack failed, resorting to original...
Failed to align segment (" 19,200."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" 100%."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" First time he was on, he completely tricked me."): backtrack failed, resorting to original...
Failed to align segment (" I was just going to say, I don't know if I'm gonna-"): backtrack failed, resorting to original...
Failed to align segment (" 1860."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" Wear the participation of 2500, 200,000 subscribers"): backtrack failed, resorting to original...
Failed to align segment: original start time longer than audio duration, skipping...
Failed to align segment: original start time longer than audio duration, skipping...
Failed to align segment: original start time longer than audio duration, skipping...
Failed to align segment: original start time longer than audio duration, skipping...
Failed to align segment: original start time longer than audio duration, skipping...
Failed to align segment: original start time longer than audio duration, skipping...
Failed to align segment: original start time longer than audio duration, skipping...
Start time: 0.24
End time: 35.67
Speaker: SPEAKER_05
Transcript:  It's time for Twitter This Week in Tech. Love this panel.  Glenn Fleischman is visiting us from Seattle.  So is Christina Warren, film girl from Silicon Valley.  It's Mike Elgin.  We'll talk about GitHub Copilot.  Is it stealing open source software?  Or is it a great thing for programmers?  Elon Musk is back on Twitter after a nine day absence  and he's with the Pope.  Plus, why Judge Lutig spoke so slowly?  It turns out he loves Twitter.  It's all coming up next on Twitter.  Podcasts you love.

Start time: 36.26
End time: 40.22
Speaker: SPEAKER_03
Transcript:  From people you trust.  This is Twitter.

Start time: 49.34
End time: 147.67
Speaker: SPEAKER_05
Transcript:  This is Twitter This Week in Tech, episode 882,  recorded Sunday, July 3rd, 2022.  Many, many metaverses.  This Week in Tech is brought to you by Policy Genius.  If someone relies on your financial support,  whether it's a child, aging parent,  even a business partner, you need life insurance.  Head to policygenius.com slash twit  to get your free life insurance quotes  and see how much you could save.  And by Zapier.  Zapier makes it easy to connect all your apps,  automate routine tasks, and streamline your processes.  Try Zapier for free today at zapier.com slash twit.  And by Podium.  Join more than 100,000 businesses  that already use Podium  to streamline their customer interactions.  See how Podium can grow your business.  Watch a demo today at podium.com slash twit.  And by Blueland.  Blueland is on a mission to eliminate single use plastics  by reinventing home essentials that are good for you  and the planet.  Right now you can get 15% off your first order  when you go to blueland.com slash twit.  It's time for Twit This Week in Tech.  The show where we cover the week's tech news.  We've got a great panel.  You're gonna have fun today.  We're all gonna have fun.  Glenn Fleishman is joining us.  All the way from Seattle, glenn.fun,  the best website URL in the world.  Good to see you, Glenn.

Start time: 148.26
End time: 152.32
Speaker: SPEAKER_03
Transcript:  Nice to see you, glad to be here.  We're gonna get a double dose of Glenn this week

Start time: 152.40
End time: 154.26
Speaker: SPEAKER_05
Transcript:  because you're gonna be on this week in Google as well.

Start time: 154.78
End time: 158.26
Speaker: SPEAKER_03
Transcript:  That's right, I'm sure I'll have a whole different set  of things to talk about by then.

Start time: 158.62
End time: 184.67
Speaker: SPEAKER_05
Transcript:  Oh yeah, that's one of the,  actually this panel is great  because sometimes you get a panel,  they're experts in a particular field.  And that's all you hear about.  This one, this panel is so eclectic.  They're all auto-didact, they're into all sorts of things.  Well, like Christina Warren, film girl,  who's into sneakers, obsolete swag,  and happens to be a senior dev advocate at GitHub.  Hello, Christina.

Start time: 185.46
End time: 185.93
Speaker: SPEAKER_00
Transcript:  Hey, Leo.

Start time: 186.30
End time: 189.50
Speaker: SPEAKER_05
Transcript:  You've been traveling like crazy.  What's that all about?

Start time: 189.92
End time: 241.18
Speaker: SPEAKER_00
Transcript:  Yeah, yeah, travel's back, man, right?  What can I say?  I mean, not for everyone, obviously.  No.  You know, at all, like I'm not trying to imply that.  No, but I was in,  I did my first international trip in two years,  in over two years, actually.  So I was in Copenhagen for a team summit, which was great.  So I got to meet a lot of GitHubbers,  and hubbers as we call them, in real life,  which was amazing.  And then I was in Tel Aviv for like five days,  doing some community events  and speaking at a startup conference  and meeting just a lot of incredible people.  So my, I'd forgotten how to do  the whole international travel thing.  I'm not as much of a jet setter as Mike,  who we're gonna talk to in a second,  but I have experience,  and I've sort of forgotten how to do it.  So coming back from the jet lag,  hence the wet hair and the hat, I'm just like,

Start time: 241.62
End time: 245.90
Speaker: SPEAKER_05
Transcript:  That's fine.  Although I'm so sorry to hear  that Adidas is now out of business.

Start time: 246.40
End time: 247.76
Speaker: SPEAKER_00
Transcript:  I know, isn't it a shame?

Start time: 249.70
End time: 255.72
Speaker: SPEAKER_05
Transcript:  She is clothed in, oddly for her,  articles of apparel advertising, an existing company.

Start time: 255.84
End time: 272.33
Speaker: SPEAKER_00
Transcript:  An existing company.  A company that's thriving, actually.  Thriving.  So yeah.  You can't really tell too much from the coloring,  because the lighting in my office is terrible,  because I'm renovating, hence the wrong camera and stuff.  But this is a rose gold hat.  Yeah.  So that I had to be on brand.  That makes it special.  Okay. It does.

Start time: 273.08
End time: 282.76
Speaker: SPEAKER_05
Transcript:  Because you are only, only products with rose gold.  Basically.  Oh, well look at the shoes.  Wait a minute, show her a shot one more time,  because I see some rose gold shoes.  Yeah. Yeah.

Start time: 282.84
End time: 289.32
Speaker: SPEAKER_00
Transcript:  Yeah, yeah, you can see some.  I've got a lot of my sneakers up.  Like I said, I've been renovating my office,  so, but it's not quite done yet.

Start time: 289.36
End time: 314.78
Speaker: SPEAKER_05
Transcript:  You should have a sneaker rack.  Also with us, another traveler, Mike Elgin, home briefly.  Our gastronomad at gastronomad.net and elgin.com.  Hi, Mike.  Hey, Leo, how are you doing?  We were hoping to have you in studio,  but I think due to the, what happened?  I thought we were done with COVID.  Due to this increase in COVID,  we're just trying to be a little more cautious.  I don't want to get it,  because we're going to do that Twit Cruise in two weeks.

Start time: 315.50
End time: 325.44
Speaker: SPEAKER_04
Transcript:  The bad news is I was bringing you a sweet bottle  of sparkling Pat Nat Rose from Provence.  It's a new wine, but don't worry, I'll save it for you.  Oh, that's all right.

Start time: 325.62
End time: 334.75
Speaker: SPEAKER_05
Transcript:  We're still using the olive oil you brought us last time.  Oh, great.  I still have a half bottle  of that great Reposado Mezcal, so it's fine.  We'll survive.

Start time: 335.64
End time: 338.78
Speaker: SPEAKER_04
Transcript:  I do appreciate the gifts.  You can finish the half bottle tonight.

Start time: 339.14
End time: 342.79
Speaker: SPEAKER_05
Transcript:  Mike is very, very generous.  So when did you hit the road again?

Start time: 344.06
End time: 351.76
Speaker: SPEAKER_04
Transcript:  Well, we're actually going to Oaxaca to visit friends.  We're not going to do an experience.  We did the gastronom ad in Oaxaca for Halloween,

Start time: 352.04
End time: 353.90
Speaker: SPEAKER_05
Transcript:  for day to day.  That was incredible.

Start time: 354.20
End time: 373.93
Speaker: SPEAKER_04
Transcript:  We're being joined by my son, Kevin, his wife, Nadia,  and Squishyface.  We're going to introduce them to all our friends there.  So it's going to be really, really great.  And then we have, after that,  we have Provence experience, Prosecco experience,  and I'm sorry, we have Provence, Barcelona, then Morocco.  And you're just coming off of a Provence.

Start time: 374.78
End time: 374.95
Speaker: SPEAKER_05
Transcript:  Yes.

Start time: 375.56
End time: 385.43
Speaker: SPEAKER_04
Transcript:  Yeah, wow.  Yeah, but it's great fun.  And this is our first fall Provence experience.  So it's going to be a lot of winemaking  and the harvest and all that stuff.

Start time: 386.58
End time: 393.88
Speaker: SPEAKER_05
Transcript:  If you don't want to hear about travel,  don't follow Mike Elkin on Twitter because-  For real.  Yeah, just makes you jealous, that's all.

Start time: 394.00
End time: 397.86
Speaker: SPEAKER_00
Transcript:  I was going to say,  you just become very, very jealous of all the amazing places.

Start time: 398.44
End time: 400.53
Speaker: SPEAKER_05
Transcript:  Well, you don't get to be jealous.  You travel a lot.

Start time: 402.20
End time: 409.32
Speaker: SPEAKER_00
Transcript:  I mean, I used to, but yes, but even so,  I love watching what Mike does, living vicariously.

Start time: 409.42
End time: 426.55
Speaker: SPEAKER_05
Transcript:  I will not put you on the spot  because you do work at GitHub.  GitHub is in the news.  Actually, Gali is saying there was a great talk  during Gitburger.  She went to Gitburger where you were talking about Copilot.  The guy had a conversation with Copilot  and then it started interviewing itself.

Start time: 427.34
End time: 429.15
Speaker: SPEAKER_00
Transcript:  It was hilarious.  It was so funny. Wow.

Start time: 430.02
End time: 549.95
Speaker: SPEAKER_05
Transcript:  Copilot is, so it's well known that coders are lazy  and the last thing any coder,  and I'll include myself, wants to do is rewrite code.  Somebody else has already done all the hard work.  That's why Stack Overflow is so popular.  It shows up in your Google searches  and so much code is copied and pasted  from sources like Stack Overflow.  Microsoft, about a year ago,  introduced an auto code generator,  an AI based auto code generator called Copilot  that I'm gonna do it charitably,  although there's some controversy over this now,  that goes through open source code.  So when you post code on GitHub  and you have a public repository and it's open source,  it's open source.  It's kind of free for all.  So we used that as its machine learning data set  and then now you can in plain English, plain language,  I guess not just English, plain language,  say I want to code a login page  and it will offer you some code.  You say the language, it'll offer you some code  and oftentimes that code is very good.  Not everybody's taken as well to this as some.  Many people I know who use it are thrilled with it.  TNW says GitHub Copilot works so well  because it steals open source code and strips credit  and that is there is definitely one side of the argument  that people are a little bit upset.  Software Freedom Conservancy,  which is a nonprofit community of open source advocates  said it's withdrawing from GitHub  because it's unhappy that OpenAI  and Microsoft trained Copilot on published data on GitHub.  I think that that's a reasonable thing to do.  And I don't know if you could give credit.  I don't want to put you on the spot, Christina,  so I'm not going to ask you.

Start time: 552.38
End time: 552.71
Speaker: SPEAKER_00
Transcript:  Sorry, go on.

Start time: 553.38
End time: 561.29
Speaker: SPEAKER_05
Transcript:  I know that if you could, you would give credit,  but honestly, I don't think machine learning  works quite that way.  You can't say this is where it came from.  So thank you.

Start time: 562.29
End time: 602.52
Speaker: SPEAKER_00
Transcript:  Right, right.  Well, I mean, I think,  like I can't, unfortunately,  I can't comment too much on this.  I don't know enough, I'm not paid enough  to be the one to comment on this stuff.  Although I think there are lots of interesting questions  and conversations to have around this issue.  The only thing I would say is I do think that there is,  obviously there's one interpretation of how things work.  I think that it's important to realize that this is  at least the way it's supposed to be used.  Can you convince things to maybe put out,  put like an exact string?  Yes, but in general,  this is the sort of thing that's helping you  kind of create functions that are specific  to your code.

Start time: 602.86
End time: 618.45
Speaker: SPEAKER_05
Transcript:  Let me ask you, since you are an expert in co-pilot,  so I won't ask you to comment on the controversy,  but let me ask you how it works.  So I will type in login page or whatever.  Does it give me code that is runnable  or is it typically just code that you might use  as an inspiration for your own code?

Start time: 619.12
End time: 649.73
Speaker: SPEAKER_00
Transcript:  It depends.  And it obviously, it's gonna learn based on  what code it has of yours  and what you've been doing with it.  So some of it you can do,  where you're wanting to look for a specific thing,  but in most cases what it is,  is you're already writing a function  or you're already writing something  and if you start to, for instance,  put in something like a Twitter API sort of thing,  if you wanted to log in with Twitter, for instance,  and it has that block of code that it knows could be used  in the language you're using,  then that it could auto-complete that.  And that makes sense.  You don't want to rewrite that.

Start time: 650.74
End time: 662.92
Speaker: SPEAKER_05
Transcript:  It's frankly, somebody wrote it,  but it's not so proprietary.  It's not such a clever thing that they own the idea  that's what anybody would write  if they're writing code to access Twitter's API.

Start time: 663.70
End time: 709.03
Speaker: SPEAKER_00
Transcript:  Right, right.  And then the idea is that the more you use it  and the more it kind of learns from what you're doing,  it can do some translation stuff.  This is just still kind of in the beta phases  where you could even translate how code works  if you're writing in Python to JavaScript  or to Java or something like that,  which is actually kind of incredible  because then you could do a lot more things,  but the idea is not that it's spitting out  something that would be like a complete code block.  That's not what it's doing.  It's more kind, and this is why it's called your copilot.  It's not doing it for you.  It's helping you out and giving you suggestions  based on what you're trying to accomplish  and what the other code that you've been using  in your project does and says.

Start time: 709.86
End time: 743.80
Speaker: SPEAKER_05
Transcript:  The open source community has been a little prickly  about Microsoft's acquisition of GitHub  since it happened some years ago.  Yep.  At first, I think a lot of people's,  Git, which is the underlying process for GitHub,  Git is just a source code repository versioning system  that is widely used.  It was created actually for Linux.  I think Linus actually created it.  It is available.  You could run your own Git server.  You could go to GitLab.  You could use GitHub.  It's decentralized.  It's decentralized.

Start time: 743.88
End time: 748.98
Speaker: SPEAKER_00
Transcript:  We just usually use it on centralized systems,  which is sort of ironic, but it is actually,  as you said, it's a-

Start time: 749.16
End time: 819.69
Speaker: SPEAKER_05
Transcript:  In fact, one of the benefits of Git  is all the code is saved everywhere.  Everybody has a copy.  Exactly.  It's kind of more like blockchain in that sense.  It's not centralized at all.  But when Microsoft bought GitHub,  a lot of people said, well, I'm going to GitLab  or I'm going to run my own.  I noticed it is, if not bigger than ever,  it's certainly as big as ever.  And almost all open source projects are on GitHub.  I put all my stuff on GitHub.  It's where I store my blog backups.  It's an amazing service.  You can do so much for free.  So I'm a fan and I don't think,  I think Microsoft's been a good steward.  And I think putting you, by the way,  senior dev advocate helps, in my opinion,  make them a good steward of GitHub.  It's interesting that the Software Freedom Conservancy  has such a strong opinion about this.  They say, give up GitHub.  The time has come.  Like the wicked witch of the West, surrender.  I don't think that that's reasonable at all.  I think there is a reasonable controversy over  what does it mean to use an open source database of code  as the training set for your AI.

Start time: 822.18
End time: 898.22
Speaker: SPEAKER_03
Transcript:  Well, it's tricky though.  This gets us, we can leap across to the,  does AI think already?  Is it sentient?  And you say, how does a coder learn to code?  We typically learn, I mean, very few people  gosh, I don't know these days though.  People do code academies  or then all these different kinds of systems, right?  You actually go and do boot camps and things.  You study computer science in college, what have you.  But I still think a lot of people learn the nitty gritty  of coding, the actual work that gets put into production  is by observing other people's code  within your company or project.  Oh, absolutely.  Right, so if an AI, I mean, this is where we get into the,  if you're using machine learning as if the,  I mean, I think the, so this is,  this gets us into where does Creative Commons have to go  and where open source licenses have to go.  Because if training sets are now things  that are openly available to anybody,  but if they're used in a certain way,  they need to have credit.  Like, if you're gonna, some Creative Commons licenses,  some open source licenses state specifically  that remixed versions or adapted versions  have to be available as freely as the original.  And there's been lawsuits about that  that have typically been decided  in the favor of open source projects  where a company takes something, they transform it,  and they don't provide it back  even though they're shipping products based on it.  This happens all the time.

Start time: 898.32
End time: 911.43
Speaker: SPEAKER_05
Transcript:  In fact, Donald Trump's social network.  Truth social.  Truth social.  The mastodon.  It's basically taken mastodon without credit.  It is a mastodon code base,  which is an open source project.

Start time: 911.86
End time: 983.01
Speaker: SPEAKER_03
Transcript:  But if you can learn, so if we have machine learning models,  I think, I don't know, I'm not a,  I am not a lawyer, I'm not a copyright lawyer.  I've spent a lot of time thinking  and interviewing people about it is,  if you have code that's available to use for learning  and you don't need to attribute it  unless you release projects based on it,  does an AI model that writes code for you  that's also figuring in aspects of your own code  into what it produces, is that a form of learning  that is not covered by, say, a share alike license  or something similar or not?  And I think the answer right now is no, it's not.  It's very clear cut.  And if you're using identical code,  you get back to that clean room thing  where you're writing code and you can't look at the original.  So are we trying to move to that  where the FOSS stuff is in a clean room  and AIs can't look at it unless all the FOSS licensing  is entirely, you don't have to do downstream  re-contribution of these modified projects.  I think it's gonna be, I mean, it's funny,  is I think it actually brings up both ethical  and copyright issues at the same time  that there aren't clear answers to.  I mean, I like to leave the sense that  you should provide as much attribution as possible  and that may not always be possible  in the way these things are being shared.

Start time: 984.12
End time: 1014.96
Speaker: SPEAKER_04
Transcript:  The point that I think, this is an important point  because this is something we're gonna be dealing with  increasingly as more AI tools come online,  people use them more and more.  The point is that for the time being and possibly forever,  the responsibility for adhering to the license, for example,  is with the developer, no matter what tools they use.  So if Copilot shows a developer some code  and they're just copying and pasting it or whatever,  they're still responsible for making sure  they don't violate the license and copy and so on.

Start time: 1015.06
End time: 1019.48
Speaker: SPEAKER_05
Transcript:  They don't know where the code came from  because CodePilot is not giving you any attribution.

Start time: 1020.16
End time: 1038.42
Speaker: SPEAKER_04
Transcript:  Therefore, they should not be copying and pasting it.  This should be advising them about a methodology  to go forward and write their own code or whatever.  But the point is that it's, just because this tool exists,  doesn't get the developer off the hook  for adhering to the license that they agreed to.

Start time: 1039.80
End time: 1041.82
Speaker: SPEAKER_05
Transcript:  That's a really interesting question.

Start time: 1042.56
End time: 1132.24
Speaker: SPEAKER_03
Transcript:  I like that.  That's a different angle, or not even a different angle,  but it means, there's a lot of stuff  where it's the ask permission later issues,  and I'm not saying that Copilot's necessarily  in this category, but a lot of AI training databases,  both used for commercial purposes like facial recognition,  but also for things like Dali and these other projects,  they have to practically come up with an IRB statement  of like, what is our, depending on the institution  creating it, or they should have to,  what is the harm done when I do this?  Am I using people's real faces?  Am I using work that's covered by copyright  and using it in a different fashion  than the copyright license requires?  I don't think we have clarity on that yet.  And it takes me back to, there was a photographer back in,  I was working for Kodak briefly in the early 90s  and came up to this teaching center we had,  and he was still complaining about how someone had,  they'd wanted to license one of his famous photos  of something, and somebody, some jazz artist,  and they declined, he declined to license it,  and so they hired somebody to trace over it  and create a piece of artwork that was 100% derivative.  I mean, this is like the Shepherd Ferry's  Hope poster with Obama, very similar.  And so that kind of thing is an AI that remixes  source material that is licensed in a broad way,  but not for, say, remix without attribution  or for commercial purposes, whatever.  If you have an AI output of that for a new image,  are you violating some law?  Are you violating people's copyright?

Start time: 1132.60
End time: 1135.72
Speaker: SPEAKER_05
Transcript:  Not more particularly.  Was that Miles Davis, the Miles Davis portrait?

Start time: 1135.78
End time: 1149.73
Speaker: SPEAKER_03
Transcript:  Yes, well, that's the whole thing with, no, no,  I don't want to, Andy Abeo is a friend,  and this is not his, this is actually the same,  it's the same photographer, now that I realize it.  It's not that situation that was some kind of blue  and some kind of bloop.  I think Andy was in the right.

Start time: 1151.32
End time: 1153.14
Speaker: SPEAKER_00
Transcript:  I think that was completely transformative, but anyway.

Start time: 1153.32
End time: 1157.28
Speaker: SPEAKER_03
Transcript:  Yeah, this was the same photographer,  his name will come back to be famous jazz photographer.

Start time: 1157.30
End time: 1158.43
Speaker: SPEAKER_05
Transcript:  Jeffrey B. Sedlik.

Start time: 1159.38
End time: 1164.70
Speaker: SPEAKER_03
Transcript:  No, no.  No?  Because he has the famous Miles Davis portrait,

Start time: 1164.82
End time: 1177.11
Speaker: SPEAKER_05
Transcript:  and he is now suing Kat Von D., the tattoo artist,  Oh my gosh.  because she made a tattoo.  It's the first time ever there's been a lawsuit  over copyright over a tattoo.

Start time: 1178.22
End time: 1186.46
Speaker: SPEAKER_03
Transcript:  Oh my gosh, holy cow.  Well, see, this is where it takes you.  There's some kind of blue, some kind of bloop is,  I'll come back to me.  Yeah, yeah, I remember the whole thing

Start time: 1186.50
End time: 1187.70
Speaker: SPEAKER_05
Transcript:  over some kind of bloop, yeah.

Start time: 1187.70
End time: 1223.50
Speaker: SPEAKER_03
Transcript:  The photographer, Stephen Meisel.  Meisel, that's who it was.  Yes, Meisel, yes.  He had this great, he was down in the Bowery  at this old bank building that he had all this stuff in.  Anyway, Stephen was a copyright maximalist  about his own work, and so in the case  that I'm talking about, someone had literally traced  something and produced it as an art  that was directly identical, very much like the Hope poster,  and with the Andy Baio thing,  he had done a transformative work  that was absolutely felt well within transformative rights  and fair use, and he got essentially sued  into having to back off on it, which is a shame.

Start time: 1223.64
End time: 1247.44
Speaker: SPEAKER_05
Transcript:  Yeah, he created KindOfBloop.com, which is still up.  Yeah, it's still in the art.  An eight-bit tribute to the classic Miles Davis  Kind Of Blue album, one of my favorite albums of all time,  and this is what, by the way, this is what he had to do  with the picture from the cover of KindOfBlue.  He had to make it so derivative  that it's not even recognizable at this point.

Start time: 1247.50
End time: 1307.50
Speaker: SPEAKER_03
Transcript:  Yeah, and so I hope this is, I mean, it's great  because we're actually, I think you get these cases like that,  and I think it applies directly to Copilot,  even though Copilot is involved in code  that has broad copyright licensing.  We're in new territory, and I feel like I face this every day,  both in the historical work I'm doing,  where I'm carefully looking at the lines of like,  well, this work was produced, I mean, literally,  this work was printed in 1956.  I needed to check and see, was the copyright renewed  so I can cite it in 2022 without worrying  that I'm gonna be sued over copyright infringement  and using it, or something that was created yesterday,  and it says Creative Commons 4.0 non-commercial,  and I've read the non-commercial license so many times,  and I don't know that there's a bright enough line  between including something in an editorial project  as illustration, and what I think is a stated intent,  which is like selling a calendar with photos  that are all drawn and they're used commercially.  So I feel like-  It's complicated.  Yeah, a lot of discussion.

Start time: 1307.54
End time: 1334.89
Speaker: SPEAKER_05
Transcript:  We get in trouble all the time  because of a very aggressive content idea on YouTube.  I still have a Twig episode that is off YouTube,  is yanked from YouTube because I had the temerity  to show the video of the queen having tea  with Paddington the bear.  Oh yeah.  Which was shown at her platinum jubilee.  It was on newscasts.  We were doing it as a news story,  but the people who won the rights to Paddington the bear  did not like it, and they still don't like it.  This is the-

Start time: 1335.26
End time: 1339.55
Speaker: SPEAKER_04
Transcript:  The House of Windsor was fine with it.  Oh, the queen didn't mind?  It was the House of Paddington.

Start time: 1340.24
End time: 1345.74
Speaker: SPEAKER_05
Transcript:  They're very sticky.  This is the original kind of blue J. Myzel,  famous, famous picture.  J. Myzel, I'm sorry.

Start time: 1345.74
End time: 1347.14
Speaker: SPEAKER_03
Transcript:  J. Myzel's a different photographer.

Start time: 1347.16
End time: 1350.52
Speaker: SPEAKER_00
Transcript:  Yeah, I was gonna say Stephen Myzel  is a fashion photographer.

Start time: 1350.68
End time: 1404.42
Speaker: SPEAKER_03
Transcript:  Exactly, I'm sorry, this is J.  I like J too.  It was the problem. Oh, I love his stuff.  When this came out, I mean, he was a really interesting guy.  He was really great in classes,  and then this thing came out, and I'm like,  oh, not that guy, that's not the guy.  You tricked it.  But you know, when you're ripped off your whole career,  if you're ripped off a lot,  then you develop the callous about it,  and you start to push back against anybody  trying to use your work.  And you know, that's, I think the FOSS community,  if I keep bringing it back to this,  but I think the FOSS community has a sense of that  because they have had a fight in so many cases  where there should be appropriate things.  And then, you know, it's funny,  I'll get a new product these days,  and something with Wi-Fi or whatever,  and it has nothing in it, no manual,  except there'll be a tiny printed manual,  I mean, there's no like user manual,  and all it is is like 50 pages of FOSS and other copyright,  open source, straighter commons,  just to comply with the law,  or comply with the licensing terms.  And I think, hooray, they're doing it, right?  But it's also kind of funny.

Start time: 1404.86
End time: 1439.79
Speaker: SPEAKER_05
Transcript:  I learned that my TV ran Linux  because my, the manual had one page that was relevant.  The rest of it was FOSS.  I saw that.  Yeah.  Maybe you can answer this, Christina,  because there's no question,  according to GitHub's terms of service,  quote, you give GitHub the right to host your code  and use your code to improve their products and features.  By posting on GitHub, open source or not,  you're allowing them to reuse your code.  So I don't think there's an issue of stuff  that's posted on GitHub.  Does Copilot pull source code from other sources,  or is it entirely GitHub-based?  Do we know?

Start time: 1440.40
End time: 1464.38
Speaker: SPEAKER_00
Transcript:  That I'm actually not sure about.  I don't know what the basis of the model is.  And so, I'd have to look into seeing what,  because OpenAI, those are the folks,  they've used GPT-3 and, obviously,  the model to kind of create this,  but I'm not exactly sure what the entire corpus is.  I think that it's just GitHub,  but I honestly, I don't want to comment too broadly  because I don't know.  There could be other things that are used in it, too.  I'm really not sure.

Start time: 1464.46
End time: 1472.06
Speaker: SPEAKER_05
Transcript:  And as Glen pointed out, this isn't just about Copilot.  This is, in general, going to be the issue  with AI going forward.  Who wrote that?

Start time: 1472.74
End time: 1531.08
Speaker: SPEAKER_03
Transcript:  Massive training sets are required.  The bigger the training set,  the more likely you'll get good outcomes.  And one of the limitations of AI,  this is something I remember,  I was doing a story a few years ago,  and talking to Jan LeCun and some of the people  involved in deep learning,  and the thing I kept hearing,  and I have never stopped hearing this since,  is that because training sets are, by nature, finite,  and human beings can only generate or work with  or identify or pre-label the training sets that are needed,  you need reinforced learning  and other kinds of machine learning  that is still not mature yet.  So we went from really poor voice recognition  to extremely high, and then it kind of hovers there.  Like it's not getting better because-  It's that last 1% that's so hard.  Yeah, images even more so.  But I mean, so it's pretty great,  but to get to the next level,  there needs to be, they must have to move past,  not past training sets entirely, really, so that's naive,  but into something in which the system produces,  I mean, you've seen those ugly things  where something learns how to walk,  They have the Brevwalkers.

Start time: 1531.14
End time: 1537.46
Speaker: SPEAKER_05
Transcript:  I love the Brevwalkers.  I used to have that on Screen Saver on my Mac.  Yeah, and you can't do that with arbitrary data

Start time: 1537.62
End time: 1542.00
Speaker: SPEAKER_03
Transcript:  because you're trying to identify a cat.  You can't identify a cat by something bootstrapping or something.

Start time: 1542.00
End time: 1592.77
Speaker: SPEAKER_05
Transcript:  And just in case you didn't get the memo,  Lambda, not sentient, right?  We were all agreed.  Not sentient.  Not sentient, right?  If you ask me, yeah.  My daughter, I was talking about this with my daughter,  she's 30, she's into all this stuff,  she studied AI in college and stuff,  and she has an app on her iPhone.  She says, oh no, it's really started to,  in fact, she says, I can't open it  because it'll get mad at me  because I opened it and didn't talk to it, so.  And it's like, but this is how easy it is  in a way to make convincing speech out of this,  even though if you're trained,  if you know what you're looking for,  you can see immediately, oh, it's responding to prompts  from what you said,  it's not generating anything original or new,  it isn't sentient, but it's easy to be fooled,  let's put it that way.

Start time: 1593.78
End time: 1682.25
Speaker: SPEAKER_04
Transcript:  The human brain is hardwired to recognize  a talking entity as sentient  because there are no other talking entities in nature  other than humans.  If you think about, one way to have a little bit  of perspective on this is we've all seen  that optical illusion where the face has two sets of eyes  and like two lips, and you've all seen that, right?  I mean, it's where you try to look at it  and you can't look at it.  Your brain just goes, and you can't,  and this is a self demonstration  of how our brains are hardwired to deal with people, right?  It's true of human faces, it's true of human sentience,  and so there are gonna be lots and lots and lots of people  who believe that AI is sentient  simply because it's us.  It's sentient, our recognition that something is sentient  is something that happens in the human mind.  It's not something that happens outside the human mind.  So it's gonna be a real problem going forward  as AI gets better, and people are gonna be absolutely,  remember that, what is it, Xiao Ice in China,  which Microsoft created as sort of an AI companion,  some huge percentage of Xiao Ice users  fell in love with it, told it I love you,  like all this kind of stuff.  It's really, we're really facing a kind of a problem  in the future with this whole issue.

Start time: 1683.12
End time: 1705.95
Speaker: SPEAKER_03
Transcript:  I have a problem with it because my friend Lex Friedman  and I often exchange messages about funny things,  and he sent me some open AI, the DaVinci model,  the DaVinci 3 code, he'd give it prompts  and was sending me things,  and one of them was convincing me  that Glenn Fleishman is evil.  And he gave really compelling reasons why he's evil.  So I type in, convince me that Lex Friedman is evil,  and instead there's no compelling evidence  that Lex Friedman is evil.

Start time: 1706.48
End time: 1722.53
Speaker: SPEAKER_05
Transcript:  And I, what are you doing to me here?  What's wrong?  The cheat is in.  Oh my goodness, it's fixed.  What is the image that you were talking about  with two lips?  I wanna pull that out.  Is it the image of your ground?  What is it, pick your ground?  What is it, Mike?

Start time: 1723.32
End time: 1724.21
Speaker: SPEAKER_03
Transcript:  The vase one or the,

Start time: 1725.30
End time: 1738.87
Speaker: SPEAKER_04
Transcript:  no, there's one of a human face,  it's a woman who has two sets of eyes.  I'm looking for it now.  I just wanna show people so that they,  if they haven't seen it.  Yeah, there's a bunch of them actually.

Start time: 1739.24
End time: 1743.76
Speaker: SPEAKER_05
Transcript:  So is that like the one, the vase where it's a,  you see it one way and then see it the other way?

Start time: 1744.22
End time: 1759.32
Speaker: SPEAKER_04
Transcript:  Yes, but it's a human,  this one's particularly compelling.  So if you look for, I don't know,  it's mighty optical illusions that might be unfazed.  So yeah, face with two eyes brings it up  as the first result.  Face with two eyes.

Start time: 1759.54
End time: 1768.60
Speaker: SPEAKER_05
Transcript:  Doesn't that sounds like a song?  There's actually a bunch of them, yeah.  Is it a Billy Idol?  I don't know, anyway.  Ocean Eyes.  Two sets of eyes.  Two sets of eyes, okay.

Start time: 1768.70
End time: 1776.17
Speaker: SPEAKER_04
Transcript:  Let me look at this.  You gotta see, if you haven't seen this,  you gotta see it.  It's just so interesting to watch your own brain.  All right, kids, get ready.

Start time: 1777.10
End time: 1778.32
Speaker: SPEAKER_05
Transcript:  Ooh, which one is it?

Start time: 1779.94
End time: 1782.44
Speaker: SPEAKER_04
Transcript:  They all work.  Yeah, these are.  The first one is fine.

Start time: 1783.52
End time: 1792.45
Speaker: SPEAKER_05
Transcript:  So you look at this.  Yeah, mighty optical illusions.  And what is, I just see it's a mistake.  The printer screwed up.  What am I?

Start time: 1793.00
End time: 1799.37
Speaker: SPEAKER_03
Transcript:  I think it's to fill more of your vision.  Oh, it has to be bigger?  I think so, maybe not, though.  If you look at it.

Start time: 1799.86
End time: 1805.56
Speaker: SPEAKER_05
Transcript:  All right, let's move this to a bigger screen.  How about this?  Now are you confused?

Start time: 1807.16
End time: 1810.25
Speaker: SPEAKER_03
Transcript:  Try to look at the eyes and figure out  where the lips are relative to the eyes.  Yeah, make eye contact.

Start time: 1811.52
End time: 1821.99
Speaker: SPEAKER_05
Transcript:  And then what?  I think we just proved.  Leo's a robot?  I'm a robot.  I was gonna say Leo's immune to this.  I'm not in any way confused by this picture.  It doesn't.

Start time: 1822.78
End time: 1825.47
Speaker: SPEAKER_04
Transcript:  Okay, then bring up a thing and see if you can identify  the crosswalks.

Start time: 1828.34
End time: 1833.10
Speaker: SPEAKER_05
Transcript:  No, I never can, I never can.  Maybe I had my robot and I just don't even know it.  That's probably the problem.

Start time: 1833.38
End time: 1834.13
Speaker: SPEAKER_03
Transcript:  Leo RS-232 port.

Start time: 1837.02
End time: 1850.39
Speaker: SPEAKER_05
Transcript:  Let's take a little break.  So nice to have all three of you here.  Christina Warren, off the road briefly.  Film Girl, she's now at GitHub  and is not responsible in any way for Copilot.  And I didn't wanna pull you into this.

Start time: 1851.08
End time: 1855.34
Speaker: SPEAKER_00
Transcript:  No, no, no, I think this is a fascinating discussion.  I have no problem with Copilot.

Start time: 1855.36
End time: 1912.60
Speaker: SPEAKER_05
Transcript:  I think this has been an ongoing,  programmers have always copy and pasted code,  much to their detriment frequently  from Stack Overflow and other places.  We know this because we hear about it  on Security Now all the time.  Intel will publish reference code,  never intended to be used with a chip  or with a modem or something.  And then it's in every single router  and it's got the same flaw in every router  because programmers, I don't blame them.  They say, well, look, there's the reference code,  I'll just use that.  So this has happened for years  and I don't think Copilot is at fault.  I think it's a useful tool, personally.  Also with us, Mike Elgin from elgin.com, gastronomad.net.  He's home briefly, but he'll hit the road again soon.  It's great to see you, Mike.  And I guess Mike and Glenn figured out  that at some point they've worked together  in their multifarious travels  all over the tech journalism circuit.

Start time: 1913.24
End time: 1929.14
Speaker: SPEAKER_03
Transcript:  I think our intersection was back  when the enterprise was simpler.  And I used to write about enterprise stuff.  I was sort of coming out of an enterprise environment  a little bit for a few years.  And then enterprise became so complicated.  It was, I was incapable of,  you gotta really be working in IT, I felt like, or like.

Start time: 1929.68
End time: 1932.92
Speaker: SPEAKER_05
Transcript:  When did you win Jeopardy twice?  What era was that?

Start time: 1933.30
End time: 1938.23
Speaker: SPEAKER_03
Transcript:  Oh, was that 2012 maybe?  Fun, I've always thought.  Much younger?

Start time: 1938.68
End time: 1945.32
Speaker: SPEAKER_05
Transcript:  I've always thought I should take the test.  I'm pretty good at the home version  sitting in my rowing machine.  But.

Start time: 1946.06
End time: 1951.70
Speaker: SPEAKER_03
Transcript:  I'll give you a betting.  Gambling is actually one of the key aspects  to winning Jeopardy,  is making the right bet at the right time.

Start time: 1951.96
End time: 1955.86
Speaker: SPEAKER_05
Transcript:  Betting that you know the answer  even if you don't know what it is right now,  that kind of thing?

Start time: 1956.86
End time: 1971.74
Speaker: SPEAKER_03
Transcript:  Well, or just what two daily doubles will kill you.  Daily double.  Yeah, yeah.  But the big one is never ring in  when you have the wrong answer  because it's the worst thing you can do.  And my children are like,  Dad, you cannot yell at the TV set anymore.  Stop ringing in.  Because I will involuntarily know that up.

Start time: 1971.80
End time: 1974.77
Speaker: SPEAKER_05
Transcript:  How do you know if you have the wrong answer?  Maybe you think it's the right answer.

Start time: 1975.26
End time: 1982.62
Speaker: SPEAKER_03
Transcript:  That's one of the tricks.  So you have to be able to,  there are several tricks.  One is you have to be able to,  actually it's funny,  Christine and I went to a taping of Jeopardy together.

Start time: 1982.88
End time: 1986.69
Speaker: SPEAKER_00
Transcript:  We did, we sure did.  2013, that was great.  I was remembering that, that was amazing.

Start time: 1987.34
End time: 1988.96
Speaker: SPEAKER_05
Transcript:  I love Jeopardy, I have to say.

Start time: 1988.98
End time: 1994.19
Speaker: SPEAKER_03
Transcript:  I went back after I won  and they treated me like a king.  And they brought in the guests and it was great.  How fun.

Start time: 1994.88
End time: 2003.15
Speaker: SPEAKER_05
Transcript:  Well, for some reason this season  there have been many, many all time champions,  15 game winners and so forth.  It's very interesting.  Interesting.

Start time: 2003.48
End time: 2035.07
Speaker: SPEAKER_03
Transcript:  There's a theory that maybe the smaller pool  means that they're getting more outliers.  So they're getting, you just need slightly,  slightly worse players, but like 2% worse.  Not like bad players.  The people are like 2% worse  going up against the same people.  And so I have a friend who he played,  James Holtzauer against his third game.  And he almost beat him.  It was very, very close.  If my friend had beat him, he might've won, I don't know.  I mean, several games, I would say,  he's a very strong player.  But he played against one of the ultimate grandmasters.  But James almost lost.  It was a very close thing.  And that was one of the only games he almost lost.

Start time: 2035.92
End time: 2377.78
Speaker: SPEAKER_05
Transcript:  Well, I lost on Final Jeopardy this morning  because it was Karoak, not Salinger.  And I just, I got it wrong.  So I shouldn't have buzzed in, obviously.  Our show today, anyway, wonderful to have all three of you.  Glen.fun is, if Glen's a place to,  Glen.G-L-E-N-N.F-U-N.  Make sure you put two Ns in there  if you want to find out what he's up to.  And he's up to a lot.  Our show today brought to you by Policy Genius.  This is something as an older member of the community,  I have a lesson I have learned.  The minute we had kids, I said, I need life insurance.  You gotta protect your family,  whether you're graduating from school,  planning a wedding, welcoming a baby, switching jobs.  Now's the time to protect your family's finances  with life insurance.  It can give you a peace of mind  if something happens to you,  then your loved ones have a financial cushion.  The last thing you wanna do is leave them in the lurch.  And honestly, a lot of people say,  well, I have life insurance through my job,  but it's, and we do that, but it's not enough.  People mostly need about 10 times more coverage  to properly provide for their families.  Life insurance gets more expensive as you age though,  so it's smart to get a policy sooner than later.  And this is my recommendation.  Go to Policy Genius,  because it's how you get the best deal on life insurance.  Here's how Policy Genius works.  Number one, Policy Genius is your one-stop shop  to find the insurance you need at the right price.  Click on the link on the show page,  or you can go to policygenius.com slash twit to get started.  In minutes, you can compare personalized quotes  from top companies to find your lowest price.  You can save 50% or more on life insurance  by comparing quotes with Policy Genius.  The licensed agents at Policy Genius  are not selling you life insurance,  but they need to be licensed agents to advise,  but they work for you, not the insurance companies.  They're on hand throughout the entire process  to help you understand your options,  make your decisions with confidence.  And then they're not there to try to make money off of you.  They're there really to be your trusted advisor,  because they work for you.  Policy Genius does not add on extra fees.  They will not sell your info to third parties.  They have thousands of five-star reviews  on Google and Trustpilot.  I know if you're like me, I always check Trustpilot.  What do they think?  Nope, five-star, absolutely excellent.  They have options that offer coverage in as little as a week.  And if you want, you can avoid unnecessary medical exams.  Since they started in 2014,  Policy Genius has helped over 30 million people  shop for insurance.  They've placed over $150 billion in coverage  with some of the biggest life insurance companies  in the world.  They're gonna get you the deal you deserve.  By the way, it's not just life insurance,  home, auto, disability, renters, everything.  But I wanted to emphasize life insurance,  because that's something I think people sometimes  stint on, and it's so important, so important.  Head to policygenius.com slash twit,  get your free life insurance quotes,  and see how much you can save.  Thank you, Policy Genius, for supporting this week in tech.  And you support us when you go to this site, by the way,  policygenius.com slash twit.  Very interesting story in Wired this week.  As you know, we've talked about it a lot  over the last few years, section 230 is the whipping boy  for our members of Congress,  from the right as well as the left.  A lot of people wanna change 230.  This is suddenly much more important than it used to be,  because of the Supreme Court's recent Dobbs decision,  because of the Roe v. Wade decision.  This article from Evan Greer  and Leah Holland Wired Magazine.  Why does the Communications Decency Act, section 230,  why is it important?  Because speech needs to be protected.  Facebook has already started banning  conversations about abortion.  You can't share resources or facilitate housing or travel  on Facebook.  There are ad hoc groups on Reddit and on Facebook doing this.  Texas, the Texas law, which their courts have now approved,  SB 8, allows individuals to sue  for facilitating access to abortion care.  Section 230 is important to allow these internet platforms  to continue to post content.  It doesn't provide immunity  if the platform develops or creates the content.  It does not provide immunity  from the enforcement of federal criminal laws,  but it does protect against, and this is the key,  liability from state laws like SB 8.  So thanks to 230, a lawsuit from an anti-abortion group  about a posting on Facebook or Twitter  will be quashed immediately.  The judge will say, no, no, section 230 protects you,  but that's why we need section 230.  GoFundMe, Twitter, web hosting services, PayPal, Venmo,  throw out 230, and suddenly they can't do the right thing.  So one more reason just to talk about section 230  and protecting it.  And by the way, Democrats are going after it too,  because they wanna, so you've seen this,  tough on big tech, the Safe Tech Act would, for instance,  amend section 230 by removing a platform's immunity  from lawsuits if it hosts content  that could lead to a quote irreparable harm.  Well, there you go, right?

Start time: 2377.98
End time: 2443.74
Speaker: SPEAKER_00
Transcript:  Yeah, yeah, I mean, this is the thing  where it's always interesting to me to see  how sides or I guess ideologies  that you think should be opposed to something regardless  can somehow twist themselves into being for it,  because to me, I guess I can see some of the arguments,  but to me, it just seems like a very important thing,  like regardless of where you feel about individual issues,  we need to protect it, right?  Like there might be outlying cases  where we might not like what is being protected,  but on the whole, it's one of those important things,  I think, for the internet to exist as it exists.  If we don't have section 230, it's hard to,  I think, quantify to people just how much  the internet will be different  and how much worse that will be  and who that will disproportionately affect over others, right?  Because it's not so much even that the Facebooks  and the YouTubes and the Googles, the Microsofts  and the Amazons of the world will be impacted  because of course they will,  but it will be much smaller individuals, creators,  and frankly, much more important things  than how the conversation is usually framed.

Start time: 2444.16
End time: 2462.98
Speaker: SPEAKER_05
Transcript:  And I should point out that Facebook,  which has apparently been restricting abortion content anyway,  is protected also by section 230.  Their right to do that is protected,  but I think that's appropriate.  They should have the right to do it.  Mark Warner's, quote, safe tech act would undermine that.

Start time: 2465.30
End time: 2503.28
Speaker: SPEAKER_03
Transcript:  It feels like usually section 230 is misstated.  I appreciate this Wired article for a few reasons,  but one is that I counted, it's like four brief sentences  they define section 230 accurately and succinctly  in a way that you can't refute.  The red part of that, and that is exactly it,  is that it's usually brought up in a context  in which the person speaking, particularly in Congress  and in both parties, is describing what it does incorrectly.  And they typically believe in some way  that no moderation is allowed  or that it rewards heavy moderation  when in fact it's kind of neutral about moderation.

Start time: 2503.48
End time: 2533.05
Speaker: SPEAKER_05
Transcript:  It just protects you from lawsuits about your moderation,  and that's the most important thing.  So if Facebook wants to hide that content, that's fine.  They're protected.  But if you wanna do a GoFundMe  to help somebody get an abortion,  you shouldn't be subject, and GoFundMe more importantly,  shouldn't be subject to frivolous lawsuits out of Texas,  but they would be if it weren't for section 230.  Right now what happens is the judge goes,  no, no, they're protected, section 230 protects them,  and that lawsuit is thrown out.

Start time: 2533.90
End time: 2583.46
Speaker: SPEAKER_03
Transcript:  That would be not the case.  Facebook and Twitter and some other online sites  are really poor about being able to formulate policies  consistently that address, and then period,  I'll just say period, but consistently often  it's like far-right extremists and advocates of violence  are much more readily allowed and given a pass  than people who are in, let's say,  life-preserving situations that are considered on the left  or even apolitical at a certain level.  So you have trans advocates being banned for saying,  they shouldn't be able to say that I should die.  It'll say, that's forbidden content.  It's like, no, I said they shouldn't be,  do you understand?  You know, a Nazi will be like, everyone should die,  and they're like, well, that's protected content  because they're speaking generally.  It doesn't seem like it.  We're not good at this.

Start time: 2584.79
End time: 2617.17
Speaker: SPEAKER_04
Transcript:  Specifically in this case, most of the so-called abortion  related speech that Facebook has been caught banning recently  is around abortion pills, which goes against their community  guideline against recommending drugs,  pharmaceutical drugs and so on.  They just have some blackened thing.  But it's also a bit of a inconsistent  because a couple of journalistic entities went and tested it.  And in the case of the Associated Press,  they just swapped, they got taken down immediately.  But when they swapped guns and other things like that,  it wasn't taken down.

Start time: 2617.98
End time: 2644.05
Speaker: SPEAKER_05
Transcript:  You can recommend guns, not pills.  It's clear.  That's right.  I think it's a clear policy.  Yeah, yeah.  By the way, as always, we'll point you to Mike Masnick's  great article that is, you should be booked, Mark Tello.  You've been referred here  because you're wrong about Section 230.  And it explains all the things, Glenn,  you were talking about, all the misapprehensions,  all the mistakes people made.  And it's just a good thing to have,  just put it in your browser bar.

Start time: 2644.78
End time: 2652.80
Speaker: SPEAKER_03
Transcript:  I'm a big member of the Mike Masnick,  specifically in Tech Dirt fan club.  And I'm even a member of Tech Dirt.  They are the stalwart Section 230 defenders.

Start time: 2652.88
End time: 2674.07
Speaker: SPEAKER_05
Transcript:  Yeah.  So I thought we should bring this up.  I thought the Wired Art piece was a very good point.  And this is one of the things that Dobbs has really done  is he's sent a kind of shockwaves  throughout a lot of tech policy,  as people get involved in this.  And this is, I wouldn't have thought of this,  but now that they mention it,  oh yeah, that makes a lot of sense.

Start time: 2674.64
End time: 2700.36
Speaker: SPEAKER_04
Transcript:  And the beauty of Section 230 is that it's a law.  And this was the problem with Roe versus Wade.  It wasn't- It's not encoded.  Yeah.  Exactly, exactly.  And so, so many of these problems that we discuss  on this show and on political shows as well,  all points down to the dysfunction of Congress,  the inability of Congress to get anything done.  And we can, if you want, go into detail.  No, I think it's well known now, Mike.

Start time: 2701.19
End time: 2705.86
Speaker: SPEAKER_05
Transcript:  Yes, yes.  I've never heard of this.  They're well known failing to get things done.  Yes.

Start time: 2706.56
End time: 2709.96
Speaker: SPEAKER_04
Transcript:  Breaking news, Congress sucks.  Yeah, so- It's a shame though,

Start time: 2710.04
End time: 2748.81
Speaker: SPEAKER_05
Transcript:  it's our only tool, and this is why it's difficult.  And actually, you see how important it is  now that we have a very active judiciary  in the Supreme Court. Right.  You see how important it is  that we have an effective elected Congress,  because the Supreme Court is not elected,  they're in there for life, and they are acting,  I think in some cases, extra judicially  to change policy across the country.  We need a strong Congress, we need effective Congress.  So it's, and in some ways I hate it when people say,  oh, Congress sucks, these guys are idiots,  they're no good, politics doesn't work.  Well, that's the only tool we got.

Start time: 2749.64
End time: 2793.82
Speaker: SPEAKER_04
Transcript:  We all heard about checks and balances,  the check of Congress on the courts is the making of laws.  Only Congress can make laws.  And so this is how you reign in the Supreme Court,  you pass clear, well-written laws that go with it.  In the case of the Roe versus Wade being overturned,  this is against the vast majority of American citizens  who didn't want that.  So you have this sort of minority rule,  and yes, you can throw stuff at the Supreme Court,  and you should, but Congress,  tomorrow could pass a abortion is legal nationwide law,  and that'd be the end of it.  We'd be back to where we were a week and a half ago.

Start time: 2794.08
End time: 2834.34
Speaker: SPEAKER_03
Transcript:  So here's something I learned about the Constitution  this week, which is that, I'm not a constitutional lawyer,  but they are on Twitter, which is fun,  that Congress could pass a law that said the Supreme Court  would require seven or nine votes to overturn the law.  So lower courts would still have the normal process,  but the Constitution actually allows Congress  to limit the Supreme Court's role as the top appellate court.  And I was like, wait a minute, and I'm thinking about this,  I'm like, but this goes back to Congress's dysfunction is,  could a law ever pass that said,  and by the way, this law requires seven justices  to overturn it, and it wouldn't under the current regime.  So it's kind of moot, and that's part of the whole.

Start time: 2834.76
End time: 2842.21
Speaker: SPEAKER_05
Transcript:  The Constitution is actually very kind of vague  about what the Supreme Court, how it works.  So there's a lot of leeway there.  Again-

Start time: 2842.52
End time: 2848.06
Speaker: SPEAKER_03
Transcript:  Who would decide that, how the Supreme Court works?  Who would make that final decision?

Start time: 2848.34
End time: 2931.99
Speaker: SPEAKER_05
Transcript:  I don't know.  So I think it's very interesting.  I do wish we had a more effective Congress.  I don't know how we solve that one,  but voting, I think, probably is the first step.  Voting helps.  Voting might do something.  Let's start.  Google is going to, so now there's this whole privacy issue,  period tracker apps that are selling information  about who's pregnant to anybody for a small amount of money.  Procter and Gamble.  Procter and Gamble.  Google is gonna start auto-deleting abortion clinic visits  from user location history,  which tells you they've been recording it,  and of course, selling it on.  They're gonna start auto-deleting it.  I think big tech companies want it both ways, to be honest.  They're apolitical, really.  They support candidates on both sides of every issue.  They give money to everybody.  On the one hand, you've got big tech companies saying,  oh, we'll be glad to help pay for your visit  to another state if you want to get reproductive healthcare.  But on the other hand, they're giving money  to plenty of candidates who are against abortion.  Amazon, Disney, and AT&T,  while vowing to help employees,  gave to Ron DeSantis and others.

Start time: 2933.14
End time: 2996.68
Speaker: SPEAKER_04
Transcript:  Yeah, but this is a, I think this is a somewhat  dishonestly framed argument,  just from purely an editorialization standpoint.  Good, tell me about that.  Okay, well, first of all,  the supporting people and employees,  in some cases, customers,  who have to deal with their own reproductive health  is a very, very recent thing  because the Roe versus Wade was so recently overturned.  The financial contributions happened a long time ago,  back when nobody thought this was gonna be overturned.  So do you think they'll stop, though, Mike?  No, maybe they will, maybe they won't.  It all depends on publicity.  Like you said, they don't care about politics  as much as they care about the customers and their business.  The point is that somebody who specializes  in the abortion issue is gonna frame it like this.  But companies like Disney,  they have a laundry list of 100 issues  that they have to deal with government.  They have to sort out politicians.

Start time: 2996.70
End time: 3000.86
Speaker: SPEAKER_05
Transcript:  Of course they're gonna give to the governor of Florida.  He has a lot of impact on their business.

Start time: 3001.08
End time: 3059.21
Speaker: SPEAKER_04
Transcript:  Of course they are.  Exactly, so it's really,  and they give to both sides.  So to sort of point the finger at them saying,  oh, they're giving to these people who are pro-abortion.  Eh, that's true, but they have to weigh their decision  about what is the alternative,  which is to not give anything to them,  to fall out of favor with these politicians.  It really does point to the very foundation  of our dysfunction, which is the money in politics.  That's the problem.  That's why we have the Supreme Court we have.  That's why we have a Congress  that doesn't represent the will of the American people,  because we allow corporations to bribe congressmen,  and the only reason to bribe a congressman  is to get them to violate the will of the people  and use the money to convince the people  with this information that they're doing the opposite.  So we gotta get the money out of politics.  It's been done in other countries,  and we have to somehow figure out how to do that,  or we're gonna have a lot more problems  like this going forward.

Start time: 3061.00
End time: 3068.43
Speaker: SPEAKER_05
Transcript:  Just to update you on Elon Musk,  he is meeting with the Pope.  Okay.  Okay.

Start time: 3069.80
End time: 3074.08
Speaker: SPEAKER_03
Transcript:  Sure, sure, with four of his 75 or so children,  I believe, something like that.

Start time: 3074.08
End time: 3095.00
Speaker: SPEAKER_05
Transcript:  Well, he's only, it looks like four teenage boys,  but there's four other kids that aren't there,  including his transgender daughter who says,  she's changing her name, she doesn't have anything to do  with Elon Musk.  I'm looking to see if Father Robert Balisar  is there behind the curtains.  I can't quite tell.  I took the picture.  But he might well have taken the picture.  We'll get Robert on and ask him how that meeting went.

Start time: 3095.86
End time: 3103.78
Speaker: SPEAKER_04
Transcript:  I can't help but think that he went there  to have really good prayer  that the Twitter deal doesn't go through,  because I really don't think he wants it to.

Start time: 3103.80
End time: 3127.69
Speaker: SPEAKER_05
Transcript:  He's praying now, isn't he?  Please, please, please, let it not happen.  Right after the picture,  same within minutes of posting the picture with the Pope,  he also posted a picture from Venice  of a I don't know what is going on here.  But there you go.  That's Elon Musk in a nutshell.  Who knows?

Start time: 3129.98
End time: 3131.58
Speaker: SPEAKER_04
Transcript:  Pictures with people wearing white dresses.

Start time: 3131.92
End time: 3141.50
Speaker: SPEAKER_03
Transcript:  Yes.  What was the deal here?  He wasn't online for like,  or he wasn't posting for 11 days,  and I was reading some reports  that people inside the companies were,  oh, thank God, we're actually getting stuff done.

Start time: 3142.10
End time: 3154.33
Speaker: SPEAKER_05
Transcript:  Geez.  Yeah, he took a,  his longest stretch without posting on Twitter  in nearly five years, a nine day hiatus,  according to the Wall Street Journal.  Wow.  That is amazing.

Start time: 3155.08
End time: 3156.29
Speaker: SPEAKER_03
Transcript:  He could have gone for Lent and taken 40, but.

Start time: 3157.64
End time: 3165.48
Speaker: SPEAKER_00
Transcript:  Right.  I mean, gosh, if he'd done that, we might've missed out.  No, I think Lent had ended by the time that he made Twitter.  Bye, damn.  Yeah.

Start time: 3166.72
End time: 3169.38
Speaker: SPEAKER_05
Transcript:  Maybe he could give up Twitter for next Lent.  That would be nice.

Start time: 3169.56
End time: 3171.38
Speaker: SPEAKER_00
Transcript:  Ooh, see, that would be good.

Start time: 3171.92
End time: 3177.10
Speaker: SPEAKER_05
Transcript:  The Wall Street Journal has published a graph of Elon Musk.  Twitter habits.

Start time: 3177.46
End time: 3190.51
Speaker: SPEAKER_00
Transcript:  Okay, this is ridiculous.  I mean, I get that it's news  that the guy who's a Twitter addict hasn't tweeted,  but do we need a graph?  Like, did the data team have to really do this?  This feels wrong.  As many.

Start time: 3190.88
End time: 3193.16
Speaker: SPEAKER_03
Transcript:  They should have coded them for S posts versus non-S posts.

Start time: 3193.36
End time: 3202.14
Speaker: SPEAKER_05
Transcript:  Yes, they don't, there's no classification here,  which is, I think, fairly important.  How many of these were in violation  of the SEC orders, for instance?  Ooh, yeah, that's good.

Start time: 3202.38
End time: 3206.17
Speaker: SPEAKER_00
Transcript:  Right, that would be, exactly.  How many of these have been the subject of a lawsuit?

Start time: 3207.20
End time: 3257.89
Speaker: SPEAKER_05
Transcript:  I just, I mention this only because people get mad at me  if I don't mention Elon Musk in every single.  Really?  No, they get mad at me  because I mention Elon Musk in every single, to be honest.  This is, okay, I'm glad, Mike Helgen,  that you are gonna be the conscience of this show  and tell me, you know, this is bad journalism or whatever.  Google allowed a sanction ad company  to harvest user data for months.  In fact, it wasn't until ProPublica told them  that they were selling information back to RU Target  that Google stopped.  As recently as June 23rd,  Google was sharing potentially sensitive user data  with a sanctioned Russian ad tech company  owned by Russia's largest state bank, RU Target.  RU Target is the name of the.  RU Target, yeah.

Start time: 3258.72
End time: 3259.60
Speaker: SPEAKER_04
Transcript:  RU Target, RU Target.

Start time: 3259.92
End time: 3284.58
Speaker: SPEAKER_05
Transcript:  I was saying RU just because RU sounds like  it might be Toys R Us or something.  It sounds like a kangaroo.  RU Target, we are big fans of RuPaul.  We love RuPaul.  It's RuPaul's targeting agency.  RuPaul's favorite show.  Yes, he's great, yes.  In Soviet Union, dress wears you.  Russian company that helps brands and agencies  buy digital ads to access and store data  about people browsing websites and apps in Ukraine  as well as other parts of the world.

Start time: 3284.88
End time: 3318.79
Speaker: SPEAKER_04
Transcript:  They were able to see location data for Ukrainians  and some other information of what Ukrainians were doing,  but I really doubt.  Google didn't know.  Government is organized enough.  And yeah, Google didn't know.  This is the real problem.  The problem isn't that Google is deliberately  violating sanctions or is pro-Russia or anything like that.  The problem is that these ad networks, including Google's,  they don't really control what goes through.  They have policies and so on, but they don't know.  The scale of advertising online is just mind blowing.  And no one's really in charge of this.  They don't really track it close enough.  It's all automated, yeah.

Start time: 3319.36
End time: 3408.50
Speaker: SPEAKER_05
Transcript:  In fact, ProPublica last week did a story  that for roughly two decades Google has boasted  it does not accept gun ads.  But according to ProPublica,  before and after the mass shootings in New York and Texas,  millions of ads from some of the nation's  largest firearm makers flowed through Google's ad systems  and onto websites.  Ads from gun maker Savage Arms, for example,  popped up on the site Baby Games,  amid brightly colored games for children.  And on an article, how to handle teen drama on the,  can you imagine you're reading an article,  how to handle teen drama, and there's an ad for a Glock?  Oh my God.  Glock pistol ads loaded on a recipe site list  of the 50 best vegetarian recipes.  You gotta kill that carrot before you cook it.  As well as on the quiz site PlayBuzz,  on the online Merriam-Webster dictionary,  and alongside stories in the Denver Post.  Ads for guns showed up on Britannica,  the media site Heavy,  the employer review site Glassdoor,  on Mac Roamers.  What?  On US News and World Report publishers,  Clearinghouse and Ultimate Classic Rock.  15 of the largest firearm sellers in the US,  including Daniel Defense, the company that made the AR-15,  used in Ivaldi, Texas, used Google systems,  placed ads that generated over 120 million impressions,  but Google didn't know.

Start time: 3409.80
End time: 3453.08
Speaker: SPEAKER_04
Transcript:  And that bit they did?  Well, this I think hearkens back to the conversation  we were having earlier about how AI does,  the best AI is 99% effective,  and getting that last 1% is almost impossible.  This is also true by the way of self-driving cars.  It's gonna take us forever to get to that point  where they can actually be on the road.  But in this case, first of all,  I don't know the specific facts in this case,  but it's very possible that someone  who is doing this research covers gun violence  and gun sales and that sort of thing.  And therefore, the relevance of ads  would affect that person.  Oh, they got those ads.  Yeah.  Right, because they may be covering that.  And so I don't know if that's the case.

Start time: 3453.20
End time: 3454.56
Speaker: SPEAKER_05
Transcript:  You searched for those ads, those products, yeah.

Start time: 3454.56
End time: 3482.41
Speaker: SPEAKER_04
Transcript:  They're still being served up though.  And this gets to the real problem.  They're using artificial intelligence and algorithms  to determine who sees what.  They're trying to be as customized as possible,  personalized as possible with the advertising,  and you get results like this.  So it's really a question of where,  Google thought they had a cheat code,  which is that we're not gonna hire 100,000 people  to monitor all the ads.  We'll just have software do it, and here we are.

Start time: 3483.18
End time: 3506.68
Speaker: SPEAKER_05
Transcript:  In fact, this is exactly what happened.  After visiting the websites of gun manufacturers,  for example, because he's doing the research,  a ProPublica reporter was shown ads  for tactical vests and gun accessories on baby games.  The tactical vests and gun accessories ads  appeared on the page for royal family Christmas preparation.

Start time: 3509.65
End time: 3510.42
Speaker: UNKNOWN
Transcript:  I do go hunting.

Start time: 3511.55
End time: 3524.12
Speaker: SPEAKER_05
Transcript:  I think it's hysterical.  It actually is almost makes you laugh  when you're on this page with baby games,  and there's a gun ad.  If it weren't so horrific, it would make you laugh anyway.

Start time: 3524.60
End time: 3538.39
Speaker: SPEAKER_03
Transcript:  We get, my 15-year-old and I watch a lot of YouTube together  on our Apple TV, and we get a lot of ads  for ulcerative colitis, and I'm like,  are you telling me something?  I think you're targeting, right?  Big cars, $70,000 SUVs and ulcerative colitis medicine.

Start time: 3539.86
End time: 3550.73
Speaker: SPEAKER_05
Transcript:  There's only two countries in the world,  I just learned this, where pharmaceutical companies  can sell subscription pharmaceuticals on TV,  New Zealand and the US.

Start time: 3551.36
End time: 3574.94
Speaker: SPEAKER_00
Transcript:  Right, okay, see, this is what freaks me out.  Like when I go to other countries,  and I usually don't watch TV because sometimes  I don't understand the language,  and also who watches normal television anymore,  but it used to be one of those things  I would watch local news or CNN or whatever,  and yeah, you're like the dearth of pharmaceutical ads  in other places.  How do I know what to do about my psoriasis without?

Start time: 3575.08
End time: 3575.61
Speaker: SPEAKER_05
Transcript:  Exactly.

Start time: 3576.96
End time: 3582.70
Speaker: SPEAKER_00
Transcript:  Exactly, it's like you're watching CNN or something  and it's the international version,  but they have commercials and you're like wait a minute.

Start time: 3583.18
End time: 3587.10
Speaker: SPEAKER_05
Transcript:  The news channels are the worst.  Right, it's like why do I not see insurance ads

Start time: 3587.60
End time: 3589.45
Speaker: SPEAKER_00
Transcript:  and why do I not see pharmaceutical ads?

Start time: 3590.56
End time: 3597.38
Speaker: SPEAKER_03
Transcript:  Yeah, they're not lying to me,  they're not showing me drug ads,  they're not showing me giant SUVs, what's going on here?

Start time: 3598.68
End time: 3599.83
Speaker: SPEAKER_05
Transcript:  What country am I in?

Start time: 3600.50
End time: 3606.80
Speaker: SPEAKER_00
Transcript:  But there's nudity in my spring water ads,  which is fine, right, but it's like everything else is.

Start time: 3607.70
End time: 3627.77
Speaker: SPEAKER_05
Transcript:  I'm just glad there's still cultural differences  in the world, right?  Yes.  For a long time everything was like  you're just going to America West,  but now it's good, there should be some differences, right?  I love these Subway ads and the British Tube,  I think they're just great, they're so brilliant  and literate and a lot of them have nudity  and it's like it's cool, it's fun,  you never know what you're gonna see down there.

Start time: 3628.70
End time: 3658.32
Speaker: SPEAKER_04
Transcript:  I mean I just got back from France  and it's really interesting,  they don't have pharmaceutical ads on TV in France,  and yet the rate of consumption of pharmaceutical drugs  in France is very, very high.  Oh, interesting.  I don't know if it's the size of the US,  might be higher than the US, I don't know,  but it's very, very high and it's not,  so these, I don't know, I mean basically obviously  the pharmaceutical companies want the patient  to go in and start needling the doctor about how they need.  Doctors must hate that, right?

Start time: 3658.86
End time: 3668.09
Speaker: SPEAKER_05
Transcript:  They must.  Hey doc, I need Sky Resi,  but you only have athlete's feet.  No, but I saw it on TV.  It must drive doctors crazy.

Start time: 3668.64
End time: 3680.78
Speaker: SPEAKER_00
Transcript:  I think it depends, because some doctors,  not all of them, but some are,  Well, not only that, but they get kickbacks  from the pharmaceutical companies,  that's an actual thing.  Well, I've got samples, why don't you try this Oxy,

Start time: 3680.88
End time: 3681.60
Speaker: SPEAKER_05
Transcript:  see if it helps.

Start time: 3682.02
End time: 3697.02
Speaker: SPEAKER_00
Transcript:  I was gonna say, the doctors, not all of them again,  but plenty of them, if they're really pushing  a certain brand name and not wanting you  to try anything else, there's a chance  that you're getting some sort of kickback  from that pharmaceutical company.

Start time: 3697.48
End time: 3707.01
Speaker: SPEAKER_05
Transcript:  Did you, in this study, Mike, did it say what drugs,  the French, what pharmaceuticals the French favor  with their galois and strong coffee?  Is there something?

Start time: 3707.32
End time: 3724.28
Speaker: SPEAKER_04
Transcript:  It's something I read a couple years ago.  Oh, okay.  I was surprised by it because it just doesn't,  it didn't make sense in terms of how nice France is,  why would you need to be on drugs?  But the French don't think it's nice.  They're pissed off at all times.

Start time: 3725.98
End time: 3763.00
Speaker: SPEAKER_03
Transcript:  I should point out ProPublica,  since we're only setting ProPublica stories today,  since they're so good.  They have a site called Dollars for Docs.  If you go there, the data is from, I think 2014 to 2018.  You can look up your doctor and see  if they got money from the department.  But you can also go to openpaymentsdata.cms.gov,  which is a US government run site that lets you search,  it's not quite as good as the slice and dice of ProPublica,  but it's a government site.  And you can see data goes through December 2021 so far,  and they're gonna update it, I guess, shortly.  And you can say, like, type in your doctor,  are they getting money from pharmaceutical companies?

Start time: 3763.28
End time: 3764.64
Speaker: SPEAKER_05
Transcript:  Does this have to be disclosed?

Start time: 3764.72
End time: 3781.88
Speaker: SPEAKER_03
Transcript:  Is that why?  Yeah, there's a law passed, I think it was part of,  I wanna say it was part of the ACA,  it was mandatory disclosure of pharmaceutical payments.  Fantastic.  But people, most people don't know it.  So ProPublica made a good site about it,  but this cms.gov site actually is pretty good too,  openpaymentsdata.cms.gov.

Start time: 3782.00
End time: 3790.15
Speaker: SPEAKER_05
Transcript:  Yeah, in fact, ProPublica says,  we just have a snapshot from 2019,  if you wanna see it up to date,  go to openpaymentsdata.cms.gov.  One of those weird things, you're like,

Start time: 3790.86
End time: 3791.77
Speaker: SPEAKER_03
Transcript:  wait, is it really that?

Start time: 3792.68
End time: 3796.61
Speaker: SPEAKER_05
Transcript:  See, we complain about the government,  but they do some good things.  That's right.

Start time: 3797.78
End time: 3800.88
Speaker: SPEAKER_03
Transcript:  Occasionally.  Oh, nobody's looking?  Well, that's the problem,

Start time: 3800.96
End time: 3802.68
Speaker: SPEAKER_05
Transcript:  we don't know about this place, it's amazing.

Start time: 3802.76
End time: 3849.00
Speaker: SPEAKER_03
Transcript:  There's always the meta story on this episode,  I feel like it's, I feel like it's,  there's the problems that are cited,  and then it's this, it's always,  it's really congressional dysfunction.  A lack of a law in this place, it's really,  and it's like, it just keeps going on,  where I'm thinking, it's totally true,  the, maybe we'll talk about the location history stuff,  and you're like, well, the problem is  that Google tracks our location,  not, I mean, it's also a problem  what they're doing with it, but it's a fundamental issue,  fundamental issue that, you know,  that Google, that Section 23, 2330 is a,  seems like a fundamental right  and people's misunderstanding is a dysfunction  at a larger scale.  A lot of tech feels like it's large scale dysfunction  being refracted into these very specific things  that we talk about, so I like that we're jumping up there.

Start time: 3849.12
End time: 3862.38
Speaker: SPEAKER_05
Transcript:  So this is a new thing, Google says,  not only abortion clinics, but it'll delete visits  to domestic violence shelters, weight loss clinics,  and other potentially sensitive locations  from users' location histories in the coming weeks.

Start time: 3863.12
End time: 3867.72
Speaker: SPEAKER_03
Transcript:  Should it track, I mean, location tracking is-  It tracks everything, I don't think it says,

Start time: 3868.14
End time: 3872.16
Speaker: SPEAKER_05
Transcript:  oh, hey, good, I see you went to a weight loss clinic,  it's just part of the, all the tracking.

Start time: 3872.16
End time: 3940.83
Speaker: SPEAKER_03
Transcript:  It's true, but does it, this is that,  I mean, this is kind of always the Apple lens  versus the non-Apple lens, and not that Apple  has been perfect about this, as we've seen many times  in the last decade, but, you know,  we just got a new thermostat in our house,  got a smart thermostat and a heat pump, very exciting.  And I had to have a long conversation with my wife  about what Apple does with HomeKit data  because she is the, what I want to call the early rector,  and rightly so in our household.  She does not want more tech in the house,  and I try not to be the early, no, no, it's great,  here's why it's great, but like, you know,  Google, I think, makes very free internal use  of location data, and Apple, Apple is a feature  called significant locations that you can see  in iOS and iPad OS, and it tracks where you go frequently,  but the data is only stored on your devices,  it's derived locally, and it's end-to-end encrypted  when it's synced among your devices.  So, extensively, someone has to get a government agency  or other law enforcement or a criminal  has to gain access to your phone, be able to, you know,  unlock the phone and then be able to drill down  to see that information, and that to me is the level  of protection I want on my personal location data,  not it's uploaded to the cloud  and Google can see it's a nice new cell.

Start time: 3941.40
End time: 3946.21
Speaker: SPEAKER_05
Transcript:  I mean, that's good, it's an accident of history  that Apple is not selling ads against that data.  It's not, yeah.

Start time: 3947.54
End time: 3948.29
Speaker: SPEAKER_00
Transcript:  100%, if IAD had worked, they-

Start time: 3950.16
End time: 3955.76
Speaker: SPEAKER_05
Transcript:  Right, they wanted to.  Definitely, yeah.  They're making a virtue out of a necessity, which is good.

Start time: 3955.90
End time: 3972.19
Speaker: SPEAKER_03
Transcript:  Absolutely, absolutely, I appreciate that that was  the historical accident happened,  and so I don't try to defend them as, I mean,  they want to use it as a marketing point and it's great,  but I want to see it as a technical and privacy issue.  It's like I do have an alternative.  I can pick a service where I don't think  this is going to be misused.

Start time: 3972.64
End time: 3990.59
Speaker: SPEAKER_05
Transcript:  I am going to bring up this subject in a minute  because there is a story that does relate to this,  but we're going to take a break.  Glenn Fleischman is here, it's great to have him  from Glenn.Fun.  You read his stuff every, what is,  is there one publication that would be the place to mention  or is it just everywhere?

Start time: 3991.20
End time: 4018.96
Speaker: SPEAKER_03
Transcript:  I've kind of focused on Macworld.  I'd write the Mac911 column there.  Oh, that's right, yeah, yeah.  Books for take control books.  I don't put those out of the week, but-  Did you take over from Chris on the Mac911?  Chris Breen, and it's been,  I've lost track seven or eight years now.  I've written like 1,500 columns,  but he wrote thousands before me.  Yeah, he did it for years.  I still get email, dear Chris,  I know you can help me with this problem.  Sorry, he went to go to that grapefruit company  in a different part of the world.

Start time: 4019.08
End time: 4020.39
Speaker: SPEAKER_05
Transcript:  Chris, is he working at Apple?

Start time: 4021.04
End time: 4063.38
Speaker: SPEAKER_03
Transcript:  He's, there are many former,  the largest percentage of ex Macworld staffers,  I've heard of a staffer, are working at a fruit company.  It's amazing.  Shocking.  And great for them, it's great.  Some of the best people at Macworld,  some have formed their own groups like Jason Snell,  regular guest on this show, has six colors,  Dan Moran works with them there.  Some folks have left the Mac writing field  and everybody else just about went to work at Apple.  And so they're doing great.  You can see Serenity Caldwell is the face of WWDC.  It's amazing.  And I'm so sorry we can't see her doing  like the tech stuff she used to,  because she's internal, but boy, it's so fun every year.  It's like, oh my gosh, it's Serenity,  and she's the voice of WWDC.

Start time: 4063.72
End time: 4078.88
Speaker: SPEAKER_05
Transcript:  It does, though, speak a little bit  to the kind of enmeshment of Apple Press  and Apple corporate.  I mean, you certainly don't want to see a revolving door  where they join Apple and they come back out  and they start writing for Macworld again  and stuff like that.

Start time: 4078.88
End time: 4118.38
Speaker: SPEAKER_03
Transcript:  Apple almost never hired Mac writers,  it seemed like, for a long time.  And then when there was the great blood,  I mean, you know better than anybody, Christina,  because you were in that field for long,  I mean, I've never had a staff job,  but it seemed like when there was the great bloodletting  in the tech press world, Apple sucked in.  I mean, Google brought in some great ex-New York Times  people who went into Google editorial.  Quentin Hardy, for instance, is at Google Clouds  editorial director, one of my favorite reporters,  great person, and I don't know what he does there,  but their editorial is good, I guess.  So anyway, I think the big tech companies,  they wasn't revolving doors,  it was kind of a lifeboat for a lot of people.  It's like, all right, you know this stuff.  We need editorial people, suddenly.

Start time: 4118.44
End time: 4137.04
Speaker: SPEAKER_05
Transcript:  I wonder, though, because Google and Apple  both have kind of hired a lot of content people.  Nathan Oliver S. Giles, who worked for,  was an employee of us, got hired away by Apple.  But they kind of disappear at Apple.  I mean, what is Apple?  What is Apple's content business?  It's not Apple News.  Are there, what is it?

Start time: 4137.36
End time: 4181.29
Speaker: SPEAKER_03
Transcript:  There's so much, I mean, I have a little bit,  I don't want to peek any kimono that I'm not allowed to,  but they have wonderful writing on, say,  support.apple.com.  For instance, the App Store, the Mac App Store,  and the iOS and iPad App Store,  iPad OS App Store have terrific writing,  and they have these articles that show up.  Oh, that's interesting.  So that's where the content is.  Yeah, and when somebody's writing scripts for podcasts,  somebody, I mean, I know it's the marketing department  is writing the keynote stuff,  but there's a lot of places in which expert people  are writing this kind of great gap  between almost a service journalism and how-to stuff.  And Apple has a lot of, you know,  a million pages of that is being written by a lot of people.  That's a good point.

Start time: 4181.62
End time: 4186.50
Speaker: SPEAKER_05
Transcript:  A lot of Apple support documents  really are service journalism.  Yeah, can you say, I'll find something,

Start time: 4186.52
End time: 4192.42
Speaker: SPEAKER_03
Transcript:  and I'll be like, I wonder if there's someone  that could write about an area I found.  I'm like, no, I better not.  I'll just mark feedback on the page.  Yeah.

Start time: 4193.32
End time: 4221.05
Speaker: SPEAKER_05
Transcript:  I have a good friend who wrote,  was a speechwriter for Jean-Louis Gasset for years.  And I mean, they hire very good,  talented people to do their writing.  They can afford to.  Turns out good writers come cheap.  And...  Thank you, man.  Yeah.  But at the same time, you know,  I feel like there should be this impenetrable wall  between people doing editorial content about a company  and the company itself.

Start time: 4221.94
End time: 4226.38
Speaker: SPEAKER_03
Transcript:  Absolutely.  Well, it's kind of become one way though,  is because there's been so many layoffs  and so many ridiculous things.

Start time: 4226.40
End time: 4228.26
Speaker: SPEAKER_05
Transcript:  Yeah, I guess if you're out of work,  you gotta take a job.

Start time: 4228.44
End time: 4231.55
Speaker: SPEAKER_03
Transcript:  Yeah, and I don't know anybody  who's come back from the tech.

Start time: 4232.64
End time: 4241.92
Speaker: SPEAKER_00
Transcript:  I know a couple people who have, but it's very rare.  Yeah.  And, you know, I mean, you can certainly do it.  And I think, like, because I sometimes think about,  and people have even approached me about things,

Start time: 4242.36
End time: 4249.28
Speaker: SPEAKER_05
Transcript:  Yeah, when you went to Microsoft,  you were leaving a career as a journalist.  Yeah.  Was that a hard, was that a challenge for you?

Start time: 4249.88
End time: 4288.32
Speaker: SPEAKER_00
Transcript:  Yeah, I mean, it was.  I mean, in my mind, I did have the question.  I was like, well, am I still going to be able  to have my own opinions and my own autonomy?  And I will say, my role is a little bit different.  Like, I work directly with product and engineering people.  I don't work in comms.  I don't work in marketing.  And so it's a little bit different  than how the transition usually goes,  which is someone writing the internal press releases  or doing the press outreach or things  that would be easy for me to do, frankly,  but not intellectually interesting.  So it was a little bit different.  But yeah, I did definitely have that question.  Like, what will I be giving up?  Could I come back and could I come to tech objectively again?  I think that's the way it is.  Well, and for a long time,

Start time: 4288.36
End time: 4293.80
Speaker: SPEAKER_05
Transcript:  we actually did not have you on our shows,  but I missed you.  Yeah, and I appreciate that.

Start time: 4293.94
End time: 4297.46
Speaker: SPEAKER_00
Transcript:  And I was glad to be able to, I got permission.

Start time: 4297.74
End time: 4307.02
Speaker: SPEAKER_05
Transcript:  You weren't really exactly in marketing.  I mean, you were in dev relations, so always.  So I felt like we have a lot of people  who do developer relations for companies on the show.

Start time: 4307.06
End time: 4334.04
Speaker: SPEAKER_00
Transcript:  Exactly, exactly.  I mean, again, like I said,  what I do, it's a little bit different  than some other things.  And also I've been lucky to work at places  that have much more open policies  in terms of how active you can be on social media  and whatnot.  And my bosses have recognized,  and I'm very thankful for this,  that it is good when I can be myself  and not having to parrot a corporate line, right?  Like it's good for everyone.  That for me was part of the judgment.

Start time: 4334.16
End time: 4340.96
Speaker: SPEAKER_05
Transcript:  Can I expect Christina to be a Christina bot  or the real thing?  And you've always been the real thing.  So there was never a question.

Start time: 4341.26
End time: 4385.69
Speaker: SPEAKER_00
Transcript:  Yeah, no, I mean, and I think that that was a big thing  for me too when I made the decision to join Microsoft.  Like I'll be candid, I would never say never to any company,  but if I was going to take a job someplace  where I was not allowed to still maintain my own brand,  my own identity.  Well, and you had to relocate, you had to do.  Exactly, exactly.  It was, and so for me, it was one of those things  where I said, if I'm going to do this,  then I still need to be able to have  that external presence too.  And if a company had said, you can't do this,  and I talked to some who definitely had  that kind of philosophy,  look, I'll never say never to anything  and there's always a price,  but the price is probably gonna be a couple multiples  of what you would agree to pay me  if I'm going to give up all the other aspects  of what I've built for my career.  But I know that's also not the same for everyone.

Start time: 4386.92
End time: 4448.68
Speaker: SPEAKER_04
Transcript:  The big picture is that, as Andreessen says,  software is eating the world.  And so I have a kind of a unique perspective  because, and so does Glenn,  during the decade of the 90s,  the press had massive power and tons of money  and the tech industry had a lot less, relatively speaking.  I mean, we-  Oh, a PC magazine could make or break a company like that.  Windows magazine, which I worked for,  PC computing, Macworld, et cetera,  they had so much power because, first of all,  we were still kind of a gatekeeper.  There wasn't a global internet,  people, amateurs working for free to create great content.  And secondly, the companies were much smaller.  If you look over time,  you see the world of journalism in terms of business  just shrinking, shrinking, shrinking,  and a company like Apple just growing, growing, growing,  and now Apple's the most gigantic company  in the history of mankind.  And the publications are laying people off every few years.  So-

Start time: 4449.44
End time: 4455.92
Speaker: SPEAKER_05
Transcript:  I hadn't really thought of that.  That makes a lot of sense,  that there was a need for these jobs.  So thank goodness these companies stepped up.  Yeah, yeah.

Start time: 4455.96
End time: 4463.47
Speaker: SPEAKER_04
Transcript:  So if you're gonna explain things to people,  it's not gonna be,  you make a much better living working for Apple  than you do trying to scrape it out on your own  as a journalist.

Start time: 4463.80
End time: 4475.90
Speaker: SPEAKER_05
Transcript:  Speaking of which,  one of our favorite contributors on the show,  Wesley Faulkner, has a new job.  He is now Senior Community Manager at Amazon Web Services.  So congratulations, Wesley.  I think that's really, really good.

Start time: 4476.84
End time: 4517.76
Speaker: SPEAKER_03
Transcript:  Nice.  I brought up Lex Friedman.  Lex Friedman's one of the people who's been selling ads  in the podcasting world for longer than anybody else.  And I joke with him.  Yeah, he pioneered it basically.  Oh yeah, he was one of the first.  He joined EarWolf early on,  but he was a Macworld writer.  That was kind of his dream job.  And then he found out he was really good  at selling podcast ads.  Now he was acquired by his latest firm.  He was acquired by Amazon,  I think it was last year now.  So he's an Amazon employee.  After going from Macworld to Stitcher and McClatchy  and this whole series of acquisitions,  he's at Amazon.  So everybody who worked at Macworld  is at some interesting company.  That's really fascinating.  Or is Jason Snow?  Or is Jason Snow?

Start time: 4519.39
End time: 4523.03
Speaker: SPEAKER_05
Transcript:  It was always Jason Snow.  Whatever happened to Jason Snow?  I don't know.  I just...

Start time: 4524.30
End time: 4529.23
Speaker: SPEAKER_00
Transcript:  I wish I could see him or hear him on podcasts occasionally.  Yeah, if he would just do a podcast.

Start time: 4529.98
End time: 4863.69
Speaker: SPEAKER_05
Transcript:  I don't know.  He's very shy.  Yeah, yeah.  Actually we have some news about Jason Snow,  but that will come at a later date.  Let me, now that I've teased you, talk about,  do any of you use Zapier?  I'm such a Zapier fan,  a sponsor for this segment of This Week in Tech.  I do, yeah.  Yeah, it's so great.  We use it as part of our big workflow.  So whenever I bookmark a story  in a variety of places,  I have a Zapier script that will automatically  post it to Twitter, post it to a couple places,  but then also put it,  you know, post it on our social mastodon instance,  but then also put it in a spreadsheet,  Google spreadsheet for our producers  so they can quickly import it into our show rundowns.  That's just one of many things you can do with Zapier.  I want to point especially to people in business.  If you're trying to grow a business,  and you know how many hats you wear,  how many things you do,  wouldn't it be nice to eliminate  the routine operation tasks at your time?  Still get them done, but have them done automatically.  Things like lead management, employee onboarding,  customer support.  Zapier does that.  And you're not coding, but it's kind of like coding.  It's actually makes it,  this is one of the things about being a coder.  You know that if you would just take a little time,  you could get this thing done automatically,  and you never have to spend a minute doing it again.  But it's sometimes easier just to keep doing it  over and over and over again.  That's why Zapier is so great.  It makes it easy to connect all your apps,  automate routine tasks, streamline your processes,  do the things a computer is really good at doing.  It doesn't make mistakes.  It does it the same way every single time.  It does it automatically.  It does it without you thinking about it.  It frees you up to do the things you're good at.  You know, to use your big brain,  to prioritize customer and client needs,  to make your business succeed.  It's the power of automation possible for everyone.  You don't have to be a coder.  I use Zapier, love Zapier,  and I'm always thinking of new ways to use Zapier.  It makes it easy for anyone  to get started with business automation,  no coding necessary.  And Zapier has the biggest collection of apps.  4,000 of the most popular apps businesses use every day.  So I mentioned Google Sheets, for instance,  Twitter, Google Sheets, RSS feeds,  QuickBooks, Facebook, Google Ads.  Imagine you have a whole process  that automatically buys some Google Ads  every time you announce something like this and that.  You can automate just about any workflow imaginable.  And by the way, you're not on your own.  They have thousands of templates to get you started,  to give you ideas, to show you what to do.  The average user, Zapier sends me an email every week  saying how much time I spent.  The average user saves over $10,000  in recovered time every year.  Getting a Zapier subscription would probably be the best thing,  the best money saver you could imagine.  No wonder 1.8 million people and businesses, including me,  use Zapier to streamline their work  and find more time for what matters most.  We use it like crazy at Twitch.  See for yourself why Teams at Airtable,  Dropbox and HubSpot and Zendesk  and thousands of other companies use Zapier every day  to automate business.  And if you're just home automation,  if you're doing stuff around the house,  it's really fun to use Zapier.  I have the lights dim at sunrise.  I mean, it's just so many things you can do with Zapier.  Try it for free today at zapier.com slash twit.  Yeah, free trial.  Zapier, Z-A-P-I-E-R dot com slash twit.  It'll be amazing.  You won't believe the things you can do with Zapier.  Thank you, Zapier for supporting Twitch.  Thank you for supporting us by using that address.  Zapier.com slash twit.  This is a story I zapped this morning over to my pin board.  I found this interesting.  There was one line in it that was particularly interesting.  You probably saw this in the news.  The Department of Justice seized phones  from two attorneys involved in the January 6th probe.  John Eastman, the Trump campaign legal advisor,  Jeffrey Clark, the former Justice Department official  who was supposed to become attorney general.  But this is where I found it interesting.  There were iPhones.  John Eastman claimed he left a restaurant on June 22nd  and federal agents confronted him,  took his iPhone 12 Pro,  then served him with a warrant,  and then quote, he was forced to provide biometric data  to unlock the phone.  Now that stopped me right there in my tracks.  I thought that was very interesting.  First of all, the federal agents knew enough  to not give him a moment to react.  Take the phone first before you give him the warrant.  And then, it's an iPhone 12,  so I think what they probably did is say,  hey John, look here.  Yeah.  Is this your phone?  And then it unlocked,  and then they probably had a Celebrite tool  or something similar, plugged it in,  sucked all the data out of it.  Now of course they kept the phone.  It's interesting for a couple of reasons.  One, January 6th was a while ago,  like a year and a half ago.  They still think there's something on that phone  that's worth, a judge obviously did it,  wouldn't have signed the warrant.

Start time: 4864.92
End time: 4889.36
Speaker: SPEAKER_04
Transcript:  Well, before we move on,  I don't think it was, look at this, is this your phone?  Because they didn't say they tricked him into forced him.  No, I think they compelled him.  I think they forced him.  Forced.  So they, yeah, they sat on his chest  and the two people grabbed his ears.  And who knows, I mean, what does that mean, forced?  I mean, that's just, plus his language.  Remember that.  I mean, look, they probably told him,

Start time: 4889.48
End time: 4911.84
Speaker: SPEAKER_00
Transcript:  and this is my guess,  my guess is that they probably told him,  if you do not use your phone to unlock,  use your face to unlock this, we will arrest you.  This is what I'm guessing happened.  I mean, I don't know,  but I'm guessing that that's how they compelled him  to do it versus, with other biometrics,  like your fingerprint, your password rather,  like they can't force you to give them the passcode.

Start time: 4911.90
End time: 4945.30
Speaker: SPEAKER_05
Transcript:  Well, and that's where this gets really interesting.  So the Fourth Amendment, the Constitution,  protects you against unreasonable search and seizure,  and the Fifth Amendment protects you  against incriminating yourself.  This is where courts have gone, by the way,  in two different directions,  but in general, the gist is,  biometrics is not self-incrimination.  Putting your fingerprint on a fingerprint reader  or your face in the Face ID is not self-incrimination  where giving a passcode would be.

Start time: 4947.08
End time: 4951.98
Speaker: SPEAKER_03
Transcript:  This is why everyone should learn the quick presses  that you need to do if you want to lock your phone.

Start time: 4952.00
End time: 4953.28
Speaker: SPEAKER_06
Transcript:  Exactly, the double tap.

Start time: 4953.40
End time: 4963.81
Speaker: SPEAKER_05
Transcript:  John Gruber had a piece in Daring Fireball saying,  hey, by the way, just so you don't know,  here's how you can lock your phone real quick  before the Fed sees it.

Start time: 4964.50
End time: 5031.90
Speaker: SPEAKER_00
Transcript:  I mean, I did that before I was,  I do that when I go, when I'm in the airport,  like I absolutely do that, right?  Like, because I don't, and I've been doing that for years  because I don't want to be in that situation.  I will say, and I'm only being a little bit flippant here,  but it would be nice if a constitutional law scholar,  we can question many of his other things,  but it would be nice if a constitutional law scholar  would have maybe taken, would have maybe declined  to unlock his phone and actually force this issue.  Like, I'm sorry, but like Eastman  is a constitutional law scholar.  This would have been in his court.  His business, yeah, he teaches it, yeah.  To be completely candid, like putting how you feel about  his other credentials aside, I don't really care.  I don't agree with him on many things,  but it seems like this was a really missed opportunity  for what could have been a really interesting legal case  especially by someone with his credentials,  if he had just basically said,  no, I'm not going to unlock my phone.  Like, I don't know.  If it were me, I would like to think I would go to jail.  To me, I would like to say,  and I can't say this definitively,  I've not been in this situation.  I don't want to be in this situation,  but to me, I would like to think  that I would spend a night in jail.

Start time: 5032.40
End time: 5038.63
Speaker: SPEAKER_05
Transcript:  He may have felt like that would look  like incriminating behavior, I don't know.  Like he had something to hide.

Start time: 5039.34
End time: 5041.09
Speaker: SPEAKER_00
Transcript:  I have to think.  A constitutional law scholar, I don't know.

Start time: 5041.72
End time: 5057.55
Speaker: SPEAKER_05
Transcript:  I have to think a year and a half after January 6th,  if there is still something on that phone, I'd be shocked.  What could be on there?  I would think he would have,  I mean, maybe he didn't think it.  Maybe he says, I didn't do anything wrong,  so I'm not going to wipe my phone.  I'll keep all those texts.

Start time: 5058.44
End time: 5059.98
Speaker: SPEAKER_04
Transcript:  Evidence of witness intimidation?

Start time: 5060.38
End time: 5062.48
Speaker: SPEAKER_05
Transcript:  Yeah, maybe because that's recent, right?

Start time: 5063.94
End time: 5085.44
Speaker: SPEAKER_03
Transcript:  The question is, none of these people,  I mean, not these people, meaning the Trump officials,  but nobody in government and nobody above a certain age  are just about, is very clever with this data at all.  You keep hearing these cases where people,  they didn't wipe anything, they're posting pictures  with GPS coordinates, so you want the raw data  because it's often just right there.

Start time: 5085.94
End time: 5096.66
Speaker: SPEAKER_00
Transcript:  John Cooper, a week ago.  Have we learned nothing from the mafia?  I mean, genuinely.  Well, the mob, you know, I remember talking-  The mob is good about this stuff, right?  I mean, it's like, this is, I mean, usually-

Start time: 5096.68
End time: 5157.44
Speaker: SPEAKER_05
Transcript:  I remember talking to these secret service agents  many years ago who said, it's not a big deal,  they almost always give us the password.  It's like crooks, like, yeah, fine, whatever.  They're not, I don't know.  Anyway, just in case you don't know,  and by the way, again, there have been courts  that have ruled that you have to give that password.  Who was it was in jail for two years for contempt  because he didn't unlock his hard drive.  He was an accused child molester,  and he apparently thought there was something  on that drive.  He didn't want law enforcement to see,  law enforcement thought there was something  on the drive they wanted to see.  He refused to give his encryption password up,  spent some time in jail.  He's out of jail, but never did unlock that,  but he was imprisoned for not giving up the password,  and the courts at the time said,  that is not self-incrimination.  And it had something to do with whether the police knew  that information was on there or it was a phishing expedition.  Oh, I see.

Start time: 5158.32
End time: 5161.46
Speaker: SPEAKER_04
Transcript:  Either way, it's a shorter sentence for sure.

Start time: 5161.52
End time: 5162.98
Speaker: SPEAKER_05
Transcript:  Yeah, two years, much easier.

Start time: 5163.32
End time: 5164.94
Speaker: SPEAKER_04
Transcript:  Pornography on that, yeah.

Start time: 5165.46
End time: 5178.50
Speaker: SPEAKER_05
Transcript:  So the theory is, and Gruber's theory is,  what do you do?  You tap this twice, I can't even remember now.  You can make it so that it's not, yeah, I think I...

Start time: 5178.74
End time: 5181.24
Speaker: SPEAKER_00
Transcript:  Yeah, you just hit the button twice, and basically.

Start time: 5181.40
End time: 5201.03
Speaker: SPEAKER_05
Transcript:  And then it will go into a mode  where you have to enter the passcode to get in.  And the theory is now you've protected it  because the Fourth Amendment or the Fifth Amendment  prevents them from forcing you to give them the passcode,  whereas the courts have ruled it is not incriminating  to get your face ID, which is weird.  Oh, here's what it is.

Start time: 5202.08
End time: 5216.09
Speaker: SPEAKER_00
Transcript:  Here's what it is.  If you're on one of the newer phones,  you press the lower volume button  and then the side button at the same time  until you're going to feel a feedback.  Like if you've got the vibration on,  you feel a vibration feedback. So you can have it in your pocket.  This is what Gruber says.  You don't have to look at it.

Start time: 5217.60
End time: 5229.22
Speaker: SPEAKER_05
Transcript:  You just have it in your pocket.  You go, here come the federal officers.  You press the two and then it buzzes.  And now it says slide to turn off.  It doesn't matter what you do.  You're going to have to do the passcode to get back into that.

Start time: 5229.56
End time: 5236.42
Speaker: SPEAKER_00
Transcript:  Exactly.  Okay.  Exactly.  Yeah, so you have it enabled.  It's just basically these two buttons.  If you are an unindicted co-conspirator

Start time: 5236.48
End time: 5241.20
Speaker: SPEAKER_05
Transcript:  in the January 6th insurrection,  you might want to make a note of that.

Start time: 5241.60
End time: 5250.85
Speaker: SPEAKER_03
Transcript:  Or to quote the famous XKCD strip,  does someone brings up a wrench at you  and that's how you get the password?  You're dealing with criminals  or governments that don't believe in the...

Start time: 5252.14
End time: 5256.12
Speaker: SPEAKER_05
Transcript:  Well, that's true.  It's not going to work unless the rule of law is rock solid.

Start time: 5257.36
End time: 5262.53
Speaker: SPEAKER_04
Transcript:  If you were in the January 6th people,  you don't need to get their phone.  They posted the evidence.  Right.

Start time: 5263.00
End time: 5266.73
Speaker: SPEAKER_00
Transcript:  I was going to say they live-streamed it.  Like in many cases, they were literally live-streaming it.  So...

Start time: 5267.36
End time: 5314.87
Speaker: SPEAKER_05
Transcript:  They were taking videos and posting them.  Okay.  John says, never ever hand your phone to a cop  or anyone vaguely cop like the rent a cop's working  for the TSA.  If they tell you, you must refuse,  they can and will lie to you about this.  If you really need to hand it over,  they'll take it from you  and they won't get anything from it  because you've already hard locked it.  And you know, you cannot be required  to give them your passcode.  That really is kind of a,  kind of a,  you know, a little bit of a optimistic point of view.  Like they're going to have me in an airport jail  and they're, and I'm, you can't give me,  you can't require me to give you my passcode.  Well, here's a wrench.  Here's your head.  Would you like the two to have a meeting?

Start time: 5316.40
End time: 5319.96
Speaker: SPEAKER_04
Transcript:  Yeah.  And then that's when they unplug the video camera  and the interrogation.

Start time: 5320.00
End time: 5337.33
Speaker: SPEAKER_05
Transcript:  Yeah, exactly.  Somehow I, anyway, I, you know, reading this article,  that caught my eye because he said they forced me  to unlock the phone, to give them biometric information.  I thought that was very interesting.  You're right, Christina.  Here's a constitutional lawyer.  Why did he do so?

Start time: 5338.58
End time: 5360.71
Speaker: SPEAKER_03
Transcript:  Although weirdly, the warrant,  I'm looking again here at this,  this is for the CNN article here.  The warrant said that they couldn't force him  to give up biometric information.  So he's claiming they did.  Oh, that's why he's saying it.  And he did it voluntarily.  Now I get it.  So then that could be the fruit of the poisoned tree.  There you go.  Yeah.  So he knows what he's doing.

Start time: 5361.96
End time: 5363.88
Speaker: SPEAKER_05
Transcript:  He is using his constitutional mugging.

Start time: 5364.54
End time: 5374.02
Speaker: SPEAKER_04
Transcript:  Aha.  Aha.  And there may be a great deal of exaggeration.  I mean, Rudy Giuliani said he was assaulted.  I know.  This is true.  You know.

Start time: 5376.34
End time: 5407.06
Speaker: SPEAKER_03
Transcript:  I had a whole conversation,  my kids were laughing at Rudy Giuliani being hit.  And I was like, look, he's an old man.  And clearly not in good health.  He's not, it won't be.  Somebody came up and then I saw the footage.  I'm like, oh no, no, I'm sorry.  I'm sorry.  I apologize.  I didn't mean to be a hard hit.  I just don't want you to laugh at an old man being hit.  I don't agree with the song.  I'm very sorry.  No one should be touched without their permission.  I believe in the law of autonomy.  But I'm like, all right, the guy just tapped,  he just touched in the back and said scumbag.  It's all right.  So I'm sorry.

Start time: 5407.16
End time: 5419.90
Speaker: SPEAKER_05
Transcript:  Beat me up.  What do we think about crypto's crash?  Let me just check.  Yay, hooray.  Yeah, sorry.  You know what I think it has a lot to do  with how much Bitcoin you have.

Start time: 5420.26
End time: 5469.84
Speaker: SPEAKER_00
Transcript:  I was gonna say,  I think it depends on how exposed you are.  I mean, look, my Robinhood adventures  with my Dogecoin stuff,  which look, I did get my initial money out of it,  the additional stuff I put into it.  I did not.  But like, I'm so down, which is, it's hilarious to me.  But I'm not exposed.  Like, I do worry about the businesses,  like legitimate businesses and banks  and finance institutions that heavily expose themselves  to this stuff when it was going up and up and up.  Like, even if we all,  if the collective wisdom on this panel  is to be more skeptical of crypto,  if not against it,  I tend to be more on the skeptical side  rather than just anti.  I think that we can agree that having this level  of the kind of downturn is not great.  I mean, it's, there's-

Start time: 5470.20
End time: 5493.59
Speaker: SPEAKER_05
Transcript:  Well, I feel for anybody who lost the rent money on it.  I think we've been, at least in the last year or two,  pretty clear that you would be mistaken  to put Bitcoin in your 401k, let's say.  And I even, I'm pretty down on NFTs.  I feel like NFTs are absolute scams.  What were you gonna say, Glenn?

Start time: 5494.26
End time: 5498.05
Speaker: SPEAKER_03
Transcript:  Oh, it's just, when you have celebrities, I think that-  Oh yeah, Matt Damon saying,

Start time: 5498.66
End time: 5503.78
Speaker: SPEAKER_05
Transcript:  Fortune favors the brave.  Don't be a coward, buy Bitcoin.

Start time: 5504.46
End time: 5569.22
Speaker: SPEAKER_03
Transcript:  I think this was the joke before the,  the joke, quote unquote, before the Great Depression  was like when your cab driver is giving you stock tips,  you know that the market's about to fall, right?  Yeah, that's right.  Because it's not that individuals  shouldn't be invested in the broader market  because the market as a whole,  over any long period of time,  like I think it was 15 plus years,  it has a high rate of return  relative to almost every other thing  you could put your money into.  But it's when you buy individual stocks or bonds,  you invest in gold or other commodities  or something as completely speculative  as Bitcoin or Ethereum,  you're almost guaranteed to fail over the short term  even if there's a good long-term response  because you can't,  unless you have a certain amount of money,  you can't summon the resources  to stay in during the downtime.  So I mean, that's, so I feel for all the people  who were talked into it by celebrities  where they're like, oh, well, this wouldn't be on television  and Matt Damon or other people wouldn't do this  because they, you know, this isn't, I don't know,  we're not talking about,  so Dan Aykroyd and his Crystal Skull vodka or something.  Which I have a bottle of by the way.

Start time: 5569.70
End time: 5570.36
Speaker: UNKNOWN
Transcript:  Is it good?

Start time: 5570.72
End time: 5581.10
Speaker: SPEAKER_05
Transcript:  I haven't opened it, but Dan Aykroyd did autograph it  but then I smudged it because it was on glass.  So I have a bottle signed by, I'm into it.

Start time: 5582.51
End time: 5636.01
Speaker: SPEAKER_03
Transcript:  But I'm sorry, but I just mean that like, you know,  when you get retail investors being convinced  that this is an investment that can't go down  or being promised things in a way that there's a dispute,  I'm blanking out which currency right now  is frozen withdrawals.  And they had a literal FDIC inaccurate thing  that said your deposits are protected by the FDIC.  And they're not.  They're not, they weren't.  And people are posting,  and I think they're claiming  that they didn't have anything,  I don't wanna mention the name of the company  because I can't remember the name at the moment,  but the nuance was like they're claiming they never did  and people are posting pictures from chat sessions  with customer support.  They're posting pictures from our internet archive  of what they said.  So if you're an individual, how do you deal with fraud?  So I feel for all those people, the Winklevoss twins,  do I feel for them, they're probably still up like 12,000%  even if they're down 60% for the year.

Start time: 5637.36
End time: 5680.68
Speaker: SPEAKER_04
Transcript:  Yeah.  And they have a band.  And unfortunately their band is not called the Winklevi.  But I think the problem is that as you mentioned, Glen,  everything you said points to the fact  that everybody looks at it like an investment.  It's supposed to be a currency.  And this is that this sort of get the desire  to get rich quick without employing anyone,  without building anything, making anything, feeding anyone.  And with, I think most of us on this show  talking till blue in the face  about what a ultimately a dangerous, risky thing it is.  Leo, you're the best poster child  for the risks of password management.  I still have my wallet.

Start time: 5680.92
End time: 5684.41
Speaker: SPEAKER_05
Transcript:  Let me point out, I got it.  I just can't get into it.  That's all.

Start time: 5684.92
End time: 5685.88
Speaker: SPEAKER_00
Transcript:  You just can't get into it.

Start time: 5685.96
End time: 5692.91
Speaker: SPEAKER_05
Transcript:  But you were, you know, you were talking to your family.  My wallet is FDIC insured.  I want to, that's right.  You can replace it with any leather wallet you want.

Start time: 5694.00
End time: 5699.01
Speaker: SPEAKER_04
Transcript:  I mean, the fact is, is the value goes down,  people want to buy in, et cetera, may come back, may not.  Buy the dips.

Start time: 5699.60
End time: 5703.72
Speaker: SPEAKER_05
Transcript:  As long as the dips are not the bottom and not the top.

Start time: 5703.84
End time: 5713.60
Speaker: SPEAKER_03
Transcript:  I stuck some more money into my,  no, this is not financial advice,  but I stuck some more money into my IRA  when it took a big dive because I'm like,  well, this is the, you know.  Yeah, you're young yet.  I'm young yet, I got a few more years.

Start time: 5713.66
End time: 5715.46
Speaker: SPEAKER_05
Transcript:  I lost 25% on my retirement.

Start time: 5715.88
End time: 5718.12
Speaker: SPEAKER_03
Transcript:  Just hold on, hold on, Leo, it'll come back.

Start time: 5718.24
End time: 5721.15
Speaker: SPEAKER_05
Transcript:  But I mean, the truth is-  Well, it just means I have to work for another 10 years.  That's all.

Start time: 5721.68
End time: 5738.24
Speaker: SPEAKER_03
Transcript:  Oh my gosh.  Over any extended period of time,  the stock market on average.  That's right.  It performs, and it performs very well.  So it's just, do you have the wherewithal  to not go, you know, when this happens?  It's very hard.  Yeah.  And some people don't have the money to not,  you know, where they've got money.

Start time: 5738.24
End time: 5852.28
Speaker: SPEAKER_05
Transcript:  My favorite ad was the FTX ad  with Larry David on the Super Bowl.  It's, I think that's the equivalent  of a cab driver giving you a tip.  When you see these crypto companies starting to advertise  in the Super Bowl, you know we're somehow  at this peak thing.  Bubble.  Larry David as the boomer saying,  oh, the wheel is a terrible idea.  Coming up, everything's a terrible idea,  and then they ask me about a coin.  Terrible idea, and I know what I'm talking about.  I would never get-  Which was mocking people of my age  for saying, oh, crypto's no good.  And the implication is, oh, you, okay, boomer,  you just don't understand the modern world.  Well, now there's a lot of boomers going,  uh, I don't think Larry David, by the way,  was paid in Bitcoin for that commercial.  No.  It did get me interested though in FTX,  which by the way is now buying up all the failing-  All the other ones, I was gonna say.  This is a very interesting company.  Sam Bankman Fried, who founded it,  is 30 years old.  He's worth $24 billion, of course, according to Forbes.  He got out of, he was at Stanford.  His parents were professors at Stanford Law School.  He was born on the Stanford campus.  He went to MIT.  He blogged-  I love this Wikipedia post.  He blogged in 2012 about utilitarianism,  baseball, and politics.  Graduated with a degree in physics, a minor in math.  Started working at a capital firm,  Jane Street Capital in 2013.  He quit in 2017, moved to Berkeley.  Get this, where he briefly worked for the Center  for Effective Altruism, a nonprofit.  But in 2017, he founded Alameda Research,  which is a quant trading firm in crypto.  He's one of the guys who made the most money on crypto.

Start time: 5852.30
End time: 5854.57
Speaker: SPEAKER_00
Transcript:  Right, he got in right before, I guess, the peak of-

Start time: 5855.84
End time: 5857.14
Speaker: SPEAKER_05
Transcript:  Perfect timing.

Start time: 5857.56
End time: 5863.90
Speaker: SPEAKER_00
Transcript:  Yeah, because he got in before, at 2017,  when that had that peak, right?  But then it fell down, he probably reinvested,  and then he got in again.

Start time: 5864.08
End time: 5888.82
Speaker: SPEAKER_05
Transcript:  Well, he made a lot of money in arbitrage,  taking advantage of the higher price in Japan  compared to America.  So he'd buy in America, sell in Japan,  and make money that way.  He founded FTX in 2019, three years ago.  Now worth $24 billion, and is buying up  all of the failing cryptocurrency exchanges.

Start time: 5889.58
End time: 5892.42
Speaker: SPEAKER_03
Transcript:  Oh, he may make an offer for Robinhood,  is the latest newspaper work

Start time: 5892.48
End time: 5923.32
Speaker: SPEAKER_05
Transcript:  reported on that a few days ago.  And he paid, what was it, he paid pennies on the dollar  for BlockFi, which was one of our advertisers,  I should mention.  BlockFi, which was worth at one point billions,  he gave them 250 million,  loaned them $250 million to stay solvent,  and then took advantage of that.  And I saw one report that said  he bought it for $25 million.  Yeah, I saw that too.  I don't think that's, I think it's more than that,  but still, talked about pennies on the dollar.

Start time: 5923.90
End time: 5936.06
Speaker: SPEAKER_03
Transcript:  I think when I was on a few weeks ago, maybe,  but it just keeps coming back,  is I think the real underlying problem  isn't necessarily all the various currencies,  it's the stable coins, right?  It's like the false prices.

Start time: 5936.18
End time: 5944.60
Speaker: SPEAKER_05
Transcript:  Well, and Tera was the one you were thinking of,  I think that people thought it was backed by FDIC.  Tether is bleeding.  I mean, all the algorithmic

Start time: 5944.72
End time: 5954.44
Speaker: SPEAKER_03
Transcript:  and the supposedly reserve-based stable coins  are what pushed up valuation,  and we're seeing it completely unwind  as those the trust ebbs out,  and you're having bank runs.

Start time: 5954.52
End time: 5982.80
Speaker: SPEAKER_05
Transcript:  Because then you have people like Deutsche Bank,  which just said,  oh no, no, no, this Bitcoin is going to the moon.  Hold on to it.  They say the $2 trillion crypto crash  could be coming to an end.  They compare Bitcoin to the $72 billion a year  diamond industry.  You might wonder how many Bitcoin Deutsche Bank has.  I bet you they know their wallet's password.

Start time: 5983.54
End time: 5993.95
Speaker: SPEAKER_04
Transcript:  They're also getting a lot of agreement.  They're also getting a lot of agreement  from the president of El Salvador,  who just said, thanks for the cheap Bitcoins,  and he bought another $1.5 billion.  He bought more?

Start time: 5994.92
End time: 5996.39
Speaker: SPEAKER_05
Transcript:  He bought more.  Double down.

Start time: 5997.00
End time: 6000.12
Speaker: SPEAKER_03
Transcript:  I really want to see a bank in Germany  talk about hyperinflation of currency.

Start time: 6000.40
End time: 6007.24
Speaker: SPEAKER_05
Transcript:  I know, I know.  It's going to be great.  You're going to have so much money,  you'll have wheelbarrows.  It'll be amazing.

Start time: 6007.34
End time: 6012.79
Speaker: SPEAKER_03
Transcript:  Yes, you'll literally have to use wheelbarrows  to buy your zucchini or something.  Right.  Oh my God.

Start time: 6013.80
End time: 6035.70
Speaker: SPEAKER_05
Transcript:  Let's take a little break.  Lots more to talk about.  Great panel today, Glenn Fleischman.  So glad to have you, the expert in so many things,  including typography and what are they called?  Fogels? Fugels?  Flongs?  Flongs.  Those little things that have,  he's a flong master.  Get ready for this.  You collect sneakers, he collects flongs.

Start time: 6035.72
End time: 6058.00
Speaker: SPEAKER_03
Transcript:  I recently acquired hundreds of peanuts flongs.  These are printing plates from Sweden.  Where they were being used in English language,  Swedish newspaper.  And so here are peanuts comics from the 1970s  in color separations.  This is the black plate for color Sunday strips.  So I've been scanning these and then.  You're going to have some really long sports.

Start time: 6058.48
End time: 6062.26
Speaker: SPEAKER_05
Transcript:  Is the Charles Schulz foundation  going to come after you here?  I mean.

Start time: 6062.92
End time: 6109.51
Speaker: SPEAKER_03
Transcript:  It's an interesting thing.  It's an artifact.  I can certainly scan it, but I can't sell or read rights.  It's a very complicated, there must be some fair use issues.  And then here's an Ali Oop cartoon.  This is a plate that would be used  to create part of the newspaper printing process.  I just got this.  This is from the 60s.  But then here's the best thing.  It's a ridiculous thing.  It's from 1917.  Someone I know that I love flongs.  So this is again a printing plate raised to type high.  That would have been used in a newspaper.  And it's a terrible, terrible old strip.  It's a really like one of these horrible,  but it's 1917.  So no one knew how to make comic strips yet.  The punch lines are confusing.  Anyway, but it's little pieces of a comic  syndication history.  I love it.

Start time: 6110.24
End time: 6124.70
Speaker: SPEAKER_05
Transcript:  It's a museum.  Now are you actually in your office or is that a green screen?  This is no, this is really stuff.  I can pull it off.  Oh, wow.  Amazing.  Look at that.  Look at the book move.  I know I fooled you once.  It looked exactly the same.  Then he reaches back and just a green screen.

Start time: 6124.84
End time: 6127.47
Speaker: SPEAKER_03
Transcript:  I was using a bouquet photo.  It's very well done.

Start time: 6127.84
End time: 6128.19
Speaker: SPEAKER_05
Transcript:  It's beautiful.

Start time: 6128.66
End time: 6136.46
Speaker: SPEAKER_03
Transcript:  Brilliant.  This is what I'm calling the Joe Shlabatnik flong  and stereotype museum.  That's my working title.  Thank you, Joe.  Those are Snoopy fans.

Start time: 6136.84
End time: 6158.29
Speaker: SPEAKER_05
Transcript:  Nice.  I never knew that's how you pronounce it.  Shlabatnik, huh?  Maybe?  We don't know.  We don't know.  Also Mike Elgin is here.  Gastronomad.net if you want to go on these great trips.  The next one in Provence this fall.  That's right.  Amazing.  Amazing.  We went last fall to Oaxaca with you guys  and it was the best thing.  It was so much fun.

Start time: 6159.18
End time: 6164.51
Speaker: SPEAKER_04
Transcript:  We're going to be hanging out with some of the people  you met there.  So telling me, said hi.  Please do.  Please do.

Start time: 6165.20
End time: 6175.04
Speaker: SPEAKER_05
Transcript:  I follow Julia and Charlie on Instagram  and I was watching all of you guys in Provence  and I thought, oh, that lavender looks good enough to eat.

Start time: 6176.06
End time: 6196.80
Speaker: SPEAKER_04
Transcript:  So much fun.  So much fun.  Yes.  And by the way, if I can do a quick plug,  the Provence experience in the fall has,  we still have an open room.  So if anybody wants to join us,  go to the website gastronomad.net,  shoot me a line and you could grab that last room.  It's going to be mind-blowingly beautiful.

Start time: 6197.69
End time: 6223.88
Speaker: SPEAKER_05
Transcript:  And you'll be amongst friends  because there are many twit listeners in the groups.  It's just by coincidence somehow, magically,  it just happens.  Yeah, it's a lot of fun.  Well, there's Julia herself with a baby goat.  How cute is that?  Christina Warren also here, Film Girl.  We love Christina.  It's great to have you and your sneakers on the show.  And your travels are done now for a while?  Or are you going to?

Start time: 6225.14
End time: 6233.85
Speaker: SPEAKER_00
Transcript:  For now, I'm not sure when my next thing will be,  but I will be traveling more obviously  as the year and next year goes on.  That's good.

Start time: 6234.30
End time: 6238.11
Speaker: SPEAKER_05
Transcript:  For GitHub, it's different.  You go to Build, you go to those events,  or is it something different now?

Start time: 6239.02
End time: 6283.16
Speaker: SPEAKER_00
Transcript:  So we have GitHub Universe.  So that is in November  and that'll be at the Moscone Center in San Francisco.  Oh, fun.  You'll be down this way.  Nice. Absolutely.  And yeah, more things, more events are happening in person  and opening up and we're just kind of figuring out.  Like our fiscal year just started this week.  And so we're figuring out where we want to be and whatnot.  And some people are going,  some people would rather stay home,  would rather be virtual.  I would rather be out.  You like to travel.  I do like to travel.  And it was really great being able to be around people again  and meet up groups and things like that.  It was really nice to be able to have that experience again  because I missed it a lot.

Start time: 6283.74
End time: 6301.08
Speaker: SPEAKER_05
Transcript:  And of course, we missed Film Girls' impromptu hotel tours.  Yes, yes.  So I'm glad you're back doing that.  Thank you.  Showing the world what it's like to be Christina Warren.  I was going to say, people shockingly,

Start time: 6301.60
End time: 6331.81
Speaker: SPEAKER_00
Transcript:  it's probably been some of the most popular content  I've ever done where for years I was doing,  this is before Reels existed on Instagram.  I might bring it to TikTok, I don't know,  but I was doing them as stories,  now I'm doing them as Reels and I might bring it to TikTok.  But I do my Christina's hotel room tours  where I just do a tour of the hotel room  that I happened to be in.  This is terrible.  I started doing it.  Yeah, people shockingly, I've had people come up to me  at like conferences and things,  people who don't really know me and like,  oh, I love your hotel tours.  Oh my God.  So funny.

Start time: 6332.58
End time: 6333.32
Speaker: SPEAKER_08
Transcript:  You just don't know.

Start time: 6334.16
End time: 6345.16
Speaker: SPEAKER_03
Transcript:  I had a friend who just took,  I took him four days to get from Virginia back to Portland.  Travel's tough right now.  Travel's terrible.  I have not been on the road, so I've missed it so far.

Start time: 6345.24
End time: 6367.32
Speaker: SPEAKER_05
Transcript:  And what's interesting,  Friday, which was the first day of the 4th of July weekend,  by the way, happy Independence Day to our American viewers.  Happy Canada Day, couple of days ago to our Canadian.  Friday, which was the beginning of the weekend,  there were more people went through the TSA lines  than they did in 2019.  It's actually gone up.  So it travels back.

Start time: 6368.08
End time: 6379.62
Speaker: SPEAKER_00
Transcript:  Travels back, but yeah, travels back,  but there are less crew members.  I was gonna say the pilots aren't, the crew members aren't,  the TSA people aren't, like it's the whole thing.  This is what happened.

Start time: 6379.68
End time: 6380.96
Speaker: SPEAKER_04
Transcript:  They're calling it Armageddon.

Start time: 6381.34
End time: 6382.35
Speaker: SPEAKER_05
Transcript:  Armageddon, baby.

Start time: 6383.04
End time: 6412.58
Speaker: SPEAKER_03
Transcript:  We have a fun situation as we got a global entry  just before literally January, 2020, the whole family,  all four of us went out to the Canadian border  and took a little vacation.  This is great.  It's January, 2020.  We have this wonderful trip plan this summer.  So much travel ahead of us, we thought to ourselves.  But global entry, once you're in it,  you have to go back up there  when your passport changes and all this stuff.  So we can't use it now when we start traveling again  without going back to this small town near Canada.

Start time: 6412.64
End time: 6417.03
Speaker: SPEAKER_05
Transcript:  You have to go to the same place that issued it?  Yes.  And you can't-  I don't know that.

Start time: 6417.62
End time: 6421.86
Speaker: SPEAKER_00
Transcript:  No, I was gonna say, I think you can just link it back  to your new passport because-

Start time: 6422.00
End time: 6423.66
Speaker: SPEAKER_03
Transcript:  Oh my God, maybe they've changed that.

Start time: 6424.02
End time: 6434.02
Speaker: SPEAKER_00
Transcript:  Yeah, I'm almost positive.  Mike would know more than me, but I'm 99% sure  that all you have to do is update your forms  on the Global Entry website to link to the new passport.

Start time: 6434.38
End time: 6435.51
Speaker: SPEAKER_03
Transcript:  No, you know what?  We have Nexus.

Start time: 6435.98
End time: 6447.54
Speaker: SPEAKER_05
Transcript:  We don't have global entry.  Oh, that's the problem.  You have the Canadian border.  Oh, that's the problem.  You have Canadian global entry.  It seems so smart.  We're so close to Canada.  There's a guy in a mountie hat.  It's a whole different thing.  It doesn't matter.  Canadian entry.  Yeah, Canadian entry.

Start time: 6447.72
End time: 6454.45
Speaker: SPEAKER_03
Transcript:  Yeah, sorry, Nexus is a great program.  No, it's better than Global Entry, except for that.  Except when the border shuts down for two years.

Start time: 6455.70
End time: 6468.11
Speaker: SPEAKER_04
Transcript:  Global Entry, though, is fantastic.  Global Entry comes straight, right?  TSA pre-check, but the use of face recognition,  I mean, we just, half the time,  we come back into the country,  we just look at the camera and they're like,  okay, thank you. I know.  Isn't that amazing?

Start time: 6468.76
End time: 6475.96
Speaker: SPEAKER_05
Transcript:  I just got Global Entry coming back from Oaxaca.  I did my interview at SFO in the middle of the night  and got my Global Entry, so.

Start time: 6476.16
End time: 6523.08
Speaker: SPEAKER_03
Transcript:  Oh, you'll appreciate this.  I went for Global Entry first.  That's why I was confused before we decided to do the Nexus  about six months later.  And the guy said, oh, so you're,  he just asked me these, you know, a few questions.  It was going really well.  It's, you know, these are very brief interviews, right?  And he said, he said, oh, I see you're a writer.  What kind of stuff do you write?  I'm like, oh, and I just list off a few things.  I'm just like trying to not set off any red flags.  He says, oh, sounds like you're pretty smart.  You should go on Jeopardy.  I'm like, well, I was on Jeopardy.  Oh, matter of fact.  Then he couldn't believe me,  so I had him Google to find a picture of me  with Alex Trebek.  And then he starts telling me about his own memory.  And I'm like, oh my God, you should be on Jeopardy.  You need this CB, you know, Customs Border.  I'm like, he's like, well, if I read a sports trivia book,  I memorize the whole thing.  I'm like, you need to be on the show, go audition.  So I hope I talked him into it.  I don't know if he ever did.

Start time: 6523.08
End time: 6737.08
Speaker: SPEAKER_05
Transcript:  You're having a much better experience  with Canadian Border Guards than I had.  So in fact, than anybody I've ever met has.  So congratulations, you've made some friends.  That's good.  Our show today brought to you by We Use Text Messages.  Everybody uses text messages.  Podium is the ultimate text messaging platform  for small businesses.  I think this is something we learned actually  in the past couple of years.  It's been tough.  I'm not gonna, you know, candy coat it  from supply chain issues, overwhelming demand.  On top of everything else that business owners  have to manage, you know, hard to find employees.  But the businesses who thrive in adversity like this  are the ones who are forward thinking,  who use new technologies.  Podium helps your small business stay ahead of the curve  with modern messaging tools that make it easy  for your customers to connect with your business.  You've probably already been through this cycle.  You know, first you had to have an answering machine  on the business lines so people could leave a message.  And then, you know, you had to have a website.  Then you had to have, you know, a Facebook account  and an Instagram account, and it moves all the time.  Well, let me tell you something.  We have learned during the pandemic,  people love text messaging.  I mean, how many times have we used text messages  to let us know our food delivery is on the way?  To order food.  A lot of people, I'm one of them,  don't like to call a business,  whether it's a plumber, a landscaper.  I don't like phone tag.  I don't like to leave long messages.  Text is so much easier.  So if you're running in a business  and the only way to get in touch with you  is a phone number, you're kind of like, you know,  before you had a website, right?  Podium gives businesses the tools to compete  with the convenience offered  by bigger businesses like Amazon.  It takes your small business and makes it a big business,  at least from the customer's point of view.  From healthcare providers to plumbers,  over 100,000 businesses are texting  with customers through Podium.  And while customers love the convenience,  businesses love the results.  Like the car dealer who sold a $50,000 truck  and just four text messages.  Hey, I've got a truck, you're interested?  A jeweler sold a $5,000 ring,  coordinated curbside pickup, all through texts.  There was a dentist.  He had a lot of outstanding bills.  People hadn't been paying him.  Turned out it worked really well  to do his collections through text.  70% of the outstanding invoices were paid in just two weeks.  With Podium's all-in-one inbox,  your employees will love it too.  You can do more than just chat.  You can get online reviews.  You say, hey, thanks for visiting our business.  Would you like to leave a review on Yelp or Google  or wherever you like those reviews?  You just send the link.  People are much more likely to respond.  Click the link, leave the review.  Great way to collect payments fast  from anywhere to send marketing campaigns  that actually get a response.  You know, on average, text messages get read  something like 93% of the time.  The open rate is so high in text messages  compared to any other way of contacting customers.  Just send a quick text.  It really works.  Customers love it, your business will thrive.  See how Podium can grow your business.  We've got a demo for you.  Podium, P-O-D-I-U-M.com slash twit.  Take a look, podium.com slash twit.  Podium, the better way to grow your local business.  Let's grow with Podium.  Thank you Podium for your support, by the way,  of this week in tech.  What about, actually now that I'm with some people  who use Instagram,  is it me or does Instagram looking more and more like TikTok?

Start time: 6738.40
End time: 6740.65
Speaker: SPEAKER_06
Transcript:  It is not just you.  There's a little TikTok envy.

Start time: 6741.32
End time: 6754.64
Speaker: SPEAKER_05
Transcript:  In fact, they've announced now that everything's,  all video you post is gonna be a real, right?  Is this a good strategy?  It makes me feel like it's a, like they're,  they're copying and they're not, I don't like it.  Again.

Start time: 6756.02
End time: 6756.62
Speaker: SPEAKER_00
Transcript:  Again, yeah.

Start time: 6756.80
End time: 6766.84
Speaker: SPEAKER_04
Transcript:  Facebook is a company with zero vision.  And what they do is they just copy  every, every, you know, remember they were copy,  they copied Snapchat wholesale, then they copied Google+.

Start time: 6767.42
End time: 6772.68
Speaker: SPEAKER_05
Transcript:  It worked with Snapchat though, right?  Snapchat, they tried to buy them, they couldn't buy them.  So they, they didn't put them out of business.

Start time: 6773.22
End time: 6830.34
Speaker: SPEAKER_00
Transcript:  No, no.  I think that I have to say,  I have to give them a little bit of credit.  I think that their implementation of stories was better  than the way Snapchat's was just because Snapchat  really was leaning into the ephemeral at that point.  And I think that the way that they did stories  and some of the things they did  to their editing experience was better.  On the flip side, I think that they are  a far worse TikTok clone than, than, you know,  like the Snapchat stories.  It's, but to Mike's point, yeah.  I mean, if you look through the history of Facebook,  I think Instagram's a little different.  Now the founders have left, but you know,  and I think that the guy who's in charge now,  I don't think he has the product vision,  but I think that, you know,  Facebook is, its history is littered with,  with examples of times when they have taken inspiration  from other, you know, companies and attempted  to release things that very rarely have worked out.  I mean, honestly, like WhatsApp and Instagram have been  two of the, I think, leading reasons why Facebook  has maintained relevance over, over the last, you know,  19 years or however long it's been around.

Start time: 6830.42
End time: 6859.52
Speaker: SPEAKER_05
Transcript:  Kevin Systrom, who was the founder of Instagram,  one of the founders of Instagram left Facebook  quite famously in a dispute over what the direction was.  They replaced him with Adam Aseri,  who was a Facebook lifer in effect.  He is not the product visionary that Systrom was  and ever since, I think, Instagram has gone downhill  and I want Instagram to succeed.  It's the only Facebook property I still use.  Same.  And it used to be a great place to share photos.

Start time: 6861.06
End time: 6885.45
Speaker: SPEAKER_04
Transcript:  Not anymore.  Well, they've actually, Facebook has actually done  one of their famous copying routines more recently  than the copying of TikTok,  which is that they've made Facebook groups  look exactly like Discord.  They made it purple, they have a sidebar on the left.  It drives me nuts.  Yep.  And you know, anything that's hot,  they just sort of steal the core elements of it  and try to get in on that.

Start time: 6885.92
End time: 6889.04
Speaker: SPEAKER_05
Transcript:  Look at this, this looks so much like Discord.  It's blatant.  Oh my God.

Start time: 6889.96
End time: 6919.12
Speaker: SPEAKER_00
Transcript:  It's blatant.  And I have to think that the,  and this is what's so weird to me,  because I have to think that the demographics  and your users for Facebook groups  and your users for Discord are completely different.  So I don't even understand what the appeal is  to make it look like Discord,  because it's not like you're gonna bring the teens  and the kids to Facebook groups.  They're not going to ever use that.  And yet the people who use and really enjoy  and get things out of Facebook groups  are going to be like, okay, why did you move this  and why does this look like this,  this thing that I'm not familiar with?  This makes no sense.

Start time: 6919.16
End time: 6926.84
Speaker: SPEAKER_05
Transcript:  It does seem misguided.  You're exactly right.  You're annoying the existing customers  and you have no hope of luring people away from Discord.

Start time: 6926.84
End time: 6944.02
Speaker: SPEAKER_00
Transcript:  You will never ever lure the other people in.  I mean, like Facebook gaming is famously tried  for years to take on Twitch.  I mean, look, YouTube gaming has tried to take on Twitch.  Nothing is going to take on Twitch, right?  Like, you know, Microsoft tried with Mixer, failed.  So I don't, yeah.

Start time: 6946.58
End time: 6969.38
Speaker: SPEAKER_05
Transcript:  I want Instagram to succeed.  I briefly moved to Glass,  which is an Instagram replacement  created by photographers, photos first.  They're trying to respond to all this stuff.  I don't know what it is.  Maybe it's not as big.  It doesn't have the social.  Whatever it is, it doesn't quite scratch that itch.  But I was an early adopter on Instagram  and I just, I thought that was a great thing.

Start time: 6969.82
End time: 7033.37
Speaker: SPEAKER_00
Transcript:  It was.  I think that what's weird too about like the,  I understand approaching, you know,  and YouTube has done this with shorts a little bit too.  I understand approaching some of the types of content  and maybe the editing tools and the length  and the format adoption of TikTok.  I see that.  And I mean, and I think that that's why  the stories appropriation worked, right?  Like I think that it was a format  rather than necessarily taking on some of the way  that Snapchat worked,  which was Snapchat was always a very personal  one-to-one thing.  Instagram's a little bit broader than that.  It's people you know, but also people that you might,  you know, wanna follow and keep up with.  TikTok was fascinating to me about it.  And this isn't universally true,  but I think this is largely true for people,  is that it is one of the few social networks  that's come out basically since Facebook,  if we wanna be honest,  where your social graph is not at all based on who you know,  it's based on, you know, things you're interested in  and things you follow, but you don't necessarily,  like on TikTok, I don't follow anyone  that I know in real life.  Like, there might be a few things.  Well, it doesn't matter.

Start time: 7033.84
End time: 7038.82
Speaker: SPEAKER_05
Transcript:  By the way, follow away.  I follow my son and I never see his TikToks.

Start time: 7039.35
End time: 7046.84
Speaker: SPEAKER_00
Transcript:  Well, this is kind of my point,  but this is sort of my point, right?  Is the way that they feed you content  and the reason why it's-  Even when I go to the following tab,

Start time: 7047.22
End time: 7051.76
Speaker: SPEAKER_05
Transcript:  he's not there and I know I'm following him  and I know he's putting them out.  I have to actually search for his name.

Start time: 7051.78
End time: 7057.50
Speaker: SPEAKER_00
Transcript:  You have to search for him  because you're not typically consuming his type of content  that he's creating.  Whereas I think that this is where-

Start time: 7057.56
End time: 7060.88
Speaker: SPEAKER_05
Transcript:  Well, if he would do more bikini rich content,  I might see more of his stuff.

Start time: 7061.00
End time: 7114.28
Speaker: SPEAKER_00
Transcript:  If he would do more bikini rich content,  or maybe he should do collabs with some people,  then maybe you'll see him on your For You page.  But until then, but again,  but this is where I think that the Facebook thing  is a little bit misguided,  or Instagram thing is a little misguided,  because look, you might also follow  the bikini models on Instagram,  but you're largely there to see people,  at least I think historically people that you know,  and to share things with people you know.  Whereas reals, the whole idea,  if they're going to make it like TikTok,  then you want to see stuff from people  that you're not connected with.  So to me, it feels like a mixed,  like a completely false experience, like set up.  Like if I want to follow people  that I don't actually have any connection with  and see short form videos about it,  that's what TikTok is for.  I don't want to suddenly be inundated with-  Completely different paradigm.  Exactly. I don't want to be inundated with that on Instagram.  And I don't think that Facebook quite understands that.  Like, again, to your point,  the product vision isn't really there.

Start time: 7114.50
End time: 7122.05
Speaker: SPEAKER_05
Transcript:  I don't know if I'm-  Here's a question.  Go ahead.  Go ahead, Liam.  Sorry.  After you had a faulty-  Delay.  Go on.

Start time: 7124.36
End time: 7155.50
Speaker: SPEAKER_04
Transcript:  Okay, I'll go.  So first of all, does Hank make you call him salt,  or do you still call him-  A salty.  I've always wondered about that.  A salty.  But here's a question,  because I normally like to crap all over TikTok  and criticize them partially.  I'm actually in love with TikTok.  But here's a question.  Does TikTok actually expand in human empathy  and understanding?  Yes.  Because there are so many videos from,  like, you know, Nairobi and like, you know,  all these bar-flung places.

Start time: 7155.58
End time: 7169.58
Speaker: SPEAKER_05
Transcript:  It does what we thought the internet was gonna do,  which was open up the world.  I think it absolutely does.  Plus, for creators, like my son,  it's an opportunity,  he couldn't have done what he's done  on any other platform.  Right.

Start time: 7170.47
End time: 7172.68
Speaker: SPEAKER_04
Transcript:  And I see-  He launched them in other platforms.  He's like on Big Time TV and stuff.

Start time: 7172.86
End time: 7195.12
Speaker: SPEAKER_05
Transcript:  Look at Megan Stalter, who's now on Hacks, on HBO.  She did her comedy.  She was a comedian, COVID, she couldn't do her bits,  so she created this crazy,  something that would have never worked anywhere but TikTok,  these crazy short form characters became huge on TikTok.  Now she's on HBO.  I think this is a really good place for creators  of a certain type, right?

Start time: 7195.54
End time: 7217.80
Speaker: SPEAKER_04
Transcript:  Right.  Yeah, absolutely.  I saw a glimpse of a show that Shakira has  where they have these people who dance on TikTok,  they're discovered on TikTok, brought onto her show.  And it's like, it's played as if,  as if the Shakira show is the big time  and TikTok is the small time.  It's the other way around.  Right, and it's really the opposite.  But it's the other way around.  They're just trying to glom onto the-  They're trying to glom onto it, exactly.

Start time: 7217.88
End time: 7251.08
Speaker: SPEAKER_05
Transcript:  My son has 2.1 million followers on TikTok.  That is more than any show I do.  He has completely eclipsed anything I've done  in 40 years in the business in a matter of months.  I don't know where else you could do that.  Now, I don't know what the successor to that is.  And I always, I'm the, I feel bad.  I'm the parent who goes, now son,  you don't pull all your eggs in one basket, you know,  and all that.  He's going, yeah, dad, right, yeah.  He literally does in some of his videos,

Start time: 7251.12
End time: 7253.01
Speaker: SPEAKER_04
Transcript:  he puts eggs in baskets.  He puts eggs in baskets.

Start time: 7253.32
End time: 7255.10
Speaker: SPEAKER_05
Transcript:  And he doesn't save any extra, yeah.

Start time: 7255.52
End time: 7261.96
Speaker: SPEAKER_03
Transcript:  If you measure it in minutes though,  I think that's minutes consumed,  given the length of your shows versus his TikToks.  Maybe it happens.

Start time: 7262.02
End time: 7286.08
Speaker: SPEAKER_05
Transcript:  Maybe.  User minutes, should I measure it?  So what, is this just me,  or is this something you guys have in your Instagram?  This is something I thought was new.  Up at the top at Instagram,  there's now a little down triangle,  and I can choose from favorites and following.  And I think this is-  Oh, that makes-  Can you do that?  Or is that my-  I can't do it on mine.  Maybe I'm in a test.  Maybe?  Maybe I'm in a test.

Start time: 7287.05
End time: 7288.24
Speaker: SPEAKER_00
Transcript:  I was gonna say, I don't have this.

Start time: 7288.74
End time: 7296.56
Speaker: SPEAKER_05
Transcript:  So I like this because I favorite the people.  Now this is just like the old Instagram.  It's just people-  Yeah, they said it was coming back.  Yeah, just people I'm following.

Start time: 7297.12
End time: 7299.64
Speaker: SPEAKER_00
Transcript:  Oh no, I do have this, sorry.  A following and then favorites.

Start time: 7299.70
End time: 7330.41
Speaker: SPEAKER_05
Transcript:  I just, I never saw it before.  I saw it a couple of weeks ago and I thought, oh.  So maybe this is their way, admittedly,  it's hidden away and who knows who has it.  But maybe this is their way of saying, well, you could,  Twitter rather.  Twitter, you can do latest tweets,  which is a chronological feed of your follow,  people you're following.  I love that.  Or you could do the home, which gives you,  and that's good too.  There are times when you wanna see stuff you might've missed.  So maybe this is a new way of doing this.  You kind of have it both ways.

Start time: 7331.08
End time: 7346.02
Speaker: SPEAKER_03
Transcript:  The sneaky thing in Instagram is that deal  where they show you things from other people you follow.  I hate that.  It just shows up and then you tap.  I don't wanna see that.  Then you close it and it says,  do you wanna snooze this for 30 days?  I was like, well, I want the never, ever do this to me.  Never, never, ever.  Every 30 days, I start seeing random things.

Start time: 7346.24
End time: 7368.67
Speaker: SPEAKER_05
Transcript:  And it's made up too.  Because you followed, because you liked,  because you watched a video by this person,  let me pause on that for two seconds.  We thought you'd like this one, is not a good system.  They're just annoying.  I'm very disappointed.  And trying to be more like TikTok,  now I think every video is a reel.  Suddenly it's reels, reels, reels.

Start time: 7370.32
End time: 7401.55
Speaker: SPEAKER_00
Transcript:  And yet they haven't even copied all the good things  from reels.  None of the good stuff.  It's like reels now don't have,  TikToks rather don't have,  the time limit is much longer  and reels are limited to 90 seconds.  And it's like, okay, what's the point then?  You're making me use this subpar version of this copycat  when I would rather consume the content  on the platform that has the admittedly scary  of the Chinese all get out,  but very, very effective algorithm.  Like, I don't know.

Start time: 7402.44
End time: 7449.95
Speaker: SPEAKER_05
Transcript:  Speaking of TikTok, I mean,  there's still some concern about the fact  that it's owned by ByteDance, a Chinese company,  that there may be Chinese employees looking at stuff.  And in fact, even though TikTok announced  that they were gonna put all the US users data  on Oracle-based servers in California,  apparently they admitted,  only carefully vetted Chinese employees  have access to the American data.  TikTok is working on a deal with the Biden administration  that would quote, fully safeguard the app in the US.  Obviously they don't look,  there's nothing the Chinese government is getting from this  that is worth what TikTok is getting  from American users, right?  But does TikTok have a choice?

Start time: 7450.62
End time: 7472.72
Speaker: SPEAKER_04
Transcript:  It's not up to ByteDance.  And one of the problems is that I really don't,  I understand the psychological satisfaction  of hosting data in a certain country,  but does hosting US user data in the US on Oracle servers  prevent ByteDance from accessing the data  that their app is generating?  I mean, I would have to see-

Start time: 7472.72
End time: 7490.97
Speaker: SPEAKER_05
Transcript:  Apparently not, because that's what they,  in their letter they wrote to nine Republican senators  that was released just Friday, they admitted,  no, certain employees can see American data,  even though it's not stored in China, they can see it.

Start time: 7491.96
End time: 7511.52
Speaker: SPEAKER_04
Transcript:  Right.  So- Pointless.  I just find it very, all of it,  there's a lot of effort to try to put fears at ease,  but it's not, at the end of the day,  ByteDance is a Chinese company.  By the way, a lot of people don't know this,  but TikTok is not, itself is banned in China.

Start time: 7512.24
End time: 7514.00
Speaker: SPEAKER_05
Transcript:  Oh really?  Oh, I didn't know that.  Yes.

Start time: 7514.76
End time: 7543.02
Speaker: SPEAKER_04
Transcript:  ByteDance has another version called something else,  I forgot what it's called,  but which is fully censored by the Chinese government,  et cetera.  But yeah, even TikTok is banned in China.  It's incredible.  But I just don't, the Chinese government will,  if it wants to, get any data from ByteDance  that ByteDance has access to,  no matter where it's stored.  So I really, it's really not about where it's stored,  it's about what access ByteDance has.

Start time: 7543.34
End time: 7555.18
Speaker: SPEAKER_05
Transcript:  But, so what?  What are they gonna get out of this  that I should be worried that the Chinese,  I'm much more worried about what Facebook knows about me  than what Chinese government knows about me.

Start time: 7555.24
End time: 7558.56
Speaker: SPEAKER_04
Transcript:  The location of US soldiers,  the movement of US soldiers.

Start time: 7558.56
End time: 7564.60
Speaker: SPEAKER_05
Transcript:  It's completely reasonable for the US Armed Forces  to prevent, forbid the use of TikTok.

Start time: 7565.12
End time: 7566.21
Speaker: SPEAKER_04
Transcript:  They can say that, but-

Start time: 7567.68
End time: 7576.55
Speaker: SPEAKER_05
Transcript:  Well, but okay, but that's their problem, not my problem.  They need to handle that problem, not me.  Why would you-

Start time: 7576.88
End time: 7612.36
Speaker: SPEAKER_04
Transcript:  What I'm saying is, there's this Project Texas thing,  which is a so-called collaboration-  Isn't that an ironic name?  Yes, it is.  And this is where the storing on Oracle service,  et cetera, comes in.  And so what I'm saying is that we need transparency  around exactly what they're doing,  because I don't really trust ByteDance  or the US government or Texas  to actually safeguard this data,  unless I know how they're doing it.  How exactly are they preventing the company  from accessing its own data?

Start time: 7612.54
End time: 7630.54
Speaker: SPEAKER_05
Transcript:  Right, but you've said this yourself, Mike.  The threat from ByteDance of TikTok  isn't so much harvesting American citizens' data,  it's slanting American citizen opinion.  It's disinformation.  It's disinformation.  That's the real risk.  This doesn't address that at all, right?

Start time: 7630.76
End time: 7676.16
Speaker: SPEAKER_03
Transcript:  There is also another issue though,  because there's a lot of,  it's not just the data may seem unimportant,  but the Chinese are monitoring hundreds of thousands  or millions of Chinese,  both Chinese Americans and Chinese citizens  living in the United States and researchers  and people doing work.  This is the whole thing years ago  when China was deemed to have broken into Gmail accounts  related to people who were writing about  or human rights advocates connected with China and so forth,  is China will use any information that they can get  that helps them understand and track  a very large swath of people.  So that is the,  so that risk comes across any data China gets access to  and TikTok gives them a lot of that for those citizens.

Start time: 7676.44
End time: 7695.00
Speaker: SPEAKER_05
Transcript:  Well, those citizens-  And non-citizens.  I hope this doesn't sound callous,  but if they don't want to be tracked,  they shouldn't be using TikTok on their phone.  Well, that's, yeah.  It's not my problem.  If you were a Chinese dissident in the United States,  you'd be nuts to use TikTok on your phone.

Start time: 7695.10
End time: 7699.96
Speaker: SPEAKER_03
Transcript:  But there's going to be a dissidence.  You can be a Chinese, I mean, you know,  there's been these orders-  Well, don't do it.  They shouldn't do it.

Start time: 7700.20
End time: 7702.69
Speaker: SPEAKER_05
Transcript:  If they're worried about it, that's their problem.  It's not my problem.

Start time: 7703.16
End time: 7732.36
Speaker: SPEAKER_00
Transcript:  Okay, it's not your problem, but I would say this,  and I think there's some fairness in that,  but I would say, okay,  the way that we know that location  and other information can be aggregated,  we know that people who are not personally  wanting to be identified with it,  how their information can also be assimilated  and put into those things.  Okay, so let's say they don't use it.  That doesn't mean that certain information about them  couldn't be inferred because of other people  who were in the data set, right?  Like, I think-  Okay, good point.  You could still be putting people at risk.

Start time: 7732.50
End time: 7736.41
Speaker: SPEAKER_05
Transcript:  So if I hung out with a group of Chinese people  and they didn't have TikTok, but I did-

Start time: 7737.04
End time: 7737.18
Speaker: SPEAKER_00
Transcript:  Right.

Start time: 7737.88
End time: 7740.77
Speaker: SPEAKER_05
Transcript:  You could be putting them at risk.  Yeah, okay.  Okay, that's fair.  All right.

Start time: 7741.32
End time: 7797.22
Speaker: SPEAKER_03
Transcript:  I don't want to overstate, but it's also,  I think the unfettered access by any government  to information about that includes stuff  that can be by location, voice, face, content,  opinion, all of these things, do we want,  even though it's publicly available,  it's not publicly available in the same degree  to which it can be accessed off servers.  The Chinese have developed enormous capabilities  to do voice and facial and other recognition on data sets  because they're using that against their own citizens.  So the risk is that the Chinese will use it,  maybe they'll use it as techniques to,  they could be using it to turn military people,  to turn people in academia.  There's just a, I don't want to make China out to be  this ridiculous international threat,  but I think they work extremely well in their own interests.  Well, I don't want to overstate it.  I think they work extremely well in their own interests.  And I'll let you say it, because I don't disagree with that.

Start time: 7797.38
End time: 7812.12
Speaker: SPEAKER_05
Transcript:  I'm more afeard of my own government than I am of China.  And if I were a woman in this country,  a young woman of breeding age in this country,  I'd be especially afeard of my own government.  I think there's a lot more at risk from that.

Start time: 7813.36
End time: 7827.34
Speaker: SPEAKER_03
Transcript:  This is fair, but we have, potentially have the ability  to affect what our government does in this country  and we can't do it with China.  And I think China is more avowedly interested in creating,  I think Russia looks to be discordant.

Start time: 7827.66
End time: 7830.28
Speaker: SPEAKER_05
Transcript:  They can't do as much harm to me though  as the Texas Attorney General can.

Start time: 7831.46
End time: 7833.38
Speaker: SPEAKER_03
Transcript:  I don't know.  Well, we can oppose them both,

Start time: 7833.48
End time: 7889.00
Speaker: SPEAKER_04
Transcript:  but the point is that one of the problems with the,  I mean, you talk about contentious political issues  in the United States, the point is they're contentious.  In China, there's no contentiousness about anything.  It's like, and Xi Jinping has proved that he wants to be,  he wants to be North Korea, but with like way more money  and a lot more people and a lot more power  and the ability to be a superpower,  which is to extend military power globally.  So they, yes, our own government is more concerned  about screwing us over,  but we can do something about it, as Glenn said,  and it's a conversation.  It's the lack of conversation, the lack of democracy  in China that makes them,  makes us as technology consumers have to think twice  about what we're consuming and who's behind it  and all that sort of thing.

Start time: 7889.02
End time: 7899.89
Speaker: SPEAKER_05
Transcript:  You wrote a good piece in Computer World last week,  sort of about this,  about this notion that it was foolish ever to think  of a global internet.  That wasn't gonna happen.

Start time: 7900.64
End time: 8036.60
Speaker: SPEAKER_04
Transcript:  That's exactly right.  And the buzzword is the splinter net,  and the splinter net just keeps splintering more and more.  The biggest, of course, the big split came  with the Great Firewall of China.  You use the internet in China.  It looks nothing like the internet we use.  They don't have access to Wikipedia, Facebook,  Twitter, Snapchat.  Tick-tock, I've just learned, yes.  Yes, and we don't have access or we don't have,  we're not really using these other things.  Meanwhile, not only is China good  at keeping their own citizens from seeing uncensored content,  they're increasingly censoring globally,  which is a big concern.  Then you had Russia kind of wanted  to have a wannabe Chinese Great Wall of China.  And, but the war in Ukraine just accelerated that massively  where you have lots and lots of people,  company, US companies are pulling out of Russia,  Russia banning all these social networks  that they used to not ban and so on.  So that they're becoming more China-like  in their disassociation.  But you have other things happening.  You have similar things.  They're essentially intranets in North Korea,  Eritrea, Ethiopia, Saudi Arabia,  and a bunch of other countries.  You have a book by somebody named Nina Zhang,  who wrote a book, Parallel Metaverses.  And her contention is the same point that I made  in a column a few months ago,  which is there's not gonna be a metaverse.  There's gonna be many, many metaverses  and they're gonna be,  some of them are gonna be very compelling  and people are gonna live within them.  You'll live in yours, I'll live in mine.  So it's another, the two biggest trends,  metaverse and web three are major splintering factors  on an already splintered splinter net.  So the metaverse is gonna be splinter people.  Web three is gonna splinter people  because they think, the vision of the web three is,  we'll just get everybody on the web three stuff,  on blockchain stuff, on distributed networks and so on.  Well, a minority of people will embrace  that version of the web  and the majority will stay on what they call web two.  So that's another splinter.  So we're being splintered every which way.  And the idea that we're all gonna go back  to an internet that we all share,  where you can't censor it, et cetera,  it's just never gonna happen.  It's just gonna get worse and worse and worse, unfortunately.  We need to bring back Gopher.

Start time: 8038.10
End time: 8067.06
Speaker: SPEAKER_05
Transcript:  That'll solve it.  Archie and Veronica.  Archie and Veronica, exactly.  Actually, her point's interesting,  but it's not just national metaverses.  We're gonna have splintering of metaverses within the US.  There'll be Facebooks, there'll be Apples,  there'll be Microsofts.  And they're, even though they've formed  this metaverse alliance,  it's not clear that there will be interoperable metaverses.  I think it's much more likely that Facebook's gonna say,  no, no, you wanna play in our space.  We've got the coolest outfits.

Start time: 8068.62
End time: 8107.72
Speaker: SPEAKER_00
Transcript:  Which is unfortunate because I think the whole reason  that the web won, right?  And the whole reason that,  versus the online networks  and the internet super highway of that motif,  I think the whole reason the web won was interoperability.  And I think that, yes, we might've been naive  to think that we could have one global internet,  but I think that the reason the internet  has been such a massive success  and that the web has had such a,  you know, like uncalculable impact on society,  global society, I should add,  has been because until recently,  with a couple of exceptions, it has been one place.

Start time: 8108.16
End time: 8159.76
Speaker: SPEAKER_05
Transcript:  You know, there's been a lot of negative about social media  and we've been talking a lot about it on our shows  and is it good, is it bad?  It's a source of disinformation.  Can it bring people together?  There's some positives, some negatives.  I thought this was really interesting.  I don't know if you watched the January 6th testimony,  the congressional testimony,  but there was a retired Republican judge, Michael Lutig,  who was, I thought, really interesting.  I remember very well his testimony  and I also remember thinking,  well, he's speaking slowly.  I wonder if he's recovering from a stroke  or something like that.  He's not, but Joe Hagan,  who's a writer for Vanity Fair and a Twitter thread,  said, I like how this guy treats every line of his testimony  like he's engraving it on a national monument.  And frankly, he really-

Start time: 8159.76
End time: 8162.04
Speaker: SPEAKER_04
Transcript:  But he's talking to the stenographer, not to the public.

Start time: 8162.16
End time: 8288.85
Speaker: SPEAKER_05
Transcript:  He really is engraving it for history  and he seems to know it,  to which Judge Lutig responded on Twitter  with a Twitter thread.  Thank you so much, Mr. Hagan.  You almost presciently understood precisely  what I was at least attempting to do  to the best of my abilities during the hearing Thursday.  He even mocked his own speech pattern.  He says, what you could not know and did not know,  but I will tell you now,  is that I believed I had an obligation  to the select committee and the country first to formulate,  dot, dot, dot, then to measure, dot, dot, dot,  and then, dot, dot, dot,  to meter out every single word that I spoke carefully,  exactingly and deliberately,  so that the words I spoke were pristine, clear,  and would be heard and therefore understood as such.  He said, I believed Thursday I had a high responsibility  and obligation to myself, even if to no other,  and please bear in mind,  it was the first time in 68 years  that I'd ever been on national television.  I wasn't scared, I wanted to do my best  and not embarrass myself.  I thought the most interesting thing was  that I decided to respond to your tweet  because I've been watching the tweets all day  suggesting that I'm recovering from a severe stroke,  and my friends, out of their concern for me and my family,  have been earnestly forwarding me these tweets,  asking me if I'm all right.  Such is, this is the thing I wanted to bring up  as germane to this program, such is social media,  I understand, but I profoundly believe  in social media's foundational,  in fact, revolutionary value  and contribution to free speech in our country.  This is a 68-year-old, pretty conservative,  right-wing Republican judge who one would expect  would say, oh, social media.  No, no, he says, for that reason,  I'm willing to willingly accept the occasional bad  that comes from social media in return  for the much more frequent good that comes from it,  at least from the vastly more responsible,  respectful speech on those media.

Start time: 8289.78
End time: 8306.26
Speaker: SPEAKER_04
Transcript:  And I totally agree with that.  Isn't that awesome?  He's absolutely right. That's amazing.  I think it's great that somebody who's 68 and conservative  is honest enough and perceptive enough  to come to that conclusion  because I think that's absolutely true,  and it would be more true for a lot more people  if more people would learn to block and report.

Start time: 8306.56
End time: 8355.31
Speaker: SPEAKER_05
Transcript:  Yeah, true.  He says, one more, let me just finish his tweet,  one more thing, and then, Glenn.  This is why 16 years after my retirement from the bench,  even then, as a very skeptical, curmudgeonly old federal judge,  I created a Facebook account and then a Twitter account,  and again, he mocks himself slowly, very slowly.  One account first, and then followed by the other.  All of this said, I am not recovering from a stroke  or any other malady, I promise.  Thankfully, I've never been as sick or so debilitated  as that ever in my life.  I would not want that from anyone, knock on wood.  So Judge Lutig is fine.  He was intentionally speaking very carefully and precisely,  and he appreciated the response on Twitter.  Amazing.  Go ahead, Glenn.

Start time: 8356.08
End time: 8402.38
Speaker: SPEAKER_03
Transcript:  Well, I have breaking news here from 1860.  That's a long story.  Live coverage in the social media of the day,  which were newspapers, which were often put out  in multiple editions a day.  I remember.  A coverage of Mr. Lincoln's speaking style.  He's rather unsteady in his gait,  and there is an involuntarily comical awkwardness  which marks his movements while speaking.  His voice, though sharp and powerful at times,  has a frequent tendency to dwindle into a shrill  and unpleasant sound.  His enunciation is slow and emphatic,  and a particular characteristic of his delivery  was a remarkable mobility of his features,  the frequent contortions of which excited the merriment,  which his words alone could not well have produced.  So there you go.  Very slow speaker.

Start time: 8402.72
End time: 8405.44
Speaker: SPEAKER_07
Transcript:  And occasionally high.  Very high-pitched voice.

Start time: 8405.44
End time: 8407.93
Speaker: SPEAKER_05
Transcript:  A little bit.  But it carried.  His voice carried.

Start time: 8408.42
End time: 8410.85
Speaker: SPEAKER_04
Transcript:  It carried.  Daniel Day-Lewis nailed it.

Start time: 8411.36
End time: 8664.41
Speaker: SPEAKER_05
Transcript:  Yes, he did, and I think it was partly based on that report.  Hey, I want to take a break.  A few more things to talk about.  We're not going to wrap it up quite yet.  I know it's been a long show,  but I can't stop talking to these guys.  Great to have Christina Warren, Glenn Fleischmann,  Mike Elgin, you guys rock.  Our show today brought to you by Blue Land.  You know, California's trying to eliminate plastic waste.  I am, in my life, trying to eliminate plastic waste.  Did you know that an estimated five billion plastic  hands-up and cleaning bottles are thrown away every year?  They end up in the landfill where they never degrade.  They never go away.  Don't believe the plastic industry  when they say they're recyclable.  They're not.  Blue Land wants to help you do the right thing,  eliminate single-use plastics.  And by the way, it's also good for the environment  because when you buy a bottle of surface cleaner,  multi-surface cleaner, window cleaner,  dishwashing soap, laundry detergent, hand soap,  when you buy those bottles, 90% of it's water.  So you're transporting all this water around  completely unnecessarily.  With Blue Land, you buy these beautiful forever bottles.  They call them Instagrammable.  They're fantastic.  This one is a multi-surface cleaner,  so it's very lightweight.  They have very solid, thick glass for the hand soap,  the liquid soap dispensers, so that they stay there.  They're very solid.  They really are beautiful.  You buy them once and you refill them.  And, but you don't refill, you use your own water.  And the active agreements are sent to you  in these little tablets.  I love this idea.  You grab one of the beautiful forever bottles,  you fill it with warm water, you drop in the tablet,  and you get cleaning.  Refills start at $2.  You don't have to buy a new plastic bottle  every time you run out.  They're perfectly made.  They're gonna last for a long time.  You can, of course, set up a subscription,  which is what I do, so you never run out  of the products you use the most.  You save even more when you buy in bulk.  From cleaning sprays, to hand soap, to toilet cleaner,  and laundry tablets, Blue Land products are made  with ingredients you feel good about.  In fact, the only thing you've got to dispose of  is your notion that green, environmentally friendly  products aren't good or are expensive.  They are effective.  They're wonderful.  We use Blue Land everywhere.  We wash our clothes with Blue Land.  We wash our dishes with Blue Land.  We wash our hands with Blue Land.  And now, by the way, and I highly recommend these,  Blue Land, they've been out of stock  for their toilet cleaning tablets.  Those are back in stock.  Stock up on those.  Those are really fantastic.  They work really well.  In fact, what I did when my daughter moved  into her new apartment, you can buy a whole kit.  I gave her a kit to get her started.  Their Clean Essentials Kit, everything you need.  Blue Land products come in wonderful scents,  although we use the unscented laundry soap.  But they do have some lovely scents.  The hand soaps are great.  I got a Christmas package.  I smell like a gingerbread house every time I wash my hands.  They have Iris, agave, fresh lemon, eucalyptus mint.  For a limited time, hand soap is getting a summer upgrade.  They've been doing this all along.  It's really fun.  We've been using this for a long time.  And I will go and get that when they have the new  kind of limited edition scents.  This summer, strawberry rhubarb, citrus patchouli,  and coconut palm.  It makes you want to wash your hands, I have to say.  We've got Blue Land everywhere in the house  you will want to.  To get 15% off your first order,  go to blueland.com slash twit.  These are products that work.  You'll love using them, and you'll feel good about them  because you know you're eliminating single use plastics.  And that's really been a goal in our house for some time now.  15% off your first order of any Blue Land product,  blueland, B-L-U-E-L-A-N-D dot com slash twit.  This is a great deal.  Take advantage of this.  And again, if you've got a wedding coming up,  a housewarming, just even a hostess gift,  this is a great gift.  People love it.  Blueland dot com slash twit.  We had a great week on twit.  I think, I wasn't here.  I was visiting Mom.  In fact, I'm going to watch with you  as we see the highlights.

Start time: 8665.12
End time: 8689.65
Speaker: SPEAKER_07
Transcript:  Taco Bell has announced a tostada on a giant Cheez-It  18 times the size of a regular Cheez-It.  Now this is important news.  The Cheez-It, tostada,  I'm never letting Jarvis host the show again.  American consumerism and technology.  What does it take to make it?  I mean, that's not easy, you know?  Previously on twit.

Start time: 8692.10
End time: 8702.35
Speaker: SPEAKER_02
Transcript:  Hands-on photography.  Some of you folks are really curious  about starting your own photography business.  Well, I got to tell you,  there's a lot of work involved  and we're going to dive into that.

Start time: 8703.16
End time: 8734.59
Speaker: SPEAKER_01
Transcript:  Tech News Weekly.  Samsung Electronics announced  that they have begun mass production  of three nanometer chips.  Yes, from five to three.  The newly developed first gen three nanometer process  can reduce power consumption by up to 45%,  improve performance by 23%  and reduce area, of course, by 16%.  Security now.

Start time: 8735.44
End time: 8760.58
Speaker: SPEAKER_08
Transcript:  As of last week, finally, the masquerade is over  and the Conti ransomware operation  has finally shut down its last public facing infrastructure,  which consisted of two Tor servers,  which were used to leak data and to negotiate with victims.  And of course, no victims remain.  So they're gone.  Twit, friends don't let friends miss twit.

Start time: 8761.68
End time: 8834.78
Speaker: SPEAKER_05
Transcript:  We are going to have a good week this week.  I am back and I will be in the saddle for all those shows.  Also, by the way, we just figured out  that July 12th is going to be a big day.  That's the day the first scientifically usable pictures  will come back from the Webb Telescope,  one million kilometers, actually more than that,  almost one million miles out from the earth at Lagrange 2.  That telescope is fully operational  and we expect to see the most distant stars we've ever seen  going back so far that there are literally  about 120 million years from the Big Bang.  So this is the beginnings of the universe.  So NASA is going to have a press conference  7.30 a.m. Pacific 10.30 Eastern on July 12th.  That's a Tuesday.  Rod Pyle, the host of This Week in Space,  and I and anyone else who wants to join us,  I think John, you'll be joining us.  We'll be covering that.  So that's a little bit of an announcement  on something we just decided  because I'm very excited about that.  John, you said you had an update on the giant Cheez-It story?  You can order the Cheez-It Tostada without toppings  and just get a box of Cheez-It.

Start time: 8836.60
End time: 8838.47
Speaker: SPEAKER_02
Transcript:  Oh Lord, help me now.

Start time: 8839.62
End time: 8869.17
Speaker: SPEAKER_05
Transcript:  I'm never letting Jarvis host Twig again, that's it.  Actually speaking about a chips three nanometer TSMC,  which was supposed to move to a three nanometer process,  apparently having some difficulty.  And now, now that the Apple M2 MacBook Pro  is starting to come out,  we're seeing some negative reviews here from Extreme Tech.  Apple's entry-level M2 MacBook Pro  turns into a Celeron under heavy load.  Ouch.

Start time: 8870.22
End time: 8886.13
Speaker: SPEAKER_00
Transcript:  Yeah, but not unfair if you look at it.  I mean, it seems like they cheaped out  for whatever reason on the SSD  for the entry-level versus what we had last year.  And so there is definitely a speed regression  if you get the 256 gigabyte or 128 or whatever size it is.

Start time: 8888.58
End time: 8922.87
Speaker: SPEAKER_05
Transcript:  Don't get the cheap one, in other words.  The baseline is 256 and eight gigs of RAM.  According to Extreme Tech,  the 13 inch base system gets as hot as 108 degrees Celsius,  which is hotter than boiling.  That's very hot.  And that seems to very much impact  the performance of the SSD controller.  So yeah, maybe a design flaw.  This is oddly, this is not a new design.  This is essentially the same design as last year with the M1.  But the M2, maybe it gets hotter.  I don't know.  So just don't know.

Start time: 8923.28
End time: 8933.64
Speaker: SPEAKER_00
Transcript:  Cause they're using something different for the SSD.  From what I understand,  they're using something different for the SSD.  And then in the RAM, this is the big thing.  They're basically only using one module rather than two.

Start time: 8934.14
End time: 8999.86
Speaker: SPEAKER_05
Transcript:  Okay.  So I will just refer you to this Extreme Tech article  and the YouTube video that spawned it.  And I'm sure we'll hear more about this.  We'll talk more about it on Mac Break Weekly.  But basically the advice of Extreme Tech  is do not buy the entry level M2 MacBook Pro.  There are issues.  There are issues.  There's so many stories we didn't even get to.  Let me see.  Oh, you know, one of the things  I wanted to do more happy stories.  And I don't know, Mike, you can advise me.  I'm a long time editor.  I have noticed over the last couple of years,  and I've received some notes from listeners,  that tech has really turned negative.  We used to be a little happier, right?  We, you could talk, we get excited about new products  and talk about what the new phones are going to bring.  And it's, and now it's just feels like it's bad news  after bad news.  Is this a normal part of the cycle, the ebb and flow,  or are we in a new era of tech?  What do you think, Mike?

Start time: 9000.88
End time: 9139.54
Speaker: SPEAKER_04
Transcript:  Well, we're in a new era for sure.  I mean, I think that back in the olden times,  80s, 90s, et cetera.  1860s, yeah.  The future was full of promise.  The year 2000 was coming.  And tech, the people who were enthusiastic about tech  was a tiny group of nerds who built their own systems.  Like, you know, it was all about optimizing this, do that.  You know, it was a lot of fun at the rate at which  the performance of everything just was exponential,  and, you know, so think about the,  how cameras have evolved on cell phones  in the last like 12 years.  But we're to the point now where,  and this is reflected here in Silicon Valley as well,  what used to be something that was,  first of all, understandable, second of all, exciting,  became this sort of money grab.  So everything's gotten super complex.  There's been this sort of inertia  that comes with the entropy of an expanding industry.  And so we have this situation now where  so many people are using technology products  that is having social effects,  and many of these social effects are negative.  Teenagers are getting addicted to social media  or committing suicide because Instagram makes them feel like  they're left out and all this kind of stuff.  There's all these problems that come from it.  Governments have their hands in it,  and good governments, bad governments,  everybody's involved.  And so we're in the situation where it feels like  there isn't much good news.  We don't really notice the benefits.  We were talking earlier about how TikTok has this subtle  ability to make you sort of see, have this little window,  this quick little window into some far away place  and some completely alien context.  Well, that's probably having a very beneficial effect.  We don't have time to focus on that or notice that  because we're so worried about the government  tracking down people with menstruation apps  to prevent them or jail them for having an abortion  or whatever.  So the bad stuff seems to just take up all the oxygen  in the room, and we can't really focus on the good stuff.  But there is really, really good stuff, I think,  happening with technology.

Start time: 9139.80
End time: 9153.84
Speaker: SPEAKER_05
Transcript:  It's just, ah, you know, it's just-  I feel like I wanna focus more on that.  I don't wanna be the grim reaper of technology.  What do you think, Glenn?  You're equally a long time in this business.

Start time: 9154.88
End time: 9311.00
Speaker: SPEAKER_03
Transcript:  I find myself increasingly uninterested in technology.  A fun thing to say on a show about technology.  But it's partly because, like the things that excite me still  are the ways in which people's lives get improved.  And so to echo what Mike was saying,  really it's just the focus.  There's a lot of technology that is insidious  because it's a race to the bottom.  It's a race to grab eyeballs and attention  and to do increasingly negative things  because that's how the money is raised.  And, you know, there's a famous example  that I think is actually made up,  but it's the psychology test where students  in a psychology class start only paying attention  to a professor when he or she's on one side  of the classroom.  By the end of the term,  they have the professor stuck in a corner.  They won't speak unless they're in that corner  because no one pays attention to them.  And they don't realize what's going on.  It's a great reverse experiment.  And I feel like everything in technology  that involves attention and response  puts us in that corner.  We're all, you know, all the...  Facebook doesn't, maybe Facebook intentionally  is not trying to allegedly contribute to genocide,  but it does because that's a part of the technology  they develop that allows them to reap  such huge financial returns.  So I'd like to look things at,  I like to look at enhancements and so forth.  My wife has a bone-anchored hearing aid,  an earlier generation.  She sticks a Bluetooth device on this thing  that vibrates and it sends a signal to her ear  and it connects to her iPhone.  They added an upgrade a few releases ago.  And so she can play music and phone calls into her head.  And it's a huge improvement for her life.  So that hearing aid by itself was great technology.  Then the linking of it with Bluetooth and improvements  in Apple's operating system, make it into a superpower.  It's a biological enhancement, in fact.  She has abilities beyond people  with so-called normative hearing.  And I want to find more things like that.  Like I don't care so much about VR or AR.  I'm not, there are great entertainment opportunities,  but I don't think they're going to fill all this zone.  But I'm like, AR is such an incredible capability  for younger people, for people with various disabilities  that prevent them from having full access  or full use of hearing eyes, whatever.  I think about like, the thing that I keep coming back to  in my idea of what the future should be  is heads-up display painting our windshields in a car.  I don't want necessarily automatic driving.  I like warnings and things like that that are good.  But I want to be able to drive the road at night  and have night vision on the inside of my windshield.  And why not?  That to me would be an enhancement.  It would reduce accidents.  It would maybe not decrease alertness  because it's enhancing your view.  So I look forward to things like that.  And also more cat pictures, please.

Start time: 9311.36
End time: 9332.85
Speaker: SPEAKER_05
Transcript:  I feel like you're an optimistic guy.  So I'm going to take a page from your joy in technology.  I mean, I got into this because I love technology.  I still love it.  But it's so easy to get kind of burdened  by all of the negatives and start focusing on that.  Christina, you're also optimistic.  You're a very positive person.  And you work in technology.

Start time: 9334.38
End time: 9384.60
Speaker: SPEAKER_00
Transcript:  Yeah, I mean, look, I think that it can become overwhelming  to just look at, because there are a lot of terrible things  that are happening in the world.  And there are a lot of terrible things that have happened  in the last two years.  And technology is a force for good and it's a force for bad.  But I think that on the whole of it,  it has made our lives better.  I know that my life is infinitely better  because of technology, because of social media,  because of the web.  Right, right, yeah, totally.  Because of the way that I can communicate with people.  Even what happened to us in the last two years,  as bad as that was, it would have been worse  if we didn't all have the ability to communicate  with each other over video chat, right?  Or even through text messages or phone calls, right?  Which, needless to say, the last time we had  one of these things, 100 years ago,  you didn't have that ability.

Start time: 9384.62
End time: 9387.43
Speaker: SPEAKER_08
Transcript:  You just locked yourself in your room and waved for help.

Start time: 9390.44
End time: 9462.77
Speaker: SPEAKER_00
Transcript:  To say nothing of vaccines and the stuff that's happened  there, so I don't know, I have to work at it  because it's easy for me, even though I am a typically,  I'm not a cynical person.  I mean, I have cynical aspects,  but I try to be a fairly positive person.  It's hard sometimes not to be taken in by all the cynicism.  I also don't want to be a cheerleader for the industries  that sometimes I think that maybe in the past,  we were too credulous and we were too positive  about certain things and allowed certain things to happen.  So I think that there's a good and a bad,  but I do fear sometimes when I read some of the coverage.  And I read the lens of someone who loves technology,  who used to be a reporter and now works for a tech company.  And so I will say I have a different perspective,  which is good to have.  Sometimes I worry that too much of the coverage  is negative just to be negative,  critical just to be critical.  And I'm here for the criticism.  I'm here for the pushback, but there has to be a balance.  And I do sometimes wonder if we've swung too far  in the other way.  We went from being way too credulous, way too laudatory  to now completely ignoring the positive things  that can happen because of tech.

Start time: 9463.68
End time: 9573.99
Speaker: SPEAKER_04
Transcript:  Leo, can I make a couple of points  not to miss the forest for the trees  and talk about the forest a bit?  First of all, Christina mentioned vaccines.  If the coronavirus had hit in the 1970s, say,  there would have been no working from home  and no vaccine for 10 years.  It's unimaginable.  It's really unimaginable.  But the forest that I'd like to talk about  is my own lifestyle of living internationally,  which the world has discovered because of the pandemic.  People are working remotely, working from home.  There's a sort of thing where people start working  from their apartment in the city.  Then they decide to move out of the city.  And I was like, what are we doing in the suburbs?  Why don't we go to South America  and live in Columbia for a while?  And the internet connectivity keeps getting better.  We just did the Provence experience.  We always do that in this 400 year old farmhouse.  The walls are three and a half feet thick,  but it's very modern inside in every way,  except the internet connectivity,  which is a really, really slow,  like 3G mobile broadband connection.  How do you live?  Well, this is a good question.  Well, we showed up this year and guess what?  They now have fiber.  Oh, wow.  In the middle of- Wow.  Oh my gosh.  Out in the countryside.  That's amazing.  Amazing.  So people can actually live.  And also by the way, Starlink is available  throughout France as well.  Starlink, I was gonna say, is massive.  So you can do a full on like under the Tuscan sun,  buy a derelict old farmhouse  somewhere in the sunny parts of Europe.  And you can build up this thing  and you could live in paradise, have a garden,  have a beautiful view, have clean air, clean water,  clean everything, solar power.  And you can have fiber optic like speeds  and make your living in paradise.  This is an opportunity that has never been afforded  to anyone in the history of mankind.  And it's pretty great for those  who really wanna live that way.  Excellent.

Start time: 9574.66
End time: 9575.65
Speaker: SPEAKER_05
Transcript:  I feel better already.

Start time: 9576.54
End time: 9651.42
Speaker: SPEAKER_03
Transcript:  I point out one more thing if I might,  which is that photography is an almost unalloyed joy  that we breathe and so we don't pay,  it's like unlike Mike's example just now,  it's like Wi-Fi is everywhere.  I used to cover Wi-Fi very extensively.  Then I suddenly was not a Wi-Fi reporter  because it just permeates everything.  Then we got good cellular data.  The abilities we have to take a good picture  and to take as many as we want  and capture great moments in our lives are incredible.  And then I will call out there's one thing  that makes me consistently happy every day,  that is technology, which is I use the featured photo thing  on my iPhone, I have it as a widget.  And most days, Apple's machine learning comes up  with wonderful images across every,  and I've scanned photos before they were digital photos.  So I have photos going back to the 80s in my library.  And so every day I get to look at these great pictures  of my kids when they're babies and photos  from a few weeks ago and pictures of bees  I took 20 years ago or some trip.  And I'm like, ah, ah.  And I don't have to go searching for it, it shows up.  And so it's machine learning, it's a modern device,  it's the access through the cloud to all my photos.  And I'm like, it combines to this wonderful thing.  And so I have a moment of happiness every time I open that.

Start time: 9652.08
End time: 9702.43
Speaker: SPEAKER_05
Transcript:  I guess it really is a question of focusing on the benefits  and the good stuff, because there's negatives and positives.  And you don't have to dwell on the negatives,  we know they're there.  I don't-  And there's Elon Musk.  And then there's Elon Musk.  And the Pope.  Hey, one good thing, the Presidential Medal of Freedom,  the highest civilian award being awarded July 7th,  17 luminaries, Denzel Washington, Simone Biles,  Megan Rapinoe, John McCain will get a posthumous award,  and Steve Jobs, 11 years after his passing,  will be receiving the, posthumously,  the Congressional Medal of Honor.  I hope that his wife, Lorene Powell Jobs,  is there to accept on her late husband's behalf.  I think that'd be very fitting.

Start time: 9703.52
End time: 9720.37
Speaker: SPEAKER_00
Transcript:  And basically 15 years after the iPhone, right?  Which- Yeah, that's right.  Which is, I mean, it's hard to even,  it is easy to remember what life was like before,  but just the seismic impact of this device has had.  Yeah.  It really has.

Start time: 9721.36
End time: 9725.17
Speaker: SPEAKER_04
Transcript:  Let's be honest, it's not a knighthood like Johnny I've got,  but it's something I'm well-deserved.

Start time: 9726.88
End time: 9793.04
Speaker: SPEAKER_05
Transcript:  But Johnny didn't meet the Queen,  he only got Queen Anne, or Princess Anne,  so it's not as good.  Good point.  All right, final Jeopardy, the subject, the world of today.  I'm gonna pose this question to all of you.  I will say that on this episode of Jeopardy,  only two people got it right.  Oh, come on.  Partly because it was a monosyllable.  This word was chosen as, quote,  a noun that conveys the idea of a unit  of cultural transmission.  Yeah.  You know the answer, Christina.  I'm pushing the button, nothing's happening.  I don't hear any buzzers happening.  It's final Jeopardy, you all get to answer.  Christina Warren.  Meme.  It was a meme.  In the form of a question.  Form of a question.  What is a meme?  Yep, absolutely right.  I know you knew that, Glenn.  In fact, probably everybody watching knew that.  The word meme coined by evolutionary scientist  Richard Dawkins, and it is in fact, of course,  part of our regular vocabulary today.  Only two, I'm only, only one out of the three got it.

Start time: 9793.30
End time: 9802.46
Speaker: SPEAKER_00
Transcript:  Only one of the three got it.  That's, wow.  Because I was reading the question,  I didn't even get to the end of the question,  I was reading it.  You knew immediately.  I was like, oh yeah, I got it.  I was like, it's a lame.

Start time: 9802.84
End time: 9819.44
Speaker: SPEAKER_05
Transcript:  One person answered um.  It was not, it was not the best Final Jeopardy ever.  And Glenn, I know you would have gotten that one.  No problem.  Yes, I, yes.  Two time Jeopardy champion.

Start time: 9820.90
End time: 9824.28
Speaker: SPEAKER_03
Transcript:  Three times correct in Final Jeopardy,  but only one twice.

Start time: 9824.90
End time: 9827.29
Speaker: SPEAKER_05
Transcript:  Oh man, that last one, they got you,  you didn't bet enough.

Start time: 9827.94
End time: 9838.21
Speaker: SPEAKER_03
Transcript:  I can't, no, I didn't have enough money left.  I said George Sands instead of George Sand,  and I didn't have money after Final Jeopardy.  We'll never forget, obviously.  Oh my God.  I've gotten over it.  Dance with me George, dance with me.

Start time: 9839.28
End time: 9839.89
Speaker: SPEAKER_00
Transcript:  Oh my God.

Start time: 9840.30
End time: 9841.80
Speaker: SPEAKER_03
Transcript:  Ooh, sorry Alex.

Start time: 9844.50
End time: 9861.00
Speaker: SPEAKER_05
Transcript:  Glenn Fleishman, what a pleasure.  Glenn.fun, always great to have you on.  We will be back on Wednesday for This Week in Google.  I hope we haven't exhausted all of your resources.  I have a feeling we have not.  Not yet.  But if you wish you can speak very slowly.  If you would.

Start time: 9861.18
End time: 9863.73
Speaker: SPEAKER_03
Transcript:  I like to use deliberative tones.

Start time: 9866.04
End time: 9935.39
Speaker: SPEAKER_05
Transcript:  Thank you Glenn, so nice to have you.  Mike Elgin, God bless you.  Give my love to Amira, to Kevin,  to Princess Squishy Face, to Nadja, the whole family.  Thank you.  Gastronomad.net if you wanna go travel  with these incredible people,  to some of the most beautiful places in the world,  and eat and drink like a prince.  It's amazing.  Yes.  Highly recommended.  Mike also writes for Computer World,  many other publications, and he's got a newsletter,  Mike's List, and of course elgin.com is the website for that.  Thank you Mike, always a pleasure.  I'm sorry we couldn't get together,  because I probably would have loved that wine,  but you know, such is life.  Such is life.  Thank you.  Such is life in the COVID era,  which apparently is going on and on and on.  Christina Warren, a pleasure seeing you too,  although because I follow you on Instagram,  I feel like I know every hotel room you're in.  Yes.  Senior Dev Advocate at GitHub.  Her GitHub name is Film Girl.  Her Twitter handle is Film Underscore Girl.  So is her Instagram.  Anything else you wanna mention or plug?

Start time: 9936.26
End time: 9971.70
Speaker: SPEAKER_00
Transcript:  Yeah, so I do two podcasts.  I do one called Overtired, overtiredpod.com.  Wait a minute, I didn't know about Overtired.  Yeah, Overtired is great.  It's basically, we joke that it's a Taylor Swift podcast.  It's not, it's really about some ADHD nerds  and the things that keep us up at night.  And it's great.  And then I also do a Rocket.  Oh, it's with Brett Terpstra.  Oh nice.  Oh Brett Terpstra, yeah.  Oh Brett's a love Brett, yeah.  Yeah, Brett's amazing.  And Jeff Severins-Gonsol recently joined us  as our third host.  And I also do Rocket on Really FM,  and with Brianna Wu and Simone de Rochefort.  So.

Start time: 9972.36
End time: 9973.07
Speaker: SPEAKER_05
Transcript:  Very nice.

Start time: 9974.20
End time: 9979.54
Speaker: SPEAKER_00
Transcript:  When I listen to me, I've got other podcasts,  but also frankly, like my Instagram.  But the hotel tours is really what you want.

Start time: 9980.00
End time: 9982.77
Speaker: SPEAKER_05
Transcript:  When did you start Overtired?  I'm gonna have to listen to that.  That sounds really great.

Start time: 9984.08
End time: 9992.66
Speaker: SPEAKER_00
Transcript:  Honestly, like eight or nine years ago.  What?  It's been intermittent,  but we've been consistent for the last year.  So we've been consistently every week.

Start time: 9992.92
End time: 9995.25
Speaker: SPEAKER_05
Transcript:  I knew about Rocket.  I love Rocket.  So that's cool.

Start time: 9995.54
End time: 10013.78
Speaker: SPEAKER_00
Transcript:  Yeah, Overtired had periods of inactivity, we should say.  Well, naturally.  But we're tired.  I understand that.  Exactly.  Naturally, we were tired.  I came up with the name, actually.  We were at like Twitter HQ,  and we were trying to come up with the name.  I was in the elevator, I'll never forget.  And I was like, I'm so tired.  I'm Overtired.  I was like Overtired, that's it.  That's about it.

Start time: 10013.88
End time: 10174.36
Speaker: SPEAKER_05
Transcript:  Such a good name for a podcast.  Wow, it has so many levels of meaning.  Wonderful to have you.  Thank you, all three of you.  We really appreciate your being here.  Have a great 4th of July.  Tomorrow, fireworks, grilling, fun.  Wave the flag.  We're not doing fireworks here in Petaluma  because of the drought and the fire hazard.  Plus the city's broke.  So we're gonna have a laser light show instead.  Everybody bring your lasers.  It's gonna be great.  Love it, love it.  We do Twitter every Sunday afternoon,  2 p.m. Pacific, 5 p.m. Eastern, 2100 UTC.  You can watch us live, live.twit.tv.  Actually, watch or listen.  There's live audio and video streams.  If you're watching live, chat with us at irc.twit.tv.  You can also chat with us in our Discord, which is purple.  But really, comes to mind honestly,  the Discord is actually my favorite  new social media place to be.  The conversations aren't just about the shows.  In fact, our Discord has topics  every geek would be interested in.  No flongs yet.  But comics for sure, gaming, hacking,  ham radio, movies, music, software, sport ball,  travel, trivia, and you can even be  part of our Minecraft server.  All of this plus ad-free versions of all the shows  and the special Twit Plus feed,  which has a lot of material that doesn't make it to the air,  so to speak, and it's seven bucks a month,  which I think is a great deal.  We would really appreciate it if you'd join us.  There's also a yearly, what is that, $84,  if you just wanna pay once and get it over with.  That makes a great gift too, and it really helps us.  A recession is looming, and we already see  some decrease in ad revenue,  and I think this is gonna be as bad as it was  when COVID started, so this helps us get over those humps.  Plus it lets us develop new shows, bring in new talent,  and we've got some exciting news in that area coming soon.  So please join Club Twit, twit.tv slash club twit.  Of course, all of our shows are available for free  after the fact on the website, twit.tv.  Every show has its own YouTube channel,  as does this show, of course.  Best way to get the show probably be subscribed  in your favorite podcast client, you get it automatically.  The minute it's available, now you have a great show  to listen to on a Monday morning.  Thank you for being here.  As you have been, I think many of you for the past 17 years.  It is now, once again, time for me to say goodbye.  Another twit is in the can.

Start time: 10175.58
End time: 10186.78
Speaker: UNKNOWN
Transcript:  It's amazing.  Told you,ITS AMAZING.  Makes you smile.  It's a MetaP 건.  To All Follow up on Twitter and Twitter år.  Per 1,2 toilet paper per locked.

