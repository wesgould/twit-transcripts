;FFMETADATA1
title=Banana Is Phone
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=655
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100
Start time: 1.26
End time: 140.52
Speaker: SPEAKER_02
Transcript:  It's time for Twit this Week in Tech. Great panel for you, Amy Webb, Brianna Wu, Michael Nunez.  We're going to talk about the Galaxy S9, just announced from Samsung.  Privacy regulations in the US and China and their differences.  And Apple repair services calling 911 thousands of times.  It's all coming up next on Twit.  This is Twit.  Bandwidth for This Week in Tech is provided by Cashfly at C-A-C-H-E-F-L-Y dot com.  This is Twit This Week in Tech.  Episode 655 recorded Sunday, February 25th, 2018.  Banana is phone.  This Week in Tech is brought to you by Audible. Audible makes getting more books in your life easy.  Sign up for the Gold Plus One plan to get two free books and a 30-day free trial at audible.com slash twit two.  And by LegalZoom. Get your dream business up and running or take control of your family's future with LegalZoom.  For special savings, visit LegalZoom.com and enter twit at checkout.  And by ZipRecruiter. Hiring? ZipRecruiter has revolutionized how you'll do it.  Their technology identifies people with the right experience and invites them to apply to your job.  Try it free today at ziprecruiter.com slash twit.  And by Cloud Spanner from Google Cloud Platform.  Cloud Spanner is the only horizontally scalable and strongly consistent relational database service.  To learn more, visit g.co slash get spanner today.  It's time for Twit This Week in Tech, the show where we cover the week's tech news.  Very good panel this week. I say that every week, but I mean it every week.  Let's start with Amy Webb. She's a futurist and the author of a book.  This is actually how I met her called The Signals Are Talking. Why Today's Fringe is Tomorrow's Mainstream.  She is joining us from where are you? Somewhere different. You're in Nashville.

Start time: 141.22
End time: 146.00
Speaker: SPEAKER_05
Transcript:  This week I'm in Nashville. I'm speaking at a big conference tomorrow on the future of energy.

Start time: 146.54
End time: 152.96
Speaker: SPEAKER_02
Transcript:  Nice. Founder of the Future Today Institute. Your new FTI Trend Report. You just held it up. It's going to be out soon, right?

Start time: 153.46
End time: 186.00
Speaker: SPEAKER_05
Transcript:  It's so exciting. It launches at South by Southwest on March 11th. We have 225 emerging tech trends this year.  This is the 11th annual edition of the report. It's our largest yet.  It has had 6 million cumulative views. I can't wait. It's digital also, but we've made some printed versions.  It goes online on March 10th. You can sign up to receive an advance copy now on our website.  On March 11th it will be everywhere. You can download it. We'll be in Austin on March 9th doing a panel down there.

Start time: 186.00
End time: 233.96
Speaker: SPEAKER_02
Transcript:  If you're in the area, come by. We're at the Capital One house in Antons. Unfortunately, our panel is at 8.30 in the morning.  We're going to do a panel on consumer security. Consumers hear all the meltdowns, specter, Equifax, all the issues.  What is really at stake for them and what are the real practical things we should do? We have some really good security experts on.  Great.  Anyway, thank you, Amy, for being here all the way from Nashville.  Also joining us from the Massachusetts Eighth District where she is a candidate for US Congress. Brianna Wu, space cat gal, is back in the studio. Hey, how you doing, Brianna?

Start time: 234.80
End time: 279.92
Speaker: SPEAKER_00
Transcript:  I feel really good. I have to tell you, I've had so many conversations with elected officials as I'm running for Congress here about cybersecurity.  It's so depressing because you will talk to people and they're in charge of like a massive computer system here in the state and you'll ask them specific technical questions.  And all they ever say is like, we have an IT department.  They're not even thinking about it.  They're not. I was trying to talk to someone the other day about like, look, if you've got these machines, these voting machines, you've got to check and make sure the version of software that's running on it is the same software you think it is.  And it's just, it's a level too high for them to even talk about.  We've got to have technologically literate people actually making decisions at some point.  It's highly problematic.

Start time: 280.44
End time: 292.94
Speaker: SPEAKER_02
Transcript:  I find it also very frustrating that as far as I could tell, Equifax has gotten off scot-free.  No punishment.  None at all.  No consequences whatsoever.  In fact, they made money on the breach.

Start time: 294.32
End time: 322.98
Speaker: SPEAKER_00
Transcript:  What really gets me about that Leo is if you actually go out and talk to people, they are as angry about Equifax as you could possibly imagine.  You talk to them.  It doesn't matter if they're Republican and Democrat, not politically active.  You just see their blood pressure rising.  And you would think that just out of pure self-interest, you would have politicians talking about it.  And they just, I don't know if they're just so like caught up in the system or they just don't care.  But for whatever reasons, like you said, they got off scot-free.

Start time: 324.16
End time: 331.72
Speaker: SPEAKER_05
Transcript:  Hey Brianna, are you doing anything for candidates in the state of Massachusetts around election fraud?  And is there any, like what's happening?

Start time: 332.42
End time: 351.11
Speaker: SPEAKER_00
Transcript:  I can't say that I've had really big talks with the Secretary of State's office about that.  We are currently having, there are concerns, but when you ask questions, I hope I'm not burning any bridges when I say I haven't like the answers I've gotten to that question.  So, you know, we need to take it more seriously.

Start time: 352.00
End time: 366.51
Speaker: SPEAKER_02
Transcript:  Also in the studio, well actually not in the studio, in his studio, he's at Mashable, Michael Nunez.  Remember him from Popular Science.  He's now over at the Mashable headquarters where he actually is at work on a Sunday evening.  I'm sorry, Deputy Tech Editor over there.  Hey Michael.

Start time: 367.31
End time: 367.88
Speaker: SPEAKER_03
Transcript:  Hey, how are you?

Start time: 368.02
End time: 375.56
Speaker: SPEAKER_02
Transcript:  Great to have you as always.  You're not, everybody, it's empty over there.  That's because everybody's in Barcelona probably, right?

Start time: 376.00
End time: 392.88
Speaker: SPEAKER_04
Transcript:  That's exactly right.  Yeah, so I've been here for a little while monitoring our Mobile World Congress coverage.  Obviously the Samsung Galaxy S9 release and a couple of other of the Android phones that came out today.  So it's been a busy Sunday, but you know, it's what I love to do.  So I'm happy to be here.

Start time: 393.38
End time: 436.69
Speaker: SPEAKER_02
Transcript:  We actually streamed along with Samsung the event 9 a.m. our time, noon your time, and about five in the evening in Barcelona where they announced the S9.  Looks like it went very well.  Very pleased to see Samsung did not follow Apple in almost any respect.  And they were very proud to say no notch.  We still have a headphone jack.  Yes, there's a fingerprint reader.  But most importantly to me, they didn't raise the hike, the price an awful lot.  There's this the S9 is seven hundred twenty dollars.  The S9 plus the six point two inch model with dual cameras.  One hundred twenty dollars more.  Eight hundred forty dollars.  That's not exactly holding the line, but it's still not a thousand dollar phone.

Start time: 438.39
End time: 465.00
Speaker: SPEAKER_05
Transcript:  Well, it kind of is though.  Is it?  It is. Amy says it is.  Well, so I have an essay and I'm a pretty careful person and I've now broken two screens because the thing is slippery as butter and it's delicate.  Do you not put it in a case or that's even with a case?  Oh, no, no, no.  This is with a case.  And yeah, so.  Butterfingers.  It's not just me, though.  These these screens are constantly getting broken.  And if you choose to repair, it's a couple hundred bucks.

Start time: 465.68
End time: 470.00
Speaker: SPEAKER_02
Transcript:  Do you think you'd have the same problem with an iPhone 10, which is also an edge to edge slippery?

Start time: 470.00
End time: 480.96
Speaker: SPEAKER_05
Transcript:  I would have so many more problems with an iPhone 10.  I loved it when you said earlier that Samsung isn't copying Apple.  I mean, Apple, you know.

Start time: 481.30
End time: 506.98
Speaker: SPEAKER_02
Transcript:  Well, OK, but there's no notch.  They're doing dual cameras, but they're doing F1.5 and F2.4, which Apple does not do.  It looks like they're closer to Google's Pixel because they have a dual pixel camera.  I'm very excited about the low light and they're doing something Apple can't do on the new S9, which is nine hundred sixty frames per second.  Super slow mo.  And that's attractive.  What is the reaction you're hearing from Barcelona, Michael?

Start time: 507.96
End time: 515.86
Speaker: SPEAKER_04
Transcript:  Well, I think most people are excited about, oddly enough, the Animoji rip off.  So, you know, come on, but they are.  That's what that's what they're copying.

Start time: 516.65
End time: 517.66
Speaker: SPEAKER_02
Transcript:  Apple is the Animoji.

Start time: 518.60
End time: 573.98
Speaker: SPEAKER_04
Transcript:  Yeah, people love people love these things.  And and frankly, I like them.  They're a lot of fun.  So I'm excited to actually play with that when the phone gets back to New York.  I think generally, you know, the the the consensus is that this isn't a leap ahead of the Galaxy S8.  So if you have last year's model, there's not enough reason to go out to run out and get the S9.  But they're they're still building on a very solid foundation.  You know, Samsung has nearly perfected this Galaxy series with the edge to edge display.  I think a lot of people like the the performance, obviously, on the cameras and low light settings.  You know, the the display itself is really nice that the phone looks very premium.  So people still consider this one of the best Android phones available.  It's just, you know, it's not really pushing the boundary in the same way that the iPhone 10 is is trying to, you know,  guess where where phones are headed in the future.  So so this doesn't quite set the same benchmark, but it's still a very good phone.

Start time: 574.98
End time: 589.96
Speaker: SPEAKER_02
Transcript:  The Animoji feature that they demonstrated on stage did not feature aliens, monkeys, lions.  It just took your picture and turned it into something that vaguely looked like you.  But is there more to it than that?

Start time: 590.00
End time: 599.00
Speaker: SPEAKER_04
Transcript:  No, that's it. That's it. But people love doing that.  I mean, like people do that on the Nintendo Wii.  They do that through Bitmoji. I mean, and people are obsessed with themselves.

Start time: 600.04
End time: 604.80
Speaker: SPEAKER_02
Transcript:  And I guess that's the point is I could do this with Bitmoji on a snapchat on Snapchat on any phone. Right.

Start time: 605.64
End time: 608.74
Speaker: SPEAKER_04
Transcript:  Well, you could, but you can't do this actually animates.

Start time: 609.08
End time: 613.32
Speaker: SPEAKER_02
Transcript:  So Bitmoji right now, it doesn't you can't talk and have its lips move.

Start time: 614.02
End time: 643.00
Speaker: SPEAKER_04
Transcript:  Yeah, exactly. And so I think, you know, I'm sure Snapchat has the capability to do this.  Obviously, they have like 3D renders of your Bitmoji in Snapchat.  But this is one of the only apps or features that lets you control a 3D avatar, much like you would with a puppet or something like that.  So it's just it's a fun, stupid feature.  But and so it's like not you shouldn't go buy the phone just because of this one thing.  However, it's a nice addition, I think, if you decide to buy it.

Start time: 643.50
End time: 659.86
Speaker: SPEAKER_02
Transcript:  I could tell you I have the Animoji on the iPhone 10 and I used it a few times at the beginning when I first got it.  I've never even thought of using it again.  Maybe that's just because I'm an old person.  It's the same. I used it once.  Yeah, it's gimmicky. I don't know.  What do I want to send an animated tiger for?

Start time: 661.40
End time: 674.00
Speaker: SPEAKER_00
Transcript:  So I want to know like explode gate like, you know, last year they kind of brought their the milliamps of the battery down a little bit.  Did they amp it up this year?  Did they are they betting big on the battery again or they worried it's going to explode?

Start time: 674.90
End time: 679.29
Speaker: SPEAKER_04
Transcript:  So I can't say off the top of my head what the size of the battery is.  I can. I memorized all the stats.

Start time: 680.24
End time: 689.00
Speaker: SPEAKER_02
Transcript:  Three thousand milliamp hours for the S9 and for the S9 plus thirty five hundred.  That's still a lot below. I think the Note 7 was four thousand.

Start time: 689.22
End time: 696.59
Speaker: SPEAKER_04
Transcript:  Yeah, I was going to say I think they haven't gone quite up to the same capacity as the Note 7 that was explored.  Do you find it amazing?

Start time: 698.46
End time: 725.72
Speaker: SPEAKER_02
Transcript:  I thought after the Note gate, after the Note 7, Samsung would really hurt that this would be a big deal.  It did not seem to impact them at all.  They immediately the very next quarter, they had a massive quarter with the S8 and the Note 8.  Nobody held back.  I guess people believed, as I think is probably the case, that Samsung will be extra.  This is the least likely phone to explode now.

Start time: 726.44
End time: 728.00
Speaker: SPEAKER_05
Transcript:  There's not a lot of competition in the marketplace, though, right?

Start time: 728.00
End time: 730.30
Speaker: SPEAKER_02
Transcript:  So, you know, it's Samsung and Apple and that's it, right?

Start time: 732.07
End time: 737.09
Speaker: SPEAKER_05
Transcript:  Right. So, I mean, if you're not, you know, if you're interested in Android,  there are other models, but I prefer the Google Pixels.

Start time: 739.88
End time: 744.72
Speaker: SPEAKER_02
Transcript:  But you're right. Most people are doing poorly.  Are they doing that badly?

Start time: 745.38
End time: 753.00
Speaker: SPEAKER_04
Transcript:  Oh, the Pixel 2 is like an abomination.  I think it was only like three million units sold worldwide or something.  It's so sad. It's easily the best.

Start time: 753.12
End time: 762.58
Speaker: SPEAKER_05
Transcript:  Google is having a hard time with hardware.  I just I think that they just don't have it together.  They've tried to be a hardware company a few times now and it's just not, you know.

Start time: 763.68
End time: 793.87
Speaker: SPEAKER_02
Transcript:  Samsung spends unlike most other companies, its marketing dollar is tied to its revenue.  So as they can as they roll in the dough and they really are rolling in the dough,  they buy more ads and you'll see more Samsung ads everywhere than anything.  So I mean, even Apple, which buys a lot of ads, you'll see Samsung's marketing everywhere.  And obviously that's overcome any concerns people have.  And yeah, maybe it's just no competition, although there is competition.  It's just people aren't choosing it.

Start time: 795.00
End time: 809.00
Speaker: SPEAKER_04
Transcript:  Well, many people rely on Samsung for the creation of OLED panels.  And I think the production process for a long time has been something that Samsung has really cornered the market on.  So they're one of the, you know, the biggest phone manufacturers.

Start time: 809.16
End time: 814.03
Speaker: SPEAKER_02
Transcript:  And so the success of the screens, they even make the screens for Apple.  That's right.

Start time: 815.86
End time: 840.79
Speaker: SPEAKER_05
Transcript:  Samsung has sort of greater brand penetration because they're not just making phone like HTC has a problem.  HTC has many problems, but HTC has a problem because you don't buy other HTC products.  You know, people have Samsung refrigerators and washing machines.  So it's a brand with much higher capacity and greater penetration.  So I think even if they falter, there's so many other products in the marketplace that people do like.  And they're so far ahead in other areas like IoT.

Start time: 844.01
End time: 847.00
Speaker: SPEAKER_02
Transcript:  Brianna, you started to say Xiaomi makes some good phones, right?

Start time: 847.20
End time: 876.12
Speaker: SPEAKER_00
Transcript:  Yeah, I mean, I think I don't know if you guys watch the YouTube channel Unbox Therapy, but they bring out always amazingly talented.  But they bring out a lot of these phones that we just don't hear about if you watch this week in tech or the Verge or other things like that every week.  And, you know, I've been really impressed with the quality of them when I've seen them in person.  Like some of the Chinese people I know here in Boston, like it's I think it's a bigger brand in China than in the United States.  Yeah.

Start time: 877.00
End time: 887.99
Speaker: SPEAKER_04
Transcript:  What about the US intelligence agencies have advised against purchasing phones from Huawei and Xiaomi?  They could potentially be spying on you.  So Huawei had a deal.

Start time: 889.06
End time: 926.80
Speaker: SPEAKER_02
Transcript:  It's very sad. Huawei had a deal for their new phone with both AT&T and Verizon.  And after the US government said no, no, no, both AT&T and Verizon pulled out and Huawei was, you know, devastated.  They said if you don't have a carrier deal in the US, you don't sell phones.  Is it? Do you actually know? This is an interesting question.  All all I mean, all the iPhones are made in China.  Is there something about a Huawei or a Xiaomi or that that makes it more inherently more risky than a phone that's from an American company made in China?  What do you think, Michael?

Start time: 928.08
End time: 944.00
Speaker: SPEAKER_04
Transcript:  I think it comes down to the software that's packaged with the phone.  So it's a phenomenal question.  I mean, you know, I think theoretically, you know, all phones that that begin from the same origin would be would have the same risk.

Start time: 944.94
End time: 958.00
Speaker: SPEAKER_02
Transcript:  What's the stuff people to go from going into Foxconn unbeknownst to Apple and saying, I mean, after all, this company is a Chinese company and saying to them, here's a little something extra you'd be putting in the phone.  Thank you very much.  Don't tell Apple.

Start time: 958.91
End time: 964.76
Speaker: SPEAKER_04
Transcript:  Yeah, I think it's I think it's a great point.  I I imagine that there are pretty strict quality assurance.

Start time: 965.14
End time: 968.50
Speaker: SPEAKER_02
Transcript:  You know, Apple is probably has people there watching for exactly that.

Start time: 969.00
End time: 976.00
Speaker: SPEAKER_04
Transcript:  Yeah. And also testing devices, the devices in the US.  You know, once they reach the US, I'm sure that they have a team of engineers that are trying these things out.

Start time: 976.30
End time: 980.31
Speaker: SPEAKER_02
Transcript:  So and we should point out that Samsung's phones are not made in China.  They're made in Korea.

Start time: 981.87
End time: 1029.98
Speaker: SPEAKER_00
Transcript:  I feel like I have to add to that.  Oh, sorry. I was just going to say, I feel like I have to add to that.  You know, I did a piece on the FISA bill, which is an absolute disaster for HuffPo a few weeks ago.  I was speaking with the FF about like, you know, does is it theoretically possible for Congress to pass laws in that channel saying Apple has to do A, B or C to their phone?  You know, could you be having that kind of policy here?  The answer is we don't know.  The answer is flat out.  We don't know if they did have something like that.  We wouldn't be able to know.  So, you know, like if I get elected, I will certainly say what I can.  But I think it's worth saying, like people could have that same legitimate fear against states, especially because we literally just have this big FISA bill renewed, which gives us broad powers to spy on the entire planet in secret.

Start time: 1030.82
End time: 1037.88
Speaker: SPEAKER_02
Transcript:  And that's the important part is that a national security letter often says and you can't tell anybody we told you exactly.

Start time: 1038.30
End time: 1049.00
Speaker: SPEAKER_00
Transcript:  Yep. You have three judges on the FISA court that theoretically can give some pushback and we can read some of their rulings.  But as far as it being transparent for the public, no, it's really scary.

Start time: 1049.26
End time: 1107.22
Speaker: SPEAKER_02
Transcript:  The more you learn about it, there is a certain hypocrisy and us complaining, for instance, that the Russians impacted our elections when we have been for 100 years impacting elections all over the world.  It's just, you know, we didn't think it was in Facebook to do it.  Here's a story that was big in Reuters this week.  Apple moves to store iCloud keys in China, raising human rights fears.  But I have to say, this is not, I mean, Apple is a company doing business in China.  Any company doing business in China is required to obey the laws of China, just as any company doing business in the US is required to obey our laws.  And incidentally, guess where the iCloud keys are stored in the US?  They're stored at Apple and they will hand them over to law enforcement, given a FISA request, an NSL letter or a simple subpoena or warrant.  It's no different, in other words.

Start time: 1108.14
End time: 1166.72
Speaker: SPEAKER_05
Transcript:  Well, I think there's a key difference.  You know, so I lived in China for a while and in China you don't have a reasonable expectation of privacy, even if you're pretty digitally savvy and sort of on the higher end of the income spectrum.  That is, you know, in the United States, people are sort of blindly using the packaged software and the tools and the systems that come with their computers and their cell phones.  And I don't think the average person who uses keychain understands what that is and where the data is and who has access to the data.  You know, and so we sort of blindly click buttons and follow answers here.  And we lack a certain amount of skepticism that.  And so, you know, sort of seems a little counterintuitive, but I think people who were who would be using the service in China are a little bit more street savvy.  They're safer is what you're saying.

Start time: 1167.14
End time: 1169.34
Speaker: SPEAKER_02
Transcript:  The Americans who trust Apple.

Start time: 1170.04
End time: 1192.04
Speaker: SPEAKER_05
Transcript:  I'm saying they're more aware and I would I would be surprised if they're it's been my experience that in the digital realm, at least people are a lot less naive.  It's so funny.  China is a huge country.  So it's not everybody, but it seems to be a greater sophistication there among sort of the average user in my experience than I than I observe here in the United States.

Start time: 1193.00
End time: 1218.14
Speaker: SPEAKER_04
Transcript:  Well, I think the average person's Michael and then Brianna.  Yeah, sorry.  The average person's relationship with the government and how they use technology and what they're able to see and not see, I think, is much different in China when you compare it to the average US citizen.  So, of course, the government is spying on on American citizens, but not in the same capacity that China is spying on and clamping down on.  Do we know that it's behind the layers?

Start time: 1219.14
End time: 1223.98
Speaker: SPEAKER_02
Transcript:  So do we know that, though?  We don't know it because of the FISA bill.  We don't know what the American government is doing.

Start time: 1225.08
End time: 1237.98
Speaker: SPEAKER_05
Transcript:  We don't have a culture of sort of layers upon layers upon layers of a sort of information network where there are tendrils that may span up through prefectural governors.  It's different here.

Start time: 1238.18
End time: 1268.74
Speaker: SPEAKER_02
Transcript:  Let me ask you this, since you've lived there, Amy.  This month, the Wall Street Journal had this article about the Chinese police adding facial recognition glasses that they can walk around and they can see people and they get immediate facial recognition.  This is the kind of thing Google Glass people were worried about Google Glass because now the average Chinese citizen.  I mean, you did this in America.  Well, that'd be a big deal.  Does the average Chinese citizen look at this and say, oh, that's good.  We're going to be safer.  Or do they say, oh, that's terrible.

Start time: 1269.57
End time: 1314.86
Speaker: SPEAKER_05
Transcript:  Couple things.  First of all, this is this has been reported as though this is some kind of groundbreaking new technology in the 2008.  I think it was World Cup.  This exact technology was and a much slower version of it, of course, and less powerful.  But it was already in use and it was being tested to sort of predetermine who the Rapplerosers are.  Who's likely to cause problems.  China has a very different attitude towards privacy than a lot of other places do around the world.  So there are already systems where if you Jaywalk, you know, you're there's there's facial recognition everywhere.  So if you if you Jaywalk, your face is shown on a sort of digital billboard with your name and your employer.  And, you know, it's a purpose of it is to publicly shame you.

Start time: 1315.16
End time: 1325.80
Speaker: SPEAKER_02
Transcript:  Is it is that considered a good thing or a bad thing?  It's my sense that at least in some parts of China, that's considered a good thing.  That's like, yes, that's keeping order.

Start time: 1326.62
End time: 1360.00
Speaker: SPEAKER_00
Transcript:  That's right. Think about from the other end, though, like you would never have something like Gamergate in China with people sending hundreds and hundreds and hundreds of them.  And they take a lot of pride in that.  You know, I've talked to my father in law about this.  It's just it's a different culture with different priorities there.  I did want to say about the Apple.  You said Apple keeps the encrypted keys stored here in the United States.  Are you talking about the we're talking at the the file that your I cloud with all of your passwords.  We're not talking at your public and private key to actually decrypt everything.

Start time: 1360.12
End time: 1393.39
Speaker: SPEAKER_02
Transcript:  Yes. So remember, during San Bernardino, Apple said to the FBI, no, we won't decrypt the phone.  However, if you had just thought to bring the phone to the guy's house because it's probably syncing to I cloud, most I founds do.  We'd be glad to hand over his I cloud data.  Oh, Apple. Apple has never.  They don't like to talk about it, but they've never hidden the fact that they've always had access to your I cloud data.  Dropbox has access to your Dropbox data.  It's not that Google has access to Google Drive data.  That's typical in these situations.  Your key does not protect you.  It's right.

Start time: 1394.85
End time: 1399.92
Speaker: SPEAKER_05
Transcript:  I don't know why this is a mystery to everybody.  It seems to be.  But it shouldn't be.

Start time: 1401.13
End time: 1418.88
Speaker: SPEAKER_02
Transcript:  But that's why this headline is interesting to me.  Apple moves to store I cloud keys in China.  Well, of course, the Chinese say if you're going to store data of Chinese citizens, it better be stored in China, including the key.  Just as here in the United States, Apple stores I cloud keys in the US and it's available to law enforcement as it would be in China.

Start time: 1419.60
End time: 1429.66
Speaker: SPEAKER_00
Transcript:  I guess I incorrectly assumed that that would be encrypted because you kind of try to do the right thing.  OK, so it is encrypted.  They have to break the encrypted child.  No, Apple has the key.

Start time: 1430.50
End time: 1448.96
Speaker: SPEAKER_04
Transcript:  OK, Apple isn't the point that if a Chinese government official wanted to look at citizens I cloud account, they it would be easier for them to do that now that the keys are based in China rather than having to deal with like the US legal system.  And so that was my takeaway.  It was just that it's much easier for you.

Start time: 1449.14
End time: 1455.66
Speaker: SPEAKER_02
Transcript:  But you're a US company doing business in China.  It would be just as we would demand that they be right.

Start time: 1456.70
End time: 1478.00
Speaker: SPEAKER_05
Transcript:  But you've got to follow the rules of the right local place.  I mean, again, like I just I there's there's a level of sophistication.  I think there's a.  I think I would be surprised if people are storing copious amounts of very sensitive private data on, you know, in China they would know better.

Start time: 1478.16
End time: 1479.92
Speaker: SPEAKER_02
Transcript:  Yeah, that's right.  You're saying that's fair.

Start time: 1480.04
End time: 1481.54
Speaker: SPEAKER_05
Transcript:  I mean, not everybody, but yes, that's that would be my.

Start time: 1482.52
End time: 1488.20
Speaker: SPEAKER_02
Transcript:  So in a way, we're more vulnerable in the US because the general impression in the US is, oh, no, it's an I cloud Apple protects my privacy.  It's safe.

Start time: 1490.00
End time: 1505.86
Speaker: SPEAKER_05
Transcript:  Life is a lot easier here.  And it gets, you know, and we just lack we lack the skepticism that I see in other places.  And we sort of blindly follow the the edicts that we see on our screens without stopping to think for a few minutes about the consequences.

Start time: 1506.00
End time: 1525.25
Speaker: SPEAKER_02
Transcript:  So and it is the case that China's process for looking at that data is different here in the United States.  You need a legal entity with a warrant or a subpoena or an NSL.  In China, it's not quite as difficult for authorities to demand those keys.  Court approval isn't required under Chinese law.  So the police can just do it.

Start time: 1526.00
End time: 1552.72
Speaker: SPEAKER_05
Transcript:  Now, here's something interesting.  The GDPR goes into play in Europe in a couple of months.  This is a huge sweeping privacy regulation.  So I'm sort of now curious to find out how how key chain.  How does that work going forward?  I mean, how many different you know what I mean?  From a practical point of view, like how many times do you have to have to authenticate and how do they ensure the encryption?  And so that it still meets the standards of all that that regulation.

Start time: 1553.78
End time: 1565.36
Speaker: SPEAKER_02
Transcript:  Yeah, because businesses are required to protect that personal data.  That's very interesting, isn't it?  I imagine the EU will require that iCloud data be stored in.

Start time: 1567.15
End time: 1578.69
Speaker: SPEAKER_05
Transcript:  Or maybe that's why they're doing it in China.  I don't know. Or maybe that's partly why it's, you know,  Maybe everybody's in Europe will have their data stored in China to get around some of just the complicated issues.  I don't know.

Start time: 1579.58
End time: 1592.62
Speaker: SPEAKER_02
Transcript:  You know, there are a lot of there's a cloud service Dropbox like service called Tresor.  It T-R-E-S-O-R-I-T and they trump it.  We're in Switzerland.  So you're safe.

Start time: 1593.92
End time: 1595.51
Speaker: SPEAKER_05
Transcript:  But it worked out really well for everybody's bank.

Start time: 1598.60
End time: 1616.40
Speaker: SPEAKER_02
Transcript:  I think in general, in the long run, the trend is away from GDPR.  But I'm actually at first I was a little skeptical of EU regulation of American companies.  But now I'm starting to think they're the last.  That's the last stand.  That's our last chance to protect our privacy.

Start time: 1617.12
End time: 1624.94
Speaker: SPEAKER_00
Transcript:  I mean, I've had a lot of talks about how we would pass something like an omnibus privacy bill here in the United States.  Is there interest in that?  Is there? I'm sorry, I missed that.

Start time: 1625.06
End time: 1626.49
Speaker: SPEAKER_02
Transcript:  Is there an interest in that? Is that going to happen?

Start time: 1627.60
End time: 1667.00
Speaker: SPEAKER_00
Transcript:  I think there is what consumers, especially the people that donate to my campaign, the question is like, could we actually get something like that through Congress?  Because it's not I don't think from the lawyers I've talked to the tech subcommittee would have the authority to do that.  So, you know, I think what I think we need in the United States is I think we need to realize that most of our laws about privacy and online behavior were passed in the 90s.  And I think we need a fresh look at that.  I just don't know if this Congress will ever have the will to do something serious.  So I think when you're looking to Europe, if they're taking steps forwards, you know, I'll take that.

Start time: 1667.22
End time: 1670.47
Speaker: SPEAKER_02
Transcript:  GDPR goes into effect in May, and I would bet there'll be quite a reckoning.

Start time: 1673.12
End time: 1740.00
Speaker: SPEAKER_05
Transcript:  Yeah, this is this is not.  So I've been talking about this for a while.  You know, we're going to wind up with a serious we're going to wind up with a splintered Internet, right?  Where we have we have Internets that are defined different versions of the Internet with different versions of content that's defined by geographic borders, which is going to make our current fake news nightmare a insurmountable headache.  But it also makes it the cost of doing business, the practicalities of doing business.  I mean, it's just it could exponentially change in a in a sort of very negative way how all of us access information and each other.  Right. So that's that's that's, you know, and I don't know if if even more regulation regulation and absence of, you know, sort of helping people gain digital literacy.  Right. So the laws haven't changed in the 90s, but I don't think a lot of people have changed either in their approach to what they're sharing and how they're sharing information and what their expectations for their privacy is.  And, you know, some of the onus has got to be on us to which can't just all be about regulation.

Start time: 1740.28
End time: 1809.98
Speaker: SPEAKER_00
Transcript:  I you know, I understand that point and I really understand where you're coming from.  But I think when you look at something like Facebook, I don't think Facebook is ever going to change.  I think we can write all the headlines in the world, shaming them about their business practices.  I don't think they're ever going to do the right thing.  I think Facebook has grown so large and I think their leadership is really divorced from the reality of the octopus that they've created.  Talk to people that own media companies like Facebook has really, really, really been bad for most media companies.  And I think you look at their role in the election and a real failure to have accountability about Russians buying ads on their platform.  You know, here in Boston, if a Russian bought an ad for a certain political candidate, that television station would be in jail.  And the fact that we don't have those same laws online, I think we've got to take a fresh look at this.  And I tell you, I really get it. I understand it.  For someone that's run a business, it's really bizarre to be running for office and to start being the one talking about regulation.  I just don't see like a lot of these companies ever doing the right thing.

Start time: 1810.56
End time: 1822.00
Speaker: SPEAKER_02
Transcript:  It's very challenging. I agree with you, Amy, that individuals are responsible.  But at the same time, companies like Facebook should, I don't think should be allowed to run roughshod over people's privacy.

Start time: 1823.49
End time: 1847.88
Speaker: SPEAKER_05
Transcript:  The problem is that anytime we try to, here's the problem with regulation.  Regulation and policy are written by people in such a way so that it passes, right?  And what you wind up with is highly specific limiting language because anything that's too broad can't make its way through.  And so we just constantly have regulation that's out. Like the moment that it gets passed, it's outdated.

Start time: 1849.05
End time: 1851.92
Speaker: SPEAKER_02
Transcript:  So is the political process you're saying is inadequate to do this?

Start time: 1852.56
End time: 1871.00
Speaker: SPEAKER_05
Transcript:  I'm saying we need to work. I mean, listen, Brianna, I totally, you know, I support you and I, it would be awesome.  If you got to Congress and made some positive changes, that'd be amazing.  But, you know, we also just as individuals need to need to come up with some workarounds.

Start time: 1871.94
End time: 1898.76
Speaker: SPEAKER_02
Transcript:  And, you know, it may end up being I mean, ultimately, that's also the solution to fake news that people say.  Well, it's really going to be up to individuals. You can't stop fake news.  It's going to be up to each and every one of us to be more critical.  But at the same time, I think the reason the GDPR, the General Data Protection Regulation in Europe exists is because the United States has abrogated its duty.  A GDPR is aimed at American companies.

Start time: 1899.12
End time: 1899.73
Speaker: SPEAKER_05
Transcript:  Sure. That's right.

Start time: 1900.97
End time: 1961.00
Speaker: SPEAKER_00
Transcript:  I feel like I did just want to add one point of fact here.  I think I would encourage people. I understand the fear that like if you got all of Congress to vote on a technology bill.  My God, those people have no idea what they're talking about.  I understand that. But the way that Congress works and the way that the Senate works is when you're elected, you get assigned to certain subcommittees like Al Franken was assigned to the judiciary.  I hope to serve on the technology subcommittee.  And then you have a group of interested people, hopefully with some career experience in that field, to kind of read about an issue and understand it.  So it's not like this hodgepodge of like useless stuff.  So I do think that when I do think that government at its best can write good law that is well informed by the facts.  I just think currently the people serving on that all too often serve powerful.  As we have seen with our discussion on net neutrality, you have Verizon and AT&T sure gave those people a lot of money for their elections.

Start time: 1963.60
End time: 1974.00
Speaker: SPEAKER_02
Transcript:  I don't want to throw out the political process because if you say well, the political process is inadequate to it, then you have zero regulation.  Amy, is that what you're proposing?

Start time: 1975.67
End time: 2053.98
Speaker: SPEAKER_05
Transcript:  No, the challenge is, so my job is to think very, very far into the future.  So the problem is that right now, so deep fakes, we all remember what started as the porno fakes with people's faces.  So here's the problem. This raised all these thorny issues that I haven't heard anybody discuss.  And as a result, so first of all, who owns your face?  Well, that's not clear.  I went through with a fine tooth comb all of Facebook's terms of service and every part of the website that addresses nudity and people that would have addressed the issue of deep fakes.  Same thing for Twitter. Twitter, you know, nowhere.  So basically nobody broke the terms of service on Twitter.  And for Facebook, did you guys see that if you feel like you've been a victim of revenge porn or deep fakes, their solution at the moment, the last that I read was that you have to use Facebook Messenger to send in a completely nude photo of yourself.  That was their proposal. That was a nutty idea.  Well, that's being piloted in Australia, as far as I know.  So, I mean, here's the problem. The problem is that the platforms are constantly absolving themselves of any blame.

Start time: 2054.52
End time: 2058.72
Speaker: SPEAKER_02
Transcript:  They're saying we're platforms. We're not responsible.  That's right. But our current...

Start time: 2060.18
End time: 2088.76
Speaker: SPEAKER_05
Transcript:  So here's the problem. You know, who owns your face? Who owns what gets to be done with your face? If your face is you, how do you get your face back?  Right. And I could list like 20 legal questions for which we have no answers and there's no debate and there's no policy and, you know, nobody's discussing that.  And I could do the same thing for, you know, various aspects of machine learning and who owns these different parts of your data and the decisions that are made.

Start time: 2089.12
End time: 2111.00
Speaker: SPEAKER_02
Transcript:  Get ready for HR 1865, allowing states and victims to fight online sex trafficking act of 2017, which in effect makes websites responsible for the content posted on the website.  It is a complete overreaction, but it means that every website will be responsible for anything that is posted on that website.

Start time: 2111.86
End time: 2123.00
Speaker: SPEAKER_05
Transcript:  Which will become a First Amendment fight because somebody will make the case that it's limiting... you know, it's hindering and unnecessarily limiting the expression of free speech in the comment section.

Start time: 2123.32
End time: 2137.98
Speaker: SPEAKER_02
Transcript:  A provider of an interactive computer service that publishes information, I'm reading from it, provided by an information content provider with reckless disregard that the information is in furtherance of a sex traffic offense to be subject to a criminal fine or imprisonment for not more than 20 years.

Start time: 2138.04
End time: 2212.92
Speaker: SPEAKER_05
Transcript:  Great, so who's going to end for... I mean, good luck in porn. Here's the problem. Here's the problem. The deepfake sites. So it takes like three, you know, motherboards did really great reporting on this.  So if this is something listeners are interested in, I would strongly suggest you take a look at their reporting. You know, so here's the thing.  Finally, Pornhub and finally Reddit take down the thread where this is all being discussed and how to guides are being shown. But there are clones everywhere.  Everywhere. You can throw a rock on the Internet and hit a website where you can find somebody who's willing to make a deepfake for you, you know, because out of the goodness of their heart or for, you know, a fraction of Bitcoin.  So the problem is you can't you can't regulate an idea. And that's the problem that we keep coming back to in the United States over and over again. That is our current problem with the Second Amendment.  That's going to become a problem with our Fifth Amendment and various different kinds of technologies. It's a problem with deepfakes. Once the idea is out there, it's very, very difficult to draw it back in.  And all of the technology that makes us so productive and enhances our lives in so many ways, you know, can fork and take us all in a different direction. That's that's the problem.

Start time: 2213.60
End time: 2270.96
Speaker: SPEAKER_04
Transcript:  I hate to say, but I sort of disagree with that. The notion that you can't regulate or stop an idea, you know, like I think you can look at even just like copyrighted MP3 sharing.  You know, that was something that was a problem. I think people identified it. Some people made the case that you're making now, which is like, well, cats out of the bag.  People know how to share peer to peer and the Internet's only getting faster. The demand for audio is only getting is only growing.  And so the second Napster came on the scene, you couldn't put all this stuff back into into the box.  The reality is that we've kind of solved that issue now. You know, most people use streaming services rather than rather than downloading illegal MP3s as they once did.  I think in the case of deepfakes, you know, you can't you can't make an idea illegal, but you can make the act of creating fake pornography illegal.  I don't think that's out of line. Sure. You could totally do that.

Start time: 2273.00
End time: 2340.98
Speaker: SPEAKER_05
Transcript:  My point is that there was that's like fighting last yesterday's war. Right.  So sure, we just could get together tomorrow and come up with a, you know, the House could pass a deep fake bill.  That the problem is that in order to get that legislation through, you're using language for something that's already happened, not for the next third, fourth and fifth and sixth things that will happen.  And just going back to to the MP3 sharing for a minute, the piracy process.  Well, but, you know, so so Canada has legislation on the books that makes it illegal and finable for anybody to post anything that's pirated on Google.  So if I search in Canada on something and I see a pirated version of it come up, that's illegal.  And that's in direct response to the fact that they are, you know, you may not.  So peer to peer file sharing may not have may not be super popular in the United States anymore because people can stream.  But that's not the case elsewhere in the world. Right.  And that's that we keep losing perspective on, you know, just because something no longer is attractive or popular here in the United States.  You know, we have this sort of recency phenomenon where we forget that maybe things are not, you know, maybe things are a little different elsewhere.

Start time: 2343.05
End time: 2377.98
Speaker: SPEAKER_04
Transcript:  Of course. But we're talking about U.S. policy and lawmakers, you know, taking responsibility for the things that are happening online.  I think, you know, as you said, like, sure, they're they're solving a problem that is sort of that's already happened in there and and they're sort of losing ground on the next big the next big battle here.  But but I think that's kind of how that's kind of how law the law system works.  So like the the political system works, you know, we can't the lawmakers job is not to predict, you know, future crimes.  I mean, to some extent, I totally, totally disagree.

Start time: 2378.42
End time: 2467.96
Speaker: SPEAKER_05
Transcript:  I totally agree. We we had we've had offices whose express job it was to and that is what strategic foresight is to map out, given what we know to be true today and all of the data that we have, what's likely coming and to monitor that and then write policy so that we can keep track.  Technology is evolving so quickly that it can no longer keep up with.  I'm sorry that the policy can no longer keep up with technology the way that it has in the past.  And just really quickly on the Internet. So we don't see the Internet as sort of as the commons the same way that we do the the air overhead.  Right. So so with different ecological and environmental issues, we have multinational stakeholder groups where there are global scale regulations and not entirely enforceable in the way that a traditional law might be.  You know, if you break that, that the penalties may be enforceable.  But we we absolved ourselves of that with the Internet.  So there is no, you know, there there are different groups here and there, but we don't have global treaties.  We don't have global regulatory policy.  So even if we were to pass a law in the United States and it became illegal to create a deep fake, you know, here, there's nothing preventing somebody from doing that exact same thing and having it show up in the exact same way.  You know, as long as they were outside of the boundaries of the United States.

Start time: 2468.62
End time: 2560.44
Speaker: SPEAKER_00
Transcript:  So I feel like I need to add something here because this isn't hypothetical for me.  I actually I know the people at the very forefront of working on this area of legislation.  Her name is Maryam Frank. She's one of the most brilliant lawyers in the United States.  I've worked with her on this at Harvard and she herself, like the person that's on the forefront in trying to figure out the legal apparatus for fighting this.  She's not 100 percent on the side of government regulation.  Like she talks to Google all the time about updating their policy.  She talks to Reddit. She talks to Facebook.  Then she goes and tries to work with local law like here in Massachusetts.  She wants to give prosecutors more power.  So I think with all respect to your point, I understand like globally, there's not one single solution you can point to.  What something like this is going to require is exactly what Maryam is doing.  She's looking at the problem for a large legislative point of view and she's walking working with all the involved actors.  So like Google, if Google will like remove certain things from the search results because they agree it's an invasion of privacy, then you know that reduces some of the risks.  So it's it's a very difficult problem to solve.  Like just talk to her. She spends all of her time doing this.  But I mean, I certainly think you're seeing her move forward on that.  And I think the situation with revenge porn is much better than it was five years ago because she didn't like shrug her shoulders like she got in there and worked with the law and start making a difference here.

Start time: 2563.54
End time: 2588.00
Speaker: SPEAKER_02
Transcript:  It's a challenge.  It's a big challenge.  And you know, we don't want I frankly think it's virtually intractable.  And yet you don't want to give up.  You need to try to make some steps.  You need to try to do something because the alternative is to give up.  You're not saying we should give up, Amy.  You're saying we should think more, be more forward thinking.

Start time: 2588.06
End time: 2634.11
Speaker: SPEAKER_05
Transcript:  That's absolutely right.  I'm not saying to give up and I don't mean to sound like a fatalist.  What I am saying is, you know, the problems that we are going to face over the next 10 to 20 years are nothing, you know, are orders of magnitude more complicated than we've seen thus far.  And it's going to require very smart people like, you know, like Brianna and like, you know, I think that there's a new crop of people who are running for Congress.  There are people who are in Congress who are very smart.  There's people who are writing policy.  It's just going to require a different approach.  And there is an inherent tension between the way that we have always created policy and law and the current ways in which we share information.  And use technology.

Start time: 2635.30
End time: 2704.72
Speaker: SPEAKER_02
Transcript:  I would submit that you are a stakeholder in this, Amy.  Your focus is in the future.  That absolutely has to be considered.  The women who are today victims of repent, revenge porn and fakes also are a stakeholder and need to be considered.  The challenge, Brianna, that your friend faces is you also have to consider Google.  You have to consider kind of bad ideas like FOSTA, which is going to be, by the way, HR 1865 is going to be voted on.  On Tuesday, this is not hypothetical.  It's not in committee.  This is going to be this is about to vote.  These the House of Representatives about to vote on this.  This is a bad idea.  And there are plenty of those as well.  But I think we need to find a way forward.  And the sad fact, maybe that's a hopeful fact.  I don't know.  The fact of the matter is we are faced right now because of the speed that technology is changing our lives in so many ways with artificial intelligence.  You know, self driving cars, free speech.  We are faced with very difficult challenges.  That's why, by the way, Brianna, I hope you win and I hope you understand what you're getting yourself into, because this is a mess.

Start time: 2705.71
End time: 2742.14
Speaker: SPEAKER_00
Transcript:  And I look at that bill you just mentioned, Leo.  I would vote against that bill and I would have no problem with that.  And I know I would take a lot of heat for that.  It's a terrible solution.  But I would say this, you know, all respect to the generation that's older than me.  I do think that if we new generations come up and take the helm and it's it's my hope.  Maybe this is idealistic, but it's my hope that like the next generation is going to have less of a ruthless approach to problem solving.  And maybe maybe we can like change the culture in Congress.  You know, it certainly is a scorched ed, scorched earth approach anyway.

Start time: 2743.14
End time: 2826.03
Speaker: SPEAKER_02
Transcript:  Yeah. Yeah.  We're so unfortunately polarized over this.  It's impossible to make headway in any direction.  We had a very good interview on Friday in triangulation with Andrew Keene, who's for a long time said the Internet is broken and has written a new book on what we needed to fix it.  And essentially, that's his position.  He says this is very similar to the Industrial Revolution, where you had technologists and you have them today who are very hopeful that technology will just solve all of this.  There's no need for regulation.  It'll all be fixed.  There'll be universal income.  Everything will be super cheap.  It's all going to be fine.  Don't worry.  There are the naysayers who say this is all a mess.  Let's destroy the looms.  Let's go back to the past.  Well, let's get kerosene and light the homes that way.  And then there's the he calls them the maybes that the people in the middle.  And this is what you need to be.  This is what we all need to be.  People who understand this is a very difficult problem, but not throw up their hands, not assume that it's going to happen by itself, but actually dig in and have these discussions and see what we can do to fix it.  And you can't expect agreement.  And I guess I worry one of the things that worried me that Amy that you said was that the legislative process is essentially political.  It is about compromise.  But that's a necessity.  I don't think you can write the perfect law.  Do you think that that's it?  That's a failing?  That's not that means it won't have won't work.

Start time: 2828.52
End time: 2964.94
Speaker: SPEAKER_05
Transcript:  I was at the state of the net, which is so there's this conference that happens and this gathering annual gathering in D.C.  And I don't know if over the first two hours, I must have heard the word bot like, you know, uttered by senators and, you know, really, really like top level people.  And I got to the point where it was like, I don't think everybody understands what that word means.  I don't think it means exactly right.  That's exactly right.  And here's why I found that so concerning, because if our and I don't expect every lawmaker to have a very high level understanding, deep level understanding of all different technologies that they could possibly regulate.  However, our legislative process is necessarily slow.  And that's a good thing.  We don't want our laws changing every five seconds.  The challenge, however, is that technology is becoming complex and it is presenting us with questions that we have never had to ask or an answer before.  You know, we talk about artificial intelligence.  It's not just automation that for me, this is the area that I research.  The thing for me that's most concerning has to do with autonomous decision making, you know, by machines that don't share conscious don't have consciousness the way that we do.  So machines are, you know, are making sort of non conscious decisions, which is which will be the first time in humanity that's that's ever happened.  And the problem is that questions like who owns your face, right, will seem childish today, you know, compared with the direction that we're headed in.  And if I have a lawmaker who five years after the fact is having a hard time explaining to a group of technologists what a bot is, that signifies to me that we need to come up with, you know, we need for sort of the grand scale, you know, issues in society are currently happening.  Our current system works, you know, works.  But when it comes to technology, we need to think of we need to think of alternate methods to have faster, smarter conversations, stakeholders who are not just tied to the commercial sector and who are not totally politicized.  Right. It's a tall order, but it's a very tall order.

Start time: 2965.06
End time: 2999.58
Speaker: SPEAKER_02
Transcript:  And my fear is that if you get too negative about it, then what happens is you leave the democratic process behind.  Because an authoritative process, authoritarian process is very good at handling this and can move very quickly.  Maybe not. Yeah.  And maybe that's not the right answer either.  Yeah. Yeah.  Michael Nunez is here from Mashable.  I'm going to give you the final word, Michael, because we've been hogging the conversation before we take a break.  Isn't it fascinating?  And I try not to get depressed by it.

Start time: 3000.34
End time: 3003.37
Speaker: SPEAKER_04
Transcript:  Yeah, I also I kind of forgot I was on the show for a second.  I was back.  Yeah, me too.

Start time: 3004.06
End time: 3006.27
Speaker: SPEAKER_02
Transcript:  I'm listening. Yeah.  Two smart people.  Yeah.

Start time: 3007.00
End time: 3029.68
Speaker: SPEAKER_04
Transcript:  I think just to clarify my point, you know, it's not that lawmakers shouldn't be thinking about the future.  Of course, they should be doing that.  But laws are often written based on precedent.  Right. So it's things happen and then lawmakers react.  And I think that's just the sort of realistic expectation that I've come to learn.  I think, you know, to Amy's point about what to expect in the future, I think it's the PP tape.  I think it's the Donald Trump P tape.  I'm surprised that that hasn't surfaced already.

Start time: 3030.00
End time: 3031.47
Speaker: SPEAKER_02
Transcript:  What does this have to do with the P tape?

Start time: 3032.04
End time: 3032.96
Speaker: SPEAKER_04
Transcript:  Well, it doesn't matter.

Start time: 3033.02
End time: 3035.73
Speaker: SPEAKER_02
Transcript:  Let's talk about it.  Which may or may not exist.

Start time: 3037.42
End time: 3044.92
Speaker: SPEAKER_04
Transcript:  Well, it probably who knows whether it exists in reality.  But things like deepfakes and AI generated.

Start time: 3046.24
End time: 3052.19
Speaker: SPEAKER_02
Transcript:  Do you think we're being set up so that they could say that's a fake if it should emerge?  Is that what you're saying?

Start time: 3053.60
End time: 3064.00
Speaker: SPEAKER_04
Transcript:  Yeah. I mean, I'm not in the conspiracy.  It's a good theory.  You're saying that.  But I think that it would be, I think it's realistic to expect a video like that to surfaced.

Start time: 3064.56
End time: 3102.77
Speaker: SPEAKER_02
Transcript:  In a larger scale, here's what I think you're saying that is, I think, really important.  And it's the sad state of affairs is that we've set up all of these things that if people are good and benevolent and wonderful,  are good and benevolent and wonderful.  YouTube, Facebook, Twitter, on and on and on.  Many of the great technologies we've created.  What we didn't countenance and plan for is people who aren't good, people who are motivated in a variety of different ways.  And they have discovered technology and have discovered ways to bend it.  That are problematic.  But that's always happened with every technology.

Start time: 3104.72
End time: 3143.24
Speaker: SPEAKER_05
Transcript:  You know, every technology that has always been created with benevolent purposes in mind has taken a turn for the evil.  Because humans suck.  So what do you do about that?  Prepare and advance.  Prepare for the suck attitude?  Yeah.  No, no, but this is my whole point.  We have people in Washington, D.C. who are not thinking, not assuming that at some point the catastrophic scenarios are plausible.  And if you're not in that headspace, I'm not saying to be negative all the time, but you have to acknowledge the possibility that these things could happen.  Right.  Or something bad.  Well, and then acknowledge that you can't stop it.  No.

Start time: 3144.35
End time: 3224.74
Speaker: SPEAKER_00
Transcript:  No.  So then what I can 100% promise you, Amy, is as someone that's doing this every single day, I promise you they have no idea.  They have no idea what deep fakes is.  They have no plan for this.  And they just this is the fundamental problem is they see it as they hear people with IT knowledge as someone with it's like a backup singer that they can hire and bring in to solve the problem.  They have no stake in this problem by themselves.  And it is I'm telling you, this is someone who's a software engineer and someone who like stopped to get involved and do this.  And I am so depressed by the level of technological literacy that I see in government.  But that's why I need everyone on Twitter that's listening to this to realize the process needs you like get involved.  Go run for your town committee.  Go sit on your local political party council, especially if you're a Republican Republicans.  We need Republicans that care about these issues.  Like, let's the thing I found is technologists generally agree on a certain core of things, no matter what political party we belong to.  So, Amy, I really agree with you is worse than I possibly could have imagined.  But that's why we have to not get cynical and get involved.

Start time: 3225.49
End time: 3306.43
Speaker: SPEAKER_02
Transcript:  All right.  That's a good way to put it.  And we're going to take a break at that on that note.  This is a conversation.  It's interesting.  It's happening more and more on this network.  I think that we are all kind of aware of this now.  And we're wondering what what to do.  My fear is that we'll at some point abandon a democratic policies and become a technocratic state because I think there's there's going to be a feeling at some point that only the technocrats can solve this.  And the Mark Zuckerbergs of the world are going to step up and say, I'll take care of this.  The Jeff Bezos of the world said, you know, you know, I understand how this works.  Just let me take care of this.  And I do see that as being one of the possible scenarios that respond to all of these problems that we're talking about.  And it's one that I don't think would be a very good path to go down.  But there we go.  Let's take a break. We've got a great panel.  As I said, Michael Nunez from Mashable.  Great to have you.  Michael Brianna Wu.  Congress running for Congress.  The primary has been set September 2018.  If you're in the Massachusetts, you know what I think.  You know what about for an Amy Webb, the author of The Signals are talking why today's fringe is tomorrow's mainstream.  And we'll be very interested to see the FTI trend report when it comes out.  Is there a place people can go to order it now to get on the list now?  Yeah, well, we give it away.

Start time: 3307.00
End time: 3313.48
Speaker: SPEAKER_05
Transcript:  So it's free.  So if you go to futuretodayinstitute.com, there's a link to it from the front page.  Fantastic. Thank you.

Start time: 3315.80
End time: 3443.07
Speaker: SPEAKER_02
Transcript:  Our show today brought to you by Audible.  If some of this gets you down, here's some good news.  You can listen to a great book, a work of art that can take over your life and your mind and give you respite.  And believe me, I do it every single day.  Thanks to Audible.  There's plenty of time.  Reading is great.  But my problem is, as I think probably a lot of you, life took over and I didn't have enough time to read.  But Audible fills those holes in your day where you can't hold a book, you can't read, but you could listen to a book when you're driving to work, when you're walking the dog, when you're doing the dishes or the yard work.  And Audible is such a great solution for that.  I am very excited about there's a couple of books I'm looking forward to.  I already got on the wait list for this one called Tangerine.  It's a novel that sounds fantastic.  It's a preorder.  But then I do listen to a lot of nonfiction as well.  I mentioned that I'm watching rewatching HBO's Band of Brothers and I thought, you know, I really ought to listen to the original Stephen Ambrose book.  In fact, there's a ton of Stephen.  Ambrose is one of my favorite historians.  Isn't he great?  And there's a ton of Ambrose works, including Band of Brothers, that you can listen to.  Audible always has the best narrators.  That's one of the things you might say, oh, I don't know.  I don't want somebody droning into my ear.  I can't listen to a book.  Yes, you believe me.  In some ways, listening to a book is the best way to absorb a book.  I just I just love it.  And so many great books.  Here's what we're going to do to get you started.  If you're a little I don't know, is this for me?  We've got a great offer for you.  It's called the Gold Plus One Plan.  You're going to sign up for the Gold Plus One Plan at audible.com slash twit two.  Here's how it works.  You're going to get two books to start and then a 30 day free trial and a book a month after that.  Two books to start means you don't have to do the tough thing of picking just one.  And I can tell you that's always tough for me.  I have a huge library of audible books.  I've been an audible subscriber since the year 2000.  So I have over 500 books.

Start time: 3445.06
End time: 3455.79
Speaker: SPEAKER_00
Transcript:  And I've been once since 1998.  You beat me.  Well, what are you listening to, Brianna?  All right. I've got my phone right here.  Lost Camp of Girls Forever.  That's really good.  Lost Camp of Girls Forever.

Start time: 3457.12
End time: 3457.96
Speaker: SPEAKER_02
Transcript:  That sounds scary.

Start time: 3458.63
End time: 3479.99
Speaker: SPEAKER_00
Transcript:  It's really it's really scary.  And Persepolis Rising.  That's the new James S.A.  Corey novel.  You know, The Expanse is on Syfy Channel.  Yes, The Expanse is so good.  Oh, I love it.  But the books are so much better.  Leviathan Wakes is probably one of the very best books on audible.  And so is Snow Crash.  Like you should sign up and just listen to those two.  Oh, I love both those books.

Start time: 3481.28
End time: 3543.94
Speaker: SPEAKER_02
Transcript:  And in fact, I have amazing both those books on audible.  So I am with you 100 percent on on that.  And if you want something a little cheerier to improve your outlook,  I listen I like to listen to nonfiction to the Steven Pinker book.  The Better Angels of Our Nature really will make you feel better about today.  It'll really cheer you up.  Bill Gates recently picked Steven Pinker's new book as his favorite book of all time.  Enlightenment Now.  That's on there too.  Here's the deal.  Go to audible.com slash twit to get yourself two free books.  I think we've talked about eight now.  But anyway, pick two and then one book credit per month.  It is a great deal.  30 day free as with all the free subscriptions, you get the Wall Street Journal  or the New York Times Daily audio program.  So you have more to listen to.  The offer is good in the U.S. and Canada, but audibles all over the world.  So if you're in another country, don't hesitate to go to audibles.com.  If you're in another country, don't hesitate.  Try it anyway to get two free audio books and a free 30 day trial.  Audible.com slash twit to audible.com slash twit to you've been a member since 1998.  Brianna, you beat me.  I thought I was the king.

Start time: 3544.71
End time: 3552.00
Speaker: SPEAKER_00
Transcript:  No.  Do you remember when you had to get the Rio 500?  That's what I had to get the compact flash for that data proprietary thing.

Start time: 3552.00
End time: 3554.18
Speaker: SPEAKER_02
Transcript:  I think they call the auto.  Do you remember that?  I do.

Start time: 3555.40
End time: 3560.94
Speaker: SPEAKER_00
Transcript:  Do you remember burning your own CD?  Yes.  It would fail three fourths of the time.  Oh my gosh.  I love audible.

Start time: 3561.72
End time: 3612.00
Speaker: SPEAKER_02
Transcript:  I started listening to audiobooks when you had to get cassettes and that was really a  lousy experience because you only had a month for one thing and you had to mail them back.  The cassettes, one would break, right?  And they say, oh, no problem if one breaks, just mail it in and we'll send you a new one.  But I'm stuck in the middle of the book now.  I can't move on.  It's frustrating.  Audio is so much better when you can download it.  One of the nice things about audible, you get the book right away.  If you say, oh, I got to read that, you're reading it five seconds later.  So that's really nice.  Audible.com slash twit to thank them for their support of twit.  They make it all possible.  We should pick something more cheerful.  We kind of went down a bad road there, but I think we do that more and more lately because  I think that these things are coming up more and more often.  Frankly, this has become one of the issues in our lives.

Start time: 3613.69
End time: 3639.59
Speaker: SPEAKER_05
Transcript:  I think people are feeling anxious.  Yes.  Wonder why.  Well, we sort of crossed over into this weird territory.  And I think regardless of where you are on the political spectrum, after the last election,  I think things have, we're sort of in unfamiliar territory.  And I think people are just feeling more anxious in general, you know, on technology and the  economy and politics.

Start time: 3641.24
End time: 3679.00
Speaker: SPEAKER_02
Transcript:  Yeah, I think though, even if that hadn't happened, I think people would be feeling  badly right now about social media.  That certainly accelerated it.  But I think we're starting to see this.  Andrew Keen, I was talking about on Friday, calls it surveillance capitalism.  He says Google and Facebook, who are getting massively, you know, there was a good article  in the Sunday Times by Charles Duhigg, the case against Google.  It's so big now that it needs to be regulated, that you just can't let a company become that  dominant.  I think more, I'm more worried about Amazon.

Start time: 3679.70
End time: 3682.88
Speaker: SPEAKER_05
Transcript:  I was just going to say, I'm surprised that, you know, Amazon is more clever.

Start time: 3683.22
End time: 3688.31
Speaker: SPEAKER_02
Transcript:  That's why I'm more worried.  Jeff's smart.  Oh, my God.  Azos is smart.  Oh, yeah.

Start time: 3689.02
End time: 3704.69
Speaker: SPEAKER_05
Transcript:  And if you stop and think about, they don't currently butt up against any antitrust legislation  or laws because of that.  No, because they're totally diversified.  But you know, Amazon is a health care company.  Amazon is a credit card company.  Amazon, you know.

Start time: 3705.81
End time: 3770.96
Speaker: SPEAKER_02
Transcript:  Although interesting, somebody in the chat room was we were talking about the Samsung  at the beginning of the show, said if you go to Korea, Samsung is everywhere.  They're 30% of the GDP.  He said, my friends in Korea have the Samsung Health Plan.  They go to a hospital run by Samsung.  The school is sponsored by Samsung.  Their refrigerator and washer and dryer, Samsung.  This is certainly the case in other countries that these corporations are getting more and  more dominant.  In fact, remember Korea prosecuted Samsung's CEO for bribery, put him in jail.  They just let him out.  Yeah, you know, I just I worry that we're headed in that direction.  We're headed towards a technocracy.  I really do.  Here is something cheerful.  See, we got the depressing thing again.  Let's talk about gadgets.  A hundred and fifty new emojis.  Yay.  This is from Emojipedia.  There's a party face, a woozy face.  Wait a minute.  Wow.  Finally.  There's a lotion bottle.  There's a what?

Start time: 3771.00
End time: 3772.00
Speaker: SPEAKER_05
Transcript:  There's a lotion bottle.

Start time: 3772.31
End time: 3772.86
Speaker: SPEAKER_02
Transcript:  A lotion bottle.

Start time: 3773.45
End time: 3774.90
Speaker: SPEAKER_05
Transcript:  What?  I don't know what that's for.

Start time: 3775.02
End time: 3805.51
Speaker: SPEAKER_02
Transcript:  I think that goes with the whole cosmetics kit.  Cold face and hot face.  Ginger.  You finally.  Yes, you finally have an emoji for you, as do curly haired people and old folks like  me, white haired people and bald people.  There's a picture for an emoji for you.  There's a super villain.  Yeah.  I don't know.  Is that fair to say the super villain, the superhero look a lot alike?  I don't.  There is a completely weird disembodied leg.  Everybody needs a leg.

Start time: 3808.83
End time: 3819.67
Speaker: SPEAKER_05
Transcript:  When do you need to send somebody a leg?  What's the short hand?  What are you shortening in your sentence?  It's a major award.  I run a lot.  I could see myself texting my husband, this is what I need you to do.  This is why I injured this week.  Rub this.

Start time: 3820.00
End time: 3821.00
Speaker: SPEAKER_02
Transcript:  This is what I need you to do.

Start time: 3821.88
End time: 3830.96
Speaker: SPEAKER_00
Transcript:  Yeah.  There's also feet.  Disembodied.  Now, there's a weird one.  Tooth and bone.  I don't know.  I don't know.  I don't know.  I don't know.  I don't know.

Start time: 3831.02
End time: 3932.82
Speaker: SPEAKER_02
Transcript:  I don't know.  I don't know.  I don't know.  I don't know.  There's also a weird one.  Tooth and bone.  Okay.  These, by the way, this is an arduous process they have to go through.  The emojis are determined by the Unicode committee.  In fact, Jeremy Rouge, who founded Emojipedia, this video is from Emojipedia, has been on  our show many times.  He is part of the Emoji committee.  They receive proposals for emoji from all over the world.  They have to then narrow them down and approve them.  So, you're looking for emojis that are of universal, international import.  And lab coat and goggles?  Sure.  Hiking boot and a flat.  That is a paramecium.  And there's a mosquito and a parrot.  A badger and a peacock.  A swan and a strange black and white raccoon.  Is that a Japanese raccoon?  A Chinese raccoon?  I've never seen a raccoon look like that.  By the way, these renderings are not official.  This is just what the Unicode committee proposes as a reference.  But everybody, Twitter, Google, Facebook, Apple, all design their own.  And they won't look just like this.  Kangaroo.  Okay, now Andy Iannacco on our MacBreak Weekly show, he's in New England.  He had to point out that lobster has been cooked.  That is not a healthy lobster.  That is a cooked lobster because it's bright red.  Do we need a green lobster?  Let's see.  We'll see if Apple does one that's not cooked.  Hippopotamus.  And the leg makes its strange reappearance.  Now it's hippo.

Start time: 3933.70
End time: 3936.42
Speaker: SPEAKER_05
Transcript:  Hippopotamus has got long, luxurious legs.

Start time: 3936.44
End time: 3948.47
Speaker: SPEAKER_02
Transcript:  It's a very elegant hippo.  As is the llama.  There's food, leafy greens, cupcakes and bagels.  There's a mooncake.  What is that?

Start time: 3949.31
End time: 3950.96
Speaker: SPEAKER_00
Transcript:  I don't know.  I didn't tell you.

Start time: 3951.66
End time: 3955.24
Speaker: SPEAKER_05
Transcript:  That, yeah, that's a, there's a holiday where you eat them.

Start time: 3957.25
End time: 3958.20
Speaker: SPEAKER_02
Transcript:  It could just be a pie.

Start time: 3959.01
End time: 3959.76
Speaker: UNKNOWN
Transcript:  It could be a pie.

Start time: 3960.04
End time: 3984.52
Speaker: SPEAKER_02
Transcript:  But I think that it's an egg in the middle or something.  There's something there going on there.  It's like Mardi Gras, a king cake.  Yeah, it could be like a king cake.  Salt.  Everybody needs salt.  A compass and luggage.  Bricks and a skateboard.  LaCrosse and a flying disc, AKA, we should point out, frisbee.  There's a Jace jigsaw puzzle, chess pawn, softball, magnet, toolbox.

Start time: 3985.63
End time: 3987.46
Speaker: SPEAKER_05
Transcript:  Hey, did they post a list of the rejects?

Start time: 3988.22
End time: 4030.20
Speaker: SPEAKER_02
Transcript:  Yeah, sometimes Jeremy will talk about them.  There have been some very, yeah.  I'm so curious.  Let me see if they, there's your lotion bottle, by the way.  Yeah.  Abacus and fire extinguisher.  Let's see what the rejects, see if, these are really what matters, these textual descriptions.  Because that, so in fact, they do call it a super villain and a superhero.  So maybe there'll be a better distinguish, distinguishing characteristics.  Safety pins, sponge, infinity, pirate flag.  Let me see if he mentions the rejects.  When Jeremy comes on, he always talks about the rejects, but I don't see that on the article  in Emojipedia.  But yeah, it's-

Start time: 4030.20
End time: 4052.14
Speaker: SPEAKER_00
Transcript:  Yeah, just to talk about something positive that's working.  I think our standards committees are a pretty good example of something that works in technology.  Like the USB committee and the Emoji committee, Unicode committee.  I think it's because you stack it with people that are vested experts in a field that are  not politicians.  I think that's why we have such better results with that.

Start time: 4052.48
End time: 4118.97
Speaker: SPEAKER_02
Transcript:  If you talk to the people who serve on those committees, they will say, oh my God, they're  broken.  It's a fight.  There's big companies come in.  But I think you're right.  I think that while there have been examples of standards not being influenced by the big  I think in general, it kind of does work.  It certainly works a lot better than government.  So maybe that is a model for the future.  I don't know.  Here's a little word of warning for people who sell their Apple equipment.  Brendan Mulligan, who is an entrepreneur and a designer, he says, I sold an old iMac to  somebody and I had access to its location for over three years.  This doesn't happen if the new owner signs into their iCloud account, but apparently  the new owner did not.  He had erased the computer.  He had installed a fresh copy of OS X.  He says, the mistake I made was I didn't sign out of iCloud to find my Mac before erasing.  I thought erasing it would do it, but it doesn't.  So you have to remove it.

Start time: 4122.04
End time: 4123.93
Speaker: SPEAKER_05
Transcript:  So are you sort of like purgatory?

Start time: 4125.68
End time: 4164.50
Speaker: SPEAKER_02
Transcript:  It just means that Mac will show up.  And the worst thing is, maybe we're telling people something they shouldn't know, but  you could, he points it out, with two clicks at any point I could have shut down the user's  computer, wiped it clean, they couldn't stop it, they'd have no control.  So there's a message to both sides.  If you're selling a Mac, don't merely erase it.  Remove it from your find my iPhone, from your iCloud account, which you can do before you  erase it.  And then if you buy a Mac or an iPhone for somebody, make sure you log it into your iCloud  account so that the previous owner can't lock you out of your own stuff.

Start time: 4165.63
End time: 4174.21
Speaker: SPEAKER_05
Transcript:  Wow.  So I guess my question is, if you erase everything on your computer, right, and you don't sign  out of iCloud, is there no way...

Start time: 4174.92
End time: 4178.09
Speaker: SPEAKER_02
Transcript:  You could go to another device, I think, and remove it.  I think.

Start time: 4179.34
End time: 4202.78
Speaker: SPEAKER_05
Transcript:  The way that they've updated this multiple device sign-in...  It's crazy, isn't it?  It's crazy, and it's also challenging.  Like, if you don't, you know, and the...  I just had this problem with my iPad the other day.  I was trying to sign on and it's really confusing.  And I'm a pretty tech savvy person.  I can't imagine how confounding it would be.

Start time: 4203.50
End time: 4206.22
Speaker: SPEAKER_02
Transcript:  And what if you don't have another Apple device?

Start time: 4206.88
End time: 4214.04
Speaker: SPEAKER_05
Transcript:  Or what if somebody stole your backpack and they have all your devices?  Doesn't that...  Isn't it meant to prevent theft of information?

Start time: 4214.24
End time: 4247.72
Speaker: SPEAKER_00
Transcript:  They have screens out there of what iOS was like, like for iOS 1, 2, and 3, and compare  it to all the setup screens today.  And it's true.  You go through so many modal dialogues these days.  And I just...  My measure of what I feel normal people can get is watching my husband.  He just completely tunes it out.  We bought him a new machine and just...  He just doesn't want to deal with it.  So it's...  I feel like it's gotten so complicated.  It's very easy for me to understand why someone would buy a Mac and would just hit, do later,  do later, do later.

Start time: 4247.76
End time: 4352.44
Speaker: SPEAKER_02
Transcript:  I had a great caller, a guy who was in his 80s called the radio show today.  He says, I'm a technical writer.  I've been writing about technology for 40 years.  I have a Windows computer.  I've been using Windows for 30 years.  I have a Surface Pro right here.  Somebody gave me an iPad.  I can't figure out how the hell to use it.  What do those pictures mean?  What am I...  And I said, oh, easy.  Give it to a two-year-old.  They'll show you.  They intuitively know how to use it.  The problem is we have to unlearn everything we ever knew.  He said, is there a manual for this thing?  And actually I found out, thank you to the chat room, there is a manual.  It doesn't come on the iPad, but you can go into iBooks and download Apple's 100...  It's a 300 page manual on how to use an iPad for old people.  I swear I've seen nonverbal kids launch Netflix and launch Phineas and Ferb completely autonomously.  Here's an Apple repair center that apparently doesn't really know how to use Apple technology.  They've accidentally called 911 about 1,600 times in four months and no one knows why.  This is Elk Grove, California.  The Elk Grove Police Department said, yeah, we get about 20 calls a day from the Apple  repair center.  There's nobody on the other line.  Currently they're coming from iPhones and Apple watches.  I don't know if you know, but there's an emergency call feature now.  If you press both buttons and hold it for a few seconds, it'll call 911.  Apple said, we take this very seriously and we're working closely with local law enforcement  to investigate the cause and ensure this doesn't continue.  I guess it's a little, I don't know, there's something they're doing in the recycling center.

Start time: 4353.26
End time: 4357.60
Speaker: SPEAKER_05
Transcript:  Maybe it's the way that they're trying to take the case, like pop the case off.  It's got to be, right?

Start time: 4358.10
End time: 4360.19
Speaker: SPEAKER_02
Transcript:  But it's an Apple facility.  That's the funny thing.

Start time: 4361.62
End time: 4368.20
Speaker: SPEAKER_00
Transcript:  Why'd they're dealing with like broken iPhones and it's like the digitizer is all randomly  pressing and it's like dragging it across the screen.

Start time: 4368.84
End time: 4407.78
Speaker: SPEAKER_02
Transcript:  Yeah.  I mean, I think really they should probably have a Faraday cage around the building or  something.  They need to do something.  Apparently this is not unusual.  It's a problem of course for Elk Grove because their lines are constantly being peppered  by fake 911 calls.  But I didn't know this, but in 2011, a Google research study looked at 911 calls in San  Francisco and found, this is seven years ago, that 30% of the 911 calls were accidental  from wireless phones.  But 37% from wired phones were accidental.

Start time: 4408.88
End time: 4411.65
Speaker: SPEAKER_05
Transcript:  That was the part that I thought, who's accidentally calling 911 from your landline?

Start time: 4412.90
End time: 4512.73
Speaker: SPEAKER_02
Transcript:  The same two-year-old is trying to launch Phineas and Ferb on the landline.  Come on, I know this, man.  Now, what's weird is they can't just hang up if nobody's on the line because it could  be somebody who's tied up.  So when the dispatcher receives those calls, they listen for a while.  When they only hear an open line, they have to call back and leave a voicemail.  I mean, it's not an easy problem to solve.  All right, that was our happy segment.  Emojis, 911 calls.  I don't want to go into the case against Google, but do you have an opinion on that story?  Anybody have a thought on this?  We talked about it a lot on our show on Wednesday this week in Google.  Let's say the search giant is squelching competition before it begins.  They use as an example a vertical search shopping engine called, what was it?  FoundMe, something like that.  I'll get the name right.  And this couple, Adam and Siobhan Raff, who basically were put out of business by Google,  they created a vertical search shopping search.  And when they went live with it, they disappeared from the Google search page because Google  in their algorithm said, well, you're just generating a link farm basically.  You're generating links to shopping sites.  And we don't think that's what users want.  And essentially they went out of business.  They've been suing.

Start time: 4513.28
End time: 4530.52
Speaker: SPEAKER_05
Transcript:  This is the problem.  Google is a commercial entity.  It's not the de facto, they're not archivists.  So they don't have any obligation to show every single page and index it so that it  can be listed publicly.

Start time: 4531.57
End time: 4567.82
Speaker: SPEAKER_02
Transcript:  No, they're private enterprise.  Now, I guess if you're, you could go after them as the EU has for favoring their own  shopping against a competitor.  But Google's explanation actually is kind of credible, which is, well, we don't surface  sites that don't have any outbound links or inbound links.  They just have a lot of outbound links because we consider them spam.  Of course, as they point out in this article, that's all Google is.  It's a bunch of, there's no, nobody links to a Google search result.  It's all outbound links.

Start time: 4569.04
End time: 4587.26
Speaker: SPEAKER_00
Transcript:  Do you know what gives me a lot of pause is I think if you look at the anti, you know,  the legislation against Microsoft in the nineties, you know, basically ruling them in a monopoly.  And I think now many years later, if you look at that, I think it's a very mixed bag if  that particular legislation did anything.

Start time: 4587.32
End time: 4606.90
Speaker: SPEAKER_02
Transcript:  Well, you should read this article because again, they talk about this and they say Google  wouldn't exist if Microsoft hadn't been slapped on the wrist by the DOJ.  A process that took 10 years cost a lot of money.  A lot of people said it went so slow that by the time the DOJ won that case, it didn't  matter anymore.  Right.

Start time: 4607.48
End time: 4638.74
Speaker: SPEAKER_00
Transcript:  I guess it's like, when I look at Facebook, I see the vicious effect Facebook has had  on media.  And it's like, I understand that argument.  Like that is an anti-competition case I would be very interested in looking at.  For Google, I can see it.  I just, you know, it's any of these, when you're talking about getting government involved  in slicing up a business as important as Google, it gives me pause.  That's not to say I don't think we should do it.  I just think it's something you should think very, very deeply about.

Start time: 4639.66
End time: 4640.50
Speaker: UNKNOWN
Transcript:  Yeah.

Start time: 4641.32
End time: 4807.21
Speaker: SPEAKER_04
Transcript:  I mean, I think what worries me here, so I think it's totally valid for Google to say  that this company was just sending links outward and therefore, you know, maybe it wasn't the  best website.  But what's a little bit scary is that Google can, you know, by flipping a switch, Google  can either create a multimillion dollar business.  Like this company had solved a problem that people legitimately wanted solved and it could  have grown into a very successful business.  But by turning the switch off, Google was able to eliminate a competitor.  And so, you know, it does tie into, I think, the Microsoft, the legislation against Microsoft  that you're talking about, because, you know, you could have made the same case for Internet  Explorer.  I think, you know, Microsoft had every right to put Internet Explorer on the machines that  were running Windows.  But luckily, we were all given better, better choices.  You know, we were given Netscape, we were given Firefox, we were given eventually Chrome.  And the reason that those things were able to take off is because Microsoft got slapped  in the wrist for this Internet Explorer thing.  And you know, what's interesting is I don't know if it was in this New York Times article  or a separate story that I read this week, but I think a lot of the employees that were  working at Microsoft around that time said that there was, it did have a residual effect.  You know, after they were slapped on the wrist by the government, executives were thinking  twice before making decisions about some of their business.  That was in this article.  Yep.  Yeah, because they didn't want to go through that ordeal again, because it was such a,  it painted the company in such a negative light and it was such a headache for the higher  ups that there was careful consideration around decisions that were made after the fact.  And so I think with, you know, you're seeing that right now with Facebook and the way that  it handles news and also the way that it interacts with Washington.  I think right now, you know, from what I've heard from people inside Facebook, like the  number one thing that Facebook doesn't want is to be regulated.  And so there's a lot of special consideration around things like deciding whether to flag  fake news or deciding whether to hire more curators to curb fake news.  You know, there's really, really careful consideration and long debates about any tiny little maneuver  that has to deal with either the news or politics in the U.S. and any of the sensitive content  on Facebook right now because they're basically on high alert because, you know, the one thing  that they don't want is exactly what Microsoft went through in the 90s.  So that's beneficial.

Start time: 4809.38
End time: 4894.52
Speaker: SPEAKER_02
Transcript:  The article says that the United States courts have increasingly held that the government  has to show consumer harm to win in a case like this.  And that's part of the problem is consumers are not complaining.  The people who are complaining against Google are other companies.  That's why it succeeded in the European Union where competition is considered a more important  net or a more important way to protect consumers is to preserve innovation and competition  between companies.  So good articles, an interesting article.  It's a difficult challenge.  It's clear though, as Google and Facebook and Amazon get bigger and bigger, the challenges  are going to get bigger and bigger.  And this is another one of those difficult to legislate.  Let's take a break and talk some more.  Great panel here.  She's a futurist created the Future Today Institute publisher of the annual FTI Trend  Report just out and her book, which is really worth working, will help you think about the  future differently.  The signals are talking why today's fringes tomorrow's mainstream.  Brianna Wu, she's running for Congress in the Massachusetts Eighth District primaries  coming up September.  Brianna's working hard.  She's raising money.  You can go to BriannaWu2018.com to help out if you think we need more smart people like  Brianna in Congress.  I do.  And of course from Mashable, Michael Nunez, who has not yet announced whether he's running,  but he does believe in victory.

Start time: 4894.62
End time: 4896.54
Speaker: SPEAKER_04
Transcript:  Give it time.  Give it time.

Start time: 4896.54
End time: 5046.22
Speaker: SPEAKER_02
Transcript:  Our show today brought to you by, speaking of legal matters, Legal Zoom, small business,  hot topic this year.  We talk a lot about the big businesses and the power, but this is National Small Business  Month.  Actually, as a small business, I kind of appreciate Legal Zoom.  When I was starting out and I consulted my friends who had started companies, I said,  you need to make an LLC to protect yourself.  And I went to Legal Zoom and they made it easy and affordable, even though I couldn't,  you know, I was brand new.  I couldn't afford a law firm.  I got the advice and the information and the forms I needed from Legal Zoom.  Whether you're already in business or just starting out, 2018 is going to be an exciting  year.  The new tax law is perhaps the most significant change for business owners in the last 30  years.  Looking at, well, should I incorporate?  Should I be an LLC, a pass-through entity?  Legal Zoom can help you understand what it means for you.  They're not a law firm.  I want to make this clear, but they do hook you up with independent tax professionals  and attorneys so you can get your questions answered about the new tax bill, about incorporation,  about business matters.  Legal Zoom understands you need to tap into the right resources to run a successful business.  So they have been around for 16 years.  They helped me a lot in the beginning and they have taken what they know to provide  business owners with the tools they need to start and run their businesses the right way.  They have a white glove service for business owners.  Everything you need to run your business.  I still get the email from Legal Zoom reminding me it's, you know, time to do this or that,  which is fantastic.  I don't have to worry about compliance or when things are due, they let me know.  The services include tax consultation, intellectual property, payroll, business compliance.  They do it all.  Over the next few weeks, because it's National Small Business Month, we're going to talk  about different ways Legal Zoom can help you this month.  So if you're in a small business or you want to start one, and who doesn't really want  to have their own business, stay tuned.  For now, check out LegalZoom.com today and get special savings when you enter the promo  code TWIT in the referral box at checkout.  Legal Zoom where life meets legal.  LegalZoom.com and if you see something you want there, make sure you use the offer code  TWIT so they know you heard it here and you get a special $10 off.  LegalZoom.com.  I'm always forever grateful to Legal Zoom.  We trademarked the TWIT logo, the TWIT name.  That was back in 2004, 2005.  It was early on and I'm very grateful to them for everything.

Start time: 5046.28
End time: 5052.30
Speaker: SPEAKER_00
Transcript:  I was just having to laugh at this price.  That's what one second of calling your lawyer on the phone costs.

Start time: 5052.90
End time: 5064.32
Speaker: SPEAKER_02
Transcript:  I know.  Now, of course, we have a law firm and every time I get on the phone with lawyers and there's  three of them on the phone, I can't help it.  I'm thinking that cost $12.  That cost $12.

Start time: 5067.06
End time: 5069.48
Speaker: SPEAKER_00
Transcript:  They're saying hello and you're just like, let's move past this.

Start time: 5069.56
End time: 5073.50
Speaker: SPEAKER_02
Transcript:  No, they do.  They say, how was your day?  And I know it's a dollar.  I don't want to talk about that.

Start time: 5074.35
End time: 5076.15
Speaker: SPEAKER_05
Transcript:  And they bill in 15 minute increments.  Oh yeah.

Start time: 5076.82
End time: 5118.50
Speaker: SPEAKER_02
Transcript:  I don't want to talk about that.  No, but I really love our attorneys.  They're really great.  I kind of wish I were back in the LegalZoom days, I got to say.  Let's see.  Let's talk about machine learning and ad buys.  Google has announced something called auto ads.  They're not ads for automobiles, but they're ads that will use artificial intelligence,  they say, to help you with placement and make choices for monetization.  I feel like this is the beginning of what we're going to see big time.

Start time: 5119.76
End time: 5126.64
Speaker: SPEAKER_05
Transcript:  Are people still paying attention to ads?  I'd be curious.  I'm curious to find out if we've...

Start time: 5126.86
End time: 5132.64
Speaker: SPEAKER_02
Transcript:  God, I hope so.  No, you're not talking about my ads, you're talking about banner ads, right?

Start time: 5133.20
End time: 5141.04
Speaker: SPEAKER_05
Transcript:  No, because in the audio world, people just listen.  I'm talking about the display ads.  I don't see banner ads.

Start time: 5141.38
End time: 5147.95
Speaker: SPEAKER_02
Transcript:  And I think there's this whole problem with ad blockers.  Everybody's running by ad blockers.  Even Chrome now has ad blockers.

Start time: 5150.66
End time: 5158.86
Speaker: SPEAKER_00
Transcript:  I can say that on Twitter and Facebook ads, they do work for a congressional campaign,  at least people do pay attention to those.

Start time: 5159.18
End time: 5169.49
Speaker: SPEAKER_04
Transcript:  I think you'd find a lot of businesses that would say that they work for them as well,  like Daniel Wellington, Allbirds.  There are multi-million dollar companies that have been made in the past.  I have Allbirds.

Start time: 5170.44
End time: 5179.12
Speaker: SPEAKER_02
Transcript:  I have Allbirds, yep.  They worked for me.  I actually hate Instagram because they put an ad every, what is it, eighth post, and  I have bought so much crap.

Start time: 5180.36
End time: 5181.20
Speaker: SPEAKER_04
Transcript:  They're very effective.

Start time: 5182.34
End time: 5186.96
Speaker: SPEAKER_05
Transcript:  But I'm talking about Google, right?  Because Google's not selling ads on Facebook.

Start time: 5187.00
End time: 5188.85
Speaker: SPEAKER_02
Transcript:  They're doing banner ads, right?  No, no.

Start time: 5189.46
End time: 5195.94
Speaker: SPEAKER_05
Transcript:  That's what I'm saying.  Like Michael, do you have, I mean, you probably can't tell us very much, but for Mashable.

Start time: 5196.24
End time: 5197.83
Speaker: SPEAKER_02
Transcript:  We have Google ads on Mashable, I'm sure.

Start time: 5199.14
End time: 5201.85
Speaker: SPEAKER_04
Transcript:  Yeah, I think, I mean, I don't obviously.

Start time: 5202.94
End time: 5207.48
Speaker: SPEAKER_02
Transcript:  You don't know because this is good because they separate that away from you as they should.

Start time: 5208.25
End time: 5214.30
Speaker: SPEAKER_04
Transcript:  Yeah, that's right.  But I'm sure we do.  I mean, I imagine that we do.  But do you get a sense that people are, like, there's avoidance?

Start time: 5214.82
End time: 5223.72
Speaker: SPEAKER_05
Transcript:  You know, like, I don't even, I know that there are ads on my screen.  I have ad blockers up, but I just, I don't even, they don't register anymore, you know?

Start time: 5225.14
End time: 5235.94
Speaker: SPEAKER_04
Transcript:  I know.  Yeah, for me, that's very true, except in the case of like, you know, when they're inserted  in the feeds that I'm looking at, they're very effective.  I've never really clicked on Google AdSense ads to the iPhone.

Start time: 5235.96
End time: 5265.02
Speaker: SPEAKER_02
Transcript:  My suspicion is this is exactly why Google's doing this.  Because they want to make ads more effective.  They claim that they are seeing with this auto, you know, this artificial intelligence  auto ads placement that they're seeing average revenue lift at 10% with revenue increases  ranging from 5 to 15%.  I would guess that's exactly why because they're, you know, they're using things like heat maps  where people look and they're really starting to get smart about ad placement.

Start time: 5265.56
End time: 5309.99
Speaker: SPEAKER_00
Transcript:  I guess it makes sense too.  I think about how much time for us on a campaign, we do A versus B testing and different keyword  testing to, you know, with like, and we do all kinds of, you know, advertising, like  mailing lists or buying certain kinds of ads.  And either as a candidate, get in and get really deep with like, what is my message  I'm trying to do here?  Who am I trying to target?  Or you have to hire someone that's very, very expensive to go like work that out for you  and find that market segmentation.  So like I read this and I'm like, I would absolutely use something like this if it was  effective.  So yeah, I think it's a, it's a certainly like removing the human element from that,  which I like.

Start time: 5310.46
End time: 5315.50
Speaker: SPEAKER_02
Transcript:  So I'm actually curious, you, you, do you have consultants who help you with this?

Start time: 5316.50
End time: 5337.42
Speaker: SPEAKER_00
Transcript:  So to be honest, when big democratic party consultants call me, I just, I think it's  a dark road to go down.  When I run into people, they're passionate about say, cybersecurity and want to get involved  with our campaign.  We do hire people like that, that have experience with marketing.  But you know, as far as like, you know, like that, there's a-

Start time: 5337.42
End time: 5343.32
Speaker: SPEAKER_02
Transcript:  Now if you win the primary, the DNC is going to step up and say, okay, we'll take it from  here, aren't they?

Start time: 5343.60
End time: 5354.96
Speaker: SPEAKER_00
Transcript:  I guess I've upset a lot of people at the DNC and running because, you know, I've, I've,  I've critiqued our party quite a bit, like FISA.  I'm very upset about that.  We'll see. We'll see.

Start time: 5355.44
End time: 5359.90
Speaker: SPEAKER_02
Transcript:  They may know.  Look, if you win the primary, they got to go with you.

Start time: 5360.68
End time: 5361.38
Speaker: SPEAKER_00
Transcript:  Yeah, I hope so.

Start time: 5363.74
End time: 5365.90
Speaker: SPEAKER_05
Transcript:  So do they have to or can they?

Start time: 5366.02
End time: 5368.09
Speaker: SPEAKER_02
Transcript:  No, they don't have to do anything.  Right.

Start time: 5368.78
End time: 5372.14
Speaker: SPEAKER_00
Transcript:  I mean, I imagine they would.  It's not like, you know, ask Bernie Sanders.

Start time: 5372.86
End time: 5374.40
Speaker: SPEAKER_02
Transcript:  See what, see what happened with Bernie.

Start time: 5375.04
End time: 5376.28
Speaker: SPEAKER_00
Transcript:  Yeah, I think that's really fair.

Start time: 5376.60
End time: 5382.34
Speaker: SPEAKER_05
Transcript:  Yeah.  Today is unendorsed, right?  Did that just happen hours ago?

Start time: 5383.24
End time: 5401.80
Speaker: SPEAKER_02
Transcript:  Yeah.  So I'm just curious because there, of course, there was a big article in Wired this week  about saying, in effect, forget Russian bots.  That wasn't Trump.  The Trump campaign used Facebook very effectively.  They won because they used it very effectively.  It's actually a fascinating article.

Start time: 5401.84
End time: 5417.50
Speaker: SPEAKER_04
Transcript:  And one of the things we also written by the guy who created their advertising platform,  I think that's it. Oh, really?  So that story. Yeah.  So he was the former head of advertising at Facebook.  He wrote the book Chaos on Antonio.  Oh, he's a jerk.

Start time: 5418.56
End time: 5421.00
Speaker: SPEAKER_02
Transcript:  Well, I mean, Chaos Monkeys is the worst.

Start time: 5421.78
End time: 5430.57
Speaker: SPEAKER_04
Transcript:  Oh, it's it's a fine, you know, it's a fine book.  But I think it's not.  They built the platform.  It's championing.  OK, OK.

Start time: 5431.54
End time: 5464.42
Speaker: SPEAKER_02
Transcript:  Wired. This is not editorial.  This is a this is an opinion piece.  By the way, an opinion.  No, I think they call it editorial.  And by the way, somebody pointed out  Casey Newton wrote essentially the same story in the last year about how,  you know, the Trump campaign, let me see if I can find it.  The Trump campaign, very intent, you know, cleverly.  Here it is. How face Trump conquered Facebook without Russian ads.  This is this doesn't say opinion.  I mean, it's, you know, it's

Start time: 5464.66
End time: 5469.99
Speaker: SPEAKER_05
Transcript:  rolled to the bottom and see if it lists his sometimes they'll put a disclaimer  in the tagline at the bottom.

Start time: 5474.20
End time: 5495.38
Speaker: SPEAKER_02
Transcript:  I don't even see a bio at the bottom.  Yeah, I don't even see mention of Chaos Monkeys, which made him persona  non grata in Silicon Valley for some time.  Oh, oh, look here.  OK, look at this page.  Can you tell anything about this page?  There's a little word here. Ideas.  Oh, that that is that mean it's an opinion piece?

Start time: 5495.96
End time: 5505.55
Speaker: SPEAKER_05
Transcript:  I don't know. I know the people who who work on the editorial side.  I there. I don't think that.  But this this is surprising.

Start time: 5506.74
End time: 5509.68
Speaker: SPEAKER_02
Transcript:  Well, this is the new behind the paywall wired, right?

Start time: 5510.56
End time: 5521.00
Speaker: SPEAKER_04
Transcript:  Yeah, and I have I have other issues with wired this month, but but  but, you know, I'm not I'm not saying that that, you know, that the story isn't.  I just think that that should be disclosed.

Start time: 5521.12
End time: 5549.86
Speaker: SPEAKER_02
Transcript:  I mean, if we're going to say now in the bio is an idea is contributed for wire.  Then it talks.  It does talk about chaos monkeys in the bio on the left.  So but I didn't you know, now that I see it, I guess it's an opinion piece.  But it sure felt like a heavily researched piece on how.  And I think there's merit in this on how Facebook  really does give some real tools to political campaigns.  Do you advertise on Facebook, Brianna, for your campaign?

Start time: 5550.08
End time: 5575.67
Speaker: SPEAKER_00
Transcript:  Absolutely. In fact, the same tools that Trump used for his election,  nation builder, we use that as well.  It's it's a really amazing thing.  Like, it's really good.  Like you type it in, you get all kinds of data about who's following you  and what their interests are.  I forget the number.  I think it's some ridiculously high number of software engineers  have contributed to my campaign.  So, you know, but yeah, like, you know, there's all that data out there.  So you got to use it.

Start time: 5576.64
End time: 5610.36
Speaker: SPEAKER_05
Transcript:  We think of so we think of right now  the Republicans being further behind and, you know, with Obama  was the sort of advent of amazing technology and grassroots  and social media and all this.  The Republicans in the early 2000s were light years ahead of the Democrats.  And for a hot minute, I don't know if you guys ever saw this.  It was Bush and Cheney when they were running for about five seconds.  That was more than five seconds for a couple of hours.  They had this poster generator on their website, their campaign site,  where you could type in.

Start time: 5610.64
End time: 5612.15
Speaker: SPEAKER_02
Transcript:  They learned quickly, didn't they?

Start time: 5613.26
End time: 5642.39
Speaker: SPEAKER_05
Transcript:  Like whatever, you know, like, you don't let the Internet do that.  No. Yes. For Bush Cheney 2004.  And anything, any poster that got created, it was intended for you to print out.  But but they created a gallery.  And so they were all being funneled into this gallery.  And it took like less than an hour for, you know, neighborhood moms  for Bush Cheney 2004 to turn into like the most ridiculous, crazy  and the whole thing got taken down.

Start time: 5644.26
End time: 5666.10
Speaker: SPEAKER_02
Transcript:  But I did not know about this.  And actually, I was looking, Metafilter had a link to all of them.  But they're all four oh fours now.  They've deleted all of them.  And here's an article from Wired Bush site, unplugged poster tool.  That was it. Yep.  Oh, it seemed like a good idea at the time.

Start time: 5666.66
End time: 5676.00
Speaker: SPEAKER_05
Transcript:  But they were pretty, you know, we don't we don't.  Now in the era of Trump, don't think about this.  But the Republicans were really far ahead in a lot of the technology  in the early days, like really far ahead.

Start time: 5676.12
End time: 5676.90
Speaker: SPEAKER_02
Transcript:  Yeah. Yeah.

Start time: 5676.94
End time: 5678.44
Speaker: SPEAKER_05
Transcript:  There's really innovative things.

Start time: 5678.72
End time: 5710.04
Speaker: SPEAKER_02
Transcript:  All right. So treat this Wired article really as an inside look at how it works.  Let me find it again. I put here it is from the guy  who was the product manager for custom audiences.  I didn't I should have read this more carefully.  Thank you, Michael, for pointing this out.  And he created this custom audiences  is the tool, one of the tools you said Nation Builder, Brianna.  That must be another one.  Yeah. That allows basically allows a advertiser to understand  to buy specific groups. Right.

Start time: 5714.00
End time: 5717.24
Speaker: SPEAKER_04
Transcript:  Yes. And target, target specific groups.  I think that's correct.

Start time: 5717.50
End time: 5737.35
Speaker: SPEAKER_02
Transcript:  There's also a tool that lets you take I know because Jason Calacanis  told me about this, take your mailing list and find like minded people,  feed it to Facebook and the Facebook algorithm says,  well, here's people who are on them or not on the mailing list,  but are like minded. You should be talking to.  It's called lookalike audiences.  Yeah, we've got that.  You got that too.

Start time: 5737.96
End time: 5743.40
Speaker: SPEAKER_00
Transcript:  Yeah, we do. It's expensive.  It costs a lot of money to when you've built a custom audience.

Start time: 5743.72
End time: 5777.58
Speaker: SPEAKER_02
Transcript:  Can you build lookalike audiences, the most unknown and poorly understood  yet powerful weapon in the Facebook ads arsenal?  With a mere mouse click from our hypothetical campaign manager,  Facebook now searches the friends of everyone in the custom audience,  trying to find everyone who looks like you using a witch's brew  of mutual engagement.  And by the way, every day this tool becomes better, right?  Because Facebook gets more data all the time.  And it's and it's just self-reinforcing better and better and better.  It's it's it's Facebook going to dominate every campaign from now on in.

Start time: 5778.84
End time: 5831.80
Speaker: SPEAKER_00
Transcript:  Well, I mean, think about like this, Leo.  I was thinking about this the other day.  Like I was going to go drive to talk to a group of disabled people  here in Massachusetts. This is very important.  These are my constituents.  I've got to meet them and listen to them.  But, you know, it's like three hours to drive there and back  and come to another event.  It's like if I'd spent that time on like that same Facebook group,  disabled people, like you get much more so much.  It is. And it's, you know, it's I think when you know somebody on Facebook  and you're talking to them, I think that's a genuine connection  where you see what's important to them every day.  So honestly, I think in this sense, it's more of a net positive  than it is a net negative, you know, when people can genuinely talk to you.  I think that's that's better than, you know, trying to go to a campaign  with 500 other people and shake their hand for four seconds.

Start time: 5831.88
End time: 5843.30
Speaker: SPEAKER_02
Transcript:  I agree. We are very fortunate that we have a chat room  that is very adept at this thing called the Internet.  Thank you, Bleak has provided me with some of the. Oh, nice.

Start time: 5843.84
End time: 5857.34
Speaker: SPEAKER_05
Transcript:  Yeah. So I love it.  Oh, that's a good one.  I'm sure somewhere there is there've got to be screen grabs  of some of the other posters.  I mean, you probably can't show.  We probably can't show all of them.

Start time: 5857.42
End time: 5879.27
Speaker: SPEAKER_02
Transcript:  That one said Bush Cheney 2004 stealing elections since I don't know.  Oh, this one. They were amazing.  This one's dead.  Yeah. You don't let people write their own slogans for your campaign.  Here's a good one. War is peace.  Hate is love. Bush Cheney, of course, from coming from the 1984  truth speak.

Start time: 5880.74
End time: 5891.31
Speaker: SPEAKER_05
Transcript:  But from a technical vantage point, just on the back end, it was a pretty  like obviously the implementation didn't get thought through,  but the technology was actually pretty good for back then.  That's clever. Yeah. Yeah.

Start time: 5893.46
End time: 5896.18
Speaker: SPEAKER_02
Transcript:  Uh, I love it.

Start time: 5896.40
End time: 5907.42
Speaker: SPEAKER_05
Transcript:  There were some really funny ones.  There was a whole series with Jefferson Airplane.  Is that a band? Yeah.  It's featuring like Jefferson Airplane lyrics for some reason.

Start time: 5908.52
End time: 5962.65
Speaker: SPEAKER_02
Transcript:  One side makes you taller.  All right. Well, we're going to take a break.  This is so much fun.  And I'm so glad we have the smartest people on the Internet with us today  to protect me from whatever I might buy next on Facebook.  Michael Nunez from Mashable.  Thank you for staying late in the office tonight.  Anything more coming in from the.  Actually, I want to ask you what other we talked all about the Samsung.  I want to ask you in a bit what other phones are new at Mobile World Congress.  What are the things? Oh, there's some recommendations we can make.  Yeah. Brianna Wu Brianna Wu 2018 dot com.  Donate and Amy Webb.  She'll take that money by great Facebook ads and you'll see a lot more of her  in your feed.  The signals are talking why today's fringe is tomorrow's mainstream.  We had a fun week on Twitter.  We've even made a highlight reel for your delegation watch previously on Twitter.  Do we switch back now?

Start time: 5963.22
End time: 5974.36
Speaker: SPEAKER_01
Transcript:  Yeah, I guess we do. Is it time?  Of course, we'll have to wipe things up, wipe things, you know, the data and stuff.  My germs probably to probably but that's OK.  They swapped iPhone and Google Pixel.

Start time: 5975.60
End time: 5976.60
Speaker: SPEAKER_02
Transcript:  I know we're chasing.

Start time: 5976.68
End time: 5985.36
Speaker: SPEAKER_01
Transcript:  Can I give you a tip on Venmo that I think change your privacy settings?  Because by default, all of your transactions are revealed.

Start time: 5985.98
End time: 6005.91
Speaker: SPEAKER_02
Transcript:  Oh, my Google.  Google AI can predict heart attacks just by looking at your eyes.  See, technology is not so bad.  Until your insurance company starts taking pictures of you on the street  and denies you saying, sorry, Jeff, you can't get a insurance  because we could see from your eyes.  You're going to get sick.

Start time: 6006.60
End time: 6008.42
Speaker: SPEAKER_04
Transcript:  That is very panoptic, Leo.

Start time: 6010.44
End time: 6012.46
Speaker: SPEAKER_02
Transcript:  Hey, I'm all about the panopticon, man.

Start time: 6012.52
End time: 6019.86
Speaker: SPEAKER_04
Transcript:  A bad path on the show.  Twit live specials.  Get looks as an iron and as nine plus.

Start time: 6020.82
End time: 6022.92
Speaker: SPEAKER_01
Transcript:  It's thin, it's sexy, it's got the curves.

Start time: 6023.44
End time: 6036.06
Speaker: SPEAKER_04
Transcript:  You know, we got some some nice metallic.  And they're the ports.  There are the ports, ladies and gentlemen.  Oh, look at that. It's the dandelion.  Wait, this is a are.  Oh, they probably have a they're holding their phones up. Right.

Start time: 6036.58
End time: 6042.79
Speaker: SPEAKER_02
Transcript:  There's probably a way for help with the technology addiction problem.  Call one eight hundred twit.  I wish that was.

Start time: 6045.76
End time: 6051.84
Speaker: SPEAKER_01
Transcript:  OK, thank you. Thank you very much.  Bye. Thank you.

Start time: 6052.42
End time: 6174.62
Speaker: SPEAKER_02
Transcript:  D.J. It ended quickly.  Should I brought you by zip recruiter?  If you're doing some hiring, zip recruiter is going to be the easiest way  to fill that job with exactly the right person, the right person is out there.  But how do you reach them with all those job boards,  all the different places you can go?  Well, that's the beauty of zip recruiter.  One post on zip recruiter posts to 100 plus job sites with one click.  And even better, zip recruiter has created a smarter way to find the right people.  They built a platform that finds the right job candidates for you.  Zip recruiter, it learns what you're looking for, identifies people  with the right experience and literally invites them to apply to your job.  These invitations have revolutionized how you find your next hire.  Technology, you got to use it.  It's out there and it can really change what you do.  Turns out 80 percent of employers who post a job on zip recruiter,  80 percent get a quality candidate through the site in just one day.  It really works. We've used it. It's amazing.  And zip recruiter doesn't stop there.  They even go through the resumes, the applications and spotlight  the strongest applications so you don't have to miss a great match  because you're overwhelmed.  The right candidates are out there.  They're waiting for you. Zip recruiter will help you find them.  Businesses of all sizes trust zip recruiter for their hiring needs  from the Fortune 100 to little old twit.  Right now, you could try zip recruiter free.  Just go to zip recruiter dot com slash twit zip recruit.  Look at the fields. Look at all the categories.  Look at all the companies.  Facebook uses zip recruit.  That actually is really a good endorsement.  Facebook uses zip recruiter.  Zip recruiter dot com slash twit zip recruiter dot com slash twit.  It's the smartest way to hire.  And it's easy and free right now.  It's zip recruiter dot com slash twit.  Michael Nunez Mashable is manning the the MWC desk in New York City.  You're the only one there.  Yeah, yeah.  But all the reports are coming into you, right?

Start time: 6175.98
End time: 6196.13
Speaker: SPEAKER_04
Transcript:  Yeah, I mean, they've slowed down at this point.  I think everyone in Barcelona is probably sleeping right now, but.  Drunk on. Yeah, it's been a busy day.  A lot of big Android announcements.  I feel like a lot of the news is bigger in Europe and other parts of the world.  But it's still really interesting to follow if you're  if you're at all interested in mobile technology.  I mean, it's all happening this weekend.

Start time: 6197.20
End time: 6214.96
Speaker: SPEAKER_02
Transcript:  It's funny because Apple, Google, Microsoft,  Facebook, they all have their own events.  They all make their announcements at those events.  They don't they don't piggyback off of other events.  But for some reason, the rest of the companies, including Samsung,  they they like to be at Mobile World Congress. Why is that?

Start time: 6216.14
End time: 6250.36
Speaker: SPEAKER_04
Transcript:  Yeah, I think it's just because there are so many brands  and companies in one place at one time.  And it's also just I think, like you said, you know, a piggyback is a good word.  You can in the case of Samsung, they're able to piggyback off of some of the excitement  and and some of the the I don't know, just the buzz surrounding that event.  They've definitely tried to do their own thing in the past.  You know, there was one year where they rented Radio City Music Hall in New York.  Oh, God, that was the worst.  Their Galaxy phone at their own event.  And so they've tried to do.

Start time: 6250.80
End time: 6271.45
Speaker: SPEAKER_02
Transcript:  That was the one where they had a fake Broadway play.  And at one point, they were talking about how you could hover your fingers  over the phone, you didn't have to touch it.  And they had and it was I'm sad to say a woman said, when my nail polish is wet,  I can use my Samsung phone.  Yeah. Oh, cringy.  The savily really cringy.

Start time: 6273.08
End time: 6319.78
Speaker: SPEAKER_04
Transcript:  Yeah. So I think like following that, they've learned from that.  Generally regarded as as kind of a failure, even though, you know, it was just it was  Samsung trying to do what Apple does really well, which is host its own event and create  a lot of buzz around that.  When Samsung tried, it was, you know, it was off the mark.  It was, you know, there were moments during that presentation that were just tone deaf.  And so I think they've reverted back to what they they had been doing, which was  which was sort of using other industry events to to to make these big announcements.  So in this case, I don't even think the Galaxy S9 event was associated directly with  Mobile World Congress. I don't think it was an official event at the show.  It just happened to be this Sunday or today, I guess, which sort of predate which

Start time: 6319.86
End time: 6322.62
Speaker: SPEAKER_02
Transcript:  which proceeds. It just happened to be in Barcelona.

Start time: 6323.38
End time: 6326.52
Speaker: SPEAKER_04
Transcript:  Yeah, exactly. It's the weekend right before the conference kicks off.

Start time: 6326.70
End time: 6332.98
Speaker: SPEAKER_02
Transcript:  So, you know, I don't know if that there were other announcements you said there  are other phones there. There were.

Start time: 6333.10
End time: 6342.32
Speaker: SPEAKER_04
Transcript:  Yeah. You know, one of the more interesting things for me, at least, because I'm just kind of  weird, is is the Nokia some of the 80 with 10.

Start time: 6344.14
End time: 6346.20
Speaker: SPEAKER_03
Transcript:  I'm so excited about the Banana Phone.

Start time: 6346.40
End time: 6347.84
Speaker: SPEAKER_05
Transcript:  Yes. Matrix.  Yeah. I can't wait.

Start time: 6350.08
End time: 6353.56
Speaker: SPEAKER_04
Transcript:  I call it the Matrix Phone because I'm obsessed with the Matrix.  Total of the Matrix Phone.

Start time: 6354.02
End time: 6356.54
Speaker: SPEAKER_02
Transcript:  Wait a minute. This is the phone that's in the was in the Matrix.

Start time: 6356.98
End time: 6357.72
Speaker: SPEAKER_01
Transcript:  Yeah. Yeah.

Start time: 6359.30
End time: 6360.70
Speaker: SPEAKER_05
Transcript:  I don't know why. It's Banana Yellow.

Start time: 6360.76
End time: 6377.56
Speaker: SPEAKER_02
Transcript:  That's why.  Well, this is a JK from The Verge showing it off.  Oh, so it's this it slides down.  It's a it's a feature phone.  It's not a smart or is it a smartphone?  It's a feature. It has 4G in it.  OK, but it doesn't have a operating system per se.

Start time: 6378.50
End time: 6381.42
Speaker: SPEAKER_04
Transcript:  Yeah. And the screen is tiny and there's no QWERTY.

Start time: 6382.08
End time: 6388.10
Speaker: SPEAKER_05
Transcript:  But the piano will come to wherever you are if you call.  And that is why I'm buying myself one.

Start time: 6389.41
End time: 6402.12
Speaker: SPEAKER_00
Transcript:  I want that.  I remember watching the Matrix and trying to figure out how to get one.  Like in Mississippi when that came out and I did the math.  I was going to cost like three thousand dollars and I couldn't get it.  And now I can get it.

Start time: 6402.34
End time: 6405.60
Speaker: SPEAKER_02
Transcript:  So I'm very you better get it in Banana Yellow or you'll really be.

Start time: 6405.84
End time: 6408.67
Speaker: SPEAKER_00
Transcript:  Oh, OK. OK. I can do that.  That would be you would do.

Start time: 6409.94
End time: 6417.40
Speaker: SPEAKER_04
Transcript:  Yeah, I would do it.  You know, this is a phone that I've wanted for more than a decade, I guess.  So I was really excited.

Start time: 6417.46
End time: 6420.78
Speaker: SPEAKER_05
Transcript:  I have the same action, though, right?  You can't like click it and have it.

Start time: 6421.78
End time: 6447.58
Speaker: SPEAKER_04
Transcript:  Wow. A true fan.  So you're right. You're exactly right.  I mean, I know I wasn't going to point that out because I wasn't sure  how people would respond to that.  But in the movie, there is we were fondly actuated mechanism.  So when you push a button, the bottom shoots out.  Because spring loaded.  Whereas this new one appears to just slide off, which is a little less.  It's so it's so it's so much.

Start time: 6447.70
End time: 6452.10
Speaker: SPEAKER_02
Transcript:  Why would they miss that critical feature?

Start time: 6452.52
End time: 6460.21
Speaker: SPEAKER_05
Transcript:  Yeah. I think that's a better thing to say is, wait a minute.  Nokia just made another phone.  No kids. Yeah.  Make phones. Yeah. Yeah.

Start time: 6461.58
End time: 6463.54
Speaker: SPEAKER_04
Transcript:  I know. Yeah, I still I get excited.

Start time: 6465.10
End time: 6471.66
Speaker: SPEAKER_02
Transcript:  Here's Neo on his banana phone. Yeah.  There's Mr. Smith and

Start time: 6473.92
End time: 6476.74
Speaker: SPEAKER_05
Transcript:  I love that movie.  The Matrix was I have never felt.

Start time: 6477.38
End time: 6499.68
Speaker: SPEAKER_02
Transcript:  Oh, he's flipping Mr. Smith off.  That's mean. That's rude.  You remember?  I don't think that's I don't think that's the phone.  I don't think I have once once again been deceived by YouTube.  I wanted to find the actual video here.  I think this is I hope this is it.

Start time: 6499.80
End time: 6504.76
Speaker: SPEAKER_05
Transcript:  This is I'm going to say banana is phone the rest of the day.  Banana is phone. I like that.

Start time: 6505.66
End time: 6515.33
Speaker: SPEAKER_02
Transcript:  So I think this is smart.  Nokia announced in 3310 last year, the year before,  which was also one of those candy bar phones.  And how did that sell?  Do you know as it was it?

Start time: 6516.18
End time: 6533.39
Speaker: SPEAKER_04
Transcript:  I don't think well, I don't know any any actual numbers.  But my impression is that it didn't it didn't do spectacularly.  But it's just kind of interesting to know that there's still a demand for these  I guess you can call them dumb phones.  And I don't know if it's the nostalgia.  Oh, there it is.

Start time: 6534.93
End time: 6546.28
Speaker: SPEAKER_02
Transcript:  Oh, look at that come out.  Wait a minute. Let's see that again.  I need my I need the Samsung super slow motion for that.  He's opening up the FedEx package.  Yes, they do have FedEx in the matrix.

Start time: 6548.18
End time: 6548.84
Speaker: UNKNOWN
Transcript:  There we go.

Start time: 6550.40
End time: 6555.56
Speaker: SPEAKER_04
Transcript:  Oh, baby.  I wanted that phone so bad.  Really? I thought it's funny.

Start time: 6555.60
End time: 6560.05
Speaker: SPEAKER_02
Transcript:  I love that movie, but I didn't I didn't get fetishized about the phone.  Oh, I did. Oh, good.

Start time: 6560.88
End time: 6563.06
Speaker: SPEAKER_00
Transcript:  Yes, I've been looking for you.

Start time: 6564.00
End time: 6566.05
Speaker: SPEAKER_02
Transcript:  I've been looking for you on your phone.

Start time: 6567.62
End time: 6590.20
Speaker: SPEAKER_04
Transcript:  But unfortunately, you know, what I was thinking about recently was like,  I heard that they're going to remake the matrix.  They're going to reboot the matrix pretty soon.  And I wonder what the matrix would be like in the era of smartphones.  You know, does the premise still hold true?  Can you can you create these situations where they're running to a landline  and that sort of thing?  So anyways, I'll just throw that out there for anyone else.

Start time: 6590.90
End time: 6598.66
Speaker: SPEAKER_02
Transcript:  Once they met the the architect, the whole series,  the whole thing fell apart.  It's just completely it's completely over now.

Start time: 6598.94
End time: 6610.66
Speaker: SPEAKER_00
Transcript:  I don't see the whole premise of the matrix.  So the matrix is set at the height of our civilization,  which is clearly the 90s. Right.  It's not going to be today.  So, you know, Spice Girls TV.

Start time: 6615.50
End time: 6621.18
Speaker: SPEAKER_02
Transcript:  Here's a little clip, just for those of you who don't remember of Neo  in the matrix may turn on the.

Start time: 6621.86
End time: 6627.26
Speaker: SPEAKER_00
Transcript:  Oh, I love this.  Wait a minute. Wait a minute.  No, no, no. That's going to be better.

Start time: 6627.44
End time: 6642.32
Speaker: SPEAKER_02
Transcript:  Is that Will Ferrell?  And Justin, because you, my friend, are completely whipped.  Watch the sass captain sassy pants.  Yeah, you're kind of spazzing out, dude.  You haven't answered my question. Yes, I did.

Start time: 6643.66
End time: 6648.67
Speaker: SPEAKER_03
Transcript:  You see what you haven't answered.  I'm trying. You just need to let me talk.  Why am I here?

Start time: 6650.19
End time: 6657.21
Speaker: SPEAKER_05
Transcript:  Oh, shut up.  You won't let it. No, you won't let it.  I'm the one who talks.  They've all shot. Here's open.

Start time: 6658.50
End time: 6661.70
Speaker: SPEAKER_02
Transcript:  All right. Enough. I'm sorry.  Once again, I have been fooled by YouTube.

Start time: 6661.98
End time: 6663.46
Speaker: SPEAKER_05
Transcript:  That was so much better than the original.

Start time: 6663.50
End time: 6674.19
Speaker: SPEAKER_02
Transcript:  It was. That was the MTV Awards. Yeah.  Will Ferrell and Justin Timberlake  mocking the greatest movie ever made.  The Matrix three.

Start time: 6674.74
End time: 6688.46
Speaker: SPEAKER_05
Transcript:  That first the first Matrix was  up until the end when Love Saved the Day was like the greatest thing  I've I've ever seen.  And the fact that somebody thinks it's a good idea to remake that near terrible.

Start time: 6689.04
End time: 6696.74
Speaker: SPEAKER_02
Transcript:  Well, no, are they remaking it or continuing it?  I think I'm going to read making it.  That shows they run out of ideas.

Start time: 6697.04
End time: 6702.66
Speaker: SPEAKER_04
Transcript:  I'm actually excited for the review.  I'm not even going to. I probably go see it.  I liked all three. Yeah, I want to.

Start time: 6703.12
End time: 6704.12
Speaker: SPEAKER_02
Transcript:  Well, there's something wrong with you.

Start time: 6704.48
End time: 6712.35
Speaker: SPEAKER_04
Transcript:  And I'm one of the rare, true fans of the Matrix.  So yeah, I'm here.  I'm here for all of it.

Start time: 6713.26
End time: 6721.86
Speaker: SPEAKER_05
Transcript:  Did you see the did you see the when did you see the Matrix?  Did you see it in a movie theater or did you see it like later on?  And later on, I saw it in.

Start time: 6722.22
End time: 6728.02
Speaker: SPEAKER_04
Transcript:  I saw it on a plane for the very first time.  I just became obsessed and bought the DVD.

Start time: 6728.62
End time: 6744.98
Speaker: SPEAKER_02
Transcript:  I think probably like you, Amy, I didn't know what I was going to.  I went to a matinee.  I had not read anything.  I know I didn't. I had no idea.  And I walked out of that theater with my draw on the ground.  Trying to figure out if I was in the matrix. Yeah.

Start time: 6746.46
End time: 6777.74
Speaker: SPEAKER_05
Transcript:  Right. And that's why I and I saw it.  I was in I was living in Japan at the time,  and I had just gotten out of a three hour Aikido practice.  And so like the kung fu scenes, I suppose all sweaty time.  Oh, yeah. And that's why I had this like  I had never felt that way. I felt.  I was just absolutely blown away.  And that's why the two matrixes that came afterwards were so like  unbelievably disappointing and depressing because I expected so much more.

Start time: 6777.88
End time: 6803.40
Speaker: SPEAKER_00
Transcript:  Yeah, I do have to say the PlayStation 2 game,  they actually went and filmed all these like scenes.  It works in conjunction with the second Matrix movie.  And you've got like all these awesome scenes with Ghost and Jada Pinkett Smith's character.  It's like the game itself, the gameplay is very mediocre,  but it's it's a really good story.  I thought that was very successful.  If you're a real fan, Michael, like you will actually like play all the way through that game.

Start time: 6803.66
End time: 6826.28
Speaker: SPEAKER_04
Transcript:  Just to defend the second one briefly, I really liked the  metaphors that were used across the movie.  So like, you know, back doors were were  were were physical parts of the matrix.  And and what else?  Like, you know, the ghosts, I think, were viruses.  And there were there was a lot of a lot of computer  jargon that was used in like really creative ways.

Start time: 6826.52
End time: 6842.62
Speaker: SPEAKER_02
Transcript:  In a way, I think I mean, given remember, we'd seen sneakers and hackers  and all these terrible movies about technology in a way.  This was the first movie where it at least  looked plausible, the technology.  And it felt like, yeah, they're getting it right.  Yeah. All right.

Start time: 6842.74
End time: 6851.85
Speaker: SPEAKER_05
Transcript:  And then I thought it was just the story fell apart.  But I don't know, I this rebooting, like  amazing movies always makes me really nervous.  I know. I know.

Start time: 6852.64
End time: 6854.18
Speaker: SPEAKER_00
Transcript:  And this is one for total recall.

Start time: 6856.06
End time: 6872.37
Speaker: SPEAKER_02
Transcript:  Oh, Arnold is the only total recall.  I'm sorry. There's no reason.  It's a terrible movie.  That's what makes it so good.  If you watch it now, you realize, my God, did we have no taste back then?  What? That thing is the worst.  But it's fun. Reboot.

Start time: 6873.06
End time: 6876.27
Speaker: SPEAKER_00
Transcript:  I meant the rebate. The rebate is too slick.  Yeah, I agree.

Start time: 6877.20
End time: 6885.42
Speaker: SPEAKER_02
Transcript:  I mean, but but I have to say it's the same thing with Terminator.  The special effects in those days were not, you know, even believable.

Start time: 6886.28
End time: 6888.02
Speaker: SPEAKER_05
Transcript:  They weren't like Sharknado level good.

Start time: 6888.20
End time: 6890.26
Speaker: SPEAKER_02
Transcript:  Not even Sharknado level good.

Start time: 6892.46
End time: 6901.12
Speaker: SPEAKER_05
Transcript:  Listen, no matter what evil is going on in the world, nothing's as bad  thought like like somebody green lighted Sharknado.  And that gives us hope for the future.

Start time: 6901.22
End time: 6986.40
Speaker: SPEAKER_02
Transcript:  Yeah. Yeah.  Is Twitter lockout not a thing anymore?  Is that like, is that the fastest meme that ever ended?  This was, of course, Twitter earlier this week  decided to delete a number of bots.  Yeah, we don't know.  I don't know if we ever got the details on how many,  but conservatives decided that they were being targeted  because it turned out oddly, a lot of those bots followed conservative users.  And so this is an example of how there is a divergence  in the reality of the people live in.  Conservatives thought this was proof positive,  proof positive that Twitter was out to block them and hurt them.  And others said, well, of course, you're the first people  who are going to lose followers.  Now, some people actually were real people who were locked out,  and they were asked to verify their phone number.  But that's not a big deal.  We don't know how Twitter, you know, what its criteria were.  We don't know how many it deleted.  This is a real guy, apparently.  Or maybe who knows for all I know, he's actually a Russian controlled account  that decided to make a big deal out of it.  Actually, that's the part of the problem with this is you don't now,  you no longer trust anybody.  You don't know what that it's like we're in the matrix.

Start time: 6987.52
End time: 6996.74
Speaker: SPEAKER_00
Transcript:  Five thousand of my blocked accounts, like, went away.  So my number went from like fifteen thousand.  I'll do like ten thousand. Oh, that's interesting.

Start time: 6997.10
End time: 7008.68
Speaker: SPEAKER_02
Transcript:  Yeah, I should. I did.  I only lost a few hundred followers, but I should look at how many of the people  I've blocked went away. Yeah.  You went that you lost five thousand accounts that you had blocked.  Those were presumably Russian bots.

Start time: 7009.22
End time: 7014.68
Speaker: SPEAKER_00
Transcript:  Well, the most of the accounts I blocked were during Gamergate.  But yeah, I mean, they were gamer games.

Start time: 7015.20
End time: 7025.00
Speaker: SPEAKER_02
Transcript:  So do you think during Gamergate, where you were one of the chief targets  and you had to move and everything was terrible.  Do you think that a lot of that was Internet research agency now in hindsight?

Start time: 7025.66
End time: 7049.86
Speaker: SPEAKER_00
Transcript:  I mean, I don't think it was bots.  I do think that they specialized in a Twitter.  They they use bots to attack me, but I don't think it was like  a Russian propaganda thing.  I think people found out they could buy bots to have certain behavior.  And, you know, we actually worked with Twitter quite a bit in.  Gosh, it was 2060 and 2017 to work on that.  And they were very effective in finally solving that.

Start time: 7050.20
End time: 7062.44
Speaker: SPEAKER_02
Transcript:  Interesting. Very interesting.  So you think that  these were just accounts for sale that were used by.  Was it mostly you think American trolls that were going after you?

Start time: 7062.46
End time: 7063.80
Speaker: SPEAKER_00
Transcript:  Yeah, that's my belief with it.

Start time: 7064.04
End time: 7089.18
Speaker: SPEAKER_02
Transcript:  OK. We've learned so much since the indictment about these  this Internet research agency, which had a significant budget  and was using real accounts, fake accounts, sockpuppet  puppet accounts to influence.  I don't want to even say American election and floods, America thought  and to create to disturb America.  I wouldn't be surprised if Gamergate was part of that campaign.  But it was before really this all became an issue. Right. Yeah.

Start time: 7089.88
End time: 7091.45
Speaker: SPEAKER_00
Transcript:  I mean, their goal is to divide.

Start time: 7092.38
End time: 7093.82
Speaker: SPEAKER_02
Transcript:  Yeah. To divide us. Right.

Start time: 7094.08
End time: 7100.15
Speaker: SPEAKER_00
Transcript:  It's not ideological.  It doesn't have anything with right versus left.  Like they support people on the right and the left.  So there it is.

Start time: 7102.32
End time: 7122.70
Speaker: SPEAKER_02
Transcript:  Intel getting a little bit of heat.  They apparently knew about the chip flaws in this.  The Spectre and Meltdown chip flaws months before they told the US  cyber officials and cert.  In fact, they told Chinese companies, Lenovo and others,  before they told the US government.

Start time: 7124.06
End time: 7131.24
Speaker: SPEAKER_05
Transcript:  This was kind of a known issue on their end, though, for like  20 years, right.  Or for like a very, very long time.

Start time: 7131.50
End time: 7190.50
Speaker: SPEAKER_02
Transcript:  Well, that's also part of the story, isn't it?  That speculative execution,  which is a technique that Intel, AMD and ARM all use to speed up  processor performance, had a potential problem, a leakage of information.  And yes, there was a paper written in 1994  saying exactly that, that you've got to watch out because there's  there's this could be there's, you know, I don't know if they mention  timing attacks, but that these could be problematic.  So Intel probably did have some idea.  But I don't know if they knew how serious it was.  And really, Spectre and Meltdown  were discovered kind of simultaneously by a number of security teams  because timing attacks have become  something we were all aware of.  And they were really looking at timing attacks.  There were other there was Roehammer and other timing attacks  that had been discovered.  And I think the security community then said, yeah, we should see  what else we can do with these.  And that's when speculative execution, you know, really has speculative

Start time: 7190.70
End time: 7202.43
Speaker: SPEAKER_00
Transcript:  execution been in the Intel chips for that long.  Because you have this split.  It's really been in there that long.  The ring one and ring zero executions of it.  All of that. Yeah.

Start time: 7203.02
End time: 7253.56
Speaker: SPEAKER_02
Transcript:  Predictive branching and speculative execution  because Intel was running, it was hitting the wall.  And these were ways to speed up chips.  And it worked so well, by the way, everybody adopted it.  Current and former US government officials have raised concerns  that the government was not informed about these flaws before they became public.  In fact, we had on the screensavers yesterday  Ian Thompson from the register, the register revealed this.  And it wasn't until the register published this article that Intel.  And by the way, Intel's first reaction was yours.  That Intel felt, oh, now we got to tell everybody.  So this is it was Google's Project Zero that informed Intel, AMD  and arm holdings of the problem back in June.  As with most security revelations, they gave the chipmakers  90 days before public disclosure.

Start time: 7256.36
End time: 7257.17
Speaker: SPEAKER_05
Transcript:  Wait, who's the they?

Start time: 7257.74
End time: 7270.10
Speaker: SPEAKER_02
Transcript:  Alphabet was the Google security team that discovered Project Zero.  The fabulous Tavis Ormandy and his his team over there.  Anyway, I don't know.

Start time: 7270.26
End time: 7308.00
Speaker: SPEAKER_05
Transcript:  So I was just talking to my husband, who  is also a geek and all of his friends work at Amazon.  And anyhow, it's really interesting, the apparently Amazon Web Services  to deal with the problem.  The the centers are configured so well that it was a downtime,  minimal downtime. It wasn't that, you know, huge of a deal.  And for people running on Microsoft's servers,  Azure had some significant apparently much more difficult.  But it says something about  the organizational structure of the backbone companies  that we all rely on that are sort of invisible, you know.

Start time: 7308.48
End time: 7317.12
Speaker: SPEAKER_02
Transcript:  And incidentally, that's those are the people who really have to worry  about Spectre and Meltdown because there are multiple people  using the same processor. So if one of them is a bad guy.

Start time: 7319.00
End time: 7334.16
Speaker: SPEAKER_05
Transcript:  Right. And the virtual machines apparently were part of a problem, too,  because if the if you had an apparently could leap, you know,  the problem could propagate.  And so many machines are now virtualized that that that's like  that's like another weird problem that nobody probably thought of.

Start time: 7334.84
End time: 7508.66
Speaker: SPEAKER_02
Transcript:  This should be a good time for me to mention our sponsor.  And then we'll get some final thoughts, including a word from Kylie Jenner.  But first, first, let's talk about Google's cloud platform  and something they called Cloud Spanner, as often as the case.  Google tries these technologies, uses them internally.  Cloud Spanner is the first horizontally scalable,  strongly consistent relational database service tested by fire  in Google's own usage and now available to you on the cloud platform.  You know, it's it's kind of common, common wisdom that distributed databases  can't be both relational and scalable.  But what if you didn't have to make tradeoffs?  What if there were a no compromise solution, a fully managed database  service that's consistent, that scales horizontally across data centers?  It speaks SQL so you don't have to learn a new language.  Introducing Cloud Spanner, it's a mission critical relational  database service from Google Cloud Platform built from the ground up  and battle tested at Google for strong consistency and high availability  at global scale.  Cloud Spanner delivers scalability, high transaction performance  and strong consistency across rows, regions, even continents.  With an industry leading, get this, SLA 99.999 percent.  That's five nines.  No planned downtime, enterprise grade security, multilanguage support.  You could choose from C sharp, Go, Java, Node, Node.js, PHP, Python and Ruby  for the client libraries.  They've got a JDBC driver for connectivity with all the popular  third party tools and it's very affordable.  Pricing is very simple and no surprises.  Very predictable. You can even try it for you.  So find out more about Cloud Spanner.  I'm going to give you a  short URL makes it easier for you to type it in.  g.co slash get Spanner.  That's g.co Google's URL shortener, g.co slash get Spanner.  Find out more about the mission critical relational database service  from Google Cloud Platform.  Battle hardened in the Google servers.  G.co slash get Spanner.  We think I'm really thrilled to have Google Cloud Platform as a sponsor on our shows.  It tells me that Google knows there's a lot of geeks are listening.  A lot of geeks are listening.  Not as many as listen to Kylie Jenner.  Kylie Jenner, I don't know anything about the Kardashians.  But I gather that she is a third generation Kardashian.  And she is apparently very popular with the youngins.  Is that true?  Yes, I think I can confirm that.  She's the youngest person on this show, Michael.

Start time: 7508.74
End time: 7510.90
Speaker: SPEAKER_04
Transcript:  I think you're going to you're going to tell us everything.

Start time: 7511.71
End time: 7512.29
Speaker: SPEAKER_03
Transcript:  So on Thursday,

Start time: 7514.04
End time: 7561.02
Speaker: SPEAKER_02
Transcript:  Kylie Jenner tweets,  See you on Thursday.  I'm going to tell you everything.  Kylie Jenner tweets,  So does anyone else not open Snapchat anymore?  I don't even know she talks like that, but I'm going to pretend she does.  Or is it just me?  So sad.  Actually, shortly after she realized, maybe I might have.  Did I go too far?  So she immediately says, still love you, though, snap.  My first love, Snapchat immediately loses one point three  billion dollars in value on the stock.  One point three million dollars.  Now, to be fair, it also happened that an analyst that day downgraded the stock  and that a lot of this is coming from Snapchat fans who are saying  we don't like the new Snapchat.

Start time: 7561.14
End time: 7582.14
Speaker: SPEAKER_00
Transcript:  But it's it's worth adding like they have no business plan.  The people running Snapchat have completely blown their IPO.  I mean, this is not the best like social media company in the world.  So, you know, I think I feel like Kylie Jenner is just one more  problem, the nail in the coffin, maybe.

Start time: 7584.10
End time: 7603.00
Speaker: SPEAKER_02
Transcript:  But we should point out that their CEO and founder, Evan Spiegel,  is perhaps one of the highest paid executives in the U.S.  after the IPO, he collected a six hundred thirty six million dollars stock grant.  Wow. It does.  It won't vest fully for two more years.  So it's not, you know, don't go hit them up for a billion now.

Start time: 7605.91
End time: 7614.38
Speaker: SPEAKER_05
Transcript:  But you could look at this story in a more optimistic framing.  Right. So content still obviously matters a lot.  Good point. So that's a good thing. Right.

Start time: 7614.50
End time: 7616.48
Speaker: SPEAKER_02
Transcript:  I mean, he's content for what it's worth.

Start time: 7617.18
End time: 7637.04
Speaker: SPEAKER_05
Transcript:  She is content.  She's photos and inane, nonsensical videos.  But, you know, they drive traffic and people seem to care.  And if the content is threatened to go away, then, you know, market values lost.  I actually think that's a good thing for content creators.  It reminds them of their value.

Start time: 7637.34
End time: 7643.82
Speaker: SPEAKER_02
Transcript:  It's not the platform. It's us.  Wow. Yeah.  That's a excellent take.  What a positive. That's really good, Amy.

Start time: 7643.92
End time: 7645.98
Speaker: SPEAKER_00
Transcript:  What a positive thought. I like it.

Start time: 7647.34
End time: 7689.41
Speaker: SPEAKER_02
Transcript:  What I don't like is that the FCC order became official yesterday, Friday,  the restoring Internet freedom order, which, in fact, of course,  kills net neutrality, entered the federal federal registry.  Now, the key here is that now all the lawsuits can begin  now that it's the the regulation of the land, so to speak.  All of the there are many states, attorneys general,  there are many entities, EFF and others who are going to be suing.  So this this begins. But meanwhile,  net neutrality is dead,  at least until some court comes along and protects it,  which I don't think is going to happen.

Start time: 7690.26
End time: 7701.24
Speaker: SPEAKER_00
Transcript:  I was really trying to get through a show without dropping the off.  I have nothing positive to say about this FCC chairman or any part of this process.

Start time: 7701.44
End time: 7762.09
Speaker: SPEAKER_02
Transcript:  Ironically, I thought for a while, well, we still don't have to worry  because the big ISPs, they're not going to, you know, they're they're  realize people are watching them.  AT&T immediately.  The AT&T, the company took out the full page ad saying,  yeah, we love net neutrality.  They immediately rolled out new features that are basically zero rating.  They expanded their sponsored data program.  If you're a prepaid wireless customer, guess who?  Guess who you can watch with no cost to you and data  AT&T's own products, DirecTV, U-verse and full screen.  If you have an AT&T product, you no longer have to pay.  It doesn't count against your data plan.  If you watch our stuff.  I think that's exactly what we were talking about.  Yeah, paid fast lanes.  And it was AT&T who said, no, no, no, we, you know, we believe in net neutrality.  Congress should have evolved.

Start time: 7763.00
End time: 7781.45
Speaker: SPEAKER_05
Transcript:  I judge the Emmy Award judge.  And every year at about this time, I start getting all these DVDs in the mail  there are screeners, you know, for your consideration screeners.  And just as this was happening, I got this giant box of AT&T shows,  which I didn't even know existed.  What? Yeah. Yeah.

Start time: 7782.42
End time: 7814.82
Speaker: SPEAKER_02
Transcript:  Yeah. So the truth is, I'm very the AT&T  Death Star doesn't worry me nearly as much as Comcast, but yeah,  we'll see what will happen.  I think they are going to tread carefully.  Initially, we'll see. But Dropbox, other big stories of the week,  Dropbox on Friday went public with their plans  to file an IPO, talk about another company that doesn't make any money.  But the good news is they're losing less money  instead of losing 200 some million dollars as they did two years ago.  They only lost 110 million dollars last year.

Start time: 7815.48
End time: 7830.62
Speaker: SPEAKER_05
Transcript:  Can you imagine going back in a time machine, 200 years and telling everybody  like if you're going to be a success, if you're if you're like losing,  you're going to lose 20 million dollars, 200 million dollars a year.  You're going to be a success. Brilliant business plan.  You're going to own a yacht. Yeah.

Start time: 7833.45
End time: 7850.18
Speaker: SPEAKER_02
Transcript:  You know, I don't buy stocks in tech companies, so I don't listen to me.  But I don't even understand it.  You know, I do buy stock in a company that has no that is not making money.  And because, well, someday they will or or what they want to.

Start time: 7850.64
End time: 7854.97
Speaker: SPEAKER_05
Transcript:  Kylie, who is a bitmoji is going to cause you.  Yeah. Yeah. Yeah.

Start time: 7856.98
End time: 7868.26
Speaker: SPEAKER_02
Transcript:  Kylie, just remember this future past person.  It's coming. Dropbox is valued, privately valued now at 10 billion dollars.  They plan to raise about half a billion dollars with the IPO. Wow.

Start time: 7869.72
End time: 7872.84
Speaker: SPEAKER_05
Transcript:  Nice lot of nice work if you can get a great amount of money,

Start time: 7874.06
End time: 7892.44
Speaker: SPEAKER_00
Transcript:  especially at the higher competition.  It's you know, I find myself asking all the time, like,  why do I continue paying Dropbox 20 dollars a month when I have, you know,  iCloud Drive and all these other services?  It's it's a well done service.  But I, you know, I find myself increasingly ask why I'm paying for it.

Start time: 7892.90
End time: 7894.82
Speaker: SPEAKER_02
Transcript:  It's hard to think of a differentiator, isn't it?

Start time: 7895.48
End time: 7938.74
Speaker: SPEAKER_04
Transcript:  Yeah. Well, the user interface is phenomenal.  I mean, if you if you've ever tried using Box or even Google Drive is is  for a lot of businesses, I think it makes more sense to use Dropbox  because it's just so intuitive.  You have a you have a folder on your desktop that syncs to the cloud.  And and it's just it's a lot easier to use.  You can see photo previews much more easily than you can in a lot of services.  And so I don't know.  Yeah, I always thought they were all sort of the same.  It's like, oh, I can just kind of interchange any one of these cloud services.  But what I've come to realize is that they're all vastly different from each other.  And interesting.  You know, a lot of my friends prefer Dropbox, honestly.  A lot of my friends that are that own that own and operate businesses.

Start time: 7939.10
End time: 8002.96
Speaker: SPEAKER_02
Transcript:  I had all of them and I still have many of them.  I had iCloud. I had Microsoft's  one drive, Google Drive, some oddball ones like Tresorit.  And I just recently killed them all except Dropbox  because Dropbox, it's an ecosystem thing.  All the iOS apps save to iCloud and Dropbox.  And actually, a lot of them don't even save to iCloud.  And so it's just it's there.  Now, I also am aware of, as we talked about earlier,  that Dropbox is not private, that the keys are held by Dropbox.  So you shouldn't put anything there that you want to put up privately.  So I just use it as if as because services and iOS expected for their storing,  their settings and storing their files and things like that.  So, yeah. So maybe they do.  Maybe they do have a reason to be.  I think we should wrap this up. We've been going long enough.  You guys are champions.  You haven't gone to the bathroom in hours.  Dinner is cold.  And Amy Webb, you could tell your husband, I got the computer glasses.  You recommended he recommended. Yeah. Yeah. That's great.

Start time: 8003.18
End time: 8004.45
Speaker: SPEAKER_05
Transcript:  I will absolutely. After we talk.

Start time: 8005.10
End time: 8064.25
Speaker: SPEAKER_02
Transcript:  They're great. We talked last time.  I realized that's what I need to sit at my desktop because I can barely see it.  And I and I took your advice and got the blue filter in it  and the slightly higher magnification. And it's great.  Nice. That's awesome.  That's great. So thank him for me.  Yes, I will do. Her husband is a ophthalmologist,  but he also is good for advice about that kind of thing.  And Amy is a futurist.  Her book, The Signals Are Talking, is really great.  She gives away all the secrets of her trade in which is bizarre.  But hey, if she's going to do it, you might as well read it.  Why Today's Fringe is Tomorrow's Mainstream.  And we will be looking for the future.  Today Institute Trend Report, which you can get from the website  or go to Amy Webb, I.O. and find out more about everything Amy's up to.  So nice to always always great to have you on.  Thank you, Amy. Brianna Wu, we're rooting for you.  Brianna Wu and 22. No, that's wrong.  We need a slogan.

Start time: 8065.76
End time: 8066.52
Speaker: SPEAKER_00
Transcript:  Wu, you're going to call.

Start time: 8066.82
End time: 8067.87
Speaker: SPEAKER_02
Transcript:  Wu, you're going to call.

Start time: 8069.27
End time: 8070.37
Speaker: SPEAKER_01
Transcript:  I love it. I love you.

Start time: 8071.34
End time: 8075.10
Speaker: SPEAKER_02
Transcript:  You need a meme generator on your website.  You could have people make posters about that.

Start time: 8075.44
End time: 8082.14
Speaker: SPEAKER_00
Transcript:  Yeah, you know, it's like, you know, this is this is 2018.  Positive attention is almost as valuable as negative.

Start time: 8082.86
End time: 8095.07
Speaker: SPEAKER_02
Transcript:  That's a good point.  That's a very good point.  We don't don't forget Bush Cheney.  They didn't they win in 2004?  I believe they did.  They did. Who are you going to call Brianna Wu?  That's who I like.

Start time: 8096.02
End time: 8106.92
Speaker: SPEAKER_00
Transcript:  Do I say if you want to donate to my campaign, it's support.  Dot com. So support.  Bri's BRI BRI a and a dot com.

Start time: 8107.14
End time: 8121.88
Speaker: SPEAKER_02
Transcript:  Support Brianna dot com and find out more about our candidacy.  Brianna Wu 2018 dot com.  And if you're in the Massachusetts, say September,  mark it in the calendar.  The first Tuesday in September, you have a job to do.  Who are you going to call?

Start time: 8122.32
End time: 8129.77
Speaker: SPEAKER_00
Transcript:  Who are you going to call?  Send me a tweet.  How many congressional candidates will be like, yeah, I'll come up coffee with you.  That's nice. That's great.

Start time: 8130.82
End time: 8163.38
Speaker: SPEAKER_02
Transcript:  So so happy to know you, Brianna, and so proud of what you're doing.  It's fantastic.  A lot of people would just, you know, disappear, move to an island.  You said I'm going to take the bull by the horns.  Let's do it. Yep.  I'm a fighter.  Michael Nunez from Mashable, where he's senior tech editor there.  His day has been long.  Deputy tech editor. I just promoted you. Sorry.  I'll take it. Get that senior guy out of there.  The day has been long.  You started early with Mobile World Congress.  I thank you for staying late with us.  Oh, thanks for having me.

Start time: 8163.42
End time: 8173.98
Speaker: SPEAKER_04
Transcript:  Yes. Awesome. Always a pleasure.  Yeah, the panel was so fun.  Aren't they great?  Yeah, really awesome.  I thoroughly enjoyed this like more than I should have as a participant.

Start time: 8174.08
End time: 8294.94
Speaker: SPEAKER_02
Transcript:  I know. I know what you mean.  That's why I do this show.  I just to me, it's all about just I get friends in and I sit back and go,  aren't you guys smart?  Wow. You make me think I learn. I love it.  And I include you in that, Michael.  Thank you for being here. Thank you all for watching.  If you want to watch live, we do at 3 p.m.  Sunday afternoons, Pacific time, 6 p.m. Eastern 2300 UTC.  We have a live stream at twit.tv slash live.  You can listen to a live audio stream, too, on any voice activated device.  I was just playing with the Echo the other day, and you actually now have to say  Echo, listen to tune in to it live.  But if you say that, your Echo will play our live stream so you can see  whatever is going on in the studio at any given time.  Or you can ask for any individual podcast and hear the most recent version.  Echo, listen to This Week in Tech.  You'll get the most recent version.  You can also go to our website, twit.tv slash live.  If you do any either of the live things, please join the chat room  because that's a great way to give us feedback.  I'm watching the chat room as we go.  I get great ideas, links, all sorts of information.  It's really important part of our broadcast day for the live shows.  Please, irc.twit.tv.  If you want to be in the studio live, we had a great live audience today.  It's fantastic. Email us, tickets at twit.tv,  and we will make sure there's a chair out for you.  If you can't watch live, we always have on demand versions of everything we do,  both audio and video at our website and wherever you find your favorite podcasts.  In fact, if you do me a favor and subscribe, that would be great.  Don't forget, I think there's a little time left to take the survey.  Twit.tv slash survey.  Once a year, we try to learn a little bit more about you,  not because we're going to share that with any third party,  but just because it helps us do a better job.  And when advertisers ask us things like, you know, are you are you people  college educated? We have it. We could say, yeah, five percent of them are.  Or whatever. I don't know what the number is. I'm sure it's higher than that.  I hope so. Thank you. I'm not. So I don't know.  Thank you all for being here. I appreciate it.  We'll see you next time. Another twit is in the can. Bye bye.

