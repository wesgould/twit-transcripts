;FFMETADATA1
title=Artisanal Pickles from Williamsburg
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=727
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf58.76.100
Failed to align segment (" You looked like a drumstick."): backtrack failed, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Start time: 0.18
End time: 22.94
Speaker: SPEAKER_07
Transcript:  It's time for Twitter this week in Tech. Caroline Haskins is here from Motherboard.  Mike Elgin has settled down from his trip around the world to this chair right here next to me.  We're going to talk about the biggest fine in FTC history, Instagram versus the bullies,  and Caroline will talk about what she's learned about a technology local cities are using to spy  on you and me. It's all coming up next on Twitter.

Start time: 25.66
End time: 28.76
Speaker: SPEAKER_01
Transcript:  Netcasts you love. From people you trust.

Start time: 32.85
End time: 34.18
Speaker: SPEAKER_04
Transcript:  This is Twitter.

Start time: 60.06
End time: 159.02
Speaker: SPEAKER_07
Transcript:  And by Mint Mobile.  Mint Mobile provides the same premium network coverage you're used to, but at a fraction of the  cost because everything's online. To get your new wireless plan for $15 a month and get the plan  shipped to your door free, go to MintMobile.com slash twit. And by Wasabi, hot cloud storage.  Thinking about moving your data storage to the cloud, Wasabi is enterprise class cloud storage  at one fifth the price of Amazon S3 and up to six times faster with no hidden fees for egress or  API requests. Calculate your savings and try Wasabi with free unlimited storage for a month  at Wasabi.com code twit. And by ZipRecruiter. Hiring is challenging, but there's one place you  can go where hiring is simple and smart. That place is ZipRecruiter where growing businesses  connect to qualified candidates. Try it free at ZipRecruiter.com slash twit.  It's time for twit this week at tech, the show we cover the week's tech news. And look who's here  in studio. Mike Elgin is joining us. He is off the road in town and whenever Mike's in town,  we'd like to get you in the studio. Thank you, Dale. It's great to be in town. He is a gastronomad. In  fact, gastronomad.net. What was your most, was Barcelona your most recent event? Barcelona is

Start time: 159.08
End time: 229.26
Speaker: SPEAKER_08
Transcript:  the next one. Oh, it's coming. We still have some space open for this one. That's what this post is  all about. Cava Barcelona. So what we do is everybody loves Barcelona, but a lot of people  don't know about the nearby Cava wine country. So we stay there for five nights, six days,  and we explore the wine tasting, we make cheese, we do all this kind of stuff with  baked bread, but we take a couple of surgical strikes into the city of Barcelona.  And it's just the most fantastic thing in the world. The food in Catalonia is incredible.  We know exactly where the most authentic and best tapas places are where just like the best  baker in Spain, that woman there, she gives us an exclusive. The best baker in Spain.  Two years ago, she was named the best baker in Spain. She is amazing, but she's a good friend.  We go in and we explore. If you go down, this is a good one. See this one right here. There's the cave.  So this is Cava. They store it in bunkers. Cava is a sparkling wine, like champagne.  Yeah, it's like Prosecco, champagne, something like that. But this guy stores it in a bomb shelter  from the Spanish Civil War. And it's in the middle of a vineyard. I can't tell you where it is.

Start time: 230.58
End time: 232.92
Speaker: SPEAKER_07
Transcript:  Generalist of the World Francisco Franco is buried there.

Start time: 233.08
End time: 241.96
Speaker: SPEAKER_08
Transcript:  But it's a fascinating region and the culture of Catalonian food, which people don't quite get  when you go to Barcelona on vacation, don't quite get to it. But we go straight to it.

Start time: 242.14
End time: 244.80
Speaker: SPEAKER_07
Transcript:  I could spend years in Barcelona and you'd never plumb the depths.

Start time: 244.88
End time: 246.48
Speaker: SPEAKER_08
Transcript:  Yeah, absolutely. Absolutely true.

Start time: 246.62
End time: 255.84
Speaker: SPEAKER_07
Transcript:  We also want to welcome a brand new member to our team. I'm really pleased to welcome from  Motherboard the vice publication, Caroline Haskins. Hi, Caroline.

Start time: 257.03
End time: 257.07
Speaker: SPEAKER_04
Transcript:  Hi.

Start time: 257.30
End time: 336.08
Speaker: SPEAKER_07
Transcript:  Great to have you. Welcome. Don't be intimidated. This is going to be a lot of fun.  We are going to start. Mike's shaking his head. He says it's not fun. We're going to start today  with Facebook, the largest fine in the history of the Federal Trade Commission. The FTC had a consent  decree with Facebook in 2011 that they would not do whatever his Facebook does. They did it,  apparently, when some of our data went to Cambridge Analytica. So the FTC got together,  voted three to two. Interestingly, it was the Republicans that voted for the fine,  the Democrats that voted against the fine. The largest fine in the history of the FTC,  five billion dollars. That sounds like a lot of money, right?  Sounds like a good Dr. Evil.  Except Facebook's stock price went up after the fine, six billion dollars.  So Mark Zuckerberg is smiling because he made money. He made money. I guess Facebook was smart.  They had said in their quarterly report that they expected this five billion dollar fine.  They budgeted it.  And so they prepared the market, right? And then when the fine actually was five billion, as usual,  you sell on the rumor, you buy on the news, or you buy on the news and you sell on the rumor.  I can't remember, but whatever was good news.

Start time: 336.76
End time: 346.88
Speaker: SPEAKER_08
Transcript:  Everybody laments the political division of society, but both Republicans and Democrats  can get behind crushing Silicon Valley. That is a nonpartisan issue as Americans.

Start time: 347.26
End time: 352.58
Speaker: SPEAKER_07
Transcript:  So Caroline, is five billion dollars a slap on? That sounds like a lot of money. Is it a slap on  the wrist?

Start time: 353.94
End time: 368.66
Speaker: SPEAKER_02
Transcript:  It kind of seems like a drop in the bucket. I don't know. I remember a couple of months ago,  there were a couple of other figures that were being thrown around and it seemed like they were  potentially going to be hit with a lot more money, but it really doesn't seem like this is going to  have an impact on them at all.

Start time: 368.90
End time: 428.58
Speaker: SPEAKER_07
Transcript:  Kara Swisher said you really want to fine them. Add a zero to the five. Make it 50 billion.  Elizabeth Warren said Facebook made five billion in profits in the first three months of the year.  Actually, that's not true. I think it was revenue, not profits.  The company's too big to oversee and this drop in the bucket penalty confirms that.  It is true. Look, anything with a B is a lot of money for any company, but  Facebook had 15 billion in revenue. Oh, I'm sorry. It is 15 billion in revenue last quarter,  22 billion in profit. So it was one quarter profit.  You could see the stock jump there. Mike Isaac said the real story is that Facebook shares surged  with that fine. So clearly the market's saying, slap on the wrist.  You're not on Facebook. In fact, I used you as an example, Mike Elgin, because you have Mike's  nice book.

Start time: 428.72
End time: 457.36
Speaker: SPEAKER_08
Transcript:  Yes. So what I did was last year I said I was getting off 4th of July and I spent all these  months this year harassing and criticizing Facebook. Of course, they did no good at all  because they were censoring my posts, clearly. But I replaced it with a Google folder I called  my nice book. It's a public folder, so anybody can follow it just as they would on Facebook.  Yes. So if you search for Mike Elgin nice book, you'll find links to it and I invite you all.  But this is my personal, this is my family.

Start time: 457.46
End time: 462.73
Speaker: SPEAKER_07
Transcript:  So it's really, it's the kind of pictures you would have put up.  Is there text though or is it just picture data?  There's text. You can do posts.

Start time: 463.28
End time: 489.04
Speaker: SPEAKER_08
Transcript:  Where do you put your dank memes? Can you put them up there too?  No, you cannot. So each person's, this is the beauty of it. This is how a social network should  work. Only I can post in my nice book and I can follow your nice book and then I see it in the  stream. So if you're on Google Photos and you go to sharing, which nobody ever does, it's the,  it's the tab on the far right. You get all the stuff that's been shared with you, all the,  you know, and it's kind of like a social network. So I think Google could turn into a little bit.

Start time: 489.22
End time: 499.90
Speaker: SPEAKER_07
Transcript:  I follow your nice book.  Yeah, there it is.  There it is.  Yeah. So I could make one of these, if I wanted to make one, I would just set up a sharing and  say it's public.

Start time: 500.14
End time: 528.60
Speaker: SPEAKER_08
Transcript:  Yes. And it's kind of, I believe that's the default actually that is public. And then you just  share the link with family and friends by email. People can choose their own notifications. So some  people get it on their phone. Some people get an email. Some people don't get the notifications.  They just see it in Google Photos when they go. But it's beautiful. These photos are full quality.  If you click on these photos, they're full quality.  Much better than Facebook.  Much better than Facebook. And you can, you can add little, you know,  comments. You can like things and it's an, it's a stream without ads.

Start time: 528.84
End time: 535.64
Speaker: SPEAKER_07
Transcript:  That's Mike's wife, by the way, Amira, who's so beautiful sitting in a restaurant that apparently  has parking meters called the Naughty Pig.

Start time: 535.94
End time: 549.04
Speaker: SPEAKER_08
Transcript:  That's on Sunset Boulevard and two nights ago. But it's, it's a wonderful alternative.  Cause really what we want to do on Facebook is we want to see a stream of our people we care about  and the photos.

Start time: 549.28
End time: 556.24
Speaker: SPEAKER_07
Transcript:  Cause I say get all the time, I say get off Facebook. I'm off Facebook. Caroline,  do you, you, you have to, it's an occupational hazard be on all the networks probably.

Start time: 557.24
End time: 563.04
Speaker: SPEAKER_02
Transcript:  Yeah. Yeah. I feel like it would be sort of irresponsible for me to like not even know  what's going on.

Start time: 563.64
End time: 566.24
Speaker: SPEAKER_07
Transcript:  Wish you couldn't, you could like get rid of Instagram.

Start time: 568.20
End time: 596.20
Speaker: SPEAKER_02
Transcript:  I wish I could. It would be nice. The strange thing is that a lot of my peers still use  Facebook for event invitations. And I've noticed people a little bit more recently  using different types of forums, but it almost seems like for a lot of people,  at least in my immediate social circle, that Facebook is still a way to guarantee that  someone is going to be able to see something. But I don't know. I want to go back to the  days of like personal websites. Like early 2000s.

Start time: 597.10
End time: 618.40
Speaker: SPEAKER_08
Transcript:  Yeah. I'm sorry to step on your comment there, Caroline, but this is what I hear.  I'm talking to lots and lots of people all over the world, Leo, because in Europe.  But you have a blog.  I have a blog, but I know lots of people in Europe who use one, two or three social  things. And those things are always Facebook properties. So I know people do Facebook,  Instagram and WhatsApp, or they just do Instagram and WhatsApp.

Start time: 619.71
End time: 631.88
Speaker: SPEAKER_07
Transcript:  And that was one of the hardships for me is when I got rid of Facebook, I felt like,  well, I should also get rid of Instagram. I didn't really use WhatsApp, but I should  get through all three. If I have any one of them on my phone, I've given Facebook an  entree into my life.

Start time: 632.06
End time: 638.24
Speaker: SPEAKER_08
Transcript:  Absolutely. And this is the interesting thing about WhatsApp. Americans don't use  WhatsApp much, but everybody else.

Start time: 638.78
End time: 646.96
Speaker: SPEAKER_07
Transcript:  Well, and that's what I hear when I say get off Facebook. What I universally hear is  that's a privileged point of view. I can't get off.

Start time: 647.18
End time: 672.96
Speaker: SPEAKER_08
Transcript:  This is the problem with Facebook. We're on the brink where we everybody has talked  to some countries.  It's the internet.  Well, exactly. And some people, lots and lots of people say, I don't use the internet.  I use Facebook.  Right.  And so it's AOL for the 21st century.  And the scheme that Mark Zuckerberg is hatching as we sit here is he's trying to turn it into  WeChat. So in China, WeChat is everything. It's an e-commerce platform.  That's why Libra coin. That's why he's got a currency because he wants this to be.

Start time: 673.14
End time: 674.36
Speaker: SPEAKER_07
Transcript:  Everything goes through Facebook.

Start time: 674.82
End time: 687.92
Speaker: SPEAKER_08
Transcript:  And so we're already like everybody I talked to says, oh, I'm not going to get off Facebook  because I need it for this reason or that reason. Caroline has her reasons.  Everybody has a reason why they need Facebook or Instagram or WhatsApp.  And this is a problem we shouldn't need.

Start time: 687.98
End time: 704.14
Speaker: SPEAKER_07
Transcript:  Caroline, I thought I had heard that younger people thought maybe maybe you're not as young  as you look, but younger people said Facebook is like your parents' social network.  And there and people under 30 say are Snapchat or TikTok.  There are other places.

Start time: 705.92
End time: 710.00
Speaker: SPEAKER_02
Transcript:  Right. Right. Yeah. I think there's definitely still that reputation.

Start time: 711.26
End time: 718.30
Speaker: SPEAKER_07
Transcript:  But in college, did you use Facebook? My daughter is 27, still is on Facebook  because that's how she stays in touch with her college friends.

Start time: 719.70
End time: 742.80
Speaker: SPEAKER_02
Transcript:  I did. Yeah. I mean, Facebook was used in terms of like finding college roommates freshman year,  doing introductions. And that's sort of pivoted onto Instagram, which is, you know, again,  still a Facebook property. So it seems like you're still sort of relying on this biggest  common denominator. Like there's this assumption that you have an account on at least one Facebook.

Start time: 742.96
End time: 764.56
Speaker: SPEAKER_07
Transcript:  It's it is really the reason Facebook is an incumbent and it will be hard to unseat is  so-called network effect. You have to be where everybody is.  There's no point. I mean, I'm on Mastodon. I'm on Ello. But there's no point because  it's me and a couple other people. But there's I don't even know them.

Start time: 764.72
End time: 793.24
Speaker: SPEAKER_08
Transcript:  And we're looking at each other going, hmm. But this is true. But here's the problem. So  the only social network that's bigger than Facebook is email, which is about three or  four times the size of Facebook. And you're a big proponent of mail newsletters.  But the problem is people have lost control of their inboxes. They're afraid of it.  They don't want to go there. Yeah. And so but but if people could just get  a handle on their email inboxes, email would be the ultimate social network because you could be  Mastodon and use email based notifications and be like everybody's on the same social network.

Start time: 793.76
End time: 802.48
Speaker: SPEAKER_07
Transcript:  But people are reticent. I often say that if you want to stay in touch  with your college friends or your grandparents, email would work. Right. But I guess it's not

Start time: 802.58
End time: 833.76
Speaker: SPEAKER_08
Transcript:  that there's not that but it's it's email should be a delivery mechanism for the notification.  It's a one on one conversation. It doesn't feel like that stream like you're tapping into what's  happening and wade into the pool of the zeitgeist. And this is how the social networks get us.  They've tapped into our psychology and makes us feel like we've got our finger on the pulse.  Whereas email feels like your finger is not on the pulse. Right. And so it's the it's all these  feel you know, feel based emotion based tricks that they use the little red thing with a number

Start time: 833.90
End time: 844.68
Speaker: SPEAKER_07
Transcript:  in it. People have to click on that. So Caroline should it would it does he does the FTC have any  solution if it had been 500 billion would have that have mattered? It doesn't it feels like

Start time: 845.02
End time: 878.10
Speaker: SPEAKER_02
Transcript:  the FTC is helpless in the face of this. Right. It's hard to say. I mean, without I mean, a fine  is one thing. But I mean, regulations that are going to be preventing something like in a Cambridge  analytical situation from happening again would be I mean, more ideal. And I mean, that doesn't look  like I mean, I know that legislation is on the way in California, but it doesn't seem like the  regulations we need are on the way and anytime anytime soon. So well, it's hard to say whether

Start time: 878.30
End time: 966.72
Speaker: SPEAKER_07
Transcript:  a fine would be like 100 percent the answer here. And a lot of times when we talk about regulation,  there's always this issue of unintended consequences. Casey Newton has a great article  this week on the verge talking about the ugly side of Facebook's pivot to privacy. So Facebook's  solution was this Mark Zuckerberg posting, Oh, OK, no problem. Everything will be end to end  encrypted private. But as Casey points out, now what you have is private groups like that horrific  Border Patrol group that ProPublica found last week. It's private. You know, they had to dig to  find it. Le Monde found in France, a group of 56,000 people devoted largely to making  anti-female comments. French group, a Twitter user stumbled across a Facebook TV ad investigated.  One of the featured groups had found a Facebook TV ad. Oh, he found it. And he posted some of  the ugly posts. Large private. This is Elizabeth Dwaskin writing in the Washington Post. Large  private groups remain unmoderated black boxes where users could freely threaten vulnerable  populations. Actually, she's quoting Jonathan Greenblatt, who's with the Anti-Defamation League.  Without any AI or human moderators, it's easy to orchestrate harassment campaigns. It becomes  4chan or 8chan. It becomes a secret place for evilness. So that's not a solution either.

Start time: 968.32
End time: 996.96
Speaker: SPEAKER_08
Transcript:  This is going to sound horrible, but I'm less bothered by this sort of thing because-  In private, you don't mind?  Well, it's not that I don't mind. I mind that people are evil. It bothers me. But they're  going to be- But at least they're not in my face evil.  Well, I mean, to me, this is more akin to just having an evil conversation in your living room  or whatever. Yeah, that's going to happen. What bothers me is the viral mechanisms of using  algorithms to bring in lots of people and sort of change their minds about-

Start time: 997.06
End time: 1022.56
Speaker: SPEAKER_07
Transcript:  See, I always thought, and maybe this was naive of me, but that light was a disinfectant, that you  lift up the rock and you let the world see this and the world will rear back in revulsion and say,  no, this will not stand. We don't want Nazis. But what has in fact happened is the Nazis have  taken over Twitter. There's no revulsion. Well, the unfortunate thing is-

Start time: 1022.56
End time: 1031.12
Speaker: SPEAKER_04
Transcript:  Karsten Bondi, my producer. The unfortunate thing is that  Yahoo's, or YouTube's algorithms sees revulsion as excitement.

Start time: 1031.16
End time: 1035.20
Speaker: SPEAKER_07
Transcript:  That's positive. That's engagement. I don't care if you're disgusted. It's engagement.

Start time: 1036.54
End time: 1041.04
Speaker: SPEAKER_08
Transcript:  Who is it that said that it's like people slow down to look at a car accident and so the internet

Start time: 1041.20
End time: 1064.32
Speaker: SPEAKER_07
Transcript:  responds by producing more car accidents? More car accidents, yeah. This is the slavish  following of the algorithm is a bad thing. I've often said that the real problem with  YouTube is the recommendation engine, the algorithm. Clearly, the problem with Facebook  is the algorithm that drives the news feed because absent any human oversight, these are  optimized for engagement because that's more revenue and that's where you get these horrible,

Start time: 1064.98
End time: 1127.20
Speaker: SPEAKER_08
Transcript:  vicious circles that promote offensive behavior. To me, the elephant in the living room,  and that's not a GOP pun by the way, the elephant in the living room, which I don't think he's  exploring here enough, is that you talked about the disinfectant quality of light.  What Zuckerberg has proposed for his big privacy pivot, which is complete BS, is to unite all of  his messaging platforms and have end-to-end encryption so nobody can see inside that black box.  The other part of it is the solution to bullying and hate speech and all that stuff  are algorithms that work behind the scenes that nobody can see how they work or what they're  doing and all that kind of stuff. We're entering into an era where all this stuff, where the  conversations are happening beyond anyone's ability to see it and also where the solution,  the algorithms are happening behind the scenes with nobody's ability to see it. This is kind of  like a golden age of journalists can go and expose these things and write articles like Casey Newton's  article. That's not going to happen. We're on the brink of him not having any access to this stuff.

Start time: 1127.26
End time: 1135.28
Speaker: SPEAKER_07
Transcript:  The public won't be able to find it. He's secret. Poor Caroline, you didn't know you're going on  the grumpy old man complain about the You Kids Today show.

Start time: 1141.86
End time: 1191.06
Speaker: SPEAKER_02
Transcript:  I just think it's strange that this whole pivot to groups and like emphasizing groups on Facebook  has been presented as this solution both to like hate speech and fake news and for making Facebook  just a place to want that people want to go. I mean, anecdotally, it seems pretty clear that  Facebook groups is one of the only reasons that people would go on Facebook for pleasure.  But in terms of that's interesting. Yeah, yeah. In terms of like, I don't know, mean groups or  like the rise of certain Facebook groups where it's like Facebook group where we all pretend to be X  like, for instance, a really popular one is a group where we all pretend to be boomers  and everybody makes fun of the way that their parents tell me you're not in that group.  I joined for journalistic purposes. Oh, yeah, sure.

Start time: 1193.00
End time: 1232.08
Speaker: SPEAKER_07
Transcript:  I think we boomers should invade Area 51. Oh, no, that's another one. Sorry.  That's a big event. Oh, that's interesting. See, this is where I am at a disadvantage. So Facebook  has kind of pivoted from what its original promise was you follow the news feed and see what your  friends and family are up to, to finding affinity groups. And we know affinity groups are the worst  thing in the world because really what happens is whatever, you know, it's a mob mentality, whatever  that prime factor for that affinity group is becomes amplified. It depends. I mean, they say

Start time: 1232.32
End time: 1292.72
Speaker: SPEAKER_02
Transcript:  that certain types of flag posts or fake news will be deprioritized even in private Facebook groups,  which I mean, I think personally, at least in some cases, I mean, not in the case of like  outright hate speech, but in terms of certain gray areas, it might be a better solution than  just pulling this stuff off the internet entirely and just having really no grasp on how different  communities are spreading different kinds of information. But, you know, at the same time,  pretending that Facebook groups is going to be like solving all of Facebook problems. Well, I mean,  your feed is going to still be including a lot of the same type of content. I mean, at the end of  the day, it's just going to be like a category specific news feed with a couple of specific people.  And I mean, when you open Facebook right now, I mean, almost every time I open it,  it'll say right at the top. This many of your friends have joined Facebook groups and find new

Start time: 1292.84
End time: 1321.78
Speaker: SPEAKER_07
Transcript:  Facebook groups. It's so funny because Google Plus in its last dying days did the same pivot.  Didn't save it. But they said, join a community, join a community. So there must be some research  that says, oh yeah, people are happiest when they're in a community. Yeah. And people do  terrible though, because the communities are horrific. I my biggest, my biggest or awesome.  Yeah. Thank you, Karsten. My piece. What's what Karsten? What groups are you in? I also am a

Start time: 1322.24
End time: 1333.90
Speaker: SPEAKER_04
Transcript:  Facebook refugee, but oh, okay. He's one of those guys who pretends to be a boomer.  There are, there's definitely something to be said for affinity groups where people can find

Start time: 1334.14
End time: 1359.24
Speaker: SPEAKER_07
Transcript:  people like them. Well, yeah, in a way that's what geeks did in the very beginning. That's what  we did. We found each other. You know, I keep thinking that the platforms can't solve this.  It's not going to be in government can't solve it. I only humans can solve it, but humans were so  flawed. I don't know if there's a solution there either. I feel like it's, I'm starting to despair,

Start time: 1359.46
End time: 1380.64
Speaker: SPEAKER_08
Transcript:  but we have to be clear about what the problem is. And it's why it bothers me that, you know,  that somebody is saying something mean on the internet somewhere is not the problem. Right?  If people should have be able to have private groups, no matter what they say to each other  in those groups, private conversations, people should be able to say on the telephone, for example,  you shouldn't have algorithms, listening to conversations. Oh, you shouldn't talk about

Start time: 1380.68
End time: 1419.92
Speaker: SPEAKER_07
Transcript:  that. Yeah. And that's historically the case. That's what section 230 of the  internet, whatever it's called, decency collaboration. What is it called? I have no idea.  I don't know what it's called. The communications decency act of 20s,  1996, I think. Section 230 said that just like the phone system, you can't expect platforms,  online services to police content. They're just conveyors of content. And so by the way,  President Trump wants to get rid of section 230. There's a move afoot to do that. So that may be  actually under assault anyway. But I don't know if that protects it either. I don't know what the

Start time: 1420.04
End time: 1482.06
Speaker: SPEAKER_08
Transcript:  solution is. I really don't. I really think we need to focus on algorithms and amplification.  That's what Facebook says, algorithms. And not, no, but focus on the problem with algorithms.  Oh. And not the focus on private little groups where nasty little people talk to each other.  Let them do their things in private. They try to make it seem like a bigger problem by saying,  oh, they could be plotting and planning all this stuff. Yes. That stuff is going to happen. And  when they break the law, they need to go to prison when they break the law in real life. But whatever  happened to free speech, we should have a place for free speech. What we shouldn't have is a place  where companies are profiting. And so Jason Calacanis, of all people, proposed a new social  network, which he described as a simple feed with no algorithmic filtering, one ad on the top of  the page. You can pay $50 a month to get rid of the ad. And it's just, you get everything that  the people you follow post in reverse chronological order. End of story. That's kind of what Facebook  was supposed to be in the beginning. Exactly. But there's no money in that. Right? I mean,  you can't be wildly, you can't end up being the most powerful person in the world and one of the

Start time: 1482.24
End time: 1494.08
Speaker: SPEAKER_07
Transcript:  richest. There has to be somewhere in between no money and $22 billion a year. There has to be some  mid ground where you make a decent living. It's a good service. People use it. It's called Macedon.

Start time: 1496.76
End time: 1513.20
Speaker: SPEAKER_08
Transcript:  I don't give a crap if Mark Zuckerberg is rich. I really don't care if he makes a lot of money.  What I care about is that people can have conversations. We have free speech, but we also  have- And we don't amplify the negative speech because it's good for engagement. We're not  creating rabbit holes and all this kind of stuff. So that's where the problem is. It's not these

Start time: 1513.30
End time: 1545.20
Speaker: SPEAKER_07
Transcript:  little private groups, I don't think. And then there was this week's social media summit at the  White House where the president said to a bunch of conspiracy theory social media folks,  the crap you guys think of is unbelievable. It is. It is, even though it's often believed. I guess  they did not invite Facebook or Jack Dorsey from Twitter, anybody who was actually from one of the  platforms to this quote social media summit was really just a bunch of- It was mostly right winged.

Start time: 1545.28
End time: 1549.72
Speaker: SPEAKER_08
Transcript:  Right wing pundits. They had to pull a few at the last minute because they found all kinds of

Start time: 1549.96
End time: 1572.24
Speaker: SPEAKER_07
Transcript:  anti-Semitic and racist stuff. And of course, Josh Hawley has proposed legislation that would  eliminate section 230, treat every political opinion equally because of this. I don't think  there's any evidence for, but there's a belief that's in the conservative circles that somehow  Twitter and Facebook are biased against conservatives. I don't see any evidence of that.

Start time: 1573.00
End time: 1618.56
Speaker: SPEAKER_08
Transcript:  The evidence is, this is actually one of the problems. You don't have insight into why they  make the decisions they make. So for example, let's say there's some- Well, it is invisible,  isn't it? The algorithms are invisible. Let's say there's an alt-right person who posts an alt-right  type post and then gets banned. And then all of his followers are like, ah, you see, it's conservative  bias. But what they don't know is that Twitter might tell you, yeah, but they also had this other  account. They had these five other accounts where they were orchestrating bots and doing all this  other stuff. And the combined effect of all those things were why we banned. But again, we have to  take their word for it because algorithms are company secrets. They don't have to reveal them  and they won't. So the Facebooks and the Twitters are really on the spot. They're essentially the  police and the judge and the jury and everything. So that's-

Start time: 1619.04
End time: 1638.44
Speaker: SPEAKER_07
Transcript:  Trump's evidence that there's a bias against him is because in the old days, he would tweet that  the Obama campaign was spying on him and it would, in his words, take off like a rocket.  And now it doesn't so much anymore. It's like, that's your evidence?  He's got how many tens of millions of followers? I think it's pretty clear Twitter is not blocking

Start time: 1638.58
End time: 1657.42
Speaker: SPEAKER_08
Transcript:  followers. The president has narcissistic personality disorder. If Georgia were here,  she could diagnose it for us. But this whole summit seemed to be a place for him to vent and  say that the fact that I don't have more followers than Obama is the reason why something has to  change and we're going to do something. And he was threatening- You know what? I should have more

Start time: 1657.56
End time: 1662.32
Speaker: SPEAKER_02
Transcript:  followers. So should I. Yeah. Okay. I'm just saying. Caroline? Tweets were printed on poster

Start time: 1662.42
End time: 1690.88
Speaker: SPEAKER_07
Transcript:  boards. So, and a sign. That shows you, right? That's it right there. That's things boomers do.  Print out tweets and put them on a poster board. That's what they do in the group that she's in.  So Instagram used to be kind of the refuge. You would go to Instagram. Oh, it's nice. It's  pictures. It's nice. And now Instagram is just as corrupt and messed up. Caroline, you've written  about this. It's just as bad on Instagram, right? I haven't been in a while. So is it?

Start time: 1692.34
End time: 1781.84
Speaker: SPEAKER_02
Transcript:  Yeah. They've had a problem with a rise of certain types of extremist hate accounts  with QAnon accounts, with anti-vaxxer accounts. And Instagram has been taking some steps to design  infrastructure that blocks certain hashtags in the same way that if you search, say, for things like  proanorexia, those hashtags are blocked. And so they're working on doing the same kind of thing  for anti-vaccinations and those types of ideologies. But I mean, the last time I  checked that feature hadn't rolled out. But I mean, yeah, it's just strange that  there was a period when I went on Facebook and you search for anti-vaxxer content and there were,  I mean, there were no results. The groups seem to have been banned. But then when you went on  Instagram, all of those accounts were still up. Yeah. Yeah. Yeah. Yeah. I don't know. In terms of  the social media summit, I think one important thing to keep in mind is that he also invited,  I think it was the CEO or whoever founded that social network Minds, M-I-N-D-S, which for at  least a certain period of time was a favored group among, I mean, Nazis. It was like GAB.  Yeah, exactly. I don't know. I think it speaks volumes. It goes, I think it goes beyond Trump  being angry about himself and trying to send a political message by, I mean, obviously the

Start time: 1782.00
End time: 1812.24
Speaker: SPEAKER_07
Transcript:  types of people that he invited to that. You have to, he has to see these social networks  as very powerful for the 2020 election as places that they can use. I mean, he does, he uses Twitter  very effectively. Yeah. And they have to see these as the place where the campaign is going  to play out next year, right? That's where it's going to matter. The truth is that- That scares me  the hell out of me, by the way. Everybody talks about how Twitter is so influential in shaping

Start time: 1812.44
End time: 1817.20
Speaker: SPEAKER_08
Transcript:  public opinion, all this kind of stuff, and it just isn't true. What happens is the media picks up on

Start time: 1817.34
End time: 1831.50
Speaker: SPEAKER_07
Transcript:  Twitter- But that's the respect it's true is that, yeah, Twitter's only a couple hundred million  people. It's not a big deal, but the media treats it as if it's the most important thing in the world.  And if anything happens on Twitter, suddenly that's a story- To be clear, editorial choices

Start time: 1831.82
End time: 1841.92
Speaker: SPEAKER_08
Transcript:  are what make everything that happens on Twitter such a big deal. If the media completely ignored  what happened on Twitter, they would have no effect. I mean, it's really not that- Have you seen this

Start time: 1842.06
End time: 1856.76
Speaker: SPEAKER_07
Transcript:  yet on Caroline on Instagram where if you put comments in that are, I guess, bullying, that it  will say, wait a minute, do you really want to say that? Let's keep Instagram a supportive place.

Start time: 1858.16
End time: 1882.48
Speaker: SPEAKER_02
Transcript:  Rethink that comment. It's really interesting because I went to a meeting with Instagram  a couple months ago when they were talking about the things that they were doing to try and combat  bullying. And I think a large part of the difficulty in moderating that type of thing is,  I mean, A, defining bullying and B, figuring out a way to do that that isn't preemptive.

Start time: 1884.60
End time: 1886.16
Speaker: SPEAKER_07
Transcript:  They don't want to censor it. They just want to-

Start time: 1887.50
End time: 1943.12
Speaker: SPEAKER_02
Transcript:  Right. I mean, even in the example that they used, I think they said, oh, if you're using the words,  it's clear that the words, ugly and stupid, triggered that pop-up to say, oh, you want to  say that. But are those really the mechanisms that people use to make others feel excluded?  They were talking about also induced FOMO, which is-  It's difficult to define. It's basically where the example that they gave-  Instagram is made of FOMO.  That's the problem. The whole idea is that if you post something at a certain place,  and a person may not have been invited, and you say, you at the person, and you say, oh,  don't you wish you were here? Do people actually do that? I think that was one of the main questions

Start time: 1943.18
End time: 1980.34
Speaker: SPEAKER_07
Transcript:  that I had coming out of that. Don't you think they do? Haven't you ever seen stuff like that?  I'll tell you where I see it. Every time I go to a concert now, most of the selfie taking is the  person turned away from the artist, videoing the artist singing and them in the picture.  What's the whole point of doing that? To show all your friends what a great time, how good your life  is. I'm at the concert. It used to be you'd video the singer, right? Because, oh, you love this  singer, you're going to like the video. Now it's, look at me at the concert. That's FOMO.

Start time: 1981.52
End time: 1988.32
Speaker: SPEAKER_02
Transcript:  That's induced FOMO. Right. They clearly were trying to make it seem as if that sort of thing is

Start time: 1989.08
End time: 1993.84
Speaker: SPEAKER_07
Transcript:  malicious. It's not malicious. It's just neurotic. It's just narcissistic.

Start time: 1996.20
End time: 2042.02
Speaker: SPEAKER_02
Transcript:  Hasn't it almost to judge people that want to document those types of experience?  Yeah, you're right. Yeah.  If you want to share that, if that's what makes you feel good, if you want to make sure you  capture something that made you happy, I'm hesitant to be like, oh, that's bad.  But when you're trying to define what actually is bad and what is harmful, I don't know. I mean,  the social ways in which people try and exclude and alienate and make other people feel bad,  that's not something that an algorithm can easily pick up.  No, it's subtle.  Right. This is only rolling out on the English speaking part of Instagram. This is only going  affecting a marginal part of their audience anyway.

Start time: 2042.20
End time: 2073.60
Speaker: SPEAKER_08
Transcript:  Surely we're talking about children though, right? I mean, adults don't like...  One of the problems they have is that they talked about how some bullying victims,  if they block somebody, it's like a big problem because they're with the bully every day. In  other words, they go to school with the bully. And so this even blocking and the mechanisms that  exist for people to protect themselves don't work because of the fact that people are in real  communication. That sounds to me like high school or junior high or something like that.

Start time: 2073.78
End time: 2105.52
Speaker: SPEAKER_07
Transcript:  I mean, I have to say, when I was posting stuff on Instagram, I would actually consciously not  try to show off on Instagram because it felt like it was about, look how great my life is.  And I was concerned. You know that when you're looking at these people's lives,  that's just the slice that makes it look good.  Everybody's life has equal amounts of bad stuff and good stuff. And to just put the pictures of  the good stuff. So I try to take pictures of all the bad stuff that happened to me to make people

Start time: 2105.66
End time: 2110.32
Speaker: SPEAKER_02
Transcript:  feel better. It's very freeing to have low standards.  Leah's going to the bathroom again.

Start time: 2110.56
End time: 2150.08
Speaker: SPEAKER_07
Transcript:  It's very freeing to have low standards. That's going to go in my tombstone actually. Thank you,  Caroline. We are very pleased to have Caroline with us. Caroline Haskins is a reporter for  Motherboard and Vice, a great site. In fact, I want to talk about Palantir when we come back  because you did a great piece on this software, this Palantir software. It's really kind of scary.  Also Mike Elgin, Off the Road and in our studios. Great to have you, elgin.com. And of course,  you could always subscribe to Mike's nice book. Although there's a lot of fumble for me  of you in Barcelona drinking wine, eating cheese. If you want to see an example of

Start time: 2150.22
End time: 2152.24
Speaker: SPEAKER_08
Transcript:  this fomo we've been talking about, go to my nice book.

Start time: 2155.32
End time: 2168.70
Speaker: SPEAKER_07
Transcript:  What a life he's had. Cheese is beautiful though, isn't it?  There's nothing like cheese.  That's definitely things baby boomers say, right? It's in that there's nothing like cheese.

Start time: 2172.48
End time: 2173.52
Speaker: SPEAKER_02
Transcript:  I'm not going to say you're wrong.

Start time: 2173.90
End time: 2407.04
Speaker: SPEAKER_07
Transcript:  No, I know I'm not wrong. I know. I'm the poster child.  Our show today brought to you by Worldwide Technology. WWT, they began with their  Advanced Technology Center 10 years ago. The lab contains more than half a billion dollars in  equipment from hundreds of OEMs. Everything you might want to use in your business, Cisco, NetApp,  VMware, emerging disruptors too. Maybe things you just recently heard about and you're curious  about like titanium and Equinix and Expanse. They're all in there and because when you're  running an enterprise, nothing exists in a vacuum. They test it all in a lab that gets you an example  of how they're going to interact, how they're going to work together. WWT, Worldwide Technology,  is your trusted partner. Been with you over the years. Many of their customers have been with them  for more than a decade because they know WWT is where they can go to get the answers they need  to make sure their business runs right. This Advanced Technology Center is something else.  It's amazing. An incubator for IT innovation and you can use it. This is the best part.  They've got hundreds of on-demand integrated solution labs that you can use representing  the newest advances in things like flash storage and software-defined networking, network automation,  endpoint security architectures. Before you try a product, before you install a product,  you can learn about it. Of course, WWT's own engineers are using it all the time to spin up  proof of concepts, pilots, using the sandbox customers can confidently see and choose the  right solutions. But you can use it too. Lab is a service, they call it. It's a dedicated lab space  within the Advanced Technology Center that customers can use to perform programmatic testing  using that incredible half billion dollar technology ecosystem WWT's already built. And  there's more coming in all the time and it's completely virtual. You don't have to go to St.  Louis. You can take advantage of the ATC's unique benefits anywhere in the world, any time of the  day or night 24-7. Later this summer, WWT is going to launch a new digital platform that gives you  hands-on access to more than 200 lab environments. This is a big deal. If you're looking at enterprise  purchases, if you're looking at setting up networks, if you're in IT, if you just want to  understand how stuff works, learn more about WWT, the ATC, sign up for pre-launch access to  their new on-demand lab platform at www.wwt.com. www.wwt.com. www.wwt.com. www.wwt.com.  WWT simplifies the complex, delivering business and technology outcomes around the world,  worldwide technology. We thank them so much for supporting TWIT. www.wwt.com.  TWIT, we thank you for supporting TWIT by visiting that address www.wwt.com.  Well, we kind of did the Facebook walk, the Instagram walk.  Prime Day tomorrow. This is the eve of Prime Day. Is everybody excited? Yeah?  Woof. First of all, not everything in Prime Day is a deal, right? Right.  Wirecutter does a great job. The New York Times about Wirecutter. They do a great job of looking  at Prime Day deals and comparing them to other prices to see if they are deals.  And oh, by the way, here's the best Prime Day deals for 2019. Notice they're not all on Amazon.  In fact, Walmart is having their own version of Prime Day. They're doing it, I think, for three  or four days. Target's doing it. Even Nordstrom later this week will be having their version of  Prime Day. I think rapidly the middle of the year is going to become the week for Christmas.  They used to call it Christmas in July. Yeah. eBay as well. eBay too. Wired Magazine called

Start time: 2407.84
End time: 2413.66
Speaker: SPEAKER_08
Transcript:  Amazon Prime Day a bacchanal of modestly discounted ephemera. Modestly discounted crap that you

Start time: 2413.84
End time: 2435.90
Speaker: SPEAKER_07
Transcript:  wouldn't ever buy. I like what eBay's doing because eBay is, they're calling it crash deals  in case Amazon crashes. Because I guess, what did, Amazon crashed last year during Prime Day?  Unbelievable. I don't know what to say about this except I'm staying home tomorrow. Yeah.

Start time: 2437.52
End time: 2441.66
Speaker: SPEAKER_04
Transcript:  No, I'm not. I don't, I don't want to. I'm coming to work. You guys have much better bandwidth there.

Start time: 2441.94
End time: 2456.56
Speaker: SPEAKER_07
Transcript:  Oh, okay. Yeah, we do. We have a lot of bandwidth. Do you buy stuff, Caroline, on Prime Day? Do you  go crazy? Is that where you get your battleship deals? Yeah, I've not participated in Prime Day.

Start time: 2456.80
End time: 2467.26
Speaker: SPEAKER_02
Transcript:  I think mainly because, I mean, this year, last year definitely, I mean, there have been different  types of demonstrations at warehouses and people demand better. Oh yeah, Minnesota's shutting it

Start time: 2467.34
End time: 2481.44
Speaker: SPEAKER_07
Transcript:  down. Shutting down the warehouse tomorrow. Yeah. Like, that's good. I mean, you've got to shut them  all down if you're going to shut it down. They just route around you. It's like the internet.  Minnesota's down. Let's just use it. Let's get it from Nebraska. I don't. Here's a really interesting

Start time: 2481.58
End time: 2545.84
Speaker: SPEAKER_08
Transcript:  thing that happened to me regarding Amazon. Very bizarre. Last year, November, December, something  like that, I went to log in and said, your account has been terminated. And I was like, okay, that's  terrible. So I've been calling and calling a couple, three, four times a month trying to get my Amazon  account back. And the reason I want it back is because I'm an author. You don't have an Amazon  account? Correct. How do you live? I do, but I don't. So I'm an author, so I have a book going,  this is being sold. I get checks from them. I've done some Amazon associate stuff. I get checks  from that. But they couldn't figure it out. I kept calling Amazon. They're like, we have no idea. We  can't figure it out. And then we finally figured it out. They had a high level person look into it.  I was one of the first, like you were, Audible subscribers. And your Audible account? I subscribed  in 2000 and I don't know what it was. Yeah, I subscribed in 2000. Something like that. And so  I recently canceled it because my wife had one. Oh, it was tied to your Amazon account. Yes. And  they couldn't figure it out. But it's basically they just terminated my account. So they're still

Start time: 2546.02
End time: 2549.92
Speaker: SPEAKER_07
Transcript:  trying to activate it. Can you get it back? They don't know. Is there any reason why you care? Why

Start time: 2550.10
End time: 2563.08
Speaker: SPEAKER_08
Transcript:  don't you set up a new account? Because I need access to my book. Oh, all your affiliate fees.  Well, yeah, there's all kinds of data in there that I need to. This is the new digital dilemma.

Start time: 2563.30
End time: 2575.60
Speaker: SPEAKER_07
Transcript:  Yeah. What do you do if you're, I mean, it's bad enough when if people lose their Google accounts,  but if you lose your Amazon account, do you really exist? Not really. I'm shut out of Prime Day. I

Start time: 2575.70
End time: 2581.80
Speaker: SPEAKER_08
Transcript:  mean, for starters. Oh my God, the horror. I have to pay full price on everything. So are you,

Start time: 2582.10
End time: 2612.24
Speaker: SPEAKER_07
Transcript:  so that's interesting that you brought that up, Caroline, because it is true. We heard nothing  but horror stories about people working Amazon warehouses. Amazon announced and now they're  already doing it in our neck of the woods. Next day delivery, which is going to make,  gotta make it even worse in the warehouses. I had an Amazon driver deliver a book at nine o'clock  last night. I mean, this poor person has probably been out in the truck all day.  Was a little van. Yeah. It's one of those prime, those new Amazon vans.

Start time: 2612.62
End time: 2623.30
Speaker: SPEAKER_04
Transcript:  The headset Caroline is wearing was placed in an Amazon locker by an Amazon worker at nine,  nine PM last night. Just, yeah, just so she could be on the show today.

Start time: 2623.84
End time: 2646.34
Speaker: SPEAKER_02
Transcript:  Wow. See? Yeah, it's right. Yeah. Yeah, I don't know. It's,  I feel like, in an ideal world, it would be nice to,  they make it. At times the convenience of it is really,  right. I mean, hard to go without. This is the modern dilemma. We want all our conveniences

Start time: 2647.08
End time: 2652.00
Speaker: SPEAKER_07
Transcript:  and we kind of know in the back of our mind is it's due to the suffering of some other human.

Start time: 2653.58
End time: 2684.78
Speaker: SPEAKER_02
Transcript:  Right. I mean, in terms of the price, I mean, a lot of times, especially if you're buying things  in bulk, like there have been times that I've bought like food or certain types of food or  cleaning supplies in bulk because that's really the only like money efficient way to do it. But  I think the important thing to keep in mind is that with Amazon, I mean, it's not just something  that affects Amazon warehouses. I mean, this is something that's creating. Oh yeah. I mean,  going to Walmart's no better. Yeah. Yeah. Pretty much any place that's relying on warehouses.

Start time: 2685.98
End time: 2702.96
Speaker: SPEAKER_07
Transcript:  I mean, it's. But what do you do? You live on artisanal pickin' pickles from Williamsburg  for the rest of your life? I mean, you can't. You can try. What would Brooklyn do?  You only shop local merchants that have handcrafted your goods. The worst part is

Start time: 2703.06
End time: 2709.76
Speaker: SPEAKER_08
Transcript:  they're going to solve the plight of their workers by replacing with robots. And so is that better?

Start time: 2710.32
End time: 2719.20
Speaker: SPEAKER_07
Transcript:  It's hard. It's so I thought, oh, this is a, this is Amazon announced that they're going to spend.  They're going to retrain. Yeah. What does it? Maniacs, which is a million. I can't remember

Start time: 2719.32
End time: 2726.63
Speaker: SPEAKER_08
Transcript:  what it sounds like a good plan to me. They're going to, it's like 700,000 or something like  that. They're going to retrain people nationwide for $700 million to retrain one third of its

Start time: 2728.90
End time: 2747.68
Speaker: SPEAKER_07
Transcript:  workforce. But if you do the math, it's like 1200 bucks per person. It's barely enough to  send somebody to school for a week. They're going to retrain a hundred thousand workers  by 2025 because they say, well, these people are going to be out of, out of work.

Start time: 2748.58
End time: 2771.52
Speaker: SPEAKER_08
Transcript:  And Amazon is very robots totalitarian in their PR approach. If you're in the press, you know this,  that they're very difficult to work with and they masters at spinning stories in their favor.  And, you know, they talk about retraining and then they throw out some examples to get your mind  thinking about advanced degrees and like doing all this kind of stuff. But really they're going  to be retraining people, factory workers to be drivers. And they're going to be, you know,

Start time: 2771.54
End time: 2779.28
Speaker: SPEAKER_07
Transcript:  because how many of those people, I don't know, but how many of those people can become coders  and how many coders do we need? Exactly. It's a sleight of hand. They're going to be doing a lot

Start time: 2779.46
End time: 2783.05
Speaker: SPEAKER_08
Transcript:  of training like every other company, every company. Okay. The $7,000 a worker, which actually

Start time: 2784.56
End time: 2815.36
Speaker: SPEAKER_07
Transcript:  is decent. It's a thousand 12, $1,200 a year for five years. So that's what's. Bloomberg had an  interesting analysis of it. They said breaking down the numbers, they'll spend 700 million,  a hundred thousand employees by 2025, $1,077 a person annually. According to an estimate  from the association for talent development, a trade group, the average organization spends  already $1,296 per employee annually on training. So in effect, Amazon's committing to spending less.

Start time: 2815.48
End time: 2840.16
Speaker: SPEAKER_08
Transcript:  And on its face, I don't believe that that's an apples to apples comparison. They say this is how  much Apple that Amazon's going to spend. How much of that is on leasing buildings and, and, and,  and, and getting projectors, you know, so you think it's just a PR move and it's not a genuine  effort to retrain? Well, no, I think, I mean, I think they're doing every company, every enterprise  has to train, they have to do training. And I think they're trying to get a lot of credit for

Start time: 2840.30
End time: 2847.68
Speaker: SPEAKER_07
Transcript:  something that is possible for Amazon to treat its workforce humanely. Absolutely. They make enough

Start time: 2847.86
End time: 2855.40
Speaker: SPEAKER_08
Transcript:  money. They could do that. Well, prices would go up. I mean, this is why things are cheap on  Amazon. They're squeezing in everything. Same with Walmart, right? They're squeezing everything.

Start time: 2855.80
End time: 2890.36
Speaker: SPEAKER_02
Transcript:  Yeah. So it's possible. Right. I mean, a $15 minimum wage, I mean, for most people still isn't  a livable wage. And I think in terms of retraining, the details are really important here. I mean,  is this something that's going to be happening in addition to slash outside of work hours? I mean,  for people who might have to work like more than one job or for people who have a family, I mean,  that might not be feasible. And for what to stay within the same company? Are they actually going  to be making more money and their retrained positions or are the conditions going to be  comparable? I don't know. I mean, it seems like at this stage, like those kinds of details are

Start time: 2890.72
End time: 2906.40
Speaker: SPEAKER_07
Transcript:  unclear. I feel bad because this show used to be all about how great technology is, it's making  our lives better. And you're going to have robots in the cars, you drive themselves, and pretty soon  you won't have to wear glasses anymore. And now it's all about dystopia. Is that what happened?

Start time: 2907.72
End time: 2924.08
Speaker: SPEAKER_08
Transcript:  Or is it just me? I don't think the story about Amazon's training workers is that much of a  technology story. It's a technology company and there's some technology elements to it.  Basically, this is a type of capitalism. It's a business story. Yeah, it's a business story.

Start time: 2926.23
End time: 2937.84
Speaker: SPEAKER_07
Transcript:  Well, let's do a technology story. Amazon is building a robot, but not for the warehouse.  It's a home robot with Amazon's Echo built in. When I heard about this, I thought it was going

Start time: 2938.24
End time: 2970.62
Speaker: SPEAKER_08
Transcript:  to be this little tiny robot that goes up, but it's waist high. It's like the size of a top.  That's so you could put your beer on its head. Yeah, exactly. That's a bad joke. I'm sorry.  I've been to cocktail parties in Sonoma where they have robots. They bring you your tray of  hors d'oeuvres. Well, actually, one of the things that they had, this was at the Future of Food  conference in Sonoma, they had robots with a tray on top and they were carrying little desserts that  were pastry versions of robots with trays on top. That's a little inception. They had little desserts

Start time: 2970.72
End time: 3019.79
Speaker: SPEAKER_07
Transcript:  on top of those. Dessert inception. It was amazing. Were the desserts on top of the robot desserts?  It was desserts all the way up. It was amazing. The robot is called Vesta.  They say we can't yet mass produce Vesta. They had hoped to reveal it this year, but it's just not  ready. Now, we had an advertiser, Bosch, who had a robot called Kuro. Remember Kuro? It was a little  robot that would wander around. It was kind of like an Amazon Alexa on wheels. They canceled that  project. I don't think it's hard to make. I think it's hard to find a market. Does anybody really  want a little robot Amazon Echo that wanders around? Yes. It sounds cute, but I feel like I'm

Start time: 3022.76
End time: 3049.04
Speaker: SPEAKER_02
Transcript:  struggling to understand this here. Let's say you have an apartment like mine that isn't that big.  This is a matter of walking literally three steps to wherever the echo is. Or let's say you have an  actually big house. Is it going to go up the stairs? Probably not. Right. I don't know. It just seems  why. I think the idea of having an Echo on a Roomba, that's cute, I guess.

Start time: 3049.68
End time: 3055.58
Speaker: SPEAKER_07
Transcript:  Jeff Bezos Instagrammed his kids had taped an Echo to a Roomba. He Instagrammed that a year ago.

Start time: 3056.66
End time: 3066.62
Speaker: SPEAKER_02
Transcript:  I think he's blaming the kids. I won't speak about Jeff, but I think his kids are genius for doing  that. Every product should just be placed on top of a Roomba and it would instantly make it better.

Start time: 3067.20
End time: 3070.94
Speaker: SPEAKER_07
Transcript:  I think all animals, especially house cats, should be placed on top of a Roomba.

Start time: 3071.06
End time: 3095.60
Speaker: SPEAKER_08
Transcript:  I mean, the reality is that damn it, we boomers were promised robots in a home, right? And  we never got them. So anybody who's working on that, I think it's great. The problem is that  Amazon is a privacy nightmare in your home. But if you ignore that part of it, it's like,  I'm glad that a company like, because look what Amazon did with the virtual assistant appliances,  what we now call smart speakers. Nobody believed in that stuff when they came out with the Echo.

Start time: 3096.02
End time: 3102.08
Speaker: SPEAKER_07
Transcript:  That's true. People said the same things about the Echo that we're saying now about this robot.  People are like, oh, you don't need it. Who wants that? That's silly.

Start time: 3102.22
End time: 3117.36
Speaker: SPEAKER_08
Transcript:  It's really changing the tech, the consumer technology world in a major way. So I would  love to see virtual assistant robot type things. I just would prefer they didn't come from Amazon.  So I mentioned- I think like-  Go ahead, K. No matter what, I mean,

Start time: 3117.36
End time: 3158.62
Speaker: SPEAKER_02
Transcript:  you're going to be having the types of security issues. I mean, the same sorts of issues with  people being creeped out about humans transcribing and having access to voice recordings. I mean,  that's a shared problem with Amazon. I mean, it seems like whoever is making these speakers,  I mean, if you're having a device that's listening to you in your home and has access to literally  everything that's going on, I mean, that's going to be a security concern. That's going to be a  privacy concern no matter which company is behind it. I mean, with companies like Google and Amazon,  I mean, it's even more of a concern considering like a large amount of data they already have  about you and your customer profile. But yeah, I don't know if it's strictly an Amazon problem.

Start time: 3159.04
End time: 3178.24
Speaker: SPEAKER_08
Transcript:  Just to be clear, this is a much bigger potential risk than it sounds. It's not that this thing  will be on wheels and roll around listening. It will be 3D mapping your home. It will be  videotaping your furniture and it'll be finding out who else is in the house,  which will be recognized through face recognition. And don't be surprised the next time you go on

Start time: 3178.30
End time: 3183.12
Speaker: SPEAKER_07
Transcript:  Amazon if it says, you know, your couch is right there. Would you like a new Amazon's Choice Couch?

Start time: 3183.32
End time: 3187.34
Speaker: SPEAKER_08
Transcript:  This couch will fit perfectly in a little space and this rug will really tie the room together.

Start time: 3187.86
End time: 3191.04
Speaker: SPEAKER_07
Transcript:  Really? You think they're going to do that? I mean, how valuable is that to Amazon?

Start time: 3191.20
End time: 3239.98
Speaker: SPEAKER_08
Transcript:  Oh, infinitely valuable. I think they sit there. I think Jeff Bezos sits in his basement at three  o'clock in the morning seething because he has all this data from Amazon Echo products, but he just  doesn't know what's in the other room. What's in there? Who's in there? I mean, I really think that  that's and he's like, I know, we'll put wheels on this thing and it'll roll around, have access to  the hive where you're sleeping. I'll go in the bathroom and go through your medicine cabinet.  I mean, who knows? But it's lots and lots of data that they, I mean, Amazon sells everything.  They sell everything and they want to see what you got. This is, I think this is one of the reasons  for this, this version of the Echo that takes pictures of your outfit. The whole point is to  see what's in your closet. I had that Echo look. Yeah. See what's in your closet. It didn't like any of my outfits.  None of them. You said Echo don't look. Sorry. But anyway, they sent it to Stacey. Stacey Higginbotham

Start time: 3240.06
End time: 3245.80
Speaker: SPEAKER_07
Transcript:  has my Echo look. I'm sure it likes her outfits much better. Well, this week in law, I'm blanking.

Start time: 3246.04
End time: 3254.56
Speaker: SPEAKER_08
Transcript:  Denise Howell is super into it. Like she, she posts. Well, she has, she has a great look and she,  she's very put together. Yeah. And she's creating FOMO on Instagram every day with this thing.

Start time: 3255.48
End time: 3415.82
Speaker: SPEAKER_07
Transcript:  So the reason I'm glad I'm not. So I have a new, I've been a new kick I've been thinking about  because we, we talk a lot. There's a lot of energy spent about artificial intelligence. You know,  I think Elon Musk and others have said, Oh no, you know, it's the terminators are coming. And this  whole notion that AI, the fear of AI is that it's going to somehow at some point gain consciousness  and it's going to think, uh, we don't need the humans. It's going to wipe us out or it's going  to turn us into batteries as it did in the matrix or something like that. And I've, I've read a couple  people, most recently Yuval Noah Harari in his 21 lessons for the 21st century who said, no one  has ever demonstrated that if you get better at AI, that at some point you'll leap this gap into  consciousness. We don't know where consciousness comes from. There's no evidence that you feed a  machine a lot of information. You know, and it becomes a great chess player. And then suddenly  it goes, I think I'm going to eat Gary Kasparov for lunch. It doesn't jump to that consciousness  thing. We don't know where consciousness comes from. Maybe someday we'll be able to. So I'm  going to submit this as my new thing that consciousness is not the threat of AI.  The threat of AI is the humans who use AI. Now you've been talking about this a little bit,  on motherboard. There was a piece in slate this morning that creeped me out. It turns out license  plate reading software has gotten so cheap and it will work with a hundred dollar cameras  that it's being installed everywhere. License plate readers. They give an example of a housing  complex where people are using it to make sure that you're not abusing your rental agreement.  They are everywhere. It's about a hundred dollars for the software on a hundred dollar camera.  The city I live in, Petaluma, I noticed was putting up cameras on every traffic light,  every street light. And I realized they're not valuable if you have to have somebody sitting  and watching them. If you've got 400 cameras in a town of 50,000 people,  800 officers looking at them? No, you put license plate reading software on it. And then if you want  to know where Leo was last night, you know. Exactly. And this is an example to me. Palantir  is another one. And I'm really interested that you, Caroline, have been able to break through  because Palantir has been almost a legendarily secret company in Silicon Valley, funded by Peter  Teal. Alex Karp is its secretive CEO. And we knew it was some sort of, well, what is it?

Start time: 3417.16
End time: 3454.24
Speaker: SPEAKER_02
Transcript:  We don't, I don't know what we knew. Yeah. I guess the best way to describe it is that it's  an aggregator. It takes data from like all different types of sources and it organizes it  and is able to find connections in ways that like if you're just a regular human analyst,  you might not be able to do it. Or if you're just a person with access to five different databases  and you're looking to use something from there, I mean, that's not actionable. Just having all this  unstructured data. So that's Palantir's role. It organizes it and it's able to make charts and  sort through very sensitive data very easily, as easy as making a search. This is what's worrying

Start time: 3454.36
End time: 3479.20
Speaker: SPEAKER_07
Transcript:  me about AI. It's not that it's going to become conscious and I want to get rid of the humans.  It's that there are humans who will be using this. You wrote that 300 California cities,  Northern California cities, I wouldn't be surprised if Petaluma is one of them,  are using Palantir. Why did Petaluma put up all those cameras to gather data?  What are they going to do with the data? I think the noteworthy thing here, oh, sorry.

Start time: 3479.84
End time: 3524.80
Speaker: SPEAKER_02
Transcript:  Go ahead. No, no. Yeah. The noteworthy thing here is that  I started this whole thing by sending public information requests to individual cities and  almost all of them came back empty. The only one that came back with information was through  the NCRIC, the Northern California Regional Intelligence Center. So even if you're a citizen  living in one of these cities and you want to find out about it, there's really no way for you  to know. I mean, only by filing a public record request to this regional center do you realize,  because here's the thing, police officers can request this type of data from the NCRIC,  but there's no paper trail for those individual cities and there's really no  transparency for the citizens that are actually living there.

Start time: 3525.46
End time: 3529.04
Speaker: SPEAKER_07
Transcript:  So this is run through the Department of Homeland Security. Do they say it's to

Start time: 3529.34
End time: 3576.48
Speaker: SPEAKER_02
Transcript:  cut down on terrorism? Right. So on their website, they claim that they,  well, most of their efforts are focused on major drug operations and terrorism operations.  But at the same time, they will pretty much investigate anything that a local police  department requests help with. And this could be, I mean, literally any type of crime. It could be  a robbery. It could be a domestic assault. It could be really any type of investigation that  a local police department is operating. So this isn't just a, let's catch people trying to commit  a major, major act of terrorism. This is, you know, local operations. And this is, you know,  they have a massive amount of data on the people that are living in those areas.

Start time: 3576.56
End time: 3590.34
Speaker: SPEAKER_07
Transcript:  On the one hand, I would say, oh, that's good. We're going to have to be a safer  city in Petalum. By the way, our county is one of the participating, 14 participating  Northern California counties in NCRIC. It's going to be safer. It's going to be safer here.

Start time: 3593.36
End time: 3611.14
Speaker: SPEAKER_02
Transcript:  I think, I don't know. I think that this is more, it sort of reminds me about the arguments that  people make with respect to privacy. Like, oh, I have nothing to hide, so I shouldn't have any  reason to worry about this. You know? I mean, if you have nothing to hide, leave the bathroom door

Start time: 3611.32
End time: 3624.16
Speaker: SPEAKER_07
Transcript:  open. I've tried that argument. People don't like that. There's reasons. It's not that you have  something to hide. It's not that you're a criminal. It's just that you, we deserve to live privately.

Start time: 3624.22
End time: 3688.64
Speaker: SPEAKER_08
Transcript:  The risk here is the slippery slope. You mentioned that, you know, why are they installing these  cameras in Petaluma? And it doesn't matter why. Once they have the cameras, they can later decide,  oh, hey, we have all these cameras. Why don't we do XYZ? So it's really the infrastructure is,  is just another step in a direction. I feel like we're sliding down this slope.  Well, here's another example. I just wrote a piece for Fast Company about emotion technology  in cars, where cars will be able to read your emotions, understand what your mindset is,  understand what's happening in the car. This is part of the, you know, self-driving cars are like  supercomputers on wheels with all these sensors pointing outward. What we're not talking enough  about is the sensors pointing inward at the drivers and everybody else. But what's interesting  is that Fictiva is in the lead with this technology of being able to read emotions of drivers,  and they're not doing it by installing cameras in cars. They're using the cameras already  installed in cars, and they're just tapping into that feed. It's like an, you know, after the fact  kind of an idea where it's like, well, you know, these high end cars have cameras. Why don't we  just read people's emotions with them? And so this is the, this is what's happening.

Start time: 3688.78
End time: 3695.76
Speaker: SPEAKER_07
Transcript:  Why do they want the emotions? I mean, I can understand for self-driving vehicles,  it's important to know what that other driver is going to do. That doesn't bother me.

Start time: 3695.86
End time: 3697.06
Speaker: SPEAKER_08
Transcript:  Well, for there's, so the-

Start time: 3697.36
End time: 3699.38
Speaker: SPEAKER_07
Transcript:  Humans are the big problem with self-driving vehicles.

Start time: 3699.84
End time: 3719.92
Speaker: SPEAKER_08
Transcript:  Well, the biggest thing is this is going to go online before they're fully self-driving.  But most urgently, Europe has enacted legislation saying that by 2021,  all cars sold in Europe will have to have basic reading function. They'll be able to,  they have to tell whether the driver's falling asleep, whether the driver's drunk.

Start time: 3720.32
End time: 3765.12
Speaker: SPEAKER_07
Transcript:  This is, you know, this is a-  Cadillac just put that in their CTS for their auto pilot feature.  Because as you know, same with Tesla, you got to keep your hand on the wheel.  And you have to keep your eyes on the road. It used to be that it was enough to have your  hand on the wheel, but Cadillac actually has a camera that sees where you're looking.  Yeah.  So that if you look down or away from the road, it, while the autopilot's on, I can,  it actually vibrates your seat and then eventually disengages it.  I had to trick it. I had to cover my eyes, but I was too scared.  While driving?  Well, that was the thing. I was too scared to actually do that. So I did like this and,  and you know, I had my, peered through my fingers and it did it.  But if you wear sunglasses.  Yeah. But, but well, exactly. I mean, it does, it's looking at you driving.  Well, the best thing-  And if they were able to get that, and I guess with OnStar, they probably are getting that.

Start time: 3765.24
End time: 3773.28
Speaker: SPEAKER_08
Transcript:  But I love that technology because you can be able to look at a store and say, is that open?  And they'll know what you're looking at. And it'll say, oh,  there's so-and-so Starbucks is not open right now.

Start time: 3773.42
End time: 3780.44
Speaker: SPEAKER_07
Transcript:  Caroline, you filed a public records request and got the Palantir user manual for cops.

Start time: 3781.97
End time: 3818.30
Speaker: SPEAKER_02
Transcript:  Right.  Wow.  Yeah. This was a specific user manual that seemed to be designed for cops that were operating in  like the West, North California area. And full disclosure, the manual was almost unreadable.  It took me several hours to be able to parse all of this through.  Because of jargon?  Because of jargon, because it was just poorly organized. It was poorly worded.  That's encouraging.  They did not define any of the terms. They just sort of said that the way it was organized was,  here's how you make a search. And then they sort of introduced different charting functions.

Start time: 3819.66
End time: 3824.56
Speaker: SPEAKER_07
Transcript:  By the way, this is confidential and proprietary, not for distribution.  So please close your eyes.

Start time: 3824.90
End time: 3828.58
Speaker: SPEAKER_08
Transcript:  Another thing boomers say, in my day, we used to go through dumpsters to find that kind of thing.

Start time: 3830.60
End time: 3838.78
Speaker: SPEAKER_07
Transcript:  So searching for records in Palantir, start. Start in the graph application. This is the worst.  You're right, Caroline. This is horrible.

Start time: 3838.88
End time: 3842.93
Speaker: SPEAKER_02
Transcript:  Yeah. It is like unreadable.  Click the gear icon.  It's extremely.

Start time: 3843.46
End time: 3844.42
Speaker: SPEAKER_07
Transcript:  Oh my God.

Start time: 3846.20
End time: 3877.66
Speaker: SPEAKER_02
Transcript:  Right. I think the best way to describe it is in terms of what you can do and what information  that you're starting with. If you're starting with just a name, you can get, I mean, if they  have it in their data systems, if they have it in police record management systems, if they have it  through other types of private data that they obtain, things that could have access to people's  email addresses or bank account numbers, really sensitive information like that.  I mean, this is all pulled instantly just from a simple name search.

Start time: 3877.80
End time: 3893.06
Speaker: SPEAKER_07
Transcript:  And if you know somebody's license plate and you use this example in your article,  you can know where they, because of license plate readers and cameras everywhere,  you can know pretty much everywhere somebody's been and when for any time period.

Start time: 3894.62
End time: 3920.49
Speaker: SPEAKER_02
Transcript:  Right. So basically you set the radius and you say you're looking for a particular license plate  number that's traveled in like, I don't know, let's say a hundred mile radius or more, and then you  can set a date range if you want. And since they have timestamps and they have location stamps,  you can get all of that information. And then they also have a picture of the car  and the license plate itself. So all of this information is stored just by searching a license  plate number.

Start time: 3920.88
End time: 3954.34
Speaker: SPEAKER_07
Transcript:  With a name, this is, I mean, we've all seen this on TV, on NCIS and stuff, but really this is even  much better than anything. With a name, you can get a person's email address, phone number,  current and previous addresses, bank accounts, social security numbers, business relationships,  family relationships, license information, height, weight, eye color. If it's in an agency's database,  you can get it. So that's what Palantir is doing. Do they talk about the sources of this information?  Are they getting it? Some of it, obviously from DMV, Department of Motor Vehicles.  Is it all government agencies? Is it Google and Facebook?

Start time: 3956.12
End time: 3999.26
Speaker: SPEAKER_02
Transcript:  See, the NCRIC specifically, it's a fusion center. So they would use Palantir to take the different  police, like local police records. So this would be like crime, arrest, et cetera, data. And Palantir  also says that they get data really vaguely from government and federal agencies. So this could be  where you're getting information about license plate data, for instance, where you could get  information about birthday, whether you're married, whether you have a business logged in your name,  that kind of thing. So some of it's public records.  Yeah. Right. Some of it's public records. In terms of email addresses or bank account records,  that would be something that would have to be acquired privately in most situations.

Start time: 4000.50
End time: 4025.82
Speaker: SPEAKER_07
Transcript:  Do we have any evidence that they, for instance, in their manual, they show you examples of different  databases you can search, including ALPR as automatic license plate readers. You can do LAPD,  LASD, border crossing vehicle query, DMV vehicle query, national license plate reader vehicle query.  And that's just a portion of it. I imagine this would scroll down quite a way.

Start time: 4026.88
End time: 4066.82
Speaker: SPEAKER_02
Transcript:  It's an incomplete list and it's also with only a sample search. A lot of the examples that they had,  you could see that the search query was Palantir and then they had example profiles that were named  things like John Badguy Smith. Badguy's my middle name.  Yeah. You can see on the right, if you choose a particular profile, let's say you search John  Badguy Smith and there's 10 people in the area with that same name, you can click on one of them  and you can see the specific details that distinguish him from the other John Badguy  Smiths in the area. And by the way, for you at home, if there's an area with 10 bad guy Smiths

Start time: 4066.88
End time: 4071.94
Speaker: SPEAKER_08
Transcript:  there, don't go to that area. Stay away. It's a bad guy area. Yeah. Very dangerous. I like the

Start time: 4073.72
End time: 4079.92
Speaker: SPEAKER_07
Transcript:  icons they use for John Badguy. They're riveting. I think that's the Hamburglar. I'm sorry, but I

Start time: 4080.04
End time: 4088.02
Speaker: SPEAKER_08
Transcript:  think that's the Hamburglar. So Leo, you should subscribe to this because you always talk to the  audience and find out who's coming. I would love to get this information. You would know before they even got here who was coming.

Start time: 4089.32
End time: 4097.48
Speaker: SPEAKER_02
Transcript:  And did you know the email address downwiththeus.org? Say again? That's the downwiththeus.org. That's the email

Start time: 4097.92
End time: 4122.98
Speaker: SPEAKER_07
Transcript:  domain. Oh, oh yeah. JBG01 at downwiththeus.org because as you know, anybody, any malefactor you know  doesn't like the America that we know. I'm scared. Now let me ask you because this came out a couple  of days ago. Was there any reaction to your article? Palantir emailed me once and said,

Start time: 4123.84
End time: 4166.98
Speaker: SPEAKER_02
Transcript:  why did you say that we didn't respond to multiple requests for comment? And I said, because you  didn't. That's pretty much the only thing that I've heard from Palantir. In terms of the response,  I guess what sort of surprised me is that I generally had an understanding of how Palantir  worked. But in terms of getting the visuals and in terms of seeing the actual manual,  it seems like that had an effect on people because it's one thing to hear that there's this secret  omnipotent data company that's operating in the shadows with regional level governments and  investigative agencies. But it's another one to see that you can just search your name and find

Start time: 4167.08
End time: 4179.06
Speaker: SPEAKER_07
Transcript:  out virtually everything about yourself. So yeah. And this is accessible to any law enforcement  agency in Northern California pretty much. It's only law enforcement though, right?

Start time: 4180.40
End time: 4185.22
Speaker: SPEAKER_02
Transcript:  Right. So it would be law enforcement and any local police department within those counties

Start time: 4185.32
End time: 4199.62
Speaker: SPEAKER_08
Transcript:  would be able to tap into those resources. Do you know who decides that that's who gets to see it?  Or if anyone is in a position to make an exception to that, like for example, mall cops maybe or...  Paul Bart.

Start time: 4199.62
End time: 4201.39
Speaker: SPEAKER_07
Transcript:  Security.  Can I get a...  Paul Bart.  Can I get this?

Start time: 4203.40
End time: 4206.06
Speaker: SPEAKER_02
Transcript:  Mall cops are usually, aren't they usually private security forces?

Start time: 4206.80
End time: 4207.94
Speaker: SPEAKER_07
Transcript:  No private security forces.

Start time: 4208.02
End time: 4214.58
Speaker: SPEAKER_08
Transcript:  My point is, is this a matter of law or is this company policy that they decide who gets to see  it and who doesn't?

Start time: 4216.22
End time: 4260.42
Speaker: SPEAKER_02
Transcript:  Right. So I think that's one important thing to keep in mind is that Palantir is the infrastructure,  but exactly how it gets used, that's all in the hands of the regional intelligence agency.  What's important is how the data that would not have been actionable is made actionable  and it's put into the hands of just other...  Without a warrant.  Right.  Right. Well, in terms of, I don't really get into the article in terms of like,  you do have to enter, for instance, like a case number in order to make a search in the ALPR  database. And in terms of the people search, at least in that version of it, it's an open field.  So when you're saying the reason for your search, it seems like you can just type in  words and that'll be accepted.

Start time: 4260.42
End time: 4265.77
Speaker: SPEAKER_07
Transcript:  Yeah. Type the reason for the search in the search purpose field. This could be a case number  or a suspect number.  Right.

Start time: 4266.44
End time: 4270.08
Speaker: SPEAKER_08
Transcript:  Or I'm just bored. I'm sitting here. I thought I'd find out what my answer is.

Start time: 4271.06
End time: 4312.46
Speaker: SPEAKER_07
Transcript:  This is kind of timely because this is what ICE is using this weekend to track down  undocumented immigrants and arrest them and deport them. The big issue for me, and I have to say,  on the one hand, you want law enforcement to have good tools protected by courts and warrants,  but you also want to have some oversight in the data. And the big concern for me is this  is a private company. Data sources may be corrupt, may be inaccurate.  Are they secure?  We know face recognition is often used in these cases. We know that's often full of false positives.

Start time: 4313.80
End time: 4380.96
Speaker: SPEAKER_02
Transcript:  Like the NCRIC does have access to facial recognition. This was in, I believe it was  in Oakland. The head of the Oakland Police Department submitted a letter to the town  because they're going to be voting on whether or not to ban facial recognition,  I think on the 16th. And they said, based on this ban, we wouldn't be able to access the facial  recognition through the NCRIC. So I think what's important to remember here is that this data can  be combined with all different other types of databases as well. And for instance, one of the  documents that I got back was how to use Palantir with Thompson Reuters Clear, which is similarly  a giant database tool for police. And I think that what you were getting at before is really  important to keep in mind that the way that you act on data is only as good as the data itself.  And we know that the state of policing in this country isn't perfect. So I think the important  thing to keep in mind is how this could be used against marginalized populations. And  what we're seeing with the ICE raids, that's pretty much a worst case scenario.

Start time: 4381.08
End time: 4384.48
Speaker: SPEAKER_07
Transcript:  I'm looking at your table of where this data comes from.

Start time: 4388.38
End time: 4398.94
Speaker: SPEAKER_02
Transcript:  Right. So I think it's important to note that this is through the DOJ and this is in general,  how fusion centers work. Because Palantir itself is incredibly vague about exactly-

Start time: 4399.22
End time: 4422.82
Speaker: SPEAKER_07
Transcript:  They may be getting it from additional sources, but this one includes amusement parks, cruise lines,  hotels, motels- Gaming industry.  Gaming industry, sports authority, securities firm-  Gamers beware. ISPs, email providers, daycare centers,  mental health records, physician-patient records-

Start time: 4424.66
End time: 4428.10
Speaker: SPEAKER_08
Transcript:  Veterinary. Records.  It says veterinary. It knows all about your dog.

Start time: 4429.38
End time: 4433.98
Speaker: SPEAKER_07
Transcript:  And the contractual. So this is a very broad net. Now this is the DOJ, but this is their guidelines.

Start time: 4435.26
End time: 4438.28
Speaker: SPEAKER_02
Transcript:  Right. And this is a- Right. So-

Start time: 4438.68
End time: 4442.74
Speaker: SPEAKER_07
Transcript:  The Palantir, I would bet, because it's a private business, this goes beyond this.

Start time: 4445.46
End time: 4469.86
Speaker: SPEAKER_02
Transcript:  Yeah. I think what's important to note, the NCRIC, this is a DHS entity. And if you have some sort of  subpoena or you can request certain types of data from these private agencies, then this automatically  can get pulled into Palantir, which organizes the data in a way that perhaps it would not have been  able to use, to have been used before. See, sometimes people say, oh, it's public data,

Start time: 4470.00
End time: 4498.56
Speaker: SPEAKER_07
Transcript:  big deal. But we've seen already in many ways how public data is changed by companies like Palantir.  Every time you buy or sell a house, it's recorded at the county seat and in a big book.  And basically you'd have to go to the county building to find out who lives at that address.  But now, because so many data companies find this valuable, they send people down  to county seats. They record all this. They put it in a database.

Start time: 4498.70
End time: 4522.58
Speaker: SPEAKER_08
Transcript:  You know who else finds this valuable? Russia, when they're trying to assassinate a political  dissident, or China, when they want to track. I mean, what are the chances that this is  not a target for hacking by- Oh my God, yeah.  The Chinese government and the Russian government. The chances are zero. Either they're trying and  failing or they're trying and succeeding to get this access so they can track their dissidents.  It's a real problem. Yeah.

Start time: 4523.10
End time: 4640.50
Speaker: SPEAKER_02
Transcript:  I think my major concern here is how this is going to be used by police departments against  bodies that are already at risk. I mean, in particular, people of color living in these  regions. I mean, yeah, it's only, I think, like I said earlier, investigations are only as good as  the data that's informing them. And for instance, I wrote an article a couple months ago about  police departments that were using PredPol, which is a predictive policing software.  And I mean, dozens of police departments around the country were using this and there was  no disclosure at all publicly about this. And what it claims to do is take crime records,  crimes that were reported or crimes that were acted upon, and put it into this database and  basically tell police, go back and look at those places. So obviously the question that you have  to be asking there is how good are those crime report records? I mean, obviously not every crime  gets reported and the types of crimes that are prosecuted or investigated by police.  I mean, that's going to vary place by place and there's going to be individual bias that  comes into play there. So there's a lot of systemic factors that has to, that plays into  the way that this data is used. And I think PredPol, that's another good example. And that's  been combined with Palantir in places like Los Angeles. PredPol and Palantir have been used  simultaneously at the same time. I mean, that's a huge amount of power put in the hands of police  that at times have a contentious relationship with their citizens, and those underlying problems  aren't being addressed. And at the same time, we have these amplifying forces that are making it  easier and easier to do these super powered investigations in a way that we've never,  ever seen before.

Start time: 4640.82
End time: 4653.84
Speaker: SPEAKER_08
Transcript:  We tell AI is applied to move, we were talking about the power of AI in the hands of various  people, but you could turn this data loose with the right kind of AI to essentially do  AI enhanced phishing expeditions and just hand you a list of all the kinds.

Start time: 4653.86
End time: 4682.40
Speaker: SPEAKER_07
Transcript:  I can guarantee you they're doing that right now inside Palantir. I guarantee you that's  the most valuable thing. I mean, data, we now know data is hugely valuable and that the difference is  that by connecting data from a disparate variety of sources, you can infer connections that you  couldn't see before. And that is to me that I don't know if this makes us safer. I don't feel  like it does make us safer. I'm all for police having the tools they need to track down criminals,  but I don't think this makes us safer in the long run.

Start time: 4682.60
End time: 4703.58
Speaker: SPEAKER_08
Transcript:  Every time there's advances in technology, political and police authorities always use  those advances to change the balance of power between the citizens and themselves. And so I've  always argued for, you know, if they can track us, we should be able to track them. If they can record  us, we should be able to record them. If there's a video camera, an interrogation room, you should

Start time: 4703.76
End time: 4708.34
Speaker: SPEAKER_07
Transcript:  also have a video camera. There is a disparity in power that is, you can't, I mean, I don't care if

Start time: 4708.44
End time: 4740.26
Speaker: SPEAKER_08
Transcript:  you can record everything. But it's growing because of technology and that's not right. We should  always push back and, you know, technology is good, but not when the technology, when one side of the  equation has a monopoly. Yes, police want to do their jobs. They want to fight crime. We want them  to fight crime. We want less crime. All of that stuff. That's all true. But every thing like  policing has to be balanced against other considerations. That's why we have a constitution.  Exactly. And that's why we have rights and that's why we have all that stuff. But if it's being  circumvented through technology that nobody's really paying attention to, that's a problem.

Start time: 4740.98
End time: 4765.14
Speaker: SPEAKER_07
Transcript:  Let's take a break. Mike Elgin is here. Elgin.com. The nice book. See nice pictures.  Of books. Of books. No, of people. Of Mike, his family. He's at Mike Elgin on Twitter.  And his gastronomic adventures continue in Barcelona this fall in September. That's right.  Gastronomant.net. Take a look. It's going to be amazing. If you like delicious food and wonderful

Start time: 4765.26
End time: 4770.98
Speaker: SPEAKER_08
Transcript:  wine. Yeah, if you're one of those people, I guess you'd probably enjoy it. Caroline Haskins

Start time: 4771.06
End time: 4805.60
Speaker: SPEAKER_07
Transcript:  also here. Great work at Motherboard. It's amazing what a public information request can do. I think  it's just a matter of time before we cut those off. That Freedom of Information Act. That is  anti-American. That is a problem. People like Caroline going rooting around. My favorite thing.  Did you ever do dumpster diving for this kind of stuff?  No. No. On my computer. You're the modern reporter now. We don't have to go in the  dumpsters anymore. Mike, that's what things baby boomers do. Yes. Hey, I've got to show you  something. Wait a minute. I'm going to take off my shirt here. I've got to show you something.

Start time: 4805.72
End time: 4814.02
Speaker: SPEAKER_08
Transcript:  He's really a superhero. This is a job for. I am chilling the fox out. I even have

Start time: 4816.50
End time: 5000.29
Speaker: SPEAKER_07
Transcript:  Fox Mint Mobile socks. Fox socks. Ladies and gentlemen, I have been converted to Mint Mobile.  Let me tell you, this is the best network for people with smartphones ever. Mintmobile.com  slash twin. If you're still using one of the big four wireless providers,  take a look at your bill. It's cray cray. My Verizon phone is 90 bucks a month and I was,  I thought, oh, it's a good deal. Unlimited data and texts and phone calls, but they're inflating  the price because they have those big retail stores. They've got all the hidden fees. Mint  Mobile provides the same exact premium network coverage you're used to at a fraction of the cost  because they've eliminated the middleman. Everything is online, no retail locations.  I got to say, this is the modern way to do a cell phone, a smartphone. Every plan on Mint Mobile,  Mint Mobile is running on the T-Mobile network. If you've got T-Mobile in your neck of the woods,  this is a great solution. It comes with unlimited nationwide text and talk.  You stop paying for unlimited data you never use. You choose between plans with three, eight,  or 12 gigabytes of 4G LTE data. I actually paid $300. I bought a year ahead of time because I  love that. It's a great price. 12 gigabytes a month. I'm never going to use that up,  but if I ever do use more, you can buy it at a very affordable price. Use your own phone with  any Mint Mobile plan. I love it too, by the way, the OnePlus 7 Pro. It's my new favorite phone.  I go around town. I do Harry Potter, Wizards Unite, lots of data, but I still am well under 12.  It's costing me 25 bucks a month. It's amazing. Use your own phone with any Mint Mobile plan.  You can keep your phone number along with all your existing contacts, all your ditching,  that old wireless bill. I am such a fan of the Fox. In fact, so much so that I have accounts with all  the major carriers, I'm going to dump them all. Why not? Mintmobile.com slash twit. Get your new  wireless plan. $15 a month. It'll be shipped to your door for free. You get the SIM card.  Great support, by the way. You're not suddenly out of luck with support. They're great.  Mintmobile.com slash twit. As little as $15 a month. The Fox is smart. He's also pretty cool.  Mintmobile.com slash twit. I love on the SIM card. They have the Fox playing a guitar at a campsite.  This is awesome. Mintmobile. Thank you, Mint, for saving me a lot of money. I don't want to  say I'm all in on the Mint, but... What does it say? Mintmobile Shop Clever. Join the move, Mint.  I have to say I was really pleased when they said, hey, we want to get ads. Do you ever  heard of us? I said, yes, I've heard of you. $25 a month, 12 gigs. I've heard of you. He's

Start time: 5003.20
End time: 5007.22
Speaker: SPEAKER_08
Transcript:  actually drinking mint tea. He goes all the way down. Oh yeah, mint tea and my Mintmobile mug.

Start time: 5009.04
End time: 5019.22
Speaker: SPEAKER_07
Transcript:  Are Redditors going to invade Area 51 in September, by the way? Is that going to happen?  I hope so. The Air Force says we stand ready. I'm not sure that's a good idea.

Start time: 5020.12
End time: 5034.26
Speaker: SPEAKER_02
Transcript:  Yeah. The last time I checked the Facebook event for the Area 51 raid, I think three quarters of  a million people had responded that they were going. Oh my God. The theory is that there's

Start time: 5034.62
End time: 5064.42
Speaker: SPEAKER_07
Transcript:  alien technology hidden away at Area 51 that the government has never told us about it.  Let's just go en masse and just march in and get it. What could possibly go wrong?  This is the dumbest thing I've ever heard. They can't stop us all.  Someone doesn't understand machine guns. Yeah, machine guns can stop you all on barbed wire and  the Air Force has planes and missiles and I don't know. I don't know if this is a good idea.

Start time: 5066.04
End time: 5068.76
Speaker: SPEAKER_08
Transcript:  Didn't they try to levitate the Pentagon in the 60s or something?

Start time: 5069.08
End time: 5075.30
Speaker: SPEAKER_07
Transcript:  Yes. Things baby boomers do. We tried to levitate the Pentagon. Your kids are trying to invade Area

Start time: 5080.15
End time: 5110.58
Speaker: SPEAKER_02
Transcript:  51. There was this meme that I saw and it was almost like a battle plan and they had various  types of internet niche subcultures but all ones that were a little bit off center. You had furries,  I think. That was one. I feel like now that I'm only remembering furries on that list. No disrespect  intended to furries but they were like half a dozen different groups in different colors  sort of combining on Area 51. I don't know. If I were the government I'd be scared. They're coming.

Start time: 5110.76
End time: 5144.98
Speaker: SPEAKER_07
Transcript:  This has been the best source. There's the attack plan. This has been the best source  of memeification ever. Yeah, Naruto runners. There's one.  All the people. Battle Royale streamers. Oh my gosh. Yeah, I play Fortnite. I can do this.  I can do this. We can do this. Yeah. So by now they've moved whatever was there out. So even if  you get in there's not going to be anything left. Well, they use the alien technology to sort of

Start time: 5145.06
End time: 5159.22
Speaker: SPEAKER_08
Transcript:  beam themselves to another part of the galaxy. What are the chances that a place that flies  experimental aircraft that people would see strange aircraft in the area? How odd is that?

Start time: 5163.74
End time: 5205.04
Speaker: SPEAKER_07
Transcript:  So Apple updated the MacBook Air and MacBook Pro and I think this is maybe sad, killed the 12-inch  MacBook nothing. It was sexy. It was innovative. It was influential. It was the smallest MacBook.  Harry McCracken writing a brief eulogy for the 12-inch MacBook, a machine of unfulfilled promise.  A tear. A tear shed. I thought it was, you know, it was a little underpowered and I guess the  MacBook Air kind of probably scratches all the itches that the 12-inch did. But I, you know,  I like that old MacBook. I thought that was a pretty sweet. Well, it reminds us back in the day

Start time: 5205.20
End time: 5231.96
Speaker: SPEAKER_08
Transcript:  when Apple was so far ahead of everyone else in laptops. So far behind. Now they just have lost  the plot. They keep coming out with things that people don't really want, keyboards that don't  really work. And it's like back, you know, like five, six, seven, eight years ago, there was just  nothing like MacBooks. Nothing. They were just perfect. They had like the MagSafe connectors.  They didn't have the dumb strip. They, you know, et cetera, et cetera. But nowadays they,

Start time: 5232.78
End time: 5248.10
Speaker: SPEAKER_07
Transcript:  I noticed you're using a Pixel. Yep. Yep. Do you use a MacBook, Caroline?  I do. Yeah. I have an Air. I have an Air. I love my Air. Yeah. And the battery life is great. And  I carry it around. I'm not a fan of the butterfly keyboard, I have to say. Yeah. My work laptop has

Start time: 5248.32
End time: 5262.82
Speaker: SPEAKER_02
Transcript:  the butterfly keyboard and it's awful. It's been causing me problems. Yeah. Yeah. There's this  thing where if I press the shift key, it acts as if I'm pressing the command key. So then the next  letter that I press, it'll just open some random app, which is great. I love that.

Start time: 5264.04
End time: 5340.42
Speaker: SPEAKER_07
Transcript:  You never know what's going to happen. It's kind of like a MacBook roulette.  Yeah. There was an issue with Zoom. This is bad behavior. Zoom, which makes the, you know,  we've all used it. Who hasn't used it? Teleconferencing software. It's kind of like  Skype. Yep. And there's a lot of times you would use it. Maybe you'd uninstall it afterwards.  Guess what? Even if you uninstalled Zoom on your Macintosh, it put a hidden web server on  your computer that was continuing to run even after uninstall. And bad guys could use to turn  on your camera to silently, quietly put you in a Zoom conference with them.  Um, Apple, uh, did the right thing though. They just pushed a Mac update without your knowledge  disabling that server. Zoom, Zoom did not respond too well to the calls to disable it. So Apple had  to Zoom released a fixed app on Tuesday, but Apple said its actions will protect users past and present  from the undocumented web server vulnerability without affecting or hindering the functionality  of the Zoom app itself, which means Zoom didn't have to do this. Yeah, that's what's, that's what's

Start time: 5340.52
End time: 5351.94
Speaker: SPEAKER_02
Transcript:  strange because that the whole, the whole selling point of that was it would open up, uh, the meeting  faster and that everything would be faster. But I mean, I guess not. It's hard to say.

Start time: 5352.04
End time: 5358.34
Speaker: SPEAKER_07
Transcript:  Well, I did if it's always running in the background, but I think that's a bad behavior  to always have a web server running in the background even after you've uninstalled the

Start time: 5358.44
End time: 5368.82
Speaker: SPEAKER_02
Transcript:  software. That's not nice. Anyway, it's fixed. It would have been nice to know before I downloaded  Zoom. Um, I didn't have it on my desktop, but I had it on my, I had it on my phone. I deleted it

Start time: 5368.88
End time: 5447.30
Speaker: SPEAKER_07
Transcript:  anyway, but who doesn't? I mean, uh, you know, it's not my preferred, uh, teleconferencing software,  but everybody uses it all the time. So, uh, if you, I was very excited when the Apple watch, uh,  series four was it the most recent one came out with walkie talkie. I thought my wife and I  all will just press a button and say, Lisa, are you there? And she'd press a button and say,  hi, hi, can you bring me, can you bring me a cup of coffee? What? No, it's not working. So, um,  apparently remember the FaceTime vulnerability lab bad guys to get in a FaceTime conversation  and watch you. Well, apparently walkie talkie, same thing, same thing. You could, uh, listen to  another customer's iPhone without consent. Apple has disabled the walkie talkie app pending a fix.  Apple apologized for the bug and the inconvenience of being unable to use walkie talkie while a fix  is made. All five walkie talkie users were mad as heck. And nobody to complain to. I use, yeah,  it's not working. I stopped using walkie talkie like four days in, it was so annoying. Yes. I  thought this is going to be great. It'll be like a next cell phone. Yeah. I mean, apps that do that

Start time: 5447.44
End time: 5454.82
Speaker: SPEAKER_08
Transcript:  have been around forever on phones and people use it for a couple of days and they're like, yeah,  you know what? This is not that cool. It could call. It's not that cool. There is one Apple

Start time: 5454.96
End time: 5511.16
Speaker: SPEAKER_07
Transcript:  feature that is being used to do God's work in Hong Kong where the protesters are, you know,  unhappy protesting about the extradition treaty with China. Yep. The Chinese firewall, of course,  is keeping them from accessing content. So they're using Apple's AirDrop. It allows devices to send  photos and video over Bluetooth and wifi to breach China's great firewall to spread information to  mainland Chinese visitors in the city. Who are confused by the protest. Yeah. Like, I don't  understand. You leave AirDrop open and you'll say, it'll say, oh, Fred's going to send you something.  And you go, really? And you get some information. This is to let people know about the  extradition bill. And it's one way around the great firewall of China. One of the things that

Start time: 5511.50
End time: 5553.34
Speaker: SPEAKER_08
Transcript:  the story highlights is something that a lot of people don't realize is that Hong Kong is a huge  tourist attraction for mainland Chinese tourists. Because it's fun. It's like, wow, this is very  strange. And this is the whole point. Because all of that, there's a total blackout within  mainland China of the fact that Hong Kong, that what is it? One quarter of the population of Hong  Kong at some point has protested. Just a massive, unprecedented, ongoing, sustained protest, which  the mainland Chinese people have no idea. They haven't heard it. It's blacked out. Completely  blacked out. So as they stand there gawking at these protests, they're sending details about  what this means, what it all is. What's going on? Here's a tweet from Alice Su. She arrived at TST

Start time: 5553.50
End time: 5561.02
Speaker: SPEAKER_07
Transcript:  station and immediately her phone is bombarded with simplified Chinese flyers via AirDrop,

Start time: 5561.32
End time: 5571.70
Speaker: SPEAKER_08
Transcript:  explaining what's going on. Simplified Chinese is the version that mainland Chinese people use,  whereas in Hong Kong they use classical Chinese. That's why it's newsworthy that they're using

Start time: 5571.90
End time: 5576.80
Speaker: SPEAKER_07
Transcript:  simplified. It proves that they're targeting Chinese visitors. Wow. I didn't know that. Very

Start time: 5577.30
End time: 5599.21
Speaker: SPEAKER_08
Transcript:  interesting. So this is fascinating. But they're always going to find a way around it, I hope.  It's just the problem is trying to get mainland Chinese people to care enough. Because the big  controversy in China is don't rock the boat. We're on the road to prosperity. Let's not  go for freedom. Let's go for prosperity. It was a feudal nation 50 years ago or 100 years ago,

Start time: 5601.82
End time: 5632.76
Speaker: SPEAKER_07
Transcript:  and it has made amazing progress, but at some cost. Among other posters, did you know over the past  month Hong Kong has seen three massive rallies with as many as two million people taking to the  streets? Don't wait until freedom is gone to regret its loss. Freedom isn't God given it's fought for  by the people. I think we may be using that soon here. Just remember AirDrop. Wow. So that's an  Apple technology that is working quite well. Yeah. Really clever, I thought. Isn't that great?

Start time: 5632.96
End time: 5636.40
Speaker: SPEAKER_08
Transcript:  It's a feature, but I think the Chinese Communist Party would consider it a bug.

Start time: 5636.66
End time: 5664.88
Speaker: SPEAKER_07
Transcript:  Yeah. We can't block it. Apple is making TV. They've already said we don't want to be Netflix.  We're going to do handcrafted artisanal block Brooklyn style shows. Throwing millions of dollars  per episode at these handmade. This is one of the shows which is called C about, I don't know,  it's weird. It's about a future where everybody's blind. Yeah. Jason Momoa is in it, Alfred Woodard.  $15 million an episode. In the Game of Thrones era, that doesn't seem like that much.

Start time: 5665.00
End time: 5681.18
Speaker: SPEAKER_08
Transcript:  Well, for the first many seasons of Game of Thrones, they didn't reach that level. So  eventually they reached $15 million and above. So they're going in just throwing tons of money.  Going in big at first. But so far Apple has demonstrated a complete lack of ability  to do compelling programming. Go ahead, Caroline.

Start time: 5682.68
End time: 5692.46
Speaker: SPEAKER_02
Transcript:  Yeah. I just think that's, I don't know, that's a huge gamble to make up front. I don't know.  I remember, remember that, I don't even remember the name of it, that like reality type or game show.

Start time: 5692.70
End time: 5712.50
Speaker: SPEAKER_07
Transcript:  Oh God. It was awful. The app. Yeah. Yeah. And I'm just thinking about how.  Yes. Yes. That's it. They had people pitching the, so the idea was to time your pitch to the investors  with Shark Tank basically. So they put them on an escalator and their pitch had to be done when  they got to the bottom. Like they're running for president. We'll see you first put Vaynerchuk in

Start time: 5712.50
End time: 5717.44
Speaker: SPEAKER_08
Transcript:  the chat room. It's not an elevator pitch, it's an escalator pitch. It's the escalator pitch. Vaynerchuk

Start time: 5717.70
End time: 5735.42
Speaker: SPEAKER_07
Transcript:  was one of the judges, Gary Vaynerchuk. That's right. Along with Gwyneth Paltrow and Will.i.am.  It was terrible. Quite a brain trust there. It's terrible. But that was made by other people.  They brought in Sony executives and they're bringing in major talent and all that stuff.

Start time: 5735.80
End time: 5759.78
Speaker: SPEAKER_08
Transcript:  It's a lot of money. Apple's got money. But even when Apple took over Carpool  karaoke, they kind of smothered the charm out of it. Well, they took James Corden out of it.  What's Carpool Karaoke without Corden? They also did super high-end cameras and better production  values. And the whole point of it was that it was cheesy and low budget and they didn't get that. So  anyway, we'll see if the planet of the blind people is going to be better. Did you see these

Start time: 5759.94
End time: 5796.82
Speaker: SPEAKER_07
Transcript:  Stranger Things AR ad? I didn't see this in the New York Times. I didn't see the actual ad.  So if you had Google Lens and you saw the ads for the Starcourt Mall, which is the  Hawkins Indiana Mall that Stranger Things said. By the way, they took an old 80s mall that was  decrepit and empty and rebuilt it. They rebuilt it. It was so cool. I haven't seen all of it.  No spoilers. But here's what would happen if you pointed your Google Lens  at the print ad, it would come alive. That's pretty neat.

Start time: 5797.64
End time: 5824.90
Speaker: SPEAKER_08
Transcript:  That is one of the Stranger Things I've ever seen done.  We were in Hollywood a couple nights ago and wandering around on Sunset Boulevard. They do  all the movie billboards. The movie billboards there are amazing. And Stranger Things is just  there's a whole several blocks where every billboard is Stranger Things. And it's like  you have to read it as you're driving down the street. These are gigantic. It's like Bermashave

Start time: 5825.06
End time: 5830.86
Speaker: SPEAKER_07
Transcript:  ads. Yeah. Caroline, don't listen. Although you could use this for your Things Boomers Do group.

Start time: 5831.28
End time: 5839.24
Speaker: SPEAKER_08
Transcript:  Yes. Oh my gosh. This is good research here. Bermashave is like beyond. That's the greatest

Start time: 5839.40
End time: 5887.97
Speaker: SPEAKER_07
Transcript:  generation. But you would sometimes see even though today sometimes, maybe I don't know,  when I was a kid, you drive around the countryside these old ads for this shaving cream.  And the whole idea was they would be sequential ads. Right. You read them as you drove by.  And they would always be a poem. And it would be a joke and would end with Bermashave.  Okay, I'm sorry I even brought it up. Go down that rat hole.  Do you want to see a Bermashave sign? Where are they now? I don't know. Here it is. So you'd go  by and the first sign says if you then don't know whose signs these are. You can't have driven very  far. Bermashave. Genius marketing. Bermashave was out of business by 1966. Coincidence?

Start time: 5891.76
End time: 5943.46
Speaker: SPEAKER_08
Transcript:  My grandparents had a whole book of them. One of my new hobbies is taking pictures of ghost  signs which I see everywhere in Europe. What's a ghost sign? When they had a sign in a building  and they just had forgotten about it and it's still there. We have some in Petaluma. There's  a really cool one we saw driving in. What was it? It was like a chicken, it was an egg hatchery or  something. Yeah, yeah, yeah. There's a lot of old hatcheries around here. There used to be a lot  of chicken farms. But there's one in France where it's like they're actually advertising telegraph  services. Wow. It's so cool. That's kind of a neat photographic hobby. Well, here's another thing you  realize. We go to a lot of wine countries and everything used to be called champagne. So you  go to the Cava country in Barcelona and it says champagne. They can't say it anymore because it's  a registered trademark. And Prosecco and all that stuff. Everything used to be champagne. You see  champagne ads in all these places where they don't make champagne. Champagne region said you can't

Start time: 5943.58
End time: 5972.34
Speaker: SPEAKER_07
Transcript:  do that. So Amazon's remaking the Lord of Rings. They spent a billion dollars for the rights.  For the rights. And they are also making a game. Which they say is not related, which I'm confused  by. Please come on. It's an MMO multiplayer, massively multiplayer online game.  So this is good. They're going to merchandise the hell out of this, right? There was a Lord of the  Rings online. I didn't know this in mid 2000s. Does anybody care about Lord of the Rings anymore?

Start time: 5973.40
End time: 5978.18
Speaker: SPEAKER_08
Transcript:  Is that a thing? Anyone? That's what I'm wondering. I mean, I don't know. I think people like to read

Start time: 5978.28
End time: 5981.52
Speaker: SPEAKER_02
Transcript:  the books. I mean, I haven't read the books. I was over at halfway through the second one.

Start time: 5981.68
End time: 5987.14
Speaker: SPEAKER_07
Transcript:  Harry Potter's even over. Is it? Yeah. It's kind of sad. I think after like,

Start time: 5988.82
End time: 6000.40
Speaker: SPEAKER_02
Transcript:  eventually at some point down the post-American, after the books come out and you just merchandise  everything and add new stuff to the canon, people get exhausted. It's too much. I think that's

Start time: 6000.60
End time: 6038.18
Speaker: SPEAKER_07
Transcript:  happened with Harry Potter. I have to see that stupid kid with a lightning on his forehead one  more time. I was in the bookstore last night and there's a whole table of Harry Potter games and  they all have Harry Potter. Yeah. Yeah. It's vexing. It's vexing. Cuphead. You ever play Cuphead? Yep.  Great game, right? Cuphead? No. It's probably the hardest game ever. It's kind of an old 20s cartoon  style, Max Fleischer cartoon style. They're making a Netflix TV show out of Cuphead. The Cuphead show  is in production. It will channel the game's homage to Fleischer era animation. It's very violent.

Start time: 6038.30
End time: 6043.80
Speaker: SPEAKER_08
Transcript:  Very violent. Yeah. As cartoons used to be. Yeah. But I think it'd be fun. Yeah. Yeah. All right.

Start time: 6044.84
End time: 6087.30
Speaker: SPEAKER_07
Transcript:  Let's take a break. Lots more to talk about. Caroline Haskins is here from Motherboard. Oh,  love the motherboard. I'm just going to say love the motherboard. Could you do a Freedom of  Information Act request of Area 51? Wow. Good question. Wouldn't that be? I mean- I will try.  Be simpler than invading it. Yeah. And easier. And if you get something that's redacted, redacted,  redacted, that's going to be. That's something. That's an article. Yeah. Yeah. She's excited about  it. I can tell. Mike Elgin's also here. Elgin.com. If you missed anything this week, we had a fun  week on Twitter. Here's a little sample of some of the things. On Twitter. Unexpected announcement

Start time: 6087.42
End time: 6091.52
Speaker: SPEAKER_06
Transcript:  this week. Creative celebrates 30 years of Sound Blaster with new AE9 and AE7 sound cards.

Start time: 6092.70
End time: 6111.86
Speaker: SPEAKER_05
Transcript:  Like, you know, the Nintendo consoles have enjoyed a renaissance with the NES Mini and the SNES Mini,  and they'll capitalize on this trend by serving a market of 10 to 15 people globally with reimagined  Game Blaster cards in vintage packaging. Creative, if you're watching, would buy one.

Start time: 6113.22
End time: 6123.76
Speaker: SPEAKER_07
Transcript:  iOS today. So the new iOS 13 came out yesterday. If you're in the public beta, we all downloaded  the public beta. We should demonstrate this, but I don't know if we can really do it properly. Now

Start time: 6123.96
End time: 6129.96
Speaker: SPEAKER_04
Transcript:  look at me. Look at the camera. Now look at me. You know, we got there. I feel like I ran a marathon

Start time: 6130.24
End time: 6141.36
Speaker: SPEAKER_00
Transcript:  today. I'm so proud. All about Android. You remember a couple of weeks ago where I brought on my Motorola  Zoom and I couldn't power it on because of the power supply. You found it. I got the power supply.

Start time: 6141.52
End time: 6146.34
Speaker: SPEAKER_04
Transcript:  Had it shipped to me. Play music. Look at that. Look at the upper left hand menu.

Start time: 6149.10
End time: 6166.90
Speaker: SPEAKER_01
Transcript:  Bitcoin is based off this wonderful, horrible idea. I'm not that interested in what is the  price of Bitcoin, right? I'm interested in the technology. Bitcoin's whole point is that it's  decentralized, but it's not as decentralized as you'd really like it to be.

Start time: 6173.32
End time: 6176.86
Speaker: SPEAKER_07
Transcript:  That was a triangulation with Bram Cohen, the guy who invented BitTorrent.

Start time: 6177.33
End time: 6177.51
Speaker: SPEAKER_00
Transcript:  Yeah.

Start time: 6178.12
End time: 6415.64
Speaker: SPEAKER_07
Transcript:  And maybe he's mad that Bitcoin took his bit.  Yeah. Just a bit.  Here's a quote. This was a tweet from Theophyte. The question was, explain Bitcoin to grandpa.  Imagine if keeping your car idling 24-7 produced solved so to cool puzzles, you could trade for  heroin. That's Bitcoin. I finally understand it.  That makes sense now. I understand it. Our show today brought to you by Wasabi. Not that green,  hot green stuff next to your sushi, but it is hot. It's hot cloud storage from two of my favorite  people in the world. David Friend, the founder of Carbonite, his CTO, Jeff Flowers. It was actually,  I think, Jeff who created a patented technology for writing on hard drives sequentially, not in  blocks. That's how every other hard drive works. But by writing sequentially, they were able to get  improved speed, improved reliability. That's how Carbonite was founded. They've gone on to  found this new Wasabi hot cloud storage, and it's incredible. They are able to  using this revolutionary process, give you enterprise-grade cloud storage that's one-fifth  the cost of Amazon S3 and six times faster. One-fifth the cost, six times faster. They never  have hidden fees for egress or API. In fact, they have a great API because it's Amazon S3's API.  So they're completely compatible that you already know how to use it. 11 nines of durability,  they do integrity checking on your data. And this is so great in this day and age of ransomware.  They do immutable data. So you can say this data may not be changed, not by ransomware,  not by a fumble-fingered employee, not by me, not by anybody. Immutable data is the secret  to keeping your data safe. HIPAA compliant, FINRA compliant, CJIS compliant.  Where everybody's moving to the cloud. Gartner Group says by 2025, 80% of businesses will have  shut down their data center. 10% today are in the cloud. It's going to be 80% in five years.  Zettabytes. Well, let me tell you, I know if you're, you know, and a lot of businesses  thinking about this right now, maybe you're charged with looking into this.  You're going to look at Amazon, Google, and Microsoft. I know you are.  Can I add a fourth name to the list? Take a look at Wasabi.  One fifth the cost, six times faster. Immutable storage. This is an amazing company with a  revolutionary solution. And because they are 11 nines of durability, you just don't have to worry.  Your data is actually more secure, safer than it'd probably be on premises. So, and with the Wasabi  ball, which I love that name, the Wasabi ball is not a green ball of hot stuff. It is actually a  giant drive array that they send to you. You put your data on it, you move it up to the cloud  instantly like that. Look, we've got unlimited storage for you for a month. So you can really  bang on this. If you go to wasabi.com, W-A-S-A-B-I, click the free trial link, edit the code,  twit, join the movement, migrate your data to the cloud with confidence, wasabi.com. Don't forget  that offer code, twit. Thank you, Wasabi. Thank you, David and Jeff for supporting us. They've  been supporting us for a long time. They're really twit fans. And I thank you, twit fans,  for supporting us by using the offer code twit at wasabi.com. Watch out, by the way, we were  mentioning Prime Day. I just want a little public service announcement. There are a number of  phishing scams around Prime Day. So, you know, it happens at tax time. The fishers are just  terrible. Prime Day phishing scams that look like emails from Amazon. Just be careful what you click  on. Is that part of your Things Boomers Do group? Click on phishing scams.  I think that, I think to be fair, I think that, I don't know, Reply All did a good thing about this

Start time: 6415.78
End time: 6449.16
Speaker: SPEAKER_02
Transcript:  also. Like, like a lot of people fall victim to phishing scams. I think that, I think that  people fall victim to phishing scams. Like even if you're, even if you consider yourself like  a generally competent person or a skeptical person. It's too easy. Yeah. Yeah. Yeah, it's very easy.  It's really, I feel like I'm skeptical of everything in my inbox now. Like I got a,  I got an email like asking to do like a survey for work and I was like emailing all my colleagues.  Like, is this real? Am I being phished? Right. That's what you have to do now, right? Yeah.

Start time: 6450.22
End time: 6454.84
Speaker: SPEAKER_07
Transcript:  Because if it's from work, that's almost a certain, that's guaranteed to be a scam.

Start time: 6455.34
End time: 6460.58
Speaker: SPEAKER_08
Transcript:  Right. Yeah. Or if it's from yourself or you know, a relative, it's not from strangers.

Start time: 6460.98
End time: 6465.38
Speaker: SPEAKER_07
Transcript:  Were you a, were you a Friends fam, Caroline? Were you a fan of the Friends TV show? You're

Start time: 6465.56
End time: 6470.96
Speaker: SPEAKER_02
Transcript:  too young for that probably. Friends, I've, I've watched Friends. It's like, it's fine.

Start time: 6471.14
End time: 6496.02
Speaker: SPEAKER_07
Transcript:  It's like a nice fan. I didn't realize it was the number one streaming show on Netflix. That and the  office are huge. I didn't know that. It's leaving. It's moving off of Netflix. It's going to something  new called HBO Max. Oh boy. Just another thing you're going to want to pay for. Thank you AT&T.  HBO Max will be a over the top streaming service. You know, HBO already has HBO Go,

Start time: 6496.36
End time: 6503.68
Speaker: SPEAKER_04
Transcript:  right? HBO Now. That's going to be shutting down. That is? Yes. When, when HBO Max launches HBO Now

Start time: 6504.44
End time: 6642.10
Speaker: SPEAKER_07
Transcript:  AT&T is going to ruin HBO. I remember where the AT&T executive came into HBO and said,  we want to be more like Netflix. I thought, oh boy. Yeah. So you'll be able to get Friends  on HBO Max as well as Fresh Prince of Bel-Air. Woo hoo. This is hot programming. Pretty little  liars. Woo hoo. And I guess all the HBO shows, if they're going, if they're not going to have HBO Go  and HBO Now, CW shows, including Batman and Katie Keene will be, this sounds like a flop. I'm sorry.  Exclusive movies with Reese Witherspoon. There's a name. That's going to two romantic comedies and  four young adult titles with Greg Berlandi. I don't even know who that is, but I'm not a young adult.  What about us boomers? An Anna Kendrick led comedy series called Love Life, an animated prequel  series for Gremlins. This sounds like, this sounds like the worst. It's going to debut in spring 2020  with 10,000 hours of material. Like Dune, the Sisterhood. Friends is it, right? Yeah.  Netflix tweeted, the one where we have to say goodbye. We're sorry to see Friends go to Warner's  streaming service at the beginning of 2020. Thanks for the Memories Gang. And then there's a little  coffee cup, which I'm sure means something in Friends language. We don't know what the price  will be, but I could tell you right now, if they got Game of Thrones on there, I guess, oh, wait a  minute, it's over. Now that it's over, they should have timed that better. And so France,  that's all I'm going to say. France, at Cien, France, at Cien's in our studio, he lives in France,  has decided to tax tech companies 3% on digital services if you make more than 750 million euros  in global revenue and 25 million in French revenue. In other words, if you're Google,  Facebook or Amazon, you're going to pay a 3% tax, 3% of your total annual revenue. That's a ton.

Start time: 6644.20
End time: 6650.28
Speaker: SPEAKER_08
Transcript:  And what's wrong with that? I mean, I think the other question is why should tech companies be

Start time: 6650.44
End time: 6661.60
Speaker: SPEAKER_07
Transcript:  tax free? No, they shouldn't be, but they shouldn't be specially taxed either.  Well, right? Should there be like a surcharge for being a successful US tech company?

Start time: 6662.26
End time: 6665.54
Speaker: SPEAKER_04
Transcript:  How much US income tax did Amazon pay this year?

Start time: 6666.44
End time: 6688.68
Speaker: SPEAKER_07
Transcript:  You know, that's kind of a misleading stat. Yeah, they got a nice check. H&R Block gave  them an advance on it. It was nice. But how much was it?  No, no, it's not zero. It's not zero. Everybody says Amazon paid zero.  And it's very low. It's very low. It's low. It's low. Okay, because they spent money. They made

Start time: 6689.20
End time: 6705.32
Speaker: SPEAKER_08
Transcript:  they put you know, here's the thing. The tax situation in France is a really touchy subject.  You can verify this. I've talked to a lot. I got a lot of friends in France. We spend a lot of time  in France. I've been told that the income tax rate can be like 70%. Is that roughly? Is that

Start time: 6706.72
End time: 6713.86
Speaker: SPEAKER_07
Transcript:  an exaggeration? It's ridiculously high, right? Yes. High services, you get what you pay for it.

Start time: 6715.72
End time: 6745.68
Speaker: SPEAKER_08
Transcript:  We pay high taxes and get nothing. But in that tax environment to tax these big companies,  3% or something is really a tiny drop in the bucket. And I think, you know, I think,  I personally am in favor of national governments doing more to police to tax to do whatever they  want with these international companies. I was listening to this political podcast,  where they were saying how the British Parliament called Mark Zuckerberg to testify and he's like,

Start time: 6746.14
End time: 6756.62
Speaker: SPEAKER_07
Transcript:  no, I'm not going to do that. He said no. He said, in fact, he can't go to Canada,  he'll be arrested. He said no to Canada. Fair enough. But I think, but my point is,

Start time: 6756.84
End time: 6776.42
Speaker: SPEAKER_08
Transcript:  the podcasters were saying dumb things, namely that, wow, Zuckerberg, the reason is that  Facebook is more powerful than the British government. No, the difference is the British  government isn't using its power. What they should say is that we're shutting off Facebook  until Mark Zuckerberg appears before us. This is a problem, though. I think it's fantastic.

Start time: 6776.50
End time: 6782.98
Speaker: SPEAKER_07
Transcript:  We're going to have a splinter net. We're going to have an American internet, a Chinese internet,  a Russian internet and a European internet. That's a different question. Things like the

Start time: 6783.20
End time: 6796.10
Speaker: SPEAKER_08
Transcript:  right to be forgotten. That's a splinter net. But taxing or banning a social network until their  CEO comes before the government is, I think, perfectly reasonable. I don't mind a tax. I just

Start time: 6796.58
End time: 6801.12
Speaker: SPEAKER_07
Transcript:  don't think there should be more tax because you're a successful tech company. I mean,

Start time: 6801.36
End time: 6809.54
Speaker: SPEAKER_08
Transcript:  lots of taxes are levied for lots of reasons. And in Europe, the cost of gasoline is super high  because they're taxing that for all kinds of reasons. I think it's, I'm fine with it.

Start time: 6809.70
End time: 6817.30
Speaker: SPEAKER_07
Transcript:  The United States trade representative said, we're going to investigate and there may even be a  tariff war as a result. Go ahead, Caroline. What do you think?

Start time: 6818.58
End time: 6849.86
Speaker: SPEAKER_02
Transcript:  Oh, no, I think it's just that, I mean, if citizens are treated like a well of data that  the company is using to profit, it's only fair to expect the company to pay back into services  that will help those people. And I think like the sentiment that it's anti-American in any kind of  way, I mean, that's ridiculous. I mean, the solution to that is just tax the companies in the U.S. But  obviously the people who are saying that it's anti-American would not be in favor of  that kind of tax. But I don't know. That's just my opinion.

Start time: 6850.16
End time: 6878.98
Speaker: SPEAKER_08
Transcript:  The big fines, like for example, against Google for favoring their own services and search results,  all those kinds of things are also said, called anti-American. I think I've said that myself,  but it's really American companies are complaining to European authorities about other American  companies. So it's like also favoring American companies for, you know, namely Microsoft, etc.  to sort of ding these giant companies that are, you know, appear to be favoring their own search

Start time: 6879.12
End time: 7123.22
Speaker: SPEAKER_07
Transcript:  results. One more break. Let's, I've got an obituary for a computer science pioneer you never heard of,  but he's done two things that you will know. One good, one bad. Okay, that's coming up.  Our show today brought to you by ZipRecruiter. If you need to do, we just recently done a lot  of hiring. I got to say ZipRecruiter is the bee's knees, as my people say. It is the easiest way to  hire. If you're the person in charge of hiring, you know that it's a terrible job because first  of all, you're down a person or two or three or whatever. So you're working harder anyway,  especially if you're a small business like ours. But also the person you're hiring, that could make  or break your company. Companies are just a bunch of people with a common purpose, a great employee.  And I think we just hired some really great employees to the moon, but somebody not so great  could bring you down. ZipRecruiter is going to improve your chance of getting that magic  employee. There's somebody out there that's just right for your opening. The question is,  how do you reach that person? ZipRecruiter. ZipRecruiter, the first thing that happens,  posts your job listing on ZipRecruiter to more than a hundred job sites with one click, including  social networks like Twitter and Facebook. So you're going to reach the largest number of  candidates. That's great. That means that person, that perfect person, no matter where they're  hiding, is going to see your job posting. But ZipRecruiter does it one more, one step better.  They use powerful matching technology to scan all the resumes, to find people who have the  experience that would be right for you, and then invite them to apply, which means they're actually  saying, hey, this is a great job. Come here. You've got to see this. And as those applications come  in and all the other applications, ZipRecruiter will analyze each one, spotlight the top candidates  so you don't miss a great match. All the applications, they don't go into your mail,  your inbox, or your phone. They go right into the ZipRecruiter interface. This matching technology  is so powerful, four out of five employers who post on ZipRecruiter get a quality candidate on  the site within the first day. That's been our experience, by the way. It's exactly within the  first few hours. Right now you could try ZipRecruiter free. We've got a special address  for you, ziprecruiter.com slash twit. Show your support for the show, just as ZipRecruiter has  shown its support by going to ziprecruiter.com slash twit. We love ZipRecruiter. It's been such  a great thing for us. Z-I-P-R-E-C-R-U-I-T-E-R dot com slash twit. ZipRecruiter. See, it's that  French language that messes up our spelling. Recruiter, Recruiter, ZipRecruiter. Yeah, we've  hired one, two, three, four new people in the last month, some of whom you don't even know about  yet, but you will hear soon. Niantic. Now, I said I don't like Harry Potter, but I can't stop playing  Harry Potter, Wizards United, it's the Pokemon Go replacement. Niantic was a spin-off of Google.  Remember, they were the Google Maps guys. Their first app, you know what their first app was?  Field Trip. Remember that? Turn on Mike's mic. Yes, yes, that was great. So, Field Trip was the app  where you'd go around and it would tell you, in fact, it was fun in Petaluma because there's only  like four points of interest. Do you know the movie Remembering the Abbots was shot in that house? Yes,  I know, you told me every time I tried to find it. American Graffiti was shot right here on this empty  lot. There's four points of interest. Anyway, they're shutting it down. It's over for Field  Trip, which is another, that's how Google works, isn't it? Yeah, they're the new Yahoo. Yeah.  Now there's Chatterbox. Is this, is this, oh wait a minute, that's, I'm gonna save Chatterbox for the  end. That wasn't it. There's a new Google, what is it called? Safety pin? Oh, shoelace, shoelace.  They're bootstrapping. I knew it was a common household object. So what does shoe leather do?

Start time: 7124.62
End time: 7130.82
Speaker: SPEAKER_08
Transcript:  Shoelace is a, so I'm especially bitter about this one, Leo, so let me allow me to express my

Start time: 7130.90
End time: 7136.40
Speaker: SPEAKER_07
Transcript:  bitterness. You already, you went all in on Google Plus. Yes. And your heart was broken. Yes. What is

Start time: 7136.60
End time: 7154.84
Speaker: SPEAKER_08
Transcript:  shoehorn gonna do? Shoe leather is a, shoelace is a, it's supposedly a social network organized around  events and other things that are geographically specific. So. This is from Google's research

Start time: 7155.26
End time: 7185.66
Speaker: SPEAKER_07
Transcript:  arm, Area 120, which is not Area 51, do not invade it. This great, although if you do invade it,  this would be a great way to organize that. Right now it's only in New York. In fact, you could use  it, Caroline. Have you tried shoe leather? I haven't, no. I'm just playing into this whole  baby boomer thing. Did you see, have you seen that I'm wearing mint socks? Have you seen that?  Nevermind. Yeah, lovely. Yeah, lovely. So here's what, here's my shoe. What is shoelace? It's this

Start time: 7185.94
End time: 7200.42
Speaker: SPEAKER_08
Transcript:  dumb thing that is basically supposedly a social network, but it's focused on. Location based.  Location based. So it's basically, it's basically, it's like 5% of Google Plus. They decided to come  out with this spectacularly insignificant thing. I have to point out, they did this already. Yes.

Start time: 7200.86
End time: 7210.34
Speaker: SPEAKER_07
Transcript:  They did Schemer. Several times. Schemer, which I tried. That was the one with the mustache.  This is basically Schemer. That one was shut down in three years. Yeah. They just need more

Start time: 7210.48
End time: 7213.62
Speaker: SPEAKER_08
Transcript:  things to shut down. So they can't shut down things unless they launch things. So it's an

Start time: 7213.72
End time: 7238.98
Speaker: SPEAKER_07
Transcript:  invite only testing phase on iOS and Android. If you want though, you can go to this URL,  docs.google.com slash form slash de slash one F A I P Q L S. I'll forget it.  And you can say, keep me in the loop about shoelace. Get it. Oh,  like that. Very nice. I'm going to put a bow on this story and move on.

Start time: 7241.34
End time: 7247.86
Speaker: SPEAKER_08
Transcript:  Shoelace. What is with Google? They really suffer from the inability to understand how people

Start time: 7248.12
End time: 7346.90
Speaker: SPEAKER_07
Transcript:  communicate. Yeah. That's the humans. We don't get them. This was a great, uh, uh, P I have to say  the privacy project in the New York times has been very interesting. Charlie Wartzel and Ashton goo  created, I don't know if that's how you pronounce it. New maybe, uh, new, new. Yeah. Created, uh,  a comparison between Google's original privacy policy in the, in the late 1990s was 600 words  to their current privacy policy for 20 years later, 4,000 words. It's cross all the way down  the page here. It is really more, it's less about Google than about how the internet has changed and  how technology has changed because in 1999 there wasn't any, you know, smartphones. They weren't  collecting mobile information at all. In 1999, they say Google may share information about users  with advertisers, business partners, sponsors, and other third parties, but we only talk about  our users in aggregate, not as, not as individuals that that was cut out three months later. Uh,  20 years later, uh, it's, it's quite the opposite. We will share information,  information, things we know about you, everything, and we will share it with everybody.  And, uh, it's a little longer location information. They didn't have that before  your Android device type carrier name crash reports, which apps are installed.  So I, it's, isn't so much demonizing Google, I think as just saying, pointing out how modern  technology like smartphones has given them so much more information. And it's really, they're, they're,

Start time: 7346.90
End time: 7351.38
Speaker: SPEAKER_08
Transcript:  they're stapling on new things every time they get caught doing something or every time they start

Start time: 7351.58
End time: 7378.60
Speaker: SPEAKER_02
Transcript:  with GDPR to be fair. Yeah. I think like the average person just figures like if they've been  using Google for a long time, like I don't think it registers in the average person's head just how  many changes have occurred. I don't know, just between like 2005 and now, for example, just like  the scope of the information that they have on you that they didn't necessarily even have before.  I don't know. I don't even think that registers in the average person. That's why I like this. And I

Start time: 7378.92
End time: 7394.58
Speaker: SPEAKER_07
Transcript:  don't know why, but the Times marks it a pro, an opinion piece, I guess everything on the privacy  project is an opinion piece, but I think it's a really interesting article and it is, it is an  eye opener. I don't think people are really aware of how this has changed because nobody reads it.  Right. They didn't read it when it was 600 words. They didn't read it when it's a thousand or 4,000.

Start time: 7396.06
End time: 7421.36
Speaker: SPEAKER_08
Transcript:  I think that Amazon's privacy policies are still pretty short because they don't want to talk about  it and they don't want to guarantee anything. Short isn't better. You know, no, it is not.  I've read their privacy policy around Alaska and because I was wondering, you know, do they reserve  for themselves the right to listen without the wake word? Do they XYZ? And they pretty much  give themselves the ability to do anything and their privacy policy doesn't say anything about

Start time: 7421.58
End time: 7498.42
Speaker: SPEAKER_07
Transcript:  them. We make no promises. Use it or don't use it, but we make no promises. And then,  if you thought Google Assistant or Google's home devices were any less intrusive, well,  you'd be wrong. Google workers listen to your queries. But you know, this is part,  I mean, all these businesses do this. Again, I think this is like, as you said, Caroline,  it's just a case of people don't really think about it. And so they don't pay attention,  but if they thought about it, yeah, one of the things that happens with both Amazon's Echo,  Google, and I bet you Cortana and Siri too, is they need humans to listen to it to see if the  computer understood it and it's how they get better. VRT News, which is a Flemish public  broadcaster in Belgium. We all watch, we all read that. Yeah. Well, if you speak Flemish,  it's really the place to go. That's right. Where else are you going to read Flemish?  Flemish News was able to, so apparently somebody leaked the user voice recordings from within  Google to this Belgian organization. A Google subcontractor passed on more than a thousand  assistant recordings. VRT said in these recordings, we clearly hear addresses and  other sensitive information. This made it easy for us to find the people involved and confront

Start time: 7498.56
End time: 7520.94
Speaker: SPEAKER_08
Transcript:  them with the audio recordings. And they said, yep, that's my voice. I said that. Wow. Here's  my favorite factoid from the article. 153 of the 1000 recordings, the command OK Google was clearly  not given. Oh, misunderstood. Or for some reason without people doing the wake word,  they started recording and they maintain and they retain that recording. Remember they only got

Start time: 7521.32
End time: 7580.98
Speaker: SPEAKER_07
Transcript:  a thousand recordings. More than 15% of them didn't have the wake word and included bedroom  conversations, conversations between parents and their children, blazing rouse and professional  phone calls containing lots of private information. And then really blazing rouse are the worst kind.  That's got to be a Flemish phrase. It's got to be. Google's response to Ars Technica,  actually to VRT, we just learned that one of our language reviewers has violated our data security  policies by leaking confidential Dutch audio data. Our security and privacy response teams have been  activated. Oh God, I bet those are robots with laser eyes and are investigating. We will take  action. We're conducting a full review of our safeguards in this space to prevent misconduct  like this from happening again. This is going to happen, right? That may be the really thing.  People always say, oh, I don't want an Amazon in my home because I don't want Amazon listening to me.  Bigger the problem may be that it's not just Amazon. It is not just Amazon.

Start time: 7583.12
End time: 7609.86
Speaker: SPEAKER_02
Transcript:  Yeah, just like remember a couple of months ago when I think someone used some GDPR clause and  requested all of the data that Amazon had about themselves through their Echo device and they sent  the wrong person's information, the wrong person's recordings to them. Yeah, that's what I thought  about when I read this. And there's going to be individual instances like this. And it's just,  I don't know. I mean, obviously it raises the question like, how does this company actually...

Start time: 7610.06
End time: 7613.78
Speaker: SPEAKER_07
Transcript:  The ice cream trucks out front, run out, get yourself a frozen tree.

Start time: 7614.94
End time: 7616.48
Speaker: SPEAKER_02
Transcript:  Wow. I guess the audio is very good.

Start time: 7618.58
End time: 7622.50
Speaker: SPEAKER_07
Transcript:  I just think moving to Brooklyn is the place to be. You got an ice cream truck.

Start time: 7623.46
End time: 7623.52
Speaker: UNKNOWN
Transcript:  Man.

Start time: 7623.94
End time: 7628.54
Speaker: SPEAKER_02
Transcript:  This is just coming down my block about five times a day. I've never gotten ice cream though.

Start time: 7628.70
End time: 7633.36
Speaker: SPEAKER_07
Transcript:  What? You don't go chasing it?  No.  That's the fun of having an ice cream truck.

Start time: 7634.94
End time: 7636.80
Speaker: SPEAKER_02
Transcript:  Some people do, I guess. It's tough.

Start time: 7637.66
End time: 7663.22
Speaker: SPEAKER_07
Transcript:  All right. I'm sorry. I mean, you're up to you, but the thought of a frozen tree got me excited.  It's a nice life.  Something boomers do. It's don't pay no attention.  We, in my day, we would chase that ice cream truck. Mr. Softy, Mr. Softy, stop.  I want a rocket pop.  What was your favorite?  I don't know.  You liked drumsticks?  Yeah, we didn't.

Start time: 7663.70
End time: 7666.40
Speaker: SPEAKER_08
Transcript:  I didn't grow up in Brooklyn. We didn't have the ice cream trucks.

Start time: 7667.52
End time: 7685.86
Speaker: SPEAKER_07
Transcript:  I'm sorry. Maybe this has just gone on too long.  Did we cover every possible angle of the tech week? Everything going on?  Twitter is going to try its hide replies feature next week in Canada.  Not here.

Start time: 7688.98
End time: 7726.30
Speaker: SPEAKER_08
Transcript:  Actually, I think this is kind of a significant story because we've had many conversations  on this show and also this week in Google about my prescription for the problems that plague  Twitter and my prescription has always been let users delete comments.  If I tweet, do a tweet and somebody comments on the tweet, I should be able to delete it for  everyone. That's what Google Plus did and it worked.  Facebook does it too. In this case, you're kind of halfway there. You can hide  people's comments and they go into sort of a hidden area. It's not that great of a solution,  but it's a step in the right direction, giving the original poster control over the comments.  I think that's-

Start time: 7726.68
End time: 7740.66
Speaker: SPEAKER_07
Transcript:  Oh, is that how they're going to do it? Because I thought it was going to be,  this is different from the one where they say, if it's from a famous or political figure,  don't look at this. They put a thing up. Are you sure? This is different.  Yes, this is different. This is different.

Start time: 7741.70
End time: 7776.92
Speaker: SPEAKER_08
Transcript:  So you post something on Twitter, you post a comment and I go in there with a nasty comment  and you can just say, you know what, hide that. If people want to go in and see the hidden comments,  they can, but they know that people are lazy and probably won't. So it devalues the comments that  the poster wants devalued. And some of the criticism I think that I disagree with quite a  bit, which is that, well, what if somebody's fact checking? What if somebody's blah, blah, blah?  I think that on a social network, you should be able to manage and moderate the conversation  that follows of your own tweets. If people want to disagree on their own stream, they can,  but I think people should have control over comments.

Start time: 7777.34
End time: 7781.26
Speaker: SPEAKER_07
Transcript:  I hope that this works and gains traction.  I hope so.

Start time: 7781.46
End time: 7789.86
Speaker: SPEAKER_02
Transcript:  I think one of Twitter's better features is just where it hides some of the bad replies at the  bottom. I don't know. It's vastly improved my Twitter experience.

Start time: 7790.04
End time: 7795.46
Speaker: SPEAKER_07
Transcript:  I got the new Twitter and it looks very different. It's no longer chronological or anything.

Start time: 7797.70
End time: 7821.38
Speaker: SPEAKER_08
Transcript:  They've really changed the feed.  Well, they have an option to flip over to recent tweets first, but that it only lasts a few days  and then they go back to algorithmically sorted, which is kind of, to me, it's kind of a dark  pattern. Yeah, I don't know what it's doing.  But I think clearly what people want is, many people want is reverse chronological with no  algorithm. And that's why I use TweetDeck because it still does that.

Start time: 7822.98
End time: 7838.10
Speaker: SPEAKER_02
Transcript:  Or if you do, if you pull up the mobile Twitter URL, because it doesn't, I can do the whole  display latest tweets first on my mobile app, but on desktop, I type in the mobile URL and do it  that way. A tip.

Start time: 7838.64
End time: 7852.72
Speaker: SPEAKER_07
Transcript:  A tip. I'll give you another tip if you're using TweetDeck. I exclude retweets.  And the only reason I do that is I feel like that's where you get the viral inflammation  happening. Like this sudden, all these retweets. I want to see the originals.

Start time: 7853.30
End time: 7874.32
Speaker: SPEAKER_08
Transcript:  I have a different approach to the same problem. If somebody retweets something objectionable,  I stop following the person who retweeted it. Yeah.  And so- Then you get quality retweets.  I follow like Matthew Ingram, there's a bunch of other people who are great retweeters.  That's true. I would want to see those.  I discover a lot of new Twitter users by other people's retweets. But I'm very-

Start time: 7874.40
End time: 7882.18
Speaker: SPEAKER_07
Transcript:  The real answer is we need better moderation tools for ourselves.  So that we can make our Twitter feeds better. Twitter wants to maintain the control over

Start time: 7883.00
End time: 7890.26
Speaker: SPEAKER_08
Transcript:  all that stuff. And I think, you know, give control to people, man. That's what I say.  As a boomer.

Start time: 7891.36
End time: 7988.58
Speaker: SPEAKER_07
Transcript:  I want to mention this because he was a very important person in computer science that I  thought I knew everybody and all the names in history. But I had never heard of Fernando  Corbato. Have you ever heard of him? You didn't know who your father was?  The father of your computer? The father of my computer.  He just passed away at the age of 93. Great obituary in the New York Times by Katie Hafner.  And here's why you want to remember Fernando Corbato. Before he came along, if you wanted to  use a computer, you had to print out a bunch of punch cards, a stack, carry them carefully  without letting them fall, spindle, fold or mutilate to the high priest running the computer  who would then deign to run your job. Maybe tomorrow, maybe the next day, maybe next week.  And if heaven for him, the cards had gotten mixed up or there was a bug,  you'd get them back and you'd have to start all over in this process again.  Computing was not interactive, in other words.  Corbato realized that these computers are fast enough that they could probably do something he  called time sharing. He invented in the early 60s something called CTSS, the Compatible Time  Sharing System, which allowed multiple users in different locations to access one big expensive  computer at the same time through telephone lines with teletypes. Remember that?  And without that, Bill Gates, very famously, Bill Gates' mom and other mothers at the Lakeside  School in Seattle had a cake sale to raise the money to get a time share teletype in a closet  at the school. He and Paul Allen learned to use computers to program computers with that interactive

Start time: 7988.72
End time: 7992.98
Speaker: SPEAKER_08
Transcript:  time share device. And then that all eventually led to Clippy.

Start time: 7996.41
End time: 8022.90
Speaker: SPEAKER_07
Transcript:  That's he created Clippy. The other thing though he had to invent, in order to make a time sharing  system work, you have multiple people on the same computer. At first, everybody was able to see  everybody else's stuff. He had to create accounts and passwords. So Corby also, he gets credit for  inventing time sharing. He also gets credit and true interactive computing for creating the

Start time: 8023.58
End time: 8028.08
Speaker: SPEAKER_08
Transcript:  password. And really isn't that what cloud computing is? Isn't cloud computing just time

Start time: 8028.34
End time: 8062.26
Speaker: SPEAKER_07
Transcript:  sharing? Yeah, basically time sharing, right? If you use Google Stadia, you're playing a game on a  computer in the cloud. That's right. So I think huge. CTSS gave rise to Multics, which was  a operating system which gave rise to Unix. Get it? Unix is a singular version of Multics.  And in fact, Multics was the inspiration for Linux because Linus Torvalds didn't like Multics.  He wanted to make his own version of Multics and created Linux. So Linux is what Android,

Start time: 8062.34
End time: 8068.56
Speaker: SPEAKER_08
Transcript:  etc. is based on and still Mac OS, right? Mac OS is based on Unix, not Linux. But both

Start time: 8069.00
End time: 8105.38
Speaker: SPEAKER_07
Transcript:  can be traced back to Corbato. So next time you log in and give a password, you can thank Corby,  the father of the computer and the interactive computing and the password. Hey, everybody,  thank you so much for being here. I really appreciate Caroline. You're great. You showed  amazing fortitude in not chasing that ice cream truck and I admire that. Caroline Haskins, you can  catch her work at Motherboard at Vice. She does such good stuff. I look forward to seeing your next  public information request. Look at all the stuff she covers, including rogue cyclists

Start time: 8105.52
End time: 8111.12
Speaker: SPEAKER_02
Transcript:  creating a bike lane with toilet plungers. New York City, baby. Boy, oh boy. It's a good city to

Start time: 8111.82
End time: 8138.42
Speaker: SPEAKER_07
Transcript:  live in, isn't it? Yeah, it's nice. Yeah. It's never boring. Nope. Nope. And neither is Caroline.  Thank you, Caroline, for being here. We appreciate it. She's on Twitter. Caroline, ha, underscore,  ha, c-a-r-o-l-i-n-e-h-a underscore. That's what I think. I think the underscore is the ha.  It just stops you on your tracks. That's a glottal stop. Ha. Yeah. Somebody already had Haskins.

Start time: 8138.68
End time: 8148.72
Speaker: SPEAKER_02
Transcript:  I wish I had Caroline Haskins, but I just found out. Yeah. That's good. I can't even change my  Twitter handle even if I wanted to apparently, or you lose the verification badge. Right. No,

Start time: 8149.12
End time: 8153.86
Speaker: SPEAKER_07
Transcript:  you're stuck with it now. You can give yourself a clever nickname. Just change your real name.

Start time: 8155.30
End time: 8160.01
Speaker: SPEAKER_08
Transcript:  Yeah. Yeah, true. Do you have an underscore in your legal name? Ha. Yeah, the first line of ha.

Start time: 8162.54
End time: 8176.16
Speaker: SPEAKER_07
Transcript:  Very nice. Also, Mike Elgin, who could be, Mike Elgin? Mike, A-E-L-G-A-N on the Twitter, Elgin.com.  Don't forget gastronomad.net. And I want to give a plug to Kevin, your son who is here today.

Start time: 8176.30
End time: 8180.30
Speaker: SPEAKER_08
Transcript:  Yes. He's a Silicon Valley entrepreneur in the education space. He's created something called

Start time: 8180.42
End time: 8238.10
Speaker: SPEAKER_07
Transcript:  shoe leather. No, no. No, no, no, no. Shatterbox, which is, we've talked about it before. It is so  cool to teach kids a little bit more about, see, I think one of the things parents are doing,  which I think is a huge mistake, they're teaching their kids to say please and thank you to their  Amazon Echo. I think that's a mistake. That's personifying something that is a machine. I  think more important, the kid learns it's a machine and here's what the machine does. Here's how it  works. Here's what an Echo is. And so this is a smart speaker anyone can build and program with  Google blocks. It's really, really cool. It's called Shatterbox. Now it was on Kickstarter.  You raised a bunch of money on Kickstarter in about one week. You can't, kids are pretty turned on by  this. That kid just dabbed because he built a Shatterbox. You can get one, but you have to  wait a little bit. It's going to Indiegogo next. They've used up Kickstarter. We were just talking

Start time: 8238.28
End time: 8249.84
Speaker: SPEAKER_08
Transcript:  about the privacy elements of these virtual assistants at home. This one doesn't listen  until you push the button and then no data is retained at all. Just period. And whose skills,

Start time: 8250.40
End time: 8261.50
Speaker: SPEAKER_07
Transcript:  is it Echo? Is it Google Assistant or is it your own? What is the skills?  So we worked on Mycroft.  Oh, it's Mycroft. Yeah. Mycroft is a very cool AI. Yeah.

Start time: 8262.46
End time: 8267.06
Speaker: SPEAKER_03
Transcript:  And so we essentially created a visual skill builder. So kids, all the skills are actually

Start time: 8267.18
End time: 8272.64
Speaker: SPEAKER_07
Transcript:  run locally on the device. Oh, so you get to program the skill. It's kind of like the Apple

Start time: 8272.78
End time: 8277.68
Speaker: SPEAKER_08
Transcript:  model. You keep it private and secure through just running it locally. No ads, no data collection.

Start time: 8277.88
End time: 8283.14
Speaker: SPEAKER_07
Transcript:  It isn't always listening. It's a chatterbox and you can make your own. How many have you shipped?

Start time: 8283.34
End time: 8286.44
Speaker: SPEAKER_03
Transcript:  Have you shipped them yet? No, they're going to be shipping in time for Christmas.

Start time: 8287.10
End time: 8291.42
Speaker: SPEAKER_07
Transcript:  What's the processor? Is it an Arduino? What's in there? It's actually based on Raspberry Pi.

Start time: 8291.86
End time: 8296.70
Speaker: SPEAKER_03
Transcript:  It's a Pi? Yeah. Nice. Nice. Now we're actually looking at using

Start time: 8297.20
End time: 8412.66
Speaker: SPEAKER_07
Transcript:  fours, upgrading everybody to fours. Oh yeah, those new Raspberry Pi fours are awesome.  Awesome. Yeah, you have to change your power supply.  Yeah, that's what I'm looking at. Hello chatterbox.com. Let's give you a nice big  plug because I think that's, in fact, I'm going to get one for the kids. I think that's really,  really cool. They'll love it. Yeah. Thank you, Mike. Thank you, Caroline. Thank you everybody  for being here. We had a great studio audience visiting from all over the world. You guys were  very patient. That's all I can ever say about our studio. They have bums of steel. Your fortitude  is impressive. Well, what we do is we invite them here. They sit down in the most uncomfortable  chairs we can find, and then we make them stay there for two solid hours. Tim and Nina from  Orlando and Rich from San Francisco. Mick was from Dublin. Etienne is from Paris. Rod and Carolyn,  you're going to have to pronounce it for me. Stelacum in the great state of Washington.  And Erin and Caitlin visiting. And of course, Roberto, great to have you visiting from Brooklyn.  No, Queens. Say again? Staten Island. He got here on the ferry. It goes a long way.  If you want to be in our studio audience, email tickets at twit.tv. We love having a studio  audience. It makes it so much more fun, especially when they pretend to laugh at my jokes. I really  appreciate that. It's always nice. If you want to watch live, you can do that too. We have a live  video and audio stream available at twit.tv slash live. But if you're doing that, you know,  chat because the chat room is a big part of all of our shows. They're always there at irc.twit.tv.  It's family friendly and fun. irc.twit.tv. After the fact, everything we do is available on demand.  Just go to our website, twit.tv. You can even subscribe. In fact, that's the best way to get  every show we do. Subscribe that way. The minute the show is available, you'll get it automatically

Start time: 8412.82
End time: 8425.04
Speaker: SPEAKER_08
Transcript:  on your smart device. And don't be a chicken. Subscribe to the all Twitch shows feed. There's  a feed for all of them. I subscribe to it. Are you not? Okay. Thank you. It's if you can actually,

Start time: 8425.22
End time: 8452.76
Speaker: SPEAKER_07
Transcript:  why not? Then why not? You know, you, you got a ton of stuff. You get it all there. That's right.  That's it. Sounds like a good idea. Thanks everybody. Uh, did I do anything? I do need to  do anything else. Carson body, our producer, our executive producer, the man in charge. I'm all set.  I'm done. I can go home. I can have lunch. All right. Thanks everybody. I'm going to go home  and watch the last episode of game of throng. Oh no, that's over friends, friends, friends.  Thanks everybody. We'll see you next time. Another twit.

