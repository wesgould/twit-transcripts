;FFMETADATA1
title=Miss Honeybelle
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=565
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf58.76.100
Failed to align segment (" 20%."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" 50%."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" 2014."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" $1,500."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" 2007."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" It was actually from a technological standpoint,"): backtrack failed, resorting to original...
Failed to align segment (" They have the screen that's like unbelievably tall"): backtrack failed, resorting to original...
Failed to align segment (" Because they don't have to build sets anymore."): backtrack failed, resorting to original...
Start time: 0.95
End time: 17.00
Speaker: SPEAKER_13
Transcript:  coming up next. It's time for  Twitter this week in tech.  Becky Warley and Harry  McCracken are here. We're  going to sit down and talk  about all the news, artificial  intelligence. Are we living in  a simulation? And I come off  as grumpy cat in the new kitten

Start time: 17.34
End time: 18.02
Speaker: UNKNOWN
Transcript:  wedding commercial. It's all

Start time: 18.68
End time: 125.00
Speaker: SPEAKER_13
Transcript:  coming up next on Twitter.  This is Twitter.  This is Twitter.  Bandwidth for this week in tech  is provided by Cashfly at  C-A-C-H-E-F-L-Y dot com.  This is Twitter this week in  tech. Episode 565 recorded  Sunday, June 5th, 2016.  This week in tech is brought  to you by Carbonite. Keep your  business safe this year.  Protect files on your computer  or server with automatic cloud  backup from Carbonite. Try it  free without a credit card at  Carbonite dot com today. And  use the offer code TWIT to get  two free bonus months if you  decide to buy. And by Wealth  Front. Wealth Front is a low  cost automated investment  service and the most  sophisticated way to invest  your money, whether you've got  millions or you're just  starting out. Visit Wealth  Front dot com slash twit and  sign up to get your free  personalized investment  portfolio. That's Wealth Front  dot com slash twit. And by  Stamps dot com. Start using  your time more effectively with  Stamps dot com. Use Stamps dot  com to buy and print real U.S.  postage the instant you need it  right from your desk. To get my  special offer, go to Stamps dot  com, click the microphone, and  you'll be the first to get your  free free trial. And by ITPro  TV. ITPro TV is an easy,  entertaining approach to online  IT training. For a free seven  day trial and 30% off the life  of your account, go to ITPro dot  tv slash twit and use the code  TWIT30.

Start time: 127.16
End time: 129.72
Speaker: UNKNOWN
Transcript:  It's time for TWIT this week in

Start time: 129.88
End time: 152.56
Speaker: SPEAKER_13
Transcript:  tech, the show where we cover  the week's tech news. And this  is going to, I just want to  tell you, this is going to, I  feel good, I'm already bathing  in this show. I'm soaking, I'm  basking in the glorious  refulgence of our guests today.  Becky Worley is here, my dear  friend from 20 years ago in tech

Start time: 152.92
End time: 154.99
Speaker: SPEAKER_03
Transcript:  TV, ZDTV. What was that word?

Start time: 155.88
End time: 159.34
Speaker: SPEAKER_04
Transcript:  Refulgence. That's a polysyllabic  word I'm unfamiliar with. It's

Start time: 159.92
End time: 165.19
Speaker: SPEAKER_13
Transcript:  only three. Refulgence. It's the  glow, the glow really. Just  bathing in the glow. That would

Start time: 165.84
End time: 181.52
Speaker: SPEAKER_04
Transcript:  be a problem. I'm sorry to say  it. No, but hey, I already  learned something. I'm just, I  am serious, I'm so excited about  the show this week because  there's an amazing amount of  tech news that needs to be  analyzed and I really want to

Start time: 181.88
End time: 184.72
Speaker: SPEAKER_13
Transcript:  hear what you two big brains  have to say. You came in

Start time: 184.88
End time: 186.42
Speaker: SPEAKER_04
Transcript:  bouncing with excitement. I am.

Start time: 186.88
End time: 211.32
Speaker: SPEAKER_13
Transcript:  Which is awesome. It's a great  news week. Awesome. Also here,  if you have a great news week,  Harry McCracken's a great guy to  be here. Great to be here. Great  to be here with Becky. What's  nice is it's kind of, I don't  know, first of all it's friends  talking but also smart friends  who have great insight and I  thought we should probably  start, actually Becky thought,  we should probably start with

Start time: 211.94
End time: 225.95
Speaker: SPEAKER_04
Transcript:  artificial intelligence since  we're so smart. Does it feel  like we need the artificial,  well I do, intelligence? No, but  the era has begun. I feel like  there was a crescendo this week  and we had sort of bots and  Microsoft bringing this in and

Start time: 226.94
End time: 311.79
Speaker: SPEAKER_13
Transcript:  piece by piece. Facebook did  their bots but then all of a  sudden Google at I.O. Right.  Announces we've been doing  machine learning. They like to  call it machine learning. And we  are going to start in, so I'll  tell you, we can kick this off  with the interview I did on  Monday with Kevin Kelly. You  know Kevin Kelly. He started  Wired, the whole electronic  world. He's talking about  artificial intelligence and  machine learning. He says when  you get a new technology, it  kicks off innovation in an  interesting way. He said when  electricity became widespread  in the U.S. farmers would do  things like hey there's my hand  pump for water. What if I  applied electricity to that and  an invention comes out of that.  We've seen that with the  internet too. What if I take a  magazine and let's just add a  little bit of water. What do we  have? He says we're in the era  now where this is going to  start happening with AI. You're  going to start seeing AI applied  to all sorts of things and you're  going to get all sorts of  massive innovation around it.  But he says there's all, you  know, a lot of times we think of  AI, we think of a human like  mind. And he actually had a list  of all kinds of minds that would  be appropriate. You know, you  don't think of Alexa as a human  like mind. It's simple. But it's  not a timer for cooking. It's  a timer for time instead of

Start time: 312.80
End time: 320.58
Speaker: SPEAKER_04
Transcript:  timer for cooking that are very  useful.  How do you define artificial  intelligence, Harry? Do you have  a sense of it in your mind of

Start time: 321.31
End time: 350.62
Speaker: SPEAKER_10
Transcript:  what it is at its narrowest  definition?  I think it's super amorphous  because in the old days you  defined it as thinking like a  human. And a lot of the stuff  that's interesting today is not  all that human like. I think in  terms of probably the technology  that people use to build it, they  are building technologies that  work a little bit more like the  human brain.  I'm going to get his book.  You're not necessarily trying to  build something that can do all  the things a human brain can do.  In a lot of cases you're building  technology to do one thing really  quickly such as look at  photographs and identify the

Start time: 350.86
End time: 360.11
Speaker: SPEAKER_04
Transcript:  objects in that photograph.  So make decisions that we would  have maybe thought of as  subjective and only human, that  only humans were capable of in  the past.

Start time: 360.56
End time: 377.39
Speaker: SPEAKER_10
Transcript:  Well, they're fuzzier. They're  fuzzier things. Like in the old  days we thought of computers as  making decisions like a flow  chart. Very binary.  If then.  If you look at the graph and  you're looking to see whether  there's a car in it, that is not  something you can flow chart.  That's a fuzzy decision because  the car could be any car at any  angle in any lighting.

Start time: 377.94
End time: 392.37
Speaker: SPEAKER_04
Transcript:  And it also seems like now that  we have so many devices that can  handle human language processing  that we can see AI in a more  transparent way and it's become  more realistic and possible in  people's minds.

Start time: 393.29
End time: 423.70
Speaker: SPEAKER_10
Transcript:  It's everywhere.  I mean it's in a lot of places  where you don't even particularly  notice it's there but it is.  I really feel like it's the next  big sea change.  Yeah.  In the 80s you had the PC and  that wiped away most of the  computer companies that existed.  Ten years after that you had the  web that wiped away most of the  PC companies.  Then you had mobile that wiped  away the phone companies.  Right.  And I feel before very long you  will have companies that nail AI  and survive and companies that  don't figure out how to deal with  AI and maybe go away or at least  they're nowhere near as relevant  as they once were.

Start time: 423.94
End time: 437.93
Speaker: SPEAKER_13
Transcript:  If you were going to throw cold  water on all of this though, you  could point out that the idea of  AI is fairly old.  That's ancient.  Going back to Marvin Minsky.  Right.  And it was really a failed idea,  right?  Why didn't AI take off in the  earliest days of its...  Yeah, I mean I tweeted this idea

Start time: 438.72
End time: 443.58
Speaker: SPEAKER_10
Transcript:  that it's going to change  everything and...  You've been saying that for  decades.

Start time: 443.70
End time: 445.32
Speaker: SPEAKER_13
Transcript:  Michael Johnson from Pixar said

Start time: 445.72
End time: 456.58
Speaker: SPEAKER_10
Transcript:  we thought that in the 1980s and  it didn't happen and my thought  was maybe it is changing  everything.  It's just happening really  slowly.  Yeah.  But it really is paying off.  And it may be a hockey stick.

Start time: 456.96
End time: 473.99
Speaker: SPEAKER_13
Transcript:  I mean a lot of what we see is  hockey stick.  In other words, it's exponential  growth so it's slow, slow, slow,  slow, fast.  And that happened certainly with  processors.  They initially were very dumb,  very slow, very limited, but when  they took off, they really took  off and that's Moore's Law,  right?

Start time: 474.82
End time: 500.52
Speaker: SPEAKER_04
Transcript:  Yeah, I think it's also...  I think it was Sundar Pichai, I  listened to so many people this  week who was saying that there  are three things that have come  to a nice crossing point which  is computational power,  the amount of data that we now  have.  And then I think the third might  have been natural language  processing but there was a third  pillar that he had that listed.  It's like it's a nexus and that  we've gotten to that point where  now everything can take off.

Start time: 500.72
End time: 575.46
Speaker: SPEAKER_13
Transcript:  Let me read to you.  I went and ran and got Kevin's  book.  It's called The Inevitable.  It comes out this week.  He says it's silly to think of it  as human minds.  He says there could be a mind  like a human mind but it's faster  in answering.  That's the easiest AI to open.  That's the easiest AI to imagine.  But what about a very slow mind  composed primarily of vast  storage and memory?  Or what about a global super mind  composed of millions of dumb  individual minds in concert?  That's...  Kevin's a guy who came up with a  hive mind.  That sounds like his hive mind.  How about a mind trained and  dedicated to enhancing your  personal mind but useless to  anybody else?  Right?  Or a mind capable of successfully  making a better mind once.  You know, I mean, that's the  point is to be creative.  We don't have to assume it's  going to look like us.  And I think we often do with  artificial intelligence.  And that's where it's a failure.  Where you say, well, but can it  appear to be human?  That's I think the Turing test  and I think that that's maybe a  limited, very limited way of  thinking of AI.  It's incredibly limited.  Yeah.  Yeah.  And so if you have a broader  definition of it, you can see it  everywhere.  Somebody's pointing out in the  chat room, Alexa had 135 skills  in January, has a thousand  skills in January.

Start time: 575.64
End time: 593.91
Speaker: SPEAKER_04
Transcript:  This week.  Let me just run through.  This is just some of the things.  So you guys jump in here as I go  through.  I'm going to jump in on this is  some of the things that happened  in AI this week that that were  sort of brought to the forefront.  So Facebook says for the first  time, AI is doing more content  monitoring than humans.  That's a that's a little bit of  a tipping point.  That's a tip.

Start time: 594.58
End time: 604.74
Speaker: SPEAKER_13
Transcript:  But that may be Facebook's.  Remember, Facebook's the one  who's denied there were human  curators and finally had to  admit it.  They may prefer that you think  that it's all AI, right?  Right.

Start time: 605.60
End time: 687.07
Speaker: SPEAKER_04
Transcript:  And that they're all perfectly  in the middle of the blue red  spectrum.  OK.  Jeff Bezos, he's he said at the  Code Conference that artificial  intelligence is in such early  days that they made the baseball  analogy.  Not only is it the first inning,  he thinks it's the first guy at  bat.  So he really sees this as early  days.  Sundar Pichai also said early  days.  Melinda Gates, also at the Code  Conference, said all the books  Bill is reading are about AI.  He said Bill Gates, he sees two  problems.  Loss of jobs.  Who controls the AI?  Making sure people stay in  charge.  Right.  Now, we'll get back to that  because that's the Elon Musk  story is incredible on that on  that realm.  Let's go into the details,  though.  Sundar Pichai talking to Walt  Mossberg and Kara Swisher said  I thought this was interesting.  I want to hear what you guys  say.  His sense of AI was so different  than the other two.  I think the sense of AI was so  different than everyone else  who was talking about it in the  global and in the sort of  speculative.  It was really literal in like  what are they doing, here are  the specifics where Google is,  and it made me realize that  without bragging too much, I  mean, he did say their AI is  better than everyone else's, but  they're really in the details.  They're not in the huge  overarching view.

Start time: 688.46
End time: 700.89
Speaker: SPEAKER_13
Transcript:  That's what tech is, though,  isn't it?  Is that the people who are  making the tech are often very  busy in the weeds and maybe  nobody is even looking at the  larger implications of it.  They're so busy solving  problems, specific problems.

Start time: 702.78
End time: 713.10
Speaker: SPEAKER_04
Transcript:  Well, I think it's, yeah, the  guys who are actually doing  that, and maybe that's why I  haven't, I feel like in some  sense this is just me when I  really pay attention, I see  bigger trends.  Right.

Start time: 713.52
End time: 722.14
Speaker: SPEAKER_13
Transcript:  Well, that's kind of our job  since we can't be in the weeds  solving problems, at least we  can be at 30,000 feet looking  down and saying hey, something  to think about here.  There are a lot of big brains

Start time: 722.95
End time: 723.94
Speaker: SPEAKER_04
Transcript:  doing that right now.

Start time: 724.40
End time: 735.52
Speaker: SPEAKER_13
Transcript:  Of course, that's what AI.org  was kind of all about, right?  That's Elon, who else got  involved?  Is this OpenAI?  Oh, OpenAI, yeah.  Yeah.  .org.

Start time: 737.04
End time: 737.16
Speaker: SPEAKER_04
Transcript:  Okay.

Start time: 737.48
End time: 757.22
Speaker: SPEAKER_13
Transcript:  So let's...  The idea was no one company  should own this.  It should be part of, and  everybody should weigh in on  this, and it should be  available, more importantly  maybe even from their point of  view, it's OpenAI.com, it  should be available to  everybody.  They're a nonprofit, but they  are funding research and  funding it big time.

Start time: 757.36
End time: 768.94
Speaker: SPEAKER_04
Transcript:  Well, let's get into that  because that, I think, is what  really...  I mean, my mind felt like it was  exploding listening to Elon talk  for an hour and a half about  artificial intelligence.  Harry, what did you take away  from that conversation?

Start time: 770.07
End time: 810.10
Speaker: SPEAKER_10
Transcript:  Well, I mean, a whole lot, and  he talked about there being a  company that scared him, but he  wouldn't say what it was.  It's got to be Facebook, right?  Well, the one thing that does  scare me about AI is the  privacy implication.  Right.  And essentially, for good AI,  you want a server on the other  end to be able to do anything  and everything with your data,  and for privacy, you want end-to-  end encryption, which  essentially makes AI...  It's the opposite.  ...impossible.  Yeah.  And the world is going to have to  decide what it wants, and I  really hope that it's not  Facebook that decides on its own  without any input from its  users.  Facebook's going to get a lot

Start time: 810.67
End time: 814.98
Speaker: SPEAKER_13
Transcript:  of competition, though.  I mean, Bezos at Recode said  there are 1,000 people at Amazon  working on it.

Start time: 815.14
End time: 830.17
Speaker: SPEAKER_10
Transcript:  Amazon has 1,000 people.  Amazon has nowhere near as much  data about people as Facebook.  Who has the most?  Facebook and Google.  Facebook and Google.  And really, and Apple, except  Apple, has been saying that  they're opting out of this, and  they don't want to use your  data, and they want to encrypt  everything.  I feel like that's a...

Start time: 831.20
End time: 831.78
Speaker: UNKNOWN
Transcript:  I don't want to say

Start time: 832.52
End time: 846.86
Speaker: SPEAKER_13
Transcript:  disingenuous of Apple, but  clearly they're collecting and  using your data.  Maybe really all their...  Ultimately saying is we're just  not going to give it to a third  party, but clearly Apple is.  A lot of the stuff that they do  would work, right?  Well, I'm fascinated that you

Start time: 847.00
End time: 853.12
Speaker: SPEAKER_04
Transcript:  think it's Facebook he was  referring to.  Who do you think it was?  Well, can we listen to the clip  because the context is actually  really important.  Okay.

Start time: 853.98
End time: 856.66
Speaker: SPEAKER_13
Transcript:  Here's Elon Musk at the  Recode conference.

Start time: 860.27
End time: 889.91
Speaker: SPEAKER_07
Transcript:  And the intent with OpenAI is to  democratize AI power.  There's a quote that I love from  Lord Acton.  He was the guy that came up with  power crufts and absolute power  crufts, absolutely, which is that  freedom consists of the  distribution of power and  despotism in its concentration.  And so I think it's important if  we have this incredible power of  AI that it not be concentrated  in the hands of a few and  potentially lead to a world that  we don't want.  And what world is that?  What do you foresee that when you

Start time: 892.09
End time: 894.74
Speaker: SPEAKER_00
Transcript:  see it?  It's called the singularity

Start time: 894.86
End time: 912.62
Speaker: SPEAKER_07
Transcript:  because it's difficult to  predict what's going to happen  and it's difficult to predict  exactly what future that might  be, except I don't know a lot of  people who love the idea of  living under a despot.  You know, I don't think people  generally choose to live in a  democracy over a dictatorship.  And the despot would be the

Start time: 912.88
End time: 914.56
Speaker: SPEAKER_09
Transcript:  computer?  Or the people controlling the

Start time: 915.61
End time: 916.01
Speaker: SPEAKER_07
Transcript:  computer.

Start time: 918.51
End time: 930.46
Speaker: SPEAKER_09
Transcript:  And do you worry specifically  about any of these companies I  mentioned who've all seemed to  now kind of...  Now kind of be pivoting toward  this as the battleground in the  next ten years?

Start time: 930.76
End time: 932.68
Speaker: SPEAKER_07
Transcript:  I wouldn't name a name, but  there is only one.  Hmm.

Start time: 933.62
End time: 941.15
Speaker: SPEAKER_09
Transcript:  There's only one you're worried  about.  So I'd say there's two.  And they're not...  At least Google.  I would make a car that will  compete with you, I assume.

Start time: 943.45
End time: 945.50
Speaker: SPEAKER_13
Transcript:  There's only one.  Maybe he's worried about Apple.

Start time: 945.62
End time: 960.13
Speaker: SPEAKER_04
Transcript:  That's because, you know, that  conversation had come from with  Walt talking about Apple and  Elon was very confrontational  as...  I mean, never has anyone  sounded so bored talking about  such amazing things.  He's thoughtful.

Start time: 960.62
End time: 962.28
Speaker: SPEAKER_13
Transcript:  He's not bored, he's thinking.  Right, but it was like so

Start time: 963.15
End time: 965.38
Speaker: SPEAKER_04
Transcript:  mellow and monotone that...  Here's why he's worried about

Start time: 965.56
End time: 967.36
Speaker: SPEAKER_13
Transcript:  Apple, if it is Apple.  Right, so he was saying that

Start time: 967.52
End time: 969.36
Speaker: SPEAKER_04
Transcript:  Apple...  Because Apple's secret.

Start time: 969.50
End time: 975.93
Speaker: SPEAKER_13
Transcript:  And Apple does what it's doing  in secret.  And at least with Google, maybe  less so with Facebook, you know,  they're kind of being open about  what they're up to.

Start time: 976.58
End time: 987.82
Speaker: SPEAKER_10
Transcript:  Facebook's pretty open about it.  I mean, I visited their AI labs.  I did a big story on Facebook at  the end of last year in a large  chunk of that was their AI stuff.  They also published a lot of  their research.  I have to say, I don't...

Start time: 989.38
End time: 1017.55
Speaker: SPEAKER_13
Transcript:  If it is Apple, I disagree with  Elon.  I think you should worry more  about Apple if you're a global  fashion brand, if you're an AI  developer.  Apple seems to have changed their  tune quite a bit.  You don't ever, by the way,  rarely do you hear the words  Apple and AI together.  And all you have to do is look  at their one AI product, Siri,  and say, well, that's not very  scary.  Do you think they've got a lab  somewhere that...  They can't opt out entirely, but

Start time: 1018.30
End time: 1045.63
Speaker: SPEAKER_10
Transcript:  I mean, Tim Cook has had this  drumbeat of how we're not going  to use your data.  We don't want to store it on our  servers.  Other companies that do that, you  should be concerned about.  So at some point, Apple's going  to have to figure out a way to  live the life it wants to live,  but also address some of the  stuff, because I think if you  want to set up scenarios where  Apple is bleeding, you have to  set up scenarios where Apple is  blown away.  It's where the sea change  happens.

Start time: 1046.14
End time: 1048.39
Speaker: SPEAKER_13
Transcript:  They've opted out, and they may  have painted themselves into a  corner.

Start time: 1049.71
End time: 1061.63
Speaker: SPEAKER_10
Transcript:  Right.  I do find it odd that he talks  about despotism, given that you  can opt out of Facebook.  You don't have to use Google  services.  It's a little bit different than  if the person running your  country suddenly decides that  he's going to tell you exactly  what to do.

Start time: 1062.14
End time: 1067.84
Speaker: SPEAKER_04
Transcript:  I don't feel like you can opt  out of Google if you're a real  human.  I mean, who's, like, living a  day-to-day life.

Start time: 1068.18
End time: 1074.49
Speaker: SPEAKER_10
Transcript:  It would be tough, but it would  not be impossible.  And if they ever do anything  terrible, millions of people  could opt out of using Google.  Fair enough.

Start time: 1075.04
End time: 1094.88
Speaker: SPEAKER_04
Transcript:  So, okay, so you made the case  for potentially Facebook why  probably it's not Apple.  The other player would have to  be Google.  Google.  What would be his fear or  concern?  How would they play into that  just because of the sheer  amount of data they have on you  in every facet of your life?  Here's the thing that would

Start time: 1095.02
End time: 1101.43
Speaker: SPEAKER_13
Transcript:  make, if I were scared of  Google, it would make me scared  is that they have shown no  reluctance to use these  technologies, right?

Start time: 1101.96
End time: 1112.60
Speaker: SPEAKER_10
Transcript:  And Google controls a phone  full of sensors, which Facebook  doesn't do.  So Google has way more  opportunity than Facebook does  in some respects to track where  you are and what you're doing.

Start time: 1112.96
End time: 1113.60
Speaker: UNKNOWN
Transcript:  Okay.

Start time: 1114.57
End time: 1129.60
Speaker: SPEAKER_04
Transcript:  This is, I don't, we know we're  going to talk about this later,  but you were talking about it  on This Week in Google about  how when they bought Nest, they  didn't want to put a microphone  into it to make it the home  assistant because they didn't  want people to think that it  was the home assistant because  they didn't want people to

Start time: 1129.78
End time: 1174.08
Speaker: SPEAKER_13
Transcript:  think what are they doing with  that.  Right.  Google is very aware of their  public persona as being,  everybody thinks Google is going  to do Skynet, right?  That Google is creating  Skynet, the Terminator  computer that sent the machines  after us.  And so there's one candidate for  Skynet, right, at this point,  isn't it?  It's Google.  Although I'm a little more  nervous about Facebook.  Did you read the article in  Vanity Fair this week from a  book by a former Facebook  employee who is so close to  supposedly blowing the lid off  Facebook and he talks about  Mark Zuckerberg is being very  nearly psychopathic in his drive  to win at all costs.  I didn't find it a damning  article after reading it.  I mean, the lead talks about  Jim Jones and Jonestown and the

Start time: 1174.78
End time: 1190.48
Speaker: SPEAKER_10
Transcript:  actual story is just that he's  incredibly ambitious and pushes  people who work for him to be  incredibly ambitious and to  work, work, work, work, work,  work, work, work, work, work,  work, work, work, work, work,  work, work, work, work, work,  work and Google maybe is at  least a tiny bit more mellow  than Facebook.

Start time: 1191.45
End time: 1197.54
Speaker: SPEAKER_04
Transcript:  So the lighthouse has turned  off of Amazon in this realm.  The eye of Mordor.

Start time: 1197.66
End time: 1199.14
Speaker: SPEAKER_13
Transcript:  Amazon has a lot of data on us

Start time: 1199.82
End time: 1202.54
Speaker: SPEAKER_10
Transcript:  but it's very specific to the  things we like to buy.

Start time: 1202.74
End time: 1220.97
Speaker: SPEAKER_04
Transcript:  I just meant the work culture  and the whole idea that Bezos  was this taskmaster that  created a sort of a thunder dome  work environment where it's  kill or be killed.  And so it was interesting that  that seems to be a story that  resonates and they're looking  for a new victim every six  months.  I've seen that story about a  lot of companies.

Start time: 1221.74
End time: 1229.40
Speaker: SPEAKER_13
Transcript:  Is Facebook listening to you  via your smartphone?  You saw that story this week  which I think was somewhat  debunked.  I mean just reading that you

Start time: 1229.54
End time: 1233.79
Speaker: SPEAKER_10
Transcript:  could tell that it was just all  theory.  Yeah.

Start time: 1234.54
End time: 1362.70
Speaker: SPEAKER_13
Transcript:  Although there was an article a  few months earlier in the BBC  actually it's kind of an  interesting article in which he  says I was, let me see if I can  find it.  I just read it the other day  even though it came out I think  in January or no March.  Is your smartphone listening to  you?  This is Zoe Kleiman so I  shouldn't say he, her.  I was doing some ironing when my  mum came in to tell me my family  friend had been killed in a  road accident in Thailand.  My phone by the way was on the  worktop behind me.  The next time I used the search  engine on it up popped the name  of our friend in the words  motorbike accident Thailand and  the year in the suggested text  below the search box I was  startled, certain I had not used  my phone at the time I had had  the conversation.  Was the phone listening to me?  We've heard a lot of anecdotal  stories over and over again by  people who think that their  echo or their phone is somehow  monitoring and changing search  results or shopping  recommendations based on  conversations they're having.  Certainly there's no way to  prove that it's not doing that.  In fact in this article she says  she went to a pen testing  company, Ken Monroe and David  Lodge from Pentest Partners and  said can you write something, an  app for an Android device that  would listen in and collate what  I said and would it be detectable?  So they actually did create a  prototype app, demonstrated its  functionality.  He said in order to use this app  of course you have to have  permission to use a microphone  although many apps do.  If you're going to talk to an  app you need to have that  permission.  They said we had to set up a  listening server on the  internet and they said we had  to set up a listening server on  the internet and everything that  microphone heard on the phone  wherever it was would come back  and we could say send it  customized ads.  He said the battery drain, this  is the key, would you notice it?  The battery drain was minimal.  That would be one way you'd  notice it.  And using Wi-Fi you didn't see a  real data plant spike.  So it's, I mean I would imagine,  I would hope there's hackers and  pen testers out there who are  running Wireshark from time to  time on their devices to make  sure it's not and Google of  course denies it.

Start time: 1362.96
End time: 1377.60
Speaker: SPEAKER_04
Transcript:  I'm going to sound so naive but  I just don't have enough  conspiracy theory in my soul to  believe that the companies would  do this without having it  explicitly in their terms of  service.  But what's to stop Amazon from

Start time: 1377.96
End time: 1389.28
Speaker: SPEAKER_13
Transcript:  getting a national security  letter from the FBI saying could  you turn on Leo's echo just for  the time being and we'd just  like to listen in and by the  way this is a national security  letter so you can't tell Leo  or anybody else.

Start time: 1391.05
End time: 1422.02
Speaker: SPEAKER_04
Transcript:  If they had a...  I'm sure they have the means.  Oh, I mean what difference is  that theoretically than search  results?  I mean yes of course if you  could get the paradigm there  that it's akin to that, would it  fall under different legal  purview because it's a bug or  is it...  It's a feature.  Are you kidding?  No, I don't mean a bug like a  bug in the software.  I mean it's a bug in your  house.

Start time: 1422.82
End time: 1435.41
Speaker: SPEAKER_13
Transcript:  A bug in your house.  Yeah, well of course they'd have  to get a court order.  That's why it's a national  security letter.  They get the FISA court which by  the way has never turned down a  request in the last two years of  thousands of requests.  They've said yes to every one of  them so that's not so much of a  prediction.

Start time: 1435.84
End time: 1441.00
Speaker: SPEAKER_04
Transcript:  Even without any  conspiratorial thoughts in my  being I do see that as a  possibility.  Yeah.

Start time: 1441.82
End time: 1464.44
Speaker: SPEAKER_13
Transcript:  So we're going to take a break.  Come back.  Let's talk more about AI and as  long as we're talking about AI  let's talk about Elon.  Let's talk about Elon.  Let's talk about Elon and his  suggestion that it's a, it's the  chances are a billion to one  that we are all living in a  simulation.  Not one in a billion, a billion  to one.  Oh and don't forget neural lace.

Start time: 1464.70
End time: 1471.74
Speaker: SPEAKER_04
Transcript:  We've got to talk about neural  lace.  I don't know what that is but  we'll talk about it.  I showed it in Pride TV.  It's not a fashion.  It's not a fashion statement?  No.

Start time: 1472.95
End time: 1576.99
Speaker: SPEAKER_13
Transcript:  Neural lace.  Hmm.  No, don't go Googling that.  Our show today brought to you by  Carbonite Online Backup.  You've got to keep your business  safe and as you know if you  listen to any of our shows  Ransomware is on the uptick.  Hundreds of millions of dollars  spent by businesses, not just  businesses, hospitals, law,  Massachusetts Police Department  that got bit by Ransomware and  paid the fee to unencrypt their  computers.  If they just had Carbonite, for  crying out loud you've got to  wonder what kind of IT you put  in there.  What kind of IT department this  hospital had?  Look, you don't need an IT  department.  You can have the best backup  solution that will protect you  against Ransomware right now  for less than you'd imagine at  carbonite.com.  Why take the risk?  Why worry about downtime?  They've got Carbonite for home,  for office, for Macs, for PCs,  for servers.  More than 500 billion files have  been backed up.  More than a million and a half  homes and businesses use  Carbonite.  They have restored 50 billion  files.  That's 50 billion files.  That's almost forever if it  weren't for Carbonite.  And yes, it does protect you  against Ransomware because  Carbonite on Windows does  versioning.  That means if you get bit by  Ransomware, you don't catch it,  it starts encrypting your files.  Okay, first thing to do, stop  the Ransomware, then restore  your unencrypted files from  Carbonite because they have  versioning.  You can even go back a couple of  versions until that file is  unencrypted.  Try it today free, no credit  card needed, but do use our  name, twit, in the offer code,  T-W-I-T, and that way you'll  get two free bonus months if  you decide to buy.  You got to back it up to get it  back.  Do it right with Carbonite.  Becky Worley is here from GMA.  I didn't say what you're from.  You're from GMA.  I'm from your past.

Start time: 1577.44
End time: 1578.20
Speaker: SPEAKER_04
Transcript:  You're from my past and my

Start time: 1578.40
End time: 1590.20
Speaker: SPEAKER_13
Transcript:  future, I hope.  Yes.  Becky was the founding member  of Tech News Today.  Thank you for setting that on  its track.  That's right.  I'm back regularly.  She's a regular every other  week, right?  Yeah, that's right.

Start time: 1590.38
End time: 1590.93
Speaker: SPEAKER_04
Transcript:  Love having you.

Start time: 1591.48
End time: 1594.41
Speaker: SPEAKER_13
Transcript:  And how often are you on  GMA these days?  Once a week, twice a week.

Start time: 1595.30
End time: 1596.04
Speaker: SPEAKER_04
Transcript:  Are you still doing the

Start time: 1596.22
End time: 1597.02
Speaker: SPEAKER_13
Transcript:  consumer stuff?

Start time: 1597.63
End time: 1625.96
Speaker: SPEAKER_04
Transcript:  Consumer.  Did some interesting things.  This week talked about Amazon  suing some of its reviewers,  the people who buy, fake  reviews.  We can talk about that.  That was kind of interesting.  Yeah, I do, I was thinking  about it.  If you guys, here's the  analogy in terms of what you  do for a living versus what I  do for a living as a consumer  reporter.  Let's imagine that we're all  working in the fashion  industry and you are setting  up the windows of the world  and you are setting up the  windows at Barneys or you're  creating a layout.

Start time: 1626.10
End time: 1627.92
Speaker: SPEAKER_13
Transcript:  By the way, my lifetime dream.  Oh, okay, we'll make that

Start time: 1628.76
End time: 1656.84
Speaker: SPEAKER_04
Transcript:  happen in some reality for you.  You're setting up the windows  in Barneys, you're styling a  shoot for Vogue.  That's the way that your work  goes around technology.  Me, I'm folding the pajamas in  the center of Costco, okay?  I'm putting the dungarees out  there.  Somebody's got to do it.  I am with all my people in the  everyday consumer and  technology is a huge part of  that, but I love it.  I love it.  I think it's helpful to a lot of  people.  I'm going to completely derail

Start time: 1657.18
End time: 1671.68
Speaker: SPEAKER_13
Transcript:  this show.  Oh, no.  Since you mentioned folding  clothes.  Did you see the Kickstarter?  No.  There's a Kickstarter for a  clothing, automatic clothing  folding machine.  No way.  Oh, my God.

Start time: 1672.47
End time: 1672.86
Speaker: SPEAKER_04
Transcript:  That would be...

Start time: 1673.51
End time: 1684.68
Speaker: SPEAKER_13
Transcript:  Is this it?  Wait a minute.  It's called the Foldy Mate.  Is that right?  Foldy Mate?  It's the miracle fold.  Apparently, when I Googled this,  there's more than one.  Wow.  These days there's more than one

Start time: 1684.90
End time: 1689.58
Speaker: SPEAKER_10
Transcript:  of anything you could on  Kickstarter.  Anything good.  Why is Gap not funding that?

Start time: 1689.86
End time: 1690.62
Speaker: SPEAKER_04
Transcript:  There's thread stacks.

Start time: 1690.86
End time: 1695.68
Speaker: SPEAKER_10
Transcript:  Is that what you're talking about?  Wow.  Thread stacks organized your  closet.  No, no, no, no, no, no.

Start time: 1695.94
End time: 1698.99
Speaker: SPEAKER_13
Transcript:  This is a machine.  It's the funniest video ever.  It's like full Rosie the robot.

Start time: 1700.86
End time: 1702.72
Speaker: SPEAKER_04
Transcript:  Yeah, it sounds like that in

Start time: 1702.86
End time: 1704.94
Speaker: SPEAKER_13
Transcript:  principle until you see the  video.  Oh.

Start time: 1705.86
End time: 1707.70
Speaker: SPEAKER_08
Transcript:  And then you read the

Start time: 1708.00
End time: 1770.52
Speaker: SPEAKER_13
Transcript:  video and then you realize,  is this it?  Yes, yes, Foldy Mate.  They're taking preorders for  next year, so it's not on  Kickstarter.  Wow.  So you've been here, the kids,  you're trying to fold, and the  kids are just throwing the  clothes in the air, and it's one  step forward, two steps  backward.  Well, enter the Foldy Mate.  Oh.  Yeah.  See, Mom just takes her clothes  and clips them into the special  Foldy Mate device.  Wow.  Okay.  And then watch what happens.  The clothes are sucked in to the  Foldy Mate where the mechanical  Foldy Mate arms will not only  automatically fold and smooth  your fabric, but spray it with  deodorizer.  Whoa.  And then, oh, and even steam it  for de-wrinkling.  Oh, de-wrinkling.  Yeah, very important.  And then at the end of the day,  the kids help too because it's  so much fun.  Oh, gosh.  So fun.  Yeah, and Dad's just sitting  there going, what the what?  And then the tray's full, but  look.  It spits out 12 perfectly

Start time: 1770.74
End time: 1771.27
Speaker: SPEAKER_03
Transcript:  folded T-shirts.

Start time: 1771.82
End time: 1783.60
Speaker: SPEAKER_13
Transcript:  I completely derailed this.  And it's only $37,000.  Yes, and it takes an hour.  They don't really, 700, 850.  They don't, that's the Target  price, by the way.  Right.  They obviously haven't built it

Start time: 1783.80
End time: 1785.62
Speaker: SPEAKER_04
Transcript:  yet.  That'll be on GMA next week.

Start time: 1786.05
End time: 1787.44
Speaker: SPEAKER_03
Transcript:  Thanks, guys.  Appreciate you.

Start time: 1787.88
End time: 1790.62
Speaker: SPEAKER_13
Transcript:  So you really are actually in the  bag of Costco folding clothes.

Start time: 1790.76
End time: 1791.65
Speaker: SPEAKER_10
Transcript:  Does it do socks and underwear?

Start time: 1793.20
End time: 1803.17
Speaker: SPEAKER_04
Transcript:  Those don't need to be folded.  Yeah, right.  I'm such a guy because I'm the  kind of person who always has  to buy the right socks.  You know, you only buy one color  sock and like 20 or 30 of them  so that you just, it doesn't  matter what you...

Start time: 1803.80
End time: 1814.33
Speaker: SPEAKER_13
Transcript:  That's really smart.  What do you need colors and  socks for?  Please.  Come on.  I know.  Actually, oh, I shouldn't tell  you this story.  I'm going to though.  You know when I say that.

Start time: 1814.84
End time: 1819.37
Speaker: SPEAKER_03
Transcript:  I'm going to.  I just had a moral dilemma.  Do I tell him not to tell the  story or do I let him tell the  story?

Start time: 1819.78
End time: 1867.48
Speaker: SPEAKER_13
Transcript:  If you were my producer, you  would say.  Don't tell them.  So I'm reading no, what was the  book about the, by the C-seal  Team Six and the killing of  Osama Bin Laden.  It was called No Bad Day, No Good  Day, something like that.  Mark Bessonet, the guy who got  in trouble because he's the guy  who was on C-seal Team Six that  killed Bin Laden.  But there was a detail in the  book.  Now everybody's paying  attention to how they arm  themselves, their strategies  for getting in, how they found  Bin Laden, how they got him.  I'm reading long and I hear, I  read and we looked in his  clothing drawer and all of his  T-shirts were rolled up and I  thought, wait a minute, that's  a great idea.  So that's my takeaway.  The Bin Laden technique.  The Bin Laden technique.  So I, the T-shirts, fold them in  half, roll them up.

Start time: 1867.78
End time: 1870.38
Speaker: SPEAKER_03
Transcript:  Wow.  Life hack.  Works great.

Start time: 1871.33
End time: 1872.32
Speaker: UNKNOWN
Transcript:  From Bin Laden.

Start time: 1872.62
End time: 1874.93
Speaker: SPEAKER_03
Transcript:  This is what I get.  This is what I get from that

Start time: 1875.89
End time: 1882.87
Speaker: SPEAKER_13
Transcript:  whole book.  Oh, I could learn how a seal  team trains.  No.  How Osama Bin Laden folded his  T-shirts.

Start time: 1883.62
End time: 1884.40
Speaker: SPEAKER_10
Transcript:  That's from Osama.

Start time: 1884.78
End time: 1892.50
Speaker: SPEAKER_13
Transcript:  Thank you, Osama.  No, no thanks.  I'm sure that he didn't invent  it.  Let's get back to artificial  intelligence.  Oh, and you said I was here but

Start time: 1892.64
End time: 1896.05
Speaker: SPEAKER_04
Transcript:  you didn't say Harry's here.  Tell this guy's Harry's here.  Oh, Harry's here too.  Harry's here.

Start time: 1896.62
End time: 1898.40
Speaker: SPEAKER_13
Transcript:  I am Harry's here.  The Technologizer.

Start time: 1898.70
End time: 1919.36
Speaker: SPEAKER_10
Transcript:  Do you still use that?  I am, technologizer.com points  to my Flipboard magazine where  I put in...  You shouldn't throw it out.  I put in my own stuff.  It's a good brand.  I put in stuff I find interesting  on the web, so yeah.  Don't throw it out.  Keep it.  It's a curated experience  rather than me creating a lot of  new stuff.  But you can read him at Fast  Company.com.  All my Fast Company stuff is also  on my Flipboard.

Start time: 1919.64
End time: 1925.25
Speaker: SPEAKER_13
Transcript:  People get mad at me.  I call you the Technologizer.  They say, oh, he's not that  anymore.  I say, no, no, Harry's always...  I will always be.

Start time: 1925.62
End time: 1927.42
Speaker: SPEAKER_03
Transcript:  You will always be.  Epitaph.

Start time: 1927.66
End time: 1978.14
Speaker: SPEAKER_13
Transcript:  At least in your eyes.  I have very limited memory, so I  have to just put you in a box  and keep you there.  I like being the Technologizer.  You're basically rolled up in my  T-shirt, Doris.  Aww.  Forever branded, the  Technologizer.  Elon Musk, also speaking at the  Recode Conference.  It's funny because I'm watching  this video.  I guess they had Q&A afterwards.  And who shows up at the Q&A?  But Joshua Topolsky.  I've been wondering what he's  been up to.  A creator of Engadget, right?  Editor-in-chief of...  I don't know if he created it,  but he was editor-in-chief  of Engadget.  And then he did The Verge,  my next thing, right?  And then he kind of...  He left, right?  He left Fox, and he just...  I don't know what he's doing  these days.  But apparently he's asking  questions at the Recode.  Went to Bloomberg for a while,  and then he went to Bloomberg.  Right, he ran Bloomberg for a  while.  I think he's doing something  new.  Anyway, he had this question.  And I see...  There's sort of a

Start time: 1978.54
End time: 1987.54
Speaker: SPEAKER_11
Transcript:  philosophic concept that a  sufficiently advanced  civilization will be able to  create a simulation...  Elon's really on...  He knows.

Start time: 1988.40
End time: 2006.69
Speaker: SPEAKER_07
Transcript:  I've had so many simulation  discussions, it's crazy.  What?  In fact, it got to the point  where basically every  conversation was the AI  slash simulation conversation.  And my brother and I finally  agreed that we would ban such  conversations if we were ever  in a hot tub.  That was like...  Okay.

Start time: 2007.52
End time: 2008.27
Speaker: SPEAKER_11
Transcript:  There's something else

Start time: 2009.26
End time: 2012.08
Speaker: SPEAKER_13
Transcript:  besides a hot tub involved  there, I think.  So the idea is right.

Start time: 2012.30
End time: 2030.96
Speaker: SPEAKER_11
Transcript:  Any sufficiently advanced  civilization could create  a simulation that's like our  existence, and so the theory  follows that maybe we're in the  simulation.  Have you thought about this?  A lot.  Are we...  A lot.  A lot.  Are we...  Even in hot tubs.  So much so that...

Start time: 2031.26
End time: 2036.12
Speaker: SPEAKER_13
Transcript:  A lot.  It's really stark.  That's exactly what I thought.  Listen to his explanation

Start time: 2036.30
End time: 2039.00
Speaker: SPEAKER_11
Transcript:  of why he believes it.  Are we in?  Are we in?

Start time: 2041.81
End time: 2125.97
Speaker: SPEAKER_07
Transcript:  I think here's...  The strongest argument for us  being in a simulation,  probably being in a simulation,  I think is the following.  That 40 years ago we had Pong.  Like two rectangles and a dot.  That was what games were.  Now 40 years later we have  photorealistic 3D simulations  with millions of people playing  simultaneously and it's getting  better every year.  And that was in 40 years.  Virtual reality, augmented  reality.  If you assume any rate of  improvement at all, then the  games will become  indistinguishable from reality.  Just indistinguishable.  Even if that rate of  advancement drops by a thousand  from what it is right now, then  you just say, okay, well, what  happens if we go back 10,000  years in the future?  Which is nothing in the  evolutionary scale.  So given that we're clearly on  our trajectory to have games  that are indistinguishable from  reality and those games could  be played on any set-top box or  on a PC or whatever and there  would probably be billions of  such computers or set-top boxes.  It would seem to follow that  the odds that we're in base  reality is one in billions.

Start time: 2128.14
End time: 2128.61
Speaker: UNKNOWN
Transcript:  Wait a minute.

Start time: 2129.22
End time: 2151.49
Speaker: SPEAKER_13
Transcript:  Now let's get this clear.  Stop it there.  The odds that we are in what  they call base reality, like  real reality, is one in a  billion.  Now that seems like pretty high  odds that we are in a  simulation.  And he's not that crazy.  Here's a Scientific American  article from last month in which  Neil deGrasse Tyson says, well,  I think it's more like 50-50.  What?  What?  Wow.

Start time: 2152.14
End time: 2167.02
Speaker: SPEAKER_10
Transcript:  I mean, I think it should be  said that while games look  incredibly better than they did  40 years ago, the gameplay has  not kept up and a lot of games  are not all that much more  sophisticated than a really  fancy version of bomb or space  invaders or whatever.  This is a panel that Scientific

Start time: 2167.14
End time: 2231.47
Speaker: SPEAKER_13
Transcript:  American had of physicists,  philosophers, Neil deGrasse  Tyson moderated it.  And what the physicists said is  well, if you want to prove or  disprove this hypothesis, what  you do is you observe and you  look for shortcuts that the  programmers might have taken  like, okay, you're laughing,  but eventually you would  discover something a little  blurry, right?  Now, the lack of it doesn't  mean you're not in a  simulation.  It just means that the  simulation is better than one  would expect or better than  maybe you think.  He says if there's an  underlying, the quote, if  there's an underlying  simulation of the universe,  that has the problem of finite  computational resources, just  as we do, then the laws of  physics have to be put in a  finite set of points and a  finite volumes.  This is Zohreh Davoudi who is a  physicist at MIT.  Then we go back and see what  kind of signatures we could  find that tell us we started  from non-continuous space time.  In other words, the kind of  evidence that would convince me  as a physicist is where it's  just kind of not quite right.  A glitch, I think they called  it in the matrix.  And it's a glitch.

Start time: 2232.17
End time: 2232.78
Speaker: UNKNOWN
Transcript:  And it's a glitch.

Start time: 2232.92
End time: 2240.60
Speaker: SPEAKER_13
Transcript:  And it's a glitch.  And it's a glitch.  And it's a glitch.  This is what's going on in  physics.  The problem is, whether we are  or not, what the hell are you

Start time: 2240.80
End time: 2241.56
Speaker: UNKNOWN
Transcript:  going to do with it?

Start time: 2244.78
End time: 2251.62
Speaker: SPEAKER_13
Transcript:  It's fascinating that Eilion  brought it up.  I guess really Joshua brought  it up.  And Eilion, though, jumped on  it.  It was like, yeah.

Start time: 2251.78
End time: 2322.38
Speaker: SPEAKER_04
Transcript:  One in a billion.  Does the guy really believe  that he's going through?  He says it's a certainty.  Basically he says it's a  certainty.  Right.  That he's going through life  like that is insanity.  I walked away from this  listening to this entire talk  with my head just exploding  thinking, genius, insane.  Genius, insane.  Genius, insane.  The one that he got to at the  end of the talk was neural  lace.  So his point being, let's just  say one in a billion were not  in a game, that this is  actually real life.  So I'm going to wing it now.  There's always a possibility.  Well, if that's the case, let's  go for it.  His thing, well, okay, the  robots are going to take over.  I'm over generalizing.  But he definitely has a fear of  artificial intelligence as we  discussed.  And he said that the way that  humans will come to life is  going to be a big problem.  And he said that the way that  humans will come to life is  going to be a big problem.  And he said that the way that  humans will come to life is  going to be a big problem.  And the way that humans will  continue to evolve and exist is  that we will create an  artificial intelligence neural  lace that intersects with our  own brains to augment our  brains, and then we will be able  to compete and still maintain  dominance over the artificial  intelligence agents.  And the way that he put it when  speaking was, well, somebody's  got to do it.  I mean, if nobody else does it,  I might do it.  But somebody's got to do it.  It does kind of explain Elan's  words.  I mean, I think it's a good  point.  I think it's a good point.  I think it's a good point.

Start time: 2322.42
End time: 2331.79
Speaker: SPEAKER_13
Transcript:  But it does explain Elan's  willingness to bet big, big  bets.  It's like, well, if it's a  simulation, you might as well.  Why not?  What does it matter?  You're playing with house  money.

Start time: 2332.46
End time: 2345.77
Speaker: SPEAKER_04
Transcript:  We're just all software.  Right.  Well, other fascinating  insights.  He said when asked about space,  he said, well, I like doing  space because it's not just  solving problems.  It's actually something that  interests me and keeps me  walking in the door to work  every day.  Like Tesla is just solving  problems.

Start time: 2346.72
End time: 2356.16
Speaker: SPEAKER_13
Transcript:  He needs a little extra oomph  to keep him interested.  How are we going to get to  Mars?  He says he's going to put a  man on Mars in what, a couple  of decades.

Start time: 2356.63
End time: 2357.14
Speaker: UNKNOWN
Transcript:  All right.

Start time: 2357.38
End time: 2362.79
Speaker: SPEAKER_13
Transcript:  Yeah.  Well.  It doesn't matter if it's  simulation.  You just press, you know, put  another quarter in.

Start time: 2363.30
End time: 2375.72
Speaker: SPEAKER_04
Transcript:  But see, then that's, you go  over and you listen to Jeff  Bezos talk about space and you  realize he makes it sound so  much more sane.  I mean, Elan made it sound  sane in some aspects, but Jeff  Bezos made it sound logical and  pragmatic.

Start time: 2378.13
End time: 2408.92
Speaker: SPEAKER_13
Transcript:  I think the problem, here's the  real problem.  Once you have a certain amount  of money, you can do anything  you want.  Yeah.  And it's kind of boring.  So you come up with crazy  things to keep yourself  interested because the things  that challenge us, like, you  know, where am I going to get  dinner tonight?  And it's just not, you got  people doing that.  You don't need, you are already  in a different universe from the  rest of us.  Don't you think?  Do you know any really, really  rich people?

Start time: 2409.41
End time: 2422.04
Speaker: SPEAKER_04
Transcript:  I do.  I know a realtor, right?  So she, on Maui, so she deals  with a lot of extraordinarily  wealthy people.  Oprah has a house there.  Oh, yeah.  I mean, Peter Thiel.  Oh.  Steve.  There's another example of a guy

Start time: 2422.24
End time: 2423.41
Speaker: SPEAKER_13
Transcript:  living in his own reality.  Oh, yeah.

Start time: 2424.99
End time: 2452.22
Speaker: SPEAKER_04
Transcript:  Steve Finn, big VC down in the  valley.  The Senegal's who own Costco,  blah, blah, blah.  I can list a million.  No one you know and not any of  those people I've just listed,  they do this thing that my mom  and I refer to as serial  manipulating.  They just have so much fun  playing with all the chess  pieces.  That's a different kind of rich  person.  Wealth makes you psychotic.  Yeah.  You do all these things that  because you're trying to find,  you're trying to find something  that still stimulates you.  Right.

Start time: 2453.08
End time: 2459.94
Speaker: SPEAKER_13
Transcript:  F. Scott Fitzgerald said the  rich are not like you and me.  They don't have money.  Peter Thiel is a good example.  He's definitely not like us.

Start time: 2460.12
End time: 2461.94
Speaker: SPEAKER_10
Transcript:  Now, I don't know Peter.

Start time: 2462.06
End time: 2473.14
Speaker: SPEAKER_13
Transcript:  Have you met Peter?  I've seen him talk on stage.  I don't think I've ever exchanged  words with him.  He supposedly was the  inspiration for that.  He was the inspiration for that  weirdly autistic venture  capitalist at the beginning of  the first season of Silicon  Valley.

Start time: 2473.98
End time: 2474.43
Speaker: SPEAKER_04
Transcript:  I've heard that.

Start time: 2475.21
End time: 2513.09
Speaker: SPEAKER_13
Transcript:  Is he like that?  Is he like strange and anyway,  I on the one hand,  I'm thrilled that he was going  after Gawker.  I couldn't, I couldn't.  It's I'm really torn on that  one and we've talked about this  before but not with you guys.  I'm really torn on that because  on the one hand and I was  talked down last week on this  because I want him,  I want somebody to take down  Nick Denton.  I just really hate Gawker.  But you don't want to be  able to take down a person  who doesn't want people just  because they have means to be  able to undermine the press,  undermine democracy and use the  courts against people just  because you can afford to lose  a lot of money, right?

Start time: 2513.94
End time: 2515.80
Speaker: SPEAKER_04
Transcript:  Free speech, First Amendment.

Start time: 2516.44
End time: 2519.82
Speaker: SPEAKER_13
Transcript:  Denton and Gawker are protected  by the First Amendment.

Start time: 2520.50
End time: 2529.66
Speaker: SPEAKER_04
Transcript:  But the laws also create space  for people to sue other people  and for there to be consequences.  But this is the point.

Start time: 2529.84
End time: 2549.70
Speaker: SPEAKER_13
Transcript:  If you have a lot of money,  you can afford to sue people on  frivolous lawsuits, bankrupt  normal people, even Hulk Hogan  is a normal person when you  come to Peter Thiel money,  bankrupt normal people defending  these lawsuits.  I think it's safe to say that  Nick Denton had to go out and  borrow money to pursue this,  to defend himself.

Start time: 2549.82
End time: 2551.70
Speaker: SPEAKER_04
Transcript:  He said that.  He said he had to take equity.

Start time: 2551.86
End time: 2564.91
Speaker: SPEAKER_13
Transcript:  He had to take investors.  Even if there's no merit in  it, if you've got billions of  dollars, you can spend a hundred  million dollars going after  somebody harassing them even if  there's no merit in it.  That's not an appropriate use of  the courts at all.

Start time: 2565.94
End time: 2567.21
Speaker: SPEAKER_04
Transcript:  But it's within the purview of  the law.

Start time: 2568.11
End time: 2568.70
Speaker: SPEAKER_13
Transcript:  Well, that's true.

Start time: 2568.82
End time: 2570.68
Speaker: SPEAKER_04
Transcript:  And the bottom line is...  I mean, the judge has the right

Start time: 2570.82
End time: 2573.17
Speaker: SPEAKER_13
Transcript:  to say this is frivolous.  It used to be illegal.  Mr. Thiel, yeah.

Start time: 2573.82
End time: 2577.70
Speaker: SPEAKER_10
Transcript:  In the old days, you could not  fund somebody else's court case.

Start time: 2577.94
End time: 2584.60
Speaker: SPEAKER_13
Transcript:  Well, and there are in some  states slap rules that protect  people against frivolous  libel suits and things like

Start time: 2584.96
End time: 2585.07
Speaker: SPEAKER_12
Transcript:  that.

Start time: 2585.82
End time: 2597.28
Speaker: SPEAKER_10
Transcript:  I mean, I think the basic issue  is if Peter Thiel can do it to  Gawker, someone can do it to  Twit, someone can do it to  Fast Company.  Most of us would have a hard  time defending ourselves against  somebody with $10 billion.

Start time: 2600.15
End time: 2600.35
Speaker: UNKNOWN
Transcript:  Yeah.

Start time: 2601.09
End time: 2620.99
Speaker: SPEAKER_04
Transcript:  Okay.  So let's play the other side of  the coin, which is, of course,  you know, we're all journalists.  We're going to protect the First  Amendment and the right to free  speech.  So let's just say that's  obvious.  The law says you can sue people.  That is the law.  Yeah.  It took so much for someone to  finally say enough with Gawker.  Yeah.

Start time: 2621.78
End time: 2622.58
Speaker: SPEAKER_12
Transcript:  He's had a lot of, yeah, I mean.

Start time: 2623.19
End time: 2629.56
Speaker: SPEAKER_04
Transcript:  He's even admitted and he spoke  on it this week and said, we've  had some terrible news judgment.  Nick Denton said this about

Start time: 2629.86
End time: 2630.21
Speaker: SPEAKER_12
Transcript:  Gawker.

Start time: 2630.72
End time: 2641.14
Speaker: SPEAKER_04
Transcript:  Well, now he thinks so.  Right.  He was actually very recalcitrant  and really not the tone that I  expected him to come out with.  And so this...  No, he just got religion.

Start time: 2641.70
End time: 2644.23
Speaker: SPEAKER_13
Transcript:  Maybe there's something to be  said for Peter Thiel spanking  him a little bit.

Start time: 2644.76
End time: 2663.97
Speaker: SPEAKER_04
Transcript:  I mean, I really...  I know in principle I definitely  stand with Gawker, but I also  see the legal system and the  financial system really of  capitalism as a part of  journalism playing into this  because it took that much for  Gawker to get spanked.  You just talked me back onto  the ledge.

Start time: 2664.70
End time: 2670.27
Speaker: SPEAKER_13
Transcript:  You just talked me...  They talked me out of it last  week.  You just talked me back into it.  Go get him, Peter.  Go get him.

Start time: 2670.70
End time: 2684.95
Speaker: SPEAKER_10
Transcript:  If it was such a great idea, he  should have done it in public.  Sure.  Maybe...  Now he has, but maybe the way to  address this is you can pay for  somebody else's court case, but  it all has to be public.  Yeah, maybe, yeah.  Where's the money coming from?  Because he waged a secret war,  not a public one.  Yeah.

Start time: 2685.70
End time: 2691.48
Speaker: SPEAKER_04
Transcript:  I'm torn because I feel  constricted as a journalist  because...  Gawker's not good for

Start time: 2691.99
End time: 2692.48
Speaker: SPEAKER_13
Transcript:  journalism.

Start time: 2692.76
End time: 2707.03
Speaker: SPEAKER_04
Transcript:  We have such stringent rules at  ABC.  Right.  As you should.  And we have such standards...  All my stuff has to go through  standards, has to go through  legal, and we really talk it  out.  And the news judgment that's  applied is so center.  Right.

Start time: 2707.66
End time: 2742.97
Speaker: SPEAKER_13
Transcript:  So...  Now, is it that way because of a  fear of lawsuit?  Or because it's the right thing  to do?  So you see a lot of that lately  is this cover your ass stuff.  We don't...  Yeah, yeah, you know what I'm  saying?  You know what I'm saying?  So that is the chilling effect.  Doing things because it's the  right thing to do is great.  Doing things because you don't  want exposure often is not good.  And our lawyers are always  saying, oh, don't do...  I get told this a lot.  Shut up.  Don't do that.  Don't say that.  Not that it's wrong or that  you're wrong, but it's risky.

Start time: 2744.46
End time: 2745.34
Speaker: UNKNOWN
Transcript:  I think the point that I have

Start time: 2745.76
End time: 2752.71
Speaker: SPEAKER_04
Transcript:  learned in my 11 years working  at a network is if you're going  to take the risk, it better be  worth it.  You better back it up.  Yeah.

Start time: 2753.46
End time: 2772.20
Speaker: SPEAKER_10
Transcript:  And you shouldn't be  unnecessarily sued.  If you have a story that might  cause somebody to sue you, you  should button down every detail  That's good.  Make sure you're right.  That's good journalistic  discipline.  Don't poke somebody in the eye  for pointless reasons.  Right.  Poke them in the eye because you  have facts behind it.  Right.  Gawker's defense, and I think

Start time: 2772.36
End time: 2788.14
Speaker: SPEAKER_13
Transcript:  it's really a disingenuous  defense, it's really bad.  It's a rationale, not a defense  as well.  You know, we have to speak truth  to power.  But outing Peter Thiel is not  speaking truth to power in any  respect.  And that's not even the only

Start time: 2788.48
End time: 2800.25
Speaker: SPEAKER_04
Transcript:  reason why he was ticked.  He said, well, you know, I'm  not going to be a good  defense.  I'm going to be a good defense  for the defense.  And he was ticked.  Peter Thiel said that he was  mad because they had done  grievous harm to his friends,  including Sean Parker and some

Start time: 2801.24
End time: 2805.10
Speaker: SPEAKER_13
Transcript:  of the other...  Well, we all know somebody who  has been slimed by Gawker.

Start time: 2805.22
End time: 2807.32
Speaker: SPEAKER_04
Transcript:  I mean, they really were  slimy.  Right.

Start time: 2808.22
End time: 2832.68
Speaker: SPEAKER_13
Transcript:  But I mean, you have to put TMZ  and Page Six and all these guys  in the same category.  Okay, here's where I say this is  different.  And Roberto Baldwin schooled me  on this.  He used to work for TMZ.  In the early days, he worked  for Harvey Levine and TMZ.  This is a symbiotic relationship.  Within that 30-mile range,  anything goes because the  celebrities want that coverage.  They call TMZ and say, you might  find me outside of a Walmart.

Start time: 2833.36
End time: 2845.98
Speaker: SPEAKER_04
Transcript:  Sometimes they want the  coverage.  Johnny Depp does not want the  coverage this week.  He did not want that coverage.  Yeah.  So I think that's not as  utilitarian as you think it is.  But there is between Hollywood

Start time: 2846.14
End time: 2871.58
Speaker: SPEAKER_13
Transcript:  and the gossip columnists.  There is a symbiosis.  And that's part of the industry.  And frankly, if you're a movie  star, you get into this.  You know, you're not getting into  this.  Peter Thiel is a venture  capitalist.  I don't think he kind of made  that implicit agreement, right,  that, well, my private life is  now public.  Why would that, why would he  even consider that?  Just because he's technically a  public figure, why would he even  consider that's fair game for  any journalistic entity?

Start time: 2872.81
End time: 2894.72
Speaker: SPEAKER_04
Transcript:  Yeah, it just doesn't feel good  any of it.  It feels so yucky that it's  really hard to, you know, I  think Jeff Bezos said this week  that it's not the pretty speech  that you need to ever defend.  Right.  It's the ugly speech.  And that's, you know, that's the  bottom line is you get into  these horrible situations where  if you're defending the First  Amendment, you always end up  doing it in cases that make you  feel yucky.  There's a lot of stuff that is

Start time: 2894.86
End time: 2898.71
Speaker: SPEAKER_10
Transcript:  yucky and should be absolutely  legal.  Yucky but legal.

Start time: 2899.96
End time: 2900.74
Speaker: SPEAKER_03
Transcript:  Okay, I want you to tweet that.

Start time: 2900.92
End time: 2909.38
Speaker: SPEAKER_13
Transcript:  And then just let the chips fall  away.  I don't know what I'm trying to  think of what that would be.

Start time: 2909.92
End time: 2915.44
Speaker: SPEAKER_10
Transcript:  Well, a lot of journalism that  makes people uncomfortable and  causes trouble for people.  Well, that's appropriate, though,

Start time: 2915.88
End time: 2916.23
Speaker: SPEAKER_13
Transcript:  if it's...

Start time: 2916.90
End time: 2926.74
Speaker: SPEAKER_04
Transcript:  It's just bad judgment.  I mean, you can't legislate bad  judgment down to an inch of its  life.  Right.  And so, ugh, yeah.  We, you know, here's good.

Start time: 2926.86
End time: 2961.62
Speaker: SPEAKER_13
Transcript:  This is not going to go away  because we live in a new age for  journalism where there is  intense pressure on journalistic  entities to survive and there  are all threatened by the  Internet and kind of the end of  the home page, you know?  And they're all kind of in  desperate need to get clicks and  traffic and links.  And journalistic rules seem to be  somewhat going out the window.  I mean, you're both longtime  journalists.  Some of the things that we  thought 20 years ago would never  happen happen all the time now,  even from well-known journalistic  entities.

Start time: 2961.80
End time: 2998.25
Speaker: SPEAKER_04
Transcript:  Well, that's where the legal  system and the financial sort of  punishments here that may be  handed down in this case.  I'm not saying that Peter Thiel  should have funded them secretly,  but they may have a chilling  effect on the needless publishing  of stuff that doesn't need to be  out there and doesn't help  anyone.  I mean, that's one of the things  that Nick Denton said is that the  amount of information that's now  available has increased  exponentially as much as the  competition and all the other  journalistic sources online, news  sources.  So they have to be more  discriminating about what they  choose to publish.  Speaking of artificial

Start time: 2999.58
End time: 3004.36
Speaker: SPEAKER_13
Transcript:  intelligence, Google has now  said that we are hiring novelists

Start time: 3005.45
End time: 3006.68
Speaker: UNKNOWN
Transcript:  to give our artificial

Start time: 3007.50
End time: 3016.36
Speaker: SPEAKER_13
Transcript:  intelligence personalities a  backstory.  This is a fast company story.  I found that really disappointing  because one of the things I've

Start time: 3016.50
End time: 3048.10
Speaker: SPEAKER_10
Transcript:  liked about Google now up until  now is it's made no attempt to  have a personality.  It doesn't understand jokes.  It just is really smart about  the stuff it does as opposed to  Siri and Cartana and Alexa, all  of which are programmed to be  funny.  They get annoying, don't they?  After a certain point, it was  very entertaining and a novelty  when Siri did it a few years  ago.  I like the fact that Google is  utilitarian and I'm a little  worried about them getting a  little bit too cute.  They're not after you.

Start time: 3048.44
End time: 3058.74
Speaker: SPEAKER_04
Transcript:  Just like the television networks  really care about the most,  the television networks really  care about the millennial demo,  they are trying to attract users  for their entire life.  And that's my kids.

Start time: 3059.70
End time: 3062.78
Speaker: SPEAKER_13
Transcript:  And do your kids want the  exchanges to be more human-like?

Start time: 3063.26
End time: 3103.88
Speaker: SPEAKER_04
Transcript:  Oh, totally.  Their expectation of human  language is high and that's why  one of the women that they hired  to do this is a woman named  Emma Coats.  From Pixar.  She's from Pixar.  And at the Moogfest, she and  Ryan Jermick, who is one of the  other guys, they were joking  about that.  You know, this is really about  humor.  And one of the things is they're  preparing answers to questions  that they get a lot, which is do  you fart?  This is a quote that they said,  do you fart?  And it might say, they say it  might lead the artificial  intelligence to say, not  recently.  Or perhaps something more sassy.  Maybe Google could ping data  about nearby air quality test  results.

Start time: 3105.19
End time: 3109.67
Speaker: SPEAKER_03
Transcript:  So, I mean, I'm being flip about  this.  But, you know, there is a

Start time: 3111.95
End time: 3126.90
Speaker: SPEAKER_04
Transcript:  willingness to go to a different  demo than your traditional tech  reviewer, tech mature audience.  And I think that they're  realizing that there's an  opportunity.  Not, we aren't going to ask  those questions.  Our kids will.  Maybe they can do it better than

Start time: 3127.02
End time: 3128.39
Speaker: SPEAKER_10
Transcript:  Siri and Alexa and Kenna have.

Start time: 3129.02
End time: 3136.82
Speaker: SPEAKER_13
Transcript:  Isn't it those very kind of  singularly unsatisfying when  Siri says, I can't answer that  question or Alexa says, I don't  know what you're talking about.  Well, Google has as good a

Start time: 3136.94
End time: 3140.78
Speaker: SPEAKER_10
Transcript:  better chance than anybody of  not having that happen.  They at least can answer the

Start time: 3140.96
End time: 3155.78
Speaker: SPEAKER_13
Transcript:  question.  Yeah.  Right.  But what if you ask it a  nonsensical question, you know?  What should its response be?  Should it just be that question  is nonsense?  I mean, that's kind of  insulting.  I personally would be okay with

Start time: 3155.90
End time: 3160.85
Speaker: SPEAKER_10
Transcript:  it saying, I don't understand  Dave or Harry.  Yeah.  Why are chickens blue?  And it goes, what is it going

Start time: 3162.10
End time: 3163.78
Speaker: SPEAKER_13
Transcript:  to say?  It is a good point.

Start time: 3163.94
End time: 3177.66
Speaker: SPEAKER_10
Transcript:  They want everybody to use this  and Google now is really  great, but I have the feeling  that even a pretty high  percentage of people who have  Android phones have not done  nearly as much with Google now  as they could because it's not  all that engaging.  It's just useful.  Well, but this is the point is  that Senator Pachai said this

Start time: 3177.94
End time: 3190.66
Speaker: SPEAKER_04
Transcript:  week that they are trying to  make an individual Google for  every single user and so that if  they were true AI, it would  learn whether you want that or  not.  That would be good.  There you go.  I think what Google, and I  mentioned this before, but I  wanted to say that Google is  not a good example of how

Start time: 3190.80
End time: 3222.93
Speaker: SPEAKER_13
Transcript:  people can make a Google  app.  I think what Google, and I  mentioned this before, but I  wanted to say it again.  Google's real opportunity here  is to be your intermediary to  the rest of the world.  So where bots went wrong is  that you had to have this  relationship with a variety of  fairly annoying things and like  whether it's 1-800-Flowers or  Poncho the weather cat, I don't  want all these relationships.  What I really want is one  relationship, a personal  assistant who then goes out and  has the relationships with  Poncho and these other things.  Microsoft is the best.  Is that what Cortana is going

Start time: 3223.72
End time: 3242.81
Speaker: SPEAKER_10
Transcript:  to do?  Microsoft says there are  agents and an agent is  something that works on your  behalf and knows an awful lot  about you and your agent works  with bots and a bot might be  from 1-800-Flowers or a hotel  chain and they work on behalf  of the hotel chain and know a  lot about it but the only  access they have to your data  is what your agent gives to  them.

Start time: 3243.54
End time: 3264.42
Speaker: SPEAKER_13
Transcript:  But Jeff Bezos said something  that scared me at Recode this  week.  He said we're all going to have  a lot of these and I imagine  this mantle piece of data is  filled with an echo and a  Google Home and a bunch of  things and then you have to  remember which can do what and  who to ask for and what the  syntax is and that seemed like  the future Jeff Bezos envisioned.  I hope that's not the case.

Start time: 3264.72
End time: 3288.65
Speaker: SPEAKER_04
Transcript:  This is just a whole new way of  having the ecosystem discussion.  So I think that we all live  within multiple ecosystems and  you'll choose which one does  what for you.  So if you really want to have  something that is going to  be a good idea, I'm out of  cornmeal.  Alexa, order more cornmeal.  I'm just making this up.  Or if it's more about music.

Start time: 3290.60
End time: 3303.01
Speaker: SPEAKER_13
Transcript:  By the way, you just bought  cornmeal for several hundred  people.  Sorry.  I hope you can use that cornmeal  everybody.  Good stuff.  I'll give you a good recipe  that involves cornmeal.  Alexa, give me a polenta recipe  and then we'll be all set.

Start time: 3304.56
End time: 3317.30
Speaker: SPEAKER_04
Transcript:  Alexa, cancel the cornmeal  order please.  So I think that you will choose  an ecosystem based on your most  pressing needs, interests and  existing affiliations.

Start time: 3317.44
End time: 3335.30
Speaker: SPEAKER_13
Transcript:  This is what Bezos said.  I think there are going to be a  bunch of artificially intelligent  agents in the world.  There are going to be specialties.  You may not ask the same AI for  everything.  I bet the average household will  use a number of these.  But to me that's a very exciting  seed we've planted.  I love working on stuff like that  and the team is brilliant.  I don't know.

Start time: 3335.42
End time: 3348.87
Speaker: SPEAKER_10
Transcript:  It's complicated though because  I want a relationship with  Facebook.  I want one with Google.  I want one with Amazon.  They're all quite different.  One of them is going to win.  It's not like choosing between  Windows and the Mac where  they're kind of doing the same  thing in a largely similar way.  These companies are all doing  different stuff.

Start time: 3349.52
End time: 3367.28
Speaker: SPEAKER_13
Transcript:  See, in my imagination I think  that Google, let's say Google is  the winner, is the incumbent.  My house will be a Google house  and I will say Google, I'm out of  toilet paper, order me some more  and it will tell Alexa, get Leo  some toilet paper.  It will talk to 50 different bots

Start time: 3367.44
End time: 3369.99
Speaker: SPEAKER_10
Transcript:  and bring the cheapest and  fastest.  I want that.

Start time: 3370.42
End time: 3376.18
Speaker: SPEAKER_13
Transcript:  I don't want 12 personal  assistants each with a different  skill.  No one wants that, right?

Start time: 3376.74
End time: 3381.30
Speaker: SPEAKER_04
Transcript:  I'm also going to start doubting  Alexa who's making noise.

Start time: 3381.76
End time: 3383.30
Speaker: SPEAKER_13
Transcript:  Alexa, buy cornmeal stock.

Start time: 3383.42
End time: 3389.97
Speaker: SPEAKER_04
Transcript:  Alexa's next to me now.  Oh, that's Echo?  Who is this?  That's Echo.

Start time: 3390.42
End time: 3395.30
Speaker: SPEAKER_13
Transcript:  We say Echo and by the way,  that one is triggered by Echo,  not by the A word.

Start time: 3395.44
End time: 3399.18
Speaker: SPEAKER_04
Transcript:  Okay.  I won't say her name or the  repeating sound word.

Start time: 3400.21
End time: 3408.67
Speaker: SPEAKER_13
Transcript:  It's like saying you want four  different operating systems in  your house.  You're going to pick one,  aren't you?  That's what an operating system  does.  It intermediates.  No.

Start time: 3409.36
End time: 3413.39
Speaker: SPEAKER_04
Transcript:  Because right now, your house  doesn't count.  I'm not a usual, but I guess

Start time: 3414.68
End time: 3420.44
Speaker: SPEAKER_13
Transcript:  everybody will have an iOS or an  Android device and maybe a Mac  and a Windows device.  I guess that's not unusual.  Yeah.

Start time: 3421.64
End time: 3435.55
Speaker: SPEAKER_04
Transcript:  We have a Nest which is a Google  world.  We buy all our stuff on Amazon  and we have mostly Macs and  iPhones.  We're all living in an ecosystem  that looks like a Venn diagram.

Start time: 3437.81
End time: 3452.06
Speaker: SPEAKER_13
Transcript:  Yeah.  That's not ideal.  In her, you dealt with Scarlett,  Johansson, and she did  everything for you.  Isn't that what you want?  You'd like to have a choice

Start time: 3452.18
End time: 3464.81
Speaker: SPEAKER_10
Transcript:  between her and competition.  You'll have a choice.  You want it to be Microsoft in  1990s when it was a period where  Microsoft seemed like the only  viable technology provider?  We've seen this before in very,  very small with instant

Start time: 3466.08
End time: 3490.85
Speaker: SPEAKER_13
Transcript:  messenger programs where you had  ICQ and you had AIM and you had  Microsoft Messenger and none of  them talked to each other and  each of them wanted to own that  space 100% and really the way to  win would have been to have one  that could talk to everybody.  That's what you want.  Nobody wanted to do that because  they wanted to own the market.  I think you're presuming this.  It killed I am, by the way.  I think you're presuming this

Start time: 3492.67
End time: 3499.82
Speaker: SPEAKER_04
Transcript:  based on a hardware mindset  because you're presuming that  you're only going to buy one  piece of hardware that's going to  run your house.

Start time: 3499.94
End time: 3504.60
Speaker: SPEAKER_13
Transcript:  I don't want a mantelpiece full  of black tubes.  This is an intermediary step.

Start time: 3505.04
End time: 3506.72
Speaker: SPEAKER_04
Transcript:  You're going to have all kinds  of stuff.

Start time: 3506.94
End time: 3507.62
Speaker: SPEAKER_12
Transcript:  The house will listen.

Start time: 3507.94
End time: 3526.54
Speaker: SPEAKER_04
Transcript:  You have all kinds of stuff now.  Your phone, blah, blah, blah.  You could have all kinds of  stuff.  The air fresheners on your  mantelpiece is an intermediary  step.  Secondarily, hardware is not the  issue because you look at Amazon  as an example.  It is a crime that they are  charging anything for this  device given that it is a  conduit to purchase more things.  They charge a lot.

Start time: 3527.07
End time: 3528.70
Speaker: SPEAKER_13
Transcript:  It's almost $200.  It's really expensive.

Start time: 3529.24
End time: 3542.66
Speaker: SPEAKER_04
Transcript:  They will give these things away  because each one of them will  find a business model that has  nothing to do with the hardware  and that's why Apple's not in it  right now is because they can't  figure out the business model  without the hardware is my  personal opinion.  They still think of themselves  as a hardware.  They still think of themselves

Start time: 3542.82
End time: 3551.66
Speaker: SPEAKER_10
Transcript:  as a hardware company.  The news is that maybe they are  working on something.  What?  That Apple is working on  something at least roughly akin  to an Echo.  All right.

Start time: 3551.86
End time: 3553.92
Speaker: SPEAKER_04
Transcript:  So this is the WWDC announcement,  right?

Start time: 3554.90
End time: 3578.66
Speaker: SPEAKER_10
Transcript:  No, it's too soon.  Not for WWDC but at some point.  I think at WWDC there probably  will be news about Siri that  starts to tiptoe in this  direction such as opening up  Siri to third party services.  But Apple is the kind of company  that takes its time.  It doesn't need to like come out  with something like the Echo  immediately.  It will do it when it feels like  it has something which is more  interesting than the Echo.

Start time: 3578.82
End time: 3585.00
Speaker: SPEAKER_12
Transcript:  I think Apple is going to be at  a disadvantage because they're  so worried about privacy, right?

Start time: 3586.41
End time: 3588.57
Speaker: SPEAKER_10
Transcript:  And they don't have huge AI  chops yet.

Start time: 3591.04
End time: 3592.97
Speaker: SPEAKER_13
Transcript:  Echo, order me an Elvis costume.

Start time: 3594.44
End time: 3596.93
Speaker: SPEAKER_12
Transcript:  Echo, order me an Elvis costume.

Start time: 3599.86
End time: 3606.32
Speaker: SPEAKER_02
Transcript:  Based on Leo's order history,  I found Elvis now deluxe aloha  Elvis costume.  White, extra large.

Start time: 3607.04
End time: 3607.34
Speaker: UNKNOWN
Transcript:  $500.99 total.

Start time: 3610.82
End time: 3612.48
Speaker: SPEAKER_02
Transcript:  To order it, tell me Leo's voice

Start time: 3612.88
End time: 3612.96
Speaker: UNKNOWN
Transcript:  code.

Start time: 3613.98
End time: 3617.45
Speaker: SPEAKER_13
Transcript:  Wow.  Wow.  So I can have an Elvis costume  tomorrow.

Start time: 3618.49
End time: 3620.46
Speaker: SPEAKER_04
Transcript:  Echo, are you sure he needs  extra large?

Start time: 3625.82
End time: 3639.38
Speaker: SPEAKER_13
Transcript:  Now, if Echo...  Now, is that a convenience or  what?  How many times have you been  walking around the house  thinking, gosh, you know what I  really need is an Elvis costume?  And now you just ask the house  and it delivers it.  Do you buy clothes from Amazon?

Start time: 3639.70
End time: 3641.75
Speaker: SPEAKER_10
Transcript:  How does it not size?  I could say more socks.

Start time: 3642.70
End time: 3646.58
Speaker: SPEAKER_13
Transcript:  Echo, order me some socks.  Jeff Bezos said that fashion is

Start time: 3646.72
End time: 3650.12
Speaker: SPEAKER_04
Transcript:  one of the categories he's most  excited about in retail.  Yeah.

Start time: 3652.43
End time: 3655.58
Speaker: SPEAKER_02
Transcript:  I can't find the answer to the  question I have.  See, that's what you don't want

Start time: 3655.99
End time: 3658.35
Speaker: SPEAKER_10
Transcript:  to hear.  It's supposed to make a funny  joke, I know.

Start time: 3658.70
End time: 3669.05
Speaker: SPEAKER_12
Transcript:  Yeah.  You should say socks?  I thought you wanted sex.  No, that's not good.  That's really not good.  Sorry about that.

Start time: 3669.82
End time: 3671.65
Speaker: SPEAKER_03
Transcript:  Sending porn to your phone now.

Start time: 3672.70
End time: 3680.40
Speaker: SPEAKER_13
Transcript:  Tomorrow you will receive some  VCS, VZVHS tapes.  Let's take a break.  Oh, Lord.

Start time: 3680.70
End time: 3684.34
Speaker: SPEAKER_03
Transcript:  You've really kicked off the  Alexa owners now.  It was like a full-fledged...

Start time: 3685.55
End time: 3714.85
Speaker: SPEAKER_13
Transcript:  No, because I don't say the A  word.  I trained it to say the E word.  Now, of course, there's people  who listen to the show who say,  oh, I can't use the A word, so  I'm going to use the E word.  Now they're really mad.  I see.  But you can also use the other  A word, Amazon, if you want.  But that's another thing, by  the way.  Each of these should have its  own unique trigger phrase.  Why in heaven's name are we  still all using the same trigger  phrase?  That's terrible.  I'm telling you.  Different Google for every  user.

Start time: 3715.58
End time: 3716.15
Speaker: UNKNOWN
Transcript:  By the way, have you seen our

Start time: 3716.62
End time: 3717.05
Speaker: SPEAKER_13
Transcript:  Google Home?

Start time: 3717.76
End time: 3718.46
Speaker: UNKNOWN
Transcript:  Have you tried it yet?

Start time: 3719.63
End time: 3757.10
Speaker: SPEAKER_13
Transcript:  It smells really good.  Mmm.  Cinnamon and vanilla flavor.  That's new and probably not  going to last.  I'm going to put that far away.  Or show today.  Thank you.  That is a glade air freshener.  But I think that that's pretty  close in size and shape.  In the chat room, the gem  doctor says, you know, an Elvis  costume is such a waste of  money, a pantomime horse  costume, however, would be far  more useful.  That takes two.  That's the problem.  It takes two people to wear it.  Are you sure?

Start time: 3757.34
End time: 3758.41
Speaker: SPEAKER_03
Transcript:  You should not down for that.

Start time: 3760.36
End time: 3969.66
Speaker: SPEAKER_13
Transcript:  No, I'm not going to do it.  I'm tempted.  But I don't think there will be  a pantomime horse costume in my  order history.  No.  It's surprising what is in my  order history, though.  You can try a few things to see  what happens.  That's another kind of a leak of  information.  Yes, I know.  Wealthfront.  I know.  The show today brought you by  Wealthfront.com.  You invest, I hope, for the  long term for you and your  financial health, your family's  financial health.  You've got kids.  You've got kids going to  college someday.  It seems like that's a long way  off.  They're only eight years old.  Ten years is nothing.  Nothing.  Start putting money aside.  But obviously, you're not going  to put that in the savings  account at the bank.  You might as well put it in  your mattress if you're going  to do that.  It's just going to whittle away  nothing.  You need to invest it.  But how do you invest?  Do you hire somebody and pay  them one, two, three percent of  what you've got under  management?  By that time, you've got to  make three percent more just to  break even.  Are you going to do it  yourself?  That's what I thought.  I'll read all the books.  I'll be smart, and I'll learn.  And I did.  I think I did a good job 10  years ago.  I haven't checked in a while.  And that's the problem.  You need to kind of monitor this  stuff and rebalance and  rejigger and kind of keep an eye  on what's going on.  Well, I've got a way to do it  that doesn't cost you.  Three percent of what you've got  under investment doesn't cost  you any time that does a better  job than you could ever do  because it's watching all the  time.  It's called Wealthfront.  And because Wealthfront is  computerized, it's software  software works cheap.  One quarter of one percent a  year with no additional charges,  no transaction fees or  anything.  Wealthfront is really, really  interesting.  This was created by some very,  very smart people using  something called Mojave.  They're using something called  Modern Portfolio Theory.  It adjusts to your own personal  risk tolerance and your time  frame.  But it does stay diversified.  And tax-efficient, they use tax  loss harvesting to make sure  that you get the highest return  at the lowest tax cost to you.  It's really cool.  You can get this Wealthfront  dashboard where you can see  exactly what they're invested in  and for, you know, day by day,  hour by hour, minute by minute.  It's not now, of course, they're  constantly rebalancing, but it's  not day trading.  This is for long-term investing.  It's going to take a few minutes  to sign up.  I'm not saying do this right  away, but I do want you to go  right now to Wealthfront.com  slash twit and at least get the  portfolio analysis, answer just a  few questions about time frame  and risk, and they will actually  create a portfolio for you.  But they'll look at your existing  portfolio, see how much you're  spending in fees, how efficient  it is, what the tax  consequences are of your  investments.  And then every trade they make,  once you do invest, you're  going to see all of the  investments.  Every time you invest, you can  see right there, along with all  your other accounts, they put it  all in one big dashboard, whether  they're at Wealthfront or not.  Wealthfront is now managing  $3 billion in client assets  because it works.  It really works.  I want you to find out more.  Go to Wealthfront.com slash  twit.  $500 is the minimum investment,  so it's easy to test it out, but  I love this.  As a twit listener, you're going  to get $15,000 managed for free.  Your first $15,000 entirely free  of charge and not just for the  first year, but forever.  It's a great way to start your  nest egg.  If you haven't started saving  for retirement, for college, for  a house, for a vacation, for just  a rainy day fund, everybody had  to have one of those.  Wealthfront.com slash twit.  We thank them so much for their  support.  This week in tech.

Start time: 3970.32
End time: 3970.83
Speaker: SPEAKER_03
Transcript:  What a week.

Start time: 3972.47
End time: 3986.50
Speaker: SPEAKER_12
Transcript:  Well, AI is a good subject.  And I think Facebook is using  AIs to look at offensive photos  more effectively.  That's actually good, because I  once saw an article about the

Start time: 3986.98
End time: 3992.37
Speaker: SPEAKER_13
Transcript:  poor people who have to look at  every image.  What a horrible, horrible job  that must be.

Start time: 3993.06
End time: 3995.13
Speaker: SPEAKER_04
Transcript:  They get PTSD.  I mean, it's horrible.

Start time: 3997.11
End time: 4034.24
Speaker: SPEAKER_13
Transcript:  So Facebook now has an AI that  will go through all the pictures  and report offensive photos more.  In fact, they do a better job  than humans do, they say.  And here's the most important  thing that I really like.  At first I thought, oh, this is  dopey, but then this sentence  got me.  This is from TechCrunch.  AI could quarantine obscene  content or offensive content  before it ever actually is seen  by a human.  Not just that, but anybody,  right?  It can catch it that fast.  And I think that's great.  I mean, there's stuff that I  regret ever having seen, you  know?  Like me and an Elvis.  And it would be nice that nobody  ever had to see that at all.

Start time: 4035.67
End time: 4052.48
Speaker: SPEAKER_10
Transcript:  I did a story recently on  Whisper, which is using AI to  hide secrets which people post  to Whisper before they're  ever seen.  Whisper's still around?  They're still around, and  they're using AI for something  similar to what Facebook is  doing, but for text messages.  That was the big problem with

Start time: 4052.62
End time: 4057.50
Speaker: SPEAKER_13
Transcript:  Secret and Whisper and all of  these was that people were using  them to say really scurrilous  things anonymously.

Start time: 4057.62
End time: 4062.72
Speaker: SPEAKER_10
Transcript:  Whisper doesn't want you to be  able to do that, and they're  able to hide a lot of it without  humans being involved.  Not all of it, but an awful  lot.

Start time: 4063.93
End time: 4064.50
Speaker: SPEAKER_13
Transcript:  That would be great.

Start time: 4064.62
End time: 4067.87
Speaker: SPEAKER_10
Transcript:  And they also say that  computers are better at  moderating stuff than human  beings are.

Start time: 4069.23
End time: 4101.26
Speaker: SPEAKER_13
Transcript:  This I find hard to believe,  because obviously they've  gotten better than the days  where it would measure the  amount of flesh in a photo.  I mean, that's what it did,  right?  And if more than 30% was naked  flesh, well, we've got to  figure there's some nudity  here.  But how do you see a beheading,  for instance, and know what  that is?  That's got to be pretty  sophisticated.  Although when I think about how  Google Photos, what a good job  of categorizing my photos, all  of my beheading photos are in a  single folder, which is really  no, that's terrible.  I shouldn't make that joke.  And we've gone to beheading

Start time: 4101.87
End time: 4104.10
Speaker: SPEAKER_03
Transcript:  you.  Wow.  Really, that's a new,

Start time: 4104.76
End time: 4107.26
Speaker: SPEAKER_13
Transcript:  that's a new rule.  Was it Periscope this week?

Start time: 4107.46
End time: 4177.02
Speaker: SPEAKER_04
Transcript:  Yeah, Periscope has a new...  I like this idea.  A jury system.  Yeah, so they're going to have  sort of crowdsourcing the  comments that are deemed  offensive.  So if someone who's  broadcasting sees a comment  that's offensive, they can  flag it, and then the person  who is in that broadcast  viewing it, a select group will  be chosen...  Randomly.  Randomly to vote on whether  they felt that that comment was  inappropriate, offensive, or  abusive.  It's a little, the way they  described it is a little bit  laborious because those seven  or eight people vote, and then  the results of that vote are  shown to the entire group, and  then they decide if the  commenter should be banned from  commenting anything that  is in that broadcast.  And that's the other thing that  I find to be a little bit of a  problem here is that the  penalties are kind of limited.  Right.  You'd like to see them maybe do  that on a one-time basis, but  if someone, if one user is  banned repeatedly, maybe then  they have a more serious  repercussion.  But the idea of crowdsourcing  comments.  Thoughts?  I think this is interesting

Start time: 4177.14
End time: 4190.86
Speaker: SPEAKER_13
Transcript:  mostly because they choose a  jury randomly.  So that would, I would think,  eliminate kind of mob rules  and ganging up on people and  stuff, but maybe not.  I think it's a great social  experiment.  I'll be very curious what  happens.  And it's like the opposite of AI.

Start time: 4191.06
End time: 4193.70
Speaker: SPEAKER_10
Transcript:  It's using actual human brains.  Well, we know ultimately aren't

Start time: 4194.36
End time: 4198.88
Speaker: SPEAKER_13
Transcript:  human brains better at this.  Maybe not.  I don't know.  Facebook says not.

Start time: 4199.02
End time: 4221.86
Speaker: SPEAKER_10
Transcript:  I don't think so given there are  so many examples of humans  either not moderating stuff they  should have or moderating stuff  they shouldn't have moderated.  It is so fuzzy and it, almost  none of this is binary.  And even, I mean Facebook has  rules which they don't entirely  understand.  Saying things like beheadings  are okay if you're not putting  them up there because you love  beheadings.  Right, it's a news story.  Because you hate beheadings and  it's okay.  How do you know, right?

Start time: 4222.10
End time: 4224.72
Speaker: SPEAKER_13
Transcript:  What's the sentiment?  We can talk about AI all day

Start time: 4225.08
End time: 4242.86
Speaker: SPEAKER_04
Transcript:  long, but fair use, which is  basically, I mean whether you  look at it in the legal context  or in this context of posting  something that's inappropriate  in one context but appropriate  in another, that is got to be  one of the hardest things for  humans and let alone, I think

Start time: 4243.36
End time: 4247.63
Speaker: SPEAKER_13
Transcript:  Google Oracle trial, they had a  judge fair use, right?  Wow.

Start time: 4248.04
End time: 4261.35
Speaker: SPEAKER_04
Transcript:  Yeah, on that, no thanks.  Right.  Yeah, have you ever come,  reading comments on Facebook,  I'm just picking Facebook  randomly, have you ever hit the  abusive button to report abuse?  Never.  Never.

Start time: 4262.31
End time: 4268.35
Speaker: SPEAKER_13
Transcript:  You don't see them.  Maybe I don't see them.  Now on Twitter I would do it at  least 50% of the time.  Really?  Oh yeah.

Start time: 4269.04
End time: 4270.90
Speaker: SPEAKER_10
Transcript:  On Twitter for a while I would  always report spammers.

Start time: 4271.31
End time: 4281.07
Speaker: SPEAKER_13
Transcript:  Yeah.  Twitter could use some of these  things.  I think it's interesting that  Periscope's doing this because I  would wonder if this goes well  in Periscope, Twitter owns  Periscope, maybe they could  apply this to tweets.

Start time: 4283.59
End time: 4289.20
Speaker: SPEAKER_04
Transcript:  I like the idea of the people  who are in the content being  polled to make the decision.  Right.

Start time: 4290.02
End time: 4298.35
Speaker: SPEAKER_13
Transcript:  And you can do that with a  live stream.  Because they know the context,  they're watching the video, they  know contextually is that an  offensive comment in this  context.

Start time: 4299.04
End time: 4303.90
Speaker: SPEAKER_04
Transcript:  So would that be enough, I mean  I'm trying to think, draw the  parallel to Twitter.  Twitter you can't really.

Start time: 4304.24
End time: 4317.39
Speaker: SPEAKER_13
Transcript:  We just have to be based on  what you said.  Yeah.  But still I think I like the  idea of a randomly selected  jury.  You're always a wisdom of  crowds guys.  Who would it be though, yeah I  like that.  I like the wisdom of crowds.  It's the individuals I hate.

Start time: 4318.83
End time: 4325.65
Speaker: SPEAKER_10
Transcript:  I mean in theory Twitter should  be able to identify who the most  upstanding members of their  community are at least in some  respects.

Start time: 4326.06
End time: 4328.72
Speaker: SPEAKER_13
Transcript:  Would it be people following  that person and the other  person?

Start time: 4329.04
End time: 4333.61
Speaker: SPEAKER_10
Transcript:  They know which people get  followed a lot, they know which  people get liked a lot.  A lot of likes.

Start time: 4335.02
End time: 4343.64
Speaker: SPEAKER_13
Transcript:  What if it became a captcha,  like whenever you logged into  Twitter it said okay and just to  prove you're not a robot is this  offensive?  That's, well it's like, well

Start time: 4344.04
End time: 4352.23
Speaker: SPEAKER_04
Transcript:  didn't they say people were  using porn to get captchas done  so you could use porn to get  comments.  Before you see Mary Jo and her

Start time: 4354.93
End time: 4360.29
Speaker: SPEAKER_13
Transcript:  friends, is this offensive?  That's the wrong people to ask.  Right.  The barrier is low, the bar is  low.

Start time: 4361.02
End time: 4361.90
Speaker: SPEAKER_14
Transcript:  But Twitter are more than almost

Start time: 4361.92
End time: 4372.04
Speaker: SPEAKER_10
Transcript:  anything, context is everything  because almost no tweet ever  stands alone.  You have to read the tweets  before it and the ones that  follow and sometimes you need to  know whether the people tweeting  each other know each other or  not.

Start time: 4372.90
End time: 4428.96
Speaker: SPEAKER_13
Transcript:  I wonder how many people are on  the team at Twitter.  It's got to be fairly big that  the abuse team that reviews  these.  This actually is a time lamp  truck.  Who was it that suggested you  send pizza to the Twitter?  I read a Medium post and I was  surprised by a guy who said I  probably shouldn't talk about  this.  I think it was today or  yesterday.  But I'm being trolled on Twitter  and these people have ordered  pizza sent to my house and let  me see if I can find the  article.  It's a very short article.  And he says how it was, how he  was going to respond.  At the end of it he said I think  everybody reading this should  send pizzas to the Twitter team.

Start time: 4429.78
End time: 4430.64
Speaker: SPEAKER_04
Transcript:  Just to let them know what it's

Start time: 4430.78
End time: 4439.00
Speaker: SPEAKER_13
Transcript:  like to be trolled in this way.  Yeah.  His complaint was that they were  slow to respond.  I've not found that to be the  case but I can't find the  article.

Start time: 4441.78
End time: 4458.82
Speaker: SPEAKER_04
Transcript:  Are we going to, when it comes  to this issue, this seems to be  reaching a crescendo pitch right  now about abuse and the fact  that these services are not  handling it well.  What's your feeling that we will  either collectively get a thicker  skin or technology will solve the  problem?

Start time: 4460.43
End time: 4463.54
Speaker: SPEAKER_12
Transcript:  Oh, gosh, I don't think we're  going to get a skin that thick.  I don't think we'd ever get a

Start time: 4463.97
End time: 4498.38
Speaker: SPEAKER_13
Transcript:  skin that thick.  Really?  Some of this stuff is really  terrible.  Why do you think Snapchat is  suddenly more popular than  Twitter?  In fact, this was the week that  it surpassed Twitter in daily  users.  150 million people use Snapchat  every day.  That's more than Twitter, which  is 140 million.  I think it's because you don't  get abuse on Snapchat, right?  It's just your buddies and your  friends sending you stuff.  It's also the fact that nothing  survives, nothing lives, it's  temporary.  My kids, Henry loves Snapchat.  That's what he uses all the time.  Your kids are too young.  Well, it's meant to be ephemeral

Start time: 4498.58
End time: 4504.02
Speaker: SPEAKER_04
Transcript:  and therefore there's not as  much meaning in what you do.  And your boss, your future boss

Start time: 4504.54
End time: 4514.14
Speaker: SPEAKER_13
Transcript:  isn't going to check it out when  you apply for a job in two years  and I think that, I don't know,  if I were Twitter, I'd be a  little nervous about the whole  thing.  Well, it does seem like the

Start time: 4515.09
End time: 4522.71
Speaker: SPEAKER_04
Transcript:  fractured social ecosystem is  cracking even more and it just  feels like tribes.  I think we went through an era  where people thought, hey, it's

Start time: 4523.50
End time: 4565.18
Speaker: SPEAKER_10
Transcript:  the web, it should be open, it  shouldn't be censored.  I also think about the fact that  lately a lot of websites have  done away with comments because  people in comments are saying,  hey, you're a good person, you  should be able to do this because  people in comments are so  horrible and a lot of them are  trolls or just basically horrible  people.  In the old days you would have  said you need to let these  people speak and today people are  more likely to say, no, this  stuff is horrible, it's not  improving the experience.  If you're not a troll, it's  making it unbearable to go to  these sites and so I think we're  sort of entering an era where  it's not only acceptable but  preferable not to let every  person run wild on the internet

Start time: 4566.01
End time: 4594.12
Speaker: SPEAKER_13
Transcript:  and so I think we're entering a  era where we're not going to  be able to do this.  I feel like we, certainly I  initially I was a wide-eyed  optimist about all of this and I  said, oh, democracy, everybody  has a voice and when everybody  is talking and you're shining  light on everything, even if you  turn over a rock and there's  something horrible, the light of  day will cleanse it and in the  long run the good stuff will  out.  I really believed that.  Boy, was I wrong.

Start time: 4594.18
End time: 4603.90
Speaker: SPEAKER_10
Transcript:  I think the world has it.  And a tiny, tiny number of  trolls can make life unbearable  for the vast majority of people  on the internet who are thoroughly  decent people.

Start time: 4604.40
End time: 4659.82
Speaker: SPEAKER_13
Transcript:  You know, I made my, I changed  my Twitter nickname to be my  name with three parentheses  around it because that, as you  know, that's the new dog whistle  for anti-Semitism.  Did you know about this?  No.  Yes.  I guess it originated at a  well-known anti-Semite site.  They wanted to highlight that  this person is Jewish.  And the way they did it was, you  know, a dog whistle is something  that normal people won't hear,  but the people who you're aiming  at will hear, like a dog will  hear a high-pitched whistle.  By putting this, hugs, what used  to be hugs around this name, it  was a dog whistle to other  anti-Semites that this is a  Jewish person.  And so I wanted, in solidarity, I  thought, well, we should all just  do this and that would just go  away.  Huh.  Isn't that reprehensible?  So they publish on Twitter and  other places names of Jewish  people with these parentheses.  They had a Chrome extension to

Start time: 4660.24
End time: 4670.08
Speaker: SPEAKER_10
Transcript:  help them manage their...  They wrote a Chrome extension.  Yep.  Which Google just got rid of  recently until recently it was  available.  Yeah.

Start time: 4672.53
End time: 4711.19
Speaker: SPEAKER_04
Transcript:  I'd say, I live in more of the  everyday where you don't see it  as much.  I just feel like, you know,  so many people go through life  kind of with the Amazon reviews  philosophy, which is don't read  the five-star reviews, don't  read the one-star reviews, just  look for the middle and try and  ignore the top and the bottom.  Yeah.  But like you said, there are  certain things you can't unsee  and when things strike a chord  and they're critical, I think it  does, it damages your...  It damages the Internet because  you don't want to put yourself  out there like that in that way  in all of these social platforms  but, ugh, that's horrible.

Start time: 4712.28
End time: 4760.64
Speaker: SPEAKER_13
Transcript:  It is a little bit of a  disappointment to me that what I  thought would be this amazing  democratizing force has just  turned out to be a way to spread  hate and vile filth and I think  it's a small number.  Yeah.  And what it turns out is that  this small number has a megaphone  just like the rest of us and so  it appears...  They can find each other.  Yeah, they can find each other  and in fact maybe even they're  using the megaphone and I have to  point at the presidential election  which is coming up in this  country and the candidate that  has benefited the most from  Twitter is Donald Trump because  it is an unmediated, unfiltered  way for him to express himself  and to find an audience for what  he believes.

Start time: 4761.91
End time: 4765.40
Speaker: SPEAKER_04
Transcript:  It also rewards those who  authentically speak.

Start time: 4765.82
End time: 4772.95
Speaker: SPEAKER_13
Transcript:  Well isn't that interesting  because he's, of all the candidates,  the only one who's using his own...  If he's got somebody posting this  for him, they're doing a really  good job.

Start time: 4773.76
End time: 4774.86
Speaker: SPEAKER_10
Transcript:  He dictates a lot of them.  Yeah.

Start time: 4775.84
End time: 4856.94
Speaker: SPEAKER_13
Transcript:  Hey, write a Twitter for me.  This is huge.  You can tell he's dictating it  because it's so off the cuff  that if you actually wrote it down  you would say,  well I'm not going to post that.  But because it's just like  something...  It's like him...  It's like Tourette's.  Hey, Joe, write this!  And it gets written.  It's like, I mean really.  So the article, if you want to  read about these things...  It comes from a Mike,  M-I-C magazine.  It's about the three parentheses.  I guess I thought it was  fairly widely known.  The secret symbol neo-Nazis  used to target Jews online.  People are probably wondering  why I wrote my name  with hugs around it now.  That's why.  I wanted a hug.  I'm no depressed.  It came from an editor  at the New York Times  who wrote a story about a week ago  about how he has been harassed  using this dog whistle.  And he didn't know  why are you putting my name  in parentheses.  And somebody tweeted at him,  it's a dog whistle fool  belling the cat  for my fellow goyim.  So it turns out we turn over the rock  and all the snakes slither out  in the public go,  hey, nice out here!

Start time: 4857.50
End time: 4865.34
Speaker: SPEAKER_04
Transcript:  We have a platform!  I just think that we'll,  we will end up finding more tools  to be critical users of the internet.  You know, I mean...

Start time: 4865.52
End time: 4867.55
Speaker: SPEAKER_13
Transcript:  Is it foolish of us  to think that AI can help?

Start time: 4868.46
End time: 4870.32
Speaker: SPEAKER_10
Transcript:  AI is already helping.  It can help more.

Start time: 4870.56
End time: 4873.13
Speaker: SPEAKER_12
Transcript:  Can it?  Good.  I hope you're right.

Start time: 4874.46
End time: 4878.89
Speaker: SPEAKER_04
Transcript:  Slight sidebar.  How many reviews on Amazon,  what percentage do you think are fake?

Start time: 4881.46
End time: 4890.28
Speaker: SPEAKER_13
Transcript:  That's a really good question.  Do you,  and the secondary question is,  do you think you can tell?  Like, do you know what,  I know it's a fake review  because it's a glowing review  of a product nobody ever heard of.

Start time: 4890.50
End time: 4896.91
Speaker: SPEAKER_04
Transcript:  Old days, I think you could tell.  Not anymore.  The sophistication has gone up.  Pick a number.  What number do you think,  like...

Start time: 4898.50
End time: 4899.32
Speaker: SPEAKER_10
Transcript:  I was going to say 22.

Start time: 4899.46
End time: 4899.89
Speaker: SPEAKER_13
Transcript:  One in five.

Start time: 4900.48
End time: 4913.28
Speaker: SPEAKER_04
Transcript:  Okay, there's some numbers  that say 13 to 15%  of all the reviews online are fake.  Those are the numbers  that have been published  by people who've studied them.  That's not so bad.  So like your TripAdvisor...  Yelp.  Yelp.  I mean, these are older numbers.

Start time: 4913.48
End time: 4936.04
Speaker: SPEAKER_13
Transcript:  But see, it's more,  so for instance,  Yelp, it's higher, I'm sure,  because every business owner  writes a Yelp review  that's positive of his business  and then goes and writes  the bad reviews  of all the competitors.  I'm sure that happens  a lot more on Yelp.  I'd say it's more like  50% on Yelp.  And Amazon, it feels like  it would be a little bit better,  especially because  you can kind of tell  if somebody's used the product  and if it's a real review.

Start time: 4936.34
End time: 4939.50
Speaker: SPEAKER_04
Transcript:  Well, remember,  you have to purchase the product  to write the review.  Right.

Start time: 4940.38
End time: 4942.22
Speaker: SPEAKER_13
Transcript:  If you're a verified purchaser,  that's going to be...

Start time: 4942.34
End time: 4943.44
Speaker: SPEAKER_04
Transcript:  Of that product.  Right.

Start time: 4944.75
End time: 4946.22
Speaker: SPEAKER_13
Transcript:  Exactly.  A more valid review.

Start time: 4946.34
End time: 4948.20
Speaker: SPEAKER_04
Transcript:  Right.  So if you're going to

Start time: 4948.34
End time: 4957.49
Speaker: SPEAKER_13
Transcript:  buy a review this week,  it's less than 1%.  That low?  Wow.  Do you think they're lying?  They are now suing people who...  Sellers who buy fake reviews.

Start time: 4958.36
End time: 4965.82
Speaker: SPEAKER_04
Transcript:  Right.  So back in April,  they sued about a thousand people  who had written fake reviews.  Now, that was just going for the

Start time: 4966.48
End time: 4967.02
Speaker: SPEAKER_13
Transcript:  small fish.

Start time: 4967.36
End time: 5005.88
Speaker: SPEAKER_04
Transcript:  But there's businesses  that do this, right?  Right.  So they were going for  the small fish,  and I thought,  that's weird.  Why would they be playing  a game of Whack-a-Mole  if they were using the information  from those lawsuits  to find out who was buying  the fake reviews?  So now they're going  after the sellers.  And now they're going after  the alleged purchasers  of the fake reviews  who are profiting from the fraud,  allegedly.  Right.  And they've shut those sellers down.  They have an arbitration agreement,  so they don't actually  take them to court.  They take them to arbitration,  but they have in their EULA,  they can shut them down,  and they're clearly sending  a message to other sellers.

Start time: 5007.03
End time: 5009.22
Speaker: SPEAKER_13
Transcript:  And they're suing for damages  in some cases.

Start time: 5009.34
End time: 5011.18
Speaker: SPEAKER_04
Transcript:  Yeah, I think so.  One percent seems low.

Start time: 5011.34
End time: 5013.83
Speaker: SPEAKER_13
Transcript:  I think it's higher than that,  don't you?  I was shocked.

Start time: 5014.78
End time: 5017.20
Speaker: SPEAKER_04
Transcript:  They did say that they have a really...

Start time: 5017.40
End time: 5022.39
Speaker: SPEAKER_13
Transcript:  And how do they know,  I guess, would be the question.  How would they know?  They're using algorithms

Start time: 5023.34
End time: 5026.38
Speaker: SPEAKER_04
Transcript:  to figure out  what are repeated phrases.  So...

Start time: 5027.34
End time: 5035.22
Speaker: SPEAKER_13
Transcript:  You know, syntactic analysis  would probably work,  wouldn't it?  Because if you're writing  fake reviews,  you're going to probably use  those same phrases in multiple reviews.

Start time: 5035.54
End time: 5047.22
Speaker: SPEAKER_04
Transcript:  Right, especially if you're  making that...  Interesting.  ...small amount of money.  They think that a lot of this stuff  is done out of the country,  so they're looking for  non-English speaking reviews,  and they're looking harder at those.

Start time: 5047.40
End time: 5056.25
Speaker: SPEAKER_13
Transcript:  Somebody in the chat room,  the takeaway for this is  I can make $10  when I take reviews?  Where would I go to do that?  Let me tweet that link to you guys.  Let me hook you up.

Start time: 5057.65
End time: 5060.16
Speaker: SPEAKER_03
Transcript:  Work from home!  I saw that posted  on a telephone pole.

Start time: 5060.42
End time: 5072.10
Speaker: SPEAKER_13
Transcript:  But honestly,  while I agree Amazon  and Yelp and everybody else  should do the best they can  to get rid of these,  can't we kind of tell?  I feel like I can.  Yeah, when I buy something,  I always read the Amazon reviews  before I buy it.  And it's the negative information

Start time: 5072.22
End time: 5097.08
Speaker: SPEAKER_10
Transcript:  in reviews that's most helpful.  That's the key.  It's not the plus,  thumbs up or thumbs down,  it's the information.  Even if it's a great product,  what you want to know  is any potential pitfalls,  and no matter how many  favorable reviews,  somebody's stuff's in there,  you can't prevent other people  from exposing the pitfalls.  Even for the most obscure product  on Amazon,  like some iPhone case  from a company you've never heard of,  there do seem to be actual reviews  from Amazon.  Are there actual people  who tell you what it's like?

Start time: 5097.59
End time: 5108.63
Speaker: SPEAKER_04
Transcript:  That's why I think  the best product reviewers  are curmudgeonly grumpy,  detail-oriented,  you know,  I'm the worst...  Dvorak.  I wasn't...

Start time: 5109.22
End time: 5109.73
Speaker: UNKNOWN
Transcript:  But wait a minute,

Start time: 5110.22
End time: 5127.53
Speaker: SPEAKER_13
Transcript:  I got to tell you,  that may not be true.  Dvorak once told me  he could review a product  just by looking at the box.  Although, I think in some cases,  this was talking about software,  but I think in some cases  he was right.  You can look at the box and go,  oh, that's not going to be good.  That's not going to be good.  But I think you normally  would want to install it  just to try it.

Start time: 5129.57
End time: 5129.98
Speaker: UNKNOWN
Transcript:  But you're right,

Start time: 5130.10
End time: 5136.65
Speaker: SPEAKER_13
Transcript:  cranky is good,  picky is good.  Right,  because they give you detail.  Finicky is good.  And you know enough to go,  well, he's being picky,

Start time: 5137.10
End time: 5141.82
Speaker: SPEAKER_10
Transcript:  I'm going to ignore that one.  Right.  Amazon also pushes up  the best negative reviews  to the top,

Start time: 5142.10
End time: 5167.80
Speaker: SPEAKER_04
Transcript:  so it's easy to find them.  They did say  the ranking is really important,  and one thing I hadn't thought about  before is that they do  a date-based ranking  because products change,  even though it's the same skew  and the same,  the product might have been  listed on Amazon  for the last six years,  but the product has changed  incrementally,  so a review that might be  really popular  from way back when,  it may have been  completely resolved by now.  They do have to fix that.

Start time: 5168.02
End time: 5174.84
Speaker: SPEAKER_13
Transcript:  I sometimes will go to a site  and it will be a review  of a related but different  product on Amazon, right?  That happens to me a lot.  And some of the best  Amazon reviews

Start time: 5175.06
End time: 5191.86
Speaker: SPEAKER_10
Transcript:  are from somebody  who bought a camera  and used it for nine months,  which professional reviewers  will almost never do.  That's what you want.  They'll buy on camera.  That's why I like it.  They'll try to have the review out  and the camera ships.  I love reviews.  There's all kinds of stuff  they'll never discover  that you will discover  if you use it for a long time.

Start time: 5192.02
End time: 5207.73
Speaker: SPEAKER_13
Transcript:  All right, let's take a break.  Come back with more.  Harry McCracken is here  from FastCompany.com  from GMA.  Becky Worley,  glad you're here today.  We had a good week on Twitter.  Hey, Becky.  Caught you  right in the middle of a drink.  Water this time.  Hey, by the way,  weren't we going to  have booze today?

Start time: 5208.98
End time: 5209.49
Speaker: SPEAKER_03
Transcript:  I'm being good.

Start time: 5210.02
End time: 5212.84
Speaker: SPEAKER_13
Transcript:  I don't know.  Are you okay?  You didn't bring wine.

Start time: 5213.02
End time: 5216.41
Speaker: SPEAKER_04
Transcript:  I'm fine.  I'm fine.  I'm fine.  You know,

Start time: 5217.00
End time: 5218.86
Speaker: SPEAKER_13
Transcript:  I was so excited  about all this stuff.

Start time: 5219.02
End time: 5221.86
Speaker: UNKNOWN
Transcript:  Let's all get in the hot tub  and talk about Sims.

Start time: 5222.72
End time: 5231.35
Speaker: SPEAKER_13
Transcript:  Huh?  Anthony Wiener.  Wiener.  Wow.  Anthony Nielsen,  who for some reason  I continually call Anthony Wiener.

Start time: 5232.10
End time: 5233.84
Speaker: SPEAKER_03
Transcript:  That's something  you wish you could unsee.

Start time: 5234.04
End time: 5242.53
Speaker: SPEAKER_04
Transcript:  Is that Freudian?  That is like a combination  of the Gawker story  and the Facebook image story.  That's what it is.  I'm burning.  Some stories need to be  challenged to power,  but you don't need

Start time: 5242.98
End time: 5247.76
Speaker: SPEAKER_10
Transcript:  to do so.  You know,  it's a great documentary,  a great documentary,  by the way,

Start time: 5248.06
End time: 5251.74
Speaker: SPEAKER_13
Transcript:  we just saw.  Of Anthony Wiener?  The Wiener documentary.  It is really good.

Start time: 5252.08
End time: 5271.70
Speaker: SPEAKER_10
Transcript:  So, what's the  bottom line on that?  Well, he and his wife  allowed a camera crew  to follow them  when he was running for mayor,  and they were incredibly  open around the camera crew,  and even after his campaign  melted down,  they continued  to allow the camera crew  to follow them,  and it's the most

Start time: 5272.19
End time: 5272.72
Speaker: SPEAKER_04
Transcript:  interesting thing

Start time: 5273.04
End time: 5273.70
Speaker: SPEAKER_13
Transcript:  for Hillary Clinton.

Start time: 5274.02
End time: 5275.21
Speaker: SPEAKER_04
Transcript:  Yes.  Interesting.

Start time: 5276.56
End time: 5278.62
Speaker: SPEAKER_12
Transcript:  She does.  Oh, I got to see that.  What's it called?

Start time: 5278.96
End time: 5280.74
Speaker: UNKNOWN
Transcript:  The Wiener?  What else could it be called?

Start time: 5281.25
End time: 5284.74
Speaker: SPEAKER_13
Transcript:  Wiener.  If you thought  you were going to get  a hot dog documentary,

Start time: 5285.17
End time: 5287.51
Speaker: SPEAKER_04
Transcript:  no.  Wiener House?  Isn't that a chain?

Start time: 5288.86
End time: 5456.63
Speaker: SPEAKER_13
Transcript:  Is your Wiener schnitzel?  We are Wieners.  This episode of  This Week in Tech  brought to you by stamps.com.  I know a lot of you sell online.  This is very popular.  What is your package  when you send it?  What does it look like?  Your Etsy or your eBay,  wherever you sell.  Does it wrapped in brown paper  with twine and then a bunch of  licked stamps on there  and a handwritten address?  That does not cast.  I mean, first of all,  your buyer may be reluctant  to open it.  I know I am.  Like, what is this?  Stamps.com makes it look  professional.  With stamps.com,  you can buy and print  real U.S. postage  right from your computer  and your printer.  You do not need a postage meter.  You just need a printer  and a computer.  And it looks great  and you can print a label  for any kind of mailing.  You can print right on the envelope  if you are sending out brochures  or bills or whatever  with your company logo.  It automatically puts  your return address in.  It will take the address  of the recipient  from your address book.  It reads almost all kinds  of address books.  If you sell on eBay  or Amazon or Etsy  or a bunch of other websites,  it will actually get  the information from the website  so it saves you typing.  And it will automatically validate  the address using  the Postal Service Database  and make sure you have  got exactly the right postage.  It does that with this USB scale.  I will tell you what,  I am going to get you the scale  and I am going to get you  Stamps.com for a month  for free and I am going to get you  $55 in postage coupons.  So I have got a really good way  to try Stamps.com.  Visit Stamps.com  in the upper right hand corner.  There is a microphone.  Do you see it?  Go to the top.  There it is.  It says,  heard us on a podcast?  Click the microphone  and use a tweet  when it asks for the offer code.  Just type in TWIT.  That is how you get  the really good trial offer.  The postage scale is awesome.  I will tell you how much  the item weighs.  It will give you mailing options  for all classes of mail,  even certified mail.  It will fill out the forms  for certified mail  and for express mail  so you do not have to.  Customs forms if you have them.  It fills them out.  It does all the work for you.  You never have to go to the post office.  The mail carrier comes,  picks it up.  It is awesome.  Stamps.com.  Make everything you see  everything you sell online.  Make it all look super pro,  super cool.  If you have a business  that does mailing,  we even use it.  We do not do a lot of mailing,  but we do enough  that it is really worthwhile.  Stamps.com.  Get our special  $110 bonus offer  by going to Stamps.com,  clicking the microphone  in the upper right hand corner  and using the promo code  TWIT.  Good week on TWIT this week.  We have a little mini movie.  I think Victor put this together  for us to show you  some of the highlights.  Watch.  Previously,  on TWIT.  I love your setup.  Wow.  Is this your man cave?  This is a Mac cave, yeah?  Yeah.  Totally Mac.  Have you heard the good word  about Linux?  No.

Start time: 5457.67
End time: 5457.99
Speaker: SPEAKER_06
Transcript:  Stop.

Start time: 5458.46
End time: 5458.91
Speaker: UNKNOWN
Transcript:  Next time,

Start time: 5459.42
End time: 5467.24
Speaker: SPEAKER_05
Transcript:  on TWIT Live Specials.  We are here at AWE,  the Augmented World Echo.  Excited.  To take a look at the  latest and greatest  in augmented reality.

Start time: 5467.68
End time: 5481.00
Speaker: SPEAKER_08
Transcript:  Augmented is really a better  technology for welding training.  Not only you can see  how you are welding,  the system will give you  the feedback on how you are doing.  It will tell you if you ruin it.  And see how you need to improve.  That was really cool.  What we are going to do is

Start time: 5481.28
End time: 5501.14
Speaker: SPEAKER_05
Transcript:  we are actually going to show you  the process.  The process that we use here  on KnowHow.  From just downloading  and printing objects.  Exactly.  Downloading and modifying  and maybe even  even mention that.  You don't have to set your hair  on fire.  It's all based on finding  something in the real world  that you want to fix  or you want to improve  and then somehow making it better.  All about Android.

Start time: 5501.46
End time: 5502.94
Speaker: SPEAKER_02
Transcript:  Blueberg last week had a report

Start time: 5503.30
End time: 5507.86
Speaker: SPEAKER_13
Transcript:  about how Google is looking  to revealing  an Android update report card.

Start time: 5508.14
End time: 5514.94
Speaker: SPEAKER_14
Transcript:  They want to like make a list  and hand out gold star stickers  like it's kindergarten  and you are going to like  get the kids to try harder.

Start time: 5515.24
End time: 5517.02
Speaker: SPEAKER_13
Transcript:  You did such a great job  with that article Ron.

Start time: 5517.75
End time: 5518.00
Speaker: SPEAKER_05
Transcript:  Tweet.

Start time: 5518.79
End time: 5530.45
Speaker: SPEAKER_13
Transcript:  Some assembly required.  Gold star for Ron.  We got a week ahead.  Who is it?  Jason or Megan?  Megan Maroney from Tech News Today  taking a look at what's ahead.  Thanks Leo.

Start time: 5531.30
End time: 5592.66
Speaker: SPEAKER_01
Transcript:  Coming up this week  it's the deadline  for the second round of bids  for Yahoo.  Anyone want to make an offer?  Anyone?  Twitter?  Yes, many sources are reporting  that Twitter has discussed  a merger with Yahoo.  Which sounds to me  a little like one drowning person  hanging on to another.  Fortune reports that it's unclear  whether the talk  for serious or not.  Verizon still seems to be  the front runner  in the race to purchase Yahoo.  In other news,  Xiaomi will start selling  its Mi Band 2 in China this week.  That's a fitness tracker  with a heart rate monitor  and it has a 20 day battery life  and you can get all of that  for only $23.  We chatted about the announcement  on last Thursday's Tech News Today  so download that to watch or listen  if you're interested  in finding out more.  Also this week at Lenovo World  we expect to see  Google's first project Tango Phone  and we think that we will see  new Moto and new Droid phones.  You will hear all about this news  and a whole lot more  on Tech News Today  hosted by Jason Howell  and myself every weekday  at 4pm Pacific, 7pm Eastern.  Back to you Leo.  Thank you Megan Maroney.

Start time: 5593.01
End time: 5598.66
Speaker: SPEAKER_13
Transcript:  Make sure you watch TNT.  That's a good show  and listen,  this one here shows up  from time to time.  Oh those two together

Start time: 5598.92
End time: 5605.46
Speaker: SPEAKER_04
Transcript:  just they're so great  and they are thoughtful  and insightful  and just such nice people  and it comes across.  I love listening.  Is that credible

Start time: 5605.78
End time: 5608.60
Speaker: SPEAKER_13
Transcript:  that Twitter might buy Yahoo?  No.  It sounds like

Start time: 5608.78
End time: 5612.62
Speaker: SPEAKER_10
Transcript:  that's an old rumor  rather than something recent  from what I can tell.  I don't think Twitter has the money.

Start time: 5612.84
End time: 5625.46
Speaker: SPEAKER_13
Transcript:  We're talking not $8 billion.  That was the original  but we're still talking  $3 or $4 billion to buy.  I don't know.  It doesn't make any sense.  They're not going to out-pick  the phone companies  that are interested in it.  Verizon, right?  Yeah.  I think they seem  like the most likely.

Start time: 5625.88
End time: 5626.66
Speaker: SPEAKER_04
Transcript:  They want those emails.

Start time: 5626.78
End time: 5634.50
Speaker: SPEAKER_13
Transcript:  Isn't that sad?  That's all it is.  Ugh.  It's just the information  about users  after all this time.  Poor Yahoo.

Start time: 5634.78
End time: 5638.39
Speaker: SPEAKER_04
Transcript:  It's like seeing  your brother-in-law  go and drinking again.  You don't drink

Start time: 5638.80
End time: 5640.62
Speaker: SPEAKER_13
Transcript:  there anymore.  I don't drink there anymore.

Start time: 5640.78
End time: 5647.66
Speaker: SPEAKER_03
Transcript:  You don't work there anymore.  You don't work there anymore.  My brother-in-law  needs to go to rehab.  It's so sad.  I thought he pulled it together.

Start time: 5648.11
End time: 5649.64
Speaker: SPEAKER_13
Transcript:  Oh no.  Back in the gutter.

Start time: 5649.78
End time: 5659.17
Speaker: SPEAKER_04
Transcript:  A lot of good people there.  A lot of good people  there.  I still believe in Yahoo  as a news platform  and I think they do  have potential there.  They just have to figure out  their business model  and figure out

Start time: 5659.82
End time: 5678.66
Speaker: SPEAKER_13
Transcript:  what they're going to do  with themselves.  I don't blame them at all.  I think that was  a very difficult challenge  and I think Marissa Meyer  knew it.  We said it  when she went there.  She must have looked  at this and said,  well, if I can do this,  I can do anything.  And she couldn't  because it was just  a challenge.  I don't know what  would you do with Yahoo?

Start time: 5678.80
End time: 5679.66
Speaker: SPEAKER_04
Transcript:  I don't know what you would do.

Start time: 5679.78
End time: 5681.88
Speaker: SPEAKER_13
Transcript:  How many hours you got?  Yeah.  No.

Start time: 5682.90
End time: 5683.17
Speaker: UNKNOWN
Transcript:  No.

Start time: 5683.86
End time: 5691.37
Speaker: SPEAKER_13
Transcript:  What do you do with Twitter?  It's the same problem, right?  What do you do?  It's not that the Twitter...  Now, at least Twitter's  making money.  Actually, Yahoo's  still making money, right?

Start time: 5692.03
End time: 5695.07
Speaker: SPEAKER_04
Transcript:  Yeah.  Their revenues come down  significantly.  You know what?

Start time: 5695.84
End time: 5724.54
Speaker: SPEAKER_13
Transcript:  Both of these companies  could just continue  doing what they're doing  and make money  and everybody be happy.  It's the stock...  The shareholders  that are really forcing this.  In a way, I think  that's an unfortunate thing.  The activist investors  and people who want...  I want money  and money for my shares.  And I think  that's forcing the company  to kind of do things  that they don't want to do  and if they're not growing  quite fast enough to sell.  And in a way,  I think it's kind of unfortunate.  Is Yahoo really doing that bad?

Start time: 5724.91
End time: 5729.33
Speaker: SPEAKER_10
Transcript:  They've been shrinking.  I mean, their ad revenue  has been going down,  which is not a good thing  in any context.

Start time: 5731.13
End time: 5733.34
Speaker: SPEAKER_13
Transcript:  Yeah, but they're not  about to go bankrupt  or anything.

Start time: 5733.66
End time: 5738.54
Speaker: SPEAKER_10
Transcript:  No.  Shrinking.  They're in a market  that's growing  and they've been shrinking.

Start time: 5738.70
End time: 5744.03
Speaker: SPEAKER_13
Transcript:  Are they really  in a market  that's growing?  I mean, aren't...  That's, I guess,  the question.

Start time: 5744.70
End time: 5747.46
Speaker: SPEAKER_10
Transcript:  It's growing,  except Facebook  is getting most of the growth.

Start time: 5747.66
End time: 5762.27
Speaker: SPEAKER_04
Transcript:  Right.  Okay, let's just have a quick...  We don't have to go through  all of it,  but to your point,  so Mary Meeker's  internet trends  and slide deck  came out this week  and one of the things  I found interesting  was she said that  under-monetized...  Over-monetized

Start time: 5762.92
End time: 5764.78
Speaker: SPEAKER_13
Transcript:  is television advertising.  Yeah.

Start time: 5765.93
End time: 5773.42
Speaker: SPEAKER_04
Transcript:  In other words,  too much value  for what it's worth.  Right.  Web advertising,  specifically video  and mobile.  So the growth is

Start time: 5773.62
End time: 5776.89
Speaker: SPEAKER_13
Transcript:  on the side of  internet advertising.  And just bringing that up

Start time: 5777.56
End time: 5784.70
Speaker: SPEAKER_04
Transcript:  to answer...  Try and answer your question  with some data  from someone who knows  a lot more than we do  because she uses...  Well, she's famous  for this.

Start time: 5785.83
End time: 5790.95
Speaker: SPEAKER_13
Transcript:  Yeah.  Whether she's always right  or I don't know.  I mean, she's pretty  astute, I guess.

Start time: 5791.54
End time: 5816.55
Speaker: SPEAKER_04
Transcript:  I think the interesting...  The things that caught  my attention  is that internet growth  is relatively flat.  It's growing.  3 billion users,  42% of the world's population.  Smartphone adoption  growth is slowing,  but Android is doing better  than iOS.  Video viewership,  way up, exploding.

Start time: 5817.84
End time: 5819.83
Speaker: SPEAKER_13
Transcript:  Snapchat, Facebook Live.  It's good for...

Start time: 5820.46
End time: 5824.75
Speaker: SPEAKER_04
Transcript:  This should be good  for me, right?  Or Twitter.  Yeah, I mean...

Start time: 5825.42
End time: 5831.89
Speaker: SPEAKER_13
Transcript:  I think people...  Okay, I'm a little flee  but a rising whale  raises all fleas, right?  That's right.

Start time: 5832.30
End time: 5835.08
Speaker: SPEAKER_04
Transcript:  I think you're a barnacle  because you've held on  for a long time.

Start time: 5835.30
End time: 5842.14
Speaker: SPEAKER_13
Transcript:  I'm a barnacle.  Yeah.  But the whale is going up.  Yeah.  Yeah.  I mean...  Get some new krill,

Start time: 5842.53
End time: 5846.48
Speaker: SPEAKER_04
Transcript:  some fresh krill.  You got that going on.  Yeah.  And you're under-monetized,  as said.

Start time: 5847.70
End time: 5908.02
Speaker: SPEAKER_13
Transcript:  I am under-monetized.  I want more money.  No, actually, we...  Look, I'm not trying  to become a big...  Internet TV player,  by any means.  But growth has been  nice and steady.  It always has been.  For 10 years,  it's been very steady.  And what I do see  is a lot of advertisers  fleeing traditional advertising  where...  You know, at first,  it was because we can't  get metrics.  Now, it's because  it's not working.  Right.  And...  You know, I didn't like  that we can't get metrics  because that meant...  Oh, well, we want  metrics from you.  We were going to the internet  because now we can measure  our audience,  we can find out more  about our audience,  we can measure clicks.  That was a bad reason to go.  You should go  because it works better,  because you are engaging  your customers,  you're having a conversation  with them,  you're dealing with them  on a more equal basis,  not your breath must smell,  so buy some mouthwash,  but here's the benefits  of our product  and we have something  to offer you,  and if you'd be interested,  why don't you try it?  That, to me, is much more...

Start time: 5908.61
End time: 5930.06
Speaker: SPEAKER_04
Transcript:  I think that...  That...  Media networks  should be really nervous  about the Amazon model,  because it completely  eradicates the need  for advertising.  What's the Amazon model?  Basically, that by providing  media through Prime,  they then create  Prime member subscribers  who have a higher buy rate  than non-Prime.  And how does a brand

Start time: 5930.38
End time: 5932.53
Speaker: SPEAKER_13
Transcript:  do that?  What, are you going to have  Tide TV?

Start time: 5933.51
End time: 5944.02
Speaker: SPEAKER_04
Transcript:  You're going to have...  Procter & Gamble TV?  You're going to disintermediate  with the loss of advertising  and create relationships  with businesses themselves  that create media.

Start time: 5944.18
End time: 5960.00
Speaker: SPEAKER_13
Transcript:  I see, I think that's a...  I think that's  also futile.  This is the native content  argument.  I know everybody's trying  to do that, and I...  First of all, I find it  reprehensible,  because it's really,  in my mind, native content  is advertising that tricks you,  is trying to trick you  into thinking it's  not advertising.

Start time: 5960.30
End time: 5989.06
Speaker: SPEAKER_04
Transcript:  But that's different  than what this is.  This is a business relationship  that Amazon has  with its viewers.  It says, we will give you  something in return  for your loyalty.  Remember, this is where  Jeff Bezos got all of  these ideas from Senegal,  who's the head of Costco.  Loyalty, membership...  Costco invented that,  didn't they?  Loyalty and membership  creates long-term revenue  with small margin.

Start time: 5989.47
End time: 5994.86
Speaker: SPEAKER_13
Transcript:  It's good for Amazon,  but how does a brand  take advantage of that?  How does Procter & Gamble  take advantage of that?  They don't.

Start time: 5995.18
End time: 6000.06
Speaker: SPEAKER_04
Transcript:  They have to find  an aggregator.  They have to find  an aggregator like an Amazon.  So you're not saying

Start time: 6000.41
End time: 6017.86
Speaker: SPEAKER_13
Transcript:  there should be  Procter & Gamble TV?  No.  Because people did...  People proposed that,  of course, that every brand  should have a camping channel  and you're watching  content that's aimed  at REI customers,  but features REI products.  That's native advertising.  I'm not as crazy  about that.  No, I think it's

Start time: 6018.18
End time: 6020.30
Speaker: SPEAKER_04
Transcript:  deceitful.  Yeah.

Start time: 6021.65
End time: 6025.69
Speaker: SPEAKER_13
Transcript:  It is, ultimately.  You want to trick people  into seeing brand messages  without knowing it.  Wow, those judges

Start time: 6026.26
End time: 6029.06
Speaker: SPEAKER_04
Transcript:  on American Idol  sure like Coke.  Boy, I want to drink

Start time: 6029.18
End time: 6031.77
Speaker: SPEAKER_13
Transcript:  some Coke, so I'll be  just like them.  Yeah, that's...

Start time: 6032.63
End time: 6036.38
Speaker: SPEAKER_04
Transcript:  It's just...  We're sheeple,  but not that much  of a sheeple.  Yeah.

Start time: 6037.30
End time: 6037.98
Speaker: SPEAKER_03
Transcript:  Block of sheeple.

Start time: 6038.24
End time: 6042.06
Speaker: SPEAKER_10
Transcript:  It might work.  Amazon is a scale to do that.  I'm curious  whether anybody else can do it.

Start time: 6042.18
End time: 6073.26
Speaker: SPEAKER_04
Transcript:  I think that's...  What are the other models?  It's not going to be  the same, but I think  one of the keys is  it's ecosystem-based.  So what is each  ecosystem going to do?  So, for example,  Jeff Bezos was talking  this week about why  the Amazon Prime player  is not on the Apple TV.  Because it doesn't  bring people to the store.  There's a conflict  of ecosystem, therefore  it's not going to work  because the model  that Amazon's working on  is too direct.  Right.

Start time: 6074.08
End time: 6076.90
Speaker: SPEAKER_10
Transcript:  And he won't sell you  an Apple TV because  you can't watch

Start time: 6077.06
End time: 6097.70
Speaker: SPEAKER_13
Transcript:  Amazon content on it?  By the way,  I've had a little  debate on Twitter  over whose fault that is.  And I guess  there's some fault...  There's some blame to both.  Amazon in January said,  well, we're making an app,  but they never released it.  And I guess the latest is,  well, we didn't release it  because we can't  get good deal...  Good terms from Apple.  It's a lot confusing

Start time: 6098.08
End time: 6099.80
Speaker: SPEAKER_10
Transcript:  given that they are  on the iPad and the iPhone.

Start time: 6099.98
End time: 6103.80
Speaker: SPEAKER_13
Transcript:  Right.  But Apple takes  30% of everything  sold through the app.

Start time: 6103.94
End time: 6106.29
Speaker: SPEAKER_10
Transcript:  But they don't,  as long as you don't  have sign up

Start time: 6107.04
End time: 6125.62
Speaker: SPEAKER_13
Transcript:  within the app.  Right.  So what Amazon does  on a lot of platforms is  I noticed this on...  What is it?  Roku, one of my TVs.  I can watch  anything I've purchased  on Amazon Prime,  but I can't buy  anything there.  I have to go to  the Amazon website,  buy it,  and stream it  minutes later.

Start time: 6125.94
End time: 6128.78
Speaker: SPEAKER_04
Transcript:  But that's why it's not on...  That's why it's not on...  But why don't they do that

Start time: 6129.10
End time: 6129.45
Speaker: SPEAKER_13
Transcript:  on Apple TV,

Start time: 6129.94
End time: 6137.82
Speaker: SPEAKER_04
Transcript:  if that's the case?  That's the mystery.  No, it doesn't make  perfect sense though  because you can't also  access the store.  So why would...  But they're willing

Start time: 6137.94
End time: 6141.59
Speaker: SPEAKER_13
Transcript:  to have a lot of other  platforms.  So Amazon might...  I mean, Apple might

Start time: 6142.06
End time: 6157.68
Speaker: SPEAKER_10
Transcript:  be keeping it off.  Who's keeping it off  is my question.  I guess what Amazon wants  is they want the app  on the Apple TV  with the ability  to buy stuff  and not giving  30% to Apple.  Ding, ding, ding, ding.  And Apple doesn't seem  to care about that.  That would be crazy.  You can decide which one  is the bad guy.

Start time: 6157.94
End time: 6185.98
Speaker: SPEAKER_13
Transcript:  They're both being  payheaded, aren't they?  Yeah.  Here's how video ads  can work per unruly,  which I guess is a...  This is a Mary Meeker slide.  Okay.  Online advertising  still has a long way to go,  but it can work  if it's authentic.  I think we check  a few of these boxes.  Entertaining, evoke emotion,  personal, relatable, useful,  viewer control.  The only one  that doesn't work so well  work with the soundoff  and non-interruptive  is those two.  But that's pretty good.  No.

Start time: 6186.94
End time: 6187.76
Speaker: SPEAKER_04
Transcript:  You've still got visuals.

Start time: 6187.94
End time: 6234.76
Speaker: SPEAKER_13
Transcript:  Yeah, but you don't want  to turn the soundoff  on a podcast  and there's not much going on.  Look at this one.  This is the one  that scares advertisers  and content companies together.  Global ad blocking users.  It is...  Talk about a hockey stick.  It is growing,  and in mobile,  that's the blue line,  growing even faster  because it went from zero  to five, almost half a billion  ad blocking users.  And I don't know about you,  but I notice this a lot  when I'm running an ad blocker.  They'll say,  I see you're running an ad blocker.  They may not...  They may let me in.  Bloomberg makes me wait  five seconds.  Most of them encourage you  to turn it off  because this is how  we make a living,  which I think is  the right thing to do.  Some will not let you in,  but most people have not  taken that attitude yet.  How do you solve this?  What does Fast Company do?

Start time: 6235.37
End time: 6238.80
Speaker: SPEAKER_10
Transcript:  We worry,  but we haven't done anything  to prevent people  from coming to our website.

Start time: 6239.70
End time: 6245.09
Speaker: SPEAKER_13
Transcript:  Right.  Because that could have  a negative reaction too, right?  But I understand  that Fast Company with an ad blocker,

Start time: 6245.94
End time: 6262.66
Speaker: SPEAKER_10
Transcript:  you make no money off of it.  Ultimately, what you want to do  is have advertising,  which people actually find  to be valuable on some level  or at least not objectionable.  And a lot of...  Such a huge percentage  of the advertising on the web  is objectionable,  particularly because  it destroys the experience  by sucking up so much bad web.

Start time: 6263.33
End time: 6266.82
Speaker: SPEAKER_13
Transcript:  Right.  Well, that's the problem.  Ad tech just got way out of hand.

Start time: 6267.02
End time: 6276.92
Speaker: SPEAKER_10
Transcript:  Way out.  You want a website  that loads quickly.  You don't want ads  that are too in your face.  Ideally, you want ads  that people find to be a benefit somehow.  Yeah.  Yeah.

Start time: 6277.82
End time: 6282.68
Speaker: SPEAKER_04
Transcript:  I do think based on  Mary Meeker's slides  that you should translate  the show into Chinese  and have Chinese advertisers.

Start time: 6283.25
End time: 6306.56
Speaker: SPEAKER_13
Transcript:  And India.  Let's not forget India.  Oh, man.  Yeah.  You know, I don't know  if I'm allowed to talk about this or not.  We have been talking with networks  about being on linear.  You know what linear is  because you're a television person.  I know.  I didn't know what it was either.  I don't know.  So we're on demand, right?  Linear is like cable TV.  Oh, I see.  You watch it in order.  It's real time.  Well, that's like

Start time: 6306.70
End time: 6307.58
Speaker: SPEAKER_04
Transcript:  your live stream is linear.

Start time: 6307.72
End time: 6327.99
Speaker: SPEAKER_13
Transcript:  This live stream,  if you're watching live,  which very few people do,  but if you're watching relatively,  but if you're watching live,  you're watching linear.  But we've been talking with people  about putting this on linear  and there's a lot of interest in India  because they want to know about tech.  They speak English.  I don't think anybody's asked us  to be in China,  but who knows?  Hey.

Start time: 6329.03
End time: 6329.19
Speaker: UNKNOWN
Transcript:  Yeah.

Start time: 6330.51
End time: 6335.58
Speaker: SPEAKER_13
Transcript:  It is an interesting  world we're living in  and it is changing rapidly,  I have to say.  It's changing very rapidly

Start time: 6335.72
End time: 6338.56
Speaker: SPEAKER_04
Transcript:  for Tony Fidel at Nest.  Oh, what do you think

Start time: 6338.70
End time: 6367.54
Speaker: SPEAKER_13
Transcript:  happened there?  So Tony Fidel,  who created the iPod,  was one of the creators  of the iPod at Apple  and then about eight years ago,  founded Nest,  that smart thermostat  that so many of us have purchased  and never used again.  I do.  I have two Nests.  I've never used them.  Yeah, but wasn't it great  the first time you programmed it?  It was great at first,  but then I moved  and I didn't bother putting it on  because you know what?  It's a lot better  than the existing  dumb thermostat  that turns on  when I get home  and turns off

Start time: 6367.70
End time: 6371.25
Speaker: SPEAKER_04
Transcript:  when I go to bed.  It was a hundred times easier  to program it  in the first place,

Start time: 6371.72
End time: 6390.99
Speaker: SPEAKER_13
Transcript:  which was worth the cost.  But sales plummeting  because it's a lot of money.  All right.  There's competition  from a lot of companies  including Honeywell,  the incumbent,  and Ecobee,  which has some features  that are superior.  Did Fidel leave?  Was he pushed out?  I mean, he'd been there  two years,  maybe he invested  and he said,  I never planned on staying.  What happened?

Start time: 6392.05
End time: 6410.58
Speaker: SPEAKER_10
Transcript:  We don't know.  I mean, there are a bunch  of things to look at.  Supposedly Nest was not living up  to the revenue expectations  that Google had.  A lot of the news about Nest  in the last few months  has been stuff involving  like unhappy Nest employees  who thought that Tony  was pushing them too hard  or was obnoxious.  You also feel like Alphabet

Start time: 6411.57
End time: 6420.58
Speaker: SPEAKER_13
Transcript:  was kind of shunning Nest.  Like was not,  like they were,  you know how,  this happens in any workplace  where they're become,  somebody becomes the pariah.  I think Alphabet still

Start time: 6420.62
End time: 6439.91
Speaker: SPEAKER_10
Transcript:  has this issue that they have,  they have all these different  companies doing stuff  that relates to hardware  and or the smart home  and the whole idea of Alphabet  is they're going to have people  like Tony Fidel  run companies on their own  with a lot of intervention  and that's...  But they may fund competition.  It's a great idea in principle.  It's really hard to do  in reality.

Start time: 6440.64
End time: 6452.20
Speaker: SPEAKER_13
Transcript:  Google hired Rick Osterloh  from Motorola to run  their hardware division.  I think, yup.  And I have to think  they're getting into competition  with their own Alphabet buddy.

Start time: 6452.60
End time: 6484.60
Speaker: SPEAKER_10
Transcript:  I mean I think Tony Fidel  is a really significant figure  and Nest is still,  for all the years  that the smart home has been around,  if you ask somebody to name  a smart home product at random...  Nest is the one.  Nest is the one  or maybe Dropcam  which Nest bought  and but there's still  an open question as to  whether people really want  these smart devices  in their home or not.  It's kind of weird.  I think depending on  how you look at it,  Nest has been incredibly influential  and important  or maybe the whole category  it's in is still something  where there has not been anything  that's been quite transformative  on the level of the iPod.  Yeah.

Start time: 6485.46
End time: 6535.22
Speaker: SPEAKER_04
Transcript:  Whenever someone of this caliber  leaves a company or moves,  there's always a series of  statements and letters  that are made  and this one in particular  has made me really wish  that there was something  that was like a  goodbye letter subtext generator.  We need some  syntactic analysis here.  This is from Larry Page.  Under Tony's leadership,  Nest has catapulted  the connected home  into the main system  of the smart home.  He connected home  into the mainstream.  But he was a jerk.  Meaning, subtext,  given their competitors  lots of stuff to work with  and then catapult over them.  Secured leadership positions  for each of its products  grown in revenue  in excess of 50% a year.  That is pathetic  in Google standards.  Yeah.  He's a true visionary,  subtext and an ass  and I look forward  to continuing working with him  in his new role  as an advisor to Alphabet.  He will still be an advisor, right?

Start time: 6535.89
End time: 6538.85
Speaker: SPEAKER_03
Transcript:  Subtext, we've put him  in the farthest corner  of the campus

Start time: 6539.36
End time: 6541.97
Speaker: SPEAKER_04
Transcript:  and told him he doesn't  have to come to work  except on Wednesdays.

Start time: 6542.40
End time: 6554.22
Speaker: SPEAKER_10
Transcript:  It doesn't really mean  a whole lot to me.  When Andy Rubin left Android,  he also stayed around  for a while.  But eventually he left  and you got to think  that eventually  Tony Fidel,  who's a really smart  and ambitious guy,  will find something

Start time: 6554.40
End time: 6557.06
Speaker: SPEAKER_13
Transcript:  more exciting to do  than advisor and page.  Maybe with Andy Rubin

Start time: 6557.34
End time: 6572.08
Speaker: SPEAKER_04
Transcript:  they used to work together  at General Magic, right?  I just think  so many of these companies  have matured  to the point where  you can't ask a guy  who got his start  basically driving a zodiac  and feel satisfied  piloting the wheelhouse  a couple days a week.  Well, that was the point

Start time: 6572.22
End time: 6600.74
Speaker: SPEAKER_13
Transcript:  of Alphabet is to give them  that kind of feeling  of being in a startup still  even though they're  under the Alphabet umbrella.  But I think that along  with that comes  other problems like  having competition  from other Alphabet companies  and losing the favor  of Larry Page.  That still is an issue,  I would imagine.  The FBI is building  a tattoo tracking AI.  You must have put  this story in here  to the point where  you can't even  You must have put  this story in here  to capture criminals.  Why do you need an AI?

Start time: 6601.12
End time: 6609.15
Speaker: SPEAKER_04
Transcript:  Well, I was going to say  I don't think this is  so much AI as it is  like when we were talking  about facial recognition.  I mean, yes, there's AI in it.  There's all kinds of stuff.  But this is

Start time: 6610.14
End time: 6612.98
Speaker: SPEAKER_03
Transcript:  there's something about  this story that  just makes me laugh.

Start time: 6613.10
End time: 6641.71
Speaker: SPEAKER_13
Transcript:  Automated tattoo recognition tech.  This is a study  from the Electronic  Frontier Foundation  who says that  they've been working on this  with NIST,  the National Institute  of Standards and Technology  The idea,  oh, this is more  this is deep.  This is not merely  oh, you know,  you've got a picture  of a tiger on your chest.  You must be the guy.  It's to develop profiles  of people based  on what their tattoos say.  Couldn't  What?

Start time: 6642.79
End time: 6648.98
Speaker: SPEAKER_04
Transcript:  I mean, wouldn't this  be easier for  using similar technology  to facial recognition?

Start time: 6649.10
End time: 6665.16
Speaker: SPEAKER_13
Transcript:  It's not just to recognize.  It's to say  we're going to  profile people.  And this is why  the EFF is a little  worried about.  They say it threatens  free speech and privacy.  If you have a  particular tattoo,  then you're at risk  for a particular  kind of crime.  Oh.

Start time: 6666.16
End time: 6670.49
Speaker: SPEAKER_10
Transcript:  Oh.  You have a swastika  on your forehead.  It is probably  not a great sign.

Start time: 6670.98
End time: 6709.09
Speaker: SPEAKER_13
Transcript:  But, but  you can't profile people  just because  they have a swastika  on their forehead.  Right?  I mean, I was  getting on a Virgin  America flight  last year  and very nicely  dressed flight attendant  welcoming people on.  And she handed her,  you know, she  stuck her arm out  to take the boarding pass  and she had kiss,  the kiss logo  tattooed on her wrist.  And I just know  that she had a young  and vibrant,  you know, her  youth was exciting.  Yes, very.  And I'm sure  nowadays she probably  deeply regrets  having a kiss  tattoo on her wrist.  You're the one  she's 90.

Start time: 6710.11
End time: 6710.74
Speaker: UNKNOWN
Transcript:  But I certainly

Start time: 6711.04
End time: 6749.54
Speaker: SPEAKER_13
Transcript:  wouldn't hold it against  her.  Right?  She, you know,  she just wanted  to party all night  and rock and roll all day  or is it the other way around?  Rock and roll all night.  Party every day.  Oh yeah.  See?  It's tattooed in my brain.  I don't have it on my wrist.  But I do think  this is a little troubling  if people were profiled  based on the tattoos  they have.  But there are tattoos  that are,  speaking of dog whistles,  and, you know,  white power  signifiers that may not,  I mean, the Nazi swastika  is very obvious,  but there are  less obvious ones that are...  So every Christmas  we get our Christmas tree

Start time: 6749.74
End time: 6757.21
Speaker: SPEAKER_04
Transcript:  from Delancey Street,  which gives jobs  to ex-cons  who can't get jobs  because they have a record.  But it's a wonderful

Start time: 6757.74
End time: 6762.14
Speaker: SPEAKER_13
Transcript:  organization for rehabbing  people and getting them  back into the mainstream.  And so this year

Start time: 6764.92
End time: 6777.48
Speaker: SPEAKER_04
Transcript:  we had to go  someplace else  because of the timing  they weren't open,  blah, blah, blah.  And my daughter says to me,  that wasn't as much fun.  They didn't have the guys  who have the teardrops  right by their eyes.  And she had no idea.

Start time: 6777.66
End time: 6781.81
Speaker: SPEAKER_03
Transcript:  No idea.  And then the year before,  my son was like reading the guy

Start time: 6782.66
End time: 6793.04
Speaker: SPEAKER_04
Transcript:  as he's putting  the Christmas tree  up on top of the minivan  and across his forehead  it says,  live to hate.  And my son's asking,  love, live.  I'm like,  okay, over here, Santa.

Start time: 6793.62
End time: 6802.38
Speaker: SPEAKER_03
Transcript:  But it's just so funny.  Like, they don't,  I mean, the teardrops,  they didn't have any idea,  but they identify  that with Christmas.  They identify that  with Christmas trees.  So there you have it.

Start time: 6802.52
End time: 6858.03
Speaker: SPEAKER_13
Transcript:  15,000 images of tattoos  obtained from arrestees  and inmates  were handed over  to third parties,  including private companies  with little restriction  on how the images  may be used or shared.  Many of the images  reviewed by the EFF  contained personally  identifying information,  including people's names,  faces, and birth dates.  But they also didn't follow  protocol for ethical research  involving humans, for instance.  They only sought permission  from supervisors  after the first major set  of experiments were completed.  The same researchers  have also not disclosed  to their supervisors  the tattooed data sets  they are using to see  the experiments came  from prisoners and arrestees.  So there's some real issues  with this.  And I, you know what,  if you made a mistake  in your youth  and you got a tattoo  that, you know,  isn't something that reflects  your personal beliefs today,  I don't think that  you should be targeted  by law enforcement  because of it.

Start time: 6858.91
End time: 6859.08
Speaker: UNKNOWN
Transcript:  No.

Start time: 6859.48
End time: 6876.37
Speaker: SPEAKER_04
Transcript:  It just did make me think  that, wow, if there,  I know this is not  what the story is about,  but what made me think was,  wow, if there was a way  to database tattoos,  you'd think that,  or unknown criminals,  you'd think that  the government would be doing it  because it's identifiable.

Start time: 6877.67
End time: 6882.81
Speaker: SPEAKER_13
Transcript:  Yeah, but this isn't like  having a mole on your chin.  It's kind of predictive.  Yes, yes.

Start time: 6883.38
End time: 6885.18
Speaker: SPEAKER_04
Transcript:  I completely agree with you  that that's creepy wackadoo.

Start time: 6885.46
End time: 6886.26
Speaker: SPEAKER_13
Transcript:  So they had a competition.

Start time: 6886.56
End time: 6887.24
Speaker: SPEAKER_04
Transcript:  That's creepy wackadoo.

Start time: 6887.30
End time: 6936.88
Speaker: SPEAKER_13
Transcript:  They sent the tattoo database  to 19 organizations,  five research institutions,  six universities,  eight private companies,  including MorphoTrack,  one of the largest marketers  of biometric technology,  to law, MorphoTrack  to law enforcement agencies,  and the idea was a challenge.  They called it  the Tattoo Recognition  Technology Challenge.  The experiments included  identify whether an image  contained a tattoo,  whether algorithms could match  different images of the same tattoo,  but the most alarming research  involved matching  common visual elements  between tattoos  with operational goal  of establishing connections  between individuals.  So a gang tattoo, perhaps,  like all the good, you know.  I don't know, I don't know,  I don't know.  Did you know that  one in five adults in the U.S.  has a tattoo?  I did know that  because I've done some stories

Start time: 6937.20
End time: 6951.76
Speaker: SPEAKER_04
Transcript:  on laser tattoo removal.  How effective is that?  It hasn't changed dramatically  in the last few years.  It's a place where  I would see,  if you want to make some money,  figure out how to do that better.

Start time: 6952.28
End time: 6953.58
Speaker: SPEAKER_12
Transcript:  Yeah, it's going to be a big market.

Start time: 6954.14
End time: 6958.73
Speaker: SPEAKER_10
Transcript:  Mm-hmm.  Yeah.  I assume it must be  way higher for people  under a certain age.

Start time: 6961.01
End time: 6965.84
Speaker: SPEAKER_13
Transcript:  Interesting.  Is that trend dwindling?  You got ink?  You got ink?  Got no ink.

Start time: 6966.34
End time: 6966.82
Speaker: SPEAKER_03
Transcript:  Oh, I do have ink.

Start time: 6967.43
End time: 6967.79
Speaker: UNKNOWN
Transcript:  You do?

Start time: 6968.20
End time: 6972.43
Speaker: SPEAKER_13
Transcript:  I do have ink.  I am one of the 20%.  I'm a 20% of you.  I see it.

Start time: 6973.75
End time: 6974.41
Speaker: UNKNOWN
Transcript:  I'm a 20% of you.

Start time: 6975.65
End time: 6977.80
Speaker: SPEAKER_13
Transcript:  Later.  Wow.  We'll have a private...

Start time: 6978.02
End time: 6981.19
Speaker: SPEAKER_04
Transcript:  I've been in a hot tub with you  and I have not seen that.  That must be relatively recent.

Start time: 6982.43
End time: 6982.67
Speaker: UNKNOWN
Transcript:  Yeah.

Start time: 6983.51
End time: 6991.52
Speaker: SPEAKER_13
Transcript:  It's the Twit logo.  I got it tattooed on my butt  for charity.

Start time: 6992.02
End time: 6993.61
Speaker: SPEAKER_10
Transcript:  Yeah, your wife told me  about this story.

Start time: 6994.10
End time: 6995.72
Speaker: SPEAKER_13
Transcript:  It was New Year's Eve.  Oh, then.

Start time: 6996.02
End time: 6996.65
Speaker: SPEAKER_10
Transcript:  This was all public.

Start time: 6997.08
End time: 7095.54
Speaker: SPEAKER_13
Transcript:  Right.  And what was I thinking?  I also shaved my head that year.  And by the way,  we've not had another  beard since.  Right.  Connection?  Possibly.  Ask the FBI.  Lenovo is in the news again.  Oh, you love this story.  Oh, man.  What is wrong with this company?  So, twice already,  they've been tagged  for putting basically malware  on their system.  In both cases,  ostensibly to help users  keep their system up to date.  In one case,  the malware is really about intruding,  putting ads into their surfing,  right, onto their browser.  And it had the side effect  of allowing man in the middle  attacks by any malefactor.  So, Lenovo apologized.  We'll never do this again.  They didn't do it on their business  class computers.  They did it on their  consumer class computers.  And I am sure, as usual,  it was just a case of,  oh, we've got to make  a little extra  because we don't make enough  on these consumer grade computers.  Now, they have a updater app  that unfortunately is vulnerable  duo security discovered  that holes in the support app  would allow eavesdropping attackers  to tap into their unencrypted  update channels.  In other words,  updating over HTTP,  not HTTPS,  and use that to compromise users.  The Lenovo accelerator application  could lead to exploitation  by an attacker  with man in the middle capabilities.  Lenovo says,  oops, can you delete that?  Can you delete that  from your Lenovo?  Lenovo recommends customers  uninstall the Lenovo  accelerator application.

Start time: 7097.15
End time: 7098.44
Speaker: SPEAKER_03
Transcript:  No credibility issues there.

Start time: 7098.66
End time: 7144.14
Speaker: SPEAKER_13
Transcript:  And by the way,  they're not the only company,  five vendors were putting this,  putting OEM software  with equal laptops from Acer,  Asus, Dell, and HP.  Half of that were found  to have a dozen vulnerabilities  all contained at least one flaw  that would allow a bad guy  to hijack the computer,  most of which are easy  to exploit.  This is according to the register.  Lenovo says,  46 notebook and 25 desktop lines  are affected,  including its top end Y700 gaming,  oops, I keep spilling my water,  I'm sorry.  My gaming laptop,  my idea center,  and all one laptops  in the Yoga Flip netbooks.  However, ThinkPad and ThinkStation  once again have skated.

Start time: 7145.34
End time: 7155.42
Speaker: SPEAKER_10
Transcript:  Basically,  if you use a Windows PC,  you want to use it with Windows  in as close as possible  to an adulterated state.  Yeah, Paul Therottes would say  this for some time.  Get the signature edition,

Start time: 7156.07
End time: 7179.01
Speaker: SPEAKER_13
Transcript:  Microsoft signature edition,  which unfortunately,  a lot of OEMs have not offered  signature PCs,  but that is the best way to do it.  Or, and I suppose I should do this  with my HP that I just bought,  wipe the machine  and install the pure version of Windows.  Start all over again.  Get it from Microsoft,  not from HP.  But I think,  I feel like there's drivers  and stuff I'll be missing  by doing that.

Start time: 7179.79
End time: 7182.18
Speaker: SPEAKER_10
Transcript:  I always think so too,  but it never seems to be  that much of an issue.

Start time: 7182.42
End time: 7183.26
Speaker: SPEAKER_13
Transcript:  Never the case, is it?

Start time: 7183.69
End time: 7188.97
Speaker: SPEAKER_10
Transcript:  It's very similar  with Android phones.  You want an Android phone  with as little stuff  done to Android as possible?  Yeah, fortunately,

Start time: 7189.60
End time: 7253.04
Speaker: SPEAKER_13
Transcript:  you can buy a Nexus device  from Google that is pure  and you can buy Microsoft devices  that are pure.  Although I've heard from some  that maybe even those signature PCs  aren't completely flip free  of bloatware.  I'm not sure exactly  what the status is of that.  But my Surface Book seems to be pure Windows.  It doesn't seem to have  anything else on it.  Windows 10 is there.  That may be.  There are those who say  that is not the best choice.  Now there's a new report  that says,  this is from ZDNet,  Mary Jo Foley writing,  Microsoft makes blocking  Windows 10 recommended update  nearly impossible.  When will they learn?  Did you see the video  of the, what was it,  the Congolese freedom fighters?  Random Patrol, go.  What was it?  They were fighting the rebels.  Where was it?  They were fighting poachers.

Start time: 7253.67
End time: 7254.18
Speaker: UNKNOWN
Transcript:  Poachers.

Start time: 7254.32
End time: 7319.06
Speaker: SPEAKER_13
Transcript:  They were fighting poachers.  Poachers.  Oh, that was it.  Poachers, not rebels.  I confused poachers and rebels.  Right.  Even in remotest Africa,  Windows 10 nagware ruins your day update  burns satellite link cache.  Lives could have been put at risk  by the pushy upgrade.  This was in the Central African Republic.  These are forces trying to protect  the wildlife from armed poachers  and the Lord's Resistance Army.  So poachers and rebels.  The Chinco Project manages  16,600 square kilometers of rain forest  in the eastern part of the Central African Republic  near the border with South Sudan.  They use satellite links to get their data.  So the staff was a little more,  a little more than a little displeased  when one of the donated laptops the teams used  began upgrading to Windows 10 automatically,  pulling in gigabytes of data over a radio link.  This is just really ridiculous.

Start time: 7319.36
End time: 7324.92
Speaker: SPEAKER_04
Transcript:  I've been really enjoying the weather forecasts.  That's a fun one.  That's been interrupted by the...

Start time: 7325.08
End time: 7326.71
Speaker: SPEAKER_12
Transcript:  Yeah, that's a fun one.  By the updates.

Start time: 7327.06
End time: 7331.72
Speaker: SPEAKER_13
Transcript:  You showed that one.  That is so good.  You work in television news.  She handled that quite well, I thought.

Start time: 7332.28
End time: 7339.94
Speaker: SPEAKER_04
Transcript:  You know, the real truth is,  in TV, you pray for moments.  That's what you hope for.  You really pray for moments.

Start time: 7340.06
End time: 7343.94
Speaker: SPEAKER_13
Transcript:  Something to take you out of your  dull day-to-day routine.

Start time: 7344.08
End time: 7359.62
Speaker: SPEAKER_04
Transcript:  That's right.  And if it's a Windows security update  popping up on your weather wall,  it's so much better than you  falling down in front of your weather wall.  That's really all you want.  Yeah, don't fall down.  There's the good YouTube highlights  and the bad ones.  So if it's Windows 10, sure.

Start time: 7361.59
End time: 7369.82
Speaker: SPEAKER_13
Transcript:  Sure.  So Mary Jo Foley says that this process...  Every week there's more bad news from Microsoft.

Start time: 7371.94
End time: 7380.15
Speaker: SPEAKER_10
Transcript:  I have to say I have several friends  who are civilians who have ended up  with Windows 10 on their computer  and not been entirely sure how it got there.  Yeah.  Yeah.

Start time: 7381.64
End time: 7432.58
Speaker: SPEAKER_13
Transcript:  So here's Microsoft's response to this.  By the way, we always recommend  and Mary Jo recommends and uses  Steve Gibson's great utility, Never 10.  There are other tools,  but Never 10 really is the best.  It uses Microsoft's own recommended  procedure registry modifications  to prevent this.  Microsoft released an official statement  on this.  The register report is inaccurate.  The Windows 10 upgrade is a choice.  Designed to help people take advantage  of the most secure and most productive Windows.  People receive multiple notifications  to accept the upgrade  and can reschedule or cancel the upgrade  if they want.  So the heck with you.  That is kind of a tone deaf response,  but the whole thing's been tone deaf all along.

Start time: 7432.99
End time: 7434.77
Speaker: SPEAKER_10
Transcript:  People are confused.  It is just not the way...

Start time: 7435.84
End time: 7440.81
Speaker: SPEAKER_13
Transcript:  You know, you want people to love Windows 10  but you're making them hate it.  And if 99.5% of people aren't confused

Start time: 7442.76
End time: 7455.93
Speaker: SPEAKER_10
Transcript:  on Windows scale, one half of 1%...  That's a lot of people.  There's still a lot of people.  Millions.  I like that you said civilians.  People who are not like tech fans,  people who don't read tech sites.  Oh, muggles.  Yeah.  People who don't watch Twitter.  Right.

Start time: 7456.86
End time: 7465.19
Speaker: SPEAKER_04
Transcript:  There's been an evolution of that word  as a tech journalist.  It started as my mom,  which I now found...  Which we have to stop.  Yes.  We can't do that.

Start time: 7465.76
End time: 7467.46
Speaker: SPEAKER_13
Transcript:  Yes.  But your moms are very smart.

Start time: 7467.76
End time: 7475.17
Speaker: SPEAKER_04
Transcript:  Yes.  And your mom used to call into the show  every once in a while.  She was a hoot.  She was great.  My aunt Peg called into the show.  Remember that?

Start time: 7475.64
End time: 7489.46
Speaker: SPEAKER_13
Transcript:  My mom is wired.  She's got a Galaxy Note 5.  She's got an iPhone 6S Plus.  She's got an iPad Pro.  Of course, I sent her all that stuff,  but she uses it.  She's got a couple of Mac PCs,  a Windows 2000 PC.  She's pretty wired.  Got it.

Start time: 7489.58
End time: 7503.03
Speaker: SPEAKER_04
Transcript:  So we will not use you from my mom.  Don't use my mom.  That's not happening.  Then it was average Joes.  Then it was Joe Sixpack.  I remember there was that.  We used that for a while.  I hate that Joe Sixpack.  Then we had...  I tend to use consumers a lot.  Consumers?  I say consumers.

Start time: 7503.58
End time: 7517.38
Speaker: SPEAKER_13
Transcript:  What do you say?  But yeah, you're just talking on GMA,  which is talking mostly to normals.  Yeah.  You don't want to call them normals  or muggles or civilians.  I say us.  Us.  There you go.  Smart move.  You know, we really don't understand  this Windows 10 upgrade, do we?

Start time: 7518.11
End time: 7519.08
Speaker: SPEAKER_04
Transcript:  It's forcing it on us.

Start time: 7520.07
End time: 7526.11
Speaker: SPEAKER_13
Transcript:  What is Windows doing to us?  Us.  We are the persecuted.  Yeah.  That's good, us.  You know what?

Start time: 7526.87
End time: 7534.18
Speaker: SPEAKER_04
Transcript:  It's inclusive.  Well, it's not something you can do  because you can't be in us  and do what you do.  Yeah.  It's very difficult to ride that line.

Start time: 7534.93
End time: 7556.46
Speaker: SPEAKER_13
Transcript:  Yeah.  Well, I actually use Windows 10,  and the fact that Microsoft's giving it away  seems good,  but at the same time,  I get people calling me all the time  saying, what happened?  I didn't want Windows 10,  and suddenly I have it.  How did that happen?  And there are good, legitimate reasons  for not wanting an upgrade.

Start time: 7556.68
End time: 7557.42
Speaker: SPEAKER_06
Transcript:  Anything besides Siri

Start time: 7558.19
End time: 7561.46
Speaker: SPEAKER_04
Transcript:  that's going to come out of this WWDC?  Thunderbolt?  We don't know.

Start time: 7561.72
End time: 7563.26
Speaker: SPEAKER_13
Transcript:  We don't know.  It's a mystery.

Start time: 7563.95
End time: 7576.17
Speaker: SPEAKER_10
Transcript:  New version of iOS,  new version of OS 10.  We know that for sure.  New watchOS probably,  new Apple TV OS hopefully.  How about hardware, though?  They'll only have hardware  if it happens to be ready.  They won't have hardware  because that's at the center  of announcements probably.  There was a rumor

Start time: 7577.10
End time: 7596.20
Speaker: SPEAKER_13
Transcript:  which Renee Richie at iMore  has thrown out  that there was going to be a new display  with, what was it, built-in GPS?  Built-in GPUs.  Oh, GPUs.  Well, I want to be the first on record  to say that Apple will not release a display  with a GPS built in this year.

Start time: 7599.80
End time: 7600.71
Speaker: SPEAKER_04
Transcript:  Find my monitor.

Start time: 7601.97
End time: 7604.18
Speaker: SPEAKER_13
Transcript:  Oh, GPU.  That makes a lot more sense.

Start time: 7604.69
End time: 7605.34
Speaker: UNKNOWN
Transcript:  Actually, it doesn't.

Start time: 7606.04
End time: 7608.30
Speaker: SPEAKER_13
Transcript:  Why would you build a GPU into a display?

Start time: 7608.72
End time: 7616.06
Speaker: SPEAKER_10
Transcript:  Because then you can have a laptop  that might be too wimpy  to power a really great display,  and it will power it  by having the GPU built into the display.

Start time: 7616.34
End time: 7619.22
Speaker: SPEAKER_13
Transcript:  You'd have to have like Thunderbolt 3  or something,  so you have a lot of throughput, right?

Start time: 7619.44
End time: 7623.48
Speaker: SPEAKER_10
Transcript:  And this is based on stuff like Thunderbolt  where you have great throughput.  Right.

Start time: 7625.14
End time: 7641.40
Speaker: SPEAKER_13
Transcript:  Yeah.  Okay.  Monitor with GPS would be more interesting.  There were rumors  that there would be a new MacBook Pro  with as weird as a GPS, frankly,  and OLED function keys  that aren't function keys  but are OLED screens.  Why?

Start time: 7642.34
End time: 7644.87
Speaker: SPEAKER_14
Transcript:  Because it can be really funny.  So programmable.

Start time: 7645.48
End time: 7650.71
Speaker: SPEAKER_13
Transcript:  Soft keys, yeah.  Do you think that'll happen?  It sounds really cool.  It sounds cool.  I would buy it,

Start time: 7651.34
End time: 7656.22
Speaker: SPEAKER_10
Transcript:  but it doesn't sound like...  At the moment,  it sounds like something  that might be real  but probably is not going to come out

Start time: 7656.34
End time: 7661.17
Speaker: SPEAKER_13
Transcript:  in the immediate future.  Wasn't there a keyboard?  Remember that?  It seemed kind of fictional  that had OLED keys.

Start time: 7662.34
End time: 7662.50
Speaker: SPEAKER_06
Transcript:  Whoa.

Start time: 7663.34
End time: 7676.20
Speaker: SPEAKER_13
Transcript:  Yeah, and it was like from a Russian guy,  and so that sounded art lebedev.  But I think it was real  now that I think about it.  Huh.  Did anybody ever get the  cool for like editors and stuff?

Start time: 7676.36
End time: 7679.50
Speaker: SPEAKER_04
Transcript:  You know,  they always have stickers on them.  Yeah.

Start time: 7680.34
End time: 7691.20
Speaker: SPEAKER_13
Transcript:  So the idea is that  instead of, you know,  fixed keys,  that every key on the keyboard  would be a little OLED screen.  I guess,  is he selling these?  Ridiculously expensive.

Start time: 7692.67
End time: 7693.71
Speaker: SPEAKER_04
Transcript:  Okay, never mind.  Exactly.

Start time: 7694.34
End time: 7695.63
Speaker: SPEAKER_13
Transcript:  Like I said.  Never mind.

Start time: 7696.36
End time: 7698.41
Speaker: SPEAKER_04
Transcript:  How about the Popularis?  Oh, that one's down to $1,000.

Start time: 7699.34
End time: 7701.95
Speaker: SPEAKER_12
Transcript:  Yeah, the Maximus.  That's got to be the most...  It's sold out.

Start time: 7702.69
End time: 7716.92
Speaker: SPEAKER_13
Transcript:  That's a lot of keys.  Jeez.  They did sell,  I think I do remember  like these little  pads  so that you could...  That would be like an editor would use that  because that would be a controller.  So, you know,

Start time: 7717.28
End time: 7725.02
Speaker: SPEAKER_04
Transcript:  our control room at GMA,  you know how we used to have  the control room  and had all the monitors?  Yeah.  It's all just one screen now.  Oh, neat.  It's just a wall screen.

Start time: 7725.22
End time: 7726.90
Speaker: SPEAKER_13
Transcript:  Yeah, what do you want bezels for?  You don't need bezels.

Start time: 7727.26
End time: 7733.10
Speaker: SPEAKER_04
Transcript:  No, and so they can  maximize or minimize  or minimize whatever they need the size to be  based on whatever the live remotes are.

Start time: 7733.47
End time: 7760.85
Speaker: SPEAKER_13
Transcript:  I just bought  this new Dell.  We still haven't set it up.  Maybe we're going to set it up next week.  One of these days,  43 inch Dell monitor  that could be four displays.  It's kind of like what you're doing  in the control room.  I don't know what I'm going to do with it.  No, Don, you don't have to get it out.  Every time I mention it,  John pulls it out.  He really wants us to set this thing up.  He's a prop master.  Yeah.  Yeah, he is the prop master, isn't he?  Among other things.  Let's take a little break.  We're...  Oh, shoot.  The game began.

Start time: 7761.40
End time: 7765.83
Speaker: SPEAKER_04
Transcript:  That's okay.  Let's keep going.  I got DVR.  You got DVR?  Oh, yes.

Start time: 7766.49
End time: 7776.10
Speaker: SPEAKER_13
Transcript:  No spoilers.  Right, yeah.  Becky's in the Dub Nation.  It's not.  Are you in the Dub Nation?  I'm in the Dub...

Start time: 7776.53
End time: 7777.06
Speaker: SPEAKER_03
Transcript:  I live in Oakland.

Start time: 7777.22
End time: 7782.94
Speaker: SPEAKER_04
Transcript:  What's your issue?  Are you in the Shark Tank?  I'm not in the Shark Tank.  I can't watch hockey,  except when it's live.  My eyes have gotten too bad.

Start time: 7783.22
End time: 8007.62
Speaker: SPEAKER_13
Transcript:  Yeah.  It's hard to follow that puck.  Our show today brought to you by ITProTV.  I know you love IT.  You wouldn't be watching this show  if you weren't into technology.  And being in IT as a job,  I think for a lot of you,  would be the dream job, right?  You get to work with technology  all the time.  But how do you get into the world of IT?  Well, it turns out  there are these certifications,  these tests you can take.  And getting a cert is often the key  to getting a great job.  But how do you learn ITProTV?  They are incredible.  They've been basically doing  what we do here at TWiT,  but for the IT professional  and the aspiring IT professional.  Now they have two studios.  They have 50 hours of new content  every week on their site,  in their library,  thousands of hours of content  in every aspect of IT.  And now they are the first IT  video provider to go do this new  Amazon Video Direct thing.  So you can actually buy  ITProTV content on Amazon.  But really the best way to do this  is to subscribe, right?  Because once you subscribe,  one flat monthly or yearly rate,  you get access to everything.  So, I think that's it for this week.  Thank you for watching.  I hope you enjoyed this week's  session.  I hope you enjoyed it.  I'll see you next week.  Bye.  I want to put this back for the  version 9 of my favorite cert.  I really want this cert.  Certified Ethical Hacker.  Three words that describe me  in my dreams.  Certified Ethical Hacker.  But imagine what a great job  you could get as a pen tester,  as a security expert.  I mean this is a cert every...  I just, I want it just for...  I want to put it on my wall.  They have a virtual machine lab,  so you don't even have to have  a Windows machine to take these.  Just an HTML5 browser,  and you can set up a server,  set up clients.  The TransCenter Practice Exam,  so you take the test  before you take the test.  And it's all for one  low monthly subscription price.  And of course, once you get the cert,  if you want to cancel,  they make it easy.  No hassle cancellation policy.  If you're currently signed up  for an enterprise account  with an ITProTV competitor,  and the rates are going up,  you know what I'm talking about,  right?  ITProTV will match  your previous year's,  previous year's pricing  on that account,  so that you don't have  to do that increase,  and you get the benefit  of ITProTV.  I love it.  Their clients include  Harvard, MIT, UCSD, Stanford.  The entire Harvard IT department  are customers.  Go to ITPro.tv slash twit  to upgrade your brain  with the most popular certs.  Premium subscriptions,  normally 57 bucks a month,  $570 a year.  That's a really good deal,  but when you use our offer code  TWIT30, you'll get a free  seven-day trial,  and if you decide to buy,  30% off forever,  for the lifetime of your account,  that makes it less than  $40 a month,  or by a year,  and it's just $3.99,  and that is well worth it.  ITPro.tv slash twit.  Whether you're in IT  and want to keep your skills up  or you're interested  in getting to IT,  it is a great job,  trust me,  and what a wonderful,  I've got so many good courses.  Forensics, our local police  department,  Petaluma Police Department  came to me and said,  and he was the only detective  we'd worked with before,  he said,  I'm now in charge of our  forensics division,  where can I learn how to use  Wireshark,  how to do forensics,  I said,  I've got a place for you,

Start time: 8007.94
End time: 8008.35
Speaker: UNKNOWN
Transcript:  ITPro.tv,

Start time: 8008.86
End time: 8011.61
Speaker: SPEAKER_13
Transcript:  they got all the courses  he signed up.  ITPro.tv.

Start time: 8013.78
End time: 8024.62
Speaker: SPEAKER_04
Transcript:  Certified ethical hacker,  that's the title of your dream?  Yeah.  That's shocking to me,  because I thought that it was  male exotic dancer.  That's what I thought.  That's where I thought  you were going with that.

Start time: 8025.17
End time: 8026.76
Speaker: SPEAKER_12
Transcript:  Someday,  I'll be some...  MED.

Start time: 8027.70
End time: 8046.01
Speaker: SPEAKER_13
Transcript:  You're going to be a MED.  I'm an MED,  Leo LaPorte,  MED.  I do have breakaway pants.  That's the Elvis costume,  actually.  What the heck?  Yeah.  Love it.  Next time you see an Uber Lifter  Deliver driver,  you might see groceries inside,  Walmart's going to be  testing delivery.  That makes sense,  you've got a lot of drivers  driving around,

Start time: 8046.62
End time: 8052.77
Speaker: SPEAKER_04
Transcript:  Uber drivers not doing anything.  They have got to maximize  capacity with their drivers  to keep them driving,  or go driverless.

Start time: 8053.74
End time: 8064.50
Speaker: SPEAKER_13
Transcript:  That's the next step.  Next Uber is a cab company  that owns no cabs.  Soon they're going to be  a cab company that owns  no drivers,  but then they'll have to  buy the cabs.

Start time: 8064.62
End time: 8064.70
Speaker: SPEAKER_04
Transcript:  Yeah.

Start time: 8065.95
End time: 8080.74
Speaker: SPEAKER_13
Transcript:  How much does Saudi Arabia  put into Uber?  What?  Some huge amount of money.  It was enormous.  That is interesting.  Is it the government?  I guess when you talk  about Saudi Arabia,  it's still the family,  whether it's the country,  it's still the family,  right?

Start time: 8081.64
End time: 8119.85
Speaker: SPEAKER_04
Transcript:  It's fascinating.  They're issuing a bond  for the first time,  right now,  raising cash.  Saudi Arabia?  Yeah.  Also, just the finances there  are so just ornate.  It's still the royal family  though, right?  The Sauds, right?  The Sauds.  I was in Spain doing  a documentary about  green energy,  and they have one of these,  they have one now in Nevada,  but it's one of these  solar arrays that uses  mirrors to heat molten salt,  and then the molten salt  heats water,  heats electricity,  and their largest investor  is Saudi Arabia.

Start time: 8120.84
End time: 8121.81
Speaker: SPEAKER_13
Transcript:  They got a lot of sun there.

Start time: 8122.62
End time: 8125.50
Speaker: SPEAKER_04
Transcript:  Because they have to diversify.  They have got to diversify.

Start time: 8125.76
End time: 8132.17
Speaker: SPEAKER_13
Transcript:  You know, if you're  an oil power,  what's the next big thing, right?  Be big in sun.  I think that's actually

Start time: 8132.95
End time: 8155.65
Speaker: SPEAKER_04
Transcript:  very smart.  So it makes sense  that they're also looking at,  you know,  they also want to create  a car-based economy  that's new,  so if car ownership  is going to diminish,  as many think that services  like Uber and Lyft  will lead to a reduction  in car sales,  despite the fact that  cars are booming now  because gas is cheap  and other reasons,  but it makes sense  that they would want to  have a stake in that as well.

Start time: 8156.52
End time: 8159.00
Speaker: SPEAKER_13
Transcript:  Sad news,  McJugger Nuggets is retiring.

Start time: 8159.56
End time: 8161.38
Speaker: SPEAKER_03
Transcript:  Oh, you're going to  bring Minecraft to me again?

Start time: 8161.93
End time: 8188.12
Speaker: SPEAKER_13
Transcript:  No, no.  That's another story.  Minecraft, yes.  I know you.  Do you still forbid your kids?  No Minecraft for you.  You know,  it's sold 100 million now.  This is the new sales.  What is it?  50,000 copies every day.  This is the beginning of the year.  Every day, 53,000 copies.  Each month,  more than 40 million people  go into their Minecraft world.  I have three Minecraft worlds  on my server just running.  I love it.

Start time: 8188.56
End time: 8188.83
Speaker: UNKNOWN
Transcript:  I know.

Start time: 8189.46
End time: 8191.26
Speaker: SPEAKER_13
Transcript:  Minecraft is everywhere.  What would you,

Start time: 8191.38
End time: 8197.65
Speaker: SPEAKER_04
Transcript:  what do you think  my kids are going to be doing?  My kids are eight.  What's their best case job  when they're 25, 30?

Start time: 8200.44
End time: 8219.26
Speaker: SPEAKER_13
Transcript:  You know,  there's actually a good living  to be made building  for the  The Sims have discarded gender rules  for all clothing customizations.  Here's the good news.  You can use any bathroom you want.

Start time: 8219.81
End time: 8220.01
Speaker: UNKNOWN
Transcript:  Nice.

Start time: 8220.63
End time: 8221.06
Speaker: SPEAKER_04
Transcript:  Go Sims.

Start time: 8221.38
End time: 8236.14
Speaker: SPEAKER_13
Transcript:  Go Sims.  You want to put heels on a male Sim?  I didn't know you couldn't.  But apparently they had rules.  But they've rightly so unlocked  the Sims for customization options.  I love it.

Start time: 8236.58
End time: 8242.90
Speaker: SPEAKER_04
Transcript:  Did you see that L'Oreal is going to have makeup  for Snapchat that they're going to virtually put on?

Start time: 8243.92
End time: 8246.67
Speaker: SPEAKER_13
Transcript:  That's the hottest thing is those Snapchat filters, right?  Isn't that hot?

Start time: 8247.46
End time: 8252.14
Speaker: SPEAKER_04
Transcript:  They already have it?  Oh, wow.  I've done that.  Yeah, no, didn't I have you do that?

Start time: 8252.28
End time: 8253.42
Speaker: SPEAKER_10
Transcript:  That's the future of advertising.  Yeah.

Start time: 8254.96
End time: 8259.10
Speaker: SPEAKER_13
Transcript:  Yeah.  You've seen my mom's...  Wait a minute.  Maybe you haven't.

Start time: 8259.42
End time: 8259.91
Speaker: SPEAKER_03
Transcript:  I haven't seen.

Start time: 8260.69
End time: 8273.02
Speaker: SPEAKER_13
Transcript:  My mom has an Instagram account.  I told her she should do it on Snapchat  where she plays a character using...  It's the same idea.  Did she kill her account?  Oh, I think she did.

Start time: 8273.18
End time: 8274.25
Speaker: SPEAKER_10
Transcript:  Is your mom on Snapchat?

Start time: 8275.52
End time: 8306.90
Speaker: SPEAKER_13
Transcript:  No, I couldn't figure out how to...  I tried to.  I couldn't figure out how to explain Snapchat  to my mom who's 83 and very smart.  But she does have an Instagram account.  I think it's gone, unfortunately.  I'm sad to say.  She had a character called Miss Honeybell  that was the makeup from a Snapchat filter  of big red cheeks and big eyes.  Wow.  And then I guess she started doing it  and she started channeling some strange character,  Miss Honeybell.

Start time: 8307.02
End time: 8310.90
Speaker: SPEAKER_04
Transcript:  Miss Honeybell.  Wow.  Is Miss Honeybell Southern or is she Rhode Island-y?

Start time: 8311.04
End time: 8315.86
Speaker: SPEAKER_13
Transcript:  Yes, she's from the South.  I wonder if she has taken it down.

Start time: 8316.40
End time: 8319.68
Speaker: SPEAKER_04
Transcript:  Your mother's secret Southern belle.  Miss Honeybell.  She's a very strange person.

Start time: 8319.90
End time: 8332.89
Speaker: SPEAKER_13
Transcript:  Oh, that is so funny.  Maybe she's still there.  Yeah, I believe she is.  Do you want to see...  Oh, I want to see Miss Honeybell.  Miss Honeybell.  She's putting her art up there now,  which is good.  Oh, wow.  You said I was joking.  Ah!  That is adorable.

Start time: 8334.02
End time: 8334.76
Speaker: SPEAKER_00
Transcript:  Oh, my God.

Start time: 8334.90
End time: 8336.78
Speaker: SPEAKER_13
Transcript:  Oh, you can't hear it.  We haven't got the sound working.

Start time: 8337.43
End time: 8337.53
Speaker: UNKNOWN
Transcript:  Oh.

Start time: 8338.25
End time: 8346.68
Speaker: SPEAKER_13
Transcript:  Oh, man.  So cute.  I want you to hear Miss Honeybell.  That's my mom.  Yeah, that's...  L'Oreal is going to be speaking to her.

Start time: 8346.90
End time: 8347.25
Speaker: SPEAKER_04
Transcript:  Wow.

Start time: 8347.90
End time: 8349.74
Speaker: SPEAKER_13
Transcript:  She's going to be a model for them.  She's got this.

Start time: 8349.90
End time: 8350.62
Speaker: SPEAKER_04
Transcript:  She has got this.

Start time: 8351.04
End time: 8351.89
Speaker: SPEAKER_13
Transcript:  Miss Honeybell.

Start time: 8353.12
End time: 8361.72
Speaker: SPEAKER_04
Transcript:  Well, you know, it's...  I won't let my son play Minecraft  and I won't let my daughter play L'Oreal makeup.  So, you know, they have this to look forward to  in their retirement.

Start time: 8362.02
End time: 8375.60
Speaker: SPEAKER_13
Transcript:  Yeah, yeah.  Miss Honeybell.  Well, I wish I had audio for you.  I knew it.  We worked so hard to get this.  So I'm...  It's this honking giant laptop in front of me.  Wow.  Show the single.  Is this too big now?

Start time: 8375.90
End time: 8377.72
Speaker: SPEAKER_04
Transcript:  Does my laptop make my hands look big?

Start time: 8377.90
End time: 8391.72
Speaker: SPEAKER_13
Transcript:  Does it make my head look small?  That's a first.  It is giant.  This is a Brian Brushwood sized laptop.  It's 17 inches.  It's a Linux laptop.  And I'm thinking now as I look at it,  it might be a little too big.

Start time: 8392.06
End time: 8393.59
Speaker: SPEAKER_10
Transcript:  I know.  It's very slimming.

Start time: 8394.92
End time: 8397.29
Speaker: SPEAKER_13
Transcript:  Slimming.  Leo seems to have shrunk.

Start time: 8399.92
End time: 8401.09
Speaker: SPEAKER_10
Transcript:  It makes all of us look a lot tidier.

Start time: 8402.14
End time: 8411.66
Speaker: SPEAKER_13
Transcript:  Tell you what, let's wrap this sucker up.  We've got a ball game to go to.  Whoop, whoop.  Becky Dub Nation-Worley.  So great to have you from Good Morning America.

Start time: 8411.90
End time: 8413.03
Speaker: SPEAKER_04
Transcript:  At BWorley on Twitter.

Start time: 8413.80
End time: 8419.29
Speaker: SPEAKER_13
Transcript:  At BWorley on Twitter.  Anything else you want to plug?  What you up to?  What's going on?

Start time: 8419.78
End time: 8454.54
Speaker: SPEAKER_04
Transcript:  Oh, I don't know.  Tweet me a good book you're reading.  I just finished Boys in the Boat.  Amazing.  What's that about?  It's about the 1936 crew team  from the University of Washington that went to Berlin.  And it's just a phenomenal summer read.  Cannot say enough good things about it.  I realized I loved, what was the Zamparini book?  Oh yeah, Unbreakable, Unbroken.  What a great book that was.  It felt like that for me.  I mean, I didn't love that movie  because it was just too brutal,  but the book was great.  The movie was brutal.  Yeah, so tweet me a good book like that  if you love it.  At BWorley.

Start time: 8454.66
End time: 8456.48
Speaker: SPEAKER_13
Transcript:  Oh, that's nice.  I'm on ABC in the morning,

Start time: 8457.04
End time: 8462.20
Speaker: SPEAKER_04
Transcript:  but watch Good Morning America,  because it's a way to connect with the world.

Start time: 8462.66
End time: 8469.38
Speaker: SPEAKER_13
Transcript:  You'll be seeing The Fold It any day now.  What, what?  The Fold It.  The closed folding machine.  Oh yeah, it's going to be on.  I want you to get one.  I'm going to.

Start time: 8469.70
End time: 8471.25
Speaker: SPEAKER_03
Transcript:  Bring them on.  I'm going to.

Start time: 8471.72
End time: 8472.15
Speaker: UNKNOWN
Transcript:  Done.

Start time: 8474.13
End time: 8490.34
Speaker: SPEAKER_13
Transcript:  Harry McCracken, he's at thefastcompany.com.  He's the technologizer.  Yep, we love him.  I wanted, you could tell I was going there.  But he's also at Harry McCracken on Twitter.  And follow him on Instagram.  I still love all the retro stuff.  You post pictures of him.  I love when you say that.

Start time: 8490.66
End time: 8497.47
Speaker: SPEAKER_10
Transcript:  Like my Instagram, for the longest time,  I was following more people on Instagram.  And then were following me.  And whenever you plug me.

Start time: 8498.86
End time: 8503.32
Speaker: SPEAKER_13
Transcript:  But is this becoming your calling?  Like the retro thing?

Start time: 8503.66
End time: 8522.06
Speaker: SPEAKER_10
Transcript:  We went to the Gerald Schulz Museum before we came here.  Oh, isn't that fun?  Yes.  Don't you love that?  We have a great exhibit on peanuts and Washington, DC.  Like with Ronald Reagan's letters to Gerald Schulz.  And Snoopy wrote a letter to Hillary Clinton in 1968  when she became the president of the Wellesley school government.

Start time: 8522.88
End time: 8528.42
Speaker: SPEAKER_13
Transcript:  So you're on Instagram as technologizer.  Yes.  There's my stuff from the museum.

Start time: 8529.05
End time: 8531.02
Speaker: SPEAKER_10
Transcript:  We all voted.  I voted for Linus for president.

Start time: 8531.66
End time: 8534.42
Speaker: SPEAKER_13
Transcript:  He ran.  Too bad he never won.

Start time: 8535.31
End time: 8536.18
Speaker: SPEAKER_10
Transcript:  He's running again this year.

Start time: 8537.43
End time: 8554.32
Speaker: SPEAKER_13
Transcript:  I loved this.  Farrah's Glamour Center.  Farrah Glamour Center.  I think L'Oreal could learn a little from this.  Yeah.  You and Marie were at an antique store.  I know because she posted a bunch of pictures  from the antique store as well.  What is...  Is that Miss Honeybell?

Start time: 8554.66
End time: 8573.28
Speaker: SPEAKER_10
Transcript:  That's my mom who I just recently discovered was on Twitter.  Oh, neat.  You see?  I assumed she wasn't and I said something on Twitter  and she commented and I said...  What?  I thought you weren't on Twitter and she replied to that saying...  Only occasionally.  My mom's on Twitter.  Cute.  All right.  She's still an egg though.  I need to show her to upload her photo.

Start time: 8573.54
End time: 8577.51
Speaker: SPEAKER_13
Transcript:  Yeah.  I don't want to know what this was.  I went to the new Apple store.

Start time: 8578.56
End time: 8579.42
Speaker: SPEAKER_10
Transcript:  We went to a Beyonce concert.

Start time: 8579.64
End time: 8587.28
Speaker: SPEAKER_13
Transcript:  Oh, that's Beyonce.  I should have known.  Yeah.  You learned so much about your friends  following him on Instagram.  Wow.  Harry McCracken is so much cooler than me.

Start time: 8587.56
End time: 8590.77
Speaker: SPEAKER_03
Transcript:  Antique stores and Beyonce.  I have just come to that realization.  Are you really into a Beyonce?  Yeah.

Start time: 8591.87
End time: 8594.24
Speaker: SPEAKER_10
Transcript:  I'm glad I went once.  it was really interesting.

Start time: 8594.68
End time: 8598.40
Speaker: SPEAKER_13
Transcript:  You know what changed concerts is these incredible screens  they have, the projection.

Start time: 8599.58
End time: 8603.40
Speaker: SPEAKER_10
Transcript:  and they rotate it.  And doors open up.  They can make it look like anything.

Start time: 8603.56
End time: 8605.42
Speaker: SPEAKER_13
Transcript:  Right.  It's really remarkable.

Start time: 8605.66
End time: 8608.34
Speaker: SPEAKER_10
Transcript:  Yeah, from a technology standpoint, it was fascinating.  I agree.

Start time: 8608.54
End time: 8615.30
Speaker: SPEAKER_13
Transcript:  I'd love to know more about this screen technology  they use at concerts these days  because it's very good.  It's vivid.  And every seat in the house was pretty good?

Start time: 8615.42
End time: 8615.50
Speaker: SPEAKER_10
Transcript:  Yeah.

Start time: 8616.42
End time: 8690.16
Speaker: SPEAKER_13
Transcript:  Right, you can't have a bad seat  because you're looking at this giant screen.  And then, of course, there's a lot of theater going on as well  with the dancers and the performers.  The stage snaked out into the audience.  Yeah, these concerts have really become quite interesting,  I think.  The big tours.  We thank you for being here.  We do the show every Sunday afternoon, 3 p.m. Pacific,  6 p.m. Eastern time, 2200 U.S. time.  We're going to be doing the UTC.  Love it if you can watch us live  and be in our chat room at irc.twit.tv.  If you can be in the studio even better,  just email tickets at twit.tv.  We'll put a chair out for you.  You're going to want to do it soon  because we're going to be moving out of the Brickhouse  in about three months, I think, at this point, at this stage.  Construction has already begun in our new studio  down the road apiece.  We're very excited about it.  If you watch at home, it won't look so very different.  We're going to take our sets with us.  Our experience in studio will be somewhat different, I think.  So come here now while you can.  Oh, Michael O'Donnell, our staff photographer at this point,  he is that on his Twitter?  Oh, man.  Yeah, twitter.com slash photo.

Start time: 8690.50
End time: 8699.71
Speaker: SPEAKER_04
Transcript:  Before the show, we were talking about the fact that my daughter,  I had to close all the windows that she'd used to write up  the wedding vows for her best friend  and her best friend's kitten.  And so?

Start time: 8700.30
End time: 8701.35
Speaker: SPEAKER_13
Transcript:  And so here they are, the...

Start time: 8702.34
End time: 8703.06
Speaker: SPEAKER_04
Transcript:  Kitten wedding vows.

Start time: 8703.18
End time: 8707.74
Speaker: SPEAKER_13
Transcript:  I look like Grumpy Cat.  I don't know, you're marrying Grumpy Cat.

Start time: 8708.53
End time: 8709.06
Speaker: UNKNOWN
Transcript:  I look hot.

Start time: 8709.61
End time: 8712.96
Speaker: SPEAKER_13
Transcript:  You look fantastic.  Wow, glasses and the cat.  What the hell's going on with Grumpy Cat?

Start time: 8713.20
End time: 8721.06
Speaker: SPEAKER_03
Transcript:  I think you're mad that my ears are pointing in the wrong direction.  That whole ear and nose and whiskers thing is working for me.

Start time: 8721.18
End time: 8722.45
Speaker: SPEAKER_04
Transcript:  Are you doing that on your phone, Michael?

Start time: 8723.28
End time: 8725.68
Speaker: SPEAKER_13
Transcript:  That was incredible.  What app are you using?

Start time: 8726.22
End time: 8726.90
Speaker: UNKNOWN
Transcript:  Perfect 365.

Start time: 8727.91
End time: 8757.74
Speaker: SPEAKER_13
Transcript:  Perfect 365.  That's pretty cool.  Dang.  So if you want to be in the studio and take pictures of us,  you can do that too.  Wow.  Email tickets at twit.tv.  Now, of course, we make on-demand audio video  of all of our shows available at the website,  twit.tv or wherever you subscribe to podcasts.  And of course, the twit apps that are everywhere on every platform  thanks to our fabulous third-party developers.  There's the website.  Thank you all for being here.  We'll see you next time.  Another twit is in the can.  Go Warriors!  Go Sharks!

Start time: 8758.08
End time: 8759.71
Speaker: SPEAKER_10
Transcript:  This is amazing.  Let's go home!

Start time: 8760.22
End time: 8768.94
Speaker: UNKNOWN
Transcript:  Ha ha ha.  Doin' the twit.  Doin' the twit.  All right.  Doin' the twit, baby.  Doin' the twit.  All right.

Start time: 8769.08
End time: 8783.27
Speaker: SPEAKER_00
Transcript:  Doin' the twit.  Oh, I just think life is a ball.  I've been going to so many parties lately  that I haven't really done you justice, honey.  But I'm thinking of you all the time.

