;FFMETADATA1
title=Anywhere but Albany
artist=TWiT
album_artist=TWiT
album=This Week in Tech
track=639
genre=Podcast
comment=http://twit.tv/twit
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf58.76.100



[00:00:00.000 --> 00:00:04.080]   As time for Twit this weekend tech, RyanX Chen from the New York Times,
[00:00:04.080 --> 00:00:08.880]   Georgia Dow from iMore, ZeeDeeNet's EdBot joins me. We have lots to talk about.
[00:00:08.880 --> 00:00:14.880]   Of course, the iPhone X. Is it good? Is it bad? Is it worth the money? The Animoji break up?
[00:00:14.880 --> 00:00:20.400]   There's problems in Poopland. We'll talk about gadget stratification and try to solve.
[00:00:20.400 --> 00:00:24.400]   The big problem? Facebook poses. It's all coming up next on Twit.
[00:00:27.040 --> 00:00:30.320]   NetCasts you love. From people you trust.
[00:00:30.320 --> 00:00:42.960]   This is Twit. bandwidth for this weekend tech is provided by cashfly at cachiefly.com.
[00:00:50.160 --> 00:00:59.120]   This is Twit this weekend tech episode 639 recorded Sunday November 5th 2017 anywhere but Albany.
[00:00:59.120 --> 00:01:02.400]   This weekend tech is brought to you by FreshBooks.
[00:01:02.400 --> 00:01:08.560]   The ridiculously easy to use cloud accounting software. It's used by over 10 million people.
[00:01:08.560 --> 00:01:15.360]   Try it free for 30 days at freshbooks.com/twit and by ZipRecruiter are you looking to hire a
[00:01:15.360 --> 00:01:20.080]   tech professional? With ZipRecruiter you can post to 100 plus job boards including social networks
[00:01:20.080 --> 00:01:24.560]   all with a single click screen rate and higher the right candidates fast.
[00:01:24.560 --> 00:01:29.120]   Try ZipRecruiter free at ziprecruiter.com/twit.
[00:01:29.120 --> 00:01:35.920]   And by Casper a sleep brand that continues to revolutionize its line of products to create an
[00:01:35.920 --> 00:01:41.440]   exceptionally comfortable sleep experience one night at a time. Get $50 towards any mattress
[00:01:41.440 --> 00:01:46.320]   purchased by visiting casper.com/twit and using the promo code TWIT at checkout.
[00:01:47.040 --> 00:01:52.240]   And by stamps.com start using your time more effectively with stamps.com.
[00:01:52.240 --> 00:01:56.800]   Use stamps.com to buy and print real US postage the instant you need it right from your desk.
[00:01:56.800 --> 00:02:01.040]   For our special offer go to stamps.com click on the microphone and enter Twit.
[00:02:01.040 --> 00:02:06.240]   It's time for Twit this weekend tech the show where we get together with the best tech journalists
[00:02:06.240 --> 00:02:10.800]   in the biz to talk about the week's tech news. I'm really this is going to be so much fun from
[00:02:10.800 --> 00:02:16.720]   Santa Fe, New Mexico, Ed Bot joins us. You might feel a little left out and if you don't have your
[00:02:16.720 --> 00:02:24.000]   iPhone 10 in hand. You know it's still on the truck I guess. Yeah that's what they told you.
[00:02:24.000 --> 00:02:32.480]   It's on the two ordered one? No I didn't think so. Okay. Ed Bot report on ZDNet. He's of course
[00:02:32.480 --> 00:02:38.080]   famous Windows tech journalist but I think you cover everything now and you certainly don't
[00:02:38.080 --> 00:02:45.840]   have a Windows phone. Did you go Android? At the moment yeah I have a 7 plus here and
[00:02:46.480 --> 00:02:54.400]   Galaxy S8 plus. So really good pretty good but we're going to get you a little bit better because
[00:02:54.400 --> 00:03:00.560]   also here Georgia Dow from iMore and she's holding Renee Richie's right now. Yeah stolen.
[00:03:00.560 --> 00:03:05.200]   Squeeze it. Always the best. You both of us have stolen phones. Yes I stole mine from my wife.
[00:03:05.200 --> 00:03:13.840]   Georgia's moving we just found out so she actually went to Renee's to do the show which is nice
[00:03:14.560 --> 00:03:19.200]   and Renee's lurking somewhere behind you isn't he? Yeah we'll see him every once in a while.
[00:03:19.200 --> 00:03:22.560]   Okay if he ever wants to you know if he's listening he says I have something to say
[00:03:22.560 --> 00:03:28.960]   he did a great 10,000 word review of the iPhone 10 after having it for one day.
[00:03:28.960 --> 00:03:35.760]   That's impressive. That's a lot of words. He writes without even thought. I know.
[00:03:35.760 --> 00:03:41.440]   Well no that. I wouldn't say that. I wouldn't say that. Well it's innate to him.
[00:03:41.440 --> 00:03:46.320]   It's an innate to him. He's thinking. A first time I'm really thrilled to have Brian Tenchin.
[00:03:46.320 --> 00:03:54.240]   I'm sorry X-chan. He you'll be Brian Tenchin for this week. He's of course lead technology
[00:03:54.240 --> 00:03:57.600]   consumer technology writer at the New York Times. Six years I didn't realize you've been there that
[00:03:57.600 --> 00:04:04.640]   long. That's awesome. I do have the iPhone X on me. Yes. I mean 10. Sorry. You must of all people must
[00:04:04.640 --> 00:04:11.200]   have the most difficulty calling at the iPhone 10. Yeah I had problems with Mac OS 10 who
[00:04:11.200 --> 00:04:16.480]   I used to call it OS X all the time. I got yelled at by all that Apple to Gerati or Bloggerati.
[00:04:16.480 --> 00:04:21.920]   So yeah iPhone 10 is a little bit hard for me. It's hard for everybody. It's kind of a weird thing.
[00:04:21.920 --> 00:04:31.760]   So by the way I loved the way you reviewed the iPhone 10 in the New York Times. The iPhone 10
[00:04:31.760 --> 00:04:39.920]   is cool wrote Brian but that doesn't mean you're ready for it. Yeah it's kind of a resting headline
[00:04:39.920 --> 00:04:44.960]   right here. You read that and then you have to click through and you'll see what I mean when
[00:04:44.960 --> 00:04:50.240]   you get through the first few paragraphs of the review. It's not that the iPhone 10 is bad. It's
[00:04:50.240 --> 00:04:55.920]   not. It's the best iPhone ever made. But my point being that I think that a lot of people who aren't
[00:04:55.920 --> 00:05:01.360]   really used to having abrupt changes in technology probably aren't going to want the iPhone 10.
[00:05:01.360 --> 00:05:06.240]   The home button's gone. The way that you turn on the phone is gone. Everything is totally different.
[00:05:06.880 --> 00:05:11.760]   But I think there are plenty of people who are technology enthusiasts who embrace change and
[00:05:11.760 --> 00:05:16.000]   are just cool with it. I think it's fine for them to spend $1000 to get the iPhone 10. I think it's
[00:05:16.000 --> 00:05:21.680]   great. I'm actually curious. You wrote your view November 1st. When did you get your iPhone 10?
[00:05:21.680 --> 00:05:29.600]   So I got it. So what day is this? I got it on Monday and we had it till Tuesday for the embargo
[00:05:29.600 --> 00:05:35.680]   to lift. But I chose to take one extra day just to spend some more time with it instead of.
[00:05:35.680 --> 00:05:40.160]   It's like if I felt like if I was doing it within the first 24 hours, I would barely even get to
[00:05:40.160 --> 00:05:43.520]   use it. I had to spend more time writing and polishing. It just wouldn't work out. It'd be
[00:05:43.520 --> 00:05:47.440]   like writing an infomercial in some ways. No offense to anybody who did pull it off and did it find
[00:05:47.440 --> 00:05:52.400]   you out doing it. Everybody else did it in 24 hours because of course you're going to get clicks.
[00:05:52.400 --> 00:05:57.200]   And I'm curious what Ed bot because you've covered this for a long time. Apple really
[00:05:57.200 --> 00:06:03.760]   did something I think unprecedented this time around. They gave four iPhones. They've done that
[00:06:03.760 --> 00:06:08.880]   before. They in fact with the original iPhone, they gave out four to David Pogue of the New York
[00:06:08.880 --> 00:06:15.360]   Times at the time at big of USA Today, Walt Mossberg of the Wall Street Journal and Stephen
[00:06:15.360 --> 00:06:20.640]   Levy who was then at Newsweek. This time around four went out, but three of them, actually all of
[00:06:20.640 --> 00:06:25.360]   them really went to web properties. Stephen Levy was the only one of the four who got one.
[00:06:25.360 --> 00:06:33.120]   And weirdly those four got him a week at a time. But weirdly, Stephen's embargo ended Monday and
[00:06:33.120 --> 00:06:36.800]   everybody else ended Tuesday. Ed, is that unusual?
[00:06:36.800 --> 00:06:45.600]   Well, that's highly unusual. I mean, I can't remember anything ever like that. I know
[00:06:45.600 --> 00:06:53.120]   with other devices, you've had, you know, some people get longer term units. Other people get
[00:06:53.120 --> 00:06:59.760]   shorter term review units. But to have things arrive with one day's notice for the majority,
[00:06:59.760 --> 00:07:04.400]   especially the established media outlets, I mean, that's just basically unheard of for me.
[00:07:04.400 --> 00:07:10.960]   And then there were some very well known people who were a little upset like the Wall Street Journal
[00:07:10.960 --> 00:07:20.320]   and John Gruber of Daring Fireball, who has always been an insider for his coverage of Apple,
[00:07:20.320 --> 00:07:26.720]   didn't get advanced units. And then now Brian, it is unusual to have a phone. I'm actually
[00:07:26.720 --> 00:07:30.800]   proud of you that you delayed another 24 hours. There must have been pressure to publish right
[00:07:30.800 --> 00:07:37.040]   away, right? Thank you. I mean, I did want to spend an entire week with it. Ideally, you know,
[00:07:37.040 --> 00:07:41.120]   typically when you get these phones, you spend a week. But my editor pointed out that if we
[00:07:41.120 --> 00:07:44.800]   waited a week, we would have missed Friday. That's when people are deciding whether or not they want
[00:07:44.800 --> 00:07:50.240]   to get in line and buy this thing. So we had to put it out before the iPhone even came out.
[00:07:51.200 --> 00:07:57.200]   But yeah, it gave me some extra time. I didn't really catch too much more than other people. I
[00:07:57.200 --> 00:08:02.240]   did catch a bug with the Amazon app that froze the phone. And that was an Apple's fault. It was just
[00:08:02.240 --> 00:08:06.400]   the thing I was pointing out was that I didn't know how to turn the phone on and off because the
[00:08:06.400 --> 00:08:12.240]   controls were very different with any iPhone. There's definitely a learning curve. Yeah,
[00:08:12.240 --> 00:08:17.200]   that's the thing. There's definitely a learning curve. I think people who are very good at
[00:08:17.200 --> 00:08:21.680]   technology or just very sophisticated with it are going to pick it up pretty fast. They're going to
[00:08:21.680 --> 00:08:26.560]   like Face ID versus Touch ID. They're going to be used to the home button pretty quickly.
[00:08:26.560 --> 00:08:30.400]   But there are a bunch of weird things, right? Like the battery indicator is gone in the corner.
[00:08:30.400 --> 00:08:35.200]   Did you notice that for the percentage? Yeah, you have to slide it down to get the control
[00:08:35.200 --> 00:08:40.000]   panel to see the battery life to turn off the phone. It's not even the power button anymore.
[00:08:40.000 --> 00:08:45.600]   You hold the power button and the volume button at the same time. And don't hold them too long.
[00:08:46.160 --> 00:08:50.720]   SOS goes off and it starts going whoop whoop whoop whoop whoop whoop. That scared the hell out of me
[00:08:50.720 --> 00:08:56.480]   the first time. Yeah, so my point was that, you know, it's I feel like it's the first iPhone where
[00:08:56.480 --> 00:09:00.560]   people probably going to have to read an instruction manual. Whereas I feel like for the past decade,
[00:09:00.560 --> 00:09:04.480]   I've never read an instruction manual for an iPhone in my life. But now I have to.
[00:09:04.480 --> 00:09:13.440]   I think Apple was fairly bold with this. I hate to admit it. It's very nice. But there is some
[00:09:13.440 --> 00:09:19.840]   question about why they, for instance, they gave Mindy Kaling a phone and then so she could write
[00:09:19.840 --> 00:09:25.520]   about it in glamour. She gave a 12 year old developer, Alex Nolafone, so he could show it on
[00:09:25.520 --> 00:09:32.800]   Ellen DeGeneres. They gave Inafrita phone to review on Axios, but they also gave Axios's
[00:09:32.800 --> 00:09:39.440]   political journalist, Mike Allen a phone. And he had his nephew, who was apparently an emoji expert
[00:09:39.440 --> 00:09:43.440]   in a freshman in college review it. This pissed John Gruber off, by the way, no.
[00:09:43.440 --> 00:09:48.960]   It was it was interesting. There is some speculate. I mean, look, it's Apple's,
[00:09:48.960 --> 00:09:54.640]   and it's Apple's right to do this. There's no, it's not there ain't no law. But it,
[00:09:54.640 --> 00:10:01.520]   some people speculated Apple might not have wanted the people like Brian and and long time tech
[00:10:01.520 --> 00:10:06.560]   reviewers to have too long with his phone. There was some concern that maybe they were hiding
[00:10:06.560 --> 00:10:10.640]   something. I think it wasn't they were hiding something so much, although if there are battery
[00:10:10.640 --> 00:10:15.680]   issues or screen burn issues, we may still not know for a few days. But I think maybe what they
[00:10:15.680 --> 00:10:22.080]   wanted and I this is, I think reasonable speculation is they wanted the reviewers who only had a day
[00:10:22.080 --> 00:10:29.440]   to focus on what's new, the new screen, the new face ID, the an emoji, and have their reviews be
[00:10:29.440 --> 00:10:34.880]   all about that because that's all you could cover. And you really didn't have time to do anything
[00:10:34.880 --> 00:10:37.360]   more in depth. Is that manipulative Ed?
[00:10:37.360 --> 00:10:48.560]   Well, I mean, the very notion of handing out review units to a selected number of outlets is by its
[00:10:48.560 --> 00:10:55.680]   definition manipulative and it's Apple's right. It is it is absolutely their right to behave in
[00:10:55.680 --> 00:11:02.880]   their own best commercial interest. So, you know, their their job is not to serve the needs of the
[00:11:02.880 --> 00:11:08.960]   journalistic community. Their job is to sell phones. I mean, I think to a certain extent,
[00:11:08.960 --> 00:11:17.040]   the audience for this phone is self selecting. This is I mean, because of the price number one,
[00:11:17.040 --> 00:11:22.000]   and because of the feature set and the amount of work that you had to do,
[00:11:22.000 --> 00:11:27.680]   you know, in terms of staying up late and not making a mistake in typing or clicking to get
[00:11:27.680 --> 00:11:33.520]   your order in, it was self selecting to the kind of technology enthusiasts who were not going to be
[00:11:33.520 --> 00:11:40.560]   dissuaded by a lukewarm review anyway. So I think they said, you know, what we really want to do
[00:11:40.560 --> 00:11:48.480]   is get this out there to people who can show it off the web based properties rather than the sort
[00:11:48.480 --> 00:11:54.160]   of older mainstream media that it's much more important to actually have people demonstrating
[00:11:54.160 --> 00:11:59.200]   the features, then simply talking about the specs and how something works.
[00:11:59.200 --> 00:12:05.200]   Yeah, I think that it was a really smart move for Apple because they're giving it out to people
[00:12:05.200 --> 00:12:09.920]   that are probably going to be a little bit more enthusiastic or, you know, a lot of us reviewers
[00:12:09.920 --> 00:12:14.720]   are getting a little bit jaded. Maybe it will be very spec oriented and what the phone can do and
[00:12:14.720 --> 00:12:19.680]   what it can't do instead of how much fun it was to use it and how I enjoyed it. And this is something
[00:12:19.680 --> 00:12:25.280]   that was really innovative and interesting. And it also broadens the audience to areas where
[00:12:25.280 --> 00:12:29.200]   usually they may not even think about a phone. So I think it was smart that they gave it to new
[00:12:29.200 --> 00:12:33.840]   different people. And it also changes the water a little bit. It's smart, but I feel like it does
[00:12:33.840 --> 00:12:38.880]   a disservice to end users who are not going to have as much information as they might like. But you
[00:12:38.880 --> 00:12:43.280]   don't have to have the review in 24 hours. That was people's choice to put them out. And they'll be
[00:12:43.280 --> 00:12:47.280]   more and more reviews that are going to come come out. A lot of people that would have a phone,
[00:12:47.280 --> 00:12:51.120]   you know, that would have it for a lot longer to be able to review, you can still they'll still
[00:12:51.120 --> 00:12:55.040]   have reviews that are out. And the phone is expensive enough that I think that people are going to
[00:12:55.040 --> 00:12:59.040]   think about it unless you are a huge tech enthusiast. And I think Brian said it well,
[00:12:59.040 --> 00:13:03.040]   you're going to go through tech shock. If you you're not used to changing technology and makes
[00:13:03.040 --> 00:13:06.720]   you frustrated when you have to learn a new interface, this might not be the phone that you're going to
[00:13:06.720 --> 00:13:11.280]   want to take a look at until you're really comfortable with it. Yeah. And I think people don't misunderstand
[00:13:11.280 --> 00:13:16.240]   me, folks, I have no sympathy or concern about whether journalists got it or didn't. I never
[00:13:16.240 --> 00:13:22.400]   take reviewing it. So I buy the units and I get it. If I'm lucky and I was my wife was lucky, I got it
[00:13:22.400 --> 00:13:30.160]   on the day of the release. Mine won't come for another week or two. But because I don't like to
[00:13:30.160 --> 00:13:35.840]   review pre-production units, I don't like to be in the kind of have a relationship at all with
[00:13:35.840 --> 00:13:41.280]   the companies. And I don't, you know, I don't have a long lead. I don't have it lead at all. I can,
[00:13:41.280 --> 00:13:45.600]   you know, as soon as I get it, I can talk about it and continue to talk about it. But I just, I think
[00:13:45.600 --> 00:13:54.560]   Apple, I worry that Apple's doing all this to, oh, they don't need to God knows, but to
[00:13:54.560 --> 00:14:02.720]   control the message, control the message more than the consumer deserves, I think, a longer
[00:14:02.720 --> 00:14:11.760]   review, to be honest before she orders it. But who needs to order it on day one or even in the first
[00:14:11.760 --> 00:14:16.320]   week? I mean, I mean, there are people who've been waiting for this who want it. And they would
[00:14:16.320 --> 00:14:22.080]   like to go on the tech. Those are only the technical issues, right? Right. Whether or without a review.
[00:14:22.080 --> 00:14:28.080]   And by the way, yeah, okay. Okay. That's fair. There is this part of the review.
[00:14:28.080 --> 00:14:33.680]   Somebody wrote this pretty black, smart blog post. I forgot who it was about how the Apple Watch
[00:14:33.680 --> 00:14:39.200]   Series three, the review cycle was just so horrendously bad for the Apple Watch because there was one
[00:14:39.200 --> 00:14:43.840]   bug that was caught pretty quickly and fixed pretty quickly. And that took over the entire
[00:14:43.840 --> 00:14:48.400]   news cycle for like an entire week where, you know, the LTE didn't work on the Apple Watch. And
[00:14:48.400 --> 00:14:53.520]   this blogger pointed out that Apple probably felt burned by this. And I think with the iPhone 10,
[00:14:53.520 --> 00:14:57.680]   it's just there's too much at stake, right? This is the most important iPhone in a decade. And,
[00:14:57.680 --> 00:15:01.360]   you know, to Ed's point, it's in their commercial interest to control the narrative.
[00:15:01.360 --> 00:15:06.640]   Of course. But if there were a showstopper on the level of the LTE issue on the
[00:15:07.280 --> 00:15:11.040]   Series three watch, no one would have known about it. You know,
[00:15:11.040 --> 00:15:16.160]   yeah, you have a 30 day return policy. Okay. All right. You know,
[00:15:16.160 --> 00:15:23.200]   no questions asked 30 days, boom, you get it, you get it, give it back. But anybody who's buying
[00:15:23.200 --> 00:15:29.680]   it in the first day or week or even month better be expecting that there are going to be some
[00:15:29.680 --> 00:15:34.880]   issues, even the best case scenario, there's going to be a half a dozen annoyances that are going to
[00:15:34.880 --> 00:15:43.440]   be fixed by at least one or two, you know, point updates to iOS in that time. That's just the way
[00:15:43.440 --> 00:15:49.600]   it works. The real testing doesn't happen until it gets in the hands of real users on real networks
[00:15:49.600 --> 00:15:56.480]   out in the real world. Well, the good news for Apple is we have a number of data points. Of
[00:15:56.480 --> 00:16:02.800]   course, Apple's own quarterly results came out the day before the iPhone 10 shipped. And they say
[00:16:02.800 --> 00:16:13.680]   they had amazing sales of iPhones. The iPhone sold 46.6 million, 46.6 million units
[00:16:13.680 --> 00:16:22.880]   in the fourth quarter. Much of those probably iPhone 8. So iPhone 8 was a success. And then,
[00:16:22.880 --> 00:16:29.600]   of course, slice, which is an interesting story. I don't know, I'd love to hear whether you guys
[00:16:29.600 --> 00:16:38.480]   trusted or not. I use slice slices in app that monitors your Gmail to see of its customers. And
[00:16:38.480 --> 00:16:45.040]   there are, I guess, millions of users monitors Gmail to see if your delivery is coming and when
[00:16:45.040 --> 00:16:51.200]   it's coming. So they have advanced information, admittedly, a sample, but I think a fairly large
[00:16:51.200 --> 00:16:57.200]   sample size. And they say, according to, you know, their customers, their users, it's the largest
[00:16:57.200 --> 00:17:02.160]   product launch in the company's history. This is the graph, the iPhone 8 and 8 Plus,
[00:17:02.160 --> 00:17:07.760]   kind of one of the smallest product launches in the company history. But the iPhone 10 even
[00:17:07.760 --> 00:17:13.040]   invested the iPhone 6, which was huge because it was the first big iPhone. This, you know,
[00:17:13.040 --> 00:17:17.520]   this is pretty significant. Do you Brian, are those useful numbers you think are these? I feel
[00:17:17.520 --> 00:17:23.200]   like slices is useful. You know, I have been an Apple reporter in several years. So I really
[00:17:23.200 --> 00:17:27.600]   don't remember, but are they scanning receipts or something? Yeah, that's how it works.
[00:17:27.600 --> 00:17:33.520]   I think Apple has disputed those metrics before, like just from what I remember, they don't love
[00:17:33.520 --> 00:17:37.360]   them. And I'm not sure if it's because they're too accurate or if they're totally wildly off.
[00:17:37.360 --> 00:17:41.760]   But I do think that early orders are definitely a good metric for, you know,
[00:17:41.760 --> 00:17:49.520]   early adopter interest and just, you know, like an indicator of whether or not a product is very
[00:17:49.520 --> 00:17:53.280]   interesting to technology enthusiasts. You know, I don't know if it really tells us much about the
[00:17:53.280 --> 00:17:58.320]   long term over the course of a year, but it definitely is interesting to see the iPhone 10
[00:17:58.320 --> 00:18:05.600]   and so much excitement over it. Yeah. Well, I think three out of the four of us have one in our hands.
[00:18:05.600 --> 00:18:13.040]   Ed bot is still using his Nokia 1050. But no, I'm teasing. But
[00:18:16.320 --> 00:18:21.040]   I wanted to hate this phone. I went for the price for the attention it was getting. I just wanted
[00:18:21.040 --> 00:18:24.480]   to hate this phone. I wanted to find something wrong with it. And I can't find anything wrong with it.
[00:18:24.480 --> 00:18:30.080]   So do you use an emoji? I have sent some that is not going to be a killer.
[00:18:30.080 --> 00:18:37.200]   Affie sure. I've said a few. And of course, our friend Harry McCracken claims to have invented
[00:18:37.200 --> 00:18:41.920]   something that is really going to end the world sooner, which is an emoji karaoke.
[00:18:42.880 --> 00:18:48.000]   I don't know if he was he the first one to do it. He claims to have invented it. Yeah.
[00:18:48.000 --> 00:18:53.360]   Yeah, I don't know. I don't know either. But I'll play a little bit for you if in case you
[00:18:53.360 --> 00:18:58.320]   somehow have have missed the excitement of an emoji karaoke. They'd say actually kind of a hard
[00:18:58.320 --> 00:19:04.080]   thing to do because what you have to do is record using the screen recorder because you're limited
[00:19:04.080 --> 00:19:12.160]   to 10 seconds. No, this is an ad. Let's see if I can find it. I think that Renee has an actual
[00:19:12.160 --> 00:19:18.960]   how to on the iMAR site of how to do this yourself. If you so wish to torture the rest of the world
[00:19:18.960 --> 00:19:24.160]   with an emoji and maybe Renee's found a better way to do it. But what I was told is that you have
[00:19:24.160 --> 00:19:31.920]   to use the screen recorder and then edit it out, crop out the UI stuff. And then you can
[00:19:31.920 --> 00:19:37.840]   according to Buzzfeed, Harry McCracken invented it. So and then you can and then you can mix it
[00:19:37.840 --> 00:19:49.680]   into a here's Harry's first or one of his first. So he's got a rabbit and a chicken singing
[00:19:49.680 --> 00:19:54.320]   singing. Oh, that's good though. I just singing Blue Swedes hooked on a feeling.
[00:19:54.320 --> 00:20:02.080]   Now I just want to remind ask at BMI that this is in use in service of news and commentary.
[00:20:03.040 --> 00:20:11.280]   Not being used for any aesthetic value. I think it's pretty funny. So how does Renee's technique?
[00:20:11.280 --> 00:20:15.600]   Does it because does he have to use his screen recorder and all that? Yeah, I think he's doing
[00:20:15.600 --> 00:20:19.280]   also. Yeah. Yeah. Here's another one from Harry. This is the first one.
[00:20:25.120 --> 00:20:34.080]   It's Bugs Bunny and Elmer Fudd. There doesn't apparently exist in Elmer Fudd and emoji. It's
[00:20:34.080 --> 00:20:41.920]   kind of a limited. Actually, there's some concern about believe it or not. I managed to find all
[00:20:41.920 --> 00:20:49.040]   the negatives. There's there's some concern about this because Apple of course Apple says your
[00:20:49.040 --> 00:20:55.360]   the face ID information is stored in the secure enclave is not available to anybody else. We don't
[00:20:55.360 --> 00:20:59.680]   see it. Only the phone sees it and it does a very good job of recognizing you. I'm actually
[00:20:59.680 --> 00:21:05.440]   pretty impressed with face ID. I wasn't you know, it's as good as it could be I think in the
[00:21:05.440 --> 00:21:10.320]   circumstances. But there's some concern because there is an API for third party developers to use
[00:21:10.320 --> 00:21:16.560]   the cameras in the notch. I imagine Snapchat be one of the first, right? You wouldn't that be a
[00:21:16.560 --> 00:21:24.000]   great way to use this get those Snapchat characters use the notch and do a better job of it. And so
[00:21:24.000 --> 00:21:29.360]   and there's nothing to stop them from ex exfiltrating that information from the phone to the Snapchat
[00:21:29.360 --> 00:21:35.920]   servers. All the information delivered by the the notch. So there's some. So you choose to say yes
[00:21:35.920 --> 00:21:40.320]   or no, you have to prove to an application. So you would approve it if you feel comfortable with
[00:21:40.320 --> 00:21:45.360]   them. Maybe knowing how you feel when you look at their app. Yeah, I think that's fair and the
[00:21:45.360 --> 00:21:51.360]   ACLU and the Center for Democracy and Technology say, well, maybe this is a problem. I don't know,
[00:21:51.360 --> 00:21:57.920]   you have to really stretch. You're right. You're right. You have to prove it.
[00:21:57.920 --> 00:22:05.840]   ACLU says a lot of things about face ID. They don't like it. But something to be aware of.
[00:22:05.840 --> 00:22:13.920]   Senior policy analyst at the ACLU says, you know, a bad guy could, you know, what? Get your face.
[00:22:15.200 --> 00:22:23.040]   Big deal. All right, I'm trying to find negatives. I really am. It's not easy.
[00:22:23.040 --> 00:22:28.880]   It's interesting because face ID misses me when I'm grumpy. Like if I have a face,
[00:22:28.880 --> 00:22:34.080]   yeah, it will miss me and my hairs and my face. It'll miss you. You have a choice of having it
[00:22:34.080 --> 00:22:38.560]   require that you're paying attention looking at the phone or not. I would imagine it's a little
[00:22:38.560 --> 00:22:42.720]   easier if you don't turn that on. I've left mine on. So somebody can't sneak up behind you and
[00:22:43.280 --> 00:22:48.640]   I don't care about that. But and grab your phone and then have to try to unlock it,
[00:22:48.640 --> 00:22:52.160]   not just steal the phone. And all you would have to do is go, I'm grumpy. I'll have to do
[00:22:52.160 --> 00:22:56.320]   is be grumpy. That's it. Which I probably would look shocked if someone, you know, smashed my,
[00:22:56.320 --> 00:23:01.360]   but like that would probably be enough to stop. I have some anecdotal evidence that it does get
[00:23:01.360 --> 00:23:06.160]   better. Apple said it would get better because occasionally it doesn't recognize me.
[00:23:06.160 --> 00:23:11.520]   When I was, I did it first with glasses, but I didn't have glasses. It didn't. I entered the
[00:23:11.520 --> 00:23:17.120]   coat. The so then you have to use your pin, but from then on, it recognized me with glasses.
[00:23:17.120 --> 00:23:22.080]   So I have a feeling it's updating all the time. Yes. And Apple said it would be. And I think there
[00:23:22.080 --> 00:23:26.560]   is evidence is doing it. Same thing. The studio lighting confused it at first, not anymore.
[00:23:26.560 --> 00:23:31.280]   It gets better. It's pretty impressive. Yeah, there was a it's to the point where a brother,
[00:23:31.280 --> 00:23:36.880]   go ahead, a brother, you know, did the exact same thing. So they had similar faces and two brothers
[00:23:37.680 --> 00:23:42.400]   unlocked the phone by, you know, having the phone relearned the new face, which was actually the
[00:23:42.400 --> 00:23:46.400]   brother's face, which was similar enough for the phone to be mixed up. So there's probably,
[00:23:46.400 --> 00:23:51.280]   you know, some updates that will make it a little bit more attuned to that. But it is
[00:23:51.280 --> 00:23:55.760]   constantly trying to relearn. Like if I probably do the passcode with a grumpy face, it would
[00:23:55.760 --> 00:23:59.360]   probably not just grumpy Georgia. It doesn't. So it doesn't recognize you. It asks for the
[00:23:59.360 --> 00:24:03.680]   passcode. You enter it. And I suspect it's that it's say, Oh, well, that was you, I guess.
[00:24:03.680 --> 00:24:09.680]   We'll add grumpy to your repertoire. We did try it with identical twins, Megan Moroni, one of my
[00:24:09.680 --> 00:24:16.720]   co hosts, tried her iPhone 10. She had one of her sons, Huck, unlock it with his face and then
[00:24:16.720 --> 00:24:20.960]   gave it to Milo Milo was able to unlock it. This is what Apple said could happen with identical
[00:24:20.960 --> 00:24:26.240]   twins in there. They were right. So that's a drawback. You can only have one face in there.
[00:24:26.240 --> 00:24:30.880]   Unlike the fingerprint, I used to let my wife have her fingerprint on there so she can get to my
[00:24:30.880 --> 00:24:35.520]   phone when she needed to do now. It's I can, you know, I have to give her the passcode.
[00:24:35.520 --> 00:24:46.160]   I fix it ran to Australia as they are want to do to get an iPhone 10 so they could destroy it.
[00:24:46.160 --> 00:24:53.520]   We had Kelsey from I fix it on the new screensavers yesterday. A couple of surprise, not surprise.
[00:24:53.520 --> 00:24:58.000]   It's been interesting things. A, they gave it a repairability score of six, which is not bad.
[00:24:59.280 --> 00:25:03.920]   Battery almost than I thought. They found the batteries in two modules. It's an L-shaped battery
[00:25:03.920 --> 00:25:10.240]   with two different modules. And as a result, the logic board has an odd shape in his jam-packed.
[00:25:10.240 --> 00:25:15.440]   They figured out it has three gigs of RAM. Apple never talks about that, but that seems more
[00:25:15.440 --> 00:25:20.640]   than adequate. Of course, it has the A11 Bionic as we expected. It actually has quite a few custom
[00:25:20.640 --> 00:25:26.880]   processors on it, which is kind of interesting. It's got a lot of smarts in here. There's the,
[00:25:28.080 --> 00:25:31.920]   you know, they give the chip numbers, but there's definitely a motion co-processor
[00:25:31.920 --> 00:25:38.400]   in there and some other things. It's a, for such a tiny logic board, we're in a lot of stuff in there.
[00:25:38.400 --> 00:25:45.280]   All right. I don't know what else to say. That's the iPhone 10. Anything else anybody
[00:25:45.280 --> 00:25:51.280]   wants to add? Do you want one now? It's gorgeous. It is the best screen. It actually, I have it
[00:25:51.280 --> 00:25:57.520]   right next to a, a note eight, which until now was the best screen I could find. Samsung Galaxy
[00:25:57.520 --> 00:26:01.120]   Note 8. And I think the colors are actually more accurate on the iPhone.
[00:26:01.120 --> 00:26:07.840]   Yeah, the Note 8 colors look blue or don't they? Yeah. They also pop a little bit, right? They're,
[00:26:07.840 --> 00:26:13.440]   Samsung kind of, even if you turn on cinema, which is the most accurate, I think, of the,
[00:26:13.440 --> 00:26:19.440]   of the choices. I'll give you an example. If I compare these, here, there's the Aussie icon on
[00:26:19.440 --> 00:26:23.600]   the Note 8 on the left and compare it to the red of the Aussie icon on the iPhone. Now,
[00:26:23.600 --> 00:26:28.400]   maybe those icons have different colors, but I would guess that Aussie's doing the same thing
[00:26:28.400 --> 00:26:35.040]   on both phones. And the red is, actually feels more true. It's a little bit, maybe magenta or pink
[00:26:35.040 --> 00:26:41.440]   on the Note 8. And it feels more true on the iPhone. And this is with the cinema mode on the
[00:26:41.440 --> 00:26:46.400]   Note 8. They have an adaptive mode that really pops it that makes it look, wow. And I think that
[00:26:46.400 --> 00:26:50.880]   probably Samsung is going to start having to think about OLEDs and say, well, maybe we should
[00:26:50.880 --> 00:26:55.760]   make these more naturalistic and not quite so bright. People who Apple was very quick to point out,
[00:26:55.760 --> 00:27:00.560]   now it's an OLED. You guys, you iPhone, people aren't used to it. When you tilt it,
[00:27:00.560 --> 00:27:05.520]   it's going to get a little blue. And then, yeah, that's anybody's using an OLED.
[00:27:05.520 --> 00:27:10.000]   And does it also have issues with polarized sunglasses?
[00:27:10.000 --> 00:27:14.800]   I think they're using circular polarization on it, because I've been told it does not.
[00:27:14.800 --> 00:27:16.960]   Brian, did you test that?
[00:27:18.080 --> 00:27:22.560]   So it doesn't have to do with whether it's polarized or non-polarized. I actually had a pair of ray
[00:27:22.560 --> 00:27:27.920]   bands that were polarized and worked with Face ID. But I had a different pair of sunglasses that
[00:27:27.920 --> 00:27:33.040]   were non-polarized and didn't work with Face ID. And I asked Apple about it. They said it has to do
[00:27:33.040 --> 00:27:41.600]   if the lenses filter out a certain part of the IR spectrum, just that specific wavelength.
[00:27:41.600 --> 00:27:46.240]   If those sunglasses block that part of your eyes from being seen, then it doesn't work
[00:27:46.240 --> 00:27:48.720]   with some sunglasses, but most.
[00:27:48.720 --> 00:27:51.920]   Because those are the IR light in here. But what about, can you read,
[00:27:51.920 --> 00:27:54.640]   I think you were talking about readability with the sunglasses.
[00:27:54.640 --> 00:28:00.000]   Right. When you flip it, a lot of devices, when you flip them 90 degrees,
[00:28:00.000 --> 00:28:04.560]   polarized sunglasses will basically turn them opaque.
[00:28:04.560 --> 00:28:09.840]   Some curious whether that's an issue. It shouldn't be an issue on a modern display.
[00:28:09.840 --> 00:28:13.520]   But I saw somebody had talked about that.
[00:28:14.080 --> 00:28:19.200]   Yeah, remember that Apple, this is a Samsung panel, but Apple's to Apple specifications.
[00:28:19.200 --> 00:28:26.800]   You know, to answer your question, Leo, one of the things actually that I like about this phone
[00:28:26.800 --> 00:28:32.240]   is the absence of the home button. That's always been a pet peeve of mine about the iPhone. It seems
[00:28:32.240 --> 00:28:41.040]   old fashioned. The constantly having to press that button and double press to go back to the
[00:28:41.040 --> 00:28:48.640]   home screen and all of that. It's just a waste of real estate that can be used for a display.
[00:28:48.640 --> 00:28:56.080]   So I'm probably the opposite of many long time iPhone users in that I'm glad to see
[00:28:56.080 --> 00:29:05.040]   the home button gone. I think that most people within about a week or so will adapt to whatever
[00:29:05.040 --> 00:29:10.880]   UI changes come because you spend, you know, if you're spending a thousand dollars on a phone,
[00:29:10.880 --> 00:29:15.600]   you're spending eight or 10 hours a day with it off and on. I didn't sleep at all last night.
[00:29:15.600 --> 00:29:22.160]   Let's put it that way. I was playing with my precious all night. Brian, what's been your
[00:29:22.160 --> 00:29:27.840]   experience? Did you get used to the UI pretty quickly? It took me, I'm still fumbling around a
[00:29:27.840 --> 00:29:32.400]   little bit when it comes to using reachability. You know, that shortcut to make the top of the
[00:29:32.400 --> 00:29:37.760]   screen come down to the bottom. Sometimes I swipe in the wrong place, but overall, it took me a
[00:29:37.760 --> 00:29:43.840]   few days to get used to it. I think I don't miss the home button that much, but there's some things
[00:29:43.840 --> 00:29:48.640]   that I could still do faster. Like app switching was faster when I had the home button. But I agree
[00:29:48.640 --> 00:29:54.160]   with Ed. I think it's about time to get rid of it and just embrace the future if you will because I
[00:29:54.160 --> 00:29:59.760]   think it's faster overall to not have a home button. Yeah, I have to say that I agree with you,
[00:29:59.760 --> 00:30:04.240]   Ed. The home button does feel kind of antiquated. Even Samsung doesn't have a home button anymore.
[00:30:04.240 --> 00:30:10.800]   This is the home button you sweep up from the bottom. So that's easy. The recents is a little
[00:30:10.800 --> 00:30:15.840]   challenging for me, Brian, as well, where you have to swipe up halfway and wait.
[00:30:15.840 --> 00:30:23.040]   Yeah, yeah, yeah. That's that's it. And then you can't get rid of an app by sweeping it off
[00:30:23.040 --> 00:30:30.640]   anymore. You have to press hold till you just like deleting an icon and then you can sweep away.
[00:30:30.640 --> 00:30:35.840]   Yeah, Apple. Apple told me they wanted to make that harder to do because people aren't supposed
[00:30:35.840 --> 00:30:43.440]   to do that. That's Apple for you. We'll leave it in, but you really shouldn't do that.
[00:30:43.440 --> 00:30:49.840]   Exactly. I find I use recents a lot. And you know, of course, the 3D touch iPhones,
[00:30:50.640 --> 00:30:53.840]   when iOS 11 first came out, they eliminated the best way to get
[00:30:53.840 --> 00:30:59.360]   recents, which is to press and hold on the left side until you get the haptic feedback and then
[00:30:59.360 --> 00:31:03.760]   slide over. And I use that all the time to paste passwords in, for instance, from LastPass.
[00:31:03.760 --> 00:31:09.920]   That no longer, ironically, it works again on the iPhone 7 and 8. They patched iOS 11 to make
[00:31:09.920 --> 00:31:14.560]   that work again, but it doesn't work at all on iPhone 10. And I realized a number of the things
[00:31:14.560 --> 00:31:19.200]   we're seeing UI, things we're seeing with iOS 11, the changes have to do with the fact that the
[00:31:19.200 --> 00:31:24.400]   iPhone 10 was coming, including that recents change, which it was a little weird in the beta.
[00:31:24.400 --> 00:31:28.800]   I would think they fixed it when iOS 11 came out. I know I'll be honest, I don't see the notch
[00:31:28.800 --> 00:31:36.560]   anymore. It doesn't bother me. I don't the UI I'm completely used to. If I know it's not faster
[00:31:36.560 --> 00:31:44.320]   because it's the same chip, it feels a little faster. I'm I have to say this is a modern phone.
[00:31:44.320 --> 00:31:49.200]   And yeah, I thought that I would miss the home button a lot more than I did.
[00:31:49.200 --> 00:31:55.600]   It's it's easy to use. It's kind of intuitive. I also find that like like switching between things,
[00:31:55.600 --> 00:32:00.400]   it's a little bit weird. And I often don't know how to like close something at first. I have to
[00:32:00.400 --> 00:32:04.480]   like rethink, oh, yeah, yeah, I just swipe again. But I think that I'm going to feel really
[00:32:04.480 --> 00:32:09.920]   comfortable with that as well. The buttons have all changed. Now the power off button invokes Siri
[00:32:09.920 --> 00:32:14.080]   instead of you can turn off the screen. And if you hold it, it invokes Siri. And if you want to
[00:32:14.080 --> 00:32:20.320]   turn off the phone, which I guess Apple also thinks you probably shouldn't do. You have to press
[00:32:20.320 --> 00:32:26.480]   two buttons on either side and hold it. And as we mentioned, the other thing, of course, is don't
[00:32:26.480 --> 00:32:34.400]   drop it because Apple has already said the screen repair is what is it 260 259. And this is without
[00:32:34.960 --> 00:32:39.680]   you know, without the extended warranty without the iPhone, Apple care plus. And every other repair,
[00:32:39.680 --> 00:32:46.480]   including cracking the back would be 500 plus dollars. So don't break it. Get a very tough idea
[00:32:46.480 --> 00:32:52.800]   immediately. I got a tougher case than my original case with the cover. Because I'm a
[00:32:52.800 --> 00:32:56.640]   terrified I'm going to break this thing. Very expensive to repair.
[00:32:57.360 --> 00:33:04.640]   Now, didn't that include? Didn't they include Apple care plus with the phone if you purchase it
[00:33:04.640 --> 00:33:10.720]   on installment through the upgrade plan, I think early on great plan. Yeah,
[00:33:10.720 --> 00:33:14.480]   that's the one where you get a new phone every time it comes out. But I don't think that's
[00:33:14.480 --> 00:33:20.160]   economical. I think you're paying extra. Is it? Yeah, you're essentially leasing a phone kind of
[00:33:20.160 --> 00:33:24.320]   like leasing a car. You never own the phone because you have to give it back before you get the new
[00:33:24.320 --> 00:33:29.280]   one. And so you get on this endless treadmill of getting new phones every year. I don't really
[00:33:29.280 --> 00:33:33.440]   like it because it seems like rampant consumerism in my opinion. But I'm sure there are plenty of
[00:33:33.440 --> 00:33:37.120]   people who enjoy doing that. That's why I don't like any of this. And I hate even
[00:33:37.120 --> 00:33:44.880]   I hate that we spent half an hour talking about it. But it is after all the premier product from
[00:33:44.880 --> 00:33:50.160]   the richest company in the world. And they're making a lot of money on it. A lot of people are
[00:33:50.160 --> 00:33:55.680]   going to buy it. If they sold 46 million iPhone at sevens and eights last quarter,
[00:33:55.680 --> 00:34:01.040]   they're going to sell that many. I'm sure with the iPhone 10 even. Do you think the price is
[00:34:01.040 --> 00:34:07.760]   I mean, it's ridiculous. But do you think that Apple people care? No, they won't. If you think
[00:34:07.760 --> 00:34:14.160]   no, if you think about how how long you spend on your phone in comparison to what you do with any
[00:34:14.160 --> 00:34:18.400]   other technology, there's this probably the technology that it makes the most spends to spend the most
[00:34:18.400 --> 00:34:22.640]   amount of money on anyways. Because it matters to you. So I think that most people that already buy
[00:34:22.640 --> 00:34:28.000]   Apple products usually are doing well enough or spend their resources so that they can afford this.
[00:34:28.000 --> 00:34:32.000]   And I don't think that they're going to mind. I think that in some ways it being so expensive
[00:34:32.000 --> 00:34:37.440]   makes people feel elite and better than others when they buy it, which is horrible statement of
[00:34:37.440 --> 00:34:44.080]   people in general. But it's probably very true. What did Tim Cook say about it, Brian?
[00:34:45.280 --> 00:34:51.600]   He said it's like buying a cup of coffee a day or something for a year. But I think he's talking
[00:34:51.600 --> 00:34:56.080]   about really fancy cups of coffee. I don't know where he gets his coffee. Very expensive.
[00:34:56.080 --> 00:35:02.000]   I get like two dollar cups of coffee or like, you know, I think about coffee in New York and
[00:35:02.000 --> 00:35:05.280]   buying coffee from the donut card. That's what I think about when I think about paying for a coffee.
[00:35:05.280 --> 00:35:09.600]   I don't think he's talking about you in that case. The coffee white. Yeah, no, I don't know.
[00:35:09.600 --> 00:35:14.480]   Definitely not talking about that. This is like a mocha chino with like, you know, cracked
[00:35:14.480 --> 00:35:18.800]   corn on top and like, you know, old flecks. Where can I get that? That sounds good.
[00:35:18.800 --> 00:35:25.840]   Go rack corn on top. Yeah, you know, something that only, only select few would get.
[00:35:25.840 --> 00:35:35.600]   I mean, the flagship models for the previous flagship model for the iPhone and the Samsung
[00:35:35.600 --> 00:35:43.280]   flagship are both up around. If you spec everything in there, they're around 900, 950 bucks. Anyway,
[00:35:43.280 --> 00:35:51.840]   already. So it's added. It's added a couple hundred dollars, perhaps. And I think more, I think
[00:35:51.840 --> 00:35:59.280]   more important than the absolute price is the psychological barrier of going into four figures
[00:35:59.280 --> 00:36:04.480]   for a phone. I think that's exactly it. It's a, there's a point.
[00:36:05.360 --> 00:36:10.960]   Yeah, but the, but the actual increase in price, especially if you think, you know, those cameras
[00:36:10.960 --> 00:36:18.240]   and the, and the sensors around them are not cheap. You know, a lot of the engineering that
[00:36:18.240 --> 00:36:24.000]   goes into the, what's inside the phone, you know, when you tear it down there, you know,
[00:36:24.000 --> 00:36:29.920]   that stuff's not cheap. And, you know, Apple likes to keep its margins. I don't think that they,
[00:36:29.920 --> 00:36:36.560]   I doubt that they've increased their margins for this device. But it's just a more expensive
[00:36:36.560 --> 00:36:41.920]   product. And they've bumped it up. You know, what is it? 20% higher than the previous model?
[00:36:41.920 --> 00:36:50.800]   I just broke my iPhone. What? Are you kidding me? What's that? What's going on? So somebody in the
[00:36:50.800 --> 00:36:55.200]   chat room said, Oh, you don't have to pause. You just go up and swipe to the right. And I,
[00:36:55.200 --> 00:37:01.200]   something strange happened. It's not the owner. Now you have to pause. What's that? What is that?
[00:37:01.200 --> 00:37:05.120]   I have no idea what it is. I'm going to try to do that. I'm going to try to do that.
[00:37:05.120 --> 00:37:11.040]   Oh, you know what? It's because I don't have any reasons. It did work. So I just need, I need
[00:37:11.040 --> 00:37:14.480]   to create some reasons. Let me, let me create some. That's what happened. I don't have any
[00:37:14.480 --> 00:37:19.440]   reasons. All right. Let me, let me open some apps. Now I have reasons that scared me. I thought,
[00:37:19.440 --> 00:37:26.880]   Oh my God, I broke it. Thank God you have AppleCare. Yeah, I'm sure this is going to work. Just
[00:37:26.880 --> 00:37:32.320]   fine. Forget it. I don't have AppleCare. By the way, don't you know, I'm just bugging you. I don't
[00:37:32.320 --> 00:37:36.560]   buy that stuff. But you know what? I know I know. Buy it with a credit card. So many credit cards
[00:37:36.560 --> 00:37:41.760]   will fix it if you break it, right? I don't know how it is in Canada. Really? Yeah. I don't think
[00:37:41.760 --> 00:37:48.480]   any of my credit cards would fix my, again, I don't know what consumer. So this, you should
[00:37:48.480 --> 00:37:54.320]   write this up, Brian. So yeah, you know, in the past, I've told people not to buy an extended warranty
[00:37:54.320 --> 00:37:59.120]   program. And that's with past iPhones because if you go to a repair shop, you know, like a screen
[00:37:59.120 --> 00:38:04.640]   repair, something like $7,500. So it's cheaper overall than that get the extended warranty. But
[00:38:04.640 --> 00:38:09.600]   I might have to revise that recommendation based on the sheer cost of fixing an iPhone 10. It's
[00:38:09.600 --> 00:38:14.800]   totally different. I never buy it. Now I wish I had to be honest with you. But if, but some credit
[00:38:14.800 --> 00:38:19.920]   cards will give you extended warranty protection, that won't, but some will give you purchase
[00:38:19.920 --> 00:38:26.320]   security, including if you break it, you'll get a fix. So you should check with your,
[00:38:26.320 --> 00:38:32.800]   check your credit cards and see if they offer that kind of protection, because that might be a way
[00:38:32.800 --> 00:38:41.120]   to avoid paying for all of that. And I believe Leo that you could still get Apple Care if you
[00:38:41.120 --> 00:38:46.480]   wanted, because isn't there like two weeks that you have that you can purchase Apple Care
[00:38:46.480 --> 00:38:50.560]   between that time? And you haven't received your phone yet. So well, this is my phone. We're
[00:38:50.560 --> 00:38:57.680]   going to at least is going to take my phone. So most of the most of the credit card policies
[00:38:57.680 --> 00:39:04.480]   that I've seen don't consider a cracked screen to be a warrant. If it still works,
[00:39:06.000 --> 00:39:12.480]   it basically has to be non-fudge effect. So if you break your screen, Ed, what you're saying is then
[00:39:12.480 --> 00:39:18.320]   step on the phone a few times. So it's working. Yeah, really makes it run over it, run over it once
[00:39:18.320 --> 00:39:24.960]   or twice with the car and get yourself a good and get yourself a good story, because you're going
[00:39:24.960 --> 00:39:31.120]   to have to swear to that, you know, under penalty of perjury that that's exactly what happened to
[00:39:31.120 --> 00:39:34.880]   it. So according to credit cards.com, there are four different things a credit card can do.
[00:39:34.880 --> 00:39:40.560]   Extended warranty, purchase security, price protection, return protection. Some cards offer all for
[00:39:40.560 --> 00:39:45.360]   the purchase security can replace, repair, or reimburse card holders for damaged,
[00:39:45.360 --> 00:39:51.280]   lost or stolen eligible items purchased with that credit card. You have to file within a specific
[00:39:51.280 --> 00:39:57.200]   time, typically 90 days after the incident, there may be caps from $510,000. And there can also
[00:39:57.200 --> 00:40:03.520]   be an annual reimbursement cap. So it might be that it will only deal with if it's over $500 worth
[00:40:03.520 --> 00:40:08.080]   of damage or whatever. But you should check with your credit card and see if they've got anything
[00:40:08.080 --> 00:40:12.480]   like that. I, you know what, I might buy Apple Care because this is such an expensive phone to fix.
[00:40:12.480 --> 00:40:18.560]   Right. I think in the past, by the way, if you updated the iOS 11 and you can no longer type
[00:40:18.560 --> 00:40:28.080]   the letter I, Apple has a fix for you. I've been having this problem. Have you? Yeah,
[00:40:28.080 --> 00:40:32.000]   it's I've been sending that weird a thing to like a million people when I type I,
[00:40:32.000 --> 00:40:40.160]   I will be wrong here. Brian 10 Chen, Apple says, if you type the letter I and it auto-corrects it to
[00:40:40.160 --> 00:40:45.920]   an A with a symbol, it's a simple fix. You go to settings, general keyboard, text replacement,
[00:40:45.920 --> 00:40:50.400]   you add a new replacement for the phrase, you type an uppercase I for the shortcut,
[00:40:50.400 --> 00:40:56.400]   you type a lowercase I, and it's all fixed. Or they could just update the software.
[00:40:58.720 --> 00:41:03.120]   This is such an Apple bug. It's so weird. There was a bug briefly because of the time change,
[00:41:03.120 --> 00:41:07.840]   you know, in the United States, we just went off daylight saving time and unfortunately it stopped
[00:41:07.840 --> 00:41:11.600]   working. But if you asked your Apple Watch or series three Apple Watch what the weather was,
[00:41:11.600 --> 00:41:17.280]   if you asked Siri, it would crash. But that's fixed now, unfortunately, because I'd love to do
[00:41:17.280 --> 00:41:23.120]   that for you. And let me just, I'm just curious if the iPhone 10 has the calculator bug that we
[00:41:23.120 --> 00:41:29.600]   talked about last week. That's where if you type too fast, the calculator thinks one plus two plus
[00:41:29.600 --> 00:41:36.880]   three is 23. Yeah, it's still there. That's an animation bug. Yeah, it's not a, you know, if you
[00:41:36.880 --> 00:41:43.840]   very slow, oh, I was still doing it. One plus, you have to wait till the animation stops on the plus.
[00:41:43.840 --> 00:41:50.160]   And then you get the right answer. But if you're, if you don't, if you're just do it, you don't have
[00:41:50.160 --> 00:41:55.840]   to do it super fast. It's kind of dopey. Get your $1,000 back.
[00:41:55.840 --> 00:42:02.000]   Well, my advice, if you're doing your taxes this year, don't use the Apple calculator because you
[00:42:02.000 --> 00:42:07.520]   might you may either over or underpay. It's unclear. And whatever you do, don't use the letter I.
[00:42:07.520 --> 00:42:13.920]   Renee gave me a tip that it's going to be it's fixed in beta. Yes, the fact somebody made that
[00:42:13.920 --> 00:42:20.720]   to the 11.2 beta or whatever it is. If you're doing your taxes on your on your Apple
[00:42:20.720 --> 00:42:26.480]   calculator, there's probably already you should do that on. Not a computer.
[00:42:26.480 --> 00:42:30.800]   Do it on a computer. Don't use an Intel chip for the rounding error. All right. No, that's old.
[00:42:30.800 --> 00:42:34.000]   That's old. Ed and I remember that. Remember that, Ed? Intel made a
[00:42:34.000 --> 00:42:40.400]   processor to do floating point math. Yeah, the floating the floating point bug. Sure. That was
[00:42:40.400 --> 00:42:47.120]   a that was a good one. It's not the first time there's been a problem. All right. What else?
[00:42:47.120 --> 00:42:52.080]   Just want to make sure we cover all the iPhone 10. I don't have any pictures of me in a brazier.
[00:42:52.080 --> 00:42:57.040]   Maybe you do. Ed.
[00:42:57.040 --> 00:43:09.040]   So I've heard about this, but but that was not related to iPhone 10 though. That's an iOS.
[00:43:09.040 --> 00:43:15.920]   That's Apple photos. It's not even a bug. It's an Apple photos feature. They categorize so you can
[00:43:15.920 --> 00:43:21.360]   look for dogs, but but somebody figured out it doesn't you can't you can type in brazier. And if
[00:43:21.360 --> 00:43:28.000]   there are pictures of you in a brazier or just braziers in general, those will show up. But so
[00:43:28.000 --> 00:43:37.840]   will Abacus and zucchini, but not underwear boxers nude. But brazier bando bra bras. Those will all
[00:43:37.840 --> 00:43:45.200]   show up. Is that something to be eggplant? Yes. If you but you have to have a picture of eggplants.
[00:43:45.200 --> 00:43:50.080]   Yeah. I don't have any pictures of me in braziers or I don't think we're eggplants.
[00:43:50.080 --> 00:43:56.000]   I think it's a feature. If you have photos of you that every category, right?
[00:43:56.000 --> 00:43:59.760]   Well, no, it can have every category, but also if they have pictures of you in a bra, then at least
[00:43:59.760 --> 00:44:04.560]   you can find them and delete them before you give your phone to your mom or something like that.
[00:44:04.560 --> 00:44:08.240]   I actually just makes it a little easier to find what you have to delete.
[00:44:08.240 --> 00:44:12.400]   When I read about this, I actually tried it just to see if there were any pictures you put your
[00:44:12.400 --> 00:44:18.320]   wear one or did you just get photos? Oh, that's a good idea. Oh, I'll go home and do that tonight.
[00:44:22.320 --> 00:44:28.320]   I remember the show where you were just with the trees. Yeah, I was naked. I ordered a bra on
[00:44:28.320 --> 00:44:34.000]   I was one of my kick starters was the Joey bra, which is but it didn't fit. What's the Joey
[00:44:34.000 --> 00:44:40.560]   bra? It let you I think you could put ID it had a pouch, like a Joey, like a kangaroo baby. It had
[00:44:40.560 --> 00:44:46.480]   a pouch in the bra. That's pretty useful. That's just a good idea. I've ordered such stupid stuff.
[00:44:46.480 --> 00:44:53.120]   I actually need to be kept from Kickstarter because I've actually ordered stuff that just know
[00:44:53.120 --> 00:44:58.160]   like the floating bonsai tree. Did you ever get the floating bonsai tree? I did, but oh,
[00:44:58.160 --> 00:45:03.680]   yeah, this was actually a great disappointment. The impression I got was that you would actually
[00:45:03.680 --> 00:45:15.200]   get a bonsai tree. But yeah, no, you have not included. What I what I got. Well, I'll show you
[00:45:15.200 --> 00:45:19.840]   actually because I can the nice thing about Kickstarter is all the humiliating experiences
[00:45:19.840 --> 00:45:26.080]   you've had buying things on Kickstarter are always available. So, you know, a lot of this stuff
[00:45:26.080 --> 00:45:33.120]   hasn't come yet. Air bonsai. So it wasn't cheap, 200 some bucks and you kind of get the impression
[00:45:33.120 --> 00:45:38.080]   if even if you look at the video that there is a bonsai involved. But what you get instead is the
[00:45:38.080 --> 00:45:44.480]   is a rock that floats and then you put the bonsai in it. But of course, the bonsai unbalances the
[00:45:44.480 --> 00:45:50.960]   rock. So you then chip off pieces of the rock to make the bonsai balance.
[00:45:50.960 --> 00:45:56.160]   Oh, this sounds like it's going to end poorly. Yeah, I just I just it's in a closet somewhere.
[00:45:56.160 --> 00:46:00.400]   Anybody wants it. I'll give it to you free. No cost floating rock floating rock.
[00:46:00.400 --> 00:46:07.040]   If the rock does float, I think adding the bonsai or even watering the bonsai could could cause
[00:46:07.040 --> 00:46:14.000]   price. Even if it was a big bonsai. That's what you need a fake bonsai. What did I think of that?
[00:46:14.000 --> 00:46:20.080]   A plastic bonsai that at least wouldn't change its shape or grow or anything like that.
[00:46:20.080 --> 00:46:22.640]   You wouldn't have to worry about killing it.
[00:46:22.640 --> 00:46:28.240]   So sad about so many of these things. I don't even want to look at it like the Robin. I
[00:46:28.240 --> 00:46:33.760]   ordered it. I bought this the radio head song you've got there. Isn't it fake plastic bonsai?
[00:46:33.760 --> 00:46:41.040]   Like fake plastic trees is of course like many of the radio head songs is totally depressing.
[00:46:41.040 --> 00:46:46.320]   Yes. Do you remember that when they gave they had kindergarteners draw pictures listening to
[00:46:46.320 --> 00:46:52.160]   radio head and they were the greenest pictures you ever. Oh, yeah. That was awesome. You should
[00:46:52.160 --> 00:46:56.880]   include that in your study somehow, Georgia. That's there's something in there for you. All right,
[00:46:56.880 --> 00:47:02.160]   let's take a break. We're done. No more iPhone 10 talk. Okay, so those of you who have been
[00:47:02.160 --> 00:47:07.280]   plugging your ears for the last half hour, it's over. You don't have to think anymore. I'm going to
[00:47:07.280 --> 00:47:13.440]   talk about a lovely company located in beautiful Canada that does a wonderful thing. They did a
[00:47:13.440 --> 00:47:19.040]   wonderful thing for me way back when when I was a freelancer I flew to Canada did a call for help
[00:47:19.040 --> 00:47:24.960]   remember up there into Rogers in Toronto for one week a month. And of course then I would have to
[00:47:24.960 --> 00:47:30.960]   invoice them. Oh, that was fun. The worst part of my life was end of the month and I have to fire
[00:47:30.960 --> 00:47:38.080]   up Microsoft Word and Excel and I have to figure out what I spent get all my receipts. And the big
[00:47:38.080 --> 00:47:43.040]   problem was I had to convert to Canadian dollars. It was just a then Amber said no, no, no, there's
[00:47:43.040 --> 00:47:48.560]   something new and it was just starting up this. I'll tell you it. This was 2004. It was web 2.0 at
[00:47:48.560 --> 00:47:55.360]   the time. Fresh books. Here we are like 13 years later over 10 million people use fresh books.
[00:47:55.360 --> 00:48:02.320]   And it is the easiest way to send invoices but more than that because it turns out if you do
[00:48:02.320 --> 00:48:08.400]   invoicing with fresh books, if you track your expenses with the fresh books app, if you track
[00:48:08.400 --> 00:48:12.640]   your time and projects and when you get paid and all of that stuff happens automatically,
[00:48:12.640 --> 00:48:18.160]   turns out that's accounting without doing accounting, you're going to get all the information you need
[00:48:18.160 --> 00:48:23.360]   to know for instance what you spend what your expenses are your profit. A lot of freelancers
[00:48:23.360 --> 00:48:28.320]   I was one of them had no idea till tax time. Did I make money this year? Well, you'll know every
[00:48:28.320 --> 00:48:33.360]   moment. Just go to your fresh books dashboard at freshbooks.com. You're going to send professional
[00:48:33.360 --> 00:48:40.320]   looking invoices to take seconds. And because they have every invoice has a pay me button,
[00:48:40.320 --> 00:48:48.400]   you get paid on average 11 days faster. That is fantastic. I mean, that is just amazing.
[00:48:49.840 --> 00:48:55.760]   In fact, clients like it turns out clients don't like paying invoices anymore than you like making
[00:48:55.760 --> 00:49:01.200]   them. You can even set it up to have recurring invoices. If your clients agree recurring payments,
[00:49:01.200 --> 00:49:06.800]   you can reward prompt clients and encourage customer loyalty by automatically adding discounts
[00:49:06.800 --> 00:49:11.520]   to your recurring templates. You'll know what you did. You'll know when you did it. You can
[00:49:11.520 --> 00:49:16.560]   build for time by client but also by project. You can have different rates for different projects
[00:49:16.560 --> 00:49:22.720]   and services that the fresh books app, which is awesome on iOS and Android, you just press play
[00:49:22.720 --> 00:49:27.840]   on the app to track your time or do it on the website. It will sort the time entries chronologically
[00:49:27.840 --> 00:49:32.720]   in the invoice. Just put them right in there. So it's completely documented. You can even add
[00:49:32.720 --> 00:49:37.280]   future unbuilt time entries to recurring templates. So even though you haven't done them yet,
[00:49:37.280 --> 00:49:40.960]   you know it's going to happen. You just put that in the template and it's automatic.
[00:49:41.760 --> 00:49:47.600]   I love it. Recede attachments. You take a picture in the iOS app. They go right into the invoice
[00:49:47.600 --> 00:49:52.800]   and your employees can log into the FreshBooks mobile app for iOS and it's easy for them to take
[00:49:52.800 --> 00:49:58.800]   care of business too. See those nice people? Those are the great support staff. FreshBooks
[00:49:58.800 --> 00:50:02.400]   has a fabulous support staff in Toronto and because they're Canadian, you know they're nice.
[00:50:02.400 --> 00:50:06.960]   They really are. They're very sweet. I love FreshBooks. No wonder they were included in the
[00:50:06.960 --> 00:50:13.680]   Forbes small giants list of 2017. You could try it free. FreshBooks.com/twit. If you see on the
[00:50:13.680 --> 00:50:17.680]   form, how did you hear about us? Please do me a favor and put this week in tech in there so they
[00:50:17.680 --> 00:50:24.080]   know. FreshBooks.com/twit and a tip of the hat. Thank you FreshBooks for saving my life
[00:50:24.080 --> 00:50:31.520]   back when I was still freelancing and now I can afford an iPhone X. So it works.
[00:50:33.280 --> 00:50:38.720]   So now Brian, are you going to fix your eye problem? You actually had that. I was trying to make it
[00:50:38.720 --> 00:50:42.960]   happen. It didn't happen to me. Sorry. Which eye problem? The one when you type an eye? No,
[00:50:42.960 --> 00:50:47.360]   no, when you type an eye and you get an A. Yeah. Yeah. I should have fixed it during that commercial
[00:50:47.360 --> 00:50:52.800]   break. That was your opportunity, dude. Your chance. Stop sending people this weird alien
[00:50:52.800 --> 00:50:56.960]   language of A, whatever. Was it like a weird? What was the symbol? It was like a weird?
[00:50:56.960 --> 00:51:02.960]   I forgot. It was just a symbol I've never seen before. Yeah. I loved that you thought it was
[00:51:02.960 --> 00:51:08.400]   your fault, not the phone. Of course. That's how it works in technology. Let's be typing the
[00:51:08.400 --> 00:51:11.200]   letter I wrong every time. And now it's auto-acting. Right.
[00:51:11.200 --> 00:51:20.160]   That's the strangest thing. Jeff Bezos, he's very wealthy, the wealthiest man in the world,
[00:51:20.160 --> 00:51:27.840]   sold a significant portion of us. It must be nice to just say, you know, I'm going to sell some stock
[00:51:27.840 --> 00:51:35.200]   for a billion dollars. He's typically sold stock periodically over the last six years,
[00:51:35.200 --> 00:51:44.080]   900,000 to 1 million. He owns 80 million shares. In May, he sold almost a billion. But now thanks to
[00:51:44.080 --> 00:51:51.600]   the fantastic results, Amazon stock is up year to date, 48 percent shares up 18 percent since
[00:51:51.600 --> 00:51:57.120]   September alone, making not only Jeff Bezos, the richest man in the world, but kind of a nice little
[00:51:57.760 --> 00:52:05.840]   little payday. He wants to put about a billion dollars a year into his space project, Blue Origin.
[00:52:05.840 --> 00:52:10.480]   And I imagine the one who posted his training, some of his income as well.
[00:52:10.480 --> 00:52:18.560]   I have to tell you, I have to read you this, even though it's not strictly speaking accurate.
[00:52:18.560 --> 00:52:22.960]   This is fake news. Jeff Bezos, you know, Amazon's looking for a new headquarters.
[00:52:24.000 --> 00:52:28.960]   Jeff Bezos' heart breaks a little, reading Albany's Amazon headquarters pitch.
[00:52:28.960 --> 00:52:30.640]   Ever been to Albany, Brian X, Chen?
[00:52:30.640 --> 00:52:33.360]   I have it. Tell me about it.
[00:52:33.360 --> 00:52:37.840]   Cringing as he scanned the section touting the city as the economic and cultural core
[00:52:37.840 --> 00:52:45.040]   of New York state's capital region. Amazon CEO Jeff Bezos reportedly felt his heart break a little
[00:52:45.040 --> 00:52:49.360]   while perusing Albany's pitch to host the company's new national headquarters sources confirmed
[00:52:49.360 --> 00:52:54.800]   Tuesday. "Oh geez," he said. "You could tell they put a lot of work into this sad presentation."
[00:52:54.800 --> 00:52:59.600]   They even provided a concept sketch of our headquarters across the river from their little
[00:52:59.600 --> 00:53:05.680]   Amtrak station. The package included a custom made, SUNY Albany Great Dane's football jersey with
[00:53:05.680 --> 00:53:11.600]   Amazon written on the nameplate and laid out the many ways a new $5 billion campus would benefit
[00:53:11.600 --> 00:53:16.720]   from being situated nearby such landmarks as the New York State Museum and the EGG,
[00:53:17.680 --> 00:53:24.240]   a performance center, the proposal referred to as iconic. Bezos said,
[00:53:24.240 --> 00:53:27.760]   "It talks about how the port of Albany has one of the biggest grain elevators in the country or
[00:53:27.760 --> 00:53:30.880]   something and they keep calling themselves the next tech valley. God, I don't think I have the
[00:53:30.880 --> 00:53:36.000]   stomach to read this section about how much we'll love their tulip festival at press time Amazon
[00:53:36.000 --> 00:53:39.520]   reportedly received an addendum to Albany's proposal noting they're optimistic that United
[00:53:39.520 --> 00:53:44.000]   Airlines may begin offering flights between their city and Detroit within the next year.
[00:53:44.000 --> 00:53:51.280]   It's the onion. I'm sorry, I couldn't resist. Well, and it is clear that whoever wrote that
[00:53:51.280 --> 00:53:59.920]   has been to Albany because I've been to Albany a couple times doing little projects and
[00:53:59.920 --> 00:54:12.800]   it's a great place to jump off to Vermont or the Berkshires or basically anywhere but Albany.
[00:54:13.600 --> 00:54:21.680]   Anywhere but Albany. Amazon's founder, despite his further, I'm sorry, wait a minute, stop it.
[00:54:21.680 --> 00:54:27.680]   No fake ads. Thank you Bloomberg. I hate that autoplay video. I don't know. Thank you, by the way,
[00:54:27.680 --> 00:54:31.040]   Brian, the New York Times has yet to do autoplay video on its site. Thank you.
[00:54:31.040 --> 00:54:36.960]   I feel like I've encountered that before the New York Times website. I'm not sure. I'm just
[00:54:36.960 --> 00:54:42.080]   going to not comment. I might have spoken too soon. Hey, we all got to make a living, right?
[00:54:42.720 --> 00:54:52.000]   Somebody asked Bezos, well, what about philanthropy? Bill Gates famously, remember,
[00:54:52.000 --> 00:54:56.560]   Ed said, I'm not going to do it until I could spend enough time to do it right, which I thought
[00:54:56.560 --> 00:55:02.000]   was great. Zuckerberg has famously thrown money at Newark that didn't do anything and so forth.
[00:55:02.000 --> 00:55:08.480]   And of course, now Gates is doing philanthropy full bore. But
[00:55:10.080 --> 00:55:14.080]   the chair in computer science and engineering at the University of Washington, the Bill and
[00:55:14.080 --> 00:55:19.840]   Melinda Gates chair, and Laszaska says, Jeff is probably not quite ready to step down yet. And
[00:55:19.840 --> 00:55:24.000]   this is a guy who like Bill is fixated on changing the world in important ways. It's a full time job
[00:55:24.000 --> 00:55:31.600]   giving money. You have to imagine he'll be every bit as philanthropic as Gates. But not yet. I think
[00:55:31.600 --> 00:55:39.680]   that's fair. I think that's fair. I'm sorry. I'm not coming up with anything good for you guys to
[00:55:40.000 --> 00:55:46.800]   chew on. I apologize. Have you seen the calculator on iOS? Never. Let's see some animated poop
[00:55:46.800 --> 00:55:54.480]   emojis. And I've done one. Ryan, have you done one yet? The animated poop? I have. Yeah, of course.
[00:55:54.480 --> 00:56:00.720]   That's like the first thing I did first thing you do. Well, I'll give a shout out to somebody
[00:56:00.720 --> 00:56:11.360]   who's not on the panel today. Joanna Stern's video review of the iPhone 10 is all
[00:56:11.360 --> 00:56:18.080]   an emojis, including a lot of poop. The whole review. The whole review is done in an emojis.
[00:56:18.080 --> 00:56:23.040]   Oh, we got it. Yeah. It's really brilliant. You know, she she does very, very good work.
[00:56:23.040 --> 00:56:29.200]   But this one is above and beyond. There you go. She's there. She's been on this show many times.
[00:56:29.760 --> 00:56:32.960]   We got we actually trying to get her back. I'm watching an idea.
[00:56:32.960 --> 00:56:38.640]   Hey, this is an ad. Sorry. Yeah. Just talk amongst yourselves while we watch this pre-rolled.
[00:56:38.640 --> 00:56:46.320]   God, it's bad enough that we got the ads in the show and then you got to watch pre-roll. Here we go.
[00:56:46.320 --> 00:56:53.120]   Oh my God. How did she do the back? She's walking down. I've never seen the back of the poop emoji.
[00:56:53.120 --> 00:57:03.760]   It's the best iPhone in years. But it's also the most changed. At first, it can be pretty darn confusing.
[00:57:03.760 --> 00:57:09.680]   So for those of you listening. That's why I'm here. Emi. Emi too. There's real video, but they're
[00:57:09.680 --> 00:57:14.880]   superimposed and emojis on the heads of the Joanna and her. I'm going to show you the biggest
[00:57:14.880 --> 00:57:19.600]   changes to the iPhone. That's a unicorn. Plus tricks for getting used to them. How long?
[00:57:19.600 --> 00:57:25.360]   The emoji movie. But better. Before we stop using this. That means more screen.
[00:57:25.360 --> 00:57:29.120]   Very soon. It's one of those features you use once, right?
[00:57:29.120 --> 00:57:34.720]   I would say once. I would give it like a few months and then we will really hate them.
[00:57:34.720 --> 00:57:40.160]   I've talked to two people who are on the fence about being the iPhone or buying the iPhone 10.
[00:57:40.160 --> 00:57:44.960]   And once they try the Animoji or once they saw it or received one, they're like, I'm going to buy
[00:57:44.960 --> 00:57:50.400]   iPhone 10. So it seems to be the most like. Can I have a list of the names of those people?
[00:57:50.400 --> 00:57:53.840]   Because I'd love to just sell them. Well, I just wanted to delete them from my
[00:57:53.840 --> 00:57:59.120]   contest list because I don't want to get any messages from them. There are very limited
[00:57:59.120 --> 00:58:04.560]   and emojis. I mean, you only have seven or eight writers. There's an alien in the unicorn and a
[00:58:04.560 --> 00:58:12.560]   cat and a dog. I mean, pandas. It's not poop chickens. I think a snapchat has some past too.
[00:58:12.560 --> 00:58:18.320]   Snapchat. Well, that and I don't know if Snapchat is yet using the what do they call that in the
[00:58:18.320 --> 00:58:24.320]   notch? What are they? The infrared camera? All that stuff in there. It's basically a miniature
[00:58:24.320 --> 00:58:29.680]   Microsoft Connect. By the way, Ed, wasn't that funny that Microsoft intentionally, I think,
[00:58:29.680 --> 00:58:33.120]   announced that they were killing the connect the day the iPhone 10 came out?
[00:58:33.120 --> 00:58:40.880]   You know, there's never a shortage of irony in Redmond. It's, you know, there's it's it's like the
[00:58:41.440 --> 00:58:48.720]   the, you know, the irony range of, you know, of the United States. So yeah.
[00:58:48.720 --> 00:58:55.200]   Yeah. RF 2020, our chairman says the emoji thing is the saving grace of the iPhone 10. It's playful.
[00:58:55.200 --> 00:59:03.040]   Playful. It's cute. It's playful. I just, I think that you're only going to use it for so much.
[00:59:03.040 --> 00:59:07.920]   Like maybe, you know, giving really bad news through like a chicken might be easier than,
[00:59:07.920 --> 00:59:14.240]   you know, yourself in there. I saw, I saw that one of the video reviewers, I think it was a
[00:59:14.240 --> 00:59:20.400]   high snobiety on YouTube used it to send a breakup message to his girlfriend.
[00:59:20.400 --> 00:59:27.760]   I was about to say there's that's that's that's harsh. That's cold. It's cold. Was it the robot?
[00:59:27.760 --> 00:59:33.600]   That's what I want to know. On the other hand, you're pretty much sure that after that one's
[00:59:33.600 --> 00:59:39.520]   delivered, you're not going to get a take me back, baby. It's that's final.
[00:59:39.520 --> 00:59:43.520]   Now they're they're questioning why they dated you in the first place. So I guess in some ways,
[00:59:43.520 --> 00:59:49.040]   it makes you feel better. So I'm just looking at Snapchat. It doesn't it doesn't look any
[00:59:49.040 --> 00:59:56.160]   different. I I wonder at some point, snap. That's cute. Yeah. It's going to probably use the face
[00:59:56.160 --> 01:00:03.520]   ID, but it's not it's not doing that yet. Okay. In fact, it's strangely positioning stuff out of
[01:00:03.520 --> 01:00:08.640]   the that but this I mean, imagine this is the next thing they're going to do. Yeah.
[01:00:08.640 --> 01:00:11.920]   Wow. That's kind of cool. Straight down on stage.
[01:00:11.920 --> 01:00:21.120]   I'm sorry. I'm distracted. I've turned into the blue man crew. You you you did promise. I want to
[01:00:21.120 --> 01:00:25.920]   go on record here saying you did promise before the last break that that was that that was it.
[01:00:25.920 --> 01:00:28.240]   I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm sorry. I'm done.
[01:00:28.240 --> 01:00:31.760]   That was it. That was Snapchat. It wasn't really the iPhone 10. It was Snapchat.
[01:00:31.760 --> 01:00:34.480]   Wait, Snapchat. Go away. I'm done with you.
[01:00:34.480 --> 01:00:41.440]   Gotta keep you honestly. No, you're right. I promised and I don't know. We got the Joanna Stern.
[01:00:41.440 --> 01:00:46.960]   We started doing emojis and that was all over kindle oasis. Oh, the new kindle is here. Sure,
[01:00:46.960 --> 01:00:52.080]   that's kind of get everybody excited. Seems like bad timing to put out that view, huh?
[01:00:52.080 --> 01:01:05.120]   Did anyone even read this article? I'm just saying. I actually bought this. I like the kindle,
[01:01:05.120 --> 01:01:09.680]   but I know that I'm Leo, you buy everything. I know. It's not a fair statement to say they.
[01:01:09.680 --> 01:01:14.880]   I know. I'm one. Yeah. It's completely been superseded. I didn't even know that people really
[01:01:14.880 --> 01:01:20.160]   used kindles now that you could. It's waterproof. They do.
[01:01:20.160 --> 01:01:31.520]   A lot of people love kindles. The grayscale kindles for the immersive experience.
[01:01:31.520 --> 01:01:38.080]   It's like reading a book and it's very, very, very easy on the eyes in the way that a
[01:01:38.080 --> 01:01:45.120]   transmissive screen isn't. If I can pivot from that just a little bit, what I found
[01:01:45.120 --> 01:01:55.120]   interesting this week was some data on tablet sales that showed that Amazon is now up to,
[01:01:55.120 --> 01:02:03.840]   I think this is IDC's data, that Amazon is now well up over a 10% share of tablet sales.
[01:02:03.840 --> 01:02:10.800]   And so they've been steadily, very, very steadily growing. They were in the 2% and 3% range
[01:02:10.800 --> 01:02:18.480]   two years ago. And now they're up in the 10% to 15% range. In a static category,
[01:02:18.480 --> 01:02:24.800]   that's even more impressive because this is not a rising tide that's going to lift all boats.
[01:02:24.800 --> 01:02:30.960]   So there's a real temptation to look at the new device that's going to sell
[01:02:31.840 --> 01:02:37.680]   50 million units per quarter and to poo poo some device that's only going to sell only
[01:02:37.680 --> 01:02:41.920]   one or two or five million per quarter. That's really true, isn't it?
[01:02:41.920 --> 01:02:51.440]   Those make a tremendous impact on the lives of people. And I think Amazon has been very focused
[01:02:51.440 --> 01:02:57.440]   and has done a great job of engineering these things. And they're succeeding in the marketplace
[01:02:57.440 --> 01:03:01.600]   while nobody's paying any attention. It should point out though that after
[01:03:01.600 --> 01:03:08.240]   years of falling iPad sales, Apple reported an increase in both Mac, iPad sales as well as,
[01:03:08.240 --> 01:03:14.000]   of course, obviously the iPhone. So the iPad is coming back, maybe that new iPad Pro, the 10.5
[01:03:14.000 --> 01:03:18.160]   inch. Go ahead, Brad, I interrupted you. Oh, that's okay. I was just clarifying. So Ed,
[01:03:18.160 --> 01:03:22.480]   you're talking about touchscreen tablets, right? Not the kindles themselves, so the kindle fire.
[01:03:22.480 --> 01:03:28.240]   That is correct. That's why I said I'm pivoting from this. But yeah, this is basically the devices
[01:03:28.240 --> 01:03:35.360]   that are replacements for cheap PCs. Yeah. Yeah. The remarkable thing about Amazon strategy is that
[01:03:35.360 --> 01:03:41.680]   their Kindle fire cost is little something like $50. That's kind of insane considering it's a
[01:03:41.680 --> 01:03:47.200]   touchscreen that can play audio and stream, Spotify and do pretty much everything we want to do on
[01:03:47.200 --> 01:03:51.440]   a tablet. Granted, it looks crapier compared to an iPad. But for 50 bucks, you're going to buy this
[01:03:51.440 --> 01:03:56.000]   for your kids and let them destroy it for Christmas, right? And if there were any doubt that the
[01:03:56.000 --> 01:04:02.160]   Kindle tablets are really loss leaders for Amazon, they offer a $99 kids edition
[01:04:02.160 --> 01:04:08.240]   that's coded in rubber, but that they promise, oh, for two years, if it gets broken, if the kid
[01:04:08.240 --> 01:04:13.840]   breaks it, they just give you a new one. That's pretty amazing. For two years. Well, I mean,
[01:04:13.840 --> 01:04:20.640]   obviously, either it costs $10 to make or it's a loss leader. They don't care because you're going
[01:04:20.640 --> 01:04:26.080]   to buy so many copies of Finneas and Furb and games and so forth that they're making.
[01:04:26.080 --> 01:04:30.240]   Yeah, you're right. They have said on the record that it's a loss leader in that they don't make
[01:04:30.240 --> 01:04:33.920]   money off the hardware. They make it off selling you books and games and all that stuff. Yeah.
[01:04:33.920 --> 01:04:38.960]   And apparently they're doing a great job because the Kindle's fire sales are going.
[01:04:38.960 --> 01:04:46.000]   Is the Kindle Fire TV selling? Well, it's in the middle against Roku and
[01:04:46.000 --> 01:04:51.680]   Fire TV. Yeah, the Fire TV. You're talking about the stick? Yeah, or whatever. I mean,
[01:04:51.680 --> 01:04:56.400]   is that the only kind only form factor now? They use now. They make a stick and they make a box.
[01:04:56.400 --> 01:05:02.240]   They have a box. And they're both available in 4K models now. And I think it's the same thing.
[01:05:02.240 --> 01:05:10.640]   They're under the radar compared to a Roku or Apple TV or even the game consoles that do similar
[01:05:10.640 --> 01:05:16.880]   things. But for the people who are Amazon's absolutely most valuable customers,
[01:05:16.880 --> 01:05:24.480]   the people who spend big bucks in their ecosystem, it's a welcome to our living room.
[01:05:24.480 --> 01:05:35.120]   There's actually is a stratification of the gadget market. You have the people who really
[01:05:35.120 --> 01:05:40.160]   spend $1,000 on the smartphone and have to have the latest and greatest. And then the
[01:05:40.160 --> 01:05:44.960]   majority of people, the vast majority of people who aren't looking for the
[01:05:44.960 --> 01:05:51.120]   shiniest new thing, they're very price sensitive. And for them, a fire tablet in the Fire TV
[01:05:51.120 --> 01:05:58.960]   are priced right. Fire TV is $40. The stick and the box is like $60. And does everything that they
[01:05:58.960 --> 01:06:03.120]   want and they're happy with that. And that for them, that is the latest, greatest technology. Yes.
[01:06:04.640 --> 01:06:13.360]   Absolutely. It's easy for us geeks and enthusiasts to forget that we're in a tiny minority.
[01:06:13.360 --> 01:06:22.480]   Well, the thing that Apple has been extremely successful about is to concentrate on the segments
[01:06:22.480 --> 01:06:31.200]   of the market that have the highest profit. And those are the highest price tags. They're people
[01:06:31.200 --> 01:06:36.880]   who are not price sensitive. They can maintain their margins and they'll leave the rest of the market
[01:06:36.880 --> 01:06:45.920]   to a variety of Asian manufacturers and to some PC manufacturers and to companies like Amazon,
[01:06:45.920 --> 01:06:53.600]   which are not going to make money on the hardware, but can often find a way as Amazon has done to
[01:06:53.600 --> 01:06:59.680]   build a very creditable revenue stream from the ecosystem around the devices.
[01:07:00.560 --> 01:07:07.200]   I think it's funny because I think in a lot of ways, that's why people that do not use
[01:07:07.200 --> 01:07:11.600]   Apple products, they really can, there's a lot of hatred towards Apple and Apple products
[01:07:11.600 --> 01:07:17.600]   because of how they're priced high. And I think that always talking about how it's the greatest
[01:07:17.600 --> 01:07:22.960]   and magical, I think that there's a lot of backlash because of the same marketing that it works very
[01:07:22.960 --> 01:07:28.000]   well and it's very successful at. But I think that same success has created a lot of people very
[01:07:28.000 --> 01:07:31.840]   angry about us covering Apple, talking too much about Apple. It kind of takes more of the piece
[01:07:31.840 --> 01:07:39.440]   of the pie. And I get a lot of Apple hatred. Is that Renee's dog? Who's dog is that?
[01:07:39.440 --> 01:07:49.600]   I have three dogs here. I'm sorry. And we've had people coming. One of them is actually in my
[01:07:49.600 --> 01:07:56.400]   office right now. Lucy is here and she wants me to go over and let her out so she can bark at
[01:07:56.400 --> 01:08:01.520]   whatever the other two dogs are barking at. We're dogs hitting someone else and I think someone
[01:08:01.520 --> 01:08:08.960]   just came to the door. So no problem. I thought I might blame Georgia. The dogs are angry about Apple.
[01:08:08.960 --> 01:08:14.800]   I just look like the easiest person to blame Leo. You can be honest. Do you look like a dog person?
[01:08:14.800 --> 01:08:18.800]   Frankly, I do have a dog though. I do. Where is your dog in this move?
[01:08:18.800 --> 01:08:23.120]   Well, I'm going to be bringing her with, I'm going to my mom's house for a while.
[01:08:24.880 --> 01:08:27.520]   And I won't have any internet. Are you going to live in the basement?
[01:08:27.520 --> 01:08:33.600]   That's true statement. Yes. I really am. We've already moved all the stuff in. We've moved all
[01:08:33.600 --> 01:08:37.040]   our stuff to my mom's house. We're going to be living in the basement for two weeks with no
[01:08:37.040 --> 01:08:41.760]   internet. I'm going to go through some serious withdrawal. Oh my goodness.
[01:08:41.760 --> 01:08:48.240]   So I would take yeah. Oh my goodness. This is when a Kindle would be a good idea. Yeah.
[01:08:52.160 --> 01:08:58.560]   I've been really avoiding a couple of stories here. The Facebook Russia story, but we got,
[01:08:58.560 --> 01:09:06.160]   I guess we have to talk about it. The great poop emoji feud. I got I don't
[01:09:06.160 --> 01:09:10.480]   post back to poop. It all comes back to poop. We've had way too much scatological
[01:09:10.480 --> 01:09:15.200]   comments. And you'll have to throw it. You'll have to throw the hamburger emoji scandal in
[01:09:15.200 --> 01:09:19.600]   there with it. Well, that's a good one. That is a good one. Well, and we had a taste test, by the
[01:09:19.600 --> 01:09:26.640]   way, yesterday we made hamburgers Google Facebook and was it Apple the other one Apple style on the
[01:09:26.640 --> 01:09:31.520]   new screen savers and then we were blindfolded mega maroney and our blindfold and we tasted them.
[01:09:31.520 --> 01:09:36.720]   But I called foul because first of all, Megan doesn't eat meat.
[01:09:36.720 --> 01:09:43.040]   So they made veggie burgers, but I don't think that's a fair test.
[01:09:44.400 --> 01:09:50.800]   And then I don't know the emoji for a veggie burger is actually the same as the poop.
[01:09:50.800 --> 01:09:59.680]   That's kind of my attitude on it. And then I don't know what kind of lame cheese they used,
[01:09:59.680 --> 01:10:03.600]   but I couldn't even find the cheese with my tongue or tastes or anything. It didn't taste
[01:10:03.600 --> 01:10:09.920]   like there was any cheese on it. So I but Megan won because I got them. I can't. And actually,
[01:10:09.920 --> 01:10:16.400]   I think what do you tell me? You have three choices. You should get all three wrong, right? I mean,
[01:10:16.400 --> 01:10:21.840]   statistically, you should get one and a half right, right? I got zero. I got them all wrong.
[01:10:21.840 --> 01:10:28.400]   Megan got one right. So she won statistically, you should get like one in three. Yeah,
[01:10:28.400 --> 01:10:33.040]   you just one in three, right? You would think. Well, let's see, it's one half times one half
[01:10:33.040 --> 01:10:38.560]   times one half. All right. Well, each time actually you get one in one in three chances.
[01:10:38.560 --> 01:10:42.240]   It doesn't actually. Yes. Right. One third times one third. One third.
[01:10:42.240 --> 01:10:46.320]   Yeah. Let me get the other one. There's separate. It's 24.
[01:10:46.320 --> 01:10:57.440]   That's a bad joke. All right. Well, we'll save all those exciting stories for a moment later.
[01:10:57.440 --> 01:11:03.120]   Some there aren't weeks really where I wish I just didn't have to do it to it. We could just go
[01:11:03.120 --> 01:11:08.320]   home and say it's a dry show. And we're you know, there's nothing
[01:11:08.320 --> 01:11:11.760]   happened of interest. There's no big scandal.
[01:11:11.760 --> 01:11:16.160]   Well, there I mean, I don't know. I guess we could go on about Congress talking to Facebook and
[01:11:16.160 --> 01:11:22.960]   Twitter and Google and I can't. I mean, nobody ever gets excited about that stuff in the chat rooms.
[01:11:22.960 --> 01:11:25.760]   Well, our chat rooms, I don't know what they're talking about.
[01:11:25.760 --> 01:11:33.360]   The hearings are well, well, okay, you can fill me in because I it's like I couldn't even
[01:11:33.360 --> 01:11:40.320]   bring myself to read the transcripts let alone watch it. And then the New York Times,
[01:11:40.320 --> 01:11:46.160]   your journal asked Brian asked nine experts how to fix Facebook.
[01:11:46.160 --> 01:11:51.760]   And but these were very smart people. And I think mostly they said, I don't know. There's no,
[01:11:51.760 --> 01:11:58.480]   it's I don't know. No, I'll ask cause it's for Facebook. Somebody call me today. This is an
[01:11:58.480 --> 01:12:03.040]   interesting thing. He was 51 years old. He said, I'm embarrassed to admit it. I've never, I never
[01:12:03.040 --> 01:12:07.360]   did Facebook. So I joined it last week, my son's overseas and I wanted to see how he's doing. And
[01:12:07.360 --> 01:12:14.320]   so I joined Facebook. He said Facebook, I he did not put a interesting, they not put a profile picture.
[01:12:14.320 --> 01:12:22.160]   Or he if he did it was a random profile picture, Facebook shut his countdown briefly and said,
[01:12:22.160 --> 01:12:25.840]   we won't reopen your account until you sent us a photograph of yourself.
[01:12:26.720 --> 01:12:33.440]   And then so he did, he said, it has to be a clear full face picture of you. So he did.
[01:12:33.440 --> 01:12:38.320]   And then they said, okay, we'll get back to you. And then like a day later, they unlocked his account.
[01:12:38.320 --> 01:12:45.600]   The thing I don't know, the thing that I'm reading between the lines, tell me if I'm wrong here.
[01:12:45.600 --> 01:12:51.280]   It sounds like Facebook would know if it was him or not from the photo, but he was never a member.
[01:12:52.880 --> 01:12:59.440]   No, no, they just wanted. They wanted to know what he looks like. No, they wanted to prove that there
[01:12:59.440 --> 01:13:05.360]   was not a computer algorithm that's spitting these things out that that somebody was actually going,
[01:13:05.360 --> 01:13:09.200]   okay, get this message and respond to it and do a minimal amount of work. But look,
[01:13:09.200 --> 01:13:19.680]   the thing that came out 200 million fake accounts on Facebook, that is the, as Jason Kint pointed
[01:13:19.680 --> 01:13:27.120]   out, that would make it the seventh largest country in the world. And would mean if you got all of
[01:13:27.120 --> 01:13:33.280]   the fake accounts on Facebook together, they would outnumber all of the real accounts in the United
[01:13:33.280 --> 01:13:43.920]   States. So there really is a problem here. And this is ironic because Facebook always gave the
[01:13:43.920 --> 01:13:50.480]   impression that we have a real name's policy. You can't use a fake name, you kind of have to be real.
[01:13:50.480 --> 01:13:54.160]   But apparently they didn't care, I guess they care now.
[01:13:54.160 --> 01:14:02.240]   That's yes. No, that policy was always BS. What they wanted was accounts that looked real.
[01:14:02.240 --> 01:14:12.560]   And what the real name policy tended to do was punish people who had legitimate reasons to preserve
[01:14:12.560 --> 01:14:22.400]   their anonymity or work under a pseudonym. People who were being harassed by an ex, for example,
[01:14:22.400 --> 01:14:34.320]   or people who, or transgender people who had changed identities and changed genders,
[01:14:34.320 --> 01:14:41.920]   changed names and such. So the whole real name policy became a great way to harass anyone who
[01:14:41.920 --> 01:14:50.720]   was different. But it did, as my late cat could tell you, it is very easy for someone to create
[01:14:50.720 --> 01:14:53.840]   a fake account and have it still available on Facebook.
[01:14:53.840 --> 01:15:00.640]   Your late cat has a Facebook account. She still has an account and it has her picture on it.
[01:15:00.640 --> 01:15:09.920]   I mean, I've kept it there. It's been there for, she died five years ago. That account's been there
[01:15:09.920 --> 01:15:18.320]   for about 10 years. It's almost as old as Facebook is. And no one from Facebook has ever come to me
[01:15:18.320 --> 01:15:22.880]   and said, "Sorry, this isn't a real person. You're going to have to shut this thing down."
[01:15:22.880 --> 01:15:27.920]   And she has lots of friends on Facebook who are cats.
[01:15:27.920 --> 01:15:33.760]   Faith, is it Facebook? It said there's 200,000 fake accounts or somebody else.
[01:15:33.760 --> 01:15:43.280]   It's 200 million. 200 million. Did Facebook say that? And who is making all these accounts?
[01:15:43.280 --> 01:15:54.480]   Uh, that's a very, very good question. And why? What do you get? I always wanted this with
[01:15:54.480 --> 01:16:01.120]   Twitter too. Now, Twitter initially said, I love this, that they had only found 200
[01:16:02.320 --> 01:16:07.280]   Russian spam accounts on Twitter. That number went up a little bit after a while.
[01:16:07.280 --> 01:16:12.160]   I believe that the number that Twitter finally copped to was 16 million
[01:16:12.160 --> 01:16:17.840]   Yeah, not even. But we know, but that's, but we know because there,
[01:16:17.840 --> 01:16:20.560]   Twitter's like half fake, right?
[01:16:20.560 --> 01:16:25.520]   There's not like 10 real people that use Facebook. I mean, Twitter. That's it.
[01:16:27.520 --> 01:16:31.280]   And now, let's be in this, Twitter. Yeah. Me and Professor Jeff Jarvis.
[01:16:31.280 --> 01:16:36.880]   Yeah, no, he's fake. He's fake. We know he's fake. So, yeah. So Congress is,
[01:16:36.880 --> 01:16:43.920]   Congress was not completely thrilled by the testimony. And by the way, Mark Zuckerberg didn't go.
[01:16:43.920 --> 01:16:51.520]   Everybody sent their corporate councils to testify. Mark said he was very busy, but
[01:16:51.520 --> 01:16:59.200]   actually somebody posted a picture of him and his wife and his children. Let me see if I can find it.
[01:16:59.200 --> 01:17:04.720]   This is what Mark Zuckerberg was doing instead of
[01:17:04.720 --> 01:17:10.720]   testifying. Well, he has a lot of good Halloween costumes.
[01:17:10.720 --> 01:17:20.720]   Yeah, but you know, I don't have a problem with that. Putting the CEOs in front of Congress
[01:17:20.720 --> 01:17:26.880]   is a great way to punch them in the face. That's what happened to the tobacco companies.
[01:17:26.880 --> 01:17:32.800]   That's what's happened to the oil companies in the past. You bring the CEOs in, and then
[01:17:32.800 --> 01:17:38.000]   all the congressmen go down the line and they take turns punching each CEO in the face.
[01:17:38.000 --> 01:17:46.480]   It's kind of grandstanding, isn't it? Of course it is. But if the purpose here was to gather
[01:17:46.480 --> 01:17:57.440]   information, then arguably the counsels, the legal counsel is closer to understanding the issues
[01:17:57.440 --> 01:18:08.400]   there. However, they are trained and their job is to obfuscate the truth and to present as
[01:18:08.400 --> 01:18:12.720]   narrow a picture as possible. So what really should have been there, and it should have been
[01:18:12.720 --> 01:18:19.440]   interviews with the staff of the congressional committees was the staff who are actually working
[01:18:19.440 --> 01:18:23.840]   on these teachers. If you want to get to the bottom of something, you don't do it on TV.
[01:18:23.840 --> 01:18:28.800]   Yeah, I don't know. I think that really what it's about is accountability. And in the end,
[01:18:28.800 --> 01:18:32.160]   the people that run the companies should be accountable to what happens there.
[01:18:32.160 --> 01:18:36.400]   And I think that if there was more accountability, then they would be much more careful that they
[01:18:36.400 --> 01:18:41.040]   were doing things on the up and up. And they can't say, well, I had no clue that this happened.
[01:18:42.000 --> 01:18:46.720]   Like, well, I think it was Alfred and that asked, well, how could you not deal with so
[01:18:46.720 --> 01:18:52.400]   many data points? And how could you not tell account and they're paying in like rubles that
[01:18:52.400 --> 01:18:57.200]   that doesn't maybe mean that there's something up between this? And so I think that it would be
[01:18:57.200 --> 01:19:01.520]   a great idea to have people be accountable for the companies that they run so they can't hide
[01:19:01.520 --> 01:19:05.040]   behind and be able to say, well, you know what, actually, I didn't know.
[01:19:05.040 --> 01:19:10.880]   Well, let's take a break. When we come back, we'll talk about some of the solutions proposed.
[01:19:11.360 --> 01:19:19.840]   And what you guys think Facebook and Twitter and Google can do, it's not merely, I mean, a lot
[01:19:19.840 --> 01:19:24.720]   of it and what the Congress is interested in is Russian meddling in the 2016 election. But
[01:19:24.720 --> 01:19:33.280]   it's a it's kind of a larger issue about who is on Facebook? What is going on? If Facebook has
[01:19:33.280 --> 01:19:38.560]   that many fake accounts, it's it's interesting. Anyway, I like to know your thoughts. We're going
[01:19:38.560 --> 01:19:43.120]   to take a break, come back with more Ed bot is here. It's always great to have Ed the Ed bot
[01:19:43.120 --> 01:19:49.520]   report at zdnet at Ed bot on the Twitter. What do you write about it? The Ed bot report?
[01:19:49.520 --> 01:19:56.480]   Anything you want? It's anything I want. It has been a lot of Windows 10 lately because
[01:19:56.480 --> 01:20:02.720]   there's been a lot of activity on Windows 10. But I've written a lot about Apple and Android
[01:20:02.720 --> 01:20:07.280]   technologies in the past as well. It's the end of the line on the free Windows 10 upgrade. We'll
[01:20:07.280 --> 01:20:13.120]   talk about we'll talk about that and the new surface and Microsoft's new direction, I think,
[01:20:13.120 --> 01:20:19.600]   with surface. It's also great to have the wonderful Georgia Dow. She's a senior editor at iMore
[01:20:19.600 --> 01:20:24.480]   and works as a psychotherapist. So I always like having her come in here for a brief consultation
[01:20:24.480 --> 01:20:30.320]   about this crazy world of ours. And thanks to Renee Richie for letting you use this studio.
[01:20:30.320 --> 01:20:34.480]   It's very nice to have you. Thank you. And for the first time here, and I'm sorry,
[01:20:34.480 --> 01:20:40.880]   it had to be this show. But I'm glad you're here, Brian. Brian Tenchin, lead consumer technology
[01:20:40.880 --> 01:20:45.680]   writer for the New York Times. We'll get you back when there's better news, more news, more
[01:20:45.680 --> 01:20:49.760]   interesting. We're going to find some stuff to talk about. It's not a bad one. I love talking
[01:20:49.760 --> 01:20:59.040]   about poop. Damn it. Who doesn't? Our show today brought to you by Zebra Cruder. If you're
[01:20:59.040 --> 01:21:03.360]   looking to hire, if you've got an opening at your company, you probably already thinking,
[01:21:03.360 --> 01:21:10.160]   well, am I going to have to go to 100 job boards and post my one by one? I mean, what's going to
[01:21:10.160 --> 01:21:14.080]   happen? Then they're going to all call me and my phone's going to be tied up for weeks. No, no,
[01:21:14.080 --> 01:21:20.160]   no, no. I've got so much of a better way. Zebra Cruder. Zebra Cruder. Well, we post once to Zebra
[01:21:20.160 --> 01:21:27.120]   Cruder. They cross post to 100 plus job boards and social networks, the single click. And then
[01:21:27.120 --> 01:21:33.280]   you don't get any phone calls. You don't get any emails. But that's a good thing. You will get
[01:21:33.280 --> 01:21:39.920]   applicants, lots of them almost right away. 80% of employers who post on Zebra Cruder get a qualified
[01:21:39.920 --> 01:21:44.640]   candidate within one day. But those candidates go into the Zebra Cruder interface where you can
[01:21:44.640 --> 01:21:49.680]   scan them fast. You can even write screening questions. Yes, no, true, false, multiple choice,
[01:21:49.680 --> 01:21:55.440]   even essay questions to eliminate candidates. You're not interested in their resumes are
[01:21:55.440 --> 01:22:00.320]   pre formatted. So they all look the same. So it's very easy to scan through them. You can screen
[01:22:00.320 --> 01:22:06.400]   them, rate them and hire the right person fast. And with Zebra Cruder's smart matching technology,
[01:22:06.400 --> 01:22:11.840]   they'll actively notify qualified candidates about your job within minutes of posting.
[01:22:11.840 --> 01:22:18.400]   They'll actually go out. They'll push your post to candidates. That's why Zebra Cruder is different.
[01:22:18.400 --> 01:22:21.760]   I don't like other hiring sites. They don't depend on the right candidates finding you.
[01:22:21.760 --> 01:22:26.960]   They find them for you. You even get a head start in the interview process with the screening questions.
[01:22:27.840 --> 01:22:32.400]   You don't have to waste time going through a bunch of resumes. And you don't have to answer the phone
[01:22:32.400 --> 01:22:38.080]   or get your email box filled. It really works. It's the smartest way to hire. Right now you could
[01:22:38.080 --> 01:22:43.600]   try it for free. Businesses of all sizes, some of the best businesses in the world. More than a
[01:22:43.600 --> 01:22:47.760]   million businesses use Zebra Cruder. Go to zippercruder.com/twit. Try it out for yourself.
[01:22:47.760 --> 01:22:56.480]   We've used it. Zippercruder.com/twit. One click. And the candidates start rolling in.
[01:22:56.480 --> 01:23:08.240]   We've been talking about Facebook. Is the whole story just at Russian interference in the election,
[01:23:08.240 --> 01:23:14.240]   or is there a larger story here? A larger concern. Oh, God, there's a much, much, much larger story,
[01:23:14.240 --> 01:23:19.760]   which is about the nature of reality and the nature of truth. I mean, we can-
[01:23:19.760 --> 01:23:27.040]   The fake news story. Well, yeah, but fake news in a much broader sense than you think.
[01:23:27.040 --> 01:23:32.960]   Think about it in terms of commercial speech with all the really crappy ads that are in there.
[01:23:32.960 --> 01:23:43.520]   And people just- The way that Facebook has designed its algorithms is it rewards engagement. And
[01:23:43.520 --> 01:23:54.640]   engagement scores tend to reward people who are most willing to manipulate the facts of a situation.
[01:23:54.640 --> 01:24:02.320]   So the political messages are- The impact of those is horrible. But every time I go on Facebook,
[01:24:02.320 --> 01:24:08.000]   and I keep a lot of the filters off just so I can see how bad it is, the amount of stuff that's
[01:24:08.000 --> 01:24:17.040]   there that is just crap is truly mind-boggling. And it filters to the top because it's inflammatory
[01:24:17.040 --> 01:24:23.840]   and therefore inspires engagement. So that's the algorithm, right?
[01:24:23.840 --> 01:24:29.120]   That's the algorithm. And they don't tell you how they do it. But isn't that their business? I mean,
[01:24:29.120 --> 01:24:35.600]   isn't that what they should be optimizing for is more users, more engaged users, isn't that-
[01:24:35.600 --> 01:24:43.440]   But whoever's- No, it's not engaged users. It's whoever screams the loudest and gets the most
[01:24:43.440 --> 01:24:53.680]   attention. So I don't know about you, but if we walk into an Amtrak station somewhere and there's
[01:24:54.640 --> 01:25:00.400]   a crazy guy standing there screaming at the top of his lungs that the world is ending at 1059.
[01:25:00.400 --> 01:25:05.600]   You walk the other way in real life, right? But that's the guy who's going to get the most
[01:25:05.600 --> 01:25:15.360]   engagement. And that's actually- I mean, that's almost literally the way that it's working right
[01:25:15.360 --> 01:25:23.280]   now. The people who can craft their message, there's no incentive to have a fact-based
[01:25:23.280 --> 01:25:31.200]   message on Facebook. In fact, a fact-based message on Facebook is going to be drowned out
[01:25:31.200 --> 01:25:36.160]   by the sensational ones that make misleading claims.
[01:25:36.160 --> 01:25:43.280]   And ultimately, it sounds like that's not good for Facebook, right? I mean, at some point,
[01:25:43.280 --> 01:25:45.840]   people are just going to throw up their hands and say, "I can't use this crap."
[01:25:45.840 --> 01:25:54.960]   Well, they- I don't know. Both Twitter and Facebook have business models that are based on monthly
[01:25:54.960 --> 01:26:05.280]   active users. So, I mean, it's like television. There's a lot of really insane reality shows
[01:26:05.280 --> 01:26:11.600]   out there that involve people screaming at each other. And they- It's more- No, isn't it
[01:26:11.600 --> 01:26:16.240]   this though, though? More comment on us, the Facebook users. Isn't this what we want? This
[01:26:16.240 --> 01:26:23.200]   is what Facebook's giving us what we want. That's an easy- That's an easy way to deny
[01:26:23.200 --> 01:26:32.400]   responsibility for something that's a major that has turned out to be a major influence on the
[01:26:32.400 --> 01:26:36.560]   civic discourse. Hey, we're just giving you what you want. Do they have a higher responsibility? I mean,
[01:26:36.560 --> 01:26:40.080]   in and out doesn't feed you broccoli either. I mean, do they have a higher responsibility?
[01:26:40.080 --> 01:26:48.560]   I think that it comes down to how easy we will be swayed into our belief systems.
[01:26:48.560 --> 01:26:52.560]   I think that we really think that we're going to be above that. We're going to be able to look at
[01:26:52.560 --> 01:26:59.440]   things really reflectively and analytically. But when there's fear-based messages on either side of
[01:26:59.440 --> 01:27:04.640]   whatever we're dealing with, that really makes close-mindedness of our mind. And so,
[01:27:04.640 --> 01:27:09.600]   these messages do have an effect and sway popular opinion even in ways that we may not
[01:27:09.600 --> 01:27:13.760]   believe that we would be able to be swayed by. But you're asking Facebook to do something
[01:27:13.760 --> 01:27:19.680]   against its better business interests, aren't you? Yes. And they- And you feel like they have
[01:27:19.680 --> 01:27:25.680]   civic responsibility to do that. It's a toxic- I think that they do. It has a toxic product.
[01:27:25.680 --> 01:27:32.320]   Yeah. Yeah. Twitter same thing? Yeah. Yeah.
[01:27:33.680 --> 01:27:37.440]   Yes. Brian, you have an opinion on all this?
[01:27:37.440 --> 01:27:42.960]   Yeah. I mean, Facebook, Twitter, Facebook, especially though, it's become one of the main
[01:27:42.960 --> 01:27:48.320]   ways that people consume information, especially the news. And I think they do have a higher
[01:27:48.320 --> 01:27:54.160]   responsibility than other companies when it comes to making sure that people access accurate
[01:27:54.160 --> 01:28:00.240]   information and are hearing it from legitimate accounts. I'd like to see them personally
[01:28:01.280 --> 01:28:05.440]   do a better job at verifying that accounts are real. It sounds like they're taking some steps,
[01:28:05.440 --> 01:28:08.400]   but sounds like they're still falling short. Actually-
[01:28:08.400 --> 01:28:12.640]   It's not that there's news out there that people disagree with. It's that they're gaming the system
[01:28:12.640 --> 01:28:18.000]   in order to make things trending that are not something that is a swaying of public opinion.
[01:28:18.000 --> 01:28:22.560]   They're creating what we think is public opinion. Right. And because of that,
[01:28:22.560 --> 01:28:27.840]   that creates a wave of us wanting to be a part of it. We are innately tribalists,
[01:28:27.840 --> 01:28:33.760]   and we want to be a part of the winning tribe. And so if we see a lot of information that is
[01:28:33.760 --> 01:28:38.960]   swaying one way, and that's why there's so many fake accounts is because then they can make things
[01:28:38.960 --> 01:28:44.800]   trending that slowly our cognitive dissonance will be broken down and we will want to become
[01:28:44.800 --> 01:28:50.560]   part of that opinion. And so they're actually just manipulating the system in order to see
[01:28:50.560 --> 01:28:58.640]   something. This is Orwellian in every stage. Thursday, the Pew Center, which comes out with these great
[01:28:58.640 --> 01:29:04.880]   surveys and tells us a lot about how Americans use the internet came out with a new survey that
[01:29:04.880 --> 01:29:09.760]   said about a quarter of all U.S. adults get news from two or more social media sites,
[01:29:09.760 --> 01:29:15.840]   one quarter that's up from 15% in 2013, 18% in 2016. But get this, this is the one.
[01:29:16.640 --> 01:29:26.000]   Just under half, 45% of U.S. adults, 45% of U.S. adults use Facebook for news. Half of Facebook's
[01:29:26.000 --> 01:29:32.560]   news users get news from that social media site alone with just one in five relying on three or
[01:29:32.560 --> 01:29:38.880]   more sites for news. So not only is Facebook dominant, you know, the source of news for many
[01:29:38.880 --> 01:29:43.520]   people, it's for many people, the only source of news, that is where they get their news.
[01:29:44.320 --> 01:29:51.360]   Right. And Georgia was right on, I want to add one thing to that, which is that in addition to
[01:29:51.360 --> 01:29:58.080]   putting out a message that people may or may not believe, there's two additional effects that you
[01:29:58.080 --> 01:30:05.440]   get from the onslaught of just pure deceptive messaging going out on a variety of topics. Number
[01:30:05.440 --> 01:30:11.600]   one is it creates the uncertainty in people's minds that say, well, I keep hearing this.
[01:30:11.600 --> 01:30:16.640]   Yeah, must be true. So there must be, there must be some kernel of truth underneath it.
[01:30:16.640 --> 01:30:24.800]   So that's part of it. And the second thing is even if you can't get that reaction from people,
[01:30:24.800 --> 01:30:33.200]   the Russian trolls in particular, and you know, in certain political arms, are incentivized to just
[01:30:33.200 --> 01:30:38.800]   break people down to the point where they throw up their hands and say, I'm not going to be
[01:30:38.800 --> 01:30:43.920]   involved in this. This is just all everyone's ugly, everyone's screaming, everyone's yelling,
[01:30:43.920 --> 01:30:49.440]   I don't believe a thing. And so they just tune out and they choose not to participate in the
[01:30:49.440 --> 01:30:55.680]   civic process. They choose not to believe that there is one side that's right and one side that's
[01:30:55.680 --> 01:31:02.160]   wrong. And there's value in gathering facts and finding out what that is. Instead, there are,
[01:31:02.160 --> 01:31:10.800]   you know, the external trolls coming from the outside are just as happy to turn us, you know,
[01:31:10.800 --> 01:31:16.720]   if they can convince 2% of the voters to just not go to the polls, they've won.
[01:31:16.720 --> 01:31:23.840]   Yeah, there's an actual physical effect that happens when you hear enough negative content.
[01:31:23.840 --> 01:31:27.760]   It's that you're the part of your brain, your prefrontal cortex, the part that actually
[01:31:27.760 --> 01:31:32.720]   analyzes consequences to action starts to shut down. And when that happens, you want to just
[01:31:32.720 --> 01:31:38.000]   avoid it because it's damaging to the system. It's actually painful for us to hear too much
[01:31:38.000 --> 01:31:44.480]   negativity. And so like in the end, they would just pit people against each other. So there's
[01:31:44.480 --> 01:31:48.960]   already been analysis of the different ads that were there and they were really just trying to
[01:31:48.960 --> 01:31:54.240]   create fights so that people would be angry and not want to be a part of things. So what Ed is
[01:31:54.240 --> 01:32:00.240]   saying is completely right. And it's damaging to discourse, to being able to discuss things,
[01:32:00.240 --> 01:32:04.880]   to have differing opinions, because they're trying to polarize people. And we are very,
[01:32:04.880 --> 01:32:09.200]   it's really easy to create our own tribes of people. And you can see it with fights between
[01:32:09.200 --> 01:32:14.720]   Android and Apple and different sports teams. We are made to do that. It was very beneficial to
[01:32:14.720 --> 01:32:19.040]   us when we worked in tribal groups, because we would keep our tribe protected. But now that we
[01:32:19.040 --> 01:32:23.920]   really have no tribe, we still have that innate want to be part of a tribe. And it's easy to
[01:32:23.920 --> 01:32:31.840]   demonize the us and them. Yeah. I would submit that what really has happened here is, and there's a
[01:32:31.840 --> 01:32:40.640]   much larger pattern, a much larger game of foot, which is that one of the side effects of technology,
[01:32:40.640 --> 01:32:48.240]   big data computation, is that companies have gotten very good at optimizing for engagement.
[01:32:48.880 --> 01:32:56.320]   This is something brand new. They've just gotten incredibly good almost, literally, not almost
[01:32:56.320 --> 01:33:03.440]   too good at optimizing for engagement. That's one. And by the way, it's a capitalist society.
[01:33:03.440 --> 01:33:09.600]   If optimizing for engagement returns more dollars, they're going to do that. They're going to do that.
[01:33:09.600 --> 01:33:18.800]   Two, a long-come actors, Russia's just one of them, who see this as an opportunity. They understand
[01:33:19.040 --> 01:33:24.640]   what's going on. And they say, "Hey, this is great. We can seed confusion and dissent and ultimately
[01:33:24.640 --> 01:33:32.240]   complete apathy by just taking advantage of these things." And it's not just Facebook, but
[01:33:32.240 --> 01:33:35.520]   Facebook's, let's use Facebook as an example, by taking advantage of Facebook.
[01:33:35.520 --> 01:33:44.160]   And it seems to me almost an inevitability when you get to the point where you have a capitalist
[01:33:44.160 --> 01:33:49.040]   system and you have technology that is able to do this, that this is going to happen.
[01:33:49.040 --> 01:33:56.720]   And I don't know what the antidote is. Let's, the interesting article in The New York Times,
[01:33:56.720 --> 01:34:03.120]   "How to Fix Facebook, Farhadmaju and Kevin Russe," who I really admire, asked some smart people.
[01:34:03.120 --> 01:34:13.040]   And what do we do about this? And there aren't a lot of solutions. Kevin Kelly said,
[01:34:13.040 --> 01:34:21.200]   "Reduce anonymity, provide verification." This is a challenge because we all acknowledge that
[01:34:21.200 --> 01:34:29.040]   there's a reason for anonymity. There's a need for ability to be a whistleblower or to talk freely
[01:34:29.040 --> 01:34:35.280]   verification of your identity. And at the same time, that's become a very damaging thing.
[01:34:35.840 --> 01:34:42.560]   They asked a congressman from Silicon Valley and he says, "We need more transparency.
[01:34:42.560 --> 01:34:46.480]   Facebook needs to tell us how the algorithm works. They're never going to do that. They should
[01:34:46.480 --> 01:34:53.680]   make their executives readily available to the press in Capitol Hill. Bad actors want to take
[01:34:53.680 --> 01:34:58.480]   advantage of technology platforms, but the key is for Facebook to be upfront about the challenges,
[01:34:58.480 --> 01:35:03.120]   open about its mistakes and willing to answer the tough questions. Eli Parriser wrote the filter
[01:35:03.120 --> 01:35:08.880]   bubble. I thought this was an interesting idea, said, "Facebook should allow independent researchers
[01:35:08.880 --> 01:35:14.480]   to study," says right now Facebook's a black box. He says there's, of course,
[01:35:14.480 --> 01:35:20.320]   a challenged opening private data to research, but there are ways to do this and it would help
[01:35:20.320 --> 01:35:26.000]   it be helpful to understand what's going on. It would be a bold move for transparency and when
[01:35:26.000 --> 01:35:31.040]   that would help us understand much better what's going on. Facebook employee, I can go on and on.
[01:35:31.040 --> 01:35:38.320]   I don't want tothere's quite a few people. Tim Wu who wrote the number of really important
[01:35:38.320 --> 01:35:42.960]   books coined the term net neutrality as the attention merges. He says, "Facebook should
[01:35:42.960 --> 01:35:46.960]   become a public benefit corporation." That's what you're suggesting, Ed, is that they should
[01:35:46.960 --> 01:35:53.600]   stop being a for-profit entity and be responsible for the problem they have created.
[01:35:55.200 --> 01:36:05.840]   Oh, well, I wish that we could reduce the problem and the solution down to a 15-second soundbite
[01:36:05.840 --> 01:36:16.320]   like that. Unfortunately, the original sin happened years ago when Facebook turned from its original
[01:36:16.320 --> 01:36:25.040]   model of being a way to connect people and the groups originally colleges and universities,
[01:36:25.040 --> 01:36:33.920]   and then it became employers and communities and local cities and such. But they made a very
[01:36:33.920 --> 01:36:42.000]   conscious decision to become a news publisher and that has been tremendously lucrative for them
[01:36:42.560 --> 01:36:51.040]   monetarily. But that's where everything went off the rails. Without being able to rewind the tape
[01:36:51.040 --> 01:36:55.440]   and go back to that point and start over again, I don't think that there is an easy solution.
[01:36:55.440 --> 01:37:02.960]   Facebook just recently said, "We're going to stop publishing." This is more of a revenue
[01:37:02.960 --> 01:37:07.360]   thing than anything else. We're going to stop allowing news publications to get into the feed
[01:37:07.360 --> 01:37:19.360]   unless they pay for it. Now that we own you, it's going to cost you. Is it just Facebook? I mean,
[01:37:19.360 --> 01:37:24.160]   Twitter is doing this, but not to the same damaging degree. It's not as popular.
[01:37:24.160 --> 01:37:33.680]   And if we forced Facebook to fix itself, wouldn't somebody else come along and say,
[01:37:33.680 --> 01:37:37.040]   "Hey, well, now that Facebook's not doing it, we should do this." No, but if they put,
[01:37:37.040 --> 01:37:41.920]   I don't want to say the word "legislate," but I am. But if they put
[01:37:41.920 --> 01:37:45.760]   legislations in place where they had to be accountable for the free speech,
[01:37:45.760 --> 01:37:51.280]   you know what though? There comes a point where your free speech is actually causing
[01:37:51.280 --> 01:37:55.600]   damage to other people and that's where free speech should end. And again, I'm from Canada,
[01:37:55.600 --> 01:38:02.160]   so yes, we're kind of a democratic socialistic nation, but you shouldn't be able to push hatred.
[01:38:02.160 --> 01:38:07.200]   And these are lies. This isn't even free speech. These are bots that are putting out media
[01:38:07.200 --> 01:38:12.720]   in order to change. I understand that. And you could send some accounts. But if you tell Facebook,
[01:38:12.720 --> 01:38:18.320]   you can't do this, that is getting in the way of their rights to do it. I have another idea to it,
[01:38:18.320 --> 01:38:22.080]   which again, may completely not work. And I think that this would change one of the reasons why
[01:38:22.080 --> 01:38:27.040]   Facebook is so popular. But if you had, like, before you're going to post something like a capture
[01:38:27.040 --> 01:38:31.440]   or something that happens so that you could prove that you are not a bot, at least it would slow
[01:38:31.440 --> 01:38:36.640]   down the percentage of bots that were out there pumping out information and then, you know,
[01:38:36.640 --> 01:38:42.080]   liking it so that it becomes trending. There has to be something that is a check in place because
[01:38:42.080 --> 01:38:48.160]   people can talk about what they want. But there shouldn't be mass produced waves of differing
[01:38:48.160 --> 01:38:53.760]   opinions that are there just to incite negativity in another country so that then you can kind of
[01:38:53.760 --> 01:38:59.120]   take over the pieces. Because when we fight among ourselves, we become weaker and then that works
[01:38:59.120 --> 01:39:04.800]   out great for rival nations. And that could be anyone. Facebook is not American. It's based in
[01:39:04.800 --> 01:39:09.600]   America, but these companies are no Google, Facebook, Amazon. These aren't American companies.
[01:39:09.600 --> 01:39:15.120]   These are global companies. Fair. But again, what I'm saying is that it's not freedom of speech,
[01:39:15.120 --> 01:39:21.280]   because this is not someone's personal opinion. We're talking about a whole bunch of bots that
[01:39:21.280 --> 01:39:26.800]   one organization or many is controlling to sway opinion. But isn't there should be
[01:39:27.360 --> 01:39:33.200]   under a different set of legislation? Isn't there a great risk of unintended consequences, though,
[01:39:33.200 --> 01:39:40.320]   if there were I don't have any faith that legislation could be written that would control this without
[01:39:40.320 --> 01:39:47.440]   having serious impacts on things like the First Amendment or I mean, I don't have
[01:39:47.440 --> 01:39:50.560]   should a computer, though, have the First Amendment rights that a person does.
[01:39:52.800 --> 01:39:58.960]   Right. So there's an interesting thing, legal issue going on here.
[01:39:58.960 --> 01:40:10.080]   Facebook wants to claim that it is simply a neutral publisher that if people or what appear to be
[01:40:10.080 --> 01:40:16.000]   people on the service are putting ideas out there, they can't be held responsible for them because
[01:40:16.000 --> 01:40:24.640]   they're simply providing a platform for them to promulgate those ideas.
[01:40:24.640 --> 01:40:34.240]   The problem is that that exception came about a long time ago when there was a significant cost
[01:40:34.240 --> 01:40:40.480]   associated with promulgating ideas. You had to own a printing press. You had to have people who
[01:40:40.480 --> 01:40:46.320]   would carry your newspapers out there. So yes, you could put fake news out there, but it came at
[01:40:46.320 --> 01:40:53.040]   a fairly high cost. Facebook's marginal cost for putting a new post out is essentially zero.
[01:40:53.040 --> 01:41:00.800]   And their economic incentive for putting hundreds of thousands of posts out per minute
[01:41:00.800 --> 01:41:07.760]   is extremely high. So at some point, you have to resolve this issue. Are they
[01:41:08.480 --> 01:41:12.400]   a part of the process? Are they responsible for the messages coming out there,
[01:41:12.400 --> 01:41:16.800]   especially when they're algorithmically determining which messages you and I see?
[01:41:16.800 --> 01:41:24.160]   Or are they true if they're truly going to be a neutral publisher the way newspapers used to be,
[01:41:24.160 --> 01:41:30.640]   then they need to just like eliminate the algorithms completely. I think it's an untenable point of
[01:41:30.640 --> 01:41:39.360]   view. And to expand on Ed's comment about how they have an incentive to have as many posts as possible,
[01:41:39.360 --> 01:41:43.760]   I also think that tech companies have been too complacent about allowing bots to exist.
[01:41:43.760 --> 01:41:49.120]   I can even look at my Instagram, which used to have 2,000 followers and I don't know that many
[01:41:49.120 --> 01:41:53.760]   people. There are mostly bots. Twitter, probably a lot of bots. Facebook, lots of bots trying to
[01:41:53.760 --> 01:41:59.360]   add me all the time. And I think there's been very little done in terms of getting rid of these
[01:41:59.360 --> 01:42:03.280]   bots because it makes them look good. It makes it look like they have more users that they can
[01:42:03.280 --> 01:42:07.840]   report to their investors every quarter. So I definitely think it's something that has not been
[01:42:07.840 --> 01:42:14.240]   addressed. And we were talking about potential solutions. I think if you look at a social network
[01:42:14.240 --> 01:42:18.320]   like Nextdoor, they do this really interesting thing where they send you a postcard with the
[01:42:18.320 --> 01:42:22.400]   code to make sure they're sending a postcard to a real person with a mailing address before you
[01:42:22.400 --> 01:42:26.400]   could use the service. There's plenty of things that can be done that aren't being done yet by
[01:42:26.400 --> 01:42:31.200]   Facebook, Twitter, and different social media companies that I wish would be more pursued.
[01:42:31.200 --> 01:42:36.880]   And didn't they also clamped down on other, well, I think this one was actually Madison.
[01:42:36.880 --> 01:42:40.880]   But anyways, they had a whole bunch of bots posing as females. That's right. That's right.
[01:42:40.880 --> 01:42:46.320]   They actually had to say, listen, these are lies. And so people are joining it, which is actually
[01:42:46.320 --> 01:42:50.800]   a lie. And because of that, they were fined for it and then said that they would get rid of it.
[01:42:50.800 --> 01:42:55.600]   And then there was like three females on the entire site. But that's a different story for a different
[01:42:55.600 --> 01:42:59.840]   time. It's hard to set up dates if you only have three women and eight million men.
[01:42:59.840 --> 01:43:01.680]   But those three women did very well. They did very well.
[01:43:01.680 --> 01:43:08.480]   They did very well. So it's the same thing that Twitter and Facebook are doing is their
[01:43:08.480 --> 01:43:13.920]   proponent lies because it's padded pads their numbers, which works that well for them. But in the
[01:43:13.920 --> 01:43:19.440]   end, I don't like to think that that person that's writing to me is a lie. There's clearly a benefit
[01:43:19.440 --> 01:43:25.360]   to padding your numbers. But is it easy to detect bots and kill them? Would that be technical
[01:43:25.360 --> 01:43:29.360]   like technically? Is it something we should demand of Twitter and Facebook because it's easy? They
[01:43:29.360 --> 01:43:33.600]   could do it. They could do it. I don't think that they want to because then we noticed that,
[01:43:33.600 --> 01:43:37.680]   you know, half of mine, everyone gets upset when suddenly like I suddenly lose like, I don't know,
[01:43:37.680 --> 01:43:42.480]   500 followers on set. Well, and they like saying we have two billion monthly active users. What if
[01:43:42.480 --> 01:43:50.320]   it's only right? Right. Right. That's a big difference. Well, there was a story this weekend.
[01:43:51.280 --> 01:43:57.360]   Jeez, I wish I had I wish I had thought to provide the link for this one, but a former
[01:43:57.360 --> 01:44:02.560]   employee of Twitter. Oh, I have a charge of security. If you've got that one handy,
[01:44:02.560 --> 01:44:08.800]   kill Donald Trump's account for 11 minutes. No, not that one. Not that one. Oh, no, no, no, no,
[01:44:08.800 --> 01:44:16.560]   not that one. This was actually the senior employee at Twitter who was in charge of security and
[01:44:16.560 --> 01:44:25.520]   had some outside researchers come to him, I think, and said, look, we see a lot of activity that
[01:44:25.520 --> 01:44:31.680]   appears to be from bots here. And so they went, they went back into, you know, with full access to
[01:44:31.680 --> 01:44:39.360]   Twitter's internal data and said, Holy crap, you're right, brought this over to management at Twitter
[01:44:39.360 --> 01:44:46.560]   and to the engineering side at Twitter. And their response was, and I quote, stay in your lane.
[01:44:46.560 --> 01:44:56.240]   And that ultimately is something that I tweeted this week, which is all of the things that are
[01:44:56.240 --> 01:45:04.960]   going to fix social media are profoundly against the economic self interests of the companies of
[01:45:04.960 --> 01:45:12.560]   the companies that are running those services. So it's in their self interests to take small
[01:45:12.560 --> 01:45:21.680]   measures that appear to be doing something to apply a blizzard of Band-Aids to the problem
[01:45:22.560 --> 01:45:27.600]   without actually affecting the underlying, you know, broken compound fractures.
[01:45:27.600 --> 01:45:35.440]   The employee, Leslie Miley, discovered a vast amount of, this is from Bloomberg of Twitter accounts
[01:45:35.440 --> 01:45:41.600]   with IP addresses in Russia and Ukraine in early 2015. He said most of them were inactive or fake,
[01:45:41.600 --> 01:45:47.040]   but weren't deleted. Miley was the engineering manager of product safety and security. He said
[01:45:47.040 --> 01:45:52.320]   efforts to root out spam and manipulation on the platform were slowed down by the company's growth
[01:45:52.320 --> 01:45:56.640]   team, which focused on increasing users and revenue. This is the quote, anything we would do
[01:45:56.640 --> 01:46:01.520]   that would slow down signups, delete accounts or remove accounts had to go through the growth
[01:46:01.520 --> 01:46:06.160]   team and they were more concerned with growth numbers than fake and compromised accounts. That's
[01:46:06.160 --> 01:46:13.280]   a smoking gun. That's something Congress can say, Oh, okay. And that goes back to my point,
[01:46:13.280 --> 01:46:20.560]   which is that is the kind of person who should have been sitting in the chair in front of Congress.
[01:46:20.560 --> 01:46:26.240]   It shouldn't have been a lawyer. It shouldn't have been a CEO. It should have been an engineer
[01:46:26.240 --> 01:46:33.520]   who can speak in plain English about the things that they under oath with no ability to take the
[01:46:33.520 --> 01:46:39.680]   Fifth Amendment and say, you know, here's what's here's exactly what's happening. That person, I hope,
[01:46:39.680 --> 01:46:46.240]   is being subpoenaed to go testify before a future committee. But that's where we're actually going
[01:46:46.240 --> 01:46:53.760]   to learn things. Although I have to think that the Russian troll farms are smart enough not to use
[01:46:53.760 --> 01:46:59.760]   Russian IP addresses when creating accounts. Well, they know that and actually, if you go back and
[01:46:59.760 --> 01:47:09.600]   look at that, you'll find they use VPNs and they use various forms of obfuscation to appear to
[01:47:09.600 --> 01:47:15.600]   make themselves look legitimate. But the nature of this kind of activity is they're always going to
[01:47:15.600 --> 01:47:22.640]   make mistakes. And when they make a mistake, I saw somebody who did an analysis of the
[01:47:22.640 --> 01:47:31.600]   GUSIFER 2.0 personality on Twitter. I was reading this article today. This is the Twitter account
[01:47:31.600 --> 01:47:41.040]   that was responsible for the first dump of the DNC Podesta emails from last year. And they were
[01:47:41.040 --> 01:47:49.440]   able to go back using a variety of tools to find and they discovered that the GUSIFER 2.0
[01:47:49.440 --> 01:47:56.960]   account was originally created in Russia. And that there was a period there where it was looking
[01:47:56.960 --> 01:48:03.440]   surprisingly French, because guess what? A French election was coming up just a few months later.
[01:48:03.440 --> 01:48:16.880]   They found that this supposedly free thinking account that is working on the
[01:48:16.880 --> 01:48:23.600]   behalf of the free citizens of the world was they found pretty damning evidence that this was
[01:48:24.560 --> 01:48:30.480]   created in Russia and was designed to influence first an election in the United States and then
[01:48:30.480 --> 01:48:38.400]   an election in France. I get a little bit worried though about Pat's solutions to this. Like, oh,
[01:48:38.400 --> 01:48:42.560]   well, Twitter just could have blocked these and they just didn't because it wasn't there in their
[01:48:42.560 --> 01:48:48.320]   interest or, oh, the election went one way because Russia got in. But I worry that those,
[01:48:48.320 --> 01:48:54.480]   they feel too easy in Pat. And I don't feel like there's an underlying problem that's deeper
[01:48:55.200 --> 01:49:00.640]   than looking for Russian IP addresses or searching for mistakes from GUSIFER.
[01:49:00.640 --> 01:49:06.560]   Won't these guys just become more sophisticated and use other tools?
[01:49:06.560 --> 01:49:08.240]   Let's make them work for it.
[01:49:08.240 --> 01:49:10.320]   Exactly.
[01:49:10.320 --> 01:49:13.280]   We should make it easy, I guess. You're right.
[01:49:13.280 --> 01:49:20.480]   You know, people still rob banks. Yeah, right. But don't make it easy. Don't leave the safe open.
[01:49:21.280 --> 01:49:27.680]   Don't leave the keys in the safe. Yeah. All right. All right. I like this. I like this.
[01:49:27.680 --> 01:49:36.560]   Boy, it just feels like we're stymied, not because the solutions aren't there,
[01:49:36.560 --> 01:49:44.720]   but they're just the same problems that these fake accounts created continue to keep us from
[01:49:44.720 --> 01:49:51.040]   fixing it. I think that people also don't know how easily we are influenced. I think that that
[01:49:51.040 --> 01:49:56.640]   needs to become media savvy has to be something that is taught to our children in school of
[01:49:56.640 --> 01:50:00.960]   how do you consume media when someone's trying to influence you by their talks. I think this would
[01:50:00.960 --> 01:50:06.960]   also help people not be influenced by salesmen and get a better amount on there when they buy a car.
[01:50:06.960 --> 01:50:11.600]   Like we need to be taught these type of dealings right from when we're really young.
[01:50:11.600 --> 01:50:16.080]   How can you tell when you're trying to be persuaded and why when is someone trying to use a fear
[01:50:16.080 --> 01:50:20.240]   tactic on you and what are these different tactics that they use? I think that would help.
[01:50:20.240 --> 01:50:23.760]   I think that that would help a lot, but it has to happen at a really young age.
[01:50:23.760 --> 01:50:27.760]   And we don't. Well, you start by telling people don't get half your don't get your news from
[01:50:27.760 --> 01:50:32.960]   Facebook only. That's what people like. I know it's easy.
[01:50:32.960 --> 01:50:38.080]   Your news that of what we already feel, right? We don't like to hear news that's going to be
[01:50:38.080 --> 01:50:41.360]   from different like, you know, oh, I don't want to hear this news from here. So then
[01:50:41.360 --> 01:50:46.080]   that makes me safe. But the problem is if it's polarized noise news, I become more and more
[01:50:46.080 --> 01:50:51.600]   leaning to whichever way I already leaned. So we're already made to be to do that.
[01:50:51.600 --> 01:50:59.040]   And here's the even worse thing is that there was a lot of focus in the congressional hearings on
[01:50:59.040 --> 01:51:06.480]   advertisements, but that's the wrong place to be looking. The ads are not the problem.
[01:51:06.480 --> 01:51:14.640]   Those were almost a side show for the whole thing. A lot of that was a lot of this was engagement
[01:51:14.640 --> 01:51:23.680]   from accounts that appear to be real people activists, you know, legitimate experts in an
[01:51:23.680 --> 01:51:36.800]   area, the black, the most. The way that the process gets most toxic is when one of those
[01:51:37.360 --> 01:51:43.840]   non-paid messages gets out there and then is amplified by your friends. When your friends
[01:51:43.840 --> 01:51:50.320]   are sharing things with you, you tend to believe it more than if it's an ad sitting in the sidebar
[01:51:50.320 --> 01:51:58.240]   that's labeled as an ad. And that's the real thing. If they have 200 million fake accounts,
[01:51:58.240 --> 01:52:04.000]   all they have to do is create a handful of stars out there that can have a couple hundred thousand
[01:52:04.000 --> 01:52:10.720]   followers and start pushing a message out that then gets, you know, they tell two friends and each one
[01:52:10.720 --> 01:52:16.160]   of those two friends tells two friends and so on and so on, the way the old commercial used to go.
[01:52:16.160 --> 01:52:26.800]   You get a multiplier factor on that that is just unbelievable and frankly unbearable when the
[01:52:26.800 --> 01:52:29.840]   message that you're starting out with is toxic.
[01:52:31.840 --> 01:52:37.840]   The problem is it's so easy to manipulate human beings and we just fall right into those traps
[01:52:37.840 --> 01:52:42.960]   and these companies have just gotten better and better and better in doing it and whether
[01:52:42.960 --> 01:52:48.240]   Facebook's doing it or they're merely a conduit to others doing it, they're somewhat complicit
[01:52:48.240 --> 01:52:53.440]   together because Facebook's made it better and easier for them to do it and they want the engagement,
[01:52:53.440 --> 01:52:56.720]   they want the bots, they want so there's an economic incentive for them.
[01:52:57.680 --> 01:53:04.000]   You know what the way to heal that is so that we're not as inclined to go into tribalism or
[01:53:04.000 --> 01:53:09.280]   in this district. Turn off Facebook. You could do that, you could do that. Many people are still
[01:53:09.280 --> 01:53:13.440]   going to be influenced by media if it is not Facebook, it could be something else. But we've
[01:53:13.440 --> 01:53:18.480]   found that people if they're happy, if they're doing good things for themselves, if they're
[01:53:18.480 --> 01:53:24.240]   dealing with their anxiety, these different things will lessen our need to be susceptible. We are
[01:53:24.240 --> 01:53:30.480]   most susceptible when we are scared, when we are worried, when we are angry and so just doing
[01:53:30.480 --> 01:53:35.920]   things for yourself, taking care of yourself will make you less susceptible to polarizing news.
[01:53:35.920 --> 01:53:41.760]   In the end, that's what we want. We want everyone to come together as a nation to be able to make
[01:53:41.760 --> 01:53:45.440]   good change so that everyone lives better lives and that's by listening to each other,
[01:53:45.440 --> 01:53:50.000]   not by shutting out one group or another. It's so sad to me because really the hope
[01:53:50.640 --> 01:53:55.280]   at the beginning, and I've mentioned this before of all of this, of the internet, of Facebook,
[01:53:55.280 --> 01:54:01.520]   of Twitter, of Google, was that it would ultimately democratize speech. Everybody would get a chance
[01:54:01.520 --> 01:54:08.880]   to have a voice that people would be heard that the oligarchs would no longer control the media
[01:54:08.880 --> 01:54:16.480]   and it's just really backfired terribly. It's not worked out like anybody. You and I were at the
[01:54:16.480 --> 01:54:21.920]   beginning of the internet. We remember those days and I was very hopeful. I thought the internet's
[01:54:21.920 --> 01:54:29.600]   going to be an amazing transformation. Well, you know, let's see today's the fifth. So three days
[01:54:29.600 --> 01:54:42.480]   ago was the 29th anniversary of the first worm in the internet. The Morris worm. I think it was
[01:54:42.480 --> 01:54:51.040]   November 2nd, 1988. The first worm in the apple. And that was sort of, you know, you saw that
[01:54:51.040 --> 01:54:58.160]   happen and all these people who invented this, the internet that had these amazing capabilities to
[01:54:58.160 --> 01:55:04.000]   it. And there was one guy saying there, you know, all it takes is somebody with some bad intent to
[01:55:04.000 --> 01:55:14.080]   go in and completely hijack this like this. And then pretty soon and then about four or five years
[01:55:14.080 --> 01:55:24.320]   later, you had email, you had spam taking over what had been wonderful email. And that was over.
[01:55:24.320 --> 01:55:30.960]   And then you had advertisements that were taken over by, you know, by malware.
[01:55:32.160 --> 01:55:38.080]   And you know, so I mean, I think the lesson of the internet for as long as it has been available
[01:55:38.080 --> 01:55:42.960]   to the public has been whatever you fall in love with is going to turn to crap really quickly.
[01:55:42.960 --> 01:55:50.640]   And yet the great hope of the internet is still there because you do have access to all the world's
[01:55:50.640 --> 01:55:57.840]   information. You do, if you want to, you can find out what's going on, right? But you have to want
[01:55:57.840 --> 01:56:02.000]   to, you have to, I agree with Georgia, I agree that media literacy is important. You have to
[01:56:02.000 --> 01:56:08.080]   understand that there are facts and then there are non facts and how to distinguish the two.
[01:56:08.080 --> 01:56:13.440]   But if you wanted to, the internet still is hugely potentially hugely valuable.
[01:56:13.440 --> 01:56:21.600]   Oh, I want. Yeah. Keep it. It is. Don't throw it out. It's wonderful. But that doesn't mean that
[01:56:21.600 --> 01:56:25.920]   it's perfect. No, it's far from it. You know what's not perfect humans.
[01:56:27.520 --> 01:56:31.520]   That's the problem. That's the best of us always are our humanity.
[01:56:31.520 --> 01:56:37.840]   Let's take a break. Great conversation. Brian X Chen is here from the New York Times lead
[01:56:37.840 --> 01:56:43.280]   consumer technology writer there. We have, of course, the fabulous Georgia Dow. You can go to
[01:56:43.280 --> 01:56:48.720]   her. She's a psychotherapist as well as a senior editor at iMore.com and her anxiety videos at
[01:56:48.720 --> 01:56:54.160]   anxiety-videos.com are really useful. People want to sleep better, who want to reduce anxiety.
[01:56:54.160 --> 01:57:00.480]   You could have better relationships of a better life. I wish you would do a media literacy video,
[01:57:00.480 --> 01:57:06.160]   Georgia. We've thought about that actually about that and also, you know, when you raise your
[01:57:06.160 --> 01:57:11.680]   kids in what media should they have asked you at times and everything as well. So, yeah. Maybe we
[01:57:11.680 --> 01:57:15.360]   should. Maybe we should. Maybe we hear a twit. We should do more about this. Maybe we could do
[01:57:15.360 --> 01:57:19.280]   something about it. That would be great. Yeah. I have to think about that. Ed Botts also here,
[01:57:19.280 --> 01:57:25.200]   the Ed Botts report on ZDNet. Great to have all three of you. Our show today brought to you by,
[01:57:25.200 --> 01:57:32.400]   I wish I'd spent more time last night, but the stupid fallback thing. But I had a nice mattress
[01:57:32.400 --> 01:57:39.440]   to lie on my Casper. Casper is an online retailer, premium mattresses for a fraction of the cost.
[01:57:39.440 --> 01:57:45.280]   They were the first to really do this, to break the hold, the grip of the mattress middleman.
[01:57:45.280 --> 01:57:50.480]   These people, these mattress stores, where they mark it up 100%, they hard sell you.
[01:57:50.480 --> 01:57:57.600]   You can go direct to the source. You go to Casper, cut the cost of dealing with resellers and showrooms,
[01:57:57.600 --> 01:58:01.520]   and the savings are passed right onto you. But now there's a problem. And the Casper immediately
[01:58:01.520 --> 01:58:07.760]   pinpointed this. People think they want to lie on the mattress before they buy the mattress.
[01:58:07.760 --> 01:58:11.440]   They think they need to go to that showroom, but I think it's pretty clear you don't learn anything
[01:58:11.440 --> 01:58:15.680]   from lying on a mattress for five minutes. In broad daylight with a salesperson looking at you,
[01:58:15.680 --> 01:58:22.080]   your shoes on, you can't tell, how about this? How about this? Get the Casper mattress,
[01:58:22.080 --> 01:58:26.560]   and then decide. You have 100 nights to sleep on your Casper, and then decide.
[01:58:26.560 --> 01:58:31.680]   Casper mattresses combine multiple supportive memory phones for a sleep surface with just,
[01:58:31.680 --> 01:58:38.880]   it's kind of a paradox, but they do it just the right sink so your hard bits get comfortably
[01:58:38.880 --> 01:58:44.240]   supported, but also just the right bounce. So your back, wake in the morning, you feel great.
[01:58:44.240 --> 01:58:49.440]   And I have to say, very important. It's breathable design, sleep, school. And I know you know this
[01:58:49.440 --> 01:58:54.640]   Georgia, sleeping cool is very important to having a good nights sleep. You don't want to sleep hot,
[01:58:54.640 --> 01:59:00.480]   and Casper mattress is the best. And it provides long lasting comfort and support. You can buy it
[01:59:00.480 --> 01:59:05.600]   online, and there's absolutely no risk. Now, I just got the new Casper mattress, the Wave,
[01:59:06.160 --> 01:59:11.600]   which features a natural geometry support system, a new top layer. It's a little more expensive,
[01:59:11.600 --> 01:59:19.440]   but I have to say, I like it even more. Free shipping, free returns to the US, Canada, and the UK,
[01:59:19.440 --> 01:59:23.840]   you get your choice, the original Casper. So what I set my kids to college with,
[01:59:23.840 --> 01:59:28.640]   and you know what's great after four years they just left it there because it was affordable.
[01:59:28.640 --> 01:59:33.440]   And they said, the next kid's going to get a nice mattress. Free delivery, you have 100 days
[01:59:33.440 --> 01:59:36.560]   to return it. If you say at any point that first hundred days, or I should say,
[01:59:36.560 --> 01:59:40.880]   hundred nights, you say, I don't want it. They will come, they will get it. They will refund every
[01:59:40.880 --> 01:59:44.880]   penny. You've got nothing to lose. They come in a very compact box. You open it up,
[01:59:44.880 --> 01:59:49.920]   they suck up all the air and they suddenly they fluff out. There is no smell. I don't know how
[01:59:49.920 --> 01:59:55.360]   they do this. They do not smell. They just they just smell great fresh. I, you know,
[01:59:55.360 --> 01:59:59.200]   I've had mattresses. You had to air them out for weeks before you wanted to sleep on them,
[01:59:59.200 --> 02:00:03.040]   not the Casper. Get a Casper mattress today. And by the way, we're going to save you an
[02:00:03.040 --> 02:00:08.000]   additional $50 by going to Casper.com/twit. All you have to do is use the promo code Twit
[02:00:08.000 --> 02:00:15.280]   T-W-I-T at checkout Casper.com/twit. $50 towards your mattress purchase when you use the promo code
[02:00:15.280 --> 02:00:20.880]   to it in terms and conditions apply. Get a great night's sleep on your Casper mattress.
[02:00:20.880 --> 02:00:25.440]   Really nice. And by the way, I'm going to say it again because maybe it didn't sink in.
[02:00:25.440 --> 02:00:30.960]   Yes, the US, but they also shipped to Canada and the UK. And we have a lot of UK listeners who
[02:00:30.960 --> 02:00:34.560]   have heard us talk about this. They're saying, all right. All right.
[02:00:34.560 --> 02:00:45.600]   By the way, Mitch McConnell yesterday said that he thinks tech giants like Facebook, Google,
[02:00:45.600 --> 02:00:52.320]   and Twitter could help the United States retaliate against Russian forces. But he's skeptical
[02:00:52.320 --> 02:00:59.200]   efforts to regulate political ads. This was on the Hugh Hewitt show. So when you get the
[02:00:59.200 --> 02:01:08.800]   leader of the Senate, or see, he's a Republican leader of the Senate saying, well, yeah, but maybe
[02:01:08.800 --> 02:01:14.480]   not. Asked about the absence of Mark Zuckerberg at the testimony, he said that was not good.
[02:01:14.480 --> 02:01:19.600]   He said, the tech industry ought to be more interested in cooperating when you have a clear
[02:01:19.600 --> 02:01:23.200]   law enforcement issue, more interested in cooperating with law enforcement than they have been.
[02:01:23.840 --> 02:01:30.000]   Now, I can't disagree with this. What we ought to do with regard to the Russians is retaliate,
[02:01:30.000 --> 02:01:35.440]   seriously retaliate against the Russians. This is great. Let's have a war with Russia over Facebook.
[02:01:35.440 --> 02:01:40.960]   And these tech terms could be helpful in giving us a way to do that. I despair, frankly,
[02:01:40.960 --> 02:01:47.840]   that Congress will ever understand what the issues are and will ever make a law that makes any sense.
[02:01:47.840 --> 02:01:51.680]   In fact, I worry that anything that they do do will actually be counterproductive,
[02:01:51.680 --> 02:01:54.880]   like encouraging Facebook to wage war against Russia. What?
[02:01:54.880 --> 02:02:07.520]   Not even a slippery slope, though. I mean, that's a that's a that's a greased slide all the way to hell.
[02:02:07.520 --> 02:02:13.680]   Well, we talked a couple of weeks. Basically, basically, what you're asking is for what are
[02:02:13.680 --> 02:02:21.520]   supposed to be global technology companies, global communication networks, to be temporarily
[02:02:21.520 --> 02:02:30.720]   co-opted by the government of one country, which may or may not be run by people who have the
[02:02:30.720 --> 02:02:38.000]   interests of the global community at large. And the idea that the government,
[02:02:38.000 --> 02:02:45.440]   that the United States government should be taking over a social media company and using it to
[02:02:45.440 --> 02:02:51.280]   attack their enemies. That's what the president's Twitter account is for.
[02:02:51.280 --> 02:02:57.520]   By the way, as we mentioned, was shut down for 11 minutes, turns out it was a Twitter employee,
[02:02:57.520 --> 02:03:03.520]   he was on the way out. He was it was his last day. And he said, I wonder if I can do this.
[02:03:03.520 --> 02:03:09.360]   And he killed the account. Of course, Twitter's government and elections team immediately reinstated
[02:03:09.360 --> 02:03:17.600]   it. But it raises the bigger issue. Well, I'm just any customer service guy could turn off
[02:03:17.600 --> 02:03:23.040]   anybody except can he tweet on your behalf? Twitter said, no, no, no, they can't they can't
[02:03:23.040 --> 02:03:28.720]   tweet on the president's behalf. And then they said, and now we're going to put in controls about
[02:03:28.720 --> 02:03:36.560]   who can delete who. But boy, that was a recommendation. Yeah. Well, someone's put them up on the
[02:03:36.560 --> 02:03:42.160]   internet for a Nobel Peace Prize. Do you do? I wonder if we'll ever know who this was. And
[02:03:42.160 --> 02:03:46.880]   well, this poor person will of course get lots of hate. This poor person will also get lots of
[02:03:46.880 --> 02:03:52.240]   job offers. So it's an interesting, I'm not sure I'd want to hire somebody who would do that. But at
[02:03:52.240 --> 02:04:00.080]   the same time, I can understand the impulse. The funniest thing about Congress asking to use
[02:04:00.080 --> 02:04:04.720]   Facebook against another country is probably the first thing if you are thinking to that is not
[02:04:04.720 --> 02:04:08.320]   to say you're going to do that. Because that kind of defeats this.
[02:04:08.320 --> 02:04:14.720]   What's with some American bots? Spread some fake news. Oh, there you go. Yeah, that's what we
[02:04:14.720 --> 02:04:19.600]   should do. Yeah. Oh, they don't have a do they have elections in Russia still? I guess they do. But
[02:04:19.600 --> 02:04:27.760]   nobody counts the votes. So I don't know. Hey, T-Mobile sprint mergers off mergers on. Now the
[02:04:27.760 --> 02:04:35.600]   mergers definitely off. The last thing I saw unless it's changed again is on T-Mobile's page. No,
[02:04:35.600 --> 02:04:42.000]   we were giving up on talks. So there was an effort to get them back together again,
[02:04:42.000 --> 02:04:48.720]   but T-Mobile and Sprint will not join together. I think that's probably a good thing. I think
[02:04:48.720 --> 02:04:55.200]   more carriers is better than fewer carriers. Well, and also how does the old saying goes,
[02:04:55.200 --> 02:05:01.760]   two turkeys don't make an eagle. I like T-Mobile.
[02:05:01.760 --> 02:05:08.240]   All right. I mean, I think you're right. You know, like having more is better. Like historically,
[02:05:08.240 --> 02:05:13.280]   it's always been shown that with telecommunications companies, especially, or utilities companies,
[02:05:13.280 --> 02:05:17.520]   whenever they're having mergers, historically it's shown that there have been fewer jobs,
[02:05:17.520 --> 02:05:22.880]   prices have risen for consumers, et cetera, et cetera. So all the historical data just shows
[02:05:22.880 --> 02:05:25.280]   that this is the right thing for the industry.
[02:05:25.280 --> 02:05:35.760]   In the United States, don't we effectively have a duopoly with Verizon and AT&T? I mean,
[02:05:35.760 --> 02:05:42.880]   collectively, when you combine their two market shares, I haven't looked lately. So I'm not going
[02:05:42.880 --> 02:05:51.920]   to guess what the number is. But the last time I looked, the vast majority, Sprint was a very
[02:05:51.920 --> 02:05:58.800]   small number, and T-Mold was a small number. And when you combine a small number and a very
[02:05:58.800 --> 02:06:06.960]   small number, you usually wind up with a small number. And so the fact of having a bunch of little
[02:06:06.960 --> 02:06:14.880]   naps in the market, I'm not sure that that's really the way that you get competition
[02:06:15.680 --> 02:06:26.800]   is by reducing the share of the two companies that make up the duopoly so that the companies
[02:06:26.800 --> 02:06:33.360]   that are third and fourth and fifth and sixth out there have a legitimate shot at winning over
[02:06:33.360 --> 02:06:40.160]   customers. The T-Mobile and Sprint merger would create a company that is third after AT&T and
[02:06:40.160 --> 02:06:47.600]   Verizon. So you're absolutely right. It would even gain market share. I don't think we can even
[02:06:47.600 --> 02:06:52.480]   change it at this point because it comes down to wireless spectrum, right? The licenses for the
[02:06:52.480 --> 02:06:56.960]   spectrum. And now we're really going into the weeds here, right? But like AT&T and Verizon own
[02:06:56.960 --> 02:07:02.640]   the vast majority of spectrum, I think about 80% of spectrum in the United States. Whereas,
[02:07:02.640 --> 02:07:07.440]   if the two combine, then they would still have nothing to use to build a greater network, a bigger
[02:07:07.440 --> 02:07:12.000]   network. So there's really no point in combining the two companies.
[02:07:12.000 --> 02:07:19.040]   Of course, Masioshi Sun, who was at one time the owner of ZDNet, as I remember, or was it Zif Davis?
[02:07:19.040 --> 02:07:26.400]   He owns Zif Davis. Yeah. Yeah. It has what? A hundred billion dollars to spend on Sprint.
[02:07:26.400 --> 02:07:30.480]   He acquired a must of Sprint. So maybe Sprint, well, I don't know. Maybe they can buy some spectrum.
[02:07:30.480 --> 02:07:39.920]   I don't know. I am no expert on geopolitical issues or how Saudi Arabia is run, but weirdly,
[02:07:39.920 --> 02:07:47.840]   Awali Bin Talal, who is a billionaire and one of the early investors in Twitter and Apple,
[02:07:47.840 --> 02:07:57.600]   owns huge stakes in both, was arrested yesterday. He also is the majority stockholder in Fox News.
[02:07:57.600 --> 02:08:05.360]   Oh, really? I did not know that. Not Murdoch. Awali? Well, well, he's the largest outside the family.
[02:08:05.360 --> 02:08:12.400]   Yeah. Largest external shareholder in the company. 11 princes, four ministers,
[02:08:12.400 --> 02:08:21.200]   and tens of former ministers were detained. This is all a succession issue. I can't imagine he's
[02:08:21.200 --> 02:08:26.960]   living in a prison cell. They have accused him, though, with money laundering, bribery, and
[02:08:26.960 --> 02:08:33.360]   extorting officials. They have turned the Ritz Carlton. This is not a joke. This is not a joke.
[02:08:33.360 --> 02:08:42.640]   They have turned the Ritz Carlton into the prison for the Saudi princes, who have been arrested as
[02:08:42.640 --> 02:08:52.400]   part of this power consolidation. There's a succession coming. The king is going to be succeeded by
[02:08:52.400 --> 02:08:58.240]   his son, the Crown Prince. But there are power plays going on. I guess these,
[02:08:58.240 --> 02:09:05.040]   arresting these proactively eliminates any contention over the succession. That's my
[02:09:05.040 --> 02:09:11.520]   understanding of it. But I don't know what the outcome will be of this, but he kind of sent
[02:09:11.520 --> 02:09:15.600]   a shock through Silicon Valley. He's a big investor. Yes. In Silicon Valley.
[02:09:19.040 --> 02:09:26.560]   Sad news, the California wildfires burned some pretty important historical records, the papers
[02:09:26.560 --> 02:09:32.480]   of the founders of Silicon Valley, William Hewlett and David Packard.
[02:09:32.480 --> 02:09:44.400]   So an HP company is up in the Santa Rosa area. It was called Agilent. They were a spin-off,
[02:09:44.400 --> 02:09:50.320]   and then they became Keysight. Keysight somehow got custody of these papers, which had been stored
[02:09:50.320 --> 02:09:57.040]   in a fireproof, safe, and so forth. Instead, just put them in a shed where they burned up.
[02:09:57.040 --> 02:10:04.000]   They had been assessed at a value in 2005, $2 million. They previously kept in special
[02:10:04.000 --> 02:10:11.680]   flame retardant-lined vaults. But I guess nobody cared Keysight. So,
[02:10:12.240 --> 02:10:17.120]   you just put them in that shed over there. So, and of course, this is from an era when
[02:10:17.120 --> 02:10:22.640]   stuff wasn't kept electronically. So these are the only copies of those papers kind of sad.
[02:10:22.640 --> 02:10:27.440]   We had a taste test of the Android burger, and I don't remember who won.
[02:10:27.440 --> 02:10:35.040]   Who won? Apparently, Google actually serves its hamburgers with the cheese on the bottom.
[02:10:36.720 --> 02:10:42.320]   And that's why the Google emoji is strangely drawn. Remember earlier this week,
[02:10:42.320 --> 02:10:48.800]   Sundar Pachai tweeted, "We're going to drop everything we're doing, and on Monday,
[02:10:48.800 --> 02:10:56.080]   address this significant burger emoji issue." No word if they actually did. But then others
[02:10:56.080 --> 02:11:01.760]   pointed out, "Hey, forget the fact that you got the cheese on the bottom. That's nothing compared
[02:11:01.760 --> 02:11:08.080]   to the beer stein emoji. The beer is apparently floating in Google's beer stein. Actually,
[02:11:08.080 --> 02:11:12.720]   the head is floating. The beer doesn't go all the way up to the top. It's just wrong all around.
[02:11:12.720 --> 02:11:19.120]   I don't know who's doing Google's emojis, but obviously they've had too much beer in cheeseburgers.
[02:11:19.120 --> 02:11:23.680]   And they've never eaten a cheeseburger. You can't put the cheese on the bottom.
[02:11:23.680 --> 02:11:27.440]   The cheese has to melt. It has to be on the patty.
[02:11:27.440 --> 02:11:31.200]   That's what we discovered yesterday. It was impossible to get the cheese to melt,
[02:11:31.200 --> 02:11:35.760]   because it was on the bottom by the bun. It doesn't work. It doesn't work. The bun is cold.
[02:11:35.760 --> 02:11:42.640]   So there you have it. I don't know. There's much more to say that.
[02:11:42.640 --> 02:11:45.920]   As long as we're in emoji, I'm moving into a cave. Apple wins the burger.
[02:11:45.920 --> 02:11:49.360]   Apple wins the burger. Yeah. That's why I bought an iPhone X.
[02:11:49.360 --> 02:11:53.680]   $1000. Yeah. That was a $1000.
[02:11:53.680 --> 02:11:58.960]   Have to have the right emoji. And apparently there's a battle raging in Unicode. Now we've had
[02:11:58.960 --> 02:12:03.600]   the Unicode guys on the subcommittee members, the emoji subcommittee.
[02:12:03.600 --> 02:12:06.560]   Jeremy comes by once in a while to talk about the new emojis.
[02:12:06.560 --> 02:12:12.240]   There is a big battle over the poop emoji. The poop emoji is a happy one.
[02:12:12.240 --> 02:12:17.760]   It's smiling. They feel some feel anyway. There should be a frowning poop emoji.
[02:12:17.760 --> 02:12:22.640]   Others say enough with the poo. We don't need a frowning emoji.
[02:12:24.880 --> 02:12:31.360]   This is a vicious, as is always the case with things that make absolutely no difference.
[02:12:31.360 --> 02:12:35.600]   This is a vicious battle. This is a slippery slope, though, Leo.
[02:12:35.600 --> 02:12:43.200]   He's not going to get the sad one, frowning one. They're going to say we want colored emojis.
[02:12:43.200 --> 02:12:50.080]   Where's the white poop emoji? I ask you. And resting poop face.
[02:12:50.080 --> 02:12:56.400]   Resting poop face. God. This is how we should fix fake news on Facebook.
[02:12:56.400 --> 02:13:03.200]   We'll have people rate with emojis. How accurate and inaccurate things are with the sad emoji versus
[02:13:03.200 --> 02:13:07.920]   happy face poop emoji. Problem solved. I thought this was kind of interesting.
[02:13:07.920 --> 02:13:15.440]   There is motherboard published in an article, the vice site, which is a very good site.
[02:13:15.440 --> 02:13:21.920]   I have to credit the author of the article, Christopher Malmo, with doing some mathematics,
[02:13:21.920 --> 02:13:27.680]   came up with a kind of not exactly an accurate headline. One Bitcoin transaction
[02:13:27.680 --> 02:13:35.760]   now uses as much energy as your house in a week. But what he did was he divided the total
[02:13:35.760 --> 02:13:44.480]   amount of energy Bitcoin miners estimate or estimated to use. About 24 terawatts of
[02:13:44.480 --> 02:13:53.600]   electricity a year by the 300,000 Bitcoin transactions a day and came up with 215 kilowatt hours
[02:13:53.600 --> 02:13:58.000]   used for each Bitcoin transaction. But of course, the transactions don't use it.
[02:13:58.000 --> 02:14:04.560]   But the miners do. And it is kind of remarkable that Bitcoin mining, now, of course, it's not
[02:14:04.560 --> 02:14:10.800]   economical if the power costs anything or much. So a lot of Bitcoin miners are next to hydroelectric
[02:14:10.800 --> 02:14:16.160]   dams in China, for instance, where power is either free or cheap. Nevertheless, 24 terawatts of
[02:14:16.160 --> 02:14:22.400]   hours of electricity a year to basically do meaningless math computations to generate more Bitcoin.
[02:14:22.400 --> 02:14:30.080]   I don't know. Maybe Satoshi Nakamoto wanted to create a climate crisis. I know it's odd.
[02:14:30.080 --> 02:14:33.520]   Seems worth it for $7,000 of coin.
[02:14:33.520 --> 02:14:35.920]   That's what the miners say.
[02:14:35.920 --> 02:14:39.120]   That's electricity bill a week. 20 bucks.
[02:14:39.120 --> 02:14:44.160]   There's a there's a Mongolia. There's a coal powered Bitcoin mine.
[02:14:44.160 --> 02:14:56.880]   Coal powered. So the estimate is that that single mine is responsible for 8 to 13,000 kilograms of
[02:14:56.880 --> 02:15:04.160]   CO2 emissions for every Bitcoin at mines is Bitcoin an environmental nightmare.
[02:15:04.160 --> 02:15:10.400]   Who cares? Nobody cares. Not your people care.
[02:15:10.400 --> 02:15:15.440]   I didn't know if that was rhetorical or you were actually asking. No, it's rhetorical.
[02:15:15.440 --> 02:15:21.120]   It's rhetorical. Here's some good news. Equifax convened a special committee.
[02:15:21.120 --> 02:15:27.040]   Remember, of course, Equifax had a data breach. What was it? 142 million records exfiltrated by
[02:15:27.040 --> 02:15:33.840]   hackers? All of us probably. And weirdly, three days after the data breach was discovered,
[02:15:33.840 --> 02:15:40.640]   Equifax executives sold their stock. But hey, here's the good news. The special committee's been
[02:15:40.640 --> 02:15:46.000]   convened. And they said, no, that wasn't insider trading. So it's good. Yeah, I'm really
[02:15:46.960 --> 02:15:53.360]   old enough for senior executives. So yes, yes, just days after workers discovered the Equifax
[02:15:53.360 --> 02:15:58.960]   breach. There was an insider trading. It was just coincidence. One point eight million dollars of
[02:15:58.960 --> 02:16:06.960]   stock was it was just coincidence. The committee interviewed dozens of people and says it right here
[02:16:06.960 --> 02:16:11.840]   reviewed 55,000 emails, text messages and phone logs.
[02:16:13.920 --> 02:16:19.200]   There was an appropriate trade that's reassuring says Equifax is non-executive chairman Mark
[02:16:19.200 --> 02:16:23.440]   Feidling. Seriously, Equifax felt 0.8% in pre market trading.
[02:16:23.440 --> 02:16:32.720]   As the saying goes, he would say that. Yes, he would. I love it. Well, we had a committee.
[02:16:32.720 --> 02:16:40.320]   It was a red ribbon committee. Blue ribbon, blue ribbon committee. Let's take a break. We'll
[02:16:40.320 --> 02:16:44.720]   say goodbyes. Final words in just a bit are showed brought to you by Stamps.com. If you do any mailing,
[02:16:44.720 --> 02:16:49.840]   if you do any mailing at all, you've got to stop going to the post office and do what the pros do.
[02:16:49.840 --> 02:16:54.000]   You Stamps.com. So you can do everything you would do at the post office at Stamps.com. Of course,
[02:16:54.000 --> 02:16:58.800]   it starts with buying and printing. This is kind of magical. You feel like, I don't know,
[02:16:58.800 --> 02:17:03.840]   you feel like John Dillinger. You can buy him print US postage with your computer and your printer.
[02:17:03.840 --> 02:17:07.920]   It comes out of the printer. It's like legal postage. Of course, you pay for it. Not free,
[02:17:08.480 --> 02:17:14.080]   but that's cool. But it goes farther than that. It will print labels for packages. It'll print on
[02:17:14.080 --> 02:17:19.680]   envelopes. It's really professional looking. If you do mailing of any kind, do the professional
[02:17:19.680 --> 02:17:23.920]   thing. Don't be licking stamps and putting them on the brown paper and the twine and all that.
[02:17:23.920 --> 02:17:29.200]   Use Stamps.com. It's easy. You can create your stamps account in minutes. There's no equipment.
[02:17:29.200 --> 02:17:33.280]   It's not postage made. There's nothing to lease, no long-term commitments. They will send you,
[02:17:33.280 --> 02:17:36.560]   though, some really cool stuff, including a digital scale that will calculate the exact
[02:17:36.560 --> 02:17:41.680]   postage, no more guessing. Stamps.com helps you decide the best class of mail every time. It'll
[02:17:41.680 --> 02:17:46.160]   even suggest less expensive classes. You can get discounts you can't even get at the post office
[02:17:46.160 --> 02:17:51.120]   on Express Mail, things like that. Fills out the forms, too. If you've got customs forms,
[02:17:51.120 --> 02:17:55.760]   if you're mailing internationally, it fills them out for you. It takes the addresses from your
[02:17:55.760 --> 02:18:00.400]   address book. If you do mailing of any kind, but especially if you're at Amazon or Etsy or eBay
[02:18:00.400 --> 02:18:05.280]   seller, this is the way to do it. Stamps.com. Now, here's the offer we're going to get you.
[02:18:05.280 --> 02:18:09.680]   See right on there, $5 of free postage. Forget that. Don't go. That's the front page.
[02:18:09.680 --> 02:18:13.440]   That's for people who don't listen to the show. Click the microphone in the upper right-hand corner.
[02:18:13.440 --> 02:18:20.000]   This is kind of magic, too. And enter "Twit" as the promo code. Did we say $5 in free postage? No,
[02:18:20.000 --> 02:18:27.360]   no, no. Try this. $55 in free postage plus the scale plus a trial of Stamps.com. It's $110 value.
[02:18:28.000 --> 02:18:35.440]   Free postage, kids. Just in time for your holiday card. Stamps.com. Click the microphone in the
[02:18:35.440 --> 02:18:39.760]   upper right-hand corner. Get that four-week trial plus the postage plus the digital scale.
[02:18:39.760 --> 02:18:44.640]   No long-term commitment. Avoid the craziness. And the holidays are coming. That means the
[02:18:44.640 --> 02:18:50.560]   post office is going to be a zoo. Amateur hour. If you're a pro-mailer, you got to use Stamps.com.
[02:18:50.560 --> 02:18:59.120]   Don't forget the offer code. "Twit." Did anybody excited about the razor phone?
[02:18:59.120 --> 02:19:07.520]   I think I missed the news about the razor phone. What? You're a lead consumer technology writer.
[02:19:07.520 --> 02:19:12.960]   Well, maybe you weren't the only one. Razor had an announcement at... They streamed it live on
[02:19:12.960 --> 02:19:18.160]   Twitch on November 1st. They announced a new phone. Possibly the... I don't want to say ugly,
[02:19:18.160 --> 02:19:26.640]   but the plainest phone ever. But at good price, it's an 835 Snapdragon 835 with a 5.7-inch LCD
[02:19:26.640 --> 02:19:32.320]   display. 120 Hertz refresh rate. So this is kind of... Razor's a gaming company. This is kind of
[02:19:32.320 --> 02:19:38.560]   gaming focused. 8 gigs of RAM. I don't know of any phone with more RAM. 64 gigs of storage plus
[02:19:38.560 --> 02:19:44.240]   the ability to support an SD card. Front-facing speakers on the left and the right with Dolby Atmos.
[02:19:44.800 --> 02:19:53.440]   Android NuGet THX certification. And it's only $699, available in the US November 17th.
[02:19:53.440 --> 02:19:58.800]   But it's... I noticed a number of reviewers said, "Damn, that's ugly." It's basically just a...
[02:19:58.800 --> 02:20:06.800]   It's just a square box. You know, there's nothing to it. Pretty impressive. Great for gaming.
[02:20:06.800 --> 02:20:09.600]   I guess they would put down no one will steal it.
[02:20:10.960 --> 02:20:15.680]   You know, it's utilitarian. And this comes... They bought, of course, next bit the company that did
[02:20:15.680 --> 02:20:20.560]   the Robin phone, which actually, if you made this baby blue, it would look just like with the front
[02:20:20.560 --> 02:20:25.040]  -facing speakers and all. So I think they just incorporated features of the Robin phone. The
[02:20:25.040 --> 02:20:32.240]   Robin team is very good. A lot of them came from Android. Also, I like that you said only $700.
[02:20:32.240 --> 02:20:35.840]   Yeah, what a deal. That's not a 10. It's done to us. Oh, God. It's cheap.
[02:20:38.080 --> 02:20:43.440]   Well, even the Note 8 is $930. I mean, that's... Although you could...
[02:20:43.440 --> 02:20:50.480]   But you have... So you have a variety of lesser tier companies.
[02:20:50.480 --> 02:20:54.480]   Essentials. Phone is five. So essential. Yeah, it was a great phone.
[02:20:54.480 --> 02:21:01.520]   Yeah. They built apparently a really nice phone and it's tanking.
[02:21:01.520 --> 02:21:03.040]   Yeah, it's pretty bad.
[02:21:04.560 --> 02:21:08.640]   They might get a second life because of the new pricing. They might get a second life.
[02:21:08.640 --> 02:21:16.880]   You know, usually price cuts are what you do right before you get sold to somebody else.
[02:21:16.880 --> 02:21:22.240]   No. This is Andy Ruben's company. They got created Android and they've had lots of
[02:21:22.240 --> 02:21:27.200]   stumbles. They're even being sued by a company who said you stole our technology for the essential
[02:21:27.200 --> 02:21:32.800]   phone. But I read it. I haven't... Did you play with it? I haven't played it. No, I was out sick
[02:21:32.800 --> 02:21:39.200]   when they were giving out the review units. But I had stuff to do when I was learning.
[02:21:39.200 --> 02:21:43.840]   I can get you when I heard it. They're cheap. I heard that the camera wasn't good, right?
[02:21:43.840 --> 02:21:48.080]   Well, that's an interesting story because most people reviewed pre-production units
[02:21:48.080 --> 02:21:54.000]   and the camera crashed. And I got my... I bought an essential phone as I do with all the stuff.
[02:21:54.000 --> 02:21:57.760]   And it crashed the first time I launched the camera, the whole phone crashed.
[02:21:57.760 --> 02:22:02.480]   But within a week, they started pushing out updates. I think they pushed three or four updates.
[02:22:02.480 --> 02:22:05.840]   And now it's fine. It works great, but it's too late.
[02:22:05.840 --> 02:22:11.840]   Yeah. Right? Too late. Everybody says the camera crashes. So that's the problem with
[02:22:11.840 --> 02:22:17.200]   pre-production units. They fixed it. Yeah. Well, it is, obviously. And it's not a great camera.
[02:22:17.200 --> 02:22:20.960]   I'll admit. It's not as good as the... Have you played with the Pixel 2 XL?
[02:22:20.960 --> 02:22:27.680]   I was on vacation during the night. Ryan, do you ever work? Do you ever work? No.
[02:22:27.680 --> 02:22:31.440]   You just wait for the iPhone to come out. That's when you come in. I understand. I don't play
[02:22:32.320 --> 02:22:35.520]   Hey, I do have the Samsung phone, so... I'm teasing you. I'm teasing you.
[02:22:35.520 --> 02:22:41.280]   Microsoft says if you want to take advantage, I didn't even know you could still get it for free.
[02:22:41.280 --> 02:22:46.560]   Ed, what's the story here? So, yeah. So it's an interesting thing that's going on here.
[02:22:46.560 --> 02:22:52.960]   You know, of course, Microsoft released Windows 10 in July of 2015. And they said,
[02:22:52.960 --> 02:22:58.720]   "Free upgrades for everybody." Oh, I'm sorry. Auto play. I hate you. Okay. God.
[02:23:00.560 --> 02:23:02.400]   Thank God. The New York Times isn't doing that.
[02:23:02.400 --> 02:23:06.960]   Was that my... Is that the internet? That's the internet. Yeah.
[02:23:06.960 --> 02:23:16.240]   I hope my management is watching. But the... Yeah. So one year after the original launch,
[02:23:16.240 --> 02:23:24.880]   they said, "Okay, the free upgrade offer is over." But if you read the disclaimers on that,
[02:23:24.880 --> 02:23:32.320]   it said, "The free upgrade offer through the Get Windows 10 app is now ended." But as it turns out
[02:23:32.320 --> 02:23:37.760]   today, if you have a PC that's running Windows 7 or Windows 8.1, you can just go out and download
[02:23:37.760 --> 02:23:41.920]   the Windows 10 code, install it, and boom, you get your free upgrade. Does it authenticate?
[02:23:41.920 --> 02:23:47.440]   Yes. Yes. They never took off the free upgrades. I've been writing about this. One of my most
[02:23:47.440 --> 02:23:53.120]   popular posts has been for a year. You can still get the upgrade. And the part of the
[02:23:53.120 --> 02:23:59.360]   justification for that was that anyone who uses any kind of assistive technology,
[02:23:59.360 --> 02:24:08.080]   which could be as simple as the screen magnifier in Windows 10, is entitled to a free upgrade.
[02:24:08.080 --> 02:24:17.040]   There's no test. There's no qualifier. Do you have to assert that you use assistive technologies?
[02:24:17.040 --> 02:24:19.840]   You don't even have to say it. You just do it.
[02:24:20.640 --> 02:24:29.040]   You just download it and do it. But that offer is officially, and that fig leaf for corporate buyers
[02:24:29.040 --> 02:24:36.960]   is officially ending as of December 31st of this year. So after that time, the question becomes,
[02:24:36.960 --> 02:24:46.800]   will Microsoft turn off the code on the activation servers that allows older PCs to upgrade for
[02:24:46.800 --> 02:24:52.640]   free? Or will it just be just like before they'll still leave it running in the background?
[02:24:52.640 --> 02:24:57.680]   But this time, there's no justification for it.
[02:24:57.680 --> 02:25:06.560]   Wow. I had no idea. I got to read the Ed Vott report more often. I had no idea. That's awesome.
[02:25:06.560 --> 02:25:12.400]   Yeah. And frankly, if you're using Windows, you're still using Windows 8,
[02:25:12.400 --> 02:25:17.120]   you should probably upgrade. That was horrible. That was a nightmare. 10 is great. I don't mind
[02:25:17.120 --> 02:25:22.480]   10 at all. I like 10 a lot. I'm using it right now with my magic Surface Studio.
[02:25:22.480 --> 02:25:30.400]   Thanks. Thanks, huge. But it's beautiful. Beautiful. It's a beauty. It's a beauty.
[02:25:30.400 --> 02:25:37.440]   Anything else? I think we can wrap it up. You guys have been it's been a long, hard slog
[02:25:38.960 --> 02:25:44.320]   through tech news heaven. I think we picked it up through the middle. You did. You saved it. I
[02:25:44.320 --> 02:25:48.880]   thank you. All of you guys are amazing. We're really working it. You were working it when we got
[02:25:48.880 --> 02:25:53.440]   to the Facebook thing. I was putting that off. I thought, Oh, that won't be and I was wrong. You
[02:25:53.440 --> 02:26:00.720]   guys, you were good. You are good. You're the best. Georgia Dow, find her at imore.com. Of course,
[02:26:00.720 --> 02:26:05.600]   we get her on as often as we can. She's at the Twitter at Georgia underscore Dow and her
[02:26:06.960 --> 02:26:16.480]   her day job as a psychotherapist is her. She's available to you through her website anxiety-videos.com
[02:26:16.480 --> 02:26:22.240]   where you can buy and actually you have downloads. You don't have to get a DVD, right? You don't have
[02:26:22.240 --> 02:26:30.240]   to get a full set. I have the full set. I'm happy to say but anxiety, panic, anything you want help
[02:26:30.240 --> 02:26:38.720]   with boundaries and consequences. Is that for grown-ups or children? Both, but mostly for adults.
[02:26:38.720 --> 02:26:42.560]   Like it's just really about boundaries and consequences. Maybe we should send this to Harvey
[02:26:42.560 --> 02:26:49.120]   Weinstein and Kevin Space and people like that. Is that who it's for? You know, you have to want
[02:26:49.120 --> 02:26:55.600]   to have healthy boundaries and consequences. So this may not help them. By the way, I'm going
[02:26:55.600 --> 02:27:02.240]   home and watching it tonight. No, not because of that. I didn't know. I need it. I admit it.
[02:27:02.240 --> 02:27:10.320]   You're too nice to people. It is good to set up. My favorite and one of the reasons to get the
[02:27:10.320 --> 02:27:16.880]   DVD, my favorite cover is get the sleep you've always dreamt of with a very restful baby on the
[02:27:16.880 --> 02:27:23.280]   front of that one. That baby's out. Is that stock photo or is that somebody you know? No, that we
[02:27:23.280 --> 02:27:27.760]   found that photo and actually it was sound with it. Found that photo and it's my favorite photo.
[02:27:27.760 --> 02:27:31.760]   Oh my gosh. That's really, that's showing what sleep really should be like. It should look just
[02:27:31.760 --> 02:27:39.600]   like that. If babies could snore, that one would be snoring. That is nice. It's great to have you.
[02:27:39.600 --> 02:27:44.080]   Nice to see you, Georgia. Good luck with the move. Good luck living in your mom's basement.
[02:27:44.080 --> 02:27:48.800]   That'll be interesting. No, we're internet. Oh, I was going to say you should start a blog,
[02:27:48.800 --> 02:27:52.080]   but I guess with no internet, I guess. Well, I have my phone. I'll still have my phone. I just...
[02:27:52.080 --> 02:28:03.840]   You can walk from your phone. Day 17. Brian X Chen, your first time here. I hope it won't be your last.
[02:28:03.840 --> 02:28:11.360]   We really always love your stuff at BX Chen on the Twitter. Lead consumer technology,
[02:28:11.360 --> 02:28:15.600]   ready for the New York Times. Please come back anytime. It's really great to have you.
[02:28:15.600 --> 02:28:17.280]   Oh, happy to. Yeah, it's been a pleasure.
[02:28:17.280 --> 02:28:21.360]   Really, really fun. Wanted to get you on for ages, so I'm glad we finally did.
[02:28:21.360 --> 02:28:28.080]   And of course, Ed Bot is always welcome. He's the guy who knows all. Even tells all the Ed Bot
[02:28:28.080 --> 02:28:33.360]   reported CD net and Ed Bot on Twitter. Thank you, Ed, for being here. I really appreciate it.
[02:28:33.360 --> 02:28:38.480]   You're welcome. I'll see you on Facebook. No, you won't. I actually... I'm very proud to say,
[02:28:38.480 --> 02:28:42.800]   and it wasn't about any of this stuff we talked about, but I just realized I woke up one night
[02:28:42.800 --> 02:28:47.840]   and was on my phone. Georgia, you'd appreciate this, looking at Facebook. And I immediately deleted
[02:28:47.840 --> 02:28:51.760]   Facebook, Instagram, and Twitter from my phones. Good for you. I said, that's not healthy.
[02:28:51.760 --> 02:28:55.120]   Well, I put Twitter, Instagram back, but Facebook's still gone.
[02:28:55.120 --> 02:29:01.760]   Okay, I'm taking back the gold star. You only get half. I can't live Twitter. Well, if you don't
[02:29:01.760 --> 02:29:06.640]   have Twitter on your phone and there's an earthquake, you don't know what to do. You have... If some...
[02:29:06.640 --> 02:29:13.040]   Twitter's where you get news now, right? Or is that a bad idea? It's breaking news. Well, it depends
[02:29:13.040 --> 02:29:17.600]   on how much you use it and how you feel when you use it. I still have on Twitter. It's just
[02:29:17.600 --> 02:29:23.600]   very rarely, and I don't usually listen to the news feed. I have to say, I do not miss Facebook
[02:29:23.600 --> 02:29:29.520]   at all. And I would kill my account, except I need to talk about it, report on it, so I have a...
[02:29:29.520 --> 02:29:33.280]   I can use it on my computer, but I don't have no urge to go there anymore. It's easy to break
[02:29:33.280 --> 02:29:37.680]   that habit. Everybody should do that. You see, for some, I think that for other people, it's a
[02:29:37.680 --> 02:29:42.880]   really hard habit to break. It's made to be as addictive as possible. I don't have any friends
[02:29:42.880 --> 02:29:49.840]   or family, so... Then it makes it easy. Temptation. Not at all.
[02:29:49.840 --> 02:29:57.200]   No, the real truth is not my friend. I never see their posts. You know, it's all... As you said,
[02:29:57.200 --> 02:30:01.840]   it's all the "ginning up engagement" stuff. That makes me feel bad. I don't want to see that.
[02:30:01.840 --> 02:30:08.960]   I'll add you on Facebook. We'll have a friend. Okay, we'll be friends. Okay, now I can go back.
[02:30:08.960 --> 02:30:14.560]   Thank you, everybody, for being here. We do this show every Sunday afternoon. Now, in California,
[02:30:14.560 --> 02:30:21.040]   we've, in fact, the U.S. for the most part, except for a few rogue states. We've gone back to daylight.
[02:30:21.040 --> 02:30:24.640]   We've eliminated daylight saving time, and we've gone back to standard time, which has been...
[02:30:24.640 --> 02:30:33.440]   is always a bad idea. But we do it. We have to do it. And so, we are still 3PM Pacific standard
[02:30:33.440 --> 02:30:40.320]   time, 6PM Eastern standard time. But that means it's 2300 UTC instead of 2200. So 2300 UTC,
[02:30:40.320 --> 02:30:44.400]   you do the math, figure out what time we're on. You can watch us live twitter.tv/live.
[02:30:44.400 --> 02:30:50.240]   If you do that, please join us in the chatroom, irc.twit.tv. It's fun to be like the kids in the
[02:30:50.240 --> 02:30:56.000]   back of the class. And I really value the chatroom's contributions. You can also be in studio.
[02:30:56.000 --> 02:31:01.520]   We have some nice studio visitors from Woodbridge, Virginia, and Regina. Regina, Regina.
[02:31:01.760 --> 02:31:03.200]   [pause]
[02:31:03.200 --> 02:31:09.840]   Georgia, how do you say that? Regina. That's what I thought. Regina Saskatchewan. I know how to say
[02:31:09.840 --> 02:31:16.640]   that. Canada. Nice to have you both. Actually, he lives here now, right? Used to... No, I'm confused.
[02:31:16.640 --> 02:31:20.080]   Never mind. He doesn't live here. And he doesn't want anybody to think he lives here.
[02:31:20.080 --> 02:31:28.000]   He's from Canada. That's what I, by the way, when I travel, that's what I tell people. I'm Canadian.
[02:31:29.200 --> 02:31:36.400]   It's almost midnight, Leo. Thanks for trying to see you next time. Another Twitch is in the game.
[02:31:36.400 --> 02:31:37.200]   Goodnight, Leo.
[02:31:37.200 --> 02:31:46.480]   [pause]

