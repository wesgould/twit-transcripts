
[00:00:00.000 --> 00:00:02.160]   It's time for Mac Break Weekly, man.
[00:00:02.160 --> 00:00:05.160]   We have a great panel for you, Lori Gill, from I'm
[00:00:05.160 --> 00:00:08.720]   or stopping by Andy and Aco, from the celestial waste
[00:00:08.720 --> 00:00:10.600]   of bandwidth and from the loop.
[00:00:10.600 --> 00:00:14.240]   Jim Dennell-Rimple, we're going to talk about Apple's reveal,
[00:00:14.240 --> 00:00:16.960]   what to expect, to the Mac Pro in 2019,
[00:00:16.960 --> 00:00:19.800]   and whether those new chips, Apple's reportedly designing,
[00:00:19.800 --> 00:00:21.400]   will be in it.
[00:00:21.400 --> 00:00:22.360]   You stay tuned.
[00:00:22.360 --> 00:00:24.960]   Mac Break Weekly is next with the Red iPhone.
[00:00:28.400 --> 00:00:30.480]   And that casts you love.
[00:00:30.480 --> 00:00:31.840]   From people you trust.
[00:00:31.840 --> 00:00:37.960]   This is Twit.
[00:00:37.960 --> 00:00:45.360]   Bandwidth for Mac Break Weekly is provided by cashfly at CACHEFLY.com.
[00:00:45.360 --> 00:00:52.840]   This is Mac Break Weekly, episode 605,
[00:00:52.840 --> 00:00:56.160]   recorded Tuesday, April 10, 2018.
[00:00:56.160 --> 00:00:59.840]   Super-sexy swinging sounds.
[00:00:59.840 --> 00:01:02.840]   Mac Break Weekly is brought to you by Rocket Mortgage
[00:01:02.840 --> 00:01:04.200]   from Quick and Loans.
[00:01:04.200 --> 00:01:05.720]   Home plays a big role in your life.
[00:01:05.720 --> 00:01:08.280]   That's why Quick and Loans created Rocket Mortgage.
[00:01:08.280 --> 00:01:10.920]   It lets you apply simply and understand the entire mortgage
[00:01:10.920 --> 00:01:13.360]   process fully so you can be confident you're
[00:01:13.360 --> 00:01:15.280]   getting the right mortgage for you.
[00:01:15.280 --> 00:01:19.440]   Get started at rocketmortgage.com/macbreak.
[00:01:19.440 --> 00:01:23.800]   And by 23andMe, a personal genetic service helping people
[00:01:23.800 --> 00:01:25.960]   understand their DNA.
[00:01:25.960 --> 00:01:31.440]   Buy your 23andMe kit today at 23andMe.com/Twit.
[00:01:31.440 --> 00:01:34.880]   And by TurboTax Live, new from TurboTax.
[00:01:34.880 --> 00:01:37.200]   Now you can get a personal review of your tax return
[00:01:37.200 --> 00:01:39.920]   with a CPA or EA right on your screen.
[00:01:39.920 --> 00:01:43.520]   Talk live with a tax expert as often as you need for tax advice
[00:01:43.520 --> 00:01:45.240]   to help you file with confidence.
[00:01:45.240 --> 00:01:49.840]   Go to TurboTaxLive.com/macbreak.
[00:01:49.840 --> 00:01:51.880]   It's time for Mac Break Weekly, the show we get together
[00:01:51.880 --> 00:01:54.080]   with the best Mac journalists in the world
[00:01:54.080 --> 00:01:56.680]   to talk about the latest news from Apple.
[00:01:56.680 --> 00:01:58.400]   And I want to welcome the beard.
[00:01:58.400 --> 00:02:00.880]   He's here, ladies and gentlemen, Jim Dalrymple
[00:02:00.880 --> 00:02:02.760]   from loopinsight.com.
[00:02:02.760 --> 00:02:03.840]   Hi, Jim.
[00:02:03.840 --> 00:02:04.880]   How you doing, Leo?
[00:02:04.880 --> 00:02:06.920]   I am wonderful.
[00:02:06.920 --> 00:02:10.320]   Summer treating you well, is it summer yet?
[00:02:10.320 --> 00:02:13.080]   It is summer, I've been in California too.
[00:02:13.080 --> 00:02:14.200]   Yeah, it's beautiful.
[00:02:14.200 --> 00:02:16.280]   With the weather, it's 75 today.
[00:02:16.280 --> 00:02:19.320]   The leaf blowers are out.
[00:02:19.320 --> 00:02:20.560]   Construction worker.
[00:02:20.560 --> 00:02:23.560]   [LAUGHTER]
[00:02:23.560 --> 00:02:24.800]   What are those headphones you wear?
[00:02:24.800 --> 00:02:26.720]   I have to ask Jim, because he's a real audiophile.
[00:02:26.720 --> 00:02:28.720]   Those look pretty heavy duty there.
[00:02:28.720 --> 00:02:30.280]   Yeah, they're AKG.
[00:02:30.280 --> 00:02:31.320]   Oh, nice.
[00:02:31.320 --> 00:02:33.200]   Yeah, I really like AKG stuff.
[00:02:33.200 --> 00:02:39.040]   I wear K240s in the studio, as many professionals do.
[00:02:39.040 --> 00:02:40.200]   Because they're comfy.
[00:02:40.200 --> 00:02:42.760]   And look, there's a small four-legged creature
[00:02:42.760 --> 00:02:43.920]   wandering behind you.
[00:02:43.920 --> 00:02:45.320]   [LAUGHTER]
[00:02:45.320 --> 00:02:51.040]   I don't know if it's yours, but just so you're aware.
[00:02:51.040 --> 00:02:54.720]   Andy, Enocho's also here.
[00:02:54.720 --> 00:02:56.640]   Enocho.com, great to see you, Andy.
[00:02:56.640 --> 00:02:57.840]   Boy, you look good.
[00:02:57.840 --> 00:03:02.840]   You look-- the lighting is really flattery.
[00:03:02.840 --> 00:03:04.040]   Yeah.
[00:03:04.040 --> 00:03:05.760]   It's getting there.
[00:03:05.760 --> 00:03:08.480]   The blackout curtains went up last week
[00:03:08.480 --> 00:03:10.280]   and have been adjusted properly.
[00:03:10.280 --> 00:03:13.280]   It's like, yeah, if I were better at what I do,
[00:03:13.280 --> 00:03:15.560]   then this would all have been done within one week.
[00:03:15.560 --> 00:03:17.280]   But now it's like, no, it's--
[00:03:17.280 --> 00:03:19.120]   we've got 45 minutes before the next show.
[00:03:19.120 --> 00:03:21.800]   Let's spend a frantic half hour adjusting things
[00:03:21.800 --> 00:03:23.440]   to where they should be permanently.
[00:03:23.440 --> 00:03:25.120]   Nice.
[00:03:25.120 --> 00:03:27.720]   Oh, and I recognize that, Lavett's Lori Gill,
[00:03:27.720 --> 00:03:29.760]   Deputy Managing Editor of I'mors.
[00:03:29.760 --> 00:03:32.520]   She's the app-aholic.
[00:03:32.520 --> 00:03:33.720]   I like the apps.
[00:03:33.720 --> 00:03:34.720]   What can I say?
[00:03:34.720 --> 00:03:35.560]   A-holic.
[00:03:35.560 --> 00:03:38.560]   If you've got any Animal Crossing tips you want
[00:03:38.560 --> 00:03:40.400]   to pass along, Lori, please.
[00:03:40.400 --> 00:03:41.080]   I do.
[00:03:41.080 --> 00:03:41.880]   I have many.
[00:03:41.880 --> 00:03:44.000]   If you're an Animal Crossing player,
[00:03:44.000 --> 00:03:47.920]   come my way, because I have lots of things to say.
[00:03:47.920 --> 00:03:49.280]   Ooh, I can't wait.
[00:03:49.280 --> 00:03:50.280]   I can't wait.
[00:03:50.280 --> 00:03:51.520]   I like this one.
[00:03:51.520 --> 00:03:52.600]   Here's a recent article.
[00:03:52.600 --> 00:03:54.600]   How to prepare your home pod for sale.
[00:03:54.600 --> 00:03:56.440]   [LAUGHTER]
[00:03:56.440 --> 00:03:58.320]   Hey, you know people--
[00:03:58.320 --> 00:03:59.840]   so they buy it.
[00:03:59.840 --> 00:04:00.920]   They change their mind.
[00:04:00.920 --> 00:04:02.600]   It was given to them as a gift.
[00:04:02.600 --> 00:04:03.600]   They need to know.
[00:04:03.600 --> 00:04:04.480]   They need to know.
[00:04:04.480 --> 00:04:08.240]   How to prepare it to get rid of it.
[00:04:08.240 --> 00:04:11.200]   So the big story of the week this week
[00:04:11.200 --> 00:04:15.600]   comes from Matthew Panzorino in a tech crunch.
[00:04:15.600 --> 00:04:16.600]   I don't know.
[00:04:16.600 --> 00:04:19.000]   He didn't mention anybody else being there.
[00:04:19.000 --> 00:04:22.000]   He was one of the five journalists invited to Apple
[00:04:22.000 --> 00:04:26.480]   last year during the famous apology tour where Apple said,
[00:04:26.480 --> 00:04:27.800]   oops, we blew it.
[00:04:27.800 --> 00:04:30.520]   The Mac Pro is a dead end.
[00:04:30.520 --> 00:04:33.080]   We have painted ourselves into a corner,
[00:04:33.080 --> 00:04:36.560]   and we won't have one for you this year.
[00:04:36.560 --> 00:04:38.600]   But we're working on a new one.
[00:04:38.600 --> 00:04:41.760]   Matthew went back almost exactly a year later to Apple
[00:04:41.760 --> 00:04:45.360]   and got a little peek under the kimono.
[00:04:45.360 --> 00:04:52.600]   And there is a Mac Pro, but it won't be ready this year.
[00:04:52.600 --> 00:04:55.240]   Yeah, wouldn't it be great if they at least showed off
[00:04:55.240 --> 00:04:56.880]   something--
[00:04:56.880 --> 00:04:58.680]   I think one of the nicest things--
[00:04:58.680 --> 00:05:01.800]   one of the most valuable things that came out of that piece
[00:05:01.800 --> 00:05:07.840]   was Apple's acknowledgment that their normal position of utter
[00:05:07.840 --> 00:05:10.200]   secrecy and denial until they actually
[00:05:10.200 --> 00:05:13.360]   unveil the thing was not working out for people who
[00:05:13.360 --> 00:05:16.640]   have to make plans for buying new hardware at a certain set
[00:05:16.640 --> 00:05:17.720]   rate of time.
[00:05:17.720 --> 00:05:20.400]   So they made the point of one of the reasons
[00:05:20.400 --> 00:05:22.360]   why they're conducting these interviews and making
[00:05:22.360 --> 00:05:26.600]   these semi-announcements was to reassure people that, here's
[00:05:26.600 --> 00:05:30.000]   what we can show you to reassure you that if you are making--
[00:05:30.000 --> 00:05:31.360]   if you are going to be in a position,
[00:05:31.360 --> 00:05:34.120]   we're going to need new hardware in 2019.
[00:05:34.120 --> 00:05:35.360]   We might have something for you.
[00:05:35.360 --> 00:05:37.240]   But if you need something this year,
[00:05:37.240 --> 00:05:38.880]   you best make other plans.
[00:05:38.880 --> 00:05:40.040]   Because that really does--
[00:05:40.040 --> 00:05:41.800]   I think that's a lot of people.
[00:05:41.800 --> 00:05:43.120]   I think that's so true.
[00:05:43.120 --> 00:05:45.840]   I think-- I know a lot of people who--
[00:05:45.840 --> 00:05:47.880]   they're always asking me about whether or not they should
[00:05:47.880 --> 00:05:48.680]   upgrade their Mac.
[00:05:48.680 --> 00:05:51.520]   And when it comes to professional Macs,
[00:05:51.520 --> 00:05:55.520]   this is definitely something they need to know.
[00:05:55.520 --> 00:05:56.840]   Should I invest now?
[00:05:56.840 --> 00:05:58.680]   Should I put this on this fiscal year?
[00:05:58.680 --> 00:05:59.400]   Or should I wait?
[00:05:59.400 --> 00:06:02.320]   Is there going to be something in September if I buy now?
[00:06:02.320 --> 00:06:04.000]   Did I just waste my money?
[00:06:04.000 --> 00:06:05.800]   And I think it was really smart on Apple's
[00:06:05.800 --> 00:06:07.760]   part to be transparent about the fact
[00:06:07.760 --> 00:06:09.240]   that it's not coming this year.
[00:06:09.240 --> 00:06:11.240]   And it'll be here next year, but they didn't even
[00:06:11.240 --> 00:06:13.280]   give us a specific timeline next year.
[00:06:13.280 --> 00:06:14.600]   Could be in the first quarter.
[00:06:14.600 --> 00:06:15.840]   It could be at the end of the year.
[00:06:15.840 --> 00:06:19.360]   But I think it was really smart to kind of let us know,
[00:06:19.360 --> 00:06:23.000]   let the professionals know that if they're thinking--
[00:06:23.000 --> 00:06:24.800]   if they're thinking of buying that they're not
[00:06:24.800 --> 00:06:27.920]   going to get a new Mac Pro until 2019,
[00:06:27.920 --> 00:06:31.560]   and if this has to do with keeping your financial records
[00:06:31.560 --> 00:06:33.520]   together, you might go ahead and purchase
[00:06:33.520 --> 00:06:35.800]   at least some of those professional grade
[00:06:35.800 --> 00:06:37.560]   Macs before the end of the quarter,
[00:06:37.560 --> 00:06:39.720]   because you're not going to get anything new until 2019.
[00:06:39.720 --> 00:06:43.360]   All right, I'm going to give you the negative spin.
[00:06:43.360 --> 00:06:45.880]   [LAUGHTER]
[00:06:45.880 --> 00:06:46.880]   That's not a surprise.
[00:06:46.880 --> 00:06:51.960]   Apple's saying, please buy an iMac Pro.
[00:06:51.960 --> 00:06:53.480]   They're saying-- I mean, you're right.
[00:06:53.480 --> 00:06:54.600]   It's that message.
[00:06:54.600 --> 00:06:58.560]   But you feel like you're saying, oh, isn't this wonderful?
[00:06:58.560 --> 00:07:00.200]   But really, what it's Apple saying
[00:07:00.200 --> 00:07:02.440]   is, look, just buy the iMac Pro.
[00:07:02.440 --> 00:07:04.000]   Please don't wait for a Mac Pro.
[00:07:04.000 --> 00:07:05.800]   I understand that's a benefit to some people.
[00:07:05.800 --> 00:07:07.120]   And I even said they should tell people
[00:07:07.120 --> 00:07:09.400]   if they're going to make something this year or not.
[00:07:09.400 --> 00:07:12.280]   But it may could also really be that they're saying, you know--
[00:07:12.280 --> 00:07:12.960]   It's the right though.
[00:07:12.960 --> 00:07:13.960]   Buy the iMac Pro.
[00:07:13.960 --> 00:07:16.840]   Please, buy the iMac Pro.
[00:07:16.840 --> 00:07:20.600]   I don't know that that's really what they're saying, though.
[00:07:20.600 --> 00:07:27.240]   I mean, do we want-- the choice here seems pretty clear.
[00:07:27.240 --> 00:07:32.720]   Apple can try and release something because people expect it,
[00:07:32.720 --> 00:07:35.680]   or they can wait, make sure it's ready,
[00:07:35.680 --> 00:07:38.720]   and a whole new modular design, whatever
[00:07:38.720 --> 00:07:41.760]   that turns out to be, and whatever the form factor turns out
[00:07:41.760 --> 00:07:45.560]   to be, will be released when it's actually ready to go.
[00:07:45.560 --> 00:07:48.920]   Imagine if they released something that really wasn't
[00:07:48.920 --> 00:07:51.760]   up to what they wanted.
[00:07:51.760 --> 00:07:52.960]   People would be all over it.
[00:07:52.960 --> 00:07:55.960]   We'd be slamming them, saying, why didn't they wait?
[00:07:55.960 --> 00:07:59.720]   So instead of doing that, they come out and say,
[00:07:59.720 --> 00:08:01.520]   we're not going to have it this year.
[00:08:01.520 --> 00:08:02.240]   Make your plans.
[00:08:02.240 --> 00:08:05.960]   If you want to buy an iMac Pro, people can do that.
[00:08:05.960 --> 00:08:08.080]   It is a powerful machine.
[00:08:08.080 --> 00:08:10.960]   But if you want to wait for this new modular design,
[00:08:10.960 --> 00:08:15.120]   then here's our sort of timeline.
[00:08:15.120 --> 00:08:15.960]   Next year.
[00:08:15.960 --> 00:08:21.520]   We didn't see that with the previous Mac Pro, to be fair.
[00:08:21.520 --> 00:08:24.280]   Here is something that you have not been asking us for.
[00:08:24.280 --> 00:08:27.840]   That does not meet your needs as you choose to define them.
[00:08:27.840 --> 00:08:28.440]   Good luck.
[00:08:28.440 --> 00:08:29.480]   Bob, but innovate.
[00:08:29.480 --> 00:08:31.360]   My ass.
[00:08:31.360 --> 00:08:36.160]   Tom Boger, senior director of Mac Hardware Product Marketing,
[00:08:36.160 --> 00:08:38.320]   Panzerino quotes him as saying, we know there are a lot
[00:08:38.320 --> 00:08:41.120]   of customers today that are making purchase decisions
[00:08:41.120 --> 00:08:43.680]   on the iMac Pro and whether or not they should
[00:08:43.680 --> 00:08:45.760]   wait for the Mac Pro.
[00:08:45.760 --> 00:08:48.680]   He doesn't finish that sentence.
[00:08:48.680 --> 00:08:51.680]   But I think I can finish it.
[00:08:51.680 --> 00:08:53.600]   Don't wait.
[00:08:53.600 --> 00:08:54.360]   Right?
[00:08:54.360 --> 00:08:58.400]   Well, that's correct to a certain extent.
[00:08:58.400 --> 00:09:01.320]   Again, it's valuable to let people know that if you were holding
[00:09:01.320 --> 00:09:04.280]   off for, let's say, WWDC, particularly to say that,
[00:09:04.280 --> 00:09:07.320]   I bet that they're going to announce something then to have
[00:09:07.320 --> 00:09:09.960]   at least a year in advance knowing that no, nothing is coming
[00:09:09.960 --> 00:09:12.880]   in 2018.
[00:09:12.880 --> 00:09:14.280]   If this isn't waiting for good though,
[00:09:14.280 --> 00:09:17.080]   you may as well leave the barren spot with a tree,
[00:09:17.080 --> 00:09:20.760]   go back to your motorhome with a microwave oven and the TV
[00:09:20.760 --> 00:09:22.480]   because you're going to have to dig in.
[00:09:22.480 --> 00:09:24.800]   I think Apple is also savvy enough
[00:09:24.800 --> 00:09:27.520]   to know that a lot of people--
[00:09:27.520 --> 00:09:30.760]   this frees up them to not simply say, well, I'm just
[00:09:30.760 --> 00:09:32.000]   going to have to buy an iMac.
[00:09:32.000 --> 00:09:34.240]   It does free up a lot of people to think, OK,
[00:09:34.240 --> 00:09:36.480]   this is where I switch to Windows because I can't wait another
[00:09:36.480 --> 00:09:38.480]   year and a half for whatever.
[00:09:38.480 --> 00:09:40.840]   That is not the most important sentence.
[00:09:40.840 --> 00:09:44.120]   So I know that's not what he meant, but that's it.
[00:09:44.120 --> 00:09:46.120]   That is part of the effect.
[00:09:46.120 --> 00:09:52.560]   There are a lot of pros that will wait.
[00:09:52.560 --> 00:09:53.560]   Yeah.
[00:09:53.560 --> 00:09:56.360]   And some of those industries, including music,
[00:09:56.360 --> 00:10:00.000]   are already a bit further behind than--
[00:10:00.000 --> 00:10:01.200]   No, interesting.
[00:10:01.200 --> 00:10:05.240]   You know, what they already have because in music,
[00:10:05.240 --> 00:10:07.080]   I don't know about video or photography,
[00:10:07.080 --> 00:10:11.640]   but in music, once you get your system set up,
[00:10:11.640 --> 00:10:13.080]   you leave it alone.
[00:10:13.080 --> 00:10:15.000]   Sometimes there's no updates.
[00:10:15.000 --> 00:10:17.000]   There's no nothing because it's working.
[00:10:17.000 --> 00:10:18.200]   It's recording.
[00:10:18.200 --> 00:10:20.920]   And any downtime is money.
[00:10:20.920 --> 00:10:23.000]   And if they do get a new machine,
[00:10:23.000 --> 00:10:27.680]   a lot of times they'll run that in parallel to the old machine
[00:10:27.680 --> 00:10:29.480]   that they know works.
[00:10:29.480 --> 00:10:32.960]   So you know that a new machine is going to come with the newest
[00:10:32.960 --> 00:10:34.840]   operating system.
[00:10:34.840 --> 00:10:37.760]   And a lot of times that won't work with some music software
[00:10:37.760 --> 00:10:38.840]   until it's updated.
[00:10:38.840 --> 00:10:40.160]   That's a good point.
[00:10:40.160 --> 00:10:46.720]   Even my music machine, the one that I record all my things
[00:10:46.720 --> 00:10:52.680]   on in Logic and Pro Tools, is always an operating system behind.
[00:10:52.680 --> 00:10:56.480]   So I'm not running high-sew on that intentionally
[00:10:56.480 --> 00:10:58.400]   because it works right now.
[00:10:58.400 --> 00:11:02.880]   And I know when I go in and I plug in my guitar and I set up
[00:11:02.880 --> 00:11:04.680]   the mics, I get everything rolling,
[00:11:04.680 --> 00:11:06.280]   everything is going to work.
[00:11:06.280 --> 00:11:08.560]   If I update something, it could break.
[00:11:08.560 --> 00:11:12.200]   So my point is for those industries,
[00:11:12.200 --> 00:11:16.760]   it's not necessarily a bad thing that they're waiting a year.
[00:11:16.760 --> 00:11:20.360]   You know, they're not going to care that much.
[00:11:20.360 --> 00:11:24.440]   Next year, studios may bring one in.
[00:11:24.440 --> 00:11:25.160]   But you're not--
[00:11:25.160 --> 00:11:27.720]   I'm going to bet, Jim, you're not using the trash
[00:11:27.720 --> 00:11:30.200]   can Mac Pro either.
[00:11:30.200 --> 00:11:32.200]   I am not amusing an iMac.
[00:11:32.200 --> 00:11:32.880]   Yeah.
[00:11:32.880 --> 00:11:34.880]   So you-- because that's the real problem.
[00:11:34.880 --> 00:11:38.360]   People who bought, as I did, a Mac Pro in 2013
[00:11:38.360 --> 00:11:45.440]   are now sitting in year five saying, oh, another year?
[00:11:45.440 --> 00:11:46.640]   Right?
[00:11:46.640 --> 00:11:48.600]   But I don't think that any of those--
[00:11:48.600 --> 00:11:50.040]   They're going to buy an iMac Pro.
[00:11:50.040 --> 00:11:51.520]   Well, they may.
[00:11:51.520 --> 00:11:52.320]   They may.
[00:11:52.320 --> 00:11:53.200]   I mean--
[00:11:53.200 --> 00:11:55.320]   That's a definite option with the iMac Pro being
[00:11:55.320 --> 00:11:56.960]   as good quality as it is.
[00:11:56.960 --> 00:12:00.160]   I think that was one of the reasons why Apple kind of went
[00:12:00.160 --> 00:12:04.880]   for that is that the Mac Pro is just not going to be ready in time.
[00:12:04.880 --> 00:12:06.080]   So here's the supplement.
[00:12:06.080 --> 00:12:08.160]   If you really feel like you have to upgrade,
[00:12:08.160 --> 00:12:11.520]   if you can't wait, here's the iMac Pro and it works great.
[00:12:11.520 --> 00:12:14.920]   And it's going to satisfy a lot of people's needs.
[00:12:14.920 --> 00:12:18.120]   But at the same time, just like Jim is saying, it's true.
[00:12:18.120 --> 00:12:21.320]   They're the people I know with Mac Pro
[00:12:21.320 --> 00:12:23.880]   that are using them for music recording or graphics
[00:12:23.880 --> 00:12:27.520]   design, they are running old software programs.
[00:12:27.520 --> 00:12:29.920]   They're running old operating systems
[00:12:29.920 --> 00:12:32.320]   because they don't want to break what currently exists.
[00:12:32.320 --> 00:12:33.440]   And so they are.
[00:12:33.440 --> 00:12:34.200]   They're the waiters.
[00:12:34.200 --> 00:12:36.840]   They're not in a hurry to upgrade.
[00:12:36.840 --> 00:12:39.040]   They'll wait until 2019.
[00:12:39.040 --> 00:12:42.480]   Whereas there are some people who maybe they're machine--
[00:12:42.480 --> 00:12:44.880]   Maybe they're just excited and they want to try something new
[00:12:44.880 --> 00:12:47.040]   and different that iMac Pro is definitely an option.
[00:12:47.040 --> 00:12:50.800]   But at the same time, for those Mac Pro users that
[00:12:50.800 --> 00:12:53.840]   need that Mac Pro spec, I think--
[00:12:53.840 --> 00:12:57.920]   Jim has nailed it that they are willing to wait for sure.
[00:12:57.920 --> 00:13:03.120]   I also think Apple has benefited from Intel's laggard
[00:13:03.120 --> 00:13:07.800]   improvement of their chips that even a late 2013 Mac Pro
[00:13:07.800 --> 00:13:12.440]   probably doesn't feel too slow compared to five years later,
[00:13:12.440 --> 00:13:14.400]   mostly because Intel hasn't really
[00:13:14.400 --> 00:13:17.160]   done that much to make their chips that much faster.
[00:13:17.160 --> 00:13:19.360]   I doubt there are many pros who are saying, oh, man,
[00:13:19.360 --> 00:13:21.360]   I can't use this Zioni 5.
[00:13:21.360 --> 00:13:24.960]   It's just too slow compared to what I need.
[00:13:24.960 --> 00:13:26.880]   Nobody's saying that, in fact, I bet.
[00:13:26.880 --> 00:13:29.000]   What you do want, though, and what
[00:13:29.000 --> 00:13:31.360]   was missing in the trash can Mac Pro
[00:13:31.360 --> 00:13:34.000]   and is missing in the iMac Pro is modularity.
[00:13:34.000 --> 00:13:36.280]   And that is the good news from Matthew Panzareno.
[00:13:36.280 --> 00:13:41.080]   Apple says, it's going to be a modular Mac.
[00:13:41.080 --> 00:13:43.080]   Depending on what you mean.
[00:13:43.080 --> 00:13:46.040]   So yeah, Andy was just saying, it depends
[00:13:46.040 --> 00:13:48.720]   on what you mean by modular and how modular.
[00:13:48.720 --> 00:13:54.600]   But if you look back to the Mac Pro, the silver one.
[00:13:54.600 --> 00:13:56.360]   The cheese grater, were you fondly?
[00:13:56.360 --> 00:13:58.720]   Yes, the cheese grater.
[00:13:58.720 --> 00:14:03.680]   I mean, I had a lot of PCI cards and things like that
[00:14:03.680 --> 00:14:07.800]   in there from companies like Universal Audio.
[00:14:07.800 --> 00:14:08.160]   To take--
[00:14:08.160 --> 00:14:09.520]   Can't do that very easily.
[00:14:09.520 --> 00:14:14.000]   Although they have EGPU support now in high Sierra.
[00:14:14.000 --> 00:14:15.880]   I don't know if EGPU means you'll also
[00:14:15.880 --> 00:14:18.600]   have the ability to run those external cards on a PCI
[00:14:18.600 --> 00:14:19.800]   slot external PCS.
[00:14:19.800 --> 00:14:23.920]   Well, part of the problem now is that when Apple moved away
[00:14:23.920 --> 00:14:26.240]   from those things, all of these companies
[00:14:26.240 --> 00:14:33.400]   came out with external DSP to take the load off of the CPU
[00:14:33.400 --> 00:14:35.400]   so that when you're running plugins,
[00:14:35.400 --> 00:14:37.320]   it doesn't tax the computer as much.
[00:14:37.320 --> 00:14:40.880]   It taxes what used to be the PCI card.
[00:14:40.880 --> 00:14:44.480]   But now is a piece of outboard gear
[00:14:44.480 --> 00:14:49.520]   that's sitting on your desktop or around the console.
[00:14:49.520 --> 00:14:52.600]   Bogar also says, there is absolutely a need
[00:14:52.600 --> 00:14:55.640]   in certain places for modularity.
[00:14:55.640 --> 00:14:56.160]   I'm sorry.
[00:14:56.160 --> 00:14:57.840]   I can't get off of my spin.
[00:14:57.840 --> 00:15:00.360]   But it's also really clear the iMac form factor of the MacBook
[00:15:00.360 --> 00:15:02.680]   Pro's can be exceptionally good tools.
[00:15:02.680 --> 00:15:10.080]   I mean, OK, I guess I'm seeing it through a certain filter.
[00:15:10.080 --> 00:15:12.160]   I do think modularity is pretty important.
[00:15:12.160 --> 00:15:13.640]   But you make an excellent point.
[00:15:13.640 --> 00:15:18.200]   If modularity hasn't been available for five years,
[00:15:18.200 --> 00:15:21.240]   maybe everybody's moved on to the next thing, Mandy?
[00:15:21.240 --> 00:15:23.560]   It depends on how you want to define, as always,
[00:15:23.560 --> 00:15:26.680]   what does the word pro mean?
[00:15:26.680 --> 00:15:29.520]   For some, it might mean a specific workflow,
[00:15:29.520 --> 00:15:31.880]   a specific type of usage.
[00:15:31.880 --> 00:15:34.360]   For me, it's always meant we will not--
[00:15:34.360 --> 00:15:36.480]   we, the manufacturer, are not going to dictate to you
[00:15:36.480 --> 00:15:38.320]   how you must use this machine.
[00:15:38.320 --> 00:15:41.680]   We know that you will have very peculiar and specific needs
[00:15:41.680 --> 00:15:45.240]   and will give you a platform that will let you make modifications
[00:15:45.240 --> 00:15:48.320]   or build a system that will really
[00:15:48.320 --> 00:15:50.960]   be focused to what you want to do.
[00:15:50.960 --> 00:15:55.960]   And historically, that fulfills a really wide range of users,
[00:15:55.960 --> 00:15:59.000]   not just the people who are doing pro audio, doing pro video,
[00:15:59.000 --> 00:16:02.440]   but also people who have some-- have
[00:16:02.440 --> 00:16:07.880]   outgrown the needs of the level of a base level, let's say,
[00:16:07.880 --> 00:16:11.640]   iMac, a consumer oriented iMac or consumer oriented
[00:16:11.640 --> 00:16:14.240]   Mac Mini, they just need a little bit more oomph.
[00:16:14.240 --> 00:16:15.520]   They need more ports.
[00:16:15.520 --> 00:16:18.560]   They need a little bit more resources for these one-off
[00:16:18.560 --> 00:16:21.480]   projects that they are potting their head against once
[00:16:21.480 --> 00:16:24.800]   or twice a year, as opposed to 12 months out of the year.
[00:16:24.800 --> 00:16:26.120]   That's what you're sort of buying.
[00:16:26.120 --> 00:16:30.040]   That's kind of what I think has marked the difference
[00:16:30.040 --> 00:16:33.440]   between, for instance, the MacBook Pro and the ordinary MacBook
[00:16:33.440 --> 00:16:34.040]   line.
[00:16:34.040 --> 00:16:37.280]   And that's always what I've sort of felt the desktop line
[00:16:37.280 --> 00:16:38.200]   to be as well.
[00:16:38.200 --> 00:16:42.560]   So my bigger worry would be that they really want
[00:16:42.560 --> 00:16:49.480]   to get such a specific data-oriented idea of the typical Mac
[00:16:49.480 --> 00:16:54.240]   Pro user that they once again sort of lock you into a track
[00:16:54.240 --> 00:16:57.080]   where, no, you don't want to have expansion cards.
[00:16:57.080 --> 00:16:59.680]   You want to put everything on an external bus instead
[00:16:59.680 --> 00:17:01.720]   for sound and for video.
[00:17:01.720 --> 00:17:03.040]   And we're going to let you do all that
[00:17:03.040 --> 00:17:05.720]   by buying all this other stuff, which, again,
[00:17:05.720 --> 00:17:08.600]   will work great for a lot of people who are making a lot of money
[00:17:08.600 --> 00:17:09.840]   with their Mac Pros.
[00:17:09.840 --> 00:17:12.600]   It won't do quite so well for people that, once again,
[00:17:12.600 --> 00:17:14.680]   they've outgrown the consumer grade,
[00:17:14.680 --> 00:17:17.920]   but they're not making a fortune off of contracts
[00:17:17.920 --> 00:17:20.400]   that they're fulfilling with their desktop system.
[00:17:20.400 --> 00:17:22.280]   So we're going to have to wait and see what they really
[00:17:22.280 --> 00:17:23.120]   have in mind for us.
[00:17:23.120 --> 00:17:24.120]   Yeah.
[00:17:24.120 --> 00:17:27.120]   But I think those people that are in between,
[00:17:27.120 --> 00:17:30.680]   that's where the iMac Pro comes in.
[00:17:30.680 --> 00:17:35.080]   Because they do have a lot of the outboard gear
[00:17:35.080 --> 00:17:39.760]   where you plug into Thunderbolt or USB or whatever.
[00:17:39.760 --> 00:17:43.960]   And if they need that extra power, they can still get it.
[00:17:43.960 --> 00:17:49.440]   I think the Mac Pro, especially in the modular design,
[00:17:49.440 --> 00:17:55.000]   is going to be for those very high-end professionals.
[00:17:55.000 --> 00:17:56.840]   And I think the power will show that.
[00:17:56.840 --> 00:17:59.960]   And most likely, the price will show that as well.
[00:17:59.960 --> 00:18:03.400]   But it's going to be a high-end machine.
[00:18:03.400 --> 00:18:08.720]   So, but once again, in this case, I'm only speaking personally.
[00:18:08.720 --> 00:18:12.480]   But I just don't have a use for an all-in-one machine.
[00:18:12.480 --> 00:18:15.240]   It just isn't how I tend to work.
[00:18:15.240 --> 00:18:17.920]   I have a really nice monitor that I'm already
[00:18:17.920 --> 00:18:19.440]   screening them very, very happy with.
[00:18:19.440 --> 00:18:21.720]   And I like being able to have it on an arm
[00:18:21.720 --> 00:18:23.080]   so I can position it anywhere.
[00:18:23.080 --> 00:18:27.520]   So I would be-- if faced with the problem of,
[00:18:27.520 --> 00:18:30.560]   I'm going to either have to spend money for a screen
[00:18:30.560 --> 00:18:34.040]   that I don't want and a form factor that isn't what I
[00:18:34.040 --> 00:18:37.000]   decree to be optimal for my use.
[00:18:37.000 --> 00:18:39.440]   Once again, it's a case of, here's $3,000.
[00:18:39.440 --> 00:18:42.480]   You're going to have to adjust what you want
[00:18:42.480 --> 00:18:44.320]   to what we're willing to sell you.
[00:18:44.320 --> 00:18:46.120]   Which admittedly, is always going to be a problem when you
[00:18:46.120 --> 00:18:50.960]   have a company that isn't going to license their designs
[00:18:50.960 --> 00:18:54.000]   to anyone else or let anybody else make hack-and-toshes
[00:18:54.000 --> 00:18:54.960]   or stuff like that.
[00:18:54.960 --> 00:18:56.760]   But nonetheless, it's always going to be a problem
[00:18:56.760 --> 00:18:59.840]   that consumers are going to have to deal with as they continue
[00:18:59.840 --> 00:19:02.520]   to evolve as users.
[00:19:02.520 --> 00:19:06.480]   Yeah, but I really don't think that you or even me,
[00:19:06.480 --> 00:19:12.760]   even recording what I do, are the market for a Mac Pro.
[00:19:12.760 --> 00:19:13.680]   Yeah.
[00:19:13.680 --> 00:19:16.240]   The other machines are so powerful.
[00:19:16.240 --> 00:19:20.520]   Even Leo sitting at his desk right now is probably not
[00:19:20.520 --> 00:19:21.760]   the market for the Mac Pro.
[00:19:21.760 --> 00:19:25.560]   However, the back end of what Leo does with all the streaming
[00:19:25.560 --> 00:19:28.200]   and everything else, that could be a market
[00:19:28.200 --> 00:19:29.800]   that they're looking at.
[00:19:29.800 --> 00:19:30.480]   Oh, sure.
[00:19:30.480 --> 00:19:32.640]   Although it's too late for many of--
[00:19:32.640 --> 00:19:34.040]   I mean, it's too late for us.
[00:19:34.040 --> 00:19:36.160]   We bought Windows machines running Premiere.
[00:19:36.160 --> 00:19:38.240]   Well, it's never too late, Leo.
[00:19:38.240 --> 00:19:39.160]   Looked to some fire.
[00:19:39.160 --> 00:19:41.520]   We're not switching back.
[00:19:41.520 --> 00:19:43.880]   Unless Microsoft dumps the Pro market,
[00:19:43.880 --> 00:19:46.240]   I don't think that's going to happen.
[00:19:46.240 --> 00:19:49.720]   Apple did in this meeting, which, again, really
[00:19:49.720 --> 00:19:53.240]   have to say, it feels more like marketing than anything else.
[00:19:53.240 --> 00:19:55.040]   Here's the message.
[00:19:55.040 --> 00:19:57.880]   We said in the meeting that the Pro community isn't
[00:19:57.880 --> 00:19:58.400]   one thing.
[00:19:58.400 --> 00:19:59.200]   It's very diverse.
[00:19:59.200 --> 00:20:01.240]   There are many different types of pros.
[00:20:01.240 --> 00:20:02.160]   We've said that too.
[00:20:02.160 --> 00:20:02.960]   I think that's obvious.
[00:20:02.960 --> 00:20:04.960]   They go really deep into the hardware and software,
[00:20:04.960 --> 00:20:08.000]   pushing everything to its limit.
[00:20:08.000 --> 00:20:11.640]   We wanted our architects to sit with real customers
[00:20:11.640 --> 00:20:14.080]   to understand the real flow.
[00:20:14.080 --> 00:20:15.880]   But of course, the challenge with that
[00:20:15.880 --> 00:20:18.360]   is that customers are typically responsive when Apple comes
[00:20:18.360 --> 00:20:18.720]   calling.
[00:20:18.720 --> 00:20:20.280]   It's not easy to get what they want,
[00:20:20.280 --> 00:20:24.080]   because they're using proprietary content.
[00:20:24.080 --> 00:20:25.480]   You're not going to-- apples can't
[00:20:25.480 --> 00:20:28.120]   get access to the Pixar studios when they're working
[00:20:28.120 --> 00:20:29.520]   on the next movie.
[00:20:29.520 --> 00:20:33.760]   So what Apple did is they hired creatives
[00:20:33.760 --> 00:20:34.840]   and brought them into Apple.
[00:20:34.840 --> 00:20:38.720]   And there's something called the Pro Workflow team,
[00:20:38.720 --> 00:20:42.320]   a bunch of artists, technicians, working on,
[00:20:42.320 --> 00:20:46.480]   they say, real projects, and then using Apple hardware--
[00:20:46.480 --> 00:20:48.720]   in some cases, prototype hardware--
[00:20:48.720 --> 00:20:52.320]   and certainly new versions of the software
[00:20:52.320 --> 00:20:56.880]   to bang on it and give Apple feedback on what it is that they
[00:20:56.880 --> 00:20:59.480]   need and where there are bottlenecks where they need
[00:20:59.480 --> 00:21:00.720]   to improve things.
[00:21:00.720 --> 00:21:03.800]   And Apple was quick to point out that this Pro Workflow team
[00:21:03.800 --> 00:21:07.000]   is sitting right next to the hardware design team that's
[00:21:07.000 --> 00:21:08.520]   working on the new Mac Pro.
[00:21:08.520 --> 00:21:09.800]   That's pretty encouraging.
[00:21:09.800 --> 00:21:12.280]   I think that that's very good news.
[00:21:12.280 --> 00:21:12.960]   It means that they're--
[00:21:12.960 --> 00:21:16.320]   Yeah, they can just sort of shout, hey, this isn't working right.
[00:21:16.320 --> 00:21:16.960]   Come fix this.
[00:21:16.960 --> 00:21:17.480]   Right.
[00:21:17.480 --> 00:21:18.480]   Yeah.
[00:21:18.480 --> 00:21:19.560]   Right.
[00:21:19.560 --> 00:21:21.360]   There are also higher level decisions
[00:21:21.360 --> 00:21:22.360]   that Apple needs to make.
[00:21:22.360 --> 00:21:24.440]   And I don't know if they're getting the kind of feedback
[00:21:24.440 --> 00:21:25.400]   they need.
[00:21:25.400 --> 00:21:30.480]   Things like OpenGL doesn't work on Mac and Tush's either fix it
[00:21:30.480 --> 00:21:32.520]   or something.
[00:21:32.520 --> 00:21:34.200]   I mean, there are issues--
[00:21:34.200 --> 00:21:36.040]   I wish-- unfortunately, Alex Lindsey, who should really
[00:21:36.040 --> 00:21:38.800]   be sitting here for this conversation,
[00:21:38.800 --> 00:21:40.400]   would be really better to talk to this.
[00:21:40.400 --> 00:21:43.280]   But I feel like there are decisions that
[00:21:43.280 --> 00:21:45.560]   aren't made at that granular level that
[00:21:45.560 --> 00:21:46.960]   need to be made at a higher level.
[00:21:46.960 --> 00:21:48.600]   Maybe Apple's getting the signals they need
[00:21:48.600 --> 00:21:51.120]   on those kinds of things as well.
[00:21:51.120 --> 00:21:55.480]   But there's many ways that Apple hasn't treated professionals
[00:21:55.480 --> 00:21:57.040]   very well.
[00:21:57.040 --> 00:21:58.800]   We were talking about this on a tweet with Brianna Wu,
[00:21:58.800 --> 00:22:00.040]   who's a game designer.
[00:22:00.040 --> 00:22:02.480]   And she said her specialty is OpenGL.
[00:22:02.480 --> 00:22:05.200]   And she said Apple's implementation is unusable.
[00:22:05.200 --> 00:22:12.880]   Yeah, I thought that was a very encouraging sign, too,
[00:22:12.880 --> 00:22:17.320]   that to the extent of hiring filmmakers to simply make films
[00:22:17.320 --> 00:22:19.640]   just so that Apple could watch them make films,
[00:22:19.640 --> 00:22:24.760]   that shows a really huge sign of faith
[00:22:24.760 --> 00:22:26.920]   in the pro level of user.
[00:22:26.920 --> 00:22:29.680]   That's unusual, and that's certainly attention getting.
[00:22:29.680 --> 00:22:31.840]   My concern is that every time that I've thought
[00:22:31.840 --> 00:22:34.400]   that Apple has messed up personally,
[00:22:34.400 --> 00:22:41.240]   it's when they feel as though when people complain that, hey,
[00:22:41.240 --> 00:22:43.280]   you've built a machine that really doesn't work for me,
[00:22:43.280 --> 00:22:46.360]   or, gee, this really isn't attractive, they instead point to it,
[00:22:46.360 --> 00:22:48.160]   hey, look, but we have numbers that prove.
[00:22:48.160 --> 00:22:50.560]   We did so much testing to prove that this is exactly the Mac
[00:22:50.560 --> 00:22:51.520]   that you want.
[00:22:51.520 --> 00:22:54.160]   So obviously, you just need to get used to it.
[00:22:54.160 --> 00:22:56.800]   And again, for the Mac Pro, I really
[00:22:56.800 --> 00:22:59.280]   think that there should be part of the Mac line that is,
[00:22:59.280 --> 00:23:02.440]   we are not going to insist that you adapt anything
[00:23:02.440 --> 00:23:07.160]   that you do to our method of manufacturing a Mac.
[00:23:07.160 --> 00:23:09.640]   We are going to give you something that's flexible enough
[00:23:09.640 --> 00:23:13.680]   that we can integrate into your office and into your job
[00:23:13.680 --> 00:23:16.560]   and into your creative goals, as opposed
[00:23:16.560 --> 00:23:19.160]   to you saying that you have to say that, well,
[00:23:19.160 --> 00:23:22.080]   I really didn't want this, but this is all your offering,
[00:23:22.080 --> 00:23:23.240]   so this is what I'm going to have to buy.
[00:23:23.240 --> 00:23:25.800]   I feel like Apple's pride got in the way
[00:23:25.800 --> 00:23:27.880]   that if Apple didn't--
[00:23:27.880 --> 00:23:29.800]   if they had had less pride, they would have just
[00:23:29.800 --> 00:23:33.320]   taken the old cheese grater Mac, updated it
[00:23:33.320 --> 00:23:35.040]   with new processors, newer bus.
[00:23:35.040 --> 00:23:37.480]   This wouldn't have been as complicated as designing
[00:23:37.480 --> 00:23:40.560]   a whole new Mac Pro, and said, yeah, we made a mistake.
[00:23:40.560 --> 00:23:42.640]   They admitted they made a mistake, but they said,
[00:23:42.640 --> 00:23:44.640]   but in two years, we're going to fix it.
[00:23:44.640 --> 00:23:46.320]   Instead, they could have said, well, in six months,
[00:23:46.320 --> 00:23:50.280]   we're going to give you a cheese grater Mac as a stopgap,
[00:23:50.280 --> 00:23:53.280]   a modular Mac as a stopgap until we get the really great thing
[00:23:53.280 --> 00:23:54.480]   out in 2019.
[00:23:54.480 --> 00:23:56.200]   Isn't that what they did with the iMac Pro?
[00:23:56.200 --> 00:23:57.720]   No, but it's not.
[00:23:57.720 --> 00:23:59.520]   That's exactly not what the iMac Pro.
[00:23:59.520 --> 00:24:04.800]   The iMac Pro is a sealed box, and it requires people to buy E.G.
[00:24:04.800 --> 00:24:06.280]   Look at this description of--
[00:24:06.280 --> 00:24:08.640]   But it's something that they could rev and update
[00:24:08.640 --> 00:24:10.200]   and get on the market really, really quick
[00:24:10.200 --> 00:24:11.920]   without having to reinvent the entire market.
[00:24:11.920 --> 00:24:13.720]   Admittedly, they could have done that with a cheese grater
[00:24:13.720 --> 00:24:15.720]   as well, right?
[00:24:15.720 --> 00:24:17.400]   But then you're talking about a price point that's
[00:24:17.400 --> 00:24:19.800]   a little higher than maybe someone wants to invest in here
[00:24:19.800 --> 00:24:20.800]   this year.
[00:24:20.800 --> 00:24:22.880]   I spent $4,000 on an iMac Pro.
[00:24:22.880 --> 00:24:24.080]   Higher than that?
[00:24:24.080 --> 00:24:27.040]   You could have spent $3,000.
[00:24:27.040 --> 00:24:27.560]   Look at this.
[00:24:27.560 --> 00:24:31.640]   Listen to the description that Matthew gives of a kind
[00:24:31.640 --> 00:24:33.960]   of a workflow situation going on.
[00:24:33.960 --> 00:24:38.160]   An iMac Pro, with two iPad Pros hooked up to it,
[00:24:38.160 --> 00:24:41.040]   allows for direct control shortcuts and live access
[00:24:41.040 --> 00:24:43.960]   to the logic manual, all while you're mixing songs
[00:24:43.960 --> 00:24:45.560]   on the main device--
[00:24:45.560 --> 00:24:46.520]   oh, wait a minute, the iMac Pro?
[00:24:46.520 --> 00:24:47.040]   No, no.
[00:24:47.040 --> 00:24:50.440]   An eGPU with a MacBook Pro running alive
[00:24:50.440 --> 00:24:52.800]   at it of an 8K stream with color grading and effects apply.
[00:24:52.800 --> 00:24:56.960]   So Apple sold an iMac Pro, two iPad Pros, an eGPU,
[00:24:56.960 --> 00:25:00.280]   and a MacBook Pro to do this.
[00:25:00.280 --> 00:25:04.280]   When really, a cheese grater could have probably handled it.
[00:25:04.280 --> 00:25:05.960]   It couldn't have done the iPad stuff.
[00:25:05.960 --> 00:25:08.840]   That was nothing that really caught my attention control.
[00:25:08.840 --> 00:25:12.840]   I've always-- like when the touch bar MacBook came out,
[00:25:12.840 --> 00:25:16.880]   my big complaint was that it really was just such weak sauce
[00:25:16.880 --> 00:25:21.240]   that if they really wanted to add touchscreen improvements
[00:25:21.240 --> 00:25:23.480]   to a pro workflow, it would be just as simple as, oh,
[00:25:23.480 --> 00:25:24.480]   I see you have an iPhone.
[00:25:24.480 --> 00:25:27.720]   Would you like me to be able to cast some of the interface,
[00:25:27.720 --> 00:25:30.760]   like a control deck or a jog shuttle onto your iPad
[00:25:30.760 --> 00:25:32.040]   or onto your iPhone?
[00:25:32.040 --> 00:25:33.360]   That's really interesting.
[00:25:33.360 --> 00:25:34.600]   And that's really cool.
[00:25:34.600 --> 00:25:38.040]   That's something that Adobe is doing with their Photoshop kit,
[00:25:38.040 --> 00:25:41.280]   where you can actually use a touchscreen device
[00:25:41.280 --> 00:25:43.000]   as part of a desktop interface.
[00:25:43.000 --> 00:25:45.960]   So that shows the sort of, we need two years
[00:25:45.960 --> 00:25:49.000]   to really figure this out thinking that I think is justified.
[00:25:49.000 --> 00:25:50.840]   Again, and I agree with you, the only reason
[00:25:50.840 --> 00:25:53.320]   why you invite a reporter into the campus
[00:25:53.320 --> 00:25:55.280]   is for some sort of message that you
[00:25:55.280 --> 00:25:58.520]   hope that reporter is going to give to everybody else.
[00:25:58.520 --> 00:26:00.000]   So I do agree with that.
[00:26:00.000 --> 00:26:02.480]   But that doesn't change the fact that a lot of the things
[00:26:02.480 --> 00:26:05.560]   that they chose to say are things that leave me optimistic
[00:26:05.560 --> 00:26:07.280]   about what's coming in 2019.
[00:26:07.280 --> 00:26:10.600]   This is big thinking as opposed to slap a better CPU
[00:26:10.600 --> 00:26:14.200]   and a better address plus into the Cheesegrader.
[00:26:14.200 --> 00:26:17.240]   >> I think the workflow team is a perfect example
[00:26:17.240 --> 00:26:20.240]   of the potential that the new MacBook Pro
[00:26:20.240 --> 00:26:21.600]   or the new MacBook Pro could have.
[00:26:21.600 --> 00:26:25.800]   And is that it potentially could fit all of our needs
[00:26:25.800 --> 00:26:28.600]   because if they really are testing the waters
[00:26:28.600 --> 00:26:30.680]   with all different manner of users
[00:26:30.680 --> 00:26:35.600]   in all different situations, not everyone is going
[00:26:35.600 --> 00:26:38.840]   to buy a MacBook Pro, then buy two iPads,
[00:26:38.840 --> 00:26:39.920]   then hook up a GPU.
[00:26:39.920 --> 00:26:42.560]   But some are, some don't want a MacBook Pro,
[00:26:42.560 --> 00:26:44.120]   some want that set up.
[00:26:44.120 --> 00:26:47.240]   So if you're navigating all these testing situations
[00:26:47.240 --> 00:26:51.120]   using the MacBook Pro into iPads and a GPU,
[00:26:51.120 --> 00:26:53.840]   but you're also doing it with this brand new MacBook Pro,
[00:26:53.840 --> 00:26:55.760]   but you're also doing it with an iMac,
[00:26:55.760 --> 00:26:57.280]   I think this is a great idea
[00:26:57.280 --> 00:27:00.840]   and could potentially not only benefit the Mac Pro
[00:27:00.840 --> 00:27:04.680]   coming out, but what I've read from this article was that
[00:27:04.680 --> 00:27:07.600]   I get the sense that Apple is working toward
[00:27:07.600 --> 00:27:11.760]   making all of the Mac line more user friendly
[00:27:11.760 --> 00:27:14.280]   across the board, no matter what level you're at,
[00:27:14.280 --> 00:27:19.280]   that even a MacBook Air,
[00:27:19.280 --> 00:27:24.920]   if that have something a little more appealing to the people
[00:27:24.920 --> 00:27:28.240]   that would use a MacBook Air so that their workflow
[00:27:28.240 --> 00:27:31.240]   is comfortable just as the way a Mac Pro users
[00:27:31.240 --> 00:27:32.640]   workflow would be comfortable.
[00:27:36.320 --> 00:27:39.360]   Well, I guess I'm just a mean old man.
[00:27:39.360 --> 00:27:42.600]   I really would have loved to have seen a cheese grater Mac,
[00:27:42.600 --> 00:27:44.600]   doesn't really take, doesn't keep them
[00:27:44.600 --> 00:27:49.240]   from doing this Mac Pro, but 2019 is six years
[00:27:49.240 --> 00:27:51.520]   after the release of the last Mac Pro,
[00:27:51.520 --> 00:27:54.080]   that's all, for any technology company,
[00:27:54.080 --> 00:27:58.800]   six years between models is a really long time.
[00:27:58.800 --> 00:28:01.840]   It's more than a lifetime, it's an eternity.
[00:28:01.840 --> 00:28:05.800]   And meanwhile, I have to also point out Apple
[00:28:05.800 --> 00:28:08.600]   that your competitors across the aisle
[00:28:08.600 --> 00:28:13.600]   are pumping out new form factors, models and ideas monthly.
[00:28:13.600 --> 00:28:17.280]   And there's plenty of companies like my company
[00:28:17.280 --> 00:28:19.560]   that finally just gave up and said,
[00:28:19.560 --> 00:28:21.360]   well, I guess we'll get a Dell.
[00:28:21.360 --> 00:28:24.560]   - Yeah, that's one thing that--
[00:28:24.560 --> 00:28:26.400]   - Just because they're pushing the monthly
[00:28:26.400 --> 00:28:28.360]   doesn't mean that's the best thing.
[00:28:28.360 --> 00:28:31.120]   - Well, this is a pretty good thing.
[00:28:31.120 --> 00:28:34.440]   But I'm just saying there's stuff out there
[00:28:34.440 --> 00:28:36.600]   that is pretty impressive.
[00:28:36.600 --> 00:28:39.440]   And the variety of the ecosystem
[00:28:39.440 --> 00:28:41.000]   and the breadth of the ecosystem
[00:28:41.000 --> 00:28:42.520]   and the windows scene is something
[00:28:42.520 --> 00:28:46.400]   that is directly in competition with Apple.
[00:28:46.400 --> 00:28:49.240]   Now, I understand Apple likes to work in a vacuum.
[00:28:49.240 --> 00:28:50.360]   In fact, it's really encouraging
[00:28:50.360 --> 00:28:52.200]   that they're bringing pros in.
[00:28:52.200 --> 00:28:53.800]   Although I doubt this is anything new,
[00:28:53.800 --> 00:28:55.360]   I'm sure that they've done this all along.
[00:28:55.360 --> 00:28:57.400]   But the--
[00:28:57.400 --> 00:28:59.400]   - It's good that they're asking.
[00:28:59.400 --> 00:29:02.000]   - Yeah, I haven't heard of a program
[00:29:02.000 --> 00:29:05.160]   that's this intense.
[00:29:05.160 --> 00:29:08.320]   Again, such as convincing somebody to please stop working
[00:29:08.320 --> 00:29:11.200]   in your business, become an employee of Apple.
[00:29:11.200 --> 00:29:12.640]   Again, just basically two people.
[00:29:12.640 --> 00:29:17.040]   We're building our own leopard and gorilla pens.
[00:29:17.040 --> 00:29:18.720]   We're building our own captive zoo.
[00:29:18.720 --> 00:29:20.600]   We just want to be able to watch you
[00:29:20.600 --> 00:29:23.200]   cavort and gamble on romp and play
[00:29:23.200 --> 00:29:25.280]   and take notes on your behavior.
[00:29:25.280 --> 00:29:28.880]   But these are both really good points.
[00:29:28.880 --> 00:29:31.240]   It's just that there's no right or wrong
[00:29:31.240 --> 00:29:33.240]   between the way that the windows ecosystem works
[00:29:33.240 --> 00:29:35.160]   and the way that the Mac ecosystem works.
[00:29:35.160 --> 00:29:39.160]   The thing is, if you buy Windows hardware,
[00:29:39.160 --> 00:29:40.520]   there's an excellent chance you're going to buy
[00:29:40.520 --> 00:29:41.920]   a piece of crap that was just pushed out
[00:29:41.920 --> 00:29:45.600]   because somebody in some room, some are thought that,
[00:29:45.600 --> 00:29:47.360]   hey, there's a market we're not attaching.
[00:29:47.360 --> 00:29:52.360]   So if we just make the model 238, the model 239/B,
[00:29:52.360 --> 00:29:54.240]   it doesn't--
[00:29:54.240 --> 00:29:56.080]   - Well, if that's how you feel, you can then go buy--
[00:29:56.080 --> 00:29:57.240]   - But then go buy all the pieces and make your own
[00:29:57.240 --> 00:29:59.520]   Windows machine that is a killer
[00:29:59.520 --> 00:30:01.840]   because you can do that in the Windows side of pieces.
[00:30:01.840 --> 00:30:03.320]   - But most people aren't going to do that.
[00:30:03.320 --> 00:30:04.360]   - But at the same, lots of people do that.
[00:30:04.360 --> 00:30:05.760]   In fact, most pros do that.
[00:30:05.760 --> 00:30:09.640]   - But at the same time, Apple will not be able to sell you
[00:30:09.640 --> 00:30:11.720]   something that is exactly what you want.
[00:30:11.720 --> 00:30:14.200]   There's going to have to be, we make model A,
[00:30:14.200 --> 00:30:15.320]   we make model B.
[00:30:15.320 --> 00:30:16.520]   If you don't like either one of these,
[00:30:16.520 --> 00:30:17.720]   you're going to have to go elsewhere
[00:30:17.720 --> 00:30:19.080]   or you're going to have to, again,
[00:30:19.080 --> 00:30:20.880]   suffer a little as you adapt what you want.
[00:30:20.880 --> 00:30:22.560]   But you will always be getting stuff
[00:30:22.560 --> 00:30:24.600]   that at least has been extremely well thought out
[00:30:24.600 --> 00:30:27.080]   and is worth betting half of the product line up.
[00:30:27.080 --> 00:30:28.360]   So you just have to--
[00:30:28.360 --> 00:30:29.320]   - There's no right or wrong there.
[00:30:29.320 --> 00:30:32.400]   - I agree that that was the burnish on the Apple
[00:30:32.400 --> 00:30:35.000]   for a long time and I think it's starting to fade.
[00:30:35.000 --> 00:30:38.600]   This also begs the question, well, what about that rumor?
[00:30:38.600 --> 00:30:39.880]   And admittedly, that's just a rumor
[00:30:39.880 --> 00:30:43.440]   that Apple's abandoning Intel the year after they put this
[00:30:43.440 --> 00:30:44.280]   thing out.
[00:30:44.280 --> 00:30:45.880]   How does that affect this?
[00:30:45.880 --> 00:30:48.640]   - Isn't that interesting?
[00:30:48.640 --> 00:30:53.640]   I still don't think that they'll be able to make a platform
[00:30:53.640 --> 00:30:58.640]   that is as powerful as even the iMac Pro that soon.
[00:30:58.640 --> 00:30:59.760]   - Not long, believe it.
[00:30:59.760 --> 00:31:00.600]   Well, maybe they can.
[00:31:00.600 --> 00:31:02.240]   I don't know, they do some pretty good stuff.
[00:31:02.240 --> 00:31:04.080]   It's not just building the hardware.
[00:31:04.080 --> 00:31:07.400]   It's also getting every single developer on board,
[00:31:07.400 --> 00:31:09.360]   making sure, I just don't see it.
[00:31:09.360 --> 00:31:10.200]   I'm not saying it's not--
[00:31:10.200 --> 00:31:13.760]   - Do you think it's possible that this development really is,
[00:31:13.760 --> 00:31:15.960]   and Matthew wouldn't necessarily have known,
[00:31:15.960 --> 00:31:18.600]   not on an Intel-based Mac Pro,
[00:31:18.600 --> 00:31:21.920]   but on an A15 or whatever Mac Pro?
[00:31:21.920 --> 00:31:22.760]   - Maybe.
[00:31:22.760 --> 00:31:24.720]   - It could be.
[00:31:24.720 --> 00:31:25.960]   - Could be, couldn't it?
[00:31:25.960 --> 00:31:27.320]   I mean, this could be--
[00:31:27.320 --> 00:31:29.760]   - Well, that might be the real reason why they didn't do
[00:31:29.760 --> 00:31:32.520]   anything today because it would have been an Intel thing,
[00:31:32.520 --> 00:31:35.400]   a cheese grater update would have been an Intel thing.
[00:31:35.400 --> 00:31:40.000]   Let's get the A chips going.
[00:31:40.000 --> 00:31:42.760]   And maybe what they're really saying is that really,
[00:31:42.760 --> 00:31:45.080]   the gaining factor was that,
[00:31:45.080 --> 00:31:47.200]   was we need a new Platt chip platform.
[00:31:47.200 --> 00:31:50.160]   It's gonna be ready in 2019 or 2020.
[00:31:50.160 --> 00:31:52.480]   Let's make the new Mac Pro be based on that.
[00:31:52.480 --> 00:31:54.200]   That would be very interesting.
[00:31:54.200 --> 00:31:57.240]   And would it kind of explain this long gap?
[00:31:57.240 --> 00:31:59.960]   - When I wrote about this,
[00:31:59.960 --> 00:32:01.440]   about that rumor a couple of weeks ago,
[00:32:01.440 --> 00:32:04.920]   I did say that I could easily believe Apple's seeing this
[00:32:04.920 --> 00:32:09.240]   as an opportunity to totally redo the Mac operating system too.
[00:32:09.240 --> 00:32:12.920]   It has the UI has been kind of frumpy
[00:32:12.920 --> 00:32:14.880]   over the past five or six years.
[00:32:14.880 --> 00:32:16.840]   We're not seeing this sort of evolution
[00:32:16.840 --> 00:32:19.640]   other than bringing a few cut and paste features
[00:32:19.640 --> 00:32:21.200]   from iOS and to Mac OS.
[00:32:21.200 --> 00:32:25.600]   And so if they're gonna go to an entirely new CPU architecture,
[00:32:25.600 --> 00:32:27.120]   this would be a great time for them to say,
[00:32:27.120 --> 00:32:28.240]   okay, we're just gonna,
[00:32:28.240 --> 00:32:30.160]   we're just gonna not necessarily start
[00:32:30.160 --> 00:32:31.320]   from scratch with a Mac,
[00:32:31.320 --> 00:32:33.920]   but we're gonna say that every single possible idea
[00:32:33.920 --> 00:32:35.680]   of things to change is now open.
[00:32:35.680 --> 00:32:36.880]   And so if they're,
[00:32:36.880 --> 00:32:38.840]   and that would be consistent with them saying,
[00:32:38.840 --> 00:32:40.960]   we're just gonna watch people use our products
[00:32:40.960 --> 00:32:43.000]   and build an operating system in a UI
[00:32:43.000 --> 00:32:44.640]   that suits the people that we're watching
[00:32:44.640 --> 00:32:47.400]   as opposed to updating what we've been essentially doing
[00:32:47.400 --> 00:32:48.920]   since Mac OS 9.
[00:32:48.920 --> 00:32:51.720]   What is not clear, and I wish Matthew had spoken to this,
[00:32:51.720 --> 00:32:54.000]   is whether this was a Matthew's initiative,
[00:32:54.000 --> 00:32:55.360]   whether he reached out and said,
[00:32:55.360 --> 00:32:56.760]   hey, it was a year ago,
[00:32:56.760 --> 00:32:59.120]   let's see what you're up to and Apple said, oh, okay.
[00:32:59.120 --> 00:33:04.120]   Or whether Apple invited him out of nowhere,
[00:33:04.120 --> 00:33:06.840]   hey, it's time to show you this.
[00:33:06.840 --> 00:33:09.240]   'Cause in the first case, I would say, oh, this is great.
[00:33:09.240 --> 00:33:12.240]   Matthew got some additional information
[00:33:12.240 --> 00:33:14.080]   that really is encouraging.
[00:33:14.080 --> 00:33:16.760]   And the second case, if it's Apple reached out and said,
[00:33:16.760 --> 00:33:18.040]   hey, come on in, let's show you.
[00:33:18.040 --> 00:33:21.080]   It feels a little more like a dog and pony show.
[00:33:21.080 --> 00:33:23.040]   It's on Apple's terms and on Apple's timing.
[00:33:23.040 --> 00:33:25.560]   So that's not clear and it makes it a little bit difficult
[00:33:25.560 --> 00:33:28.200]   to really judge this information.
[00:33:28.200 --> 00:33:30.880]   - Well, if we know anything from the way Apple works,
[00:33:30.880 --> 00:33:34.480]   it's most likely it was Apple's terms and Apple's conditions.
[00:33:34.480 --> 00:33:35.840]   - And Apple thought of this and said,
[00:33:35.840 --> 00:33:38.360]   let's bring Matthew back, yeah.
[00:33:38.360 --> 00:33:39.200]   - Yeah.
[00:33:39.200 --> 00:33:40.280]   - I wish at Matthew it said something.
[00:33:40.280 --> 00:33:42.720]   And the last thing at the end of the article that he says,
[00:33:42.720 --> 00:33:45.720]   and I, you know, he's the guy after all,
[00:33:45.720 --> 00:33:47.440]   who got the scoop, who got the story,
[00:33:47.440 --> 00:33:50.520]   and it's his impressions that are probably more important
[00:33:50.520 --> 00:33:52.000]   than somebody remotely.
[00:33:52.000 --> 00:33:54.000]   But the last thing he says,
[00:33:54.000 --> 00:33:56.240]   and I just apparently closed the article
[00:33:56.240 --> 00:33:58.600]   'cause I wanted to read his last thoughts.
[00:33:58.600 --> 00:33:59.920]   Here we go.
[00:33:59.920 --> 00:34:00.760]   Oh, I see.
[00:34:00.760 --> 00:34:04.400]   This is one of those infinitely scrolling pages.
[00:34:04.400 --> 00:34:06.200]   - Don't go too far.
[00:34:06.200 --> 00:34:09.960]   - I scrolled, I apparently reached the end of the internet
[00:34:09.960 --> 00:34:11.240]   by scrolling too far.
[00:34:11.240 --> 00:34:12.400]   (laughing)
[00:34:12.400 --> 00:34:13.880]   And let me see if I can do it.
[00:34:13.880 --> 00:34:15.680]   - Can you show me where the end of the internet is?
[00:34:15.680 --> 00:34:17.240]   I was left. - Oh, far, far away.
[00:34:17.480 --> 00:34:19.240]   - As depressing as it has been
[00:34:19.240 --> 00:34:20.800]   to see professionals believe that Apple
[00:34:20.800 --> 00:34:21.880]   was ready to give them up,
[00:34:21.880 --> 00:34:25.480]   I find this an interesting and exciting thing to watch.
[00:34:25.480 --> 00:34:28.640]   It is very, very hard for a company like Apple, Matthew writes,
[00:34:28.640 --> 00:34:32.200]   whose reputation is built on myth building
[00:34:32.200 --> 00:34:34.320]   to admit that it was mistaken.
[00:34:34.320 --> 00:34:35.240]   That's what it did last year.
[00:34:35.240 --> 00:34:37.760]   And it's even harder to then change course
[00:34:37.760 --> 00:34:40.480]   with billions of dollars worth of revenue at stake.
[00:34:40.480 --> 00:34:43.840]   I'm sure it gives a bunch of people at Apple heartburn,
[00:34:43.840 --> 00:34:45.680]   but it's fascinating for me
[00:34:45.680 --> 00:34:47.880]   because I don't have to pull it off.
[00:34:47.880 --> 00:34:48.880]   (laughing)
[00:34:48.880 --> 00:34:51.240]   That's a good way to describe the challenge
[00:34:51.240 --> 00:34:52.600]   it's facing Apple right now.
[00:34:52.600 --> 00:34:56.880]   And I think that, you know, we'll know more in June
[00:34:56.880 --> 00:34:59.840]   at WWDC, we'll know more next year
[00:34:59.840 --> 00:35:02.800]   if this Mac Pro comes out next year, we'll know more.
[00:35:02.800 --> 00:35:06.880]   I'd be fascinated and actually really encouraged
[00:35:06.880 --> 00:35:09.680]   to see Apple do something that isn't Intel,
[00:35:09.680 --> 00:35:13.800]   that really plays on its obvious expertise
[00:35:13.800 --> 00:35:17.680]   and chip design to make something that's better than Intel.
[00:35:17.680 --> 00:35:19.840]   Apple really has been let down by Intel, really,
[00:35:19.840 --> 00:35:22.560]   going back to my comments about the 2013
[00:35:22.560 --> 00:35:25.840]   or Mac Pro not being particularly out of date,
[00:35:25.840 --> 00:35:28.440]   at least in terms of the Intel chips.
[00:35:28.440 --> 00:35:30.200]   - I don't know, scheduling, I think.
[00:35:30.200 --> 00:35:31.800]   - Go ahead, Jim.
[00:35:31.800 --> 00:35:32.920]   - I'd love to see it.
[00:35:32.920 --> 00:35:33.760]   - Yeah.
[00:35:33.760 --> 00:35:37.720]   - But, you know, there are a lot of concerns and worries.
[00:35:37.720 --> 00:35:41.760]   You know, the biggest among them is the developers.
[00:35:41.760 --> 00:35:44.720]   Is there gonna be a layer where, you know,
[00:35:44.720 --> 00:35:49.400]   current apps can continue to work with this chip?
[00:35:49.400 --> 00:35:50.920]   Can Apple pull that off again?
[00:35:50.920 --> 00:35:52.000]   They did it once.
[00:35:52.000 --> 00:35:52.920]   - Right.
[00:35:52.920 --> 00:35:57.360]   - But it did take some time to get developers over.
[00:35:57.360 --> 00:36:00.280]   And I mean, that transition could hurt.
[00:36:00.280 --> 00:36:01.800]   - That's why I think June will be interesting.
[00:36:01.800 --> 00:36:03.920]   I think they'll, don't you think they'll telegraph something?
[00:36:03.920 --> 00:36:07.520]   They need to get developers in line somehow.
[00:36:07.520 --> 00:36:09.480]   - It depends on how far out they are.
[00:36:09.480 --> 00:36:11.200]   I mean, if they're a couple of years out,
[00:36:11.200 --> 00:36:12.320]   no, I don't think they will.
[00:36:12.320 --> 00:36:14.160]   - Yeah, it'd be too soon.
[00:36:14.160 --> 00:36:15.560]   We're gonna take a break, by the way,
[00:36:15.560 --> 00:36:17.760]   as many of you know those watching live,
[00:36:17.760 --> 00:36:20.320]   Mark Zuckerberg is testifying the first of two days
[00:36:20.320 --> 00:36:21.720]   of testimony before Congress.
[00:36:21.720 --> 00:36:23.200]   I have a little clip from that here.
[00:36:23.200 --> 00:36:24.040]   Let me just...
[00:36:24.040 --> 00:36:26.840]   - Mr. Zuckerberg, do I have your full attention?
[00:36:26.840 --> 00:36:28.920]   - No.
[00:36:28.920 --> 00:36:31.800]   - Do you think I deserve it?
[00:36:31.800 --> 00:36:32.800]   - What?
[00:36:32.800 --> 00:36:35.120]   - Do you think I deserve your full attention?
[00:36:35.120 --> 00:36:38.480]   - I had to swear on oath before we began this deposition
[00:36:38.480 --> 00:36:39.600]   and I don't wanna purge it myself.
[00:36:39.600 --> 00:36:41.800]   So I have a legal obligation to say no.
[00:36:41.800 --> 00:36:43.280]   - We'll come back with more in just a bit.
[00:36:43.280 --> 00:36:44.400]   Great panel.
[00:36:44.400 --> 00:36:45.760]   Really nice to have you here, Laurie.
[00:36:45.760 --> 00:36:47.440]   You feeling a little more comfortable now?
[00:36:47.440 --> 00:36:48.280]   - Yes, thank you.
[00:36:48.280 --> 00:36:49.440]   - You fit right in.
[00:36:49.440 --> 00:36:50.520]   You fit right in.
[00:36:50.520 --> 00:36:52.160]   Laurie Gill is deputy managing editor.
[00:36:52.160 --> 00:36:55.120]   I'm more, you hear on the I'more show, of course,
[00:36:55.120 --> 00:36:57.520]   and a alcoholic on the Twitter.
[00:36:57.520 --> 00:37:01.320]   Jim Dowerable from the loop, loopinsight.com.
[00:37:01.320 --> 00:37:04.160]   The isestimable beard.
[00:37:04.160 --> 00:37:05.520]   Always great to have you on.
[00:37:05.520 --> 00:37:07.720]   And of course, Andy and Naco,
[00:37:07.720 --> 00:37:09.800]   star of our show from a not code.
[00:37:09.800 --> 00:37:10.640]   - Oh, okay.
[00:37:10.640 --> 00:37:11.920]   - Renee is taking the day off
[00:37:11.920 --> 00:37:14.800]   because he's going to get briefed on red iPhones.
[00:37:14.800 --> 00:37:17.120]   Wow, what a life.
[00:37:17.120 --> 00:37:20.560]   He's not, Laurie, he didn't fly to Cupertino for that, I hope.
[00:37:20.560 --> 00:37:24.160]   - No, this time I think he went to New York.
[00:37:24.160 --> 00:37:25.080]   - That's ridiculous.
[00:37:25.080 --> 00:37:25.920]   What are they gonna say?
[00:37:25.920 --> 00:37:27.560]   It's red.
[00:37:27.560 --> 00:37:29.360]   - He came to California last week.
[00:37:29.360 --> 00:37:30.200]   - I know.
[00:37:30.200 --> 00:37:31.880]   - And was in Chicago a few days before that.
[00:37:31.880 --> 00:37:36.800]   So he has not been home for weeks now.
[00:37:36.800 --> 00:37:39.280]   And he'll be back out again for WWDC
[00:37:39.280 --> 00:37:41.280]   and maybe even before that, so.
[00:37:41.280 --> 00:37:43.960]   - It's not easy covering Apple these days.
[00:37:43.960 --> 00:37:45.480]   - It's just too much.
[00:37:45.480 --> 00:37:47.960]   - You would think one company, it'd be easy, right?
[00:37:47.960 --> 00:37:49.600]   How are it gonna be?
[00:37:49.600 --> 00:37:51.560]   - Yeah, no, I can't imagine.
[00:37:51.560 --> 00:37:55.640]   I wake up in the morning and Renee will have given me
[00:37:55.640 --> 00:37:57.960]   a notification of some kind of something coming up
[00:37:57.960 --> 00:37:59.680]   and I'm just mad at Apple.
[00:37:59.680 --> 00:38:01.520]   (laughing)
[00:38:01.520 --> 00:38:05.360]   - I think honestly, Renee next time is gonna cover IBM.
[00:38:05.360 --> 00:38:06.600]   It's a lot quieter.
[00:38:07.440 --> 00:38:08.880]   It's a lot calmer, choose IBM.
[00:38:08.880 --> 00:38:10.480]   - Yeah, he can actually take a vacation.
[00:38:10.480 --> 00:38:12.320]   - Yeah, for years.
[00:38:12.320 --> 00:38:14.400]   Our show today brought to you by Rocket Mortgage
[00:38:14.400 --> 00:38:15.760]   from Quick and Loans.
[00:38:15.760 --> 00:38:17.240]   Quick and Loans, number one lender in the country.
[00:38:17.240 --> 00:38:20.400]   Now, always number one in your hearts
[00:38:20.400 --> 00:38:23.200]   because of course, number one in customer satisfaction
[00:38:23.200 --> 00:38:26.160]   year after year according to JD Power.
[00:38:26.160 --> 00:38:28.080]   But number one in volume two,
[00:38:28.080 --> 00:38:29.720]   they've become the biggest lender in the nation.
[00:38:29.720 --> 00:38:32.920]   And I have to credit a little bit of this to Rocket Mortgage.
[00:38:32.920 --> 00:38:34.880]   Quick and Loans realized a couple of years ago
[00:38:34.880 --> 00:38:36.720]   that the mortgage experience,
[00:38:36.720 --> 00:38:37.960]   the mortgage approval process
[00:38:37.960 --> 00:38:40.160]   really wasn't keeping up with the times.
[00:38:40.160 --> 00:38:42.560]   It was straight out of the 19th century
[00:38:42.560 --> 00:38:45.080]   and going to a bank, filling out a long application,
[00:38:45.080 --> 00:38:46.680]   going to the attic,
[00:38:46.680 --> 00:38:50.840]   trying to find your pay stubs from 2012, stuff like that.
[00:38:50.840 --> 00:38:53.520]   They wanted a client-focused technological
[00:38:53.520 --> 00:38:55.180]   reinvention of the whole process
[00:38:55.180 --> 00:38:57.960]   and they created Rocket Mortgage,
[00:38:57.960 --> 00:39:01.600]   an entirely online mortgage approval process.
[00:39:01.600 --> 00:39:02.640]   You do the whole thing on your phone.
[00:39:02.640 --> 00:39:03.720]   You could, it's fast too.
[00:39:03.720 --> 00:39:04.560]   You could do it.
[00:39:04.560 --> 00:39:07.480]   It's so fast you could go to an open house,
[00:39:07.480 --> 00:39:10.480]   say, "Hey, never before having thought this,
[00:39:10.480 --> 00:39:12.800]   "we should buy this house."
[00:39:12.800 --> 00:39:14.520]   Go to Rocket Mortgage.
[00:39:14.520 --> 00:39:17.320]   It's Rocket Mortgage.com/MacBring.
[00:39:17.320 --> 00:39:18.760]   And type in a few,
[00:39:18.760 --> 00:39:20.920]   they ask you a couple of things you know already,
[00:39:20.920 --> 00:39:23.320]   your name, address, phone number, birthday.
[00:39:23.320 --> 00:39:25.280]   Then because they have relationships
[00:39:25.280 --> 00:39:26.440]   with all the financial institutions,
[00:39:26.440 --> 00:39:28.160]   they say, "Can we go get some information?"
[00:39:28.160 --> 00:39:29.680]   You say, "Yes."
[00:39:29.680 --> 00:39:32.560]   They crush the numbers based on income assets and credits.
[00:39:32.560 --> 00:39:34.760]   They analyze all the home loan options
[00:39:34.760 --> 00:39:39.040]   for which you qualify and then they offer you.
[00:39:39.040 --> 00:39:42.160]   Those home loan options, you choose the rate,
[00:39:42.160 --> 00:39:44.360]   you choose the term, you choose the down payment,
[00:39:44.360 --> 00:39:45.880]   you're approved.
[00:39:45.880 --> 00:39:48.280]   And that entire process,
[00:39:48.280 --> 00:39:49.760]   you didn't have to get up from the couch,
[00:39:49.760 --> 00:39:51.440]   you didn't have to leave the open house,
[00:39:51.440 --> 00:39:53.000]   took less than 10 minutes.
[00:39:53.000 --> 00:39:55.880]   Rocket Mortgage.com/MacBring.
[00:39:55.880 --> 00:39:58.440]   You'll apply simply, couldn't be simpler.
[00:39:58.440 --> 00:39:59.880]   You'll understand every step of the way
[00:39:59.880 --> 00:40:01.160]   exactly what's happening,
[00:40:01.160 --> 00:40:02.400]   they're totally transparent.
[00:40:02.400 --> 00:40:05.480]   And then you'll mortgage with confidence, rocket mortgage.
[00:40:05.480 --> 00:40:08.520]   To get started, go to rocketmortgage.com/MacBring.
[00:40:08.520 --> 00:40:11.640]   Rocketmortgage.com/MacBring.
[00:40:11.640 --> 00:40:12.400]   This is the only way to do it.
[00:40:12.400 --> 00:40:14.400]   Reef-I's too, by the way, with interest rates going up.
[00:40:14.400 --> 00:40:16.160]   This is a good time to check them out
[00:40:16.160 --> 00:40:18.560]   for their reef-I rates.
[00:40:18.560 --> 00:40:22.120]   Get started now and you'll be ready when that house hits you.
[00:40:22.120 --> 00:40:25.040]   Rocketmortgage.com/MacBring.
[00:40:25.040 --> 00:40:27.640]   Equal housing, lender licensed in all 50 states
[00:40:27.640 --> 00:40:30.280]   and MLS consumer access.org number 30, 30.
[00:40:31.280 --> 00:40:32.360]   I hope the house doesn't hit you.
[00:40:32.360 --> 00:40:34.000]   That's straight out of the Wizard of Oz, isn't it?
[00:40:34.000 --> 00:40:38.840]   Rocket Mortgage.com/MacBring.
[00:40:38.840 --> 00:40:43.920]   How is Zuck doing in the testimony?
[00:40:43.920 --> 00:40:46.640]   He's got a necktie on, that's good.
[00:40:46.640 --> 00:40:50.720]   Have they been spanking him?
[00:40:50.720 --> 00:40:54.480]   Seriously, I think that's kind of,
[00:40:54.480 --> 00:40:56.440]   if you read the name of the hearing,
[00:40:56.440 --> 00:40:59.600]   it sounds like they're kind of going after him.
[00:40:59.600 --> 00:41:02.000]   That seems like a totally different show.
[00:41:02.000 --> 00:41:04.800]   It doesn't seem like the Apple show, does it?
[00:41:04.800 --> 00:41:08.600]   Actually, this, well, it is the Apple show in one respect, Jim.
[00:41:08.600 --> 00:41:11.000]   All of this attention, and boy, every day,
[00:41:11.000 --> 00:41:14.480]   there's more news about how Facebook leaked information.
[00:41:14.480 --> 00:41:19.040]   And I just saw a story that said Cambridge Analytica,
[00:41:19.040 --> 00:41:20.760]   only a few hundred, a handful of people
[00:41:20.760 --> 00:41:22.560]   took their quiz in Australia,
[00:41:22.560 --> 00:41:24.800]   but they got information in almost the whole country
[00:41:24.800 --> 00:41:27.800]   because of the way Facebook handled it.
[00:41:27.800 --> 00:41:30.320]   That kind of thing just really helps Apple.
[00:41:30.320 --> 00:41:33.440]   It helps Apple's privacy story, right, Jim?
[00:41:33.440 --> 00:41:34.680]   Sure, sure it does.
[00:41:34.680 --> 00:41:39.680]   And Apple's been very clear on how they feel about privacy
[00:41:39.680 --> 00:41:41.680]   for years.
[00:41:41.680 --> 00:41:43.920]   This isn't anything new that came up
[00:41:43.920 --> 00:41:46.880]   because of how Facebook handled this.
[00:41:46.880 --> 00:41:50.960]   This is an advantage that Apple has in the market.
[00:41:50.960 --> 00:41:52.200]   Although one could say,
[00:41:52.200 --> 00:41:54.200]   we were talking about this on Sunday on Twitch,
[00:41:54.200 --> 00:41:56.920]   one could say that Apple kind of stumbled
[00:41:56.920 --> 00:42:00.040]   into this because iAds didn't work,
[00:42:00.040 --> 00:42:03.560]   so they really didn't need the advertising information.
[00:42:03.560 --> 00:42:06.800]   Ping and e-world, whatever the Apple,
[00:42:06.800 --> 00:42:08.680]   other Apple social networks, they've tried,
[00:42:08.680 --> 00:42:10.080]   none of them were successes,
[00:42:10.080 --> 00:42:13.080]   so it never really, it never was really on the table
[00:42:13.080 --> 00:42:15.440]   for Apple to steal your information.
[00:42:15.440 --> 00:42:18.440]   So might as well make a virtue out of it and say,
[00:42:18.440 --> 00:42:20.280]   oh, we care about your privacy.
[00:42:20.280 --> 00:42:21.120]   Certainly--
[00:42:21.120 --> 00:42:21.920]   That's not necessarily true.
[00:42:21.920 --> 00:42:25.880]   They could have looked at your iMessages.
[00:42:25.880 --> 00:42:29.680]   They could have made the operating system more open
[00:42:29.680 --> 00:42:32.640]   so that they could track what you do
[00:42:32.640 --> 00:42:35.560]   and where you go and things that you say,
[00:42:35.560 --> 00:42:37.720]   but all of that stuff is closed off.
[00:42:37.720 --> 00:42:40.960]   So they had lots of opportunities,
[00:42:40.960 --> 00:42:45.960]   not just with iAds, to harvest data from its users
[00:42:45.960 --> 00:42:48.800]   and it chose not to.
[00:42:48.800 --> 00:42:50.920]   And I think that was the right decision.
[00:42:50.920 --> 00:42:52.040]   Yeah.
[00:42:52.040 --> 00:42:53.640]   In fact, somebody's in the chat was pointing out
[00:42:53.640 --> 00:42:57.400]   that even in 2010,
[00:42:57.400 --> 00:43:00.200]   Jobs was concerned about Facebook's business model
[00:43:00.200 --> 00:43:01.840]   and worried about privacy issues.
[00:43:01.840 --> 00:43:05.960]   This is from CNN at the Wall Street Journal Conference.
[00:43:05.960 --> 00:43:08.920]   It's a video of Jobs discussing privacy issues.
[00:43:08.920 --> 00:43:12.840]   Privacy, and this is 2010, it's eight years ago.
[00:43:12.840 --> 00:43:14.840]   Privacy, as Jobs said, means people know
[00:43:14.840 --> 00:43:17.720]   what they're signing up for in plain English
[00:43:17.720 --> 00:43:20.360]   and repeatedly, I believe people are smart
[00:43:20.360 --> 00:43:22.360]   and some people want to share more data than other people do,
[00:43:22.360 --> 00:43:24.720]   but ask them, ask them every time.
[00:43:24.720 --> 00:43:26.720]   Make them tell you to stop asking them
[00:43:26.720 --> 00:43:28.480]   if they get tired of your asking them.
[00:43:28.480 --> 00:43:30.480]   Let them know precisely what you're going to do
[00:43:30.480 --> 00:43:31.440]   with their data.
[00:43:31.440 --> 00:43:34.000]   I tell you what, that's exactly what Facebook should have done.
[00:43:34.000 --> 00:43:35.800]   And it's what Apple does to this day.
[00:43:35.800 --> 00:43:38.520]   I was talking about this with my wife Lisa
[00:43:38.520 --> 00:43:40.680]   because we were talking about how location information
[00:43:40.680 --> 00:43:44.680]   could really leak stuff that you don't even think about.
[00:43:44.680 --> 00:43:47.520]   There was a story last Thanksgiving
[00:43:47.520 --> 00:43:50.680]   about how families with different political opinions
[00:43:50.680 --> 00:43:52.160]   were getting together for Thanksgiving
[00:43:52.160 --> 00:43:54.120]   and I was wondering, well, how do they know that?
[00:43:54.120 --> 00:43:57.560]   And it turns out the company that mined this data
[00:43:57.560 --> 00:43:58.920]   did it from people's smartphones.
[00:43:58.920 --> 00:44:01.480]   They would see when you were with a family member
[00:44:01.480 --> 00:44:04.840]   on Thanksgiving Day and then based on the information
[00:44:04.840 --> 00:44:07.280]   from Facebook about what political affiliation
[00:44:07.280 --> 00:44:10.480]   everybody in the household had, they could write this article
[00:44:10.480 --> 00:44:13.320]   and all this was information leaked out of Facebook
[00:44:13.320 --> 00:44:14.880]   and the phone.
[00:44:14.880 --> 00:44:16.440]   And we were talking about it and I said,
[00:44:16.440 --> 00:44:17.720]   that's why you should use an iPhone
[00:44:17.720 --> 00:44:20.840]   because even after you give an Apple permission,
[00:44:20.840 --> 00:44:23.640]   the iPhone will ask you again,
[00:44:23.640 --> 00:44:27.040]   "Hey, you know this app still is tracking you.
[00:44:27.040 --> 00:44:28.120]   "Do you want that?"
[00:44:28.120 --> 00:44:30.840]   Plus apps aren't allowed to share information with other apps.
[00:44:30.840 --> 00:44:34.280]   I mean, I think Apple has it right and they've done it right.
[00:44:34.280 --> 00:44:37.160]   Whether they agree or not. - I think that there's something
[00:44:37.160 --> 00:44:40.920]   to be said for this sort of shared data
[00:44:40.920 --> 00:44:43.200]   that you're talking about that is the most dangerous
[00:44:43.200 --> 00:44:46.400]   that individually companies may not be able to collect
[00:44:46.400 --> 00:44:50.480]   enough data about you, that kind of moves into creepy,
[00:44:50.480 --> 00:44:54.840]   territory, but once one company shares that data
[00:44:54.840 --> 00:44:56.640]   with another company and shares that data
[00:44:56.640 --> 00:44:59.520]   with another company, now you're looking at the ability
[00:44:59.520 --> 00:45:03.440]   to recreate your entire life right in front of your eyes
[00:45:03.440 --> 00:45:05.360]   and then we're getting into the matrix thing here.
[00:45:05.360 --> 00:45:09.840]   Where are we doing things because the internet tells us
[00:45:09.840 --> 00:45:12.280]   to do them or have we made these decisions on our own
[00:45:12.280 --> 00:45:15.040]   and it kind of puts you into a cycle that goes deeper
[00:45:15.040 --> 00:45:16.840]   and deeper when all this information about you
[00:45:16.840 --> 00:45:19.040]   is being shared and then sold back to you
[00:45:19.040 --> 00:45:20.120]   in one form or another.
[00:45:20.120 --> 00:45:20.960]   - Yeah.
[00:45:20.960 --> 00:45:26.000]   - I just, I really do think that we need federal laws
[00:45:26.000 --> 00:45:29.440]   similar to what's happening in the EU right now
[00:45:29.440 --> 00:45:33.320]   that just protects personal data from being used in a way
[00:45:33.320 --> 00:45:36.360]   that the user never explicitly approved of.
[00:45:36.360 --> 00:45:39.000]   It's just insane when you realize that you live
[00:45:39.000 --> 00:45:41.800]   in a world in which there is actually a profitable
[00:45:41.800 --> 00:45:44.800]   business model to just simply equip cars
[00:45:44.800 --> 00:45:47.760]   with license plate scanners and simply have them drive
[00:45:47.760 --> 00:45:51.520]   around parking lots and drive around residential streets
[00:45:51.520 --> 00:45:54.520]   just to collect information on what cars are where
[00:45:54.520 --> 00:45:58.440]   at what time and then that bit of information is so hugely
[00:45:58.440 --> 00:46:01.000]   valuable that it's worth putting those cars on the road
[00:46:01.000 --> 00:46:03.520]   and paying people to drive round and round and round.
[00:46:03.520 --> 00:46:07.200]   It's insane to think that the next time I have a car
[00:46:07.200 --> 00:46:10.560]   when the first user added options is going to be a little
[00:46:10.560 --> 00:46:13.440]   curtain that I deploy every time I park it to make sure
[00:46:13.440 --> 00:46:16.800]   you can't read my license tags just by simply driving past it.
[00:46:16.800 --> 00:46:17.640]   We need protection.
[00:46:17.640 --> 00:46:22.640]   - And it's more than just that we need to be able to say
[00:46:22.640 --> 00:46:26.640]   what people can and can't do with our data.
[00:46:26.640 --> 00:46:29.240]   It's that we need to know what they're doing.
[00:46:29.240 --> 00:46:32.760]   That's the biggest problem is that these companies,
[00:46:32.760 --> 00:46:36.360]   they're gleaning all of this information from us
[00:46:36.360 --> 00:46:39.160]   and they're not telling us what they're taking from us.
[00:46:39.160 --> 00:46:42.400]   And I think the transparency of everything that you're
[00:46:42.400 --> 00:46:45.840]   taking from me, I should be able to easily find out about
[00:46:45.840 --> 00:46:49.280]   and decide for myself whether or not I want to continue
[00:46:49.280 --> 00:46:50.520]   to let that happen.
[00:46:50.520 --> 00:46:54.440]   Just like maybe I'm willing to let a company take a picture
[00:46:54.440 --> 00:46:58.160]   of my driver of my license plate and follow me around.
[00:46:58.160 --> 00:47:00.760]   But I need to know that that's happening so that I can make
[00:47:00.760 --> 00:47:02.360]   that choice as a consumer.
[00:47:02.360 --> 00:47:04.480]   I think that's been the problem all along is that the
[00:47:04.480 --> 00:47:08.120]   transparency of what these companies are collecting from us
[00:47:08.120 --> 00:47:09.760]   hasn't been good enough.
[00:47:09.760 --> 00:47:13.280]   We don't understand what data is being taken from us in order
[00:47:13.280 --> 00:47:17.000]   to make proper decisions for ourselves.
[00:47:17.000 --> 00:47:22.240]   - I think it's also important to point out that people
[00:47:22.240 --> 00:47:27.240]   often willingly give up their private information.
[00:47:27.240 --> 00:47:32.440]   You tell somebody that you'll give them a $5 coupon at Walmart
[00:47:32.440 --> 00:47:36.280]   and just fill out this form and people will go fill it out.
[00:47:36.280 --> 00:47:38.280]   - I do it all the time.
[00:47:38.280 --> 00:47:42.280]   Google has a thing on Android called Google Surveys
[00:47:42.280 --> 00:47:45.320]   where they ask the most private personal details.
[00:47:45.320 --> 00:47:48.320]   I do it because you get credit, the Google Play Store.
[00:47:48.320 --> 00:47:49.880]   And it's kind of funny 'cause they'll say,
[00:47:49.880 --> 00:47:51.560]   well, where were you last night and you tell them
[00:47:51.560 --> 00:47:53.160]   and then here's 25 cents.
[00:47:53.160 --> 00:47:54.000]   (laughs)
[00:47:54.000 --> 00:47:57.480]   But I don't, so you're right Jim, but that's,
[00:47:57.480 --> 00:47:59.160]   I think was Jobs Point.
[00:47:59.160 --> 00:48:01.480]   Give them the, let them know you're doing it.
[00:48:01.480 --> 00:48:03.000]   Give them the choice.
[00:48:03.000 --> 00:48:04.360]   And yeah, I'm saying, do you want to be--
[00:48:04.360 --> 00:48:09.360]   - I mean, most people don't equate that with their privacy.
[00:48:10.480 --> 00:48:15.400]   They'll just say, oh, I get $5 for filling out this form.
[00:48:15.400 --> 00:48:17.040]   And then the next time you get--
[00:48:17.040 --> 00:48:20.760]   - Well, but they should be allowed to do that.
[00:48:20.760 --> 00:48:24.760]   - Well, if I want my Google Play credit
[00:48:24.760 --> 00:48:28.800]   and they ask me where I was and I say, okay,
[00:48:28.800 --> 00:48:30.400]   I think that's fair.
[00:48:30.400 --> 00:48:32.920]   Is that not, you think that should be prohibited?
[00:48:32.920 --> 00:48:34.840]   - No, I'm not saying it should be prohibited,
[00:48:34.840 --> 00:48:37.400]   but I'm saying a lot of the people that are yelling
[00:48:37.400 --> 00:48:41.080]   about their privacy are already giving it up.
[00:48:41.080 --> 00:48:46.080]   - Are already giving it up for a few bucks.
[00:48:46.080 --> 00:48:51.240]   So it's hard to yell about privacy
[00:48:51.240 --> 00:48:54.320]   unless you actually care about your privacy.
[00:48:54.320 --> 00:48:58.400]   - No, I don't care much about my privacy obviously.
[00:48:58.400 --> 00:48:59.600]   (laughs)
[00:48:59.600 --> 00:49:04.600]   But I do very much care about Facebook not being upfront
[00:49:05.200 --> 00:49:08.640]   about what they're gathering and who they're giving it to.
[00:49:08.640 --> 00:49:10.480]   - Yeah, I hear a lot about that.
[00:49:10.480 --> 00:49:14.000]   - See, my difficulty is that we already have companies
[00:49:14.000 --> 00:49:19.000]   that claim to be complying with certain regulations
[00:49:19.000 --> 00:49:21.600]   and rules of fairness by saying, oh, well, no,
[00:49:21.600 --> 00:49:25.360]   that user did give us permission to track their phones
[00:49:25.360 --> 00:49:27.880]   and collect information on all of their friends
[00:49:27.880 --> 00:49:30.800]   because remember we had a new piece of software that said,
[00:49:30.800 --> 00:49:33.520]   we have new terms of service, click okay
[00:49:33.520 --> 00:49:35.320]   if you accept them without reading them.
[00:49:35.320 --> 00:49:38.400]   What I'm getting on about is that I think that
[00:49:38.400 --> 00:49:40.360]   the situation has become so uncontrollable
[00:49:40.360 --> 00:49:43.520]   that we need an identification of a fundamental right
[00:49:43.520 --> 00:49:45.720]   to ownership of your personal information.
[00:49:45.720 --> 00:49:48.360]   That if you want that at best,
[00:49:48.360 --> 00:49:51.480]   when I click that button, I'm just leasing this information
[00:49:51.480 --> 00:49:56.520]   to Facebook or whatever marketer is observing my web traffic
[00:49:56.520 --> 00:49:58.160]   that if I want to, I can simply say,
[00:49:58.160 --> 00:50:00.480]   by the way, I don't like what you're doing with my data,
[00:50:00.480 --> 00:50:03.120]   I'm now terminating your license to use this data.
[00:50:03.120 --> 00:50:05.440]   And now if they violate those services,
[00:50:05.440 --> 00:50:07.720]   they're going to be trouble or quintuple damages,
[00:50:07.720 --> 00:50:09.920]   something that will really, really make them feel
[00:50:09.920 --> 00:50:10.840]   a lot of pain.
[00:50:10.840 --> 00:50:14.160]   It's like this is why it's such a long
[00:50:14.160 --> 00:50:16.240]   and complicated conversation to have
[00:50:16.240 --> 00:50:19.280]   when ever again discussions, even on a personal level
[00:50:19.280 --> 00:50:20.760]   about, oh, well, I don't like Facebook
[00:50:20.760 --> 00:50:22.600]   and I don't like Google that I trust Apple,
[00:50:22.600 --> 00:50:23.960]   but I don't like this company.
[00:50:23.960 --> 00:50:28.720]   It's like Apple feels as a core value.
[00:50:28.720 --> 00:50:31.200]   I truly believe this, that privacy is something
[00:50:31.200 --> 00:50:34.080]   that is something that is important and valuable to consumers
[00:50:34.080 --> 00:50:35.760]   and something that they don't want to violate.
[00:50:35.760 --> 00:50:38.040]   It's part of the compact that they're making with users
[00:50:38.040 --> 00:50:39.240]   and they don't want to violate it.
[00:50:39.240 --> 00:50:41.680]   I believe that that's part of their core values.
[00:50:41.680 --> 00:50:44.200]   However, you can spend as much time as you want
[00:50:44.200 --> 00:50:48.840]   in the Apple ecosystem as soon as you go into a grocery store
[00:50:48.840 --> 00:50:50.280]   and pay for something with a credit card,
[00:50:50.280 --> 00:50:52.480]   okay, you've just compromised your privacy,
[00:50:52.480 --> 00:50:54.880]   as soon as you've hit any website anywhere
[00:50:54.880 --> 00:50:57.040]   without using a really good ad tracker,
[00:50:57.040 --> 00:51:00.320]   ad blocker and cookie blocker,
[00:51:00.320 --> 00:51:01.400]   again, you're compromised.
[00:51:01.400 --> 00:51:06.400]   It's like saying that you're living in the smog filled,
[00:51:06.400 --> 00:51:10.800]   filthy environments of London in 1891,
[00:51:10.800 --> 00:51:11.960]   but you wash your hands.
[00:51:11.960 --> 00:51:14.800]   It's like, again, it's better that you're washing your hands
[00:51:14.800 --> 00:51:16.400]   instead of not, but you are still living
[00:51:16.400 --> 00:51:19.400]   in a toxic environment that you need to be protected from
[00:51:19.400 --> 00:51:21.320]   and it's not something that's gonna be gonna happen
[00:51:21.320 --> 00:51:24.920]   because of voluntary things that industry does
[00:51:24.920 --> 00:51:27.280]   or good practices that individuals do.
[00:51:27.280 --> 00:51:29.400]   It's gonna have to be laws passed to say
[00:51:29.400 --> 00:51:30.480]   that this is not right.
[00:51:30.480 --> 00:51:32.400]   Our citizens deserve better than this
[00:51:32.400 --> 00:51:34.400]   and this is gonna be a much worse situation
[00:51:34.400 --> 00:51:35.720]   before it gets better.
[00:51:35.720 --> 00:51:39.800]   - You know, I think if we actually knew all of the information
[00:51:39.800 --> 00:51:43.720]   that companies have on us,
[00:51:43.720 --> 00:51:45.640]   it would probably scare us to death.
[00:51:45.640 --> 00:51:47.240]   - That's been interesting.
[00:51:47.240 --> 00:51:49.720]   Ever since Facebook offered as a result of GDPR,
[00:51:49.720 --> 00:51:52.080]   the right to the ability to download all the things
[00:51:52.080 --> 00:51:53.640]   that knew about you,
[00:51:53.640 --> 00:51:56.000]   all that's when all of this stuff started coming out.
[00:51:56.000 --> 00:51:58.600]   For instance, the fact that Facebook Messenger,
[00:51:58.600 --> 00:52:00.880]   on Android, they couldn't do it on iPhone
[00:52:00.880 --> 00:52:04.600]   for a couple of years 'cause Android's permissions relax,
[00:52:04.600 --> 00:52:07.800]   was downloading everybody you'd called,
[00:52:07.800 --> 00:52:10.040]   how long you talked to them
[00:52:10.040 --> 00:52:11.760]   and uploading it to Facebook.
[00:52:11.760 --> 00:52:15.240]   And when people realized that
[00:52:15.240 --> 00:52:16.560]   because they were able to download the data,
[00:52:16.560 --> 00:52:18.920]   they were horrified, but that's the point is,
[00:52:18.920 --> 00:52:21.400]   I think this stuff, somebody's saying,
[00:52:21.400 --> 00:52:22.520]   beatmaster in the chat, I'm saying,
[00:52:22.520 --> 00:52:24.880]   but Leo, none of these people, none of you are private people
[00:52:24.880 --> 00:52:26.360]   by virtue of the fact that we're all sitting here
[00:52:26.360 --> 00:52:28.600]   on camera talking about stuff.
[00:52:28.600 --> 00:52:31.280]   But I don't think you have to be somebody
[00:52:31.280 --> 00:52:34.840]   who embraces total privacy to care about privacy.
[00:52:34.840 --> 00:52:38.840]   I mean, I'm a public person and I don't mind being public,
[00:52:38.840 --> 00:52:41.080]   but I still wanna know,
[00:52:41.080 --> 00:52:44.320]   and what I really don't like is when companies are
[00:52:44.320 --> 00:52:46.600]   kind of sneakily taking this data
[00:52:46.600 --> 00:52:49.720]   and giving it to other companies and not disclosing.
[00:52:49.720 --> 00:52:52.480]   Now Apple's gonna be in a different boat soon though.
[00:52:52.480 --> 00:52:54.800]   One of the reasons Apple could do this
[00:52:54.800 --> 00:52:57.240]   was because Apple sold hardware.
[00:52:57.240 --> 00:53:00.880]   Facebook and Google are advertising platforms.
[00:53:00.880 --> 00:53:02.720]   Amazon's somewhat too these days.
[00:53:02.720 --> 00:53:04.720]   And as a result, when you're an advertising platform,
[00:53:04.720 --> 00:53:06.440]   I know because we're an advertising platform,
[00:53:06.440 --> 00:53:08.600]   there's intense pressure from advertisers.
[00:53:08.600 --> 00:53:10.480]   Give us everything you could possibly tell us
[00:53:10.480 --> 00:53:11.840]   about your customers.
[00:53:11.840 --> 00:53:14.040]   We intentionally don't collect data
[00:53:14.040 --> 00:53:17.440]   and the way we solve that is being a hyper niche product.
[00:53:17.440 --> 00:53:19.280]   And we feel like, and that has been so far
[00:53:19.280 --> 00:53:22.480]   adequate for advertisers, hey, if you want early adopters,
[00:53:22.480 --> 00:53:23.720]   if you want influencers,
[00:53:23.720 --> 00:53:25.880]   if you want tech enthusiasts,
[00:53:25.880 --> 00:53:26.840]   that's what you're gonna get.
[00:53:26.840 --> 00:53:28.520]   We don't tell them more than that.
[00:53:28.520 --> 00:53:30.600]   We don't know more than that.
[00:53:30.600 --> 00:53:34.480]   But Facebook wants to give a broad general advertising
[00:53:34.480 --> 00:53:38.840]   industry lots of information and lots of granularity.
[00:53:38.840 --> 00:53:39.960]   So does Google.
[00:53:39.960 --> 00:53:43.600]   So there's huge incentive pressure even for them to do this.
[00:53:43.600 --> 00:53:46.040]   But Apple's business model is changing.
[00:53:46.040 --> 00:53:49.680]   They sell hardware, but watch as services grow
[00:53:49.680 --> 00:53:51.800]   and become more and more of their business.
[00:53:51.800 --> 00:53:54.400]   And as Siri becomes more and more part in their business,
[00:53:54.400 --> 00:53:55.880]   that's when the rubber's gonna hit the road,
[00:53:55.880 --> 00:53:57.640]   where Apple's commitment to privacy,
[00:53:57.640 --> 00:53:59.240]   that's where we really wanna test it.
[00:53:59.240 --> 00:54:00.960]   They just hired, for instance,
[00:54:00.960 --> 00:54:04.840]   Google's former head of search and AI,
[00:54:04.840 --> 00:54:07.200]   John G Andrea,
[00:54:07.200 --> 00:54:11.080]   and Tim Cook had to say,
[00:54:11.080 --> 00:54:13.320]   John shares our commitment, don't worry,
[00:54:13.320 --> 00:54:15.720]   John shares our commitment to privacy.
[00:54:15.720 --> 00:54:16.760]   And our thoughtful approaches,
[00:54:16.760 --> 00:54:19.480]   we make computers even smarter and smarter and more personal.
[00:54:19.480 --> 00:54:21.080]   I mean, I imagine some Apple people
[00:54:21.080 --> 00:54:23.120]   would be a little bit concerned when the guy
[00:54:23.120 --> 00:54:26.640]   who designs AI and search for Google comes over to Apple.
[00:54:26.640 --> 00:54:28.040]   I think it's a big score.
[00:54:28.040 --> 00:54:30.040]   I think it'll help Siri.
[00:54:30.040 --> 00:54:31.520]   But for Siri to really become good,
[00:54:31.520 --> 00:54:34.200]   it needs to kind of know more about you, doesn't it?
[00:54:34.200 --> 00:54:38.000]   - Yeah, and how much more is it gonna collect from us?
[00:54:38.000 --> 00:54:41.720]   That's kind of been Apple's point of view is that,
[00:54:41.720 --> 00:54:43.760]   yeah, Siri's not that great,
[00:54:43.760 --> 00:54:47.280]   but you know what, Siri doesn't store things that it should.
[00:54:47.280 --> 00:54:48.400]   It doesn't know anything.
[00:54:48.400 --> 00:54:51.920]   So this sort of idea that like,
[00:54:51.920 --> 00:54:53.800]   we're making Siri better,
[00:54:53.800 --> 00:54:55.920]   maybe because we're gonna store some things
[00:54:55.920 --> 00:54:57.480]   that we weren't gonna store before.
[00:54:57.480 --> 00:55:01.200]   And that really does lead down a very frightening path.
[00:55:01.200 --> 00:55:03.560]   If we're kind of all in this boat of,
[00:55:03.560 --> 00:55:06.360]   Apple's so great and I trust them with my privacy.
[00:55:06.360 --> 00:55:09.200]   And if they are walking down a path
[00:55:09.200 --> 00:55:12.760]   that potentially exposes our privacy
[00:55:12.760 --> 00:55:14.840]   in some way that we're not used to Apple doing,
[00:55:14.840 --> 00:55:18.800]   that really is a huge change from what we've been.
[00:55:18.800 --> 00:55:21.640]   So kind of wonderfully championing
[00:55:21.640 --> 00:55:23.640]   about the company for so long.
[00:55:23.640 --> 00:55:26.400]   - Yeah, Apple-- - Apple do that though.
[00:55:26.400 --> 00:55:30.520]   - Right, you don't think Apple will do that,
[00:55:30.520 --> 00:55:32.600]   but that doesn't mean that they can't
[00:55:32.600 --> 00:55:35.920]   and wouldn't possibly have the potential to.
[00:55:35.920 --> 00:55:39.000]   I mean, I agree, I don't think Apple would do that.
[00:55:39.000 --> 00:55:43.360]   But Tim Cook isn't gonna be the CEO of Apple
[00:55:43.360 --> 00:55:45.160]   for 100 million years.
[00:55:45.160 --> 00:55:47.920]   Things change, what's gonna happen in the future?
[00:55:47.920 --> 00:55:49.240]   - Well, that's my point exactly, Laurie.
[00:55:49.240 --> 00:55:52.920]   And so it's just our job to keep an eye on it, that's all.
[00:55:52.920 --> 00:55:54.200]   And to the degree we can,
[00:55:54.200 --> 00:55:56.720]   the thing that really bugged me about Facebook is
[00:55:56.720 --> 00:55:59.200]   it was so opaque, there was no way of,
[00:55:59.200 --> 00:56:00.680]   I mean, we could have guessed,
[00:56:00.680 --> 00:56:02.920]   but really there was no way of knowing how
[00:56:02.920 --> 00:56:05.640]   laxa-daisical they were being with privacy protections.
[00:56:05.640 --> 00:56:07.320]   We now know that.
[00:56:07.320 --> 00:56:09.680]   Oiandroid was being extremely laxa-daisical
[00:56:09.680 --> 00:56:11.200]   with privacy protections.
[00:56:11.200 --> 00:56:13.200]   They have since tightened up those privacy
[00:56:13.200 --> 00:56:16.240]   and controls so that that thing Facebook did a few years ago,
[00:56:16.240 --> 00:56:18.640]   can't be done on current versions of Android.
[00:56:18.640 --> 00:56:23.120]   - I think as long as people have the ability to,
[00:56:23.120 --> 00:56:24.920]   like we've been saying, control access,
[00:56:24.920 --> 00:56:27.640]   understand the transactions that they're making,
[00:56:27.640 --> 00:56:30.800]   it's okay, 'cause this really is all about transactions.
[00:56:30.800 --> 00:56:34.200]   We make transactions with Apple because we trust them.
[00:56:34.200 --> 00:56:36.760]   I make transactions with Google because I believe
[00:56:36.760 --> 00:56:38.920]   that what I'm getting from them is worth what I'm giving them.
[00:56:38.920 --> 00:56:41.720]   And I also believe that they take seriously,
[00:56:41.720 --> 00:56:43.760]   within the limits of their business model,
[00:56:43.760 --> 00:56:45.680]   the need to maintain my privacy.
[00:56:45.680 --> 00:56:48.960]   Facebook, I do believe that just as, again,
[00:56:48.960 --> 00:56:52.000]   core value of the company is that everything is meant
[00:56:52.000 --> 00:56:54.800]   to be shared, that people got drawn closer together,
[00:56:54.800 --> 00:56:57.120]   the more information is free floating out there.
[00:56:57.120 --> 00:56:59.560]   And I don't believe that there are a lot of internal breaks
[00:56:59.560 --> 00:57:01.840]   against saying, no, we should not collect this
[00:57:01.840 --> 00:57:05.200]   or no, we'll be wrong. - Sorry, I turned on
[00:57:05.200 --> 00:57:06.880]   Mark Zuckerberg briefly, go ahead, keep talking.
[00:57:06.880 --> 00:57:08.360]   (laughing)
[00:57:08.360 --> 00:57:11.200]   - I just like seeing his sweaty visage.
[00:57:11.200 --> 00:57:13.800]   That's cool, I've been, I was making such a pervasive
[00:57:13.800 --> 00:57:15.680]   argument that Zuck interrupted me because
[00:57:15.680 --> 00:57:17.520]   (laughing)
[00:57:17.520 --> 00:57:18.840]   I feel very flattered.
[00:57:18.840 --> 00:57:21.720]   You wanna hear what he's saying?
[00:57:21.720 --> 00:57:23.560]   What are you saying, Mark? - Okay.
[00:57:23.560 --> 00:57:26.880]   - Do you think that during the--
[00:57:26.880 --> 00:57:28.160]   - This is Senator Maria Campwell.
[00:57:28.160 --> 00:57:32.120]   - 2016 campaign as Cambridge Analytica was providing
[00:57:32.120 --> 00:57:35.840]   support to the Trump campaign under Project Alamo,
[00:57:35.840 --> 00:57:38.760]   were there any Facebook people involved in that
[00:57:38.760 --> 00:57:41.360]   sharing of technique and information?
[00:57:41.360 --> 00:57:46.400]   - Senator, we provided support to the Trump campaign
[00:57:46.400 --> 00:57:51.400]   similar to what we provide to any advertiser or campaign
[00:57:51.400 --> 00:57:52.960]   who asks for it.
[00:57:52.960 --> 00:57:54.400]   - So that was a yes.
[00:57:54.400 --> 00:57:56.680]   Is that a yes?
[00:57:56.680 --> 00:57:58.840]   - Senator, can you repeat the specific question?
[00:57:58.840 --> 00:58:01.440]   - Oh boy, I'm just glad that they've trained him
[00:58:01.440 --> 00:58:03.560]   to blink every few seconds now.
[00:58:03.560 --> 00:58:04.400]   I think that's-- - Wow.
[00:58:04.400 --> 00:58:07.240]   (laughing)
[00:58:07.240 --> 00:58:10.480]   - I don't envy Zuck or Berlkin.
[00:58:10.480 --> 00:58:13.280]   - Oh, can you, you wanna see some terrifying pictures?
[00:58:13.280 --> 00:58:18.280]   There's a picture on Twitter of Zuck or Berlkin sitting
[00:58:18.280 --> 00:58:21.880]   at the table all alone, surrounded by about
[00:58:21.880 --> 00:58:25.960]   100 pool photographers just right in his face
[00:58:25.960 --> 00:58:29.000]   taking pictures and-- - I can't, it's a much smaller room
[00:58:29.000 --> 00:58:30.360]   than you think it is.
[00:58:30.360 --> 00:58:33.160]   The senators and the Congress people are about
[00:58:33.160 --> 00:58:34.360]   10 or 12 feet away from you.
[00:58:34.360 --> 00:58:37.560]   It's a bad feeling when they're not there
[00:58:37.560 --> 00:58:39.120]   to give you a medal of some sort.
[00:58:39.120 --> 00:58:42.600]   - They did, I understand over the weekend,
[00:58:42.600 --> 00:58:44.620]   spend time training, Mark.
[00:58:44.620 --> 00:58:48.560]   You're kind of like you would train for a political
[00:58:48.560 --> 00:58:51.080]   campaign debate where they had surrogates
[00:58:51.080 --> 00:58:53.480]   and they had pestered him with questions and put him in all.
[00:58:53.480 --> 00:58:56.720]   So he really has actually had quite a bit of training.
[00:58:56.720 --> 00:58:59.720]   I imagine given their resources, Facebook built a room
[00:58:59.720 --> 00:59:03.320]   exactly like the Senate chamber
[00:59:03.320 --> 00:59:05.840]   and exactly to the T.
[00:59:05.840 --> 00:59:09.600]   But as you know, what you do know is gonna be happening,
[00:59:09.600 --> 00:59:13.080]   which is I kind of feel bad for Mark is the pile on
[00:59:13.080 --> 00:59:15.360]   because this is an opportunity for every senator
[00:59:15.360 --> 00:59:18.720]   to get some camera time showing how strongly they're committed
[00:59:18.720 --> 00:59:20.240]   to protecting the public.
[00:59:20.240 --> 00:59:23.320]   And so this ends up being like stump speech after stump
[00:59:23.320 --> 00:59:25.440]   speech after stump speech, it's really good.
[00:59:25.440 --> 00:59:28.520]   - Well, this is a big problem for Facebook
[00:59:28.520 --> 00:59:31.480]   because if right now the power of the internet
[00:59:31.480 --> 00:59:35.960]   has always been the presumption that government
[00:59:35.960 --> 00:59:39.680]   shouldn't really limit what people can do or say
[00:59:39.680 --> 00:59:43.320]   they can only respond when bad things happen.
[00:59:43.320 --> 00:59:45.360]   That's one of the reasons why, for instance,
[00:59:45.360 --> 00:59:48.320]   the basic principle of like you that applies to YouTube
[00:59:48.320 --> 00:59:51.240]   is that it's not Google's responsibility to prevent
[00:59:51.240 --> 00:59:55.320]   somebody from posting copyrighted content on the service
[00:59:55.320 --> 00:59:58.480]   illegally, it's just their responsibility to take it down
[00:59:58.480 --> 01:00:00.800]   once the copyright holder knows that this has happened.
[01:00:00.800 --> 01:00:03.640]   So if the Facebook is kind of doomed,
[01:00:03.640 --> 01:00:05.640]   if now they're responsible for vetting,
[01:00:05.640 --> 01:00:07.880]   every single ad that comes on board
[01:00:07.880 --> 01:00:10.960]   and every single piece of communication that comes on board
[01:00:10.960 --> 01:00:13.040]   and in the head of a major,
[01:00:13.040 --> 01:00:15.480]   in the head of the 2018 election cycle
[01:00:15.480 --> 01:00:19.000]   where there's a lot of deeply, deeply contested seats,
[01:00:19.000 --> 01:00:21.920]   this could be very, very bad, not only for Facebook,
[01:00:21.920 --> 01:00:24.320]   but if they decide to put the hammer down
[01:00:24.320 --> 01:00:26.960]   in the entire industry, it could be bad for Google as well.
[01:00:26.960 --> 01:00:29.600]   Apple, it's a good day to be Tim Cook
[01:00:29.600 --> 01:00:31.800]   because there are a lot of ways this could shake out
[01:00:31.800 --> 01:00:33.640]   and none of them would be bad for Apple.
[01:00:33.640 --> 01:00:35.440]   - And to your point, Laurie, I mean, Apple
[01:00:35.440 --> 01:00:40.040]   could change their tune, but they're watching this
[01:00:40.040 --> 01:00:43.000]   and saying, okay, bullet dodged,
[01:00:43.000 --> 01:00:46.800]   let's just make sure we stay on the straight narrow here.
[01:00:46.800 --> 01:00:49.360]   How does Siri get better though,
[01:00:49.360 --> 01:00:51.880]   if Apple wants to preserve privacy?
[01:00:51.880 --> 01:00:54.920]   Is there a way forward for Siri?
[01:00:54.920 --> 01:00:58.600]   - Who wants to take this one?
[01:00:58.600 --> 01:00:59.600]   (laughing)
[01:00:59.600 --> 01:01:00.760]   - Laurie doesn't know.
[01:01:00.760 --> 01:01:04.280]   Okay. - I mean, that's kind of the problem
[01:01:04.280 --> 01:01:08.560]   is that I do, there's gotta be a way, right?
[01:01:08.560 --> 01:01:11.880]   But there's something to be said for how well
[01:01:11.880 --> 01:01:15.640]   other virtual assistants work.
[01:01:15.640 --> 01:01:18.320]   They're the Google one and the Amazon one,
[01:01:18.320 --> 01:01:21.040]   they work better than Siri.
[01:01:21.040 --> 01:01:23.080]   I'm sorry, they do. - Absolutely, yeah.
[01:01:23.080 --> 01:01:25.960]   - And I know why, it's because they're able to collect
[01:01:25.960 --> 01:01:30.280]   and store, it's like if you had a personal assistant
[01:01:30.280 --> 01:01:33.960]   that you used a memory charm on at the end of every day
[01:01:33.960 --> 01:01:36.800]   and took away that personal assistant's memory
[01:01:36.800 --> 01:01:40.040]   so that they had to start over from scratch every time
[01:01:40.040 --> 01:01:43.040]   they wanted information, or you had to give them information.
[01:01:43.040 --> 01:01:47.720]   So how can Apple protect my privacy
[01:01:47.720 --> 01:01:49.320]   while making Siri better?
[01:01:49.320 --> 01:01:50.800]   That's the question, right?
[01:01:50.800 --> 01:01:52.520]   - There is, there is an answer.
[01:01:52.520 --> 01:01:54.440]   - So you could at least make Siri smarter
[01:01:54.440 --> 01:01:55.960]   about the outside world.
[01:01:55.960 --> 01:01:58.360]   It doesn't need to know my flight schedule
[01:01:58.360 --> 01:02:01.040]   or when I go to bed, but it could know more
[01:02:01.040 --> 01:02:03.720]   about hotels and flights and other things.
[01:02:03.720 --> 01:02:05.800]   - Well, I won't think that, go ahead, Jim.
[01:02:05.800 --> 01:02:09.720]   - There is something to be said for your point.
[01:02:09.720 --> 01:02:16.240]   I asked Siri yesterday, when do the NHL playoffs start?
[01:02:16.240 --> 01:02:19.000]   And Siri had no idea.
[01:02:19.000 --> 01:02:19.840]   - Right.
[01:02:19.840 --> 01:02:23.520]   - The playoffs start tomorrow, by the way.
[01:02:23.520 --> 01:02:26.280]   - You see, Google would know that you were a Canadian
[01:02:26.280 --> 01:02:27.640]   and have that ready.
[01:02:27.640 --> 01:02:32.360]   - So Google de-sprint analysis.
[01:02:32.360 --> 01:02:34.560]   - It's 30% heavy.
[01:02:34.560 --> 01:02:38.000]   - I have the Google app on my iPhone
[01:02:38.000 --> 01:02:40.320]   and whenever Siri can't answer something,
[01:02:40.320 --> 01:02:42.320]   I try Google just to see.
[01:02:42.320 --> 01:02:46.720]   And Google did know, but I mean, that's one of those things
[01:02:46.720 --> 01:02:51.200]   where when I wrote an article a little while ago,
[01:02:51.200 --> 01:02:53.440]   but our expectations of Siri
[01:02:53.440 --> 01:02:57.520]   and how Siri seems to work better on some devices
[01:02:57.520 --> 01:02:59.000]   as opposed to others.
[01:02:59.000 --> 01:03:03.880]   And my theory in writing this was that
[01:03:03.880 --> 01:03:06.160]   a lot of it is based on our expectations.
[01:03:06.160 --> 01:03:10.400]   So for instance, CarPlay, Siri works wonderful in CarPlay.
[01:03:10.400 --> 01:03:13.040]   It works great on the HomePod.
[01:03:13.040 --> 01:03:16.040]   But our expectations of what Siri can do for us
[01:03:16.040 --> 01:03:18.880]   and those two devices is so limited
[01:03:18.880 --> 01:03:21.640]   that it appears that Siri is working really well.
[01:03:21.640 --> 01:03:23.920]   And in fact, it does work really well.
[01:03:23.920 --> 01:03:28.520]   When I hop in the car, I'll ask it to read a text for me.
[01:03:28.520 --> 01:03:31.520]   I'll get directions and I'll play music.
[01:03:31.520 --> 01:03:34.280]   So there's three things that I do in the car
[01:03:34.280 --> 01:03:37.120]   with CarPlay, but nothing else.
[01:03:37.120 --> 01:03:40.680]   So if you go then to your phone,
[01:03:40.680 --> 01:03:43.920]   what are your expectations for the phone?
[01:03:43.920 --> 01:03:47.320]   Well, the really Apple hasn't said any expectations,
[01:03:47.320 --> 01:03:48.840]   so it's wide open.
[01:03:48.840 --> 01:03:51.520]   So we're asking Siri all kinds of different things
[01:03:51.520 --> 01:03:53.880]   to do things, to answer questions
[01:03:53.880 --> 01:03:58.120]   that for some reason, it's not able to do.
[01:03:58.120 --> 01:04:01.760]   And it appears that Siri is not working very well
[01:04:01.760 --> 01:04:05.200]   on the iPhone, but our expectations are so different
[01:04:05.200 --> 01:04:08.320]   and so a wide ranging on the iPhone
[01:04:08.320 --> 01:04:10.600]   as opposed to the other devices.
[01:04:10.600 --> 01:04:15.080]   So, is the problem, yes, that Siri can't answer
[01:04:15.080 --> 01:04:18.520]   when the NHL playoffs are, even when they're two days away?
[01:04:18.520 --> 01:04:23.040]   Or is the problem that we shouldn't be asking Siri that?
[01:04:23.040 --> 01:04:28.040]   Well, as Lori said, some of the other assistants
[01:04:28.040 --> 01:04:30.360]   can answer those questions.
[01:04:30.360 --> 01:04:32.400]   So why can't Siri?
[01:04:32.400 --> 01:04:35.200]   I'm not asking it about anything to do
[01:04:35.200 --> 01:04:37.120]   with my personal information.
[01:04:37.120 --> 01:04:41.600]   I'm asking Siri an outside question.
[01:04:41.600 --> 01:04:44.480]   This seems like a very simple question.
[01:04:44.480 --> 01:04:46.800]   I can ask Siri music questions.
[01:04:46.800 --> 01:04:50.560]   And Siri can answer.
[01:04:50.560 --> 01:04:55.880]   A frustrating part about Siri is that you can ask Siri
[01:04:55.880 --> 01:04:59.880]   whether or not the or when the NHL playoffs are
[01:04:59.880 --> 01:05:04.120]   or the season starts and it'll answer it wrong the first time
[01:05:04.120 --> 01:05:06.120]   and if you ask it again, it'll answer it right.
[01:05:06.120 --> 01:05:08.560]   For me, the most frustrating aspect of Siri
[01:05:08.560 --> 01:05:12.280]   is that it sometimes works and sometimes doesn't.
[01:05:12.280 --> 01:05:14.520]   That's just crushing to me.
[01:05:14.520 --> 01:05:17.200]   I want it to always work or always not work,
[01:05:17.200 --> 01:05:19.040]   not sometimes turn my lights on
[01:05:19.040 --> 01:05:22.600]   and then sometimes tell me it doesn't know what I'm asking.
[01:05:22.600 --> 01:05:25.600]   And I think that's even more frustrating
[01:05:25.600 --> 01:05:30.600]   that Siri might not know when a sports playoff starts,
[01:05:30.600 --> 01:05:35.040]   but I bet if you asked it again, it would have the answer.
[01:05:35.040 --> 01:05:36.680]   Even if you asked it in the same way
[01:05:36.680 --> 01:05:38.720]   and that's super frustrating.
[01:05:38.720 --> 01:05:41.760]   It's kind of a shame Facebook decided to postpone
[01:05:41.760 --> 01:05:42.600]   it's assistant.
[01:05:42.600 --> 01:05:44.160]   I bet it'd be really good.
[01:05:44.160 --> 01:05:48.680]   Oh, I think it would be the first pro act of assistant
[01:05:48.680 --> 01:05:52.080]   that says, yeah, have you thought about voting for this guy?
[01:05:52.080 --> 01:05:52.920]   Yeah.
[01:05:52.920 --> 01:05:56.560]   How would you like to learn Russian?
[01:05:56.560 --> 01:05:59.520]   This would get to that point where our personal assistant
[01:05:59.520 --> 01:06:02.720]   would get a crush on us and then try to kill our partners
[01:06:02.720 --> 01:06:05.520]   and try to track us in the bathroom.
[01:06:05.520 --> 01:06:06.760]   No, I'm ready for us.
[01:06:06.760 --> 01:06:08.320]   Scarlett Johansson and her.
[01:06:08.320 --> 01:06:10.880]   I want, I want, and I don't care if she goes off
[01:06:10.880 --> 01:06:12.120]   to the other AIs at the end.
[01:06:12.120 --> 01:06:14.080]   It's okay, it's okay.
[01:06:14.080 --> 01:06:17.160]   Apple did make a big point a year or two ago.
[01:06:17.160 --> 01:06:20.000]   I think it was a year ago about their investment
[01:06:20.000 --> 01:06:24.080]   in differential privacy, which is a concept in research
[01:06:24.080 --> 01:06:28.600]   that says there's a way to get the benefit to the user
[01:06:28.600 --> 01:06:31.680]   of personal information without necessarily actually storing
[01:06:31.680 --> 01:06:34.680]   or relating personal information to any one specific user.
[01:06:34.680 --> 01:06:37.840]   And that's a much bigger field than I just made it sound.
[01:06:37.840 --> 01:06:40.840]   So they've got a dog in that game.
[01:06:40.840 --> 01:06:44.000]   But the big problem is that it's, you know,
[01:06:44.000 --> 01:06:45.080]   just like you just like you said,
[01:06:45.080 --> 01:06:48.760]   it's people don't use a, people don't use anything
[01:06:48.760 --> 01:06:51.000]   if it doesn't work the way they expect it to.
[01:06:51.000 --> 01:06:53.120]   And I think one of the biggest problems
[01:06:53.120 --> 01:06:55.360]   of personal assistance is that people will only use it
[01:06:55.360 --> 01:06:58.120]   to find out what the weather is and just set a kitchen timer
[01:06:58.120 --> 01:07:00.560]   if that's all that it can actually do reliably.
[01:07:00.560 --> 01:07:02.120]   They never tried anything else, yeah.
[01:07:02.120 --> 01:07:04.640]   And then part of that transaction that I was speaking about
[01:07:04.640 --> 01:07:09.040]   about Google is that I have no doubts that it's that
[01:07:09.040 --> 01:07:11.320]   we're not too far away from my being able to,
[01:07:11.320 --> 01:07:14.360]   as I'm getting dressed and thinking that I'm either going
[01:07:14.360 --> 01:07:18.400]   to be, I'm either just going to just make my commuter train
[01:07:18.400 --> 01:07:19.680]   or I'm just going to miss it.
[01:07:19.680 --> 01:07:22.320]   I don't know whether I should drive or take my bike
[01:07:22.320 --> 01:07:24.400]   or whatever and being able to say,
[01:07:24.400 --> 01:07:27.280]   hey Guillermo are the trains running late today.
[01:07:27.280 --> 01:07:30.840]   And I'm perfectly fine with it knowing that it knows
[01:07:30.840 --> 01:07:34.040]   where I am so it knows what we're talking about the MBTA.
[01:07:34.040 --> 01:07:37.200]   It knows what my usual train is on what line.
[01:07:37.200 --> 01:07:40.160]   So it knows and it knows where I generally pick up the train
[01:07:40.160 --> 01:07:43.640]   from. So if it's going to say that yes, the red line is running
[01:07:43.640 --> 01:07:45.960]   about 11 minutes late during to track activity
[01:07:45.960 --> 01:07:48.600]   and track activity outside of South Station,
[01:07:48.600 --> 01:07:49.880]   then I'm like, okay, thank goodness,
[01:07:49.880 --> 01:07:51.600]   I'm not going to miss my train.
[01:07:51.600 --> 01:07:53.440]   That's the sort of stuff that people are,
[01:07:53.440 --> 01:07:56.680]   if you give me a benefit that exceeds the value
[01:07:56.680 --> 01:07:59.440]   of the information I'm giving you, that's perfectly fine.
[01:07:59.440 --> 01:08:03.160]   I love the fact that when I'm on a business trip,
[01:08:03.160 --> 01:08:06.280]   I just swipe left and my hotel information is there,
[01:08:06.280 --> 01:08:08.160]   my flight information is there,
[01:08:08.160 --> 01:08:11.960]   traffic conditions from the airport to my hotel is there.
[01:08:11.960 --> 01:08:13.880]   Everything has been collected for me.
[01:08:13.880 --> 01:08:15.640]   And again, it's an okay transaction.
[01:08:15.640 --> 01:08:18.120]   That's why I keep using these Google services.
[01:08:18.120 --> 01:08:22.800]   Siri, even when Siri, and remember that I am also
[01:08:22.800 --> 01:08:25.680]   an equal like iOS user, I just don't use it
[01:08:25.680 --> 01:08:28.600]   because it just doesn't work.
[01:08:28.600 --> 01:08:30.920]   And it doesn't give me the sort of depth of information
[01:08:30.920 --> 01:08:34.280]   that I think is valuable apart from what's the weather right now
[01:08:34.280 --> 01:08:36.560]   and set a kitchen timer for 20 minutes.
[01:08:36.560 --> 01:08:40.920]   And you can't really blame that for Apple's privacy policies
[01:08:40.920 --> 01:08:42.520]   for that.
[01:08:42.520 --> 01:08:45.600]   On the other hand, I should say that even though Siri
[01:08:45.600 --> 01:08:48.880]   is not leading the pack, even the best of them
[01:08:48.880 --> 01:08:52.280]   fails frequently enough that you have not a whole lot
[01:08:52.280 --> 01:08:53.240]   of confidence that these are.
[01:08:53.240 --> 01:08:55.920]   I mean, we're really in the primitive stages of this stuff.
[01:08:55.920 --> 01:08:58.840]   Yeah, but Siri is that, Siri is that, again,
[01:08:58.840 --> 01:09:01.440]   it's a marvelous piece of software.
[01:09:01.440 --> 01:09:03.920]   The people who work on it are doing marvelous things,
[01:09:03.920 --> 01:09:07.520]   but between Amazon's product, Google's product,
[01:09:07.520 --> 01:09:08.920]   and Apple's product.
[01:09:08.920 --> 01:09:11.200]   If you think about which one is most likely when you say
[01:09:11.200 --> 01:09:15.240]   call mom to say, "Diling, mom's diner in Stitchwood,
[01:09:15.240 --> 01:09:17.440]   Massachusetts," I think that most people think
[01:09:17.440 --> 01:09:19.600]   that would probably be Siri that would make that mistake.
[01:09:19.600 --> 01:09:21.320]   You do the first one, yeah.
[01:09:21.320 --> 01:09:23.240]   Actually, sometimes it's kind of humorous.
[01:09:23.240 --> 01:09:26.440]   I like to talk to Siri just 'cause she's wacky.
[01:09:26.440 --> 01:09:29.520]   (both laughing)
[01:09:29.520 --> 01:09:31.800]   Of course, that's why you like to talk to us.
[01:09:31.800 --> 01:09:35.000]   Yeah, definitely why I like to talk to you, Jim.
[01:09:35.000 --> 01:09:38.920]   Lots of Twitter memes already about Mark Zuckerberg
[01:09:38.920 --> 01:09:42.200]   and his testimony in "Frai Congress."
[01:09:42.200 --> 01:09:46.320]   This is gonna be an interesting couple of days.
[01:09:46.320 --> 01:09:49.560]   We're not breaking news networks, so, well,
[01:09:49.560 --> 01:09:51.280]   most of the time, unless it's an Apple event,
[01:09:51.280 --> 01:09:54.160]   so we probably won't cover this live,
[01:09:54.160 --> 01:09:59.160]   but if anything big happens, we'll let you know.
[01:09:59.480 --> 01:10:03.640]   Having some fun with Lori Gill from iMore.com,
[01:10:03.640 --> 01:10:06.120]   she's deputy managing editor there,
[01:10:06.120 --> 01:10:10.760]   Apoholic, A-P-P-A-H-O-L-I-K on Twitter.
[01:10:10.760 --> 01:10:14.840]   And someday, I will get my name back from Twitter.
[01:10:14.840 --> 01:10:18.680]   I had it once long ago and got rid of it like a fool
[01:10:18.680 --> 01:10:20.040]   and somebody else picked it up.
[01:10:20.040 --> 01:10:21.120]   I almost did that.
[01:10:21.120 --> 01:10:25.880]   I registered for Twitter in December 2006,
[01:10:25.880 --> 01:10:29.840]   got fed up with Twitter in March, quit.
[01:10:29.840 --> 01:10:31.800]   I was just lucky that when I came back a few months later,
[01:10:31.800 --> 01:10:33.680]   I still, my name was still there.
[01:10:33.680 --> 01:10:36.360]   Yeah, I had the exact opposite experience.
[01:10:36.360 --> 01:10:39.760]   When I was fed up and quit, it was gone by the time I came back.
[01:10:39.760 --> 01:10:42.080]   Did you have LOR, R-Y?
[01:10:42.080 --> 01:10:44.520]   Yep, it was L-O-R-Y-G-I-O-L.
[01:10:44.520 --> 01:10:46.400]   Oh, the whole name, did somebody took that?
[01:10:46.400 --> 01:10:49.760]   Yeah, it was my name, perfect, yeah.
[01:10:49.760 --> 01:10:53.200]   And the worst part is that whomever owns it is sitting on it.
[01:10:53.200 --> 01:10:55.200]   It hasn't actually been tweeted from in years.
[01:10:55.200 --> 01:10:57.520]   I'm hoping you'll come and pay them lots of money.
[01:10:57.520 --> 01:10:59.440]   That's probably true.
[01:10:59.440 --> 01:10:59.880]   Yeah.
[01:10:59.880 --> 01:11:03.000]   And now.
[01:11:03.000 --> 01:11:06.200]   Anionako Chicago-- oh, former.
[01:11:06.200 --> 01:11:07.840]   Normally, Chicago said times now,
[01:11:07.840 --> 01:11:11.680]   anako.com, great stuff and fast company lately.
[01:11:11.680 --> 01:11:15.360]   They're showing some good taste using your freelance services,
[01:11:15.360 --> 01:11:17.200]   I must say.
[01:11:17.200 --> 01:11:22.120]   And from the loop, the loop insight, loopinsight.com,
[01:11:22.120 --> 01:11:23.160]   Jim Dalrymple.
[01:11:23.160 --> 01:11:27.600]   He's J-D-A-L-R-Y-M-P-L-E-ON.
[01:11:27.600 --> 01:11:29.440]   Twitter.
[01:11:29.440 --> 01:11:32.840]   Our show today brought to you by my saliva.
[01:11:32.840 --> 01:11:40.600]   That's all it took to get my 23andMe reports.
[01:11:40.600 --> 01:11:42.320]   I say that because I think sometimes people
[01:11:42.320 --> 01:11:46.280]   think what I'm talking about 23andMe, which is a great service.
[01:11:46.280 --> 01:11:46.920]   I love it.
[01:11:46.920 --> 01:11:49.840]   Genetics, personal genetic service,
[01:11:49.840 --> 01:11:52.000]   that lets you find out what your DNA story is.
[01:11:52.000 --> 01:11:53.520]   Sometimes people when I say that, they think,
[01:11:53.520 --> 01:11:55.640]   oh, you have to go to a doctor or get blood drawers.
[01:11:55.640 --> 01:11:56.200]   No.
[01:11:56.200 --> 01:11:57.920]   They send you a little kit with a little tiny vial
[01:11:57.920 --> 01:11:59.720]   that you spit into.
[01:11:59.720 --> 01:12:03.880]   And your saliva contains enough of your DNA
[01:12:03.880 --> 01:12:05.400]   that they can get you the reports.
[01:12:05.400 --> 01:12:06.960]   They can do the analysis.
[01:12:06.960 --> 01:12:10.920]   Those 23 pairs of chromosomes, one set from your mom,
[01:12:10.920 --> 01:12:15.240]   one set from your dad that make you uniquely you,
[01:12:15.240 --> 01:12:17.360]   there's so much in there about your ancestry,
[01:12:17.360 --> 01:12:20.160]   about your traits, about your health.
[01:12:20.160 --> 01:12:21.640]   For a long time-- I'll give you an example.
[01:12:21.640 --> 01:12:22.120]   I've done it.
[01:12:22.120 --> 01:12:22.880]   I did it years ago.
[01:12:22.880 --> 01:12:26.200]   Lisa, my wife, I gave it this Christmas to my mom
[01:12:26.200 --> 01:12:26.720]   and my sister.
[01:12:26.720 --> 01:12:29.440]   They were having such fun with it.
[01:12:29.440 --> 01:12:32.400]   For the longest time, I've known that my wife was
[01:12:32.400 --> 01:12:33.400]   what they call a supertaster.
[01:12:33.400 --> 01:12:35.680]   I thought, anyway, she was because I would put ingredients
[01:12:35.680 --> 01:12:36.920]   in food or we'd go to a restaurant
[01:12:36.920 --> 01:12:38.640]   and she'd say, oh, yeah, there's a little vinegar in there.
[01:12:38.640 --> 01:12:39.160]   I'd say, no, there's not.
[01:12:39.160 --> 01:12:40.680]   She said, you know, I can taste the sour cream.
[01:12:40.680 --> 01:12:41.360]   It's in there.
[01:12:41.360 --> 01:12:42.240]   And I'd say, no, it's not.
[01:12:42.240 --> 01:12:44.200]   And she'd always be right.
[01:12:44.200 --> 01:12:45.880]   So I realized she must be a supertaster.
[01:12:45.880 --> 01:12:49.560]   Well, we got her ancestry report or her trait report
[01:12:49.560 --> 01:12:51.440]   back a couple of months ago.
[01:12:51.440 --> 01:12:52.880]   Actually, she was recently.
[01:12:52.880 --> 01:12:57.480]   She was looking last week, said 67% chance you're a supertaster.
[01:12:57.480 --> 01:12:59.720]   That's kind of cool to find that stuff.
[01:12:59.720 --> 01:13:01.080]   I know.
[01:13:01.080 --> 01:13:03.720]   You find out weird stuff, too, like whether you're more prone
[01:13:03.720 --> 01:13:07.080]   to having back hair or a cleft chin.
[01:13:07.080 --> 01:13:11.800]   You also got ancestry stuff that's really neat.
[01:13:11.800 --> 01:13:14.120]   I guess she went-- she was going to see
[01:13:14.120 --> 01:13:16.560]   if she had any Jewish ancestry because her maiden name
[01:13:16.560 --> 01:13:17.840]   is Rosenthal.
[01:13:17.840 --> 01:13:23.160]   And sure enough, I think like 3% Ashkenashi Jew was in there.
[01:13:23.160 --> 01:13:25.000]   She has more Neanderthal than I do.
[01:13:25.000 --> 01:13:26.160]   I was very proud of that.
[01:13:26.160 --> 01:13:29.200]   I'm about 4% Neanderthal.
[01:13:29.200 --> 01:13:29.680]   I know.
[01:13:29.680 --> 01:13:30.560]   Isn't that cool?
[01:13:30.560 --> 01:13:33.520]   That's an example of how you get more all the time for 23
[01:13:33.520 --> 01:13:33.720]   and me.
[01:13:33.720 --> 01:13:38.480]   When I did it, they didn't think at the time that Homo sapiens
[01:13:38.480 --> 01:13:39.720]   had hit her bread with Neanderthals.
[01:13:39.720 --> 01:13:42.200]   And then, not so long ago, a few years ago,
[01:13:42.200 --> 01:13:44.320]   they found some Neanderthal remains
[01:13:44.320 --> 01:13:45.680]   and they were able to get a DNA analysis.
[01:13:45.680 --> 01:13:46.920]   And whoa.
[01:13:46.920 --> 01:13:48.840]   It turns out there was interbreeding.
[01:13:48.840 --> 01:13:51.080]   But that was something when I first did 23
[01:13:51.080 --> 01:13:52.200]   and me that nobody knew about.
[01:13:52.200 --> 01:13:54.160]   And then, since I've gotten the report--
[01:13:54.160 --> 01:13:55.360]   so they are always adding.
[01:13:55.360 --> 01:13:56.640]   You're always learning more.
[01:13:56.640 --> 01:13:58.360]   You could find out where your people came from.
[01:13:58.360 --> 01:14:00.840]   Not just hundreds of years ago, but tens of thousands
[01:14:00.840 --> 01:14:01.960]   of years ago.
[01:14:01.960 --> 01:14:04.480]   You can actually watch the migration
[01:14:04.480 --> 01:14:07.360]   of your maternal and paternal haplogroups.
[01:14:07.360 --> 01:14:08.680]   Mine started in Africa.
[01:14:08.680 --> 01:14:10.760]   Then I migrated up through the Middle East into Europe.
[01:14:10.760 --> 01:14:12.080]   It's really fun.
[01:14:12.080 --> 01:14:14.080]   They've got a DNA relative finder tool
[01:14:14.080 --> 01:14:16.920]   with your permission and permissions of the relatives.
[01:14:16.920 --> 01:14:18.280]   You can connect.
[01:14:18.280 --> 01:14:19.720]   I found a second cousin.
[01:14:19.720 --> 01:14:21.600]   It's actually kind of funny.
[01:14:21.600 --> 01:14:24.840]   I told my sister, oh, look, we have a second cousin.
[01:14:24.840 --> 01:14:26.320]   And I think it must be a second cousin
[01:14:26.320 --> 01:14:29.160]   because his last name's the same as grandma's maiden name.
[01:14:29.160 --> 01:14:30.880]   My sister said, you know Anthony,
[01:14:30.880 --> 01:14:33.080]   we have pictures of him.
[01:14:33.080 --> 01:14:35.280]   Oh.
[01:14:35.280 --> 01:14:37.200]   I just forgot, I guess.
[01:14:37.200 --> 01:14:38.200]   I was so excited.
[01:14:38.200 --> 01:14:39.800]   Look, I found a second cousin.
[01:14:39.800 --> 01:14:41.840]   I have other relatives I found.
[01:14:41.840 --> 01:14:43.160]   It's really, really cool.
[01:14:43.160 --> 01:14:45.640]   Why are you 23 and me kids today at 23?
[01:14:45.640 --> 01:14:49.800]   That's the number two three and me.com/twit.
[01:14:49.800 --> 01:14:51.760]   23andme.com/twit.
[01:14:51.760 --> 01:14:54.880]   Frankly, the most fascinating book ever written.
[01:14:54.880 --> 01:14:58.080]   The story of you.
[01:14:58.080 --> 01:15:00.560]   Sweet versus salty, lactose intolerant,
[01:15:00.560 --> 01:15:01.480]   all sorts of stuff.
[01:15:01.480 --> 01:15:05.320]   23andme.com/twit.
[01:15:05.320 --> 01:15:06.320]   Everybody in my family's done.
[01:15:06.320 --> 01:15:10.400]   It's actually fun when you get everybody doing it.
[01:15:10.400 --> 01:15:11.960]   - You see, honey, now we have,
[01:15:11.960 --> 01:15:14.240]   I've got proof here that you're the one who snores.
[01:15:14.240 --> 01:15:15.080]   - Uh-huh.
[01:15:15.080 --> 01:15:17.840]   - 72% predilection towards snoring
[01:15:17.840 --> 01:15:19.560]   and then waking up their husband during the night.
[01:15:19.560 --> 01:15:21.080]   - Yes!
[01:15:21.080 --> 01:15:22.320]   - Or it's a little uncomfortable
[01:15:22.320 --> 01:15:24.920]   when that one family member's DNA results
[01:15:24.920 --> 01:15:27.200]   are completely different than everyone else's
[01:15:27.200 --> 01:15:29.280]   and you have to explain that.
[01:15:29.280 --> 01:15:32.360]   - Actually, somebody told me about this.
[01:15:32.360 --> 01:15:35.000]   I think he'd DM'd me on Twitter.
[01:15:35.000 --> 01:15:36.160]   It's somebody I've known for some time.
[01:15:36.160 --> 01:15:38.680]   He said, you gotta be careful.
[01:15:38.680 --> 01:15:40.760]   We did not know my sister was adopted.
[01:15:41.760 --> 01:15:42.760]   - Wow.
[01:15:42.760 --> 01:15:44.080]   (laughing)
[01:15:44.080 --> 01:15:45.680]   - What do you think, my report?
[01:15:45.680 --> 01:15:47.120]   13% Charles Manson.
[01:15:47.120 --> 01:15:48.640]   (laughing)
[01:15:48.640 --> 01:15:51.000]   - No, they don't, they did not know that.
[01:15:51.000 --> 01:15:53.560]   - It's their genetic trait for Charles Manson.
[01:15:53.560 --> 01:15:55.800]   (laughing)
[01:15:55.800 --> 01:15:59.360]   - As you laugh nervous.
[01:15:59.360 --> 01:16:01.620]   (laughing)
[01:16:01.620 --> 01:16:05.280]   - Stay there, Andy, stay there.
[01:16:05.280 --> 01:16:06.600]   (laughing)
[01:16:06.600 --> 01:16:07.440]   - Let's see.
[01:16:07.440 --> 01:16:09.680]   (laughing)
[01:16:09.680 --> 01:16:15.920]   What other stories are big and burbling
[01:16:15.920 --> 01:16:19.360]   in the Apple world today?
[01:16:19.360 --> 01:16:22.600]   We mentioned, there's, Apple gets, by the way,
[01:16:22.600 --> 01:16:25.680]   a very good grade in its gender pay scorecard.
[01:16:25.680 --> 01:16:29.480]   Well, very good grade relative to other Silicon Valley
[01:16:29.480 --> 01:16:30.320]   companies.
[01:16:30.320 --> 01:16:36.920]   A minus for Apple, Facebook a failing grade.
[01:16:36.920 --> 01:16:40.280]   Apple got the highest ratings of all.
[01:16:40.280 --> 01:16:42.720]   Up there with Bank of New York,
[01:16:42.720 --> 01:16:45.440]   Mellon, eBay, JP Morgan, Nike and Starbucks.
[01:16:45.440 --> 01:16:48.680]   But Apple was, these were all A minus.
[01:16:48.680 --> 01:16:52.880]   Adobe B, let's see where Google falls on this list.
[01:16:52.880 --> 01:16:56.080]   Well, it doesn't fall on this list at all.
[01:16:56.080 --> 01:16:59.280]   That's 'cause Google doesn't give up this information.
[01:16:59.280 --> 01:17:00.120]   Where is it?
[01:17:00.120 --> 01:17:01.880]   - Alphabet.
[01:17:01.880 --> 01:17:03.240]   - Oh, look under alphabet.
[01:17:03.240 --> 01:17:04.440]   Oh, it gotta be.
[01:17:04.440 --> 01:17:06.040]   Hey, nice.
[01:17:06.040 --> 01:17:07.760]   All right, I take it back.
[01:17:07.760 --> 01:17:10.080]   - Let's see what Congress has, Congress is scoring.
[01:17:10.080 --> 01:17:11.960]   (laughing)
[01:17:11.960 --> 01:17:13.720]   Whoops, a little bit lower than that.
[01:17:13.720 --> 01:17:16.200]   - Although, congratulations to Tammy Duckworth,
[01:17:16.200 --> 01:17:19.360]   who became the first sitting member of Congress
[01:17:19.360 --> 01:17:22.280]   for Senator to have a baby wall in office.
[01:17:22.280 --> 01:17:23.440]   She just had her baby.
[01:17:23.440 --> 01:17:24.720]   Isn't that great?
[01:17:24.720 --> 01:17:27.600]   11 companies, including Facebook, Oracle and HP,
[01:17:27.600 --> 01:17:31.400]   all failing grades on gender,
[01:17:31.400 --> 01:17:34.840]   how should I put this gender neutrality?
[01:17:34.840 --> 01:17:37.480]   Gender pay actually, equal pay.
[01:17:37.480 --> 01:17:39.320]   So it's not how many women work there.
[01:17:39.320 --> 01:17:41.500]   It's how the pay works out.
[01:17:41.500 --> 01:17:45.240]   - Right, so then that kind of calls into question
[01:17:45.240 --> 01:17:47.640]   of a lot of other things of what exactly
[01:17:47.640 --> 01:17:50.440]   is this scorecard about.
[01:17:50.440 --> 01:17:53.800]   I think it's great to see the equality and pay.
[01:17:53.800 --> 01:17:57.880]   But if you have seven women working at your company,
[01:17:57.880 --> 01:17:59.680]   and they happen to make the same amount of money
[01:17:59.680 --> 01:18:01.240]   as the seven men in there,
[01:18:01.240 --> 01:18:04.080]   or is the 500 men in the same category?
[01:18:04.080 --> 01:18:06.560]   I'm not sure that's a comfortable environment
[01:18:06.560 --> 01:18:07.800]   for women to work in anyway.
[01:18:07.800 --> 01:18:10.240]   So it's great to see it,
[01:18:10.240 --> 01:18:13.600]   but it doesn't really give us any information
[01:18:13.600 --> 01:18:17.120]   about the company's gender qualities
[01:18:17.120 --> 01:18:19.720]   that's really out there.
[01:18:19.720 --> 01:18:22.720]   So with this particular report,
[01:18:22.720 --> 01:18:27.440]   I kind of take it all with a grain of salt.
[01:18:27.440 --> 01:18:30.040]   I appreciate that there's a lot of companies
[01:18:30.040 --> 01:18:33.600]   that are trying to get equal pay for women on a better scale,
[01:18:33.600 --> 01:18:34.840]   but at the same time,
[01:18:34.840 --> 01:18:39.200]   if let's see,
[01:18:39.200 --> 01:18:45.520]   if Oracle is hiring tens of thousands of women
[01:18:45.520 --> 01:18:52.720]   and the work force is equal men and women on the workforce
[01:18:52.720 --> 01:18:57.360]   and they're doing worse on pay scale.
[01:18:57.360 --> 01:18:59.600]   They're employing tens of thousands of women
[01:18:59.600 --> 01:19:01.480]   instead of only seven, so.
[01:19:01.480 --> 01:19:02.760]   - That's a good point.
[01:19:02.760 --> 01:19:06.080]   I mean, you shouldn't have to pick one or the other.
[01:19:06.080 --> 01:19:10.040]   Obviously, you should have equal pay and gender diversity,
[01:19:10.040 --> 01:19:12.560]   but it sounds like you're saying gender diversity
[01:19:12.560 --> 01:19:16.040]   might be more important if you really don't hire women.
[01:19:16.040 --> 01:19:19.040]   - I think being a woman.
[01:19:19.040 --> 01:19:20.520]   - Yeah.
[01:19:20.520 --> 01:19:21.360]   You've been there.
[01:19:21.360 --> 01:19:24.280]   - When I'm in environments where I'm the only woman
[01:19:24.280 --> 01:19:26.440]   and I do see that a lot,
[01:19:26.440 --> 01:19:30.240]   I'm in a band, so I'm in the music scene
[01:19:30.240 --> 01:19:34.080]   and the scene circles that I run in are dominated by men
[01:19:34.080 --> 01:19:37.920]   and my band is somewhat popular in my local area,
[01:19:37.920 --> 01:19:39.720]   but I feel uncomfortable.
[01:19:39.720 --> 01:19:40.560]   - Yeah.
[01:19:40.560 --> 01:19:42.560]   - It kind of doesn't matter to me
[01:19:42.560 --> 01:19:45.440]   that I'm on equal footing with the other men
[01:19:45.440 --> 01:19:47.360]   that play music in my scene
[01:19:47.360 --> 01:19:51.720]   because I'm one of one woman in a crowd of hundreds.
[01:19:51.720 --> 01:19:55.960]   And yes, equal pay is a great thing,
[01:19:55.960 --> 01:19:58.840]   but it's also, it needs to be taken in consideration
[01:19:58.840 --> 01:20:01.280]   how we feel about the environment that we're working in
[01:20:01.280 --> 01:20:04.120]   and if there's women that don't feel safe or comfortable
[01:20:04.120 --> 01:20:07.600]   or just don't feel like they're,
[01:20:07.600 --> 01:20:12.160]   that they are an equal in a work environment
[01:20:12.160 --> 01:20:13.440]   where they're dominated by men,
[01:20:13.440 --> 01:20:16.040]   even if their pay is equal or higher,
[01:20:16.040 --> 01:20:19.160]   there's something to be said for the cultural kind of vibe
[01:20:19.160 --> 01:20:20.440]   that goes on.
[01:20:20.440 --> 01:20:23.720]   - I don't know what the proportion of engineers
[01:20:23.720 --> 01:20:24.760]   at Apple are female,
[01:20:24.760 --> 01:20:28.440]   but Apple I think has pretty good gender representation
[01:20:28.440 --> 01:20:31.240]   across all the fields.
[01:20:31.240 --> 01:20:34.280]   - They can't remember the report, but they do.
[01:20:34.280 --> 01:20:39.280]   There's been multiple reports that have kind of addressed
[01:20:39.280 --> 01:20:42.960]   Apple's determination to be a more diverse
[01:20:42.960 --> 01:20:45.040]   and equal opportunity company.
[01:20:45.040 --> 01:20:47.200]   So we know that specifically about Apple,
[01:20:47.200 --> 01:20:49.800]   but we're also, you know, there's a long list here
[01:20:49.800 --> 01:20:51.120]   or actually it's not that long,
[01:20:51.120 --> 01:20:54.840]   what is our 23 or 33 companies.
[01:20:54.840 --> 01:20:57.880]   I don't know the details of the rest of the companies.
[01:20:57.880 --> 01:21:00.440]   I can speak to the information I know about Apple,
[01:21:00.440 --> 01:21:02.000]   which it does seem like they're trying,
[01:21:02.000 --> 01:21:07.000]   but is Google trying as hard as Apple?
[01:21:07.000 --> 01:21:08.600]   Is Starbuck trying as hard as Apple?
[01:21:08.600 --> 01:21:10.000]   You know, I don't know.
[01:21:10.000 --> 01:21:13.240]   This information is only based on pay scale
[01:21:13.240 --> 01:21:14.880]   for the employees that are there.
[01:21:14.880 --> 01:21:18.840]   - Apple did a diversity and inclusion report last year.
[01:21:18.840 --> 01:21:23.840]   They said 29% of the leadership at Apple was female.
[01:21:23.840 --> 01:21:26.680]   That's lower than an Auduby,
[01:21:26.680 --> 01:21:30.480]   but it is an increase of one point of year over year.
[01:21:30.480 --> 01:21:33.120]   39% of leaders under 30 are women,
[01:21:33.120 --> 01:21:35.840]   so that shows that more diversity is on its way.
[01:21:35.840 --> 01:21:40.040]   It's 50% of the new hires are from underrepresented groups
[01:21:40.040 --> 01:21:42.240]   in tech that doesn't just include women,
[01:21:42.240 --> 01:21:44.160]   it includes African-Americans, Hispanic,
[01:21:44.160 --> 01:21:45.440]   Native American and Native Hawaiian
[01:21:45.440 --> 01:21:47.000]   and other Pacific Islanders.
[01:21:47.000 --> 01:21:48.720]   So you know what, this is one thing.
[01:21:48.720 --> 01:21:51.600]   If nothing else, you've got a credit Tim Cook
[01:21:51.600 --> 01:21:53.880]   with really working hard to make sure
[01:21:53.880 --> 01:21:56.320]   that Apple is a diverse workforce,
[01:21:56.320 --> 01:21:57.840]   is a compassionate workforce,
[01:21:57.840 --> 01:22:00.880]   and Apple itself is a compassionate company.
[01:22:00.880 --> 01:22:02.880]   I think he's really done a good job with that.
[01:22:02.880 --> 01:22:04.240]   - And there's also something to be said
[01:22:04.240 --> 01:22:08.920]   for this sort of education project that Apple is taking on,
[01:22:08.920 --> 01:22:11.360]   that they're trying to get children involved
[01:22:11.360 --> 01:22:15.000]   and somebody my age, women my age,
[01:22:15.000 --> 01:22:17.440]   didn't have the same opportunities to get into tech
[01:22:17.440 --> 01:22:21.280]   or we're not encouraged by people older than us
[01:22:21.280 --> 01:22:22.200]   to get into tech.
[01:22:22.200 --> 01:22:24.720]   And now that has changed completely.
[01:22:24.720 --> 01:22:28.120]   And I think coding and education is a great opportunity
[01:22:28.120 --> 01:22:31.960]   to get young girls excited about science and math
[01:22:31.960 --> 01:22:33.240]   and computers.
[01:22:33.240 --> 01:22:34.800]   And then as they get older,
[01:22:34.800 --> 01:22:38.240]   that's they start thinking of those as possible career moves,
[01:22:38.240 --> 01:22:41.360]   whereas people my age, that wasn't even a thing.
[01:22:41.360 --> 01:22:45.240]   The only guys in basements were getting jobs
[01:22:45.240 --> 01:22:46.480]   in the tech world, you know?
[01:22:46.480 --> 01:22:49.880]   And I think there's two steps.
[01:22:49.880 --> 01:22:54.560]   Step one, make your company welcoming for women to be in.
[01:22:54.560 --> 01:22:58.400]   And step two, teach our children that it doesn't matter
[01:22:58.400 --> 01:22:59.680]   what your gender identity is,
[01:22:59.680 --> 01:23:01.680]   that you're welcome to this industry.
[01:23:01.680 --> 01:23:04.680]   And I think as generations move on,
[01:23:04.680 --> 01:23:07.080]   we're gonna see a lot more diversity in companies,
[01:23:07.080 --> 01:23:09.400]   especially the ones that have been starting now
[01:23:09.400 --> 01:23:12.320]   or starting before now to get more diversity
[01:23:12.320 --> 01:23:13.680]   in their organizations.
[01:23:13.680 --> 01:23:16.120]   - Apple, according to its report from last year
[01:23:16.120 --> 01:23:18.440]   in the tech sector, the tech fields,
[01:23:18.440 --> 01:23:21.080]   the tech jobs at Apple, 77% male.
[01:23:21.080 --> 01:23:22.760]   So there's the problem right there.
[01:23:22.760 --> 01:23:24.880]   It's up a little bit over the last few years,
[01:23:24.880 --> 01:23:26.280]   but not by much.
[01:23:26.280 --> 01:23:29.320]   It really is a male dominated field.
[01:23:29.320 --> 01:23:30.160]   We gotta change that.
[01:23:30.160 --> 01:23:31.520]   'Cause I'll tell you what, it's a big difference
[01:23:31.520 --> 01:23:36.520]   in the quality and the variety of software that you get.
[01:23:36.520 --> 01:23:39.160]   And so forth, you know?
[01:23:39.160 --> 01:23:41.480]   - It's just a better, really,
[01:23:41.480 --> 01:23:43.640]   I don't know why anybody would not want that.
[01:23:43.640 --> 01:23:44.480]   - Yeah.
[01:23:44.480 --> 01:23:47.840]   - And there's very little that says disappointing
[01:23:47.840 --> 01:23:50.040]   as a user of a certain company's products
[01:23:50.040 --> 01:23:52.520]   to find out that they have this culture
[01:23:52.520 --> 01:23:56.280]   of simply accepting, not only lack of diversity,
[01:23:56.280 --> 01:23:58.080]   but lack of opportunity.
[01:23:58.080 --> 01:23:59.800]   Google is facing a bunch of class action
[01:23:59.800 --> 01:24:02.200]   series related to gender gaps.
[01:24:02.200 --> 01:24:03.560]   They're not all related to pay.
[01:24:03.560 --> 01:24:08.560]   One of them is as caustic as two engineers
[01:24:08.560 --> 01:24:11.840]   with the same experience, the exact same background,
[01:24:11.840 --> 01:24:15.840]   the male engineer is being hired into a track
[01:24:15.840 --> 01:24:18.200]   that could lead that person into becoming
[01:24:18.200 --> 01:24:20.400]   higher management or even senior executives,
[01:24:20.400 --> 01:24:23.520]   whereas the female engineer is being hired into a track
[01:24:23.520 --> 01:24:26.920]   that sort of limits them at a customer service role
[01:24:26.920 --> 01:24:30.520]   or at basically a emergency response role.
[01:24:30.520 --> 01:24:35.520]   So I love it when a company is smart enough
[01:24:35.520 --> 01:24:41.720]   and bold enough to say we're gonna make all of our numbers
[01:24:41.720 --> 01:24:46.720]   visible about what the composition of our executive team
[01:24:46.720 --> 01:24:50.640]   is like of our tech team is like,
[01:24:50.640 --> 01:24:51.960]   of all of our teams are like,
[01:24:51.960 --> 01:24:55.800]   because it's not just a PR thing to tell people like me
[01:24:55.800 --> 01:24:57.000]   and people like us.
[01:24:57.000 --> 01:24:59.760]   It also tells people inside their own organization
[01:24:59.760 --> 01:25:01.680]   where the faults lie and where the strengths are.
[01:25:01.680 --> 01:25:03.920]   It also tells people that are considering working
[01:25:03.920 --> 01:25:05.840]   for these companies where the faults are
[01:25:05.840 --> 01:25:06.880]   and where the problems are
[01:25:06.880 --> 01:25:08.880]   and what kind of environment they're getting into.
[01:25:08.880 --> 01:25:13.680]   It really do perceive it as if this is an institutional problem.
[01:25:13.680 --> 01:25:16.920]   It's not, well, thank goodness they fired that one person
[01:25:16.920 --> 01:25:19.320]   who was responsible for all the sexism.
[01:25:19.320 --> 01:25:22.600]   It's no, you have a culture that says it's pretty much okay
[01:25:22.600 --> 01:25:27.600]   to not to basically limit the world of tech
[01:25:27.600 --> 01:25:29.600]   to just like dudes.
[01:25:29.600 --> 01:25:32.400]   - I agree wholeheartedly.
[01:25:32.400 --> 01:25:37.400]   I think it's the transparency and the efforts
[01:25:38.360 --> 01:25:40.320]   of all companies.
[01:25:40.320 --> 01:25:43.360]   I mean, this has to be important to everybody.
[01:25:43.360 --> 01:25:46.440]   And I'm glad to see it.
[01:25:46.440 --> 01:25:51.600]   - What band, what kind of music do you play, Lori?
[01:25:51.600 --> 01:25:57.320]   - Pretty fast and thrashy stuff.
[01:25:57.320 --> 01:25:59.800]   It's like eating this American heart.
[01:25:59.800 --> 01:26:01.120]   (laughing)
[01:26:01.120 --> 01:26:02.560]   Or kind of stuff.
[01:26:02.560 --> 01:26:06.920]   So, yeah, pretty close.
[01:26:06.920 --> 01:26:08.400]   - And what do you play?
[01:26:08.400 --> 01:26:10.200]   - I did get to do a cover show recently
[01:26:10.200 --> 01:26:13.480]   where I got to play bass for an MC5 cover show.
[01:26:13.480 --> 01:26:14.480]   So that was really fun.
[01:26:14.480 --> 01:26:16.760]   - Oh, wow, that's nice.
[01:26:16.760 --> 01:26:19.880]   - Yeah, MC5 songs are so fun to play.
[01:26:19.880 --> 01:26:21.320]   - Wow, that's awesome.
[01:26:21.320 --> 01:26:22.960]   Are they fast?
[01:26:22.960 --> 01:26:25.000]   - Not really, they're just real grooving.
[01:26:25.000 --> 01:26:27.800]   You get to kind of stay on the same notes for a long time
[01:26:27.800 --> 01:26:30.360]   while the guitarist just kind of wails away.
[01:26:30.360 --> 01:26:31.920]   - So you're a bassist.
[01:26:31.920 --> 01:26:35.800]   - I mostly sing, but I also, I can play bass.
[01:26:35.800 --> 01:26:37.720]   I'm not great at it, but I can, yeah.
[01:26:37.720 --> 01:26:40.640]   - Do you want, do you, no, I don't want to invade your privacy.
[01:26:40.640 --> 01:26:43.000]   Do you want to tell us the name of the band or?
[01:26:43.000 --> 01:26:44.760]   - I'm in quite a few bands.
[01:26:44.760 --> 01:26:49.440]   So, Rad, R-A-D is the band that's kind of the most popular,
[01:26:49.440 --> 01:26:52.160]   the one that you can Google search and easily find.
[01:26:52.160 --> 01:26:53.000]   - Nice.
[01:26:53.000 --> 01:26:54.360]   - Although you have to use the word band
[01:26:54.360 --> 01:26:57.840]   'cause, and Sacramento, because Rad is such a general word.
[01:26:57.840 --> 01:26:59.240]   - Okay, yeah.
[01:26:59.240 --> 01:27:01.200]   - And I recently, yeah, that's us.
[01:27:01.200 --> 01:27:02.040]   - There you go.
[01:27:02.040 --> 01:27:04.480]   - And I recently just started, in Sacramento Records,
[01:27:04.480 --> 01:27:07.000]   I'm co-founder with a friend of mine.
[01:27:07.000 --> 01:27:08.360]   We run that record label together.
[01:27:08.360 --> 01:27:09.200]   - Oh, that's neat.
[01:27:09.200 --> 01:27:10.520]   You have a record label.
[01:27:10.520 --> 01:27:13.160]   - Yeah, it's not very big.
[01:27:13.160 --> 01:27:16.080]   We put out a record every couple of years
[01:27:16.080 --> 01:27:18.040]   'cause it's all, we're just doing it ourselves
[01:27:18.040 --> 01:27:20.040]   just for the love of the music.
[01:27:20.040 --> 01:27:21.640]   You know, we try to keep it local
[01:27:21.640 --> 01:27:24.040]   and keep only Sacramento-related bands.
[01:27:24.040 --> 01:27:27.240]   You know, we put out so that, you know,
[01:27:27.240 --> 01:27:29.920]   we kind of share our love of music,
[01:27:29.920 --> 01:27:32.160]   our love of the Sacramento music scene with everybody.
[01:27:32.160 --> 01:27:33.000]   - Very cool.
[01:27:33.000 --> 01:27:35.440]   - Is that you singing there and that beach
[01:27:35.440 --> 01:27:36.280]   that was always-
[01:27:36.280 --> 01:27:37.960]   - You singing loud and fast.
[01:27:37.960 --> 01:27:40.520]   - Yeah, and the funny thing is, yeah, that's me.
[01:27:40.520 --> 01:27:41.360]   Yeah.
[01:27:41.360 --> 01:27:43.160]   (laughing)
[01:27:43.160 --> 01:27:45.080]   The picture of us,
[01:27:45.080 --> 01:27:47.120]   this are most recent split seven inch.
[01:27:47.120 --> 01:27:50.920]   So that means that we're sharing time with another band.
[01:27:50.920 --> 01:27:53.200]   So we're on one side of a 45 record
[01:27:53.200 --> 01:27:54.960]   and they're on the other side of a 45 record.
[01:27:54.960 --> 01:27:57.400]   We call them seven inches in the punk rock world.
[01:27:57.400 --> 01:27:58.880]   (laughing)
[01:27:58.880 --> 01:28:01.800]   The reason that, out of that seven inch happened
[01:28:01.800 --> 01:28:05.200]   is because somebody took a picture of me
[01:28:05.200 --> 01:28:06.720]   screaming into the microphone.
[01:28:06.720 --> 01:28:07.560]   That's it.
[01:28:07.560 --> 01:28:08.400]   - Oh.
[01:28:08.400 --> 01:28:10.760]   - That's a friend of mine who is a drummer
[01:28:10.760 --> 01:28:12.520]   and the other band is on the other side.
[01:28:12.520 --> 01:28:13.920]   - She was scared.
[01:28:13.920 --> 01:28:14.760]   - Yeah.
[01:28:14.760 --> 01:28:17.000]   So we made this record because of that song,
[01:28:17.000 --> 01:28:19.680]   The Cresance, which is, she's the drummer for The Cresance.
[01:28:19.680 --> 01:28:22.320]   The whole thing happened because of that picture,
[01:28:22.320 --> 01:28:23.760]   which I thought was hilarious.
[01:28:23.760 --> 01:28:26.600]   - You know, it's funny, but it kind of reminds me
[01:28:26.600 --> 01:28:29.800]   of a picture I took in the Galapagos.
[01:28:29.800 --> 01:28:32.720]   It looks very similar.
[01:28:32.720 --> 01:28:35.720]   (laughing)
[01:28:35.720 --> 01:28:37.920]   - Yeah, that's about me right there.
[01:28:37.920 --> 01:28:38.960]   - Yeah.
[01:28:38.960 --> 01:28:41.960]   That's a seal yelling at a flightless car,
[01:28:41.960 --> 01:28:43.960]   but it looks exactly like Lori.
[01:28:43.960 --> 01:28:44.800]   (laughing)
[01:28:44.800 --> 01:28:46.560]   That's the cover of your first 10 inch.
[01:28:46.560 --> 01:28:47.920]   (laughing)
[01:28:47.920 --> 01:28:48.760]   - Yep.
[01:28:48.760 --> 01:28:50.560]   Oh, definitely, definitely.
[01:28:50.560 --> 01:28:53.160]   (laughing)
[01:28:53.160 --> 01:28:54.560]   - Oh my God, I love it.
[01:28:54.560 --> 01:28:57.400]   Well, it's nice to have two musicians.
[01:28:57.400 --> 01:28:59.120]   - I know, Jim, you and I should get together
[01:28:59.120 --> 01:28:59.960]   and jam out.
[01:28:59.960 --> 01:29:00.800]   - No kidding.
[01:29:00.800 --> 01:29:01.640]   - I know, right?
[01:29:01.640 --> 01:29:03.320]   - And Andy and I'll just go watch TV.
[01:29:03.320 --> 01:29:08.000]   Speaking of which, big news in the Apple world, Apple,
[01:29:08.000 --> 01:29:10.040]   you know, we've been taught, this is really interesting
[01:29:10.040 --> 01:29:15.040]   what's happening in the world of, you know, peak television.
[01:29:15.040 --> 01:29:19.320]   We talked yesterday about Amazon spending,
[01:29:19.320 --> 01:29:21.280]   well, was it a quarter of a billion dollars
[01:29:21.280 --> 01:29:23.840]   to get the Lord of the Rings TV show?
[01:29:23.840 --> 01:29:28.880]   And they've committed to five years, five seasons of this,
[01:29:28.880 --> 01:29:30.520]   roughly a billion dollars.
[01:29:30.520 --> 01:29:35.320]   Apple has snagged a TV adaptation of Isaac Asimov's
[01:29:35.320 --> 01:29:39.040]   great science fiction series, Foundation,
[01:29:39.040 --> 01:29:41.480]   which seems to have an infinite number of books in it,
[01:29:41.480 --> 01:29:45.880]   by the way, is, there are many foundations stories,
[01:29:45.880 --> 01:29:48.280]   but that would be a, if it's done well,
[01:29:48.280 --> 01:29:50.320]   it will be headed by David S. Goyer,
[01:29:50.320 --> 01:29:51.920]   he's the guy who did "Blade",
[01:29:51.920 --> 01:29:54.320]   Batman Begins in the Dark Knight,
[01:29:54.320 --> 01:29:57.000]   Josh Friedman, who's War of the World's Terminator,
[01:29:57.000 --> 01:30:00.120]   Sarah Connor Chronicles and Avatar 2.
[01:30:00.120 --> 01:30:02.320]   That's a pretty good pair of people.
[01:30:02.320 --> 01:30:06.320]   It's funny because it's hard to do,
[01:30:06.320 --> 01:30:09.600]   apparently Fox, Warner Brothers, Sony and HBO
[01:30:09.600 --> 01:30:12.720]   have all tried and failed to do foundation.
[01:30:12.720 --> 01:30:13.560]   (laughs)
[01:30:13.560 --> 01:30:18.560]   So this is gonna be an ambitious project for Apple.
[01:30:18.560 --> 01:30:20.240]   That's pretty exciting.
[01:30:20.240 --> 01:30:21.480]   - Hopefully it's an environment
[01:30:21.480 --> 01:30:23.360]   which it can finally succeed,
[01:30:23.360 --> 01:30:27.240]   because there's, a lot of those old classics,
[01:30:27.240 --> 01:30:29.160]   there are people that have such,
[01:30:29.160 --> 01:30:31.840]   I don't wanna say inbred,
[01:30:31.840 --> 01:30:34.280]   but such as science fiction fan inbreeding,
[01:30:34.280 --> 01:30:36.760]   idea of what it absolutely must be,
[01:30:36.760 --> 01:30:38.840]   that they're not willing to make it into,
[01:30:38.840 --> 01:30:42.160]   realizing that Asimov did not write a TV screenplay
[01:30:42.160 --> 01:30:44.360]   or a movie screenplay, he wrote a novel.
[01:30:44.360 --> 01:30:46.880]   And now if you turn the novel into a screenplay,
[01:30:46.880 --> 01:30:48.360]   you have to make certain adjustments
[01:30:48.360 --> 01:30:49.920]   so that people can actually follow it.
[01:30:49.920 --> 01:30:51.280]   And furthermore, if you're gonna spend
[01:30:51.280 --> 01:30:52.720]   half a billion dollars on this,
[01:30:52.720 --> 01:30:56.600]   you can't just make it for the diminishing
[01:30:56.600 --> 01:31:00.160]   herd of aging 1916 science fiction readers.
[01:31:00.160 --> 01:31:03.800]   - Exactly, if you're only making this for the Asimov fans,
[01:31:03.800 --> 01:31:06.840]   you definitely have a limited audience, that's so true.
[01:31:06.840 --> 01:31:08.600]   - This is, go ahead.
[01:31:08.600 --> 01:31:11.080]   Most of them are on retirement income at this point.
[01:31:11.080 --> 01:31:14.880]   They're borrowing their nieces, their nephews,
[01:31:14.880 --> 01:31:17.960]   like HBO codes to watch TV at this point.
[01:31:17.960 --> 01:31:20.040]   - This is, I think today, or yesterday,
[01:31:20.040 --> 01:31:22.040]   it was the 50th anniversary of the release
[01:31:22.040 --> 01:31:24.680]   of 2001.
[01:31:24.680 --> 01:31:29.680]   And there's a great piece talking about
[01:31:29.680 --> 01:31:33.040]   the difficult relationship between Stanley Kubrick
[01:31:33.040 --> 01:31:35.280]   and Arthur C. Clarke.
[01:31:35.280 --> 01:31:38.920]   They were writing the book while he was making the movie.
[01:31:38.920 --> 01:31:43.880]   And Clarke was very unhappy with what Kubrick was doing.
[01:31:43.880 --> 01:31:47.760]   In fact, there's a story that during the first screening
[01:31:47.760 --> 01:31:49.920]   of the movie, Arthur C. Clarke left at the intermission
[01:31:49.920 --> 01:31:52.240]   in tears.
[01:31:52.240 --> 01:31:58.240]   So it's a long, difficult road to make science fiction
[01:31:58.240 --> 01:32:01.960]   into something like a movie or a television show.
[01:32:01.960 --> 01:32:02.800]   It's hard to do.
[01:32:02.800 --> 01:32:04.240]   - I think when it comes--
[01:32:04.240 --> 01:32:05.600]   - Go ahead. - And you've also won the movie
[01:32:05.600 --> 01:32:08.320]   in 2001, the novel are both brilliant.
[01:32:08.320 --> 01:32:10.120]   - Oh, yeah, but very different, yeah.
[01:32:10.120 --> 01:32:11.160]   Go ahead, Laurie.
[01:32:11.160 --> 01:32:13.440]   - When it comes to science fiction, especially,
[01:32:13.440 --> 01:32:17.600]   the key is that the screenwriters, the directors,
[01:32:17.600 --> 01:32:19.720]   they have to love the genre.
[01:32:19.720 --> 01:32:22.560]   And if you love the genre, then you're going to make
[01:32:22.560 --> 01:32:25.280]   a good movie, you're gonna make a good TV show.
[01:32:25.280 --> 01:32:28.360]   The key is just that they have to understand
[01:32:28.360 --> 01:32:32.200]   the little nuances that sci-fi is a genre
[01:32:32.200 --> 01:32:37.200]   and it used to be kind of a C or B level genre at best.
[01:32:37.200 --> 01:32:42.320]   And it just recently has grown to be more popular
[01:32:42.320 --> 01:32:44.560]   amongst just general audiences.
[01:32:44.560 --> 01:32:49.000]   But especially when it comes to asthma, fans of sci-fi
[01:32:49.000 --> 01:32:51.440]   in general, they're gonna pick out a part,
[01:32:51.440 --> 01:32:55.200]   a TV show or a movie that's based in science fiction
[01:32:55.200 --> 01:32:57.960]   no matter who wrote the original story.
[01:32:57.960 --> 01:33:00.960]   So if you just, if you love the genre,
[01:33:00.960 --> 01:33:04.120]   you're going to present something that fans
[01:33:04.120 --> 01:33:05.840]   of the genre are gonna appreciate.
[01:33:05.840 --> 01:33:07.240]   That's kind of the key.
[01:33:07.240 --> 01:33:10.240]   - So what you're saying is that David Lynch hated Dune.
[01:33:10.240 --> 01:33:11.080]   (laughing)
[01:33:11.080 --> 01:33:11.920]   - Hated.
[01:33:11.920 --> 01:33:12.760]   - Hated.
[01:33:14.000 --> 01:33:16.080]   - Red iPhone, are we all excited?
[01:33:16.080 --> 01:33:17.440]   We kind of knew this would happen.
[01:33:17.440 --> 01:33:20.680]   I wish that they had made it available for the iPhone X.
[01:33:20.680 --> 01:33:23.080]   It's only the iPhone 8.
[01:33:23.080 --> 01:33:23.920]   - 8, yeah.
[01:33:23.920 --> 01:33:26.000]   - That's where Renee is right now.
[01:33:26.000 --> 01:33:26.840]   - Yeah.
[01:33:26.840 --> 01:33:28.760]   - Taking a briefing on the red iPhone.
[01:33:28.760 --> 01:33:30.840]   This is product red, which means it raises money
[01:33:30.840 --> 01:33:32.680]   for AIDS research, of course.
[01:33:32.680 --> 01:33:36.400]   And they did one thing right, I think.
[01:33:36.400 --> 01:33:41.040]   They put the glass face on the red iPhone 8 is black,
[01:33:41.040 --> 01:33:42.240]   not white.
[01:33:42.240 --> 01:33:44.040]   People complained about last year's iPhone,
[01:33:44.040 --> 01:33:46.160]   red iPhone 7 looked like a candy cane.
[01:33:46.160 --> 01:33:49.200]   This is a little bit best.
[01:33:49.200 --> 01:33:50.720]   - You know what though?
[01:33:50.720 --> 01:33:53.800]   People are gonna complain this year that it's black.
[01:33:53.800 --> 01:33:55.800]   There's always gonna be.
[01:33:55.800 --> 01:33:56.800]   - Yeah, I know.
[01:33:56.800 --> 01:33:58.440]   You can order it today.
[01:33:58.440 --> 01:34:02.600]   It'll be shipping Friday, day after tomorrow.
[01:34:02.600 --> 01:34:06.640]   699 for the 64 gig, 799 for an 8 plus,
[01:34:06.640 --> 01:34:09.720]   64 gig 8 and 799 for the 8 plus.
[01:34:11.040 --> 01:34:12.360]   - Anybody gonna buy one?
[01:34:12.360 --> 01:34:15.160]   - I love the red ones, but I can't imagine spending
[01:34:15.160 --> 01:34:16.560]   buying a whole new phone just for that.
[01:34:16.560 --> 01:34:21.120]   - I really do love the red ones and everything
[01:34:21.120 --> 01:34:22.680]   that it stands for.
[01:34:22.680 --> 01:34:23.520]   - Yep.
[01:34:23.520 --> 01:34:28.360]   - But this time, the iPhone X is really where I'm at.
[01:34:28.360 --> 01:34:29.200]   - Me too.
[01:34:29.200 --> 01:34:30.040]   - Me too.
[01:34:30.040 --> 01:34:33.480]   It would be tough to go back.
[01:34:33.480 --> 01:34:35.960]   - I completely agree with you.
[01:34:35.960 --> 01:34:38.360]   We were talking earlier with Michael Sargent,
[01:34:38.360 --> 01:34:41.400]   your colleague at Mobile Nations, Lori.
[01:34:41.400 --> 01:34:45.560]   He hosted iOS today 'cause Megan was out and Mike is great.
[01:34:45.560 --> 01:34:48.240]   And we were talking about this problem that Apple's facing,
[01:34:48.240 --> 01:34:50.120]   which is that they've got a user,
[01:34:50.120 --> 01:34:53.440]   one user interface for the iPhone X,
[01:34:53.440 --> 01:34:55.320]   the home buttonless iPhone X,
[01:34:55.320 --> 01:34:59.680]   and then another user face for the iPhone 8 and the iPad.
[01:34:59.680 --> 01:35:02.040]   I prefer, frankly, the iPhone X.
[01:35:02.040 --> 01:35:04.920]   I really like it, but I don't know
[01:35:04.920 --> 01:35:07.700]   if this can translate to an iPad, for instance.
[01:35:08.540 --> 01:35:09.380]   - Why not?
[01:35:09.380 --> 01:35:10.220]   - I don't know.
[01:35:10.220 --> 01:35:11.060]   - Go ahead, Lori.
[01:35:11.060 --> 01:35:13.060]   - It's all about the gestures.
[01:35:13.060 --> 01:35:17.140]   The reason, I completely understand what you're talking about,
[01:35:17.140 --> 01:35:21.060]   the comfort level of the user interface of the iPhone X,
[01:35:21.060 --> 01:35:23.060]   it's the gestures.
[01:35:23.060 --> 01:35:26.580]   Our brains adapt to that so much faster.
[01:35:26.580 --> 01:35:27.420]   - Very natural, yeah.
[01:35:27.420 --> 01:35:28.260]   - Yeah.
[01:35:28.260 --> 01:35:29.500]   It surprised me even.
[01:35:29.500 --> 01:35:34.500]   I thought it was gonna be hard to get used to the iPhone X gestures.
[01:35:34.500 --> 01:35:38.300]   And after not even a week, not only was I super comfortable
[01:35:38.300 --> 01:35:41.100]   with the way you interact with the interface,
[01:35:41.100 --> 01:35:45.700]   I found button-based iPhones to be really frustrating.
[01:35:45.700 --> 01:35:49.660]   It seems so much, it just makes more sense
[01:35:49.660 --> 01:35:52.700]   to what my brain thinks I should do next,
[01:35:52.700 --> 01:35:57.700]   whereas when you're using an iPad or iPhone 8 or iPhone 7,
[01:35:57.700 --> 01:36:02.100]   it feels limiting.
[01:36:02.100 --> 01:36:05.860]   - My brain has to be jarred into remembering what to do
[01:36:05.860 --> 01:36:09.460]   as opposed to just naturally doing what kind of happens
[01:36:09.460 --> 01:36:12.260]   when I'm using a gesture-based iPhone X.
[01:36:12.260 --> 01:36:15.860]   - So you'd vote for the 10 to become the future of iOS.
[01:36:15.860 --> 01:36:20.660]   - Absolutely, I would love Apple to be able to allow that
[01:36:20.660 --> 01:36:23.980]   into the future phones and tablets, for sure.
[01:36:23.980 --> 01:36:27.260]   I think it would definitely work across all iOS.
[01:36:27.260 --> 01:36:28.500]   - You agree, Jim?
[01:36:28.500 --> 01:36:29.700]   - Oh, absolutely, yeah.
[01:36:29.700 --> 01:36:31.100]   Yeah.
[01:36:31.100 --> 01:36:32.580]   I don't know why they didn't do it.
[01:36:32.580 --> 01:36:34.140]   They could have done a red 10.
[01:36:34.140 --> 01:36:36.540]   This is the white with Chrome 10.
[01:36:36.540 --> 01:36:38.020]   They could have made that way back.
[01:36:38.020 --> 01:36:39.020]   - I don't know.
[01:36:39.020 --> 01:36:39.940]   - Maybe they will.
[01:36:39.940 --> 01:36:41.940]   I don't know either.
[01:36:41.940 --> 01:36:42.780]   Maybe they will.
[01:36:42.780 --> 01:36:45.580]   Maybe they wanna juice a little bit juice sales of the 8.
[01:36:45.580 --> 01:36:49.100]   - It doesn't matter to them though, as long as they're selling.
[01:36:49.100 --> 01:36:50.740]   - That's true.
[01:36:50.740 --> 01:36:52.940]   I mean, I think they know they'll definitely gonna sell more
[01:36:52.940 --> 01:36:55.820]   of the 8 than they would have a much more expensive phone.
[01:36:55.820 --> 01:36:56.820]   - Yeah.
[01:36:56.820 --> 01:37:00.660]   - And yeah, so if you're raising money for a good cause
[01:37:00.660 --> 01:37:03.260]   better raise more money for a good cause.
[01:37:03.260 --> 01:37:05.340]   I don't know why they couldn't do both though.
[01:37:05.340 --> 01:37:08.620]   But to the earlier points, I just hope that Apple doesn't get
[01:37:08.620 --> 01:37:13.540]   into this sort of dogmatic jag of removing clicky buttons
[01:37:13.540 --> 01:37:17.660]   and physical interface from a device just because
[01:37:17.660 --> 01:37:20.540]   it's just because they don't like physical buttons
[01:37:20.540 --> 01:37:22.300]   and clicky things.
[01:37:22.300 --> 01:37:25.260]   I think that, for instance, with the iPads,
[01:37:25.260 --> 01:37:27.380]   you don't have, you got a lot of room.
[01:37:27.380 --> 01:37:30.660]   You can improve things with things that are tactile.
[01:37:30.660 --> 01:37:32.780]   I still think that one of the big bummers was,
[01:37:32.780 --> 01:37:35.340]   I still to this day missed the fact that you have
[01:37:35.340 --> 01:37:37.980]   a physical switch that can either mute the device
[01:37:37.980 --> 01:37:40.340]   or just simply say, please lock the screen
[01:37:40.340 --> 01:37:42.660]   so you don't keep twisting and turning every time
[01:37:42.660 --> 01:37:44.580]   that I shift on my sofa.
[01:37:44.580 --> 01:37:45.500]   I still miss it.
[01:37:45.500 --> 01:37:47.820]   'Cause I think having some sort of a physical button
[01:37:47.820 --> 01:37:49.980]   that does something that is holistic
[01:37:49.980 --> 01:37:52.100]   to the entire experience, that's a really useful thing
[01:37:52.100 --> 01:37:53.300]   to happen.
[01:37:53.300 --> 01:37:56.380]   So I don't, it's a different, the home button
[01:37:56.380 --> 01:37:59.060]   as a bigger problem, I think, with the iPad though,
[01:37:59.060 --> 01:38:02.540]   because there is something kind of,
[01:38:02.540 --> 01:38:03.660]   wouldn't call it off-putting,
[01:38:03.660 --> 01:38:07.500]   but something green and glowing about the idea of,
[01:38:07.500 --> 01:38:11.380]   well, this button is, because you use the iPad
[01:38:11.380 --> 01:38:13.380]   in horizontal mode and vertical mode
[01:38:13.380 --> 01:38:15.820]   and keep switching them, having such a crucial interface
[01:38:15.820 --> 01:38:19.100]   element that switches its position relative
[01:38:19.100 --> 01:38:21.220]   to the orientation of the screen,
[01:38:21.220 --> 01:38:23.460]   yeah, maybe that's something that you can think,
[01:38:23.460 --> 01:38:26.660]   oh, just a little bit offended by that
[01:38:26.660 --> 01:38:28.620]   as a designer and perhaps we should fix that.
[01:38:28.620 --> 01:38:31.020]   But I hope that, I think that the best interface
[01:38:31.020 --> 01:38:35.540]   is a combination of tactile and virtual.
[01:38:35.540 --> 01:38:40.540]   I'd love to see them make it as great as a combination,
[01:38:40.540 --> 01:38:43.020]   excuse me, greater as a combination
[01:38:43.020 --> 01:38:45.260]   than it would as simply one or the other.
[01:38:45.260 --> 01:38:49.460]   - Boy, I'm impressed Epic Games is making some money
[01:38:49.460 --> 01:38:53.460]   on Fortnite released to the public on iOS
[01:38:53.460 --> 01:38:55.140]   a couple of weeks ago.
[01:38:55.140 --> 01:38:59.060]   It's now making close to $2 million a day,
[01:38:59.060 --> 01:39:01.860]   and it's a free game, $2 million a day
[01:39:01.860 --> 01:39:04.620]   in just like costumes.
[01:39:04.620 --> 01:39:06.780]   (laughing)
[01:39:06.780 --> 01:39:08.660]   - Yeah, it's not even like how to play,
[01:39:08.660 --> 01:39:11.020]   it's just cosmetic stuff.
[01:39:11.020 --> 01:39:15.580]   - Yeah, on digital goods, as they call it.
[01:39:15.580 --> 01:39:18.020]   Kind of impressive.
[01:39:19.340 --> 01:39:22.660]   - Well, this is why I really, I want Tim to break it down.
[01:39:22.660 --> 01:39:25.180]   Whenever he starts off WWDC,
[01:39:25.180 --> 01:39:27.060]   I was saying last quarter alone,
[01:39:27.060 --> 01:39:31.220]   we paid out over $800,000,000 to developers.
[01:39:31.220 --> 01:39:34.140]   It's okay, how much of this went to the,
[01:39:34.140 --> 01:39:36.380]   like the kitchen table developer team
[01:39:36.380 --> 01:39:40.180]   that produced this really cool and useful utility
[01:39:40.180 --> 01:39:43.020]   versus how much was a new hat for a Pokemon?
[01:39:43.020 --> 01:39:44.620]   (laughing)
[01:39:44.620 --> 01:39:46.500]   - Actually, one of the very popular things
[01:39:46.500 --> 01:39:51.100]   on Fortnite for sale is dance moves
[01:39:51.100 --> 01:39:52.380]   to give your character.
[01:39:52.380 --> 01:39:56.180]   - Yeah, what kind of, so I remember doing this
[01:39:56.180 --> 01:39:57.780]   when I would play World of Warcraft,
[01:39:57.780 --> 01:39:59.860]   but I haven't actually played Fortnite.
[01:39:59.860 --> 01:40:04.140]   So my guess is, can you buy certain famous--
[01:40:04.140 --> 01:40:05.940]   - They're taunts.
[01:40:05.940 --> 01:40:07.380]   - Okay, yeah, yes.
[01:40:07.380 --> 01:40:10.860]   - It's to taunt the person you just killed,
[01:40:10.860 --> 01:40:12.220]   stand over them and go.
[01:40:12.220 --> 01:40:15.140]   (laughing)
[01:40:15.140 --> 01:40:17.300]   - So can you buy like the Nicki Minaj dance moves?
[01:40:17.300 --> 01:40:19.100]   - I haven't seen that, can you dab?
[01:40:19.100 --> 01:40:20.220]   I don't know, you know.
[01:40:20.220 --> 01:40:21.060]   - Yeah, yeah.
[01:40:21.060 --> 01:40:22.220]   - Yeah, that would be kind of fun.
[01:40:22.220 --> 01:40:23.700]   Fortnite is an awesome game.
[01:40:23.700 --> 01:40:26.780]   I'm a big fan, terrible at it though.
[01:40:26.780 --> 01:40:28.260]   It has several different modes,
[01:40:28.260 --> 01:40:31.060]   but the most popular I would imagine is the,
[01:40:31.060 --> 01:40:32.660]   you know, the Battle Royale mode,
[01:40:32.660 --> 01:40:34.940]   where 100 people drop into this island
[01:40:34.940 --> 01:40:37.660]   and it's the, though you win if you're the last person
[01:40:37.660 --> 01:40:39.260]   to survive, you kill it,
[01:40:39.260 --> 01:40:42.380]   or others have killed everybody else off,
[01:40:42.380 --> 01:40:45.460]   but it's fun and you could build forts.
[01:40:45.460 --> 01:40:47.460]   (laughing)
[01:40:47.460 --> 01:40:48.300]   - So--
[01:40:48.300 --> 01:40:49.300]   - Do you have to pay to build a fort?
[01:40:49.300 --> 01:40:50.620]   - No, no, that's free.
[01:40:50.620 --> 01:40:51.620]   - All of that's free.
[01:40:51.620 --> 01:40:53.660]   It's, you know, it is,
[01:40:53.660 --> 01:40:56.340]   but it has the problem all iOS,
[01:40:56.340 --> 01:40:58.380]   bad, all iOS game ports have,
[01:40:58.380 --> 01:41:01.620]   which is that they're trying to duplicate a controlled,
[01:41:01.620 --> 01:41:04.820]   you know, a device, a gamepad on the screen,
[01:41:04.820 --> 01:41:06.900]   which means the left one is how you steer,
[01:41:06.900 --> 01:41:07.740]   the right one is how,
[01:41:07.740 --> 01:41:09.820]   and that's just, I don't like that interface very much.
[01:41:09.820 --> 01:41:12.340]   It's not a touch native game, let's put it that way.
[01:41:12.340 --> 01:41:15.220]   - Do you play Fortnite on an iPad or do you play it on a--
[01:41:15.220 --> 01:41:18.180]   - I've played it on an iPad, I prefer to play it on my Mac.
[01:41:18.180 --> 01:41:20.740]   It's actually, it really runs well on an iMac Pro.
[01:41:20.740 --> 01:41:23.300]   It's the best game for $4,000.
[01:41:23.300 --> 01:41:25.140]   You got a keyboard, that's right.
[01:41:25.140 --> 01:41:27.180]   Best game ever for a $4,000 computer.
[01:41:27.180 --> 01:41:28.180]   Let me just tell you.
[01:41:28.180 --> 01:41:29.460]   (laughing)
[01:41:29.460 --> 01:41:30.260]   All right, let's take a break.
[01:41:30.260 --> 01:41:31.780]   When we come back,
[01:41:31.780 --> 01:41:34.900]   we will give you your chance to pick anything you want.
[01:41:34.900 --> 01:41:36.140]   I should tell you,
[01:41:36.140 --> 01:41:40.060]   Laurie, that Jim often picks a heavy metal album.
[01:41:40.060 --> 01:41:41.500]   - So-- - Oh, anything we want to--
[01:41:41.500 --> 01:41:45.020]   - Anything you want. - Anything you want.
[01:41:45.020 --> 01:41:46.980]   - Oh boy. - Yeah, that gives the world
[01:41:46.980 --> 01:41:49.660]   is your oyster, we'll get to that in just a second.
[01:41:49.660 --> 01:41:51.020]   And now you know Laurie's thinking,
[01:41:51.020 --> 01:41:52.100]   she's gonna come up with something wacky.
[01:41:52.100 --> 01:41:53.580]   - I know, I know. (laughing)
[01:41:53.580 --> 01:41:56.780]   - By the way, Steve Wozniak has now quit Facebook as well,
[01:41:56.780 --> 01:41:58.740]   just so you know, everybody.
[01:41:58.740 --> 01:42:00.940]   I used to follow Steve, the funny thing is,
[01:42:00.940 --> 01:42:01.780]   (laughing)
[01:42:01.780 --> 01:42:03.460]   I've quit Facebook, Steve's quit Facebook,
[01:42:03.460 --> 01:42:08.340]   but Steve, unlike me, has not quit Face, or Four Square.
[01:42:08.340 --> 01:42:11.420]   So even though you can't follow Steve on Facebook,
[01:42:11.420 --> 01:42:13.380]   you can know that he is the mayor
[01:42:13.380 --> 01:42:15.420]   of the Burger King at Dubai, in Dubai.
[01:42:15.420 --> 01:42:17.620]   So that's, those things are, you know,
[01:42:17.620 --> 01:42:20.300]   he's not completely private now, completely.
[01:42:20.300 --> 01:42:24.580]   Where does, it's the chuck wagon he likes to go to
[01:42:24.580 --> 01:42:27.460]   in a down your way, Jim, isn't it?
[01:42:27.460 --> 01:42:28.420]   Is it the chuck wagon?
[01:42:28.420 --> 01:42:31.260]   What is the restaurant that Woz loves?
[01:42:31.260 --> 01:42:33.620]   - Oh, I have no idea. - It's not a very good restaurant.
[01:42:33.620 --> 01:42:36.780]   (laughing)
[01:42:36.780 --> 01:42:38.820]   It's got a big wagon wheel up front.
[01:42:40.140 --> 01:42:42.060]   That's usually how I define a good restaurant,
[01:42:42.060 --> 01:42:46.180]   either a huge fiberglass cow or a wagon wheel beans.
[01:42:46.180 --> 01:42:47.340]   Guess what, guess what, honey,
[01:42:47.340 --> 01:42:48.900]   we're pulling over for lunch right now.
[01:42:48.900 --> 01:42:50.060]   I don't care for time, I am.
[01:42:50.060 --> 01:42:53.180]   - It's on various road, Jim, going over for lunch.
[01:42:53.180 --> 01:42:54.940]   I think you'll enjoy it.
[01:42:54.940 --> 01:42:56.380]   You might see Woz there.
[01:42:56.380 --> 01:42:57.220]   - You never know?
[01:42:57.220 --> 01:42:58.580]   - If he's not in Dubai.
[01:42:58.580 --> 01:43:01.260]   - Are you sure today brought to you?
[01:43:01.260 --> 01:43:03.420]   Oh, this is bad news.
[01:43:03.420 --> 01:43:07.500]   A week from today, your taxes are due,
[01:43:08.940 --> 01:43:09.900]   at least in the US.
[01:43:09.900 --> 01:43:12.300]   If you're in Canada, you get a little more time.
[01:43:12.300 --> 01:43:15.220]   Jim, do you file in US taxes now
[01:43:15.220 --> 01:43:18.780]   or do you get to file in the Canadian tax system?
[01:43:18.780 --> 01:43:19.860]   - I do everything.
[01:43:19.860 --> 01:43:21.260]   - You pay Canadian taxes.
[01:43:21.260 --> 01:43:22.540]   - I just pay every--
[01:43:22.540 --> 01:43:23.740]   - Everybody gets money.
[01:43:23.740 --> 01:43:24.580]   - Everybody.
[01:43:24.580 --> 01:43:25.420]   - Everybody.
[01:43:25.420 --> 01:43:26.340]   - Everybody.
[01:43:26.340 --> 01:43:29.060]   - I actually, I enjoy doing taxes.
[01:43:29.060 --> 01:43:31.300]   Now, once I found a twit, we had a company
[01:43:31.300 --> 01:43:33.580]   and we have bookkeepers and CPA.
[01:43:33.580 --> 01:43:35.780]   I didn't get to do my taxes anymore.
[01:43:35.780 --> 01:43:38.620]   But just recently, I started doing my mom's taxes
[01:43:38.620 --> 01:43:40.020]   'cause she was paying like 500 bucks
[01:43:40.020 --> 01:43:41.220]   to have somebody prepare a taxes and said,
[01:43:41.220 --> 01:43:43.340]   "Mom, mom, I can do that for you."
[01:43:43.340 --> 01:43:45.100]   And this year I'm doing hers
[01:43:45.100 --> 01:43:46.580]   and I'm doing my daughter's taxes
[01:43:46.580 --> 01:43:48.500]   'cause she got her first job this year.
[01:43:48.500 --> 01:43:51.340]   And I'm gonna invite Abby to come watch
[01:43:51.340 --> 01:43:53.860]   so she knows for a future reference.
[01:43:53.860 --> 01:43:56.420]   Teach a man to pay taxes.
[01:43:56.420 --> 01:43:59.580]   Do a man's taxes, he'll have, he'll be paid for a year.
[01:43:59.580 --> 01:44:02.780]   Teach a man to pay his own taxes.
[01:44:02.780 --> 01:44:03.980]   This isn't gonna work.
[01:44:03.980 --> 01:44:07.740]   TurboTax is the easiest way to do your taxes.
[01:44:07.740 --> 01:44:09.420]   You can file online with confidence
[01:44:09.420 --> 01:44:12.860]   and now with TurboTax Live, it's even better.
[01:44:12.860 --> 01:44:14.620]   You don't have, you're not on your own anymore.
[01:44:14.620 --> 01:44:16.900]   You can now have a personal review of your tax return
[01:44:16.900 --> 01:44:19.900]   with a CPA or an EA that's an enrolled agent
[01:44:19.900 --> 01:44:21.660]   right on your screen.
[01:44:21.660 --> 01:44:24.580]   Quickly connect to a tax expert via one-way video
[01:44:24.580 --> 01:44:25.660]   so they're not looking at you,
[01:44:25.660 --> 01:44:26.700]   even though you're looking at them.
[01:44:26.700 --> 01:44:30.260]   And you can do it by the way, not just for filing the return,
[01:44:30.260 --> 01:44:33.060]   but as often as you need, for answers and advice
[01:44:33.060 --> 01:44:35.700]   on your taxes, there's a boy, the new tax bills
[01:44:35.700 --> 01:44:37.700]   changed a lot of things.
[01:44:37.700 --> 01:44:40.340]   A lot of things, they're up on all the new tax laws
[01:44:40.340 --> 01:44:42.940]   so they can give you advice to going forward.
[01:44:42.940 --> 01:44:45.340]   You can even have the expert review your return
[01:44:45.340 --> 01:44:47.540]   before you file and make any necessary changes.
[01:44:47.540 --> 01:44:50.140]   - This is the new way to do your taxes.
[01:44:50.140 --> 01:44:51.980]   - It's the new way to do your taxes
[01:44:51.980 --> 01:44:54.740]   and it's all backed by 100% accuracy.
[01:44:54.740 --> 01:44:57.740]   Guarantee, I am a huge fan of TurboTax.
[01:44:57.740 --> 01:45:01.020]   I've used it for years and I encourage you to try it.
[01:45:01.020 --> 01:45:02.740]   If you're worried about tax time,
[01:45:02.740 --> 01:45:05.340]   if you just realized, oh my God, I have one week,
[01:45:05.340 --> 01:45:08.860]   TurboTaxLive.com/MacBreak.
[01:45:08.860 --> 01:45:11.300]   Now you can connect with a TurboTax expert today.
[01:45:11.300 --> 01:45:13.900]   TurboTaxLive.com/MacBreak.
[01:45:13.900 --> 01:45:16.260]   We thank them for their support.
[01:45:16.260 --> 01:45:19.060]   It really is, somebody called me in the chat room
[01:45:19.060 --> 01:45:21.300]   and says TurboTax is so easy.
[01:45:21.300 --> 01:45:22.220]   Yes it is.
[01:45:22.220 --> 01:45:26.220]   All right, let's see, at the bottom of the show,
[01:45:26.220 --> 01:45:28.740]   the back of the book, as I call it,
[01:45:28.740 --> 01:45:30.180]   it's time for your picks of the week.
[01:45:30.180 --> 01:45:31.740]   Let's start with Mr. Dowl Rimple.
[01:45:31.740 --> 01:45:32.740]   Jimmy?
[01:45:32.740 --> 01:45:34.340]   - All right.
[01:45:34.340 --> 01:45:38.780]   So you know that I like my hard rock and metal
[01:45:38.780 --> 01:45:39.900]   with some groove.
[01:45:39.900 --> 01:45:42.700]   - And you've always given us great picks.
[01:45:42.700 --> 01:45:45.220]   - It's got to have some groove for me.
[01:45:45.220 --> 01:45:47.500]   So over the weekend,
[01:45:47.500 --> 01:45:51.900]   I was listening to a playlist I actually have on
[01:45:51.900 --> 01:45:55.820]   Apple Music that I made
[01:45:55.820 --> 01:45:57.580]   and it's shared on my profile.
[01:45:57.580 --> 01:46:01.340]   But one of the bands that I had in the playlist,
[01:46:01.340 --> 01:46:03.220]   I had to go listen to more songs
[01:46:03.220 --> 01:46:04.300]   because I just love it.
[01:46:04.300 --> 01:46:06.140]   It's Rob Zombie.
[01:46:06.140 --> 01:46:07.700]   - Oh yeah.
[01:46:07.700 --> 01:46:12.260]   - And they just put out a new live album.
[01:46:12.260 --> 01:46:16.180]   So if you're looking for an album to start with,
[01:46:16.180 --> 01:46:17.500]   with Rob Zombie,
[01:46:17.500 --> 01:46:20.740]   there's an album called Past, Present and Future.
[01:46:20.740 --> 01:46:25.580]   And it's like the greatest hits from White Zombie,
[01:46:25.580 --> 01:46:29.340]   Rob Zombie stuff, some great stuff in there.
[01:46:29.340 --> 01:46:30.860]   And it just grooves.
[01:46:30.860 --> 01:46:35.860]   I mean, Rob and John Five know how to make a song.
[01:46:35.860 --> 01:46:39.660]   So I really enjoyed listening to a lot of this stuff.
[01:46:39.660 --> 01:46:43.980]   Thunder Kiss 65, More Human Than Human is one of my favorites.
[01:46:43.980 --> 01:46:45.540]   I love that song,
[01:46:45.540 --> 01:46:47.100]   More Human Than Human,
[01:46:47.100 --> 01:46:49.180]   just wonderful song,
[01:46:49.180 --> 01:46:50.580]   and Apple Groove.
[01:46:50.580 --> 01:46:54.460]   - Past, so present and future.
[01:46:54.460 --> 01:46:55.300]   - That's it.
[01:46:55.300 --> 01:46:59.300]   Like if you want to get introduced to the Zombie-Oeuvre,
[01:46:59.300 --> 01:47:00.100]   you would go here
[01:47:00.100 --> 01:47:00.940]   and you would get it all.
[01:47:00.940 --> 01:47:02.660]   - That is the album.
[01:47:02.660 --> 01:47:06.180]   Now you can move out from there and get,
[01:47:06.180 --> 01:47:08.820]   all the other albums,
[01:47:08.820 --> 01:47:11.580]   but this is it.
[01:47:11.580 --> 01:47:15.700]   You're gonna get a lot of great music on this album.
[01:47:15.700 --> 01:47:17.460]   - I wanna get-
[01:47:17.460 --> 01:47:21.740]   - I wanna get White Zombie's super sexy swinging sounds.
[01:47:21.740 --> 01:47:24.100]   Well, you can do that too.
[01:47:24.100 --> 01:47:25.820]   - That sounds like my kind of album.
[01:47:25.820 --> 01:47:29.700]   Hey, if people wanna follow you on Apple Music,
[01:47:29.700 --> 01:47:30.540]   can they?
[01:47:30.540 --> 01:47:32.060]   Yeah.
[01:47:32.060 --> 01:47:33.180]   Yeah, I have a,
[01:47:33.180 --> 01:47:37.340]   you just search for me and I'm on Apple Music.
[01:47:37.340 --> 01:47:39.300]   - Just as Jim Dalrymple, there's no-
[01:47:39.300 --> 01:47:40.140]   - Yep.
[01:47:40.140 --> 01:47:42.260]   My profile is open,
[01:47:42.260 --> 01:47:44.340]   so you can see what I'm listening to.
[01:47:44.340 --> 01:47:48.260]   - I'm adding you right now.
[01:47:48.260 --> 01:47:50.660]   - See playlists that I've built.
[01:47:50.660 --> 01:47:52.900]   I have a mellow rock playlist,
[01:47:52.900 --> 01:47:57.900]   you know, with some 70s and some 60s acoustic type music.
[01:47:58.780 --> 01:47:59.780]   - Nice.
[01:47:59.780 --> 01:48:01.900]   - I have a driving playlist,
[01:48:01.900 --> 01:48:04.180]   which is what Rob Zombie is on,
[01:48:04.180 --> 01:48:07.540]   you know, to get me all hyped up when I go out in the car.
[01:48:07.540 --> 01:48:09.940]   - This is one of the best things about Apple Music
[01:48:09.940 --> 01:48:12.020]   is following people who have good taste,
[01:48:12.020 --> 01:48:13.060]   'cause I have none.
[01:48:13.060 --> 01:48:13.900]   - No.
[01:48:13.900 --> 01:48:14.900]   - That's okay.
[01:48:14.900 --> 01:48:16.420]   - That's also one of the most embarrassing things
[01:48:16.420 --> 01:48:19.900]   when you're like known for being a hard punk rocker
[01:48:19.900 --> 01:48:22.100]   and you're listening to like Disney music,
[01:48:22.100 --> 01:48:23.420]   'cause that's what I do.
[01:48:23.420 --> 01:48:26.900]   - I know, days and Sundays always get me down.
[01:48:26.900 --> 01:48:27.900]   - Yep.
[01:48:27.900 --> 01:48:31.900]   - What is your pick of the weekend, the Anako?
[01:48:31.900 --> 01:48:34.900]   - Gee, I'm not, okay, I'm not gonna do it, but--
[01:48:34.900 --> 01:48:36.900]   - Oh, Joe, I want your picks.
[01:48:36.900 --> 01:48:37.900]   - I want your picks.
[01:48:37.900 --> 01:48:38.900]   - No, no, no, no, I just, okay,
[01:48:38.900 --> 01:48:40.900]   I've, the only, I was,
[01:48:40.900 --> 01:48:43.900]   knowing that there's gonna be two really, really cool picks
[01:48:43.900 --> 01:48:45.900]   that I'm gonna have to like write down
[01:48:45.900 --> 01:48:46.900]   because they're gonna be really cool
[01:48:46.900 --> 01:48:49.900]   and probably something I don't play usually.
[01:48:49.900 --> 01:48:53.900]   I will, my musical pick will be the metropolitan opera
[01:48:53.900 --> 01:48:57.900]   production of Jules Massanet's "Centre Yol",
[01:48:57.900 --> 01:49:00.900]   which is the opera based on Cinderella
[01:49:00.900 --> 01:49:01.900]   that I'm gonna be going.
[01:49:01.900 --> 01:49:03.900]   It opens on April 13th,
[01:49:03.900 --> 01:49:06.900]   if you are, if you are near New York City,
[01:49:06.900 --> 01:49:10.900]   realize that usually rush tickets can be had
[01:49:10.900 --> 01:49:12.900]   in the orchestra for 25 bucks.
[01:49:12.900 --> 01:49:14.900]   You just go to the medopera.org website
[01:49:14.900 --> 01:49:19.900]   after noon PM and they put these things on sale.
[01:49:19.900 --> 01:49:21.900]   It's, I bought these, but these tickets,
[01:49:21.900 --> 01:49:24.900]   I actually paid like full price for months in advance
[01:49:24.900 --> 01:49:26.900]   because number one,
[01:49:26.900 --> 01:49:29.900]   chiefly because two of my favorite sopranos are singing in it,
[01:49:29.900 --> 01:49:34.900]   Joyce D'etonato, who is an amazing mezzo,
[01:49:34.900 --> 01:49:36.900]   and also an amazing educator, but oh my goodness,
[01:49:36.900 --> 01:49:38.900]   I just love her voice.
[01:49:38.900 --> 01:49:41.900]   And also another soprano played with fairy godmother,
[01:49:41.900 --> 01:49:45.900]   Kathleen Kim, who I, she doesn't record much unfortunately,
[01:49:45.900 --> 01:49:48.900]   but every time I've seen her performances on YouTube,
[01:49:48.900 --> 01:49:51.900]   they've always really, really amazed me.
[01:49:51.900 --> 01:49:53.900]   So it's a really good looking production.
[01:49:53.900 --> 01:49:55.900]   I've never seen this opera before,
[01:49:55.900 --> 01:49:59.900]   but that was the idea of, again, two people
[01:49:59.900 --> 01:50:01.900]   that I've never seen perform live before
[01:50:01.900 --> 01:50:03.900]   that totally looking forward to.
[01:50:03.900 --> 01:50:06.900]   It doesn't mean I'm paying the top whack of 375 bucks,
[01:50:06.900 --> 01:50:10.900]   but I was able to say, I'm not gonna take the chance
[01:50:10.900 --> 01:50:12.900]   that I can get cheap $25 tickets.
[01:50:12.900 --> 01:50:15.900]   I'm actually spending the spending actual money for this.
[01:50:15.900 --> 01:50:19.900]   So, and if chances are, if you don't get to see it
[01:50:19.900 --> 01:50:23.900]   in New York City, I think that it's gonna be presented in theaters.
[01:50:23.900 --> 01:50:26.900]   Matter of fact, I think it's actually gonna be the Saturday mat
[01:50:26.900 --> 01:50:29.900]   in a performance that I'm seeing on Saturday,
[01:50:29.900 --> 01:50:31.900]   like something like the 28th or something like that.
[01:50:31.900 --> 01:50:33.900]   So you can see it in theaters for 20 bucks,
[01:50:33.900 --> 01:50:37.900]   and it'll probably be on PBS later in the year because most of the,
[01:50:37.900 --> 01:50:39.900]   most of the televised product, excuse me,
[01:50:39.900 --> 01:50:43.900]   most of the simulcast of theaters productions turn out to be
[01:50:43.900 --> 01:50:47.900]   a metropolitan live at the Met or whatever.
[01:50:47.900 --> 01:50:49.900]   Great performances at the Met, I think they called the series.
[01:50:49.900 --> 01:50:51.900]   Definitely gonna be worth watching.
[01:50:51.900 --> 01:50:55.900]   It's not gonna be, I don't believe it's going to be one of those ones
[01:50:55.900 --> 01:50:58.900]   where everybody dies at the end and everybody's sad and dead
[01:50:58.900 --> 01:51:00.900]   and horrible and covered with blood.
[01:51:00.900 --> 01:51:03.900]   I believe that is, I believe this is the fun part of Cinderella,
[01:51:03.900 --> 01:51:05.900]   not the original Grimm's Fairy Tale,
[01:51:05.900 --> 01:51:07.900]   where the evil sisters dance to their death at the wedding
[01:51:07.900 --> 01:51:10.900]   and ironed shoes that are heated to red hot things.
[01:51:10.900 --> 01:51:14.900]   Anyway, so again, if I'm gonna do a music pick,
[01:51:14.900 --> 01:51:18.900]   I'm afraid that that's the very, very well motivated,
[01:51:18.900 --> 01:51:20.900]   but not terrible hit.
[01:51:20.900 --> 01:51:26.900]   So we now have opera and groove rock.
[01:51:26.900 --> 01:51:30.900]   I wonder, whatever could Laurie Gill have for us?
[01:51:30.900 --> 01:51:34.900]   I wasn't planning on picking a music pick.
[01:51:34.900 --> 01:51:36.900]   You don't have to. I'm not picking music.
[01:51:36.900 --> 01:51:41.900]   So over the weekend, I finally saw the Dario Genteau movie,
[01:51:41.900 --> 01:51:44.900]   The Mother of Tears, which is the third in the trilogy
[01:51:44.900 --> 01:51:46.900]   of the Three Mothers.
[01:51:46.900 --> 01:51:49.900]   And so my pick this week is The Three Mothers trilogy
[01:51:49.900 --> 01:51:51.900]   by Dario Genteau.
[01:51:51.900 --> 01:51:54.900]   The first one is Suspiria.
[01:51:54.900 --> 01:51:58.900]   The second one is Inferno, and the third one is The Mother of Tears,
[01:51:58.900 --> 01:52:02.900]   which is actually not that good of a movie, to be honest,
[01:52:02.900 --> 01:52:04.900]   but Suspiria.
[01:52:04.900 --> 01:52:07.900]   What would the genre of these movies be?
[01:52:07.900 --> 01:52:12.900]   They're a horror film, but they're supernatural horror.
[01:52:12.900 --> 01:52:15.900]   The first two, they're all three about witches.
[01:52:15.900 --> 01:52:17.900]   Oh, I love movies about witches.
[01:52:17.900 --> 01:52:21.900]   The first one, Suspiria, is about sort of witchcraft
[01:52:21.900 --> 01:52:26.900]   in a ballet theater, and the second one is even more
[01:52:26.900 --> 01:52:33.900]   confusing with an old home that was a movie on a fire witch.
[01:52:33.900 --> 01:52:35.900]   The first one is that one.
[01:52:35.900 --> 01:52:36.900]   Okay.
[01:52:36.900 --> 01:52:39.900]   They're incredibly beautiful, and they're also really,
[01:52:39.900 --> 01:52:42.900]   really difficult to understand until you get to the movie,
[01:52:42.900 --> 01:52:46.900]   The Mother of Tears, which clarifies so many things
[01:52:46.900 --> 01:52:50.900]   that are completely unexplained in both Suspiria and Inferno.
[01:52:50.900 --> 01:52:54.900]   So Mother of Tears needs to be watched because it makes
[01:52:54.900 --> 01:52:57.900]   Suspiria and Inferno make sense.
[01:52:57.900 --> 01:53:02.900]   So I have to say the trilogy, because if you just watch Inferno,
[01:53:02.900 --> 01:53:05.900]   you might be completely confused by what happened
[01:53:05.900 --> 01:53:09.900]   and you need Mother of Tears to kind of anchor in those first two
[01:53:09.900 --> 01:53:13.900]   movies, even though it's actually not particularly good compared
[01:53:13.900 --> 01:53:14.900]   to the other two.
[01:53:14.900 --> 01:53:16.900]   So this came out in 2007.
[01:53:16.900 --> 01:53:18.900]   We're not talking about a movie in the theaters today.
[01:53:18.900 --> 01:53:21.900]   This is something that can you watch it on Netflix,
[01:53:21.900 --> 01:53:22.900]   or where are you watching?
[01:53:22.900 --> 01:53:23.900]   You can.
[01:53:23.900 --> 01:53:27.900]   Actually, you can rent them on Amazon or Google or iTunes.
[01:53:27.900 --> 01:53:28.900]   Okay.
[01:53:28.900 --> 01:53:29.900]   Yeah.
[01:53:29.900 --> 01:53:31.900]   Oh, I can't wait.
[01:53:31.900 --> 01:53:34.900]   I love, I don't know what it is, my favorite supernatural creature.
[01:53:34.900 --> 01:53:38.900]   I love witches, much better than vampires and zombies.
[01:53:38.900 --> 01:53:43.900]   There's something sort of mysterious about them.
[01:53:43.900 --> 01:53:44.900]   Yeah.
[01:53:44.900 --> 01:53:48.900]   Yeah, they're a little bit, they're dark, but kind of inviting.
[01:53:48.900 --> 01:53:49.900]   Yeah.
[01:53:49.900 --> 01:53:50.900]   Yeah.
[01:53:50.900 --> 01:53:51.900]   Awesome.
[01:53:51.900 --> 01:53:52.900]   Rob Zombie's kind of cool though.
[01:53:52.900 --> 01:53:54.900]   Oh, that's a different kind of zombie.
[01:53:54.900 --> 01:53:55.900]   I like that zombie.
[01:53:55.900 --> 01:54:00.900]   So we got zombies, we got witches, we got opera.
[01:54:00.900 --> 01:54:04.900]   I don't know how I could follow that, but I actually want to give
[01:54:04.900 --> 01:54:05.900]   a little credit.
[01:54:05.900 --> 01:54:08.900]   Somebody tweeted me and reminded me that I should mention this.
[01:54:08.900 --> 01:54:11.900]   I've been, lately I've been taking online courses.
[01:54:11.900 --> 01:54:13.900]   I just took a finished online course on programming.
[01:54:13.900 --> 01:54:14.900]   I'm really enjoying it.
[01:54:14.900 --> 01:54:16.900]   And this is one of the courses that's on my list.
[01:54:16.900 --> 01:54:20.900]   It's the fastest growing course in the history of UC Berkeley,
[01:54:20.900 --> 01:54:25.900]   Foundations of Data Science, and you can take it for free on EDX.
[01:54:25.900 --> 01:54:28.900]   EDX is the platform where I just took a great programming course,
[01:54:28.900 --> 01:54:30.900]   and I've mentioned this before.
[01:54:30.900 --> 01:54:32.900]   But if you want to know more about data science,
[01:54:32.900 --> 01:54:38.900]   Data 8X, the Foundations of Data Science, it is not for computer
[01:54:38.900 --> 01:54:43.900]   scientists particularly, or even for professional programmers.
[01:54:43.900 --> 01:54:46.900]   Now, you notice it says there's $357.
[01:54:46.900 --> 01:54:47.900]   It's free to take it.
[01:54:47.900 --> 01:54:50.900]   It's only if you want to get a certificate, a professional
[01:54:50.900 --> 01:54:52.900]   certificate, would you pay for it.
[01:54:52.900 --> 01:54:54.900]   These are fun courses.
[01:54:54.900 --> 01:54:56.900]   I like the platform, frankly.
[01:54:56.900 --> 01:55:00.900]   I feel like it's an easy to use platform, easy to follow along.
[01:55:00.900 --> 01:55:02.900]   And data science is huge.
[01:55:02.900 --> 01:55:08.900]   So the Foundations of Data Science, they say it started April 2nd,
[01:55:08.900 --> 01:55:10.900]   but that's not how these things work.
[01:55:10.900 --> 01:55:12.900]   You can pick it up and start it anytime you want.
[01:55:12.900 --> 01:55:14.900]   It's just now available as of April 2nd.
[01:55:14.900 --> 01:55:18.900]   The most popular course ever, and this is, boy, I tell you,
[01:55:18.900 --> 01:55:21.900]   this is what I love about the internet.
[01:55:21.900 --> 01:55:24.900]   This is one of the good things about the internet is,
[01:55:24.900 --> 01:55:28.900]   as long as you have internet access and a computer or something,
[01:55:28.900 --> 01:55:30.900]   you can watch your video on.
[01:55:30.900 --> 01:55:36.900]   You can take these college level fantastic courses and learn so much,
[01:55:36.900 --> 01:55:39.900]   and I think you could train yourself to be a computer scientist
[01:55:39.900 --> 01:55:41.900]   in your spare time for free.
[01:55:41.900 --> 01:55:46.900]   This does use Python 3 as the language, which is a pretty darn good
[01:55:46.900 --> 01:55:47.900]   language to learn anyway.
[01:55:47.900 --> 01:55:50.900]   So Foundations of Data Science, Computational Thinking with Python,
[01:55:50.900 --> 01:55:56.900]   it is data 8x, University of California, Berkeley, just released
[01:55:56.900 --> 01:56:00.900]   at edx.org.
[01:56:00.900 --> 01:56:01.900]   So we got everything.
[01:56:01.900 --> 01:56:03.900]   We got everything in here.
[01:56:03.900 --> 01:56:05.900]   Everything.
[01:56:05.900 --> 01:56:07.900]   And if we're there, we'd have a red iPhone too.
[01:56:07.900 --> 01:56:08.900]   (laughter)
[01:56:08.900 --> 01:56:10.900]   Laurie, you are great.
[01:56:10.900 --> 01:56:12.900]   You are coming back.
[01:56:12.900 --> 01:56:13.900]   You're wonderful.
[01:56:13.900 --> 01:56:16.900]   Laurie Giel, Deputy Managing Editor of iMore.
[01:56:16.900 --> 01:56:19.900]   She confided in me, and I'm going to break a conference
[01:56:19.900 --> 01:56:21.900]   at the beginning of the show before we started.
[01:56:21.900 --> 01:56:22.900]   She was a little nervous.
[01:56:22.900 --> 01:56:23.900]   See?
[01:56:23.900 --> 01:56:25.900]   That was nothing to be nervous about.
[01:56:25.900 --> 01:56:26.900]   It was great.
[01:56:26.900 --> 01:56:28.900]   I had a lot of fun chatting with you all.
[01:56:28.900 --> 01:56:29.900]   That was really great.
[01:56:29.900 --> 01:56:30.900]   Thank you so much for being here.
[01:56:30.900 --> 01:56:31.900]   We will see you again soon.
[01:56:31.900 --> 01:56:32.900]   Thank you for having me.
[01:56:32.900 --> 01:56:33.900]   Come in down here.
[01:56:33.900 --> 01:56:35.900]   Yeah, I'll come down and visit.
[01:56:35.900 --> 01:56:36.900]   It'll be great.
[01:56:36.900 --> 01:56:41.900]   Andy Enoco always, always as slice as they say, IHNATKO.com
[01:56:41.900 --> 01:56:46.900]   or IHNATKO.com on the internet on the Twitter, as they say.
[01:56:46.900 --> 01:56:49.900]   I never had that Twitter handle stolen from me because anyone
[01:56:49.900 --> 01:56:53.900]   who tried probably misspelled it and left the actual spelling code
[01:56:53.900 --> 01:56:54.900]   for me.
[01:56:54.900 --> 01:56:55.900]   No, it's not.
[01:56:55.900 --> 01:56:57.900]   I have no idea.
[01:56:57.900 --> 01:57:01.900]   IHNATKO.
[01:57:01.900 --> 01:57:06.900]   And the legendary Jim Dowlrimple, loopinsight.com.
[01:57:06.900 --> 01:57:08.900]   Always wonderful to have you on.
[01:57:08.900 --> 01:57:09.900]   Why is that on?
[01:57:09.900 --> 01:57:10.900]   Double goat.
[01:57:10.900 --> 01:57:11.900]   Wow.
[01:57:11.900 --> 01:57:12.900]   Double goat, baby.
[01:57:12.900 --> 01:57:13.900]   He's got the double goat.
[01:57:13.900 --> 01:57:15.900]   One for each cleft of his beard.
[01:57:15.900 --> 01:57:17.900]   [LAUGHTER]
[01:57:17.900 --> 01:57:18.900]   Always a pleasure.
[01:57:18.900 --> 01:57:19.900]   Hey, thank you all for being here.
[01:57:19.900 --> 01:57:20.900]   We do Mac break weekly.
[01:57:20.900 --> 01:57:23.900]   Every Tuesday, 11 AM Pacific, 2 PM Eastern time.
[01:57:23.900 --> 01:57:25.900]   That's 1800 UTC.
[01:57:25.900 --> 01:57:26.900]   If you want to watch live, please do.
[01:57:26.900 --> 01:57:29.900]   You can do it on our stream, twit.tv/live.
[01:57:29.900 --> 01:57:31.900]   Or you can do it in studio.
[01:57:31.900 --> 01:57:33.900]   We had a nice couple visiting us.
[01:57:33.900 --> 01:57:36.900]   Were you both entranced and intrigued?
[01:57:36.900 --> 01:57:37.900]   No.
[01:57:37.900 --> 01:57:38.900]   Yeah, why not?
[01:57:38.900 --> 01:57:44.900]   I think Joe enjoyed it, but Rachel, you're visiting from Philly today.
[01:57:44.900 --> 01:57:45.900]   Nice to have you both.
[01:57:45.900 --> 01:57:48.900]   If you do want to visit us in studio, we love having a live studio audience.
[01:57:48.900 --> 01:57:50.900]   All you have to do is email tickets at twit.tv.
[01:57:50.900 --> 01:57:52.900]   We'll put a seat out for you.
[01:57:52.900 --> 01:57:57.900]   If you're watching the stream and you've got a computer, you might as well open up the chat
[01:57:57.900 --> 01:57:58.900]   room.
[01:57:58.900 --> 01:58:00.900]   It's a great way to participate.
[01:58:00.900 --> 01:58:02.900]   IRC.twit.tv.
[01:58:02.900 --> 01:58:03.900]   IRC.twit.tv.
[01:58:03.900 --> 01:58:06.900]   And let's see.
[01:58:06.900 --> 01:58:09.900]   If you can't watch live, you can't be here live.
[01:58:09.900 --> 01:58:10.900]   What could you do?
[01:58:10.900 --> 01:58:13.900]   Oh, you go to the website, twit.tv/mbw.
[01:58:13.900 --> 01:58:18.900]   You'll find all the shows we do there, audio and video.
[01:58:18.900 --> 01:58:22.900]   And of course, you can always subscribe in your favorite podcast application like overcast
[01:58:22.900 --> 01:58:26.900]   or pocketcasts or iTunes or, you know, wherever you get your podcasts.
[01:58:26.900 --> 01:58:28.900]   Just subscribe that way you'll get every episode.
[01:58:28.900 --> 01:58:29.900]   Thanks for being here.
[01:58:29.900 --> 01:58:34.900]   Sad to say you don't have to go home, but you can't stay here.
[01:58:34.900 --> 01:58:37.900]   Break time is over.
[01:58:37.900 --> 01:58:39.900]   [laughter]
[01:58:39.900 --> 01:58:46.900]   [music]
[01:58:46.900 --> 01:58:48.900]   [MUSIC]

