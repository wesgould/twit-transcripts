;FFMETADATA1
title=Alex as a Service
artist=TWiT
album_artist=TWiT
album=MacBreak Weekly
track=687
genre=Podcast
comment=http://twit.tv/mbw
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.000]   Coming up on Mac Break Weekly, we dive into those rumors.
[00:00:04.000 --> 00:00:08.200]   We've got AR glasses, AR headsets, everything AR.
[00:00:08.200 --> 00:00:13.300]   Plus, hmm, Renee Richie isn't here, and there's a rumored Macbook Pro on the way.
[00:00:13.300 --> 00:00:15.700]   Possibly 16 inches plus.
[00:00:15.700 --> 00:00:20.000]   A DJ with his beeps and boops is playing with the new Mac Pro.
[00:00:20.000 --> 00:00:23.000]   And I think Alex Lindsay really wants to get his hands on it.
[00:00:23.000 --> 00:00:25.000]   Stay tuned. You don't want to miss it.
[00:00:25.000 --> 00:00:29.000]   Podcasts You Love
[00:00:29.000 --> 00:00:31.000]   From People You Trust.
[00:00:31.000 --> 00:00:33.000]   This is Twit.
[00:00:33.000 --> 00:00:42.000]   This is Mac Break Weekly Episode 687, recorded November 12, 2019.
[00:00:42.000 --> 00:00:45.000]   Alex as a Service.
[00:00:45.000 --> 00:00:49.000]   This episode of Mac Break Weekly is brought to you by ITProTV.
[00:00:49.000 --> 00:00:53.000]   ITProTV provides IT training that's effective and entertaining
[00:00:53.000 --> 00:00:56.000]   with access to virtual labs and practice tests.
[00:00:56.000 --> 00:01:04.000]   Visit go.itpro.tv/macbreak for an additional 30% off for the lifetime of your active subscription.
[00:01:04.000 --> 00:01:07.000]   Use code Macbreak30 at checkout.
[00:01:07.000 --> 00:01:14.000]   And by LastPass, a personal password manager and identity solution for businesses all in one.
[00:01:14.000 --> 00:01:18.000]   You only need one master password and LastPass remembers the rest.
[00:01:18.000 --> 00:01:21.000]   Visit lasspass.com/twit to learn more.
[00:01:21.000 --> 00:01:30.000]   And by Plex. With Plex, you can organize and stream your personal collection of movies, TV shows, music and photos anywhere on any device.
[00:01:30.000 --> 00:01:37.000]   Go to plex.tv/twit and intercode Twit10 to get $10 off a lifetime Plex Pass subscription.
[00:01:37.000 --> 00:01:40.000]   This offer applies to new subscribers only.
[00:01:40.000 --> 00:01:44.000]   Hello and welcome back to Mac Break Weekly.
[00:01:44.000 --> 00:01:48.000]   It's the show where we talk about Macs and break things.
[00:01:48.000 --> 00:01:49.000]   I think.
[00:01:49.000 --> 00:01:50.000]   Is that how this works?
[00:01:50.000 --> 00:01:57.000]   But we do them very, very weekly so they're very, very easy to fix if there's any visual damage to begin with.
[00:01:57.000 --> 00:02:04.000]   There are Macs. There's all sorts of Apple stuff. There's everything in between.
[00:02:04.000 --> 00:02:12.000]   And I'm excited that things have returned to a bit of normalcy because Alex Lindsey is here in the studio with me again.
[00:02:12.000 --> 00:02:13.000]   Hello.
[00:02:13.000 --> 00:02:15.000]   Hello, Alex Lindsey of Pixel Core.
[00:02:15.000 --> 00:02:22.000]   Yeah, so we had you with Andy last week and you know, as Andy mentioned, it was getting a little bit too clicky.
[00:02:22.000 --> 00:02:25.000]   And so I said separate these two.
[00:02:25.000 --> 00:02:34.000]   I think, you know, clicky, is that a synonym for the balance of power had shifted dangerously close to the East Coast for one damn week?
[00:02:34.000 --> 00:02:36.000]   And somebody couldn't take it?
[00:02:36.000 --> 00:02:37.000]   I don't know.
[00:02:37.000 --> 00:02:44.000]   I don't know who that somebody was, but I will say that, you know, somebody had to be a diva and say, "Listen, I'm not going on that show again unless this changes."
[00:02:44.000 --> 00:02:46.000]   I don't know who that was though. It wasn't me.
[00:02:46.000 --> 00:02:50.000]   Well, Alex, we're all just taking turns. I get Alex next.
[00:02:50.000 --> 00:02:51.000]   Yeah, exactly.
[00:02:51.000 --> 00:03:02.000]   I just hope Alex, that the gift basket that you got today was as big and plentiful as the gift basket with the cheeses and the ham and the USB chargers.
[00:03:02.000 --> 00:03:03.000]   The Thanksgiving turkeys.
[00:03:03.000 --> 00:03:04.000]   That was pretty good.
[00:03:04.000 --> 00:03:05.000]   It's all there.
[00:03:05.000 --> 00:03:07.000]   We of course also have Lori Gill.
[00:03:07.000 --> 00:03:09.000]   I'm more as managing editor.
[00:03:09.000 --> 00:03:10.000]   Hello, Lori.
[00:03:10.000 --> 00:03:11.000]   That's me.
[00:03:11.000 --> 00:03:12.000]   How's it going?
[00:03:12.000 --> 00:03:18.000]   There's a little bit of room in here. I could bring Alex to sit next to me. We can snuggle up in front of my timey computer.
[00:03:18.000 --> 00:03:21.000]   You know, I'm a Sacramento, actually, relatively often.
[00:03:21.000 --> 00:03:22.000]   Oh, yeah.
[00:03:22.000 --> 00:03:23.000]   It wouldn't be hard.
[00:03:23.000 --> 00:03:27.000]   We should have a remote show where you come to my office.
[00:03:27.000 --> 00:03:29.000]   I just travel around and we just find the different...
[00:03:29.000 --> 00:03:30.000]   Then I have to go to...
[00:03:30.000 --> 00:03:31.000]   Yes.
[00:03:31.000 --> 00:03:33.000]   I have to go visit Renee and have some great television.
[00:03:33.000 --> 00:03:34.000]   Yeah.
[00:03:34.000 --> 00:03:39.000]   So this would be very, very contemporary for what Apple is doing. We're launching Alex as a service.
[00:03:39.000 --> 00:03:43.000]   [laughter]
[00:03:43.000 --> 00:03:47.000]   And that great quip came from WGBH's Andy Inotco.
[00:03:47.000 --> 00:03:49.000]   And as I said before, Andy Inotco is Andy Inotco.
[00:03:49.000 --> 00:03:50.000]   Don't go on it.
[00:03:50.000 --> 00:03:52.000]   You are a force to be reckoned with.
[00:03:52.000 --> 00:03:54.000]   I'm very self-possessed, you're correct.
[00:03:54.000 --> 00:03:56.000]   I've just been commented on before.
[00:03:56.000 --> 00:04:01.000]   Well, we're all here, except for Leo, who will be returning next week.
[00:04:01.000 --> 00:04:08.000]   The vacation is coming to an end and I can hear the groans all the way from the United States as...
[00:04:08.000 --> 00:04:12.000]   He comes to that realization that he has to end the vacation.
[00:04:12.000 --> 00:04:15.000]   But I'm sure you're all looking forward to having him back.
[00:04:15.000 --> 00:04:17.000]   Until then, let's get into it.
[00:04:17.000 --> 00:04:19.000]   So we got to start with the rumors.
[00:04:19.000 --> 00:04:23.000]   Again, this is Mac Break Weekly, so we're breaking the rumors.
[00:04:23.000 --> 00:04:25.000]   I don't know. I'm trying.
[00:04:25.000 --> 00:04:26.000]   [laughter]
[00:04:26.000 --> 00:04:30.000]   And it starts with Apple's plans for AR and VR.
[00:04:30.000 --> 00:04:34.000]   Tim Cook has said, "Yeah, AR is pretty cool."
[00:04:34.000 --> 00:04:41.000]   And some form or another in every single one of the earnings calls for as long as I had been transcribing them.
[00:04:41.000 --> 00:04:46.000]   And I don't know if he's still doing that, Lori, but he certainly had been talking up AR for some time.
[00:04:46.000 --> 00:04:54.000]   And it's maybe clear now why, according to sources familiar with the matter, sources close to the company,
[00:04:54.000 --> 00:05:02.000]   sources this, sources that, Apple is working on a mixed reality system that starts with a headset
[00:05:02.000 --> 00:05:06.000]   and then later becomes just glasses.
[00:05:06.000 --> 00:05:10.000]   So Lori Gill, are you excited for Apple glasses?
[00:05:10.000 --> 00:05:13.000]   You know, I've said this before.
[00:05:13.000 --> 00:05:17.000]   AR and VR right now are not quite consumer level.
[00:05:17.000 --> 00:05:20.000]   It still seems a little far off to me.
[00:05:20.000 --> 00:05:23.000]   Well, I think the rumor is 2022, right?
[00:05:23.000 --> 00:05:25.000]   So we've got a couple of years for that.
[00:05:25.000 --> 00:05:31.000]   The use cases for them don't seem to be quite strong enough to be
[00:05:31.000 --> 00:05:34.000]   presenting something worthwhile.
[00:05:34.000 --> 00:05:40.000]   And Apple's, you know, I don't think Apple would enter this market until it feels that it has a good consumer product.
[00:05:40.000 --> 00:05:47.000]   With that in mind though, AR has gotten a lot better at becoming something we could use every day,
[00:05:47.000 --> 00:05:54.000]   especially in terms of outdoor use in this idea of, you know, being able to have your map.
[00:05:54.000 --> 00:06:00.000]   You look out and you see buildings and it shows you what the address is or what the building is like, what the business is.
[00:06:00.000 --> 00:06:05.000]   So that kind of thing definitely potentially could be great for just a pair of glasses.
[00:06:05.000 --> 00:06:12.000]   In terms of the mixed reality headset, something more like, you know, the VR headsets that we're familiar with right now.
[00:06:12.000 --> 00:06:13.000]   I don't know.
[00:06:13.000 --> 00:06:17.000]   Apple hasn't won in terms of gaming.
[00:06:17.000 --> 00:06:25.000]   Even with Apple Arcade, Apple Arcade is not as popular on Mac as it is on iOS and Apple TV and stuff.
[00:06:25.000 --> 00:06:30.000]   So, you know, a mixed reality type headset, you know, that would be like a VR headset.
[00:06:30.000 --> 00:06:35.000]   Doesn't seem like it would be something that would, you know, go over that well.
[00:06:35.000 --> 00:06:38.000]   So, I don't know. It still seems a little early.
[00:06:38.000 --> 00:06:40.000]   I'm interested to see how this plays out.
[00:06:40.000 --> 00:06:46.000]   And maybe big things are happening in the next two years that'll make it worthwhile for Apple to launch something that soon.
[00:06:46.000 --> 00:06:48.000]   I seem to see them kind of laying a base.
[00:06:48.000 --> 00:06:54.000]   I don't know how folks feel about this, but we have right now the new iPhones that include this
[00:06:54.000 --> 00:06:57.000]   wide band, ultra wide band chip in them.
[00:06:57.000 --> 00:07:03.000]   And this ultra wide band chip is going to give some spatial awareness in a way that we have not had up to this point.
[00:07:03.000 --> 00:07:12.000]   After that, according to the Bloomberg article by Mark Gurman, we are going to see an iPad Pro in theory, allegedly, reportedly.
[00:07:12.000 --> 00:07:21.000]   In the first half of 2020, that's going to have a 3D system that lets people create three-dimensional reconstructions of rooms, objects and people.
[00:07:21.000 --> 00:07:25.000]   Now, it starts there in the iPad, then it comes to the iPhone.
[00:07:25.000 --> 00:07:28.000]   So, suddenly you have an iPhone that can do 3D mapping.
[00:07:28.000 --> 00:07:30.000]   You've got an ultra wide band chip inside.
[00:07:30.000 --> 00:07:38.000]   You've got these little Apple tags hanging out in your place, and you have companies taking advantage of this spatial awareness with UWB.
[00:07:38.000 --> 00:07:43.000]   And in that world, I can start to see where AR suddenly makes sense.
[00:07:43.000 --> 00:07:50.000]   If all of these devices and Apple's doing differential privacy and things like that to keep everybody's personal data protected,
[00:07:50.000 --> 00:07:57.000]   but a billion iPhones in people's pockets, y'all, if you've got all of that data out there that's doing the mapping,
[00:07:57.000 --> 00:08:01.000]   then suddenly I can see a world that they're building with AR.
[00:08:01.000 --> 00:08:02.000]   Google's tried to do that.
[00:08:02.000 --> 00:08:08.000]   So, it's not necessarily the idea of mapping from your phone is interesting.
[00:08:08.000 --> 00:08:10.000]   But, I do a lot of mapping.
[00:08:10.000 --> 00:08:19.000]   And so, a mixture of LiDAR, photogrammetry, and then there's been a variety of laser-based versions or some version of mapping
[00:08:19.000 --> 00:08:24.000]   that has been relatively inexpensive or phone-based for three or four years now.
[00:08:24.000 --> 00:08:28.000]   And that's been hard to get off the ground because it hasn't been very clean.
[00:08:28.000 --> 00:08:29.000]   The data isn't very clean.
[00:08:29.000 --> 00:08:34.000]   Now, what it does do is allow you to improve your positional data.
[00:08:34.000 --> 00:08:45.000]   So, if you look at what the USB Bluetooth, or I'm sorry, Bluetooth LE is going to get you down to three or four feet of location.
[00:08:45.000 --> 00:08:48.000]   But, theoretically, the ultra wide band will be much better than that.
[00:08:48.000 --> 00:08:53.000]   And when we start getting into a smaller box where we know mostly where the phone is,
[00:08:53.000 --> 00:08:59.000]   what that does is it reduces the number of variables as we start to hash out that data, this room data.
[00:08:59.000 --> 00:09:04.000]   So, I know that I only have to search, you know, if I know where your phone is and roughly where it's pointed,
[00:09:04.000 --> 00:09:11.000]   I can very quickly figure out exactly where you are in that room down to the millimeter, at least where the phone is.
[00:09:11.000 --> 00:09:15.000]   Right, because when you see those little points and things are tracking and not slipping,
[00:09:15.000 --> 00:09:17.000]   that means I know exactly where your phone is.
[00:09:17.000 --> 00:09:23.000]   And so, mixed with that, it allows me to very closely pinpoint your positional data.
[00:09:23.000 --> 00:09:31.000]   Now, that has some, as Lori alluded to, it has some great opportunities for just knowing where things are
[00:09:31.000 --> 00:09:33.000]   and how to find things, but it also has incredible opportunities.
[00:09:33.000 --> 00:09:40.000]   If you think about a museum, being able to build you a digital tour that is based exactly where you're looking at,
[00:09:40.000 --> 00:09:46.000]   exactly what you're looking at, and giving you a whole bunch of extra information, annotations via AR,
[00:09:46.000 --> 00:09:51.000]   you know, extra bits and pieces, and that can be done whether it's a, you know, you're going through restoration hardware,
[00:09:51.000 --> 00:09:54.000]   it's showing you things that this could be done and how this is assembled.
[00:09:54.000 --> 00:10:04.000]   And you can basically add enormous amounts of data to what you're looking at with the AR,
[00:10:04.000 --> 00:10:09.000]   if you really know where you're at and you really know the context of what you're looking for.
[00:10:09.000 --> 00:10:12.000]   And so, that is available on the, that's going to be available on the phone.
[00:10:12.000 --> 00:10:14.000]   I mean, that could be available right now.
[00:10:14.000 --> 00:10:16.000]   This is just a limitation of people making the content.
[00:10:16.000 --> 00:10:18.000]   So, there's a lot of it.
[00:10:18.000 --> 00:10:20.000]   Google has been playing with this for a long time.
[00:10:20.000 --> 00:10:22.000]   The real problem was, is the attempt to make it easy.
[00:10:22.000 --> 00:10:26.000]   Like, we have a phone walk, when we walk through a map it, you just get bad data.
[00:10:26.000 --> 00:10:32.000]   So, in the areas where we've taken LIDAR and mixed that with photogrammetry, you know,
[00:10:32.000 --> 00:10:40.000]   so we have both structured and unstructured data, essentially now you get incredible amounts of, of, of, to work with,
[00:10:40.000 --> 00:10:42.000]   you know, of, of data to, to deal with.
[00:10:42.000 --> 00:10:48.000]   And so, I think that, you know, we can keep on playing with the phones, and I think that we'll be able to do some stuff with it.
[00:10:48.000 --> 00:10:53.000]   And there are lots of apps that do this now, where you can kind of scan a bit of something here and there,
[00:10:53.000 --> 00:10:59.000]   but to really get it working for big locations, I think they're going to need to use bigger tools.
[00:10:59.000 --> 00:11:03.000]   Now, the great thing is, the thing that's most interesting, I think almost anybody can download it now.
[00:11:03.000 --> 00:11:07.000]   I think you might need a developer, but the reality composer.
[00:11:07.000 --> 00:11:08.000]   Yes, yeah.
[00:11:08.000 --> 00:11:11.000]   So, anybody should play with you, reality composer.
[00:11:11.000 --> 00:11:19.000]   So, you know, you download it, play with it, because now you're getting to see a codeless ability to throw things, you know, out there.
[00:11:19.000 --> 00:11:24.000]   You can throw things in there, you can give them some behaviors and so on, so forth, and throw them out there.
[00:11:24.000 --> 00:11:34.000]   And that is Apple reducing the amount of work it takes by 10x to, to be able to start building the core components for an AR experience.
[00:11:34.000 --> 00:11:38.000]   And so, you're, you're seeing that kind of go down the path.
[00:11:38.000 --> 00:11:41.000]   The other thing to keep your eye on is USDZ.
[00:11:41.000 --> 00:11:48.000]   So, USD is the universal scene description, which is Pixar's transport file format.
[00:11:48.000 --> 00:11:53.000]   Apple added a Z to it, which is Zip, I think, and it's just that they zip down into a single file.
[00:11:53.000 --> 00:11:58.000]   It's like, you know, I'm sure the Pixar was like, "Oh, I really wish I thought of that."
[00:11:58.000 --> 00:12:02.000]   So, anyway, by zipping it up, it makes it a compact piece.
[00:12:02.000 --> 00:12:06.000]   Now, we're not seeing that rolling out everywhere just yet.
[00:12:06.000 --> 00:12:13.000]   So, you know, but USDZ, I think, I hope, is going to eventually, we're going to see it in all the apps that Apple makes,
[00:12:13.000 --> 00:12:15.000]   other people's apps that are, you know, starting to come out.
[00:12:15.000 --> 00:12:17.000]   Some furniture stores have been using it a little bit.
[00:12:17.000 --> 00:12:27.000]   I've seen the, what's the, it's a game, it's a game console, a little yellow game console made by the folks at Panic, I think.
[00:12:27.000 --> 00:12:28.000]   Who's it made? I can't remember.
[00:12:28.000 --> 00:12:29.000]   Oh, right, right. Panic makes it.
[00:12:29.000 --> 00:12:30.000]   Yeah, Panic makes it.
[00:12:30.000 --> 00:12:33.000]   And they have used the USDZ format to show you it on a table.
[00:12:33.000 --> 00:12:37.000]   And the advantage of the USDZ format is that it's not just geometry.
[00:12:37.000 --> 00:12:41.000]   It's the geometry, it's the texture maps, it's the lighting, it's the behaviors, it's the animation.
[00:12:41.000 --> 00:12:45.000]   All of those things can be put into one format and then made available now.
[00:12:45.000 --> 00:12:48.000]   Some of that, getting that to work with everything is still a big challenge.
[00:12:48.000 --> 00:12:53.000]   But, so we're seeing all these pieces coming together and it's not there yet.
[00:12:53.000 --> 00:12:57.000]   But, but we, but I think that it's, it's really exciting.
[00:12:57.000 --> 00:13:02.000]   And when you start really thinking and playing with some of the ideas, there's a lot that could be done.
[00:13:02.000 --> 00:13:10.000]   I'm mostly interested in from an educational perspective, but there's a lot of places that can be done for entertainment and PR as well.
[00:13:10.000 --> 00:13:16.000]   Now you name two terms. You named LIDAR, which I understand.
[00:13:16.000 --> 00:13:18.000]   What was the other one that you named and how does that one work?
[00:13:18.000 --> 00:13:24.000]   So, photogrammetry is basically, it's another way that we gather scene data.
[00:13:24.000 --> 00:13:30.000]   Okay. So, basically what you can do is you can take photos of a given object from different angles.
[00:13:30.000 --> 00:13:33.000]   And this is just standard photos. You can do it with your iPhone.
[00:13:33.000 --> 00:13:38.000]   And the best, the easiest one to use is a program called MetaShape, in my opinion.
[00:13:38.000 --> 00:13:42.000]   It used to be called, I think, a photo scan. It wasn't photoscand.
[00:13:42.000 --> 00:13:45.000]   Anyway, so MetaShape is the one that I kind of use a lot.
[00:13:45.000 --> 00:13:50.000]   And so basically what you do is you take a series of photos from different angles and not straight on.
[00:13:50.000 --> 00:13:55.000]   You think that you want to take them front side, whatever, but you actually want to shoot angles so that they, you have vanishing points.
[00:13:55.000 --> 00:14:04.000]   And so basically you shoot your object. And what it does is it says, okay, I'm going to look at all the points in every photo that are features.
[00:14:04.000 --> 00:14:09.000]   These things look unique for these photos.
[00:14:09.000 --> 00:14:15.000]   Then it takes all those unique patterns and it compares them to all the other photos.
[00:14:15.000 --> 00:14:18.000]   And it says, where can I find the same pattern in all the other photos?
[00:14:18.000 --> 00:14:21.000]   And so it goes out and attaches them all.
[00:14:21.000 --> 00:14:29.000]   If it can get at least a to 12 pair between the two pairings and it says, okay, these are the same.
[00:14:29.000 --> 00:14:35.000]   Now when I look at it and if I have vanishing points, I can figure out, I can actually reverse engineer where the cameras were.
[00:14:35.000 --> 00:14:36.000]   I see.
[00:14:36.000 --> 00:14:39.000]   And I can figure out what their focal length was. I can figure out a lot of other things.
[00:14:39.000 --> 00:14:43.000]   Now it doesn't have to figure out focal length because usually when you take the picture, it's in the metadata.
[00:14:43.000 --> 00:14:47.000]   So anyway, so it takes these photos. It finds the features.
[00:14:47.000 --> 00:14:53.000]   It then reverse engineers where the cameras are. Now once it knows where the cameras are, their focal length and everything else,
[00:14:53.000 --> 00:15:00.000]   it can now figure out where every other point was. It can basically build a depth map within of every photo.
[00:15:00.000 --> 00:15:05.000]   And then from there extract surface points and then from there extract geometry.
[00:15:05.000 --> 00:15:11.000]   And so you can actually build very complex 3D models from simple photographs.
[00:15:11.000 --> 00:15:18.000]   And so the problem with it is there's no scale and oftentimes there's areas that you can't see.
[00:15:18.000 --> 00:15:24.000]   So what you do is you by mixing the LiDAR, this is what we call structured data, with the unstructured data,
[00:15:24.000 --> 00:15:29.000]   which is the photogrammetry you're able to actually get all of the best of both worlds.
[00:15:29.000 --> 00:15:37.000]   You get the detail from the photogrammetry, you get the structure from the LiDAR, and you end up with very, very accurate and highly detailed data.
[00:15:37.000 --> 00:15:43.000]   And this is going to be a big deal today. Unreal just bought.
[00:15:43.000 --> 00:15:49.000]   Now my brain just turned off. It's a company that I've been tracking for a while.
[00:15:49.000 --> 00:15:55.000]   They just bought Quixel.
[00:15:55.000 --> 00:16:00.000]   So there's a little company called Quixel, and it was a little press release that if you weren't watching both Quixel and Unreal,
[00:16:00.000 --> 00:16:06.000]   you probably wouldn't notice. But what they do is they use photogrammetry in LiDAR to build lots and lots of real-time 3D assets.
[00:16:06.000 --> 00:16:12.000]   And assets for Unreal and so on and so forth. So that library coming to Unreal is going to be a big deal.
[00:16:12.000 --> 00:16:17.000]   But you're seeing Unreal's pay attention to this, Unity is now looking at this.
[00:16:17.000 --> 00:16:23.000]   And these are the two big companies dealing with real-time 3D data on any every platform.
[00:16:23.000 --> 00:16:30.000]   Those are the two big players. And so it's kind of amazing, by the way, that Apple hasn't bought one of them.
[00:16:30.000 --> 00:16:36.000]   They're waiting for them to buy the other one so they can just buy the whole thing.
[00:16:36.000 --> 00:16:41.000]   But these are the two big players in this market.
[00:16:41.000 --> 00:16:46.000]   And so by Unreal grabbing this, it's really started in arms race.
[00:16:46.000 --> 00:16:52.000]   But this photogrammetry is, by the way, even if you never use it for work, it's my favorite pastime.
[00:16:52.000 --> 00:16:56.000]   Like when I'm walking around, I take pictures of stuff all the time just to build 3D models out of it.
[00:16:56.000 --> 00:17:00.000]   Is this a program you have to use to make that happen?
[00:17:00.000 --> 00:17:04.000]   You can download Metascan and I think you can get a demo version that is free.
[00:17:04.000 --> 00:17:08.000]   And then you can pay a monthly fee if you want to actually export stuff out.
[00:17:08.000 --> 00:17:17.000]   I think there might be some free ones out there. I use Metascan because it's easy to use.
[00:17:17.000 --> 00:17:23.000]   But there was a 3D 1, 2, 3 capture.
[00:17:23.000 --> 00:17:34.000]   The Autodesk put out, which was the old image modeler code put into this.
[00:17:34.000 --> 00:17:37.000]   And then they turned it off. It was very frustrating.
[00:17:37.000 --> 00:17:40.000]   So, Andy?
[00:17:40.000 --> 00:17:45.000]   Well, just back to the idea of Apple making AR classes.
[00:17:45.000 --> 00:17:51.000]   I just find it hard to imagine what they could make within the next 5 years that would fit what we expect from Apple
[00:17:51.000 --> 00:17:55.000]   and what we expect when we think about augmented reality glasses.
[00:17:55.000 --> 00:18:00.000]   It feels like putting humans in a spaceship and sending them to Mars.
[00:18:00.000 --> 00:18:04.000]   That's great.
[00:18:04.000 --> 00:18:08.000]   And you see the utility of it, but you still have the problem of,
[00:18:08.000 --> 00:18:10.000]   how do you keep these people safe from radiation?
[00:18:10.000 --> 00:18:14.000]   And how do you run like a 2-year long mission?
[00:18:14.000 --> 00:18:19.000]   With AR glasses, you get down to how do you get enough processing power in the glasses,
[00:18:19.000 --> 00:18:25.000]   even just to collect data and maintain communications with a phone in your pocket that's doing the most of the calculation?
[00:18:25.000 --> 00:18:35.000]   How do you have all this imaging hardware to put something in your field of vision that can run for an appreciable amount of time
[00:18:35.000 --> 00:18:42.000]   on a battery that wouldn't require some sort of a chest harness to build in the frame of glasses?
[00:18:42.000 --> 00:18:50.000]   And then even if you did, how do you have any sort of an imager that again can usefully place objects in your field of vision
[00:18:50.000 --> 00:18:54.000]   that don't make these things look like a hockey mask?
[00:18:54.000 --> 00:19:00.000]   And then finally, even if you did solve all those problems, how do you create a piece of technology
[00:19:00.000 --> 00:19:07.000]   that people are going to want to put on their faces, particularly if they don't use a prescription glasses to begin with?
[00:19:07.000 --> 00:19:13.000]   And then you get into, Apple would have to do a whole lot of communication saying that,
[00:19:13.000 --> 00:19:16.000]   "Well, I know that you associate a table.
[00:19:16.000 --> 00:19:20.000]   Look, the person you're talking to has a camera pointed at your face at all times while they're talking to you.
[00:19:20.000 --> 00:19:25.000]   It's more of a Facebook or a Google thing, but trust us, we're not going to make it creepy in any way, shape, or form.
[00:19:25.000 --> 00:19:31.000]   But the thing that makes, so I was really skeptical when people were predicting it for next year.
[00:19:31.000 --> 00:19:39.000]   I'm still skeptical at 2022. I'm thinking that in another five years, maybe, but I just don't get it.
[00:19:39.000 --> 00:19:48.000]   One thing though in Apple's favor is that with the Apple Watch, they did prove that they understand the importance of design in selling a technology
[00:19:48.000 --> 00:19:58.000]   that I don't think the Apple Watch would have gained all that traction if they had built something that looked like an Android Wear watch
[00:19:58.000 --> 00:20:05.000]   or one of the Samsung Gear watches, an up-can of tuna on your wrist with a 9-volt battery stuck inside it.
[00:20:05.000 --> 00:20:12.000]   Even when the Apple Watch is turned off as a static item, it looks like a very, very pretty watch that you might want to,
[00:20:12.000 --> 00:20:17.000]   if you saw it in a display case in a jewelry store, you might want to take a look at it before you knew what it was.
[00:20:17.000 --> 00:20:25.000]   And so if any company could make a set of spectacles that people would be willing to put on their face because not only is it very, very pretty,
[00:20:25.000 --> 00:20:31.000]   but it also shows, "Oh, look, I can afford this luxury brand of Apple." They could do it.
[00:20:31.000 --> 00:20:42.000]   But again, this is on my list of things that I will believe when I actually see Tim Cook or Tim Cook's third-generation clone on stage
[00:20:42.000 --> 00:20:44.000]   actually wearing them and demonstrating them in an event.
[00:20:44.000 --> 00:20:48.000]   Do you think they'll be in white? Do they only make them in white?
[00:20:48.000 --> 00:20:50.000]   Oh, Lord, I hope not.
[00:20:50.000 --> 00:20:57.000]   Well, and I don't know what they're doing with glasses, but what I will say is that you're seeing two very different approaches to the same problem,
[00:20:57.000 --> 00:21:03.000]   which is that Google will oftentimes just do something where we're going to experiment with everybody.
[00:21:03.000 --> 00:21:08.000]   We're going to just throw it out there. We're going to see what works and try to error-correct from that.
[00:21:08.000 --> 00:21:16.000]   And I'm not saying one way is better than the other. I'm just saying this is a clear vision of how the two companies work that's very distinct from each other.
[00:21:16.000 --> 00:21:21.000]   So Google is, we're going to throw it out there. We're going to see what sticks to the wall.
[00:21:21.000 --> 00:21:27.000]   We're going to then turn some stuff off, turn other things on. We're going to learn from what's happening.
[00:21:27.000 --> 00:21:32.000]   Apple is building an infrastructure that is piece by piece by piece.
[00:21:32.000 --> 00:21:39.000]   And then we have a little box up there. We started off a couple years ago with the basic tracking with those nice little wood tables that are easy to track.
[00:21:39.000 --> 00:21:47.000]   And then we throw a box up there and we have we have Weta do something and then we have Minecraft do something.
[00:21:47.000 --> 00:21:51.000]   And every year there's this little progression. Now we have USDZ.
[00:21:51.000 --> 00:21:57.000]   And now we're adding these little bits and pieces. And that's how Apple, but it's a great vision.
[00:21:57.000 --> 00:22:02.000]   And it shows you the difference between the two companies. I think that Apple moves really slowly because it does that way.
[00:22:02.000 --> 00:22:07.000]   But Google also, you don't know whether you should commit to it because you don't know how it's going to last.
[00:22:07.000 --> 00:22:21.000]   Well, but this is another point that we haven't really considered. What if Apple's plans for, if they have plans for an actual, like, what we think of as a traditional luck-minute reality, paragoggles or glasses,
[00:22:21.000 --> 00:22:31.000]   if they're planning to do it the way that Microsoft is doing HoloLens or the way that Google is doing Glass, where they're not selling them to consumers to walk around the street with these on.
[00:22:31.000 --> 00:22:35.000]   They're selling these enterprise to people who are really successful as well.
[00:22:35.000 --> 00:22:50.000]   So maybe Apple is planning like an Apple Glass's Pro for like two to three thousand dollars a pair that architectural firms will wear and scientific applications will buy not in huge Apple Watch quantities,
[00:22:50.000 --> 00:22:59.000]   but enough quantities that when the technology comes along to build a thousand dollar pair or maybe even a five hundred dollar pair of consumer classes,
[00:22:59.000 --> 00:23:03.000]   they figured they've got the software all locked down and now they know exactly how to adapt it.
[00:23:03.000 --> 00:23:08.000]   So you may be right, but so there's the original article before Bloomberg came out with their report.
[00:23:08.000 --> 00:23:16.000]   The information had an excellent report about Apple's AR headset and glasses with the headset coming first, the glasses coming later.
[00:23:16.000 --> 00:23:23.000]   This was a presentation that reportedly they gave to enough employees to fill the one thousand seat Steve Jobs Theater,
[00:23:23.000 --> 00:23:27.000]   and that is according to the people rather unprecedented.
[00:23:27.000 --> 00:23:36.000]   In fact, they each had these little stickers that were placed tamper-proof stickers that were placed over their iPhones with QR codes on them,
[00:23:36.000 --> 00:23:41.000]   so that if they were ever tampered to take photos of anything, then they would know exactly who it was.
[00:23:41.000 --> 00:23:45.000]   And for those of us who work in production on these kinds of events, that's standard.
[00:23:45.000 --> 00:23:49.000]   So that part stickers on cameras is something that I just get used to.
[00:23:49.000 --> 00:23:54.000]   You just put stickers on your on your and they're kind of useless, but it makes everyone feel better.
[00:23:54.000 --> 00:24:02.000]   Right. And so this for a thing just targeted at a specific market like that, there are a lot of people that are involved in this.
[00:24:02.000 --> 00:24:08.000]   One of the things that they talk about here is the fabrics and the materials that they want to use,
[00:24:08.000 --> 00:24:16.000]   even on this headset, before we even get to the glasses, to make this light enough to where people can wear it as often as possible,
[00:24:16.000 --> 00:24:24.000]   which I'm not sold on a HoloLens-style device, a mixed reality headset that works for both AR and VR,
[00:24:24.000 --> 00:24:30.000]   that I would wear anywhere other than in a specific setting for VR.
[00:24:30.000 --> 00:24:35.000]   If I'm in my home and I've got my padded walls that are going to keep me safe as I'm walking around, sure,
[00:24:35.000 --> 00:24:39.000]   but I don't see myself personally walking around with the headset.
[00:24:39.000 --> 00:24:45.000]   But the way that they talk about it is they're trying to design it for longevity in terms of wearability.
[00:24:45.000 --> 00:24:50.000]   Has anyone used them magically?
[00:24:50.000 --> 00:24:51.000]   Yes.
[00:24:51.000 --> 00:24:53.000]   And what did you think?
[00:24:53.000 --> 00:25:03.000]   I thought that it was a really spectacular experience with the usual limitation of it will deliver really, really convincing
[00:25:03.000 --> 00:25:07.000]   imagery in your field of vision, but no peripheral vision.
[00:25:07.000 --> 00:25:12.000]   And so whoever has created the content, you have to make sure that if something enters the frame,
[00:25:12.000 --> 00:25:18.000]   it has to do a genie appear right in front of you, or walk from the distance.
[00:25:18.000 --> 00:25:25.000]   They can't, same limitation as HoloLens, where you're basically looking at a screen that's in front of you,
[00:25:25.000 --> 00:25:27.000]   it's just that it's transparent and invisible.
[00:25:27.000 --> 00:25:29.000]   But the overall effect was very, very nice.
[00:25:29.000 --> 00:25:36.000]   The fact that it was bulky because of the cabling and this pod you had to have on your hip,
[00:25:36.000 --> 00:25:39.000]   but as an effect, it worked very well.
[00:25:39.000 --> 00:25:45.000]   And if I had to do training for three or four hours, let's say, at a stretch,
[00:25:45.000 --> 00:25:52.000]   or if I were even being a creator, if I were being an architect who was walking me, myself and my team through a place
[00:25:52.000 --> 00:25:56.000]   and trying to say, "Well, what would this look like at 3 p.m. in winter?"
[00:25:56.000 --> 00:25:59.000]   Like, "Okay, great. So we need to adjust that window this way or that way."
[00:25:59.000 --> 00:26:05.000]   I could also see why you need to have comfort because it's, you can't get anything done in 20 minutes apart
[00:26:05.000 --> 00:26:09.000]   from give a demo that hopefully will let the Department of Defense order a thousand of them.
[00:26:09.000 --> 00:26:15.000]   If you actually want to get work done, you need to create something people are going to wear for a full work session.
[00:26:15.000 --> 00:26:22.000]   I think that's exactly where the AR stuff is just not really, in my opinion, ready yet,
[00:26:22.000 --> 00:26:24.000]   is what's the use case for something like this?
[00:26:24.000 --> 00:26:30.000]   What's the use case for a pair of AR VR glasses that you wear on your head while you're working, for example?
[00:26:30.000 --> 00:26:39.000]   There's ideas out there that sound fantastic, but they haven't been able to accomplish that kind of productivity
[00:26:39.000 --> 00:26:41.000]   and comfort at the same time.
[00:26:41.000 --> 00:26:47.000]   If I had a pair of glasses on my face that could call up a browser at any time that I needed it,
[00:26:47.000 --> 00:26:51.000]   you know, and I wouldn't have to do anything except, you know, tap a couple things in the air,
[00:26:51.000 --> 00:26:56.000]   that is a fantastic idea, but it's also, we're not ready for that.
[00:26:56.000 --> 00:27:00.000]   We're not ready for that kind of workflow in our day to day.
[00:27:00.000 --> 00:27:08.000]   So it definitely would have to be something that revolutionizes the way we use technology, the way we use computers.
[00:27:08.000 --> 00:27:10.000]   And this has been done before.
[00:27:10.000 --> 00:27:14.000]   I mean, the iPhone and the iPad or smartphones and tablets, they did that.
[00:27:14.000 --> 00:27:19.000]   We went from computers to tablets and most people don't even have a computer in their house anymore
[00:27:19.000 --> 00:27:23.000]   because tablets and smartphones have replaced that.
[00:27:23.000 --> 00:27:32.000]   So there's potential for some day AR or VR or mixed reality glasses or headsets to replace what we're comfortable with
[00:27:32.000 --> 00:27:41.000]   in terms of computing, but it's certainly, the use cases for it just don't seem to mesh in my opinion
[00:27:41.000 --> 00:27:44.000]   with what people need to do on the day to day.
[00:27:44.000 --> 00:27:52.000]   Maybe it could be a niche thing for entertainment, you know, for people who work in like graphic design
[00:27:52.000 --> 00:27:54.000]   and film editing and things like that.
[00:27:54.000 --> 00:27:58.000]   I've done a lot of both.
[00:27:58.000 --> 00:28:05.000]   So I think about it in a way that, you know, that is that there are many places where it comes to like, for instance, training.
[00:28:05.000 --> 00:28:13.000]   There are things like, for instance, I was playing with, there was a, the union,
[00:28:13.000 --> 00:28:21.000]   I can't think what you know, one of the Teamsters unions at the Vallejo Farmers Market.
[00:28:21.000 --> 00:28:27.000]   They had like this little tiny crane and it's like a crane, it's as if, it looked like a little toy,
[00:28:27.000 --> 00:28:29.000]   but it was a very industrial toy.
[00:28:29.000 --> 00:28:32.000]   It's one that used to train crane operators.
[00:28:32.000 --> 00:28:37.000]   So you have the two joysticks and you sit there and you play with it and you have to pick little things up
[00:28:37.000 --> 00:28:38.000]   and put things down.
[00:28:38.000 --> 00:28:42.000]   You like hook it onto this and move it around so you build up your understanding of what the two joysticks are.
[00:28:42.000 --> 00:28:49.000]   You know, there's a lot that you know, six degrees of freedom on a crane and if you screw it up, you're going to kill people
[00:28:49.000 --> 00:28:50.000]   or drop a building or whatever.
[00:28:50.000 --> 00:28:54.000]   So it's good to be, you know, you got to get good at it, right?
[00:28:54.000 --> 00:28:55.000]   Yeah.
[00:28:55.000 --> 00:29:00.000]   So anyway, so they use this thing as a training device and I very quickly realized like this is a good example
[00:29:00.000 --> 00:29:07.000]   of something that would be great in AR, where or VR where you put the goggles on and now I can feel it and it's
[00:29:07.000 --> 00:29:09.000]   integrating my experience with that process.
[00:29:09.000 --> 00:29:18.000]   Now, I want to make sure that you have this totally down and totally have the feel of it before you actually interact
[00:29:18.000 --> 00:29:26.000]   with the full device, you know, and some of the stuff that I was working on as early as the mid 90s was actually
[00:29:26.000 --> 00:29:33.000]   for military and police officer training, which was a technology called Fats.
[00:29:33.000 --> 00:29:39.000]   And basically what you would do is it was big screens, you know, like that were in front of you, it wasn't VR.
[00:29:39.000 --> 00:29:46.000]   And basically it would put you in situations, high stress situations that you would make, have to make decisions quickly.
[00:29:46.000 --> 00:29:51.000]   You know, and so it's a lot of what we think of where you put a bunch of targets or you have an interaction and,
[00:29:51.000 --> 00:29:54.000]   but they had, I mean, they had really great tools for the big ones.
[00:29:54.000 --> 00:29:58.000]   I mean, they had a shoulder mounted launcher that had pressed air.
[00:29:58.000 --> 00:30:04.000]   So you said there, you'd fire to go, you know, like, you know, and then the screen would go, you know, and it would fly up.
[00:30:04.000 --> 00:30:08.000]   And then you see a tank go, you know, experience.
[00:30:08.000 --> 00:30:10.000]   Oh, it was the ultimate distance experience.
[00:30:10.000 --> 00:30:18.000]   Anyway, so, but the, I, ironically, the reason I was looking at this stuff was to use photogrammetry, but back then we had to like,
[00:30:18.000 --> 00:30:20.000]   we had to make it by hand.
[00:30:20.000 --> 00:30:22.000]   It was like, we make little boxes and things like that.
[00:30:22.000 --> 00:30:32.000]   And so anyway, so, but what was interesting there is that when I look at VR, I think that was a very big, big projectors and screens that were all blended together.
[00:30:32.000 --> 00:30:35.000]   VR would make that much more interactive.
[00:30:35.000 --> 00:30:44.000]   And so, if you don't have to build, even if you don't have to build a bunch of those little crane things that you were talking about where you could train up 12 people and, you know,
[00:30:44.000 --> 00:30:46.000]   you don't have people waiting to be able to do it at home.
[00:30:46.000 --> 00:30:51.000]   You know, like literally you could send, you could send a bunch of crane operators, you know, stuff at home with an oculus
[00:30:51.000 --> 00:30:53.000]   and a specialized joystick.
[00:30:53.000 --> 00:31:00.000]   Whatever the device was that my daughter was using at this farmer's market, whatever that device is, that was expensive.
[00:31:00.000 --> 00:31:08.000]   You know, and this is something that for a couple hundred dollars, you could have people go to a local location and use or other things like that.
[00:31:08.000 --> 00:31:18.000]   And so, so I think that especially when it comes to training and it comes to learning things, I think that there's a lot of opportunities to have AR and VR be something that's compelling.
[00:31:18.000 --> 00:31:21.000]   I don't think that it always has to be something that I'm going to put on for hours.
[00:31:21.000 --> 00:31:22.000]   You know, the right, right.
[00:31:22.000 --> 00:31:28.000]   Some of the things like, for instance, with HoloLens that they've been really successful at in construction is I throw this thing on for a minute.
[00:31:28.000 --> 00:31:34.000]   I look out and now I can see where all my pins are going to come up and where, you know, all I have is survey data right now.
[00:31:34.000 --> 00:31:36.000]   You know, I have flags, you know, up there.
[00:31:36.000 --> 00:31:42.000]   And instead, I now can see what's actually going to be there, where those flags are going to turn into beams and everything else.
[00:31:42.000 --> 00:31:52.000]   And that helps me visualize what I'm looking at in a way that is very difficult. It's one of the big problems you have in construction is not seeing what those flags mean.
[00:31:52.000 --> 00:31:53.000]   Right.
[00:31:53.000 --> 00:31:56.000]   And so being able to kind of visualize where we are and where we're going with that.
[00:31:56.000 --> 00:31:58.000]   And that's only, you put it on for a couple minutes.
[00:31:58.000 --> 00:32:01.000]   You look out there, you have a discussion about where it's going and how it's working.
[00:32:01.000 --> 00:32:02.000]   And then you take it off.
[00:32:02.000 --> 00:32:07.000]   And so I don't think that it necessarily has to be something that you're going to have on all day or even a couple hours.
[00:32:07.000 --> 00:32:11.000]   I think a lot of AR and VR solutions could be something that could be done very quickly.
[00:32:11.000 --> 00:32:14.000]   The biggest problem you have with that is the startup process.
[00:32:14.000 --> 00:32:20.000]   You throw on a VR goggles and there's all this stupid stuff that you have to do to get to where you're trying to go.
[00:32:20.000 --> 00:32:27.000]   And it's this, you know, and that's the thing that I don't feel like anybody has done very well, is that when I put my V, like I put Oculus on,
[00:32:27.000 --> 00:32:30.000]   and now I really technically have to know what I'm doing.
[00:32:30.000 --> 00:32:31.000]   Right.
[00:32:31.000 --> 00:32:36.000]   And there's a whole bunch of bumping around that you can't just hand it to somebody and have them throw it on and have it be a fluid experience.
[00:32:36.000 --> 00:32:39.000]   And I think that's been one of the big problems with execution.
[00:32:39.000 --> 00:32:49.000]   The problem is if you start training people in this way, then you remove the possibility for accounts like cursed architecture to exist on Twitter,
[00:32:49.000 --> 00:32:55.000]   where a lot of the times they're showing off these horrifying creations.
[00:32:55.000 --> 00:33:01.000]   So for example, if you could see ahead of time, I don't know if we can show my screen here.
[00:33:01.000 --> 00:33:03.000]   But did they do that on purpose?
[00:33:03.000 --> 00:33:08.000]   Well, maybe they did, but then this kind of thing. I don't know what's going on here and why this is allowed.
[00:33:08.000 --> 00:33:19.000]   For folks at Odo, it's @cursedarchitecture on Twitter, and it basically just people submit these horrifying architectural nightmares that people have created.
[00:33:19.000 --> 00:33:24.000]   And sometimes there's probably reasons for why these exist the way that they do.
[00:33:24.000 --> 00:33:34.000]   Without European and American code codes, a lot of things get done in a different way that oftentimes is a little bit more organic.
[00:33:34.000 --> 00:33:37.000]   You're not talking about McMachian Hell, are you? That's one of my favorite.
[00:33:37.000 --> 00:33:39.000]   That's another. Yeah.
[00:33:39.000 --> 00:33:43.000]   In Rwanda, we had a hallway that didn't go anywhere.
[00:33:43.000 --> 00:33:44.000]   Oh, man.
[00:33:44.000 --> 00:33:47.000]   It was like a hallway where I don't understand why this is even here.
[00:33:47.000 --> 00:33:50.000]   But I think they just had extra space.
[00:33:50.000 --> 00:33:55.000]   Yeah, so it sounds like there are some use cases that we can imagine right now,
[00:33:55.000 --> 00:34:01.000]   and we'll see if there are going to be use cases that we have, maybe as consumers,
[00:34:01.000 --> 00:34:07.000]   that either Apple will make known to us or that we will start to see as other technology evolves around it.
[00:34:07.000 --> 00:34:13.000]   And we have to remember that many people thought that there was no reason to have an iPhone when Apple released it.
[00:34:13.000 --> 00:34:15.000]   Why would you need anything more than a drink?
[00:34:15.000 --> 00:34:21.000]   Well, well, but remember that we had that thing already.
[00:34:21.000 --> 00:34:26.000]   The idea of having... No, I'm saying that the...
[00:34:26.000 --> 00:34:32.000]   I don't think it's a great analogy because what you're talking about is here is an existing thing.
[00:34:32.000 --> 00:34:36.000]   It's like the difference between a gas powered car and electric car.
[00:34:36.000 --> 00:34:40.000]   It's the same kind of thing only with different technology powering it.
[00:34:40.000 --> 00:34:45.000]   People have already been conditioned to imagine the first pitch saying, we have this great idea.
[00:34:45.000 --> 00:34:49.000]   You know how like sometimes you want to get out of the house or get out of the office
[00:34:49.000 --> 00:34:51.000]   so that no one can reach you by phone?
[00:34:51.000 --> 00:34:54.000]   We have this technology, this device that will cost you a lot of money
[00:34:54.000 --> 00:34:58.000]   and it will allow anybody to call you wherever you are.
[00:34:58.000 --> 00:35:00.000]   You will never know a moment's peace.
[00:35:00.000 --> 00:35:02.000]   We already have that kind of...
[00:35:02.000 --> 00:35:06.000]   We already had that well in the bag before the iPhone came out.
[00:35:06.000 --> 00:35:12.000]   We're not telling people to put something on their faces that they've never put on their faces before.
[00:35:12.000 --> 00:35:16.000]   We're telling people to get used to a kind of computing that they have never done before.
[00:35:16.000 --> 00:35:23.000]   And I think this is going to be non-trivial, which is why I think that when you do it in enterprise,
[00:35:23.000 --> 00:35:26.000]   when you do it for training, when you do it for the person who's using it,
[00:35:26.000 --> 00:35:31.000]   it's not the person who's paying for it and the person who's using it is kind of being told by their boss,
[00:35:31.000 --> 00:35:32.000]   you have to use this.
[00:35:32.000 --> 00:35:35.000]   That's the great place to incubate all this technology.
[00:35:35.000 --> 00:35:38.000]   It seems to me that Andy has forgotten about the virtual boy.
[00:35:38.000 --> 00:35:40.000]   We've had this technology.
[00:35:40.000 --> 00:35:45.000]   Virtual boy was more of a pink eye enabling system.
[00:35:45.000 --> 00:35:51.000]   There weren't enough kids with pink eye and this absolutely solved that problem.
[00:35:51.000 --> 00:35:52.000]   So that's a different thing.
[00:35:52.000 --> 00:35:59.000]   The number one use that we found for Google Glass was to be able to do point-to-point training,
[00:35:59.000 --> 00:36:02.000]   where I could see what you're looking at overhangout.
[00:36:02.000 --> 00:36:06.000]   I can see what you're looking at, you can see what I'm looking at, and I can sit there and talk to you about it.
[00:36:06.000 --> 00:36:07.000]   And then they turned it off.
[00:36:07.000 --> 00:36:09.000]   And you were like, "Okay, well, now I don't have any--"
[00:36:09.000 --> 00:36:10.000]   Literally, I haven't used it.
[00:36:10.000 --> 00:36:11.000]   No, there's no use for it.
[00:36:11.000 --> 00:36:14.000]   Yeah, like it was just kind of like, "Okay, well, never mind."
[00:36:14.000 --> 00:36:16.000]   Well, we'll see what happens.
[00:36:16.000 --> 00:36:24.000]   But we have to talk about a noticeable absence in our hearts and on the panel today.
[00:36:24.000 --> 00:36:28.000]   A certain Renee Richie is not here today.
[00:36:28.000 --> 00:36:38.000]   And at the same time, there have been some rumors suggesting that a 16-inch MacBook Pro could be coming as soon as tomorrow.
[00:36:38.000 --> 00:36:39.000]   Now, I don't know.
[00:36:39.000 --> 00:36:40.000]   I'm not drawing any connections.
[00:36:40.000 --> 00:36:42.000]   Leave those connections to you folks out there.
[00:36:42.000 --> 00:36:45.000]   I think he's actually having a communication with Georgia Dow.
[00:36:45.000 --> 00:36:47.000]   Oh, is that what it is?
[00:36:47.000 --> 00:36:50.000]   Now, you're the managing editor of What Side Again?
[00:36:50.000 --> 00:36:51.000]   I don't know.
[00:36:51.000 --> 00:36:54.000]   Am I going to get myself a trouble by saying anything?
[00:36:54.000 --> 00:36:57.000]   I'm just saying anything.
[00:36:57.000 --> 00:37:04.000]   All I know is that as soon as I heard that rumor that there are people flying into Apple's Briefing Suite in New York City,
[00:37:04.000 --> 00:37:09.000]   I'm like, "Well, let's go to Instagram.com/ReneeRitchie
[00:37:09.000 --> 00:37:14.000]   and see if there's a picture of an Apple watch going to LaGuardia."
[00:37:14.000 --> 00:37:18.000]   And I didn't see that, which means that either A, yes, he's on vacation somewhere,
[00:37:18.000 --> 00:37:23.000]   or B, Apple, the control freaks that they are, had a little word with them saying,
[00:37:23.000 --> 00:37:27.000]   "Well, every time you tweet that picture, the world knows that you're coming in for a briefing me,
[00:37:27.000 --> 00:37:29.000]   we wouldn't do what you want.
[00:37:29.000 --> 00:37:32.000]   We would just be really, really happy if you didn't do that anymore."
[00:37:32.000 --> 00:37:34.000]   That's a really good point.
[00:37:34.000 --> 00:37:38.000]   I hadn't thought about the reading between the lines there.
[00:37:38.000 --> 00:37:45.000]   But there's apparently going to be -- we've heard about this 16-inch MacBook Pro for quite some time.
[00:37:45.000 --> 00:37:53.000]   Now, of course, there are rumors that the folks are being flown in to discuss this 16-inch MacBook Pro.
[00:37:53.000 --> 00:38:01.000]   And Mark Gurman on Twitter was being lambasted because of some earlier tweet
[00:38:01.000 --> 00:38:04.000]   where he said that the release was imminent.
[00:38:04.000 --> 00:38:10.000]   And then people were following up saying, "Imminent, you say, well, clearly it has not happened yet,
[00:38:10.000 --> 00:38:14.000]   but now rumored to be potentially released tomorrow."
[00:38:14.000 --> 00:38:19.000]   So it was kind of -- was it going to be released today as folks were getting their press briefings
[00:38:19.000 --> 00:38:25.000]   or was it going to be tomorrow after that has happened with some reviews of first looks?
[00:38:25.000 --> 00:38:27.000]   And I have a bunch of weenies.
[00:38:27.000 --> 00:38:32.000]   I do want to make it clear that no one has said anything to me.
[00:38:32.000 --> 00:38:36.000]   I don't know anything that was just a funny ha ha about Renee not being here.
[00:38:36.000 --> 00:38:39.000]   He probably is on vacation with Georgia.
[00:38:39.000 --> 00:38:40.000]   I don't know.
[00:38:40.000 --> 00:38:41.000]   In New York.
[00:38:41.000 --> 00:38:43.000]   He's there eating sushi or something.
[00:38:43.000 --> 00:38:45.000]   As he has wanted to do.
[00:38:45.000 --> 00:38:48.000]   But 16-inch MacBook Pro.
[00:38:48.000 --> 00:38:52.000]   I just got this 15-inch MacBook Pro with Touch Bar.
[00:38:52.000 --> 00:38:53.000]   Let's see.
[00:38:53.000 --> 00:38:54.000]   What is this?
[00:38:54.000 --> 00:38:57.000]   This is the 2019 model.
[00:38:57.000 --> 00:38:58.000]   So that's from this year.
[00:38:58.000 --> 00:38:59.000]   Yes.
[00:38:59.000 --> 00:39:00.000]   So the brand new one, right?
[00:39:00.000 --> 00:39:01.000]   Yeah.
[00:39:01.000 --> 00:39:04.000]   And you know, I wish I would have held out.
[00:39:04.000 --> 00:39:07.000]   I've been -- I was like, I'm going to let them sort this all out.
[00:39:07.000 --> 00:39:08.000]   I'm going to hold out on it.
[00:39:08.000 --> 00:39:10.000]   So I think this is my model coming.
[00:39:10.000 --> 00:39:15.000]   I still have a 2015 that I'm not allowed to fly with anymore in Asia.
[00:39:15.000 --> 00:39:19.000]   So -- and so I've been hanging on for a long time.
[00:39:19.000 --> 00:39:22.000]   I'm going to have to -- I know I'm going to have to give up the whole -- I want my mag safe back,
[00:39:22.000 --> 00:39:23.000]   I think.
[00:39:23.000 --> 00:39:29.000]   You know, that's the only thing I'm -- but that's been the thing that has actually been the number one issue that I've had.
[00:39:29.000 --> 00:39:31.000]   But it's now just gotten too slow.
[00:39:31.000 --> 00:39:32.000]   So I'm excited.
[00:39:32.000 --> 00:39:37.000]   When I saw the Mac Pro, I was hoping that we were going to end up with a Mac Pro-like MacBook Pro,
[00:39:37.000 --> 00:39:39.000]   but it doesn't look like that's going to be the case.
[00:39:39.000 --> 00:39:45.000]   Like what I wanted was gnarly, heavy, long battery life, has a crazy processor.
[00:39:45.000 --> 00:39:47.000]   I'm not sure that that's what we're going to get.
[00:39:47.000 --> 00:39:51.000]   Because I feel like the current Mac Pro should be the Mac -- like the MacBook.
[00:39:51.000 --> 00:39:52.000]   Oh, interesting.
[00:39:52.000 --> 00:39:55.000]   You know, like what they consider a Mac Pro right now is to be a MacBook.
[00:39:55.000 --> 00:39:58.000]   And then they should make one that is beefy.
[00:39:58.000 --> 00:39:59.000]   Actually a Pro.
[00:39:59.000 --> 00:40:00.000]   And actually a Pro.
[00:40:00.000 --> 00:40:05.000]   Yeah, so this one's supposed to come with an updated keyboard mechanism.
[00:40:05.000 --> 00:40:09.000]   It is now a scissor switch instead of the butterflies of times.
[00:40:09.000 --> 00:40:10.000]   I want cookies.
[00:40:10.000 --> 00:40:11.000]   I want cookies.
[00:40:11.000 --> 00:40:12.000]   You won't fall on it.
[00:40:12.000 --> 00:40:12.000]   I think it's --
[00:40:12.000 --> 00:40:13.000]   Clickies.
[00:40:13.000 --> 00:40:14.000]   Chari's.
[00:40:14.000 --> 00:40:17.000]   I think there's been -- there's been room or that it's like a hybrid version.
[00:40:17.000 --> 00:40:23.000]   Like that it's going to be like kind of butterfly kind of scissor or it's like it's butterfly,
[00:40:23.000 --> 00:40:27.000]   but they're going to use some of the scissor mechanisms or something like that.
[00:40:27.000 --> 00:40:29.000]   I remember Renee talking about that.
[00:40:29.000 --> 00:40:34.000]   What's the term for that language in 1984 where they're lying to you?
[00:40:34.000 --> 00:40:35.000]   Yeah, that's --
[00:40:35.000 --> 00:40:36.000]   Yeah, I speak to you.
[00:40:36.000 --> 00:40:40.000]   They've agreed to focus in the eye with a slightly blunter stick now.
[00:40:40.000 --> 00:40:44.000]   It's known that the keyboards, the garbage fire start to finish.
[00:40:44.000 --> 00:40:49.000]   The sooner that they basically say we have a brand new keyboard design as opposed to,
[00:40:49.000 --> 00:40:54.000]   you know how we told you twice already that we fixed the problems with the old design?
[00:40:54.000 --> 00:40:55.000]   And now it's perfect.
[00:40:55.000 --> 00:40:56.000]   Get ready again.
[00:40:56.000 --> 00:41:02.000]   I think that if once again they show us a .58 millimeter, let's go through that again.
[00:41:02.000 --> 00:41:08.000]   .58 millimeter key travel keyboard, it's just garbage again.
[00:41:08.000 --> 00:41:09.000]   Which is funny.
[00:41:09.000 --> 00:41:14.000]   I have one with the flat keys and I mean a smaller 12 inch.
[00:41:14.000 --> 00:41:17.000]   And I actually like my iPad keyboard better.
[00:41:17.000 --> 00:41:20.000]   I'd rather type on my iPad keyboard than on that.
[00:41:20.000 --> 00:41:21.000]   I won't type anything very --
[00:41:21.000 --> 00:41:24.000]   Is that the smart keyboard or the Apple Smart Keyboard?
[00:41:24.000 --> 00:41:25.000]   It's the Apple Smart Keyboard.
[00:41:25.000 --> 00:41:26.000]   I prefer that.
[00:41:26.000 --> 00:41:31.000]   I prefer to type on that than the -- my little 12 inch that has the flat keys.
[00:41:31.000 --> 00:41:32.000]   I'm trying to see.
[00:41:32.000 --> 00:41:33.000]   Yeah.
[00:41:33.000 --> 00:41:40.000]   I think I've never really been -- I think Renee uses the term keyboard agnostic.
[00:41:40.000 --> 00:41:43.000]   I've never really had other than mechanical keyboards.
[00:41:43.000 --> 00:41:45.000]   Those are difficult for me to type on.
[00:41:45.000 --> 00:41:51.000]   But otherwise I flow from one keyboard to another without any sort of -- you know, I don't
[00:41:51.000 --> 00:41:55.000]   worry about the bounce back or the tactileness or anything like that.
[00:41:55.000 --> 00:41:58.000]   The mushiness, sometimes there are keyboards that feel a little more sheer than others.
[00:41:58.000 --> 00:42:00.000]   But for the most part it's never really been an issue for me.
[00:42:00.000 --> 00:42:06.000]   So like I don't have a problem with the butterfly keyboard in terms of how it feels and how it
[00:42:06.000 --> 00:42:11.000]   works except for the problems that the butterfly keyboard has had in the past.
[00:42:11.000 --> 00:42:19.000]   And apparently -- and you know, I know, Michael, you've got the 2019 model and you're going
[00:42:19.000 --> 00:42:25.000]   to be the first one to know if the new model has improved the keyboard or not if you have
[00:42:25.000 --> 00:42:26.000]   an issue with it.
[00:42:26.000 --> 00:42:29.000]   But the last two iterations did still have problems.
[00:42:29.000 --> 00:42:31.000]   So maybe this third one doesn't.
[00:42:31.000 --> 00:42:37.000]   So in my opinion, if we stick with the butterfly keyboard for all time, I'm fine with it because
[00:42:37.000 --> 00:42:41.000]   I think it's perfectly fine in terms of its usability.
[00:42:41.000 --> 00:42:47.000]   But they need to perfect the problems with it, which is a completely different situation,
[00:42:47.000 --> 00:42:48.000]   you know.
[00:42:48.000 --> 00:42:49.000]   Yeah.
[00:42:49.000 --> 00:42:53.000]   And well, the keyboard is on a laptop with something that you can't avoid using, particularly when
[00:42:53.000 --> 00:42:57.000]   you're not making MacBooks with touch screens on them.
[00:42:57.000 --> 00:43:06.000]   And it's no good to have -- to be experimenting on people who are spending $1,600 to $3,000
[00:43:06.000 --> 00:43:09.000]   on what is supposed to be a premium laptop.
[00:43:09.000 --> 00:43:11.000]   And don't worry, we fixed it this time.
[00:43:11.000 --> 00:43:14.000]   Okay, well, we didn't really fix it last time, but we're going to fix it again this time.
[00:43:14.000 --> 00:43:19.000]   It's just that a keyboard is one of the simplest darned things to build.
[00:43:19.000 --> 00:43:22.000]   I realize I'm oversimplifying things.
[00:43:22.000 --> 00:43:26.000]   But when's the last time you saw a premium notebook that said, "Wow, this keyboard is
[00:43:26.000 --> 00:43:28.000]   a total piece of crap."
[00:43:28.000 --> 00:43:33.000]   And the best people can say about it is that, "Hey, I use it and I don't mind it," which
[00:43:33.000 --> 00:43:35.000]   is a totally legitimate point of view.
[00:43:35.000 --> 00:43:40.000]   I'm not saying that people who like it are wrong or they're just not as good as important
[00:43:40.000 --> 00:43:42.000]   a typist as I am.
[00:43:42.000 --> 00:43:46.000]   But it seems like this is such a solved problem.
[00:43:46.000 --> 00:43:51.000]   There are companies that make laptops that are as thin as the MacBook Pro that don't have
[00:43:51.000 --> 00:43:53.000]   to have this weird, super flat keyboard.
[00:43:53.000 --> 00:43:59.000]   And what really is, I will define earnestly the statement that this is 100% style over
[00:43:59.000 --> 00:44:04.000]   function, that this is not something that should have ever left the lab to begin with, and
[00:44:04.000 --> 00:44:08.000]   that the best move that Apple could make for the future of the MacBook is to simply not
[00:44:08.000 --> 00:44:13.000]   even have to say, "Maya Culpa, we screwed up," but simply to say, "Mysteriously enough,
[00:44:13.000 --> 00:44:17.000]   we have decided to go with a completely more conventional design for the keyboard."
[00:44:17.000 --> 00:44:22.000]   So that's all I'm getting at is that the fact that you have a controversial keyboard
[00:44:22.000 --> 00:44:29.000]   that is in and of that hasn't shaken itself down and fixed itself within one generation
[00:44:29.000 --> 00:44:32.000]   basically underscores that this is a problem.
[00:44:32.000 --> 00:44:38.000]   And I've said it before and I'll say it again, this is if I don't like the keyboard of the
[00:44:38.000 --> 00:44:43.000]   next generation of MacBooks, my next notebook is going to be a ThinkPad.
[00:44:43.000 --> 00:44:45.000]   I've got a ThinkPad in front of me.
[00:44:45.000 --> 00:44:46.000]   I love the keyboard.
[00:44:46.000 --> 00:44:47.000]   There are other things I like about it.
[00:44:47.000 --> 00:44:49.000]   I don't like Windows so much.
[00:44:49.000 --> 00:44:55.000]   At this point, the difference I think between Windows 10 and the latest version of Mac OS
[00:44:55.000 --> 00:45:03.000]   is not so broad that my dislike of Windows can't overcome my absolute inability to use
[00:45:03.000 --> 00:45:06.000]   this super flat 0.58 millimeter travel keyboard.
[00:45:06.000 --> 00:45:11.000]   And that's a hell of a thing to have to say to someone who's first, the first computer I bought
[00:45:11.000 --> 00:45:13.000]   with my own money was a Macintosh.
[00:45:13.000 --> 00:45:18.000]   And I've been a Mac user since that was the sort of thing that got you made fun of by everybody.
[00:45:18.000 --> 00:45:27.000]   But I would take all the money that I would take the money that I would save on the MacBook
[00:45:27.000 --> 00:45:32.000]   by buying a ThinkPad and use it to buy a much, much better desktop Mac instead.
[00:45:32.000 --> 00:45:38.000]   So I still have a desktop, but there's no way in hell I will be buying another MacBook
[00:45:38.000 --> 00:45:40.000]   unless they fix the keyboard.
[00:45:40.000 --> 00:45:41.000]   It's just a deal breaker.
[00:45:41.000 --> 00:45:51.000]   Andy, you make such a good point in that the butterfly keyboard is polarizing.
[00:45:51.000 --> 00:45:53.000]   People hate it.
[00:45:53.000 --> 00:45:54.000]   And that's a problem.
[00:45:54.000 --> 00:45:55.000]   It doesn't matter.
[00:45:55.000 --> 00:45:58.000]   I don't think it's like there's as many people love it as hate it.
[00:45:58.000 --> 00:46:03.000]   I think it's like there are a group of people who say it's not that bad and then people who hate it.
[00:46:03.000 --> 00:46:05.000]   But there's no one that says, "Oh, I love this keyboard."
[00:46:05.000 --> 00:46:06.000]   This is my favorite.
[00:46:06.000 --> 00:46:08.000]   No one says never.
[00:46:08.000 --> 00:46:14.000]   And that's a problem and that is absolutely true that from day one when it first came
[00:46:14.000 --> 00:46:19.600]   out, before we knew about the issues, people were saying they hated the butterfly keyboard
[00:46:19.600 --> 00:46:22.000]   and Apple didn't fix that problem.
[00:46:22.000 --> 00:46:26.000]   And you can't have a keyboard on a Mac that people hate.
[00:46:26.000 --> 00:46:29.000]   You need it to be a keyboard that people don't care about.
[00:46:29.000 --> 00:46:31.000]   Like that's the one you want.
[00:46:31.000 --> 00:46:35.000]   Yeah, you shouldn't have any, you shouldn't even know that it's there pretty much.
[00:46:35.000 --> 00:46:38.000]   It should just be something that you don't have to think about.
[00:46:38.000 --> 00:46:42.400]   If you can get that out of the way, then that's even better because if you're focusing on
[00:46:42.400 --> 00:46:44.500]   that thing, then of course it calls it out.
[00:46:44.500 --> 00:46:45.500]   We do need to take a break.
[00:46:45.500 --> 00:46:51.000]   But when we come back, we've got a lot more to talk about including a certain producer/
[00:46:51.000 --> 00:46:53.000]   I don't know, what do you call those people?
[00:46:53.000 --> 00:46:54.000]   The Beats people.
[00:46:54.000 --> 00:46:58.000]   The people that make music that's just a bunch of beeps and boops.
[00:46:58.000 --> 00:47:01.000]   One of them is using the new Mac Pro.
[00:47:01.000 --> 00:47:02.000]   Interesting.
[00:47:02.000 --> 00:47:07.000]   First, this episode of Mac Break Weekly is brought to you by ITProTV.
[00:47:07.000 --> 00:47:13.000]   Enjoy learning with ITProTV's entertainers who blend education and entertainment to make
[00:47:13.000 --> 00:47:18.000]   learning IT engaging and fun in an interactive talk show format.
[00:47:18.000 --> 00:47:21.000]   So you might be familiar with that kind of feel.
[00:47:21.000 --> 00:47:23.000]   Hopefully you've been a little bit fun and a little bit engaging today.
[00:47:23.000 --> 00:47:27.000]   So if you like that kind of thing, then you should check out ITProTV.
[00:47:27.000 --> 00:47:33.000]   Now it's a big month for Microsoft announcements.
[00:47:33.000 --> 00:47:35.000]   We covered the new stuff that Microsoft announced.
[00:47:35.000 --> 00:47:36.000]   I think that was just last week.
[00:47:36.000 --> 00:47:38.000]   And there was a lot to go through.
[00:47:38.000 --> 00:47:43.000]   You can use ITProTV to get the certs you need to become a Microsoft professional.
[00:47:43.000 --> 00:47:50.000]   ITProTV has more than 800 hours of Microsoft training, including Microsoft Azure.
[00:47:50.000 --> 00:47:56.000]   Azure, of course, is a big part of Microsoft's offerings and sort of is the backbone of a lot
[00:47:56.000 --> 00:47:58.000]   of different platforms that exist there.
[00:47:58.000 --> 00:48:04.000]   So if you want to learn more about that and become a better user of Azure and therefore
[00:48:04.000 --> 00:48:10.000]   a more valuable employee or even just to add it to your resume, then ITProTV is a great
[00:48:10.000 --> 00:48:13.000]   place to do that with more than 800 hours of training.
[00:48:13.000 --> 00:48:15.000]   ITProTV is so versatile.
[00:48:15.000 --> 00:48:21.000]   They can help you and your team get certified in IT training in all sectors, be it government,
[00:48:21.000 --> 00:48:27.000]   research services, healthcare, education, tech, finance, insurance and so much more.
[00:48:27.000 --> 00:48:32.000]   They are the official video training partner for CompTIA.
[00:48:32.000 --> 00:48:41.000]   And they have 12 CompTIA on-demand courses, including CompTIA A+, Network Plus and Security Plus certs.
[00:48:41.000 --> 00:48:46.000]   You can become part of ITProTV's family with either a standard membership, a video only,
[00:48:46.000 --> 00:48:52.000]   or a premium membership, which includes both video and labs and practice tests.
[00:48:52.000 --> 00:48:54.000]   So you get the whole kit and kaboodle there.
[00:48:54.000 --> 00:48:55.000]   You don't want to wait.
[00:48:55.000 --> 00:49:04.000]   You visit go.itpro.tv/macbreak and use the code Macbreak30 and you're going to get 30% off.
[00:49:04.000 --> 00:49:14.000]   Once again, that's go.itpro.tv/macbreak and use the code Macbreak30 for an additional 30% off
[00:49:14.000 --> 00:49:17.000]   for the lifetime of your active subscription.
[00:49:17.000 --> 00:49:20.000]   So the whole time you've got a subscription, you're getting 30% off.
[00:49:20.000 --> 00:49:22.000]   That's quite the deal.
[00:49:22.000 --> 00:49:26.000]   ITProTV, build or expand your IT career and enjoy the journey.
[00:49:26.000 --> 00:49:31.000]   Thanks so much to ITProTV for sponsoring this week's episode of Macbreak Weekly.
[00:49:31.000 --> 00:49:33.000]   Let's talk about Calvin Harris.
[00:49:33.000 --> 00:49:35.000]   Yes, folks, that was the person I was referring to.
[00:49:35.000 --> 00:49:37.000]   The DJ is the the Sherm.
[00:49:37.000 --> 00:49:40.000]   So thank you for those of you who guessed it.
[00:49:40.000 --> 00:49:42.000]   The beeps and the boops.
[00:49:42.000 --> 00:49:48.000]   So you think of a person who DJs as just somebody who makes beeps and boops?
[00:49:48.000 --> 00:49:51.000]   No, they're not invited you to the park.
[00:49:51.000 --> 00:49:53.000]   They're a lot of whoons as well.
[00:49:53.000 --> 00:49:54.000]   Yes, some oons as you're right.
[00:49:54.000 --> 00:49:56.000]   There are some oons as there's some thoughts.
[00:49:56.000 --> 00:49:57.000]   Yes, yes.
[00:49:57.000 --> 00:49:58.000]   There's some thought that goes into it.
[00:49:58.000 --> 00:50:02.000]   But what is it that people, you know, they're really it's the EDM.
[00:50:02.000 --> 00:50:04.000]   It's the beeps and the boops of the EDM.
[00:50:04.000 --> 00:50:07.000]   As a former rave jock, I take offense to the whole thing.
[00:50:07.000 --> 00:50:08.000]   So sorry.
[00:50:08.000 --> 00:50:11.000]   Those of you out there who beep and boop, I know you're doing hard work.
[00:50:11.000 --> 00:50:16.000]   Wait, wait, wait, I think I think we need to address the fact that Alex just said that he's a former rave jockey.
[00:50:16.000 --> 00:50:17.000]   What is it?
[00:50:17.000 --> 00:50:18.000]   Did you really have to do it?
[00:50:18.000 --> 00:50:19.000]   What is a rave jockey?
[00:50:19.000 --> 00:50:20.000]   Wow.
[00:50:20.000 --> 00:50:21.000]   What is that?
[00:50:21.000 --> 00:50:27.000]   I used to do I used to spin at raves a long time ago.
[00:50:27.000 --> 00:50:28.000]   That's amazing.
[00:50:28.000 --> 00:50:29.000]   Okay.
[00:50:29.000 --> 00:50:30.000]   30 years ago.
[00:50:30.000 --> 00:50:31.000]   I had my hair.
[00:50:31.000 --> 00:50:33.000]   I want to see this in real life.
[00:50:33.000 --> 00:50:34.000]   I don't.
[00:50:34.000 --> 00:50:36.000]   Oh man, I have to I have to find my stuff.
[00:50:36.000 --> 00:50:41.000]   But I had a couple MK 1200s and I had, you know, just a lot of you had a Mohawk?
[00:50:41.000 --> 00:50:43.000]   Is that what you were trying to say?
[00:50:43.000 --> 00:50:45.000]   It didn't look like a Mohawk.
[00:50:45.000 --> 00:50:48.000]   It was it was my hair was long in the center and shaved on the side.
[00:50:48.000 --> 00:50:51.000]   So it was that way, but it was a little lower and the hair was a little longer.
[00:50:51.000 --> 00:50:53.000]   So it didn't stick up or anything.
[00:50:53.000 --> 00:50:54.000]   So so it was so is.
[00:50:54.000 --> 00:50:58.000]   Does your hair still test positive for ecstasy?
[00:50:58.000 --> 00:50:59.000]   That's what you're saying.
[00:50:59.000 --> 00:51:04.000]   How long does it take for that really completely fleshes out your system?
[00:51:04.000 --> 00:51:06.000]   You just don't take the jacket anywhere.
[00:51:06.000 --> 00:51:07.000]   That's the operation.
[00:51:07.000 --> 00:51:09.000]   So it's so anyway.
[00:51:09.000 --> 00:51:12.000]   Yeah, it's so but anyway, it's a lot of work.
[00:51:12.000 --> 00:51:14.000]   It's to do it well and I wasn't great at it.
[00:51:14.000 --> 00:51:15.000]   I was like the opening guy.
[00:51:15.000 --> 00:51:19.000]   I was the guy that was there when there was like a hundred people there, not when it was
[00:51:19.000 --> 00:51:21.000]   2000, you know, or whatever.
[00:51:21.000 --> 00:51:26.000]   So Calvin Harris is posting some photos on Instagram.
[00:51:26.000 --> 00:51:30.000]   Also, I resent the fact someone saying that I must not be a club goer.
[00:51:30.000 --> 00:51:31.000]   I love going dancing.
[00:51:31.000 --> 00:51:32.000]   Thank you.
[00:51:32.000 --> 00:51:33.000]   I just forgotten the moment.
[00:51:33.000 --> 00:51:36.000]   I need to eat more almonds before the show started.
[00:51:36.000 --> 00:51:38.000]   So I said beeps and boops instead of DJ.
[00:51:38.000 --> 00:51:39.000]   I'm a robot.
[00:51:39.000 --> 00:51:40.000]   Just deal with it.
[00:51:40.000 --> 00:51:49.000]   So, Calvin Harris has been posting photo or Instagram stories of his studio and while he's working on his beeps and boops.
[00:51:49.000 --> 00:51:55.000]   And while that was going on, you can see a Mac Pro hanging out there.
[00:51:55.000 --> 00:51:56.000]   I doubt my accident.
[00:51:56.000 --> 00:51:57.000]   And it's got the wheels.
[00:51:57.000 --> 00:51:58.000]   It's got the wheels.
[00:51:58.000 --> 00:52:00.000]   It's got the it's got the modern look.
[00:52:00.000 --> 00:52:02.000]   It is not the old cheese grater.
[00:52:02.000 --> 00:52:03.000]   It is the new cheese grater.
[00:52:03.000 --> 00:52:05.000]   I need to eat the queue.
[00:52:05.000 --> 00:52:06.000]   Oh, dream.
[00:52:06.000 --> 00:52:07.000]   Oh my gosh.
[00:52:07.000 --> 00:52:09.000]   That looks amazing.
[00:52:09.000 --> 00:52:15.000]   Of course, this is the Mac Pro that starts from $5,999.
[00:52:15.000 --> 00:52:17.000]   It is a powerhouse machine.
[00:52:17.000 --> 00:52:21.000]   It is a power powerhouse machine.
[00:52:21.000 --> 00:52:25.000]   And folks are wanting to get their hands.
[00:52:25.000 --> 00:52:30.000]   They're they're an apple will make it will sell as many as they can make at that price.
[00:52:30.000 --> 00:52:34.000]   And probably at the $30,000 price, they're going to sell as many as they can make.
[00:52:34.000 --> 00:52:39.600]   So, obviously, this is this is I mean, I think, yeah, there's there's no mistake here.
[00:52:39.600 --> 00:52:47.000]   This is clearly showing one creative outlet for the use of a machine, someone who needs this machine to power the stuff that they're doing.
[00:52:47.000 --> 00:52:59.000]   But can we talk a little bit about what are some of the go to fields and go to use cases for this level of machine and why you need this versus an iPhone?
[00:52:59.000 --> 00:53:08.000]   Or as we've talked about the Mac book pro that's not necessarily pro, who is using this besides DJ beat boop Calvin Harris?
[00:53:08.000 --> 00:53:13.000]   Well, you know, for visual effects, we use pretty heavy duty machines.
[00:53:13.000 --> 00:53:14.000]   You need a lot of RAM.
[00:53:14.000 --> 00:53:16.000]   You need possibly multiple GPUs.
[00:53:16.000 --> 00:53:18.000]   You need tons of CPU power.
[00:53:18.000 --> 00:53:20.000]   And a lot of us have wanted to be able to rack mount them.
[00:53:20.000 --> 00:53:27.000]   We wanted to be able to, you know, add add new things, be able to continue to keep upgrading them if you're going to put that kind of money into it.
[00:53:27.000 --> 00:53:33.000]   So the you need a lot of power and a lot of people have been looking at.
[00:53:33.000 --> 00:53:43.000]   When people have been leaving the Mac platform specifically because we can build more powerful PCs than we can get with a Mac.
[00:53:43.000 --> 00:53:47.000]   We just got to a point where the trash can wasn't going to be enough to do anything.
[00:53:47.000 --> 00:53:49.000]   And that was like 10 days after the trash can was released.
[00:53:49.000 --> 00:54:03.000]   So the fact that we now have something that is highly scalable, that is very powerful, that Apple, I think, did all the right things with this piece of hardware, which is that they said, okay, we're not going to worry about making these.
[00:54:03.000 --> 00:54:05.000]   This is not a consumer box.
[00:54:05.000 --> 00:54:09.000]   It is a this is truly a Mac Pro.
[00:54:09.000 --> 00:54:15.000]   You know, and so they say pro in this case, I don't think in all the cases that they say pro, including the laptop.
[00:54:15.000 --> 00:54:16.000]   AirPods Pro.
[00:54:16.000 --> 00:54:17.000]   Come on.
[00:54:17.000 --> 00:54:25.000]   So this is truly a pro device, you know, and Apple was not constricted to if you know, folks who want something they're like, well, they should make it cheaper.
[00:54:25.000 --> 00:54:29.000]   Well, there's an iMac Pro, right, that has a lot of power.
[00:54:29.000 --> 00:54:31.000]   You know, the Mac Pro is very powerful.
[00:54:31.000 --> 00:54:33.000]   This is where that ends.
[00:54:33.000 --> 00:54:36.000]   And there's a little overlap between them between the two and price.
[00:54:36.000 --> 00:54:37.000]   Yeah.
[00:54:37.000 --> 00:54:40.000]   And then it goes up into the place where folks that I work with need it.
[00:54:40.000 --> 00:54:44.000]   And so if you're doing if you're going to be doing 8k video, this is going to be the machine.
[00:54:44.000 --> 00:54:50.000]   If you're going to be doing, you know, for high end, you know, visual effects, this could be the next, you know, quote unquote, SGI.
[00:54:50.000 --> 00:54:58.000]   And for those of, you know, when I was at ILM, most people, except for me, I was in the Rebel Mac unit.
[00:54:58.000 --> 00:55:07.000]   But the almost everybody else had Octanes, you know, or, or, you know, or at least what was the little one.
[00:55:07.000 --> 00:55:12.000]   There was a little little version of the Octane, O2s that were on every desk.
[00:55:12.000 --> 00:55:16.000]   And these started at 15 or $16,000, went to $6,000, $100,000.
[00:55:16.000 --> 00:55:18.000]   And people, that's what everybody had.
[00:55:18.000 --> 00:55:19.000]   Wow.
[00:55:19.000 --> 00:55:21.000]   Because that's what you needed to do this kind of work.
[00:55:21.000 --> 00:55:33.000]   And so when you're talking about this high end development work, when you're talking about scientific simulation, big math, big, you know, there's lots of places where you need to crunch serious numbers.
[00:55:33.000 --> 00:55:35.000]   And you're just not going to be able to do it.
[00:55:35.000 --> 00:55:39.000]   I have the, when we're talking about photogrammetry, I was shooting a bunch of photogrammetry.
[00:55:39.000 --> 00:55:45.000]   I built a, I built a model on my little IMac at home that has 343 million polygons.
[00:55:45.000 --> 00:55:46.000]   And you know what?
[00:55:46.000 --> 00:55:49.000]   I, I can, I hit move and then I go have a coffee.
[00:55:49.000 --> 00:55:51.000]   When I come back, it is new.
[00:55:51.000 --> 00:55:59.000]   You know, like, like it is, I, I have taken this to the outer edge and it took, it took six days for that little IMac to create that model.
[00:55:59.000 --> 00:56:00.000]   Yeah.
[00:56:00.000 --> 00:56:01.000]   You know, from the photographs.
[00:56:01.000 --> 00:56:02.000]   Wow.
[00:56:02.000 --> 00:56:03.000]   370 photographs.
[00:56:03.000 --> 00:56:05.000]   And so, so the, and that was the low res photographs.
[00:56:05.000 --> 00:56:08.000]   That wasn't like the full res photographs that it would have been much worse.
[00:56:08.000 --> 00:56:12.000]   So for that kind of work, what I need is a Mac Pro.
[00:56:12.000 --> 00:56:17.000]   And the reason I have an iMac and not a Mac Pro is because I was waiting for an actual Mac Pro.
[00:56:17.000 --> 00:56:18.000]   Yeah.
[00:56:18.000 --> 00:56:23.000]   So, so the, now I have a bigger PC that I'm using right now for the, for the bigger work.
[00:56:23.000 --> 00:56:28.000]   So I have it's got, it's got a thread ripper and a couple of big GPUs and a ton of RAM.
[00:56:28.000 --> 00:56:32.000]   And so that works pretty well for that one operation.
[00:56:32.000 --> 00:56:34.000]   But I, you know, obviously I can't wait for a Mac Pro.
[00:56:34.000 --> 00:56:39.560]   And so there's a lot of people and in Hollywood in a lot of other places, there's also going
[00:56:39.560 --> 00:56:41.120]   to be the cool factor.
[00:56:41.120 --> 00:56:44.120]   There are people who are going to get the monitor and the, and the, and the, and they're not
[00:56:44.120 --> 00:56:45.560]   going to need it.
[00:56:45.560 --> 00:56:47.480]   But it does matter.
[00:56:47.480 --> 00:56:51.920]   Like what you show up with, you know, in a production environment.
[00:56:51.920 --> 00:56:52.920]   Right.
[00:56:52.920 --> 00:56:56.280]   Tells the client that I'm making good money because I'm good at this and I'm doing this
[00:56:56.280 --> 00:56:57.280]   things.
[00:56:57.280 --> 00:56:58.760]   It, it does matter what car you drive.
[00:56:58.760 --> 00:57:01.040]   It does matter what, what computer you use.
[00:57:01.040 --> 00:57:06.680]   It does like all of those things say stability and success, you know, and they communicate
[00:57:06.680 --> 00:57:07.680]   those to the client.
[00:57:07.680 --> 00:57:12.680]   If you've ever walked into an edit suite in Hollywood or anywhere else or a, or a color
[00:57:12.680 --> 00:57:17.680]   suite or an effect suite, everything is the best that they can get.
[00:57:17.680 --> 00:57:18.680]   Right.
[00:57:18.680 --> 00:57:22.200]   Because people are spending a thousand dollars an hour or $2,000 an hour to be sitting in
[00:57:22.200 --> 00:57:23.200]   there.
[00:57:23.200 --> 00:57:25.000]   And so the, the cost of the equipment is less important.
[00:57:25.000 --> 00:57:26.960]   You want it to be shiny and really powerful.
[00:57:26.960 --> 00:57:30.720]   And so anyway, so Apple, even if you never put it in front of someone, the fact that it's
[00:57:30.720 --> 00:57:35.920]   rack mountable, the fact that it's totally extensible, it is an amazing machine.
[00:57:35.920 --> 00:57:39.480]   So it's, I'm, I'm glad a lot of us love the cheese bader.
[00:57:39.480 --> 00:57:43.200]   I'm glad we just got an, I'm totally happy with the updated cheese, cheese cake, the
[00:57:43.200 --> 00:57:44.200]   three.
[00:57:44.200 --> 00:57:45.200]   I want to quickly compare.
[00:57:45.200 --> 00:57:49.880]   So the, the display, this, this, uh, super professional.
[00:57:49.880 --> 00:57:50.960]   That's actually really.
[00:57:50.960 --> 00:57:53.360]   That's what I was about to ask.
[00:57:53.360 --> 00:57:58.080]   So let's compare what it does to a similar monitor that's available right now.
[00:57:58.080 --> 00:57:59.080]   Two or three times more.
[00:57:59.080 --> 00:58:00.080]   That's okay.
[00:58:00.080 --> 00:58:02.200]   It is an incredible value.
[00:58:02.200 --> 00:58:06.200]   What that, what this display is providing is a great value.
[00:58:06.200 --> 00:58:10.840]   And I think, I think that the, the idea behind the stand made a lot of sense, which is that
[00:58:10.840 --> 00:58:13.520]   we're going to let our designers make the best stand that's going to make this thing
[00:58:13.520 --> 00:58:15.200]   feel like it's floating.
[00:58:15.200 --> 00:58:18.200]   And if you don't want that, we're going to give you a way to, we're going to make it
[00:58:18.200 --> 00:58:19.200]   easy for you to just go ahead.
[00:58:19.200 --> 00:58:22.080]   We're not going to make you pay for that for the stand because a lot of people put them
[00:58:22.080 --> 00:58:24.920]   on walls or they have their own way that they want to mount them.
[00:58:24.920 --> 00:58:27.720]   I think the stand, you know, I is a great stand.
[00:58:27.720 --> 00:58:29.680]   I don't know if I would get the stand.
[00:58:29.680 --> 00:58:34.040]   I think I would probably buy a third party that gives me more, actually more, an ability
[00:58:34.040 --> 00:58:37.520]   to move the monitor more than what that stand's going to let me do.
[00:58:37.520 --> 00:58:40.320]   But I love the fact that Apple let their engineers go.
[00:58:40.320 --> 00:58:46.320]   And I think that in general, I think that just like a Ferrari or other folks let their
[00:58:46.320 --> 00:58:51.280]   engineers, you know, have an F1, you know, version of what they're doing, it allows them
[00:58:51.280 --> 00:58:55.560]   to press the outer envelope of what they're doing and lets the engineers run wild.
[00:58:55.560 --> 00:58:58.480]   And I think that this piece of hardware lets the engineers run wild.
[00:58:58.480 --> 00:59:04.080]   I think it'll, it'll affect things down the road with the entire line.
[00:59:04.080 --> 00:59:07.920]   But it lets people who can afford it, you know, pay for the thought process.
[00:59:07.920 --> 00:59:08.920]   Excellent.
[00:59:08.920 --> 00:59:16.440]   That was kind of my curiosity going into as we get closer to this machine and we see folks
[00:59:16.440 --> 00:59:18.240]   using it sort of.
[00:59:18.240 --> 00:59:19.240]   And as we just made sense.
[00:59:19.240 --> 00:59:23.120]   And my only thing that's missing for me is that it won't have Nvidia cards.
[00:59:23.120 --> 00:59:27.920]   I'm not an ATI fan.
[00:59:27.920 --> 00:59:31.240]   Any other thoughts on the Mac Pro?
[00:59:31.240 --> 00:59:35.400]   I genuinely have nothing to add because it's not a machine today.
[00:59:35.400 --> 00:59:40.720]   What I was just thinking though is could I get, I mean, you know, obviously money is
[00:59:40.720 --> 00:59:41.720]   a factor.
[00:59:41.720 --> 00:59:46.800]   But like what about the XTR, the Pro XTR display and the MacBook Pro, the brand new
[00:59:46.800 --> 00:59:47.800]   MacBook Pro?
[00:59:47.800 --> 00:59:50.560]   I mean, you know, is that ridiculous?
[00:59:50.560 --> 00:59:53.840]   It'd be a little ridiculous.
[00:59:53.840 --> 00:59:56.240]   I mean, you know, like it would be, you know, like if you wanted a big monitor, it means
[00:59:56.240 --> 00:59:58.080]   a really expensive monitor to do that.
[00:59:58.080 --> 01:00:01.120]   It is going to give you a very, very accurate display.
[01:00:01.120 --> 01:00:02.880]   So I think that there are reasons for you to do that.
[01:00:02.880 --> 01:00:04.080]   There's other accurate monitors.
[01:00:04.080 --> 01:00:09.040]   But if you really need a color accurate monitor that is going to be spot on and full, you
[01:00:09.040 --> 01:00:14.800]   know, not full gamut, but very close to full gamut, you are, I think that that's going
[01:00:14.800 --> 01:00:16.240]   to be a great display for you.
[01:00:16.240 --> 01:00:18.360]   And I think that there are people that are going to get that monitor.
[01:00:18.360 --> 01:00:19.360]   I think you're right.
[01:00:19.360 --> 01:00:20.840]   Maybe photographers or something.
[01:00:20.840 --> 01:00:23.920]   Photographers, people who are doing still editing, but they're not using the Mac Pro.
[01:00:23.920 --> 01:00:28.520]   They're using something smaller, like a MacBook Pro that they're going to plug into it.
[01:00:28.520 --> 01:00:35.520]   So I do think that there is a reason that people will, you know, get the monitor just
[01:00:35.520 --> 01:00:36.520]   for their laptop.
[01:00:36.520 --> 01:00:42.560]   So it's not something I would jump to immediately, but I think that it definitely will make
[01:00:42.560 --> 01:00:43.560]   sense for folks.
[01:00:43.560 --> 01:00:45.760]   And I think they were showing super high res with code.
[01:00:45.760 --> 01:00:46.760]   Yeah, they're showing code.
[01:00:46.760 --> 01:00:49.680]   You know, so that could be another reason.
[01:00:49.680 --> 01:00:51.600]   I guess we're a high paid coder.
[01:00:51.600 --> 01:00:53.600]   Not a real estate there.
[01:00:53.600 --> 01:00:54.960]   And this is not minor.
[01:00:54.960 --> 01:00:59.920]   So when you're looking at code like this, being able to see more, you know, more lines
[01:00:59.920 --> 01:01:03.240]   lets you, especially as you're trying to figure out what's wrong or what's missing or how
[01:01:03.240 --> 01:01:07.400]   this relates to something else, it's not necessarily trivial that you can, you know, that you can
[01:01:07.400 --> 01:01:09.280]   see more of it at one time.
[01:01:09.280 --> 01:01:10.280]   Right.
[01:01:10.280 --> 01:01:12.080]   But you can do that with other less expensive.
[01:01:12.080 --> 01:01:14.480]   Yeah, you can spend $700 on.
[01:01:14.480 --> 01:01:16.280]   I don't think I would buy it for that.
[01:01:16.280 --> 01:01:20.680]   But again, yeah, maybe if you're the, oh, and see here's, we're talking about, what
[01:01:20.680 --> 01:01:21.680]   is it?
[01:01:21.680 --> 01:01:22.680]   XDRs.
[01:01:22.680 --> 01:01:23.680]   I forget now.
[01:01:23.680 --> 01:01:26.800]   It's the, it's the AR package that you were talking about earlier.
[01:01:26.800 --> 01:01:27.800]   Well, you can play.
[01:01:27.800 --> 01:01:30.200]   Well, this is, yeah, this is also you play throw the monitor anywhere.
[01:01:30.200 --> 01:01:32.320]   So you can see what it would look like in your office.
[01:01:32.320 --> 01:01:33.320]   Yeah.
[01:01:33.320 --> 01:01:35.720]   And then that's how they get you.
[01:01:35.720 --> 01:01:36.720]   So that's not going to lie.
[01:01:36.720 --> 01:01:41.160]   I actually think it would be really fun to have that monitor, even though it's absolutely
[01:01:41.160 --> 01:01:43.000]   unnecessary in my household.
[01:01:43.000 --> 01:01:44.000]   Yeah.
[01:01:44.000 --> 01:01:48.720]   Throw it on top of your Ikea desktop with your, with the desk, with the chair that you stole
[01:01:48.720 --> 01:01:49.720]   from, from Staples.
[01:01:49.720 --> 01:01:50.720]   Exactly.
[01:01:50.720 --> 01:01:55.120]   If you're, if you're doing serious color work, you know, mission critical, which I don't.
[01:01:55.120 --> 01:02:00.560]   You're getting paid or solar work, whether it's video or photos, this monitor is the best,
[01:02:00.560 --> 01:02:02.080]   best buy out there.
[01:02:02.080 --> 01:02:04.000]   If you are not doing that, it's a waste of money.
[01:02:04.000 --> 01:02:05.000]   So I do.
[01:02:05.000 --> 01:02:08.920]   And some other folks, I think do suffer from seasonal depression.
[01:02:08.920 --> 01:02:12.080]   And most of the time you buy a third, you just buy a light that does that.
[01:02:12.080 --> 01:02:13.080]   You could do that.
[01:02:13.080 --> 01:02:14.800]   But you could buy this display, use it on the regular.
[01:02:14.800 --> 01:02:17.160]   It's got a thousand nits of brightness.
[01:02:17.160 --> 01:02:19.440]   It's 1,200 nits peak.
[01:02:19.440 --> 01:02:23.640]   So I can do my little treat my seasonal depression treatments with this display.
[01:02:23.640 --> 01:02:25.280]   So let's see how I get my insurance.
[01:02:25.280 --> 01:02:26.520]   Mike, I, exactly.
[01:02:26.520 --> 01:02:29.920]   I'm saying that I want to be on your insurance plan if it's covered.
[01:02:29.920 --> 01:02:30.920]   I'll let you know.
[01:02:30.920 --> 01:02:32.320]   I'll follow up with that.
[01:02:32.320 --> 01:02:34.760]   Laurie, you were about to say something.
[01:02:34.760 --> 01:02:38.120]   Um, it was so distracted by how much fun we're having.
[01:02:38.120 --> 01:02:43.360]   Oh, Alex, maybe you can remind me of this when, when Apple first announced the display,
[01:02:43.360 --> 01:02:49.920]   there was a conversation about the brightness and color accuracy that in other monitors
[01:02:49.920 --> 01:02:56.080]   at that peak that the XDR display gets, it would actually shut down other monitors or
[01:02:56.080 --> 01:02:57.080]   something like that.
[01:02:57.080 --> 01:02:59.720]   Do you know, do you remember what I'm talking about with that?
[01:02:59.720 --> 01:03:00.720]   I don't.
[01:03:00.720 --> 01:03:04.680]   I think that the problem that you end up with with other monitors is, is in this one, we'll
[01:03:04.680 --> 01:03:06.720]   still, you still have to be careful with this, I think.
[01:03:06.720 --> 01:03:11.120]   I'm not sure, but I think that you have to be careful in general, which is that a lot
[01:03:11.120 --> 01:03:13.600]   of them, a lot of them peak at a thousand nits.
[01:03:13.600 --> 01:03:16.200]   This one peaks at 1600 nits.
[01:03:16.200 --> 01:03:20.240]   And so the sustained brightness being at a thousand nits is, is, is a lot more than
[01:03:20.240 --> 01:03:21.240]   what you normally get.
[01:03:21.240 --> 01:03:24.000]   So most of the monitors are peaking at a thousand nits.
[01:03:24.000 --> 01:03:28.920]   And to put it in perspective, the, the full gamut for a HDR, I'm not going to get into
[01:03:28.920 --> 01:03:31.760]   the details of this, but the full gamut is 10,000.
[01:03:31.760 --> 01:03:36.960]   The, the, the brightest I've seen is 4,000.
[01:03:36.960 --> 01:03:43.280]   And 1000 is pretty, pretty common for an HDR display, but it's usually peaked at 1000.
[01:03:43.280 --> 01:03:47.720]   And you, you can't keep it there because it'll shorten the life of the monitor.
[01:03:47.720 --> 01:03:52.480]   So having a peak at 1600 and saying that it can withstand a thousand is, it's a lot of
[01:03:52.480 --> 01:03:53.480]   brightness.
[01:03:53.480 --> 01:03:54.480]   Yeah.
[01:03:54.480 --> 01:03:55.840]   And there's a little asterisk that takes you to the bottom of the page.
[01:03:55.840 --> 01:04:01.400]   It will peak at 1600 nits of brightness in temperatures less than 25 degrees Celsius,
[01:04:01.400 --> 01:04:03.360]   which is 77 degrees Fahrenheit.
[01:04:03.360 --> 01:04:08.120]   So as long as it can get, as long as it's maintaining that low, lower temperature, then
[01:04:08.120 --> 01:04:12.480]   it will not be working over 77 degrees for the electronics in my opinion.
[01:04:12.480 --> 01:04:13.480]   Yeah.
[01:04:13.480 --> 01:04:14.480]   Sorry.
[01:04:14.480 --> 01:04:16.800]   And it's mostly, it's, as they say, more air than metals.
[01:04:16.800 --> 01:04:17.800]   Literally.
[01:04:17.800 --> 01:04:18.800]   We've got this whole cooling system.
[01:04:18.800 --> 01:04:23.280]   It's literally in my, when, when as we were doing productions, it's literally in our rider,
[01:04:23.280 --> 01:04:25.360]   the maximum temperature is 75 degrees.
[01:04:25.360 --> 01:04:26.360]   Really?
[01:04:26.360 --> 01:04:27.360]   Yeah.
[01:04:27.360 --> 01:04:28.360]   Yeah.
[01:04:28.360 --> 01:04:29.920]   Like, you know, like, because it's not good for the equipment, you know, and so yeah,
[01:04:29.920 --> 01:04:30.920]   that's what I say anyway.
[01:04:30.920 --> 01:04:33.520]   It's not good for the M&Ms that you like to have.
[01:04:33.520 --> 01:04:34.520]   Exactly.
[01:04:34.520 --> 01:04:35.520]   You don't want those melting.
[01:04:35.520 --> 01:04:36.520]   Yeah.
[01:04:36.520 --> 01:04:37.520]   Without the brown.
[01:04:37.520 --> 01:04:38.520]   Yeah.
[01:04:38.520 --> 01:04:39.520]   Without the brown M&Ms that nobody likes.
[01:04:39.520 --> 01:04:45.840]   Now, Apple is, is going to be working on, uh, there was a, there was a bug with encryption
[01:04:45.840 --> 01:04:49.800]   for email and apparently was caused by Siri, which is interesting.
[01:04:49.800 --> 01:04:54.000]   Uh, this, this bug is something that Apple is working on, but in the meantime, there have
[01:04:54.000 --> 01:04:57.120]   been some, uh, workarounds implemented.
[01:04:57.120 --> 01:05:01.120]   I do, I've not had this issue personally.
[01:05:01.120 --> 01:05:05.280]   I don't use, um, the built in mail app for iOS.
[01:05:05.280 --> 01:05:12.040]   Uh, I'm curious if you folks as iOS users, regular iOS users and Mac OS users, raise your
[01:05:12.040 --> 01:05:13.840]   hand if you, well, you don't have to raise your hand.
[01:05:13.840 --> 01:05:14.840]   Just let me know.
[01:05:14.840 --> 01:05:18.320]   Do you use the built in default apps for mail?
[01:05:18.320 --> 01:05:19.320]   Lori Gill.
[01:05:19.320 --> 01:05:21.840]   I do on my Mac, not on my iPhone.
[01:05:21.840 --> 01:05:27.080]   Um, the, the, I, because of what I do for a living, I have to remember.
[01:05:27.080 --> 01:05:31.640]   That, um, there's built in apps that, that we have to deal with and look at and learn
[01:05:31.640 --> 01:05:34.400]   how to use so that we can tell other people how to use them.
[01:05:34.400 --> 01:05:37.800]   So on my Mac, I still have the, I'm using the built in app.
[01:05:37.800 --> 01:05:43.560]   Um, I believe the issue that if I'm not mistaken, it has to do with encrypting a message.
[01:05:43.560 --> 01:05:50.680]   Um, so if you're trying to encrypt a message, the Siri, um, suggestion will accidentally
[01:05:50.680 --> 01:05:54.280]   save that text unencrypteded.
[01:05:54.280 --> 01:06:02.520]   Um, so it's, it seems like a very, um, limited issue, but also really a big deal because people
[01:06:02.520 --> 01:06:08.400]   who need to encrypt their emails, they encrypted for a reason and having it unencrypted is,
[01:06:08.400 --> 01:06:13.160]   is such a dangerous thing for, for what they're trying to, to achieve, which is complete
[01:06:13.160 --> 01:06:14.320]   privacy.
[01:06:14.320 --> 01:06:21.160]   Um, so it, it's good to see that, that Apple is acknowledging this and they're working
[01:06:21.160 --> 01:06:25.560]   on taking care of this, but it certainly is something that, um, it's a, it's a little
[01:06:25.560 --> 01:06:32.800]   jarring to know that something that is intended to be this absolute secure way of transmitting
[01:06:32.800 --> 01:06:35.800]   an email has actually left a little cookie behind.
[01:06:35.800 --> 01:06:40.680]   That's, you know, easy, not, not hard for, you know, the little mouse to come pick up
[01:06:40.680 --> 01:06:42.880]   the crumbs from if, if they wanted to.
[01:06:42.880 --> 01:06:47.800]   Yeah, essentially you, you want to be able to ask Siri for, well, some people do want
[01:06:47.800 --> 01:06:53.080]   to be able to ask Siri for references to emails that you may have sent.
[01:06:53.080 --> 01:06:58.920]   And so as Siri is going through and saving this information, be it an email in this case,
[01:06:58.920 --> 01:07:03.440]   it's storing it in something called, I believe the, the file is called snippets.db.
[01:07:03.440 --> 01:07:07.360]   And when it's stored there, it's unencrypted despite the fact that in your email, it is
[01:07:07.360 --> 01:07:08.400]   encrypted.
[01:07:08.400 --> 01:07:12.240]   So Siri in order to see it is storing it in a place that is unencrypted.
[01:07:12.240 --> 01:07:13.480]   So that just goes against.
[01:07:13.480 --> 01:07:17.240]   Uh, there are some suggestions for what to do in this nine to five Mac article.
[01:07:17.240 --> 01:07:19.160]   There's one that I just do anyway.
[01:07:19.160 --> 01:07:21.000]   Uh, you turn on file vault.
[01:07:21.000 --> 01:07:25.160]   Uh, for folks who don't know, that's in system preferences, security and privacy and then
[01:07:25.160 --> 01:07:27.760]   file vault that encrypts your drive.
[01:07:27.760 --> 01:07:32.440]   Uh, and then you can also turn off Siri suggestions for particular apps.
[01:07:32.440 --> 01:07:39.040]   And so you can turn those off for mail and then Siri won't save those in snippets.db
[01:07:39.040 --> 01:07:42.640]   because you don't have serious suggestions turned on for that.
[01:07:42.640 --> 01:07:46.120]   I don't find myself using Siri on the Mac ever, ever, ever.
[01:07:46.120 --> 01:07:47.120]   Um,
[01:07:47.120 --> 01:07:48.120]   I don't either.
[01:07:48.120 --> 01:07:49.120]   Yeah.
[01:07:49.120 --> 01:07:53.480]   And so I should probably just turn these features off in general.
[01:07:53.480 --> 01:07:55.880]   I've kept them on just in case.
[01:07:55.880 --> 01:08:00.520]   I wanted to use Siri on the Mac, but I've genuinely never, except when I wanted to see,
[01:08:00.520 --> 01:08:04.520]   oh, they say that Siri can do this on the Mac to run a test, but other than I don't
[01:08:04.520 --> 01:08:06.480]   really use it on the Mac, which is.
[01:08:06.480 --> 01:08:07.800]   It seems awkward, doesn't it?
[01:08:07.800 --> 01:08:08.800]   Yeah.
[01:08:08.800 --> 01:08:09.800]   You should.
[01:08:09.800 --> 01:08:14.680]   I know there's a lot of people for whom voice activation and even, you know, the assistance
[01:08:14.680 --> 01:08:16.840]   of Siri on a Mac is a great idea.
[01:08:16.840 --> 01:08:21.200]   But I have not yet found a good reason to use it on a Mac.
[01:08:21.200 --> 01:08:22.200]   Yeah.
[01:08:22.200 --> 01:08:27.640]   I wish that there was a way to input via text to speak to Siri on the Mac because the number
[01:08:27.640 --> 01:08:31.000]   of times where I just wanted answers to the question and I want something a little bit
[01:08:31.000 --> 01:08:37.080]   more powerful than than using the search bar, just the ability to say schedule an appointment
[01:08:37.080 --> 01:08:41.920]   for this time, this place or what's this time.
[01:08:41.920 --> 01:08:45.240]   I can think of hopefully things that you can't just do with the search for.
[01:08:45.240 --> 01:08:51.720]   But it's very, very awkward for me to speak to my computer when I've got my hands on a
[01:08:51.720 --> 01:08:54.160]   keyboard, my thumbs on a trackpad.
[01:08:54.160 --> 01:08:57.920]   And also I probably also already have my phone nearby anyway.
[01:08:57.920 --> 01:09:01.200]   And so if I really want a voice assistant, I'm probably going to be able to use it through
[01:09:01.200 --> 01:09:02.440]   the phone anyway.
[01:09:02.440 --> 01:09:06.920]   So it's a weird implementation, I think.
[01:09:06.920 --> 01:09:12.040]   I have, I use the mail app, but I also view pretty much any electronic communication is
[01:09:12.040 --> 01:09:17.000]   unsecure.
[01:09:17.000 --> 01:09:20.560]   I don't like the idea of encrypting emails specifically because I don't want to think
[01:09:20.560 --> 01:09:22.840]   about them that way.
[01:09:22.840 --> 01:09:28.160]   So I don't think about, I don't post private stuff on Twitter, I don't have a lot of private
[01:09:28.160 --> 01:09:33.760]   conversations that I, or anything else in my DMs or anywhere because I'm just like,
[01:09:33.760 --> 01:09:37.880]   I don't, and I don't do like friends that I only share with on any social platform.
[01:09:37.880 --> 01:09:40.440]   I'm going to do social platforms, it's all public.
[01:09:40.440 --> 01:09:41.440]   It's never private.
[01:09:41.440 --> 01:09:44.120]   And it's not because, it's just because I don't want to think about it that way.
[01:09:44.120 --> 01:09:48.520]   I don't want to create, I don't want to when path came out, I started sharing pictures
[01:09:48.520 --> 01:09:50.440]   of my kids because it was only a handful of people.
[01:09:50.440 --> 01:09:52.440]   And then I was like, I'm not going to do this.
[01:09:52.440 --> 01:09:56.200]   You know, like I just, and that was when I changed my thought process away from that.
[01:09:56.200 --> 01:10:02.200]   Now if I have things that are semi complicated, but not secure conversations or stuff that
[01:10:02.200 --> 01:10:07.200]   you have in a with trusted friends face to face, like that is the, like that is, that
[01:10:07.200 --> 01:10:10.400]   is how you have secure, secure, the semi secure is something that you're going to do
[01:10:10.400 --> 01:10:11.400]   something like signal.
[01:10:11.400 --> 01:10:16.200]   You know, and that is as, as, as, as unsecure as I'm going to, you know, get with anything.
[01:10:16.200 --> 01:10:20.320]   If I'm really worried about something, where am I, where I'm talking about real secrets
[01:10:20.320 --> 01:10:22.880]   or whatever, I'm not going to use any of those communication things.
[01:10:22.880 --> 01:10:28.280]   You know, so semi secure is like a, a safe phone call and a, you know, that I'm relatively
[01:10:28.280 --> 01:10:32.960]   trust in a trustworthy place to a trustworthy person or in person, you know, or signal.
[01:10:32.960 --> 01:10:37.320]   Those are the two like that I consider semi safe, but I would still never put anything
[01:10:37.320 --> 01:10:42.760]   in there that I would worry about anybody saying because you just can't, you can't trust.
[01:10:42.760 --> 01:10:44.440]   You shouldn't, I don't know.
[01:10:44.440 --> 01:10:47.560]   I, I, my opinion is you shouldn't trust any of these.
[01:10:47.560 --> 01:10:50.040]   You, it's not safe.
[01:10:50.040 --> 01:10:56.400]   Is that specific to communication services or like, do you not have like a password protection
[01:10:56.400 --> 01:11:02.000]   or a password manager because you worry about the, you know, your password manager, I'm
[01:11:02.000 --> 01:11:04.400]   getting access or is it just the communication set?
[01:11:04.400 --> 01:11:10.240]   I actually use the last pass because of, I don't like typing, I don't like typing my
[01:11:10.240 --> 01:11:12.000]   passwords in unless I have to.
[01:11:12.000 --> 01:11:13.000]   Same, same reason.
[01:11:13.000 --> 01:11:16.920]   You know what I don't want to, it's actually, you're, you're less secure typing those passwords
[01:11:16.920 --> 01:11:21.000]   in than you are having last pass automatically fill them.
[01:11:21.000 --> 01:11:28.760]   So there's a, you know, my, both my phone and last pass have, have cripplingly long passwords,
[01:11:28.760 --> 01:11:32.200]   you know, and, and so, and I won't give them to anybody.
[01:11:32.200 --> 01:11:33.200]   Won't even breathe them.
[01:11:33.200 --> 01:11:35.080]   No, like it's not.
[01:11:35.080 --> 01:11:39.760]   So, but I, I still know that there's a chance that those things could, could happen there.
[01:11:39.760 --> 01:11:45.160]   But I do use a password, most of, so that I can not be typing them in, especially if
[01:11:45.160 --> 01:11:46.640]   I'm on a plane or in a public place.
[01:11:46.640 --> 01:11:48.320]   I don't want to type them in.
[01:11:48.320 --> 01:11:51.520]   And then I generally try to operate inside of VPNs.
[01:11:51.520 --> 01:11:55.680]   You know, so when I'm not, I don't, if I'm, I don't mind jumping on to wifi, but I want
[01:11:55.680 --> 01:11:59.680]   to have my communication, then tied down pretty quickly.
[01:11:59.680 --> 01:12:03.440]   This is actually the perfect time for us to take another break.
[01:12:03.440 --> 01:12:07.320]   Speaking of last pass, they're actually bringing us this episode.
[01:12:07.320 --> 01:12:08.320]   Good thing.
[01:12:08.320 --> 01:12:09.320]   Alex, I did not.
[01:12:09.320 --> 01:12:10.760]   I just want to point out for the record.
[01:12:10.760 --> 01:12:11.760]   Yeah.
[01:12:11.760 --> 01:12:15.320]   Alex didn't know that surprise last pass is bringing you this episode of Mac break weekly.
[01:12:15.320 --> 01:12:20.560]   Uh, it, of course, is an award winning security solution that has helped millions of individuals
[01:12:20.560 --> 01:12:27.520]   and over 43,000 organizations navigate their online lives easily and securely.
[01:12:27.520 --> 01:12:31.240]   Let's be honest, you're probably accessing different password protected accounts all
[01:12:31.240 --> 01:12:34.960]   over the place from your smartphone, your smartwatch, your laptop.
[01:12:34.960 --> 01:12:39.080]   With a last pass mobile app, you can continue to have the safety and security of logging
[01:12:39.080 --> 01:12:40.840]   in anytime, anywhere.
[01:12:40.840 --> 01:12:44.240]   And you still only need that one master password.
[01:12:44.240 --> 01:12:48.320]   Your last pass account is backed up and synced across all devices for access to your passwords,
[01:12:48.320 --> 01:12:49.880]   no matter where you are.
[01:12:49.880 --> 01:12:54.000]   All you do is download last passes password manager from the app store on your device and
[01:12:54.000 --> 01:12:57.360]   log in with the same last pass account to sync your data.
[01:12:57.360 --> 01:13:02.040]   The auto fill on mobile device removes the hassle of typing on small mobile keyboards.
[01:13:02.040 --> 01:13:04.360]   And also, as Alex pointed out, is more secure.
[01:13:04.360 --> 01:13:08.800]   So you're not in public typing in those passwords, particularly if you're not a typist and you
[01:13:08.800 --> 01:13:15.120]   are sort of hunting and pecking at keys, someone sees that and gets access to that.
[01:13:15.120 --> 01:13:16.120]   Of course, yeah.
[01:13:16.120 --> 01:13:19.680]   One of the things that's really important about last pass and why we really got into this is
[01:13:19.680 --> 01:13:26.000]   that you can share passwords with other people and in your organization that they don't see
[01:13:26.000 --> 01:13:27.000]   the password.
[01:13:27.000 --> 01:13:30.320]   So a lot of times we were working with a lot of external accounts that you, you know,
[01:13:30.320 --> 01:13:32.720]   and so we want to minimize the number of people that touch that password.
[01:13:32.720 --> 01:13:34.880]   So you can set up a password.
[01:13:34.880 --> 01:13:37.760]   You can set it up in last pass and then you put it in a folder, but you're locking down
[01:13:37.760 --> 01:13:42.120]   that password so they can log into that account if they have to, but they don't actually know
[01:13:42.120 --> 01:13:48.920]   what the password is because giving away passwords is not just the fact that you're giving someone
[01:13:48.920 --> 01:13:52.520]   something to type, but you're also creating, you're showing possible patterns of how you
[01:13:52.520 --> 01:13:54.360]   do your passwords.
[01:13:54.360 --> 01:14:01.680]   So it's important to share that as few times as possible and we used it across the company.
[01:14:01.680 --> 01:14:06.920]   That's, yeah, I hadn't considered the ability to be able to share without sharing.
[01:14:06.920 --> 01:14:08.280]   That's really nice.
[01:14:08.280 --> 01:14:13.320]   Of course, in fact, we do use last pass enterprise here at Twit.
[01:14:13.320 --> 01:14:17.820]   Everybody who needs to have access to our different Wi-Fi accounts and the other accounts
[01:14:17.820 --> 01:14:22.760]   that we use, we can all easily log into that, get access to that and there's even secure
[01:14:22.760 --> 01:14:27.000]   notes and things like that if you need to keep that data more secure.
[01:14:27.000 --> 01:14:33.160]   Of course, last pass is set up so that you can use your authentication methods that you
[01:14:33.160 --> 01:14:34.160]   already have.
[01:14:34.160 --> 01:14:40.720]   So your fingerprint, your face ID, and that gives you access to your passwords after
[01:14:40.720 --> 01:14:45.800]   you've typed in your master password, a little bit more convenience there.
[01:14:45.800 --> 01:14:53.080]   So again, having last pass available to where I'm not having to run to IT or a specific person
[01:14:53.080 --> 01:14:55.800]   and go, "Now, what is the password for that Amazon thing again?"
[01:14:55.800 --> 01:15:00.600]   And then suddenly it's being shouted out loud or it's being shared over post-it notes for
[01:15:00.600 --> 01:15:01.600]   goodness sake.
[01:15:01.600 --> 01:15:05.440]   None of that, this helps keep everything secure if you're working with a team or even as an
[01:15:05.440 --> 01:15:06.640]   individual.
[01:15:06.640 --> 01:15:10.960]   Last pass also has an expanded business lineup with some amazing features that will improve
[01:15:10.960 --> 01:15:16.160]   security across your company and make life easier for your users, make it easier for
[01:15:16.160 --> 01:15:18.040]   them which makes it easier for you.
[01:15:18.040 --> 01:15:23.560]   If you visit lastpass.com/twit, you're going to find out how they can help you.
[01:15:23.560 --> 01:15:27.840]   Lastpass.com/twit is where you want to head.
[01:15:27.840 --> 01:15:30.960]   There's our Palleo talking about last pass.
[01:15:30.960 --> 01:15:38.400]   We do enjoy it here at Twit and I know many of our listeners are last pass users and last
[01:15:38.400 --> 01:15:40.200]   pass lovers.
[01:15:40.200 --> 01:15:46.320]   It's been great for convenience but added security and giving it to your family, making sure
[01:15:46.320 --> 01:15:52.000]   that they're keeping their stuff secure is also a great little gift and a tip for the
[01:15:52.000 --> 01:15:54.080]   holiday season while you're home.
[01:15:54.080 --> 01:15:55.880]   Tell your family about last pass.
[01:15:55.880 --> 01:16:00.520]   Help them get it all set up and then of course when they need it, you can be there to help
[01:16:00.520 --> 01:16:02.280]   them from afar.
[01:16:02.280 --> 01:16:06.360]   All right, let's go and move on to this is exciting.
[01:16:06.360 --> 01:16:08.920]   I'm personally excited about this because I've been using this.
[01:16:08.920 --> 01:16:13.680]   This will probably make Alex Lindsay kind of shiver a little bit but I really like the
[01:16:13.680 --> 01:16:17.880]   health records feature in the health app for iOS.
[01:16:17.880 --> 01:16:23.560]   Basically, I can go into the health app and I can say, "Okay, now here in California,
[01:16:23.560 --> 01:16:27.360]   I'm part of the Kaiser Permanente doctor stuff."
[01:16:27.360 --> 01:16:28.360]   The health is up.
[01:16:28.360 --> 01:16:34.400]   It was a little bit different where I came from where the insurance and the actual doctor
[01:16:34.400 --> 01:16:35.920]   that I went to were separate things.
[01:16:35.920 --> 01:16:39.600]   This is a little weird where the whole system's one thing here.
[01:16:39.600 --> 01:16:44.720]   Anyway, aside from that, I can log in with my account credentials and the health app is
[01:16:44.720 --> 01:16:47.000]   able to pull down my information.
[01:16:47.000 --> 01:16:51.760]   When I go in and I get my blood pressure measure to get my height and weight measured
[01:16:51.760 --> 01:16:56.840]   and temperature and all those different things, all those panels and tests and whatever, that
[01:16:56.840 --> 01:17:02.440]   information is stored with me on my device and I am able to then keep track of it and
[01:17:02.440 --> 01:17:05.000]   add it to my health data.
[01:17:05.000 --> 01:17:08.080]   I've been using health records for quite a while.
[01:17:08.080 --> 01:17:14.640]   In fact, when I first came to Twit, one of the first things I did was after I got set
[01:17:14.640 --> 01:17:18.520]   up with Kaiser Permanente was I went on and saw that Kaiser Permanente was not an option
[01:17:18.520 --> 01:17:19.520]   for integration.
[01:17:19.520 --> 01:17:21.520]   I was like, "I thought this was California.
[01:17:21.520 --> 01:17:23.880]   I thought we were just north of Silicon Valley.
[01:17:23.880 --> 01:17:25.440]   What's going on?"
[01:17:25.440 --> 01:17:27.440]   But they recently added for-
[01:17:27.440 --> 01:17:30.280]   Staying your longer, you realize that we can't even keep the power on.
[01:17:30.280 --> 01:17:31.280]   Exactly.
[01:17:31.280 --> 01:17:32.280]   Exactly.
[01:17:32.280 --> 01:17:33.280]   Bye, Golly.
[01:17:33.280 --> 01:17:35.000]   That was an exciting thing for me.
[01:17:35.000 --> 01:17:39.720]   But Apple and the US Department of Veterans have announced that veterans can now access
[01:17:39.720 --> 01:17:43.920]   their health records on their iPhone via Apple's health app.
[01:17:43.920 --> 01:17:46.080]   By the way, I actually think this is great.
[01:17:46.080 --> 01:17:50.000]   I think that your phone is probably the most secure place that your medical records are.
[01:17:50.000 --> 01:17:51.000]   That's a good point.
[01:17:51.000 --> 01:17:52.000]   I hate to break it to you all.
[01:17:52.000 --> 01:17:53.000]   That's fair.
[01:17:53.000 --> 01:17:56.040]   So there's a lot of people touching medical records and there's a lot of access to them.
[01:17:56.040 --> 01:17:59.440]   I think that Apple has gone through an enormous amount of trouble to secure this.
[01:17:59.440 --> 01:18:06.120]   I think this is where Apple's work on privacy is paying off, where they can take on these
[01:18:06.120 --> 01:18:11.480]   kinds of things and people might actually want to use them.
[01:18:11.480 --> 01:18:17.840]   I think doing it for veterans and obviously the announcement near Veterans Day is a great
[01:18:17.840 --> 01:18:18.840]   thing.
[01:18:18.840 --> 01:18:19.840]   So I think that's great.
[01:18:19.840 --> 01:18:25.880]   I think it also is easier for them to do because it's a large national unified solution.
[01:18:25.880 --> 01:18:29.160]   I wouldn't be surprised if we saw Medicare somewhere down the path.
[01:18:29.160 --> 01:18:30.160]   Yeah.
[01:18:30.160 --> 01:18:34.800]   Because we get to do all of it at one time rather than the piecemeal.
[01:18:34.800 --> 01:18:43.040]   So it lets you work on it and build trust and it'll help bring in more health care providers,
[01:18:43.040 --> 01:18:44.040]   I think.
[01:18:44.040 --> 01:18:46.680]   It says more than 400 health systems have signed on.
[01:18:46.680 --> 01:18:50.080]   That list is getting long if you go in and click the little add button to try and add
[01:18:50.080 --> 01:18:52.320]   your system to find yours.
[01:18:52.320 --> 01:18:55.880]   It does surface the ones that are closest to you.
[01:18:55.880 --> 01:18:59.440]   It asks for your location to let you get plugged in.
[01:18:59.440 --> 01:19:04.880]   But yeah, this has partnered with the, or worked with the Department of Veteran Affairs.
[01:19:04.880 --> 01:19:12.880]   And it's a great way too for doctors to, for a patient to sort of work a little bit closer
[01:19:12.880 --> 01:19:17.400]   with their doctor where a lot of times, you know, your doctor might say, "Oh yeah, here's
[01:19:17.400 --> 01:19:18.400]   a info sheet."
[01:19:18.400 --> 01:19:23.600]   It's this giant eight and a half by 11 page and there's this little link on it and it's
[01:19:23.600 --> 01:19:26.640]   a long link instead of a bitlier or something like that.
[01:19:26.640 --> 01:19:27.640]   It's not shortened.
[01:19:27.640 --> 01:19:31.040]   You go there to this online web portal and you can keep track of this and that and find
[01:19:31.040 --> 01:19:33.080]   out how all these integrations need to be plugged in.
[01:19:33.080 --> 01:19:36.400]   And that gets a little confusing, a little complicated.
[01:19:36.400 --> 01:19:39.360]   And so this feature where, "Oh, it's suddenly on my phone.
[01:19:39.360 --> 01:19:44.880]   I can see now that my lab panels have come through and I get a notification on my phone,
[01:19:44.880 --> 01:19:46.960]   "Hey, you've got some new records available."
[01:19:46.960 --> 01:19:48.720]   You can go in right there and see.
[01:19:48.720 --> 01:19:56.080]   And the cool thing is the Health app, it integrates with the national health systems and the databases
[01:19:56.080 --> 01:19:59.240]   for different tests.
[01:19:59.240 --> 01:20:06.320]   And so it has sort of the standard deviation and the average for the tests that are healthy.
[01:20:06.320 --> 01:20:11.560]   And so you can see where your blood panel might be in or outside of those tests.
[01:20:11.560 --> 01:20:15.560]   It works with prescription medications as well and gives you more information about those.
[01:20:15.560 --> 01:20:19.240]   It's got a lot of information in there and I found it helpful for myself and so I'm glad
[01:20:19.240 --> 01:20:22.240]   that the VA is also adding this on.
[01:20:22.240 --> 01:20:27.640]   And I hope that folks are given proper tutorials for how to take advantage of it because I
[01:20:27.640 --> 01:20:30.720]   think that it can be helpful if they are.
[01:20:30.720 --> 01:20:35.560]   I think that we're going to keep moving slowly as I think Apple is doing the same thing they're
[01:20:35.560 --> 01:20:41.240]   doing where they are, which is that we're slowly adding parts of this puzzle into the
[01:20:41.240 --> 01:20:42.240]   process.
[01:20:42.240 --> 01:20:45.080]   But I think that this is a super important thing for Apple to do.
[01:20:45.080 --> 01:20:49.120]   But I think we're going to start seeing also right now we're not keeping track of all of
[01:20:49.120 --> 01:20:53.800]   our data from our watch isn't all going into this currently.
[01:20:53.800 --> 01:20:57.040]   But I think that as we build trust and as we do those things we're going to start seeing
[01:20:57.040 --> 01:21:02.880]   a point where we are tracking all of our health data and more and more of our health data
[01:21:02.880 --> 01:21:06.160]   where we're able to provide our doctors with more.
[01:21:06.160 --> 01:21:07.240]   And we're going to start seeing things.
[01:21:07.240 --> 01:21:14.080]   I think that when we anonymize all this data, so differential privacy being able to
[01:21:14.080 --> 01:21:16.320]   start seeing patterns.
[01:21:16.320 --> 01:21:20.520]   So if you start tying and I don't think Apple is going to do this anytime soon, so before
[01:21:20.520 --> 01:21:24.480]   everyone starts putting on their foil hats, but there is some point where we start tying
[01:21:24.480 --> 01:21:30.600]   our DNA records to the data.
[01:21:30.600 --> 01:21:33.080]   And it can be anonymized.
[01:21:33.080 --> 01:21:36.080]   But the idea is we're going to start to be able to see trends.
[01:21:36.080 --> 01:21:41.080]   Okay, so I see you having this happening with your heart or this resting heart rate.
[01:21:41.080 --> 01:21:43.080]   We're going to see things that we never saw before.
[01:21:43.080 --> 01:21:44.080]   Ever.
[01:21:44.080 --> 01:21:49.760]   There's going to be things that we see that are happening with your body that we now know
[01:21:49.760 --> 01:21:53.560]   are a precursor to something really bad happening in six months or three months or two months
[01:21:53.560 --> 01:21:54.560]   or whatever.
[01:21:54.560 --> 01:21:57.800]   And we're able to say, you should probably go in for a doctor's appointment.
[01:21:57.800 --> 01:21:59.800]   Can I schedule that for you?
[01:21:59.800 --> 01:22:02.480]   And so I think that's a decade away.
[01:22:02.480 --> 01:22:05.240]   I don't think that there's a lot of things that we have to do between now and then and
[01:22:05.240 --> 01:22:06.240]   there's going to be more features.
[01:22:06.240 --> 01:22:10.160]   But I think that this is definitely Apple kind of creeping up that path.
[01:22:10.160 --> 01:22:11.160]   Absolutely.
[01:22:11.160 --> 01:22:13.760]   I need to go back and look for it.
[01:22:13.760 --> 01:22:20.760]   But I recently interviewed someone on triangulation about this specific topic.
[01:22:20.760 --> 01:22:29.240]   And one of the issues that we as humans have is that we want to have explanations for every
[01:22:29.240 --> 01:22:37.520]   pattern, everything, every answer that comes from a given process.
[01:22:37.520 --> 01:22:40.400]   And sometimes there just aren't answers.
[01:22:40.400 --> 01:22:45.440]   So David Weinberger wrote this book called Everyday Chaos and it's technology, complexity
[01:22:45.440 --> 01:22:48.280]   and how we're thriving in a new world of possibility.
[01:22:48.280 --> 01:22:56.160]   And so in this book, he talks about how AI and big data are way more complex and unpredictable
[01:22:56.160 --> 01:23:01.280]   than we realize and then we kind of allow ourselves to realize.
[01:23:01.280 --> 01:23:05.560]   And it's like that Pocahontas quote, how can there be so much that you don't know, you
[01:23:05.560 --> 01:23:06.600]   don't know.
[01:23:06.600 --> 01:23:10.640]   We really don't know how powerful this stuff is.
[01:23:10.640 --> 01:23:15.040]   But instead of giving over to that chaos, that everyday chaos, we want to sort of hold
[01:23:15.040 --> 01:23:19.520]   back and say, I need to know why that does that or why that doesn't do that.
[01:23:19.520 --> 01:23:20.760]   So he talks about A/B testing.
[01:23:20.760 --> 01:23:21.760]   He talks about all these things.
[01:23:21.760 --> 01:23:26.840]   But the big thing is it starts with a conversation about how there are right now essentially
[01:23:26.840 --> 01:23:31.960]   like a big black box that you can take someone's whole history of their health and put it
[01:23:31.960 --> 01:23:33.480]   into this big black box.
[01:23:33.480 --> 01:23:37.800]   And then out the other end spits this little thing that says, hey, you might want to get
[01:23:37.800 --> 01:23:38.800]   tested for this.
[01:23:38.800 --> 01:23:40.560]   Hey, you might want to change this about your diet.
[01:23:40.560 --> 01:23:42.480]   Hey, you might want to do this.
[01:23:42.480 --> 01:23:47.280]   And right now we see that information and we want to go, now how did you come to that?
[01:23:47.280 --> 01:23:51.480]   But to be able to understand that our minds need to be that big black box of AI computing
[01:23:51.480 --> 01:23:54.600]   that's looking at all of those data points simultaneously.
[01:23:54.600 --> 01:24:00.320]   And if we can let ourselves sort of look past that and just accept that some things are
[01:24:00.320 --> 01:24:04.080]   the things we can't explain, but that that data is there, that's kind of what the conversation
[01:24:04.080 --> 01:24:05.080]   was about in the book.
[01:24:05.080 --> 01:24:10.000]   But I found it interesting in terms of, yeah, when we start tracking all of this data and
[01:24:10.000 --> 01:24:16.200]   find a place to put it that we feel safe with it, then we can catch things early on.
[01:24:16.200 --> 01:24:21.760]   I think of it in the same way that I think of what my life was like before Yelp.
[01:24:21.760 --> 01:24:23.920]   You know, like I don't know where to go eat.
[01:24:23.920 --> 01:24:27.920]   You know, like, and now my whole way, like I went to India and there was no like, there
[01:24:27.920 --> 01:24:30.400]   was no Yelp working in the cities that I was in.
[01:24:30.400 --> 01:24:32.120]   And I was like, how am I supposed to do this?
[01:24:32.120 --> 01:24:35.720]   Like, you know, now I'm just going to have to walk around and find someplace, you know,
[01:24:35.720 --> 01:24:37.840]   like this is, this is crazy.
[01:24:37.840 --> 01:24:42.000]   You know, and so the, but I think that that we've gotten used to a lot of other parts
[01:24:42.000 --> 01:24:49.520]   of our life that are highly organized because of kind of a group data that has been added
[01:24:49.520 --> 01:24:51.080]   for better and for us.
[01:24:51.080 --> 01:24:54.520]   You know, but, but I think that, you know, there's going to be a lot around health that's
[01:24:54.520 --> 01:24:56.920]   going to benefit us in the future.
[01:24:56.920 --> 01:24:57.920]   Yeah.
[01:24:57.920 --> 01:25:02.720]   Do you folks use apples or do you do any health tracking, activity tracking, anything like
[01:25:02.720 --> 01:25:06.600]   that with your Apple watches or other wearables, Andy?
[01:25:06.600 --> 01:25:10.720]   Not to the extent that I don't make, I don't make full use of the features of the Apple
[01:25:10.720 --> 01:25:15.480]   Watch and big be, although I've been wearing it practically daily since I got it a few
[01:25:15.480 --> 01:25:20.280]   months ago, it's mostly it's just keeping an eye on my level of activity throughout the
[01:25:20.280 --> 01:25:21.280]   day.
[01:25:21.280 --> 01:25:23.240]   But yeah, what else is saying is absolutely true.
[01:25:23.240 --> 01:25:28.240]   It's there, there are things you can't, there, the things that happen when you start collecting
[01:25:28.240 --> 01:25:32.640]   data about yourself, even if it's just simply a spreadsheet that you're just making a tick
[01:25:32.640 --> 01:25:36.200]   mark saying today I felt good today, I felt not so good.
[01:25:36.200 --> 01:25:41.040]   And then when you get in the habit of just that binary good, not so good, if you've been,
[01:25:41.040 --> 01:25:47.080]   if you create that habit, you add like maybe one more column, like every month, like did
[01:25:47.080 --> 01:25:49.000]   I get do I feel like I got a lot of sleep today?
[01:25:49.000 --> 01:25:50.920]   I know I did yes or no.
[01:25:50.920 --> 01:25:52.880]   Did I feel like I ate well today?
[01:25:52.880 --> 01:25:53.880]   Yes or no?
[01:25:53.880 --> 01:25:55.280]   Do I feel like I was really active today?
[01:25:55.280 --> 01:25:56.280]   Yes or no?
[01:25:56.280 --> 01:26:00.600]   And once it's not something that's useful after about a month, it's something that's
[01:26:00.600 --> 01:26:05.880]   useful after a year or two, when you suddenly realize that, oh, look, there seems to be
[01:26:05.880 --> 01:26:11.080]   a pattern here that that time where I was eating, there was Thanksgiving, I had lots
[01:26:11.080 --> 01:26:12.080]   and lots of sugar.
[01:26:12.080 --> 01:26:16.120]   I was not only did I like not feel like I was very active, not only was I not very active
[01:26:16.120 --> 01:26:21.480]   for the next two or three days, but I was also I also described myself as being in a
[01:26:21.480 --> 01:26:26.240]   down or grumpy mood for three days after that, perhaps as a correlation there.
[01:26:26.240 --> 01:26:33.800]   The I will say cynically, however, that this will be a great technology for every country
[01:26:33.800 --> 01:26:39.960]   other than the United States of America, because you the biggest feature of such a data collection
[01:26:39.960 --> 01:26:45.520]   and analysis program is going to have to be making sure that there that it is legally
[01:26:45.520 --> 01:26:50.720]   not possible for an insurance company to screw you based on the fact that you allowed you
[01:26:50.720 --> 01:26:53.720]   allowed information about yourself to be tracked.
[01:26:53.720 --> 01:27:01.080]   Because as as it is, the idea of the very last thing that I would allow an ensure potential
[01:27:01.080 --> 01:27:05.800]   insurer or an insurer to have his access to my genetic records, or I don't even want them
[01:27:05.800 --> 01:27:12.200]   to know like what did my parents die of what my grandparents die of because I've we live
[01:27:12.200 --> 01:27:16.320]   in a kind of like a healthcare hell in the United States.
[01:27:16.320 --> 01:27:19.200]   Everyone who's listening from outside the United States, everything you heard is absolutely
[01:27:19.200 --> 01:27:20.200]   true.
[01:27:20.200 --> 01:27:24.960]   If you are in that if you are in that bracket of people that happen to have good corporate
[01:27:24.960 --> 01:27:29.280]   good health care, because you're part of a large company that made sure that you have
[01:27:29.280 --> 01:27:32.480]   good health care and didn't skimp on it, that's great.
[01:27:32.480 --> 01:27:36.640]   Otherwise, you know that even if you are covered by insurance, there's going to be a good
[01:27:36.640 --> 01:27:40.680]   chance that this company is going to fight you on every single transaction that they have
[01:27:40.680 --> 01:27:41.880]   promised to give you.
[01:27:41.880 --> 01:27:45.080]   And if you don't have insurance that they're going to fight to make sure that they're not
[01:27:45.080 --> 01:27:53.640]   going to take you unless you have really unless you have the equivalent of like an 800 credit
[01:27:53.640 --> 01:27:55.480]   score for health.
[01:27:55.480 --> 01:28:00.400]   Meaning that all of your all of your family have died of no of natural causes, no age
[01:28:00.400 --> 01:28:02.120]   younger than 100.
[01:28:02.120 --> 01:28:03.960]   And you don't drive a car.
[01:28:03.960 --> 01:28:05.560]   You don't you don't do anything.
[01:28:05.560 --> 01:28:12.200]   It's I've been through this where it's just absolutely impossible to get treated as though
[01:28:12.200 --> 01:28:17.680]   you you deserve to have health care because you're a human being who has had very good
[01:28:17.680 --> 01:28:23.000]   look up to now, but God forbid you step off a curb at the wrong time or God forbid there
[01:28:23.000 --> 01:28:27.760]   is an embolism that's been waiting for a really amusing time to burst on you.
[01:28:27.760 --> 01:28:36.560]   So I really feel as though data is the is your most important tool as an individual who wants
[01:28:36.560 --> 01:28:42.080]   to stay healthy and wants to get adequate, adequate diagnoses, it is your absolute enemy
[01:28:42.080 --> 01:28:44.400]   when it comes to dealing with the American health care industry.
[01:28:44.400 --> 01:28:52.360]   So once once we have like European style protections in place and we have to realize that the
[01:28:52.360 --> 01:28:56.900]   times where Google has been nailed to the wall for collecting health care information
[01:28:56.900 --> 01:28:58.600]   and improperly it's been the EU.
[01:28:58.600 --> 01:29:01.760]   It's has not been the United States who has done that.
[01:29:01.760 --> 01:29:05.440]   Once those protections are in place, that's when these beautiful things can start to happen,
[01:29:05.440 --> 01:29:07.600]   but really pretty much not before.
[01:29:07.600 --> 01:29:10.360]   Well, but now Laurie, what about you?
[01:29:10.360 --> 01:29:14.720]   Are you a activity tracker health app user?
[01:29:14.720 --> 01:29:22.160]   So I've I've, Micah, you and I have have known each other since since the day health
[01:29:22.160 --> 01:29:29.060]   records was available in the health app and I was just kind of, well, you know, it's not
[01:29:29.060 --> 01:29:31.020]   available around here and I don't know.
[01:29:31.020 --> 01:29:32.540]   I'm not that worried about it.
[01:29:32.540 --> 01:29:37.980]   Just now when you were talking about it and you mentioned that more organizations are now
[01:29:37.980 --> 01:29:42.420]   using it, I just popped into the health app and literally when we were talking, I added
[01:29:42.420 --> 01:29:49.220]   my my insurance account to the health records and I actually found the information kind of
[01:29:49.220 --> 01:29:50.220]   fascinating.
[01:29:50.220 --> 01:29:56.600]   It has all of the appointments that I've had dating back at least a year.
[01:29:56.600 --> 01:30:02.200]   It just has that basic information, my blood pressure, my weight, my, you know, all my
[01:30:02.200 --> 01:30:04.360]   to that I say my temperature like things like that.
[01:30:04.360 --> 01:30:06.680]   It's all just in there.
[01:30:06.680 --> 01:30:11.760]   And for me, I look at this stuff and I don't see anything I need to know.
[01:30:11.760 --> 01:30:18.120]   I also don't see anything that that from my perspective is important to track.
[01:30:18.120 --> 01:30:27.740]   But knowing that it's there, I feel that I now have I'm more empowered to use my health
[01:30:27.740 --> 01:30:34.240]   information where I need to and where I want to instead of having to rely on the doctor's
[01:30:34.240 --> 01:30:40.780]   office to provide that to me, it's my health data and they are the ones that are keeping
[01:30:40.780 --> 01:30:45.260]   track of it, which, you know, for our privacy and security, that's fine.
[01:30:45.260 --> 01:30:50.240]   But I also am beholden to them when they're the ones in charge of it.
[01:30:50.240 --> 01:30:54.200]   And I feel now that it's sitting here on my phone, I actually feel more in charge of
[01:30:54.200 --> 01:30:59.320]   my health data right now, just just having done that in the couple of minutes since you
[01:30:59.320 --> 01:31:00.480]   started talking about it.
[01:31:00.480 --> 01:31:01.480]   So it's interesting.
[01:31:01.480 --> 01:31:05.200]   And this is going to make a bigger difference also when we start moving to more and more
[01:31:05.200 --> 01:31:10.520]   virtual medicine, which is what we're seeing Amazon experimenting with a lot that probably
[01:31:10.520 --> 01:31:17.340]   terrify every insurance company out there, that, you know, the man who says your margin
[01:31:17.340 --> 01:31:18.340]   is my opportunity.
[01:31:18.340 --> 01:31:22.260]   There's a lot of margin that is this opportunity.
[01:31:22.260 --> 01:31:26.980]   So, so we're seeing some experimentation that Amazon's doing with virtual medicine and a
[01:31:26.980 --> 01:31:28.460]   lot of other folks are doing as well.
[01:31:28.460 --> 01:31:31.860]   But this kind of getting this all on your iPhone, getting it portable, getting it something
[01:31:31.860 --> 01:31:36.140]   that you can send and share with the people that you trust to do that is going to be something
[01:31:36.140 --> 01:31:39.340]   that's going to become more and more important as we move down that path.
[01:31:39.340 --> 01:31:40.340]   Okay.
[01:31:40.340 --> 01:31:41.980]   Let's see.
[01:31:41.980 --> 01:31:44.920]   We have got to talk about this story.
[01:31:44.920 --> 01:31:47.700]   There was a, there was a series of tweets.
[01:31:47.700 --> 01:31:49.960]   I think we now call that a thread.
[01:31:49.960 --> 01:31:57.160]   It was at one point called a tweet storm about apple card.
[01:31:57.160 --> 01:32:01.960]   And now, so, so there was, there was a, there was a series of tweets that went out and it
[01:32:01.960 --> 01:32:09.120]   was about DHH who is the, what is it co-creator or the creator of Ruby on Rails.
[01:32:09.120 --> 01:32:15.600]   He signed up for the apple card and his wife signed up for the apple card.
[01:32:15.600 --> 01:32:21.760]   And when he signed up for the apple card, he had a Giganto credit limit and he and his
[01:32:21.760 --> 01:32:24.320]   wife filed their tax return together.
[01:32:24.320 --> 01:32:30.440]   There are all these things that point to them both being ranked by algorithms exactly the
[01:32:30.440 --> 01:32:31.440]   same.
[01:32:31.440 --> 01:32:36.360]   There, her credit score was higher than his even and all these things that pointed to
[01:32:36.360 --> 01:32:39.880]   when she signed up, you would think that she would have the same credit limit.
[01:32:39.880 --> 01:32:46.360]   For some reason, she had a much smaller credit limit, much, much, much smaller credit limit.
[01:32:46.360 --> 01:32:52.640]   And also there was another, there was another bit of a, of a barrier added on her account
[01:32:52.640 --> 01:32:58.320]   where say she spent $30 somewhere with her apple card, if she were to go and pay that
[01:32:58.320 --> 01:33:06.040]   $30 on her card, she wouldn't actually gain access to that credit limit addition until
[01:33:06.040 --> 01:33:08.320]   the next statement came through.
[01:33:08.320 --> 01:33:11.840]   So all these barriers were being put on her account for some reason and he wasn't sure
[01:33:11.840 --> 01:33:14.640]   why and she wasn't sure why.
[01:33:14.640 --> 01:33:20.520]   And so they reached out to both apple support and then it seems like they spoke to Goldman
[01:33:20.520 --> 01:33:27.920]   Sachs and DHH that's @dhh on Twitter was, you know, sort of talking about how this all
[01:33:27.920 --> 01:33:32.200]   went down and what every step of this was.
[01:33:32.200 --> 01:33:37.760]   And while this was going on, while the complaints were being made, then suddenly her credit
[01:33:37.760 --> 01:33:41.120]   limit jumped to the same one that he had.
[01:33:41.120 --> 01:33:46.400]   And there was no clear communication about why the credit limit had changed.
[01:33:46.400 --> 01:33:51.040]   When they spoke to some support teams, the support team said, look, we don't know.
[01:33:51.040 --> 01:33:52.200]   It's a black box.
[01:33:52.200 --> 01:33:56.440]   It's the algorithms determine things and we're not sure why you originally didn't have that
[01:33:56.440 --> 01:33:58.520]   credit limit and you do now.
[01:33:58.520 --> 01:34:03.560]   And so he said, speaking to both apple and Goldman Sachs, the people that they were able
[01:34:03.560 --> 01:34:09.880]   to talk to, no one knew why the system had had done it differently.
[01:34:09.880 --> 01:34:15.640]   And the there was an original claim, you know, from from DHH that this was an example of bias
[01:34:15.640 --> 01:34:23.160]   in AI and artificial intelligence that led to a sexist decision that resulted in him having
[01:34:23.160 --> 01:34:29.160]   a higher credit limit than his wife, because he was trying to find other ways to show or
[01:34:29.160 --> 01:34:33.160]   to come across some other means to show why she would have a lower credit limit, despite
[01:34:33.160 --> 01:34:36.360]   the fact that she had a higher credit score.
[01:34:36.360 --> 01:34:40.600]   The only other point I want to add before we break into the discussion here is that the
[01:34:40.600 --> 01:34:46.520]   New York's there's a New York organization that's in charge of making sure that New York's
[01:34:46.520 --> 01:34:50.200]   laws, financial laws are followed.
[01:34:50.200 --> 01:34:51.960]   And I wish I could remember the name of the department.
[01:34:51.960 --> 01:34:56.280]   Basically, they are looking into they're doing a Goldman Sachs probe now to determine if
[01:34:56.280 --> 01:35:05.240]   laws were broken, because in New York it is illegal to discriminate against someone financially
[01:35:05.240 --> 01:35:07.240]   based on their sex.
[01:35:07.240 --> 01:35:11.560]   And I assume that that's the case in many places, but I can't speak for some states,
[01:35:11.560 --> 01:35:12.560]   who knows.
[01:35:12.560 --> 01:35:15.600]   So yeah, that that all has been going on.
[01:35:15.600 --> 01:35:21.720]   And DHH now has sort of been out in the open about this and Steve Wozniak even got involved
[01:35:21.720 --> 01:35:27.240]   and said that he and his wife had the same thing where he had a higher rating or had
[01:35:27.240 --> 01:35:28.560]   more money than she did.
[01:35:28.560 --> 01:35:30.560]   So let's talk about this.
[01:35:30.560 --> 01:35:32.880]   So I don't know a lot about it.
[01:35:32.880 --> 01:35:38.680]   In fact, I've spent most of my life with a lower credit limit than my wife.
[01:35:38.680 --> 01:35:43.360]   So she feels much better about those things than I am.
[01:35:43.360 --> 01:35:47.680]   But I did consult with some folks that know a little bit more than I do about this.
[01:35:47.680 --> 01:35:51.400]   And one of the things that they said is what we don't know, they're not saying that it's
[01:35:51.400 --> 01:35:52.400]   not the same.
[01:35:52.400 --> 01:35:53.680]   And they said they should absolutely look at the algorithm.
[01:35:53.680 --> 01:35:55.680]   They should absolutely look at before we start.
[01:35:55.680 --> 01:36:00.440]   But before we start running around with torches, what they brought up was what we don't know
[01:36:00.440 --> 01:36:03.600]   about that is number one is the credit score is not the only thing.
[01:36:03.600 --> 01:36:06.640]   So your credit score is not the only thing they use that the algorithm uses to calculate
[01:36:06.640 --> 01:36:07.640]   it.
[01:36:07.640 --> 01:36:08.640]   There is credit utilization.
[01:36:08.640 --> 01:36:12.800]   So there's the how much of your credit are you using and how much is out, you know,
[01:36:12.800 --> 01:36:16.800]   and it's also credit utilization history across a long period of time.
[01:36:16.800 --> 01:36:18.360]   It can be looking at those things.
[01:36:18.360 --> 01:36:23.520]   What has your credit limit been for the last decade or the last seven years or whatever?
[01:36:23.520 --> 01:36:26.920]   So there's a running average of that process.
[01:36:26.920 --> 01:36:28.920]   Also who applied first?
[01:36:28.920 --> 01:36:34.080]   If you have joint financials, one person getting a lot of credit can affect the other
[01:36:34.080 --> 01:36:37.080]   person, the other person's ability to do the same thing.
[01:36:37.080 --> 01:36:43.520]   So they're not saying that there could be something very wrong with the algorithm.
[01:36:43.520 --> 01:36:46.960]   They said it's not probably something that is vicious.
[01:36:46.960 --> 01:36:51.160]   It's probably something that is just an odd, you know, it's just picked up something that
[01:36:51.160 --> 01:36:54.240]   it's not doing correctly.
[01:36:54.240 --> 01:36:56.120]   And they can, you know, it'll get fixed.
[01:36:56.120 --> 01:36:58.840]   It's something that needs to be addressed and needs to be looked at.
[01:36:58.840 --> 01:37:02.320]   But there are other factors, at least that I'm told.
[01:37:02.320 --> 01:37:07.040]   And again, I'm not the expert on this area, but I'm told that there are other factors
[01:37:07.040 --> 01:37:11.080]   in that calculation that are probably creating the errata that people are seeing.
[01:37:11.080 --> 01:37:13.600]   There's probably not a errata that's occurring for everyone.
[01:37:13.600 --> 01:37:17.680]   There's probably a handful of things that are happening that cause the algorithm to flip
[01:37:17.680 --> 01:37:20.800]   and they're definitely going to look at it.
[01:37:20.800 --> 01:37:21.800]   And they definitely should.
[01:37:21.800 --> 01:37:25.000]   But it's probably not someone in there trying to make it one way or the other or having
[01:37:25.000 --> 01:37:26.440]   any opinion about it.
[01:37:26.440 --> 01:37:28.120]   It's an algorithm that's just looking at a bunch of numbers.
[01:37:28.120 --> 01:37:29.120]   Yeah.
[01:37:29.120 --> 01:37:34.600]   And I wanted to point out that DHH even says in the series of tweets, I am not under the
[01:37:34.600 --> 01:37:40.000]   assumption that there's some nefarious human being out there making this sexist decision.
[01:37:40.000 --> 01:37:43.880]   He was bringing the seemingly sexist decision to light.
[01:37:43.880 --> 01:37:47.280]   He was bringing it to light and saying, "Look, this is what's going on."
[01:37:47.280 --> 01:37:49.000]   And nobody's able to answer the question.
[01:37:49.000 --> 01:37:50.000]   And that's where the problem exists.
[01:37:50.000 --> 01:37:51.000]   Yeah.
[01:37:51.000 --> 01:37:55.680]   The thing that the person that I talked to or the folks that I referred to is that the
[01:37:55.680 --> 01:37:58.360]   number one thing is you have to have people who can answer the phone that can solve the
[01:37:58.360 --> 01:37:59.360]   problem.
[01:37:59.360 --> 01:38:02.600]   Like that it's not that the algorithm is going to be perfect.
[01:38:02.600 --> 01:38:05.960]   It's just that you can't put people in a circle when they can't figure it out.
[01:38:05.960 --> 01:38:09.440]   When something's obviously wrong, there has to be someone that you can get to make that
[01:38:09.440 --> 01:38:11.760]   decision and fix that decision.
[01:38:11.760 --> 01:38:14.760]   And there's just always going to be error corrections in this process.
[01:38:14.760 --> 01:38:19.440]   I mean, and if you call, I mean, I've called credit cards and just gotten them to give
[01:38:19.440 --> 01:38:24.480]   me another 5,000 or 10,000 or like arguing with them about it and then they pop it up.
[01:38:24.480 --> 01:38:28.600]   So their algorithm said one thing and then you talk to them and someone, a human looks
[01:38:28.600 --> 01:38:30.600]   at it and then they make an adjustment.
[01:38:30.600 --> 01:38:31.600]   Yeah.
[01:38:31.600 --> 01:38:36.440]   This is the sort of stuff that I was afraid of when Apple announced that they were watching
[01:38:36.440 --> 01:38:45.360]   this credit card with Goldman Sachs that there's the credit industry is not known for good
[01:38:45.360 --> 01:38:46.640]   customer service.
[01:38:46.640 --> 01:38:50.040]   They're not known for really good customer outcomes.
[01:38:50.040 --> 01:38:55.440]   And every time that there's a screw up like this, whether it's intentional sexism, whether
[01:38:55.440 --> 01:38:59.640]   it's a black box algorithm, that they have to unwind and figure out why it's doing that.
[01:38:59.640 --> 01:39:04.080]   Or as Alex says, there's a lot of whiffle dust that goes into the decision of how much
[01:39:04.080 --> 01:39:08.400]   credit to offer somebody, Apple still gets that stink on them.
[01:39:08.400 --> 01:39:11.760]   And it's not, they can't parry it off on Goldman Sachs.
[01:39:11.760 --> 01:39:16.720]   It, they just, because they decided to have to get in bed with this, this company that
[01:39:16.720 --> 01:39:21.120]   wanted desperately to get into the credit, credit business or excuse me, the consumer
[01:39:21.120 --> 01:39:22.760]   credit card business.
[01:39:22.760 --> 01:39:27.760]   And this is the same company that two years ago got fined $5 billion for their part in
[01:39:27.760 --> 01:39:35.120]   the housing lending crisis of actually deceiving investors about the value of these notes that
[01:39:35.120 --> 01:39:37.160]   they were that they were putting out to people.
[01:39:37.160 --> 01:39:44.040]   So I continue to wonder why Apple feels it really necessary to be in this business to
[01:39:44.040 --> 01:39:45.920]   begin with.
[01:39:45.920 --> 01:39:51.760]   There must be a hell of a lot of money involved because there is so much PR downside.
[01:39:51.760 --> 01:39:56.480]   They can't, they can't, they can't absolve themselves and saying, oh, well, we, we designed
[01:39:56.480 --> 01:40:01.000]   that really wonderful titanium card and we're the guys who put together the app, we're the
[01:40:01.000 --> 01:40:02.160]   people who put together the app.
[01:40:02.160 --> 01:40:04.280]   We're not responsible for actual credit approval.
[01:40:04.280 --> 01:40:07.600]   We're not responsible for collection agencies going after people.
[01:40:07.600 --> 01:40:14.000]   They, again, they are, it's, it is the Motorola rocker of financial instruments for them where
[01:40:14.000 --> 01:40:19.080]   they can't say that that there's just terrible product that they don't, that does things that
[01:40:19.080 --> 01:40:21.240]   they wish didn't do, but they were involved in it.
[01:40:21.240 --> 01:40:24.400]   They decided to put their name on it and they are in bed with these people.
[01:40:24.400 --> 01:40:25.640]   They have to deal with it.
[01:40:25.640 --> 01:40:32.480]   And one thing too is that, you know, again, DHH is talking, has been making responses
[01:40:32.480 --> 01:40:33.760]   based on what people have said.
[01:40:33.760 --> 01:40:38.160]   And one of the things is that, you know, people are like, why are you so upset about this?
[01:40:38.160 --> 01:40:40.960]   This is common everyday banking practice.
[01:40:40.960 --> 01:40:44.800]   And that is what he's saying is that's the thing I take issue with is the fact that,
[01:40:44.800 --> 01:40:49.880]   that yes, this might be depending on your, your particular situation or whatever it happens
[01:40:49.880 --> 01:40:55.280]   to be, but he's saying that's not cool, particularly because as you note, Andy, Apple is saying,
[01:40:55.280 --> 01:40:56.640]   oh, we've made a different card.
[01:40:56.640 --> 01:40:58.160]   It's different from other credit cards.
[01:40:58.160 --> 01:41:00.280]   It's different from this.
[01:41:00.280 --> 01:41:07.320]   So Goldman Sachs has put out a statement and according to the statement, it says, we have
[01:41:07.320 --> 01:41:10.520]   not and never will make decisions based on factors like gender.
[01:41:10.520 --> 01:41:16.200]   In fact, we do not know your gender or marital status during the apple card application process.
[01:41:16.200 --> 01:41:19.040]   We are committed to ensuring our credit decision process is fair.
[01:41:19.040 --> 01:41:22.600]   Together with a third party, we have reviewed our credit decision process to guard against
[01:41:22.600 --> 01:41:24.720]   unintended biases and outcomes.
[01:41:24.720 --> 01:41:30.680]   They go on to say that they're going to, if folks are in particular situations that are
[01:41:30.680 --> 01:41:34.960]   affected by this, that they will, you can contact them and get more support.
[01:41:34.960 --> 01:41:38.120]   But again, I think that this just goes back to the original conversation that we're having
[01:41:38.120 --> 01:41:41.800]   about making sure that there's someone there who can actually answer this question and fix
[01:41:41.800 --> 01:41:44.040]   the problem if there is an issue that's there.
[01:41:44.040 --> 01:41:47.560]   I mean, this is just, I mean, from from my perspective, it's a credit version of the
[01:41:47.560 --> 01:41:51.080]   Intenigate, you know, like it didn't work as well as they thought it would.
[01:41:51.080 --> 01:41:52.360]   And then they fixed it on the next one.
[01:41:52.360 --> 01:41:54.560]   I think that apples, you know, there's going to be some bumps on the road.
[01:41:54.560 --> 01:41:58.240]   I think that Apple had to work with Goldman Sachs because Apple liked the reason that Apple
[01:41:58.240 --> 01:41:59.320]   didn't work with Verizon.
[01:41:59.320 --> 01:42:04.600]   They worked with AT&T because AT&T was willing to give Apple what it wanted to make changes
[01:42:04.600 --> 01:42:07.000]   to the way a phone works.
[01:42:07.000 --> 01:42:12.360]   Goldman Sachs gave Apple a lot of, gave Apple a lot of leeway in a way that no other credit
[01:42:12.360 --> 01:42:13.640]   card was going to give.
[01:42:13.640 --> 01:42:19.360]   Apple gave Goldman Sachs an AT&T opportunity to go to move into a market extremely quickly.
[01:42:19.360 --> 01:42:20.360]   But that was the payoff.
[01:42:20.360 --> 01:42:24.080]   I mean, you know, that was the, that was the negotiation, I'm sure, or the calculation
[01:42:24.080 --> 01:42:26.520]   that a lot of them made in that process.
[01:42:26.520 --> 01:42:29.880]   And so Apple's getting, you know, able to continue to move this down the path.
[01:42:29.880 --> 01:42:33.680]   And we should expect more hiccups along the way.
[01:42:33.680 --> 01:42:37.080]   But I don't have, I haven't talked to a lot of people that are overall upset about their
[01:42:37.080 --> 01:42:38.080]   Apple card.
[01:42:38.080 --> 01:42:43.680]   And, you know, and, and so, and I think that this is again, slowly boiling a financial
[01:42:43.680 --> 01:42:45.880]   frog that I don't think Apple's done with.
[01:42:45.880 --> 01:42:46.880]   Yeah.
[01:42:46.880 --> 01:42:50.960]   Another way of putting it is that your point is taken, but another way of putting it is
[01:42:50.960 --> 01:42:58.240]   that Apple wanted to open this card on their terms without having to negotiate as hard
[01:42:58.240 --> 01:43:01.840]   as they, excuse me, without having to give up as much as they would want to.
[01:43:01.840 --> 01:43:10.160]   And eventually they were reduced to dealing with a known to be shifty financial company.
[01:43:10.160 --> 01:43:14.600]   So they, again, there's a lot to unwrap here.
[01:43:14.600 --> 01:43:19.320]   There's where their intentions and the actual results are unknown at this point.
[01:43:19.320 --> 01:43:26.240]   But I, my personal thought is that the obligation is on Goldman Sachs to make sure that they
[01:43:26.240 --> 01:43:32.160]   make a really, really strong case that they're, they are not guilty of any wrongdoing.
[01:43:32.160 --> 01:43:37.440]   And Apple has to continue to make a good case that they did not make a mistake by getting
[01:43:37.440 --> 01:43:39.080]   it to coheuts with Goldman Sachs.
[01:43:39.080 --> 01:43:41.760]   And it makes, I hope I'm not overstating this.
[01:43:41.760 --> 01:43:45.920]   It might sound as though I'm saying that Goldman Sachs is an evil jerk company that nobody
[01:43:45.920 --> 01:43:47.000]   should touch.
[01:43:47.000 --> 01:43:53.400]   But again, they're the financial, the housing, the housing lending crisis was not an oops.
[01:43:53.400 --> 01:43:55.480]   It wasn't a, oh, an unrestricted market.
[01:43:55.480 --> 01:44:02.640]   It was the FTC agreed that this was malfeasance that needed a $5 billion correction.
[01:44:02.640 --> 01:44:08.320]   That's something that, again, if that appeared, if imagine Goldman Sachs filing out a credit
[01:44:08.320 --> 01:44:13.960]   report and saying, oh, well, geez, see here that you were cheating investors out of money
[01:44:13.960 --> 01:44:19.160]   and also locking individual consumers into loans that you knew that they would not be
[01:44:19.160 --> 01:44:21.800]   able to ever pay back.
[01:44:21.800 --> 01:44:27.000]   I'm afraid we're not going to be able to give you this opportunity today, Goldman Sachs,
[01:44:27.000 --> 01:44:29.200]   he says, feeding it into a shredder.
[01:44:29.200 --> 01:44:31.680]   But this is, this is the problem that Apple faces.
[01:44:31.680 --> 01:44:34.000]   Now, Lori, do you use Apple Card?
[01:44:34.000 --> 01:44:35.000]   I do.
[01:44:35.000 --> 01:44:36.000]   Yes.
[01:44:36.000 --> 01:44:38.280]   Did you have any issues with sign up or anything like that?
[01:44:38.280 --> 01:44:40.080]   How have you found the card?
[01:44:40.080 --> 01:44:44.360]   I actually, I have so many feels to unpack right now.
[01:44:44.360 --> 01:44:46.680]   So bear with me on this.
[01:44:46.680 --> 01:44:53.880]   First of all, I think that Hanson, DHH, he went about all of this completely wrong.
[01:44:53.880 --> 01:44:57.840]   And I personally take a little bit of offense to the Apple card is sexist.
[01:44:57.840 --> 01:45:06.160]   That bothers me because being somebody who has faced sexism in my lifetime, using this
[01:45:06.160 --> 01:45:12.920]   unknown, I don't know why my wife's credit score or credit approval was lower than mine.
[01:45:12.920 --> 01:45:19.440]   And just throwing that sexism card at it reduces my sexism issues that I've actually had that
[01:45:19.440 --> 01:45:21.960]   I know for sure come from something like that.
[01:45:21.960 --> 01:45:26.000]   So when I hear this kind of thing, like my hackles are up of like, what do you mean?
[01:45:26.000 --> 01:45:27.400]   How can you prove this?
[01:45:27.400 --> 01:45:33.200]   And throwing that out there reduces the times when I say that I've been the victim of sexism.
[01:45:33.200 --> 01:45:35.680]   So I'm immediately upset by that.
[01:45:35.680 --> 01:45:42.520]   So I have to put that out there and say that like, his first sentence in his first tweet
[01:45:42.520 --> 01:45:46.240]   is the Apple card is such an effing sexist program.
[01:45:46.240 --> 01:45:47.560]   And you know what that also means?
[01:45:47.560 --> 01:45:50.680]   It means that the rest of the internet is going to report that.
[01:45:50.680 --> 01:45:52.440]   So he is not a reporter.
[01:45:52.440 --> 01:45:58.080]   It's not his job to be unbiased and to be clear and say things that are accurate.
[01:45:58.080 --> 01:45:59.960]   He's okay with that on Twitter to do that.
[01:45:59.960 --> 01:46:05.480]   But the rest of the blogging world jumped on it and turned it into this like rolling
[01:46:05.480 --> 01:46:08.400]   boil of what is Apple doing wrong?
[01:46:08.400 --> 01:46:14.200]   What is Goldman Sachs doing wrong when there is very, very little evidence one way or another
[01:46:14.200 --> 01:46:15.640]   about the situation.
[01:46:15.640 --> 01:46:22.520]   So that's to me where everything went wrong, where the crap hit the fan and this shouldn't
[01:46:22.520 --> 01:46:25.520]   have been reported on the way it was reported on.
[01:46:25.520 --> 01:46:29.800]   Because what you've said quite a few times and what I think is actually true is it's
[01:46:29.800 --> 01:46:34.600]   not about the Apple card is sexist, which is what everyone reported after he tweeted
[01:46:34.600 --> 01:46:35.680]   that.
[01:46:35.680 --> 01:46:42.120]   It's that the credit industry in general is not transparent for us.
[01:46:42.120 --> 01:46:47.560]   And specifically in this case, this black box idea of that we just we don't question
[01:46:47.560 --> 01:46:48.560]   it.
[01:46:48.560 --> 01:46:54.240]   So the people that worked at Goldman Sachs, those representatives that he spoke to that
[01:46:54.240 --> 01:46:56.320]   kept saying it's an algorithm.
[01:46:56.320 --> 01:46:57.520]   I don't have access to it.
[01:46:57.520 --> 01:46:58.520]   I don't know.
[01:46:58.520 --> 01:46:59.520]   It's an algorithm.
[01:46:59.520 --> 01:47:00.520]   The algorithm is there.
[01:47:00.520 --> 01:47:01.760]   I trust that.
[01:47:01.760 --> 01:47:02.760]   That's dangerous.
[01:47:02.760 --> 01:47:07.960]   And it's good that this is being called into question of maybe there is an accidental bias
[01:47:07.960 --> 01:47:13.240]   in here that does need to be addressed and to bring that to light of like, hey, you know,
[01:47:13.240 --> 01:47:19.240]   we need to be looking into whether or not this is a, you know, has any kind of bias unintentional,
[01:47:19.240 --> 01:47:22.880]   you know, in this locked algorithm that we don't know about.
[01:47:22.880 --> 01:47:28.920]   That's the stuff that needs to be reported and not this like blowing up of Apple card
[01:47:28.920 --> 01:47:30.200]   is sexist.
[01:47:30.200 --> 01:47:33.440]   And so I find I'm, I find the whole thing very frustrating.
[01:47:33.440 --> 01:47:40.880]   And I certainly don't want to defend the way Goldman Sachs's algorithm works or Apple's
[01:47:40.880 --> 01:47:45.760]   relationship with Goldman Sachs and in this endeavor because number one, Goldman Sachs
[01:47:45.760 --> 01:47:50.320]   should be a little more transparent and have a better way to access algorithms so that
[01:47:50.320 --> 01:47:53.280]   we can understand how those kinds of things are determined.
[01:47:53.280 --> 01:47:58.560]   And number two, Apple should they, they are, they're holding hands with Goldman Sachs.
[01:47:58.560 --> 01:48:03.440]   So they, they're, their reputation is tarnished when Goldman Sachs reputation is tarnished
[01:48:03.440 --> 01:48:07.760]   and they need to be, they need to be more proactive about doing something about it.
[01:48:07.760 --> 01:48:08.760]   Okay.
[01:48:08.760 --> 01:48:09.760]   I think I got it all out.
[01:48:09.760 --> 01:48:13.960]   Lori, I want to, I want to apologize for not leading with you.
[01:48:13.960 --> 01:48:18.520]   And I mean, that's sincerely, we, I know I really should have time to listen to everyone
[01:48:18.520 --> 01:48:20.840]   else's, the way they addressed it.
[01:48:20.840 --> 01:48:25.880]   And it gave me some more information in my own head about, you know, yes, this is true
[01:48:25.880 --> 01:48:27.160]   and no, I don't believe that.
[01:48:27.160 --> 01:48:28.160]   And so it was good.
[01:48:28.160 --> 01:48:30.400]   I had a good way to, to barf that out of there.
[01:48:30.400 --> 01:48:32.240]   I'm glad you had time to percolate.
[01:48:32.240 --> 01:48:37.760]   And the one thing that I'm always surprised by that, that I, that companies don't do at
[01:48:37.760 --> 01:48:42.400]   almost every level is pay attention to social scores.
[01:48:42.400 --> 01:48:47.520]   So when someone calls you, you should immediately be able to know what their, how many Twitter
[01:48:47.520 --> 01:48:48.520]   followers they have.
[01:48:48.520 --> 01:48:49.520]   Yeah.
[01:48:49.520 --> 01:48:56.600]   Like, like, but I'm always amazed at, you know, because, you know, the, the, you can always
[01:48:56.600 --> 01:49:01.560]   tell the companies that do because they respond very, very quickly to a lot of these things.
[01:49:01.560 --> 01:49:02.880]   And there's a lot of great tools.
[01:49:02.880 --> 01:49:06.280]   Salesforce, I think bought one called the Radian Six that I think is now something,
[01:49:06.280 --> 01:49:08.400]   some kind of social studio or whatever they call it.
[01:49:08.400 --> 01:49:13.640]   And there's other tools out there, but I'm always amazed at a hotel, at a restaurant,
[01:49:13.640 --> 01:49:17.040]   at a, you know, like that they're not carving, you don't point up that information.
[01:49:17.040 --> 01:49:21.880]   There's some guy who is a founder who has a lot of followers, calls you.
[01:49:21.880 --> 01:49:26.360]   They should literally in my opinion go to another person, you know, like an, an, an
[01:49:26.360 --> 01:49:33.400]   not be, you know, uh, and, and it's just, this is less to do with credit scores and everything
[01:49:33.400 --> 01:49:34.400]   else.
[01:49:34.400 --> 01:49:39.040]   But just as a company, you should know what the impact's going to be to give that person.
[01:49:39.040 --> 01:49:40.040]   Yeah.
[01:49:40.040 --> 01:49:44.760]   You know, they used to say that a bad, an angry, um, uh, you know, an angry customer would
[01:49:44.760 --> 01:49:46.960]   lead to 10, you know, it would hit 10 people.
[01:49:46.960 --> 01:49:51.960]   Uh, uh, now it's tens of thousands of hundreds of thousands of people get in and it creates
[01:49:51.960 --> 01:49:57.240]   this huge, uh, process, but, but it's, um, you know, and, and it's not that you can't,
[01:49:57.240 --> 01:50:00.520]   you shouldn't treat everybody, you know, you should treat everybody well, but you should,
[01:50:00.520 --> 01:50:06.680]   there is a certain level of, um, crisis management that goes into this person can cause a lot
[01:50:06.680 --> 01:50:07.680]   of trouble really fast.
[01:50:07.680 --> 01:50:11.240]   It can cause a lot of trouble and a lot of misinformation, which leads to more customers
[01:50:11.240 --> 01:50:15.360]   being harmed in the process, or potentially harmed in the process.
[01:50:15.360 --> 01:50:20.800]   So yeah, I, I agree with the concerns about preferential treatment there obviously, but
[01:50:20.800 --> 01:50:26.360]   I do think that there is some impact on making sure that I'm not saying that's fair, by the
[01:50:26.360 --> 01:50:27.360]   way, right?
[01:50:27.360 --> 01:50:28.360]   Yeah, it's not the same, right.
[01:50:28.360 --> 01:50:29.360]   It's just good company policy.
[01:50:29.360 --> 01:50:34.520]   It's very unfair, but you think it's very unfair, but if you're, if you're a, if you're
[01:50:34.520 --> 01:50:38.800]   a company that does this, that there are a lot of companies that do it.
[01:50:38.800 --> 01:50:42.840]   Like, so let's just be clear, like it's not, uh, this is a very popular thing.
[01:50:42.840 --> 01:50:45.560]   And the fact that they're not interacting with this, there's, there's a huge number
[01:50:45.560 --> 01:50:49.680]   of companies that already, uh, are pretty clear of what's, what's actually happening
[01:50:49.680 --> 01:50:50.680]   there.
[01:50:50.680 --> 01:50:51.680]   Yeah.
[01:50:51.680 --> 01:50:54.880]   Uh, the, this is something to continue to continue to watch.
[01:50:54.880 --> 01:50:59.440]   Of course, like I said, their, the department is looking into, uh, golden and sacks.
[01:50:59.440 --> 01:51:04.440]   And so there will be eventually an answer, a clear answer to make sure that, uh, these
[01:51:04.440 --> 01:51:10.200]   algorithms that are put in place are doing the right thing, uh, and that it's, you know,
[01:51:10.200 --> 01:51:12.920]   the black box is going to be, I don't know, great a little bit.
[01:51:12.920 --> 01:51:14.760]   So I'll be able to see a little bit into them.
[01:51:14.760 --> 01:51:18.600]   Um, not to keep plugging triangulations, but to keep plugging triangulations.
[01:51:18.600 --> 01:51:25.040]   Uh, I also had the privilege just recently of interviewing, um, of interviewing Ruha
[01:51:25.040 --> 01:51:31.040]   Benjamin, uh, on her book, Race After Technology, abolitionist tools for the new gym code.
[01:51:31.040 --> 01:51:35.800]   And in this book, Ruha Benjamin, who is an associate professor of African American studies
[01:51:35.800 --> 01:51:46.160]   at Princeton, uh, talks about, uh, biases in tech and particularly in AI and how the,
[01:51:46.160 --> 01:51:54.200]   the very popular data sets on which, um, our modern AI engines are built came with a whole
[01:51:54.200 --> 01:52:01.200]   lot of biases in place and how even still we think of, of artificial intelligence and
[01:52:01.200 --> 01:52:05.080]   algorithms and these things as, uh, completely separate from humans.
[01:52:05.080 --> 01:52:08.840]   They're computers that just that think like Vulcans do.
[01:52:08.840 --> 01:52:12.880]   And the fact is they don't, they were created by, and I'm sure someone's going to quibble
[01:52:12.880 --> 01:52:13.880]   with me.
[01:52:13.880 --> 01:52:20.240]   I understand, but you get the point, uh, they are, they were originally created by humans
[01:52:20.240 --> 01:52:24.320]   and with the help of humans feeding these data sets and training these data sets.
[01:52:24.320 --> 01:52:28.000]   And so the fact is human bias still plays a role in those things.
[01:52:28.000 --> 01:52:33.080]   Uh, so that's another, a great conversation if you want to, or, or book there, again,
[01:52:33.080 --> 01:52:36.280]   Race After Technology by Ruha Benjamin.
[01:52:36.280 --> 01:52:43.600]   Um, so let's go ahead and take another quick break here before we come back and do our
[01:52:43.600 --> 01:52:45.920]   picks of the week.
[01:52:45.920 --> 01:52:50.760]   This episode of Mac Break Weekly is brought to you by our pals at Plex.
[01:52:50.760 --> 01:52:54.360]   Plex brings together all the media that matters to you in a single app.
[01:52:54.360 --> 01:52:58.040]   It is available on any device, no matter where you are.
[01:52:58.040 --> 01:53:03.640]   You can organize and stream free for your personal collection of movies, TV shows, music,
[01:53:03.640 --> 01:53:05.640]   favorite podcasts, web series, news and more.
[01:53:05.640 --> 01:53:07.000]   Yeah, that is a lot.
[01:53:07.000 --> 01:53:10.920]   You can, you can check out movies, TV shows, music, podcasts, web series, news, it's got
[01:53:10.920 --> 01:53:11.920]   it all.
[01:53:11.920 --> 01:53:17.920]   Plex is an all in one package that gets you all of the stuff that you want to stream across
[01:53:17.920 --> 01:53:18.920]   all of your devices.
[01:53:18.920 --> 01:53:23.420]   You can give your media the royal treatment it deserves with the Plex Pass with premium
[01:53:23.420 --> 01:53:26.800]   features you can bring out the best and whatever media you have.
[01:53:26.800 --> 01:53:31.240]   It's like taking all of your media that's sort of existing on these different hard drives
[01:53:31.240 --> 01:53:35.860]   and different places that you've collected over time and you put it all in this one place
[01:53:35.860 --> 01:53:40.320]   and then Plex goes ahead and takes that feather duster and dust things off.
[01:53:40.320 --> 01:53:44.120]   And sometimes, I don't know if you've ever seen those Instagram videos of an art person,
[01:53:44.120 --> 01:53:51.480]   an art restorer working on a piece of art, but suddenly that movie that once looked like
[01:53:51.480 --> 01:53:53.920]   it was, it had been through two wars.
[01:53:53.920 --> 01:53:55.200]   It's the Mona Lisa again.
[01:53:55.200 --> 01:53:56.200]   It's beautiful.
[01:53:56.200 --> 01:53:57.200]   It's recreated.
[01:53:57.200 --> 01:53:58.200]   It's wonderful.
[01:53:58.200 --> 01:53:59.560]   And that is what Plex does.
[01:53:59.560 --> 01:54:03.900]   They restore your beautiful work with a Plex Pass, an antenna and a tuner.
[01:54:03.900 --> 01:54:05.600]   You can stop paying for cable.
[01:54:05.600 --> 01:54:10.280]   Heck yeah, cut the cord and enjoy great TV and even record free HD broadcast.
[01:54:10.280 --> 01:54:12.280]   Cast channels right to your library.
[01:54:12.280 --> 01:54:15.920]   Leo's talked before about that's his next or that's his project for this coming year.
[01:54:15.920 --> 01:54:21.280]   He wants to get a really fancy TV tuner, get the antenna, get the Plex, or already a Plex
[01:54:21.280 --> 01:54:26.160]   Pass subscriber and sort of put those all together and stop paying for cable there.
[01:54:26.160 --> 01:54:28.480]   You can use offline accessibility with mobile sync.
[01:54:28.480 --> 01:54:33.720]   So if you're on a plane, on a boat in a submarine, I don't care where you are, with mobile sync
[01:54:33.720 --> 01:54:38.080]   you can sync your movies, your shows, your music, your photos to your mobile device.
[01:54:38.080 --> 01:54:41.840]   So you can have that offline enjoyment wherever you go.
[01:54:41.840 --> 01:54:45.840]   Right now you want to stream some stuff and there are only certain apps and services that
[01:54:45.840 --> 01:54:48.240]   allow that content to be downloaded.
[01:54:48.240 --> 01:54:51.800]   And sometimes it's in standard definition, instead of high definition.
[01:54:51.800 --> 01:54:55.240]   And it only lasts three days before it gets deleted from your device.
[01:54:55.240 --> 01:54:58.200]   There are all these rules and stipulations and things like that.
[01:54:58.200 --> 01:55:01.640]   When you're using your own personal media and you're using mobile sync, it stays there
[01:55:01.640 --> 01:55:03.040]   as long as you want it there.
[01:55:03.040 --> 01:55:07.280]   So when the kid wants to watch the wheels on the bus go round and round, you can count
[01:55:07.280 --> 01:55:08.280]   on it being there.
[01:55:08.280 --> 01:55:10.600]   There's also premium music.
[01:55:10.600 --> 01:55:15.360]   So you'll get special features like lyrics and custom curated playlists based on your
[01:55:15.360 --> 01:55:17.000]   music preferences.
[01:55:17.000 --> 01:55:22.680]   So when the New Year's Eve party rolls around and you all are feeling like some karaoke,
[01:55:22.680 --> 01:55:25.520]   that feature will come in handy as well as premium photos.
[01:55:25.520 --> 01:55:29.360]   So you can make photo albums that you can customize and share.
[01:55:29.360 --> 01:55:32.760]   So you can share your favorite memories on your television or your devices wherever it
[01:55:32.760 --> 01:55:33.920]   is.
[01:55:33.920 --> 01:55:39.360]   And this is one of my favorite ones, get cinema-like experience when you're watching your personal
[01:55:39.360 --> 01:55:40.520]   movie collection.
[01:55:40.520 --> 01:55:45.560]   So you pop in your personal movies and Plex adds trailers.
[01:55:45.560 --> 01:55:49.240]   They add special features that you might not be able to get anywhere else behind the scenes
[01:55:49.240 --> 01:55:50.800]   stuff, cast interviews.
[01:55:50.800 --> 01:55:52.200]   That's all included.
[01:55:52.200 --> 01:55:57.360]   So again, it's taking what you already have and adding even more great content to it.
[01:55:57.360 --> 01:56:02.680]   And if you've got multiple users, well, you can use Plex Home to switch between users.
[01:56:02.680 --> 01:56:08.600]   So that way you get customized, managed accounts that make switching easier between those users
[01:56:08.600 --> 01:56:10.600]   and some parental controls.
[01:56:10.600 --> 01:56:13.760]   So you can safely let your little ones enjoy too.
[01:56:13.760 --> 01:56:17.280]   And Rian Mizzi can't watch some of the films I watch, so I make sure those parental controls
[01:56:17.280 --> 01:56:19.080]   are turned on.
[01:56:19.080 --> 01:56:24.280]   With Plex Pass, you also get Plex Pass perks, the three P's, where you get exclusive access
[01:56:24.280 --> 01:56:29.920]   to promos and discounts on partner products and the newest features before everyone else.
[01:56:29.920 --> 01:56:34.040]   So Leo and I, of course, were bragging about the fact that we got access to the new UI for
[01:56:34.040 --> 01:56:40.000]   Plex before other folks, because we are lifetime Plex Pass members, which was kind of nice to
[01:56:40.000 --> 01:56:41.000]   get a preview.
[01:56:41.000 --> 01:56:44.600]   But it is out now and it's beautiful, nice redesign.
[01:56:44.600 --> 01:56:50.600]   And even more features, such as loudness leveling, sweet fades, timeline view, and advanced audio
[01:56:50.600 --> 01:56:51.600]   features.
[01:56:51.600 --> 01:56:53.640]   So are you ready for your Plex Pass?
[01:56:53.640 --> 01:57:00.320]   Well, Plex is offering Twit listeners $10 off the lifetime Plex Pass subscription for new
[01:57:00.320 --> 01:57:01.320]   subscribers only.
[01:57:01.320 --> 01:57:12.400]   When you go to plex.tv/twit and enter the code TWIT10, that's plex.tv/twit with the code TWIT10.
[01:57:12.400 --> 01:57:18.040]   So you can get all of your content available on all your devices, streaming and dreaming.
[01:57:18.040 --> 01:57:22.160]   Thank you so much to Plex for sponsoring this week's episode of Mac Break Weekly.
[01:57:22.160 --> 01:57:26.720]   All right, folks, break time is almost over.
[01:57:26.720 --> 01:57:30.480]   But I do want to tell you about iOS today.
[01:57:30.480 --> 01:57:33.640]   Just recorded that one yesterday went live today.
[01:57:33.640 --> 01:57:36.880]   We had, I had it on Russell O'Vonovich of Shifty Jelly.
[01:57:36.880 --> 01:57:43.360]   He is the co-founder of the company and the co-creator of PocketCasts, the podcast app
[01:57:43.360 --> 01:57:45.560]   that many people use across different devices.
[01:57:45.560 --> 01:57:52.480]   So had him on, we talked about the creation of PocketCasts and where it started, actually
[01:57:52.480 --> 01:57:57.120]   it started with weather before it was ever, before the company ever created their Pocket,
[01:57:57.120 --> 01:57:59.120]   their podcasts app.
[01:57:59.120 --> 01:58:01.680]   And yeah, it was a really fascinating conversation.
[01:58:01.680 --> 01:58:04.840]   And before we talked about the news of the week in iOS and things like that.
[01:58:04.840 --> 01:58:09.720]   So be sure to check that out for all things iPhone, iPad, Apple Watch and more.
[01:58:09.720 --> 01:58:11.720]   That's iOS today.
[01:58:11.720 --> 01:58:15.960]   All righty, it is time for our picks.
[01:58:15.960 --> 01:58:19.320]   And I think this week we'll start with Andy.
[01:58:19.320 --> 01:58:22.320]   Well, I'm finding you should mention Plex.
[01:58:22.320 --> 01:58:26.160]   I've been a fan of Plex and user of Plex for years and years and years.
[01:58:26.160 --> 01:58:31.080]   All my data is all my entertainment is on a Plex server on a NAS.
[01:58:31.080 --> 01:58:39.080]   And recently, I finally after only two years of complaining about how I needed universal
[01:58:39.080 --> 01:58:43.680]   remote because now I've got way too many components I need to switch on and interact
[01:58:43.680 --> 01:58:46.320]   with whenever I want to watch a movie or something.
[01:58:46.320 --> 01:58:53.160]   Finally decided to finally spend the money on this a lot of the Logitech Harmony companion,
[01:58:53.160 --> 01:58:59.480]   which is exactly in the sweet spot of what I want the old style idea of and just of infrared
[01:58:59.480 --> 01:59:01.800]   remote that you just punch codes into.
[01:59:01.800 --> 01:59:04.000]   Well, that's not really worth your money.
[01:59:04.000 --> 01:59:09.760]   This is a totally unified sort of thing comes with a little like a little hockey puck sort
[01:59:09.760 --> 01:59:15.760]   of box plus an IR blaster because it can not only deal with infrared remotes, it can also
[01:59:15.760 --> 01:59:18.520]   deal with like Bluetooth wireless remotes.
[01:59:18.520 --> 01:59:24.640]   So finally, for the first time, I can push a button on this one little unified remote
[01:59:24.640 --> 01:59:27.640]   with the sequence that I've set up on the phone app.
[01:59:27.640 --> 01:59:33.720]   It will turn on my TV, turn on my AV receiver, switch it to the input that has my Apple TV
[01:59:33.720 --> 01:59:40.040]   on it and then send the right codes to the Apple TV to turn yourself on, get yourself
[01:59:40.040 --> 01:59:41.560]   into this app.
[01:59:41.560 --> 01:59:43.880]   And it just all works really nicely.
[01:59:43.880 --> 01:59:48.360]   You can it's not I would like to say that don't let the app throw you off.
[01:59:48.360 --> 01:59:52.760]   I think the user interface could be a little bit more polished, but the thing is it was
[01:59:52.760 --> 01:59:56.760]   a lit setting everything up the way I wanted it was a completely linear process without
[01:59:56.760 --> 01:59:58.400]   huh, how come it's not responding?
[01:59:58.400 --> 02:00:00.560]   Huh, how come this is in turned off?
[02:00:00.560 --> 02:00:01.560]   Huh?
[02:00:01.560 --> 02:00:05.200]   Really everything every time that I try to do something, try to set up something like a
[02:00:05.200 --> 02:00:07.720]   sequence or say, okay, this is my music player.
[02:00:07.720 --> 02:00:11.520]   This is what I want to happen when I press the button on this remote for music for listening
[02:00:11.520 --> 02:00:12.520]   to music.
[02:00:12.520 --> 02:00:16.520]   It was just a very nice linear fashion setup was perfectly fine.
[02:00:16.520 --> 02:00:19.200]   It supports up to a I think eight different devices.
[02:00:19.200 --> 02:00:24.040]   The nice thing about this is it also will control home lighting and home automation stuff.
[02:00:24.040 --> 02:00:30.120]   So you can also see exactly so you can also set it set to do things like it's I'm watching
[02:00:30.120 --> 02:00:31.120]   a movie.
[02:00:31.120 --> 02:00:35.000]   So dim down the turn off the lights in the living room dim the lights in the next room,
[02:00:35.000 --> 02:00:39.400]   turn on the turn on this little back lighting thing, switch to this inputs, which of this.
[02:00:39.400 --> 02:00:43.000]   So it's not you know, and I'm making it sound like it's scripting, but it really isn't
[02:00:43.000 --> 02:00:47.560]   it's just here is a list of things that I want you to do while you do it.
[02:00:47.560 --> 02:00:51.040]   Support is it's a you don't have to look up codes.
[02:00:51.040 --> 02:00:53.880]   It supports everything that I've been throwing at it.
[02:00:53.880 --> 02:00:55.360]   And right now I've set up different.
[02:00:55.360 --> 02:00:59.880]   I think I've got seven things set up with it, some of which are pretty darn old.
[02:00:59.880 --> 02:01:04.920]   The only difficulty that I had in setting this up was my Sony Blu-ray player doesn't have
[02:01:04.920 --> 02:01:07.080]   the model number printed anywhere on it.
[02:01:07.080 --> 02:01:13.640]   So I actually had to like go to like think I bought it from B&H photo or something.
[02:01:13.640 --> 02:01:17.880]   So I'd go back to B&H photo, look at my order history to get the model number of my Blu-ray
[02:01:17.880 --> 02:01:18.880]   player.
[02:01:18.880 --> 02:01:21.960]   But that but that I don't think that's logic text fault.
[02:01:21.960 --> 02:01:29.400]   But the last thing I want to compliment it on is that I had one of the earlier generation
[02:01:29.400 --> 02:01:33.720]   Logitech Harmony remotes with kind of was like really, really long.
[02:01:33.720 --> 02:01:36.760]   I had an LCD screen on it.
[02:01:36.760 --> 02:01:40.760]   And one of the things that made me not want to use it and really stop using was the fact
[02:01:40.760 --> 02:01:45.680]   that it had to really keep it in its charging cradle when you weren't using it or else it
[02:01:45.680 --> 02:01:48.040]   would just die every like three or four days.
[02:01:48.040 --> 02:01:52.320]   This is it communicates with that little hockey puck thing via Bluetooth low energy.
[02:01:52.320 --> 02:01:57.440]   So the battery in this I believe is literally just a little coin cell battery and it says
[02:01:57.440 --> 02:02:00.040]   it's last about a full year.
[02:02:00.040 --> 02:02:07.120]   So I've now managed to replace the TV remote that got destroyed when I lifted on a windows
[02:02:07.120 --> 02:02:11.440]   sill and there was a horrible rain storm that rendered it inoperative.
[02:02:11.440 --> 02:02:14.760]   I've replaced the two or three remotes I'd have to juggle in order to get things done.
[02:02:14.760 --> 02:02:20.120]   And I no longer have to like shout instructions to Guillermo whenever I want to watch something
[02:02:20.120 --> 02:02:26.240]   like like Apocalypse Now, which really demands the full lighting effect.
[02:02:26.240 --> 02:02:27.840]   But it's not the cheapest one.
[02:02:27.840 --> 02:02:33.840]   It's about I think it lists for 150, but I got it on Amazon for 110 close to that.
[02:02:33.840 --> 02:02:36.440]   I think it was 100 bucks plus tax.
[02:02:36.440 --> 02:02:42.720]   And it's with all the other ones that I was looking at, it really is worth the extra $50
[02:02:42.720 --> 02:02:46.720]   or $60 you'd spend in that many of these will be IR only.
[02:02:46.720 --> 02:02:51.440]   It won't be able to control Bluetooth stuff like like the Apple TV.
[02:02:51.440 --> 02:02:56.040]   It seems like it's very, very future forward that I won't have to replace into it three
[02:02:56.040 --> 02:02:58.240]   years when I buy a new component.
[02:02:58.240 --> 02:03:01.640]   And I'm very, very, very happy with the only thing I wish it had is I wish this this keyboard
[02:03:01.640 --> 02:03:04.560]   were backlit, but I suppose that would kill the battery life.
[02:03:04.560 --> 02:03:05.560]   So oh well.
[02:03:05.560 --> 02:03:08.440]   And it looks like a remote, which is so nice.
[02:03:08.440 --> 02:03:10.560]   It's curved.
[02:03:10.560 --> 02:03:11.800]   It's compact.
[02:03:11.800 --> 02:03:18.640]   It also has this really nice like sort of like plastic, rubbery texture on the bottom
[02:03:18.640 --> 02:03:19.640]   of it.
[02:03:19.640 --> 02:03:22.640]   So you really have and has the hump right where you want it.
[02:03:22.640 --> 02:03:26.400]   It is the antithesis of the Apple TV remote when you pick it up.
[02:03:26.400 --> 02:03:30.840]   Your thumb is falling exactly on the button that you were most likely to be hitting like
[02:03:30.840 --> 02:03:34.520]   the D-pad for navigating menus.
[02:03:34.520 --> 02:03:37.960]   It's just a very, very satisfying object, very, very nicely designed.
[02:03:37.960 --> 02:03:40.920]   And the nice thing also is I have the older version, which I'm about to upgrade.
[02:03:40.920 --> 02:03:42.760]   And I was like, I wonder if the new version is any good.
[02:03:42.760 --> 02:03:44.120]   And then you just did a review.
[02:03:44.120 --> 02:03:46.920]   But the so I have the older version.
[02:03:46.920 --> 02:03:51.680]   And the nice thing is is that all the equipment that goes on my TV is in another room.
[02:03:51.680 --> 02:03:53.200]   It's in a server room.
[02:03:53.200 --> 02:03:55.440]   So it's somewhere else in the house.
[02:03:55.440 --> 02:03:59.480]   And so being able to have a controller that then controls all the equipment and then feeds
[02:03:59.480 --> 02:04:01.840]   it back to the TV is also useful.
[02:04:01.840 --> 02:04:06.720]   It's beyond just the getting rid of all the controllers, but it's allowing me to have
[02:04:06.720 --> 02:04:10.160]   all my equipment somewhere else other than the TV room.
[02:04:10.160 --> 02:04:11.800]   So all I have is a screen on the wall.
[02:04:11.800 --> 02:04:15.960]   I don't have any equipment in the in the in the right.
[02:04:15.960 --> 02:04:20.400]   You can hide everything inside a cabinet because again, the IR blaster, if you've found
[02:04:20.400 --> 02:04:24.800]   the IR blaster is inside the cabinet and it kills my every got couple of those just hanging
[02:04:24.800 --> 02:04:26.720]   there and they do all the right they do right.
[02:04:26.720 --> 02:04:27.720]   It does.
[02:04:27.720 --> 02:04:31.320]   I've actually got mine just perched on top of the it's power perched on top of the receiver.
[02:04:31.320 --> 02:04:32.320]   It's powerful enough.
[02:04:32.320 --> 02:04:36.040]   I think it's actually bouncing off the rear wall and then get forward again to hit the
[02:04:36.040 --> 02:04:37.040]   stuff.
[02:04:37.040 --> 02:04:40.200]   But again, if you want to have everything completely hidden out of the way, you can absolutely
[02:04:40.200 --> 02:04:41.200]   do that.
[02:04:41.200 --> 02:04:42.200]   Awesome.
[02:04:42.200 --> 02:04:46.960]   All right, let's move on to our next pick, which comes from Luregil.
[02:04:46.960 --> 02:04:47.960]   What do you got for us, Lori?
[02:04:47.960 --> 02:04:48.960]   That's me.
[02:04:48.960 --> 02:04:49.960]   That's you.
[02:04:49.960 --> 02:04:53.000]   I'm about to fly to Japan on Sunday.
[02:04:53.000 --> 02:04:56.120]   I'm leaving and I'll be gone for 10 days.
[02:04:56.120 --> 02:04:59.320]   So it's very exciting, but it's also a very long flight.
[02:04:59.320 --> 02:05:03.960]   And of course, yeah, we'll brief you.
[02:05:03.960 --> 02:05:06.680]   No, live a boot account.
[02:05:06.680 --> 02:05:07.680]   Remember?
[02:05:07.680 --> 02:05:08.680]   Oh, yes.
[02:05:08.680 --> 02:05:09.680]   Oh, right.
[02:05:09.680 --> 02:05:15.680]   So the one super awesome thing that has been like a great part of my life is airfly,
[02:05:15.680 --> 02:05:21.520]   which is a Bluetooth transmitter that you can plug into any device that has a 3.5 millimeter
[02:05:21.520 --> 02:05:26.080]   jack and it turns that thing into a Bluetooth enabled device.
[02:05:26.080 --> 02:05:29.720]   So it works perfect on planes that have inflate entertainment.
[02:05:29.720 --> 02:05:32.920]   They hand you those little plastic buds that you can use and you stick them in their ear
[02:05:32.920 --> 02:05:36.720]   and you're wired and you connect them to the TV screen.
[02:05:36.720 --> 02:05:40.120]   It's uncomfortable if you fall asleep, they rip out of your ear.
[02:05:40.120 --> 02:05:45.600]   Airfly makes it so that you can actually use any Bluetooth device with it.
[02:05:45.600 --> 02:05:50.160]   So all of your wireless earbuds, your noise canceling headphones, anything you want that's
[02:05:50.160 --> 02:05:52.360]   wireless, you connect it and it works.
[02:05:52.360 --> 02:05:59.280]   Today, 12 South just came out with an updated version called Airfly Pro, which has a couple
[02:05:59.280 --> 02:06:02.360]   super awesome new features that I'm very excited about.
[02:06:02.360 --> 02:06:04.680]   One of them is audio sharing.
[02:06:04.680 --> 02:06:08.200]   So iOS 13 and AirPods has audio sharing.
[02:06:08.200 --> 02:06:12.360]   This has audio sharing and it doesn't have to be an iOS 13 device and it doesn't have
[02:06:12.360 --> 02:06:13.480]   to be AirPods.
[02:06:13.480 --> 02:06:17.240]   It could be any two Bluetooth headphones and any device.
[02:06:17.240 --> 02:06:23.400]   So it can be your iPhone, it can be your iPad, it can be Android device, it could be the
[02:06:23.400 --> 02:06:26.040]   inflate entertainment screen, anything you want.
[02:06:26.040 --> 02:06:27.880]   Two pairs of headphones connect to it.
[02:06:27.880 --> 02:06:33.320]   It's like a splitter basically that will let you use two different pairs of headphones
[02:06:33.320 --> 02:06:34.400]   at the same time.
[02:06:34.400 --> 02:06:38.040]   It also has the reverse of a Bluetooth transmission.
[02:06:38.040 --> 02:06:39.560]   It's also a Bluetooth receiver.
[02:06:39.560 --> 02:06:45.840]   So you can plug this into anything that doesn't already have Bluetooth enabled and as long as
[02:06:45.840 --> 02:06:50.600]   it has a 3.5 millimeter jack, it'll make it a Bluetooth enabled device.
[02:06:50.600 --> 02:06:58.720]   A lot of scenarios that 12 South is representing is you hop in a rental car and you don't want
[02:06:58.720 --> 02:07:03.400]   to connect your phone to that Bluetooth stereo for example.
[02:07:03.400 --> 02:07:07.000]   You plug this in and it doesn't connect that way, it connects to the Bluetooth.
[02:07:07.000 --> 02:07:12.440]   I have a car that doesn't even have Bluetooth capabilities but it does have a 3.5 millimeter
[02:07:12.440 --> 02:07:13.440]   audio in jack.
[02:07:13.440 --> 02:07:16.000]   It has to be an audio in jack, not a headphone jack.
[02:07:16.000 --> 02:07:20.760]   So I hopped in my car and I plugged in the air fly and now my phone actually can be played
[02:07:20.760 --> 02:07:23.640]   through my stereo is something that it couldn't do before.
[02:07:23.640 --> 02:07:25.320]   So it's pretty awesome.
[02:07:25.320 --> 02:07:26.800]   That's very cool.
[02:07:26.800 --> 02:07:31.960]   It also has more than 16 hours of battery life.
[02:07:31.960 --> 02:07:37.880]   So they actually had said that 12 South had said that they tested it on one of the longest
[02:07:37.880 --> 02:07:42.360]   flights that you can take nonstop which I believe is about 17.5 hours.
[02:07:42.360 --> 02:07:49.560]   I think it might have been from something like Dubai to Australia or something like that.
[02:07:49.560 --> 02:07:52.400]   And it surpassed it.
[02:07:52.400 --> 02:07:58.720]   It made it through the 17 and a half hours flight plus but they're saying 16 hours just
[02:07:58.720 --> 02:08:01.160]   to give you that kind of cushioning.
[02:08:01.160 --> 02:08:03.680]   So yeah, this thing is pretty awesome.
[02:08:03.680 --> 02:08:05.800]   Airfly already was really cool.
[02:08:05.800 --> 02:08:10.880]   It's a great little device but Airfly Pro now has these extra features that make it
[02:08:10.880 --> 02:08:11.880]   really awesome.
[02:08:11.880 --> 02:08:17.720]   And I know the word Pro gets thrown around a lot but I think I'd like to say that this
[02:08:17.720 --> 02:08:22.240]   one actually deserves that nomenclature just because it really does add some amazing additional
[02:08:22.240 --> 02:08:25.600]   features that makes it way better than the other version.
[02:08:25.600 --> 02:08:28.360]   And it's only $10 more than the standard Airfly.
[02:08:28.360 --> 02:08:35.280]   Yeah, the fact that it does both transmitting and I don't know broadcast transmission,
[02:08:35.280 --> 02:08:36.280]   whatever.
[02:08:36.280 --> 02:08:37.280]   Receiving transmission.
[02:08:37.280 --> 02:08:38.280]   Receiving transmission.
[02:08:38.280 --> 02:08:40.120]   That's very cool.
[02:08:40.120 --> 02:08:45.080]   And I see that there's a review over on iMOR for this product.
[02:08:45.080 --> 02:08:46.080]   Of course.
[02:08:46.080 --> 02:08:48.760]   Yeah, which again we've got dark mode on iMOR which is nice.
[02:08:48.760 --> 02:08:49.760]   Yes, I know.
[02:08:49.760 --> 02:08:50.760]   It's great.
[02:08:50.760 --> 02:08:52.760]   Yeah, there it is with my Nintendo Switch.
[02:08:52.760 --> 02:08:55.760]   That's what I tested it on when I was in the house.
[02:08:55.760 --> 02:08:59.000]   When I did the audio sharing when it was great I plugged in the Airfly.
[02:08:59.000 --> 02:09:00.160]   I put in some headphones.
[02:09:00.160 --> 02:09:03.800]   I made my partner put in some headphones and we played some video games on it.
[02:09:03.800 --> 02:09:08.880]   We were both listening with our wireless headphones instead of on the television set
[02:09:08.880 --> 02:09:09.880]   or something.
[02:09:09.880 --> 02:09:10.880]   It was really fun.
[02:09:10.880 --> 02:09:11.880]   Nice.
[02:09:11.880 --> 02:09:15.720]   Because the Nintendo Switch itself doesn't have a lot of good Bluetooth support, correct?
[02:09:15.720 --> 02:09:16.720]   Right.
[02:09:16.720 --> 02:09:20.400]   It does support some Bluetooth devices but not a lot of them.
[02:09:20.400 --> 02:09:23.560]   There's I don't know maybe two dozen tops that it supports.
[02:09:23.560 --> 02:09:27.560]   For example, it doesn't support AirPods.
[02:09:27.560 --> 02:09:31.000]   Yeah, I always use an Airfly if I want to use the...
[02:09:31.000 --> 02:09:34.520]   If I want to play my Nintendo Switch with headphones on because I just plug it in and
[02:09:34.520 --> 02:09:36.040]   I can use it that way.
[02:09:36.040 --> 02:09:40.280]   But now I can use it with myself and another person and they can use their headphones to
[02:09:40.280 --> 02:09:42.880]   connect to it and we can both listen at the same time.
[02:09:42.880 --> 02:09:43.880]   Fun, fun, fun.
[02:09:43.880 --> 02:09:44.880]   All right.
[02:09:44.880 --> 02:09:48.560]   That's Airfly Pro and now it's time for Alex.
[02:09:48.560 --> 02:09:49.560]   What have you got for us?
[02:09:49.560 --> 02:09:52.000]   So I'd like to first thank Chris Hedlin.
[02:09:52.000 --> 02:09:53.440]   I believe it's Chris Hedlin.
[02:09:53.440 --> 02:09:57.360]   That's his Twitter thing.
[02:09:57.360 --> 02:09:58.360]   He suggested it.
[02:09:58.360 --> 02:10:01.720]   I've complained a lot about not having field runners working on my phone.
[02:10:01.720 --> 02:10:05.760]   In fact, I have a phone that I've updated because I can still play field runners.
[02:10:05.760 --> 02:10:12.080]   I love desktop tower defense since the first desktop tower defense on Flash on my webpage.
[02:10:12.080 --> 02:10:15.280]   And just for some reason that's the kind of thing I like to play.
[02:10:15.280 --> 02:10:16.280]   And so...
[02:10:16.280 --> 02:10:19.800]   But I haven't been very happy with most of the desktop tower defenses.
[02:10:19.800 --> 02:10:26.880]   Even when he suggested it on Twitter, I was like, "Oh, another desktop tower defense that
[02:10:26.880 --> 02:10:28.360]   I'm not going to like."
[02:10:28.360 --> 02:10:31.440]   And I was kind of like, "Oh, but I'll download it and just take a look at it.
[02:10:31.440 --> 02:10:32.440]   We'll just see."
[02:10:32.440 --> 02:10:37.760]   And on my flight back from Washington DC last week, I was like, "Okay, I'm going to
[02:10:37.760 --> 02:10:40.320]   open it and just see how it turns out."
[02:10:40.320 --> 02:10:41.960]   Five hours later.
[02:10:41.960 --> 02:10:42.960]   Whoa!
[02:10:42.960 --> 02:10:43.960]   We landed.
[02:10:43.960 --> 02:10:44.960]   Whoa!
[02:10:44.960 --> 02:10:47.600]   That was like literally an entire flight just disappeared.
[02:10:47.600 --> 02:10:50.280]   It was just gone.
[02:10:50.280 --> 02:10:53.160]   You know, and I'm on level six now.
[02:10:53.160 --> 02:10:57.240]   But so it's called Kingdom Rush.
[02:10:57.240 --> 02:11:00.360]   And this is a great desktop tower defense.
[02:11:00.360 --> 02:11:02.960]   And again, there was a bunch of things I didn't like about it when I first saw it, which
[02:11:02.960 --> 02:11:06.360]   was like, "Oh, I can only put my towers in certain places.
[02:11:06.360 --> 02:11:07.360]   I can't...
[02:11:07.360 --> 02:11:11.840]   It's really not about controlling the way the guys run through it."
[02:11:11.840 --> 02:11:16.160]   It's like the very structured ones you'd see in field runners.
[02:11:16.160 --> 02:11:17.800]   And you can only put your towers in certain places.
[02:11:17.800 --> 02:11:20.360]   But I found that a couple things.
[02:11:20.360 --> 02:11:22.720]   One is that I really...
[02:11:22.720 --> 02:11:26.440]   And obviously I spent a lot of time playing it, at least in one flight.
[02:11:26.440 --> 02:11:31.000]   But also that what was interesting is that because there's things you have to do during
[02:11:31.000 --> 02:11:34.760]   it, in old desktop tower defense, there are like dead time.
[02:11:34.760 --> 02:11:38.120]   You know, like you get the whole thing set up and then you just wait for them to get
[02:11:38.120 --> 02:11:41.160]   through certain things because you've got something worked out.
[02:11:41.160 --> 02:11:43.200]   Here you have to be adding what they call reinforcements.
[02:11:43.200 --> 02:11:46.400]   You have to add things to it all the time or you're just not going to win.
[02:11:46.400 --> 02:11:47.400]   Like you have to...
[02:11:47.400 --> 02:11:50.240]   And you really have to think through it about how you're putting those things together.
[02:11:50.240 --> 02:11:53.520]   So it's just a different set of rules.
[02:11:53.520 --> 02:11:59.760]   And but you really have to throw people into it or little fighters or whatever into it
[02:11:59.760 --> 02:12:01.040]   to make it work.
[02:12:01.040 --> 02:12:02.040]   And so I...
[02:12:02.040 --> 02:12:05.680]   Anyway, so I really enjoy it.
[02:12:05.680 --> 02:12:06.680]   It's pretty fun.
[02:12:06.680 --> 02:12:07.680]   I don't know.
[02:12:07.680 --> 02:12:08.680]   I don't remember paying for it.
[02:12:08.680 --> 02:12:11.360]   It might have been $2 or $3, but I think it might be free to start with.
[02:12:11.360 --> 02:12:13.840]   I'm not sure what I would have to pay for because I haven't.
[02:12:13.840 --> 02:12:14.840]   I've just been playing it.
[02:12:14.840 --> 02:12:16.760]   But anyway, it's great.
[02:12:16.760 --> 02:12:21.440]   If you like desktop tower defenses, as much as I do, it's pretty good.
[02:12:21.440 --> 02:12:26.560]   And then the only side recommendation I want to make is that the Mandalorian is pretty
[02:12:26.560 --> 02:12:27.560]   awesome.
[02:12:27.560 --> 02:12:29.360]   We kind of skip over that.
[02:12:29.360 --> 02:12:31.200]   I haven't had time to watch it yet.
[02:12:31.200 --> 02:12:32.360]   I'm not going to...
[02:12:32.360 --> 02:12:33.360]   I'm not going to...
[02:12:33.360 --> 02:12:34.360]   Those spoilers.
[02:12:34.360 --> 02:12:36.000]   And it's great.
[02:12:36.000 --> 02:12:41.320]   You know, if Disney keeps on doing that, then it's going to be a good service.
[02:12:41.320 --> 02:12:43.320]   Because it's not quite movie.
[02:12:43.320 --> 02:12:47.760]   You know, like there's something out with the audio at the very beginning with some of the
[02:12:47.760 --> 02:12:52.360]   voices that I felt were thin.
[02:12:52.360 --> 02:12:55.600]   Like they didn't feel like a movie, like a feature film kind of thing, which is I think
[02:12:55.600 --> 02:12:58.680]   I was kind of expecting because the visual effects are outstanding.
[02:12:58.680 --> 02:13:01.960]   You know, just completely film quality.
[02:13:01.960 --> 02:13:05.280]   And so it felt like the audio wasn't quite keeping up with that at the beginning, but
[02:13:05.280 --> 02:13:06.640]   then I sunk into it.
[02:13:06.640 --> 02:13:11.040]   But it's definitely one of the best...
[02:13:11.040 --> 02:13:19.920]   Yeah, it's definitely one of the best digital only releases that I've seen for anything.
[02:13:19.920 --> 02:13:20.920]   Wow.
[02:13:20.920 --> 02:13:23.320]   And you know, the character development's a lot better.
[02:13:23.320 --> 02:13:24.320]   I just finished watching...
[02:13:24.320 --> 02:13:27.400]   I took my son to the Dolby Theatre to see Midway.
[02:13:27.400 --> 02:13:29.800]   I'm a war buff.
[02:13:29.800 --> 02:13:31.640]   So Midway.
[02:13:31.640 --> 02:13:34.440]   You know, it's a very important battle.
[02:13:34.440 --> 02:13:37.960]   Probably one of the most important battles of World War II in the Pacific.
[02:13:37.960 --> 02:13:44.840]   And anyway, good movie, no character development.
[02:13:44.840 --> 02:13:45.840]   Oh, I see.
[02:13:45.840 --> 02:13:46.840]   You know, like it was...
[02:13:46.840 --> 02:13:49.600]   Historically, I was glad my son got to see it.
[02:13:49.600 --> 02:13:52.120]   So he understands, you know, kind of what happened there.
[02:13:52.120 --> 02:13:54.920]   I think it's mostly pretty accurate.
[02:13:54.920 --> 02:13:57.320]   As far as the bits and pieces, probably more accurate than...
[02:13:57.320 --> 02:14:00.880]   It's definitely more accurate than Pearl Harbor.
[02:14:00.880 --> 02:14:04.480]   But there's just not that...
[02:14:04.480 --> 02:14:07.240]   I was like, it's just interesting how you write something.
[02:14:07.240 --> 02:14:09.040]   And there were so many plot lines.
[02:14:09.040 --> 02:14:11.200]   And there was so much, you just weren't attached to anybody.
[02:14:11.200 --> 02:14:12.200]   Right, okay.
[02:14:12.200 --> 02:14:13.200]   But the visual effects were great.
[02:14:13.200 --> 02:14:15.400]   I'm glad I saw it in a big theatre.
[02:14:15.400 --> 02:14:18.560]   But this was a completely other thing where the development just really...
[02:14:18.560 --> 02:14:21.520]   You just realize what great writing and great effects and great...
[02:14:21.520 --> 02:14:22.520]   It's exciting.
[02:14:22.520 --> 02:14:23.520]   Everything.
[02:14:23.520 --> 02:14:24.520]   Everything this.
[02:14:24.520 --> 02:14:25.520]   Everything was great.
[02:14:25.520 --> 02:14:26.520]   It's good.
[02:14:26.520 --> 02:14:28.520]   So for Kingdom Rush, that is free.
[02:14:28.520 --> 02:14:34.400]   And it does have in-app purchases, which are probably for little things you can pay to
[02:14:34.400 --> 02:14:37.400]   make the game move faster and stuff like that.
[02:14:37.400 --> 02:14:38.400]   But it's from download, I think.
[02:14:38.400 --> 02:14:41.680]   Yeah, free to download it with in-app purchases for little characters.
[02:14:41.680 --> 02:14:42.680]   It looks like...
[02:14:42.680 --> 02:14:46.720]   And I have to say that I've played the first five hours of it and I haven't bought anything.
[02:14:46.720 --> 02:14:47.720]   And that's usually...
[02:14:47.720 --> 02:14:51.600]   If anything charges me to just play, I kind of like, no.
[02:14:51.600 --> 02:14:52.600]   Like, ongoingly.
[02:14:52.600 --> 02:14:53.600]   Right.
[02:14:53.600 --> 02:14:55.400]   So it's good.
[02:14:55.400 --> 02:14:56.400]   Yeah.
[02:14:56.400 --> 02:14:57.400]   Excellent.
[02:14:57.400 --> 02:14:59.480]   So the pick is a new app.
[02:14:59.480 --> 02:15:00.480]   Just hit the app store.
[02:15:00.480 --> 02:15:02.880]   It's called Food Gnomes.
[02:15:02.880 --> 02:15:03.880]   That's...
[02:15:03.880 --> 02:15:04.880]   There it is.
[02:15:04.880 --> 02:15:05.880]   F-O-O-D in O-M-S.
[02:15:05.880 --> 02:15:11.080]   And it is a nutrition food tracking app.
[02:15:11.080 --> 02:15:12.080]   The thing that...
[02:15:12.080 --> 02:15:14.400]   There are multiple things that makes this app pretty neat.
[02:15:14.400 --> 02:15:18.040]   It is also free with IAP.
[02:15:18.040 --> 02:15:22.240]   With my fitness pal is one of the very popular food tracking apps.
[02:15:22.240 --> 02:15:27.960]   And it has a huge database of information that makes it pretty easy to log your food.
[02:15:27.960 --> 02:15:33.080]   But one of the problems with that is it's plugged into some online database somewhere
[02:15:33.080 --> 02:15:37.840]   that is, you know, sinking your information across and you've got all these different
[02:15:37.840 --> 02:15:38.840]   privacy policies.
[02:15:38.840 --> 02:15:42.240]   Food Gnomes, one of the things that they put forth as the most important aspect of the
[02:15:42.240 --> 02:15:46.200]   app is that it is a privacy-focused app.
[02:15:46.200 --> 02:15:52.600]   So except for pulling from the database that exists to get nutrition information, your data
[02:15:52.600 --> 02:15:54.840]   is not going that way.
[02:15:54.840 --> 02:15:56.360]   This stuff is coming down.
[02:15:56.360 --> 02:16:00.360]   But what I think is very cool about this app is along with being able to see some really
[02:16:00.360 --> 02:16:04.720]   great graphs for your information is the nutrition label scanning feature.
[02:16:04.720 --> 02:16:11.040]   So even if the information is not available in the app, in the database that they have
[02:16:11.040 --> 02:16:16.760]   available, they take advantage of some of the new computer vision APIs that are in iOS
[02:16:16.760 --> 02:16:23.080]   that were introduced in iOS 13 that were announced at WWDC to basically you take a snapshot,
[02:16:23.080 --> 02:16:28.400]   you take a photo of a nutrition fact label and it pulls in all of the information from
[02:16:28.400 --> 02:16:32.920]   it, the calories, all of that information, but as well as, you know, serving size and
[02:16:32.920 --> 02:16:33.920]   things like that.
[02:16:33.920 --> 02:16:39.640]   And so you can use that to then inform your tracking throughout the day.
[02:16:39.640 --> 02:16:43.920]   And then of course, my most important feature is that it syncs with the Health app.
[02:16:43.920 --> 02:16:47.760]   And so all that information is available in my Health app, but then also is available
[02:16:47.760 --> 02:16:53.600]   to the other apps I use who pull their data from the Health app as its database.
[02:16:53.600 --> 02:17:01.760]   If you want to up your subscription, the Food Noms Plus subscription is $1.99 a month
[02:17:01.760 --> 02:17:03.120]   or $1.6.99 a year.
[02:17:03.120 --> 02:17:04.600]   Again, free to download.
[02:17:04.600 --> 02:17:07.440]   The Plus subscription is where the additions come from.
[02:17:07.440 --> 02:17:13.520]   That gives you unlimited nutrition goals and you can track some other nutrition data that
[02:17:13.520 --> 02:17:19.160]   is not available with just the normal version, but the Plus version.
[02:17:19.160 --> 02:17:21.840]   You can sync of course across all your devices.
[02:17:21.840 --> 02:17:26.400]   And like I said, it's the scanning feature that I really like, this nutrition label scanning
[02:17:26.400 --> 02:17:27.680]   and the barcode scanner.
[02:17:27.680 --> 02:17:30.240]   They're both very quick and very easy ways.
[02:17:30.240 --> 02:17:37.480]   I am notorious, I've talked about this before, but I wish I didn't have to eat.
[02:17:37.480 --> 02:17:42.760]   I wish that eating wasn't a thing that humans were required to do because it's just a pain
[02:17:42.760 --> 02:17:44.240]   in the tuckus.
[02:17:44.240 --> 02:17:45.760]   And I often forget to eat.
[02:17:45.760 --> 02:17:46.760]   You're eating wrong.
[02:17:46.760 --> 02:17:48.760]   And then the day, thank you.
[02:17:48.760 --> 02:17:52.080]   As if I haven't heard that every time I say this.
[02:17:52.080 --> 02:17:53.080]   Sorry, sorry.
[02:17:53.080 --> 02:17:56.800]   If only you had tried this one meal, I'm like, no, that's not going to change anything for
[02:17:56.800 --> 02:17:57.800]   me.
[02:17:57.800 --> 02:18:02.000]   I feel I love the people love food, you should love food if you love food, love food.
[02:18:02.000 --> 02:18:03.000]   That's great.
[02:18:03.000 --> 02:18:04.640]   And there are some meals that are good.
[02:18:04.640 --> 02:18:08.280]   But if I could go without having to eat, if I could take a pill at the beginning of the
[02:18:08.280 --> 02:18:12.320]   day that gave me everything I needed for the day, God, I'd be in heaven.
[02:18:12.320 --> 02:18:17.200]   So because of that though, it'll often come around to three or four p.m.
[02:18:17.200 --> 02:18:19.400]   And I'm like, why am I so tired?
[02:18:19.400 --> 02:18:23.520]   And then it's the realization that, oh my goodness, I haven't fed myself today.
[02:18:23.520 --> 02:18:27.320]   And I need to be better, obviously, about calorie tracking and making sure I'm at least
[02:18:27.320 --> 02:18:31.320]   getting the minimum calories that I need in a given day and nutrition.
[02:18:31.320 --> 02:18:35.840]   So I'm really trying to stick to that with this food gnomes app and it makes it very fast.
[02:18:35.840 --> 02:18:40.360]   So if I'm going in between shows or I'm back at my desk or I'm in transition from being
[02:18:40.360 --> 02:18:45.600]   home to walk the dogs and let them out and coming back here, then I can very easily track
[02:18:45.600 --> 02:18:46.600]   that.
[02:18:46.600 --> 02:18:53.080]   So yes, that is food gnomes, again, available for free with an in-app purchase.
[02:18:53.080 --> 02:18:55.920]   And new app to hit the app store.
[02:18:55.920 --> 02:18:59.080]   And that is the end of another episode.
[02:18:59.080 --> 02:19:04.200]   So I want to ask, of course, Andy and Otco, WGBHs or is it WES?
[02:19:04.200 --> 02:19:07.200]   WGBHs, Andy and Otco and notco.com.
[02:19:07.200 --> 02:19:11.600]   If people are looking to get in touch with you, if they want to follow your work and if
[02:19:11.600 --> 02:19:15.320]   they want to check out the stuff you're doing, how can they do all of that?
[02:19:15.320 --> 02:19:19.880]   No show this week because we're being preempted for the impeachment hearings coverage live
[02:19:19.880 --> 02:19:20.880]   on WGBH.
[02:19:20.880 --> 02:19:26.400]   But as usual, go check me out on Twitter and not go or Instagram or not go and you'll
[02:19:26.400 --> 02:19:33.640]   be able to find my synaptic misfireings, reactions, ideas, thoughts, and basically what
[02:19:33.640 --> 02:19:35.400]   I do instead of writing.
[02:19:35.400 --> 02:19:37.400]   All right, excellent.
[02:19:37.400 --> 02:19:42.200]   And I'm more's own managing editor, Lori Gill.
[02:19:42.200 --> 02:19:47.000]   How can people check you out online, check out your work, all that stuff.
[02:19:47.000 --> 02:19:50.080]   Andy, you have anything to pitch?
[02:19:50.080 --> 02:19:54.240]   You can find me @applaholic on Twitter, A-P-P-A-H-O-L-I-K.
[02:19:54.240 --> 02:19:57.920]   You can find me @Lori Gill at most of the other social things.
[02:19:57.920 --> 02:20:01.760]   And the only thing that I've got to pitch is I'll be on tour in Japan next week.
[02:20:01.760 --> 02:20:03.320]   So hope I have a look.
[02:20:03.320 --> 02:20:04.320]   Hey, yay!
[02:20:04.320 --> 02:20:05.320]   Safe travels.
[02:20:05.320 --> 02:20:06.320]   Ramen.
[02:20:06.320 --> 02:20:07.320]   Yeah, enjoy your travel.
[02:20:07.320 --> 02:20:08.320]   I can't wait.
[02:20:08.320 --> 02:20:09.920]   And enjoy your food there.
[02:20:09.920 --> 02:20:14.240]   I will live vicariously through you in that way.
[02:20:14.240 --> 02:20:24.720]   Alex Lindsey, Pixel Core, and just massive amounts of technical knowledge that I appreciate
[02:20:24.720 --> 02:20:28.320]   getting to learn about every time you-- I'm here with you.
[02:20:28.320 --> 02:20:29.320]   Thank you.
[02:20:29.320 --> 02:20:32.560]   Where can people follow you online, keep up with what you do, and do you have anything
[02:20:32.560 --> 02:20:33.560]   to pitch?
[02:20:33.560 --> 02:20:34.960]   I don't really need to pitch.
[02:20:34.960 --> 02:20:43.400]   You can find me on both Twitter and Instagram as Alex Lindsey with an A-Y, not an A-Y.
[02:20:43.400 --> 02:20:44.840]   And then I started to write some stuff on Medium.
[02:20:44.840 --> 02:20:49.320]   I think if you search for Medium for Alex Lindsey, you can find some stuff on Blue Collar,
[02:20:49.320 --> 02:20:54.440]   Digital Work, and e-game, esports, and livestreaming, you know, kind of geeky stuff.
[02:20:54.440 --> 02:20:55.880]   I'll probably do more of that.
[02:20:55.880 --> 02:20:57.360]   That's about it.
[02:20:57.360 --> 02:20:58.360]   Excellent.
[02:20:58.360 --> 02:21:01.600]   Well, folks, this is going to be my last Mac break weekly.
[02:21:01.600 --> 02:21:07.480]   And until the next time I am needed, Leo, we'll be back next week.
[02:21:07.480 --> 02:21:11.920]   But if you're looking for me online, you can find me @mikasargent on pretty much all
[02:21:11.920 --> 02:21:13.720]   of the social platforms.
[02:21:13.720 --> 02:21:17.580]   You can head to chihuahua.coffy, C-H-I-H-U-A-H-U-A.coffy.
[02:21:17.580 --> 02:21:21.840]   Thank you, Renee Ritchie, which has links to all the different things that I do.
[02:21:21.840 --> 02:21:27.840]   And I guess my pitch would be to check out Smart Tech today, a show that we publish, that
[02:21:27.840 --> 02:21:34.160]   we record live every Monday at 4 p.m. Pacific.
[02:21:34.160 --> 02:21:39.840]   And that is a show all about Smart Tech, which includes smart home stuff, digital assistance,
[02:21:39.840 --> 02:21:42.800]   and everything in between that I do with Matthew Cass and Ellie.
[02:21:42.800 --> 02:21:47.560]   So check that out if you are into that sort of thing or want to get into that sort of
[02:21:47.560 --> 02:21:48.560]   thing.
[02:21:48.560 --> 02:21:56.880]   Of course, this show records-- let me go find the exact-- because I never remember the UTC
[02:21:56.880 --> 02:21:57.880]   times.
[02:21:57.880 --> 02:22:01.160]   This show records live every Tuesday at 2 p.m. Eastern, which is 11 a.m.
[02:22:01.160 --> 02:22:05.600]   Pacific, which is 1900 UTC.
[02:22:05.600 --> 02:22:11.760]   If you had to twitch.tv/mbw, then you can subscribe to the show on Apple Podcasts, Google Podcasts,
[02:22:11.760 --> 02:22:15.760]   or any other podcast platform, as well as check out the YouTube page there.
[02:22:15.760 --> 02:22:21.360]   If you had to twitch.tv/live, that's how you join us live and hang out in the chat if
[02:22:21.360 --> 02:22:23.400]   you'd like to.
[02:22:23.400 --> 02:22:26.360]   And share your thoughts there while we're having our conversation.
[02:22:26.360 --> 02:22:29.920]   So we thank you all for tuning in this week.
[02:22:29.920 --> 02:22:33.720]   And thank you all for letting me join you.
[02:22:33.720 --> 02:22:35.720]   I've really appreciated this time.
[02:22:35.720 --> 02:22:36.720]   You did a great job.
[02:22:36.720 --> 02:22:37.720]   Thank you.
[02:22:37.720 --> 02:22:38.720]   Thank you.
[02:22:38.720 --> 02:22:39.720]   Thank you.
[02:22:39.720 --> 02:22:41.720]   Yep, it was wonderful.
[02:22:41.720 --> 02:22:45.760]   And until next time, it's time to get back to work.
[02:22:45.760 --> 02:22:46.480]   This break time is over.
[02:22:46.480 --> 02:22:56.480]   [MUSIC]
[02:22:56.480 --> 02:22:59.060]   (upbeat music)

