;FFMETADATA1
title=Hatch My Eggs!
artist=Leo Laporte, Andy Ihnatko, Rene Ritchie, Alex Lindsay
album_artist=TWiT
publisher=TWiT
album=MacBreak Weekly
TRDA=2021-08-10
track=778
language=English
genre=Podcast
comment=Apple CSAM, patent trolls, iPhone 13 rumors
encoded_by=Uniblab 5.3
date=2021
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:03.600]   It's time for Mac Break Weekly, Andy, Alex, Renee.
[00:00:03.600 --> 00:00:04.400]   They're all here.
[00:00:04.400 --> 00:00:08.120]   They've all been studying hard, and we will give you
[00:00:08.120 --> 00:00:12.920]   the final definitive everything you need to know
[00:00:12.920 --> 00:00:17.240]   about Apple's new child pornography plans,
[00:00:17.240 --> 00:00:21.760]   what it means, how it works, and what the problems are.
[00:00:21.760 --> 00:00:24.420]   This is one you're not gonna wanna miss.
[00:00:24.420 --> 00:00:27.520]   We'll also talk about some new Apple TV programming,
[00:00:27.520 --> 00:00:30.080]   and we've got some tips as well.
[00:00:30.080 --> 00:00:32.240]   It's all coming up next on Mac Break Weekly.
[00:00:32.240 --> 00:00:36.440]   Podcasts you love.
[00:00:36.440 --> 00:00:37.920]   - From people you trust.
[00:00:37.920 --> 00:00:40.320]   - This is true.
[00:00:40.320 --> 00:00:49.640]   - This is Mac Break Weekly, episode 778.
[00:00:49.640 --> 00:00:52.880]   Recorded Tuesday, August 10th, 2021.
[00:00:52.880 --> 00:00:54.480]   Hatch my eggs.
[00:00:55.560 --> 00:00:58.960]   Mac Break Weekly is brought to you by Udacity.
[00:00:58.960 --> 00:01:01.760]   Gain in-demand tech skills in as little as three months
[00:01:01.760 --> 00:01:05.360]   with Udacity's part-time online tech courses.
[00:01:05.360 --> 00:01:10.160]   Visit Udacity.com/twit and get 75% off any program
[00:01:10.160 --> 00:01:13.280]   with code TWIT 7.5, limited time offer.
[00:01:13.280 --> 00:01:17.560]   And by AT&T active armor.
[00:01:17.560 --> 00:01:19.600]   We rely so much on our phones these days
[00:01:19.600 --> 00:01:23.240]   and are always on them, whether it's live streaming content,
[00:01:23.240 --> 00:01:25.880]   catching up with family on weekly video calls,
[00:01:25.880 --> 00:01:27.880]   or watching your favorite podcast,
[00:01:27.880 --> 00:01:30.160]   there's no room for fraud calls.
[00:01:30.160 --> 00:01:33.600]   Thankfully, AT&T makes customer security a priority,
[00:01:33.600 --> 00:01:36.200]   helping block those pesky calls.
[00:01:36.200 --> 00:01:37.520]   It's not complicated.
[00:01:37.520 --> 00:01:39.440]   AT&T active armor.
[00:01:39.440 --> 00:01:43.920]   24/7 proactive network security and fraud call blocking
[00:01:43.920 --> 00:01:47.080]   to help stop threats at no extra charge.
[00:01:47.080 --> 00:01:49.000]   Compatible device and service required.
[00:01:49.000 --> 00:01:53.120]   Visit att.com/active armor for details.
[00:01:53.120 --> 00:01:55.000]   It's time for Mac Break Weekly, the show we cover
[00:01:55.000 --> 00:01:56.880]   the latest Apple news.
[00:01:56.880 --> 00:02:01.440]   Our team has assembled Alex Lindsey from 090.media
[00:02:01.440 --> 00:02:06.120]   and of course, office hours.globalgoodday, Alex.
[00:02:06.120 --> 00:02:06.960]   Hello, hello.
[00:02:06.960 --> 00:02:10.240]   Do you sometimes lose track of what time of day or night it is?
[00:02:10.240 --> 00:02:11.400]   (laughing)
[00:02:11.400 --> 00:02:12.400]   It is.
[00:02:12.400 --> 00:02:15.640]   It does get, it turns into a little bit of a wash, you know?
[00:02:15.640 --> 00:02:18.040]   'Cause now that office hours is 24/7,
[00:02:18.040 --> 00:02:20.520]   I was like hanging out last night cleaning and I was like,
[00:02:20.520 --> 00:02:21.640]   "Oh, I'm just gonna jump into office hours."
[00:02:21.640 --> 00:02:23.440]   Yeah, thanks for your nice and comfortable.
[00:02:23.440 --> 00:02:24.280]   Thanks for having us in the conference.
[00:02:24.280 --> 00:02:25.400]   You keep the curtain strong.
[00:02:25.400 --> 00:02:27.560]   You don't need to know the sun has come up.
[00:02:27.560 --> 00:02:28.400]   Yep.
[00:02:28.400 --> 00:02:29.240]   Good to see you.
[00:02:29.240 --> 00:02:30.080]   Good to be here.
[00:02:30.080 --> 00:02:33.120]   Also Andy Inaco, who spent the morning shaving.
[00:02:33.120 --> 00:02:35.360]   (laughing)
[00:02:35.360 --> 00:02:38.880]   It wasn't a six hour process.
[00:02:38.880 --> 00:02:42.560]   It was just one of those, like you make the call at 10 a.m.
[00:02:42.560 --> 00:02:44.600]   that no, you know what, I don't need to shave.
[00:02:44.600 --> 00:02:47.320]   And then like 10 minutes before your people are gonna be
[00:02:47.320 --> 00:02:51.120]   seeing you, your faith in your judgment lapses.
[00:02:51.120 --> 00:02:53.840]   Like, you know what, I kind of really just shaved a case.
[00:02:53.840 --> 00:02:57.440]   I forget I have a decent camera now and people can.
[00:02:57.440 --> 00:02:58.800]   You do that.
[00:02:58.800 --> 00:03:02.160]   I tell you, Alex has raised the bar for all of us.
[00:03:02.160 --> 00:03:04.440]   I am now the lowest quality camera,
[00:03:04.440 --> 00:03:07.400]   even though I'm in studio and you guys are all in Zoom.
[00:03:07.400 --> 00:03:09.560]   My quality is terrible, which is good
[00:03:09.560 --> 00:03:11.760]   'cause the bags in my eyes.
[00:03:11.760 --> 00:03:13.200]   You know, I need an eye light.
[00:03:13.200 --> 00:03:14.880]   I need a, can you get me a light, right?
[00:03:14.880 --> 00:03:16.360]   That's what Peter Jennings used to have.
[00:03:16.360 --> 00:03:19.040]   A light right there, firing into the bags,
[00:03:19.040 --> 00:03:20.480]   flattens them right out, right Alex?
[00:03:20.480 --> 00:03:22.720]   That's all you need, just an eye light.
[00:03:22.720 --> 00:03:25.520]   Yeah, there's, who had those?
[00:03:25.520 --> 00:03:28.280]   And CMDC and Wall Street.
[00:03:28.280 --> 00:03:29.320]   Yeah, ABC, Peter Jennings famous.
[00:03:29.320 --> 00:03:32.120]   How these little like, they're like Roscoe Pat,
[00:03:32.120 --> 00:03:34.000]   the little pads I think are the things that go up there.
[00:03:34.000 --> 00:03:36.720]   Famous, you know, that Peter Jennings just had a little light
[00:03:36.720 --> 00:03:38.440]   and it's on your desk firing right in your eyes.
[00:03:38.440 --> 00:03:41.280]   I don't know how you get used to that, but anyway,
[00:03:41.280 --> 00:03:42.880]   it certainly helps.
[00:03:42.880 --> 00:03:43.720]   (laughing)
[00:03:43.720 --> 00:03:45.800]   Also, somebody who does not need an eye light,
[00:03:45.800 --> 00:03:48.480]   but now has a pop filter, so you know,
[00:03:48.480 --> 00:03:50.880]   each to his own, Mr. Renee.
[00:03:50.880 --> 00:03:51.720]   It's so close.
[00:03:51.720 --> 00:03:52.920]   Hey, Renee, Richard.
[00:03:52.920 --> 00:03:55.360]   Hey Leo, I'm so happy I spent three days
[00:03:55.360 --> 00:03:58.080]   making the toughest 43 minute video of my life.
[00:03:58.080 --> 00:04:00.000]   And now I can just relax and talk comic books
[00:04:00.000 --> 00:04:01.600]   and operate with you.
[00:04:01.600 --> 00:04:04.040]   No, no, no, wait, no, no.
[00:04:04.040 --> 00:04:06.000]   No, no, no, wrong.
[00:04:06.000 --> 00:04:08.760]   Because of course everybody knows this is,
[00:04:08.760 --> 00:04:11.000]   this is the show where we talk about apples.
[00:04:11.000 --> 00:04:14.720]   Quote, expanded protections for children.
[00:04:14.720 --> 00:04:17.000]   Think of the children.
[00:04:17.000 --> 00:04:20.640]   Apple.com, if you haven't already heard this discussion,
[00:04:20.640 --> 00:04:23.280]   ad nauseam, but I thought, you know,
[00:04:23.280 --> 00:04:25.440]   this is Mac Break Weekly, if anywhere
[00:04:25.440 --> 00:04:26.960]   we should be talking about it.
[00:04:26.960 --> 00:04:27.800]   Well, what better?
[00:04:27.800 --> 00:04:32.800]   Start with Apple's page, which is apple.com/childsafety.
[00:04:32.800 --> 00:04:35.920]   And if you go to the page, you will understand better
[00:04:35.920 --> 00:04:37.600]   what they're doing, by the way, better than a lot
[00:04:37.600 --> 00:04:39.760]   of mainstream media, what they're doing.
[00:04:39.760 --> 00:04:42.720]   And then if you really care, there's a frequently asked
[00:04:42.720 --> 00:04:46.000]   questions, there's a white paper on how they're doing it.
[00:04:47.000 --> 00:04:51.000]   And I'll give you the brief succinct version.
[00:04:51.000 --> 00:04:53.480]   And correct me if I'm wrong, because it is easy
[00:04:53.480 --> 00:04:54.240]   to get this wrong.
[00:04:54.240 --> 00:04:55.080]   Apple's actually--
[00:04:55.080 --> 00:04:55.880]   It's super complicated.
[00:04:55.880 --> 00:04:57.640]   They announced three different initiatives,
[00:04:57.640 --> 00:05:02.320]   all under one rubric of detecting child pornography,
[00:05:02.320 --> 00:05:06.080]   or as they call it, CSAM child sexual abuse material.
[00:05:06.080 --> 00:05:12.440]   They're going to scan images in iCloud photos.
[00:05:12.440 --> 00:05:17.920]   They are also going to scan images on your iPad and iPhone,
[00:05:17.920 --> 00:05:20.520]   starting with iOS 15.
[00:05:20.520 --> 00:05:23.680]   But scan, we need to understand what that means.
[00:05:23.680 --> 00:05:27.360]   They are going to use a database of--
[00:05:27.360 --> 00:05:30.800]   essentially fingerprints hashes from the National Center
[00:05:30.800 --> 00:05:32.840]   for Missing and Exploited Children here and after,
[00:05:32.840 --> 00:05:34.760]   referred to as NECMEC.
[00:05:34.760 --> 00:05:37.640]   NECMEC has maintained this database for some time.
[00:05:37.640 --> 00:05:42.600]   It's created using a perceptual hash technology that
[00:05:42.600 --> 00:05:47.240]   was developed by Microsoft and given to NECMEC by Microsoft.
[00:05:47.240 --> 00:05:51.520]   It creates what NECMEC claims is a unique hash for known
[00:05:51.520 --> 00:05:54.880]   child pornography, images that are known to be child
[00:05:54.880 --> 00:05:56.080]   pornography.
[00:05:56.080 --> 00:06:00.920]   That child pornography cannot be held by any other organization
[00:06:00.920 --> 00:06:02.080]   for obvious reasons.
[00:06:02.080 --> 00:06:03.520]   You don't want to distribute it.
[00:06:03.520 --> 00:06:07.280]   So the US government created and funded NECMEC to do this.
[00:06:07.280 --> 00:06:08.440]   They hold those images.
[00:06:08.440 --> 00:06:10.720]   They create that hash.
[00:06:10.720 --> 00:06:12.600]   And then companies like Facebook, they've
[00:06:12.600 --> 00:06:14.120]   been doing it for some time, Google.
[00:06:14.120 --> 00:06:15.520]   They've been doing it for some time.
[00:06:15.520 --> 00:06:18.640]   And now Apple use that database to matte
[00:06:18.640 --> 00:06:21.240]   and they create on their end a similar hash using
[00:06:21.240 --> 00:06:23.560]   a similar technology and then check.
[00:06:23.560 --> 00:06:26.640]   And if the fingerprints match, and Apple
[00:06:26.640 --> 00:06:28.760]   says there's a 1 in 1 trillion, which
[00:06:28.760 --> 00:06:32.920]   we'll get to, a 1 in 1 trillion chance of a false positive,
[00:06:32.920 --> 00:06:34.680]   that's a little check mark.
[00:06:34.680 --> 00:06:36.640]   And Apple has some threshold at some point
[00:06:36.640 --> 00:06:38.600]   at which if there are enough check marks,
[00:06:38.600 --> 00:06:40.920]   they notify NECMEC.
[00:06:40.920 --> 00:06:44.000]   We've got somebody who's got CSAM.
[00:06:44.000 --> 00:06:46.640]   And then I don't know what NECMEC does, presumably they
[00:06:46.640 --> 00:06:50.240]   turn you over to the law enforcement.
[00:06:50.240 --> 00:06:52.920]   Now, we should be clear that Apple's doing this
[00:06:52.920 --> 00:06:54.200]   in three different ways.
[00:06:54.200 --> 00:06:56.400]   iCloud Photos, there's--
[00:06:56.400 --> 00:06:58.400]   before an image goes to iCloud Photos,
[00:06:58.400 --> 00:07:02.960]   there's an on-device matching process
[00:07:02.960 --> 00:07:06.240]   that checks against the NECMEC database.
[00:07:06.240 --> 00:07:08.320]   There's also--
[00:07:08.320 --> 00:07:11.360]   they've got-- that's when this threshold secret sharing
[00:07:11.360 --> 00:07:14.720]   system, which Apple developed, comes into place.
[00:07:14.720 --> 00:07:17.720]   The contents of the vouchers generated
[00:07:17.720 --> 00:07:23.600]   by this cryptographic process cannot be interpreted by Apple
[00:07:23.600 --> 00:07:26.960]   unless the iCloud Photos account crosses the threshold of known
[00:07:26.960 --> 00:07:28.000]   CSAM content.
[00:07:28.000 --> 00:07:29.600]   They don't say what the threshold is.
[00:07:29.600 --> 00:07:32.320]   But they say it is set to provide an extremely high level
[00:07:32.320 --> 00:07:36.160]   of accuracy and ensures less than 1 in 1 trillion chance
[00:07:36.160 --> 00:07:41.040]   per year of incorrectly flagging a given account.
[00:07:41.040 --> 00:07:43.680]   Then, once it crosses that threshold,
[00:07:43.680 --> 00:07:46.240]   Apple manually reviews each report
[00:07:46.240 --> 00:07:47.400]   to confirm there's a match.
[00:07:47.400 --> 00:07:51.040]   In other words, a lower quality copy of that image
[00:07:51.040 --> 00:07:55.160]   is sent to a human being at Apple who--
[00:07:55.160 --> 00:07:56.360]   what is he matching against?
[00:07:56.360 --> 00:07:59.560]   It can't be the actual image because they don't have the images.
[00:07:59.560 --> 00:08:00.760]   So I guess they're looking--
[00:08:00.760 --> 00:08:01.920]   Yeah, it's the number--
[00:08:01.920 --> 00:08:04.440]   if they hash it and then the low-res version of the image
[00:08:04.440 --> 00:08:05.040]   if they have to.
[00:08:05.040 --> 00:08:07.040]   I guess they can look at the lower-res image and say,
[00:08:07.040 --> 00:08:08.520]   yes, that's poor now.
[00:08:08.520 --> 00:08:09.160]   Child's porn.
[00:08:09.160 --> 00:08:10.080]   OK.
[00:08:10.080 --> 00:08:12.920]   Then they disable account report to NetMac.
[00:08:12.920 --> 00:08:15.080]   If the user feels the account has been mistakenly flagged,
[00:08:15.080 --> 00:08:17.920]   they can file an appeal.
[00:08:17.920 --> 00:08:21.440]   There is also another technology being done on the phone
[00:08:21.440 --> 00:08:24.600]   and it stays on the phone.
[00:08:24.600 --> 00:08:27.880]   And it's used-- now, this one is a little less clear.
[00:08:27.880 --> 00:08:31.880]   So Renee, you might want to help me on this one.
[00:08:31.880 --> 00:08:34.360]   For sure.
[00:08:34.360 --> 00:08:37.640]   In Syrian search, they're going to provide--
[00:08:37.640 --> 00:08:40.040]   Apple says, additional resources to help children and parents
[00:08:40.040 --> 00:08:43.000]   stay safe online and get help with unsafe situations.
[00:08:43.000 --> 00:08:45.760]   For example, users who ask Siri how they can report
[00:08:45.760 --> 00:08:47.960]   CSAM or child exploitation will be
[00:08:47.960 --> 00:08:50.480]   pointed to an appropriate spot.
[00:08:50.480 --> 00:08:52.120]   That's not controversial.
[00:08:52.120 --> 00:08:53.400]   This might be a little bit more.
[00:08:53.400 --> 00:08:56.040]   Syrian search are being updated to intervene when users
[00:08:56.040 --> 00:08:59.880]   perform searches for queries related to CSAM.
[00:08:59.880 --> 00:09:02.760]   They'll say, hey, that's harmful and problematic,
[00:09:02.760 --> 00:09:06.480]   et cetera, et cetera, and provide resources from partners.
[00:09:06.480 --> 00:09:10.840]   That's coming to iOS 15, iPadOS 15, WatchOS 8, and MacOS
[00:09:10.840 --> 00:09:12.240]   Monterey.
[00:09:12.240 --> 00:09:18.120]   And then if you are under 13, if you're a child,
[00:09:18.120 --> 00:09:22.280]   images sent to and from you are being scanned in the same way.
[00:09:22.280 --> 00:09:24.840]   And this I wasn't clear, Renee.
[00:09:24.840 --> 00:09:26.120]   Do they have to cross that threshold?
[00:09:26.120 --> 00:09:27.280]   Probably not.
[00:09:27.280 --> 00:09:29.920]   If even one incident, it will then notify the parent.
[00:09:29.920 --> 00:09:30.400]   It does not--
[00:09:30.400 --> 00:09:31.800]   Yeah, so this is a different--
[00:09:31.800 --> 00:09:32.520]   That's a different--
[00:09:32.520 --> 00:09:33.720]   It's a very different system and it's
[00:09:33.720 --> 00:09:35.080]   causing a lot of confusion.
[00:09:35.080 --> 00:09:37.080]   This is not being matched against anything.
[00:09:37.080 --> 00:09:40.640]   The matching is only for existing--
[00:09:40.640 --> 00:09:42.000]   Images on.
[00:09:42.000 --> 00:09:42.840]   Images.
[00:09:42.840 --> 00:09:44.960]   This is for images that are being sent to a child.
[00:09:44.960 --> 00:09:47.960]   So everything about-- it's not an iMessage feature at all
[00:09:47.960 --> 00:09:49.960]   because it also works with SMS and MMS.
[00:09:49.960 --> 00:09:51.880]   It's built into the Messenger client.
[00:09:51.880 --> 00:09:53.280]   So it uses computer vision.
[00:09:53.280 --> 00:09:56.160]   And if it determines-- the same way the Photos app can tell you
[00:09:56.160 --> 00:09:59.080]   if it's a cat or a car, this will determine
[00:09:59.080 --> 00:10:00.920]   if it's an explicit sexual image.
[00:10:00.920 --> 00:10:02.680]   And then it will blur it automatically.
[00:10:02.680 --> 00:10:03.760]   So that's not C-Sam.
[00:10:03.760 --> 00:10:05.800]   That could be pornography of any kind.
[00:10:05.800 --> 00:10:08.880]   Or it's anything that's detected to be explicit sexuality.
[00:10:08.880 --> 00:10:09.280]   Yeah.
[00:10:09.280 --> 00:10:12.160]   And we don't know how well that works.
[00:10:12.160 --> 00:10:14.200]   In the past we've seen systems like this that have not
[00:10:14.200 --> 00:10:15.440]   worked very well.
[00:10:15.440 --> 00:10:17.440]   But again, this doesn't go to the police or neck-meck.
[00:10:17.440 --> 00:10:18.920]   This goes to parents.
[00:10:18.920 --> 00:10:19.320]   All right.
[00:10:19.320 --> 00:10:19.840]   Let's take--
[00:10:19.840 --> 00:10:20.480]   Go ahead.
[00:10:20.480 --> 00:10:21.400]   I'll go ahead.
[00:10:21.400 --> 00:10:24.160]   That's the three different things it's doing.
[00:10:24.160 --> 00:10:24.680]   If I left anything--
[00:10:24.680 --> 00:10:28.680]   On a virtual aspect to this one is that if the person is
[00:10:28.680 --> 00:10:31.440]   under-- is 12 years older under, the parent can also
[00:10:31.440 --> 00:10:33.000]   optionally-- it's all opt-in.
[00:10:33.000 --> 00:10:34.200]   It's not on by default.
[00:10:34.200 --> 00:10:36.600]   But they can opt-in to getting a notification.
[00:10:36.600 --> 00:10:39.320]   So if the child hits, show me the picture anyway.
[00:10:39.320 --> 00:10:40.440]   They'll put up a warning.
[00:10:40.440 --> 00:10:42.000]   If the kid says, I still want to see it,
[00:10:42.000 --> 00:10:44.280]   they'll put up a second warning saying, if you look at this,
[00:10:44.280 --> 00:10:45.640]   your parent's going to be notified.
[00:10:45.640 --> 00:10:48.440]   And if they hit that anyway, they'll send a notification.
[00:10:48.440 --> 00:10:50.320]   And some people worry that this will out.
[00:10:50.320 --> 00:10:52.240]   If it's a non-hetero image, for example,
[00:10:52.240 --> 00:10:54.720]   it will lead to outing, which can lead to abuse or abandonment
[00:10:54.720 --> 00:10:55.800]   or issues like that.
[00:10:55.800 --> 00:10:56.640]   Here's the--
[00:10:56.640 --> 00:10:57.160]   But there's the--
[00:10:57.160 --> 00:10:58.360]   There's the four different--
[00:10:58.360 --> 00:11:03.720]   Here's the four different screens that a child would see
[00:11:03.720 --> 00:11:05.360]   in the four different levels.
[00:11:05.360 --> 00:11:06.880]   And of course, this is the final one.
[00:11:06.880 --> 00:11:08.040]   And it's sending and receiving.
[00:11:08.040 --> 00:11:09.040]   Yeah.
[00:11:09.040 --> 00:11:09.880]   Yeah.
[00:11:09.880 --> 00:11:12.080]   We should mention there is a refinement on this, though.
[00:11:12.080 --> 00:11:16.520]   Specifically, that is what happens if the user is 12 years old
[00:11:16.520 --> 00:11:17.640]   or younger.
[00:11:17.640 --> 00:11:22.320]   If it's a teenager, the tool will say, hey, by the way,
[00:11:22.320 --> 00:11:24.680]   this seems to be explicit content.
[00:11:24.680 --> 00:11:27.440]   And you have to willingly tap on it to get it.
[00:11:27.440 --> 00:11:29.840]   But specifically, if it's a teenager,
[00:11:29.840 --> 00:11:32.160]   then the parent does not get notified.
[00:11:32.160 --> 00:11:32.880]   It's just simply--
[00:11:32.880 --> 00:11:34.040]   Under 13.
[00:11:34.040 --> 00:11:34.880]   Under 13.
[00:11:34.880 --> 00:11:35.320]   No, no, no.
[00:11:35.320 --> 00:11:37.880]   It's a teenager between 13 and 17.
[00:11:37.880 --> 00:11:38.320]   And--
[00:11:38.320 --> 00:11:40.880]   Oh, they just get that warning, though, I was talking about earlier.
[00:11:40.880 --> 00:11:41.560]   Right, exactly.
[00:11:41.560 --> 00:11:44.480]   So if you're a teenager, so basically,
[00:11:44.480 --> 00:11:48.440]   within that understood demographic of kids who
[00:11:48.440 --> 00:11:51.640]   are more sexually aware, who might be--
[00:11:51.640 --> 00:11:53.040]   That's an extroing sexuality.
[00:11:53.040 --> 00:11:56.080]   And not want to share certain things with their parents.
[00:11:56.080 --> 00:12:00.080]   The parents can activate or deactivate the broader feature.
[00:12:00.080 --> 00:12:01.840]   But if they're a teenager, they cannot
[00:12:01.840 --> 00:12:07.400]   enable the feature that says, if the child decides
[00:12:07.400 --> 00:12:12.640]   to view this explicit image, suspected explicit image
[00:12:12.640 --> 00:12:14.280]   inside the messages app, the parent
[00:12:14.280 --> 00:12:16.000]   will be notified.
[00:12:16.000 --> 00:12:18.920]   This will not happen, cannot happen if it's a teenager.
[00:12:18.920 --> 00:12:20.040]   However, that's serious.
[00:12:20.040 --> 00:12:20.720]   They can't act either.
[00:12:20.720 --> 00:12:21.600]   That's serious.
[00:12:21.600 --> 00:12:22.520]   If the child is--
[00:12:22.520 --> 00:12:23.640]   Go ahead.
[00:12:23.640 --> 00:12:24.000]   Sorry.
[00:12:24.000 --> 00:12:26.120]   I was going to say, if the child is over 13
[00:12:26.120 --> 00:12:28.240]   and they want to try to roll it back to control it anyway,
[00:12:28.240 --> 00:12:30.960]   you can't change the age of an under 13 account.
[00:12:30.960 --> 00:12:32.200]   You could create a new one.
[00:12:32.200 --> 00:12:34.560]   You can't make someone under 13 again
[00:12:34.560 --> 00:12:36.760]   if they've already been under 13.
[00:12:36.760 --> 00:12:40.400]   And the Syrian search thing only apply to children,
[00:12:40.400 --> 00:12:42.480]   or does it apply to everyone?
[00:12:42.480 --> 00:12:42.920]   Everyone.
[00:12:42.920 --> 00:12:44.080]   It applies to everybody.
[00:12:44.080 --> 00:12:46.120]   But all of this stuff is US only.
[00:12:46.120 --> 00:12:47.480]   Yeah.
[00:12:47.480 --> 00:12:50.560]   The Syrian search thing is more of a general information
[00:12:50.560 --> 00:12:52.200]   sort of resource.
[00:12:52.200 --> 00:12:55.680]   And we also should call out the--
[00:12:55.680 --> 00:12:57.960]   when you think about this warnings
[00:12:57.960 --> 00:13:01.280]   that 12 years old and younger get,
[00:13:01.280 --> 00:13:04.560]   you imagine like, nanny patrol has blocked
[00:13:04.560 --> 00:13:05.720]   transmission of this.
[00:13:05.720 --> 00:13:08.720]   It's actually a very conversational sort of, hey,
[00:13:08.720 --> 00:13:11.040]   we want to let you know that we think that this might be
[00:13:11.040 --> 00:13:11.800]   explicit.
[00:13:11.800 --> 00:13:14.320]   You may or may not want to view this.
[00:13:14.320 --> 00:13:16.840]   And it's OK if you decide not to see this.
[00:13:16.840 --> 00:13:19.760]   And also very, very gently saying, here's
[00:13:19.760 --> 00:13:22.840]   what you might be in for.
[00:13:22.840 --> 00:13:27.640]   It doesn't anticipate that this is like a 22-year-old who's
[00:13:27.640 --> 00:13:28.840]   being given these messages.
[00:13:28.840 --> 00:13:31.600]   It basically talks in the simple language
[00:13:31.600 --> 00:13:34.240]   that you would find helpful for a child to see
[00:13:34.240 --> 00:13:37.200]   if they have been swapping pictures between each other
[00:13:37.200 --> 00:13:39.040]   without really understanding what's going on.
[00:13:39.040 --> 00:13:41.600]   Or if they are, unfortunately, being
[00:13:41.600 --> 00:13:44.680]   groomed for future abuse, this is basically
[00:13:44.680 --> 00:13:47.240]   let's them know that you've done nothing wrong.
[00:13:47.240 --> 00:13:49.360]   This is there are people you can talk to about this.
[00:13:49.360 --> 00:13:52.280]   This is something that you might want to start to think more
[00:13:52.280 --> 00:13:53.400]   heavily about.
[00:13:53.400 --> 00:13:56.360]   So I think it's been very, very well done.
[00:13:56.360 --> 00:13:58.480]   There are-- well, we're going to talk about that in a second.
[00:13:58.480 --> 00:14:05.040]   There is a duty to report in the US penal code.
[00:14:05.040 --> 00:14:06.040]   They have to report.
[00:14:06.040 --> 00:14:10.440]   But what's important is there is a protection of privacy
[00:14:10.440 --> 00:14:13.560]   built into that penal code, which says nothing in this section
[00:14:13.560 --> 00:14:16.560]   shall be construed to require a provider to monitor any user,
[00:14:16.560 --> 00:14:19.040]   subscriber, or customer, monitor the content.
[00:14:19.040 --> 00:14:21.440]   So in other words, Apple's not required by the penal code
[00:14:21.440 --> 00:14:22.480]   to do this.
[00:14:22.480 --> 00:14:26.800]   They are required if they should find out in some other way.
[00:14:26.800 --> 00:14:28.840]   A requirement to scan as a requirement to report
[00:14:28.840 --> 00:14:29.400]   if they do find--
[00:14:29.400 --> 00:14:30.320]   They have a requirement.
[00:14:30.320 --> 00:14:32.280]   As a result, by the way-- and we should
[00:14:32.280 --> 00:14:34.200]   give you some context--
[00:14:34.200 --> 00:14:38.320]   Facebook has reported last year in 2020,
[00:14:38.320 --> 00:14:42.160]   0.3 million reports of CSAM, 20 million reports.
[00:14:42.160 --> 00:14:44.360]   Out of the 21 million they got, 20 million
[00:14:44.360 --> 00:14:46.040]   were from Facebook, Instagram, and WhatsApp.
[00:14:46.040 --> 00:14:46.920]   Yeah.
[00:14:46.920 --> 00:14:50.640]   In the same year, Apple made 265.
[00:14:50.640 --> 00:14:52.400]   265 compared to 20 million.
[00:14:52.400 --> 00:14:55.360]   By the way, Facebook and Google are already using--
[00:14:55.360 --> 00:14:56.280]   Google means 500,000.
[00:14:56.280 --> 00:14:58.160]   In fact, I think many other cloud providers
[00:14:58.160 --> 00:15:00.560]   are using this NICMIC database and the fingerprinting
[00:15:00.560 --> 00:15:02.160]   technology on their cloud.
[00:15:02.160 --> 00:15:03.640]   It's not in the cloud.
[00:15:03.640 --> 00:15:06.640]   Microsoft all of them did hundreds of thousands of reports.
[00:15:06.640 --> 00:15:07.720]   Anyone you could think of--
[00:15:07.720 --> 00:15:12.920]   And they're doing that against data stored in their cloud
[00:15:12.920 --> 00:15:16.160]   services in every-- in every case.
[00:15:16.160 --> 00:15:17.160]   Well, there are--
[00:15:17.160 --> 00:15:18.160]   [INAUDIBLE]
[00:15:18.160 --> 00:15:19.560]   I know a photo DNA runs on the cloud and does scans.
[00:15:19.560 --> 00:15:20.560]   Yeah.
[00:15:20.560 --> 00:15:23.960]   Google is also doing matches against file attachments
[00:15:23.960 --> 00:15:24.920]   and Gmail as well.
[00:15:24.920 --> 00:15:25.360]   That's right.
[00:15:25.360 --> 00:15:26.480]   Gmail is very emphatic.
[00:15:26.480 --> 00:15:26.960]   That's right.
[00:15:26.960 --> 00:15:27.960]   Yeah.
[00:15:27.960 --> 00:15:30.560]   And Apple has done that in Apple Mail for several years
[00:15:30.560 --> 00:15:31.060]   as well.
[00:15:31.060 --> 00:15:32.560]   This is just the first time they're doing it in--
[00:15:32.560 --> 00:15:33.280]   Well, that's interesting.
[00:15:33.280 --> 00:15:33.840]   I didn't know that.
[00:15:33.840 --> 00:15:37.200]   So this is not the first time they're doing it in Apple Mail.
[00:15:37.200 --> 00:15:39.680]   When you say Apple Mail, that's mail--
[00:15:39.680 --> 00:15:40.440]   iCloud Mail.
[00:15:40.440 --> 00:15:41.320]   iCloud Mail.
[00:15:41.320 --> 00:15:42.360]   Very important.
[00:15:42.360 --> 00:15:43.640]   They're not doing it on the app.
[00:15:43.640 --> 00:15:44.720]   They're doing it in the cloud.
[00:15:45.720 --> 00:15:50.720]   As-- yeah, in transit, they were doing a similar sort of--
[00:15:50.720 --> 00:15:53.720]   If you use iCloud Mail.
[00:15:53.720 --> 00:15:55.720]   Not for other mail providers.
[00:15:55.720 --> 00:15:56.720]   All right.
[00:15:56.720 --> 00:15:59.720]   So I think we've laid the--
[00:15:59.720 --> 00:16:00.720]   Like you said, they all do it.
[00:16:00.720 --> 00:16:01.720]   They all do it.
[00:16:01.720 --> 00:16:04.720]   But they all do it and there's a very, very important distinction.
[00:16:04.720 --> 00:16:06.720]   They all do it in the cloud.
[00:16:06.720 --> 00:16:07.720]   Yeah.
[00:16:07.720 --> 00:16:10.720]   Nobody, as to my knowledge, Google does not do it on your Android
[00:16:10.720 --> 00:16:11.720]   devices.
[00:16:11.720 --> 00:16:12.720]   Is that correct?
[00:16:12.720 --> 00:16:14.720]   As far as I understand, no, no.
[00:16:14.720 --> 00:16:20.720]   In fact, nobody does it on your computer or your phone.
[00:16:20.720 --> 00:16:25.720]   Everybody that does it does it on their cloud service.
[00:16:25.720 --> 00:16:26.720]   Yeah.
[00:16:26.720 --> 00:16:29.720]   And in the case of Apple, it's a little bit farther in transit to
[00:16:29.720 --> 00:16:32.720]   and for Apple and Google with mail and transit to and from.
[00:16:32.720 --> 00:16:33.720]   Yeah.
[00:16:33.720 --> 00:16:37.720]   Can I just say that I think that we're going to talk a lot about
[00:16:37.720 --> 00:16:39.720]   the things that Apple is doing right and Apple--
[00:16:39.720 --> 00:16:41.720]   The things that we think Apple is doing wrong.
[00:16:41.720 --> 00:16:44.720]   I think the one thing after studying this for days and days
[00:16:44.720 --> 00:16:47.720]   that I think is unequivocally wrong is that boy, did they
[00:16:47.720 --> 00:16:50.720]   screw up the messaging on this big time.
[00:16:50.720 --> 00:16:54.720]   That when you-- when the word that comes out early on, well,
[00:16:54.720 --> 00:16:58.720]   when the news has broken officially, but they've yet to come
[00:16:58.720 --> 00:17:00.720]   out with the fact they've yet to send people out to give
[00:17:00.720 --> 00:17:03.720]   interviews and give more information, they're allowing
[00:17:03.720 --> 00:17:06.720]   people to think that this is all one feature, this idea of
[00:17:06.720 --> 00:17:10.720]   scanning things on your device that applies to all of the
[00:17:10.720 --> 00:17:12.720]   new policies.
[00:17:12.720 --> 00:17:16.720]   Instead of making it very, very clear that there is one feature
[00:17:16.720 --> 00:17:21.720]   that will scan photos looking for content matches that only
[00:17:21.720 --> 00:17:24.720]   applies to photos that you're uploading to iCloud.
[00:17:24.720 --> 00:17:28.720]   There is a second feature that does not involve the cops,
[00:17:28.720 --> 00:17:32.720]   does not involve criminal investigation at all, that only
[00:17:32.720 --> 00:17:37.720]   affects messages that are being transmitted to or from a
[00:17:37.720 --> 00:17:40.720]   teenager or someone younger than that.
[00:17:40.720 --> 00:17:42.720]   There is a third thing about that is simply informational
[00:17:42.720 --> 00:17:43.720]   basis.
[00:17:43.720 --> 00:17:47.720]   It's amazing how much that-- I'm not the smartest knife in
[00:17:47.720 --> 00:17:49.720]   the onion box.
[00:17:49.720 --> 00:17:52.720]   However, the amount of time it took me to convince myself that
[00:17:52.720 --> 00:17:56.720]   we are, indeed, talking about two or three completely separate
[00:17:56.720 --> 00:17:59.720]   features with separate powers and separate limitations and
[00:17:59.720 --> 00:18:03.720]   separate threats and separate features.
[00:18:03.720 --> 00:18:07.720]   That was shocking for me, that Apple dropped the ball that
[00:18:07.720 --> 00:18:09.720]   badly on the messaging of this.
[00:18:09.720 --> 00:18:14.720]   They could have saved themselves so much hurt by rolling these
[00:18:14.720 --> 00:18:17.720]   things out one at a time separately by basically saying
[00:18:17.720 --> 00:18:23.720]   that we're having a more active approach against exposure of
[00:18:23.720 --> 00:18:30.720]   abuse of children and exposure of children to sexually advanced,
[00:18:30.720 --> 00:18:33.720]   let's say, imagery and making-- I'm sorry.
[00:18:33.720 --> 00:18:35.720]   I'm getting ahead of myself.
[00:18:35.720 --> 00:18:37.720]   All I'm saying is that if they had done one thing about the
[00:18:37.720 --> 00:18:42.720]   on-device stuff that only affects iCloud, one thing that only
[00:18:42.720 --> 00:18:48.720]   affects the communication between children, made those two
[00:18:48.720 --> 00:18:50.720]   separate announcements on separate weeks, I think they could
[00:18:50.720 --> 00:18:52.720]   have saved themselves a whole bag of hurt.
[00:18:52.720 --> 00:18:53.720]   That's all I wanted to say.
[00:18:53.720 --> 00:18:56.720]   Yeah, and we're fortunate because we are now discussing it in
[00:18:56.720 --> 00:18:59.720]   the subsequent week after hearing from a lot of different
[00:18:59.720 --> 00:19:00.720]   voices.
[00:19:00.720 --> 00:19:07.720]   There is a letter that has been signed by a lot of experts in the
[00:19:07.720 --> 00:19:10.720]   field, the Electronic Frontier Foundation, the Center for
[00:19:10.720 --> 00:19:16.720]   Democracy and Technology, somebody I highly respect, a
[00:19:16.720 --> 00:19:19.720]   security researcher and a cryptographer out of Johns
[00:19:19.720 --> 00:19:23.720]   Hopkins, Matthew Green, all saying Apple, stop, this is the
[00:19:23.720 --> 00:19:25.720]   wrong thing to do.
[00:19:25.720 --> 00:19:29.720]   Most of the complaints involve the slippery slope argument.
[00:19:29.720 --> 00:19:32.720]   Some say the slippery slope fallacy that once you say you can
[00:19:32.720 --> 00:19:35.720]   do this, other governments from other countries are going to
[00:19:35.720 --> 00:19:38.720]   come to you and say, good, now you have to match against, you
[00:19:38.720 --> 00:19:42.720]   know, pictures of Tiananmen Square and, you know, thing--
[00:19:42.720 --> 00:19:44.720]   Yeah, I think man.
[00:19:44.720 --> 00:19:46.720]   The problem is that it may be too late now.
[00:19:46.720 --> 00:19:48.720]   Like I think that Apple may have-- They've announced the
[00:19:48.720 --> 00:19:49.720]   capability.
[00:19:49.720 --> 00:19:52.720]   Yeah, and even if they said at this point, they're not going to
[00:19:52.720 --> 00:19:54.720]   do it, they now-- we now know they can do it.
[00:19:54.720 --> 00:19:56.720]   So those countries are going to come to them whether they don't
[00:19:56.720 --> 00:19:57.720]   or do.
[00:19:57.720 --> 00:19:58.720]   Yeah.
[00:19:58.720 --> 00:20:02.720]   I mean, I think that I feel like this is probably Apple trying
[00:20:02.720 --> 00:20:03.720]   to head off.
[00:20:03.720 --> 00:20:06.720]   This absolute-- like you can't get into the phone.
[00:20:06.720 --> 00:20:08.720]   You know, the soft point of that is always--
[00:20:08.720 --> 00:20:09.720]   Yeah, that's the question.
[00:20:09.720 --> 00:20:10.720]   Why do they do this now?
[00:20:10.720 --> 00:20:14.720]   I think it's the soft point for law enforcement that wants to get
[00:20:14.720 --> 00:20:18.720]   into your phone for a lot of reasons is always this subject,
[00:20:18.720 --> 00:20:22.720]   you know, of top pornography because it's a soft point because
[00:20:22.720 --> 00:20:25.720]   it's indefensible, you know, like it's a horrible thing and it needs
[00:20:25.720 --> 00:20:28.720]   to-- you know, and we have to do what we need to do to make that
[00:20:28.720 --> 00:20:30.720]   go away.
[00:20:30.720 --> 00:20:33.720]   So-- but the problem is because it's so indefensible, they use it
[00:20:33.720 --> 00:20:34.720]   all the time on everyone.
[00:20:34.720 --> 00:20:36.720]   Well, think about child pornography.
[00:20:36.720 --> 00:20:41.720]   Like, that's just what the FBI-- what everyone uses to pry things
[00:20:41.720 --> 00:20:44.720]   open for a variety of other issues as well.
[00:20:44.720 --> 00:20:49.720]   And so I think that Apple may be trying to head that off,
[00:20:49.720 --> 00:20:52.720]   that argument, especially as they go into, you know, a variety of
[00:20:52.720 --> 00:20:55.720]   hearings and so on and so forth in the fall.
[00:20:55.720 --> 00:20:59.720]   And so I can see why they would do that, but I think it's just a
[00:20:59.720 --> 00:21:03.720]   stunningly bad idea.
[00:21:03.720 --> 00:21:06.720]   I mean, because they just opened up-- they just opened up a
[00:21:06.720 --> 00:21:08.720]  -- like, there was a-- like, we don't know how to do this,
[00:21:08.720 --> 00:21:11.720]   we can't do it, we're going to continue to close things off
[00:21:11.720 --> 00:21:13.720]   and make it impossible to get in.
[00:21:13.720 --> 00:21:15.720]   And then they suddenly went the other direction.
[00:21:15.720 --> 00:21:18.720]   And I think it's-- you know, for other people, for Google or other--
[00:21:18.720 --> 00:21:20.720]   we don't expect to have any privacy.
[00:21:20.720 --> 00:21:22.720]   We shouldn't expect that any privacy.
[00:21:22.720 --> 00:21:24.720]   Well, ironically, you might have more privacy now with an
[00:21:24.720 --> 00:21:27.720]   Android phone than you do with an Apple phone.
[00:21:27.720 --> 00:21:30.720]   And that's the fundamental thing, is that Apple had--
[00:21:30.720 --> 00:21:33.720]   the problem for Apple is not what they're doing, it's that it
[00:21:33.720 --> 00:21:35.720]   just goes-- it's so hard to separate it from the marketing
[00:21:35.720 --> 00:21:38.720]   that they already have been doing for so long.
[00:21:38.720 --> 00:21:40.720]   And I think that's the real complexity for them.
[00:21:40.720 --> 00:21:43.720]   In this letter, an open letter against Apple against Apple's
[00:21:43.720 --> 00:21:47.720]   privacy-invasive content-scanning technology, which has
[00:21:47.720 --> 00:21:51.720]   been about 20,000 of signatures now, this is bold in the first
[00:21:51.720 --> 00:21:52.720]   paragraph.
[00:21:52.720 --> 00:21:56.720]   Apple's proposal introduces a backdoor that threatens to
[00:21:56.720 --> 00:22:00.720]   undermine fundamental privacy protections for all Apple users of
[00:22:00.720 --> 00:22:01.720]   Apple products.
[00:22:01.720 --> 00:22:05.720]   Is that a fair characterization, Renee?
[00:22:05.720 --> 00:22:07.720]   So I can give you-- well, I'll give you Apple's answer,
[00:22:07.720 --> 00:22:10.720]   then I'll give you my answer, because I think both are important.
[00:22:10.720 --> 00:22:12.720]   I always like to look at the company's answer because then I can
[00:22:12.720 --> 00:22:14.720]   see whether it's true or not.
[00:22:14.720 --> 00:22:17.720]   Apple's answer to this, I think, would be they can no longer abide
[00:22:17.720 --> 00:22:19.720]   having the CSAM material on their servers.
[00:22:19.720 --> 00:22:22.720]   But because of their previous-- on their current stance on privacy,
[00:22:22.720 --> 00:22:25.720]   they just refuse to do server-side scans.
[00:22:25.720 --> 00:22:27.720]   They don't want to look at everybody's images on the cloud.
[00:22:27.720 --> 00:22:30.720]   And why now, I think, is a twofold answer.
[00:22:30.720 --> 00:22:33.720]   One is they've architected the technology that they believe
[00:22:33.720 --> 00:22:36.720]   allows them to do, and they really do believe this in a more
[00:22:36.720 --> 00:22:37.720]   private way.
[00:22:37.720 --> 00:22:38.720]   Like, they see anything on device.
[00:22:38.720 --> 00:22:40.720]   And that's why I think there's a big disconnect.
[00:22:40.720 --> 00:22:43.720]   They see anything on device as being private, where we see it
[00:22:43.720 --> 00:22:45.720]   being on device being private if it's done for us.
[00:22:45.720 --> 00:22:47.720]   But when it's being done for somebody else, we see it as
[00:22:47.720 --> 00:22:48.720]   incredibly intrusive.
[00:22:48.720 --> 00:22:51.720]   And I think that's a mental disconnect there.
[00:22:51.720 --> 00:22:54.720]   But they believe that this is a more privacy-centric way of doing
[00:22:54.720 --> 00:22:55.720]   it.
[00:22:55.720 --> 00:22:56.720]   And there are a bunch of--
[00:22:56.720 --> 00:22:57.720]   Because, by the way, they're presumably--
[00:22:57.720 --> 00:23:00.720]   They're presumably scanning your device for viruses, your email
[00:23:00.720 --> 00:23:01.720]   being spanned--
[00:23:01.720 --> 00:23:02.720]   And also for DRM.
[00:23:02.720 --> 00:23:05.720]   Like, you can't take a screenshot of a Hollywood movie on your
[00:23:05.720 --> 00:23:06.720]   iPhone.
[00:23:06.720 --> 00:23:08.720]   On my iPhone, I can't tell you how angry that makes me that I
[00:23:08.720 --> 00:23:10.720]   can't take-- it's nothing compared to this, obviously.
[00:23:10.720 --> 00:23:13.720]   But a simple fact that I can't take a screenshot of a movie.
[00:23:13.720 --> 00:23:15.720]   But I'm getting-- the other thing is, there's a bunch of laws.
[00:23:15.720 --> 00:23:16.720]   Canada has them.
[00:23:16.720 --> 00:23:17.720]   The UK has them.
[00:23:17.720 --> 00:23:20.720]   The EU is proposing them, where there's going to be minimal
[00:23:20.720 --> 00:23:25.720]   response time and maximum fines for this kind of stuff and also
[00:23:25.720 --> 00:23:27.720]   for some copyright material.
[00:23:27.720 --> 00:23:30.720]   And Apple's not deploying it internationally yet, but their
[00:23:30.720 --> 00:23:33.720]   legal teams are absolutely looking at every company, what the
[00:23:33.720 --> 00:23:34.720]   obligations are going to be there.
[00:23:34.720 --> 00:23:35.720]   Yeah.
[00:23:35.720 --> 00:23:36.720]   So--
[00:23:36.720 --> 00:23:39.720]   And by the way, I should have said this right at the beginning.
[00:23:39.720 --> 00:23:44.720]   Nobody on this panel, nobody in their right mind, is for protecting
[00:23:44.720 --> 00:23:47.720]   child pornographers or CSAM material.
[00:23:47.720 --> 00:23:49.720]   That's not the debate at this point.
[00:23:49.720 --> 00:23:50.720]   And I don't think anybody--
[00:23:50.720 --> 00:23:51.720]   Or do we hate privacy?
[00:23:51.720 --> 00:23:52.720]   Yeah.
[00:23:52.720 --> 00:23:56.720]   You can have a discussion about this without approving of
[00:23:56.720 --> 00:23:58.720]   child endangerment.
[00:23:58.720 --> 00:24:00.720]   And the other thing I'll say is that Apple's response to the
[00:24:00.720 --> 00:24:03.720]   back door is they will say emphatically that it is not one
[00:24:03.720 --> 00:24:05.720]   that it was architected to not be one.
[00:24:05.720 --> 00:24:08.720]   They understand that governments are going to see that it's one
[00:24:08.720 --> 00:24:10.720]   just like a lot of people are seeing that it's one.
[00:24:10.720 --> 00:24:12.720]   And it might increase the pressure, but they say that pressure
[00:24:12.720 --> 00:24:13.720]   has always been there.
[00:24:13.720 --> 00:24:15.720]   That pressure is there last week.
[00:24:15.720 --> 00:24:16.720]   It'll be there next week.
[00:24:16.720 --> 00:24:19.720]   And they will go and as often as they have to explain an
[00:24:19.720 --> 00:24:23.720]   excruciating detail why it's not a back door and why they can't do
[00:24:23.720 --> 00:24:25.720]   anything more with it than what they said they can do.
[00:24:25.720 --> 00:24:26.720]   Yeah.
[00:24:26.720 --> 00:24:31.720]   This is a piece from rentafounder.com.
[00:24:31.720 --> 00:24:37.720]   Olivier is a computer scientist who does perceptual hashing
[00:24:37.720 --> 00:24:41.720]   and is an expert in forensic perceptual hashing.
[00:24:41.720 --> 00:24:48.720]   One of the points he brings up is Apple's claim of a trillion,
[00:24:48.720 --> 00:24:52.720]   one in a trillion is on the face of it absurd.
[00:24:52.720 --> 00:24:57.720]   It's-- you know, it's-- that's PR, not fact.
[00:24:57.720 --> 00:24:58.720]   We don't know what--
[00:24:58.720 --> 00:24:59.720]   So that's being misunderstood too.
[00:24:59.720 --> 00:25:01.720]   It's not based on the perceptual hashing.
[00:25:01.720 --> 00:25:03.720]   That's based on the entire process, including the human
[00:25:03.720 --> 00:25:04.720]   review.
[00:25:04.720 --> 00:25:05.720]   Yeah, and that's why they're doing the fact--
[00:25:05.720 --> 00:25:07.720]   The threshold of the safety, the review.
[00:25:07.720 --> 00:25:08.720]   Yeah.
[00:25:08.720 --> 00:25:12.220]   That's what it's still-- it's still, obviously, a made up
[00:25:12.220 --> 00:25:12.720]   misleading.
[00:25:12.720 --> 00:25:14.720]   No one can know what that number is.
[00:25:14.720 --> 00:25:17.720]   If people are misunderstanding it, it's because Apple, I think,
[00:25:17.720 --> 00:25:22.720]   specifically chose to pick to a methodology that people would
[00:25:22.720 --> 00:25:25.720]   not really-- not really understand to begin with.
[00:25:25.720 --> 00:25:26.720]   But that's-- that's totally wrong.
[00:25:26.720 --> 00:25:27.720]   And I understand.
[00:25:27.720 --> 00:25:28.720]   Apple's saying, look, we're doing everything.
[00:25:28.720 --> 00:25:31.720]   But to say it's one in a trillion is-- is-- is--
[00:25:31.720 --> 00:25:33.720]   It's a-- it's one is a cajillion.
[00:25:33.720 --> 00:25:35.720]   It's-- it's not a reasonable thing to say.
[00:25:35.720 --> 00:25:38.720]   So let's-- let's say Apple, another mistake.
[00:25:38.720 --> 00:25:41.720]   Oh, and also, if-- like, I just really quickly-- I also want
[00:25:41.720 --> 00:25:43.720]   to point out that, like, I've spent the last three days trying
[00:25:43.720 --> 00:25:45.720]   to make sure that all the technology has explained as
[00:25:45.720 --> 00:25:46.720]   accurately as possible.
[00:25:46.720 --> 00:25:48.720]   But I-- like, you can just hate this.
[00:25:48.720 --> 00:25:49.720]   Like, it is totally fine.
[00:25:49.720 --> 00:25:51.720]   If the technology could be the best thing in the world,
[00:25:51.720 --> 00:25:52.720]   could be bulletproof.
[00:25:52.720 --> 00:25:54.720]   There could be zero issues with it at all.
[00:25:54.720 --> 00:25:56.720]   And you can still absolutely legitimately think this is the
[00:25:56.720 --> 00:25:57.720]   worst idea ever.
[00:25:57.720 --> 00:25:58.720]   Yeah.
[00:25:58.720 --> 00:26:00.720]   So that's one of the-- if I-- if I'm like explaining technology,
[00:26:00.720 --> 00:26:02.720]   it's not because I agree with this ethically.
[00:26:02.720 --> 00:26:05.720]   So, no, we want everybody-- that's-- part of the problem was,
[00:26:05.720 --> 00:26:07.720]   everybody rushed to judgment.
[00:26:07.720 --> 00:26:09.720]   Apple didn't do a good job communicating it.
[00:26:09.720 --> 00:26:11.720]   There was some-- there were some misunderstandings.
[00:26:11.720 --> 00:26:12.720]   I think John Gruber--
[00:26:12.720 --> 00:26:14.720]   And some fear mongering with the technology.
[00:26:14.720 --> 00:26:15.720]   Fear mongering.
[00:26:15.720 --> 00:26:17.720]   But John Gruber, I think, did a good job of describing it
[00:26:17.720 --> 00:26:20.720]   and pointing out that people like Rita Elbergotti
[00:26:20.720 --> 00:26:23.720]   and The Washington Post had misstated what Apple was doing.
[00:26:23.720 --> 00:26:26.720]   I think now, after, you know, we've had time to reflect,
[00:26:26.720 --> 00:26:30.720]   I think it's important that we explain what this technology is.
[00:26:30.720 --> 00:26:34.720]   And then we can think about, well, what are the implications of it?
[00:26:34.720 --> 00:26:37.720]   I argue against what it is, not what you worried that it was
[00:26:37.720 --> 00:26:38.720]   going to be.
[00:26:38.720 --> 00:26:39.720]   Right.
[00:26:39.720 --> 00:26:43.720]   Ben Thompson, I think, on Stretecry makes the point I would
[00:26:43.720 --> 00:26:48.720]   probably agree with most, which is, Apple should absolutely have
[00:26:48.720 --> 00:26:52.720]   done this with iCloud as pretty much everybody else has done.
[00:26:52.720 --> 00:26:55.720]   Apple's mistake was to extend it to the phone.
[00:26:55.720 --> 00:26:56.720]   And I agree.
[00:26:56.720 --> 00:26:59.720]   I-- I think that-- I don't think any of this would have gone
[00:26:59.720 --> 00:27:00.720]   anywhere.
[00:27:00.720 --> 00:27:02.720]   It would have been iCloud, because they've been-- they let law
[00:27:02.720 --> 00:27:04.720]   enforcement agencies in iCloud all the time.
[00:27:04.720 --> 00:27:06.720]   We know that iCloud's not secure.
[00:27:06.720 --> 00:27:07.720]   Right.
[00:27:07.720 --> 00:27:09.720]   They would have gotten headlines anyway, but I don't think it
[00:27:09.720 --> 00:27:10.720]   would have been the same.
[00:27:10.720 --> 00:27:12.720]   And some of-- some of-- some of speculate that maybe that's
[00:27:12.720 --> 00:27:16.720]   because Apple was about to do fully end-to-end encrypted iCloud.
[00:27:16.720 --> 00:27:20.720]   And in order to forestall the objections from police to that,
[00:27:20.720 --> 00:27:22.720]   they introduced the CSAM technology.
[00:27:22.720 --> 00:27:23.720]   Yeah, I don't know.
[00:27:23.720 --> 00:27:27.720]   Yeah, and the contact recovery system, which they-- the reason
[00:27:27.720 --> 00:27:29.720]   they didn't do that, people say it's because they didn't do
[00:27:29.720 --> 00:27:32.720]   that before because people lost access to their data.
[00:27:32.720 --> 00:27:33.720]   And that was terrible for Apple.
[00:27:33.720 --> 00:27:33.720]   Yeah.
[00:27:33.720 --> 00:27:34.720]   They had so many reports of that.
[00:27:34.720 --> 00:27:35.720]   We've talked about that.
[00:27:35.720 --> 00:27:36.720]   So they stopped.
[00:27:36.720 --> 00:27:38.720]   But that will allow this new thing with iOS 15 will allow them
[00:27:38.720 --> 00:27:41.720]   to recover accounts because you can suggest the contact.
[00:27:41.720 --> 00:27:42.720]   Right.
[00:27:42.720 --> 00:27:44.720]   There's two things I would like to see with this.
[00:27:44.720 --> 00:27:46.720]   Like if I-- if I was in charge of this, if I got my wish list,
[00:27:46.720 --> 00:27:50.720]   I would make-- I would switch the communication protections to
[00:27:50.720 --> 00:27:52.720]   not make a notification at all, but to do a block instead,
[00:27:52.720 --> 00:27:56.720]   which I think protects the chances of-- of outing and also
[00:27:56.720 --> 00:28:00.720]   is in line with how the content parental things happen anyway.
[00:28:00.720 --> 00:28:02.720]   And I would also move the stuff off device and into a relay
[00:28:02.720 --> 00:28:05.720]   server the way private relay works because Apple want zero
[00:28:05.720 --> 00:28:06.720]   knowledge.
[00:28:06.720 --> 00:28:07.720]   That's fine.
[00:28:07.720 --> 00:28:11.720]   But if they could do the hash matching on a separate relay
[00:28:11.720 --> 00:28:14.720]   server, that way we would not have it on our devices and Apple
[00:28:14.720 --> 00:28:16.720]   would not have full knowledge of the system.
[00:28:16.720 --> 00:28:18.720]   And I think in that way, everybody wins.
[00:28:18.720 --> 00:28:19.720]   I'm not a privacy engineer.
[00:28:19.720 --> 00:28:21.720]   I have no responsibility here whatsoever.
[00:28:21.720 --> 00:28:22.720]   But if I had my dr--
[00:28:22.720 --> 00:28:25.720]   There are potential harms, particularly to that.
[00:28:25.720 --> 00:28:29.720]   A separate kind of scanning that Apple is doing, looking for
[00:28:29.720 --> 00:28:32.720]   pornographic images on kids' phones.
[00:28:32.720 --> 00:28:35.720]   Kendra Albert, who's a lawyer at the Harvard Law School's
[00:28:35.720 --> 00:28:39.720]   Cyber Law Clinic, says that these child protection features
[00:28:39.720 --> 00:28:42.720]   are going to get queer kids kicked out of their homes beaten or
[00:28:42.720 --> 00:28:43.720]   worse.
[00:28:43.720 --> 00:28:46.720]   She says, "I just know, calling it now, that these machine
[00:28:46.720 --> 00:28:49.720]   learning algorithms are going to flag transition photos, for
[00:28:49.720 --> 00:28:50.720]   instance."
[00:28:50.720 --> 00:28:53.720]   And that's going to be a real harm to kids in transition.
[00:28:53.720 --> 00:28:56.720]   And I will make a similar statement on Twitter.
[00:28:56.720 --> 00:28:57.720]   Yeah.
[00:28:57.720 --> 00:28:59.720]   Alex, you started--
[00:28:59.720 --> 00:29:02.720]   I want to give you some time to tell us how you feel.
[00:29:02.720 --> 00:29:05.720]   Well, no, I just think that the cloud would have been fine.
[00:29:05.720 --> 00:29:07.720]   I think even as a parent, I don't--
[00:29:07.720 --> 00:29:08.720]   Yeah, absolutely.
[00:29:08.720 --> 00:29:11.720]   Even as a parent, I am uncomfortable with the idea that
[00:29:11.720 --> 00:29:13.720]   it's scanning through my kid's phone.
[00:29:13.720 --> 00:29:14.720]   Extremely, yes.
[00:29:14.720 --> 00:29:18.720]   So the thing is, is that I have kids that are 12 and 13 years
[00:29:18.720 --> 00:29:19.720]   old.
[00:29:19.720 --> 00:29:21.720]   They are the target of what this would be.
[00:29:21.720 --> 00:29:23.720]   I mean, they're at the time when you'd have to worry about it.
[00:29:23.720 --> 00:29:26.720]   And I would still rather do it in many other ways.
[00:29:26.720 --> 00:29:30.720]   You know, we already are pretty careful about what they have
[00:29:30.720 --> 00:29:34.720]   access to at home, where they can look at it, all those things.
[00:29:34.720 --> 00:29:35.720]   So we think about those things.
[00:29:35.720 --> 00:29:38.720]   But I am really uncomfortable with the idea that I have, you
[00:29:38.720 --> 00:29:40.720]   know, that we've opened up a window.
[00:29:40.720 --> 00:29:43.720]   And for me, I don't think it really affects me that much.
[00:29:43.720 --> 00:29:44.720]   I mean, I never--
[00:29:44.720 --> 00:29:46.720]   I don't have anything on it that would--
[00:29:46.720 --> 00:29:47.720]   that it would scan.
[00:29:47.720 --> 00:29:50.720]   I don't have anything-- even if they expanded it to all the
[00:29:50.720 --> 00:29:52.720]   threats that we're afraid that they're going to expand it to.
[00:29:52.720 --> 00:29:54.720]   I doubt I would show up in the radar.
[00:29:54.720 --> 00:29:58.720]   And so it's not that I think that it'll affect me or now or in
[00:29:58.720 --> 00:30:02.720]   the future, but I just think that it really goes against what,
[00:30:02.720 --> 00:30:05.720]   you know, Apple has held up until this moment.
[00:30:05.720 --> 00:30:07.720]   The iPhone is the one safe place.
[00:30:07.720 --> 00:30:10.720]   You know, like, and we've had this come up before where, you
[00:30:10.720 --> 00:30:14.720]   know, like, we'll hand off iCloud data.
[00:30:14.720 --> 00:30:17.720]   We'll serve it on Chinese servers, but the one place that you
[00:30:17.720 --> 00:30:19.720]   don't get to go is the phone.
[00:30:19.720 --> 00:30:22.720]   And I think that they gave that away.
[00:30:22.720 --> 00:30:24.720]   And I think that it's just a--
[00:30:24.720 --> 00:30:26.720]   and I don't think there's anything they've done about it.
[00:30:26.720 --> 00:30:28.720]   Like, I don't think that they couldn't say now because of
[00:30:28.720 --> 00:30:29.720]   pressure, we're not going to do it.
[00:30:29.720 --> 00:30:31.720]   I mean, law enforcement would be all over them.
[00:30:31.720 --> 00:30:34.720]   And now this may be a long standing thing that they've been
[00:30:34.720 --> 00:30:37.720]   interacting with law enforcement over years to figure out.
[00:30:37.720 --> 00:30:40.720]   So it may not be anything they could have pulled back at any
[00:30:40.720 --> 00:30:42.720]   point in time, but I think going down this path is--
[00:30:42.720 --> 00:30:46.720]   and I'm almost certain that they're doing it to deflect, you
[00:30:46.720 --> 00:30:50.720]   know, the constant pressure to open up the phones.
[00:30:50.720 --> 00:30:52.720]   So I think that the reason that they're doing this is--
[00:30:52.720 --> 00:30:54.720]   I mean, they'll say that it because it's the right thing, but
[00:30:54.720 --> 00:30:57.720]   I think that primarily Apple's doing it to deflect the constant
[00:30:57.720 --> 00:31:01.720]   attack from organizations like, you know, law enforcement and
[00:31:01.720 --> 00:31:04.720]   the Five Eyes and Chinese government and the Russian
[00:31:04.720 --> 00:31:05.720]   government to get in.
[00:31:05.720 --> 00:31:07.720]   And so they're trying-- and this is the soft point.
[00:31:07.720 --> 00:31:10.720]   This is the open, you know, point in the armor to go through.
[00:31:10.720 --> 00:31:12.720]   That's a really excellent point.
[00:31:12.720 --> 00:31:15.720]   We don't know all of the information that Apple has.
[00:31:15.720 --> 00:31:18.720]   We can presume that everything we've talked about, everybody
[00:31:18.720 --> 00:31:21.720]   else has talked about over the last five days, Apple talked
[00:31:21.720 --> 00:31:23.720]   about internally before they made this announcement.
[00:31:23.720 --> 00:31:24.720]   Yeah.
[00:31:24.720 --> 00:31:26.720]   And we don't know what kind of pressure they were on.
[00:31:26.720 --> 00:31:28.720]   I mean, do you remember the one that this announcement had?
[00:31:28.720 --> 00:31:29.720]   This is about it either.
[00:31:29.720 --> 00:31:30.720]   Yeah.
[00:31:30.720 --> 00:31:32.720]   And I'm sure that this discussion started two or three years ago.
[00:31:32.720 --> 00:31:34.720]   This is not like something you build that they built over the
[00:31:34.720 --> 00:31:35.720]   summer.
[00:31:35.720 --> 00:31:36.720]   Right.
[00:31:36.720 --> 00:31:38.720]   You know, like this is something that is years in the making to
[00:31:38.720 --> 00:31:40.720]   build something that's this vast.
[00:31:40.720 --> 00:31:44.720]   So I don't think that this is a-- there's no knee jerk here.
[00:31:44.720 --> 00:31:48.720]   This is a-- and again, I think I wouldn't be surprised if we
[00:31:48.720 --> 00:31:51.720]   found out that this started happening around the San Bernardino
[00:31:51.720 --> 00:31:52.720]   argument.
[00:31:52.720 --> 00:31:53.720]   The conversation.
[00:31:53.720 --> 00:31:54.720]   The conversation.
[00:31:54.720 --> 00:31:57.720]   And this is an evolution from that process.
[00:31:57.720 --> 00:32:02.720]   So I think that they're doing it to-- I actually think they're
[00:32:02.720 --> 00:32:05.720]   doing it to protect the phone from further incursions from law
[00:32:05.720 --> 00:32:06.720]   enforcement.
[00:32:06.720 --> 00:32:11.720]   But I think that it just opens up just such a wide open gaping
[00:32:11.720 --> 00:32:13.720]   hole that I just don't know.
[00:32:13.720 --> 00:32:16.720]   And as I said, I mean, they're constantly under pressure to
[00:32:16.720 --> 00:32:17.720]   continue to open it.
[00:32:17.720 --> 00:32:20.720]   And I just think it'll be harder and harder to do that.
[00:32:20.720 --> 00:32:21.720]   Electronic front tear found.
[00:32:21.720 --> 00:32:24.720]   In fact, they did say specifically about-- they tried to
[00:32:24.720 --> 00:32:27.720]   address this issue by saying-- and this is a quote, "Let us
[00:32:27.720 --> 00:32:28.720]   be clear.
[00:32:28.720 --> 00:32:31.720]   This technology is limited to detecting CSAM stored at iCloud
[00:32:31.720 --> 00:32:34.720]   and we will not exceed any government's request to expand
[00:32:34.720 --> 00:32:35.720]   it."
[00:32:35.720 --> 00:32:36.720]   That would have been perfect.
[00:32:36.720 --> 00:32:37.720]   Yeah.
[00:32:37.720 --> 00:32:39.720]   Which is-- which is-- and it is in the fact, however, that doesn't
[00:32:39.720 --> 00:32:42.720]   exclude them saying-- that basically do a command C, command C,
[00:32:42.720 --> 00:32:46.720]   command V, creating a different version of the system that
[00:32:46.720 --> 00:32:50.720]   tags into a different database of hashtags of political content
[00:32:50.720 --> 00:32:51.720]   of--
[00:32:51.720 --> 00:32:54.720]   I mean, we're in a country where they told us that they only
[00:32:54.720 --> 00:32:55.720]   wanted to sell security numbers.
[00:32:55.720 --> 00:32:56.720]   They'd give us money.
[00:32:56.720 --> 00:32:58.720]   And everyone was like, you're going to use it to taxes.
[00:32:58.720 --> 00:33:00.720]   And now they don't even call it our social security number
[00:33:00.720 --> 00:33:01.720]   anymore.
[00:33:01.720 --> 00:33:02.720]   It's our tax-site number.
[00:33:02.720 --> 00:33:05.720]   So the thing is, is that what we open up things for is we can
[00:33:05.720 --> 00:33:08.720]   have those things, but it always evolves over time.
[00:33:08.720 --> 00:33:11.720]   And I think that this is going to be-- I think there's-- I
[00:33:11.720 --> 00:33:14.720]   don't know for sure, but I think that there is a relatively
[00:33:14.720 --> 00:33:17.720]   high possibility that five years from now we'll be talking
[00:33:17.720 --> 00:33:23.720]   about this week and how this was where it got popped open.
[00:33:23.720 --> 00:33:25.720]   And then there's all these other things that are happening.
[00:33:25.720 --> 00:33:26.720]   And I don't even know if it'll be in the United States.
[00:33:26.720 --> 00:33:29.720]   I think it'll be in other countries where people's privacy
[00:33:29.720 --> 00:33:35.720]   is more important to them than here in the sense that it's a
[00:33:35.720 --> 00:33:39.720]   life and death situation that's going to be more problematic.
[00:33:39.720 --> 00:33:40.720]   To that point, this is what the--
[00:33:40.720 --> 00:33:41.720]   Hold on a sec.
[00:33:41.720 --> 00:33:43.720]   To that point, this is what EFF said.
[00:33:43.720 --> 00:33:46.720]   Take the example of India where recently passed rules include
[00:33:46.720 --> 00:33:50.720]   dangerous requirements for platforms to identify the origins
[00:33:50.720 --> 00:33:52.720]   of messages and pre-screen content.
[00:33:52.720 --> 00:33:56.720]   New laws in Ethiopia requiring content takedowns of, quote,
[00:33:56.720 --> 00:34:00.720]   misinformation in 24 hours may apply to messaging services.
[00:34:00.720 --> 00:34:03.720]   And many other countries, often those with authoritarian
[00:34:03.720 --> 00:34:05.720]   governments, have passed similar laws.
[00:34:05.720 --> 00:34:09.720]   Apple's changes would enable such screening takedown enable
[00:34:09.720 --> 00:34:12.720]   such screening takedown and reporting in its end to end
[00:34:12.720 --> 00:34:13.720]   messaging.
[00:34:13.720 --> 00:34:15.720]   The abuse cases are easy to imagine.
[00:34:15.720 --> 00:34:18.720]   Governments that outlaw homosexuality might require the
[00:34:18.720 --> 00:34:23.720]   classifier to be trained to restrict apparent LGBTQ+ content
[00:34:23.720 --> 00:34:26.720]   or an authoritarian regime might demand the classifier be able
[00:34:26.720 --> 00:34:30.720]   to spot popular satirical images or protest flyers.
[00:34:30.720 --> 00:34:32.720]   So that's the slippery slope argument.
[00:34:32.720 --> 00:34:35.720]   But I have to say, I feel like we're already sliding down it
[00:34:35.720 --> 00:34:36.720]   pretty quick here.
[00:34:36.720 --> 00:34:39.720]   Go ahead then.
[00:34:39.720 --> 00:34:42.720]   >> In addition to what Andy was explaining, I think it's an
[00:34:42.720 --> 00:34:45.720]   important technical one, is that-- and Apple will say this is
[00:34:45.720 --> 00:34:47.720]   part of the defense system they built into this, is that
[00:34:47.720 --> 00:34:48.720]   there's only one iOS.
[00:34:48.720 --> 00:34:51.720]   Like, there's no separate version of iOS for any individual or
[00:34:51.720 --> 00:34:52.720]   any jurisdiction.
[00:34:52.720 --> 00:34:55.720]   It's one image that gets downloaded on every phone everywhere
[00:34:55.720 --> 00:34:58.720]   and that adding additional images, like if somebody hacked
[00:34:58.720 --> 00:35:01.720]   into CSAM or if Apple was forced by a company under a security
[00:35:01.720 --> 00:35:04.720]   letter to install another database or to add to the
[00:35:04.720 --> 00:35:07.720]   database, that would be on every iPhone everywhere and it would
[00:35:07.720 --> 00:35:10.720]   pop up to an American screener, the same way it would pop up
[00:35:10.720 --> 00:35:12.720]   to a Chinese screener.
[00:35:12.720 --> 00:35:14.720]   And that makes it not only unlikely, like in America they
[00:35:14.720 --> 00:35:16.720]   wouldn't really tolerate Tiananmen Square images.
[00:35:16.720 --> 00:35:19.720]   The EFF gets a little bit wrong that Apple can't train this on
[00:35:19.720 --> 00:35:21.720]   anything, it's a hash matching.
[00:35:21.720 --> 00:35:23.720]   There's no machine learning involved here.
[00:35:23.720 --> 00:35:24.720]   >> Wait a minute.
[00:35:24.720 --> 00:35:27.720]   That's for the NICMA cache.
[00:35:27.720 --> 00:35:32.720]   But the watching of messages can be.
[00:35:32.720 --> 00:35:34.720]   >> That's a hash that has no reporting.
[00:35:34.720 --> 00:35:36.720]   That has no reporting mechanism.
[00:35:36.720 --> 00:35:39.720]   >> Well, as implemented today has no reporting mechanism.
[00:35:39.720 --> 00:35:43.720]   But if you open it, say, hey, you're doing it, now you have to
[00:35:43.720 --> 00:35:44.720]   tell us to.
[00:35:44.720 --> 00:35:45.720]   >> Yeah.
[00:35:45.720 --> 00:35:47.720]   >> Their defense to that is that could have happened a week ago.
[00:35:47.720 --> 00:35:49.720]   Like, the system, like they could be put under that pressure at
[00:35:49.720 --> 00:35:50.720]   any time, it's like an econormal.
[00:35:50.720 --> 00:35:53.720]   >> They could have been told you need to have a system like
[00:35:53.720 --> 00:35:54.720]   that.
[00:35:54.720 --> 00:35:55.720]   >> Yes.
[00:35:55.720 --> 00:35:57.720]   >> Apple's response should be it's end to end encrypted.
[00:35:57.720 --> 00:35:59.720]   We can't and leave it at that.
[00:35:59.720 --> 00:36:02.720]   Now they've opened the Pandora's box by saying, oh, by the way,
[00:36:02.720 --> 00:36:05.720]   we're going to do this for this particular instance of people
[00:36:05.720 --> 00:36:06.720]   under 18.
[00:36:06.720 --> 00:36:07.720]   >> And so you can.
[00:36:07.720 --> 00:36:09.720]   >> I'm not saying I agree with this.
[00:36:09.720 --> 00:36:11.720]   >> I'm not saying I agree with this one.
[00:36:11.720 --> 00:36:12.720]   >> I agree with this one.
[00:36:12.720 --> 00:36:14.720]   >> I'm not defending this.
[00:36:14.720 --> 00:36:15.720]   >> Yes.
[00:36:15.720 --> 00:36:16.720]   >> And I'm not defending this.
[00:36:16.720 --> 00:36:18.720]   But Apple says that this, like, that communications thing popping
[00:36:18.720 --> 00:36:21.720]   up a warning is equivalent to popping up a warning saying this
[00:36:21.720 --> 00:36:22.720]   file is too large.
[00:36:22.720 --> 00:36:25.720]   You can't send this over iMessage and putting a warning up before
[00:36:25.720 --> 00:36:28.720]   you send it is equivalent to sticking a sticker on it.
[00:36:28.720 --> 00:36:30.720]   >> They understand the governments might see this one way,
[00:36:30.720 --> 00:36:33.720]   but they think technologically it's not a sea change in any way.
[00:36:33.720 --> 00:36:36.720]   >> Well, I would disagree, Renee, because you can look at the
[00:36:36.720 --> 00:36:39.720]   file size without looking at the file content.
[00:36:39.720 --> 00:36:43.720]   Do you think Apple's looking at our file content now?
[00:36:43.720 --> 00:36:45.720]   >> Well, the photos app they are because they tell you if it's
[00:36:45.720 --> 00:36:48.720]   a cat or a dog or they suggest photo effects for it.
[00:36:48.720 --> 00:36:49.720]   >> That's true.
[00:36:49.720 --> 00:36:50.720]   And that's done on camera, right?
[00:36:50.720 --> 00:36:52.720]   >> I mean, on a device.
[00:36:52.720 --> 00:36:53.720]   >> So, yeah, I guess you're right.
[00:36:53.720 --> 00:36:56.720]   Apple's already said we know how to do this and Ethiopia could have
[00:36:56.720 --> 00:36:59.720]   said, okay, instead of a cat, we want --
[00:36:59.720 --> 00:37:02.720]   >> If in live text you see this line of text, please alert us.
[00:37:02.720 --> 00:37:03.720]   >> Yeah.
[00:37:03.720 --> 00:37:04.720]   Okay, so that's a good point.
[00:37:04.720 --> 00:37:07.720]   They've already opened that door.
[00:37:07.720 --> 00:37:09.720]   >> Just a quickly address.
[00:37:09.720 --> 00:37:11.720]   I think Renee might have misunderstood what I was saying.
[00:37:11.720 --> 00:37:15.720]   I know there are protections in place that they can't -- a
[00:37:15.720 --> 00:37:19.720]   government or an outside bad actor can't simply add content to
[00:37:19.720 --> 00:37:20.720]   this database.
[00:37:20.720 --> 00:37:21.720]   It is very tightly locked down.
[00:37:21.720 --> 00:37:25.720]   However, if another government hours are so close,
[00:37:25.720 --> 00:37:27.720]   this is a great technology.
[00:37:27.720 --> 00:37:30.720]   We should insist that they do basically create a second version
[00:37:30.720 --> 00:37:34.720]   of this black box that taps into this other database of file
[00:37:34.720 --> 00:37:37.720]   hashes, image hashes that we provide for them that contains
[00:37:37.720 --> 00:37:40.720]   political content that we want to keep an eye on, religious
[00:37:40.720 --> 00:37:43.720]   content, we want to keep an eye on, or any other content that we
[00:37:43.720 --> 00:37:44.720]   want to keep an eye on.
[00:37:44.720 --> 00:37:47.720]   So this box, as it's being installed, is safe from that sort
[00:37:47.720 --> 00:37:48.720]   of thing.
[00:37:48.720 --> 00:37:51.720]   But now that -- as kind of like what Alex has said, now that
[00:37:51.720 --> 00:37:56.720]   Apple has said, hey, look, we've got this really, really slick
[00:37:56.720 --> 00:38:01.720]   and secure system that will on device check files -- check
[00:38:01.720 --> 00:38:05.720]   image files on this device to see if it contains content that
[00:38:05.720 --> 00:38:09.720]   an outside party deems objectionable outside of Apple.
[00:38:09.720 --> 00:38:10.720]   Great.
[00:38:10.720 --> 00:38:11.720]   Build us one of those.
[00:38:11.720 --> 00:38:14.720]   You can keep the one that you built for your child abuse
[00:38:14.720 --> 00:38:18.720]   images, but build us one so that any time -- so we can get a
[00:38:18.720 --> 00:38:22.720]   lock on those Winnie the Pooh images of our fearless leader
[00:38:22.720 --> 00:38:24.720]   that keep being posted on Weibo.
[00:38:24.720 --> 00:38:27.720]   Well, and I think that the Chinese government doesn't care
[00:38:27.720 --> 00:38:29.720]   whether -- they don't need you to focus on anyone.
[00:38:29.720 --> 00:38:31.720]   They would love to know where propaganda images show up
[00:38:31.720 --> 00:38:33.720]   anywhere in the world.
[00:38:33.720 --> 00:38:39.720]   And so the thing is that those getting that information,
[00:38:39.720 --> 00:38:43.720]   they could be asking Apple to do those kinds of things.
[00:38:43.720 --> 00:38:45.720]   And that's the thing that I think is going to be really
[00:38:45.720 --> 00:38:46.720]   complicated.
[00:38:46.720 --> 00:38:49.720]   And just to -- I just feel like a briar patch, you know, that's
[00:38:49.720 --> 00:38:51.720]   going to be really difficult to get out of.
[00:38:51.720 --> 00:38:54.720]   But I think here is why --
[00:38:54.720 --> 00:38:56.720]   Exactly, wrong regardless of the technology.
[00:38:56.720 --> 00:38:59.720]   So let me -- let's -- I want to ask each of you, start with
[00:38:59.720 --> 00:39:01.720]   Renee, what should Apple do at this point?
[00:39:01.720 --> 00:39:05.720]   Yeah, I think that they should switch the reporting -- they
[00:39:05.720 --> 00:39:07.720]   should switch the parental notification to a parental
[00:39:07.720 --> 00:39:09.720]   block so the parent doesn't have any knowledge of the specific
[00:39:09.720 --> 00:39:10.720]   photos.
[00:39:10.720 --> 00:39:11.720]   It just blocks that get from getting it.
[00:39:11.720 --> 00:39:14.720]   And I think they should move the on device matching into a
[00:39:14.720 --> 00:39:17.720]   separate relay server the way private relay works so that
[00:39:17.720 --> 00:39:18.720]   they're not on our device.
[00:39:18.720 --> 00:39:21.720]   It's like the warehouse company doesn't come to my house and
[00:39:21.720 --> 00:39:23.720]   look at the stuff before I store it at the warehouse place.
[00:39:23.720 --> 00:39:25.720]   Even if they're picking it up, they don't get to look through
[00:39:25.720 --> 00:39:27.720]   the boxes before they pick it up.
[00:39:27.720 --> 00:39:28.720]   You want to do that?
[00:39:28.720 --> 00:39:29.720]   Do that at the warehouse.
[00:39:29.720 --> 00:39:31.720]   And if Apple wants zero knowledge, put in a relay service so they
[00:39:31.720 --> 00:39:34.720]   only ever have the first layer of decryption on the relay
[00:39:34.720 --> 00:39:36.720]   server, the second layer of decryption at Apple.
[00:39:36.720 --> 00:39:39.720]   And then I think they get what they want and the argument about
[00:39:39.720 --> 00:39:41.720]   invasiveness goes away.
[00:39:41.720 --> 00:39:44.720]   >> You agree, Andy?
[00:39:44.720 --> 00:39:45.720]   What would you recommend?
[00:39:45.720 --> 00:39:48.720]   >> I don't think Apple has made a strong case for why they have
[00:39:48.720 --> 00:39:51.720]   to do this processing on device instead of in the cloud.
[00:39:51.720 --> 00:39:54.720]   I think that the only practical reason I come up with is that
[00:39:54.720 --> 00:39:57.720]   maybe they simply don't want to have to burn up their own server
[00:39:57.720 --> 00:40:00.720]   CPU cycles doing these hash matches.
[00:40:00.720 --> 00:40:02.720]   They would much rather burn CPU cycles on the device to do
[00:40:02.720 --> 00:40:03.720]   that instead.
[00:40:03.720 --> 00:40:08.720]   We have -- this is -- the industry has done this on cloud
[00:40:08.720 --> 00:40:10.720]   servers across the industry.
[00:40:10.720 --> 00:40:12.720]   There hasn't been -- there's a president for it.
[00:40:12.720 --> 00:40:15.720]   If people have objections to this, they will not have any new
[00:40:15.720 --> 00:40:18.720]   objections to the way that Apple's doing it if they're doing
[00:40:18.720 --> 00:40:20.720]   it on the cloud.
[00:40:20.720 --> 00:40:23.720]   And I think that -- I think that Ray made a very good point
[00:40:23.720 --> 00:40:26.720]   that I think that just culturally, Apple believes that,
[00:40:26.720 --> 00:40:30.720]   hey, if I do this on device, that by then by its very nature,
[00:40:30.720 --> 00:40:34.720]   this makes it more private and safe than doing it on one of the
[00:40:34.720 --> 00:40:36.720]   servers that we ourselves own.
[00:40:36.720 --> 00:40:40.720]   And I also think that a lot of the fine details about this need
[00:40:40.720 --> 00:40:46.720]   to be -- need to be reevaluated, such as, again, keeping kids safe
[00:40:46.720 --> 00:40:49.720]   not only from predators online but from their own parents
[00:40:49.720 --> 00:40:50.720]   and their own guardians.
[00:40:50.720 --> 00:40:54.720]   I don't think that -- at minimum, I don't think that enough
[00:40:54.720 --> 00:41:00.720]   people have been satisfied that this is a safe system for children
[00:41:00.720 --> 00:41:02.720]   that are in danger in that way.
[00:41:02.720 --> 00:41:05.720]   At worst, I think that there are indeed serious flaws that
[00:41:05.720 --> 00:41:08.720]   Apple should be compelled to address.
[00:41:08.720 --> 00:41:13.720]   So this has not been done exceptionally well, I think.
[00:41:13.720 --> 00:41:15.720]   What do you think, Alex?
[00:41:15.720 --> 00:41:17.720]   What should Apple do?
[00:41:17.720 --> 00:41:19.720]   I don't think there's anything to be done.
[00:41:19.720 --> 00:41:21.720]   I think that they just stay the course at this point.
[00:41:21.720 --> 00:41:23.720]   I mean, there's not really any -- they can't pull back.
[00:41:23.720 --> 00:41:25.720]   I mean, they can't -- they're not going to be able to, you know,
[00:41:25.720 --> 00:41:27.720]   enforcement agencies and everything else.
[00:41:27.720 --> 00:41:28.720]   They've opened up a can of worms.
[00:41:28.720 --> 00:41:31.720]   They can't -- they've opened up a Pandora's box that can't be
[00:41:31.720 --> 00:41:34.720]   closed, you know, and I think that they're --
[00:41:34.720 --> 00:41:38.720]   I think that they -- I think I agree probably with Renee
[00:41:38.720 --> 00:41:40.720]   that that's what I would love to see them do.
[00:41:40.720 --> 00:41:42.720]   And I don't think they're going to.
[00:41:42.720 --> 00:41:45.720]   I think that it's now you just kind of batten down the hatch
[00:41:45.720 --> 00:41:49.720]   and, you know, just try to weather the next two or three weeks
[00:41:49.720 --> 00:41:52.720]   and hope people let it wander off.
[00:41:52.720 --> 00:41:55.720]   But I think that it just really undermines the user trust
[00:41:55.720 --> 00:41:59.720]   that they've spent so much time building, you know, around the device.
[00:41:59.720 --> 00:42:02.720]   You know, I think that's the real challenge, is how do they get
[00:42:02.720 --> 00:42:03.720]   themselves out of them?
[00:42:03.720 --> 00:42:08.720]   Do you -- with this, Alex, in -- was this change your decision
[00:42:08.720 --> 00:42:10.720]   to use an iPhone?
[00:42:10.720 --> 00:42:11.720]   No.
[00:42:11.720 --> 00:42:16.720]   Like, no, no, I'm frustrated, you know, but -- but, you know,
[00:42:16.720 --> 00:42:19.720]   I'm not going to -- what am I going to -- where am I going to go?
[00:42:19.720 --> 00:42:21.720]   And do you already -- you're already an Android user.
[00:42:21.720 --> 00:42:24.720]   Would you not use an iPhone because of this?
[00:42:24.720 --> 00:42:28.720]   No, but if this had been as bad as people had been worrying
[00:42:28.720 --> 00:42:31.720]   before, if there had been a proactive on-device scanning
[00:42:31.720 --> 00:42:35.720]   of photos on-device, if any -- any situation in which the device
[00:42:35.720 --> 00:42:39.720]   is constantly scanning for evidence that I might have committed
[00:42:39.720 --> 00:42:42.720]   to crime, that's a hard damn no.
[00:42:42.720 --> 00:42:45.720]   That is -- that is -- I would have -- there would have been --
[00:42:45.720 --> 00:42:48.720]   I might have even stopped using my iPad if that had been part
[00:42:48.720 --> 00:42:51.720]   of the rules of using it that I am under -- I am a suspect simply
[00:42:51.720 --> 00:42:54.720]   by version -- by virtue of the fact that I'm putting photos
[00:42:54.720 --> 00:42:57.720]   on this device, that's a hard no.
[00:42:57.720 --> 00:42:58.720]   But that's not the case here.
[00:42:58.720 --> 00:43:01.720]   How about you, Renee, with this changer?
[00:43:01.720 --> 00:43:04.720]   I think you're kind of -- unfortunately, you're kind of --
[00:43:04.720 --> 00:43:07.720]   You kind of have to use the iPhone.
[00:43:07.720 --> 00:43:11.720]   But I mean -- no, I walked away from Microsoft because they weren't
[00:43:11.720 --> 00:43:12.720]   serving my needs.
[00:43:12.720 --> 00:43:14.720]   I'd walk away from Apple and a heartbeat, I'd stop serving my needs.
[00:43:14.720 --> 00:43:16.720]   With this, the easy out -- it's not an easy out.
[00:43:16.720 --> 00:43:17.720]   It's a horrible out.
[00:43:17.720 --> 00:43:19.720]   But the out is like you don't enable those services, you don't have
[00:43:19.720 --> 00:43:22.720]   to be a kid of a choice, or turn off a photo library because
[00:43:22.720 --> 00:43:25.720]   that turns off the entire system at the -- at the hash generation
[00:43:25.720 --> 00:43:29.720]   level, turn off a photo library, nothing gets processed on your
[00:43:29.720 --> 00:43:30.720]   device.
[00:43:30.720 --> 00:43:33.720]   The bigger concern I have right now is that we are -- as a people,
[00:43:33.720 --> 00:43:35.720]   we are no longer like 20 years ago, we have such high brand
[00:43:35.720 --> 00:43:39.720]   affinity and such low attention span that -- and I'm not doing
[00:43:39.720 --> 00:43:42.720]   this for false equivalency or to try to like what about is
[00:43:42.720 --> 00:43:45.720]   it, but like every company has their scandal, Samsung has
[00:43:45.720 --> 00:43:47.720]   exploding phones and Sony root kits people and Lenovo does
[00:43:47.720 --> 00:43:50.720]   person in the middle attacks for Adware and Google steals
[00:43:50.720 --> 00:43:51.720]   WiFi.
[00:43:51.720 --> 00:43:53.720]   The list goes on and on and we don't -- like two weeks later,
[00:43:53.720 --> 00:43:55.720]   we don't even think about it.
[00:43:55.720 --> 00:43:58.720]   And Facebook and Cambridge Analytica and SIOBS, we don't
[00:43:58.720 --> 00:43:59.720]   even think about it anymore.
[00:43:59.720 --> 00:44:01.720]   There's no long-term consequences of doing these things.
[00:44:01.720 --> 00:44:04.720]   It becomes a two-week news cycle and then we forget about it.
[00:44:04.720 --> 00:44:07.720]   And a lot of stuff is so much -- is so important, it should
[00:44:07.720 --> 00:44:09.720]   never happen.
[00:44:09.720 --> 00:44:11.720]   And my fear is like again, in two weeks, then we'll be talking
[00:44:11.720 --> 00:44:12.720]   about it.
[00:44:12.720 --> 00:44:15.720]   >> Well, that's probably the argument for why Apple should just
[00:44:15.720 --> 00:44:18.720]   stay the course at this point because -- are they going to
[00:44:18.720 --> 00:44:19.720]   lose any business?
[00:44:19.720 --> 00:44:21.720]   >> We'll get new iPhones and we'll forget.
[00:44:21.720 --> 00:44:23.720]   >> They'll be an iPhone 13, they'll be shining and we'll
[00:44:23.720 --> 00:44:24.720]   forget.
[00:44:24.720 --> 00:44:25.720]   >> Yeah.
[00:44:25.720 --> 00:44:26.720]   >> It just makes it less clear.
[00:44:26.720 --> 00:44:28.720]   Like it's just -- and I think that that's going to be the
[00:44:28.720 --> 00:44:29.720]   hard part.
[00:44:29.720 --> 00:44:33.720]   And I think that we as -- I mean, our -- our governments are
[00:44:33.720 --> 00:44:37.720]   very afraid of us, because people are able to organize at a
[00:44:37.720 --> 00:44:40.720]   level that has never been -- in the history of mankind has
[00:44:40.720 --> 00:44:41.720]   never been possible.
[00:44:41.720 --> 00:44:43.720]   You know, and so we just have to be very careful of where
[00:44:43.720 --> 00:44:47.720]   they're taking away our ability to do that because, you know,
[00:44:47.720 --> 00:44:50.720]   a lot of this is coming from governments being very afraid
[00:44:50.720 --> 00:44:53.720]   that they're losing positive control of their population.
[00:44:53.720 --> 00:44:55.720]   You know, and so we just have to be very -- and this is all
[00:44:55.720 --> 00:44:58.720]   governments, not just the Chinese and the Russians.
[00:44:58.720 --> 00:45:02.720]   And so, you know, it's -- and because the population now can
[00:45:02.720 --> 00:45:06.720]   self-organize very, very fast, you know, and for good and bad.
[00:45:06.720 --> 00:45:08.720]   >> For good and still.
[00:45:08.720 --> 00:45:11.720]   >> Yeah, so -- but I think that -- but so governments are
[00:45:11.720 --> 00:45:13.720]   afraid of that, and I -- but I think we have to be very
[00:45:13.720 --> 00:45:16.720]   careful about how quickly this becomes something that we really
[00:45:16.720 --> 00:45:19.720]   wish hadn't happened.
[00:45:19.720 --> 00:45:21.720]   >> Yeah.
[00:45:21.720 --> 00:45:24.720]   One of the broader things that I've been thinking about over the
[00:45:24.720 --> 00:45:28.720]   weekend, the first step, the two larger clarity over my feelings
[00:45:28.720 --> 00:45:31.720]   on this issue is I do believe that as a large principle that we
[00:45:31.720 --> 00:45:35.720]   have the right to control the devices that we own, and that
[00:45:35.720 --> 00:45:38.720]   usually I speak about that in terms of if I have a phone, I
[00:45:38.720 --> 00:45:40.720]   should be able to do whatever I want with it.
[00:45:40.720 --> 00:45:42.720]   If I should be able to install whatever software I want, I
[00:45:42.720 --> 00:45:45.720]   should be able to replace the bootloader if I want to do that.
[00:45:45.720 --> 00:45:49.720]   But I also believe that applies to Apple, that they own the iCloud
[00:45:49.720 --> 00:45:50.720]   servers.
[00:45:50.720 --> 00:45:53.720]   They have the right to control whether or not this is being used
[00:45:53.720 --> 00:45:59.720]   to transact imagery and content that they feel as though they
[00:45:59.720 --> 00:46:01.720]   have a power to stop.
[00:46:01.720 --> 00:46:05.720]   And so within the -- within the limitations that this is only a
[00:46:05.720 --> 00:46:09.720]   feature that happens if I choose to put my photos onto their
[00:46:09.720 --> 00:46:14.720]   servers, that's the linchpin of my acceptance of Apple's --
[00:46:14.720 --> 00:46:18.720]   not necessarily the rightness of them doing this, but their
[00:46:18.720 --> 00:46:21.720]   ability to do this and why I have to respect that right of them
[00:46:21.720 --> 00:46:22.720]   to do it.
[00:46:22.720 --> 00:46:25.720]   Implementation is a different thing, but I will absolutely not
[00:46:25.720 --> 00:46:29.720]   say that it's not right for the owner of a server to want to
[00:46:29.720 --> 00:46:33.720]   control how that server is being used out in the world, the
[00:46:33.720 --> 00:46:37.720]   damage that's being done to people through hardware that
[00:46:37.720 --> 00:46:41.720]   they're buying, they're maintaining the connection to.
[00:46:41.720 --> 00:46:44.720]   They have that right just as I feel as though I have the right to
[00:46:44.720 --> 00:46:45.720]   do whatever I want with my phone.
[00:46:45.720 --> 00:46:49.720]   >> Yeah, I don't have any problem with a cloud server making
[00:46:49.720 --> 00:46:52.720]   sure that no stuff they don't want, whether it's child
[00:46:52.720 --> 00:46:55.720]   pornography or a copyright material is stored there.
[00:46:55.720 --> 00:46:58.720]   They're right and they should be able to do that and you have
[00:46:58.720 --> 00:46:59.720]   the right not to use them.
[00:46:59.720 --> 00:47:03.720]   Is it the case, Renee, that if I turn off iCloud photo sharing,
[00:47:03.720 --> 00:47:08.720]   all three of these initiatives stop, like even the teenage --
[00:47:08.720 --> 00:47:09.720]   >> No, they're --
[00:47:09.720 --> 00:47:11.720]   >> No, they still scan phones.
[00:47:11.720 --> 00:47:14.720]   >> No, the parent is control -- yeah, the parent is in control
[00:47:14.720 --> 00:47:17.720]   of -- the parent can choose to enable it or not enable it for
[00:47:17.720 --> 00:47:20.720]   the messenger safety feature because that's under parental
[00:47:20.720 --> 00:47:21.720]   controls.
[00:47:21.720 --> 00:47:25.720]   You, as for the CSAM's detection, if you turn off iCloud
[00:47:25.720 --> 00:47:28.720]   photo library, it's only done on upload and the way it's
[00:47:28.720 --> 00:47:31.720]   architected is that it requires a server-side secret to even
[00:47:31.720 --> 00:47:35.720]   open the headers on the -- that -- the vouchers are double
[00:47:35.720 --> 00:47:37.720]   wrapped basically and the headers can't even open.
[00:47:37.720 --> 00:47:39.720]   >> But Apple said earlier today with an interview with
[00:47:39.720 --> 00:47:42.720]   Matthew Panzerino on TechCrunch that once you turn that off the
[00:47:42.720 --> 00:47:43.720]   entire system, just dies.
[00:47:43.720 --> 00:47:46.720]   Nothing -- not even generating neural hashes anymore at that
[00:47:46.720 --> 00:47:47.720]   point.
[00:47:47.720 --> 00:47:49.720]   >> So that's just for people to know.
[00:47:49.720 --> 00:47:51.720]   That's the way you can privatize phone.
[00:47:51.720 --> 00:47:54.720]   >> The sad thing with this though is that there -- like
[00:47:54.720 --> 00:47:56.720]   regardless of -- like some people are just privacy
[00:47:56.720 --> 00:47:57.720]   absolutist.
[00:47:57.720 --> 00:47:59.720]   Doesn't matter if it's like terrorist propaganda or a
[00:47:59.720 --> 00:48:01.720]   c-s, they just don't believe anyone has any business to look
[00:48:01.720 --> 00:48:04.720]   at their stuff and until now iCloud was an option because
[00:48:04.720 --> 00:48:06.720]   Apple just wasn't looking at anything.
[00:48:06.720 --> 00:48:10.720]   >> And now there's no mainstream -- I don't even have any
[00:48:10.720 --> 00:48:11.720]   boutique options.
[00:48:11.720 --> 00:48:15.720]   You've got to basically sink over a cable to your Mac or PC and
[00:48:15.720 --> 00:48:17.720]   then handle your own off-site backups from there.
[00:48:17.720 --> 00:48:22.720]   So it does -- for people who are fundamentalist privacy absolutist,
[00:48:22.720 --> 00:48:25.720]   they have no easy option anymore.
[00:48:25.720 --> 00:48:28.720]   >> I should, by the way, recommend youtube.com/renewritchie.
[00:48:28.720 --> 00:48:32.720]   His most recent video, The Ugly Truth About Apple's privacy
[00:48:32.720 --> 00:48:36.720]   panic, is a very clear description of what they're doing.
[00:48:36.720 --> 00:48:37.720]   Exactly how it works.
[00:48:37.720 --> 00:48:40.720]   So if you are still kind of in mystery about all this, and I
[00:48:40.720 --> 00:48:43.720]   wouldn't be surprised if you are, I know I am.
[00:48:43.720 --> 00:48:45.720]   That's the place to go.
[00:48:45.720 --> 00:48:46.720]   >> You know, I like you, Renee.
[00:48:46.720 --> 00:48:50.720]   I stopped using Windows because I was tired of Microsoft's for
[00:48:50.720 --> 00:48:54.720]   a variety of reasons and I'm very happy using Linux.
[00:48:54.720 --> 00:48:59.720]   You can if you -- there is an option if you want to get away
[00:48:59.720 --> 00:49:03.720]   from all this to go to an Android device, probably a pixel, and
[00:49:03.720 --> 00:49:07.720]   then replace the stock Android with something like Calix OS, which
[00:49:07.720 --> 00:49:13.720]   is a privacy-focused ROM that is Android but is de-googled.
[00:49:13.720 --> 00:49:19.720]   So it is -- I think if you care, there are ways to -- I think
[00:49:19.720 --> 00:49:21.720]   you probably can't get away from it entirely.
[00:49:21.720 --> 00:49:22.720]   >> It's less convenient.
[00:49:22.720 --> 00:49:26.720]   Because the services are -- it requires so much money to do
[00:49:26.720 --> 00:49:28.720]   the convenient services.
[00:49:28.720 --> 00:49:30.720]   That's the whole problem here.
[00:49:30.720 --> 00:49:31.720]   Why we use this stuff?
[00:49:31.720 --> 00:49:32.720]   Why we make these deals?
[00:49:32.720 --> 00:49:33.720]   Why we use Facebook?
[00:49:33.720 --> 00:49:34.720]   Why we use Google?
[00:49:34.720 --> 00:49:35.720]   Because it is so good.
[00:49:35.720 --> 00:49:36.720]   >> Yeah.
[00:49:36.720 --> 00:49:39.720]   I have to say, before I buy -- before next month and my
[00:49:39.720 --> 00:49:44.720]   decision to buy another iPhone, and probably before October,
[00:49:44.720 --> 00:49:48.720]   in my decision to buy another MacBook Pro, I'm going to really
[00:49:48.720 --> 00:49:50.720]   have to think hard about this.
[00:49:50.720 --> 00:49:52.720]   I'm very happy with Linux.
[00:49:52.720 --> 00:49:56.720]   I probably will buy the new Pixel phone and I'll put Calix on it.
[00:49:56.720 --> 00:49:59.720]   And if those two solutions suit, I might well do that.
[00:49:59.720 --> 00:50:04.720]   Not so much -- just as a statement, you know, that I want
[00:50:04.720 --> 00:50:06.720]   to use privacy-forward stuff.
[00:50:06.720 --> 00:50:07.720]   >> I agree.
[00:50:07.720 --> 00:50:12.720]   I'm not ready to abandon commercial -- more popular
[00:50:12.720 --> 00:50:16.720]   commercial operating systems for open source or for Linux.
[00:50:16.720 --> 00:50:21.720]   However, I'm keeping my toe in Linux because it's a great
[00:50:21.720 --> 00:50:23.720]   operating system and it's a great resource.
[00:50:23.720 --> 00:50:27.720]   And I like to -- just like when I board a plane, I like to know
[00:50:27.720 --> 00:50:29.720]   where all the exits are because you never know which one of them
[00:50:29.720 --> 00:50:31.720]   is going to be useful to you at any given moment.
[00:50:31.720 --> 00:50:35.720]   So this is why, even though I was an iPhone user, I was keeping
[00:50:35.720 --> 00:50:38.720]   very, very hip to what was going on in Android so that at the
[00:50:38.720 --> 00:50:41.720]   moment when it felt like, gee, I really do prefer the features
[00:50:41.720 --> 00:50:44.720]   of Android, I knew where that exit was, I was able to go.
[00:50:44.720 --> 00:50:50.720]   Similarly, when I felt like Apple was not making Macs that
[00:50:50.720 --> 00:50:55.720]   were in any way reasonable for what my needs are, I had the
[00:50:55.720 --> 00:50:59.720]   exit for -- I had the Lenovo ThinkPad picked out that I was
[00:50:59.720 --> 00:51:01.720]   going to be buying on and on and on.
[00:51:01.720 --> 00:51:04.720]   You have to know where your exits are and know how to use each
[00:51:04.720 --> 00:51:06.720]   one of them in each kind of crisis.
[00:51:06.720 --> 00:51:07.720]   >> Yeah.
[00:51:07.720 --> 00:51:09.720]   But they're -- you have to think about these things.
[00:51:09.720 --> 00:51:11.720]   Like I said, they won't let you take a screenshot of a
[00:51:11.720 --> 00:51:12.720]   Hollywood movie.
[00:51:12.720 --> 00:51:14.720]   An explicit image will never show up in the photo widget on your
[00:51:14.720 --> 00:51:15.720]   home screen.
[00:51:15.720 --> 00:51:17.720]   Like that -- because they know it's explicit.
[00:51:17.720 --> 00:51:20.720]   Like they are increasingly Google, Apple, everybody, Microsoft,
[00:51:20.720 --> 00:51:22.720]   they're increasingly acting like our parents.
[00:51:22.720 --> 00:51:24.720]   And the worst part is you shouldn't have to feel like a
[00:51:24.720 --> 00:51:26.720]   criminal if you don't like that and you're exploring other
[00:51:26.720 --> 00:51:27.720]   options.
[00:51:27.720 --> 00:51:30.720]   But now you have the presumption of -- why -- where do you have
[00:51:30.720 --> 00:51:31.720]   to hide?
[00:51:31.720 --> 00:51:34.720]   And that's the worst, most cliched hailstorm of hot takes out
[00:51:34.720 --> 00:51:37.720]   of all of this is that you're made to feel that way if you just
[00:51:37.720 --> 00:51:39.720]   want to have something that's yours.
[00:51:39.720 --> 00:51:40.720]   >> Yeah.
[00:51:40.720 --> 00:51:43.720]   It's a challenge for me because I'm supposed to cover Apple
[00:51:43.720 --> 00:51:44.720]   products.
[00:51:44.720 --> 00:51:45.720]   I'm supposed to cover Windows products.
[00:51:45.720 --> 00:51:47.720]   >> Oh, well, we'll start at Apple.
[00:51:47.720 --> 00:51:49.720]   >> As part of my job, and I'll still have those, but my
[00:51:49.720 --> 00:51:53.720]   definitely my preferred choice is something more privacy-
[00:51:53.720 --> 00:51:54.720]   >> You'll have a stream deck.
[00:51:54.720 --> 00:51:55.720]   >> Yeah.
[00:51:55.720 --> 00:51:56.720]   Right.
[00:51:56.720 --> 00:51:59.720]   And at some point, you know, when I retire, I think it's pretty
[00:51:59.720 --> 00:52:04.720]   clear to me that I will abandon those invasive operating
[00:52:04.720 --> 00:52:07.720]   systems because I just -- I don't want to support them.
[00:52:07.720 --> 00:52:11.720]   >> It isn't insidious, though, the way a lot of these things work.
[00:52:11.720 --> 00:52:15.720]   I think you mentioned a really good privacy forward operating
[00:52:15.720 --> 00:52:16.720]   system.
[00:52:16.720 --> 00:52:19.720]   You can install on any Android phone that has an open boot
[00:52:19.720 --> 00:52:20.720]   loader.
[00:52:20.720 --> 00:52:23.720]   But how -- but the question becomes, are you okay with not
[00:52:23.720 --> 00:52:26.720]   having access to Lyft and Uber?
[00:52:26.720 --> 00:52:29.720]   Are you okay with not having access to your banking app?
[00:52:29.720 --> 00:52:32.720]   Not all apps, even though it is technically an option of Android
[00:52:32.720 --> 00:52:35.720]   and it tries to be as compatible as possible, that doesn't
[00:52:35.720 --> 00:52:38.720]   necessarily mean that all these services that you have told
[00:52:38.720 --> 00:52:41.720]   yourself you absolutely can't do without are going to be
[00:52:41.720 --> 00:52:45.720]   compatible with this -- this freedom, this paradise of freedom
[00:52:45.720 --> 00:52:46.720]   that you're creating for yourself.
[00:52:46.720 --> 00:52:49.720]   So a lot of it really -- I mean, a lot of the stuff that goes
[00:52:49.720 --> 00:52:53.720]   into our material lives of do I really need to have all of these
[00:52:53.720 --> 00:52:56.720]   books, do I really need to have all of this electronic skier,
[00:52:56.720 --> 00:52:59.720]   how much of this is superfluous, how much is this just self-soothing,
[00:52:59.720 --> 00:53:03.720]   a lot of this has to happen with our dependence on apps, on
[00:53:03.720 --> 00:53:05.720]   services, on third-party data.
[00:53:05.720 --> 00:53:09.720]   We have to understand what this device is, how it's there to
[00:53:09.720 --> 00:53:13.720]   serve us, and to what degree we are giving up our freedom by
[00:53:13.720 --> 00:53:15.720]   accepting some convenience.
[00:53:15.720 --> 00:53:18.720]   Well, and I think that while I'm disappointed with what Apple
[00:53:18.720 --> 00:53:21.720]   did, I think we need to be realists about how much privacy
[00:53:21.720 --> 00:53:23.720]   we really have.
[00:53:23.720 --> 00:53:25.720]   You know, like, I mean, there's the level of tracking.
[00:53:25.720 --> 00:53:28.720]   And I was obsessive about it in the '90s, like really just
[00:53:28.720 --> 00:53:32.720]   obsessive about not giving up anything ever and buying things
[00:53:32.720 --> 00:53:36.720]   with cash, and like really not playing at all.
[00:53:36.720 --> 00:53:40.720]   And I think that after some work that I did, I realized how deep
[00:53:40.720 --> 00:53:42.720]   the thing went.
[00:53:42.720 --> 00:53:45.720]   And I was kind of like, well, I'll just not be interesting.
[00:53:45.720 --> 00:53:48.720]   You know, like, because it's just -- it's very, very difficult
[00:53:48.720 --> 00:53:49.720]   to get out of the net.
[00:53:49.720 --> 00:53:51.720]   And so I think that we can do a lot of those things.
[00:53:51.720 --> 00:53:54.720]   But if we interact with the outside world, we're building
[00:53:54.720 --> 00:53:55.720]   a pretty searchable database.
[00:53:55.720 --> 00:53:58.720]   And I think that, you know, I feel like the problem is that
[00:53:58.720 --> 00:54:02.720]   Apple just -- there was at least one place that we -- my
[00:54:02.720 --> 00:54:04.720]   frustration is I felt like there was at least one place that
[00:54:04.720 --> 00:54:07.720]   we had at least some semblance of that.
[00:54:07.720 --> 00:54:11.720]   And that place is now got a -- it's not over.
[00:54:11.720 --> 00:54:14.720]   It just has a gap now that didn't exist before.
[00:54:14.720 --> 00:54:15.720]   Yeah.
[00:54:15.720 --> 00:54:17.720]   I mean, honestly, and I said this on the radio show on the
[00:54:17.720 --> 00:54:20.720]   weekend, once you go down the rabbit hole of I want to be
[00:54:20.720 --> 00:54:23.720]   private, you end up living in a cabin in the woods off the grid
[00:54:23.720 --> 00:54:25.720]   because it's very difficult.
[00:54:25.720 --> 00:54:27.720]   They don't even need to ask for this stuff.
[00:54:27.720 --> 00:54:29.720]   Like, we'll give it to, like, Pokemon Go says, I'll hatch
[00:54:29.720 --> 00:54:31.720]   your eggs if you give us permanent location status.
[00:54:31.720 --> 00:54:33.720]   And I'm like, I don't even think about it.
[00:54:33.720 --> 00:54:34.720]   Like, really?
[00:54:34.720 --> 00:54:36.720]   I'm thinking about privacy all the time.
[00:54:36.720 --> 00:54:39.720]   I saw a bunch of people show me and announce their own
[00:54:39.720 --> 00:54:41.720]   version of the Spotdog, the Boston Dynamics Spotdog today.
[00:54:41.720 --> 00:54:43.720]   And you know that thing is just reported.
[00:54:43.720 --> 00:54:44.720]   And people are like, I don't care.
[00:54:44.720 --> 00:54:45.720]   I want it.
[00:54:45.720 --> 00:54:46.720]   I don't care what data it takes.
[00:54:46.720 --> 00:54:47.720]   I want.
[00:54:47.720 --> 00:54:50.720]   Like, if you make something shiny, like, the debates evaporate.
[00:54:50.720 --> 00:54:52.720]   Humans are the darnest creatures.
[00:54:52.720 --> 00:54:53.720]   You know?
[00:54:53.720 --> 00:54:58.720]   And it just sounds like we've given up.
[00:54:58.720 --> 00:54:59.720]   It's like, okay.
[00:54:59.720 --> 00:55:00.720]   No.
[00:55:00.720 --> 00:55:01.720]   I think there's--
[00:55:01.720 --> 00:55:03.720]   We're giving up food.
[00:55:03.720 --> 00:55:08.720]   Another one that I was telling you about earlier is just the
[00:55:08.720 --> 00:55:11.720]   fact that you have to respect the difference between an
[00:55:11.720 --> 00:55:14.720]   academic argument and a practical argument.
[00:55:14.720 --> 00:55:17.720]   Like, there was ways that I think of a certain situation,
[00:55:17.720 --> 00:55:21.720]   meaning that inside this room where anything-- inside this
[00:55:21.720 --> 00:55:25.720]   room devoid of any outside feedback of any repercussions that
[00:55:25.720 --> 00:55:29.720]   I can't imagine, I believe that my power over this device should
[00:55:29.720 --> 00:55:31.720]   be absolutely sacrosanct.
[00:55:31.720 --> 00:55:34.720]   However, outside when it becomes a practical thing,
[00:55:34.720 --> 00:55:37.720]   where here are the numbers of how technology is being abused
[00:55:37.720 --> 00:55:38.720]   in this way.
[00:55:38.720 --> 00:55:43.720]   Here's how easily that a technological solution can not
[00:55:43.720 --> 00:55:46.720]   solve this problem but at least blunt this problem.
[00:55:46.720 --> 00:55:50.720]   And every 5% you can knock down that problem with are 5% of
[00:55:50.720 --> 00:55:53.720]   people that are not going to suffer the way that they are
[00:55:53.720 --> 00:55:55.720]   being made to suffer right now.
[00:55:55.720 --> 00:55:57.720]   That's not an answer to the question.
[00:55:57.720 --> 00:56:00.720]   However, that means that you can't just simply say,
[00:56:00.720 --> 00:56:04.720]   you know, all the entire world is going to be happy that I,
[00:56:04.720 --> 00:56:07.720]   as your supreme ruler of all things, have decided to make
[00:56:07.720 --> 00:56:11.720]   sure that everything can be encrypted top to bottom inside
[00:56:11.720 --> 00:56:15.720]   and out, there is no circumstance under which the law enforcement
[00:56:15.720 --> 00:56:17.720]   can take hold of your data or your material.
[00:56:17.720 --> 00:56:21.720]   Don't, and then I don't want to find out 10 years later that
[00:56:21.720 --> 00:56:25.720]   this is why World War 4 happened and was all because of 800
[00:56:25.720 --> 00:56:28.720]   individual armies, each doing horrible things inside the
[00:56:28.720 --> 00:56:30.720]   Commonwealth of Massachusetts.
[00:56:30.720 --> 00:56:31.720]   That's a slip or a slip.
[00:56:31.720 --> 00:56:32.720]   I can't slope argument.
[00:56:32.720 --> 00:56:33.720]   I'm not.
[00:56:33.720 --> 00:56:34.720]   I'm not.
[00:56:34.720 --> 00:56:36.720]   I wasn't making a slip or a two-part one.
[00:56:36.720 --> 00:56:39.720]   I'm saying, I'll give them action.
[00:56:39.720 --> 00:56:41.720]   I'll give them more practice.
[00:56:41.720 --> 00:56:42.720]   I'll give them more practice.
[00:56:42.720 --> 00:56:43.720]   I'll give them more practice in the next World War.
[00:56:43.720 --> 00:56:44.720]   No, no.
[00:56:44.720 --> 00:56:46.720]   I'll give a quick and more practical thing that's actually
[00:56:46.720 --> 00:56:51.720]   from my own internal arguments, like people who work in the
[00:56:51.720 --> 00:56:52.720]   sex industry.
[00:56:52.720 --> 00:56:57.720]   I believe that, I believe in principle that two consenting
[00:56:57.720 --> 00:57:01.720]   adults that want to engage in a transaction, I don't think that
[00:57:01.720 --> 00:57:04.720]   I have the ability or the law has the ability to say that this
[00:57:04.720 --> 00:57:07.720]   thing that does not harm anybody else, again, inside this
[00:57:07.720 --> 00:57:11.720]   academic bubble of two people, of the person who's working in
[00:57:11.720 --> 00:57:13.720]   this industry, having full knowledge, full power, full
[00:57:13.720 --> 00:57:15.720]   control, full consent.
[00:57:15.720 --> 00:57:19.720]   However, the thing that makes me stop from, if this were a
[00:57:19.720 --> 00:57:21.720]   ballot measure that I could vote on, I would have great
[00:57:21.720 --> 00:57:24.720]   difficulty navigating the problem of, okay, academically,
[00:57:24.720 --> 00:57:25.720]   you are in favor of this.
[00:57:25.720 --> 00:57:30.720]   However, do you know that this will not result in more
[00:57:30.720 --> 00:57:31.720]   abuse of people?
[00:57:31.720 --> 00:57:34.720]   Is this going to be, is this going to create more problems of
[00:57:34.720 --> 00:57:38.720]   people being brought into this country for the purpose of
[00:57:38.720 --> 00:57:39.720]   essentially slavery?
[00:57:39.720 --> 00:57:41.720]   I have to, that's the difference between an academic
[00:57:41.720 --> 00:57:44.720]   argument and now, and then having to have a separate
[00:57:44.720 --> 00:57:47.720]   argument about how does this, how will this, this principle
[00:57:47.720 --> 00:57:48.720]   affect the real world?
[00:57:48.720 --> 00:57:51.720]   How, what damage could this create that I'm not dealing
[00:57:51.720 --> 00:57:53.720]   with because again, I'm just leaning back in my chair, having a
[00:57:53.720 --> 00:57:55.720]   beverage and stroking my beard?
[00:57:55.720 --> 00:57:56.720]   Yeah.
[00:57:56.720 --> 00:58:01.720]   Incidentally, this just came out in Mac rumors, Apple today
[00:58:01.720 --> 00:58:04.720]   held a question and answer session with reporters regarding
[00:58:04.720 --> 00:58:05.720]   these features.
[00:58:05.720 --> 00:58:08.720]   During the briefing, Apple confirmed it would be open to
[00:58:08.720 --> 00:58:11.720]   expanding the features to third party apps in the future.
[00:58:11.720 --> 00:58:14.720]   Yeah, that's getting misreported a lot too.
[00:58:14.720 --> 00:58:17.720]   So my understanding of this is that what they meant was if,
[00:58:17.720 --> 00:58:21.720]   they're about to launch a screen time API, it's part of iOS 15,
[00:58:21.720 --> 00:58:23.720]   because they had that whole controversy over other apps,
[00:58:23.720 --> 00:58:25.720]   they were trying to do parental controls.
[00:58:25.720 --> 00:58:29.720]   And this is not part of that yet, but they are, too, or thinking
[00:58:29.720 --> 00:58:32.720]   about whether they should make the automatic photo blurring
[00:58:32.720 --> 00:58:33.720]   available.
[00:58:33.720 --> 00:58:35.720]   So for example, if, like, not any of the other things, like not
[00:58:35.720 --> 00:58:37.720]   ceasing, because they can't, literally can't, Apple is
[00:58:37.720 --> 00:58:40.720]   reviewing that stuff on their own, in their own company.
[00:58:40.720 --> 00:58:43.720]   But if, for example, Snapchat wanted to easily add a way to
[00:58:43.720 --> 00:58:46.720]   blur explicit photos, they could just add that API and then
[00:58:46.720 --> 00:58:48.720]   you'd have to click through to see a photo.
[00:58:48.720 --> 00:58:49.720]   They could do that on their own.
[00:58:49.720 --> 00:58:50.720]   They don't need Apple for this.
[00:58:50.720 --> 00:58:51.720]   It's just easy for--
[00:58:51.720 --> 00:58:56.720]   For instance, we can all think of groups that, for which social
[00:58:56.720 --> 00:58:59.720]   media is a nightmare specifically because of unsolicited
[00:58:59.720 --> 00:59:02.720]   nudes and suggesting to really get sent to them.
[00:59:02.720 --> 00:59:06.720]   And so that's, yeah, so that's an area in which, although it's
[00:59:06.720 --> 00:59:08.720]   like, oh my God, I don't want this to spread.
[00:59:08.720 --> 00:59:11.720]   I don't want every single app to suddenly be scanning photos
[00:59:11.720 --> 00:59:13.720]   and reporting to the CSAM.
[00:59:13.720 --> 00:59:16.720]   But nonetheless, this is an interesting thing.
[00:59:16.720 --> 00:59:21.720]   If this other version of this neural network-based scanning
[00:59:21.720 --> 00:59:24.720]   were to be available to chat apps and other things like that.
[00:59:24.720 --> 00:59:26.720]   I don't want to make light of this, but there's a video from
[00:59:26.720 --> 00:59:29.720]   Alanna Pierce, a really famous YouTuber, a games journalist,
[00:59:29.720 --> 00:59:32.720]   who said that her only recourse became storing all the hotdog
[00:59:32.720 --> 00:59:34.720]   pictures she got and then responding with slightly bigger
[00:59:34.720 --> 00:59:37.720]   hotdog pictures every time, because that was the only thing
[00:59:37.720 --> 00:59:39.720]   she could think of to get people to desist.
[00:59:39.720 --> 00:59:42.720]   And some people would really welcome an ability not to be
[00:59:42.720 --> 00:59:45.720]   showing this stuff immediately on delivery.
[00:59:45.720 --> 00:59:47.720]   Yeah, let's take a break.
[00:59:47.720 --> 00:59:51.720]   That was a very good conversation as I fully expected from the three
[00:59:51.720 --> 00:59:52.720]   of you, I appreciate it.
[00:59:52.720 --> 00:59:53.720]   How are you people?
[00:59:53.720 --> 00:59:58.720]   Alex Lindsey, Renee Richie, Andy Enocho.
[00:59:58.720 --> 00:59:59.720]   Great to have all three.
[00:59:59.720 --> 01:00:01.720]   I'm so glad I'm having this conversation with you three
[01:00:01.720 --> 01:00:03.720]   a couple of days before I have to go on the radio and tell
[01:00:03.720 --> 01:00:05.720]   I'll talk about this to all of Boston.
[01:00:05.720 --> 01:00:07.720]   Oh, yes, that's my attitude.
[01:00:07.720 --> 01:00:08.720]   Oh, you're the author.
[01:00:08.720 --> 01:00:12.720]   You didn't go on before he goes to the Apollo.
[01:00:12.720 --> 01:00:14.720]   Oh, with a warm-up audience.
[01:00:14.720 --> 01:00:17.720]   Yeah, if it explodes on the launch period with us, he's not
[01:00:17.720 --> 01:00:18.720]   going to use it.
[01:00:18.720 --> 01:00:19.720]   Yeah, he's not going to be a Apollo.
[01:00:19.720 --> 01:00:22.720]   You three are keeping Sandman Sims off the stage, and I
[01:00:22.720 --> 01:00:23.720]   thank you for it.
[01:00:23.720 --> 01:00:27.720]   No, seriously, is why I do these shows.
[01:00:27.720 --> 01:00:30.720]   I want to be informed, and so the best thing I could think of
[01:00:30.720 --> 01:00:33.720]   is get very smart people that I know in and tell me what it means.
[01:00:33.720 --> 01:00:34.720]   And they learn me.
[01:00:34.720 --> 01:00:36.720]   Tell me what it means.
[01:00:36.720 --> 01:00:37.720]   Learn me.
[01:00:37.720 --> 01:00:38.720]   Teach me.
[01:00:38.720 --> 01:00:41.720]   You know who's going to teach you tonight?
[01:00:41.720 --> 01:00:44.720]   Udacity, our sponsor for the segment of Mac Brake Weekly.
[01:00:44.720 --> 01:00:49.720]   Udacity is a fantastic online learning solution.
[01:00:49.720 --> 01:00:52.720]   Geared for people who love technology and want to take their
[01:00:52.720 --> 01:00:55.720]   knowledge to the next level, they've got content no one else
[01:00:55.720 --> 01:00:59.720]   does, but that's kind of because of the origins of Udacity.
[01:00:59.720 --> 01:01:03.720]   Started by a Googler Sebastian Thrun, who said, you know, we're
[01:01:03.720 --> 01:01:09.720]   not getting, even with graduates, PhDs, the quality of employees
[01:01:09.720 --> 01:01:12.720]   we need, there needs to be a better way to train people to
[01:01:12.720 --> 01:01:14.720]   have the skills that we need.
[01:01:14.720 --> 01:01:18.720]   Udacity has nanodegrees now with all the industry leaders,
[01:01:18.720 --> 01:01:21.720]   Microsoft, Google, IBM, AWS.
[01:01:21.720 --> 01:01:25.720]   You'll see team leads from those companies as your instructors,
[01:01:25.720 --> 01:01:28.720]   which means you're really learning from the people who are
[01:01:28.720 --> 01:01:32.720]   on the ground doing this stuff day in, day out, and you can get
[01:01:32.720 --> 01:01:36.720]   these nanodegrees in that are, they're not available anywhere
[01:01:36.720 --> 01:01:38.720]   else in amazing areas.
[01:01:38.720 --> 01:01:42.720]   Would you like to become an autonomous flight engineer or
[01:01:42.720 --> 01:01:44.720]   design flying cars?
[01:01:44.720 --> 01:01:45.720]   They've got a degree for that.
[01:01:45.720 --> 01:01:50.720]   AI, deep learning, intro to self-driving cars, machine learning
[01:01:50.720 --> 01:01:54.720]   engineer, robotic software engineer.
[01:01:54.720 --> 01:01:58.720]   The thing I really appreciate about Udacity is it's hands-on.
[01:01:58.720 --> 01:02:02.720]   They understand that it's one thing to learn the material,
[01:02:02.720 --> 01:02:05.720]   and of course they've got the great videos, the great instructors,
[01:02:05.720 --> 01:02:08.720]   so you can watch the lectures, but then you've got to apply
[01:02:08.720 --> 01:02:11.720]   what you've learned to get that nanodegree.
[01:02:11.720 --> 01:02:15.720]   All the courses are project-based, active learning.
[01:02:15.720 --> 01:02:20.720]   So, for instance, you'll have to do one or more projects to show
[01:02:20.720 --> 01:02:22.720]   that you've understood the material and can apply it.
[01:02:22.720 --> 01:02:25.720]   All your homework, all your projects will be reviewed by qualified
[01:02:25.720 --> 01:02:26.720]   professionals.
[01:02:26.720 --> 01:02:29.720]   You get code reviews like you would in the real world, real human
[01:02:29.720 --> 01:02:34.720]   feedback, and don't worry, you're not on your own because Udacity
[01:02:34.720 --> 01:02:39.720]   has a very strong mentorship program, and you can have mentors,
[01:02:39.720 --> 01:02:42.720]   you talk to your peers 24/7.
[01:02:42.720 --> 01:02:46.720]   That's important too because Udacity understands a lot of you have
[01:02:46.720 --> 01:02:50.720]   a day job and you want to get these skills in your free time.
[01:02:50.720 --> 01:02:53.720]   Udacity's flexible schedules mean you can put in five to ten hours
[01:02:53.720 --> 01:02:57.720]   a week, work at your own pace any time of the day or night,
[01:02:57.720 --> 01:03:00.720]   and still graduate in as little as three months.
[01:03:00.720 --> 01:03:05.720]   This is a scary stat, the World Economic Forum says 75 million
[01:03:05.720 --> 01:03:10.720]   jobs that exist today will be replaced by automated processes
[01:03:10.720 --> 01:03:12.720]   in the next three years.
[01:03:12.720 --> 01:03:14.720]   Three years.
[01:03:14.720 --> 01:03:16.720]   You may well have one of those jobs.
[01:03:16.720 --> 01:03:17.720]   Heck, I might have one of those jobs.
[01:03:17.720 --> 01:03:19.720]   Maybe that was the time to get some training in a job that's
[01:03:19.720 --> 01:03:21.720]   going to exist three years from now.
[01:03:21.720 --> 01:03:24.720]   Udacity prepares its students for the jobs of the future.
[01:03:24.720 --> 01:03:27.720]   I think the thing to do, and I've said this before, is to go
[01:03:27.720 --> 01:03:31.720]   to Udacity.com, look at the course listings, and find something
[01:03:31.720 --> 01:03:35.720]   that excites you because A, you'll do better, you'll enjoy it,
[01:03:35.720 --> 01:03:39.720]   and you'll be better at it just because it's something excites you.
[01:03:39.720 --> 01:03:43.720]   And I guarantee you there's something exciting for everybody
[01:03:43.720 --> 01:03:45.720]   at Udacity.com/twit.
[01:03:45.720 --> 01:03:48.720]   And by the way, you're a business.
[01:03:48.720 --> 01:03:52.720]   Udacity for Enterprise helps your team master those cutting edge
[01:03:52.720 --> 01:03:55.720]   technologies they're going to need like data science, AI,
[01:03:55.720 --> 01:03:59.720]   cyber security, upskill your entire workforce with Udacity's
[01:03:59.720 --> 01:04:02.720]   world famous real world project based learning.
[01:04:02.720 --> 01:04:05.720]   Make sure you check out the Enterprise section at Udacity's
[01:04:05.720 --> 01:04:06.720]   website as well.
[01:04:06.720 --> 01:04:09.720]   They have free courses, flexible payment options.
[01:04:09.720 --> 01:04:11.720]   You can learn at your own pace and schedule.
[01:04:11.720 --> 01:04:16.720]   Get the in demand tech skills you need to advance your career.
[01:04:16.720 --> 01:04:18.720]   And we've got an amazing deal.
[01:04:18.720 --> 01:04:20.720]   Go to Udacity.com/twit.
[01:04:20.720 --> 01:04:23.720]   U-D-A-C-I-T-Y, Udacity.
[01:04:23.720 --> 01:04:26.720]   It's like audacity without the A. Get ready for this.
[01:04:26.720 --> 01:04:30.720]   75% off any program.
[01:04:30.720 --> 01:04:34.720]   Please use the offer code TWIT75 for this.
[01:04:34.720 --> 01:04:37.720]   This will not last long, so please take advantage of it now.
[01:04:37.720 --> 01:04:41.720]   Udacity.com/twit.
[01:04:41.720 --> 01:04:43.720]   The offer code is TWIT75.
[01:04:43.720 --> 01:04:45.720]   Thank you, Udacity.
[01:04:45.720 --> 01:04:47.720]   I've taken courses that are great.
[01:04:47.720 --> 01:04:49.720]   Udacity.com/twit.
[01:04:49.720 --> 01:04:52.720]   The offer code TWIT75.
[01:04:52.720 --> 01:04:55.720]   Please use that offer code so they know you saw it here.
[01:04:55.720 --> 01:04:58.720]   I know you're smart and you can just go to Udacity.com.
[01:04:58.720 --> 01:05:00.720]   But A, you want the 75% off.
[01:05:00.720 --> 01:05:01.720]   That's smart.
[01:05:01.720 --> 01:05:03.720]   B, you want to support us, right?
[01:05:03.720 --> 01:05:06.720]   Hey, speaking of supporting us, I do encourage anybody who
[01:05:06.720 --> 01:05:09.720]   watches our shows and wants to support the TWIT Network
[01:05:09.720 --> 01:05:11.720]   to join club TWIT.
[01:05:11.720 --> 01:05:16.720]   This is our way of becoming less dependent on advertising,
[01:05:16.720 --> 01:05:20.720]   less dependent on tracking, and give you more of what you want.
[01:05:20.720 --> 01:05:22.720]   You get three benefits.
[01:05:22.720 --> 01:05:24.720]   You get ad-free versions of all the shows.
[01:05:24.720 --> 01:05:26.720]   You don't even hear this promo in your club TWIT feed.
[01:05:26.720 --> 01:05:28.720]   Audio or video.
[01:05:28.720 --> 01:05:32.720]   I mean, I guess there's no reason to really promote club TWIT to people who are already members.
[01:05:32.720 --> 01:05:34.720]   You get access to a great club TWIT Discord,
[01:05:34.720 --> 01:05:36.720]   which is a heck of a lot of fun.
[01:05:36.720 --> 01:05:38.720]   Really enjoy it.
[01:05:38.720 --> 01:05:43.720]   It's a community now of smart, interesting club TWIT members.
[01:05:43.720 --> 01:05:46.720]   You have to be in the club to join, although all of our hosts are in there.
[01:05:46.720 --> 01:05:50.720]   I know we're in A's right now in our Mac break weekly conversation.
[01:05:50.720 --> 01:05:52.720]   There's also the TWIT+...
[01:05:52.720 --> 01:05:56.720]   By the way, one of the benefits of the Discord is animated GIFs.
[01:05:56.720 --> 01:06:02.720]   I know we have an IRC, but those animated GIFs in the TWIT Discord really speak to me.
[01:06:02.720 --> 01:06:04.720]   The memes...
[01:06:04.720 --> 01:06:06.720]   Join us.
[01:06:06.720 --> 01:06:12.720]   You also get a TWIT+ feed with stuff that's not anywhere else, including show conversations
[01:06:12.720 --> 01:06:18.720]   before and after the show with our hosts, special Q&A's, AMAs are on title Linux show.
[01:06:18.720 --> 01:06:20.720]   I think I'm going to do a...
[01:06:20.720 --> 01:06:22.720]   I have to do something for the TWIT+ feed.
[01:06:22.720 --> 01:06:26.720]   I haven't decided what to do yet, but I think I should do a show as well.
[01:06:26.720 --> 01:06:28.720]   So there will be benefits that you can't get anywhere else.
[01:06:28.720 --> 01:06:34.720]   If you want to know more, TWIT is at TWIT.tv/clubtwit.
[01:06:34.720 --> 01:06:36.720]   Yay, Cesar and A-Ritchie.
[01:06:36.720 --> 01:06:38.720]   Yay!
[01:06:38.720 --> 01:06:44.720]   Thank you everybody for putting up with that.
[01:06:44.720 --> 01:06:46.720]   Now, moving right along.
[01:06:46.720 --> 01:06:48.720]   Suicide Squad.
[01:06:48.720 --> 01:06:50.720]   It's the memes. It's the memes, Leela.
[01:06:50.720 --> 01:06:52.720]   The memes are the best thing ever.
[01:06:52.720 --> 01:06:54.720]   I love the animated GIFs.
[01:06:54.720 --> 01:06:56.720]   I love the animated GIFs.
[01:06:56.720 --> 01:06:58.720]   I always do some more of that.
[01:06:58.720 --> 01:07:00.720]   I was streaming my Valheim conquests.
[01:07:00.720 --> 01:07:04.720]   I got a little less active because I conquered all the bosses, and I'm waiting for the updates
[01:07:04.720 --> 01:07:06.720]   to Valheim to add some new bosses.
[01:07:06.720 --> 01:07:12.720]   But I've redesigned my living space in Valheim and stuff, so I should probably do a feed update
[01:07:12.720 --> 01:07:14.720]   to you. That was part of the club TWIT as well.
[01:07:14.720 --> 01:07:16.720]   So are the most informationally dense communication form humans have ever invented?
[01:07:16.720 --> 01:07:18.720]   It's amazing.
[01:07:18.720 --> 01:07:20.720]   One picture is worth a million words.
[01:07:20.720 --> 01:07:22.720]   What's really new?
[01:07:22.720 --> 01:07:24.720]   They move.
[01:07:24.720 --> 01:07:26.720]   Thumbs up or thumbs down on the Suicide Squad.
[01:07:26.720 --> 01:07:28.720]   Renee, I know, and Renee, and you're all comic book fans.
[01:07:28.720 --> 01:07:30.720]   Seven out of ten.
[01:07:30.720 --> 01:07:32.720]   I really love James Gunn.
[01:07:32.720 --> 01:07:34.720]   It was really funny.
[01:07:34.720 --> 01:07:38.720]   I have a lower violence threshold than a lot of people, so it was way violent.
[01:07:38.720 --> 01:07:42.720]   But there were so many characters that it didn't resonate with me
[01:07:42.720 --> 01:07:44.720]   for each character the way Guardians of the Galaxy did.
[01:07:44.720 --> 01:07:46.720]   No, because it's like a giant rubber shark.
[01:07:46.720 --> 01:07:48.720]   No, he's great.
[01:07:48.720 --> 01:07:50.720]   Bird.
[01:07:50.720 --> 01:07:52.720]   It's what best dressed alone is a giant shark.
[01:07:52.720 --> 01:07:54.720]   What more do you want in life?
[01:07:54.720 --> 01:07:56.720]   There you go.
[01:07:56.720 --> 01:07:58.720]   So, George Adal has an amazing video up just on King Shark.
[01:07:58.720 --> 01:08:00.720]   He put it up yesterday about friendship,
[01:08:00.720 --> 01:08:04.720]   about how a giant shark learns to have friends.
[01:08:04.720 --> 01:08:06.720]   Oh, yeah, you could use that.
[01:08:06.720 --> 01:08:10.720]   So you say seven out of ten, Andy, have you seen it yet?
[01:08:10.720 --> 01:08:12.720]   I've seen it. I would say eight out of ten.
[01:08:12.720 --> 01:08:14.720]   Oh.
[01:08:14.720 --> 01:08:18.720]   Especially if you've been scared off by, oh my God, it's a comic book movie,
[01:08:18.720 --> 01:08:20.720]   which means that I'll have to have seen like two TV series,
[01:08:20.720 --> 01:08:24.720]   eight different movies, and I still won't learn what went on until
[01:08:24.720 --> 01:08:26.720]   like another two series that come up in the future.
[01:08:26.720 --> 01:08:30.720]   It is a very much, it's there to entertain you for a couple hours.
[01:08:30.720 --> 01:08:34.720]   It knows what it's about and Harley Quinn for Heaven's Sakes.
[01:08:34.720 --> 01:08:38.720]   This is one of the best movie characters in comics movies ever.
[01:08:38.720 --> 01:08:41.720]   She's more Paul Deeney again.
[01:08:41.720 --> 01:08:43.720]   She's not the Harloty.
[01:08:43.720 --> 01:08:44.720]   Right.
[01:08:44.720 --> 01:08:46.720]   They had a couple articles about how Marga,
[01:08:46.720 --> 01:08:49.720]   Marga, Robie was, I'm sorry, I can't remember her name.
[01:08:49.720 --> 01:08:51.720]   Marga, Marga, Marga.
[01:08:51.720 --> 01:08:53.720]   Thank you very much. I was tripping on this on the second name.
[01:08:53.720 --> 01:08:56.720]   Yeah, she and the director were like talking about,
[01:08:56.720 --> 01:09:00.720]   "Y'all, let's move her forward a little bit, so let's just say she had the,
[01:09:00.720 --> 01:09:04.720]   she had this tattoo off of her face,
[01:09:04.720 --> 01:09:06.720]   a property of the Joker.
[01:09:06.720 --> 01:09:09.720]   Let's have that change to property of myself,
[01:09:09.720 --> 01:09:13.720]   and making her into something more like what we kind of,
[01:09:13.720 --> 01:09:17.720]   the more of the kind of character that we less feel sorry for
[01:09:17.720 --> 01:09:20.720]   and feel afraid for and more feel and how we're putting it all.
[01:09:20.720 --> 01:09:22.720]   And how we're putting it all and afraid of.
[01:09:22.720 --> 01:09:23.720]   Yes, exactly.
[01:09:23.720 --> 01:09:26.720]   This is why in the comics particularly,
[01:09:26.720 --> 01:09:28.720]   when, when, when Rhett and Rell,
[01:09:28.720 --> 01:09:31.720]   you're rooting for her while being terrified of her.
[01:09:31.720 --> 01:09:34.720]   She's like the word, because her heart's in the right place,
[01:09:34.720 --> 01:09:36.720]   but she has very, very severe impulse problems.
[01:09:36.720 --> 01:09:37.720]   Purple and props.
[01:09:37.720 --> 01:09:38.720]   Yes.
[01:09:38.720 --> 01:09:41.720]   Alex, I'm sure you haven't seen it, but I,
[01:09:41.720 --> 01:09:44.720]   I haven't, I, you're the worst part is I really enjoyed the first one,
[01:09:44.720 --> 01:09:46.720]   and I was really excited to see the second one,
[01:09:46.720 --> 01:09:47.720]   which was like my schedule.
[01:09:47.720 --> 01:09:48.720]   I just kept on going,
[01:09:48.720 --> 01:09:49.720]   oh, I'm gonna sit down and watch it.
[01:09:49.720 --> 01:09:50.720]   And then I didn't.
[01:09:50.720 --> 01:09:51.720]   Yeah.
[01:09:51.720 --> 01:09:52.720]   So it's, but it's.
[01:09:52.720 --> 01:09:53.720]   Yeah.
[01:09:53.720 --> 01:09:54.720]   You watch it.
[01:09:54.720 --> 01:09:55.720]   You see the bad compositions and stuff.
[01:09:55.720 --> 01:09:57.720]   Like it must be like a typographer looking at his concerns.
[01:09:57.720 --> 01:09:59.720]   I mean, the first one I thought was pretty good.
[01:09:59.720 --> 01:10:00.720]   I mean, I thought that it was,
[01:10:00.720 --> 01:10:03.720]   I thought that most of the effects were pretty good,
[01:10:03.720 --> 01:10:05.720]   and it was just a fun ride.
[01:10:05.720 --> 01:10:07.720]   The specular highlight is a little bit off on the line.
[01:10:07.720 --> 01:10:08.720]   Yeah, yeah.
[01:10:08.720 --> 01:10:09.720]   It was so hard.
[01:10:09.720 --> 01:10:12.720]   Yeah, it's, it's, it's a little rough, but, but the, but,
[01:10:12.720 --> 01:10:15.720]   but yeah, overall, I, I was excited about the first one,
[01:10:15.720 --> 01:10:16.720]   and I'm ready to watch the second one.
[01:10:16.720 --> 01:10:18.720]   Just haven't gotten to gotten the time.
[01:10:18.720 --> 01:10:19.720]   Let us sit down and do it.
[01:10:19.720 --> 01:10:21.720]   There's something wrong with me, I guess,
[01:10:21.720 --> 01:10:23.720]   because everybody's told me how great this movie was.
[01:10:23.720 --> 01:10:24.720]   It'll be there.
[01:10:24.720 --> 01:10:26.720]   When, when we get around to it, it'll still be there.
[01:10:26.720 --> 01:10:28.720]   It'll watch a little bit of it.
[01:10:28.720 --> 01:10:29.720]   I like the first half hour.
[01:10:29.720 --> 01:10:30.720]   A lot of people I know didn't like it.
[01:10:30.720 --> 01:10:32.720]   I, I never seen it like this movie.
[01:10:32.720 --> 01:10:34.720]   I would have walked out of it if I'd seen it in the theater.
[01:10:34.720 --> 01:10:35.720]   I would have walked out.
[01:10:35.720 --> 01:10:36.720]   We did walk out.
[01:10:36.720 --> 01:10:39.720]   We stopped watching it, but, um, so I guess it's just not for me.
[01:10:39.720 --> 01:10:44.720]   It's not for my, my, here I am wearing a plaid suit and a plaid shirt.
[01:10:44.720 --> 01:10:45.720]   Obviously, I have no taste.
[01:10:45.720 --> 01:10:46.720]   You're Perry White.
[01:10:46.720 --> 01:10:47.720]   I'm afraid.
[01:10:47.720 --> 01:10:51.720]   I'm afraid my, my problem is like I've, I've been falling into all these documentaries that
[01:10:51.720 --> 01:10:55.720]   are sitting on Netflix for this and other things and I, and I, and I'm having a hard time watching
[01:10:55.720 --> 01:10:59.720]   the movies because like there's one called This Is Pop that's just like all that, like
[01:10:59.720 --> 01:11:05.720]   the, the Swedish sound and re and, um, and pitch shifting and, and how's the festival started.
[01:11:05.720 --> 01:11:10.720]   And it shows Steve Wozniak and how his, you know, the Us festival and, and everything.
[01:11:10.720 --> 01:11:12.720]   This is what I'm gonna watch.
[01:11:12.720 --> 01:11:13.720]   This is, yeah, this is pop.
[01:11:13.720 --> 01:11:16.720]   And then, and then the movies that made us, uh, there was some, there's a good one.
[01:11:16.720 --> 01:11:20.520]   That's a little, you know, it's trashy, but it's still fun.
[01:11:20.520 --> 01:11:24.200]   It's really, no, no, the funny thing, the movies that made us, if you go to, uh, if you look
[01:11:24.200 --> 01:11:27.720]   at the Jurassic Park one, uh, you will not see the license plate, but you will see my
[01:11:27.720 --> 01:11:28.720]   car.
[01:11:28.720 --> 01:11:34.720]   So I think we're shooting at, at the old ILM stage and I, they had asked for access last
[01:11:34.720 --> 01:11:35.720]   year.
[01:11:35.720 --> 01:11:38.920]   So I knew that they were shooting it, um, but they shot this, this shot in the back behind
[01:11:38.920 --> 01:11:40.800]   it and my, my car is there.
[01:11:40.800 --> 01:11:46.120]   Is that a mistake or is it with the, no, my car isn't, has anything to do with the story.
[01:11:46.120 --> 01:11:48.720]   It just has to do with the back there that it would just happen to be there when they
[01:11:48.720 --> 01:11:50.000]   shot the establishing shot.
[01:11:50.000 --> 01:11:52.360]   And so, um, and they're talking to the spasm.
[01:11:52.360 --> 01:11:55.440]   Oh, I see in the, uh, the documentary, not in the movie.
[01:11:55.440 --> 01:11:56.440]   I got it.
[01:11:56.440 --> 01:11:57.440]   Yeah.
[01:11:57.440 --> 01:11:58.440]   Yeah.
[01:11:58.440 --> 01:11:59.440]   No, no, my car was actually hidden in Jurassic Park.
[01:11:59.440 --> 01:12:00.440]   It's a little extra.
[01:12:00.440 --> 01:12:01.440]   Yeah.
[01:12:01.440 --> 01:12:06.880]   No, I wasn't, I wasn't working in ILM, but you know, I, you know, can I just, can I just
[01:12:06.880 --> 01:12:07.880]   give you one piece of advice?
[01:12:07.880 --> 01:12:13.000]   If you, if you don't see the, the Justice League movie, the game trailer for the Justice League
[01:12:13.000 --> 01:12:19.160]   video game last year, just a, uh, uh, suicide, suicide squad, kill the Justice League, that
[01:12:19.160 --> 01:12:24.400]   is like a two minute perfect mini movie that I, I've actually had to download it and put
[01:12:24.400 --> 01:12:29.080]   it on my media server because it is like a perfect two minute long movie that makes you
[01:12:29.080 --> 01:12:31.800]   love this team hugely.
[01:12:31.800 --> 01:12:34.880]   So that's going to be, that won't be my pick of the week, but I'm saying that seek this
[01:12:34.880 --> 01:12:39.480]   out. I actually put the pace of the, uh, YouTube link from DC Comics and the show notes, but
[01:12:39.480 --> 01:12:40.480]   it is exception.
[01:12:40.480 --> 01:12:42.000]   I'm going to have to play the game.
[01:12:42.000 --> 01:12:43.360]   Actually, it looks like a pretty good game.
[01:12:43.360 --> 01:12:45.840]   I said, yeah, but they built this trailer.
[01:12:45.840 --> 01:12:47.360]   Like they're shooting a two minute long movie.
[01:12:47.360 --> 01:12:49.920]   It's not like, Oh, play your favorite character.
[01:12:49.920 --> 01:12:54.960]   It was like, well, Batman and Robin are crazy.
[01:12:54.960 --> 01:12:56.440]   I loved rock and asylum.
[01:12:56.440 --> 01:12:57.440]   Arkham Asylum.
[01:12:57.440 --> 01:12:58.440]   I thought they did a good job with that.
[01:12:58.440 --> 01:12:59.440]   I like that dark style.
[01:12:59.440 --> 01:13:00.440]   Yeah.
[01:13:00.440 --> 01:13:01.440]   Yeah.
[01:13:01.440 --> 01:13:02.440]   Metropolis.
[01:13:02.440 --> 01:13:03.440]   Look at Metropolis.
[01:13:03.440 --> 01:13:04.440]   Ooh.
[01:13:04.440 --> 01:13:05.440]   It's Disney plus.
[01:13:05.440 --> 01:13:06.440]   What if, huh?
[01:13:06.440 --> 01:13:07.440]   What is what if?
[01:13:07.440 --> 01:13:10.640]   What if, what if it's like, if you'd make one change, like I think the first episode
[01:13:10.640 --> 01:13:13.520]   is what if Peggy Carter became Captain America instead of Steve Rogers.
[01:13:13.520 --> 01:13:14.520]   Yeah.
[01:13:14.520 --> 01:13:15.520]   And then they ask those kinds of questions every week.
[01:13:15.520 --> 01:13:18.400]   This is part of the reason I don't enjoy these is because I have no idea who those
[01:13:18.400 --> 01:13:19.400]   people are.
[01:13:19.400 --> 01:13:20.400]   I don't.
[01:13:20.400 --> 01:13:21.400]   Yeah.
[01:13:21.400 --> 01:13:23.720]   See, that's my problem with Marvel's son, Madike, and because I'm glad that I'm glad
[01:13:23.720 --> 01:13:24.720]   that so many people love it.
[01:13:24.720 --> 01:13:27.120]   They're obviously doing some great stuff that people love.
[01:13:27.120 --> 01:13:30.200]   I just can't get into it because I don't have time to do the homework.
[01:13:30.200 --> 01:13:31.200]   Yeah.
[01:13:31.200 --> 01:13:32.200]   Yeah.
[01:13:32.200 --> 01:13:33.200]   And I'm a Marvel fan.
[01:13:33.200 --> 01:13:35.080]   I've had most of the stories these things were based on.
[01:13:35.080 --> 01:13:38.600]   It's like, oh God, why do I, what's the, what's the orange glowing thing?
[01:13:38.600 --> 01:13:41.120]   And why do I not know what it is and why are they not explaining it to me?
[01:13:41.120 --> 01:13:42.120]   What does everybody want it?
[01:13:42.120 --> 01:13:45.560]   Because you didn't read the 13 different variant comics out of Crisis on Infinidorous
[01:13:45.560 --> 01:13:46.960]   and Secret Wars, clearly Andy.
[01:13:46.960 --> 01:13:47.960]   It was 20 years ago.
[01:13:47.960 --> 01:13:48.960]   It's not everything.
[01:13:48.960 --> 01:13:50.640]   There's, there's, there's stuff about the next Star Wars movie.
[01:13:50.640 --> 01:13:54.620]   I'm not going to be able to understand unless I spend $4,000 to stay in the Star Wars
[01:13:54.620 --> 01:13:56.480]   Starship Hotel at Disney World.
[01:13:56.480 --> 01:13:57.560]   I don't, it's not right.
[01:13:57.560 --> 01:13:58.560]   I'm telling you.
[01:13:58.560 --> 01:14:01.800]   You know, I was, I was, I was appalled by how much they're charging.
[01:14:01.800 --> 01:14:05.320]   And then I thought to myself, I wonder if I can afford that.
[01:14:05.320 --> 01:14:06.320]   Oh, I know.
[01:14:06.320 --> 01:14:07.320]   I know.
[01:14:07.320 --> 01:14:08.320]   Right.
[01:14:08.320 --> 01:14:09.320]   I was like, how do you know?
[01:14:09.320 --> 01:14:10.320]   The other thing has her lightsabers.
[01:14:10.320 --> 01:14:13.040]   It makes you so much like, I have their lightsabers.
[01:14:13.040 --> 01:14:15.240]   It's really good.
[01:14:15.240 --> 01:14:18.360]   In my opinion, for $4,000, it has to be open world.
[01:14:18.360 --> 01:14:19.360]   It can't be.
[01:14:19.360 --> 01:14:23.080]   Oh, by the way, you have, you have to choose the time that you get to visit the Millennium
[01:14:23.080 --> 01:14:27.560]   Falcon and okay, well, no, you're, you can't, you can't go to this section of the ship
[01:14:27.560 --> 01:14:31.760]   yet because we're not scheduled to see it until four, no, no screw you.
[01:14:31.760 --> 01:14:32.760]   $4,000.
[01:14:32.760 --> 01:14:39.200]   I get, if I want to use the employee bathroom, I get to use the employee bathroom or $4,000.
[01:14:39.200 --> 01:14:49.040]   I go to a, a class of exercise class every week, tomorrow with a woman whose husband
[01:14:49.040 --> 01:14:50.800]   has designed that hotel.
[01:14:50.800 --> 01:14:52.400]   He works at ILM.
[01:14:52.400 --> 01:14:57.840]   So you would think I could maybe ask for a discount, but no.
[01:14:57.840 --> 01:15:00.280]   I think we, I think Lisa and I may do it, man.
[01:15:00.280 --> 01:15:03.440]   Lisa, Alex worked on the movies and they don't give them a, I know.
[01:15:03.440 --> 01:15:05.000]   She's a big Star Wars fan.
[01:15:05.000 --> 01:15:07.640]   And I'm very, this is like 10 gently related.
[01:15:07.640 --> 01:15:15.480]   I go to Florida anytime in the next year, but, but when it's safe to go to Florida, I think
[01:15:15.480 --> 01:15:18.480]   I'm like, not, not until Florida.
[01:15:18.480 --> 01:15:23.920]   It's a huge Quebec vacation destination that nobody's willing to go anymore.
[01:15:23.920 --> 01:15:26.280]   We'll go there and we're speedos on the beaches, Leo.
[01:15:26.280 --> 01:15:27.280]   That's what we're known for.
[01:15:27.280 --> 01:15:28.280]   Oh, God.
[01:15:28.280 --> 01:15:29.280]   Oh, God.
[01:15:29.280 --> 01:15:30.280]   So I'm new.
[01:15:30.280 --> 01:15:31.280]   You don't want us there.
[01:15:31.280 --> 01:15:40.840]   A new rumor from Mark Gurman, who says, you know, the next iPhone is not going to be
[01:15:40.840 --> 01:15:42.600]   a massive update.
[01:15:42.600 --> 01:15:46.880]   I don't think they're going to call it the 12 S, but maybe, maybe you say nude rumor
[01:15:46.880 --> 01:15:48.120]   because my phone blocked it.
[01:15:48.120 --> 01:15:50.880]   That nude rumor, you see, you can't get the nude rumors anymore.
[01:15:50.880 --> 01:15:52.720]   I just got a blur.
[01:15:52.720 --> 01:15:53.720]   Apple's next.
[01:15:53.720 --> 01:15:54.720]   Richie.
[01:15:54.720 --> 01:15:55.720]   Mr. Richie.
[01:15:55.720 --> 01:15:56.720]   Get out.
[01:15:56.720 --> 01:15:57.720]   Please come out, sir.
[01:15:57.720 --> 01:16:02.720]   I'm glad you guys can joke about that.
[01:16:02.720 --> 01:16:07.600]   Take a seat.
[01:16:07.600 --> 01:16:11.520]   So the new phone will have at least three, according to Gurman.
[01:16:11.520 --> 01:16:14.360]   And by the way, we're like weeks away, right?
[01:16:14.360 --> 01:16:17.280]   We're maybe four to twenty twenty one goal.
[01:16:17.280 --> 01:16:18.280]   Yeah.
[01:16:18.280 --> 01:16:19.280]   Seriously.
[01:16:19.280 --> 01:16:21.160]   What do we have a prediction for the, for the event?
[01:16:21.160 --> 01:16:24.280]   It won't be Labor Day, obviously.
[01:16:24.280 --> 01:16:26.840]   So that means it'll probably be the set later than usual.
[01:16:26.840 --> 01:16:29.640]   Yeah, the fourteenth maybe.
[01:16:29.640 --> 01:16:31.640]   Usually it would be the, it would be the, what is it?
[01:16:31.640 --> 01:16:34.920]   The Labor Day is the sixth.
[01:16:34.920 --> 01:16:37.040]   So they wouldn't do it on the seventh.
[01:16:37.040 --> 01:16:38.400]   So they're going to have to do it on the fourteenth.
[01:16:38.400 --> 01:16:40.760]   That's what they did last year too, right?
[01:16:40.760 --> 01:16:42.440]   Sometimes they've done the Wednesday because of Labor Day.
[01:16:42.440 --> 01:16:44.120]   So it would be the eighth or the fourteenth.
[01:16:44.120 --> 01:16:46.960]   There's been rumors that it'll be slightly later just because of 95.
[01:16:46.960 --> 01:16:48.160]   It's hard to tell.
[01:16:48.160 --> 01:16:50.600]   So we're about a month off from the iPhone 13.
[01:16:50.600 --> 01:16:53.000]   Will it be a 13?
[01:16:53.000 --> 01:16:55.080]   They're not going to worry about superstition, are they?
[01:16:55.080 --> 01:16:56.080]   There was an A13.
[01:16:56.080 --> 01:16:58.080]   And there's 13 inch, they sell 13 inch MacBooks.
[01:16:58.080 --> 01:17:01.920]   They sell, I mean, they may, you know, the thing is like, that's like, it used to be
[01:17:01.920 --> 01:17:02.920]   Phil Schiller.
[01:17:02.920 --> 01:17:03.920]   Now it's Greg Jawswick.
[01:17:03.920 --> 01:17:05.960]   I guess they walk into a room and they say, this is what's going on the boxes and the
[01:17:05.960 --> 01:17:06.960]   posters.
[01:17:06.960 --> 01:17:09.880]   And like, nobody has to know until they, usually what happens is they have a big list.
[01:17:09.880 --> 01:17:11.800]   They have their preferred name on the top.
[01:17:11.800 --> 01:17:14.680]   And then they have a bunch of alternative names in case one of those names means something
[01:17:14.680 --> 01:17:16.280]   bad in another country.
[01:17:16.280 --> 01:17:18.640]   You know, like, for example, we can't use this because in all the Saudi countries it
[01:17:18.640 --> 01:17:20.120]   means XYZ instead.
[01:17:20.120 --> 01:17:21.120]   Oh, okay.
[01:17:21.120 --> 01:17:25.120]   So like MacBook Air, I think was Mac, sorry, Mac, the 12 inch MacBook was MacBook stealth
[01:17:25.120 --> 01:17:26.120]   originally.
[01:17:26.120 --> 01:17:28.200]   And then they turned it out, they hated that name.
[01:17:28.200 --> 01:17:32.040]   So they go through it and then they pick a name, but it's no more or less precious than
[01:17:32.040 --> 01:17:33.040]   that.
[01:17:33.040 --> 01:17:36.120]   So it could be iPhone, anything, whatever they want.
[01:17:36.120 --> 01:17:38.000]   Right.
[01:17:38.000 --> 01:17:40.000]   It will be any sense.
[01:17:40.000 --> 01:17:41.000]   Better cameras.
[01:17:41.000 --> 01:17:43.080]   It's now called iPhone.
[01:17:43.080 --> 01:17:44.080]   iPhone.
[01:17:44.080 --> 01:17:45.080]   And there is no, there is no number.
[01:17:45.080 --> 01:17:47.840]   And then, and then it's, I don't have the same connection we have with iPads.
[01:17:47.840 --> 01:17:51.800]   Like I don't know which one I have, you know, like it's, you know, we know that it'll,
[01:17:51.800 --> 01:17:57.480]   or a German says, and I think it's reasonable to assume it will have a new faster A15 chip
[01:17:57.480 --> 01:17:58.480]   in it.
[01:17:58.480 --> 01:18:01.680]   We've also seen that the display cut out is a little bit smaller than notch is a little
[01:18:01.680 --> 01:18:02.680]   bit smaller.
[01:18:02.680 --> 01:18:05.080]   And that'll be on TSMC's new five nine meter process.
[01:18:05.080 --> 01:18:06.600]   It won't go down yet, but it's going to be on there.
[01:18:06.600 --> 01:18:09.520]   And I think it's five nine meter P or something.
[01:18:09.520 --> 01:18:10.520]   Yeah.
[01:18:10.520 --> 01:18:13.960]   It also though, the biggest thing will be the camera enhancements according to German.
[01:18:13.960 --> 01:18:19.960]   The new handsets will include a video version of the portrait mode, which is nice.
[01:18:19.960 --> 01:18:25.640]   It'll also be able to record video in a higher quality format called ProRes and a new filters
[01:18:25.640 --> 01:18:28.040]   like system that approves the looking color of photos.
[01:18:28.040 --> 01:18:29.560]   According to people familiar with matter.
[01:18:29.560 --> 01:18:30.640]   Alex Moore.
[01:18:30.640 --> 01:18:31.640]   So what is ProRes?
[01:18:31.640 --> 01:18:32.640]   Do we have any idea?
[01:18:32.640 --> 01:18:36.720]   Well, is it, is it like the, it's some version of ProRes.
[01:18:36.720 --> 01:18:37.720]   I don't know what's ProRes.
[01:18:37.720 --> 01:18:38.720]   It's ProRes.
[01:18:38.720 --> 01:18:39.720]   It's just going to record in ProRes.
[01:18:39.720 --> 01:18:40.720]   Yeah, it's like final con ProRes.
[01:18:40.720 --> 01:18:43.520]   It's like raw for stills.
[01:18:43.520 --> 01:18:45.320]   Well, it's not raw.
[01:18:45.320 --> 01:18:46.320]   I know.
[01:18:46.320 --> 01:18:47.320]   You can never do a raw video.
[01:18:47.320 --> 01:18:49.000]   I don't know whether they're going to do all of them.
[01:18:49.000 --> 01:18:53.960]   And I'm not clear whether it'll be the same ProRes or it might be phone ProRes or something.
[01:18:53.960 --> 01:19:02.840]   But Apple ProRes comes in a variety of different flavors from 4, 4, 4, 4 to HQ and 4 to 2 and
[01:19:02.840 --> 01:19:05.840]   a variety of different and then LT and other ones there.
[01:19:05.840 --> 01:19:12.840]   All of them are better than the current version that records to the iPhone because they're
[01:19:12.840 --> 01:19:13.840]   current version.
[01:19:13.840 --> 01:19:22.000]   So, a good example is take a 4K video and you set it to HDR or whatever and you take it
[01:19:22.000 --> 01:19:26.720]   of trees, a lot of trees and then you zoom in on that and what you're going to see is
[01:19:26.720 --> 01:19:29.360]   like what looks like a little just designs.
[01:19:29.360 --> 01:19:32.760]   Because it just can't hold all that data, you know, blowing trees, it can't hold all
[01:19:32.760 --> 01:19:34.160]   that data in the frames.
[01:19:34.160 --> 01:19:38.440]   Apple ProRes will let them do that and also let them have a higher bit depth.
[01:19:38.440 --> 01:19:40.080]   So, you know, 10 bit and so on and so forth.
[01:19:40.080 --> 01:19:41.640]   Now it'll chew up.
[01:19:41.640 --> 01:19:45.800]   You know, I have a feeling that it's not going to necessarily be the 4, 4 because you wouldn't
[01:19:45.800 --> 01:19:47.960]   have spaced record, right?
[01:19:47.960 --> 01:19:53.960]   Well, I think that it would be unlikely that they would implement exactly what they have
[01:19:53.960 --> 01:19:56.440]   there because again, it's not uncompressed.
[01:19:56.440 --> 01:20:00.840]   It is compressed but it's perceptually very, very good.
[01:20:00.840 --> 01:20:03.400]   And so, but it's not like AGBC.
[01:20:03.400 --> 01:20:05.560]   I mean, it's way more data.
[01:20:05.560 --> 01:20:06.560]   What?
[01:20:06.560 --> 01:20:11.920]   I think what people are hoping is that it'll record internally and it'll also let you do
[01:20:11.920 --> 01:20:15.560]   what Apple does, which is the preview modes that are still good enough and are tied to
[01:20:15.560 --> 01:20:19.600]   the original files so that you can edit them much more quickly than you would otherwise.
[01:20:19.600 --> 01:20:22.320]   Sort of the fog being, forget what they call it.
[01:20:22.320 --> 01:20:30.800]   Yeah, so it'll be interesting to see, you know, whether it's, you know, pixel for pixel
[01:20:30.800 --> 01:20:33.160]   and how they're going to implement that.
[01:20:33.160 --> 01:20:36.280]   But the goal will be probably that you have a lot more to edit.
[01:20:36.280 --> 01:20:39.840]   Like you're really turning the phones into real capture devices.
[01:20:39.840 --> 01:20:42.000]   Right now they're still kind of toys.
[01:20:42.000 --> 01:20:44.520]   When it comes to it, it's cool that they can do what they do.
[01:20:44.520 --> 01:20:46.040]   And they do an amazing job.
[01:20:46.040 --> 01:20:47.040]   Pretty good.
[01:20:47.040 --> 01:20:51.320]   But the quality of the capture, as someone who captures on bigger cameras, you're still
[01:20:51.320 --> 01:20:53.080]   like, "Oh, it's cute."
[01:20:53.080 --> 01:20:58.240]   But the sensor and the lenses stand way out.
[01:20:58.240 --> 01:21:02.960]   What's the weak point right now that I think Apple's getting ready to address is what it
[01:21:02.960 --> 01:21:06.080]   saves it in to the phone.
[01:21:06.080 --> 01:21:11.840]   And again, long, you'll run out of drive space really fast depending on how they do it.
[01:21:11.840 --> 01:21:18.800]   My guess is it's going to be some version of ProRes that is not what we normally think
[01:21:18.800 --> 01:21:19.800]   of as ProRes.
[01:21:19.800 --> 01:21:23.760]   It'll be some version for the phone that's way better than a HEVC, but not the ProRes
[01:21:23.760 --> 01:21:25.040]   that we're used to cutting.
[01:21:25.040 --> 01:21:26.040]   But I could be wrong.
[01:21:26.040 --> 01:21:27.040]   Is HEVC that bad?
[01:21:27.040 --> 01:21:28.040]   That's pretty good.
[01:21:28.040 --> 01:21:29.040]   I thought it was pretty good.
[01:21:29.040 --> 01:21:30.880]   HEVC is really good.
[01:21:30.880 --> 01:21:33.040]   I mean, it's really efficient for what it is.
[01:21:33.040 --> 01:21:39.320]   But it's not the replacement for a true, because it's also what we call long-gop, which means
[01:21:39.320 --> 01:21:42.400]   that it saves very few.
[01:21:42.400 --> 01:21:44.600]   It needs to have all the frames there.
[01:21:44.600 --> 01:21:46.240]   So it's cutting it, becomes harder.
[01:21:46.240 --> 01:21:47.920]   It becomes a little more sluggish.
[01:21:47.920 --> 01:21:52.920]   And so what HEVC is really good at is taking a really, really big image and making it a
[01:21:52.920 --> 01:21:56.160]   really small image and keeping an enormous amount of the fidelity.
[01:21:56.160 --> 01:21:58.400]   But it's not keeping all of fidelity.
[01:21:58.400 --> 01:22:03.280]   As you go into ProRes, you're going to get into a possibility of keeping a lot more of
[01:22:03.280 --> 01:22:04.920]   that fidelity that's just impossible.
[01:22:04.920 --> 01:22:07.680]   And it just means it's going to be much, much larger files.
[01:22:07.680 --> 01:22:12.920]   So it's not that it's, but people who want to use the phone that way potentially could.
[01:22:12.920 --> 01:22:17.000]   And it could mean that they're also going to put much more memory in some of the phones.
[01:22:17.000 --> 01:22:23.200]   So the Pro version might have a couple terabytes or whatever in it as far as memory as well.
[01:22:23.200 --> 01:22:24.200]   Yeah.
[01:22:24.200 --> 01:22:29.000]   And you have to transfer it over Wi-Fi because they're not giving you USB-C or Thunderbolt.
[01:22:29.000 --> 01:22:32.680]   Am I foolish to think that this quote filters likes it?
[01:22:32.680 --> 01:22:36.560]   Let me live in delusion for at least another year, Renato.
[01:22:36.560 --> 01:22:43.160]   Let me believe that I will not live long enough to see a portless iPhone.
[01:22:43.160 --> 01:22:45.840]   As sad as that might be that I die.
[01:22:45.840 --> 01:22:51.880]   I think that there's a high probability that it may be portless, but it doesn't mean that
[01:22:51.880 --> 01:22:56.680]   it will not have those kind of contacts that we see inside the iPad that could potentially
[01:22:56.680 --> 01:22:58.120]   live the band support.
[01:22:58.120 --> 01:22:59.120]   40 gigabits.
[01:22:59.120 --> 01:23:02.320]   Way more convenient than USB-C.
[01:23:02.320 --> 01:23:03.560]   Thank God.
[01:23:03.560 --> 01:23:09.400]   Thank you, Rapple, for giving us Pogo pins instead of a USB-C port.
[01:23:09.400 --> 01:23:15.560]   There's always a Google Pixel 6 with the CalXOS on it, Andy, for you.
[01:23:15.560 --> 01:23:16.560]   Hard core.
[01:23:16.560 --> 01:23:17.560]   I'll leave.
[01:23:17.560 --> 01:23:18.560]   I'll leave.
[01:23:18.560 --> 01:23:20.240]   I'll drive over that cliff and that convertible with you.
[01:23:20.240 --> 01:23:21.240]   I want to die with you.
[01:23:21.240 --> 01:23:22.240]   I'll leave.
[01:23:22.240 --> 01:23:23.240]   MKV and Og Vorbis editing.
[01:23:23.240 --> 01:23:25.240]   I'll step away.
[01:23:25.240 --> 01:23:32.040]   There's something satisfying, by the way, about moving to a cabin in the woods and being
[01:23:32.040 --> 01:23:33.040]   off the grid.
[01:23:33.040 --> 01:23:34.600]   I'm just saying.
[01:23:34.600 --> 01:23:37.520]   If you do patent in Comfort Linux, it's even more fun.
[01:23:37.520 --> 01:23:38.640]   Oh, God.
[01:23:38.640 --> 01:23:40.360]   So they do quote.
[01:23:40.360 --> 01:23:46.080]   So Gurman says, "A new filter like sister that improves the look and colors of photos."
[01:23:46.080 --> 01:23:50.960]   Reading between the lines, maybe a LUT system of some kind or what do you think that is?
[01:23:50.960 --> 01:23:53.360]   Maybe they'll bring Gotham back now that this is kind of interesting.
[01:23:53.360 --> 01:23:55.280]   I'm never going to do that.
[01:23:55.280 --> 01:23:57.760]   I'm sorry, I do not get those references.
[01:23:57.760 --> 01:23:58.760]   Sorry.
[01:23:58.760 --> 01:23:59.760]   Go ahead.
[01:23:59.760 --> 01:24:00.760]   Being able to apply LUTs would be amazing.
[01:24:00.760 --> 01:24:01.760]   Wouldn't that be nice?
[01:24:01.760 --> 01:24:02.760]   Yeah.
[01:24:02.760 --> 01:24:06.880]   Have it kind of built in and it opens up a whole new set of things that are in LUTs for people
[01:24:06.880 --> 01:24:10.480]   who are listening or basically what their look up tables.
[01:24:10.480 --> 01:24:11.840]   So they basically just say transfer.
[01:24:11.840 --> 01:24:15.040]   It's like a curve that you'd see in Photoshop, but imagine that in 3D.
[01:24:15.040 --> 01:24:20.680]   And so it's just moving the color information inside of, if you think of color as a cube,
[01:24:20.680 --> 01:24:26.160]   it's moving it inside of that space so that you can do very delicate transforms.
[01:24:26.160 --> 01:24:29.320]   And they come in different numbers of points of resolution.
[01:24:29.320 --> 01:24:33.960]   But anyway, it's how a lot of us transform a lot of video.
[01:24:33.960 --> 01:24:39.320]   And it's not to say that you would want, I know you would, but I would want to do this
[01:24:39.320 --> 01:24:45.520]   3D manipulation, but that if they used a standard like that for filtering, people like Alex
[01:24:45.520 --> 01:24:48.040]   could create LUTs that he could then download.
[01:24:48.040 --> 01:24:50.560]   Yeah, and there are apps that do LUTs now.
[01:24:50.560 --> 01:24:54.160]   I mean, I think that you can do LUTs with Filmic Pro and I think some of that stuff is
[01:24:54.160 --> 01:24:55.160]   already there.
[01:24:55.160 --> 01:24:58.960]   It's not like it doesn't exist, but having it really easy in part of the phone and just
[01:24:58.960 --> 01:25:04.680]   something like, oh, I can load a LUT into it, there's a lot of LUTs out there that would
[01:25:04.680 --> 01:25:06.200]   be people would really enjoy.
[01:25:06.200 --> 01:25:07.200]   Especially in the texture.
[01:25:07.200 --> 01:25:08.200]   Yeah.
[01:25:08.200 --> 01:25:09.200]   So you get to see what it looks like when you shoot it.
[01:25:09.200 --> 01:25:14.920]   Am I crazy to kind of read between the lines on the new filters like system and think maybe
[01:25:14.920 --> 01:25:15.920]   that's LUTs?
[01:25:15.920 --> 01:25:19.080]   If you didn't know what a LUT was, that might be how you'd describe it.
[01:25:19.080 --> 01:25:20.080]   Yeah, exactly.
[01:25:20.080 --> 01:25:23.640]   It's like filters, but they're not.
[01:25:23.640 --> 01:25:25.480]   It's not real, so it could be anything we want it to be.
[01:25:25.480 --> 01:25:26.480]   I know.
[01:25:26.480 --> 01:25:28.320]   It will all be disappointed because it won't be exactly what we want.
[01:25:28.320 --> 01:25:30.080]   But for now we can dream.
[01:25:30.080 --> 01:25:33.280]   We think that it's actually a 200 point LUT.
[01:25:33.280 --> 01:25:35.800]   That doesn't really exist, but it would be amazing.
[01:25:35.800 --> 01:25:38.880]   It's a new filter like system that it brews.
[01:25:38.880 --> 01:25:40.720]   It made a deal with Ari.
[01:25:40.720 --> 01:25:42.960]   The look and colors of photos.
[01:25:42.960 --> 01:25:43.960]   The look.
[01:25:43.960 --> 01:25:44.960]   It sounds like LUTs.
[01:25:44.960 --> 01:25:46.960]   It sounds very much like LUTs.
[01:25:46.960 --> 01:25:50.040]   Like a press person who doesn't know what that is.
[01:25:50.040 --> 01:25:51.040]   Right.
[01:25:51.040 --> 01:25:52.040]   It's a Peter McKinnon.
[01:25:52.040 --> 01:25:53.040]   It's not a lot like that.
[01:25:53.040 --> 01:25:54.280]   Or yeah, I bet Mark does.
[01:25:54.280 --> 01:25:58.960]   Kerman does, but maybe he's not going to put that in Bloomberg.
[01:25:58.960 --> 01:25:59.960]   I don't know.
[01:25:59.960 --> 01:26:00.960]   Does he?
[01:26:00.960 --> 01:26:02.960]   Does he really?
[01:26:02.960 --> 01:26:03.960]   Does he?
[01:26:03.960 --> 01:26:08.320]   Beyond the camera enhancements, the new fine iPhones will get, he says relatively modest
[01:26:08.320 --> 01:26:14.320]   upgrades because of the big redesign this year and the 5G wireless networking.
[01:26:14.320 --> 01:26:15.320]   And so forth.
[01:26:15.320 --> 01:26:17.320]   Getting a fighter modem.
[01:26:17.320 --> 01:26:19.040]   I'm looking forward to that.
[01:26:19.040 --> 01:26:20.040]   Will we get a better modem?
[01:26:20.040 --> 01:26:21.040]   Not a Qualcomm.
[01:26:21.040 --> 01:26:22.040]   Yeah, the X60.
[01:26:22.040 --> 01:26:23.040]   It's still be Qualcomm.
[01:26:23.040 --> 01:26:25.200]   It's the last year we got the X65.
[01:26:25.200 --> 01:26:29.320]   The X55 are going to be the X60, which is on Samsung's 5nm process, so it's not quite
[01:26:29.320 --> 01:26:30.320]   so power hungry.
[01:26:30.320 --> 01:26:31.320]   Good.
[01:26:31.320 --> 01:26:32.560]   It's a better battery life.
[01:26:32.560 --> 01:26:38.520]   Same 5.4 inch and 6.1 inch regular size is 6.7 inch pro.
[01:26:38.520 --> 01:26:39.520]   Same design.
[01:26:39.520 --> 01:26:42.040]   It would be what Apple would call an iPhone.
[01:26:42.040 --> 01:26:43.320]   If you like the small iPhone.
[01:26:43.320 --> 01:26:44.320]   Yeah, it could still be.
[01:26:44.320 --> 01:26:45.320]   It could still be a 12S.
[01:26:45.320 --> 01:26:48.080]   I believe that's a marketing decision.
[01:26:48.080 --> 01:26:49.720]   If they want to goose sales, they use a full number.
[01:26:49.720 --> 01:26:53.560]   If they want to lower expectations, they use an S. But if you like the small version
[01:26:53.560 --> 01:26:56.200]   of the phone, that's apparently the last year they're going to make, at least for a
[01:26:56.200 --> 01:26:59.080]   while, they're going to make a small, a tiny, a mini iPhone.
[01:26:59.080 --> 01:27:02.520]   So if you want that, get it now and then ride that into the sunset like you're John
[01:27:02.520 --> 01:27:05.160]   Moltz.
[01:27:05.160 --> 01:27:12.040]   The ProRes feature he writes would follow last year's edition of ProRaw.
[01:27:12.040 --> 01:27:13.520]   There's more about the filters.
[01:27:13.520 --> 01:27:18.640]   Another feature will let users better control the look of colors and highlights in their
[01:27:18.640 --> 01:27:19.640]   pictures.
[01:27:19.640 --> 01:27:23.480]   Users will be able to choose from several styles to apply to their photos, including
[01:27:23.480 --> 01:27:27.840]   for one for showing colors of either a warmer or cooler temperature while keeping whites
[01:27:27.840 --> 01:27:28.840]   neutral.
[01:27:28.840 --> 01:27:33.200]   Another option will add a more dramatic look with deeper shadows and more contrast.
[01:27:33.200 --> 01:27:37.440]   The company is planning a more balanced style for showing shadows and true-to-life colors
[01:27:37.440 --> 01:27:39.440]   with a brighter appearance.
[01:27:39.440 --> 01:27:45.840]   It will differ from standard filters by precisely applying changes to objects and people across
[01:27:45.840 --> 01:27:49.960]   the photos using AI rather than a single filter across the entire picture.
[01:27:49.960 --> 01:27:52.840]   Oh, that isn't nuts, but that's something interesting.
[01:27:52.840 --> 01:27:54.240]   That's content-aware.
[01:27:54.240 --> 01:27:59.040]   Separating lighting effects for foreground and background will be pretty big.
[01:27:59.040 --> 01:28:04.080]   Well, and that's potentially using the LiDAR to know what are objects and what aren't.
[01:28:04.080 --> 01:28:08.000]   So it can use AI, but in some of the phones it'll actually know, and these are subjects
[01:28:08.000 --> 01:28:09.680]   for this and these aren't.
[01:28:09.680 --> 01:28:11.360]   So it's really interesting.
[01:28:11.360 --> 01:28:15.920]   At the very bottom of the article he says the company is also working on a revamped MacBook
[01:28:15.920 --> 01:28:23.480]   Pro's with in-house chips, likely to be dubbed M1X, a redesigned iPad Mini, and an entry-level
[01:28:23.480 --> 01:28:24.480]   iPad geared at students.
[01:28:24.480 --> 01:28:28.640]   It's also preparing new Apple watches and entry-level AirPods.
[01:28:28.640 --> 01:28:34.640]   Obviously, I would not obviously, but I doubt they'd announce all of that next month.
[01:28:34.640 --> 01:28:39.720]   AirPods are easy to float into an iPhone announcement, and then it just depends if they're ready,
[01:28:39.720 --> 01:28:41.560]   because they want to sell them for the school season if they can.
[01:28:41.560 --> 01:28:43.480]   If they're not really allowed to do it.
[01:28:43.480 --> 01:28:44.480]   But Apple's...
[01:28:44.480 --> 01:28:45.480]   People...
[01:28:45.480 --> 01:28:46.480]   A lot of the stuff becomes practical.
[01:28:46.480 --> 01:28:47.720]   It's like Apple's like, "Is it ready to ship?"
[01:28:47.720 --> 01:28:48.720]   "Yes."
[01:28:48.720 --> 01:28:49.720]   "What's the next event?"
[01:28:49.720 --> 01:28:50.720]   "Okay, do it."
[01:28:50.720 --> 01:28:52.440]   It's a lot more complicated than that.
[01:28:52.440 --> 01:28:55.880]   But I would think that there's also a sense of we don't want to dilute the impact of the
[01:28:55.880 --> 01:28:56.880]   iPhone, right?
[01:28:56.880 --> 01:29:01.440]   They want to sell, and there's people who are buying a MacBook who won't buy an iPhone.
[01:29:01.440 --> 01:29:02.440]   Right.
[01:29:02.440 --> 01:29:06.600]   But also considering how much money comes in because of AirPods, the sooner you can turn
[01:29:06.600 --> 01:29:10.280]   those taps on, I'm sure the better as far as Apple's concerned.
[01:29:10.280 --> 01:29:11.280]   Yeah.
[01:29:11.280 --> 01:29:12.320]   Nice and simple.
[01:29:12.320 --> 01:29:18.000]   If you were worried about privacy as an iPhone owner, you definitely don't want to be a call
[01:29:18.000 --> 01:29:19.000]   center worker.
[01:29:19.000 --> 01:29:22.800]   Apple is going to monitor them with cameras in their houses.
[01:29:22.800 --> 01:29:24.840]   Apple denies this, though.
[01:29:24.840 --> 01:29:25.840]   They have some important...
[01:29:25.840 --> 01:29:27.560]   This is from NBC News.
[01:29:27.560 --> 01:29:28.560]   Yeah.
[01:29:28.560 --> 01:29:31.200]   This one's a little bit complicated.
[01:29:31.200 --> 01:29:32.200]   They're subcontractors.
[01:29:32.200 --> 01:29:33.200]   Subcontractors.
[01:29:33.200 --> 01:29:35.240]   So they're not working directly for Apple.
[01:29:35.240 --> 01:29:39.240]   A lot of them are now working from home, as opposed from working from a call center.
[01:29:39.240 --> 01:29:45.120]   And there is an international blight of software that's being used to manage these call centers
[01:29:45.120 --> 01:29:50.280]   remotely, some of which use artificial intelligence based on cameras to detect, "Hey, this person
[01:29:50.280 --> 01:29:52.080]   had their cell phone on their desk.
[01:29:52.080 --> 01:29:53.160]   They shouldn't have it on their desk."
[01:29:53.160 --> 01:29:59.520]   "Hey, they were not typing or mousing at this point and sent all these reports to managers."
[01:29:59.520 --> 01:30:03.400]   And so they're complaining that these individual employees are complaining that they're immediate
[01:30:03.400 --> 01:30:09.760]   managers and the subcontractors they're working for are asking/ insisting that they have these
[01:30:09.760 --> 01:30:10.920]   cameras installed.
[01:30:10.920 --> 01:30:15.160]   The pushback is not only just on the principle of surveillance, but also that, "Hey, look,
[01:30:15.160 --> 01:30:16.680]   I am working from home.
[01:30:16.680 --> 01:30:18.880]   This camera is in my bedroom on my computer.
[01:30:18.880 --> 01:30:20.640]   I don't want a camera in my bedroom."
[01:30:20.640 --> 01:30:23.280]   They're also because they can't really control...
[01:30:23.280 --> 01:30:28.080]   Because the contractor can't control what they're going to catch, they have to ask for
[01:30:28.080 --> 01:30:31.840]   permission to also take video of kids, any other people in the house.
[01:30:31.840 --> 01:30:33.520]   So that's what the pushback is about.
[01:30:33.520 --> 01:30:38.760]   Apple said that they did a review of all of their subcontractors in the area and didn't
[01:30:38.760 --> 01:30:40.000]   find any problems.
[01:30:40.000 --> 01:30:41.000]   What I found...
[01:30:41.000 --> 01:30:44.280]   The only thing that was not satisfying to me was that I don't...
[01:30:44.280 --> 01:30:48.760]   I don't think they specified if they did this after these complaints were coming out and
[01:30:48.760 --> 01:30:53.320]   if they were doing an investigation, they specifically on these problems.
[01:30:53.320 --> 01:30:58.800]   So it's wrong to say that Apple is demanding cameras being put in these workers' homes.
[01:30:58.800 --> 01:31:03.680]   However, I want Apple to say that, "Hey, we've looked at this particular request and made
[01:31:03.680 --> 01:31:07.840]   sure that this contractor is not making this demand that we don't approve of and that Earth's
[01:31:07.840 --> 01:31:11.440]   counter to our agreement."
[01:31:11.440 --> 01:31:16.600]   Apple says the company prohibits the use of video or photographic monitoring by our suppliers
[01:31:16.600 --> 01:31:21.280]   and it's confirmed that teleperformance, which is the supplier that NBC was talking
[01:31:21.280 --> 01:31:26.520]   about, does not use video monitoring for any of their teams working with Apple.
[01:31:26.520 --> 01:31:33.880]   Apple has also, according to the Verge, been shutting down employee-run surveys on pay
[01:31:33.880 --> 01:31:41.320]   equity, which is, according to labor law illegal.
[01:31:41.320 --> 01:31:44.680]   Apple insisted does not have a problem with pay and equality.
[01:31:44.680 --> 01:31:48.960]   Skeptical Apple employees, this is from the Verge, have been trying to verify that claim
[01:31:48.960 --> 01:31:54.320]   by sending out informal surveys on how much people make, but the company shut down the
[01:31:54.320 --> 01:32:03.280]   three of those surveys, citing stringent rules on how employees can collect data.
[01:32:03.280 --> 01:32:09.080]   I actually understand why they would do that, but apparently it's illegal, according to US
[01:32:09.080 --> 01:32:10.080]   law.
[01:32:10.080 --> 01:32:13.840]   Say you can add eggs faster by doing it, everyone will sign up.
[01:32:13.840 --> 01:32:15.440]   How are your eggs, by the way, Renee?
[01:32:15.440 --> 01:32:20.440]   I hear they're hatching fast.
[01:32:20.440 --> 01:32:25.640]   No, just like you on the Pokémon GO, I turned on, what do they call that feature, where it
[01:32:25.640 --> 01:32:27.600]   monitors your movement even when you're...
[01:32:27.600 --> 01:32:31.520]   Yeah, the thing that I spent years protesting that I would never, ever give away is, "It
[01:32:31.520 --> 01:32:32.680]   makes me turn on in a second.
[01:32:32.680 --> 01:32:33.680]   I hate myself."
[01:32:33.680 --> 01:32:36.080]   It's just the antique, a Google company.
[01:32:36.080 --> 01:32:44.320]   Quickly, though, the law that's being talked about there is that it's illegal to prevent
[01:32:44.320 --> 01:32:50.840]   employees from possibly organizing themselves on company property that from a long time ago
[01:32:50.840 --> 01:32:55.760]   with recognizing the fact that that's the best opportunity that people have to organize.
[01:32:55.760 --> 01:32:58.360]   You can't go house to house, town to town.
[01:32:58.360 --> 01:33:01.880]   When everyone's sitting together in one space during the lunch hour, that's a great place
[01:33:01.880 --> 01:33:05.080]   to talk about the common grievances.
[01:33:05.080 --> 01:33:07.080]   But it's a difficult...
[01:33:07.080 --> 01:33:11.480]   I think it becomes a little more complicated when it becomes okay, but if we're talking
[01:33:11.480 --> 01:33:17.600]   about this in 1970s, lingo, is it okay to use the company's mimeograph machine to print
[01:33:17.600 --> 01:33:20.680]   up these ballots about info things?
[01:33:20.680 --> 01:33:25.520]   And a lot of this stuff is, is it okay to use internal mailing lists, internal message
[01:33:25.520 --> 01:33:27.200]   boards to do labor organizing?
[01:33:27.200 --> 01:33:30.360]   I don't think that question has really been settled adequately.
[01:33:30.360 --> 01:33:31.360]   Yeah, I don't...
[01:33:31.360 --> 01:33:33.640]   There's lawyers that say a lot of things.
[01:33:33.640 --> 01:33:34.640]   Right.
[01:33:34.640 --> 01:33:35.800]   I can always get a lawyer to say any things.
[01:33:35.800 --> 01:33:37.800]   So, we haven't got a court yet.
[01:33:37.800 --> 01:33:41.760]   And until the Supreme Court tells us that it's illegal, then it doesn't really exist.
[01:33:41.760 --> 01:33:43.120]   It's just a lawyer's opinion.
[01:33:43.120 --> 01:33:47.960]   And so, a lawyer is saying it is good press, but it just doesn't mean anything.
[01:33:47.960 --> 01:33:51.360]   And I think that there's a slippery slope here that...
[01:33:51.360 --> 01:33:55.680]   Obviously, people need to have the right to talk to each other about this stuff.
[01:33:55.680 --> 01:33:58.720]   But I think that employees can get pretty...
[01:33:58.720 --> 01:34:03.800]   I've been in situations where I was an employee that wasn't really interested in playing any
[01:34:03.800 --> 01:34:06.120]   employee reindeer games.
[01:34:06.120 --> 01:34:13.000]   And I got a lot of pressure from other employees to be part of all the things that they wanted
[01:34:13.000 --> 01:34:14.000]   to do.
[01:34:14.000 --> 01:34:16.800]   And I'm not going to get into the details of it, but I felt a lot of pressure of it.
[01:34:16.800 --> 01:34:17.800]   And I didn't think that the...
[01:34:17.800 --> 01:34:21.720]   I didn't think they should be doing that at the company, so around me.
[01:34:21.720 --> 01:34:23.800]   And so, like, I just want to be left alone.
[01:34:23.800 --> 01:34:26.560]   So, it sounds like, oh, Apple is just...
[01:34:26.560 --> 01:34:28.240]   But again, it's people's privacy.
[01:34:28.240 --> 01:34:33.120]   It's their information that people are asking for.
[01:34:33.120 --> 01:34:36.640]   And that may or may not be appropriate, and they should probably take it to court and find
[01:34:36.640 --> 01:34:37.640]   out.
[01:34:37.640 --> 01:34:42.240]   And I think that if the employees really feel like this, the reason they're probably publishing
[01:34:42.240 --> 01:34:45.000]   this is because they probably don't have a case.
[01:34:45.000 --> 01:34:47.640]   And so, they've signed away a bunch of agreements.
[01:34:47.640 --> 01:34:50.240]   Well, they should then take it to court.
[01:34:50.240 --> 01:34:56.080]   But if they should take Apple to court over it, but I think that as an employee, I generally
[01:34:56.080 --> 01:34:57.080]   don't like...
[01:34:57.080 --> 01:35:00.000]   I will admit, when I was an employee, I'm an employee now.
[01:35:00.000 --> 01:35:02.320]   I don't really like getting into the drama around it.
[01:35:02.320 --> 01:35:05.560]   I just want to do my thing, and I mostly just want to be left alone.
[01:35:05.560 --> 01:35:07.960]   And so, the thing is, is I have the right to be left alone, too.
[01:35:07.960 --> 01:35:12.160]   It's my guess that Apple's interest in preventing this is not so much to make employees not
[01:35:12.160 --> 01:35:17.880]   feel peer pressure, as no company wants its employees to compare salaries, period.
[01:35:17.880 --> 01:35:19.080]   Because they can do that now.
[01:35:19.080 --> 01:35:22.080]   I mean, they can do all of the...
[01:35:22.080 --> 01:35:23.480]   Yeah, they should really...
[01:35:23.480 --> 01:35:26.840]   Should they be allowed to use company resources to do that or to them?
[01:35:26.840 --> 01:35:32.280]   Well, also, should we also point out that, by and large, it's not white.
[01:35:32.280 --> 01:35:35.080]   Men who are complaining about pay discrepancies?
[01:35:35.080 --> 01:35:36.080]   Right.
[01:35:36.080 --> 01:35:37.680]   No, no, this is protected classes.
[01:35:37.680 --> 01:35:42.640]   And that's one of the things the attorney said is, you've got to be very careful about
[01:35:42.640 --> 01:35:46.840]   discriminating protected classes, and that might be true to that.
[01:35:46.840 --> 01:35:51.840]   So, but I think people who are not white men inside Apple might feel differently about
[01:35:51.840 --> 01:35:55.680]   use of company mailing lists to talk about pay discrepancies.
[01:35:55.680 --> 01:35:59.480]   And people in protected classes might be sensitive to it, too.
[01:35:59.480 --> 01:36:02.520]   You know, like we just have to understand that it's not...
[01:36:02.520 --> 01:36:03.760]   Like people can get very...
[01:36:03.760 --> 01:36:06.760]   People who are militant can get really to be a pain in the neck.
[01:36:06.760 --> 01:36:07.760]   Right.
[01:36:07.760 --> 01:36:10.120]   And so the thing is, is that to people who just don't want to play, like they don't want
[01:36:10.120 --> 01:36:11.120]   to get...
[01:36:11.120 --> 01:36:12.120]   They don't want to get played.
[01:36:12.120 --> 01:36:13.120]   No evidence in that act.
[01:36:13.120 --> 01:36:15.120]   No evidence at all that that act.
[01:36:15.120 --> 01:36:16.120]   It just happens all the time.
[01:36:16.120 --> 01:36:17.920]   It may not happen here.
[01:36:17.920 --> 01:36:19.720]   It's often...
[01:36:19.720 --> 01:36:20.720]   Okay.
[01:36:20.720 --> 01:36:25.240]   We started off about talking about slippery slopes and how dangerous something can be
[01:36:25.240 --> 01:36:26.400]   in principle.
[01:36:26.400 --> 01:36:29.640]   For me, I think that we're ending the show, close to ending the show, on kind of the
[01:36:29.640 --> 01:36:34.120]   same note, where it is very, very dangerous when there are steps taken to make it more
[01:36:34.120 --> 01:36:37.160]   difficult for employees to organize.
[01:36:37.160 --> 01:36:42.240]   And so I think that the natural gravity well here should be to make it easier for people
[01:36:42.240 --> 01:36:44.400]   to organize rather than to make it harder.
[01:36:44.400 --> 01:36:45.400]   I don't...
[01:36:45.400 --> 01:36:46.400]   I think that Apple is...
[01:36:46.400 --> 01:36:50.720]   I tend to believe that Apple is being honest about the reasons why they're shutting this
[01:36:50.720 --> 01:36:51.720]   down.
[01:36:51.720 --> 01:36:58.520]   They're afraid of personal data being compromised, even voluntarily.
[01:36:58.520 --> 01:37:02.880]   However, I think that we should make sure that we preserve the ability of workers to
[01:37:02.880 --> 01:37:06.320]   organize and to, again, share information willingly.
[01:37:06.320 --> 01:37:10.680]   Those who wish to share information willingly between themselves should be able to do so
[01:37:10.680 --> 01:37:15.240]   without interference from management or corporate leadership.
[01:37:15.240 --> 01:37:19.080]   Our show today brought to you by AT&T Active Armor.
[01:37:19.080 --> 01:37:21.640]   We thank AT&T for their support.
[01:37:21.640 --> 01:37:24.440]   We rely so much on our phones these days, you know.
[01:37:24.440 --> 01:37:29.760]   I know you perhaps listened to the show or watched the show on your phone as well as your
[01:37:29.760 --> 01:37:34.840]   other favorite podcast, or maybe on your phone catching up with the family as I do every week
[01:37:34.840 --> 01:37:42.840]   on those weekly video calls or watching maybe the latest streaming content on HBO Max,
[01:37:42.840 --> 01:37:44.120]   Suicide Squad.
[01:37:44.120 --> 01:37:48.320]   The last thing you want, you're in the middle of a great scene, and so is the Suicide Squad
[01:37:48.320 --> 01:37:56.000]   to get a fraudly link call saying your auto insurance is about to expire or something
[01:37:56.000 --> 01:37:57.000]   like that.
[01:37:57.000 --> 01:38:02.120]   It got so bad at one point that I just stopped answering the phone.
[01:38:02.120 --> 01:38:07.920]   Thankfully AT&T makes customer security a priority and blocks those pesky calls.
[01:38:07.920 --> 01:38:08.920]   It's not complicated.
[01:38:08.920 --> 01:38:15.960]   AT&T Active Armor 24/7 proactive network security and fraud call blocking to help stop threats
[01:38:15.960 --> 01:38:18.760]   at no extra charge.
[01:38:18.760 --> 01:38:20.560]   Capitable devices service required.
[01:38:20.560 --> 01:38:25.480]   Visit att.com/active armor for details.
[01:38:25.480 --> 01:38:27.440]   Thank you, AT&T.
[01:38:27.440 --> 01:38:29.680]   Big victory for Apple.
[01:38:29.680 --> 01:38:33.720]   I always love seeing these in Marshall, Texas.
[01:38:33.720 --> 01:38:36.640]   Home of the patent troll.
[01:38:36.640 --> 01:38:40.080]   The judge actually said, "Yeah, well, wait a minute, not this time."
[01:38:40.080 --> 01:38:43.160]   There is a non-practicing entity.
[01:38:43.160 --> 01:38:47.760]   That's the politically correct way of calling it a patent troll.
[01:38:47.760 --> 01:38:59.080]   Personalized media communications, which was looking for $308.5 million from Apple saying
[01:38:59.080 --> 01:39:02.840]   that Apple was infringing one of their patents.
[01:39:02.840 --> 01:39:07.960]   But the judge didn't like the way the patent had been created.
[01:39:07.960 --> 01:39:15.880]   It seems that pre-1995, the US Patent and Trademark Office would start the term of the patent
[01:39:15.880 --> 01:39:17.960]   when the patent was granted.
[01:39:17.960 --> 01:39:24.080]   You'd get 17 years from the date of grant, not from the date of application.
[01:39:24.080 --> 01:39:28.120]   Personalized media, according to the judge, was taking advantage of this by applying but
[01:39:28.120 --> 01:39:33.320]   then slow walking the rest of it until they would see that a patent could have some value.
[01:39:33.320 --> 01:39:39.000]   Then, once somebody else was using it, then they'd say, "Yeah, go ahead and give them
[01:39:39.000 --> 01:39:41.000]   17 years."
[01:39:41.000 --> 01:39:46.720]   The company filed hundreds of applications in the late '80s and early 1990s but didn't
[01:39:46.720 --> 01:39:49.440]   get patents until 2010.
[01:39:49.440 --> 01:39:52.800]   101 have been issued since then.
[01:39:52.800 --> 01:39:59.200]   The judge, Rodney Gilstrapp of Marshall, Texas said, "You get nothing.
[01:39:59.200 --> 01:40:04.200]   In fact, you might have to pay some of Apple's legal costs because of this.
[01:40:04.200 --> 01:40:06.880]   They call it a "submarineing" of patents.
[01:40:06.880 --> 01:40:09.360]   By the way, the patent law changed in 1995.
[01:40:09.360 --> 01:40:16.040]   It is now 20 years from the date of application.
[01:40:16.040 --> 01:40:17.040]   Good news for Apple.
[01:40:17.040 --> 01:40:20.880]   $308 million they won't have to pay.
[01:40:20.880 --> 01:40:30.080]   This fair play software was ruled infringing of this patent and the jury awarded a royalty
[01:40:30.080 --> 01:40:34.760]   of $308.5 million.
[01:40:34.760 --> 01:40:35.760]   Judge, throw it out.
[01:40:35.760 --> 01:40:37.960]   That doesn't happen that often.
[01:40:37.960 --> 01:40:43.200]   Even in Texas, I was about to say, "You know, you really screwed this up."
[01:40:43.200 --> 01:40:44.200]   Exactly.
[01:40:44.200 --> 01:40:48.800]   We'd love to give you that money but maybe not.
[01:40:48.800 --> 01:40:56.120]   A long island man has credited the Apple Watch with saving his life after a serious fall.
[01:40:56.120 --> 01:40:57.640]   He was only 25.
[01:40:57.640 --> 01:40:59.760]   An active guy rides hikes.
[01:40:59.760 --> 01:41:02.560]   He's a Peloton sales specialist.
[01:41:02.560 --> 01:41:05.760]   He has four marathons under his belt.
[01:41:05.760 --> 01:41:12.720]   He decided to go to the hospital after suffering from severe abdominal pain for days.
[01:41:12.720 --> 01:41:16.000]   Accompanied by his dad, he went to the emergency room during the visit.
[01:41:16.000 --> 01:41:20.600]   He went to the restroom where he passed out.
[01:41:20.600 --> 01:41:21.600]   Oomp.
[01:41:21.600 --> 01:41:25.200]   Fortunately, his Apple Watch called dad.
[01:41:25.200 --> 01:41:32.120]   Dad rushed into the bathroom and immediately got hospital staff to his side.
[01:41:32.120 --> 01:41:36.960]   Fortunately, along with a fractured skull, he had life-threatening hematomas and underwent
[01:41:36.960 --> 01:41:45.160]   emergency brain surgery fortunately that watch notified his dad promptly.
[01:41:45.160 --> 01:41:46.640]   There's a lot of these stories.
[01:41:46.640 --> 01:41:48.240]   I hear them all the time now.
[01:41:48.240 --> 01:41:49.240]   It's really good.
[01:41:49.240 --> 01:41:54.840]   That's why I got my mom out one of those for the fall detection.
[01:41:54.840 --> 01:41:57.480]   I don't care about the 2022 MacBook Air.
[01:41:57.480 --> 01:41:58.680]   Should I talk about it?
[01:41:58.680 --> 01:42:01.280]   Actually, maybe we should because it does have one feature.
[01:42:01.280 --> 01:42:06.680]   A lot of us who were looking longingly at those iMacs wanted.
[01:42:06.680 --> 01:42:07.680]   "Kala!"
[01:42:07.680 --> 01:42:11.160]   Do you think this is Ming-Chi Kuo?
[01:42:11.160 --> 01:42:13.360]   As you say, "Gwomen-Chi"?
[01:42:13.360 --> 01:42:15.360]   Or whatever you say.
[01:42:15.360 --> 01:42:16.360]   "Gwomen-Chi"?
[01:42:16.360 --> 01:42:17.360]   "Gwomen-Chi"?
[01:42:17.360 --> 01:42:18.360]   You did Chinese.
[01:42:18.360 --> 01:42:19.360]   "Gwomen-Chi"?
[01:42:19.360 --> 01:42:26.400]   He says in mid 2022, a MacBook Air with a mini LED screen will come out with multiple
[01:42:26.400 --> 01:42:32.040]   colors which is actually a bummer because I was going to get that 16-inch MacBook Pro
[01:42:32.040 --> 01:42:35.040]   this fall but maybe it'll be worth waiting because the colors aren't pretty.
[01:42:35.040 --> 01:42:36.040]   You're going to get both.
[01:42:36.040 --> 01:42:37.040]   I mean, come on.
[01:42:37.040 --> 01:42:38.040]   Okay, yeah, sure.
[01:42:38.040 --> 01:42:40.000]   Why not?
[01:42:40.000 --> 01:42:41.800]   That means John will get the 16-inch.
[01:42:41.800 --> 01:42:44.000]   John's happy about that with the M1X.
[01:42:44.000 --> 01:42:46.720]   Do you think actually, German was saying M1X?
[01:42:46.720 --> 01:42:48.640]   Do you think that's...
[01:42:48.640 --> 01:42:49.640]   I saw...
[01:42:49.640 --> 01:42:50.640]   M1X is going to be...
[01:42:50.640 --> 01:42:55.360]   So the way people get so confused, but the way to think about it is Apple has generations
[01:42:55.360 --> 01:42:56.640]   and then scale as well.
[01:42:56.640 --> 01:42:59.760]   So Intel has Skylake and then KBlake.
[01:42:59.760 --> 01:43:05.360]   But in each of those, there's the i3, the i5, the i7, the i9.
[01:43:05.360 --> 01:43:10.080]   And so there's the M1 silicon generation which is the same as the A14 in the iPhone.
[01:43:10.080 --> 01:43:12.320]   And then there's the A14 and then there's got more cores.
[01:43:12.320 --> 01:43:13.320]   It's the M1.
[01:43:13.320 --> 01:43:14.320]   It's got more cores.
[01:43:14.320 --> 01:43:15.320]   It's the M1X.
[01:43:15.320 --> 01:43:18.640]   Then there'll be an A15, M2, M2X.
[01:43:18.640 --> 01:43:22.520]   So it's basically the silicon generation and then the amount of cores that it has.
[01:43:22.520 --> 01:43:24.600]   And you want more cores on a Pro machine.
[01:43:24.600 --> 01:43:29.560]   The M2 is going to be more efficient and, you know, like better, like more advanced,
[01:43:29.560 --> 01:43:35.360]   newer, more novel cores but efficiency cores whereas the X1s will be the big scaled cores.
[01:43:35.360 --> 01:43:37.880]   Ed Hardy writing in Kulte-Mac last weekend.
[01:43:37.880 --> 01:43:40.920]   I didn't mention it but it's appropriate now.
[01:43:40.920 --> 01:43:47.440]   Said that the Apple M1X processor would be a billion dollar mistake.
[01:43:47.440 --> 01:43:52.400]   He says you should call it the M2 because...
[01:43:52.400 --> 01:43:54.240]   You should call it the M2.
[01:43:54.240 --> 01:43:55.240]   Huh?
[01:43:55.240 --> 01:43:56.680]   Then what do you call the M2 in a car?
[01:43:56.680 --> 01:43:57.680]   M3.
[01:43:57.680 --> 01:43:58.680]   That's so difficult.
[01:43:58.680 --> 01:44:02.880]   But then the M3, you're going to have five numbers a year that way because they're going
[01:44:02.880 --> 01:44:04.760]   to scale to a Mac Pro.
[01:44:04.760 --> 01:44:08.200]   He says it would mean releasing new flagship MacBooks with the M1X.
[01:44:08.200 --> 01:44:10.480]   So we're obsolete on day one.
[01:44:10.480 --> 01:44:15.560]   They debut with what's essentially 2020 chips in late 2021.
[01:44:15.560 --> 01:44:17.720]   He said, "Should Apple make this mistake?
[01:44:17.720 --> 01:44:22.400]   You should absolutely not buy these computers because they will certainly add the M2 processor
[01:44:22.400 --> 01:44:25.200]   to the same MacBooks next year."
[01:44:25.200 --> 01:44:27.360]   But then they'll say don't buy it away from it.
[01:44:27.360 --> 01:44:28.720]   I think Apple's done this before.
[01:44:28.720 --> 01:44:34.520]   They released an iPad Pro with an A12Z when they'd already released an A13 on the iPhone.
[01:44:34.520 --> 01:44:37.080]   So the iPhone had more recent cores than the iPad.
[01:44:37.080 --> 01:44:40.920]   But the iPad had way more cores, which is what people who buy that care about.
[01:44:40.920 --> 01:44:43.560]   It's such a weird, semanticl argument to make.
[01:44:43.560 --> 01:44:46.480]   And then it destroys our ability to know what generation the chip is.
[01:44:46.480 --> 01:44:50.440]   How would I know if every chip gets a new number, there's no easy way to tell what generation
[01:44:50.440 --> 01:44:52.440]   the silicon is anymore?
[01:44:52.440 --> 01:45:00.040]   So he's just talking about a name, I guess, not the actual design of the chip.
[01:45:00.040 --> 01:45:04.400]   He says the problem is if you do an M1X, nobody's going to buy those knowing the M2's coming
[01:45:04.400 --> 01:45:25.040]   out next year and so you're going to have a billion dollars of
[01:45:25.040 --> 01:45:32.800]   would be yeah exactly with the M2 be noticeably faster than the M1 X. Renee so
[01:45:32.800 --> 01:45:37.620]   It depends on how you're defining speed. Apple Apple every generation is about 20% faster.
[01:45:37.620 --> 01:45:42.180]   Sometimes the graphics are a little bit faster than that. Then they have their more efficient because
[01:45:42.180 --> 01:45:46.660]   they typically have better better node processes. So it would be single core
[01:45:46.660 --> 01:45:52.240]   would be better like same way the iPhone 11 iPhone 12 single core was better than
[01:45:52.240 --> 01:45:56.560]   the iPad Pro single core but the iPad Pro at twice as many cores so anything
[01:45:56.560 --> 01:46:00.480]   that you do that involves it all kind of scalability was still way better.
[01:46:00.480 --> 01:46:05.080]   What about GPUs because honestly I think that's going to become more and more of
[01:46:05.080 --> 01:46:09.560]   an issue since Apple will no longer use third-party graphics processors. We want
[01:46:09.560 --> 01:46:16.200]   to see the M series chips have good strong GPUs and video capable quality or at
[01:46:16.200 --> 01:46:19.960]   least Radeon quality. They hired all those guys they hired so many NVIDIA and AMD
[01:46:19.960 --> 01:46:23.140]   people over the last few years but Alex is last week point they won't be
[01:46:23.140 --> 01:46:27.160]   CUDA cores. So it's like something that'll never happen. I think that I think that
[01:46:27.160 --> 01:46:31.520]   that affects external apps that want to be cross-platform and want to be able to
[01:46:31.520 --> 01:46:35.920]   call to CUDA cores or whatever but I think that the issue is is that the way
[01:46:35.920 --> 01:46:41.600]   that the operating system the way that the hardware and software use the GPU and
[01:46:41.600 --> 01:46:46.400]   CPU and the RAM is so different and I and I think also what we're going to see
[01:46:46.400 --> 01:46:52.640]   again what I kept on thinking about with Apple's financial report was that
[01:46:52.640 --> 01:46:57.640]   legacy you know that talking about legacy components I think that what we're
[01:46:57.640 --> 01:47:01.440]   probably going to see is more and more unification under Apple's you know
[01:47:01.440 --> 01:47:05.200]   building all of these components that are tighter together I started thinking
[01:47:05.200 --> 01:47:10.200]   about I don't think I don't think this is necessarily the future but like could
[01:47:10.200 --> 01:47:12.880]   they actually make the whole thing just on a chip. Like they just print a chip
[01:47:12.880 --> 01:47:15.720]   and then put it in the thing you know like there's very little external
[01:47:15.720 --> 01:47:20.000]   components. I think you're doing that. I thought that the M1 did have the GPU on
[01:47:20.000 --> 01:47:22.520]   the same die. Well but I'm talking about I think they're gonna but there's all
[01:47:22.520 --> 01:47:25.480]   these other components that are in the file I see that are separate. There are
[01:47:25.480 --> 01:47:28.960]   how many of those things become how many of those things keep on finding their
[01:47:28.960 --> 01:47:31.720]   way onto the chip as it as it keeps moving forward. There's some
[01:47:31.720 --> 01:47:36.000]   inefficiencies in that as well but there's also. Right. On die is actually
[01:47:36.000 --> 01:47:40.680]   part of the process or on packages in the plastic thing and there is a lot of
[01:47:40.680 --> 01:47:45.080]   the I mean that's where the way it is right now. Yeah yeah. So so the thing is
[01:47:45.080 --> 01:47:48.840]   is that what we're finding is is that the amount of RAM you need is not as
[01:47:48.840 --> 01:47:51.960]   high as we thought it would be right now because of the way it's processing it.
[01:47:51.960 --> 01:47:57.120]   The GPU GPU and CPU are going to operate differently so it's not really there's
[01:47:57.120 --> 01:48:00.720]   no apples to apples comparison and Apple could theoretically have something
[01:48:00.720 --> 01:48:04.680]   that's much less expensive to make much lower energy and still perform as well
[01:48:04.680 --> 01:48:09.120]   as many very high performance GPUs that have to live outside of that. There's a
[01:48:09.120 --> 01:48:16.560]   massive efficiency loss in putting a card in a slot. You know like that that is
[01:48:16.560 --> 01:48:21.720]   there so they have to overpower all of that. Yeah and so that that's they have
[01:48:21.720 --> 01:48:26.320]   to overpower all of the inefficiencies of the of the external bus that Apple is
[01:48:26.320 --> 01:48:29.360]   not going to have to do and so you could theoretically have just the same
[01:48:29.360 --> 01:48:37.920]   graphics performance without a you know without a discrete card. Good. Maybe I'll
[01:48:37.920 --> 01:48:43.200]   buy the color Mac book here instead. Purple. It's all about purple. I don't know. I
[01:48:43.200 --> 01:48:50.280]   have pink Airpod Max or I don't know they look pink maybe they're red
[01:48:50.280 --> 01:48:55.840]   supposedly but I just bought more on Mac minis. Did you? Yeah you know because
[01:48:55.840 --> 01:49:01.840]   the photogrammetry I was talking to a friend of mine and and and Brent
[01:49:01.840 --> 01:49:05.400]   Brench anyway I was talking to a friend and he's he's like oh the
[01:49:05.400 --> 01:49:09.880]   photogrammetry I the listing is 16 gigs so you should. So I had to miss I'm
[01:49:09.880 --> 01:49:12.600]   waiting for it now because I had to order order one that because all the
[01:49:12.600 --> 01:49:14.960]   other ones I've gotten to rate gigs because then they do everything I need
[01:49:14.960 --> 01:49:18.800]   them to do it is that amazing. Yeah it's just but for photogrammetry you think
[01:49:18.800 --> 01:49:22.800]   you need more. Well I'm gonna test it I'm gonna take take an eight good one and I've
[01:49:22.800 --> 01:49:27.080]   got five of the eight gigs already so I'm gonna play with it. Yeah let's hear I'd
[01:49:27.080 --> 01:49:30.960]   love to know. Yeah actually if there is a difference. Yeah yeah. Just just just just
[01:49:30.960 --> 01:49:35.520]   as a matter of principle MacBook Airs and iMacs should be available in colors.
[01:49:35.520 --> 01:49:40.760]   I agree and not gray or different shade of gray it's like it should be
[01:49:40.760 --> 01:49:46.480]   rainbow spectrum. Yes the pros want to be gray let them. Yeah but the rest of us
[01:49:46.480 --> 01:49:51.480]   like color. Let's just know what I remember what it was like to be young.
[01:49:51.480 --> 01:49:55.200]   I was talking to someone about laptops the other day and I was like you know I
[01:49:55.200 --> 01:50:00.840]   all I do now has been time on my my iMac and my Mac minis and my iPad and my
[01:50:00.840 --> 01:50:05.560]   little my poor little MacBook Pro doesn't come out very often you know because
[01:50:05.560 --> 01:50:08.120]   it's just it's you know I'd rather have the bigger machine and the bigger screens
[01:50:08.120 --> 01:50:11.160]   or I you know because we just don't travel as much as we used to or I don't
[01:50:11.160 --> 01:50:17.440]   travel as much as I used to. Yeah I have to say my MacBook Pro is like by my side
[01:50:17.440 --> 01:50:21.160]   as I move around the house. I travel around the house and I really like that.
[01:50:21.160 --> 01:50:26.040]   Same. I don't want to sit at a desk. I have to say that I'm a holster like a
[01:50:26.040 --> 01:50:32.200]   nice leather one. A holster that's a good idea. That's a great idea. I'm actually
[01:50:32.200 --> 01:50:37.200]   thinking about picking up a an M1 Mac mini if I can find one cheap because the
[01:50:37.200 --> 01:50:41.400]   original plan was to keep this like M1 MacBook Pro as sort of my desktop until
[01:50:41.400 --> 01:50:46.960]   I replace it with like a proper like mini Mac Pro or whatever but I'm fine. I'm
[01:50:46.960 --> 01:50:50.600]   kind of missing not having a MacBook in the rest of the house and it's too
[01:50:50.600 --> 01:50:54.320]   much of a hassle to unplug all my hard drives and all my screens from here so
[01:50:54.320 --> 01:50:58.120]   it's like it's only six hundred dollars and that's a business expense and I like
[01:50:58.120 --> 01:51:05.520]   it too much. Consider the source Alex but this is from Leaks Apple Pro the M1X
[01:51:05.520 --> 01:51:10.480]   Mac mini's leak schematics according to WCCF tech show a generous number of
[01:51:10.480 --> 01:51:18.320]   ports a magnetic charger and more. It looks good. Looks good. I mean I think
[01:51:18.320 --> 01:51:21.360]   that the Mac mini is really I'm much happier with the Mac minis than I am
[01:51:21.360 --> 01:51:25.080]   with my iMac friends. I haven't gotten the new one yet but because there's so
[01:51:25.080 --> 01:51:31.640]   much more I/O you know and so I have four T4 ports too according to the
[01:51:31.640 --> 01:51:37.600]   rumor to USB-A ports a full-size ethernet jack and an HDMI port that sounds
[01:51:37.600 --> 01:51:43.960]   but it seems reasonable. Yeah. It's a very comfy. Apple's Apple's going through
[01:51:43.960 --> 01:51:47.360]   really it's this can be an interesting inflection point in the transition
[01:51:47.360 --> 01:51:52.640]   pardon me to M1 because remember that though all this pretty much all the
[01:51:52.640 --> 01:51:56.480]   stuff it's out until now is hey we have the exact same chip and we've decided to
[01:51:56.480 --> 01:52:01.560]   express it and all of the flavors that Max come in except for the Mac Pro but
[01:52:01.560 --> 01:52:08.360]   now late 2021 2022 are the years that that the expectation is going to be okay
[01:52:08.360 --> 01:52:13.160]   that's fine but now you have to come back to affordable and just powerful
[01:52:13.160 --> 01:52:17.560]   enough now we need them then we need the mid-range thing that this could be the
[01:52:17.560 --> 01:52:21.360]   mobile desk mobile desk warrior and we need the powerful stuff that does the
[01:52:21.360 --> 01:52:25.280]   big number crunch crunching and the big processing so they've already
[01:52:25.280 --> 01:52:30.680]   demonstrated that the M1 transition is 100% successful and the power of the
[01:52:30.680 --> 01:52:34.680]   entire platform now it's time for them to say no now we're not just gonna
[01:52:34.680 --> 01:52:37.720]   simply have the same pop-tart just putting it in different
[01:52:37.720 --> 01:52:41.480]   something in different toasters we are now going to show how well it scales up
[01:52:41.480 --> 01:52:47.480]   and how well it scales down Netflix and Apple both bidding for the next Gen
[01:52:47.480 --> 01:52:56.520]   of her Lawrence J. Law film she'll play Sue Menger's super agent I don't I think
[01:52:56.520 --> 01:53:00.400]   that well I don't know I feel like that's miscast I think it's more of a
[01:53:00.400 --> 01:53:04.520]   Jennifer Coolidge kind of a role but okay okay first first of all in this in
[01:53:04.520 --> 01:53:07.760]   this streaming market entertainment market they have to be very very clear
[01:53:07.760 --> 01:53:12.920]   do they mean super agent as in no a very very good I agent or it's mom a
[01:53:12.920 --> 01:53:18.160]   superpowers no no super powers I will affect my stream was a yeah was a talent
[01:53:18.160 --> 01:53:24.320]   agent there go he was very very powerful but did not have as far as I know any
[01:53:24.320 --> 01:53:30.320]   superpowers unless it was her poison pants not James Bond is the film will be
[01:53:30.320 --> 01:53:35.600]   produced by excellent cadaver which I'm sad to say is Jennifer Lawrence's
[01:53:35.600 --> 01:53:41.160]   production company bidding has eclipsed 80 million dollars there are some
[01:53:41.160 --> 01:53:46.000]   mutterings according to variety it's got I like that mutterings that has reached
[01:53:46.000 --> 01:53:52.680]   95 million dollars I think I think one of the really interesting things with the
[01:53:52.680 --> 01:53:56.640]   streaming networks is that the math is changing for what wow you know what
[01:53:56.640 --> 01:53:59.920]   movies make sense and what don't because they're trying to fill out an entire
[01:53:59.920 --> 01:54:03.600]   stable of you know they're they're looking at how they do it and whether it
[01:54:03.600 --> 01:54:07.120]   makes money on the box in the box office is less important now you know and it's
[01:54:07.120 --> 01:54:13.040]   it is or not important at all and so the there it's a really interesting math
[01:54:13.040 --> 01:54:16.640]   that they're applying to all of these of of it you got to have this many of this
[01:54:16.640 --> 01:54:20.640]   and this many of that and Netflix is way ahead of everybody as far as knowing
[01:54:20.640 --> 01:54:24.320]   what they what they want in that area but but all of them the bidding is going
[01:54:24.320 --> 01:54:27.600]   I think we're going to see different kinds of movies getting put into it and
[01:54:27.600 --> 01:54:31.680]   then we have in the past because of that yeah it's also I think it also
[01:54:31.680 --> 01:54:36.880]   affects how the producers actually sell their wares now that they know that
[01:54:36.880 --> 01:54:40.480]   it's good if I'm selling this to Netflix there's not going to be it's not going
[01:54:40.480 --> 01:54:45.120]   be I'm not going to make money off of of any other sales or releases I can't
[01:54:45.120 --> 01:54:49.680]   it's not going to be if it's being produced by this company it's not as though in
[01:54:49.680 --> 01:54:54.240]   two years from time they lose their exclusivity exclusivity and now I can
[01:54:54.240 --> 01:54:58.000]   bid up to another to another streaming agent so a lot of them are going to be
[01:54:58.000 --> 01:55:01.760]   fake look you're going to be if you want this if this is a really competitive
[01:55:01.760 --> 01:55:04.480]   thing that a lot of people are bidding for you're going to be paying a lot more
[01:55:04.480 --> 01:55:08.080]   for this than you might have paid for it five years ago I'm telling you that
[01:55:08.080 --> 01:55:12.240]   by the way I just announced a huge addition like they're going to do so many
[01:55:12.240 --> 01:55:15.040]   reality shows they need to they need to do a mega audition now and doesn't
[01:55:15.040 --> 01:55:18.080]   matter for what show it just show up audition if they let you know say you're
[01:55:18.080 --> 01:55:21.040]   out where you put your whole tone in one video and they'll
[01:55:21.040 --> 01:55:25.280]   yeah so they'll like Andy wants the like the incredible race to send in your
[01:55:25.280 --> 01:55:28.080]   one-minute video Andy and you'll go whatever Netflix makes out of the
[01:55:28.080 --> 01:55:30.560]   right yeah yeah I'll end up on one of those things where you have to eat
[01:55:30.560 --> 01:55:36.320]   scary bugs and I'm no sorry Vince all I can say is that the scorpions are very
[01:55:36.320 --> 01:55:40.800]   chewy chewy the body body is chewy not if you deep-fed fry them then they're a
[01:55:40.800 --> 01:55:45.680]   little crisper really which I would recommend yeah okay my my pitch deck my
[01:55:45.680 --> 01:55:49.040]   pitch deck has has us our production company is flipping the model as a
[01:55:49.040 --> 01:55:53.840]   reality competition in which the winner manages to maintain their integrity
[01:55:53.840 --> 01:55:58.400]   and their dignity throughout the entire series the first people to agree to do
[01:55:58.400 --> 01:56:04.640]   something that is hard to get eliminated I love it it'll be no no no I don't think
[01:56:04.640 --> 01:56:08.240]   I will be eating that those bull testicles that's disgusting much much less
[01:56:08.240 --> 01:56:12.320]   let you film me for it congratulations you win you win the fast forward to the
[01:56:12.320 --> 01:56:16.760]   next one you're looking for a what boy no I know I'll be sitting here reading
[01:56:16.760 --> 01:56:22.680]   I like it strong more a's that'll be good I don't know if you've read that
[01:56:22.680 --> 01:56:27.760]   Carl Hyerson I he's one of my favorite novelists he had a great book in 2013
[01:56:27.760 --> 01:56:33.500]   called Bad Monkey the story of a one-time detective demoted this is so Carl
[01:56:33.500 --> 01:56:39.760]   Hyerson to a restaurant inspector in southern Florida a severed arm found by
[01:56:39.760 --> 01:56:44.400]   a tourist out fishing pulls Yancy into the world of greed and corruption that
[01:56:44.400 --> 01:56:47.960]   decimates the land and environment in both Florida and the Bahamas and yes
[01:56:47.960 --> 01:56:55.320]   there is a monkey Apple TV has just made a deal to produce a new 10 episodes series
[01:56:55.320 --> 01:57:01.920]   based on bad monkey yes there's a Florida man joke you all Carl Hyerson
[01:57:01.920 --> 01:57:07.720]   novels are Florida man jokes have you do you like take it and you like Carl
[01:57:07.720 --> 01:57:13.000]   Hyerson well he's that's one of those names where yeah it's up to you to screw
[01:57:13.000 --> 01:57:16.400]   this up if you're gonna adapt this for for television for a movie it really is
[01:57:16.400 --> 01:57:20.880]   as you can't you can't say that you weren't given incredible material that
[01:57:20.880 --> 01:57:25.800]   would make a great pitch a great poster a great trailer and a great pilot he's
[01:57:25.800 --> 01:57:29.520]   up to you not to screw the great many Carl Hyerson TV shows and movies I think
[01:57:29.520 --> 01:57:33.160]   yeah I think that they to promote the promoter they need to put out a little
[01:57:33.160 --> 01:57:36.240]   app that just does a search all you have to do is do a Google search of your
[01:57:36.240 --> 01:57:40.640]   birthday and Florida man just just put that date in Florida man and it just
[01:57:40.640 --> 01:57:43.120]   they just build an app that does that because we have found that there is no
[01:57:43.120 --> 01:57:48.880]   date that we couldn't find that didn't produce a hilariously amazing article
[01:57:48.880 --> 01:57:52.920]   like it just just Google like whatever date you want and then put Florida man
[01:57:52.920 --> 01:58:00.960]   Florida man you will get I know I want some sociologist for his for their PhD
[01:58:00.960 --> 01:58:07.720]   does the dissertation to to to to specifically and definitively document
[01:58:07.720 --> 01:58:11.680]   the first the the original Cardinal Florida man just just like we're always
[01:58:11.680 --> 01:58:15.640]   looking for like that first division between Hamlet erectus and whatever find
[01:58:15.640 --> 01:58:19.320]   the first known instance of Florida man that all Florida man behavior I think
[01:58:19.320 --> 01:58:23.480]   that I think it has to do less with the Florida men in Florida and more that it
[01:58:23.480 --> 01:58:27.120]   just sounds good to say Florida man Arizona man Pennsylvania man there's
[01:58:27.120 --> 01:58:32.320]   doesn't mean every state believe me yeah yeah I feel bad but I love Florida and I
[01:58:32.320 --> 01:58:35.640]   think we've dissed it several times now on the show and separate and I
[01:58:35.640 --> 01:58:41.320]   apologize to all our Florida fans I'm I'm just a pogis by the way bad
[01:58:41.320 --> 01:58:48.200]   monkey will star Vince Vaughn perfect for Lauren a man actually I should point
[01:58:48.200 --> 01:58:53.160]   out in Hyacinth stories the hero which Vaughn will be playing is always smart
[01:58:53.160 --> 01:59:01.120]   canny effective yeah and it's always him in opposite opposition to the you know
[01:59:01.120 --> 01:59:05.560]   not so smart Florida people that he runs into so Vince Vaughn will try the
[01:59:05.560 --> 01:59:09.720]   smart guy the smart Florida man and it will be produced by and you might be
[01:59:09.720 --> 01:59:13.640]   excited about this the writer and executive producer of Ted Lasso Bill
[01:59:13.640 --> 01:59:19.600]   Lawrence so it should it has a good friend for everybody yeah sure Fred
[01:59:19.600 --> 01:59:29.000]   will not appear in this you talk about someone who could blow their nose in a
[01:59:29.000 --> 01:59:33.560]   paper napkin and then make that into a slide deck and get a 12 episode in the
[01:59:33.560 --> 01:59:37.760]   room yeah Ted Lasso that's all you got to say yeah I think Apple probably has
[01:59:37.760 --> 01:59:41.400]   just signed him up for the rest of his rest of his if only to keep them happy
[01:59:41.400 --> 01:59:48.440]   and keep them in the board yeah yeah all right let's take a little time out so
[01:59:48.440 --> 01:59:54.320]   you can all self-medicate whatever it's you to
[01:59:54.320 --> 02:00:05.760]   get his eggs hatched and and Alex can photogrammetry something on his desk
[02:00:05.760 --> 02:00:11.600]   and then we will continue with our picks of the week picks of the week let's
[02:00:11.600 --> 02:00:16.800]   start I'm gonna go left to right this time with Renee Richie Renee so I I
[02:00:16.800 --> 02:00:19.800]   highlighted a Sony camera last week so I thought it was only fair to highlight
[02:00:19.800 --> 02:00:24.440]   and you can in camera this week and by no means am I turning this into Canon
[02:00:24.440 --> 02:00:27.760]   or camera break weekly but there are such interesting features happening there
[02:00:27.760 --> 02:00:31.440]   that I want to have on you know all our devices for a while smartphones were
[02:00:31.440 --> 02:00:34.320]   really leading the pack and it feels like the camera companies are paying
[02:00:34.320 --> 02:00:38.160]   attention now it's trying to do interesting things so Canon has a new R3
[02:00:38.160 --> 02:00:42.640]   which is like their more photography centric like if the R5 is in the middle
[02:00:42.640 --> 02:00:47.360]   and the C and the C70 is more like a videographer camera this is more a
[02:00:47.360 --> 02:00:51.560]   photographer camera it does 30 frames per second bursts it can do it utterly
[02:00:51.560 --> 02:00:55.440]   silently if you want it can do synthetic click noises it can do manual shutter
[02:00:55.440 --> 02:00:58.600]   if you want it to but it has a couple cool features like it doesn't just do
[02:00:58.600 --> 02:01:03.040]   face detection and eye detection and pet detection does car detection it'll
[02:01:03.040 --> 02:01:08.000]   track all of those things with autofocus so you don't have to and what's neat is
[02:01:08.000 --> 02:01:12.160]   when you put your eye up to the view screen it'll scan your eye and then focus
[02:01:12.160 --> 02:01:16.440]   based on what you're looking at oh wow really interesting thing and like we
[02:01:16.440 --> 02:01:20.360]   already have these on iPhones like we have the Face ID thing so if you could
[02:01:20.360 --> 02:01:23.440]   like look at what I'm looking at and then just focus on that for me and I'm not
[02:01:23.440 --> 02:01:28.720]   so wow tapping the screen like an animal that's pretty cool that would be
[02:01:28.720 --> 02:01:34.680]   great so is this less expensive than the R5 or is it more expensive or do we
[02:01:34.680 --> 02:01:38.360]   know know if they've said I think it's less expensive than the R5 the R5 is
[02:01:38.360 --> 02:01:42.360]   just ridiculously expensive yeah at least for me and I picked a bad time to
[02:01:42.360 --> 02:01:46.240]   to quit Canon I have to say they've really done some amazing stuff but Sony
[02:01:46.240 --> 02:01:49.560]   is doing is so I think Fuji there's so many companies doing such interesting
[02:01:49.560 --> 02:01:52.120]   things with cameras right now I just want to spread though I don't want to pay
[02:01:52.120 --> 02:01:57.760]   for everything I want to spread the love I gave my like my vast collection of
[02:01:57.760 --> 02:02:04.560]   Canon L lenses to my son who's using it for his career so I guess yeah birthday
[02:02:04.560 --> 02:02:08.320]   maybe we're gonna have to take a look at a R5 or something because he has the
[02:02:08.320 --> 02:02:10.960]   one Canon seems like they're all in on our lens it's like they're not making any
[02:02:10.960 --> 02:02:14.840]   EF lenses anymore that I can tell it's all RF lenses can you adapt an EF
[02:02:14.840 --> 02:02:18.480]   lens yes you can yes and they yeah they even have speed booster is which let
[02:02:18.480 --> 02:02:23.640]   you get full frame out of the crop sensors which is really nice but like
[02:02:23.640 --> 02:02:27.920]   for what I do it makes autofocus like I need really fast autofocus I need quiet
[02:02:27.920 --> 02:02:32.080]   autofocus because I do the video so I don't use the adapter as much they're
[02:02:32.080 --> 02:02:36.480]   nice and a pinch but the RF lenses super smooth stabilization in the body in the
[02:02:36.480 --> 02:02:40.880]   lens so I don't like if I don't have a tripod or I don't have a like a
[02:02:40.880 --> 02:02:44.640]   I'm a jib with me like anything like that it's still super smooth especially
[02:02:44.640 --> 02:02:50.120]   when I slow it down from 60 to 24 it's just the convenience is so is so great
[02:02:50.120 --> 02:02:57.520]   I'm sure at Pruitt will review it because he loves the R5 he had to send it back
[02:02:57.520 --> 02:03:02.320]   poor guy but was really impressed with the R5 so he'll be all over it on our
[02:03:02.320 --> 02:03:07.520]   hands on it's great I have one sure right here you have an R5 yeah look how
[02:03:07.520 --> 02:03:14.040]   much smaller that is the mark than the 5d I'm really is nice yeah Andy not co it
[02:03:14.040 --> 02:03:18.480]   like it will overheat if you do 8k and of course yeah well that's the only
[02:03:18.480 --> 02:03:27.260]   downside but if you want oh oh he's coming and going and you're not
[02:03:27.260 --> 02:03:31.880]   co pick of the week if a lot of you are familiar with Mystery Science Theater
[02:03:31.880 --> 02:03:36.840]   3000 that really seminal and historically funny series that would
[02:03:36.840 --> 02:03:42.960]   basically riff bad old movies with like new with a new sarcastic but funny
[02:03:42.960 --> 02:03:46.280]   commentary if you're familiar with that then you're probably familiar with
[02:03:46.280 --> 02:03:50.600]   riff tracks because after Mystery Science Theater 3000 sort of shut down its
[02:03:50.600 --> 02:03:55.000]   doors mostly for the bait a lot of people who are working on that formed
[02:03:55.000 --> 02:03:58.360]   this company riff tracks it did a lot of the same stuff only on streaming and
[02:03:58.360 --> 02:04:04.520]   they have a big library of streaming riff instructional movies and like B
[02:04:04.520 --> 02:04:08.480]   movies and stuff like that the only bad the only thing that kind of held me off
[02:04:08.480 --> 02:04:13.280]   from experiencing them is that riff movies they're almost always great but I
[02:04:13.280 --> 02:04:16.840]   can't spend like ten dollars to like download a digital video of something
[02:04:16.840 --> 02:04:20.600]   that I might like or might it might just be a terrible movie that cannot be made
[02:04:20.600 --> 02:04:25.040]   fun of because there is it's it's it's it's anti fun they but how it's so it's
[02:04:25.040 --> 02:04:29.880]   such a bad movie however they've just created their own streaming service called
[02:04:29.880 --> 02:04:34.280]   riff tracks friends and so if you can just go to the riff track riff tracks
[02:04:34.280 --> 02:04:39.840]   calm for five dollars and ninety nine cents a month you can you can stream a
[02:04:39.840 --> 02:04:45.240]   large chunk of their rift library indefinitely as much as much as you want
[02:04:45.240 --> 02:04:49.960]   and that's exactly the way that I like to enjoy riff tracks content because if
[02:04:49.960 --> 02:04:54.960]   again sometimes these movies they're just nothing is happening for two hours
[02:04:54.960 --> 02:04:59.640]   straight and there's such a complete lack of anything happening there is
[02:04:59.640 --> 02:05:03.840]   nothing to make fun of there is nothing to be funny about and that's when you
[02:05:03.840 --> 02:05:08.080]   bail the move on to the next thing I will also say that what got me to sign up
[02:05:08.080 --> 02:05:13.640]   for it was I fell in love with the riffs that are done by Bridget Bridget Nelson
[02:05:13.640 --> 02:05:20.080]   and Mary Jo Peel they are such a great team because they had such a if you're
[02:05:20.080 --> 02:05:24.760]   familiar with Mr. Science Theater 3000 it's normally these three dudes and
[02:05:24.760 --> 02:05:28.800]   or one dude in their two puppets and it's a sort of viable like there's like a
[02:05:28.800 --> 02:05:34.640]   very male sort of like hey we're all just sort of being sarcastic and
[02:05:34.640 --> 02:05:38.400]   aggressive it's funny but it's a definitely sort of a three guys on a
[02:05:38.400 --> 02:05:42.800]   second-hand sofa sort of vibe to it with Bridget and Mary Jo it's more like two
[02:05:42.800 --> 02:05:46.160]   friends that are kind of together and they're basically having fun together
[02:05:46.160 --> 02:05:51.960]   riffing this movie this is Devil Girl from Mars
[02:05:51.960 --> 02:05:57.400]   it's a room before the planet
[02:05:57.400 --> 02:06:02.400]   the haunting of Wuthering Heights last chill house on the left do you think
[02:06:02.400 --> 02:06:06.160]   they write those ahead of time or is it huh?
[02:06:06.160 --> 02:06:11.040]   of course they do yeah they can they they they used to in the first couple
[02:06:11.040 --> 02:06:15.280]   seasons of the first season of Mr. Science Theater 3000 they were just like
[02:06:15.280 --> 02:06:19.920]   do it on on the spot and they all acknowledge that yeah that was not ideal
[02:06:19.920 --> 02:06:23.040]   and we kind of like we kind of like to pretend that that season didn't exist
[02:06:23.040 --> 02:06:26.800]   so yeah it is very very well written so it's not so you're going through like
[02:06:26.800 --> 02:06:29.360]   four minutes of silence while they're waiting for the next funny thing to
[02:06:29.360 --> 02:06:32.720]   happen they will fill they will fill time with funny stuff you might have
[02:06:32.720 --> 02:06:36.000]   won me over with this one I used to love Mr. Science Theater 3000 but I haven't
[02:06:36.000 --> 02:06:39.600]   seen any of the riff tracks and yeah I think this might be fun
[02:06:39.600 --> 02:06:43.040]   a lot of is great especially again if you're a fan of Mr. Science Theater 3000
[02:06:43.040 --> 02:06:46.640]   oftentimes they go back and they re-riff stuff that's in the public domain
[02:06:46.640 --> 02:06:49.760]   like they do it there's the riff tracks version of Mr. B natural
[02:06:49.760 --> 02:06:53.440]   there's the mystery there's the riff tracks version of I think monos
[02:06:53.440 --> 02:06:57.520]   there's definitely the riff tracks version of Santa Claus Conquers the
[02:06:57.520 --> 02:07:01.360]   Martians and for God's sake that you have to almost applaud that they have
[02:07:01.360 --> 02:07:05.120]   to do a riff of another of a 90-minute movie all over again
[02:07:05.120 --> 02:07:09.600]   without repeating the same beautiful jokes that were that made the cut the
[02:07:09.600 --> 02:07:13.040]   first time and so oftentimes it's it's just it's funny I don't
[02:07:13.040 --> 02:07:16.480]   anticipate that I'm going to be subscribing six bucks a month forever
[02:07:16.480 --> 02:07:20.480]   I suspect that at some point I will get a few months and then yeah but I'm
[02:07:20.480 --> 02:07:23.440]   going to have a good time going through the entire collection like I said
[02:07:23.440 --> 02:07:26.320]   I love these people I want to support the work they do
[02:07:26.320 --> 02:07:29.520]   but I can't spend 10 bucks not knowing if this is
[02:07:29.520 --> 02:07:33.760]   another like puppet master movie where it's like oh god I'm
[02:07:33.760 --> 02:07:38.160]   I feel I feel the sadness that is befalling the people who had watched this
[02:07:38.160 --> 02:07:41.680]   movie 10 times to write this show yeah this is bad
[02:07:41.680 --> 02:07:47.920]   is are any of the MST 3K guys on this is yeah riff tracks is not right
[02:07:47.920 --> 02:07:51.200]   no Joel's not he's still he's still doing Mr. Science 3000
[02:07:51.200 --> 02:07:53.840]   they're now they're doing another kickstarter to help please
[02:07:53.840 --> 02:07:56.880]   help me bankroll another launch of Mr. Science there it is
[02:07:56.880 --> 02:08:02.880]   so 3000 but no very 14% funded yay so
[02:08:02.880 --> 02:08:08.080]   Mary Jo is one of the former meds Mike Nelson is in it
[02:08:08.080 --> 02:08:14.880]   Mike the voice of the Kevin Kevin and Mike the voice the last voices of
[02:08:14.880 --> 02:08:18.320]   Crow and Servo are in it and you'll also recognize
[02:08:18.320 --> 02:08:21.840]   the mother but again Brigitte Mary Jo are also part of the original DNA of
[02:08:21.840 --> 02:08:24.960]   Mr. Science the 1000 and it's great stuff
[02:08:24.960 --> 02:08:29.680]   brilliant Alex Lindsey pick of the week
[02:08:29.680 --> 02:08:34.480]   so a little known fact is that what I came out when I decided I wanted to
[02:08:34.480 --> 02:08:37.040]   learn Photoshop there was a there was a little training
[02:08:37.040 --> 02:08:40.480]   in South San Francisco at the South San Francisco Convention Center
[02:08:40.480 --> 02:08:44.800]   and I flew out I probably in 19 I want to say 1991 might have been
[02:08:44.800 --> 02:08:49.680]   in 1992 and Bert Monroy what and they'd be
[02:08:49.680 --> 02:08:53.520]   at me but Bert Monroy was one of the folks training
[02:08:53.520 --> 02:08:57.520]   and and then and then I got to run into him again when we were doing
[02:08:57.520 --> 02:09:03.200]   screen savers screen savers and and then we did recording with revision three
[02:09:03.200 --> 02:09:07.440]   you know with pixel perfect so we did a lot of that with with Bert so we
[02:09:07.440 --> 02:09:12.240]   I get to see Bert work over time and it just keeps on getting more amazing and
[02:09:12.240 --> 02:09:17.040]   he actually has a website where he's been very productive over
[02:09:17.040 --> 02:09:20.400]   COVID COVID times and what what you're looking at
[02:09:20.400 --> 02:09:26.080]   in those images are no photographs or scans so this is all done from scratch
[02:09:26.080 --> 02:09:29.440]   you know so everything he does is from scratch and if you click on fine art I
[02:09:29.440 --> 02:09:33.520]   think a newest one just came out today that one that's that I think the top one
[02:09:33.520 --> 02:09:37.280]   there it says it's um the Paris courtyard yeah so that
[02:09:37.280 --> 02:09:41.680]   when you look at that he's just hasn't incredible
[02:09:41.680 --> 02:09:46.000]   ability to build this from the ground up you know
[02:09:46.000 --> 02:09:49.760]   many hundreds of layers and the thing is you don't really get unless you can
[02:09:49.760 --> 02:09:54.400]   see these in person is yeah you can zoom in a lot
[02:09:54.400 --> 02:09:59.040]   yeah this is dot by dot he's doing yeah and so it's just just incredible
[02:09:59.040 --> 02:10:03.680]   work and so it's it's just worth if you look at any of the images that you see
[02:10:03.680 --> 02:10:06.560]   there you'll think oh well that's a great photograph you know that's that's
[02:10:06.560 --> 02:10:10.880]   cool and then you go oh that's not a photograph that is a
[02:10:10.880 --> 02:10:16.480]   computer enhance yeah it's like it's like telling computer enhance zoom yeah
[02:10:16.480 --> 02:10:20.640]   oh my god there's more detail zoom oh my god there's more detail zoom oh my god
[02:10:20.640 --> 02:10:23.680]   there's more detail yeah I'm actually yeah I mean this one of times
[02:10:23.680 --> 02:10:27.920]   square somewhere I can never remember I'm on a garbage can somewhere I think
[02:10:27.920 --> 02:10:31.680]   hey you see all these faces are real people that Bert knows that he adds to
[02:10:31.680 --> 02:10:35.120]   his uh you see there's just amazing muscle me just
[02:10:35.120 --> 02:10:39.760]   yeah stunningly amazing work yeah so so it's just worth it's just worth
[02:10:39.760 --> 02:10:43.440]   checking out the website and so that's Bert um that's his ponytail yep I'd
[02:10:43.440 --> 02:10:46.320]   recognize that a mile away oh there we go there's
[02:10:46.320 --> 02:10:50.000]   Twit look at that on the garbage can it's John I'm pretty sure the one in the
[02:10:50.000 --> 02:10:53.200]   red shirt there is John Noel oh yeah he and his brother created for
[02:10:53.200 --> 02:10:58.160]   a one of sets his brother yeah yeah oh gosh I love Bert
[02:10:58.160 --> 02:11:01.520]   uh fact now that he's got a new one we should probably by the way notice I
[02:11:01.520 --> 02:11:04.560]   am zooming in and in and in and in yeah exactly
[02:11:04.560 --> 02:11:09.280]   let's zoom all the way in you can yeah you can see the bolts on the on the
[02:11:09.280 --> 02:11:13.520]   yeah screens and times square and this is a this is when he did a long time
[02:11:13.520 --> 02:11:17.200]   ago he's gotten even more more refined yeah that's really great and
[02:11:17.200 --> 02:11:20.880]   only when you zoom in that far in did you realize that what you thought was
[02:11:20.880 --> 02:11:25.200]   just a photo is no he decided to make artwork of those
[02:11:25.200 --> 02:11:27.920]   those posts of those jackets those up right i mean he did
[02:11:27.920 --> 02:11:31.760]   you know it probably took him a day or more to do the stitching
[02:11:31.760 --> 02:11:35.200]   on that jacket you know it's incredible yeah that's incredible
[02:11:35.200 --> 02:11:38.640]   it's like where's where's Waldo only there's no Waldo which it actually
[02:11:38.640 --> 02:11:42.320]   makes it as much fun yeah but there's so much detail just
[02:11:42.320 --> 02:11:44.800]   keep examined it's it's like walking through times
[02:11:44.800 --> 02:11:48.480]   square and there are people that you pay attention to people you don't notice
[02:11:48.480 --> 02:11:53.280]   people you notice again it really is a dramatically cool
[02:11:53.280 --> 02:11:57.200]   imagery i'm glad he's killed doing it a little plug for an app that mica
[02:11:57.200 --> 02:12:00.800]   sergeant told me about and i've used ever since called i'm
[02:12:00.800 --> 02:12:03.920]   amazing it is not free but it is probably the best way to
[02:12:03.920 --> 02:12:08.560]   back up your iphone it's really powerful they've just added a new feature
[02:12:08.560 --> 02:12:12.640]   if you're worried about pegasus i'm amazing now detects
[02:12:12.640 --> 02:12:19.600]   pegasus spyware on your phone uh just a little plug for them and actually
[02:12:19.600 --> 02:12:22.640]   you should consider i'm amazing because it's a very very
[02:12:22.640 --> 02:12:28.560]   uh good program anyway for your backup um you could try it for free
[02:12:28.560 --> 02:12:35.360]   it's sixty dollars for a full license and now with pegasus detection
[02:12:35.360 --> 02:12:40.480]   uh that is it for mac break wakely kids this was a good edition i know a
[02:12:40.480 --> 02:12:45.440]   number of people were worried about the show uh and and the conversation
[02:12:45.440 --> 02:12:49.520]   about apples privacy and of course many of you worried about the fact that i
[02:12:49.520 --> 02:12:53.040]   was wearing a plaid shirt and a plaid suit both of those
[02:12:53.040 --> 02:12:56.000]   both of those fears i hope have been abeliorated
[02:12:56.000 --> 02:12:59.760]   uh did that just did that just to make alix's left eye twitch like
[02:12:59.760 --> 02:13:01.760]   scrubbing patterns scrubbing patterns
[02:13:01.760 --> 02:13:06.800]   for the plaid i sense more a sense more right uh we do mac break weekly
[02:13:06.800 --> 02:13:10.960]   every tuesday uh 11 a.m pacific 2 p.m. eastern time 1800
[02:13:10.960 --> 02:13:14.960]   utc uh almost always joined by three of the best people in the business
[02:13:14.960 --> 02:13:21.280]   rene richy find him at youtube.com/rene richy and again another plug
[02:13:21.280 --> 02:13:25.040]   for the excellent job you did breaking it all down uh and your most recent
[02:13:25.040 --> 02:13:28.880]   video really really good uh sounds like you spent some time on it too
[02:13:28.880 --> 02:13:32.640]   uh week of three three days of me not moving
[02:13:32.640 --> 02:13:39.920]   uh yep it is reward his work just put it on auto loop
[02:13:39.920 --> 02:13:44.080]   for the rest of his 45 minutes long it'll take all your life to get ready
[02:13:44.080 --> 02:13:46.960]   thank you so much rene we really appreciate it thank you so much thanks to
[02:13:46.960 --> 02:13:48.880]   andy and that co when are you going to be on gbh
[02:13:48.880 --> 02:13:52.240]   again i'm on friday this week at one p.m just go to
[02:13:52.240 --> 02:13:56.160]   wgph news.org to stream it live or stream it later
[02:13:56.160 --> 02:13:58.800]   still known news on when we're going to be back at the boston public
[02:13:58.800 --> 02:14:02.960]   library studios uh but hopefully they'll be sooner rather than later
[02:14:02.960 --> 02:14:09.840]   yeah now you're prepared exactly and i i again my
[02:14:09.840 --> 02:14:13.680]   my i have to i have to do that what i have to do that that that predator
[02:14:13.680 --> 02:14:17.680]   like arm clasp with uh between uh carl wethers and stilthas was still
[02:14:17.680 --> 02:14:21.680]   own with with rene because like i too for the past like three or four days
[02:14:21.680 --> 02:14:24.960]   it's like okay we'll have make one list of things that are
[02:14:24.960 --> 02:14:29.120]   tardly not clear things that i thought i understand but are contradicted by
[02:14:29.120 --> 02:14:33.760]   things that apple has said and third things i have no idea about and have to
[02:14:33.760 --> 02:14:40.160]   become an expert on in two days well let's order in yes yes
[02:14:40.160 --> 02:14:43.520]   uh always a pleasure thank you andy and of course alex lindsay
[02:14:43.520 --> 02:14:48.000]   office hours dot global to watch the now 24 hour
[02:14:48.000 --> 02:14:52.960]   day it's amazing like it is it's become like this
[02:14:52.960 --> 02:14:56.480]   i mean it's we've watched it grow over the time here but it's gotten to be
[02:14:56.480 --> 02:15:00.320]   surreal because 24/7 you just you literally just log in and
[02:15:00.320 --> 02:15:04.000]   and there's somebody there talking about something techie and we're
[02:15:04.000 --> 02:15:07.120]   experimenting with something last week i think uh
[02:15:07.120 --> 02:15:10.640]   wednesday of last week i i put up oh we're going to talk about the olympics
[02:15:10.640 --> 02:15:14.160]   like just the olympic production we had members from office hours
[02:15:14.160 --> 02:15:19.040]   that are in tokyo working on the olympics who came in and we just talked
[02:15:19.040 --> 02:15:23.200]   about audio like the we talked about the the commentator stations and the
[02:15:23.200 --> 02:15:26.560]   audio routing and and just how many people were working on it but these are
[02:15:26.560 --> 02:15:29.680]   people that are actually they're in off their office hour members like they've
[02:15:29.680 --> 02:15:34.240]   been part of the office hours community and uh part of that was they can
[02:15:34.240 --> 02:15:37.440]   found each other to go to tokyo and so now they're all in tokyo
[02:15:37.440 --> 02:15:40.720]   and um and so they're we're gonna talk about the olympics again tomorrow
[02:15:40.720 --> 02:15:43.120]   but just video instead of audio because we said the whole time talking about
[02:15:43.120 --> 02:15:48.000]   audio because the audio guys showed up you know and and just and and i hear
[02:15:48.000 --> 02:15:51.360]   that yeah yeah it's it's really fascinating and and we've had some
[02:15:51.360 --> 02:15:54.960]   folks from other broadcasters show up in the in these after hours like some
[02:15:54.960 --> 02:15:58.960]   some of the guys can't talk on you know on the record on the record so the
[02:15:58.960 --> 02:16:02.000]   after hours becomes this thing where these guys show up and they're like
[02:16:02.000 --> 02:16:06.000]   uh you know oh yeah this is this is this is how that video got done or
[02:16:06.000 --> 02:16:09.440]   this is what it looks like it's it's it's quite a thing so congratulations on
[02:16:09.440 --> 02:16:13.440]   your five hundredth episode you're such an overachiever
[02:16:13.440 --> 02:16:19.520]   30 weeks 500 episodes folks 30 weeks 500 this month yeah
[02:16:19.520 --> 02:16:24.240]   you know for our party people that's what that's your substance yeah
[02:16:24.240 --> 02:16:32.000]   office hours not global of course Alex's day job 090. media
[02:16:32.000 --> 02:16:36.880]   we invite you to join us as i mentioned every Tuesday to watch live if you're
[02:16:36.880 --> 02:16:42.000]   doing that chat live at irc.twit.tv of course club twit members can also chat
[02:16:42.000 --> 02:16:47.440]   live in the discord server after the show is over we produce it
[02:16:47.440 --> 02:16:52.720]   clean it up chop it up put a beginning and end on it and put it up on
[02:16:52.720 --> 02:16:58.640]   the website for your download at twit.tv/mbw you'll note though that there are
[02:16:58.640 --> 02:17:02.000]   links there to our youtube channel Macbreak has its own youtube channel so
[02:17:02.000 --> 02:17:06.160]   you can watch shows there too you also can subscribe in your favorite
[02:17:06.160 --> 02:17:10.880]   podcast player if you do please do us a favor give us a five-star review so let
[02:17:10.880 --> 02:17:14.400]   the world know about Macbreak weekly believe it or not there's still some
[02:17:14.400 --> 02:17:19.520]   apple lovers who don't know about Macbreak weekly it's a shock
[02:17:19.520 --> 02:17:24.240]   i know thanks to everyone for being here we'll see you next time now it's time to
[02:17:24.240 --> 02:17:28.640]   get back to work because break time is over
[02:17:28.640 --> 02:17:31.680]   bye bye hey i hope you enjoyed that podcast episode
[02:17:31.680 --> 02:17:36.720]   if you would like to check out more about tech news then you should check out
[02:17:36.720 --> 02:17:42.720]   tech news weekly with me Mike Asargent my co-host Jason Howell where we
[02:17:42.720 --> 02:17:52.640]   interview the people making and breaking the tech news every week
[02:17:52.640 --> 02:17:55.220]   (upbeat music)
[02:17:55.220 --> 02:17:57.800]   (upbeat music)
[02:17:57.800 --> 02:17:59.400]   (upbeat music)

