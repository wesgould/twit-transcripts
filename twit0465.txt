
[00:00:00.000 --> 00:00:04.360]   It's time for Twit, this week in Tech and, boy, do we've got an episode for you.
[00:00:04.360 --> 00:00:09.640]   A lot of legal stuff, anti-cyber bullying, a little bit of courtroom drama over the patent
[00:00:09.640 --> 00:00:14.200]   troll, Microsoft's newest watch-o, and a lot of legal stuff.
[00:00:14.200 --> 00:00:16.600]   Another Twit is next.
[00:00:16.600 --> 00:00:20.800]   Netcasts you love.
[00:00:20.800 --> 00:00:24.000]   From people you trust.
[00:00:24.000 --> 00:00:28.440]   This is Twit.
[00:00:28.440 --> 00:00:35.440]   The bandwidth for this week in Tech is provided by CashFly at CACHEFLY.com.
[00:00:35.440 --> 00:00:41.200]   This is Twit.
[00:00:41.200 --> 00:00:46.240]   This week in Tech, Episode 465, recorded Sunday, July 6, 2014.
[00:00:46.240 --> 00:00:48.480]   Let's ask the audience.
[00:00:48.480 --> 00:00:50.840]   This week in Tech is brought to you by ITProTV.
[00:00:50.840 --> 00:00:54.920]   Are you looking to upgrade your IT skills or prepare for certification?
[00:00:54.920 --> 00:01:00.920]   ITProTV offers engaging and informative tutorials streamed to your Roku, computer, or mobile device.
[00:01:00.920 --> 00:01:09.520]   For 30% off the lifetime of your account, go to itpro.tv/twit and use the code TWIT30
[00:01:09.520 --> 00:01:11.640]   and buy NatureBox.
[00:01:11.640 --> 00:01:14.480]   Order great-tasting healthy snacks delivered right to your door.
[00:01:14.480 --> 00:01:18.700]   Forget the vending machine and get in shape with healthy, delicious treats like roasted
[00:01:18.700 --> 00:01:20.320]   garlic pumpkin seeds.
[00:01:20.320 --> 00:01:24.640]   To get 50% off your first box, go to naturebox.com/twit.
[00:01:24.640 --> 00:01:29.640]   And buy Audible.com.
[00:01:29.640 --> 00:01:32.520]   Sign up for the platinum plan and get two free books.
[00:01:32.520 --> 00:01:35.440]   Go to audible.com/twit2.
[00:01:35.440 --> 00:01:41.080]   Follow Audible on Twitter, user ID Audible_com, and buy Squarespace.
[00:01:41.080 --> 00:01:44.480]   The only one platform that makes it fast and easy to create your own professional website
[00:01:44.480 --> 00:01:46.040]   or online portfolio.
[00:01:46.040 --> 00:01:53.040]   For a free two-week trial and 10% off, go to squarespace.com and use the offer code TWIT.
[00:01:54.240 --> 00:01:56.320]   This time for TWIT this week in tech.
[00:01:56.320 --> 00:01:59.360]   It's the show where we take the tech news of the week, load it in a mortar, shoot it
[00:01:59.360 --> 00:02:04.720]   up into the sky, and let the sparky sparky sprinkle down on us like the ash of yesteryear
[00:02:04.720 --> 00:02:05.720]   gone past.
[00:02:05.720 --> 00:02:10.120]   I'm Father Robert Balleser, the digital Jesuit in for Leo Laport, the tech guy who's currently
[00:02:10.120 --> 00:02:11.120]   in Hawaii.
[00:02:11.120 --> 00:02:14.880]   We don't know why, but we assume our wonderful things are coming.
[00:02:14.880 --> 00:02:21.600]   Joining me today, starting on my right, Mr. Harry McCracken from The Technologizer, Harry,
[00:02:21.600 --> 00:02:24.000]   are we allowed to talk about your future announcement?
[00:02:24.000 --> 00:02:25.000]   Yes.
[00:02:25.000 --> 00:02:29.800]   If, as of two weeks from tomorrow, I will be technology editor for Fast Company, which
[00:02:29.800 --> 00:02:31.280]   I'm excited about.
[00:02:31.280 --> 00:02:33.720]   You do look a lot happier right now.
[00:02:33.720 --> 00:02:38.000]   You've got the glow of a geek who's had the world lifted from your shoulders.
[00:02:38.000 --> 00:02:39.200]   Well, I'm excited about it.
[00:02:39.200 --> 00:02:43.640]   I've been a fan of Fast Company since the first issue came out, which I think was 19
[00:02:43.640 --> 00:02:44.640]   years ago.
[00:02:44.640 --> 00:02:47.720]   We're talking about doing all kinds of cool stuff.
[00:02:47.720 --> 00:02:48.720]   Nice.
[00:02:48.720 --> 00:02:52.960]   It's always nice to be able to walk into someplace and sort of develop, build something
[00:02:52.960 --> 00:02:53.960]   on your own.
[00:02:53.960 --> 00:02:55.520]   They're doing cool stuff.
[00:02:55.520 --> 00:02:56.520]   Yeah.
[00:02:56.520 --> 00:03:00.920]   Speaking of building something on your own, this man is no stranger to doing just that.
[00:03:00.920 --> 00:03:06.520]   We bring in Steve Kovach, the senior tech editor at Business Insider.
[00:03:06.520 --> 00:03:08.600]   Steven, thank you for joining us.
[00:03:08.600 --> 00:03:10.160]   Hey, thanks for having me.
[00:03:10.160 --> 00:03:12.280]   Now, we were talking about this right before the show.
[00:03:12.280 --> 00:03:17.480]   I think I had a conversation with you way back when sometime in January, you seem to
[00:03:17.480 --> 00:03:21.760]   recall that we were talking about Microsoft, but I remember you didn't have that really
[00:03:21.760 --> 00:03:23.520]   cool brick background.
[00:03:23.520 --> 00:03:25.240]   Did you build that just for us?
[00:03:25.240 --> 00:03:30.160]   No, I kind of shifted things around in my living room a little bit to get that dark
[00:03:30.160 --> 00:03:33.400]   stand up comic vibe, I guess, like I'm in some sort of comedy cellar.
[00:03:33.400 --> 00:03:36.600]   But if I turn it around, we can see the vinyl in my apartment.
[00:03:36.600 --> 00:03:37.600]   If you guys want to check it out.
[00:03:37.600 --> 00:03:42.320]   Oh, no, see now you broke the fourth wall now.
[00:03:42.320 --> 00:03:47.840]   We were all imagining that you were somewhere an ivory, flea dorm room somewhere.
[00:03:47.840 --> 00:03:49.640]   Like a fun word, something like that.
[00:03:49.640 --> 00:03:50.880]   Well, just my apartment.
[00:03:50.880 --> 00:03:52.640]   We'll just have to imagine now.
[00:03:52.640 --> 00:03:56.240]   Well, gentlemen, what do you say we get down to the tech news?
[00:03:56.240 --> 00:03:58.840]   No, that was a question.
[00:03:58.840 --> 00:03:59.840]   Okay.
[00:03:59.840 --> 00:04:01.640]   This first one is all about Google.
[00:04:01.640 --> 00:04:05.120]   Now, we all know that the EU broke the internet two months ago.
[00:04:05.120 --> 00:04:06.520]   At least again, that's what the press was saying.
[00:04:06.520 --> 00:04:11.320]   We were all saying that the right to be forgotten was going to be a fundamental mistake that
[00:04:11.320 --> 00:04:13.360]   it was going to destroy the way that the internet worked.
[00:04:13.360 --> 00:04:18.320]   And we were all going to have to go back to chiseling things into tablets with rocks
[00:04:18.320 --> 00:04:20.040]   and whatever those chisel things.
[00:04:20.040 --> 00:04:21.240]   I don't know what tools are.
[00:04:21.240 --> 00:04:25.800]   I use a computer, but anyways, it didn't break the internet, but it did make a mess
[00:04:25.800 --> 00:04:26.800]   of it.
[00:04:26.800 --> 00:04:28.640]   And it seems like Google is exacerbating the mess.
[00:04:28.640 --> 00:04:34.000]   Now we may remember that two months ago, the top EU court backed the right to be forgotten
[00:04:34.000 --> 00:04:38.120]   as a fundamental or principal right of every EU citizen.
[00:04:38.120 --> 00:04:42.920]   It told Google that it was responsible for deleting inadequate irrelevant or no longer
[00:04:42.920 --> 00:04:47.720]   relevant data from its search results when requested to do so by members of the public.
[00:04:47.720 --> 00:04:49.560]   Now there was that public outcry.
[00:04:49.560 --> 00:04:52.720]   There was a lot of experts who said that this was either a good thing or a bad thing,
[00:04:52.720 --> 00:04:54.240]   but we kind of forgot it.
[00:04:54.240 --> 00:05:00.600]   Well, Google is bringing it back into our mind view because a lot of stuff has happened
[00:05:00.600 --> 00:05:01.600]   since then.
[00:05:01.600 --> 00:05:06.720]   The test case was first brought against Google by Spanish citizen Mario Costaia Gonzalez,
[00:05:06.720 --> 00:05:13.280]   who wanted to delete links to a listing for an auction for his house, which had been foreclosed
[00:05:13.280 --> 00:05:14.960]   because of debt.
[00:05:14.960 --> 00:05:16.560]   Well he said that was back in 1998.
[00:05:16.560 --> 00:05:17.880]   I don't have those debts anymore.
[00:05:17.880 --> 00:05:22.160]   I've paid those debts and I don't want that to be the first thing that pops into a search
[00:05:22.160 --> 00:05:24.520]   result when someone types my name.
[00:05:24.520 --> 00:05:28.720]   The EU court agreed and they told Google, you got to take it down.
[00:05:28.720 --> 00:05:30.840]   Now simple, right?
[00:05:30.840 --> 00:05:31.840]   Easy.
[00:05:31.840 --> 00:05:32.840]   Done with.
[00:05:32.840 --> 00:05:37.480]   Since the ruling, there has been a rush to invoke the right to be forgotten.
[00:05:37.480 --> 00:05:41.480]   There was a politician who no longer wanted his behavior in office to be linked with his
[00:05:41.480 --> 00:05:42.480]   name.
[00:05:42.480 --> 00:05:46.680]   There was a doctor who wanted poor reviews removed from her search, a pedophile who wanted
[00:05:46.680 --> 00:05:52.000]   information about his conviction deleted, an actor who wanted articles about his affair
[00:05:52.000 --> 00:05:56.800]   with a teenager to be unlinked, an individual who tried to murder his family who thought
[00:05:56.800 --> 00:06:01.320]   the public should know about that, a cyberstalker, a suspended university professor and the list
[00:06:01.320 --> 00:06:02.960]   goes on and on.
[00:06:02.960 --> 00:06:08.440]   In fact, all told, since the court agreed with the right to be forgotten, there have been
[00:06:08.440 --> 00:06:16.240]   70,000 requests to remove more than 275 individual listings with most requests coming from France,
[00:06:16.240 --> 00:06:18.520]   Germany, the UK, Spain and Italy.
[00:06:18.520 --> 00:06:21.120]   Now I want to throw this over to you first, Steve.
[00:06:21.120 --> 00:06:22.520]   This was kind of what we were expecting, right?
[00:06:22.520 --> 00:06:27.240]   I mean, when the EU said that yes, you have a right to be forgotten, we knew there was
[00:06:27.240 --> 00:06:31.120]   going to be a rush for all these people who had been waiting for years and years for
[00:06:31.120 --> 00:06:35.720]   a way to get that stuff off the internet to bum rush the front doors.
[00:06:35.720 --> 00:06:38.560]   Is this more or less what we expected?
[00:06:38.560 --> 00:06:42.920]   Yeah, I don't think this is a surprise, especially a lot of these examples you name
[00:06:42.920 --> 00:06:48.920]   where people either charge with crimes or convicted of crimes or have some sort of nefarious
[00:06:48.920 --> 00:06:51.640]   shady pasts that they want to hide.
[00:06:51.640 --> 00:06:59.320]   And as a journalist, I'm very against this, I'm a super pro first amendment and this does
[00:06:59.320 --> 00:07:02.560]   amount to censorship in effect.
[00:07:02.560 --> 00:07:07.760]   Yes, those websites still exist, but you've got to remember that Google is a utility,
[00:07:07.760 --> 00:07:10.920]   it's the gateway to the internet for a lot of people.
[00:07:10.920 --> 00:07:15.040]   Even on my own site, we noticed so much traffic comes to business insider just from people
[00:07:15.040 --> 00:07:17.320]   who can't figure out how to type it in the URL bar.
[00:07:17.320 --> 00:07:20.520]   They go to Google and literally just type in business insider.
[00:07:20.520 --> 00:07:26.320]   So Google is this gateway for so many people to access information and the fact that people
[00:07:26.320 --> 00:07:34.080]   can essentially censor themselves out, especially criminals and so forth, that's harmful to
[00:07:34.080 --> 00:07:37.400]   just the public good in general.
[00:07:37.400 --> 00:07:41.920]   And so it's not a surprise that a lot of these types of people we're seeing are coming
[00:07:41.920 --> 00:07:44.640]   forth tens of thousands of people.
[00:07:44.640 --> 00:07:49.320]   And I feel like it's only going to accelerate until maybe someone challenges it with some
[00:07:49.320 --> 00:07:51.920]   strict or standards of what can be removed.
[00:07:51.920 --> 00:07:56.720]   All right, Harry, we're seeing about 1000 new requests submitted each day.
[00:07:56.720 --> 00:07:57.720]   But what about that?
[00:07:57.720 --> 00:07:58.720]   Is this censorship?
[00:07:58.720 --> 00:08:01.480]   I mean, because I mentioned all the bad things, right?
[00:08:01.480 --> 00:08:05.000]   Of course, you've got people who want to get their bad behavior off the internet.
[00:08:05.000 --> 00:08:10.800]   But the reason why the EU court decided that this was a fundamental right was because there
[00:08:10.800 --> 00:08:12.760]   is sort of a statute of limitations.
[00:08:12.760 --> 00:08:17.800]   I mean, if I was in debt 20 years ago, but I'm no longer in debt, why should that be the
[00:08:17.800 --> 00:08:20.320]   first thing that people find when they Google my name?
[00:08:20.320 --> 00:08:25.120]   Or if I had a job and I did poorly at that job and there was some sort of scandal, some
[00:08:25.120 --> 00:08:28.920]   sort of brew, haha, but now I'm in a job which has nothing to do with what I used to
[00:08:28.920 --> 00:08:32.480]   do, should that haunt me forever?
[00:08:32.480 --> 00:08:35.840]   Is it censorship or is this just prudent trimming of data?
[00:08:35.840 --> 00:08:40.240]   Well, there are certainly scenarios in which it's easy to be sympathetic with the people
[00:08:40.240 --> 00:08:41.880]   who are unhappy about having their stuff up.
[00:08:41.880 --> 00:08:47.400]   But this is yet another example of governments not being very good at creating laws which
[00:08:47.400 --> 00:08:48.400]   apply to technology.
[00:08:48.400 --> 00:08:54.920]   I mean, it sounds like the EU was just so incredibly vague about this that all kinds
[00:08:54.920 --> 00:08:59.440]   of people are able to take advantage of out, including people who did things which you
[00:08:59.440 --> 00:09:02.360]   should know about whether it's 20 or 30 years later.
[00:09:02.360 --> 00:09:07.240]   I feel like if you were accused of a crime and found innocent, that's one thing.
[00:09:07.240 --> 00:09:12.240]   I can sort of plausibly see how you might have laws relating to that information.
[00:09:12.240 --> 00:09:16.800]   If you were convicted of a crime, though, I don't see how it's Google's problem.
[00:09:16.800 --> 00:09:18.400]   If people know about it.
[00:09:18.400 --> 00:09:22.960]   I really feel like in the old days it is true that things you did in your past sort of
[00:09:22.960 --> 00:09:24.760]   disappeared over time.
[00:09:24.760 --> 00:09:29.160]   And that's just not going to be true today moving forward because of technology.
[00:09:29.160 --> 00:09:31.560]   Stuff is not going to disappear and I think the world sort of has to figure out how to
[00:09:31.560 --> 00:09:32.560]   deal with that.
[00:09:32.560 --> 00:09:34.400]   I think human beings should forgive people.
[00:09:34.400 --> 00:09:40.040]   I mean, if somebody's house was foreclosed upon 15 or 20 years ago, it probably doesn't
[00:09:40.040 --> 00:09:42.400]   matter very much if they've had a nice record since then.
[00:09:42.400 --> 00:09:47.080]   But it's up to the humans to deal with that, not to the search engine.
[00:09:47.080 --> 00:09:53.600]   Let me add another layer onto this because I actually don't think the idea itself is
[00:09:53.600 --> 00:09:54.600]   horrible.
[00:09:54.600 --> 00:09:59.280]   I don't think that the right to be forgotten is something that will destroy the Internet.
[00:09:59.280 --> 00:10:01.920]   But I just think it was very clumsily implemented.
[00:10:01.920 --> 00:10:07.000]   In fact, the problem that they're finding right now is that the EU issued such broad
[00:10:07.000 --> 00:10:12.240]   rules when they made this law, when they went down with this decision, that essentially
[00:10:12.240 --> 00:10:15.760]   Google and the other search engines can do whatever they want.
[00:10:15.760 --> 00:10:21.360]   So right now, remember, what they told Google was that Google was responsible for making
[00:10:21.360 --> 00:10:26.840]   sure that information that was inaccurate, inadequate, irrelevant, or no longer relevant
[00:10:26.840 --> 00:10:30.760]   could be removed from the Internet on the request of the individual.
[00:10:30.760 --> 00:10:34.080]   But they never defined what those are.
[00:10:34.080 --> 00:10:39.120]   So if you don't define what that means, then that means Google is now in this position
[00:10:39.120 --> 00:10:40.880]   where they have to act like the sensor.
[00:10:40.880 --> 00:10:44.200]   Steve, I want to throw this back over to you.
[00:10:44.200 --> 00:10:49.640]   If you're told to do something, but then they don't tell you exactly how to do it,
[00:10:49.640 --> 00:10:54.680]   and it's now up to you to decide how it works, what the criteria is going to be, when it
[00:10:54.680 --> 00:11:00.960]   gets implemented, how fast it's going to work, then you really have no expectations of blame
[00:11:00.960 --> 00:11:02.160]   on yourself, right?
[00:11:02.160 --> 00:11:03.160]   Right.
[00:11:03.160 --> 00:11:06.600]   I think you nailed it right there when you said it was overly broad.
[00:11:06.600 --> 00:11:08.960]   And that's exactly what this is.
[00:11:08.960 --> 00:11:11.760]   It can be interpreted so many different ways.
[00:11:11.760 --> 00:11:15.800]   For example, one of my colleagues, he's going through the process.
[00:11:15.800 --> 00:11:16.960]   He's in the EU right now.
[00:11:16.960 --> 00:11:18.240]   He's our London editor.
[00:11:18.240 --> 00:11:21.640]   And he's going through the process right now just to see what it's like.
[00:11:21.640 --> 00:11:25.520]   He was mentioned in a book kind of negatively, not too long ago.
[00:11:25.520 --> 00:11:29.000]   And he's trying to get that link to in Google Books removed.
[00:11:29.000 --> 00:11:32.920]   And again, it's, you know, he was a critic of this company he was writing about.
[00:11:32.920 --> 00:11:36.000]   And then this person wrote about him.
[00:11:36.000 --> 00:11:37.800]   Really a bad thing.
[00:11:37.800 --> 00:11:40.160]   It's easy to find and so forth.
[00:11:40.160 --> 00:11:44.240]   But it seems like it's something he'll be able to get removed because he can argue that
[00:11:44.240 --> 00:11:46.720]   it's damaging to his reputation.
[00:11:46.720 --> 00:11:51.120]   And you know, especially someone like us who make our living, you know, in the public,
[00:11:51.120 --> 00:11:56.680]   you know, writing publicly and so forth, you know, that's very damaging just to the public
[00:11:56.680 --> 00:11:59.240]   good at large.
[00:11:59.240 --> 00:12:03.000]   And so, yeah, I think it's overly broad.
[00:12:03.000 --> 00:12:06.920]   And I think eventually we're going to have to get to a point where someone challenges
[00:12:06.920 --> 00:12:07.920]   this again.
[00:12:07.920 --> 00:12:11.920]   It says to the EU courts, hey, you know, let's get a little bit more specific here and figure
[00:12:11.920 --> 00:12:13.080]   out exactly.
[00:12:13.080 --> 00:12:14.080]   Okay.
[00:12:14.080 --> 00:12:19.080]   And strict terms, what can and can't be censored out of these things.
[00:12:19.080 --> 00:12:20.080]   Right.
[00:12:20.080 --> 00:12:25.120]   I think we need to clarify what you can remove too because it's again, that's a little clumsy.
[00:12:25.120 --> 00:12:26.120]   They're figuring it out.
[00:12:26.120 --> 00:12:28.920]   But right now you can remove a link to your name.
[00:12:28.920 --> 00:12:33.200]   So if someone searched for Robert Balaser and I don't like the fact that the very first
[00:12:33.200 --> 00:12:37.400]   search result is a picture of me holding bacon in a very strange way.
[00:12:37.400 --> 00:12:40.600]   I can say no, Google, no, no, no, this was no, no, get rid of this.
[00:12:40.600 --> 00:12:41.600]   This is not relevant.
[00:12:41.600 --> 00:12:42.840]   People don't need to know about that.
[00:12:42.840 --> 00:12:47.560]   Google would be obligated if I was in the EU to remove that link to me holding the bacon
[00:12:47.560 --> 00:12:48.640]   because it was a hot day.
[00:12:48.640 --> 00:12:49.640]   I was naked.
[00:12:49.640 --> 00:12:50.640]   It was strange.
[00:12:50.640 --> 00:12:57.760]   But if someone put bacon, Balaser, I could still find the search result or someone searched
[00:12:57.760 --> 00:13:00.520]   a different country search engine they could still find me there.
[00:13:00.520 --> 00:13:02.600]   So it's not like the data is destroyed.
[00:13:02.600 --> 00:13:04.120]   It's just the link is destroyed.
[00:13:04.120 --> 00:13:07.360]   Harry, let's talk a little bit about that because there's been a lot of focus on, well,
[00:13:07.360 --> 00:13:09.800]   it's not censorship because you can still find it.
[00:13:09.800 --> 00:13:14.640]   If you know where the site is, he just won't be able to search for it through our service.
[00:13:14.640 --> 00:13:20.320]   Well, almost all of us are extremely dependent on this one company's search engine these
[00:13:20.320 --> 00:13:21.840]   days to do that.
[00:13:21.840 --> 00:13:23.520]   And it's a fascinating question.
[00:13:23.520 --> 00:13:26.600]   If there was a little bit more competition in search engines, how would they deal with
[00:13:26.600 --> 00:13:27.600]   that?
[00:13:27.600 --> 00:13:33.560]   Because right now, if you can't be found in Google, then you can't be found to a great
[00:13:33.560 --> 00:13:35.280]   extent.
[00:13:35.280 --> 00:13:40.800]   And of course, I mean, the definition of relevance is so incredibly vague stuff that
[00:13:40.800 --> 00:13:43.600]   the EU is irrelevant to me might be very relevant.
[00:13:43.600 --> 00:13:44.600]   Right.
[00:13:44.600 --> 00:13:45.600]   Right.
[00:13:45.600 --> 00:13:46.600]   Steve, what about that?
[00:13:46.600 --> 00:13:49.400]   I mean, if you can't be found in Google, then you can't be found.
[00:13:49.400 --> 00:13:51.480]   That's actually a pervasive argument.
[00:13:51.480 --> 00:13:54.640]   People are saying, wait a minute.
[00:13:54.640 --> 00:13:59.320]   If you're not giving me the ability to be searched for, then I might as well not have
[00:13:59.320 --> 00:14:00.320]   a site.
[00:14:00.320 --> 00:14:02.360]   I might as well not have a presence on the internet.
[00:14:02.360 --> 00:14:06.120]   But is that the same thing as saying that I'm censoring you?
[00:14:06.120 --> 00:14:14.400]   Well, that's an interesting question too, because kind of like I said, it's censoring
[00:14:14.400 --> 00:14:20.400]   in the sense that there's a lot of public information out there that should be known.
[00:14:20.400 --> 00:14:26.240]   Like you mentioned cases about pedophiles and so forth, that stuff is incredibly relevant
[00:14:26.240 --> 00:14:27.640]   to the public interest.
[00:14:27.640 --> 00:14:31.160]   And it's censoring in the narrow scope of people just in the EU.
[00:14:31.160 --> 00:14:34.400]   But like you even said, you can noodle around with the searches.
[00:14:34.400 --> 00:14:40.640]   And also keep in mind, it's not censorship in the sense that those sites still exist.
[00:14:40.640 --> 00:14:43.960]   Google isn't just showing them to you.
[00:14:43.960 --> 00:14:48.640]   Google isn't like when you search Steve Kowback, you might not, you only see the good stuff,
[00:14:48.640 --> 00:14:52.360]   the only stuff in the EU that I want you to see.
[00:14:52.360 --> 00:14:54.160]   So it's censorship through Google.
[00:14:54.160 --> 00:14:58.000]   And like I even said, Google is such an important utility.
[00:14:58.000 --> 00:15:04.920]   And like Harry said, with very little competition that it's the default knowledge engine for
[00:15:04.920 --> 00:15:05.920]   so many people.
[00:15:05.920 --> 00:15:11.680]   It's what people go to to find everything from how to make spaghetti to just get information
[00:15:11.680 --> 00:15:18.960]   on the latest news and learn about people, especially important, relevant news to the
[00:15:18.960 --> 00:15:19.960]   day.
[00:15:19.960 --> 00:15:22.800]   So it's censorship in that sense.
[00:15:22.800 --> 00:15:27.760]   But you got to keep in mind, for the rest of the world, these links still do exist.
[00:15:27.760 --> 00:15:28.760]   Right.
[00:15:28.760 --> 00:15:32.560]   Now let's get a little bit away from the theoretical here because people always have a problem
[00:15:32.560 --> 00:15:35.520]   with, oh, well, we haven't really sit in the horn.
[00:15:35.520 --> 00:15:38.320]   Yeah, you say all these bad things are going to happen.
[00:15:38.320 --> 00:15:39.320]   Nothing's happened.
[00:15:39.320 --> 00:15:43.240]   Let's look at some of the things that have happened in the two months since the EU backed
[00:15:43.240 --> 00:15:45.280]   the right to be forgotten.
[00:15:45.280 --> 00:15:50.120]   First an article written by economist Robert Preston about the 2007 Merrill Lynch subprime
[00:15:50.120 --> 00:15:57.000]   mortgage disaster was removed because the former Merrill Lynch chairman, Stan O'Neill,
[00:15:57.000 --> 00:16:01.720]   who was the only person mentioned in the article said, wait a minute, I don't work for Merrill
[00:16:01.720 --> 00:16:02.720]   Lynch anymore.
[00:16:02.720 --> 00:16:04.360]   I don't want this linking to my name.
[00:16:04.360 --> 00:16:05.720]   And they pulled it down.
[00:16:05.720 --> 00:16:10.200]   Six Guardian articles were taken down, including three by about Dougie McDonald, who was a
[00:16:10.200 --> 00:16:16.400]   football ref who was forced to resign after a possible match fixing scandal.
[00:16:16.400 --> 00:16:20.280]   And three newspapers, including the Daily Mail, have had stories pulled down by people
[00:16:20.280 --> 00:16:24.640]   who were mentioned in the stories, but no longer wanted to be associated with whatever
[00:16:24.640 --> 00:16:25.920]   news was in those stories.
[00:16:25.920 --> 00:16:29.840]   Now, they're being very vague deliberately because they don't want us to see exactly
[00:16:29.840 --> 00:16:31.240]   what the content was.
[00:16:31.240 --> 00:16:36.240]   But it seems to me that we're now getting real concrete information about how this is
[00:16:36.240 --> 00:16:38.520]   working, which is I'm sure it's doing some good.
[00:16:38.520 --> 00:16:42.080]   I'm sure there's some very outdated information that's being pulled down.
[00:16:42.080 --> 00:16:48.120]   But again, because there are no guidelines, you've got this law of unintended consequences,
[00:16:48.120 --> 00:16:49.560]   where you know what?
[00:16:49.560 --> 00:16:54.280]   It probably would be good to know that Stan O'Neill was involved with the Merrill Lynch
[00:16:54.280 --> 00:16:55.480]   meltdown.
[00:16:55.480 --> 00:16:59.600]   That's not outdated information, but Google gets to make the decision.
[00:16:59.600 --> 00:17:01.600]   Harry, what's wrong with that?
[00:17:01.600 --> 00:17:07.680]   Well, in any one case, you could plausibly see Google thinking it over and coming to
[00:17:07.680 --> 00:17:10.040]   a rational decision.
[00:17:10.040 --> 00:17:14.160]   But for 70,000 cases, the only way you could possibly deal with that is if you had an
[00:17:14.160 --> 00:17:20.720]   enormous infrastructure and essentially like a court system to look at every instance and
[00:17:20.720 --> 00:17:22.640]   figure out whether it made sense or not.
[00:17:22.640 --> 00:17:28.920]   And of course, the more it comes down to hearing about cases in which media companies
[00:17:28.920 --> 00:17:33.520]   had stories pulled about powerful people, the more bothersome it is.
[00:17:33.520 --> 00:17:35.520]   Because it really is censorship.
[00:17:35.520 --> 00:17:39.640]   It's censorship for the 21st century.
[00:17:39.640 --> 00:17:42.880]   Steve, I want to get your input on this.
[00:17:42.880 --> 00:17:48.640]   There are people who are saying that Google is deliberately doing sort of reduxio ad absurdum
[00:17:48.640 --> 00:17:49.640]   here.
[00:17:49.640 --> 00:17:53.640]   They don't have to cooperate as quickly as they've been cooperating with the ruling.
[00:17:53.640 --> 00:17:55.000]   In fact, people are saying, look at Yahoo!
[00:17:55.000 --> 00:17:56.000]   Look at Bing.
[00:17:56.000 --> 00:17:57.200]   They're all very slow to respond.
[00:17:57.200 --> 00:18:01.720]   So they understand how the rule works, but the rule also doesn't have a timeframe so
[00:18:01.720 --> 00:18:03.760]   they're moving very slowly on request.
[00:18:03.760 --> 00:18:06.480]   Whereas Google has just been whipping through them and they're saying, well, Google is
[00:18:06.480 --> 00:18:10.320]   at fault because they don't have to take the ruling so literally.
[00:18:10.320 --> 00:18:13.280]   But it seems to me that that's not Google's problem.
[00:18:13.280 --> 00:18:18.000]   If you make a law, they can comply with the law.
[00:18:18.000 --> 00:18:20.160]   I mean, I don't understand why.
[00:18:20.160 --> 00:18:22.720]   Yeah, I mean, it seems like they're getting a bad route here.
[00:18:22.720 --> 00:18:23.720]   It's not Google's fault.
[00:18:23.720 --> 00:18:24.720]   Yeah, they are.
[00:18:24.720 --> 00:18:29.600]   I think they were put in a sticky situation and the last thing they want to do is wind
[00:18:29.600 --> 00:18:31.560]   up in court again.
[00:18:31.560 --> 00:18:34.960]   But what the EU did is put them in a situation where they're basically the arbiter and they
[00:18:34.960 --> 00:18:36.640]   get to go case by case.
[00:18:36.640 --> 00:18:39.200]   Okay, do we block the link to the mayoral guide?
[00:18:39.200 --> 00:18:40.680]   We block the link to the pedophile.
[00:18:40.680 --> 00:18:45.160]   Do we block the link to this guy who couldn't pay off his loans or something?
[00:18:45.160 --> 00:18:50.320]   And do we, does the EU really want Google to be deciding this kind of stuff?
[00:18:50.320 --> 00:18:54.120]   That they're like Harry said, like this court system?
[00:18:54.120 --> 00:18:58.600]   They put some in such a sticky situation and it isn't their fault.
[00:18:58.600 --> 00:19:03.200]   I think right now, if anything, they're erring on the side of caution and just accepting
[00:19:03.200 --> 00:19:05.480]   all these requests as fast as they can.
[00:19:05.480 --> 00:19:11.280]   And they're probably getting way more requests than being is because they have such a large
[00:19:11.280 --> 00:19:13.000]   chunk of the market share in search.
[00:19:13.000 --> 00:19:16.640]   I don't worry because Bing will actually be copying the requests that Google has.
[00:19:16.640 --> 00:19:18.680]   So anytime Google thinks something now, let's not go there.
[00:19:18.680 --> 00:19:19.680]   They don't do that anymore.
[00:19:19.680 --> 00:19:20.680]   All right, okay.
[00:19:20.680 --> 00:19:24.080]   So I want to close this up because we spend a lot of time talking about it.
[00:19:24.080 --> 00:19:26.480]   The right to be forgotten, the unintended consequences.
[00:19:26.480 --> 00:19:30.280]   But let me ask both of you, would this, would something like this ever work in the United
[00:19:30.280 --> 00:19:31.760]   States?
[00:19:31.760 --> 00:19:35.840]   We have a real different philosophy about a lot of this stuff like in the UK, you can
[00:19:35.840 --> 00:19:40.400]   slander somebody by writing something about them, which is true.
[00:19:40.400 --> 00:19:43.920]   Totally different from over here where slander by definition is saying something that's
[00:19:43.920 --> 00:19:45.120]   not true.
[00:19:45.120 --> 00:19:49.560]   So I think we've always had a way more liberal attitude on this stuff.
[00:19:49.560 --> 00:19:52.960]   And it's kind of hard to imagine anything this broad happening here.
[00:19:52.960 --> 00:19:53.960]   Right.
[00:19:53.960 --> 00:19:58.400]   Again, if it's incorrect information, maybe, but stuff you just don't like being up about
[00:19:58.400 --> 00:20:00.080]   you because it puts you in a bad light.
[00:20:00.080 --> 00:20:01.640]   I don't see it happening.
[00:20:01.640 --> 00:20:02.720]   Steve, what about that?
[00:20:02.720 --> 00:20:06.520]   I mean, because we already have strong laws for slander.
[00:20:06.520 --> 00:20:10.240]   I mean, would this even be required in the United States?
[00:20:10.240 --> 00:20:14.160]   I mean, if someone says something untrue about you, you can actually, you have legal recourse
[00:20:14.160 --> 00:20:15.520]   to go against them.
[00:20:15.520 --> 00:20:19.200]   But if someone just reports news about something, I mean, you shouldn't be able to take that
[00:20:19.200 --> 00:20:20.200]   down.
[00:20:20.200 --> 00:20:21.200]   Right.
[00:20:21.200 --> 00:20:23.560]   It's always slander if it's false.
[00:20:23.560 --> 00:20:25.840]   And so again, I completely agree with Harry.
[00:20:25.840 --> 00:20:29.960]   This would never happen in the US just because we have, I mean, it's the first amendment
[00:20:29.960 --> 00:20:34.840]   freedom of speech and that there are protections for people against slander and libel.
[00:20:34.840 --> 00:20:37.840]   But again, it has to be false information.
[00:20:37.840 --> 00:20:44.200]   So maybe if some kind of case comes through where someone wants false information taken
[00:20:44.200 --> 00:20:48.160]   down, but even then they'd go against go after the individual outlet.
[00:20:48.160 --> 00:20:52.160]   So that's not a problem for Google to solve.
[00:20:52.160 --> 00:20:56.520]   And I've been a journalist in both London and the United States.
[00:20:56.520 --> 00:20:57.680]   And Harry nailed it.
[00:20:57.680 --> 00:21:03.720]   I mean, the laws are completely different over there, especially in the UK.
[00:21:03.720 --> 00:21:07.480]   You can write something true and still get in legal trouble.
[00:21:07.480 --> 00:21:14.360]   And so we're very lucky and fortunate to live in a country that lets us, lets journalists
[00:21:14.360 --> 00:21:16.880]   and the freedom of speech operate the way it does.
[00:21:16.880 --> 00:21:20.200]   So I think we're pretty safe.
[00:21:20.200 --> 00:21:21.200]   Let's hope so.
[00:21:21.200 --> 00:21:22.760]   I know that was very patriotic and delightful.
[00:21:22.760 --> 00:21:24.560]   But you know, I actually do believe it.
[00:21:24.560 --> 00:21:27.600]   Well, I mean, you may have the right to be forgotten in the United States, but the NSA
[00:21:27.600 --> 00:21:28.600]   won't forget you.
[00:21:28.600 --> 00:21:29.600]   So.
[00:21:29.600 --> 00:21:30.600]   Exactly.
[00:21:30.600 --> 00:21:31.600]   Let's bring that back in.
[00:21:31.600 --> 00:21:32.600]   No, we're not going to talk about that.
[00:21:32.600 --> 00:21:33.600]   In fact, let's go to something a bit more fun.
[00:21:33.600 --> 00:21:38.480]   Kuku for cocoa puffs specifically sticks and stones may break your bones, but Apple can't
[00:21:38.480 --> 00:21:40.000]   call you a troll.
[00:21:40.000 --> 00:21:42.800]   Like last week, the US district judge Lucy Ko.
[00:21:42.800 --> 00:21:46.040]   You may remember her from the Apple Samsung blockbuster case.
[00:21:46.040 --> 00:21:51.720]   Well, she issued a no name calling rule in the Apple GPNE case.
[00:21:51.720 --> 00:21:54.520]   Now, GPNE is a non-practicing entity.
[00:21:54.520 --> 00:21:56.720]   It's what we normally call a patent troll.
[00:21:56.720 --> 00:22:01.640]   It's a corporation formed with the sole purpose of acquiring IP, which they then use to go
[00:22:01.640 --> 00:22:04.520]   after other companies who are actually making things.
[00:22:04.520 --> 00:22:05.520]   That's what they do.
[00:22:05.520 --> 00:22:09.400]   They sort of shotgun a bunch of litigation and hopefully someone will pay up.
[00:22:09.400 --> 00:22:14.200]   Now, in this particular case, GPNE has acquired multiple patents that vaguely, very vaguely
[00:22:14.200 --> 00:22:16.640]   address mobile communications.
[00:22:16.640 --> 00:22:23.560]   For example, Chad, if you have this up, US patent 755.5267, which describes a central
[00:22:23.560 --> 00:22:27.280]   office with some form of two-way paging.
[00:22:27.280 --> 00:22:31.800]   If you scroll down to the, actually, now it's the link above from giga-ohm, it shows you
[00:22:31.800 --> 00:22:34.760]   the what the vision was for this.
[00:22:34.760 --> 00:22:38.640]   It's essentially using a bunch of pagers with some receivers, so you could have two-way
[00:22:38.640 --> 00:22:39.640]   paging.
[00:22:39.640 --> 00:22:45.720]   They're using that as a way to claim that they own Apple's communications technologies,
[00:22:45.720 --> 00:22:47.440]   and Apple therefore needs to pay up.
[00:22:47.440 --> 00:22:53.240]   Now, in any other circumstance, we would call that a patent troll, but in this case,
[00:22:53.240 --> 00:22:58.080]   Lucico has said, not only can they not call them a patent troll during the trial, but
[00:22:58.080 --> 00:23:04.960]   Apple can also not call them a pirate, a bounty hunter, a privateer, a bandit, a paper, a
[00:23:04.960 --> 00:23:09.760]   patent, stick up, shake down, playing the lawsuit lottery, corporate shell game or corporate
[00:23:09.760 --> 00:23:10.760]   shell.
[00:23:10.760 --> 00:23:15.440]   Now, Steve, I want to throw this over to you first.
[00:23:15.440 --> 00:23:19.240]   It sounds as if what Lucy's trying to do, she's trying to make sure that there's no
[00:23:19.240 --> 00:23:25.320]   defamatory language, or there's no biased language in the courtroom, but I mean, is patent troll
[00:23:25.320 --> 00:23:29.040]   really all that surprising to people who might be listening to this case?
[00:23:29.040 --> 00:23:34.920]   No, it's become such common vernacular, and these companies, like you said, are designed
[00:23:34.920 --> 00:23:41.800]   just to look through patents and see what they can snap up and then sue for and make money.
[00:23:41.800 --> 00:23:48.840]   I mean, it's calling a spade a spade, and they are, it's such a common phrase these
[00:23:48.840 --> 00:23:52.400]   days that I don't think it's that bad.
[00:23:52.400 --> 00:23:57.480]   Maybe the thing like shell corporation or pirate and so forth, maybe those are a little
[00:23:57.480 --> 00:24:02.800]   derogatory and shouldn't be used in the courtroom, but even the White House has said patent
[00:24:02.800 --> 00:24:03.800]   troll.
[00:24:03.800 --> 00:24:07.120]   And that's safe to say that they're pretty unbiased in a lot of these things.
[00:24:07.120 --> 00:24:12.400]   So I'm okay with Apple calling this company a patent troll, but I think Co is right to
[00:24:12.400 --> 00:24:15.040]   kind of tamp down the rest of that harsh language.
[00:24:15.040 --> 00:24:19.160]   And that's the amazing part because the White House commission, the fact sheet that you got
[00:24:19.160 --> 00:24:24.760]   from the commission about patent reform, they actually use the phrase patent troll.
[00:24:24.760 --> 00:24:29.560]   So evidently patent troll cannot be used in a courtroom, but it's just fine for the president
[00:24:29.560 --> 00:24:30.720]   of the United States.
[00:24:30.720 --> 00:24:34.920]   Harry, I really don't understand this.
[00:24:34.920 --> 00:24:38.960]   Is it just because she doesn't want leaning, she doesn't want to mistrial, she doesn't
[00:24:38.960 --> 00:24:41.440]   want to worry about legal ramifications later on?
[00:24:41.440 --> 00:24:45.800]   Because it seems strange to remove words from the courtroom.
[00:24:45.800 --> 00:24:49.920]   Well, I'm reasonably sympathetic with her.
[00:24:49.920 --> 00:24:51.160]   They are patent trolls.
[00:24:51.160 --> 00:24:55.920]   They certainly don't have a problem with the White House saying so.
[00:24:55.920 --> 00:24:59.800]   But a courtroom should be about decorum and it should, I mean, I think it's fine to say
[00:24:59.800 --> 00:25:04.840]   that you don't want emotionally charged words being applied because the job of the court
[00:25:04.840 --> 00:25:07.560]   is to determine the facts of the case.
[00:25:07.560 --> 00:25:13.640]   And to me, we are not at a point where calling somebody a patent troll is not a judgment and
[00:25:13.640 --> 00:25:14.640]   a form of name calling.
[00:25:14.640 --> 00:25:17.680]   It is a form of name calling.
[00:25:17.680 --> 00:25:20.560]   So I don't see why it's unreasonable for to do that.
[00:25:20.560 --> 00:25:26.560]   And to me, it sounds a lot worse than the shell game and so forth or shell entity.
[00:25:26.560 --> 00:25:30.880]   It's kind of like a bunch of kids shouting at each other and the mother says, we don't
[00:25:30.880 --> 00:25:32.600]   use that kind of language here.
[00:25:32.600 --> 00:25:33.600]   Yeah.
[00:25:33.600 --> 00:25:34.600]   I don't know.
[00:25:34.600 --> 00:25:37.520]   I mean, judges are there partially to do that.
[00:25:37.520 --> 00:25:41.800]   But I mean, some of these things like a corporate shell, corporate, that's, that's, you can
[00:25:41.800 --> 00:25:45.280]   actually describe most of these non-practicing entities as a corporate shell.
[00:25:45.280 --> 00:25:47.360]   It's a corporation that has nothing in it.
[00:25:47.360 --> 00:25:48.360]   Right.
[00:25:48.360 --> 00:25:50.720]   I mean, that sounds more like a statement of fact to me.
[00:25:50.720 --> 00:25:51.720]   Right.
[00:25:51.720 --> 00:25:53.040]   So, I mean, okay, maybe patent troll.
[00:25:53.040 --> 00:25:56.760]   Maybe I can understand patent troll because it does have some sort of negative connotation
[00:25:56.760 --> 00:26:00.760]   that you may not want to use inside of a court, a court of law.
[00:26:00.760 --> 00:26:06.000]   But some of these, these things like corporate shell or corporate shell game, that's actually
[00:26:06.000 --> 00:26:09.760]   just a description that that's not really a derogatory statement.
[00:26:09.760 --> 00:26:11.920]   Stephen, are we going to see more of this?
[00:26:11.920 --> 00:26:14.800]   Because I mean, patent troll lawsuits are not going to go away.
[00:26:14.800 --> 00:26:18.880]   Is she blazing the trail for future judges to say, no, you can't, you can't call them
[00:26:18.880 --> 00:26:19.880]   bad people?
[00:26:19.880 --> 00:26:24.880]   Yeah, I think, you know, you can clearly see what's happening here.
[00:26:24.880 --> 00:26:29.360]   I mean, you don't need a judge or a jury to see that these companies are designed literally
[00:26:29.360 --> 00:26:32.720]   just to troll rich corporations like Apple.
[00:26:32.720 --> 00:26:35.440]   And yeah, we are going to see, I mean, these cases have been going on forever and they're
[00:26:35.440 --> 00:26:37.400]   going to continue.
[00:26:37.400 --> 00:26:43.440]   So yeah, maybe that's her goal here is to kind of set the standard in the courtroom.
[00:26:43.440 --> 00:26:48.600]   And inevitably, when these cases keep coming back to her and her colleagues in the system
[00:26:48.600 --> 00:26:53.320]   to keep it as impartial as possible, you know, some of those terms, like you said, I mean,
[00:26:53.320 --> 00:26:54.320]   they're very literal.
[00:26:54.320 --> 00:26:58.760]   And it's hard to argue that they have any kind of bias towards them, like a shell corporation.
[00:26:58.760 --> 00:27:03.240]   Troll, again, like I said, I still think that's okay just because it's in the common vernacular
[00:27:03.240 --> 00:27:07.200]   now and people understand what that means.
[00:27:07.200 --> 00:27:11.800]   But yeah, other stuff like pirate and so forth and maybe anything else that could be
[00:27:11.800 --> 00:27:14.240]   determined derogatory.
[00:27:14.240 --> 00:27:19.440]   I think that's good to remain impartial, especially if juries are listening to this.
[00:27:19.440 --> 00:27:23.640]   Yeah, so it's going to keep happening and this is setting a precedent.
[00:27:23.640 --> 00:27:24.640]   I don't know.
[00:27:24.640 --> 00:27:29.080]   I'm going to miss hearing like pirates in the middle of the Google look, most legal proceedings
[00:27:29.080 --> 00:27:30.080]   are really boring.
[00:27:30.080 --> 00:27:32.080]   I want to hear at least a little bit of spicy language.
[00:27:32.080 --> 00:27:35.600]   Now, when we come back, we're going to talk a little bit about how to become the most hated
[00:27:35.600 --> 00:27:37.600]   man in San Francisco.
[00:27:37.600 --> 00:27:41.920]   Earlier on, I had this titled how to become a D bag in just one day, but I was told by
[00:27:41.920 --> 00:27:45.760]   the people at Twit that we don't use words like D bag on the stream.
[00:27:45.760 --> 00:27:49.760]   So instead, we're going to take a break to talk about the first sponsor of this episode
[00:27:49.760 --> 00:27:51.240]   of this week in tech.
[00:27:51.240 --> 00:27:53.280]   And that is IT Pro TV.
[00:27:53.280 --> 00:27:58.120]   Now, the other show that I do, well, actually I do multiple shows, but the show I do tomorrow
[00:27:58.120 --> 00:27:59.800]   is called this week in enterprise tech.
[00:27:59.800 --> 00:28:00.800]   It's all about networking.
[00:28:00.800 --> 00:28:01.800]   It's all about data centers.
[00:28:01.800 --> 00:28:03.280]   It's about how the world is connected.
[00:28:03.280 --> 00:28:08.480]   And one of the questions we get most often is from the odd user who just wants to know,
[00:28:08.480 --> 00:28:10.000]   how do I get into this?
[00:28:10.000 --> 00:28:13.480]   How do I start learning about the technology that connects us?
[00:28:13.480 --> 00:28:18.600]   How do I start a career or at least the path towards a career that will let me deal with
[00:28:18.600 --> 00:28:21.320]   some of the most cutting edge technology on the planet?
[00:28:21.320 --> 00:28:28.000]   Well, the answer is you need to sign up with some sort of outfit, with some sort of organization
[00:28:28.000 --> 00:28:32.280]   that can give you the ropes that can let you learn at your own pace that can teach you
[00:28:32.280 --> 00:28:36.200]   the information you need to know at the pace you need to know it.
[00:28:36.200 --> 00:28:39.320]   And thankfully, that's IT Pro TV.
[00:28:39.320 --> 00:28:45.120]   Now, IT Pro TV is a video network designed to exclusively serve the world of information
[00:28:45.120 --> 00:28:49.560]   technology, whether you're looking to jumpstart a career in IT or if you're already working
[00:28:49.560 --> 00:28:54.840]   in the field, IT Pro TV supplements traditional learning methods in a fun and engaging way
[00:28:54.840 --> 00:28:59.680]   that maximizes your learning and prepares you for a certificate exam.
[00:28:59.680 --> 00:29:02.240]   Now hundreds of hours of contents are produced.
[00:29:02.240 --> 00:29:08.440]   Now with 30 hours being added each week, growing episode libraries with video courses on Apple,
[00:29:08.440 --> 00:29:14.160]   Microsoft Cisco and more including a plus CCNA security plus MCSA CISSP.
[00:29:14.160 --> 00:29:18.000]   Now with Linux plus and Apple certification coming in July.
[00:29:18.000 --> 00:29:23.840]   Now course covers the topics like network security, Linux, Windows, OS 10 support for
[00:29:23.840 --> 00:29:25.720]   desktop and servers and more.
[00:29:25.720 --> 00:29:31.040]   And episode libraries are organized by exam objectives, making it easy for you to target
[00:29:31.040 --> 00:29:35.880]   the areas to successfully pass the certification test that you are prepping for.
[00:29:35.880 --> 00:29:41.640]   Even if you're studying with a book already or enrolled in a certification program or technical
[00:29:41.640 --> 00:29:46.000]   degree program, this is a fantastic supplement to learn at your own pace.
[00:29:46.000 --> 00:29:50.000]   The shows are streamed live and are available on demand worldwide to you, to your Roku,
[00:29:50.000 --> 00:29:54.520]   your computer or mobile device for one low monthly price.
[00:29:54.520 --> 00:29:59.640]   Now comparable to the cost of a study guide, the IT Pro TV is much cheaper than going to
[00:29:59.640 --> 00:30:04.200]   an IT bootcamp and it's no hassle with an easy cancellation policy.
[00:30:04.200 --> 00:30:07.200]   Now one of the things I really like is you get direct interaction with hosts.
[00:30:07.200 --> 00:30:10.840]   It's a lot like Twitch and that there's a chat room during the shows.
[00:30:10.840 --> 00:30:15.080]   There's web based Q&A specific to the topic of study.
[00:30:15.080 --> 00:30:20.080]   Now they have over 10 years of experience in IT and learning and were inspired by Leo
[00:30:20.080 --> 00:30:23.000]   to create what you see here on the screen.
[00:30:23.000 --> 00:30:26.680]   A studio devoted to nothing but IT.
[00:30:26.680 --> 00:30:30.360]   They even use the same cameras, microphones, lighting and try cast or equipment that we
[00:30:30.360 --> 00:30:33.760]   do so you'll know that they'll give you the goods.
[00:30:33.760 --> 00:30:36.960]   Now they've also added a new web interface and learning management system to track your
[00:30:36.960 --> 00:30:37.960]   progress.
[00:30:37.960 --> 00:30:41.280]   You get a virtual sandbox lab environment for hands on practice which means you get to
[00:30:41.280 --> 00:30:45.040]   play with the equipment as if you were sitting in front of it before you actually have to
[00:30:45.040 --> 00:30:46.720]   buy anything.
[00:30:46.720 --> 00:30:52.400]   They also have measure practice exams included with your subscription which are a $79 value.
[00:30:52.400 --> 00:30:57.760]   Annual subscribers can now also download episodes and audio only MP3s for offline consumption.
[00:30:57.760 --> 00:31:02.000]   For example, if you want something to listen to on that drive to work, why not listen
[00:31:02.000 --> 00:31:05.800]   to something that will help you brush up your IT skills.
[00:31:05.800 --> 00:31:08.240]   Corporate accounts are also available for departments and companies.
[00:31:08.240 --> 00:31:12.120]   Check out the corporate group pricing at the bottom of the pricing page.
[00:31:12.120 --> 00:31:17.400]   ITPro has an amazing response from corporate IT departments wanting to get subscriptions
[00:31:17.400 --> 00:31:18.640]   for team members.
[00:31:18.640 --> 00:31:20.480]   So here's what I want you to do.
[00:31:20.480 --> 00:31:25.040]   I want you to see if maybe the world of IT is a fit for you.
[00:31:25.040 --> 00:31:31.400]   Check out ITProTV/Twit to upgrade your brain with the most popular certifications recognized
[00:31:31.400 --> 00:31:33.080]   by employers around the world.
[00:31:33.080 --> 00:31:37.200]   There's also a free preview on the site if you want to check out some of their videos
[00:31:37.200 --> 00:31:39.480]   or their live stream.
[00:31:39.480 --> 00:31:45.080]   Subscriptions are normally $57 per month or $570 for the entire year but we have a special
[00:31:45.080 --> 00:31:47.000]   offer because they're huge fans of Twit.
[00:31:47.000 --> 00:31:53.360]   If you sign up now and use the code TWIT30 you'll receive 30% off your subscription for
[00:31:53.360 --> 00:31:55.400]   the lifetime of your account.
[00:31:55.400 --> 00:32:00.440]   That's less than $40 per month or $399 for the entire year.
[00:32:00.440 --> 00:32:03.560]   That's ITProTV/Twit.
[00:32:03.560 --> 00:32:10.040]   ITProTV/Twit and use the code TWIT30 to receive 30% off.
[00:32:10.040 --> 00:32:15.560]   We thank ITProTV for their support of this week in tech.
[00:32:15.560 --> 00:32:21.000]   I don't know if you've heard about this but over the weekend we had a little bit of a,
[00:32:21.000 --> 00:32:22.240]   I think it was a hate parade.
[00:32:22.240 --> 00:32:24.200]   Can we call it a hate parade in San Francisco?
[00:32:24.200 --> 00:32:25.200]   Definitely.
[00:32:25.200 --> 00:32:27.000]   Steve, you heard about this, right?
[00:32:27.000 --> 00:32:28.000]   Oh yeah.
[00:32:28.000 --> 00:32:33.080]   So, you've, you know, table reservations especially in holidays are kind of difficult
[00:32:33.080 --> 00:32:34.920]   to come by in San Francisco.
[00:32:34.920 --> 00:32:37.400]   So you know it's a really good way to piss people off.
[00:32:37.400 --> 00:32:41.280]   How about if you make a bunch of fake reservations and then sell those reservations to the highest
[00:32:41.280 --> 00:32:42.280]   bidder?
[00:32:42.280 --> 00:32:44.200]   Yeah, that's exactly what happened.
[00:32:44.200 --> 00:32:49.160]   A man by the name of Brian Myers, a developer, a project manager and an entrepreneur in San
[00:32:49.160 --> 00:32:52.360]   Francisco, created a new service called Reservation Hop.
[00:32:52.360 --> 00:32:53.760]   Now he says he did it over the weekend.
[00:32:53.760 --> 00:32:56.000]   It was just something fun that he put together.
[00:32:56.000 --> 00:33:02.080]   Well, the way it works is that he makes reservations at the busiest times of the hottest restaurants
[00:33:02.080 --> 00:33:05.560]   in San Francisco under assumed names.
[00:33:05.560 --> 00:33:08.480]   And then he offers those reservations for sale on his site.
[00:33:08.480 --> 00:33:12.520]   Now once you pay, he will give you the name of the reservation and the time that you're
[00:33:12.520 --> 00:33:13.760]   supposed to show up.
[00:33:13.760 --> 00:33:16.400]   Now naturally this caused a little bit of consternation.
[00:33:16.400 --> 00:33:20.600]   There was a lot of restaurant tours who were saying, "Wait a minute, you can't do that.
[00:33:20.600 --> 00:33:21.600]   That's not cool."
[00:33:21.600 --> 00:33:27.280]   His excuses, well I release the reservations if no one buys it, like five minutes before.
[00:33:27.280 --> 00:33:30.200]   And these are popular restaurants, so I'm sure they're not going to have problems filling
[00:33:30.200 --> 00:33:31.200]   the seats.
[00:33:31.200 --> 00:33:35.600]   But it seems like a real, well it's a to do she thing to do.
[00:33:35.600 --> 00:33:38.200]   Harry, I mean, it seems really sleazy.
[00:33:38.200 --> 00:33:42.160]   And it seems like just in the last few weeks there have been more really stupid ideas for
[00:33:42.160 --> 00:33:43.160]   startups.
[00:33:43.160 --> 00:33:46.920]   And I can remember there were those guys who were selling rolls of quarters for use at
[00:33:46.920 --> 00:33:48.880]   the laundromat, which they marked up.
[00:33:48.880 --> 00:33:52.320]   So you paid $15 for $10 with the quarters.
[00:33:52.320 --> 00:33:57.040]   There was a whole thing in San Francisco with the apps for auctioning off your parking
[00:33:57.040 --> 00:34:01.040]   space when you're leaving out, which the city said is illegal.
[00:34:01.040 --> 00:34:05.840]   And now this guy who like Farhad Manjo from the New York Times said that he's violating
[00:34:05.840 --> 00:34:09.280]   the social contract, which seems fair to me.
[00:34:09.280 --> 00:34:14.480]   Yeah, there's an expectation that you act certain ways when you live with a lot of other
[00:34:14.480 --> 00:34:16.720]   people because you want them to act the same way.
[00:34:16.720 --> 00:34:19.080]   This seems like one of those things where, no dude, that's cool.
[00:34:19.080 --> 00:34:20.080]   Just don't do it.
[00:34:20.080 --> 00:34:25.720]   Now, Chad, if you could bring up his website, the funny thing was he's sort of basking in
[00:34:25.720 --> 00:34:31.960]   the negativity, actually his blog page, the negativity that is his disaster here.
[00:34:31.960 --> 00:34:35.960]   He's saying, well, since people started tweeting about me and calling me the most horrible
[00:34:35.960 --> 00:34:42.080]   person on the face of the city, my site traffic has gone up like 5,000%.
[00:34:42.080 --> 00:34:46.400]   But Steve, let me throw this over to you because there's actually a bigger lesson I
[00:34:46.400 --> 00:34:47.400]   think here.
[00:34:47.400 --> 00:34:51.440]   It's not just about one person creating a really, really nasty app that a lot of people are
[00:34:51.440 --> 00:34:53.720]   getting angry about.
[00:34:53.720 --> 00:34:56.560]   This is kind of the state of innovation in San Francisco right now.
[00:34:56.560 --> 00:35:03.120]   If you look at some of the most recent startups, they're all about extracting value from things
[00:35:03.120 --> 00:35:05.760]   that people used to think were free.
[00:35:05.760 --> 00:35:11.520]   And here are some of the hate tweets that he's gotten, and he likes this.
[00:35:11.520 --> 00:35:13.920]   Is this where innovation is headed in the Silicon Valley?
[00:35:13.920 --> 00:35:19.800]   Yeah, and I think I have a unique perspective on this from an East Coast or a New Yorker
[00:35:19.800 --> 00:35:21.160]   looking at it from the outside.
[00:35:21.160 --> 00:35:25.000]   It seems like so many of these developers and entrepreneurs in the area, they just get
[00:35:25.000 --> 00:35:31.360]   lost in their own mind bubble that everything is right for disruption, including reservations.
[00:35:31.360 --> 00:35:35.200]   And there are legitimate services that do help you make reservations.
[00:35:35.200 --> 00:35:39.240]   There's Open Table, the most obvious answer, and that's a great service and it does it
[00:35:39.240 --> 00:35:40.240]   well.
[00:35:40.240 --> 00:35:41.640]   And you don't need to do anything shady.
[00:35:41.640 --> 00:35:44.800]   They work directly with the restaurants.
[00:35:44.800 --> 00:35:48.880]   And so this is akin to someone, kind of like Harry said, just like finding an open parking
[00:35:48.880 --> 00:35:53.840]   spot and paying a guy to stand in there until someone auctions it off and bids on it and
[00:35:53.840 --> 00:35:56.280]   no one parks there.
[00:35:56.280 --> 00:36:00.800]   It's maybe not necessarily illegal, but yeah, it violates the social contract.
[00:36:00.800 --> 00:36:08.120]   I'll quote some friend of mine on Twitter said something like he had a, he pretended
[00:36:08.120 --> 00:36:12.000]   he has started an idea to stand in front of someone in a movie theater until they pay
[00:36:12.000 --> 00:36:13.200]   him to sit down.
[00:36:13.200 --> 00:36:15.960]   You know, it's exactly like that.
[00:36:15.960 --> 00:36:18.840]   That was actually Matt Honan from Wired who said that the other night.
[00:36:18.840 --> 00:36:20.040]   I thought that was really funny.
[00:36:20.040 --> 00:36:24.600]   And that's exactly what, you know, you see these kids come through thinking they're really
[00:36:24.600 --> 00:36:28.080]   just like blowing up certain industries and they're not.
[00:36:28.080 --> 00:36:33.440]   You can't, there's not going to be an Uber for everything or an Airbnb for everything.
[00:36:33.440 --> 00:36:39.000]   And this is just, you know, it's hurting local businesses and restaurants, you know, are
[00:36:39.000 --> 00:36:44.160]   losing, could lose potential customers by some kid just calling around and making phony
[00:36:44.160 --> 00:36:46.120]   reservations.
[00:36:46.120 --> 00:36:48.920]   And the fact that he's bragging about it just makes it worse.
[00:36:48.920 --> 00:36:53.320]   And maybe he's getting more traffic on his site, but I'd be shocked if he's making any
[00:36:53.320 --> 00:36:54.320]   money off this.
[00:36:54.320 --> 00:36:55.320]   Okay, wait, wait, wait.
[00:36:55.320 --> 00:36:58.880]   So let me, let me take the devil's advocate's position here because it's easy to look at
[00:36:58.880 --> 00:37:03.680]   something like this or like the parking meter startup that we had in San Francisco.
[00:37:03.680 --> 00:37:04.680]   What was that thing called?
[00:37:04.680 --> 00:37:05.960]   Or a couple of them.
[00:37:05.960 --> 00:37:06.960]   Yeah.
[00:37:06.960 --> 00:37:08.280]   Something monkey is one of them.
[00:37:08.280 --> 00:37:09.920]   Yeah, parking monkey, parking monkey.
[00:37:09.920 --> 00:37:16.080]   The idea of let me take a free resource and I'll give you a little bit of service and you
[00:37:16.080 --> 00:37:17.720]   give me profit.
[00:37:17.720 --> 00:37:20.840]   And people, people generally look frown upon this because again, it's breaking the social
[00:37:20.840 --> 00:37:21.840]   contract.
[00:37:21.840 --> 00:37:25.400]   But the people in the chat room are quick to point out, wait a minute, what about Ticketmaster?
[00:37:25.400 --> 00:37:26.640]   This is just another middleman scheme.
[00:37:26.640 --> 00:37:28.640]   I'm not so crazy about Ticketmaster either.
[00:37:28.640 --> 00:37:32.080]   But Ticketmaster, that's accepted, right?
[00:37:32.080 --> 00:37:33.440]   Yeah, I mean, yeah.
[00:37:33.440 --> 00:37:36.200]   Yeah, but they created this platform to buy these tickets.
[00:37:36.200 --> 00:37:37.720]   You know, that's a useful tool.
[00:37:37.720 --> 00:37:42.160]   Yeah, they charge you way too many fees, but they did create a service.
[00:37:42.160 --> 00:37:46.000]   I mean, Seamless Web, I don't know if you guys have that out there, but it's the food
[00:37:46.000 --> 00:37:47.920]   delivery, a grub hub and so forth.
[00:37:47.920 --> 00:37:52.240]   You know, you're still paying for the same stuff, but it's this platform and it's a use,
[00:37:52.240 --> 00:37:56.320]   it's an actual useful tool and they partner, keep in mind, Ticketmaster partners with the
[00:37:56.320 --> 00:38:00.400]   venues, Seamless and Grub Hub and so forth, partner with the restaurants.
[00:38:00.400 --> 00:38:04.680]   This guy's just going on his own and finding something free and charging people for it.
[00:38:04.680 --> 00:38:06.680]   And it's kind of similar to what we saw at the ARIO case.
[00:38:06.680 --> 00:38:11.520]   I know we're going to get to that later, but you know, ARIO took these free signals
[00:38:11.520 --> 00:38:15.920]   and then charged people to beam them back over the internet and SCOTUS, you know, a
[00:38:15.920 --> 00:38:17.760]   couple of weeks ago said that's illegal.
[00:38:17.760 --> 00:38:20.800]   But, wait a minute, isn't that the role of the entrepreneur?
[00:38:20.800 --> 00:38:25.080]   The entrepreneur finds things that are undervalued and makes them valuable.
[00:38:25.080 --> 00:38:26.080]   Isn't that innovation?
[00:38:26.080 --> 00:38:30.640]   I mean, in the chat room, people are talking about stub hub and some people have said this
[00:38:30.640 --> 00:38:32.440]   guy is just scalping reservations.
[00:38:32.440 --> 00:38:38.920]   I mean, even scalpers have to pay for the tickets and they're taking a risk and if you
[00:38:38.920 --> 00:38:43.800]   scalp tickets to a show, the theater will be okay because you paid for the ticket.
[00:38:43.800 --> 00:38:48.880]   And this guy does say, I believe, that he cancels the reservations four hours before
[00:38:48.880 --> 00:38:54.200]   if he hasn't sold them, which in theory means that the restaurant has plenty of time to
[00:38:54.200 --> 00:39:01.080]   find somebody to sit down, but it still seems like, you know, it's the restaurant's decision.
[00:39:01.080 --> 00:39:05.360]   And I feel like if this guy actually does take off or if he has copycats, the way this
[00:39:05.360 --> 00:39:10.680]   will be solved is that restaurants will force you to give a credit card number, which some
[00:39:10.680 --> 00:39:13.800]   restaurants do today, especially for big nights.
[00:39:13.800 --> 00:39:17.560]   And you won't be able to just make a reservation for free.
[00:39:17.560 --> 00:39:22.400]   Now, let me get deep into the devil's advocate position because I mean, I understand we're
[00:39:22.400 --> 00:39:26.600]   saying, well, this doesn't agree with the social contract that I've made with my fellow
[00:39:26.600 --> 00:39:27.600]   city dwellers.
[00:39:27.600 --> 00:39:29.920]   But I mean, is that just a matter of time?
[00:39:29.920 --> 00:39:35.000]   If I were to go back 20 years and say, oh, by the way, I'm developing a new company,
[00:39:35.000 --> 00:39:37.600]   what I'm going to do is I'm going to take all your personal information.
[00:39:37.600 --> 00:39:41.360]   And I'm going to make it available for people to search for it and I'm going to sell advertising
[00:39:41.360 --> 00:39:42.360]   against it.
[00:39:42.360 --> 00:39:44.360]   People would say, no, no, that violates the social contract.
[00:39:44.360 --> 00:39:45.360]   That's totally uncool.
[00:39:45.360 --> 00:39:46.360]   Maybe a company who said that.
[00:39:46.360 --> 00:39:47.360]   Yeah.
[00:39:47.360 --> 00:39:50.960]   I worked for a publication that blocked Google for a while because they felt like Google was
[00:39:50.960 --> 00:39:51.960]   stealing their content.
[00:39:51.960 --> 00:39:55.320]   I'm trying to call on our content machine.
[00:39:55.320 --> 00:39:59.800]   So is it just a bad idea until people start doing it?
[00:39:59.800 --> 00:40:04.200]   And if that case, wouldn't you want to get the little bit of hate so you could be first?
[00:40:04.200 --> 00:40:08.400]   I don't think in this case, I don't think it applies this at all.
[00:40:08.400 --> 00:40:11.400]   I don't think so either, but I'm like, I want to push this a little bit.
[00:40:11.400 --> 00:40:15.840]   I know you're playing the devil's advocate, but it's just hard to buy that.
[00:40:15.840 --> 00:40:18.160]   It's simply destroying that social contract.
[00:40:18.160 --> 00:40:24.160]   We have that reasonable expectation that anyone can call and make a reservation for free.
[00:40:24.160 --> 00:40:27.320]   It's not a legal right, but it's socially acceptable.
[00:40:27.320 --> 00:40:32.240]   It's, I'm all for innovation and change and disrupting industries, but this isn't disrupting
[00:40:32.240 --> 00:40:33.240]   an industry.
[00:40:33.240 --> 00:40:34.520]   It's pissing everyone off.
[00:40:34.520 --> 00:40:35.520]   All right.
[00:40:35.520 --> 00:40:40.600]   And the fact that you used fake names kind of tells you that it's not something that people
[00:40:40.600 --> 00:40:41.600]   think is okay.
[00:40:41.600 --> 00:40:44.000]   The fruits of the poison tree, I think, is what they call it.
[00:40:44.000 --> 00:40:45.320]   I'd love to know what the names are though.
[00:40:45.320 --> 00:40:47.480]   And does he use a unique name every single time?
[00:40:47.480 --> 00:40:49.480]   I'm sure he's been using Herring the Cracker.
[00:40:49.480 --> 00:40:50.480]   I love changing.
[00:40:50.480 --> 00:40:54.520]   He also, he said something about how it works 99% of the time, and I wonder what happens
[00:40:54.520 --> 00:40:57.560]   in the 1% of the time when it doesn't work.
[00:40:57.560 --> 00:41:04.680]   Now, okay, I think what is coming down to is we believe, even if we can't express it,
[00:41:04.680 --> 00:41:07.920]   that if someone is going to make a profit, they need to have a little bit of skin in the
[00:41:07.920 --> 00:41:08.920]   game, right?
[00:41:08.920 --> 00:41:09.920]   They have to work a little bit.
[00:41:09.920 --> 00:41:15.200]   We have no problem as someone takes a risk and gets payoff, but maybe our problem with
[00:41:15.200 --> 00:41:18.600]   this guy is he's not taking a risk.
[00:41:18.600 --> 00:41:22.520]   He's taking advantage of a system that's there.
[00:41:22.520 --> 00:41:24.040]   Is that fair?
[00:41:24.040 --> 00:41:25.200]   Is that what we're saying?
[00:41:25.200 --> 00:41:26.200]   I'm confused.
[00:41:26.200 --> 00:41:27.200]   I don't know what I'm saying.
[00:41:27.200 --> 00:41:32.040]   He's taking advantage of the fact that it runs on trust right now because you're going
[00:41:32.040 --> 00:41:34.840]   to make a reservation just by giving your name.
[00:41:34.840 --> 00:41:37.160]   There's trust there and he's violating that trust.
[00:41:37.160 --> 00:41:39.960]   I can't believe that people give me their personal information.
[00:41:39.960 --> 00:41:41.160]   They trust me with their pictures.
[00:41:41.160 --> 00:41:46.320]   I think some famous man said that before he founded some Facebook-y thing, right?
[00:41:46.320 --> 00:41:48.040]   Let's get back to this.
[00:41:48.040 --> 00:41:49.960]   Let's step away from this.
[00:41:49.960 --> 00:41:55.040]   This particular example, let's talk about this whole genre of innovation in particular.
[00:41:55.040 --> 00:41:56.760]   That's what I really want to talk about.
[00:41:56.760 --> 00:42:01.720]   If this is the future of innovation, taking things that are free, making value of them,
[00:42:01.720 --> 00:42:05.960]   and then selling them so I can make profit, a lot of companies, and I'm just these small
[00:42:05.960 --> 00:42:12.960]   startups seem to be based around that model.
[00:42:12.960 --> 00:42:13.960]   Look at Airbnb.
[00:42:13.960 --> 00:42:14.960]   I think that's really cool.
[00:42:14.960 --> 00:42:18.720]   They're the largest hotel service in the world right now.
[00:42:18.720 --> 00:42:22.960]   I think Branch Husky tweeted yesterday or the day before.
[00:42:22.960 --> 00:42:29.640]   They hit a record of 330,000 people staying in Airbnb's in one night.
[00:42:29.640 --> 00:42:31.280]   That's significant.
[00:42:31.280 --> 00:42:33.680]   That is actually creating a useful service.
[00:42:33.680 --> 00:42:42.240]   People have rooms open or a spare apartment or a separate vacation home or whatever.
[00:42:42.240 --> 00:42:44.040]   They want to rent it out.
[00:42:44.040 --> 00:42:47.160]   Airbnb created this excellent platform to enable that.
[00:42:47.160 --> 00:42:57.920]   I think that's a great example of someone who's a company and entrepreneurs who found
[00:42:57.920 --> 00:43:01.680]   some low-hanging fruit that was right for an disruption.
[00:43:01.680 --> 00:43:06.440]   I've stayed in Airbnb's before and it's almost better than staying in a hotel in a lot of
[00:43:06.440 --> 00:43:07.600]   ways.
[00:43:07.600 --> 00:43:10.880]   It's very personal and you get your own place and so on.
[00:43:10.880 --> 00:43:12.680]   You get to go through their stuff, which I love.
[00:43:12.680 --> 00:43:13.680]   That's my favorite part.
[00:43:13.680 --> 00:43:14.680]   Yeah, that's right.
[00:43:14.680 --> 00:43:15.680]   That's right.
[00:43:15.680 --> 00:43:16.680]   That's my favorite.
[00:43:16.680 --> 00:43:17.680]   That's my favorite.
[00:43:17.680 --> 00:43:18.680]   That's my favorite.
[00:43:18.680 --> 00:43:19.680]   That's my favorite part.
[00:43:19.680 --> 00:43:20.680]   That's my favorite part.
[00:43:20.680 --> 00:43:21.680]   That's my favorite.
[00:43:21.680 --> 00:43:22.680]   That's my favorite.
[00:43:22.680 --> 00:43:23.680]   That's my favorite.
[00:43:23.680 --> 00:43:24.680]   That's my favorite.
[00:43:24.680 --> 00:43:25.680]   That's my favorite part.
[00:43:25.680 --> 00:43:26.680]   That's my favorite part.
[00:43:26.680 --> 00:43:27.680]   That's my favorite part.
[00:43:27.680 --> 00:43:28.680]   That's my favorite part.
[00:43:28.680 --> 00:43:29.680]   That's my favorite part.
[00:43:29.680 --> 00:43:30.680]   That's my favorite part.
[00:43:30.680 --> 00:43:31.680]   That's my favorite part.
[00:43:31.680 --> 00:43:32.680]   That's my favorite part.
[00:43:32.680 --> 00:43:33.680]   That's my favorite part.
[00:43:33.680 --> 00:43:34.680]   That's my favorite part.
[00:43:34.680 --> 00:43:35.680]   That's my favorite part.
[00:43:35.680 --> 00:43:36.680]   That's my favorite part.
[00:43:36.680 --> 00:43:37.680]   That's my favorite part.
[00:43:37.680 --> 00:43:38.680]   That's my favorite part.
[00:43:38.680 --> 00:43:39.680]   That's my favorite part.
[00:43:39.680 --> 00:43:40.680]   That's my favorite part.
[00:43:40.680 --> 00:43:41.680]   That's my favorite part.
[00:43:41.680 --> 00:43:42.680]   That's my favorite part.
[00:43:42.680 --> 00:43:43.680]   That's my favorite part.
[00:43:43.680 --> 00:43:44.680]   That's my favorite part.
[00:43:44.680 --> 00:43:45.680]   That's my favorite part.
[00:43:45.680 --> 00:43:46.680]   That's my favorite part.
[00:43:46.680 --> 00:43:47.680]   That's my favorite part.
[00:43:47.680 --> 00:43:48.680]   That's my favorite part.
[00:43:48.680 --> 00:43:49.680]   That's my favorite part.
[00:43:49.680 --> 00:43:50.680]   That's my favorite part.
[00:43:50.680 --> 00:43:51.680]   That's my favorite part.
[00:43:51.680 --> 00:43:52.680]   That's my favorite part.
[00:43:52.680 --> 00:43:53.680]   That's my favorite part.
[00:43:53.680 --> 00:43:54.680]   That's my favorite part.
[00:43:54.680 --> 00:43:55.680]   That's my favorite part.
[00:43:55.680 --> 00:43:56.680]   That's my favorite part.
[00:43:56.680 --> 00:43:57.680]   That's my favorite part.
[00:43:57.680 --> 00:43:59.680]   That's my favorite part.
[00:43:59.680 --> 00:44:00.680]   That's my favorite part.
[00:44:00.680 --> 00:44:01.680]   That's my favorite part.
[00:44:01.680 --> 00:44:02.680]   That's my favorite part.
[00:44:02.680 --> 00:44:03.680]   That's my favorite part.
[00:44:03.680 --> 00:44:04.680]   That's my favorite part.
[00:44:04.680 --> 00:44:05.680]   That's my favorite part.
[00:44:05.680 --> 00:44:06.680]   That's my favorite part.
[00:44:06.680 --> 00:44:07.680]   That's my favorite part.
[00:44:07.680 --> 00:44:08.680]   That's my favorite part.
[00:44:08.680 --> 00:44:09.680]   That's my favorite part.
[00:44:09.680 --> 00:44:10.680]   That's my favorite part.
[00:44:10.680 --> 00:44:11.680]   That's my favorite part.
[00:44:11.680 --> 00:44:12.680]   That's my favorite part.
[00:44:12.680 --> 00:44:13.680]   That's my favorite part.
[00:44:13.680 --> 00:44:14.680]   That's my favorite part.
[00:44:14.680 --> 00:44:15.680]   That's my favorite part.
[00:44:15.680 --> 00:44:16.680]   That's my favorite part.
[00:44:16.680 --> 00:44:17.680]   That's my favorite part.
[00:44:17.680 --> 00:44:18.680]   That's my favorite part.
[00:44:18.680 --> 00:44:19.680]   That's my favorite part.
[00:44:19.680 --> 00:44:20.680]   That's my favorite part.
[00:44:20.680 --> 00:44:21.680]   That's my favorite part.
[00:44:21.680 --> 00:44:22.680]   That's my favorite part.
[00:44:22.680 --> 00:44:23.680]   That's my favorite part.
[00:44:23.680 --> 00:44:24.680]   That's my favorite part.
[00:44:24.680 --> 00:44:25.680]   That's my favorite part.
[00:44:25.680 --> 00:44:26.680]   That's my favorite part.
[00:44:26.680 --> 00:44:27.680]   That's my favorite part.
[00:44:27.680 --> 00:44:28.680]   That's my favorite part.
[00:44:28.680 --> 00:44:29.680]   That's my favorite part.
[00:44:29.680 --> 00:44:30.680]   That's my favorite part.
[00:44:30.680 --> 00:44:31.680]   That's my favorite part.
[00:44:31.680 --> 00:44:32.680]   That's my favorite part.
[00:44:32.680 --> 00:44:33.680]   That's my favorite part.
[00:44:33.680 --> 00:44:34.680]   That's my favorite part.
[00:44:34.680 --> 00:44:35.680]   That's my favorite part.
[00:44:35.680 --> 00:44:36.680]   That's my favorite part.
[00:44:36.680 --> 00:44:37.680]   That's my favorite part.
[00:44:37.680 --> 00:44:38.680]   That's my favorite part.
[00:44:38.680 --> 00:44:39.680]   That's my favorite part.
[00:44:39.680 --> 00:44:40.680]   That's my favorite part.
[00:44:40.680 --> 00:44:41.680]   That's my favorite part.
[00:44:41.680 --> 00:44:42.680]   That's my favorite part.
[00:44:42.680 --> 00:44:43.680]   That's my favorite part.
[00:44:43.680 --> 00:44:44.680]   That's my favorite part.
[00:44:44.680 --> 00:44:45.680]   That's my favorite part.
[00:44:45.680 --> 00:44:46.680]   That's my favorite part.
[00:44:46.680 --> 00:44:47.680]   That's my favorite part.
[00:44:47.680 --> 00:44:48.680]   That's my favorite part.
[00:44:48.680 --> 00:44:49.680]   That's my favorite part.
[00:44:49.680 --> 00:44:50.680]   That's my favorite part.
[00:44:50.680 --> 00:44:51.680]   That's my favorite part.
[00:44:51.680 --> 00:44:52.680]   That's my favorite part.
[00:44:52.680 --> 00:44:57.680]   That's my favorite part.
[00:44:57.680 --> 00:44:58.680]   That's my favorite part.
[00:44:58.680 --> 00:44:59.680]   That's my favorite part.
[00:44:59.680 --> 00:45:00.680]   That's my favorite part.
[00:45:00.680 --> 00:45:01.680]   That's my favorite part.
[00:45:01.680 --> 00:45:02.680]   That's my favorite part.
[00:45:02.680 --> 00:45:03.680]   That's my favorite part.
[00:45:03.680 --> 00:45:04.680]   That's my favorite part.
[00:45:04.680 --> 00:45:05.680]   That's my favorite part.
[00:45:05.680 --> 00:45:06.680]   That's my favorite part.
[00:45:06.680 --> 00:45:07.680]   That's my favorite part.
[00:45:07.680 --> 00:45:08.680]   That's my favorite part.
[00:45:08.680 --> 00:45:09.680]   That's my favorite part.
[00:45:09.680 --> 00:45:10.680]   That's my favorite part.
[00:45:10.680 --> 00:45:11.680]   That's my favorite part.
[00:45:11.680 --> 00:45:12.680]   That's my favorite part.
[00:45:12.680 --> 00:45:13.680]   That's my favorite part.
[00:45:13.680 --> 00:45:14.680]   That's my favorite part.
[00:45:14.680 --> 00:45:15.680]   That's my favorite part.
[00:45:15.680 --> 00:45:16.680]   That's my favorite part.
[00:45:16.680 --> 00:45:17.680]   That's my favorite part.
[00:45:17.680 --> 00:45:18.680]   That's my favorite part.
[00:45:18.680 --> 00:45:19.680]   That's my favorite part.
[00:45:19.680 --> 00:45:20.680]   That's my favorite part.
[00:45:20.680 --> 00:45:21.680]   That's my favorite part.
[00:45:21.680 --> 00:45:24.880]   We'll invite our guests to go back there later on and see what we have.
[00:45:24.880 --> 00:45:26.680]   We have a row of chocolates.
[00:45:26.680 --> 00:45:28.800]   We have a row of sugars and sweets.
[00:45:28.800 --> 00:45:32.080]   Then we've got a diminishing stack of nature box packages.
[00:45:32.080 --> 00:45:34.040]   We got a couple of hundred of these things.
[00:45:34.040 --> 00:45:39.400]   I think we're down to a dozen or so because this is what the Twit people snack on.
[00:45:39.400 --> 00:45:43.000]   When you've got something this good, this natural, you don't have to care about whether
[00:45:43.000 --> 00:45:44.000]   or not it's good for you.
[00:45:44.000 --> 00:45:46.200]   That's just sort of an added bonus.
[00:45:46.200 --> 00:45:48.280]   Now, here's how the process works.
[00:45:48.280 --> 00:45:49.440]   You've got to go to nature box.
[00:45:49.440 --> 00:45:51.960]   Try to go and show them the nature box website.
[00:45:51.960 --> 00:45:56.120]   What you're going to do is you're going to choose a pack that works for you.
[00:45:56.120 --> 00:45:59.800]   Click on the continue button on the website and you get to choose between three subscription
[00:45:59.800 --> 00:46:05.200]   options that will determine how much you get, how often you get, and what kind of packages
[00:46:05.200 --> 00:46:08.160]   you're going to receive inside your nature box.
[00:46:08.160 --> 00:46:12.480]   Once you remember, you can select which snacks you'd like in that box and you can also select
[00:46:12.480 --> 00:46:14.040]   by your dietary need.
[00:46:14.040 --> 00:46:18.840]   If you're vegan, if you're soy-free, gluten-conscious, lactose-free, nut-free, non-GMO,
[00:46:18.840 --> 00:46:25.320]   or if you're like me and you just want tasty, tasty stuff, you get to customize what comes
[00:46:25.320 --> 00:46:26.560]   in your box.
[00:46:26.560 --> 00:46:28.320]   You can also select by taste.
[00:46:28.320 --> 00:46:33.360]   And actually, this is important because I didn't know this, but when you start designing
[00:46:33.360 --> 00:46:38.320]   your own pack, you really do want to balance between savory, sweet, or spicy.
[00:46:38.320 --> 00:46:40.680]   Previously I thought, "Oh, snacks, this chocolate."
[00:46:40.680 --> 00:46:42.280]   Does everything taste like chocolate?
[00:46:42.280 --> 00:46:43.280]   No.
[00:46:43.280 --> 00:46:44.920]   Now I can go by mood.
[00:46:44.920 --> 00:46:48.000]   Sometimes I want something really, really sweet.
[00:46:48.000 --> 00:46:50.680]   Sometimes I want something a little bit of salty with a little bit of tang.
[00:46:50.680 --> 00:46:56.160]   And then sometimes I just want something that's a little bit of wholesome goodness.
[00:46:56.160 --> 00:47:03.080]   That's what I love about nature box, which is it allows me to plan my snacking.
[00:47:03.080 --> 00:47:06.600]   When you plan your snacking, you get much healthier snacks.
[00:47:06.600 --> 00:47:08.760]   So here's what we want you to do.
[00:47:08.760 --> 00:47:14.360]   We want you to try guilt-free snacks, things like coconut date, energy bites, Santa Fe,
[00:47:14.360 --> 00:47:19.600]   corn sticks, which I love, pair pry-lean crunch in over 100 more healthy choices.
[00:47:19.600 --> 00:47:24.640]   Go to naturebox.com/twit and get 50% off your first box.
[00:47:24.640 --> 00:47:25.640]   Stay full.
[00:47:25.640 --> 00:47:26.640]   Stay strong.
[00:47:26.640 --> 00:47:29.520]   Go to naturebox.com/twit.
[00:47:29.520 --> 00:47:33.400]   And we thank nature box for their support of this week in tech.
[00:47:33.400 --> 00:47:35.480]   Now seriously Harry, you got to grab one of these.
[00:47:35.480 --> 00:47:36.480]   These are pretty good.
[00:47:36.480 --> 00:47:37.760]   We'll send you one, Steve.
[00:47:37.760 --> 00:47:38.760]   Alright.
[00:47:38.760 --> 00:47:40.960]   Are you a savory guy, a sweet guy?
[00:47:40.960 --> 00:47:41.960]   What's it going to be?
[00:47:41.960 --> 00:47:43.160]   I want savory guy.
[00:47:43.160 --> 00:47:44.160]   You're a savory guy.
[00:47:44.160 --> 00:47:45.160]   Oh.
[00:47:45.160 --> 00:47:46.160]   The spicy one sounds good too.
[00:47:46.160 --> 00:47:48.440]   Okay, actually then you're going to love the Santa Fe corn sticks.
[00:47:48.440 --> 00:47:50.120]   That's actually my favorite right now.
[00:47:50.120 --> 00:47:54.840]   They also have these spicy peas, dried peas.
[00:47:54.840 --> 00:47:56.840]   Oh, the wispabi peas?
[00:47:56.840 --> 00:47:57.840]   Yeah.
[00:47:57.840 --> 00:48:00.240]   I mean, obviously most of the stuff, I used to make fun of it.
[00:48:00.240 --> 00:48:03.760]   I'm like, I was going to eat that, but it's actually good stuff.
[00:48:03.760 --> 00:48:04.840]   Go figure.
[00:48:04.840 --> 00:48:09.440]   And you know me, if it's food, I'll eat it.
[00:48:09.440 --> 00:48:10.440]   Alright.
[00:48:10.440 --> 00:48:11.440]   Yeah.
[00:48:11.440 --> 00:48:14.640]   Now, we were just talking a little bit about how to be a D bag in San Francisco.
[00:48:14.640 --> 00:48:18.680]   Let's talk about how not to be a D bag and extract value out of something that wasn't
[00:48:18.680 --> 00:48:24.640]   there before and then maybe get smacked down, which specifically talking about Uber and
[00:48:24.640 --> 00:48:25.640]   Lyft.
[00:48:25.640 --> 00:48:27.680]   Steve, you were just talking about Uber and Lyft.
[00:48:27.680 --> 00:48:29.480]   Have you actually used Uber and Lyft?
[00:48:29.480 --> 00:48:30.480]   Yeah.
[00:48:30.480 --> 00:48:31.480]   I've never used Lyft.
[00:48:31.480 --> 00:48:34.800]   I use Uber a lot, both in New York and when I'm visiting San Francisco.
[00:48:34.800 --> 00:48:38.240]   And I mean, it's amazing, especially here in New York.
[00:48:38.240 --> 00:48:41.600]   If it's rainy or rush hour, you can't get a yellow cab.
[00:48:41.600 --> 00:48:43.480]   I mean, Uber is always there.
[00:48:43.480 --> 00:48:47.480]   Yes, they do the search pricing thing sometimes, but it does guarantee you always have a car
[00:48:47.480 --> 00:48:49.040]   and a way to get around.
[00:48:49.040 --> 00:48:50.520]   I'm obsessed with it.
[00:48:50.520 --> 00:48:55.240]   And we don't have Lyft here, but I am curious to try it next time I'm out in San Francisco.
[00:48:55.240 --> 00:48:56.640]   Now, Harry, what about you?
[00:48:56.640 --> 00:48:59.320]   Because I actually used Uber twice.
[00:48:59.320 --> 00:49:01.280]   The first time it was fantastic, I thought it was great.
[00:49:01.280 --> 00:49:02.600]   It got me to where I needed to go.
[00:49:02.600 --> 00:49:06.640]   I live in San Francisco, so I don't like driving because I can never part.
[00:49:06.640 --> 00:49:11.840]   But the second time my driver got lost, we actually ended up on the road.
[00:49:11.840 --> 00:49:14.280]   And I kept telling him, I don't think this is where we're supposed to be going.
[00:49:14.280 --> 00:49:16.840]   He's like, no, no, I've lived here for 20 years.
[00:49:16.840 --> 00:49:18.840]   And I mean, we ended up on the wrong side of the city.
[00:49:18.840 --> 00:49:20.600]   And then he wanted to charge me for the entire fair.
[00:49:20.600 --> 00:49:22.720]   And I'm thinking, no, no.
[00:49:22.720 --> 00:49:27.160]   I mean, that's sort of the inconsistency that I can't abide.
[00:49:27.160 --> 00:49:30.200]   Harry, have you been using the cars with the pink mustaches?
[00:49:30.200 --> 00:49:35.440]   I've been in Lyft a couple of times, and in Uber a couple of times.
[00:49:35.440 --> 00:49:39.240]   But I have lots of nightmare stories about cab drivers who have gone to the wrong side
[00:49:39.240 --> 00:49:43.760]   of town or won't go where I want them to go or charge me for their mistakes.
[00:49:43.760 --> 00:49:49.400]   So it's not like-- I mean, if taxi cabs were a great experience, Lyft and Uber would
[00:49:49.400 --> 00:49:51.360]   not have an opportunity.
[00:49:51.360 --> 00:49:51.880]   Yeah.
[00:49:51.880 --> 00:49:57.160]   I think that's what it comes down to, because when I lived in DC, it was all taxi.
[00:49:57.160 --> 00:49:58.160]   We didn't have a car.
[00:49:58.160 --> 00:50:02.240]   We had to use a taxi if you want to get somewhere that the trains didn't go.
[00:50:02.240 --> 00:50:06.080]   And you just kind of expected it was going to be an unpleasant experience.
[00:50:06.080 --> 00:50:10.280]   And in San Francisco, cabs in general I have found are particularly bad.
[00:50:10.280 --> 00:50:12.120]   You can't get them.
[00:50:12.120 --> 00:50:14.000]   You call them and they don't come.
[00:50:14.000 --> 00:50:16.280]   They don't know what they're doing.
[00:50:16.280 --> 00:50:21.280]   I once was in a cab that got into a funeral procession with me in it.
[00:50:21.280 --> 00:50:26.640]   And a cop wrote alongside us on his motorcycle screaming at the cab driver until he got
[00:50:26.640 --> 00:50:29.600]   out of the funeral procession.
[00:50:29.600 --> 00:50:33.520]   I had a cab driver who was stopped for speeding in San Francisco.
[00:50:33.520 --> 00:50:35.040]   It's funny you should mention that.
[00:50:35.040 --> 00:50:40.600]   Just two weeks ago I had a cab that-- I didn't have a cab until later.
[00:50:40.600 --> 00:50:44.960]   I couldn't get a cab because I was in my full priest outfit and I had a big cross.
[00:50:44.960 --> 00:50:47.080]   And I guess that's scary at 10 o'clock at night.
[00:50:47.080 --> 00:50:49.520]   People were like, oh, crazy person.
[00:50:49.520 --> 00:50:50.520]   I should have used Uber.
[00:50:50.520 --> 00:50:52.240]   Okay, anyways, let's get down to the story.
[00:50:52.240 --> 00:50:56.240]   So what we have is a little bit of pain and a little bit of joy for Uber.
[00:50:56.240 --> 00:51:02.040]   In London, Uber was in trouble because only the city's black taxis are allowed by law
[00:51:02.040 --> 00:51:05.000]   to use meters to charge customers.
[00:51:05.000 --> 00:51:06.000]   That's how they work.
[00:51:06.000 --> 00:51:10.160]   However, the transport for London, which controls all that, has decided that phones
[00:51:10.160 --> 00:51:16.280]   on which the Uber and Lyft apps reside are not taximeters within the meaning of the current
[00:51:16.280 --> 00:51:17.480]   legislation.
[00:51:17.480 --> 00:51:22.760]   That decision could change when another court convenes in the fall to actually decide what
[00:51:22.760 --> 00:51:24.280]   a meter constitutes.
[00:51:24.280 --> 00:51:29.280]   But the end result is that Uber can continue to operate in London along with Lyft.
[00:51:29.280 --> 00:51:31.360]   It's a different thing stateside.
[00:51:31.360 --> 00:51:35.880]   Just this last week, the Public Utilities Commission of Pittsburgh, Pennsylvania, has
[00:51:35.880 --> 00:51:40.120]   issued cease and desist orders for both Uber and Lyft.
[00:51:40.120 --> 00:51:45.440]   Both crowdsourced transportation options must immediately cease to operate in the boundaries
[00:51:45.440 --> 00:51:46.720]   of Pittsburgh.
[00:51:46.720 --> 00:51:49.880]   Unlike London, the issue is not about the technology.
[00:51:49.880 --> 00:51:54.200]   It's not about the meters, but it's about three issues that the PUC pointed out.
[00:51:54.200 --> 00:51:56.560]   The first is driver background checks.
[00:51:56.560 --> 00:51:58.480]   The second is proper insurance.
[00:51:58.480 --> 00:52:02.520]   And the third is proper inspection of cars and drivers.
[00:52:02.520 --> 00:52:05.560]   Now I'm not going to let my bad experience color it.
[00:52:05.560 --> 00:52:07.320]   I want to hand it off to you.
[00:52:07.320 --> 00:52:09.640]   Steve, you first.
[00:52:09.640 --> 00:52:15.960]   This, you know, when people are championing Uber and Lyft, they say, well, this is really
[00:52:15.960 --> 00:52:23.120]   just a grab by the existing taxi cab concessionaires who don't want another option in the cities
[00:52:23.120 --> 00:52:24.240]   in which they operate.
[00:52:24.240 --> 00:52:26.440]   But those are actually important things.
[00:52:26.440 --> 00:52:30.720]   I mean, I actually started thinking about that on that second trip, which is I was like,
[00:52:30.720 --> 00:52:32.000]   does this guy even have a license?
[00:52:32.000 --> 00:52:33.880]   Does he know what he's going?
[00:52:33.880 --> 00:52:36.000]   The car was kind of ratty.
[00:52:36.000 --> 00:52:37.480]   That's not controlled under Uber.
[00:52:37.480 --> 00:52:40.400]   It is kind of buyer beware, right?
[00:52:40.400 --> 00:52:41.400]   It is.
[00:52:41.400 --> 00:52:46.400]   You know, so Uber has this platform again that lets anyone kind of get in and become
[00:52:46.400 --> 00:52:48.960]   this Uber driver as long as they meet certain standards.
[00:52:48.960 --> 00:52:54.720]   I think they have a car of a certain model year and has to be four doors and so on.
[00:52:54.720 --> 00:52:57.480]   But that's, and I think insured too, but I'm not sure.
[00:52:57.480 --> 00:53:02.520]   But you know, that's really all the regulation that Uber gets.
[00:53:02.520 --> 00:53:07.560]   You know, they're not regulated in the same sense that traditional city taxis are.
[00:53:07.560 --> 00:53:12.560]   And I think the Pittsburgh example is much more relevant in the near term than the London
[00:53:12.560 --> 00:53:17.120]   one just because, you know, in these cities, you kind of hinted at this that, you know,
[00:53:17.120 --> 00:53:19.520]   there are a lot of players here.
[00:53:19.520 --> 00:53:25.360]   You know, they're the traditional taxi and cab commissions and other black car services
[00:53:25.360 --> 00:53:30.360]   who are licensed and it really bothers them when someone can just come in and take their
[00:53:30.360 --> 00:53:34.560]   business without being regulated the way they have to be regulated.
[00:53:34.560 --> 00:53:38.600]   Another part of this is if you want to be a little cynical, it's part of the city government.
[00:53:38.600 --> 00:53:43.160]   You know, they want those taxes and fees from the drivers or Uber itself and they want
[00:53:43.160 --> 00:53:44.560]   to license these cars.
[00:53:44.560 --> 00:53:47.960]   On the other hand, there is, yes, there's definitely a public safety issue and this is
[00:53:47.960 --> 00:53:51.160]   something Uber has to tackle.
[00:53:51.160 --> 00:53:53.960]   You know, insurance, you know, we've heard the Uber horror stories.
[00:53:53.960 --> 00:53:57.520]   I think there was one in San Francisco where a little girl got hit or a little kid got
[00:53:57.520 --> 00:53:59.560]   hit and things like that.
[00:53:59.560 --> 00:54:03.240]   And you know, those drivers can kind of say, oh, I'm not plugged into the Uber system right
[00:54:03.240 --> 00:54:04.240]   now.
[00:54:04.240 --> 00:54:05.240]   But those need to be regulated.
[00:54:05.240 --> 00:54:07.120]   It is a public safety issue.
[00:54:07.120 --> 00:54:11.880]   So I think the answer is kind of this hybrid thing where Uber, yes, they need to eventually
[00:54:11.880 --> 00:54:18.040]   start only licensing their cars for public safety reasons.
[00:54:18.040 --> 00:54:24.000]   And then also, you know, the city governments, you know, there's too much influence from
[00:54:24.000 --> 00:54:27.120]   these lobbyists, from the traditional car companies.
[00:54:27.120 --> 00:54:31.040]   There's a lot of money flowing in there and a lot of thuggish behavior going on behind
[00:54:31.040 --> 00:54:33.840]   the scenes that hasn't really been reported on.
[00:54:33.840 --> 00:54:35.520]   The chat room is completely polarized.
[00:54:35.520 --> 00:54:38.960]   I don't know if either of you are watching the chat right now, but it seems everyone
[00:54:38.960 --> 00:54:43.400]   in there either believes that Uber and Lyft are the way to go and that the public utilities
[00:54:43.400 --> 00:54:47.520]   commission is in the pockets of the unions or you got people saying, no, no, no, this
[00:54:47.520 --> 00:54:48.720]   is a safety thing, man.
[00:54:48.720 --> 00:54:52.400]   I mean, seriously, we have registered cabs for a reason.
[00:54:52.400 --> 00:54:57.080]   We have, we have this regulation because it's a safety issue for the public.
[00:54:57.080 --> 00:55:00.040]   And it doesn't seem like either of them are willing to concede any.
[00:55:00.040 --> 00:55:02.160]   It's always got to be one or the other.
[00:55:02.160 --> 00:55:08.240]   Uber is awesome and we should allow it because it's the best thing ever or Uber eventually
[00:55:08.240 --> 00:55:10.320]   is going to kill someone and then what happens?
[00:55:10.320 --> 00:55:13.200]   It's, you know, that's, that's a weird place to be.
[00:55:13.200 --> 00:55:20.400]   Well, presumably licensed cab drivers occasionally kill people, not intentionally, hopefully.
[00:55:20.400 --> 00:55:25.120]   So even if it does happen with Uber or Lyft, I don't think it means that the idea is bad.
[00:55:25.120 --> 00:55:26.120]   Yeah.
[00:55:26.120 --> 00:55:27.120]   Yeah.
[00:55:27.120 --> 00:55:30.120]   It's that that's actually one of the things that I think has really bothered me during
[00:55:30.120 --> 00:55:35.360]   this, this entire saga, which is a lot of people are saying it while saying, well, look,
[00:55:35.360 --> 00:55:36.360]   this is new.
[00:55:36.360 --> 00:55:37.520]   This is, this is different.
[00:55:37.520 --> 00:55:39.080]   This is something that the law has to adapt to.
[00:55:39.080 --> 00:55:43.760]   But I see it the other way, which is if you're going to allow for Uber and Lyft, then essentially
[00:55:43.760 --> 00:55:48.880]   what you're telling cab companies is you can ignore any sort of registration.
[00:55:48.880 --> 00:55:53.480]   You can ignore any regulation about your industry and just go back to operating as independent
[00:55:53.480 --> 00:55:54.480]   cabs.
[00:55:54.480 --> 00:55:55.480]   And we don't want that, right?
[00:55:55.480 --> 00:55:56.480]   Steve?
[00:55:56.480 --> 00:55:59.080]   I mean, that's, that's, I don't think that's what Uber people are advocating.
[00:55:59.080 --> 00:56:00.920]   No, totally not.
[00:56:00.920 --> 00:56:04.760]   And I mean, I think the answer, I don't think this is either or issue.
[00:56:04.760 --> 00:56:08.680]   I think there needs to be a hybrid compromise going on here.
[00:56:08.680 --> 00:56:11.560]   There do need to be safety standards.
[00:56:11.560 --> 00:56:14.240]   And unfortunately, it's a, it's a city by city thing.
[00:56:14.240 --> 00:56:17.680]   There's no federal taxi regulator.
[00:56:17.680 --> 00:56:19.880]   You know, it's city by city and state by state.
[00:56:19.880 --> 00:56:22.280]   And that's kind of the battle Uber is fighting right now.
[00:56:22.280 --> 00:56:26.800]   It's like every region and every city is totally different and operates differently
[00:56:26.800 --> 00:56:28.560]   than the next one.
[00:56:28.560 --> 00:56:32.560]   So what, what can fly in New York clearly can't fly in Pittsburgh.
[00:56:32.560 --> 00:56:33.800]   How do you have that hybrid?
[00:56:33.800 --> 00:56:35.480]   I mean, that's what I understand.
[00:56:35.480 --> 00:56:36.720]   Where would the hybrid come into?
[00:56:36.720 --> 00:56:40.600]   Because it would seem as if the diehard Uber fans are saying, no, this, all this is,
[00:56:40.600 --> 00:56:42.920]   this is Lyft sharing and you're tipping someone.
[00:56:42.920 --> 00:56:44.880]   You're helping them out for helping you out.
[00:56:44.880 --> 00:56:49.640]   It's, it's community based versus the taxi cab company, which is very regulated.
[00:56:49.640 --> 00:56:50.840]   It's very regimented.
[00:56:50.840 --> 00:56:51.840]   We understand how it works.
[00:56:51.840 --> 00:56:56.840]   It's a known quantity, which it seems to be diametrically opposed to Uber.
[00:56:56.840 --> 00:57:02.920]   It sounds as if a hybrid compromise would either have to greatly reduce the amount of
[00:57:02.920 --> 00:57:08.160]   regulation that we put upon taxi companies or it would regulate Uber and Lyft to the
[00:57:08.160 --> 00:57:10.600]   point where it's no longer Uber or Lyft.
[00:57:10.600 --> 00:57:15.760]   Yeah, but I mean, it's, it's, uh, well, Lyft is a little bit different than Uber, at least
[00:57:15.760 --> 00:57:19.160]   in my view in the sense that it is kind of like this hippie dippy like, Hey, I'm going
[00:57:19.160 --> 00:57:22.640]   to throw a pink mustache on my Toyota Corolla and you go.
[00:57:22.640 --> 00:57:25.800]   No, it's that they're going to run into more trouble.
[00:57:25.800 --> 00:57:30.320]   I think Uber, they do have, you got to keep in mind, Uber does have license drivers in
[00:57:30.320 --> 00:57:32.720]   their network and they do here in New York.
[00:57:32.720 --> 00:57:36.880]   They have yellow, like yellow cabs can sign on to Uber too.
[00:57:36.880 --> 00:57:40.000]   And so I think one of the miss, this hybrid thing I'm talking about, one of the missed
[00:57:40.000 --> 00:57:46.200]   opportunity is New York does have a system in place for anybody to create an Uber like
[00:57:46.200 --> 00:57:51.560]   app with all that they have all the data and so forth to pull that in, but nobody's doing
[00:57:51.560 --> 00:57:53.640]   it and nobody's doing it as well as Uber.
[00:57:53.640 --> 00:57:55.240]   That's the thing.
[00:57:55.240 --> 00:58:00.720]   And so yeah, do you think there needs to be these people do need to be licensed?
[00:58:00.720 --> 00:58:04.760]   They're does need to, they do need to make sure they're insured and so forth.
[00:58:04.760 --> 00:58:08.520]   But also there's, there is this technology available out there for people to plug into
[00:58:08.520 --> 00:58:10.520]   at least in New York.
[00:58:10.520 --> 00:58:13.280]   And so I think, I think there is a hybrid answer.
[00:58:13.280 --> 00:58:17.200]   Well, you know, I think we can go around in circles here.
[00:58:17.200 --> 00:58:18.200]   Let's go to the audience.
[00:58:18.200 --> 00:58:23.120]   And to show of hands really quickly here, who would feel safe putting your child and actually
[00:58:23.120 --> 00:58:29.240]   if you're your future child into an Uber or Lyft car, show of hands.
[00:58:29.240 --> 00:58:31.200]   Oh, really?
[00:58:31.200 --> 00:58:32.200]   You know what?
[00:58:32.200 --> 00:58:33.640]   You're all going to be horrible parents.
[00:58:33.640 --> 00:58:36.680]   Don't I should have done that actually.
[00:58:36.680 --> 00:58:37.680]   I take that back.
[00:58:37.680 --> 00:58:39.880]   We're not going to the audience ever again.
[00:58:39.880 --> 00:58:41.880]   Obviously they're communists.
[00:58:41.880 --> 00:58:42.880]   Okay.
[00:58:42.880 --> 00:58:48.640]   Let you know what, I want to break away from some of the seriousness for just a second
[00:58:48.640 --> 00:58:51.920]   and talk a little bit about hardware lust.
[00:58:51.920 --> 00:58:54.840]   Have you heard about the new Android Black phone?
[00:58:54.840 --> 00:58:55.840]   Yeah.
[00:58:55.840 --> 00:59:00.840]   Yeah, it's the phone built for the paranoid, Android phone for the paranoid.
[00:59:00.840 --> 00:59:01.840]   Actually, okay.
[00:59:01.840 --> 00:59:02.840]   And I mean this in a good way.
[00:59:02.840 --> 00:59:03.840]   I don't mean paranoid crazy people.
[00:59:03.840 --> 00:59:08.080]   I mean, for people who really, really want some security, the Android Black phone is,
[00:59:08.080 --> 00:59:10.000]   is pretty incredible.
[00:59:10.000 --> 00:59:13.720]   First Technica got their hands on a release of the Black phone.
[00:59:13.720 --> 00:59:18.680]   And from what they can see, it's, the hardware is not all that great.
[00:59:18.680 --> 00:59:20.240]   I mean, it's decent.
[00:59:20.240 --> 00:59:23.880]   It's a 4.7 inch IPS screen, 1280 by 720 resolution.
[00:59:23.880 --> 00:59:27.720]   It's got private OS, which is a fork from Android 4.4 KitKat.
[00:59:27.720 --> 00:59:32.240]   It runs a two gigahertz quad core Nvidia Tegra processor with a Tegra 4i GPU.
[00:59:32.240 --> 00:59:37.440]   It's got one gigabyte of system memory, 16 gigabytes of storage plus a micro SD slot,
[00:59:37.440 --> 00:59:45.560]   an 8 megabyte rear, 5 megapixel rear, 5 megapixel front camera, 2,000 milliamp hour battery,
[00:59:45.560 --> 00:59:48.120]   comes for about $629 on lock.
[00:59:48.120 --> 00:59:53.880]   So that's the hardware, which is, that's basically, what, mid-range and 12-inch.
[00:59:53.880 --> 00:59:54.880]   Yeah, mid-range.
[00:59:54.880 --> 00:59:55.880]   Yeah, mid-range.
[00:59:55.880 --> 00:59:58.480]   But where the magic comes in is what is built into it.
[00:59:58.480 --> 01:00:03.440]   It's got a two-year subscription to Silent Circles, secure voice and video text messaging
[01:00:03.440 --> 01:00:04.600]   services.
[01:00:04.600 --> 01:00:09.360]   It's got three one-year subscriptions to Silent Circle that you can gift to people who you
[01:00:09.360 --> 01:00:11.360]   want to communicate securely with.
[01:00:11.360 --> 01:00:18.520]   Two years of one gigabyte per month VPN service from Disconnect, Disconnect's automatic anonymous
[01:00:18.520 --> 01:00:20.920]   search service baked into the browser.
[01:00:20.920 --> 01:00:26.200]   Two years of Spyder Oak secure cloud storage and sharing with five gigabytes a month of
[01:00:26.200 --> 01:00:31.360]   transfer and some cool software, including one called Kismet Smarter Wi-Fi, which keeps
[01:00:31.360 --> 01:00:35.200]   the phone from being spoofed or connected to untrusted networks.
[01:00:35.200 --> 01:00:39.560]   It learns the location of your trusted networks by noting its location via the cell tower
[01:00:39.560 --> 01:00:45.920]   it detects and then it can't be tricked into connecting to a rogue AP that's trying to
[01:00:45.920 --> 01:00:47.080]   slurp your data.
[01:00:47.080 --> 01:00:52.000]   Now, of course, encryption is built in heavy end-to-end encryption on everything that you
[01:00:52.000 --> 01:00:53.680]   do on this phone.
[01:00:53.680 --> 01:00:59.800]   And the whole idea is this is the phone you want to use if you're tired of people looking
[01:00:59.800 --> 01:01:01.280]   at your data.
[01:01:01.280 --> 01:01:06.280]   Well, Steve, would you pay $629 for this?
[01:01:06.280 --> 01:01:11.240]   No, I mean, I'm a spec geek too, so I want a more powerful phone.
[01:01:11.240 --> 01:01:15.640]   But also, I mean, I think this is a very narrow audience they're going after.
[01:01:15.640 --> 01:01:18.760]   Kind of like you said, the paranoid folks who really think people are going to be spoofing
[01:01:18.760 --> 01:01:22.080]   their Wi-Fi or whatever.
[01:01:22.080 --> 01:01:27.920]   And then again, it's also how secure is it with that new NSA story that came out.
[01:01:27.920 --> 01:01:31.000]   They can dig into anything it seems like.
[01:01:31.000 --> 01:01:37.120]   I'm no security expert, but it does sound like at least the standard Android and iOS.
[01:01:37.120 --> 01:01:41.640]   And especially iOS 8 has some really great features that provide a lot of this already
[01:01:41.640 --> 01:01:43.520]   out of the box.
[01:01:43.520 --> 01:01:47.760]   But certain people, I think this will be a decent option that the so-called paranoid
[01:01:47.760 --> 01:01:48.760]   folks.
[01:01:48.760 --> 01:01:52.840]   I'm going back and forth wondering if-- because I mean, it's not a poorly designed phone.
[01:01:52.840 --> 01:01:55.360]   It looks like it's pretty well integrated with all the security features.
[01:01:55.360 --> 01:01:59.320]   But I'm wondering if they're just trying to take advantage of the security scare right
[01:01:59.320 --> 01:02:00.320]   now.
[01:02:00.320 --> 01:02:03.760]   And I think they're so freaked out that everyone is listening to everything that you have on
[01:02:03.760 --> 01:02:05.760]   your phone.
[01:02:05.760 --> 01:02:06.760]   That's what they're doing.
[01:02:06.760 --> 01:02:07.760]   They're just taking advantage of that.
[01:02:07.760 --> 01:02:09.680]   In which case, I really don't like it.
[01:02:09.680 --> 01:02:14.880]   But like you said, Steve, a lot of these security features you could just load on your current
[01:02:14.880 --> 01:02:15.880]   phone.
[01:02:15.880 --> 01:02:19.080]   So the only reason why you would get this is if you really believe that there are so many
[01:02:19.080 --> 01:02:25.960]   back doors into your device right now that you want a clean OS that has been forked off
[01:02:25.960 --> 01:02:26.960]   of the main.
[01:02:26.960 --> 01:02:27.960]   No, Harry?
[01:02:27.960 --> 01:02:30.560]   Well, I mean, Steve is right.
[01:02:30.560 --> 01:02:35.640]   I think the more interesting thing is Apple and Google and hardware makers doing some
[01:02:35.640 --> 01:02:38.320]   of this stuff because that can reach far more people.
[01:02:38.320 --> 01:02:43.480]   And Apple is doing stuff like, I guess it's scrambling the MAC address when your phone
[01:02:43.480 --> 01:02:49.520]   reports itself out, which sounds like that's going to be really good in terms of security.
[01:02:49.520 --> 01:02:53.000]   And it's going to be something that every person who has an iPhone will take advantage
[01:02:53.000 --> 01:02:54.560]   of whether they know it or not.
[01:02:54.560 --> 01:02:58.840]   I mean, the black phone is something that you're going to buy if you're a hardcore privacy
[01:02:58.840 --> 01:03:04.440]   and security kind of person, which most people would rather that their phone did the heavy
[01:03:04.440 --> 01:03:08.280]   left in and didn't make them have to think about this stuff.
[01:03:08.280 --> 01:03:09.280]   Yeah.
[01:03:09.280 --> 01:03:10.960]   And actually, that's a good point.
[01:03:10.960 --> 01:03:14.840]   We do have another story about security on the Android device.
[01:03:14.840 --> 01:03:22.080]   Now, you may remember that in the latest update to iOS, Apple changed the way that the
[01:03:22.080 --> 01:03:27.440]   Wi-Fi system works so that it automatically anonymizes the MAC address, which means that
[01:03:27.440 --> 01:03:31.440]   someone who's trying to track you via your MAC address won't be able to do it.
[01:03:31.440 --> 01:03:33.880]   They won't be able to do it quite as easily.
[01:03:33.880 --> 01:03:39.480]   However, there was a story about how the EFF has approached Google with what seems to
[01:03:39.480 --> 01:03:44.560]   be a pretty serious flaw in the way that Google handles Wi-Fi connections.
[01:03:44.560 --> 01:03:50.720]   So right now, if you take your Google phone like this, I've got mine here, even though
[01:03:50.720 --> 01:03:55.000]   I'm not doing anything on it, because my Wi-Fi is on and because I'm not connected to any
[01:03:55.000 --> 01:04:01.560]   networks in this area, it's constantly broadcasting names of networks that I have connected to
[01:04:01.560 --> 01:04:02.560]   previously.
[01:04:02.560 --> 01:04:06.760]   The reason why it does this is it wants to be able to really quickly establish that network
[01:04:06.760 --> 01:04:10.720]   connection when I do turn it on.
[01:04:10.720 --> 01:04:18.040]   So as a result, if I was listening with the right device, I would see the names and the
[01:04:18.040 --> 01:04:22.000]   MAC addresses of all the APs that your device is connected to.
[01:04:22.000 --> 01:04:26.380]   And if I have a big enough database, it means I could actually track your movements throughout
[01:04:26.380 --> 01:04:27.380]   the day.
[01:04:27.380 --> 01:04:28.380]   That's kind of scary.
[01:04:28.380 --> 01:04:33.260]   That actually goes away with the Kismit Wi-Fi manager on the black phone, because the black
[01:04:33.260 --> 01:04:38.360]   phone will automatically anonymize and spoof your address so they couldn't do that.
[01:04:38.360 --> 01:04:41.600]   Now would you buy it, Steve?
[01:04:41.600 --> 01:04:46.600]   Yeah, if it was an only Android user, that is a little troublesome.
[01:04:46.600 --> 01:04:51.360]   And I think Apple is doing something here that Google is in, and that's like Harry said,
[01:04:51.360 --> 01:04:53.280]   just doing the lifting in the background for people.
[01:04:53.280 --> 01:04:54.480]   So they don't even have to think about it.
[01:04:54.480 --> 01:04:56.320]   I think that's the answer.
[01:04:56.320 --> 01:05:03.040]   I'm not sure if buying a brand new $630 phone is for people is the answer.
[01:05:03.040 --> 01:05:08.160]   It's on Google and the Android developers to make sure this happens right away.
[01:05:08.160 --> 01:05:16.400]   And I think EFF has a very good case here and it very, they raise a very legitimate concern.
[01:05:16.400 --> 01:05:21.200]   Now the chances that somebody is tracking your movements this way, very slim.
[01:05:21.200 --> 01:05:24.280]   But I'd like to see Google do what Apple is doing and just err on the side of caution
[01:05:24.280 --> 01:05:27.000]   and do the work for users.
[01:05:27.000 --> 01:05:31.560]   Well, 5088 in the chat room says, look, the black phone is all about exploiting security
[01:05:31.560 --> 01:05:34.160]   theater, which I actually think he has a good.
[01:05:34.160 --> 01:05:35.160]   You know what?
[01:05:35.160 --> 01:05:36.160]   I'm going to give the audience another chance here.
[01:05:36.160 --> 01:05:38.040]   We're going to cut back to them.
[01:05:38.040 --> 01:05:44.360]   How many of you are concerned about being tracked on your device?
[01:05:44.360 --> 01:05:45.360]   You know what?
[01:05:45.360 --> 01:05:47.240]   I'm just going to the audience.
[01:05:47.240 --> 01:05:48.240]   My cuteness.
[01:05:48.240 --> 01:05:54.600]   You know, some people say that Apple is in a better position than Google to take a lead
[01:05:54.600 --> 01:05:59.280]   on this because Google's business is about watching what you do with your devices and
[01:05:59.280 --> 01:06:01.400]   monetizing it through advertising.
[01:06:01.400 --> 01:06:06.600]   And because Apple is a company that sells hardware, they don't have that incentive to
[01:06:06.600 --> 01:06:08.000]   kind of keep track of what you're up to.
[01:06:08.000 --> 01:06:11.200]   And for them, it's kind of an easy decision to err on the side of privacy.
[01:06:11.200 --> 01:06:16.160]   But I would love to see them get enough kudos for that that Google has to match what they're
[01:06:16.160 --> 01:06:17.160]   doing.
[01:06:17.160 --> 01:06:18.160]   All right.
[01:06:18.160 --> 01:06:19.160]   Right.
[01:06:19.160 --> 01:06:20.160]   Any last words, Steve?
[01:06:20.160 --> 01:06:24.200]   Are you further concerned or do you agree with Web 5088?
[01:06:24.200 --> 01:06:25.560]   This is a security theater.
[01:06:25.560 --> 01:06:28.120]   This is another way to sell an expensive phone.
[01:06:28.120 --> 01:06:29.120]   Yeah.
[01:06:29.120 --> 01:06:32.400]   I think it's just a way to get people to buy an expensive phone.
[01:06:32.400 --> 01:06:36.640]   I mean, there's probably a very, and I'm sure they know this, a very small group of people
[01:06:36.640 --> 01:06:37.800]   who'd be interested in it.
[01:06:37.800 --> 01:06:43.120]   For most people, your standard Samsung or HTC phone will be just fine.
[01:06:43.120 --> 01:06:47.760]   And then again, it is on Google to really take this issue and just build that into Android
[01:06:47.760 --> 01:06:48.960]   like Apple did.
[01:06:48.960 --> 01:06:49.960]   All right.
[01:06:49.960 --> 01:06:56.560]   Well, I was hoping people would be more paranoid and more hating on both security and lift
[01:06:56.560 --> 01:06:58.720]   and Uber, but I guess I'm overruled.
[01:06:58.720 --> 01:06:59.720]   All right.
[01:06:59.720 --> 01:07:05.040]   Let's move on to a little something something about New York's anti-cyber bullying law.
[01:07:05.040 --> 01:07:11.200]   You may have read this week that in November of 2010, Albany County enacted the nation's
[01:07:11.200 --> 01:07:18.080]   toughest cyberbullying laws in response to a young man posting pictures and nasty comments
[01:07:18.080 --> 01:07:19.240]   of his classmates.
[01:07:19.240 --> 01:07:20.600]   Well, they just struck it down.
[01:07:20.600 --> 01:07:27.520]   New York's highest court has come back and ruled that the ban on cyberbullying was overly
[01:07:27.520 --> 01:07:28.520]   broad.
[01:07:28.520 --> 01:07:32.280]   Now they made it clear that the law could actually be enacted.
[01:07:32.280 --> 01:07:35.120]   You could build anti-cyber bullying legislation.
[01:07:35.120 --> 01:07:42.120]   They just thought what Albany did, which would allow for the criminalization of any form of
[01:07:42.120 --> 01:07:47.760]   harassment, electronic harassment punishable by $1,000 of fine or one year in jail.
[01:07:47.760 --> 01:07:51.680]   They thought that the way that you worded it is just not right.
[01:07:51.680 --> 01:07:56.200]   I think this is back to that the law of unintended consequences.
[01:07:56.200 --> 01:07:58.040]   Steve, have you followed this case at all?
[01:07:58.040 --> 01:08:00.600]   Because two years ago, it was big.
[01:08:00.600 --> 01:08:06.160]   And when the law was first challenged, people started saying, "This will actually be a good
[01:08:06.160 --> 01:08:07.160]   case."
[01:08:07.160 --> 01:08:12.600]   Can you legally outlaw cyberbullying when it seems to be a constitutional fact, a constitutional
[01:08:12.600 --> 01:08:14.360]   right to be mean?
[01:08:14.360 --> 01:08:15.360]   Yeah.
[01:08:15.360 --> 01:08:18.320]   Well, there's mean and then there's threatening.
[01:08:18.320 --> 01:08:25.720]   We've heard numerous examples of the years of suicides from cyberbullying and self-harm from
[01:08:25.720 --> 01:08:26.720]   cyberbullying.
[01:08:26.720 --> 01:08:33.360]   So it is a very real and very serious public safety issue.
[01:08:33.360 --> 01:08:36.680]   But I've been following it a little bit just tangentially.
[01:08:36.680 --> 01:08:41.880]   And I mean, the law, as written, didn't seem overly broad.
[01:08:41.880 --> 01:08:45.040]   I think it was very clear what constitutes cyberbullying.
[01:08:45.040 --> 01:08:47.560]   Yeah, we have it up on the screen right now.
[01:08:47.560 --> 01:08:51.560]   I don't know how more narrow you can get.
[01:08:51.560 --> 01:08:52.960]   Maybe Harry has an opinion on that.
[01:08:52.960 --> 01:08:59.920]   But it literally describes what cyberbullying is right there.
[01:08:59.920 --> 01:09:02.240]   And I think it's very easy to detect.
[01:09:02.240 --> 01:09:08.320]   And a reasonable person can detect what constitutes cyberbullying and what doesn't.
[01:09:08.320 --> 01:09:10.200]   And I think that law spells it out pretty well.
[01:09:10.200 --> 01:09:15.800]   So I'm curious to read that whole court's opinion on why they think it's overly broad.
[01:09:15.800 --> 01:09:19.200]   Yeah, that's actually what had me so puzzled.
[01:09:19.200 --> 01:09:24.640]   So if you look at the-- Chad was actually just showing you what the legislation says.
[01:09:24.640 --> 01:09:29.760]   Cyberbullying was defined as any act of communicating by mechanical electronic means, including
[01:09:29.760 --> 01:09:34.600]   posting statements on the internet or through a computer or email network that disseminate
[01:09:34.600 --> 01:09:40.120]   embarrassing or sexually explicit photographs, disseminate private personal false or sexual
[01:09:40.120 --> 01:09:45.960]   information that include hate mail or include information with no legitimate private personal
[01:09:45.960 --> 01:09:52.720]   or public purpose, with the intent to harass, annoy, threaten, abuse, taunt, intimidate,
[01:09:52.720 --> 01:09:57.360]   torment, humiliate, or otherwise inflict significant emotional harm on another person.
[01:09:57.360 --> 01:09:59.400]   So they defined what it is.
[01:09:59.400 --> 01:10:01.280]   They defined what's included.
[01:10:01.280 --> 01:10:02.440]   And they actually added intent.
[01:10:02.440 --> 01:10:04.480]   There has to be an intent to harass.
[01:10:04.480 --> 01:10:07.200]   It can't just have been a random posting.
[01:10:07.200 --> 01:10:10.520]   I mean, Harry, how do you get more narrow than that?
[01:10:10.520 --> 01:10:12.600]   I mean, it seems pretty clear to me.
[01:10:12.600 --> 01:10:16.360]   And I mean, online harassment is a really serious issue.
[01:10:16.360 --> 01:10:20.080]   And in general, I err on the side of being sympathetic to the people being harassed rather
[01:10:20.080 --> 01:10:21.320]   than the harassers.
[01:10:21.320 --> 01:10:22.320]   Yeah.
[01:10:22.320 --> 01:10:25.760]   I just-- I don't know how to take this.
[01:10:25.760 --> 01:10:32.200]   You know, again, the case was started back in 2011 by a young man by the name of Mark
[01:10:32.200 --> 01:10:39.480]   Juan Markey Meigs, who in 2011 created a Facebook page that included pictures of his classmates.
[01:10:39.480 --> 01:10:45.120]   And I remember properly, he was writing things like slot or sleeps around.
[01:10:45.120 --> 01:10:48.560]   It was-- I mean, stuff that a 15-year-old would write.
[01:10:48.560 --> 01:10:49.880]   It was designed to be hurtful.
[01:10:49.880 --> 01:10:53.400]   Obviously, he was trying to make fun of these people.
[01:10:53.400 --> 01:10:57.600]   And he pleaded guilty to cyberbullying, which is a misdemeanor.
[01:10:57.600 --> 01:11:04.400]   Now, he challenged on First Amendment grounds even after pleading guilty.
[01:11:04.400 --> 01:11:13.760]   Now, but since the Court of Appeals has agreed 5-2 that the statute was overly broad, his
[01:11:13.760 --> 01:11:15.680]   conviction is now avoided.
[01:11:15.680 --> 01:11:20.120]   So let me throw this over to you, Steve.
[01:11:20.120 --> 01:11:22.000]   Is there no way to outlaw cyberbullying?
[01:11:22.000 --> 01:11:27.040]   Because it is currently on the books of over a dozen states, a dozen counties.
[01:11:27.040 --> 01:11:30.400]   Is there no way to say, hey, stop acting like a jerk?
[01:11:30.400 --> 01:11:33.040]   Well, I mean, keep in mind this is only New York.
[01:11:33.040 --> 01:11:38.680]   Like you said, there are probably other states and municipalities where this is-- there are
[01:11:38.680 --> 01:11:40.640]   laws.
[01:11:40.640 --> 01:11:46.480]   And I think the New York Court did say that, OK, we are open to having such laws.
[01:11:46.480 --> 01:11:48.840]   It just needs to be super narrow.
[01:11:48.840 --> 01:11:50.800]   I don't know what else Albany could do.
[01:11:50.800 --> 01:11:54.640]   I don't know how-- this is really and truly baffling.
[01:11:54.640 --> 01:11:58.040]   And like Harry said, I mean, I don't have kids, but I have colleagues and friends who
[01:11:58.040 --> 01:11:59.080]   have kids.
[01:11:59.080 --> 01:12:02.480]   And it is a very serious problem, especially in that age group.
[01:12:02.480 --> 01:12:05.640]   I tend to, let's say, 16 or whatever.
[01:12:05.640 --> 01:12:11.520]   And there have been a lot of high profile cases and stories over the last few years of
[01:12:11.520 --> 01:12:18.280]   just that cyberbullying and pretty much people following that law or doing what was described
[01:12:18.280 --> 01:12:20.320]   in a law to the letter.
[01:12:20.320 --> 01:12:23.680]   That case in New Jersey, I think it was the Rutgers student who killed himself after being
[01:12:23.680 --> 01:12:24.680]   cyberbullied.
[01:12:24.680 --> 01:12:28.240]   That was huge and very sad story.
[01:12:28.240 --> 01:12:33.320]   So it is an important kind of law to have.
[01:12:33.320 --> 01:12:39.280]   It's just very unfortunate that the Supreme Court in New York didn't think it was.
[01:12:39.280 --> 01:12:42.560]   And the chat room is pretty clear that they're all saying, look, people are jerks.
[01:12:42.560 --> 01:12:43.760]   You can't do anything about it.
[01:12:43.760 --> 01:12:46.960]   And others are saying, look, it's a thought crime.
[01:12:46.960 --> 01:12:49.560]   And how do you police thought crimes?
[01:12:49.560 --> 01:12:51.000]   And others are saying kids will be kids.
[01:12:51.000 --> 01:12:57.400]   But what strikes me is, when we actually start talking about cyberbullying today, most
[01:12:57.400 --> 01:12:59.720]   of the time we're not talking about children.
[01:12:59.720 --> 01:13:04.280]   Remember, the repeal of this law also applies to revenge porn.
[01:13:04.280 --> 01:13:06.800]   Revenge porn is a form of cyberbullying.
[01:13:06.800 --> 01:13:11.880]   So if you live in Albany and you break up with someone, you can now post graphic videos
[01:13:11.880 --> 01:13:16.320]   of your former without worrying about being thrown in jail.
[01:13:16.320 --> 01:13:20.720]   I'm not saying that, you know, that it's kind of strange for me to talk about that,
[01:13:20.720 --> 01:13:21.720]   actually.
[01:13:21.720 --> 01:13:23.920]   You shouldn't do that, but you can, I guess.
[01:13:23.920 --> 01:13:24.920]   Yeah.
[01:13:24.920 --> 01:13:25.920]   Yeah.
[01:13:25.920 --> 01:13:26.920]   That's good.
[01:13:26.920 --> 01:13:28.520]   Any last words on cyberbullying?
[01:13:28.520 --> 01:13:30.480]   Or are we just agreeing that people are jerks?
[01:13:30.480 --> 01:13:36.480]   I mean, it's yet another case where no matter how well-intentioned you are and how reasonable
[01:13:36.480 --> 01:13:41.960]   you are, it is really hard to write laws on any of this stuff, even in cases where such
[01:13:41.960 --> 01:13:44.200]   as this, I think you should write those laws.
[01:13:44.200 --> 01:13:45.560]   It's still not easy.
[01:13:45.560 --> 01:13:46.560]   All right.
[01:13:46.560 --> 01:13:49.960]   Well, let's move away from cyberbullying because that's a downer.
[01:13:49.960 --> 01:13:53.280]   Let's talk a little bit about Google buying beats.
[01:13:53.280 --> 01:13:55.160]   No, I totally didn't have it.
[01:13:55.160 --> 01:14:00.600]   Actually, they bought songs after weeks of quiet speculation, which is quite a change
[01:14:00.600 --> 01:14:04.880]   from what we had come to expect from the acquisition of any sort of music company.
[01:14:04.880 --> 01:14:09.360]   Google has acquired songs, which is a long island based music streaming service.
[01:14:09.360 --> 01:14:14.680]   Now, though the exact price of the acquisition is unknown, it's reported to be somewhere
[01:14:14.680 --> 01:14:22.960]   north of $15 million, which, wait, if I do my math, carry the one, is less than $3 billion.
[01:14:22.960 --> 01:14:24.840]   Now here's the interesting thing.
[01:14:24.840 --> 01:14:28.720]   Mike Elgin, why are very old Mike Elgin wrote a very interesting piece about the acquisition
[01:14:28.720 --> 01:14:34.160]   in which he was saying, Google just showed Apple how to do a music acquisition.
[01:14:34.160 --> 01:14:40.640]   Now, of course, that title was a little bit of a link, but let's think it through.
[01:14:40.640 --> 01:14:43.240]   What beats was a premium manufacturer.
[01:14:43.240 --> 01:14:46.800]   And what Mike pointed out was that all of these music companies are looking for what's
[01:14:46.800 --> 01:14:48.800]   called the 360 cell.
[01:14:48.800 --> 01:14:50.840]   You can't make money off of music anymore.
[01:14:50.840 --> 01:14:53.680]   You make money off of the things that are attached to the music.
[01:14:53.680 --> 01:14:54.880]   That's what Apple was after.
[01:14:54.880 --> 01:15:00.320]   You're after the cred, you're after the after-sell, you're after for that upsell.
[01:15:00.320 --> 01:15:03.000]   But what Mike was saying was like, "Look, Apple already had that.
[01:15:03.000 --> 01:15:04.600]   They had a very valuable brand.
[01:15:04.600 --> 01:15:07.800]   They didn't really add anything new with Beats.
[01:15:07.800 --> 01:15:10.200]   All they got was a music streaming service.
[01:15:10.200 --> 01:15:16.800]   And Google just got one of those for 1,000th of the price.
[01:15:16.800 --> 01:15:18.960]   And in songs, they get something that's different.
[01:15:18.960 --> 01:15:24.480]   Beats directly competes with something like Spotify or with Pandora.
[01:15:24.480 --> 01:15:28.680]   But what you get with songs is the human curated playlist, which is unique.
[01:15:28.680 --> 01:15:30.200]   No one else does that.
[01:15:30.200 --> 01:15:31.440]   And it is something that's different.
[01:15:31.440 --> 01:15:37.040]   It is something that Google can integrate into their 360, which is advertising.
[01:15:37.040 --> 01:15:41.760]   Now, so Harry, I hate to use Mike because he's one of our own.
[01:15:41.760 --> 01:15:42.760]   He's not even here.
[01:15:42.760 --> 01:15:46.400]   But do you think this was Beats done right?
[01:15:46.400 --> 01:15:52.480]   Well, I think it's kind of Apple's no pun intended in oranges in some ways.
[01:15:52.480 --> 01:15:57.360]   Not the least of which is because Apple got this large hardware brand, which is doing
[01:15:57.360 --> 01:16:05.640]   extremely well at selling expensive devices, which you plug into other Apple devices.
[01:16:05.640 --> 01:16:07.200]   I think Songz is very cool.
[01:16:07.200 --> 01:16:11.400]   And I kind of worry that it's going to be like a lot of other Google acquisitions where
[01:16:11.400 --> 01:16:15.680]   they kind of really wanted the talented people behind the service.
[01:16:15.680 --> 01:16:20.520]   They're either going to let Songz out language or they're going to explicitly shut it down
[01:16:20.520 --> 01:16:22.560]   at some point.
[01:16:22.560 --> 01:16:26.440]   But I would like to think that they see value in the idea of human curation because there
[01:16:26.440 --> 01:16:31.240]   are all these music services curated by algorithms.
[01:16:31.240 --> 01:16:35.040]   And they just want to have as much personality as the best stuff curated by a person.
[01:16:35.040 --> 01:16:36.040]   Right.
[01:16:36.040 --> 01:16:41.640]   When I was driving up here from San Francisco, I was listening to music curated by human
[01:16:41.640 --> 01:16:44.680]   beings rather than something like Pandora.
[01:16:44.680 --> 01:16:47.400]   And I think I enjoyed it more and I learned more about stuff I might want to listen to
[01:16:47.400 --> 01:16:48.880]   because of that.
[01:16:48.880 --> 01:16:51.920]   I had a very interesting conversation with some geeks last night.
[01:16:51.920 --> 01:16:53.160]   I was doing a hangout.
[01:16:53.160 --> 01:16:59.400]   And one of them said, you know, with Google buying Songz, I could totally see them integrating
[01:16:59.400 --> 01:17:02.760]   this into Google Plus because Google Plus is all about human curation.
[01:17:02.760 --> 01:17:05.800]   It's all about people bringing the best stories to their groups.
[01:17:05.800 --> 01:17:12.800]   Can you imagine if they integrated Songz into G Plus so that people could make playlists
[01:17:12.800 --> 01:17:16.680]   and those playlists could be recommended to Songz subscribers?
[01:17:16.680 --> 01:17:18.200]   I'm not saying that's what they're going to do.
[01:17:18.200 --> 01:17:24.960]   But I mean, it does seem to naturally fit what Google is trying to do with human interaction.
[01:17:24.960 --> 01:17:27.000]   Steve, thoughts?
[01:17:27.000 --> 01:17:28.800]   I disagree with that.
[01:17:28.800 --> 01:17:29.800]   Good.
[01:17:29.800 --> 01:17:34.720]   Putting Songz into Google Plus will just ensure that no one uses Songz again.
[01:17:34.720 --> 01:17:39.000]   Google Plus is, I mean, I know people are going to disagree with me on this, but it is a ghost
[01:17:39.000 --> 01:17:41.520]   town unless you're one of those people.
[01:17:41.520 --> 01:17:44.240]   Yeah, I said it.
[01:17:44.240 --> 01:17:48.240]   But separately from that, you know, it's funny that all these weeks later we're still talking
[01:17:48.240 --> 01:17:52.080]   about the Apple Beats acquisition and trying to make sense of it all.
[01:17:52.080 --> 01:17:56.240]   But I think, you know, you look at the Songz just streaming music service and you look at
[01:17:56.240 --> 01:17:58.000]   Beats.
[01:17:58.000 --> 01:18:02.880]   Songz, like Harry said, you know, it has this unique thing.
[01:18:02.880 --> 01:18:05.240]   It's curated by humans.
[01:18:05.240 --> 01:18:09.120]   And you know, when everyone was talking about the Beats acquisition leading up to the official
[01:18:09.120 --> 01:18:14.520]   announcement and figuring it all out, this video of Jimmy Iovine at one of the All Things
[01:18:14.520 --> 01:18:19.160]   Deconferences surfaced and he was talking about curation and how technology can enable
[01:18:19.160 --> 01:18:22.400]   curation and they're going to create this amazing product which turned out to be Beats
[01:18:22.400 --> 01:18:27.200]   music that can do this curation naturally as if a human were doing it.
[01:18:27.200 --> 01:18:31.240]   Well, I mean, if you've used Beats, it's not really that.
[01:18:31.240 --> 01:18:35.480]   It's mostly just a Spotify and audio clone.
[01:18:35.480 --> 01:18:37.440]   And Songz does just that.
[01:18:37.440 --> 01:18:41.920]   Songz is humans making these, you know, perfectly curated playlists and it's awesome.
[01:18:41.920 --> 01:18:44.440]   I don't know if you have it used it, you should.
[01:18:44.440 --> 01:18:51.080]   And you really do get that cool experience of listening to songs in that perfect order,
[01:18:51.080 --> 01:18:54.840]   you know, just like you're listening to a vinyl or something like that.
[01:18:54.840 --> 01:18:57.760]   So I think Google really did win this.
[01:18:57.760 --> 01:19:03.000]   If you're going to compare the two acquisitions, I think Google, yeah, they got a better service,
[01:19:03.000 --> 01:19:07.760]   a better streaming service for way cheaper.
[01:19:07.760 --> 01:19:09.600]   And hopefully they do something really good with it.
[01:19:09.600 --> 01:19:12.160]   I don't want to see it implemented in Google plus.
[01:19:12.160 --> 01:19:14.480]   I'd like to see it in Google music or something.
[01:19:14.480 --> 01:19:16.520]   I think that would make a lot more sense.
[01:19:16.520 --> 01:19:21.880]   And I think that's the next frontier in this digital music is really nailing that curation
[01:19:21.880 --> 01:19:26.440]   and bringing back that experience of listening to the radio and having that perfect playlist.
[01:19:26.440 --> 01:19:30.040]   And I think Songz does that way better than Beats.
[01:19:30.040 --> 01:19:33.000]   I do think that Google got a deal.
[01:19:33.000 --> 01:19:37.320]   They got to steal in getting songs of for what, 15, 20 million, whatever it's going to end
[01:19:37.320 --> 01:19:38.320]   up being.
[01:19:38.320 --> 01:19:43.800]   But when I was talking about the 360 business model and when I was talking about how Apple
[01:19:43.800 --> 01:19:47.920]   got a premium brand in Beats, I will say that some of the audience members right in front
[01:19:47.920 --> 01:19:51.720]   of me were nodding their heads as if they understand what that's all about, the getting
[01:19:51.720 --> 01:19:52.720]   that premium hardware.
[01:19:52.720 --> 01:19:57.000]   Now I don't trust the audience anymore because they've let me down twice.
[01:19:57.000 --> 01:20:02.640]   But I think people, even though, yes, Songz of dollar for dollar, Google got something
[01:20:02.640 --> 01:20:08.560]   better, I'm not talking down to the Beats model because I think Apple probably made
[01:20:08.560 --> 01:20:11.040]   all the back off of Beats already.
[01:20:11.040 --> 01:20:12.680]   So go figure.
[01:20:12.680 --> 01:20:13.680]   Harry, last words.
[01:20:13.680 --> 01:20:17.080]   Well, Beats does have at least a dash of human curation as well.
[01:20:17.080 --> 01:20:19.040]   They do have playlists.
[01:20:19.040 --> 01:20:21.480]   But Songz seems to be doing it better than anybody else.
[01:20:21.480 --> 01:20:24.360]   They would never want to see human curation die.
[01:20:24.360 --> 01:20:28.720]   And they would love to see the possibility that it might be the next big thing.
[01:20:28.720 --> 01:20:32.520]   And Google has the opportunity to do that if they want to make it happen.
[01:20:32.520 --> 01:20:33.520]   Indeed.
[01:20:33.520 --> 01:20:37.120]   Oh, when we come back, we're going to be talking about something.
[01:20:37.120 --> 01:20:38.120]   I don't know.
[01:20:38.120 --> 01:20:40.360]   We're going to look through the doc and figure out what I want to talk about next.
[01:20:40.360 --> 01:20:44.320]   But before we do that, I thought now might be a good time to take another break, to talk
[01:20:44.320 --> 01:20:48.080]   about the third sponsor of this episode of This Week in Tech.
[01:20:48.080 --> 01:20:49.080]   And that's audible.
[01:20:49.080 --> 01:20:50.080]   You know them.
[01:20:50.080 --> 01:20:51.080]   You love them.
[01:20:51.080 --> 01:20:52.560]   They're the ones who give me all the audio books I use.
[01:20:52.560 --> 01:20:55.200]   I drive two hours a day.
[01:20:55.200 --> 01:20:58.760]   That's my commute, which may not be a lot to people who have actually had to work in
[01:20:58.760 --> 01:21:00.160]   the real world for the last 20 years.
[01:21:00.160 --> 01:21:04.720]   But for me, what I'm used to living at the place where I work two hours is that it's
[01:21:04.720 --> 01:21:05.720]   kind of unbearable.
[01:21:05.720 --> 01:21:09.800]   And so most of the time I'm alone with my thoughts unless I've got a decent audio book
[01:21:09.800 --> 01:21:15.520]   from Audible because it's obviously become my favorite way to consume books.
[01:21:15.520 --> 01:21:19.040]   This week in tech is brought to you by Audible.com.
[01:21:19.040 --> 01:21:25.240]   Now, we offer special benefits for this week in tech members of our audience.
[01:21:25.240 --> 01:21:29.520]   For those who need to audio books, you can give Audible a try.
[01:21:29.520 --> 01:21:32.520]   And today, Audible is giving you a special deal.
[01:21:32.520 --> 01:21:37.480]   If you go to their site, if you type in our code, if you click on our link, you'll get
[01:21:37.480 --> 01:21:40.080]   two audio books for free.
[01:21:40.080 --> 01:21:41.080]   That's right.
[01:21:41.080 --> 01:21:42.080]   For gratis, for nothing.
[01:21:42.080 --> 01:21:46.480]   Just for trying out the best audio book service on the planet.
[01:21:46.480 --> 01:21:50.880]   This gives you two free audio books, two credits to try out, and two book credits per month,
[01:21:50.880 --> 01:21:55.920]   which is a nice way of saying Audible helps you to keep reading, which is what we encourage
[01:21:55.920 --> 01:21:57.200]   for the Twitter audience.
[01:21:57.200 --> 01:22:01.080]   It's also a great deal for people who enjoy listening to audio programming.
[01:22:01.080 --> 01:22:04.440]   And as with other plans, the plan that you'll get by signing up with Audible through our
[01:22:04.440 --> 01:22:08.880]   link, you'll get a free subscription to the Wall Street Journal or the New York Times
[01:22:08.880 --> 01:22:10.280]   Daily Audio Program.
[01:22:10.280 --> 01:22:14.600]   Now, the book that I've been listening to, and this is actually something that I've recommended
[01:22:14.600 --> 01:22:19.160]   on several of the programs that I've been on when there's even when there's not an Audible
[01:22:19.160 --> 01:22:22.880]   ad, is a book called The Martian by Andy Weir.
[01:22:22.880 --> 01:22:25.720]   Now, Chad, you've been listening to The Martian as well.
[01:22:25.720 --> 01:22:26.720]   I finished it.
[01:22:26.720 --> 01:22:30.200]   I think I'm like my 12th round fruit.
[01:22:30.200 --> 01:22:31.200]   So good.
[01:22:31.200 --> 01:22:32.200]   Okay.
[01:22:32.200 --> 01:22:33.560]   So let me set the stage for you.
[01:22:33.560 --> 01:22:34.560]   Have you read The Martian?
[01:22:34.560 --> 01:22:35.560]   I have not.
[01:22:35.560 --> 01:22:37.280]   Steve, have you heard about The Martian yet?
[01:22:37.280 --> 01:22:38.760]   No, I never even heard of it.
[01:22:38.760 --> 01:22:41.160]   So here's a setting.
[01:22:41.160 --> 01:22:43.080]   Mission to Mars sometime in the very near future.
[01:22:43.080 --> 01:22:45.120]   None of the tech is super futuristic.
[01:22:45.120 --> 01:22:46.680]   There are no warp drives.
[01:22:46.680 --> 01:22:52.120]   They're using good old fashioned physics to get you to the red planet.
[01:22:52.120 --> 01:22:53.120]   There's a snowstorm.
[01:22:53.120 --> 01:22:54.120]   Oh, that's snowstorm.
[01:22:54.120 --> 01:22:55.640]   There's a snowstorm on Mars.
[01:22:55.640 --> 01:22:57.160]   But this is not futuristic.
[01:22:57.160 --> 01:22:58.160]   Everything is so realistic.
[01:22:58.160 --> 01:23:06.680]   There's a sandstorm, a dust storm that happens on Soul Six, Day Six of the third mission,
[01:23:06.680 --> 01:23:08.800]   the Aries mission to Mars.
[01:23:08.800 --> 01:23:09.800]   And they have to evacuate.
[01:23:09.800 --> 01:23:14.480]   And as they evacuate, one of the astronauts is struck by the communication dish that's
[01:23:14.480 --> 01:23:17.520]   torn off and flies into him.
[01:23:17.520 --> 01:23:20.120]   So the other five evacuate thinking that he's dead.
[01:23:20.120 --> 01:23:22.560]   Of course, it turns out he's not dead.
[01:23:22.560 --> 01:23:23.680]   He's on the red planet.
[01:23:23.680 --> 01:23:30.200]   And for the next glorious 10 hours of the audiobook, you get to find out if he survives.
[01:23:30.200 --> 01:23:33.320]   Now, the nice thing about what I really like about this, and this is sort of what I like
[01:23:33.320 --> 01:23:35.640]   about all sci-fi, smart sci-fi.
[01:23:35.640 --> 01:23:37.800]   Speaking about how to fix the problems.
[01:23:37.800 --> 01:23:41.880]   And if you listen to it, he's actually using technical means that we have available to
[01:23:41.880 --> 01:23:42.880]   us.
[01:23:42.880 --> 01:23:44.480]   In fact, I'm going to play a little something something.
[01:23:44.480 --> 01:23:48.800]   This kind of typifies the humor that you're going to hear from the book.
[01:23:48.800 --> 01:23:52.360]   Everyone knew Brendan Hutch would be running missions soon.
[01:23:52.360 --> 01:23:57.760]   He'd risen through NASA's ranks as fast as one could in the large inertia-bound organization.
[01:23:57.760 --> 01:24:02.200]   He was known as a diligent worker, and his skill and leadership qualities were plain to
[01:24:02.200 --> 01:24:04.120]   all his subordinates.
[01:24:04.120 --> 01:24:09.400]   Brendan was in charge of mission control from 1 AM to 9 AM every night.
[01:24:09.400 --> 01:24:13.520]   Continued excellent performance and this role would certainly net him a promotion.
[01:24:13.520 --> 01:24:17.960]   It had already been announced he'd be back up flight controller for Ares 4, and he had
[01:24:17.960 --> 01:24:21.040]   a good shot at the top job for Ares 5.
[01:24:21.040 --> 01:24:24.560]   "Flight, Capcom," a voice said through his headset.
[01:24:24.560 --> 01:24:28.040]   "Go, Capcom," Brendan responded.
[01:24:28.040 --> 01:24:32.920]   Though they were in the same room, radio protocol was observed at all times.
[01:24:32.920 --> 01:24:36.280]   Some scheduled status update from Hermes.
[01:24:36.280 --> 01:24:41.880]   With Hermes 90 light seconds away, back and forth, voice communication was impractical.
[01:24:41.880 --> 01:24:47.120]   Other than media relations, Hermes would communicate via text until they were much closer.
[01:24:47.120 --> 01:24:49.400]   "Roger," Brendan said.
[01:24:49.400 --> 01:24:50.400]   "Read it out."
[01:24:50.400 --> 01:24:51.400]   "I...
[01:24:51.400 --> 01:24:54.960]   I don't get it, Flight," came the confused reply.
[01:24:54.960 --> 01:24:59.040]   "No real status, just a single sentence."
[01:24:59.040 --> 01:25:00.680]   What should say?
[01:25:00.680 --> 01:25:04.040]   "The reads, Houston, be advised.
[01:25:04.040 --> 01:25:07.560]   Rich Purnell is a steely-eyed missile man."
[01:25:07.560 --> 01:25:11.960]   Now, if you want to know who Rich Parnell is, you've got to get the book.
[01:25:11.960 --> 01:25:17.440]   Now, seriously, this is my favorite book since Ready Player One, and I really, really enjoyed
[01:25:17.440 --> 01:25:18.440]   Ready Player One.
[01:25:18.440 --> 01:25:24.000]   So, if you like hard fiction, if you like science, like actual science, not just stuff
[01:25:24.000 --> 01:25:27.560]   that's pulled out of the air, you've got to pick up the Martian by Andy Weir.
[01:25:27.560 --> 01:25:32.960]   You're going to find it on Audible as one of your free downloads, and yeah, that's,
[01:25:32.960 --> 01:25:35.120]   I think that's all we have to say about that.
[01:25:35.120 --> 01:25:39.800]   So, if you want to find out what happened to our fearless astronaut, if you want to find
[01:25:39.800 --> 01:25:44.880]   out what the Rich Parnell Maneuver actually is, go ahead and subscribe to Audible.
[01:25:44.880 --> 01:25:53.680]   For more details, or to get two free audiobooks and their platinum offer, go to Audible.com/Twit2.
[01:25:53.680 --> 01:25:58.320]   That's Audible.com/Twit, and the number two.
[01:25:58.320 --> 01:26:06.160]   Now, gentlemen, we got a little something something here about, oh, I don't know, T-Mobile, the
[01:26:06.160 --> 01:26:07.720]   uncarrier.
[01:26:07.720 --> 01:26:12.240]   Now with more bogus fees, I'm assuming that you heard about this, right?
[01:26:12.240 --> 01:26:13.240]   Oh, yeah.
[01:26:13.240 --> 01:26:14.240]   Yeah.
[01:26:14.240 --> 01:26:19.720]   So, last Tuesday, the FTC filed a claim against cell carrier T-Mobile, claiming that the fourth
[01:26:19.720 --> 01:26:22.200]   largest US carrier was cramming.
[01:26:22.200 --> 01:26:24.400]   Now, you may not have heard of cramming.
[01:26:24.400 --> 01:26:28.400]   If you're an old-timer like me and you grew up in the land, in the time of the landline,
[01:26:28.400 --> 01:26:32.920]   you know cramming because cramming was actually big back when we didn't have cell phones.
[01:26:32.920 --> 01:26:38.080]   It's a practice of loading a customer's bill with hidden chargers for carrier and texting
[01:26:38.080 --> 01:26:42.800]   services, and then trying to cover it up with language that purposely obfuscates what
[01:26:42.800 --> 01:26:43.880]   it was for.
[01:26:43.880 --> 01:26:49.680]   The FTCC says that T-Mobile has reaped hundreds of millions of dollars from premium texting
[01:26:49.680 --> 01:26:52.280]   fees that were not authorized by the customers.
[01:26:52.280 --> 01:26:58.800]   Now, the previous services amounted to about $9.99 per user per month, and the premium
[01:26:58.800 --> 01:27:03.880]   services included things like Jestra Digital, which is accused of deceiving customers with
[01:27:03.880 --> 01:27:10.720]   anti-virus scams, Wise Media, specializing in horoscopes, Tattoo, which was known for
[01:27:10.720 --> 01:27:12.320]   celebrity gossip alerts.
[01:27:12.320 --> 01:27:14.400]   Now, here's the fun part.
[01:27:14.400 --> 01:27:19.800]   T-Mobile was charged in the fee even after they were determined to be fraudulent, pocketing
[01:27:19.800 --> 01:27:25.440]   about 40% of the monthly fee for themselves and forwarding the rest to the service providers.
[01:27:25.440 --> 01:27:32.120]   Now, in November of 2013, all four of the U.S. major carriers were approached by the
[01:27:32.120 --> 01:27:37.520]   FTC and they agreed to stop billing for the premium tech services.
[01:27:37.520 --> 01:27:43.040]   However, according to the FTC, the practice continued at T-Mobile at least through December
[01:27:43.040 --> 01:27:47.200]   2013, most likely through January 2014.
[01:27:47.200 --> 01:27:51.720]   Now, this is one of these things that it just gets my go.
[01:27:51.720 --> 01:27:57.280]   I'm a T-Mobile subscriber, but I have a prepaid bill, so they can't charge me for these services.
[01:27:57.280 --> 01:28:05.000]   But I just can't imagine how easy it would be to hide $9 if you've got a bill of $120,
[01:28:05.000 --> 01:28:06.000]   $110.
[01:28:06.000 --> 01:28:07.480]   That's kind of what they were counting on, right, Steve?
[01:28:07.480 --> 01:28:11.240]   I mean, that most customers don't want to go through the 50 pages of bills.
[01:28:11.240 --> 01:28:16.840]   Yeah, and you've got to keep in mind, this is a very deep and complex issue and it goes
[01:28:16.840 --> 01:28:20.000]   beyond just these premium texting services.
[01:28:20.000 --> 01:28:23.000]   But you also got to keep in mind, it's not just T-Mobile.
[01:28:23.000 --> 01:28:28.000]   Yes, the FTC is going after T-Mobile, but Verizon's Brent and AT&T were doing it too and they
[01:28:28.000 --> 01:28:32.320]   all kind of decided at the same time, okay, we're going to stop our relationship with
[01:28:32.320 --> 01:28:34.400]   these premium texting services.
[01:28:34.400 --> 01:28:39.560]   So then the question becomes, okay, so why is the FTC picking on T-Mobile?
[01:28:39.560 --> 01:28:43.560]   Well, I've spoken to the FTC a lot this week about this story.
[01:28:43.560 --> 01:28:48.560]   One reason is, yes, T-Mobile said they stopped doing it and they're going to do their best
[01:28:48.560 --> 01:28:56.120]   to refund people, but they want a court order that they want it on paper legally that such
[01:28:56.120 --> 01:29:00.760]   cramming charges, not just for the premium texting services like those ones you described,
[01:29:00.760 --> 01:29:04.480]   but any kind of cramming cannot happen again.
[01:29:04.480 --> 01:29:08.520]   And they also want to make sure that everyone who was affected by these practices gets
[01:29:08.520 --> 01:29:14.080]   refunded, which might not necessarily happen because right now T-Mobile, it's kind of come
[01:29:14.080 --> 01:29:17.560]   to us if you think you're fraudulently charged.
[01:29:17.560 --> 01:29:22.160]   They want T-Mobile being more proactive and paying literally everyone.
[01:29:22.160 --> 01:29:27.040]   So there's a lot to unpack here, but basically the FTC, this is the first time we're going
[01:29:27.040 --> 01:29:34.280]   to hear from this from the FTC and they're really going against this cramming thing.
[01:29:34.280 --> 01:29:40.360]   These services are intensely sketchy and the way they skim your phone number and they cut
[01:29:40.360 --> 01:29:42.560]   these deals with the carriers.
[01:29:42.560 --> 01:29:46.000]   What I'd like to see is the carriers to come out and say, "We're going to stop all third-party
[01:29:46.000 --> 01:29:49.880]   billing from third-party services," which isn't happening yet.
[01:29:49.880 --> 01:29:53.640]   Right, until they do that, Harry, it's like whack-a-mole, right?
[01:29:53.640 --> 01:29:57.160]   I mean, T-Mobile got caught this time, but they're not the only carrier doing this.
[01:29:57.160 --> 01:30:00.240]   We've seen this from Sprint from AT&T, from Verizon.
[01:30:00.240 --> 01:30:05.480]   The idea of hiding charges in the bill, which is why every month your bill is slightly a
[01:30:05.480 --> 01:30:09.360]   different cost because they've hidden the charges a different way.
[01:30:09.360 --> 01:30:11.440]   It's like it's a time-honored tradition.
[01:30:11.440 --> 01:30:14.480]   The only reason they can do this is because phone bills are incomprehensible.
[01:30:14.480 --> 01:30:16.240]   Yeah, Chad, we've got a picture.
[01:30:16.240 --> 01:30:20.080]   Go ahead and go to that excerpt from an actual T-Mobile bill.
[01:30:20.080 --> 01:30:23.440]   Tell me, because there's a lot of people who are going to say, "Oh, this is stupid.
[01:30:23.440 --> 01:30:27.440]   I mean, if you can't pay attention to your bill, if you can't look and make sure that
[01:30:27.440 --> 01:30:29.720]   you're paying the right amount, then it's your fault."
[01:30:29.720 --> 01:30:33.320]   Look, this is what an actual T-Mobile bill looks like.
[01:30:33.320 --> 01:30:37.320]   Now, that $9.99 is hidden as a usage charge.
[01:30:37.320 --> 01:30:42.320]   Now, you may have paid $85 the previous month and $93 this month, but you're just thinking,
[01:30:42.320 --> 01:30:44.320]   "Ah, I don't know, it looks right."
[01:30:44.320 --> 01:30:50.880]   And if you scroll down a little bit, Chad, it's 123 pages until you finally find out
[01:30:50.880 --> 01:30:53.920]   where that $9.99 charge came from.
[01:30:53.920 --> 01:30:55.960]   So I mean, Evan, then you don't really know.
[01:30:55.960 --> 01:30:56.960]   Yeah, exactly.
[01:30:56.960 --> 01:30:59.360]   I mean, look, you're looking at Shaboom Media.
[01:30:59.360 --> 01:31:01.280]   Did I buy something from Shaboom Media?
[01:31:01.280 --> 01:31:02.760]   Is it an app?
[01:31:02.760 --> 01:31:05.920]   I mean, is that what this is?
[01:31:05.920 --> 01:31:10.600]   So even though, yes, there is an element of buyer beware here.
[01:31:10.600 --> 01:31:13.360]   There is an element of you need to do your due diligence.
[01:31:13.360 --> 01:31:16.480]   This is not a new phenomenon.
[01:31:16.480 --> 01:31:19.720]   This is something that's been happening with not just the cell phone carriers, but all
[01:31:19.720 --> 01:31:23.880]   carriers since we had the first spam phone call.
[01:31:23.880 --> 01:31:28.400]   I mean, presumably they could do things that would help have some sort of system where
[01:31:28.400 --> 01:31:33.720]   before you get billed for this stuff, there's some sort of double opt-in.
[01:31:33.720 --> 01:31:37.880]   So nobody can ever claim that they weren't aware they were agreeing to get their horoscopes
[01:31:37.880 --> 01:31:39.120]   on their phone or whatever.
[01:31:39.120 --> 01:31:44.920]   I think in some cases, in some cases people may have agreed to do it, knowing they were
[01:31:44.920 --> 01:31:45.920]   agreeing.
[01:31:45.920 --> 01:31:48.280]   In some cases, they may have been confused about it.
[01:31:48.280 --> 01:31:51.720]   In some cases, they may have been crammed on without the customer knowing about it at
[01:31:51.720 --> 01:31:52.720]   all.
[01:31:52.720 --> 01:31:54.480]   And one of these is a Facebook scam.
[01:31:54.480 --> 01:31:59.000]   So you download a Facebook app to your phone and they offer you something for free.
[01:31:59.000 --> 01:32:03.160]   So supposedly it's a way to get Facebook updates to your phone more quickly.
[01:32:03.160 --> 01:32:06.720]   And of course, there's a EULA and you go right to the EULA and you click OK.
[01:32:06.720 --> 01:32:11.320]   And in that EULA is, oh, by the way, you're agreeing to let us charge you $9.99 a month.
[01:32:11.320 --> 01:32:14.640]   And then that charge gets forever hidden and it's almost impossible to cancel.
[01:32:14.640 --> 01:32:18.920]   If the track them down, call a number, there's no online forum.
[01:32:18.920 --> 01:32:23.120]   In fact, actually Xbox Live used to do this before you can cancel it.
[01:32:23.120 --> 01:32:25.720]   And that's the most maddening part.
[01:32:25.720 --> 01:32:31.880]   Steve, you say that we need to stop the third party charges, but they'd never do that, right?
[01:32:31.880 --> 01:32:33.960]   Because they make way too much money from that.
[01:32:33.960 --> 01:32:35.960]   No, that would be killing the revenue.
[01:32:35.960 --> 01:32:39.560]   And that's why the FGC is getting involved and the FCC.
[01:32:39.560 --> 01:32:47.040]   The FCC is seeking potentially punitive damages towards T-Mobile in a separate case.
[01:32:47.040 --> 01:32:52.520]   So it's kind of sad that it takes some kind of government intervention or government
[01:32:52.520 --> 01:32:54.880]   agency intervention to stop this practice.
[01:32:54.880 --> 01:32:57.080]   And it's a long battle.
[01:32:57.080 --> 01:32:58.080]   It was funny.
[01:32:58.080 --> 01:33:02.560]   I talked to a sprint spokesperson this week about it and she framed it as, oh, well, we
[01:33:02.560 --> 01:33:06.280]   use this third party billing to make it easier on the customers.
[01:33:06.280 --> 01:33:09.280]   So they don't have to go through a separate billing process.
[01:33:09.280 --> 01:33:10.280]   And it's no.
[01:33:10.280 --> 01:33:17.040]   It's clear they're skimming revenue from users whenever they can and ending this practice.
[01:33:17.040 --> 01:33:21.440]   Any kind of third party billing will just put a huge ding into their revenue.
[01:33:21.440 --> 01:33:25.120]   And it's also on these third party services.
[01:33:25.120 --> 01:33:28.520]   If you're watching Comedy Central late at night or something, you see those weird commercials
[01:33:28.520 --> 01:33:33.000]   like, oh, just Texas number to get flirt tips or something.
[01:33:33.000 --> 01:33:38.880]   It's very easy for someone without knowledge of the situation to just fall under that trap
[01:33:38.880 --> 01:33:44.080]   and text that number and not know exactly what they're signing up for and reading the
[01:33:44.080 --> 01:33:45.240]   fine print.
[01:33:45.240 --> 01:33:48.920]   And that's kind of why the carriers ended the relationship with at least these texting
[01:33:48.920 --> 01:33:54.040]   services because a lot of them didn't make it clear what people were signing up for simply
[01:33:54.040 --> 01:33:56.120]   by texting a certain number.
[01:33:56.120 --> 01:34:00.640]   And but it's also on the carriers to be upfront about how they're billing people.
[01:34:00.640 --> 01:34:02.360]   And they're not quite doing that yet.
[01:34:02.360 --> 01:34:06.480]   It's especially hard on T-Mobile's reputation because their whole marketing messages were
[01:34:06.480 --> 01:34:10.080]   the un-carrier AT&T and Verizon are the bad guys.
[01:34:10.080 --> 01:34:14.360]   But we T-Mobile are on the side of you, the consumer.
[01:34:14.360 --> 01:34:18.360]   And then not sure how they overcome the ding to their reputation.
[01:34:18.360 --> 01:34:21.920]   No matter how much it's deserved or is not deserved.
[01:34:21.920 --> 01:34:23.880]   We are the un-crammer.
[01:34:23.880 --> 01:34:28.120]   And that's my theory now is, like I said, all the carriers are doing it.
[01:34:28.120 --> 01:34:32.640]   But my hunch, and I've asked the F2DC about this, they wouldn't say, but my hunch is they're
[01:34:32.640 --> 01:34:37.640]   going after T-Mobile because T-Mobile is that very loud, very noisy marketing message now
[01:34:37.640 --> 01:34:42.720]   that we're here, we're on your side and you're going to eliminate all the pain points that
[01:34:42.720 --> 01:34:45.080]   carriers have been giving you all this time.
[01:34:45.080 --> 01:34:48.160]   And yet they got caught doing the exact same thing as the other carriers.
[01:34:48.160 --> 01:34:52.000]   So I think they're kind of like the strong man right now for the F2DC, even though they're
[01:34:52.000 --> 01:34:53.240]   not alone doing it.
[01:34:53.240 --> 01:34:56.600]   And I'm not saying they shouldn't go after T-Mobile, they totally should.
[01:34:56.600 --> 01:35:00.880]   But T-Mobile is the perfect choice if you're going to sue one of the carriers.
[01:35:00.880 --> 01:35:04.560]   T-Mobile is the perfect choice right now because of that really strong marketing message.
[01:35:04.560 --> 01:35:05.560]   It makes a big point.
[01:35:05.560 --> 01:35:06.560]   Right, right.
[01:35:06.560 --> 01:35:07.560]   It's more damaging.
[01:35:07.560 --> 01:35:10.000]   And so therefore they want to deal with it more quickly.
[01:35:10.000 --> 01:35:11.440]   That makes sense.
[01:35:11.440 --> 01:35:15.240]   Now, I am going to go out on a limb here and reach out to the audience one more time.
[01:35:15.240 --> 01:35:19.760]   I know I shouldn't do this, but it's the definition of insanity.
[01:35:19.760 --> 01:35:24.680]   How many of you have actually gone through your phone bill to find hidden charges and
[01:35:24.680 --> 01:35:25.600]   then disputed them?
[01:35:25.600 --> 01:35:28.640]   So is the one guy.
[01:35:28.640 --> 01:35:34.400]   I actually, except for the one guy that kind of shows the point, which is this is what
[01:35:34.400 --> 01:35:35.400]   they're counting on, right?
[01:35:35.400 --> 01:35:40.560]   I mean, they're counting on us not caring enough to go and track down the air and charge.
[01:35:40.560 --> 01:35:47.200]   So even if most of us, even if my regular bill is $89 a month, this month it was $100,
[01:35:47.200 --> 01:35:50.240]   I'm going to be thinking, I'm not going to waste time.
[01:35:50.240 --> 01:35:58.640]   I'm not going to waste five hours out of my life to track down $9.
[01:35:58.640 --> 01:36:02.080]   I'm just going to let it sit there.
[01:36:02.080 --> 01:36:05.120]   It's dead air.
[01:36:05.120 --> 01:36:06.960]   This is what we're doing now.
[01:36:06.960 --> 01:36:12.200]   It's remarkable how many things in the world are easy to sign up for and almost impossible
[01:36:12.200 --> 01:36:15.320]   to opt out of.
[01:36:15.320 --> 01:36:21.880]   I've spent more hours than I can think of on the phone with Comcast and my phone carriers
[01:36:21.880 --> 01:36:23.360]   and all kinds of other people.
[01:36:23.360 --> 01:36:25.840]   Generally speaking, cannot do this stuff online.
[01:36:25.840 --> 01:36:30.320]   But with like one click, you can sign up for these services.
[01:36:30.320 --> 01:36:33.800]   Sadly enough, I don't, I think we just don't care enough.
[01:36:33.800 --> 01:36:38.560]   I remember when I used to really care about being flocked and fleeced and now it's like,
[01:36:38.560 --> 01:36:40.400]   okay, yeah, I get it.
[01:36:40.400 --> 01:36:41.480]   I'm going to take it some way.
[01:36:41.480 --> 01:36:42.880]   So this is a small one.
[01:36:42.880 --> 01:36:44.520]   All right, let's, let's, let's move on.
[01:36:44.520 --> 01:36:47.000]   Let's get away from that because that's when they get kind of nasty.
[01:36:47.000 --> 01:36:48.280]   Steve, let me ask you this question.
[01:36:48.280 --> 01:36:53.520]   Have you ever sent an email and then really quickly realized, oh my God, just as I sent
[01:36:53.520 --> 01:36:56.240]   that send hit that send button, I should not have sent that email.
[01:36:56.240 --> 01:36:58.280]   That was a horrible, horrible mistake.
[01:36:58.280 --> 01:36:59.880]   I do that several times a day properly.
[01:36:59.880 --> 01:37:00.880]   I think so.
[01:37:00.880 --> 01:37:01.880]   I think everyone.
[01:37:01.880 --> 01:37:03.760]   Maybe it's a horrible mistake, but it's like, oh man, I had a time.
[01:37:03.760 --> 01:37:05.760]   It was a typo or something that I wish I had fixed.
[01:37:05.760 --> 01:37:06.760]   A typo.
[01:37:06.760 --> 01:37:07.760]   Okay.
[01:37:07.760 --> 01:37:08.760]   A typo.
[01:37:08.760 --> 01:37:09.760]   Harry, have you had that?
[01:37:09.760 --> 01:37:10.760]   Like sent out an email you really didn't want to.
[01:37:10.760 --> 01:37:11.760]   Maybe once or twice.
[01:37:11.760 --> 01:37:12.760]   Yeah.
[01:37:12.760 --> 01:37:13.760]   A typo or?
[01:37:13.760 --> 01:37:20.640]   The thing I do occasionally is when I'm sending an email about somebody, I accidentally address
[01:37:20.640 --> 01:37:23.960]   it to them and I've never done it in a way that was super embarrassing.
[01:37:23.960 --> 01:37:24.960]   Okay.
[01:37:24.960 --> 01:37:27.120]   So, you know, typo may be misaddressing some.
[01:37:27.120 --> 01:37:30.080]   Gmail does it that feature where you can like for a split second after you send a
[01:37:30.080 --> 01:37:31.080]   Gmail.
[01:37:31.080 --> 01:37:32.080]   Take it back.
[01:37:32.080 --> 01:37:33.080]   You can take it back.
[01:37:33.080 --> 01:37:35.080]   So, I mean, those are pretty serious.
[01:37:35.080 --> 01:37:38.800]   You know, typo or, you know, the wrong addressing.
[01:37:38.800 --> 01:37:44.120]   What if you accidentally sent a secure customer list that contains all the secrets about your
[01:37:44.120 --> 01:37:47.280]   company's security to a totally random Gmail user?
[01:37:47.280 --> 01:37:48.280]   Yeah.
[01:37:48.280 --> 01:37:50.240]   That's what happened to someone from Goldman Sachs.
[01:37:50.240 --> 01:37:56.040]   On June 23rd, a Goldman Sachs contractor accidentally sent a Gmail message containing,
[01:37:56.040 --> 01:38:01.320]   quote unquote, "highly confidential brokerage account information to the wrong Gmail account."
[01:38:01.320 --> 01:38:05.760]   The contractor had been testing changes that the bank had made to become compliant with
[01:38:05.760 --> 01:38:10.360]   the requirements set forth by the financial industry regulatory authority.
[01:38:10.360 --> 01:38:17.160]   The email contained the contractor's report, which he meant to send to a gs.com account,
[01:38:17.160 --> 01:38:22.560]   but which he says his browser accidentally auto completed to Gmail.com.
[01:38:22.560 --> 01:38:28.040]   On June 26th, realizing the mistake Goldman Sachs asked Google to delete the email message
[01:38:28.040 --> 01:38:29.040]   from their servers.
[01:38:29.040 --> 01:38:33.200]   Google's incident response team responded that the email could not be deleted without
[01:38:33.200 --> 01:38:39.280]   a court order, but in compromise, Google blocked access to the email while Goldman Sachs sought
[01:38:39.280 --> 01:38:41.640]   a court order to delete the email message.
[01:38:41.640 --> 01:38:43.200]   So let me start with that.
[01:38:43.200 --> 01:38:46.880]   Automatically, so Google, Goldman Sachs got a mulligan.
[01:38:46.880 --> 01:38:48.160]   They got to do over.
[01:38:48.160 --> 01:38:52.600]   They got to do something that none of us can do, which is they froze the email after it
[01:38:52.600 --> 01:38:54.800]   had been sent out.
[01:38:54.800 --> 01:38:58.040]   First impressions from the panel, do we have any problems with that?
[01:38:58.040 --> 01:38:59.040]   Yes.
[01:38:59.040 --> 01:39:04.440]   I think that's a very slippery slope to give a mega corporation with a lot of power, that
[01:39:04.440 --> 01:39:05.920]   kind of preferential treatment.
[01:39:05.920 --> 01:39:12.080]   If I, you know, contact Google and say, "Oh, I wish I never sent my ex-girlfriend that
[01:39:12.080 --> 01:39:16.240]   email asking for her forgiveness or something," like they would laugh at me.
[01:39:16.240 --> 01:39:21.680]   But the fact that, you know, this company is coming through and touting FGC regulations
[01:39:21.680 --> 01:39:25.680]   and a bunch of scary jargon, they get that preferential treatment.
[01:39:25.680 --> 01:39:30.280]   I think, you know, right now it's probably an innocuous email that probably said nothing,
[01:39:30.280 --> 01:39:34.160]   but the fact that they were given that preferential treatment makes you wonder what could happen
[01:39:34.160 --> 01:39:35.160]   in the future.
[01:39:35.160 --> 01:39:37.160]   Yeah, I think that's what strikes me about that.
[01:39:37.160 --> 01:39:38.920]   And Harry, I want to throw this over to you.
[01:39:38.920 --> 01:39:43.640]   The way that they got Google to freeze the email was that they said, quote, unquote,
[01:39:43.640 --> 01:39:48.560]   again, "Emergency relief is necessary to avoid the risk of inflicting a needless and
[01:39:48.560 --> 01:39:54.600]   massive privacy violation upon Goldman Sachs' clients and to avoid the risk of unnecessary
[01:39:54.600 --> 01:39:57.160]   reputation damage to Goldman Sachs."
[01:39:57.160 --> 01:40:00.960]   But then I think, wait a minute, if this was a contractor who was sending a report about
[01:40:00.960 --> 01:40:07.160]   whether or not they complied with regulatory rules, there shouldn't be any customer information.
[01:40:07.160 --> 01:40:09.000]   There's no major database here.
[01:40:09.000 --> 01:40:13.520]   The only thing that could possibly be would be embarrassing in that he said, "No, you're
[01:40:13.520 --> 01:40:15.440]   not compliant right now."
[01:40:15.440 --> 01:40:20.640]   And what does Goldman Sachs do in using an email system that can even talk to Gmail to
[01:40:20.640 --> 01:40:22.280]   send this kind of stuff?
[01:40:22.280 --> 01:40:23.280]   Exactly.
[01:40:23.280 --> 01:40:28.600]   Well, they should block Gmail for anything like this or not send it to the email at all.
[01:40:28.600 --> 01:40:31.280]   I'm not deeply bothered by this, probably.
[01:40:31.280 --> 01:40:34.120]   Maybe to the extent that Steve is.
[01:40:34.120 --> 01:40:35.120]   But it's totally true.
[01:40:35.120 --> 01:40:39.720]   If you were at a similar request, we probably could not get Google on the phone.
[01:40:39.720 --> 01:40:47.480]   Well, I think what bothers me is that it's obvious that Goldman Sachs is talking up the
[01:40:47.480 --> 01:40:51.440]   concerns so that they could get this embarrassing email frozen.
[01:40:51.440 --> 01:40:52.540]   There's no customer information.
[01:40:52.540 --> 01:40:57.520]   There is no massive privacy violation upon Goldman Sachs clients because there's not
[01:40:57.520 --> 01:41:02.000]   going to be any information about Goldman Sachs clients unless this external contractor,
[01:41:02.000 --> 01:41:06.580]   for some reason, was sending back and forth a list of Goldman Sachs clients, which, okay,
[01:41:06.580 --> 01:41:09.760]   then they've got another problem, which is they've got really bad contractors.
[01:41:09.760 --> 01:41:16.120]   So it's as if corporations now have this special button that they can push.
[01:41:16.120 --> 01:41:18.040]   Well, they say, "Oh, privacy violation."
[01:41:18.040 --> 01:41:20.280]   And Google will do their beck and call.
[01:41:20.280 --> 01:41:22.520]   That really rusted me the wrong way.
[01:41:22.520 --> 01:41:27.780]   Steve, are you like me or do you have a different reason for thinking that this is a slippery
[01:41:27.780 --> 01:41:28.780]   slope?
[01:41:28.780 --> 01:41:30.940]   No, I'm totally with you.
[01:41:30.940 --> 01:41:36.900]   And again, these are also the companies that were largely responsible for our financial
[01:41:36.900 --> 01:41:42.980]   meltdown and to give them that kind of preferential treatment just rubs their wrong way.
[01:41:42.980 --> 01:41:48.420]   And also, it's a little worrisome that Google has that power to tap into one's inbox and
[01:41:48.420 --> 01:41:53.740]   prevent you from reading an email, the fact that they can do that because a company requested
[01:41:53.740 --> 01:41:54.740]   it.
[01:41:54.740 --> 01:41:57.620]   I think that's pretty bothersome too.
[01:41:57.620 --> 01:42:02.740]   You can think of numerous examples of how that could be abused.
[01:42:02.740 --> 01:42:07.660]   So it gives Google a lot of, again, acting like the arbiter and deciding case by case
[01:42:07.660 --> 01:42:13.220]   what, when they should exercise this power to stop you from reading email that goes into
[01:42:13.220 --> 01:42:15.060]   your inbox, that's crazy to me.
[01:42:15.060 --> 01:42:16.060]   Yeah.
[01:42:16.060 --> 01:42:19.340]   People in the chat room are saying, I don't understand why this is a big problem.
[01:42:19.340 --> 01:42:24.700]   But Brian W in the chat room, he actually, I think he brings forth the big issue for me,
[01:42:24.700 --> 01:42:28.900]   which is, well, the reason why they can do this is it's not your inbox.
[01:42:28.900 --> 01:42:29.900]   It's Google's, right?
[01:42:29.900 --> 01:42:33.100]   I mean, because if it's Google's inbox, they can do anything they want.
[01:42:33.100 --> 01:42:34.380]   They could freeze the email.
[01:42:34.380 --> 01:42:36.140]   They can delete it after a court order.
[01:42:36.140 --> 01:42:40.540]   But if you believe that it's your inbox, you should be upset that Google can reach in
[01:42:40.540 --> 01:42:43.380]   and freeze a particular email.
[01:42:43.380 --> 01:42:49.140]   It's not your inbox to the same degree that, you know, an IMAP inbox, we can download stuff
[01:42:49.140 --> 01:42:52.740]   that your own hard drive is your own inbox.
[01:42:52.740 --> 01:42:56.060]   And I kind of hope whoever received this actually did download it before Google was
[01:42:56.060 --> 01:42:59.460]   able to tamper with the inbox.
[01:42:59.460 --> 01:43:03.980]   You should never think of Gmail as being the same as your own inbox because it's just not.
[01:43:03.980 --> 01:43:04.980]   I don't know.
[01:43:04.980 --> 01:43:05.980]   I'm incensed.
[01:43:05.980 --> 01:43:06.980]   I'm pissed.
[01:43:06.980 --> 01:43:07.980]   I think this is a major big.
[01:43:07.980 --> 01:43:10.620]   In fact, okay, Chad, bring up the audience again.
[01:43:10.620 --> 01:43:12.860]   Let's give them one last chance.
[01:43:12.860 --> 01:43:17.460]   How many of you think that this is a gross invasion of your privacy that Google has this
[01:43:17.460 --> 01:43:18.460]   ability?
[01:43:18.460 --> 01:43:19.460]   Okay.
[01:43:19.460 --> 01:43:20.460]   Yes.
[01:43:20.460 --> 01:43:21.460]   Okay.
[01:43:21.460 --> 01:43:22.460]   See, we got mostly a right answer.
[01:43:22.460 --> 01:43:23.460]   Thank you very much.
[01:43:23.460 --> 01:43:24.940]   Finally, the audience pulls through.
[01:43:24.940 --> 01:43:31.860]   I, okay, I understand what you're saying, Harry, but, you know, I don't feel like that.
[01:43:31.860 --> 01:43:35.580]   I do feel my mail is my mail.
[01:43:35.580 --> 01:43:38.980]   You don't have a right to go through my mail without a court order.
[01:43:38.980 --> 01:43:43.340]   Even if Golden Spax says something really bad is going to happen if someone reads that
[01:43:43.340 --> 01:43:48.060]   email message, it doesn't mean that they have a legal right to freeze that email message.
[01:43:48.060 --> 01:43:51.140]   The good news is, Goldman Sachs looks like a total bunch of doofus says they do because
[01:43:51.140 --> 01:43:52.140]   this became public.
[01:43:52.140 --> 01:43:53.140]   Yeah.
[01:43:53.140 --> 01:43:56.380]   I hope it's at least as embarrassing for them as if the information had gotten out because
[01:43:56.380 --> 01:43:58.300]   they deserve it in this case.
[01:43:58.300 --> 01:43:59.300]   Yeah.
[01:43:59.300 --> 01:44:00.300]   Steve, last words.
[01:44:00.300 --> 01:44:01.300]   Sure.
[01:44:01.300 --> 01:44:02.300]   It's probably nothing.
[01:44:02.300 --> 01:44:03.980]   Yeah, the information is probably nothing first of all.
[01:44:03.980 --> 01:44:06.060]   And Harry is like technically correct.
[01:44:06.060 --> 01:44:07.060]   Yes.
[01:44:07.060 --> 01:44:10.820]   The email does the inbox and if you want to be super safe, you should download it all.
[01:44:10.820 --> 01:44:16.740]   But, you know, we do put a lot of trust in this company and the fact that they get to,
[01:44:16.740 --> 01:44:22.220]   you know, play judge and jury and decide when you get to read emails sent to you or not,
[01:44:22.220 --> 01:44:24.580]   that's a little bothersome.
[01:44:24.580 --> 01:44:29.260]   And you know, again, if you want to go into the NSA stuff and all that kind of backdoor
[01:44:29.260 --> 01:44:30.820]   dealing, that's also worrisome.
[01:44:30.820 --> 01:44:34.740]   Google, just remember if you really want to freeze that email, the only thing to do is
[01:44:34.740 --> 01:44:36.220]   to nuke me from orbit.
[01:44:36.220 --> 01:44:38.020]   It's the only safe way.
[01:44:38.020 --> 01:44:41.460]   Now when we come back, we're going to wrap up with a little bit of Microsoft rumors because
[01:44:41.460 --> 01:44:43.140]   that's how I like to do it.
[01:44:43.140 --> 01:44:47.300]   But before that, let's take a little break to talk about the last sponsor of this episode
[01:44:47.300 --> 01:44:49.060]   of this week in tech.
[01:44:49.060 --> 01:44:50.380]   And that's Squarespace.
[01:44:50.380 --> 01:44:56.220]   Now, do you want a single place that you can go to get everything that you need to get
[01:44:56.220 --> 01:44:57.900]   your creative ideas onto the internet?
[01:44:57.900 --> 01:45:01.340]   Now, I know there are a lot of people out there who like a bit more control.
[01:45:01.340 --> 01:45:04.660]   So, so maybe you're going to buy your own domain name registrar.
[01:45:04.660 --> 01:45:06.540]   You're going to buy your own hosting company.
[01:45:06.540 --> 01:45:08.900]   Maybe you want to set up the back end and that's fine.
[01:45:08.900 --> 01:45:09.900]   That's great.
[01:45:09.900 --> 01:45:13.420]   We love geeks who want to do that.
[01:45:13.420 --> 01:45:17.660]   But there are a lot of people who don't want that hassle who go through that because they
[01:45:17.660 --> 01:45:19.460]   have to not because they want to.
[01:45:19.460 --> 01:45:26.780]   There are more people who just want one easy stop, one service, one place that will take
[01:45:26.780 --> 01:45:31.460]   care of everything and get that idea, that project, that picture, that photo, that video
[01:45:31.460 --> 01:45:32.380]   onto the internet.
[01:45:32.380 --> 01:45:34.860]   And that folks is Squarespace.
[01:45:34.860 --> 01:45:39.780]   Now, I have used Squarespace constantly over the last three years.
[01:45:39.780 --> 01:45:43.980]   Ever since I started hearing about them because well, their sites never go down.
[01:45:43.980 --> 01:45:48.580]   And so, whenever I've done a job for for a parish or a university or a high school and
[01:45:48.580 --> 01:45:51.580]   they don't have a lot of technical people, they don't have a lot of people who want to
[01:45:51.580 --> 01:45:54.940]   do the programming, I always say, well, why go through that trouble?
[01:45:54.940 --> 01:45:57.300]   Why not get yourself a Squarespace site?
[01:45:57.300 --> 01:46:00.820]   Now, the reason why I love Squarespace is well, multi fold.
[01:46:00.820 --> 01:46:03.180]   First of all, they're always improving their platform.
[01:46:03.180 --> 01:46:06.580]   They're not content to sit on what they had a couple of years ago.
[01:46:06.580 --> 01:46:11.340]   They're always giving you new designs, new features, and even better support.
[01:46:11.340 --> 01:46:15.940]   They've got beautiful designs, 25 custom templates for you to start with.
[01:46:15.940 --> 01:46:19.980]   And they recently added a logo creator tool, which is a basic tool for individuals and
[01:46:19.980 --> 01:46:26.140]   small businesses with limited resources who want to create a unique identity for themselves.
[01:46:26.140 --> 01:46:28.260]   It's also incredibly easy to use.
[01:46:28.260 --> 01:46:31.620]   Squarespace is always there for you when you need help.
[01:46:31.620 --> 01:46:34.900]   They have live chat and email support 24 hours a day, seven days a week.
[01:46:34.900 --> 01:46:40.380]   Plus, there's a completely redesigned customer help site for easier access to self-help articles
[01:46:40.380 --> 01:46:42.300]   and video workshops.
[01:46:42.300 --> 01:46:47.340]   Squarespace also offers e-commerce solutions, now available for all subscription plan levels,
[01:46:47.340 --> 01:46:51.460]   including the ability to accept donations, which is great for nonprofits, cash, wedding
[01:46:51.460 --> 01:46:53.620]   registries, and school fun drives.
[01:46:53.620 --> 01:46:55.700]   That's exactly what I've been using it for.
[01:46:55.700 --> 01:46:57.300]   It's also inexpensive.
[01:46:57.300 --> 01:47:03.580]   It starts at just $8 a month and includes a free domain name if you sign up for a year.
[01:47:03.580 --> 01:47:04.940]   Squarespace is also mobile ready.
[01:47:04.940 --> 01:47:09.260]   You may have seen some janky websites that look okay on a desktop but look horrible on
[01:47:09.260 --> 01:47:10.340]   a mobile device.
[01:47:10.340 --> 01:47:14.620]   That's because they're not dynamically coded to change according to the device it's being
[01:47:14.620 --> 01:47:16.020]   viewed on.
[01:47:16.020 --> 01:47:18.540]   Squarespace does all that for you.
[01:47:18.540 --> 01:47:23.540]   The Squarespace metric app for iPhone and iPad allow you to check site stats like page views,
[01:47:23.540 --> 01:47:27.620]   unique visitors, and social media followers, and the site will automatically adjust to
[01:47:27.620 --> 01:47:31.180]   look as good as it can on those mobile devices.
[01:47:31.180 --> 01:47:33.260]   Even the code is beautiful.
[01:47:33.260 --> 01:47:37.900]   We all know that the Squarespace sites look beautiful on the outside, but what's amazing
[01:47:37.900 --> 01:47:41.700]   is that the code underneath is just elegant.
[01:47:41.700 --> 01:47:46.420]   Squarespace takes as much pride in their code as they do in the front end.
[01:47:46.420 --> 01:47:50.860]   That's of course, because it's a one-stop shop, Squarespace also includes hosting.
[01:47:50.860 --> 01:47:51.860]   So you don't have to.
[01:47:51.860 --> 01:47:53.220]   You don't have to worry about a separate bill.
[01:47:53.220 --> 01:47:54.500]   It's all in one place.
[01:47:54.500 --> 01:47:56.620]   So here's what we want you to do.
[01:47:56.620 --> 01:48:01.700]   We want you to start a two-week free trial with no credit card required and start building
[01:48:01.700 --> 01:48:03.540]   your website today.
[01:48:03.540 --> 01:48:07.020]   When you decide to sign up for Squarespace, make sure to use the offer code TWIT to get
[01:48:07.020 --> 01:48:11.220]   10% off and to show your support for this week in tech.
[01:48:11.220 --> 01:48:16.660]   We thank Squarespace for their support of this week in tech of better web awaits.
[01:48:16.660 --> 01:48:20.180]   It starts now with your new Squarespace website.
[01:48:20.180 --> 01:48:21.380]   Let's get to the rumors.
[01:48:21.380 --> 01:48:26.500]   This is the part that I like unsubstantiated tech.
[01:48:26.500 --> 01:48:29.780]   Now Tom's hardware claims that they got a little sneak peek.
[01:48:29.780 --> 01:48:30.780]   They got some skivvy.
[01:48:30.780 --> 01:48:35.820]   They got from someone in the know about Microsoft's smart watch research.
[01:48:35.820 --> 01:48:39.860]   And they think they know what the face of Microsoft entry is going to look like.
[01:48:39.860 --> 01:48:40.860]   And guess what?
[01:48:40.860 --> 01:48:41.860]   It's not a watch.
[01:48:41.860 --> 01:48:45.180]   First and foremost, Microsoft is not pitching a smart watch.
[01:48:45.180 --> 01:48:48.060]   They're pitching what they're calling a smart band.
[01:48:48.060 --> 01:48:51.100]   Think of it like a Nike fuel band, but just a little bit wider.
[01:48:51.100 --> 01:48:56.660]   Now it will reportedly have 11 sensors, cross-platform support, so it's going to work on a Windows
[01:48:56.660 --> 01:48:58.220]   phone, Android or iOS.
[01:48:58.220 --> 01:49:03.000]   It's got a slim band design that is more akin again to that Nike fuel band than to a
[01:49:03.000 --> 01:49:04.660]   Pebble or a Google watch.
[01:49:04.660 --> 01:49:06.740]   It doesn't actually look like a banded watch.
[01:49:06.740 --> 01:49:10.620]   It has open APIs, so you're going to be able to program for it quite easily.
[01:49:10.620 --> 01:49:15.620]   A screen, this is what I really like, that is inside the wrist, not on the top of the
[01:49:15.620 --> 01:49:16.620]   wrist.
[01:49:16.620 --> 01:49:21.900]   It's here rather than here, and it will launch sometime after October.
[01:49:21.900 --> 01:49:28.060]   Steve, I got to say, if these rumors turn out to be true, the thing that most excites
[01:49:28.060 --> 01:49:30.660]   me is not the API, it's not the sensors.
[01:49:30.660 --> 01:49:32.100]   It's that the screen's on the inside.
[01:49:32.100 --> 01:49:37.860]   I mean, for me, that makes a whole lot more sense than having to do this.
[01:49:37.860 --> 01:49:40.220]   This we don't do anymore because we don't wear watches.
[01:49:40.220 --> 01:49:44.380]   This feels perfectly normal because this is also how I use my phone.
[01:49:44.380 --> 01:49:46.580]   What are your takes?
[01:49:46.580 --> 01:49:49.780]   When I heard that rumor, the first thing that came to my mind was, I don't know if you're
[01:49:49.780 --> 01:49:54.100]   familiar with the Samsung Gear Fit, but it had a curved screen that goes on the top,
[01:49:54.100 --> 01:49:57.300]   and it was super awkward to look at like this.
[01:49:57.300 --> 01:50:00.100]   If it was on the inside of your wrist, it would have been so much better.
[01:50:00.100 --> 01:50:05.180]   This kind of makes me think that it's going to be like a curved screen similar to that,
[01:50:05.180 --> 01:50:08.140]   but it's more natural looking on the inside.
[01:50:08.140 --> 01:50:10.940]   That's probably why they made the design choice.
[01:50:10.940 --> 01:50:15.380]   What excited me the most, I think, is I've been using Android Wear where I stopped using
[01:50:15.380 --> 01:50:19.980]   it after my review of it, but I was using it for four or five or six days.
[01:50:19.980 --> 01:50:21.620]   That thing just drew me crazy.
[01:50:21.620 --> 01:50:24.620]   It was because it was just constantly setting notifications.
[01:50:24.620 --> 01:50:29.940]   It was constantly buzzing my wrist with every tweet and email I got.
[01:50:29.940 --> 01:50:34.020]   I didn't really find it useful because I just mimicked everything that was already happening
[01:50:34.020 --> 01:50:36.780]   on my smartphone.
[01:50:36.780 --> 01:50:41.380]   Here it sounds like Microsoft has taken the smarter approach and focusing on fitness,
[01:50:41.380 --> 01:50:44.980]   which is really important in this fitness trucker as we know like Jawbone and so forth.
[01:50:44.980 --> 01:50:47.860]   They're very popular and very useful.
[01:50:47.860 --> 01:50:53.180]   What I assume is just a very limited notification thing on that screen.
[01:50:53.180 --> 01:50:57.180]   I feel like that would be create a much better product than the smart watches and smart bands
[01:50:57.180 --> 01:50:59.780]   or whatever you want to call them that we're already seeing.
[01:50:59.780 --> 01:51:01.380]   It also sounds a lot like the iWatch.
[01:51:01.380 --> 01:51:04.860]   You hear rumors of 10 or 11 different sensors.
[01:51:04.860 --> 01:51:06.740]   That's the same thing we're hearing about the iWatch.
[01:51:06.740 --> 01:51:11.180]   It's going to be able to detect everything from your hydration levels to your glucose
[01:51:11.180 --> 01:51:12.700]   and so on.
[01:51:12.700 --> 01:51:16.620]   If Microsoft is doing the same thing in making a cross platform and they do it well, that
[01:51:16.620 --> 01:51:18.180]   could be really huge.
[01:51:18.180 --> 01:51:23.460]   Ari, do you care at all about smart watches, smart bands, smart devices on your wrist?
[01:51:23.460 --> 01:51:25.740]   I'm wearing Android right now.
[01:51:25.740 --> 01:51:32.140]   Actually, yesterday night I was at the movies and it kept going off and it was really bright.
[01:51:32.140 --> 01:51:35.980]   I actually rotated around and put it on the other side of my wrist just so that I could
[01:51:35.980 --> 01:51:37.740]   kind of go like this.
[01:51:37.740 --> 01:51:42.940]   What's the idea of somebody intentionally designing a device like that sort of makes sense to me?
[01:51:42.940 --> 01:51:46.340]   He's Ari McCracken and the smart band was his idea.
[01:51:46.340 --> 01:51:50.060]   I do worry a little bit though about Microsoft doing this because they have so many major
[01:51:50.060 --> 01:51:53.860]   fish to fry and problems to solve.
[01:51:53.860 --> 01:51:59.820]   It's kind of hard to imagine a Microsoft band being an enormous product that saves the company.
[01:51:59.820 --> 01:52:04.060]   You see, I don't need an enormous product that saves the company.
[01:52:04.060 --> 01:52:07.020]   What I like is it's actually something different.
[01:52:07.020 --> 01:52:13.740]   The last 15 years has always felt as if Microsoft/Intell were a step behind.
[01:52:13.740 --> 01:52:18.140]   They had the tech, they had some decent design but it always was like, "Okay, well, that's
[01:52:18.140 --> 01:52:19.140]   popular.
[01:52:19.140 --> 01:52:20.300]   Let's make one of those."
[01:52:20.300 --> 01:52:23.260]   This is finally something with this saying, "Look, a watch is stupid.
[01:52:23.260 --> 01:52:24.620]   We're not going to build you a watch.
[01:52:24.620 --> 01:52:28.820]   No one wants a watch but would you take a band that has a different kind of screen?
[01:52:28.820 --> 01:52:30.580]   It's not one of these big, clunky screens.
[01:52:30.580 --> 01:52:34.900]   It's going to be super, super thin and it's not designed to operate like a watch.
[01:52:34.900 --> 01:52:37.380]   It's designed to operate like an extension of your phone.
[01:52:37.380 --> 01:52:39.060]   I kind of like that.
[01:52:39.060 --> 01:52:43.020]   I like forward thinking even if it doesn't come through at least trying something that's
[01:52:43.020 --> 01:52:44.820]   not what Apple or Google did.
[01:52:44.820 --> 01:52:49.740]   It would be a great story if the Microsoft Smart Band at least competed on the same
[01:52:49.740 --> 01:52:52.740]   level as the iWatch.
[01:52:52.740 --> 01:52:56.740]   How awesome would it be if it outsold it?
[01:52:56.740 --> 01:53:00.420]   Microsoft keeps saying that it's a company about supporting multiple platforms and it's
[01:53:00.420 --> 01:53:03.740]   nice to see them putting their money where their mouth is and not building something
[01:53:03.740 --> 01:53:06.220]   to be used with your Windows phone.
[01:53:06.220 --> 01:53:10.300]   Of course, they have every incentive to support Android and iOS in this case because if it
[01:53:10.300 --> 01:53:13.900]   did only work with your Windows phone, the market would be really small.
[01:53:13.900 --> 01:53:14.900]   Absolutely.
[01:53:14.900 --> 01:53:15.900]   Steve, what about it?
[01:53:15.900 --> 01:53:19.180]   Are you going to get both the iWatch, the next Google watch and the Microsoft.
[01:53:19.180 --> 01:53:20.380]   I mean, you probably will.
[01:53:20.380 --> 01:53:22.060]   That's what they have to wait and see.
[01:53:22.060 --> 01:53:26.740]   The best example I can think of is I wear this, so the jawbone up and I'm obsessed with it.
[01:53:26.740 --> 01:53:30.100]   That's because it does a few things and it doesn't very well.
[01:53:30.100 --> 01:53:35.340]   It tracks my steps, it tracks my sleep and I can type in and track when I go to the gym
[01:53:35.340 --> 01:53:36.900]   and track my workouts.
[01:53:36.900 --> 01:53:39.180]   That's amazing and it adds value.
[01:53:39.180 --> 01:53:42.500]   You know, today's current smart watches don't add any value.
[01:53:42.500 --> 01:53:48.780]   They're just a $200 thing you slap in your wrist that does the same thing as your smartphone.
[01:53:48.780 --> 01:53:52.460]   The reports, there's so many reports and rumors about the iWatch and the Microsoft
[01:53:52.460 --> 01:53:55.180]   Band or whatever you want to call it.
[01:53:55.180 --> 01:54:01.780]   It sounds like they're taking a much better and much more intelligent approach to this
[01:54:01.780 --> 01:54:08.300]   wearable device category than we've seen Google and Samsung and Pebble do.
[01:54:08.300 --> 01:54:09.300]   That's what excites me.
[01:54:09.300 --> 01:54:13.100]   I'm not saying it's going to save Microsoft or be the next big computing platform, but
[01:54:13.100 --> 01:54:17.940]   if this is going to be a popular category, I think the approach that Microsoft and Apple
[01:54:17.940 --> 01:54:20.460]   are reportedly taking, that's the right approach.
[01:54:20.460 --> 01:54:21.740]   I do like that.
[01:54:21.740 --> 01:54:23.500]   I think I agree with you.
[01:54:23.500 --> 01:54:28.300]   Now, one last bit before we say goodbye, just because I was really into the World Cup,
[01:54:28.300 --> 01:54:31.980]   I didn't think we're going to use this, but I think we are going to use it now.
[01:54:31.980 --> 01:54:36.780]   We all know that defacing is bad, like graffiti is bad, tagging is bad, but something happened
[01:54:36.780 --> 01:54:42.980]   to Wikipedia last week right after the United States lost to Belgium in the World Cup.
[01:54:42.980 --> 01:54:47.860]   And that is the Wikipedia page for the United States Secretary of Defense was changed.
[01:54:47.860 --> 01:54:50.100]   Chad, if you could go ahead and bring that up.
[01:54:50.100 --> 01:54:56.900]   The Wikipedia entry was changed from the current incumbent Chuck Hagel to Tim Howard.
[01:54:56.900 --> 01:55:01.780]   Now, though, Wikipedia does not tolerate any defacement of entries for any reason, even
[01:55:01.780 --> 01:55:08.660]   Wikipedia mastermind, it made it that the prank was quite exquisite.
[01:55:08.660 --> 01:55:12.020]   That does it for this episode of this week in tech.
[01:55:12.020 --> 01:55:13.940]   I want to thank our panelists for joining us.
[01:55:13.940 --> 01:55:17.300]   Harry McCracken, can we officially say that?
[01:55:17.300 --> 01:55:18.300]   Oh, I'm sorry.
[01:55:18.300 --> 01:55:19.300]   Chad is pointing at me.
[01:55:19.300 --> 01:55:20.300]   We have a week ahead.
[01:55:20.300 --> 01:55:21.300]   Yeah, we will.
[01:55:21.300 --> 01:55:23.300]   We have the past week.
[01:55:23.300 --> 01:55:25.620]   Oh, we have a little promo.
[01:55:25.620 --> 01:55:26.780]   All right, hit that.
[01:55:26.780 --> 01:55:27.780]   You ready to roll it?
[01:55:27.780 --> 01:55:28.780]   Here we go.
[01:55:28.780 --> 01:55:33.820]   Previously on Twitter, we're not going to light up like 40 of them at the same time.
[01:55:33.820 --> 01:55:35.460]   That is such a bad idea.
[01:55:35.460 --> 01:55:36.460]   You did what?
[01:55:36.460 --> 01:55:37.460]   You are insane.
[01:55:37.460 --> 01:55:44.860]   Security now to keep things simple buffers are always larger than the maximum space we
[01:55:44.860 --> 01:55:45.860]   need.
[01:55:45.860 --> 01:55:48.860]   The companies should just say insert hack here.
[01:55:48.860 --> 01:55:53.860]   I'm going to teach you how to turn this into something like this.
[01:55:53.860 --> 01:55:55.660]   This is a chat getting revenge.
[01:55:55.660 --> 01:55:58.300]   It's alive and break.
[01:55:58.300 --> 01:55:59.300]   Whoa!
[01:55:59.300 --> 01:56:00.300]   Windows Weekly.
[01:56:00.300 --> 01:56:02.580]   There's also going to be a pro version of the fitness band.
[01:56:02.580 --> 01:56:03.580]   Both girls.
[01:56:03.580 --> 01:56:04.580]   Yeah, both girls.
[01:56:04.580 --> 01:56:05.580]   Yeah, both girls.
[01:56:05.580 --> 01:56:08.140]   Yeah, that's what I give up.
[01:56:08.140 --> 01:56:09.220]   Coding 101.
[01:56:09.220 --> 01:56:10.580]   I like how your makeup looks.
[01:56:10.580 --> 01:56:12.380]   I like how your makeup looks too.
[01:56:12.380 --> 01:56:14.020]   Oh, it's fine.
[01:56:14.020 --> 01:56:16.100]   I was eating chocolate this morning.
[01:56:16.100 --> 01:56:17.100]   This weekend Enterprise.
[01:56:17.100 --> 01:56:18.100]   You stop it!
[01:56:18.100 --> 01:56:20.260]   Time is off to your left.
[01:56:20.260 --> 01:56:22.340]   You can look in there, but I would mostly...
[01:56:22.340 --> 01:56:23.420]   Make the faines stop!
[01:56:23.420 --> 01:56:24.820]   They see me trolling.
[01:56:24.820 --> 01:56:28.340]   If you missed Twit this week, you missed a lot of Padre.
[01:56:28.340 --> 01:56:29.340]   Ow!
[01:56:29.340 --> 01:56:30.340]   Ow!
[01:56:30.340 --> 01:56:31.340]   Ow!
[01:56:31.340 --> 01:56:32.340]   Ow!
[01:56:32.340 --> 01:56:35.700]   Do you ever sleep?
[01:56:35.700 --> 01:56:40.340]   This is, I guess, we did this the chat a while back and I guess this is sort of his
[01:56:40.340 --> 01:56:41.340]   revenge.
[01:56:41.340 --> 01:56:43.580]   When Leo is away, at least one of us will play.
[01:56:43.580 --> 01:56:45.060]   This week it was Padre.
[01:56:45.060 --> 01:56:46.900]   Oh my goodness.
[01:56:46.900 --> 01:56:47.900]   That's what I get.
[01:56:47.900 --> 01:56:52.540]   Steve, if you ever work for a network like Twit, just make sure you never put yourself
[01:56:52.540 --> 01:56:53.540]   out there, okay?
[01:56:53.540 --> 01:56:55.740]   Because you're going to get stepped on.
[01:56:55.740 --> 01:56:57.500]   I do want to thank the two of you.
[01:56:57.500 --> 01:56:58.740]   Now can I talk about them?
[01:56:58.740 --> 01:56:59.740]   Yes, go ahead.
[01:56:59.740 --> 01:57:00.740]   Okay.
[01:57:00.740 --> 01:57:02.380]   Harry McCracken, technologizer.
[01:57:02.380 --> 01:57:04.940]   But no, now we're saying that you're working for...
[01:57:04.940 --> 01:57:05.940]   Fast company.
[01:57:05.940 --> 01:57:06.940]   Fast company.
[01:57:06.940 --> 01:57:07.940]   Two weeks.
[01:57:07.940 --> 01:57:08.940]   Technologizer.
[01:57:08.940 --> 01:57:10.460]   Well, just going to be a place where I have fun on the side.
[01:57:10.460 --> 01:57:13.620]   But mainly fast company starting two weeks from tomorrow.
[01:57:13.620 --> 01:57:15.900]   And of course they're going to find you at Fast Company, but where else can they find
[01:57:15.900 --> 01:57:17.780]   you if they want to check out your work?
[01:57:17.780 --> 01:57:19.140]   On Twitter for sure.
[01:57:19.140 --> 01:57:20.140]   Harry McCracken.
[01:57:20.140 --> 01:57:23.660]   On Google+ sort of on Facebook kind of.
[01:57:23.660 --> 01:57:26.100]   Although it's mostly the same stuff I put on Twitter.
[01:57:26.100 --> 01:57:29.940]   You say Fast Company, then Twitter, then Technologizer.
[01:57:29.940 --> 01:57:30.940]   Moving forward.
[01:57:30.940 --> 01:57:31.940]   All right.
[01:57:31.940 --> 01:57:33.620]   Well, we have got you all planned out.
[01:57:33.620 --> 01:57:36.500]   And also planned out is Mr. Steve Kovach.
[01:57:36.500 --> 01:57:37.700]   Thank you so very much for coming in.
[01:57:37.700 --> 01:57:41.860]   I know you're busy and I thank you for coming in on a July 4 weekend.
[01:57:41.860 --> 01:57:44.100]   Same to you Harry.
[01:57:44.100 --> 01:57:46.020]   Where can people find you?
[01:57:46.020 --> 01:57:47.020]   Yeah.
[01:57:47.020 --> 01:57:48.020]   You can read my stuff.
[01:57:48.020 --> 01:57:50.820]   Businessinsider.com/sai.
[01:57:50.820 --> 01:57:52.020]   That's the tech section.
[01:57:52.020 --> 01:57:55.060]   And then follow me on Twitter @SteveKovach.
[01:57:55.060 --> 01:57:56.460]   And yeah, that's the best way.
[01:57:56.460 --> 01:57:57.460]   Thanks.
[01:57:57.460 --> 01:57:58.460]   Thank you.
[01:57:58.460 --> 01:58:02.460]   And you'll probably find him on future episodes of Tech News Today and Tech News Tonight.
[01:58:02.460 --> 01:58:04.300]   We keep going back to the well.
[01:58:04.300 --> 01:58:05.300]   That is Steve Kovach.
[01:58:05.300 --> 01:58:11.300]   Now don't forget that you can always find us live every Sunday at 3 o'clock p.m.
[01:58:11.300 --> 01:58:15.580]   At 6 o'clock Eastern or 2200 UTC.
[01:58:15.580 --> 01:58:18.340]   You want to find us live, go to live.twit.tv.
[01:58:18.340 --> 01:58:22.940]   And as long as you're watching us live, why not jump into our chat room at IRC.twit.tv.
[01:58:22.940 --> 01:58:26.700]   It's a fun part of Twit where you get to interact with the host.
[01:58:26.700 --> 01:58:29.820]   In fact, you've heard me call out to the chat room.
[01:58:29.820 --> 01:58:31.620]   It's that kind of relationship.
[01:58:31.620 --> 01:58:35.700]   Also you can find our shows at twit.tv/twit.
[01:58:35.700 --> 01:58:36.700]   Go ahead and drop by.
[01:58:36.700 --> 01:58:39.140]   You'll see not just all of our episodes, but also the show notes.
[01:58:39.140 --> 01:58:47.460]   If there was a story that you really want to read up on, you're going to find it at twit.tv/twit.
[01:58:47.460 --> 01:58:53.500]   Also did you know that I'm actually on this network like more than just Twit?
[01:58:53.500 --> 01:58:56.860]   You're going to find actually I guess you do because Chad decided to play that video.
[01:58:56.860 --> 01:59:01.420]   You can find me Mondays at 2.30 p.m. Pacific time for this week in Enterprise Tech where
[01:59:01.420 --> 01:59:02.980]   again we get to talk about technology.
[01:59:02.980 --> 01:59:04.100]   We get to talk about network.
[01:59:04.100 --> 01:59:05.940]   We get to talk about data centers.
[01:59:05.940 --> 01:59:10.740]   On Thursday you'll find me both at 11 o'clock for know-how which is a show about makers,
[01:59:10.740 --> 01:59:17.540]   about DIY and at 1.30 for coding 101 which is all about bringing you into the world of
[01:59:17.540 --> 01:59:18.540]   the code monkey.
[01:59:18.540 --> 01:59:23.380]   And finally on Friday it's an unofficial show but stopped by at 7 o'clock p.m. Pacific
[01:59:23.380 --> 01:59:25.220]   time for Padre's Corner.
[01:59:25.220 --> 01:59:30.060]   We'll get to Jib Jam about all the tech news that slipped through the cracks.
[01:59:30.060 --> 01:59:34.460]   Until next time I'm Father Robert Ballisair, the digital Jesuit infarleal report The Tech
[01:59:34.460 --> 01:59:49.460]   Guy and another Twit is in the can.

