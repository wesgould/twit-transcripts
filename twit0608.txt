
[00:00:00.000 --> 00:00:13.000]   It's time for Twit this week in Tech. We've got a great panel for you. Brianna Wu, she's running for Congress and of course is a game developer, Aaron Griffith from Fortune.com and Larry Magan from CBS Radio.
[00:00:13.000 --> 00:00:26.000]   We're going to talk about the latest Tech News. New emojis are here. The Samsung Galaxy S8 is here. And yes, Congress decided you don't need privacy on the Internet. It's all coming up next on Twit.
[00:00:29.000 --> 00:00:34.000]   NetCasts you love. From people you trust.
[00:00:34.000 --> 00:00:38.000]   This is Twit.
[00:00:38.000 --> 00:00:46.000]   Bandwidth for this week in Tech is provided by CashFly at CACHEFLY.com.
[00:00:52.000 --> 00:01:01.000]   This is Twit this week in Tech. Episode 608 recorded Sunday April 2nd, 2017. Super canoe.
[00:01:01.000 --> 00:01:18.000]   This week in Tech is brought to you by Carbonite. Keep your business safe this year. Protect your business from ransomware and hacker attacks with automatic cloud backup from Carbonite. Try it free at Carbonite.com. Use the offer code Twit to get two free bonus months if you decide to buy.
[00:01:19.000 --> 00:01:32.000]   And by WordPress. More websites run on WordPress than on any other platform. Create your website today and get 15% off at WordPress.com/Twit. That's WordPress.com/Twit.
[00:01:33.000 --> 00:01:50.000]   And by ZipRecruiter. Are you hiring? With ZipRecruiter.com you can post it to 200+ job boards including social networks all with a single click screen, rate and hire the right candidates fast. Try ZipRecruiter free at zipprecruiter.com/Twit.
[00:01:51.000 --> 00:02:05.000]   And by Stamps.com. Start using your time more effectively with Stamps.com. Use Stamps.com to buy and print real US postage the instant you needed right from your desk. For our special offer go to Stamps.com, click on the microphone and enter Twit.
[00:02:10.000 --> 00:02:22.000]   It's time for Twit this week in Tech. The show where we get together with some of the best tech journalists in the biz and talk about technology. Larry Magget is actually in the studio with me from CBS Radio. Good to see you Larry. Good to see you Leo.
[00:02:22.000 --> 00:02:29.000]   Safe for Kids.org. SafeKids.com and Connect Safe for you. You got close. I have many years if I said that wrong.
[00:02:29.000 --> 00:02:35.000]   Actually just go to connect safely.org. That's the non-profit. It's even on the screen if I would just look.
[00:02:36.000 --> 00:02:44.000]   It's nice to have you in studio. Usually you're on Skype. It's great to come to Petalome. It's unfortunate that there's huge traffic even on a Sunday to get here.
[00:02:44.000 --> 00:02:47.000]   Especially on a Sunday because people come up here for a big year.
[00:02:47.000 --> 00:02:52.000]   I see when you're going by the Golden Gate Bridge or up, Golden Gate Park. But it's lovely. Nice to see you. Lovely new studio.
[00:02:52.000 --> 00:02:59.000]   Thank you for coming up. I appreciate you. Also back from fortune.com where she's a senior writer. It's Erin Griffith. Great to see you on your bike.
[00:03:00.000 --> 00:03:14.000]   Back from Thailand. She says she's still a little Zen. Yes. I'm actually going out to San Francisco next week to meet with a ton of venture capitalists and tech startups.
[00:03:14.000 --> 00:03:22.000]   I'm sure after that that will be enough to wipe away any leftover vacations. You get all the stress that they're under. You get all that stuff.
[00:03:23.000 --> 00:03:31.000]   It's palpable. Erin has, besides reporting a senior writer at Fortune where she's been for several years, she also now does the term sheet.
[00:03:31.000 --> 00:03:35.000]   Daily newsletter for people who are investors.
[00:03:35.000 --> 00:03:48.000]   That web view clearly has a bug in it. I don't know what this is. More. Generally people don't read it online. That's a thing that we don't advertise to.
[00:03:49.000 --> 00:03:59.000]   I'm not sure if you're interested in that. Yeah. Haven't been a lot of resource dedicated to. Actually, it used to look a lot worse. It had no line breaks in it. But anyways, read it in your inbox.
[00:03:59.000 --> 00:04:09.000]   Yeah, that's supposed to be a comment. I don't know why we're seeing that. Brianna Wu would pick that right up. She's, of course, a developer. And I'm really thrilled to say this. I don't know if it's the first time ever.
[00:04:10.000 --> 00:04:27.000]   I'm not sure if it's the first time ever. I'm not sure if it's the first time ever. I'm not sure if it's the first time ever. I'm not sure if it's the first time ever. I'm not sure if it's the first time ever.
[00:04:27.000 --> 00:04:34.000]   I'm not sure if it's the first time ever. I'm not sure if it's the first time ever. I'm not sure if it's the first time ever.
[00:04:35.000 --> 00:04:38.820]   team and yeah I got to tell you Leah I'm so excited a few weeks and we're going to be
[00:04:38.820 --> 00:04:43.920]   starting the initiative where I'm going to try to recruit other Silicon Valley engineers
[00:04:43.920 --> 00:04:49.460]   to run alongside me especially Republicans. We need the Silicon Six to basically go take
[00:04:49.460 --> 00:04:55.540]   over the tech subcommittee in Congress and write some just same policy because it's terrible
[00:04:55.540 --> 00:04:56.620]   right now.
[00:04:56.620 --> 00:04:59.860]   Especially after last week with the privacy policy.
[00:04:59.860 --> 00:05:01.180]   Well it was so disastrous.
[00:05:01.180 --> 00:05:05.940]   Let's talk about that but also I didn't Donald Trump just say that he they have not fully
[00:05:05.940 --> 00:05:09.740]   staffed the office of technology in the White House I think.
[00:05:09.740 --> 00:05:15.020]   They're getting they're getting no information.
[00:05:15.020 --> 00:05:18.860]   So who took over Megan Smith's job? Do we have a CTO?
[00:05:18.860 --> 00:05:25.100]   A CTO I don't think we're missing half of the cabinet positions are on field. I don't
[00:05:25.100 --> 00:05:29.420]   know. I don't know what's going on but it is it's pretty clear when you when you hear
[00:05:29.420 --> 00:05:33.740]   members of Congress talk about technology. Some know some understand I think Ron Wyden
[00:05:33.740 --> 00:05:39.700]   understands there are some members of Congress who are pretty savvy and then you know for
[00:05:39.700 --> 00:05:44.860]   better or for worse Darrylissa who is is fairly tech savvy even though some of his policies
[00:05:44.860 --> 00:05:51.180]   I wouldn't agree with. But then a lot of them just really it's like they never even used
[00:05:51.180 --> 00:05:52.180]   a computer.
[00:05:52.180 --> 00:05:54.780]   Yeah I always thought there were two political parties when it comes to tech they clued it
[00:05:54.780 --> 00:05:55.780]   in the clueless.
[00:05:55.780 --> 00:05:56.780]   Yeah.
[00:05:56.780 --> 00:05:58.420]   And you have RMDs next to their names.
[00:05:58.420 --> 00:06:03.180]   I really agree with that. I think the access isn't right versus left. I think it's informed
[00:06:03.180 --> 00:06:04.980]   versus right and formed.
[00:06:04.980 --> 00:06:09.780]   As we've started looking into this policy yeah cyber security is national security issue
[00:06:09.780 --> 00:06:14.700]   has nothing to do with Republicans or Democrats and we are massively vulnerable just because
[00:06:14.700 --> 00:06:21.140]   the people making these policies don't understand it. So I think it's very patriotic for people
[00:06:21.140 --> 00:06:26.860]   that really have a passion for making better policies step up and to you know do public
[00:06:26.860 --> 00:06:27.860]   service.
[00:06:27.860 --> 00:06:28.860]   Good for you.
[00:06:28.860 --> 00:06:34.580]   That's CTO position is you know Senate confirmed official position I don't but I don't know
[00:06:34.580 --> 00:06:36.980]   if there's been anybody nominated to fill it that's a very good question.
[00:06:36.980 --> 00:06:40.860]   So I'll register in the in your district and vote for you and of course I'll still want
[00:06:40.860 --> 00:06:45.220]   California because we all know that that's okay to do that now that's the new thing.
[00:06:45.220 --> 00:06:46.220]   Okay.
[00:06:46.220 --> 00:06:47.220]   All right.
[00:06:47.220 --> 00:06:53.380]   Breanna is also a developer and a gamer and giant space cat dot com is her company.
[00:06:53.380 --> 00:06:57.340]   A Boston independent game studio. That's what we do.
[00:06:57.340 --> 00:07:02.220]   So I guess we might as well start with the political apologies to those who say I just
[00:07:02.220 --> 00:07:05.860]   want to hear about the new Samsung Galaxy S8. We'll get to that.
[00:07:05.860 --> 00:07:06.860]   Yeah.
[00:07:06.860 --> 00:07:10.580]   But I do think it's important. I'm hearing a lot of talk from normal people about this
[00:07:10.580 --> 00:07:17.260]   as well. Congress and that is the house and now the Senate mostly long party lines approved
[00:07:17.260 --> 00:07:22.020]   a new bill that among other effects it has actually a number of effects but among other
[00:07:22.020 --> 00:07:28.180]   effects overturns a privacy regulation the FCC implemented October of last year that
[00:07:28.180 --> 00:07:37.580]   prevented ISPs from selling your information to marketers should point out that you know
[00:07:37.580 --> 00:07:42.500]   this is a very new rule. So it's not like we're making a big step backwards.
[00:07:42.500 --> 00:07:44.700]   This is like how it was last year.
[00:07:44.700 --> 00:07:45.700]   Right.
[00:07:45.700 --> 00:07:50.860]   Let's say ISPs also include telecommunications companies like Verizon Sprint T-Mobile and
[00:07:50.860 --> 00:07:57.220]   ATT their your ISP on your phone. And so there's some concern that ISPs but this bill also
[00:07:57.220 --> 00:08:02.540]   does more Brianna you probably should we will let you explain this bill prevents as I understand
[00:08:02.540 --> 00:08:06.020]   the FCC from making any regulations of this kind in future.
[00:08:06.020 --> 00:08:11.620]   Yeah, that's exactly it. And you know it's a really disturbing bill. I think one of the
[00:08:11.620 --> 00:08:16.900]   strongest arguments for it is that you know Facebook and Google kind of have a duopoly
[00:08:16.900 --> 00:08:22.260]   on using your information to kind of market products to you and you know their argument
[00:08:22.260 --> 00:08:27.820]   was they wanted Verizon and other internet service providers in the mix being able to
[00:08:27.820 --> 00:08:33.060]   get this information. But the thing is if I you know choose not to use Facebook I can
[00:08:33.060 --> 00:08:38.980]   opt out of that. I can't opt out of you know using internet service providers. So it's
[00:08:38.980 --> 00:08:44.300]   a really big violation for privacy and you know I can't be the only engineer that started
[00:08:44.300 --> 00:08:49.580]   looking at VPNs this week. It's very disturbing to find out if I use a VPN I'm not protected.
[00:08:49.580 --> 00:08:50.580]   Not fully protected.
[00:08:50.580 --> 00:08:55.300]   A lot of people I think there's a little some people are overly concerned and this is maybe
[00:08:55.300 --> 00:08:58.540]   fostered a little bit by the tech community the guy who created cards against humanity
[00:08:58.540 --> 00:09:03.460]   said oh fine then I'm buying a Congress's search history and I'm going to publish it.
[00:09:03.460 --> 00:09:08.300]   This was never on the table that you could go to your an ISP and say I want Larry Maggud
[00:09:08.300 --> 00:09:09.500]   search history. Right.
[00:09:09.500 --> 00:09:12.540]   They're not selling individual. Well, soon.
[00:09:12.540 --> 00:09:17.860]   So I mean part of what they what they want to be able to do and what Facebook and Google
[00:09:17.860 --> 00:09:24.820]   already do is to target ads. So for example if I get an ad that's aimed at people in Palo
[00:09:24.820 --> 00:09:29.180]   Alto who are interested in technology it's not necessarily that they sold that information
[00:09:29.180 --> 00:09:34.940]   but that they've aimed that ad to me. Somebody basically bought my demographic. But again
[00:09:34.940 --> 00:09:40.740]   to to repeat what you just said is that not only are Facebook and Google voluntary you
[00:09:40.740 --> 00:09:43.980]   don't have to use either those product you use duct out go as your search engine if you
[00:09:43.980 --> 00:09:48.420]   want. But it's almost like the difference between a store having a sees you know a camera
[00:09:48.420 --> 00:09:51.860]   in the store versus the city having a drone following you.
[00:09:51.860 --> 00:09:53.900]   Your eyes sees everywhere you go.
[00:09:53.900 --> 00:09:59.380]   They see what time in my case they see what time I go to bed because I use I use my my
[00:09:59.380 --> 00:10:03.700]   IOT system to turn the lights off at night. They're going to soon be able to see what's
[00:10:03.700 --> 00:10:08.340]   going on literally scary. I'm about to put in something under my bed which will measure
[00:10:08.340 --> 00:10:11.740]   my wife's and my sleeping patterns. You can't get much more intimate.
[00:10:11.740 --> 00:10:16.460]   Yeah but who wants that? I don't want that. The point is that nobody should have that
[00:10:16.460 --> 00:10:21.620]   information. I guess. You know they can start marketing sleeping medication to me. But that's
[00:10:21.620 --> 00:10:27.580]   not on the table. That is not the kind of information ISPs plan to sell Verizon said
[00:10:27.580 --> 00:10:33.860]   that anyway. And I think that if they were to do that then I think we would see some action.
[00:10:33.860 --> 00:10:38.780]   What what is mostly and by the way they also can't see they can see when you're going
[00:10:38.780 --> 00:10:41.540]   to Google and Facebook but they can't see what you do with Google and Facebook because
[00:10:41.540 --> 00:10:46.060]   in both cases they're encrypt they're using SSL or TLS to encrypt it. And now I kind of
[00:10:46.060 --> 00:10:51.100]   understand Google has been pushing for HTTPS everywhere as has the EFF. For some years
[00:10:51.100 --> 00:10:56.260]   Google even says will rank you higher in search results if you are a secure site. Now maybe
[00:10:56.260 --> 00:11:00.260]   it makes a little bit more sense. We did that with Twit.tv but it's not like I was
[00:11:00.260 --> 00:11:03.380]   worried that somebody was going to you don't even have a login. What are they going to
[00:11:03.380 --> 00:11:07.940]   sell? But now I understand that prevents the internet service provider from seeing what
[00:11:07.940 --> 00:11:11.420]   you're doing on that side. They can see that you've gone to Google or Facebook or Twit
[00:11:11.420 --> 00:11:14.900]   but they can't see what you do on that side. If you go to Larrytheworld.com the second
[00:11:14.900 --> 00:11:20.780]   article you'll see among other things an interview with Minyans Clyburn of the FCC with a Democrat.
[00:11:20.780 --> 00:11:23.900]   But also she's still a commissioner. She's still a commissioner. Yeah. I also have a sidebar
[00:11:23.900 --> 00:11:28.940]   on there which is how to protect yourself. And of course using encryption sites is one
[00:11:28.940 --> 00:11:33.420]   tour browser with another VPN. I'm not sure I'd want to use a VPN all the time. It's an
[00:11:33.420 --> 00:11:37.420]   option. I mean I don't use it. Doesn't it slow you down Brianna? I mean it slows you down
[00:11:37.420 --> 00:11:41.980]   a lot I think. It does. And ours Technica had an amazing piece this week looking at that
[00:11:41.980 --> 00:11:46.420]   protect yourself tour. We all love tour but you're locked into a very specific version
[00:11:46.420 --> 00:11:51.660]   of Firefox. It has you know vulnerability so there is a way to look at it where that
[00:11:51.660 --> 00:11:57.380]   could make you even more unsafe in some ways. So you know I do have to agree with you. I
[00:11:57.380 --> 00:12:03.620]   think some of the rhetoric around this has been a little overheated. But I think what
[00:12:03.620 --> 00:12:09.300]   really frustrates me is the pattern. Because now they're going to be collecting this information.
[00:12:09.300 --> 00:12:14.500]   And some ways I'm less concerned about Verizon having this information to market to me. I'm
[00:12:14.500 --> 00:12:20.860]   more concerned about them not storing it properly not using proper infosecond encryption and
[00:12:20.860 --> 00:12:25.700]   then people for nefarious purposes getting obtaining that. That's what I'm worried about
[00:12:25.700 --> 00:12:31.660]   because that really could be tremendous damaging to just ordinary Americans. And it's just another
[00:12:31.660 --> 00:12:35.900]   thing that we're losing for our privacy. I also think that even though this doesn't
[00:12:35.900 --> 00:12:41.980]   change the rules that much I mean given that that's how it was in September 2016 it's just
[00:12:41.980 --> 00:12:50.540]   the same as that. But it is more than that a signal to these ISPs that the Congress and
[00:12:50.540 --> 00:12:54.980]   the government doesn't care what they do. And so in a way it's permission Verizon got
[00:12:54.980 --> 00:12:58.420]   in trouble for the super cookie that they were putting on everybody's browser. If you were
[00:12:58.420 --> 00:13:03.380]   a Verizon customer Verizon was identifying you uniquely to every site you visited and
[00:13:03.380 --> 00:13:08.660]   the site could then go to Verizon and say well who is that? Verizon got in trouble they
[00:13:08.660 --> 00:13:14.660]   got the FCC went after them they got a judgment against them a slap on the wrist 1.7 million
[00:13:14.660 --> 00:13:20.140]   dollar fine and they were prevented from doing that. That ended the super cookie but that's
[00:13:20.140 --> 00:13:25.260]   not going to ever happen again. I think Verizon is going to say it's open season now on our
[00:13:25.260 --> 00:13:28.940]   customers. The other thing that bothers me maybe Aaron you want to comment on this is
[00:13:28.940 --> 00:13:36.140]   it feels like our Congress got the telecommunications industry is the number one donor to Congress
[00:13:36.140 --> 00:13:41.340]   by far. It's been a lot of money. But by an individual Congress person they sold pretty
[00:13:41.340 --> 00:13:46.780]   cheap a few thousand dollar contribution and you got that vote. They don't care about
[00:13:46.780 --> 00:13:50.780]   consumers. >> And what I think is kind of noteworthy about
[00:13:50.780 --> 00:13:55.100]   this entire thing is that I agree with Brianna that some of the rhetoric has been a little
[00:13:55.100 --> 00:13:59.020]   bit overblown. It seems like some of the headlines I've been reading is like people are melting
[00:13:59.020 --> 00:14:05.020]   down like they sold you out. But I think it's important that people are finally getting freaked
[00:14:05.020 --> 00:14:09.980]   out about their data because there's been so many every time there's a new retailer that gets hacked
[00:14:09.980 --> 00:14:14.940]   or Yahoo gets hacked people maybe change their passwords but they don't really change their
[00:14:14.940 --> 00:14:20.620]   behaviors or think that much about their own personal privacy and they don't really push
[00:14:20.620 --> 00:14:25.980]   companies to be more secure. It's kind of one of those people shrug and say well yeah I guess
[00:14:25.980 --> 00:14:30.300]   we're all kind of vulnerable and we can't protect ourselves so that's how it goes.
[00:14:30.300 --> 00:14:34.700]   And I think the fact that people are starting to pay closer attention to this and realize that
[00:14:34.700 --> 00:14:41.340]   they need to take action is good. So the freaking out is maybe needed.
[00:14:41.340 --> 00:14:44.860]   >> And I also think the reality point about it's data retention. I mean if this is a
[00:14:44.860 --> 00:14:49.980]   valuable resource to the ISPs and they start warehousing this data that makes it all the more
[00:14:49.980 --> 00:14:54.380]   vulnerable to hackers and also governments. And I use governments with an S in the end.
[00:14:54.380 --> 00:15:00.300]   Plural getting access to this data of ours. So I think it's more than just commercial privacy.
[00:15:00.300 --> 00:15:05.260]   It's safety, security and protection against government intrusion that concerns me about this.
[00:15:05.260 --> 00:15:10.700]   And also why it's sort of like a network neutrality debate. I mean it's true that this law didn't
[00:15:10.700 --> 00:15:16.620]   change anything on day one. But what's the point of going in there and killing this particular
[00:15:16.620 --> 00:15:22.060]   FCC regulation who benefits besides AT&T, Verizon, Comcast and the other large agencies.
[00:15:22.060 --> 00:15:27.420]   >> Well let me make the argument that the congressmen and women who voted against it or voted for it
[00:15:27.420 --> 00:15:33.260]   argue. Brianna you mentioned one argument and an argument Verizon's brought up which levels the
[00:15:33.260 --> 00:15:36.300]   playing field. Google and Facebook have this data. >> It's not regulated by the FCC.
[00:15:36.300 --> 00:15:39.580]   >> Why shouldn't your ISP. But I think we've shot that one down.
[00:15:39.580 --> 00:15:43.340]   >> Right. >> The other argument which is a larger argument and as a philosophical
[00:15:43.340 --> 00:15:47.420]   argument is that the government shouldn't be regulating the internet at all. That the free
[00:15:47.420 --> 00:15:53.340]   market should control this. And it's true if you had a choice of an ISP who promised not to do this
[00:15:53.340 --> 00:16:00.460]   most people would choose that. Our ISP here doesn't. It's SonicNet. But my ISP at home is Comcast.
[00:16:00.460 --> 00:16:04.780]   I can't get SonicNet at home. And most people in this country don't have that kind of choice.
[00:16:04.780 --> 00:16:11.020]   But from a purely philosophical point of view, I'm not sure I disagree that
[00:16:11.020 --> 00:16:16.940]   government regulation on the internet is fraught with peril. And if we could get a free market
[00:16:16.940 --> 00:16:23.100]   in real competition going that would be preferable. >> It's very difficult to do because last month.
[00:16:23.100 --> 00:16:30.700]   >> You know, I do believe the government has a role to play in facilitating this. I think one of
[00:16:30.700 --> 00:16:35.820]   the reasons we're hesitant to do this is because Congress is so inept at the
[00:16:35.820 --> 00:16:37.820]   form of policy. >> They don't understand the internet.
[00:16:37.820 --> 00:16:42.540]   They shouldn't be regulating the internet. >> But they're not regulating the virtual monopoly
[00:16:42.540 --> 00:16:48.460]   duopoly that is running wires to your house. I mean, Comcast and AT&T.
[00:16:48.460 --> 00:16:51.740]   >> They created that duopoly by the way. >> Yeah, they're the only two providers that I
[00:16:51.740 --> 00:16:55.820]   can get where I live is Comcast and AT&T. So it's not like I get to go through the yellow
[00:16:55.820 --> 00:16:59.420]   page and say, oh, I'm going to get this ISP. Because they've got great privacy. If I could,
[00:16:59.420 --> 00:17:05.580]   that'd be fine. No problem. >> I think I would add this. I think particularly
[00:17:05.580 --> 00:17:11.020]   at the infosec. This is not the kind of problem that the marketplace can solve because neither the
[00:17:11.020 --> 00:17:17.580]   seller nor the buyer is interested in spending the money. Consumers, we can, as technology people,
[00:17:17.580 --> 00:17:23.580]   we can believe that there's going to be a magical future where ordinary people care about VPNs
[00:17:23.580 --> 00:17:28.860]   and stuff. It's not pragmatic. And then for a company like Verizon, it is to their economic
[00:17:28.860 --> 00:17:36.460]   benefit to collect as much data as possible. So the only safeguard this pragmatic I can see on privacy
[00:17:36.460 --> 00:17:42.060]   is government regulation. And it's exactly like you said, Leo, these congresspeople,
[00:17:42.060 --> 00:17:47.180]   their votes are being bought for a pittance. And if I'm elected, I'm not going to take money
[00:17:47.180 --> 00:17:51.900]   from these people. I just, I couldn't do it ethically. And I think they shouldn't take money,
[00:17:51.900 --> 00:17:59.340]   there's the regulating it. >> Of course, that was a very brief candidacy of what's his name,
[00:17:59.340 --> 00:18:02.860]   Larry, the guy who created the Creative Commons. >> Larry Lessig.
[00:18:02.860 --> 00:18:06.860]   >> Yeah. >> His very brief candidacy, unfortunately, he kind of got out of the race too early.
[00:18:06.860 --> 00:18:13.020]   His whole plan was, which is crazy. Larry is a constitutional lawyer. He created the Creative
[00:18:13.020 --> 00:18:16.940]   Commons. He's a brilliant thinker for a long time. He was fighting against DRM. But then he realized
[00:18:16.940 --> 00:18:22.380]   none of this is going to ever work until we get money out of Congress. And his whole plan was to
[00:18:22.380 --> 00:18:26.940]   run for president, get elected, have to choose a really good vice president, run for president,
[00:18:26.940 --> 00:18:33.500]   get elected, completely reform campaign finance so that there's no private money at all in campaigns,
[00:18:33.500 --> 00:18:38.860]   and then resign and let the other guy run the country. I wish Larry had won, but Larry didn't
[00:18:38.860 --> 00:18:45.260]   get a chance. Here's a full page ad from TheFightForTheFuture.org, which is one of many,
[00:18:45.260 --> 00:18:50.540]   this was a group that started with the SOPA debates a couple of years ago. Keep our net free.org
[00:18:50.540 --> 00:18:55.100]   and save broadband privacy. Dear Mr. President, you just got spied on, big league. You know what
[00:18:55.100 --> 00:19:00.220]   it's like, you really do. Don't subject us all to the same bull hockey. This is your chance to prove
[00:19:00.220 --> 00:19:05.660]   if you're with the money or with the people. Aaron, is that really the choice that Congress made
[00:19:05.660 --> 00:19:10.220]   with the money or with the people? >> Sorry, I'm really stuck on the big league.
[00:19:10.220 --> 00:19:15.980]   >> It's actually a big league. >> No, he's always been saying big league,
[00:19:15.980 --> 00:19:20.860]   but he says big league, and it sounds like big league. >> That settles the bet.
[00:19:20.860 --> 00:19:28.140]   >> I mean, I think part of this is that, and this requires Congress standing up to these
[00:19:28.140 --> 00:19:32.620]   companies and saying, no, you're a utility. I'm sorry, but that's what you are. That's what
[00:19:32.620 --> 00:19:37.260]   you have to be treated by as investors, and that's the obligation that you have to your customers.
[00:19:37.260 --> 00:19:42.300]   They do not want to be utilities because that is not a great business. It's a very low margin,
[00:19:42.300 --> 00:19:49.820]   boring, low growth business to be in. And until that happens, they're going to be pushing more and
[00:19:49.820 --> 00:19:54.300]   more into the data and content business. >> Well, we're going to have that in the next couple of
[00:19:54.300 --> 00:20:00.220]   weeks on Twitch. Title II will absolutely be one of the top stories because the new chairman of the
[00:20:00.220 --> 00:20:07.180]   FCC, Ajit Pai, has already said that this Title II was the way the FCC did regulate net neutrality.
[00:20:07.260 --> 00:20:10.540]   The president has also already said he's not in favor of net neutrality.
[00:20:10.540 --> 00:20:15.820]   This rule will be thrown out, and it'll be thrown out soon. I don't know if Ajit Pai could do it
[00:20:15.820 --> 00:20:20.460]   with a stroke of a pen. If the president has to do it, if Congress has to do it, but there's
[00:20:20.460 --> 00:20:26.700]   absolute consensus that this regulating ISPs' utilities is not going to work, which means
[00:20:26.700 --> 00:20:31.580]   that's that was the only mechanism that the FCC had to regulate net neutrality.
[00:20:31.580 --> 00:20:35.340]   Net neutrality is out the window. I think it's safe to say over the next few months,
[00:20:36.220 --> 00:20:39.980]   all regulations protecting consumers on the internet are gone.
[00:20:39.980 --> 00:20:42.380]   >> It appears that way. >> Should consume.
[00:20:42.380 --> 00:20:47.420]   But is it a here on fire moment? I mean, should I hear a lot of people saying I'm going to use a VPN?
[00:20:47.420 --> 00:20:51.180]   I'm not going to use a VPN. >> I don't think the VPN is a solution. I mean,
[00:20:51.180 --> 00:20:55.580]   I think if you it's an option that people can have, I use it when I'm overseas for two reasons.
[00:20:55.580 --> 00:20:58.460]   >> Well, I use it when I'm on an open access point. >> I use it when I'm in Russia,
[00:20:58.460 --> 00:21:02.140]   I use it when I'm in China. And I hope I don't have to add American.
[00:21:02.140 --> 00:21:04.540]   >> But Netflix won't let you watch Netflix on a VPN. >> Netflix on a VPN.
[00:21:04.540 --> 00:21:07.820]   >> And your bank probably won't let you log in on it. >> When you're in Turkey and you want to use
[00:21:07.820 --> 00:21:12.060]   YouTube and every gone just banned YouTube, which is what happened to me, I needed an ISP
[00:21:12.060 --> 00:21:18.380]   when I'm in Russia. And I know for a fact that they spy on foreign visitors, I use a VPN.
[00:21:18.380 --> 00:21:22.220]   But the point is that we shouldn't have to do that. I mean, that's I think,
[00:21:22.220 --> 00:21:27.100]   you know, the point that the pre-onimate and I agree, we shouldn't have to resort to extraordinary
[00:21:27.100 --> 00:21:30.060]   means to protect our privacy. >> Should we write our members of Congress,
[00:21:30.060 --> 00:21:34.620]   beyond is that effective? Should we? >> I think he should. I help people run for
[00:21:34.620 --> 00:21:41.020]   office alongside me. But I think net neutrality, without net neutrality, we really don't live in
[00:21:41.020 --> 00:21:49.180]   a free society. And I'm not somebody that wants to say this is a harem fire moment. But we've seen
[00:21:49.180 --> 00:21:55.020]   the way this administration talks about internet issues and they clearly do not even understand
[00:21:55.020 --> 00:22:01.820]   the basics. So I think it's a very, very serious situation. And that's a lot of why I'm running
[00:22:01.820 --> 00:22:07.100]   for office. Again, it's not right versus left. It's informed versus uninformed. And I think you'd
[00:22:07.100 --> 00:22:11.660]   be very hard pressed to find a journalist that doesn't strongly believe in net neutrality or an
[00:22:11.660 --> 00:22:15.660]   engineer. >> And Brian, I also don't think it's regulation versus non-regulation. I mean,
[00:22:15.660 --> 00:22:19.340]   certain things you don't want Congress to regulate like content, right? >> Yeah.
[00:22:19.340 --> 00:22:23.660]   >> We don't want Congress regulating speech. But there's a difference between enforcing privacy
[00:22:23.660 --> 00:22:28.700]   regulations, which the Federal Trade Commission supposedly does anyway, and other kinds of things
[00:22:28.700 --> 00:22:33.020]   like net neutrality, it's not the same thing as controlling the internet, not controlling what you
[00:22:33.020 --> 00:22:37.900]   and I can say over the internet. So I think we just have to be smart about how we regulate and not
[00:22:37.900 --> 00:22:42.940]   have this attitude regulation good, regulation bad. It's just more nuanced than that. >> You know,
[00:22:42.940 --> 00:22:50.140]   there's a Twitch broadcaster in Germany that has just, Germany has required him to sign up for a
[00:22:50.140 --> 00:22:55.740]   broadcast TV license because he's a broadcaster. And that's the kind of regulation that would
[00:22:55.740 --> 00:23:03.340]   scare the hell out of me. I don't want the FCC to start regulating podcasting. So I think that
[00:23:03.340 --> 00:23:11.260]   you can't overreach as well. So I'm not, I remember we talked to John Perry Barlow when the EFF was
[00:23:11.260 --> 00:23:17.820]   debating how it wanted to protect net neutrality. EFF board agreed net neutrality need to be protected.
[00:23:17.820 --> 00:23:21.660]   But a good number of the board members didn't think that government interference was the right
[00:23:21.660 --> 00:23:29.820]   way to do this. I don't know what the right way is to do this. If you look at, it's, look,
[00:23:29.820 --> 00:23:35.900]   we fetishize free markets in this country as a religion. And I don't think that's necessarily
[00:23:35.900 --> 00:23:41.260]   bad, but there are some things free markets don't do well. And that's why we have anti-trust rules,
[00:23:41.260 --> 00:23:45.740]   any monopoly rules, because free markets tend to often run into monopolies. And as soon as
[00:23:45.740 --> 00:23:49.180]   something's a monopoly, there is no free market. There's no choice. We have a health care policy,
[00:23:49.180 --> 00:23:53.500]   because free markets have not done a particularly good job in keeping health care. So I think it's
[00:23:53.500 --> 00:23:58.460]   legitimate to say there is a role, I don't want to use the word government. There's a role for us
[00:23:58.460 --> 00:24:07.020]   as a society to limit what these businesses can do. But I think there's also room for debate about
[00:24:07.020 --> 00:24:10.780]   how far we want to go in that. And there are certainly risks involved in government regulation
[00:24:10.780 --> 00:24:15.340]   of the internet. If I could say one last thing on this, I completely agree with you.
[00:24:15.740 --> 00:24:21.580]   But I think it's really important to look at policy we're currently getting. Do you guys remember
[00:24:21.580 --> 00:24:26.700]   the Mariah botnet last year, which took down a huge amount of internet on this coast?
[00:24:26.700 --> 00:24:27.100]   >> Yes.
[00:24:27.100 --> 00:24:32.700]   >> What's really shocking to me is what the Republicans on the technology subcommittee in
[00:24:32.700 --> 00:24:40.300]   Congress that I may be working with. Marsha Rayburn, she came out and blamed the Mariah botnet on
[00:24:40.300 --> 00:24:44.300]   SOPA. >> She blamed it on some policy.
[00:24:44.300 --> 00:24:50.540]   Because Motto had the headline, this is the kind of idiot that's in charge of regulating the
[00:24:50.540 --> 00:24:57.500]   internet. It was beyond fair. So I agree with you, Leah, we have a reasonable conversation about
[00:24:57.500 --> 00:25:03.340]   that. But the more my campaign gets down and really studies the sausage being made by the
[00:25:03.340 --> 00:25:09.420]   technology subcommittee, it's just stunning to me. And this is, it's not the conversation that
[00:25:09.420 --> 00:25:14.380]   they're having. It's just a free-for-all giveaway with the people that donate to their campaigns.
[00:25:14.380 --> 00:25:20.060]   And it's just tremendously disturbing. It has huge cybersecurity consequences for this country.
[00:25:20.060 --> 00:25:26.780]   >> I also don't want, I mean, I think that there's a good chance that the technocrats in Silicon
[00:25:26.780 --> 00:25:31.100]   Valley are going to look at Trump's election and say, "Oh, I guess I could run." I mean,
[00:25:31.100 --> 00:25:33.740]   we think Mark Zuckerberg may run, right? >> Yeah.
[00:25:33.740 --> 00:25:37.980]   >> And I don't, sure, I want Mark Zuckerberg. >> He's the worst choice out of any
[00:25:37.980 --> 00:25:44.940]   out of any prominent tech person. I think Trump, if he's taught us anything that is that people
[00:25:44.940 --> 00:25:51.740]   want authenticity and people who are themselves. And Mark Zuckerberg's supposed to campaign is
[00:25:51.740 --> 00:25:58.620]   him going around and very stiffly shaking hands with people like almost cosplaying like a politician.
[00:25:58.620 --> 00:26:04.540]   >> Honest, I'm a human. I'm a human. I really am. I'm not a robot. >> Yeah. People would
[00:26:04.540 --> 00:26:10.780]   relate to that or even find that inspiring or, I mean, you know, so if that's what he's going for.
[00:26:10.780 --> 00:26:14.700]   >> Watch. I'm sure Jeff Bezos is considering it. Mark Zuckerberg is considering it.
[00:26:14.700 --> 00:26:19.340]   >> Is this a little bit more compelling? >> I don't think Silicon Valley is,
[00:26:19.340 --> 00:26:23.740]   is, I agree with you, Brianna. We want people to understand technology, but I don't think
[00:26:23.740 --> 00:26:26.780]   technologists necessarily are the right people to run the government either.
[00:26:27.580 --> 00:26:31.740]   You know, I think there's a technocratic point of view that, well, we know how things run
[00:26:31.740 --> 00:26:36.780]   and we're going to fix this all. And I'm not sure that's right either. Politics is a lot of,
[00:26:36.780 --> 00:26:43.100]   there's a lot of art and a lot of compromise and a lot of negotiation and technologists are not
[00:26:43.100 --> 00:26:46.940]   not noticed. >> But I do think it would be good to have a few more tech savvy people in Congress.
[00:26:46.940 --> 00:26:52.380]   I'm not sure I necessarily, we need to have a technocratic president, but for Congress to understand
[00:26:52.380 --> 00:26:56.220]   the more nuanced and subtle issues that was going on in the technology world would be helpful.
[00:26:56.220 --> 00:27:00.620]   >> Yeah. >> We talk a lot about diversity and I don't think we
[00:27:00.620 --> 00:27:06.780]   talk enough about diversity of background. Right now over 40% of Congress is comprised of lawyers.
[00:27:06.780 --> 00:27:13.900]   I work with plenty of lawyers in my career, but there's just having Congress so hyper-sampled
[00:27:13.900 --> 00:27:20.860]   from that group, I think it leads to a suboptimal outcome. So it's not just I want more technologists
[00:27:20.860 --> 00:27:26.540]   for Congress. I want more Georgia Dow, she'd be a great congressman if she weren't Canadian.
[00:27:26.540 --> 00:27:31.980]   She's comes from a therapy background. I want more academics. I just want more people with
[00:27:31.980 --> 00:27:36.700]   different perspectives coming and representing themselves in government because I think clearly
[00:27:36.700 --> 00:27:40.860]   the system we have right now is not working. >> I really like that, Brianna. That is a great goal.
[00:27:40.860 --> 00:27:47.420]   Let's just make it more diverse. More voices is always going to be better. More voices heard from.
[00:27:48.700 --> 00:27:53.260]   I completely agree with you on that. Let's take a break. We've got a great panel. Brianna Wu is
[00:27:53.260 --> 00:28:00.300]   here, SpaceCatGal on Twitter. And don't forget our website, BriannaWoo2018.com. If you're in the
[00:28:00.300 --> 00:28:06.460]   Massachusetts 8th, Brianna Wu is the gal for you. How about that? Can you use that?
[00:28:06.460 --> 00:28:07.980]   >> You can do that.
[00:28:07.980 --> 00:28:09.820]   [laughter]
[00:28:09.820 --> 00:28:13.740]   >> That's our campaign slogan. I like it.
[00:28:13.740 --> 00:28:16.780]   [laughter]
[00:28:16.780 --> 00:28:22.380]   >> Aaron Griffin is also here. She's at -- I'm sorry at Fortune.com. Sorry, Aaron.
[00:28:22.380 --> 00:28:26.940]   You're not related to Andy Griffin. That's somebody else. No, Andy Griffith.
[00:28:26.940 --> 00:28:28.940]   >> Yeah. He's also a Griffith.
[00:28:28.940 --> 00:28:33.500]   >> Are you married? Are you -- not married. I think almost asked, are you married to Andy Griffith?
[00:28:33.500 --> 00:28:36.860]   I do not mean to ask that. Are you related to Andy Griffith?
[00:28:36.860 --> 00:28:44.540]   >> I don't think so. Although growing up, my dad had a lot of paraphernalia from that show.
[00:28:44.540 --> 00:28:46.060]   >> He liked it.
[00:28:46.060 --> 00:28:48.140]   >> Around the -- I don't think there's any relation.
[00:28:48.140 --> 00:28:53.820]   >> I bet it wasn't even his real name. He always played the country guy, you know, the
[00:28:53.820 --> 00:29:00.220]   hick. But he was from Brooklyn. He was from New York. So an actor. I mean, he was an actor.
[00:29:00.220 --> 00:29:04.940]   That's called being a good actor. No, he actually was born in Mary, North Carolina,
[00:29:04.940 --> 00:29:12.300]   and he is Andy Samuel Griffith. So I take it all back. I apologize. But he's not Aaron's husband.
[00:29:12.300 --> 00:29:17.820]   Also, Aaron's husband, by the way. I hope you don't mind. But he's in the background right now
[00:29:17.820 --> 00:29:19.740]   trying to figure out how to solve a Rubik's Cube.
[00:29:19.740 --> 00:29:24.060]   >> Matt, have you solved the Rubik's Cube? He said not yet.
[00:29:24.060 --> 00:29:28.220]   >> Orkai. He has to sit quietly.
[00:29:28.220 --> 00:29:29.980]   >> Oh, no. He's frozen.
[00:29:29.980 --> 00:29:36.620]   >> He can't -- and Aaron is frozen. She's frozen, ladies and gentlemen. Also with
[00:29:36.620 --> 00:29:41.180]   his in studio. And it's nice for a change to have your in studio. The great Larry Magad of CBS
[00:29:41.180 --> 00:29:44.460]   Radio and connect safely.org. >> Hey, you got it right.
[00:29:44.460 --> 00:29:49.260]   >> I got it right this time. Our show today brought to you by Carbonite Online Backup.
[00:29:49.260 --> 00:29:58.380]   Ransomware, what was the number I heard? Ransomware in 2016 was a billion-dollar business.
[00:29:58.380 --> 00:29:59.340]   >> Yeah, it's huge.
[00:29:59.340 --> 00:30:03.580]   >> And the costs in terms of data down and time lost.
[00:30:04.140 --> 00:30:08.060]   Tens of billions of dollars last year. >> You want your data story off somewhere else.
[00:30:08.060 --> 00:30:10.780]   >> I was talking to somebody. I won't name names.
[00:30:10.780 --> 00:30:17.020]   He's on the board with somebody who's with a federal bank. And he's told me that the federal
[00:30:17.020 --> 00:30:21.420]   bank was saving bitcoins. Because -- and apparently a lot of private businesses are doing this now
[00:30:21.420 --> 00:30:24.300]   because they're worried about getting bit by ransomware. And they want to have bitcoins ready
[00:30:24.300 --> 00:30:26.860]   to buy the unlock key. >> I can't.
[00:30:26.860 --> 00:30:32.860]   >> This is the worst strategy I've ever heard. For crying out loud, don't stock up on Bitcoin.
[00:30:32.860 --> 00:30:38.940]   Get Carbonite. Again, get a good backup. >> Backing up isn't hard. It's easy.
[00:30:38.940 --> 00:30:42.220]   Here's what you want. I credit Peter Krogh, my friend, the photographer,
[00:30:42.220 --> 00:30:47.740]   with the 3-2-1 backup. You want three copies of everything. And by the way, if you delete
[00:30:47.740 --> 00:30:52.700]   your original, that's one copy. So three copies of everything. Two different media so that you're
[00:30:52.700 --> 00:30:59.340]   not tied to DVDs or USB. But one site, one should be offsite. One needs to be a way -- because
[00:30:59.340 --> 00:31:04.060]   what if you have fire insurance if your business burnt down, if your backups are sitting next to
[00:31:04.060 --> 00:31:09.260]   the computer or in a closet somewhere and it burns down too, are you -- you could rebuild,
[00:31:09.260 --> 00:31:13.100]   but can you rebuild your data? Can you rebuild your customer list and your supplier list and
[00:31:13.100 --> 00:31:16.940]   your accounts receivable? Can you pay your taxes? You can't do any of that because it's all on the
[00:31:16.940 --> 00:31:21.660]   computers. Back it up with Carbonite. They've got great plans for small and medium businesses,
[00:31:21.660 --> 00:31:28.540]   for homes as well. And if you want to read more about using Carbonite for ransomware mitigation,
[00:31:28.540 --> 00:31:32.220]   go to the Carbonite for office site, take a look at resources. They've got a bunch of white papers
[00:31:32.220 --> 00:31:36.700]   about ransomware, how to mitigate it, how to prevent it in the first place. And it's not just an
[00:31:36.700 --> 00:31:41.740]   ad for Carbonite. It's a really useful, some very useful white papers. It's all free to you at
[00:31:41.740 --> 00:31:47.020]   carbonite.com. So is a free trial. No credit card required. If you do the free trial, though,
[00:31:47.020 --> 00:31:52.060]   please use the offer code TWIT. That way they'll know you heard about it here. And
[00:31:52.060 --> 00:31:57.020]   you'll get two free bonus months if you decide to buy. You got to back it up to get it back,
[00:31:57.020 --> 00:32:02.380]   protect the business data right now at Carbonite.com. Use the offer code TWIT for two months.
[00:32:02.380 --> 00:32:09.180]   Yeah, I love them. What I really appreciate about Carbonite is like a live technical people. My
[00:32:09.180 --> 00:32:14.460]   spouse is less technical than I am. And I love it because I just set it up on his computer and
[00:32:14.460 --> 00:32:20.940]   it's no problems. Because for me, I can use super-duper and make a mirror copy of my hard drive bit
[00:32:20.940 --> 00:32:26.380]   for a bit. Frank's just not about that. And I just think it's an amazing product for people that
[00:32:26.380 --> 00:32:30.460]   don't want to mess with it. They're in your neighborhood too. Just there in Boston.
[00:32:30.460 --> 00:32:34.620]   You know, that's exactly right. I know our audience often they say, well, I've got, you know,
[00:32:34.620 --> 00:32:38.700]   I've got jungle this set up with S3 buckets and I'm going to have, and you know, and you know,
[00:32:38.700 --> 00:32:43.820]   they're geeks. So of course, but I guarantee you, in your family, there's somebody who doesn't
[00:32:43.820 --> 00:32:50.700]   know what backup is, who's stocking up on bitcoins. Do them a favor and tell them about carbonite.
[00:32:50.700 --> 00:32:54.860]   I mean, I heard that. That's like, what was that government institution that was doing this?
[00:32:55.660 --> 00:32:59.580]   Where do they keep their bitcoins? And then wallet. They're Bitcoin wallet.
[00:32:59.580 --> 00:33:06.140]   Bitcoin wallet. I worry about that. Yeah. Crazy. Crazy. Aaron is unfrozen.
[00:33:06.140 --> 00:33:12.620]   Yes. Now she's silent. Silent is the day as long.
[00:33:12.620 --> 00:33:21.180]   Okay, I'm in. Now I hear you. Yeah. There we go. Okay. Okay. Everybody's back. Hello, everybody.
[00:33:21.180 --> 00:33:26.140]   Let's talk about shiny objects. Because I know that's why you turn in this show. You don't want
[00:33:26.140 --> 00:33:30.380]   to hear about politics. You don't want to be a bad boy. Let's talk about the Galaxy S8,
[00:33:30.380 --> 00:33:37.260]   the new exploding phone from Samsung. No, no, no, it's not going to explode. Samsung had an event on
[00:33:37.260 --> 00:33:42.060]   on Wednesday in New York City. I don't know if anybody went showing off the new essay. You didn't
[00:33:42.060 --> 00:33:49.260]   go, Aaron? No, I shouldn't be saying this in the context of this podcast, but I don't really cover
[00:33:49.260 --> 00:33:59.100]   gadgets. No, I resisted covering gadgets for years. I wanted to talk about computing and technology.
[00:33:59.100 --> 00:34:03.660]   And anytime I went anywhere, people say, yeah, but what about the new phone? Right.
[00:34:03.660 --> 00:34:10.860]   Because all people care about is shiny gadgets. Right. Those stories get a lot more traffic than
[00:34:10.860 --> 00:34:19.100]   my very, very thoughtful analyses of the latest M&A transaction. I know. I know. It's crazy.
[00:34:19.740 --> 00:34:23.900]   So I ordered the S8 Plus because that's my job. And actually, you know what happened is I kind of
[00:34:23.900 --> 00:34:28.940]   in the process, got to fell in love with gadgets too. And now I always have a new phone every five
[00:34:28.940 --> 00:34:35.900]   minutes. This is going to be the first, the precursor of what we're going to see a lot in the next
[00:34:35.900 --> 00:34:43.020]   coming years, which are essentially phones with minimal bezels, minimal frames. Even Apple,
[00:34:43.020 --> 00:34:47.340]   supposedly with its next generation iPhone, will get rid of the physical home button.
[00:34:48.300 --> 00:34:52.860]   And spread that screen almost all the way to the edge top, bottom and left and right.
[00:34:52.860 --> 00:34:58.940]   The galaxies for sometimes now, since the S6 Edge have gone all the way around left to right.
[00:34:58.940 --> 00:35:03.020]   Well, optionally, the high end models are all the way around.
[00:35:03.020 --> 00:35:06.300]   Yeah. And actually, they call it now they're calling it the Infinities Play,
[00:35:06.300 --> 00:35:12.700]   which is pretty funny. I actually like it. I don't like the curvature. I don't see,
[00:35:12.700 --> 00:35:17.020]   there's nothing to, you know, that edge is wasted. It's not like they put stuff on there,
[00:35:17.020 --> 00:35:21.660]   but I never use it. I never use it. And you're sold on the utility of it.
[00:35:21.660 --> 00:35:26.940]   Yeah. I buy pretty much, I have to with my job, you know, ring a game studio.
[00:35:26.940 --> 00:35:32.540]   You do mobile games? We do. We do. We've looked really hard at doing Android games. I was really
[00:35:32.540 --> 00:35:36.940]   sad when they announced this phone because I was going to buy it. And I'm like, I'm running
[00:35:36.940 --> 00:35:43.660]   for Congress. I don't have to buy this phone. You can use it. Go. You do as a president as
[00:35:43.660 --> 00:35:49.500]   in using S3. Well, no, I think we'll go with the more secure. I think it's a gorgeous phone.
[00:35:49.500 --> 00:35:54.620]   I'm a little worried about the less the lower battery size in it. Like they didn't go very
[00:35:54.620 --> 00:35:58.940]   conservative with battery tech this way. This time, understand. I wonder why. Yeah.
[00:35:58.940 --> 00:36:05.660]   Yeah. I have to say the curved display, the Samsung Galaxy Edge is a more beautiful phone,
[00:36:05.660 --> 00:36:10.380]   but I think people don't understand that when you're actually using it, it picks up glare.
[00:36:10.380 --> 00:36:14.620]   And it's just very awkward. Like, oh, yeah, it looks pretty, but it's not practical.
[00:36:14.620 --> 00:36:16.860]   And if you have a case on your phone, you kind of destroy that anyway. I mean,
[00:36:16.860 --> 00:36:21.740]   the case, you know, the edge cover that. So what I was excited because they're making two models,
[00:36:21.740 --> 00:36:29.100]   the S8 is 5.8 inches screen size. And the S8 plus is 6.2 inches. But I was excited because
[00:36:29.100 --> 00:36:34.940]   they've gotten rid of the bezel. And I checked the measurements. The S8 plus, the bigger 6.2
[00:36:34.940 --> 00:36:39.820]   inch screen is the same physical size of the phone as an iPhone 7 plus, which is a 5 and a half
[00:36:39.820 --> 00:36:43.580]   inch screen because there's no, there's, you don't have all this wasted space.
[00:36:43.580 --> 00:36:50.620]   It is weirdly tall. So what algae did this with their new G6 too, they're doing these tall phones
[00:36:50.620 --> 00:36:56.540]   so that you can use one hand. If it's too wide, and I actually couldn't do the S, the Apple 7 plus
[00:36:56.540 --> 00:37:02.780]   with one hand, but there were these are narrower, taller phones. So I don't know. And they're getting
[00:37:02.780 --> 00:37:06.220]   rid of the fingerprint reader on the front. They're going to put that on the back right
[00:37:06.220 --> 00:37:10.300]   next to the camera so you can smudge the camera. The pixel has this, have it on the back. Yeah,
[00:37:10.300 --> 00:37:13.900]   the pixel is in the right spot. I like it. So I can just like Samsung's going to put it up by
[00:37:13.900 --> 00:37:20.140]   the camera. Oh yeah, that's not so good. And then, and then they'll have a capacitive button.
[00:37:20.140 --> 00:37:23.820]   Although there's an option, there's apparently something physical under the screen so you can
[00:37:23.820 --> 00:37:28.540]   press the screen really hard. That'd be a home button there. That's dopey. I'll turn that off
[00:37:28.540 --> 00:37:35.420]   right away. Apparently you can. And then one more thing that is a little controversial, they've added
[00:37:36.220 --> 00:37:40.940]   the iris scanning, which is very secure. That was in the note seven. I had that for about a week
[00:37:40.940 --> 00:37:45.420]   before I had the 10. But I liked it. It was a little slow. You had and you had a position just
[00:37:45.420 --> 00:37:49.260]   right, but it's more it's as accurate as a fingerprint reader because your irises are as
[00:37:49.260 --> 00:37:53.020]   unique as your fingerprint, maybe even more so. They're going to have the fingerprint.
[00:37:53.020 --> 00:37:57.980]   And then they're also going to have face recognition. And all the videos we've seen is like this. It's
[00:37:57.980 --> 00:38:06.140]   instant. Boom. Unfortunately, somebody at the at the show on Wednesday brought a picture of
[00:38:06.140 --> 00:38:09.900]   themselves or actually took a picture of themselves with their phone. This is very this is intrepid
[00:38:09.900 --> 00:38:16.380]   journalism. And then was able to unlock the essay with a picture of themselves on a phone. So it
[00:38:16.380 --> 00:38:20.860]   means it any even Samsung says it's not the most secure. It's not secure at all. I thought they
[00:38:20.860 --> 00:38:25.500]   were supposed to look for some movement like look for your eye. I left. So there's some apps that do
[00:38:25.500 --> 00:38:30.780]   this on the my banking app. USA a uses face recognition, but they say in the process,
[00:38:30.780 --> 00:38:33.340]   blink that now blink. You got to see. Yeah, I got to see the movement. Yeah.
[00:38:33.340 --> 00:38:37.500]   This is a Windows machine. This uses Windows Hello and Windows and it's
[00:38:37.500 --> 00:38:43.660]   if it's a Windows Hello face recognition capable machine, they don't just have a regular camera.
[00:38:43.660 --> 00:38:49.020]   They have a depth sensing camera like on the connect and that can tell if you're, you know,
[00:38:49.020 --> 00:38:53.100]   if you're a human, if you're in three dimensions, and they can also the way these face recognitions
[00:38:53.100 --> 00:38:57.260]   work, they measure like distance, inter pupillary distance and length of the nose, but they can
[00:38:57.260 --> 00:39:02.780]   also mention now measure the depth of the eyes, you know, how big your mouth is if your ears are
[00:39:02.780 --> 00:39:09.260]   in the back of your head, the front. And so that's more accurate and probably less easily spoofed,
[00:39:09.260 --> 00:39:14.300]   I would assume. But you still have to have a password to the backup. Just yeah, you should.
[00:39:14.300 --> 00:39:18.060]   Yeah, we have to. And Samsung says if you're going to use a Samsung pay,
[00:39:19.500 --> 00:39:26.700]   you should use fingerprint or iris to be extra sure. So my big question with it is touch widths.
[00:39:26.700 --> 00:39:31.500]   You know, this is kind of infamously the issue of Samsung phones. And what I found really
[00:39:31.500 --> 00:39:36.460]   frustrating is, you know, like Apple has stolen so many designs from, you know, Samsung, I want to
[00:39:36.460 --> 00:39:41.580]   see them do reachability, where you double tap and it moves down the screen on, you know, one of
[00:39:41.580 --> 00:39:45.180]   the bigger ones. Oh, I use it all the time. Yeah. I just live by. I turn that off because it
[00:39:45.180 --> 00:39:48.940]   confused me. Really? Oh my goodness. They didn't have people call me say, I don't know what happened.
[00:39:48.940 --> 00:39:56.060]   My screen slid down. How do I face that? Yeah. Apple does that all the time. They add features
[00:39:56.060 --> 00:40:02.380]   like that that people forget about or never use. You use that. Are you? Yeah. How about three
[00:40:02.380 --> 00:40:07.180]   most high pieces normal people? Yeah. It drives me crazy. Because you know, I want to on my iPhone,
[00:40:07.180 --> 00:40:12.940]   I want to press and hold the icon to erase it to get it to go jiggle jiggle jiggle. And it never
[00:40:12.940 --> 00:40:17.100]   jiggle jiggle jiggles. It always does 3D touch and pops and acts like you have to do it just right
[00:40:17.100 --> 00:40:22.700]   to get the jiggle jiggle jiggle. I hate that. Yeah. I like that. I'm starting to sell like
[00:40:22.700 --> 00:40:29.260]   Regis Philbin. I'm sorry. Yeah. I do like the 3D touch where you can use the cursor because I
[00:40:29.260 --> 00:40:36.460]   send like my iPhone 6 plus or 7 plus is like the that's what I do all my email. Right. So I think
[00:40:36.460 --> 00:40:41.260]   that's that. Really? You don't use a computer for email? I, you know, when you're running for
[00:40:41.260 --> 00:40:46.460]   office, you spend so much time out there going to churches and just different events. Like,
[00:40:46.460 --> 00:40:51.820]   it's really hard. Like I have a, you know, the standard MacBook, you know, like the 12 inch one
[00:40:51.820 --> 00:40:57.020]   they made. I bring it with me but I do most of my work on my iPhone these days. So it's just
[00:40:57.020 --> 00:41:03.180]   reality of it. So you you have to start your campaign years early. I do have a lot of work to do.
[00:41:03.180 --> 00:41:08.140]   And you know, even Barack Obama did not win his first time out of the gate. So I'm, you know,
[00:41:08.140 --> 00:41:13.580]   if I lose in 2018, I'm gonna be knocking on my opponent's door again 2020. I really promise that.
[00:41:13.580 --> 00:41:17.820]   You're gonna do you're not just that's great. Wow. I'm so impressed, Brianna.
[00:41:17.820 --> 00:41:24.220]   It's fine. People don't know this. Running for office is so much fun. You get to talk to people
[00:41:24.220 --> 00:41:28.860]   all day long. You hear their stories. You learn about what their hopes and their dreams are.
[00:41:28.860 --> 00:41:32.620]   You learn about their families. It's fun. And no one talks about that. That's the
[00:41:32.620 --> 00:41:40.460]   difference. So you actually like people. You say Mary friendly. I seem is the word. I don't.
[00:41:40.460 --> 00:41:45.020]   I don't really like people. I could never. I did. I served briefly. The city of
[00:41:45.020 --> 00:41:49.820]   Petaluma had a technology committee, which it was political. And I served briefly on that like
[00:41:49.820 --> 00:41:54.940]   a month or two before I went absolutely bonkers with the pace of government,
[00:41:54.940 --> 00:42:00.860]   which is snail like. And that's by the way, I understood that that's a good thing. You do not
[00:42:00.860 --> 00:42:05.420]   want an efficient fast government because then you have no time to stop them. Right.
[00:42:06.700 --> 00:42:11.180]   But it was frustrating for me. And I think if these Silicon Valley people end up running for
[00:42:11.180 --> 00:42:16.620]   office, I think frankly, President Trump is starting to get a little like, this is not what I
[00:42:16.620 --> 00:42:22.060]   thought it was. Right. Oh, that happened on like day two. Yeah. I think you get in there and you
[00:42:22.060 --> 00:42:27.420]   and somebody like Barack Obama was really well suited to it. He grew up in that environment.
[00:42:27.420 --> 00:42:32.620]   He liked that. You know, you could see the presidents who kind of like process and
[00:42:32.620 --> 00:42:37.500]   they don't mind sitting there for hours and talking. And then somebody like Trump who's been running
[00:42:37.500 --> 00:42:42.460]   a family business and his word is law gets in there. It's got to be frustrating where you can't
[00:42:42.460 --> 00:42:46.940]   just say, no, pass that bill. I think at least working for a public. I mean, Tillerson at least
[00:42:46.940 --> 00:42:51.340]   worked for a public corporation. So we understand even even. I mean, I'm not. I listen is struggling
[00:42:51.340 --> 00:42:56.220]   with it. Right. I understand that. But the idea of having a CEO of a private family company
[00:42:56.220 --> 00:43:01.980]   does not prepare you to run a government agency where you have constituents that actually have
[00:43:01.980 --> 00:43:06.380]   something to be said. Every president I know. I would even say I would even say specifically in
[00:43:06.380 --> 00:43:11.820]   the real estate industry, which does was in a very different way than almost any other industry.
[00:43:11.820 --> 00:43:18.700]   And treats its customers in a different way than many other industries is also very specific.
[00:43:18.700 --> 00:43:24.460]   If you're a real estate and you say, that's a 700 story building, when it's really a 52 story
[00:43:24.460 --> 00:43:30.540]   building, that's okay. It's acceptable. That's that's just called salesmanship. Right. And he's
[00:43:30.540 --> 00:43:34.700]   clearly a great salesman. But it's a little different when you're president of the United
[00:43:34.700 --> 00:43:39.420]   States. And you say, there were 80 million people in my inauguration. You can't it doesn't it doesn't,
[00:43:39.420 --> 00:43:45.020]   you can't say that you have to start kind of you're cuing the line a little bit closer to fact.
[00:43:45.020 --> 00:43:51.740]   And I think that we're starting to learn where the great stuff is getting away with it.
[00:43:51.740 --> 00:43:57.100]   Yeah. I mean, look, that is part of the job to a salesmanship. Let's not forget. I mean, you know,
[00:43:57.100 --> 00:44:00.540]   you're essentially selling an agenda to the Reagan and
[00:44:00.540 --> 00:44:02.860]   going to leave and Clinton were all great. Get a lead.
[00:44:02.860 --> 00:44:06.620]   Yeah. Right. I think I know.
[00:44:06.620 --> 00:44:11.340]   Go ahead, Brianna. I know I'm I think local politics is just a little bit different because I think
[00:44:11.340 --> 00:44:16.620]   you know, the presidency, that's the entire nation. What I'm finding is local politics is a lot more,
[00:44:16.620 --> 00:44:22.620]   you're talking to people that need very specific things allocated in the budget for their businesses
[00:44:22.620 --> 00:44:28.860]   to survive. I'll give you an example. There's a company out in district eight that's looking at
[00:44:28.860 --> 00:44:33.740]   vehicle to vehicle communications, right? Like, obviating crashes by laying vehicles like
[00:44:33.740 --> 00:44:40.460]   talk to each other so they don't, you know, you're getting information. That involves regulatory
[00:44:40.460 --> 00:44:46.940]   apparatus, like making it free for them to do that. So I think I do agree as an engineer. I think
[00:44:46.940 --> 00:44:53.100]   it's going to be frustrating in some ways. But I also think like, I think that this last election
[00:44:53.100 --> 00:44:57.740]   has really made a lot of people realize that people never thought they could run before,
[00:44:57.740 --> 00:45:04.060]   that maybe it's time to get involved there. And you know, I think every day about how I can't let
[00:45:04.060 --> 00:45:06.940]   this change me. I can't let this change. Yeah.
[00:45:06.940 --> 00:45:12.780]   And what I stand for the biggest, you know, tragedy wouldn't be losing a race. It would be letting
[00:45:12.780 --> 00:45:19.260]   this process change me. So if I go there for two years and I just can't do it and walk away
[00:45:19.260 --> 00:45:23.660]   with the clean conscience, I won't run again. You know, if Donald Trump is inspiring people
[00:45:23.660 --> 00:45:28.060]   like you and people all over the country to get involved in politics, then maybe he really is
[00:45:28.060 --> 00:45:33.260]   making America great. And that is that's a great part of America. You know, I'm a hippie. Yeah.
[00:45:33.260 --> 00:45:38.380]   And I remember the nicks and I remember the sixties. And you do too. I think I was on I'm on
[00:45:38.380 --> 00:45:44.620]   Nixon and Trump's enemies. Both. It literally is. But that's another story. I'm on Tim Cook's
[00:45:44.620 --> 00:45:51.980]   enemies list. Well, that's another story. But it's always the case that, you know, there's
[00:45:51.980 --> 00:45:57.900]   pendulum swings. Yeah. And when it swings one way, it activates the people on the other side
[00:45:57.900 --> 00:46:02.620]   to get participate. And if we see more participation and more diversity, as you say,
[00:46:02.620 --> 00:46:08.140]   Brianna, and I'm sure you told Frank kick my ass if I change into somebody else. I absolutely have
[00:46:08.140 --> 00:46:13.020]   no joking at all. That's something that a lot talks about. Yeah. Yeah. You want people around
[00:46:13.020 --> 00:46:18.940]   you who are going to hold you to a standard. Yeah. Absolutely. Yeah. Yeah. That's, you know,
[00:46:18.940 --> 00:46:23.020]   that's awesome. Well, I've always said that behind every member of Congress is a good man.
[00:46:23.020 --> 00:46:27.420]   And hopefully you'll actually have to use Twitter effectively. Hopefully, Brianna knows how to use
[00:46:27.420 --> 00:46:34.220]   Twitter responsibly. I do. I do. I think it's a little hard because I'm a kind of fiery feminist.
[00:46:34.220 --> 00:46:40.060]   And you got a little bit of trouble. We all know. Yes. Yes, I did. I did. You know, I was saying
[00:46:40.060 --> 00:46:45.180]   something as we can about asking people not to make fun of Christians. And I got in a lot of hot
[00:46:45.180 --> 00:46:50.860]   water from that from the progressive. So it's, it's very difficult to walk that balance. Yeah.
[00:46:50.860 --> 00:46:57.260]   I really like that. You do you find after gamergate that you are more careful about what you say
[00:46:57.340 --> 00:47:05.420]   in public and especially on Twitter. No, no. Well, I try to be very genuine. You know, I think it's,
[00:47:05.420 --> 00:47:11.340]   it's really hard for anyone to just be there on a self with the public. So I was very careful to
[00:47:11.340 --> 00:47:19.420]   not let gamergate change me and certainly matured me quite a bit. But I still say what I think and
[00:47:19.420 --> 00:47:24.300]   what I feel. And I think that's just very important. I think it's very brave of you because I think
[00:47:24.300 --> 00:47:30.220]   a lot of people who had been, you know, hit with that horrible,
[00:47:30.220 --> 00:47:37.980]   the two peration and attacks that you got would choose to hide, which who's not to be in the public
[00:47:37.980 --> 00:47:43.020]   eye would say that's it. In fact, I've been tempted to get out of the public eye. And you
[00:47:43.020 --> 00:47:47.340]   are going in exact opposite direction because of your convict of your convictions. I think that's
[00:47:47.340 --> 00:47:53.260]   awesome. Yeah, I could turn the camera to the 90 degrees right now. You could see a smashed window
[00:47:53.260 --> 00:47:59.660]   in my house where somebody drove through it and my window still because I can't hide my address.
[00:47:59.660 --> 00:48:05.900]   And yeah, and it's just, it's a kind of thing where some people shut down for me. It just made
[00:48:05.900 --> 00:48:10.780]   me completely fearless. You know, there's very little that scares me after gamer games. I am so
[00:48:10.780 --> 00:48:22.380]   impressed. Wow. Bravo. Agreed. All right, moving on. Actually, let's take a little break because
[00:48:22.380 --> 00:48:26.780]   there's there's there's more to talk about in every area of technology. I'm just going to
[00:48:26.780 --> 00:48:30.140]   I'll let you guys have the rundown. If there's something you feel like we should talk about,
[00:48:30.140 --> 00:48:34.220]   I'm going to let you you pick Twitter's retiring the egg.
[00:48:34.220 --> 00:48:43.500]   Big story, breaking news. Yeah. We're not going to solve the harassment issues,
[00:48:43.500 --> 00:48:48.860]   the abuse problems, but you'll be glad to know that the new anonymous icon on Twitter is no
[00:48:48.860 --> 00:48:55.100]   longer an egg. It's a egg shaped human. They put out a blog talking out there,
[00:48:55.100 --> 00:49:00.540]   inclusive design decisions behind that with their thoughts. No, what? They really did. So,
[00:49:00.540 --> 00:49:05.020]   look, go back to the page there. Like, look at the figure. They deliberately designed it so it
[00:49:05.020 --> 00:49:12.540]   doesn't look like a man or a woman. They put a lot of thought into that. So, I appreciate iconography
[00:49:12.540 --> 00:49:17.420]   and I appreciate anyone that puts a lot of thought into that iconography. But it's hard to not feel
[00:49:17.420 --> 00:49:27.900]   like Twitter is attacking the wrong problem. But the problem is so complicated for them to solve.
[00:49:27.900 --> 00:49:32.300]   And I'm not saying that they have done a great job at even attempting it because they've clearly
[00:49:32.300 --> 00:49:39.660]   been so much slower than all of their competitors. But I feel like until they have satisfied everyone,
[00:49:39.660 --> 00:49:45.580]   which may be never any change that they make, any product that they make is going to get that
[00:49:45.580 --> 00:49:52.220]   exact same reaction, like laughter, anger, making fun of them. And also, why haven't you fixed the
[00:49:52.220 --> 00:50:00.140]   bullying problem? I don't know if they can win. They have such core users that expect the product
[00:50:00.140 --> 00:50:05.820]   to stay the same and be working exactly the same way. That I feel like it's going to be hard for
[00:50:05.820 --> 00:50:10.860]   them to expand the product and change in any way to appeal to a wider audience, which is what
[00:50:10.860 --> 00:50:17.660]   they're trying to do while also piecing their core audience that doesn't want them to change
[00:50:17.660 --> 00:50:22.460]   anything. I've come around a little bit on Twitter. They seem to, and, Brandon, you'd be more of
[00:50:22.460 --> 00:50:27.580]   an expert on this than me, but they seem to have done a better job of suspending accounts.
[00:50:27.580 --> 00:50:35.740]   It used to take me sometimes a long time to get accounts suspended. They respond a lot faster than
[00:50:35.740 --> 00:50:43.740]   they used to. I feel like Twitter does not get the credit they deserve here. I've talked to them so
[00:50:43.740 --> 00:50:49.660]   often in back channel over the past few years. You have teams of people that are there working
[00:50:49.660 --> 00:50:55.180]   their butts off to solve this problem. And it's exactly, it's like you guys said, it doesn't
[00:50:55.180 --> 00:50:59.980]   matter what they do, they get critiqued on it. The iconographer, the graphic design person,
[00:50:59.980 --> 00:51:05.020]   designed that egg, had nothing to do with Twitter's harassment department. Their work is going to
[00:51:05.020 --> 00:51:10.940]   get blasted. Twitter is moving faster. They're making good decisions here. It's getting better.
[00:51:10.940 --> 00:51:15.900]   And I do think they're held to a double standard versus somewhere like Reddit,
[00:51:15.900 --> 00:51:20.460]   where if you're getting docs from Reddit, there's practically no oversight with that.
[00:51:20.460 --> 00:51:27.020]   I wish people would give them credit for the work that they're doing because they're really
[00:51:27.020 --> 00:51:28.460]   making strides.
[00:51:28.460 --> 00:51:34.620]   It's part of my work.
[00:51:34.620 --> 00:51:39.260]   Part of Twitter's problem for the longest time has been that they were to beholden to their core
[00:51:39.260 --> 00:51:43.820]   users and too scared to make any changes or to improve the product to make it more accessible
[00:51:43.820 --> 00:51:48.780]   to outsiders because people would freak out. And so they would say, okay, no, let's keep the
[00:51:48.780 --> 00:51:53.100]   product exactly as it is. Whereas if you look at other social networks like Facebook that are
[00:51:53.100 --> 00:51:57.900]   constantly rolling things out and just basically ignoring when users push back and complain.
[00:51:57.900 --> 00:52:01.340]   And that is how they've been able to attract a bigger audience along the way.
[00:52:01.340 --> 00:52:05.900]   I would actually argue that Reddit is in the same boat there with Twitter where they're afraid to
[00:52:05.900 --> 00:52:11.500]   change anything because their core users will really become angry. And that's why the product is
[00:52:11.500 --> 00:52:16.620]   kind of confusing and looks a little bit dated compared to some of their contemporaries.
[00:52:16.620 --> 00:52:20.460]   As part of my work was connect safely.org. I'm on their trust and safety council. And
[00:52:20.460 --> 00:52:24.620]   Anita Sarcazian is on a number of the people who've actually been victimized by some of this
[00:52:24.620 --> 00:52:29.100]   harassment. And they take it very seriously. I mean, they have a staff of people who actually
[00:52:29.100 --> 00:52:33.660]   work really hard to try to up the game when it comes to bullying and harassment. There's pushback.
[00:52:33.660 --> 00:52:37.100]   No question about it. There's pushback from the engineers and others in the marketing people in
[00:52:37.100 --> 00:52:41.340]   the company. But it's a real struggle. And what people don't realize is when companies are
[00:52:41.340 --> 00:52:46.300]   dealing with these issues is they're sometimes subtlety. Sometimes what appears to be a good move
[00:52:46.300 --> 00:52:49.980]   from the stamp on a protection brings up issues when it comes to free speech.
[00:52:49.980 --> 00:52:54.060]   And there's a lot of tension back and forth irrespective of their economic case.
[00:52:54.060 --> 00:52:59.820]   It's pretty clear if people were forced to use their real identities that wouldn't fix this entirely,
[00:52:59.820 --> 00:53:04.380]   but it would certainly mitigate a lot of the problems. I mean, Facebook doesn't have nearly
[00:53:04.380 --> 00:53:09.900]   the problems. Even Google+ would use the real name policy for a long time and no longer uses it.
[00:53:09.900 --> 00:53:12.060]   Still remains a little bit better. You disagree?
[00:53:12.060 --> 00:53:19.580]   I don't actually think that the real names makes that much of a difference. If you look at
[00:53:19.580 --> 00:53:24.940]   Facebook Live videos, we do a lot of them at Fortune. And the kinds of comments that people
[00:53:24.940 --> 00:53:31.740]   are willing to make with their real names and photos attached can be just as horrific and harassing
[00:53:31.740 --> 00:53:36.860]   as what you can find on Twitter. The problem is just that you can't make, if Facebook decides to
[00:53:36.860 --> 00:53:43.980]   delete your account or sort of take action against you, you can't really easily make a new profile
[00:53:43.980 --> 00:53:49.500]   like you can on Twitter. Yeah, I have to agree with you. And the academic research
[00:53:49.500 --> 00:53:55.020]   absolutely backs that up. We all think anonymity is a really big predictor of this. Science shows
[00:53:55.020 --> 00:54:02.860]   that it's not. I also think we tend to talk about it from a very American-centric viewpoint.
[00:54:02.860 --> 00:54:07.980]   If you're locking in people's identities, think about situations like in Egypt where
[00:54:07.980 --> 00:54:13.900]   Twitter played a really big part in the uprising against the government. There's a downside.
[00:54:13.900 --> 00:54:17.420]   Engineering is all about trade-offs. And every time we talk about one of these policies,
[00:54:17.420 --> 00:54:20.540]   there's a trade-off about it. So you got to think about it.
[00:54:20.540 --> 00:54:26.780]   So I've always been coming from, and I guess I'm wrong, from the point of view,
[00:54:26.780 --> 00:54:33.580]   that there is the free speech argument and the free speech wing of the free speech party,
[00:54:33.580 --> 00:54:38.220]   which Twitter has always claimed to be. It always struck me that 4chan Reddit and Twitter
[00:54:38.220 --> 00:54:43.980]   really became cesspools because of the anonymity there. And they're very kind of
[00:54:45.740 --> 00:54:51.180]   dogmatic support for free speech. But that's not reflected in the numbers.
[00:54:51.180 --> 00:54:59.180]   The science shows it's not. I honestly, I think more than that, the really big problem nowadays is
[00:54:59.180 --> 00:55:07.020]   bots. Twitter is overrun with bots frequently from Russia. We're seeing very deliberate social
[00:55:07.020 --> 00:55:12.780]   manipulation with this. They're live really great articles out there about how they do this on Reddit
[00:55:12.780 --> 00:55:19.900]   as well. But nowadays, you can write bots with these talking points, which are kind of simplistic,
[00:55:19.900 --> 00:55:25.340]   and you can just have them going and flood people's conversations and really make it seem like
[00:55:25.340 --> 00:55:29.340]   there's public pressure for something when there's not. So you think bots are a bigger problem than
[00:55:29.340 --> 00:55:35.180]   trolls? Yes, absolutely. And that's coming out now as part of this whole Russian investigation.
[00:55:35.180 --> 00:55:42.540]   They said the intelligence committee said 1,000 Russian bots making fake news during the campaign.
[00:55:42.540 --> 00:55:49.020]   So it's definitely, it's having a huge impact on the politics of this country right now.
[00:55:49.020 --> 00:55:53.340]   Well, this takes us actually to something we were talking about before the show. Dana Boyd's
[00:55:53.340 --> 00:55:58.940]   very interesting piece in back channel on Medium about fake news. And I think we could talk about
[00:55:58.940 --> 00:56:02.460]   this when we come back. How about that? That's my vote. We've got other stories we can do too.
[00:56:02.460 --> 00:56:07.580]   Our show today brought to you by one of my favorite companies of all time WordPress.
[00:56:08.380 --> 00:56:14.460]   Did you know that WordPress runs 27% of all the websites in the world are running on WordPress
[00:56:14.460 --> 00:56:19.980]   for years? That was my blogging platform. In fact, I've been setting up my blog once again on
[00:56:19.980 --> 00:56:23.020]   WordPress and having a great time doing it. I'm doing something differently. I always had a
[00:56:23.020 --> 00:56:27.740]   self-hosted WordPress. And I thought I'd try WordPress.com, which is their hosted version of
[00:56:27.740 --> 00:56:32.540]   WordPress. And there's some real advantages to that. For one thing, WordPress.com
[00:56:32.540 --> 00:56:37.900]   keeps your site up to date. It does all the updates. It does all the security patches. So
[00:56:37.900 --> 00:56:44.940]   you're always secure. They offer a huge selection of plugins and themes, all the tools you need.
[00:56:44.940 --> 00:56:50.700]   And it's a community at WordPress.com. So you're joining a global community, which drives traffic
[00:56:50.700 --> 00:56:56.140]   to your site just because you're a part of it. And if you're a complete novice, if you don't
[00:56:56.140 --> 00:57:00.940]   have any experience in building a website, WordPress can guide you through the process. It is as easy
[00:57:00.940 --> 00:57:06.140]   as pie. If hundreds of customizable themes, you can make it your own. They have built-in search
[00:57:06.140 --> 00:57:11.820]   engine optimization, social sharing. If you want to support the app platform, so your pages load
[00:57:11.820 --> 00:57:18.940]   super fast and mobile, it's just a checkbox. HTTPS, secure HTTP, it's built-in. Let's encrypt.
[00:57:18.940 --> 00:57:23.180]   It's built-in. They do everything, which I really like. They have a public-sized feature that
[00:57:23.180 --> 00:57:28.380]   automatically shares posts to social media networks. You can share previously published posts as well.
[00:57:28.380 --> 00:57:33.100]   So you get lots of nice social sharing features. Of course, your visitors have share buttons as
[00:57:33.100 --> 00:57:38.780]   well. And it's got great support 24/7. You're in great company, answers to your questions,
[00:57:38.780 --> 00:57:45.980]   to get you back to getting your site up and running so fast. I just love WordPress. I feel
[00:57:45.980 --> 00:57:49.820]   like I'm coming home when I come to WordPress.com. And no longer do I have to worry about
[00:57:49.820 --> 00:57:55.980]   keeping my plugins up to date. It's all done for me. It is so much fun. I'll be rolling out my new
[00:57:55.980 --> 00:58:00.780]   WordPress site very soon. I'll let you know all about it when I do. You can get started today.
[00:58:00.780 --> 00:58:04.540]   And believe me, I took advantage of this with 15% off any new plan purchase when you go to
[00:58:04.540 --> 00:58:09.660]   wordpress.com/twit. Create your website. Find the membership plan that's right for you and save
[00:58:09.660 --> 00:58:20.460]   15% right off the top at wordpress.com/twit. I've been with these guys forever. I know Matt
[00:58:20.460 --> 00:58:25.820]   Mullenweg. Well, I know the team well. It's just a great company and makes me so happy to welcome
[00:58:25.820 --> 00:58:31.660]   them back to the Twitch podcast network, wordpress.com. 27% of the internet.
[00:58:31.660 --> 00:58:33.820]   All of my sites.
[00:58:33.820 --> 00:58:35.100]   Isn't that amazing?
[00:58:35.100 --> 00:58:36.460]   That includes version.com.
[00:58:36.460 --> 00:58:41.980]   Okay. Even big publications. That's interesting. I don't know. Fortune is running on that.
[00:58:41.980 --> 00:58:42.940]   Well, I'll be down.
[00:58:42.940 --> 00:58:44.140]   Yeah. Re-code runs on it.
[00:58:44.140 --> 00:58:49.020]   Re-code does too. Yeah. Well, there you go. I like doing ads for companies people like.
[00:58:49.020 --> 00:58:53.580]   When I do that, trust ad next, though. You don't have to... No, I'm just kidding.
[00:58:55.500 --> 00:58:59.340]   One more thing about Twitter, then we'll get to Dana Boyne's article. They did now say
[00:58:59.340 --> 00:59:05.660]   that the @ is not going to be... The @ reply is not going to be counted in the 140 characters.
[00:59:05.660 --> 00:59:08.060]   Why are you laughing?
[00:59:08.060 --> 00:59:14.460]   People will freak out on this the same way they do with every Twitter product update.
[00:59:14.460 --> 00:59:16.700]   No, you can't make any changes, Twitter. You can't.
[00:59:16.700 --> 00:59:21.180]   But this was a big deal, especially when you had one of those... Remember the Twitter canoe?
[00:59:22.140 --> 00:59:26.220]   Did you see the super canoes that people were creating and
[00:59:26.220 --> 00:59:30.140]   like hundreds of @ replies and then just saying hi?
[00:59:30.140 --> 00:59:35.420]   No. Is Twitter going to do anything about that or is that going to be...
[00:59:35.420 --> 00:59:38.220]   I would hope that seems like a bug.
[00:59:38.220 --> 00:59:42.300]   What can they say? You can only add seven people.
[00:59:42.300 --> 00:59:42.780]   I don't know.
[00:59:42.780 --> 00:59:44.700]   That's hysterical. A super canoe.
[00:59:49.420 --> 00:59:55.580]   I'm confused because you couldn't really tell on mobile updates if it's a direct message
[00:59:55.580 --> 01:00:00.940]   or if someone's responding to you publicly. You really have to be looking closely.
[01:00:00.940 --> 01:00:04.300]   And I have Open DMs. I get a lot of spam sent there.
[01:00:04.300 --> 01:00:10.140]   And I couldn't tell if someone's trying to give me a news tip or if it's just some random teenager
[01:00:10.140 --> 01:00:11.820]   trying to mess with me.
[01:00:11.820 --> 01:00:16.620]   That's brave. Open DMs. But I guess you have to because that's how you get tips, right?
[01:00:17.580 --> 01:00:20.780]   Yeah. I'm very disorganized with my contact.
[01:00:20.780 --> 01:00:25.900]   So that's the easiest way for me to get in touch with people I'm trying to report on.
[01:00:25.900 --> 01:00:31.500]   So a canoe was when you'd have @ reply, out reply, out reply, you know, you have a lot of names.
[01:00:31.500 --> 01:00:36.780]   But now that they don't count against the 140 characters, there's no limit to how many names.
[01:00:36.780 --> 01:00:40.780]   So a super canoe could have hundreds of @... Oh wow.
[01:00:40.780 --> 01:00:46.300]   They have to cut it off at a certain point. But I saw some floating through my feed or
[01:00:46.780 --> 01:00:50.300]   gigantic. I was happy to see this.
[01:00:50.300 --> 01:00:51.660]   It's just the new way to spam.
[01:00:51.660 --> 01:00:57.500]   It is. But they also had the mute conversation feature, which they finally added that.
[01:00:57.500 --> 01:01:02.060]   So, you know, I was added to the super canoes is just click a button and it's gone.
[01:01:02.060 --> 01:01:08.140]   I'm happy to see them addressing the core usability issue with Twitter because it's just,
[01:01:08.140 --> 01:01:13.420]   it's impenetrable for normal people. And I just think this is another thing that,
[01:01:13.420 --> 01:01:18.140]   you know, it puts the reply to any tweet right underneath it. And I think it's a big step up.
[01:01:18.140 --> 01:01:24.460]   Yeah. That was one of the reasons that it was impenetrable is because with only 140 characters,
[01:01:24.460 --> 01:01:31.500]   you really had to make it super succinct. I mean, I'm not, I mean, I've been on Twitter since 2006
[01:01:31.500 --> 01:01:35.180]   and I still felt like sometimes I was having a stroke when I was reading Twitter. I would
[01:01:35.180 --> 01:01:39.020]   these words, it's word salad. I don't understand what I'm reading.
[01:01:39.020 --> 01:01:43.340]   And I've gotten in trouble trying to take something complicated and say it in 140 characters and
[01:01:43.340 --> 01:01:49.660]   actually lined up embarrassing myself. Your first mistake is trying to say something complicated.
[01:01:49.660 --> 01:01:56.860]   Yeah. I find it a great discipline though. And it is to take something while I write it long.
[01:01:56.860 --> 01:02:02.620]   And then I play with it. And I think there is a certain skill to making a coherent.
[01:02:02.620 --> 01:02:07.580]   And I always attempted to be coherent, like give context. I mean, I tried to make my responses
[01:02:08.460 --> 01:02:12.220]   like you could read them and understand them, not like you were having a stroke and what is this
[01:02:12.220 --> 01:02:18.060]   word salad. I think it works really well for Donald Trump because I think he thinks in those
[01:02:18.060 --> 01:02:23.340]   very short, fantastic ways, but some of us are a little more complicated than what we think.
[01:02:23.340 --> 01:02:23.980]   Bigly. Yeah.
[01:02:23.980 --> 01:02:30.860]   There's a natural talent for it that is for sure. If there was ever a person made for
[01:02:30.860 --> 01:02:35.420]   Twitter, it's it's the president. That's for sure. But actually, that's why that's why Twitter is
[01:02:35.420 --> 01:02:41.340]   wise to be rolling out aggressively rolling out features that make the product more usable for
[01:02:41.340 --> 01:02:45.900]   the everyday person. Because right now people want to be on Twitter more than ever to see what's
[01:02:45.900 --> 01:02:51.500]   going on and try to like be following the day to day news, which actually, you know, changes by
[01:02:51.500 --> 01:02:55.900]   the hour. So it makes sense. Hopefully, I don't know, I don't think this was reflected in their
[01:02:55.900 --> 01:03:01.980]   year end numbers, but hopefully next quarter, you know, it will lead to a boost in users or at
[01:03:01.980 --> 01:03:07.020]   least engagement for them. Yeah, every quarter they add one percent. I mean, it's a tiny growth in the
[01:03:07.020 --> 01:03:10.940]   stock market at some point is going to start punishing at some point. Last year is going to
[01:03:10.940 --> 01:03:17.580]   start punishing them for this, you know, very anemic growth. Yeah. I think Twitter moments. I've
[01:03:17.580 --> 01:03:24.700]   been really just like, I love Twitter moments because when I'm bored, I mean, I have the times
[01:03:24.700 --> 01:03:29.500]   on my phone. I have Washington Post, but you know, Twitter excels at giving those kind of
[01:03:29.500 --> 01:03:35.660]   live moments of very specific hashtags. I stopped clicking on it because it was so useless, but
[01:03:35.660 --> 01:03:39.420]   you're right. I've noticed they've actually been pretty good. Yeah.
[01:03:39.420 --> 01:03:46.700]   Yeah. Actually, I had coffee with someone from Twitter's PR team last week and that was one
[01:03:46.700 --> 01:03:52.780]   thing that they were like, I think you'd be surprised. Like moments, you know, people kind of talked
[01:03:52.780 --> 01:03:57.260]   about people kind of criticized the feature, but he's like, people are really, really using it.
[01:03:58.140 --> 01:04:04.060]   And they're seeing that in their numbers. So that's good. That's great. I don't use it as much, but
[01:04:04.060 --> 01:04:10.700]   clearly people are. Yeah. I'm going to start doing it more. It's got pictures of dogs and babies.
[01:04:10.700 --> 01:04:17.500]   They don't look maybe the dogs. How could you not love that? I mean, that's good stuff.
[01:04:17.500 --> 01:04:23.820]   Actually, you know why Twitter moments is going to succeed because there's no politics.
[01:04:25.100 --> 01:04:30.860]   It's like some, but it's a little, when I go to my Facebook feed, it's all positive.
[01:04:30.860 --> 01:04:36.620]   This is like, there's some happy stuff here. Yeah. We need, we need just kind of some, it's like,
[01:04:36.620 --> 01:04:41.740]   you know, readers digest lightweight kind of jokey fun stuff. I like that.
[01:04:41.740 --> 01:04:46.060]   All right, Dana, boy, let's talk a little bit about, oh, by the way, I wanted, I did want to show
[01:04:46.060 --> 01:04:52.060]   this. This is just in case for those of you who say Twitter, they don't change that that egg is
[01:04:52.060 --> 01:04:57.260]   only fairly recent. And I didn't know, I don't remember this in the earliest days at Twitter.
[01:04:57.260 --> 01:05:01.660]   That was the unknown. It was the guy with an umbrella and a briefcase.
[01:05:01.660 --> 01:05:07.020]   That's very ominous. That looks like a killer from a horror movie.
[01:05:07.020 --> 01:05:13.660]   I know it's a Freddy Krueger coming for you. That was back when it was TWTTR though. That,
[01:05:13.660 --> 01:05:19.420]   I think that's, then it was the, it was the emoticon, the zero underscore zero emoticon.
[01:05:20.060 --> 01:05:23.100]   Then it was a bird. I don't remember it being the bird. It was the bird for a year.
[01:05:23.100 --> 01:05:28.140]   Then the egg started in 2010 and there was a new Svelte egg, which was,
[01:05:28.140 --> 01:05:33.820]   rolls out in 2014. Well, that was a little thinner too. That was the last way.
[01:05:33.820 --> 01:05:39.100]   And last way. Anyway, Dana Boyd, let's talk about her article. She's saying the fake news problem is
[01:05:39.100 --> 01:05:49.260]   more nuanced and complicated than people recognize. We should first mention who Dana Boyd is.
[01:05:50.140 --> 01:05:57.660]   She's at Microsoft Research for years though. She was the queen of social media scholarship
[01:05:57.660 --> 01:06:03.980]   studying young people. And how young people used Snapchat and-
[01:06:03.980 --> 01:06:07.660]   MySpace is where she started that. MySpace.
[01:06:07.660 --> 01:06:10.300]   Yeah, sure. We're working on researching my space.
[01:06:10.300 --> 01:06:16.220]   She says, Google, this is an article she just published in a back journal. Google and Facebook
[01:06:16.220 --> 01:06:20.300]   can't just make fake news disappear. It's too big and messy to solve with algorithms
[01:06:20.300 --> 01:06:25.020]   or editors because this is the most important part. The problem is us.
[01:06:25.020 --> 01:06:32.380]   And by the way, it goes way back. I mean, the term fake news entered our vocabulary or sometime this
[01:06:32.380 --> 01:06:37.500]   fall, but we've had urban myths. We've had urban legends. We've had, you remember this story about
[01:06:37.500 --> 01:06:42.140]   how the post office was going to charge five cents per email that was circulated for a year.
[01:06:42.140 --> 01:06:43.980]   The Bill Gates was going to give you money.
[01:06:43.980 --> 01:06:48.700]   Right. And then Mark Zuckerberg wanted me to pay him six bucks a year for a private account.
[01:06:48.700 --> 01:06:52.700]   So long before the word fake news came out, I've been writing about these urban myths.
[01:06:52.700 --> 01:07:00.140]   Some of the times they make up Congress people, this email scam, the five cent email,
[01:07:00.140 --> 01:07:05.260]   there was a Congress person who had to write to, he didn't exist. So there's nothing new about these
[01:07:05.260 --> 01:07:07.180]   fake news- There's a little difference.
[01:07:07.180 --> 01:07:08.700]   Oh, there's no, there's changes, absolutely.
[01:07:08.700 --> 01:07:14.460]   But and also the people who created those fake news stories did it for the walls, not for money
[01:07:14.460 --> 01:07:16.700]   or for political games. Exactly.
[01:07:16.700 --> 01:07:17.900]   They were just messing with you.
[01:07:17.900 --> 01:07:19.580]   Right. But the difference also
[01:07:19.580 --> 01:07:24.300]   would fall for it and spread it. And that's what hasn't changed.
[01:07:24.300 --> 01:07:25.660]   Yeah, that hasn't changed, right?
[01:07:25.660 --> 01:07:26.060]   Exactly.
[01:07:26.060 --> 01:07:31.980]   And those stories are easily debunked by Snopes or any kind of fact-checking website.
[01:07:31.980 --> 01:07:37.260]   But what she seems to be talking about is ones where they just really twist the context around
[01:07:37.260 --> 01:07:43.260]   or kind of change the framing of the story in a way that there's at least a shred of something
[01:07:43.260 --> 01:07:48.780]   true in there. So it can't be completely debunked, but it's just the interpretation of it.
[01:07:48.780 --> 01:07:53.660]   And that's what will be really hard for editors or algorithms to police.
[01:07:53.660 --> 01:07:54.540]   Yeah. Yeah.
[01:07:54.540 --> 01:07:55.020]   Yeah.
[01:07:55.020 --> 01:07:55.420]   Yeah. Actually-
[01:07:55.420 --> 01:08:00.460]   There's a there's a there's a tendency, I'm noticing the tech industry, that male engineers
[01:08:00.460 --> 01:08:07.020]   tend to really believe in technical solutions to social problems. And a lot of these are
[01:08:07.020 --> 01:08:12.300]   human problems. They can only be solved through curation. But I think anyone is talking about
[01:08:12.300 --> 01:08:18.140]   the fake news subject and they're not talking about themselves. I think they're really going
[01:08:18.140 --> 01:08:24.140]   in the wrong direction. I am vulnerable to this, right? Like a story comes across my feet and it
[01:08:24.140 --> 01:08:30.940]   has some sexism scandal. Like, you know, I want to click on it, right? I want to believe it.
[01:08:30.940 --> 01:08:38.540]   And we have to take responsibility in ourselves to kind of take a step back. So what I've tried to
[01:08:38.540 --> 01:08:44.060]   do is, especially because running for office, I talk to conservatives every single day.
[01:08:44.060 --> 01:08:51.660]   And I do make it a point to read reputable conservative news sources now. And I will not
[01:08:51.660 --> 01:08:57.340]   click on links from certain publications like raw story, just because it's maybe sensational,
[01:08:57.340 --> 01:09:04.060]   but it's not quality journalism. So I think that all of us have to realize that social media
[01:09:04.060 --> 01:09:12.300]   really exacerbates the most instinctual parts of our personality. It really taps into that. And
[01:09:12.300 --> 01:09:17.900]   we're really getting into this world now, where people are not subjected to viewpoints on the
[01:09:17.900 --> 01:09:21.740]   other side and is not healthy for me. It's not healthy for anyone.
[01:09:21.740 --> 01:09:25.820]   But I think this notion of sharing, I mean, one of the things that I've been harping on is that
[01:09:25.820 --> 01:09:30.620]   you don't share a story until you vet a story. It doesn't mean you have to know for absolute
[01:09:30.620 --> 01:09:34.860]   certain that there's no inaccuracies in the story. But if I'm going to even like something,
[01:09:34.860 --> 01:09:39.740]   I want to know that there's some credibility behind it. And you're absolutely right that it's
[01:09:39.740 --> 01:09:45.420]   much more subtle than pure fakeness because people tend to get opinion and fact mixed up,
[01:09:45.420 --> 01:09:50.460]   or they tend to have some fact and some fiction. So it's harder to kind of say, and that's one of
[01:09:50.460 --> 01:09:54.860]   the things that Facebook is struggling with and why what they're calling it now is disputed versus
[01:09:54.860 --> 01:10:01.420]   fake because it's hard sometimes to know that this is completely fake versus something that
[01:10:01.420 --> 01:10:05.980]   anything is disputed. If you say something I disagree with factual or not, I might
[01:10:05.980 --> 01:10:11.180]   dispute it. I can I can watch what it is about as Nambi Pambia description of it is like,
[01:10:11.180 --> 01:10:15.580]   it's fine. I can watch MSNBC and Fox News and it got less than that. But you know,
[01:10:15.580 --> 01:10:20.700]   let them let them all pine all they want. But when they start saying things that are factually
[01:10:20.700 --> 01:10:25.500]   this is the problem. And this is what Boyd says is that, you know, that no, you can't even define
[01:10:25.500 --> 01:10:31.740]   fake news, let alone. She also coined the terms, I think she's coined it solutionism to describe
[01:10:31.740 --> 01:10:35.500]   what you were just talking about Brianna, which is that and I don't think it's just men engineers.
[01:10:35.500 --> 01:10:39.980]   I'm not sure why you say men engineers to women engineers not do this. Most technologists think
[01:10:39.980 --> 01:10:43.820]   there's a technological solution to everything, right? Is it mostly men?
[01:10:44.620 --> 01:10:52.940]   I in my experience of talking to Facebook and Twitter and other companies, it is my tendency.
[01:10:52.940 --> 01:10:59.660]   I've seen that male engineers generally tend to believe in technological fixes. I think generally
[01:10:59.660 --> 01:11:04.220]   speaking, the women engineers have met believe more in curation. You know what this reminds me of
[01:11:04.220 --> 01:11:08.540]   is men are from Mars, women are from Venus because one of his tenants, and I only know this because
[01:11:08.540 --> 01:11:14.540]   I interviewed him 38 years ago, whenever, was that if you if you sit down and have a conversation
[01:11:14.540 --> 01:11:19.260]   about a problem in your life with a guy, the guy will tend to fix it. So what you need to do is
[01:11:19.260 --> 01:11:25.100]   this, this, this, and this and a woman will listen and empathize. So maybe this is just an example of
[01:11:25.100 --> 01:11:28.380]   that. My wife and I used to fight whenever the kids would cry, I'd show up with a band-aid.
[01:11:28.380 --> 01:11:32.540]   She'd show up with a couple of arms with a hug. So it's funny, you know, I mentioned earlier that
[01:11:32.540 --> 01:11:37.020]   I'm working on this parent and teacher's guide to media literacy. And on Wednesday, I'm going to
[01:11:37.020 --> 01:11:41.420]   be interviewing Mark Brackett and Robin, I can't remember the last name who run these Yale Center
[01:11:41.420 --> 01:11:45.980]   for Emotional Intelligence. And this was a suggestion of a friend of mine said, you need to think about
[01:11:45.980 --> 01:11:51.020]   emotional intelligence and social emotional learning as part of the battle against fake news,
[01:11:51.020 --> 01:11:54.220]   because why is this successful? It's successful because it's, it's, it's,
[01:11:54.220 --> 01:11:58.540]   stipulate some kind of an emotional response. So is it some sort of introspective understanding
[01:11:58.540 --> 01:12:03.580]   of yourself? Of yourself and what motivates people to react? And it's not whether a story is true or
[01:12:03.580 --> 01:12:09.020]   not. It's how a story affects you. My initial propagandists to some degree are- But my initial
[01:12:09.020 --> 01:12:13.500]   reaction is Mr. Fix, it was to think, oh, it's all about media literacy. And then it really went
[01:12:13.500 --> 01:12:17.660]   off in my head. It's also about emotional intelligence. How we responded? If you look at
[01:12:17.660 --> 01:12:22.620]   the success of any demagogue, and I won't mention names, but we know one, one particular one,
[01:12:22.620 --> 01:12:27.340]   what they're good at is getting people riled up. And, and whether they're using truth to rile them
[01:12:27.340 --> 01:12:31.980]   up. And sometimes that works or mixing truth and fiction. It's all about getting that emotional
[01:12:31.980 --> 01:12:37.340]   response. So we have to think that through. I really, it falls into epistemic closure,
[01:12:37.340 --> 01:12:42.460]   what's a psychological phenomenon where you have something, it feeds into your belief system and
[01:12:42.460 --> 01:12:48.780]   confirms it. There, we are all susceptible to that. But I think it's really worth saying. If I
[01:12:48.780 --> 01:12:55.660]   go and make a tweet tonight, and I tweet a really thoughtful New York Times article on like budget
[01:12:55.660 --> 01:13:02.780]   negotiations, that's not going to get as much feedback as if I talk about some, you know, sexist
[01:13:02.780 --> 01:13:09.660]   scandal in the, in the technology industry. And it's just like the very model of social media
[01:13:09.660 --> 01:13:14.540]   really rewards us going to what my friend, Georgia Dow calls the loudest argument.
[01:13:14.540 --> 01:13:21.980]   The human mind is attracted to the extreme of any argument. You know, it's why we see movies like
[01:13:21.980 --> 01:13:29.180]   going more violent or more sexy or more explosions. We always want to go further. And I think social
[01:13:29.180 --> 01:13:33.100]   media is just amplifying some of the worst tendencies in human behavior.
[01:13:33.100 --> 01:13:41.660]   So did I read, I just kind of skimmed because I was short on time, but it sounds like Dana has a
[01:13:41.660 --> 01:13:50.220]   very depressing conclusion, which is that it can't be, it can't be fixed. Did I miss something?
[01:13:50.220 --> 01:13:51.980]   No, I think that's exactly. Yeah.
[01:13:51.980 --> 01:13:58.460]   She says the puzzles made visible through fake news are hard. They are socially and culturally
[01:13:58.460 --> 01:14:03.260]   hard. They force us to contend with how people construct knowledge and ideas, communicate with
[01:14:03.260 --> 01:14:08.540]   others and construct a society. They're also deeply messy, revealing divisions and fractures
[01:14:08.540 --> 01:14:13.740]   and beliefs and attitudes. And that means they're not technically easy to build or implement. If we
[01:14:13.740 --> 01:14:19.660]   want technical solutions to complex socio technical issues, we can't simply throw it over the wall
[01:14:19.660 --> 01:14:24.780]   and tell companies to fix the broken parts of society that they made visible and help magnify.
[01:14:24.780 --> 01:14:29.500]   I really like that. It's not that these companies invented fake news. They just made it visible
[01:14:29.500 --> 01:14:34.300]   and help magnify it. We need to work together and build coalitions of groups who do not share
[01:14:34.300 --> 01:14:40.540]   the same political and social ideals to address the issues we can all agree are broken. I don't
[01:14:40.540 --> 01:14:45.980]   know if we have any much agreement these days anymore and what's broken. Otherwise, all we're
[01:14:45.980 --> 01:14:50.060]   going to do is try to wage a cultural war with companies as the intermediary and referee.
[01:14:50.060 --> 01:14:52.940]   And that sounds like a dreadful idea. I completely agree with her. I mean,
[01:14:52.940 --> 01:14:56.860]   she articulated something I've thought for a long time but wasn't able to articulate as clearly
[01:14:56.860 --> 01:15:01.340]   as well. So I was very grateful for this article. I think that's exactly right. But you're right,
[01:15:01.340 --> 01:15:10.380]   Aaron, it doesn't solve it, does it? No, no, I mean, yeah, it makes me think back to what I feel like
[01:15:10.380 --> 01:15:17.340]   maybe was at the heart of why Facebook was so reticent to take responsibility for the fake news
[01:15:17.340 --> 01:15:22.540]   problem, which was the accusations that they were suppressing conservative news outlets.
[01:15:22.540 --> 01:15:28.700]   And they had that, I guess, coalition of conservative voices that came and basically complained.
[01:15:28.700 --> 01:15:33.980]   And then, as Zuckerberg said, don't worry, we're going to make it better. But I sort of wish that
[01:15:33.980 --> 01:15:39.340]   that had happened with both sides present or at least people from kind of all the stakeholders,
[01:15:39.340 --> 01:15:45.820]   because maybe that would have led to Facebook taking more responsibility for this earlier and
[01:15:45.820 --> 01:15:51.420]   working on the problem before the election. Let me throw a theory at you and see what you guys
[01:15:51.420 --> 01:15:58.380]   think of this. Until recently, media was controlled by a small group of people.
[01:15:58.380 --> 01:16:05.820]   And you and I come to come from that good old days. Three days. And there was kind of a lid
[01:16:05.820 --> 01:16:11.420]   placed on the power of media. We've seen it. And I think some of this is in reaction.
[01:16:11.420 --> 01:16:16.540]   Believe it or not, to World War II and Nazism, where media was really used effectively
[01:16:17.580 --> 01:16:23.340]   to manipulate a large audience and to really have horrific effects. And I think that the media
[01:16:23.340 --> 01:16:29.100]   people who grew up in that era, the Edward R. Murrows of the world, really understood that the
[01:16:29.100 --> 01:16:36.140]   dangerous power that particularly television had and kept a lid on it. They were very careful
[01:16:36.140 --> 01:16:41.500]   about it. Then what happened when we got into the new internet era was we all got access to
[01:16:41.500 --> 01:16:47.020]   media. We got access to Twitter and to Facebook and to YouTube and everybody was creating media
[01:16:47.020 --> 01:16:51.340]   without any of this knowledge or understanding of the risks that media brings.
[01:16:51.340 --> 01:16:55.580]   And so what we've really created in Facebook and Twitter, particularly YouTube somewhat,
[01:16:55.580 --> 01:16:57.820]   is a megaphone for emotional,
[01:16:57.820 --> 01:17:07.820]   anger and feelings and strife. And these have become really well-tuned megaphones for our feelings.
[01:17:07.820 --> 01:17:14.540]   And as a result, I mean, yeah, sure, there's a lot of intellectual and, but nobody reads that crap.
[01:17:14.540 --> 01:17:17.740]   It's all about, as you pointed out, Brianna, the stuff that gets you,
[01:17:17.740 --> 01:17:24.860]   go, go. And so we've in effect. And I think this is the, what happened with the internet,
[01:17:24.860 --> 01:17:28.540]   sad to say. I was really excited about the internet at first because I thought this is going
[01:17:28.540 --> 01:17:33.180]   to give everybody a voice. It's the ultimate democratizing medium. But what I forgot was
[01:17:33.180 --> 01:17:38.940]   that the kind of voice it gave people ultimately could be very destructive because it's so emotional.
[01:17:38.940 --> 01:17:43.580]   You know, it's interesting. As you know, I work with CBS News and I'm very proud to be associated
[01:17:43.580 --> 01:17:49.580]   with this company, which dates back at one world. But you know, it's when Walt's not anymore.
[01:17:49.580 --> 01:17:55.820]   Well, yes and no. I mean, I, there is a very, very strong premium. Shrews is true, you know,
[01:17:55.820 --> 01:18:00.380]   unfortunate in all the media companies, a very strong premium on accuracy. I mean,
[01:18:00.380 --> 01:18:05.980]   you'll be fired for for for knowingly lying or reckless disregard for the truth and an error,
[01:18:05.980 --> 01:18:10.860]   a mistake is extremely embarrassing. And if you make too many of those, you get fired from that as
[01:18:10.860 --> 01:18:14.940]   well. And so there is a culture of trying to be accurate, I think, in mainstream.
[01:18:14.940 --> 01:18:19.340]   And it's being buried. It's being buried. And it's also being ridiculed. And it's being denied.
[01:18:19.340 --> 01:18:24.380]   I mean, when when Trump goes around calling us and I put all of us, I do want to say one thing.
[01:18:24.380 --> 01:18:28.780]   It's a mistake to blame Trump for this. Maybe this is articulating it.
[01:18:28.780 --> 01:18:33.020]   This is, I think this is the consequence, perhaps, at least short term right now.
[01:18:33.020 --> 01:18:37.900]   But I don't want to blame him for this. He is the beneficiary of something that has been brewing
[01:18:37.900 --> 01:18:43.260]   for a long time. And it won't just be Donald Trump. This is going to be all over everywhere.
[01:18:43.260 --> 01:18:48.300]   It's game or gate. It's all the harassment that happens on these sites. It's the bullying. It's
[01:18:48.300 --> 01:18:54.140]   the live streaming video of people being tortured on Facebook. That's what we're getting. And I don't
[01:18:54.140 --> 01:18:59.740]   think you could say it's the Republicans are Donald Trump. It is the society we have created
[01:18:59.740 --> 01:19:05.500]   with our technology. What I am saying is that Trump didn't mean the entire profession of journalism.
[01:19:05.500 --> 01:19:09.740]   Journalism's dead. Well, I don't know. I'm going to keep practicing it a long time.
[01:19:09.740 --> 01:19:13.100]   Well, I need to. But don't you see that we're in the elephant's graveyard?
[01:19:13.100 --> 01:19:16.300]   Go ahead. I'm sorry. Brianna, go ahead.
[01:19:16.300 --> 01:19:22.220]   No, no, no. I was just going to say, I do think that the left falls into this. And I think that,
[01:19:22.220 --> 01:19:27.820]   you know, there are some extreme right wing outlets like Breitbart that don't take accuracy very
[01:19:27.820 --> 01:19:32.540]   seriously. I've been the subject of plenty of bad articles by these sites. And, you know,
[01:19:32.540 --> 01:19:36.060]   it's easy to pick on that. But the left absolutely has this problem.
[01:19:36.060 --> 01:19:40.940]   I can tell you as an absolute fact, being a progressive and running for office,
[01:19:40.940 --> 01:19:46.460]   anything I say that is this much moderate or gives a little bit of credence to the other side,
[01:19:46.460 --> 01:19:52.940]   I get attacked about that. And it is an entire society that's really pushing us to the extremes.
[01:19:52.940 --> 01:19:59.420]   I do have one very concrete suggestion that I think would make this better. And what I would
[01:19:59.420 --> 01:20:05.900]   like to see Facebook and Twitter and other social networks do is to rate the quality
[01:20:05.900 --> 01:20:11.020]   of certain sites and stories when they come out. Generally speaking, if something comes from the
[01:20:11.020 --> 01:20:16.380]   Wall Street Journal, I may not like their economic conclusions, but it's going to be well researched.
[01:20:16.380 --> 01:20:23.260]   And I would like to see that story come with a ribbon or some sort of marker that indicates
[01:20:23.260 --> 01:20:30.460]   his quality content. So I would like to see information from Wall Street Journal, New York Times,
[01:20:30.460 --> 01:20:37.900]   LA Times, those kinds of quality news sources. I'd like to see them elevated in social media.
[01:20:37.900 --> 01:20:43.340]   Yeah, I would like to see on the left and the right some of these sites that kind of play to
[01:20:43.340 --> 01:20:49.500]   our internal biases and epistemic closure. I would like to see them not get that. So it just kind of
[01:20:49.500 --> 01:20:54.220]   gives people a base word. The thing that I fear though is that we at this point have gotten so
[01:20:54.220 --> 01:20:58.780]   polarized that we aren't even hearing each other. I believe it. And so the people who are reading
[01:20:58.780 --> 01:21:04.220]   the Washington Post and the New York Times are one group of people. But that's one group and
[01:21:04.220 --> 01:21:07.980]   they're not hearing the other group and the other group is not hearing them. And I don't think there
[01:21:07.980 --> 01:21:11.980]   is a conversation going on at all anymore. It's just a bunch of people shouting. And I think that's
[01:21:11.980 --> 01:21:15.180]   one of the problems with the internet. You know, back in the days, and I don't want to go back to
[01:21:15.180 --> 01:21:19.020]   the go-to-all days. But back in the days when we had three television networks, in every city had
[01:21:19.020 --> 01:21:26.140]   two newspapers, we had a very set number of people giving us facts. And we should be in the
[01:21:26.140 --> 01:21:29.580]   effects. Yeah, and there wasn't some in respect to battle days. It was William Randolph Hearst who
[01:21:29.580 --> 01:21:35.100]   created a war against Spain out of thin air. That's right. So it wasn't always positive.
[01:21:35.100 --> 01:21:38.620]   And you're absolutely right. And newspapers where politically biased people would take the
[01:21:38.620 --> 01:21:42.460]   democratic paper, the republican paper. So it's not about- Yeah, and then there was that polarisation.
[01:21:42.460 --> 01:21:47.660]   But we pretty much most of the time agreed on the facts, most of the time, not all the time.
[01:21:47.660 --> 01:21:51.660]   Now you're absolutely right. The New York Times breaks the story and I read it and I say, wow,
[01:21:51.660 --> 01:21:55.980]   this is amazing. This is important stuff. Everybody else? And the other people are either ignoring it
[01:21:55.980 --> 01:22:01.580]   or considering it's fake. Right, it's fake news. It's fake news. I think that whoever said it,
[01:22:01.580 --> 01:22:06.700]   we've got a lot of grief. But we aren't a post-fact era. Right, exactly. In many respects.
[01:22:06.700 --> 01:22:13.580]   Aaron, I'm sorry. I really like your suggestion for adding a marker to stories that are
[01:22:13.580 --> 01:22:19.660]   trusted and of quality. And the reason I think that Facebook hasn't done that yet is because
[01:22:19.660 --> 01:22:25.260]   there's this fear. It's kind of like the net neutrality argument. There's this fear that
[01:22:25.260 --> 01:22:32.460]   there's no room for a company like Business Insider or an Engadget or any sort of new blog
[01:22:32.460 --> 01:22:41.980]   to come up and become trusted because the journal and the New York Times and all of the old
[01:22:41.980 --> 01:22:46.860]   institutions will just continue to hold on to their power. And Facebook wants to be seen as neutral.
[01:22:46.860 --> 01:22:51.660]   I'm really curious to see if that will change. But I think there would be a lot of pushback when
[01:22:51.660 --> 01:22:57.180]   that starts. Yeah, I agree. It's a very difficult problem to solve. And you have to say this all
[01:22:57.180 --> 01:23:02.060]   the time. Engineering is all about compromises. If you do one thing, it's going to have trade-offs
[01:23:02.060 --> 01:23:05.580]   and our system now is clearly not working. Something's got to change.
[01:23:05.580 --> 01:23:09.500]   I don't know what the answer is though. I mean, I really don't. I feel like this is-
[01:23:09.500 --> 01:23:14.460]   Well, you're an example of somebody who created his own successful media company and that
[01:23:14.460 --> 01:23:18.220]   wouldn't have been possible 20 years ago. Right? Exactly. That's why I celebrate this.
[01:23:18.220 --> 01:23:22.860]   And I would hate to see you not get the badge because you don't have 40 years of-
[01:23:22.860 --> 01:23:27.980]   Yeah, I benefit it greatly from the democratization of media. I couldn't work in Main Street
[01:23:27.980 --> 01:23:33.740]   Mainie anymore. So I created my own thing. But I still fear that the side effects that we created
[01:23:33.740 --> 01:23:38.780]   are terrifying. Yeah. And I don't know what the answer is to it. But that we're going to-
[01:23:38.780 --> 01:23:45.100]   on that note, pause. I do have- and by the way, this is an example of how the internet is so great.
[01:23:45.100 --> 01:23:50.380]   Gollum in the chat room did an interesting observation. We were showing the anonymous
[01:23:50.380 --> 01:23:55.100]   icons of Twitter, right? And this is in the early days. And we couldn't really figure out this
[01:23:55.100 --> 01:23:58.780]   guy carrying an umbrella in a suitcase. What is that? Gollum figured it out.
[01:23:58.780 --> 01:24:06.620]   It's Michael Douglas from Falling Down carrying a shotgun. Is that not the same?
[01:24:06.620 --> 01:24:13.100]   It's a little changed, but not much. Wow. The internet isn't an amazing-
[01:24:13.100 --> 01:24:15.100]   Oh my. See, this is why we-
[01:24:15.100 --> 01:24:21.020]   I doubt the Twitter guys even knew what they were up to what somebody in there did. Somebody was
[01:24:21.020 --> 01:24:23.900]   subversive. Some designer said, "I have an idea."
[01:24:24.780 --> 01:24:32.060]   Wow. Thank you, Gollum, for catching that. We had a great week this week on Twitter.
[01:24:32.060 --> 01:24:36.380]   Lots of fun. I wasn't here, but I understand good things happened. That's why we've made this
[01:24:36.380 --> 01:24:42.940]   small movie to brief me when I missed a previously on Twitter. The company is Digivina. I don't
[01:24:42.940 --> 01:24:49.900]   know if you remember this. Make your own vinyl record by using all the old plastic bottles in your house.
[01:24:49.900 --> 01:24:55.580]   This idea. You could be the first podcast on vinyl.
[01:24:55.580 --> 01:25:02.220]   Security now. Tavis Ormonde, our favorite security researcher,
[01:25:02.220 --> 01:25:10.460]   tweeted shortly after tawling himself off, "I had an epiphany in the shower and realized how to get
[01:25:10.460 --> 01:25:18.380]   code execution in last pass. This is apparently very sophisticated, but also that's going to
[01:25:18.380 --> 01:25:24.700]   require some re-engineering." The new screensabers. I'm about to hop on Galactic Attack. It's a
[01:25:24.700 --> 01:25:31.420]   converted Kong roller coaster that brings a little Samsung Gear VR into the action mixed reality
[01:25:31.420 --> 01:25:40.060]   experience. Yep, we're in space and we're about to die. Wow, this is really weird.
[01:25:41.100 --> 01:25:49.340]   To it. Technology for your eyes and ear holes. Digivina is an April Fool's gag. I can't leave
[01:25:49.340 --> 01:25:56.220]   you hanging like this. There's no such thing. It was believable, wasn't it? Yeah. You take your
[01:25:56.220 --> 01:26:00.780]   old bottles and turn them into a... I love the idea of a vinyl podcast on vinyl. You just send
[01:26:00.780 --> 01:26:05.260]   a new one out every day. I'm going to do that. I'm finding a way to do that. Jason Howell,
[01:26:05.260 --> 01:26:10.620]   what's ahead this week? Here's a look at just a few of the stories that we'll be watching in the
[01:26:10.620 --> 01:26:16.780]   week ahead. On Monday, April 3rd, the US Citizenship and Immigration Services will suspend expedited
[01:26:16.780 --> 01:26:23.660]   processing of H1B petitions for up to six months, which could have a dramatic effect on the hiring
[01:26:23.660 --> 01:26:28.860]   practices of technology companies throughout the year. On Wednesday, April 5th, Huawei is launching
[01:26:28.860 --> 01:26:34.700]   its worst kept secret. The Honor 8 Pro, Russian Huawei site, inadvertently spilled the beans on the
[01:26:34.700 --> 01:26:40.380]   5.7-inch premium spec Android device that we still don't know price or whether it'll be released in
[01:26:40.380 --> 01:26:46.380]   the US like the Honor 8 was last year, which by the way, I loved in the $400 range. And on Thursday,
[01:26:46.380 --> 01:26:52.220]   April 6th, the UK gets its long overdue release of the Google Home Assistant, as well as the Google
[01:26:52.220 --> 01:26:59.500]   Wi-Fi router. Each device runs 129 euros with a two-pack of the Google Wi-Fi running 229 euros.
[01:26:59.500 --> 01:27:03.100]   That's a look at a few of the things we'll be tracking in the coming week. Join Meghan Moroni
[01:27:03.100 --> 01:27:09.660]   and me on Tech News Today, every weekday at 4PM Pacific, 7PM Eastern on twit.tv.
[01:27:10.620 --> 01:27:15.500]   Thank you Jason Hal. Thank you for putting euros for the UK price. Don't they use pounds in the UK?
[01:27:15.500 --> 01:27:20.060]   I guess the Brexit memo didn't come out for Jason. I don't know.
[01:27:20.060 --> 01:27:23.100]   That doesn't everybody think in euros? I do.
[01:27:23.100 --> 01:27:30.060]   Our show today brought to you by those great folks at ZipRecruiter. If you're the person who has to do
[01:27:30.060 --> 01:27:34.140]   the hiring in your company, and you are, if you're the sole proprietor, you know this is the thing
[01:27:34.140 --> 01:27:38.700]   you'd least like to do in your business is find the right employee. And yet it probably is your single
[01:27:39.420 --> 01:27:44.540]   most important job, right? The right hire can change your company for the best,
[01:27:44.540 --> 01:27:48.460]   for the, you know, really make it different. The wrong hire could bring your company to its knees.
[01:27:48.460 --> 01:27:53.340]   So you, let's assume, and I think it's a safe assumption, somewhere out there is just the right
[01:27:53.340 --> 01:27:58.460]   person for the job you want to fill. How do you reach that person? Which job board is that person
[01:27:58.460 --> 01:28:01.740]   looking at? When do they look at it? With ZipRecruiter, you don't have to worry about that. You'll
[01:28:01.740 --> 01:28:07.580]   post it 200 plus job boards with one click of the mouse at zippercruiter.com. And I love this. You're
[01:28:07.580 --> 01:28:10.940]   going to get, not only are you going to get your message out to all those job boards and
[01:28:10.940 --> 01:28:17.180]   Twitter and Facebook, but you're also going to get all the resumes pre formatted by ZipRecruiter. So
[01:28:17.180 --> 01:28:22.700]   they're easy to read. All the applicants filter into the ZipRecruiter interface. No more calls to
[01:28:22.700 --> 01:28:27.900]   your phone or emails to your inbox. You can go right to the interface. You can have screening
[01:28:27.900 --> 01:28:33.020]   questions for them, multiple choice. Yes, no, even essay questions that help you narrow it down,
[01:28:33.020 --> 01:28:38.140]   screen out the people who aren't right, rank the rest and hire the right person. Fast. This is the
[01:28:38.140 --> 01:28:43.740]   most efficient way to do the toughest but most important job in your business. You're going to
[01:28:43.740 --> 01:28:49.820]   love ZipRecruiter used by Fortune 100, companies thousands of small and medium businesses over a
[01:28:49.820 --> 01:28:55.580]   million companies, including to it, use ZipRecruiter to fill those positions. You should try it free.
[01:28:56.620 --> 01:29:04.940]   Go to ziprecruiter.com/twit right now and have a free trial, some ziprecruiter.com/twit.
[01:29:04.940 --> 01:29:10.940]   We thank ZipRecruiter for making our podcast. That is the hardest job for any business.
[01:29:10.940 --> 01:29:17.020]   It is. It's a fine and good people. That is all you do and a team lives or dies based on
[01:29:17.020 --> 01:29:20.300]   any higher. How old is SpaceCat? How long have you been doing that?
[01:29:20.300 --> 01:29:26.380]   Well, my studio has been around since 2010. We saw the percentage of women gamers just
[01:29:26.380 --> 01:29:30.140]   exploding. I was all in. I'm like, it's time to launch my own game studio.
[01:29:30.140 --> 01:29:37.260]   And how many people work for you? Well, it depends. Game development is when you,
[01:29:37.260 --> 01:29:41.340]   depending on where you are in the process, you bring people in and then you let them go. When the
[01:29:41.340 --> 01:29:46.380]   job is done, it's very sad about the game industry. So, depending on where you are, we may have five
[01:29:46.380 --> 01:29:51.740]   people working for us or 15. So, you're always going up and down and that, yeah, you understand
[01:29:51.740 --> 01:29:59.180]   we're a small business too. We have 25 employees. And boy, I shouldn't talk about this in public,
[01:29:59.180 --> 01:30:05.420]   but the worst thing in business is having to fire somebody. Oh, it's so bad. It's so bad.
[01:30:05.420 --> 01:30:12.060]   It's miserable and you feel terrible. And you know, I mean, you're not insensitive to what's
[01:30:12.060 --> 01:30:16.780]   happening. This is terrible. I've been fired. I don't like to do that. But at the same time,
[01:30:16.780 --> 01:30:22.620]   you have to sometimes. So, that's why hiring is important because right, you don't want to hire
[01:30:22.620 --> 01:30:26.220]   somebody, you're going to have to fire. And it's also a very expensive mistake when you hire the
[01:30:26.220 --> 01:30:32.460]   wrong person. I know that well, unfortunately. Yeah, I don't. Again, I could go on and on because
[01:30:32.460 --> 01:30:37.660]   I've had employees who've cost us hundreds of thousands of dollars. It is not a good thing.
[01:30:37.660 --> 01:30:41.500]   Yeah. Yeah. Anyway, I don't know. I don't know. I got it. Oh,
[01:30:42.860 --> 01:30:48.780]   by the way, Brianna does a very good podcast on relay.fm that everybody should be listening to. I hope
[01:30:48.780 --> 01:30:56.700]   people know about Brianna's show. It's called Disruption. Tell us what it's about.
[01:30:56.700 --> 01:31:04.060]   Well, I tell you, that's the one I did that one with Georgia. And it's more of a social show.
[01:31:04.060 --> 01:31:08.540]   Like we look at how technology is affecting people and we have different perspectives.
[01:31:09.260 --> 01:31:16.380]   The show I'm really proud of is called Rocket on relay. Oh, man. My wife loves that show, by the way.
[01:31:16.380 --> 01:31:19.420]   Oh, I'm so I'm so I'm so I'm so I'm so I'm so I'm so I'm so I'm so I'm so I'm so I'm so I'm so
[01:31:19.420 --> 01:31:26.460]   I love your wife. She's awesome. Every I'm on Twitter. No, rocket is it's a great it's a great show
[01:31:26.460 --> 01:31:32.940]   because it's all women. It's me. It's Christina Warren, who has so much talent. Like every single
[01:31:33.580 --> 01:31:40.300]   week I do a show of Christina. I leave and I'm just jealous of how much talent and intellect she has.
[01:31:40.300 --> 01:31:46.300]   She's amazing. And we do it with Simone de Roche for, who's a video content producer at Polygon.
[01:31:46.300 --> 01:31:52.460]   She's younger is just super enthusiastic and makes the show super weird and uncomfortable.
[01:31:52.460 --> 01:31:58.540]   But what I love about the show is, you know, we talk so much about women and tech issues. Rocket
[01:31:58.540 --> 01:32:02.940]   is a show where it's just women talking about technology and bringing our perspective to it.
[01:32:02.940 --> 01:32:07.420]   And we don't talk about politics a lot. And there's nothing like else like it in the tech world.
[01:32:07.420 --> 01:32:13.020]   Yeah, Lisa loves she's always in you can listen to rocket. I said, but it's for women. I'm a I'm a
[01:32:13.020 --> 01:32:17.420]   guy. I don't know. I don't know. I don't listen to any podcast. I don't have time. I'm too busy.
[01:32:17.420 --> 01:32:21.900]   Yeah, too busy making them. But I will listen to rocket because I love all three of you. And I
[01:32:21.900 --> 01:32:27.820]   think that's a what a great idea for a show at replay. I'm sorry, relay. I always get this wrong.
[01:32:27.820 --> 01:32:34.220]   Relay.fm re la y.fm. I think it's psychological. I don't want to promote Mike Hurley at all.
[01:32:34.220 --> 01:32:39.100]   He's too darn good. He's got too many shows I wish I had.
[01:32:39.100 --> 01:32:46.220]   And of course with us Erin Griffith, she writes for fortune at fortune.com and don't forget
[01:32:46.220 --> 01:32:50.460]   her daily newsletter. If you're an investor, a must read, where can they find that?
[01:32:50.460 --> 01:32:59.100]   The term sheet, you can go to fortune.com/getterm sheet and sign up for it there.
[01:32:59.100 --> 01:33:04.300]   And it's a daily listing of every single M&A transaction that happened in the last 24 hours.
[01:33:04.300 --> 01:33:07.260]   Wow. So that's a lot. And then also my commentary.
[01:33:07.260 --> 01:33:12.300]   Wow, busy. Any big, any big mergers and acquisitions in the last week that
[01:33:13.420 --> 01:33:20.620]   people missed maybe missed the big story? Well, let's see. Toshiba is selling its chip.
[01:33:20.620 --> 01:33:25.980]   Yeah, we're hearing rumors that Apple might be looking at Toshiba, right? Really? That would be
[01:33:25.980 --> 01:33:33.580]   interesting. Yeah. There's a soft bank is just throwing money away faster than it can light it on
[01:33:33.580 --> 01:33:40.060]   fire. They're trying to invest in we work. They're maybe going to give $60 billion to DD, which
[01:33:40.700 --> 01:33:44.700]   would be the largest venture capital investment of all time. That's the Uber of China, right?
[01:33:44.700 --> 01:33:51.660]   Yep. DD. Actually, this Toshiba thing is interesting because it's not just Apple,
[01:33:51.660 --> 01:33:57.980]   but Google and Amazon apparently also looking at this. Why would these companies want to make
[01:33:57.980 --> 01:34:04.700]   their own flash ram? What would be the advantage to that? I could see Apple. They probably sell
[01:34:04.700 --> 01:34:09.900]   more flash memory than anybody in the world, right? Well, they could improve the quality
[01:34:09.900 --> 01:34:14.220]   theoretically and cut down the cost. But Google is not known as a manufacturing. They even make
[01:34:14.220 --> 01:34:21.340]   the pixel. They designed the pixel, but they made LG. LG, LG built this one. They owned Motorola and
[01:34:21.340 --> 01:34:25.740]   did very badly. Right. They don't want to own hardware. They don't want to own hardware.
[01:34:25.740 --> 01:34:30.060]   And Amazon is not, I guess Amazon, because they make a lot of tablets.
[01:34:30.060 --> 01:34:34.620]   Food. I don't know. It seems like Apple would be the most logical of...
[01:34:35.580 --> 01:34:39.820]   They bought that Israeli company a few years ago that specialized in this technology.
[01:34:39.820 --> 01:34:42.780]   I bet it's more about the patents if I had to...
[01:34:42.780 --> 01:34:50.860]   Yeah, it's always about the patents, isn't it, these days. Yeah. Apple, though, I have to say,
[01:34:50.860 --> 01:34:55.900]   I think learned a lesson that they want to make everything that they sell, right?
[01:34:55.900 --> 01:35:00.700]   They want to control the entire ecosystem. Control it from beginning to end, right?
[01:35:00.700 --> 01:35:07.340]   And they've also become a lot more acquisitive under Tim Cook. They used to really never acquire
[01:35:07.340 --> 01:35:12.300]   companies. And now it seems like they're snapping up lots of little ones and also not scared to do
[01:35:12.300 --> 01:35:20.060]   some big deals. Remember Andy Rubin? He's the guy who created Android, sold the company to Google,
[01:35:20.060 --> 01:35:25.900]   did pretty well than left. Actually, what he did is first he went to robots, and then he left Google.
[01:35:25.900 --> 01:35:33.900]   He's been working on a phone. They call it essential. And guess who leaked out that the
[01:35:33.900 --> 01:35:38.380]   essential will be an Android phone? Eric Schmidt of all people, former Google CEO.
[01:35:38.380 --> 01:35:42.540]   He tweeted, "Yeah, it's an Android phone. I don't know what Eric's
[01:35:42.540 --> 01:35:51.180]   interested in all this." But it's another one of these bezel-less, very thin frame phones.
[01:35:52.540 --> 01:35:59.180]   Truly, that's not an accidental leak. Anything that he's revealing has been vetted by the
[01:35:59.180 --> 01:36:04.380]   lawyers and the PR team that both sides involved. Probably he wanted to quell any possible rumors
[01:36:04.380 --> 01:36:10.460]   that Andy Rubin is working on a new competitor to Android that he'll sell to Amazon or whoever
[01:36:10.460 --> 01:36:15.420]   wants a new operating system. When are we going to get to the point when we really don't care about
[01:36:15.420 --> 01:36:20.860]   a new phone? I think I get to that point a few years ago. I totally said, "I don't want to buy
[01:36:20.860 --> 01:36:24.700]   any more phones." She said, "You have to." When's the last time you have to buy every new phone that
[01:36:24.700 --> 01:36:32.540]   comes out? You have to. Well, you do. I mean, I haven't bought a television set now in six years,
[01:36:32.540 --> 01:36:38.140]   right? I probably should buy an ultra high definition TV set at some point. It's your fault
[01:36:38.140 --> 01:36:42.940]   that Sony and Samsung, they're going out of business. They're losing money. You got to buy a TV every
[01:36:42.940 --> 01:36:49.820]   few years. There's a few jobs. But you know, phones, I don't know. I find it like even, you know,
[01:36:49.820 --> 01:36:55.820]   I review phones. It's boring. I mean, so, you know, we sit there and we obsess over the side of the
[01:36:55.820 --> 01:37:00.860]   phone. You know what's more boring than phones? Tablets. Tablets. Oh, boring. I have to tell you,
[01:37:00.860 --> 01:37:07.500]   if you Google this, Google my name and the word iPad underwhelming, and you will see that in 2010,
[01:37:07.500 --> 01:37:14.380]   I declared the iPad as underwhelming. And I was initially wrong in terms of market share. The iPad
[01:37:14.380 --> 01:37:19.580]   is underwhelming. You know, it's so funny because you were not alone. A lot of people said this.
[01:37:19.580 --> 01:37:24.940]   Yeah. And I took great pride in the fact that I said this is the on the day. I remember sitting
[01:37:24.940 --> 01:37:29.420]   out front of Herbal Boyna Center on the day that Steve Jobs, yeah, you came over and talked. We're
[01:37:29.420 --> 01:37:35.660]   sitting in lawn chairs. And I remember vividly saying this is the product Steve Jobs was born
[01:37:35.660 --> 01:37:40.700]   to make. This is what he made Apple for. This is going to revolutionize computing. And it turned,
[01:37:40.700 --> 01:37:44.540]   and I was right for a moment. And I was wrong in the long run. You were right in the long run.
[01:37:44.540 --> 01:37:49.500]   I was right in the long run, but wrong, wrong in the moment. I, the fails were phenomenal. And I,
[01:37:49.500 --> 01:37:53.900]   was almost ready to write a retraction. And then, you know, eventually iPad,
[01:37:53.900 --> 01:37:54.940]   started to dwindle.
[01:37:54.940 --> 01:37:59.900]   Josh, nobody wants to buy a mouse. Sunday he'll be right. Part of the reason why he's right.
[01:37:59.900 --> 01:38:05.820]   The phones are bigger and the laptops are lighter. So, I think Apple deserves a lot of
[01:38:05.820 --> 01:38:09.580]   responsibility here. I mean, you know, Leah, look at that, the machine in front of you. That's
[01:38:09.580 --> 01:38:14.860]   the Microsoft Surface Studio. It's awesome. In fact, see, I want one of those so badly.
[01:38:14.860 --> 01:38:20.380]   The reason I want it is because it has professional Photoshop and Illustrator and premiere.
[01:38:20.380 --> 01:38:26.860]   And Apple has really abrogated any kind of responsibility with leading the pro app market
[01:38:26.860 --> 01:38:32.140]   on the iPad. And, you know, like, there's a point where pages and numbers and spreadsheets,
[01:38:32.140 --> 01:38:38.140]   it just doesn't cut it for pro users. And I just, I think they had a really great product with the
[01:38:38.140 --> 01:38:43.500]   iPad Pro, but they have, they've not developed a in the software ecosystem around it. I think it's
[01:38:43.500 --> 01:38:49.340]   100% what's going on in Apple. Why haven't they kept this leadership?
[01:38:49.340 --> 01:38:55.980]   I think on the PC side, I mean, I'm for the first time ever carrying around a Windows laptop.
[01:38:55.980 --> 01:39:01.100]   You look packer, right? I can do this with it. I know. I know. I can do this with it. In fact,
[01:39:01.100 --> 01:39:05.260]   just to try to try to build your boring and tablet's for your MacBook Pro. It turns out the most
[01:39:05.260 --> 01:39:09.820]   exciting category right now is laptops and Windows. And Windows machines. That's the irony of it.
[01:39:09.820 --> 01:39:15.260]   We just about declared Microsoft dead. I remember when I was at it with a Walt
[01:39:15.260 --> 01:39:18.380]   Musberg and Cara Swisher run this conference, he's called All Things D. Yeah.
[01:39:18.380 --> 01:39:22.940]   Now it's called code. And I remember when I can't remember who it was, I think it talked about the
[01:39:22.940 --> 01:39:30.060]   most important companies in the industry. And it was Apple, Amazon and Google. And Microsoft
[01:39:30.060 --> 01:39:33.900]   wasn't on the list. Right. My stuff has its mojo back. It's back on the list.
[01:39:33.900 --> 01:39:38.380]   Yeah, they're really doing good work. The HoloLens, I think you have to say this.
[01:39:38.380 --> 01:39:42.540]   So much of the work that I've seen done on HoloLens, it's really worth noting there are a lot
[01:39:42.540 --> 01:39:48.780]   of women engineers on that team. And I think it's just one of the best leg companies project
[01:39:48.780 --> 01:39:53.820]   teams I've seen at Microsoft. It's an amazing product. It's got a long way to go. But, you know,
[01:39:53.820 --> 01:40:00.700]   at GSX, my game studio, we've got Oculus, Vive, Gear VR, we've looked at all of it. And I feel
[01:40:00.700 --> 01:40:06.460]   strongly Microsoft has the best product in that space by a wide market. Is it because it's the
[01:40:06.460 --> 01:40:11.020]   best product or because they went for AR and all the rest are VR.
[01:40:11.020 --> 01:40:12.460]   That's it. That's it.
[01:40:12.460 --> 01:40:17.900]   Yeah. And by the way, that's interesting here from a game developer because VR is a great gaming
[01:40:17.900 --> 01:40:23.500]   platform. So they are. Yeah, not as great. I think AR has more potential in a lot of other
[01:40:23.500 --> 01:40:28.300]   realms as well. And when you're gaming, I think you want immersive. I don't think it's a problem
[01:40:28.300 --> 01:40:31.820]   you can't see the world around you. What's the one that everybody's playing that Nintendo?
[01:40:31.820 --> 01:40:36.940]   Pokemon is an AR game. Sorry. It's quasi. It's a poor man's AR.
[01:40:36.940 --> 01:40:41.100]   Somebody made the case though, you know, because everybody's waiting for Apple to drop the other
[01:40:41.100 --> 01:40:46.300]   shoe on AR. And somebody made the case that Pokemon go was actually very, even though it's not really
[01:40:46.300 --> 01:40:51.180]   AR, it was very important in getting people to kind of accustomed to the idea that they could see
[01:40:51.180 --> 01:40:56.380]   the street through their phone and there'd be a Pokemon on it. That's a first step in getting a
[01:40:56.380 --> 01:41:04.380]   customer's use to this idea. So here's the question. Apple, you know, they're making so much money
[01:41:04.380 --> 01:41:09.580]   on the iPhone. It's understandable. They might kind of let computing slip a little bit and focus on
[01:41:09.580 --> 01:41:16.700]   mobile. But everybody's saying Apple's putting all this money into AR that, you know, some say this
[01:41:16.700 --> 01:41:22.380]   year, I think the general consensus is next year, Apple will have a product, an augmented reality
[01:41:22.380 --> 01:41:26.620]   product. Can they make that magic happen one more time?
[01:41:26.620 --> 01:41:33.420]   Leo, you've got to let me say this. People don't talk about this issue with Apple developing an AR
[01:41:33.420 --> 01:41:40.700]   product. And that is thinking about how extremely weak Apple's 3D technologies are. If you go into
[01:41:40.700 --> 01:41:47.100]   the iPhone SDK and you look at the things they have built around 3D, it is baby talk in game
[01:41:47.100 --> 01:41:53.980]   developer terms. Everybody out there is doing serious 3D work on the iPad. Like look at a Vang
[01:41:53.980 --> 01:41:59.500]   Glory, probably the most gorgeous game on iPad that's made with proprietary engine. Most people
[01:41:59.500 --> 01:42:05.100]   have like my studio goes to Unreal because Apple's tools are unsatisfactory. And look at their big
[01:42:05.100 --> 01:42:11.020]   gambit with metal. Metal is a great technology. But where's the software actually using it? It
[01:42:11.020 --> 01:42:16.460]   doesn't exist. So in the meantime, they've got this technology built on the OpenGL layer,
[01:42:16.460 --> 01:42:23.980]   which is very thick and inefficient. We see a 25% decrease in frame rate in using the exact same
[01:42:23.980 --> 01:42:30.220]   software on a Mac. And then that same Mac running Windows will get 25% better frame rate because
[01:42:30.220 --> 01:42:34.620]   Apple's implementation of it is that. Is that because Apple put went all in on OpenGL when the
[01:42:34.620 --> 01:42:40.620]   rest of the world was going to DirectX and it turned out OpenGL sucked? Yeah, I think that's a lot of
[01:42:40.620 --> 01:42:46.060]   it. But it's just a bad choice. That's like sprint choosing YMAX instead of LTE. That's a bad
[01:42:46.060 --> 01:42:51.100]   choice. We've got a choice that haunts a company for years, but it's not. It's just a mistake.
[01:42:51.100 --> 01:42:56.300]   So if they're going to be bringing this product out, they're going to have to really get serious
[01:42:56.300 --> 01:43:03.420]   about 3D technologies. Interesting. They blindsided us with Swift. Nobody saw that coming. So maybe
[01:43:03.420 --> 01:43:08.540]   they have a group of people that are working to really build up Apple's 3D technologies. But
[01:43:08.540 --> 01:43:14.380]   somebody that ships mobile games on Apple devices, there's a reason we use Unreal Engine.
[01:43:14.380 --> 01:43:17.660]   It's because Apple's tech doesn't have it. Everybody uses Unreal Engine.
[01:43:17.660 --> 01:43:25.900]   Or does Unity have good 3D support? It's solid. It's not as advanced. It's cross-platform,
[01:43:25.900 --> 01:43:30.140]   which is nice. It's cross-platform. The reason they've gotten a lot of adoption is it's simpler.
[01:43:30.140 --> 01:43:35.180]   And they've done a really good job at reaching out to universities. So a lot of students know how
[01:43:35.180 --> 01:43:41.580]   to use it. But we prefer Unreal because it's better. Well, maybe Apple also suffered. This
[01:43:41.580 --> 01:43:45.500]   isn't interesting. Somebody in the chatroom suggesting Apple didn't have to worry about a 3D
[01:43:45.500 --> 01:43:51.020]   engine because you don't game so much on a Macintosh. And so there was no pressure on them
[01:43:51.020 --> 01:43:56.220]   to create something good. And that ended up hurting the tablet as well, iOS as well,
[01:43:56.220 --> 01:44:00.060]   because they didn't have to develop these technologies. Didn't they claim that iOS was
[01:44:00.060 --> 01:44:04.460]   actually one of the most popular gaming platforms in the world? It's casual gaming.
[01:44:04.460 --> 01:44:08.140]   It is. But it is the most popular gaming platform in the world.
[01:44:08.140 --> 01:44:12.380]   But that's what you develop more exclusively, right? That's right. 40% of the profits are
[01:44:12.380 --> 01:44:17.500]   industry or mobile devices. But this hurts Apple in the long term. Look at the Apple TV.
[01:44:17.500 --> 01:44:24.060]   I think it's really hard to look at that product and not see it as a failure because the apps on
[01:44:24.060 --> 01:44:30.540]   it do not make money for developers. And it's just not a great place for developers to go unless
[01:44:30.540 --> 01:44:37.100]   they're porting iPhone games over to it. So Apple's weak leadership in this area is really coming back
[01:44:37.100 --> 01:44:40.460]   to haunt them, I believe. Interesting. Now I have to point out, Android's no better.
[01:44:40.460 --> 01:44:46.220]   That's true. That's true. You don't have to sell me. It's a real right here.
[01:44:46.220 --> 01:44:52.700]   So there really is. How about the Nintendo Switch? There's a mobile platform for 3D.
[01:44:52.700 --> 01:44:55.500]   I bet that's a pretty good platform.
[01:44:55.500 --> 01:45:01.980]   We're looking at it. It's really exciting. I'm not convinced it doesn't have fundamental hardware
[01:45:01.980 --> 01:45:08.060]   issues with the Bluetooth controller. But the Tegra processor underneath it, it's a very
[01:45:08.060 --> 01:45:11.900]   solid product for Nintendo. And I'm really looking forward to getting one.
[01:45:11.900 --> 01:45:17.900]   This is Vanglor. You think this is the best? I can't nobody can see it. It really is amazing.
[01:45:17.900 --> 01:45:23.500]   But what engine is this using? That's a proprietary engine that they run themselves.
[01:45:23.500 --> 01:45:26.620]   But look at it. The particle effects. Yeah, it's really nice.
[01:45:27.260 --> 01:45:32.220]   There's really not great tools in Apple's iPhone SDK to do things like that.
[01:45:32.220 --> 01:45:35.820]   Interesting. I have no... This is why I love getting developers on.
[01:45:35.820 --> 01:45:41.020]   You see it completely different way than end users do. We don't know what's under the hood.
[01:45:41.020 --> 01:45:45.340]   We don't know if this is good or bad. It's difficult stuff.
[01:45:45.340 --> 01:45:49.980]   Really? I'm looking forward to you making speeches from the floor of Congress with this
[01:45:49.980 --> 01:45:55.500]   level of technical. That would be awesome. You'd have your own C-SPAN channel.
[01:45:55.500 --> 01:46:01.260]   Resolved. Open GL. Shall no longer be used on any platform. The eyes have it.
[01:46:01.260 --> 01:46:05.660]   I would pass a bill out while I flash. That would be really good for the world.
[01:46:05.660 --> 01:46:07.740]   Would you please? Yes, I'll vote for that.
[01:46:07.740 --> 01:46:14.540]   Finally on its last legs, you saw that FedEx is offering people $5 rebate if they turn on
[01:46:14.540 --> 01:46:20.700]   flash in their browser. Because flash is now disabled in Chrome and Firefox. But unfortunately,
[01:46:20.700 --> 01:46:26.060]   I guess FedEx can't figure out how to get a developer to not use flash. So they're so flash
[01:46:26.060 --> 01:46:30.940]   dependent, they're offering you a $5 rebate to turn it back on. Oh, that's sad.
[01:46:30.940 --> 01:46:35.900]   Oh, I don't do that. I had to turn it back on yesterday because I was watching some video I
[01:46:35.900 --> 01:46:43.740]   needed to watch. There are 69 new emojis. We've got them for you here, including, I think,
[01:46:43.740 --> 01:46:47.820]   one we're going to take a little bit of credit for. This is the Unicode committee.
[01:46:47.820 --> 01:46:52.860]   There's an emoji committee. We talked to one of the members of the committee when he was out
[01:46:52.860 --> 01:47:00.300]   here in San Francisco. Many of these have been launched now in iOS 10.3. One of them is a milkshake.
[01:47:00.300 --> 01:47:06.060]   I have to give credit to our own Tanya Hall who talked to the guy when he was visiting us and
[01:47:06.060 --> 01:47:10.300]   said, "Why is there not a milkshake emoji? There's other pizza. There's hot dogs. There's
[01:47:10.300 --> 01:47:16.220]   hamburgers now." There is now a milkshake emoji. I think we have to thank our own Tanya Hall for
[01:47:16.220 --> 01:47:21.980]   making that happen. There's a bearded person, not a bearded man. That's a bearded person.
[01:47:21.980 --> 01:47:26.780]   Now, this is an interesting choice. This breastfeeding one is a little controversial. By the way,
[01:47:26.780 --> 01:47:34.860]   remember, when you see an emoji, there is a reference design, but every platform,
[01:47:34.860 --> 01:47:40.220]   Twitter, Facebook, Google, Amazon, Apple, all have their own design. This was a controversial one,
[01:47:40.220 --> 01:47:46.220]   because this is, by the way, weird. Originally, the breastfeeding emoji didn't have a head,
[01:47:46.220 --> 01:47:53.100]   because they didn't want to say it was a man or a woman. They wanted to be gender neutral on the
[01:47:53.100 --> 01:48:02.700]   breastfeeding emoji. Men can breastfeed, I was told. Didn't know that. Not all men. Small,
[01:48:02.700 --> 01:48:09.420]   small percentage. But it was so creepy to have an emoji, breastfeeding emoji with no head.
[01:48:09.420 --> 01:48:14.460]   It was totally out of a horror film. I guess they've decided that, well, okay, we'll give it,
[01:48:14.460 --> 01:48:17.580]   but I bet you there's a man and a woman. I bet you.
[01:48:17.580 --> 01:48:20.460]   Does Congress have to approve these emojis?
[01:48:20.460 --> 01:48:21.660]   No, God.
[01:48:21.660 --> 01:48:23.580]   Just the Unicode consortium.
[01:48:23.580 --> 01:48:30.940]   Okay, absolutely. I feel very strongly that the double-rounded peach emoji needs to be part of
[01:48:30.940 --> 01:48:34.940]   our own. I was very disappointed that they kind of took some of the rounding out of the peach.
[01:48:34.940 --> 01:48:36.540]   Yeah, I think it's very sound.
[01:48:36.540 --> 01:48:40.860]   We need an eggplant. We need a peach. Otherwise, how are we going to use, you know, be sexy emoji?
[01:48:40.860 --> 01:48:45.020]   Very important. I just brought that up, Brianna.
[01:48:45.020 --> 01:48:52.220]   These are some of the other new emojis. There's an elf. There's a genie. There's a vampire.
[01:48:52.220 --> 01:48:56.540]   Nice. That's sexy. There's a fairy.
[01:48:57.580 --> 01:49:00.380]   A male fairy and a female fairy. Of course, fairies come in all kinds.
[01:49:00.380 --> 01:49:06.140]   Merp persons. Merp maids. I've never seen a male mermaid, but I've always hoped to see one.
[01:49:06.140 --> 01:49:11.100]   There's a climber, person in lotus position. That looks like the breastfeeding woman,
[01:49:11.100 --> 01:49:12.620]   doesn't it? Yeah, it's the same one. Yeah.
[01:49:12.620 --> 01:49:15.900]   There's only one woman. She gets around sled.
[01:49:15.900 --> 01:49:19.420]   Oh, this is for our friends in Canada, a curling stone.
[01:49:19.420 --> 01:49:22.620]   Now that way, but that's a little, I think, nation-specific.
[01:49:22.620 --> 01:49:24.060]   Have you thought of launching this thing?
[01:49:24.060 --> 01:49:25.020]   Sounds like a rare-y thing.
[01:49:25.020 --> 01:49:28.940]   We did a whole show dedicated to this. We did a whole show dedicated to this.
[01:49:28.940 --> 01:49:30.780]   We did. We spent a lot of time on the emojis.
[01:49:30.780 --> 01:49:32.460]   I've got a weekly show every week.
[01:49:32.460 --> 01:49:33.900]   Oh, emoji week. Yeah, emoji.
[01:49:33.900 --> 01:49:36.060]   Emojis this week. This week in Hedgehog emoji.
[01:49:36.060 --> 01:49:39.500]   All the things you can do T-Rex like that.
[01:49:39.500 --> 01:49:39.980]   Good.
[01:49:39.980 --> 01:49:40.540]   Yeah.
[01:49:40.540 --> 01:49:42.700]   There are in total how many cars?
[01:49:42.700 --> 01:49:44.220]   Five, 15 new emojis.
[01:49:44.220 --> 01:49:46.460]   59 new emojis.
[01:49:46.460 --> 01:49:47.420]   59 new emojis.
[01:49:47.420 --> 01:49:50.060]   Cricket? That's interesting.
[01:49:50.060 --> 01:49:51.340]   Giraffe.
[01:49:52.460 --> 01:49:54.860]   So these have been in the brewing for a long time.
[01:49:54.860 --> 01:49:55.340]   Zebra.
[01:49:55.340 --> 01:49:56.300]   Zebra.
[01:49:56.300 --> 01:49:56.780]   Yeah.
[01:49:56.780 --> 01:49:59.660]   Okay. We could just could really extend the show for a long time.
[01:49:59.660 --> 01:50:00.220]   So I'm not-
[01:50:00.220 --> 01:50:01.500]   Sandwich. That's what I like.
[01:50:01.500 --> 01:50:02.300]   Sandwich.
[01:50:02.300 --> 01:50:05.580]   69. There's 69 new emojis. Takeout box.
[01:50:05.580 --> 01:50:07.100]   But it's a Chinese takeout box, right?
[01:50:07.100 --> 01:50:11.180]   In one reference design, yes.
[01:50:11.180 --> 01:50:14.540]   But even the milkshake, by the way, is in a milkshake, see?
[01:50:14.540 --> 01:50:17.820]   It's a cup with straw, so you can determine what else is in there.
[01:50:17.820 --> 01:50:18.460]   Okay.
[01:50:18.460 --> 01:50:21.580]   And that may be that looks like, say, McDonald's cup,
[01:50:21.580 --> 01:50:22.540]   but you know, that's-
[01:50:22.540 --> 01:50:23.900]   Twitter gets to do something different.
[01:50:23.900 --> 01:50:25.740]   That's just the reference design.
[01:50:25.740 --> 01:50:26.220]   Gotcha.
[01:50:26.220 --> 01:50:27.740]   I want a developer emoji.
[01:50:27.740 --> 01:50:30.780]   I want a man and a woman developer with coffee cups
[01:50:30.780 --> 01:50:32.620]   just piled up all over their desk.
[01:50:32.620 --> 01:50:33.500]   Well, they're just-
[01:50:33.500 --> 01:50:34.940]   They're head-on the desk, right?
[01:50:34.940 --> 01:50:35.980]   Yeah.
[01:50:35.980 --> 01:50:36.780]   That would be great.
[01:50:36.780 --> 01:50:38.860]   And they should be wearing carpal tunnel braces.
[01:50:38.860 --> 01:50:40.860]   That would be very accurate.
[01:50:40.860 --> 01:50:41.260]   Yes.
[01:50:41.260 --> 01:50:42.140]   To make it real.
[01:50:42.140 --> 01:50:43.020]   Yes.
[01:50:43.020 --> 01:50:46.540]   Hey, congratulations to Andy Bio.
[01:50:46.540 --> 01:50:47.900]   What a saga this is.
[01:50:47.900 --> 01:50:51.020]   Andy Bio founded a site many years ago.
[01:50:51.020 --> 01:50:54.060]   We all use it on the early days of the internet called upcoming.org.
[01:50:54.060 --> 01:50:57.660]   Remember, this was the first kind of event site on the internet.
[01:50:57.660 --> 01:51:01.900]   Two years after it was founded in the early 2000s, Yahoo bought it.
[01:51:01.900 --> 01:51:05.020]   Which of course is the beginning of the end for many a great site.
[01:51:05.020 --> 01:51:10.140]   In 2013, Yahoo shut upcoming.org down.
[01:51:10.140 --> 01:51:11.580]   But that's not the end of the saga.
[01:51:11.580 --> 01:51:20.620]   Then Andy Bio created a Kickstarter campaign to buy it back and revive upcoming.com.
[01:51:20.940 --> 01:51:24.540]   He raised $30,000 in 90 minutes, $100,000 total.
[01:51:24.540 --> 01:51:30.140]   Four years later, upcoming.com is back.
[01:51:30.140 --> 01:51:32.380]   Not only that, he restored the archives.
[01:51:32.380 --> 01:51:34.300]   So you can-
[01:51:34.300 --> 01:51:35.740]   It's actually upcoming.org.
[01:51:35.740 --> 01:51:36.300]   Yeah, do I get it?
[01:51:36.300 --> 01:51:39.420]   So you can see things we did back in the 2000s.
[01:51:39.420 --> 01:51:39.820]   Cool.
[01:51:39.820 --> 01:51:41.820]   You know what he paid, Yahoo for it?
[01:51:41.820 --> 01:51:42.140]   What?
[01:51:42.140 --> 01:51:42.620]   Hopefully not.
[01:51:42.620 --> 01:51:43.100]   No, I don't know.
[01:51:43.100 --> 01:51:43.660]   No, nothing.
[01:51:43.660 --> 01:51:43.980]   Oh, good.
[01:51:43.980 --> 01:51:44.940]   What did Yahoo want?
[01:51:44.940 --> 01:51:45.500]   Hopefully.
[01:51:45.500 --> 01:51:45.980]   A quarter.
[01:51:45.980 --> 01:51:45.980]   A quarter.
[01:51:45.980 --> 01:51:46.780]   Yeah.
[01:51:46.780 --> 01:51:48.620]   Yeah, I don't think he-
[01:51:48.620 --> 01:51:49.100]   I don't know.
[01:51:49.100 --> 01:51:49.820]   That's a good question.
[01:51:49.820 --> 01:51:50.700]   He'll have to pay a lot for his interest.
[01:51:50.700 --> 01:51:54.300]   I hate to tell him that he has some new competition in the intro-
[01:51:54.300 --> 01:51:55.340]   and the intro-
[01:51:55.340 --> 01:51:56.620]   meaning 15 years.
[01:51:56.620 --> 01:51:57.260]   Oh, no.
[01:51:57.260 --> 01:52:01.500]   There are a lot of new event sites that have sprung up to take his place.
[01:52:01.500 --> 01:52:03.020]   I hope he has some new feature ideas.
[01:52:03.020 --> 01:52:05.580]   There's event bride and yeah, there are a lot of them.
[01:52:05.580 --> 01:52:08.540]   Upcoming though, I will use upcoming just because that's the-
[01:52:08.540 --> 01:52:09.420]   that was the original.
[01:52:09.420 --> 01:52:11.020]   It just looks a little like an old site.
[01:52:11.020 --> 01:52:12.540]   It does, doesn't it?
[01:52:12.540 --> 01:52:12.940]   It's okay.
[01:52:12.940 --> 01:52:13.980]   It's kind of like delicious.
[01:52:13.980 --> 01:52:16.300]   Another site that the Yahoo practically killed.
[01:52:16.300 --> 01:52:17.420]   It's probably a lot faster.
[01:52:18.060 --> 01:52:19.900]   Palmer Lucky is leaving.
[01:52:19.900 --> 01:52:23.180]   Oculus, what do you think of this?
[01:52:23.180 --> 01:52:24.380]   What do you make of this?
[01:52:24.380 --> 01:52:26.860]   Palmer Lucky was a teenager who dreamed of-
[01:52:26.860 --> 01:52:29.660]   I think the PR people have to be celebrating this.
[01:52:29.660 --> 01:52:34.140]   I mean, they've been trying to distance themselves from him for quite some time.
[01:52:34.140 --> 01:52:38.300]   You know, when it came up that he was the one who was behind all of these
[01:52:38.300 --> 01:52:43.980]   crass memes and not to mention their lawsuit that they've been dealing with was Zenimax.
[01:52:43.980 --> 01:52:45.500]   Obviously, he's at the center of it.
[01:52:46.620 --> 01:52:48.540]   They're very terse.
[01:52:48.540 --> 01:52:53.340]   We wish him the best statement with why behind it.
[01:52:53.340 --> 01:52:57.500]   I think was telling if you're between the lines.
[01:52:57.500 --> 01:53:02.780]   I got to tell you, I got to tell you, he got two billion dollars when Facebook bought Oculus.
[01:53:02.780 --> 01:53:06.460]   He personally didn't get that, but he did get a lot of money.
[01:53:06.460 --> 01:53:07.980]   I think he could live on that for a while.
[01:53:07.980 --> 01:53:09.900]   He got a lot of it, I would guess.
[01:53:09.900 --> 01:53:11.660]   Enough that he probably doesn't have to work.
[01:53:11.660 --> 01:53:14.220]   If I were Palmer Lucky, I would take it a little easy by now.
[01:53:14.780 --> 01:53:19.260]   I think it's tempting to look at this through the social disaster story.
[01:53:19.260 --> 01:53:23.100]   And certainly the stuff he did was, it didn't look good.
[01:53:23.100 --> 01:53:29.900]   But I think the bigger issue here is Oculus' launch was really blown in a way that really
[01:53:29.900 --> 01:53:32.620]   jeopardizes the long-term health of that company.
[01:53:32.620 --> 01:53:34.940]   I say that's someone that develops with VR.
[01:53:34.940 --> 01:53:40.380]   Oculus Touch is the best product on the market for interfacing in VR.
[01:53:40.380 --> 01:53:41.740]   It didn't launch with it.
[01:53:41.740 --> 01:53:43.100]   It launched after the fact.
[01:53:43.100 --> 01:53:47.020]   You have games like Robo Recall, which are exceptional in the system,
[01:53:47.020 --> 01:53:49.740]   which have not gotten any attention at all.
[01:53:49.740 --> 01:53:55.260]   You look at this with problems recruiting developers,
[01:53:55.260 --> 01:53:58.620]   problems of really getting a solid dev kit out there to people,
[01:53:58.620 --> 01:54:01.900]   problems with really getting a marketplace,
[01:54:01.900 --> 01:54:04.060]   problems with attracting a user base.
[01:54:04.060 --> 01:54:05.820]   And it just needs a new direction.
[01:54:05.820 --> 01:54:09.580]   So I'm happy to put all of my social differences with him aside
[01:54:09.580 --> 01:54:13.980]   and say someone's got to take responsibility to this blown launch
[01:54:13.980 --> 01:54:15.820]   with this very important product.
[01:54:15.820 --> 01:54:19.020]   And I clearly think there's new leadership needed there.
[01:54:19.020 --> 01:54:27.100]   What's the best game on VR, whether it's Vive or Aroculous?
[01:54:27.100 --> 01:54:28.620]   Robo Recall.
[01:54:28.620 --> 01:54:28.940]   Really?
[01:54:28.940 --> 01:54:31.820]   Yeah, you're dodging, you're shooting bullets.
[01:54:31.820 --> 01:54:35.500]   You grab robots and throw them into teleporters.
[01:54:35.500 --> 01:54:37.020]   It's really amazing.
[01:54:37.020 --> 01:54:37.900]   I'll have to try it.
[01:54:37.900 --> 01:54:38.700]   Yeah.
[01:54:38.700 --> 01:54:40.220]   That's an epic game.
[01:54:40.220 --> 01:54:41.100]   It is.
[01:54:41.100 --> 01:54:42.940]   It is made with Unreal Engine.
[01:54:42.940 --> 01:54:43.500]   Interesting.
[01:54:43.500 --> 01:54:47.500]   Do you spend a lot of time in what do we call it?
[01:54:47.500 --> 01:54:48.300]   In the hood?
[01:54:48.300 --> 01:54:49.020]   In the viter?
[01:54:49.020 --> 01:54:50.460]   I do.
[01:54:50.460 --> 01:54:52.540]   We have an entire room.
[01:54:52.540 --> 01:54:54.140]   My studio is dedicated to it.
[01:54:54.140 --> 01:54:58.380]   I have a really cool tech demo that we've been working on
[01:54:58.380 --> 01:55:01.500]   that I'm putting aside to go run for Congress.
[01:55:01.500 --> 01:55:04.940]   It's really sad because I think it's some really fun technology,
[01:55:04.940 --> 01:55:08.860]   but I'm just not going to feel great about developing pleasant distractions
[01:55:08.860 --> 01:55:10.140]   for the next four years.
[01:55:10.140 --> 01:55:13.180]   Yeah, I know Georgia and Anthony are huge.
[01:55:13.180 --> 01:55:16.460]   They have a dedicated VR room in their house.
[01:55:16.460 --> 01:55:16.940]   They do.
[01:55:16.940 --> 01:55:18.620]   They're talking about buying new house.
[01:55:18.620 --> 01:55:23.740]   They're going to buy a new house for a VR room to have another view.
[01:55:23.740 --> 01:55:28.060]   Because right now, she plays downstairs against him.
[01:55:28.060 --> 01:55:28.860]   He's upstairs.
[01:55:28.860 --> 01:55:29.340]   Yeah.
[01:55:29.340 --> 01:55:29.820]   Crazy.
[01:55:29.820 --> 01:55:32.060]   Crazy.
[01:55:32.060 --> 01:55:33.820]   I'm not sold on VR.
[01:55:33.820 --> 01:55:35.500]   I'm much more excited about AR.
[01:55:35.500 --> 01:55:36.220]   I'm not either.
[01:55:36.220 --> 01:55:36.860]   I agree.
[01:55:36.860 --> 01:55:37.900]   I can't wait.
[01:55:37.900 --> 01:55:42.860]   I'm not willing to invest in a high-end VR system in the room it takes in the house.
[01:55:42.860 --> 01:55:43.340]   Right.
[01:55:43.340 --> 01:55:46.940]   And so I've got the Oculus VR and I've got a few other devices,
[01:55:46.940 --> 01:55:48.460]   but they're all fun.
[01:55:48.460 --> 01:55:51.020]   But after a while, I kind of move on.
[01:55:51.020 --> 01:55:53.580]   I have a game room that has VIVE set up.
[01:55:53.580 --> 01:55:55.980]   It has the sensors nailed to the wall and everything.
[01:55:55.980 --> 01:55:57.980]   But we don't do it that often.
[01:55:57.980 --> 01:55:59.020]   You don't need that.
[01:56:00.380 --> 01:56:05.020]   I think it's, I think that we haven't seen the use case proven for it yet.
[01:56:05.020 --> 01:56:05.500]   Right.
[01:56:05.500 --> 01:56:06.700]   So there it is.
[01:56:06.700 --> 01:56:07.580]   I agree.
[01:56:07.580 --> 01:56:08.220]   Let's take a break.
[01:56:08.220 --> 01:56:10.300]   When we come back, it was April Fool's Day yesterday.
[01:56:10.300 --> 01:56:11.820]   I'm going to let each of you pick your favorite.
[01:56:11.820 --> 01:56:13.740]   I hate April Fool's Day.
[01:56:13.740 --> 01:56:16.700]   This show, the day after April Fool's, is so hard to do because
[01:56:16.700 --> 01:56:20.140]   is George TK running for Congress or not?
[01:56:20.140 --> 01:56:22.300]   I don't know.
[01:56:22.300 --> 01:56:26.620]   Because everything you read, you have to filter.
[01:56:26.620 --> 01:56:26.940]   Right.
[01:56:26.940 --> 01:56:29.660]   Did Apple buy Tesla?
[01:56:29.660 --> 01:56:30.700]   I don't know.
[01:56:30.700 --> 01:56:33.900]   Anyway, we're going to take a break and come back to Google by Spotify.
[01:56:33.900 --> 01:56:36.140]   Your favorite April Fool's jokes when we return.
[01:56:36.140 --> 01:56:37.260]   This is no joke.
[01:56:37.260 --> 01:56:40.540]   Stamps.com, if you are in the business where you mail stuff
[01:56:40.540 --> 01:56:44.860]   and you are still going to the post office to get stamps, to buy stamps, or worse,
[01:56:44.860 --> 01:56:49.580]   you have a postage meter that you bring to the post office.
[01:56:49.580 --> 01:56:54.220]   It looks like it's a nuclear containment vessel that you have weighs about 40 pounds.
[01:56:54.220 --> 01:56:57.580]   You bring it to the post office to get postage put on it and you're buying special ink.
[01:56:57.580 --> 01:57:00.460]   You're crazy. That's not the 21st century.
[01:57:00.460 --> 01:57:07.260]   Stamps.com, my friends, use your computer, your printer to print real US postage as needed.
[01:57:07.260 --> 01:57:09.100]   And it does so much more.
[01:57:09.100 --> 01:57:11.020]   It really actually solves your fulfillment problem.
[01:57:11.020 --> 01:57:12.780]   In fact, you could do anything you would do with the post office,
[01:57:12.780 --> 01:57:16.700]   including mail stuff from your desk with stamps.com.
[01:57:16.700 --> 01:57:19.660]   No equipment to lease, no long-term commitments.
[01:57:19.660 --> 01:57:23.500]   They'll even send you a digital scale, a USB scale that calculates exactly the right
[01:57:23.500 --> 01:57:29.580]   postage. No more guessing. When I buy stuff on Etsy or eBay, sometimes I'll get a brown paper
[01:57:29.580 --> 01:57:33.340]   wrapped package in twine. It's kind of lumpy and funny shaped.
[01:57:33.340 --> 01:57:37.340]   And then there's about 20 extra stamps stuck on it because I know they didn't want to,
[01:57:37.340 --> 01:57:38.300]   you know, they weren't sure.
[01:57:38.300 --> 01:57:44.140]   Stamps.com, if print out the label right for the packaging, it even fills out the forms you need.
[01:57:44.140 --> 01:57:46.940]   The customs forms, the express mail forms, you get discounts.
[01:57:46.940 --> 01:57:51.660]   You can't get it the post office because by the way, the post office loves stamps.com.
[01:57:51.660 --> 01:57:55.660]   They want you to use stamps.com. So they give you discounts you can't get anywhere else.
[01:57:55.660 --> 01:58:00.300]   It is awesome. And right now you can try it free. In fact, it's a great deal.
[01:58:00.300 --> 01:58:05.020]   A four-week trial plus $55 in free postage coupons.
[01:58:05.020 --> 01:58:09.500]   You can use over the first few months of your account plus the digital scale, a great deal.
[01:58:09.500 --> 01:58:14.780]   Stamps.com, you got to try it. If you're doing mailing at all, go to stamps.com,
[01:58:14.780 --> 01:58:18.700]   click the upper right hand corner. There's a microphone up there and enter.
[01:58:18.700 --> 01:58:25.100]   Twit is the offer code. This is a $110 bonus value and a free trial of stamps.com.
[01:58:25.100 --> 01:58:29.980]   We use it like crazy. It's the only way to do mailing. It makes you look professional.
[01:58:29.980 --> 01:58:32.140]   You can put it right on the envelope too with your logo and everything.
[01:58:32.140 --> 01:58:35.980]   Stamps.com. All right. There were some good April Fool's pranks.
[01:58:35.980 --> 01:58:41.100]   There were also some bad ones. I'm pretty sure George Tique is not running for Congress,
[01:58:41.100 --> 01:58:45.980]   but Branna Wu is. Yes, we'll try. Although you said you would vote for him, I would.
[01:58:45.980 --> 01:58:51.020]   Yes, sure. Of course, I would. I thought it was really interesting. The reason I fell for this
[01:58:51.020 --> 01:58:56.540]   and even retweeted it is he ran for who was thinking about running back in the 70s.
[01:58:56.540 --> 01:59:01.740]   He ultimately had to pull his candidacy because Star Trek was still in the air.
[01:59:01.740 --> 01:59:09.260]   Because of equal time laws, they would have to give the other person a ton of time on the air
[01:59:09.260 --> 01:59:14.940]   as well. I completely fell for this. I am vulnerable and people called me on it.
[01:59:14.940 --> 01:59:19.900]   I would love to see him run. I would confess. When I first read it, I forgot it was April Fool's
[01:59:19.900 --> 01:59:25.260]   Day. I did believe it and I was thrilled. I didn't retweet it. Thank God. I didn't fall.
[01:59:25.260 --> 01:59:29.500]   But I was thrilled. I thought, "Who doesn't love George Tique?"
[01:59:29.500 --> 01:59:41.180]   And he's openly gay. He's funny, smart. He understands technology. He's very political.
[01:59:41.180 --> 01:59:44.780]   And I just would love it if he would run. George, maybe you should run.
[01:59:44.780 --> 01:59:52.540]   No equal time problems these days. But it was in April Fool's. What was your favorite?
[01:59:52.540 --> 01:59:57.580]   Well, it's Google Cloud. Google Wind where they're going to be able to use the cloud to predict
[01:59:57.580 --> 02:00:03.100]   clouds and actually use windmills to clear the sky. But I have to say, I put on Facebook that
[02:00:03.100 --> 02:00:08.540]   yesterday I called it "fake news day." This is a day when it's okay. It's okay. Get it out of your
[02:00:08.540 --> 02:00:14.540]   system. Do it now. This is the get wind. This was Google Netherlands. One of the problems with
[02:00:14.540 --> 02:00:21.660]   Google is they have every Google division across the world does their own April Fool's joke. In
[02:00:21.660 --> 02:00:24.780]   fact, at some point, I feel like Google is spending more time on April Fool's jokes and
[02:00:24.780 --> 02:00:29.340]   figuring out which messaging program we're going to use. They've just spent a little time more on
[02:00:29.340 --> 02:00:33.660]   the messaging mess up there. That's a sick bird.
[02:00:36.300 --> 02:00:39.980]   Brianna, did you have a favorite April Fool's joke from the tech community?
[02:00:39.980 --> 02:00:46.220]   It was George to Kake. Like I said, I closed my browser and said, "This is not a good day for me
[02:00:46.220 --> 02:00:53.260]   to be a producer." We should make this the new thing. This is the day you disconnect as April Fool's
[02:00:53.260 --> 02:00:59.100]   day. No screen day. How about you, Aaron Griffith? Did you have a favorite April?
[02:00:59.100 --> 02:01:05.820]   I actually fell for the George to K-thing because I only got the nuzzle push notification
[02:01:06.460 --> 02:01:11.020]   to the original article and all the tweets around it. It was still so early that everyone was saying,
[02:01:11.020 --> 02:01:17.020]   "Oh my God, yes, this is so awesome." Then obviously later it was disproven,
[02:01:17.020 --> 02:01:19.900]   but I never got a second push notification telling me that.
[02:01:19.900 --> 02:01:22.780]   It's the perfect fake news story because we all want to believe it.
[02:01:22.780 --> 02:01:26.540]   Well, that's what fake news is. It reinforces our bias.
[02:01:26.540 --> 02:01:32.860]   It also wasn't a piece of news that I feel obligated to cover, which is what I find so
[02:01:32.860 --> 02:01:37.180]   infuriating about this is when you get something that actually looks like a real press release
[02:01:37.180 --> 02:01:42.940]   from the company. Everything about it seems legit, and then you still have to ask yourself,
[02:01:42.940 --> 02:01:47.100]   "Oh wait, no, this is probably not real and I won't cover it. I was so glad it was on a Saturday
[02:01:47.100 --> 02:01:52.940]   this year." We also Google's Google GNOME, Google GNOME, which is the outdoor version of Google Home.
[02:01:52.940 --> 02:01:57.260]   That was a very funny video. I have to say though, I want to give props to Snapchat
[02:01:57.820 --> 02:02:04.060]   because they did a very subtle and a very good, this was the Snapchat filter yesterday.
[02:02:04.060 --> 02:02:07.020]   It took your Snapchat picture and made it look like it was on Instagram.
[02:02:07.020 --> 02:02:18.220]   Note the likes from my mom. That's my kind of April Fool's joke, right?
[02:02:18.220 --> 02:02:21.260]   Snapchat's Instagram filter, Krista.
[02:02:21.260 --> 02:02:27.580]   On one level, you want to say, "No, don't ever let Facebook see that you've gotten to them."
[02:02:28.380 --> 02:02:33.180]   Their copying has actually gotten to you and that you care. But on the other hand,
[02:02:33.180 --> 02:02:38.380]   it's now so blatant and just lame that I appreciate the clapback.
[02:02:38.380 --> 02:02:40.940]   I do too. I think it's so awesome.
[02:02:40.940 --> 02:02:45.420]   I once wrote an April Fool's column about eye insurance predicting that Steve Jobs is going to
[02:02:45.420 --> 02:02:51.020]   launch a health insurance company just for iPhone users and the theory being that it's believable.
[02:02:51.020 --> 02:02:51.500]   That's believable.
[02:02:51.500 --> 02:02:53.740]   And actually, I got so much-- It's a self-scented group.
[02:02:53.740 --> 02:02:59.180]   I got so much mail from people who believed it that complaining, no, we're really angry at the
[02:02:59.180 --> 02:03:01.660]   fact that Apple was entering the healthcare field.
[02:03:01.660 --> 02:03:06.620]   Did anybody watch Will Arnett on Netflix Live? Their new live stream?
[02:03:06.620 --> 02:03:10.460]   Yeah. I heard him out. It was supposedly very funny.
[02:03:10.460 --> 02:03:15.340]   Is it over? Can I watch it on Netflix now? Because it was a joke, obviously.
[02:03:15.340 --> 02:03:17.340]   There's no face in the netbook live stream.
[02:03:19.500 --> 02:03:23.820]   Apparently, he was just narrating a live stream of life's biggest thrills, including
[02:03:23.820 --> 02:03:28.940]   toasters toasting, grass growing, and fans blowing.
[02:03:28.940 --> 02:03:35.340]   And on that note, ladies and gentlemen, I think we should call it a day.
[02:03:35.340 --> 02:03:35.900]   Okay.
[02:03:35.900 --> 02:03:39.100]   Larry Magad, always a pleasure to have you in studio even better.
[02:03:39.100 --> 02:03:42.460]   And I'm going to give you a plug for connect safely.org.
[02:03:42.460 --> 02:03:45.180]   Safekids.com, anything else you want to promote?
[02:03:45.180 --> 02:03:46.300]   Going to LarryThworld.com.
[02:03:46.300 --> 02:03:46.780]   They're all--
[02:03:46.780 --> 02:03:47.500]   That's your website.
[02:03:47.500 --> 02:03:48.620]   But that's my personal website.
[02:03:48.620 --> 02:03:49.180]   Yeah.
[02:03:49.180 --> 02:03:51.900]   And I used that when we have a 14-year-old.
[02:03:51.900 --> 02:03:53.980]   We wanted a contract for internet use.
[02:03:53.980 --> 02:03:54.940]   You know, you bet.
[02:03:54.940 --> 02:03:57.180]   I went right to connect safely.org.
[02:03:57.180 --> 02:03:57.660]   Thank you.
[02:03:57.660 --> 02:03:58.780]   And by the way, there's a--
[02:03:58.780 --> 02:04:03.740]   On connect safely.org, we took a swipe at the Congressional Privacy
[02:04:03.740 --> 02:04:06.380]   vote that happened the other day.
[02:04:06.380 --> 02:04:07.180]   So--
[02:04:07.180 --> 02:04:10.220]   And I do suggest you listen to the podcast with
[02:04:10.220 --> 02:04:14.620]   Minion from the federal communications.
[02:04:14.620 --> 02:04:15.580]   That's a great get.
[02:04:15.580 --> 02:04:15.980]   Yeah.
[02:04:15.980 --> 02:04:17.420]   Because she's a commissioner.
[02:04:17.420 --> 02:04:18.620]   And she was good.
[02:04:18.620 --> 02:04:19.020]   I thought--
[02:04:19.020 --> 02:04:20.460]   I always liked her a lot.
[02:04:20.460 --> 02:04:21.660]   I hope she--
[02:04:21.660 --> 02:04:22.780]   I doubt she'll stay on the commission.
[02:04:22.780 --> 02:04:26.220]   Although, weirdly, you have to appoint an equal number of Democrats and Republicans.
[02:04:26.220 --> 02:04:28.060]   Right. But right now, the chair is--
[02:04:28.060 --> 02:04:28.860]   Is the Republican.
[02:04:28.860 --> 02:04:29.260]   --is the Republican.
[02:04:29.260 --> 02:04:29.260]   Yeah.
[02:04:29.260 --> 02:04:31.260]   And as he's always the case, it's the party in power.
[02:04:31.260 --> 02:04:31.740]   That's right.
[02:04:31.740 --> 02:04:35.740]   Speaking of podcasts, Brianna Wu has a couple of great ones.
[02:04:35.740 --> 02:04:40.540]   We've got to highly recommend you go to relay.fm and check out.
[02:04:40.540 --> 02:04:44.620]   What's the one that I should--
[02:04:44.620 --> 02:04:46.300]   The one that I should be watching?
[02:04:46.300 --> 02:04:47.820]   I think Rocket is awesome.
[02:04:47.820 --> 02:04:49.260]   But you're a Georgia Dal fan.
[02:04:49.260 --> 02:04:50.540]   So the structure's also good.
[02:04:50.540 --> 02:04:52.460]   I confess a soft spot for Georgia too.
[02:04:52.460 --> 02:04:52.780]   So--
[02:04:52.780 --> 02:04:53.820]   Who doesn't like Georgia?
[02:04:53.820 --> 02:04:54.140]   I'll describe your notes.
[02:04:54.140 --> 02:04:55.340]   She's awesome.
[02:04:55.340 --> 02:04:55.900]   Who doesn't--
[02:04:55.900 --> 02:04:56.860]   You got time for two.
[02:04:56.860 --> 02:04:57.260]   Come on.
[02:04:57.260 --> 02:04:59.180]   I got a long way home.
[02:04:59.180 --> 02:04:59.980]   I can listen to a podcast.
[02:04:59.980 --> 02:05:04.780]   And Brianna Wu 2018.com, especially if you're in the Massachusetts 8th.
[02:05:04.780 --> 02:05:06.140]   That's true.
[02:05:06.140 --> 02:05:07.500]   You're going to be able to vote for her.
[02:05:07.500 --> 02:05:08.060]   Is there a--
[02:05:08.060 --> 02:05:09.580]   There's a primary first, right?
[02:05:09.580 --> 02:05:10.380]   There's a primary.
[02:05:10.380 --> 02:05:11.900]   I'm trying to primary Stephen Lynch.
[02:05:11.900 --> 02:05:13.980]   Not really a big fan of his.
[02:05:13.980 --> 02:05:16.140]   But any of your listeners, for real,
[02:05:16.140 --> 02:05:19.100]   if you want better tech policy,
[02:05:19.100 --> 02:05:21.020]   go to supportbrianna.com.
[02:05:21.020 --> 02:05:25.340]   I'm trying to not get in the pocket of corporate money
[02:05:25.340 --> 02:05:26.300]   as I'm doing this.
[02:05:26.300 --> 02:05:30.300]   And what I want to do is make technologists
[02:05:30.300 --> 02:05:33.740]   the next really sought after demographic
[02:05:33.740 --> 02:05:35.580]   with political movements.
[02:05:35.580 --> 02:05:39.500]   I'm like, donate to candidates that have good tech policy.
[02:05:39.500 --> 02:05:41.340]   And you will see tech policy improve.
[02:05:41.340 --> 02:05:42.220]   I can guarantee you.
[02:05:42.220 --> 02:05:44.780]   And when is the date for the primary?
[02:05:44.780 --> 02:05:45.980]   It's next year.
[02:05:45.980 --> 02:05:47.740]   So I believe it's in October.
[02:05:47.740 --> 02:05:49.100]   So I've got about a year and a half
[02:05:49.100 --> 02:05:51.660]   to go and shake about 30,000 hands.
[02:05:51.660 --> 02:05:52.220]   Wow.
[02:05:52.220 --> 02:05:55.180]   And yet, I'm going to go over and donate
[02:05:55.180 --> 02:05:58.380]   because I like the idea of small donors
[02:05:58.380 --> 02:06:00.620]   supporting a very important candidate
[02:06:00.620 --> 02:06:02.860]   to bring some sense into Congress.
[02:06:02.860 --> 02:06:03.500]   Are you fanners?
[02:06:03.500 --> 02:06:05.420]   Good luck to you, Brianna.
[02:06:05.420 --> 02:06:06.060]   I think that's great.
[02:06:06.060 --> 02:06:06.540]   Thank you.
[02:06:06.540 --> 02:06:07.420]   It was great having you on.
[02:06:07.420 --> 02:06:09.500]   I've been trying to get you on for ages.
[02:06:09.500 --> 02:06:11.500]   But it was all in my head.
[02:06:12.140 --> 02:06:13.900]   I heard that all I had to do was email you.
[02:06:13.900 --> 02:06:16.380]   So thanks for joining us.
[02:06:16.380 --> 02:06:17.260]   I give it every day.
[02:06:17.260 --> 02:06:18.860]   I would think I got to get Brianna on.
[02:06:18.860 --> 02:06:19.740]   I love Brianna.
[02:06:19.740 --> 02:06:21.580]   And also love Erin Griffith.
[02:06:21.580 --> 02:06:22.780]   Always great to see you.
[02:06:22.780 --> 02:06:24.300]   Thank you, Erin, for joining us.
[02:06:24.300 --> 02:06:26.300]   After your vacation, your Zen,
[02:06:26.300 --> 02:06:28.460]   I hope your Zen state is still intact.
[02:06:28.460 --> 02:06:30.140]   Find her in the future.
[02:06:30.140 --> 02:06:30.620]   Yeah, for two hours later.
[02:06:30.620 --> 02:06:32.380]   Bring the Zen state to Silicon Valley
[02:06:32.380 --> 02:06:33.180]   and leave it here.
[02:06:33.180 --> 02:06:33.740]   I could use it.
[02:06:33.740 --> 02:06:34.220]   Can use it.
[02:06:34.220 --> 02:06:35.180]   Oh, God.
[02:06:35.180 --> 02:06:37.020]   Fortune.com.
[02:06:41.020 --> 02:06:44.620]   Fortune.com/UnicornTears
[02:06:44.620 --> 02:06:47.340]   will direct you to my author page.
[02:06:47.340 --> 02:06:51.580]   Fortune.com/GettermSheet
[02:06:51.580 --> 02:06:53.340]   will direct you to the sign up page
[02:06:53.340 --> 02:06:57.660]   for my daily newsletter on deals and dealmakers.
[02:06:57.660 --> 02:06:58.140]   And by the way,
[02:06:58.140 --> 02:06:59.820]   the unicorn tears is not an April Fool's joke
[02:06:59.820 --> 02:07:01.260]   that's actually the URL,
[02:07:01.260 --> 02:07:02.300]   which is the best job.
[02:07:02.300 --> 02:07:02.940]   That is.
[02:07:02.940 --> 02:07:04.540]   And how's Larry doing on the Rubik's?
[02:07:04.540 --> 02:07:05.580]   I guess my editor gave me.
[02:07:05.580 --> 02:07:06.780]   How's he doing on the Rubik's Cube?
[02:07:06.780 --> 02:07:07.420]   Is it a little?
[02:07:07.420 --> 02:07:09.580]   He dropped this off earlier.
[02:07:09.580 --> 02:07:10.540]   Oh, nice.
[02:07:11.500 --> 02:07:12.140]   It is great.
[02:07:12.140 --> 02:07:13.580]   Solid colors all the way around.
[02:07:13.580 --> 02:07:16.460]   He solved it another two hours.
[02:07:16.460 --> 02:07:20.380]   I think we can thank a YouTube video or two for that.
[02:07:20.380 --> 02:07:21.020]   Nice.
[02:07:21.020 --> 02:07:21.580]   Very nice.
[02:07:21.580 --> 02:07:24.460]   Thanks to all of you for being here with Great Studio Audience.
[02:07:24.460 --> 02:07:25.260]   Nice to have you.
[02:07:25.260 --> 02:07:26.940]   You can email tickets at twit.tv.
[02:07:26.940 --> 02:07:29.100]   We'll be glad to get a chair out for you.
[02:07:29.100 --> 02:07:31.580]   Usually there's somebody who's really excited about the show
[02:07:31.580 --> 02:07:34.620]   and then three or four family members who are bored to tears.
[02:07:34.620 --> 02:07:37.180]   And you're all welcome.
[02:07:37.180 --> 02:07:38.220]   You can also...
[02:07:39.660 --> 02:07:40.460]   You're gonna...
[02:07:40.460 --> 02:07:41.580]   Is it over, dad?
[02:07:41.580 --> 02:07:42.140]   Is it over?
[02:07:42.140 --> 02:07:43.420]   It's almost over, isn't it?
[02:07:43.420 --> 02:07:46.380]   You can also join us on the live stream.
[02:07:46.380 --> 02:07:49.740]   We're live everywhere now, including youtube.com/twit.
[02:07:49.740 --> 02:07:50.940]   Twitch.tv/out.
[02:07:50.940 --> 02:07:51.900]   Don't tell Germany.
[02:07:51.900 --> 02:07:53.740]   Twitch.tv/twit.
[02:07:53.740 --> 02:07:55.660]   Youstream.com/twit.
[02:07:55.660 --> 02:07:57.580]   And twit.tv/live.
[02:07:57.580 --> 02:07:59.980]   Really confused the issue.
[02:07:59.980 --> 02:08:03.260]   If you're live, do join us in the chatroom at irc.twit.tv.
[02:08:03.260 --> 02:08:05.100]   We love having the kids in the back of the class.
[02:08:05.100 --> 02:08:06.620]   There are spitballs at us.
[02:08:06.620 --> 02:08:08.300]   Digital spitballs, but spitballs.
[02:08:08.300 --> 02:08:09.660]   Some of the couple of shots at me.
[02:08:09.660 --> 02:08:10.380]   Yeah, sure.
[02:08:10.380 --> 02:08:11.340]   Somebody said thank you.
[02:08:11.340 --> 02:08:11.900]   That was great.
[02:08:11.900 --> 02:08:12.860]   Yeah, no, it's great.
[02:08:12.860 --> 02:08:15.660]   And of course, if you can't watch live,
[02:08:15.660 --> 02:08:17.740]   you can always watch on the main.
[02:08:17.740 --> 02:08:19.420]   All of our shows are available.
[02:08:19.420 --> 02:08:23.500]   On the marvelous thing we call the internet twit.tv/thisweekintech
[02:08:23.500 --> 02:08:25.180]   or your favorite podcast.
[02:08:25.180 --> 02:08:27.900]   You're subscribed and get every episode.
[02:08:27.900 --> 02:08:29.740]   Thank you so much for being here.
[02:08:29.740 --> 02:08:30.780]   We'll see you next week.
[02:08:30.780 --> 02:08:31.500]   Another Twitch.
[02:08:31.500 --> 02:08:32.860]   This is amazing.
[02:08:32.860 --> 02:08:33.340]   Bye.
[02:08:33.340 --> 02:08:35.340]   [Music]
[02:08:36.220 --> 02:08:36.540]   Do the twit.
[02:08:36.540 --> 02:08:37.500]   Do the twit.
[02:08:37.500 --> 02:08:38.220]   All right.
[02:08:38.220 --> 02:08:39.660]   Do the twit, baby.
[02:08:39.660 --> 02:08:41.180]   Do the twit.
[02:08:41.180 --> 02:08:41.580]   All right.

