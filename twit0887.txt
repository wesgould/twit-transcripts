
[00:00:00.000 --> 00:00:02.500]   It's time for Twit This Week in Tech.
[00:00:02.500 --> 00:00:04.260]   Oh, you're going to like this panel.
[00:00:04.260 --> 00:00:07.340]   Brand new on Twit, Abraar Al-Hidi from CNET.
[00:00:07.340 --> 00:00:11.460]   She'll join our old favorites, Georgia Dow and Christina Warren.
[00:00:11.460 --> 00:00:15.840]   What is Amazon up to with its $1.7 billion acquisition
[00:00:15.840 --> 00:00:20.240]   of the Roomba makers, the Senate passes,
[00:00:20.240 --> 00:00:21.780]   the big infrastructure bill.
[00:00:21.780 --> 00:00:24.340]   What does this mean for electric vehicles?
[00:00:24.340 --> 00:00:27.660]   And why your absent printer has just stopped printing.
[00:00:27.660 --> 00:00:30.300]   It's all coming up next on Twit.
[00:00:30.300 --> 00:00:34.540]   Podcasts you love.
[00:00:34.540 --> 00:00:37.060]   From people you trust.
[00:00:37.060 --> 00:00:38.700]   This is Twit.
[00:00:38.700 --> 00:00:49.020]   This is Twit This Week in Tech.
[00:00:49.020 --> 00:00:54.260]   Episode 887, recorded Sunday, August 7, 2022.
[00:00:54.260 --> 00:00:57.620]   Chorizo in Space.
[00:00:57.620 --> 00:01:00.140]   This week in Tech is brought to you by Bloond.
[00:01:00.140 --> 00:01:03.460]   Bloond is on a mission to eliminate single-use plastics
[00:01:03.460 --> 00:01:06.420]   by reinventing home essentials that are good for you
[00:01:06.420 --> 00:01:07.380]   and the planet.
[00:01:07.380 --> 00:01:09.740]   Right now you can get 15% off your first order
[00:01:09.740 --> 00:01:13.580]   when you go to bloond.com/twit.
[00:01:13.580 --> 00:01:15.620]   And by podium.
[00:01:15.620 --> 00:01:19.460]   Join more than 100,000 businesses that already use podium
[00:01:19.460 --> 00:01:22.060]   to streamline their customer interactions.
[00:01:22.060 --> 00:01:24.140]   See how podium can grow your business.
[00:01:24.140 --> 00:01:28.500]   Watch a demo today at podium.com/twit.
[00:01:28.500 --> 00:01:30.980]   And by userway.org.
[00:01:30.980 --> 00:01:34.260]   Userway is the world's number one accessibility solution
[00:01:34.260 --> 00:01:37.100]   committed to enabling the fundamental human right
[00:01:37.100 --> 00:01:40.260]   of digital accessibility for everyone.
[00:01:40.260 --> 00:01:42.300]   When you're ready to make your site compliant,
[00:01:42.300 --> 00:01:45.420]   deciding which solution to use, it's an easy choice to make.
[00:01:45.420 --> 00:01:48.380]   Go to userway.org/twit for 30% off
[00:01:48.380 --> 00:01:51.620]   userway's AI-powered accessibility solution.
[00:01:51.620 --> 00:01:55.260]   [MUSIC PLAYING]
[00:01:55.260 --> 00:01:57.220]   It's time for Twit this week in Tech,
[00:01:57.220 --> 00:02:00.180]   the show we cover the latest tech news
[00:02:00.180 --> 00:02:03.900]   with a panel of fabulously brilliant people.
[00:02:03.900 --> 00:02:05.940]   And I'm happy to say we did it again.
[00:02:05.940 --> 00:02:08.980]   I don't know how it happens, but magically our producer, Jason
[00:02:08.980 --> 00:02:10.900]   Hallows, put together a wonderful panel,
[00:02:10.900 --> 00:02:16.020]   starting with Georgia Dow from youtube.com/georgydow.
[00:02:16.020 --> 00:02:17.100]   And West Mount Therapy.
[00:02:17.100 --> 00:02:18.900]   Hello, Georgia.
[00:02:18.900 --> 00:02:20.140]   Hello.
[00:02:20.140 --> 00:02:22.580]   You are preparing your final segment
[00:02:22.580 --> 00:02:24.700]   on the boys at Therapist Reacts, I think.
[00:02:24.700 --> 00:02:28.140]   On the boys, I am doing own war.
[00:02:28.140 --> 00:02:29.140]   Nice.
[00:02:29.140 --> 00:02:30.740]   And you've got a bird in your hair.
[00:02:30.740 --> 00:02:31.220]   What is that?
[00:02:31.220 --> 00:02:31.580]   A bird?
[00:02:31.580 --> 00:02:32.860]   I have a bird in my hair.
[00:02:32.860 --> 00:02:33.700]   It's a bird.
[00:02:33.700 --> 00:02:34.200]   OK.
[00:02:34.200 --> 00:02:34.700]   The birds.
[00:02:34.700 --> 00:02:35.420]   Some will know.
[00:02:35.420 --> 00:02:36.900]   Some will not know.
[00:02:36.900 --> 00:02:37.620]   I do not know.
[00:02:37.620 --> 00:02:38.700]   I've only seen season one.
[00:02:38.700 --> 00:02:40.100]   I've got to catch up.
[00:02:40.100 --> 00:02:41.740]   You've got to eat that like, watch the fun.
[00:02:41.740 --> 00:02:45.780]   Should you watch the show before you watch Therapist Reacts?
[00:02:45.780 --> 00:02:49.020]   You should, because they'll be spoilers if you don't already
[00:02:49.020 --> 00:02:49.220]   know.
[00:02:49.220 --> 00:02:50.820]   Some people do, because they're just there.
[00:02:50.820 --> 00:02:53.340]   Like, I watch a show, and then I go through the psychology
[00:02:53.340 --> 00:02:53.900]   of the show.
[00:02:53.900 --> 00:02:56.660]   So when we do-- sorry, Black Noir, I think I said own war,
[00:02:56.660 --> 00:02:58.540]   because there's a restaurant that I love in Montreal.
[00:02:58.540 --> 00:03:00.140]   Close.
[00:03:00.140 --> 00:03:00.660]   It's close.
[00:03:00.660 --> 00:03:02.220]   It's similar, not the same.
[00:03:02.220 --> 00:03:04.420]   But yeah, so you should-- some people
[00:03:04.420 --> 00:03:06.300]   watch-- just watch it for the psychology aspects,
[00:03:06.300 --> 00:03:07.380]   because that's what I deal with.
[00:03:07.380 --> 00:03:09.380]   I just go through what is the psychology,
[00:03:09.380 --> 00:03:12.380]   and I usually choose a certain aspect of psychology
[00:03:12.380 --> 00:03:14.660]   to be able to deal with through a character on a show.
[00:03:14.660 --> 00:03:16.460]   So it's a fun way to be educated on--
[00:03:16.460 --> 00:03:19.060]   Do you find-- I mean, I would guess this is probably
[00:03:19.060 --> 00:03:21.780]   true for people who write TV shows,
[00:03:21.780 --> 00:03:24.700]   that they have to understand, at least intuitively,
[00:03:24.700 --> 00:03:27.100]   have to understand psychology.
[00:03:27.100 --> 00:03:28.620]   Do you find that the psychology--
[00:03:28.620 --> 00:03:30.260]   there's Black Noir, by the way--
[00:03:30.260 --> 00:03:33.380]   that the psychology is pretty accurate?
[00:03:33.380 --> 00:03:36.060]   For a lot of shows, it's exceptionally accurate.
[00:03:36.060 --> 00:03:36.560]   Yeah.
[00:03:36.560 --> 00:03:37.980]   I think that they do a really good job.
[00:03:37.980 --> 00:03:39.820]   I think that a lot of shows hire people like me
[00:03:39.820 --> 00:03:41.340]   to make sure that the psychology--
[00:03:41.340 --> 00:03:41.820]   No, interesting.
[00:03:41.820 --> 00:03:42.660]   --notches up.
[00:03:42.660 --> 00:03:44.780]   And there are some shows that the psych--
[00:03:44.780 --> 00:03:45.860]   like it's spot on.
[00:03:45.860 --> 00:03:47.620]   Like, they're kind of hitting all the marks,
[00:03:47.620 --> 00:03:50.100]   and I can really go through different sets of--
[00:03:50.100 --> 00:03:51.940]   like, the actors are doing a really great job
[00:03:51.940 --> 00:03:53.140]   of portraying the feelings.
[00:03:53.140 --> 00:03:55.340]   And there's even some animations that they've just
[00:03:55.340 --> 00:03:57.140]   done, such like arcane, that they've
[00:03:57.140 --> 00:03:59.580]   done just such an amazing job at making sure
[00:03:59.580 --> 00:04:01.860]   that all of the emotions come through,
[00:04:01.860 --> 00:04:04.940]   and they understand why their character is doing what they
[00:04:04.940 --> 00:04:06.660]   were doing, and for what reasons for it.
[00:04:06.660 --> 00:04:07.740]   And there's probably--
[00:04:07.740 --> 00:04:08.220]   And there's probably--
[00:04:08.220 --> 00:04:09.900]   If you're watching a show, and somebody
[00:04:09.900 --> 00:04:12.500]   does something that's psychologically wrong,
[00:04:12.500 --> 00:04:15.420]   and somehow doesn't match up, you probably
[00:04:15.420 --> 00:04:18.180]   make-- you may not know why, but you may go,
[00:04:18.180 --> 00:04:19.100]   this doesn't feel right.
[00:04:19.100 --> 00:04:20.660]   Like, that's not how somebody would really
[00:04:20.660 --> 00:04:21.700]   behave in real life.
[00:04:21.700 --> 00:04:22.200]   Yeah.
[00:04:22.200 --> 00:04:22.700]   Yeah.
[00:04:22.700 --> 00:04:24.820]   And for me, it really bothers me, right?
[00:04:24.820 --> 00:04:27.540]   Like, if someone has some sort of an issue with something,
[00:04:27.540 --> 00:04:29.220]   and then they forget it in between,
[00:04:29.220 --> 00:04:30.700]   and I'm like, hey, wouldn't be touching that.
[00:04:30.700 --> 00:04:32.260]   They're already-- they're germophobic.
[00:04:32.260 --> 00:04:33.300]   They wouldn't be touching this.
[00:04:33.300 --> 00:04:36.260]   It doesn't fit with all of the mythos of their character.
[00:04:36.260 --> 00:04:38.900]   And it psychologically kind of pulls us out, right?
[00:04:38.900 --> 00:04:40.940]   It causes that disjoint in our mind
[00:04:40.940 --> 00:04:44.420]   to be able to be like, that doesn't really fit.
[00:04:44.420 --> 00:04:46.660]   And that cognitive dissonance kind of stops us
[00:04:46.660 --> 00:04:48.180]   from being fully immersed.
[00:04:48.180 --> 00:04:50.140]   Makes sense.
[00:04:50.140 --> 00:04:52.620]   But this is an embarrassment of riches today,
[00:04:52.620 --> 00:04:53.740]   because not only do we have Georgia,
[00:04:53.740 --> 00:04:55.980]   that we also have Christina Warren,
[00:04:55.980 --> 00:04:58.940]   now senior developer advocate at KitHub,
[00:04:58.940 --> 00:05:00.620]   and owner of many fine kicks.
[00:05:00.620 --> 00:05:02.580]   Hello, so Christina.
[00:05:02.580 --> 00:05:03.780]   Hey, Leo.
[00:05:03.780 --> 00:05:06.860]   Your shoe rack looks very shiny.
[00:05:06.860 --> 00:05:07.740]   It is shiny.
[00:05:07.740 --> 00:05:10.020]   As people have already noted in the chat,
[00:05:10.020 --> 00:05:12.060]   some of the shoes are missing.
[00:05:12.060 --> 00:05:15.700]   But look, at least we're in the process of getting things
[00:05:15.700 --> 00:05:16.500]   sort of--
[00:05:16.500 --> 00:05:18.820]   Like, there's a pump on the third row.
[00:05:18.820 --> 00:05:20.620]   There's only one of them.
[00:05:20.620 --> 00:05:22.820]   There is, and it's probably someplace else,
[00:05:22.820 --> 00:05:23.820]   and I don't even think--
[00:05:23.820 --> 00:05:26.820]   No, no, I actually sort of think there's a story to tell.
[00:05:26.820 --> 00:05:27.340]   Probably.
[00:05:27.340 --> 00:05:28.020]   Like Cinderella.
[00:05:28.020 --> 00:05:30.220]   You only have one shoe.
[00:05:30.220 --> 00:05:32.100]   It was a great party.
[00:05:32.100 --> 00:05:33.420]   Right.
[00:05:33.420 --> 00:05:34.140]   It's really good.
[00:05:34.140 --> 00:05:36.820]   It had a really good time, and I came home without a shoe.
[00:05:36.820 --> 00:05:40.940]   Which actually I think has happened to me before,
[00:05:40.940 --> 00:05:43.300]   where I've come home with a missing shoe.
[00:05:43.300 --> 00:05:45.700]   But yeah, no, I mean, at least this is better.
[00:05:45.700 --> 00:05:48.500]   We're working on-- I'm working on my office.
[00:05:48.500 --> 00:05:51.260]   At some point in the future, I'll have a really nice looking
[00:05:51.260 --> 00:05:54.220]   setup like Georgia does, but not quite there yet.
[00:05:54.220 --> 00:05:55.060]   With pictures of like one.
[00:05:55.060 --> 00:05:56.140]   Did you see that I had to pause?
[00:05:56.140 --> 00:05:58.900]   No, I had to pause to be able to clear out--
[00:05:58.900 --> 00:06:00.780]   like I bought like these giant wings.
[00:06:00.780 --> 00:06:03.220]   Anyways, they're-- I have to clear out some stuff,
[00:06:03.220 --> 00:06:04.820]   so it wasn't that great.
[00:06:04.820 --> 00:06:07.620]   Usually, they only see this much.
[00:06:07.620 --> 00:06:08.620]   It's hard.
[00:06:08.620 --> 00:06:09.120]   It's hard.
[00:06:09.120 --> 00:06:10.380]   It's very hard.
[00:06:10.380 --> 00:06:14.140]   And I hope that poor Abrau al Heedie is not now thinking,
[00:06:14.140 --> 00:06:16.940]   oh my god, they're going to be analyzing my background.
[00:06:16.940 --> 00:06:18.020]   I will, but--
[00:06:18.020 --> 00:06:19.860]   Yeah, they're thinking about those blinds.
[00:06:19.860 --> 00:06:21.780]   I could tell you right now, Abrau al Heedie.
[00:06:21.780 --> 00:06:22.420]   That one's annoying.
[00:06:22.420 --> 00:06:24.420]   Video producer at CNET.
[00:06:24.420 --> 00:06:26.020]   Yeah, we want to just touch that one.
[00:06:26.020 --> 00:06:27.220]   We want to just pop out.
[00:06:27.220 --> 00:06:28.220]   That's like sticking out.
[00:06:28.220 --> 00:06:30.420]   It's kind of bothering me now.
[00:06:30.420 --> 00:06:31.580]   Oh my god.
[00:06:31.580 --> 00:06:33.380]   Now that's what everyone's going to notice.
[00:06:33.380 --> 00:06:33.820]   I'm sorry.
[00:06:33.820 --> 00:06:35.380]   I'm so sorry.
[00:06:35.380 --> 00:06:36.620]   Don't listen to anything we say.
[00:06:36.620 --> 00:06:37.140]   Just--
[00:06:37.140 --> 00:06:40.620]   I warned you, Abrau, we have a fairly OCD audience.
[00:06:40.620 --> 00:06:44.340]   They already noticed missing shoes from Christina's rack.
[00:06:44.340 --> 00:06:46.340]   Yeah, I think they're going to be bothered by that blind
[00:06:46.340 --> 00:06:47.460]   for the rest of the show.
[00:06:47.460 --> 00:06:48.820]   Yeah, my apologies.
[00:06:48.820 --> 00:06:52.380]   Abrau works for CNET internet trends, entertainment, pop
[00:06:52.380 --> 00:06:54.940]   culture, digital accessibility.
[00:06:54.940 --> 00:06:57.740]   And as Christina noted, she hiles
[00:06:57.740 --> 00:07:01.100]   from the home of Mozilla or Bana Champagne in Illinois.
[00:07:01.100 --> 00:07:01.580]   That's right.
[00:07:01.580 --> 00:07:02.220]   Yes.
[00:07:02.220 --> 00:07:02.620]   Great to have you.
[00:07:02.620 --> 00:07:03.740]   How to?
[00:07:03.740 --> 00:07:04.860]   Thank you so much for having me.
[00:07:04.860 --> 00:07:06.380]   I appreciate it.
[00:07:06.380 --> 00:07:07.180]   Amazon.
[00:07:07.180 --> 00:07:07.540]   All right.
[00:07:07.540 --> 00:07:09.820]   This is a really interesting story.
[00:07:09.820 --> 00:07:12.420]   And I think there are a lot of ramifications.
[00:07:12.420 --> 00:07:15.980]   On the surface of it, Amazon's going to buy Roomba.
[00:07:15.980 --> 00:07:19.580]   I-Robot, they make the Roomba vacuum, robot vacuum.
[00:07:19.580 --> 00:07:21.460]   $1.7 billion.
[00:07:21.460 --> 00:07:23.420]   Seems like a good business.
[00:07:23.420 --> 00:07:28.580]   But there was a very good article I thought in Wired
[00:07:28.580 --> 00:07:30.460]   that maybe it's conspiracy theory.
[00:07:30.460 --> 00:07:32.820]   I'd like to know what y'all think.
[00:07:32.820 --> 00:07:38.340]   I-Robot deal would give Amazon maps inside millions of homes.
[00:07:38.340 --> 00:07:40.620]   It ain't the dust, writes Carrie Johnson.
[00:07:40.620 --> 00:07:43.140]   It's the data.
[00:07:43.140 --> 00:07:47.940]   Christina, is there more to this acquisition?
[00:07:47.940 --> 00:07:50.820]   I mean, I definitely think the data is part of it, right?
[00:07:50.820 --> 00:07:52.700]   I don't know if that was the impetus
[00:07:52.700 --> 00:07:54.660]   between why they were buying I-Robot.
[00:07:54.660 --> 00:07:56.860]   I have to think that they were also--
[00:07:56.860 --> 00:07:59.060]   I mean, because Amazon had been kind of in this space, too,
[00:07:59.060 --> 00:08:00.780]   and to try to sell competitors.
[00:08:00.780 --> 00:08:02.540]   Did they have a robot vacuum?
[00:08:02.540 --> 00:08:03.740]   It feels like they might have.
[00:08:03.740 --> 00:08:04.260]   Yeah.
[00:08:04.260 --> 00:08:04.460]   Yeah.
[00:08:04.460 --> 00:08:05.300]   They definitely did.
[00:08:05.300 --> 00:08:08.900]   And definitely, I mean, with their big IoT push
[00:08:08.900 --> 00:08:09.980]   and with the ring.
[00:08:09.980 --> 00:08:12.540]   Sidewalk and the ring door, though.
[00:08:12.540 --> 00:08:13.100]   It's exactly--
[00:08:13.100 --> 00:08:14.220]   That's what Carrie says.
[00:08:14.220 --> 00:08:18.340]   They bought the Euro in 2019, Ring in 2018.
[00:08:18.340 --> 00:08:20.500]   Of course, they've got-- in most homes,
[00:08:20.500 --> 00:08:25.820]   they've got an Amazon Echo or two with microphones and cameras.
[00:08:25.820 --> 00:08:28.380]   So it does look like--
[00:08:28.380 --> 00:08:30.580]   maybe it's a coin-keating.
[00:08:30.580 --> 00:08:32.740]   Kyle looks like they're putting together some sort
[00:08:32.740 --> 00:08:36.180]   of portfolio of data about me.
[00:08:36.180 --> 00:08:36.500]   Yeah.
[00:08:36.500 --> 00:08:39.420]   I mean, and certainly, I could see areas
[00:08:39.420 --> 00:08:42.060]   where it could be interesting if you had even just
[00:08:42.060 --> 00:08:44.820]   an ancillary data about the layout's appeal, houses
[00:08:44.820 --> 00:08:45.380]   and whatnot.
[00:08:45.380 --> 00:08:47.100]   If you're in the business of maybe
[00:08:47.100 --> 00:08:48.460]   wanting to sell furniture, I don't know,
[00:08:48.460 --> 00:08:50.940]   or selling electronics or selling other things
[00:08:50.940 --> 00:08:54.940]   and wanting to-- Amazon wants to be the store for everything,
[00:08:54.940 --> 00:08:56.860]   I don't think that there's an argument
[00:08:56.860 --> 00:08:58.460]   that you can make that having this data wouldn't
[00:08:58.460 --> 00:09:00.500]   be potentially useful.
[00:09:00.500 --> 00:09:02.780]   I don't know, though, if that's the only reason why they're
[00:09:02.780 --> 00:09:05.300]   buying this company, if that makes sense.
[00:09:05.300 --> 00:09:08.260]   Abraar, it makes me, though, think that Amazon is not
[00:09:08.260 --> 00:09:13.100]   the innocent internet storefront that we've thought it was.
[00:09:13.100 --> 00:09:15.140]   Yeah, I think it's so fascinating to see
[00:09:15.140 --> 00:09:17.380]   how it's gone from a place where you can kind of conveniently
[00:09:17.380 --> 00:09:19.740]   buy things at a lower price to, oh, my god,
[00:09:19.740 --> 00:09:22.460]   they know everything about what I'm buying, what I'm watching,
[00:09:22.460 --> 00:09:24.460]   what I'm reading, what I'm listening to.
[00:09:24.460 --> 00:09:27.100]   And they're in so many different facets of our lives now.
[00:09:27.100 --> 00:09:29.580]   And I think we kind of like woke up one day
[00:09:29.580 --> 00:09:31.020]   and were like, oh, my god.
[00:09:31.020 --> 00:09:34.500]   I think most people didn't really realize how quickly
[00:09:34.500 --> 00:09:35.460]   it all kind of ramped up.
[00:09:35.460 --> 00:09:37.460]   And now it kind of feels like it spiraling out of control.
[00:09:37.460 --> 00:09:39.500]   And to think, oh, my god, they would know the layout of my home
[00:09:39.500 --> 00:09:41.380]   just feels incredibly intrusive.
[00:09:41.380 --> 00:09:42.900]   Remember that Roomba got in--
[00:09:42.900 --> 00:09:45.100]   or I, Roomba got a little trouble when people realized
[00:09:45.100 --> 00:09:46.700]   that those maps, that the Roomba has
[00:09:46.700 --> 00:09:51.020]   to make at a necessity of where the dog dish is,
[00:09:51.020 --> 00:09:53.620]   where the sofa is, where your kitchen is,
[00:09:53.620 --> 00:09:56.260]   so that it can navigate those spaces.
[00:09:56.260 --> 00:09:58.540]   We're getting uploaded to iRobot.
[00:09:58.540 --> 00:10:02.380]   And that's when people went, wait a minute, why?
[00:10:02.380 --> 00:10:05.020]   I don't know if I Roomba ever sufficiently explained it.
[00:10:05.020 --> 00:10:08.020]   They certainly didn't stop doing it.
[00:10:08.020 --> 00:10:09.820]   But then I guess the question is, well, what--
[00:10:09.820 --> 00:10:13.420]   I mean, so what if Amazon has a map of my house?
[00:10:13.420 --> 00:10:17.380]   I mean, what are they going to do with it?
[00:10:17.380 --> 00:10:18.380]   Do this so--
[00:10:18.380 --> 00:10:18.900]   I'm going to find out.
[00:10:18.900 --> 00:10:22.620]   Because it becomes one more piece of information
[00:10:22.620 --> 00:10:25.860]   that a company has that did not disclose it beforehand.
[00:10:25.860 --> 00:10:28.140]   Like I think that Facebook has taken a whole brunt
[00:10:28.140 --> 00:10:32.700]   of damage control on misusing all of our information.
[00:10:32.700 --> 00:10:36.260]   Amazon's kind of been really quiet about it,
[00:10:36.260 --> 00:10:39.260]   just taking the information and not really said anything.
[00:10:39.260 --> 00:10:43.460]   Because when you put all of that information together,
[00:10:43.460 --> 00:10:45.900]   they really know--
[00:10:45.900 --> 00:10:47.660]   I won't say almost everything about us,
[00:10:47.660 --> 00:10:50.060]   but almost everything about us.
[00:10:50.060 --> 00:10:50.560]   Yeah.
[00:10:50.560 --> 00:10:52.340]   So that's the layout of the house.
[00:10:52.340 --> 00:10:55.860]   They just bought one medical for 3.49 billion.
[00:10:55.860 --> 00:10:57.340]   That one bothers me more.
[00:10:57.340 --> 00:10:58.180]   That one bothers me more.
[00:10:58.180 --> 00:10:59.420]   They get all those health records.
[00:10:59.420 --> 00:11:01.780]   I'm sure they're protected somehow by HIPAA.
[00:11:01.780 --> 00:11:06.860]   But still, it does not look like Amazon
[00:11:06.860 --> 00:11:10.420]   is building a portfolio of products it can sell.
[00:11:10.420 --> 00:11:13.140]   And in fact-- so when Amazon first started,
[00:11:13.140 --> 00:11:15.020]   that was kind of the idea was--
[00:11:15.020 --> 00:11:17.900]   in fact, I think they said the world's largest bookstore
[00:11:17.900 --> 00:11:18.660]   or something like that.
[00:11:18.660 --> 00:11:21.500]   The idea was, hey, we're going to be the best retail ever.
[00:11:21.500 --> 00:11:25.580]   But then-- and we've got more mature on our thinking about it.
[00:11:25.580 --> 00:11:27.380]   And I think Brad Stone's book's about Amazon
[00:11:27.380 --> 00:11:28.620]   got me thinking about.
[00:11:28.620 --> 00:11:32.380]   And at one point, I think Stone says, well, what Amazon really
[00:11:32.380 --> 00:11:35.180]   wants to do is own a small piece of every transaction.
[00:11:35.180 --> 00:11:38.940]   Like a couple of pennies every time you buy something online,
[00:11:38.940 --> 00:11:41.220]   that's a good living.
[00:11:41.220 --> 00:11:42.860]   Then they became an advertising company.
[00:11:42.860 --> 00:11:44.140]   In fact, they're quarterly results show
[00:11:44.140 --> 00:11:45.220]   that they're very good at that.
[00:11:45.220 --> 00:11:46.780]   They make a lot of money in advertising.
[00:11:46.780 --> 00:11:48.500]   And well, what's their biggest business?
[00:11:48.500 --> 00:11:56.020]   The US, which is network cloud stuff, selling cloud access
[00:11:56.020 --> 00:11:57.500]   to people.
[00:11:57.500 --> 00:11:59.660]   I don't know how that fits in.
[00:11:59.660 --> 00:12:03.340]   But then all these acquisitions, it really looks like Amazon.
[00:12:03.340 --> 00:12:05.780]   Isn't necessarily a bookstore.
[00:12:05.780 --> 00:12:11.660]   Isn't necessarily a Visa card, a transaction collector.
[00:12:11.660 --> 00:12:13.940]   That they're somehow building--
[00:12:13.940 --> 00:12:15.020]   I don't know.
[00:12:15.020 --> 00:12:16.220]   It's unclear in my mind.
[00:12:16.220 --> 00:12:20.820]   But they're somehow building a dossier about everybody.
[00:12:20.820 --> 00:12:22.620]   What would they use that for?
[00:12:22.620 --> 00:12:25.220]   What could that be?
[00:12:25.220 --> 00:12:27.820]   There's a lot of information that isn't shown.
[00:12:27.820 --> 00:12:30.580]   It's the rooms that we choose that we want to clean.
[00:12:30.580 --> 00:12:32.940]   It's the rooms that we use the most of.
[00:12:32.940 --> 00:12:37.540]   It's where furniture is placed to be able to sell things.
[00:12:37.540 --> 00:12:39.540]   It's where people usually travel to.
[00:12:39.540 --> 00:12:43.660]   It's economic status because larger houses, larger spaces
[00:12:43.660 --> 00:12:45.700]   of where people are located.
[00:12:45.700 --> 00:12:50.180]   It's how much people purchase in certain sized homes.
[00:12:50.180 --> 00:12:52.580]   And I think that my biggest issue, though,
[00:12:52.580 --> 00:12:53.980]   isn't even the data.
[00:12:53.980 --> 00:12:58.020]   It's that when you sign a privacy policy for a company
[00:12:58.020 --> 00:13:00.660]   that you trust, and you're all comfortable,
[00:13:00.660 --> 00:13:03.620]   but then they get bought out all of your information
[00:13:03.620 --> 00:13:06.380]   that you believed was secure because you trusted the company.
[00:13:06.380 --> 00:13:09.220]   Now is in whatever some nefarious company
[00:13:09.220 --> 00:13:10.940]   or non-nefarious company's hand.
[00:13:10.940 --> 00:13:12.140]   And it changes everything.
[00:13:12.140 --> 00:13:14.340]   And we don't have a right to say, you know what?
[00:13:14.340 --> 00:13:16.980]   I now want to-- you know, there's no sandbox
[00:13:16.980 --> 00:13:17.900]   around my information.
[00:13:17.900 --> 00:13:19.700]   It's just kind of given away.
[00:13:19.700 --> 00:13:23.860]   And it's like we've been sold off to the highest bidder
[00:13:23.860 --> 00:13:26.260]   whoever that person might be when we actually
[00:13:26.260 --> 00:13:28.380]   signed a contract with someone else.
[00:13:28.380 --> 00:13:31.380]   And there is no contract law that really protects us
[00:13:31.380 --> 00:13:34.180]   and allows us to revoke access to the data that we've already
[00:13:34.180 --> 00:13:37.700]   given away in a trusted situation.
[00:13:37.700 --> 00:13:39.380]   Well, I don't know how much people trusted Roomba
[00:13:39.380 --> 00:13:41.500]   to save those maps anyway.
[00:13:41.500 --> 00:13:43.980]   I mean, I don't think anyone knew
[00:13:43.980 --> 00:13:45.180]   that they were being mapped.
[00:13:45.180 --> 00:13:45.700]   Right.
[00:13:45.700 --> 00:13:47.740]   I didn't know that when I had my Roomba at all.
[00:13:47.740 --> 00:13:49.540]   I mean, if you think about it, you realize that's how--
[00:13:49.540 --> 00:13:51.420]   --that it has to do that, right?
[00:13:51.420 --> 00:13:52.260]   It has to kind of--
[00:13:52.260 --> 00:13:53.140]   It has to upload it.
[00:13:53.140 --> 00:13:55.300]   It has to know itself because what they say--
[00:13:55.300 --> 00:13:56.340]   Exactly.
[00:13:56.340 --> 00:13:59.060]   When you read it, they say that the Roomba takes a look
[00:13:59.060 --> 00:14:01.900]   at the area and then goes back and forth
[00:14:01.900 --> 00:14:04.700]   and kind of remembers it does not tell you,
[00:14:04.700 --> 00:14:06.860]   at least when I had my Roomba, it did not tell me.
[00:14:06.860 --> 00:14:08.740]   And I actually read privacy policies
[00:14:08.740 --> 00:14:11.580]   because I'm nerdy that way, that it did not tell me
[00:14:11.580 --> 00:14:13.340]   that it's uploading and saving that data
[00:14:13.340 --> 00:14:15.940]   and could sell that off to a third party.
[00:14:15.940 --> 00:14:18.340]   Well, I remember Amazon--
[00:14:18.340 --> 00:14:19.940]   I think they did sell a few of them.
[00:14:19.940 --> 00:14:22.780]   Built this robot Astro that would know where your kitchen is.
[00:14:22.780 --> 00:14:26.220]   So you could say Astro go to the kitchen.
[00:14:26.220 --> 00:14:29.260]   I mean, really, I mean, if they're not intentionally
[00:14:29.260 --> 00:14:32.980]   trying to build this very complete map of everything
[00:14:32.980 --> 00:14:38.620]   I buy, own, do, am, then by accident they're doing this.
[00:14:38.620 --> 00:14:41.340]   But it sure looks like it's intentional.
[00:14:41.340 --> 00:14:45.940]   So is that a problem?
[00:14:45.940 --> 00:14:48.420]   I think it's-- I think the thing that a lot of people
[00:14:48.420 --> 00:14:50.660]   are growing increasingly uncomfortable with
[00:14:50.660 --> 00:14:54.340]   is that Georgia, I love that you read the privacy policies
[00:14:54.340 --> 00:14:54.980]   of these companies.
[00:14:54.980 --> 00:14:58.500]   I think a lot of people don't necessarily do that.
[00:14:58.500 --> 00:15:02.180]   And I think they use these products or services
[00:15:02.180 --> 00:15:05.380]   and then realize, how much am I giving away with all of this?
[00:15:05.380 --> 00:15:08.060]   And I think we're kind of feeling inundated with the fact
[00:15:08.060 --> 00:15:10.860]   that any platform you use, any service you use,
[00:15:10.860 --> 00:15:13.340]   you're giving away so much more information
[00:15:13.340 --> 00:15:14.340]   than you would feel comfortable with.
[00:15:14.340 --> 00:15:17.100]   And you kind of feel helpless in the sense that there
[00:15:17.100 --> 00:15:19.700]   is a beauty to having a sense of privacy
[00:15:19.700 --> 00:15:23.300]   and not feeling like your data is being used to sell products
[00:15:23.300 --> 00:15:25.340]   or services to get more of your money.
[00:15:25.340 --> 00:15:27.180]   It just kind of feels like this endless spiral.
[00:15:27.180 --> 00:15:29.820]   So I think just knowing how much they
[00:15:29.820 --> 00:15:31.660]   know about you is incredibly uncomfortable.
[00:15:31.660 --> 00:15:34.980]   And companies like Amazon will only continue to grow
[00:15:34.980 --> 00:15:40.140]   and only continue to glean more information about each of us.
[00:15:40.140 --> 00:15:41.940]   Sorry, I just sneezed.
[00:15:41.940 --> 00:15:43.140]   I'm going to bless you.
[00:15:43.140 --> 00:15:49.460]   Yeah, so I go back and forth on privacy.
[00:15:49.460 --> 00:15:52.380]   And on the one hand, if all Amazon's going to do
[00:15:52.380 --> 00:15:55.220]   is use this to put better recommendations
[00:15:55.220 --> 00:15:57.060]   at the bottom of the Amazon.com page,
[00:15:57.060 --> 00:16:00.140]   I think that's relatively harmless.
[00:16:00.140 --> 00:16:03.540]   But then I also start to look at stories about, for instance,
[00:16:03.540 --> 00:16:08.060]   the government buying information from data brokers
[00:16:08.060 --> 00:16:12.860]   that some data brokers are selling for 150, 160 bucks,
[00:16:12.860 --> 00:16:15.660]   a list of all the people who went to visit an abortion clinic
[00:16:15.660 --> 00:16:17.700]   in the last six weeks, that kind of thing.
[00:16:17.700 --> 00:16:23.820]   And I start to realize that potentially this becomes harmful.
[00:16:23.820 --> 00:16:28.060]   I don't think Amazon is thinking, what could we sell the government?
[00:16:28.060 --> 00:16:28.900]   Well, yes and no.
[00:16:28.900 --> 00:16:31.500]   I mean, you look at the fact that a ring--
[00:16:31.500 --> 00:16:34.580]   and some of this might have had carve outs before Amazon acquired
[00:16:34.580 --> 00:16:37.820]   them, but a ring will give your data over to the police.
[00:16:37.820 --> 00:16:40.180]   And which bothers me on a lot of levels.
[00:16:40.180 --> 00:16:43.860]   Even if you opt out, the police can still
[00:16:43.860 --> 00:16:46.260]   kind of get into these programs where without a search warrant,
[00:16:46.260 --> 00:16:49.060]   they can get access to this ring data.
[00:16:49.060 --> 00:16:51.540]   What bothers me about that is if you as an individual
[00:16:51.540 --> 00:16:55.980]   want to offer some of your camera information, fine.
[00:16:55.980 --> 00:16:58.860]   But ring is taking video footage of people
[00:16:58.860 --> 00:17:00.340]   who are in your surrounding area
[00:17:00.340 --> 00:17:02.660]   and is also collating things with people
[00:17:02.660 --> 00:17:04.140]   who haven't opted into that.
[00:17:04.140 --> 00:17:08.260]   So I have very, very big problems with that happening at all.
[00:17:08.260 --> 00:17:12.340]   I think that if the police want to get information from someone's
[00:17:12.340 --> 00:17:15.180]   security system, regardless of whether it's cloud-based or local,
[00:17:15.180 --> 00:17:17.100]   I think they need to have a warrant for that period.
[00:17:17.100 --> 00:17:19.580]   I don't think that you should have companies
[00:17:19.580 --> 00:17:22.860]   like the ring and Amazon by extension just passing it over.
[00:17:22.860 --> 00:17:25.140]   I think that that is a massive violation.
[00:17:25.140 --> 00:17:27.940]   And so if you look at that perspective and you're saying,
[00:17:27.940 --> 00:17:29.340]   well, they'll do it in this instance.
[00:17:29.340 --> 00:17:31.540]   And we know that they also will, without warrants,
[00:17:31.540 --> 00:17:36.500]   in some context, give Alexa information over to law enforcement,
[00:17:36.500 --> 00:17:39.500]   then I do have concerns about what other information
[00:17:39.500 --> 00:17:42.140]   they have collected on me and how willing they will be
[00:17:42.140 --> 00:17:47.740]   to provide it to people under whatever justification
[00:17:47.740 --> 00:17:48.900]   they want to give it to.
[00:17:48.900 --> 00:17:53.540]   And personally, I think that is more troubling in some regards
[00:17:53.540 --> 00:17:55.620]   to say we're going to give it to law enforcement
[00:17:55.620 --> 00:17:58.940]   without warrants than we would be to sell it to advertisers.
[00:17:58.940 --> 00:18:01.140]   Although I do think that selling it to advertisers
[00:18:01.140 --> 00:18:02.980]   and selling it to government entities
[00:18:02.980 --> 00:18:04.300]   is a massive problem too.
[00:18:04.300 --> 00:18:07.860]   But the fact that you have a very large company like Amazon,
[00:18:07.860 --> 00:18:09.460]   but you could say the same thing for Google.
[00:18:09.460 --> 00:18:10.620]   You could say it for Microsoft.
[00:18:10.620 --> 00:18:12.620]   Yeah, Google does, by the way, the same thing.
[00:18:12.620 --> 00:18:13.180]   100%.
[00:18:13.180 --> 00:18:14.180]   You could say it for Meta.
[00:18:14.180 --> 00:18:17.060]   The fact that they collect all this information about us
[00:18:17.060 --> 00:18:20.540]   and that it exists anywhere where it is, regardless
[00:18:20.540 --> 00:18:23.100]   of what they say, there's a way that they can have it tied
[00:18:23.100 --> 00:18:24.580]   to an individual identity.
[00:18:24.580 --> 00:18:26.420]   And that can be tied to a person.
[00:18:26.420 --> 00:18:28.620]   I think that should cause us to have concerns,
[00:18:28.620 --> 00:18:31.500]   even if we are resigned as I basically am,
[00:18:31.500 --> 00:18:33.940]   that privacy in a lot of regards is dead.
[00:18:33.940 --> 00:18:35.980]   I still think that we should have concerns
[00:18:35.980 --> 00:18:38.220]   and should be asking questions about
[00:18:38.220 --> 00:18:40.180]   why does all this information need to exist
[00:18:40.180 --> 00:18:42.460]   and why does it all have to be tied and controlled
[00:18:42.460 --> 00:18:46.100]   by these very large companies that are acting
[00:18:46.100 --> 00:18:48.420]   as data brokers, but not always having to take
[00:18:48.420 --> 00:18:52.620]   the same responsibility that other data brokers might.
[00:18:52.620 --> 00:18:54.420]   Well, if you think about it, if you wanted to build
[00:18:54.420 --> 00:18:57.940]   a Norwellian surveillance state,
[00:18:57.940 --> 00:18:59.780]   you would do all of this.
[00:18:59.780 --> 00:19:00.460]   Right.
[00:19:00.460 --> 00:19:05.060]   So in a way, what's happened is private corporations
[00:19:05.060 --> 00:19:07.420]   have done it for the government.
[00:19:07.420 --> 00:19:09.380]   And all it's missing is the government saying,
[00:19:09.380 --> 00:19:12.940]   okay, fine, great, we'll take it from here.
[00:19:12.940 --> 00:19:16.860]   The requests that go to Ring and Google for their camera footage
[00:19:16.860 --> 00:19:19.940]   are what's called emergency requests.
[00:19:19.940 --> 00:19:21.780]   Most of the time you do need a warrant.
[00:19:21.780 --> 00:19:26.780]   But if it's something that is time sensitive,
[00:19:26.780 --> 00:19:30.980]   somebody's getting murdered or something,
[00:19:30.980 --> 00:19:34.700]   and we could stop it if we got the footage.
[00:19:34.700 --> 00:19:35.540]   So that's the theory.
[00:19:35.540 --> 00:19:37.700]   And I think no company, I don't think it's just Google
[00:19:37.700 --> 00:19:39.780]   and Amazon, I think no company wants to be the company
[00:19:39.780 --> 00:19:43.260]   that says, oh, we could have stopped that abduction
[00:19:43.260 --> 00:19:45.700]   if we had just given footage to the law enforcement
[00:19:45.700 --> 00:19:46.700]   when they asked for it.
[00:19:46.700 --> 00:19:48.500]   Well, but there's also,
[00:19:48.500 --> 00:19:51.540]   if there are really life in that situations,
[00:19:51.540 --> 00:19:53.980]   then you can get judges and you can have warrants
[00:19:53.980 --> 00:19:55.580]   issued usually very quickly.
[00:19:55.580 --> 00:19:57.460]   So I don't buy that as an argument.
[00:19:57.460 --> 00:20:00.100]   I still think, yeah, I mean, the question says,
[00:20:00.100 --> 00:20:01.380]   there needs to be a warrant.
[00:20:01.380 --> 00:20:02.220]   I mean, that's-
[00:20:02.220 --> 00:20:03.220]   I was gonna say, I'm sorry,
[00:20:03.220 --> 00:20:05.340]   but like I think that this is a fourth amendment issue
[00:20:05.340 --> 00:20:07.780]   fundamentally, and I'm going to come down in favor
[00:20:07.780 --> 00:20:10.100]   of the fourth amendment over what other, like,
[00:20:10.100 --> 00:20:11.980]   what is to say or you want to put for someplace.
[00:20:11.980 --> 00:20:13.940]   I just am, I'm going to say,
[00:20:13.940 --> 00:20:15.540]   I think the fourth amendment is more important.
[00:20:15.540 --> 00:20:19.500]   And I also think that there are things and clauses in place
[00:20:19.500 --> 00:20:23.100]   within the court system to get judges to sign warrants
[00:20:23.100 --> 00:20:25.260]   almost immediately. I don't, I have a big problem
[00:20:25.260 --> 00:20:27.140]   with the fact that the companies are just willing
[00:20:27.140 --> 00:20:29.420]   to oblige, especially since when you look
[00:20:29.420 --> 00:20:32.220]   into these data situations, many of these circumstances
[00:20:32.220 --> 00:20:34.620]   aren't necessarily these life-and-death scenarios.
[00:20:34.620 --> 00:20:36.860]   So I don't know, to me-
[00:20:36.860 --> 00:20:38.380]   Well, and also there's been hacks.
[00:20:38.380 --> 00:20:39.220]   So-
[00:20:39.220 --> 00:20:40.060]   Right, right.
[00:20:40.060 --> 00:20:41.380]   You could pretend to be law enforcement
[00:20:41.380 --> 00:20:42.540]   and get this footage.
[00:20:42.540 --> 00:20:44.260]   Exactly, which-
[00:20:44.260 --> 00:20:45.900]   That has happened, which is a big problem.
[00:20:45.900 --> 00:20:49.460]   And so, yeah, I just, again, I'm personally going to be more
[00:20:49.460 --> 00:20:51.460]   in favor of the fourth amendment versus
[00:20:51.460 --> 00:20:53.700]   whatever, you know, what if terrible scenario,
[00:20:53.700 --> 00:20:54.780]   you have it, that's me.
[00:20:54.780 --> 00:20:57.940]   No, that's actually really an excellent point.
[00:20:57.940 --> 00:20:59.940]   You have a constitutional protection.
[00:20:59.940 --> 00:21:02.980]   It says you have to have a warrant to do that kind of stuff.
[00:21:02.980 --> 00:21:05.380]   And let's, yeah, let's make that possible.
[00:21:05.380 --> 00:21:07.500]   Let's at least go to a judge and say,
[00:21:07.500 --> 00:21:09.460]   hey, we need this information.
[00:21:09.460 --> 00:21:12.620]   The problem though, when these large companies,
[00:21:12.620 --> 00:21:14.820]   they have all of this lobbying and-
[00:21:14.820 --> 00:21:15.660]   Oh, sure.
[00:21:15.660 --> 00:21:17.420]   Us as regular people, we really don't.
[00:21:17.420 --> 00:21:20.580]   We don't have the amount of protections that are in place.
[00:21:20.580 --> 00:21:22.620]   Companies do because companies are now people.
[00:21:22.620 --> 00:21:23.660]   So they get the-
[00:21:23.660 --> 00:21:26.500]   All of the handouts that they get for being a big company,
[00:21:26.500 --> 00:21:28.380]   and the lobbying, and the amount of money.
[00:21:28.380 --> 00:21:30.380]   But also they get all the protections as a person.
[00:21:30.380 --> 00:21:33.300]   And yet, as people, us being all single,
[00:21:33.300 --> 00:21:35.860]   we really don't have much of a stake
[00:21:35.860 --> 00:21:37.740]   at being able to make huge changes.
[00:21:37.740 --> 00:21:38.820]   And we're not protected.
[00:21:38.820 --> 00:21:40.460]   So I fully agree with you, Christina,
[00:21:40.460 --> 00:21:43.380]   that we really need to make sure that protections are in place
[00:21:43.380 --> 00:21:45.300]   because there isn't transparency,
[00:21:45.300 --> 00:21:47.980]   there isn't any accountability if anything happens wrong.
[00:21:47.980 --> 00:21:49.700]   And it's pretty much just like, oh, well,
[00:21:49.700 --> 00:21:52.500]   another breach, sorry, your information is out there.
[00:21:52.500 --> 00:21:54.060]   Hope nothing bad happens.
[00:21:54.060 --> 00:21:54.900]   And that's it.
[00:21:54.900 --> 00:21:56.860]   And then their hands are washed of it, and then they go on.
[00:21:56.860 --> 00:22:00.340]   And it happens so often, we become complacent to it.
[00:22:00.340 --> 00:22:02.820]   We just become like, oh, that's just life now.
[00:22:02.820 --> 00:22:05.420]   Should the FTC block this acquisition?
[00:22:05.420 --> 00:22:08.700]   I don't think that it's that big that they should block it,
[00:22:08.700 --> 00:22:10.140]   but I don't think that they should make sure
[00:22:10.140 --> 00:22:11.860]   that they should have protections in place
[00:22:11.860 --> 00:22:16.380]   to be able to ensure that all of our information is shown.
[00:22:16.380 --> 00:22:19.140]   It's written in a way that's really easy to understand
[00:22:19.140 --> 00:22:21.900]   because it's not, it's really filled with legalese.
[00:22:21.900 --> 00:22:25.340]   The private, no one reads privacy, unless you really have
[00:22:25.340 --> 00:22:28.340]   a lot of time on your hands, no one's gonna read them
[00:22:28.340 --> 00:22:30.780]   because they're so difficult to read and they're terrifying.
[00:22:30.780 --> 00:22:33.740]   Well, and also we kind of assume, well, I have no privacy.
[00:22:33.740 --> 00:22:36.180]   They're gonna, regardless of what they say
[00:22:36.180 --> 00:22:38.220]   and regardless of what I agree to, they're gonna take it.
[00:22:38.220 --> 00:22:39.820]   So I give up.
[00:22:39.820 --> 00:22:42.700]   I mean, I think most of us have just given up at this point.
[00:22:42.700 --> 00:22:46.420]   Abra, are you saying that they should stop it?
[00:22:46.420 --> 00:22:48.220]   Oh, sorry.
[00:22:48.220 --> 00:22:50.420]   No, I-- Or those too small to stop.
[00:22:50.420 --> 00:22:52.420]   Yeah, I don't think that they would stop it.
[00:22:52.420 --> 00:22:53.580]   They're not going the way in.
[00:22:53.580 --> 00:22:55.380]   Yeah, no, I don't.
[00:22:55.380 --> 00:22:58.660]   And also there's competition.
[00:22:58.660 --> 00:23:00.940]   There are other companies that do this.
[00:23:00.940 --> 00:23:04.220]   It's not sowing up the market, so maybe there isn't
[00:23:04.220 --> 00:23:05.460]   an antitrust reason.
[00:23:05.460 --> 00:23:07.260]   It's really about privacy.
[00:23:07.260 --> 00:23:09.780]   I don't know if the FTC has a mandate to do that.
[00:23:09.780 --> 00:23:11.860]   We know Lena Kahn, their chair does.
[00:23:11.860 --> 00:23:16.140]   She wants to, I'm sure, but she may not be able to.
[00:23:16.980 --> 00:23:19.980]   So what is our recourse?
[00:23:19.980 --> 00:23:23.940]   We just have to sit and take it, or not by a Roomba,
[00:23:23.940 --> 00:23:24.860]   and not by an echo.
[00:23:24.860 --> 00:23:26.660]   By the way, let's not forget.
[00:23:26.660 --> 00:23:29.300]   And again, I'm not convinced that Amazon's doing this
[00:23:29.300 --> 00:23:31.660]   out of any nefarious intent, but they have set up
[00:23:31.660 --> 00:23:34.620]   using Ring Doorbells and Echo devices,
[00:23:34.620 --> 00:23:39.420]   a low power, low ROI network called Sidewalk
[00:23:39.420 --> 00:23:42.500]   that is intended to cover the entire country.
[00:23:42.500 --> 00:23:46.100]   Every square inch, because if you have an Amazon device,
[00:23:46.100 --> 00:23:48.500]   the chances are you're already part of this network,
[00:23:48.500 --> 00:23:50.620]   sharing a little tiny bit of your internet
[00:23:50.620 --> 00:23:53.980]   so that lost dogs, can lost keys, can be found.
[00:23:53.980 --> 00:23:58.300]   But that seems also to be a very big surveillance tool.
[00:23:58.300 --> 00:24:04.780]   It's too much of a coincidence.
[00:24:04.780 --> 00:24:08.100]   And I just wonder what they're up to.
[00:24:08.100 --> 00:24:09.540]   - I feel like there's also just no escape.
[00:24:09.540 --> 00:24:11.860]   Like there's no way to escape Amazon at this point.
[00:24:11.860 --> 00:24:13.700]   Like, you're going to-- - Yeah, no, that's right.
[00:24:13.700 --> 00:24:16.660]   You know, you're going to buy a product or use a service
[00:24:16.660 --> 00:24:20.540]   in some capacity, and it really does feel rather helpless.
[00:24:20.540 --> 00:24:22.660]   I don't know what the answer is in terms of what to do,
[00:24:22.660 --> 00:24:24.620]   but it's kind of daunting.
[00:24:24.620 --> 00:24:27.220]   - Are we sleep walk as mashed potato or chalamis?
[00:24:27.220 --> 00:24:29.500]   Are we sleep walking into minority report?
[00:24:29.500 --> 00:24:33.500]   - We are so close already.
[00:24:33.500 --> 00:24:35.300]   - We're so close, we really are.
[00:24:35.300 --> 00:24:36.140]   - Yeah. - Yeah.
[00:24:36.140 --> 00:24:39.260]   - I'm like, oh my God, every time I get eyeball scanned,
[00:24:39.260 --> 00:24:41.140]   I'm like, oh, oh no.
[00:24:42.020 --> 00:24:44.860]   - Well, yeah, there's this story about the UK.
[00:24:44.860 --> 00:24:50.140]   If you're a, and by the way, this is really sad.
[00:24:50.140 --> 00:24:51.580]   It's not just regular offenders.
[00:24:51.580 --> 00:24:56.220]   If you're a foreign offender in the UK,
[00:24:56.220 --> 00:24:58.100]   one of them immigrant types,
[00:24:58.100 --> 00:25:00.300]   they're going to require migrants convicted of crimes
[00:25:00.300 --> 00:25:04.900]   to put on a watch that takes a picture of them
[00:25:04.900 --> 00:25:08.740]   five times a day and does face recognition,
[00:25:08.740 --> 00:25:11.940]   make sure it's them, and then sends a GPS
[00:25:11.940 --> 00:25:14.180]   so they can, in case they're up to no good.
[00:25:14.180 --> 00:25:16.820]   Those are blag to where the devices will need
[00:25:16.820 --> 00:25:19.100]   to complete periodic monitoring checks throughout the day
[00:25:19.100 --> 00:25:22.260]   by taking a photograph of themselves on the smartwatch
[00:25:22.260 --> 00:25:23.580]   with information including their names,
[00:25:23.580 --> 00:25:25.260]   date of birth, nationality, photograph,
[00:25:25.260 --> 00:25:26.700]   stored for up to six years,
[00:25:26.700 --> 00:25:29.100]   locations will be tracked 24/7,
[00:25:29.100 --> 00:25:31.820]   allowing trail monitoring data to be recorded.
[00:25:31.820 --> 00:25:34.060]   The UK is way ahead of us in this regard.
[00:25:34.060 --> 00:25:37.260]   - Can you imagine how exhausting that would be though
[00:25:37.260 --> 00:25:42.260]   as the person, just like mentally and emotionally exhausting?
[00:25:42.260 --> 00:25:46.300]   I don't understand what the reasoning is
[00:25:46.300 --> 00:25:49.060]   for someone taking a picture five times a day of themselves,
[00:25:49.060 --> 00:25:53.500]   but I just feel like, yeah, this can't be healthy at all.
[00:25:53.500 --> 00:25:57.380]   - In some cases, these are asylum seekers coming to the UK
[00:25:57.380 --> 00:26:01.020]   because of political violence in their native land.
[00:26:01.020 --> 00:26:03.900]   And well, we don't want to incarcerate you.
[00:26:03.900 --> 00:26:07.700]   So here, wear this watch check-in five times a day
[00:26:07.700 --> 00:26:08.980]   and we're gonna track you.
[00:26:08.980 --> 00:26:11.440]   Unbelievable.
[00:26:11.440 --> 00:26:15.900]   Unbelievable, it's gonna cost six million pounds.
[00:26:15.900 --> 00:26:18.920]   It'll start in the autumn across the UK.
[00:26:18.920 --> 00:26:23.260]   When I saw that, this is very, this is Orwell.
[00:26:23.260 --> 00:26:27.140]   This is 1984, this is holy moly.
[00:26:27.140 --> 00:26:28.980]   - I was trying to think like,
[00:26:28.980 --> 00:26:30.940]   do we think something like this, whatever happened?
[00:26:30.940 --> 00:26:33.060]   Like if something like this came up in the US,
[00:26:33.060 --> 00:26:34.820]   like what would the backlash be like,
[00:26:34.820 --> 00:26:36.460]   or would it be enough?
[00:26:36.460 --> 00:26:37.300]   I don't know.
[00:26:37.300 --> 00:26:40.980]   - I hope that it wouldn't happen, right?
[00:26:40.980 --> 00:26:42.220]   - Yeah, I would hope so.
[00:26:42.220 --> 00:26:45.540]   - No, you see, it can because we end up doing this thing
[00:26:45.540 --> 00:26:46.860]   of like us and them.
[00:26:46.860 --> 00:26:48.660]   They'll do it to a them.
[00:26:48.660 --> 00:26:50.300]   We try to separate people.
[00:26:50.300 --> 00:26:51.140]   - That's right, do it to migrants.
[00:26:51.140 --> 00:26:52.940]   - And they start out with a other.
[00:26:52.940 --> 00:26:55.900]   And because it's an other and it's not us, people say okay.
[00:26:55.900 --> 00:26:57.660]   And so you give up a little bit of your rights
[00:26:57.660 --> 00:26:59.860]   for your safety, which is the fastest way
[00:26:59.860 --> 00:27:01.540]   to make someone give up their rights.
[00:27:01.540 --> 00:27:03.860]   And then after we're comfortable with it happening to them,
[00:27:03.860 --> 00:27:07.380]   it happens to bad people, right?
[00:27:07.380 --> 00:27:09.020]   Like it's just them.
[00:27:09.020 --> 00:27:10.460]   And then it just happens to people
[00:27:10.460 --> 00:27:12.500]   that have like, sense offended, whatever,
[00:27:12.500 --> 00:27:13.780]   done something that's wrong.
[00:27:13.780 --> 00:27:16.300]   And then slowly it becomes just mainstay.
[00:27:16.300 --> 00:27:19.260]   And so it's not something that's gonna happen right away.
[00:27:19.260 --> 00:27:22.140]   And it becomes like, oh, but child predators,
[00:27:22.140 --> 00:27:24.260]   like they put it on to something that's really hard
[00:27:24.260 --> 00:27:26.540]   to be able to say, no, we shouldn't go with this
[00:27:26.540 --> 00:27:28.100]   because then you become a horrible person
[00:27:28.100 --> 00:27:31.460]   that's on the side of predators or abusers.
[00:27:31.460 --> 00:27:35.660]   And then it's just this insidious sliding over of our rights.
[00:27:35.660 --> 00:27:38.420]   And unfortunately, I would love to say that I'm not,
[00:27:38.420 --> 00:27:41.180]   I'm just wearing like a aluminum hat right now.
[00:27:41.180 --> 00:27:43.300]   And this isn't something that happens,
[00:27:43.300 --> 00:27:46.820]   but this is exactly the psychology of what happens
[00:27:46.820 --> 00:27:49.580]   when governments want to grab more power.
[00:27:49.580 --> 00:27:51.620]   They find something to make us afraid.
[00:27:51.620 --> 00:27:54.300]   And because we're afraid, we give up our rights faster
[00:27:54.300 --> 00:27:57.580]   than anything else because it works on that limbic primal
[00:27:57.580 --> 00:28:00.100]   part of our brain that safety is more important
[00:28:00.100 --> 00:28:01.300]   and we're at danger.
[00:28:01.300 --> 00:28:04.620]   Though we've never been safer, the amount of crime
[00:28:04.620 --> 00:28:08.980]   in the world, in again, first, you know, world countries
[00:28:08.980 --> 00:28:12.820]   has gone starkly down from the 70s yet we are starkly
[00:28:12.820 --> 00:28:14.740]   more afraid than we've ever been.
[00:28:14.740 --> 00:28:15.700]   - Right.
[00:28:15.700 --> 00:28:16.940]   No, you're exactly right.
[00:28:16.940 --> 00:28:18.860]   And I think everything you said is dead on.
[00:28:18.860 --> 00:28:20.020]   The other thing I would say though,
[00:28:20.020 --> 00:28:22.340]   is that what I think what would happen in the US
[00:28:22.340 --> 00:28:24.340]   in addition to kind of this like, you know,
[00:28:24.340 --> 00:28:26.940]   like a small slide of starting with one group
[00:28:26.940 --> 00:28:28.860]   and then slowly expanding to others
[00:28:28.860 --> 00:28:30.580]   and then it becomes mainstay,
[00:28:30.580 --> 00:28:32.900]   is that we will just corporatize it,
[00:28:32.900 --> 00:28:34.780]   which we've already done.
[00:28:34.780 --> 00:28:37.660]   Where it'll be part of a private company doing these things
[00:28:37.660 --> 00:28:38.900]   and then it becomes kind of the norm
[00:28:38.900 --> 00:28:41.140]   and then it becomes part of government programs.
[00:28:41.140 --> 00:28:44.300]   Like I'm part of Clear, which is like a way
[00:28:44.300 --> 00:28:46.820]   where you can get through, you know, like the airport faster.
[00:28:46.820 --> 00:28:48.220]   - Yeah, they do iris scans.
[00:28:48.220 --> 00:28:49.580]   - Yeah, they do iris scanning.
[00:28:49.580 --> 00:28:52.020]   I also have like TSA Pre-Check and Global Entry
[00:28:52.020 --> 00:28:55.220]   and all that stuff, but Clear partners with Delta,
[00:28:55.220 --> 00:28:57.260]   who's the airline that I primarily fly with,
[00:28:57.260 --> 00:28:59.340]   where if you are wanting to, you know,
[00:28:59.340 --> 00:29:02.260]   go to certain countries, they will have like iris scanning
[00:29:02.260 --> 00:29:05.580]   in lieu of checking, you know, your passport
[00:29:05.580 --> 00:29:07.780]   before you board the flight.
[00:29:07.780 --> 00:29:10.060]   And this is just becoming a commonplace thing
[00:29:10.060 --> 00:29:11.420]   and these are becoming adopted
[00:29:11.420 --> 00:29:14.220]   like these previous technologies are becoming embedded
[00:29:14.220 --> 00:29:17.340]   into systems that governments interface with.
[00:29:17.340 --> 00:29:19.900]   And so I can see this sort of thing happening where, okay,
[00:29:19.900 --> 00:29:22.380]   it just starts with one sort of thing
[00:29:22.380 --> 00:29:24.820]   that is operating as a private entity.
[00:29:24.820 --> 00:29:27.420]   And then once there's acceptance there,
[00:29:27.420 --> 00:29:29.620]   then those private entities now suddenly have partnerships
[00:29:29.620 --> 00:29:30.700]   with the government.
[00:29:30.700 --> 00:29:34.740]   And suddenly that's another way of expanding things too,
[00:29:34.740 --> 00:29:37.620]   in a way that is much more palatable to people
[00:29:37.620 --> 00:29:39.900]   in the United States where we're all about, you know,
[00:29:39.900 --> 00:29:44.420]   kind of like like freedom and we have like a very different
[00:29:44.420 --> 00:29:46.900]   kind of worldview, you know, shaped by our founders
[00:29:46.900 --> 00:29:50.300]   about how we feel about people encroaching on civil liberties.
[00:29:50.300 --> 00:29:52.140]   But one of the exceptions has always been, okay,
[00:29:52.140 --> 00:29:53.580]   but if a private company is doing it,
[00:29:53.580 --> 00:29:54.900]   then that's a little bit different
[00:29:54.900 --> 00:29:56.980]   because I've chosen to opt into this.
[00:29:56.980 --> 00:30:00.180]   And I think that that's one way you kind of get around that
[00:30:00.180 --> 00:30:01.860]   as you start with the private companies
[00:30:01.860 --> 00:30:03.340]   who all of a sudden are partnering
[00:30:03.340 --> 00:30:06.020]   with the government entities and then the line between the two
[00:30:06.020 --> 00:30:07.740]   is not existent. - Sure, if Disney,
[00:30:07.740 --> 00:30:10.340]   if Walt Disney said you could jump the line,
[00:30:10.340 --> 00:30:12.060]   if you wear this watch that checks that you check
[00:30:12.060 --> 00:30:13.860]   in at five last today. - And they do.
[00:30:13.860 --> 00:30:14.700]   - And they do. - And they do.
[00:30:14.700 --> 00:30:17.140]   - Then we can all do it. - They call the magic pass.
[00:30:17.140 --> 00:30:18.300]   It's called the magic wand thing.
[00:30:18.300 --> 00:30:19.420]   That's literally what it is.
[00:30:19.420 --> 00:30:21.740]   - This is tracks everywhere you wear everything.
[00:30:21.740 --> 00:30:23.860]   - And if you're not at Disney.
[00:30:23.860 --> 00:30:24.780]   - Yes. - That all starts
[00:30:24.780 --> 00:30:25.860]   with Disney, doesn't it?
[00:30:25.860 --> 00:30:29.340]   - I'll be right, let's do it.
[00:30:29.340 --> 00:30:30.260]   - Let's just do it.
[00:30:30.260 --> 00:30:31.660]   Hey, but hey, but get ready
[00:30:31.660 --> 00:30:32.980]   'cause the Mickey Mouse copy Reddit,
[00:30:32.980 --> 00:30:36.180]   there's no sunny Bono to extend copyright law.
[00:30:36.180 --> 00:30:39.540]   Mickey Mouse is going out of copyright soon.
[00:30:39.540 --> 00:30:41.380]   That's gonna be Armageddon.
[00:30:41.380 --> 00:30:43.900]   - Oh, they'll throw gazillion dollars.
[00:30:43.900 --> 00:30:45.220]   They'll suddenly have-- - You think they'll get it?
[00:30:45.220 --> 00:30:47.460]   They'll find somebody to-- - Yes, they'll--
[00:30:47.460 --> 00:30:48.300]   What are you kidding?
[00:30:48.300 --> 00:30:51.940]   - Like how quickly do people fold?
[00:30:51.940 --> 00:30:54.260]   I'm sorry, you throw a billion dollars,
[00:30:54.260 --> 00:30:55.900]   I'll be like, yeah, you know what?
[00:30:55.900 --> 00:30:57.220]   I'm throwing my vote in.
[00:30:57.220 --> 00:30:58.980]   It's just-- - So for people who don't know--
[00:30:58.980 --> 00:30:59.820]   - For the number of numbers.
[00:30:59.820 --> 00:31:02.180]   - Mickey Mouse, which was created in 1928
[00:31:02.180 --> 00:31:03.660]   by stealing from other people.
[00:31:03.660 --> 00:31:05.420]   We won't mention that part.
[00:31:05.420 --> 00:31:08.380]   Has never gone out of copyright
[00:31:08.380 --> 00:31:13.500]   because every time the copyright term is about to expire,
[00:31:13.500 --> 00:31:16.780]   Disney goes to Congress for sunny Bono was for a long time
[00:31:16.780 --> 00:31:19.420]   and they would just extend the copyright law.
[00:31:19.420 --> 00:31:21.780]   But they've apparently got nobody to do it,
[00:31:21.780 --> 00:31:24.500]   so Mickey's gonna be public domain in 2024,
[00:31:24.500 --> 00:31:26.180]   but you think they'll find somebody.
[00:31:26.180 --> 00:31:30.860]   October 1st, 2024, we'll be back here, watch.
[00:31:30.860 --> 00:31:32.780]   We'll see, we'll have a party.
[00:31:32.780 --> 00:31:35.180]   We'll do some-- - Disney party?
[00:31:35.180 --> 00:31:36.860]   - We'll all dress like Mickey Mouse.
[00:31:36.860 --> 00:31:38.340]   - We'll watch Twit get canceled.
[00:31:38.340 --> 00:31:39.860]   - Yeah. (laughs)
[00:31:39.860 --> 00:31:41.220]   - Yeah, you don't really need copyright
[00:31:41.220 --> 00:31:43.620]   to knock us off the air.
[00:31:43.620 --> 00:31:44.940]   You can probably find other words.
[00:31:44.940 --> 00:31:46.700]   - They go after daycares.
[00:31:46.700 --> 00:31:47.700]   - I know. - Mm-hmm.
[00:31:47.700 --> 00:31:48.540]   - I know. - I know.
[00:31:48.540 --> 00:31:49.860]   - I know they have to protect their copyright
[00:31:49.860 --> 00:31:51.620]   and if they show that they're not protecting it.
[00:31:51.620 --> 00:31:54.500]   But like daycares, I'm like, "Ah, like really?"
[00:31:54.500 --> 00:32:00.020]   - Apparently Disney says the original rat-like iteration
[00:32:00.020 --> 00:32:03.260]   of Mickey, we'll go public domain,
[00:32:03.260 --> 00:32:06.260]   but we retain copyright on subsequent variations.
[00:32:06.260 --> 00:32:09.300]   So the Mickey that you see today
[00:32:09.300 --> 00:32:11.500]   is probably gonna continue to be protected.
[00:32:11.500 --> 00:32:13.820]   But we can all have rat-like Mickey Mouse costumes.
[00:32:13.820 --> 00:32:16.140]   - Yeah, it's probably gonna be similar to like,
[00:32:16.140 --> 00:32:17.980]   how the winning the poo situation is now
[00:32:17.980 --> 00:32:20.740]   because winning the poo is now in public domain.
[00:32:20.740 --> 00:32:24.060]   But obviously the modern design,
[00:32:24.060 --> 00:32:25.820]   from like the '50s or '60s onward,
[00:32:25.820 --> 00:32:27.420]   most people associate with winning the poo.
[00:32:27.420 --> 00:32:29.460]   That is still under copyright,
[00:32:29.460 --> 00:32:33.340]   but people can draw variations of the A-A-Mome character
[00:32:33.340 --> 00:32:36.860]   and can also put it into horrific situations.
[00:32:36.860 --> 00:32:38.900]   Like there's a horror film that's coming out of this thing.
[00:32:38.900 --> 00:32:40.580]   - Oh, God. - In October with winning the--
[00:32:40.580 --> 00:32:42.100]   It's awful. - Don't do that
[00:32:42.100 --> 00:32:43.180]   to winnie the poo. - It's true.
[00:32:43.180 --> 00:32:44.020]   - I think you.
[00:32:44.020 --> 00:32:47.020]   - It's like, I'm a huge fan of like,
[00:32:47.020 --> 00:32:49.180]   you know, fixing the copyright system
[00:32:49.180 --> 00:32:50.180]   and then something like this happens.
[00:32:50.180 --> 00:32:52.460]   And I go, this is why we can't have nice things
[00:32:52.460 --> 00:32:53.940]   because this goes into public domain.
[00:32:53.940 --> 00:32:56.700]   And instantly you wanna do some horror horror,
[00:32:56.700 --> 00:32:58.580]   like "Wenny the Pooh Stuff" which is just--
[00:32:58.580 --> 00:32:59.700]   - Although-- - You see not?
[00:32:59.700 --> 00:33:02.020]   - I did laugh, our sponsor meant mobile,
[00:33:02.020 --> 00:33:03.540]   Ryan Reynolds owns it.
[00:33:03.540 --> 00:33:06.740]   You just see the ad where he reads a children's book
[00:33:06.740 --> 00:33:09.340]   called "Winnie the Screwed" about a bear
[00:33:09.340 --> 00:33:11.820]   with a foam bill that was through the roof.
[00:33:11.820 --> 00:33:12.820]   Okay. - That's funny.
[00:33:12.820 --> 00:33:14.020]   - That was funny. - That's funny.
[00:33:14.020 --> 00:33:16.380]   Maybe not, you know, appropriate, but--
[00:33:16.380 --> 00:33:17.860]   (laughing)
[00:33:17.860 --> 00:33:19.820]   - You can't help but laugh.
[00:33:19.820 --> 00:33:23.500]   Wow, that's, we'll have to watch.
[00:33:23.500 --> 00:33:27.500]   Disney, remember, is not as favorite as it used to be, right?
[00:33:27.500 --> 00:33:30.660]   They used to get all sorts of in Florida.
[00:33:30.660 --> 00:33:32.740]   Remember they made that social media bill,
[00:33:32.740 --> 00:33:35.540]   but it didn't apply to anybody who owns amusement parks.
[00:33:35.540 --> 00:33:37.300]   (laughing)
[00:33:37.300 --> 00:33:40.460]   Josh Hawley is now going after Disney
[00:33:40.460 --> 00:33:43.060]   because they're too woke.
[00:33:43.060 --> 00:33:48.060]   So maybe Disney doesn't have the votes, I don't know.
[00:33:48.060 --> 00:33:49.860]   We'll watch this with interest.
[00:33:49.860 --> 00:33:51.780]   Let's take a little break.
[00:33:51.780 --> 00:33:55.860]   We're gonna come back with more great panel today.
[00:33:55.860 --> 00:33:57.860]   I am thrilled to get you a bra.
[00:33:57.860 --> 00:34:00.300]   Al Heedie, you've been great on Tech News Weekly.
[00:34:00.300 --> 00:34:01.900]   And they said, Jason and Mike said,
[00:34:01.900 --> 00:34:03.260]   "Why don't you have a bra on the show?"
[00:34:03.260 --> 00:34:05.460]   I said, "Yes, let's do it."
[00:34:05.460 --> 00:34:07.260]   - That's perfect. - From CNET, video host
[00:34:07.260 --> 00:34:08.180]   and producer.
[00:34:08.180 --> 00:34:09.660]   Her blind is still a little bit bad,
[00:34:09.660 --> 00:34:12.700]   but that's okay, we're not gonna hold that against you.
[00:34:12.700 --> 00:34:14.180]   - We're not, we're not, no.
[00:34:14.180 --> 00:34:16.420]   Just ignore it, nothing here, nothing to see.
[00:34:16.420 --> 00:34:18.660]   - I can't, the kids stop, thank you.
[00:34:18.660 --> 00:34:22.820]   - Also with us, she of the left shoe only, Christina Warren.
[00:34:22.820 --> 00:34:24.620]   (laughing)
[00:34:24.620 --> 00:34:27.060]   Senior developer advocate, I'm just teasing, you know,
[00:34:27.060 --> 00:34:28.860]   I am at GitHub. - I know.
[00:34:28.860 --> 00:34:31.660]   - And there's absolutely nothing wrong with Georgia Dow.
[00:34:31.660 --> 00:34:34.340]   She is perfectly symmetrical.
[00:34:34.340 --> 00:34:36.580]   Thank you, thank you, Georgia.
[00:34:36.580 --> 00:34:38.700]   All three of you, great to have you here.
[00:34:38.700 --> 00:34:39.740]   Lots more to talk about.
[00:34:39.740 --> 00:34:42.780]   Our show though, today brought to you by Blue Land.
[00:34:42.780 --> 00:34:43.980]   We really are happy.
[00:34:43.980 --> 00:34:48.980]   I got, I, we, Lisa is, my wife is on a crusade
[00:34:48.980 --> 00:34:51.420]   against single use plastics.
[00:34:51.420 --> 00:34:53.660]   'Cause she likes turtles and whales
[00:34:53.660 --> 00:34:56.300]   and she doesn't like seeing all this plastic in the ocean.
[00:34:56.300 --> 00:34:59.460]   She does, you've seen plastics now in our bloodstreams.
[00:34:59.460 --> 00:35:01.980]   So she, we've gotten rid of plastic
[00:35:01.980 --> 00:35:03.700]   in almost every aspect of our life.
[00:35:03.700 --> 00:35:05.020]   This is the latest and I love it.
[00:35:05.020 --> 00:35:07.180]   It's called Blue Land.
[00:35:07.180 --> 00:35:09.900]   Did you know that an estimated five billion
[00:35:09.900 --> 00:35:12.780]   plastic hand soap and cleaning bottles
[00:35:12.780 --> 00:35:15.300]   end up in landfill every year?
[00:35:15.300 --> 00:35:17.020]   And of course, they never degrade.
[00:35:17.020 --> 00:35:19.780]   They'll be there for a million years.
[00:35:19.780 --> 00:35:22.540]   Most cleaning formulas, they're mostly water.
[00:35:22.540 --> 00:35:25.260]   So you're transporting 90% water
[00:35:25.260 --> 00:35:27.140]   in trucks across the country.
[00:35:27.140 --> 00:35:29.020]   There is a better way.
[00:35:29.020 --> 00:35:32.220]   Plus those products are often filled with nasty ingredients,
[00:35:32.220 --> 00:35:33.980]   chlorine, ammonia.
[00:35:33.980 --> 00:35:35.860]   Look, it's, it's a lose, lose all around,
[00:35:35.860 --> 00:35:38.020]   but Blue Land solves the problem.
[00:35:38.020 --> 00:35:42.780]   Eco-friendly products with bottles
[00:35:42.780 --> 00:35:45.420]   designed to be reused again and again.
[00:35:45.420 --> 00:35:47.780]   We replaced our cleaning bottles.
[00:35:47.780 --> 00:35:51.740]   We replaced our hand soap, you know, the soap dispensers.
[00:35:51.740 --> 00:35:53.580]   We replaced our laundry soap, our dish soap,
[00:35:53.580 --> 00:35:56.660]   all with Blue Land, you get, you start
[00:35:56.660 --> 00:35:59.140]   with a beautiful Blue Land bottle,
[00:35:59.140 --> 00:36:01.340]   Instagrammable bottle that you use.
[00:36:01.340 --> 00:36:02.940]   It's a forever bottle.
[00:36:02.940 --> 00:36:05.660]   All you have to do is you fill it with your own water.
[00:36:05.660 --> 00:36:07.500]   So you don't have to transport that water.
[00:36:07.500 --> 00:36:09.940]   And then Blue Land sends you little tablets,
[00:36:09.940 --> 00:36:12.340]   little fizzies you put in the warm water that is off.
[00:36:12.340 --> 00:36:15.580]   And now this is the, this is the multi-surface cleaning stuff.
[00:36:15.580 --> 00:36:17.900]   You've got a great multi-surface cleaner.
[00:36:17.900 --> 00:36:20.740]   I have it in all the bathroom sinks in the house
[00:36:20.740 --> 00:36:22.180]   here at the office.
[00:36:22.180 --> 00:36:24.300]   We have Blue Land and when it runs out,
[00:36:24.300 --> 00:36:25.620]   you just put warm water in there,
[00:36:25.620 --> 00:36:26.420]   put one in the tablets.
[00:36:26.420 --> 00:36:27.620]   You can even subscribe to these.
[00:36:27.620 --> 00:36:29.860]   So they come, these are easy to ship.
[00:36:29.860 --> 00:36:32.260]   They come in paper, pouches.
[00:36:32.260 --> 00:36:34.180]   So you can recycle those.
[00:36:34.180 --> 00:36:35.900]   This is eco-friendly done right.
[00:36:35.900 --> 00:36:37.940]   And the only thing you're gonna lose
[00:36:37.940 --> 00:36:40.860]   is your outdated notion that eco-friendly products
[00:36:40.860 --> 00:36:44.300]   are too expensive or less effective.
[00:36:44.300 --> 00:36:46.220]   Blue Land is on a mission.
[00:36:46.220 --> 00:36:49.500]   A mission I'm 100% behind to eliminate single use plastics
[00:36:49.500 --> 00:36:51.780]   by reinventing home essentials that are good
[00:36:51.780 --> 00:36:53.260]   for you and the planet.
[00:36:53.260 --> 00:36:55.740]   Their innovative tablet refill solution takes
[00:36:55.740 --> 00:36:59.740]   up to 10 times less space than a traditional bottle.
[00:36:59.740 --> 00:37:01.700]   Their powerful formulas keep your home clean
[00:37:01.700 --> 00:37:02.980]   and smell amazing.
[00:37:03.820 --> 00:37:08.340]   Refills start at $2 and you don't buy a new bottle.
[00:37:08.340 --> 00:37:09.660]   You can buy a new bottle when you want to,
[00:37:09.660 --> 00:37:11.380]   but you don't because you're gonna refill it.
[00:37:11.380 --> 00:37:13.700]   They last for a long, long time.
[00:37:13.700 --> 00:37:15.420]   From cleaning sprays to hands up to toilet,
[00:37:15.420 --> 00:37:17.140]   oh, the toilet cleaner, I love it.
[00:37:17.140 --> 00:37:18.140]   Oh, I love it.
[00:37:18.140 --> 00:37:19.140]   In fact, they sell out of that.
[00:37:19.140 --> 00:37:20.500]   So while they're in stock, get it.
[00:37:20.500 --> 00:37:22.060]   You just drop it in the toilet.
[00:37:22.060 --> 00:37:23.940]   It's amazing laundry tablets.
[00:37:23.940 --> 00:37:25.660]   They even sell when we use these, I don't know,
[00:37:25.660 --> 00:37:27.860]   wool balls you put in your dryer.
[00:37:27.860 --> 00:37:29.100]   We put three in there.
[00:37:29.100 --> 00:37:30.140]   Things dry faster.
[00:37:30.140 --> 00:37:32.060]   You don't have to use dryer sheets anymore.
[00:37:32.060 --> 00:37:33.580]   There's no, it's anti-static.
[00:37:33.580 --> 00:37:34.820]   It's kind of magical.
[00:37:34.820 --> 00:37:38.500]   It start with, I did this when my daughter moved.
[00:37:38.500 --> 00:37:40.700]   I gave it to her as a housewarming.
[00:37:40.700 --> 00:37:43.500]   The clean essentials get everything you need to get started.
[00:37:43.500 --> 00:37:46.340]   And the cents are fantastic.
[00:37:46.340 --> 00:37:47.820]   You can get holiday cents.
[00:37:47.820 --> 00:37:50.100]   I mentioned before I got the Christmas cents.
[00:37:50.100 --> 00:37:51.860]   I still have some gingerbread soap
[00:37:51.860 --> 00:37:54.580]   and my bathroom size smell like gingerbread house.
[00:37:54.580 --> 00:37:57.060]   When I come out, Iris agave, fresh lemon,
[00:37:57.060 --> 00:37:58.940]   eucalyptus mint.
[00:37:58.940 --> 00:38:01.260]   For a limited time, they've got some hand soap,
[00:38:01.260 --> 00:38:05.300]   scents for summer that you're gonna love strawberry rhubarb,
[00:38:05.300 --> 00:38:07.900]   citrus, patchouli and coconut palm.
[00:38:07.900 --> 00:38:08.940]   But here's, you don't have to,
[00:38:08.940 --> 00:38:10.700]   but you can order these.
[00:38:10.700 --> 00:38:14.060]   It's just, it's kind of like, oh, I got new soap.
[00:38:14.060 --> 00:38:14.860]   Oh, it smells great.
[00:38:14.860 --> 00:38:17.820]   Right now, 15% off your first order,
[00:38:17.820 --> 00:38:21.980]   go to blueland, BLUELAND.com/twit,
[00:38:21.980 --> 00:38:26.580]   blueland.com/twit, 15% off your first order
[00:38:26.580 --> 00:38:30.060]   of any blueland products, blueland.com/twit,
[00:38:30.060 --> 00:38:34.660]   BLUELAND.BLUELAND.com/twit, thank you, blueland.
[00:38:34.660 --> 00:38:38.660]   And of course, we thank you, dear twit listener,
[00:38:38.660 --> 00:38:39.980]   for going to that special address,
[00:38:39.980 --> 00:38:44.500]   that way we get credit for it, blueland.com/twit.
[00:38:44.500 --> 00:38:46.180]   We've been using these for a year now.
[00:38:46.180 --> 00:38:50.860]   I just love our blueland stuff, blueland.com/twit.
[00:38:50.860 --> 00:38:53.340]   And they keep track of when you're gonna run out,
[00:38:53.340 --> 00:38:54.500]   they send you a little text message,
[00:38:54.500 --> 00:38:55.340]   you want some more?
[00:38:55.340 --> 00:38:59.500]   And I said, yes, it's great, blueland.com/twit.
[00:39:00.500 --> 00:39:04.340]   Uh-oh, Tesla might be in trouble.
[00:39:04.340 --> 00:39:07.460]   The Department of Motor Vehicles in R-fine,
[00:39:07.460 --> 00:39:09.580]   State of California is accusing Tesla
[00:39:09.580 --> 00:39:13.620]   of falsely advertising autopilot.
[00:39:13.620 --> 00:39:17.580]   It's about time, it is not an autopilot,
[00:39:17.580 --> 00:39:19.500]   it's driver assist.
[00:39:19.500 --> 00:39:21.140]   Tesla loves you to think that, you know,
[00:39:21.140 --> 00:39:23.020]   it's a self-driving vehicle.
[00:39:23.020 --> 00:39:27.980]   But DMV says, that's false advertising,
[00:39:27.980 --> 00:39:31.300]   you misled consumers, claiming in advertisements
[00:39:31.300 --> 00:39:33.140]   that vehicles equipped with autopilot
[00:39:33.140 --> 00:39:35.980]   and full self-driving were autonomous.
[00:39:35.980 --> 00:39:37.700]   They have complained to the state's office
[00:39:37.700 --> 00:39:39.860]   of administrative hearings,
[00:39:39.860 --> 00:39:41.540]   and the potential risk for Tesla
[00:39:41.540 --> 00:39:44.740]   is the license to make and sell vehicles in California.
[00:39:44.740 --> 00:39:48.360]   They do both, could be suspended or revoked.
[00:39:48.360 --> 00:39:50.660]   Wow.
[00:39:50.660 --> 00:39:53.980]   No response from Elon.
[00:39:53.980 --> 00:39:55.500]   I'm surprised he hasn't tweeted about this,
[00:39:55.500 --> 00:39:57.260]   he tweets about everything else.
[00:39:58.260 --> 00:40:01.100]   What do you think, is this fair?
[00:40:01.100 --> 00:40:05.980]   I think it's important to raise this concern
[00:40:05.980 --> 00:40:10.500]   just because, you know, there have been accidents
[00:40:10.500 --> 00:40:11.780]   and there have been deaths.
[00:40:11.780 --> 00:40:15.260]   And I think, you know, I think sometimes people might,
[00:40:15.260 --> 00:40:18.180]   that term autopilot can be incredibly misleading
[00:40:18.180 --> 00:40:21.020]   or saying that something is fully self-driving when it's not.
[00:40:21.020 --> 00:40:23.260]   I mean, I have friends who have Teslas
[00:40:23.260 --> 00:40:24.740]   and maybe get a little too comfortable
[00:40:24.740 --> 00:40:26.500]   when they do turn on autopilot.
[00:40:26.500 --> 00:40:27.500]   It's a specific problem.
[00:40:27.500 --> 00:40:29.380]   And so, yeah.
[00:40:29.380 --> 00:40:33.060]   So, you know, they'll be like completely on their phones
[00:40:33.060 --> 00:40:34.900]   the whole time or like working.
[00:40:34.900 --> 00:40:36.220]   It's just absolutely reckless.
[00:40:36.220 --> 00:40:40.340]   But I think it is fair to bring this up as a concern.
[00:40:40.340 --> 00:40:42.500]   And it'll be interesting to see how this plays out
[00:40:42.500 --> 00:40:43.980]   and if Elon weighs in.
[00:40:43.980 --> 00:40:46.220]   I'd be surprised if he didn't at some point.
[00:40:46.220 --> 00:40:48.860]   National Highway Traffic Safety Administration,
[00:40:48.860 --> 00:40:51.140]   NHTSA has been investigating all this effect.
[00:40:51.140 --> 00:40:52.700]   There were two crashes last month
[00:40:52.700 --> 00:40:55.580]   in which Teslas collided with motorcycles
[00:40:55.580 --> 00:40:58.340]   on freeways in the dark.
[00:40:58.340 --> 00:41:00.300]   Both were fatal, I'm sorry to say.
[00:41:00.300 --> 00:41:03.620]   And the concern is that maybe the Teslas didn't even see them.
[00:41:03.620 --> 00:41:05.540]   You know, that they couldn't,
[00:41:05.540 --> 00:41:07.480]   one was in Riverside, California.
[00:41:07.480 --> 00:41:11.600]   There's another Draper, Utah, middle of the night.
[00:41:11.600 --> 00:41:14.260]   And of course, one of the things Tesla does,
[00:41:14.260 --> 00:41:16.940]   which I think is a little slimy is,
[00:41:16.940 --> 00:41:18.940]   and NHTSA wants this information,
[00:41:18.940 --> 00:41:22.260]   they will turn off autopilot right before the crash.
[00:41:23.340 --> 00:41:28.180]   And then they can say, "Oh, autopilot wasn't involved."
[00:41:28.180 --> 00:41:31.180]   It was off when the accident happened.
[00:41:31.180 --> 00:41:33.940]   That's one of the things NHTSA has been saying.
[00:41:33.940 --> 00:41:35.940]   Yikes.
[00:41:35.940 --> 00:41:40.860]   You know, I had a Tesla, loved my Tesla.
[00:41:40.860 --> 00:41:41.900]   I don't have a Tesla now,
[00:41:41.900 --> 00:41:44.420]   but even when I had a Tesla with autopilot,
[00:41:44.420 --> 00:41:47.300]   I was vigilant.
[00:41:47.300 --> 00:41:49.820]   And there were times when the thing would start
[00:41:49.820 --> 00:41:53.820]   to veer off to the shoulder or even into a barrier.
[00:41:53.820 --> 00:41:57.340]   There were times when I had lane merging,
[00:41:57.340 --> 00:41:58.380]   where you'd signal and it would go
[00:41:58.380 --> 00:42:00.700]   into the next lane automatically, and it would do it,
[00:42:00.700 --> 00:42:02.540]   and it was really close to a car behind me.
[00:42:02.540 --> 00:42:05.020]   And I was like, "Nee, stop!"
[00:42:05.020 --> 00:42:07.780]   You just don't want to fully trust it.
[00:42:07.780 --> 00:42:10.180]   So advertising that is full self-driving is,
[00:42:10.180 --> 00:42:12.940]   maybe you shouldn't.
[00:42:12.940 --> 00:42:14.940]   - Yeah, and it's word's murder.
[00:42:14.940 --> 00:42:18.700]   People will hear autopilot and think that they can do
[00:42:18.700 --> 00:42:20.980]   their crossword puzzle while they're driving.
[00:42:20.980 --> 00:42:23.740]   Go to sleep, take a nap, turn around.
[00:42:23.740 --> 00:42:26.780]   Like, already, unfortunately,
[00:42:26.780 --> 00:42:29.860]   we want to think that we're like a higher formed organism
[00:42:29.860 --> 00:42:31.340]   and we think all these things.
[00:42:31.340 --> 00:42:34.260]   But you just TikTok videos, people getting out of their car
[00:42:34.260 --> 00:42:35.980]   and dancing while the car is driving,
[00:42:35.980 --> 00:42:37.100]   and they're actually doing it.
[00:42:37.100 --> 00:42:39.180]   It's not that someone's actually taken over driving,
[00:42:39.180 --> 00:42:41.140]   which is what happens in most of the videos,
[00:42:41.140 --> 00:42:42.980]   but you know, or they're on the roof of the car.
[00:42:42.980 --> 00:42:45.540]   Like, no, you probably should be driving.
[00:42:45.540 --> 00:42:49.180]   It's thousands, like, you know, hundreds of pounds
[00:42:49.180 --> 00:42:52.500]   of steel probably or, you know, aluminum.
[00:42:52.500 --> 00:42:56.020]   And, you know, it's just a dangerous thing to be able to do.
[00:42:56.020 --> 00:42:58.980]   But when you say autopilot, people will believe that
[00:42:58.980 --> 00:43:01.820]   because we're not as evolved as we think we are
[00:43:01.820 --> 00:43:03.740]   and then we'll do things that we shouldn't do,
[00:43:03.740 --> 00:43:05.220]   thinking that the car will take over.
[00:43:05.220 --> 00:43:07.740]   And even if it does a lot of the time,
[00:43:07.740 --> 00:43:09.500]   that means that there's a whole bunch of times
[00:43:09.500 --> 00:43:10.820]   when it won't, so.
[00:43:10.820 --> 00:43:14.620]   - But on the other hand, we are humans, are terrible drivers.
[00:43:14.620 --> 00:43:16.780]   I mean, sure, Tesla's ran into two motorcycles
[00:43:16.780 --> 00:43:17.620]   in the last month.
[00:43:17.620 --> 00:43:19.780]   How many motorcyclists have been killed by humans
[00:43:19.780 --> 00:43:22.260]   driving, you know, 100%.
[00:43:22.260 --> 00:43:23.940]   We're terrible drivers.
[00:43:23.940 --> 00:43:26.140]   So. - We're tearing lots of things.
[00:43:26.140 --> 00:43:28.660]   - That's one of the questions is, okay, admittedly,
[00:43:28.660 --> 00:43:31.180]   Tesla's self-driving is not perfect,
[00:43:31.180 --> 00:43:32.820]   but is it better than a human?
[00:43:32.820 --> 00:43:36.260]   It's unknown and that's what we got to investigate.
[00:43:36.260 --> 00:43:39.380]   - Right, like as long as they said it was an assist
[00:43:39.380 --> 00:43:40.580]   instead of it was self-driving.
[00:43:40.580 --> 00:43:41.420]   - That's true.
[00:43:41.420 --> 00:43:44.580]   - With self-driving, we think that the car is self-driving.
[00:43:44.580 --> 00:43:46.460]   Hence the word self and driving.
[00:43:46.460 --> 00:43:48.220]   But if it said just driver assist,
[00:43:48.220 --> 00:43:49.740]   then it was like it's there to help you.
[00:43:49.740 --> 00:43:50.980]   It's like cruise control, right?
[00:43:50.980 --> 00:43:53.500]   If they said something that was more similar to that,
[00:43:53.500 --> 00:43:55.460]   we're like, okay, we still have to pay attention.
[00:43:55.460 --> 00:43:58.020]   It's gonna be keeping the same a certain distance,
[00:43:58.020 --> 00:44:00.100]   but we have to pay attention because it doesn't deal
[00:44:00.100 --> 00:44:02.220]   with every single situation.
[00:44:02.220 --> 00:44:03.980]   - Tesla has till Friday to respond,
[00:44:03.980 --> 00:44:05.580]   but one of their responses could be,
[00:44:05.580 --> 00:44:06.820]   what's his marketing, guys?
[00:44:06.820 --> 00:44:08.380]   Come on.
[00:44:08.380 --> 00:44:10.420]   - That is probably what they will say.
[00:44:10.420 --> 00:44:11.420]   - That is probably what they'll say.
[00:44:11.420 --> 00:44:13.100]   I don't know how well that works though,
[00:44:13.100 --> 00:44:16.340]   because to your point, marketing words have meaning.
[00:44:16.340 --> 00:44:19.420]   And they clearly chose autopilot
[00:44:19.420 --> 00:44:23.220]   because they want to push things
[00:44:23.220 --> 00:44:24.900]   to be being fully self-driven.
[00:44:24.900 --> 00:44:26.900]   Like that's in Tesla's best interest.
[00:44:26.900 --> 00:44:29.860]   That's where they wanna push the technology.
[00:44:29.860 --> 00:44:32.740]   And I've said this many times over the years
[00:44:32.740 --> 00:44:33.780]   on this show and on others.
[00:44:33.780 --> 00:44:36.140]   I think that the biggest thing that's going to hold us up
[00:44:36.140 --> 00:44:39.660]   on self-driving is actually the regulatory aspects
[00:44:39.660 --> 00:44:41.860]   more than the technology itself.
[00:44:41.860 --> 00:44:43.620]   But putting that aside,
[00:44:43.620 --> 00:44:46.860]   it's not a fully self-driving thing,
[00:44:46.860 --> 00:44:48.020]   but people still treat it that way.
[00:44:48.020 --> 00:44:50.540]   And a big part of that is the name autopilot.
[00:44:50.540 --> 00:44:52.980]   So no matter what they're doing,
[00:44:52.980 --> 00:44:57.980]   they are inherently the way they promote this feature,
[00:44:57.980 --> 00:44:59.740]   kind of letting people know,
[00:44:59.740 --> 00:45:02.220]   oh, you can actually treat this
[00:45:02.220 --> 00:45:04.900]   as if it's a fully autonomous driving solution
[00:45:04.900 --> 00:45:06.420]   when that's not the case.
[00:45:06.420 --> 00:45:09.900]   And so I don't know how well that,
[00:45:09.900 --> 00:45:11.260]   or I'm sure that's the argument it'll make,
[00:45:11.260 --> 00:45:13.260]   but I don't know if that argument actually,
[00:45:13.260 --> 00:45:16.260]   changes reality because if you're advertising something
[00:45:16.260 --> 00:45:17.500]   that's being one thing,
[00:45:17.500 --> 00:45:19.300]   you can't be angry when people actually use it
[00:45:19.300 --> 00:45:20.900]   the way you're advertising it.
[00:45:20.900 --> 00:45:23.980]   - Well, one thing Tesla will be celebrating
[00:45:23.980 --> 00:45:27.740]   is the return of the tax credit about five hours ago,
[00:45:27.740 --> 00:45:32.740]   the Senate passed that sweeping $430 billion bill
[00:45:32.740 --> 00:45:37.500]   which fights inflation, flights climate change,
[00:45:37.500 --> 00:45:39.060]   lowers drug prices,
[00:45:39.060 --> 00:45:42.460]   and restores the tax credit
[00:45:42.460 --> 00:45:46.220]   in some circumstances for electric vehicles.
[00:45:46.220 --> 00:45:51.180]   Tesla, GM had already sold more than 200,000 vehicles.
[00:45:51.180 --> 00:45:52.020]   That was the cap,
[00:45:52.020 --> 00:45:55.380]   so they lost that $7,500 tax credit.
[00:45:55.380 --> 00:45:59.260]   If this bill passes through the house intact
[00:45:59.260 --> 00:46:01.220]   and then it's signed by the president,
[00:46:01.220 --> 00:46:06.700]   that credit will be coming back to promote EV sales.
[00:46:06.700 --> 00:46:08.620]   By the way, you also get a $4,000 credit
[00:46:08.620 --> 00:46:12.620]   on used electric vehicles, which is good, I think.
[00:46:12.620 --> 00:46:14.980]   Do we still need though to subsidize EVs?
[00:46:14.980 --> 00:46:17.860]   - Yeah, I think so.
[00:46:17.860 --> 00:46:21.300]   - People are still reluctant, it's a little more expensive,
[00:46:21.300 --> 00:46:23.300]   you're paying for the battery.
[00:46:23.300 --> 00:46:24.940]   - And also it's been difficult for people
[00:46:24.940 --> 00:46:26.740]   to get cars in general, I think at this point.
[00:46:26.740 --> 00:46:28.980]   So I think especially the used thing,
[00:46:28.980 --> 00:46:33.420]   just because there's been such a kind of a shortage
[00:46:33.420 --> 00:46:36.580]   in certain areas for people getting cars,
[00:46:36.580 --> 00:46:38.580]   people are on wait lists and things like that.
[00:46:38.580 --> 00:46:40.860]   - I think anything you can do to encourage people
[00:46:40.860 --> 00:46:43.260]   to adopt more EVs and to get more,
[00:46:43.260 --> 00:46:44.340]   and the ecosystem is good.
[00:46:44.340 --> 00:46:49.340]   I'm actually a bigger fan of the credit for the used EV sales
[00:46:49.340 --> 00:46:50.980]   than even the first time thing.
[00:46:50.980 --> 00:46:54.500]   I think that's a really good thing to encourage people
[00:46:54.500 --> 00:46:58.060]   who might not have the money or the inclination to buy a new car
[00:46:58.060 --> 00:46:59.860]   to at least okay if I'm buying something used,
[00:46:59.860 --> 00:47:01.780]   I can still benefit from this credit.
[00:47:01.780 --> 00:47:03.540]   I'm a fan of this personally.
[00:47:03.540 --> 00:47:04.380]   - Yeah.
[00:47:05.180 --> 00:47:09.780]   - It looks like there will be some income caps
[00:47:09.780 --> 00:47:12.220]   and there'll be caps on the expense of the vehicle.
[00:47:12.220 --> 00:47:13.700]   It's not clear 'cause this was,
[00:47:13.700 --> 00:47:17.260]   this kind of went back and forth for a while.
[00:47:17.260 --> 00:47:22.220]   But it is at least some tax credit,
[00:47:22.220 --> 00:47:23.260]   and I guess when the smoke clears,
[00:47:23.260 --> 00:47:26.680]   we'll know exactly what the details are.
[00:47:26.680 --> 00:47:31.540]   But that's also, that bill's a big deal for climate change.
[00:47:31.540 --> 00:47:34.740]   It's Bill Gates last Sunday in the New York Times
[00:47:34.740 --> 00:47:37.900]   wrote an opinion piece saying,
[00:47:37.900 --> 00:47:39.780]   "We're on the verge of a remarkable moment
[00:47:39.780 --> 00:47:42.660]   "for Congress in the country asking the Senate
[00:47:42.660 --> 00:47:46.860]   "to pass this Bill the Inflation Reduction Act of 2022."
[00:47:46.860 --> 00:47:48.940]   He said it might be the single most important piece
[00:47:48.940 --> 00:47:52.420]   of climate legislation in American history
[00:47:52.420 --> 00:47:56.820]   because of the subsidies for alternative energy.
[00:47:56.820 --> 00:47:59.700]   He says, "Many of the technologies will need
[00:47:59.700 --> 00:48:02.540]   "to reach net zero emissions don't exist,
[00:48:02.540 --> 00:48:04.240]   "or are in early stages development
[00:48:04.240 --> 00:48:06.940]   "or still too expensive to scale up.
[00:48:06.940 --> 00:48:10.620]   "Without new and expanded tax credits, government support,
[00:48:10.620 --> 00:48:13.460]   "many of these technologies won't be developed.
[00:48:13.460 --> 00:48:15.180]   "The incentives provide the private sector
[00:48:15.180 --> 00:48:17.780]   "with the confidence to invest for the long term."
[00:48:17.780 --> 00:48:22.060]   So I guess Mr. Gates must be happy today.
[00:48:22.060 --> 00:48:27.020]   27-hour session, including the Vodarama
[00:48:27.020 --> 00:48:31.660]   that happened overnight as different amendments
[00:48:31.660 --> 00:48:35.020]   and modifications were proposed, most of them voted down.
[00:48:35.020 --> 00:48:37.900]   So good, I think good news.
[00:48:37.900 --> 00:48:39.820]   I'm willing to say good news.
[00:48:39.820 --> 00:48:41.940]   I know that's a little partisan,
[00:48:41.940 --> 00:48:44.100]   but I'm in favor of clean energy.
[00:48:44.100 --> 00:48:44.940]   Yeah.
[00:48:44.940 --> 00:48:50.620]   - And the drug costs.
[00:48:50.620 --> 00:48:53.020]   - Yeah, these other benefits, non-tech benefits.
[00:48:53.020 --> 00:48:54.180]   Yeah, absolutely.
[00:48:54.180 --> 00:48:55.020]   - Yeah.
[00:48:55.020 --> 00:48:57.620]   - So this doesn't affect you 'cause you're in Canada
[00:48:57.620 --> 00:48:59.900]   where drugs are free, right?
[00:48:59.900 --> 00:49:04.060]   - I think they, not only are they, they're subsidized,
[00:49:04.060 --> 00:49:06.740]   like the government will cover the cost of drugs
[00:49:06.740 --> 00:49:08.620]   so that they're free for you.
[00:49:08.620 --> 00:49:12.140]   So, but it's just a lot of my clients are American
[00:49:12.140 --> 00:49:13.740]   and they can't afford their medication.
[00:49:13.740 --> 00:49:15.180]   - Insulin in particular.
[00:49:15.180 --> 00:49:16.500]   - Insulin in particular.
[00:49:16.500 --> 00:49:17.340]   - Yeah.
[00:49:17.340 --> 00:49:18.980]   - That actually, there was a proposed insulin cap
[00:49:18.980 --> 00:49:22.340]   on private insurers that did not make it through,
[00:49:22.340 --> 00:49:27.020]   but the $35 a month cap for Medicare patients
[00:49:27.020 --> 00:49:29.060]   did make it through, but the private health insurance market
[00:49:29.060 --> 00:49:30.540]   is not capped on insulin costs.
[00:49:30.540 --> 00:49:32.660]   This has been a big problem, I think.
[00:49:32.660 --> 00:49:34.100]   - It's a huge problem.
[00:49:34.100 --> 00:49:36.220]   - It's such a horrible thing when you can't do that.
[00:49:36.220 --> 00:49:37.980]   - Insulin is not an optional drug.
[00:49:37.980 --> 00:49:39.580]   You have it to save your life.
[00:49:39.580 --> 00:49:40.780]   - Yeah, it's a horrific thing to think
[00:49:40.780 --> 00:49:42.980]   that people are choosing to eat or to choose
[00:49:42.980 --> 00:49:43.980]   to have their medication.
[00:49:43.980 --> 00:49:44.820]   It's really scary.
[00:49:44.820 --> 00:49:47.780]   And like this is where some billionaires
[00:49:47.780 --> 00:49:50.380]   are actually doing some good, like Mark Cuban
[00:49:50.380 --> 00:49:53.740]   started his drug company where he's giving to
[00:49:53.740 --> 00:49:56.540]   a little bit over cost for, I think it's like
[00:49:56.540 --> 00:49:58.380]   was 200 different drugs.
[00:49:58.380 --> 00:50:03.060]   And like that's something where we can get behind
[00:50:03.060 --> 00:50:04.300]   and be able to say, you know what,
[00:50:04.300 --> 00:50:08.220]   we can do this better because really,
[00:50:08.220 --> 00:50:09.940]   if we're not taking care of people,
[00:50:09.940 --> 00:50:12.500]   then what does any of this matter?
[00:50:12.500 --> 00:50:13.900]   - I think it's called cost plus.
[00:50:13.900 --> 00:50:15.740]   - Cost plus, yeah.
[00:50:15.740 --> 00:50:19.500]   You know, I'm not a huge Mark Cuban fan,
[00:50:19.500 --> 00:50:22.700]   but I feel like he's just a very lucky fellow who,
[00:50:22.700 --> 00:50:27.260]   was able to convince AOL to buy broadcast
[00:50:27.260 --> 00:50:29.300]   that got over a billion dollars.
[00:50:29.300 --> 00:50:31.460]   But in this case, yeah, maybe, I don't know.
[00:50:31.460 --> 00:50:32.940]   I don't know anything about it.
[00:50:32.940 --> 00:50:34.180]   I've read about it.
[00:50:34.180 --> 00:50:36.060]   It's a public benefit corporation,
[00:50:36.060 --> 00:50:40.820]   which means that it's not a for profit operation.
[00:50:40.820 --> 00:50:45.140]   And they're selling drugs at just slightly over cost
[00:50:45.140 --> 00:50:46.820]   just to cover the costs.
[00:50:47.980 --> 00:50:50.180]   He says, "I could make a fortune from this, but I won't.
[00:50:50.180 --> 00:50:51.380]   I've got enough money.
[00:50:51.380 --> 00:50:54.860]   I'd rather F up the drug industry in every possible way."
[00:50:54.860 --> 00:50:57.220]   I think, you know what, now I'm a Mark Cuban fan.
[00:50:57.220 --> 00:50:59.460]   (laughing)
[00:50:59.460 --> 00:51:05.780]   It's an interesting idea anyway.
[00:51:05.780 --> 00:51:07.780]   Boy, I'd love to see more billionaires
[00:51:07.780 --> 00:51:09.700]   F up other industries like this.
[00:51:09.700 --> 00:51:10.540]   - Right.
[00:51:10.540 --> 00:51:11.380]   - That's what they're,
[00:51:11.380 --> 00:51:12.860]   that's what they should be doing.
[00:51:12.860 --> 00:51:13.700]   - Yeah, yeah.
[00:51:15.620 --> 00:51:18.060]   I suppose that means we should talk about Elon.
[00:51:18.060 --> 00:51:21.460]   Let's see, what are they?
[00:51:21.460 --> 00:51:23.100]   I think I usually bury these.
[00:51:23.100 --> 00:51:26.820]   Oh yeah, here's my Elon story for the week.
[00:51:26.820 --> 00:51:30.020]   As you know, Twitter suing Elon Musk saying,
[00:51:30.020 --> 00:51:35.060]   "You said you'd pay 44 billion dollars for us, 54 20 a share.
[00:51:35.060 --> 00:51:36.500]   You agree to that?
[00:51:36.500 --> 00:51:37.340]   You better do it.
[00:51:37.340 --> 00:51:39.900]   They've gone to the Delaware Chance Record.
[00:51:39.900 --> 00:51:42.460]   The trial starts October 17th.
[00:51:42.460 --> 00:51:46.540]   Elon countered Sude saying a lot of,
[00:51:46.540 --> 00:51:48.380]   in my opinion, kind of ridiculous things.
[00:51:48.380 --> 00:51:51.740]   Now Elon is challenging Paragogro wall,
[00:51:51.740 --> 00:51:54.740]   the CEO of Twitter to a public debate about bots.
[00:51:54.740 --> 00:51:57.000]   Sure, Elon, that's a great idea.
[00:51:57.000 --> 00:52:00.820]   - But just more interesting if it was a boxing match, but--
[00:52:00.820 --> 00:52:03.340]   - Yeah, it might as well be.
[00:52:03.340 --> 00:52:04.420]   Might as well be.
[00:52:04.420 --> 00:52:08.860]   - It's just marinating that he's holding on to the bots argument
[00:52:08.860 --> 00:52:10.420]   so strongly.
[00:52:11.620 --> 00:52:14.980]   He's a little Trumpian in his adamancy, isn't it?
[00:52:14.980 --> 00:52:17.580]   And of course--
[00:52:17.580 --> 00:52:19.340]   - I don't have a legal standing if he's like,
[00:52:19.340 --> 00:52:22.420]   let's debate this in the court of public opinion.
[00:52:22.420 --> 00:52:25.980]   Why would he do that if he has any legal standing?
[00:52:25.980 --> 00:52:28.740]   - Here's a tweet and Elon has really been
[00:52:28.740 --> 00:52:31.700]   litigating this via Twitter.
[00:52:31.700 --> 00:52:35.700]   I hereby challenge Paragogro to a public debate
[00:52:35.700 --> 00:52:37.020]   about the Twitter bot percentage.
[00:52:37.020 --> 00:52:39.340]   Let him prove to the public that Twitter
[00:52:39.340 --> 00:52:43.060]   has less than 5% faker spam daily users.
[00:52:43.060 --> 00:52:46.900]   - Dude, that's what the lawsuit's gonna be about.
[00:52:46.900 --> 00:52:50.100]   Honestly, the courts are going to decide some of this stuff.
[00:52:50.100 --> 00:52:51.420]   - They sure are.
[00:52:51.420 --> 00:52:52.660]   - Why does he have to debate you?
[00:52:52.660 --> 00:52:54.940]   This is the, I mean, honestly,
[00:52:54.940 --> 00:52:57.540]   everyone knows that Paragog is not gonna be
[00:52:57.540 --> 00:52:59.540]   the CEO of Twitter very much longer,
[00:52:59.540 --> 00:53:01.540]   whether Elon has forced to buy it
[00:53:01.540 --> 00:53:02.540]   or goes into something else.
[00:53:02.540 --> 00:53:07.540]   Like Parag is gone, so I don't even know why you care.
[00:53:07.540 --> 00:53:09.740]   - The lawyers are going to figure this out, dude.
[00:53:09.740 --> 00:53:13.460]   Like not some sort of public debate on Twitter spaces
[00:53:13.460 --> 00:53:16.060]   as entertaining as that would be for all of us.
[00:53:16.060 --> 00:53:18.220]   - You really kind of wonder what is going through
[00:53:18.220 --> 00:53:19.380]   Elon's head sometimes.
[00:53:19.380 --> 00:53:23.140]   You really just like, is it just for fun?
[00:53:23.140 --> 00:53:25.820]   - You've fallen so, I can't help himself.
[00:53:25.820 --> 00:53:27.380]   Like, you know, there's some people that,
[00:53:27.380 --> 00:53:29.180]   every once in a while, you should just put away the phone.
[00:53:29.180 --> 00:53:31.900]   Like, like my rule is like, if you're really upset
[00:53:31.900 --> 00:53:35.060]   or, you know, passionate about something or angry,
[00:53:35.060 --> 00:53:36.820]   you probably shouldn't tweet, you shouldn't call,
[00:53:36.820 --> 00:53:39.580]   you shouldn't talk to anyone until you've kind of calmed down.
[00:53:39.580 --> 00:53:41.100]   But the problem is when you're so powerful,
[00:53:41.100 --> 00:53:43.340]   who's gonna take away your phone?
[00:53:43.340 --> 00:53:45.860]   But sometimes Elon comes out like, you know,
[00:53:45.860 --> 00:53:47.900]   one of these like mustache quirling,
[00:53:47.900 --> 00:53:49.900]   gonna grab his love and just, you know,
[00:53:49.900 --> 00:53:52.220]   (laughing)
[00:53:52.220 --> 00:53:53.740]   you have offended me, so.
[00:53:53.740 --> 00:53:57.260]   Let us 12 paces, please.
[00:53:57.260 --> 00:53:59.100]   (laughing)
[00:53:59.100 --> 00:53:59.940]   You know?
[00:53:59.940 --> 00:54:02.340]   - My name is Elon Musk.
[00:54:02.340 --> 00:54:05.300]   You killed my Twitter, prepare to die.
[00:54:05.300 --> 00:54:07.220]   (laughing)
[00:54:07.220 --> 00:54:08.940]   - Well, and it feels very much like,
[00:54:08.940 --> 00:54:10.540]   I think a lot of people were accusing him
[00:54:10.540 --> 00:54:14.020]   of just making up excuses as to why he wanted to back out
[00:54:14.020 --> 00:54:16.460]   and saying that he probably didn't have the money
[00:54:16.460 --> 00:54:18.420]   that he thought he would to be able to afford it.
[00:54:18.420 --> 00:54:19.860]   And it kind of just feels like,
[00:54:19.860 --> 00:54:21.420]   he's not ready to go down without a fight
[00:54:21.420 --> 00:54:24.060]   in terms of being like, no, this is really the reason why.
[00:54:24.060 --> 00:54:26.220]   Like, this is really why I'm so, you know,
[00:54:26.220 --> 00:54:27.580]   trying to back out of this, I don't know,
[00:54:27.580 --> 00:54:30.140]   that's just the impression I get.
[00:54:30.140 --> 00:54:32.860]   - He's also had to admit that the cyber truck,
[00:54:32.860 --> 00:54:37.860]   which is missing in action, will end up costing more
[00:54:37.860 --> 00:54:38.860]   than he said.
[00:54:38.860 --> 00:54:42.540]   They were talking about a $40,000 price tag,
[00:54:42.540 --> 00:54:45.780]   which even now, I mean, it really doesn't seem
[00:54:45.780 --> 00:54:47.820]   quite right to begin with.
[00:54:47.820 --> 00:54:54.260]   He has now said the pricing, which was unveiled in 2019
[00:54:54.260 --> 00:54:55.700]   and the reservation was $99.
[00:54:55.700 --> 00:54:57.860]   A lot has changed since then.
[00:54:57.860 --> 00:55:00.340]   So the specs and pricing will be different.
[00:55:00.340 --> 00:55:02.540]   I hate to give sort of a little bit of bad news,
[00:55:02.540 --> 00:55:04.540]   but I think there's no way to sort of have,
[00:55:04.540 --> 00:55:05.900]   there's a lot of sort ofs in here.
[00:55:05.900 --> 00:55:08.100]   It's a sort of have anticipated quite the inflation
[00:55:08.100 --> 00:55:09.100]   that we've seen.
[00:55:09.100 --> 00:55:12.100]   It's inflation's fault and the various issues.
[00:55:12.100 --> 00:55:13.580]   That's it, it's inflation.
[00:55:13.580 --> 00:55:17.660]   But he still says, good news, the cyber truck
[00:55:17.660 --> 00:55:20.720]   will be one hell of a product in a damn fine machine.
[00:55:20.720 --> 00:55:26.180]   You could say stuff like that, that's legal, it's okay.
[00:55:26.180 --> 00:55:28.420]   That's just marketing, right?
[00:55:30.220 --> 00:55:33.820]   Still targeting mid 2023 for the start of production.
[00:55:33.820 --> 00:55:39.860]   And they'll be making it at the Gigafactory in Texas.
[00:55:39.860 --> 00:55:44.980]   If you're a reservation holder for the Gigafruck,
[00:55:44.980 --> 00:55:46.980]   it just, I think if you drove that thing around,
[00:55:46.980 --> 00:55:49.540]   that's the one that really looks like you're the Terminator.
[00:55:49.540 --> 00:55:53.980]   People would look a scance at you, would they not?
[00:55:53.980 --> 00:55:55.300]   Oh, absolutely they should.
[00:55:55.300 --> 00:55:56.140]   Oh yeah.
[00:55:56.140 --> 00:55:56.980]   They should.
[00:55:56.980 --> 00:55:58.260]   Yes, they absolutely should.
[00:55:58.260 --> 00:56:00.180]   The bar says then they'd be right.
[00:56:00.180 --> 00:56:01.020]   Yes.
[00:56:01.020 --> 00:56:04.540]   It's not judgment, it's just the fact that's why.
[00:56:04.540 --> 00:56:06.700]   Oh, there's no judgment.
[00:56:06.700 --> 00:56:08.340]   You're just a jerk, sir.
[00:56:08.340 --> 00:56:11.700]   In your jerky car.
[00:56:11.700 --> 00:56:14.540]   All right, a little break time.
[00:56:14.540 --> 00:56:19.340]   We will continue on in moments with our fabulous panel.
[00:56:19.340 --> 00:56:21.220]   What are you working on right now, a bar?
[00:56:21.220 --> 00:56:23.900]   Has you got anything in the hopper?
[00:56:23.900 --> 00:56:26.780]   I'm ready for Samsung Unpack next week.
[00:56:26.780 --> 00:56:27.860]   So next week will be busy.
[00:56:27.860 --> 00:56:28.860]   Ooh.
[00:56:28.860 --> 00:56:30.060]   Stay tuned, yes.
[00:56:30.060 --> 00:56:32.300]   Okay, we're going to talk about that when we come back,
[00:56:32.300 --> 00:56:33.300]   actually.
[00:56:33.300 --> 00:56:35.780]   This is, we're getting to the season, aren't we?
[00:56:35.780 --> 00:56:38.860]   Next month's Apple, probably with a lot of announcements,
[00:56:38.860 --> 00:56:40.540]   as always in September.
[00:56:40.540 --> 00:56:42.860]   Samsung likes to eclipse that a little bit.
[00:56:42.860 --> 00:56:46.460]   I imagine, now last year Google waited till after Apple,
[00:56:46.460 --> 00:56:48.340]   year before Google did it before Apple,
[00:56:48.340 --> 00:56:49.460]   we'll see what Google does.
[00:56:49.460 --> 00:56:50.940]   They have that Pixel watch coming
[00:56:50.940 --> 00:56:55.500]   and the Pixel 7, I guess, is what it is.
[00:56:55.500 --> 00:56:58.980]   And then, yeah, we'll talk about folding phones,
[00:56:58.980 --> 00:57:01.860]   which we expect to see in just a little bit.
[00:57:01.860 --> 00:57:06.860]   Kristia Warren, senior dev advocate at GitHub.
[00:57:06.860 --> 00:57:09.300]   How are things at GitHub?
[00:57:09.300 --> 00:57:11.580]   You've been there now for a couple of months, yeah.
[00:57:11.580 --> 00:57:14.420]   Yeah, I've been there like four months now, it's awesome.
[00:57:14.420 --> 00:57:17.460]   Yeah, I know, yeah, time has flown by.
[00:57:17.460 --> 00:57:20.260]   And it's great, having a good time.
[00:57:20.260 --> 00:57:25.260]   GitHub universe is going to be in San Francisco in November.
[00:57:25.260 --> 00:57:27.780]   Good, maybe we'll see you, that would be great.
[00:57:27.780 --> 00:57:29.780]   Yeah, actually that would be amazing.
[00:57:29.780 --> 00:57:32.100]   I'll have to see when I'm coming into town,
[00:57:32.100 --> 00:57:33.980]   but that would be great if that's possible.
[00:57:33.980 --> 00:57:36.060]   If we can drag you down or up.
[00:57:36.060 --> 00:57:38.700]   I mean, exactly, I was going to say
[00:57:38.700 --> 00:57:40.660]   I would love to come up and visit.
[00:57:40.660 --> 00:57:42.300]   That would be so much fun.
[00:57:42.300 --> 00:57:46.180]   And of course, Georgia Dow, I've got all the videos, Georgia.
[00:57:46.180 --> 00:57:51.180]   So I am no longer anxious, I am no longer calm,
[00:57:52.820 --> 00:57:56.340]   I have, what is this?
[00:57:56.340 --> 00:57:58.740]   Session four, no more anxiety.
[00:57:58.740 --> 00:58:01.020]   Here's parenting, that's too late for me,
[00:58:01.020 --> 00:58:02.820]   that ship is sailed, I'm sorry.
[00:58:02.820 --> 00:58:05.940]   I wish, I wish you'd put these videos out earlier.
[00:58:05.940 --> 00:58:09.340]   Boundaries and consequences, I'm hopeless on that one.
[00:58:09.340 --> 00:58:12.820]   Ah, get the sleepy voice, look at that baby sleeping.
[00:58:12.820 --> 00:58:14.900]   Get the sleepy voice dreamed of
[00:58:14.900 --> 00:58:16.460]   and how to get out of depression.
[00:58:16.460 --> 00:58:17.660]   Are you going to do more of these videos?
[00:58:17.660 --> 00:58:18.500]   I love these.
[00:58:18.500 --> 00:58:22.540]   No, we might do something a little bit different.
[00:58:22.540 --> 00:58:23.860]   We will see.
[00:58:23.860 --> 00:58:25.780]   We might continue with the series,
[00:58:25.780 --> 00:58:27.620]   we'll have to kind of take a look.
[00:58:27.620 --> 00:58:28.460]   We'll see how we go.
[00:58:28.460 --> 00:58:31.300]   If everybody runs to anxiety-videos.com
[00:58:31.300 --> 00:58:33.820]   and buys them, then maybe they'll be more.
[00:58:33.820 --> 00:58:34.580]   How about that?
[00:58:34.580 --> 00:58:35.420]   Maybe.
[00:58:35.420 --> 00:58:40.060]   Yeah, the market is speaking as we speak, Georgia Dow.
[00:58:40.060 --> 00:58:40.900]   And--
[00:58:40.900 --> 00:58:41.940]   There's a lot of anxiety out there.
[00:58:41.940 --> 00:58:45.020]   Oh God, you couldn't have timed it better, right?
[00:58:45.020 --> 00:58:45.860]   Yeah.
[00:58:45.860 --> 00:58:47.020]   You wanna actually, I'm curious,
[00:58:47.020 --> 00:58:49.220]   one of the things I've, Lisa and I both have noticed this,
[00:58:49.220 --> 00:58:52.100]   we've now gone to, there was a music festival
[00:58:52.100 --> 00:58:54.340]   in Petaluma yesterday.
[00:58:54.340 --> 00:58:58.140]   We went somewhere else in the public the day before.
[00:58:58.140 --> 00:59:02.020]   I have this theory that somehow over the two years of COVID
[00:59:02.020 --> 00:59:03.300]   where we were all just staying home,
[00:59:03.300 --> 00:59:05.420]   we all got desocialized.
[00:59:05.420 --> 00:59:08.180]   And we no longer know that other people exist.
[00:59:08.180 --> 00:59:10.500]   There's this, I don't know if it's,
[00:59:10.500 --> 00:59:11.620]   maybe it's different in Canada.
[00:59:11.620 --> 00:59:12.460]   I don't know.
[00:59:12.460 --> 00:59:13.980]   There's this sense, it was people wanting around,
[00:59:13.980 --> 00:59:15.740]   they're not even aware.
[00:59:15.740 --> 00:59:17.140]   You know, people just jump in front of you,
[00:59:17.140 --> 00:59:18.260]   oh, you went to the county fair
[00:59:18.260 --> 00:59:20.540]   and people just walk up in the middle of the line
[00:59:20.540 --> 00:59:21.900]   and they'll come in line.
[00:59:21.900 --> 00:59:23.860]   Like no one else exists.
[00:59:23.860 --> 00:59:27.700]   Is it possible that you forgot because of COVID?
[00:59:27.700 --> 00:59:30.780]   Being with people is a skill, right?
[00:59:30.780 --> 00:59:34.300]   And so that's why a lot of those personal,
[00:59:34.300 --> 00:59:37.260]   interpersonal skills, the newer generations
[00:59:37.260 --> 00:59:38.620]   are having much more difficulty.
[00:59:38.620 --> 00:59:40.500]   There's much more social anxiety
[00:59:40.500 --> 00:59:42.340]   because they're doing a lot of interaction
[00:59:42.340 --> 00:59:45.940]   through a computer screen or just by text
[00:59:45.940 --> 00:59:48.580]   and learning how to read body image
[00:59:48.580 --> 00:59:52.060]   and body language is really difficult
[00:59:52.060 --> 00:59:53.740]   if you're not socialized to do it.
[00:59:53.740 --> 00:59:54.660]   We used to be so bored,
[00:59:54.660 --> 00:59:55.820]   we'd wanna hang around with each other
[00:59:55.820 --> 00:59:58.860]   and now we're like such an antithesis, like stay away.
[00:59:58.860 --> 00:59:59.980]   - Stay away from me.
[00:59:59.980 --> 01:00:00.820]   Don't touch me.
[01:00:00.820 --> 01:00:04.700]   - People are an illness, so we're like really stay away.
[01:00:04.700 --> 01:00:06.140]   - Get people equal COVID.
[01:00:06.140 --> 01:00:07.060]   - Get people equal those skills.
[01:00:07.060 --> 01:00:07.900]   - Yes.
[01:00:07.900 --> 01:00:09.460]   - Don't go to a movie theater
[01:00:09.460 --> 01:00:10.860]   'cause it's full of teenagers
[01:00:10.860 --> 01:00:13.620]   who have completely forgotten
[01:00:13.620 --> 01:00:15.740]   there's anybody else in the world
[01:00:15.740 --> 01:00:16.940]   and they're making a mess,
[01:00:16.940 --> 01:00:19.580]   they're talking, they're throwing popcorn around.
[01:00:19.580 --> 01:00:21.620]   It's like they're at home.
[01:00:21.620 --> 01:00:24.980]   - Yeah, it's a very strange thing.
[01:00:24.980 --> 01:00:27.660]   But then I watch videos that are like movies from like,
[01:00:27.660 --> 01:00:29.260]   I don't know, whatever, seven years ago,
[01:00:29.260 --> 01:00:31.220]   10 years ago and it's like a rave scene
[01:00:31.220 --> 01:00:32.980]   and everyone's spitting and yelling at each other
[01:00:32.980 --> 01:00:34.180]   and I'm like, that's gross.
[01:00:34.180 --> 01:00:35.020]   - Right, right.
[01:00:35.020 --> 01:00:35.860]   - Right.
[01:00:35.860 --> 01:00:36.700]   - That's not right.
[01:00:36.700 --> 01:00:37.540]   - Oh, we did not speak the name.
[01:00:37.540 --> 01:00:38.620]   - We didn't even know.
[01:00:38.620 --> 01:00:40.860]   Oh my God, what's wrong with us?
[01:00:40.860 --> 01:00:43.020]   We're, look how close he's standing.
[01:00:43.020 --> 01:00:45.140]   Oh my, is that funny?
[01:00:45.140 --> 01:00:45.980]   - I know.
[01:00:45.980 --> 01:00:47.420]   - Is that hysterical?
[01:00:47.420 --> 01:00:48.260]   - Yeah.
[01:00:48.260 --> 01:00:50.460]   - Oh, there are all of these weird changes
[01:00:50.460 --> 01:00:52.580]   in society that we have to adapt to
[01:00:52.580 --> 01:00:54.820]   but if you don't do something, you lose the skill
[01:00:54.820 --> 01:00:57.380]   and socialization is another one of the skills that--
[01:00:57.380 --> 01:01:00.740]   - Have you gotten COVID yet or are you still a unit?
[01:01:00.740 --> 01:01:04.540]   - I have not yet gotten COVID as of yet.
[01:01:04.540 --> 01:01:06.060]   It's, we've been lucky enough.
[01:01:06.060 --> 01:01:06.900]   - How about you, if you've been able to--
[01:01:06.900 --> 01:01:07.740]   - I didn't know.
[01:01:07.740 --> 01:01:09.580]   - Have you been able to dodge?
[01:01:09.580 --> 01:01:11.380]   - I have not been able to dodge right out a few months ago
[01:01:11.380 --> 01:01:13.020]   but it was actually great 'cause I was like,
[01:01:13.020 --> 01:01:13.860]   - Yeah.
[01:01:13.860 --> 01:01:15.460]   - It's like a free booster, you know?
[01:01:15.460 --> 01:01:17.380]   Now that I survived, I didn't die.
[01:01:17.380 --> 01:01:18.220]   - I love it, yeah.
[01:01:18.220 --> 01:01:19.220]   - Yeah, exactly.
[01:01:19.220 --> 01:01:21.180]   - I'm going, oh good now, I got a little extra.
[01:01:21.180 --> 01:01:23.660]   - Did you get a week off to be able to just chill
[01:01:23.660 --> 01:01:25.300]   and relax and everyone has to serve you?
[01:01:25.300 --> 01:01:26.180]   There are some benefits.
[01:01:26.180 --> 01:01:27.460]   - Yeah, and it was very mild.
[01:01:27.460 --> 01:01:28.380]   I mean, I'm lucky.
[01:01:28.380 --> 01:01:29.820]   At least it did not get it as mildly.
[01:01:29.820 --> 01:01:33.180]   She's still got aches and pains and cognitive fog
[01:01:33.180 --> 01:01:34.820]   and so forth but--
[01:01:34.820 --> 01:01:35.660]   - It sucks.
[01:01:35.660 --> 01:01:36.500]   - Relatively mild.
[01:01:36.500 --> 01:01:38.820]   I mean, we didn't have to get on it going on ventilator
[01:01:38.820 --> 01:01:41.860]   and I feel like, I don't know, on the one hand
[01:01:41.860 --> 01:01:45.020]   it was like, oh, we had this, two years
[01:01:45.020 --> 01:01:50.020]   of absolute insane, like washing our hands
[01:01:50.020 --> 01:01:52.740]   five times a day for 20s,
[01:01:52.740 --> 01:01:54.660]   singing happy birthday over and over.
[01:01:54.660 --> 01:01:57.740]   And it's like, and then now it's like,
[01:01:57.740 --> 01:02:00.020]   I don't care now, I don't care anymore.
[01:02:00.020 --> 01:02:02.380]   - Yeah, I think we've realized we're not gonna die.
[01:02:02.380 --> 01:02:03.780]   Well, hopefully, right?
[01:02:03.780 --> 01:02:05.340]   Like, so we're like, okay, you know,
[01:02:05.340 --> 01:02:08.540]   I might feel down for a bit, but it's not like for death.
[01:02:08.540 --> 01:02:10.900]   - It's like a cold, it's not as bad as a flu at least.
[01:02:10.900 --> 01:02:13.700]   How about you, Christina, have you managed to dodge it or?
[01:02:13.700 --> 01:02:15.380]   - No, I had it in December.
[01:02:15.380 --> 01:02:16.740]   - I think I remember that.
[01:02:16.740 --> 01:02:18.980]   - Yeah, I got the Omocron, kind of the same as everybody else.
[01:02:18.980 --> 01:02:20.300]   So, yeah.
[01:02:20.300 --> 01:02:22.420]   - I'm sure we got, 'cause we got it two weeks ago
[01:02:22.420 --> 01:02:25.620]   on that cruise, I'm sure we got BA-5 the latest.
[01:02:25.620 --> 01:02:27.980]   So I feel like, yeah, you're so trendy.
[01:02:27.980 --> 01:02:28.980]   - I'm trendy, you got the latest.
[01:02:28.980 --> 01:02:30.340]   - I was gonna say, you got the latest thing,
[01:02:30.340 --> 01:02:32.220]   'cause I still only have the one booster
[01:02:32.220 --> 01:02:34.220]   because that's what they've been encouraging people
[01:02:34.220 --> 01:02:35.060]   to do right now.
[01:02:35.060 --> 01:02:36.060]   They're like, now they're like,
[01:02:36.060 --> 01:02:38.020]   well, don't get the second booster,
[01:02:38.020 --> 01:02:39.900]   because we're waiting for new vaccines.
[01:02:39.900 --> 01:02:41.940]   And I'm like, okay, fine, whatever.
[01:02:41.940 --> 01:02:44.220]   Just tell me what shot I need to get,
[01:02:44.220 --> 01:02:45.620]   and I'll get it, it's fine.
[01:02:45.620 --> 01:02:48.460]   - And with all of that and all that size of relief,
[01:02:48.460 --> 01:02:49.780]   it is still very dangerous.
[01:02:49.780 --> 01:02:52.380]   There are a lot of people who have immune compromised
[01:02:52.380 --> 01:02:53.980]   or they're older or whatever.
[01:02:53.980 --> 01:02:56.820]   And so absolutely, I'm still wearing the mask
[01:02:56.820 --> 01:02:59.300]   and very careful, I don't wanna get anybody sick.
[01:02:59.300 --> 01:03:02.060]   But I feel like some of the pressure is off me.
[01:03:02.060 --> 01:03:05.420]   Like, right, it's like, all right, okay.
[01:03:05.420 --> 01:03:07.660]   - And I feel really bad for people
[01:03:07.660 --> 01:03:09.540]   who lost sense of taste and smell.
[01:03:09.540 --> 01:03:12.740]   That I feel like I would not have been able to tolerate.
[01:03:12.740 --> 01:03:15.380]   - Yeah, Lisa, when you know what's really bad about that,
[01:03:15.380 --> 01:03:16.620]   when it comes back,
[01:03:16.620 --> 01:03:20.220]   somebody was telling me this is an evolutionary thing
[01:03:20.220 --> 01:03:23.140]   to protect you, the disgusting taste,
[01:03:23.140 --> 01:03:24.740]   the smell compacts first,
[01:03:24.740 --> 01:03:27.980]   so that you won't eat bad food and bad stuff.
[01:03:27.980 --> 01:03:32.380]   So everything tastes horrible for a while.
[01:03:32.380 --> 01:03:34.780]   And Lisa's at that stage where--
[01:03:34.780 --> 01:03:35.620]   - Oh, that's horrible.
[01:03:35.620 --> 01:03:37.500]   - Oh, I know. - Is it going to a restaurant?
[01:03:37.500 --> 01:03:39.180]   - Oh my God, forget that.
[01:03:39.180 --> 01:03:40.940]   She kissed me and she went, "Ew!"
[01:03:40.940 --> 01:03:45.460]   So forget that, it's not good.
[01:03:45.460 --> 01:03:46.980]   Yeah, so.
[01:03:46.980 --> 01:03:47.820]   - Oh, sorry.
[01:03:47.820 --> 01:03:48.820]   - I know.
[01:03:48.820 --> 01:03:51.100]   She said, "What are you eating?"
[01:03:51.100 --> 01:03:52.380]   I said, "No, I'm fine."
[01:03:52.380 --> 01:03:54.460]   She said, "Oh, you smell bad."
[01:03:54.460 --> 01:03:55.620]   - I was like, "No, you're not."
[01:03:55.620 --> 01:03:56.460]   I'm like, "Oh, no."
[01:03:56.460 --> 01:03:57.940]   - Oh, no.
[01:03:57.940 --> 01:04:00.380]   Never thought that would happen.
[01:04:00.380 --> 01:04:02.060]   Anyway, yes, be careful.
[01:04:02.060 --> 01:04:05.460]   Not advocating in any way letting your guard down.
[01:04:05.460 --> 01:04:07.460]   That's clearly still a problem.
[01:04:07.460 --> 01:04:10.500]   We don't in public, but at the same time,
[01:04:10.500 --> 01:04:12.940]   kind of like the pressure's off a little bit anyway,
[01:04:12.940 --> 01:04:14.180]   a little bit.
[01:04:14.180 --> 01:04:16.380]   And I'm glad you all are here and survived.
[01:04:16.380 --> 01:04:17.260]   Let's put it that way.
[01:04:17.260 --> 01:04:20.340]   And Georgia, good luck in keeping your super,
[01:04:20.340 --> 01:04:21.180]   what do they call you?
[01:04:21.180 --> 01:04:22.940]   What is it?
[01:04:22.940 --> 01:04:23.940]   - No, I'm from super dodger.
[01:04:23.940 --> 01:04:25.660]   - Super dodger, you're a super dodger.
[01:04:25.660 --> 01:04:28.740]   - So far, so far so you could like, you know--
[01:04:28.740 --> 01:04:30.340]   - Do you never go anywhere outside?
[01:04:30.340 --> 01:04:32.500]   But you got kids in school, right?
[01:04:32.500 --> 01:04:34.740]   - We just came back from Florida, so.
[01:04:34.740 --> 01:04:36.420]   - Well, stay away from here.
[01:04:36.420 --> 01:04:38.500]   Went to Universal, went to Disney.
[01:04:38.500 --> 01:04:39.420]   - What?
[01:04:39.420 --> 01:04:40.940]   And you didn't catch anything.
[01:04:40.940 --> 01:04:41.780]   Wow.
[01:04:41.780 --> 01:04:44.300]   - No, but we did wear our masks at Disney.
[01:04:44.300 --> 01:04:47.260]   I know, not the coolest of luck, but--
[01:04:47.260 --> 01:04:48.740]   - No, no, no, I'm wearing mine.
[01:04:48.740 --> 01:04:53.540]   In fact, I was told I couldn't get on the plane with this.
[01:04:53.540 --> 01:04:57.540]   I'm wearing a respirator now, not just,
[01:04:57.540 --> 01:05:00.420]   'cause now I really, now it's like, obviously--
[01:05:00.420 --> 01:05:01.500]   - We have them too.
[01:05:01.500 --> 01:05:04.300]   - I needed better masks, and these don't wear out as fast.
[01:05:04.300 --> 01:05:07.300]   So, but you also, you look like Bane.
[01:05:07.300 --> 01:05:09.900]   - It looks awesome, I have to say actually,
[01:05:09.900 --> 01:05:11.780]   you look really cool.
[01:05:11.780 --> 01:05:12.620]   I'm sorry, like--
[01:05:12.620 --> 01:05:13.780]   - Like a fighter pilot.
[01:05:13.780 --> 01:05:14.620]   - You're really cool.
[01:05:14.620 --> 01:05:15.620]   - I like it, I think it's looking cool.
[01:05:15.620 --> 01:05:16.980]   - Call me Maverick, yeah.
[01:05:16.980 --> 01:05:17.820]   - Yeah.
[01:05:17.820 --> 01:05:18.660]   (laughing)
[01:05:18.660 --> 01:05:19.500]   Good movie.
[01:05:19.500 --> 01:05:20.580]   (laughing)
[01:05:20.580 --> 01:05:21.860]   - All right, all right.
[01:05:21.860 --> 01:05:24.300]   Anyway, please everybody, we don't wanna lose anybody.
[01:05:24.300 --> 01:05:26.060]   Stay safe, protect yourself.
[01:05:26.060 --> 01:05:29.980]   We'll get through this, we'll get through this someday, somehow.
[01:05:29.980 --> 01:05:32.580]   Our show today brought to you by podium.
[01:05:32.580 --> 01:05:37.020]   I have to say, one of the really interesting changes
[01:05:37.020 --> 01:05:40.140]   in society thanks to COVID and quarantine,
[01:05:40.140 --> 01:05:43.180]   is we've gotten really used to text messages,
[01:05:43.180 --> 01:05:45.300]   communicating via text, getting a text,
[01:05:45.300 --> 01:05:46.860]   your food's on the way, or getting a text,
[01:05:46.860 --> 01:05:48.220]   you can pick up your groceries now.
[01:05:48.220 --> 01:05:52.220]   And you know, it's the best way to do business.
[01:05:52.220 --> 01:05:54.180]   It is better than email, better than phone calls,
[01:05:54.180 --> 01:05:55.540]   better than anything.
[01:05:55.540 --> 01:05:56.700]   If you own a small business,
[01:05:56.700 --> 01:05:58.380]   and you've survived the last couple of years,
[01:05:58.380 --> 01:06:00.260]   and I know they've been hard,
[01:06:00.260 --> 01:06:02.740]   not just supply chain issues,
[01:06:02.740 --> 01:06:04.180]   demand you didn't expect,
[01:06:04.180 --> 01:06:06.220]   and you've got to, you know,
[01:06:06.220 --> 01:06:08.740]   all that stuff, businesses that thrive right now
[01:06:08.740 --> 01:06:11.060]   are the ones who, you know, in recession,
[01:06:11.060 --> 01:06:12.860]   you've got to plan for growth.
[01:06:12.860 --> 01:06:14.500]   This is an opportunity.
[01:06:14.500 --> 01:06:16.460]   And the businesses who are planning for that
[01:06:16.460 --> 01:06:18.540]   are doing, are thriving.
[01:06:18.540 --> 01:06:21.260]   podium helps your small business stay ahead of the curve
[01:06:21.260 --> 01:06:24.900]   with modern messaging tools that's kind of remarkable.
[01:06:24.900 --> 01:06:28.460]   We have a few businesses in our small town that use podium,
[01:06:28.460 --> 01:06:29.300]   and I love it.
[01:06:29.300 --> 01:06:30.140]   I love businesses.
[01:06:30.140 --> 01:06:31.060]   I leave the dentist's office.
[01:06:31.060 --> 01:06:34.540]   Before I am two steps away, I get a text saying,
[01:06:34.540 --> 01:06:35.820]   how was our service?
[01:06:35.820 --> 01:06:40.020]   Leave a review for us on Yelp, or Google business?
[01:06:40.020 --> 01:06:42.540]   It's amazing.
[01:06:42.540 --> 01:06:43.380]   Every once in a while,
[01:06:43.380 --> 01:06:44.220]   and I don't like this one.
[01:06:44.220 --> 01:06:46.020]   I mentioned it before I get a text message
[01:06:46.020 --> 01:06:47.700]   from our local ice cream parlor saying,
[01:06:47.700 --> 01:06:48.540]   we haven't seen you in a while.
[01:06:48.540 --> 01:06:50.500]   Here's a 20% coupon.
[01:06:50.500 --> 01:06:51.740]   Well, thanks.
[01:06:51.740 --> 01:06:53.500]   Now I got to go get ice cream.
[01:06:53.500 --> 01:06:55.180]   It works.
[01:06:55.180 --> 01:06:57.020]   And if you are a business, a plumber,
[01:06:57.020 --> 01:07:01.140]   a landscaper playing phone tag with potential customers,
[01:07:01.140 --> 01:07:02.980]   people hate calling.
[01:07:02.980 --> 01:07:04.580]   They don't like to do that.
[01:07:04.580 --> 01:07:07.340]   They'd rather send you a message and you can message back
[01:07:07.340 --> 01:07:09.260]   and you don't play that phone tag.
[01:07:09.260 --> 01:07:11.700]   It's the best way to stay in touch with you.
[01:07:11.700 --> 01:07:12.740]   If you're running a business,
[01:07:12.740 --> 01:07:14.420]   and the only way to get in touch with you
[01:07:14.420 --> 01:07:15.420]   is with a phone number,
[01:07:15.420 --> 01:07:16.980]   you're going to be losing business.
[01:07:16.980 --> 01:07:19.740]   podium gives businesses the tools to compete
[01:07:19.740 --> 01:07:22.460]   with the convenience offered by big businesses
[01:07:22.460 --> 01:07:24.780]   like Amazon now, right?
[01:07:24.780 --> 01:07:27.220]   From healthcare providers to plumbers,
[01:07:27.220 --> 01:07:29.860]   over 100,000 businesses are texting with customers
[01:07:29.860 --> 01:07:32.980]   through podium, B-O-D-I-U-M.
[01:07:32.980 --> 01:07:35.180]   Customers love the convenience and business
[01:07:35.180 --> 01:07:36.260]   loves the results.
[01:07:36.260 --> 01:07:38.300]   One car dealer sold their $50,000 truck
[01:07:38.300 --> 01:07:39.700]   and four text messages.
[01:07:39.700 --> 01:07:41.180]   That's happening more and more, right?
[01:07:41.180 --> 01:07:45.020]   You get text message, hey, we got a great deal right now
[01:07:45.020 --> 01:07:46.620]   on a Ford Lightning, come on in
[01:07:46.620 --> 01:07:48.220]   and you can sell it right away.
[01:07:48.220 --> 01:07:52.580]   A jeweler sold a $5,000 ring, coordinated curbside pickups,
[01:07:52.580 --> 01:07:56.860]   the whole thing, the whole transaction through texts.
[01:07:56.860 --> 01:07:58.860]   You can also collect with podium.
[01:07:58.860 --> 01:08:00.620]   People can pay you through podium.
[01:08:00.620 --> 01:08:04.060]   A dentist sent payment requests through texts
[01:08:04.060 --> 01:08:05.340]   instead of bills in the mail,
[01:08:05.340 --> 01:08:08.780]   got 70% of their outstanding collections in just two weeks.
[01:08:08.780 --> 01:08:10.260]   'Cause it's easy, it's low friction.
[01:08:10.260 --> 01:08:11.220]   Oh yeah, okay.
[01:08:11.220 --> 01:08:12.700]   Here, let me send you the money.
[01:08:12.700 --> 01:08:14.140]   With podiums all in one inbox,
[01:08:14.140 --> 01:08:15.820]   you can do even more than just chat.
[01:08:15.820 --> 01:08:18.300]   You can get online reviews, just send out a link.
[01:08:18.300 --> 01:08:20.580]   You can collect payments fast from anywhere.
[01:08:20.580 --> 01:08:22.060]   You could send marketing campaigns
[01:08:22.060 --> 01:08:23.140]   and get a response, you know?
[01:08:23.140 --> 01:08:27.940]   The read percentage on text messages is well over 90%,
[01:08:27.940 --> 01:08:29.860]   so much better than email
[01:08:29.860 --> 01:08:32.180]   than any other way of communicating.
[01:08:32.180 --> 01:08:34.740]   And your customers actually appreciate it.
[01:08:34.740 --> 01:08:35.820]   They actually like it.
[01:08:35.820 --> 01:08:37.820]   See how podium can grow your business?
[01:08:37.820 --> 01:08:39.580]   They've got a demo waiting for you right now,
[01:08:39.580 --> 01:08:44.580]   podiumpodim.com/twit.
[01:08:44.580 --> 01:08:46.860]   Especially for small businesses,
[01:08:46.860 --> 01:08:49.540]   this is a great way to stay in touch with your customers.
[01:08:49.540 --> 01:08:54.380]   podium.com/twitpodim.
[01:08:54.380 --> 01:08:55.580]   Let's grow.
[01:08:55.580 --> 01:08:59.340]   Let's see.
[01:08:59.340 --> 01:09:01.740]   Washington Post, great article by Jeffrey Fowler.
[01:09:01.740 --> 01:09:05.620]   Here's why your gadgets die so quickly.
[01:09:05.620 --> 01:09:07.940]   Electronics are built with death dates.
[01:09:07.940 --> 01:09:11.500]   Let's not keep them a secret.
[01:09:11.500 --> 01:09:14.460]   And he actually put together a gadget graveyard,
[01:09:14.460 --> 01:09:16.580]   which I thought was really good.
[01:09:16.580 --> 01:09:19.020]   The hidden death dates on popular devices,
[01:09:19.020 --> 01:09:21.700]   these are devices that the batteries cannot be replaced.
[01:09:21.700 --> 01:09:23.540]   And as you know, lithium ion batteries
[01:09:23.540 --> 01:09:25.660]   have a certain number of charge cycles.
[01:09:25.660 --> 01:09:29.260]   After that, you can't charge them anymore.
[01:09:29.260 --> 01:09:33.420]   If you've got air pods, after two years in most cases,
[01:09:33.420 --> 01:09:35.700]   you're just gonna have to throw them away and get a new one.
[01:09:35.700 --> 01:09:39.260]   Apple sells, has a quote replacement deal
[01:09:39.260 --> 01:09:41.820]   where you pay 49 bucks for one air pod.
[01:09:41.820 --> 01:09:44.780]   But they don't, and I don't know,
[01:09:44.780 --> 01:09:47.020]   they maybe they recycle it when you send it back to them,
[01:09:47.020 --> 01:09:50.540]   but I suspect there's quite a few air pods in the landfill.
[01:09:50.540 --> 01:09:52.780]   Amazon Fire HD 8 tablet.
[01:09:52.780 --> 01:09:56.620]   Amazon won't disclose how many recharges it can take.
[01:09:56.620 --> 01:09:59.420]   Amazon offers no battery replacement service.
[01:09:59.420 --> 01:10:03.260]   You can go to iFixit, I think, and get a battery.
[01:10:03.260 --> 01:10:06.940]   And while it's not easy, you could, I guess, replace it.
[01:10:06.940 --> 01:10:10.100]   But I would guess most Amazon tablets
[01:10:10.100 --> 01:10:13.900]   end up in landfill, like air pods.
[01:10:13.900 --> 01:10:15.620]   iPhones, good on Apple.
[01:10:15.620 --> 01:10:20.620]   They will, for 69 bucks, replace it, the battery.
[01:10:20.620 --> 01:10:22.980]   Same with the MacBooks.
[01:10:22.980 --> 01:10:27.300]   Not so much with the Bose QC35 noise canceling headphones.
[01:10:27.300 --> 01:10:30.620]   No out of warranty battery replacement service.
[01:10:30.620 --> 01:10:33.340]   What do you think?
[01:10:33.340 --> 01:10:36.420]   You know, a bro, are you cover consumer technology?
[01:10:36.420 --> 01:10:40.220]   Do you ever talk about this as an issue?
[01:10:40.220 --> 01:10:43.340]   - Yeah, I think, you know, this conversation around
[01:10:43.340 --> 01:10:45.860]   electronic waste is something that's really ramping up.
[01:10:45.860 --> 01:10:48.220]   And, you know, that's one side of it,
[01:10:48.220 --> 01:10:49.700]   and the other side of it is also,
[01:10:49.700 --> 01:10:52.780]   we don't feel like we are ready to let go of our devices
[01:10:52.780 --> 01:10:54.020]   as quickly as we have to.
[01:10:54.020 --> 01:10:57.420]   And it's really annoying that it is like, okay, I've had my,
[01:10:57.420 --> 01:11:00.020]   I'm approaching the two year mark of how long I've had my phone,
[01:11:00.020 --> 01:11:01.260]   and I know I have to replace it,
[01:11:01.260 --> 01:11:03.460]   and there's nothing I can do about it.
[01:11:03.460 --> 01:11:07.100]   And so I think, you know, I love that this article is like,
[01:11:07.100 --> 01:11:09.420]   let's discuss the fact that this is like not something
[01:11:09.420 --> 01:11:10.580]   that we should just be accepting.
[01:11:10.580 --> 01:11:12.540]   And I think that, you know, one of the things
[01:11:12.540 --> 01:11:14.060]   that it brings up that I think is really interesting
[01:11:14.060 --> 01:11:15.260]   is that the marketing angle.
[01:11:15.260 --> 01:11:17.100]   Like in order for us to make your phone a slim
[01:11:17.100 --> 01:11:19.260]   and waterproof as we want to make it,
[01:11:19.260 --> 01:11:21.380]   sorry you're not going to be able to access the battery.
[01:11:21.380 --> 01:11:23.380]   And we've kind of just gone along with it,
[01:11:23.380 --> 01:11:25.660]   like, okay, in the name of innovation, sure, okay,
[01:11:25.660 --> 01:11:26.940]   these design changes are something
[01:11:26.940 --> 01:11:29.420]   that's going to make it, you know, better.
[01:11:29.420 --> 01:11:33.660]   But it is really unfortunate and wasteful and a pain
[01:11:33.660 --> 01:11:36.420]   for consumers to have to constantly feel like
[01:11:36.420 --> 01:11:39.300]   they have to switch out, you know, their devices also
[01:11:39.300 --> 01:11:41.260]   in the name of keeping up with trends.
[01:11:41.260 --> 01:11:43.260]   And I feel like Apple does a really good job
[01:11:43.260 --> 01:11:46.060]   of making people feel like it's time for them to upgrade
[01:11:46.060 --> 01:11:49.100]   to a new device, not because they feel like they want to,
[01:11:49.100 --> 01:11:51.700]   but because they have to look like they're on top of it.
[01:11:51.700 --> 01:11:54.820]   - Aren't we all looking forward to the iPhone 14
[01:11:54.820 --> 01:11:58.380]   and September and all the, ooh, shiny, shiny, shiny.
[01:11:58.380 --> 01:11:59.780]   - Yeah, absolutely.
[01:11:59.780 --> 01:12:01.820]   - I admit, you know, I fall for that too.
[01:12:01.820 --> 01:12:04.620]   By the way, it's not just at the end of the life,
[01:12:04.620 --> 01:12:06.820]   about 70, according to Apple,
[01:12:06.820 --> 01:12:11.140]   about 70% of the carbon emissions come from manufacturer.
[01:12:11.140 --> 01:12:13.620]   So the longer you, it's not just throwing it out,
[01:12:13.620 --> 01:12:15.140]   the longer you can keep in service,
[01:12:15.140 --> 01:12:17.500]   that's one more phone, air pod,
[01:12:17.500 --> 01:12:18.980]   something that doesn't have to be manufactured.
[01:12:18.980 --> 01:12:22.260]   And that's a big source of emissions.
[01:12:22.260 --> 01:12:25.300]   Yeah, I think, look, it's not going to go away,
[01:12:25.300 --> 01:12:26.700]   but it's important to be aware of it.
[01:12:26.700 --> 01:12:29.780]   And that's just to kind of unconsciously say, oh yeah,
[01:12:29.780 --> 01:12:30.860]   let's get it.
[01:12:30.860 --> 01:12:33.780]   I wish, honestly, I really wish, you know what,
[01:12:33.780 --> 01:12:37.020]   my battery never dies on my wired headphones.
[01:12:37.020 --> 01:12:38.860]   I wish-- - They just never will.
[01:12:38.860 --> 01:12:41.620]   - It just drives me crazy that it really,
[01:12:41.620 --> 01:12:44.820]   it looks like Apple and Samsung and others.
[01:12:44.820 --> 01:12:48.980]   It's just because they want to sell Bluetooth headphones.
[01:12:48.980 --> 01:12:51.740]   There's rumors that the next iPad
[01:12:51.740 --> 01:12:53.140]   will not have a headphone jack.
[01:12:53.140 --> 01:12:54.740]   There is no reason for that.
[01:12:54.740 --> 01:12:56.300]   There's plenty of room.
[01:12:56.300 --> 01:12:58.180]   - I hate that.
[01:12:58.180 --> 01:12:59.020]   I hate that.
[01:12:59.020 --> 01:13:01.420]   I use, and I know I'm probably the only one.
[01:13:01.420 --> 01:13:02.700]   Christina, don't judge me.
[01:13:02.700 --> 01:13:03.540]   Don't judge me.
[01:13:03.540 --> 01:13:04.380]   - I won't judge you. - I won't judge you.
[01:13:04.380 --> 01:13:06.340]   - I only use-- - Look at Christina's
[01:13:06.340 --> 01:13:07.820]   on wired headphones right now.
[01:13:07.820 --> 01:13:09.540]   - I'm gone wired right now,
[01:13:09.540 --> 01:13:12.940]   but I bet that Christina has like all of the best of Bluetooth.
[01:13:12.940 --> 01:13:16.340]   But I don't-- - But I'm not gonna judge you.
[01:13:16.340 --> 01:13:18.220]   No, and I don't blame you for it, honestly.
[01:13:18.220 --> 01:13:19.220]   I don't blame you for it at all.
[01:13:19.220 --> 01:13:21.860]   Like, there's even-- - I just want to work.
[01:13:21.860 --> 01:13:24.260]   - And by the way, why are you even works better?
[01:13:24.260 --> 01:13:25.500]   - And I wanted to plug it into,
[01:13:25.500 --> 01:13:27.300]   I wanted to plug into,
[01:13:27.300 --> 01:13:28.620]   and I know it's gonna be there
[01:13:28.620 --> 01:13:31.580]   and it's not gonna play on like my home pod
[01:13:31.580 --> 01:13:33.420]   and one of my clients are suddenly talking to me.
[01:13:33.420 --> 01:13:35.420]   - Totally. - It's on a home pod somewhere.
[01:13:35.420 --> 01:13:37.780]   It's in my car Bluetooth, but it shouldn't be.
[01:13:37.780 --> 01:13:40.620]   And so I carry around, I'll be honest,
[01:13:40.620 --> 01:13:43.940]   I steal from Renee, 'cause he has all of the,
[01:13:43.940 --> 01:13:46.900]   like all these little packages of like all of the--
[01:13:46.900 --> 01:13:48.260]   - He does it, he does it, he does it.
[01:13:48.260 --> 01:13:49.460]   - He doesn't even open them, right?
[01:13:49.460 --> 01:13:51.540]   He just has them sitting there and fully re--
[01:13:51.540 --> 01:13:52.820]   - He has 100,000, I'm suddenly like,
[01:13:52.820 --> 01:13:53.980]   "Oh, I'm gonna grab two of them."
[01:13:53.980 --> 01:13:57.380]   And I carry both, like the 3.5 millimeter.
[01:13:57.380 --> 01:13:59.900]   And like, yeah, I carry them all in my purse
[01:13:59.900 --> 01:14:04.300]   because I like wired for everything.
[01:14:04.300 --> 01:14:09.060]   And I hate charging batteries, I'm lazy as can be,
[01:14:09.060 --> 01:14:11.020]   I lose the bloody things.
[01:14:11.020 --> 01:14:13.620]   Then when I finally decide to use them 100%,
[01:14:13.620 --> 01:14:15.660]   I drained them by that time.
[01:14:15.660 --> 01:14:19.300]   And then I'm just hungry and frustrated and yeah,
[01:14:19.300 --> 01:14:22.500]   so I am so old school that way, I'm sorry,
[01:14:22.500 --> 01:14:25.900]   everyone can judge me, send all of your hate
[01:14:25.900 --> 01:14:27.180]   to like at the--
[01:14:27.180 --> 01:14:29.260]   - No, you're right. - No, you're fine,
[01:14:29.260 --> 01:14:30.900]   you're fine. - And honestly,
[01:14:30.900 --> 01:14:33.180]   I think we could put pressure on Apple,
[01:14:33.180 --> 01:14:35.740]   keep the headphone jack, put it back.
[01:14:35.740 --> 01:14:38.060]   - No, 'cause here's the thing,
[01:14:38.060 --> 01:14:41.660]   like AirPods are good enough and some of the Bluetooth stuff,
[01:14:41.660 --> 01:14:42.860]   even though there are those frustrations
[01:14:42.860 --> 01:14:43.820]   that I totally agree with,
[01:14:43.820 --> 01:14:45.420]   the convenience for a lot of us,
[01:14:45.420 --> 01:14:49.140]   we would still use, like I would still use AirPods,
[01:14:49.140 --> 01:14:51.060]   I would still use like over the ear,
[01:14:51.060 --> 01:14:52.740]   like maybe I'd have them plugged in,
[01:14:52.740 --> 01:14:53.820]   maybe I wouldn't, it would depend,
[01:14:53.820 --> 01:14:56.300]   but I would probably still use wireless more often than not.
[01:14:56.300 --> 01:14:58.020]   Like that's not going to be changing
[01:14:58.020 --> 01:15:00.340]   just because my phone has a headphone jack on it.
[01:15:00.340 --> 01:15:03.620]   Like if you are, in my opinion,
[01:15:03.620 --> 01:15:06.300]   like if you're somebody who's choosing to spend $200
[01:15:06.300 --> 01:15:07.500]   on a pair of AirPods,
[01:15:07.500 --> 01:15:10.300]   it's because you appreciate that convenience,
[01:15:10.300 --> 01:15:12.020]   not so much because like that's the only way
[01:15:12.020 --> 01:15:13.500]   you can connect them into your phone.
[01:15:13.500 --> 01:15:14.660]   So-- - Except that it--
[01:15:14.660 --> 01:15:17.340]   - Yeah, it is. - You have to buy some
[01:15:17.340 --> 01:15:19.220]   sort of Bluetooth. - Right, we have to--
[01:15:19.220 --> 01:15:22.820]   - Or use the stupid wired headphones that come in the box,
[01:15:22.820 --> 01:15:25.660]   but like, you know, they'd have the lightning connector.
[01:15:25.660 --> 01:15:26.980]   I'm just saying like $200. - Oh, can I,
[01:15:26.980 --> 01:15:28.740]   do you think anybody does that?
[01:15:28.740 --> 01:15:31.580]   - Yeah, last year it became like a trend to be,
[01:15:31.580 --> 01:15:33.900]   it was like an aesthetic thing where there were a number
[01:15:33.900 --> 01:15:36.660]   of like very big fashion influencers who were doing that.
[01:15:36.660 --> 01:15:37.500]   - Oh, really? - So, Georgia,
[01:15:37.500 --> 01:15:39.820]   you're like on trend actually.
[01:15:39.820 --> 01:15:43.100]   Yeah, it's kind of like a weird throwback to, you know,
[01:15:43.100 --> 01:15:46.300]   like 2000s, you know, like aesthetic.
[01:15:46.300 --> 01:15:47.420]   I don't know. - Long enough,
[01:15:47.420 --> 01:15:49.420]   it comes back around-- - It comes back around.
[01:15:49.420 --> 01:15:52.260]   - No, I was, I'm gonna say like everything that I wore,
[01:15:52.260 --> 01:15:54.260]   like when I was like in late high school and in college
[01:15:54.260 --> 01:15:55.100]   is like-- - It's back.
[01:15:55.100 --> 01:15:57.700]   - Popular again, and so that's part of it.
[01:15:57.700 --> 01:15:59.420]   But no, but I'm just saying like,
[01:15:59.420 --> 01:16:01.060]   obviously they want you to use Bluetooth,
[01:16:01.060 --> 01:16:02.980]   but I think that even if you had a headphone jack,
[01:16:02.980 --> 01:16:04.500]   I still think that there are enough people
[01:16:04.500 --> 01:16:06.220]   who would still be buying Bluetooth headphones.
[01:16:06.220 --> 01:16:07.820]   It's not like that would stop.
[01:16:07.820 --> 01:16:09.860]   Like I had Bluetooth headphones, I had, you know,
[01:16:09.860 --> 01:16:14.340]   wireless beats before AirPods, so--
[01:16:14.340 --> 01:16:15.820]   - But this sound-- - Yeah, I actually have--
[01:16:15.820 --> 01:16:16.820]   - Go ahead, Abra. - Sorry.
[01:16:16.820 --> 01:16:19.020]   - Abra, what do you have? - I have a,
[01:16:19.020 --> 01:16:23.100]   I actually have a Galaxy device, and so I have a headphone jack,
[01:16:23.100 --> 01:16:24.900]   but I, these are wireless normally, I just have to--
[01:16:24.900 --> 01:16:26.660]   - You're wearing beats right now, aren't you?
[01:16:26.660 --> 01:16:28.500]   - And I'm wearing beats, so-- - Yeah, yes.
[01:16:28.500 --> 01:16:30.300]   - I love them actually. - Your lips too.
[01:16:30.300 --> 01:16:31.980]   - No, they're good, I have the same ones.
[01:16:31.980 --> 01:16:34.180]   - I have to say those are a very big color.
[01:16:34.180 --> 01:16:35.980]   Rose Gold. - Rose Gold beat.
[01:16:35.980 --> 01:16:37.740]   - I love them, I like it.
[01:16:37.740 --> 01:16:40.140]   - Thank you so much, thank you for the approval, yes.
[01:16:40.140 --> 01:16:41.700]   (laughing)
[01:16:41.700 --> 01:16:44.060]   But I love, I love over ear headphones too,
[01:16:44.060 --> 01:16:45.820]   'cause AirBuds, I can't, I don't know how you guys
[01:16:45.820 --> 01:16:48.500]   do AirBuds, because I cannot stand,
[01:16:48.500 --> 01:16:50.460]   I feel like I'm just like throwing something inside.
[01:16:50.460 --> 01:16:51.780]   Like I should-- - Now you wear a hijab,
[01:16:51.780 --> 01:16:54.140]   I should point out for those not watching a video.
[01:16:54.140 --> 01:16:55.460]   - Yes. - Could you put the,
[01:16:55.460 --> 01:16:57.860]   I guess, actually the best advantage of that,
[01:16:57.860 --> 01:16:59.060]   well not the only, but the best,
[01:16:59.060 --> 01:17:01.700]   one advantage of it is if you did an AirPod fell out,
[01:17:01.700 --> 01:17:02.860]   at least you wouldn't lose it, right?
[01:17:02.860 --> 01:17:04.420]   It would end up a scar. - Right, I see,
[01:17:04.420 --> 01:17:06.940]   that's so true, I remember. - Yeah, but in your clothing,
[01:17:06.940 --> 01:17:09.460]   and you'd have to like, still-- - You're right.
[01:17:09.460 --> 01:17:12.220]   - So you would be safe, but you'd still have to do that.
[01:17:12.220 --> 01:17:16.220]   - You would swallow it by accident, let's put it that way.
[01:17:16.220 --> 01:17:18.060]   - The funny thing is my friend the other day--
[01:17:18.060 --> 01:17:18.900]   - You're AirPods.
[01:17:18.900 --> 01:17:20.420]   (laughing)
[01:17:20.420 --> 01:17:22.260]   - My friend the other day had her AirPods
[01:17:22.260 --> 01:17:24.420]   and we couldn't see it, 'cause she also wears a hijab,
[01:17:24.420 --> 01:17:26.620]   and then she just suddenly starts talking into her,
[01:17:26.620 --> 01:17:27.980]   and we're like, what?
[01:17:27.980 --> 01:17:29.420]   She's like, how I do it all the time.
[01:17:29.420 --> 01:17:31.300]   (laughing)
[01:17:31.300 --> 01:17:33.940]   Yeah, there we go, you should watch the black more video
[01:17:33.940 --> 01:17:35.820]   I'm gonna do, we're gonna be talking about that.
[01:17:35.820 --> 01:17:37.900]   When is talking to yourself, okay?
[01:17:37.900 --> 01:17:41.180]   - Oh, okay, yeah, it's a sign, right?
[01:17:41.180 --> 01:17:44.380]   I've always talked to myself, I don't think it's a sign of--
[01:17:44.380 --> 01:17:46.540]   - She's probably totally fine. - I agree, I just--
[01:17:46.540 --> 01:17:48.340]   - I find it felt fine. - Yes.
[01:17:48.340 --> 01:17:50.380]   - Yeah. - And answering back
[01:17:50.380 --> 01:17:52.100]   is also still totally healthy,
[01:17:52.100 --> 01:17:54.500]   but you can talk to yourself-- - I have to ranch back.
[01:17:54.500 --> 01:17:56.100]   - No, answering yourself is totally fine.
[01:17:56.100 --> 01:17:58.740]   - It's okay to answer yourself, but not in a different voice.
[01:17:58.740 --> 01:18:00.060]   So you're gonna go, what do you think?
[01:18:00.060 --> 01:18:01.340]   - I'm gonna go, what do you think?
[01:18:01.340 --> 01:18:03.300]   - Well, I don't know, maybe I should do that.
[01:18:03.300 --> 01:18:05.940]   No, you don't do that, that's dangerous.
[01:18:05.940 --> 01:18:07.460]   - Okay, noted, I will not do that.
[01:18:07.460 --> 01:18:08.300]   - Don't do that. - Okay.
[01:18:08.300 --> 01:18:10.100]   - As long as you know, you're doing it--
[01:18:10.100 --> 01:18:12.700]   - That's the kind of thing that Joker would do.
[01:18:12.700 --> 01:18:15.300]   Oh, do it, that's scary.
[01:18:15.300 --> 01:18:19.300]   So, actually, completely peripherally,
[01:18:19.300 --> 01:18:22.500]   but it is, you mentioned hipsters, by the way,
[01:18:22.500 --> 01:18:25.260]   I still have some wide ties that I am not throwing out.
[01:18:25.260 --> 01:18:28.500]   I don't think wide ties are ever coming back,
[01:18:28.500 --> 01:18:30.780]   though, I gotta tell you, you never know.
[01:18:30.780 --> 01:18:31.940]   - Maybe it'll be a while.
[01:18:31.940 --> 01:18:33.580]   - For a while, vinyl, right?
[01:18:33.580 --> 01:18:34.780]   Everybody's into vinyl.
[01:18:34.780 --> 01:18:36.180]   There is a big scandal going on
[01:18:36.180 --> 01:18:38.380]   in the vinyl world that you read about this.
[01:18:38.380 --> 01:18:41.100]   - Oh, I read that this morning, oh my God, that's amazing.
[01:18:41.100 --> 01:18:45.140]   - So, MoFi, M-O-F-I, is a company
[01:18:45.140 --> 01:18:47.500]   that's been around for decades.
[01:18:47.500 --> 01:18:50.340]   They're actually up our way in Sebastopol.
[01:18:50.340 --> 01:18:52.740]   And their claim to fame was,
[01:18:52.740 --> 01:18:55.740]   they're selling vinyl records that are mastered
[01:18:55.740 --> 01:18:58.660]   from the original digital, non-digital,
[01:18:58.660 --> 01:19:03.660]   analog masters of classics, Asia, from Steely Danarth,
[01:19:03.660 --> 01:19:07.860]   or even Thriller, which was mastered to tape.
[01:19:07.860 --> 01:19:12.260]   And they were selling it this way for a long time
[01:19:12.260 --> 01:19:16.260]   until a record store owner, Phoenix Record Shop,
[01:19:17.260 --> 01:19:22.260]   owner, said, "According to pretty reliable sources,
[01:19:22.260 --> 01:19:28.340]   "MoFi, mobile fidelity, has been using digital files
[01:19:28.340 --> 01:19:31.380]   "instead to create these vinyl records.
[01:19:31.380 --> 01:19:33.060]   "They are not analog masters."
[01:19:33.060 --> 01:19:34.620]   And then a number of people spoke up and said,
[01:19:34.620 --> 01:19:35.580]   "You know what, that makes sense,
[01:19:35.580 --> 01:19:37.620]   "because if they're making these vinyl records
[01:19:37.620 --> 01:19:40.460]   "from analog masters, they have to keep rewinding the tape
[01:19:40.460 --> 01:19:42.140]   "and playing it, rewinding the tape."
[01:19:42.140 --> 01:19:44.060]   Nobody's gonna allow them to do that.
[01:19:45.020 --> 01:19:48.860]   So in fact, it's now come out, engineers,
[01:19:48.860 --> 01:19:50.540]   MoFi didn't want to admit it,
[01:19:50.540 --> 01:19:52.860]   but engineers from MoFi have started to say,
[01:19:52.860 --> 01:19:57.780]   yeah, we started using digital stream,
[01:19:57.780 --> 01:20:02.020]   it's called Direct Stream Digital Technology in 2011.
[01:20:02.020 --> 01:20:04.420]   On a release of Tony Bennett's,
[01:20:04.420 --> 01:20:06.780]   I left my heart in San Francisco.
[01:20:06.780 --> 01:20:10.100]   And by the end of 2011, 60% of their vinyl releases
[01:20:10.100 --> 01:20:13.500]   used digital sources.
[01:20:14.340 --> 01:20:16.900]   (laughs)
[01:20:16.900 --> 01:20:18.100]   - You're laughing 'cause of the hip shoes.
[01:20:18.100 --> 01:20:18.940]   - I am laughing.
[01:20:18.940 --> 01:20:21.020]   No, we'll-- - Make you fun of them.
[01:20:21.020 --> 01:20:23.220]   - Okay, I'm making fun of them, but Leo,
[01:20:23.220 --> 01:20:25.660]   I got really into vinyl during the pandemic,
[01:20:25.660 --> 01:20:27.060]   so I'm also laughing at myself,
[01:20:27.060 --> 01:20:29.300]   because I've spent like thousands of dollars
[01:20:29.300 --> 01:20:30.780]   in vinyl records over the last two years,
[01:20:30.780 --> 01:20:32.660]   and then I wish that I was-- - Wow.
[01:20:32.660 --> 01:20:35.500]   - Do you have a turntable that's in a sandbox
[01:20:35.500 --> 01:20:37.820]   with special things? - Well, I mean,
[01:20:37.820 --> 01:20:40.100]   the thousands includes the turntable that I got,
[01:20:40.100 --> 01:20:43.300]   but yeah, so, you know, but I'm part of like a monthly
[01:20:43.300 --> 01:20:44.700]   like record of the month club thing.
[01:20:44.700 --> 01:20:46.420]   Like, it's stupid.
[01:20:46.420 --> 01:20:49.380]   I bought all of the variations of Taylor Swift's
[01:20:49.380 --> 01:20:52.540]   folklore album on vinyl,
[01:20:52.540 --> 01:20:54.260]   like all like seven versions, right?
[01:20:54.260 --> 01:20:55.500]   I've got them all.
[01:20:55.500 --> 01:20:59.140]   So I'm laughing at myself in terms of this too,
[01:20:59.140 --> 01:21:01.300]   because I had looked at maybe getting
[01:21:01.300 --> 01:21:04.580]   that the thriller album that they have up for pre-order,
[01:21:04.580 --> 01:21:06.740]   which is like $100, which they're claiming
[01:21:06.740 --> 01:21:08.340]   came from like the analog, like master.
[01:21:08.340 --> 01:21:09.420]   I was like, oh, well, you know,
[01:21:09.420 --> 01:21:11.140]   maybe that would be really cool.
[01:21:11.140 --> 01:21:13.700]   Now I'm like, you absolute idiot,
[01:21:13.700 --> 01:21:17.100]   because they're just sourcing it from a digital master.
[01:21:17.100 --> 01:21:19.900]   And they can say, oh, well, it sounds this good and whatnot.
[01:21:19.900 --> 01:21:22.660]   Okay, well, no, this is just more proof
[01:21:22.660 --> 01:21:24.620]   that people who buy into audio file stuff,
[01:21:24.620 --> 01:21:26.860]   which again, I'm absolutely one of these people.
[01:21:26.860 --> 01:21:29.500]   Like, we're basically flushing money down the toilet.
[01:21:29.500 --> 01:21:31.180]   We're minute things that we claim,
[01:21:31.180 --> 01:21:32.420]   differences we claim we can hear
[01:21:32.420 --> 01:21:34.580]   that we absolutely cannot hear
[01:21:34.580 --> 01:21:36.060]   for the aesthetic and for other things.
[01:21:36.060 --> 01:21:37.820]   So I love this.
[01:21:37.820 --> 01:21:40.500]   It's also hilarious that the initial response
[01:21:40.500 --> 01:21:43.020]   from the community was to attack this record store guy
[01:21:43.020 --> 01:21:44.740]   and be like, you're wrong, you're wrong.
[01:21:44.740 --> 01:21:46.820]   And then like the company admits it and it's like,
[01:21:46.820 --> 01:21:48.820]   oh, yeah, sorry, are mad.
[01:21:48.820 --> 01:21:51.380]   - According to Washington Post,
[01:21:51.380 --> 01:21:54.180]   the fallout of the mofai revelation
[01:21:54.180 --> 01:21:56.100]   has thrown the audio file community
[01:21:56.100 --> 01:21:58.780]   into something of an existential crisis.
[01:21:58.780 --> 01:22:00.820]   - Right, right, exactly.
[01:22:00.820 --> 01:22:04.260]   'Cause it's like, but I swore that I could hear the difference.
[01:22:04.260 --> 01:22:05.740]   - It sounded better on Twitter.
[01:22:05.740 --> 01:22:07.780]   - And now I know it's a placebo,
[01:22:07.780 --> 01:22:09.860]   which is, I think most of us who are part
[01:22:09.860 --> 01:22:12.420]   of kind of the hobby would admit that
[01:22:12.420 --> 01:22:15.220]   we know that we're just paying more to pay more.
[01:22:15.220 --> 01:22:17.260]   But it's not.
[01:22:17.260 --> 01:22:18.260]   - It's joy.
[01:22:18.260 --> 01:22:20.260]   It's joy though.
[01:22:20.260 --> 01:22:21.740]   - There is an aesthetic.
[01:22:21.740 --> 01:22:23.500]   - Oh, there's the aesthetic I love.
[01:22:23.500 --> 01:22:24.340]   - Yes.
[01:22:24.340 --> 01:22:28.940]   - And you can like, full.
[01:22:28.940 --> 01:22:31.500]   And I think it's the same thing with people that like books,
[01:22:31.500 --> 01:22:34.020]   which I like paper books with like pages
[01:22:34.020 --> 01:22:35.900]   with stuff written on it that I have to go through.
[01:22:35.900 --> 01:22:38.460]   And I lose the page and all of that frustration.
[01:22:38.460 --> 01:22:40.420]   But I prefer the experience,
[01:22:40.420 --> 01:22:42.980]   even though it's much easier to read it on my phone,
[01:22:42.980 --> 01:22:44.620]   where I don't have to like have a light
[01:22:44.620 --> 01:22:48.460]   and can't see the letters because the light's not bright enough.
[01:22:48.460 --> 01:22:50.100]   But there's something that's a joyful thing
[01:22:50.100 --> 01:22:52.340]   about actually being able to hold and own
[01:22:52.340 --> 01:22:55.220]   and manipulate something that isn't just digital.
[01:22:55.220 --> 01:22:57.340]   So go for it, enjoy it.
[01:22:57.340 --> 01:22:59.820]   - As a visitor from the age of vinyl,
[01:22:59.820 --> 01:23:02.780]   I actually had vinyl records
[01:23:02.780 --> 01:23:05.780]   when they were the only way to get music.
[01:23:05.780 --> 01:23:09.460]   I remember buying a 40 of my,
[01:23:09.460 --> 01:23:12.700]   I think my first record was a Beatles 45.
[01:23:12.700 --> 01:23:14.540]   I wanna hold her hand.
[01:23:14.540 --> 01:23:17.140]   As a, it's not about the sound quality.
[01:23:17.140 --> 01:23:18.340]   That sounded like crap.
[01:23:18.340 --> 01:23:20.140]   (laughs)
[01:23:20.140 --> 01:23:22.780]   But there is an aesthetic to taking it out
[01:23:22.780 --> 01:23:23.860]   and out of the sleeve.
[01:23:23.860 --> 01:23:25.260]   They've got the liner notes.
[01:23:25.260 --> 01:23:26.460]   There's a whole thing.
[01:23:26.460 --> 01:23:29.940]   You clean it with the disc washer, three drops, that's all.
[01:23:29.940 --> 01:23:31.700]   And then you put it on the thing.
[01:23:31.700 --> 01:23:34.860]   You gently lower the needle on there.
[01:23:34.860 --> 01:23:37.020]   I understand the aesthetic of it.
[01:23:37.020 --> 01:23:39.540]   - It's not one of the really old ones,
[01:23:39.540 --> 01:23:41.540]   like gramophone kind of like look to it.
[01:23:41.540 --> 01:23:43.860]   (mumbles)
[01:23:43.860 --> 01:23:48.660]   - Yeah, but I mean, to say, oh, this is magically sounds.
[01:23:48.660 --> 01:23:50.780]   Now, Mofai is saying, hey, look,
[01:23:50.780 --> 01:23:53.380]   even though we're using digital,
[01:23:53.380 --> 01:23:56.940]   we get the masters and we very carefully
[01:23:56.940 --> 01:23:59.100]   make this digital version.
[01:23:59.100 --> 01:24:02.020]   - And they might actually have like a better master
[01:24:02.020 --> 01:24:03.580]   'cause a lot of times the reason people
[01:24:03.580 --> 01:24:05.940]   get mad about digital masters isn't because digital,
[01:24:05.940 --> 01:24:06.820]   there's anything wrong with it,
[01:24:06.820 --> 01:24:09.500]   it's because the mastering process or the remastering
[01:24:09.500 --> 01:24:12.100]   has been like crunched and compressed to the point
[01:24:12.100 --> 01:24:13.100]   that it sounds terrible.
[01:24:13.100 --> 01:24:14.500]   And you can actually hear like,
[01:24:14.500 --> 01:24:16.900]   and this isn't a BS audio file thing.
[01:24:16.900 --> 01:24:19.020]   You can do like A/B sampling
[01:24:19.020 --> 01:24:21.660]   where there have been conclusive differences
[01:24:21.660 --> 01:24:24.300]   where you can take like a CD that was pressed in like 1990
[01:24:24.300 --> 01:24:26.300]   and one that was pressed in 2015.
[01:24:26.300 --> 01:24:27.780]   And it's the same album,
[01:24:27.780 --> 01:24:28.980]   they sound very different
[01:24:28.980 --> 01:24:31.220]   because of the way the mastering process works.
[01:24:31.220 --> 01:24:34.820]   So it's possible that they still do a superior job
[01:24:34.820 --> 01:24:36.940]   with mastering and that they still have a better source
[01:24:36.940 --> 01:24:39.300]   material they're doing from this vinyl,
[01:24:39.300 --> 01:24:43.940]   but since the big part of their whole thing has been like,
[01:24:43.940 --> 01:24:46.700]   oh, we're coming from like directly from the analog,
[01:24:46.700 --> 01:24:51.700]   which is especially with the fact that like vinyl plants
[01:24:51.700 --> 01:24:55.260]   are almost impossible for people to even get time on,
[01:24:55.260 --> 01:24:57.340]   like things are backlog so much
[01:24:57.340 --> 01:24:59.660]   that the additional time that you're adding to that
[01:24:59.660 --> 01:25:01.900]   would be untenable to do,
[01:25:01.900 --> 01:25:04.540]   especially to do like a large batch thing,
[01:25:04.540 --> 01:25:06.220]   like the thriller album where they said
[01:25:06.220 --> 01:25:07.660]   they do 40,000 copies,
[01:25:07.660 --> 01:25:10.420]   like there's no way.
[01:25:10.420 --> 01:25:12.340]   - You don't have to run the tape
[01:25:12.340 --> 01:25:15.100]   for every single little pressing,
[01:25:15.100 --> 01:25:16.460]   but you have to run it more than once.
[01:25:16.460 --> 01:25:18.460]   You're not making a number of shellacs.
[01:25:18.460 --> 01:25:19.460]   - That's what I'm saying.
[01:25:19.460 --> 01:25:20.700]   You have to do it at a certain times,
[01:25:20.700 --> 01:25:21.980]   especially if you're going to be claiming
[01:25:21.980 --> 01:25:24.420]   you want like high fidelity recordings, right?
[01:25:24.420 --> 01:25:25.580]   Where you don't want it to sound like that.
[01:25:25.580 --> 01:25:26.620]   I want to hold your hand.
[01:25:26.620 --> 01:25:27.460]   - Fourth generation.
[01:25:27.460 --> 01:25:28.300]   - You have to do it for five that you had.
[01:25:28.300 --> 01:25:29.660]   - Exactly, you don't want it to be that way.
[01:25:29.660 --> 01:25:32.420]   So yeah, I mean, I think that some of it
[01:25:32.420 --> 01:25:33.580]   is probably much to do about nothing,
[01:25:33.580 --> 01:25:36.540]   but it is funny to see people who are still
[01:25:36.540 --> 01:25:38.900]   trying to convince themselves that it's better.
[01:25:38.900 --> 01:25:40.620]   That said, they also sell,
[01:25:40.620 --> 01:25:44.300]   I wasn't aware of this, they sell super audio CDs.
[01:25:44.300 --> 01:25:46.900]   I'm super excited to see that the SACD market
[01:25:46.900 --> 01:25:47.900]   is coming back a little bit.
[01:25:47.900 --> 01:25:48.900]   - Is it?
[01:25:48.900 --> 01:25:50.380]   - It seems to be,
[01:25:50.380 --> 01:25:52.380]   which there are like some pre-orders
[01:25:52.380 --> 01:25:56.180]   and coming soon re-releases on SACD,
[01:25:56.180 --> 01:25:57.980]   that's actually much more exciting to me.
[01:25:57.980 --> 01:25:58.820]   So,
[01:25:58.820 --> 01:26:01.060]   - So, go ahead.
[01:26:01.060 --> 01:26:02.060]   - Sorry, did you also,
[01:26:02.060 --> 01:26:03.860]   you mentioned Taylor Swift when she had released
[01:26:03.860 --> 01:26:05.620]   her floors, she also released it on cassette.
[01:26:05.620 --> 01:26:07.140]   And I thought that was bizarre.
[01:26:07.140 --> 01:26:07.980]   - I love that.
[01:26:07.980 --> 01:26:09.740]   Yeah, so cassette just had a moment.
[01:26:09.740 --> 01:26:11.380]   - That's hipster, right?
[01:26:11.380 --> 01:26:12.380]   - That's completely aesthetic.
[01:26:12.380 --> 01:26:14.220]   - That's completely aesthetic.
[01:26:14.220 --> 01:26:16.380]   That's been big for five or six years now
[01:26:16.380 --> 01:26:19.020]   where you've seen, especially with younger people
[01:26:19.020 --> 01:26:20.700]   wanting to get it for the aesthetic.
[01:26:20.700 --> 01:26:22.900]   And like, I bought a radio head
[01:26:22.900 --> 01:26:26.140]   when they released the 25th anniversary of OK Computer.
[01:26:26.140 --> 01:26:28.340]   I got it on Mini-Disc.
[01:26:28.340 --> 01:26:29.860]   So that was,
[01:26:29.860 --> 01:26:32.860]   which is like the ultimate, you know, like,
[01:26:32.860 --> 01:26:34.300]   and I do actually have a Mini-Disc player,
[01:26:34.300 --> 01:26:35.380]   so I can play it back,
[01:26:35.380 --> 01:26:37.580]   but that was like the ultimate, like,
[01:26:37.580 --> 01:26:39.060]   really Christina, really.
[01:26:39.060 --> 01:26:40.540]   And I think I got it.
[01:26:40.540 --> 01:26:41.700]   I think I got that on,
[01:26:41.700 --> 01:26:43.060]   there was a cassette thing there too,
[01:26:43.060 --> 01:26:45.700]   but you're right, yeah, she releases stuff on cassette.
[01:26:45.700 --> 01:26:46.740]   What I'm waiting for,
[01:26:46.740 --> 01:26:48.700]   we're seeing SACD come back.
[01:26:48.700 --> 01:26:52.940]   I'm waiting for actual just CDs to come back, right?
[01:26:52.940 --> 01:26:54.340]   That I'm waiting for.
[01:26:54.340 --> 01:26:55.180]   - What's the,
[01:26:55.180 --> 01:26:56.780]   look, it's a digital recording. - Why not?
[01:26:56.780 --> 01:26:57.620]   When you download it,
[01:26:57.620 --> 01:26:59.820]   it's identical to the CD.
[01:26:59.820 --> 01:27:01.900]   I've no downloaded MP3 or AAC,
[01:27:01.900 --> 01:27:04.300]   but if you download a lossless version of it,
[01:27:04.300 --> 01:27:07.220]   it's identical to the 441 CD.
[01:27:07.220 --> 01:27:08.060]   I don't know, I mean,
[01:27:08.060 --> 01:27:09.780]   I'm just looking forward to the aesthetic coming back.
[01:27:09.780 --> 01:27:12.180]   I just want to see the kids walking on the giant walkmans.
[01:27:12.180 --> 01:27:13.460]   - Oh, you like it. - Yeah, I mean, I don't care.
[01:27:13.460 --> 01:27:14.780]   I don't, to be honest with you, I don't care.
[01:27:14.780 --> 01:27:16.820]   I just want to see people walking around with giant,
[01:27:16.820 --> 01:27:18.940]   like, you know, walkmans again.
[01:27:18.940 --> 01:27:20.180]   Like, I think that would just be funny.
[01:27:20.180 --> 01:27:21.340]   - I think you can make the case.
[01:27:21.340 --> 01:27:23.900]   And I have been, you know,
[01:27:23.900 --> 01:27:28.020]   I remember walking by the Dolby offices in San Francisco
[01:27:28.020 --> 01:27:29.980]   many years ago and a Dolby engineer came out,
[01:27:29.980 --> 01:27:32.260]   and he brought me in,
[01:27:32.260 --> 01:27:34.300]   they had a very, it's famous,
[01:27:34.300 --> 01:27:37.940]   a very famous theater in there
[01:27:37.940 --> 01:27:40.220]   with really good, revel speakers.
[01:27:40.220 --> 01:27:41.820]   I mean, just a really nice setup.
[01:27:41.820 --> 01:27:44.620]   And he played an AB comparison for me between,
[01:27:44.620 --> 01:27:46.300]   now it was admittedly, it was Steely Dan.
[01:27:46.300 --> 01:27:48.340]   It was not a very complex piece of music,
[01:27:48.340 --> 01:27:52.820]   but between an analog and a digital,
[01:27:52.820 --> 01:27:54.580]   I think it was an even MP3 recording,
[01:27:54.580 --> 01:27:56.180]   might have been an AAC.
[01:27:56.180 --> 01:27:57.860]   But remember Dolby was very much into
[01:27:57.860 --> 01:28:00.540]   this digital compression technologies,
[01:28:00.540 --> 01:28:02.660]   and it was indistinguishable.
[01:28:02.660 --> 01:28:03.900]   But, and then I've also had people say,
[01:28:03.900 --> 01:28:06.180]   now listen carefully and you can hear,
[01:28:06.180 --> 01:28:07.900]   you know, there's some loss of fidelity
[01:28:07.900 --> 01:28:09.660]   and like the symbol here.
[01:28:09.660 --> 01:28:12.140]   And if they teach you and tell you what to listen to,
[01:28:12.140 --> 01:28:13.620]   you can kind of tell an MP3,
[01:28:13.620 --> 01:28:15.820]   especially 128 kilobits MP3,
[01:28:15.820 --> 01:28:20.420]   as good as say, you know, a lossless version of the CD.
[01:28:20.420 --> 01:28:22.860]   But most people, let's face it,
[01:28:22.860 --> 01:28:24.980]   they're listening on those crappy ear pods.
[01:28:24.980 --> 01:28:26.860]   - Well, that's, this is the thing, right?
[01:28:26.860 --> 01:28:27.940]   Like this is always,
[01:28:27.940 --> 01:28:28.940]   - Blue tooth, yeah, yeah.
[01:28:28.940 --> 01:28:32.140]   - Well, this is the hilarious thing about the vinyl world.
[01:28:32.140 --> 01:28:35.140]   So if you go to like the R/vinyl, like Separate and stuff,
[01:28:35.140 --> 01:28:37.940]   you have a lot of people who were wanting to get turntables
[01:28:37.940 --> 01:28:39.180]   and other things.
[01:28:39.180 --> 01:28:41.100]   And then one of the first questions they ask is,
[01:28:41.100 --> 01:28:43.020]   okay, so how do I listen to this with Bluetooth?
[01:28:43.020 --> 01:28:44.420]   How do I connect this to my sonos?
[01:28:44.420 --> 01:28:45.660]   How do I know other stuff?
[01:28:45.660 --> 01:28:46.500]   - No!
[01:28:46.500 --> 01:28:47.340]   - And you can do it.
[01:28:47.340 --> 01:28:49.020]   Like I do actually have my turn to be connected
[01:28:49.020 --> 01:28:49.860]   to my sonos.
[01:28:49.860 --> 01:28:52.220]   But I'm primarily, when I want to listen to vinyl,
[01:28:52.220 --> 01:28:55.660]   I have like my very expensive like headphones plugged in
[01:28:55.660 --> 01:28:58.620]   directly to my amp plugged into my turntable.
[01:28:58.620 --> 01:29:00.500]   And that's how I'm enjoying the experience.
[01:29:00.500 --> 01:29:02.980]   But it is very funny that people will wanna,
[01:29:02.980 --> 01:29:05.340]   on the one hand, take on the aesthetic.
[01:29:05.340 --> 01:29:06.580]   But on the other hand,
[01:29:06.580 --> 01:29:10.260]   immediately want to be able to listen to it wirelessly.
[01:29:10.260 --> 01:29:12.900]   And it's like, okay, you do understand
[01:29:12.900 --> 01:29:13.900]   what you've just done here.
[01:29:13.900 --> 01:29:16.340]   You've just completely given up the entire thing.
[01:29:16.340 --> 01:29:18.740]   Like I get it, it's nice to be able to drop a needle
[01:29:18.740 --> 01:29:19.940]   on something and do that.
[01:29:19.940 --> 01:29:22.580]   But anything you wanna try to claim about like,
[01:29:22.580 --> 01:29:25.860]   audio fidelity is completely out the window
[01:29:25.860 --> 01:29:27.340]   as soon as you are, you know,
[01:29:27.340 --> 01:29:28.900]   - Bluetooth is so depressed.
[01:29:28.900 --> 01:29:29.740]   - Yeah.
[01:29:29.740 --> 01:29:32.500]   - But even just doing an analog to digital converter.
[01:29:32.500 --> 01:29:34.100]   'Cause in that case, in most cases you're taking,
[01:29:34.100 --> 01:29:36.700]   okay, something that was digital became analog.
[01:29:36.700 --> 01:29:38.340]   Now it's being digital again.
[01:29:38.340 --> 01:29:40.140]   Like, come on.
[01:29:40.140 --> 01:29:41.340]   - What kind of turntable do you have?
[01:29:41.340 --> 01:29:42.940]   - It's the inception of everything.
[01:29:42.940 --> 01:29:44.620]   - It's inception, exactly.
[01:29:44.620 --> 01:29:46.340]   What kind of turntable do you have, Christina?
[01:29:46.340 --> 01:29:47.980]   - I can't remember right now.
[01:29:47.980 --> 01:29:49.700]   - You're no audio file.
[01:29:49.700 --> 01:29:52.180]   - I'm gonna kick your way off slash or slash file.
[01:29:52.180 --> 01:29:53.660]   - No, I got it like two years ago.
[01:29:53.660 --> 01:29:55.300]   I kind of remember which one it was.
[01:29:55.300 --> 01:29:56.140]   It was one that actually--
[01:29:56.140 --> 01:29:57.020]   - You know what I love about you though?
[01:29:57.020 --> 01:29:58.460]   And you're an enthusiast.
[01:29:58.460 --> 01:30:01.380]   And I recognize this, 'cause I'm kind of the same way,
[01:30:01.380 --> 01:30:03.060]   where you get into something
[01:30:03.060 --> 01:30:04.900]   and then you have to do it in, you know,
[01:30:04.900 --> 01:30:07.460]   in its entirety, whatever it is, right?
[01:30:07.460 --> 01:30:08.820]   And then you move on.
[01:30:08.820 --> 01:30:09.660]   Now it's the next--
[01:30:09.660 --> 01:30:11.060]   - Right, that was basically the thing.
[01:30:11.060 --> 01:30:12.660]   Like I got really into it for a period of time
[01:30:12.660 --> 01:30:14.340]   and I got really as much anymore.
[01:30:14.340 --> 01:30:15.180]   But yeah.
[01:30:15.180 --> 01:30:16.340]   - God bless the enthusiast.
[01:30:16.340 --> 01:30:19.780]   That's the joy in life, the passion for something.
[01:30:19.780 --> 01:30:20.700]   You care so much about it.
[01:30:20.700 --> 01:30:22.380]   - Oh, it's a project.
[01:30:22.380 --> 01:30:23.220]   That's what it is.
[01:30:23.220 --> 01:30:24.500]   It's from Project.
[01:30:24.500 --> 01:30:26.020]   - Yeah, I'm the same way.
[01:30:26.020 --> 01:30:26.860]   - That's what it's from.
[01:30:26.860 --> 01:30:27.700]   - Yeah.
[01:30:27.700 --> 01:30:28.540]   And you know what, I don't know about you,
[01:30:28.540 --> 01:30:30.500]   but, and Georgia, you probably can confirm this,
[01:30:30.500 --> 01:30:33.260]   but it's because I'm ADD,
[01:30:33.260 --> 01:30:35.620]   that as even as a kid,
[01:30:35.620 --> 01:30:39.100]   the way I got functional with my attention deficit
[01:30:39.100 --> 01:30:41.300]   was I would hyper-focus.
[01:30:41.300 --> 01:30:44.220]   And so everything for me was a project,
[01:30:44.220 --> 01:30:47.060]   it was a hyper-focused thing
[01:30:47.060 --> 01:30:48.780]   because it's the only way I could really do it.
[01:30:48.780 --> 01:30:51.780]   And I think probably most of our audience is the same way.
[01:30:51.780 --> 01:30:52.620]   I'm guessing.
[01:30:52.620 --> 01:30:54.780]   - Yeah, and it gives you all that wonderful dopamine
[01:30:54.780 --> 01:30:56.860]   as it's new and exciting and fun.
[01:30:56.860 --> 01:30:57.700]   - Yeah.
[01:30:57.700 --> 01:31:01.060]   - And that's true, well, dopamine, other stuff,
[01:31:01.060 --> 01:31:02.540]   and then you move on to learning
[01:31:02.540 --> 01:31:04.420]   and experiencing something else.
[01:31:04.420 --> 01:31:06.620]   It's, there's nothing wrong with it.
[01:31:06.620 --> 01:31:07.700]   Enjoy, have fun.
[01:31:07.700 --> 01:31:08.540]   Let's be sure.
[01:31:08.540 --> 01:31:09.620]   - Yes, see, we're okay.
[01:31:09.620 --> 01:31:12.260]   Don't mind that.
[01:31:14.020 --> 01:31:16.140]   Speaking of gadget graveyards,
[01:31:16.140 --> 01:31:20.500]   Epson, a little bit of hot water here.
[01:31:20.500 --> 01:31:24.540]   This is from the Fight to Repair Substack newsletter,
[01:31:24.540 --> 01:31:27.580]   citing danger of ink spills,
[01:31:27.580 --> 01:31:30.180]   Epson programs End of Life for some printers.
[01:31:30.180 --> 01:31:31.860]   We've seen this with other printer companies
[01:31:31.860 --> 01:31:34.300]   where the printer just stops working.
[01:31:34.300 --> 01:31:35.380]   In this case,
[01:31:35.380 --> 01:31:40.580]   and it's particularly the L series Epson printers,
[01:31:40.580 --> 01:31:42.260]   which are not the cheap ones,
[01:31:42.260 --> 01:31:44.860]   they're not the cheap inkjet printers.
[01:31:44.860 --> 01:31:48.220]   There is an ink pad in there,
[01:31:48.220 --> 01:31:52.940]   which Epson describes as a porous pad in the printer.
[01:31:52.940 --> 01:31:54.100]   The collects, distributes,
[01:31:54.100 --> 01:31:56.860]   and very importantly contains the ink
[01:31:56.860 --> 01:31:59.820]   that is not used on printed pages.
[01:31:59.820 --> 01:32:01.740]   Over time, these pads wear out
[01:32:01.740 --> 01:32:07.860]   and there's actually a counter built into your printer.
[01:32:07.860 --> 01:32:12.220]   And when that counter reaches a certain number of print jobs,
[01:32:12.220 --> 01:32:14.140]   your printer will just stop working.
[01:32:14.140 --> 01:32:17.700]   It just won't print anymore.
[01:32:17.700 --> 01:32:18.940]   And you gotta buy a new one,
[01:32:18.940 --> 01:32:22.740]   or maybe you can recycle it
[01:32:22.740 --> 01:32:24.820]   or get Epson to replace the pad.
[01:32:24.820 --> 01:32:26.460]   It turns out the pad replacement,
[01:32:26.460 --> 01:32:27.900]   a number of people have done it themselves,
[01:32:27.900 --> 01:32:29.740]   is very simple, very inexpensive.
[01:32:29.740 --> 01:32:31.500]   Epson doesn't sell those pads,
[01:32:31.500 --> 01:32:33.860]   but the reason Epson says
[01:32:33.860 --> 01:32:35.580]   that they disable the printers
[01:32:35.580 --> 01:32:38.100]   once those pads are full of ink.
[01:32:38.100 --> 01:32:38.940]   This is the quote,
[01:32:38.940 --> 01:32:40.860]   "The printers are designed to stop operating at a point
[01:32:40.860 --> 01:32:43.980]   where further use without replacing the ink pads
[01:32:43.980 --> 01:32:48.260]   could create risks of property damage from ink spills
[01:32:48.260 --> 01:32:53.780]   or safety issues related to excess ink
[01:32:53.780 --> 01:32:56.100]   contacting an electrical component."
[01:32:56.100 --> 01:32:58.260]   - So ridiculous.
[01:32:58.260 --> 01:33:00.100]   - You gotta wonder,
[01:33:00.100 --> 01:33:02.260]   is this really to protect people from ink spills
[01:33:02.260 --> 01:33:04.900]   or is it really to make a little extra money on a printer?
[01:33:04.900 --> 01:33:07.940]   'Cause you've been keeping it in service too long.
[01:33:07.940 --> 01:33:09.380]   This came up when a lecturer
[01:33:09.380 --> 01:33:11.620]   at University of New Haven in Connecticut,
[01:33:11.620 --> 01:33:12.780]   Mark Tavern tweeted,
[01:33:12.780 --> 01:33:14.100]   "My wife's very expensive,"
[01:33:14.100 --> 01:33:15.900]   Epson printer just gave a message saying
[01:33:15.900 --> 01:33:18.700]   it had reached the end of its service life
[01:33:18.700 --> 01:33:20.540]   and proceeded to brick itself.
[01:33:20.540 --> 01:33:22.660]   Apparently she can pay to service it or buy a new one,
[01:33:22.660 --> 01:33:24.540]   even though it was working fine.
[01:33:24.540 --> 01:33:26.720]   Outrageous.
[01:33:26.720 --> 01:33:31.740]   4,500 likes, 800-wee tweets.
[01:33:31.740 --> 01:33:35.580]   Epson does make for Windows users a special program,
[01:33:35.580 --> 01:33:40.100]   the Waste InkPad Counter Reset program.
[01:33:40.100 --> 01:33:41.980]   That lets you change the counter.
[01:33:41.980 --> 01:33:46.460]   But there's only a version for Windows 10, 8, 7, Vista,
[01:33:46.460 --> 01:33:48.380]   and XP, there's no Mac version.
[01:33:48.380 --> 01:33:50.700]   And it can only be used once
[01:33:50.700 --> 01:33:52.620]   and it will allow printing for a short period of time,
[01:33:52.620 --> 01:33:54.020]   says Epson.
[01:33:54.020 --> 01:33:57.020]   - I am sure someone will be hacking that very soon.
[01:33:57.020 --> 01:33:57.860]   - Yeah.
[01:33:57.860 --> 01:33:59.220]   - If not already,
[01:33:59.220 --> 01:34:02.740]   like it's just one of these ridiculous things where,
[01:34:02.740 --> 01:34:04.900]   you know, like you buy something,
[01:34:04.900 --> 01:34:07.900]   you're supposed to own it and like,
[01:34:07.900 --> 01:34:10.060]   if it happens like the battery dies
[01:34:10.060 --> 01:34:11.540]   because the battery actually dies,
[01:34:11.540 --> 01:34:14.140]   like I'm already a little bit salty about that,
[01:34:14.140 --> 01:34:16.980]   but to have some arbitrary idea that, you know what,
[01:34:16.980 --> 01:34:19.380]   we're gonna protect you from ink damage
[01:34:19.380 --> 01:34:21.180]   because that would be so horrible.
[01:34:21.180 --> 01:34:23.940]   Like if anyone's ever changed ink on a printer knows
[01:34:23.940 --> 01:34:26.260]   that they really don't care about ink damaging
[01:34:26.260 --> 01:34:28.140]   anything and everything in the rest.
[01:34:28.140 --> 01:34:29.140]   (laughing)
[01:34:29.140 --> 01:34:31.180]   - Here's a guy, this is a video from 2017,
[01:34:31.180 --> 01:34:33.900]   a guy just kind of tore up some foam.
[01:34:33.900 --> 01:34:35.980]   Put a hole in it and replaced it.
[01:34:35.980 --> 01:34:39.940]   Just, you know, shaped some foam rubber to fit in there.
[01:34:39.940 --> 01:34:40.940]   Replaced it.
[01:34:40.940 --> 01:34:43.140]   Of course then you have to hack the printer to say,
[01:34:43.140 --> 01:34:45.420]   you know, hey, new foam pads in there,
[01:34:45.420 --> 01:34:46.540]   new ink pads in there.
[01:34:46.540 --> 01:34:49.180]   So you can do it yourself.
[01:34:49.180 --> 01:34:51.740]   And like, you know, Epson doesn't really want you to do it
[01:34:51.740 --> 01:34:53.340]   through them or do it yourself.
[01:34:53.340 --> 01:34:55.420]   They want you to buy a new printer.
[01:34:55.420 --> 01:34:57.500]   - We're gonna guess Gaslit by Epson.
[01:34:57.500 --> 01:34:58.340]   - Gaslit.
[01:34:58.340 --> 01:34:59.340]   - It's a oil stone, there we go.
[01:34:59.340 --> 01:35:00.340]   That's, you know,
[01:35:00.340 --> 01:35:01.980]   - Oil that trendy.
[01:35:01.980 --> 01:35:03.940]   - Right, exactly.
[01:35:03.940 --> 01:35:05.620]   - Gaslit by Epson.
[01:35:05.620 --> 01:35:06.700]   - Wow.
[01:35:06.700 --> 01:35:07.700]   - That should have been the headline.
[01:35:07.700 --> 01:35:10.220]   - I think it is, that's the headline.
[01:35:10.220 --> 01:35:11.060]   - Yeah.
[01:35:11.060 --> 01:35:15.540]   Let's see what's our timing.
[01:35:15.540 --> 01:35:16.940]   Maybe I should take a little break here.
[01:35:16.940 --> 01:35:19.220]   I don't want to run this too long.
[01:35:19.220 --> 01:35:22.460]   I have a very good sponsor to talk about anyway.
[01:35:22.460 --> 01:35:24.300]   So I'm happy to do this.
[01:35:24.300 --> 01:35:28.940]   Our show this week and at often is brought to you by
[01:35:28.940 --> 01:35:30.540]   userway.org.
[01:35:30.540 --> 01:35:33.460]   Userway.org.
[01:35:33.460 --> 01:35:37.660]   I'm talking about making your website, ADA compliant,
[01:35:37.660 --> 01:35:38.860]   accessible.
[01:35:38.860 --> 01:35:40.540]   Not only is it the right thing to do
[01:35:40.540 --> 01:35:42.700]   because you're opening up your website
[01:35:42.700 --> 01:35:46.300]   to a much larger group, 60 million plus people.
[01:35:46.300 --> 01:35:49.140]   You have a responsibility to make you site accessible.
[01:35:49.140 --> 01:35:51.780]   It's a public entity, so you gotta make it accessible.
[01:35:51.780 --> 01:35:54.300]   And with Userway, it's easy.
[01:35:54.300 --> 01:35:55.740]   That was my biggest concern was,
[01:35:55.740 --> 01:35:57.940]   oh, I can't afford it or it's gonna be too hard.
[01:35:57.940 --> 01:36:01.100]   No, Userway is really affordable and it's really easy.
[01:36:01.100 --> 01:36:03.220]   And incredible, it's AI powered,
[01:36:03.220 --> 01:36:06.420]   it tirelessly enforces all the accessibility guidelines,
[01:36:06.420 --> 01:36:09.300]   the WCAG WCAG guidelines.
[01:36:09.300 --> 01:36:11.580]   And I love this, so do our engineers.
[01:36:11.580 --> 01:36:13.260]   It's one line of JavaScript.
[01:36:13.260 --> 01:36:14.100]   That's it.
[01:36:14.100 --> 01:36:16.180]   Because Userway is so good, it's used by more than
[01:36:16.180 --> 01:36:19.700]   a million websites, including the big guys, Coca-Cola,
[01:36:19.700 --> 01:36:21.140]   Disney, eBay.
[01:36:21.140 --> 01:36:24.220]   These are companies that really have to be accessible
[01:36:24.220 --> 01:36:25.580]   and Userway can do that.
[01:36:25.580 --> 01:36:28.060]   As you get bigger, they scale with you.
[01:36:28.060 --> 01:36:31.660]   If they can handle Disney, absolutely they can handle you.
[01:36:31.660 --> 01:36:34.500]   They make best in class enterprise level accessibility
[01:36:34.500 --> 01:36:38.300]   tools available to you, your small or medium sized business.
[01:36:38.300 --> 01:36:41.580]   And then as you scale, you need Userway and you're ready.
[01:36:41.580 --> 01:36:43.100]   It just makes business sense.
[01:36:43.100 --> 01:36:46.340]   Some of the biggest problems, nav menus, very difficult.
[01:36:46.340 --> 01:36:48.860]   So the way this works, if you're blind or you're using
[01:36:48.860 --> 01:36:51.620]   accessibility tools, there is what they call
[01:36:51.620 --> 01:36:52.940]   an accessibility layer.
[01:36:52.940 --> 01:36:55.380]   That's what the screen reader sees.
[01:36:55.380 --> 01:36:58.140]   So really what Userway does is make sure that all the
[01:36:58.140 --> 01:37:01.500]   information available to the front page to the sighted user
[01:37:01.500 --> 01:37:04.860]   is available to the browser in the accessibility layer.
[01:37:04.860 --> 01:37:06.460]   It changes colors.
[01:37:06.460 --> 01:37:08.700]   Now you've got your Pantone color for your business.
[01:37:08.700 --> 01:37:09.980]   Of course, we do too.
[01:37:09.980 --> 01:37:11.300]   Doesn't change that.
[01:37:11.300 --> 01:37:13.700]   But it adjusts hue and luminance, so it's easier for
[01:37:13.700 --> 01:37:15.980]   people with vision issues to read.
[01:37:15.980 --> 01:37:17.740]   So Userway will generate alt tags.
[01:37:17.740 --> 01:37:20.140]   That's one of the reasons in EDAI, it can actually see the
[01:37:20.140 --> 01:37:22.580]   picture and generate an alt tag that matches the picture
[01:37:22.580 --> 01:37:23.660]   automatically.
[01:37:23.660 --> 01:37:24.700]   You can go in if you want.
[01:37:24.700 --> 01:37:26.780]   You can modify it, of course.
[01:37:26.780 --> 01:37:30.900]   It fixes violations like vague links, fixes broken links,
[01:37:30.900 --> 01:37:34.500]   make sure that your website uses accessible colors.
[01:37:34.500 --> 01:37:37.140]   And you'll get a detailed report of all the violations that
[01:37:37.140 --> 01:37:40.180]   were fixed on your website, so you know exactly what it did.
[01:37:40.180 --> 01:37:41.820]   Plus you can work with it.
[01:37:41.820 --> 01:37:45.180]   Userway integrates seamlessly with your site builder
[01:37:45.180 --> 01:37:46.580]   software.
[01:37:46.580 --> 01:37:49.380]   Let Userway help your business meet its compliance goals,
[01:37:49.380 --> 01:37:51.340]   improve the experience for your users.
[01:37:51.340 --> 01:37:54.020]   Userway can make any website fully accessible,
[01:37:54.020 --> 01:37:55.540]   an EDA compliant.
[01:37:55.540 --> 01:37:58.140]   And everyone who visits can browse seamlessly,
[01:37:58.140 --> 01:37:59.860]   customize it to fit their needs.
[01:37:59.860 --> 01:38:02.620]   It's a great way to show your brand's commitment to the
[01:38:02.620 --> 01:38:04.820]   millions of people with disabilities.
[01:38:04.820 --> 01:38:06.100]   It's the right thing to do.
[01:38:06.100 --> 01:38:09.380]   Userway can make any website fully accessible, an EDA
[01:38:09.380 --> 01:38:10.900]   compliant with Userway.
[01:38:10.900 --> 01:38:13.540]   Everyone who visits your site can browse seamlessly,
[01:38:13.540 --> 01:38:15.180]   customize it to fit their needs.
[01:38:15.180 --> 01:38:16.220]   We've got it on our website.
[01:38:16.220 --> 01:38:18.860]   Go to twit.tv, go to the lower right there.
[01:38:18.860 --> 01:38:21.180]   Click that accessibility symbol.
[01:38:21.180 --> 01:38:23.980]   You'll see all the things it does with one line of code.
[01:38:23.980 --> 01:38:25.180]   Go to our website.
[01:38:25.180 --> 01:38:26.620]   And you know what I really appreciate?
[01:38:26.620 --> 01:38:29.780]   It's a great way to showcase your brand's commitment
[01:38:29.780 --> 01:38:32.020]   to millions of people with disabilities.
[01:38:32.020 --> 01:38:33.580]   You wouldn't want to lock them out of your site.
[01:38:33.580 --> 01:38:34.420]   Of course not.
[01:38:34.420 --> 01:38:36.700]   Go to userway.org/twit.
[01:38:36.700 --> 01:38:40.660]   And you'll get 30% off Userway's AI powered accessibility
[01:38:40.660 --> 01:38:41.540]   solution.
[01:38:41.540 --> 01:38:44.060]   Just book a short call, get their accessibility guide.
[01:38:44.060 --> 01:38:44.860]   They're there for you.
[01:38:44.860 --> 01:38:48.660]   Userway, making the internet accessible for everyone.
[01:38:48.660 --> 01:38:51.860]   Visit userway.org/twit.
[01:38:51.860 --> 01:38:55.620]   We thank them so much for their support of this week in tech.
[01:38:55.620 --> 01:38:57.740]   We had a fun week this week.
[01:38:57.740 --> 01:39:00.780]   And I think Benito has a little movie
[01:39:00.780 --> 01:39:04.100]   to show us showing us why.
[01:39:04.100 --> 01:39:04.580]   You know what?
[01:39:04.580 --> 01:39:07.700]   The chip business is in a big turmoil right now.
[01:39:07.700 --> 01:39:09.660]   It's very interesting to see what's going to happen.
[01:39:09.660 --> 01:39:13.460]   I wonder how this is going to impact Frito-Lay.
[01:39:13.460 --> 01:39:16.260]   Previously on Twit.
[01:39:16.260 --> 01:39:17.780]   Tech News Weekly.
[01:39:17.780 --> 01:39:19.540]   Actually, my friend, neighbor, he
[01:39:19.540 --> 01:39:20.860]   lives just a couple of walks away.
[01:39:20.860 --> 01:39:24.660]   Alan Cecil joins to talk about how his team used his TAS bot
[01:39:24.660 --> 01:39:26.460]   to do some pretty incredible things
[01:39:26.460 --> 01:39:30.740]   on the Nintendo 64, specifically on the Ocarina of Time.
[01:39:30.740 --> 01:39:32.380]   This is our mascot.
[01:39:32.380 --> 01:39:35.460]   And we use him to play video games perfectly
[01:39:35.460 --> 01:39:38.620]   at Game's Done Quick and Other Charity events.
[01:39:38.620 --> 01:39:39.740]   All about Android.
[01:39:39.740 --> 01:39:42.700]   Your phone needs to be repaired.
[01:39:42.700 --> 01:39:43.980]   You drop your phone.
[01:39:43.980 --> 01:39:45.460]   The display is broken.
[01:39:45.460 --> 01:39:47.620]   There's a nervousness around like, here's my phone
[01:39:47.620 --> 01:39:49.180]   with everything that's important to me.
[01:39:49.180 --> 01:39:52.100]   I'm going to send it in just to get this repair done.
[01:39:52.100 --> 01:39:56.420]   Well, Samsung is making a change to add something called a repair
[01:39:56.420 --> 01:39:58.860]   mode that you put it into repair mode.
[01:39:58.860 --> 01:40:00.980]   It locks the phone data down.
[01:40:00.980 --> 01:40:06.180]   So all it offers is the default installed app.
[01:40:06.180 --> 01:40:07.500]   This weekend Google.
[01:40:07.500 --> 01:40:11.180]   I quit my job to buy and resell used books on Amazon.
[01:40:11.180 --> 01:40:15.180]   Now I use my six figure income to travel the world to the world.
[01:40:15.180 --> 01:40:17.700]   I just got some old life magazines for $2.
[01:40:17.700 --> 01:40:20.700]   I'm going to bet I can sell that for more money.
[01:40:20.700 --> 01:40:24.500]   Well, I have this fine picture of a handsome gentleman.
[01:40:24.500 --> 01:40:25.700]   Former TV guy.
[01:40:25.700 --> 01:40:27.660]   If somebody is going to buy, if some shmuck
[01:40:27.660 --> 01:40:29.460]   is going to buy even that.
[01:40:29.460 --> 01:40:30.140]   Twit.
[01:40:30.140 --> 01:40:33.980]   I'm pretty sure they're not traveling the world.
[01:40:33.980 --> 01:40:37.500]   The big bucks from selling Jeff Jarvis portrait.
[01:40:37.500 --> 01:40:38.500]   Blah.
[01:40:38.500 --> 01:40:39.000]   Bye.
[01:40:39.000 --> 01:40:46.380]   Thank you for that moment.
[01:40:46.380 --> 01:40:49.900]   And in time we were talking about the week's tech news
[01:40:49.900 --> 01:40:52.340]   with our great panel.
[01:40:52.340 --> 01:40:54.060]   First time on the show, Anubi.
[01:40:54.060 --> 01:40:55.260]   But boy, you fit in great.
[01:40:55.260 --> 01:40:57.340]   Abrara Al-Hidi from CNET.
[01:40:57.340 --> 01:41:01.100]   Thank you very much for being here this week, Abrara.
[01:41:01.100 --> 01:41:03.700]   They were right when they said how wonderful you are.
[01:41:03.700 --> 01:41:04.740]   That's so kind of you.
[01:41:04.740 --> 01:41:05.260]   Thank you.
[01:41:05.260 --> 01:41:06.980]   All friend, Georgia Dow.
[01:41:06.980 --> 01:41:11.620]   Always great to see you from YouTube fame.
[01:41:11.620 --> 01:41:14.060]   YouTube.com/georgeadow.
[01:41:14.060 --> 01:41:19.340]   And Christina Warren, who we have known through at least four
[01:41:19.340 --> 01:41:20.620]   jobs, I think.
[01:41:20.620 --> 01:41:21.100]   Yeah.
[01:41:21.100 --> 01:41:21.300]   Yeah.
[01:41:21.300 --> 01:41:22.020]   I think so.
[01:41:22.020 --> 01:41:22.780]   I think so, yeah.
[01:41:22.780 --> 01:41:25.260]   Mashable, Microsoft, GitHub.
[01:41:25.260 --> 01:41:26.340]   Where were you before Mashable?
[01:41:26.340 --> 01:41:27.700]   I think that's where we met.
[01:41:27.700 --> 01:41:29.460]   We met him Mashable, and then I was at Gizmodo.
[01:41:29.460 --> 01:41:30.460]   His modo.
[01:41:30.460 --> 01:41:31.980]   And now GitHub.
[01:41:31.980 --> 01:41:33.060]   So yeah, four jobs.
[01:41:33.060 --> 01:41:34.060]   Yeah.
[01:41:34.060 --> 01:41:34.580]   That's right.
[01:41:34.580 --> 01:41:35.140]   Over a decade.
[01:41:35.140 --> 01:41:35.340]   Like--
[01:41:35.340 --> 01:41:36.420]   Yeah, that's not that many.
[01:41:36.420 --> 01:41:37.980]   It's been a long time, actually.
[01:41:37.980 --> 01:41:40.220]   No, I see jobs typically a long time.
[01:41:40.220 --> 01:41:42.140]   But we've been--
[01:41:42.140 --> 01:41:45.100]   I mean, I think I met you for the first time in 2009.
[01:41:45.100 --> 01:41:46.660]   Like at a Mac world or something.
[01:41:46.660 --> 01:41:47.580]   Yeah, it was.
[01:41:47.580 --> 01:41:51.140]   Yeah, that's how long ago that was.
[01:41:51.140 --> 01:41:54.100]   There, as you may know, there's
[01:41:54.100 --> 01:41:57.940]   concern about quantum computing and encryption,
[01:41:57.940 --> 01:42:01.860]   particularly encryption keys.
[01:42:01.860 --> 01:42:05.420]   And so the National Institutes for Standards and Time
[01:42:05.420 --> 01:42:07.860]   has set up a competition to come up
[01:42:07.860 --> 01:42:14.700]   with new public key crypto that will survive quantum computing.
[01:42:14.700 --> 01:42:18.020]   There were four contenders.
[01:42:18.020 --> 01:42:19.460]   Well, there were four contenders.
[01:42:19.460 --> 01:42:23.860]   One of them is now out of the running.
[01:42:23.860 --> 01:42:28.980]   And it only took a single core PC and an hour to do it.
[01:42:28.980 --> 01:42:30.900]   This article from Dan Gooden and ours
[01:42:30.900 --> 01:42:31.380]   technical.
[01:42:31.380 --> 01:42:33.340]   Leave it to mathematicians to mock up
[01:42:33.340 --> 01:42:35.260]   what looked like an impressive new algorithm.
[01:42:35.260 --> 01:42:37.140]   One of the reasons they have these competitions, though,
[01:42:37.140 --> 01:42:41.780]   is to come up with these improved crypto techniques
[01:42:41.780 --> 01:42:44.540]   and then let people bang on it to make sure it really, really
[01:42:44.540 --> 01:42:48.300]   will work.
[01:42:48.300 --> 01:42:55.180]   The new attack breaks the algorithm called Sike, S-I-K-E.
[01:42:55.180 --> 01:42:58.420]   This is one of the four replacement algorithms
[01:42:58.420 --> 01:43:02.580]   that NIST says need new testing.
[01:43:02.580 --> 01:43:05.740]   The attack has no impact on the four other four algorithms
[01:43:05.740 --> 01:43:07.900]   selected by NIST as approved standards.
[01:43:07.900 --> 01:43:10.140]   So we have four that are approved and then four
[01:43:10.140 --> 01:43:11.420]   they thought were interesting.
[01:43:11.420 --> 01:43:13.300]   But let's test them.
[01:43:13.300 --> 01:43:15.060]   Well, Sike is out.
[01:43:15.060 --> 01:43:20.540]   Super singular isogene, isogene key encapsulation.
[01:43:20.540 --> 01:43:22.700]   Researchers from the Computer Security Industrial
[01:43:22.700 --> 01:43:27.820]   Cryptography Group at KU Louvin wrote a paper called
[01:43:27.820 --> 01:43:29.540]   "Efficient."
[01:43:29.540 --> 01:43:30.820]   No doubt.
[01:43:30.820 --> 01:43:35.260]   "Efficient key recovery tech used complex mathematics
[01:43:35.260 --> 01:43:37.860]   in a single traditional PC to recover the encryption
[01:43:37.860 --> 01:43:41.140]   keys in an hour."
[01:43:41.140 --> 01:43:43.980]   By the way, they are now eligible for a $50,000 reward
[01:43:43.980 --> 01:43:46.460]   from Microsoft.
[01:43:46.460 --> 01:43:48.860]   Nice work if you can get it.
[01:43:48.860 --> 01:43:54.100]   But I think we are coming along with post-quantum computing.
[01:43:54.100 --> 01:43:57.180]   Now if we could just convince some quad-post-quantum computing
[01:43:57.180 --> 01:44:03.820]   computers, none of them are really that impressive yet.
[01:44:03.820 --> 01:44:07.700]   Pearson wants to make a little more money on its textbooks,
[01:44:07.700 --> 01:44:10.700]   which are already really expensive.
[01:44:10.700 --> 01:44:14.340]   Pearson, which is, I think, the world's largest textbook
[01:44:14.340 --> 01:44:17.020]   publisher, and my former publisher, I might add,
[01:44:17.020 --> 01:44:18.580]   has decided--
[01:44:18.580 --> 01:44:19.380]   here's what we do.
[01:44:19.380 --> 01:44:23.140]   We sell our book for $100.
[01:44:23.140 --> 01:44:25.460]   But we'll also include with that an NFT
[01:44:25.460 --> 01:44:28.540]   so that we can recapture some of the resales
[01:44:28.540 --> 01:44:31.860]   in the used book market.
[01:44:31.860 --> 01:44:35.420]   CEO of Pearson, Andy Bird, says, in the analog world
[01:44:35.420 --> 01:44:38.380]   a Pearson textbook, where he's resold up to seven times.
[01:44:38.380 --> 01:44:41.460]   And we could only participate in the first sale.
[01:44:41.460 --> 01:44:44.620]   Oh, oh.
[01:44:44.620 --> 01:44:46.500]   The move to digital helps to diminish
[01:44:46.500 --> 01:44:49.780]   the secondary market and technology like blockchain and NFTs
[01:44:49.780 --> 01:44:53.980]   allows us to participate in every sale of that particular item
[01:44:53.980 --> 01:44:56.940]   as it goes through its life.
[01:44:56.940 --> 01:44:58.380]   Evil?
[01:44:58.380 --> 01:44:59.700]   Yeah, you don't seem--
[01:44:59.700 --> 01:45:00.340]   Greedy.
[01:45:00.340 --> 01:45:01.100]   Greedy.
[01:45:01.100 --> 01:45:01.620]   Greedy.
[01:45:01.620 --> 01:45:04.540]   It's so very greedy when--
[01:45:04.540 --> 01:45:05.940]   and these are students.
[01:45:05.940 --> 01:45:06.620]   It's just--
[01:45:06.620 --> 01:45:07.620]   Yep.
[01:45:07.620 --> 01:45:11.700]   No thought at all or care about what happens.
[01:45:11.700 --> 01:45:15.540]   We want to educate society, and I think education should be free.
[01:45:15.540 --> 01:45:18.660]   And then we suddenly start to gouge students.
[01:45:18.660 --> 01:45:24.420]   Just, oh, you can't get behind when they're just trying to--
[01:45:24.420 --> 01:45:28.300]   even reselling of textbooks was really expensive for students
[01:45:28.300 --> 01:45:29.340]   to be able to deal with it.
[01:45:29.340 --> 01:45:30.780]   They didn't make a piece of it.
[01:45:30.780 --> 01:45:32.580]   So now, oh, for them.
[01:45:32.580 --> 01:45:35.060]   The world's smallest violin crashed and burned.
[01:45:35.060 --> 01:45:36.060]   I'm sorry, nothing.
[01:45:36.060 --> 01:45:37.820]   Nothing for me.
[01:45:37.820 --> 01:45:41.100]   Yeah, no, I was talking about this on my podcast Rocket.
[01:45:41.100 --> 01:45:43.780]   And I did actually think of the only possible good thing
[01:45:43.780 --> 01:45:45.180]   that could come from this.
[01:45:45.180 --> 01:45:48.300]   If they decide to put this on the blockchain or whatever
[01:45:48.300 --> 01:45:51.820]   under some sort of DRM, that DRM will be cracked instantly,
[01:45:51.820 --> 01:45:54.580]   in which case we could then just have a very easy way
[01:45:54.580 --> 01:45:56.700]   to right click on all the textbooks.
[01:45:56.700 --> 01:45:59.740]   So part of me is kind of like, yes, please do this
[01:45:59.740 --> 01:46:01.820]   and lead to the destruction of your own business,
[01:46:01.820 --> 01:46:04.020]   because that I would be down for.
[01:46:04.020 --> 01:46:07.340]   But yeah, I'm not a person with you, Georgia.
[01:46:07.340 --> 01:46:08.180]   They're greedy.
[01:46:08.180 --> 01:46:12.220]   The textbook market both used and new is completely
[01:46:12.220 --> 01:46:14.780]   predatory on so many levels.
[01:46:14.780 --> 01:46:15.860]   Yes.
[01:46:15.860 --> 01:46:17.940]   If what they did then is that, well, because we're
[01:46:17.940 --> 01:46:21.020]   going to recoup some of the money from used book sales,
[01:46:21.020 --> 01:46:23.620]   we will lower the cost of textbooks.
[01:46:23.620 --> 01:46:24.820]   OK, maybe.
[01:46:24.820 --> 01:46:28.780]   But the textbooks are $100, $200 because, oh, it
[01:46:28.780 --> 01:46:30.060]   costs us so much to create.
[01:46:30.060 --> 01:46:32.700]   So we have to charge you this money.
[01:46:32.700 --> 01:46:35.660]   And then if there are too many of them in circulation,
[01:46:35.660 --> 01:46:37.900]   they will issue a very small update.
[01:46:37.900 --> 01:46:39.220]   It then becomes a new addition.
[01:46:39.220 --> 01:46:41.980]   That then your professors require you to get.
[01:46:41.980 --> 01:46:44.060]   Because they've always hated this resale market.
[01:46:44.060 --> 01:46:44.780]   They've always hated.
[01:46:44.780 --> 01:46:45.280]   They have.
[01:46:45.280 --> 01:46:46.380]   Oh, I was going to say it.
[01:46:46.380 --> 01:46:48.740]   So they do everything they can to suppress the used market.
[01:46:48.740 --> 01:46:50.700]   And to be clear, the universities,
[01:46:50.700 --> 01:46:52.300]   like the official bookstores and even
[01:46:52.300 --> 01:46:54.940]   like the unofficial ones, like they're predatory as all get
[01:46:54.940 --> 01:46:55.420]   out to.
[01:46:55.420 --> 01:46:57.620]   And the way that they handle used book store sales
[01:46:57.620 --> 01:47:01.260]   for they'll give you $20 for a book that they then sell for $85.
[01:47:01.260 --> 01:47:04.300]   Like the whole system is a scam.
[01:47:04.300 --> 01:47:05.300]   But you're exactly right.
[01:47:05.300 --> 01:47:07.860]   Like they do everything they can to get away
[01:47:07.860 --> 01:47:09.980]   from the used book market.
[01:47:09.980 --> 01:47:11.700]   And they can't partake in those sales
[01:47:11.700 --> 01:47:13.060]   because of the first sale doctrine.
[01:47:13.060 --> 01:47:16.340]   So they're like, yes, we'll just find a way to avoid that here.
[01:47:16.340 --> 01:47:20.300]   And then to make updates incrementally, yeah.
[01:47:20.300 --> 01:47:21.660]   Like I said, the only good thing about this
[01:47:21.660 --> 01:47:23.460]   would be that they would have terrible DRM.
[01:47:23.460 --> 01:47:24.780]   We know it would be cracked.
[01:47:24.780 --> 01:47:27.420]   And then we could, you know, like right click and share
[01:47:27.420 --> 01:47:28.060]   with everyone.
[01:47:28.060 --> 01:47:30.300]   That's the unintended consequence of this.
[01:47:30.300 --> 01:47:32.060]   When you start to lock staff down like this,
[01:47:32.060 --> 01:47:35.380]   professors start Xeroxing textbooks.
[01:47:35.380 --> 01:47:35.820]   Yeah.
[01:47:35.820 --> 01:47:37.740]   People start to crack the DRM.
[01:47:37.740 --> 01:47:40.820]   That's always-- DRM drives me crazy
[01:47:40.820 --> 01:47:43.820]   because it never stops pirates.
[01:47:43.820 --> 01:47:44.620]   Ever.
[01:47:44.620 --> 01:47:46.860]   Pirates just go right around it.
[01:47:46.860 --> 01:47:48.940]   It stops normal users.
[01:47:48.940 --> 01:47:49.860]   It's just sad.
[01:47:49.860 --> 01:47:51.380]   It's those that are rule abiding.
[01:47:51.380 --> 01:47:53.940]   Rule abiding, lawful users.
[01:47:53.940 --> 01:47:55.140]   Is that who you want to publish?
[01:47:55.140 --> 01:47:55.900]   Punish.
[01:47:55.900 --> 01:47:57.140]   Punish.
[01:47:57.140 --> 01:47:58.500]   I don't think they care.
[01:47:58.500 --> 01:47:59.580]   They don't care.
[01:47:59.580 --> 01:48:00.140]   They don't care.
[01:48:00.140 --> 01:48:00.620]   They care.
[01:48:00.620 --> 01:48:01.220]   They're fine.
[01:48:01.220 --> 01:48:03.380]   I think they're sleeping fine on their, you know,
[01:48:03.380 --> 01:48:05.860]   whatever $1,000 pillows.
[01:48:05.860 --> 01:48:07.860]   They're fine.
[01:48:07.860 --> 01:48:08.940]   You know, I've slept on money.
[01:48:08.940 --> 01:48:09.740]   It's not comfortable.
[01:48:09.740 --> 01:48:10.660]   Don't do that.
[01:48:10.660 --> 01:48:12.140]   [LAUGHTER]
[01:48:12.140 --> 01:48:15.020]   This is out of just South Leo.
[01:48:15.020 --> 01:48:16.540]   Oh, I used to take a bath in it.
[01:48:16.540 --> 01:48:18.500]   That's even worse.
[01:48:18.500 --> 01:48:20.420]   So yeah.
[01:48:20.420 --> 01:48:24.140]   I did fill my swimming pool with $1,000 bill.
[01:48:24.140 --> 01:48:25.220]   So that's OK.
[01:48:25.220 --> 01:48:28.060]   Duck Duck Go has finally changed their tune.
[01:48:28.060 --> 01:48:29.540]   You may remember they got a lot of trouble
[01:48:29.540 --> 01:48:32.380]   because they claimed their deal with Microsoft
[01:48:32.380 --> 01:48:35.220]   for the Bing search engine required their privacy
[01:48:35.220 --> 01:48:39.820]   browser to allow Microsoft trackers through.
[01:48:39.820 --> 01:48:45.780]   After an uproar, Duck Duck Go now says their privacy protection
[01:48:45.780 --> 01:48:50.740]   will apply to Microsoft scripts as well.
[01:48:50.740 --> 01:48:55.020]   Except it's not quite 100%.
[01:48:55.020 --> 01:48:58.020]   100%.
[01:48:58.020 --> 01:49:00.300]   VP of communications for Duck Duck Go
[01:49:00.300 --> 01:49:03.740]   told the Verge that most Microsoft scripts were already
[01:49:03.740 --> 01:49:08.980]   being blocked by the browser's other protections.
[01:49:08.980 --> 01:49:11.380]   Camille, as Baz said, we ran a test
[01:49:11.380 --> 01:49:13.380]   to see how much more blocking is happening
[01:49:13.380 --> 01:49:16.620]   as a result of this update based on the top 1,000 websites.
[01:49:16.620 --> 01:49:20.660]   The increase was only 0.25%.
[01:49:20.660 --> 01:49:27.540]   But it won't block scripts for bat.bing.com, which
[01:49:27.540 --> 01:49:32.460]   is a script used on advertiser sites to measure effectiveness.
[01:49:32.460 --> 01:49:34.820]   So I think that some permanent reputation
[01:49:34.820 --> 01:49:38.300]   damage because Duck Duck Go kind of didn't mention
[01:49:38.300 --> 01:49:40.460]   this exemption for Microsoft scripts.
[01:49:40.460 --> 01:49:46.380]   Yeah, that's a problem, though, is that if you're going on a platform
[01:49:46.380 --> 01:49:49.420]   of we should be able to be trusted,
[01:49:49.420 --> 01:49:53.700]   and then you get found out that you're not trustworthy,
[01:49:53.700 --> 01:49:55.180]   it becomes a really huge issue.
[01:49:55.180 --> 01:49:57.780]   Versus if you're just like, we're evil, everyone expects it,
[01:49:57.780 --> 01:50:00.140]   and then you don't have to worry about anything.
[01:50:00.140 --> 01:50:01.020]   Has anybody done that?
[01:50:01.020 --> 01:50:03.940]   Oh, Facebook, they just embraced the evil.
[01:50:03.940 --> 01:50:06.460]   Goof, Google got rid of, don't be evil.
[01:50:06.460 --> 01:50:08.340]   They don't even say it anymore.
[01:50:08.340 --> 01:50:15.260]   They-- like a bra, what are your thoughts on?
[01:50:15.260 --> 01:50:16.540]   Evil Google.
[01:50:16.540 --> 01:50:18.580]   No, I agree with you.
[01:50:18.580 --> 01:50:21.300]   I think you really got it down in the sense
[01:50:21.300 --> 01:50:23.580]   that when we started out this conversation talking
[01:50:23.580 --> 01:50:27.420]   about how people feel like they're everywhere they look,
[01:50:27.420 --> 01:50:29.300]   whatever platform or product they use,
[01:50:29.300 --> 01:50:30.380]   there's no sense of privacy.
[01:50:30.380 --> 01:50:34.420]   But I think people feel like there's very few platforms or services
[01:50:34.420 --> 01:50:37.980]   where they do have even a little bit more of a sense of privacy.
[01:50:37.980 --> 01:50:40.900]   And now they have this humbling reminder
[01:50:40.900 --> 01:50:43.020]   that maybe that's not the case.
[01:50:43.020 --> 01:50:51.060]   All right, so the Galaxy Unpacked Event is August 10th, three days.
[01:50:51.060 --> 01:50:51.940]   Is that Wednesdays?
[01:50:51.940 --> 01:50:53.220]   8, 9, 10.
[01:50:53.220 --> 01:50:54.220]   It is Wednesday, yes.
[01:50:54.220 --> 01:50:56.820]   And it's early in the morning for us, isn't it, bra?
[01:50:56.820 --> 01:50:58.380]   It's too early in the morning.
[01:50:58.380 --> 01:50:59.980]   Yeah, it's like 7 AM or something.
[01:50:59.980 --> 01:51:01.700]   I make you 6 AM.
[01:51:01.700 --> 01:51:03.020]   Oh, man, Pacific.
[01:51:03.020 --> 01:51:05.900]   I'm making Jason Howell, and I think Ron's going to try them.
[01:51:05.900 --> 01:51:08.140]   I'm making the all about Android team doing this.
[01:51:08.140 --> 01:51:09.500]   What are we going to see, a bra?
[01:51:09.500 --> 01:51:10.860]   Do we know?
[01:51:10.860 --> 01:51:11.660]   We're hoping.
[01:51:11.660 --> 01:51:13.020]   We're not sure what we're going to see.
[01:51:13.020 --> 01:51:17.380]   I think a lot of us are hoping that we'll see updates
[01:51:17.380 --> 01:51:18.460]   to the foldable phones.
[01:51:18.460 --> 01:51:22.420]   So we have the Galaxy Z Fold and the Galaxy Z Flip.
[01:51:22.420 --> 01:51:24.580]   And foldable phones are interesting,
[01:51:24.580 --> 01:51:29.940]   because I think a lot of people see them as snazzy and fun to look at.
[01:51:29.940 --> 01:51:33.180]   But the foldable market is growing,
[01:51:33.180 --> 01:51:37.220]   but you don't walk around and see people open up a fold.
[01:51:37.220 --> 01:51:38.380]   I like it.
[01:51:38.380 --> 01:51:41.060]   I don't use it, but I like the flip.
[01:51:41.060 --> 01:51:44.340]   Yeah, and the flip is actually the more popular one,
[01:51:44.340 --> 01:51:46.060]   I think, because it's nice and small,
[01:51:46.060 --> 01:51:48.780]   and everything people love that clamshell kind of style.
[01:51:48.780 --> 01:51:51.340]   And you can fit in your pocket really easily.
[01:51:51.340 --> 01:51:55.620]   The thing about the fold is that it looks beautiful when you open it.
[01:51:55.620 --> 01:51:57.020]   It's like a nice big tablet.
[01:51:57.020 --> 01:52:01.180]   But then when it's closed, the screen is really thin and awkward.
[01:52:01.180 --> 01:52:03.980]   And so I think that's something that Samsung has to figure out,
[01:52:03.980 --> 01:52:05.140]   and that's something that we're hoping,
[01:52:05.140 --> 01:52:06.980]   if there is the next iteration of it,
[01:52:06.980 --> 01:52:09.100]   that we kind of figure out a better use case for that.
[01:52:09.100 --> 01:52:12.620]   But the flip is really popular, and it's really cute and snazzy.
[01:52:12.620 --> 01:52:16.340]   But the thing with these phones also is that if they want people
[01:52:16.340 --> 01:52:19.940]   to buy into them more, they're going to have to get the basics down.
[01:52:19.940 --> 01:52:22.380]   Like, OK, cool, we have a foldable phone, foldable screen.
[01:52:22.380 --> 01:52:23.180]   That's really cool.
[01:52:23.180 --> 01:52:25.020]   But battery life isn't great.
[01:52:25.020 --> 01:52:27.060]   The cameras are OK, but they're not great.
[01:52:27.060 --> 01:52:28.580]   There's design issues.
[01:52:28.580 --> 01:52:31.420]   And so I think once they really get that down,
[01:52:31.420 --> 01:52:34.940]   maybe we'll see more people kind of out in the wild with foldable and flipable phones.
[01:52:34.940 --> 01:52:40.220]   One rumor that I kind of believe is that Samsung will drop the Z, the Z,
[01:52:40.220 --> 01:52:45.260]   because the Russians use that as their symbol for the Ukrainian invasion.
[01:52:45.260 --> 01:52:48.540]   And so it's not cool to be a Z anymore.
[01:52:48.540 --> 01:52:50.340]   So it might just be the flip--
[01:52:50.340 --> 01:52:52.020]   I don't know why you had a Z anyway.
[01:52:52.020 --> 01:52:54.380]   It might not be just a flip and fold for.
[01:52:54.380 --> 01:52:56.180]   They throw so many numbers and letters into phones.
[01:52:56.180 --> 01:52:59.180]   That doesn't make any sense at all.
[01:52:59.180 --> 01:53:02.540]   I really like-- I gave my flip to Stacey Higginbotham on Twig,
[01:53:02.540 --> 01:53:08.220]   because I'm going to be always probably an iPhone and Pixel phone user,
[01:53:08.220 --> 01:53:11.020]   just because that's kind of the mainstream stuff.
[01:53:11.020 --> 01:53:13.380]   But I really think that that was cute.
[01:53:13.380 --> 01:53:13.940]   It was little.
[01:53:13.940 --> 01:53:16.220]   You could slip in your pocket or your purse.
[01:53:16.220 --> 01:53:18.380]   It opened up to a normal-sized phone.
[01:53:18.380 --> 01:53:21.140]   It wasn't a giant-sized phone like the Fold.
[01:53:21.140 --> 01:53:22.620]   It was just a normal little thing.
[01:53:22.620 --> 01:53:23.780]   And I don't know.
[01:53:23.780 --> 01:53:24.460]   I kind of like it.
[01:53:24.460 --> 01:53:29.060]   We've seen some leaks, different colors, and so forth.
[01:53:29.060 --> 01:53:31.260]   But we'll find out a little more on Wednesday.
[01:53:31.260 --> 01:53:33.620]   We do know-- I'm pretty sure that Samsung will
[01:53:33.620 --> 01:53:37.420]   ask the watch 5, the Galaxy Watch 5.
[01:53:37.420 --> 01:53:39.740]   Again, I think--
[01:53:39.740 --> 01:53:42.860]   I'm an Apple Watch wearer, but I think
[01:53:42.860 --> 01:53:45.940]   there's a pretty good competitor for it.
[01:53:45.940 --> 01:53:46.580]   Absolutely.
[01:53:46.580 --> 01:53:50.180]   I think I always get really annoyed when people--
[01:53:50.180 --> 01:53:53.180]   when we talk about any non-Apple company,
[01:53:53.180 --> 01:53:54.780]   and people see that I have an Android,
[01:53:54.780 --> 01:53:56.220]   and they're like, oh, you have an Android.
[01:53:56.220 --> 01:53:57.540]   You don't understand that.
[01:53:57.540 --> 01:53:59.780]   Samsung, not all Android's are critical.
[01:53:59.780 --> 01:54:02.700]   Samsung does a really good job with its products.
[01:54:02.700 --> 01:54:04.540]   But yeah, definitely good Apple competitors,
[01:54:04.540 --> 01:54:07.060]   but it's not the Apple name.
[01:54:07.060 --> 01:54:09.340]   I like the bezel that turns.
[01:54:09.340 --> 01:54:11.340]   I'm glad they brought that back.
[01:54:11.340 --> 01:54:16.220]   There is a rumor that the new one will have big battery life.
[01:54:16.220 --> 01:54:16.540]   I don't know.
[01:54:16.540 --> 01:54:19.020]   We'll have to see that you hear these rumors.
[01:54:19.020 --> 01:54:23.540]   But they're saying the battery is 590 milliamp hours,
[01:54:23.540 --> 01:54:26.700]   which would give it a runtime of up to 80 hours.
[01:54:26.700 --> 01:54:29.740]   It'd be about a five or six day watch, which
[01:54:29.740 --> 01:54:31.860]   would be pretty impressive.
[01:54:31.860 --> 01:54:33.260]   That's the other big thing that I think
[01:54:33.260 --> 01:54:37.500]   watches in general, once you have a longer battery life,
[01:54:37.500 --> 01:54:40.940]   people might be more likely to wear them and keep them on.
[01:54:40.940 --> 01:54:44.220]   I mean, I'm just used to--
[01:54:44.220 --> 01:54:46.420]   every night has taken everything out of my pockets
[01:54:46.420 --> 01:54:49.220]   and I'll get it all up to the charger.
[01:54:49.220 --> 01:54:51.580]   I got to charge some stuff anyway,
[01:54:51.580 --> 01:54:53.260]   so I might as well charge it all.
[01:54:53.260 --> 01:54:55.500]   I'm impressed when people can sleep with anything on their arm.
[01:54:55.500 --> 01:54:55.820]   I--
[01:54:55.820 --> 01:54:56.320]   No.
[01:54:56.320 --> 01:54:57.220]   --I do bother me so much.
[01:54:57.220 --> 01:54:59.060]   But some people actually do the sleep tracking.
[01:54:59.060 --> 01:54:59.940]   And yeah.
[01:54:59.940 --> 01:55:00.780]   Yeah.
[01:55:00.780 --> 01:55:02.220]   Yeah.
[01:55:02.220 --> 01:55:02.580]   All right.
[01:55:02.580 --> 01:55:05.940]   Well, Wednesdays, the day 6 AM, are you guys going to be--
[01:55:05.940 --> 01:55:09.220]   I presume you guys will have live coverage of it as well.
[01:55:09.220 --> 01:55:09.780]   Yeah, we'll give you a--
[01:55:09.780 --> 01:55:12.500]   We will have live coverage, yes.
[01:55:12.500 --> 01:55:16.900]   My fearless colleague Claire Riley will be spearheading that.
[01:55:16.900 --> 01:55:19.100]   And I will be on as well with her.
[01:55:19.100 --> 01:55:19.600]   Good.
[01:55:19.600 --> 01:55:21.100]   Wish us luck for waking up.
[01:55:21.100 --> 01:55:21.600]   6 AM.
[01:55:21.600 --> 01:55:24.460]   --that will not be sleeping very much, yes.
[01:55:24.460 --> 01:55:25.540]   But yeah, we'll have coverage.
[01:55:25.540 --> 01:55:28.860]   And then we'll have post coverage as well.
[01:55:28.860 --> 01:55:29.340]   Yeah.
[01:55:29.340 --> 01:55:30.660]   Good.
[01:55:30.660 --> 01:55:32.180]   As I said, this is going to--
[01:55:32.180 --> 01:55:34.820]   we're getting into the expensive season
[01:55:34.820 --> 01:55:36.020]   because not only--
[01:55:36.020 --> 01:55:37.540]   this is going to start with Samsung,
[01:55:37.540 --> 01:55:39.700]   and then presumably at some point, Google
[01:55:39.700 --> 01:55:42.500]   will announce its Pixel 7 and the Pixel--
[01:55:42.500 --> 01:55:44.380]   I'm actually very interested in the Pixel Watch.
[01:55:44.380 --> 01:55:48.980]   Google hasn't made a watch in a long time ever.
[01:55:48.980 --> 01:55:50.340]   So this would be the first--
[01:55:50.340 --> 01:55:51.220]   No, I think they did.
[01:55:51.220 --> 01:55:52.220]   Didn't they?
[01:55:52.220 --> 01:55:54.340]   It wasn't there early on before it was Android
[01:55:54.340 --> 01:55:55.820]   where I'm almost positive Google.
[01:55:55.820 --> 01:55:58.260]   Oh, they had a watch, but it wasn't where.
[01:55:58.260 --> 01:55:58.620]   Yeah.
[01:55:58.620 --> 01:55:59.780]   Maybe that's it.
[01:55:59.780 --> 01:56:00.780]   Yeah.
[01:56:00.780 --> 01:56:01.280]   Yeah.
[01:56:01.280 --> 01:56:03.820]   Because I'm seeming to remember some pretty awful Google
[01:56:03.820 --> 01:56:07.060]   watch that I have there for review purposes.
[01:56:07.060 --> 01:56:08.540]   I must have blocked it out.
[01:56:08.620 --> 01:56:10.060]   [LAUGHTER]
[01:56:10.060 --> 01:56:14.900]   They now that they own Fitbit, presumably the Pixel Watch
[01:56:14.900 --> 01:56:17.380]   will have some interesting health.
[01:56:17.380 --> 01:56:19.100]   I mean, Google has the capability.
[01:56:19.100 --> 01:56:21.220]   It feels like they've given up, but they
[01:56:21.220 --> 01:56:24.180]   have the capability to do some amazing stuff.
[01:56:24.180 --> 01:56:26.860]   They just don't seem to have their mojo intact.
[01:56:26.860 --> 01:56:28.260]   I don't know why.
[01:56:28.260 --> 01:56:30.180]   I feel like they also do like six different things
[01:56:30.180 --> 01:56:30.980]   at the same time.
[01:56:30.980 --> 01:56:31.500]   I think that's it.
[01:56:31.500 --> 01:56:33.860]   Like, sure, let's release five different chat platforms.
[01:56:33.860 --> 01:56:35.540]   Decide which one we want to keep.
[01:56:35.540 --> 01:56:36.060]   Yeah.
[01:56:36.060 --> 01:56:36.700]   And then, like, I don't know.
[01:56:36.700 --> 01:56:38.020]   That's just kind of like Google style.
[01:56:38.020 --> 01:56:39.020]   Yeah.
[01:56:39.020 --> 01:56:42.220]   Well, look what they did with duo and meet and duo and meet.
[01:56:42.220 --> 01:56:44.380]   And oh, god, what a mess.
[01:56:44.380 --> 01:56:46.580]   Yeah.
[01:56:46.580 --> 01:56:50.860]   And then probably roughly a month,
[01:56:50.860 --> 01:56:53.620]   we're going to see Apple's new stuff.
[01:56:53.620 --> 01:56:54.540]   Rumors are now.
[01:56:54.540 --> 01:56:57.860]   There'll be a new HomePod, some new HomeKit stuff.
[01:56:57.860 --> 01:57:00.380]   Of course, there will be a new iPhone,
[01:57:00.380 --> 01:57:02.500]   and presumably a new watch.
[01:57:02.500 --> 01:57:06.300]   And there are rumors that there will be a pro version of the watch.
[01:57:06.300 --> 01:57:11.500]   It'll be made of unobtainium, and it'll last for 1,000 hours.
[01:57:11.500 --> 01:57:13.780]   And I don't know what, turn your wrist green.
[01:57:13.780 --> 01:57:15.300]   I don't know.
[01:57:15.300 --> 01:57:17.100]   We shall see.
[01:57:17.100 --> 01:57:17.980]   We shall see.
[01:57:17.980 --> 01:57:21.980]   This is an exciting, exciting time.
[01:57:21.980 --> 01:57:25.060]   If you've been all excited about dating in the metaverse,
[01:57:25.060 --> 01:57:26.300]   I'm bad news for you.
[01:57:26.300 --> 01:57:36.260]   Tinder has given up its plans for dating in the metaverse.
[01:57:36.260 --> 01:57:39.260]   The hyperconnect unit, which Tinder acquired the match group,
[01:57:39.260 --> 01:57:42.220]   which owns Tinder acquired in 2021,
[01:57:42.220 --> 01:57:47.900]   has been asked to scale back its metaverse dating plans.
[01:57:47.900 --> 01:57:50.180]   Chief Bernard Kim said, uncertainty
[01:57:50.180 --> 01:57:51.740]   about success with virtual worlds
[01:57:51.740 --> 01:57:55.300]   required the team not invest heavily in the metaverse,
[01:57:55.300 --> 01:57:57.900]   unlike Mark Zuckerberg.
[01:57:57.900 --> 01:58:00.460]   The match group further blamed the hyperconnect purchase
[01:58:00.460 --> 01:58:03.220]   for a $10 million operating loss.
[01:58:03.220 --> 01:58:08.100]   So there, they're also stepping back on their plans
[01:58:08.100 --> 01:58:10.620]   to add cryptocurrency to Tinder.
[01:58:10.620 --> 01:58:17.300]   Tinder coins didn't really take off.
[01:58:17.300 --> 01:58:24.820]   Nothing more to say, I guess.
[01:58:24.820 --> 01:58:29.020]   Well, didn't Tinder-- I mean, don't they have a new CEO now, too?
[01:58:29.020 --> 01:58:29.020]   They do.
[01:58:29.020 --> 01:58:30.340]   Do they just fire their CEO?
[01:58:30.340 --> 01:58:31.420]   No, they fire this CEO.
[01:58:31.420 --> 01:58:31.940]   Yeah.
[01:58:31.940 --> 01:58:35.860]   It seems like the old CEO maybe had a bunch of bad decisions,
[01:58:35.860 --> 01:58:38.140]   go big on crypto, go big on the metaverse.
[01:58:38.140 --> 01:58:40.580]   And meanwhile, everybody's like, no, actually,
[01:58:40.580 --> 01:58:42.340]   that's not why we use these apps.
[01:58:42.340 --> 01:58:44.100]   We just want to swipe right, please.
[01:58:44.100 --> 01:58:44.940]   Exactly.
[01:58:44.940 --> 01:58:45.940]   Yeah.
[01:58:45.940 --> 01:58:48.660]   We just want to be DTF, so it's not
[01:58:48.660 --> 01:58:49.700]   messing with the name of the other stuff.
[01:58:49.700 --> 01:58:51.500]   Thank you for telling the truth.
[01:58:51.500 --> 01:58:54.180]   But honestly, really, how could you lose money on that?
[01:58:54.180 --> 01:58:56.180]   I mean, that seems like a pretty good business.
[01:58:56.180 --> 01:59:00.460]   Honestly, which is why it's been a match group
[01:59:00.460 --> 01:59:04.020]   spun out from IAC because they're like, this makes us so much money.
[01:59:04.020 --> 01:59:04.740]   Yeah, exactly.
[01:59:04.740 --> 01:59:10.140]   It takes a lot for you to find a way to lose money on this market.
[01:59:10.140 --> 01:59:11.140]   Yeah.
[01:59:11.140 --> 01:59:12.140]   OK.
[01:59:12.140 --> 01:59:12.780]   Good job.
[01:59:12.780 --> 01:59:14.620]   Sometimes you just go too far.
[01:59:14.620 --> 01:59:17.340]   Like, Tinder trying to make it rain with their coins.
[01:59:17.340 --> 01:59:18.220]   I'm sorry, Tinder.
[01:59:18.220 --> 01:59:19.220]   Stop making it rain.
[01:59:19.220 --> 01:59:19.720]   Right.
[01:59:19.720 --> 01:59:21.020]   Leave this, totally are.
[01:59:21.020 --> 01:59:22.700]   Don't need Tinder coin.
[01:59:22.700 --> 01:59:23.220]   No.
[01:59:23.220 --> 01:59:23.580]   Yeah.
[01:59:23.580 --> 01:59:26.780]   Who would spend an envision--
[01:59:26.780 --> 01:59:28.220]   Sorry, being in the metaverse.
[01:59:28.220 --> 01:59:29.420]   Yes, someone giving you a coin.
[01:59:29.420 --> 01:59:32.300]   I'm sorry, that would be like, are you now sure I'm defended?
[01:59:32.300 --> 01:59:34.500]   I have a 100 Tinder coin.
[01:59:34.500 --> 01:59:35.500]   Yeah, no.
[01:59:35.500 --> 01:59:38.380]   And yeah, metaverse dating, Abra, are you ready for that?
[01:59:38.380 --> 01:59:40.060]   Ooh, that sounds great.
[01:59:40.060 --> 01:59:41.060]   Can't wait.
[01:59:41.060 --> 01:59:42.060]   Oh, my God.
[01:59:42.060 --> 01:59:44.100]   As if, you know, how could we make this worse?
[01:59:44.100 --> 01:59:44.900]   I think we probably would.
[01:59:44.900 --> 01:59:44.900]   Yes.
[01:59:44.900 --> 01:59:45.740]   How could we make dating worse?
[01:59:45.740 --> 01:59:46.660]   Like, on a meeting.
[01:59:46.660 --> 01:59:47.620]   Yeah, yeah, yeah.
[01:59:47.620 --> 01:59:48.100]   And that's--
[01:59:48.100 --> 01:59:49.380]   We did speed dating.
[01:59:49.380 --> 01:59:51.740]   What could we do this even worse?
[01:59:51.740 --> 01:59:52.380]   Exactly.
[01:59:52.380 --> 01:59:54.420]   Ever stating.
[01:59:54.420 --> 01:59:54.820]   Well, I'm sorry.
[01:59:54.820 --> 01:59:56.420]   Are you in your avatar?
[01:59:56.420 --> 01:59:58.140]   Like, you know, are we all--
[01:59:58.140 --> 01:59:59.380]   What was going to--
[01:59:59.380 --> 02:00:00.100]   No, I was going to say--
[02:00:00.100 --> 02:00:01.540]   I was already like--
[02:00:01.540 --> 02:00:02.900]   You're a panda.
[02:00:02.900 --> 02:00:04.060]   I don't understand.
[02:00:04.060 --> 02:00:07.060]   Oh, it's great for furries, but the rest of us, yeah.
[02:00:07.060 --> 02:00:08.540]   Right, I was going to say anybody else,
[02:00:08.540 --> 02:00:10.460]   like, we're already worried enough about catfishing
[02:00:10.460 --> 02:00:13.660]   and other stuff with people using fake things.
[02:00:13.660 --> 02:00:15.260]   And I was like, now, you literally
[02:00:15.260 --> 02:00:18.020]   can just pretend to be anyone.
[02:00:18.020 --> 02:00:19.780]   You could actually be a catfish.
[02:00:19.780 --> 02:00:20.780]   You can be a catfish.
[02:00:20.780 --> 02:00:21.580]   You could actually be a catfish.
[02:00:21.580 --> 02:00:23.060]   Yes.
[02:00:23.060 --> 02:00:26.340]   It's the-- we call it the double catfish.
[02:00:26.340 --> 02:00:28.540]   It's really a sophisticated maneuver.
[02:00:28.540 --> 02:00:29.780]   Yeah, it cancels each other out.
[02:00:29.780 --> 02:00:30.940]   Yeah, next right.
[02:00:30.940 --> 02:00:33.180]   I'm doing the double catfish.
[02:00:33.180 --> 02:00:36.580]   Christine, I know you're a big fan of TV and movies.
[02:00:36.580 --> 02:00:38.100]   A la Film Girl.
[02:00:38.100 --> 02:00:41.540]   You talk about it on Rocket.
[02:00:41.540 --> 02:00:43.260]   I have to say, I'm a little sad to hear
[02:00:43.260 --> 02:00:48.940]   that HBO is going to go away, merge with Discovery Plus
[02:00:48.940 --> 02:00:51.140]   next summer.
[02:00:51.140 --> 02:00:52.100]   Yeah.
[02:00:52.100 --> 02:00:54.620]   So there was a lot of uncertainty
[02:00:54.620 --> 02:00:57.220]   around what was going to happen with that.
[02:00:57.220 --> 02:00:58.940]   There was a rumor that basically we were going to get rid
[02:00:58.940 --> 02:00:59.820]   of the whole thing.
[02:00:59.820 --> 02:01:02.980]   Now, it seems like, based on the earnings call,
[02:01:02.980 --> 02:01:05.500]   probably listened to and was a very interesting earnings call.
[02:01:05.500 --> 02:01:08.780]   I have to say, first one under one of our other's discovery,
[02:01:08.780 --> 02:01:11.780]   David Zazlov and some of the other execs gave things.
[02:01:11.780 --> 02:01:13.020]   There's going to be a new service.
[02:01:13.020 --> 02:01:14.220]   They don't know the name of it yet,
[02:01:14.220 --> 02:01:15.860]   but it's going to basically combine everything that's
[02:01:15.860 --> 02:01:18.980]   in HBO Max and everything that's in Discovery Plus.
[02:01:18.980 --> 02:01:21.300]   But they admitted-- and I appreciated this--
[02:01:21.300 --> 02:01:23.340]   that both apps kind of suck.
[02:01:23.340 --> 02:01:24.580]   And they have to have--
[02:01:24.580 --> 02:01:27.380]   So let's make one app that sucks twice as well.
[02:01:27.380 --> 02:01:29.340]   Well, I mean, I think that this is actually--
[02:01:29.340 --> 02:01:31.500]   and this is where I'm a complete nerd on a level
[02:01:31.500 --> 02:01:33.500]   that some of the audience will appreciate.
[02:01:33.500 --> 02:01:36.020]   I started thinking about the technological,
[02:01:36.020 --> 02:01:39.380]   the requirements of how you would actually design
[02:01:39.380 --> 02:01:41.660]   an app like this that's combining the things
[02:01:41.660 --> 02:01:44.740]   from the different services and how you would do this
[02:01:44.740 --> 02:01:47.420]   as a greenfield app to build a new streaming thing
[02:01:47.420 --> 02:01:50.860]   with all these disparate service points.
[02:01:50.860 --> 02:01:52.900]   That actually was kind of exciting to me.
[02:01:52.900 --> 02:01:56.780]   But yeah, in theory, maybe they'll actually get it right
[02:01:56.780 --> 02:01:59.900]   and they'll have a strong technical back-end
[02:01:59.900 --> 02:02:02.500]   so that when you watch Euphoria, the app doesn't crash.
[02:02:02.500 --> 02:02:04.740]   But that remains to be determined.
[02:02:04.740 --> 02:02:07.380]   But they are making some changes in terms
[02:02:07.380 --> 02:02:10.180]   of what types of content different brands will have.
[02:02:10.180 --> 02:02:14.220]   And it seems like the reality TV stuff is all
[02:02:14.220 --> 02:02:17.940]   going to be under Discovery and building off of that.
[02:02:17.940 --> 02:02:21.300]   And they're not going to be doing the day and date streaming
[02:02:21.300 --> 02:02:24.700]   of a film, both in theaters and online anymore,
[02:02:24.700 --> 02:02:26.420]   which they've already said that one of you.
[02:02:26.420 --> 02:02:31.100]   That was very controversial, both with creators
[02:02:31.100 --> 02:02:32.820]   and theater owners.
[02:02:32.820 --> 02:02:34.380]   We liked it, right?
[02:02:34.380 --> 02:02:37.700]   We liked it, but it didn't work.
[02:02:37.700 --> 02:02:40.460]   And I think that at this point, it's probably not wrong
[02:02:40.460 --> 02:02:42.260]   to say if you're going to do theatrical,
[02:02:42.260 --> 02:02:44.500]   you need to be pure theatrical.
[02:02:44.500 --> 02:02:47.860]   If you have shorter windows, if you have 45 days or whatever,
[02:02:47.860 --> 02:02:48.620]   that's better.
[02:02:48.620 --> 02:02:50.340]   And I think that gets you to a surface faster.
[02:02:50.340 --> 02:02:53.420]   And I think for a lot of people, that's a good compromise
[02:02:53.420 --> 02:02:55.500]   versus what the old window used to be.
[02:02:55.500 --> 02:02:59.460]   But the reality is--
[02:02:59.460 --> 02:03:01.780]   and I think this is for worse, but the only films that really
[02:03:01.780 --> 02:03:04.780]   succeed in the theater are these big tentpole films.
[02:03:04.780 --> 02:03:07.060]   And so smaller films could go directly to streaming,
[02:03:07.060 --> 02:03:08.140]   and that's OK.
[02:03:08.140 --> 02:03:10.380]   But then you have the circumstance
[02:03:10.380 --> 02:03:14.220]   which got the most controversy, which is a Batgirl, which
[02:03:14.220 --> 02:03:15.820]   was done with principal photography.
[02:03:15.820 --> 02:03:17.980]   It was in the editing stages.
[02:03:17.980 --> 02:03:21.660]   It had already been screened in front of test audiences.
[02:03:21.660 --> 02:03:22.940]   And it's canceled.
[02:03:22.940 --> 02:03:24.380]   It's not going anywhere.
[02:03:24.380 --> 02:03:27.220]   They are refusing to invest even one more cent in it.
[02:03:27.220 --> 02:03:29.860]   They spent $90 million on it.
[02:03:29.860 --> 02:03:31.020]   Yeah.
[02:03:31.020 --> 02:03:33.260]   Is you think it was because it was a terrible movie,
[02:03:33.260 --> 02:03:36.660]   or do you think they decided that they couldn't make money
[02:03:36.660 --> 02:03:39.620]   on it, that spending another $100 million to market it would be?
[02:03:39.620 --> 02:03:41.020]   I think it's probably both.
[02:03:41.020 --> 02:03:42.260]   I think so.
[02:03:42.260 --> 02:03:45.460]   I mean, there was some good intel that was coming in
[02:03:45.460 --> 02:03:47.740]   that there were tax reasons to do this.
[02:03:47.740 --> 02:03:49.140]   They have until the middle of August
[02:03:49.140 --> 02:03:52.660]   to get certain tax write-offs based on the previous owners
[02:03:52.660 --> 02:03:53.940]   of Warner Brothers.
[02:03:53.940 --> 02:03:56.060]   They take a $90 million loss.
[02:03:56.060 --> 02:03:58.940]   Exactly, which would be good for their tax purposes.
[02:03:58.940 --> 02:04:00.420]   I do have to say, though, I think
[02:04:00.420 --> 02:04:04.460]   if they thought there was a way where they could invest in another $10
[02:04:04.460 --> 02:04:09.500]   or $20 million to finish the film and sell it to foreign markets,
[02:04:09.500 --> 02:04:13.060]   where you could still sell it and then release it directly
[02:04:13.060 --> 02:04:16.740]   to HBO Max, even without any publicity.
[02:04:16.740 --> 02:04:18.780]   And they could make some of their principal back.
[02:04:18.780 --> 02:04:19.820]   I think they would have done that.
[02:04:19.820 --> 02:04:24.420]   But it seems like-- and I'd heard from a couple of people
[02:04:24.420 --> 02:04:28.740]   who would heard internally things that it was just hot garbage,
[02:04:28.740 --> 02:04:30.980]   that it was just an absolutely irredeemable film.
[02:04:30.980 --> 02:04:32.140]   And so at that point, if you're talking
[02:04:32.140 --> 02:04:34.540]   about extensive reshoots, which is different than just finishing
[02:04:34.540 --> 02:04:37.900]   the edit and adding the special effects,
[02:04:37.900 --> 02:04:40.020]   at a certain point, you are at a set cost fallacy, right?
[02:04:40.020 --> 02:04:41.380]   You're throwing good money after bad.
[02:04:41.380 --> 02:04:46.700]   And maybe the best thing is to just say, OK, you know what?
[02:04:46.700 --> 02:04:51.140]   Another administration, so to speak, made these decisions.
[02:04:51.140 --> 02:04:52.340]   We didn't agree to it.
[02:04:52.340 --> 02:04:53.780]   We wouldn't have greenlit this film.
[02:04:53.780 --> 02:04:55.220]   It's not testing well.
[02:04:55.220 --> 02:04:58.980]   We're not going to put it out because it is bad financially,
[02:04:58.980 --> 02:05:01.700]   but also probably because it's not a good film.
[02:05:01.700 --> 02:05:02.820]   It's not a precedent.
[02:05:02.820 --> 02:05:03.780]   I mean, this is right.
[02:05:03.780 --> 02:05:05.060]   I mean, this happens.
[02:05:05.060 --> 02:05:06.380]   I would imagine this a lot.
[02:05:06.380 --> 02:05:08.580]   No, no, this is fairly unprecedented.
[02:05:08.580 --> 02:05:11.820]   For a film to actually be done with principal photography and--
[02:05:11.820 --> 02:05:13.380]   And almost fully edited.
[02:05:13.380 --> 02:05:15.260]   And exactly, it's for it to be at this stage
[02:05:15.260 --> 02:05:17.860]   and then for them to shelve it and for it to be $100 million
[02:05:17.860 --> 02:05:19.660]   film, that is fairly unprecedented.
[02:05:19.660 --> 02:05:21.060]   But I can't think of another time.
[02:05:21.060 --> 02:05:24.780]   It's also been in an era where marketing is a huge--
[02:05:24.780 --> 02:05:27.340]   I mean, it's going to be more than $90 million.
[02:05:27.340 --> 02:05:31.380]   So once it gets to that level, then you really have to say,
[02:05:31.380 --> 02:05:33.180]   is it worth spending money in a market of film
[02:05:33.180 --> 02:05:34.740]   that's going to tank?
[02:05:34.740 --> 02:05:35.740]   Right.
[02:05:35.740 --> 02:05:38.500]   And I mean, to me, my kind of thing--
[02:05:38.500 --> 02:05:40.300]   And this is why my initial thought was,
[02:05:40.300 --> 02:05:43.020]   this must really not be a good film-- was, again,
[02:05:43.020 --> 02:05:45.060]   if it was just about trying to recoup some of the money,
[02:05:45.060 --> 02:05:47.220]   which, again, this is before I found out about the tax
[02:05:47.220 --> 02:05:50.620]   element, which complicates things, I was thinking, OK, well,
[02:05:50.620 --> 02:05:53.820]   again, if all you had to do was finish the edit,
[02:05:53.820 --> 02:05:56.100]   not getting reshoots into it, you could sell it
[02:05:56.100 --> 02:05:59.740]   at a certain foreign territories where that licensing money
[02:05:59.740 --> 02:06:01.340]   would bring back a lot of it.
[02:06:01.340 --> 02:06:03.540]   And then you could just release it straight to--
[02:06:03.540 --> 02:06:05.140]   Straight to streaming is not bad.
[02:06:05.140 --> 02:06:06.420]   Without any publicity, right?
[02:06:06.420 --> 02:06:07.100]   You could do that.
[02:06:07.100 --> 02:06:10.380]   The thing is, though, if it's going to require, say,
[02:06:10.380 --> 02:06:13.380]   even a $40 or $50 million commitment, at that point,
[02:06:13.380 --> 02:06:15.660]   I think that completely changes the financial calculus.
[02:06:15.660 --> 02:06:19.780]   And so especially if they're getting the tax right off,
[02:06:19.780 --> 02:06:24.340]   I mean, it's unfortunate to see a film that was led
[02:06:24.340 --> 02:06:27.300]   by an Afro-Latina, like, that that's--
[02:06:27.300 --> 02:06:30.420]   it's bad optically for them to get rid of the film.
[02:06:30.420 --> 02:06:33.340]   But I haven't heard anybody coming out of the woodwork
[02:06:33.340 --> 02:06:35.540]   being like, no, this was actually a really great script
[02:06:35.540 --> 02:06:36.460]   and a really great movie.
[02:06:36.460 --> 02:06:37.500]   No one's saying that.
[02:06:37.500 --> 02:06:39.820]   The best everybody's saying is, oh, no, it's not as bad
[02:06:39.820 --> 02:06:41.460]   as you thought.
[02:06:41.460 --> 02:06:43.340]   Yeah, that's pretty bad.
[02:06:43.340 --> 02:06:46.140]   Which is kind of damning with Nate Fraser, right?
[02:06:46.140 --> 02:06:47.140]   So I don't know.
[02:06:47.140 --> 02:06:48.700]   But it is fairly unprecedented, which
[02:06:48.700 --> 02:06:52.140]   is why I think a lot of us were shocked, because usually--
[02:06:52.140 --> 02:06:53.940]   you see it with television pilots.
[02:06:53.940 --> 02:06:57.580]   You might see films going shelved or go direct DVD,
[02:06:57.580 --> 02:07:00.660]   but usually not $100 million films that
[02:07:00.660 --> 02:07:02.100]   are part of the big franchise.
[02:07:02.100 --> 02:07:06.900]   They did also cancel Scoob Holiday Hunt, which is mighty--
[02:07:06.900 --> 02:07:09.340]   See, that makes total sense, right?
[02:07:09.340 --> 02:07:11.100]   That sort of thing happens all the time.
[02:07:11.100 --> 02:07:12.100]   But--
[02:07:12.100 --> 02:07:13.140]   That was not-- wait a minute.
[02:07:13.140 --> 02:07:16.660]   It was 95% finished.
[02:07:16.660 --> 02:07:18.620]   I know I'm not the audience for it,
[02:07:18.620 --> 02:07:21.500]   but the creator said the audience is like it.
[02:07:21.500 --> 02:07:25.100]   And this is kind of a no-brainer for making money,
[02:07:25.100 --> 02:07:28.500]   because it's the time of year that it would appear, which
[02:07:28.500 --> 02:07:31.700]   is after Halloween before Christmas.
[02:07:31.700 --> 02:07:33.500]   All right, who knows?
[02:07:33.500 --> 02:07:34.380]   It's not my business.
[02:07:34.380 --> 02:07:35.020]   It's their business.
[02:07:35.020 --> 02:07:36.540]   They get to do whatever they want.
[02:07:36.540 --> 02:07:40.860]   I wonder if the merging of Discovery Plus and HBO Max,
[02:07:40.860 --> 02:07:44.620]   is it acknowledgment that there are too many streaming services
[02:07:44.620 --> 02:07:47.340]   that people are tired of spending so much money
[02:07:47.340 --> 02:07:48.940]   on separate services?
[02:07:48.940 --> 02:07:49.340]   Yeah.
[02:07:49.340 --> 02:07:52.500]   Well, that's sort of been David Zazlop's whole thing.
[02:07:52.500 --> 02:07:54.700]   This was actually one of the reasons why he shut down
[02:07:54.700 --> 02:07:57.580]   CNN Plus, basically, as soon as the company took over,
[02:07:57.580 --> 02:07:59.340]   they killed it.
[02:07:59.340 --> 02:08:02.460]   Because basically, he'd said very publicly
[02:08:02.460 --> 02:08:04.980]   that he thought that having all these individual streamers
[02:08:04.980 --> 02:08:06.820]   and these individual services was a problem,
[02:08:06.820 --> 02:08:09.540]   and that you should just have these big omni services.
[02:08:09.540 --> 02:08:13.180]   Because Discovery had tried, and he's been public about this.
[02:08:13.180 --> 02:08:16.180]   They'd tried to have many different sub-streaming networks
[02:08:16.180 --> 02:08:18.460]   for a long time, and it wasn't successful.
[02:08:18.460 --> 02:08:19.900]   And then they were like, OK, we're just
[02:08:19.900 --> 02:08:21.540]   going to do Discovery Plus.
[02:08:21.540 --> 02:08:22.780]   What's Discovery Plus?
[02:08:22.780 --> 02:08:23.300]   I don't know.
[02:08:23.300 --> 02:08:25.420]   What's on Discovery Plus?
[02:08:25.420 --> 02:08:27.460]   So it's basically everything from the various Discovery
[02:08:27.460 --> 02:08:28.580]   channels.
[02:08:28.580 --> 02:08:31.300]   But that includes TLC and some of the other stuff.
[02:08:31.300 --> 02:08:33.100]   So you see some original--
[02:08:33.100 --> 02:08:35.060]   It's all the housewives shows.
[02:08:35.060 --> 02:08:36.140]   No, no, no, no.
[02:08:36.140 --> 02:08:36.980]   That's on Peacock.
[02:08:36.980 --> 02:08:37.980]   That's Peacock.
[02:08:37.980 --> 02:08:41.300]   It more be like the 90-day fiance universe.
[02:08:41.300 --> 02:08:43.020]   It's you Discovery Plus hats.
[02:08:43.020 --> 02:08:44.420]   Very important to make it distinction.
[02:08:44.420 --> 02:08:45.420]   Very important.
[02:08:45.420 --> 02:08:45.860]   Very important.
[02:08:45.860 --> 02:08:46.460]   Well, yeah, no, no.
[02:08:46.460 --> 02:08:47.580]   Because Bravo's a step up.
[02:08:47.580 --> 02:08:48.740]   No, I want to be very clear.
[02:08:48.740 --> 02:08:50.020]   Bravo's a step up.
[02:08:50.020 --> 02:08:54.020]   Bravo, like, spins away more money on reality, 100%.
[02:08:54.020 --> 02:08:56.420]   Discovery is low on the totem pole, right?
[02:08:56.420 --> 02:09:01.380]   But they also have the ship and Joanna Gaines stuff.
[02:09:01.380 --> 02:09:01.900]   And a lot of the--
[02:09:01.900 --> 02:09:06.660]   So here's the slides that David Zazlov showed explaining
[02:09:06.660 --> 02:09:09.940]   why these are unique and complementary properties.
[02:09:09.940 --> 02:09:12.380]   HBO Max, he said, has a male skew.
[02:09:12.380 --> 02:09:14.380]   It's scripted, sure, Game of Thrones.
[02:09:14.380 --> 02:09:15.340]   It's lean in.
[02:09:15.340 --> 02:09:16.980]   It's appointment viewing.
[02:09:16.980 --> 02:09:18.620]   It's the home of fandoms.
[02:09:18.620 --> 02:09:20.100]   Yeah, I think that's true.
[02:09:20.100 --> 02:09:23.940]   Discovery Plus, female skew, unscripted,
[02:09:23.940 --> 02:09:28.620]   lean back, comfort viewing, the home of genre doms.
[02:09:28.620 --> 02:09:29.900]   Does that seem fair?
[02:09:29.900 --> 02:09:31.100]   It seems to me if those--
[02:09:31.100 --> 02:09:33.460]   these are so antithetical, you don't
[02:09:33.460 --> 02:09:36.380]   want to combine them into one's service.
[02:09:36.380 --> 02:09:37.580]   I mean, I don't know.
[02:09:37.580 --> 02:09:41.540]   I'm probably the rare person who enjoys the absolute trash.
[02:09:41.540 --> 02:09:43.300]   And let's be very clear, it is absolute trash.
[02:09:43.300 --> 02:09:44.860]   I'm the 90 day fiancee in the universe.
[02:09:44.860 --> 02:09:45.460]   I'm with you.
[02:09:45.460 --> 02:09:49.140]   And in the press TV, I love them both.
[02:09:49.140 --> 02:09:50.500]   So I'm actually excited to not have
[02:09:50.500 --> 02:09:52.980]   to pay for them both, to be honest with you.
[02:09:52.980 --> 02:09:54.140]   No, I'm with you, Tristan.
[02:09:54.140 --> 02:09:55.700]   I'll take all the trashy shows.
[02:09:55.700 --> 02:09:57.500]   I just want my brain to melt.
[02:09:57.500 --> 02:09:59.540]   If I'm watching something, I don't want to have to think.
[02:09:59.540 --> 02:10:00.060]   Right.
[02:10:00.060 --> 02:10:02.380]   I just want my brain to melt.
[02:10:02.380 --> 02:10:03.380]   Which is, I have to say--
[02:10:03.380 --> 02:10:05.340]   --the trashiest.
[02:10:05.340 --> 02:10:07.060]   And that is honestly what Discovery is great for.
[02:10:07.060 --> 02:10:09.940]   And they've made a ridiculous amount of money off
[02:10:09.940 --> 02:10:11.940]   of the worst stuff imaginable over the years.
[02:10:11.940 --> 02:10:14.580]   And whereas HBO was high rail.
[02:10:14.580 --> 02:10:17.020]   So I don't know if this works or not.
[02:10:17.020 --> 02:10:19.300]   But certainly, if you have them in different tabs,
[02:10:19.300 --> 02:10:20.620]   and if you're not advertised--
[02:10:20.620 --> 02:10:21.980]   if you're not promoting, and I'm sure
[02:10:21.980 --> 02:10:24.100]   that they would not want to do this because their algo would
[02:10:24.100 --> 02:10:27.060]   be smarter than that, as long as you're not recommending
[02:10:27.060 --> 02:10:29.900]   certain content that the people who only want Game of Thrones
[02:10:29.900 --> 02:10:35.320]   or Sopranos reruns, it probably does make sense.
[02:10:35.320 --> 02:10:38.760]   At least for families who have people with different tastes,
[02:10:38.760 --> 02:10:39.480]   watching something.
[02:10:39.480 --> 02:10:41.260]   I don't know.
[02:10:41.260 --> 02:10:44.840]   I mean, it sounds like you're replacing one brain
[02:10:44.840 --> 02:10:45.680]   fry for another.
[02:10:45.680 --> 02:10:48.960]   You would rather watch 90-day fiance,
[02:10:48.960 --> 02:10:51.080]   get your brain mushed that way than trying
[02:10:51.080 --> 02:10:54.640]   to figure out what streaming service it's on.
[02:10:54.640 --> 02:10:55.680]   Right.
[02:10:55.680 --> 02:10:57.400]   There's just way too many.
[02:10:57.400 --> 02:11:01.960]   We can only-- people, especially now, when we're dealing
[02:11:01.960 --> 02:11:03.200]   with what are we going to be buying?
[02:11:03.200 --> 02:11:04.600]   Where are we going to be spending money?
[02:11:04.600 --> 02:11:06.000]   And we don't have as much.
[02:11:06.000 --> 02:11:07.400]   You just can't buy all of them.
[02:11:07.400 --> 02:11:10.280]   And because they're all splintered off, people
[02:11:10.280 --> 02:11:14.800]   like choose to buy something for a month, binge it, record it,
[02:11:14.800 --> 02:11:15.360]   and they're done.
[02:11:15.360 --> 02:11:16.120]   That keeps them subscribed.
[02:11:16.120 --> 02:11:17.200]   And then go to the next one.
[02:11:17.200 --> 02:11:19.160]   It keeps the worst cable.
[02:11:19.160 --> 02:11:21.760]   It's basically taken the worst aspects of cable
[02:11:21.760 --> 02:11:25.480]   and made it part of the streaming dichotomy.
[02:11:25.480 --> 02:11:28.600]   If I'm sitting down on a Sunday night to watch Game of Thrones
[02:11:28.600 --> 02:11:32.720]   and I get 90-day fiance, I may not be--
[02:11:32.720 --> 02:11:33.960]   You can do both.
[02:11:33.960 --> 02:11:35.240]   What if you can do both?
[02:11:35.240 --> 02:11:36.520]   You can watch Game of Thrones.
[02:11:36.520 --> 02:11:40.200]   And then you can watch 90-day fiance as well.
[02:11:40.200 --> 02:11:41.000]   Right.
[02:11:41.000 --> 02:11:43.000]   You can enjoy love after lock up and euphoria.
[02:11:43.000 --> 02:11:45.320]   I think there's a lot of couples that
[02:11:45.320 --> 02:11:47.440]   are going to be causing some real friction
[02:11:47.440 --> 02:11:52.640]   in many households where she wants to watch 90-day fiance.
[02:11:52.640 --> 02:11:54.880]   I want to watch Game of Thrones.
[02:11:54.880 --> 02:11:57.200]   And they're both-- I mean, this is not--
[02:11:57.200 --> 02:11:58.840]   or do you think, well, we'll both agree.
[02:11:58.840 --> 02:12:03.800]   Let's buy-- we should definitely buy HBO disco max.
[02:12:03.800 --> 02:12:04.880]   It's very confusing.
[02:12:04.880 --> 02:12:05.640]   I don't know.
[02:12:05.640 --> 02:12:06.160]   We'll see.
[02:12:06.160 --> 02:12:07.680]   Look, he's trying stuff.
[02:12:07.680 --> 02:12:10.320]   I'm not a David Zazlev fan, I've got to say.
[02:12:10.320 --> 02:12:11.040]   He's smart.
[02:12:11.040 --> 02:12:11.760]   He's smart.
[02:12:11.760 --> 02:12:13.200]   I mean, when I commented--
[02:12:13.200 --> 02:12:13.920]   He's cynical.
[02:12:13.920 --> 02:12:14.440]   He's green.
[02:12:14.440 --> 02:12:15.280]   He is cynical.
[02:12:15.280 --> 02:12:16.600]   Here's the interesting thing, though.
[02:12:16.600 --> 02:12:17.680]   I've never seen this before.
[02:12:17.680 --> 02:12:20.560]   I've never seen someone-- a company
[02:12:20.560 --> 02:12:24.280]   who came and who bought, obviously, like Warner Brothers
[02:12:24.280 --> 02:12:28.840]   from and turn all that apart from Warner Media
[02:12:28.840 --> 02:12:33.040]   basically then go around and undo every major decision
[02:12:33.040 --> 02:12:34.120]   that the previous owners--
[02:12:34.120 --> 02:12:35.240]   Oh, he did, too.
[02:12:35.240 --> 02:12:35.760]   Yeah.
[02:12:35.760 --> 02:12:36.400]   Instantly.
[02:12:36.400 --> 02:12:39.160]   This entire thing has been nothing but a referendum
[02:12:39.160 --> 02:12:42.720]   on John Stanky, who's CEO of AT&T and Jason Keelar,
[02:12:42.720 --> 02:12:45.400]   who he put in charge of Warner Media.
[02:12:45.400 --> 02:12:48.880]   Literally every decision that they've made from the name HBO
[02:12:48.880 --> 02:12:51.280]   Max, which, look, I think it's a great service.
[02:12:51.280 --> 02:12:52.280]   It's my favorite service.
[02:12:52.280 --> 02:12:54.720]   I think we can all agree the name is terrible,
[02:12:54.720 --> 02:12:57.880]   to the day-in-date theater thing, to CNN+
[02:12:57.880 --> 02:13:00.680]   to all these other kinds of decisions going in--
[02:13:00.680 --> 02:13:03.000]   But HBO Max was already diluted.
[02:13:03.000 --> 02:13:06.320]   Like, it took HBO, which is very clear.
[02:13:06.320 --> 02:13:09.040]   And then they added a bunch of stuff that isn't HBO.
[02:13:09.040 --> 02:13:09.600]   Exactly.
[02:13:09.600 --> 02:13:10.400]   And now they're--
[02:13:10.400 --> 02:13:11.640]   Look what they say.
[02:13:11.640 --> 02:13:15.560]   The top franchises are-- this is another Zazlov slide.
[02:13:15.560 --> 02:13:19.960]   HBO discovery, CNN, HGTV, CN, DC, Looney Tunes.
[02:13:19.960 --> 02:13:21.240]   What are the franchises?
[02:13:21.240 --> 02:13:22.760]   You got Batman.
[02:13:22.760 --> 02:13:23.840]   You got-- what's that?
[02:13:23.840 --> 02:13:24.960]   Wrestling or Wonder Woman?
[02:13:24.960 --> 02:13:26.240]   I think Wonder Woman is Wonder Woman.
[02:13:26.240 --> 02:13:29.000]   I confuse this with the WWE.
[02:13:29.000 --> 02:13:30.240]   logo, Superman.
[02:13:30.240 --> 02:13:32.040]   Then there's Shark Week, then there's Game of Thrones.
[02:13:32.040 --> 02:13:34.240]   Then there's 90-day fiance universe--
[02:13:34.240 --> 02:13:34.840]   [LAUGHTER]
[02:13:34.840 --> 02:13:35.920]   --the military Potter.
[02:13:35.920 --> 02:13:38.000]   I like all of this.
[02:13:38.000 --> 02:13:38.520]   OK.
[02:13:38.520 --> 02:13:38.720]   Same.
[02:13:38.720 --> 02:13:40.400]   I was going to say, I'm into all of it.
[02:13:40.400 --> 02:13:41.000]   I'm all in.
[02:13:41.000 --> 02:13:41.600]   A bra?
[02:13:41.600 --> 02:13:42.640]   What about you?
[02:13:42.640 --> 02:13:44.360]   OK, well, I think the only thing--
[02:13:44.360 --> 02:13:46.320]   I've never heard someone say, hey,
[02:13:46.320 --> 02:13:48.640]   do you have a Discovery+ account so I can use your password?
[02:13:48.640 --> 02:13:49.240]   You're dead on.
[02:13:49.240 --> 02:13:50.040]   Like, you're dead on it.
[02:13:50.040 --> 02:13:51.040]   Absolutely.
[02:13:51.040 --> 02:13:52.040]   Yeah.
[02:13:52.040 --> 02:13:53.040]   Absolutely.
[02:13:53.040 --> 02:13:54.520]   I only have it because it's free.
[02:13:54.520 --> 02:13:56.440]   I only have it because I get it for free with my--
[02:13:56.440 --> 02:13:56.440]   Right.
[02:13:56.440 --> 02:13:57.600]   --for my Broadway account, to be honest.
[02:13:57.600 --> 02:13:58.520]   Yeah.
[02:13:58.520 --> 02:14:00.720]   And that's the only way I've almost been tempted to get it
[02:14:00.720 --> 02:14:02.840]   is because I also have it for you through a Verizon account.
[02:14:02.840 --> 02:14:06.520]   But yeah, HBO Max is one of those platforms where it's like,
[02:14:06.520 --> 02:14:07.480]   I got somebody's password.
[02:14:07.480 --> 02:14:08.520]   I'm all set.
[02:14:08.520 --> 02:14:09.040]   Right.
[02:14:09.040 --> 02:14:11.640]   Because as we discuss, there are too many streaming platforms.
[02:14:11.640 --> 02:14:13.840]   And so everyone's just borrowing passwords,
[02:14:13.840 --> 02:14:16.000]   which is why Netflix is now trying to crack down on that
[02:14:16.000 --> 02:14:18.040]   and make people pay if they share their passwords.
[02:14:18.040 --> 02:14:20.600]   But yeah, I think this is a good way
[02:14:20.600 --> 02:14:26.360]   to force people to watch the shows that are on Discovery+
[02:14:26.360 --> 02:14:27.720]   because it's like right there.
[02:14:27.720 --> 02:14:30.200]   I deeply regret getting Peacock
[02:14:30.200 --> 02:14:34.240]   because then we discovered the Below Deck.
[02:14:34.240 --> 02:14:35.440]   Reality, transition.
[02:14:35.440 --> 02:14:39.960]   I was going to say, again, this is higher quality,
[02:14:39.960 --> 02:14:43.920]   the Below Deck, which is kind of part of the Vanderpump rules,
[02:14:43.920 --> 02:14:46.960]   Roni kind of whole universe.
[02:14:46.960 --> 02:14:47.480]   Yeah, I agree.
[02:14:47.480 --> 02:14:50.400]   It's terrible, but it's better than the quality of every stuff.
[02:14:50.400 --> 02:14:54.360]   Lisa's saying, we used to get two Below decks a week.
[02:14:54.360 --> 02:14:57.840]   There was Below Deck down under and Below Deck demand.
[02:14:57.840 --> 02:15:00.000]   And now we only get one Below Deck a week.
[02:15:00.000 --> 02:15:04.000]   She was upset that there isn't more Below Deck, but good news.
[02:15:04.000 --> 02:15:05.920]   There's like going to be two more Below Deck.
[02:15:05.920 --> 02:15:06.600]   Oh, yeah.
[02:15:06.600 --> 02:15:08.520]   The whole premise of this, if you're smart
[02:15:08.520 --> 02:15:09.920]   and you'd have never heard of this thing,
[02:15:09.920 --> 02:15:12.840]   is it is kind of the upstairs downstairs
[02:15:12.840 --> 02:15:15.160]   for the giant mega-yacht set.
[02:15:15.160 --> 02:15:17.320]   So you're following these poor people
[02:15:17.320 --> 02:15:19.200]   who live in these little tiny cabins
[02:15:19.200 --> 02:15:21.040]   and they're right on top of each other
[02:15:21.040 --> 02:15:23.760]   as they serve the most entitled, awful people
[02:15:23.760 --> 02:15:26.640]   in the world above decks on these super yachts.
[02:15:26.640 --> 02:15:30.280]   And then the drama that ensues.
[02:15:30.280 --> 02:15:33.440]   And what's hysterical is it's a reality show
[02:15:33.440 --> 02:15:35.640]   where the camera people, the producers,
[02:15:35.640 --> 02:15:37.120]   they're a-all on the yacht.
[02:15:37.120 --> 02:15:39.760]   They're all like, cheek by jowl.
[02:15:39.760 --> 02:15:44.520]   Everybody's jammed in together and they can't get off.
[02:15:44.520 --> 02:15:46.720]   It's actually a great idea for a shit-all.
[02:15:46.720 --> 02:15:47.720]   Honestly.
[02:15:47.720 --> 02:15:48.640]   I know.
[02:15:48.640 --> 02:15:50.520]   It's honestly very watchable.
[02:15:50.520 --> 02:15:52.560]   I enjoy the whole Bravo universe.
[02:15:52.560 --> 02:15:54.000]   I'm so embarrassed we have watched.
[02:15:54.000 --> 02:15:55.000]   And how I'm very serious, Mark.
[02:15:55.000 --> 02:15:56.800]   It started, I was looking for something
[02:15:56.800 --> 02:15:58.680]   'cause we couldn't travel in pandemic.
[02:15:58.680 --> 02:16:00.880]   And I thought, oh good, we'll get to see
[02:16:00.880 --> 02:16:04.520]   beautiful sunsets in the Caribbean or whatever.
[02:16:04.520 --> 02:16:07.000]   And we have now watched literally every single
[02:16:07.000 --> 02:16:08.120]   Below Deck show.
[02:16:08.120 --> 02:16:10.400]   We went all the way back, all the way forward
[02:16:10.400 --> 02:16:12.520]   with hundreds of hours.
[02:16:12.520 --> 02:16:13.360]   I love it.
[02:16:13.360 --> 02:16:15.120]   Lost to that freak show.
[02:16:15.120 --> 02:16:16.600]   Lost though, I think it's worth it.
[02:16:16.600 --> 02:16:17.960]   It seems like you-
[02:16:17.960 --> 02:16:19.360]   I shouldn't feel guilty.
[02:16:19.360 --> 02:16:20.960]   You're saying I shouldn't feel guilty?
[02:16:20.960 --> 02:16:23.040]   That's the basic time you've summarized it.
[02:16:23.040 --> 02:16:23.880]   Bless you.
[02:16:23.880 --> 02:16:24.720]   Yeah.
[02:16:24.720 --> 02:16:25.720]   I mean, it's not better than it is.
[02:16:25.720 --> 02:16:26.720]   It's the construction, right?
[02:16:26.720 --> 02:16:29.240]   You need to have some stuff, especially
[02:16:29.240 --> 02:16:32.680]   when you're with public, you have to always be on camera
[02:16:32.680 --> 02:16:34.040]   dealing with people.
[02:16:34.040 --> 02:16:36.120]   It's really nice to just have something
[02:16:36.120 --> 02:16:37.840]   where you don't have to fix, deal with it,
[02:16:37.840 --> 02:16:39.480]   and you can just enjoy it like candy.
[02:16:39.480 --> 02:16:40.320]   It's like rain.
[02:16:40.320 --> 02:16:41.160]   Exactly.
[02:16:41.160 --> 02:16:42.000]   The guys are great.
[02:16:42.000 --> 02:16:43.200]   And it's just on the background.
[02:16:43.200 --> 02:16:44.640]   I mean, I will say he's right.
[02:16:44.640 --> 02:16:46.680]   It is lean back stuff 'cause you're not paying attention.
[02:16:46.680 --> 02:16:47.520]   No.
[02:16:47.520 --> 02:16:48.960]   No, I got my phone open.
[02:16:48.960 --> 02:16:49.960]   I got my iPad open.
[02:16:49.960 --> 02:16:51.560]   I got my laptop.
[02:16:51.560 --> 02:16:52.400]   I'm playing the world.
[02:16:52.400 --> 02:16:53.240]   It's very relaxing.
[02:16:53.240 --> 02:16:54.080]   Yeah, right.
[02:16:54.080 --> 02:16:56.880]   Sometimes, you know, the shows as much as we're like TV
[02:16:56.880 --> 02:16:57.720]   and it's great.
[02:16:57.720 --> 02:16:59.800]   You have to pay so much attention to every little thing.
[02:16:59.800 --> 02:17:00.800]   True.
[02:17:00.800 --> 02:17:02.600]   It's like a chore.
[02:17:02.600 --> 02:17:04.600]   It is not a chore to watch "Blo Deck."
[02:17:04.600 --> 02:17:06.120]   Like, you know?
[02:17:06.120 --> 02:17:07.760]   It's not a chore.
[02:17:07.760 --> 02:17:11.600]   Sandy Yawn, Captain Sandy, is coming to Santa Rosa
[02:17:11.600 --> 02:17:13.320]   in a couple of months.
[02:17:13.320 --> 02:17:15.600]   And Lisa says we're getting tickets, right?
[02:17:15.600 --> 02:17:19.760]   I say to see the yacht, Captain, what is she going to talk about?
[02:17:19.760 --> 02:17:21.000]   Swabbing the poop deck.
[02:17:21.000 --> 02:17:23.400]   I don't know, but we're going to go see her, I guess.
[02:17:24.400 --> 02:17:26.400]   That'd be a great trip.
[02:17:26.400 --> 02:17:28.680]   You have to be stuck in the show.
[02:17:28.680 --> 02:17:29.680]   You are now below deck.
[02:17:29.680 --> 02:17:31.880]   They'd like you'd pay all this money.
[02:17:31.880 --> 02:17:32.880]   They wouldn't make all this money.
[02:17:32.880 --> 02:17:33.880]   They won't let you out.
[02:17:33.880 --> 02:17:34.880]   They're stuck there.
[02:17:34.880 --> 02:17:37.160]   Oh my God, isn't that the Star Wars experience?
[02:17:37.160 --> 02:17:38.920]   Yeah, you're the hotel.
[02:17:38.920 --> 02:17:39.920]   You can't leave.
[02:17:39.920 --> 02:17:41.760]   It's the hotel, like, where you spend all that money
[02:17:41.760 --> 02:17:45.680]   for the terrible hotel room and then you're part of the cosplay thing.
[02:17:45.680 --> 02:17:47.680]   That's basically what they've done.
[02:17:47.680 --> 02:17:50.280]   Bravo, because there's a Bravo con, they should totally do that.
[02:17:50.280 --> 02:17:52.440]   They could auction off in a below deck experience
[02:17:52.440 --> 02:17:53.800]   and they could make so much money.
[02:17:53.800 --> 02:17:54.800]   I'm not even joking.
[02:17:54.800 --> 02:17:59.480]   I wouldn't pay for it because I like my space too much, but I would.
[02:17:59.480 --> 02:18:04.240]   There'd be so many people who would pay for a below deck experience.
[02:18:04.240 --> 02:18:08.880]   The best part is, you know, you're always trying to figure out, well, who of the crew
[02:18:08.880 --> 02:18:10.040]   is going to hook up?
[02:18:10.040 --> 02:18:11.520]   Because that's like the whole show.
[02:18:11.520 --> 02:18:12.840]   That's the whole point of the show, yeah.
[02:18:12.840 --> 02:18:14.640]   The whole point of the show, who's going to hook up?
[02:18:14.640 --> 02:18:16.680]   And they never do because there's cameras everywhere.
[02:18:16.680 --> 02:18:18.760]   There's no more private at all.
[02:18:18.760 --> 02:18:23.920]   But then the guests on these shows are the worst people.
[02:18:23.920 --> 02:18:25.000]   They've actually gotten a little better.
[02:18:25.000 --> 02:18:28.400]   I think they must have gotten some notes from people saying, don't make them so horrible
[02:18:28.400 --> 02:18:29.400]   or something.
[02:18:29.400 --> 02:18:33.680]   Or maybe they've watched the show and they now know it's going to be permanent record.
[02:18:33.680 --> 02:18:35.000]   But they're nicer than they used to be.
[02:18:35.000 --> 02:18:36.240]   They used to be.
[02:18:36.240 --> 02:18:41.160]   Like they had the woman who was the queen of Versailles, you know, that documentary about
[02:18:41.160 --> 02:18:45.480]   the woman who married the 800-year-old timeshare magnet.
[02:18:45.480 --> 02:18:49.720]   She had a little dog's poop all over the house because she couldn't be bothered to take
[02:18:49.720 --> 02:18:50.800]   him out for a walk.
[02:18:50.800 --> 02:18:52.000]   She gets on the yacht.
[02:18:52.000 --> 02:18:53.160]   That's fun.
[02:18:53.160 --> 02:18:54.160]   That's fun.
[02:18:54.160 --> 02:18:55.160]   All right.
[02:18:55.160 --> 02:18:58.240]   Anyway, I got to get going.
[02:18:58.240 --> 02:18:59.800]   There's a show tonight.
[02:18:59.800 --> 02:19:00.800]   I don't want to miss it.
[02:19:00.800 --> 02:19:02.000]   So here we go.
[02:19:02.000 --> 02:19:03.000]   Beautiful picture.
[02:19:03.000 --> 02:19:06.360]   God, you got to love the James Webb telescope.
[02:19:06.360 --> 02:19:10.120]   This picture of the Proxima Centauri.
[02:19:10.120 --> 02:19:11.120]   Beautiful picture of a galaxy.
[02:19:11.120 --> 02:19:12.120]   No, it's not.
[02:19:12.120 --> 02:19:15.320]   Actually, it's a piece of sausage.
[02:19:15.320 --> 02:19:17.640]   It's incline.
[02:19:17.640 --> 02:19:22.120]   By the way, you might trust he's the research director at France's Alternative Energy and
[02:19:22.120 --> 02:19:25.120]   Atomic Energy Commission.
[02:19:25.120 --> 02:19:29.760]   Tweeted this photo last week saying it's the closest star to his son.
[02:19:29.760 --> 02:19:30.760]   Look at it.
[02:19:30.760 --> 02:19:35.600]   It's beautiful from the James Webb Space Telescope.
[02:19:35.600 --> 02:19:39.520]   Lots of people tweeted it, retweeted it, liked it.
[02:19:39.520 --> 02:19:41.240]   The level of detail he wrote.
[02:19:41.240 --> 02:19:44.880]   A new world is revealed day after day.
[02:19:44.880 --> 02:19:46.760]   And you can't do it, man.
[02:19:46.760 --> 02:19:51.000]   A few days later, it's not in fact the work of the world's most powerful space telescope.
[02:19:51.000 --> 02:19:55.960]   It is a slice of chorizo sausage.
[02:19:55.960 --> 02:20:01.760]   And then apologizes saying according to contemporary cosmology, no object belonging
[02:20:01.760 --> 02:20:07.280]   to Spanish charcuterie exists anywhere but on Earth.
[02:20:07.280 --> 02:20:08.880]   Lots of people pissed off.
[02:20:08.880 --> 02:20:16.160]   At the end, we're trolling the world of the piece of Spanish sausage.
[02:20:16.160 --> 02:20:19.880]   It's so telling that it does kind of look like you could have been from the G.
[02:20:19.880 --> 02:20:22.600]   I really did actually believe it when I first saw it.
[02:20:22.600 --> 02:20:24.600]   I fooled you, didn't I?
[02:20:24.600 --> 02:20:27.600]   I was like, oh, and then, yeah.
[02:20:27.600 --> 02:20:28.600]   Same.
[02:20:28.600 --> 02:20:29.600]   Same.
[02:20:29.600 --> 02:20:35.000]   And then you look at it more closely and you're like, oh, no, this cup runny.
[02:20:35.000 --> 02:20:38.840]   What I love too is like, this is just hilarious because I don't know if you guys are very
[02:20:38.840 --> 02:20:39.840]   interested on TikTok.
[02:20:39.840 --> 02:20:42.960]   A lot of people have been like, okay, you're showing me all these pictures.
[02:20:42.960 --> 02:20:43.960]   I don't fully understand.
[02:20:43.960 --> 02:20:45.440]   Like, am I supposed to be excited?
[02:20:45.440 --> 02:20:46.440]   It's like super colorful to bright.
[02:20:46.440 --> 02:20:47.920]   I think you have one side.
[02:20:47.920 --> 02:20:50.440]   You have like the people who are really into science where like, this is amazing.
[02:20:50.440 --> 02:20:53.040]   And then you have the other side that's like, okay, what now?
[02:20:53.040 --> 02:20:54.040]   And then you have this.
[02:20:54.040 --> 02:20:55.040]   And then there's something.
[02:20:55.040 --> 02:20:56.040]   Yeah.
[02:20:56.040 --> 02:20:58.160]   We're like, oh, I guess I'm supposed to be excited about this.
[02:20:58.160 --> 02:20:59.160]   And then, yeah.
[02:20:59.160 --> 02:21:00.160]   I love it.
[02:21:00.160 --> 02:21:01.160]   I love it.
[02:21:01.160 --> 02:21:02.160]   I love it.
[02:21:02.160 --> 02:21:06.080]   People, the academics of us down a little bit to be like, okay, like just, you know, hold
[02:21:06.080 --> 02:21:11.080]   off on your high horse, even you got it.
[02:21:11.080 --> 02:21:13.440]   It's tastier than it is really scientific.
[02:21:13.440 --> 02:21:20.480]   So this is one, one galaxy that will taste great with your scrambled eggs.
[02:21:20.480 --> 02:21:21.800]   Thank you so much, Abra.
[02:21:21.800 --> 02:21:22.960]   I hope you will come back.
[02:21:22.960 --> 02:21:23.960]   Abra al-Hidi.
[02:21:23.960 --> 02:21:26.200]   Wonderful to have you your first time on Twit.
[02:21:26.200 --> 02:21:27.200]   Was it okay?
[02:21:27.200 --> 02:21:28.400]   It was so much fun.
[02:21:28.400 --> 02:21:29.800]   Thank you so much for having me.
[02:21:29.800 --> 02:21:30.800]   Good.
[02:21:30.800 --> 02:21:31.800]   I'm glad you were here.
[02:21:31.800 --> 02:21:32.800]   Video host producer at CNET.
[02:21:32.800 --> 02:21:36.040]   She'll be up early on Wednesday morning.
[02:21:36.040 --> 02:21:40.200]   During Samsung's Galaxy Unplugged event.
[02:21:40.200 --> 02:21:41.200]   Thank you so much.
[02:21:41.200 --> 02:21:42.200]   I look forward to it.
[02:21:42.200 --> 02:21:43.200]   I really appreciate it.
[02:21:43.200 --> 02:21:44.200]   You're being fun.
[02:21:44.200 --> 02:21:45.200]   Thank you so much.
[02:21:45.200 --> 02:21:46.200]   Thank you for having me.
[02:21:46.200 --> 02:21:47.200]   Thank you for having me.
[02:21:47.200 --> 02:21:48.200]   You're so good.
[02:21:48.200 --> 02:21:49.200]   I forgot about the bent blind.
[02:21:49.200 --> 02:21:50.200]   Oh, good.
[02:21:50.200 --> 02:21:51.200]   See?
[02:21:51.200 --> 02:21:52.200]   Okay, good.
[02:21:52.200 --> 02:21:53.200]   That's a huge compliment.
[02:21:53.200 --> 02:21:54.200]   Yeah.
[02:21:54.200 --> 02:21:55.200]   Yeah.
[02:21:55.200 --> 02:21:56.200]   I just didn't even notice after a while.
[02:21:56.200 --> 02:21:57.200]   I'll carry that in my heart.
[02:21:57.200 --> 02:21:58.200]   Thank you.
[02:21:58.200 --> 02:21:59.200]   Always a pleasure to have you on Christina Warren.
[02:21:59.200 --> 02:22:01.120]   Congratulations on four months now at GitHub Senior Dev Advocate.
[02:22:01.120 --> 02:22:04.840]   Some days soon she'll get the right pump back.
[02:22:04.840 --> 02:22:11.400]   Some girl on Twitter, what's the most valuable shoe in that rack behind you?
[02:22:11.400 --> 02:22:13.400]   Some of those kicks are worth hundreds, yes?
[02:22:13.400 --> 02:22:15.880]   Some of them are, yeah.
[02:22:15.880 --> 02:22:17.520]   Are you out of that now?
[02:22:17.520 --> 02:22:19.320]   Is that another project you moved on from?
[02:22:19.320 --> 02:22:21.000]   Yeah, I've kind of moved on from that a little bit.
[02:22:21.000 --> 02:22:22.000]   I'm not as into it.
[02:22:22.000 --> 02:22:27.480]   I have, there's a pair of off-whites that are not on the rack that they're in a box that's
[02:22:27.480 --> 02:22:28.960]   up there that are the most valuable.
[02:22:28.960 --> 02:22:29.960]   Silled in the box.
[02:22:29.960 --> 02:22:32.800]   No, I mean, they're just still in the box.
[02:22:32.800 --> 02:22:33.880]   They just aren't on display.
[02:22:33.880 --> 02:22:36.240]   I wear shoes, I don't do that whole thing.
[02:22:36.240 --> 02:22:42.080]   But I have a pair of off-whites that are probably $600.
[02:22:42.080 --> 02:22:46.280]   That's not the most I've spent on shoes, but that's probably the most expensive on-
[02:22:46.280 --> 02:22:47.380]   Differentes.
[02:22:47.380 --> 02:22:48.580]   These are not manolos.
[02:22:48.580 --> 02:22:49.680]   These are comfortable.
[02:22:49.680 --> 02:22:51.840]   You can wear them, you can enjoy them.
[02:22:51.840 --> 02:22:56.680]   Well, in its street style, I mean, there's other stuff with it too, but yeah, totally.
[02:22:56.680 --> 02:22:57.760]   I love it.
[02:22:57.760 --> 02:22:58.920]   Thank you, Christina.
[02:22:58.920 --> 02:23:00.280]   So good to see you.
[02:23:00.280 --> 02:23:01.600]   Thank you, Georgia Dow.
[02:23:01.600 --> 02:23:06.560]   As always, Georgia gives out her email address for anybody who's struggling during these
[02:23:06.560 --> 02:23:11.320]   difficult times, Georgia@Westmounttherapy.com.
[02:23:11.320 --> 02:23:12.400]   Thank you for doing that, Georgia.
[02:23:12.400 --> 02:23:14.640]   I appreciate it.
[02:23:14.640 --> 02:23:21.440]   And if you have not watched Therapist Reacts in the other videos she does at youtube.com/georgiadow,
[02:23:21.440 --> 02:23:23.080]   you are missing.
[02:23:23.080 --> 02:23:27.800]   This is, this adds, in fact, you need to do a below-deck Therapist Reacts.
[02:23:27.800 --> 02:23:32.440]   These adds to the enjoyment of trash TV.
[02:23:32.440 --> 02:23:34.840]   I did the Will Smith Apollo.
[02:23:34.840 --> 02:23:36.640]   That was the first real person.
[02:23:36.640 --> 02:23:37.640]   Oh, wow.
[02:23:37.640 --> 02:23:39.640]   I did do that one.
[02:23:39.640 --> 02:23:40.640]   Oh, wow.
[02:23:40.640 --> 02:23:44.320]   If the first time I've done that, it actually did really well in comparison to the toxic
[02:23:44.320 --> 02:23:48.780]   Max Luke did really well the toxic masculinity, but I thought you can go take a look at the
[02:23:48.780 --> 02:23:53.040]   comments for your entertainment value.
[02:23:53.040 --> 02:24:00.040]   I am very curious what you have to say about Will Smith's faux apology to Chris Rock for
[02:24:00.040 --> 02:24:01.520]   slapping him.
[02:24:01.520 --> 02:24:03.960]   I had a few thoughts about it.
[02:24:03.960 --> 02:24:05.920]   I have two thoughts about it and I enjoy doing it.
[02:24:05.920 --> 02:24:10.920]   So I might do it on the TV, but I like doing the character stuff and I don't know.
[02:24:10.920 --> 02:24:13.960]   I'm going to take a look and see where it's at.
[02:24:13.960 --> 02:24:16.320]   But yeah, O'Nore's coming up.
[02:24:16.320 --> 02:24:21.800]   Toxic masculinity from Soldier Boy was the last one.
[02:24:21.800 --> 02:24:23.720]   You can just check out the comments.
[02:24:23.720 --> 02:24:25.400]   Your comments are always great.
[02:24:25.400 --> 02:24:29.560]   Like this one on the Will Smith apology guy has an Oscar and can't even act like he's
[02:24:29.560 --> 02:24:30.560]   sorry.
[02:24:30.560 --> 02:24:32.200]   I love that.
[02:24:32.200 --> 02:24:37.160]   As you know, you've done something I thought no one can do.
[02:24:37.160 --> 02:24:40.080]   You've actually made YouTube comments good.
[02:24:40.080 --> 02:24:47.200]   So everybody Georgia Dow is at youtube.com/gergidow.
[02:24:47.200 --> 02:24:48.400]   So great to have you.
[02:24:48.400 --> 02:24:50.720]   Thanks once again.
[02:24:50.720 --> 02:24:52.360]   Thanks to all of you for joining us.
[02:24:52.360 --> 02:24:57.360]   We do Twitch every Sunday afternoon, 2pm Pacific, 5pm Eastern.
[02:24:57.360 --> 02:24:59.000]   That's 2100 UTC.
[02:24:59.000 --> 02:25:00.640]   That's when we kind of start assembling.
[02:25:00.640 --> 02:25:03.600]   So usually begins by half past.
[02:25:03.600 --> 02:25:09.320]   You can watch the pre-show and the conversations and the chit chat and the show itself live
[02:25:09.320 --> 02:25:11.960]   during our live stream live.twit.tv.
[02:25:11.960 --> 02:25:13.040]   There's audio and video there.
[02:25:13.040 --> 02:25:15.440]   If you're watching live, join the chat room.
[02:25:15.440 --> 02:25:20.560]   They're there 24/7, but it's most active while we're live during shows and I'm watching
[02:25:20.560 --> 02:25:23.440]   and we always get great interaction from our IRC.
[02:25:23.440 --> 02:25:26.040]   It's IRC.twit.tv.
[02:25:26.040 --> 02:25:30.840]   We also have a Discord chat, which is always a lot of fun.
[02:25:30.840 --> 02:25:37.200]   These are members of Club Twit.
[02:25:37.200 --> 02:25:41.840]   And the animated gifs just keep on coming.
[02:25:41.840 --> 02:25:48.280]   If you are not in a member of Club Twit, $7 a month gets you ad free versions of all
[02:25:48.280 --> 02:25:49.680]   of our shows.
[02:25:49.680 --> 02:25:53.240]   It gets you the access to the Discord, which is more than just conversations about the
[02:25:53.240 --> 02:25:54.240]   shows.
[02:25:54.240 --> 02:25:57.520]   There's every geek topic under the sun, including our book club.
[02:25:57.520 --> 02:26:01.360]   This month Stacey's book club will be Clara and the sun.
[02:26:01.360 --> 02:26:03.800]   We're going to do that August 25th.
[02:26:03.800 --> 02:26:07.360]   We're about a week away from Alex Lindsey's Ask Me Anything.
[02:26:07.360 --> 02:26:08.880]   That'll be on the 18th.
[02:26:08.880 --> 02:26:10.240]   So we've got club events.
[02:26:10.240 --> 02:26:14.360]   We have shows that actually do not get released outside the club.
[02:26:14.360 --> 02:26:18.280]   Our new hands on windows show with Paul Therat is an example.
[02:26:18.280 --> 02:26:20.520]   There's the untitled Linux show.
[02:26:20.520 --> 02:26:23.480]   There's the Gizfiz, the book club.
[02:26:23.480 --> 02:26:29.200]   And then shows often when they're successful, it's kind of an incubator because the club
[02:26:29.200 --> 02:26:31.880]   members are paying to support the shows.
[02:26:31.880 --> 02:26:34.520]   We don't have to worry about audience size and advertisers.
[02:26:34.520 --> 02:26:39.760]   But then when a show takes off like this, we can release it to the public.
[02:26:39.760 --> 02:26:43.240]   So that's one of the best benefits of Club Twit.
[02:26:43.240 --> 02:26:47.040]   All the shows also can be bought individually, by the way, at $2.99 a month.
[02:26:47.040 --> 02:26:48.880]   But I think the $7 a month is worth it.
[02:26:48.880 --> 02:26:55.160]   You also get the Twit Plus feed, which includes stuff that didn't make it to the podcasts.
[02:26:55.160 --> 02:26:57.800]   If you're interested in joining, please, we appreciate it.
[02:26:57.800 --> 02:27:00.120]   It really helps us out.
[02:27:00.120 --> 02:27:03.360]   All you have to do is go to twit.tv/clubtwits.
[02:27:03.360 --> 02:27:05.560]   $7 a month is a yearly.
[02:27:05.560 --> 02:27:07.840]   There's also corporate membership.
[02:27:07.840 --> 02:27:11.160]   After the fact, this show and all the shows that are released publicly are available on
[02:27:11.160 --> 02:27:13.400]   our website at twit.tv.
[02:27:13.400 --> 02:27:16.840]   Each show has its own YouTube channel as well, just like Georgia Dow just without any
[02:27:16.840 --> 02:27:18.200]   audience.
[02:27:18.200 --> 02:27:24.320]   We also, without the viewership and the comments, we also have, of course, a podcast feed because
[02:27:24.320 --> 02:27:25.320]   they are podcasts.
[02:27:25.320 --> 02:27:27.640]   And you can get your podcast player and subscribe.
[02:27:27.640 --> 02:27:29.800]   In fact, that's the best way to get to it.
[02:27:29.800 --> 02:27:34.120]   If you subscribe to it, we guarantee you'll have it by your Monday morning commute.
[02:27:34.120 --> 02:27:35.120]   Thanks for being here, everybody.
[02:27:35.120 --> 02:27:36.120]   We'll see you next time.
[02:27:36.120 --> 02:27:38.120]   Another Twit is in the camp.
[02:27:38.120 --> 02:27:50.400]   Easy.

