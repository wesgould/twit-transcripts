;FFMETADATA1
title=Taco Fixins
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=562
genre=Podcast
comment=https://twit.tv/twig
copyright=These podcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.160]   It's time for Twig this weekend. Google. Stacey Egan-Botham's here. Jeff Jarvis is here. We're
[00:00:06.160 --> 00:00:14.960]   going to talk about CES 2021. It's on! But would you go? Facebook employees walk out and then they come
[00:00:14.960 --> 00:00:23.280]   right back and Project Gutenberg banned in Italy. It's all coming up next on Twig. This week at Google
[00:00:23.280 --> 00:00:28.560]   comes to you from Twig's last past studios. Stay in control when it comes to your company's access
[00:00:28.560 --> 00:00:34.880]   points and authentication. LastPass makes enterprise-level security simple for your remote workforce.
[00:00:34.880 --> 00:00:38.400]   Check out lastpass.com/twit to learn more.
[00:00:38.400 --> 00:00:47.280]   Podcasts you love from people you trust. This is Twig.
[00:00:52.000 --> 00:00:59.440]   This is Twig this week in Google. Episode 562 recorded Wednesday, June 3, 2020.
[00:00:59.440 --> 00:01:05.760]   Taco Fixins. This episode of this week in Google is brought to you by LastPass.
[00:01:05.760 --> 00:01:12.000]   Prepare for the unexpected in your business with LastPass. Trusted by over 17 million users
[00:01:12.000 --> 00:01:19.520]   and 61,000 businesses worldwide. Visit lastpass.com/twit to find out how they can help you.
[00:01:20.400 --> 00:01:26.000]   It's time for Twig this week in Google. The show we cover the latest from, I know, we can't say
[00:01:26.000 --> 00:01:31.680]   the Google verse. It's not just Google. The world around us, the technology influenced
[00:01:31.680 --> 00:01:39.040]   internet infused world around us. That's Stacey Higginbotham. Stacey on IOT.com.
[00:01:39.040 --> 00:01:48.800]   Increasingly, the host of online panels discussing... A Plenty. A Plenty. Panels a Plenty. In fact,
[00:01:48.800 --> 00:01:53.280]   next week you're doing a panel. What's the panel about next week? Machine learning at the edge.
[00:01:53.280 --> 00:02:00.800]   It's going to be awesome. I can't wait. Go to Stacey on IOT.com/edge.
[00:02:00.800 --> 00:02:06.880]   And you can sign. It's free. It's an online. It's a Zoom. Is it Zoom? Do you Zoom? No, we're using a
[00:02:06.880 --> 00:02:11.920]   new platform. So this is a really fun platform called Hopin. And there'll be people from John
[00:02:11.920 --> 00:02:20.320]   Deere, Shell, Allegian, Tufts University, lots of places. It's a knowledge sharing platform.
[00:02:20.320 --> 00:02:24.720]   That sounds way fancier than what it is. But sure.
[00:02:24.720 --> 00:02:31.840]   And it's free and you're all invited. And the COVID event that she did a couple of weeks
[00:02:31.840 --> 00:02:38.240]   goes online at Stacey on IOT.com/COVID. So there's a lot of good stuff at Stacey on IOT. Not to
[00:02:38.240 --> 00:02:43.440]   mention this is the IOT podcast she does with Kevin. I was like not to mention me. Not to mention
[00:02:43.440 --> 00:02:48.160]   the wonderful Kevin Dovalent Stacey here at Gotham. On my left ladies and gentlemen,
[00:02:48.160 --> 00:02:53.200]   I give you the town Leonard Towne professor for journalistic innovation at the Craig Newmark.
[00:02:53.200 --> 00:02:57.920]   We're back in two minutes. And she was school journalism at the City University of New York,
[00:02:57.920 --> 00:03:03.040]   Jeff Jarvis. Teaching from home. Are you teaching from home? Have you been in? Teaching from home.
[00:03:03.040 --> 00:03:09.760]   At all? March 10's last day I was like, wow. I'm teaching from home. Today was a big day for me.
[00:03:09.760 --> 00:03:15.360]   Big day. What happened? Not a haircut, obviously. I went to the dentist. Wow.
[00:03:15.360 --> 00:03:20.160]   I went to the dentist on Monday. This is a big outing for me.
[00:03:20.160 --> 00:03:28.560]   I was at the dentist on Monday and it was a totally ancient experience. They were like,
[00:03:28.560 --> 00:03:33.360]   we cannot use any of the things that are aerosol stuff. They're like hands scraping. I was like,
[00:03:33.360 --> 00:03:42.080]   oh, wow. Can you, you know, you need a mask for your nose and eyes. Mouth has to be open.
[00:03:42.080 --> 00:03:48.480]   I don't know. Well, they're more worried about germs. They're they had. They need all the PPE,
[00:03:48.480 --> 00:03:54.880]   of course. Yeah. They're PPE. They're PPE up. I just assume everybody has it.
[00:03:56.400 --> 00:04:00.800]   And then I have it. Oh, for that purpose? Yes. For that purpose. Yeah. I mean, I know everybody
[00:04:00.800 --> 00:04:05.360]   doesn't have it. In fact, it's, you know, I mean, knock on wood. Very few people have it around here,
[00:04:05.360 --> 00:04:11.200]   but that could change any time. I thought you were going to celebrate Jeff Jarvis. Not a visit
[00:04:11.200 --> 00:04:17.760]   to the dentist, but the virtual Chipotle Carstons. Chipotle, what's your mouth out?
[00:04:17.760 --> 00:04:23.040]   Taco Bell. What's your mouth out? Taco Bell. So thanks to Carston, see that bottle of official,
[00:04:23.040 --> 00:04:30.320]   Taco Bell hot sauce right there. I got two of them. Surprise, surprise in the mail
[00:04:30.320 --> 00:04:37.280]   from none other than Carston. And thank you, Carston, for all we jokes. We love each other. And then came
[00:04:37.280 --> 00:04:45.120]   taco seasoning, envelope of taco seasoning. So I have the taste of that picture.
[00:04:45.120 --> 00:04:51.520]   In that picture, it was very good. That picture you see. So I had, I had refried beans and some enchilada
[00:04:51.520 --> 00:04:58.480]   sauce and the hot sauce and the tortillas and the cheese. And I've done it. And then you see the
[00:04:58.480 --> 00:05:02.800]   result of the next picture. You have the next thing as there it is. I'm not very art art.
[00:05:02.800 --> 00:05:07.600]   It's a little lopsided. Did you, did you heat your tortillas before you folded them?
[00:05:07.600 --> 00:05:10.800]   Yeah, it seems not. Doesn't it? No, you think I used the tortilla.
[00:05:10.800 --> 00:05:13.440]   It's a problem. Oh, okay. I'm like,
[00:05:13.440 --> 00:05:21.040]   Stacy Stacy is a native of Texas and probably was not very good. So I'm learning, but I was,
[00:05:21.040 --> 00:05:27.120]   I was happy about the deck in junior high. She, yeah, one oh one. You got to take the burrito class,
[00:05:27.120 --> 00:05:31.760]   the remedial burrito class. And then as you get older, you get into tamales.
[00:05:31.760 --> 00:05:37.760]   Oh, that's sophisticated. That's graduate school. So I want to be very clear, because we
[00:05:37.760 --> 00:05:41.440]   joke each other all the time, but we joke each other with love. Carston, thank you.
[00:05:41.440 --> 00:05:44.000]   Oh, thank you. I'll think of you every time I burp.
[00:05:46.960 --> 00:05:52.240]   That's pretty fun. There was actually no meat in any of that. I was, it was what I, my normal order
[00:05:52.240 --> 00:05:57.760]   at Taco Bell is to be burrito is to be burritos. It's, I'm very happy with that. Very happy.
[00:05:57.760 --> 00:06:03.040]   And the lemonade, I don't even know that. Scooter X is reminding me there's some really good news.
[00:06:03.040 --> 00:06:11.600]   CES is returning to Las Vegas in January. Oh, I am not going. Yes. Having been a hot spot.
[00:06:11.600 --> 00:06:21.360]   The last time around, yeah, I'm not going. They're going to have a digital something. And I'm,
[00:06:21.360 --> 00:06:28.800]   I just, I know, no, no, the interesting thing doesn't it change your, your, we talked about this
[00:06:28.800 --> 00:06:33.120]   reform, curious what this has changed. Because we talked about the value of being this kind of
[00:06:33.120 --> 00:06:40.720]   place in person. But our calculation now is very different. Yeah. Right. So how do you
[00:06:40.720 --> 00:06:44.480]   calculate the value of that? I think we're also getting better at doing these things. I have to
[00:06:44.480 --> 00:06:49.520]   say Microsoft build was really incredible that we're getting better at doing virtual events that
[00:06:49.520 --> 00:06:55.920]   have some of the benefit of in person. What you're going to do, for instance, next week with Hoppen
[00:06:55.920 --> 00:07:01.440]   is a lot more, is less of a present. You know, you can get more and more of a dialogue going.
[00:07:01.440 --> 00:07:06.640]   Right. Yeah. They actually, so one of the reasons we chose it, and I'm not, I'm not a paid
[00:07:06.640 --> 00:07:11.840]   shill for Hoppen or anything. But when you shouldn't be, they have, they have this
[00:07:11.840 --> 00:07:17.680]   hop on them. See how my, my event goes. But you can actually start like, if we were all in the
[00:07:17.680 --> 00:07:23.680]   same event, I can go to the people tag find you and invite you to like a little private video chat,
[00:07:23.680 --> 00:07:26.720]   which is kind of the equivalent of grabbing someone at a conference and saying, Hey, let's
[00:07:26.720 --> 00:07:31.520]   chat about this over, you know, at the coffee station. So those kind of things, I think will be
[00:07:31.520 --> 00:07:35.440]   helpful. I don't just over. Do you remember, you remember Jeff Paul?
[00:07:35.440 --> 00:07:36.440]   Of course. Yeah.
[00:07:36.440 --> 00:07:40.240]   All of us great. Some pauver today had a, he was running 140 conferences.
[00:07:40.240 --> 00:07:42.800]   He's the king of VoIP. And then he was,
[00:07:42.800 --> 00:07:44.560]   Oh, yes. I remember it.
[00:07:44.560 --> 00:07:50.160]   A lot of. Jeff is just a great character. So today he had a session. He had Dennis Crawley,
[00:07:50.160 --> 00:07:57.200]   Crowley. Oh, wow. He had a 17 year old kid who didn't sell his COVID tracker site for $8 million.
[00:07:57.200 --> 00:08:00.800]   He had a musician that I had to go to the dentist. And he had people that Jeff is just the greatest
[00:08:00.800 --> 00:08:05.760]   convener alive. Right. And he brought together 120 people and they were talking and they were
[00:08:05.760 --> 00:08:08.720]   meeting up again in the chat. And it's a kind of a beautiful thing.
[00:08:08.720 --> 00:08:12.880]   You know, our own Alex Lindsey does now something he calls office hours,
[00:08:12.880 --> 00:08:19.840]   seven days a week every morning, 7 a.m. Pacific time. And it is about 40 of the
[00:08:19.840 --> 00:08:29.200]   of the most accomplished filmmakers, special effects people, you know, everybody in that space.
[00:08:29.200 --> 00:08:34.400]   And then another 300 people watch it. There's questions and answers. I think we're learning.
[00:08:34.400 --> 00:08:40.560]   Instead of saying, Oh, you know, we, oh, I missed the one on one. Well, you know,
[00:08:40.560 --> 00:08:44.480]   we're learning, you know, maybe there's a way to do something that is almost as good or has
[00:08:44.480 --> 00:08:48.880]   some value. I think this is this idea of the breakouts in the hop in is a great idea. I
[00:08:48.880 --> 00:08:54.800]   went without the need. I mean, later, I think I was flying 250,000 miles without the need to fly
[00:08:54.800 --> 00:09:00.720]   without the expense of flying without the the damage to the environment of flying without the hotel
[00:09:00.720 --> 00:09:06.240]   room, without all that stuff. And more time at home. There's immense pressure in Las Vegas.
[00:09:06.240 --> 00:09:14.000]   Go ahead. I will still go to events when we have some sort of when it's safer when we have
[00:09:14.000 --> 00:09:18.080]   either vaccine or you go to as many as my question. Will you go to as many?
[00:09:18.080 --> 00:09:22.240]   Has this changed your calculation? That's what I was trying to ask. Has this changed your
[00:09:22.240 --> 00:09:30.000]   calculation about the, um, no, you know, the bar. No, it hasn't. That's because I live in a place.
[00:09:30.000 --> 00:09:36.560]   Oh, well, I also you're going to, okay, go ahead. You tell me why Leo. Well, I know why because
[00:09:36.560 --> 00:09:43.200]   you're a good reporter. And yeah, the best way to do your job is to have one-on-one briefings,
[00:09:43.200 --> 00:09:47.600]   side conversation to go to events. Because that's where you get the grist for your mill.
[00:09:49.360 --> 00:09:54.640]   Yes, I would never have used the grist for my mill phrase, but yes, because she's not as old as you
[00:09:54.640 --> 00:10:03.280]   are. I remember because I'm in the middle of used to get our flower, where I had to run around
[00:10:03.280 --> 00:10:07.440]   with the, with the donkeys to run the mill, but then we got it back out and made our breath.
[00:10:07.440 --> 00:10:11.360]   Is it also because you live in a rural area? Is that part of it too? That you just want to get out
[00:10:11.360 --> 00:10:17.600]   of there? Well, no, I just, I want to, I have to go places because I can see the volume of people I
[00:10:17.600 --> 00:10:21.840]   can see in a short amount of time is incredibly high. Yeah, it's efficient. So,
[00:10:21.840 --> 00:10:29.360]   I on the other hand, who have even without COVID-19 been glad to eschew these events,
[00:10:29.360 --> 00:10:35.040]   we'll, we'll just have an excuse not to go now. So I have no intention of ever going to CES again,
[00:10:35.040 --> 00:10:40.880]   because if it's, you know, you didn't have fun with Ant? I had a great time. I love CES.
[00:10:40.880 --> 00:10:44.880]   I don't think it's worth the risk. And they're all, you know, you're going to get sick.
[00:10:46.240 --> 00:10:52.000]   Anyway, and you know, this isn't the last pandemic. It may not even be the last pandemic in my lifetime.
[00:10:52.000 --> 00:11:00.880]   So why take a chance, you know? I, but my point was going to be that I understand why the Consumer
[00:11:00.880 --> 00:11:05.840]   Electronics Association or it's considered like technology associates doing it, because a,
[00:11:05.840 --> 00:11:10.320]   there's tons of pressure in Vegas, constant pressure in Vegas to bring it back, bring it back,
[00:11:10.320 --> 00:11:16.560]   bring it back. That's a town that doesn't exist without tourism, gambling, and the strip. I mean,
[00:11:16.560 --> 00:11:22.400]   there's a lot more to it than that. I know that. And it's beautiful city. I love it. But, and, and,
[00:11:22.400 --> 00:11:30.240]   they've just, I don't know if you remember, Stacy at CES, but they were building an extension to
[00:11:30.240 --> 00:11:36.000]   the convention center that was as big as the North Hall. It was huge across the street. That's
[00:11:36.000 --> 00:11:43.520]   out almost a billion dollar project that will be coming to a close right around then. Why? Because
[00:11:43.520 --> 00:11:51.680]   it's for CES. They're building it. 175,000 people come to CES. I don't think there's any way to do
[00:11:51.680 --> 00:11:59.680]   CES safely. The CTA says, well, we're going to regularly clean and sanitize spaces. We're going
[00:11:59.680 --> 00:12:05.760]   to offer sanitization stations. They're going to most of the transmission is not through surfaces.
[00:12:05.760 --> 00:12:12.400]   Right. They're going to widen aisles and seats to increase distancing. There's no way 175,000
[00:12:12.400 --> 00:12:16.240]   people can be six feet apart. All of them. Well, it's because they're going to be lucky to get
[00:12:16.240 --> 00:12:22.480]   somebody with some zoom all of Nevada to distance. Well, I will say that there's going to be a lot
[00:12:22.480 --> 00:12:28.160]   of people who don't come. Yeah. So it'll be a lot. It'll be interesting. The other thing is they,
[00:12:28.160 --> 00:12:33.600]   we don't know what it'll be like in January. It's completely possible, unlikely, but possible.
[00:12:34.320 --> 00:12:40.160]   Everybody will say, oh, it's over. It mutated into a broccoli eating germ. And thank God,
[00:12:40.160 --> 00:12:46.720]   there's no more broccoli. And we can all go to CES. I would be so sad without broccoli.
[00:12:46.720 --> 00:12:50.240]   Well, somebody that's Dr. Brussels sprouts, please. Okay. Even better.
[00:12:50.240 --> 00:12:58.400]   It could be a tofu eating germ. There's going to work on CRISPR right now.
[00:12:59.040 --> 00:13:04.000]   I give the CRISPR a run in the they're going to limit touch points by using
[00:13:04.000 --> 00:13:10.080]   tech like mobile payments. They're going to provide onsite health services like that's.
[00:13:10.080 --> 00:13:17.040]   Oh, oh, yeah. What's that to your ICU next to the Microsoft booth? Yeah. And
[00:13:17.040 --> 00:13:21.760]   use a hundred a hundred a year. They haven't been there years.
[00:13:22.400 --> 00:13:28.480]   CTA says it'll be it's going to look into doing temperature scans. Oh, Jesus.
[00:13:28.480 --> 00:13:33.840]   And then it plans to issue best practices like wearing a mask, although they haven't said it'll
[00:13:33.840 --> 00:13:45.120]   be required. Oh, it's a germ fest already. So again, it was seen as a super spreader event
[00:13:45.120 --> 00:13:54.000]   in the early days of the yeah, CES is a is it in a I mean, like, it's a super spreader for flu
[00:13:54.000 --> 00:14:01.280]   for a lot of it. Like I got the only time I got the flu was a year I later found out that my flu
[00:14:01.280 --> 00:14:07.920]   vaccine was not very effective and lo and behold, CES gave it to me. And I would avoid that. I mean,
[00:14:07.920 --> 00:14:11.840]   if I didn't get a flu vaccine, I would never go to CES. The thing that's interesting is,
[00:14:11.840 --> 00:14:17.600]   remember these events, the biggest problem with canceling an event is you've got contracts for
[00:14:17.600 --> 00:14:23.680]   hotels space for convention space. The way CES, I think this is probably how they work. This is how
[00:14:23.680 --> 00:14:29.440]   convex work works. The convex, they would buy up all the hotel rooms in town when you got it.
[00:14:29.440 --> 00:14:32.560]   And I think it's true at CES too, when you get a hotel room, you don't get it from the hotel,
[00:14:32.560 --> 00:14:38.560]   you get it from CES. CES basically buys up all the hotel rooms. And I'm guessing those are long
[00:14:38.560 --> 00:14:44.240]   term contracts. They don't say round about June. I think we'll buy some hotel rooms in January.
[00:14:44.240 --> 00:14:49.440]   They have had those and probably a considerable amount of money for them, whether they have a
[00:14:49.440 --> 00:14:56.320]   show or not. Yeah, when you do an event, you usually you contract with a venue or in CES,
[00:14:56.320 --> 00:15:00.640]   as case, multiple venues. And you that's where actually your upfront costs, some of your upfront
[00:15:00.640 --> 00:15:04.720]   costs are most of them. The difference is contracting with them. And this is how Sheldon
[00:15:04.720 --> 00:15:09.520]   Edelson made so much money on convex. And this is the difference. Shelley, I don't know, he invented
[00:15:09.520 --> 00:15:14.880]   it, but he perfected it, would buy up all the hotel rooms. So that's why, I mean, then they
[00:15:14.880 --> 00:15:20.720]   jack up the prices two or three times for the conference. And that's where he made all of his
[00:15:20.720 --> 00:15:30.960]   money, huge amount of money. Enough money to fund Macau casinos and a presidency. So this was a
[00:15:30.960 --> 00:15:35.280]   clever, I don't know if CES does that or not, but the Condex really did. And it was really a
[00:15:35.280 --> 00:15:40.800]   but you wonder too, what do others say? So the story of Mashable from April that says that
[00:15:40.800 --> 00:15:45.440]   CES might have spread COVID through the whole US. What do other states say at some level?
[00:15:45.440 --> 00:15:51.520]   You know, what do they know? This is a problem. We don't know. We do, you know, the only thing
[00:15:51.520 --> 00:15:56.960]   I've read is, and again, we're not epidemiologists. So anything we say, but we don't need to be
[00:15:56.960 --> 00:16:00.800]   that story was not a reason. Yeah, I think so. Yeah, don't.
[00:16:00.800 --> 00:16:05.520]   That's a but I'm saying that and event. So the same as the Boston event.
[00:16:05.520 --> 00:16:13.920]   And that's it. Actually has they actually looked at the genetic strains from people who had the
[00:16:13.920 --> 00:16:20.480]   Boston, the Boston one, right? Yeah, biogen conference. But the CES thing is all hypothetical,
[00:16:20.480 --> 00:16:30.240]   and it's pretty great evidence. Yeah, they they say that there are two, there's a European strain
[00:16:30.240 --> 00:16:37.600]   and an Asian strain, right? Let's see. CES secures from the selection of Las Vegas hotels and use
[00:16:37.600 --> 00:16:42.400]   the reservation book and site powered by on peak. So yeah, CES does the same thing, which means
[00:16:42.400 --> 00:16:46.320]   they've already are, you know, they probably already committed a lot of money.
[00:16:47.360 --> 00:16:51.840]   Your seat when you go by through CES, though, you tend to pay less for the hotel. I mean,
[00:16:51.840 --> 00:16:56.160]   they're still crazy expensive, but there is high demand for it. Yeah. Like if you try to get a
[00:16:56.160 --> 00:17:00.880]   hotel that's not part of the CES housing block, it's usually more than what a hotel the CES
[00:17:00.880 --> 00:17:06.400]   has. Everybody's getting rich. So what happens to the event insurance, which never had pandemic
[00:17:06.400 --> 00:17:12.640]   clauses or rarely did now? Well, look, I mean, I don't I don't know have any insight insight.
[00:17:14.160 --> 00:17:18.480]   But look what O'Reilly did. They just said we're never doing live events ever again.
[00:17:18.480 --> 00:17:22.960]   Really? Oh, yeah, I know that they canceled their wealth. They basically killed their live event.
[00:17:22.960 --> 00:17:27.040]   You know, and that's probably a twofold thing. One is that early thing we were talking about,
[00:17:27.040 --> 00:17:33.280]   which is maybe online is actually as good or better. And the other is there's such a consequence
[00:17:33.280 --> 00:17:40.480]   to canceling an event, financial consequence that the risk is to high insurance cost would be now
[00:17:41.040 --> 00:17:46.480]   right, it's dependence. Right. And I honestly don't think this is the last pandemic.
[00:17:46.480 --> 00:17:49.760]   You know, it's I know it's a it's a hundred year pandemic.
[00:17:49.760 --> 00:17:58.080]   What's changed is how quickly we move around the world. Yep. And I just, you know, we were lucky
[00:17:58.080 --> 00:18:06.720]   with SARS and MERS and Ebola because those particular viruses, you know, were had weren't as
[00:18:06.720 --> 00:18:11.600]   dangerous because while SARS, for instance, you always had a temperature before you were contagious.
[00:18:11.600 --> 00:18:16.480]   So it was easy to that's where all that temperature measuring came from. But we now know that's not
[00:18:16.480 --> 00:18:22.160]   as useful with COVID because you're often asymptomatic and pre symptomatic, pre symptomatic. Yeah.
[00:18:22.160 --> 00:18:29.600]   So anyway, isn't it funny how in the national news,
[00:18:31.440 --> 00:18:38.880]   COVID just took a backseat very quickly. Everybody was so tired of the pandemic and talking about
[00:18:38.880 --> 00:18:43.520]   it. And news, normally the news cycle is literally, you know, it's one day and that what's next,
[00:18:43.520 --> 00:18:49.760]   what's next, what's next? And, you know, it says if there was no pandemic at all, I guess,
[00:18:49.760 --> 00:18:55.360]   that's not that's not really true. There is, I mean, if you go to like the New York Times,
[00:18:55.360 --> 00:18:58.400]   they're still covering the top stories. They're still covering it. Yeah.
[00:18:58.400 --> 00:19:02.320]   Yeah. But I think he's talking about cable coverage. Yeah. They're crystal covering it. But, but,
[00:19:02.320 --> 00:19:11.600]   you know, who gets there? Like, I, nobody I know who's my age or younger spends time watching
[00:19:11.600 --> 00:19:15.760]   cable news. Yeah, there's still, there's still a lot of you're right. There's a lot of pandemic
[00:19:15.760 --> 00:19:22.880]   coverage on the front page of the Times. But even like the Wall Street Journal, I mean, they even have,
[00:19:23.760 --> 00:19:30.160]   I know, Jeff, you don't love the Wall Street Journal. But, whoof. All right, moving along,
[00:19:30.160 --> 00:19:35.360]   moving along. I just, that actually was kind of the irony of this is apparently it's been on the
[00:19:35.360 --> 00:19:42.480]   CES website since May 7th. No, no, yeah, nobody. No way. Yeah. The Verge noticed it and put a story
[00:19:42.480 --> 00:19:46.720]   out. And that's why everybody's talking about it. They announced it a month ago.
[00:19:47.680 --> 00:19:54.400]   No, they didn't because I, I emailed them like three weeks ago. Oh, all right. Well, this is what
[00:19:54.400 --> 00:20:00.160]   the Verge is saying. They're saying, it turns out, except we, they announced this May 7th, but we just
[00:20:00.160 --> 00:20:05.680]   noticed. No, no, you don't think so. Okay. Which would be the Verge at the video. They didn't have
[00:20:05.680 --> 00:20:10.160]   quite the scoop they thought they had, which is even funnier, but yeah, really. No, because I said
[00:20:10.160 --> 00:20:14.000]   that I said, I'm looking at my email. Because you were interested whether they were going to have a
[00:20:14.000 --> 00:20:18.240]   conference. You wanted to know? Yeah. Well, I was interested because I was, I was reporting on
[00:20:18.240 --> 00:20:27.360]   IFA. Yeah. What IFA was doing. So I just shot an email over the CTA to say, Hey, big conference.
[00:20:27.360 --> 00:20:30.400]   What are you going to do? And what, what was your response? And they were like, we don't know yet.
[00:20:30.400 --> 00:20:39.680]   Oh, they had decided. So, uh, Android 11 announcement was going to be this week.
[00:20:40.640 --> 00:20:46.400]   What's me today? I think postponed due to the unrest in the United States.
[00:20:46.400 --> 00:20:52.880]   I think that's smart. I mean, nobody cares about Sony was going to be doing. Yeah, it could be
[00:20:52.880 --> 00:20:59.280]   partly because nobody cares. Also the optics, it's, it looks like it's been challenging for me to
[00:20:59.280 --> 00:21:02.960]   think about should we do shows? I don't know. I don't know if I want to talk about the tech stuff.
[00:21:02.960 --> 00:21:08.240]   It's hard. A lot of stores are shut. I mean, like, uh, there's a lot of stores. So if you think
[00:21:08.240 --> 00:21:12.400]   about your retail outlets going in, because we talked, didn't we talk about getting the phones
[00:21:12.400 --> 00:21:16.640]   in physical stores? Yep. Those are shut down right now. Yep. In a lot of areas.
[00:21:16.640 --> 00:21:23.520]   So, uh, Sony's PlayStation five game announcement was this week too. They canceled that. I think
[00:21:23.520 --> 00:21:29.040]   there's some, there's some good, um, there's some good sense prevailing that it's just, you know,
[00:21:29.040 --> 00:21:36.160]   maybe we shouldn't, uh, we should be they, Google's literally or Android actually literally said on
[00:21:36.160 --> 00:21:40.960]   Twitter, we're excited to tell you more about Android 11, but now is not the time to celebrate.
[00:21:40.960 --> 00:21:47.280]   We'll be back with more soon. We talked about last week in the, in the context of the, um,
[00:21:47.280 --> 00:21:54.320]   for a Google for a pixel for a, but it's also a huge proportion of America's unemployed and not,
[00:21:54.320 --> 00:21:59.920]   they do not have access money to spend on anything. Yeah. But they have time for a product launch.
[00:22:00.880 --> 00:22:07.600]   Well, sometimes protesting, uh, super seeds, other issues, although you have to think that the amount,
[00:22:07.600 --> 00:22:13.520]   and, and fewer of the protesting was somewhat, uh, I don't know, you think powered by the fact
[00:22:13.520 --> 00:22:18.480]   that everybody was stuck at home for three months, not to diminish the, the righteous anger,
[00:22:18.480 --> 00:22:24.560]   but it didn't help that unemployment is at 25% people have been stuck at home for three months,
[00:22:24.560 --> 00:22:29.120]   then George Floyd happens. It was a perfect storm. Well, yeah.
[00:22:29.120 --> 00:22:32.400]   Yeah. If you think about, oh, go on, Jeff. Go ahead. There you go.
[00:22:32.400 --> 00:22:38.080]   I was going to say, if you think about the loss of life that has been happening in this country,
[00:22:38.080 --> 00:22:42.800]   it has gone almost unacknowledged by our leadership. It's stunning. A hundred thousand people.
[00:22:42.800 --> 00:22:50.720]   It's stunning. You're unemployed. If someone, all you need is a spark in that situation and
[00:22:50.720 --> 00:22:58.240]   you have time, you have anger, you have personal fear and a stake in this, and you have lost the
[00:22:58.240 --> 00:23:01.600]   faith of your country. Of course, you're going to go out and protest.
[00:23:01.600 --> 00:23:06.960]   Yeah. Yeah. And, and the, you know, the key to this, I was asked to write a piece for an Irish
[00:23:06.960 --> 00:23:13.760]   news site, which will be out tomorrow. And, um, I'm going to state the obvious, but you come off of
[00:23:13.760 --> 00:23:22.160]   the racial inequity of the impact of COVID. And then on top of that, you have unemployment.
[00:23:22.160 --> 00:23:27.680]   And then on top of that, you now have most important of all, uh, in their family's life,
[00:23:28.400 --> 00:23:36.080]   George Floyd. And, um, and then on top of that, you have Donald Trump. It's just, it's, I don't
[00:23:36.080 --> 00:23:40.560]   want to call it a perfect storm or anything, but it's just comes together in such a way that, um,
[00:23:40.560 --> 00:23:46.720]   of course, people are angry because, because, because the underlying factors have been here for
[00:23:46.720 --> 00:23:51.840]   a century, but they are all out in front of us now. We talked, we've been talking about that.
[00:23:51.840 --> 00:23:56.960]   Early on, we talked about that, that the, this, this, the virus brought forth the fractions.
[00:23:56.960 --> 00:24:03.680]   Exactly. The fractures in American society of income inequality. It disproportionately hits
[00:24:03.680 --> 00:24:10.320]   people of color. I mean, it's just, it's, it's, and now the, uh, all the businesses that are so
[00:24:10.320 --> 00:24:17.600]   highly leveraged, we talked about this last week, Stacy, suddenly collapsing. Uh, it just showed what
[00:24:17.600 --> 00:24:19.840]   a, what a house of cards we've been living on.
[00:24:19.840 --> 00:24:23.840]   Hmm. And also.
[00:24:25.360 --> 00:24:28.800]   Go ahead, Jeff. Go ahead, Stacy. Go ahead, stay. No, go ahead, Jeff. Yeah.
[00:24:28.800 --> 00:24:34.320]   Well, no, so why confess in mind, you know, this, this is the, what we're seeing is the last
[00:24:34.320 --> 00:24:38.960]   stand of the old white man. And I say that as an old white man. Uh, and, and that's really what's
[00:24:38.960 --> 00:24:42.240]   happening here. It's the fear of being super seated. It's the fear of all that. It's the
[00:24:42.240 --> 00:24:49.120]   uneducated old white man too. And, and the, the racial nature of what's happening. That's fair.
[00:24:49.120 --> 00:24:54.400]   It's not uneducated. It's a legitimate fear to have. It really is. It's not,
[00:24:54.960 --> 00:25:01.920]   it's not people. No, no, it's not okay. But it's, it's, I can understand why it's making people
[00:25:01.920 --> 00:25:05.920]   anxious. Any change to the status quo makes people anxious. And I don't think it has any
[00:25:05.920 --> 00:25:12.640]   new education level. It's scary. Well, it does in terms of the polls and who supports certain
[00:25:12.640 --> 00:25:18.160]   person and who's rock solid there. It is uneducated white men. That is the base. That is not actually
[00:25:18.160 --> 00:25:24.800]   true. There are very educated, rich white men. There are those two. There are those two.
[00:25:24.800 --> 00:25:31.760]   But the most solid ever since 2016, the most solid single demographic has been uneducated white men.
[00:25:31.760 --> 00:25:40.080]   I, I just say I'm sympathetic. I understand how it's scary to have this. I mean, to have the status
[00:25:40.080 --> 00:25:45.200]   only if you only if you choose to make people of color scary. No, I'm not. There's no reason for
[00:25:45.200 --> 00:25:51.680]   no. That's what it is. It's a minority minority. It has to do with women. It has to, if we've,
[00:25:52.240 --> 00:25:56.240]   if we as old white men have been on top and have had all this privilege,
[00:25:56.240 --> 00:26:01.920]   right, the threat of losing that privilege, I don't care. It's that it's legit. Of course,
[00:26:01.920 --> 00:26:07.760]   it's completely legitimate. But it's completely the right thing. It doesn't mean it doesn't make you
[00:26:07.760 --> 00:26:14.880]   anxious. It's, it's, it's, it's, I completely think that's a legitimate response to it is yikes.
[00:26:14.880 --> 00:26:19.360]   You know, my world is changing. It should change. Yeah. I mean,
[00:26:19.360 --> 00:26:23.840]   think about women have always had to be twice as good, right? Right. Right.
[00:26:23.840 --> 00:26:28.160]   And you see that throughout in people of color, gosh, like four times, six times as good. I don't
[00:26:28.160 --> 00:26:32.480]   even know. I don't know the math there. But the point is when you realize that you've been holding
[00:26:32.480 --> 00:26:38.400]   these people who are more accomplished and you're going to have to work as hard as they've having
[00:26:38.400 --> 00:26:42.560]   to. I mean, that's scary as all get out. Oh, yeah. No, I'm not diminishing any. You're
[00:26:42.560 --> 00:26:44.880]   not going to be
[00:26:44.880 --> 00:26:49.760]   trying to change the board. Like, yeah, we live in interesting times. This that is the
[00:26:49.760 --> 00:26:54.640]   Chinese curse. And, and we it's very dis, it's very, uh,
[00:26:54.640 --> 00:27:01.440]   disorienting for people for a variety of reasons. And I would be, but what I'm trying to say is we've
[00:27:01.440 --> 00:27:08.160]   made it, of course, do it awesome, then disorientation and it needn't be that in a, in a, in a country
[00:27:08.160 --> 00:27:13.920]   that supposedly is built on openness and equality. Yeah, but never was. Sorry. It never was. I know.
[00:27:13.920 --> 00:27:18.080]   That's what I'm saying. We had, we had a great American myth. I would love us to live up to it.
[00:27:18.080 --> 00:27:22.320]   Paradox. I would love us to live up to it. And maybe we will. Maybe this is the beginning.
[00:27:22.320 --> 00:27:28.160]   But it's going to be a paroxysm. It's going to be disruptive. It's going to be upsetting.
[00:27:28.160 --> 00:27:32.880]   But it's a chance. It's the only way we can make it this, you know, change.
[00:27:33.600 --> 00:27:39.680]   But this country is, this country was built on slavery on the complete, you know, disruption of
[00:27:39.680 --> 00:27:45.200]   the indigenous peoples. And by the way, you know, who's really suffering from COVID-19
[00:27:45.200 --> 00:27:50.960]   are Native Americans stuck in reservations, getting very little healthcare. We're still
[00:27:50.960 --> 00:27:57.280]   mistreating them. So, I mean, the history of this country, it's so different from the mythos.
[00:27:57.280 --> 00:28:00.960]   And yet I want to embrace the mythos because that's what, by the way, that's why all the,
[00:28:01.440 --> 00:28:06.160]   we've all immigrated here, all except the Native Americans have immigrated here.
[00:28:06.160 --> 00:28:11.280]   Because we believe this, in this shining city on the hill, we wanted to be part of
[00:28:11.280 --> 00:28:17.440]   what was, what we thought was going on in America. Let's make it so. I think it's great.
[00:28:17.440 --> 00:28:23.920]   But it's anxious. It's anxious making. By the way, President Obama is now speaking and he's using Zoom.
[00:28:23.920 --> 00:28:30.000]   So there. With, by the way, a Zoom logo on it, which none of us have to have.
[00:28:30.720 --> 00:28:32.480]   Oh, I wonder if Zoom's sponsoring.
[00:28:32.480 --> 00:28:38.720]   I would, I would certainly hope that is another sin in America.
[00:28:38.720 --> 00:28:44.160]   MSNBC slapped its logo over the Zoom logo, but there's a Zoom logo.
[00:28:44.160 --> 00:28:49.760]   That's interesting, huh? So YouTube, I, this is a big shift for YouTube, getting back to
[00:28:49.760 --> 00:28:56.560]   some Google content briefly. This is a big shift for YouTube. Remember, they were all in on
[00:28:56.560 --> 00:29:02.160]   bringing in celebrities and scripted content. They spent hundreds of millions of dollars on that.
[00:29:02.160 --> 00:29:07.120]   And they had a huge success. They had many, but I think the biggest was Cobra Kai,
[00:29:07.120 --> 00:29:15.840]   the, the, the reintroduction, the reboot of the Karate Kid franchise. They had two hugely
[00:29:15.840 --> 00:29:23.360]   successful seasons. Reportedly, they will not air season three. They're going to let it go to
[00:29:23.360 --> 00:29:30.320]   another network. And, and there are no plans for a fourth season. And, and that's because
[00:29:30.320 --> 00:29:34.960]   YouTube's shifting away from this kind of content, even though it's been very successful. They want
[00:29:34.960 --> 00:29:41.440]   to do more creator driven content, the kind of stuff YouTube's known for. That makes sense, frankly.
[00:29:41.440 --> 00:29:47.040]   That does make sense. I mean, one's a new and upcoming model of making, and there's money to
[00:29:47.040 --> 00:29:55.520]   be made there. So, yeah. They're doing the recently announced a slate of hashtag with me originals.
[00:29:55.520 --> 00:30:06.880]   I don't know. I think it's a what is what is with me originals? What's that hashtag with me?
[00:30:06.880 --> 00:30:12.800]   Well, what is what is hashtag? What is it? What is the pound side with me?
[00:30:12.800 --> 00:30:22.560]   Or, I don't know. I just say. That's a good question. Let's, let's go to YouTube and find out.
[00:30:22.560 --> 00:30:28.080]   Shall we? Let's go to the video. Let's go to the tape. I'm sorry that we are,
[00:30:28.080 --> 00:30:33.920]   we are at the simulcasting with the president. You can go, you can go watch that. All right. It's
[00:30:33.920 --> 00:30:40.480]   all right. We won't say anything interesting. You can catch us later. So, get by together hashtag
[00:30:40.480 --> 00:30:45.920]   with me. Build a garden hashtag with me. Watch a concert a day hashtag with me.
[00:30:45.920 --> 00:30:49.520]   Hashtag stay home and help save lives with hashtag with me.
[00:30:49.520 --> 00:30:58.240]   Meditate with me. So, you know, this is like part of the we're all together in this whole
[00:30:58.240 --> 00:31:06.000]   COVID-19 thing. I think they're trying to create a new style of, yes, I guess,
[00:31:06.000 --> 00:31:09.520]   or a new style of content. Because remember how well they did with the,
[00:31:09.520 --> 00:31:13.040]   what do they call those? Play with me, the, with the streaming, the video games.
[00:31:13.040 --> 00:31:17.680]   I think they want to create something kind of a movement like that. I don't know.
[00:31:17.680 --> 00:31:21.760]   Which like for things that are video games? Right. Exactly. Okay.
[00:31:21.760 --> 00:31:28.080]   Secret Double Tree chocolate chip cookie recipe test live bake with me.
[00:31:28.080 --> 00:31:30.880]   Booze. Hello, my beautiful lovelies. Thanks so much.
[00:31:30.880 --> 00:31:35.360]   So, I guess it's lonely people. She has cute hair. You like that, huh? Sorry.
[00:31:35.360 --> 00:31:41.680]   I was like, that is a cute haircut. That's Emmy made in Japan. 1.95 million subscribers.
[00:31:41.680 --> 00:31:45.680]   What? The kitchen is also cute. Amazing.
[00:31:45.680 --> 00:31:58.160]   Amazing. 1.95 million subscribers. That's why they want to do with me. Bake with me.
[00:31:58.160 --> 00:32:04.160]   Yeah. I mean, that makes sense. Yeah. You've got people that you feel are your friends and you
[00:32:04.160 --> 00:32:08.480]   get together and you here's fun with me. Farm. That's cute.
[00:32:08.480 --> 00:32:12.480]   Go cow. Go. Look at it. Cow farming. Look feeding pretty girl, modern,
[00:32:12.480 --> 00:32:18.880]   tatra military talk, cow shape cleaning. Is she feeding milk to the cow? How's Drake milk?
[00:32:18.880 --> 00:32:24.400]   Yeah. That's like cannibalism. No, it's like, is it a baby cow? Oh, maybe it's a baby cow.
[00:32:24.400 --> 00:32:31.120]   Oh, maybe. Oh, maybe she's feeding milk to a baby cow. Okay. Okay. Sorry. I'm like,
[00:32:31.120 --> 00:32:35.280]   wait a second. Grow up cow's drink milk. I thought only grow up humans drink. That's cannibalism.
[00:32:35.280 --> 00:32:46.640]   Stay home. Work out with me. Legs and hips strengthening. Oscar, the grouch says stay home with me.
[00:32:46.640 --> 00:32:52.560]   Yeah, this is a COVID thing, but also like a let's all hang out and watch you together.
[00:32:52.560 --> 00:32:59.680]   Watch party with me. Huh. Yeah, I guess this is a COVID thing. Anyway, it's
[00:32:59.680 --> 00:33:07.280]   yeah, the new owners unnamed. Who's gonna who's gonna buy this Cobra Kai? It doesn't say.
[00:33:07.280 --> 00:33:13.760]   The new owners will the plan is according to nine and five Google air season three,
[00:33:13.760 --> 00:33:20.320]   get the back catalog and then perhaps they'll spend the money on season four. But that's really
[00:33:20.320 --> 00:33:28.800]   wild that the season three's done and YouTube's never mind. It was really successful. In fact,
[00:33:28.800 --> 00:33:34.560]   as I remember is whatever. That's when you sell something. Right. That's right. That's why John
[00:33:34.560 --> 00:33:42.480]   Krasinski sold some good news. SGN. SGN. Let's see.
[00:33:44.960 --> 00:33:52.080]   Let's do. Should we talk about God? Should we talk about Facebook and yeah, I think even you,
[00:33:52.080 --> 00:33:58.800]   Jeff, finally, how do you mean even even even you're a Facebook apologist? Are you not? I am not.
[00:33:58.800 --> 00:34:06.880]   I think I I would not poke with a stick. We said you have burrito.
[00:34:06.880 --> 00:34:14.400]   No, you always say the whole damn burrito. Maybe you could insult me, but
[00:34:14.800 --> 00:34:21.520]   you don't want me to FedEx an actual Taco Bell burrito. So he asked me to be
[00:34:21.520 --> 00:34:25.360]   arrested. Probably arrived completely fine. I ruined his joke. Yeah, right. Poor
[00:34:25.360 --> 00:34:28.720]   Carson. I ruined his joke because he asked me for address and I said, and smart ass, I said,
[00:34:28.720 --> 00:34:36.560]   burritos don't travel well. And so I ruined it. Came in a poor Carson.
[00:34:37.520 --> 00:34:46.800]   So Facebook's employees, some high profile employees actually quitting the rest doing a virtual walkout
[00:34:46.800 --> 00:34:52.880]   upset over Mark Zuckerberg's continued unwillingness to censor the president.
[00:34:52.880 --> 00:35:04.320]   Thoughts? I'd walk out to. I mean, I don't know what Mark Zuckerberg is doing here, but he's
[00:35:04.320 --> 00:35:08.000]   it's not a good look for him. And you know, we've all known that he is not the most
[00:35:08.000 --> 00:35:14.080]   empathetic human being on the planet. So in a job that could you can you deny he's doing exactly
[00:35:14.080 --> 00:35:19.840]   what's right for the company? Oh, yeah, you can't. I think it hurts the company. Yeah,
[00:35:19.840 --> 00:35:25.920]   hurts the company. Okay. Oh, yeah. So I read he is said so and I don't disagree with this.
[00:35:25.920 --> 00:35:31.200]   He said it on Fox News. Social media platforms should not fact check the president.
[00:35:33.600 --> 00:35:38.560]   He said when your president is not when your president is not telling the truth,
[00:35:38.560 --> 00:35:43.920]   maybe you don't back check a president when they're actually I think you should always
[00:35:43.920 --> 00:35:48.640]   fact check a president, but that's just my early reading. I don't think that's I think that's
[00:35:48.640 --> 00:35:54.800]   the job of journalists and newspapers. Is it the job of the platform? Right? No, I don't know.
[00:35:54.800 --> 00:36:00.240]   That's why it's a false. It's a false battlefield, I think. And so what I argue is the issue here
[00:36:00.240 --> 00:36:04.720]   isn't fact checking him. The issue here isn't taking him down either. I think Twitter did the
[00:36:04.720 --> 00:36:12.160]   right thing. The issue here is what does Facebook stand for? And by doing nothing
[00:36:12.160 --> 00:36:20.400]   and choosing to do nothing, Facebook all but endorses the behavior. And when you have your
[00:36:20.400 --> 00:36:24.000]   employees walking out when you have this going on, when you are in the midst of this horrible
[00:36:24.000 --> 00:36:28.080]   crisis, and this is happening to stand, you could no longer just stand back and say,
[00:36:28.080 --> 00:36:32.320]   oh, it's freedom of expression. He's plenty of expression. It's not the issue. And nor can you
[00:36:32.320 --> 00:36:36.640]   stand back and say, oh, we don't fact check. That's not the issue. The issue is what does
[00:36:36.640 --> 00:36:41.680]   Facebook stand for? What does Mark Zuckerberg stand for? What does this give to the public and
[00:36:41.680 --> 00:36:47.200]   the community that he has there? And he can't run away from that. So I think the the the
[00:36:47.200 --> 00:36:54.080]   Jack and Mark got into a fact check fight there. I think that's that's the wrong place to go here.
[00:36:54.080 --> 00:36:59.600]   They fact check stuff. That's not what what is needed here. What's needed is for Mark Zuckerberg
[00:36:59.600 --> 00:37:05.360]   to say this is unacceptable. Inciting violence is unacceptable. Well, they would certainly say if
[00:37:05.360 --> 00:37:13.600]   it were if it were ISIS putting up a post, they would not only say that they would take it down,
[00:37:13.600 --> 00:37:16.640]   right? In fact, they do. They take terrorist posts down. They don't want terrorists.
[00:37:16.640 --> 00:37:21.840]   Most down, but but but but head of state posts. I think I think I can argue the Jack to the right
[00:37:21.840 --> 00:37:27.360]   thing, leaving it up, but not promoting it, putting a warning in front of it in the one case, adding
[00:37:27.360 --> 00:37:33.680]   more information, but leaving it up to be able to see what what what he says, I think is a legitimate
[00:37:33.680 --> 00:37:41.520]   decision that Jack made. But I think that that Mark Zuckerberg, the other thing I said was,
[00:37:41.520 --> 00:37:47.120]   it's time to have this I said this before last weekend, there's time to have a meeting of their
[00:37:47.120 --> 00:37:51.840]   oversight board and the oversight board should have their own damn meeting whether or not Facebook
[00:37:51.840 --> 00:37:59.200]   likes it. If they don't, then why does it exist? Right. Now of all times, it has to. And one of
[00:37:59.200 --> 00:38:02.480]   those were friend of mine, I'll rush for the editor of the garden from right over the Guardian,
[00:38:02.480 --> 00:38:12.240]   and I haven't communicated with him on this. But if they don't at least deliberate on this issue,
[00:38:12.240 --> 00:38:16.480]   and there are things to deliberate on here, there are choices. I'm not suggesting that this is a
[00:38:16.480 --> 00:38:22.320]   case where the oversight board gives Mark Zuckerberg an order. No, but if any you have 20 brilliant
[00:38:22.320 --> 00:38:29.440]   people there and you don't convene them to at least advise, he also he also spoke to the president on
[00:38:29.440 --> 00:38:34.800]   Friday. That's scary in and of itself. And apparently does that regularly, at least that's
[00:38:34.800 --> 00:38:37.360]   I saw some reporting on the screen.
[00:38:41.280 --> 00:38:47.040]   I know I really don't know what the answer is. On the one hand, I almost feel like they should
[00:38:47.040 --> 00:38:52.080]   be common carriers like the phone company and they should just put up whatever anybody wants
[00:38:52.080 --> 00:38:58.560]   to put up. If they did that, I think there would be a lot more willingness on the part of its users
[00:38:58.560 --> 00:39:03.520]   to both Twitter and Facebook to be critical to think critically about the stuff they see,
[00:39:03.520 --> 00:39:09.840]   knowing that anything goes. It gives a false sense of security if Facebook blocks some stuff like,
[00:39:09.840 --> 00:39:15.440]   "Oh, well, the worst stuff is not getting up here, so I probably can trust most of it." That seems bad,
[00:39:15.440 --> 00:39:23.760]   too. And then it really seems bad to put anybody, especially a Silicon Valley executive,
[00:39:23.760 --> 00:39:28.400]   in charge of determining right and wrong. That seems pretty tough.
[00:39:28.400 --> 00:39:36.560]   What would be wrong if Facebook and Twitter just said, "Okay, anything goes?"
[00:39:38.640 --> 00:39:42.080]   Well, that may be where we end up without Section 230, in a sense.
[00:39:42.080 --> 00:39:53.200]   The back end of this is, Section 230 gives them the sword and the shield, both.
[00:39:53.200 --> 00:39:56.240]   Right. Right. So there are very constraints on the shield, but it gives them the sword.
[00:39:56.240 --> 00:40:01.200]   What happened before 230, and I highly recommend Jeff Kosslef's book, The 26 Words that Created
[00:40:01.200 --> 00:40:08.320]   the Internet, it is the definitive work on 230. Before 230, what publishers said, my lawyer said to me
[00:40:08.320 --> 00:40:12.960]   was, "No, no, no, no, no, no, don't touch anything, because if you touch it once,
[00:40:12.960 --> 00:40:18.800]   then you fail the next time, then you are more liable." That's what 230 got rid of.
[00:40:18.800 --> 00:40:24.880]   So you're going to have one extreme or another. You're going to have, on the one extreme,
[00:40:24.880 --> 00:40:29.360]   nobody could do nothing here, because I could get in trouble for it. Or the other extreme is,
[00:40:29.360 --> 00:40:34.560]   "I'm not touching nothing, because I don't want to be blamed for it. I'm just a common
[00:40:34.560 --> 00:40:40.480]   carrier man." It would be an awful, awful internet. Now, I also put up a post,
[00:40:40.480 --> 00:40:47.200]   I'm going to go off for one second here, pardon me, but I put up a post where I took Benjamin Franklin's
[00:40:47.200 --> 00:40:54.720]   1761, I think it was, apology for printers. He wasn't an apology at all, but people were
[00:40:54.720 --> 00:40:57.920]   pissed at him from the stuff that he was printing. It wasn't so much as a newspaper, it was the ads
[00:40:57.920 --> 00:41:04.400]   that he printed for people. They got mad at him. He went on a beautiful rant that I took the word
[00:41:04.400 --> 00:41:10.080]   printer out and added in platform and social media and post and serve instead of the verb
[00:41:10.080 --> 00:41:15.920]   noun, print and printer. It becomes clear that Franklin saw that printing was a platform.
[00:41:15.920 --> 00:41:22.400]   And he said, "There are things that I will not print, but if all you want is the things I agree with,
[00:41:22.400 --> 00:41:26.560]   you're not going to like that. Or if all you want is the things that you want and agree with,
[00:41:26.560 --> 00:41:33.360]   that's impossible." So he saw printing as a platform, but he made judgments. He said,
[00:41:33.360 --> 00:41:36.800]   "There are things that I will not do." And Zuckerberg too makes judgments,
[00:41:36.800 --> 00:41:39.280]   and he's not made a judgment about Trump. And that's where he's...
[00:41:39.280 --> 00:41:43.680]   Actually, he pointed out in the phone call, they pulled a Trump ad down in March
[00:41:43.680 --> 00:41:50.320]   that misled users into thinking a campaign survey was the census, the US census. They did take that
[00:41:50.320 --> 00:41:56.880]   down. So he takes something down. He said in this phone call, this is the Verge reporting,
[00:41:58.320 --> 00:42:03.760]   he's worried that free speech will only ratchet down. Over time, he said, "Oh, in general, we tend to
[00:42:03.760 --> 00:42:07.840]   add more policies to restrict things more and more. If every time there's something that's
[00:42:07.840 --> 00:42:13.200]   controversial, your instinct is, "Okay, let's restrict a lot," then you do end up restricting a
[00:42:13.200 --> 00:42:18.320]   lot of things. I think it would eventually be good for everyone. It is kind of Franklin Esquid,
[00:42:18.320 --> 00:42:22.000]   there's some things that we won't do, but most of the things we let do.
[00:42:22.000 --> 00:42:29.680]   Well, his line is very... Sorry, Stacey. His line is a millimeter up from sea level.
[00:42:29.680 --> 00:42:31.040]   It's not very high. Stacey, sorry.
[00:42:31.040 --> 00:42:37.760]   No, I was going to say he has made plenty, and Facebook is a platform has made plenty of editorial
[00:42:37.760 --> 00:42:43.280]   judgments. Well, you could argue, the algorithm does that in the newsfeed every single second,
[00:42:43.280 --> 00:42:47.520]   whether it's editorial or something. Right, and they focus on how to tune that.
[00:42:47.520 --> 00:42:53.760]   And they have historically made... There's a couple things that if you look at even free speech in
[00:42:53.760 --> 00:43:00.000]   the US, there are things that fire in a crowd of theaters, one of our favorites, right? There's
[00:43:00.000 --> 00:43:05.360]   pornography, obscenity, that's not actually a free speech. I think that's sending it through the
[00:43:05.360 --> 00:43:12.880]   male kind of legal argument. But there are things that we have, as a society, made a
[00:43:12.880 --> 00:43:18.880]   judgment about. There are things that, and I should say as a society based on constitutional
[00:43:18.880 --> 00:43:25.440]   rights, as a private company, Zuckerberg and Co have made similar editorial judgments about
[00:43:25.440 --> 00:43:30.400]   similar categories. And sometimes... Yes.
[00:43:30.400 --> 00:43:35.840]   They've been right. Right. I mean, they did naked children and the Vietnam photo and
[00:43:35.840 --> 00:43:42.320]   breast and breastfeeding. Yes. So the key that I think we're looking for here is,
[00:43:42.320 --> 00:43:49.200]   do you say the president is lying, or do you say we don't want to incite violence, which is kind
[00:43:49.200 --> 00:43:54.160]   of like a fire in a crowded theater argument? Ding, ding, ding, ding. Exactly, Stacy.
[00:43:54.160 --> 00:44:02.480]   And this is a really hard... I mean, these are big constitutional law cases for a reason. They're
[00:44:02.480 --> 00:44:08.160]   hard for people. And we have all these educated judges and lawyers that paid a lot and thought
[00:44:08.160 --> 00:44:13.280]   about this a lot. We have dozens of really smart people basically trying to figure this stuff out.
[00:44:13.280 --> 00:44:18.720]   And they really haven't been able to. I mean, I'll know it when I see it is kind of a big dodge.
[00:44:18.720 --> 00:44:27.840]   It's the right call, but it's a dodge. Right. So leaving that to what is essentially Mark Zuckerberg,
[00:44:28.960 --> 00:44:33.600]   that is scary. And that's what I think people freak out about is because you've got... How
[00:44:33.600 --> 00:44:42.320]   old is he? 35? 38? Well, and as somebody pointed out on Twit, here you have a guy who never was not
[00:44:42.320 --> 00:44:48.320]   rich. Like he never had a chance. Right. He never had a chance to have the normal developmental 20s.
[00:44:48.320 --> 00:44:56.240]   He went zero to a million. Yeah, you have this person who is probably more isolated
[00:44:57.840 --> 00:45:04.080]   than other people whose life experience does not at all mirror any... And there is even a legal
[00:45:04.080 --> 00:45:09.840]   argument in... Or an argument in legal circles, how much does life experience? How much should it
[00:45:09.840 --> 00:45:17.200]   affect your arguments, your judgments? If you talk to Sonia Santamayor, she's like,
[00:45:17.200 --> 00:45:22.400]   "Yes, 100%!" You talk to someone like John Roberts, he's probably like, "No, even though it does."
[00:45:24.960 --> 00:45:31.680]   So you've got this person who is probably completely unequipped to really see and understand the issue
[00:45:31.680 --> 00:45:38.480]   at a level that they should. And the importance that his employees and his users think is real.
[00:45:38.480 --> 00:45:47.440]   And so I think the walkout here is a cry to saying, "Hey, listen to us. You're not the only
[00:45:47.440 --> 00:45:52.320]   designer here." Let me understand that, Stacey. I'm agreeing with everything you're saying, but
[00:45:52.320 --> 00:45:56.880]   there's a... I think there's a little bit of a conundrum in there. In the end,
[00:45:56.880 --> 00:46:01.280]   what I think I hear you saying is, and I agree, as I said it too,
[00:46:01.280 --> 00:46:07.280]   make this judgment with the help of others, with the help of your employees and your users and the
[00:46:07.280 --> 00:46:12.960]   oversight board and smart people. However, it's still his decision then because he's a boss.
[00:46:12.960 --> 00:46:19.440]   It's his party. So in a way, I hear you saying, "I don't trust you to make this decision, Mark Zuckerberg.
[00:46:19.440 --> 00:46:23.600]   Don't make it." On the other hand, I'm hearing you saying, "Yeah, no, make it."
[00:46:23.600 --> 00:46:27.440]   Which is it there? I don't trust him to make the decision in isolation.
[00:46:27.440 --> 00:46:36.160]   I also don't know... I also don't know... I also don't know... No. I don't know if he can actually make this
[00:46:36.160 --> 00:46:43.440]   decision. And that's why I feel... I want to fall down on one side or the other, like theoretically,
[00:46:43.440 --> 00:46:50.960]   you should be able to make this decision. But the Mark Zuckerberg we've known is not someone
[00:46:50.960 --> 00:46:55.360]   who I would trust to make this decision even after he's listened to people. And it's not just because
[00:46:55.360 --> 00:47:02.640]   I disagree with his decision. I just don't feel like he's empathetic enough. He doesn't have the
[00:47:02.640 --> 00:47:06.960]   mindset. But he is the boss. And so I'm going to push you a little bit.
[00:47:10.480 --> 00:47:13.520]   He's the hand, you're dealt. So what do you expect of him?
[00:47:13.520 --> 00:47:19.920]   I mean, if he behaves like this, I expect... I mean, I am glad that his employees are walking out.
[00:47:19.920 --> 00:47:25.680]   I am... Well, hopefully his users will... I'm gonna... I'm gonna quote Casey Newton here in the
[00:47:25.680 --> 00:47:34.720]   Verge who says that the people he spoke to said that the majority of Facebook employees supported
[00:47:34.720 --> 00:47:40.320]   Mark. It was a small group. It was only 100, so people in the walkout. But people were reluctant
[00:47:40.320 --> 00:47:46.880]   to say they supported Mark because it was such a flashpoint. They didn't want a program.
[00:47:46.880 --> 00:47:57.440]   So Newton got a recording of this presentation that Mark did on Tuesday to his staff.
[00:47:59.440 --> 00:48:06.560]   And one of the quotes, according to the recording obtained by the Verge, Zuckerberg described being
[00:48:06.560 --> 00:48:11.760]   upset by Trump's recent posts, one of which warned protesters that when the looting starts,
[00:48:11.760 --> 00:48:15.760]   the shooting starts, but quote... And this is Zuckerberg speaking, "I knew that I needed to
[00:48:15.760 --> 00:48:22.320]   separate my personal opinion from what our policy is and the principles of the platform
[00:48:22.320 --> 00:48:27.440]   we are running are knowing that the decision we made was going to lead to a lot of people
[00:48:27.440 --> 00:48:31.680]   being very upset inside the company and a lot of the media criticism we're going to get."
[00:48:31.680 --> 00:48:37.040]   So he's not completely unaware. He sounds like he can't be unaware. He's trying... He can't be
[00:48:37.040 --> 00:48:43.360]   unaware. I mean, this is the same thing, Matt. We've given this guy rightly or wrongly. This
[00:48:43.360 --> 00:48:49.920]   guy has huge influence worldwide. He's got... Well, I should give him too much credit, but that's
[00:48:49.920 --> 00:48:55.840]   why... I don't know. A lot of people get their news from Facebook. A lot like... I don't think most
[00:48:55.840 --> 00:48:59.280]   people see Donald Trump on Facebook. I don't think anybody sees Donald Trump on Facebook.
[00:48:59.280 --> 00:49:03.280]   That's not even... That's not even Jermaine. They get their news from Facebook and from the
[00:49:03.280 --> 00:49:08.800]   algorithmically generated Facebook news... They get weird news. They get news that promotes
[00:49:08.800 --> 00:49:14.640]   Trump or promotes his... Whatever they're doing... Two percent of their... I mean, it was 4 percent
[00:49:14.640 --> 00:49:21.520]   its highest was news. They get hardly any news from Facebook. Very level. Which is to say,
[00:49:21.520 --> 00:49:25.360]   people won't get much news. Now, I got rid of Facebook again because I couldn't take it, but
[00:49:25.360 --> 00:49:31.520]   for the month or two I was on Facebook. There's definitely in that stream
[00:49:31.520 --> 00:49:39.040]   content that swings you one way or the other. You're weird. You're weird. I don't think so. It
[00:49:39.040 --> 00:49:44.960]   wasn't just... You get rid of news. Most people aren't getting news. News is a tiny, tiny portion.
[00:49:44.960 --> 00:49:50.320]   No, I can argue that. It's all everything in there is opinion of some kind or another.
[00:49:50.320 --> 00:49:57.440]   It's a polemic of some kind or another. Even if it's just... Well, maybe it's burritos, but it's not.
[00:49:57.440 --> 00:50:04.640]   It's a lot of time. Oh, look at this influencer pretending to drill on... Put up a board and then
[00:50:04.640 --> 00:50:10.320]   getting an emissities. There's content in there. You may not call it news in your standard of what
[00:50:10.320 --> 00:50:17.200]   news is. It's news in the standard of what humans consider information about the world around them
[00:50:18.160 --> 00:50:24.880]   and Mark controls it. He has a huge bully pulpit. Now, I don't think he controls it with his like,
[00:50:24.880 --> 00:50:31.760]   "Oh, we should do this. We should do that." I think the algorithm controls it and he and his
[00:50:31.760 --> 00:50:36.240]   team give the rules to the algorithm. I think you're going... They're very powerful, though.
[00:50:36.240 --> 00:50:44.080]   You can't say not to somebody. Yeah, but I think in ways that do not have evidence.
[00:50:45.760 --> 00:50:49.280]   Well, if you have it, this is there. Nonetheless, nonetheless. I'm quite grateful.
[00:50:49.280 --> 00:50:55.520]   Wait a minute. You don't think that people make decisions about politics based on what
[00:50:55.520 --> 00:51:02.640]   some degree based on what they read on Facebook. I come back to Ben Franklin and John Milton and
[00:51:02.640 --> 00:51:09.280]   Franklin's talking. He's talking as a... Not a publisher, but as a printer, right? No, he was
[00:51:09.280 --> 00:51:14.080]   talking his both. Because he ran a print shop. He did have a newspaper. He was also a publisher.
[00:51:14.080 --> 00:51:18.240]   It is a newspaper. But I bet you that he made a distinction between what he'd be willing to run
[00:51:18.240 --> 00:51:24.000]   his... Through his printing press and what he would be putting out over his name in his newspaper.
[00:51:24.000 --> 00:51:30.320]   If we don't know, we're actually not sure. We... Historians aren't sure what the apology is referring
[00:51:30.320 --> 00:51:35.200]   to. What kerfuffle, because they don't have the record. It was probably an ad in the newspaper.
[00:51:37.600 --> 00:51:46.800]   But we also have John Milton. John Milton wrote the legendary Ario Pajitica in 1644
[00:51:46.800 --> 00:51:53.920]   against the licensing of books in the UK. I saw a lot of parallels between the oversight board
[00:51:53.920 --> 00:51:58.400]   and the stationers company, which was a private entity that was supposed to license and protect
[00:51:58.400 --> 00:52:04.480]   us from bad books. Milton was inspired and a great measure by his visit to Galileo, while Galileo
[00:52:04.480 --> 00:52:10.400]   was on house arrest because he had dangerous ideas. Milton is saying that if we don't exercise our minds
[00:52:10.400 --> 00:52:17.840]   by hearing the good and the bad and finally deciding what is good, then I'll be less
[00:52:17.840 --> 00:52:24.320]   articulate with him. We're going to end up with mush minds. That's why I like Jack's view.
[00:52:24.320 --> 00:52:28.480]   Leave it up. It's out there anyway. The New York Times is going to report it. It's going to be all
[00:52:28.480 --> 00:52:34.240]   over. But Jack had a stand. Jack said this incites violence. That's the question I have.
[00:52:34.960 --> 00:52:43.360]   I mean, it was very late to the game. Oh, you want? And I disagree with the stand about ads.
[00:52:43.360 --> 00:52:47.760]   I just agree with lots of things. I'm just saying that in this one moment in time,
[00:52:47.760 --> 00:52:53.760]   I'll praise the one and put more on the other. I will say that Jeff, you are in the minority.
[00:52:53.760 --> 00:53:01.280]   According to Pew, not 88% of Americans say that social media companies now have at least some
[00:53:01.280 --> 00:53:09.360]   control over the mix of news that people see each day. 55% of us adults get their news from social
[00:53:09.360 --> 00:53:17.520]   media either often or sometimes, which is up 8% from 2018. 28% say they get their news often from
[00:53:17.520 --> 00:53:23.280]   social media up from 20% in 2018. So that's that's what what does that mean, Leo? That means
[00:53:23.280 --> 00:53:28.400]   oftentimes get their news from Facebook. Who do I thought it's not Facebook? It's the who are you
[00:53:28.400 --> 00:53:35.520]   who you choose to follow on Facebook. Facebook shows you things that once you start clicking
[00:53:35.520 --> 00:53:39.440]   on things, Facebook will start showing you more things like it. And that's how you get people
[00:53:39.440 --> 00:53:45.760]   escalating down this weird trail of like conspiracy theories and anti-vax data or
[00:53:45.760 --> 00:53:51.120]   think about all the stuff targeting moms around Facebook shows you a subset of the people you
[00:53:51.120 --> 00:53:56.240]   follow full stop. So if you don't follow, you don't see Alex Jones should follow.
[00:53:56.960 --> 00:53:59.680]   It also recommends who you will follow. It does.
[00:53:59.680 --> 00:54:04.880]   But I don't think that's I would argue that's not a major factor and I want to see the evidence.
[00:54:04.880 --> 00:54:09.920]   No, that is not true at all because when I like when you go on Facebook and it's like, oh,
[00:54:09.920 --> 00:54:16.080]   you know, it's kind of like you're interested in this. Their whole business model is to find
[00:54:16.080 --> 00:54:21.280]   demographics that you fit in and to draw your attention to those things. And they do a really
[00:54:21.280 --> 00:54:27.680]   good job of it. And if you're sort of trying out weird ideas, they'll help you try those out
[00:54:27.680 --> 00:54:31.840]   till you get all the way down the path of those weird ideas. That's what they do.
[00:54:31.840 --> 00:54:35.840]   That's how they make the real problem. The real problem I have with both of your arguments here
[00:54:35.840 --> 00:54:41.680]   is that it's a case of the third person effect, right? That there's tons of people out there
[00:54:41.680 --> 00:54:45.920]   that are affected by this, but I'm okay. I'm above it. But there's a lot of people who are just too
[00:54:45.920 --> 00:54:50.720]   stupid for this. And I think we always that's what that's what both Franklin and you'll do.
[00:54:50.720 --> 00:54:58.560]   I'm not trying to say. You weren't a little bit ago, but then you started into the old
[00:54:58.560 --> 00:55:02.480]   algorithm is really taking people down a bad spot and it's going to ruin them. I don't I don't
[00:55:02.480 --> 00:55:08.000]   buy that. Researchers have looked at Facebook and seen that people are unaware that the algorithm
[00:55:08.000 --> 00:55:12.080]   is picking stuff up for them and even the next step. What post their friend they see.
[00:55:12.080 --> 00:55:17.440]   Yeah, the next step is that does this change their does this change their whole worldview?
[00:55:18.320 --> 00:55:23.600]   I don't change everybody's know it does change in it. I think they were already there, man.
[00:55:23.600 --> 00:55:26.480]   They were already there, which goes back to our first discussion.
[00:55:26.480 --> 00:55:29.920]   Have you been to the United States? Where the races are going to find racist.
[00:55:29.920 --> 00:55:33.120]   Sorry, Carson, you're going to have that. No, you're wrong. That's real.
[00:55:33.120 --> 00:55:37.920]   How many things have you bought based on seeing Instagram ads for what was that lit in shirt that
[00:55:37.920 --> 00:55:43.200]   you think? Some jacket. I would buy a real lead. That's why I also delete my
[00:55:43.200 --> 00:55:51.200]   Instagram. My lord Stacy Stacy. I would not wear a jacket. You bought some weird jacket. I remember
[00:55:51.200 --> 00:55:56.800]   that by a jacket on Instagram. People couple them. Nice. Nice. Nice. It's a nice jacket. What's the
[00:55:56.800 --> 00:56:04.400]   problem? Yeah. Yeah. I watch the show. There's no ads on them. You get anything enough time.
[00:56:04.400 --> 00:56:12.880]   There's influence and you go down that path and especially in this is really important if you are
[00:56:12.880 --> 00:56:19.200]   in a vulnerable spot or maybe you feel sad or whatever. If you feel that,
[00:56:19.200 --> 00:56:24.880]   then you're more vulnerable to those messages. Yes, you could be smart as anything, but you're
[00:56:24.880 --> 00:56:28.160]   still going to buy the jacket. Don't show me those studies. People are. People are not. That's the
[00:56:28.160 --> 00:56:31.440]   first person effect. Look, that's some people are vulnerable, but I'm not. People are not. They're
[00:56:31.440 --> 00:56:35.680]   vulnerable out there. This is going to affect them. They're people, but I'm not. People are not
[00:56:35.680 --> 00:56:41.120]   born racist. That's not. Oh, they're trained. The race is very early on. They're trained racist.
[00:56:41.680 --> 00:56:46.640]   And you see their parents. Oh, it's only their parents. That's my face book. Oh, wait a minute.
[00:56:46.640 --> 00:56:52.000]   You're saying only the parents are in that perfectly sane, well-educated, normal person and give
[00:56:52.000 --> 00:56:55.440]   them Facebook for a week and they're going to turn into a complete not for a week. But there's a
[00:56:55.440 --> 00:57:00.480]   gradual erosion. Oh, no. You don't think the same as the myth is the myth of the filter bubble.
[00:57:00.480 --> 00:57:06.960]   Do you think that the that the anti-vax movement would be as widespread and strong as it is without
[00:57:06.960 --> 00:57:10.880]   the help of social. Yes. Yes. Yes. Because I've been in the kinds of towns. No, it would not.
[00:57:10.880 --> 00:57:16.160]   It would not. Absolutely. I lived in Austin. Austin.
[00:57:16.160 --> 00:57:21.200]   Austin. Oh, she's frozen. Hold on a sec. We'll get her back.
[00:57:21.200 --> 00:57:27.040]   Well, that horrible sound. That ringing back. There you are. You're back. You said you lived in
[00:57:27.040 --> 00:57:33.120]   Austin and then you froze. I lived in Austin by friends with who went to Waldorf schools. I can
[00:57:33.120 --> 00:57:39.360]   tell you that not everybody is anti-vax, but with Facebook more and more of them were. They would
[00:57:39.360 --> 00:57:45.840]   consider things that they wouldn't consider before. And from consideration, absent, absolute scientific
[00:57:45.840 --> 00:57:54.080]   certainty, you can be able to get into your predisposition. But if you didn't consume these
[00:57:54.080 --> 00:57:58.080]   kinds of, it's YouTube too, by the way, YouTube, Twitter and Facebook, but YouTube and Facebook
[00:57:58.080 --> 00:58:03.040]   primarily for normal people. And I think you might have a predisposition to believe that thing,
[00:58:03.040 --> 00:58:08.880]   but it's the constant repetition of it from a variety of sources that we just go, "Oh, well,
[00:58:08.880 --> 00:58:13.920]   everybody believes this. It must be true." Let me be very clear that we know what we know about the
[00:58:13.920 --> 00:58:21.840]   murder of George Floyd from a 17-year-old putting the video up on Facebook. That is how we know.
[00:58:21.840 --> 00:58:25.280]   Because mainstream media isn't covering this, never covering this. It's only because of living
[00:58:25.280 --> 00:58:30.080]   while Black and Black lives matter on social media that we have the movements we have now
[00:58:30.080 --> 00:58:36.000]   to try to tear down the racism that you say is being built there. So this is what Franklin is saying.
[00:58:36.000 --> 00:58:41.600]   You're going to have both. And at the end, the only solution to this is not an algorithm and not a
[00:58:41.600 --> 00:58:47.840]   regulation. It's education, full stop. And the problem is that there are uneducated people who
[00:58:47.840 --> 00:58:52.160]   don't respect science and don't respect other people. And that's our problem in society. And we're
[00:58:52.160 --> 00:59:00.320]   ignoring that fundamentally by trying to blame in, get ready? Get ready? More old panic about
[00:59:00.320 --> 00:59:07.360]   the technology and the algorithm. We're going for an easy, bad guy and an easy answer. The problem is
[00:59:07.360 --> 00:59:13.600]   this country has devalued education over generations. I think it's more nuanced than that. I think that
[00:59:13.600 --> 00:59:24.320]   all humans have a lot of inputs. And you can drown out some bad inputs like Facebook
[00:59:24.960 --> 00:59:31.760]   with good inputs like education. But don't call Facebook entirely a bad influence.
[00:59:31.760 --> 00:59:37.520]   Or I just say about about George Floyd. Well, I'm not convinced that the news media
[00:59:37.520 --> 00:59:41.200]   was missing entirely. You are dismissing the people who are using this platform for that purpose.
[00:59:41.200 --> 00:59:45.520]   I'm not convinced that the news media didn't have a lot to do with the dissemination of that story.
[00:59:45.520 --> 00:59:51.760]   After that, yes, but the only way it started was because of course they did. Of course they did.
[00:59:51.760 --> 00:59:56.080]   But it started because that's brave, probably scarred for life, 17 year old girl.
[00:59:56.080 --> 01:00:04.320]   Young woman had the courage to record a murder by police in front of her and put it onto social
[01:00:04.320 --> 01:00:09.520]   media because that was what she was capable of, which wasn't there years ago. So it was much easier.
[01:00:09.520 --> 01:00:11.120]   It was much easier for her. It was much easier for her.
[01:00:11.120 --> 01:00:12.320]   This Facebook has his publishing.
[01:00:12.320 --> 01:00:16.080]   It's really bad. That has no nuance, Leo. That has zero nuance.
[01:00:19.520 --> 01:00:25.680]   You're dismissing all the voices that are then there. That is Franklin's point. That is Milton's point.
[01:00:25.680 --> 01:00:31.680]   Well, I've got to give people respect in the arguing for zero control. I think there's a
[01:00:31.680 --> 01:00:39.760]   mistake to show to show some control because I think that's misleading. And it also lends to
[01:00:39.760 --> 01:00:45.120]   editorializing by some guy who just happened to get it.
[01:00:45.120 --> 01:00:52.560]   Jacked the wrong thing. I don't know. I mean, I choose to avoid the streams, to be honest with you.
[01:00:52.560 --> 01:00:56.000]   No, I think I think he did the right thing on Twitter. Is that what we're talking about?
[01:00:56.000 --> 01:00:59.280]   Yeah. Yeah. Yeah. I'm just making sure I just want to clarify.
[01:00:59.280 --> 01:01:06.080]   What decision do you think if you could sit down with Zuckerberg at a very nice dinner in his house
[01:01:06.080 --> 01:01:09.120]   and tell him, and he left saying, you're right, Stacy, what would you tell him?
[01:01:09.120 --> 01:01:11.360]   That's a good question.
[01:01:14.320 --> 01:01:14.960]   I don't know.
[01:01:14.960 --> 01:01:20.640]   We talked about memcache. So I'm like, well, I don't know.
[01:01:20.640 --> 01:01:23.760]   Oh, no, we froze again.
[01:01:23.760 --> 01:01:30.720]   Oh, it's a good. That's a good way to freeze, though. I think that's literally Stacy's response.
[01:01:30.720 --> 01:01:36.080]   Oh, man. That was awesome.
[01:01:36.080 --> 01:01:40.720]   No, I think that's a great question because,
[01:01:41.280 --> 01:01:46.000]   yeah, I mean, I really, I don't, this is a tough, this hard. It's very difficult. Yeah.
[01:01:46.000 --> 01:01:47.520]   Very hard. Stacy.
[01:01:47.520 --> 01:01:52.960]   So, so, yeah, I'm like, oh, have you bought yourself time with a freeze there?
[01:01:52.960 --> 01:01:59.520]   I would. No, sorry. I would ask him where his loyalties lie. I think I would, I would want to
[01:01:59.520 --> 01:02:06.000]   understand, do you want, is this a moment to do the best for your business? Is this the moment to do
[01:02:06.000 --> 01:02:10.400]   the best for the country? Is there a larger picture that you should think about here?
[01:02:10.960 --> 01:02:18.000]   Uh, because for his business, maybe it's, I don't know if, you know, he knows way more about what's
[01:02:18.000 --> 01:02:22.400]   going on under the covers of Facebook than I do. So maybe that's the right decision based on his
[01:02:22.400 --> 01:02:30.640]   strategy and where he's trying to take it. But as a businesses do not exist, I know they, they
[01:02:30.640 --> 01:02:36.800]   feel like they do today, but they, they exist as part of a society. And I don't think it was the
[01:02:36.800 --> 01:02:40.560]   right decision for society. And I would try to convince him of that.
[01:02:40.560 --> 01:02:46.960]   I have to say, I have to say, neither Facebook nor Twitter had any difficulty
[01:02:46.960 --> 01:02:51.360]   with COVID-19 and blocking bad information.
[01:02:51.360 --> 01:02:59.680]   Science a lot different from politics. Right. So, so I think that it's possible to do a good job
[01:02:59.680 --> 01:03:05.360]   in some circumstances. It's much more difficult when you have a norm-busting president.
[01:03:05.920 --> 01:03:12.400]   Uh, who was willing to, you know, use those platforms for his own ends to know how to handle
[01:03:12.400 --> 01:03:17.040]   this because the norm says the president should have a bully pulpit. Now it's Denise Halpp pointed
[01:03:17.040 --> 01:03:23.920]   out on a Sunday. He doesn't, he's got a bully pulpit with her without Twitter. Yeah. So, uh, but it's,
[01:03:23.920 --> 01:03:28.800]   but he's very, very good at using Twitter and Brad Parscale, his campaign manager is very,
[01:03:28.800 --> 01:03:35.440]   very good at using Facebook. Uh, and, uh, that's a, that is a lot harder than saying, well,
[01:03:35.440 --> 01:03:40.480]   this is bad scientific information. So I don't know. And that's the problem is who should be the
[01:03:40.480 --> 01:03:45.840]   arbiter of truth. It's one thing to say is to be the arbiter of truth in science. True. In this
[01:03:45.840 --> 01:03:50.880]   case, it's, it's decency. It's, it's, I don't want to use the word civility because that's loaded,
[01:03:50.880 --> 01:03:54.240]   but that's what Stacy was saying in a minute ago. It's what I'm trying to say too. What do you
[01:03:54.240 --> 01:04:00.080]   stand for? What do your companies stand for? Right. You choose to sell cigarettes or not.
[01:04:00.080 --> 01:04:04.160]   CVS at some point said we're in the health business. We're not going to sell cigarettes.
[01:04:04.160 --> 01:04:09.040]   Right. I have to say some of the things Newton talks about in this phone call,
[01:04:09.040 --> 01:04:16.240]   85 minute recording that he reviewed on the verge. Here's a quote from Zuckerberg. If we're
[01:04:16.240 --> 01:04:21.520]   entering a period where there may be a prolonged period of civil unrest, then that might suggest
[01:04:21.520 --> 01:04:25.440]   we need different policies, even just temporarily in the US for some period,
[01:04:25.440 --> 01:04:30.240]   compared to where we were before. Who's saying that? Zuckerberg Zuckerberg Zuckerberg.
[01:04:30.240 --> 01:04:34.720]   And we have some precedence for what that might look like. He's talking about the COVID
[01:04:34.720 --> 01:04:40.800]   misinformation. So I think he's thinking about this. I don't think Mark is
[01:04:40.800 --> 01:04:42.960]   No, it's not. Why?
[01:04:42.960 --> 01:04:52.160]   I'm rightfully planning his world domination, I don't think. But it's very difficult with
[01:04:52.160 --> 01:04:58.560]   a politician and politics compared to science. So Stacy, what do you think about Snap's decision?
[01:04:58.560 --> 01:05:02.400]   What was Snap's decision? So the difference here is Snap,
[01:05:02.400 --> 01:05:12.240]   one second pre-emble. Facebook says we will not judge anything off platform. We will only judge
[01:05:12.240 --> 01:05:17.040]   that which you put on the platform, which is why it took so long for them to get to Alex Jones.
[01:05:17.040 --> 01:05:20.240]   They were judging that. It's why these other sites that are still up there, it's an issue.
[01:05:20.240 --> 01:05:24.240]   Snap said, we're going to judge what you do on other platforms. We're going to do off the world,
[01:05:24.240 --> 01:05:29.920]   and we're not going to promote you. So Snap made a different decision that was about
[01:05:29.920 --> 01:05:35.200]   their disapproval of not what he did on their platform, but who he is and what he does.
[01:05:35.200 --> 01:05:36.480]   What do you think of that?
[01:05:37.680 --> 01:05:43.440]   So given Snap's audience, I'm okay with that. Just because
[01:05:43.440 --> 01:05:51.600]   They're even more mush-mind did. Yeah, well, no, I just they're younger, they're more
[01:05:51.600 --> 01:06:01.280]   influencer-influenceable. More easily influenced. And I also think that
[01:06:04.480 --> 01:06:10.720]   I think that the president is doing such a bad job right now in terms of the country,
[01:06:10.720 --> 01:06:17.440]   that it's hard not to take a stand against him. I guess, or it's hard not to take a stand
[01:06:17.440 --> 01:06:21.600]   that's pretty. It's not just that he's a polarizing figure. He's also,
[01:06:21.600 --> 01:06:31.280]   this hurts me. He doesn't live up to what I think America's ideals are. Even if you want to take
[01:06:31.280 --> 01:06:37.200]   the cynical view of what America's ideals are. So I feel like if you are a business owner and
[01:06:37.200 --> 01:06:43.120]   you overlook this, it really does feel like you're complicit in something that you're going to
[01:06:43.120 --> 01:06:48.000]   regret later on. And so I understand why Snap would make that decision.
[01:06:48.000 --> 01:06:50.480]   So the other question Leo asked me a while ago. Sorry.
[01:06:50.480 --> 01:06:54.400]   Let's go to the ask you a little bit. It's also a much smaller platform.
[01:06:54.400 --> 01:07:00.240]   So, but yeah, go ask your deep thoughts. The other question Leo asked a while ago.
[01:07:00.240 --> 01:07:02.880]   Do you think this was good or bad for Snap's business?
[01:07:02.880 --> 01:07:07.280]   Just to pick on that. I think it's probably going to be good for Snap's business. I mean,
[01:07:07.280 --> 01:07:14.560]   it's not a Facebook. Do I think it would probably be a little bit harmful to Facebook's business in
[01:07:14.560 --> 01:07:20.960]   the short term. Which would be? I think Facebook speak to for Facebook to take a stand against
[01:07:20.960 --> 01:07:26.400]   what Trump's message. The cynic would say, oh, Facebook's looking forward to the windfall
[01:07:26.400 --> 01:07:32.480]   profits from Trump's massive ad campaigns. They've already spent many millions of dollars and plan
[01:07:32.480 --> 01:07:38.800]   to spend many more before November. That's pretty cynical. And I think Mark's probably made enough
[01:07:38.800 --> 01:07:44.480]   money that he can afford not to take. I wish, I honestly wish Facebook would say we're not going
[01:07:44.480 --> 01:07:48.640]   to do any political ads. That would be something I would ask Mark to do at dinner.
[01:07:48.640 --> 01:07:53.120]   You see, I was against that at Twitter. I thought that was the wrong move. I can't
[01:07:53.120 --> 01:07:56.480]   remember what you said at the time, Stacey. I don't remember what I said.
[01:07:56.480 --> 01:08:02.880]   What would be wrong with Facebook saying, yeah, we can't control it. We got the Russians. I don't
[01:08:02.880 --> 01:08:08.960]   know what's going on. Well, let's just stop taking ad money for political ads. Because it's my
[01:08:08.960 --> 01:08:13.120]   Congressperson here, especially right now. I'll give you the answer right now. Because I want to
[01:08:13.120 --> 01:08:17.360]   work with my Congressperson here. And I can't go knocking at any of yours. What I can do is give
[01:08:17.360 --> 01:08:23.040]   money to put ads up on Facebook targeted. I thought Facebook didn't even talk to our
[01:08:23.040 --> 01:08:33.600]   district. Ads ads do. Oh, ads do ads do. But not the news announcements from my friends telling
[01:08:33.600 --> 01:08:38.640]   like everything else. It's a terrible vaccine experience. It's a playing field, right? Yes.
[01:08:38.640 --> 01:08:45.760]   You can you can put up stuff to either side of anything. Witness, witness Benjamin Franklin once
[01:08:45.760 --> 01:08:52.720]   again. And then it's a playing field. It's there. You get rid of if you get rid of all
[01:08:52.720 --> 01:08:58.480]   social media targeted advertising. My problem is that you're left with television.
[01:08:58.480 --> 01:09:03.680]   You're left with big money. I don't think political ads in general are a good idea.
[01:09:03.680 --> 01:09:09.440]   Period. Well, there's that period. There's that there's sure they can they and other countries.
[01:09:09.440 --> 01:09:13.200]   Yeah, they don't. Yeah, let's just ban. I mean, but since we don't ban political ads,
[01:09:13.200 --> 01:09:17.920]   we don't. We can afford to do that. Yeah, but we could afford to do that on social media.
[01:09:17.920 --> 01:09:22.000]   If you're going to do it on one, you're then driving that. Well, it would be nice to do it elsewhere.
[01:09:22.000 --> 01:09:27.520]   But since, but let's we're talking about Facebook here. I'm not talking about ABC's decisions.
[01:09:27.520 --> 01:09:33.680]   But why wouldn't I am just cutting a big money? Only big money can then run for office in this
[01:09:33.680 --> 01:09:40.720]   country, including small offices. I don't think that's true because I don't. My daughter is not on
[01:09:40.720 --> 01:09:49.040]   TV. I am not on TV. Like, I don't see ads unless they're on the internet period or in a physical
[01:09:49.040 --> 01:09:54.160]   magazine. You're probably unusual, though. Yeah, you are. You're you're you're a com I don't know in a
[01:09:54.160 --> 01:10:05.360]   generation. It would be interesting to see like how how that has changed because it has changed.
[01:10:05.360 --> 01:10:12.400]   And I don't think it's that unusual in a certain demographic. Actually, I blocked all the ads on
[01:10:12.400 --> 01:10:19.120]   Facebook while I was on Facebook. So I didn't see any ads. So Joe Trippy said in his what when did
[01:10:19.120 --> 01:10:26.160]   Joe Trippy write it? Joe Trippy book. That's one of the parts of the internet. The revolution will
[01:10:26.160 --> 01:10:32.320]   not be televised 2004. So he said television was over then. We then have citizens united. We still
[01:10:32.320 --> 01:10:39.280]   have big money involved in all the elections. And it's not just Facebook. Facebook is actually
[01:10:39.280 --> 01:10:45.280]   little money. It's not it's pretty damn cheap. It's quite cheap. Super cheap. Oh my gosh. I can
[01:10:45.280 --> 01:10:50.800]   run a campaign on Facebook for so little. Yeah. Sorry. Right. They're very effective too.
[01:10:53.440 --> 01:11:01.600]   $21 million spent on Facebook ads by the Trump campaign in 2018.
[01:11:01.600 --> 01:11:08.000]   How much revenue? 2018. I mean, they may be cheap, but if you buy a lot of them, it adds up.
[01:11:08.000 --> 01:11:12.160]   That's true. Mine. I'm not spending that much. But wow. Go them.
[01:11:12.160 --> 01:11:16.400]   Facebook revenue in 2018 was $55 billion.
[01:11:20.240 --> 01:11:29.360]   Trump bought 286,476 ads in 2019. It's spending $21.5 million.
[01:11:29.360 --> 01:11:40.080]   And Clinton unfortunately didn't. This was by the way. This wasn't in 2016. This was last year.
[01:11:40.080 --> 01:11:45.760]   Last year. The campaign goes on. Brad, Brad, Brad, Brad, Para,
[01:11:45.760 --> 01:11:49.680]   Scall gets a huge cut of that. Oh yeah. He's got several Ferraris.
[01:11:49.680 --> 01:11:52.480]   Yes. And a yacht. And a yacht.
[01:11:52.480 --> 01:12:01.120]   All right. Well, I don't think we're ever going to solve this, but we gave it the college try.
[01:12:01.120 --> 01:12:05.600]   Well, we gave it the jacket. We yelled at each other for a while.
[01:12:05.600 --> 01:12:13.200]   I didn't yell at you. I yelled at Leo. I'm offended. Horribly offended, Jeff.
[01:12:14.960 --> 01:12:19.280]   So offended. Get me to yell about Pixelbuds. That'll get me to yell.
[01:12:19.280 --> 01:12:22.960]   You still haven't trouble with him? I sent back the second pair.
[01:12:22.960 --> 01:12:28.640]   And now there's stories saying they don't work. I guess I just never should buy anything early.
[01:12:28.640 --> 01:12:36.400]   Just Google. Just maybe Google isn't good at headphones. Let's just go with that.
[01:12:36.400 --> 01:12:39.440]   Maybe. Yeah, maybe. You know what? They're wonderfully designed.
[01:12:39.440 --> 01:12:42.800]   Oh, they're beautifully designed. I love them, but they don't work.
[01:12:42.800 --> 01:12:49.120]   You know what's grind in my gears? Tell us. What HBO Max.
[01:12:49.120 --> 01:12:53.520]   AT&T, which of course is the corporate parent.
[01:12:53.520 --> 01:13:09.040]   That was good. I like this. Let me repeat that. HBO Max. Remember the world? Remember net neutrality?
[01:13:10.160 --> 01:13:17.040]   Remember the idea that a company shouldn't favor its own content or paid content over
[01:13:17.040 --> 01:13:24.560]   competing company's content? Remember when the FCC chairman said, "Oh, that's just nobody.
[01:13:24.560 --> 01:13:30.640]   That would never. We don't need that." Eli Patel writing an article. Very upset. And he's right.
[01:13:30.640 --> 01:13:38.720]   AT&T has announced that any content coming in over HBO Max will not affect your data caps
[01:13:38.720 --> 01:13:42.240]   if you're an AT&T subscriber. However, Netflix and Disney+ certainly will.
[01:13:42.240 --> 01:13:45.760]   That it sounds a little bit competitive to me.
[01:13:45.760 --> 01:13:50.720]   Super any competitive. So any competitive that when Comcast bought universal,
[01:13:50.720 --> 01:13:57.120]   we actually, the FCC and the FTC said, "Hey, for the next seven years, you cannot prioritize
[01:13:57.120 --> 01:14:03.120]   your content and Comcast said, "Sure." But that deal, it'll be up soon. And what we're seeing here
[01:14:03.120 --> 01:14:10.080]   is the end of net neutrality. And I tweeted this. I'll say it again for everybody who didn't see it.
[01:14:10.080 --> 01:14:18.080]   This is important because it puts a cost associated with independent content, like Leo.
[01:14:18.080 --> 01:14:22.800]   But also things like, "Hey, are you going to watch a protest video and suck up your data cap? Are
[01:14:22.800 --> 01:14:27.040]   you just going to sit back and enjoy friends? My God, you're going to watch friends."
[01:14:27.040 --> 01:14:34.960]   Yeah, of course you are. AT&T owns HBO Max. AT&T will say, "No, no, no, no. We have this
[01:14:34.960 --> 01:14:43.520]   sponsored data system. Any company can pay us to excuse the service from data caps."
[01:14:43.520 --> 01:14:50.240]   But of course, AT&T owns HBO Max. So it's just shuffling money from one division to another.
[01:14:50.240 --> 01:14:58.480]   And Neelai says, "There were only three streaming services that pay for sponsored data on AT&T's network.
[01:14:58.480 --> 01:15:05.360]   They're all owned by AT&T. All owned by AT&T." What a regulate something.
[01:15:05.360 --> 01:15:13.120]   But AT&T, I remember promised that they would never do such a thing.
[01:15:14.400 --> 01:15:20.640]   Never believe the telcos. Never, ever, ever. These are people who the internet was a gift
[01:15:20.640 --> 01:15:28.560]   they didn't want. They didn't build for it. And now they want to charge you for every second.
[01:15:28.560 --> 01:15:35.520]   And the idea of actually making a bigger internet and then having a bigger pie for everything else,
[01:15:35.520 --> 01:15:40.800]   totally not in their worldview. It drives me absolutely bonkers. I hate them. I hate them.
[01:15:42.240 --> 01:15:46.080]   I'm done. And then there's the German newspaper that is delivering beer.
[01:15:46.080 --> 01:15:54.400]   So, yes. This is from Jeff's Buzz Machine blog. Everybody loves this one. So I was reading
[01:15:54.400 --> 01:15:58.800]   Teatsite. Teatsite took a drink. He has to be here. There's some German words for you this week.
[01:15:58.800 --> 01:16:06.480]   And the Mindana Taga Blat newspaper saw that their local merchants were suffering. And they
[01:16:06.480 --> 01:16:13.120]   already had a fulfillment operation, which was delivering newspapers and taking ad material and
[01:16:13.120 --> 01:16:20.480]   doing things like that. So they started delivering beer, shoes, and office supplies. It's not going
[01:16:20.480 --> 01:16:25.600]   to make them rich. They have a 250-350 Euro.
[01:16:25.600 --> 01:16:30.000]   The shoes story. I think we talked about beer and shoes last week, didn't we?
[01:16:30.000 --> 01:16:34.640]   Wasn't that the title? I think it was the title of the show. Well, no, I didn't put two and two
[01:16:34.640 --> 01:16:41.280]   together. No, we didn't talk about this last week on this show. I know you do a lot of shows,
[01:16:41.280 --> 01:16:46.560]   Leo. I do a lot of shows. If I could just get this fine Zimshitneki.
[01:16:46.560 --> 01:16:52.320]   So then Zimshitneki, my colleague, who used to work at their standard in Austria,
[01:16:52.320 --> 01:16:57.760]   said they bought a local bread company. So you could get bread delivered every day,
[01:16:57.760 --> 01:17:01.840]   click on the link with the news. I want my Zimshitneki.
[01:17:03.760 --> 01:17:11.040]   That looks good. It does look good. So, there we go. You get a whole thing.
[01:17:11.040 --> 01:17:19.120]   Oh, Stacey, look at this delivered every day. Basket. Basket put a croissants in.
[01:17:19.120 --> 01:17:22.640]   Crescents with a cinnamon roll in there. It's cinnamon roll.
[01:17:22.640 --> 01:17:30.400]   Zimshitneki. Zimshitneki. And a shoko muffin. And then orange zuffed. And the darbo mama lada.
[01:17:32.320 --> 01:17:39.920]   And some corn spit. Oh, I'm sorry. It's bio corn spits. Yum yum.
[01:17:39.920 --> 01:17:43.040]   Beosh corn spits. Yum yum.
[01:17:43.040 --> 01:17:49.840]   Okay, where's the where's the Nutella? Don't they have Nutella in Germany?
[01:17:49.840 --> 01:17:56.000]   This is that's Austria. Oh, it's Austria. I don't ever remember. I'm never was a fan of Nutella.
[01:17:56.000 --> 01:17:59.520]   You guys, Nutella fans? I love Nutella. I mean, it's,
[01:17:59.520 --> 01:18:03.680]   yes, Stacey. We're great watching. I know it's not real food, but it's good. It's too sweet.
[01:18:03.680 --> 01:18:06.000]   Yeah, it's too sweet. I just feel bad. Like when people are like,
[01:18:06.000 --> 01:18:11.120]   eh, it's all right. They're like, no, but you know what's too sweet and delicious?
[01:18:11.120 --> 01:18:20.560]   Last pass. Yes. Very good. It sounded like you were going into an atom. Like, let's see.
[01:18:20.560 --> 01:18:27.360]   Actually, I wasn't, but that's good idea. I think, I think I agree with you that last pass
[01:18:28.160 --> 01:18:36.080]   is delicious. It just sounded like a segment of it. I was like, what's the, what's the cookies
[01:18:36.080 --> 01:18:42.160]   that you're speculose that you grind up and make speculose. Oh, I like those. No, you get them on the
[01:18:42.160 --> 01:18:47.680]   airplane. Yeah, but don't eat the cookies, grind them into peanut butter like consistency.
[01:18:47.680 --> 01:18:51.360]   And you get something called speculose butter, which is even sweeter.
[01:18:52.640 --> 01:18:59.440]   Can't eat it than last pass, but delicious. I showed it. I brought to you my last pass.
[01:18:59.440 --> 01:19:05.040]   As you send your employees home, you know, I feel like we were so well prepared.
[01:19:05.040 --> 01:19:09.200]   We didn't know about work from home. We weren't planning on it. In fact,
[01:19:09.200 --> 01:19:13.280]   we really like our employees to come into the office. In fact, I missed the social environment,
[01:19:13.280 --> 01:19:18.640]   the one's the office, but when the virus came along, of course, we sent everybody home.
[01:19:18.640 --> 01:19:22.480]   And I feel like just by maybe by accident, I don't know, we were really well prepared.
[01:19:22.480 --> 01:19:26.880]   This has been great. One of the things that we did some years ago that really helped,
[01:19:26.880 --> 01:19:32.960]   we started using last pass enterprise. When you send employees home, suddenly they're no longer
[01:19:32.960 --> 01:19:40.400]   in the warm bath, the warm protective bath of the IT department at work. They are out there in the
[01:19:40.400 --> 01:19:48.160]   real world. And God knows what kind of internet situation and they're logging into your stuff.
[01:19:48.560 --> 01:19:53.680]   They're logging into your bank accounts and your databases. And we have to. Our
[01:19:53.680 --> 01:19:58.160]   accountant, Robin, has to be doing that. She does it from the house. Thank goodness she's using
[01:19:58.160 --> 01:20:03.360]   LastPass. To make sure your business keeps running smoothly, every employee login is secure.
[01:20:03.360 --> 01:20:07.840]   And they do it in a lot of ways. Of course, everybody knows LastPass is the greatest password
[01:20:07.840 --> 01:20:13.680]   manager. Their enterprise grade password management gives insurers oversight of shadow IT enforceable
[01:20:13.680 --> 01:20:18.800]   policies across all password protected accounts. It makes it easy for employees to share passwords
[01:20:18.800 --> 01:20:23.440]   securely. And I can go on and on and on. But it's more than just password management.
[01:20:23.440 --> 01:20:30.080]   There's also single sign on LastPass with their LastPass enterprises embraced single sign on apps.
[01:20:30.080 --> 01:20:35.120]   They have 1200 plus apps that you can use. And that's actually better than passwords.
[01:20:35.120 --> 01:20:39.360]   It's both easier and more convenient for employees and more secure than passwords.
[01:20:40.480 --> 01:20:47.840]   There's also multi factor authentication. I love this. Make sure that that user is really that
[01:20:47.840 --> 01:20:53.920]   user. And I'm not just talking about thumb printer face ID. It's it's it's biometrics, yes, but also
[01:20:53.920 --> 01:21:00.560]   contextual factors, things like geolocation and IP address. It makes the process smoother for
[01:21:00.560 --> 01:21:07.520]   your employees and it makes it more secure for you. IT always has full insight into exactly who
[01:21:07.520 --> 01:21:14.000]   has access to what and from where it your your secure your safe even though your employees are
[01:21:14.000 --> 01:21:19.360]   out there in the real world. And one of the things you'll love is you know that LastPass
[01:21:19.360 --> 01:21:24.720]   vault is never decrypted anywhere but on device and every device Android iOS, Windows, Mac,
[01:21:24.720 --> 01:21:31.440]   Linux, whatever you use smart TVs everywhere. LastPass works. Only users can get access to their
[01:21:31.440 --> 01:21:38.640]   data. It's encrypted with 256 bit AES and it never the master password is never stored
[01:21:38.640 --> 01:21:44.560]   or sent. LastPass doesn't have it. And that's good news because if they don't have it neither
[01:21:44.560 --> 01:21:51.040]   back guys can't get it. LastPass protects you and your business and still provides a seamless
[01:21:51.040 --> 01:21:57.680]   workflow for your employees. That's why I say it's super sweet. Account access and passwords can
[01:21:57.680 --> 01:22:04.160]   easily be shared between employees. It's easy to onboard new employees because we have folders
[01:22:04.160 --> 01:22:08.240]   that makes it possible to add somebody to a group and boom they've got all the passwords.
[01:22:08.240 --> 01:22:15.760]   And things like single sign on just make it easier multi-factor authentication. Your IT department
[01:22:15.760 --> 01:22:21.600]   will love it. Your employees will love it. You will love it. LastPass can help make remote work
[01:22:21.600 --> 01:22:27.040]   simple and secure go to lastpass.com/twit to find out how they can help you stay productive and
[01:22:27.040 --> 01:22:32.880]   secure no matter what. No matter where. They even I love it even works offline.
[01:22:32.880 --> 01:22:38.880]   So when your employees you know like Stacey it drops out once in a while don't worry they still
[01:22:38.880 --> 01:22:45.920]   get the multi-factor they still get the passwords. LastPass.com/twit. We thank you so much for their
[01:22:45.920 --> 01:22:54.560]   support. I was thinking specular splatter. Yes. Almost. Yes. 53 minutes ago. Yes. Medium sends
[01:22:54.560 --> 01:22:59.840]   out a message to its contributors like me. Yeah. That it now offers newsletters.
[01:22:59.840 --> 01:23:04.400]   So as my friend David Cohen said does medium become a sub stack or does sub stack become medium?
[01:23:04.400 --> 01:23:12.160]   Well you know. Because of you Jeff I gave them their five bucks a month. Yay. Because of you I
[01:23:12.160 --> 01:23:19.760]   put everything up on Buzz machine so you didn't have to. I realized yeah I was blowing it. I was
[01:23:19.760 --> 01:23:24.800]   blowing it. I was you know it's only five bucks a month and I use it so often. Let me just sign
[01:23:24.800 --> 01:23:33.760]   in after you. It's not Facebook. It's. No although. I okay now that I'm paying for your muted.
[01:23:33.760 --> 01:23:40.240]   I notice. Oh sorry. For some reason on the front page there's articles as old as three years old
[01:23:40.240 --> 01:23:45.440]   on the front page. That's the point of medium. They want to. Yeah. They want to resurface the
[01:23:45.440 --> 01:23:50.320]   point is there's good content that's still relevant. Okay. That's their point. Oh okay. All right.
[01:23:50.320 --> 01:23:56.480]   All right. They started medium. They had no dates on any piece. Oh. Absolutely. Absolutely. Same here.
[01:23:56.480 --> 01:24:02.000]   Yeah. Because I don't want to retweet something that's three years old. I will find people to be
[01:24:02.000 --> 01:24:08.480]   back. No. No. When it was written. No. No. No. In that context. Yes. Like okay I saw it.
[01:24:08.480 --> 01:24:13.520]   Jared Diamond says there's a 49% chance that the world as we know will end by 2050. Oh no. And then
[01:24:13.520 --> 01:24:20.000]   I see oh that came out in May of last year. In fact the other thing is maybe it's because of my
[01:24:20.000 --> 01:24:26.000]   advanced age. I don't know. I probably read that article a year ago. I just forgot. Well that's why
[01:24:26.000 --> 01:24:31.440]   it's good to you. I don't want to reread articles. Life's too short. I was like that was your problem
[01:24:31.440 --> 01:24:36.000]   with the article is that it didn't have a date not the fact that this guy is good. Yeah. The world's
[01:24:36.000 --> 01:24:41.280]   going to end by 2050. Oh I don't think Jared Diamond knows what he's talking about. Besides I'll be
[01:24:41.280 --> 01:24:50.080]   dead by that anyway. So well I'll be 94. That's you know. That was fast math. It's wrong math but
[01:24:50.080 --> 01:24:59.680]   it's fast. I'll be 90. No I will be. I'll be 94. Yeah exactly. Albert Einstein was not happy.
[01:24:59.680 --> 01:25:06.240]   Fascinating. Yeah. Based on your reading history thing I've never liked. Where's that? That's what
[01:25:06.240 --> 01:25:12.320]   says at the top. Oh that's there. That's so yeah because I read that a year ago. So you probably
[01:25:12.320 --> 01:25:16.640]   forgot you read this. Why is it giving me that? Then highly intelligent people are miserable.
[01:25:16.640 --> 01:25:23.440]   An algorithm. Oh no. It's an algorithm. How to learn. Okay we are not reflexively hating on
[01:25:23.440 --> 01:25:28.160]   algorithms. We are reflexively hating on Facebook's algorithm. Yes that's true. Some algorithms.
[01:25:28.160 --> 01:25:35.280]   Okay. No I think no it's good and it's worth paying for and so I and I felt you made me feel
[01:25:35.280 --> 01:25:41.280]   guilty Jeff so I ponied up. And actually there is good content. It's good. There's good stuff there.
[01:25:41.280 --> 01:25:45.360]   They also added a new feature I see here to mute people.
[01:25:45.360 --> 01:25:50.960]   Oh Jeff I bet there's lots of people out there clicking that button next to you.
[01:25:50.960 --> 01:25:57.040]   Mute. Hey hey hey. You know that there are people who have very strong anti-Jeff feelings.
[01:25:57.040 --> 01:26:04.080]   Are there? Why? No. Really? Chocking. Everybody loves Jeff. I'm gonna get yelled at her for the show.
[01:26:04.880 --> 01:26:10.880]   That's because you yelled at Stacy. That's not nice. That's exactly what it is. Yes. People don't
[01:26:10.880 --> 01:26:16.960]   yell at you. Stacy and I were agreeing about everything. Ask me and hit Stacy. You were agreeing.
[01:26:16.960 --> 01:26:21.040]   I was interviewing Stacy and asking her lots of questions. I wanted her opinion. You. I was
[01:26:21.040 --> 01:26:24.960]   saying that was a good question. You did have a good question. So good. It made me feel.
[01:26:24.960 --> 01:26:32.400]   And I decided. You ever answered? No but I did. I said Mark stop letting no more political ads Mark.
[01:26:32.400 --> 01:26:35.920]   Take a moment. I didn't like your answer. I know you like your answer. I want Stacy's answer.
[01:26:35.920 --> 01:26:40.000]   All right. What's your answer? I did answer. I know. Oh god. Now I got to remember.
[01:26:40.000 --> 01:26:47.680]   Oh it was all about. It was all about being sorry. It was about decency again. So I'm using
[01:26:47.680 --> 01:26:51.440]   your shorthand. But it was like hey sometimes you can't do what's good for your business. You got
[01:26:51.440 --> 01:26:58.000]   to do what's good for the country blah blah blah. See we agree. Yulia. Yulia. You. Here's some good news.
[01:26:58.000 --> 01:27:03.120]   Hanneker. Yulia Musk is taking a break from Twitter. Oh.
[01:27:03.120 --> 01:27:09.840]   That's why I went. Did you. What was your reaction? I was so mixed because I wanted to
[01:27:09.840 --> 01:27:14.880]   absolutely love the space launch because I did. I did. But the fact that it's Yulia Musk just kind
[01:27:14.880 --> 01:27:20.320]   of took a little bit of an edge off. I know. I know. How to give. There are real big benefits to
[01:27:20.320 --> 01:27:26.880]   society that are completely created by big jerks. So you know. Yeah very fun brown huh. Yeah.
[01:27:26.880 --> 01:27:29.920]   I guess we wouldn't have gone in the moon without that nazi.
[01:27:29.920 --> 01:27:40.640]   So I mean sometimes yeah okay. Thank you Stacy. Netflix just bought the Egyptian theater
[01:27:40.640 --> 01:27:48.000]   in Hollywood. Is this the old Grommons Chinese theater which is now the Egyptian theater? No I
[01:27:48.000 --> 01:27:54.800]   don't think so. No. Grommons. I think the Egyptian is where they were they've done the Oscars a
[01:27:54.800 --> 01:28:01.520]   couple times. Yeah. I thought that was Grommons. It's a Grommons just Egyptian. Anyway I've
[01:28:01.520 --> 01:28:08.160]   walked by it. Yeah it was opened on Hollywood Boulevard in 1922 by Sid Grommon. It's got you know
[01:28:08.160 --> 01:28:16.080]   a Sphinx and the stage has got columns. The first premiere was the Douglas Fairbank's flick Robinhood.
[01:28:16.080 --> 01:28:22.080]   It was closed in 1992 purchased by the American Cinematique for $1
[01:28:23.680 --> 01:28:27.840]   with the provision that the historical landmark would be restored to its original grandeur and
[01:28:27.840 --> 01:28:34.000]   reopened as a movie theater showcasing the organization's celebrated public programming and it was
[01:28:34.000 --> 01:28:42.000]   opened after a $12.8 million renovation in 1998 and now they've sold it on to Netflix.
[01:28:42.000 --> 01:28:49.360]   Netflix has been buying theaters probably mostly so that they can get some of their movies into the
[01:28:49.360 --> 01:28:56.480]   Oscar nominations. Oh that would be yeah. How long before you're comfortable going back to
[01:28:56.480 --> 01:29:02.800]   movie theater? I love my home theater. Popcorn's better. I don't think I would go to a movie theater.
[01:29:02.800 --> 01:29:08.880]   I don't I mean I went to the movie theaters like twice a year and that was only for the latest
[01:29:08.880 --> 01:29:13.920]   cartoon or Marvel flick with my daughter. So Apple TV and I would always go to a fancy one.
[01:29:13.920 --> 01:29:19.760]   Apple TV just won a bidding war for Martin Scorsese's next movie with Leonardo DiCaprio,
[01:29:19.760 --> 01:29:30.560]   Robert De Niro, $180 million. So movies go on but I think that streaming there's
[01:29:30.560 --> 01:29:35.280]   are the streaming companies buying these movies now. You know why I went twice a year to Stacy you
[01:29:35.280 --> 01:29:41.440]   know why? Why? Popcorn. I'm telling you I can make you the best popcorn you've ever had.
[01:29:42.000 --> 01:29:47.680]   In your in your $5,000 cooking thing is to do that too. No actually the Thermomics which is far from
[01:29:47.680 --> 01:29:52.240]   $5,000. It does not make it. It does not. It could though Stacy wait a minute.
[01:29:52.240 --> 01:30:00.400]   It has the it turns well stir. I bet it does. Let me let me investigate. I have to go to cookie do.
[01:30:00.400 --> 01:30:08.480]   It's the dumbest name. It's French. It makes caramel popcorn I think. Yeah the right party popcorn
[01:30:08.480 --> 01:30:15.600]   caramel pop here it is. Oh caramel popcorn party pop or salted caramel popcorn in the Thermomics.
[01:30:15.600 --> 01:30:21.520]   I'm going to make caramel corn tonight. Whoa tonight. That'll hold Leo. You can send that out to us.
[01:30:21.520 --> 01:30:28.640]   You can make Stacy very good. You get bored of the thermomics just feel send it to you and you
[01:30:28.640 --> 01:30:35.920]   can send me the popcorn back. Yeah Leo I make bread I make food I'll make popcorn and send it back to
[01:30:35.920 --> 01:30:43.120]   you. Yeah you probably would too. This looks good I'm making this man this is good. I did
[01:30:43.120 --> 01:30:50.880]   I'm so glad you brought that up. Popcorn old caramel. Oh now it's French popcorn so fancy.
[01:30:50.880 --> 01:30:55.120]   It has to be at the price of the device. Everything has to be a fancy name. Mike Maszak.
[01:30:55.120 --> 01:30:59.520]   Do you have Thermomics? Go ahead Thermomics questions are much more important than copyright.
[01:30:59.520 --> 01:31:03.760]   No no I was going to ask if they were French but I think it's Swiss.
[01:31:05.120 --> 01:31:12.240]   Okay I feel like it's Swiss. The only things I'm making are mashed potatoes in risotto. I've got
[01:31:12.240 --> 01:31:16.960]   a really French out but it's very good. Potatoes really? Oh it's the best mashed potatoes I've ever
[01:31:16.960 --> 01:31:23.120]   had. Oh why are they the best? I don't know and you know it's great he's got a little scale in it
[01:31:23.120 --> 01:31:30.160]   right. So it says okay now slice up some potatoes and put in what it was 750 grams of potatoes so
[01:31:30.160 --> 01:31:37.200]   you put them in until it says 750 grams. Okay now put in 150 grams of cream. I mean it's all measured
[01:31:37.200 --> 01:31:42.640]   out and it tells you what to do. There's buttons there's knobs you just do it and it comes out a
[01:31:42.640 --> 01:31:48.880]   half an hour later the creamiest richest. These are these rival the mashed potatoes at the world
[01:31:48.880 --> 01:31:54.880]   famous Joelle Robachon. They're very good by the way those are the best mashed potatoes in the world.
[01:31:54.880 --> 01:32:00.080]   How much butter is in them? Lots. Okay. Oh they're not healthy. That's really all you need.
[01:32:00.080 --> 01:32:09.520]   For good mashed potatoes. Buttercream yeah I agree. Speaking of the public domain. Italian
[01:32:09.520 --> 01:32:15.600]   prosecutors what the hell Mike Masnick and Mike in Tech Dirt I love Mike stuff. Says that the
[01:32:15.600 --> 01:32:22.000]   public prosecutors in Italy have declared Project Gutenberg which by the way is Gutenberg. Good
[01:32:22.000 --> 01:32:28.560]   word. Did I hear Gutenberg? Yes I brought it up just for you. Gutenberg. Gutenberg. They take it down
[01:32:28.560 --> 01:32:36.000]   for copyright infringement even though it's a repository of public domain works. It seems like
[01:32:36.000 --> 01:32:45.440]   some lazy work on the part of the Italian prosecutor. What? What a lazy prosecutor just. What? How
[01:32:45.440 --> 01:32:55.360]   could that be? Apparently they were monitoring some telegram private channels saw someone there
[01:32:55.360 --> 01:33:01.920]   linked to some pirate sites and Project Gutenberg and rather than you know investigate rights Mike
[01:33:01.920 --> 01:33:06.560]   they just decided to ban the entire list. Now this is facilitated by something in Italy
[01:33:06.560 --> 01:33:12.880]   that I don't like so much. Apparently it's the law in Italy that the prosecutor can tell ISPs
[01:33:12.880 --> 01:33:18.560]   you these are sites you must block period and there's no appeal. Do you think these are
[01:33:18.560 --> 01:33:24.720]   rights kind of rules or is it? It's gone. They never even contacted Project Gutenberg.
[01:33:24.720 --> 01:33:33.680]   But because they have the they this is where you got to be careful because they have the right to
[01:33:33.680 --> 01:33:45.520]   just tell ISPs. Here's a list of sites you must now block. I will say ISPs large social media platforms
[01:33:45.520 --> 01:33:54.000]   search platforms. I think there is a huge challenge in getting them to realize the impact that those
[01:33:54.000 --> 01:34:00.160]   kind of blocks can have. The impact that a casual decision at the platform level can have on a business
[01:34:01.120 --> 01:34:06.240]   and setting up the proper channels even if they're at scalable to deal with that quickly
[01:34:06.240 --> 01:34:12.400]   is so essential. I don't know how we do. I don't know. I mean legally there's no
[01:34:12.400 --> 01:34:17.360]   framework for dealing with that but it is a huge problem. Well we should not really have a law
[01:34:17.360 --> 01:34:23.360]   that says that ISPs can just unilaterally be instructed to block. We don't have one. No I
[01:34:23.360 --> 01:34:29.440]   know. We should be careful we never get one without a court order or anything. Take them off.
[01:34:29.440 --> 01:34:33.280]   And I honestly it's not merely Project Gutenberg which still has probably adherence all over the
[01:34:33.280 --> 01:34:37.200]   world. It's really an amazing thing. I feel bad for the Italians who won't be able to access it.
[01:34:37.200 --> 01:34:42.880]   The school kids and stuff who won't be able to read the Scarlet Letter for their homework.
[01:34:42.880 --> 01:34:47.280]   They'll have to go out and buy it. But then there was also another case in the last two weeks where
[01:34:47.280 --> 01:34:53.440]   book publishers were pissed at them in the US because they were getting like the internet archives.
[01:34:53.440 --> 01:34:58.800]   Yeah an archive right. So that's some parallel things. Well we were talking about that one.
[01:34:58.800 --> 01:35:04.800]   I thought we talked about that on the show but you know did we? I feel like we did.
[01:35:04.800 --> 01:35:11.760]   Oh it's hell get an old stacey don't you don't do it. In an archive in honor of the quarantine
[01:35:11.760 --> 01:35:19.840]   decided to put up it has a lot of books put up a collection of books that it normally treats
[01:35:19.840 --> 01:35:27.120]   like a library that you borrow. They call it the open library ebook lending publishers sued them.
[01:35:27.120 --> 01:35:34.800]   And you know what in this case these are these are copyright. This is not public.
[01:35:34.800 --> 01:35:40.400]   It's not an easy one. They're using though that control digital lending or they used to use
[01:35:40.400 --> 01:35:44.880]   control digital lending that other public libraries use but they announced the National
[01:35:44.880 --> 01:35:50.080]   Emergency Library which suspended wait lists and made all books immediately accessible to anyone
[01:35:50.080 --> 01:35:54.080]   with an account and the publishers didn't like that. That was that was because of the quarantine.
[01:35:54.080 --> 01:36:03.520]   It wasn't intended to be a long-term thing. I can see why I mean I can see why that would
[01:36:03.520 --> 01:36:09.760]   frustrate publishers and authors. I mean if I were an author in well get paid for my books.
[01:36:09.760 --> 01:36:14.320]   I mean it would have been nice if maybe the Internet Archive had gone to publishers and say
[01:36:14.320 --> 01:36:20.160]   you know this is going to be good for your good publicity for you good for us good for America.
[01:36:20.160 --> 01:36:25.040]   We'd like to make these available to you know without the restrictions that we normally have to
[01:36:25.040 --> 01:36:32.000]   make for CDL control digital lending but they didn't and I think the publishers probably will
[01:36:32.000 --> 01:36:37.040]   win this case because they really can't they don't have a leg to stand on. No they don't.
[01:36:37.040 --> 01:36:42.720]   I will say that I love my quarantine reading has been amazing because I've got you know
[01:36:42.720 --> 01:36:48.800]   I get the digital books downloaded to my Kindle yeah and I'm just like and I don't know what's
[01:36:48.800 --> 01:36:54.320]   happening but all my like holds are coming in like right after another I'm like oh oh I've got
[01:36:54.320 --> 01:36:59.520]   too many books to read this is wonderful. Which uh live which uh software does your library use?
[01:36:59.520 --> 01:37:05.280]   They use overdrive and I use both overdrive and then they have Libby and I'm not sure why there are
[01:37:05.280 --> 01:37:11.920]   two apps I think I think overdrive owns Libby. Okay but they don't have the same books it's very
[01:37:11.920 --> 01:37:16.320]   weird. Yeah that is weird they should have the same books yeah Libby is owned by overdrive.
[01:37:16.320 --> 01:37:25.440]   Yeah so it's it's a better app experience and y'all if you like to read and your library supports this
[01:37:25.440 --> 01:37:31.120]   just do it's like the easiest best thing in the world. I mean I love it that you can they have
[01:37:31.120 --> 01:37:35.840]   audiobooks too but I love it that you can just send it to your Kindle or you can listen to it on
[01:37:35.840 --> 01:37:41.520]   your library it's really really cool overdrive Libby there's some other ones too so check your
[01:37:41.520 --> 01:37:48.400]   local library to see which one they support. I think most libraries now support um oh my god
[01:37:48.400 --> 01:37:57.440]   overdrive's owned by Rakuten. Really? Yes really. Oh that's a little bit of a shock.
[01:37:58.560 --> 01:38:04.480]   Oh Rakuten's buying up everything. That's that is crazy. Oh where's there where's their money?
[01:38:04.480 --> 01:38:12.800]   Who's behind Rakuten? It's Japanese. Chinese Japanese. I can't remember. I feel like it's
[01:38:12.800 --> 01:38:19.040]   it's Japanese and that you know they bought um they've been buying a lot of um Japanese
[01:38:19.040 --> 01:38:22.880]   electronic commerce and online retail and company based in Tokyo. Yeah thank you.
[01:38:22.880 --> 01:38:27.120]   On a bike. So Roshi Mikitani. I'm reading it from Wikipedia.
[01:38:27.120 --> 01:38:36.960]   Found it in 1997 18,000 employees. Yep. But they own a lot of other things too. Ebates. I mean I've
[01:38:36.960 --> 01:38:44.160]   seen the ads anyway they bought Ebates um and I did but I'm kind of surprised to learn that they own
[01:38:44.160 --> 01:38:50.640]   overdrive. They own this library lending app that's kind of wild. Well there was a big thing in
[01:38:50.640 --> 01:38:57.360]   which publisher was it? Um they were talking about with ebooks at libraries they were saying
[01:38:57.360 --> 01:39:01.600]   that they were going to do some more windowing there and like a library could only because I know
[01:39:01.600 --> 01:39:09.200]   like my library on popular books they purchased like 10 licenses for a book right and who was
[01:39:09.200 --> 01:39:14.400]   the publisher who was saying they would only be able to purchase like one or two and they would
[01:39:14.400 --> 01:39:23.360]   they would put a limit on it and the librarians were like rightly upset but publishers windowing
[01:39:23.360 --> 01:39:32.480]   ebooks. I think it was it. McMillan. Boom. Yes right right. And the idea McMillan yeah and the idea
[01:39:32.480 --> 01:39:37.360]   was that people were not buying books they were just waiting for them at the library and this was
[01:39:37.360 --> 01:39:43.760]   cutting into book sales. To which I'm like these are ebooks and that's kind of what libraries do.
[01:39:44.560 --> 01:39:50.000]   And are you gonna like only let a library buy two print copies of the books?
[01:39:50.000 --> 01:39:57.600]   We're back to Ben Franklin. And had it not been for Franklin if publishers had their way would
[01:39:57.600 --> 01:40:03.680]   there ever be libraries? No wasn't it Franklin? No. It started the public library movement in the
[01:40:03.680 --> 01:40:11.520]   United States. Wow this guy from McMillan says 45% of McMillan ebooks read every year are read for
[01:40:11.520 --> 01:40:19.760]   free in libraries. Wow no wonder they're a little worried. Yeah he does not go into detail about
[01:40:19.760 --> 01:40:24.640]   how that figure has arrived at but whether it's really 45% or not I don't doubt that that's
[01:40:24.640 --> 01:40:32.560]   a library. Yeah wow. Then the library isn't or maybe they do maybe they pay them.
[01:40:32.560 --> 01:40:38.800]   So the library pays for a life the physical books yeah yeah all right and they I don't
[01:40:39.760 --> 01:40:44.320]   when a library buys an e-book it's not like you and I buying an e-book they're buying a license to
[01:40:44.320 --> 01:40:50.240]   lend the e-book which is a different pricing bottle. Yeah right all right. By the way this
[01:40:50.240 --> 01:40:58.400]   week in Google episode 560 from May 20th was titled beer and shoes. Oh sorry okay I went looking
[01:40:58.400 --> 01:41:02.800]   I could find it. Honestly don't know if we I mean we must have talked about that story.
[01:41:02.800 --> 01:41:06.880]   But I don't think we talked about it. I know I don't think we spent as much time I don't even
[01:41:06.880 --> 01:41:11.680]   see it in the show notes so. Was I there that day? Maybe no one was here that day.
[01:41:11.680 --> 01:41:18.960]   Just Carsten. Just Carsten did that show in his mind. It was His Imagination. Yes. It was Carsten's
[01:41:18.960 --> 01:41:26.960]   Show of His Dreams. You know I Carsten by the way I miss getting a note from you at the end of the
[01:41:26.960 --> 01:41:32.560]   show to like us that we didn't focus enough on certain stories. So I. Does he do that? Oh no no
[01:41:32.560 --> 01:41:36.560]   in a nice way. I don't know. I don't know if I do that. What? Yeah we got it once. He said us
[01:41:36.560 --> 01:41:40.480]   that he said us a little note after he was like a rewieger. But I kind of liked it.
[01:41:40.480 --> 01:41:44.960]   Wait a minute. Wait a minute. Here's the stories you missed in the show. No no no just that he
[01:41:44.960 --> 01:41:48.160]   thought we should have focused more on this. I think it was a producer. Oh he was a producer.
[01:41:48.160 --> 01:41:52.480]   I mean he hasn't sent it to me. It was good. I'm the guy who chooses what stories we talk about.
[01:41:52.480 --> 01:41:57.280]   He knows you're hopeless Leo. He's like Jeff Stacey. They can still be taught. He's
[01:41:57.280 --> 01:42:02.240]   he's he's we're we're his root in. He sent you a note saying you should have covered this.
[01:42:02.240 --> 01:42:09.360]   It's not even up to you. Don't you don't you give a car stay in trouble. He's my taco buddy.
[01:42:09.360 --> 01:42:14.160]   Don't you give me any trouble. No I understand he's bribing you. Yeah.
[01:42:14.160 --> 01:42:21.440]   Taco but now I've got Carsten in trouble. Apparently he sent you a note saying here's what I would
[01:42:21.440 --> 01:42:30.960]   have talked about on the show. That's why I want Carsten to camp. Oh Lord I'm facing an insurrection.
[01:42:30.960 --> 01:42:36.480]   Maybe this would be a good time to do the Google change log.
[01:42:36.480 --> 01:42:42.560]   The Google change log. Oh man.
[01:42:46.080 --> 01:42:51.680]   I thought I thought I'd throw him but no he had his finger on the button. Good job Jeff. Ready.
[01:42:51.680 --> 01:42:59.680]   I'm gonna call him JC. Because we got to distinguish him from JJ.
[01:42:59.680 --> 01:43:04.160]   Well you should ask him first. Maybe he'd like something else.
[01:43:04.160 --> 01:43:07.840]   What would you like me to call you? Was JP? JP Rockman?
[01:43:07.840 --> 01:43:17.600]   JP. JP's good. Yes JP. Thank you JP. Good job JP. The third pixel feature drop has
[01:43:17.600 --> 01:43:24.480]   happened. Did you get it on your pixel? Oh I don't know. Yeah. There's some actually some good stuff.
[01:43:24.480 --> 01:43:28.560]   There's an attack. And we started. Your battery should be better. Mine has definitely. I've
[01:43:28.560 --> 01:43:35.760]   noticed it. There's an AI powered adaptive battery feature that apparently notices which apps
[01:43:36.560 --> 01:43:43.840]   are sucking battery even if you're not using them. It uses and this is for Stacey.
[01:43:43.840 --> 01:43:50.960]   A deep convolutional neural net. I know you like those. To predict which apps you'll use in the
[01:43:50.960 --> 01:43:57.120]   get this which apps you'll use in the next few hours and which apps you probably won't use until
[01:43:57.120 --> 01:44:04.880]   later and then reduce his power to the ones you rarely use. Take that. Why would you need to see
[01:44:04.880 --> 01:44:11.520]   an end to configure that out? Oh a CNN. A deep. Well a convolutional neural network. Why would you?
[01:44:11.520 --> 01:44:16.800]   Don't know because it needs to observe your behavior and figure it out. I don't know.
[01:44:16.800 --> 01:44:23.920]   You're asking me. I don't even know what it is. It's the same. It's the same thing you do.
[01:44:23.920 --> 01:44:28.800]   It's what you usually use for like image recognition and the idea is you show it lots of things and
[01:44:28.800 --> 01:44:34.640]   then it makes a conclusion. I think it's making a prediction as you use your phone as to which apps
[01:44:34.640 --> 01:44:39.280]   are going to use. Yeah I guess they do. They use that for language translations. So okay yeah that
[01:44:39.280 --> 01:44:44.480]   makes sense. Google spokesman says adaptive battery now uses multiple models as input
[01:44:44.480 --> 01:44:50.400]   determined how best to optimize your phone. In addition to using in addition to the existing
[01:44:50.400 --> 01:44:55.360]   model to predict app usage. We now also use a model that predicts how your battery is likely to
[01:44:55.360 --> 01:45:02.880]   discharge and another model that predicts when you're next likely to plug in. This is like minority
[01:45:02.880 --> 01:45:10.080]   report. The models run locally on the device and are personalized. Bringing these together the
[01:45:10.080 --> 01:45:14.160]   device can react if it predicts you're likely to run out of a charge and enable some additional
[01:45:14.160 --> 01:45:19.120]   power saving techniques to help your battery last longer. Wild. Is that wild? That's wild.
[01:45:19.120 --> 01:45:27.520]   They're actually doing that on other like using machine learning broadly to predict how long
[01:45:27.520 --> 01:45:31.760]   and how to optimize for battery life is actually something that's being studied right now.
[01:45:31.760 --> 01:45:35.760]   And it might help us. I mean it's going to help here on our phones but it'll also help in like
[01:45:35.760 --> 01:45:40.720]   IOT sensors too. These pixel drops are cool. So this is something Google started last year
[01:45:40.720 --> 01:45:45.520]   where they would add capabilities to the phone after you bought it. But they've done several now
[01:45:45.520 --> 01:45:53.680]   with a pixel. There are also you may remember the recorder app that we talked about that's so cool
[01:45:53.680 --> 01:46:00.320]   it records and transcribes at the same time. It lets you search. Great. Have you been using it?
[01:46:00.320 --> 01:46:04.640]   It is it is so good. It's it's a reporter's dream a student's dream.
[01:46:04.640 --> 01:46:12.000]   It lets you search audio files for words export text transcripts recommends audio message titles
[01:46:12.000 --> 01:46:19.520]   based on keywords or on music applause or speech. And now that functionality is being pulled out by
[01:46:19.520 --> 01:46:25.520]   Google Assistant. Let me try it. I'm just going to see if here I'll mute my microphone.
[01:46:27.600 --> 01:46:31.840]   Start recording my meeting. And in theory.
[01:46:31.840 --> 01:46:41.760]   Nothing happened. And in theory something would happen. In theory something would happen.
[01:46:41.760 --> 01:46:45.440]   Well I don't know. Okay you should also be able to say
[01:46:45.440 --> 01:46:49.040]   show me recordings about dogs.
[01:46:51.760 --> 01:46:59.200]   I have none. Or you can also oh no that's those are the two things you can do. It doesn't have to be
[01:46:59.200 --> 01:47:04.320]   dogs obviously. But you could you know say show me all the all the meetings with JB.
[01:47:04.320 --> 01:47:12.720]   You can also export transcripts to Google Docs. There's new bedtime and personal safety features.
[01:47:12.720 --> 01:47:19.360]   You can now fall asleep to calming sounds from YouTube music spotify calm and other apps.
[01:47:19.360 --> 01:47:24.960]   You could set a bedtime schedule get a reminder when it's time for bed and limit
[01:47:24.960 --> 01:47:29.600]   interruptions when you sleep. And if you take what happens when it's bedtime.
[01:47:29.600 --> 01:47:39.040]   It says it's time to go to sleep now and play calming sounds. Oh it also turn off your access
[01:47:39.040 --> 01:47:44.720]   to Twitter. It can yes. If you stay up on your phone past bedtime you'll get a snapshot of how
[01:47:44.720 --> 01:47:48.480]   much time you're spending awake. That's how I go to sleep. I don't know which I hold myself
[01:47:48.480 --> 01:47:54.080]   with my friends. No going to do not go to Twitter before you go to bed. That's the bad idea.
[01:47:54.080 --> 01:47:59.280]   In the morning you can wake up to your favorite track or with a gradually bright
[01:47:59.280 --> 01:48:05.840]   ear screen with sunrise alarm. Android users will get some of these functions later this summer.
[01:48:05.840 --> 01:48:11.680]   So these this is right now for pixel and pixel 4 XL users. And there's a new personal safety
[01:48:11.680 --> 01:48:17.680]   app which I really like. I think I could well I could show you this. But basically if you're
[01:48:17.680 --> 01:48:21.760]   going to go let's say you're going to let's say you're going to go on a walk it's late at night.
[01:48:21.760 --> 01:48:28.320]   You don't know if you'll ever come back. So you can be meeting night. So you could say to the
[01:48:28.320 --> 01:48:34.560]   personal safety app you could say I'm going for a walk if I don't come back in an hour call
[01:48:34.560 --> 01:48:42.240]   mom or something. Wait so you leave your phones with you? Yeah it's with you. But if
[01:48:42.240 --> 01:48:48.560]   that's not useful. Well let me see here. Sorry okay I'm thinking of like when I go hiking sometimes
[01:48:48.560 --> 01:48:54.240]   there's no cell phone coverage. It's like that. Oh I see. But so I would leave my phone at the
[01:48:54.240 --> 01:48:58.560]   at the trailhead where there's coverage and then I could be like if I don't come back. Oh no you
[01:48:58.560 --> 01:49:02.960]   could do this. Actually you could do this. It says in uncertain situations set up a time for your
[01:49:02.960 --> 01:49:07.520]   phone to check that you're safe. So you could say I should be back in two hours leave the phone
[01:49:07.520 --> 01:49:11.600]   when you get home the phone will say are you are you home? Are you okay? If you don't respond
[01:49:11.600 --> 01:49:16.800]   emergency sharing automatically starts sends your contacts information. You can also share
[01:49:16.800 --> 01:49:23.760]   real time location with your emergency contacts. I think that's so this is the safety check. So I
[01:49:23.760 --> 01:49:27.200]   can see I'll end up running into a neighbor down the street end up in a conversation.
[01:49:27.200 --> 01:49:34.800]   Forget that I did that. The cops will come. My father will be upset. No it doesn't call the cops
[01:49:34.800 --> 01:49:40.000]   it just calls your father. Yeah and you would just if you have your phone still on you it would
[01:49:40.000 --> 01:49:43.920]   alert you and then you could hit a button while you're talking. But in that scenario it was home.
[01:49:43.920 --> 01:49:48.400]   I think it's really mostly designed for you to have with you to be honest. Okay right. Yeah.
[01:49:48.400 --> 01:49:52.320]   Because it's also saying location. I just I'm looking for something for when I go into the back
[01:49:52.320 --> 01:49:57.760]   country and my I'm by myself because my husband gets really nervous. Yes. Yeah well that's kind of
[01:49:57.760 --> 01:50:02.480]   the idea of this. I'm going on a hike and I might you know if I don't get back in a couple hours
[01:50:02.480 --> 01:50:08.240]   tell everybody I'm not back. That's pretty cool. I think that's kind of neat. And you could share
[01:50:08.240 --> 01:50:14.080]   real time location information using it. It also lets you turn on crisis alerts to get
[01:50:14.080 --> 01:50:22.720]   notifications about natural disasters or other public emergencies. That is in the third pixel
[01:50:22.720 --> 01:50:30.720]   drop pixel feature drop which I got like June 1. So you should have it by now.
[01:50:30.720 --> 01:50:40.560]   You want to you want to use your phone for social distancing. Google has a new AR tool called SODAR
[01:50:40.560 --> 01:50:48.720]   that will tell you how close somebody is. You don't even need an app you just visit the SODAR
[01:50:48.720 --> 01:50:55.600]   website using Chrome or pull up using Google's QR code and your browser will turn into a standalone
[01:50:55.600 --> 01:51:01.840]   tool that uses your phone's camera to draw a six foot perimeter around you. That's cool.
[01:51:01.840 --> 01:51:10.160]   Let me go to the SODAR. It's SODAR with Google.com.
[01:51:12.240 --> 01:51:22.560]   And here I got the QR code on the site. Let me see. There we go. SODAR. That was nice.
[01:51:22.560 --> 01:51:32.400]   Your connection is not private. What? Oh no. What? They are their website not.
[01:51:32.400 --> 01:51:40.640]   You know what's funny the QR code didn't put in the HTTPS or maybe it did. It did. That might be
[01:51:40.640 --> 01:51:49.440]   something local. Anyway, I can show you a little video. So that's cool. SODAR. See this? It shows
[01:51:49.440 --> 01:51:54.560]   you. That's two meters. Don't get any closer. Actually, I could have used that yesterday. I had a
[01:51:54.560 --> 01:51:59.600]   guy come right up to me. I said, you know, I do. Have you ever done this? You do the thing where
[01:51:59.600 --> 01:52:06.400]   you kind of go, you stagger backward. You go, oh, I staggered backwards. Like, no, put my hand out.
[01:52:08.080 --> 01:52:13.520]   I feel bad doing that. But I think it's good to do that. Oh, it's there's a guy I know in Europe.
[01:52:13.520 --> 01:52:18.240]   That's as specific as I'll get. Nice guy. I see him at conferences. Then I forget.
[01:52:18.240 --> 01:52:24.000]   Nobody violates my space more than this guy. And I'll back up. He's a close talker. And he's
[01:52:24.000 --> 01:52:29.840]   a stalker. If you if you did, if you use my phone and did a route, you'd see me trying to get away
[01:52:30.480 --> 01:52:39.120]   and a return. And I fail. Have you have you just done this? Hey, hold back off just a bit. I just
[01:52:39.120 --> 01:52:47.520]   need my space, please. I just go. Chill man. COVID. Well, even if I mean, like, people try to get up.
[01:52:47.520 --> 01:52:54.480]   Like, I have a very wide personal space. And I'm just like, Hey, just take a step back, please.
[01:52:54.480 --> 01:52:59.920]   And they're like, Oh, okay. Yeah, I feel bad. But I think you got to do it. Yeah.
[01:53:00.560 --> 01:53:04.800]   The guy did have a mask or anything. And he just can't start coming up to me.
[01:53:04.800 --> 01:53:10.000]   I come up to people sometimes because I forget. You forget. I think I terrify.
[01:53:10.000 --> 01:53:14.960]   Maybe that's me. And so if you do that, and I did what whoa, you know, let's social. And then
[01:53:14.960 --> 01:53:19.440]   I'm like, Oh, yeah, I'm sorry. Sorry. It's fine. So now we can say social distancing. Now I'm very
[01:53:19.440 --> 01:53:23.920]   happy. Now we can just say that. It's fun. Social distancing. Yeah. Oh, I'm sorry. I don't want
[01:53:23.920 --> 01:53:30.480]   to get sick and you look ill. My last meeting in New York, I remember people started shaking hands
[01:53:30.480 --> 01:53:34.640]   and I said, uh, and they were kind of first, I kind of looked at me funny and then they realized,
[01:53:34.640 --> 01:53:41.120]   no, that's the right thing to do. Here's a story. Carson would have done. But I'm not going to do.
[01:53:41.120 --> 01:53:45.040]   What's about Stadia? How did you know it was about Stadia?
[01:53:49.920 --> 01:53:58.720]   Wow. Use the poor boy. My friend, my buddy. Taco buddy. Nobody. But I'm not going to do.
[01:53:58.720 --> 01:54:03.680]   It's a stupid, stupid, Stadia. You want you want to? Okay. Okay. I don't care.
[01:54:03.680 --> 01:54:07.440]   I don't care. I don't care. You be the judge. You be the judge. I don't care.
[01:54:07.440 --> 01:54:14.320]   I don't care. I don't care. 2.19. Preps playing on non certified phones, free weekends,
[01:54:14.320 --> 01:54:19.200]   touch controls and more. Excuse me. I'm going to go to social media and tell all the world this.
[01:54:19.280 --> 01:54:22.720]   [laughter]
[01:54:22.720 --> 01:54:25.280]   You're right. You're right. They don't. You're right. You're right. All right.
[01:54:25.280 --> 01:54:31.520]   Here's one you're going to care about, Jeff. G Suite customers will soon be able to make
[01:54:31.520 --> 01:54:35.680]   Google voice calls right from Gmail. What do you do?
[01:54:35.680 --> 01:54:43.440]   Hey, it should be in the change luck though. You will agree. Yes, I will. Yeah. Google Maps makes
[01:54:43.440 --> 01:54:52.160]   it easier to share your location even if you don't have an address. Remember we talked about what
[01:54:52.160 --> 01:55:01.120]   three words? Plus codes are actually, aren't they? Tell me about this, Stacey. This is more of a
[01:55:01.120 --> 01:55:07.040]   standard, right? Plus codes. Well, it's got a larger company behind it. Oh, it's still a private
[01:55:07.040 --> 01:55:12.560]   company. That bothered me. Yeah. I like what three words is open source. Wait, wait, can you see that
[01:55:12.560 --> 01:55:18.000]   the Jabra 675T refurbished that were cheaper? Did you see that?
[01:55:18.000 --> 01:55:22.320]   So, scroll back. You want me to go to an ad?
[01:55:22.320 --> 01:55:27.680]   Oh, good deals. I might need to do this because I fried my Jabras.
[01:55:27.680 --> 01:55:32.960]   But I don't know. I don't know what happened. I had two Jabras, both of which I can't charge
[01:55:32.960 --> 01:55:39.840]   anymore. I think I had a bad type of C cable. I mean, a micro USB cable. I should only buy stuff.
[01:55:39.840 --> 01:55:43.760]   That one is USB-C. That one's USB-C. Yeah, see, that's a good reason to buy it. This is the one
[01:55:43.760 --> 01:55:51.840]   you bought, right? Right here. 100 bucks refurbished at Newegg. What about how do we feel about refurbished?
[01:55:51.840 --> 01:55:57.200]   Ooh, refurbished. You're the expert. Do they replace the little plasticy thingies or?
[01:55:57.200 --> 01:56:09.040]   On the other hand, you can't sell something as new if it's been bought. It's opened, right?
[01:56:09.040 --> 01:56:12.400]   Even if it's never worn. I probably buy it, actually. Especially for 100 bucks.
[01:56:12.400 --> 01:56:15.600]   That's a good price for these. And normally, what I do want to do.
[01:56:15.600 --> 01:56:18.640]   I still have not used mine. It might still work. I'm not buying it. I'm not buying it.
[01:56:18.640 --> 01:56:20.640]   Not looking. Yeah.
[01:56:20.640 --> 01:56:27.440]   Okay. The top critical review says, "Truly refurbished."
[01:56:27.440 --> 01:56:30.960]   What does that even mean?
[01:56:30.960 --> 01:56:37.280]   Okay, how did I get? I was telling you a story. I'm sorry. You were telling us a plus
[01:56:37.280 --> 01:56:44.320]   codes. So I think what three words, for instance, we are glow walnut nasal. You enter that into
[01:56:44.320 --> 01:56:48.160]   what three words it'll give you the logic to latitude. Yeah, it's easy to remember. That's my
[01:56:48.160 --> 01:56:56.720]   point. Three words, easy to remember. Yeah. PR7G plus J2. I like plus three words. I'm
[01:56:56.720 --> 01:56:59.920]   going to happen to you better. What three words are better? They are.
[01:56:59.920 --> 01:57:06.560]   Plus codes. So you can use plus codes now in Google Maps. It generates a six digit code based
[01:57:06.560 --> 01:57:10.640]   on your location, which you can give to others. It's certainly easier than saying an address.
[01:57:10.640 --> 01:57:19.280]   And it's from plus dot codes. But I, I don't know. I think they just decided.
[01:57:19.280 --> 01:57:23.120]   What? Stacy. I love it. Stacy does that.
[01:57:23.120 --> 01:57:29.440]   No. Stacy. What? You guys, we are talking about three words. And I was like, oh, my helium router
[01:57:29.440 --> 01:57:33.600]   is named three words. And I was going to say it. But I then Googled it just to see it. It has
[01:57:33.600 --> 01:57:39.280]   my address. So I can't ever tell you the name of my battery. That seems like a that's intentional,
[01:57:39.280 --> 01:57:45.280]   huh? Well, yeah, because it's a distributed network and there's probably like, yeah,
[01:57:45.280 --> 01:57:51.440]   that's really interesting. So if I use what's to figure out where you live, I can use your router.
[01:57:51.440 --> 01:57:58.480]   Or if I had a what three words with my address, you could definitely. Yeah. Sorry. I'm just,
[01:57:58.480 --> 01:58:02.960]   I'm just thinking, Oh, I would never share my what three words. And then I'm like, what about glow?
[01:58:02.960 --> 01:58:09.360]   Sorry. So if I got a helium, how do you get your glory glow walnut nasal, right?
[01:58:09.360 --> 01:58:12.960]   Well, I wouldn't share it on this show. I would share it with someone who's trying to send me a
[01:58:12.960 --> 01:58:18.320]   package. Yeah. It's your front door. But I don't. Yeah. Yeah. I don't know that I would, I would
[01:58:18.320 --> 01:58:25.120]   tell everybody who listens to Twig where I live. I'm sure you're all very nice. Probably, I think
[01:58:25.120 --> 01:58:34.240]   probably that sensible. And finally, Google has added a suite of bedtime tools. I think this is
[01:58:34.240 --> 01:58:41.120]   related to the pixel drop. Do not disturb gray scale effect. Pixels get it first. I think this
[01:58:41.120 --> 01:58:45.680]   is related. So we'll just say we already did that one. I thought the pixel drop was pretty cool.
[01:58:45.680 --> 01:58:50.320]   I mean, if there's something about it, this is six month old phone, there's just something about it
[01:58:50.320 --> 01:58:54.960]   getting nice new features like that. I think that's pretty cool. Like that voice recorder,
[01:58:54.960 --> 01:59:00.240]   that thing's amazing. Yeah. Yeah. That is, that is neat. Although that's, that's the beauty of
[01:59:00.240 --> 01:59:06.480]   having a connected device. It could get better over time. He's smarter. Yeah. Ta-da. And that, ta-da.
[01:59:06.480 --> 01:59:10.800]   Wait, wait, no, we didn't talk about Nest adding. Sorry. I'm going to add something to the Google
[01:59:10.800 --> 01:59:16.640]   chain. Please. Well, it's not in there. Yes. You're WWKD. What would Carsten do?
[01:59:18.080 --> 01:59:23.280]   He's going to, he's going to be fine with this. Good. Nest is adding Google's advanced protection
[01:59:23.280 --> 01:59:31.600]   services to its devices. Yeah. That's one where you use a physical key in addition, two physical keys
[01:59:31.600 --> 01:59:37.520]   in addition. Well, you only use one, but you have two. You have your phone there. You should always
[01:59:37.520 --> 01:59:41.600]   have a backup physical key anyway. You should never just use one. But if you lost it, that'd be bad.
[01:59:43.840 --> 01:59:48.880]   So, so yeah, I thought that was really good. Although I don't think I would use that. I'm actually
[01:59:48.880 --> 01:59:54.400]   curious, do any of you use the advanced security? I have. I have. And you lose so many features
[01:59:54.400 --> 02:00:02.960]   that I use that I've, I've turned it on twice and turned it off twice. And, you know, most recently,
[02:00:02.960 --> 02:00:09.200]   the feature to embed Google Docs in other things, which I really valued, but you can't do that if
[02:00:09.200 --> 02:00:14.880]   you're using the advanced protection, but advanced protection. But, and I should point this out,
[02:00:14.880 --> 02:00:19.840]   you could still use a Yubike or some sort of physical dongle as your authentication on Google.
[02:00:19.840 --> 02:00:25.200]   So it's not like without advanced protection. So it's not. So I do that.
[02:00:25.200 --> 02:00:29.520]   And advanced protection is like for like super secure people. Although if you're
[02:00:29.520 --> 02:00:34.000]   super secure like that, you probably wouldn't have an off the shelf connected video camera in your
[02:00:34.000 --> 02:00:39.840]   home. It's like that. But I could be wrong. I thought it was worth mentioning.
[02:00:39.840 --> 02:00:45.520]   Anything else? Are we any other new Google features? Carsten? Oh, I see. What would you do?
[02:00:45.520 --> 02:00:51.440]   Anything else? Okay. That's the Google change log.
[02:00:51.440 --> 02:01:01.040]   I think we could, we could go to the, the end of the show at this point.
[02:01:02.240 --> 02:01:07.920]   Yeah, I think you did it. I think so. I think so. I want you to start Stacy, if you have a thing
[02:01:07.920 --> 02:01:15.360]   or two. So I'm gonna, I'm gonna confess to you guys. I have been painting all weekend. Yeah.
[02:01:15.360 --> 02:01:21.600]   No, I just, I haven't had any time. What are you painting? Are you painting a tree? A little bird,
[02:01:21.600 --> 02:01:25.120]   a room's in your house. Well, that sounds like what you're in. I thought you didn't,
[02:01:25.120 --> 02:01:29.840]   we're closing yet. You closed? Oh, we've, we have now closed and we are now. Oh,
[02:01:29.840 --> 02:01:36.560]   muzzle. Tweaking. Thank you. So yes, I have, I have, I'm trying to think if I purchased anything
[02:01:36.560 --> 02:01:43.600]   interesting related to housing stuff. I'm about to start doing all of my connected home stuff.
[02:01:43.600 --> 02:01:49.360]   No, I haven't yet. So, well, we definitely have a report then once you get in the house all
[02:01:49.360 --> 02:01:56.240]   wired up. That's good. But yeah, right now, I'm sorry y'all. I, I wish I had, oh, I did read a
[02:01:56.240 --> 02:02:01.840]   good book. Okay. But it's, it's kind of old. I always want to hear what to read. I'm always looking
[02:02:01.840 --> 02:02:08.240]   for other books to read. Well, it was the 2018 Pulitzer Prize winning book. So it's not secret,
[02:02:08.240 --> 02:02:15.440]   but it's the over story by Richard Power. Don't know it. It's really good. And it,
[02:02:15.440 --> 02:02:22.160]   it's really slow getting there. And I thought I was reading one book and then like a third
[02:02:22.160 --> 02:02:26.080]   of the way through, I realized I was reading a totally different book, but it's, it's really good.
[02:02:26.080 --> 02:02:31.280]   And it makes you think about part of it's because I, I like nature and trees and a lot of it set in
[02:02:31.280 --> 02:02:36.240]   the Pacific Northwest. But I liked it. It actually, well, this sounds really good.
[02:02:36.240 --> 02:02:41.200]   It sounds really good book. Yeah. So that's what I've been doing.
[02:02:41.200 --> 02:02:45.760]   Shortlist for the man Booker prize Pulitzer Prize winner in 2019. Oh, yeah, I saw that in the store.
[02:02:45.760 --> 02:02:50.400]   Oh, 2019. Yeah. I am adding this to my list. That sounds great.
[02:02:50.400 --> 02:02:54.560]   So. Thank you. See, I don't. There you go. Sorry.
[02:02:54.560 --> 02:02:58.880]   It doesn't have to be a TV show. It doesn't have to be, you know,
[02:02:58.880 --> 02:03:06.560]   I'm going to see if it's unaudible because I no longer can read. Yes, it is. 22 hours.
[02:03:06.560 --> 02:03:12.480]   Good Lord. Good Lord. I listened to East West Street, which is spectacular.
[02:03:12.480 --> 02:03:24.160]   What's that? It is really fascinating story of the origins of genocide and crimes against
[02:03:24.160 --> 02:03:32.000]   humanity at an individual or group level in the Duremberg trials told by an author who follows his
[02:03:32.000 --> 02:03:36.960]   own relative and then runs into two other relatives from the same. They were all involved in the same
[02:03:36.960 --> 02:03:44.160]   town. It's, it's amazing. He has a new book coming out. It's really smart. Nice East West
[02:03:44.160 --> 02:03:49.040]   Street. By the way, the overstory is on a two for one sale right now at Audible.
[02:03:50.320 --> 02:03:54.960]   Wait, so you buy one and you get two? Yeah. That's how it works.
[02:03:54.960 --> 02:03:59.600]   Oh, you get two of the same book? Well, that wouldn't be, especially an audiobook.
[02:03:59.600 --> 02:04:04.400]   Well, that's what I'm curious. What? No, you get there. There's a list of books. Buy one, get one.
[02:04:04.400 --> 02:04:12.800]   Right. No, it's not a bogo. It's a two for one selection. I listen, you just,
[02:04:12.800 --> 02:04:16.560]   and there's a bunch of books in that. And if it's in that cat in those lists,
[02:04:16.560 --> 02:04:21.680]   then you could buy one and you could then pick another one for free. Oh, the other book I read
[02:04:21.680 --> 02:04:25.760]   that's really good. I'm going to give it to you because it also made me change my world. The
[02:04:25.760 --> 02:04:32.080]   water dancer by Tenishi Tenishi Coates. I love Tana Hasi. Tana Hasi. Yeah, Barra,
[02:04:32.080 --> 02:04:36.080]   Tinde finally told me how to say that. Tana Hasi, which is not how it's spelled.
[02:04:36.080 --> 02:04:40.640]   It is not. I love. He taught it. He taught it at our school. That's how I know. Oh, did he? Oh,
[02:04:40.640 --> 02:04:44.880]   okay. Yes. I thought between the world and me. In fact, that's one I would recommend
[02:04:45.520 --> 02:04:49.520]   as one of the, and it's one of Barra Tunde's books that would help you understand
[02:04:49.520 --> 02:04:54.080]   what it's like to be black in America. Very powerful between the world and me.
[02:04:54.080 --> 02:04:58.640]   And that is so good. So this is a novel. Yeah. He's a great writer. And
[02:04:58.640 --> 02:05:08.320]   it was so good. And I am mad that children do not read this in school because I thought that
[02:05:08.320 --> 02:05:15.200]   he wrote a quintessential story about America that we really haven't heard before. Yeah.
[02:05:15.200 --> 02:05:25.040]   Wow. And it made me very aware of how much, because I had no part in slavery. I'm not a part of that.
[02:05:25.040 --> 02:05:32.480]   Right. And I recognize what that has done, you know, Jim Crow and all the way up and today
[02:05:32.480 --> 02:05:41.680]   in terms of systemic racism. But he talks about how it, I mean, he really drove home the point of
[02:05:43.600 --> 02:05:48.160]   how it compromised and is such an essential part of the creation of our country.
[02:05:48.160 --> 02:05:55.520]   Absolutely. In a way that was really beautiful and just entertaining and speaks to the heart.
[02:05:55.520 --> 02:05:59.680]   Nice. Anyway, it's on my list. Just added it.
[02:05:59.680 --> 02:06:04.880]   Jeff, see, you had two picks you didn't even know. There we go. There you go.
[02:06:04.880 --> 02:06:09.760]   Jeff, you're a number. Well, I could do a number, but I could piss off Carson by
[02:06:09.760 --> 02:06:13.680]   taco buddy. Yeah, piss off the taco. Would you do that?
[02:06:13.680 --> 02:06:17.680]   Because he wants to be doing numbers all the time, but I have German words,
[02:06:17.680 --> 02:06:22.720]   a whole German thing. You could do anything you want. Nobody says you have to do a thing today.
[02:06:22.720 --> 02:06:26.400]   So nobody said you have to do what? You have to do numbers. I even volunteered
[02:06:26.400 --> 02:06:30.720]   to take numbers over if you want. Carson objected and he's my taco buddy. And I'm listening to
[02:06:30.720 --> 02:06:37.200]   Carson. I was saying that with the power grab here. No, it's not a grab.
[02:06:37.200 --> 02:06:41.360]   It's always a threatened old white man, man. Geez.
[02:06:41.360 --> 02:06:49.120]   Okay. I give it by a harbor. I submit to my Carson overlord. Go ahead.
[02:06:49.120 --> 02:06:52.560]   Well, no, no. So nice. You done books and they're doing a book. Well, I'm not really a book,
[02:06:52.560 --> 02:06:58.240]   a story, a story. So I just started it just came out yesterday, Humankind by Rutker Brigman.
[02:06:58.240 --> 02:07:03.040]   He was the guy who went to Davos and lectured all the Davosians about how screwed up they were
[02:07:03.040 --> 02:07:06.400]   and wrong when they weren't everything. He's just written a book called Humankind,
[02:07:06.400 --> 02:07:11.120]   which is about the we're not so bad after all. You probably won't like it as a result because
[02:07:11.120 --> 02:07:17.040]   you want to think people are just slimed. But anyway, he has a story in there and his research
[02:07:17.040 --> 02:07:19.920]   that he did in the Guardian. I just put it up on the bottom of the rundown under other.
[02:07:19.920 --> 02:07:24.160]   The real Lord of the Flies story. Did you see this tale?
[02:07:24.160 --> 02:07:27.120]   I did see that on medium, I think. But go ahead.
[02:07:27.120 --> 02:07:32.400]   It was actually it was in the Guardian. But actually, I think I've also read somewhere that
[02:07:32.400 --> 02:07:37.440]   this maybe isn't quite exactly how it was. Oh, really? Yeah, I'll find that article for you.
[02:07:37.440 --> 02:07:42.640]   Oh, dude. Yeah. So, so obviously William Golding's not what we were all forced to read in schools
[02:07:42.640 --> 02:07:48.320]   is we're all just horrible people. And it comes out on the island alone. And then he found the real
[02:07:48.320 --> 02:08:00.320]   story of five boys and Tonga, I think it was, who was basically stole a boat and ended up shipwrecked
[02:08:00.320 --> 02:08:04.640]   for a year and a half. And they had a nice society and they got along. They made a
[02:08:04.640 --> 02:08:10.240]   pack, never to quarrel. And then if they did, they would go take timeouts.
[02:08:10.240 --> 02:08:16.480]   And they would come back together and then a ship captain, a fishing boat captain,
[02:08:16.480 --> 02:08:23.040]   happened to buy the island, happened on all of them rescued them and their friends to this day.
[02:08:23.040 --> 02:08:28.480]   And it's really quite a remarkable, wonderful, global story. So, I've just started the book.
[02:08:28.480 --> 02:08:33.040]   I don't know when I like the book or not, but they were they were saved by the ship captain
[02:08:33.040 --> 02:08:40.640]   who noticed burning patches on the green cliffs. Then he saw a boy naked hair down to his shoulders
[02:08:40.640 --> 02:08:45.040]   who leaped from the cliffside plunged into the water. Suddenly more boys followed screaming
[02:08:45.040 --> 02:08:48.080]   at the top of their lungs. He didn't take long for the first boy to reach the boat.
[02:08:48.080 --> 02:08:53.360]   "My name is Stephen," he cried in perfect English. "There are six of us and we reckon we've been
[02:08:53.360 --> 02:09:00.080]   here 15 months." Students at a boarding school in Nuka Lofa, the Tongan capital,
[02:09:00.080 --> 02:09:04.240]   sick of school meals. They decided to go fishing. They got caught in a storm.
[02:09:04.240 --> 02:09:13.760]   Okay, nice story. And there they are later. Yep, after they grew up.
[02:09:13.760 --> 02:09:19.600]   It was kind of a goose bumpy story. So, you think it's not the case?
[02:09:19.600 --> 02:09:23.440]   Well, I don't know. You know, this is, I should never say things like that because
[02:09:23.440 --> 02:09:27.920]   you probably read that on Facebook. It's a headline I scanned quickly and thought,
[02:09:27.920 --> 02:09:29.120]   "Oh, I got to read that."
[02:09:29.120 --> 02:09:38.400]   You know what? I'm always suspicious of nice stories. See, that's the problem. That's the problem.
[02:09:38.400 --> 02:09:43.600]   I always believe in. I always believe in. There is probably more to that than me.
[02:09:43.600 --> 02:09:46.240]   See, that's your problem. You're too much of a nihilist.
[02:09:47.120 --> 02:09:51.360]   That comes into your attitude about Facebook and everything. Yes, there are.
[02:09:51.360 --> 02:09:57.680]   See, Stacey and I agree again. You're even mean to my taco buddy.
[02:09:57.680 --> 02:10:02.640]   I mean to... Oh no, he's... No, Leo's mean to my taco buddy.
[02:10:02.640 --> 02:10:12.720]   Nobody's going to find the story and say yes. In fact, humankind is corrupt and awful and miserable,
[02:10:12.720 --> 02:10:19.520]   Jarvis, you fool. It is both. I think most people want to do the right thing at the time.
[02:10:19.520 --> 02:10:23.360]   The story as told by the Dutch historian and author Rtger Breggman is upset.
[02:10:23.360 --> 02:10:28.160]   Some members of the Pacific Island community who argue the story of the six young Tongan
[02:10:28.160 --> 02:10:33.680]   boys had been instead told through a colonial lens and missed the Pacific point of view.
[02:10:33.680 --> 02:10:40.800]   But I'm a gardening expert. By the way, that gardening expert has been read more than seven
[02:10:40.800 --> 02:10:44.480]   million times. Yes, it's phenomenal. The Holy Cow.
[02:10:44.480 --> 02:10:50.880]   The story is based on Tongans. I'm Tongan and I do not relate to that story because it was told
[02:10:50.880 --> 02:11:02.000]   through a colonial lens. Let me see what they... I told them... Okay, but I want to see what she
[02:11:02.000 --> 02:11:09.280]   didn't like about it. Here's the account we should have had first.
[02:11:09.280 --> 02:11:16.320]   Oh, basically. It's because they're Tongan.
[02:11:16.320 --> 02:11:23.520]   We were raised to build communities. It's very hard to exist outside of community.
[02:11:23.520 --> 02:11:30.480]   And so that's... It wasn't about the nature of mankind. Yeah, nature of Tongans.
[02:11:30.480 --> 02:11:34.400]   Yeah. Yeah, that's not so bad.
[02:11:37.360 --> 02:11:42.320]   For me, it's hard to process because whiteness believes it can own everything and everything.
[02:11:42.320 --> 02:11:47.520]   I don't think she disagrees about the facts of it. Okay.
[02:11:47.520 --> 02:11:57.760]   She just felt like it was cultural appropriation that this guy got all the credit.
[02:11:57.760 --> 02:12:01.200]   The glory. The glory. About writing about Tongans. Tongans.
[02:12:03.120 --> 02:12:09.680]   So if you want, you can go back to the Guardian and read the actual survivors' story of what happened.
[02:12:09.680 --> 02:12:11.920]   Oh. Yeah, he's 73 now.
[02:12:11.920 --> 02:12:19.920]   And so I think they're resenting that Rucker Breggman's humankind and the excerpt we just
[02:12:19.920 --> 02:12:24.080]   talked about got all the attention when it really should have been the Tongans who told their own
[02:12:24.080 --> 02:12:32.400]   story. So if you want, read the also. Read the actual account by the kid now.
[02:12:32.400 --> 02:12:40.800]   In his 70s, who was rescued. He says he has nothing but praise for Warner, the rescue
[02:12:40.800 --> 02:12:46.400]   where Peter Warner. But he says initially Warner and the crew were fearful of the boys
[02:12:46.400 --> 02:12:48.320]   because we were all naked in that long hair.
[02:12:48.320 --> 02:12:56.320]   Because what he explains is that certain places would drop off Miss Kranz in their own
[02:12:56.320 --> 02:13:02.240]   Australia. And so you didn't know whether they were dropped there. And the other part of the
[02:13:02.240 --> 02:13:08.960]   story was when they got back to Tonga, the fishing boat owner who's both been stolen was still upset.
[02:13:08.960 --> 02:13:16.000]   And so the boys all got arrested. And so the fishing boat captain had connections in Australia.
[02:13:16.000 --> 02:13:20.960]   And so he said, I'll give you the rights to the story in Australia for a TV show.
[02:13:22.240 --> 02:13:29.360]   But one time, and give me the money. And then I'll buy the boat from the guy and get them out of jail.
[02:13:29.360 --> 02:13:39.440]   And that's what happened. And then he, a little more. So he had gone to the King of Tonga,
[02:13:39.440 --> 02:13:43.760]   asking to do a lobster business. And the King of Tonga said, no. But after he did this amazing
[02:13:43.760 --> 02:13:47.440]   things rescuing the boys, the King of Tonga said, what would you like from me? And he said,
[02:13:47.440 --> 02:13:51.440]   I'd like to wear a lobster business. And the King of Tonga said, okay, you can do a lobster business.
[02:13:51.440 --> 02:13:54.640]   So what did the guy do? The fishing boat captain? He hired all the boys.
[02:13:54.640 --> 02:13:58.400]   Oh, oh. So he was good. Peter Warner. In fact,
[02:13:58.400 --> 02:14:02.880]   yeah, he's very good. In fact, this guy in his story says I have nothing but love and respect
[02:14:02.880 --> 02:14:07.200]   for Peter Warner. See, he really owe you reflex. You just wanted, you wanted to find a nice
[02:14:07.200 --> 02:14:13.360]   story about humanity. But he also said he's managed that he said, I wanted to write this story and
[02:14:13.360 --> 02:14:19.440]   make some money for my kids. Now this Wagner guys come along and it's too late. Actually,
[02:14:19.440 --> 02:14:23.760]   I don't think the story is so so light. There's a lot more there. He says, I don't want anybody
[02:14:23.760 --> 02:14:27.440]   to tell my full story until I publish a book from maybe make some living for my grandchildren.
[02:14:27.440 --> 02:14:31.680]   But he says, I don't blame Warner. He says, I know a lot of people say to me things like Mr.
[02:14:31.680 --> 02:14:35.840]   Warner makes a lot of money from our story. Who cares? If no, Mr. Warner, we never survive.
[02:14:35.840 --> 02:14:39.920]   If no, Mr. Warner, we won't be here to tell our story. If Mr. Warner makes some money from
[02:14:39.920 --> 02:14:44.560]   a good luck for him, that's my opinion. I would tell everybody, please shut up. So there you go.
[02:14:44.560 --> 02:14:52.160]   The final word from Toto. Okay. And now my pick.
[02:14:52.160 --> 02:15:01.360]   Well, yeah, tear down all of that. I just said, I heard I remember reading there was more to the
[02:15:01.360 --> 02:15:06.880]   story than a Nihilus meets the eye. I'm not a Nihilus. All right, maybe I am.
[02:15:06.880 --> 02:15:14.000]   So my my pick of the week is a free audio editor web based. So this is good. I miss this. I love
[02:15:14.000 --> 02:15:21.360]   you. Chrome book users because it's all in the browser. It's audio mass dot co. And honestly,
[02:15:21.360 --> 02:15:27.120]   and I've, you know, I use a lot of audio editors. This is a very power. This is kind of amazing.
[02:15:27.120 --> 02:15:32.160]   This is the kind of thing. Yes, journalists can use it has recording built in.
[02:15:32.160 --> 02:15:39.920]   Multi track. It has effects built in, including normalizing. It has graphic equalizer. It's
[02:15:39.920 --> 02:15:45.920]   got a limiter distortion reverb. This is essentially the most important parts.
[02:15:45.920 --> 02:15:51.040]   So if I were doing, so this is just editing, if I were doing an interview with you,
[02:15:51.040 --> 02:15:57.040]   yeah, you could record yourself using this and I could record me using it and then I could
[02:15:57.040 --> 02:16:01.920]   mush the two together. You wouldn't have to have it. Fancy. Yes. No. And the nice thing is this
[02:16:01.920 --> 02:16:06.640]   will work on your Chromebook. This is finally, right? You know, a brand. This is exciting because
[02:16:06.640 --> 02:16:13.040]   Kevin records. He does gymnastics to get audacity running two machines.
[02:16:13.040 --> 02:16:19.920]   How long have you, how large of a file have you brought into this?
[02:16:19.920 --> 02:16:25.600]   I haven't. So I don't know. That would be an interesting question. And if it's really big,
[02:16:25.600 --> 02:16:29.680]   obviously it's going to take a while to upload, right? Yeah, it's a lot of you.
[02:16:29.680 --> 02:16:40.000]   So that much. We'll check a look at this. Check a look at this. Check a look at it.
[02:16:40.000 --> 02:16:46.560]   Stays these tired. And then I want to mention this is related and I think this is really
[02:16:46.560 --> 02:16:51.840]   interesting too. Kevin Rose brought this to my attention in his Twitter. Yes, I read Twitter
[02:16:51.840 --> 02:16:56.720]   once in a while. It's called Descript. Descript got calm. This is not free, but it's really
[02:16:56.720 --> 02:17:02.400]   interesting. And you might be useful. This might be useful for you, Stacey. You record audio and
[02:17:02.400 --> 02:17:09.920]   then it transcribes it. And instead of editing the audio directly, you edit the text and that
[02:17:09.920 --> 02:17:15.280]   and it's the audio. That's also a good question. So I could just say, umbs, but not just by
[02:17:15.280 --> 02:17:19.920]   because like right now I take out the umbs via the phone. So you're good if you have the
[02:17:19.920 --> 02:17:25.200]   consistent phone, but. And it's actually does have a free tier three hours a month for free.
[02:17:26.320 --> 02:17:31.200]   You also if you're paid 10 bucks a month, you can get the audio, human audio transcriptions
[02:17:31.200 --> 02:17:36.560]   and all sorts of stuff. I mean, it's it's pretty amazing. It's a really interesting concept.
[02:17:36.560 --> 02:17:42.240]   That is. Edit audio by editing text. So there's two different things for you. One
[02:17:42.240 --> 02:17:46.880]   or more traditional. And this one is. And I'm sorry, what's this called again?
[02:17:46.880 --> 02:17:53.120]   It's Descript. D E S C R I dot com or Descript. If you think about it, I guess it's a.
[02:17:53.120 --> 02:17:58.880]   Oh, I see it's your D script in your idea. I get it. It does transcription. Apparently you
[02:17:58.880 --> 02:18:03.280]   could do video editing as well because you can X what you do is take the audio track like of this
[02:18:03.280 --> 02:18:09.680]   show and then export the edits to premiere or final cut and do a video edit based on that,
[02:18:09.680 --> 02:18:20.640]   which is pretty darn amazing. That's fancy. Wow. Yeah. Pretty darn good. Also, um, real time
[02:18:20.640 --> 02:18:27.680]   multi user editing and commenting. So as you're working with Kevin, you know, you could do it
[02:18:27.680 --> 02:18:35.040]   together as I don't know how well you get along, but you can do this together to edit your podcast.
[02:18:35.040 --> 02:18:41.920]   Right. I think it's good. I I maintain all editorial control over the podcast. Yes. You
[02:18:41.920 --> 02:18:47.600]   have no Carson to bother you. That's so Kevin. Kevin just records with me. And then I yeah,
[02:18:47.600 --> 02:18:56.160]   I don't have a Carson Carson to piss you off. Huh. Watch it. Watch it. I, you know, I don't take
[02:18:56.160 --> 02:19:07.360]   feedback. That doesn't make me angry. Leo. Oh, I hate you. Oh, thank you everybody for being
[02:19:07.360 --> 02:19:13.360]   here. Stacy Higginbotham and her fabulous podcast on IOT with Kevin Tofel. You'll find that at
[02:19:13.360 --> 02:19:21.280]   Stacy on IOT.com. And of course, her newsletter, which is free and a wonderful read and plus lots
[02:19:21.280 --> 02:19:27.680]   of articles at the website. Don't forget her event is coming up. Yes. Stacy on IOT.com/edge.
[02:19:27.680 --> 02:19:33.360]   Next week at this time, she's going to be competing with us. No, no, no, no. Not next week. It's in a
[02:19:33.360 --> 02:19:38.160]   couple. It's in a few weeks. Sorry. It's next week. It's actually on Thursday. You know, it's not on
[02:19:38.160 --> 02:19:44.320]   the 10th. I'm taking off because Thursday is when I do my newsletter, but I need time to write
[02:19:44.320 --> 02:19:49.040]   the newsletter. So I'm sorry. That's why I'm so organized. We'll have Carson do the show. Wow.
[02:19:49.040 --> 02:19:53.600]   And it'll be great. I was going to say, don't be sad. You're going to get Ant. And he is just like
[02:19:53.600 --> 02:20:00.320]   a cheery, a bear of a person. Yes. He's a cuddly teddy bear of a guy. Unless he gets mad at you.
[02:20:00.320 --> 02:20:06.640]   I'm Jen. He's got muscles out there. And I die. I can't imagine that. No, I, you know,
[02:20:06.640 --> 02:20:08.800]   I've never seen a man. He's just the sweetest. Yep.
[02:20:08.800 --> 02:20:16.400]   And by the way, he posted and we've tweeted it. He posted it on YouTube on his YouTube channel.
[02:20:16.400 --> 02:20:23.520]   Kind of just a 15 minute stream of consciousness about, you know, George Floyd and about the
[02:20:23.520 --> 02:20:29.600]   other stuff. It's very good. And I just love Ant. And I think one of the things that really helps
[02:20:31.040 --> 02:20:37.200]   is just to get to know somebody. I've seen other Black people do this on Twitter and other places
[02:20:37.200 --> 02:20:42.080]   where just let me tell you about myself. You know, I'm not, I'm not the enemy. I'm a human,
[02:20:42.080 --> 02:20:47.520]   just like you. I think that's very valuable. You know, just to remind us, we're all, you know,
[02:20:47.520 --> 02:20:53.680]   we're all in this together. The darkness of one skin does not really change anything at all.
[02:20:53.680 --> 02:20:57.440]   At all. I don't like you, Jeff, because you're so much whiter than I am.
[02:20:58.480 --> 02:21:04.000]   Well, I am extremely white, pink from the camera. Practically, practically pink.
[02:21:04.000 --> 02:21:11.840]   And the more hell I guess worse it is. And some would say a pinko. He is the director of the town.
[02:21:11.840 --> 02:21:17.840]   Look how white he is. The townite center for the entrepreneurial journalism at the Craig Newmark,
[02:21:17.840 --> 02:21:24.400]   Craig Newmark, graduate school journalism, the Craig Newmark graduate school journalism at the
[02:21:24.400 --> 02:21:33.360]   city university of New York, New York, New York. I was watching an interview with the highest
[02:21:33.360 --> 02:21:39.280]   ranking uniformed police officer in the NYPD. And it was great. He was such a New Yorker.
[02:21:39.280 --> 02:21:45.200]   It was so great. Well, I got to try to keep these cleats, streets clear tonight. It was so great.
[02:21:45.200 --> 02:21:50.720]   Oh, man, I miss New York. Thank you, Jeff. Thank you, Stacy. Be well.
[02:21:50.720 --> 02:21:56.400]   Thank you. I love you guys. Love you, Jeff. Even if I am a nihilist.
[02:21:56.400 --> 02:22:05.760]   Bah, humbug. Our show is Wednesday's 130 Pacific. I know it says one on the calendar. I just learned
[02:22:05.760 --> 02:22:11.680]   that myself. I've been late half an hour for the last five years. So I don't know. We'll see if
[02:22:11.680 --> 02:22:15.440]   we can do it. Actually, that was the way to fool you by telling you it was one we actually got to
[02:22:15.440 --> 02:22:21.200]   do it by 130. Now it's going to be too smart. Smart. No, no, no, I'm not going to change the
[02:22:21.200 --> 02:22:26.720]   calendar. That's a very clever idea. Yeah, every every now and then, Carsten's like, hey,
[02:22:26.720 --> 02:22:33.040]   do you want to do it at one? And I'm always like, Oh, no. No, yeah. We could I mean, I could have
[02:22:33.040 --> 02:22:37.600]   today we were when as weekly was done at 1245, but I instead decided to have a leisurely lunch.
[02:22:37.600 --> 02:22:42.480]   I was late today, but it was because I dropped my coffee on the floor and I had to clean it up
[02:22:42.480 --> 02:22:49.280]   before I was like, Oh, no, that's that's awful. That's worse than like anything dropping your coffee.
[02:22:49.280 --> 02:22:54.000]   You have this beautiful couple of you looking for drinking and it's gone. There are lots of
[02:22:54.000 --> 02:23:03.680]   things to work. Not much. That's as bad as it gets. Oh, dear. Oh, dear. I'm a nihilist and a
[02:23:03.680 --> 02:23:10.080]   Pollyanna. It's how does it happen? I don't understand it. It's a contradiction. We do this
[02:23:10.080 --> 02:23:18.160]   show every whenever Wednesday, 130 sort of who cares who cares. It's all me. This I'm a nihilist.
[02:23:18.160 --> 02:23:25.120]   It doesn't matter anyway. That's Pacific time 430 Eastern time 2030. You see if you want to
[02:23:25.120 --> 02:23:29.920]   watch us do it live, you can. There's a stream of twit.tv slash live. There's audio there and video
[02:23:29.920 --> 02:23:35.040]   pick your stream. If you're doing that, chat along with our other live viewers in the chatroom,
[02:23:35.040 --> 02:23:45.680]   I R C dot twit dot TV and and there's on demand versions at the website, twit.tv slash twig.
[02:23:45.680 --> 02:23:50.640]   And that's kind of the key to the whole thing called a podcast. You don't have to listen live.
[02:23:50.640 --> 02:23:56.400]   You can listen whenever you want or watch. We do video to twit.tv slash twig. There's a YouTube
[02:23:56.400 --> 02:24:02.000]   channel with all of our episodes. Smartest thing to do though would be subscribe that way you'd
[02:24:02.000 --> 02:24:05.520]   have it automatically. You wouldn't have to think about it. You just go to your phone and say,
[02:24:05.520 --> 02:24:10.320]   Oh, I do have this week in Google this week. And you can listen at your leisure.
[02:24:10.320 --> 02:24:15.440]   I hope you will do that for us. Thank you. Stay safe, everybody. Have a great week.
[02:24:15.440 --> 02:24:22.080]   And let's let's just do the best we can. Okay, we're going to try to try to get through this
[02:24:22.080 --> 02:24:26.400]   all together. We'll see you next time on this week in Google. Bye bye.
[02:24:27.040 --> 02:24:32.720]   Hey, folks, I am Mike as sergeant co host of tech news weekly right here on the twit network. Yes,
[02:24:32.720 --> 02:24:38.000]   tech news weekly is a show we do every week, Jason how on myself, where we talk to people who are
[02:24:38.000 --> 02:24:42.560]   making and a break in the tech news. That's right. It's journalists, it's inventors, it's
[02:24:42.560 --> 02:24:48.400]   app makers, it's everybody who's bringing the tech news in a given week. It's all the stuff you
[02:24:48.400 --> 02:24:54.400]   want to know about in bite sized chunks in a fantastic package. So be sure to subscribe
[02:24:54.400 --> 02:25:03.760]   is twit.tv/tnw.
[02:25:03.760 --> 02:25:06.340]   (upbeat music)
[02:25:06.340 --> 02:25:09.100]   (silence)

