;FFMETADATA1
title=The Right to Be For Scottin
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=574
genre=Podcast
comment=https://twit.tv/twig
copyright=These podcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.320]   It's time for Twig. This week in Google, Jeff Jarvis is here, Ant-Proit is here, Stacey
[00:00:05.320 --> 00:00:12.320]   Higginbotham is here. We're going to talk about Palantir. What does it do? As it enters
[00:00:12.320 --> 00:00:20.360]   its IPO phase, we're going to talk about heavy ads. How heavy is heavy? And the $200
[00:00:20.360 --> 00:00:27.680]   billion man. We have the technology next on Twig. This week in Google comes to you from
[00:00:27.680 --> 00:00:33.800]   LastPass Studios. Securing every access point in your company doesn't have to be a challenge.
[00:00:33.800 --> 00:00:40.120]   LastPass unifies access and authentication to make securing your employees simple and secure.
[00:00:40.120 --> 00:00:47.800]   Even when they're working remotely, check out LastPass.com/twit to learn more.
[00:00:47.800 --> 00:01:05.560]   Yes you love. This is Twig. This is Twig. This week in Google, Episode 574, recorded Wednesday,
[00:01:05.560 --> 00:01:13.160]   August 26, 2020. The right to be for Scottin. This episode of This Week in Google is brought
[00:01:13.160 --> 00:01:20.040]   to you by Wasabi Hot Cloud Storage. Thinking about moving your data storage to the cloud?
[00:01:20.040 --> 00:01:25.880]   Wasabi is enterprise-class cloud storage and 1/5 the price of Amazon S3 and faster than
[00:01:25.880 --> 00:01:32.400]   the competition with no fees for egress or API requests and no complex storage tiers.
[00:01:32.400 --> 00:01:38.480]   Start a free trial at wasabi.com. Enter the code Twit. It's time for Twig. This week
[00:01:38.480 --> 00:01:43.760]   in Google, the show where we never talk about Google. Just wanted to warn you ahead of time.
[00:01:43.760 --> 00:01:47.960]   Don't get angry. Don't get mad. That's the way it is. Stacey Eganbotham is here. She
[00:01:47.960 --> 00:01:54.760]   talks about the Internet of Things on her website, StaceyOnIOT.com. She's also the host
[00:01:54.760 --> 00:02:02.160]   of the Internet of Things podcast with Kevin Double. Hello Stacey. Hello, yeah. Hello.
[00:02:02.160 --> 00:02:11.040]   It's good to see you also here from the... Where's his? I don't know. I need your title card.
[00:02:11.040 --> 00:02:15.800]   From the Leonard Taill Professor for Generalistic Innovation at the Craig Neumark Graduate School
[00:02:15.800 --> 00:02:21.200]   of Journalism at the City University of New York, Mr. Jeff Jarvis. How are you, Jeff? There
[00:02:21.200 --> 00:02:31.080]   it is. There's the whole lower third. The complete set of honoreres, Buzzmachine.com. He's
[00:02:31.080 --> 00:02:35.520]   sinking behind his lower third. In your case, the lower third is really more like the lower
[00:02:35.520 --> 00:02:39.760]   half. That's good. Well, why do they call a lower third or lower third? It's never third
[00:02:39.760 --> 00:02:44.760]   by the way. It should be the lower sixth, maybe. Yeah. I'm thinking. Yeah. Maybe Aunt
[00:02:44.760 --> 00:02:49.320]   Pruitt knows that. He's a photography kind of guy. I have Aunt Pruitt from Hands Off
[00:02:49.320 --> 00:02:54.320]   Photography and Hands On Wellness. Good to see you. How you doing, Mr. LaPorte? I am well.
[00:02:54.320 --> 00:03:01.520]   I think you had both a sad day and a happy day over the last couple. Yeah. It's been
[00:03:01.520 --> 00:03:07.760]   an interesting couple days here. Should I mention, or is it a private affair? Yeah.
[00:03:07.760 --> 00:03:12.200]   We'll just keep it private. We'll just say things have been up and down, but we are still
[00:03:12.200 --> 00:03:17.040]   unbelievable as always. But on the upside, I think a little bit outweighs the downsides.
[00:03:17.040 --> 00:03:21.920]   Always. Always. A new grandson is always... Or is it a granddaughter? Is always a welcome.
[00:03:21.920 --> 00:03:30.080]   I plead a fifth. I think that should be celebrated. I think that's fantastic. He's a young man,
[00:03:30.080 --> 00:03:38.520]   but he's been busy, as they say. Right. So, Palantir, we were talking about the Lord
[00:03:38.520 --> 00:03:46.640]   of the Rings earlier, the Palantir and Lord of the Rings is that Saruman or Sauron's...
[00:03:46.640 --> 00:03:51.880]   It was the ancient wizards set up Palantir's so that they could see what was... Oh, God,
[00:03:51.880 --> 00:03:57.680]   we're going to go through this now for... Oh, no. No. I refuse to be on a show that takes
[00:03:57.680 --> 00:04:02.680]   the Lord of the Rings. Oh, no. No. Well, that's where the name comes from. I'm just saying.
[00:04:02.680 --> 00:04:05.680]   Oh, my God. It's just... I'm just saying. There were giant crystal balls that were spread
[00:04:05.680 --> 00:04:10.440]   around the earth. You could see what was going on from one Palantir and another. It was for
[00:04:10.440 --> 00:04:18.520]   communications. And it's... Let's talk about... When Peter Teal, former PayPaler, founded a
[00:04:18.520 --> 00:04:23.160]   new company in 2003, he named it Palantir, which tells you a little bit of kind of what
[00:04:23.160 --> 00:04:32.520]   its goals were. It's been a kind of a hushed, shrouded in secrecy, kind of a company until
[00:04:32.520 --> 00:04:42.240]   now. It's about to issue its first IPO, kind of a weird IPO. It's not a traditional IPO.
[00:04:42.240 --> 00:04:47.560]   It's... And I don't really understand what it does. I know that it doesn't make money.
[00:04:47.560 --> 00:04:54.120]   It's quite good at losing money. But the idea is that it uses artificial intelligence to
[00:04:54.120 --> 00:05:02.040]   extract data, which it sells to a variety of people, including the immigration control
[00:05:02.040 --> 00:05:07.160]   in the United States, which has been a little controversial. They sell it to state and local
[00:05:07.160 --> 00:05:13.320]   governments, healthcare industries, financial. They've been involved in tracking COVID-19,
[00:05:13.320 --> 00:05:19.880]   I think, to the good. So they are going to go... They were valued in 2014 at 9 billion,
[00:05:21.880 --> 00:05:31.160]   2015 at 15 billion, 20 billion late that year. They've never, ever reported a profit,
[00:05:31.160 --> 00:05:38.040]   which is my mistake, I think, because we were profitable. And I think the best thing would have
[00:05:38.040 --> 00:05:41.720]   been for us to lose more money. We'd be worth a hell of a lot more.
[00:05:41.720 --> 00:05:49.400]   Jeff Bezos strung that out for a long time. Yeah, but the market knew very well
[00:05:50.600 --> 00:05:57.080]   that he could make money. He chose to. That was kind of more of an accounting thing.
[00:05:57.080 --> 00:06:02.280]   So Alex Karp, who's a very intro... Did you know that Alex Karp did his PhD under Habermas?
[00:06:02.280 --> 00:06:13.160]   I saw him at a conference in Vienna, where he chose to do his interview in German.
[00:06:13.800 --> 00:06:26.280]   He speaks fluent French, German, and English. I would say a bright guy. His PhD thesis under
[00:06:26.280 --> 00:06:33.400]   Habermas was... Let me see if I can find it, because it was... In fact, just now, I was digging back in
[00:06:33.400 --> 00:06:37.960]   to my Habermas. Yeah. Is Habermas still alive? I have a headache.
[00:06:39.000 --> 00:06:44.200]   Someone should explain to those of us who are not intellectually elite what Hopper... Who and
[00:06:44.200 --> 00:06:49.400]   what Habermas... I'll be honest, I would have no idea if Jeff didn't focus his name all the time.
[00:06:49.400 --> 00:06:52.120]   I'm scrambling through to run down.
[00:06:52.120 --> 00:07:01.960]   Who is credited with the concept of the public sphere? And he argued that it arose in the salons
[00:07:01.960 --> 00:07:08.200]   and coffee houses of the 18th century in England and France. There are many who disagree with him
[00:07:08.200 --> 00:07:14.360]   and think the publicness was created otherwise, but he has that analysis and that's what he says.
[00:07:14.360 --> 00:07:18.920]   So, Karp is kind of... Do you want to go back to
[00:07:18.920 --> 00:07:23.960]   Palantiers now and all that, which is worse. Habermas or Palantiers?
[00:07:23.960 --> 00:07:28.680]   Well, no, I've got... So, you know, I have read the Lord of the Rings. So, I had context there.
[00:07:28.680 --> 00:07:31.000]   I just didn't want to spend all my time on it.
[00:07:31.000 --> 00:07:32.920]   Watch out, Robert, I got the Gutenberg.
[00:07:32.920 --> 00:07:37.880]   It's not a big leap from Habermas to Gutenberg at all in my head.
[00:07:37.880 --> 00:07:44.040]   But I'll refrain. As long as we don't have life-stung stuff... Whatever that was.
[00:07:44.040 --> 00:07:53.720]   So, you can tell me what this means. This is his PhD thesis, Alex Karp's "aggression in
[00:07:53.720 --> 00:08:00.440]   Der Liebensfeld". What is that? The free world? "aggression in the life's world.
[00:08:01.400 --> 00:08:06.680]   And fight around the process." He writes about jargon, aggression and culture.
[00:08:06.680 --> 00:08:13.720]   And it is of course in German, because it was the Frankfurt Institute under Habermas that he wrote this.
[00:08:13.720 --> 00:08:21.880]   So, Karp, I think you could probably argue is a fairly sharp fellow. He's been... I think he's
[00:08:21.880 --> 00:08:26.360]   more a businessman than anything else. He inherited money from his grandfather, which he
[00:08:26.920 --> 00:08:34.120]   invested. In fact, he created a private investment firm in the UK called Kedmon and made money there.
[00:08:34.120 --> 00:08:39.880]   Was hired a year after the founding of Palantir to run it. So, he's been there since 2004.
[00:08:39.880 --> 00:08:48.520]   In any event, the reason I bring all of this up is as part of the IPO, the CEO of Palantir,
[00:08:48.520 --> 00:08:54.040]   Alex Karp, has written a letter, which is kind of interesting. And I thought maybe
[00:08:54.920 --> 00:09:00.520]   we could talk about it. It turns out none of you have read it, so I'll give you a little bit of it.
[00:09:00.520 --> 00:09:07.640]   It's not really long, but here it is from CNBC. It starts our welfare and security depend on
[00:09:07.640 --> 00:09:14.440]   effective software. Remember, the business of Palantir is essentially data mining. But he makes
[00:09:14.440 --> 00:09:18.600]   a big distinction between data mining for good and data mining for evil.
[00:09:18.600 --> 00:09:23.160]   Which is fascinating because everyone presumes the Palantir.
[00:09:23.160 --> 00:09:29.400]   It's evil. Yeah. Our software platforms are used by the United States and its allies around the world.
[00:09:29.400 --> 00:09:33.880]   Many of the world's most vital institutions, he writes from defense and intelligence agencies
[00:09:33.880 --> 00:09:40.840]   to companies in healthcare, energy and manufacturing sectors, rely on the software platforms we built.
[00:09:40.840 --> 00:09:44.520]   Our customers come to us because they're, I'm skipping around,
[00:09:44.520 --> 00:09:49.960]   our technological infrastructure has failed them. The enterprise software industry's focus on
[00:09:49.960 --> 00:09:54.760]   custom software tools and applications is misplaced. These approaches often only work
[00:09:54.760 --> 00:09:59.480]   briefly if at all. The problems and needs of an organization often change. Before software can
[00:09:59.480 --> 00:10:04.600]   even be deployed. Our partners need something more than need generalizable platforms for modeling
[00:10:04.600 --> 00:10:08.680]   the world and making decisions. And this is what we've built. This is by the way, the first time
[00:10:08.680 --> 00:10:13.960]   anybody's really said what Palantir does. I don't think that's true. I really want to quibble with
[00:10:13.960 --> 00:10:19.560]   that because we have been saying this. It's an easy cheat to say that we don't know what they do.
[00:10:19.560 --> 00:10:24.440]   And you actually said machine learning earlier, Palantir is just a platform for data analytics.
[00:10:24.440 --> 00:10:31.960]   That has not been a secret at all. And what is a secret is all the resources they're using
[00:10:31.960 --> 00:10:37.080]   and how effective it is. However, not what they do as much as how they do it, I guess.
[00:10:37.080 --> 00:10:41.880]   And whether they're actually good at it, I think that's a really important point Stacy.
[00:10:41.880 --> 00:10:46.280]   And I think they are really good at it. And that's what scares people. So back to the letter. I just,
[00:10:46.280 --> 00:10:50.360]   I hate when people are like, they're so evil and secretive. I'm like, no, they're not. They say
[00:10:50.360 --> 00:10:54.600]   what they do. We just, what's Stacy, how do we know our motives? Are people given everything?
[00:10:54.600 --> 00:10:58.680]   How do we know their government? Because did you? Government ties? Yeah.
[00:10:58.680 --> 00:11:05.640]   I think that's right. Well, there's a lot to unpack here. And we will. I, but we know they're
[00:11:05.640 --> 00:11:11.560]   good at it because ICE, Immigration and Custom Enforcement in the US has been using it very
[00:11:11.560 --> 00:11:18.280]   effectively to mine social data of immigrants and people in communities that have immigrants to
[00:11:18.280 --> 00:11:23.160]   pick the Bob. That New York Times did some great reporting on that fairly recently.
[00:11:23.160 --> 00:11:27.560]   But Clark was quick to say as others have that they don't have anything to do with putting kids
[00:11:27.560 --> 00:11:31.960]   in cages. They're looking for people. A lot of other people take nice dogs.
[00:11:31.960 --> 00:11:37.880]   There's other things they do. There's a big menu, but they're looking for people who've broken the
[00:11:37.880 --> 00:11:46.360]   law. So, well, so have they broken? And this is where we get to, we can make laws.
[00:11:46.360 --> 00:11:50.920]   There's a difference between laws and justice. There's when you, when you start thinking about
[00:11:50.920 --> 00:11:57.400]   laws, we can have unequal enforcement of the laws, but in living in what is becoming a surveillance
[00:11:57.400 --> 00:12:02.600]   state, we can unjustly enforce those laws, which we're having protests right now.
[00:12:02.600 --> 00:12:07.080]   Something interesting to say about that. But that, in that case, I guess the question is,
[00:12:07.080 --> 00:12:09.560]   do you blame Palantir or do you blame the lawmakers?
[00:12:09.560 --> 00:12:15.240]   I think you blame both the lawmakers, but you also look at the tools they're using.
[00:12:15.240 --> 00:12:21.480]   You can't give someone a pass for designing the nuclear bomb, right? I mean, even the scientists
[00:12:21.480 --> 00:12:27.960]   who worked on that were like, oh, they did it. They, you know, and so the question becomes then,
[00:12:27.960 --> 00:12:31.240]   and you could say that an all-
[00:12:31.240 --> 00:12:38.760]   an argument even about the nuclear bomb, which is clearly used against people. But there's,
[00:12:38.760 --> 00:12:42.360]   there's still an argument made that has shortened the war, might have saved lives.
[00:12:42.360 --> 00:12:49.000]   I mean, I remember going to Nagasaki and seeing the classroom of children that was
[00:12:49.000 --> 00:12:54.120]   incinerated by the nuclear bomb, and it's a tragic, tragic thing to see there.
[00:12:54.120 --> 00:12:58.280]   One of the American generals insisted that I just finished reading the book about John
[00:12:58.280 --> 00:13:03.240]   Hersey and Hiroshima that radiation poisoning was a pleasant way to die.
[00:13:03.240 --> 00:13:08.920]   Not so. Yeah. So, and I'm sorry, I was cutting over you when I was asking the case of my question.
[00:13:08.920 --> 00:13:14.120]   You were saying something. Oh, no, I was just, just concerned because he started out saying that
[00:13:14.120 --> 00:13:20.840]   people assume they're evil when all they're doing is just, as with Mrs. Stacy said, was collecting data
[00:13:20.840 --> 00:13:26.360]   and analyzing data. And you, you're going to assume it's evil because it's working with the different
[00:13:27.160 --> 00:13:32.120]   branches of the government. I don't think that's fair. Yeah, I agree with you. Let me continue on.
[00:13:32.120 --> 00:13:37.960]   Because one of the things Carp does in this letter is really excoriate Silicon Valley,
[00:13:37.960 --> 00:13:40.760]   says you're looking at the wrong people. We're not the bad guys here.
[00:13:40.760 --> 00:13:46.600]   First of all, he says, at many organizations, Silicon Valley employees spend their days,
[00:13:46.600 --> 00:13:51.400]   even their careers posturing for others, concerned with claiming credit for success
[00:13:51.400 --> 00:13:55.960]   and avoiding blame for failure. We have rejected that being.
[00:13:56.760 --> 00:14:02.680]   Oh, that's just being all fussy and, you know, he's claiming in this letter. Remember, this letter
[00:14:02.680 --> 00:14:08.680]   is written for potential investors to make the case for why you should invest in us, right? So,
[00:14:08.680 --> 00:14:13.800]   this is, this is to pitch his company, right? I'm better than that. The culture of our company is
[00:14:13.800 --> 00:14:18.200]   more than a mere byproduct of the people we choose to hire our culture and means of organizing
[00:14:18.200 --> 00:14:22.360]   ourselves or preconditions for the creation of effective software. We identify what needs to be
[00:14:22.360 --> 00:14:25.560]   done and organize ourselves around the outcomes that we hope to achieve.
[00:14:25.560 --> 00:14:31.320]   Entire companies can assist for years on business models that may have made sense at some point
[00:14:31.320 --> 00:14:34.760]   in the past and the short term they're often profits to be extracted from the enterprise
[00:14:34.760 --> 00:14:39.320]   and from customers, but we've rejected this way of working. The alignment of interest between our
[00:14:39.320 --> 00:14:44.280]   employees and our company and between our company and our customers is one of the principal reasons
[00:14:44.280 --> 00:14:52.440]   we've come as far as we have. Now, this is where he starts to get mad at Silicon Valley.
[00:14:52.440 --> 00:14:56.760]   And it actually, it stays to be really interesting what you think about this. So,
[00:14:56.760 --> 00:15:01.800]   our work and the use of our software present difficult questions. So, acknowledge is what
[00:15:01.800 --> 00:15:06.440]   we're talking about here. The construction of software platforms that enable more effective
[00:15:06.440 --> 00:15:13.640]   surveillance by the state of its adversaries or that assists soldiers in executing attacks,
[00:15:13.640 --> 00:15:19.240]   raises countless issues involving the points of tension and trade-offs between our collective
[00:15:19.240 --> 00:15:26.920]   security and individual privacy, the power of machines, and the types of lives we both want to
[00:15:26.920 --> 00:15:31.400]   and should lead the ethical challenges that arise are constant and unrelenting. So, he's
[00:15:31.400 --> 00:15:34.440]   basically saying, "We don't ignore that." He's owning it up to it.
[00:15:34.440 --> 00:15:38.360]   Yeah, we accept. Let's see what choices he chooses to make and that's how you judge them.
[00:15:38.360 --> 00:15:42.040]   It's not enough to say they're ethical challenges. The fundamental issue is we're authority
[00:15:42.600 --> 00:15:48.920]   to resolve such questions to decide how technology may be used and by whom should reside. Our society
[00:15:48.920 --> 00:15:53.640]   has effectively outsourced the building of software that makes our world possible.
[00:15:53.640 --> 00:15:58.040]   Now, this is where he really starts to get critical of Silicon Valley to a small group of
[00:15:58.040 --> 00:16:04.200]   engineers in an isolated corner of the country. The question is whether we also want to outsource
[00:16:04.200 --> 00:16:09.720]   the adjudication of some of the most consequential moral and philosophical questions of our time.
[00:16:09.720 --> 00:16:14.520]   The engineering elite of Silicon Valley may know more than most about building software,
[00:16:14.520 --> 00:16:19.640]   but they do not know more about how society should be organized or what justice requires.
[00:16:19.640 --> 00:16:26.840]   I'm going to come back up with Stacy, you first. No, I was just to say yes.
[00:16:26.840 --> 00:16:31.160]   Yes, it is an interesting letter. Yeah, don't you think?
[00:16:31.160 --> 00:16:36.600]   But, well, no, here's, so I heard him do the spiel in Vienna two years ago.
[00:16:37.880 --> 00:16:41.160]   And this is regulatory capture is what's happening here.
[00:16:41.160 --> 00:16:45.800]   What he's saying is, don't blame us. Sorry. We shouldn't make any of these decisions.
[00:16:45.800 --> 00:16:48.280]   Yeah, don't blame us. Don't blame us for what we're doing.
[00:16:48.280 --> 00:16:50.680]   And then don't blame us, right? Because government should make decisions.
[00:16:50.680 --> 00:16:54.520]   We shouldn't make decisions. So you do it and we'll just do whatever the hell we want within those
[00:16:54.520 --> 00:17:00.680]   limitations. And then we're going to go wild. And I heard him then as a cop out.
[00:17:00.680 --> 00:17:06.360]   But wait, I think it's an adaptation of the individual's role in participating in
[00:17:06.360 --> 00:17:09.720]   sex. But I do think. Well said. Okay.
[00:17:09.720 --> 00:17:13.320]   But he is saying, let me go on. Next section, section four.
[00:17:13.320 --> 00:17:19.800]   Our company was founded in Silicon Valley, but we seem to share fewer and fewer of the technology
[00:17:19.800 --> 00:17:23.640]   sectors, values, and commitments. This is something we talk about a lot on this show.
[00:17:23.640 --> 00:17:29.960]   From the start, we've repeatedly turned down opportunities to sell, collect, or mine data.
[00:17:29.960 --> 00:17:35.080]   Other technology companies, including some of the largest in the world, Google,
[00:17:35.080 --> 00:17:38.680]   have built their entire businesses on doing just that.
[00:17:38.680 --> 00:17:44.120]   Software projects with our nation's defense and intelligence agencies, whose missions are to
[00:17:44.120 --> 00:17:49.640]   keep us safe, have become controversial. While companies built on advertising dollars,
[00:17:49.640 --> 00:17:54.280]   are commonplace. For many consumer internet companies, our thoughts and inclinations,
[00:17:54.280 --> 00:18:00.520]   behaviors, and browsing habits are the product for sale. The slogans and marketing of many of
[00:18:00.520 --> 00:18:03.960]   the Valley's largest technology firms attempt to obscure this simple fact.
[00:18:03.960 --> 00:18:10.280]   The world's largest consumer internet companies have never had greater access to the most intimate
[00:18:10.280 --> 00:18:15.000]   aspects of our lives. And the advance of their technologies has outpaced the development of
[00:18:15.000 --> 00:18:19.080]   the forms of political control that are capable of governing their use.
[00:18:19.080 --> 00:18:22.840]   Palantir is serving people with guns and Google is not.
[00:18:24.120 --> 00:18:31.400]   So yes, he's not wrong here. I stepped on you didn't mean to.
[00:18:31.400 --> 00:18:34.600]   No, I want you have not said a word. Do it.
[00:18:34.600 --> 00:18:40.840]   Well, so right there, they're pointing at the likes of Google, but aren't they still doing the
[00:18:40.840 --> 00:18:45.560]   same thing, just collecting data, analyzing data, figuring out a way to air quotes,
[00:18:45.560 --> 00:18:48.120]   sale that to their client for some sort of profit.
[00:18:48.120 --> 00:18:57.320]   Yes, but they said, but the purpose is different. They say our software isn't used to collect your
[00:18:57.320 --> 00:19:02.920]   personal data for marketing. Our software is used to target terrorists and to keep soldiers safe.
[00:19:02.920 --> 00:19:07.000]   If we're going to ask someone to put themselves in harm's way, we believe we have a duty to give
[00:19:07.000 --> 00:19:11.800]   them what they need to do their job. We have chosen sides. And we know that our partners value
[00:19:11.800 --> 00:19:17.800]   our commitment. We stand by them when it's convenient and when it's not. So what he's really saying
[00:19:17.800 --> 00:19:19.960]   is manufacturer. They're a weapons manufacturer.
[00:19:19.960 --> 00:19:23.400]   Yes. They're like an arm stealer. Yeah.
[00:19:23.400 --> 00:19:31.000]   Let's take this to the Marvel universe. There. Let me start. Pre his Iron Man debut.
[00:19:31.000 --> 00:19:35.240]   And the debate we're about to have in was it age of ultra? No, which one was it where
[00:19:35.240 --> 00:19:41.880]   they were the big debate is they're launching the little satellites up in the air to like
[00:19:43.000 --> 00:19:49.400]   understand what everyone's doing. Well, we're out here. Was that civil war? Was that civil war?
[00:19:49.400 --> 00:19:56.920]   I can't remember. I think it was civil war action. No, I can't remember.
[00:19:56.920 --> 00:20:01.000]   Ask me about playing the Chinese and automobiles and we can. I think. All right.
[00:20:01.000 --> 00:20:06.280]   Just civil war says low jobs. So the point. So the point is in the plot line there was that
[00:20:06.280 --> 00:20:12.280]   to prevent terrorism, you have to know everything about everybody and have the ability to take them
[00:20:12.280 --> 00:20:17.640]   out before they do evil. This isn't that's an exaggeration of this argument, but that's what's
[00:20:17.640 --> 00:20:23.880]   happening. And this is a very simplistic view of the world. And yes, he's not wrong about Google,
[00:20:23.880 --> 00:20:33.880]   but it's very common and it's easy to say. I am going to let I'm going to abdicate my moral
[00:20:33.880 --> 00:20:40.280]   responsibility to my customers and I've made my moral decision by supporting the aims of my
[00:20:40.280 --> 00:20:48.280]   customers. But that ignores like Tony Stark ignored the fact that creating these wars is not great
[00:20:48.280 --> 00:20:54.280]   and that those arms can get into other hands and that there is inherent damage from this. And so
[00:20:54.280 --> 00:20:59.800]   you can't and we don't live in the Marvel universe, right? We live in the real world. So you have to say,
[00:20:59.800 --> 00:21:06.040]   I think you constantly have to evaluate this and you may have to say, yeah, we're okay.
[00:21:07.080 --> 00:21:12.840]   You know, using people's data, don't collect the data. Their customers collect the data for
[00:21:12.840 --> 00:21:16.920]   them and give it to them and then they analyze it and come up with they create the platform for it.
[00:21:16.920 --> 00:21:24.760]   Okay. And we're okay putting people in jail that it may not be just, but it follows the law.
[00:21:24.760 --> 00:21:28.520]   And that's that's what they do. And this letter is just.
[00:21:28.520 --> 00:21:32.600]   I don't think he's abrogating. I think you're I think you're saying that he's abrogating
[00:21:32.600 --> 00:21:38.040]   responsibility for what he's doing. I think he's saying, look, we we we use similar technology to
[00:21:38.040 --> 00:21:43.000]   that of the advertising companies like Facebook and Google, but we feel that we have a higher
[00:21:43.000 --> 00:21:50.840]   calling. We're using that information to save lives, to protect our nation, to to act the will
[00:21:50.840 --> 00:21:59.960]   out the will of society as opposed to the chasing the money for
[00:22:01.240 --> 00:22:08.200]   for marketing that we have a higher principle. Yeah, I get that. But that saying that that's
[00:22:08.200 --> 00:22:14.760]   your higher principle. Well, it is a higher. Everyone's still about it. We might just look at it. I think
[00:22:14.760 --> 00:22:20.920]   one thing we all agree on is perhaps we don't agree with what the United States decides
[00:22:20.920 --> 00:22:26.680]   what our current government has decided to do with this information. But if you put that aside
[00:22:26.680 --> 00:22:32.040]   and say, look, the purpose of government of civil society is to express the will of the people.
[00:22:32.040 --> 00:22:40.040]   And it is, I mean, no one is saying you shouldn't have a military, right? Or maybe maybe you are
[00:22:40.040 --> 00:22:45.240]   saying there are people who are actually I know people say that, but put it to police. We should
[00:22:45.240 --> 00:22:50.920]   put it to policing, right? So let's look, we had this discussion before about facial recognition,
[00:22:50.920 --> 00:22:54.840]   and you were both on the case of, yes, cut it off, because you don't know how police are going to
[00:22:54.840 --> 00:22:58.680]   use it. They're going to use it badly. They should not have it. They shouldn't have it because it is
[00:22:58.680 --> 00:23:04.440]   not currently as it exists. It's not reliable. That's you don't even know what palantarians do.
[00:23:04.440 --> 00:23:07.400]   You don't even know what conclusions are going to be placed. You don't even know where they're going
[00:23:07.400 --> 00:23:11.480]   because there's no transparency here because it's all secretive. And so it could be worse than that.
[00:23:11.480 --> 00:23:15.720]   That's actually good. Yet you're somehow saying, oh, it's okay here because we don't know.
[00:23:15.720 --> 00:23:21.640]   No, that's a very good point that that we would it would be better. This I would trust this letter
[00:23:21.640 --> 00:23:26.280]   better if there were more open about what they do and how they do it. I agree with you.
[00:23:26.280 --> 00:23:31.480]   I don't think it matters. They're taking a bit of a moral hybrid. Well, absolutely. That's their
[00:23:31.480 --> 00:23:38.360]   point. Let's just look at this in a simpleton standpoint. And the first thing to come to my
[00:23:38.360 --> 00:23:44.520]   mind was Google and Google Maps. And I'm a commuter that's not making a lot of money,
[00:23:44.520 --> 00:23:50.040]   but I have to get to work on time every day. And it saves me a little bit of money to bypass
[00:23:50.600 --> 00:23:55.560]   tolls or what have you. So Google knows, okay, you need to take this route to bypass tolls.
[00:23:55.560 --> 00:24:00.280]   It's watching me and saying, hey, you know what, you might want to turn left here instead of
[00:24:00.280 --> 00:24:04.440]   turning right over there because you'll be able to get to work on time a little bit faster and
[00:24:04.440 --> 00:24:10.920]   you're able to avoid the tolls. That's a big help to some people. And it's a lot of privacy
[00:24:10.920 --> 00:24:16.040]   implications there, but that is a big help and convenient for some people. Why are they trying
[00:24:16.040 --> 00:24:21.000]   to say that's just something horrible that Google is doing? No, they're saying, no, I don't think
[00:24:21.000 --> 00:24:26.200]   that they're talking about that. They're talking about the fact that's why utilitarianism morals to
[00:24:26.200 --> 00:24:32.440]   Google. I think you did. Did that just happen? That was awesome. But I don't think that's the
[00:24:32.440 --> 00:24:36.280]   criticism he's making. I think he's saying, look, these companies don't kid yourself.
[00:24:36.280 --> 00:24:40.920]   Google's business and Facebook's business is to collect everything they know about you so they
[00:24:40.920 --> 00:24:46.280]   could sell that to the highest. Mark, that's what I said, the fraction of it. So I know it's not
[00:24:46.280 --> 00:24:52.200]   the rule. You're exactly right. And that's the trade off that you and I make. We use Google
[00:24:52.200 --> 00:24:56.440]   knowing perfectly well that they're going to do that because we get value. There's utility in the
[00:24:56.440 --> 00:25:02.600]   stuff. They give us a return. So we're making an economic, we're making an economic decision,
[00:25:02.600 --> 00:25:07.400]   which is ours to make saying, look, I'm going to use a Google, I'm going to have a Google
[00:25:07.400 --> 00:25:12.600]   camera in my house because it's very useful to me for a variety of reasons. I know what they're
[00:25:12.600 --> 00:25:19.880]   doing with that information, but I think that's a fair trade. I would say you have to also consider
[00:25:19.880 --> 00:25:26.360]   is Google doesn't actually have access to the power of the state. And Palantir's data collection
[00:25:26.360 --> 00:25:31.800]   comes with the arm. It serves the power of the state. And he's using that as an awesome thing,
[00:25:31.800 --> 00:25:41.400]   right, which is great in terms of his worldview. But the state can do all kinds of things to
[00:25:41.400 --> 00:25:47.320]   citizen with that data that Google cannot. So he doesn't really talk about that. And he just kind
[00:25:47.320 --> 00:25:51.800]   of elides that point with the fact that, oh, we've all agreed to this with the moral, you know,
[00:25:51.800 --> 00:25:57.000]   as a society, but we really haven't. And what states, by the way, we have it one because there's
[00:25:57.000 --> 00:26:02.280]   not true, but well, and then he may say, well, that don't take that up with me. Take that up
[00:26:02.280 --> 00:26:08.360]   with government. If the government is reflecting their desire, yeah, we need government. Is he doing
[00:26:08.360 --> 00:26:12.600]   it? Is he doing it for Turkey? Is he doing it for Hungary? Is he doing it for China? We don't know.
[00:26:12.600 --> 00:26:17.160]   No, no, he says very specifically. We were now, he hasn't met. I don't know about Hungary and Turkey,
[00:26:17.160 --> 00:26:22.520]   but he's very specifically said, we have chosen not to give that information to China, because we
[00:26:22.520 --> 00:26:27.400]   don't. Our leadership believes that this is the quote is in their s one filing. Our leadership
[00:26:27.400 --> 00:26:31.880]   believes that working with the Chinese Communist Party is inconsistent with our culture and mission.
[00:26:31.880 --> 00:26:36.440]   We do not consider any sales opportunities within the Chinese Communist Party. Do not host our
[00:26:36.440 --> 00:26:44.440]   platforms in China. That's the only country he names. He names it as a risk. What about Brazil?
[00:26:44.440 --> 00:26:49.480]   Yeah, he names. No, he knows the reasoning is a risk. No, stop. Let me finish. The reason he names
[00:26:49.480 --> 00:26:54.760]   it as a risk is because it's a very, very large market. He says our unwillingness to work with
[00:26:54.760 --> 00:26:59.560]   China could hamper growth, given that it's the world's second largest economy. But here's why
[00:26:59.560 --> 00:27:07.160]   we don't do it. We to promote respect for and defend privacy and civil liberties protections.
[00:27:07.160 --> 00:27:11.560]   So I don't eat. They don't bring up Turkey, but it's not a very big economy. They may well not
[00:27:11.560 --> 00:27:15.560]   choose to work with Turkey. I don't know. I think you hit the nail on the head, though, Jeff.
[00:27:16.600 --> 00:27:20.920]   All of this is fine if they're open about what they do and how they do it.
[00:27:20.920 --> 00:27:27.080]   But because it's a black box, nobody's getting a way in on what he's up to. He's just saying,
[00:27:27.080 --> 00:27:32.120]   well, no, the government knows. Right. And it's like the stuff that Snowden revealed.
[00:27:32.120 --> 00:27:35.400]   Right. This is all. This is for your good. We're doing this in your interest. We are the government,
[00:27:35.400 --> 00:27:39.480]   which one would hope to wish to believe. But in the case of what Snowden revealed,
[00:27:39.480 --> 00:27:43.880]   no, don't do that in my name. We don't want that done in our name. In this case, it's not just
[00:27:43.880 --> 00:27:47.480]   that was just privacy. Right. And I'm not I'm not the finish. Any board is a privacy folks.
[00:27:47.480 --> 00:27:51.480]   It's important, but it's a lot more to stop people at the border,
[00:27:51.480 --> 00:27:56.120]   Stacy's right to arrest people, presumptively, because you think they could be doing something
[00:27:56.120 --> 00:28:06.120]   bad or to target bombs in Iraq or Afghanistan. Right. Like the winter soldier. Yes.
[00:28:06.760 --> 00:28:13.880]   Winter soldier. Thank you, Chad. I was like, evil John in the chat room says, he's a war
[00:28:13.880 --> 00:28:23.000]   profiteer that makes it legal, but doesn't make it ethical. Oh, right. So I actually,
[00:28:23.000 --> 00:28:28.760]   when I read this, I liked it. The moral high ground he took. But I think you guys have really
[00:28:28.760 --> 00:28:35.240]   punctured it with the problems and the chief problem for me is it's complete lack of transparency
[00:28:35.240 --> 00:28:41.000]   about what it's also, I think it's a little bit like Apple, where Apple took a disadvantage.
[00:28:41.000 --> 00:28:44.920]   It couldn't sell ads to know how to and turn that into a feature and said, Oh, we're wonderful.
[00:28:44.920 --> 00:28:48.840]   Well, right now in the last weeks, now that Epic is going after them, now Epic is paying
[00:28:48.840 --> 00:28:52.280]   Apple as the evil company and they may not be evil and advertising, but they're evil and
[00:28:52.280 --> 00:28:55.960]   taking 30% of my business. Right. So, you know, I can.
[00:28:55.960 --> 00:29:04.280]   It is. So let's not let's not take profiting. And I wouldn't even call that profiteering. That's
[00:29:04.280 --> 00:29:08.200]   just a business decision. I agree with you. I don't think it's evil.
[00:29:08.200 --> 00:29:13.400]   I agree. No, but I'm saying people are calling them evil. I agree. No, I agree with you. Absolutely.
[00:29:13.400 --> 00:29:15.880]   I know we're so quick to call everything evil.
[00:29:15.880 --> 00:29:20.600]   Yeah. When a reporter came after me and tried to get me to say it was evil, I said it's
[00:29:20.600 --> 00:29:25.400]   negotiation. He's got he's got more power than most Epic does, right? More power than most now.
[00:29:25.400 --> 00:29:28.680]   He's trying to use it to reduce the rate. It's business. It's always been business.
[00:29:28.680 --> 00:29:33.240]   You know, that's what it is. So, no, I agree with you Stacy, but I'm just saying that that
[00:29:34.200 --> 00:29:40.440]   the presumption that facial recognition technology out of Amazon is evil and wrong, right,
[00:29:40.440 --> 00:29:46.120]   is is no different from saying the talent here is evil or right. We just we don't know enough.
[00:29:46.120 --> 00:29:51.960]   This is a very good conversation. I'm glad I had a feeling when I read this that you would
[00:29:51.960 --> 00:29:56.280]   all have something to say about it. And you've absolutely clarified my thinking a little bit.
[00:29:56.280 --> 00:29:59.480]   And thank you for doing our homework for us because that's the one that I didn't read.
[00:29:59.480 --> 00:30:05.320]   Well, I wish I saw it in a rundown sooner. Yeah. I mean, I think it's well, and I moved it
[00:30:05.320 --> 00:30:11.960]   high right up to the top. But mostly because it's a Habermas was mentioned, but breaking news
[00:30:11.960 --> 00:30:18.360]   from the world or not. Yes. CNN politics just in Dr. Anthony Fauci says he was undergoing surgery
[00:30:18.360 --> 00:30:24.440]   and under anesthesia when the White House Coronavirus Task Force discussed new CDC testing guidelines
[00:30:24.440 --> 00:30:27.960]   in which they're backing off testing. Yeah. Yeah. Good timing.
[00:30:27.960 --> 00:30:31.560]   These are the folks who are hiring. Convenient. Just just to mention, just to mention, just
[00:30:31.560 --> 00:30:35.480]   convenient. Yeah. But I have to tell you, if Joe Biden gets elected, I guarantee you,
[00:30:35.480 --> 00:30:39.080]   it's not going to cut into the Palantiers profit. Actually, they don't have any, but.
[00:30:39.080 --> 00:30:46.120]   It's not going to cut into their revenue. Yeah. I don't think those contracts go away.
[00:30:46.120 --> 00:30:51.240]   I mean, and they were there under Obama as well. It's pretty clear. Yeah. If you, I mean, go
[00:30:52.120 --> 00:30:58.600]   back to Eisenhower's famous speech about the military industrial complex and insert instead
[00:30:58.600 --> 00:31:04.360]   of military industrial, maybe we call it the military data complex. And we're just going to
[00:31:04.360 --> 00:31:10.840]   keep building this and building this until we, as a society, decide it's not worth it. And I
[00:31:10.840 --> 00:31:19.400]   don't see us making that decision anytime soon. And, you know, I respect. I don't know. I heavily
[00:31:19.400 --> 00:31:25.480]   respect the desire to keep our service personnel overseas safe. I think that's a great thing. I
[00:31:25.480 --> 00:31:32.120]   heavily, I respect the desire to keep us safe from attack. That's all to the well and good.
[00:31:32.120 --> 00:31:36.600]   But I think it's also in a democratic society important to debate it and important to understand
[00:31:36.600 --> 00:31:42.040]   the tools that are being used. And the problem with these new software tools is there,
[00:31:42.040 --> 00:31:48.760]   it's unknown how powerful they are. They may be extraordinarily powerful. And it's as if you
[00:31:48.760 --> 00:31:53.800]   invented the atom bomb, it didn't tell anybody what it did or how it worked. You just sold it to
[00:31:53.800 --> 00:31:59.400]   whoever wanted it. That's problematic. We need to have, you can't have a debate. And this, and our
[00:31:59.400 --> 00:32:03.400]   society depends on that debate, unless you understand what you're debating. And we just
[00:32:03.400 --> 00:32:07.640]   tell the Hersey book, Hiroshima, which was written for the New Yorker, and they took over the entire
[00:32:07.640 --> 00:32:12.120]   issue, and then it was sold as a book, huge sales, the book I just read or listened to,
[00:32:12.120 --> 00:32:18.520]   about the making of the Hersey book, was making clear that the effort of government was to keep
[00:32:18.520 --> 00:32:24.520]   reporters out of Hiroshima and Nagasaki, to not reveal how bad the bomb destruction was,
[00:32:24.520 --> 00:32:29.480]   to act as if dying in radiation poisoning. Well, first to deny that existed, and then to say
[00:32:29.480 --> 00:32:35.160]   that it was a pleasant way to die, and to try to keep us from having the knowledge that we need
[00:32:35.160 --> 00:32:38.280]   and the democracy to make exactly the kind of decisions you're talking about.
[00:32:38.280 --> 00:32:42.600]   We have to make this. There's an argument to be able to need military secrecy.
[00:32:42.600 --> 00:32:48.040]   If the Manhattan Project hadn't been secret, the Germans or the Japanese might have been able to
[00:32:48.040 --> 00:32:53.560]   steal it and beat us to the punch. So there's a reasonable argument for secrecy, but at some point
[00:32:53.560 --> 00:32:58.840]   in a democratic society, we need to debate these things. I don't know if Truman could have
[00:32:58.840 --> 00:33:03.640]   gone in the nation and say, "Hey, look, I'm thinking about a massive bomb on Japan. What do you think?
[00:33:03.640 --> 00:33:07.960]   Yes or no?" That wouldn't have worked either. So this is, it's a little challenging. It's a
[00:33:07.960 --> 00:33:12.280]   little difficult, by the way. I just found out my grandfather worked on the Manhattan Project.
[00:33:13.160 --> 00:33:18.440]   Wow. He was a metallurgist. My mom used to tell me to come home with a briefcase
[00:33:18.440 --> 00:33:27.400]   chained to his sleeve. She said, "We'd go to a picnic or whatever. He'd never be without it.
[00:33:27.400 --> 00:33:31.400]   His briefcase was with him at all times." She said, "I don't know exactly what he did,
[00:33:31.400 --> 00:33:35.480]   but it was something about reactors." I said, "Oh, well, he's a metallurgist. He's either working on
[00:33:35.480 --> 00:33:41.160]   the rods or the containment vessels, something like that." And the other thing she said is,
[00:33:41.160 --> 00:33:47.000]   one night in 1945, he came home. He said, "I can't tell you why, but the war is going to be over
[00:33:47.000 --> 00:33:53.160]   in four months." Whoa. Whoa. And he was right. I think he actually had to kill you then.
[00:33:53.160 --> 00:33:57.880]   That was Hiroshima and Nagasaki. Wow. My grandfather worked on that.
[00:33:57.880 --> 00:34:07.240]   I don't know at what point that debate happens. You can't have it before. You can have it after.
[00:34:07.240 --> 00:34:12.920]   I guess. I think that that debate, we had that debate globally over nuclear proliferation.
[00:34:12.920 --> 00:34:18.520]   I think we've all agreed. We shouldn't have another case of Hiroshima and Nagasaki, right?
[00:34:18.520 --> 00:34:21.960]   So you're delayed as well. Something. Something that you're talking about.
[00:34:21.960 --> 00:34:29.720]   Oh, no, that's okay. Some things have to be done in private, but not as many things need to be
[00:34:29.720 --> 00:34:35.640]   done in privacy as the government and as the people in charge would have you think.
[00:34:35.640 --> 00:34:43.800]   Right. They love secrecy. Yeah. And it's a fetish. So I think, yeah.
[00:34:43.800 --> 00:34:48.920]   So we elect Congress. We elect oversight committees,
[00:34:48.920 --> 00:34:53.720]   intelligence committees, a meeting secret that are told things that the public can't be told.
[00:34:53.720 --> 00:34:58.120]   They don't know stuff now, right? And that was, again, that goes back to the point of Snowden.
[00:34:58.120 --> 00:35:02.760]   There were things that the government was doing that Congress didn't know. There are things
[00:35:02.760 --> 00:35:06.120]   the government's doing now that Congress doesn't know. There were things that they were doing to
[00:35:06.120 --> 00:35:13.640]   Google that Google didn't know. Well, we're in a situation where what we all thought were norms
[00:35:13.640 --> 00:35:20.840]   and normative behavior that everybody would adhere to suddenly nobody cares about anymore.
[00:35:20.840 --> 00:35:29.320]   And that's a problem. And you have political conventions being held in the White House.
[00:35:29.320 --> 00:35:33.160]   That's a problem. And it's a patent violation of the law, but it's
[00:35:33.160 --> 00:35:36.280]   Kellyanne Conway said, "Let me know when they put somebody in jail for this."
[00:35:36.280 --> 00:35:42.200]   And so if you've got somebody who's willing to break the norms, doesn't really care,
[00:35:42.200 --> 00:35:47.320]   then we really got a problem because there is no chance for this democratic debate.
[00:35:47.320 --> 00:35:53.480]   There's no chance for Congress to do oversight. This was a good discussion.
[00:35:53.480 --> 00:35:59.160]   Yeah. Let's take a break. We have some Googly stuff. This was peripherally about
[00:35:59.160 --> 00:36:04.440]   Google. Because I think his criticism is certainly of Google and probably of Facebook as well.
[00:36:04.440 --> 00:36:09.320]   And if anyone gives us grief about talking about not talking about Google last week,
[00:36:09.320 --> 00:36:12.840]   we talked to good 25% about Google. At least.
[00:36:12.840 --> 00:36:15.720]   Pop that number up. Pop that number up.
[00:36:15.720 --> 00:36:20.760]   Twenty-five percent. Can't we do more? It was pretty high. Look, I'm going to confess,
[00:36:20.760 --> 00:36:27.880]   I misnamed the show. I can't deny it. It is not. We just don't we don't have another name for it.
[00:36:27.880 --> 00:36:31.320]   And now it's a gathering about technology and society.
[00:36:31.320 --> 00:36:34.040]   Yeah, that wouldn't be good. If nobody's going to listen to that, grab one.
[00:36:34.040 --> 00:36:36.040]   So we have to pretend it's about Google. I'm saying,
[00:36:36.040 --> 00:36:39.240]   Albermas and Gutenberg. This weekend, Humbermas.
[00:36:39.240 --> 00:36:43.960]   I would not listen to that. I got to be honest.
[00:36:43.960 --> 00:36:51.560]   I showed it a brought to you my wasabi hot cloud storage. Would you listen to me?
[00:36:51.560 --> 00:36:55.000]   If I told you there's something better than S3, better than Google Cloud,
[00:36:55.000 --> 00:37:01.080]   better than Azure, faster, less expensive, better than on-prem storage, that's wasabi.
[00:37:01.080 --> 00:37:09.320]   Wasabi is disruptive technology that's highly secure. It's turning the industry on its ear.
[00:37:09.320 --> 00:37:15.320]   Storage that's 80% cheaper and up to six times the speed of Amazon S3.
[00:37:15.320 --> 00:37:23.800]   With no charge for egress, no complicated tiering, no charge for API access. Wasabi's
[00:37:23.800 --> 00:37:30.920]   kind of amazing. Wasabi is so affordable, it actually costs less than the same amount of on-premises
[00:37:30.920 --> 00:37:37.000]   storage. In fact, it not only costs less than the annual maintenance fees on the same amount of
[00:37:37.000 --> 00:37:41.800]   on-prem storage. You'll save a lot of money with wasabi. A lot of businesses these days are
[00:37:41.800 --> 00:37:47.000]   creating data at a rapid but predictable pace. You know, we're going to need another petabyte
[00:37:47.000 --> 00:37:50.840]   of storage in the next year. We're going to need another 100 terabytes in the next month.
[00:37:50.840 --> 00:37:55.240]   That kind of thing. You know, so instead of going out and buying on-premise
[00:37:55.240 --> 00:38:00.680]   storage solutions, why don't you do it in the cloud? I'll tell you why. I'll take
[00:38:00.680 --> 00:38:06.280]   you to my argument for it. I would argue it's more secure than your on-prem storage. 11
[00:38:06.280 --> 00:38:13.640]   nines of durability. Wasabi's data is hosted in premier, redundant, tier four data center
[00:38:13.640 --> 00:38:18.600]   facilities. They're highly secure. Their active integrity checking means everything you store
[00:38:18.600 --> 00:38:24.840]   in wasabi is checked for integrity every 90 days. And because you're in redundant servers,
[00:38:24.840 --> 00:38:31.080]   in redundant centers, you can always restore anything that's missing. Wasabi is secure by default.
[00:38:31.080 --> 00:38:35.960]   All the data stored in the cloud is always encrypted at rest, even if you don't specify it.
[00:38:35.960 --> 00:38:41.800]   Wasabi has some really cool ways of keeping your data safe from, let's say, ransomware or human
[00:38:41.800 --> 00:38:47.560]   error. For instance, you can designate data immutable. It cannot be erased. It cannot be altered. You'll
[00:38:47.560 --> 00:38:53.720]   be protected from malware, from hackers, from fumble-fingered employees. That's awesome. There's
[00:38:53.720 --> 00:38:58.600]   access control mechanisms, bucket policies and access controllers so that only the right people
[00:38:58.600 --> 00:39:03.800]   have access to your data. Wasabi follows in every respect the best industry security models
[00:39:03.800 --> 00:39:09.160]   and design practices. Now, there's two ways to pay. They've got their very low cost,
[00:39:09.160 --> 00:39:14.440]   play as you go, so just buy it as you need it. And I actually know a lot of people are using it
[00:39:14.440 --> 00:39:18.680]   that way, just kind of back up that kind of thing. But you can also pay ahead of time with reserved
[00:39:18.680 --> 00:39:23.880]   capacity storage. This is particularly for people who are buying on-prem storage at a regular clip.
[00:39:23.880 --> 00:39:31.240]   You know what you need. If you buy ahead one, three or five year increments, you'll get greater
[00:39:31.240 --> 00:39:38.840]   discounts for the longer term and the higher capacity. The savings are spectacular. It's really a
[00:39:38.840 --> 00:39:44.680]   good solution for anybody who's buying hardware right now. Don't buy more hard drives. Buy the
[00:39:44.680 --> 00:39:52.360]   cloud by Wasabi. Of course, it's HIPAA compliant, FINRA compliant. CJIS compliant. Wasabi is secure,
[00:39:52.360 --> 00:39:57.800]   it's fast, it's safe, and it's 80% less expensive. Calculate the savings for yourself and start a
[00:39:57.800 --> 00:40:04.120]   free trial for a month. Check out Wasabi, W-A-S-A-B-I.com. Click the free trial link.
[00:40:04.120 --> 00:40:10.360]   Get to the code "Twit" wasabi.com. Offer code "Twit". Join the movement. Migrate your data to the
[00:40:10.360 --> 00:40:14.920]   cloud and do it with confidence. I'm telling you, I know the boss is going to say, "Who?" You just
[00:40:14.920 --> 00:40:20.120]   say, "Look, let me tell you why. Just repeat what I just said." And I think the boss will say, "Wow,
[00:40:20.120 --> 00:40:27.720]   that's it. Wasabi hot cloud storage for me." Thank you, Wasabi, for supporting this week in
[00:40:28.840 --> 00:40:35.880]   Google. All right. Let me find some Google-ish stuff here.
[00:40:35.880 --> 00:40:46.520]   I'm seeing the wheel spin and the yo's heading. Where's the wheel going to stop?
[00:40:46.520 --> 00:40:52.440]   Yeah, round and round she goes, where she stops, nobody knows. Verily is getting into insurance.
[00:40:52.440 --> 00:40:56.680]   That's the alphabet company that's for health sciences.
[00:40:57.400 --> 00:41:00.680]   Not a tear. I put that up there. It's not terribly exciting because what they're getting into
[00:41:00.680 --> 00:41:06.840]   is stop loss insurance. It's not retail insurance. I thought it'd be like health insurance.
[00:41:06.840 --> 00:41:12.920]   It's for the health insurance companies. Oh, it's insurance for the insurers. I get it.
[00:41:12.920 --> 00:41:17.000]   Yes. So that you don't get in nowadays with COVID, I think, insurance. Or for a company that's
[00:41:17.000 --> 00:41:21.640]   self-insurance. Yeah. Yeah, that makes sense. Stop loss insurance. Yeah, that makes sense.
[00:41:21.640 --> 00:41:27.240]   We thought for a while both Amazon started offering insurance to their employees.
[00:41:27.240 --> 00:41:31.240]   We thought they would get in this business. We thought Google would nothing yet.
[00:41:31.240 --> 00:41:34.280]   Are they betting that we might actually get single payer?
[00:41:34.280 --> 00:41:38.920]   Yeah, maybe this isn't a good time to get into that business. Maybe it's not.
[00:41:38.920 --> 00:41:40.680]   Maybe you wait till after November 3rd.
[00:41:40.680 --> 00:41:49.320]   The heavy ads story is interesting. Heavy ads. What are heavy ads? Google's blocking ads.
[00:41:49.320 --> 00:41:55.080]   Or ads that carry a lot of megs with them. And Google's going to start blocking them.
[00:41:55.080 --> 00:41:58.600]   And that means that ads that have fancy stuff going on in them.
[00:41:58.600 --> 00:42:02.040]   Good. Which are expensive. Also, may get blocked.
[00:42:02.040 --> 00:42:08.280]   Anything that consumes more than four megabytes of network data or 60 seconds of CPU usage,
[00:42:08.280 --> 00:42:15.000]   that's a lot. And it is only 0.3% of all ads out there. But because they're so heavy,
[00:42:15.000 --> 00:42:19.720]   they make up more than a quarter of all ad data network consumption.
[00:42:19.720 --> 00:42:24.120]   I wonder if the takeover ad that I complained about last week with Washington Post would have
[00:42:24.120 --> 00:42:27.480]   been a heavy ad. If it's got video probably.
[00:42:27.480 --> 00:42:33.080]   I appreciate the fact that the people designing the ads didn't necessarily
[00:42:33.080 --> 00:42:38.440]   think about just putting all of the big flashy stuff out there. Because they know as a society,
[00:42:38.440 --> 00:42:44.200]   we are stuck on the whole squirrel complex and we look at big shiny things on the screen.
[00:42:44.200 --> 00:42:47.640]   They fought that urge. They fought that urge.
[00:42:49.480 --> 00:42:56.200]   This is why AMP exists. Because people were what you were downloading with every web page
[00:42:56.200 --> 00:43:00.920]   was megabytes of crap. That can't exist for a number of reasons.
[00:43:00.920 --> 00:43:02.600]   I know you're going to set you up on that.
[00:43:02.600 --> 00:43:08.520]   Okay. The calendar your bait amp to be fine with it.
[00:43:08.520 --> 00:43:16.440]   Fight words. So you're such an unhappy person. I don't know how you.
[00:43:17.560 --> 00:43:22.600]   Oh, I'm sorry. I was saying I love the little disbelieving Leo squeak.
[00:43:22.600 --> 00:43:28.040]   We need a sound.
[00:43:28.040 --> 00:43:32.760]   I disagree with our various sounds. Stacy, you have about 10 of them. I lost.
[00:43:32.760 --> 00:43:36.680]   She's got the best sounds. You got we did. We did. We did a Stacey Leo sound board.
[00:43:36.680 --> 00:43:42.200]   I'm actually just copying Stacy. I'm just trying to get more Stacy stuff going in here.
[00:43:43.400 --> 00:43:50.280]   Facebook. Okay. What Facebook? Oh, that's okay. I'm pissed off. Facebook now says you have to have
[00:43:50.280 --> 00:43:57.640]   a Facebook account to use your Oculus Rift. Oh, really? Yeah. And Oculus Connect is now
[00:43:57.640 --> 00:44:02.200]   Facebook Connect. They're going to do a virtual conference September 16th.
[00:44:02.200 --> 00:44:05.880]   Facebook. Versus the other thing that the other name they came up with.
[00:44:08.600 --> 00:44:15.480]   The reality labs. Oh, yeah. The AR VR teams are now Facebook reality labs. A company that most
[00:44:15.480 --> 00:44:21.880]   people don't want screw in with reality is Facebook. Yeah. Well, in Facebook's reality is not real
[00:44:21.880 --> 00:44:28.600]   reality. Unfortunately, give or take. Yeah. No, this is it. This is so frustrating because when
[00:44:28.600 --> 00:44:36.280]   Facebook, I mean, when Facebook swallows a company, it it's trying to absorb every aspect of it and
[00:44:36.280 --> 00:44:43.560]   it will force users onto its platform. And people are now, I mean, if I were an Oculus user, I'd be
[00:44:43.560 --> 00:44:48.120]   pissed. I am and it's going in a box because I'm not going to create a Facebook account. So what's
[00:44:48.120 --> 00:44:53.240]   the benefit? I understand the benefit of tying Instagram data to Facebook data. I get that. I don't
[00:44:53.240 --> 00:44:57.320]   understand the benefit to Facebook here of demanding you have a Facebook for something that's basically
[00:44:57.320 --> 00:45:05.320]   its own business unit. Because Facebook wants to make its into real reality, right? So think about
[00:45:05.320 --> 00:45:10.280]   things like the portal, think about things like Oculus, you can see where someone is in their home,
[00:45:10.280 --> 00:45:16.200]   you can influence their physical actions in the world and get data about where they exist in the
[00:45:16.200 --> 00:45:22.600]   real world. That's very powerful data. And it's no wonder that Facebook wants it. They don't know
[00:45:22.600 --> 00:45:28.360]   necessarily what they're going to do with it. I know Mark has some weird vision of VR, but you know,
[00:45:29.400 --> 00:45:36.360]   that's how I look at this. It's funny and terrible. It's like I update the driver on the wrist,
[00:45:36.360 --> 00:45:41.160]   but now I'm scared after hearing this news. Are you an Oculus? Yeah, I gave you my Oculus. You have
[00:45:41.160 --> 00:45:48.120]   an Oculus. Yeah, I'm not. I mean, the kids. You will be forced to do this. Yeah. Yeah, I'm not.
[00:45:48.120 --> 00:45:59.160]   I'm going HTC Vive, baby. I mean, I'm an Instagram user. I use Instagram fairly regularly in
[00:45:59.160 --> 00:46:06.200]   a Facebook property, but I guess I'm limited. I sort of limit what I put on there as well.
[00:46:06.200 --> 00:46:13.080]   Could you use something like Flickr instead? Is there anything you could use instead that isn't
[00:46:13.080 --> 00:46:19.560]   said there are options with Flickr and stuff like that? I look at my engagement levels. I get a lot
[00:46:19.560 --> 00:46:26.120]   more engagement about my work on Instagram and Twitter. Of course. Nothing on Flickr or anything
[00:46:26.120 --> 00:46:31.240]   like that. Of course you do. That's the problem. That's where the people are. That's where the
[00:46:31.240 --> 00:46:37.560]   people are. That's the whole problem. You know, I said before the show, I said, I'm done striving.
[00:46:37.560 --> 00:46:44.920]   That's why I can now safely leave Twitter, Facebook, Instagram. I not look back because I don't need
[00:46:44.920 --> 00:46:49.000]   that. You just enjoy being a contrarian. I don't like them. I don't want them.
[00:46:49.640 --> 00:46:58.120]   You know, you enjoy not enjoying. My new master is Jeff Bezos, the world's first $200 billion man.
[00:46:58.120 --> 00:47:07.880]   Unbelievable. $200 billion. He's got that means he's got two billion Franklin's.
[00:47:07.880 --> 00:47:16.120]   There's a number for you. You think with all that money, you could buy himself a better jacket.
[00:47:17.080 --> 00:47:22.520]   Hey, that jacket right there. Oh, no. Really? You think I said it? You like that jacket?
[00:47:22.520 --> 00:47:27.400]   I could wear it. I don't know about you, but I could. You could pull it off. Yes. You could pull
[00:47:27.400 --> 00:47:32.040]   it off. You could wear a toga and look good. It doesn't. You don't need, you know,
[00:47:32.040 --> 00:47:35.480]   clothing's for you or just, you know, something to hold your muscles back.
[00:47:35.480 --> 00:47:46.200]   Amazon stock went up another 2% this afternoon. Bezos made, I can't you imagine making $4.9 billion
[00:47:46.840 --> 00:47:56.520]   in an afternoon. Wow. He is now as of 1.50 p.m. Eastern time today worth $204.6 billion.
[00:47:56.520 --> 00:48:03.400]   The next richest person in the world is Bill Gates. He's a he's a punter at $116 billion.
[00:48:03.400 --> 00:48:13.560]   Even adjusting for inflation Forbes says they believe Bezos's fortune is the largest ever amassed.
[00:48:16.600 --> 00:48:23.640]   I see this article that makes me think about a recent issue I had with Amazon order and not a
[00:48:23.640 --> 00:48:29.720]   delivery in particular. This was more so on the database side and software side. Something went wrong.
[00:48:29.720 --> 00:48:35.800]   It was Amazon's fault and Jeff should have given you a billion right there. He just peel it right
[00:48:35.800 --> 00:48:40.280]   off. It's no problem. Well, that's the thing they come at you and say, you know what, we're sorry
[00:48:40.280 --> 00:48:46.360]   about this. And I'm thinking, all right, we pay the however much it is per year for that service.
[00:48:46.360 --> 00:48:53.320]   And they they say, well, we'll give you a $10 credit or something like that. And I'm like,
[00:48:53.320 --> 00:48:58.760]   that's a slap in the face, especially if this was something that I really needed at the time for a
[00:48:58.760 --> 00:49:04.520]   job. I think Jeff Bezos should come like your house and make it rain. I think he should just
[00:49:06.120 --> 00:49:10.520]   tell the representative, make it 50 bucks and I'll be happier. Otherwise, just keep you $10.
[00:49:10.520 --> 00:49:15.720]   That's a slap in the face. It's not worth the effort to cash the check, tell him. I just can't be
[00:49:15.720 --> 00:49:25.560]   bothered. I'm rich like Bezos. He would insult me with your trivial offer or peace.
[00:49:25.560 --> 00:49:30.440]   You're $10. To mean anything to me, I am Mr. Ant Pruitt.
[00:49:32.680 --> 00:49:38.760]   The president is actually going to go to the Supreme Court. This is how pathetic we've gotten.
[00:49:38.760 --> 00:49:45.240]   This is how sad and it's not a comment on Trump. It's just how sad the whole political sphere's
[00:49:45.240 --> 00:49:49.240]   gotten. He's going to go to the United States Supreme Court. The highest court in the land.
[00:49:49.240 --> 00:49:56.120]   Ask them to let him block users on Twitter again. Oh, bless his heart. He's using the
[00:49:56.120 --> 00:50:04.360]   solicitor general in the United States of America so that he can block users on Twitter.
[00:50:04.360 --> 00:50:10.120]   I never quite got an understanding on his Twitter account versus the president of the United States.
[00:50:10.120 --> 00:50:15.240]   Well, that's the argument. He says, look, I got a POTUS account. I won't block things on that.
[00:50:15.240 --> 00:50:19.480]   But the real Donald Trump, that's my personal account. I can do that.
[00:50:20.280 --> 00:50:25.640]   Okay. I think he's president all the time, not just nine to five.
[00:50:25.640 --> 00:50:32.040]   He would argue if you tried to tell him that he was not president at certain times a day,
[00:50:32.040 --> 00:50:35.400]   he would argue that no, he is president all the time and will be forever.
[00:50:35.400 --> 00:50:45.160]   Forever. So arguing that this is a purely personal action is, I think, not going to.
[00:50:45.160 --> 00:50:50.440]   I don't know. It'd be really interesting to see what the Supremes say. The court, a three-judge
[00:50:50.440 --> 00:50:55.880]   panel, unanimously ruled last year, as you might remember, that he could not block users on Twitter
[00:50:55.880 --> 00:51:03.800]   because he used to make official pronouncements. And it is kind of the thing we do in America.
[00:51:03.800 --> 00:51:10.680]   I think it's in the First Amendment. I might be wrong. The right to speak up and say, I don't like
[00:51:10.680 --> 00:51:16.680]   that. I think. Let me double check. I think it's in there. Well, this is a case too. It's in the
[00:51:16.680 --> 00:51:20.520]   what you call the law of opening up information.
[00:51:20.520 --> 00:51:30.360]   It's transparency. Yes. Yeah. But I'm just going to bet the Supremes were going to
[00:51:30.360 --> 00:51:37.160]   punt and wait and not. It seems such a trivial, terrible thing for them.
[00:51:37.160 --> 00:51:41.160]   They don't want to get dragged down. So many more serious things like TikTok. They could be
[00:51:41.160 --> 00:51:46.360]   getting involved in the tip, TikTok, or Apple versus Epic. There's so many more important things.
[00:51:46.360 --> 00:51:53.080]   Oh, Lord. I don't know. Well, let's take this a little further. So not just Donald
[00:51:53.080 --> 00:51:59.480]   putting to block people, but let's think about as we go forward in time, we're going to have
[00:51:59.480 --> 00:52:05.880]   presidents and people in power who have a history of social media use, for example.
[00:52:05.880 --> 00:52:12.600]   And if you start thinking from that perspective, how far to what extent could Kamala Harris go to
[00:52:12.600 --> 00:52:20.280]   protect her accounts from harassment? And I don't know. So I'm just trying to think about,
[00:52:20.280 --> 00:52:28.360]   maybe it's not just Twitter, but how, at what point do you become your job? It's kind of the
[00:52:28.360 --> 00:52:36.680]   same between a public and a private person for libel, right? Or not libel, coverage reasons.
[00:52:36.680 --> 00:52:42.520]   And I mean, I'm not saying that Trump is thinking this far ahead, but as a lawyer,
[00:52:42.520 --> 00:52:46.680]   I would be thinking that way. And I assume some lawyers are.
[00:52:46.680 --> 00:52:52.280]   And just like your personal Instagram, or what about your kids Instagram?
[00:52:53.720 --> 00:53:00.360]   And yes, he is making political statements on Twitter. So does that negate that? And if that's
[00:53:00.360 --> 00:53:05.080]   the rule that we come up with, then how does that make other people behave on Twitter if they
[00:53:05.080 --> 00:53:10.120]   aspire to this? I understand he's not. So he's not saying I want the power to delete old tweets,
[00:53:10.120 --> 00:53:14.600]   which he also do. I know he's saying I want to be able to, I don't want to, I want to be able to
[00:53:14.600 --> 00:53:20.440]   put my fingers in my ears and say, no, no, no, I can't hear you. I don't know what you're saying.
[00:53:20.440 --> 00:53:25.880]   He wants to block a route of for the citizens in the United States to turn back to him.
[00:53:25.880 --> 00:53:30.200]   And Stacy brings up a really good analogy talking about about Kamala Harris.
[00:53:30.200 --> 00:53:35.320]   I think there's a professor at University of Maryland, Matthew Kirschenbaum,
[00:53:35.320 --> 00:53:38.040]   and the name you should know, because he wrote the history of word processing.
[00:53:38.040 --> 00:53:41.320]   It's great. I have that book, actually. It's a really fun.
[00:53:41.320 --> 00:53:43.480]   Is that there? Yeah, I have it. Yeah.
[00:53:43.480 --> 00:53:49.960]   Track changes. Track changes. So he, the other day he tweeted somebody with some
[00:53:49.960 --> 00:53:53.400]   trolls going after him. And he was just kind of saying, I'm not playing. And he finally said,
[00:53:53.400 --> 00:54:01.560]   you don't have a right to a conversation. And I like that. I have a responsibility to respond to
[00:54:01.560 --> 00:54:08.200]   you. I don't need to rise to whatever bait you're praying to before me. So there's that.
[00:54:08.200 --> 00:54:12.360]   Then there's the, do you have a right to be heard? No, you don't.
[00:54:14.920 --> 00:54:20.120]   So I think Stacy's right that do you have a right to not be harassed? These are the things
[00:54:20.120 --> 00:54:25.720]   we've got to discuss now. Oh, that's an interesting voice. A reason. Yeah. Stacy
[00:54:25.720 --> 00:54:31.000]   had got bought. Yeah. But who defines harassment? Because I think some people would say, well,
[00:54:31.000 --> 00:54:35.320]   anything that disagrees with me is harassed. Disreasurable. Yeah. Exactly. But you know what?
[00:54:35.320 --> 00:54:38.520]   That's that's where you get the Supreme Court involved. Right.
[00:54:38.520 --> 00:54:42.760]   He's not playing with something like, I know it when I see it. Yeah.
[00:54:43.720 --> 00:54:47.480]   He's not reading his tweet feed. I think he's more concerned.
[00:54:47.480 --> 00:54:53.160]   Well, I don't know if that's the case, but I think he's more concerned about
[00:54:53.160 --> 00:55:00.520]   followers seeing other people's tweets to him than he is about him seeing them. You know what I'm
[00:55:00.520 --> 00:55:06.840]   saying? He wants to, he wants to keep the dissent out of his at replies. Because that's a difference.
[00:55:06.840 --> 00:55:13.960]   Okay, that's a different question then. Does he? Hmm. I don't know.
[00:55:13.960 --> 00:55:20.520]   I'm still in the message. I did. Yes. I hope we I hope I pray to God we can get rid of President's
[00:55:20.520 --> 00:55:24.840]   tweeting. Please just get rid of that. That's a bad. That's a relationship.
[00:55:24.840 --> 00:55:32.440]   Partly I used to I was I was sad. So back in the day way back in the day, I even did stuff on this,
[00:55:32.440 --> 00:55:38.200]   right? The candidates would Obama was making YouTube videos. Right. Right. Now I keep doing that.
[00:55:38.200 --> 00:55:42.680]   It's a direct connection to the public. This is great. It's using social media really well.
[00:55:42.680 --> 00:55:48.520]   I love this. And if Obama did it, I would have loved it. But yeah, it could get abused.
[00:55:48.520 --> 00:55:53.640]   On a demo, a dog does it. Well, I would say that, I mean, FDR started his radio addresses and he
[00:55:53.640 --> 00:55:58.920]   did it because he didn't like the message from the press. Right. Right. So there's a time honored
[00:55:58.920 --> 00:56:04.200]   history. Yeah, speaking to people, not a bad thing. But that's why we call it the bully pulpit.
[00:56:04.200 --> 00:56:09.160]   You have plenty of options to do that. You can call the networks and they come running.
[00:56:09.160 --> 00:56:15.560]   Why not modernize a little bit? Why not modernize and go where again, go where the people are?
[00:56:15.560 --> 00:56:21.480]   I guarantee you, my daughter is not listening to the radio or watching television.
[00:56:21.480 --> 00:56:26.120]   Apparently I didn't know this one. Joe Biden says he's promised to stop using his personal
[00:56:26.120 --> 00:56:30.360]   Twitter account if he's elected. He'll still just use the POTUS account. The interest
[00:56:30.360 --> 00:56:37.480]   about the POTUS account is that is an official account for the president of the United States.
[00:56:37.480 --> 00:56:43.400]   So, and it is not your account, right? When Obama, which was created under Obama, but when he
[00:56:43.400 --> 00:56:48.280]   stepped down, he handed it over to Trump and presumably Trump will hand it to his successor
[00:56:48.280 --> 00:56:52.120]   and on and on and on. And I think that's interesting. That's that I don't mind.
[00:56:53.240 --> 00:56:58.440]   Because that does have this then has the standard delineation, an official pronouncement from the
[00:56:58.440 --> 00:57:08.040]   president. Right. And I think the refusal of Trump to use it is very indicative of his personality
[00:57:08.040 --> 00:57:13.320]   and his goals with this. And I think Obama's willingness to create the account and then leave
[00:57:13.320 --> 00:57:19.720]   it behind is also very indicative of who he was as a politician. Actually, you may be able to
[00:57:19.720 --> 00:57:25.880]   delete your tweets, but you can never delete your email if the US border patrol gets a hold of it.
[00:57:25.880 --> 00:57:31.480]   The end of the month, last month's Department of Homeland Security published a privacy impact
[00:57:31.480 --> 00:57:36.840]   assessment detailing the electronic data they can choose to collect from people crossing the border
[00:57:36.840 --> 00:57:41.960]   and what happens to it. In this assessment, they claimed the right to search laptops, thumb
[00:57:41.960 --> 00:57:48.360]   dries, cell phones, any device capable of storing electronic information. And when they call it a
[00:57:48.360 --> 00:57:53.560]   border search, they can do this not just when you're crossing the border in either direction,
[00:57:53.560 --> 00:58:00.680]   but even anywhere within 100 miles of the border. That's two thirds of the US population lives in
[00:58:00.680 --> 00:58:07.000]   within 100 miles of the border. So now they have asserted a right to collect any electronic data
[00:58:07.000 --> 00:58:14.360]   for anybody from two thirds of the United States. They also say, we will keep this. We will we will
[00:58:14.360 --> 00:58:20.760]   acquire a mirror copy of the data on the device and store it locally. Once they make sure there's no
[00:58:20.760 --> 00:58:28.520]   porn on it, because that's dangerous. Once they've determined it's clean, they transfer it to
[00:58:28.520 --> 00:58:38.360]   a border patrol system called PLX, where the information is stored and searchable for 75 years.
[00:58:40.040 --> 00:58:44.600]   This will get sued. I'm sure it also gets sent to Palantir, because right now.
[00:58:44.600 --> 00:58:51.080]   But yes, they will be sued for this. They were sued over the within the 100 miles of the border,
[00:58:51.080 --> 00:58:57.880]   and that didn't work. This is this is really, I mean, this is the sort of stuff we look at other
[00:58:57.880 --> 00:59:03.000]   countries doing this and we're like outraged at. But this is where we are as a country.
[00:59:03.000 --> 00:59:11.400]   We'll see what the courts say. They say they plan to keep travelers, emails, videos, pictures,
[00:59:11.400 --> 00:59:16.840]   as long as they're not pornographic. Text and tap messages, financial accounts and transactions.
[00:59:16.840 --> 00:59:24.120]   By the way, gave me a great idea, a new kind of encoding. If you put all your secrets in dirty
[00:59:24.120 --> 00:59:30.760]   pictures, you're safe, right? You're safe. Financial accounts and transactions, location history,
[00:59:30.760 --> 00:59:40.120]   web browser bookmarks, task lists, step one, acquired bomb material, step two. Well, I won't
[00:59:40.120 --> 00:59:45.320]   continue because it's going to get in this list. Your calendars, your call logs, your contracts,
[00:59:45.320 --> 00:59:53.880]   75 years, although if it's not related to a crime, it may be deleted after 20 years. We can't
[00:59:53.880 --> 00:59:58.520]   promise, they say. So you travel with a clean phone? Is it what the sounds?
[00:59:58.520 --> 01:00:03.080]   Yeah, don't cross. Well, don't get within 100 miles of the border with anything.
[01:00:03.080 --> 01:00:06.840]   Well, 100 miles, that's right. Oh, right. Right. Right. Right.
[01:00:06.840 --> 01:00:12.200]   Right. So a border patrol agent, if you're within 100 miles of the border, and this happens all
[01:00:12.200 --> 01:00:16.680]   the time, I understand in Vermont and areas near the Canadian border, they can just say, Hey,
[01:00:16.680 --> 01:00:21.320]   come here, give me your phone. Thanks. Okay, I got it. Have a nice day, citizen.
[01:00:22.680 --> 01:00:30.920]   You don't have to be crossing the border. Yeah. It's blatantly wrong. But you won
[01:00:30.920 --> 01:00:41.720]   palantier to protect our boys overseas. Yes, I do in Canada. Yes, I do.
[01:00:41.720 --> 01:00:45.400]   I've always wondered. I've always wondered if you're a border guard, because you don't have to
[01:00:45.400 --> 01:00:54.760]   fly back from Toronto, you go through customs there. Are those those US border agents live
[01:00:54.760 --> 01:00:57.800]   there Americans that they have to be American citizens, I assume living in Canada. Yeah.
[01:00:57.800 --> 01:01:05.160]   Not a bad game. No. They're always very nice to me. Some of them are fans. I'm not criticizing
[01:01:05.160 --> 01:01:10.040]   you guys. I just don't think you should be able to suck all the data out of my devices and keep
[01:01:10.040 --> 01:01:17.160]   it for seven hundred miles. Seattle's 135 miles from the
[01:01:17.160 --> 01:01:22.440]   safe border. You're safe. Well, but people who live in like the Northern suburbs.
[01:01:22.440 --> 01:01:31.160]   I'm puzzled because if they say two thirds of the nation, does that mean anybody who lives on the
[01:01:31.160 --> 01:01:40.440]   coast? Because the territorial border is what is it 20 miles? Is that everybody that anybody who
[01:01:40.440 --> 01:01:47.400]   lives on the miles of the town? I'm screwed. That's right. Yeah. I guess so. Because because
[01:01:47.400 --> 01:01:52.920]   the coast is is your what's what's the border 35 miles? I remember what the I always thought
[01:01:52.920 --> 01:01:58.680]   was 20, but uh, territorial international waters territory versus fishing versus this versus that.
[01:01:58.680 --> 01:02:04.200]   Yeah, what's our territorial waters? No detail is too small for us. We will.
[01:02:04.200 --> 01:02:13.320]   This is maritime law, my friend maritime law. I do not know the law of the sea, my friends.
[01:02:13.320 --> 01:02:19.240]   Two hundred on the DHS state. The high seas.
[01:02:22.920 --> 01:02:32.040]   The Copenhagen Convention of 1857. It's complicated is the answer.
[01:02:32.040 --> 01:02:41.960]   Wow, it is just complicated as hell. Look at this chart. There's the continental shelf
[01:02:41.960 --> 01:02:47.560]   and then the extended continental shelf, the international seabed international waters,
[01:02:47.560 --> 01:02:53.720]   surface international exclusive economic zone, national space and then finally outer space.
[01:02:53.720 --> 01:03:02.920]   So it's if somewhere in this table. There's national air space, international air space,
[01:03:02.920 --> 01:03:07.720]   territorial sea, contiguous zone, high seas. High seas seem to go out a long way.
[01:03:07.720 --> 01:03:13.800]   Exclusive economic zone is an airport of vertical miles. Is an airport of border?
[01:03:13.800 --> 01:03:19.560]   Airports of border too, because you I don't know how this works. Oh my gosh. You're just you just
[01:03:19.560 --> 01:03:25.560]   just we need a maritime. I want to have it all. Yeah. Oh, you just need a you just need an
[01:03:25.560 --> 01:03:30.760]   immigration lawyer. I'm sure they could tell you anyone in the chat room. Somebody in the chat room.
[01:03:30.760 --> 01:03:37.240]   Anyone? I'm sure we have a few play out on TV. All right. I need to take a break. Little breather.
[01:03:37.240 --> 01:03:42.520]   One moment. Everybody stretch and then when we come back, we're going to talk about a new way,
[01:03:42.520 --> 01:03:51.800]   the bad guys can make a copy of your keys with their smartphone as they're walking by. Lovely.
[01:03:51.800 --> 01:03:58.760]   This section, we talked about this. I just had a little stretch. Sorry. We talked about this
[01:03:58.760 --> 01:04:06.920]   on security now from the Association of Computing Machinery and a demo. I think this was at Black Hat.
[01:04:08.120 --> 01:04:16.920]   It turns out if you record the audio of a key in a lock, security researchers were able to
[01:04:16.920 --> 01:04:28.040]   actually make a copy of the key 3D printed based on the sounds it makes when the key hits the
[01:04:28.040 --> 01:04:37.160]   tumbler and it pushes it and all of that stuff. They can they can they so with a smartphone or even
[01:04:37.160 --> 01:04:45.960]   they say the microphone in a video doorbell, they can attack and they can record. You want to hear
[01:04:45.960 --> 01:04:50.440]   what the clicks sound like? Here, I'll play the microphone on the video doorbell. Your doorbell
[01:04:50.440 --> 01:04:55.080]   so it wouldn't be done. Yeah, but when they hack into my doorbell, and then I open the door,
[01:04:55.080 --> 01:05:00.920]   this you should have this at IOT. You stay CNIOT here. Listen, did you hear that?
[01:05:01.880 --> 01:05:06.520]   No. Well, turn up your sound. That's... Oh, I did hear it. That's...
[01:05:06.520 --> 01:05:10.520]   That's... Now,
[01:05:10.520 --> 01:05:15.400]   apparently they were able to record this from a distance.
[01:05:15.400 --> 01:05:21.720]   That's getting some pretty high frequencies too. Yeah, and they actually roll off everything under
[01:05:21.720 --> 01:05:30.200]   like 10,000 Hertz. They don't need it. And there are... I didn't even know this, but in most keys,
[01:05:30.200 --> 01:05:39.320]   there's about 330,000 keys. So, using that audio file, they can reduce the search space down to just
[01:05:39.320 --> 01:05:47.480]   three. So, they can 3D print the keys for the codes inferred from the audio and one of those three
[01:05:47.480 --> 01:05:55.720]   will almost certainly work. So, here's the deal. Most blocks are fairly hackable with just a screwdriver
[01:05:55.720 --> 01:06:01.800]   or a credit card or a good kick in the door jam. So, I mean,
[01:06:01.800 --> 01:06:09.560]   I always... I'm intrigued by people who are hacking door locks because really, what you need to watch
[01:06:09.560 --> 01:06:17.240]   out for, what I think about is remote access that can open a lot of doors at once. Because that is
[01:06:17.240 --> 01:06:22.120]   something that someone... That's better. It would be worth trying. Like that, like that the hack that
[01:06:22.120 --> 01:06:28.120]   was getting into hotel, electronic hotel doors, right? That the guy could just go down the hall
[01:06:28.120 --> 01:06:31.160]   one by one, open the door, go and take your stuff, go to the next door and all that.
[01:06:31.160 --> 01:06:38.760]   Yep. And even that's... I mean, that is still much more value-add for me. So, yes, if you are like
[01:06:38.760 --> 01:06:45.400]   a weirdly popular... Like, if you're Beyonce, you've got a different security profile, right? But
[01:06:45.400 --> 01:06:51.640]   for most of us, I would worry more about someone in a door jam. And it could happen.
[01:06:52.520 --> 01:06:59.160]   Yeah. As Carson says, locks are just a suggestion. Like, please don't come in here.
[01:06:59.160 --> 01:07:07.320]   I'm looking at that and I'm thinking about the different variables with the locks. I'm assuming
[01:07:07.320 --> 01:07:11.480]   not all locks are created with the same materials, right?
[01:07:11.480 --> 01:07:16.600]   That is... Yeah, no. I don't know. Yes.
[01:07:16.600 --> 01:07:21.960]   They're supposedly... Don't they make... What are those medical locks that can't be picked supposedly?
[01:07:21.960 --> 01:07:27.720]   But then Steve Gibson says... And when we talked about this yesterday in security,
[01:07:27.720 --> 01:07:35.080]   I said, "But Leo, as you and I both know, every hacker worth his salt can unlock a door very
[01:07:35.080 --> 01:07:41.880]   quickly with just a hat pin and a couple of lock pick tools, which I can't. But I was honored
[01:07:41.880 --> 01:07:46.280]   that he included me in that. What I'm saying is you have... You go to your local hardware store
[01:07:46.280 --> 01:07:51.960]   and you go to pick up the lock for your front door. You see the $10 one and you see the $15 one
[01:07:51.960 --> 01:07:57.080]   and you see the $100 one. They're not all made the same. So why would I assume that they are all
[01:07:57.080 --> 01:08:04.120]   used the same types of materials and the different materials? No, no. There's a certain sounds. No,
[01:08:04.120 --> 01:08:15.560]   but there are less pickable locks, supposedly anyway. I don't know. I don't know. I just thought
[01:08:15.560 --> 01:08:18.120]   I'd bring it up. I thought it was kind of fun. I just want to play that sound.
[01:08:18.120 --> 01:08:27.640]   I got nothing. If you tap your fork against your wine glass versus a cheaper wine glass,
[01:08:27.640 --> 01:08:32.440]   it's both wine glasses. But they're listening for it's not the quality of the sound, but the
[01:08:32.440 --> 01:08:38.920]   actual sound of the pin hitting the tumbler and setting it. So even though it might sound different,
[01:08:38.920 --> 01:08:43.720]   there's a distinct... You heard the clips. There's a distinct... The frequency. It's like the old
[01:08:43.720 --> 01:08:48.360]   days of listening to a typewriter and being able to replicate what the spies can do.
[01:08:48.360 --> 01:08:55.000]   It's the timing. John says the distance between the clicks tells you how big the humps... I don't know.
[01:08:55.000 --> 01:09:01.080]   Thank you, Jammer B. Thank you, Jammer B.
[01:09:01.080 --> 01:09:08.280]   I just put it in the chat, but I found the ACLU's thing on the border zone and the 100-mile border
[01:09:08.280 --> 01:09:13.560]   zone with the map that shows you the border zone. Oh, handy. And is it look like a
[01:09:13.560 --> 01:09:18.040]   lot of people are within that? Yes. Really? Jeff, you're in it with the New York City.
[01:09:18.040 --> 01:09:21.640]   It's in the chat room. Oh, here. I'll put it in the... So you're in it, Stacy?
[01:09:21.640 --> 01:09:28.920]   Yeah, but here. I'll put it right here. Thank you, Stacy. Your rights in the border zone.
[01:09:28.920 --> 01:09:33.400]   This is where the figure comes from. Pretty much everybody in the coast on it.
[01:09:33.400 --> 01:09:42.120]   Yeah, it's just all the way around. Wow. That's... So that's all of us, right?
[01:09:43.080 --> 01:09:47.640]   Yeah. That one here is going to have it all. And they mentioned, you know, as an example,
[01:09:47.640 --> 01:09:53.960]   on January 19th, two border patrol agents boarded a Greyhound bus at a Fort Lauderdale station
[01:09:53.960 --> 01:09:59.800]   and questioned passengers row by row. The bus was scheduled to travel from Orlando to Miami.
[01:09:59.800 --> 01:10:05.080]   No international border, but they ultimately detained a Jamaican national who they claimed
[01:10:05.080 --> 01:10:10.040]   over stayed her tourist visa. Apparently, this happens all the time. And I remember reading about,
[01:10:10.040 --> 01:10:14.040]   I think it was a Vermont town that was routinely harassed by the
[01:10:14.040 --> 01:10:19.800]   Carstomism border patrol agents because they would come down on a Saturday night. They love to
[01:10:19.800 --> 01:10:28.360]   rouse to people. So 100 air miles from any external boundary of the US is a reasonable distance.
[01:10:28.360 --> 01:10:35.480]   Wow. They can board a bus or train without warrant, without warrant, by the way.
[01:10:35.480 --> 01:10:39.720]   Yeah. Anywhere... What rate do you have to say, "No, I'm not going to do this."
[01:10:39.880 --> 01:10:44.920]   Do you have any rights? You do have that right. You have... They cannot detain you
[01:10:44.920 --> 01:10:50.280]   without reasonable suspicion. So if you go... There's a segment in the ACLU, are there limitations
[01:10:50.280 --> 01:10:54.040]   to immigration officials' power? You have the right to remain silent or tell the agent that
[01:10:54.040 --> 01:10:58.200]   you'll only answer questions in the presence of an attorney, no matter what your status is.
[01:10:58.200 --> 01:11:03.880]   And they cannot detain you without reasonable suspicion, although they can create that very
[01:11:03.880 --> 01:11:11.640]   quickly. And they cannot search you without probable cause or your consent. So basically,
[01:11:11.640 --> 01:11:17.480]   shut up, say, "I need to see an attorney," and they can't arrest you for that. And it knows
[01:11:17.480 --> 01:11:19.640]   that the attorney looks suspicious. Yeah.
[01:11:19.640 --> 01:11:29.320]   Fascinating. They can't arrest you, apparently, if you're not... If they ask you about your
[01:11:29.320 --> 01:11:34.520]   immigration status and you don't have those documents... There's some exceptions. Yeah. But
[01:11:34.520 --> 01:11:42.280]   the thing is, it's very intimidating. And you have to be a surprisingly strong-willed person to
[01:11:42.280 --> 01:11:46.680]   not say anything. You have to know this. I mean, like... And you have to know it. Yeah.
[01:11:46.680 --> 01:11:53.160]   Most people are inclined to... And you see this in cop shows all the time. But they're inclined to
[01:11:53.160 --> 01:11:58.120]   help because they're probably not guilty of anything, and then they get suckered into something. Right.
[01:11:58.600 --> 01:12:06.120]   There's a great video. I gave it to my kids, but it's a video by a defense attorney who says,
[01:12:06.120 --> 01:12:12.360]   "Under no circumstances should you at any time speak to the police, period. No good can come of it.
[01:12:12.360 --> 01:12:20.680]   Just don't. If you're within your rights, not to. So don't." And it's on YouTube if you want to watch
[01:12:20.680 --> 01:12:26.280]   it. He makes a strong case. I'm not that guy. I'm going to say, "Sure, officer, whatever. What do you
[01:12:26.280 --> 01:12:32.600]   need?" I'm an honest guy. Get along Leo. Get along me. Oh, that's me. That's me.
[01:12:32.600 --> 01:12:41.240]   I'll show my palantier card. I'm one of you. I'm one of you, right?
[01:12:41.240 --> 01:12:48.600]   Wink, wink, secret handshake. Yeah. I'm there. I love it when I see people usually in hot cars,
[01:12:48.600 --> 01:12:55.480]   you know, Ferraris, Lamborghinis, Maseratis. And they have a license plate border that says
[01:12:55.480 --> 01:13:03.320]   something like, "I'm in the police 100 club." There's something... Oh, it's the 100 club. Yeah,
[01:13:03.320 --> 01:13:10.520]   they have stickers. You see it all the time in the suburbs. Yeah. It's a... Yeah, it's... I don't know.
[01:13:10.520 --> 01:13:17.480]   We donate money to your pension fund club thing. Yeah. And supposedly that gets you off the hook.
[01:13:17.480 --> 01:13:21.160]   I don't... In Jersey, they also put... They have these shields. They put right next to the driver
[01:13:21.160 --> 01:13:24.520]   in the windshield. Yeah. In the cops. See, I believe it works in Jersey.
[01:13:24.520 --> 01:13:33.400]   You got a problem with that? I know Chris Christie. It's the CHP 1199 Foundation.
[01:13:33.400 --> 01:13:38.600]   But see, I think that's nice. You should make a donation, but not to get out of a traffic ticket.
[01:13:38.600 --> 01:13:47.400]   So my elite relative of mine, somewhat distant, was friends with cops in Jersey. And they used to
[01:13:47.400 --> 01:13:51.800]   give him a card. And if you got stopped, you just hand over the card and kind of...
[01:13:51.800 --> 01:13:56.680]   It is a get out of a jail free card. It says, "I'm a friend of Corporal Tumoski." Yeah.
[01:13:56.680 --> 01:14:03.240]   Yeah. Look at this wallet you get. Is it a get out of a jail free card? Or is it a...
[01:14:03.240 --> 01:14:06.600]   Just get out of a city. Just give me a warning. Those are very different.
[01:14:06.600 --> 01:14:13.320]   Okay. Yeah. I mean, I think you can only take it so far, honestly. Plus, the other thing is,
[01:14:13.320 --> 01:14:17.400]   there's all these fake police charities that call all the time. Yeah. Those, by the way,
[01:14:17.400 --> 01:14:22.760]   those are almost always scams. Yeah. Yes.
[01:14:22.760 --> 01:14:31.720]   Yeah. So much talk about Leo. So much. Where do you start? And none of it's about Google.
[01:14:31.720 --> 01:14:41.160]   I'm trying. I'm trying. Let's see. What do you pick? I am... Like I said, I'm done striving.
[01:14:41.160 --> 01:14:45.800]   Checked out. I'm done striving. I don't have lost his work. No more striving.
[01:14:45.800 --> 01:14:54.360]   What about the gap school? What about it? You brought it up. You got it. You got to pitch it.
[01:14:54.360 --> 01:14:58.120]   You got to tell us what it's important. It's yours. It's yours. You own it now, baby.
[01:14:58.120 --> 01:15:03.880]   What is it? I'm not Leo on the port. I may not prove it. Come on.
[01:15:03.880 --> 01:15:09.720]   Oh, so you're just going to bring up a story and then let me do the work, the heavy lifting.
[01:15:09.720 --> 01:15:15.000]   Exactly. You have to pipe this in everything. Please do it. Please do it. Please do me what
[01:15:15.000 --> 01:15:21.480]   Jeff does. Give me the line number. Oh, line number. Sorry. Line number is 28, sir.
[01:15:21.480 --> 01:15:26.440]   So from now on, just give me the line number. Oh, yeah. Actually, I started this, but I couldn't
[01:15:26.440 --> 01:15:34.360]   figure out how to pronounce exuglers. These are ex-googlers. They have formed a virtual tech school
[01:15:34.360 --> 01:15:40.840]   for gap year students. Jeff, you were in a bit of a Twitter feud about the idea of taking a year
[01:15:40.840 --> 01:15:47.000]   off. I feel as if that was better necessarily. It was a matter of privileged people. People can
[01:15:47.000 --> 01:15:52.520]   do it better than those who are. Yes. But I feel so bad for kids who worked hard. They got through
[01:15:52.520 --> 01:15:58.280]   high school. First of all, they didn't get to walk as high school seniors. And then the college says,
[01:15:59.400 --> 01:16:04.760]   by the way, just stay home. You can watch your classes on video. We know you get a long-world
[01:16:04.760 --> 01:16:09.320]   mom and dad. Oh my God. I feel so bad for this generation. That just, you know what I had my first
[01:16:09.320 --> 01:16:16.760]   class today? Last week, I had the whole entire incoming class, 100 people in Zoom.
[01:16:16.760 --> 01:16:22.360]   Zoom didn't work for breakout sessions. I had to do 100 person brainstorm session.
[01:16:22.360 --> 01:16:29.000]   But today we had the actual first class with 16 students. And it was great. And that was wonderful.
[01:16:29.320 --> 01:16:33.320]   Were they at home? Where are they? Yeah, they're at homes wherever. And
[01:16:33.320 --> 01:16:39.160]   ones in Venezuela, ones in Mexico, all over the country. Yeah. Nice.
[01:16:39.160 --> 01:16:43.880]   They're really New Yorkers. Yeah. So I think we're going to learn how to do this better. And it may
[01:16:43.880 --> 01:16:49.480]   actually be that after quarantine, we actually have a new technique, which is great. But I think
[01:16:49.480 --> 01:16:55.720]   if I were a college kid, I might be tempted if I had the option to take a year off. And you know,
[01:16:55.720 --> 01:16:59.480]   Jeff, you were saying, you know, well, not everybody could do the grand tour and,
[01:16:59.480 --> 01:17:04.760]   you know, just kick around. But maybe that what you do is you work, you get a job at the grocery
[01:17:04.760 --> 01:17:09.320]   store. And deal, if you heard, have you heard? What? We have 60 million people out of jobs. Oh,
[01:17:09.320 --> 01:17:15.160]   oh, yeah, that's that. Right. There's that. Yeah. But yeah, there are jobs. Like my daughters
[01:17:15.160 --> 01:17:20.600]   got a job a couple months ago at Trader Joe's. And, you know, there are some of these jobs
[01:17:20.600 --> 01:17:24.840]   nobody wants because they're, you know, if you're an ad executive, you don't want to work as a
[01:17:24.840 --> 01:17:30.840]   bagger at Trader Joe's. But they're for college. I would work. I would do it. I would work at
[01:17:30.840 --> 01:17:38.760]   Starbucks. She loves it. Abby loves it. And I was with Leo. Leo, this is a big, I'm about to give
[01:17:38.760 --> 01:17:44.920]   you a great tip here. Because Trader Joe's has a new dish. I wanted the food people on the call
[01:17:44.920 --> 01:17:50.120]   here. Okay. See what you think. Yeah. One of my favorite dishes when I go to Italy, I have it
[01:17:50.120 --> 01:17:54.520]   without fail. I love this. It is the simplest, most elegant, wonderful dish there is.
[01:17:54.520 --> 01:18:00.040]   Kachua Pepe. Kachua Pepe. I love Kachua Pepe. There's a place there.
[01:18:00.040 --> 01:18:05.320]   It makes such a so good. So this will be that place. But, but, but, uh,
[01:18:05.320 --> 01:18:09.560]   Trader Joe's has frozen microwaveable kachua Pepe and I'm going to have it tonight. And it's
[01:18:09.560 --> 01:18:18.920]   really good. I bet I could make this because it's pasta and pepper and cheese and cheese and cheese
[01:18:18.920 --> 01:18:25.320]   and a little bit. So the, you can always add like the place near me does lemon, which is delightful.
[01:18:25.320 --> 01:18:31.320]   My parents used to make this all the time. They called it spaghetti alburo, which means spaghetti
[01:18:31.320 --> 01:18:35.160]   with butter. It's when we didn't have any sauce. No, it's different. No, it's different.
[01:18:35.160 --> 01:18:39.960]   How's it? It has a lot of cheese and so just the right timing to get it to coat properly.
[01:18:39.960 --> 01:18:45.240]   It's a big deal. It's, I've made it. Even I have made it twice. One successfully, one's not.
[01:18:47.000 --> 01:18:52.360]   But it's kind of like my happiness. Where's the carmenara, which I've made? Yeah. But there's no egg
[01:18:52.360 --> 01:18:58.680]   and there's no bacon. Uh, it's a six. So it's, and by the way, I personally, I would make my own
[01:18:58.680 --> 01:19:04.600]   pasta if you really wanted to do it, right? Make some talyolini, some buccotini, some spaghetti.
[01:19:04.600 --> 01:19:10.280]   You put in the butter, the cracked pepper, the parmajano, regiano, a little pecorino for,
[01:19:10.280 --> 01:19:16.840]   uh, for bite. It's not hard. What's hard about this? You toss it in the pan. I'm going to go out.
[01:19:17.160 --> 01:19:23.160]   After the show, my wife refused to eat this late and I, and I got out of the freezer and I put it
[01:19:23.160 --> 01:19:28.760]   in the microwave dish. That's true. Seven minutes. It's ready to go. It's ready to go. It's got a
[01:19:28.760 --> 01:19:35.640]   adult macaroni and cheese. Yeah, that's what it is, isn't it? Yeah. C-A-C-I-O-E-P-E.
[01:19:35.640 --> 01:19:40.200]   Caccio. I never heard a day. Cheese and pepper. Oh, it's delicious.
[01:19:41.240 --> 01:19:47.400]   Whereas my mom and dad called it Spaghetti Alburo. I have some grain out back. I'm trying to grow the
[01:19:47.400 --> 01:19:53.400]   heritage. You could have a million your own wheat. I actually do mill my own wheat, wait a minute.
[01:19:53.400 --> 01:19:59.000]   I do mill my own wheat, but I don't grow the grain. In fact, my son, who is a little wise-ass,
[01:19:59.000 --> 01:20:04.520]   he's 17, says, when we say we're going to homemade pasta, he said, you're growing the wheat? I said,
[01:20:04.520 --> 01:20:15.160]   no. I will say, so this is as crazy as I got, but I realized how much our food chain is so much
[01:20:15.160 --> 01:20:20.840]   better than life used to be, because I made a loaf of bread and it happened to be the same day
[01:20:20.840 --> 01:20:24.120]   that I had also made meatballs and we're going to do paninis. Delicious.
[01:20:24.120 --> 01:20:28.760]   And then I also had fresh tomatoes. I was like, oh, just make the tomato sauce with the basil.
[01:20:29.560 --> 01:20:36.200]   Dear God, I was cooking for like six hours. Fresh tomatoes. And yeah, they didn't five minutes.
[01:20:36.200 --> 01:20:44.520]   Mom, that was great. Bye. I mean, it was the pey. I don't think I'd ever do that again.
[01:20:44.520 --> 01:20:51.480]   It was only it was only happenstance. I didn't do it. It's hard to make it from fresh fresh tomatoes,
[01:20:51.480 --> 01:20:58.200]   but yeah, because there's a lot of cooking involved. If you get some nice San Marzano tomatoes,
[01:20:58.200 --> 01:21:03.160]   here's a trick I learned from the great Marcella Hazan, one of the great Italian cookbooks of all
[01:21:03.160 --> 01:21:10.280]   time. Very simple marinara sauce, a can of marzano's are the best San Marzano tomatoes.
[01:21:10.280 --> 01:21:16.520]   Tastes if you want, whole if you want, you can squish them up, a half an onion and a stick of
[01:21:16.520 --> 01:21:21.080]   butter. That's it. Cook it for 45 minutes. That's it. It's the most. I'm going to one up you.
[01:21:21.640 --> 01:21:26.920]   Fantastic. Better. Yeah. Roast it instead of cooking it. Oh, good thinking.
[01:21:26.920 --> 01:21:33.160]   They're going to caramelize a little bit. Very nice. Very nice. Very nice. Okay, I like it.
[01:21:33.160 --> 01:21:37.560]   I will. Here's, I'm going to throw this all in. You know, if you don't want onion,
[01:21:37.560 --> 01:21:41.960]   because I'm not a huge onion fan, stick some garlic. If you want to get crazy,
[01:21:41.960 --> 01:21:46.600]   stick like an anchovy filling. See, that's why we don't chop up the onion. We cut it in half
[01:21:46.600 --> 01:21:51.400]   and put it in half an onion in there, because then you take it out. It just flavors it.
[01:21:51.400 --> 01:21:55.880]   And the butter gives it a nice fatty smoothness. It's very good. Yeah.
[01:21:55.880 --> 01:22:01.480]   I learned this from Blue Apron. I now finish all of my pasta sauce. That's a good idea.
[01:22:01.480 --> 01:22:05.560]   And the other. Gave it a pat or butter. Yeah. Oh, yeah. You always put a little bit. You know what?
[01:22:05.560 --> 01:22:13.480]   What is it? Salt, acid, fat. Heat. Yeah. It's only a few things in the world. That's it. That's it.
[01:22:14.840 --> 01:22:20.920]   God, why are we doing it? Like Google, we should be doing a cooking show. So the application.
[01:22:20.920 --> 01:22:28.600]   The application process was open for classes to start on September 14. Oh, yeah. But
[01:22:28.600 --> 01:22:36.360]   oh, yeah. But they don't mention anything about pricing for this particular service or
[01:22:36.360 --> 01:22:42.360]   opportunity for kids trying to have a gap school year. So I love the idea. Take advantage of that
[01:22:42.360 --> 01:22:47.960]   gap semester. Invest eight weeks this fall. Preparing for the real world. Build your network.
[01:22:47.960 --> 01:22:51.000]   Gain guidance from mentors. This is a great idea.
[01:22:51.000 --> 01:22:56.680]   Yeah. Let's apply. You know what? Here's how you find out how much it's going to cost.
[01:22:56.680 --> 01:23:00.200]   There we go. Let's apply. Send a form. Send it. Send it. Send it.
[01:23:00.200 --> 01:23:04.280]   Send a form. It doesn't sound like it costs anything.
[01:23:06.840 --> 01:23:13.640]   I think you just fill this out. I don't know how you would like. Does every I bet you it's just
[01:23:13.640 --> 01:23:20.840]   virtual, right? It's called an externship, not an internship because you and if is virtual, that's
[01:23:20.840 --> 01:23:27.320]   fine, but that still doesn't particularly mean free of charge, right? Yeah. And they talk about
[01:23:27.320 --> 01:23:31.240]   mentorship. Obviously, not everyone can do this. So there has to be something, right?
[01:23:35.080 --> 01:23:39.960]   What is my time commitment? Who is this course designed for college seniors? You have to be 18.
[01:23:39.960 --> 01:23:44.520]   Eight week program starts September 14th college seniors or. High school seniors.
[01:23:44.520 --> 01:23:46.680]   High school. Wait a minute.
[01:23:46.680 --> 01:23:55.480]   College seniors and juniors. Oh, so this is not for this is not for kids going to college.
[01:23:55.480 --> 01:23:58.920]   That's weird. So it isn't really gap years.
[01:23:58.920 --> 01:24:04.920]   Well, that's just really now really confused. It's a gap in the middle of your college years.
[01:24:04.920 --> 01:24:10.520]   As opposed to between his calling courses will be taught live via video. So that's how they can
[01:24:10.520 --> 01:24:16.680]   accommodate. There is no cost to attend our speaker series and workshops. We will adopt
[01:24:16.680 --> 01:24:21.720]   offer additional services you might find useful to purchase in the future. You don't get credit
[01:24:21.720 --> 01:24:27.960]   for it. There's no cost. It's really just informational video seminars about a lot of things
[01:24:27.960 --> 01:24:33.720]   that you might want to know about. And here's an example of your schedule, project planning,
[01:24:33.720 --> 01:24:37.560]   how to stand out to recruiters. This is for people about to graduate from college.
[01:24:37.560 --> 01:24:42.920]   This is to get you ready for your career, which I think is a great thing.
[01:24:42.920 --> 01:24:47.480]   I think it's especially since colleges can be so terrible at that.
[01:24:47.480 --> 01:24:52.840]   They really like if you ever go to like career counseling or services at a college, I mean,
[01:24:52.840 --> 01:24:58.360]   sometimes you just get the most outlandishly weird information. And I get why it's because
[01:24:58.360 --> 01:25:03.080]   they're trying to counsel people, you know, through a wide variety of jobs, but it's terrible.
[01:25:03.080 --> 01:25:07.320]   If you're a college junior or senior, you're going to take a gap semester because of COVID.
[01:25:07.320 --> 01:25:17.000]   Go to exuglerschool.com, ex-o-o-g-l-e-r-s-c-h-o-o-l.com. I think, and thank you for bringing this up.
[01:25:17.000 --> 01:25:24.840]   This is really good. That's really neat and it's free. And you know, it's definitely pre-professional
[01:25:24.840 --> 01:25:30.280]   training. I think that's really great. I had high school grades on the brain because I'm thinking
[01:25:30.280 --> 01:25:35.000]   about my... My heart-hit son is a senior. Yeah. What's he going to do?
[01:25:35.000 --> 01:25:40.120]   We don't know yet. You know, we're still going through the process of trying to figure out
[01:25:40.120 --> 01:25:47.320]   where to go. He definitely wants to go to college, but... And he won't be going till a year from
[01:25:47.320 --> 01:25:55.640]   September. So by then... Lockwoody, really? I think it'll still be different, but I think we'll be...
[01:25:56.680 --> 01:26:01.880]   better, should. We'll be in a different place that should be slightly better, but it may not be
[01:26:01.880 --> 01:26:08.200]   what we are used to. Right. I think that's true in general. I mean, that's... Well, yeah, that's...
[01:26:08.200 --> 01:26:14.120]   Thank you, Stacy. Thank you, Captain. That's called life. But it will be even more different
[01:26:14.120 --> 01:26:21.960]   than we expect. Sorry. I think a year from now, organizations will have learned a lot
[01:26:22.840 --> 01:26:27.800]   on how to deal with what we're dealing with. I think they already have. Some haven't,
[01:26:27.800 --> 01:26:33.080]   some haven't. Some are terribly slow. Are they? Because ours, my son is attending the
[01:26:33.080 --> 01:26:38.040]   Petaluma High for the first time this year as a senior. He was at another online school
[01:26:38.040 --> 01:26:42.520]   for a couple of years volitionally. Oh, I didn't know he was switching to Petal. Oh, wow.
[01:26:42.520 --> 01:26:47.640]   Well, he wants to walk with his friends. All right. Okay, got it. Right. But they have learned a lot
[01:26:47.640 --> 01:26:51.160]   in the intervening summer. They've really got the systems down a lot better.
[01:26:52.440 --> 01:26:56.680]   You know, and I think next year there'll be even better still. I just hope that we can get back
[01:26:56.680 --> 01:27:02.760]   to some sort of group activities. I don't know. So while we're on the... Can I do a quick plug
[01:27:02.760 --> 01:27:06.360]   for my school for the Craig Newmark Graduate School of Journalism? Yes, you know. That we just
[01:27:06.360 --> 01:27:12.040]   redid our entrepreneurial journalism program and applications just opened for... We planted
[01:27:12.040 --> 01:27:18.760]   this all online anyway. It was not because of COVID. 100-day all online program for certificate
[01:27:18.760 --> 01:27:24.680]   for the independent, resilient journalist. So if you want to serve someone, a community or market
[01:27:24.680 --> 01:27:29.800]   with your sub-stack email and your YouTube and your medium and events, we can have them and so on
[01:27:29.800 --> 01:27:35.160]   and so forth and give me money through Patreon and Kickstarter and all of that, then that's what
[01:27:35.160 --> 01:27:41.080]   we're going to teach you. Stacey, you should definitely... I said, Jeff, I've actually talked to...
[01:27:41.080 --> 01:27:46.200]   You know, Rose and Thal Alves, right? I've talked to him about... His classes in the past about
[01:27:46.200 --> 01:27:52.200]   entrepreneurial journalism. So if you want, not only do I have my own media company,
[01:27:52.200 --> 01:27:57.160]   my husband has his own media company in a totally different place. We will... Well,
[01:27:57.160 --> 01:28:03.160]   it's not a different physical place, but a... No, no, you're right. It's the same place.
[01:28:03.160 --> 01:28:13.480]   Has... One over. Do you think your school has gotten better at it, Jeff, that you've kind of
[01:28:13.480 --> 01:28:16.680]   figured out remote learning?
[01:28:16.680 --> 01:28:25.720]   Honest answer is that what we're still doing is... In the early days of media, we called it
[01:28:25.720 --> 01:28:30.840]   "shoverware," right? Do what you used to do in this new way. I think what... I think the benefit
[01:28:30.840 --> 01:28:34.440]   that's going to come out of this for us is the professors are all getting very excited about
[01:28:34.440 --> 01:28:40.120]   suddenly making hybrid things. They're making videos for the classes. The students can watch
[01:28:40.120 --> 01:28:45.560]   them at their own. I did my entire orientation thing and did not only YouTube videos. I turned
[01:28:45.560 --> 01:28:50.600]   into a podcast so they could listen. That's something I hadn't done before. So I think we'll get...
[01:28:50.600 --> 01:28:56.200]   Yes, we're doing fine at replicating what we did, but our classes are still three hours long.
[01:28:56.200 --> 01:29:01.320]   That's kind of ridiculous. We've got to rethink that. So I think this will open up our brains to
[01:29:01.320 --> 01:29:05.080]   rethink things more fundamentally, which would be a good thing. Yeah, I don't think that's a bad thing.
[01:29:05.080 --> 01:29:11.720]   Hey, let's go ahead. Nope, I was just going to say exactly. That's what I think in a year.
[01:29:11.720 --> 01:29:16.600]   That's the stuff I think will be different. It will be like, yeah. We'll have a vaccine by then.
[01:29:16.600 --> 01:29:24.680]   Even so, I don't think we'll be at the same place. And we're not thinking the vaccine as a panacea
[01:29:24.680 --> 01:29:29.720]   is silly. Really? Get your hopes up there. Yeah. Do you think we're looking at lower levels of
[01:29:29.720 --> 01:29:36.440]   immunity? We're looking at a population that has lots of anti-vaxxers. I mean, you're looking at...
[01:29:36.440 --> 01:29:38.600]   Yeah, but if I'm vaccinated, I don't care about them.
[01:29:38.600 --> 01:29:43.720]   The style of worms is going to be totally different.
[01:29:43.720 --> 01:29:49.400]   Whatever your new recommendation is not going to last forever.
[01:29:49.400 --> 01:29:53.320]   Well, I'll get another one. It's a little round in the population. Yeah, yeah.
[01:29:53.320 --> 01:29:58.440]   When you're... Look at that. The pandemic of 1918 never went away. It's H1N1.
[01:29:59.560 --> 01:30:08.040]   And we get a flu vaccine every fall. But it doesn't necessarily stop just that.
[01:30:08.040 --> 01:30:13.160]   Do you think... It doesn't stop all blues? No, I understand. And sometimes you get the flu.
[01:30:13.160 --> 01:30:18.840]   And really, the only reason that works is because it did mutate into something less fatal,
[01:30:18.840 --> 01:30:22.840]   which was a good thing. And there's no guarantee that would happen with COVID-19.
[01:30:22.840 --> 01:30:27.640]   But do you think, I mean, at some point, like in a year, two years, will I ever get to travel again?
[01:30:28.600 --> 01:30:33.400]   Will I ever get to eat at a restaurant? Go to a movie, go to a bar? Not at my age.
[01:30:33.400 --> 01:30:39.720]   That is a question. I mean, you can say like there's lots of people who might not...
[01:30:39.720 --> 01:30:43.160]   That's the other thing. You can say you'll get a vaccine, but maybe you won't be able to get a
[01:30:43.160 --> 01:30:47.560]   vaccine for production errors. Maybe it'll be riskier for people who are your age.
[01:30:47.560 --> 01:30:53.800]   So you're just saying it's unknown. I'm saying it's unknown, and it's likely not to ever go back to
[01:30:53.800 --> 01:30:59.080]   being ever so strong term. I don't think it'll go back within the next two to three years.
[01:30:59.080 --> 01:31:04.280]   Because the next one's coming. Well, that's the other thing that concerns me. I mean,
[01:31:04.280 --> 01:31:11.400]   it isn't like this is unheard of. We had SARS and we had MERS and we were lucky in both cases.
[01:31:11.400 --> 01:31:17.160]   We kind of dodged a bullet because of the kind of the profile of those particular viruses.
[01:31:17.160 --> 01:31:22.280]   We didn't this time and we could not again next time. And that could be a year from now. That
[01:31:22.280 --> 01:31:27.240]   could be three years from now. We don't know, right? I'm sure Elon Musk will have a cure by then.
[01:31:27.240 --> 01:31:31.720]   I actually like wearing a mask if it's freshly ironed.
[01:31:31.720 --> 01:31:38.520]   Feels kind of like a nice sheet on the bed. I do. I use the Niagara spray starch.
[01:31:38.520 --> 01:31:43.480]   It's like wearing a nice sheet. It's like getting in bed when your sheets have changed.
[01:31:43.480 --> 01:31:48.920]   It's very nice. Freshly ironed mask. The nice thing about that ironing a mask takes a second
[01:31:48.920 --> 01:31:53.800]   compared to ironing a sheet. You can have a freshly ironed mask every single day of the week.
[01:31:53.800 --> 01:31:56.760]   How about that? Do you guys have ironed sheets?
[01:31:56.760 --> 01:32:04.760]   Is that really something y'all do? That would be no. No. I'm old enough.
[01:32:04.760 --> 01:32:08.920]   No, but my in-laws actually have their housekeepers iron their sheets.
[01:32:08.920 --> 01:32:12.440]   And the first time I slipped in there, I was like, what is happening? It's pretty nice.
[01:32:12.440 --> 01:32:15.320]   It's very nice. It's pretty nice if you can do it. But I was like,
[01:32:16.040 --> 01:32:23.720]   who would make someone ironed sheets? So I learned from my devoted watching of my
[01:32:23.720 --> 01:32:30.840]   reality show below deck, which is all about the life of people who work in the charter yacht
[01:32:30.840 --> 01:32:38.280]   business, those 150 foot mega yachts, that there actually is a big rolling device that you could
[01:32:38.280 --> 01:32:42.040]   they iron their sheets, but they don't do it with an iron. There's a big rolling device.
[01:32:42.040 --> 01:32:48.200]   You put it through press. Yeah. So we just get one of those press. We talk about good bird.
[01:32:48.200 --> 01:32:54.200]   Good bird. Nope. Nope. I want to do the change log. Play the drums.
[01:32:54.200 --> 01:32:57.960]   The Google change log.
[01:32:57.960 --> 01:33:05.560]   Google, you will be thrilled to learn Jeff Jarvis.
[01:33:06.600 --> 01:33:13.720]   What is rolling out automatic dark light mode switching to the Google keyboard, the Gboard beta
[01:33:13.720 --> 01:33:20.200]   users. Enough said I just happened to me recently. Did it just happen? Not back. No, not that.
[01:33:20.200 --> 01:33:24.440]   Something else would have made a dark mode. And I was just, yeah, I was growling.
[01:33:24.440 --> 01:33:29.560]   Google is releasing AdMob for Android early access available. Not to everybody on the play
[01:33:29.560 --> 01:33:34.520]   store. You can keep track of your earnings, your apps, explore useful metrics.
[01:33:34.520 --> 01:33:40.520]   I don't know. You're so excited. I lost your spark.
[01:33:40.520 --> 01:33:51.800]   I lost my mojo. Google camera 7.5 does away with storing pixel portrait pairs and individual photos.
[01:33:51.800 --> 01:33:57.240]   I don't even know what I just said. Is that the two pictures that happen?
[01:33:57.880 --> 01:34:02.680]   Like sometimes when I take a picture in certain. Yeah, it saves a blurred version in the original
[01:34:02.680 --> 01:34:11.160]   shot so that you can edit one or the other if you want. Currently, 7.4 each pair generates and is
[01:34:11.160 --> 01:34:16.840]   stored in a standalone folder, which means you will have hundreds and thousands of folders.
[01:34:16.840 --> 01:34:20.120]   So now they've got some other way of doing it. Yeah.
[01:34:20.120 --> 01:34:25.000]   It's actually in. Yeah, it helps you clean up your phone a little bit.
[01:34:25.000 --> 01:34:28.680]   Right. They're actually going to name it in a way that you can look at it and go,
[01:34:28.680 --> 01:34:33.160]   Oh, that's the portrait. And that's the original. And yeah, that's good.
[01:34:33.160 --> 01:34:39.640]   I think that's a good thing. I actually used, I actually go between looking at those two
[01:34:39.640 --> 01:34:46.840]   point of views because sometimes the focal length is just right.
[01:34:46.840 --> 01:34:53.160]   Right. With that versus using the regular focal length on the non-portrait mode. So you can just
[01:34:53.160 --> 01:34:58.520]   pick between the two and don't necessarily keep the blur, but still have that same focal length,
[01:34:58.520 --> 01:35:03.880]   that same bit of distortion. You'll also get the new naming begins with the PXL,
[01:35:03.880 --> 01:35:09.880]   then the date, then a serial number, and then the name has information about whether it's a cover
[01:35:09.880 --> 01:35:18.040]   or the original. So that's good. That's going to be available in Android 11, which just, I think,
[01:35:18.040 --> 01:35:21.400]   it's another public beta. So I think we must be getting close to the release.
[01:35:21.400 --> 01:35:24.840]   Andrea, I like a lot. I really like a lot.
[01:35:24.840 --> 01:35:34.440]   Let's see. Google Chrome version 80 is now out and it's 10% faster, kids.
[01:35:34.440 --> 01:35:42.680]   With tabs. It's got tab grouping. Better 10 grouping.
[01:35:42.680 --> 01:35:45.240]   Better tab grouping. Somehow now it's 10% faster.
[01:35:45.240 --> 01:35:47.400]   Newer 10% faster.
[01:35:47.400 --> 01:35:50.760]   I haven't, have you used tab grouping? Or you know, that's what you won't use.
[01:35:50.760 --> 01:35:57.560]   I use a figure of Firefox. Actually, I downloaded 80 just this morning just to see
[01:35:57.560 --> 01:36:03.160]   what's different about it. And it's not, you know, I like pinned tabs a lot. So this is kind of
[01:36:03.160 --> 01:36:09.400]   like pinned tabs, but you can have groups of work groups and stuff. So that's nice. So you
[01:36:09.400 --> 01:36:15.720]   can have a news. And I would do that. I have a news. Here's an example. This is a tab that's now
[01:36:15.720 --> 01:36:21.560]   expanded and then contracted back down. Save room. Because what happens as happens to me with a
[01:36:21.560 --> 01:36:26.760]   lot of pinned tabs is pretty soon you're told top of the browser bar is occupied.
[01:36:26.760 --> 01:36:32.840]   And something, something QR codes.
[01:36:34.280 --> 01:36:38.920]   Yeah, I didn't understand that at all. I didn't. Okay, let me scroll down. What is it?
[01:36:38.920 --> 01:36:48.120]   The new way to share URLs. You can in fact print the page or generate a QR code. So
[01:36:48.120 --> 01:36:52.360]   with a little dinosaur. This is like the, this is the QCat goes virtual. Yeah.
[01:36:52.360 --> 01:36:56.120]   Ridiculous. Yeah. So if you want to share a web page with somebody, you can just give them a little
[01:36:56.120 --> 01:37:01.480]   dinosaur QR code. Do you guys, are you guys old enough to know about the QCat?
[01:37:02.120 --> 01:37:06.440]   Oh, yeah. I know. I know Dave. I know you do. I know the guy invented it.
[01:37:06.440 --> 01:37:15.240]   Oh, you're not. I don't know. If I'm old enough, I don't know anything about it. So, well, guess what?
[01:37:15.240 --> 01:37:19.640]   I'm not enlightened. We have one somewhere. It's probably in my, oh, where throw to me.
[01:37:19.640 --> 01:37:28.520]   I feel like we in both the QCat and all the time. This is why we're still live.
[01:37:29.080 --> 01:37:33.720]   In the Mike Falls.
[01:37:33.720 --> 01:37:40.600]   This is why you watch it live. Yeah, they're not going to cut that out. I guarantee you.
[01:37:40.600 --> 01:37:47.480]   Probably be tweeted. So that's a QCat. You, we've talked about this like five times.
[01:37:47.480 --> 01:37:48.760]   Everyone. Everybody. Okay.
[01:37:48.760 --> 01:37:51.800]   Stop. I've seen it, but I know.
[01:37:51.800 --> 01:37:56.280]   Mine is autograph. Mine's autograph by Dave Matthews, the guy who invented it.
[01:37:56.920 --> 01:37:59.080]   Not the band. Okay.
[01:37:59.080 --> 01:38:01.560]   That's how I wore the huge fan of Twit.
[01:38:01.560 --> 01:38:05.320]   And your team, thanks for doing what you do. Dave Matthews inventor.
[01:38:05.320 --> 01:38:13.720]   They gave these away at radio shacks. You could tell it's pretty old because instead of having
[01:38:13.720 --> 01:38:18.440]   like a USB connector, it's got these right keyboard connector. And the idea is you'd read
[01:38:18.440 --> 01:38:23.080]   a newspaper and you'd see a QR barcode. It wasn't a QR code. And you could scan it with this.
[01:38:23.080 --> 01:38:27.640]   And it would open your browser. Because URLs were just too hard to ever imagine.
[01:38:27.640 --> 01:38:30.760]   It's whatever type the mess did not make. Wow.
[01:38:30.760 --> 01:38:36.280]   It did not make a big, big splash, especially because it's cat-shaped, but it's cool to have.
[01:38:36.280 --> 01:38:41.080]   And Dave Matthews signed it for you. I thought the cat shape was a selling point myself.
[01:38:41.080 --> 01:38:43.960]   Yeah. The Internet loves cats. You have a cat and a mouse.
[01:38:43.960 --> 01:38:47.000]   I think it was free too. Right. You got a cat and oh yeah.
[01:38:47.000 --> 01:38:50.440]   Not wired game in the way. That was the whole idea. You're going to put, you are, you're going to put
[01:38:50.440 --> 01:38:56.040]   codes on every one of your ads and stories. You're going to be tethered to your desktop machine and
[01:38:56.040 --> 01:39:00.520]   the den. Right. Because it was going to be too difficult to type in a URL.
[01:39:00.520 --> 01:39:07.240]   Usually change logs are things that are good. This is a thing that is bad. Google Fi is ending
[01:39:07.240 --> 01:39:15.240]   its payment grace period for COVID-19. So they're going to return to their standard policies for
[01:39:15.240 --> 01:39:19.720]   late payments and data speeds. Because good news. COVID is over. Everybody's back to work.
[01:39:19.720 --> 01:39:28.760]   The economy's booming. Congratulations. To be fair, how long do you do this?
[01:39:28.760 --> 01:39:33.400]   I mean, how long do you hold off on letting people pay for essential services?
[01:39:33.400 --> 01:39:39.480]   And possibly, maybe if Google says, all right, we're not doing this and all these other people
[01:39:39.480 --> 01:39:44.120]   do this, maybe the government will realize that they need to solve this. I keep thinking we're
[01:39:44.120 --> 01:39:49.080]   going to get nationwide broadband, but I've so far been wrong. Oh gosh. We're going to get
[01:39:49.080 --> 01:39:53.880]   Starlink. We're going to get Elon Musk broadband for $80 a month. That's what we're going to
[01:39:53.880 --> 01:39:58.840]   do. It's not going to help me cancel my fi. I'll leave you here. Fi when I was traveling.
[01:39:58.840 --> 01:40:07.160]   If I stop the fi, do I keep my number? Oh, that's an issue. No, I guess you could. You could
[01:40:07.160 --> 01:40:09.960]   probably transfer it back to Google Voice. Yeah, you want to keep your number. Yeah.
[01:40:09.960 --> 01:40:15.640]   Earlier this year, Google extended the fi grace period in which subscribers maintain full
[01:40:15.640 --> 01:40:19.640]   salary of service to 60 days from the missed billing dates. You had two months.
[01:40:19.640 --> 01:40:26.920]   And if you experience hardship related to COVID-19, you could request an extension from your account
[01:40:26.920 --> 01:40:32.520]   page. They are now reverting the late payment extension back to three days, not 60 days.
[01:40:32.520 --> 01:40:37.960]   After that, you won't be able to make or accept calls, send or receive texts or use data. Google
[01:40:37.960 --> 01:40:44.680]   One subscriptions also get suspended. Meanwhile, full speed data limits will return to 15 gigabytes
[01:40:44.680 --> 01:40:50.520]   for flexible 22 gigabytes for unlimited starting on or after September 3rd.
[01:40:50.520 --> 01:40:56.280]   Sounds like they're on par with everybody else. And the market's back to normal.
[01:40:56.280 --> 01:41:02.200]   Yeah, everybody else has started to change their services back in July or so. Yeah, I guess that
[01:41:02.200 --> 01:41:07.080]   makes sense. And you can stop your Google fly temporarily. How long is temporary? Oh, that's
[01:41:07.080 --> 01:41:13.320]   three months. It's just just halted. Yeah. Oh, I'll do that for three months and then pay for it.
[01:41:13.320 --> 01:41:17.640]   I'll do it. Then you can come back to it. Yeah, okay. I'll do that because it was basically
[01:41:17.640 --> 01:41:25.560]   I'm paying for zoom now instead of Google five. Yeah. When you look for weather on your Android
[01:41:25.560 --> 01:41:31.880]   device now, you will see the little cute little Google frog that is in all the weather displays
[01:41:31.880 --> 01:41:38.200]   has started wearing a mask when he goes outside. It's kind of cute. So I have a question about
[01:41:38.200 --> 01:41:44.680]   the Google frog. Yes. Does he do the same activities for certain temperatures? What is like?
[01:41:44.680 --> 01:41:49.640]   Because you sometimes see the same stuff, but I have never mapped out his activities to the
[01:41:49.640 --> 01:41:54.680]   temperature. But I kind of wish someone had maybe someone has, but I'm very curious if the frog is
[01:41:54.680 --> 01:42:00.520]   like, that's a good question. No one ever asked this? Come on, y'all. I know someone out there has
[01:42:00.520 --> 01:42:06.120]   wondered this and it knows the answer. They see. I never even noticed a dad gum frog on this thing
[01:42:06.120 --> 01:42:10.600]   to see. I love the frog. I feel like the frog is talking about.
[01:42:10.600 --> 01:42:18.120]   So, okay. Well, here, everybody pick up your phone. Okay. My television right now is 75 Fahrenheit
[01:42:18.120 --> 01:42:22.840]   and my frog. I've never seen him do with this before. He's actually on the roof of a building
[01:42:22.840 --> 01:42:30.360]   in a lawn chair with a glass next to him wearing his mask. What is your frog? How do I get it?
[01:42:30.360 --> 01:42:35.480]   I don't even know. That's the weather like. Click the weather and little weather icon.
[01:42:36.280 --> 01:42:39.960]   The weather icon. Where's the weather? That's what I'm doing. It's on my front screen.
[01:42:39.960 --> 01:42:48.360]   Mine has the frog up on top of a rock or a hill or whatever. Looks like it's having lunch in a
[01:42:48.360 --> 01:42:54.920]   spot of tea or maybe coffee. It's just a little bit smoky and hazy. Maybe you can see it. I don't know.
[01:42:54.920 --> 01:43:02.440]   Let's see. I don't have a weather. I don't have a weather. I've never seen that. I've seen the
[01:43:02.440 --> 01:43:09.720]   frog on the rocks. Okay. And that was 70. Oh, I've got a frog on the on the on the on the roof with
[01:43:09.720 --> 01:43:17.240]   a drink. Oh, what's your temperature? 73. Where do you get these guy? How do you get? I
[01:43:17.240 --> 01:43:26.360]   on the on the on the on the on the on the right here. I don't have a pixel launcher. Oh, you don't
[01:43:26.360 --> 01:43:31.640]   have a pixel that there because he's got to be special. The okay. I have different launcher.
[01:43:32.200 --> 01:43:36.760]   So I don't have that. He has got to be contrarian. But what I understand is there's no way to get
[01:43:36.760 --> 01:43:41.080]   it. Otherwise there's not like a weather. I search. You know, if you search if you Google
[01:43:41.080 --> 01:43:47.880]   weather. Weather if you Google weather, then you should get now my frog on the weather is
[01:43:47.880 --> 01:43:53.640]   flying a kite weather. The amount looks different now. Is he's flying a kite? What if our frogs are
[01:43:53.640 --> 01:43:59.080]   the same? Mine is a frog. I can't tell what that is. He's on the rooftop somewhere with the.
[01:44:00.280 --> 01:44:04.200]   Oh, that's fine. So I have the right. Yeah, it looks like you're right now on my other weather.
[01:44:04.200 --> 01:44:11.720]   Okay. So this is a huge digression, but it was about Google. So that was our only story about Google
[01:44:11.720 --> 01:44:20.920]   all day long. I don't have any weather. Well, you scroll down, Leo. That was that was it.
[01:44:20.920 --> 01:44:24.040]   Oh, no, here. So here's what you look at me.
[01:44:25.560 --> 01:44:30.760]   Look at you're getting a different weather. I see my weather. Yeah, because you have that damn
[01:44:30.760 --> 01:44:39.960]   dark boat. That's why. Well, that's a good stuff. I can scroll up and up and up. But no weather.
[01:44:39.960 --> 01:44:49.160]   It's a different. I got it's not a Samsung. I don't know. It's weird. That's the Google change
[01:44:53.160 --> 01:44:57.160]   Okay, I'm going to give you one last chance to pick a story. Well, I have a few. Wait a minute. I got
[01:44:57.160 --> 01:45:04.520]   to pick a few. There's a few here. Like the like it turns out, I didn't know this, but there is a
[01:45:04.520 --> 01:45:12.360]   Scottish Wikipedia. Did you see this? I saw the headline. I didn't get the story. So apparently,
[01:45:12.360 --> 01:45:19.000]   this Scottish Wikipedia is being edited. But the problem is it's by a guy who doesn't speak Scottish.
[01:45:19.720 --> 01:45:28.040]   He's some American guy, according to vice a self professed Christian INTP furry,
[01:45:28.040 --> 01:45:33.800]   furry living somewhere in North Carolina. And Leo Leo Leo stop. You got to do this in the accent.
[01:45:33.800 --> 01:45:38.040]   You have to destroy the accent. I thought he was living in 10 years. Well, the funny thing is,
[01:45:38.040 --> 01:45:43.320]   his Scottish is about as real as mine is.
[01:45:45.080 --> 01:45:52.360]   So here's an example. This is the first article he edited. The human development index. I mean,
[01:45:52.360 --> 01:45:59.720]   it's just a simple, simple thing. I'll just blow it up. Free Wikipedia, the free book, a knowledge.
[01:45:59.720 --> 01:46:06.840]   The human development index is a composite statistic or life expectancy, education,
[01:46:07.480 --> 01:46:14.280]   and income indices to write kinders into a flowers, tears, or human development.
[01:46:14.280 --> 01:46:21.560]   Oh, my God. But that apparently is no relation to anything.
[01:46:21.560 --> 01:46:30.680]   Well, Scottish. Apparently, though, he's not he's not he's not doing it for any mean reason.
[01:46:30.680 --> 01:46:37.160]   What he's doing is he'll write the article in English and then look up each word in a Scottish
[01:46:37.160 --> 01:46:44.520]   English dictionary and just stick it in if it kind of sort of matches. But this is the sad part.
[01:46:44.520 --> 01:46:51.800]   He's responsible for one third of the Scots Wikipedia entries. And probably nobody noticed
[01:46:51.800 --> 01:46:59.320]   till now. Well, yeah. One user wrote, I find it insulting that you would pass this off as our
[01:46:59.320 --> 01:47:06.760]   native language, but you don't speak. Again, as a native Scot and native speaker, no one
[01:47:07.720 --> 01:47:12.360]   uses who uses the site as it isn't even close to resembling any Scots language.
[01:47:12.360 --> 01:47:22.280]   Here on a page about the movie Million Dollar Baby, he wrote this film is a boot,
[01:47:22.280 --> 01:47:24.920]   an underappreciate a boxing trainer.
[01:47:27.640 --> 01:47:37.880]   Pitkine is a peer to peer payment system introduced as open source software in 2009 by developer Satoshi
[01:47:37.880 --> 01:47:46.280]   Nakamoto. Oh, geez. Yeah, there's no indication, according to Vice at Amarillo,
[01:47:46.280 --> 01:47:50.680]   that's the sky's name, Amarillo's gardener, his handle was attempting to do anything wrong.
[01:47:50.680 --> 01:47:55.480]   But their work has been damaging nonetheless on their talk page. They wrote,
[01:47:55.480 --> 01:48:00.280]   if I had to do it over, I would have kept two more clean up and just keeping the wiki up and
[01:48:00.280 --> 01:48:07.000]   running instead of writing articles. But I meant the best. It's like, it's like those old ladies
[01:48:07.000 --> 01:48:12.840]   who try to redo the, you know, the Renaissance painting. Yeah, exactly. You end up with something
[01:48:12.840 --> 01:48:19.640]   horrible, right? Yeah, you get the smoosh, Jesus. Yeah. On the Reddit post, it says,
[01:48:20.200 --> 01:48:25.400]   the damage done by this may be more severe than anyone anticipates as a result, quote,
[01:48:25.400 --> 01:48:30.520]   this person has possibly done more damage to the Scott's language than anyone in history.
[01:48:30.520 --> 01:48:35.000]   Because of this cultural vandalism, it's possible many people think,
[01:48:35.000 --> 01:48:41.480]   think Scott's is a horribly mangled rendering of English rather than a language of its own,
[01:48:41.480 --> 01:48:45.160]   and for which I take some responsibility as you should.
[01:48:47.960 --> 01:48:51.560]   So now they're debating, what do we do? If we close it, it will never be reopened.
[01:48:51.560 --> 01:48:58.680]   The guy was just trying to preserve Scottish Wikipedia. Oh God.
[01:48:58.680 --> 01:49:10.280]   Mr. Naze's is to solicit more people to get more people to more Scottish people to actually
[01:49:10.280 --> 01:49:17.880]   participate. Because that's, is the downside of not having enough participants in an open ecosystem.
[01:49:18.520 --> 01:49:25.560]   Yeah. It was apparently he was a teenager when he started doing it. He was the
[01:49:25.560 --> 01:49:29.480]   Redditor who discovered it said, I've been told that there's been harassment going on.
[01:49:29.480 --> 01:49:33.000]   Seems like a nice person who made a mistake when they were a young child,
[01:49:33.000 --> 01:49:37.080]   a mistake nobody ever bothered to correct. It's hardly their fault. They're very passionate
[01:49:37.080 --> 01:49:43.640]   and dedicated. The Scott's language version of Wikipedia is legendarily bad.
[01:49:46.760 --> 01:49:54.920]   Wow. Blaze Pascal was a French mathematician, physicist inventor, writer, and Christian philosopher.
[01:49:54.920 --> 01:50:00.680]   He was a child prodigy that was educated by his father, a tax collector in New York.
[01:50:00.680 --> 01:50:03.480]   So I think the kid thought this is how this is how they do it.
[01:50:03.480 --> 01:50:06.840]   You find some real Scottish language.
[01:50:06.840 --> 01:50:07.800]   Very easy with that.
[01:50:07.800 --> 01:50:14.040]   They misuse common elements of Scott's, or even regularly found in Scott's English, like
[01:50:14.600 --> 01:50:27.400]   sign and, well, yeah, that's a Scotts, right? Old Langseine.
[01:50:27.400 --> 01:50:30.760]   There's Scott's language and then there's Scottish English.
[01:50:30.760 --> 01:50:36.840]   Yeah, I don't.
[01:50:36.840 --> 01:50:46.200]   Once again, where's John McWhorter? It's pretty funny.
[01:50:46.200 --> 01:50:48.360]   It is.
[01:50:48.360 --> 01:50:55.000]   Yeah. And the funniest thing is the kid apparently was sincere. This wasn't like some.
[01:50:55.000 --> 01:50:59.000]   Yeah, it's not funny. That's sad. Everybody's being fiendy.
[01:50:59.000 --> 01:51:00.200]   He's like Star Wars kid.
[01:51:00.200 --> 01:51:03.960]   My fear is that he's a twit fan.
[01:51:03.960 --> 01:51:08.120]   He's probably watching right now and he learned how to speak Scott's from me.
[01:51:08.120 --> 01:51:09.720]   On the chat room.
[01:51:09.720 --> 01:51:11.320]   It's all me fault.
[01:51:11.320 --> 01:51:15.080]   Welcome to Wikipedia.
[01:51:15.080 --> 01:51:18.680]   Would you like a scone?
[01:51:18.680 --> 01:51:20.040]   All right.
[01:51:20.040 --> 01:51:25.800]   I did kiss the scone a scone or a scone. I don't know what it's called.
[01:51:25.800 --> 01:51:27.800]   Wouldn't you have like a bannock, not a scone?
[01:51:27.800 --> 01:51:28.680]   I'd have a bannock.
[01:51:31.080 --> 01:51:35.320]   Was Zoom down for your daughter? A couple of days ago.
[01:51:35.320 --> 01:51:36.440]   They use Google meets.
[01:51:36.440 --> 01:51:37.080]   Oh, they use meet.
[01:51:37.080 --> 01:51:41.240]   So I got a panicked call from Lisa said.
[01:51:41.240 --> 01:51:44.280]   The school call us. They said Zoom's down.
[01:51:44.280 --> 01:51:45.960]   It was.
[01:51:45.960 --> 01:51:46.280]   Yeah.
[01:51:46.280 --> 01:51:50.520]   And the children they did rejoice according to the verge.
[01:51:50.520 --> 01:51:53.880]   I like the idea of calling it the new snow day.
[01:51:53.880 --> 01:51:54.760]   The new snow day.
[01:51:54.760 --> 01:51:56.840]   Well, we really got a snow year is what we got.
[01:51:58.600 --> 01:52:03.800]   It was a big outage that covered much of the United States
[01:52:03.800 --> 01:52:05.560]   at the beginning of the school day.
[01:52:05.560 --> 01:52:07.080]   So yeah, Zoom is.
[01:52:07.080 --> 01:52:10.040]   This was on what this was on the 24th at one time.
[01:52:10.040 --> 01:52:15.560]   Starting at 6.52 AM, I guess Eastern.
[01:52:15.560 --> 01:52:19.720]   So there's a hilarious Twitter account called associate deans.
[01:52:19.720 --> 01:52:21.160]   Ask underscore deans.
[01:52:21.160 --> 01:52:25.080]   That is makes fun of all administrators and universities.
[01:52:25.080 --> 01:52:27.400]   And at the same time, it just said,
[01:52:27.400 --> 01:52:29.400]   do you have a plan for when zoomed goes down?
[01:52:29.400 --> 01:52:29.800]   Correct.
[01:52:29.800 --> 01:52:34.760]   Everyone was retweeting the hell out of that.
[01:52:34.760 --> 01:52:39.240]   Trust us.
[01:52:39.240 --> 01:52:41.000]   We're from the middle of the administration.
[01:52:41.000 --> 01:52:41.960]   We're here to help you.
[01:52:41.960 --> 01:52:46.840]   You do have a plan for when Zoom goes down.
[01:52:46.840 --> 01:52:48.120]   Correct.
[01:52:48.120 --> 01:52:52.520]   All right.
[01:52:52.520 --> 01:52:53.800]   So Charlie.
[01:52:55.720 --> 01:52:59.000]   Boys might be weathering the pandemic better than girls.
[01:52:59.000 --> 01:53:03.720]   Guess which august newspaper printed that headline?
[01:53:03.720 --> 01:53:06.520]   New York Times Wall Street Journal.
[01:53:06.520 --> 01:53:07.160]   Wall Street Journal.
[01:53:07.160 --> 01:53:07.480]   Sorry.
[01:53:07.480 --> 01:53:09.160]   Or yeah, coming to New York Post too.
[01:53:09.160 --> 01:53:09.640]   Yeah.
[01:53:09.640 --> 01:53:14.600]   This is by somebody named Julie jargon.
[01:53:14.600 --> 01:53:15.000]   Really?
[01:53:15.000 --> 01:53:17.240]   Oh, I know, Julie.
[01:53:17.240 --> 01:53:17.480]   Oh.
[01:53:17.480 --> 01:53:19.000]   She talks to my husband for things.
[01:53:19.000 --> 01:53:19.560]   Well.
[01:53:19.560 --> 01:53:20.680]   And never quotes him.
[01:53:22.200 --> 01:53:26.040]   Video game playing his sword during the COVID-19 pandemic
[01:53:26.040 --> 01:53:29.320]   fueled largely by boys who socialize while they play.
[01:53:29.320 --> 01:53:29.960]   That's true.
[01:53:29.960 --> 01:53:33.400]   I have to say our 17 year old, as soon as school is out,
[01:53:33.400 --> 01:53:35.160]   he sits right down in front of the computer
[01:53:35.160 --> 01:53:37.400]   and plays video games with his friends,
[01:53:37.400 --> 01:53:38.280]   with his school friends.
[01:53:38.280 --> 01:53:38.680]   Yeah.
[01:53:38.680 --> 01:53:41.560]   Typical day.
[01:53:41.560 --> 01:53:42.440]   That's social.
[01:53:42.440 --> 01:53:43.880]   Plus they're anti social.
[01:53:43.880 --> 01:53:45.240]   They don't want to be around anybody.
[01:53:45.240 --> 01:53:45.560]   Yeah.
[01:53:45.560 --> 01:53:46.120]   They're happy.
[01:53:46.120 --> 01:53:46.840]   Boys like it.
[01:53:46.840 --> 01:53:50.280]   Speaking of video games,
[01:53:50.280 --> 01:53:52.600]   did you see the AI created tennis games?
[01:53:52.600 --> 01:53:55.160]   Feather versus feather.
[01:53:55.160 --> 01:53:58.040]   Let's see it right now.
[01:53:58.040 --> 01:53:59.720]   I didn't see it.
[01:53:59.720 --> 01:54:00.280]   It's got it.
[01:54:00.280 --> 01:54:01.080]   It's pretty fun.
[01:54:01.080 --> 01:54:01.720]   It's pretty fun.
[01:54:01.720 --> 01:54:04.280]   So they made little sprites.
[01:54:04.280 --> 01:54:06.760]   And that's better.
[01:54:06.760 --> 01:54:07.720]   He played himself.
[01:54:07.720 --> 01:54:09.720]   You could they have feather.
[01:54:09.720 --> 01:54:11.480]   They could they can put anybody against anybody.
[01:54:11.480 --> 01:54:15.320]   And it's real players with real shots mixed.
[01:54:15.320 --> 01:54:18.040]   So I'm confused.
[01:54:18.040 --> 01:54:19.320]   Is those are two sprites?
[01:54:19.320 --> 01:54:21.080]   Those are not if you look carefully.
[01:54:21.080 --> 01:54:21.400]   Oh, yeah.
[01:54:21.400 --> 01:54:23.240]   They're not really attached to the ground.
[01:54:23.240 --> 01:54:23.560]   Yeah.
[01:54:23.560 --> 01:54:24.040]   Yeah.
[01:54:24.040 --> 01:54:24.520]   Right.
[01:54:24.520 --> 01:54:27.000]   So if I and nobody else is moving, so obviously.
[01:54:27.000 --> 01:54:33.640]   And so where are the sprites generated from real games?
[01:54:33.640 --> 01:54:34.840]   I think they take they take pieces.
[01:54:34.840 --> 01:54:35.000]   Yeah.
[01:54:35.000 --> 01:54:36.840]   So it's an animated database of shots.
[01:54:36.840 --> 01:54:38.200]   That's awesome.
[01:54:38.200 --> 01:54:38.840]   Keep going.
[01:54:38.840 --> 01:54:39.880]   Now we have feather or V.
[01:54:39.880 --> 01:54:40.200]   Fetter.
[01:54:40.200 --> 01:54:42.520]   I don't think we're ever going to really need
[01:54:42.520 --> 01:54:43.720]   tennis players ever again.
[01:54:43.720 --> 01:54:44.360]   No, we're not.
[01:54:44.360 --> 01:54:46.120]   We're certainly baseball.
[01:54:46.120 --> 01:54:47.800]   Now you now you can.
[01:54:47.800 --> 01:54:49.320]   No, Serena Williams.
[01:54:49.320 --> 01:54:50.760]   Serena versus Federer.
[01:54:50.760 --> 01:54:51.000]   Yeah.
[01:54:51.000 --> 01:54:51.880]   That's cool, isn't it?
[01:54:51.880 --> 01:54:55.480]   And then finally you never see, right?
[01:54:55.480 --> 01:54:56.440]   Yeah, you never see.
[01:54:56.440 --> 01:54:59.080]   Now you can direct where the shot goes
[01:54:59.080 --> 01:55:00.520]   and the NDA will do it.
[01:55:00.520 --> 01:55:02.120]   Oh my god, it'll actually put it there.
[01:55:02.120 --> 01:55:03.800]   And then Federer will get it there.
[01:55:03.800 --> 01:55:08.520]   This becomes a whole new view of a of a of a sport game.
[01:55:08.520 --> 01:55:10.440]   Wow.
[01:55:10.440 --> 01:55:11.640]   That's really interesting.
[01:55:11.640 --> 01:55:12.600]   Isn't that cool?
[01:55:12.600 --> 01:55:13.000]   Yeah.
[01:55:13.000 --> 01:55:15.400]   Well, this be the next version of e-sports.
[01:55:15.400 --> 01:55:16.440]   Is that what you're saying?
[01:55:16.440 --> 01:55:16.920]   That's what I'm thinking.
[01:55:16.920 --> 01:55:17.240]   Yeah.
[01:55:17.640 --> 01:55:20.280]   But it's going to feel real or because you're going to have real players.
[01:55:20.280 --> 01:55:24.840]   You can do it in baseball because they spend nine hours just standing there.
[01:55:24.840 --> 01:55:25.560]   So I'm easy.
[01:55:25.560 --> 01:55:28.280]   Well, they did.
[01:55:28.280 --> 01:55:30.360]   I will say my husband is desperate for sports.
[01:55:30.360 --> 01:55:32.040]   Mading football is the same concept of.
[01:55:32.040 --> 01:55:32.360]   Yeah.
[01:55:32.360 --> 01:55:33.000]   You could share it.
[01:55:33.000 --> 01:55:36.680]   You know how to control where the ball goes and things like that.
[01:55:36.680 --> 01:55:36.680]   Yeah.
[01:55:36.680 --> 01:55:37.160]   Yeah.
[01:55:37.160 --> 01:55:37.720]   Yeah.
[01:55:37.720 --> 01:55:41.320]   Who put this ad in for the IBM Selectric?
[01:55:41.320 --> 01:55:42.360]   Did you put this in?
[01:55:42.360 --> 01:55:42.760]   I did.
[01:55:42.760 --> 01:55:44.760]   I always wanted one of these.
[01:55:44.760 --> 01:55:48.440]   I wanted all the best thing that's open to typing since electricity.
[01:55:48.440 --> 01:55:51.160]   The IBM Selectric typewriter.
[01:55:51.160 --> 01:55:53.560]   Instead of type bars.
[01:55:53.560 --> 01:55:54.680]   Is that working well?
[01:55:54.680 --> 01:55:55.480]   It's a working element.
[01:55:55.480 --> 01:55:56.920]   No.
[01:55:56.920 --> 01:56:01.080]   The dances across the paper at incredible speed.
[01:56:01.080 --> 01:56:02.680]   That is pretty bad.
[01:56:02.680 --> 01:56:03.800]   That's an Austin.
[01:56:03.800 --> 01:56:09.160]   Now, watch in slow motion as it turns, tilts and prints.
[01:56:09.160 --> 01:56:13.560]   This tiny printing element is also interchangeable.
[01:56:13.800 --> 01:56:17.160]   So, simply remove one type style.
[01:56:17.160 --> 01:56:20.440]   Choose another from several of the same type papers.
[01:56:20.440 --> 01:56:21.000]   Those balls.
[01:56:21.000 --> 01:56:22.760]   That's pretty cool.
[01:56:22.760 --> 01:56:23.800]   I wanted the big one.
[01:56:23.800 --> 01:56:24.440]   I wanted the big one.
[01:56:24.440 --> 01:56:25.720]   That you could do speeches with.
[01:56:25.720 --> 01:56:26.200]   Oh, yeah.
[01:56:26.200 --> 01:56:27.720]   Takes only five seconds.
[01:56:27.720 --> 01:56:30.600]   And you're ready to start typing again.
[01:56:30.600 --> 01:56:33.640]   Someday, all typewriters will work like the IBM Selectric.
[01:56:33.640 --> 01:56:37.400]   Someday, all typewriters will be on the trash heap of history.
[01:56:37.400 --> 01:56:42.360]   Or in the lobby of the Craig No Mark Graduate School of Journalism.
[01:56:43.400 --> 01:56:49.320]   I was a typewriter fetishist when I was in high school and college.
[01:56:49.320 --> 01:56:52.760]   That was like, that was instead of computers and smartphones.
[01:56:52.760 --> 01:56:54.280]   That was your tool, right?
[01:56:54.280 --> 01:56:54.760]   Yeah.
[01:56:54.760 --> 01:56:56.600]   I was a good typist.
[01:56:56.600 --> 01:57:00.600]   So, I ended up at three in the morning typing papers for other students.
[01:57:00.600 --> 01:57:01.480]   Because I was a schmuck.
[01:57:01.480 --> 01:57:03.560]   Did they pay you?
[01:57:03.560 --> 01:57:04.680]   Oh, man.
[01:57:04.680 --> 01:57:05.800]   I did that in college.
[01:57:05.800 --> 01:57:06.200]   Just, basically.
[01:57:06.200 --> 01:57:08.360]   It wasn't for, it wasn't a typewriter.
[01:57:08.360 --> 01:57:09.720]   It was going to the computer lab.
[01:57:09.720 --> 01:57:12.600]   But none of my football teammates knew how to type.
[01:57:12.600 --> 01:57:15.800]   So, you're a buddy.
[01:57:15.800 --> 01:57:16.840]   I see a smarter nightmare.
[01:57:16.840 --> 01:57:18.120]   Yeah, he's smart.
[01:57:18.120 --> 01:57:19.640]   He's like, I'm a socialist.
[01:57:19.640 --> 01:57:30.440]   Somebody posted this story about the telegram messenger being used in Belarus
[01:57:30.440 --> 01:57:33.320]   during the protests over the election.
[01:57:33.320 --> 01:57:37.400]   And so, what they said, and what's fast made about it, was that,
[01:57:37.400 --> 01:57:40.680]   at one point in the demonstration, there's no microphones, there's no power,
[01:57:40.680 --> 01:57:43.800]   there's nothing but suddenly everybody does the same thing.
[01:57:43.800 --> 01:57:44.680]   They all leave.
[01:57:44.680 --> 01:57:45.960]   They all do this.
[01:57:45.960 --> 01:57:47.560]   Because they're all getting the same messages on telegram.
[01:57:47.560 --> 01:57:49.240]   That's really interesting.
[01:57:49.240 --> 01:57:50.120]   We've seen this before.
[01:57:50.120 --> 01:57:51.160]   We saw it in Hong Kong.
[01:57:51.160 --> 01:57:53.320]   But it's really interesting.
[01:57:53.320 --> 01:57:56.360]   And it's very difficult for the authorities to stop.
[01:57:56.360 --> 01:57:57.800]   Yeah, telegram is encrypted.
[01:57:57.800 --> 01:58:00.200]   I actually really like telegram.
[01:58:00.200 --> 01:58:04.520]   It's not an open source crypto.
[01:58:04.520 --> 01:58:07.080]   So, it's not necessarily as safe as signals say.
[01:58:07.080 --> 01:58:08.440]   But I like it.
[01:58:08.440 --> 01:58:09.720]   I really like using it.
[01:58:09.720 --> 01:58:11.320]   And you know what?
[01:58:11.320 --> 01:58:16.040]   Obviously, this worked because if the Belarus authorities could figure out
[01:58:16.040 --> 01:58:18.040]   how to get these guys, they probably would.
[01:58:18.040 --> 01:58:19.080]   Yeah.
[01:58:19.080 --> 01:58:20.600]   Wow.
[01:58:20.600 --> 01:58:24.600]   Yeah, telegram's really a nice messaging app.
[01:58:24.600 --> 01:58:25.400]   I really like it.
[01:58:25.400 --> 01:58:27.480]   All right, let's say what?
[01:58:27.480 --> 01:58:29.320]   Who owns it?
[01:58:29.320 --> 01:58:32.120]   So, the story is interesting because it was the,
[01:58:32.120 --> 01:58:34.360]   they called him the Mark Zuckerberg of Russia.
[01:58:36.360 --> 01:58:37.480]   And his name is Pafel.
[01:58:37.480 --> 01:58:39.960]   I can't remember his last name.
[01:58:39.960 --> 01:58:40.520]   Doraov.
[01:58:40.520 --> 01:58:41.400]   Doraov, that's it.
[01:58:41.400 --> 01:58:45.800]   And he was a Russian national created telegram.
[01:58:45.800 --> 01:58:48.120]   Was very successful.
[01:58:48.120 --> 01:58:50.200]   Before that, he created Bikon Tacht.
[01:58:50.200 --> 01:58:52.760]   Which was the actual Facebook of Russia.
[01:58:52.760 --> 01:58:53.160]   Yeah.
[01:58:53.160 --> 01:58:53.480]   Yeah.
[01:58:53.480 --> 01:58:55.000]   And then he had to leave the country
[01:58:55.000 --> 01:58:56.680]   because they tried to take it over and they took it over.
[01:58:56.680 --> 01:58:58.680]   Well, that's what happened is he didn't want to sell it.
[01:58:58.680 --> 01:59:01.560]   But Putin's government insisted.
[01:59:01.560 --> 01:59:06.200]   And in fact, he was involved in a standoff with police in St.
[01:59:06.200 --> 01:59:07.000]   Petersburg.
[01:59:07.000 --> 01:59:12.200]   So he was, he left the country.
[01:59:12.200 --> 01:59:14.040]   He fled Russia.
[01:59:14.040 --> 01:59:14.600]   He's a fighting.
[01:59:14.600 --> 01:59:14.840]   Yeah.
[01:59:14.840 --> 01:59:21.640]   And after leaving Russia, he got citizenship at St.
[01:59:21.640 --> 01:59:24.680]   Kitts and Nevis by donating a quarter of a million dollars
[01:59:24.680 --> 01:59:28.440]   to the Sugar Industry Diversification Foundation.
[01:59:28.440 --> 01:59:30.520]   Hey, if that's all it costs, I'm on my way.
[01:59:30.520 --> 01:59:35.400]   And he'll diversify into extortion.
[01:59:35.400 --> 01:59:35.800]   Sugar.
[01:59:35.800 --> 01:59:36.600]   Yeah.
[01:59:36.600 --> 01:59:41.800]   And then he formed telegram, which was originally based in Berlin.
[01:59:41.800 --> 01:59:46.120]   They flirted with a cryptocurrency for a while,
[01:59:46.120 --> 01:59:48.120]   which thank goodness they kind of dumped.
[01:59:48.120 --> 01:59:50.120]   The tonned platform.
[01:59:50.120 --> 01:59:52.600]   They raised money from Steve Jobs,
[01:59:52.600 --> 01:59:54.200]   widow, Lorraine Powell Jobs.
[01:59:54.200 --> 01:59:56.280]   Federal courts halted those.
[01:59:56.280 --> 02:00:00.680]   He's described, self-described as a libertarian and a vegetarian.
[02:00:00.680 --> 02:00:05.160]   But yeah, he and so he's an interesting
[02:00:05.720 --> 02:00:06.120]   fella.
[02:00:06.120 --> 02:00:07.800]   It's an interesting story.
[02:00:07.800 --> 02:00:08.120]   Yes.
[02:00:08.120 --> 02:00:08.600]   He's very interesting.
[02:00:08.600 --> 02:00:11.080]   I don't know if I fully trust it or not.
[02:00:11.080 --> 02:00:11.880]   I really don't.
[02:00:11.880 --> 02:00:15.960]   But it is a great messaging platform.
[02:00:15.960 --> 02:00:20.040]   If he used an open source, well-known messaging algorithm,
[02:00:20.040 --> 02:00:22.840]   I'd jump on it in a heart because I really like it.
[02:00:22.840 --> 02:00:25.080]   But I just don't know if I can trust it.
[02:00:25.080 --> 02:00:27.640]   Not that anything I'm messaging is anything important.
[02:00:27.640 --> 02:00:28.760]   Well, you don't trust anything.
[02:00:28.760 --> 02:00:31.560]   I trust you, Jeff Jarvis.
[02:00:33.800 --> 02:00:35.080]   Napster has been acquired.
[02:00:35.080 --> 02:00:37.640]   What?
[02:00:37.640 --> 02:00:38.360]   Remember Napster?
[02:00:38.360 --> 02:00:40.040]   Are you all you guys old enough to remember Napster?
[02:00:40.040 --> 02:00:40.440]   Oh, yeah.
[02:00:40.440 --> 02:00:40.840]   Yeah.
[02:00:40.840 --> 02:00:43.160]   That's where old Napster remembered Napster.
[02:00:43.160 --> 02:00:44.040]   Yes, Jeff.
[02:00:44.040 --> 02:00:46.440]   It's just barely though.
[02:00:46.440 --> 02:00:47.400]   70 million dollars.
[02:00:47.400 --> 02:00:50.200]   Napster was owned most recently by Real Networks.
[02:00:50.200 --> 02:00:51.400]   Did you know that?
[02:00:51.400 --> 02:00:52.120]   I didn't know that.
[02:00:52.120 --> 02:00:55.400]   Are you old enough to know that everybody hated Real Networks?
[02:00:55.400 --> 02:00:55.960]   Everybody.
[02:00:55.960 --> 02:00:57.560]   Real player.
[02:00:57.560 --> 02:00:58.920]   Yeah, real player.
[02:00:58.920 --> 02:00:59.400]   Real player.
[02:01:01.320 --> 02:01:03.480]   Also being any of the DRM dramas.
[02:01:03.480 --> 02:01:04.680]   Yeah.
[02:01:04.680 --> 02:01:09.800]   Actually, Rob Glazier was a classmate at Yale,
[02:01:09.800 --> 02:01:12.920]   and I've served on some committees with him.
[02:01:12.920 --> 02:01:13.560]   He's a nice guy.
[02:01:13.560 --> 02:01:14.360]   I like him a lot.
[02:01:14.360 --> 02:01:18.440]   But he said the company was grateful for the hard work
[02:01:18.440 --> 02:01:22.600]   by the entire Napster team to keep the torch alive all these years.
[02:01:22.600 --> 02:01:25.480]   Sold it for surprisingly a lot of money.
[02:01:25.480 --> 02:01:30.520]   70 million dollars to a VR experience company, Melody VR.
[02:01:31.320 --> 02:01:35.080]   It was 44 million dollars in debt, mostly in music industry companies.
[02:01:35.080 --> 02:01:38.840]   And they're going to use Napster to establish quote,
[02:01:38.840 --> 02:01:42.520]   "An entertainment platform that spans immersive live performances
[02:01:42.520 --> 02:01:44.040]   and recording music streaming."
[02:01:44.040 --> 02:01:46.120]   I like it that people are still coming up with ideas.
[02:01:46.120 --> 02:01:48.280]   Trying to do something different.
[02:01:48.280 --> 02:01:50.680]   Now's the time.
[02:01:50.680 --> 02:01:51.960]   Yeah.
[02:01:51.960 --> 02:01:55.320]   This is the time to do concerts you don't have to go to.
[02:01:55.320 --> 02:01:56.600]   Things like that.
[02:01:56.600 --> 02:01:58.200]   All right.
[02:01:58.200 --> 02:01:59.240]   She don't have to go to.
[02:01:59.240 --> 02:02:00.040]   Coming up next.
[02:02:00.440 --> 02:02:01.480]   Get them ready.
[02:02:01.480 --> 02:02:04.200]   It's time for your picks of the week.
[02:02:04.200 --> 02:02:10.600]   Let's start those picks of the week with Stacy Yegembotham.
[02:02:10.600 --> 02:02:13.400]   Is it time?
[02:02:13.400 --> 02:02:13.640]   Yep.
[02:02:13.640 --> 02:02:14.840]   Oh, okay.
[02:02:14.840 --> 02:02:17.240]   I was like, I was not prepared for this.
[02:02:17.240 --> 02:02:18.520]   Yes, you are.
[02:02:18.520 --> 02:02:19.560]   You have a good pick.
[02:02:19.560 --> 02:02:21.480]   Is an app.
[02:02:21.480 --> 02:02:24.040]   I actually wrote about it last week in the newsletter.
[02:02:24.040 --> 02:02:27.080]   So this may be not news to everyone, but it's a good app.
[02:02:27.080 --> 02:02:28.040]   It's called Smores Up.
[02:02:28.840 --> 02:02:30.200]   It is a chore app.
[02:02:30.200 --> 02:02:35.640]   And I wrote about it because they connected it to Bosch dishwashers.
[02:02:35.640 --> 02:02:37.560]   So if you're connected dishwasher,
[02:02:37.560 --> 02:02:39.880]   if you have this app and a connected dishwasher,
[02:02:39.880 --> 02:02:41.160]   your dishwasher can actually,
[02:02:41.160 --> 02:02:42.920]   when it's done working,
[02:02:42.920 --> 02:02:45.560]   it will assign the chore to whichever kid does your dishes.
[02:02:45.560 --> 02:02:47.400]   Time to empty the dishwasher.
[02:02:47.400 --> 02:02:51.080]   But even if you don't have any of those things,
[02:02:51.080 --> 02:02:52.680]   because that's probably like 10 people,
[02:02:52.680 --> 02:02:55.640]   it's actually really handy for,
[02:02:57.560 --> 02:02:58.920]   especially in the pandemic.
[02:02:58.920 --> 02:03:02.600]   Like I feel like I'm constantly just telling my child,
[02:03:02.600 --> 02:03:04.760]   like be here, do this.
[02:03:04.760 --> 02:03:07.080]   Did you do this?
[02:03:07.080 --> 02:03:08.520]   You know, there's a lot more nagging.
[02:03:08.520 --> 02:03:09.400]   You want to be a nag, yeah.
[02:03:09.400 --> 02:03:12.040]   And it's not necessarily nagging.
[02:03:12.040 --> 02:03:14.120]   It's just, you know, these things need to be done.
[02:03:14.120 --> 02:03:14.520]   Mommy.
[02:03:14.520 --> 02:03:17.240]   Or parenting.
[02:03:17.240 --> 02:03:17.960]   Yes.
[02:03:17.960 --> 02:03:18.440]   Yes.
[02:03:18.440 --> 02:03:19.320]   As we call it.
[02:03:19.320 --> 02:03:21.000]   No, I just asked you to go bomb.
[02:03:21.000 --> 02:03:21.400]   Yes.
[02:03:21.400 --> 02:03:21.800]   True.
[02:03:21.800 --> 02:03:21.800]   True.
[02:03:21.800 --> 02:03:22.440]   Yes.
[02:03:22.440 --> 02:03:27.320]   But this app actually takes
[02:03:27.320 --> 02:03:28.440]   some of that off your plate.
[02:03:28.440 --> 02:03:30.200]   And it helps incentivize kids.
[02:03:30.200 --> 02:03:33.000]   If your kid, my kid is not super money motivated,
[02:03:33.000 --> 02:03:37.240]   but you give, you can assign chores, token values.
[02:03:37.240 --> 02:03:38.520]   And they get enough tokens.
[02:03:38.520 --> 02:03:39.800]   They can save some of it.
[02:03:39.800 --> 02:03:42.040]   They can apply it towards things.
[02:03:42.040 --> 02:03:44.120]   It's a nice app.
[02:03:44.120 --> 02:03:45.880]   And there's like calendaring features.
[02:03:45.880 --> 02:03:47.240]   I think if you have more kids,
[02:03:47.240 --> 02:03:48.840]   it's probably more useful because,
[02:03:48.840 --> 02:03:52.120]   I don't know, my brother and I used to have like these
[02:03:52.120 --> 02:03:55.720]   complicated monopoly style negotiations over
[02:03:55.720 --> 02:03:57.640]   who did what's sure on what day.
[02:03:57.640 --> 02:04:02.120]   And, you know, I would trade two dishwasher unloadings for
[02:04:02.120 --> 02:04:03.400]   one folding the laundry.
[02:04:03.400 --> 02:04:04.840]   Artal.
[02:04:04.840 --> 02:04:08.040]   You know, all of this happens in the app.
[02:04:08.040 --> 02:04:11.080]   And you don't have to like mediate it or deal with it
[02:04:11.080 --> 02:04:12.520]   unless it doesn't get done.
[02:04:12.520 --> 02:04:15.000]   And then the app's like, yo, this didn't happen.
[02:04:15.000 --> 02:04:17.960]   You can set like times for something to have happened by.
[02:04:17.960 --> 02:04:20.280]   And it'll be like, hey, it's four o'clock.
[02:04:20.280 --> 02:04:21.400]   No one walked the dog.
[02:04:21.400 --> 02:04:21.960]   This is cool.
[02:04:21.960 --> 02:04:23.320]   And yeah.
[02:04:23.320 --> 02:04:24.920]   So I'm going to make this my app cap
[02:04:24.920 --> 02:04:29.160]   on Iowa today, I think, because I don't have any occasion to use it.
[02:04:29.160 --> 02:04:31.560]   Actually, Lisa probably would like to use it with me.
[02:04:31.560 --> 02:04:35.080]   You could actually, I mean, you can do that.
[02:04:35.080 --> 02:04:36.600]   I could see that.
[02:04:36.600 --> 02:04:37.560]   I can totally see that.
[02:04:37.560 --> 02:04:40.200]   And you could actually do it for yourself if you wanted to.
[02:04:40.200 --> 02:04:42.120]   I mean, like, I just got a chore reminder.
[02:04:42.120 --> 02:04:45.880]   Take chore, chore, take pet for a walk, assign to,
[02:04:45.880 --> 02:04:47.240]   oh, it's assigned to me.
[02:04:47.240 --> 02:04:49.640]   But it is my job.
[02:04:49.640 --> 02:04:50.520]   That's fair.
[02:04:50.520 --> 02:04:51.400]   Go afternoon.
[02:04:51.400 --> 02:04:51.640]   You got it.
[02:04:51.640 --> 02:04:53.240]   So, but this way it's fair, right?
[02:04:53.240 --> 02:04:53.960]   Yeah.
[02:04:54.600 --> 02:04:57.560]   75 days or 750 chores free.
[02:04:57.560 --> 02:05:01.960]   So the free version is actually quite nice, I will say.
[02:05:01.960 --> 02:05:06.600]   You might want the premium version if you have a larger family.
[02:05:06.600 --> 02:05:11.560]   And I talked to the founders and they are not taking data on your child.
[02:05:11.560 --> 02:05:14.840]   They're not pulling any personally identifiable data on any of this.
[02:05:14.840 --> 02:05:19.080]   I actually told them I as a parent would be interested in like aggregate data on like,
[02:05:19.080 --> 02:05:22.760]   at what age do kids start making their bed every day?
[02:05:22.760 --> 02:05:23.080]   Yeah.
[02:05:23.080 --> 02:05:24.360]   You know, that'd be kind of fun.
[02:05:24.360 --> 02:05:25.240]   But they don't do any of that.
[02:05:25.240 --> 02:05:25.640]   I know.
[02:05:25.640 --> 02:05:26.760]   Oh.
[02:05:26.760 --> 02:05:29.000]   I just, you know, you know how parents love to like,
[02:05:29.000 --> 02:05:30.200]   and a spark.
[02:05:30.200 --> 02:05:31.240]   Are my kids normal?
[02:05:31.240 --> 02:05:31.640]   Exactly.
[02:05:31.640 --> 02:05:31.800]   Yeah.
[02:05:31.800 --> 02:05:34.440]   Or more like, is it good parents?
[02:05:34.440 --> 02:05:37.480]   I expect my child to do this at the age of 14.
[02:05:37.480 --> 02:05:37.720]   Yeah.
[02:05:37.720 --> 02:05:39.080]   No, that's a good question.
[02:05:39.080 --> 02:05:39.480]   Yeah.
[02:05:39.480 --> 02:05:40.520]   Yeah, yeah, yeah.
[02:05:40.520 --> 02:05:44.760]   I like this s'moresup, S-M-O-R-E-S-U-P.com,
[02:05:44.760 --> 02:05:47.240]   Android, iOS, and Amazon.
[02:05:47.240 --> 02:05:49.560]   Put it on your fire.
[02:05:49.560 --> 02:05:52.280]   Jeff, do you have a number?
[02:05:53.320 --> 02:05:56.840]   Um, so a wonderful tweet I just saw when we were on the air.
[02:05:56.840 --> 02:05:59.080]   Hey guys, want to feel old?
[02:05:59.080 --> 02:06:00.920]   I'm 40.
[02:06:00.920 --> 02:06:01.640]   You're welcome.
[02:06:01.640 --> 02:06:02.680]   Signed.
[02:06:02.680 --> 02:06:03.960]   We call it Colcom.
[02:06:03.960 --> 02:06:04.920]   Oh my God.
[02:06:04.920 --> 02:06:06.120]   Wow.
[02:06:06.120 --> 02:06:09.480]   The child star of Home Alone.
[02:06:09.480 --> 02:06:11.800]   That's 40.
[02:06:11.800 --> 02:06:13.160]   Wow.
[02:06:13.160 --> 02:06:13.640]   It's 40.
[02:06:13.640 --> 02:06:16.280]   I have another one if you want.
[02:06:16.280 --> 02:06:16.840]   Sure.
[02:06:16.840 --> 02:06:18.200]   Um, this is a couple of days ago.
[02:06:18.200 --> 02:06:19.960]   So it's even more so now I didn't realize this.
[02:06:19.960 --> 02:06:21.400]   The top five companies.
[02:06:22.280 --> 02:06:24.920]   Apple, Amazon, Alphabet, Microsoft, Facebook.
[02:06:24.920 --> 02:06:27.240]   Five largest publicly traded companies in America.
[02:06:27.240 --> 02:06:30.280]   Rose, 37% in the first seven months of this year.
[02:06:30.280 --> 02:06:30.840]   Guess why?
[02:06:30.840 --> 02:06:31.560]   Because we need them.
[02:06:31.560 --> 02:06:35.960]   While other stocks fell on the S&P 500 fell combined at 6%.
[02:06:35.960 --> 02:06:38.680]   I think I mentioned this last week.
[02:06:38.680 --> 02:06:39.960]   Oh, you did.
[02:06:39.960 --> 02:06:40.200]   Okay.
[02:06:40.200 --> 02:06:40.760]   Never mind.
[02:06:40.760 --> 02:06:43.000]   By the way, thanks to McCauley-Cock.
[02:06:43.000 --> 02:06:45.640]   And here's a picture of him then and now.
[02:06:45.640 --> 02:06:49.480]   This is actually McCauley with Donald Trump in Home Alone.
[02:06:49.480 --> 02:06:51.320]   I think it was in the second one, right?
[02:06:51.320 --> 02:06:52.520]   Where he goes to New York City.
[02:06:52.520 --> 02:06:53.160]   Wait a second.
[02:06:53.160 --> 02:06:53.720]   Yeah.
[02:06:53.720 --> 02:06:56.680]   This is the part they edited out in the Canadian version.
[02:06:56.680 --> 02:06:59.640]   And now here is what McCauley-Cock looks like
[02:06:59.640 --> 02:07:01.240]   today with Donald Trump.
[02:07:01.240 --> 02:07:02.120]   So there's really...
[02:07:02.120 --> 02:07:05.320]   For those of you listening...
[02:07:05.320 --> 02:07:07.800]   That's Boris Johnson.
[02:07:07.800 --> 02:07:08.840]   That's Boris Johnson.
[02:07:08.840 --> 02:07:10.920]   And I shouldn't get credit for that.
[02:07:10.920 --> 02:07:13.880]   That's a tweet from Juan Darnayoc.
[02:07:13.880 --> 02:07:16.840]   Juan AD on Twitter.
[02:07:16.840 --> 02:07:19.960]   That's a very clever response to McCauley credit.
[02:07:19.960 --> 02:07:20.280]   Funny.
[02:07:21.000 --> 02:07:26.920]   Yeah, I tech is a huge part of this so-called...
[02:07:26.920 --> 02:07:30.840]   I didn't realize it was 20% of the total value of the market now.
[02:07:30.840 --> 02:07:31.080]   Yeah.
[02:07:31.080 --> 02:07:32.680]   Big tech.
[02:07:32.680 --> 02:07:33.320]   That's what was new to me.
[02:07:33.320 --> 02:07:33.880]   That's why you got...
[02:07:33.880 --> 02:07:37.480]   It's a challenge to regulate them because they are a driver,
[02:07:37.480 --> 02:07:39.160]   especially because of COVID.
[02:07:39.160 --> 02:07:42.520]   They are a driver of the economy right now.
[02:07:42.520 --> 02:07:44.840]   We don't know.
[02:07:44.840 --> 02:07:47.320]   Audible has been a sponsor off and on for years.
[02:07:47.320 --> 02:07:49.960]   I think we were one of the very first podcasts
[02:07:49.960 --> 02:07:51.160]   that they advertised on.
[02:07:51.160 --> 02:07:53.240]   They don't have an ad on our network.
[02:07:53.240 --> 02:07:54.920]   They haven't had one in a couple of years.
[02:07:54.920 --> 02:07:56.040]   But I still want to give them a plug.
[02:07:56.040 --> 02:07:56.600]   Ungrateful.
[02:07:56.600 --> 02:07:57.080]   Louds.
[02:07:57.080 --> 02:07:57.720]   Ungrateful.
[02:07:57.720 --> 02:07:58.040]   Louds.
[02:07:58.040 --> 02:07:59.240]   We put them on the map.
[02:07:59.240 --> 02:08:03.240]   Amazon bought pretty much every advertiser we ever had,
[02:08:03.240 --> 02:08:04.440]   including this one.
[02:08:04.440 --> 02:08:07.400]   But they have come up with a new membership plan,
[02:08:07.400 --> 02:08:09.160]   which I thought was kind of interesting.
[02:08:09.160 --> 02:08:12.520]   They call it the Audible Plus catalog.
[02:08:12.520 --> 02:08:16.040]   It's a limited catalog of about 11,000 books.
[02:08:16.040 --> 02:08:19.480]   And a lot of them read by famous people.
[02:08:20.360 --> 02:08:22.120]   And I think this is an interesting...
[02:08:22.120 --> 02:08:23.480]   It's really good.
[02:08:23.480 --> 02:08:25.160]   Last night, I was writing a new book.
[02:08:25.160 --> 02:08:25.960]   Thanks.
[02:08:25.960 --> 02:08:28.680]   Okay, both of you talked about it.
[02:08:28.680 --> 02:08:29.240]   Go ahead, Jeff.
[02:08:29.240 --> 02:08:29.720]   Sorry.
[02:08:29.720 --> 02:08:31.320]   And then Stacey.
[02:08:31.320 --> 02:08:33.240]   Stacey, go ahead.
[02:08:33.240 --> 02:08:34.680]   So last night, I was going to go ahead, Jan.
[02:08:34.680 --> 02:08:34.680]   Yeah.
[02:08:34.680 --> 02:08:36.680]   And I saw that this was there.
[02:08:36.680 --> 02:08:37.960]   And you have a limited box.
[02:08:37.960 --> 02:08:38.360]   Pick one.
[02:08:38.360 --> 02:08:39.880]   And the first one was the French Revolution,
[02:08:39.880 --> 02:08:40.680]   which I want to know more about.
[02:08:40.680 --> 02:08:41.960]   I hit it and I started listening to it.
[02:08:41.960 --> 02:08:43.800]   I didn't cost me a three-part membership.
[02:08:43.800 --> 02:08:45.320]   You have to be a subscriber,
[02:08:45.320 --> 02:08:47.480]   but I think you can do it for eight bucks a month, I think.
[02:08:48.280 --> 02:08:49.400]   And the two levels now.
[02:08:49.400 --> 02:08:50.600]   This is the higher level.
[02:08:50.600 --> 02:08:51.320]   Okay.
[02:08:51.320 --> 02:08:53.080]   Because I am a subscriber anyway.
[02:08:53.080 --> 02:08:57.400]   And so I got this as part of my membership, which is great.
[02:08:57.400 --> 02:09:01.640]   So I saw this new notification,
[02:09:01.640 --> 02:09:04.840]   but I didn't have time to dig into it to see what it was all about.
[02:09:04.840 --> 02:09:06.840]   Audible Premium Plus.
[02:09:06.840 --> 02:09:10.360]   You can listen to all you want of the Plus catalog
[02:09:10.360 --> 02:09:12.680]   on top of the credits you get as your membership.
[02:09:12.680 --> 02:09:16.360]   This is part of their plan to add podcasts.
[02:09:16.360 --> 02:09:17.880]   By the way, podcast will be a part of this,
[02:09:17.880 --> 02:09:19.240]   as well as audiobooks and originals.
[02:09:19.240 --> 02:09:21.880]   That's my understanding, though,
[02:09:21.880 --> 02:09:23.800]   that these are ad-free podcasts.
[02:09:23.800 --> 02:09:26.120]   So I don't think it would be in their catalog, unfortunately.
[02:09:26.120 --> 02:09:27.800]   Well, maybe we will.
[02:09:27.800 --> 02:09:28.680]   We're trying to make their own run.
[02:09:28.680 --> 02:09:29.400]   It's getting worse.
[02:09:29.400 --> 02:09:32.200]   But for now, that's right.
[02:09:32.200 --> 02:09:34.280]   That's right.
[02:09:34.280 --> 02:09:35.960]   Make it without them.
[02:09:35.960 --> 02:09:37.720]   They're doing a lot of the Audible originals.
[02:09:37.720 --> 02:09:38.360]   Yeah.
[02:09:38.360 --> 02:09:39.320]   You know, it's kind of unclear.
[02:09:39.320 --> 02:09:40.200]   Is that a podcast?
[02:09:40.200 --> 02:09:40.760]   What is that?
[02:09:40.760 --> 02:09:41.000]   Yeah.
[02:09:41.000 --> 02:09:41.880]   Yeah.
[02:09:41.880 --> 02:09:44.520]   But they also, I think they've started to open up
[02:09:44.520 --> 02:09:48.600]   their catalog to podcasters, as well, which is interesting.
[02:09:48.600 --> 02:09:49.240]   Absolutely.
[02:09:49.240 --> 02:09:50.360]   Stacey, what were you going to say?
[02:09:50.360 --> 02:09:51.720]   Oh, no.
[02:09:51.720 --> 02:09:54.680]   I was just going to say they have a similar kindle,
[02:09:54.680 --> 02:09:55.560]   something for reading.
[02:09:55.560 --> 02:09:57.240]   Yeah, it's like kindle unlimited, exactly.
[02:09:57.240 --> 02:09:57.560]   Yeah.
[02:09:57.560 --> 02:09:57.800]   Yeah.
[02:09:57.800 --> 02:10:01.640]   And frankly, I appreciate it because I get tired.
[02:10:01.640 --> 02:10:02.440]   My eyes get tired.
[02:10:02.440 --> 02:10:04.440]   I like to listen these days more than I like to.
[02:10:04.440 --> 02:10:06.760]   I cannot handle listening to books.
[02:10:06.760 --> 02:10:07.800]   I tried it.
[02:10:07.800 --> 02:10:11.000]   I was trying so hard, but nope, it's not working.
[02:10:11.000 --> 02:10:12.200]   You're striving too much.
[02:10:12.200 --> 02:10:13.480]   You got to stop trying.
[02:10:13.480 --> 02:10:14.040]   Yeah.
[02:10:14.040 --> 02:10:15.080]   [LAUGHTER]
[02:10:15.080 --> 02:10:16.760]   Sit back, start enjoying.
[02:10:16.760 --> 02:10:18.440]   Stop striving, Stacey.
[02:10:18.440 --> 02:10:18.600]   Stop striving.
[02:10:18.600 --> 02:10:19.560]   What do you do?
[02:10:19.560 --> 02:10:22.520]   Like, are you listening while you do something else?
[02:10:22.520 --> 02:10:24.760]   Washing the dishes, cooking, walking.
[02:10:24.760 --> 02:10:25.240]   Walking.
[02:10:25.240 --> 02:10:25.640]   Walking.
[02:10:25.640 --> 02:10:29.800]   I can't do it while I'm reading newspaper articles or something.
[02:10:29.800 --> 02:10:31.800]   But yeah, I don't commute anymore.
[02:10:31.800 --> 02:10:36.200]   So yeah, I used to get two or three hours a day listening.
[02:10:36.200 --> 02:10:36.200]   OK.
[02:10:36.200 --> 02:10:37.240]   Which is really great.
[02:10:37.240 --> 02:10:38.280]   OK.
[02:10:38.280 --> 02:10:40.520]   And what's a pick?
[02:10:40.520 --> 02:10:41.240]   Give us a pick.
[02:10:41.240 --> 02:10:45.640]   For me, as there's two picks, today has a recording this.
[02:10:45.640 --> 02:10:51.800]   DJI released a new smartphone gimbal that not much to talk about,
[02:10:51.800 --> 02:10:54.840]   except for the fact that they're making it a little bit easier to use.
[02:10:54.840 --> 02:10:56.600]   I like to see us.
[02:10:56.600 --> 02:10:59.080]   It folds down and pretty portable.
[02:10:59.080 --> 02:10:59.560]   Yeah.
[02:10:59.560 --> 02:11:04.520]   But now you get this little magnetic clip that you can just magnetically connect
[02:11:04.520 --> 02:11:10.120]   your phone to it instead of having to battle with clamps and arms and hooks and things like that.
[02:11:10.120 --> 02:11:10.360]   Yeah.
[02:11:10.360 --> 02:11:11.400]   Maggots are so cool.
[02:11:11.400 --> 02:11:11.960]   That's neat.
[02:11:11.960 --> 02:11:13.000]   Yeah.
[02:11:13.000 --> 02:11:15.240]   And it's a pretty good price at 150 bucks.
[02:11:15.240 --> 02:11:19.800]   I have two smartphone gimbals here, so I doubt I'll buy it.
[02:11:19.800 --> 02:11:24.200]   But I thought it was worth mentioning for people that are trying to start creating
[02:11:24.200 --> 02:11:25.240]   stuff while they're at home.
[02:11:25.240 --> 02:11:28.840]   I've had a couple of osmos and they do an amazing job.
[02:11:28.840 --> 02:11:29.880]   They're very smooth.
[02:11:29.880 --> 02:11:31.720]   They're really kind of incredible.
[02:11:31.720 --> 02:11:33.000]   I can't.
[02:11:33.000 --> 02:11:35.400]   The problem with gimbals is balancing.
[02:11:35.400 --> 02:11:37.880]   And so if you have a magnet, I guess it must.
[02:11:39.320 --> 02:11:40.440]   Because you have to then balance.
[02:11:40.440 --> 02:11:44.680]   I wonder how well it must be auto balancing now.
[02:11:44.680 --> 02:11:50.600]   It's got to do something because I'm with you far as balancing those things could be
[02:11:50.600 --> 02:11:51.640]   quite a task.
[02:11:51.640 --> 02:11:52.920]   It's usually a big deal.
[02:11:52.920 --> 02:11:53.640]   Yeah.
[02:11:53.640 --> 02:11:58.120]   If you're using, I've used it starting on mics on my phone, so I had to buy a counterweight
[02:11:58.120 --> 02:11:59.560]   to put on there.
[02:11:59.560 --> 02:12:01.320]   And that just made it even more challenging.
[02:12:01.320 --> 02:12:07.000]   I eventually got it to work, but it's still a bit of a pain in the butt to get started.
[02:12:07.000 --> 02:12:08.200]   Maybe I'll order this one.
[02:12:08.200 --> 02:12:10.120]   You like the G-U-N as well, right?
[02:12:10.120 --> 02:12:11.400]   Yes, sir.
[02:12:11.400 --> 02:12:11.640]   Yeah.
[02:12:11.640 --> 02:12:14.680]   You can read all about it at antpruit.com.
[02:12:14.680 --> 02:12:20.360]   It's a post on his most recent blog post, the DJI Cosmo Mobile 4.
[02:12:20.360 --> 02:12:22.520]   And you're on a podcast, I hear.
[02:12:22.520 --> 02:12:23.000]   Yes.
[02:12:23.000 --> 02:12:23.320]   Yes.
[02:12:23.320 --> 02:12:24.280]   That's my second pick.
[02:12:24.280 --> 02:12:27.400]   I was, I've been on a couple of podcasts here recently.
[02:12:27.400 --> 02:12:29.560]   And I said I'd like to share them out.
[02:12:29.560 --> 02:12:30.840]   This one was really fun.
[02:12:30.840 --> 02:12:36.760]   It was on, he shoots, he draws with Dave Clayton and Alan Hess.
[02:12:36.760 --> 02:12:42.680]   Alan Hess is a big Twit fan, big security now fans know all about you, Mr. Le Porte.
[02:12:42.680 --> 02:12:43.880]   That was all about you.
[02:12:43.880 --> 02:12:46.040]   But he loves you.
[02:12:46.040 --> 02:12:51.640]   And they allowed me to just chit chat about Twit and the things that I do.
[02:12:51.640 --> 02:12:55.800]   And it went a little bit longer than most of their episodes.
[02:12:55.800 --> 02:12:57.880]   And I really appreciate that.
[02:12:57.880 --> 02:12:59.480]   We're catching, I'm sorry.
[02:12:59.480 --> 02:13:06.200]   I felt honored to be on it and felt honored to be able to just share my philosophy on how I do
[02:13:06.200 --> 02:13:08.760]   things and why I do things the way I do it.
[02:13:08.760 --> 02:13:13.960]   I think I have met, I feel like I've met Alan Hess.
[02:13:13.960 --> 02:13:16.840]   Oh, he loves Le Porte.
[02:13:16.840 --> 02:13:23.560]   Yeah, I think he's come to visit us because he's a great concert photographer.
[02:13:23.560 --> 02:13:25.240]   So I feel like maybe I just heard.
[02:13:25.240 --> 02:13:27.800]   Concert photographer and Comic Con.
[02:13:27.800 --> 02:13:28.040]   Yeah.
[02:13:28.040 --> 02:13:29.320]   Yeah, yeah.
[02:13:29.320 --> 02:13:30.600]   Nice stuff.
[02:13:30.600 --> 02:13:32.200]   Great fun.
[02:13:32.200 --> 02:13:33.400]   Good.
[02:13:33.400 --> 02:13:34.440]   We'll have to listen to that.
[02:13:34.440 --> 02:13:36.920]   Can't wait to hear you malign me.
[02:13:36.920 --> 02:13:42.040]   I have to listen to all these to make sure that people are being nice.
[02:13:42.040 --> 02:13:47.960]   He shoots, he draws podcasts featuring Aunt Pruitt, the 17th of August edition.
[02:13:47.960 --> 02:13:53.080]   Carsten's Mask of the Week is wild.
[02:13:53.080 --> 02:14:02.360]   It's the Air Solo antimicrobial irradiation respirator, a little expensive at $120.
[02:14:03.160 --> 02:14:05.000]   Shipping begins this month.
[02:14:05.000 --> 02:14:11.640]   It's worn under your face mask and uses a patent pending system to neutralize harmful contaminants
[02:14:11.640 --> 02:14:14.040]   trapped in your cloth mask.
[02:14:14.040 --> 02:14:16.440]   It's an interesting idea.
[02:14:16.440 --> 02:14:19.960]   The decid has UVC?
[02:14:19.960 --> 02:14:22.360]   UVC LED emitters.
[02:14:22.360 --> 02:14:23.400]   Wow.
[02:14:23.400 --> 02:14:23.800]   Yes.
[02:14:23.800 --> 02:14:27.240]   John and I are getting our Kickstarter pretty soon.
[02:14:27.240 --> 02:14:27.800]   Right, John?
[02:14:27.800 --> 02:14:29.560]   Yeah.
[02:14:30.040 --> 02:14:31.080]   A $100.
[02:14:31.080 --> 02:14:32.200]   Right, John?
[02:14:32.200 --> 02:14:33.880]   A $100 Kickstarter.
[02:14:33.880 --> 02:14:41.560]   And then he also recommends that you stay safe with this alien face hugger mask.
[02:14:41.560 --> 02:14:43.960]   Oh my god.
[02:14:43.960 --> 02:14:44.760]   Do not.
[02:14:44.760 --> 02:14:45.960]   That's terrifying.
[02:14:45.960 --> 02:14:49.240]   Man, that's got Carsten Bondi written all over it.
[02:14:49.240 --> 02:14:55.080]   If you've ever played, what is that game that the face hugger comes and gets you?
[02:14:55.080 --> 02:14:57.080]   Oh man.
[02:14:57.080 --> 02:14:59.160]   It's terrifying.
[02:14:59.160 --> 02:15:05.000]   Well, this is from Alien, but it reminds me of that other game, Half Life, where the face
[02:15:05.000 --> 02:15:07.400]   hugger-- Oh yeah, Half Life come after you.
[02:15:07.400 --> 02:15:10.360]   But this is the alien face hugger.
[02:15:10.360 --> 02:15:10.680]   Wow.
[02:15:10.680 --> 02:15:15.000]   He's sold out currently, but he's going to be making more.
[02:15:15.000 --> 02:15:20.440]   He makes these by hand in his Etsy shop, but he has other nice leather stuff as well.
[02:15:20.440 --> 02:15:22.040]   Wow.
[02:15:22.040 --> 02:15:22.360]   Yeah.
[02:15:22.360 --> 02:15:25.480]   Face other hugger masks sold out.
[02:15:26.920 --> 02:15:33.240]   Because who wouldn't want a disgusting alien on your face as you walk around town?
[02:15:33.240 --> 02:15:34.280]   Who wouldn't want that?
[02:15:34.280 --> 02:15:39.320]   Carsten will appreciate the McSweeney's article from earlier this month.
[02:15:39.320 --> 02:15:42.360]   The corporation from Alien shares its reopening plan.
[02:15:42.360 --> 02:15:46.360]   And it is quite hilarious.
[02:15:46.360 --> 02:15:47.640]   Carsten, you should read it here.
[02:15:47.640 --> 02:15:48.120]   I'll stick it over.
[02:15:48.120 --> 02:15:49.640]   I love McSweeney's.
[02:15:49.640 --> 02:15:51.080]   They're doing some great humor.
[02:15:51.080 --> 02:15:53.400]   Yeah.
[02:15:53.400 --> 02:15:55.640]   I subscribe to The Quarterly Concern.
[02:15:55.640 --> 02:16:03.240]   It's really a print-- Right, but they now have an internet thing that they do also.
[02:16:03.240 --> 02:16:05.000]   Yes, yes.
[02:16:05.000 --> 02:16:07.880]   Their internet tendency is their humor.
[02:16:07.880 --> 02:16:09.240]   Internet tendency, that's it.
[02:16:09.240 --> 02:16:13.400]   They have their big stuff, but here, I think, I think it's easy.
[02:16:13.400 --> 02:16:14.920]   Oh, it's way up there.
[02:16:14.920 --> 02:16:17.560]   I'm attached to my computer.
[02:16:17.560 --> 02:16:19.400]   I can't get it, but it's up on that bookshelf.
[02:16:19.400 --> 02:16:19.640]   Nice.
[02:16:19.640 --> 02:16:21.320]   McSweeney's.net.
[02:16:22.200 --> 02:16:26.520]   Ladies and gentlemen, have we completed every portion of our allotted task?
[02:16:26.520 --> 02:16:27.240]   I think we have.
[02:16:27.240 --> 02:16:31.800]   This is the time we say goodbye to all our family.
[02:16:31.800 --> 02:16:35.640]   Stacey Higginbotham is at Stacey on IOT.com.
[02:16:35.640 --> 02:16:41.320]   Sign up for that free newsletter because it's full of great IOT information.
[02:16:41.320 --> 02:16:45.080]   Of course, she does a great podcast with Kevin Tofel, the IOT cast.
[02:16:45.080 --> 02:16:47.160]   That's also their @Gigastacey on the Twitter.
[02:16:47.160 --> 02:16:48.040]   Thank you, Stacey.
[02:16:48.040 --> 02:16:50.120]   Thank you.
[02:16:50.120 --> 02:16:54.200]   A little "Kachoe Pepe" for our friend, Jeff Jarvis.
[02:16:54.200 --> 02:16:55.960]   It's waiting for me in the freezer.
[02:16:55.960 --> 02:16:57.640]   He's got his dinner ready to go.
[02:16:57.640 --> 02:16:58.680]   He's so excited.
[02:16:58.680 --> 02:16:59.240]   Look at his face.
[02:16:59.240 --> 02:16:59.800]   Look at his face.
[02:16:59.800 --> 02:17:05.000]   The director of the Tablight Center for Entrepreneurial Journalism at the Craig Newmark
[02:17:05.000 --> 02:17:10.120]   Graduate School of Journalism at the City University of New York.
[02:17:10.120 --> 02:17:10.840]   Thank you, Jeff.
[02:17:10.840 --> 02:17:12.440]   Buzzmachine.com is his blog.
[02:17:12.440 --> 02:17:16.840]   Habermanas and Gutenberg are his personal heroes.
[02:17:16.840 --> 02:17:19.720]   It's good to see you.
[02:17:19.960 --> 02:17:20.920]   Thanks for joining us.
[02:17:20.920 --> 02:17:23.320]   Aunt Pruitt comes back every week to join us here,
[02:17:23.320 --> 02:17:26.600]   but he also is on hands-on photography and hands-on wellness.
[02:17:26.600 --> 02:17:27.640]   Two of our Twitch shows.
[02:17:27.640 --> 02:17:29.400]   Good luck and fella.
[02:17:29.400 --> 02:17:30.680]   Always nice to see you.
[02:17:30.680 --> 02:17:32.600]   Congratulations on the newest Pruitt.
[02:17:32.600 --> 02:17:34.120]   We will see you.
[02:17:34.120 --> 02:17:36.120]   Yeah, that's really cool.
[02:17:36.120 --> 02:17:36.600]   Buzzmachine.
[02:17:36.600 --> 02:17:38.600]   Is your son still in this service?
[02:17:38.600 --> 02:17:40.120]   Yes, he is.
[02:17:40.120 --> 02:17:41.480]   So he's serving our country.
[02:17:41.480 --> 02:17:42.920]   Yes, he is.
[02:17:42.920 --> 02:17:44.440]   He's being protected by Palantir.
[02:17:44.440 --> 02:17:46.680]   So that's a good one.
[02:17:46.680 --> 02:17:49.480]   We're also looking for justice for Breonna Taylor.
[02:17:49.480 --> 02:17:50.360]   Oh my god.
[02:17:50.360 --> 02:17:51.080]   Amen.
[02:17:51.080 --> 02:17:53.000]   And the newest one in Kenosha.
[02:17:53.000 --> 02:17:56.760]   And I guess there'll be no NBA playoff tonight.
[02:17:56.760 --> 02:18:01.080]   Because of boycotts from the...
[02:18:01.080 --> 02:18:02.440]   No, it's not a boycott.
[02:18:02.440 --> 02:18:03.240]   It's a strike.
[02:18:03.240 --> 02:18:03.880]   A strike.
[02:18:03.880 --> 02:18:04.440]   It's a strike.
[02:18:04.440 --> 02:18:05.000]   It's an off-boycott.
[02:18:05.000 --> 02:18:09.320]   Actually, I just tweeted this because while you were talking,
[02:18:09.320 --> 02:18:14.440]   I was actually watching this, but Kenny Smith, former player,
[02:18:14.440 --> 02:18:18.200]   walked off in the middle of his broadcast, which I thought was...
[02:18:19.080 --> 02:18:19.720]   Nice.
[02:18:19.720 --> 02:18:20.600]   I love seeing this.
[02:18:20.600 --> 02:18:21.560]   Really bold.
[02:18:21.560 --> 02:18:22.120]   Yeah.
[02:18:22.120 --> 02:18:23.880]   I was like, "Oh, you buddy."
[02:18:23.880 --> 02:18:27.560]   And then, of course, I really want to go see all of this,
[02:18:27.560 --> 02:18:28.840]   but I'm on the show.
[02:18:28.840 --> 02:18:29.560]   So I cannot.
[02:18:29.560 --> 02:18:29.800]   But...
[02:18:29.800 --> 02:18:31.560]   Jacob Blake.
[02:18:31.560 --> 02:18:33.480]   Gotta remember those names.
[02:18:33.480 --> 02:18:35.160]   Yes, they're names.
[02:18:35.160 --> 02:18:35.640]   Yeah.
[02:18:35.640 --> 02:18:38.360]   Why particularly Breonna Taylor, Ant?
[02:18:38.360 --> 02:18:43.640]   Well, she was shot in the middle of a raid in Louisville, Kentucky.
[02:18:43.640 --> 02:18:44.600]   No, no, they weren't.
[02:18:44.600 --> 02:18:45.080]   Yep.
[02:18:45.080 --> 02:18:47.880]   Gorn after her boyfriend,
[02:18:47.880 --> 02:18:52.040]   and these police officers are still out just living their lives.
[02:18:52.040 --> 02:18:52.600]   Yep.
[02:18:52.600 --> 02:18:57.480]   And we saw the Kentucky Attorney General on the Republican
[02:18:57.480 --> 02:18:59.640]   Nation Convention yesterday.
[02:18:59.640 --> 02:19:00.200]   Right.
[02:19:00.200 --> 02:19:02.680]   Who mentioned Breonna Taylor,
[02:19:02.680 --> 02:19:06.840]   without mentioning that he declined to prosecute her murderers.
[02:19:06.840 --> 02:19:07.960]   So that's interesting.
[02:19:07.960 --> 02:19:09.080]   Yep.
[02:19:09.080 --> 02:19:11.160]   Ant, sorry to...
[02:19:11.160 --> 02:19:14.520]   I have to talk about that when you have such happy news.
[02:19:14.520 --> 02:19:15.400]   Congratulations.
[02:19:15.400 --> 02:19:15.400]   Oh, no.
[02:19:15.400 --> 02:19:16.280]   It's all good.
[02:19:16.280 --> 02:19:16.840]   Yeah.
[02:19:16.840 --> 02:19:18.200]   We're just fine.
[02:19:18.200 --> 02:19:19.080]   We're just fine.
[02:19:19.080 --> 02:19:22.120]   Happy for the new grandbaby and the family
[02:19:22.120 --> 02:19:24.040]   that we'll see one of these days.
[02:19:24.040 --> 02:19:25.080]   Who knows?
[02:19:25.080 --> 02:19:26.120]   Oh, that must be hard.
[02:19:26.120 --> 02:19:27.080]   That's right.
[02:19:27.080 --> 02:19:27.720]   That's right.
[02:19:27.720 --> 02:19:28.280]   Where are they?
[02:19:28.280 --> 02:19:28.760]   Yeah.
[02:19:28.760 --> 02:19:30.040]   It's all good.
[02:19:30.040 --> 02:19:31.000]   Are they Florida?
[02:19:31.000 --> 02:19:33.320]   Oh, no, no, no, no.
[02:19:33.320 --> 02:19:35.720]   They're on the other side of the country.
[02:19:35.720 --> 02:19:36.280]   Where are they?
[02:19:36.280 --> 02:19:37.880]   You don't have to say.
[02:19:37.880 --> 02:19:38.440]   I'm not going to say.
[02:19:38.440 --> 02:19:40.120]   It's very private, which I admire.
[02:19:40.120 --> 02:19:40.760]   Yes.
[02:19:40.760 --> 02:19:41.320]   I admire that.
[02:19:41.320 --> 02:19:42.680]   You are not helping the guy.
[02:19:42.680 --> 02:19:43.800]   I'm working on him.
[02:19:43.800 --> 02:19:45.560]   Well, I have to ask the hard questions.
[02:19:45.560 --> 02:19:46.920]   I'm a trained professional.
[02:19:46.920 --> 02:19:47.560]   Oh, no, wait a minute.
[02:19:47.560 --> 02:19:49.960]   But I'm going to get poker play too.
[02:19:49.960 --> 02:19:50.680]   So I know.
[02:19:50.680 --> 02:19:50.840]   I know.
[02:19:50.840 --> 02:19:51.480]   I wasn't here.
[02:19:51.480 --> 02:19:52.440]   I'm trying to get data, though.
[02:19:52.440 --> 02:19:57.080]   Anyway, I apologize if I brought up something
[02:19:57.080 --> 02:19:58.200]   that's considered secret,
[02:19:58.200 --> 02:19:59.560]   but I'm just so happy for you.
[02:19:59.560 --> 02:20:00.280]   I think it's great.
[02:20:00.280 --> 02:20:00.840]   I appreciate it.
[02:20:00.840 --> 02:20:01.880]   It's not an excuse.
[02:20:01.880 --> 02:20:05.000]   That's the mother-in-law excuse when they...
[02:20:05.000 --> 02:20:06.680]   Do something for a whole lot.
[02:20:06.680 --> 02:20:07.160]   Okay.
[02:20:07.160 --> 02:20:08.360]   I'm his mother-in-law.
[02:20:08.360 --> 02:20:08.920]   So there.
[02:20:08.920 --> 02:20:12.440]   And if you want, we'll edit all of this out.
[02:20:12.440 --> 02:20:13.240]   Oh, we get it.
[02:20:13.240 --> 02:20:13.640]   All right.
[02:20:13.640 --> 02:20:15.000]   Thanks, everybody.
[02:20:15.000 --> 02:20:18.200]   We do this week in Google every Wednesday,
[02:20:18.200 --> 02:20:19.160]   about 1.30.
[02:20:19.160 --> 02:20:22.120]   Actually, now it's 2 p.m. Pacific, 5 p.m. Eastern.
[02:20:22.120 --> 02:20:22.600]   My fault.
[02:20:22.600 --> 02:20:24.360]   No, no, no, no, no, no, no, fall.
[02:20:24.360 --> 02:20:25.080]   We actually...
[02:20:25.080 --> 02:20:26.520]   We never run time anyway, so...
[02:20:26.520 --> 02:20:28.280]   Why not?
[02:20:28.280 --> 02:20:31.000]   2100 UTC.
[02:20:31.000 --> 02:20:32.040]   Combine, say hi.
[02:20:32.040 --> 02:20:33.080]   If you want to watch the live stream,
[02:20:33.080 --> 02:20:35.080]   it's twit.tv/live.
[02:20:35.080 --> 02:20:36.600]   There's audio and video there.
[02:20:36.600 --> 02:20:37.720]   Chatroom's always open.
[02:20:37.720 --> 02:20:39.960]   IRC.twit.tv.
[02:20:41.480 --> 02:20:44.680]   After the fact, you can get our podcasts at the website,
[02:20:44.680 --> 02:20:45.560]   twit.tv.
[02:20:45.560 --> 02:20:47.560]   For this show, it's twit.tv/twig.
[02:20:47.560 --> 02:20:49.640]   You also get it on YouTube.
[02:20:49.640 --> 02:20:51.560]   But there's a bunch of YouTube channels,
[02:20:51.560 --> 02:20:54.600]   but the main channels, youtube.com/twit.
[02:20:54.600 --> 02:20:58.760]   And let's see what else.
[02:20:58.760 --> 02:21:01.000]   Oh, subscribe in your favorite podcast application.
[02:21:01.000 --> 02:21:03.640]   That way you get it the minute it's available
[02:21:03.640 --> 02:21:06.440]   late on Wednesday.
[02:21:06.440 --> 02:21:08.040]   Thanks, everybody.
[02:21:08.040 --> 02:21:10.600]   We'll see you next time on this week in Google.
[02:21:10.600 --> 02:21:13.480]   Hi, I'm Jason Howell, host of All About Android,
[02:21:13.480 --> 02:21:15.720]   where each week I'm joined by my co-hosts,
[02:21:15.720 --> 02:21:17.960]   Florence Ion and Ron Richards.
[02:21:17.960 --> 02:21:21.000]   And we talk about everything that has to do with Android.
[02:21:21.000 --> 02:21:21.800]   Is it news?
[02:21:21.800 --> 02:21:22.840]   Is it hardware?
[02:21:22.840 --> 02:21:23.560]   Is it apps?
[02:21:23.560 --> 02:21:24.360]   Well, you name it.
[02:21:24.360 --> 02:21:25.000]   We talk about it.
[02:21:25.000 --> 02:21:27.320]   We invite guests from the industry on the show.
[02:21:27.320 --> 02:21:31.320]   We even sometimes have people from the Android team themselves
[02:21:31.320 --> 02:21:33.880]   talking about what makes Android so great.
[02:21:33.880 --> 02:21:35.880]   And you could subscribe so you don't miss anything
[02:21:35.880 --> 02:21:39.720]   about the world of Android by going to twit.tv/AA.
[02:21:39.720 --> 02:21:40.920]   We'll see you there.
[02:21:40.920 --> 02:21:50.920]   [MUSIC]
[02:21:50.920 --> 02:21:52.260]   

