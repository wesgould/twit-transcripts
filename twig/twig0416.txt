;FFMETADATA1
title=Mr. Nutter Butter Has a Message for You
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=416
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:02.000]   It's time for Twig this week at Google.
[00:00:02.000 --> 00:00:04.720]   Oh, I'm excited about this show.
[00:00:04.720 --> 00:00:05.720]   Jeff Jarvis is here.
[00:00:05.720 --> 00:00:07.480]   He's at MIT's Media Lab.
[00:00:07.480 --> 00:00:11.040]   Kevin Marks is visiting us from somewhere in North England
[00:00:11.040 --> 00:00:14.400]   and all the way from the United States Digital Service,
[00:00:14.400 --> 00:00:17.120]   Acting Administrator Matt Cuts.
[00:00:17.120 --> 00:00:20.560]   We're going to discuss the latest news from Google, Facebook,
[00:00:20.560 --> 00:00:22.080]   and the US government.
[00:00:22.080 --> 00:00:23.680]   It's all next on Twig.
[00:00:27.320 --> 00:00:29.400]   Netcasts you love.
[00:00:29.400 --> 00:00:30.800]   From people you trust.
[00:00:30.800 --> 00:00:37.040]   This is Twig.
[00:00:37.040 --> 00:00:38.840]   Bandwidth for this week in Google
[00:00:38.840 --> 00:00:43.760]   is provided by cashfly, C-A-C-H-E-F-L-Y.com.
[00:00:43.760 --> 00:00:49.880]   This is Twig.
[00:00:49.880 --> 00:00:54.240]   Episode 416 recorded Wednesday, August 2, 2017.
[00:00:54.240 --> 00:00:58.240]   Mr. Nutter Butter has a message for you.
[00:00:58.240 --> 00:01:00.720]   This week in Google is brought to you by CloudFlare.
[00:01:00.720 --> 00:01:05.000]   More than 6 million websites, apps, APIs, and SaaS companies
[00:01:05.000 --> 00:01:08.120]   use CloudFlare services to weather whatever
[00:01:08.120 --> 00:01:09.360]   the internet throws at them.
[00:01:09.360 --> 00:01:12.920]   For a free online chat session with one of CloudFlare's
[00:01:12.920 --> 00:01:20.160]   brilliant support engineers, visit cloudflare.com/twits.
[00:01:20.160 --> 00:01:21.800]   It's time for Twig this week in Google
[00:01:21.800 --> 00:01:24.400]   to show where we cover the latest news from Google
[00:01:24.400 --> 00:01:26.200]   and the Googleverse.
[00:01:26.200 --> 00:01:28.480]   And boy, do we have a panel today.
[00:01:28.480 --> 00:01:31.880]   Stacey Higginbotham still has the week off.
[00:01:31.880 --> 00:01:34.080]   I think maybe Jeff Jarvis we chased her way.
[00:01:34.080 --> 00:01:35.720]   Jeff Jarvis is here, but he's not as--
[00:01:35.720 --> 00:01:36.220]   Hey!
[00:01:36.220 --> 00:01:36.720]   Hey!
[00:01:36.720 --> 00:01:37.560]   He's not as--
[00:01:37.560 --> 00:01:39.600]   OK, you, not-- I mean me, not you.
[00:01:39.600 --> 00:01:42.200]   It was me.
[00:01:42.200 --> 00:01:44.560]   Jeff is at MIT's Media Lab.
[00:01:44.560 --> 00:01:46.440]   What are you doing there?
[00:01:46.440 --> 00:01:49.240]   I'm seeing the DeBroy of MIT and Twitter tomorrow
[00:01:49.240 --> 00:01:51.600]   for a news integrity initiative business.
[00:01:51.600 --> 00:01:54.520]   And so I came in early so I could do the show.
[00:01:54.520 --> 00:01:55.880]   So I scheduled the flight.
[00:01:55.880 --> 00:01:57.000]   You're going to hear the story now.
[00:01:57.000 --> 00:01:59.120]   I scheduled the flight so I can land at 1 o'clock.
[00:01:59.120 --> 00:02:00.000]   Nice and easy, right?
[00:02:00.000 --> 00:02:01.680]   Get over here, check in the hotel.
[00:02:01.680 --> 00:02:03.080]   Get over here, do the show.
[00:02:03.080 --> 00:02:04.320]   So I didn't take the train.
[00:02:04.320 --> 00:02:05.920]   I did everything.
[00:02:05.920 --> 00:02:07.400]   Thunderstorms in Newark.
[00:02:07.400 --> 00:02:09.360]   And we finally get up in the air.
[00:02:09.360 --> 00:02:11.760]   Thunderstorms over Boston.
[00:02:11.760 --> 00:02:14.320]   I buy the Wi-Fi for once it works.
[00:02:14.320 --> 00:02:16.360]   So I can email Carsten and say, I don't know if I want
[00:02:16.360 --> 00:02:16.840]   to make it or not.
[00:02:16.840 --> 00:02:17.840]   I don't know if I want to make it or not.
[00:02:17.840 --> 00:02:20.040]   Then I get a cabie who had no idea where he was going.
[00:02:20.040 --> 00:02:22.200]   So I'm dashing down the street.
[00:02:22.200 --> 00:02:22.840]   But I'm here.
[00:02:22.840 --> 00:02:24.480]   We started 45 minutes late.
[00:02:24.480 --> 00:02:26.160]   Bravo, Jeff Jarvis.
[00:02:26.160 --> 00:02:27.840]   Apple, which is my fault.
[00:02:27.840 --> 00:02:31.920]   I'm glad you're here because you are going to help me welcome--
[00:02:31.920 --> 00:02:33.400]   well, first let me introduce Kevin Marks
[00:02:33.400 --> 00:02:34.880]   before I welcome our special guest.
[00:02:34.880 --> 00:02:35.680]   Kevin Marks is here.
[00:02:35.680 --> 00:02:36.480]   Oh, offense, Kevin.
[00:02:36.480 --> 00:02:37.440]   You're not the special guest.
[00:02:37.440 --> 00:02:38.360]   He's pretty special.
[00:02:38.360 --> 00:02:39.000]   I'm not special, yes.
[00:02:39.000 --> 00:02:40.880]   He's the less special.
[00:02:40.880 --> 00:02:43.200]   But I think he'd agree to from indyweb.org.
[00:02:43.200 --> 00:02:45.440]   It's great to see you, Kevin, as always.
[00:02:45.440 --> 00:02:45.960]   We have many--
[00:02:45.960 --> 00:02:47.280]   This is great to see you guys, too.
[00:02:47.280 --> 00:02:49.640]   Half the time we do this show, Stacy,
[00:02:49.640 --> 00:02:51.440]   in particular, would say, well, I wonder what Kevin Marks would
[00:02:51.440 --> 00:02:52.560]   say about that.
[00:02:52.560 --> 00:02:53.720]   I miss Stacy as well.
[00:02:53.720 --> 00:02:54.920]   I'm going to say she's not here.
[00:02:54.920 --> 00:02:55.440]   Yeah.
[00:02:55.440 --> 00:02:56.600]   I'm sure we can--
[00:02:56.600 --> 00:02:58.080]   we'll find something to talk about anyway.
[00:02:58.080 --> 00:03:00.120]   We will find a few things to talk about
[00:03:00.120 --> 00:03:04.320]   because joining us for the first time in more than a year--
[00:03:04.320 --> 00:03:05.760]   Hip, hip, hooray.
[00:03:05.760 --> 00:03:09.160]   Mr. Matt Cuts of the US Digital Service.
[00:03:09.160 --> 00:03:09.720]   Hello.
[00:03:09.720 --> 00:03:10.640]   Good to see everybody.
[00:03:10.640 --> 00:03:11.480]   How are you?
[00:03:11.480 --> 00:03:14.200]   Matt has been a long time friend of the show.
[00:03:14.200 --> 00:03:18.480]   I'm proud to say, originally as the spam fighter at Google,
[00:03:18.480 --> 00:03:20.280]   one of the early employees at Google,
[00:03:20.280 --> 00:03:22.000]   and he went on leave last--
[00:03:22.000 --> 00:03:22.880]   was it last year?
[00:03:22.880 --> 00:03:24.600]   He went on leave?
[00:03:24.600 --> 00:03:26.000]   Seems like about a year ago.
[00:03:26.000 --> 00:03:28.480]   Feels like about five years ago, but--
[00:03:28.480 --> 00:03:32.680]   to go to work for the government and the US Digital
[00:03:32.680 --> 00:03:37.120]   Service, which is a really neat part of the government.
[00:03:37.120 --> 00:03:38.960]   And for a while, you were at the Pentagon
[00:03:38.960 --> 00:03:41.560]   doing secret stuff.
[00:03:41.560 --> 00:03:46.720]   Well, it's all about improving the technology in government,
[00:03:46.720 --> 00:03:48.240]   including web design.
[00:03:48.240 --> 00:03:52.720]   So for you may remember, when healthcare.gov had its troubles,
[00:03:52.720 --> 00:03:59.000]   that Silicon Valley jumped in to help revamp and make it work,
[00:03:59.000 --> 00:04:01.240]   and the USDS was born.
[00:04:01.240 --> 00:04:02.800]   And it's still--
[00:04:02.800 --> 00:04:04.600]   well, let me ask you, Matt.
[00:04:04.600 --> 00:04:07.480]   Are you still the interim administrator there?
[00:04:07.480 --> 00:04:08.560]   Yes?
[00:04:08.560 --> 00:04:09.160]   That's right.
[00:04:09.160 --> 00:04:09.520]   Yes.
[00:04:09.520 --> 00:04:12.680]   I am the acting administrator of the US Digital Service.
[00:04:12.680 --> 00:04:15.840]   And I just want to let people know that the US Digital
[00:04:15.840 --> 00:04:17.040]   Service is still here.
[00:04:17.040 --> 00:04:19.880]   We're still hiring, and we're working on important problems
[00:04:19.880 --> 00:04:21.600]   that make things better for the American people.
[00:04:21.600 --> 00:04:23.000]   Well, bravo.
[00:04:23.000 --> 00:04:24.640]   Yeah, your predecessor had to leave
[00:04:24.640 --> 00:04:26.920]   because she was a political appointee.
[00:04:26.920 --> 00:04:28.280]   That's right.
[00:04:28.280 --> 00:04:32.120]   But you're not a political appointee, apparently.
[00:04:32.120 --> 00:04:35.000]   That's the acting in the acting administrator.
[00:04:35.000 --> 00:04:37.240]   And we'll see if the administration gets
[00:04:37.240 --> 00:04:39.920]   around to appointing somebody to run the place.
[00:04:39.920 --> 00:04:42.600]   But I think it is-- and I'm very gratified to hear,
[00:04:42.600 --> 00:04:45.320]   because you wonder, is it getting funded?
[00:04:45.320 --> 00:04:47.320]   Is anything happening?
[00:04:47.320 --> 00:04:49.760]   But it sounds like you are.
[00:04:49.760 --> 00:04:50.320]   We are.
[00:04:50.320 --> 00:04:53.880]   And it's really great, because the people who needed help
[00:04:53.880 --> 00:04:55.640]   before the election still need help.
[00:04:55.640 --> 00:04:57.840]   And so the mission of the US Digital Service
[00:04:57.840 --> 00:05:01.080]   is really important, and I'm glad that there's
[00:05:01.080 --> 00:05:05.560]   a fantastic group of geeks and designers and software
[00:05:05.560 --> 00:05:08.000]   engineers, a whole bunch of people
[00:05:08.000 --> 00:05:10.640]   who are willing to make sure that the US Digital Service is
[00:05:10.640 --> 00:05:13.120]   like trying to help build important services
[00:05:13.120 --> 00:05:14.120]   and fix things that bring you.
[00:05:14.120 --> 00:05:16.280]   What are some examples these days, Matt?
[00:05:16.280 --> 00:05:17.800]   What you guys are working on?
[00:05:17.800 --> 00:05:20.360]   So one of my favorite ones is vets.gov,
[00:05:20.360 --> 00:05:23.840]   which is a place where people can discover, apply for, manage,
[00:05:23.840 --> 00:05:25.200]   and track their benefits.
[00:05:25.200 --> 00:05:28.640]   So if you are a veteran or know someone who is a veteran,
[00:05:28.640 --> 00:05:32.760]   if you've ever dealt with the GI Bill comparison tools
[00:05:32.760 --> 00:05:35.800]   or trying to sign up for health benefits,
[00:05:35.800 --> 00:05:38.360]   this is basically a one-stop shop that's
[00:05:38.360 --> 00:05:40.920]   intended to make it really easy for people to find
[00:05:40.920 --> 00:05:42.480]   and apply for different benefits.
[00:05:42.480 --> 00:05:43.560]   And I just want to point out, did you
[00:05:43.560 --> 00:05:45.440]   see how fast that site loaded?
[00:05:45.440 --> 00:05:46.200]   Let me do it again.
[00:05:46.200 --> 00:05:47.680]   Watch this.
[00:05:47.680 --> 00:05:49.200]   This is no health care.gov.
[00:05:49.200 --> 00:05:52.160]   This thing is loads faster than any website I've ever been on.
[00:05:52.160 --> 00:05:56.840]   And I imagine that is with a little help from the USDS.
[00:05:56.840 --> 00:05:59.000]   We power a lot of that site.
[00:05:59.000 --> 00:05:59.960]   Yes.
[00:05:59.960 --> 00:06:01.640]   It's a fantastic service.
[00:06:01.640 --> 00:06:03.640]   That's really, really good job.
[00:06:03.640 --> 00:06:05.760]   I'm just thrilled to have you back on.
[00:06:05.760 --> 00:06:06.680]   Now, are there limits?
[00:06:06.680 --> 00:06:10.200]   Tell me ahead of time of things we can ask you.
[00:06:10.200 --> 00:06:13.520]   Well, if something gets too close to something
[00:06:13.520 --> 00:06:17.280]   legal or something too crazy, I might recuse myself.
[00:06:17.280 --> 00:06:18.680]   You're always allowed to do that.
[00:06:18.680 --> 00:06:21.280]   But really, what's that Larry Page like, really?
[00:06:21.280 --> 00:06:23.120]   No, I'm just kidding.
[00:06:23.120 --> 00:06:25.120]   [LAUGHTER]
[00:06:25.120 --> 00:06:26.000]   He's a great guy.
[00:06:26.000 --> 00:06:29.480]   Now you can tell us.
[00:06:29.480 --> 00:06:32.120]   Actually, we could talk a little bit about Alphabet
[00:06:32.120 --> 00:06:34.880]   because their quarterly results came out.
[00:06:34.880 --> 00:06:38.280]   The stock went down, but I have no idea why,
[00:06:38.280 --> 00:06:40.480]   because Alphabet's numbers were excellent.
[00:06:40.480 --> 00:06:43.600]   Well, I guess what people are saying
[00:06:43.600 --> 00:06:49.280]   is it's more about the guidance Alphabet gave about the future.
[00:06:49.280 --> 00:06:54.240]   And the fact that net revenue growth has gone down a little bit.
[00:06:54.240 --> 00:06:59.400]   But it's not like they're not doing really, really well.
[00:06:59.400 --> 00:07:02.560]   Net revenue for the ad business was up 16%
[00:07:02.560 --> 00:07:04.080]   during the second quarter.
[00:07:04.080 --> 00:07:07.080]   So it was up 20% last year.
[00:07:07.080 --> 00:07:12.080]   So the growth is still there just slowing.
[00:07:12.080 --> 00:07:15.640]   But some analysts call that a meaningful deceleration.
[00:07:15.640 --> 00:07:17.920]   Net income profit, in other words,
[00:07:17.920 --> 00:07:22.400]   was so big that even after subtracting $2.7 billion
[00:07:22.400 --> 00:07:28.880]   for the EU fine, Alphabet still made $3.5 billion.
[00:07:28.880 --> 00:07:31.440]   So that's down, but that's because of the fine.
[00:07:31.440 --> 00:07:34.440]   If you add the two together, they made $6.2 billion.
[00:07:34.440 --> 00:07:36.000]   They aren't necessarily paying the fine.
[00:07:36.000 --> 00:07:37.560]   That's just a hold in advance.
[00:07:37.560 --> 00:07:38.960]   Right.
[00:07:38.960 --> 00:07:43.080]   They have almost $95 billion in cash.
[00:07:43.080 --> 00:07:44.600]   Headcount went up.
[00:07:44.600 --> 00:07:46.040]   Almost 10,000 people.
[00:07:46.040 --> 00:07:47.680]   That's significant.
[00:07:47.680 --> 00:07:53.600]   This is maybe one issue, which is cost per click down 26%.
[00:07:53.600 --> 00:07:57.360]   Paid clicks, though, made up for it because they got more--
[00:07:57.360 --> 00:07:59.720]   they sold more ads, even though the value of each ad
[00:07:59.720 --> 00:08:01.120]   was down 26%.
[00:08:01.120 --> 00:08:05.360]   They sold 61% more ads.
[00:08:05.360 --> 00:08:07.680]   Paid clicks were up 61%.
[00:08:07.680 --> 00:08:09.080]   Revenues for other bets.
[00:08:09.080 --> 00:08:12.120]   That's Waymo, that's Nest, that's the life sciences,
[00:08:12.120 --> 00:08:14.680]   Verily, and so forth.
[00:08:14.680 --> 00:08:18.720]   $248 million, but they lost $3.25 billion on other bets.
[00:08:18.720 --> 00:08:19.880]   But that's what you kind of expect.
[00:08:19.880 --> 00:08:25.520]   Other bets means that stuff we're going to R&D, basically.
[00:08:25.520 --> 00:08:26.520]   The little future.
[00:08:26.520 --> 00:08:28.960]   And Sundar Pichai, the CEO of Google,
[00:08:28.960 --> 00:08:30.240]   has been added to the board.
[00:08:30.240 --> 00:08:31.240]   It's 13th.
[00:08:31.240 --> 00:08:32.560]   Oh.
[00:08:32.560 --> 00:08:34.200]   So--
[00:08:34.200 --> 00:08:35.480]   Well, that makes a lot of sense.
[00:08:35.480 --> 00:08:37.160]   Sure does.
[00:08:37.160 --> 00:08:39.720]   Sundar's rise has been somewhat meteoric, though.
[00:08:39.720 --> 00:08:40.880]   I have to say.
[00:08:40.880 --> 00:08:45.080]   I met him when he was head of Chrome OS.
[00:08:45.080 --> 00:08:47.400]   And that wasn't sold very long ago.
[00:08:47.400 --> 00:08:49.000]   I'd argued with him.
[00:08:49.000 --> 00:08:51.400]   Now let's not bring that up.
[00:08:51.400 --> 00:08:54.880]   I was wrong, and I admit it.
[00:08:54.880 --> 00:08:57.240]   Because I thought, who's going to-- this
[00:08:57.240 --> 00:08:59.080]   was back when it was that black Chromebook.
[00:08:59.080 --> 00:09:01.600]   I remember that everybody got the--
[00:09:01.600 --> 00:09:02.440]   CR48?
[00:09:02.440 --> 00:09:02.960]   CR48?
[00:09:02.960 --> 00:09:04.600]   CR48, the preliminary.
[00:09:04.600 --> 00:09:06.120]   And I said, why would anybody want this?
[00:09:06.120 --> 00:09:07.720]   It's just a browser.
[00:09:07.720 --> 00:09:09.080]   What was I wrong?
[00:09:09.080 --> 00:09:10.200]   Well, can I computer reuse?
[00:09:10.200 --> 00:09:12.000]   I didn't know.
[00:09:12.000 --> 00:09:13.000]   At the time, it was early.
[00:09:13.000 --> 00:09:14.040]   Yeah, matter--
[00:09:14.040 --> 00:09:15.040]   Yeah.
[00:09:15.040 --> 00:09:16.960]   Do you get a government issue PC?
[00:09:16.960 --> 00:09:18.120]   Oh, I can only imagine.
[00:09:18.120 --> 00:09:18.920]   I do.
[00:09:18.920 --> 00:09:20.840]   It's a lot like the CR48, for you.
[00:09:20.840 --> 00:09:22.480]   Yeah, it is.
[00:09:22.480 --> 00:09:23.440]   Yeah.
[00:09:23.440 --> 00:09:27.000]   But you get to have your own system, I'm sure.
[00:09:27.000 --> 00:09:27.360]   Yeah.
[00:09:27.360 --> 00:09:28.280]   But it was interesting.
[00:09:28.280 --> 00:09:30.240]   Because I remember-- I think it was at a holiday party.
[00:09:30.240 --> 00:09:31.400]   I think I got to see you.
[00:09:31.400 --> 00:09:31.880]   I was there.
[00:09:31.880 --> 00:09:32.840]   You're exactly right.
[00:09:32.840 --> 00:09:33.200]   We--
[00:09:33.200 --> 00:09:33.200]   We--
[00:09:33.200 --> 00:09:33.720]   We--
[00:09:33.720 --> 00:09:34.720]   We--
[00:09:34.720 --> 00:09:35.720]   We--
[00:09:35.720 --> 00:09:36.720]   And you were right at the time.
[00:09:36.720 --> 00:09:37.720]   Like Chrome OS couldn't do that much.
[00:09:37.720 --> 00:09:39.920]   And there were a lot of apps that people were using.
[00:09:39.920 --> 00:09:41.680]   But he saw the long-term vision.
[00:09:41.680 --> 00:09:44.800]   And really, I mean, there's no doubt
[00:09:44.800 --> 00:09:47.480]   that this is a huge success, Chrome OS.
[00:09:47.480 --> 00:09:50.960]   As it's matured, but also has been embraced by education,
[00:09:50.960 --> 00:09:51.800]   I use it.
[00:09:51.800 --> 00:09:56.560]   I've purchased since then five or six Chromebooks.
[00:09:56.560 --> 00:09:57.560]   So--
[00:09:57.560 --> 00:09:58.560]   I like it.
[00:09:58.560 --> 00:10:03.000]   I just got my daughter a new Samsung Pro.
[00:10:03.000 --> 00:10:04.920]   I mean, plus.
[00:10:04.920 --> 00:10:05.420]   Plus.
[00:10:05.420 --> 00:10:07.400]   I gave my daughter a plus to your school for college.
[00:10:07.400 --> 00:10:08.000]   She loves it.
[00:10:08.000 --> 00:10:08.320]   Yep.
[00:10:08.320 --> 00:10:09.000]   She loves it.
[00:10:09.000 --> 00:10:09.680]   Yeah.
[00:10:09.680 --> 00:10:12.360]   She had that-- I had given her my own pixel.
[00:10:12.360 --> 00:10:14.200]   And I said, maybe you'll like the plus better,
[00:10:14.200 --> 00:10:14.880]   because it's a lot lighter.
[00:10:14.880 --> 00:10:15.800]   And she does.
[00:10:15.800 --> 00:10:18.200]   And she's-- you know, so--
[00:10:18.200 --> 00:10:19.200]   there you go.
[00:10:19.200 --> 00:10:21.120]   It's also a lot less expensive.
[00:10:21.120 --> 00:10:25.760]   Now, this is a good time, perhaps, to bring up Project Eve.
[00:10:25.760 --> 00:10:27.080]   What do you know about Project Eve?
[00:10:27.080 --> 00:10:29.600]   Matt, I know nothing.
[00:10:29.600 --> 00:10:31.600]   Nothing.
[00:10:31.600 --> 00:10:32.920]   Nothing.
[00:10:32.920 --> 00:10:35.280]   So this is the rumored Chromebook.
[00:10:35.280 --> 00:10:37.880]   We talked a little bit about this last week, I think.
[00:10:37.880 --> 00:10:38.920]   Didn't we, Jeff?
[00:10:38.920 --> 00:10:39.560]   Yeah, we did a bit.
[00:10:39.560 --> 00:10:40.060]   Yeah.
[00:10:40.060 --> 00:10:41.480]   So there's nothing more to say about that.
[00:10:41.480 --> 00:10:45.040]   It's just that I feel like we're getting closer and closer.
[00:10:45.040 --> 00:10:46.080]   There's got to be an announcement.
[00:10:46.080 --> 00:10:47.000]   I hope so.
[00:10:47.000 --> 00:10:48.360]   Yeah.
[00:10:48.360 --> 00:10:50.080]   Because we want-- we want to have a successor
[00:10:50.080 --> 00:10:52.360]   to the Chromebook pixel, which we loved.
[00:10:52.360 --> 00:10:53.200]   Yeah.
[00:10:53.200 --> 00:10:53.700]   All right.
[00:10:53.700 --> 00:10:56.520]   I guess I don't need to bring up Project Eve.
[00:10:56.520 --> 00:10:58.640]   I already done "Brunge It Up."
[00:10:58.640 --> 00:10:59.720]   Well, I mean, there is the weird thing
[00:10:59.720 --> 00:11:01.160]   that the Chromebook pixel is still actually
[00:11:01.160 --> 00:11:02.560]   quite usable machine, which is--
[00:11:02.560 --> 00:11:03.880]   Absolutely.
[00:11:03.880 --> 00:11:05.720]   It was over-- it was over designed.
[00:11:05.720 --> 00:11:08.080]   Three and a half years ago.
[00:11:08.080 --> 00:11:09.560]   Well, there's two things going on there.
[00:11:09.560 --> 00:11:10.880]   One is that it was over designed.
[00:11:10.880 --> 00:11:14.160]   The other is we've grown to the flat part of Moore's Law
[00:11:14.160 --> 00:11:17.200]   and things haven't been growing expansion.
[00:11:17.200 --> 00:11:19.440]   That's really true, yeah.
[00:11:19.440 --> 00:11:21.080]   Yeah, your five-year-old computer
[00:11:21.080 --> 00:11:23.880]   is probably just as fast as it was.
[00:11:23.880 --> 00:11:25.720]   The biggest change I think is the last five years--
[00:11:25.720 --> 00:11:30.120]   Moore's Law doesn't affect us at the PC level as much anymore,
[00:11:30.120 --> 00:11:35.120]   but doesn't it affect other areas, AI and such?
[00:11:35.120 --> 00:11:37.280]   IoT.
[00:11:37.280 --> 00:11:38.800]   Well, AI has gone massively parallel.
[00:11:38.800 --> 00:11:42.400]   So they're sort of working around it by throwing more CPUs at it
[00:11:42.400 --> 00:11:46.000]   and because of their projects are massively parallelizable.
[00:11:46.000 --> 00:11:49.560]   And GPUs that-- GPUs that are on the same thing.
[00:11:49.560 --> 00:11:52.760]   IoT cares more about power consumption
[00:11:52.760 --> 00:11:55.520]   than it does about CPU processing normally.
[00:11:55.520 --> 00:11:58.400]   So the other end of Moore's-- there's
[00:11:58.400 --> 00:12:01.760]   another one that I forgot the name of, which is the amount of power
[00:12:01.760 --> 00:12:03.080]   you do the same amount of computation
[00:12:03.080 --> 00:12:05.160]   does keep going down.
[00:12:05.160 --> 00:12:07.520]   And that's basically what the chipsets have been doing
[00:12:07.520 --> 00:12:09.000]   for the last few years as well because they've
[00:12:09.000 --> 00:12:10.160]   been focusing on mobile.
[00:12:10.160 --> 00:12:13.720]   So they haven't been saying, oh, we need to keep growing
[00:12:13.720 --> 00:12:14.600]   execution speed.
[00:12:14.600 --> 00:12:16.520]   They've been saying, we need to reduce power consumption
[00:12:16.520 --> 00:12:17.520]   further.
[00:12:17.520 --> 00:12:19.200]   Can we have the voltage again?
[00:12:19.200 --> 00:12:22.880]   So that's been a big focus in chipsets over the last five
[00:12:22.880 --> 00:12:25.160]   years or so.
[00:12:25.160 --> 00:12:27.640]   And of course, PCs have sped up for other reasons.
[00:12:27.640 --> 00:12:31.960]   More RAM, cheaper RAM, faster, hard drives, SSDs
[00:12:31.960 --> 00:12:36.680]   have made a massive difference in the speeds.
[00:12:36.680 --> 00:12:41.520]   And that's mostly replacing spinning metal with silicon.
[00:12:41.520 --> 00:12:42.880]   Yeah, absolutely.
[00:12:42.880 --> 00:12:43.360]   Yeah.
[00:12:43.360 --> 00:12:46.080]   Again, very parallel silicon.
[00:12:46.080 --> 00:12:47.840]   The point is we've gone from everything
[00:12:47.840 --> 00:12:50.840]   being a CPU bottleneck to having much more things in parallel.
[00:12:50.840 --> 00:12:52.320]   And that has made a difference.
[00:12:52.320 --> 00:12:53.360]   But it has made a difference to how
[00:12:53.360 --> 00:12:56.600]   we have to think about coding as well.
[00:12:56.600 --> 00:12:59.040]   So the ad blocker is in.
[00:12:59.040 --> 00:13:01.560]   I frankly didn't believe this.
[00:13:01.560 --> 00:13:05.480]   But Google's ad blocker is now live in Canary and Dev
[00:13:05.480 --> 00:13:11.120]   builds of Google Chrome, a native ad blocker in the browser.
[00:13:11.120 --> 00:13:13.160]   I haven't played with any of you.
[00:13:13.160 --> 00:13:16.360]   No, I'm not using Canary or even Dev.
[00:13:16.360 --> 00:13:17.280]   I'm not even on Dev.
[00:13:17.280 --> 00:13:18.880]   I'm not going to have a look.
[00:13:18.880 --> 00:13:20.960]   Yeah.
[00:13:20.960 --> 00:13:23.240]   No, it's Dev.
[00:13:23.240 --> 00:13:25.200]   Canary is gamma.
[00:13:25.200 --> 00:13:26.120]   And then there's beta.
[00:13:26.120 --> 00:13:30.800]   Is Dev even more early stage than Canary?
[00:13:30.800 --> 00:13:32.520]   Or is it in the middle?
[00:13:32.520 --> 00:13:33.160]   I can't remember.
[00:13:33.160 --> 00:13:33.960]   It's in the middle.
[00:13:33.960 --> 00:13:35.160]   It's the beta version.
[00:13:35.160 --> 00:13:35.960]   OK.
[00:13:35.960 --> 00:13:37.640]   Yeah, there's a-- there's like a train.
[00:13:37.640 --> 00:13:39.600]   The Canary is the earliest warning train.
[00:13:39.600 --> 00:13:42.400]   And then Dev is, OK, we've got the bugs out
[00:13:42.400 --> 00:13:43.440]   that will probably destroy you.
[00:13:43.440 --> 00:13:47.240]   You should test this if you're building leading edge stuff.
[00:13:47.240 --> 00:13:49.640]   And then there's one more one.
[00:13:49.640 --> 00:13:51.480]   And then there's release, right?
[00:13:51.480 --> 00:13:52.840]   And there's four.
[00:13:52.840 --> 00:13:53.840]   It's four total, OK?
[00:13:53.840 --> 00:13:54.680]   Four.
[00:13:54.680 --> 00:13:58.120]   Can they read beta and release?
[00:13:58.120 --> 00:13:59.200]   That's right.
[00:13:59.200 --> 00:14:00.720]   That's right, yeah.
[00:14:00.720 --> 00:14:03.480]   So if it's in Dev, it means it's fairly close.
[00:14:03.480 --> 00:14:06.560]   I don't know if they've said what version of Chrome it will be.
[00:14:06.560 --> 00:14:09.240]   And I think we're in 16 now.
[00:14:09.240 --> 00:14:10.040]   Or we're in 59.
[00:14:10.040 --> 00:14:11.640]   No, it's not a complete ad blocker, right?
[00:14:11.640 --> 00:14:12.140]   Isn't it?
[00:14:12.140 --> 00:14:13.800]   No, it's certain kinds of ads.
[00:14:13.800 --> 00:14:17.480]   They say intrusive ads.
[00:14:17.480 --> 00:14:18.480]   Yeah.
[00:14:18.480 --> 00:14:19.240]   No, it's a--
[00:14:19.240 --> 00:14:21.560]   I'm willing to bet none of the Google ads are intrusive.
[00:14:21.560 --> 00:14:23.440]   I'm just thinking.
[00:14:23.440 --> 00:14:24.360]   I don't know.
[00:14:24.360 --> 00:14:26.600]   I mean, Matt has done this before where he's blocked Google ads.
[00:14:26.600 --> 00:14:29.080]   So I would believe that they would--
[00:14:29.080 --> 00:14:30.720]   Now I know why you're working with the government.
[00:14:30.720 --> 00:14:35.560]   Well, I have blocked when people would buy links that pass
[00:14:35.560 --> 00:14:36.720]   page rank, but that's different.
[00:14:36.720 --> 00:14:38.240]   That's a violation of Google's guidelines.
[00:14:38.240 --> 00:14:40.960]   But it does make sense to me that there
[00:14:40.960 --> 00:14:44.320]   are certain classes of ads that are really beyond the pale.
[00:14:44.320 --> 00:14:48.320]   And so if somebody's a good citizen, then absolutely.
[00:14:48.320 --> 00:14:50.560]   I don't block those ads myself.
[00:14:50.560 --> 00:14:53.600]   But if somebody's doing something really intrusive
[00:14:53.600 --> 00:14:56.840]   or really deceptive, then I can see in the same way
[00:14:56.840 --> 00:14:59.640]   that Google uses safe browsing to protect users,
[00:14:59.640 --> 00:15:03.280]   it might do something similar to protect them against nasty ads
[00:15:03.280 --> 00:15:04.080]   in those ways.
[00:15:04.080 --> 00:15:05.200]   Oh, I just got 60.
[00:15:05.200 --> 00:15:06.320]   So we are now at 60.
[00:15:06.320 --> 00:15:10.960]   Yeah, that makes a lot--
[00:15:10.960 --> 00:15:12.640]   I think it's just like--
[00:15:12.640 --> 00:15:15.280]   I mean, the phrase that comes to mind is health.
[00:15:15.280 --> 00:15:17.400]   Rose is freezing over.
[00:15:17.400 --> 00:15:19.880]   You just don't expect a company that
[00:15:19.880 --> 00:15:24.400]   makes its money from advertising to put an ad blocker in.
[00:15:24.400 --> 00:15:25.760]   But I think a lot of what Google's
[00:15:25.760 --> 00:15:28.440]   done in the last couple of years, AMP, is another example,
[00:15:28.440 --> 00:15:33.480]   is to shore up the business against people who
[00:15:33.480 --> 00:15:34.920]   are just blocking all ads.
[00:15:34.920 --> 00:15:35.920]   Quality.
[00:15:35.920 --> 00:15:37.760]   Yeah, and it's also a quality question.
[00:15:37.760 --> 00:15:40.320]   I wrote piece of it two years ago.
[00:15:40.320 --> 00:15:41.720]   I wrote a piece about two years ago
[00:15:41.720 --> 00:15:44.480]   suggesting the publisher should create their own ad blocker.
[00:15:44.480 --> 00:15:45.760]   And really, what all you're doing
[00:15:45.760 --> 00:15:47.120]   is you're setting a standard.
[00:15:47.120 --> 00:15:48.160]   You're saying this is the standard,
[00:15:48.160 --> 00:15:50.880]   and we will help you get rid of all the junk below,
[00:15:50.880 --> 00:15:53.320]   and we'll warrant that we're above that line.
[00:15:53.320 --> 00:15:56.120]   So have the publishers join this coalition for better ads
[00:15:56.120 --> 00:15:59.480]   that Google has sort of delegated this to?
[00:15:59.480 --> 00:16:01.040]   Some did, yes.
[00:16:01.040 --> 00:16:01.960]   I think so.
[00:16:01.960 --> 00:16:02.520]   Here it is.
[00:16:02.520 --> 00:16:05.320]   It's betterads.org.
[00:16:05.320 --> 00:16:08.720]   And maybe it'll say-- yeah, members.
[00:16:08.720 --> 00:16:09.360]   Let's see.
[00:16:09.360 --> 00:16:10.360]   Let's see whose members.
[00:16:10.360 --> 00:16:11.880]   Oh, a lot of them.
[00:16:11.880 --> 00:16:12.760]   A lot of ad blockers.
[00:16:12.760 --> 00:16:13.800]   Proctoring gamble.
[00:16:13.800 --> 00:16:14.560]   Oh, newscope.
[00:16:14.560 --> 00:16:15.040]   OK.
[00:16:15.040 --> 00:16:15.920]   Newscorp.
[00:16:15.920 --> 00:16:16.920]   Proctoring gamble.
[00:16:16.920 --> 00:16:21.720]   Well, P&G made a fair bit of noise
[00:16:21.720 --> 00:16:25.680]   about getting rid of lots of useless ads last month,
[00:16:25.680 --> 00:16:26.040]   didn't they?
[00:16:26.040 --> 00:16:27.200]   They dumped a bunch of ads.
[00:16:27.200 --> 00:16:28.160]   They dumped a bunch of ads.
[00:16:28.160 --> 00:16:28.600]   Yeah.
[00:16:28.600 --> 00:16:31.840]   $100 million worth of ads of--
[00:16:31.840 --> 00:16:33.360]   With the most last book?
[00:16:33.360 --> 00:16:36.320]   There was just digital cross-aboard.
[00:16:36.320 --> 00:16:38.560]   They were a little opaque about exactly what it was.
[00:16:38.560 --> 00:16:42.880]   But they'd say, they cut-- which $100 million--
[00:16:42.880 --> 00:16:46.040]   it's a reasonable fraction of their budget,
[00:16:46.040 --> 00:16:46.880]   but it's not that much.
[00:16:46.880 --> 00:16:48.400]   They're budget because they're P&G.
[00:16:48.400 --> 00:16:51.080]   But their point was, these are the ones that
[00:16:51.080 --> 00:16:52.120]   weren't doing anything for us.
[00:16:52.120 --> 00:16:53.280]   We wanted to get rid of them.
[00:16:53.280 --> 00:16:59.720]   And I think it was the more supposedly better targeted ones.
[00:16:59.720 --> 00:17:03.000]   And their big brand advertisers
[00:17:03.000 --> 00:17:06.080]   is very hard to sort of do social targeting
[00:17:06.080 --> 00:17:08.240]   on bleach and things.
[00:17:08.240 --> 00:17:11.360]   But it's--
[00:17:11.360 --> 00:17:14.000]   Oh, is it really?
[00:17:14.000 --> 00:17:16.880]   I'm just thinking who would be a targeted ad for bleach.
[00:17:16.880 --> 00:17:18.520]   No, serial killer.
[00:17:18.520 --> 00:17:20.440]   Yeah, there you go.
[00:17:20.440 --> 00:17:21.840]   Anybody running an email server?
[00:17:21.840 --> 00:17:23.720]   You know, those kinds of people.
[00:17:23.720 --> 00:17:25.560]   No bad.
[00:17:25.560 --> 00:17:28.760]   Interactive advertising bureau is a member.
[00:17:28.760 --> 00:17:30.360]   Unilever is a member.
[00:17:30.360 --> 00:17:32.560]   Thomson Reuters, Washington Post.
[00:17:32.560 --> 00:17:34.440]   I don't see the New York Times on here.
[00:17:34.440 --> 00:17:36.640]   I do see Facebook on here.
[00:17:36.640 --> 00:17:37.880]   Yeah, no.
[00:17:37.880 --> 00:17:43.440]   So it's Google and Facebook who are obviously--
[00:17:43.440 --> 00:17:45.400]   they are all the growth in the ads industry.
[00:17:45.400 --> 00:17:47.320]   And they want to maintain that.
[00:17:47.320 --> 00:17:49.480]   And so part of this is them saying,
[00:17:49.480 --> 00:17:51.360]   there's a lot of ad tech out there that Shady, you should
[00:17:51.360 --> 00:17:53.320]   stick with us well-known big brands.
[00:17:53.320 --> 00:17:57.360]   And we'll make a coalition with the rest of you.
[00:17:57.360 --> 00:17:59.360]   And there's some reason to that.
[00:17:59.360 --> 00:18:02.200]   I don't see an outbrainer Tagula in here either.
[00:18:02.200 --> 00:18:03.240]   I'd be interested.
[00:18:03.240 --> 00:18:04.200]   Let me tell you about that.
[00:18:04.200 --> 00:18:05.400]   Let me tell you about that.
[00:18:05.400 --> 00:18:08.040]   So as I mentioned before in the show,
[00:18:08.040 --> 00:18:10.120]   at the News Integrity Initiative,
[00:18:10.120 --> 00:18:13.560]   that we're doing at Q&A, we partnered with Storeful and Moat.
[00:18:13.560 --> 00:18:17.360]   And we're now collecting the worst of the lowest hanging
[00:18:17.360 --> 00:18:19.560]   rotten fruit of web stuff.
[00:18:19.560 --> 00:18:21.200]   And boy, if you look at these URLs--
[00:18:21.200 --> 00:18:21.920]   What are the best--
[00:18:21.920 --> 00:18:23.480]   What are the worst ads?
[00:18:23.480 --> 00:18:25.040]   Tell me one that's really--
[00:18:25.040 --> 00:18:25.680]   These aren't ads.
[00:18:25.680 --> 00:18:26.560]   These are sites.
[00:18:26.560 --> 00:18:27.320]   These are sites.
[00:18:27.320 --> 00:18:28.280]   Well, get in there a second.
[00:18:28.280 --> 00:18:31.840]   So these are sites that have the real made up fake news junk.
[00:18:31.840 --> 00:18:32.320]   Oh, OK.
[00:18:32.320 --> 00:18:34.760]   And I wish I had to--
[00:18:34.760 --> 00:18:36.360]   It's probably going to give you examples.
[00:18:36.360 --> 00:18:37.000]   Oh, I can find them.
[00:18:37.000 --> 00:18:40.600]   What we're seeing, we're also checking those pages
[00:18:40.600 --> 00:18:43.400]   and how they work with the recirculation engine.
[00:18:43.400 --> 00:18:44.720]   So it's not just to pull an outbrain.
[00:18:44.720 --> 00:18:47.080]   Don't forget the Newsmax has one.
[00:18:47.080 --> 00:18:49.320]   And Rev Content is another one.
[00:18:49.320 --> 00:18:54.080]   And so those organizations are throwing both traffic and
[00:18:54.080 --> 00:18:56.440]   revenue at the fake news sites.
[00:18:56.440 --> 00:18:58.760]   So part of what we're going to try to do there is clean that up.
[00:18:58.760 --> 00:19:00.680]   This is a conversation I want to buy Matt lunch.
[00:19:00.680 --> 00:19:01.880]   I guess I'm probably not allowed to.
[00:19:01.880 --> 00:19:04.560]   I want to share a coffee with Matt.
[00:19:04.560 --> 00:19:07.880]   And get some of his insight about this, about how you
[00:19:07.880 --> 00:19:10.680]   attack this moving beast.
[00:19:10.680 --> 00:19:12.880]   But what we're seeing in the fake news stuff is that there's
[00:19:12.880 --> 00:19:16.960]   a lot more money going to them than I ever would have imagined
[00:19:16.960 --> 00:19:19.920]   from ad networks and such.
[00:19:19.920 --> 00:19:23.760]   And so what you're seeing is it's not just about a junkie
[00:19:23.760 --> 00:19:25.120]   ad on a page.
[00:19:25.120 --> 00:19:28.960]   It's also about fake news content being promoted.
[00:19:28.960 --> 00:19:32.520]   And it's also about legitimate ads showing up on junkie content.
[00:19:32.520 --> 00:19:33.080]   Right.
[00:19:33.080 --> 00:19:34.160]   So here's an example.
[00:19:34.160 --> 00:19:40.040]   This is kind of one of the most famous ABC News.com.co, which
[00:19:40.040 --> 00:19:42.440]   is actually does double duty because ABC could be the
[00:19:42.440 --> 00:19:46.360]   Australian Broadcasting Company or the American Broadcasting
[00:19:46.360 --> 00:19:46.800]   Company.
[00:19:46.800 --> 00:19:47.840]   I've got an ad blocker on.
[00:19:47.840 --> 00:19:50.560]   Let me just refresh this minus the ad blocker.
[00:19:50.560 --> 00:19:52.320]   Get the ads to pop up here.
[00:19:52.320 --> 00:19:56.520]   And here's five must see places to see in Amsterdam and Prague
[00:19:56.520 --> 00:19:59.720]   and make a difference, donate, and help the homeless.
[00:19:59.720 --> 00:20:03.040]   And interesting facts you must know about beard growth.
[00:20:03.040 --> 00:20:05.000]   Feel free to ride your motorcycle in the middle of the
[00:20:05.000 --> 00:20:07.040]   road from now on.
[00:20:07.040 --> 00:20:10.640]   Actually, this isn't as fake as it used to be.
[00:20:10.640 --> 00:20:11.440]   This is pretty legit.
[00:20:11.440 --> 00:20:12.760]   Well, that's what they do.
[00:20:12.760 --> 00:20:14.880]   They put in 80% OK looking.
[00:20:14.880 --> 00:20:16.800]   And then to get the 20% right.
[00:20:16.800 --> 00:20:17.320]   Right.
[00:20:17.320 --> 00:20:19.480]   And they actually don't have as many ads as I expected.
[00:20:19.480 --> 00:20:22.480]   But maybe that's because Google and others are making it
[00:20:22.480 --> 00:20:23.920]   harder for them to buy ads.
[00:20:23.920 --> 00:20:26.280]   I don't see any Google ads on here.
[00:20:26.280 --> 00:20:27.320]   Maybe that's progress.
[00:20:27.320 --> 00:20:28.080]   Yeah.
[00:20:28.080 --> 00:20:28.400]   Yeah.
[00:20:28.400 --> 00:20:29.600]   Well, that's part of it, isn't it?
[00:20:29.600 --> 00:20:36.320]   Under-- wow.
[00:20:36.320 --> 00:20:39.480]   If you want to have some fun, go to the bottom of this page.
[00:20:39.480 --> 00:20:42.440]   I'm not going to show it on the air and read this fine print
[00:20:42.440 --> 00:20:44.560]   disclaimer at the bottom.
[00:20:44.560 --> 00:20:46.560]   Because it starts normal and it gets weird.
[00:20:46.560 --> 00:20:53.640]   Yes, it just gets weird.
[00:20:53.640 --> 00:20:55.120]   Wow.
[00:20:55.120 --> 00:20:57.600]   I highly encourage it for a little extra credit.
[00:20:58.320 --> 00:21:00.240]   [LAUGHS]
[00:21:00.240 --> 00:21:02.000]   So that's one thing, Matt, right?
[00:21:02.000 --> 00:21:03.920]   I mean, I know you're no longer at Google.
[00:21:03.920 --> 00:21:05.360]   But I think that's one thing.
[00:21:05.360 --> 00:21:05.960]   Or are you?
[00:21:05.960 --> 00:21:08.640]   Are you technically not at Google or are you?
[00:21:08.640 --> 00:21:09.800]   I am no longer with Google.
[00:21:09.800 --> 00:21:15.360]   So I resigned December 31, 2016.
[00:21:15.360 --> 00:21:18.200]   But Google has a very clear pattern over years and years
[00:21:18.200 --> 00:21:21.600]   and years of saying, hey, try to make sure that you can
[00:21:21.600 --> 00:21:25.320]   allow lots of great innovation on the web, free speech,
[00:21:25.320 --> 00:21:26.600]   fantastic stuff.
[00:21:26.600 --> 00:21:30.360]   But then when people start to abuse, whether it's spam,
[00:21:30.360 --> 00:21:35.360]   or whether it's malicious content, or intrusive ads,
[00:21:35.360 --> 00:21:39.400]   or whatever, OK, what is a reasonable guideline or path
[00:21:39.400 --> 00:21:41.920]   to push people towards better behavior?
[00:21:41.920 --> 00:21:44.520]   And some people might resent that.
[00:21:44.520 --> 00:21:47.000]   But for example, with Chrome, they're
[00:21:47.000 --> 00:21:49.280]   moving more towards making the web encrypted.
[00:21:49.280 --> 00:21:52.360]   And so over time, over the course of a year or two,
[00:21:52.360 --> 00:21:55.800]   they're making it so that HTTP stuff will show more warnings.
[00:21:55.800 --> 00:21:59.400]   And so I think the most recent was if you are entering a form
[00:21:59.400 --> 00:22:02.360]   and it's an HTTP, not an HTTPS form,
[00:22:02.360 --> 00:22:03.560]   then they'll show you a warning.
[00:22:03.560 --> 00:22:08.560]   So they're just gradually trying to push the web towards being
[00:22:08.560 --> 00:22:12.080]   a good, well-lit place where high quality information happens.
[00:22:12.080 --> 00:22:13.760]   And that includes the whole ecosystem,
[00:22:13.760 --> 00:22:15.640]   the quality of the information, which you see in the search
[00:22:15.640 --> 00:22:17.720]   results and the algorithms they have there.
[00:22:17.720 --> 00:22:19.680]   But also how that gets monetized,
[00:22:19.680 --> 00:22:21.640]   because you want to be able to support publishers,
[00:22:21.640 --> 00:22:24.720]   but you don't want to be able to support bad behavior.
[00:22:24.720 --> 00:22:25.640]   Actually, it strikes me.
[00:22:25.640 --> 00:22:27.840]   I realize we have not talked to you
[00:22:27.840 --> 00:22:33.040]   since this whole fake news thing surfaced.
[00:22:33.040 --> 00:22:35.160]   And I'm sure you've been watching this with interest,
[00:22:35.160 --> 00:22:38.040]   because on the one hand, well, you
[00:22:38.040 --> 00:22:39.960]   stated it perfectly, which is you want
[00:22:39.960 --> 00:22:43.360]   to encourage innovation and free speech on the internet,
[00:22:43.360 --> 00:22:45.960]   but you also want to make sure that--
[00:22:45.960 --> 00:22:46.880]   I don't know.
[00:22:46.880 --> 00:22:50.480]   How do you define fake news?
[00:22:50.480 --> 00:22:52.400]   Not how do you define fake news personally,
[00:22:52.400 --> 00:22:55.000]   but how do you algorithmically define fake news?
[00:22:55.000 --> 00:22:57.440]   How can you determine what's fake?
[00:22:57.440 --> 00:23:00.720]   And how do you then weed it out?
[00:23:00.720 --> 00:23:02.560]   Well, there's lots of ways where you could try to think
[00:23:02.560 --> 00:23:04.120]   about the algorithms, and you could
[00:23:04.120 --> 00:23:06.280]   try to check the quality of the content,
[00:23:06.280 --> 00:23:09.720]   the quality of the channel or the publisher.
[00:23:09.720 --> 00:23:12.640]   Are these facts corroborated in different places
[00:23:12.640 --> 00:23:14.520]   that are also reputable or believable?
[00:23:14.520 --> 00:23:16.120]   But I think what's more interesting
[00:23:16.120 --> 00:23:19.120]   has been the trend towards saying, OK, what can we
[00:23:19.120 --> 00:23:22.160]   do to make sure that things are vouched
[00:23:22.160 --> 00:23:24.040]   and that the user interface supports things?
[00:23:24.040 --> 00:23:25.800]   So I remember when the very first thing happened,
[00:23:25.800 --> 00:23:30.960]   it was because some egregiously misleading or false news
[00:23:30.960 --> 00:23:36.320]   got into one box, which was originally news sources only,
[00:23:36.320 --> 00:23:38.520]   and things have to be vetted to get into the Google News
[00:23:38.520 --> 00:23:39.480]   corpus.
[00:23:39.480 --> 00:23:43.120]   And so my initial take, and I still
[00:23:43.120 --> 00:23:46.520]   had access to Google email, so I was throwing my opinion around,
[00:23:46.520 --> 00:23:48.840]   was, look, this should only be the new Google News
[00:23:48.840 --> 00:23:51.400]   corpus, not just things that look kind of interesting
[00:23:51.400 --> 00:23:52.640]   or hot topics.
[00:23:52.640 --> 00:23:57.160]   And I think, I don't know, maybe some stronger action
[00:23:57.160 --> 00:23:59.680]   a little earlier there could have nipped some of that
[00:23:59.680 --> 00:24:00.200]   in the bud.
[00:24:00.200 --> 00:24:03.840]   I will say, in the same way that the ABC News
[00:24:03.840 --> 00:24:07.320]   example seems a little better, I just noticed last week,
[00:24:07.320 --> 00:24:10.880]   like, you haven't really heard about fake or malicious
[00:24:10.880 --> 00:24:13.920]   or egregiously bad news in Google search results for a while.
[00:24:13.920 --> 00:24:16.800]   And normally, you only notice when things bad happen.
[00:24:16.800 --> 00:24:20.000]   And I noticed nothing bad had happened for a little while.
[00:24:20.000 --> 00:24:20.600]   And so--
[00:24:20.600 --> 00:24:21.680]   Congratulations.
[00:24:21.680 --> 00:24:23.920]   --which is normally, you only notice when people complain.
[00:24:23.920 --> 00:24:25.400]   And so I know that the people at Google
[00:24:25.400 --> 00:24:29.840]   are taking it very seriously and are trying to make it better.
[00:24:29.840 --> 00:24:33.280]   So Matt, did you see the Ben Gomes post
[00:24:33.280 --> 00:24:35.840]   that you put up about two months ago about changes
[00:24:35.840 --> 00:24:37.560]   in structure?
[00:24:37.560 --> 00:24:38.640]   I saw that as a--
[00:24:38.640 --> 00:24:40.120]   I think they were trying to solve pedal up.
[00:24:40.120 --> 00:24:41.520]   But I think the fact that Ben said
[00:24:41.520 --> 00:24:44.760]   that they were going to account for the reliability, quality,
[00:24:44.760 --> 00:24:51.000]   and authority of sources was a sea change in how Google
[00:24:51.000 --> 00:24:51.480]   had to operate.
[00:24:51.480 --> 00:24:53.280]   What do you think?
[00:24:53.280 --> 00:24:56.040]   I don't consider it a sea change so much as a doubling down.
[00:24:56.040 --> 00:24:58.960]   The fact that it was Ben Gomes saying it carries a lot of weight
[00:24:58.960 --> 00:24:59.800]   because--
[00:24:59.800 --> 00:25:01.840]   He's a deep engineer in engineering.
[00:25:01.840 --> 00:25:02.360]   Exactly.
[00:25:02.360 --> 00:25:02.880]   For sure.
[00:25:02.880 --> 00:25:04.320]   If you're talking about search ranking,
[00:25:04.320 --> 00:25:06.480]   you really will have a hard time finding someone more
[00:25:06.480 --> 00:25:07.680]   reputable than that.
[00:25:07.680 --> 00:25:10.880]   And it also fit the timeline of November, December,
[00:25:10.880 --> 00:25:12.200]   when people start talking about it.
[00:25:12.200 --> 00:25:14.360]   Normally, it takes Google at least three or four months
[00:25:14.360 --> 00:25:16.720]   if they're going to do a systemic change or an algorithmic
[00:25:16.720 --> 00:25:18.160]   change.
[00:25:18.160 --> 00:25:21.080]   If something launches and then something launches the next day,
[00:25:21.080 --> 00:25:22.480]   that's usually coincidence.
[00:25:22.480 --> 00:25:24.840]   So the fact that you saw that happen a few months later,
[00:25:24.840 --> 00:25:27.400]   in my mind, from the outside is like, OK, Google
[00:25:27.400 --> 00:25:28.160]   knew it was a problem.
[00:25:28.160 --> 00:25:29.200]   They did a full review.
[00:25:29.200 --> 00:25:31.160]   They said, OK, what are the issues
[00:25:31.160 --> 00:25:34.840]   and what can we solve algorithmically or reasonably
[00:25:34.840 --> 00:25:37.440]   to take care of the most egregious, most misleading,
[00:25:37.440 --> 00:25:39.360]   most false kind of things?
[00:25:39.360 --> 00:25:40.680]   And I'm sure they'll keep iterating.
[00:25:40.680 --> 00:25:44.560]   But I think, to me, that was Google taking a strong stand.
[00:25:44.560 --> 00:25:45.840]   Yeah, it was a big deal.
[00:25:45.840 --> 00:25:49.600]   And I had a conversation with Ben and others about this.
[00:25:49.600 --> 00:25:52.040]   An example in conversation was climate change.
[00:25:52.040 --> 00:25:53.320]   And I've said this on the show before.
[00:25:53.320 --> 00:25:55.800]   But if your search was climate change, you got good results.
[00:25:55.800 --> 00:25:58.640]   But if your search was, is climate change real?
[00:25:58.640 --> 00:26:00.000]   You got crappy results.
[00:26:00.000 --> 00:26:01.680]   Because Google wasn't-- relevance
[00:26:01.680 --> 00:26:04.400]   required that people who ask this question click on this.
[00:26:04.400 --> 00:26:05.880]   If you're stupid enough to ask this question,
[00:26:05.880 --> 00:26:07.160]   you're stupid enough to click on that.
[00:26:07.160 --> 00:26:08.720]   And those things rose.
[00:26:08.720 --> 00:26:11.360]   And there was a manipulation that occurred,
[00:26:11.360 --> 00:26:14.600]   a thumb on the scale that Google had to compensate for.
[00:26:14.600 --> 00:26:19.160]   And so in the end, Matt, I think that Google--
[00:26:19.160 --> 00:26:21.920]   so now if you ask, as climate change real last I asked,
[00:26:21.920 --> 00:26:22.720]   it was good results.
[00:26:22.720 --> 00:26:24.440]   I haven't asked in a while.
[00:26:24.440 --> 00:26:29.400]   Google was kind of siding with the institution of science.
[00:26:29.400 --> 00:26:31.840]   I think Google has a huge believer in--
[00:26:31.840 --> 00:26:35.040]   I think Google is a huge believer in the scientific method.
[00:26:35.040 --> 00:26:37.880]   And that's a good way to get to truth.
[00:26:37.880 --> 00:26:38.600]   In general.
[00:26:38.600 --> 00:26:43.160]   I don't know.
[00:26:43.160 --> 00:26:46.760]   What's kind of interesting to me is there's always
[00:26:46.760 --> 00:26:49.880]   been this tension between trying to make sure
[00:26:49.880 --> 00:26:53.000]   that things are well represented and reflect the web.
[00:26:53.000 --> 00:26:55.760]   So if somebody does a question, you
[00:26:55.760 --> 00:26:58.880]   want to reflect what the wisdom of the web sort of says.
[00:26:58.880 --> 00:27:00.920]   And so in that sense, you're like a mirror.
[00:27:00.920 --> 00:27:02.920]   But then there's also been this, I call it,
[00:27:02.920 --> 00:27:05.200]   the evil unicorn problem.
[00:27:05.200 --> 00:27:07.000]   Everybody knows unicorns are awesome.
[00:27:07.000 --> 00:27:08.000]   They're fantastic.
[00:27:08.000 --> 00:27:08.560]   They're good.
[00:27:08.560 --> 00:27:09.440]   They're light.
[00:27:09.440 --> 00:27:11.600]   Nobody ever thinks of an evil unicorn.
[00:27:11.600 --> 00:27:14.400]   But you can still go to Google and type in evil unicorn.
[00:27:14.400 --> 00:27:16.840]   And people expect something to show up.
[00:27:16.840 --> 00:27:18.920]   And so the wording that people use, like,
[00:27:18.920 --> 00:27:22.160]   is this product fake?
[00:27:22.160 --> 00:27:24.240]   Or is this a scam?
[00:27:24.240 --> 00:27:27.880]   Sometimes the people who might believe in something really
[00:27:27.880 --> 00:27:30.560]   strongly think about vaccines or something like that.
[00:27:30.560 --> 00:27:33.240]   Sometimes some people are really working hard
[00:27:33.240 --> 00:27:35.160]   to try to make sure they produce a lot of content
[00:27:35.160 --> 00:27:36.160]   in that area.
[00:27:36.160 --> 00:27:38.120]   And somebody else is like, well, we
[00:27:38.120 --> 00:27:39.400]   think there's a consensus, so we're not
[00:27:39.400 --> 00:27:42.760]   going to work that much to get our side of the story out.
[00:27:42.760 --> 00:27:48.200]   And so sometimes you do see those sorts of--
[00:27:48.200 --> 00:27:51.080]   the landscape is not always--
[00:27:51.080 --> 00:27:53.520]   what is on the web is not always what some people would
[00:27:53.520 --> 00:27:54.520]   consider reality.
[00:27:54.520 --> 00:27:55.520]   You can see how hard this is.
[00:27:55.520 --> 00:27:56.020]   Right.
[00:27:56.020 --> 00:27:56.520]   Right.
[00:27:56.520 --> 00:27:58.160]   The web is cracked.
[00:27:58.160 --> 00:27:58.720]   Yeah.
[00:27:58.720 --> 00:28:01.160]   And there's also certain phrases as well.
[00:28:01.160 --> 00:28:02.480]   There are certain phrases that--
[00:28:02.480 --> 00:28:03.240]   I'll give you an example.
[00:28:03.240 --> 00:28:04.240]   I'll give you an example.
[00:28:04.240 --> 00:28:05.440]   And then they get redefined.
[00:28:05.440 --> 00:28:08.920]   I just search for do vaccines cause autism.
[00:28:08.920 --> 00:28:13.640]   And the number one result is how do vaccines cause autism.com.
[00:28:13.640 --> 00:28:20.520]   So that's an example of what you talked about, Jeff.
[00:28:20.520 --> 00:28:22.240]   I bet you if I search for vaccines,
[00:28:22.240 --> 00:28:24.080]   I'd get lots of--
[00:28:24.080 --> 00:28:25.080]   Right.
[00:28:25.080 --> 00:28:26.040]   This is the relevant--
[00:28:26.040 --> 00:28:26.720]   Good science.
[00:28:26.720 --> 00:28:29.520]   And it's also the problem of--
[00:28:29.520 --> 00:28:31.440]   there's one scientific paper over here
[00:28:31.440 --> 00:28:32.280]   that nobody's talking about.
[00:28:32.280 --> 00:28:34.360]   And there's 1,000 stupid blog posts a million people
[00:28:34.360 --> 00:28:35.320]   are talking about over here.
[00:28:35.320 --> 00:28:36.520]   How do you determine that?
[00:28:36.520 --> 00:28:37.480]   The signals are wrong.
[00:28:37.480 --> 00:28:38.440]   However, Matt, you're right.
[00:28:38.440 --> 00:28:40.360]   If you do search for evil unicorns,
[00:28:40.360 --> 00:28:41.400]   it took me to Amazon.
[00:28:41.400 --> 00:28:47.200]   And you can buy an inflatable evil unicorn horn for cats.
[00:28:47.200 --> 00:28:50.320]   I actually do have an evil unicorn action figure
[00:28:50.320 --> 00:28:51.880]   because I was going to do a blog post.
[00:28:51.880 --> 00:28:53.240]   But I'm off duty.
[00:28:53.240 --> 00:28:55.400]   I don't need to talk about evil unicorns anymore.
[00:28:55.400 --> 00:28:56.440]   So--
[00:28:56.440 --> 00:29:00.520]   By the way, if you search for do dog vaccines cause autism,
[00:29:00.520 --> 00:29:03.520]   Google's very good about debunking that, despite the least--
[00:29:03.520 --> 00:29:04.960]   I'm actually--
[00:29:04.960 --> 00:29:08.800]   The first link is a search grabbing site,
[00:29:08.800 --> 00:29:10.520]   but don't click through because it swears.
[00:29:10.520 --> 00:29:12.920]   OK.
[00:29:12.920 --> 00:29:15.680]   This one is timed around a news story,
[00:29:15.680 --> 00:29:18.040]   which sounds like fake news to me
[00:29:18.040 --> 00:29:22.240]   that some Brooklyn denizens are not
[00:29:22.240 --> 00:29:27.920]   vaccinating their dogs against rabies and other serious diseases
[00:29:27.920 --> 00:29:31.480]   because they believe it causes autism in their dogs, which
[00:29:31.480 --> 00:29:34.040]   I believe that I don't believe there is such a thing.
[00:29:34.040 --> 00:29:37.360]   So I think that sounds like a fake news story,
[00:29:37.360 --> 00:29:38.760]   but I--
[00:29:38.760 --> 00:29:42.640]   But also, there is actually an issue with vaccines and dogs
[00:29:42.640 --> 00:29:49.120]   because the problem is that they're not as thoroughly
[00:29:49.120 --> 00:29:51.160]   tested as they are on humans.
[00:29:51.160 --> 00:29:54.400]   And also vets use them as a way to make an annual visit.
[00:29:54.400 --> 00:29:58.920]   So I have had a dog that's happened to where we were very
[00:29:58.920 --> 00:30:00.800]   conscientious and did what we were told
[00:30:00.800 --> 00:30:03.360]   and went to the vet every year and was given this cocktail
[00:30:03.360 --> 00:30:04.400]   of vaccines.
[00:30:04.400 --> 00:30:06.920]   And literally, the vet gave the dog the annual checkup said,
[00:30:06.920 --> 00:30:07.720]   oh, this dog's fine.
[00:30:07.720 --> 00:30:09.960]   Everything's great.
[00:30:09.960 --> 00:30:12.000]   Let me give this giant cocktail of vaccines.
[00:30:12.000 --> 00:30:14.640]   And then within a week, it had an autoimmune disease.
[00:30:14.640 --> 00:30:18.440]   So the problem is they haven't--
[00:30:18.440 --> 00:30:21.760]   literally, her lymph nodes grew up.
[00:30:21.760 --> 00:30:23.600]   She was really sick.
[00:30:23.600 --> 00:30:25.760]   And she died within a month.
[00:30:25.760 --> 00:30:27.560]   It was really shocking for us.
[00:30:27.560 --> 00:30:29.600]   And since then, we've been much more careful about that.
[00:30:29.600 --> 00:30:35.400]   But there is this-- more vaccines are better thing
[00:30:35.400 --> 00:30:40.200]   that is slightly sketchy because the interactions
[00:30:40.200 --> 00:30:42.000]   between them haven't actually been tested.
[00:30:42.000 --> 00:30:43.240]   And so they rely--
[00:30:43.240 --> 00:30:46.700]   So I just--
[00:30:46.700 --> 00:30:50.720]   No, no, I really don't want to come down on vaccines
[00:30:50.720 --> 00:30:51.920]   are good or bad or dog.
[00:30:51.920 --> 00:30:52.800]   Vaccines are good or bad.
[00:30:52.800 --> 00:30:55.520]   I just want to point out the people who feel strongly
[00:30:55.520 --> 00:30:57.840]   about a given topic will talk about something.
[00:30:57.840 --> 00:31:00.120]   And then you can type anything into Google.
[00:31:00.120 --> 00:31:02.680]   And we got a return 10 results, or Google has to return 10
[00:31:02.680 --> 00:31:04.480]   results.
[00:31:04.480 --> 00:31:08.160]   And so that leads to interesting situations.
[00:31:08.160 --> 00:31:09.640]   Yeah, that's why it's so difficult.
[00:31:09.640 --> 00:31:12.360]   In fact, I think my attitude during this whole fake news
[00:31:12.360 --> 00:31:15.400]   thing was I don't want to see companies like Facebook and
[00:31:15.400 --> 00:31:20.000]   Google trying to determine what's true or not.
[00:31:20.000 --> 00:31:21.240]   Because that's--
[00:31:21.240 --> 00:31:24.440]   I mean, admittedly, there's facts in the world.
[00:31:24.440 --> 00:31:24.920]   But--
[00:31:24.920 --> 00:31:27.560]   Well, nobody wants to be the truth police, but there are
[00:31:27.560 --> 00:31:29.160]   truth police either, exactly.
[00:31:29.160 --> 00:31:30.760]   But there are some things that are--
[00:31:30.760 --> 00:31:32.400]   But the thing is that--
[00:31:32.400 --> 00:31:32.840]   It's not--
[00:31:32.840 --> 00:31:33.800]   Yes.
[00:31:33.800 --> 00:31:37.240]   But the two things we've mentioned--
[00:31:37.240 --> 00:31:40.920]   well, I know we all agree that vaccines don't cause autism
[00:31:40.920 --> 00:31:42.480]   and that climate change is man-made.
[00:31:42.480 --> 00:31:43.840]   I know we all agree on that.
[00:31:43.840 --> 00:31:47.640]   But there is still debated.
[00:31:47.640 --> 00:31:53.400]   Is it Google or Facebook's place to weigh in on that?
[00:31:53.400 --> 00:31:54.640]   I would argue no.
[00:31:54.640 --> 00:31:56.640]   I would argue that egregious the bar
[00:31:56.640 --> 00:31:58.960]   should be even higher.
[00:31:58.960 --> 00:32:00.760]   That's how I would argue as well.
[00:32:00.760 --> 00:32:04.080]   And then we can all agree that there's not a colony of
[00:32:04.080 --> 00:32:09.120]   Martians or Collea Moon denizens living on the moon.
[00:32:09.120 --> 00:32:10.840]   We can all agree on that.
[00:32:10.840 --> 00:32:13.360]   That's egregious.
[00:32:13.360 --> 00:32:15.960]   But nobody's publishing stories like that because there's
[00:32:15.960 --> 00:32:18.640]   no money to be made on stories like that.
[00:32:18.640 --> 00:32:21.240]   That's the real problem, isn't it?
[00:32:21.240 --> 00:32:24.480]   I guess maybe the weekly world news did for years with the
[00:32:24.480 --> 00:32:26.720]   alien babies.
[00:32:26.720 --> 00:32:29.320]   I mean, I'm looking through the sites that we have on our
[00:32:29.320 --> 00:32:31.400]   project.
[00:32:31.400 --> 00:32:34.240]   And you could debate this one, but I just put it aside.
[00:32:34.240 --> 00:32:37.000]   Matt, did you know that we should mention when you say
[00:32:37.000 --> 00:32:42.840]   our project so everybody knows that Craig--
[00:32:42.840 --> 00:32:44.560]   I got your full disclosure.
[00:32:44.560 --> 00:32:48.760]   Yes, I got $40 million from a combination of Craig Newmark
[00:32:48.760 --> 00:32:51.920]   Facebook, the Ford Foundation and other supporters.
[00:32:51.920 --> 00:32:55.280]   And we have independence in our governments, but you should
[00:32:55.280 --> 00:32:58.160]   know that by all means that I received those funds to give
[00:32:58.160 --> 00:33:00.440]   them back out in the cause of truth.
[00:33:00.440 --> 00:33:04.040]   And Jeff's just one of the people who's doing this, which
[00:33:04.040 --> 00:33:05.960]   is I think fantastic.
[00:33:05.960 --> 00:33:08.120]   That's the news integrity project he's been mentioning.
[00:33:08.120 --> 00:33:09.800]   This is why I want to have coffee with Matt too, because I
[00:33:09.800 --> 00:33:12.280]   want to get his perspective about how this world operates.
[00:33:12.280 --> 00:33:13.840]   So you have a dog in this hunt.
[00:33:13.840 --> 00:33:16.200]   I mean, this is something you spend a lot of time thinking
[00:33:16.200 --> 00:33:17.440]   about.
[00:33:17.440 --> 00:33:18.880]   Yeah.
[00:33:18.880 --> 00:33:20.640]   But is it a vaccinated dog?
[00:33:20.640 --> 00:33:21.880]   Sorry, I'm good business.
[00:33:21.880 --> 00:33:25.280]   I'm sorry.
[00:33:25.280 --> 00:33:26.800]   It's a serious topic.
[00:33:26.800 --> 00:33:27.520]   I didn't mean to be like--
[00:33:27.520 --> 00:33:28.760]   It is a serious topic.
[00:33:28.760 --> 00:33:30.520]   And actually, I think it's well-tech.
[00:33:30.520 --> 00:33:31.520]   Oh.
[00:33:31.520 --> 00:33:33.960]   Kevin loves spools.
[00:33:33.960 --> 00:33:36.280]   I've got it's OK, yeah.
[00:33:36.280 --> 00:33:37.960]   The other three I'm saying is--
[00:33:37.960 --> 00:33:41.440]   It's clear, of course, that dogs need to be vaccinating.
[00:33:41.440 --> 00:33:42.120]   It's rabies.
[00:33:42.120 --> 00:33:44.800]   And they're heartworm.
[00:33:44.800 --> 00:33:46.360]   And there are lots of things.
[00:33:46.360 --> 00:33:47.640]   And I think you make a good point.
[00:33:47.640 --> 00:33:49.720]   You can over vaccinate out of greed.
[00:33:49.720 --> 00:33:52.080]   Well, the point is more that puppies need to be vaccinate
[00:33:52.080 --> 00:33:53.800]   against it.
[00:33:53.800 --> 00:33:56.000]   And dogs need to refresher at some interval.
[00:33:56.000 --> 00:33:58.120]   Every three years for distemper or something like that,
[00:33:58.120 --> 00:33:59.200]   I can't remember what it was.
[00:33:59.200 --> 00:34:00.880]   But the interval is not annually.
[00:34:00.880 --> 00:34:02.880]   And actually, most vets will send you an annual thing,
[00:34:02.880 --> 00:34:06.240]   because that's their way of getting in the door.
[00:34:06.240 --> 00:34:07.040]   And that's the--
[00:34:07.040 --> 00:34:10.680]   I think we need to do a story on bad vets,
[00:34:10.680 --> 00:34:13.280]   because I've run into bad vets as well.
[00:34:13.280 --> 00:34:14.200]   And I think--
[00:34:14.200 --> 00:34:16.040]   Oh, I could tell you about our job.
[00:34:16.040 --> 00:34:19.800]   It was also, I think, ultimately killed by bad veterinary
[00:34:19.800 --> 00:34:21.680]   treatment.
[00:34:21.680 --> 00:34:23.600]   So our dog ended up having--
[00:34:23.600 --> 00:34:27.960]   Ozzy ended up having a $10,000 back surgery
[00:34:27.960 --> 00:34:31.840]   that I think he didn't need and I think killed him.
[00:34:31.840 --> 00:34:33.600]   But that's another story for another day.
[00:34:33.600 --> 00:34:35.680]   So bad vets.
[00:34:35.680 --> 00:34:43.920]   So Leo, if you go to truthuncensored.net, I think,
[00:34:43.920 --> 00:34:45.600]   with your ad blocker off.
[00:34:45.600 --> 00:34:47.400]   OK, I'll block her off.
[00:34:47.400 --> 00:34:49.480]   Do I really want to do that?
[00:34:49.480 --> 00:34:50.880]   Well, if you go down-- if you go down
[00:34:50.880 --> 00:34:53.280]   on the second row of stories, for example, one story they
[00:34:53.280 --> 00:34:54.280]   have there is breaking.
[00:34:54.280 --> 00:34:56.920]   Government admits plan to microchip the population.
[00:34:56.920 --> 00:34:58.920]   Yes, of course they do.
[00:34:58.920 --> 00:35:00.080]   That's what they wanted to call along.
[00:35:00.080 --> 00:35:03.720]   So I could argue about the credibility of this site.
[00:35:03.720 --> 00:35:07.760]   But for me, I have ads galore on this thing.
[00:35:07.760 --> 00:35:08.280]   Yeah.
[00:35:08.280 --> 00:35:09.080]   Loft.
[00:35:09.080 --> 00:35:09.600]   Yeah.
[00:35:09.600 --> 00:35:12.680]   Zodiac, strepiphong.
[00:35:12.680 --> 00:35:17.120]   Scary dollar prediction, scary Bitcoin prediction.
[00:35:17.120 --> 00:35:19.000]   Yeah, no, I see them all.
[00:35:19.000 --> 00:35:20.120]   So here's Tabula.
[00:35:20.120 --> 00:35:22.160]   I see Tabula ads.
[00:35:22.160 --> 00:35:25.200]   Do you see any Google ads on there, though?
[00:35:25.200 --> 00:35:26.400]   No.
[00:35:26.400 --> 00:35:28.640]   Well, I do get my ad choices, Link.
[00:35:28.640 --> 00:35:30.320]   I always love that.
[00:35:30.320 --> 00:35:33.280]   You do have a choice when it comes to ads.
[00:35:33.280 --> 00:35:34.360]   That's not necessarily Google.
[00:35:34.360 --> 00:35:35.200]   Oh, it's Google.
[00:35:35.200 --> 00:35:37.320]   That's AdSense.
[00:35:37.320 --> 00:35:39.240]   Is that correct?
[00:35:39.240 --> 00:35:41.080]   I think it is.
[00:35:41.080 --> 00:35:43.440]   So this here, the camera saw it all.
[00:35:43.440 --> 00:35:46.480]   She wore very little and you won't believe what she showed
[00:35:46.480 --> 00:35:50.320]   is a Google ad because I get the ad choices, Link, on it.
[00:35:50.320 --> 00:35:54.480]   Unless somebody's spoofing that.
[00:35:54.480 --> 00:35:57.760]   Wouldn't surprise me.
[00:35:57.760 --> 00:36:00.400]   Someone at the Googleplex right now is like, shut it down.
[00:36:00.400 --> 00:36:01.280]   Shut it all down.
[00:36:01.280 --> 00:36:03.280]   Yeah.
[00:36:03.280 --> 00:36:06.000]   From the web sponsored links, that's Tabula, right?
[00:36:06.000 --> 00:36:07.160]   Yeah, that's a Tabula.
[00:36:07.160 --> 00:36:08.520]   Or one of them.
[00:36:08.520 --> 00:36:11.440]   Yeah, this scary Bitcoin prediction also has ad choices on it.
[00:36:11.440 --> 00:36:14.200]   Does that mean it's Google?
[00:36:14.200 --> 00:36:15.640]   I think it does.
[00:36:15.640 --> 00:36:16.440]   Yeah.
[00:36:16.440 --> 00:36:16.960]   Oh, yeah.
[00:36:16.960 --> 00:36:17.240]   Cool.
[00:36:17.240 --> 00:36:17.240]   I can't--
[00:36:17.240 --> 00:36:17.760]   Yes.
[00:36:17.760 --> 00:36:18.400]   The link is to--
[00:36:18.400 --> 00:36:19.080]   Not always.
[00:36:19.080 --> 00:36:21.800]   No, it's Google adsservices.com.
[00:36:21.800 --> 00:36:22.440]   That's the link.
[00:36:22.440 --> 00:36:23.000]   Google ads services.
[00:36:23.000 --> 00:36:24.400]   One of them is, but another one.
[00:36:24.400 --> 00:36:26.680]   Is that a real one?
[00:36:26.680 --> 00:36:27.720]   Yeah.
[00:36:27.720 --> 00:36:33.000]   When I hover over the link, it's www.google adsservices.com.
[00:36:33.000 --> 00:36:36.160]   And then, of course, the long extra stuff.
[00:36:36.160 --> 00:36:38.160]   So these--
[00:36:38.160 --> 00:36:39.360]   You have that same arrow that same arrow
[00:36:39.360 --> 00:36:40.720]   could appear on non-Google ads.
[00:36:40.720 --> 00:36:41.080]   No, no.
[00:36:41.080 --> 00:36:41.600]   I know.
[00:36:41.600 --> 00:36:42.840]   But this is a Google ad.
[00:36:42.840 --> 00:36:44.760]   This is a Google ad.
[00:36:44.760 --> 00:36:46.080]   Yeah, just Tabula here as well.
[00:36:46.080 --> 00:36:47.600]   Yeah.
[00:36:47.600 --> 00:36:50.040]   Just because I'm telling-- the link
[00:36:50.040 --> 00:36:51.840]   is through Google ad services.
[00:36:51.840 --> 00:36:54.280]   So Google has absolutely has not pulled their ads
[00:36:54.280 --> 00:36:56.640]   from Truth Uncensored, the truth about political news.
[00:36:56.640 --> 00:36:58.720]   But this may be a political--
[00:36:58.720 --> 00:37:00.640]   see, I think this doesn't rise to the level
[00:37:00.640 --> 00:37:04.840]   that was talking about of egregiousness.
[00:37:04.840 --> 00:37:05.640]   Maybe it does.
[00:37:05.640 --> 00:37:07.560]   Sometimes in the past, we've seen somebody
[00:37:07.560 --> 00:37:09.360]   admit that they defrauded somebody,
[00:37:09.360 --> 00:37:10.880]   or admit that a story was fake.
[00:37:10.880 --> 00:37:15.200]   There was a story about a 11 or a 13-year-old who
[00:37:15.200 --> 00:37:19.960]   got money and called in prostitutes to play Xbox with him.
[00:37:19.960 --> 00:37:22.520]   And it was all just this viral story
[00:37:22.520 --> 00:37:23.760]   that somebody concocted.
[00:37:23.760 --> 00:37:27.880]   And then the person admitted that they had deliberately
[00:37:27.880 --> 00:37:29.080]   done this as a fake story.
[00:37:29.080 --> 00:37:30.080]   That's--
[00:37:30.080 --> 00:37:32.080]   It's more slanted than fake.
[00:37:32.080 --> 00:37:35.520]   Liberal news outlets working overtime to cover huge democratic
[00:37:35.520 --> 00:37:40.320]   scandals, that kind of thing.
[00:37:40.320 --> 00:37:42.320]   So this is why it's so difficult, though, right?
[00:37:42.320 --> 00:37:43.080]   I mean, this is the challenge.
[00:37:43.080 --> 00:37:44.920]   It is difficult.
[00:37:44.920 --> 00:37:48.600]   Just because you from your political vantage point
[00:37:48.600 --> 00:37:54.400]   may hate this doesn't necessarily mean it's fake news,
[00:37:54.400 --> 00:37:55.640]   by any means.
[00:37:55.640 --> 00:37:56.680]   Fake news would have been--
[00:37:56.680 --> 00:37:58.080]   Do I do doubt that the government has been
[00:37:58.080 --> 00:38:00.320]   planning to microchip us all?
[00:38:00.320 --> 00:38:01.720]   Well, that's true.
[00:38:01.720 --> 00:38:02.720]   Fake news would have to be--
[00:38:02.720 --> 00:38:03.920]   That's the question.
[00:38:03.920 --> 00:38:04.920]   False.
[00:38:04.920 --> 00:38:05.480]   Just I don't.
[00:38:05.480 --> 00:38:08.000]   Well--
[00:38:08.000 --> 00:38:09.080]   But here's the issue.
[00:38:09.080 --> 00:38:12.120]   So I've had people ask me, well, if it's like 90% OK,
[00:38:12.120 --> 00:38:13.080]   is that OK?
[00:38:13.080 --> 00:38:14.720]   No, because they throw the 90% on them,
[00:38:14.720 --> 00:38:18.400]   seemingly OK stuff to sneak the 10% buy.
[00:38:18.400 --> 00:38:18.880]   Yeah.
[00:38:18.880 --> 00:38:20.240]   Let me give you another one.
[00:38:20.240 --> 00:38:22.160]   I'm going to give up-- this is real irreverent right now.
[00:38:22.160 --> 00:38:24.520]   If you go to my numbers section, you
[00:38:24.520 --> 00:38:28.960]   will see a fascinating link, I think, to the--
[00:38:28.960 --> 00:38:31.240]   hold on here--
[00:38:31.240 --> 00:38:33.320]   Russian Twitter propaganda dashboard.
[00:38:33.320 --> 00:38:34.120]   Oh, I saw this.
[00:38:34.120 --> 00:38:34.920]   This is a great--
[00:38:34.920 --> 00:38:36.240]   --scurrying democracy.org.
[00:38:36.240 --> 00:38:38.080]   This is phenomenal.
[00:38:38.080 --> 00:38:40.320]   And it's a very legitimate organization
[00:38:40.320 --> 00:38:41.400]   that is going through.
[00:38:41.400 --> 00:38:43.680]   And now, if you look at the--
[00:38:43.680 --> 00:38:49.160]   It calls Sputnik and RT Russian propaganda.
[00:38:49.160 --> 00:38:49.680]   It does.
[00:38:49.680 --> 00:38:52.040]   And also, the way this works is they
[00:38:52.040 --> 00:38:54.640]   identify Twitter accounts that were tied to Russian propaganda.
[00:38:54.640 --> 00:38:57.720]   And then they see what they are presenting.
[00:38:57.720 --> 00:39:00.040]   And what domains and what stories?
[00:39:00.040 --> 00:39:04.480]   And you see a big tie to this to things like Breitbart and stuff.
[00:39:04.480 --> 00:39:05.480]   Trending domains.
[00:39:05.480 --> 00:39:06.040]   Trending domains.
[00:39:06.040 --> 00:39:09.240]   I drain the swamp.com, bigleaguepolitics.com,
[00:39:09.240 --> 00:39:11.120]   weaselzippers.us.
[00:39:11.120 --> 00:39:12.640]   I don't know what that's all about.
[00:39:12.640 --> 00:39:15.440]   Might have more to do with veterinarian vaccines.
[00:39:15.440 --> 00:39:16.920]   I don't know.
[00:39:16.920 --> 00:39:20.360]   But that's-- I mean, the first two are clearly
[00:39:20.360 --> 00:39:21.320]   Trump-focused.
[00:39:21.320 --> 00:39:24.680]   Top topics, Trump, US, Russia, Russian, Syria.
[00:39:24.680 --> 00:39:30.200]   But you could say that about if you were covering Washington
[00:39:30.200 --> 00:39:32.560]   Post tweets, it would probably be the same ranking
[00:39:32.560 --> 00:39:34.680]   of those subjects.
[00:39:34.680 --> 00:39:36.200]   Robert, I looked at this earlier today.
[00:39:36.200 --> 00:39:37.600]   There were other topics.
[00:39:37.600 --> 00:39:38.840]   Stephen Miller is big right now.
[00:39:38.840 --> 00:39:40.240]   Ben Rhodes, that story.
[00:39:40.240 --> 00:39:41.280]   That story is--
[00:39:41.280 --> 00:39:42.240]   Ben Rhodes--
[00:39:42.240 --> 00:39:43.720]   That's a part of the story.
[00:39:43.720 --> 00:39:45.840]   That's a part of the story that you're seeing that on the right.
[00:39:45.840 --> 00:39:49.120]   You do not see that all on the left.
[00:39:49.120 --> 00:39:52.920]   I don't know why Howard Dean is on the left.
[00:39:52.920 --> 00:39:55.000]   Well, he's become once again relevant.
[00:39:55.000 --> 00:39:56.160]   I don't know.
[00:39:56.160 --> 00:39:58.360]   This is really interesting.
[00:39:58.360 --> 00:39:59.520]   Do they--
[00:39:59.520 --> 00:39:59.960]   Sort of--
[00:39:59.960 --> 00:40:02.680]   How many bots do they think are Russia?
[00:40:02.680 --> 00:40:04.680]   I think they're tracking 300 of them.
[00:40:04.680 --> 00:40:07.080]   So I went through their fact form.
[00:40:07.080 --> 00:40:07.560]   Interesting.
[00:40:07.560 --> 00:40:08.240]   Yeah.
[00:40:08.240 --> 00:40:09.120]   Can't find them now.
[00:40:09.120 --> 00:40:13.000]   Dashboard tracking Russian propaganda on Twitter.
[00:40:13.000 --> 00:40:13.600]   Well, we--
[00:40:13.600 --> 00:40:15.880]   Matt, Matt, I've on the show before.
[00:40:15.880 --> 00:40:19.720]   I've gone on at paranoid-- at Tin Hat length.
[00:40:19.720 --> 00:40:20.800]   I read the NATO--
[00:40:20.800 --> 00:40:22.800]   NATO--
[00:40:22.800 --> 00:40:23.800]   They just dropped out.
[00:40:23.800 --> 00:40:24.800]   They just dropped out.
[00:40:24.800 --> 00:40:25.800]   They just dropped out.
[00:40:25.800 --> 00:40:26.800]   They just dropped out.
[00:40:26.800 --> 00:40:27.800]   [LAUGHTER]
[00:40:27.800 --> 00:40:28.800]   That's like--
[00:40:28.800 --> 00:40:30.800]   Is it right, Kevin?
[00:40:30.800 --> 00:40:31.800]   [LAUGHTER]
[00:40:31.800 --> 00:40:34.800]   He said the magic words that caused this internet connection
[00:40:34.800 --> 00:40:35.800]   to drop out.
[00:40:35.800 --> 00:40:36.800]   [LAUGHTER]
[00:40:36.800 --> 00:40:37.800]   Well, I have this with you.
[00:40:37.800 --> 00:40:40.800]   If I do Google search my browser, Skype drops out in the background.
[00:40:40.800 --> 00:40:42.800]   I've no idea what's going on there.
[00:40:42.800 --> 00:40:47.800]   Well, Skype says, oh, you want some bandwidth for that browser?
[00:40:47.800 --> 00:40:48.800]   Let's--
[00:40:48.800 --> 00:40:49.800]   Let's do that.
[00:40:49.800 --> 00:40:51.800]   Let's do that instead.
[00:40:51.800 --> 00:40:52.800]   [LAUGHTER]
[00:40:52.800 --> 00:40:54.800]   FTC is--
[00:40:54.800 --> 00:41:02.800]   EPIC has gone to the FTC to submit a complaint about this Google
[00:41:02.800 --> 00:41:03.800]   technology that we were talking about.
[00:41:03.800 --> 00:41:07.800]   Remember we said that-- and if the way it was written in the
[00:41:07.800 --> 00:41:09.800]   papers, it did sound pretty cheesy.
[00:41:09.800 --> 00:41:16.800]   Google would be able to tie your online ad viewing with your
[00:41:16.800 --> 00:41:21.800]   offline purchases using something called Store Sales Measurement,
[00:41:21.800 --> 00:41:25.800]   a consumer profiling technique to track consumers who make
[00:41:25.800 --> 00:41:26.800]   offline purchases.
[00:41:26.800 --> 00:41:31.800]   The idea is to tell advertisers how effective their ads are.
[00:41:31.800 --> 00:41:35.800]   And of course, the way we do it on our shows generally is what
[00:41:35.800 --> 00:41:36.800]   they call direct response.
[00:41:36.800 --> 00:41:41.800]   We give you a promo code that's got our name in it or we give you
[00:41:41.800 --> 00:41:43.800]   a URL slash Twit.
[00:41:43.800 --> 00:41:47.800]   And the advertisers say, well, we got this many responses,
[00:41:47.800 --> 00:41:49.800]   so that's the tracking we do.
[00:41:49.800 --> 00:41:52.800]   But it's hard to do that in every case, certainly, when a lot
[00:41:52.800 --> 00:41:53.800]   of Google ads don't.
[00:41:53.800 --> 00:41:58.800]   So this was designed, I think, by Google Sales to help advertisers
[00:41:58.800 --> 00:42:01.800]   understand how their ads were doing.
[00:42:01.800 --> 00:42:04.800]   Did you sell that car?
[00:42:04.800 --> 00:42:07.800]   When Ford is on Twit, they can't say, well, we know we sold this
[00:42:07.800 --> 00:42:11.800]   many cars because of Twit without doing a lot of research.
[00:42:11.800 --> 00:42:13.800]   And Google hopes to help them with that.
[00:42:13.800 --> 00:42:17.800]   According to Google, it could track about 70% of all credit card
[00:42:17.800 --> 00:42:22.800]   and debit card transactions in the US and tie them back to you,
[00:42:22.800 --> 00:42:25.800]   to the people who made them, to seeing those ads.
[00:42:25.800 --> 00:42:30.800]   Epic has filed with the FTC asking that they investigate this.
[00:42:30.800 --> 00:42:34.800]   Request for investigation, injunction, and other relief against
[00:42:34.800 --> 00:42:36.800]   this technology.
[00:42:36.800 --> 00:42:37.800]   We got them back.
[00:42:37.800 --> 00:42:40.800]   Jeff Jarvis is back.
[00:42:40.800 --> 00:42:44.800]   What do you think?
[00:42:44.800 --> 00:42:46.800]   Well, it's one of these things.
[00:42:46.800 --> 00:42:48.800]   They've been trying to do this for a long time, and there were
[00:42:48.800 --> 00:42:51.800]   lots of sketch organizations in the US that do this already.
[00:42:51.800 --> 00:42:55.800]   Experian Equifax and those guys are trawling all that data and
[00:42:55.800 --> 00:42:57.800]   trying to get stuff about you.
[00:42:57.800 --> 00:43:02.800]   For Google to tie up with that is, yeah, it's a little disappointing.
[00:43:02.800 --> 00:43:06.800]   They also have been doing Google Wallet, stroke Android Pay,
[00:43:06.800 --> 00:43:08.800]   stroke, whatever it's called this week.
[00:43:08.800 --> 00:43:11.800]   And Apple has been doing a similar thing.
[00:43:11.800 --> 00:43:13.800]   And there's a set of, if we can track all the payments,
[00:43:13.800 --> 00:43:16.800]   we can keep track of all this stuff.
[00:43:16.800 --> 00:43:19.800]   But a lot of it is based on guessing correlations.
[00:43:19.800 --> 00:43:24.800]   And in fact, most of the Equifax stuff is sort of bad,
[00:43:24.800 --> 00:43:26.800]   big data correlation stuff.
[00:43:26.800 --> 00:43:29.800]   Now, Google is better at that than those companies are,
[00:43:29.800 --> 00:43:31.800]   and so it could do a better job of correlating that stuff.
[00:43:31.800 --> 00:43:34.800]   So there may be a case for being a little more nervous about it.
[00:43:34.800 --> 00:43:37.800]   But in practice, we already gave up this thing when we accepted
[00:43:37.800 --> 00:43:40.800]   credit ratings 20 years ago, 30 years ago.
[00:43:40.800 --> 00:43:41.800]   >> At a point.
[00:43:41.800 --> 00:43:45.800]   >> This is your mania's point is that the Turing test was passed
[00:43:45.800 --> 00:43:47.800]   at the point where we started doing stupid things without
[00:43:47.800 --> 00:43:51.800]   credit to trample-kating out with them somewhere in Equifax.
[00:43:51.800 --> 00:43:55.800]   And I did this when I moved to America,
[00:43:55.800 --> 00:43:59.800]   from the UK with a large amount of money because I just sold a house.
[00:43:59.800 --> 00:44:00.800]   But did I have a credit rating?
[00:44:00.800 --> 00:44:01.800]   Did I hell?
[00:44:01.800 --> 00:44:03.800]   And I had to go and see a guy and say, oh, yeah.
[00:44:03.800 --> 00:44:08.800]   >> Right. >> Do these six things?
[00:44:08.800 --> 00:44:09.800]   Now you have a credit rating.
[00:44:09.800 --> 00:44:11.800]   >> We tell college kids to do this.
[00:44:11.800 --> 00:44:12.800]   >> We do.
[00:44:12.800 --> 00:44:13.800]   >> Yeah.
[00:44:13.800 --> 00:44:17.800]   And it's basically somebody's reverse engineered the heuristic
[00:44:17.800 --> 00:44:23.800]   that these 1980s mainframe algorithms are trying to do.
[00:44:23.800 --> 00:44:28.800]   So there is a problem here, but the problem is not Google's
[00:44:28.800 --> 00:44:33.800]   John AI or any of this stuff.
[00:44:33.800 --> 00:44:36.800]   It is that we have sort of delegated our judgment to the
[00:44:36.800 --> 00:44:40.800]   machines and even a really bad algorithm will let us do that.
[00:44:40.800 --> 00:44:44.800]   And that's the bigger problem than the AI taking over the world
[00:44:44.800 --> 00:44:45.800]   problem.
[00:44:45.800 --> 00:44:48.800]   It's the do we actually understand what we're doing here or are we
[00:44:48.800 --> 00:44:49.800]   just getting?
[00:44:49.800 --> 00:44:55.800]   And that's the piece that makes me more nervous.
[00:44:55.800 --> 00:45:01.800]   So specifically going off to Google is, yeah, let's keep an
[00:45:01.800 --> 00:45:03.800]   eye on them and make sure they're behaving well.
[00:45:03.800 --> 00:45:06.800]   They will probably try really hard to behave well because they're
[00:45:06.800 --> 00:45:09.800]   smart and they realize there's a problem, whereas a lot of the
[00:45:09.800 --> 00:45:11.800]   other companies will be doing less of that.
[00:45:11.800 --> 00:45:15.800]   But the real answer is legislation about this and holding them
[00:45:15.800 --> 00:45:17.800]   to account in public.
[00:45:17.800 --> 00:45:21.800]   And the thing that's happening in this realm is, I don't know how
[00:45:21.800 --> 00:45:24.800]   much we've talked about the GDPR so far, a little bit on the
[00:45:24.800 --> 00:45:25.800]   issue.
[00:45:25.800 --> 00:45:28.800]   That's the sort of ticking time bomb that's happening in Europe,
[00:45:28.800 --> 00:45:32.800]   which is actually writing new regulations about what you can do
[00:45:32.800 --> 00:45:36.800]   about profiling and tracking user data and making sure people
[00:45:36.800 --> 00:45:38.800]   have actually consented to their data being tracked.
[00:45:38.800 --> 00:45:41.800]   And that's a big change that's going through at the moment.
[00:45:41.800 --> 00:45:45.800]   And in the UK, everyone I'm talking to is thinking about this
[00:45:45.800 --> 00:45:47.800]   and saying, how do we make our stuff compliant with this?
[00:45:47.800 --> 00:45:50.800]   I mean, in the US, they're still going a bit.
[00:45:50.800 --> 00:45:54.800]   But it's actually, you know, there is legislation that is going
[00:45:54.800 --> 00:45:57.800]   to come into effect next year that has actual teeth in it about
[00:45:57.800 --> 00:45:59.800]   tracking users data in the EU.
[00:45:59.800 --> 00:46:04.800]   Meanwhile, the government admits a plan to microchip the
[00:46:04.800 --> 00:46:05.800]   population.
[00:46:05.800 --> 00:46:06.800]   Oh, no, sorry.
[00:46:06.800 --> 00:46:11.800]   I'm excited.
[00:46:11.800 --> 00:46:12.800]   I'm excited.
[00:46:12.800 --> 00:46:13.800]   This is good story.
[00:46:13.800 --> 00:46:19.800]   So, yeah, that's an interesting conundrum.
[00:46:20.800 --> 00:46:21.800]   I guess.
[00:46:21.800 --> 00:46:25.800]   Doesn't, I'm a bad guy to ask about this stuff because I don't
[00:46:25.800 --> 00:46:26.800]   really care.
[00:46:26.800 --> 00:46:30.800]   But of course, you know, you're absolutely nothing
[00:46:30.800 --> 00:46:31.800]   to get away with it.
[00:46:31.800 --> 00:46:33.800]   And also you gave up on your privacy years ago.
[00:46:33.800 --> 00:46:34.800]   Right.
[00:46:34.800 --> 00:46:35.800]   Right.
[00:46:35.800 --> 00:46:37.800]   Coasting on the other end of this.
[00:46:37.800 --> 00:46:38.800]   Yeah.
[00:46:38.800 --> 00:46:42.800]   So I'm really, I can't use my own feelings about this as a way
[00:46:42.800 --> 00:46:43.800]   to judge it.
[00:46:43.800 --> 00:46:44.800]   No, exactly.
[00:46:44.800 --> 00:46:47.800]   But part of the problem, you know, that is a structural problem
[00:46:47.800 --> 00:46:50.800]   that you do in that a lot of the people who are making the
[00:46:50.800 --> 00:46:53.800]   decisions about this are people who are well off a living in
[00:46:53.800 --> 00:46:56.800]   Silicon Valley and have a fairly comfortable life and haven't
[00:46:56.800 --> 00:46:57.800]   actually hit the issue.
[00:46:57.800 --> 00:46:58.800]   Exactly.
[00:46:58.800 --> 00:46:59.800]   Right.
[00:46:59.800 --> 00:47:00.800]   Yep.
[00:47:00.800 --> 00:47:01.800]   And that's that's the structural thing that they don't actually
[00:47:01.800 --> 00:47:04.800]   have the ability to imagine the problems that you have if you're
[00:47:04.800 --> 00:47:06.800]   They're not getting denied credit.
[00:47:06.800 --> 00:47:07.800]   That's right.
[00:47:07.800 --> 00:47:08.800]   Right.
[00:47:08.800 --> 00:47:09.800]   Yeah.
[00:47:09.800 --> 00:47:10.800]   You don't have access to credit.
[00:47:10.800 --> 00:47:12.800]   You don't have access to banking if you're if you're trying to
[00:47:12.800 --> 00:47:13.800]   do everything in cash.
[00:47:13.800 --> 00:47:16.800]   And, you know, well, that's hard.
[00:47:16.800 --> 00:47:21.800]   But I don't I guess I just saying I don't mind if an advertiser
[00:47:21.800 --> 00:47:25.800]   knows that I bought something based on an ad I saw in a Google
[00:47:25.800 --> 00:47:26.800]   ad.
[00:47:26.800 --> 00:47:30.800]   And if that helps not Google, but if it helps the website that's
[00:47:30.800 --> 00:47:33.800]   running the Google ad, I don't think that's a bad thing.
[00:47:33.800 --> 00:47:37.800]   But again, I'm in the I kind of quasi in the advertising business.
[00:47:37.800 --> 00:47:38.800]   We sell advertising.
[00:47:38.800 --> 00:47:40.800]   That's what kills a bloke.
[00:47:40.800 --> 00:47:43.800]   But I can understand why an advertiser would want to know that.
[00:47:43.800 --> 00:47:45.800]   And I don't feel like, okay, so here's the here's the nub of it.
[00:47:45.800 --> 00:47:48.800]   And I'll let Jeff argue this too, maybe.
[00:47:48.800 --> 00:47:54.800]   But what is the harm in Google connecting these data points?
[00:47:54.800 --> 00:47:59.800]   Well, the the harm is makes it goes up for privacy all the time.
[00:47:59.800 --> 00:48:02.800]   But I think the real question here is that there's this is an
[00:48:02.800 --> 00:48:04.800]   advertiser benefit, a media benefit.
[00:48:04.800 --> 00:48:07.800]   You know, at the same time, up a couple spots in the rundown is
[00:48:07.800 --> 00:48:10.800]   Ray Kurzweil is writing your emails for the first time.
[00:48:10.800 --> 00:48:12.800]   And I think that's a good thing.
[00:48:12.800 --> 00:48:15.800]   But I think the only thing that's going to be the right thing
[00:48:15.800 --> 00:48:17.800]   is that you're going to be able to do that.
[00:48:17.800 --> 00:48:19.800]   And I think that's a good thing.
[00:48:19.800 --> 00:48:21.800]   And I think that's a good thing.
[00:48:21.800 --> 00:48:23.800]   And I think that's a good thing.
[00:48:23.800 --> 00:48:25.800]   And I think that's a good thing.
[00:48:25.800 --> 00:48:27.800]   And I think that's a good thing.
[00:48:27.800 --> 00:48:29.800]   And I think that's a good thing.
[00:48:29.800 --> 00:48:31.800]   And I think that's a good thing.
[00:48:31.800 --> 00:48:33.800]   And I think that's a good thing.
[00:48:33.800 --> 00:48:35.800]   And I think that's a good thing.
[00:48:35.800 --> 00:48:36.800]   And I think that's a good thing.
[00:48:36.800 --> 00:48:38.800]   And I think that's a good thing.
[00:48:38.800 --> 00:48:40.800]   And I think that's a good thing.
[00:48:40.800 --> 00:48:42.800]   Yeah.
[00:48:42.800 --> 00:48:44.800]   Google stop doing ads out of reading emails.
[00:48:44.800 --> 00:48:47.800]   But now they're writing replies for you and I'm using it.
[00:48:47.800 --> 00:48:48.800]   Hell yeah.
[00:48:48.800 --> 00:48:51.800]   No, and it is useful, sure.
[00:48:51.800 --> 00:48:55.800]   So the thing I would look, mathbabe.org, you know,
[00:48:55.800 --> 00:48:56.800]   Kathy O'Neill.
[00:48:56.800 --> 00:48:57.800]   She's written a book.
[00:48:57.800 --> 00:48:58.800]   We've interviewed her.
[00:48:58.800 --> 00:48:59.800]   We're a math associate, yeah.
[00:48:59.800 --> 00:49:00.800]   Yeah.
[00:49:00.800 --> 00:49:02.800]   She's really good on this stuff because she's actually thought
[00:49:02.800 --> 00:49:05.800]   about a depth and written it well in ways people can understand.
[00:49:05.800 --> 00:49:09.800]   And written about the, you know, basically it's model failure.
[00:49:09.800 --> 00:49:13.800]   It's people who are building very naive models and then somehow
[00:49:13.800 --> 00:49:16.800]   getting them baked into the way we experience the world.
[00:49:16.800 --> 00:49:17.800]   Right.
[00:49:17.800 --> 00:49:19.800]   And that's the piece that's wrong with this.
[00:49:19.800 --> 00:49:21.800]   And the answer is not give up modeling.
[00:49:21.800 --> 00:49:23.800]   The answer is give up better models and more,
[00:49:23.800 --> 00:49:25.800]   and have more transparent models.
[00:49:25.800 --> 00:49:28.800]   So the GDPR stuff for me is that I think that's an encouraging step.
[00:49:28.800 --> 00:49:31.800]   Because it's basically saying, okay, you can do this stuff,
[00:49:31.800 --> 00:49:34.800]   but you've got to get people to agree to it and you've got to explain
[00:49:34.800 --> 00:49:35.800]   it where they can actually understand.
[00:49:35.800 --> 00:49:38.800]   So you've got to get consent from people to what kind of data
[00:49:38.800 --> 00:49:40.800]   manipulation you're going to do on their data.
[00:49:40.800 --> 00:49:43.800]   And that is different from, you know, the classic, you know,
[00:49:43.800 --> 00:49:47.800]   Google worldview was, we'll grab all the data and try and make sense of it later.
[00:49:47.800 --> 00:49:52.800]   Because that works for the web and that model was sent into a personal
[00:49:52.800 --> 00:49:56.800]   data as well with the, you know, the obvious, like the drive by Wi-Fi
[00:49:56.800 --> 00:49:59.800]   scraping and things like that that we've talked about before.
[00:49:59.800 --> 00:50:04.800]   And that having some kind of stuff and think about that a bit is like
[00:50:04.800 --> 00:50:09.800]   don't be evil, it's saying think about the consequences of what you're doing
[00:50:09.800 --> 00:50:13.800]   and make sure that you can explain this to the person whose data you're tracking.
[00:50:13.800 --> 00:50:17.800]   And that's, you know, that's so this is very different.
[00:50:17.800 --> 00:50:21.800]   In line with what Kathy O'Neill is saying is not that it's bad to
[00:50:21.800 --> 00:50:23.800]   gather the data nor is it bad to analyze it.
[00:50:23.800 --> 00:50:25.800]   It's just bad to use bad models.
[00:50:25.800 --> 00:50:30.800]   But I don't think Epic is saying that Epic saying no,
[00:50:30.800 --> 00:50:32.800]   no, you shouldn't be collecting this data at all.
[00:50:32.800 --> 00:50:34.800]   But that is also part of this as well.
[00:50:34.800 --> 00:50:37.800]   This goes back to what should you default to?
[00:50:37.800 --> 00:50:38.800]   Right.
[00:50:38.800 --> 00:50:42.800]   You know, there's, if you listen to a match, a and a reductro,
[00:50:42.800 --> 00:50:49.800]   there is the personal is like, you know, toxic ways.
[00:50:49.800 --> 00:50:51.800]   You've got to be careful about how you handle it.
[00:50:51.800 --> 00:50:53.800]   You've got to make sure you don't spill it anywhere.
[00:50:53.800 --> 00:50:55.800]   There's a lot of overhead to that.
[00:50:55.800 --> 00:50:59.800]   And you do you really want to be dealing with this if you don't actually understand it.
[00:50:59.800 --> 00:51:00.800]   There was an example in the UK.
[00:51:00.800 --> 00:51:02.800]   Well, so kick Kevin.
[00:51:02.800 --> 00:51:09.800]   My example is weather spoons, which is a big pub chain in the UK,
[00:51:09.800 --> 00:51:14.800]   recently deleted their entire email database because they were worried
[00:51:14.800 --> 00:51:15.800]   there might be a breach.
[00:51:15.800 --> 00:51:17.800]   They're worried about the GDPR stuff coming.
[00:51:17.800 --> 00:51:20.800]   And actually most of their business people walking through the door with cash
[00:51:20.800 --> 00:51:23.800]   and having an email list was not giving them much benefit from that.
[00:51:23.800 --> 00:51:29.800]   So from their point of view, it's like this isn't worth the pain of this.
[00:51:29.800 --> 00:51:32.800]   And which is very different from this is what another is.
[00:51:32.800 --> 00:51:37.800]   All I want to say is I think the examples you just gave, it's the Dana Boyd rule.
[00:51:37.800 --> 00:51:42.800]   Why is MIT's bandwidth not working?
[00:51:42.800 --> 00:51:46.800]   Of all the places.
[00:51:46.800 --> 00:51:47.800]   You take over for Jeff.
[00:51:47.800 --> 00:51:49.800]   I'll be substitute.
[00:51:49.800 --> 00:51:52.800]   I'd be substitute Jeff, Matt. That's good.
[00:51:52.800 --> 00:51:58.800]   Okay. If I were substitute Jeff, like I understand probably from Google's perspective,
[00:51:58.800 --> 00:52:00.800]   they think their advertising is very effective.
[00:52:00.800 --> 00:52:04.800]   And so showing that this drives offline sales is something that they would really want to do
[00:52:04.800 --> 00:52:08.800]   so that people don't waste their hundred million dollars of brand advertising,
[00:52:08.800 --> 00:52:10.800]   you know, all the stuff that doesn't work.
[00:52:10.800 --> 00:52:11.800]   Right.
[00:52:11.800 --> 00:52:16.800]   But to me it depends on how much of this is in aggregate because I'm very mindful of like this.
[00:52:16.800 --> 00:52:18.800]   Google says it's all in aggregate by the way.
[00:52:18.800 --> 00:52:21.800]   Google says it's not there's no individual information being exposed.
[00:52:21.800 --> 00:52:26.800]   That's good because, you know, I'm just mindful, like if I'm channeling Stacey,
[00:52:26.800 --> 00:52:29.800]   here we have a group of four white guys.
[00:52:29.800 --> 00:52:35.800]   And yet if you think about an ad like bail bonds DC, you know, if you can track who clicks
[00:52:35.800 --> 00:52:40.800]   on that and then see what the offline usage of that, then you start to learn something about
[00:52:40.800 --> 00:52:41.800]   people that are vulnerable.
[00:52:41.800 --> 00:52:45.800]   And I would, that's where it edges into something that I would worry about.
[00:52:45.800 --> 00:52:47.800]   So if they're only doing aggregate data, then that makes sense.
[00:52:47.800 --> 00:52:48.800]   So hearing, okay.
[00:52:48.800 --> 00:52:55.800]   So I'll raise the issue there, which is the generally agreed wisdom that there's no such thing
[00:52:55.800 --> 00:53:02.800]   as anonymization and that as soon as you're aggregating the data, you can't really anonymize
[00:53:02.800 --> 00:53:06.800]   the data is you do reject that, Matt.
[00:53:06.800 --> 00:53:07.800]   You probably have more experience.
[00:53:07.800 --> 00:53:10.800]   That's Jeff Conestroy this week, wasn't it?
[00:53:10.800 --> 00:53:12.800]   Somebody set themselves up, I want to turn it on the story.
[00:53:12.800 --> 00:53:17.800]   Somebody set themselves up as a data broker and got a lot of consumer data, I think in Germany,
[00:53:17.800 --> 00:53:24.800]   which Jeff would enjoy, and then identified politicians by looking for their names in the
[00:53:24.800 --> 00:53:26.800]   data because this happened over and over.
[00:53:26.800 --> 00:53:29.800]   They had such URLs, things like that.
[00:53:29.800 --> 00:53:30.800]   Yeah.
[00:53:30.800 --> 00:53:36.800]   New York Magazine had an article quoting the Guardian story, "3 billion URLs from 3 million
[00:53:36.800 --> 00:53:40.800]   German users in a database.
[00:53:40.800 --> 00:53:44.800]   These researchers acquired it by pretending to be a marketing company."
[00:53:44.800 --> 00:53:45.800]   That's the one, yeah.
[00:53:45.800 --> 00:53:46.800]   Yeah.
[00:53:46.800 --> 00:53:50.800]   And they demonstrated that it was not so difficult to de-anonymize it.
[00:53:50.800 --> 00:53:53.800]   And we've seen this before many times.
[00:53:53.800 --> 00:53:54.800]   Right.
[00:53:54.800 --> 00:54:00.800]   So then, okay Matt, so I agree with you, if it's an aggregate, what's the harm?
[00:54:00.800 --> 00:54:03.800]   I mean, we look at statistics all the time.
[00:54:03.800 --> 00:54:06.800]   And it's funny because there was a great post on Medium.
[00:54:06.800 --> 00:54:10.800]   I'll see if I can find it about privacy that pointed out the first US census was posted
[00:54:10.800 --> 00:54:15.800]   publicly, everything that was known in the US census, but that was more so people could
[00:54:15.800 --> 00:54:17.800]   check to make sure it was accurate.
[00:54:17.800 --> 00:54:18.800]   It's open sourced.
[00:54:18.800 --> 00:54:20.800]   It was open sourced.
[00:54:20.800 --> 00:54:25.800]   Well, they had similar hustings but getting them as well, didn't they?
[00:54:25.800 --> 00:54:30.800]   Yeah, our conception of privacy, human conception of privacy has changed considerably over the
[00:54:30.800 --> 00:54:31.800]   years.
[00:54:31.800 --> 00:54:33.800]   This was actually a really good post about the history of privacy.
[00:54:33.800 --> 00:54:34.800]   See if I can find it.
[00:54:34.800 --> 00:54:35.800]   From the auditor?
[00:54:35.800 --> 00:54:36.800]   Yeah.
[00:54:36.800 --> 00:54:37.800]   Yeah.
[00:54:37.800 --> 00:54:38.800]   You saw it?
[00:54:38.800 --> 00:54:39.800]   No, from, yeah.
[00:54:39.800 --> 00:54:46.200]   The birth and death of privacy, 3,000 years of history, told through 46 images by Greg
[00:54:46.200 --> 00:54:53.200]   Ferenstein.
[00:54:53.200 --> 00:54:59.200]   It really showed that what we think of as kind of a human right and a human need was really
[00:54:59.200 --> 00:55:03.200]   not acknowledged as either a need or a right until fairly recently.
[00:55:03.200 --> 00:55:09.280]   For instance, people didn't even read silently until 1215 when the church mandated confessions
[00:55:09.280 --> 00:55:12.480]   for the masses.
[00:55:12.480 --> 00:55:17.800]   People shared beds until around 1700 because they were so expensive.
[00:55:17.800 --> 00:55:22.480]   In fact, it was a problem in hospitals because they were having all the patients like 12
[00:55:22.480 --> 00:55:25.680]   to a bed.
[00:55:25.680 --> 00:55:29.720]   Vint Cerf says privacy may, and I remember him talking about this, may actually be an
[00:55:29.720 --> 00:55:30.720]   anomaly.
[00:55:30.720 --> 00:55:35.280]   This might be something we only now have started thinking about.
[00:55:35.280 --> 00:55:40.880]   But we assume that this forever has been how it is.
[00:55:40.880 --> 00:55:43.880]   It's really well worth reading this article, at least to talk about it.
[00:55:43.880 --> 00:55:45.680]   It is thinking on this.
[00:55:45.680 --> 00:55:46.680]   Yeah.
[00:55:46.680 --> 00:55:47.680]   Yeah.
[00:55:47.680 --> 00:55:49.680]   And it's easy to read because there's lots of pictures.
[00:55:49.680 --> 00:55:51.680]   I like that.
[00:55:51.680 --> 00:55:55.880]   In video, this is a video from a movie called Beowulf.
[00:55:55.880 --> 00:55:56.880]   Oh, it's not available.
[00:55:56.880 --> 00:55:57.880]   They pulled it down.
[00:55:57.880 --> 00:56:01.080]   Of all the people sleeping together in the hut.
[00:56:01.080 --> 00:56:04.840]   There's some adult images in here, by the way.
[00:56:04.840 --> 00:56:06.280]   This is 3D Beowulf?
[00:56:06.280 --> 00:56:09.880]   Yeah, the ugly, horrible 3D Beowulf.
[00:56:09.880 --> 00:56:10.880]   You know what?
[00:56:10.880 --> 00:56:14.880]   I think Greg is just trying to make this exciting.
[00:56:14.880 --> 00:56:22.520]   But anyway, so, but let's get back to this issue.
[00:56:22.520 --> 00:56:25.080]   Do you feel mad as a data scientist?
[00:56:25.080 --> 00:56:29.600]   I'm sure that that's some of your training that you can aggregate data, anonymous, anonymize
[00:56:29.600 --> 00:56:32.160]   it and use it effectively.
[00:56:32.160 --> 00:56:38.520]   I think probably what Google is after, my guess is the top line, you know, which is,
[00:56:38.520 --> 00:56:43.200]   you know, 70% offline purchases are influenced in some way.
[00:56:43.200 --> 00:56:47.760]   And I suspect that is the most effective thing for what they're trying to do.
[00:56:47.760 --> 00:56:52.280]   And I would trust that they would be trying to combine this data in an ethical way.
[00:56:52.280 --> 00:56:54.840]   It certainly, nobody doubts that that's what Google's after.
[00:56:54.840 --> 00:57:01.400]   The issue is do they inadvertently leak information like bail bonds, people who go to bail bonds
[00:57:01.400 --> 00:57:02.400]   men inadvertently?
[00:57:02.400 --> 00:57:08.240]   Is that information potentially inadvertently leaked in this process?
[00:57:08.240 --> 00:57:11.440]   Yeah, I'd have to look into that more to have a strong opinion.
[00:57:11.440 --> 00:57:15.800]   But it is the case that a lot of the times you think you can anonymize data and it turns
[00:57:15.800 --> 00:57:20.000]   out people come up with a really creative way to slice it in a different way and then
[00:57:20.000 --> 00:57:21.240]   they de-anonymize it.
[00:57:21.240 --> 00:57:22.240]   Yes.
[00:57:22.240 --> 00:57:23.240]   But that's also the issue.
[00:57:23.240 --> 00:57:28.520]   The cost of not allowing this, that at some point media is going to have to prove its
[00:57:28.520 --> 00:57:29.520]   value to advertisers.
[00:57:29.520 --> 00:57:30.840]   And this is a way to do that.
[00:57:30.840 --> 00:57:32.560]   It's a holy grail.
[00:57:32.560 --> 00:57:37.320]   And to have advertisers support for so much that we love in media.
[00:57:37.320 --> 00:57:39.800]   It's maybe necessary at some level.
[00:57:39.800 --> 00:57:40.800]   Right.
[00:57:40.800 --> 00:57:45.640]   Well, and it's funny, it's a holy grail for digital advertising companies like ours.
[00:57:45.640 --> 00:57:50.920]   It is exactly what television and radio don't want you to do because they don't really want
[00:57:50.920 --> 00:57:55.280]   you to know how few of your ads are actually doing anything at all.
[00:57:55.280 --> 00:57:56.280]   Yeah.
[00:57:56.280 --> 00:57:57.280]   So.
[00:57:57.280 --> 00:58:00.280]   But the other part of this is in order to do this well, you have to have enough data
[00:58:00.280 --> 00:58:02.200]   points to do realistic stats.
[00:58:02.200 --> 00:58:06.120]   You can't do A/B testing with that enough data to know if there's a significant or
[00:58:06.120 --> 00:58:07.120]   not.
[00:58:07.120 --> 00:58:09.280]   And you have to acknowledge big data is going to happen.
[00:58:09.280 --> 00:58:10.280]   It's happening.
[00:58:10.280 --> 00:58:11.280]   It's done.
[00:58:11.280 --> 00:58:13.720]   There's no turning clock back on that.
[00:58:13.720 --> 00:58:18.360]   No, but the thing is, you know, the problem is that all this media stuff is parallel distributed.
[00:58:18.360 --> 00:58:24.120]   So unless you are actually at very large scale, you're not going to be able to extract good
[00:58:24.120 --> 00:58:26.120]   enough data to get an optimization out of it.
[00:58:26.120 --> 00:58:27.120]   Yeah.
[00:58:27.120 --> 00:58:28.120]   That is the challenge.
[00:58:28.120 --> 00:58:32.680]   If you've only got a few hundred referrals, you can't really do much with that because
[00:58:32.680 --> 00:58:35.360]   that's not enough to do any breakdown on it.
[00:58:35.360 --> 00:58:36.360]   Right.
[00:58:36.360 --> 00:58:41.680]   Because if you get a few hundred people buying four cars for the show, then we're doing well.
[00:58:41.680 --> 00:58:42.680]   Right.
[00:58:42.680 --> 00:58:44.160]   Hey, Ford was very happy.
[00:58:44.160 --> 00:58:46.320]   They were very happy.
[00:58:46.320 --> 00:58:52.440]   But you know, actually, I always end up talking about our business on this show.
[00:58:52.440 --> 00:58:56.040]   But just a little peek behind the scenes, the way you do that, if you're Ford or some
[00:58:56.040 --> 00:59:01.760]   other proctor and gamble brand advertiser is you with research, you call people.
[00:59:01.760 --> 00:59:05.440]   Do you remember, do you ever listen to a show called, you know, and they'll give you five
[00:59:05.440 --> 00:59:06.440]   shows?
[00:59:06.440 --> 00:59:08.440]   Do you remember any of the advertisers on there?
[00:59:08.440 --> 00:59:11.000]   They call that unaided recall.
[00:59:11.000 --> 00:59:14.400]   And if you get a high score, then it worked.
[00:59:14.400 --> 00:59:16.280]   They can't measure sales.
[00:59:16.280 --> 00:59:19.600]   It's too big a company to measure sales.
[00:59:19.600 --> 00:59:25.360]   Google has actually, this is a good one for Matt too, has is experimenting with the search
[00:59:25.360 --> 00:59:27.960]   console.
[00:59:27.960 --> 00:59:31.200]   What is search console Matt?
[00:59:31.200 --> 00:59:36.200]   If it's what I'm thinking of, there's the Webmaster Tools, which became the Webmaster
[00:59:36.200 --> 00:59:37.200]   console.
[00:59:37.200 --> 00:59:39.760]   And then Webmaster, like who calls them, Webmasters anymore.
[00:59:39.760 --> 00:59:42.200]   So now you can have a search console.
[00:59:42.200 --> 00:59:46.960]   I mean, it's nice to have a channel where Google can give information back to you and
[00:59:46.960 --> 00:59:51.160]   get information from people so that if you are trying to give some structured information,
[00:59:51.160 --> 00:59:52.680]   you know, here's a place where you can do it.
[00:59:52.680 --> 00:59:55.760]   You can make sure there's no syntax errors, that sort of thing.
[00:59:55.760 --> 01:00:02.960]   So this is the original tools.
[01:00:02.960 --> 01:00:05.680]   This is funny on search console.
[01:00:05.680 --> 01:00:06.680]   Wow.
[01:00:06.680 --> 01:00:08.360]   Going back in time a little bit here.
[01:00:08.360 --> 01:00:11.280]   But these kinds of six.
[01:00:11.280 --> 01:00:14.000]   This is probably right about your time, isn't it?
[01:00:14.000 --> 01:00:15.000]   Oh, yeah.
[01:00:15.000 --> 01:00:20.080]   Yeah, Vanessa Fox was a person who, and there was a great team up in Washington state that
[01:00:20.080 --> 01:00:22.280]   worked on this, the initial version.
[01:00:22.280 --> 01:00:23.280]   Yeah.
[01:00:23.280 --> 01:00:25.120]   I remember this stuff.
[01:00:25.120 --> 01:00:27.720]   So they have some, they now have more than two dozen reports.
[01:00:27.720 --> 01:00:30.680]   They've got lots of useful tools.
[01:00:30.680 --> 01:00:36.240]   And they've added two new ones or an extensive redesign to show you more actionable insights,
[01:00:36.240 --> 01:00:40.600]   but are supportive workflow, faster feedback loops between you and Google.
[01:00:40.600 --> 01:00:45.640]   And the new beta features are, I don't know what this any of this means, but since Matt's
[01:00:45.640 --> 01:00:50.640]   here, I'm going to bring it up index coverage report and amp fixing flow.
[01:00:50.640 --> 01:00:54.400]   Somebody's buzzing like crazy.
[01:00:54.400 --> 01:00:55.400]   Who's that?
[01:00:55.400 --> 01:00:56.400]   Is that man?
[01:00:56.400 --> 01:00:57.400]   Not it's me.
[01:00:57.400 --> 01:00:59.880]   Unplug and replug Matt.
[01:00:59.880 --> 01:01:00.880]   Is it me?
[01:01:00.880 --> 01:01:03.680]   I'm going to give you the signal.
[01:01:03.680 --> 01:01:06.920]   Do we hit the hour spot?
[01:01:06.920 --> 01:01:08.760]   Is that what it is?
[01:01:08.760 --> 01:01:09.760]   Could be.
[01:01:09.760 --> 01:01:11.320]   It's 59 minutes into the show.
[01:01:11.320 --> 01:01:13.560]   59 minutes and 40 seconds.
[01:01:13.560 --> 01:01:14.560]   And now we can't hear him.
[01:01:14.560 --> 01:01:15.560]   You say happens.
[01:01:15.560 --> 01:01:16.560]   Uh oh.
[01:01:16.560 --> 01:01:17.560]   You can't hear me?
[01:01:17.560 --> 01:01:18.560]   Now you're back.
[01:01:18.560 --> 01:01:19.560]   Yeah, yeah, yeah.
[01:01:19.560 --> 01:01:20.560]   That was us.
[01:01:20.560 --> 01:01:22.440]   We, I guess we muted you so that you wouldn't buzz us.
[01:01:22.440 --> 01:01:25.880]   So index coverage report shows count of index pages, information.
[01:01:25.880 --> 01:01:29.120]   Oh, this is, so this is, I remember this from Webmaster Tools.
[01:01:29.120 --> 01:01:32.360]   This is like how, what Google's knows about you basically.
[01:01:32.360 --> 01:01:33.360]   Yeah.
[01:01:33.360 --> 01:01:34.360]   Yeah.
[01:01:34.360 --> 01:01:37.280]   How many, how many pages have been crawled and are in Google's index?
[01:01:37.280 --> 01:01:38.280]   Right.
[01:01:38.280 --> 01:01:39.280]   Okay.
[01:01:39.280 --> 01:01:40.280]   That's cool.
[01:01:40.280 --> 01:01:42.240]   And then what is amp fixing flow?
[01:01:42.240 --> 01:01:45.080]   Oh, this is about issues with your site.
[01:01:45.080 --> 01:01:47.920]   Ah, okay.
[01:01:47.920 --> 01:01:48.920]   Fix the amp issue.
[01:01:48.920 --> 01:01:54.120]   Yeah, it looks like they've got to, this is the amp out of it.
[01:01:54.120 --> 01:01:55.120]   Yeah.
[01:01:55.120 --> 01:01:56.120]   God, I hate Skype.
[01:01:56.120 --> 01:01:58.920]   We're just going to shoot Skype right now and put it out of its misery.
[01:01:58.920 --> 01:02:00.400]   Thank you, Microsoft.
[01:02:00.400 --> 01:02:01.400]   Job well done.
[01:02:01.400 --> 01:02:02.400]   Goodbye.
[01:02:02.400 --> 01:02:04.160]   I've actually, Jeff's not using Skype.
[01:02:04.160 --> 01:02:07.400]   He's using another technology called IP DTL and it's just as bad.
[01:02:07.400 --> 01:02:09.040]   So we, you know what?
[01:02:09.040 --> 01:02:10.040]   It did all.
[01:02:10.040 --> 01:02:16.760]   Why did I, why did I think I could do a network of a broadcast network with people over IP
[01:02:16.760 --> 01:02:17.960]   voice over IP?
[01:02:17.960 --> 01:02:18.960]   Why did I think that?
[01:02:18.960 --> 01:02:21.480]   Do you go through this at the other shows or is it just us?
[01:02:21.480 --> 01:02:22.480]   This is me.
[01:02:22.480 --> 01:02:24.320]   Lately it's been happening more with Skype.
[01:02:24.320 --> 01:02:25.920]   It's been happening a lot with Skype.
[01:02:25.920 --> 01:02:26.920]   Really?
[01:02:26.920 --> 01:02:29.800]   Actually, you know, I mean, it would, in the early days of Twitter, it was the worst.
[01:02:29.800 --> 01:02:30.800]   It was horrible.
[01:02:30.800 --> 01:02:38.840]   I spent hour, I was spent hours trying to fix the audio after every show.
[01:02:38.840 --> 01:02:46.600]   Facebook is tweaking its mobile news feed to prioritize fast loading pages.
[01:02:46.600 --> 01:02:49.280]   Oh, hello.
[01:02:49.280 --> 01:02:52.880]   Google's done that, of course, with its search results.
[01:02:52.880 --> 01:02:57.760]   So are they going to support AMP pages or are they just going to support the ones that
[01:02:57.760 --> 01:02:58.760]   are interesting?
[01:02:58.760 --> 01:02:59.760]   Yeah.
[01:02:59.760 --> 01:03:00.760]   Fair random markup.
[01:03:00.760 --> 01:03:03.560]   Even Facebook's Instant Articles is adopting AMP.
[01:03:03.560 --> 01:03:09.680]   Yeah, you can, you can know, right one, one's published twice.
[01:03:09.680 --> 01:03:12.920]   Facebook says we've heard from people that it's frustrating to click on a link that leads
[01:03:12.920 --> 01:03:14.320]   to a slow loading webpage.
[01:03:14.320 --> 01:03:15.320]   No kidding.
[01:03:15.320 --> 01:03:16.320]   Yeah, I think.
[01:03:16.320 --> 01:03:20.120]   In fact, even more broadly on the internet, we've found that when people have to wait
[01:03:20.120 --> 01:03:23.840]   for a site to load for too long, they abandoned what they were clicking on altogether.
[01:03:23.840 --> 01:03:24.840]   Yep.
[01:03:24.840 --> 01:03:28.920]   As many as 40% of website visitors abandoned that site after three seconds.
[01:03:28.920 --> 01:03:32.760]   God, I bet you that I would love to see that number over time.
[01:03:32.760 --> 01:03:35.520]   Like was it five seconds, 10 years ago?
[01:03:35.520 --> 01:03:36.520]   Is it four seconds?
[01:03:36.520 --> 01:03:37.520]   Yeah.
[01:03:37.520 --> 01:03:40.040]   Is it going to be one second next year?
[01:03:40.040 --> 01:03:42.560]   I bet that number is going down.
[01:03:42.560 --> 01:03:45.080]   We are so impatient.
[01:03:45.080 --> 01:03:50.160]   So the social network will soon take into account the estimated load time of a webpage
[01:03:50.160 --> 01:03:58.680]   that someone clicks to from a newsfeed and prefer pages that load faster.
[01:03:58.680 --> 01:04:03.080]   I'm sure it's a second order effect, but it's still probably pretty useful in the sense
[01:04:03.080 --> 01:04:07.760]   that this is something like everybody would prefer a faster website over a slower website,
[01:04:07.760 --> 01:04:12.360]   you know, and it pushes all the sites of the web in order to behave better.
[01:04:12.360 --> 01:04:16.280]   It's not like that has a particular ideological bent or anything like that.
[01:04:16.280 --> 01:04:18.880]   It's like, no, everybody wants the web to be faster.
[01:04:18.880 --> 01:04:23.320]   So it seems like a healthy thing to push those or, you know, to have encryption so
[01:04:23.320 --> 01:04:26.360]   that everybody knows, you know, their connection is secure.
[01:04:26.360 --> 01:04:27.360]   It's just good behavior.
[01:04:27.360 --> 01:04:30.860]   But he is a little bit in this age of net neutrality, a little bit of a disadvantage to
[01:04:30.860 --> 01:04:36.360]   sites that don't have the resources or on shared servers.
[01:04:36.360 --> 01:04:40.360]   They may be saying something very important that deserves to show up and search results
[01:04:40.360 --> 01:04:46.520]   or deserves to show up in the newsfeed, but they can't be as fast as, you know, the
[01:04:46.520 --> 01:04:49.600]   news corp because they don't have the resources, right?
[01:04:49.600 --> 01:04:57.480]   Well, you can know, what junk's up the pages so much as ads and trackers and other things.
[01:04:57.480 --> 01:05:00.040]   So you could you can create a simple webpage.
[01:05:00.040 --> 01:05:03.320]   Oh, that's the easy part, no?
[01:05:03.320 --> 01:05:04.320]   Yeah.
[01:05:04.320 --> 01:05:09.360]   I mean, you could you mentioned the webmaster, Google has a talk with Lighthouse.
[01:05:09.360 --> 01:05:10.360]   It's quite good at this.
[01:05:10.360 --> 01:05:13.080]   You throw it at your website and it says, no, that's a bit slow.
[01:05:13.080 --> 01:05:15.600]   Have you tried changing this to this?
[01:05:15.600 --> 01:05:19.280]   And it's like the webmaster would have more focus, a more speech-focused version of that
[01:05:19.280 --> 01:05:24.560]   rather than are you checking the boxes on our indexing thing.
[01:05:24.560 --> 01:05:27.720]   And it will tell you to make a progressive web app because that's, you know, part of
[01:05:27.720 --> 01:05:28.720]   what its job is.
[01:05:28.720 --> 01:05:33.680]   But it will, but it will actually give you a prioritised list of these images loading
[01:05:33.680 --> 01:05:39.200]   really slowly or these images are really big, which make them smaller or, you know,
[01:05:39.200 --> 01:05:41.240]   this CSS is loading really slowly.
[01:05:41.240 --> 01:05:43.080]   Do you want to check where you're serving that from?
[01:05:43.080 --> 01:05:45.240]   It will actually do that kind of profiling for you.
[01:05:45.240 --> 01:05:49.120]   Let me just let me just try Lighthouse on our on our page.
[01:05:49.120 --> 01:05:50.120]   It's a Chrome plugin.
[01:05:50.120 --> 01:05:51.120]   Yeah, I got it.
[01:05:51.120 --> 01:05:54.960]   I'm just worried that it's going to be really, really bad news.
[01:05:54.960 --> 01:05:58.200]   Well, it does load it three times as it loads it like with different windows.
[01:05:58.200 --> 01:06:03.320]   Yeah, that's the that's the mobile version because it's a small, small window.
[01:06:03.320 --> 01:06:04.320]   Oh, God.
[01:06:04.320 --> 01:06:05.320]   Oh, I'm depressed.
[01:06:05.320 --> 01:06:06.320]   Oh, yeah.
[01:06:06.320 --> 01:06:09.040]   You need to do some image variants.
[01:06:09.040 --> 01:06:12.960]   Oh, Lord above or above.
[01:06:12.960 --> 01:06:14.960]   Now check Matt's vet site.
[01:06:14.960 --> 01:06:15.960]   Yeah.
[01:06:15.960 --> 01:06:16.960]   Wow.
[01:06:16.960 --> 01:06:19.840]   Yeah, but the vet.gov is doing great.
[01:06:19.840 --> 01:06:25.960]   Well, and there's probably some adoption curve where you can say in the early days,
[01:06:25.960 --> 01:06:28.600]   you don't want to, you know, speed to be that strong of a factor.
[01:06:28.600 --> 01:06:31.120]   It's definitely a second or even third order effect.
[01:06:31.120 --> 01:06:34.760]   But even including it as a factor makes people say, you know what?
[01:06:34.760 --> 01:06:36.320]   I should start paying attention to this.
[01:06:36.320 --> 01:06:40.640]   So even if it doesn't get that much weight in Facebook's algorithm to have people see
[01:06:40.640 --> 01:06:44.440]   that and hear that means that now it's on their mind, it's on their radar.
[01:06:44.440 --> 01:06:47.640]   And they're like, well, I can't just wait 30 seconds for my pages to load.
[01:06:47.640 --> 01:06:49.480]   I have to at least think about that.
[01:06:49.480 --> 01:06:52.440]   Well, I got a 97% for accessibility.
[01:06:52.440 --> 01:06:53.440]   That's good.
[01:06:53.440 --> 01:06:59.280]   But performance only 69 and like everything else sucks.
[01:06:59.280 --> 01:07:00.280]   I didn't register.
[01:07:00.280 --> 01:07:01.280]   I'm going to get rid of that site.
[01:07:01.280 --> 01:07:02.440]   Oh, you don't even want to know.
[01:07:02.440 --> 01:07:04.800]   Does not respond with a 200 when offline.
[01:07:04.800 --> 01:07:08.240]   I don't know what that user will not be prompted to install the web app.
[01:07:08.240 --> 01:07:10.960]   What is not configured for a custom splash.
[01:07:10.960 --> 01:07:12.560]   That's the AMSTF.
[01:07:12.560 --> 01:07:13.880]   Just called the scroll beyond that.
[01:07:13.880 --> 01:07:14.760]   Oh, yeah.
[01:07:14.760 --> 01:07:15.280]   But I don't.
[01:07:15.280 --> 01:07:16.080]   Progressive web app stuff is it.
[01:07:16.080 --> 01:07:18.480]   No, progressive web app stuff, which is good.
[01:07:18.480 --> 01:07:21.440]   But you it isn't the performance tab is the next one.
[01:07:21.440 --> 01:07:22.520]   This is the one I care about.
[01:07:22.520 --> 01:07:23.480]   We wouldn't look at first.
[01:07:23.480 --> 01:07:24.000]   Yeah.
[01:07:24.000 --> 01:07:24.520]   Yeah.
[01:07:24.520 --> 01:07:29.560]   First meaningful pain, 4.7 millis, 4.7, 4.7 seconds.
[01:07:29.560 --> 01:07:30.240]   First and direct.
[01:07:30.240 --> 01:07:32.040]   Actually, that's the guy I got.
[01:07:32.040 --> 01:07:35.520]   I got a five and seconds there.
[01:07:35.520 --> 01:07:36.880]   So maybe it doesn't work.
[01:07:36.880 --> 01:07:37.880]   UK as well.
[01:07:37.880 --> 01:07:39.600]   Yeah, best practices.
[01:07:39.600 --> 01:07:41.000]   Five failed audits.
[01:07:41.000 --> 01:07:43.440]   Oh, Lord, I don't care anymore.
[01:07:43.440 --> 01:07:44.280]   Goodbye.
[01:07:44.280 --> 01:07:46.520]   Goodbye, Lighthouse.
[01:07:46.520 --> 01:07:50.680]   I guess I'm not going to rank up there on Facebook.
[01:07:50.680 --> 01:07:53.160]   I mean, do you worry about about that at all?
[01:07:53.160 --> 01:07:56.600]   I mean, I understand that you can do things to speed up a site.
[01:07:56.600 --> 01:07:57.960]   But.
[01:07:57.960 --> 01:08:03.000]   It's useful to look at these things because it will often say, oh, you've got this one
[01:08:03.000 --> 01:08:04.760]   image there and you're like, oh, that I understand.
[01:08:04.760 --> 01:08:09.120]   Certainly if you have an important to say on your blog, you should probably use Lighthouse
[01:08:09.120 --> 01:08:10.120]   and so forth.
[01:08:10.120 --> 01:08:14.360]   I just worry that algorithms will prioritize pages that load in less than two seconds and
[01:08:14.360 --> 01:08:17.520]   that will leave out a lot of the most interesting, valuable.
[01:08:17.520 --> 01:08:18.800]   That's a good point.
[01:08:18.800 --> 01:08:23.200]   I'm not as worried about that because like we would get questions about that at search
[01:08:23.200 --> 01:08:27.600]   conferences at Google and somebody would say, well, my website takes five seconds to
[01:08:27.600 --> 01:08:33.400]   load and a lot of what people don't realize is some web pages take 60 seconds to load.
[01:08:33.400 --> 01:08:34.400]   We have seen.
[01:08:34.400 --> 01:08:35.400]   Yeah.
[01:08:35.400 --> 01:08:39.360]   Like I think one of the reasons healthcare.gov looked like or some sites looked like they
[01:08:39.360 --> 01:08:44.320]   were broken is we recently ran into a website where it took five minutes for the page to
[01:08:44.320 --> 01:08:45.320]   load.
[01:08:45.320 --> 01:08:47.400]   So of course, everybody was like, well, it's not working.
[01:08:47.400 --> 01:08:50.560]   So I'll just reload, which then just made things worse.
[01:08:50.560 --> 01:08:54.320]   So people don't realize just how bad some websites can be.
[01:08:54.320 --> 01:08:58.840]   So maybe there's something that would say if you're more than 30 seconds to load or 25
[01:08:58.840 --> 01:09:03.640]   seconds to load, then okay, we ding you by some small amount so that we look for better
[01:09:03.640 --> 01:09:04.640]   alternatives.
[01:09:04.640 --> 01:09:10.240]   You should ask Joe Ito about this, Jeff, while you're there at the MIT's Media Lab, Google
[01:09:10.240 --> 01:09:14.120]   and MIT's new machine learning algorithms.
[01:09:14.120 --> 01:09:17.400]   Retouch your photos before you take them.
[01:09:17.400 --> 01:09:18.400]   This is pretty cool.
[01:09:18.400 --> 01:09:19.400]   Whoa.
[01:09:19.400 --> 01:09:23.000]   The algorithm is now so tight.
[01:09:23.000 --> 01:09:26.600]   It can check it can adjust the photo before you take it.
[01:09:26.600 --> 01:09:28.120]   So wow.
[01:09:28.120 --> 01:09:29.120]   So wow.
[01:09:29.120 --> 01:09:31.520]   Oh, so it can do it in the viewfinder.
[01:09:31.520 --> 01:09:34.680]   It's doing it the whole time you're looking at whatever you're looking in case you take
[01:09:34.680 --> 01:09:35.880]   a picture.
[01:09:35.880 --> 01:09:36.880]   Yeah.
[01:09:36.880 --> 01:09:37.880]   Wow.
[01:09:37.880 --> 01:09:40.800]   Computational photography is amazing.
[01:09:40.800 --> 01:09:43.800]   I don't agree, however, with Vic Gundotra.
[01:09:43.800 --> 01:09:45.960]   This is fascinating.
[01:09:45.960 --> 01:09:53.760]   Who says I should ditch my DSLR, my thousands of dollars of cameras because frankly the
[01:09:53.760 --> 01:09:55.480]   iPhone is all you need.
[01:09:55.480 --> 01:09:57.920]   Now this is and never buy it, Android.
[01:09:57.920 --> 01:09:58.920]   Never buy it.
[01:09:58.920 --> 01:09:59.920]   This is.
[01:09:59.920 --> 01:10:04.640]   Oh, now remember, okay, the story of Vic Gundotra as he worked at Microsoft worked then at
[01:10:04.640 --> 01:10:11.760]   Google working with Apple on the Google Apps for the iPhone was apparently a great advocate
[01:10:11.760 --> 01:10:17.560]   for Google and social and prodded Larry Page till he set up Google+.
[01:10:17.560 --> 01:10:20.320]   Then left, he's currently at Cardia, which is one of the most.
[01:10:20.320 --> 01:10:22.280]   Well, he was also kind of Mr. Mobile.
[01:10:22.280 --> 01:10:23.280]   Mr. Mobile?
[01:10:23.280 --> 01:10:24.280]   At Google, too.
[01:10:24.280 --> 01:10:25.280]   In between.
[01:10:25.280 --> 01:10:26.280]   Then I left out of stage.
[01:10:26.280 --> 01:10:30.000]   And then he left and he's founded Cardia, which we've talked about.
[01:10:30.000 --> 01:10:31.000]   We really like.
[01:10:31.000 --> 01:10:32.000]   We love.
[01:10:32.000 --> 01:10:35.200]   A few devices, medical devices with FDA approval.
[01:10:35.200 --> 01:10:36.200]   He posted.
[01:10:36.200 --> 01:10:37.200]   Okay.
[01:10:37.200 --> 01:10:40.800]   So I'm thinking he's throwing shade at his old employer.
[01:10:40.800 --> 01:10:45.160]   Because first of all, he posted this not on Google+, but on Facebook, right?
[01:10:45.160 --> 01:10:48.000]   And then he says, I love my iPhone so much.
[01:10:48.000 --> 01:10:53.760]   I'm getting rid of my DSLR and one should never use an Android phone again.
[01:10:53.760 --> 01:10:55.640]   He added that in the comments.
[01:10:55.640 --> 01:10:57.240]   He was goaded into it.
[01:10:57.240 --> 01:10:59.000]   But yeah, Scobble was good.
[01:10:59.000 --> 01:11:00.000]   He didn't want to.
[01:11:00.000 --> 01:11:04.880]   Scobble was the one who said, oh, I gave my expensive Canon systems to some filmmakers
[01:11:04.880 --> 01:11:05.960]   just because of this.
[01:11:05.960 --> 01:11:07.520]   I love the show.
[01:11:07.520 --> 01:11:13.960]   Of course, and he's showing off two pictures of his daughters, Vixdaughters, using the
[01:11:13.960 --> 01:11:15.960]   portrait feature in the iPhone.
[01:11:15.960 --> 01:11:21.440]   But as many have pointed out, portrait does a terrible job.
[01:11:21.440 --> 01:11:27.680]   It's impressive if you're not a pro or pixel peeping or really paying attention.
[01:11:27.680 --> 01:11:33.960]   The dot-ner hair is strangely out of focus in this picture is just one example.
[01:11:33.960 --> 01:11:40.080]   There was, he created quite a storm and I loved reading the, yeah, there's one response
[01:11:40.080 --> 01:11:41.920]   from Android Central.
[01:11:41.920 --> 01:11:45.080]   But I loved reading the comments back and forth.
[01:11:45.080 --> 01:11:48.280]   I mean, as you said, Scobble completely agreed there were a number of people who said, are
[01:11:48.280 --> 01:11:49.280]   you kidding?
[01:11:49.280 --> 01:11:50.760]   There were some other prominent people in that argument.
[01:11:50.760 --> 01:11:54.600]   Yeah, Pixel has a far better camera than the iPhone and I think many agree.
[01:11:54.600 --> 01:11:56.200]   The Pixel on the Soul Tastes good pictures.
[01:11:56.200 --> 01:11:59.280]   I've been taking some very pleasant pictures with this thing.
[01:11:59.280 --> 01:12:03.160]   Seems like Vixd's biggest interest here was in iPhones, portrait mode.
[01:12:03.160 --> 01:12:09.000]   But I think the point was made that with two lenses, the iPhone 7 Plus can do things that
[01:12:09.000 --> 01:12:12.400]   a single lens camera like the Pixel XL can't do.
[01:12:12.400 --> 01:12:13.400]   I don't know.
[01:12:13.400 --> 01:12:17.400]   Yeah, I think that's going to, I've been writing about that for years.
[01:12:17.400 --> 01:12:20.600]   Sure, more lenses helps because then you can do synthetic average stuff.
[01:12:20.600 --> 01:12:21.600]   It's very cool.
[01:12:21.600 --> 01:12:25.600]   The real takeaway here is how powerful computational photography is, I think.
[01:12:25.600 --> 01:12:27.280]   Yeah, and that's a more true.
[01:12:27.280 --> 01:12:28.280]   Yes, yes.
[01:12:28.280 --> 01:12:33.120]   And as we throw more sensors, we're going to be having more sensors on our phones.
[01:12:33.120 --> 01:12:35.680]   Over time, for lots of reasons.
[01:12:35.680 --> 01:12:38.800]   And they get cheaper and cheaper and they're going to do this for more sense.
[01:12:38.800 --> 01:12:41.120]   And the MIT thing is part of that.
[01:12:41.120 --> 01:12:45.080]   But even just the way HDR works now is like that too.
[01:12:45.080 --> 01:12:51.280]   The stuff that this phone does with HDR, because it can do it quick enough that there's no
[01:12:51.280 --> 01:12:54.040]   motion blur, is very impressive.
[01:12:54.040 --> 01:12:55.040]   Yeah.
[01:12:55.040 --> 01:13:01.760]   Here's a picture posted by a photographer Matthias Appel from his Nikon D7000 DSLR.
[01:13:01.760 --> 01:13:06.680]   He says to Vic, well, then it should be no problem to recreate this with your iPhone.
[01:13:06.680 --> 01:13:08.480]   Is that a lemur?
[01:13:08.480 --> 01:13:11.600]   I don't know what it is, but it is an amazing shot.
[01:13:11.600 --> 01:13:13.480]   And you probably couldn't do that with the camera.
[01:13:13.480 --> 01:13:14.480]   And Selena with everyone.
[01:13:14.480 --> 01:13:16.480]   Yeah, long zoom.
[01:13:16.480 --> 01:13:18.760]   So, Matt, you've been so dawg-ed.
[01:13:18.760 --> 01:13:19.760]   Yeah.
[01:13:19.760 --> 01:13:24.640]   I miss dog fooding so much, but you know, I still have my Pixel XL.
[01:13:24.640 --> 01:13:30.280]   I just offer out one computational photography idea, which I have not had time to do, which
[01:13:30.280 --> 01:13:37.680]   is if you can control the focus plane in software from your camera, you can imagine
[01:13:37.680 --> 01:13:40.160]   marching your focus plane forward.
[01:13:40.160 --> 01:13:41.160]   Right.
[01:13:41.160 --> 01:13:45.800]   And basically doing a 3D reconstruction of a scene using only the regular camera.
[01:13:45.800 --> 01:13:48.760]   So if something had enough stuff, you could actually do that.
[01:13:48.760 --> 01:13:53.880]   So if somebody wants to write a fun app, just cycle through the focal planes, see what
[01:13:53.880 --> 01:13:56.120]   is at most focus at each range.
[01:13:56.120 --> 01:13:59.720]   And you could probably reconstruct a poor man's 3D version of a scene.
[01:13:59.720 --> 01:14:05.960]   Or do what the Lightro does, which is a very expensive camera that effectively does that
[01:14:05.960 --> 01:14:09.880]   and allows you to choose what part is in focus after the fact.
[01:14:09.880 --> 01:14:13.440]   Well, when we go to the Facebook, we're showing an effect, too.
[01:14:13.440 --> 01:14:14.440]   Right.
[01:14:14.440 --> 01:14:18.200]   Was creating a 3D scene from the image.
[01:14:18.200 --> 01:14:21.080]   And that's really interesting, Matt.
[01:14:21.080 --> 01:14:22.080]   You're absolutely right.
[01:14:22.080 --> 01:14:25.560]   You don't need two lenses for that or special depth sensing or anything like that.
[01:14:25.560 --> 01:14:29.680]   You just need to take a lot of pictures fast, which we already are doing.
[01:14:29.680 --> 01:14:33.360]   But Andro really says, "Have that as lens blur for about four years now?"
[01:14:33.360 --> 01:14:34.640]   But now it's actually practical.
[01:14:34.640 --> 01:14:38.240]   It used to be, you had to be really careful to go, "Move it up."
[01:14:38.240 --> 01:14:43.960]   Whereas now I can grab a photo of my microphone and go, "Oh, I want the microphone focus.
[01:14:43.960 --> 01:14:44.960]   I want the glass and focus."
[01:14:44.960 --> 01:14:48.600]   And it just switches between them.
[01:14:48.600 --> 01:14:49.600]   And that's with one lens.
[01:14:49.600 --> 01:14:53.760]   If you had two or three lenses on here, which obviously you will have soon, then you can
[01:14:53.760 --> 01:14:55.600]   do that in real time.
[01:14:55.600 --> 01:14:59.360]   And you could actually do the MIT thing of do it in the viewfinder and pick your focal
[01:14:59.360 --> 01:15:00.360]   plane there.
[01:15:00.360 --> 01:15:02.400]   Because actually these things have depth of field.
[01:15:02.400 --> 01:15:04.320]   They're basically little tiny binoculars.
[01:15:04.320 --> 01:15:06.000]   They've got huge depth of field.
[01:15:06.000 --> 01:15:10.080]   But often what you want is to pull the stuff out from the foreground and the background.
[01:15:10.080 --> 01:15:11.720]   And if you've got more lenses, you can do that.
[01:15:11.720 --> 01:15:16.080]   So yeah, this is obviously coming in next year's, or this year's phones, as they come
[01:15:16.080 --> 01:15:18.080]   out at the end of the year.
[01:15:18.080 --> 01:15:21.280]   We're going to have many more little cameras in there because it's the obvious thing to
[01:15:21.280 --> 01:15:22.360]   do next.
[01:15:22.360 --> 01:15:27.400]   And that will mean, firstly, the obvious thing to do first is to put two in so you can do
[01:15:27.400 --> 01:15:34.040]   actually stereoscopic photography and you can shoot video where you've got a 3D thing.
[01:15:34.040 --> 01:15:37.480]   And everyone's been shipping 3D headsets for two years.
[01:15:37.480 --> 01:15:38.960]   You know, Apple was talking about AR.
[01:15:38.960 --> 01:15:41.040]   The deal was being talking about it for a year.
[01:15:41.040 --> 01:15:42.760]   So that's obviously going to happen too.
[01:15:42.760 --> 01:15:47.480]   But the other part of that is if you just by putting more lenses on there, you can do
[01:15:47.480 --> 01:15:49.680]   this kind of intro process and do some very powerful things with it.
[01:15:49.680 --> 01:15:52.400]   So yeah, that's clearly going to be shipping this year.
[01:15:52.400 --> 01:15:53.400]   Yeah.
[01:15:53.400 --> 01:15:55.600]   You know, it's not just in phones, by the way.
[01:15:55.600 --> 01:15:59.400]   My wife shoots, I shoot a big full frame cameras.
[01:15:59.400 --> 01:16:04.320]   I just got the Sony A9, which is a really interesting, complicated sensor that's stacked,
[01:16:04.320 --> 01:16:05.600]   those little sorts of things.
[01:16:05.600 --> 01:16:07.600]   But my wife shoots a micro four third.
[01:16:07.600 --> 01:16:10.600]   She's using Olympus OM-D.
[01:16:10.600 --> 01:16:14.920]   And it is getting amazingly high quality images.
[01:16:14.920 --> 01:16:20.720]   And I'm convinced this is computational photography from a much smaller sensor.
[01:16:20.720 --> 01:16:26.120]   The clarity, the detail is as good as any full sensor.
[01:16:26.120 --> 01:16:30.720]   So this kinds of computational photography is also migrating into cameras.
[01:16:30.720 --> 01:16:35.560]   And cameras with small sensors, bigger than a phone camera phone sensor, but with small
[01:16:35.560 --> 01:16:39.880]   sensors relative to the big DSLRs are doing remarkable jobs.
[01:16:39.880 --> 01:16:42.360]   This Olympus blows me away every single time.
[01:16:42.360 --> 01:16:44.400]   I can't believe the images.
[01:16:44.400 --> 01:16:48.520]   I mean, you will still get better results with the good lens on the front of it.
[01:16:48.520 --> 01:16:49.520]   Glass is glass.
[01:16:49.520 --> 01:16:51.920]   You can't physics is always going to be there.
[01:16:51.920 --> 01:16:53.920]   But you can't create you with computations.
[01:16:53.920 --> 01:16:56.720]   You can do amazing things with correct for bed.
[01:16:56.720 --> 01:16:57.720]   Absolutely.
[01:16:57.720 --> 01:16:58.720]   Right?
[01:16:58.720 --> 01:16:59.720]   Yeah.
[01:16:59.720 --> 01:17:01.720]   And I just put a link in the chat.
[01:17:01.720 --> 01:17:05.440]   The stuff that the HDR does now is just like, okay, I'm going to take a photograph of my
[01:17:05.440 --> 01:17:08.320]   dogs in a cornfield in front of the sunset.
[01:17:08.320 --> 01:17:10.280]   And all of it is exposed.
[01:17:10.280 --> 01:17:11.280]   That's gorgeous.
[01:17:11.280 --> 01:17:12.840]   What a great shot.
[01:17:12.840 --> 01:17:16.640]   And I could not do that with, you know, I could not do that with film without sitting
[01:17:16.640 --> 01:17:20.800]   there for a long time thinking about it or actually bracketing and then mixing it afterwards.
[01:17:20.800 --> 01:17:26.040]   I would just say because if you say all of this is happening on the camera phone, it's
[01:17:26.040 --> 01:17:30.160]   also happening to the same degree on bigger cameras, more expensive cameras, maybe even
[01:17:30.160 --> 01:17:31.160]   to a greater degree.
[01:17:31.160 --> 01:17:32.480]   You're seeing amazing stuff being.
[01:17:32.480 --> 01:17:33.480]   Yes, absolutely.
[01:17:33.480 --> 01:17:34.480]   Yeah.
[01:17:34.480 --> 01:17:38.960]   And also you're suddenly sitting down at, you know, at 4K video resolution as well, which
[01:17:38.960 --> 01:17:41.360]   is the other sort of freaky thing about this.
[01:17:41.360 --> 01:17:44.160]   The stuff that you can do with that now is quite amazing.
[01:17:44.160 --> 01:17:45.160]   Yeah.
[01:17:45.160 --> 01:17:49.240]   I mean, people I think think, well, but the phone is a computer, but absolutely these
[01:17:49.240 --> 01:17:55.040]   days if you're buying a DSLR, you're buying a computer that happens to have a sensor and
[01:17:55.040 --> 01:17:58.480]   pieces of glass in front of it, but it's just as much of a computer.
[01:17:58.480 --> 01:17:59.680]   That's a beautiful shot.
[01:17:59.680 --> 01:18:02.840]   Was that a single shot done in camera HDR?
[01:18:02.840 --> 01:18:05.520]   Let me see what it says.
[01:18:05.520 --> 01:18:06.520]   Hang on.
[01:18:06.520 --> 01:18:08.320]   It was a, I'm pretty sure it was HDR.
[01:18:08.320 --> 01:18:09.320]   Yeah.
[01:18:09.320 --> 01:18:10.320]   Yeah, it's got to be HDR.
[01:18:10.320 --> 01:18:12.120]   I can see in the info here.
[01:18:12.120 --> 01:18:13.120]   Yeah.
[01:18:13.120 --> 01:18:14.120]   Pixel XL.
[01:18:14.120 --> 01:18:15.120]   It's just two.
[01:18:15.120 --> 01:18:16.120]   One two thousandths.
[01:18:16.120 --> 01:18:17.120]   I say 51.
[01:18:17.120 --> 01:18:18.120]   Yeah.
[01:18:18.120 --> 01:18:20.120]   It doesn't, it doesn't actually say what it's HDR.
[01:18:20.120 --> 01:18:21.120]   Yeah.
[01:18:21.120 --> 01:18:25.840]   But I mean, you know, the thing is it has, it by default is HDR auto now.
[01:18:25.840 --> 01:18:28.360]   So we're actually just guess whether it needs it or not.
[01:18:28.360 --> 01:18:29.360]   It's clearly HDR.
[01:18:29.360 --> 01:18:33.000]   I mean, if you look at the lower right corner and compare it to the upper left, the brightness
[01:18:33.000 --> 01:18:34.480]   that's a huge dynamic range.
[01:18:34.480 --> 01:18:35.480]   Yeah.
[01:18:35.480 --> 01:18:38.200]   Much larger than the human eye, I'm sure.
[01:18:38.200 --> 01:18:39.400]   Hey, let's take a little break.
[01:18:39.400 --> 01:18:40.400]   We got lots more.
[01:18:40.400 --> 01:18:43.840]   Kevin Marks is visiting us from Middlesbrough.
[01:18:43.840 --> 01:18:44.840]   UK.
[01:18:44.840 --> 01:18:46.560]   Say that right.
[01:18:46.560 --> 01:18:47.560]   Middlesbrough.
[01:18:47.560 --> 01:18:48.560]   Yeah.
[01:18:48.560 --> 01:18:49.560]   Middlesbrough.
[01:18:49.560 --> 01:18:50.560]   Middlesbrough.
[01:18:50.560 --> 01:18:51.560]   Middlesbrough.
[01:18:51.560 --> 01:18:56.800]   Where he and his poodles have to where he and his poodles have migrated to be closer
[01:18:56.800 --> 01:19:00.040]   to his sons.
[01:19:00.040 --> 01:19:01.040]   It's always a pleasure.
[01:19:01.040 --> 01:19:02.040]   Thank you for joining us.
[01:19:02.040 --> 01:19:03.040]   I appreciate it.
[01:19:03.040 --> 01:19:04.040]   Because I know it's late at night here.
[01:19:04.040 --> 01:19:05.040]   There.
[01:19:05.040 --> 01:19:06.040]   It's almost midnight, right?
[01:19:06.040 --> 01:19:07.640]   We'll get done by midnight.
[01:19:07.640 --> 01:19:08.640]   I promise.
[01:19:08.640 --> 01:19:09.640]   Ah, you're looking 35.
[01:19:09.640 --> 01:19:10.640]   Yeah.
[01:19:10.640 --> 01:19:17.440]   So with this all the way from MIT, Jeff Jarvis, you look like with the lights behind you.
[01:19:17.440 --> 01:19:18.680]   Frankly, it looks like that.
[01:19:18.680 --> 01:19:20.160]   It looks like that.
[01:19:20.160 --> 01:19:22.280]   That headphone could be a halo.
[01:19:22.280 --> 01:19:23.440]   You could be Jesus.
[01:19:23.440 --> 01:19:24.440]   Of course it is.
[01:19:24.440 --> 01:19:25.440]   Yeah.
[01:19:25.440 --> 01:19:26.440]   Yeah.
[01:19:26.440 --> 01:19:32.960]   He's the Jesus of the journalists, Jeff Jarvis, Buzzmachine.com and a professor of journalism.
[01:19:32.960 --> 01:19:38.880]   You got to send this picture to your students at the City University of New York where he
[01:19:38.880 --> 01:19:39.880]   does.
[01:19:39.880 --> 01:19:40.880]   He's just doing this.
[01:19:40.880 --> 01:19:41.880]   And also joining us.
[01:19:41.880 --> 01:19:42.880]   He's all thrown.
[01:19:42.880 --> 01:19:43.880]   Whiteboard during the break.
[01:19:43.880 --> 01:19:51.080]   We're thrilled to have a Mac Cuts of the US Digital Service, USDS.gov where he is doing
[01:19:51.080 --> 01:19:57.280]   great work as the Acting Administrator, helping websites and technology and the government
[01:19:57.280 --> 01:19:58.680]   get better and faster.
[01:19:58.680 --> 01:20:01.880]   And gosh, it's great to see you again.
[01:20:01.880 --> 01:20:03.120]   After it seems like a year.
[01:20:03.120 --> 01:20:05.840]   You're having fun and enjoying yourself.
[01:20:05.840 --> 01:20:08.720]   I wouldn't say it's fun, but it's very meaningful.
[01:20:08.720 --> 01:20:09.720]   It's almost better.
[01:20:09.720 --> 01:20:10.720]   Right?
[01:20:10.720 --> 01:20:11.720]   Fun is overrated.
[01:20:11.720 --> 01:20:15.120]   Fun is like Elon Musk say, I couldn't live on the beach.
[01:20:15.120 --> 01:20:17.240]   I'd go crazy.
[01:20:17.240 --> 01:20:19.440]   I need stimulus.
[01:20:19.440 --> 01:20:22.640]   Satisfaction is fun in the long run.
[01:20:22.640 --> 01:20:23.640]   Right.
[01:20:23.640 --> 01:20:24.640]   It's important work.
[01:20:24.640 --> 01:20:25.640]   Yeah.
[01:20:25.640 --> 01:20:26.640]   You must feel good about that.
[01:20:26.640 --> 01:20:28.480]   How is living in DC, Matt?
[01:20:28.480 --> 01:20:30.160]   DC is a pretty great city.
[01:20:30.160 --> 01:20:32.800]   I haven't been on the Eastern Seaboard in a while.
[01:20:32.800 --> 01:20:35.080]   And so there's a lot to do.
[01:20:35.080 --> 01:20:37.760]   There's good food these days.
[01:20:37.760 --> 01:20:42.040]   And I will say the US Digital Service has a lot of transient people coming from across
[01:20:42.040 --> 01:20:43.040]   the country.
[01:20:43.040 --> 01:20:47.840]   And so we do some fun things from escape rooms to karaoke to game nights.
[01:20:47.840 --> 01:20:48.840]   Oh, no.
[01:20:48.840 --> 01:20:49.840]   That's a good group.
[01:20:49.840 --> 01:20:52.760]   How many people are there at the USDS?
[01:20:52.760 --> 01:20:54.120]   It's a little less than 200.
[01:20:54.120 --> 01:20:55.120]   Oh, that's great.
[01:20:55.120 --> 01:20:56.120]   Yeah.
[01:20:56.120 --> 01:20:57.120]   Yeah.
[01:20:57.120 --> 01:21:00.200]   We're split halfway between different agencies versus headquarters.
[01:21:00.200 --> 01:21:04.360]   We've got groups at Veterans Affairs, Health and Human Services.
[01:21:04.360 --> 01:21:07.840]   So a Department of Homeland Security, the Pentagon, a bunch of different places.
[01:21:07.840 --> 01:21:12.240]   So when you start working with one of these agencies, you send a SWAT team and they get
[01:21:12.240 --> 01:21:15.480]   headquartered over at the agency to do the work.
[01:21:15.480 --> 01:21:16.480]   Yeah.
[01:21:16.480 --> 01:21:18.120]   And are you getting new assignments?
[01:21:18.120 --> 01:21:19.520]   Have things slowed down?
[01:21:19.520 --> 01:21:21.600]   I mean, who's running you?
[01:21:21.600 --> 01:21:24.440]   Are you part of the Department of Commerce?
[01:21:24.440 --> 01:21:25.920]   Who's the--?
[01:21:25.920 --> 01:21:29.440]   So we technically sit in the office of management in the budget, which is in the executive
[01:21:29.440 --> 01:21:30.840]   office of the president.
[01:21:30.840 --> 01:21:31.840]   Yeah.
[01:21:31.840 --> 01:21:36.160]   But what tends to happen is something blows up or something is on fire.
[01:21:36.160 --> 01:21:39.640]   So for example, if military families want to move across the country and that system
[01:21:39.640 --> 01:21:43.960]   is not performing, then we'll come in and say, OK, what can we do to figure out how
[01:21:43.960 --> 01:21:45.120]   to improve that?
[01:21:45.120 --> 01:21:49.400]   And then we also have some engagements that we've been doing for quite a while that are
[01:21:49.400 --> 01:21:53.000]   continuing, that are really important and impactful stuff as well.
[01:21:53.000 --> 01:21:57.120]   USDS just set off its report to Congress a few days ago.
[01:21:57.120 --> 01:22:01.880]   So you can read more about this on the website at usds.gov.
[01:22:01.880 --> 01:22:04.480]   And we are looking for tech folks.
[01:22:04.480 --> 01:22:05.680]   So if you're interested.
[01:22:05.680 --> 01:22:06.680]   Nice.
[01:22:06.680 --> 01:22:07.680]   Absolutely.
[01:22:07.680 --> 01:22:08.680]   Yeah.
[01:22:08.680 --> 01:22:09.680]   Nice.
[01:22:09.680 --> 01:22:13.280]   If I had a good product manager, designer, engineer, like $100 million plus projects, we
[01:22:13.280 --> 01:22:15.120]   could make a difference on right now.
[01:22:15.120 --> 01:22:16.400]   Yeah.
[01:22:16.400 --> 01:22:25.240]   And there's information about how much you've saved our government in IT, dashboard.gov,
[01:22:25.240 --> 01:22:28.880]   and it looks like you're saving us some money, some significant money.
[01:22:28.880 --> 01:22:29.880]   I like that.
[01:22:29.880 --> 01:22:30.880]   I like that a lot.
[01:22:30.880 --> 01:22:31.880]   We're a pretty good value.
[01:22:31.880 --> 01:22:33.560]   But it's not just about saving money.
[01:22:33.560 --> 01:22:34.880]   It's about improving services, right?
[01:22:34.880 --> 01:22:38.200]   No, but if you're going to get budget, you know, you're going to get Congress to fund
[01:22:38.200 --> 01:22:40.120]   you, you got to show them this.
[01:22:40.120 --> 01:22:41.120]   Yeah.
[01:22:41.120 --> 01:22:46.040]   See, the nice technology is one of those areas where the services can get better and they
[01:22:46.040 --> 01:22:47.040]   can get cheaper.
[01:22:47.040 --> 01:22:48.800]   Usually you don't get both of those.
[01:22:48.800 --> 01:22:49.800]   Isn't that nice?
[01:22:49.800 --> 01:22:52.360]   Is the Donald Everdrop by?
[01:22:52.360 --> 01:22:55.960]   I have been in a room with a real two or three times.
[01:22:55.960 --> 01:22:56.960]   Wow.
[01:22:56.960 --> 01:22:59.800]   For example, to see there was the American Tech.
[01:22:59.800 --> 01:23:03.840]   So we work with an office called the Office for American Innovation.
[01:23:03.840 --> 01:23:09.520]   So Jared Kushner and Chris Liddell, who's the former CFO of Microsoft.
[01:23:09.520 --> 01:23:13.960]   And that group of folks absolutely realizes the importance of making sure that technology
[01:23:13.960 --> 01:23:15.360]   works well in the government.
[01:23:15.360 --> 01:23:17.440]   So how politicized is it?
[01:23:17.440 --> 01:23:19.440]   You feel like you're above the fray.
[01:23:19.440 --> 01:23:22.840]   You don't have to really worry about the politics going on.
[01:23:22.840 --> 01:23:24.520]   We're a non-partisan group.
[01:23:24.520 --> 01:23:28.600]   So the one thing that everybody can agree on is government technology should work better.
[01:23:28.600 --> 01:23:32.960]   And we spend way too much and we don't get services that are what you would expect on
[01:23:32.960 --> 01:23:36.880]   a Google or an iPhone or a Facebook website.
[01:23:36.880 --> 01:23:41.480]   And so if you can use your phone and see how good it is and then try to use a government,
[01:23:41.480 --> 01:23:45.520]   you know, piece of technology and see how bad it is, that's something that everybody agrees
[01:23:45.520 --> 01:23:46.800]   needs to work better.
[01:23:46.800 --> 01:23:51.840]   If you go to usds.gov, there's a Join Us button.
[01:23:51.840 --> 01:23:58.160]   And if you are, you know, maybe looking at a sabbatical at your cushy job at Google or
[01:23:58.160 --> 01:24:02.800]   something like that, you maybe want to spend some of that time in DC helping things run
[01:24:02.800 --> 01:24:04.840]   better for the people.
[01:24:04.840 --> 01:24:06.120]   I like that.
[01:24:06.120 --> 01:24:07.760]   Thank you for your service, Matt.
[01:24:07.760 --> 01:24:09.760]   I appreciate it.
[01:24:09.760 --> 01:24:10.760]   Indeed.
[01:24:10.760 --> 01:24:11.760]   Yeah.
[01:24:11.760 --> 01:24:12.760]   Yeah.
[01:24:12.760 --> 01:24:14.680]   Our show today brought to you by, well, we have lots more to talk about.
[01:24:14.680 --> 01:24:16.760]   We've got to get a goal here.
[01:24:16.760 --> 01:24:20.200]   Our show today brought to you by CloudFlare.
[01:24:20.200 --> 01:24:21.200]   Talk about service.
[01:24:21.200 --> 01:24:24.480]   This is CloudFlare is on a mission to build a better internet.
[01:24:24.480 --> 01:24:26.640]   You know, I've talked to the folks at CloudFlare.
[01:24:26.640 --> 01:24:30.400]   It's so great because they say, because I try to tell you everything CloudFlare does.
[01:24:30.400 --> 01:24:33.440]   And they say, you know, you don't have to say everything because it goes on and on and
[01:24:33.440 --> 01:24:34.440]   on.
[01:24:34.440 --> 01:24:35.440]   CloudFlare is an amazing company.
[01:24:35.440 --> 01:24:38.240]   Of course, we're good friends with John Graham coming.
[01:24:38.240 --> 01:24:39.240]   They're CTO.
[01:24:39.240 --> 01:24:43.240]   We've talked to many of the folks, including Mark Rogers at CloudFlare, who's their security
[01:24:43.240 --> 01:24:47.480]   guy, some of the smartest people in the world work at CloudFlare.
[01:24:47.480 --> 01:24:53.400]   They want the initial benefit to you is they can make your site or your app faster.
[01:24:53.400 --> 01:24:58.080]   They can make it safer because, in effect, they have a web application firewall.
[01:24:58.080 --> 01:24:59.560]   I'll tell you how that works.
[01:24:59.560 --> 01:25:01.040]   It's amazing.
[01:25:01.040 --> 01:25:02.600]   They can make it more reliable.
[01:25:02.600 --> 01:25:05.040]   So you're protected against DDoS.
[01:25:05.040 --> 01:25:09.320]   You're protected against inadvertent DDoS, the slash dot effect, you know, where a lot
[01:25:09.320 --> 01:25:11.640]   of people go to your site all at once.
[01:25:11.640 --> 01:25:16.080]   You could stop worrying if you use CloudFlare about slow loading page times, downtime,
[01:25:16.080 --> 01:25:17.080]   about getting hacked.
[01:25:17.080 --> 01:25:18.160]   It's easy to use.
[01:25:18.160 --> 01:25:19.520]   You could sign up in five minutes.
[01:25:19.520 --> 01:25:21.360]   And can I tell you something?
[01:25:21.360 --> 01:25:25.200]   There is a free tier that is really, really good.
[01:25:25.200 --> 01:25:30.720]   One of the reasons CloudFlare offers this protection to you for free, see $0 a month
[01:25:30.720 --> 01:25:37.320]   over on the left, is because by being a part of the CloudFlare network, you help them provide
[01:25:37.320 --> 01:25:44.600]   a more useful web application firewall with a massive IP reputation database that updates
[01:25:44.600 --> 01:25:47.000]   for everybody, the free people in the paid people.
[01:25:47.000 --> 01:25:48.520]   So it's really valuable.
[01:25:48.520 --> 01:25:54.240]   Of course, CloudFlare security team starting with Mark is constantly watching 24/7 for
[01:25:54.240 --> 01:25:57.920]   vulnerabilities deploying real time protection.
[01:25:57.920 --> 01:26:04.760]   I know a lot of you know about their DDoS protection, but they also give you IPV6, which
[01:26:04.760 --> 01:26:08.120]   can make a huge difference in your performance and on a mobile app.
[01:26:08.120 --> 01:26:11.280]   I mean, just boom, like that.
[01:26:11.280 --> 01:26:17.600]   They have a CDN, 115 plus data centers worldwide, which caches your content, moves it closer
[01:26:17.600 --> 01:26:19.400]   to your customers.
[01:26:19.400 --> 01:26:20.400]   That'll speed you up.
[01:26:20.400 --> 01:26:22.320]   I mean, I can go on and on.
[01:26:22.320 --> 01:26:25.560]   You know, we've got something actually really great.
[01:26:25.560 --> 01:26:31.600]   If you're interested in CloudFlare, if you go to cloudflare.com/twit, they are offering
[01:26:31.600 --> 01:26:35.920]   a webinar with one of their best support engineers.
[01:26:35.920 --> 01:26:37.520]   He's really great at talking about this.
[01:26:37.520 --> 01:26:40.640]   Jameson Sundell, and explaining it.
[01:26:40.640 --> 01:26:41.640]   And you can be part of it.
[01:26:41.640 --> 01:26:42.640]   Ask questions.
[01:26:42.640 --> 01:26:43.640]   Find out what CloudFlare can do for you.
[01:26:43.640 --> 01:26:46.400]   All you have to do is go to cloudflare.com/twit.
[01:26:46.400 --> 01:26:49.960]   Give them your name and email and you'll register for a session with Jameson.
[01:26:49.960 --> 01:26:53.680]   It's fantastic.
[01:26:53.680 --> 01:26:59.520]   You know, if you're using cloud solutions like AWS or Google Cloud or Azure, CloudFlare
[01:26:59.520 --> 01:27:02.600]   can help you work with all of them and eliminate lock-in.
[01:27:02.600 --> 01:27:05.760]   So you can use more than one provider.
[01:27:05.760 --> 01:27:10.760]   And then if you decide to move on, you're not locked in.
[01:27:10.760 --> 01:27:12.480]   It goes on and on.
[01:27:12.480 --> 01:27:17.000]   This is a great company doing amazing technical work and helping websites everywhere.
[01:27:17.000 --> 01:27:18.960]   CloudFlare.com/twit.
[01:27:18.960 --> 01:27:23.680]   Find out more by talking to Jameson Sundell.
[01:27:23.680 --> 01:27:26.760]   Prices range from free to $20 a month to $200 a month.
[01:27:26.760 --> 01:27:29.480]   And of course, as you get bigger, you're going to want an enterprise plan.
[01:27:29.480 --> 01:27:32.440]   And they can work with you on that too.
[01:27:32.440 --> 01:27:33.680]   Don't get hit by DDoS.
[01:27:33.680 --> 01:27:35.640]   Don't get hit with security flaws.
[01:27:35.640 --> 01:27:38.040]   Work better for your customers.
[01:27:38.040 --> 01:27:41.040]   It's a win all around at cloudflare.com/twit.
[01:27:41.040 --> 01:27:47.960]   And we thank them so much for their support of this week in Google.
[01:27:47.960 --> 01:27:50.440]   Let's see.
[01:27:50.440 --> 01:27:52.520]   What else should we talk about here?
[01:27:52.520 --> 01:27:55.920]   There was a lot of, here's a surprise.
[01:27:55.920 --> 01:27:56.920]   The YouTube TV.
[01:27:56.920 --> 01:27:57.920]   I actually have been paying for this.
[01:27:57.920 --> 01:27:58.920]   And I love it.
[01:27:58.920 --> 01:28:00.200]   It's $35 a month.
[01:28:00.200 --> 01:28:02.120]   I get my locals in San Francisco.
[01:28:02.120 --> 01:28:05.360]   Two million downloads for this court gutter app.
[01:28:05.360 --> 01:28:12.160]   That means, I don't know how many subscriptions, but that's pretty amazing.
[01:28:12.160 --> 01:28:15.040]   That's at least two million people trying it.
[01:28:15.040 --> 01:28:19.080]   According to SensorTower, 700,000 new installs since the announcement last week that was
[01:28:19.080 --> 01:28:20.600]   entering new markets.
[01:28:20.600 --> 01:28:21.960]   So I think people are kind of waiting.
[01:28:21.960 --> 01:28:25.240]   Can we get the local stations from YouTube TV?
[01:28:25.240 --> 01:28:27.760]   And when you can, it really is a good deal.
[01:28:27.760 --> 01:28:28.960]   I really like it.
[01:28:28.960 --> 01:28:31.000]   This ties into an article I had.
[01:28:31.000 --> 01:28:33.880]   I thought I'm reading the onion, but it wasn't the onion.
[01:28:33.880 --> 01:28:35.240]   It was a Wall Street Journal.
[01:28:35.240 --> 01:28:38.320]   Do you see this article?
[01:28:38.320 --> 01:28:39.680]   Millennials on Earth.
[01:28:39.680 --> 01:28:44.480]   An amazing hack to get free TV.
[01:28:44.480 --> 01:28:50.040]   The antenna.
[01:28:50.040 --> 01:28:54.640]   They quote, I got a sign in because it's behind a paywall, but they quote some millennials
[01:28:54.640 --> 01:29:01.680]   who say, I had no idea that all this free programming was out there.
[01:29:01.680 --> 01:29:06.800]   And all I had to do was get us some rabbit ears.
[01:29:06.800 --> 01:29:10.160]   Why did this last year, the year before when I was in San Jose?
[01:29:10.160 --> 01:29:16.120]   It was like, okay, I don't actually need to pay cable for TV because I have Netflix and
[01:29:16.120 --> 01:29:17.120]   Amazon.
[01:29:17.120 --> 01:29:21.840]   And if I just stick a thing on the wall, I can get the live stuff that the cable providers
[01:29:21.840 --> 01:29:22.840]   can give me.
[01:29:22.840 --> 01:29:23.840]   And that's done.
[01:29:23.840 --> 01:29:29.720]   The UK, it's even better, but the digital over the air stuff here is actually really good.
[01:29:29.720 --> 01:29:35.560]   And all the channels have, there's I player for the BBC, there's an ITV app, there's a
[01:29:35.560 --> 01:29:37.600]   channel 4 app, there's a channel 5 app.
[01:29:37.600 --> 01:29:42.480]   So all the channels are competing to give you digital versions of their stuff too.
[01:29:42.480 --> 01:29:48.080]   So I buy a TV here, it says, give me an internet connection, give me an over the air connection
[01:29:48.080 --> 01:29:50.920]   and I'll give you what you can find out of both.
[01:29:50.920 --> 01:29:57.000]   So it's already happened here in the US lags a bit because there are these monopoly cable
[01:29:57.000 --> 01:30:01.600]   providers who are trying to persuade you that you need to pay them 200s or a month to do
[01:30:01.600 --> 01:30:02.600]   this for you.
[01:30:02.600 --> 01:30:08.080]   So that's kind of the joke of it is that, look, I didn't have to go to the cable company
[01:30:08.080 --> 01:30:11.000]   to get all these free sites.
[01:30:11.000 --> 01:30:12.000]   It's amazing.
[01:30:12.000 --> 01:30:13.000]   It's incredible.
[01:30:13.000 --> 01:30:17.600]   I don't, I can't understand why the Wall Street Journal wrote this article to be honest
[01:30:17.600 --> 01:30:18.600]   with you.
[01:30:18.600 --> 01:30:23.680]   I did think I must be, I must be reading the, the onion here.
[01:30:23.680 --> 01:30:26.080]   Shows a millennial family watching television.
[01:30:26.080 --> 01:30:32.160]   I mean, it's, it's, it's part of this is like, oh, you know, that's not, but anyway, there
[01:30:32.160 --> 01:30:36.520]   was, there was some guy today saying, yeah, but then he was, but then he was telling me
[01:30:36.520 --> 01:30:41.440]   they don't ask the door, but unless someone texts them first and it's like, well, and
[01:30:41.440 --> 01:30:42.440]   it's like, yes.
[01:30:42.440 --> 01:30:45.720]   Yeah, you're a journalist in London.
[01:30:45.720 --> 01:30:50.000]   And it is in your office a living like, you know, six to a flat.
[01:30:50.000 --> 01:30:53.040]   They're not going to answer the door because half the cool things won't be for them.
[01:30:53.040 --> 01:30:56.040]   They don't end up in a house and suburbs like you are.
[01:30:56.040 --> 01:30:59.120]   And then they don't have a family member at home or data once they're talking to them.
[01:30:59.120 --> 01:31:04.840]   I was just kind of surprised that this technology exists says, Mr. Cisco, 28 years old.
[01:31:04.840 --> 01:31:06.000]   It's been awesome.
[01:31:06.000 --> 01:31:11.800]   It doesn't log out and it doesn't skip.
[01:31:11.800 --> 01:31:14.480]   But you have to stand up and hold the, the antenna.
[01:31:14.480 --> 01:31:16.120]   Well, we got to teach them that.
[01:31:16.120 --> 01:31:18.000]   We got to teach them to that.
[01:31:18.000 --> 01:31:23.560]   Apparently, and sales are up 7%, 8 million units, according to the Consumer Technology
[01:31:23.560 --> 01:31:25.200]   Association.
[01:31:25.200 --> 01:31:29.000]   So maybe there is a boom in antenna TV.
[01:31:29.000 --> 01:31:35.800]   Cisco, I remember this back, you know, 15 years ago, we were down to 12% of America
[01:31:35.800 --> 01:31:37.680]   got their TV from over the air.
[01:31:37.680 --> 01:31:40.400]   It's got to be, it's got to be next to nothing now.
[01:31:40.400 --> 01:31:41.400]   Right.
[01:31:41.400 --> 01:31:46.840]   Just a third of Americans, 29% are unaware that local TV is available free.
[01:31:46.840 --> 01:31:55.760]   According to a survey by the National Association of Broadcasters, what has that things changed
[01:31:55.760 --> 01:31:56.760]   this much?
[01:31:56.760 --> 01:31:59.760]   Oh, you can watch.
[01:31:59.760 --> 01:32:00.760]   Wait a minute.
[01:32:00.760 --> 01:32:06.680]   What is flying through the air is and some, somebody says, is that legal?
[01:32:06.680 --> 01:32:13.840]   Twenty four year old Hunter Wills living in Chicago mostly watches Netflix.
[01:32:13.840 --> 01:32:15.160]   I had no idea.
[01:32:15.160 --> 01:32:21.400]   I'm still not even familiar with the concept.
[01:32:21.400 --> 01:32:25.400]   She thought it was a some modern satellite service or something.
[01:32:25.400 --> 01:32:30.840]   He's one of the guys says of his daughter in her early twenties.
[01:32:30.840 --> 01:32:32.080]   Okay.
[01:32:32.080 --> 01:32:34.520]   I just, okay.
[01:32:34.520 --> 01:32:35.520]   Wow.
[01:32:35.520 --> 01:32:36.520]   Wow.
[01:32:36.520 --> 01:32:38.720]   Are we all doomed?
[01:32:38.720 --> 01:32:39.720]   Yeah.
[01:32:39.720 --> 01:32:40.720]   We're doomed.
[01:32:40.720 --> 01:32:41.720]   We're doomed.
[01:32:41.720 --> 01:32:46.040]   I just want to give them a dial telephone and see what they do with it.
[01:32:46.040 --> 01:32:49.160]   Uh, okay.
[01:32:49.160 --> 01:32:50.160]   Let's see.
[01:32:50.160 --> 01:32:53.880]   Two billion users, Facebook's profits, revenues, sore.
[01:32:53.880 --> 01:32:55.920]   Nothing more to say on that.
[01:32:55.920 --> 01:32:58.120]   Uh, she's the least man.
[01:32:58.120 --> 01:32:59.120]   Oh man.
[01:32:59.120 --> 01:33:00.120]   Oh man.
[01:33:00.120 --> 01:33:01.120]   Um, Twitter stock plunges.
[01:33:01.120 --> 01:33:16.040]   Uh, as it, uh, it shows literally zero growth in monthly active users.
[01:33:16.040 --> 01:33:24.720]   But Twitter said, but daily active users were up 50%, 50% of what they wouldn't say.
[01:33:24.720 --> 01:33:30.600]   So the SEC says, well, why don't you disclose daily, uh, user numbers?
[01:33:30.600 --> 01:33:32.520]   What are you, what are you hiding?
[01:33:32.520 --> 01:33:35.200]   328 million monthly active users.
[01:33:35.200 --> 01:33:40.560]   Um, but it actually this letter from the SEC went, came, goes back to May.
[01:33:40.560 --> 01:33:46.640]   Uh, Twitter's response, it said, well, showing growth is more important than showing the
[01:33:46.640 --> 01:33:47.640]   number.
[01:33:47.640 --> 01:33:53.720]   The reason they said is, well, we're afraid you'll compare it to Facebook and if quote,
[01:33:53.720 --> 01:33:56.920]   investors would not be able to compare for performance between the company and this other
[01:33:56.920 --> 01:33:58.920]   company too late.
[01:33:58.920 --> 01:34:06.920]   Or his Facebook has two billion monthly active, uh, users.
[01:34:06.920 --> 01:34:07.920]   I don't know.
[01:34:07.920 --> 01:34:08.920]   I'm not worried about Twitter.
[01:34:08.920 --> 01:34:09.920]   They've got the Trump effect.
[01:34:09.920 --> 01:34:10.920]   My God.
[01:34:10.920 --> 01:34:16.440]   This is, uh, we now, Donald Trump is now just issuing executive orders on Twitter.
[01:34:16.440 --> 01:34:17.440]   Yeah.
[01:34:17.440 --> 01:34:20.000]   They're collecting to mention it to anybody else.
[01:34:20.000 --> 01:34:21.280]   Just putting it on Twitter.
[01:34:21.280 --> 01:34:23.160]   And then, oh, I loved the tweet.
[01:34:23.160 --> 01:34:24.920]   I don't want to knock him.
[01:34:24.920 --> 01:34:26.080]   He's a president of the United States.
[01:34:26.080 --> 01:34:28.560]   I acknowledge that he's bats boss.
[01:34:28.560 --> 01:34:32.680]   And, uh, so I don't want, I don't want to knock him, but he, I have to read this tweet
[01:34:32.680 --> 01:34:36.400]   to you because I just was like, my jaw, my jaw dropped.
[01:34:36.400 --> 01:34:43.080]   Wasn't the first time, uh, he's talking about, uh, he says only the fake news media.
[01:34:43.080 --> 01:34:45.040]   Oh, let me get rid of this.
[01:34:45.040 --> 01:34:52.000]   Only the fake news media and my enemies want me to stop using social media.
[01:34:52.000 --> 01:34:56.880]   And then I'm not sure what 110 million people, I guess is referring to his followers.
[01:34:56.880 --> 01:35:03.880]   Any way for me to get the truth out, Donald, you're the president of the United States.
[01:35:03.880 --> 01:35:09.320]   You, you can, you have a button you can press that would send a text message to every smartphone
[01:35:09.320 --> 01:35:11.560]   in the country.
[01:35:11.560 --> 01:35:13.720]   You can go on ABC.
[01:35:13.720 --> 01:35:18.000]   Don't tell them that you can go on ABC, CBS and NBC.
[01:35:18.000 --> 01:35:23.800]   Anytime you want and tell people anything you want, you, you don't, you don't need the
[01:35:23.800 --> 01:35:24.800]   Twitter.
[01:35:24.800 --> 01:35:27.080]   But please continue to use it.
[01:35:27.080 --> 01:35:31.440]   And by the way, I, I, I, by the way, I get mad when journalists say, well, he really
[01:35:31.440 --> 01:35:32.440]   should get off Twitter.
[01:35:32.440 --> 01:35:34.360]   That is not the journalist job to do.
[01:35:34.360 --> 01:35:36.520]   I, I say let him be him.
[01:35:36.520 --> 01:35:37.520]   Yeah.
[01:35:37.520 --> 01:35:39.080]   And, and, um, he's the president.
[01:35:39.080 --> 01:35:41.720]   He can use our job to tell him what to do and what not to do.
[01:35:41.720 --> 01:35:43.600]   No, no, he should tweet.
[01:35:43.600 --> 01:35:47.600]   I maybe think you could argue, and I'm sure a few people on the joint chiefs of staff
[01:35:47.600 --> 01:35:53.080]   have that it might be better not to set military policy on Twitter.
[01:35:53.080 --> 01:35:57.480]   But that's just a, that's just a procedural issue.
[01:35:57.480 --> 01:35:59.960]   Um, I'm sorry, Matt.
[01:35:59.960 --> 01:36:02.720]   I, I shouldn't, I shouldn't, I shouldn't do that to you.
[01:36:02.720 --> 01:36:04.480]   I'm not going to, don't just shut up.
[01:36:04.480 --> 01:36:05.480]   You didn't hear it.
[01:36:05.480 --> 01:36:06.480]   You didn't see it.
[01:36:06.480 --> 01:36:09.120]   This is like math on Google topics in the old days.
[01:36:09.120 --> 01:36:10.120]   Yeah.
[01:36:10.120 --> 01:36:11.600]   It's a step up.
[01:36:11.600 --> 01:36:13.160]   You used to not be able to talk about Google.
[01:36:13.160 --> 01:36:15.160]   Now you can't talk about the federal government.
[01:36:15.160 --> 01:36:19.840]   That's, you know, that's, you know, you're broadening your reach here.
[01:36:19.840 --> 01:36:21.480]   Um, what else?
[01:36:21.480 --> 01:36:23.000]   Anything else we need to talk about here?
[01:36:23.000 --> 01:36:24.000]   I just, um, Amazon.
[01:36:24.000 --> 01:36:25.480]   I wanted to mention, go ahead.
[01:36:25.480 --> 01:36:30.880]   I would mention the, um, somebody has threw it in the chat as well, but, um, the UK home
[01:36:30.880 --> 01:36:34.280]   secretary, Amber Rudd, um, is in the, in Silicon Valley.
[01:36:34.280 --> 01:36:35.280]   Hang on.
[01:36:35.280 --> 01:36:36.440]   She's hanging.
[01:36:36.440 --> 01:36:41.600]   She's trying to persuade them to not using encryption quite so much, or at least give
[01:36:41.600 --> 01:36:43.120]   my metadata or something.
[01:36:43.120 --> 01:36:48.120]   Um, so there's, there's this sort of long running thing in the UK where, um, Theresa May,
[01:36:48.120 --> 01:36:51.280]   the, who is now the Prime Minister in the previous home secretary and Amber Rudd, who is the
[01:36:51.280 --> 01:36:54.520]   new home secretary, have been saying, oh, this encryption stuff's very bad.
[01:36:54.520 --> 01:36:56.440]   You know, we want to, we want to stop that.
[01:36:56.440 --> 01:37:00.440]   Um, and everyone's been saying, you can't actually stop that.
[01:37:00.440 --> 01:37:01.600]   That's how things work.
[01:37:01.600 --> 01:37:06.160]   Um, and so the position has moved a bit now and they're no longer saying they want a
[01:37:06.160 --> 01:37:07.640]   bad encryption.
[01:37:07.640 --> 01:37:10.600]   They want to come to an understanding with the Silicon Valley companies to give them more
[01:37:10.600 --> 01:37:13.000]   metadata behind closed doors and so on.
[01:37:13.000 --> 01:37:14.960]   And this, there's a little dance going on here.
[01:37:14.960 --> 01:37:22.640]   So, um, Cheryl Sandberg was on desert island discs, um, two days ago.
[01:37:22.640 --> 01:37:24.120]   Desert Island Disc is wonderful.
[01:37:24.120 --> 01:37:25.120]   It's wonderful.
[01:37:25.120 --> 01:37:26.120]   It's a program.
[01:37:26.120 --> 01:37:27.760]   What absolutely amazing.
[01:37:27.760 --> 01:37:31.680]   It's, it's, it's basically they get people to come on and they say, if we start human
[01:37:31.680 --> 01:37:35.200]   desert island, what would be the eight records you would bring with you?
[01:37:35.200 --> 01:37:36.360]   Um, and play them.
[01:37:36.360 --> 01:37:41.920]   And it's, yeah, and play them for them and it's excuse to, um, talk about their lives
[01:37:41.920 --> 01:37:42.960]   and so on.
[01:37:42.960 --> 01:37:46.680]   But the, the Sandberg one was weird because like there's, there's five minutes of her
[01:37:46.680 --> 01:37:50.640]   talking about encryption at the beginning of it, which I extracted and put on my website.
[01:37:50.640 --> 01:37:54.960]   Um, and, but then she talks about her book and her husband dying and it's actually a
[01:37:54.960 --> 01:37:57.560]   very good, it's a very moving show and it's worth listening to.
[01:37:57.560 --> 01:38:02.080]   But there was, it was this suddenly weird like, oh yes, I met Amber Rudd and we're working
[01:38:02.080 --> 01:38:04.960]   together and all this stuff, um, going on as well.
[01:38:04.960 --> 01:38:09.840]   So there's a certain amount of sort of weird, um, stuff going on there.
[01:38:09.840 --> 01:38:16.800]   I think part of this is, um, Rachel Wettstone just moved to that group at FED Facebook
[01:38:16.800 --> 01:38:24.520]   and so she's trying to smooth over the dispute between the UK government and, um, Facebook
[01:38:24.520 --> 01:38:28.800]   about encryption and she's got form there because her husband used to be advised to
[01:38:28.800 --> 01:38:30.640]   UK go up to the Tory party in the UK government.
[01:38:30.640 --> 01:38:32.800]   So there's a bit of that going on as well.
[01:38:32.800 --> 01:38:38.000]   But there is also this thing of the position has shifted from no, we're going to hang on
[01:38:38.000 --> 01:38:41.680]   to encryption at all counts to, I'm sure we can work something out with you.
[01:38:41.680 --> 01:38:46.480]   Let's, let's go behind closed doors and talk about metadata.
[01:38:46.480 --> 01:38:52.520]   And then the thing that that connected to for me is that, um, there was a, um, somebody
[01:38:52.520 --> 01:39:02.480]   pointed out and I've got to try and find the link now, um, that if you type a URL in, um,
[01:39:02.480 --> 01:39:08.160]   WhatsApp, it fetches it character by character as you type it from the server.
[01:39:08.160 --> 01:39:10.480]   Which is a bit, which is a bit weird.
[01:39:10.480 --> 01:39:13.800]   Instead of holding it, letting you type it, buffering it and sending the URL.
[01:39:13.800 --> 01:39:14.800]   Yes.
[01:39:14.800 --> 01:39:18.240]   And so I think it's basically trying to decide when the, if there's a preview for it or something
[01:39:18.240 --> 01:39:19.240]   like that.
[01:39:19.240 --> 01:39:24.520]   But if you, if you sit there, um, it's still encrypted going to the server, right?
[01:39:24.520 --> 01:39:29.360]   So the, the, the, the, the chat is encrypted between you between the two people you're
[01:39:29.360 --> 01:39:30.360]   talking to.
[01:39:30.360 --> 01:39:35.320]   But it is fetching the URL you are typing from the, sorry, you are typing it from.
[01:39:35.320 --> 01:39:40.040]   So if I say there's something suspicious about this URL, let me WhatsApp it to you.
[01:39:40.040 --> 01:39:44.520]   Cause I think that's a cure actually that you're all get a ping, um, from WhatsApp.
[01:39:44.520 --> 01:39:49.080]   Um, and it will get every character I type as well, which is kind of, you know, so that's
[01:39:49.080 --> 01:39:53.240]   the kind of sort of weird metadata breach that, that they may be talking about.
[01:39:53.240 --> 01:39:56.200]   Um, because those, that stuff is being fetched outside.
[01:39:56.200 --> 01:39:57.200]   Yeah.
[01:39:57.200 --> 01:40:01.720]   If you're sending links to, to people through WhatsApp, they, they could be leaking that
[01:40:01.720 --> 01:40:04.560]   because that stuff is already going out over the net.
[01:40:04.560 --> 01:40:07.920]   And they can, they can track that on their exit node, presumably.
[01:40:07.920 --> 01:40:13.200]   Well, you know, we'll watch with interest to the snoopers charter and of course it's
[01:40:13.200 --> 01:40:14.200]   happening in Australia.
[01:40:14.200 --> 01:40:19.720]   I'm sure it'll happen here at some point where the governments say, uh, you must not, uh,
[01:40:19.720 --> 01:40:24.600]   encrypt or we must have a backdoor into the encryption or if we ask you, you've got to
[01:40:24.600 --> 01:40:28.000]   provide us with clear text of whatever those messages were.
[01:40:28.000 --> 01:40:32.280]   Um, it's interesting that maybe they're willing to settle for metadata.
[01:40:32.280 --> 01:40:33.280]   That doesn't sound right.
[01:40:33.280 --> 01:40:36.640]   Well, that's, that's the conversation they're having.
[01:40:36.640 --> 01:40:37.640]   Yeah.
[01:40:37.640 --> 01:40:40.360]   Well, they've got metadata mostly anyway.
[01:40:40.360 --> 01:40:45.480]   Um, and with, with, you know, December was explicitly saying it on the, on the, on the
[01:40:45.480 --> 01:40:49.400]   clip, um, we can't tell what you're saying to each other, but we can tell who you were
[01:40:49.400 --> 01:40:51.800]   talking to and we could give that to the government.
[01:40:51.800 --> 01:40:52.800]   She said that.
[01:40:52.800 --> 01:40:53.800]   Good to know.
[01:40:53.800 --> 01:40:59.320]   And in, in between choosing a song from Beyonce and the one from you.
[01:40:59.320 --> 01:41:01.760]   I want to know what you thought about this, uh, Jeff Jarvis.
[01:41:01.760 --> 01:41:03.160]   This is from fair.
[01:41:03.160 --> 01:41:09.400]   Um, uh, fair is the, uh, fairness and accuracy and reporting website challenging media by
[01:41:09.400 --> 01:41:15.980]   livestock since 1986 and I like fair, but they say Jeff Bezos is getting a free pass, not
[01:41:15.980 --> 01:41:20.240]   just from his own paper, the Washington Post, but a kind of collegial free pass from the
[01:41:20.240 --> 01:41:23.640]   New York times and the Wall Street Journal at all as well.
[01:41:23.640 --> 01:41:30.160]   They reviewed 190 articles, uh, over the past year, none of the articles were exposs,
[01:41:30.160 --> 01:41:36.360]   6% leaned negative 54% were straighter neutral, 40% were positive, mostly with a fawning or
[01:41:36.360 --> 01:41:38.360]   even press release.
[01:41:38.360 --> 01:41:39.360]   Like tone.
[01:41:39.360 --> 01:41:44.600]   I do remember though, two years ago, the New York times frankly hit pieces of Amazon.
[01:41:44.600 --> 01:41:45.600]   Yeah, they did.
[01:41:45.600 --> 01:41:47.840]   You know, people are crying at their desks.
[01:41:47.840 --> 01:41:49.720]   Uh, but there hasn't been anything.
[01:41:49.720 --> 01:41:51.920]   I guess since then there hasn't been anything to prove it.
[01:41:51.920 --> 01:41:52.920]   What do you think?
[01:41:52.920 --> 01:41:53.920]   It's a proofing a negative.
[01:41:53.920 --> 01:42:00.560]   I mean, it's pretty, it's a conservative, um, uh, media watchdog and now since he owns
[01:42:00.560 --> 01:42:02.880]   the Washington Post that, that ties that together.
[01:42:02.880 --> 01:42:07.400]   It's reasonable to worry about it, I think, you know, but, but, but, but, you know, gee,
[01:42:07.400 --> 01:42:11.560]   the man built a company single handedly to make him the richest man in the world.
[01:42:11.560 --> 01:42:12.560]   Let's go after him.
[01:42:12.560 --> 01:42:14.360]   Let's not, let's not say anything nice about him.
[01:42:14.360 --> 01:42:17.920]   I mean, I will be watching though to see what kind of coverage.
[01:42:17.920 --> 01:42:18.920]   What, what kind of coverage do you want?
[01:42:18.920 --> 01:42:24.640]   I, well, I want to see more coverage of the antitrust issues, Amazon's, uh, acquisition
[01:42:24.640 --> 01:42:29.920]   of, uh, whole food for instance represents and the larger issue of Amazon basically taking
[01:42:29.920 --> 01:42:30.920]   over all e-commerce.
[01:42:30.920 --> 01:42:35.720]   Well, here's, and the impact on, on labor is huge.
[01:42:35.720 --> 01:42:39.400]   Here's what's going to happen is, you know, Eric Schmidt said years ago, the internet
[01:42:39.400 --> 01:42:40.920]   is terribly disruptive for us.
[01:42:40.920 --> 01:42:42.160]   Google is the biggest thing in the internet.
[01:42:42.160 --> 01:42:43.640]   So they're going to come across first.
[01:42:43.640 --> 01:42:45.040]   Who are they going after next?
[01:42:45.040 --> 01:42:47.000]   Facebook is the next biggest thing.
[01:42:47.000 --> 01:42:48.000]   And he had to happily.
[01:42:48.000 --> 01:42:49.200]   Who are they going to go after next?
[01:42:49.200 --> 01:42:54.000]   They're going to go after Amazon and Amazon, for example, is just going into Australia.
[01:42:54.000 --> 01:42:59.800]   It's going into other countries and it's going to have, um, a disruptive impact there.
[01:42:59.800 --> 01:43:03.920]   And so yeah, it's going to be the target of, of, of attacks, but that's also to me, the
[01:43:03.920 --> 01:43:06.240]   generic tech is bad.
[01:43:06.240 --> 01:43:07.640]   American tech companies are bad.
[01:43:07.640 --> 01:43:08.640]   Let's go after them.
[01:43:08.640 --> 01:43:09.640]   Right.
[01:43:09.640 --> 01:43:10.640]   Thing.
[01:43:10.640 --> 01:43:12.680]   I, you know what, tell me what Jeff Bezos is doing wrong.
[01:43:12.680 --> 01:43:17.320]   They should be covering and, and maybe almost into your story, but just saying that, that
[01:43:17.320 --> 01:43:18.920]   they're not finding horrible things about them.
[01:43:18.920 --> 01:43:20.400]   Well, right.
[01:43:20.400 --> 01:43:21.400]   Okay.
[01:43:21.400 --> 01:43:27.720]   I don't even want to get into the Bitcoin fork unless one of you can explain it to me.
[01:43:27.720 --> 01:43:31.520]   I can recommend some reading.
[01:43:31.520 --> 01:43:32.520]   Yeah.
[01:43:32.520 --> 01:43:33.520]   Yeah.
[01:43:33.520 --> 01:43:34.520]   Yeah.
[01:43:34.520 --> 01:43:35.520]   Yeah.
[01:43:35.520 --> 01:43:36.520]   Yeah.
[01:43:36.520 --> 01:43:37.520]   There's a lot, you know, there's a lot of places you go to find out more about blockchain.
[01:43:37.520 --> 01:43:40.140]   The fork happened on August 1st, which is yesterday.
[01:43:40.140 --> 01:43:45.920]   And some of the Bitcoin miners apparently were very slow to take it up because the new
[01:43:45.920 --> 01:43:50.800]   Bitcoin cash, you know, you have to have miners creating the bitcoins.
[01:43:50.800 --> 01:43:54.440]   Their miners were the ones who didn't really want Bitcoin to change, I think.
[01:43:54.440 --> 01:43:56.840]   At least that's my understanding of the politics involved.
[01:43:56.840 --> 01:43:58.840]   There's a lot of politics involved.
[01:43:58.840 --> 01:44:01.920]   Nevertheless, Bitcoin was getting very unwieldy.
[01:44:01.920 --> 01:44:03.920]   The blockchain was huge.
[01:44:03.920 --> 01:44:06.200]   It was really slowing down transactions.
[01:44:06.200 --> 01:44:12.120]   There was a strong movement to, to change the technology, which was rejected by the Bitcoin
[01:44:12.120 --> 01:44:13.120]   foundation.
[01:44:13.120 --> 01:44:16.680]   There was a split.
[01:44:16.680 --> 01:44:22.320]   The new Bitcoin cash is apparently somehow compatible.
[01:44:22.320 --> 01:44:29.360]   But there, there wasn't apparently an issue with mining because the first Bitcoin wasn't
[01:44:29.360 --> 01:44:36.000]   mined for a while, not until 220 yesterday afternoon.
[01:44:36.000 --> 01:44:40.320]   There might be some technical issues slowing it down since somebody, but I think it's more
[01:44:40.320 --> 01:44:43.760]   the miners not jumping on this new Bitcoin cash.
[01:44:43.760 --> 01:44:46.600]   We'll watch with interest.
[01:44:46.600 --> 01:44:47.960]   It's one of these things.
[01:44:47.960 --> 01:44:53.280]   It's just so complicated, not technology, but just the politics of it.
[01:44:53.280 --> 01:44:56.280]   But that's the thing.
[01:44:56.280 --> 01:45:00.120]   It was designed without really having governance rules on the assumption.
[01:45:00.120 --> 01:45:03.720]   You could replace that with code.
[01:45:03.720 --> 01:45:07.720]   And of course, then it's like, well, who decides who's running the code?
[01:45:07.720 --> 01:45:08.960]   Who decides what code is written?
[01:45:08.960 --> 01:45:14.480]   Who decides what code is run?
[01:45:14.480 --> 01:45:19.160]   We have this tension between the different groups who are writing code and then the mining
[01:45:19.160 --> 01:45:21.480]   syndicate, so we're deciding what code they run.
[01:45:21.480 --> 01:45:25.920]   The people writing the code want the code that blocks to be smaller and more secure.
[01:45:25.920 --> 01:45:28.800]   The miners would like the blocks to be much bigger.
[01:45:28.800 --> 01:45:32.840]   They say that makes Bitcoin faster and more scalable.
[01:45:32.840 --> 01:45:37.200]   But there's also other factions within the miners because part of it is they don't want
[01:45:37.200 --> 01:45:38.200]   to change.
[01:45:38.200 --> 01:45:44.080]   It's talking about the miners are in revolt.
[01:45:44.080 --> 01:45:47.480]   But they are mostly Chinese now?
[01:45:47.480 --> 01:45:48.480]   Is it almost?
[01:45:48.480 --> 01:45:55.080]   Yes, they are almost all Chinese because basically you need access to free power to compete with
[01:45:55.080 --> 01:45:56.080]   mining.
[01:45:56.080 --> 01:46:03.160]   And so they are set up in bits of China where they're plugged into hydroelectric power stations.
[01:46:03.160 --> 01:46:09.160]   So that blue roof building is the mining thing next to the hydroelectric dam there.
[01:46:09.160 --> 01:46:16.760]   And so they're basically siphoning off electricity and turning it into pseudo money.
[01:46:16.760 --> 01:46:21.800]   And the amount of power they're using is quite remarkably high at the moment.
[01:46:21.800 --> 01:46:22.800]   So that's it.
[01:46:22.800 --> 01:46:28.680]   Is the Chinese government then involved in Bitcoin mining?
[01:46:28.680 --> 01:46:30.400]   Not officially.
[01:46:30.400 --> 01:46:36.640]   But yes, obviously if you are able to set up a thing like this and plug it into the power
[01:46:36.640 --> 01:46:40.800]   station, then some bits of the Chinese government are loading somewhere.
[01:46:40.800 --> 01:46:41.800]   Yes.
[01:46:41.800 --> 01:46:48.440]   It sort of feels like Bitcoin is like fantasy football for geeks though.
[01:46:48.440 --> 01:46:50.440]   But there's real money involved.
[01:46:50.440 --> 01:46:53.960]   Well, there is a bit of a problem.
[01:46:53.960 --> 01:47:04.080]   It feels like all the friendliness of an open source community with all the fiscal responsibility
[01:47:04.080 --> 01:47:08.760]   of players on Wall Street and put those two together.
[01:47:08.760 --> 01:47:09.760]   And I don't know.
[01:47:09.760 --> 01:47:10.760]   It's wild.
[01:47:10.760 --> 01:47:11.760]   We'll watch.
[01:47:11.760 --> 01:47:14.400]   We'll watch with interest.
[01:47:14.400 --> 01:47:19.400]   Speaking of China, Amazon has halted sales of a phone made in China.
[01:47:19.400 --> 01:47:21.760]   A very affordable Android device by Blue.
[01:47:21.760 --> 01:47:23.440]   Actually, it's a number of phones.
[01:47:23.440 --> 01:47:25.880]   Blue also made Windows phones.
[01:47:25.880 --> 01:47:30.680]   But Amazon has suspended sales of Blue phones on its site, amid concerns that the device
[01:47:30.680 --> 01:47:35.840]   data may be being forwarded to China.
[01:47:35.840 --> 01:47:43.480]   A potential security issue in November, a security firm mentioned these firmware over
[01:47:43.480 --> 01:47:48.480]   the year update software from a Chinese vendor, which was being applied to Blue phones and
[01:47:48.480 --> 01:47:55.920]   was then transmitting text messages and other private data to an unknown server in China.
[01:47:55.920 --> 01:48:00.600]   Blue announced that it requested the company to disable that functionality.
[01:48:00.600 --> 01:48:04.480]   The company that had made the firmware update said that they had fixed the issue.
[01:48:04.480 --> 01:48:09.880]   But at Black Hat, Crypto Wire, the security company that discovered it was back saying,
[01:48:09.880 --> 01:48:10.880]   "Yep.
[01:48:10.880 --> 01:48:13.400]   There's still transmitting users' private data."
[01:48:13.400 --> 01:48:17.400]   And there's a command and control server capable of installing apps, taking screenshots,
[01:48:17.400 --> 01:48:21.920]   recording the screen, making calls, and wiping devices without the owner's permission.
[01:48:21.920 --> 01:48:22.920]   Oh!
[01:48:22.920 --> 01:48:27.040]   So maybe if you have one of them, their Blue phones, you might want to consider getting
[01:48:27.040 --> 01:48:28.560]   a new one.
[01:48:28.560 --> 01:48:29.920]   They're very affordable.
[01:48:29.920 --> 01:48:32.560]   $60.
[01:48:32.560 --> 01:48:38.520]   The particular one that Crypto Wire found with the software on it was Blue R1HD.
[01:48:38.520 --> 01:48:39.520]   It's Android.
[01:48:39.520 --> 01:48:40.520]   It's old.
[01:48:40.520 --> 01:48:42.120]   It's not very recent Android.
[01:48:42.120 --> 01:48:45.120]   Apparently, some Blue models are still available on Amazon.
[01:48:45.120 --> 01:48:51.680]   It's unclear whether Blue is culpable here or maybe one of their suppliers.
[01:48:51.680 --> 01:48:57.960]   And Blue phones, by the way, were on that list of phones you could get with Amazon ads
[01:48:57.960 --> 01:49:03.200]   in the front that reduce the cost even further.
[01:49:03.200 --> 01:49:13.400]   Blue said it's going to start using Google's over-the-air update service going forward.
[01:49:13.400 --> 01:49:18.080]   But it argued that using the old software was not an issue, it was merely collecting information
[01:49:18.080 --> 01:49:23.040]   standard for over-the-air update functionality and consistent with other smartphone brands.
[01:49:23.040 --> 01:49:26.440]   I don't know if that's true.
[01:49:26.440 --> 01:49:27.440]   I don't know.
[01:49:27.440 --> 01:49:28.440]   Maybe Blue is called.
[01:49:28.440 --> 01:49:30.440]   I'm a little skeptical.
[01:49:30.440 --> 01:49:32.280]   Color me skeptical, Blue.
[01:49:32.280 --> 01:49:33.520]   I don't know about that.
[01:49:33.520 --> 01:49:34.520]   Yes.
[01:49:34.520 --> 01:49:35.520]   Let me, Blue.
[01:49:35.520 --> 01:49:36.520]   All right.
[01:49:36.520 --> 01:49:37.520]   I think we can.
[01:49:37.520 --> 01:49:42.680]   I mean, there's so much more I could talk about, you know, net neutrality.
[01:49:42.680 --> 01:49:47.080]   80-curric leaving oath.
[01:49:47.080 --> 01:49:48.080]   Tom Wheeler.
[01:49:48.080 --> 01:49:49.800]   Actually, let me point you to this article.
[01:49:49.800 --> 01:49:54.880]   I mentioned it on another show, but Tom Wheeler in an interview with Fast Company, the former
[01:49:54.880 --> 01:50:01.040]   chairman of the FCC really knocking the current chairman, Ajit Pai, saying ultimately he's
[01:50:01.040 --> 01:50:03.960]   doing the bidding of the four big ISPs.
[01:50:03.960 --> 01:50:08.600]   The money quotes pretty much at the very end.
[01:50:08.600 --> 01:50:12.480]   Tom Wheeler says it looks like the FCC is standing up for four companies when you're really
[01:50:12.480 --> 01:50:13.800]   right down to it.
[01:50:13.800 --> 01:50:18.560]   There are four companies who are really the major beneficiaries of rolling back Title
[01:50:18.560 --> 01:50:24.760]   Two regulation, that neutrality regulations, Comcast, AT&T, Verizon, and Charter.
[01:50:24.760 --> 01:50:27.760]   They provide the vast majority of high-speed internet in the country.
[01:50:27.760 --> 01:50:28.760]   Four companies.
[01:50:28.760 --> 01:50:32.360]   There are a thousand companies who are the early stage innovators, the kind of folks who
[01:50:32.360 --> 01:50:36.360]   bring opportunity and create new jobs who have written letters to the FCC saying they're
[01:50:36.360 --> 01:50:39.400]   and I, by the way, wrote a letter to the FCC saying exactly this.
[01:50:39.400 --> 01:50:43.760]   My business will be threatened by the elimination of Title Two in order to increase the power
[01:50:43.760 --> 01:50:48.320]   of the big four that is just an absolutely startling comparison.
[01:50:48.320 --> 01:50:52.480]   Four companies are going to get bigger and more powerful at the expense of a thousand
[01:50:52.480 --> 01:50:58.360]   startups and tens of millions of consumers that is so out of whack as to be shameful.
[01:50:58.360 --> 01:51:01.760]   The former commissioner of the FCC on net neutrality.
[01:51:01.760 --> 01:51:04.280]   I thought that was a good statement.
[01:51:04.280 --> 01:51:06.320]   We thought Tom Wheeler was a dingo, but he's not.
[01:51:06.320 --> 01:51:07.320]   Yeah, no.
[01:51:07.320 --> 01:51:08.620]   He was with the angels.
[01:51:08.620 --> 01:51:11.160]   He was with the angels and still is.
[01:51:11.160 --> 01:51:14.840]   He could shut up, but he's still weighing in on this one.
[01:51:14.840 --> 01:51:15.840]   Yeah.
[01:51:15.840 --> 01:51:17.680]   Actually, it'll be very interesting to watch.
[01:51:17.680 --> 01:51:23.660]   The information points out that with the AT&T Time Warner acquisition moving forward,
[01:51:23.660 --> 01:51:26.600]   Time Warner owns HBO.
[01:51:26.600 --> 01:51:31.000]   It might be interesting to see if AT&T, which has a significant amount of debt, might start
[01:51:31.000 --> 01:51:35.400]   to cut back the amount of money HBO gets for original programming.
[01:51:35.400 --> 01:51:39.260]   Could be a little inside fight.
[01:51:39.260 --> 01:51:40.260]   Did you see?
[01:51:40.260 --> 01:51:43.140]   Oh, I think Jeff, you posted this.
[01:51:43.140 --> 01:51:45.340]   This is the funniest thing ever.
[01:51:45.340 --> 01:51:46.340]   This is funny.
[01:51:46.340 --> 01:51:50.580]   From the ACLU, they filed an amicus brief.
[01:51:50.580 --> 01:51:59.820]   John Oliver on his show said something bad about what is the guy own coal mines?
[01:51:59.820 --> 01:52:00.820]   He's a coal magnet.
[01:52:00.820 --> 01:52:01.820]   Coal.
[01:52:01.820 --> 01:52:02.820]   Coal.
[01:52:02.820 --> 01:52:06.960]   As they say, Robert E. Bob Murray.
[01:52:06.960 --> 01:52:10.880]   Murray didn't like it that John Oliver said bad things about him.
[01:52:10.880 --> 01:52:19.360]   So he sued HBO and John Oliver and the ACLU is filed, I think probably the best legal document
[01:52:19.360 --> 01:52:26.920]   I've ever read on behalf of the defendant, John Oliver and HBO.
[01:52:26.920 --> 01:52:28.520]   Just the table of contents is hilarious.
[01:52:28.520 --> 01:52:34.920]   Oh, yeah, because, well, I can't basically, one of the lines in the show was eat poop,
[01:52:34.920 --> 01:52:37.600]   Bob, only in a little more strongly.
[01:52:37.600 --> 01:52:44.520]   And the ACLU points out, anyone can legally say eat poop, Bob.
[01:52:44.520 --> 01:52:51.680]   If the comment on the rundown is my favorite excerpt.
[01:52:51.680 --> 01:52:53.800]   Okay, let me find that here.
[01:52:53.800 --> 01:52:56.440]   Hold on a second.
[01:52:56.440 --> 01:53:00.840]   The comment on the rundown, all I have is a script article.
[01:53:00.840 --> 01:53:02.640]   Where does the comment?
[01:53:02.640 --> 01:53:06.240]   No, no, no, I added a cover over the hover.
[01:53:06.240 --> 01:53:07.680]   I don't understand hover.
[01:53:07.680 --> 01:53:08.680]   Okay.
[01:53:08.680 --> 01:53:09.680]   Here it is.
[01:53:09.680 --> 01:53:11.560]   Any of this case is beyond meritless.
[01:53:11.560 --> 01:53:13.040]   This is the ACLU writing.
[01:53:13.040 --> 01:53:17.840]   It is offensive to the very ideals of free speech about it in the First Amendment.
[01:53:17.840 --> 01:53:22.080]   The fact that the plaintiff's filed this case, by the way, Bob is apparently known to be
[01:53:22.080 --> 01:53:23.640]   fairly litigious.
[01:53:23.640 --> 01:53:27.040]   The fact the plaintiff's filed this case is ridiculous enough, but to pour gasoline on
[01:53:27.040 --> 01:53:32.040]   the fire, plaintiff's counsel has also filed a motion asking the court to make John Oliver
[01:53:32.040 --> 01:53:36.480]   not say mean things about him anymore.
[01:53:36.480 --> 01:53:37.880]   It is frankly shocking to be honest.
[01:53:37.880 --> 01:53:43.440]   We're able to find attorneys willing to file a lawsuit that is so obviously unconstitutional.
[01:53:43.440 --> 01:53:48.320]   It is apt that one of the plaintiff's objections to the show is about a human-sized squirrel
[01:53:48.320 --> 01:53:52.680]   named Mr. Nutter butter, because this case is nuts.
[01:53:52.680 --> 01:53:57.200]   Which also begs the question is Mr. Nutter butter, one of the 50 dough defendants included
[01:53:57.200 --> 01:53:58.200]   in this action.
[01:53:58.200 --> 01:54:00.040]   I love it.
[01:54:00.040 --> 01:54:02.440]   Somebody at the ACLU had a lot of fun writing that.
[01:54:02.440 --> 01:54:03.440]   That ball.
[01:54:03.440 --> 01:54:04.440]   Isn't that awesome?
[01:54:04.440 --> 01:54:10.480]   I don't think Bob's point was to win in this case, but just to harass John Oliver.
[01:54:10.480 --> 01:54:11.480]   Any got attention?
[01:54:11.480 --> 01:54:12.480]   All right.
[01:54:12.480 --> 01:54:14.600]   Let's let's wrap this thing up.
[01:54:14.600 --> 01:54:15.760]   Matt, you've been so great.
[01:54:15.760 --> 01:54:17.240]   It's been so nice to have you.
[01:54:17.240 --> 01:54:21.800]   I'm going to guess that your thing, your pick of the week might have something to do with
[01:54:21.800 --> 01:54:24.160]   the US Digital Service.
[01:54:24.160 --> 01:54:25.160]   It does.
[01:54:25.160 --> 01:54:30.680]   I'll just tell you about one industry practice we brought in, which is called a bug bounty.
[01:54:30.680 --> 01:54:34.600]   If you listen to this week in Google or any of Leo shows, you're familiar with the idea
[01:54:34.600 --> 01:54:39.920]   of paying for a security hole so that other bad people don't exploit that security hole.
[01:54:39.920 --> 01:54:43.440]   But the federal government had never done a bug bounty before.
[01:54:43.440 --> 01:54:45.000]   So they ran one last year.
[01:54:45.000 --> 01:54:46.600]   It was called hack the Pentagon.
[01:54:46.600 --> 01:54:50.960]   It turns out they were able to find a lot of great security holes.
[01:54:50.960 --> 01:54:55.520]   They lowered the cost of finding those security holes and better protected federal websites
[01:54:55.520 --> 01:54:56.520]   and technology.
[01:54:56.520 --> 01:54:58.280]   It cost $150,000.
[01:54:58.280 --> 01:55:00.880]   It would have cost more than a million.
[01:55:00.880 --> 01:55:04.440]   Yeah, chicken feed by government terms.
[01:55:04.440 --> 01:55:05.440]   Yeah.
[01:55:05.440 --> 01:55:06.440]   They've done screwdriver.
[01:55:06.440 --> 01:55:07.440]   I'm not the Army.
[01:55:07.440 --> 01:55:08.440]   Nothing.
[01:55:08.440 --> 01:55:09.440]   Yeah.
[01:55:09.440 --> 01:55:11.440]   They're better at the Navy.
[01:55:11.440 --> 01:55:12.760]   But I'm teasing.
[01:55:12.760 --> 01:55:16.560]   I just finished running hack the Air Force.
[01:55:16.560 --> 01:55:18.800]   So they've done several of these, including a classified one.
[01:55:18.800 --> 01:55:24.320]   So if you are the sort of person who has heard of a bug bounty or has deployed things to
[01:55:24.320 --> 01:55:30.720]   the cloud and you think you might be able to do a few months tour in DC, I encourage
[01:55:30.720 --> 01:55:32.800]   you to check out usds.gov.
[01:55:32.800 --> 01:55:35.160]   We have that slash join page.
[01:55:35.160 --> 01:55:36.160]   I suspect.
[01:55:36.160 --> 01:55:38.800]   How do you do a classified bug bounty?
[01:55:38.800 --> 01:55:45.840]   Oh, you get researchers who have been pre-qualified and you make sure that they're in a cyber
[01:55:45.840 --> 01:55:46.840]   range.
[01:55:46.840 --> 01:55:47.840]   That's what they call it.
[01:55:47.840 --> 01:55:49.080]   They do it on a site.
[01:55:49.080 --> 01:55:50.560]   That's really cool.
[01:55:50.560 --> 01:55:51.560]   That's really cool.
[01:55:51.560 --> 01:55:52.560]   Wow.
[01:55:52.560 --> 01:55:53.560]   Yeah.
[01:55:53.560 --> 01:55:54.640]   And they found good security holes in that one too.
[01:55:54.640 --> 01:55:57.920]   Like bug bounties are a great way to find security holes.
[01:55:57.920 --> 01:56:00.440]   And now they have a vulnerability disclosure policy.
[01:56:00.440 --> 01:56:06.160]   There's going to be civilian bug bounty programs in the next few months.
[01:56:06.160 --> 01:56:08.720]   So this is like you're coming from the future.
[01:56:08.720 --> 01:56:13.000]   If you're coming from the tech industry and you can bring these time tested, battle tested
[01:56:13.000 --> 01:56:17.120]   techniques that everybody knows works that aren't really that risky and make government
[01:56:17.120 --> 01:56:18.120]   work better.
[01:56:18.120 --> 01:56:19.480]   I was ever our friend.
[01:56:19.480 --> 01:56:20.480]   You're doing God's work.
[01:56:20.480 --> 01:56:25.360]   I imagine there are quite a few hackers now, white hat hackers now, who make a living on
[01:56:25.360 --> 01:56:26.360]   bug bounties.
[01:56:26.360 --> 01:56:29.240]   There's a significant amount of money.
[01:56:29.240 --> 01:56:33.720]   So for Hack the Air Force, I think there was like a 17 year old that made something
[01:56:33.720 --> 01:56:39.680]   like $39,000 and it's still a good deal for everybody by finding this security hole.
[01:56:39.680 --> 01:56:40.680]   Yeah.
[01:56:40.680 --> 01:56:41.680]   Really nice work.
[01:56:41.680 --> 01:56:47.080]   And some of these bug bounties are, you know, I know Microsoft just announced that
[01:56:47.080 --> 01:56:51.840]   bug bounties in over $100,000 for one edge flaw or whatever it was.
[01:56:51.840 --> 01:56:53.520]   You know, it was a hyper V flaw.
[01:56:53.520 --> 01:56:56.400]   So there's some big money, big money in this.
[01:56:56.400 --> 01:56:57.400]   Well good.
[01:56:57.400 --> 01:56:58.400]   That's pretty cool.
[01:56:58.400 --> 01:57:04.520]   We never, you know, that's probably not in your realm, but I was someday would like
[01:57:04.520 --> 01:57:10.200]   to pick your brain on the vulnerabilities equity process and where that stands now in
[01:57:10.200 --> 01:57:11.200]   the government.
[01:57:11.200 --> 01:57:17.960]   So the idea that there should be a process once an intelligence agency like the NSA or
[01:57:17.960 --> 01:57:24.760]   the CIA discovers a flaw and exploit, there should be a process in which it justifies
[01:57:24.760 --> 01:57:29.400]   holding on to it or the decision is made whether to reveal it to the company so they
[01:57:29.400 --> 01:57:31.160]   can fix the flaw.
[01:57:31.160 --> 01:57:34.560]   And this was created in the Obama administration a few years ago.
[01:57:34.560 --> 01:57:38.480]   And I don't, I don't, are they, do they do it still or is it just kind of fallen by
[01:57:38.480 --> 01:57:40.520]   the wayside or?
[01:57:40.520 --> 01:57:42.080]   There's a lot of nuance to that.
[01:57:42.080 --> 01:57:45.640]   So that's a, that could be a long discussion.
[01:57:45.640 --> 01:57:50.000]   But I will say like, you know, everybody agrees that government IT systems should be
[01:57:50.000 --> 01:57:54.960]   secure and bug bounties are a really cool tool that industry found years and years ago.
[01:57:54.960 --> 01:57:58.040]   So it's a good, good idea across the board.
[01:57:58.040 --> 01:57:59.040]   I agree.
[01:57:59.040 --> 01:58:00.040]   Nice job.
[01:58:00.040 --> 01:58:01.040]   Nice dodge.
[01:58:01.040 --> 01:58:02.040]   Well done.
[01:58:02.040 --> 01:58:03.040]   Bravo.
[01:58:03.040 --> 01:58:06.040]   At least I don't have to talk about the algorithm.
[01:58:06.040 --> 01:58:08.840]   That's what we love you Matt.
[01:58:08.840 --> 01:58:10.400]   Oh, I'll tell you a great.
[01:58:10.400 --> 01:58:11.400]   Yeah.
[01:58:11.400 --> 01:58:13.640]   How about a number of the week, Jeff Jarvis?
[01:58:13.640 --> 01:58:17.560]   So I was, I was a little appalled the story came by and I thought it was a good one for
[01:58:17.560 --> 01:58:18.560]   today.
[01:58:18.560 --> 01:58:23.600]   There was a restaurant in Silicon Valley, $600 a head Silicon Valley restaurant with gold
[01:58:23.600 --> 01:58:24.600]   flecked steaks.
[01:58:24.600 --> 01:58:26.600]   Oh, you see these kinds of ridiculous stories.
[01:58:26.600 --> 01:58:27.600]   You can find them.
[01:58:27.600 --> 01:58:30.440]   Even by the way, it does not look like a good steak.
[01:58:30.440 --> 01:58:35.240]   That is a no, it looks all it looks like a minute steak with gold leaf on it.
[01:58:35.240 --> 01:58:38.600]   And you know, if I make you come to my house, give me $500.
[01:58:38.600 --> 01:58:42.240]   I'll make you a nice ribeye, two and a half inches thick.
[01:58:42.240 --> 01:58:44.400]   It'll be delicious and no gold flecked.
[01:58:44.400 --> 01:58:45.400]   I'll eat it at all.
[01:58:45.400 --> 01:58:46.400]   It was first.
[01:58:46.400 --> 01:58:48.000]   All the guns is even better.
[01:58:48.000 --> 01:58:51.520]   If I were if I were if I were PR and any of the technology companies, I would want to
[01:58:51.520 --> 01:58:56.800]   send out a quiet, classified member that says, don't go there.
[01:58:56.800 --> 01:58:58.680]   You're going to make look Silicon Valley, just look awful.
[01:58:58.680 --> 01:59:02.840]   I think there's a there's a there's a backlash against technology and technologists.
[01:59:02.840 --> 01:59:04.320]   I think they're the new 1%.
[01:59:04.320 --> 01:59:07.480]   I'm worried about the reaction to Silicon Valley as a whole.
[01:59:07.480 --> 01:59:11.280]   And this kind of place does not help.
[01:59:11.280 --> 01:59:13.720]   They only have three to five dinners a week.
[01:59:13.720 --> 01:59:21.120]   It's a Japanese chef Hiroshi Kamura who moved to Silicon Valley and launched this deep pockets,
[01:59:21.120 --> 01:59:26.720]   you know, concept restaurant dinners, 395 ahead, 500, 600 with beverages and taxes.
[01:59:26.720 --> 01:59:30.840]   I got to point out that there are I mean, if you go to French laundry in Yountville up
[01:59:30.840 --> 01:59:33.720]   our way, it's going to cost you that much as well.
[01:59:33.720 --> 01:59:34.720]   That much?
[01:59:34.720 --> 01:59:35.720]   Oh, yeah.
[01:59:35.720 --> 01:59:36.720]   That much?
[01:59:36.720 --> 01:59:37.720]   Oh, yeah.
[01:59:37.720 --> 01:59:38.720]   With wine.
[01:59:38.720 --> 01:59:39.720]   Oh, yeah.
[01:59:39.720 --> 01:59:41.720]   Well, without the line, I can take it.
[01:59:41.720 --> 01:59:42.720]   I can take it.
[01:59:42.720 --> 01:59:45.800]   I can take it to several restaurants in Napa that would cost you that much.
[01:59:45.800 --> 01:59:46.800]   Yeah.
[01:59:46.800 --> 01:59:47.800]   Jesus.
[01:59:47.800 --> 01:59:48.800]   I'm just a Chipotle guy.
[01:59:48.800 --> 01:59:49.800]   Yeah, you spend too much time.
[01:59:49.800 --> 01:59:50.800]   It's a bad Uncle Bell.
[01:59:50.800 --> 01:59:51.800]   But you think you never do.
[01:59:51.800 --> 01:59:52.800]   I don't know why.
[01:59:52.800 --> 01:59:56.560]   I tell you what.
[01:59:56.560 --> 02:00:01.400]   Resident so but strange is it's in a it's in a shopping plaza in Los Altos.
[02:00:01.400 --> 02:00:04.400]   So it's not really I mean, look, there's a shoe rack outside.
[02:00:04.400 --> 02:00:08.240]   It's not really but there you go.
[02:00:08.240 --> 02:00:10.200]   You know, there you go.
[02:00:10.200 --> 02:00:11.200]   Heroshies.
[02:00:11.200 --> 02:00:16.120]   Heroshies opened by appointment only.
[02:00:16.120 --> 02:00:17.440]   So it's kind of you know what?
[02:00:17.440 --> 02:00:18.440]   Go to Morimoto.
[02:00:18.440 --> 02:00:19.920]   Like, I have okay.
[02:00:19.920 --> 02:00:21.800]   Obviously this is a five wagyu.
[02:00:21.800 --> 02:00:23.760]   That's why it's so expensive, but go to Morimoto.
[02:00:23.760 --> 02:00:26.160]   You get a nice wagyu for less than that.
[02:00:26.160 --> 02:00:27.160]   Well, that looks good.
[02:00:27.160 --> 02:00:28.160]   I'll take that.
[02:00:28.160 --> 02:00:33.800]   That looks like that's the Tonkatsu sandwich breaded deep fried pork cutlet in Deminglass.
[02:00:33.800 --> 02:00:34.800]   You get 10 courses.
[02:00:34.800 --> 02:00:35.800]   Come on, Jeff.
[02:00:35.800 --> 02:00:36.800]   What's the problem?
[02:00:36.800 --> 02:00:37.800]   Image.
[02:00:37.800 --> 02:00:40.400]   Oh, there you go.
[02:00:40.400 --> 02:00:41.400]   That is beautiful.
[02:00:41.400 --> 02:00:42.400]   That is Jeff.
[02:00:42.400 --> 02:00:43.400]   You're in New York.
[02:00:43.400 --> 02:00:44.800]   I hate you have this nonsense.
[02:00:44.800 --> 02:00:46.200]   Yeah, please, Jeff.
[02:00:46.200 --> 02:00:48.440]   I think you're so worried about Silicon Valley.
[02:00:48.440 --> 02:00:50.720]   I think you're an Impiccunious professor.
[02:00:50.720 --> 02:00:53.880]   You just don't understand.
[02:00:53.880 --> 02:00:57.240]   I've had I've had it food in Paris with gold leaf on it.
[02:00:57.240 --> 02:01:03.280]   We went to Loik Lemur took us to Gisavois and some of the food had gold leaf on it.
[02:01:03.280 --> 02:01:05.280]   I don't know why because it doesn't add anything.
[02:01:05.280 --> 02:01:06.280]   I don't know.
[02:01:06.280 --> 02:01:08.520]   It's probably not very good for you.
[02:01:08.520 --> 02:01:10.520]   Mr. Marks, I bet you you won.
[02:01:10.520 --> 02:01:11.520]   I bet you won't.
[02:01:11.520 --> 02:01:12.520]   Yeah, it's yeah.
[02:01:12.520 --> 02:01:15.200]   It's there's no real it's without like some good roughage, I guess.
[02:01:15.200 --> 02:01:17.160]   But what do you got for us, Jeff?
[02:01:17.160 --> 02:01:18.160]   Sorry, Kevin.
[02:01:18.160 --> 02:01:19.920]   I'll go three things up.
[02:01:19.920 --> 02:01:25.360]   My usual thing is indyweb.org, homebrew website club.
[02:01:25.360 --> 02:01:30.560]   There was going to be one this week in Portland, but it was so hot they moved to next week
[02:01:30.560 --> 02:01:31.560]   as well.
[02:01:31.560 --> 02:01:32.560]   So they're all happening next week.
[02:01:32.560 --> 02:01:35.280]   What is hot in Portland like 82 degrees?
[02:01:35.280 --> 02:01:36.280]   112.
[02:01:36.280 --> 02:01:39.880]   Oh, Portland can't take that.
[02:01:39.880 --> 02:01:41.840]   No, they don't wait for you.
[02:01:41.840 --> 02:01:42.840]   Snowy signal.
[02:01:42.840 --> 02:01:44.800]   That's terrible.
[02:01:44.800 --> 02:01:45.800]   Wow.
[02:01:45.800 --> 02:01:50.000]   But I bet and also it gets muggy there and you know, 112 where you are is like you can
[02:01:50.000 --> 02:01:54.320]   live with it because whereas when Portland it's when it's that that is also sweaty and
[02:01:54.320 --> 02:01:55.320]   it's bad.
[02:01:55.320 --> 02:01:59.640]   I was I was there when it was kidding like 95 and it was much less comfortable and silly
[02:01:59.640 --> 02:02:03.080]   and funny.
[02:02:03.080 --> 02:02:09.600]   So yeah, homebrew website club is happening London, Brighton, Portland, San Francisco and
[02:02:09.600 --> 02:02:13.320]   a few other places in Germany that I've forgotten.
[02:02:13.320 --> 02:02:17.200]   So go to that and the Liberty Foundation I wanted to mention this is another Portland
[02:02:17.200 --> 02:02:19.440]   connection here.
[02:02:19.440 --> 02:02:26.640]   This is the great idea by Andy McMillan, who's one of the organizers of XOXO.
[02:02:26.640 --> 02:02:34.320]   He's trying to set up a way to support artists to keep to maintain momentum and work through
[02:02:34.320 --> 02:02:35.320]   that.
[02:02:35.320 --> 02:02:39.040]   So this is this is well worth paying attention to and helping him from this is it's a great
[02:02:39.040 --> 02:02:40.520]   idea.
[02:02:40.520 --> 02:02:44.680]   And then the third one I've got is completely crazy, but I think you like it, Jeff.
[02:02:44.680 --> 02:02:45.680]   So have a look at this thing.
[02:02:45.680 --> 02:02:46.680]   Is this a video?
[02:02:46.680 --> 02:02:53.520]   If you have one extra thumb, just think of what you could do.
[02:02:53.520 --> 02:02:54.520]   All you could do.
[02:02:54.520 --> 02:02:55.520]   Yeah.
[02:02:55.520 --> 02:03:00.280]   So you have two opposable thumbs.
[02:03:00.280 --> 02:03:04.600]   This New Zealand designer Danny Claude developed his 3D printed.
[02:03:04.600 --> 02:03:05.600]   It's a prosthetic.
[02:03:05.600 --> 02:03:07.560]   I don't know how you how do you control it, Kevin?
[02:03:07.560 --> 02:03:11.920]   It shows you it shows you it's it's a chat to your legs.
[02:03:11.920 --> 02:03:19.600]   So you have to be sitting down, but then you flex your legs and back controls the thumb.
[02:03:19.600 --> 02:03:28.320]   There's a new way to play gin rummy, apparently.
[02:03:28.320 --> 02:03:31.160]   Hold those extra big hands.
[02:03:31.160 --> 02:03:32.160]   Wow.
[02:03:32.160 --> 02:03:33.160]   Wow.
[02:03:33.160 --> 02:03:35.280]   I feel like the whole show came from the onion today.
[02:03:35.280 --> 02:03:36.280]   I swear to God.
[02:03:36.280 --> 02:03:37.280]   The senses in your shoes.
[02:03:37.280 --> 02:03:38.280]   The Kickstarter.
[02:03:38.280 --> 02:03:39.280]   So it's wild.
[02:03:39.280 --> 02:03:40.280]   It's wild.
[02:03:40.280 --> 02:03:43.680]   I just thought I thought you should do you like that, Leo.
[02:03:43.680 --> 02:03:44.680]   That's a really.
[02:03:44.680 --> 02:03:45.680]   Sure.
[02:03:45.680 --> 02:03:46.680]   I need it.
[02:03:46.680 --> 02:03:47.680]   I got to buy it.
[02:03:47.680 --> 02:03:48.680]   I'm ordering it now.
[02:03:48.680 --> 02:03:50.200]   Oh, I would have already bought it.
[02:03:50.200 --> 02:03:51.520]   That's exactly right.
[02:03:51.520 --> 02:03:56.160]   I'm still waiting for Stacy told me about those LED light up by lashes and I ordered
[02:03:56.160 --> 02:03:57.160]   those.
[02:03:57.160 --> 02:03:59.400]   So that should be fun.
[02:03:59.400 --> 02:04:02.040]   Matt, so nice to see you.
[02:04:02.040 --> 02:04:08.480]   Congratulations on your good works and thank you for sacrificing on all of our behalf.
[02:04:08.480 --> 02:04:09.480]   It's great.
[02:04:09.480 --> 02:04:13.880]   It's so good to be back on this week in Google and it's hilarious because I was I was reading
[02:04:13.880 --> 02:04:17.760]   the chat and somebody was like, okay, where's the application page?
[02:04:17.760 --> 02:04:19.760]   So that warms my heart.
[02:04:19.760 --> 02:04:20.760]   USDS.gov/join.
[02:04:20.760 --> 02:04:21.760]   USDS.gov/join.
[02:04:21.760 --> 02:04:22.760]   Yeah.
[02:04:22.760 --> 02:04:23.760]   And yeah, absolutely.
[02:04:23.760 --> 02:04:24.760]   What a contribution.
[02:04:24.760 --> 02:04:25.760]   What a contribution.
[02:04:25.760 --> 02:04:26.760]   Thank you, Kevin Marks.
[02:04:26.760 --> 02:04:27.760]   It's mid-time.
[02:04:27.760 --> 02:04:28.760]   It's boring in the UK.
[02:04:28.760 --> 02:04:29.760]   Well, of course.
[02:04:29.760 --> 02:04:40.560]   Well, once it never rained, you'll have to sundown.
[02:04:40.560 --> 02:04:46.360]   So Kevin is at indieweb.org and doing a great job and love to your poodles and we will
[02:04:46.360 --> 02:04:47.800]   see you again very soon.
[02:04:47.800 --> 02:04:49.800]   I hope you'll come back and join us.
[02:04:49.800 --> 02:04:51.800]   Yeah, that's rain.
[02:04:51.800 --> 02:04:55.800]   Well, I mean, I'm in the conservatory, so it's raining on the roof.
[02:04:55.800 --> 02:04:56.800]   Of course.
[02:04:56.800 --> 02:05:00.960]   Are you in the conservatory with Professor Plum and the lead pipe?
[02:05:00.960 --> 02:05:01.960]   Thank you, Kevin.
[02:05:01.960 --> 02:05:06.480]   Well, the conservatory with the poodles, so it's funny.
[02:05:06.480 --> 02:05:07.480]   Thank you, too.
[02:05:07.480 --> 02:05:10.320]   And thanks to MIT for allowing Jeff to spend some time in there.
[02:05:10.320 --> 02:05:11.880]   Yes, thank you, MIT in the media lab.
[02:05:11.880 --> 02:05:13.120]   Your magic room in the media lab.
[02:05:13.120 --> 02:05:15.120]   Jeff Jarvis is at Buzzmachine.com.
[02:05:15.120 --> 02:05:22.240]   And he joins us each week here every Wednesday, about 130 Pacific, 430 Eastern, 2030 UTC for
[02:05:22.240 --> 02:05:23.680]   this week in Google.
[02:05:23.680 --> 02:05:25.240]   Thanks to all of you for being here.
[02:05:25.240 --> 02:05:28.160]   You can watch live the twit.tv/live.
[02:05:28.160 --> 02:05:32.120]   You can join us in the studio as Brandon Jeff and Melinda have.
[02:05:32.120 --> 02:05:37.240]   All you have to do is email tickets@twit.tv or, by the way, if you are live, chat with us
[02:05:37.240 --> 02:05:38.240]   at irc.twit.tv.
[02:05:38.240 --> 02:05:45.080]   It's always nice to have the chatroom behind the scenes throwing spitballs or bouquois.
[02:05:45.080 --> 02:05:50.400]   But if you can't be here live, you can always get the show on demand, audio and video of
[02:05:50.400 --> 02:05:56.640]   everything we do is available both at our website, twit.tv, in this case, twit.tv/twig.
[02:05:56.640 --> 02:06:00.560]   And wherever you get your podcasts, I mean, we are on every app, every platform.
[02:06:00.560 --> 02:06:01.560]   In fact, do me a favor.
[02:06:01.560 --> 02:06:02.560]   Subscribe to twig.
[02:06:02.560 --> 02:06:05.520]   That way you'll get it every single week.
[02:06:05.520 --> 02:06:06.760]   Thanks for joining us.
[02:06:06.760 --> 02:06:08.960]   We'll see you next time on this week in Google.
[02:06:08.960 --> 02:06:08.960]   Bye-bye.
[02:06:08.960 --> 02:06:18.960]   [MUSIC]

