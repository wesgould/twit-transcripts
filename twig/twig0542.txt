;FFMETADATA1
title=Surreptitious Wikipedia
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=542
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.320]   It's time for Twig this week at Google Stacey, Jeff and I are all here, three out of the
[00:00:05.320 --> 00:00:06.320]   four of us were at CES.
[00:00:06.320 --> 00:00:11.320]   Yeah, we'll talk a little bit about Stacey's big epiphanies, the things she realized, some
[00:00:11.320 --> 00:00:17.600]   very cool CES products, some less cool CES products, why YouTube's new content restrictions
[00:00:17.600 --> 00:00:23.000]   are going to be a problem for a lot of sites that aren't for kids only, and Facebook's
[00:00:23.000 --> 00:00:29.200]   decision to not tell you when a politician is lying is actually a good thing.
[00:00:29.200 --> 00:00:33.560]   It says Jeff Jarvis, it's all coming up next on Twig.
[00:00:33.560 --> 00:00:37.840]   This week at Google comes to you from the Twit LastPass Studios.
[00:00:37.840 --> 00:00:41.240]   Securing every access point in your company doesn't have to be a challenge.
[00:00:41.240 --> 00:00:46.080]   LastPass unifies access and authentication to make securing your employees simple and
[00:00:46.080 --> 00:00:47.080]   secure.
[00:00:47.080 --> 00:00:53.080]   Check out lastpass.com/twit to learn more.
[00:00:53.080 --> 00:01:04.320]   This is Twig.
[00:01:04.320 --> 00:01:05.660]   This is Twig.
[00:01:05.660 --> 00:01:12.680]   This week at Google, episode 542, recorded Wednesday, January 15, 2020.
[00:01:12.680 --> 00:01:15.720]   Sarah Ptiscious, Wikipedia.
[00:01:15.720 --> 00:01:19.440]   This week at Google is brought to you by HealthIQ.
[00:01:19.440 --> 00:01:24.800]   HealthIQ uses science and data to secure lower life insurance rates for healthy people like
[00:01:24.800 --> 00:01:25.800]   you.
[00:01:25.800 --> 00:01:30.560]   To see if you qualify, go to healthIQ.com/twig and take the HealthIQ quiz.
[00:01:30.560 --> 00:01:36.160]   It could help save you up to 41% on your life insurance premiums compared to other providers.
[00:01:36.160 --> 00:01:41.560]   And by LinkedIn marketing solutions, LinkedIn can help you speak to the right professionals
[00:01:41.560 --> 00:01:43.280]   at the right time.
[00:01:43.280 --> 00:01:48.320]   Right now, get a free $100 LinkedIn ad credit to launch your first campaign.
[00:01:48.320 --> 00:01:51.760]   Just visit linkedin.com/twig.
[00:01:51.760 --> 00:01:53.280]   And by Zapier.
[00:01:53.280 --> 00:01:57.360]   Zapier connects all your business software and handles the work for you so you could
[00:01:57.360 --> 00:01:59.160]   focus on what matters most.
[00:01:59.160 --> 00:02:05.920]   Right now, through the end of the month, go to zapier.com/twig for your free 14-day trial.
[00:02:05.920 --> 00:02:07.120]   It's time for Twig.
[00:02:07.120 --> 00:02:11.520]   This week in Google, the show we cover, the Google verse, the Twitter verse, the Facebook
[00:02:11.520 --> 00:02:18.320]   verse, and everything in between with Mr. Jeff Jarvis, professor of journalism at CUNY,
[00:02:18.320 --> 00:02:23.440]   blog at buzzmachine.com, the author of so many great books, including Public Parts, What
[00:02:23.440 --> 00:02:28.360]   Would Google Do, Gutenberg, Geeks, Bearing Gifts.
[00:02:28.360 --> 00:02:29.880]   Oh, that's it.
[00:02:29.880 --> 00:02:31.400]   The gang's back together.
[00:02:31.400 --> 00:02:32.400]   Yay!
[00:02:32.400 --> 00:02:35.560]   It is because Stacy Higginbotham is also here.
[00:02:35.560 --> 00:02:38.160]   Back as I am from CES.
[00:02:38.160 --> 00:02:39.160]   Hi, Stacy.
[00:02:39.160 --> 00:02:40.960]   Hello, y'all.
[00:02:40.960 --> 00:02:44.120]   She's getting Seattle's Snowpocalypse right now.
[00:02:44.120 --> 00:02:45.120]   I am.
[00:02:45.120 --> 00:02:46.120]   It's crazy.
[00:02:46.120 --> 00:02:48.080]   I've never seen this before in my life.
[00:02:48.080 --> 00:02:49.080]   Really?
[00:02:49.080 --> 00:02:50.080]   You've never had snow?
[00:02:50.080 --> 00:02:51.080]   Really?
[00:02:51.080 --> 00:02:52.080]   Oh, well, I've had snow.
[00:02:52.080 --> 00:02:55.080]   I mean, I lived in New York, but it was in the city, so we didn't have like...
[00:02:55.080 --> 00:02:56.080]   No, it was gray.
[00:02:56.080 --> 00:02:57.080]   Yeah.
[00:02:57.080 --> 00:02:58.080]   Yeah, it was gross.
[00:02:58.080 --> 00:02:59.080]   And how's your daughter?
[00:02:59.080 --> 00:03:01.120]   Your daughter definitely hasn't ever seen snow, right?
[00:03:01.120 --> 00:03:02.840]   No, they built a snow fort.
[00:03:02.840 --> 00:03:05.240]   She and my husband built a snow fort this morning.
[00:03:05.240 --> 00:03:06.240]   So cute.
[00:03:06.240 --> 00:03:07.240]   Dorps.
[00:03:07.240 --> 00:03:08.240]   That's so cute.
[00:03:08.240 --> 00:03:10.040]   When they come in, the tips of their fingers are black and falling off.
[00:03:10.040 --> 00:03:11.040]   I just...
[00:03:11.040 --> 00:03:12.040]   Oh, my God.
[00:03:12.040 --> 00:03:16.120]   Hey, that's Ann Proit, who doesn't know from snow and never will.
[00:03:16.120 --> 00:03:18.200]   Oh, I know snow and I hate snow.
[00:03:18.200 --> 00:03:19.200]   Yeah.
[00:03:19.200 --> 00:03:20.200]   I was the weird kid.
[00:03:20.200 --> 00:03:23.040]   My mom would tell us to go out and play and I'd say, "No."
[00:03:23.040 --> 00:03:24.040]   That stuff's cold and...
[00:03:24.040 --> 00:03:25.040]   Wait a minute.
[00:03:25.040 --> 00:03:26.040]   You didn't have snow in South Carolina.
[00:03:26.040 --> 00:03:27.040]   Oh, yeah.
[00:03:27.040 --> 00:03:28.720]   We get snow every February.
[00:03:28.720 --> 00:03:29.720]   Up in the mountains?
[00:03:29.720 --> 00:03:30.720]   We get the mountains.
[00:03:30.720 --> 00:03:31.720]   We're in the foothills.
[00:03:31.720 --> 00:03:32.720]   We're in the foothills.
[00:03:32.720 --> 00:03:33.720]   All right.
[00:03:33.720 --> 00:03:34.720]   But we get snow every year, January February.
[00:03:34.720 --> 00:03:35.720]   I think of it as the south.
[00:03:35.720 --> 00:03:37.720]   I don't think of it as getting cold enough to have snow.
[00:03:37.720 --> 00:03:38.720]   We get all the seasons.
[00:03:38.720 --> 00:03:39.720]   Oh, I love that.
[00:03:39.720 --> 00:03:41.600]   It's one of the northern California folks here.
[00:03:41.600 --> 00:03:43.360]   No, we don't get seasons.
[00:03:43.360 --> 00:03:46.080]   We get seasonal suggestions.
[00:03:46.080 --> 00:03:47.280]   I am wearing a scarf, though.
[00:03:47.280 --> 00:03:48.280]   It's Stacy's honor.
[00:03:48.280 --> 00:03:50.640]   Oh, it's a nice scarf.
[00:03:50.640 --> 00:03:51.640]   Isn't it?
[00:03:51.640 --> 00:03:52.640]   I like a good scarf.
[00:03:52.640 --> 00:03:53.640]   You look so regal, sir.
[00:03:53.640 --> 00:03:55.600]   I'm wearing a scarf myself.
[00:03:55.600 --> 00:03:56.600]   It's time to do this.
[00:03:56.600 --> 00:03:57.600]   Now, what about those people?
[00:03:57.600 --> 00:03:58.600]   I see these people in New York.
[00:03:58.600 --> 00:03:59.600]   It's a cold day today, right?
[00:03:59.600 --> 00:04:00.600]   It was like 38 degrees.
[00:04:00.600 --> 00:04:01.600]   And why not?
[00:04:01.600 --> 00:04:06.280]   I see the occasional bozo in a suit with just a scarf like that's going to keep warm.
[00:04:06.280 --> 00:04:07.280]   It does.
[00:04:07.280 --> 00:04:08.280]   That's what I'm doing.
[00:04:08.280 --> 00:04:11.720]   The bozo in the scarf.
[00:04:11.720 --> 00:04:14.000]   All you have to really do is keep this part right here.
[00:04:14.000 --> 00:04:15.000]   Maybe he's got a--
[00:04:15.000 --> 00:04:17.000]   That does help.
[00:04:17.000 --> 00:04:19.760]   It does help, but you still need more.
[00:04:19.760 --> 00:04:23.480]   I wish I had my Yale scarf because it was long.
[00:04:23.480 --> 00:04:25.960]   You could wrap it all the way around your head.
[00:04:25.960 --> 00:04:28.360]   Did you have a crimson scarf, Carsten?
[00:04:28.360 --> 00:04:29.360]   Of course.
[00:04:29.360 --> 00:04:30.360]   Yeah.
[00:04:30.360 --> 00:04:31.360]   Seven-foot scarf.
[00:04:31.360 --> 00:04:32.360]   Yeah, absolutely.
[00:04:32.360 --> 00:04:33.360]   Yeah.
[00:04:33.360 --> 00:04:34.360]   Okay.
[00:04:34.360 --> 00:04:36.880]   CES, the consumer electronic show.
[00:04:36.880 --> 00:04:37.880]   Books of your husband's call.
[00:04:37.880 --> 00:04:39.120]   Was it worth the trip?
[00:04:39.120 --> 00:04:40.120]   Yes.
[00:04:40.120 --> 00:04:41.120]   What do you think, Ed?
[00:04:41.120 --> 00:04:42.120]   It was outstanding.
[00:04:42.120 --> 00:04:43.120]   It was really fun.
[00:04:43.120 --> 00:04:44.600]   Totally worth it.
[00:04:44.600 --> 00:04:47.600]   We worked our dairy air shoes.
[00:04:47.600 --> 00:04:48.600]   Took us those shoes.
[00:04:48.600 --> 00:04:53.360]   Well, you know, it's kind of-- when we hit-- whenever we wrote the treatment for Antonya's
[00:04:53.360 --> 00:04:58.400]   excellent CES adventure, I had booked in four-- I said, we will do 10 segments a day for
[00:04:58.400 --> 00:04:59.400]   four days.
[00:04:59.400 --> 00:05:02.000]   We will have 40 segments plus three half hour shows.
[00:05:02.000 --> 00:05:03.000]   We got 38 segments.
[00:05:03.000 --> 00:05:05.280]   We didn't have more if they chucked some of them up.
[00:05:05.280 --> 00:05:06.280]   Right.
[00:05:06.280 --> 00:05:08.880]   And when it was all robots, there were like six things in it.
[00:05:08.880 --> 00:05:10.360]   We worked.
[00:05:10.360 --> 00:05:12.480]   And I think it came out quite nicely.
[00:05:12.480 --> 00:05:14.000]   I didn't see you, Stacey.
[00:05:14.000 --> 00:05:15.000]   I looked for you.
[00:05:15.000 --> 00:05:16.000]   I saw Kevin.
[00:05:16.000 --> 00:05:17.000]   I know.
[00:05:17.000 --> 00:05:18.000]   I'm sorry.
[00:05:18.000 --> 00:05:19.000]   I was only there for two days.
[00:05:19.000 --> 00:05:21.000]   Like, I left Wednesday night.
[00:05:21.000 --> 00:05:22.000]   You don't need to apologize.
[00:05:22.000 --> 00:05:25.160]   I'm just-- I'm sad I wanted to see you, but did you have fun?
[00:05:25.160 --> 00:05:26.400]   You wanted to take you.
[00:05:26.400 --> 00:05:27.400]   Yeah.
[00:05:27.400 --> 00:05:28.400]   Yeah.
[00:05:28.400 --> 00:05:30.640]   And we were trying to figure out a time to do like the sands with you, but we didn't
[00:05:30.640 --> 00:05:32.800]   even get to the sands until Wednesday afternoon.
[00:05:32.800 --> 00:05:33.800]   Oh, man, the sands.
[00:05:33.800 --> 00:05:35.800]   That sounds about right.
[00:05:35.800 --> 00:05:40.800]   But I am not going to the Las Vegas Convention Center again.
[00:05:40.800 --> 00:05:44.200]   All the cool stuff from the show is at the sands, I thought.
[00:05:44.200 --> 00:05:46.200]   Oh, the good IOT stuff.
[00:05:46.200 --> 00:05:47.200]   From the IOT stuff.
[00:05:47.200 --> 00:05:48.200]   Yeah.
[00:05:48.200 --> 00:05:50.760]   But I love the central hawks.
[00:05:50.760 --> 00:05:51.760]   That's all the TVs.
[00:05:51.760 --> 00:05:54.280]   You saw some nice 8K TVs, didn't you?
[00:05:54.280 --> 00:05:59.880]   OK, like I care about the-- I can't-- 8K TV to me is just like a greater number of flaws
[00:05:59.880 --> 00:06:00.880]   that I can see on.
[00:06:00.880 --> 00:06:03.520]   I'm just like, ah, stop.
[00:06:03.520 --> 00:06:04.800]   Wash your mouth out.
[00:06:04.800 --> 00:06:05.760]   Yeah.
[00:06:05.760 --> 00:06:06.760]   Yeah.
[00:06:06.760 --> 00:06:08.320]   It's not my thing.
[00:06:08.320 --> 00:06:12.000]   You got to see the Joker on 8K if you really want to have fun.
[00:06:12.000 --> 00:06:13.920]   Give me all the pixels.
[00:06:13.920 --> 00:06:14.920]   All the pixels.
[00:06:14.920 --> 00:06:18.520]   Well, you wrote the article on Stacy on IOT.com.
[00:06:18.520 --> 00:06:21.400]   I went to CES and had four epiphanies.
[00:06:21.400 --> 00:06:23.880]   I only could eat about three.
[00:06:23.880 --> 00:06:28.120]   So I was impressed that you could eat all four.
[00:06:28.120 --> 00:06:29.600]   What were your epiphanies?
[00:06:29.600 --> 00:06:30.600]   Oh, man.
[00:06:30.600 --> 00:06:31.600]   Let's see.
[00:06:31.600 --> 00:06:33.680]   I'm like clicking on this story like I can see.
[00:06:33.680 --> 00:06:35.560]   Like I can click here.
[00:06:35.560 --> 00:06:40.800]   If you were at CES and not overwhelmed by the array of products in front of you, I'm impressed,
[00:06:40.800 --> 00:06:41.800]   she writes.
[00:06:41.800 --> 00:06:44.800]   Every year I come back feeling like I only saw a tenth of the things.
[00:06:44.800 --> 00:06:49.960]   If you saw a tenth of the things you were doing really well, there were 4,500 booths
[00:06:49.960 --> 00:06:51.960]   each with many things.
[00:06:51.960 --> 00:06:56.480]   So if you saw a tenth of the things, you would have seen hundreds, maybe five or 600
[00:06:56.480 --> 00:06:57.480]   things.
[00:06:57.480 --> 00:06:58.480]   You didn't see that many even.
[00:06:58.480 --> 00:06:59.480]   Oh, my gosh.
[00:06:59.480 --> 00:07:00.320]   I feel like we saw about 400.
[00:07:00.320 --> 00:07:01.720]   So I've got it now.
[00:07:01.720 --> 00:07:03.560]   So one was-- and I did a panel.
[00:07:03.560 --> 00:07:08.240]   So my first epiphanie came from this panel and the AARP booth, which was actually really
[00:07:08.240 --> 00:07:09.240]   cool.
[00:07:09.240 --> 00:07:14.520]   I had thought-- when I think of technology for seniors, I think of health-related stuff.
[00:07:14.520 --> 00:07:17.880]   Most of us probably do our fall detection.
[00:07:17.880 --> 00:07:20.520]   And there was so much stuff on VR and EO.
[00:07:20.520 --> 00:07:21.520]   Exactly.
[00:07:21.520 --> 00:07:26.400]   The other big story, because hearing aids are going over the counter this year, there
[00:07:26.400 --> 00:07:33.240]   were a lot of companies like Phonak and showing over-the-counter hearing things, not just
[00:07:33.240 --> 00:07:36.920]   aids, not just audio, but sensors of all kinds.
[00:07:36.920 --> 00:07:37.920]   Wow.
[00:07:37.920 --> 00:07:40.840]   You just take a lot of really interesting sensors in the year.
[00:07:40.840 --> 00:07:44.120]   I think I wrote about that a couple of years ago for IEEE.
[00:07:44.120 --> 00:07:48.800]   But yeah, you can get galvanic skin response, you can get steps, you can get heart rate.
[00:07:48.800 --> 00:07:50.400]   I thought it was interesting that you thought that--
[00:07:50.400 --> 00:07:51.400]   I was interested in stuff, though.
[00:07:51.400 --> 00:07:55.000]   Us olds wanted a VR.
[00:07:55.000 --> 00:07:57.640]   I was surprised that you thought that was a good thing.
[00:07:57.640 --> 00:08:02.600]   So I don't know if it's a good thing, but I glad that they're doing things with it.
[00:08:02.600 --> 00:08:08.960]   And I will say I talked to somebody from Johns Hopkins also and a doctor from Humana talking
[00:08:08.960 --> 00:08:17.680]   about VR and not just for travel, although people apparently like that, but telemedicine.
[00:08:17.680 --> 00:08:20.920]   So there was a lot of interesting VR for doctors visits.
[00:08:20.920 --> 00:08:26.760]   Yes, we're getting back to the medicalization, but it also provides a social outlet.
[00:08:26.760 --> 00:08:28.680]   I don't know.
[00:08:28.680 --> 00:08:31.800]   Again, I don't know.
[00:08:31.800 --> 00:08:32.800]   I'm such a hermit.
[00:08:32.800 --> 00:08:34.040]   I don't care.
[00:08:34.040 --> 00:08:39.320]   I do know, for instance, my mom who's 86, loves technology.
[00:08:39.320 --> 00:08:40.680]   She loves her iPad.
[00:08:40.680 --> 00:08:42.880]   She loves her iPhone.
[00:08:42.880 --> 00:08:45.440]   She's an artist, so like Aunt, she likes to draw.
[00:08:45.440 --> 00:08:50.840]   She likes to use the pencil and draw on the iPad.
[00:08:50.840 --> 00:08:55.680]   For her, technology is a way to stay in touch.
[00:08:55.680 --> 00:08:57.960]   She doesn't get out much, but she can stay in touch with me.
[00:08:57.960 --> 00:09:01.560]   We do FaceTime all the time.
[00:09:01.560 --> 00:09:05.280]   I think technology, I completely get what they're saying about seniors in technology.
[00:09:05.280 --> 00:09:07.480]   I think there is a lot to be said.
[00:09:07.480 --> 00:09:09.120]   There is some kind of age to my father.
[00:09:09.120 --> 00:09:10.600]   I can't get my father on a smartphone.
[00:09:10.600 --> 00:09:16.520]   He just beyond him, but my wife's late mother, it was how they stayed in touch.
[00:09:16.520 --> 00:09:17.520]   Yes.
[00:09:17.520 --> 00:09:21.920]   This is just another way of being inclusive, if you will, today's technology.
[00:09:21.920 --> 00:09:27.080]   And I think that if a parent isn't, "Oh, I'm a Windows 10 person."
[00:09:27.080 --> 00:09:33.160]   If an older person, if you just get them like a Nest Hub Max or an Echo Show, the device
[00:09:33.160 --> 00:09:37.880]   with the camera and screen, when we first got the show, I would set it up in the kitchen
[00:09:37.880 --> 00:09:40.120]   while I'm cooking and my mom would be on it.
[00:09:40.120 --> 00:09:44.480]   And for her, it felt like she was sitting with us while we were cooking.
[00:09:44.480 --> 00:09:49.080]   There's things like that where it's not, for her, wasn't complicated.
[00:09:49.080 --> 00:09:51.520]   She just says, "Call, you know, call Leo."
[00:09:51.520 --> 00:09:53.600]   And then it rings me.
[00:09:53.600 --> 00:09:57.520]   It's not like they're sitting down coding.
[00:09:57.520 --> 00:09:59.280]   I don't know if she'd be in the VR, though.
[00:09:59.280 --> 00:10:02.080]   I don't know if I can get her an augmented or virtual reality.
[00:10:02.080 --> 00:10:05.240]   I guess if she goes like she is sitting in the kitchen.
[00:10:05.240 --> 00:10:06.480]   My mom liked VR.
[00:10:06.480 --> 00:10:14.960]   She actually enjoyed, it was kind of like just, we used to have one of those viewfinders when
[00:10:14.960 --> 00:10:15.960]   I was a little kid.
[00:10:15.960 --> 00:10:16.960]   Yeah, yeah.
[00:10:16.960 --> 00:10:17.960]   The view master.
[00:10:17.960 --> 00:10:18.960]   Yeah.
[00:10:18.960 --> 00:10:19.960]   Yeah, view master.
[00:10:19.960 --> 00:10:22.960]   She loved all the, remember when they were making all this content, like, of different
[00:10:22.960 --> 00:10:24.520]   places, she loved all that.
[00:10:24.520 --> 00:10:28.800]   She would just sit there and swivel her head around and look up and down.
[00:10:28.800 --> 00:10:29.800]   That's nice.
[00:10:29.800 --> 00:10:31.480]   And she thought it was super fun.
[00:10:31.480 --> 00:10:35.000]   So I honestly, I think it just depends on the person.
[00:10:35.000 --> 00:10:36.000]   Yes.
[00:10:36.000 --> 00:10:38.640]   Oh, last week we have a new feature on the show.
[00:10:38.640 --> 00:10:39.640]   You don't know about.
[00:10:39.640 --> 00:10:40.640]   Oh, cool.
[00:10:40.640 --> 00:10:42.320]   A Seinfeld episode and every show.
[00:10:42.320 --> 00:10:43.320]   So here it goes.
[00:10:43.320 --> 00:10:44.320]   I think I mentioned this one last week already, though.
[00:10:44.320 --> 00:10:48.880]   When I got my mother a kindle years back.
[00:10:48.880 --> 00:10:49.880]   Yeah.
[00:10:49.880 --> 00:10:53.880]   There was reaction was like Jerry's parents when he got them the fruit of the month club.
[00:10:53.880 --> 00:10:54.880]   Yeah.
[00:10:54.880 --> 00:10:56.880]   Why are you getting me all this fruit?
[00:10:56.880 --> 00:10:57.880]   I didn't ask for this fruit.
[00:10:57.880 --> 00:10:59.880]   Who could use all this food?
[00:10:59.880 --> 00:11:01.880]   Why would anybody ask this fruit?
[00:11:01.880 --> 00:11:02.880]   Exactly.
[00:11:02.880 --> 00:11:03.880]   The same reaction.
[00:11:03.880 --> 00:11:05.880]   Why would you do this to me?
[00:11:05.880 --> 00:11:06.880]   Why?
[00:11:06.880 --> 00:11:07.880]   Nope.
[00:11:07.880 --> 00:11:08.880]   Gave you that.
[00:11:08.880 --> 00:11:10.880]   It's your Seinfeld theme.
[00:11:10.880 --> 00:11:12.880]   We're going to play that.
[00:11:12.880 --> 00:11:16.240]   I could play a little bass, a little slap bass.
[00:11:16.240 --> 00:11:18.400]   Don't show the screen so they don't know where it came from.
[00:11:19.400 --> 00:11:20.400]   Oh, no.
[00:11:20.400 --> 00:11:23.400]   YouTube is going to slap us.
[00:11:23.400 --> 00:11:26.400]   You can't play the Jeopardy theme.
[00:11:26.400 --> 00:11:27.400]   That's right.
[00:11:27.400 --> 00:11:30.400]   I know Alex Trebek is going to come down hard.
[00:11:30.400 --> 00:11:31.400]   Right.
[00:11:31.400 --> 00:11:33.400]   I just got a little gadget.
[00:11:33.400 --> 00:11:35.400]   What is it?
[00:11:35.400 --> 00:11:37.400]   The O2 ring.
[00:11:37.400 --> 00:11:38.400]   It's an oximeter.
[00:11:38.400 --> 00:11:39.400]   It's to check your oxygen.
[00:11:39.400 --> 00:11:44.400]   It's this little thing that you put on your thumb at night and checks your oxygen all night.
[00:11:44.400 --> 00:11:47.400]   Because the doctor says I have sleep apnea.
[00:11:47.400 --> 00:11:53.840]   But the device that you wear for this thing, it's like this huge thing on your head and
[00:11:53.840 --> 00:11:56.400]   things going all around and oxygen things coming in.
[00:11:56.400 --> 00:11:58.400]   You need the better.
[00:11:58.400 --> 00:11:59.400]   You got to sleep.
[00:11:59.400 --> 00:12:01.400]   Supposedly you're sleeping and it's testing your sleep.
[00:12:01.400 --> 00:12:02.400]   You can't sleep with this crap on.
[00:12:02.400 --> 00:12:03.400]   You need the better.
[00:12:03.400 --> 00:12:04.400]   Look at this.
[00:12:04.400 --> 00:12:05.400]   Get the better.
[00:12:05.400 --> 00:12:06.400]   I got to get the better.
[00:12:06.400 --> 00:12:07.400]   I saw this.
[00:12:07.400 --> 00:12:08.400]   This is just, in fact, Michael loves this.
[00:12:08.400 --> 00:12:09.400]   Michael Sargent uses this.
[00:12:09.400 --> 00:12:13.400]   It is basically a sleep study in a little thing that glues to your forehead.
[00:12:13.400 --> 00:12:18.400]   You look like a dork, but, and I didn't say that to them.
[00:12:18.400 --> 00:12:22.480]   It's not going up your nose or anything and it does do all of those same measurements.
[00:12:22.480 --> 00:12:23.480]   It does.
[00:12:23.480 --> 00:12:27.840]   Or in a couple of months, you can get the Y-things scan watch.
[00:12:27.840 --> 00:12:31.800]   Now this is going crazy about this on Twitter.
[00:12:31.800 --> 00:12:32.800]   This is great.
[00:12:32.800 --> 00:12:34.800]   Jason Heiner loved this thing.
[00:12:34.800 --> 00:12:36.800]   In fact, I want to buy this.
[00:12:36.800 --> 00:12:37.800]   It's great for you, Jeff.
[00:12:37.800 --> 00:12:39.600]   Because it's got EKGs.
[00:12:39.600 --> 00:12:41.400]   It's got AFib detection.
[00:12:41.400 --> 00:12:43.400]   It's got sleep apnea or oximeter.
[00:12:43.400 --> 00:12:44.400]   Oximeter?
[00:12:44.400 --> 00:12:45.400]   Yep.
[00:12:45.400 --> 00:12:46.400]   Oximeter.
[00:12:46.400 --> 00:12:48.200]   It's amazing.
[00:12:48.200 --> 00:12:49.400]   So check this out.
[00:12:49.400 --> 00:13:00.600]   It's $249.2999, I think, for the 38 millimeter and then $300 or $299 for the 42 millimeter watch.
[00:13:00.600 --> 00:13:02.200]   And what's, it is pretty.
[00:13:02.200 --> 00:13:09.440]   What old people like you, Jeff, will like is that it's actually a wristwatch with hands
[00:13:09.440 --> 00:13:10.440]   and a second hand.
[00:13:10.440 --> 00:13:12.440]   It's a physical watch with just a little.
[00:13:12.440 --> 00:13:13.440]   Oh, I could read it.
[00:13:13.440 --> 00:13:14.840]   Yeah, I could see it's a real watch.
[00:13:14.840 --> 00:13:16.880]   But it has a little screen on it.
[00:13:16.880 --> 00:13:18.720]   So it does all the smartwatch stuff.
[00:13:18.720 --> 00:13:21.360]   This is their previous version, but it looks just like this.
[00:13:21.360 --> 00:13:25.080]   So it's a regular watch with a smartwatch screen, little screen.
[00:13:25.080 --> 00:13:26.280]   The straps are nicer.
[00:13:26.280 --> 00:13:29.520]   Yeah, this is, yeah, this is just like a classy watch.
[00:13:29.520 --> 00:13:30.520]   Yeah.
[00:13:30.520 --> 00:13:35.640]   It is, I mean, it's a nice watch and it has, it's, and it's medically, it's FDA approved.
[00:13:35.640 --> 00:13:38.120]   So this is not like, oh.
[00:13:38.120 --> 00:13:39.120]   I want to get this.
[00:13:39.120 --> 00:13:43.520]   I wear an Apple watch, but I think in some ways this is better, more functional.
[00:13:43.520 --> 00:13:44.520]   There's more things.
[00:13:44.520 --> 00:13:48.360]   So Carson, I just sent, because I don't have Kevin your email, I sent Carson, I sent you
[00:13:48.360 --> 00:13:50.480]   the picture of me being embarrassed.
[00:13:50.480 --> 00:13:52.920]   The device you have to wear for the sleep test.
[00:13:52.920 --> 00:13:54.120]   Now you don't go to the lab anymore.
[00:13:54.120 --> 00:13:56.080]   You don't know, but it is such.
[00:13:56.080 --> 00:13:58.120]   I wore one the other night.
[00:13:58.120 --> 00:14:01.240]   So I actually did sleep study for sleep apnea as well.
[00:14:01.240 --> 00:14:06.960]   A couple of weeks ago in Jeff, I think you're making a little bit of a mountain out of a
[00:14:06.960 --> 00:14:07.960]   mole.
[00:14:07.960 --> 00:14:10.440]   It is, it is a lot of stuff.
[00:14:10.440 --> 00:14:14.560]   All night, the lady, the lady, it talks to you, the lady wakes up and says, put the nose
[00:14:14.560 --> 00:14:16.400]   thing back in and in and in.
[00:14:16.400 --> 00:14:20.480]   So the old Jeff, Jeff, Jeff.
[00:14:20.480 --> 00:14:26.160]   Oh, mine had a slightly smaller head thing, but it had a strap around your heart.
[00:14:26.160 --> 00:14:29.320]   You looked like the guy in Breaking Bad who couldn't talk, had to bring that bell the
[00:14:29.320 --> 00:14:30.320]   whole time.
[00:14:30.320 --> 00:14:31.320]   Yeah.
[00:14:31.320 --> 00:14:36.200]   This is the watch.
[00:14:36.200 --> 00:14:38.920]   This wouldn't you prefer Jeff to wear?
[00:14:38.920 --> 00:14:39.920]   This is the wife.
[00:14:39.920 --> 00:14:43.760]   It's called the scan watch, but you said it's not going to be out.
[00:14:43.760 --> 00:14:45.600]   Stacey for a couple of months.
[00:14:45.600 --> 00:14:47.920]   I think it's Q2 coming soon.
[00:14:47.920 --> 00:14:51.800]   I think they were saying Q2, which usually means the end of Q2.
[00:14:51.800 --> 00:14:55.000]   So this is the report I get from my thing.
[00:14:55.000 --> 00:14:58.640]   Oh, that's tracked by the hour and tells you what.
[00:14:58.640 --> 00:15:02.320]   So I had 97% average oxygen.
[00:15:02.320 --> 00:15:03.320]   Okay.
[00:15:03.320 --> 00:15:09.680]   I had, let's see, oh, I had 38 drops, more than 4%.
[00:15:09.680 --> 00:15:10.680]   I guess that sleep apnea.
[00:15:10.680 --> 00:15:11.680]   I don't know.
[00:15:11.680 --> 00:15:12.680]   I don't know how to read this stuff.
[00:15:12.680 --> 00:15:13.680]   That's the problem.
[00:15:13.680 --> 00:15:14.680]   Oh, I can tell you because I read mine.
[00:15:14.680 --> 00:15:17.520]   I had 32 and I was barely sleep apnea.
[00:15:17.520 --> 00:15:18.520]   Oh, okay.
[00:15:18.520 --> 00:15:21.480]   So this was the highest I've had.
[00:15:21.480 --> 00:15:26.880]   So yeah, that's why I think that what do you, what's the, none of you is Jewish, I
[00:15:26.880 --> 00:15:29.400]   think the thing been wear on their forehead.
[00:15:29.400 --> 00:15:30.400]   Yeah.
[00:15:30.400 --> 00:15:31.400]   Yeah.
[00:15:31.400 --> 00:15:32.400]   Yeah.
[00:15:32.400 --> 00:15:33.400]   I can't recall it.
[00:15:33.400 --> 00:15:36.280]   I can't remember chat room, but it's not a good thing.
[00:15:36.280 --> 00:15:37.840]   It doesn't work.
[00:15:37.840 --> 00:15:38.840]   This is kind of neat.
[00:15:38.840 --> 00:15:44.200]   And I'm going to go to my doctor and say, okay, do you still say I have it?
[00:15:44.200 --> 00:15:53.200]   I was able to speak with the Phillips folks in San's and they had the sleep band or something
[00:15:53.200 --> 00:15:54.200]   like that.
[00:15:54.200 --> 00:15:56.640]   I can't remember exactly what it was called, but I think it was called smart sleep.
[00:15:56.640 --> 00:15:57.640]   Yep.
[00:15:57.640 --> 00:16:00.840]   Smart sleep, deep sleep headband and their update and their product.
[00:16:00.840 --> 00:16:07.480]   I believe it is Q2 and it's not necessarily a sleep tracker, but it's more of a way of
[00:16:07.480 --> 00:16:11.960]   training you to figure out how to sleep better and fixing your health.
[00:16:11.960 --> 00:16:13.600]   It seems to be a big category.
[00:16:13.600 --> 00:16:14.600]   Really?
[00:16:14.600 --> 00:16:19.120]   And you have to think that some of this is baby boomers who, you know, I mean, this is
[00:16:19.120 --> 00:16:26.680]   going to be a huge market as we all, you know, face knee surgery and more sleep and, you
[00:16:26.680 --> 00:16:28.240]   know, and all of this.
[00:16:28.240 --> 00:16:29.240]   The seat belt?
[00:16:29.240 --> 00:16:30.240]   Hold on.
[00:16:30.240 --> 00:16:31.240]   Hold on.
[00:16:31.240 --> 00:16:32.240]   Yep.
[00:16:32.240 --> 00:16:33.240]   Okay.
[00:16:33.240 --> 00:16:37.120]   Casper, the mattress company, filed to go public last Friday.
[00:16:37.120 --> 00:16:38.120]   Oh, they did.
[00:16:38.120 --> 00:16:41.560]   And they named the global sleep economy.
[00:16:41.560 --> 00:16:42.560]   Wow.
[00:16:42.560 --> 00:16:46.760]   I'm just going to call it that as $432 billion opportunity.
[00:16:46.760 --> 00:16:51.800]   The US sleep economy is only a $79 billion opportunity.
[00:16:51.800 --> 00:16:59.440]   And that counts things like mattresses, bedding, bedroom furniture, et cetera, et cetera.
[00:16:59.440 --> 00:17:00.440]   It's pretty hilarious.
[00:17:00.440 --> 00:17:04.720]   Anyway, so I wanted to give you actual numbers for sleep being a big deal.
[00:17:04.720 --> 00:17:05.720]   Go.
[00:17:05.720 --> 00:17:13.360]   So I went and saw, so CPAP, I'm being, I don't know, I might get certified for the World
[00:17:13.360 --> 00:17:16.880]   Trade Center health fund in which I saw it get it for free.
[00:17:16.880 --> 00:17:24.760]   But if not, to get the CPAP plus the mask plus the cleaner thing they advertise every
[00:17:24.760 --> 00:17:27.160]   two minutes, it's like $1,200.
[00:17:27.160 --> 00:17:28.160]   Wow.
[00:17:28.160 --> 00:17:29.160]   Yes.
[00:17:29.160 --> 00:17:33.520]   And your insurance company will monitor that you're actually using it because CPAP for
[00:17:33.520 --> 00:17:34.520]   now connected.
[00:17:34.520 --> 00:17:38.480]   And if you don't use it, they'll be like, yep, we're going to take it away.
[00:17:38.480 --> 00:17:41.440]   And we're going to increase your rate.
[00:17:41.440 --> 00:17:43.600]   This is a privacy violation.
[00:17:43.600 --> 00:17:45.080]   This will probably agree.
[00:17:45.080 --> 00:17:46.640]   Oh my God.
[00:17:46.640 --> 00:17:47.640]   What just happened?
[00:17:47.640 --> 00:17:48.640]   I know.
[00:17:48.640 --> 00:17:49.640]   You agreed?
[00:17:49.640 --> 00:17:50.640]   Is it a fact?
[00:17:50.640 --> 00:17:51.640]   I think it's tech panic.
[00:17:51.640 --> 00:17:52.640]   Wait a minute.
[00:17:52.640 --> 00:17:53.640]   What?
[00:17:53.640 --> 00:17:54.640]   Moral panic, Jeff.
[00:17:54.640 --> 00:17:55.640]   I know.
[00:17:55.640 --> 00:17:59.080]   I know, both of them agreed on something for once.
[00:17:59.080 --> 00:18:00.080]   Real hate.
[00:18:00.080 --> 00:18:01.080]   I know.
[00:18:01.080 --> 00:18:02.080]   I know.
[00:18:02.080 --> 00:18:03.080]   It's a lie.
[00:18:03.080 --> 00:18:04.080]   Come on.
[00:18:04.080 --> 00:18:05.080]   Fight you too.
[00:18:05.080 --> 00:18:06.080]   I'm a few things.
[00:18:06.080 --> 00:18:12.080]   So I will say that was one of my epiphanies, which is tech firms need to grow up and recognize
[00:18:12.080 --> 00:18:15.560]   the power, the potential harm of their innovations.
[00:18:15.560 --> 00:18:17.680]   And I'm not seeing that yet.
[00:18:17.680 --> 00:18:24.360]   And like Jeff, I would say Jeff needs to recognize the potential harm of some of these tech innovations
[00:18:24.360 --> 00:18:25.360]   himself.
[00:18:25.360 --> 00:18:26.360]   And I just did.
[00:18:26.360 --> 00:18:27.360]   That was exciting.
[00:18:27.360 --> 00:18:29.640]   Aren't you wonderful, Jeff?
[00:18:29.640 --> 00:18:30.640]   She wiped the tears.
[00:18:30.640 --> 00:18:31.640]   She was so excited.
[00:18:31.640 --> 00:18:33.240]   If you start liking each other, this is just going to ruin the show.
[00:18:33.240 --> 00:18:34.240]   That's okay.
[00:18:34.240 --> 00:18:38.880]   I'll be all annoyed Stacy enough for both of us, Jeff.
[00:18:38.880 --> 00:18:41.880]   Stacy's epiphany number two.
[00:18:41.880 --> 00:18:42.880]   Speaking of.
[00:18:42.880 --> 00:18:43.880]   Oh, okay.
[00:18:43.880 --> 00:18:44.880]   Oh, okay.
[00:18:44.880 --> 00:18:45.880]   This one was good.
[00:18:45.880 --> 00:18:46.880]   Yeah.
[00:18:46.880 --> 00:18:47.880]   We are near.
[00:18:47.880 --> 00:18:48.880]   We are near.
[00:18:48.880 --> 00:18:50.800]   Serious enough about climate change.
[00:18:50.800 --> 00:18:51.800]   Yeah.
[00:18:51.800 --> 00:18:58.240]   I saw some really awesome devices for climate change that run the gamut from like crazy fabrics
[00:18:58.240 --> 00:19:03.760]   for industrial, like keeping people cool on industrial sites to personal devices to
[00:19:03.760 --> 00:19:08.400]   this crazy thing that pulled moisture from the air and made it potable water out of it.
[00:19:08.400 --> 00:19:12.800]   Samsung had a or LG had a $20,000 refrigerator.
[00:19:12.800 --> 00:19:14.600]   Let you go herbs inside.
[00:19:14.600 --> 00:19:15.600]   Yes, sure.
[00:19:15.600 --> 00:19:16.600]   Right.
[00:19:16.600 --> 00:19:17.600]   That's good for the year.
[00:19:17.600 --> 00:19:22.840]   Did you see hires zero, higher zero waste kitchen by any chance?
[00:19:22.840 --> 00:19:23.840]   Oh, no.
[00:19:23.840 --> 00:19:24.840]   What do they do with the waste?
[00:19:24.840 --> 00:19:25.840]   Oh, my.
[00:19:25.840 --> 00:19:30.840]   Well, so the idea was you would and this was only a concept, but you it was a beautiful
[00:19:30.840 --> 00:19:36.440]   kitchen where that you were growing herbs and vegetables on your wall and you had a monitoring
[00:19:36.440 --> 00:19:39.400]   system built into the wall to manage that.
[00:19:39.400 --> 00:19:45.040]   You also had a system that weighed out your food and could identify it.
[00:19:45.040 --> 00:19:49.240]   So you put food on it, whatever you had in your fridge that you wanted to get rid of.
[00:19:49.240 --> 00:19:53.560]   And then it would show you like project the slices that you needed to make or the weights
[00:19:53.560 --> 00:19:57.320]   that you needed to make and there were scales integrated into things, projectors integrated
[00:19:57.320 --> 00:19:58.320]   into things.
[00:19:58.320 --> 00:20:01.920]   It was really a fun, fun kitchen.
[00:20:01.920 --> 00:20:03.840]   And does it help you with composting potentially?
[00:20:03.840 --> 00:20:05.720]   It does help the composter.
[00:20:05.720 --> 00:20:06.720]   Right.
[00:20:06.720 --> 00:20:10.560]   That waste is all the food you didn't eat and the packaging and all that stuff.
[00:20:10.560 --> 00:20:11.560]   Yeah.
[00:20:11.560 --> 00:20:13.080]   Well, the packaging they didn't have an answer for it.
[00:20:13.080 --> 00:20:16.040]   They had a recycling center as part of the thing that encomposed.
[00:20:16.040 --> 00:20:17.040]   I did.
[00:20:17.040 --> 00:20:18.040]   There was a personal greenhouse.
[00:20:18.040 --> 00:20:26.440]   You see in the sands, the small greenhouse hydroponics, the herbs were growing up sideways.
[00:20:26.440 --> 00:20:31.080]   So I wouldn't be surprised to see a lot of stuff like that coming along.
[00:20:31.080 --> 00:20:32.400]   In my new house.
[00:20:32.400 --> 00:20:33.640]   Your photo.
[00:20:33.640 --> 00:20:35.560]   You're probably asking about this.
[00:20:35.560 --> 00:20:37.480]   Your photo says Kevin is trying the device.
[00:20:37.480 --> 00:20:39.360]   I don't see him trying the device.
[00:20:39.360 --> 00:20:40.760]   Oh, you know what?
[00:20:40.760 --> 00:20:44.640]   I think I might have cut the device out of that photo because I have a terrible face.
[00:20:44.640 --> 00:20:48.880]   He's testing the personal throwing device from Ember, but you can't see his wrist.
[00:20:48.880 --> 00:20:50.840]   That was the one that went on the wrist, right?
[00:20:50.840 --> 00:20:51.840]   Oh, yeah.
[00:20:51.840 --> 00:20:53.520]   This is the wrong photo I put in here.
[00:20:53.520 --> 00:20:54.520]   Sorry, guys.
[00:20:54.520 --> 00:20:58.080]   He is wearing the Ember, but I had a larger version of the photo for him.
[00:20:58.080 --> 00:21:04.000]   And by the way, I'm glad that that mean S. Hickenbluth bottom gave you the courtesy
[00:21:04.000 --> 00:21:07.080]   of the use of the image in your own sight.
[00:21:07.080 --> 00:21:08.920]   Courtesy S. Hickenblutham.
[00:21:08.920 --> 00:21:12.240]   I just pull it because sometimes I use Kevin's or others.
[00:21:12.240 --> 00:21:14.200]   It's just our style, man.
[00:21:14.200 --> 00:21:17.400]   I have a style guide for Stacy on IOT if you believe it.
[00:21:17.400 --> 00:21:19.160]   I respect that.
[00:21:19.160 --> 00:21:21.960]   You should just write image courtesy me.
[00:21:21.960 --> 00:21:22.960]   OK, no.
[00:21:22.960 --> 00:21:25.000]   It should be italicized.
[00:21:25.000 --> 00:21:27.240]   I clearly did not do a good job when I posted this.
[00:21:27.240 --> 00:21:29.000]   Oh, you were drunk when you did this.
[00:21:29.000 --> 00:21:30.000]   It's OK.
[00:21:30.000 --> 00:21:33.000]   I was on a CES hangover.
[00:21:33.000 --> 00:21:34.000]   Believe me.
[00:21:34.000 --> 00:21:35.000]   I understand that.
[00:21:35.000 --> 00:21:36.640]   I went to bed at seven last night.
[00:21:36.640 --> 00:21:37.640]   I was exhausted.
[00:21:37.640 --> 00:21:38.640]   How were your feet?
[00:21:38.640 --> 00:21:40.120]   That's the killer of Buds.
[00:21:40.120 --> 00:21:43.680]   You know, I did it at your feet.
[00:21:43.680 --> 00:21:45.600]   We walked a lot, but I like seven miles.
[00:21:45.600 --> 00:21:46.600]   I got good shoes.
[00:21:46.600 --> 00:21:49.120]   I had really good shoes.
[00:21:49.120 --> 00:21:52.360]   The carpeting is-- and I both noticed this.
[00:21:52.360 --> 00:21:56.440]   If it's a fancy company, they have thick carpeting.
[00:21:56.440 --> 00:22:01.080]   It's like a cheesy company, like the Arnold Schwarzenegger Robot Company.
[00:22:01.080 --> 00:22:02.080]   All right.
[00:22:02.080 --> 00:22:03.280]   You're in the concrete, then.
[00:22:03.280 --> 00:22:04.280]   That's concrete, baby.
[00:22:04.280 --> 00:22:05.280]   You know, there's no concrete.
[00:22:05.280 --> 00:22:07.760]   I'm starting to round people constantly as they're-- especially
[00:22:07.760 --> 00:22:09.840]   naturally, they're texting and doing all that.
[00:22:09.840 --> 00:22:11.320]   Oh, God.
[00:22:11.320 --> 00:22:12.840]   So I hadn't been there in eight years.
[00:22:12.840 --> 00:22:18.320]   It is now an epidemic of people looking at their phone, just wandering into walls, wandering
[00:22:18.320 --> 00:22:22.720]   into you, going three feet an hour.
[00:22:22.720 --> 00:22:25.920]   I mean, like, dude, go to the bathroom.
[00:22:25.920 --> 00:22:26.920]   You're going to the bathroom.
[00:22:26.920 --> 00:22:27.920]   Go to the bathroom.
[00:22:27.920 --> 00:22:28.920]   Don't walk there.
[00:22:28.920 --> 00:22:29.920]   Right.
[00:22:29.920 --> 00:22:32.000]   Like in a funeral procession.
[00:22:32.000 --> 00:22:33.000]   Looking at your phone.
[00:22:33.000 --> 00:22:34.000]   I throw me nuts.
[00:22:34.000 --> 00:22:36.720]   I think I was telling Mr. Sergeant yesterday.
[00:22:36.720 --> 00:22:41.000]   It was a couple times where, you know, I'm trailing behind you and Mr. Wilkinson when
[00:22:41.000 --> 00:22:42.400]   we was doing our TV segment.
[00:22:42.400 --> 00:22:43.400]   And I had my cameras--
[00:22:43.400 --> 00:22:44.400]   He was shamed.
[00:22:44.400 --> 00:22:45.400]   --to my shoulder.
[00:22:45.400 --> 00:22:46.400]   Yeah.
[00:22:46.400 --> 00:22:48.200]   And people just kept bumping into me.
[00:22:48.200 --> 00:22:50.600]   And I'm like, really, I know you see me.
[00:22:50.600 --> 00:22:51.600]   We hate to eat more.
[00:22:51.600 --> 00:22:52.600]   We hate to eat more.
[00:22:52.600 --> 00:22:55.880]   And I decided that I was just going to be rigid as I walked through.
[00:22:55.880 --> 00:22:58.160]   And if somebody bumped into me, they felt it.
[00:22:58.160 --> 00:22:59.160]   Good.
[00:22:59.160 --> 00:23:00.160]   This is what happened.
[00:23:00.160 --> 00:23:02.640]   This is the most I've been bumped at CES.
[00:23:02.640 --> 00:23:06.360]   Like I was just like, what-- like my shoulders were just constantly.
[00:23:06.360 --> 00:23:07.360]   They're not looking, right?
[00:23:07.360 --> 00:23:08.360]   They're not looking, right?
[00:23:08.360 --> 00:23:09.360]   Right.
[00:23:09.360 --> 00:23:10.360]   Everybody's looking down.
[00:23:10.360 --> 00:23:11.360]   I was like--
[00:23:11.360 --> 00:23:13.640]   I just-- it just really cut into my Pokemon Go playing.
[00:23:13.640 --> 00:23:17.760]   I just want to say.
[00:23:17.760 --> 00:23:21.960]   So I'm going to say this because I've been at CES for the last five years and Kevin had
[00:23:21.960 --> 00:23:24.400]   been there for the last 15, maybe six years.
[00:23:24.400 --> 00:23:27.280]   I don't remember.
[00:23:27.280 --> 00:23:30.200]   Did anyone notice that the Intel booth was gone?
[00:23:30.200 --> 00:23:32.800]   This is the first year that Intel was not the main booth.
[00:23:32.800 --> 00:23:33.800]   You know what was--
[00:23:33.800 --> 00:23:36.840]   Not only did I notice it, but there was a Chinese TV.
[00:23:36.840 --> 00:23:37.840]   Yes.
[00:23:37.840 --> 00:23:57.400]   T
[00:23:57.400 --> 00:24:00.840]   And they put a lot of money into it.
[00:24:00.840 --> 00:24:05.360]   And Qualcomm was behind Intel and they moved over to the North Hall with all their automotive
[00:24:05.360 --> 00:24:06.360]   stuff.
[00:24:06.360 --> 00:24:07.360]   So I was just like--
[00:24:07.360 --> 00:24:08.600]   You remember where the booths were?
[00:24:08.600 --> 00:24:09.600]   Oh, you do.
[00:24:09.600 --> 00:24:10.600]   Well, it's PTSD.
[00:24:10.600 --> 00:24:11.600]   You can.
[00:24:11.600 --> 00:24:15.840]   If you go in and Intel was hard to-- I mean, it was like--
[00:24:15.840 --> 00:24:16.840]   Whoa, blue.
[00:24:16.840 --> 00:24:17.840]   Right.
[00:24:17.840 --> 00:24:18.840]   Yeah.
[00:24:18.840 --> 00:24:20.640]   Really, it was an AMD show Intel, I think.
[00:24:20.640 --> 00:24:24.320]   I'm too lost out to AMD in this particular show.
[00:24:24.320 --> 00:24:27.120]   We talked about that on Sunday.
[00:24:27.120 --> 00:24:29.960]   But there were a lot of green things.
[00:24:29.960 --> 00:24:32.480]   The badge no longer is in a plastic badge holder.
[00:24:32.480 --> 00:24:36.160]   It's a recyclable kind of plastic-y paper thing.
[00:24:36.160 --> 00:24:38.360]   Still cost you $300 if you lose it.
[00:24:38.360 --> 00:24:39.360]   Really?
[00:24:39.360 --> 00:24:40.360]   Oh, yeah.
[00:24:40.360 --> 00:24:41.360]   Did you lose it?
[00:24:41.360 --> 00:24:42.360]   I didn't lose it.
[00:24:42.360 --> 00:24:44.360]   Oh, but they tell you like three times when you get a badge.
[00:24:44.360 --> 00:24:45.360]   Don't lose it.
[00:24:45.360 --> 00:24:46.360]   It's three.
[00:24:46.360 --> 00:24:47.360]   And there was recycling bins for the badges.
[00:24:47.360 --> 00:24:48.360]   Put your badge when you're done.
[00:24:48.360 --> 00:24:50.680]   Put your badge and lanyard in there.
[00:24:50.680 --> 00:24:56.320]   Instead of lots of plastic water bottles everywhere you went, there were water filtration systems
[00:24:56.320 --> 00:24:57.320]   you could fill up your--
[00:24:57.320 --> 00:25:00.320]   I never saw a water filtration system.
[00:25:00.320 --> 00:25:01.320]   What?
[00:25:01.320 --> 00:25:02.320]   I was--
[00:25:02.320 --> 00:25:03.560]   I was all over the place.
[00:25:03.560 --> 00:25:06.560]   I was like, yeah, I was sad.
[00:25:06.560 --> 00:25:07.560]   Interesting.
[00:25:07.560 --> 00:25:08.560]   Huh.
[00:25:08.560 --> 00:25:09.560]   Couldn't miss it.
[00:25:09.560 --> 00:25:11.080]   No, I missed all of those.
[00:25:11.080 --> 00:25:15.760]   I think that they're at least-- it still feels like lip service because you're also
[00:25:15.760 --> 00:25:20.200]   seeing a million disposable gadgets with lithium-ion batteries.
[00:25:20.200 --> 00:25:26.160]   I mean, it is not-- in no sense can you say the modern tech industry is eco-friendly.
[00:25:26.160 --> 00:25:27.160]   Not yet.
[00:25:27.160 --> 00:25:32.800]   No, I was looking at the-- I was talking to 3M actually there about their filtreat sensors
[00:25:32.800 --> 00:25:35.720]   or filtreat-- what are those things called?
[00:25:35.720 --> 00:25:39.920]   The things that filter-- filter for your air conditioning.
[00:25:39.920 --> 00:25:42.640]   And they have a connected one, of course.
[00:25:42.640 --> 00:25:46.560]   And it is a Bluetooth sensor that measures air pressure.
[00:25:46.560 --> 00:25:49.320]   So it detects how efficient your air is flowing through the filter.
[00:25:49.320 --> 00:25:51.360]   And then it's like, oh, I'm not efficient.
[00:25:51.360 --> 00:25:52.360]   Change me.
[00:25:52.360 --> 00:25:55.760]   But when they change you, you just throw that whole thing away.
[00:25:55.760 --> 00:26:01.160]   And they ask you to peel the sensor with the Bluetooth radio off and recycle it, treat
[00:26:01.160 --> 00:26:02.960]   it like you do batteries.
[00:26:02.960 --> 00:26:03.960]   But--
[00:26:03.960 --> 00:26:04.960]   No.
[00:26:04.960 --> 00:26:07.600]   I mean, are you?
[00:26:07.600 --> 00:26:08.600]   No.
[00:26:08.600 --> 00:26:09.600]   Nobody's going to take that--
[00:26:09.600 --> 00:26:12.080]   That's actually epiphany number three.
[00:26:12.080 --> 00:26:18.040]   Tech firms need to grow up and recognize the personal harm of their inventions.
[00:26:18.040 --> 00:26:19.560]   Yes.
[00:26:19.560 --> 00:26:24.400]   This is the-- no longer do you get out a jail-- get a get out a jail free card because you're
[00:26:24.400 --> 00:26:25.800]   like, I'm doing tech.
[00:26:25.800 --> 00:26:27.480]   It's solving cool problems.
[00:26:27.480 --> 00:26:30.520]   You need to start thinking about the impact of what you're creating.
[00:26:30.520 --> 00:26:32.800]   And your executives need to start thinking about that.
[00:26:32.800 --> 00:26:37.760]   And this came about because Plume announced this really cool Wi-Fi motion technology.
[00:26:37.760 --> 00:26:39.520]   They did a deal with a company called Cognitive.
[00:26:39.520 --> 00:26:41.720]   And it is really cool.
[00:26:41.720 --> 00:26:44.080]   It is like motion sensing.
[00:26:44.080 --> 00:26:45.800]   They've got people tracking.
[00:26:45.800 --> 00:26:47.600]   Right now it's just for-- sorry.
[00:26:47.600 --> 00:26:48.880]   It's through your Wi-Fi router.
[00:26:48.880 --> 00:26:53.840]   So if you have a Wi-Fi router that has the Plume software running on it, it has the ability
[00:26:53.840 --> 00:26:57.800]   to basically add a motion sensor in your house.
[00:26:57.800 --> 00:27:03.280]   So when someone disrupts the RF signals between the Wi-Fi, between your devices, it'll be like,
[00:27:03.280 --> 00:27:06.440]   hey, something's happening.
[00:27:06.440 --> 00:27:07.440]   And if they--
[00:27:07.440 --> 00:27:08.440]   What would they use it for?
[00:27:08.440 --> 00:27:10.240]   Why would someone like that?
[00:27:10.240 --> 00:27:16.640]   You would want it for coming into a room and turning the lights on, for example.
[00:27:16.640 --> 00:27:20.320]   So no one who it is, but there's a big bag of water in the room.
[00:27:20.320 --> 00:27:21.320]   Exactly.
[00:27:21.320 --> 00:27:23.120]   Big bag of water interest room.
[00:27:23.120 --> 00:27:27.720]   They actually can do person recognition if you have your cell phone on and they are testing
[00:27:27.720 --> 00:27:31.440]   things like keep recognition to recognize the individual without a cell phone.
[00:27:31.440 --> 00:27:34.400]   And of course you'll get the data, but who else gets the data is the question.
[00:27:34.400 --> 00:27:36.120]   Your ISP gets the data.
[00:27:36.120 --> 00:27:37.120]   Oh great.
[00:27:37.120 --> 00:27:41.520]   Now Comcast knows which room in the house I'm in.
[00:27:41.520 --> 00:27:43.760]   Comcast is a Plume customer.
[00:27:43.760 --> 00:27:45.000]   Comcast owns.
[00:27:45.000 --> 00:27:46.000]   Is it investors?
[00:27:46.000 --> 00:27:47.200]   They do not own-- they do not-- yeah.
[00:27:47.200 --> 00:27:49.400]   They're big investors.
[00:27:49.400 --> 00:27:52.680]   They have an investment, but they also manufacture the Plume pods for--
[00:27:52.680 --> 00:27:53.680]   Right.
[00:27:53.680 --> 00:27:54.680]   Their own stuff.
[00:27:54.680 --> 00:27:55.680]   Right.
[00:27:55.680 --> 00:27:57.320]   Now they're selling it as if it's their thing.
[00:27:57.320 --> 00:27:58.320]   I see.
[00:27:58.320 --> 00:27:59.320]   I didn't know that.
[00:27:59.320 --> 00:28:01.320]   All I saw was just their own little--
[00:28:01.320 --> 00:28:03.320]   But they're also in the Samsung Wi-Fi?
[00:28:03.320 --> 00:28:06.320]   Yeah, those little octagon pods or something like that.
[00:28:06.320 --> 00:28:07.320]   Those are plume pods.
[00:28:07.320 --> 00:28:08.320]   Yeah.
[00:28:08.320 --> 00:28:09.320]   I did not know that.
[00:28:09.320 --> 00:28:12.800]   But they're the power inside the Samsung SmartThings Wi-Fi routers?
[00:28:12.800 --> 00:28:13.800]   Plume is?
[00:28:13.800 --> 00:28:14.800]   Yes.
[00:28:14.800 --> 00:28:15.800]   Oh, I didn't know that.
[00:28:15.800 --> 00:28:19.640]   And they just did a deal with Lynxis, so they might become part of Lynxis routers.
[00:28:19.640 --> 00:28:21.000]   They've got some good technology.
[00:28:21.000 --> 00:28:22.240]   I used Plume for a long time.
[00:28:22.240 --> 00:28:23.920]   I love the idea.
[00:28:23.920 --> 00:28:26.680]   But the results were not great.
[00:28:26.680 --> 00:28:29.440]   I like the results now.
[00:28:29.440 --> 00:28:30.920]   They're not faster on work.
[00:28:30.920 --> 00:28:32.560]   Did you move with them?
[00:28:32.560 --> 00:28:33.920]   I did not move with them.
[00:28:33.920 --> 00:28:34.920]   But you got something moving.
[00:28:34.920 --> 00:28:35.920]   I could have them now.
[00:28:35.920 --> 00:28:36.920]   Oh, you-- Comcast?
[00:28:36.920 --> 00:28:37.920]   Comcast?
[00:28:37.920 --> 00:28:38.920]   Oh, yeah.
[00:28:38.920 --> 00:28:43.400]   No, I have-- I went all in on Plume when they first came out.
[00:28:43.400 --> 00:28:48.640]   I have the new base station and like 12 little plumes because the problem with the plume
[00:28:48.640 --> 00:28:51.360]   is each room has to have a plume.
[00:28:51.360 --> 00:28:55.680]   So your Wi-Fi extender-- unlike, say, Euro or Orbea, or LinkVellop.
[00:28:55.680 --> 00:28:56.680]   TP-Lumps or whatnot.
[00:28:56.680 --> 00:28:59.360]   Yeah, you have to have one in every room.
[00:28:59.360 --> 00:29:03.800]   But the way they described it and the reason that they say it works is because Wi-Fi is
[00:29:03.800 --> 00:29:05.480]   like a lamp.
[00:29:05.480 --> 00:29:07.520]   And it doesn't travel very well through walls.
[00:29:07.520 --> 00:29:10.480]   So what you really want is a lamp in every room.
[00:29:10.480 --> 00:29:14.160]   You can't expect the light from the room next door to do a very good job getting into
[00:29:14.160 --> 00:29:15.160]   the room.
[00:29:15.160 --> 00:29:16.160]   That's a fair analogy.
[00:29:16.160 --> 00:29:17.440]   Yeah, I think it's a decent analogy.
[00:29:17.440 --> 00:29:20.200]   The guy who told me that, by the way, was the guy who told me humans are the biggest
[00:29:20.200 --> 00:29:23.440]   problem with Wi-Fi because we're big bags of water.
[00:29:23.440 --> 00:29:27.640]   We like it like movable Wi-Fi interference devices.
[00:29:27.640 --> 00:29:28.640]   Right.
[00:29:28.640 --> 00:29:29.640]   Yep.
[00:29:29.640 --> 00:29:30.640]   We are a pain.
[00:29:30.640 --> 00:29:34.040]   So they're turning water into gold.
[00:29:34.040 --> 00:29:35.040]   Gold.
[00:29:35.040 --> 00:29:36.680]   Yes, they're gold.
[00:29:36.680 --> 00:29:37.680]   And--
[00:29:37.680 --> 00:29:38.680]   So, but this--
[00:29:38.680 --> 00:29:39.680]   Go on.
[00:29:39.680 --> 00:29:44.280]   Tiffany number four, not everything needs to be smart, especially Leo.
[00:29:44.280 --> 00:29:45.280]   Yes.
[00:29:45.280 --> 00:29:46.680]   You don't need to--
[00:29:46.680 --> 00:29:48.520]   What does that mean?
[00:29:48.520 --> 00:29:54.040]   So I saw a lot of things that we had connected to gather data on people that I didn't think
[00:29:54.040 --> 00:29:56.000]   were necessary.
[00:29:56.000 --> 00:29:57.960]   This is the tech industry at large.
[00:29:57.960 --> 00:30:01.640]   So they get any idea they say, like AI or blockchain.
[00:30:01.640 --> 00:30:05.480]   They just say, well, spread it all over everything.
[00:30:05.480 --> 00:30:06.480]   So, yeah.
[00:30:06.480 --> 00:30:12.120]   So this is-- I was looking at my-- I think it was the third P on a stick and get information
[00:30:12.120 --> 00:30:13.120]   company that I see.
[00:30:13.120 --> 00:30:14.120]   And I was like--
[00:30:14.120 --> 00:30:16.120]   Yeah, I missed those.
[00:30:16.120 --> 00:30:17.120]   [LAUGHTER]
[00:30:17.120 --> 00:30:22.520]   I'm like, OK, so this device will tell me, are you drinking enough water?
[00:30:22.520 --> 00:30:25.360]   Are you eating enough vegetables or too much protein?
[00:30:25.360 --> 00:30:27.200]   And I'm like, you know what?
[00:30:27.200 --> 00:30:31.760]   If you're telling me something, eat enough vegetables or in the case of better, you need
[00:30:31.760 --> 00:30:33.200]   better sleep, right?
[00:30:33.200 --> 00:30:35.120]   Sleep more.
[00:30:35.120 --> 00:30:36.280]   There's not a lot like--
[00:30:36.280 --> 00:30:37.280]   It's not that useful.
[00:30:37.280 --> 00:30:38.280]   That's not going to help me.
[00:30:38.280 --> 00:30:39.280]   It's not that useful.
[00:30:39.280 --> 00:30:45.360]   Unless I'm one of these dedicated people who are going to be really-- I might eat more
[00:30:45.360 --> 00:30:49.560]   greens for a day or two, but I'm not going to change my life because I purchased something
[00:30:49.560 --> 00:30:50.840]   and it told me.
[00:30:50.840 --> 00:30:55.400]   And this may seem overly cynical, but this kind of data getting out into the world, I
[00:30:55.400 --> 00:30:59.120]   just-- I don't think we need most of this.
[00:30:59.120 --> 00:31:00.120]   I'll have to be honest.
[00:31:00.120 --> 00:31:04.640]   Actually, you hit on something because I've been saying for a long time, don't do-- we
[00:31:04.640 --> 00:31:06.560]   have-- I have had a lot of sleep trackers.
[00:31:06.560 --> 00:31:09.240]   All it does makes you anxious about your sleep patterns.
[00:31:09.240 --> 00:31:11.560]   It doesn't help you sleep because it's not telling anything you don't know.
[00:31:11.560 --> 00:31:12.560]   I didn't sleep well.
[00:31:12.560 --> 00:31:13.560]   I know.
[00:31:13.560 --> 00:31:14.560]   I'm tired.
[00:31:14.560 --> 00:31:18.040]   And I think you hit something here, though.
[00:31:18.040 --> 00:31:21.800]   These companies are not making it because they think they're going to help you sleep
[00:31:21.800 --> 00:31:22.800]   better.
[00:31:22.800 --> 00:31:26.960]   They're making it because they can sell the data that they get from watching you.
[00:31:26.960 --> 00:31:30.440]   And so it isn't really-- none of these devices are in your interest.
[00:31:30.440 --> 00:31:32.760]   What's the value of that data?
[00:31:32.760 --> 00:31:33.920]   Oh, there's-- I don't know.
[00:31:33.920 --> 00:31:34.920]   There's-- I don't know.
[00:31:34.920 --> 00:31:39.480]   But I remember talking to Philippe Kahn, who created-- he was a guy-- he was like a legend
[00:31:39.480 --> 00:31:42.000]   in the computer industry, created Turbo Pascal.
[00:31:42.000 --> 00:31:45.840]   And the first smartphone camera, he has a patent on it.
[00:31:45.840 --> 00:31:48.880]   But the other thing he did is create a company called MotionX.
[00:31:48.880 --> 00:31:52.120]   He's the guy who makes all those sensors in everything.
[00:31:52.120 --> 00:31:54.360]   It's in your watch and your phone and everything.
[00:31:54.360 --> 00:31:56.600]   Everybody's using his patents.
[00:31:56.600 --> 00:32:02.760]   And he was telling me about the sleep tracker I use, which is sold by Beautyrest.
[00:32:02.760 --> 00:32:04.960]   And it's a little pad that goes under your bed.
[00:32:04.960 --> 00:32:07.640]   And it's-- he makes the hardware.
[00:32:07.640 --> 00:32:11.760]   And he's-- I wish I could find the clip from the triangulation in Philippe's--
[00:32:11.760 --> 00:32:14.160]   you wouldn't believe the data we're getting.
[00:32:14.160 --> 00:32:15.680]   It's like-- Oh, man.
[00:32:15.680 --> 00:32:20.120]   And it's-- but what he's saying is the insights we can offer get better and better
[00:32:20.120 --> 00:32:22.120]   and better as we learn more and more and more.
[00:32:22.120 --> 00:32:24.360]   So they will say, well, did you drink last night?
[00:32:24.360 --> 00:32:25.600]   Did you exercise?
[00:32:25.600 --> 00:32:26.760]   When did you eat?
[00:32:26.760 --> 00:32:28.160]   How late did you eat?
[00:32:28.160 --> 00:32:30.760]   And then they correlate that with your sleep patterns.
[00:32:30.760 --> 00:32:34.600]   And he says, as people use these devices, they'll become more useful.
[00:32:34.600 --> 00:32:36.760]   So there's one use, which is a benign use.
[00:32:36.760 --> 00:32:38.000]   That's the case you used to then.
[00:32:38.000 --> 00:32:41.560]   Well, it's a benign use because you're going to-- you're an early adopter.
[00:32:41.560 --> 00:32:43.960]   But you're going to get a better and better product because--
[00:32:43.960 --> 00:32:45.360]   I mean, that's Google's doing it.
[00:32:45.360 --> 00:32:47.960]   Why do you think Google asks you if that's a crosswalk or a hydrant?
[00:32:47.960 --> 00:32:48.960]   Exactly.
[00:32:48.960 --> 00:32:51.360]   Because they're learning from you.
[00:32:51.360 --> 00:32:52.760]   They're using you.
[00:32:52.760 --> 00:32:56.560]   There's no benefit to you for telling Google that's a hydrant.
[00:32:56.560 --> 00:32:58.960]   And some of the sleep data is interesting.
[00:32:58.960 --> 00:33:00.960]   It will be interesting for doctors.
[00:33:00.960 --> 00:33:01.960]   Down the road.
[00:33:01.960 --> 00:33:06.360]   But it will also-- I mean, there are, like, if your corporate wellness program
[00:33:06.360 --> 00:33:10.960]   tracks your sleep, for example, once your employer understands how much you've slept
[00:33:10.960 --> 00:33:14.360]   up last night or whether or not you had too much to drink.
[00:33:14.360 --> 00:33:18.360]   I mean, these are things that could start having real world implications for people.
[00:33:18.360 --> 00:33:20.960]   And I would hope we would prevent things like that.
[00:33:20.960 --> 00:33:21.760]   But once again--
[00:33:21.760 --> 00:33:22.760]   Oh, we are not.
[00:33:22.760 --> 00:33:23.560]   We say we're not--
[00:33:23.560 --> 00:33:26.960]   We need legislation about the use of the data, not necessarily the collection of the data.
[00:33:26.960 --> 00:33:27.560]   Well, that's right.
[00:33:27.560 --> 00:33:28.360]   Because here's a benefit.
[00:33:28.360 --> 00:33:30.360]   So Philippe's saying, look, as Mark data, I get the better.
[00:33:30.360 --> 00:33:31.760]   I can tell you how you slept.
[00:33:31.760 --> 00:33:33.160]   You're going to benefit from it.
[00:33:33.160 --> 00:33:36.160]   But he might also be selling it to insurance companies or--
[00:33:36.160 --> 00:33:37.160]   Yeah, right.
[00:33:37.160 --> 00:33:39.760]   And there's prohibitions on use.
[00:33:39.760 --> 00:33:40.460]   There's permission.
[00:33:40.460 --> 00:33:41.260]   There's transparency.
[00:33:41.260 --> 00:33:42.660]   There's all kinds of things that we should be looking at.
[00:33:42.660 --> 00:33:46.960]   But your insurance company can monitor your use of the CPAP.
[00:33:46.960 --> 00:33:50.060]   Right, because they're paying for it.
[00:33:50.060 --> 00:33:52.660]   Well, I'm paying for you guys.
[00:33:52.660 --> 00:33:55.660]   Since they're paying for it, you should be a bit monitored.
[00:33:55.660 --> 00:33:59.160]   Well, I'll call you in the morning and tell you how well I slept.
[00:33:59.160 --> 00:34:02.560]   They want to see if you're actually using something because they're spending the money on it.
[00:34:02.560 --> 00:34:03.360]   No, I just did.
[00:34:03.360 --> 00:34:03.360]   It's interesting.
[00:34:03.360 --> 00:34:04.860]   It's just taking a sift.
[00:34:04.860 --> 00:34:08.660]   Your employer, which right now does not see that kind of data.
[00:34:08.660 --> 00:34:10.560]   And should never see that kind of data.
[00:34:10.560 --> 00:34:12.060]   I want to see how healthy my people are.
[00:34:12.060 --> 00:34:14.360]   Can I just-- I have to do this again, you guys.
[00:34:14.360 --> 00:34:15.160]   Check this out.
[00:34:15.160 --> 00:34:15.860]   It's crazy.
[00:34:15.860 --> 00:34:16.860]   I have never seen anything like this.
[00:34:16.860 --> 00:34:20.360]   It's snowpocalypse in Bainbridge Island.
[00:34:20.360 --> 00:34:23.060]   It's pouring white stuff.
[00:34:23.060 --> 00:34:24.460]   Please keep that up there.
[00:34:24.460 --> 00:34:26.260]   Oh, it's nice, isn't it?
[00:34:26.260 --> 00:34:27.060]   It's lovely.
[00:34:27.060 --> 00:34:29.060]    Leather outside is frightful. 
[00:34:29.060 --> 00:34:30.160]   That's a nice little--
[00:34:30.160 --> 00:34:32.460]    I'm sure daylight. 
[00:34:32.460 --> 00:34:35.660]   Move it over a little left so we get the window frame out of there.
[00:34:35.660 --> 00:34:36.160]   So we just get--
[00:34:36.160 --> 00:34:36.960]   Oh, sorry.
[00:34:36.960 --> 00:34:37.360]   Yeah.
[00:34:37.360 --> 00:34:37.860]   Zoom in.
[00:34:37.860 --> 00:34:38.360]   Okay.
[00:34:38.360 --> 00:34:38.860]   Yeah.
[00:34:38.860 --> 00:34:39.360]   Okay.
[00:34:39.360 --> 00:34:39.560]   Center.
[00:34:39.560 --> 00:34:40.060]   Okay.
[00:34:40.060 --> 00:34:41.060]   I got to stand up.
[00:34:41.060 --> 00:34:41.560]   There.
[00:34:41.560 --> 00:34:42.060]   Dance.
[00:34:42.060 --> 00:34:42.560]   No.
[00:34:42.560 --> 00:34:43.060]   No.
[00:34:43.060 --> 00:34:43.560]   No.
[00:34:43.560 --> 00:34:44.060]   Center.
[00:34:44.060 --> 00:34:45.060]   There you go.
[00:34:45.060 --> 00:34:47.060]   Do you want more treats?
[00:34:47.060 --> 00:34:47.560]   Oh!
[00:34:47.560 --> 00:34:48.560]   Oh!
[00:34:48.560 --> 00:34:49.060]   Oh!
[00:34:49.060 --> 00:34:50.060]   It's a snowpocalypse.
[00:34:50.060 --> 00:34:50.560]   Nice.
[00:34:50.560 --> 00:34:51.060]   Nice.
[00:34:51.060 --> 00:34:51.560]   Mr. Kevin.
[00:34:51.560 --> 00:34:52.060]   Nice.
[00:34:52.060 --> 00:34:53.060]   No sheep.
[00:34:53.060 --> 00:34:55.460]   Where the heck did sheep come?
[00:34:55.460 --> 00:34:57.460]   I have no-- Kevin is a master of the tricaster.
[00:34:57.460 --> 00:34:58.460]   You're talking about sleep.
[00:34:58.460 --> 00:34:59.460]   Sleep.
[00:34:59.460 --> 00:34:59.960]   Oh!
[00:34:59.960 --> 00:35:00.960]   You made a play to run a reference.
[00:35:00.960 --> 00:35:01.960]   Oh!
[00:35:01.960 --> 00:35:02.960]   Sleep to Andrew.
[00:35:02.960 --> 00:35:03.960]   Oh, man.
[00:35:03.960 --> 00:35:04.960]   Oh, Jesus.
[00:35:04.960 --> 00:35:07.460]   Boy, that is an obscure-- Kevin, I'm proud of you.
[00:35:07.460 --> 00:35:08.460]   You see that?
[00:35:08.460 --> 00:35:12.660]   That's the original Philip K. Dick's short story that Blade Runner is based on.
[00:35:12.660 --> 00:35:13.160]   Right.
[00:35:13.160 --> 00:35:14.160]   He is next level.
[00:35:14.160 --> 00:35:15.860]   But I am impressed that a man of your youth--
[00:35:15.860 --> 00:35:17.060]   He is next level.
[00:35:17.060 --> 00:35:17.960]   He's next level.
[00:35:17.960 --> 00:35:19.960]   That's another way of putting it, yes.
[00:35:19.960 --> 00:35:24.260]   Kevin is planning on buying a pet fitness tracker.
[00:35:24.260 --> 00:35:26.260]   That's the epiphany I got.
[00:35:26.260 --> 00:35:26.760]   Oh!
[00:35:26.760 --> 00:35:27.760]   Yeah!
[00:35:27.760 --> 00:35:28.760]   Isn't that hell?
[00:35:28.760 --> 00:35:30.360]   He is going to buy the whistle fit.
[00:35:30.360 --> 00:35:31.360]   Did you guys see this?
[00:35:31.360 --> 00:35:32.360]   This is a commit.
[00:35:32.360 --> 00:35:33.360]   This is a commit.
[00:35:33.360 --> 00:35:35.360]   This is for your dog.
[00:35:35.360 --> 00:35:37.460]   This is for your dog-- it's a fit bit for your dog.
[00:35:37.460 --> 00:35:42.660]   It tracks not just steps, but it also tracks licks, shakes, and I want to say something
[00:35:42.660 --> 00:35:43.660]   else.
[00:35:43.660 --> 00:35:45.660]   And Norm has allergies.
[00:35:45.660 --> 00:35:47.780]   So he licks himself a lot.
[00:35:47.780 --> 00:35:51.860]   And Kevin thinks that-- Oh, not his lick of you, but his lick of himself.
[00:35:51.860 --> 00:35:52.860]   Himself.
[00:35:52.860 --> 00:35:53.860]   So he licks his paws.
[00:35:53.860 --> 00:35:55.960]   That's a common thing for dogs with allergies.
[00:35:55.960 --> 00:35:56.960]   Yeah.
[00:35:56.960 --> 00:36:01.060]   So they're interested in finding out-- I don't know more about his allergies.
[00:36:01.060 --> 00:36:02.060]   And this will also--
[00:36:02.060 --> 00:36:03.660]   Normans privacy is going to be violent.
[00:36:03.660 --> 00:36:04.660]   Poor Norman.
[00:36:04.660 --> 00:36:08.360]   And I bet you Kevin's privacy a little bit, too.
[00:36:08.360 --> 00:36:11.860]   You get notifications when it's time to go for a walk.
[00:36:11.860 --> 00:36:16.460]   I always wonder about-- I don't want my phone to tell me it's time to walk the dog.
[00:36:16.460 --> 00:36:21.700]   Yeah, I never really found a use for all of the connected stuff for pets.
[00:36:21.700 --> 00:36:25.760]   Because most of the time there's something about feeding or something about exercise.
[00:36:25.760 --> 00:36:28.160]   And I don't think you need a device to remind you about it.
[00:36:28.160 --> 00:36:29.160]   No, they'll remind you.
[00:36:29.160 --> 00:36:30.160]   They'll remind you.
[00:36:30.160 --> 00:36:31.160]   They'll remind you.
[00:36:31.160 --> 00:36:32.160]   We'll see.
[00:36:32.160 --> 00:36:33.160]   And this is why it was in my "You Don't Need to Be Smart" section.
[00:36:33.160 --> 00:36:36.260]   But Kevin was like, I really want this information.
[00:36:36.260 --> 00:36:42.160]   Did you also see the dog talking device from language less?
[00:36:42.160 --> 00:36:43.560]   Did it translate?
[00:36:43.560 --> 00:36:44.560]   It's late.
[00:36:44.560 --> 00:36:45.960]   OK, sort of.
[00:36:45.960 --> 00:36:47.160]   There's two trends here.
[00:36:47.160 --> 00:36:49.660]   One, stupid stuff that's connected.
[00:36:49.660 --> 00:36:51.960]   The other is heart rate variability.
[00:36:51.960 --> 00:36:59.760]   So this company from Japan measures your dog's heart rate variability to determine if it is happy,
[00:36:59.760 --> 00:37:04.560]   excited, relaxed, stressed, or afraid.
[00:37:04.560 --> 00:37:09.760]   And then it will-- I'm trying to-- let me pull up my device.
[00:37:09.760 --> 00:37:14.160]   Because I know human heart rate variability can tell you a lot of stuff about it.
[00:37:14.160 --> 00:37:15.160]   That makes sense.
[00:37:15.160 --> 00:37:16.160]   And that is true.
[00:37:16.160 --> 00:37:25.160]   Since you train, if you lift, you want to lift-- let's see, the more variable, the better.
[00:37:25.160 --> 00:37:27.120]   So you want to lift when there's a lot of variability.
[00:37:27.120 --> 00:37:29.920]   You don't want to lift when the variability is low because you're still in recovery.
[00:37:29.920 --> 00:37:30.920]   Now, you know that.
[00:37:30.920 --> 00:37:35.920]   You take a day off after you lift heavy, but it helps you do it a little bit better.
[00:37:35.920 --> 00:37:38.320]   Optimize your performance.
[00:37:38.320 --> 00:37:42.720]   All of that makes sense for our tracking with pets, especially because pets can't tell you
[00:37:42.720 --> 00:37:43.720]   I'm stressed out.
[00:37:43.720 --> 00:37:45.720]   They can't just verbally tell you that.
[00:37:45.720 --> 00:37:47.920]   And they hide, they don't see the point.
[00:37:47.920 --> 00:37:49.320]   Wait, wait, wait, wait, wait, wait.
[00:37:49.320 --> 00:37:55.320]   Let's not get-- what's the matter?
[00:37:55.320 --> 00:38:01.800]   It is an external device-based treatment for premature ejaculation.
[00:38:01.800 --> 00:38:04.600]   So that's smart technology gone truly crazy.
[00:38:04.600 --> 00:38:06.840]   So this was my epiphany.
[00:38:06.840 --> 00:38:07.840]   This is at CES.
[00:38:07.840 --> 00:38:13.880]   Yeah, so last year, you remember CES had awarded a vibrator best--
[00:38:13.880 --> 00:38:14.880]   Right.
[00:38:14.880 --> 00:38:15.880]   --and then--
[00:38:15.880 --> 00:38:16.880]   It's only last year.
[00:38:16.880 --> 00:38:17.880]   Yeah, it was only last year.
[00:38:17.880 --> 00:38:18.880]   And they took it back.
[00:38:18.880 --> 00:38:19.880]   And they pulled it.
[00:38:19.880 --> 00:38:20.880]   Right.
[00:38:20.880 --> 00:38:21.880]   Because, oh, oh.
[00:38:21.880 --> 00:38:22.880]   And female sexuality.
[00:38:22.880 --> 00:38:23.880]   Male sexuality.
[00:38:23.880 --> 00:38:24.880]   Fine.
[00:38:24.880 --> 00:38:25.880]   But females?
[00:38:25.880 --> 00:38:26.880]   Mm-hmm.
[00:38:26.880 --> 00:38:33.440]   So they got-- the good thing after that is that that company got more publicity than
[00:38:33.440 --> 00:38:36.880]   they would have ever gotten if they'd just got the award and everybody went on with
[00:38:36.880 --> 00:38:38.180]   their lives.
[00:38:38.180 --> 00:38:45.520]   And this year, CES decided to vote entire swaths of the show floor to female sexuality.
[00:38:45.520 --> 00:38:46.520]   Why?
[00:38:46.520 --> 00:38:47.520]   They're one.
[00:38:47.520 --> 00:38:48.520]   They're one.
[00:38:48.520 --> 00:38:49.520]   Yeah, right hand.
[00:38:49.520 --> 00:38:50.520]   Lots of them.
[00:38:50.520 --> 00:38:57.640]   I just-- I declined to give it any-- I just didn't-- I wasn't going to--
[00:38:57.640 --> 00:39:02.480]   I still worry about why does it have to be Bluetooth connected for those things.
[00:39:02.480 --> 00:39:03.480]   I just--
[00:39:03.480 --> 00:39:04.480]   Or Wi-Fi.
[00:39:04.480 --> 00:39:05.480]   Or Wi-Fi.
[00:39:05.480 --> 00:39:06.480]   Or Wi-Fi.
[00:39:06.480 --> 00:39:07.480]   That was just me.
[00:39:07.480 --> 00:39:08.480]   There was a lot of that.
[00:39:08.480 --> 00:39:09.480]   I'm not trying to go to show up with it.
[00:39:09.480 --> 00:39:13.240]   I played with one for guys.
[00:39:13.240 --> 00:39:16.040]   I used my fingers, not other parts.
[00:39:16.040 --> 00:39:17.040]   Yes.
[00:39:17.040 --> 00:39:18.920]   I saw.
[00:39:18.920 --> 00:39:20.920]   We decided not to run that segment.
[00:39:20.920 --> 00:39:21.920]   Mm-hmm.
[00:39:21.920 --> 00:39:25.800]   I just feel like I'm going to stick with computers.
[00:39:25.800 --> 00:39:26.800]   Processes.
[00:39:26.800 --> 00:39:27.800]   This is fascinating.
[00:39:27.800 --> 00:39:30.560]   Wait, did you go to that booth next to her?
[00:39:30.560 --> 00:39:31.560]   Marari?
[00:39:31.560 --> 00:39:32.640]   No.
[00:39:32.640 --> 00:39:39.640]   So based on basic science research and study data, it uses transdermal based product using
[00:39:39.640 --> 00:39:46.440]   neural modulation as a means of inhibiting the nerves on the penis, thereby delaying.
[00:39:46.440 --> 00:39:49.040]   Everything is connected though.
[00:39:49.040 --> 00:39:50.680]   Nothing wrong with that.
[00:39:50.680 --> 00:39:52.760]   And then they send information back to Google.
[00:39:52.760 --> 00:39:55.880]   And tomorrow you're going to get all these ads.
[00:39:55.880 --> 00:40:00.280]   All these ads.
[00:40:00.280 --> 00:40:01.280]   I don't know.
[00:40:01.280 --> 00:40:03.480]   I'm not approved, but I didn't really think that that.
[00:40:03.480 --> 00:40:05.440]   I wanted to cover that.
[00:40:05.440 --> 00:40:09.280]   It's just a bit-- but I'm just proving Stacy's point that now everything is connected.
[00:40:09.280 --> 00:40:10.880]   Not everything needs to be smart.
[00:40:10.880 --> 00:40:12.720]   You're absolutely right.
[00:40:12.720 --> 00:40:15.680]   And I think that's really kind of the other thing you kind of get from CES.
[00:40:15.680 --> 00:40:21.520]   It's just this overwhelming-- everybody's striving so hard.
[00:40:21.520 --> 00:40:24.240]   Everybody wants to be the next unicorn.
[00:40:24.240 --> 00:40:27.560]   And especially like the Sands basement, which it feels like a science fair.
[00:40:27.560 --> 00:40:28.560]   It's like a high science--
[00:40:28.560 --> 00:40:29.560]   No, Eureka Park.
[00:40:29.560 --> 00:40:30.560]   Trash.
[00:40:30.560 --> 00:40:31.560]   Treasure.
[00:40:31.560 --> 00:40:32.760]   It's fun.
[00:40:32.760 --> 00:40:40.640]   And boy, we talked to the Italian company that is making the kurig of olive oil.
[00:40:40.640 --> 00:40:43.400]   And at first I was disappointed because at first I thought, oh, you just bring your
[00:40:43.400 --> 00:40:45.600]   olives and they'll squish them.
[00:40:45.600 --> 00:40:48.960]   But no, you have to buy their prepackages like Giussera.
[00:40:48.960 --> 00:40:51.400]   The prepackaged frozen olive base.
[00:40:51.400 --> 00:40:52.560]   Everybody's got their own.
[00:40:52.560 --> 00:40:55.560]   And then you put the capsule in there.
[00:40:55.560 --> 00:40:57.880]   And then like this much olive oil comes out.
[00:40:57.880 --> 00:40:59.800]   This is like the-- what was the-- not kurig.
[00:40:59.800 --> 00:41:00.800]   What was the other one?
[00:41:00.800 --> 00:41:03.080]   The Stacy had that she defended.
[00:41:03.080 --> 00:41:06.000]   The roti-- the roti-matic or--
[00:41:06.000 --> 00:41:07.000]   No, no.
[00:41:07.000 --> 00:41:08.000]   We love that.
[00:41:08.000 --> 00:41:09.000]   The Giussera?
[00:41:09.000 --> 00:41:10.000]   That was--
[00:41:10.000 --> 00:41:11.000]   The Giussera.
[00:41:11.000 --> 00:41:12.000]   It's just like the Giussera.
[00:41:12.000 --> 00:41:13.000]   Yeah.
[00:41:13.000 --> 00:41:14.000]   And then there was the kurig.
[00:41:14.000 --> 00:41:15.000]   The dentist.
[00:41:15.000 --> 00:41:18.640]   This is also in Eureka Park, the kurig of muffin ovens.
[00:41:18.640 --> 00:41:19.640]   You might have liked this, Stacy.
[00:41:19.640 --> 00:41:20.640]   Little pods.
[00:41:20.640 --> 00:41:21.640]   Little pods.
[00:41:21.640 --> 00:41:22.640]   No, they just little pods.
[00:41:22.640 --> 00:41:23.640]   Saw all of them.
[00:41:23.640 --> 00:41:25.440]   And it's especially built oven to take up her.
[00:41:25.440 --> 00:41:26.440]   Pods.
[00:41:26.440 --> 00:41:27.440]   Single big muffins.
[00:41:27.440 --> 00:41:28.440]   It's single big.
[00:41:28.440 --> 00:41:31.200]   You're a sight man on her face, folks.
[00:41:31.200 --> 00:41:32.200]   Oh my gosh.
[00:41:32.200 --> 00:41:34.040]   How much was that?
[00:41:34.040 --> 00:41:35.040]   You know what?
[00:41:35.040 --> 00:41:36.040]   There was such a crowd.
[00:41:36.040 --> 00:41:39.320]   Lisa and I tried to get video this guy three or four times.
[00:41:39.320 --> 00:41:40.480]   It kept coming back.
[00:41:40.480 --> 00:41:41.680]   And there were so many people there.
[00:41:41.680 --> 00:41:43.680]   And I think they were just there for the muffins.
[00:41:43.680 --> 00:41:44.680]   But they were just--
[00:41:44.680 --> 00:41:47.360]   I couldn't ever-- I think we got video of it, but I don't know.
[00:41:47.360 --> 00:41:50.760]   Did you put video of that in the-- does anybody know if we ended this?
[00:41:50.760 --> 00:41:52.400]   I don't recall seeing that one.
[00:41:52.400 --> 00:41:53.400]   I don't recall.
[00:41:53.400 --> 00:41:55.200]   I don't think we got that one.
[00:41:55.200 --> 00:41:58.840]   We shot a lot of stuff that landed up on the cutting room floor.
[00:41:58.840 --> 00:42:00.240]   Well, I was looking for it.
[00:42:00.240 --> 00:42:04.480]   I just called the story from the spoon of all of the food stuff there.
[00:42:04.480 --> 00:42:11.600]   Robot pizza, robot ramen, ramen, beer bots, drip bots, wine tech, DNA driven food choices.
[00:42:11.600 --> 00:42:13.880]   Smart countertop cooking, intelligence surface cooking.
[00:42:13.880 --> 00:42:14.880]   There's always something about--
[00:42:14.880 --> 00:42:17.200]   Smart home gardening, vertical garden, you mentioned that one.
[00:42:17.200 --> 00:42:18.200]   Home food robots.
[00:42:18.200 --> 00:42:19.200]   What does that do?
[00:42:19.200 --> 00:42:20.200]   It's a cooking robot--
[00:42:20.200 --> 00:42:24.000]   That's like the roadie medic and all of those, yeah.
[00:42:24.000 --> 00:42:25.000]   It is really--
[00:42:25.000 --> 00:42:26.840]   That's the coffee stuff I remember that.
[00:42:26.840 --> 00:42:32.680]   I think what's interesting-- and this is one thing that-- it's not changed, but it's
[00:42:32.680 --> 00:42:35.600]   just-- it's even more than it was eight years ago.
[00:42:35.600 --> 00:42:38.160]   There's so much money if you get a hit, right?
[00:42:38.160 --> 00:42:40.160]   Everybody wants to be the next Uber.
[00:42:40.160 --> 00:42:47.400]   And so you just see the show floor is jammed with these people who are just so sincere
[00:42:47.400 --> 00:42:52.640]   and they really want to be the next unicorn and they got the best thing ever.
[00:42:52.640 --> 00:42:56.920]   It's like you don't-- any idea you can-- anything you can think of.
[00:42:56.920 --> 00:42:57.920]   Somebody's going to make it.
[00:42:57.920 --> 00:43:01.320]   And then there's a lot of the booths were companies that do that.
[00:43:01.320 --> 00:43:03.720]   They're connected to the smart pet rocks.
[00:43:03.720 --> 00:43:04.720]   Yeah.
[00:43:04.720 --> 00:43:06.680]   I would go up to booths thinking, oh, that looks interesting.
[00:43:06.680 --> 00:43:09.200]   They're realizing, no, no, they're not selling that.
[00:43:09.200 --> 00:43:12.840]   They're a company that you go to with your brilliant idea and they make-- they get-- they
[00:43:12.840 --> 00:43:17.880]   connect you with China, they make it-- so there's a whole supply chain for people who
[00:43:17.880 --> 00:43:21.240]   have an idea now to make products.
[00:43:21.240 --> 00:43:25.640]   And I respect that to a certain extent because if you have an idea, you have every right to
[00:43:25.640 --> 00:43:27.120]   try to take it to market.
[00:43:27.120 --> 00:43:28.120]   Oh, I don't mind it.
[00:43:28.120 --> 00:43:29.120]   No.
[00:43:29.120 --> 00:43:32.480]   But the problem is that I've seen-- and it's not just from those little guys, but heck,
[00:43:32.480 --> 00:43:38.280]   even some of these big tech companies, I think they try to create a problem and make a product
[00:43:38.280 --> 00:43:39.280]   off of it.
[00:43:39.280 --> 00:43:43.560]   It's not necessarily a problem that I want to flip my light switch with my fingers.
[00:43:43.560 --> 00:43:47.160]   Humans are endlessly creative.
[00:43:47.160 --> 00:43:51.280]   But they want to tell everybody, hey, we can connect your lights and have you turn it off
[00:43:51.280 --> 00:43:54.040]   just by speaking into the air.
[00:43:54.040 --> 00:43:57.560]   Burke says we should talk about the power of the exoskeleton.
[00:43:57.560 --> 00:44:01.480]   That's because we make Burke lift.
[00:44:01.480 --> 00:44:05.880]   Delta, first time an airline had ever had a booth and they had a big booth.
[00:44:05.880 --> 00:44:10.200]   They're CEO even spoke at the keynote, I believe.
[00:44:10.200 --> 00:44:12.000]   And they had-- did you see that Stacey?
[00:44:12.000 --> 00:44:15.480]   They had the exoskeletons you put on and you could lift massive amounts of--
[00:44:15.480 --> 00:44:17.960]   Oh, I saw the old people exoskeletons.
[00:44:17.960 --> 00:44:19.360]   I missed the delta exoskeleton.
[00:44:19.360 --> 00:44:20.360]   Oh, old people exoskeletons.
[00:44:20.360 --> 00:44:21.360]   Oh, yeah.
[00:44:21.360 --> 00:44:22.360]   It was very similar.
[00:44:22.360 --> 00:44:23.360]   I knew it was very similar.
[00:44:23.360 --> 00:44:24.360]   Yeah, it's similar.
[00:44:24.360 --> 00:44:26.960]   You sort of look like Tony Stark on Sage in--
[00:44:26.960 --> 00:44:28.200]   You look like Jarvis.
[00:44:28.200 --> 00:44:29.200]   Right.
[00:44:29.200 --> 00:44:34.160]   Did you go inside the delta booth because they had a new kind of screen they're going
[00:44:34.160 --> 00:44:36.160]   to have at airports?
[00:44:36.160 --> 00:44:37.160]   I saw it.
[00:44:37.160 --> 00:44:38.640]   Everybody gets a different thing.
[00:44:38.640 --> 00:44:39.640]   Right.
[00:44:39.640 --> 00:44:40.640]   It was a long line.
[00:44:40.640 --> 00:44:44.160]   Everybody-- so you go in, you scan your ticket and the screens you see at the airport
[00:44:44.160 --> 00:44:46.600]   instead of showing all the flights say, hi, Aunt.
[00:44:46.600 --> 00:44:47.920]   Your flight's at gate 32.
[00:44:47.920 --> 00:44:48.920]   Right.
[00:44:48.920 --> 00:44:49.920]   Customize your attention.
[00:44:49.920 --> 00:44:52.120]   347 people around the same screen.
[00:44:52.120 --> 00:44:53.120]   Yes.
[00:44:53.120 --> 00:44:54.560]   And each of them gets their own--
[00:44:54.560 --> 00:44:55.560]   Right.
[00:44:55.560 --> 00:44:56.560]   I don't know how they do.
[00:44:56.560 --> 00:44:57.560]   I don't believe it.
[00:44:57.560 --> 00:44:58.560]   It's a miracle.
[00:44:58.560 --> 00:45:00.000]   Do they get an individual of the whole screen or do they block it off?
[00:45:00.000 --> 00:45:03.200]   No, no, no, you get your whole-- the whole screen.
[00:45:03.200 --> 00:45:04.000]   Huh.
[00:45:04.000 --> 00:45:05.000]   Texas villains.
[00:45:05.000 --> 00:45:07.320]   This guy's lifting a hundred pound-- under 30 pound tire.
[00:45:07.320 --> 00:45:09.320]   I can do that.
[00:45:09.320 --> 00:45:14.600]   I was speaking of one thing turning or like showing a single individual, a single stream
[00:45:14.600 --> 00:45:18.280]   to a single individual from a shared resource like a television screen.
[00:45:18.280 --> 00:45:19.760]   Have we talked about Bluetooth yet?
[00:45:19.760 --> 00:45:22.640]   Bluetooth 5.2 codec that was announced at the show?
[00:45:22.640 --> 00:45:23.640]   Let's take a break.
[00:45:23.640 --> 00:45:24.640]   I want you to tell me about that.
[00:45:24.640 --> 00:45:25.640]   5.2.
[00:45:25.640 --> 00:45:29.280]   And we can also talk about those light field technology 3D things.
[00:45:29.280 --> 00:45:30.280]   Ooh.
[00:45:30.280 --> 00:45:31.280]   Which--
[00:45:31.280 --> 00:45:32.280]   I--
[00:45:32.280 --> 00:45:33.280]   Lots of potential.
[00:45:33.280 --> 00:45:34.280]   You know what that means?
[00:45:34.280 --> 00:45:36.280]   And they say you have lots of potential.
[00:45:36.280 --> 00:45:37.280]   Lots of potential.
[00:45:37.280 --> 00:45:40.160]   You're just not living up to it.
[00:45:40.160 --> 00:45:42.360]   Our show today brought to you-- we have a great panel.
[00:45:42.360 --> 00:45:45.960]   Is this-- you know, I hope you're not bored with this CES talk.
[00:45:45.960 --> 00:45:46.960]   We have lots of Google news.
[00:45:46.960 --> 00:45:47.960]   We're going to get to that.
[00:45:47.960 --> 00:45:50.280]   Stacey Higginbotham is here.
[00:45:50.280 --> 00:45:51.800]   Three of the four of us were at CES.
[00:45:51.800 --> 00:45:53.600]   So, you know, we're reminiscing.
[00:45:53.600 --> 00:45:54.600]   Stacey--
[00:45:54.600 --> 00:45:55.600]   You're so left out.
[00:45:55.600 --> 00:45:57.240]   Oh, Jeff, next year you're coming with us.
[00:45:57.240 --> 00:46:00.520]   Jeff Jarvis from CUNY and Pruitt.
[00:46:00.520 --> 00:46:03.240]   Our show today is for you, Ant.
[00:46:03.240 --> 00:46:06.880]   I use you as an example with HealthIQ all the time.
[00:46:06.880 --> 00:46:09.680]   HealthIQ is a life insurance agency.
[00:46:09.680 --> 00:46:13.160]   They work on your behalf, but they have a very special niche.
[00:46:13.160 --> 00:46:18.120]   They are for health conscious people, people who exercise, who eat right, who pay attention,
[00:46:18.120 --> 00:46:21.240]   who get a right amount of sleep, who take care of themselves.
[00:46:21.240 --> 00:46:26.600]   HealthIQ is a concierge life insurance agency that goes to bat for you.
[00:46:26.600 --> 00:46:29.040]   So the perfect example is you're in great shape.
[00:46:29.040 --> 00:46:30.200]   You lift.
[00:46:30.200 --> 00:46:34.520]   But because you have so much muscle mass, your body mass index--
[00:46:34.520 --> 00:46:35.800]   I am overweight.
[00:46:35.800 --> 00:46:37.000]   You look like you're obese.
[00:46:37.000 --> 00:46:38.000]   You're morbidly obese.
[00:46:38.000 --> 00:46:39.000]   Right.
[00:46:39.000 --> 00:46:41.320]   And an insurance company is going to look at that number and say, "We can't insure you,
[00:46:41.320 --> 00:46:42.320]   Ant."
[00:46:42.320 --> 00:46:43.320]   And every time.
[00:46:43.320 --> 00:46:45.320]   Yeah, what HealthIQ does is they go to bat for you.
[00:46:45.320 --> 00:46:49.360]   So you know, no, no, no, you can understand, Ant is in fantastic shape.
[00:46:49.360 --> 00:46:50.720]   And they'll even use--
[00:46:50.720 --> 00:46:55.520]   They'll even use with your permission, they'll say, "We can get you an even better rate if
[00:46:55.520 --> 00:46:59.920]   you'll give us the data from your smartwatch or from your fitness tracker."
[00:46:59.920 --> 00:47:02.520]   Because that proves that you've been lifting.
[00:47:02.520 --> 00:47:07.200]   And so this is very highly personalized to you.
[00:47:07.200 --> 00:47:09.360]   And this is a really neat idea.
[00:47:09.360 --> 00:47:14.360]   They use science and data to get lower life insurance rates for people who care, who get
[00:47:14.360 --> 00:47:17.760]   a minimum of eight hours sleep, who eat well, who exercise.
[00:47:17.760 --> 00:47:19.320]   And it can be really a good deal.
[00:47:19.320 --> 00:47:23.360]   A million dollars of life insurance for 36 bucks a month.
[00:47:23.360 --> 00:47:26.560]   See, the reason this works is-- and look at these guys.
[00:47:26.560 --> 00:47:28.800]   These are the guys who started at their fitness fanatics.
[00:47:28.800 --> 00:47:36.080]   The reason this works is frankly, the life insurance companies have been subsidizing the
[00:47:36.080 --> 00:47:39.960]   unhealthy by charging more to the health conscious.
[00:47:39.960 --> 00:47:42.600]   It's not a conspiracy, it's just actuarial science.
[00:47:42.600 --> 00:47:44.280]   It's how insurance works.
[00:47:44.280 --> 00:47:47.200]   You need to let your insurance company know you're healthy and then you can get these
[00:47:47.200 --> 00:47:49.920]   great rates that only HealthIQ can give you.
[00:47:49.920 --> 00:47:52.640]   HealthIQ is concierge, white love service.
[00:47:52.640 --> 00:47:53.640]   They do the whole thing.
[00:47:53.640 --> 00:47:55.840]   They work through the entire process.
[00:47:55.840 --> 00:47:59.080]   They are working with the top 30 insurance companies.
[00:47:59.080 --> 00:48:03.000]   So you're going to get a policy not from HealthIQ, but from an insurance company.
[00:48:03.000 --> 00:48:05.560]   They're an insurance agency.
[00:48:05.560 --> 00:48:09.080]   And by the way, they have rates that only HealthIQ can get.
[00:48:09.080 --> 00:48:10.680]   You won't find them anywhere else.
[00:48:10.680 --> 00:48:11.680]   But you have to qualify.
[00:48:11.680 --> 00:48:13.080]   So here's what happens.
[00:48:13.080 --> 00:48:14.920]   You go and take the HealthIQ quiz.
[00:48:14.920 --> 00:48:17.160]   It's healthIQ.com/twig.
[00:48:17.160 --> 00:48:22.640]   They have developed this proprietary health quiz, which is not asking you about your habits.
[00:48:22.640 --> 00:48:24.520]   It's asking you about your knowledge.
[00:48:24.520 --> 00:48:25.680]   It's a knowledge assessment.
[00:48:25.680 --> 00:48:30.760]   They put together a team of the top medical health and fitness experts to create this
[00:48:30.760 --> 00:48:32.400]   quiz.
[00:48:32.400 --> 00:48:37.360]   Depending on your score plus other qualifying factors like the access to your data on your
[00:48:37.360 --> 00:48:44.360]   fitness tracker, you can save a huge amount, like up to 41% of your life insurance premiums
[00:48:44.360 --> 00:48:45.360]   compared to other providers.
[00:48:45.360 --> 00:48:46.360]   There's no commitment.
[00:48:46.360 --> 00:48:47.360]   It won't cost you anything.
[00:48:47.360 --> 00:48:50.320]   You'll learn even more about potential opportunities to be rewarded for your commitment to living
[00:48:50.320 --> 00:48:51.320]   healthy.
[00:48:51.320 --> 00:48:53.800]   But you've got to go to healthIQ.com/twig.
[00:48:53.800 --> 00:48:55.960]   With the quiz, you'll give them your phone number.
[00:48:55.960 --> 00:48:59.320]   Your concierge will call you, talk you through the process.
[00:48:59.320 --> 00:49:00.680]   It's just such a great idea.
[00:49:00.680 --> 00:49:06.080]   HealthIQ.com/twig.
[00:49:06.080 --> 00:49:10.640]   They came to us because they say, "We know you have healthy listeners.
[00:49:10.640 --> 00:49:11.960]   You have smart listeners.
[00:49:11.960 --> 00:49:13.280]   They take care of themselves."
[00:49:13.280 --> 00:49:14.280]   I said, "Really?"
[00:49:14.280 --> 00:49:17.680]   But you know what, couch potatoes?
[00:49:17.680 --> 00:49:18.680]   Really?
[00:49:18.680 --> 00:49:21.560]   But you know what, you look at this panel.
[00:49:21.560 --> 00:49:23.560]   We all are very health conscious.
[00:49:23.560 --> 00:49:27.840]   I think that the proof is in the pudding, except don't eat the pudding.
[00:49:27.840 --> 00:49:29.160]   That's what I say.
[00:49:29.160 --> 00:49:31.880]   We can eat the pudding.
[00:49:31.880 --> 00:49:34.040]   HealthIQ.com/twig.
[00:49:34.040 --> 00:49:35.920]   I say this now in the ads.
[00:49:35.920 --> 00:49:37.720]   We don't track you.
[00:49:37.720 --> 00:49:38.720]   We don't track you.
[00:49:38.720 --> 00:49:39.720]   We don't know anything about you.
[00:49:39.720 --> 00:49:42.640]   So you've got to use that address so that they know you saw it here.
[00:49:42.640 --> 00:49:44.400]   HealthIQ.com/twig.
[00:49:44.400 --> 00:49:46.320]   That's a nice twig.
[00:49:46.320 --> 00:49:50.960]   You know, I'm really nervous because Spotify just announced they're going to start tracking
[00:49:50.960 --> 00:49:56.640]   people who listen to Spotify exclusive podcasts on the Spotify app because they know everything
[00:49:56.640 --> 00:49:57.640]   about you.
[00:49:57.640 --> 00:49:58.640]   They have your credit card.
[00:49:58.640 --> 00:49:59.640]   They have listening.
[00:49:59.640 --> 00:50:00.640]   They have your location.
[00:50:00.640 --> 00:50:01.640]   Data, data, data.
[00:50:01.640 --> 00:50:02.640]   And they're going to give that.
[00:50:02.640 --> 00:50:05.560]   They're going to start selling that to advertisers.
[00:50:05.560 --> 00:50:06.560]   So much money and data.
[00:50:06.560 --> 00:50:11.200]   Scares the willies at them because we're not going to do that.
[00:50:11.200 --> 00:50:12.200]   We don't want to do that.
[00:50:12.200 --> 00:50:18.560]   So by the way, I just put up in the chat the there's a Delta video of the screen.
[00:50:18.560 --> 00:50:23.120]   And it depends apparently it takes a while to get to it, but it depends which angle
[00:50:23.120 --> 00:50:24.120]   you're out of the screen.
[00:50:24.120 --> 00:50:25.120]   Yeah, yeah, yeah.
[00:50:25.120 --> 00:50:26.120]   Right.
[00:50:26.120 --> 00:50:29.040]   So there were a number of technologies like that.
[00:50:29.040 --> 00:50:30.520]   This is the light field of red.
[00:50:30.520 --> 00:50:36.840]   So maybe think of it that are doing glasses list.
[00:50:36.840 --> 00:50:37.920]   Fast forward a bit.
[00:50:37.920 --> 00:50:39.160]   This I didn't try.
[00:50:39.160 --> 00:50:40.160]   I didn't try.
[00:50:40.160 --> 00:50:41.160]   There we go.
[00:50:41.160 --> 00:50:42.160]   As they come up to the screen.
[00:50:42.160 --> 00:50:43.680]   I didn't try to shoot this because you can't.
[00:50:43.680 --> 00:50:45.240]   No, you can't see it.
[00:50:45.240 --> 00:50:51.640]   So each person is getting a different message depending on the angle of viewing.
[00:50:51.640 --> 00:50:55.840]   In order to do that, by the way, they have to scan something when you come in your ticket
[00:50:55.840 --> 00:50:57.120]   usually.
[00:50:57.120 --> 00:51:00.240]   And there's cameras everywhere that are watching every step.
[00:51:00.240 --> 00:51:01.240]   It's going to freak people out.
[00:51:01.240 --> 00:51:03.240]   So they say, oh, Justin and they show him.
[00:51:03.240 --> 00:51:04.240]   Yeah.
[00:51:04.240 --> 00:51:06.240]   Oh, yeah, because they know it's a good point.
[00:51:06.240 --> 00:51:07.240]   I took two cars.
[00:51:07.240 --> 00:51:08.240]   Excitement on 42nd Street in New York.
[00:51:08.240 --> 00:51:09.240]   We have finally helped those Amazon.
[00:51:09.240 --> 00:51:16.240]   Go stores.
[00:51:16.240 --> 00:51:17.240]   Yeah.
[00:51:17.240 --> 00:51:18.240]   So I did it.
[00:51:18.240 --> 00:51:19.240]   I got the app and I went in.
[00:51:19.240 --> 00:51:20.240]   I'm so excited.
[00:51:20.240 --> 00:51:22.240]   The sandwiches are overpriced and junk.
[00:51:22.240 --> 00:51:24.240]   I like that chicken bond.
[00:51:24.240 --> 00:51:25.240]   Is that all right?
[00:51:25.240 --> 00:51:27.240]   I love that one.
[00:51:27.240 --> 00:51:29.240]   I don't think we have that one.
[00:51:29.240 --> 00:51:30.240]   Yeah.
[00:51:30.240 --> 00:51:33.240]   It's like seven bucks for a basic turkey sandwich.
[00:51:33.240 --> 00:51:35.240]   I'm playing bread.
[00:51:35.240 --> 00:51:36.240]   I wasn't that impressed.
[00:51:36.240 --> 00:51:37.240]   Bob, what would you call it?
[00:51:37.240 --> 00:51:39.240]   Those cameras don't come cheap.
[00:51:39.240 --> 00:51:40.240]   I know.
[00:51:40.240 --> 00:51:41.240]   What's the big deal?
[00:51:41.240 --> 00:51:42.240]   What's the video?
[00:51:42.240 --> 00:51:45.240]   So they realized I said, well, you know, one person can check you in and then everything
[00:51:45.240 --> 00:51:47.240]   you buy, I pay for it.
[00:51:47.240 --> 00:51:48.240]   They said, OK.
[00:51:48.240 --> 00:51:51.240]   I bought a soda and a sandwich for colleagues.
[00:51:51.240 --> 00:51:53.240]   But it is pretty amazing.
[00:51:53.240 --> 00:51:56.240]   So not waiting in line is awesome.
[00:51:56.240 --> 00:51:59.240]   Do people trust Google?
[00:51:59.240 --> 00:52:01.240]   Yes, they do.
[00:52:01.240 --> 00:52:03.240]   More than they trust Tom Hanks.
[00:52:03.240 --> 00:52:04.240]   Do Tom Hanks?
[00:52:04.240 --> 00:52:08.240]   Well, I'm not sure if you've seen this moral panic show they don't, but they do.
[00:52:08.240 --> 00:52:18.240]   This is the state of brand trusts, a survey of 16,700 people per brand.
[00:52:18.240 --> 00:52:20.240]   The most trusted, by the way, is your doctor.
[00:52:20.240 --> 00:52:28.240]   50% of Americans trust that your doctor, a lot is the phrase they used to do the right thing.
[00:52:28.240 --> 00:52:29.240]   Then the military--
[00:52:29.240 --> 00:52:32.240]   Who does the trust extreme weather warnings?
[00:52:32.240 --> 00:52:33.240]   Yeah, well, it gets weird.
[00:52:33.240 --> 00:52:38.240]   Then Amazon, then Google-- those are in the top four extreme weather warnings is number
[00:52:38.240 --> 00:52:41.240]   five-- then teachers, then Tom Hanks.
[00:52:41.240 --> 00:52:42.240]   I don't.
[00:52:42.240 --> 00:52:46.240]   Then the police-- so they trust Tom Hanks more than the police.
[00:52:46.240 --> 00:52:48.240]   But they trust the police more than they trust Oprah.
[00:52:48.240 --> 00:52:53.240]   And they trust-- and this is what really scares me-- Oprah more than they trust scientific
[00:52:53.240 --> 00:52:54.240]   studies.
[00:52:54.240 --> 00:52:55.240]   That's the scariest there.
[00:52:55.240 --> 00:52:59.240]   They trust health warnings more than they trust Donald Trump.
[00:52:59.240 --> 00:53:01.240]   So you know what they trust the least?
[00:53:01.240 --> 00:53:06.240]   Hollywood, Wall Street, and the US government, which is really weird because Donald Trump
[00:53:06.240 --> 00:53:07.240]   is the US government.
[00:53:07.240 --> 00:53:08.240]   But OK, fine.
[00:53:08.240 --> 00:53:09.240]   This is so funny.
[00:53:09.240 --> 00:53:16.240]   This is Americans who say they trust each of the following a lot to do the right thing.
[00:53:16.240 --> 00:53:19.240]   So we're just saying, are these brands going to do the right thing?
[00:53:19.240 --> 00:53:23.240]   They're not-- I don't know why extreme weather warning, are they doing the right thing?
[00:53:23.240 --> 00:53:24.240]   The wrong thing.
[00:53:24.240 --> 00:53:26.240]   Why does Tom Hanks get 100%?
[00:53:26.240 --> 00:53:27.240]   Geez.
[00:53:27.240 --> 00:53:28.240]   You know he's going to do the right thing?
[00:53:28.240 --> 00:53:29.240]   Yeah.
[00:53:29.240 --> 00:53:32.240]   I'd rather trust him than my doctor.
[00:53:32.240 --> 00:53:34.240]   Well, sir.
[00:53:34.240 --> 00:53:40.240]   They trust the labels on food packaging more than they trust religious leaders.
[00:53:40.240 --> 00:53:43.240]   They just-- Well, religious leaders have taken a dive on this one.
[00:53:43.240 --> 00:53:48.240]   Yeah, they're going to-- and Jeff, you'll be sad to know that only 8% trust the news.
[00:53:48.240 --> 00:53:50.240]   Why is that high?
[00:53:50.240 --> 00:53:51.240]   Yeah.
[00:53:51.240 --> 00:53:54.240]   This is the state of brand trust.
[00:53:54.240 --> 00:53:56.240]   It just says a lot about society.
[00:53:56.240 --> 00:53:57.240]   Oh, yes.
[00:53:57.240 --> 00:53:58.240]   It could also be just a BS study.
[00:53:58.240 --> 00:53:59.240]   No.
[00:53:59.240 --> 00:54:01.240]   It's from Morningcon salts.
[00:54:01.240 --> 00:54:02.240]   It is.
[00:54:02.240 --> 00:54:09.240]   Google is the most trusted brand among millennials and Gen Z. Amazon is third.
[00:54:09.240 --> 00:54:11.240]   To do the right thing.
[00:54:11.240 --> 00:54:15.240]   Gen Z and millennials, according to the report, hold brands to a higher standard.
[00:54:15.240 --> 00:54:21.240]   They're more distrusting of brands across the board, except when it comes to Google.
[00:54:21.240 --> 00:54:25.240]   Or Netflix is pretty good too.
[00:54:25.240 --> 00:54:27.640]   Netflix is right up there with Gen Z's.
[00:54:27.640 --> 00:54:29.840]   I trust Netflix to do the right thing.
[00:54:29.840 --> 00:54:30.840]   Don't you?
[00:54:30.840 --> 00:54:31.840]   I do now.
[00:54:31.840 --> 00:54:33.840]   What does that even mean?
[00:54:33.840 --> 00:54:37.240]   Oh, maybe they're watching you the right thing on Netflix.
[00:54:37.240 --> 00:54:40.240]   Well, in the old days, it was sending you the right tape.
[00:54:40.240 --> 00:54:41.240]   Yeah.
[00:54:41.240 --> 00:54:42.240]   Actually, you know what?
[00:54:42.240 --> 00:54:43.240]   They were very good.
[00:54:43.240 --> 00:54:45.240]   It was amazing how accurate they were.
[00:54:45.240 --> 00:54:46.240]   They had DVDs.
[00:54:46.240 --> 00:54:47.240]   Those little red envelopes.
[00:54:47.240 --> 00:54:51.240]   The other day I talked to my daughter, 27, she said, "Did you know that Netflix?"
[00:54:51.240 --> 00:54:56.240]   And that little red envelopes with the discs.
[00:54:56.240 --> 00:54:57.240]   We still have some that we bought.
[00:54:57.240 --> 00:55:02.240]   Like my husband bought some old Netflix videos, DVDs, whatever.
[00:55:02.240 --> 00:55:03.240]   You just cut that plan off of it?
[00:55:03.240 --> 00:55:04.240]   What?
[00:55:04.240 --> 00:55:05.240]   Just four or five years ago?
[00:55:05.240 --> 00:55:07.240]   It wasn't that long, right?
[00:55:07.240 --> 00:55:08.240]   You just cut that plan off.
[00:55:08.240 --> 00:55:10.240]   Oh, man, though.
[00:55:10.240 --> 00:55:14.240]   It was a bad idea because I think I had the five disc subscription.
[00:55:14.240 --> 00:55:17.240]   And I just kept meaning to watch those discs by the time.
[00:55:17.240 --> 00:55:19.240]   You know, and you just gathered dust.
[00:55:19.240 --> 00:55:22.240]   You can't get another one until you send one back.
[00:55:22.240 --> 00:55:24.240]   Streaming is so much better.
[00:55:24.240 --> 00:55:25.240]   - Streaming is so much better.
[00:55:25.240 --> 00:55:26.240]   - Blockbuster, man.
[00:55:26.240 --> 00:55:27.240]   I missed my blockbuster.
[00:55:27.240 --> 00:55:28.240]   - Really?
[00:55:28.240 --> 00:55:29.240]   Do you want to go randomly?
[00:55:29.240 --> 00:55:30.240]   - Well, no.
[00:55:30.240 --> 00:55:31.240]   You know what I miss?
[00:55:31.240 --> 00:55:32.240]   I miss browsing.
[00:55:32.240 --> 00:55:33.240]   - Yeah, that was fun.
[00:55:33.240 --> 00:55:38.240]   - I miss going to the record store and the bookstore and the electronic store and the computer store.
[00:55:38.240 --> 00:55:39.240]   But remember, we had those?
[00:55:39.240 --> 00:55:40.240]   - Oh, yeah.
[00:55:40.240 --> 00:55:41.240]   - And just browsing.
[00:55:41.240 --> 00:55:42.240]   - Browsing's dead.
[00:55:42.240 --> 00:55:45.240]   - I remember going to the record store and flipping through the LPs.
[00:55:45.240 --> 00:55:46.240]   - Yeah.
[00:55:46.240 --> 00:55:47.240]   - Right?
[00:55:47.240 --> 00:55:48.240]   - Now, you talk about...
[00:55:48.240 --> 00:55:49.240]   - I'm so excited.
[00:55:49.240 --> 00:55:51.240]   - It's our old fart moment.
[00:55:51.240 --> 00:55:54.240]   - So I know, I was going to say I browse differently now.
[00:55:54.240 --> 00:55:59.240]   So I look at top 10 lists or I go places and I'm like, "Hey, what are people watching?"
[00:55:59.240 --> 00:56:00.240]   - Yeah.
[00:56:00.240 --> 00:56:01.240]   - I ask friends.
[00:56:01.240 --> 00:56:02.240]   - Well, like that survey we just did.
[00:56:02.240 --> 00:56:05.240]   That's a kind of browsing, right?
[00:56:05.240 --> 00:56:11.240]   - What gets me is you talked about having to struggle to get your DVD, your five set DVD
[00:56:11.240 --> 00:56:13.240]   and turn M1 every week or whatever.
[00:56:13.240 --> 00:56:17.240]   But yet, just last week, you told me you binge watched some show on there, just like,
[00:56:17.240 --> 00:56:20.240]   back to back to back to back to back.
[00:56:20.240 --> 00:56:21.240]   - Yeah.
[00:56:21.240 --> 00:56:22.240]   - How was it more...
[00:56:22.240 --> 00:56:25.240]   - Much more to see that smile.
[00:56:25.240 --> 00:56:26.240]   - Oh, great.
[00:56:26.240 --> 00:56:28.240]   - Or is just trying to pop in one DVD.
[00:56:28.240 --> 00:56:29.240]   - Oh no, it's better.
[00:56:29.240 --> 00:56:31.240]   - You'll watch eight hours of...
[00:56:31.240 --> 00:56:32.240]   - Yeah.
[00:56:32.240 --> 00:56:33.240]   That's good.
[00:56:33.240 --> 00:56:35.240]   You have a problem with that?
[00:56:35.240 --> 00:56:39.240]   So at CES, Lisa and I didn't get any...
[00:56:39.240 --> 00:56:40.240]   - Was it the Messiah?
[00:56:40.240 --> 00:56:41.240]   - Is that what it was?
[00:56:41.240 --> 00:56:43.240]   - We watched Messiah the whole.
[00:56:43.240 --> 00:56:45.240]   The new Netflix show, Messiah.
[00:56:45.240 --> 00:56:46.240]   We watched the whole thing in one week.
[00:56:46.240 --> 00:56:47.240]   - I can't watch this DVD.
[00:56:47.240 --> 00:56:50.240]   I just don't have the time to watch this hour and a half DVD.
[00:56:50.240 --> 00:56:51.240]   - Wasn't the time.
[00:56:51.240 --> 00:56:53.240]   Maybe it was just getting up and putting it in.
[00:56:53.240 --> 00:56:56.240]   I don't know what it was, but something about streaming it.
[00:56:56.240 --> 00:56:57.240]   - You gotta point their hand.
[00:56:57.240 --> 00:56:58.240]   - Come on, man.
[00:56:58.240 --> 00:56:59.240]   - This is a good show.
[00:56:59.240 --> 00:57:00.240]   I like this.
[00:57:00.240 --> 00:57:02.240]   - What's the terrible reviews?
[00:57:02.240 --> 00:57:03.240]   - Well, it's...
[00:57:03.240 --> 00:57:04.240]   - My ability to...
[00:57:04.240 --> 00:57:06.240]   - Somebody's talking to me.
[00:57:06.240 --> 00:57:08.240]   My phone or my watch, oh, it was my watch.
[00:57:08.240 --> 00:57:09.240]   - Must have been you, sir.
[00:57:09.240 --> 00:57:12.240]   - Siri said it's beyond my abilities at the moment.
[00:57:12.240 --> 00:57:14.240]   Okay, thank you, Siri.
[00:57:14.240 --> 00:57:18.240]   - It got like 38 unrotting tomatoes, so don't watch it.
[00:57:18.240 --> 00:57:19.240]   But I happen to like it.
[00:57:19.240 --> 00:57:23.240]   The idea is there's this guy of kind of unknown origin,
[00:57:23.240 --> 00:57:27.240]   but he's vaguely Middle Eastern, who just appears and starts
[00:57:27.240 --> 00:57:30.240]   creating miracles and people start following him.
[00:57:30.240 --> 00:57:33.240]   Bigger and bigger groups start following him.
[00:57:33.240 --> 00:57:35.240]   They think he's the Messiah.
[00:57:35.240 --> 00:57:40.240]   And meanwhile, as one would expect, just like the Romans,
[00:57:40.240 --> 00:57:42.240]   the authorities go, "He ain't the Messiah.
[00:57:42.240 --> 00:57:43.240]   "He's a terrorist.
[00:57:43.240 --> 00:57:44.240]   "Let's arrest him."
[00:57:44.240 --> 00:57:48.240]   They're throwing him in jail, and he mysteriously escapes.
[00:57:48.240 --> 00:57:50.240]   And so...
[00:57:50.240 --> 00:57:54.240]   But they did a good job preserving throughout the entire season
[00:57:54.240 --> 00:57:55.240]   the ambiguity.
[00:57:55.240 --> 00:57:59.240]   Well, is he or is he a trickster?
[00:57:59.240 --> 00:58:00.240]   Is he a magician?
[00:58:00.240 --> 00:58:02.240]   Is he really the Messiah?
[00:58:02.240 --> 00:58:06.240]   But I think season two, you're going to find out he's neither.
[00:58:06.240 --> 00:58:07.240]   I know what he is.
[00:58:07.240 --> 00:58:09.240]   - Oh, you know, huh?
[00:58:09.240 --> 00:58:10.240]   - Oh, I think I know.
[00:58:10.240 --> 00:58:11.240]   - Care to spoil.
[00:58:11.240 --> 00:58:13.240]   - He's a Facebook executive.
[00:58:13.240 --> 00:58:14.240]   - Yes.
[00:58:14.240 --> 00:58:16.240]   - It's Mark Zuckerberg.
[00:58:16.240 --> 00:58:18.240]   You figured it out!
[00:58:18.240 --> 00:58:21.240]   It was his yearly challenge.
[00:58:21.240 --> 00:58:23.240]   Do you see Mark's not going to do those anymore?
[00:58:23.240 --> 00:58:24.240]   - No.
[00:58:24.240 --> 00:58:25.240]   He's got enough challenges.
[00:58:25.240 --> 00:58:28.240]   - Yeah, that's basically what he wrote in his post.
[00:58:28.240 --> 00:58:31.240]   I've grown out of this thing about doing a challenge every year.
[00:58:31.240 --> 00:58:33.240]   I'm just, I got problems.
[00:58:33.240 --> 00:58:34.240]   I got to solve these.
[00:58:34.240 --> 00:58:38.240]   That's kind of, you know, a nutshell.
[00:58:38.240 --> 00:58:44.240]   YouTube is, should I do Zach's scoop?
[00:58:44.240 --> 00:58:45.240]   Let me do Zach's scoop.
[00:58:45.240 --> 00:58:46.240]   - Oh, let's do this.
[00:58:46.240 --> 00:58:50.240]   - So Carson's son Zach is actually a very smart fellow.
[00:58:50.240 --> 00:58:59.240]   And noticed that there, well, so should I show this?
[00:58:59.240 --> 00:59:00.240]   - Careful.
[00:59:00.240 --> 00:59:01.240]   - Channel?
[00:59:01.240 --> 00:59:02.240]   - Careful.
[00:59:02.240 --> 00:59:06.240]   - The problem is you can't because of the next, the next.
[00:59:06.240 --> 00:59:11.240]   - So there's a channel that my 17 year old, and I think Zach at the same time discovered
[00:59:11.240 --> 00:59:13.240]   called Don't Hug Me, I'm Scared.
[00:59:13.240 --> 00:59:14.240]   It's puppets.
[00:59:14.240 --> 00:59:15.240]   It's colorful.
[00:59:15.240 --> 00:59:21.240]   It is subversive because they're not muppets.
[00:59:21.240 --> 00:59:24.240]   It's kind of weirdly surreal.
[00:59:24.240 --> 00:59:25.240]   It's actually great.
[00:59:25.240 --> 00:59:27.240]   It is not for kids.
[00:59:27.240 --> 00:59:33.240]   But YouTube says this for kids because it has puppets.
[00:59:33.240 --> 00:59:36.240]   And this is going to be the problem.
[00:59:36.240 --> 00:59:41.240]   - Oh, so the paradox here, oh, it's four kids.
[00:59:41.240 --> 00:59:43.240]   - They say it's four kids.
[00:59:43.240 --> 00:59:46.240]   - It's definitely not for kids.
[00:59:46.240 --> 00:59:51.240]   It's got puppets, but that doesn't make it for kids.
[00:59:51.240 --> 00:59:54.240]   But now it shows up.
[00:59:54.240 --> 01:00:01.240]   As a, you know, by the way, if you want to be disturbed, watch these.
[01:00:01.240 --> 01:00:02.240]   - So yeah, they're--
[01:00:02.240 --> 01:00:03.240]   - They can't monetize?
[01:00:03.240 --> 01:00:04.240]   What does this mean?
[01:00:04.240 --> 01:00:05.240]   - They're not monetized.
[01:00:05.240 --> 01:00:09.240]   They cannot have comments.
[01:00:09.240 --> 01:00:13.240]   They're basically all of their interactivity has been.
[01:00:13.240 --> 01:00:14.240]   - Can they appeal this?
[01:00:14.240 --> 01:00:15.240]   Can they go to YouTube?
[01:00:15.240 --> 01:00:17.240]   There's no appeal.
[01:00:17.240 --> 01:00:20.240]   - There's no way to appeal to this.
[01:00:20.240 --> 01:00:22.240]   This has happened to them.
[01:00:22.240 --> 01:00:25.240]   This has happened to Cartoon Network, which--
[01:00:25.240 --> 01:00:29.240]   - Well, that's for kids, sort of, right?
[01:00:29.240 --> 01:00:30.240]   - There's a lot of stuff.
[01:00:30.240 --> 01:00:33.240]   I mean, Bojack Horseman's not for kids.
[01:00:33.240 --> 01:00:36.240]   There's a lot of cartoons that are not for kids.
[01:00:36.240 --> 01:00:37.240]   - Archer.
[01:00:37.240 --> 01:00:40.240]   - Archer's definitely not for kids.
[01:00:40.240 --> 01:00:47.240]   But now is there the risk that kids will now be seeing more of this stuff because YouTube's decided it's for kids?
[01:00:47.240 --> 01:00:49.240]   Because that's really disturbing.
[01:00:49.240 --> 01:00:52.240]   - It just shows you how screwed up this stuff can be.
[01:00:52.240 --> 01:00:54.240]   They have all these wonderful ideas.
[01:00:54.240 --> 01:00:55.240]   - Machines can't do it.
[01:00:55.240 --> 01:01:01.240]   They necessarily go through all of the proper R&D and not having enough human training for this stuff.
[01:01:01.240 --> 01:01:06.240]   - Well, and then we get all upset when we find out that humans are involved.
[01:01:06.240 --> 01:01:16.240]   Microsoft's getting heat now because it turns out that contractors have been listening to Skype conversations to grade the speech recognition.
[01:01:16.240 --> 01:01:21.240]   And it turns out it was just a bunch of Chinese people in their houses at home.
[01:01:21.240 --> 01:01:24.240]   And so I'm sure Microsoft will do something about that.
[01:01:24.240 --> 01:01:25.240]   - Frog pants.
[01:01:25.240 --> 01:01:26.240]   - Oh, Mr. Johnson.
[01:01:26.240 --> 01:01:27.240]   - I feel so bad.
[01:01:27.240 --> 01:01:29.240]   I did not know this happened.
[01:01:29.240 --> 01:01:31.240]   Scott Johnson.
[01:01:31.240 --> 01:01:37.240]   I got trolled and also FU tube.
[01:01:37.240 --> 01:01:47.240]   The instance was terminated because it was linked to a channel that was disabled for having three or more copyright strikes, which I'm sure is not the case with Scott Johnson.
[01:01:47.240 --> 01:01:50.240]   So he's moving his everything over to a Twitch.
[01:01:50.240 --> 01:01:58.240]   - I've been entertained on years old content and every single one of his channels has been taken off.
[01:01:58.240 --> 01:02:03.240]   - The Morning Stream, which is a great show, has been banned from YouTube.
[01:02:03.240 --> 01:02:12.240]   You are, by the way, please be aware you're prohibited from accessing or creating any other YouTube accounts unless the link channel is reinstated.
[01:02:12.240 --> 01:02:14.240]   - What if this happened to us?
[01:02:14.240 --> 01:02:15.240]   - Man.
[01:02:15.240 --> 01:02:16.240]   - This would kill Twitter.
[01:02:16.240 --> 01:02:24.240]   - If it's going back to something that's a year over for Mr. Johnson, what about some of the stuff that's three, four years old on the Twitch network?
[01:02:24.240 --> 01:02:26.240]   - The good news is, don't say it.
[01:02:26.240 --> 01:02:27.240]   - Don't say it.
[01:02:27.240 --> 01:02:28.240]   - Every day.
[01:02:28.240 --> 01:02:29.240]   - We get dinged a lot.
[01:02:29.240 --> 01:02:30.240]   - We get dinged on stuff.
[01:02:30.240 --> 01:02:34.240]   - The good news is we never relied on YouTube because I knew this was a potential problem.
[01:02:34.240 --> 01:02:35.240]   - Right.
[01:02:35.240 --> 01:02:38.240]   - Same reason people said, "Oh, you ought to go all in on Facebook video."
[01:02:38.240 --> 01:02:39.240]   - No.
[01:02:39.240 --> 01:02:40.240]   - No.
[01:02:40.240 --> 01:02:41.240]   - No.
[01:02:41.240 --> 01:02:42.240]   - No.
[01:02:42.240 --> 01:02:46.240]   - You build your platform on somebody else's site, they can always do that.
[01:02:46.240 --> 01:02:47.240]   - They have to leverage.
[01:02:47.240 --> 01:02:48.240]   - So.
[01:02:48.240 --> 01:02:50.240]   - So just a word of warning, I guess.
[01:02:50.240 --> 01:02:53.240]   These automated systems are just not very good.
[01:02:53.240 --> 01:03:01.240]   - I get them wanting to, I get where their heart is.
[01:03:01.240 --> 01:03:03.240]   They wanted to do the right thing, YouTube.
[01:03:03.240 --> 01:03:08.240]   But again, we still need to have someone step in and put some common sense on it.
[01:03:08.240 --> 01:03:09.240]   - You need humans with scale.
[01:03:09.240 --> 01:03:10.240]   - Right.
[01:03:10.240 --> 01:03:12.240]   - That's the problem, humans don't scale.
[01:03:12.240 --> 01:03:13.240]   - Right.
[01:03:13.240 --> 01:03:15.240]   - There's only seven billion of us.
[01:03:15.240 --> 01:03:16.240]   (laughing)
[01:03:16.240 --> 01:03:22.120]   Yeah, somebody said in the chat room, "Bleep Doubles says you're already making editorial
[01:03:22.120 --> 01:03:23.240]   choices based on YouTube.
[01:03:23.240 --> 01:03:25.800]   It's true, there's a chilling effect.
[01:03:25.800 --> 01:03:31.120]   We are now very careful about not playing videos that might get us copyrighted."
[01:03:31.120 --> 01:03:33.240]   Although we just did that.
[01:03:33.240 --> 01:03:34.240]   - Yeah.
[01:03:34.240 --> 01:03:35.960]   - I just, whoops.
[01:03:35.960 --> 01:03:39.000]   It's not my nature.
[01:03:39.000 --> 01:03:40.360]   Just tell me I can't do something.
[01:03:40.360 --> 01:03:41.840]   Pretty much I'm gonna do it.
[01:03:41.840 --> 01:03:43.000]   Pretty much, that's what's gonna happen.
[01:03:43.000 --> 01:03:46.000]   - And then I'm gonna go behind your back and edit it out.
[01:03:46.000 --> 01:03:47.000]   - Right.
[01:03:47.000 --> 01:03:49.000]   (laughing)
[01:03:49.000 --> 01:03:52.000]   - That's good, Carson does.
[01:03:52.000 --> 01:03:57.000]   - Here's a story that really could be in the change log, except it's not happening until
[01:03:57.000 --> 01:03:58.880]   2022.
[01:03:58.880 --> 01:04:02.960]   So it's a future change log, but a very big story, I think.
[01:04:02.960 --> 01:04:08.440]   Google has announced they're gonna drop third party cookie support in Chrome.
[01:04:08.440 --> 01:04:13.000]   Which means, by the way, since everybody's basing on their browser in Chrome Brave does,
[01:04:13.000 --> 01:04:19.280]   Microsoft does with Edge, I wonder if third party cookies are dead, dead, dead.
[01:04:19.280 --> 01:04:25.880]   This is a post building a more private web from the Chromium blog, a path toward making
[01:04:25.880 --> 01:04:27.360]   third party cookies obsolete.
[01:04:27.360 --> 01:04:31.120]   You might think, "Well, this isn't this against Google's business model.
[01:04:31.120 --> 01:04:32.120]   I mean, they're business models."
[01:04:32.120 --> 01:04:34.920]   - Not when they have all the data everybody has.
[01:04:34.920 --> 01:04:36.600]   - They don't need to share this.
[01:04:36.600 --> 01:04:37.600]   Yeah.
[01:04:37.600 --> 01:04:40.600]   It hurts the competitors in the ad world.
[01:04:40.600 --> 01:04:46.600]   - So how soon will we see the government step in on this?
[01:04:46.600 --> 01:04:49.960]   - It's any competitive behavior.
[01:04:49.960 --> 01:04:52.360]   But at the same time, it's good for privacy, right?
[01:04:52.360 --> 01:04:58.760]   In fact, one of the first things we tell people to do is turn off third party cookies
[01:04:58.760 --> 01:05:01.800]   in your browser, almost all browsers, except Chrome.
[01:05:01.800 --> 01:05:02.800]   What do you do that?
[01:05:02.800 --> 01:05:06.720]   Now Chrome's not even gonna give you an option, they're just gonna block them.
[01:05:06.720 --> 01:05:12.000]   So just to understand what this is, when you go to a website, cookies are a completely
[01:05:12.000 --> 01:05:15.280]   benign mechanism and they needed to exist.
[01:05:15.280 --> 01:05:18.040]   When you, for instance, go to Facebook and you don't have to log in again, that's 'cause
[01:05:18.040 --> 01:05:23.120]   Facebook saves some information on your hard drive.
[01:05:23.120 --> 01:05:25.720]   They call it a cookie, but it's just a little bit of information.
[01:05:25.720 --> 01:05:30.480]   - Even getting all the various parts of a single page requires it.
[01:05:30.480 --> 01:05:32.840]   Maintained state when there's an estateless world.
[01:05:32.840 --> 01:05:39.400]   It was originally created by Mozilla as persistent client side state information.
[01:05:39.400 --> 01:05:43.520]   They should have called them Pixies, but instead they call them cookies 'cause they
[01:05:43.520 --> 01:05:45.200]   thought, "Oh, it'll be nice, nobody."
[01:05:45.200 --> 01:05:47.520]   But the problem is not first party cookies.
[01:05:47.520 --> 01:05:49.200]   Cookies saved by the site you're visiting.
[01:05:49.200 --> 01:05:52.040]   The problem is third party cookies.
[01:05:52.040 --> 01:05:56.360]   Cookies that are, for instance, like the Facebook like button, that's a third party.
[01:05:56.360 --> 01:05:59.560]   You're visiting a website, but that's a third party, saves a cookie.
[01:05:59.560 --> 01:06:05.040]   And then, in effect, gives them the ability to watch everywhere you go around the web
[01:06:05.040 --> 01:06:10.880]   because any time that cookie, any time that Facebook like button shows up, they can say,
[01:06:10.880 --> 01:06:12.560]   "Oh, they were just at Starbucks.
[01:06:12.560 --> 01:06:14.760]   Oh, they were just at that.
[01:06:14.760 --> 01:06:18.640]   So there is a privacy information leak there.
[01:06:18.640 --> 01:06:22.760]   Cookies were carefully designed to prevent, you know, their design that only the first
[01:06:22.760 --> 01:06:26.680]   party can load the cookie, but nobody imagined the idea that people would embed little bits
[01:06:26.680 --> 01:06:30.200]   of content coming from their site on somebody else's site.
[01:06:30.200 --> 01:06:34.040]   So third party cookies are potential privacy violation.
[01:06:34.040 --> 01:06:35.040]   What do you think, Jeff?
[01:06:35.040 --> 01:06:38.520]   Does that bother you if the Facebook like button then knows everywhere?
[01:06:38.520 --> 01:06:41.160]   It only knows when you go to other pages with the Facebook like.
[01:06:41.160 --> 01:06:45.680]   With the Facebook like, which that was a major kerfuffle at the time.
[01:06:45.680 --> 01:06:48.920]   We're a bit over it now.
[01:06:48.920 --> 01:06:52.480]   I've always said that when it comes to antitrust and stuff, the weakness for Google is advertising
[01:06:52.480 --> 01:06:56.240]   because it's in the advertising business and it has the power of God.
[01:06:56.240 --> 01:07:01.680]   But I don't think so I think that all of the ad tech stocks are all nose diving.
[01:07:01.680 --> 01:07:02.840]   Because of this.
[01:07:02.840 --> 01:07:03.840]   Because of this.
[01:07:03.840 --> 01:07:04.840]   Wow.
[01:07:04.840 --> 01:07:10.760]   Well, and then there was a story related that Apple, because Apple now when you use your
[01:07:10.760 --> 01:07:16.840]   iPhone ever since iOS 13 came out, says, "You know, Google's been tracking your location.
[01:07:16.840 --> 01:07:18.520]   You want to let them do that."
[01:07:18.520 --> 01:07:23.680]   Because of that, what used to be nearly 100% opt in for location tracking with apps has
[01:07:23.680 --> 01:07:25.240]   dropped to 50%.
[01:07:25.240 --> 01:07:30.440]   So location based advertising is really getting hurt by iOS 13.
[01:07:30.440 --> 01:07:32.120]   So I imagine that has something to do with it as well.
[01:07:32.120 --> 01:07:38.560]   So I wrote a piece that will get Stacey and me to Zareen again.
[01:07:38.560 --> 01:07:44.400]   Which came out of a discussion on the show last week in defense of targeting.
[01:07:44.400 --> 01:07:48.120]   That targeting as a whole is being demonized.
[01:07:48.120 --> 01:07:51.200]   And the alternative to targeting is mass.
[01:07:51.200 --> 01:07:52.200]   Right?
[01:07:52.200 --> 01:07:55.080]   Nothing about you and it's a billboard and everybody sees the same thing.
[01:07:55.080 --> 01:08:02.040]   Taking away relevance and further taking away efficient, inexpensive advertising that democratizes
[01:08:02.040 --> 01:08:06.280]   advertising for new and small businesses and movements and small candidates and so on and
[01:08:06.280 --> 01:08:07.280]   so forth.
[01:08:07.280 --> 01:08:11.480]   And we've got to find some kind of medium here where you got Roger McNamee who's driving
[01:08:11.480 --> 01:08:16.880]   me completely crazy out there saying, "Get rid of all targeting and hyper micro target
[01:08:16.880 --> 01:08:18.960]   and just he hates Google.
[01:08:18.960 --> 01:08:20.920]   I know Roger because I went to school with him."
[01:08:20.920 --> 01:08:22.920]   I hate Facebook and Google.
[01:08:22.920 --> 01:08:27.120]   He wasn't an early investor in Google but turned against them at some point.
[01:08:27.120 --> 01:08:28.880]   And Facebook was marked up calling him.
[01:08:28.880 --> 01:08:33.320]   He used to be Mark's mentor but Mark stopped calling me so I'm going to go on every TV show
[01:08:33.320 --> 01:08:34.320]   and fashion.
[01:08:34.320 --> 01:08:35.320]   But that's another story.
[01:08:35.320 --> 01:08:38.160]   So targeting to me is not an evil.
[01:08:38.160 --> 01:08:39.880]   It could be misused of course.
[01:08:39.880 --> 01:08:41.840]   But it opens up possibilities.
[01:08:41.840 --> 01:08:46.480]   There were small mom selling or jam that was only possible because you could find people
[01:08:46.480 --> 01:08:53.360]   who just love jam or movements that occur or the low cost of ads on Facebook.
[01:08:53.360 --> 01:08:55.160]   And I think it's been demonized so much.
[01:08:55.160 --> 01:08:57.000]   There's this whole notion of third party cookies.
[01:08:57.000 --> 01:09:02.040]   Cookies as a whole got horribly misused by the advertising industry and the media industry
[01:09:02.040 --> 01:09:03.280]   and the technology industry.
[01:09:03.280 --> 01:09:07.560]   We didn't tell people what they were and it was easy to then demonize them.
[01:09:07.560 --> 01:09:11.640]   But they have functions that are valuable and I worry about that.
[01:09:11.640 --> 01:09:13.960]   I'm worried if we go to a mass web.
[01:09:13.960 --> 01:09:14.960]   Stacey?
[01:09:14.960 --> 01:09:17.280]   I actually agree with you on micro targeting.
[01:09:17.280 --> 01:09:20.560]   I don't think it's a terrible evil.
[01:09:20.560 --> 01:09:21.560]   So I'm sorry.
[01:09:21.560 --> 01:09:23.240]   What has happened to the alignment of the planets?
[01:09:23.240 --> 01:09:24.240]   I know.
[01:09:24.240 --> 01:09:25.240]   I'm sorry.
[01:09:25.240 --> 01:09:27.480]   But you probably don't like.
[01:09:27.480 --> 01:09:32.880]   And what Google mentions with third party cookies is when people turn off cookies and
[01:09:32.880 --> 01:09:38.760]   that kind of tracking then much more draconian fingerprinting technologies take.
[01:09:38.760 --> 01:09:39.760]   Yes.
[01:09:39.760 --> 01:09:42.400]   Where they really interrupted Stacey to make a joke.
[01:09:42.400 --> 01:09:43.400]   Go ahead Stacey.
[01:09:43.400 --> 01:09:45.320]   And she was actually agreeing with me.
[01:09:45.320 --> 01:09:47.680]   So I want to make sure Stacey gets her time to agree with me.
[01:09:47.680 --> 01:09:49.200]   I agree with you.
[01:09:49.200 --> 01:09:56.000]   I also think that cookies, I remember being offended by cookies.
[01:09:56.000 --> 01:09:59.440]   But by golly when you turn them off the web does not work as well.
[01:09:59.440 --> 01:10:08.400]   So I feel like we still are huge impasse that we've come to is that right now we're sacrificing
[01:10:08.400 --> 01:10:13.880]   convenience for an exchange of our information and the ability to be targeted.
[01:10:13.880 --> 01:10:17.640]   I do think targeted advertising is more effective.
[01:10:17.640 --> 01:10:25.800]   I think it can be if not coercive, definitely manipulative in a way that I don't love for
[01:10:25.800 --> 01:10:26.800]   people.
[01:10:26.800 --> 01:10:28.000]   I think we need to.
[01:10:28.000 --> 01:10:30.760]   I think the solution though isn't always to turn it off.
[01:10:30.760 --> 01:10:33.720]   I think we need to do a lot more education around it.
[01:10:33.720 --> 01:10:39.560]   And I also would like to see business models that do not rely solely on advertising.
[01:10:39.560 --> 01:10:43.880]   And I'm kind of optimistic we're getting there in some ways.
[01:10:43.880 --> 01:10:46.240]   But you're saying that advertising.
[01:10:46.240 --> 01:10:47.240]   How do you see that?
[01:10:47.240 --> 01:10:49.240]   Isn't that how you get paid in Stacey and IOT?
[01:10:49.240 --> 01:10:50.240]   I do.
[01:10:50.240 --> 01:10:52.200]   I do not do incredibly targeted advertising.
[01:10:52.200 --> 01:10:54.520]   I mean when you come to my site.
[01:10:54.520 --> 01:10:55.520]   You already are targeted.
[01:10:55.520 --> 01:10:56.520]   Well yeah.
[01:10:56.520 --> 01:10:57.520]   Well yeah.
[01:10:57.520 --> 01:10:58.520]   I call your niche targets.
[01:10:58.520 --> 01:10:59.520]   Yeah just like Twitter.
[01:10:59.520 --> 01:11:00.520]   The content targets.
[01:11:00.520 --> 01:11:01.520]   Right.
[01:11:01.520 --> 01:11:02.520]   So I'm not.
[01:11:02.520 --> 01:11:03.520]   Which is the best way.
[01:11:03.520 --> 01:11:04.520]   Right.
[01:11:04.520 --> 01:11:10.880]   So the questions that I think we need to answer is how do we fund things for the mass because
[01:11:10.880 --> 01:11:19.640]   there is value in mass without being without scraping too much data and misusing that
[01:11:19.640 --> 01:11:21.120]   data.
[01:11:21.120 --> 01:11:25.220]   And I don't I mean paywalls are one way and we might all hate them but there's a reason
[01:11:25.220 --> 01:11:29.440]   people are going to them and I mean we're buying them.
[01:11:29.440 --> 01:11:36.400]   I mean I subscribe to a bunch of publications now because I do want to read them.
[01:11:36.400 --> 01:11:43.000]   And you know it does it irk me not if I know that it's you know helping fund a publication
[01:11:43.000 --> 01:11:44.800]   whose stuff I value.
[01:11:44.800 --> 01:11:45.800]   Do I.
[01:11:45.800 --> 01:11:52.320]   Can I ask Stacey how many of them are I presume a fair number of them are business expenses
[01:11:52.320 --> 01:11:55.440]   and needed for your expertise there.
[01:11:55.440 --> 01:11:56.440]   What about on the personal.
[01:11:56.440 --> 01:11:58.440]   How many do you subscribe to if I may ask?
[01:11:58.440 --> 01:12:03.320]   I'm going to push you into a side to probably eight.
[01:12:03.320 --> 01:12:04.320]   Wow.
[01:12:04.320 --> 01:12:05.320]   Oh your generous.
[01:12:05.320 --> 01:12:07.240]   So I do NYT cooking.
[01:12:07.240 --> 01:12:08.680]   I do New York magazine.
[01:12:08.680 --> 01:12:09.680]   Me too.
[01:12:09.680 --> 01:12:14.160]   Only for vulture that I like reading about shows.
[01:12:14.160 --> 01:12:15.440]   That's a really good column though.
[01:12:15.440 --> 01:12:17.360]   I love vulture.
[01:12:17.360 --> 01:12:23.240]   I do scientific American just for me.
[01:12:23.240 --> 01:12:26.720]   I guess I could justify that as a business expense.
[01:12:26.720 --> 01:12:29.560]   I have the New York Times normal.
[01:12:29.560 --> 01:12:31.080]   That could go either way.
[01:12:31.080 --> 01:12:34.600]   You know so some of these like wired I would subscribe to regardless.
[01:12:34.600 --> 01:12:37.440]   But I put it as a business expense you know because I can.
[01:12:37.440 --> 01:12:39.120]   I wasn't asking is your account.
[01:12:39.120 --> 01:12:41.120]   I want to get your trouble here.
[01:12:41.120 --> 01:12:42.120]   But yes.
[01:12:42.120 --> 01:12:44.120]   No no I mean well I mean it is a legitimate.
[01:12:44.120 --> 01:12:46.120]   It was hard to.
[01:12:46.120 --> 01:12:47.120]   It is.
[01:12:47.120 --> 01:12:48.120]   It is fine.
[01:12:48.120 --> 01:12:49.120]   Yes.
[01:12:49.120 --> 01:12:52.320]   And then let's see I subscribe to the New Yorker and the economist just.
[01:12:52.320 --> 01:12:53.320]   Well just personally.
[01:12:53.320 --> 01:12:54.320]   So smart.
[01:12:54.320 --> 01:12:55.320]   How much.
[01:12:55.320 --> 01:12:56.320]   How much economists.
[01:12:56.320 --> 01:12:58.080]   How much economists do you get to read.
[01:12:58.080 --> 01:13:00.080]   Yeah I stop and it piles up.
[01:13:00.080 --> 01:13:02.520]   It piled up like a guilt for me.
[01:13:02.520 --> 01:13:05.800]   I well my husband also reads the economist he reads it more.
[01:13:05.800 --> 01:13:09.680]   I read probably one out of every.
[01:13:09.680 --> 01:13:13.360]   Three issues I read all of the New Yorker though.
[01:13:13.360 --> 01:13:15.320]   Except for the baseball artist and the fly fishing.
[01:13:15.320 --> 01:13:17.320]   He's so smart.
[01:13:17.320 --> 01:13:18.480]   Seriously just smart.
[01:13:18.480 --> 01:13:19.840]   She just doesn't watch TV.
[01:13:19.840 --> 01:13:21.000]   That's the secret.
[01:13:21.000 --> 01:13:22.400]   I do I read a lot.
[01:13:22.400 --> 01:13:23.400]   Yeah.
[01:13:23.400 --> 01:13:25.960]   And if I've never told you Libby is my pick of the week.
[01:13:25.960 --> 01:13:29.440]   I encourage everyone who has a public library that supports Libby.
[01:13:29.440 --> 01:13:32.000]   Download that today and start downloading books.
[01:13:32.000 --> 01:13:33.000]   Yes.
[01:13:33.000 --> 01:13:36.160]   And actually if it's not Libby your public library almost certainly supports some sort
[01:13:36.160 --> 01:13:38.360]   of digital content application.
[01:13:38.360 --> 01:13:39.360]   There's different.
[01:13:39.360 --> 01:13:42.000]   Can I give you my library moment.
[01:13:42.000 --> 01:13:43.000]   No.
[01:13:43.000 --> 01:13:48.640]   So I'm doing my Gutenberg research and there's this whole series of extremely expensive academic
[01:13:48.640 --> 01:13:49.880]   books.
[01:13:49.880 --> 01:13:52.920]   They cost $200 each I'm not buying them.
[01:13:52.920 --> 01:13:53.920]   No.
[01:13:53.920 --> 01:13:54.920]   Right.
[01:13:54.920 --> 01:13:56.880]   And I have them.
[01:13:56.880 --> 01:14:01.960]   My best crowdfunding thing ever which may not be saying much but it is.
[01:14:01.960 --> 01:14:03.560]   I love this crowdfunding thing.
[01:14:03.560 --> 01:14:08.960]   I crowdfunded the Caesar CZUR Aura scanner.
[01:14:08.960 --> 01:14:11.800]   And trying to one me open up.
[01:14:11.800 --> 01:14:13.240]   Move into camera.
[01:14:13.240 --> 01:14:14.240]   It's a book.
[01:14:14.240 --> 01:14:15.240]   So you wait a minute.
[01:14:15.240 --> 01:14:17.240]   I wonder if this scanner legal.
[01:14:17.240 --> 01:14:18.800]   You don't want to leave your library.
[01:14:18.800 --> 01:14:21.360]   You get books and then you scan them in.
[01:14:21.360 --> 01:14:22.360]   It's personal purposes.
[01:14:22.360 --> 01:14:23.920]   Did Google get in trouble for that?
[01:14:23.920 --> 01:14:24.920]   So yeah well they did.
[01:14:24.920 --> 01:14:25.920]   But this is fine for me.
[01:14:25.920 --> 01:14:26.920]   So this is cool.
[01:14:26.920 --> 01:14:28.680]   So that's it looks like a lamp.
[01:14:28.680 --> 01:14:29.680]   It's a little thing.
[01:14:29.680 --> 01:14:30.680]   Yeah.
[01:14:30.680 --> 01:14:31.680]   It's not big at all.
[01:14:31.680 --> 01:14:33.680]   The software is phenomenal.
[01:14:33.680 --> 01:14:37.080]   It's it does as you are as well as scanning.
[01:14:37.080 --> 01:14:39.320]   It does as well does PDF as well.
[01:14:39.320 --> 01:14:42.920]   And then it'll also recognize when I turn the page and take the next page.
[01:14:42.920 --> 01:14:44.720]   Oh, MG I got to get that.
[01:14:44.720 --> 01:14:45.720]   That's cool.
[01:14:45.720 --> 01:14:48.600]   And and sorry for making you all dizzy with that.
[01:14:48.600 --> 01:14:49.600]   What's that?
[01:14:49.600 --> 01:14:50.600]   Again.
[01:14:50.600 --> 01:14:51.600]   The Caesar CZUR.
[01:14:51.600 --> 01:14:54.840]   This one is called the aura.
[01:14:54.840 --> 01:14:55.840]   That's the one I have.
[01:14:55.840 --> 01:14:57.880]   And they come up with just they just came up with a new one.
[01:14:57.880 --> 01:14:58.880]   This is cheaper.
[01:14:58.880 --> 01:14:59.880]   This is 350.
[01:14:59.880 --> 01:15:03.000]   I got it for like 250 on on crowdfunding.
[01:15:03.000 --> 01:15:05.080]   And it's magnificent.
[01:15:05.080 --> 01:15:12.840]   And so I'm getting these books and I'm just able to have these chapters and mark them
[01:15:12.840 --> 01:15:13.840]   up.
[01:15:13.840 --> 01:15:15.760]   But there's no legal ramifications, sir.
[01:15:15.760 --> 01:15:17.440]   No, no, no, because it personally uses fun.
[01:15:17.440 --> 01:15:18.440]   Okay.
[01:15:18.440 --> 01:15:20.120]   It's absolutely fine.
[01:15:20.120 --> 01:15:25.520]   I could take pictures with my phone, but that doesn't work.
[01:15:25.520 --> 01:15:27.440]   So also you do all the PDFs.
[01:15:27.440 --> 01:15:29.480]   Stacey's buying it right now.
[01:15:29.480 --> 01:15:39.080]   And then it has a foot pedal or it has the automated thing because it comes with these
[01:15:39.080 --> 01:15:40.240]   little thumb things.
[01:15:40.240 --> 01:15:41.880]   You find it works pretty well.
[01:15:41.880 --> 01:15:43.480]   The pages work brilliantly.
[01:15:43.480 --> 01:15:44.480]   Beautiful.
[01:15:44.480 --> 01:15:45.480]   Get in it.
[01:15:45.480 --> 01:15:46.480]   That's awesome.
[01:15:46.480 --> 01:15:47.480]   And so software.
[01:15:47.480 --> 01:15:51.360]   So you do a whole bunch of PDFs and then you say, okay, make all that one PDF.
[01:15:51.360 --> 01:15:53.800]   There it goes.
[01:15:53.800 --> 01:15:57.040]   Do you have the Aura X Pro or?
[01:15:57.040 --> 01:15:58.800]   I have just the aura, I think.
[01:15:58.800 --> 01:15:59.800]   There's the aura.
[01:15:59.800 --> 01:16:00.800]   They have a new one.
[01:16:00.800 --> 01:16:02.560]   And this man is a lot more.
[01:16:02.560 --> 01:16:04.080]   It's a hundred bucks more for the man is.
[01:16:04.080 --> 01:16:06.040]   Oh, I don't know which one I have.
[01:16:06.040 --> 01:16:08.800]   There's a but they have a Caesar has a new new one.
[01:16:08.800 --> 01:16:10.720]   That's a two hundred bucks.
[01:16:10.720 --> 01:16:13.560]   And if it's the same software, I think it'll be good.
[01:16:13.560 --> 01:16:14.880]   But but my point in library.
[01:16:14.880 --> 01:16:17.960]   So I love, you know, our, our university library.
[01:16:17.960 --> 01:16:20.960]   I love the New York public library.
[01:16:20.960 --> 01:16:26.360]   And because I'm a professor, though a fake one, only a journalism professor, I get these
[01:16:26.360 --> 01:16:27.760]   books that you're always supposed to use the library.
[01:16:27.760 --> 01:16:29.120]   I'm allowed to take out.
[01:16:29.120 --> 01:16:32.680]   Wait, how is it a journalism professor is a fake professor?
[01:16:32.680 --> 01:16:34.760]   So I have a bachelor's degree.
[01:16:34.760 --> 01:16:37.800]   Oh, I have a bachelor's or journalism too.
[01:16:37.800 --> 01:16:39.480]   You guys started three master's degrees.
[01:16:39.480 --> 01:16:40.480]   I don't have a master's degree.
[01:16:40.480 --> 01:16:41.480]   You guys beat me.
[01:16:41.480 --> 01:16:42.480]   I got a high school diploma.
[01:16:42.480 --> 01:16:48.160]   But you got a great acceptance.
[01:16:48.160 --> 01:16:50.720]   So anyway, so this has just been a godsend to me.
[01:16:50.720 --> 01:16:52.840]   Because I was trying to figure out how to scanning.
[01:16:52.840 --> 01:16:53.840]   That's wonderful.
[01:16:53.840 --> 01:16:57.040]   So I just wanted to plug those wonderful people.
[01:16:57.040 --> 01:17:00.800]   That's I like this disclaimer on the Caesar site.
[01:17:00.800 --> 01:17:06.240]   If your materials are more in color demand, such as magazine, art books and so on, please
[01:17:06.240 --> 01:17:12.440]   contact us first for scanning sample via message in case of unpleasant product experience.
[01:17:12.440 --> 01:17:14.960]   That is nice.
[01:17:14.960 --> 01:17:18.960]   That's warning you that it may not be amazing for high quality color.
[01:17:18.960 --> 01:17:19.960]   Yeah.
[01:17:19.960 --> 01:17:20.960]   Cool device.
[01:17:20.960 --> 01:17:26.240]   I also on the top of that arm, there's a screen on the top of the arm.
[01:17:26.240 --> 01:17:29.000]   So you can stand up and see what you're standing.
[01:17:29.000 --> 01:17:34.840]   I'm going to have to spend some time looking at the various models because there's very,
[01:17:34.840 --> 01:17:37.320]   this is the global version for overseas customers.
[01:17:37.320 --> 01:17:38.720]   I guess I don't want that one.
[01:17:38.720 --> 01:17:43.040]   I'll tell you what's going to happen next is you're going to see this in your Instagram
[01:17:43.040 --> 01:17:44.040]   ads.
[01:17:44.040 --> 01:17:47.280]   Oh, you know, I that'll be a good test.
[01:17:47.280 --> 01:17:50.800]   Of course, if I had an Instagram account, I would, but I don't.
[01:17:50.800 --> 01:17:51.800]   You know what I found?
[01:17:51.800 --> 01:17:53.640]   I have an Instagram account, but I only follow Lisa.
[01:17:53.640 --> 01:17:56.080]   If you only follow one person, you don't get ads.
[01:17:56.080 --> 01:17:57.080]   Oh, really?
[01:17:57.080 --> 01:17:58.960]   You have to have enough content for them to give you.
[01:17:58.960 --> 01:18:04.160]   That must be why Jeff Bezos follows only one person on Amazon.
[01:18:04.160 --> 01:18:05.240]   This is in the rundown.
[01:18:05.240 --> 01:18:07.520]   But he only follows one person on Instagram.
[01:18:07.520 --> 01:18:08.520]   Yes, who?
[01:18:08.520 --> 01:18:09.520]   And she doesn't follow him back.
[01:18:09.520 --> 01:18:10.880]   So I'll know knowing those two things.
[01:18:10.880 --> 01:18:12.280]   Who do you think it is?
[01:18:12.280 --> 01:18:14.080]   Lauren Sanchez.
[01:18:14.080 --> 01:18:15.080]   Nope.
[01:18:15.080 --> 01:18:16.080]   Mrs. Bezos.
[01:18:16.080 --> 01:18:17.760]   Yes, of course.
[01:18:17.760 --> 01:18:19.120]   And she doesn't follow him back.
[01:18:19.120 --> 01:18:20.120]   Of course.
[01:18:20.120 --> 01:18:21.240]   I got, I got the money.
[01:18:21.240 --> 01:18:23.240]   You take your high little girlfriend.
[01:18:23.240 --> 01:18:25.760]   I got the money and all I'm not.
[01:18:25.760 --> 01:18:30.480]   Of course, she doesn't want to see his pictures of going right to the aruba.
[01:18:30.480 --> 01:18:31.480]   Right.
[01:18:31.480 --> 01:18:33.920]   He's he wants to check up on her though.
[01:18:33.920 --> 01:18:34.920]   That's interesting.
[01:18:34.920 --> 01:18:39.160]   Man, we got a whole soap opera out of that one little fat boy.
[01:18:39.160 --> 01:18:40.160]   That quick.
[01:18:40.160 --> 01:18:43.640]   That quick little thing.
[01:18:43.640 --> 01:18:51.560]   Google is besides third party cookies, Google also plans to phase out user agent strings.
[01:18:51.560 --> 01:18:57.440]   So browsers announce what they are with the user agent string to every site they visit
[01:18:57.440 --> 01:18:59.960]   so that the site knows what the browser's capabilities are.
[01:18:59.960 --> 01:19:03.760]   And of course, many browsers lie.
[01:19:03.760 --> 01:19:08.560]   And there apparently there is a privacy issue with this.
[01:19:08.560 --> 01:19:13.000]   UA strings have been used by online advertisers as a way to track and fingerprint.
[01:19:13.000 --> 01:19:15.600]   It's one of many data points they can't.
[01:19:15.600 --> 01:19:16.600]   Dastardly.
[01:19:16.600 --> 01:19:17.600]   Dastardly.
[01:19:17.600 --> 01:19:24.480]   User agent sniffing, which is illegal in 22 states, I might add, is an abundant source
[01:19:24.480 --> 01:19:29.920]   of compatibility issues, in particular for minority browsers, resulting in browsers lying
[01:19:29.920 --> 01:19:35.240]   about themselves and sites being broken and some browsers for no good reason.
[01:19:35.240 --> 01:19:42.800]   So instead of UA strings, they're going to do something called browse or client hints.
[01:19:42.800 --> 01:19:48.200]   Client hints are a mechanism that provides a way for web sites.
[01:19:48.200 --> 01:19:57.680]   It's more like remember when you remember modems and you would dial in and go.
[01:19:57.680 --> 01:19:58.680]   That was a negotiation.
[01:19:58.680 --> 01:20:02.880]   It was the handshake where the modem says, I can do this, this and this.
[01:20:02.880 --> 01:20:03.880]   What can you do?
[01:20:03.880 --> 01:20:05.920]   And the site would say, I can do that.
[01:20:05.920 --> 01:20:07.840]   Let's do this and talk.
[01:20:07.840 --> 01:20:10.080]   That was the handshake was a negotiation.
[01:20:10.080 --> 01:20:14.680]   So that's kind of what client hints are is a conversation between the website and the
[01:20:14.680 --> 01:20:18.080]   browser about what they can do.
[01:20:18.080 --> 01:20:20.280]   That's my understanding anyway.
[01:20:20.280 --> 01:20:22.120]   So that's kind of interesting.
[01:20:22.120 --> 01:20:25.120]   So you identify your capabilities, not your brand?
[01:20:25.120 --> 01:20:26.120]   Yes.
[01:20:26.120 --> 01:20:27.120]   Okay.
[01:20:27.120 --> 01:20:31.960]   So a mechanism which might allow user agents to be a bit more aggressive about removing
[01:20:31.960 --> 01:20:35.520]   entropy from the user agent string generally.
[01:20:35.520 --> 01:20:39.480]   Okay, programmers, stop it.
[01:20:39.480 --> 01:20:41.160]   Entropy, what?
[01:20:41.160 --> 01:20:45.760]   By giving servers that really need some specific details about the client, the ability to opt
[01:20:45.760 --> 01:20:47.560]   into receiving them.
[01:20:47.560 --> 01:20:54.640]   So instead of just, hey, I'm Mozilla, take it or leave it, browser hints or client hints
[01:20:54.640 --> 01:20:56.400]   can do a little bit better.
[01:20:56.400 --> 01:20:57.920]   That's interesting.
[01:20:57.920 --> 01:21:04.280]   So Google, you know, I think I always think of these companies as monolithic.
[01:21:04.280 --> 01:21:08.960]   Like, there's, you know, everybody Google has the same marching orders.
[01:21:08.960 --> 01:21:10.200]   But that's not the case.
[01:21:10.200 --> 01:21:13.160]   There's people at Google who want to do the right thing for privacy.
[01:21:13.160 --> 01:21:16.560]   There's people in advertising who say, what are you talking about?
[01:21:16.560 --> 01:21:18.760]   We need all the data we get.
[01:21:18.760 --> 01:21:23.040]   But in this case, I think the chromium folks and the chrome folks are doing probably doing
[01:21:23.040 --> 01:21:24.240]   the right thing.
[01:21:24.240 --> 01:21:28.240]   I don't want every site Stacey to have a pay wall.
[01:21:28.240 --> 01:21:29.240]   That doesn't seem.
[01:21:29.240 --> 01:21:31.040]   I don't want every site to have a pay wall.
[01:21:31.040 --> 01:21:35.360]   But I do think, you know, if you're producing valuable content, you should get paid for it.
[01:21:35.360 --> 01:21:41.200]   And if the advertising models are becoming too intrusive, then that is a problem.
[01:21:41.200 --> 01:21:45.560]   And I mean, that's why I'm okay with it.
[01:21:45.560 --> 01:21:46.720]   We chose early on.
[01:21:46.720 --> 01:21:52.760]   We tried briefly the idea of listeners supported and that didn't give us enough money.
[01:21:52.760 --> 01:21:55.160]   But Jake gave you money way back.
[01:21:55.160 --> 01:21:56.160]   I know.
[01:21:56.160 --> 01:21:57.160]   Huh?
[01:21:57.160 --> 01:21:58.160]   Seven Bitcoin.
[01:21:58.160 --> 01:22:00.240]   Seven Bitcoins.
[01:22:00.240 --> 01:22:03.000]   But it wasn't enough to have, we have 26 employees.
[01:22:03.000 --> 01:22:04.640]   We have a big facility.
[01:22:04.640 --> 01:22:06.400]   We have many shows.
[01:22:06.400 --> 01:22:07.400]   So we decided to go ask.
[01:22:07.400 --> 01:22:08.400]   Free food on Wednesdays.
[01:22:08.400 --> 01:22:11.240]   Free food on Wednesdays was Mexican today.
[01:22:11.240 --> 01:22:12.240]   Mmm.
[01:22:12.240 --> 01:22:13.240]   Free lunch.
[01:22:13.240 --> 01:22:18.200]   We have a massage therapist come in once a week.
[01:22:18.200 --> 01:22:20.120]   But California.
[01:22:20.120 --> 01:22:21.120]   Yeah.
[01:22:21.120 --> 01:22:27.840]   I like the idea being free because I feel like, and Mike Elgum was a guy who told me, this
[01:22:27.840 --> 01:22:28.840]   is democratic.
[01:22:28.840 --> 01:22:33.680]   Anybody who can listen, there's no means test to listen to Twitter.
[01:22:33.680 --> 01:22:35.400]   And fortunately we can do it ad supported.
[01:22:35.400 --> 01:22:41.920]   I do worry though, Stacey, you're right, that this reaction to tracking and the ads and
[01:22:41.920 --> 01:22:48.200]   the demand for advertisers to have more information about listeners could jeopardize us because
[01:22:48.200 --> 01:22:50.600]   I don't think we can turn around and stay now.
[01:22:50.600 --> 01:22:51.600]   Okay.
[01:22:51.600 --> 01:22:52.600]   Five bucks a month.
[01:22:52.600 --> 01:22:53.600]   I don't think we can do that.
[01:22:53.600 --> 01:22:57.280]   I don't think we've been able to worry about the redlining of journalism and quality information.
[01:22:57.280 --> 01:22:58.280]   That too.
[01:22:58.280 --> 01:22:59.280]   Yes.
[01:22:59.280 --> 01:23:03.760]   I have books every time I go to the Financial Times and I cannot read it.
[01:23:03.760 --> 01:23:10.040]   Stacey, where do you stand with ads from the broadcast standpoint with television and
[01:23:10.040 --> 01:23:14.560]   radio where it's not as targeted?
[01:23:14.560 --> 01:23:15.560]   Where do I stand?
[01:23:15.560 --> 01:23:17.200]   I don't understand your question.
[01:23:17.200 --> 01:23:22.120]   Well, you're saying it's like it's dying and it makes more sense if you could put some
[01:23:22.120 --> 01:23:25.040]   value on it and have people do a paywall.
[01:23:25.040 --> 01:23:26.520]   Oh, for, okay.
[01:23:26.520 --> 01:23:33.480]   So for public television, and this gets into some interesting issues because the airwaves
[01:23:33.480 --> 01:23:37.960]   are a public resource, but they're charging for the channels now, which I'm kind of like
[01:23:37.960 --> 01:23:41.040]   "Ahh."
[01:23:41.040 --> 01:23:44.600]   But I don't have an issue with those.
[01:23:44.600 --> 01:23:50.480]   I do have an issue with the idea that, you know, Canoe wanted to do his way back in the
[01:23:50.480 --> 01:23:51.480]   day.
[01:23:51.480 --> 01:23:55.680]   There's a lot of effort now for understanding exactly what TV shows you're watching.
[01:23:55.680 --> 01:23:59.040]   So your TV is watching you while you watch TV kind of thing.
[01:23:59.040 --> 01:24:07.160]   And that gives me the PBGBs a bit partially because I watch, I sometimes watch trashy television.
[01:24:07.160 --> 01:24:09.320]   You don't want them to know.
[01:24:09.320 --> 01:24:12.760]   I thought you're meeting the economist in the battle.
[01:24:12.760 --> 01:24:14.360]   No, you're watching the Bachelor.
[01:24:14.360 --> 01:24:18.680]   So while I'm watching the Bachelor, I am also flipping through the economist.
[01:24:18.680 --> 01:24:19.680]   Flipping through.
[01:24:19.680 --> 01:24:22.080]   And that's the problem.
[01:24:22.080 --> 01:24:27.880]   This brute force blunt object tracking can't tell that she's also reading the economist.
[01:24:27.880 --> 01:24:28.880]   Flipping through.
[01:24:28.880 --> 01:24:31.480]   No, I mean, I don't actually watch that much TV.
[01:24:31.480 --> 01:24:32.960]   Now you're trying to...
[01:24:32.960 --> 01:24:35.040]   Actually, television is a really good example.
[01:24:35.040 --> 01:24:36.880]   You're showing it back in.
[01:24:36.880 --> 01:24:38.840]   Because there are both models and both models coexist.
[01:24:38.840 --> 01:24:39.840]   We pay for Netflix.
[01:24:39.840 --> 01:24:40.840]   We pay for HBO.
[01:24:40.840 --> 01:24:42.000]   We pay for cable.
[01:24:42.000 --> 01:24:44.840]   But there's also free to broadcast the air.
[01:24:44.840 --> 01:24:46.600]   I don't like to watch broadcast TV.
[01:24:46.600 --> 01:24:47.600]   There's too many commercials.
[01:24:47.600 --> 01:24:48.600]   Too many commercials.
[01:24:48.600 --> 01:24:51.080]   I just say that out loud.
[01:24:51.080 --> 01:24:56.280]   In this academic book I just bought the first page, how to lose money in the business of
[01:24:56.280 --> 01:25:03.680]   books in 1524, the Leipzig Town Council appealed to the Duke of Saxony on behalf of
[01:25:03.680 --> 01:25:05.040]   all the printers.
[01:25:05.040 --> 01:25:08.440]   I mean, they were in danger of losing house, home and all their livelihoods.
[01:25:08.440 --> 01:25:13.040]   They asked in desperation to be allowed to print or sell anything that is made in Wittenberg
[01:25:13.040 --> 01:25:14.280]   or elsewhere.
[01:25:14.280 --> 01:25:18.040]   For that which one would gladly sell and for which there is demand, they are not allowed
[01:25:18.040 --> 01:25:19.040]   to have or sell.
[01:25:19.040 --> 01:25:20.040]   You can't say it on Word Book.
[01:25:20.040 --> 01:25:21.040]   But they have an old Word book.
[01:25:21.040 --> 01:25:22.040]   But they could sell books early on.
[01:25:22.040 --> 01:25:23.040]   But they could sell books early on.
[01:25:23.040 --> 01:25:25.240]   Catholic treatises until the Reformation.
[01:25:25.240 --> 01:25:26.240]   What?
[01:25:26.240 --> 01:25:27.800]   You had to give them away by law?
[01:25:27.800 --> 01:25:28.800]   No, no, no, no, no.
[01:25:28.800 --> 01:25:29.800]   They could sell books.
[01:25:29.800 --> 01:25:30.880]   But the one he was buying them.
[01:25:30.880 --> 01:25:36.320]   They bought the first wave of buying was the ancients and all and Bibles and soldiers and
[01:25:36.320 --> 01:25:37.840]   all the stuff was around.
[01:25:37.840 --> 01:25:40.800]   And then the book industry started collapsing horribly.
[01:25:40.800 --> 01:25:42.640]   I just realized that the Bible was listening.
[01:25:42.640 --> 01:25:45.920]   And then along came Luther.
[01:25:45.920 --> 01:25:51.360]   And pamphlets and what was then news before the newspapers exploded.
[01:25:51.360 --> 01:25:53.320]   It's the same in podcasts.
[01:25:53.320 --> 01:25:57.520]   Along came Gimlet and then everything changed.
[01:25:57.520 --> 01:26:00.960]   It's like Gimlet is the Luther podcasting.
[01:26:00.960 --> 01:26:01.960]   Literally.
[01:26:01.960 --> 01:26:04.400]   He said so bitterly.
[01:26:04.400 --> 01:26:06.160]   How much did they sell for?
[01:26:06.160 --> 01:26:07.160]   $230 million.
[01:26:07.160 --> 01:26:08.160]   $230 million.
[01:26:08.160 --> 01:26:14.400]   They have 16 shows.
[01:26:14.400 --> 01:26:18.360]   $230 million to Spotify.
[01:26:18.360 --> 01:26:24.800]   I'm not jealous, but I better do an ad.
[01:26:24.800 --> 01:26:25.800]   I like our model.
[01:26:25.800 --> 01:26:27.440]   I think ad support is fine.
[01:26:27.440 --> 01:26:29.440]   I just don't think we could charge people.
[01:26:29.440 --> 01:26:31.800]   It's just like a different retireber, that's all.
[01:26:31.800 --> 01:26:35.800]   I think our model works because of the research we put into it.
[01:26:35.800 --> 01:26:38.560]   We try to give people good content.
[01:26:38.560 --> 01:26:40.120]   We know who our audience is.
[01:26:40.120 --> 01:26:42.720]   We're not just throwing trash out.
[01:26:42.720 --> 01:26:43.720]   And we try to produce--
[01:26:43.720 --> 01:26:44.720]   Some of us are.
[01:26:44.720 --> 01:26:46.360]   Leo, is that--
[01:26:46.360 --> 01:26:48.360]   Are you sub-tweeting one of us?
[01:26:48.360 --> 01:26:49.360]   They're sub-tweeting me.
[01:26:49.360 --> 01:26:50.360]   I know.
[01:26:50.360 --> 01:26:51.360]   I can tell.
[01:26:51.360 --> 01:26:52.360]   So I don't speak.
[01:26:52.360 --> 01:26:54.440]   You can't punch me.
[01:26:54.440 --> 01:26:56.160]   And we try to do high quality.
[01:26:56.160 --> 01:27:02.280]   I mean, I've tried to have a certain standard because I don't want to waste people's time.
[01:27:02.280 --> 01:27:03.600]   But I don't know.
[01:27:03.600 --> 01:27:04.600]   Who knows?
[01:27:04.600 --> 01:27:06.320]   I don't know.
[01:27:06.320 --> 01:27:10.160]   Our show today is brought to you by a number of fine sponsors.
[01:27:10.160 --> 01:27:13.400]   We are very grateful to them for making it possible to do this.
[01:27:13.400 --> 01:27:16.600]   It's very expensive to run this.
[01:27:16.600 --> 01:27:22.280]   I was going to do-- add up all the money I've spent over the 15 years of Twitter.
[01:27:22.280 --> 01:27:24.480]   And I thought, that's a bad idea.
[01:27:24.480 --> 01:27:25.480]   Newk.
[01:27:25.480 --> 01:27:31.000]   That's a really bad idea.
[01:27:31.000 --> 01:27:32.640]   But we couldn't do it without the advertisers.
[01:27:32.640 --> 01:27:33.640]   So I'm very grateful.
[01:27:33.640 --> 01:27:34.640]   We have great advertisers.
[01:27:34.640 --> 01:27:35.640]   We're very picky.
[01:27:35.640 --> 01:27:37.720]   For instance, LinkedIn marketing solutions.
[01:27:37.720 --> 01:27:40.560]   This is a company we've wanted to do business with for a very long time.
[01:27:40.560 --> 01:27:42.000]   We're big fans of LinkedIn.
[01:27:42.000 --> 01:27:45.920]   I've always said it's the last decent social network.
[01:27:45.920 --> 01:27:51.320]   But people don't know that LinkedIn does a lot more than just a social network.
[01:27:51.320 --> 01:27:59.040]   LinkedIn marketing can help you speak to the right professionals at the right time.
[01:27:59.040 --> 01:28:03.880]   With over 62 million decision makers on LinkedIn, you're going to be able to connect with the
[01:28:03.880 --> 01:28:06.880]   right business leaders who are relevant to your company.
[01:28:06.880 --> 01:28:10.920]   And with LinkedIn ads, you can make sure your messages are getting through to the right
[01:28:10.920 --> 01:28:11.920]   people.
[01:28:11.920 --> 01:28:15.160]   You talk about an ad landscape that's valuable.
[01:28:15.160 --> 01:28:16.960]   Man, it's LinkedIn.
[01:28:16.960 --> 01:28:19.360]   And where the conversation is productive.
[01:28:19.360 --> 01:28:20.360]   It's high quality.
[01:28:20.360 --> 01:28:21.360]   It's smart.
[01:28:21.360 --> 01:28:22.360]   Yep.
[01:28:22.360 --> 01:28:27.040]   How do you get people's attention when there's a million messages a minute?
[01:28:27.040 --> 01:28:30.280]   There's a million hours of TV on all at the same time.
[01:28:30.280 --> 01:28:32.120]   There's just not enough hours in the day.
[01:28:32.120 --> 01:28:37.800]   LinkedIn ads are a very efficient, effective way to reach a very high quality audience.
[01:28:37.800 --> 01:28:40.800]   Even small to medium sized businesses can use LinkedIn ads.
[01:28:40.800 --> 01:28:44.320]   They're doing a great job with them to get their voices heard, to get their messages
[01:28:44.320 --> 01:28:47.200]   to resonate with the audience.
[01:28:47.200 --> 01:28:49.440]   And it's by the way, it's not just about awareness.
[01:28:49.440 --> 01:28:51.400]   No, no LinkedIn ads drive traffic.
[01:28:51.400 --> 01:28:53.200]   They drive engagement.
[01:28:53.200 --> 01:28:57.520]   They drive visits to a landing page, registrations to events.
[01:28:57.520 --> 01:28:58.960]   Did you think about that for your event?
[01:28:58.960 --> 01:29:00.360]   Are you doing an event?
[01:29:00.360 --> 01:29:06.560]   What better place to advertise an event than LinkedIn downloads of thought leadership content?
[01:29:06.560 --> 01:29:10.800]   We try to put stuff up all the time on LinkedIn because it's such a great place for people
[01:29:10.800 --> 01:29:15.320]   to learn about what you're doing and how you're thinking and to establish, you know, it's
[01:29:15.320 --> 01:29:21.720]   a subtle way to establish your brand as a thought leader, you know, as an executive.
[01:29:21.720 --> 01:29:26.440]   With precise targeting, small and medium sized businesses can talk only to the people who
[01:29:26.440 --> 01:29:27.440]   matter.
[01:29:27.440 --> 01:29:28.440]   Very efficient.
[01:29:28.440 --> 01:29:31.640]   At the end of the day, LinkedIn ads are helping smaller businesses get big results.
[01:29:31.640 --> 01:29:33.840]   This is exactly what we've been talking about here.
[01:29:33.840 --> 01:29:37.280]   And I think this is a very benign, very effective way to do it.
[01:29:37.280 --> 01:29:41.840]   And we believe in it so much we're going to get you a $100 ad credit right now.
[01:29:41.840 --> 01:29:46.320]   If you want to launch your first campaign, but you do have to go to the special landing
[01:29:46.320 --> 01:29:49.800]   page, LinkedIn.com/twig.
[01:29:49.800 --> 01:29:51.920]   Some terms and conditions apply about it.
[01:29:51.920 --> 01:29:53.920]   A $100 ad credit is a great way.
[01:29:53.920 --> 01:29:54.920]   Believe it or not.
[01:29:54.920 --> 01:29:58.440]   And we were talking about this earlier, Jeff, how $100 is a very, you can do very efficient
[01:29:58.440 --> 01:29:59.440]   buys.
[01:29:59.440 --> 01:30:00.940]   Amen, exactly.
[01:30:00.940 --> 01:30:05.080]   And so because of targeting, and you go to a place like LinkedIn, you want to reach people
[01:30:05.080 --> 01:30:12.480]   who are HR executives in this industry, that kind of stuff, that's incredibly valuable.
[01:30:12.480 --> 01:30:16.120]   And they don't say this in their ad copy, but I'm going to say it.
[01:30:16.120 --> 01:30:20.280]   A lot of other places you advertise, you don't know what your ad is going to be next to.
[01:30:20.280 --> 01:30:21.280]   Right.
[01:30:21.280 --> 01:30:24.840]   You really don't know what the environment is going to be.
[01:30:24.840 --> 01:30:29.680]   Any on Facebook, on Twitter, on YouTube, especially, but on LinkedIn, you know it's
[01:30:29.680 --> 01:30:30.960]   a quality environment.
[01:30:30.960 --> 01:30:36.320]   You're going to be, you know, this is going to reflect well on you, LinkedIn.com/twig.
[01:30:36.320 --> 01:30:41.080]   We're really happy to have LinkedIn as a sponsor of this week at Google.
[01:30:41.080 --> 01:30:43.920]   And it really is kind of apropos this whole conversation.
[01:30:43.920 --> 01:30:50.680]   I did not plan this, but I think it does make the point that some targeting, whether it's
[01:30:50.680 --> 01:30:54.400]   the targeting Stacy and I do where we know, and that LinkedIn does that too, where you
[01:30:54.400 --> 01:30:57.960]   know what the audience is because of the content you provide.
[01:30:57.960 --> 01:31:00.080]   And some of it is LinkedIn also as a social network.
[01:31:00.080 --> 01:31:03.240]   So they can say, well, we know this person is an executive or this person is a buyer
[01:31:03.240 --> 01:31:04.240]   of certain products.
[01:31:04.240 --> 01:31:05.240]   I love that.
[01:31:05.240 --> 01:31:06.240]   It's very efficient.
[01:31:06.240 --> 01:31:07.240]   I don't think there's anything wrong with that.
[01:31:07.240 --> 01:31:08.240]   I really don't.
[01:31:08.240 --> 01:31:14.640]   I always ask people, well, wouldn't you prefer an ad for something you're interested in and
[01:31:14.640 --> 01:31:17.520]   something you're not going to ever buy?
[01:31:17.520 --> 01:31:19.320]   Doesn't that ad waste your time?
[01:31:19.320 --> 01:31:20.320]   Exactly.
[01:31:20.320 --> 01:31:22.000]   I've always thought that.
[01:31:22.000 --> 01:31:24.040]   LinkedIn.com/twig.
[01:31:24.040 --> 01:31:25.600]   Don't waste your time.
[01:31:25.600 --> 01:31:27.720]   Don't waste your dollars.
[01:31:27.720 --> 01:31:34.760]   It's a very effective place to advertise.
[01:31:34.760 --> 01:31:39.040]   People love going through the APKs of Google apps and Android apps.
[01:31:39.040 --> 01:31:43.680]   And I'm sure they talked about this at all about Android, but apparently the Google Call
[01:31:43.680 --> 01:31:50.320]   APK has a little bit of code that shows that they're going to be, this is from GSM Arena,
[01:31:50.320 --> 01:31:52.280]   they're going to be adding call recording.
[01:31:52.280 --> 01:31:53.280]   No, it's--
[01:31:53.280 --> 01:31:54.840]   It's a free slope.
[01:31:54.840 --> 01:31:56.440]   Well, free slope.
[01:31:56.440 --> 01:32:00.720]   I mean, you also will have to be cognizant of what the laws are in your--
[01:32:00.720 --> 01:32:01.720]   Exactly.
[01:32:01.720 --> 01:32:04.560]   In my day and Leo's, since we're very old farts--
[01:32:04.560 --> 01:32:08.800]   Wait, I know this is going to talk about recording your conversations.
[01:32:08.800 --> 01:32:13.040]   Yes, well, you had to put a ding on the call if you were reporting.
[01:32:13.040 --> 01:32:14.040]   Oh, remember that?
[01:32:14.040 --> 01:32:15.040]   The beep?
[01:32:15.040 --> 01:32:16.040]   Yep.
[01:32:16.040 --> 01:32:17.040]   The beep.
[01:32:17.040 --> 01:32:18.040]   Google Voice does that.
[01:32:18.040 --> 01:32:19.040]   Beep.
[01:32:19.040 --> 01:32:20.040]   Actually.
[01:32:20.040 --> 01:32:21.320]   That was a signal that you were recording.
[01:32:21.320 --> 01:32:24.040]   But in-- so California's a two-party state.
[01:32:24.040 --> 01:32:25.040]   New York is not.
[01:32:25.040 --> 01:32:26.040]   Texas was not.
[01:32:26.040 --> 01:32:27.040]   Texas is not.
[01:32:27.040 --> 01:32:28.040]   New York is not.
[01:32:28.040 --> 01:32:29.040]   New York is not.
[01:32:29.040 --> 01:32:35.200]   So-- and it really is an-- these are antiquated laws because the reason that Texas and New
[01:32:35.200 --> 01:32:39.000]   York say, well, you only-- only one person has to know is because they were trying to
[01:32:39.000 --> 01:32:41.920]   prevent like wire tapping.
[01:32:41.920 --> 01:32:46.920]   But really, both people should have to give informed consent to a recording, right?
[01:32:46.920 --> 01:32:47.920]   I think so.
[01:32:47.920 --> 01:32:51.480]   So I think the California law makes sense.
[01:32:51.480 --> 01:32:54.560]   The New York state and Texas laws seem odd to me.
[01:32:54.560 --> 01:32:55.560]   I couldn't remember if you were Carolina.
[01:32:55.560 --> 01:32:56.560]   Carolina was.
[01:32:56.560 --> 01:33:02.920]   But I had a situation where I had to record a conversation and I just sold them straight
[01:33:02.920 --> 01:33:03.920]   up.
[01:33:03.920 --> 01:33:04.920]   It seems ethical.
[01:33:04.920 --> 01:33:08.560]   I'm going to record this right now just so you know because right now I don't remember
[01:33:08.560 --> 01:33:10.960]   if we have to consent that.
[01:33:10.960 --> 01:33:11.960]   Right.
[01:33:11.960 --> 01:33:12.960]   You know.
[01:33:12.960 --> 01:33:13.960]   But I--
[01:33:13.960 --> 01:33:16.760]   As a journalist though, it's damn convenient not having to tell anybody.
[01:33:16.760 --> 01:33:17.760]   Right.
[01:33:17.760 --> 01:33:18.760]   [LAUGH]
[01:33:18.760 --> 01:33:19.760]   Well, I was--
[01:33:19.760 --> 01:33:20.760]   I was a--
[01:33:20.760 --> 01:33:22.960]   Or as a whistleblower or a disgruntled--
[01:33:22.960 --> 01:33:23.960]   Mm-hmm.
[01:33:23.960 --> 01:33:25.360]   You know, if you're an unhappy employee, your boss is--
[01:33:25.360 --> 01:33:29.600]   Your boss is harassing you, having a phone-- I mean, it's the plot in many a movie, having
[01:33:29.600 --> 01:33:35.520]   a phone in your pocket, recording the boss berating you.
[01:33:35.520 --> 01:33:36.520]   Go ahead, Stacey.
[01:33:36.520 --> 01:33:38.080]   Oh, no.
[01:33:38.080 --> 01:33:45.120]   I was just going to say that it's interesting because now I record people and I'm like,
[01:33:45.120 --> 01:33:50.360]   "Hey, I'm going to record you for note-taking purposes versus record you for publication."
[01:33:50.360 --> 01:33:53.200]   Oh, smart.
[01:33:53.200 --> 01:34:00.160]   It's a little bit-- I mean, partly that's because my show is not adversarial in that way.
[01:34:00.160 --> 01:34:04.800]   And you went above and beyond because North Carolina is a single party state.
[01:34:04.800 --> 01:34:05.800]   Thank you, Mr. Scooter.
[01:34:05.800 --> 01:34:06.800]   It's in the chat room.
[01:34:06.800 --> 01:34:08.200]   Thank you very much.
[01:34:08.200 --> 01:34:14.840]   See, I think those are older laws that were more worried about a conversation be recorded
[01:34:14.840 --> 01:34:18.040]   by some other party outside, right?
[01:34:18.040 --> 01:34:21.320]   They're not worried about you recording a conversation you're having with somebody,
[01:34:21.320 --> 01:34:22.320]   but really they should.
[01:34:22.320 --> 01:34:23.320]   But that's not always--
[01:34:23.320 --> 01:34:27.600]   You know, to carry in a 40-pound reeled reel.
[01:34:27.600 --> 01:34:28.600]   Right.
[01:34:28.600 --> 01:34:30.800]   That's what's changed, right?
[01:34:30.800 --> 01:34:35.560]   I mean, everybody has a very good call recorder on their phone.
[01:34:35.560 --> 01:34:39.800]   In fact, pre-marshmallow Android phones did have call recording.
[01:34:39.800 --> 01:34:41.800]   And they took it out, I think, because of these legal concerns.
[01:34:41.800 --> 01:34:42.800]   Because it's all out there.
[01:34:42.800 --> 01:34:45.080]   Right now it looks like they're thinking about putting it in back in.
[01:34:45.080 --> 01:34:49.720]   I mean, I used to have-- it was part of a-- I mean, when I was at Business Week as an
[01:34:49.720 --> 01:34:57.800]   intern back in 1999, we had like, your phone system was-- you recorded your things through
[01:34:57.800 --> 01:35:00.640]   the phone system, and it was fancy, fancy setup.
[01:35:00.640 --> 01:35:03.360]   And you could do it on Google Voice, right?
[01:35:03.360 --> 01:35:04.360]   There's a star--
[01:35:04.360 --> 01:35:05.360]   Yeah, Google Voice.
[01:35:05.360 --> 01:35:06.360]   Like, she'd do it.
[01:35:06.360 --> 01:35:07.360]   And it didn't now.
[01:35:07.360 --> 01:35:08.360]   We used to do a Skype.
[01:35:08.360 --> 01:35:11.680]   This was before IP, or as IP was rolling out.
[01:35:11.680 --> 01:35:12.680]   This was--
[01:35:12.680 --> 01:35:13.680]   Have you-- are you that old, Stacey?
[01:35:13.680 --> 01:35:14.680]   I didn't know you were that old.
[01:35:14.680 --> 01:35:15.680]   It's not that old.
[01:35:15.680 --> 01:35:16.680]   She's a--
[01:35:16.680 --> 01:35:19.680]   I was working for the print version of Business Week.
[01:35:19.680 --> 01:35:20.680]   In 1999.
[01:35:20.680 --> 01:35:21.680]   Aw.
[01:35:21.680 --> 01:35:22.680]   Come on.
[01:35:22.680 --> 01:35:23.680]   She was only 11.
[01:35:23.680 --> 01:35:24.680]   Did you ever--
[01:35:24.680 --> 01:35:25.680]   Steve Shepherd?
[01:35:25.680 --> 01:35:27.680]   Steve Shepherd the other than no.
[01:35:27.680 --> 01:35:30.360]   Steve Shepherd and Mark Morrison, yes.
[01:35:30.360 --> 01:35:31.920]   He was my first dean.
[01:35:31.920 --> 01:35:32.920]   It's cool.
[01:35:32.920 --> 01:35:33.920]   Aw.
[01:35:33.920 --> 01:35:34.920]   Wonderful man.
[01:35:34.920 --> 01:35:37.200]   Wonderful, wonderful man.
[01:35:37.200 --> 01:35:38.200]   There you go.
[01:35:38.200 --> 01:35:41.920]   So have you tried the new call card?
[01:35:41.920 --> 01:35:44.200]   Because I think they have it on the 3A now.
[01:35:44.200 --> 01:35:45.200]   What?
[01:35:45.200 --> 01:35:46.200]   No, I haven't.
[01:35:46.200 --> 01:35:48.760]   Yeah, that does-- I remember we showed you this before that it records.
[01:35:48.760 --> 01:35:49.760]   Oh, yes.
[01:35:49.760 --> 01:35:50.760]   Yes, it was conversations.
[01:35:50.760 --> 01:35:51.760]   Oh, yes, I have.
[01:35:51.760 --> 01:35:52.760]   Yes, I've tried that.
[01:35:52.760 --> 01:35:56.080]   So, I mean, talk about for a reporter taking notes.
[01:35:56.080 --> 01:35:57.080]   Oh.
[01:35:57.080 --> 01:36:00.560]   Well, so I used it actually because I didn't have time to transcribe something from my
[01:36:00.560 --> 01:36:01.560]   podcast.
[01:36:01.560 --> 01:36:04.040]   I know I could have sent it away, but I was just trying to finish something up.
[01:36:04.040 --> 01:36:06.200]   So I like, played it.
[01:36:06.200 --> 01:36:10.000]   I recorded something like from my podcast.
[01:36:10.000 --> 01:36:11.000]   So I could get a--
[01:36:11.000 --> 01:36:12.240]   How well did it work?
[01:36:12.240 --> 01:36:13.240]   It worked really well.
[01:36:13.240 --> 01:36:14.240]   Yeah, nice.
[01:36:14.240 --> 01:36:15.240]   I mean, it was super handy.
[01:36:15.240 --> 01:36:18.440]   It was kind of just a little hack just to be like, I need this quote and I don't want to
[01:36:18.440 --> 01:36:21.440]   listen to this to transcribe it, you know, slowly.
[01:36:21.440 --> 01:36:22.440]   We're going to--
[01:36:22.440 --> 01:36:28.800]   We're going to look back and say, do you remember when you had to write things down?
[01:36:28.800 --> 01:36:30.280]   You should still write things down.
[01:36:30.280 --> 01:36:31.280]   I still do.
[01:36:31.280 --> 01:36:33.560]   I think it's an important part of retaining information.
[01:36:33.560 --> 01:36:34.560]   And--
[01:36:34.560 --> 01:36:35.560]   Oh, you're writing parts, Stacy.
[01:36:35.560 --> 01:36:38.800]   No, I was going to say is a writer, right?
[01:36:38.800 --> 01:36:43.360]   When I'm writing a story, when I do my first draft of a story, like anything that's more
[01:36:43.360 --> 01:36:48.400]   than a news story, I actually do TKs wherever I can.
[01:36:48.400 --> 01:36:49.400]   I don't have the facts.
[01:36:49.400 --> 01:36:50.920]   I write everything.
[01:36:50.920 --> 01:36:55.040]   And then I do paraphrases of the quote with quote TK.
[01:36:55.040 --> 01:36:56.040]   TKs.
[01:36:56.040 --> 01:36:57.040]   So I can--
[01:36:57.040 --> 01:36:58.040]   Smart.
[01:36:58.040 --> 01:37:01.880]   And I do that so I can-- it's basically like whatever flows to the top is probably the
[01:37:01.880 --> 01:37:02.880]   most interesting thing.
[01:37:02.880 --> 01:37:05.600]   It's first trillion's go what TK is.
[01:37:05.600 --> 01:37:06.600]   Sloppy copy.
[01:37:06.600 --> 01:37:08.600]   That's so mean.
[01:37:08.600 --> 01:37:11.920]   No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,
[01:37:11.920 --> 01:37:13.800]   I say that with--
[01:37:13.800 --> 01:37:16.600]   It's a typesetter, it's a typesetter abbreviation, right?
[01:37:16.600 --> 01:37:17.600]   No.
[01:37:17.600 --> 01:37:22.720]   What you were describing was a sloppy copy and I'm the same way I have this.
[01:37:22.720 --> 01:37:26.120]   No, you type-- because you want the first-- I told my daughter this when she was writing
[01:37:26.120 --> 01:37:27.120]   an opinion piece.
[01:37:27.120 --> 01:37:29.640]   I said, just write-- don't-- because she was getting writer's block.
[01:37:29.640 --> 01:37:30.640]   I said, just write.
[01:37:30.640 --> 01:37:31.640]   Yeah, just let it out.
[01:37:31.640 --> 01:37:32.640]   That's your first draft.
[01:37:32.640 --> 01:37:34.400]   You could throw the whole thing away from one.
[01:37:34.400 --> 01:37:35.920]   And I think TKs are a great part of that.
[01:37:35.920 --> 01:37:38.160]   You go, well, the quote was like this, TK.
[01:37:38.160 --> 01:37:39.160]   Yup.
[01:37:39.160 --> 01:37:40.160]   The problem is--
[01:37:40.160 --> 01:37:42.160]   I didn't really know TKs but the magazine.
[01:37:42.160 --> 01:37:43.160]   It's really funny.
[01:37:43.160 --> 01:37:44.160]   The problem is--
[01:37:44.160 --> 01:37:45.160]   You've got to then search for your TKs.
[01:37:45.160 --> 01:37:46.160]   Yeah.
[01:37:46.160 --> 01:37:48.960]   The worst thing is to file a copy and there's no editors anymore.
[01:37:48.960 --> 01:37:50.760]   And TK makes it to print.
[01:37:50.760 --> 01:37:51.760]   Right.
[01:37:51.760 --> 01:37:52.760]   Yes.
[01:37:52.760 --> 01:37:53.760]   That's embarrassing.
[01:37:53.760 --> 01:37:57.520]   That's why TKs are-- that's why you don't like-- yeah.
[01:37:57.520 --> 01:37:58.720]   That's why I don't make things up.
[01:37:58.720 --> 01:38:03.200]   I'm always like TK because otherwise you'll not see your made up thing.
[01:38:03.200 --> 01:38:07.160]   Ant, your personal assistant has made you a cup of coffee to replace that old--
[01:38:07.160 --> 01:38:10.480]   Miss Sarah, she knew I was freezing in here.
[01:38:10.480 --> 01:38:12.760]   So she brought me some more coffee.
[01:38:12.760 --> 01:38:13.760]   Thank you so much.
[01:38:13.760 --> 01:38:14.760]   You just got all your hat and--
[01:38:14.760 --> 01:38:19.760]   [LAUGHTER]
[01:38:19.760 --> 01:38:20.760]   Ant's way nice.
[01:38:20.760 --> 01:38:22.760]   I would bring in a cup of coffee any day.
[01:38:22.760 --> 01:38:23.760]   But Leo, I got a--
[01:38:23.760 --> 01:38:24.760]   Whoa.
[01:38:24.760 --> 01:38:28.040]   I'm wearing my bob cratch at start today.
[01:38:28.040 --> 01:38:29.760]   Thank you, Miss Sarah.
[01:38:29.760 --> 01:38:30.760]   As always.
[01:38:30.760 --> 01:38:37.160]   So Instagram, I really want to know what Ant thinks about this.
[01:38:37.160 --> 01:38:41.000]   When Instagram first started, I do remember that it made me mad that people would take
[01:38:41.000 --> 01:38:44.160]   pictures with SLRs, with big fancy cameras.
[01:38:44.160 --> 01:38:47.360]   I thought, no, Instagram is made for your camera phone.
[01:38:47.360 --> 01:38:48.360]   For socializing.
[01:38:48.360 --> 01:38:49.760]   And so you shouldn't be posting.
[01:38:49.760 --> 01:38:51.400]   But I quickly gave that up.
[01:38:51.400 --> 01:38:52.400]   Right?
[01:38:52.400 --> 01:38:53.400]   Yeah.
[01:38:53.400 --> 01:38:58.800]   Now Instagram says, you can't use Photoshop on an image on Instagram.
[01:38:58.800 --> 01:38:59.800]   At all.
[01:38:59.800 --> 01:39:00.800]   What?
[01:39:00.800 --> 01:39:01.800]   I hate this verbiage.
[01:39:01.800 --> 01:39:02.800]   I hate this verbiage.
[01:39:02.800 --> 01:39:05.440]   What do they mean?
[01:39:05.440 --> 01:39:06.440]   I saw this on--
[01:39:06.440 --> 01:39:07.440]   Fake news.
[01:39:07.440 --> 01:39:08.440]   Right.
[01:39:08.440 --> 01:39:13.640]   Everybody's wanting to say it's a way to sort of knock down all of the bad mess that's
[01:39:13.640 --> 01:39:15.640]   being sprayed and all the false information.
[01:39:15.640 --> 01:39:17.160]   Also way to improve photos.
[01:39:17.160 --> 01:39:20.680]   But you just-- you can't say a Photoshop image.
[01:39:20.680 --> 01:39:26.280]   Everything-- even if you just boost the saturation to make it look a little bit better, that's
[01:39:26.280 --> 01:39:27.280]   Photoshop in it.
[01:39:27.280 --> 01:39:28.280]   Right?
[01:39:28.280 --> 01:39:29.280]   Yup.
[01:39:29.280 --> 01:39:31.200]   So why are they using that particular terminology for this?
[01:39:31.200 --> 01:39:34.760]   Now, Granite, you can look at the example on the next web where they had a picture of
[01:39:34.760 --> 01:39:40.040]   EZ and his crew with Kurt Cobain, quote unquote, "photoshopped" in.
[01:39:40.040 --> 01:39:45.600]   Yes, that is an actual manipulation and sticking him into the image and totally changing that
[01:39:45.600 --> 01:39:46.600]   image.
[01:39:46.600 --> 01:39:47.600]   Because that never happened.
[01:39:47.600 --> 01:39:48.600]   That never happened.
[01:39:48.600 --> 01:39:52.600]   But all of this whole Photoshop, we're just going to stop locking all of the--
[01:39:52.600 --> 01:39:53.600]   Surely they don't need that.
[01:39:53.600 --> 01:39:54.840]   Do they have to say that?
[01:39:54.840 --> 01:39:56.440]   Are they doing that?
[01:39:56.440 --> 01:40:00.880]   I haven't seen it in my feed yet, but there's been, I believe on pedapixel.com, they had
[01:40:00.880 --> 01:40:07.080]   a couple people that had examples of the screen saying this has been flagged as not legit
[01:40:07.080 --> 01:40:08.560]   or not real or something like that.
[01:40:08.560 --> 01:40:10.280]   I can't remember this as that verbiage.
[01:40:10.280 --> 01:40:17.720]   Are there technological signatures of that larger manipulation or could we have Photoshop
[01:40:17.720 --> 01:40:23.600]   type programs add some sort of technological signature that companies could look for?
[01:40:23.600 --> 01:40:24.600]   Oh, yeah.
[01:40:24.600 --> 01:40:28.040]   Like, sorting little invisible blue dots saying this has been Photoshop like printers do.
[01:40:28.040 --> 01:40:30.400]   Right, pixel stretching things in that image.
[01:40:30.400 --> 01:40:34.000]   You can analyze a photo and say, "Well, that's been meant to me."
[01:40:34.000 --> 01:40:37.240]   See, it's going to hurt my favorite Instagram feed.
[01:40:37.240 --> 01:40:38.640]   Do you know Kirby Jenner?
[01:40:38.640 --> 01:40:39.640]   Kirby Jenner?
[01:40:39.640 --> 01:40:41.840]   You're going to like this one, Jeff.
[01:40:41.840 --> 01:40:42.840]   Oh, boy.
[01:40:42.840 --> 01:40:47.520]   That's Meg Whitman and Jeffrey Katzenberg, the founders of Quibi, the new short form streaming
[01:40:47.520 --> 01:40:53.720]   service that's already raised a billion dollars and says, "But we're going to spend 1.2."
[01:40:53.720 --> 01:40:55.680]   And there's Kirby Photoshopped in.
[01:40:55.680 --> 01:41:00.120]   He Photoshopped himself into pictures.
[01:41:00.120 --> 01:41:01.160]   And that's great.
[01:41:01.160 --> 01:41:06.480]   He pretends he's Kendall Jenner's twin brother.
[01:41:06.480 --> 01:41:08.960]   And then just, but see, this is art.
[01:41:08.960 --> 01:41:11.160]   See, this is what, this is what I'm going to say.
[01:41:11.160 --> 01:41:12.160]   I'm going to say it.
[01:41:12.160 --> 01:41:15.320]   This is where moral panic means us.
[01:41:15.320 --> 01:41:19.160]   You get rid of a technology because it can be misused and then you lose all the good
[01:41:19.160 --> 01:41:22.280]   uses of it.
[01:41:22.280 --> 01:41:25.280]   This guy is one of the best.
[01:41:25.280 --> 01:41:29.200]   I don't think people understand how brilliant he is as a paratist.
[01:41:29.200 --> 01:41:32.280]   I mean, all of this stuff is fake.
[01:41:32.280 --> 01:41:34.640]   It's awesome.
[01:41:34.640 --> 01:41:40.080]   It's so awesome.
[01:41:40.080 --> 01:41:43.600]   There's Kim Kardashian and Selene Dion.
[01:41:43.600 --> 01:41:46.840]   And now that's a real picture, that part.
[01:41:46.840 --> 01:41:52.600]   And then he goes into the studio, shoots himself in a perfectly suitable outfit and
[01:41:52.600 --> 01:41:54.480]   edits himself into the picture.
[01:41:54.480 --> 01:41:55.480]   He's brilliant.
[01:41:55.480 --> 01:41:56.480]   That's Photoshop.
[01:41:56.480 --> 01:41:57.480]   Photoshop.
[01:41:57.480 --> 01:41:58.480]   It's great Photoshop.
[01:41:58.480 --> 01:42:02.280]   That's probably going to go away.
[01:42:02.280 --> 01:42:04.080]   I put up visual grams.
[01:42:04.080 --> 01:42:09.840]   I don't even know what's happening here, but it's so crazy.
[01:42:09.840 --> 01:42:12.040]   Napoleon Dynamite in the chat.
[01:42:12.040 --> 01:42:13.680]   Oh my God.
[01:42:13.680 --> 01:42:16.880]   When I saw this, what is that?
[01:42:16.880 --> 01:42:17.960]   That's the moment.
[01:42:17.960 --> 01:42:20.280]   That's the moment gallery benefit.
[01:42:20.280 --> 01:42:22.080]   It's a great benefit every year.
[01:42:22.080 --> 01:42:23.880]   Kirby and Kendall go.
[01:42:23.880 --> 01:42:26.200]   Of course, they're famous for their outfits.
[01:42:26.200 --> 01:42:28.200]   Looks like he's wearing a one-man tent.
[01:42:28.200 --> 01:42:29.680]   I don't know if that's it.
[01:42:29.680 --> 01:42:31.680]   Yeah, that does like a tent.
[01:42:31.680 --> 01:42:32.680]   That is a tent.
[01:42:32.680 --> 01:42:33.680]   That's amazing.
[01:42:33.680 --> 01:42:37.280]   I knew I'd get you eventually.
[01:42:37.280 --> 01:42:39.280]   Oh gosh.
[01:42:39.280 --> 01:42:43.520]   These are, I'm showing years worth of work because he takes, you know, he'll take a
[01:42:43.520 --> 01:42:45.040]   long time to try to figure this out.
[01:42:45.040 --> 01:42:46.040]   A lot of work.
[01:42:46.040 --> 01:42:47.040]   That composition has.
[01:42:47.040 --> 01:42:48.040]   Yeah, yeah.
[01:42:48.040 --> 01:42:49.200]   And he gets the lighting just right here.
[01:42:49.200 --> 01:42:52.760]   He is with Kanye having a eating fruit loops.
[01:42:52.760 --> 01:42:56.440]   No, and see, that should be flagged because we know that didn't happen.
[01:42:56.440 --> 01:42:57.440]   That is fake.
[01:42:57.440 --> 01:42:58.440]   Right.
[01:42:58.440 --> 01:42:59.440]   So what is, they're not going to take it down.
[01:42:59.440 --> 01:43:02.920]   They're not going to block it, but they're going to say, you know, it's the screenshots
[01:43:02.920 --> 01:43:05.720]   that I saw, maybe it's in my other rundown for folks.
[01:43:05.720 --> 01:43:08.440]   I have, is it visual grams here?
[01:43:08.440 --> 01:43:10.280]   These are all photoshopped too.
[01:43:10.280 --> 01:43:11.760]   This is photographic art.
[01:43:11.760 --> 01:43:12.760]   Right.
[01:43:12.760 --> 01:43:15.240]   Visual grams is a popular account on Instagram.
[01:43:15.240 --> 01:43:20.600]   And when you look at it, it just plays into the eye, but 90% of those are quote unquote
[01:43:20.600 --> 01:43:24.240]   photoshopped images, but they're just beautiful art.
[01:43:24.240 --> 01:43:31.320]   My friend Trey rekcliffe uses HDR and Photoshop to do some of those beautiful art ever here.
[01:43:31.320 --> 01:43:32.320]   Okay.
[01:43:32.320 --> 01:43:34.560]   I'll find the petapixel site here.
[01:43:34.560 --> 01:43:41.880]   Somebody in our chat room has linked to Instagram now hiding and it puts a big X across it.
[01:43:41.880 --> 01:43:43.880]   Reviewed by independent fact checkers.
[01:43:43.880 --> 01:43:48.480]   Oh, you see, this is where this leads us.
[01:43:48.480 --> 01:43:49.480]   This is not.
[01:43:49.480 --> 01:43:54.320]   This is where they should be fact checking every political ad makes them so scared.
[01:43:54.320 --> 01:43:55.320]   This was the picture.
[01:43:55.320 --> 01:44:00.600]   This is also what happens when you don't invest in people for content moderation.
[01:44:00.600 --> 01:44:03.000]   And this is what happens when you try to scale.
[01:44:03.000 --> 01:44:04.000]   Well, they're really big.
[01:44:04.000 --> 01:44:05.000]   I mean, that's what this is.
[01:44:05.000 --> 01:44:06.000]   They have to be.
[01:44:06.000 --> 01:44:10.000]   Now, I have to point out that even though it had this false information, this big X on
[01:44:10.000 --> 01:44:12.640]   it, you could click through it.
[01:44:12.640 --> 01:44:15.680]   And yes, clearly those mountains aren't that rainbow color.
[01:44:15.680 --> 01:44:16.680]   All right.
[01:44:16.680 --> 01:44:17.680]   So almost false information.
[01:44:17.680 --> 01:44:19.320]   I'm going to site you right there.
[01:44:19.320 --> 01:44:20.320]   But let's think about that.
[01:44:20.320 --> 01:44:24.760]   If you can click through it, you're scrolling through just exactly exactly.
[01:44:24.760 --> 01:44:26.880]   You just, I can't see that.
[01:44:26.880 --> 01:44:32.480]   Well, and it really has conversions if account has lots of these X's that the implication
[01:44:32.480 --> 01:44:35.320]   is this guy is trying to trick people.
[01:44:35.320 --> 01:44:37.720]   Kirby's definitely trying to trick people.
[01:44:37.720 --> 01:44:40.120]   It's a joke.
[01:44:40.120 --> 01:44:42.280]   You know, it's not a matter of time before.
[01:44:42.280 --> 01:44:43.440]   I mean, this is, this is what.
[01:44:43.440 --> 01:44:46.560]   If you can click through, I think it's okay.
[01:44:46.560 --> 01:44:47.560]   I'm going to be honest.
[01:44:47.560 --> 01:44:48.560]   But that's the thing though.
[01:44:48.560 --> 01:44:51.280]   I know not everyone's going to click through.
[01:44:51.280 --> 01:44:54.360]   So I think it'll be harder to establish.
[01:44:54.360 --> 01:44:56.080]   It's also saying it's false information.
[01:44:56.080 --> 01:45:01.440]   And I think that's not okay because it's false information about that photo.
[01:45:01.440 --> 01:45:06.680]   They just because of photos manipulated doesn't mean it's misleading or false information.
[01:45:06.680 --> 01:45:08.920]   You could say this is a manipulated photo.
[01:45:08.920 --> 01:45:10.280]   That's probably a better way to do it.
[01:45:10.280 --> 01:45:12.200]   And maybe not put a big red X.
[01:45:12.200 --> 01:45:13.200]   I wonder.
[01:45:13.200 --> 01:45:20.280]   I think the big red X or a if you get a this is this photo has been manipulated across the
[01:45:20.280 --> 01:45:21.680]   photo that you click through.
[01:45:21.680 --> 01:45:22.680]   I think that's actually okay.
[01:45:22.680 --> 01:45:28.960]   But you can see why this is a problem because guess who's getting a lot of hate because
[01:45:28.960 --> 01:45:30.720]   they won't do this Facebook.
[01:45:30.720 --> 01:45:31.720]   Yeah.
[01:45:31.720 --> 01:45:35.360]   They're saying any politician who wants to say anything they want in a political ad can
[01:45:35.360 --> 01:45:37.320]   jump as on television.
[01:45:37.320 --> 01:45:38.320]   They're allowed to.
[01:45:38.320 --> 01:45:39.320]   Yeah.
[01:45:39.320 --> 01:45:41.400]   And we're going to allow that.
[01:45:41.400 --> 01:45:44.680]   And so this is which is ironic because Instagram is owned by Facebook.
[01:45:44.680 --> 01:45:50.080]   But this is the problem is former head of news feed is now the head of Instagram.
[01:45:50.080 --> 01:45:52.600]   So he's going his own way.
[01:45:52.600 --> 01:45:55.360]   You think you think Mark didn't say yes to it.
[01:45:55.360 --> 01:45:56.360]   Oh yeah.
[01:45:56.360 --> 01:45:57.360]   No, I absolutely did.
[01:45:57.360 --> 01:45:58.360]   But Adam was sorry.
[01:45:58.360 --> 01:46:02.800]   You know, I'm sure argued there was a different culture there and it was a lot easier to do.
[01:46:02.800 --> 01:46:05.280]   Well, and that's the problem.
[01:46:05.280 --> 01:46:07.040]   But it's about change or not.
[01:46:07.040 --> 01:46:11.840]   And that's why this is such a bad thing because it is using a mechanical system to say, oh,
[01:46:11.840 --> 01:46:13.520]   well, that's been photoshopped.
[01:46:13.520 --> 01:46:16.320]   And the presumption is it's misleading or it's false.
[01:46:16.320 --> 01:46:18.040]   But we can do it.
[01:46:18.040 --> 01:46:21.280]   And this is my problem with it because, well, we can do it.
[01:46:21.280 --> 01:46:23.040]   They're going to do it even if it's the wrong thing to do.
[01:46:23.040 --> 01:46:26.240]   And Facebook's not going to do it because they can't do it even though that's the right
[01:46:26.240 --> 01:46:27.240]   thing to do.
[01:46:27.240 --> 01:46:28.240]   All right.
[01:46:28.240 --> 01:46:33.000]   And so it really comes down and does every single time in Silicon Valley to the technology.
[01:46:33.000 --> 01:46:34.000]   Can we do it?
[01:46:34.000 --> 01:46:35.000]   Then we'll do it.
[01:46:35.000 --> 01:46:36.000]   If we can't, well, we won't.
[01:46:36.000 --> 01:46:37.160]   I don't want Facebook.
[01:46:37.160 --> 01:46:41.200]   I don't want you think Facebook's going to do a good job of fact checking?
[01:46:41.200 --> 01:46:42.800]   They're going to do an awful job of fact checking.
[01:46:42.800 --> 01:46:45.920]   It leads us to the kind of stuff you showed.
[01:46:45.920 --> 01:46:51.960]   And, you know, everything the politician says practically can be called a lie by somebody
[01:46:51.960 --> 01:46:53.120]   who doesn't like it.
[01:46:53.120 --> 01:46:54.120]   Right.
[01:46:54.120 --> 01:46:58.360]   I think putting them in that position and telling them to fact check political ads is ridiculous.
[01:46:58.360 --> 01:46:59.800]   How about anti-vaxx ads?
[01:46:59.800 --> 01:47:00.800]   Should they run those?
[01:47:00.800 --> 01:47:01.800]   Yes.
[01:47:01.800 --> 01:47:02.800]   No, they should get rid of those.
[01:47:02.800 --> 01:47:03.880]   Yes, they're running them.
[01:47:03.880 --> 01:47:08.280]   Here's, this is from BuzzFeed, Carolyn Haskins.
[01:47:08.280 --> 01:47:09.280]   This is a screw up.
[01:47:09.280 --> 01:47:11.120]   Is it a screw up or a...
[01:47:11.120 --> 01:47:12.600]   Or what is it?
[01:47:12.600 --> 01:47:15.000]   Well, the policy is not to run anti-vaxx.
[01:47:15.000 --> 01:47:18.920]   Policy is not to run them so they're screwing up.
[01:47:18.920 --> 01:47:20.320]   Or let's just example.
[01:47:20.320 --> 01:47:22.360]   See, technology can't do it.
[01:47:22.360 --> 01:47:25.480]   So well, we're going to just go ahead.
[01:47:25.480 --> 01:47:31.120]   I think this is bad because people might look at this guide to pertussis, which implies
[01:47:31.120 --> 01:47:34.120]   this is a guide to a whooping cough and what to do about it.
[01:47:34.120 --> 01:47:39.480]   It falsely claims that the whooping cough vaccine causes neurological damage.
[01:47:39.480 --> 01:47:44.440]   Instead, you should buy a product from the company that makes this pamphlet that contains
[01:47:44.440 --> 01:47:48.120]   elderberry, elixir, vitamin C powder and a mixture of herbs.
[01:47:48.120 --> 01:47:49.320]   So he's a crazy human.
[01:47:49.320 --> 01:47:50.800]   They're going to get fooled by this.
[01:47:50.800 --> 01:47:51.800]   Yes.
[01:47:51.800 --> 01:47:52.800]   Yes.
[01:47:52.800 --> 01:47:53.800]   Yes, they're going to screw up.
[01:47:53.800 --> 01:47:56.960]   They're, they're, they're, you know, and the problem is that story just brought that
[01:47:56.960 --> 01:47:59.920]   a hell of a lot more attention than that ever did.
[01:47:59.920 --> 01:48:00.920]   I don't know.
[01:48:00.920 --> 01:48:01.920]   That's a bad way of that.
[01:48:01.920 --> 01:48:03.520]   How many you don't, we don't know that.
[01:48:03.520 --> 01:48:07.440]   I admit it's been millions of people might have seen that at.
[01:48:07.440 --> 01:48:11.440]   I guarantee you, these people did not hear this show.
[01:48:11.440 --> 01:48:14.980]   I wish, I wish I was as effective as Facebook.
[01:48:14.980 --> 01:48:15.980]   We are heard.
[01:48:15.980 --> 01:48:16.980]   We are heard.
[01:48:16.980 --> 01:48:18.760]   I wish.
[01:48:18.760 --> 01:48:20.880]   So PayPal bought honey.
[01:48:20.880 --> 01:48:23.960]   Remember we talked about that for like what a billion dollars?
[01:48:23.960 --> 01:48:27.960]   Now Amazon says, you know, they were telling you security risks.
[01:48:27.960 --> 01:48:30.720]   They were talking to you, right?
[01:48:30.720 --> 01:48:35.120]   That's interesting.
[01:48:35.120 --> 01:48:42.840]   Honey, which my wife uses and loves is a browser extension that finds coupons.
[01:48:42.840 --> 01:48:47.560]   I asked Lisa, you know that the way the reason that's freeze, because it's tracking where
[01:48:47.560 --> 01:48:48.560]   you go, she said, yeah, that's fine.
[01:48:48.560 --> 01:48:49.560]   I get it.
[01:48:49.560 --> 01:48:50.560]   I get to save so much money.
[01:48:50.560 --> 01:48:51.560]   It's worth it.
[01:48:51.560 --> 01:48:52.560]   So she knows.
[01:48:52.560 --> 01:48:53.560]   Right.
[01:48:53.560 --> 01:48:57.960]   Amazon says, well, that extension is a security risk, not a privacy risk.
[01:48:57.960 --> 01:49:00.560]   Amazon would, that would be, that would be hood spa.
[01:49:00.560 --> 01:49:04.400]   But, you know, honey's flying on you.
[01:49:04.400 --> 01:49:07.920]   And no one is saying anything about Amazon is tracking cookies though.
[01:49:07.920 --> 01:49:08.920]   Right.
[01:49:08.920 --> 01:49:10.680]   They're doing the same thing.
[01:49:10.680 --> 01:49:13.960]   And by the way, honey's been available on Amazon for years.
[01:49:13.960 --> 01:49:19.040]   So it's not, you know, four billion dollars.
[01:49:19.040 --> 01:49:20.040]   That's what the hell paid.
[01:49:20.040 --> 01:49:26.320]   Hey, every, every woman I know who's a mom or a real person who does not speak technology,
[01:49:26.320 --> 01:49:27.720]   they all use this.
[01:49:27.720 --> 01:49:28.800]   Do you think legit?
[01:49:28.800 --> 01:49:33.040]   Do you think they know Stacey, how honey makes money?
[01:49:33.040 --> 01:49:37.120]   A couple of them do, but most of them don't care because they're also getting value.
[01:49:37.120 --> 01:49:39.000]   And that, that's the point, right?
[01:49:39.000 --> 01:49:40.000]   Yeah.
[01:49:40.000 --> 01:49:42.880]   If you can get value from things, people don't mind.
[01:49:42.880 --> 01:49:48.360]   I think the question is, that value is easy to see because you're saving actual money.
[01:49:48.360 --> 01:49:49.360]   Right.
[01:49:49.360 --> 01:49:53.800]   That's the same argument I have with just being logged into Google services on my Android
[01:49:53.800 --> 01:49:54.800]   device.
[01:49:54.800 --> 01:49:59.800]   There's a value for me to be able to go through the big city of Petaloma down these streets
[01:49:59.800 --> 01:50:04.000]   that I have no idea about and let Google track me and tell me the right way and so on
[01:50:04.000 --> 01:50:05.000]   and so forth.
[01:50:05.000 --> 01:50:06.000]   There's a value.
[01:50:06.000 --> 01:50:07.000]   Oh, yeah.
[01:50:07.000 --> 01:50:08.000]   Maps for sure.
[01:50:08.000 --> 01:50:09.000]   Right.
[01:50:09.000 --> 01:50:13.600]   But do you leave maps location tracking on after you're when you're not using it?
[01:50:13.600 --> 01:50:14.600]   I don't think so.
[01:50:14.600 --> 01:50:16.000]   No, that's that Apple thing.
[01:50:16.000 --> 01:50:18.000]   It's only allow one app is running.
[01:50:18.000 --> 01:50:19.800]   It's less time I do turn it off.
[01:50:19.800 --> 01:50:20.800]   I'll do that all time.
[01:50:20.800 --> 01:50:21.800]   No, I'm an android.
[01:50:21.800 --> 01:50:22.800]   I know you have that choice on Android.
[01:50:22.800 --> 01:50:23.800]   Yeah.
[01:50:23.800 --> 01:50:25.800]   Google offers you that now on Android.
[01:50:25.800 --> 01:50:30.200]   It's like, hey, this location just or this app just got your location in the background.
[01:50:30.200 --> 01:50:31.940]   I'm glad both are doing it.
[01:50:31.940 --> 01:50:37.820]   This is why I like actually really like California's Consumer Privacy Act because there's really
[01:50:37.820 --> 01:50:38.820]   only two parts to it.
[01:50:38.820 --> 01:50:39.820]   It's easy to understand.
[01:50:39.820 --> 01:50:42.840]   A, you have to tell them what information you're gathering and B, you have to give them
[01:50:42.840 --> 01:50:43.840]   a choice to opt out.
[01:50:43.840 --> 01:50:45.080]   Let us delete it too.
[01:50:45.080 --> 01:50:46.080]   That's very simple.
[01:50:46.080 --> 01:50:49.720]   And I think that that's what we should expect from every company.
[01:50:49.720 --> 01:50:52.080]   You know, honey should say, look, this is what we gather.
[01:50:52.080 --> 01:50:53.080]   You're getting a great deal.
[01:50:53.080 --> 01:50:54.960]   You're saving hundreds of dollars in return.
[01:50:54.960 --> 01:50:56.060]   It's a free service.
[01:50:56.060 --> 01:50:57.240]   We got to make money.
[01:50:57.240 --> 01:50:58.640]   This is how we make money.
[01:50:58.640 --> 01:50:59.640]   Just be clear.
[01:50:59.640 --> 01:51:03.000]   I would say this is what we gather and this is where it goes.
[01:51:03.000 --> 01:51:04.000]   Yeah.
[01:51:04.000 --> 01:51:05.000]   Yes.
[01:51:05.000 --> 01:51:06.000]   Yes.
[01:51:06.000 --> 01:51:07.000]   And that's in the law too.
[01:51:07.000 --> 01:51:08.000]   This is who gets it.
[01:51:08.000 --> 01:51:09.000]   Yeah.
[01:51:09.000 --> 01:51:11.800]   Which if we'd done that, it's the early days of cookies, we wouldn't be in this situation.
[01:51:11.800 --> 01:51:12.800]   Our own situation.
[01:51:12.800 --> 01:51:15.480]   Our disclosure is which I wrote in a book.
[01:51:15.480 --> 01:51:16.480]   You did.
[01:51:16.480 --> 01:51:18.280]   See, I should read more.
[01:51:18.280 --> 01:51:19.840]   Was that what?
[01:51:19.840 --> 01:51:22.760]   Jase is the one who reads.
[01:51:22.760 --> 01:51:25.280]   I just like to watch TV.
[01:51:25.280 --> 01:51:30.960]   As Chauncey Gardner said, I like to watch.
[01:51:30.960 --> 01:51:34.440]   Twitter.
[01:51:34.440 --> 01:51:35.440]   All sorts of changes.
[01:51:35.440 --> 01:51:36.520]   They're looking at all sorts of things.
[01:51:36.520 --> 01:51:40.360]   One thing they will not do, according to Jack Dorsey's ad editing, is an edit button.
[01:51:40.360 --> 01:51:41.880]   I still don't quite get that.
[01:51:41.880 --> 01:51:43.480]   Because it's already out there.
[01:51:43.480 --> 01:51:44.480]   It lives.
[01:51:44.480 --> 01:51:45.480]   I did.
[01:51:45.480 --> 01:51:48.280]   But it's even if it goes out on RSS.
[01:51:48.280 --> 01:51:50.200]   Even if it's already out there.
[01:51:50.200 --> 01:51:51.760]   You can put an edit tag on there.
[01:51:51.760 --> 01:51:53.360]   You know, we have chat room does.
[01:51:53.360 --> 01:51:54.760]   Well, no, because they can't pull it back.
[01:51:54.760 --> 01:51:55.760]   It's out there now.
[01:51:55.760 --> 01:51:56.760]   They can't control.
[01:51:56.760 --> 01:51:57.760]   So you can edit it.
[01:51:57.760 --> 01:52:00.840]   You'll think it's edited, but it's not edited on all those other places it went.
[01:52:00.840 --> 01:52:02.480]   Oh, and now I'll see what you're saying.
[01:52:02.480 --> 01:52:03.480]   Yeah.
[01:52:03.480 --> 01:52:04.480]   Okay.
[01:52:04.480 --> 01:52:07.640]   So what Mastodon does, which is the Twitter clone that we use, Twitter.social if you
[01:52:07.640 --> 01:52:12.680]   want to join our Mastodon instance, is if you say I want to edit it, it says you can
[01:52:12.680 --> 01:52:16.200]   delete it and post a copy.
[01:52:16.200 --> 01:52:17.280]   And we will honor that.
[01:52:17.280 --> 01:52:19.040]   So you say delete an edit.
[01:52:19.040 --> 01:52:21.360]   That's a Twitter.social Mastodon if you want to join it.
[01:52:21.360 --> 01:52:22.360]   That's social.
[01:52:22.360 --> 01:52:26.200]   So actually, you know, great about the Twitter compliance feed.
[01:52:26.200 --> 01:52:27.360]   No, what's that?
[01:52:27.360 --> 01:52:30.480]   I just heard about this today that evidently when Twitter takes something down for some
[01:52:30.480 --> 01:52:35.160]   kind of legal reason, they send out a feed to those who still have mechanisms to run
[01:52:35.160 --> 01:52:38.920]   Twitter saying you must kill this.
[01:52:38.920 --> 01:52:40.160]   So they could have sent out a feed.
[01:52:40.160 --> 01:52:41.560]   This is, you know, you've got to add to it.
[01:52:41.560 --> 01:52:46.400]   I never wanted them to allow somebody to change a tweet and not have evidence about.
[01:52:46.400 --> 01:52:49.440]   All I wanted to do was to say the full original tweet is fine.
[01:52:49.440 --> 01:52:53.080]   Let me add on to it to say here's the mistake and it goes with it.
[01:52:53.080 --> 01:52:54.080]   That's a line we're wanted.
[01:52:54.080 --> 01:52:59.520]   I think I mentioned this to Jack personally two years ago and evidently what the story
[01:52:59.520 --> 01:53:05.120]   says is basically they've been, there's a queen to Americanism, green effing us all
[01:53:05.120 --> 01:53:06.120]   along.
[01:53:06.120 --> 01:53:07.120]   Oh, yeah, yeah, okay.
[01:53:07.120 --> 01:53:08.120]   We're thinking about that.
[01:53:08.120 --> 01:53:10.040]   We're trying to, they never intended it.
[01:53:10.040 --> 01:53:15.160]   Honestly, it might be easier now, but when there were lots of third party apps, that was
[01:53:15.160 --> 01:53:16.160]   hard.
[01:53:16.160 --> 01:53:18.960]   The issue is you can't guarantee that everybody's seeing the edit.
[01:53:18.960 --> 01:53:19.960]   All right.
[01:53:19.960 --> 01:53:21.560]   So misrepresents it to you.
[01:53:21.560 --> 01:53:26.520]   You see it on Twitter, but you don't know who's seeing the edited version that other
[01:53:26.520 --> 01:53:27.520]   versions gone out.
[01:53:27.520 --> 01:53:28.520]   It's out there.
[01:53:28.520 --> 01:53:29.520]   It's in the world now.
[01:53:29.520 --> 01:53:34.720]   You can't show something else like live TV, which is their argument that the case.
[01:53:34.720 --> 01:53:36.920]   It's a SMS.
[01:53:36.920 --> 01:53:39.760]   I think they turned that off after check out.
[01:53:39.760 --> 01:53:40.760]   Okay, sorry.
[01:53:40.760 --> 01:53:41.760]   I was like, wait a second.
[01:53:41.760 --> 01:53:43.600]   Is that still a thing they can have it?
[01:53:43.600 --> 01:53:44.600]   No, Jack got hacked.
[01:53:44.600 --> 01:53:48.800]   By the way, great bit on security now this week yesterday.
[01:53:48.800 --> 01:53:51.560]   Steve Gibson talked about a report.
[01:53:51.560 --> 01:53:59.080]   I think Princeton did it where they got prepaid accounts with all the major phone companies.
[01:53:59.080 --> 01:54:03.000]   And they showed how easy it was to Simjack any of these accounts because the customer
[01:54:03.000 --> 01:54:05.440]   service reps really did not.
[01:54:05.440 --> 01:54:07.400]   You could say, well, I don't remember my pin.
[01:54:07.400 --> 01:54:10.840]   Oh, well, do you know?
[01:54:10.840 --> 01:54:12.200]   Tell me two calls you made recently.
[01:54:12.200 --> 01:54:14.360]   I don't know that.
[01:54:14.360 --> 01:54:15.960]   Tell me two calls that came in recently.
[01:54:15.960 --> 01:54:18.000]   Oh, I do know that because I placed them.
[01:54:18.000 --> 01:54:19.000]   Right.
[01:54:19.000 --> 01:54:20.000]   And then you have the Simjack.
[01:54:20.000 --> 01:54:25.280]   So Sims and cell phone numbers are a terrible way to authenticate.
[01:54:25.280 --> 01:54:29.000]   This is a great story and listen to security now because he talks about this and shows
[01:54:29.000 --> 01:54:30.760]   the whole process.
[01:54:30.760 --> 01:54:34.080]   But the point being that's how Jack Dorsey got hacked because they did have a way to
[01:54:34.080 --> 01:54:36.560]   tweet without authentication.
[01:54:36.560 --> 01:54:38.600]   Because it's from your number, it must be you.
[01:54:38.600 --> 01:54:42.560]   Except it's not like customer service people are paid enough to care.
[01:54:42.560 --> 01:54:44.120]   No, their job is customer service.
[01:54:44.120 --> 01:54:45.120]   People care.
[01:54:45.120 --> 01:54:46.640]   I think it's the other way around.
[01:54:46.640 --> 01:54:47.960]   They want to serve.
[01:54:47.960 --> 01:54:51.360]   And if they think you're the customer, they're going to do everything they can to get you
[01:54:51.360 --> 01:54:52.360]   that new Sim.
[01:54:52.360 --> 01:54:53.360]   I'll rephrase that.
[01:54:53.360 --> 01:54:56.880]   Care enough to do enough fact check to make sure you are who you are.
[01:54:56.880 --> 01:54:58.280]   They don't want to be mean.
[01:54:58.280 --> 01:54:59.280]   Right.
[01:54:59.280 --> 01:55:04.960]   Well, I'm going to tell you that I called Verizon and I had them now if anyone tries
[01:55:04.960 --> 01:55:11.080]   to get access to my phone or any of that, basically, if anyone tries to change my phone
[01:55:11.080 --> 01:55:16.400]   number, get access to my phone or my SIM information, they call me.
[01:55:16.400 --> 01:55:19.040]   So it's like, oh, that's a good idea.
[01:55:19.040 --> 01:55:20.600]   And I had to call them and ask for that.
[01:55:20.600 --> 01:55:23.600]   I don't think it's a service they provide, but I think they should offer it.
[01:55:23.600 --> 01:55:26.160]   You know, the only problem with that Stacy?
[01:55:26.160 --> 01:55:27.600]   What?
[01:55:27.600 --> 01:55:30.760]   If the number they're calling is the guy who's sim-jacking you.
[01:55:30.760 --> 01:55:31.760]   Mm.
[01:55:31.760 --> 01:55:34.280]   They're calling me on a different number.
[01:55:34.280 --> 01:55:35.280]   Yeah.
[01:55:35.280 --> 01:55:39.480]   So that's like the Google has that recovery email address, which is different than your
[01:55:39.480 --> 01:55:41.480]   Google voice or your fine number.
[01:55:41.480 --> 01:55:42.480]   That's what you need to do.
[01:55:42.480 --> 01:55:44.320]   You have to have a second number.
[01:55:44.320 --> 01:55:45.320]   And that's better.
[01:55:45.320 --> 01:55:49.120]   I mean, still conceivable that you could be some checked on that number.
[01:55:49.120 --> 01:55:50.120]   Well, yes.
[01:55:50.120 --> 01:55:51.120]   I mean, they're they're hot.
[01:55:51.120 --> 01:55:52.120]   But pins don't work.
[01:55:52.120 --> 01:55:53.360]   The point was pins don't work.
[01:55:53.360 --> 01:55:58.040]   In almost every case, these guys were able to say, it's one, two, three, four.
[01:55:58.040 --> 01:55:59.040]   No.
[01:55:59.040 --> 01:56:01.040]   Oh, my, I must have written it down wrong.
[01:56:01.040 --> 01:56:02.040]   Right.
[01:56:02.040 --> 01:56:03.040]   Oh, well, we have other ways you can authenticate.
[01:56:03.040 --> 01:56:05.040]   And of course, the other ways were increasingly weak.
[01:56:05.040 --> 01:56:06.040]   Yeah.
[01:56:06.040 --> 01:56:07.040]   At one point of--
[01:56:07.040 --> 01:56:11.040]   At one point, they were saying something like, what's your birthday?
[01:56:11.040 --> 01:56:15.480]   And you said, January 4th, no, you're getting warm.
[01:56:15.480 --> 01:56:16.480]   They literally--
[01:56:16.480 --> 01:56:17.480]   Wow.
[01:56:17.480 --> 01:56:18.480]   Literally.
[01:56:18.480 --> 01:56:21.920]   The customer service versus-- no, that's close.
[01:56:21.920 --> 01:56:23.920]   It's a little earlier.
[01:56:23.920 --> 01:56:24.920]   You got to listen to them.
[01:56:24.920 --> 01:56:25.920]   No, that's crazy.
[01:56:25.920 --> 01:56:31.360]   Well, but again, I don't think they're they're they're not trained to train enough hate enough
[01:56:31.360 --> 01:56:32.360]   to say, you know what?
[01:56:32.360 --> 01:56:33.360]   No, that's that's not cool.
[01:56:33.360 --> 01:56:36.360]   So what I'm going to do is I'm going to do a little bit of a little bit of a little bit
[01:56:36.360 --> 01:56:39.360]   So what else is Twitter's doing a bunch of stuff, let's see.
[01:56:39.360 --> 01:56:42.440]   Conversation participants.
[01:56:42.440 --> 01:56:46.600]   Screen compose, screen tool is coming this year.
[01:56:46.600 --> 01:56:48.080]   >> This is going to bug me.
[01:56:48.080 --> 01:56:51.380]   This is, this is trying to make Twitter kind of private and you can,
[01:56:51.380 --> 01:56:54.480]   there's all, it make, all kinds of levels.
[01:56:54.480 --> 01:56:57.560]   It happened to me for the first time yesterday I saw somebody respond to a tweet and I want to say,
[01:56:57.560 --> 01:57:02.620]   well this person restricts some of what some of who can see what this.
[01:57:02.620 --> 01:57:06.440]   You don't know who the person is, you don't know what was said.
[01:57:06.440 --> 01:57:11.020]   So now you can, you can have four options, global, which is everybody, a group,
[01:57:11.020 --> 01:57:17.420]   a panel which I think is people who are, you name in the tweet.
[01:57:17.420 --> 01:57:18.220]   >> Yeah.
[01:57:18.220 --> 01:57:22.020]   >> And then statement is for everybody.
[01:57:22.020 --> 01:57:23.220]   >> Nobody can respond.
[01:57:23.220 --> 01:57:25.620]   >> So where, you post a tweet but you can't get any replies.
[01:57:25.620 --> 01:57:30.100]   >> It's like a, it's like a presidential press conference.
[01:57:30.100 --> 01:57:31.020]   >> That's perfect for Twitter.
[01:57:31.020 --> 01:57:31.500]   >> It's just right.
[01:57:31.500 --> 01:57:34.460]   >> Well yeah, I mean, wait until Trump discovers that one.
[01:57:34.460 --> 01:57:35.060]   >> Right.
[01:57:35.060 --> 01:57:38.020]   Well he should be using that one.
[01:57:38.020 --> 01:57:40.220]   Why does he need replies?
[01:57:40.220 --> 01:57:42.540]   Actually, probably he's not allowed to, right?
[01:57:42.540 --> 01:57:45.580]   He has to, he can't block replies.
[01:57:45.580 --> 01:57:46.820]   >> Well now it's just a feature.
[01:57:46.820 --> 01:57:48.500]   He's not blocking them.
[01:57:48.500 --> 01:57:51.380]   >> Roy and I just put it up a statement instead of a tweet.
[01:57:51.380 --> 01:57:52.420]   >> Right, it's a statement.
[01:57:52.420 --> 01:57:54.820]   A statement thing from the Oval Office.
[01:57:54.820 --> 01:58:01.100]   >> Roy and I in the chat says it reminds them of the, him or her, of the Google+ circles
[01:58:01.100 --> 01:58:02.100]   back in the days.
[01:58:02.100 --> 01:58:03.100]   >> Yeah.
[01:58:03.100 --> 01:58:04.860]   >> And we have that on Twitch social by the way.
[01:58:04.860 --> 01:58:07.500]   You can make a toot, that's what we call them.
[01:58:07.500 --> 01:58:08.500]   >> On past and on.
[01:58:08.500 --> 01:58:14.460]   >> You can make a toot that's public, private, friends, you can fart in any direction you
[01:58:14.460 --> 01:58:15.460]   want.
[01:58:15.460 --> 01:58:16.460]   >> Mm-hm.
[01:58:16.460 --> 01:58:19.460]   >> Twitter is also considering tipping.
[01:58:19.460 --> 01:58:22.180]   This is according to Yahoo Finance, I don't know.
[01:58:22.180 --> 01:58:25.180]   Are they, are they, are they, are they, are they, are they, are they, are they, are they
[01:58:25.180 --> 01:58:26.540]   the infirm, oh no, it's not.
[01:58:26.540 --> 01:58:28.300]   It's the information we got to give credit then.
[01:58:28.300 --> 01:58:31.060]   This is a good source.
[01:58:31.060 --> 01:58:32.660]   You actually have the account, I don't.
[01:58:32.660 --> 01:58:34.100]   >> Yeah, I paid for it.
[01:58:34.100 --> 01:58:40.300]   So see, apparently one of the things, the information, this is a leak, Twitter has not
[01:58:40.300 --> 01:58:41.300]   announced this.
[01:58:41.300 --> 01:58:44.580]   But one of the things they're talking about is tipping.
[01:58:44.580 --> 01:58:46.540]   What about Twitter banning political ads?
[01:58:46.540 --> 01:58:48.860]   Was that not an appropriate solution?
[01:58:48.860 --> 01:58:53.660]   >> I argued that it was, that both Facebook and Twitter were wrong.
[01:58:53.660 --> 01:58:58.260]   And the reason I'm against what Twitter did is once again, it cuts off new candidates
[01:58:58.260 --> 01:59:04.500]   and new movements from an efficient mechanism of advertising and forces them back on a
[01:59:04.500 --> 01:59:10.820]   television where Tom Steyer and Mike Bloomberg and Donald Trump all win.
[01:59:10.820 --> 01:59:14.740]   >> The information says Twitter is considering a feature that will allow users to tip, send
[01:59:14.740 --> 01:59:17.260]   each other money from the tweets.
[01:59:17.260 --> 01:59:20.940]   According to two people familiar with the company's decisions, it couldn't be learned
[01:59:20.940 --> 01:59:25.940]   when the tipping feature will debut or whether microtransactions play.
[01:59:25.940 --> 01:59:30.060]   We'll see Twitter linking up with Dorsey's other company's Square.
[01:59:30.060 --> 01:59:32.740]   A Twitter spokesperson said the company explores lots of ideas.
[01:59:32.740 --> 01:59:34.900]   It wasn't currently developing a tipping feature.
[01:59:34.900 --> 01:59:37.260]   They denied it in other words.
[01:59:37.260 --> 01:59:38.740]   >> Is it sort of other way to be pissed?
[01:59:38.740 --> 01:59:41.340]   >> Sending money from Twitter is completely reasonable.
[01:59:41.340 --> 01:59:42.700]   You can send money at Facebook Messenger.
[01:59:42.700 --> 01:59:44.300]   You can send money in Apple's Messenger.
[01:59:44.300 --> 01:59:45.300]   I don't see any reason.
[01:59:45.300 --> 01:59:46.660]   >> It's a Chinese thing, you know.
[01:59:46.660 --> 01:59:47.660]   >> Yeah.
[01:59:47.660 --> 01:59:48.660]   >> Why wouldn't this be an obvious pivot for them?
[01:59:48.660 --> 01:59:49.660]   >> Yeah.
[01:59:49.660 --> 01:59:52.420]   >> Maybe then I could drop all the advertising and you could just send me money.
[01:59:52.420 --> 01:59:54.420]   >> Means you've got to go back on Twitter.
[01:59:54.420 --> 01:59:55.420]   >> That's why we had it.
[01:59:55.420 --> 01:59:57.420]   >> That's what they do.
[01:59:57.420 --> 01:59:58.420]   >> Yeah.
[01:59:58.420 --> 01:59:59.420]   >> Twitter was like, "WeChat."
[01:59:59.420 --> 02:00:00.420]   >> WeChat.
[02:00:00.420 --> 02:00:01.420]   >> WeChat.
[02:00:01.420 --> 02:00:02.420]   >> They allowed paying and boom.
[02:00:02.420 --> 02:00:03.420]   >> Boom.
[02:00:03.420 --> 02:00:04.420]   >> Boom.
[02:00:04.420 --> 02:00:05.420]   >> Off.
[02:00:05.420 --> 02:00:06.420]   Off.
[02:00:06.420 --> 02:00:10.020]   >> So literally we discussed this while you were gone, but the Indefensive Twitter line there
[02:00:10.020 --> 02:00:16.340]   is a really good, I think, because I read with it, op-ed in The New York Times by a
[02:00:16.340 --> 02:00:17.820]   university professor.
[02:00:17.820 --> 02:00:18.820]   >> I read that.
[02:00:18.820 --> 02:00:19.820]   >> I did like that.
[02:00:19.820 --> 02:00:23.420]   >> And so she has a book coming out, which we might want to just mention.
[02:00:23.420 --> 02:00:24.420]   >> Called.
[02:00:24.420 --> 02:00:26.220]   I'm so never going to forget the name of it.
[02:00:26.220 --> 02:00:28.980]   >> Sarah Jackson is a professor at Penn.
[02:00:28.980 --> 02:00:34.140]   #activismnetworks of race and gender justice.
[02:00:34.140 --> 02:00:39.260]   Her point is that lots of marginalized groups got a voice on Twitter, like Black Twitter,
[02:00:39.260 --> 02:00:41.820]   which is actually the best Twitter of all.
[02:00:41.820 --> 02:00:43.540]   >> I've heard that.
[02:00:43.540 --> 02:00:44.540]   >> Yeah.
[02:00:44.540 --> 02:00:45.540]   You probably don't follow them.
[02:00:45.540 --> 02:00:46.540]   >> No, but I've heard that.
[02:00:46.540 --> 02:00:47.740]   >> Andrea Langston gave me.
[02:00:47.740 --> 02:00:50.300]   I asked on Twitter, "Well, who should I follow?"
[02:00:50.300 --> 02:00:51.460]   She gave me a whole bunch of people.
[02:00:51.460 --> 02:00:53.260]   I should follow on Twitter.
[02:00:53.260 --> 02:00:56.900]   And it definitely adds flavor to the Twitter feed.
[02:00:56.900 --> 02:00:57.900]   I like it.
[02:00:57.900 --> 02:00:58.900]   >> No pun intended.
[02:00:58.900 --> 02:00:59.900]   >> Yeah.
[02:00:59.900 --> 02:01:00.900]   A little chocolate in my Twitter feed.
[02:01:00.900 --> 02:01:05.900]   No, but that's the point is that there are different disenfranchised groups who suddenly
[02:01:05.900 --> 02:01:06.900]   have a voice.
[02:01:06.900 --> 02:01:08.420]   And I think that's absolutely true.
[02:01:08.420 --> 02:01:14.380]   Nobody says, even Leo, when he says Twitter is a dumpster fire, I don't mean to say that
[02:01:14.380 --> 02:01:16.100]   there isn't some value in it at all.
[02:01:16.100 --> 02:01:17.420]   There's huge value in it.
[02:01:17.420 --> 02:01:20.220]   >> Yeah, we've already talked about it several times.
[02:01:20.220 --> 02:01:21.900]   We've argued about it several times.
[02:01:21.900 --> 02:01:22.900]   >> That's value in it.
[02:01:22.900 --> 02:01:27.860]   The question is whether it's worth sending your eyebrows on the dumpster fire.
[02:01:27.860 --> 02:01:35.140]   >> It's a position of privilege for us who have these megaphones to say that others shouldn't.
[02:01:35.140 --> 02:01:36.140]   >> Mm-hmm.
[02:01:36.140 --> 02:01:38.140]   >> Oh, you're right.
[02:01:38.140 --> 02:01:39.140]   All right.
[02:01:39.140 --> 02:01:43.900]   She mentions, Jackson mentions the hashtag justice for Trayvon.
[02:01:43.900 --> 02:01:46.900]   The hashtag #BlackLivesMatter probably wouldn't exist without Twitter.
[02:01:46.900 --> 02:01:47.900]   >> Right.
[02:01:47.900 --> 02:01:48.900]   Oscar is so white.
[02:01:48.900 --> 02:01:49.900]   >> Me too.
[02:01:49.900 --> 02:01:50.900]   Oscar is so white.
[02:01:50.900 --> 02:01:51.900]   >> They're on and on.
[02:01:51.900 --> 02:01:52.900]   They're alive.
[02:01:52.900 --> 02:01:55.540]   >> My favorite is looking while black, where I have learned things that I should have known.
[02:01:55.540 --> 02:01:58.340]   There's a case from people's lives that I did not know.
[02:01:58.340 --> 02:02:05.140]   >> How about hashtag #YIStayed, which gave women in abusive relationships a chance to
[02:02:05.140 --> 02:02:06.340]   talk about that.
[02:02:06.340 --> 02:02:07.980]   That's heavy duty.
[02:02:07.980 --> 02:02:12.100]   But Twitter in its anonymity, it's kind of spontaneity really becomes a good place for
[02:02:12.100 --> 02:02:16.260]   conversations like that.
[02:02:16.260 --> 02:02:17.260]   You okay?
[02:02:17.260 --> 02:02:20.820]   >> Antimone, Antimone, if I ask you something personal, then please say if you do.
[02:02:20.820 --> 02:02:21.820]   >> Sure, go ahead.
[02:02:21.820 --> 02:02:23.740]   >> I don't guarantee an answer.
[02:02:23.740 --> 02:02:24.740]   >> Do you ever wear a hood?
[02:02:24.740 --> 02:02:25.740]   >> No, you shouldn't.
[02:02:25.740 --> 02:02:26.740]   >> Late at night.
[02:02:26.740 --> 02:02:28.060]   >> You shouldn't talk around peddling too much.
[02:02:28.060 --> 02:02:32.540]   I'm asking the updated question of whether you have the talk with your sons.
[02:02:32.540 --> 02:02:33.540]   >> Oh, God.
[02:02:33.540 --> 02:02:34.540]   >> Okay.
[02:02:34.540 --> 02:02:40.300]   >> And then whether you have it in social media.
[02:02:40.300 --> 02:02:46.340]   >> Any talks with the boys are always just between us and four walls.
[02:02:46.340 --> 02:02:47.340]   >> Okay.
[02:02:47.340 --> 02:02:52.860]   >> And as far as them being online, they have private accounts.
[02:02:52.860 --> 02:02:56.700]   But I only hide Queen Pruitt for the most part.
[02:02:56.700 --> 02:02:58.540]   I don't hide the boys because they're athletes.
[02:02:58.540 --> 02:02:59.540]   Because they're athletes.
[02:02:59.540 --> 02:03:00.540]   >> They're already public.
[02:03:00.540 --> 02:03:01.540]   >> And the public.
[02:03:01.540 --> 02:03:03.740]   >> They're going to be the public eye.
[02:03:03.740 --> 02:03:06.220]   >> So they've got to understand how to maneuver it.
[02:03:06.220 --> 02:03:07.460]   >> They're also really good looking.
[02:03:07.460 --> 02:03:08.460]   >> Right.
[02:03:08.460 --> 02:03:12.380]   And they've learned how to watch for this and watch for that and to look out for predators
[02:03:12.380 --> 02:03:14.300]   and things of that nature.
[02:03:14.300 --> 02:03:19.180]   >> Every now and then I had to tell them to stop putting locations down.
[02:03:19.180 --> 02:03:20.180]   But they've learned.
[02:03:20.180 --> 02:03:22.020]   >> Oh, Doc Stacey and your daughter.
[02:03:22.020 --> 02:03:26.140]   >> Oh, as your daughter has been very open about talking about what he tells his daughter
[02:03:26.140 --> 02:03:28.100]   about being black.
[02:03:28.100 --> 02:03:32.700]   Because, oh, doctor lives, it drives a fancy car in a fancy neighborhood and gets pulled
[02:03:32.700 --> 02:03:36.220]   over weekly for driving while black.
[02:03:36.220 --> 02:03:40.380]   And he is very open with her about, well, you've got to understand racism and you've
[02:03:40.380 --> 02:03:41.580]   got to understand what's going on.
[02:03:41.580 --> 02:03:48.100]   >> We've had those conversations prior to coming to California and that was part of the discussion
[02:03:48.100 --> 02:03:49.780]   of deciding to come to California.
[02:03:49.780 --> 02:03:55.780]   It's like it's going to be different because some things we're not going to see right here.
[02:03:55.780 --> 02:03:59.380]   Not to say that it doesn't exist, but it's a pretty strong chance.
[02:03:59.380 --> 02:04:02.380]   >> It's a different kind of racism.
[02:04:02.380 --> 02:04:03.380]   >> Right, you know.
[02:04:03.380 --> 02:04:08.540]   But I mean, if I had a teen, if our black and black son, a teenager, and after Trayvon,
[02:04:08.540 --> 02:04:12.500]   I would tell him, I don't know what I would tell him.
[02:04:12.500 --> 02:04:13.980]   I would say I'm sorry.
[02:04:13.980 --> 02:04:14.980]   >> I told my boys.
[02:04:14.980 --> 02:04:15.980]   >> I told my boys.
[02:04:15.980 --> 02:04:21.420]   >> Taniac coats incredible book, which was written for his son is the conversation.
[02:04:21.420 --> 02:04:22.780]   >> That's a letter to his son.
[02:04:22.780 --> 02:04:23.780]   >> Letter to his son.
[02:04:23.780 --> 02:04:26.460]   It breaks your heart.
[02:04:26.460 --> 02:04:32.620]   >> My boys have dread lots and whatever those hairstyles are called.
[02:04:32.620 --> 02:04:33.620]   I don't know.
[02:04:33.620 --> 02:04:34.620]   I don't have it here.
[02:04:34.620 --> 02:04:35.620]   >> You're jealous.
[02:04:35.620 --> 02:04:42.020]   >> But that was part of our conversation a couple of years back was you're going to
[02:04:42.020 --> 02:04:46.140]   be judged just because of how your hair looks, just period.
[02:04:46.140 --> 02:04:49.260]   It's not fair, but that's just the reality of it.
[02:04:49.260 --> 02:04:51.300]   And we've worked through that and we've been fine.
[02:04:51.300 --> 02:04:52.300]   We've moved on.
[02:04:52.300 --> 02:04:55.260]   Because they know that you offer more than just their haircuts.
[02:04:55.260 --> 02:04:56.260]   >> Yep.
[02:04:56.260 --> 02:05:00.980]   One of my students in social journalism is her community, we have a student pixel community,
[02:05:00.980 --> 02:05:04.460]   and her community is people who keep their hair natural.
[02:05:04.460 --> 02:05:07.900]   And the discussions about how people change their hair to get a job interview, what happens
[02:05:07.900 --> 02:05:10.620]   to them work, all of that.
[02:05:10.620 --> 02:05:15.420]   What's interesting to me and Stacey, I'm curious from you too, as your daughter gets
[02:05:15.420 --> 02:05:23.660]   to the age where she can be on social media, what are you telling her these days?
[02:05:23.660 --> 02:05:26.100]   >> She doesn't want to be on social media.
[02:05:26.100 --> 02:05:31.100]   She looks at it as not, I mean, she lurks.
[02:05:31.100 --> 02:05:33.980]   She wants to be on, she calls it, "pintrest."
[02:05:33.980 --> 02:05:37.340]   She wants to be on, "pintrest."
[02:05:37.340 --> 02:05:39.260]   She has a lot of friends on Instagram.
[02:05:39.260 --> 02:05:41.300]   She sees things on Instagram.
[02:05:41.300 --> 02:05:45.740]   She, I don't know if she has, she doesn't have her own account, but she does look at
[02:05:45.740 --> 02:05:49.260]   other people sometimes.
[02:05:49.260 --> 02:05:52.940]   She's not interested in putting herself on Instagram.
[02:05:52.940 --> 02:05:57.540]   And I think part of that is a result of me being hesitant to put her online anywhere and
[02:05:57.540 --> 02:06:03.500]   talking about that with her.
[02:06:03.500 --> 02:06:06.860]   I don't know.
[02:06:06.860 --> 02:06:09.300]   So right now it's not something I have to deal with.
[02:06:09.300 --> 02:06:12.060]   I did let her have an account on Pinterest.
[02:06:12.060 --> 02:06:15.220]   And she knows her school has had a curriculum around it.
[02:06:15.220 --> 02:06:17.380]   I think this is where her high school did.
[02:06:17.380 --> 02:06:21.700]   Yeah, her school did a lot for her in a way that I don't think.
[02:06:21.700 --> 02:06:23.620]   >> Yeah, most try to just ignore it, act like a good.
[02:06:23.620 --> 02:06:25.140]   >> No, I think that's starting to change.
[02:06:25.140 --> 02:06:26.140]   >> You're always it.
[02:06:26.140 --> 02:06:27.140]   >> Yeah.
[02:06:27.140 --> 02:06:32.780]   >> We didn't have it in North Carolina prior to getting over here, but we did have the
[02:06:32.780 --> 02:06:35.940]   discussion about the mental health side of it.
[02:06:35.940 --> 02:06:41.940]   And I had to have that talk with my boys to say, look, I know you guys enjoy showing this
[02:06:41.940 --> 02:06:46.460]   and that to your friends on social media, but I want you to sort of be cognizant and
[02:06:46.460 --> 02:06:49.540]   not be braggadocious on social media.
[02:06:49.540 --> 02:06:50.540]   >> Right.
[02:06:50.540 --> 02:06:54.260]   >> Because you don't know how that's affecting people because like you said, they're good
[02:06:54.260 --> 02:06:55.260]   looking kids.
[02:06:55.260 --> 02:06:58.660]   They got my jeans, they'll go on that.
[02:06:58.660 --> 02:06:59.660]   But they're talented.
[02:06:59.660 --> 02:07:01.860]   >> I was gonna say look a lot more like Queen Prue.
[02:07:01.860 --> 02:07:02.860]   >> Watch it.
[02:07:02.860 --> 02:07:08.620]   >> But they have personality and charisma and they do really well in school.
[02:07:08.620 --> 02:07:11.180]   They do really well with their athletics and so.
[02:07:11.180 --> 02:07:12.180]   >> They're superstars.
[02:07:12.180 --> 02:07:13.180]   You can tell.
[02:07:13.180 --> 02:07:17.420]   >> So every now and then they could come off as braggy, but I have to tell them, look,
[02:07:17.420 --> 02:07:18.500]   tone it down just a touch.
[02:07:18.500 --> 02:07:20.940]   I know you just whooped that dude and track, but.
[02:07:20.940 --> 02:07:22.820]   >> You know, though, they have that Southern humility.
[02:07:22.820 --> 02:07:25.620]   They say, sir and ma'am, they're actually really good.
[02:07:25.620 --> 02:07:27.820]   You don't know how good you're kids.
[02:07:27.820 --> 02:07:32.980]   >> They are really well behaved and well brought up kids.
[02:07:32.980 --> 02:07:35.820]   This is the book and I listened to it on Audible.
[02:07:35.820 --> 02:07:38.820]   Tane, easy coats between the world and me.
[02:07:38.820 --> 02:07:40.980]   And I was in tears through much of it.
[02:07:40.980 --> 02:07:45.660]   >> I recommend getting the Audible because it's so powerful.
[02:07:45.660 --> 02:07:47.980]   And it is, it's what he would tell his son.
[02:07:47.980 --> 02:07:49.940]   And he's, you know, the world is not fair.
[02:07:49.940 --> 02:07:53.540]   And this is the world you're growing up in and you need to know about this.
[02:07:53.540 --> 02:07:54.980]   >> Between the world and me.
[02:07:54.980 --> 02:07:56.740]   >> Oh, yeah.
[02:07:56.740 --> 02:07:58.460]   >> I'd be actually really curious what you think of it.
[02:07:58.460 --> 02:07:59.460]   >> Yeah.
[02:07:59.460 --> 02:08:00.460]   >> I have to go right now.
[02:08:00.460 --> 02:08:01.460]   >> What's your experience?
[02:08:01.460 --> 02:08:06.100]   >> Let's take a little break and Stacy's going to get to go home in a minute.
[02:08:06.100 --> 02:08:07.260]   >> I have a home.
[02:08:07.260 --> 02:08:09.380]   >> You want to build a snowman out there?
[02:08:09.380 --> 02:08:13.100]   >> There's, I was like, we built a snowman, we built a snow four.
[02:08:13.100 --> 02:08:14.340]   It's been snowing for three days.
[02:08:14.340 --> 02:08:16.700]   >> How many inches did you get?
[02:08:16.700 --> 02:08:19.700]   >> Like six, seven.
[02:08:19.700 --> 02:08:21.260]   >> Oh, three days.
[02:08:21.260 --> 02:08:22.980]   It's been snowing.
[02:08:22.980 --> 02:08:23.980]   >> I mean, yeah.
[02:08:23.980 --> 02:08:24.980]   >> It's kind of jealous.
[02:08:24.980 --> 02:08:25.980]   I love snow.
[02:08:25.980 --> 02:08:26.980]   >> Nope.
[02:08:26.980 --> 02:08:29.740]   >> Hey, you want me to show you the snowboard?
[02:08:29.740 --> 02:08:31.900]   >> Does King Hickenbotham do the shoveling?
[02:08:31.900 --> 02:08:34.100]   >> What do you call it, Queen?
[02:08:34.100 --> 02:08:35.100]   >> It's true.
[02:08:35.100 --> 02:08:36.700]   We got to call him King Hickenbotham.
[02:08:36.700 --> 02:08:38.860]   >> I'm not going to call him King Hickenbotham.
[02:08:38.860 --> 02:08:42.020]   >> I'll call him a Prince.
[02:08:42.020 --> 02:08:43.500]   >> Prince Hickenbotham.
[02:08:43.500 --> 02:08:44.500]   That's even better.
[02:08:44.500 --> 02:08:45.500]   >> That's as much as...
[02:08:45.500 --> 02:08:46.500]   >> That sounds pretty good.
[02:08:46.500 --> 02:08:47.500]   Prince Andrew.
[02:08:47.500 --> 02:08:48.500]   Oh, no, actually, sorry.
[02:08:48.500 --> 02:08:49.500]   >> That's not good.
[02:08:49.500 --> 02:08:50.500]   >> No.
[02:08:50.500 --> 02:08:51.500]   >> Never mind.
[02:08:51.500 --> 02:08:52.500]   >> Never mind.
[02:08:52.500 --> 02:08:53.500]   >> Never mind.
[02:08:53.500 --> 02:08:54.500]   >> He's not that guy.
[02:08:54.500 --> 02:08:55.500]   >> Never mind guy.
[02:08:55.500 --> 02:08:56.500]   Yeah.
[02:08:56.500 --> 02:08:59.700]   No, Andrew can be Andrew because he's online in a consent.
[02:08:59.700 --> 02:09:00.700]   >> He's public.
[02:09:00.700 --> 02:09:01.700]   >> Yeah.
[02:09:01.700 --> 02:09:02.700]   >> He's public.
[02:09:02.700 --> 02:09:03.700]   >> Yeah.
[02:09:03.700 --> 02:09:04.700]   >> He's been on the show.
[02:09:04.700 --> 02:09:05.700]   >> Right.
[02:09:05.700 --> 02:09:06.700]   Yeah, he had a segment, right?
[02:09:06.700 --> 02:09:07.700]   >> Yeah.
[02:09:07.700 --> 02:09:08.700]   >> Yeah.
[02:09:08.700 --> 02:09:12.060]   Although I realized, you know, and I do so much to not show my daughter online, but this
[02:09:12.060 --> 02:09:17.260]   whole time in my office, there are pictures of her on my little bulletin board behind
[02:09:17.260 --> 02:09:18.260]   me.
[02:09:18.260 --> 02:09:19.260]   >> Oh, we can't make those out.
[02:09:19.260 --> 02:09:20.260]   >> Yeah.
[02:09:20.260 --> 02:09:22.740]   >> She is too in them, so I don't feel so bad.
[02:09:22.740 --> 02:09:23.740]   >> I'm so good about that, good.
[02:09:23.740 --> 02:09:27.060]   But I'm like, oh, this whole time I have not been.
[02:09:27.060 --> 02:09:31.780]   >> It's not my grapple with all the time because from the moment my kids were born,
[02:09:31.780 --> 02:09:33.580]   I was on TV and then doing this.
[02:09:33.580 --> 02:09:37.420]   And I have a bad habit of talking about my family.
[02:09:37.420 --> 02:09:38.420]   And they don't like it.
[02:09:38.420 --> 02:09:39.420]   One cotton-picking bit.
[02:09:39.420 --> 02:09:40.420]   >> None of them.
[02:09:40.420 --> 02:09:41.420]   None of them.
[02:09:41.420 --> 02:09:45.860]   >> Well, the kids actually don't seem to mind that much.
[02:09:45.860 --> 02:09:51.220]   But none of my wives have enjoyed it.
[02:09:51.220 --> 02:09:53.420]   My family has been indifferent about it.
[02:09:53.420 --> 02:09:55.580]   Yeah, whatever.
[02:09:55.580 --> 02:09:59.780]   >> The good thing is, I mean, in this environment, it's not like you're exposed.
[02:09:59.780 --> 02:10:01.980]   It's not like I'm on national TV or anything.
[02:10:01.980 --> 02:10:06.300]   But still, it isn't something that they agreed to or bought into.
[02:10:06.300 --> 02:10:07.740]   This is my life, not their life.
[02:10:07.740 --> 02:10:11.220]   So I kind of feel I should have done that better.
[02:10:11.220 --> 02:10:13.500]   Oh, well, too late now.
[02:10:13.500 --> 02:10:15.260]   >> There's so much on that list, man.
[02:10:15.260 --> 02:10:16.260]   So much.
[02:10:16.260 --> 02:10:20.300]   >> Well, people said this along with the older you get, the longer it gets.
[02:10:20.300 --> 02:10:23.020]   >> People just called me.
[02:10:23.020 --> 02:10:24.500]   I don't know if she's listening.
[02:10:24.500 --> 02:10:26.220]   I'm not talking about you, Abby.
[02:10:26.220 --> 02:10:27.220]   Go ahead, Stacy.
[02:10:27.220 --> 02:10:28.220]   You do it.
[02:10:28.220 --> 02:10:29.220]   >> Oh, no.
[02:10:29.220 --> 02:10:30.220]   I was going to...
[02:10:30.220 --> 02:10:35.420]   >> The people who started blogging in like 2004, 2000.
[02:10:35.420 --> 02:10:37.740]   My daughter was born in 2006.
[02:10:37.740 --> 02:10:42.940]   And so that whole time period, everyone was putting their kids and everything online.
[02:10:42.940 --> 02:10:43.940]   >> I think of dudes.
[02:10:43.940 --> 02:10:44.940]   >> Yeah.
[02:10:44.940 --> 02:10:45.940]   >> Yeah.
[02:10:45.940 --> 02:10:50.940]   And it was kind of normalized, but around when she was two, I kind of got the heebie
[02:10:50.940 --> 02:10:54.780]   jeebies about it and we stopped.
[02:10:54.780 --> 02:10:56.780]   And it was weird for a long time.
[02:10:56.780 --> 02:11:01.620]   Only in the last probably four years has it been okay.
[02:11:01.620 --> 02:11:05.900]   And we still, like, I mean, her schools in camps always ask for permission to photograph
[02:11:05.900 --> 02:11:09.020]   her and I'm always telling them no.
[02:11:09.020 --> 02:11:11.460]   So and I know we look like crazy people.
[02:11:11.460 --> 02:11:12.460]   They're like, what the heck?
[02:11:12.460 --> 02:11:14.660]   >> No, you don't look like crazy people.
[02:11:14.660 --> 02:11:15.660]   You don't.
[02:11:15.660 --> 02:11:19.900]   They're reminding me that I let Abby do a podcast on the network when she was in high
[02:11:19.900 --> 02:11:20.900]   school.
[02:11:20.900 --> 02:11:24.060]   So I guess she did sign up for it, actually.
[02:11:24.060 --> 02:11:26.340]   >> Well, and my daughter has come on the show.
[02:11:26.340 --> 02:11:31.220]   Like my show, she comes on once a year usually to talk.
[02:11:31.220 --> 02:11:32.220]   But again, that's...
[02:11:32.220 --> 02:11:33.220]   >> That's audio only.
[02:11:33.220 --> 02:11:34.740]   It's a little different.
[02:11:34.740 --> 02:11:35.700]   >> It's audio only.
[02:11:35.700 --> 02:11:39.100]   She is, you know, it's a...
[02:11:39.100 --> 02:11:44.620]   She's getting a chance to put on her professional face, as it were, or her in the world face.
[02:11:44.620 --> 02:11:48.500]   That I don't think kids are really aware of until...
[02:11:48.500 --> 02:11:50.460]   >> No, you're lucky to be able to give her that.
[02:11:50.460 --> 02:11:53.660]   I think that's a great, that's a good experience for her.
[02:11:53.660 --> 02:11:57.500]   Honestly, if it's in a safe environment, which it is.
[02:11:57.500 --> 02:11:59.700]   >> I'm screwing her up in other ways.
[02:11:59.700 --> 02:12:00.700]   [laughter]
[02:12:00.700 --> 02:12:07.100]   >> I showed it a brought to you by a tool you will use a lot.
[02:12:07.100 --> 02:12:08.620]   You got to sign up for Zapier.
[02:12:08.620 --> 02:12:09.620]   It is awesome.
[02:12:09.620 --> 02:12:12.340]   We use it all the time.
[02:12:12.340 --> 02:12:15.780]   Zapier allows you to...
[02:12:15.780 --> 02:12:16.980]   How can I describe it?
[02:12:16.980 --> 02:12:22.460]   You create zaps with your little applications that connect one thing to another.
[02:12:22.460 --> 02:12:25.260]   Your Gmail to a spreadsheet.
[02:12:25.260 --> 02:12:27.300]   Actually, we use a lot of the Google stuff.
[02:12:27.300 --> 02:12:34.260]   For instance, I have a Zapier that automatically, when I favorite an article in my newsreader,
[02:12:34.260 --> 02:12:39.660]   automatically bookmarks it on Pinboard, which is a bookmark website, which automatically
[02:12:39.660 --> 02:12:44.660]   sends it to a Google sheet in a precisely formatted way so that Carsten can then add
[02:12:44.660 --> 02:12:46.580]   it to the show rundowns.
[02:12:46.580 --> 02:12:47.580]   That's all done automatically.
[02:12:47.580 --> 02:12:50.940]   One of the things I love about Zapier is it has multi-step zaps.
[02:12:50.940 --> 02:12:53.400]   It also has all the integrations.
[02:12:53.400 --> 02:12:58.820]   Over 1,500 applications, software, lots of business integrations.
[02:12:58.820 --> 02:13:00.620]   In fact, it's really great.
[02:13:00.620 --> 02:13:04.580]   If you're in sales, for instance, you could just set it up so that the minute you get
[02:13:04.580 --> 02:13:09.500]   a lead, you engage them, you automatically import new customers, you notify your team
[02:13:09.500 --> 02:13:12.260]   about what you're doing, what your opportunities are.
[02:13:12.260 --> 02:13:14.620]   It works with Salesforce, with your CRM.
[02:13:14.620 --> 02:13:17.300]   It works with Spreadsheets.
[02:13:17.300 --> 02:13:22.620]   Because it supports multi-step zaps, I love that feature, you can have one trigger to
[02:13:22.620 --> 02:13:24.700]   a bunch of stuff.
[02:13:24.700 --> 02:13:26.860]   We use, you know, we're all in on Slack.
[02:13:26.860 --> 02:13:27.860]   It works with Slack.
[02:13:27.860 --> 02:13:28.860]   I mean, it was--
[02:13:28.860 --> 02:13:31.420]   It was last week during CES.
[02:13:31.420 --> 02:13:32.420]   Did you?
[02:13:32.420 --> 02:13:33.420]   I did.
[02:13:33.420 --> 02:13:38.180]   Whenever we had something go up on our YouTube channel, my Zapier account would grab that
[02:13:38.180 --> 02:13:43.820]   information for the YouTube, grab the thumbnail, and then send it on over to my buffer account
[02:13:43.820 --> 02:13:49.180]   so I could post it up to Twitter and to link then automatically because I couldn't keep
[02:13:49.180 --> 02:13:50.180]   up when--
[02:13:50.180 --> 02:13:52.100]   You know, I was wondering if you would do all this tweeting.
[02:13:52.100 --> 02:13:53.940]   I didn't understand how you did that.
[02:13:53.940 --> 02:13:54.940]   I should have known.
[02:13:54.940 --> 02:13:55.940]   Zapier, baby.
[02:13:55.940 --> 02:13:56.940]   Shit of--
[02:13:56.940 --> 02:13:57.940]   Known.
[02:13:57.940 --> 02:13:58.940]   It made me feel bad.
[02:13:58.940 --> 02:14:02.140]   I thought I answered out socially.
[02:14:02.140 --> 02:14:06.980]   C-A-P-I-E-R.com/twig.
[02:14:06.980 --> 02:14:08.180]   Connect the apps to use the most.
[02:14:08.180 --> 02:14:09.540]   Let Zapier take it for there.
[02:14:09.540 --> 02:14:11.020]   There is a free tier.
[02:14:11.020 --> 02:14:15.420]   I'm on a paid tier because I found a thousand ways to use it.
[02:14:15.420 --> 02:14:16.420]   It's amazing.
[02:14:16.420 --> 02:14:17.980]   In fact, you're inspiring me.
[02:14:17.980 --> 02:14:20.700]   There's ways-- that's the thing is you talk to people and there's other ways you can use
[02:14:20.700 --> 02:14:21.700]   it.
[02:14:21.700 --> 02:14:22.860]   It is not-- don't get scared.
[02:14:22.860 --> 02:14:23.860]   It's not programming.
[02:14:23.860 --> 02:14:27.140]   It's very simple step-by-step.
[02:14:27.140 --> 02:14:28.140]   Anybody could do this.
[02:14:28.140 --> 02:14:29.140]   In fact, lots of people do.
[02:14:29.140 --> 02:14:34.620]   Four and a half million people use Zapier and on average they save, get this 40 hours a
[02:14:34.620 --> 02:14:35.780]   month.
[02:14:35.780 --> 02:14:42.860]   That's a full work week free without any work on your part at zapier.com/twig.
[02:14:42.860 --> 02:14:47.060]   For business, personal-- I just love Zapier.
[02:14:47.060 --> 02:14:48.060]   You got to try it.
[02:14:48.060 --> 02:14:51.580]   Zapier, Z-A-P-I-E-R.com/twig.
[02:14:51.580 --> 02:14:54.140]   They've got a free 14-day trial up there for you.
[02:14:54.140 --> 02:14:56.140]   Zapier.com/twig.
[02:14:56.140 --> 02:14:57.140]   It's kind of fun.
[02:14:57.140 --> 02:14:59.380]   You've got to be hooked on it and then you start thinking about other things you can
[02:14:59.380 --> 02:15:01.540]   do and all sorts of stuff.
[02:15:01.540 --> 02:15:04.540]   I'm looking at those hue lights that they announced, the outdoor lights.
[02:15:04.540 --> 02:15:10.020]   Stacey, I want to set up a little extensive Zap that will do all sorts of things different
[02:15:10.020 --> 02:15:11.780]   times of day and so forth.
[02:15:11.780 --> 02:15:17.220]   Zapier.com/twig.
[02:15:17.220 --> 02:15:21.420]   Stacey, what's your thing this week?
[02:15:21.420 --> 02:15:26.020]   Well I was going to do the personalized pop socket that my husband gave me for Christmas,
[02:15:26.020 --> 02:15:27.020]   but I'm just kidding.
[02:15:27.020 --> 02:15:29.020]   Oh, does that have your picture on it?
[02:15:29.020 --> 02:15:31.220]   It has my dog's picture on it.
[02:15:31.220 --> 02:15:33.220]   Oh, it's a dog's picture on it.
[02:15:33.220 --> 02:15:35.540]   She's gurr.
[02:15:35.540 --> 02:15:37.380]   But this-- you flew it upside down.
[02:15:37.380 --> 02:15:38.380]   Now she's happy.
[02:15:38.380 --> 02:15:40.180]   Happy dog, pager dog.
[02:15:40.180 --> 02:15:41.180]   I love it.
[02:15:41.180 --> 02:15:43.660]   Okay, but that is not actually it.
[02:15:43.660 --> 02:15:47.300]   Although you can buy customized pop sockets for your loved ones and I will say that was
[02:15:47.300 --> 02:15:49.700]   the best gift that I think I got.
[02:15:49.700 --> 02:15:51.340]   Very sweet.
[02:15:51.340 --> 02:15:57.820]   No, my choice this week is a-- I saw it at CES and I'm a heating pad aficionado because
[02:15:57.820 --> 02:16:01.780]   I have migraines and I get all this tension and blah, blah, blah.
[02:16:01.780 --> 02:16:06.740]   And I hate being stuck to the court.
[02:16:06.740 --> 02:16:10.260]   I'm constantly-- I want to move around, I want to do things, but instead I just have
[02:16:10.260 --> 02:16:14.140]   to sit and watch TV or read the Economist and it's just no fun.
[02:16:14.140 --> 02:16:20.380]   So a company called Relief Heat makes a heating pad that you strap.
[02:16:20.380 --> 02:16:21.860]   It's mostly for your back.
[02:16:21.860 --> 02:16:22.860]   Oh.
[02:16:22.860 --> 02:16:23.860]   How you strap it around your waist.
[02:16:23.860 --> 02:16:24.860]   Father Robert had this.
[02:16:24.860 --> 02:16:25.860]   Okay.
[02:16:25.860 --> 02:16:27.100]   He brought it in on Sunday.
[02:16:27.100 --> 02:16:28.900]   160 degrees on your back.
[02:16:28.900 --> 02:16:29.900]   I put it on it.
[02:16:29.900 --> 02:16:31.260]   It's so hot I was sweating.
[02:16:31.260 --> 02:16:32.260]   Okay, yeah.
[02:16:32.260 --> 02:16:33.260]   It's a little hot, but--
[02:16:33.260 --> 02:16:34.260]   Well, you can control it.
[02:16:34.260 --> 02:16:35.260]   Yeah.
[02:16:35.260 --> 02:16:37.260]   And you control it via your smartphone.
[02:16:37.260 --> 02:16:38.260]   I love this.
[02:16:38.260 --> 02:16:39.260]   And--
[02:16:39.260 --> 02:16:43.420]   Yeah, I love this too because I'm like-- so I bought one.
[02:16:43.420 --> 02:16:45.140]   I'm going to wear it more around my shoulders.
[02:16:45.140 --> 02:16:48.100]   It's not ideal for that, but I'm going to see how it works.
[02:16:48.100 --> 02:16:49.100]   But yeah.
[02:16:49.100 --> 02:16:51.220]   I design really to go right in the small of your back.
[02:16:51.220 --> 02:16:56.620]   It's just the right size to go right where most people are tense and tight.
[02:16:56.620 --> 02:17:00.660]   But I was like-- and had they had a relief one designed-- because I have a little-- I
[02:17:00.660 --> 02:17:05.420]   have a shoulder and neck heating pad that I love for my migrants.
[02:17:05.420 --> 02:17:08.260]   But I'm going to try it because how awesome would it be?
[02:17:08.260 --> 02:17:10.580]   Like I could be cooking dinner while wearing this.
[02:17:10.580 --> 02:17:11.940]   I could be doing this show.
[02:17:11.940 --> 02:17:12.940]   I just love it.
[02:17:12.940 --> 02:17:14.700]   So that is my pick of the week.
[02:17:14.700 --> 02:17:16.420]   Tell me the name again.
[02:17:16.420 --> 02:17:17.420]   Relief Heat.
[02:17:17.420 --> 02:17:18.420]   Relief Heat.
[02:17:18.420 --> 02:17:19.420]   Available now?
[02:17:19.420 --> 02:17:20.900]   It is available now.
[02:17:20.900 --> 02:17:21.900]   Great.
[02:17:21.900 --> 02:17:23.300]   In you, there's two sizes.
[02:17:23.300 --> 02:17:24.300]   So make sure you look.
[02:17:24.300 --> 02:17:28.820]   There is up to 40 inch waist and I believe bigger.
[02:17:28.820 --> 02:17:33.380]   Well, if you're bigger, you really do need 40 to 60 inch waist.
[02:17:33.380 --> 02:17:34.380]   Yeah.
[02:17:34.380 --> 02:17:35.380]   There you go.
[02:17:35.380 --> 02:17:36.380]   What is up with you these days?
[02:17:36.380 --> 02:17:37.980]   What do you want to share with us?
[02:17:37.980 --> 02:17:41.180]   Well, my pick is Miss Patty Mates.
[02:17:41.180 --> 02:17:43.460]   And I hope I'm pronouncing that correctly.
[02:17:43.460 --> 02:17:51.420]   This is someone I started following on Instagram that is P-A-M-A-T-E-S on Instagram.
[02:17:51.420 --> 02:17:56.940]   And I came across her from watching another one of my favorite photography resources.
[02:17:56.940 --> 02:17:59.540]   And she's someone is getting started in photography.
[02:17:59.540 --> 02:18:00.540]   I love her.
[02:18:00.540 --> 02:18:04.700]   But she's wanting to step up her photography game because she's wanting to be better with
[02:18:04.700 --> 02:18:07.620]   getting picks for the animal shelter.
[02:18:07.620 --> 02:18:12.940]   So she's been investing a lot of time and trying to learn the world of photography and
[02:18:12.940 --> 02:18:17.460]   is really trying to just make these animals shine on the...
[02:18:17.460 --> 02:18:20.460]   So it's studio photography, portraiture, but it's for animals.
[02:18:20.460 --> 02:18:21.460]   But it's for animals.
[02:18:21.460 --> 02:18:22.460]   I love it.
[02:18:22.460 --> 02:18:23.820]   She doesn't have a lot of followers.
[02:18:23.820 --> 02:18:27.820]   So, to wake folks, go over there and give her a follow and just show your support because
[02:18:27.820 --> 02:18:31.500]   she's trying to do something really good with getting all these animals adopted.
[02:18:31.500 --> 02:18:32.820]   And she's thinking, "You know what?
[02:18:32.820 --> 02:18:35.540]   I can't just take regular drag pictures.
[02:18:35.540 --> 02:18:37.860]   I've talked about it on hands-on photography.
[02:18:37.860 --> 02:18:41.620]   If you're going to do headshots, you can give someone a nice headshot or you can give
[02:18:41.620 --> 02:18:42.620]   them a mugshot.
[02:18:42.620 --> 02:18:46.020]   It's all about the personality and it's all about what you do as a photographer to make
[02:18:46.020 --> 02:18:47.620]   that person shine."
[02:18:47.620 --> 02:18:48.980]   Same goes for these pet portraits.
[02:18:48.980 --> 02:18:51.620]   So, Patty Mates on Instagram.
[02:18:51.620 --> 02:18:55.980]   It's P-A-M-A-T-T-E-S.
[02:18:55.980 --> 02:18:58.900]   Instagram.com/P-A-Mattice.
[02:18:58.900 --> 02:18:59.900]   I bet it's Mattice.
[02:18:59.900 --> 02:19:00.900]   Mattice.
[02:19:00.900 --> 02:19:01.900]   Mad dog Mattice.
[02:19:01.900 --> 02:19:02.900]   I don't know.
[02:19:02.900 --> 02:19:03.900]   Okay.
[02:19:03.900 --> 02:19:04.900]   P-A-M-A-T-T-E-S.
[02:19:04.900 --> 02:19:07.300]   Or maybe Mats like Lotts.
[02:19:07.300 --> 02:19:08.300]   Lotts.
[02:19:08.300 --> 02:19:09.300]   I don't know.
[02:19:09.300 --> 02:19:12.660]   Jeff Jarvis, on Number, sir?
[02:19:12.660 --> 02:19:17.660]   So I have a very quick collection of mobile moment numbers.
[02:19:17.660 --> 02:19:21.140]   Google is about to hit the trillion dollar valuation club.
[02:19:21.140 --> 02:19:22.140]   Where Amazon.
[02:19:22.140 --> 02:19:23.140]   I mean, Apple.
[02:19:23.140 --> 02:19:24.140]   Apple.
[02:19:24.140 --> 02:19:25.140]   Apple.
[02:19:25.140 --> 02:19:26.140]   Microsoft to Ben.
[02:19:26.140 --> 02:19:30.820]   Mark Zuckerberg is now the fifth richest man in the world.
[02:19:30.820 --> 02:19:39.180]   And interesting stuff in this story about the subjects of the movie.
[02:19:39.180 --> 02:19:47.140]   So Eduardo Severin, who complained about losing stock, is worth $12.3 billion.
[02:19:47.140 --> 02:19:48.300]   What?
[02:19:48.300 --> 02:19:53.660]   So he was the guy who was like Mark's roommate and kind of get aced out of it, right?
[02:19:53.660 --> 02:19:56.180]   Did he never sued like the Winklevoss twins?
[02:19:56.180 --> 02:19:57.380]   But you fell out of the way.
[02:19:57.380 --> 02:19:58.380]   Oh, well they had a fight, though.
[02:19:58.380 --> 02:20:00.820]   Yeah, and the social network, you felt really bad for him.
[02:20:00.820 --> 02:20:01.820]   I guess not.
[02:20:01.820 --> 02:20:04.900]   He would have had a 30% stake, which was ridiculous.
[02:20:04.900 --> 02:20:09.140]   It was ignorant and naive that Mark did that.
[02:20:09.140 --> 02:20:16.260]   And Dustin Moskowitz, who was the other kind of roommate partner, sold some of his shares,
[02:20:16.260 --> 02:20:17.260]   the fool.
[02:20:17.260 --> 02:20:21.660]   Nonetheless, his holdings now are worth $7.2 billion.
[02:20:21.660 --> 02:20:24.500]   If he held on to them, it would be worth $27.4 billion.
[02:20:24.500 --> 02:20:29.500]   What's the difference between having $7 billion and $20 billion?
[02:20:29.500 --> 02:20:31.140]   I don't know.
[02:20:31.140 --> 02:20:33.300]   I don't know, but I'm trying to find out.
[02:20:33.300 --> 02:20:35.460]   You're infinitely rich in other cases.
[02:20:35.460 --> 02:20:37.460]   Let me try to find it.
[02:20:37.460 --> 02:20:39.460]   You can have 20.
[02:20:39.460 --> 02:20:40.460]   I'll have seven.
[02:20:40.460 --> 02:20:41.460]   Okay.
[02:20:41.460 --> 02:20:42.460]   And we'll have...
[02:20:42.460 --> 02:20:44.460]   Let's just give us a little bit of that.
[02:20:44.460 --> 02:20:48.300]   Let's give you a couple of billion each.
[02:20:48.300 --> 02:20:57.980]   So then, and Williams, who besides having medium, has just raised another $271,828,182
[02:20:57.980 --> 02:21:00.420]   for his third raise for his fund.
[02:21:00.420 --> 02:21:01.420]   Oh, not for me.
[02:21:01.420 --> 02:21:02.420]   No, for me.
[02:21:02.420 --> 02:21:03.420]   For about $585 billion.
[02:21:03.420 --> 02:21:04.420]   No, he has a fund.
[02:21:04.420 --> 02:21:09.620]   The fund owned 9% of Beyond Meat.
[02:21:09.620 --> 02:21:11.860]   Is that the Impossible Burger as Beyond Meat?
[02:21:11.860 --> 02:21:12.860]   Yes.
[02:21:12.860 --> 02:21:14.700]   No, it's a different company.
[02:21:14.700 --> 02:21:15.700]   Oh.
[02:21:15.700 --> 02:21:19.060]   Did you have the Impossible Sliders Stacey at CES?
[02:21:19.060 --> 02:21:20.980]   I've had Impossible...
[02:21:20.980 --> 02:21:21.980]   Apparently the pork is good.
[02:21:21.980 --> 02:21:22.980]   Furs.
[02:21:22.980 --> 02:21:23.980]   Yeah.
[02:21:23.980 --> 02:21:24.980]   I've done it.
[02:21:24.980 --> 02:21:25.980]   Pork would be easier because it's so spiced.
[02:21:25.980 --> 02:21:26.980]   Yeah.
[02:21:26.980 --> 02:21:31.020]   So, invest in world positive startups.
[02:21:31.020 --> 02:21:32.020]   Good for him.
[02:21:32.020 --> 02:21:37.340]   Holly Diamond Foundry, which makes diamonds and labs instead of mines.
[02:21:37.340 --> 02:21:42.580]   Plant-based food, biaco's kitchen, and here's a fun part of this one.
[02:21:42.580 --> 02:21:49.300]   The last round was $191,919,191 as a palindrome.
[02:21:49.300 --> 02:21:54.020]   Oh, 119191919191.
[02:21:54.020 --> 02:22:00.940]   This one is again, $271,828,182 is a nod to the mathematical constant Euler's number.
[02:22:00.940 --> 02:22:01.940]   Euler's number, yes.
[02:22:01.940 --> 02:22:03.940]   Euler, thank you, yes.
[02:22:03.940 --> 02:22:05.820]   It's not a big conflict on Canadian.
[02:22:05.820 --> 02:22:09.300]   And then finally, our last mobile moment of the day.
[02:22:09.300 --> 02:22:10.780]   You look like an idiot.
[02:22:10.780 --> 02:22:14.580]   Don't know Euler's number, my God.
[02:22:14.580 --> 02:22:19.020]   I think all of the people abuse me in this audience.
[02:22:19.020 --> 02:22:20.500]   E.
[02:22:20.500 --> 02:22:25.700]   And then the last mobile moment is that Jack Dorsey now eats one meal a day, which is
[02:22:25.700 --> 02:22:26.860]   more than he used to.
[02:22:26.860 --> 02:22:29.180]   Oh, he used to fast a lot, right?
[02:22:29.180 --> 02:22:30.900]   He's like three meals a week.
[02:22:30.900 --> 02:22:32.900]   So no, he's doing a meal with that.
[02:22:32.900 --> 02:22:37.140]   He's looking kind of fat.
[02:22:37.140 --> 02:22:39.900]   I'm going to body shame Jack Dorsey.
[02:22:39.900 --> 02:22:40.900]   Jack.
[02:22:40.900 --> 02:22:43.700]   No, no, we're not body shaming anyone.
[02:22:43.700 --> 02:22:46.860]   No, but this is a guy you should body shame.
[02:22:46.860 --> 02:22:51.340]   No, you never have to body shame anyone, even if they're being obnoxious.
[02:22:51.340 --> 02:22:52.340]   Nope.
[02:22:52.340 --> 02:22:55.580]   What's with the nose ring, Jack?
[02:22:55.580 --> 02:22:58.180]   Let it flutter down like a little good fairy.
[02:22:58.180 --> 02:23:01.220]   Oh, God, punch Leo.
[02:23:01.220 --> 02:23:04.460]   I used to have a guy I worked with who said, don't us.
[02:23:04.460 --> 02:23:05.380]   Just bad mojo.
[02:23:05.380 --> 02:23:05.980]   Don't do it.
[02:23:05.980 --> 02:23:06.780]   Bad mojo.
[02:23:06.780 --> 02:23:06.780]   Yeah.
[02:23:06.780 --> 02:23:08.180]   Mojo.
[02:23:08.180 --> 02:23:08.780]   Some of us.
[02:23:08.780 --> 02:23:12.180]   I did not know how to spell Euler's constant.
[02:23:12.180 --> 02:23:14.060]   So thank you, Jeff.
[02:23:14.060 --> 02:23:15.020]   I didn't know the pronounce it.
[02:23:15.020 --> 02:23:18.540]   So between the two of us together, I still don't know what the heck you're all
[02:23:18.540 --> 02:23:20.460]   talking about, but I'm quite all right with that.
[02:23:20.460 --> 02:23:21.540]   What is he?
[02:23:21.540 --> 02:23:23.060]   What does it represent?
[02:23:23.060 --> 02:23:25.940]   What is it a constant for?
[02:23:25.940 --> 02:23:27.740]   He's got the Wikipedia page up.
[02:23:27.740 --> 02:23:29.900]   As we all do right now.
[02:23:29.900 --> 02:23:30.900]   How many show of hands?
[02:23:30.900 --> 02:23:32.300]   How many of you opened up Wikipedia?
[02:23:32.300 --> 02:23:33.780]   See, that's why we have a smart audience.
[02:23:33.780 --> 02:23:34.620]   Right.
[02:23:34.620 --> 02:23:37.100]   They look it up to me healing.
[02:23:37.100 --> 02:23:38.940]   So they can show us up?
[02:23:38.940 --> 02:23:40.100]   No.
[02:23:40.100 --> 02:23:43.220]   OK, I confess to something on iPad today.
[02:23:43.220 --> 02:23:44.580]   Yesterday.
[02:23:44.580 --> 02:23:45.620]   iOS today.
[02:23:45.620 --> 02:23:46.100]   Yesterday.
[02:23:46.100 --> 02:23:47.380]   First of all, I don't know the name of the show.
[02:23:47.380 --> 02:23:47.980]   That's the one one.
[02:23:47.980 --> 02:23:48.980]   One of your shows.
[02:23:48.980 --> 02:23:49.740]   Some show I do.
[02:23:49.740 --> 02:23:51.580]   I don't know.
[02:23:51.580 --> 02:23:53.820]   I do it with Sarah Lane, right?
[02:23:53.820 --> 02:23:54.900]   No, I thought it was Megan.
[02:23:54.900 --> 02:23:55.820]   No, is--
[02:23:55.820 --> 02:23:56.780]   Yeah, Micah.
[02:23:56.780 --> 02:23:57.300]   Micah.
[02:23:57.300 --> 02:23:58.300]   Some guy named Micah.
[02:23:58.300 --> 02:24:01.900]   But I confess to Micah, we're watching Ford versus Ferrari,
[02:24:01.900 --> 02:24:02.700]   which is very good.
[02:24:02.700 --> 02:24:03.220]   By the way--
[02:24:03.220 --> 02:24:03.900]   That's a good flick.
[02:24:03.900 --> 02:24:04.820]   It was good.
[02:24:04.820 --> 02:24:06.420]   And I didn't watch it at first because I thought--
[02:24:06.420 --> 02:24:07.460]   I'm not in a car racing.
[02:24:07.460 --> 02:24:08.860]   It's an Adam Corolla documentary.
[02:24:08.860 --> 02:24:12.300]   Did you know that?
[02:24:12.300 --> 02:24:13.420]   What do you mean?
[02:24:13.420 --> 02:24:15.300]   Adam Corolla did that documentary.
[02:24:15.300 --> 02:24:17.020]   That's his production.
[02:24:17.020 --> 02:24:19.460]   Adam Corolla made Ford versus Ferrari.
[02:24:19.460 --> 02:24:21.380]   That's him.
[02:24:21.380 --> 02:24:23.660]   He's done quite a few documentaries out there.
[02:24:23.660 --> 02:24:26.660]   He's a little more prolific than one may think.
[02:24:26.660 --> 02:24:28.900]   Wait, Ford versus Ferrari is a documentary?
[02:24:28.900 --> 02:24:30.180]   No, it's not.
[02:24:30.180 --> 02:24:30.980]   Oh, OK.
[02:24:30.980 --> 02:24:32.580]   But maybe--
[02:24:32.580 --> 02:24:33.580]   Well, it's a true story.
[02:24:33.580 --> 02:24:34.340]   It's a true story.
[02:24:34.340 --> 02:24:35.540]   Not a documentary, sorry.
[02:24:35.540 --> 02:24:37.660]   It's based on a true story?
[02:24:37.660 --> 02:24:39.140]   Yes, it's true.
[02:24:39.140 --> 02:24:40.140]   It's about--
[02:24:40.140 --> 02:24:41.260]   He's the dad.
[02:24:41.260 --> 02:24:42.420]   He also did--
[02:24:42.420 --> 02:24:45.020]   Kelby, Shelby, and--
[02:24:45.020 --> 02:24:46.220]   What's it called?
[02:24:46.220 --> 02:24:47.100]   Shelby--
[02:24:47.100 --> 02:24:50.980]   And so Ferrari and Leia Coca's in it.
[02:24:50.980 --> 02:24:52.060]   And it's great.
[02:24:52.060 --> 02:24:55.340]   Matt Damon plays Carol Shelby and Ken Miles,
[02:24:55.340 --> 02:24:57.220]   who's the race car driver in his--
[02:24:57.220 --> 02:24:58.900]   beautifully played by Christian Bale.
[02:24:58.900 --> 02:25:00.420]   But I confess we're watching it.
[02:25:00.420 --> 02:25:04.940]   And we're watching it in a group with Lisa, my wife,
[02:25:04.940 --> 02:25:09.900]   Lisa's son, Michael, and Lisa's son's dad, Mike.
[02:25:09.900 --> 02:25:12.220]   Who is a car guy?
[02:25:12.220 --> 02:25:16.020]   Maybe it was-- I just felt a little bit like I should be
[02:25:16.020 --> 02:25:17.900]   competing.
[02:25:17.900 --> 02:25:21.180]   So I'm surreptitiously Wikipediaing--
[02:25:21.180 --> 02:25:22.020]   Oh, no.
[02:25:22.020 --> 02:25:23.020]   The story.
[02:25:23.020 --> 02:25:23.460]   The movie.
[02:25:23.460 --> 02:25:24.580]   Yeah.
[02:25:24.580 --> 02:25:27.260]   So, oh, yeah, watch what happens here.
[02:25:27.260 --> 02:25:28.100]   Is there in the movie?
[02:25:28.100 --> 02:25:31.700]   Think that what happens.
[02:25:31.700 --> 02:25:33.100]   That was bad.
[02:25:33.100 --> 02:25:33.980]   I got away with it.
[02:25:33.980 --> 02:25:35.340]   Oh, gosh.
[02:25:35.340 --> 02:25:37.900]   Well, can I just take a little--
[02:25:37.900 --> 02:25:38.660]   I'll put an email.
[02:25:38.660 --> 02:25:41.540]   HLN changing his program lineup.
[02:25:41.540 --> 02:25:44.540]   Headline news, that's the CNN headline news.
[02:25:44.540 --> 02:25:46.500]   Yeah, so we complain about how awful
[02:25:46.500 --> 02:25:49.140]   what a cesspool social media is, right?
[02:25:49.140 --> 02:25:52.260]   Let me just quickly read the titles of their shows.
[02:25:52.260 --> 02:25:53.340]   Oh, god.
[02:25:53.340 --> 02:25:58.340]   Vengeance, killer coworkers, forensic files, too.
[02:25:58.340 --> 02:26:01.260]   Sex and murder, but killer truth.
[02:26:01.260 --> 02:26:03.660]   Vengeance, killer families.
[02:26:03.660 --> 02:26:05.860]   Very scary people.
[02:26:05.860 --> 02:26:08.260]   Death row stories.
[02:26:08.260 --> 02:26:09.180]   Dead wives.
[02:26:09.180 --> 02:26:11.180]   Just like MSNBC on weekends--
[02:26:11.180 --> 02:26:14.180]   You're like, lock up.
[02:26:14.180 --> 02:26:16.020]   Lock up now looks like--
[02:26:16.020 --> 02:26:18.420]   Nothing compared to that.
[02:26:18.420 --> 02:26:18.780]   You know what?
[02:26:18.780 --> 02:26:21.900]   This is what happens to every cable channel eventually,
[02:26:21.900 --> 02:26:24.620]   because no one watches them, so they have to finally go
[02:26:24.620 --> 02:26:25.460]   sensational.
[02:26:25.460 --> 02:26:26.700]   That's even tech TV.
[02:26:26.700 --> 02:26:27.140]   Pretty much.
[02:26:27.140 --> 02:26:31.540]   We started showing cops, literally, overnight.
[02:26:31.540 --> 02:26:33.060]   They were showing cops reruns.
[02:26:33.060 --> 02:26:33.780]   All right.
[02:26:33.780 --> 02:26:35.700]   Bad boys, bad boys.
[02:26:35.700 --> 02:26:37.340]   It's embarrassing.
[02:26:37.340 --> 02:26:39.380]   It looped people in for some reason.
[02:26:39.380 --> 02:26:41.300]   Oh, sorry for the birds.
[02:26:41.300 --> 02:26:43.860]   Detour, but I just close the page.
[02:26:43.860 --> 02:26:46.500]   All right, well, I think--
[02:26:46.500 --> 02:26:49.340]   What was Mike Bloomberg's weird tweet on debate?
[02:26:49.340 --> 02:26:50.700]   Oh, you didn't see this?
[02:26:50.700 --> 02:26:54.500]   His whole account went wacky during the debate.
[02:26:54.500 --> 02:26:59.460]   And the weirdest of all was find Mike's face in the meatball.
[02:26:59.460 --> 02:27:01.660]   And journalists were sure it was hacked,
[02:27:01.660 --> 02:27:03.300]   and they kept on going to them.
[02:27:03.300 --> 02:27:04.700]   You can't put a heck what's going on.
[02:27:04.700 --> 02:27:07.980]   And then no, but hey, we got your attention.
[02:27:07.980 --> 02:27:09.780]   Mike's given billions to charity,
[02:27:09.780 --> 02:27:12.500]   but refuses to give another cent to his lazy, slacker
[02:27:12.500 --> 02:27:14.340]   nephew, Duane.
[02:27:14.340 --> 02:27:18.700]   This is the team Bloomberg Twitter @Mike2020.
[02:27:18.700 --> 02:27:21.580]   Mike has eaten claims casino for breakfast, lunch, and dinner
[02:27:21.580 --> 02:27:24.380]   every day for the past 30 years.
[02:27:24.380 --> 02:27:27.740]   But the best one is spot the meatball that looks like Mike.
[02:27:27.740 --> 02:27:30.780]   And I guess there are pictures.
[02:27:30.780 --> 02:27:32.420]   It does look like him.
[02:27:32.420 --> 02:27:34.980]   Wow, that's uncanny.
[02:27:34.980 --> 02:27:36.660]   It really looks just like it.
[02:27:36.660 --> 02:27:38.100]   Oh, my goodness.
[02:27:38.100 --> 02:27:40.700]   Are you serious?
[02:27:40.700 --> 02:27:41.300]   You know what?
[02:27:41.300 --> 02:27:43.860]   That's viral marketing, kids.
[02:27:43.860 --> 02:27:44.780]   That's disgusting.
[02:27:44.780 --> 02:27:46.900]   That's viral marketing.
[02:27:46.900 --> 02:27:48.340]   Wow.
[02:27:48.340 --> 02:27:49.540]   Wow.
[02:27:49.540 --> 02:27:50.740]   Geez.
[02:27:50.740 --> 02:27:54.500]   Oh, by the way, yeah, did you go to Google and search
[02:27:54.500 --> 02:27:56.300]   for the Wizard of Oz?
[02:27:56.300 --> 02:27:57.340]   Is this old?
[02:27:57.340 --> 02:27:58.060]   I don't know.
[02:27:58.060 --> 02:27:59.220]   Oh, yeah, no, this is old.
[02:27:59.220 --> 02:27:59.780]   Yeah, yeah, yeah.
[02:27:59.780 --> 02:28:00.060]   It's old.
[02:28:00.060 --> 02:28:00.500]   Never mind.
[02:28:00.500 --> 02:28:01.180]   Don't do it that way.
[02:28:01.180 --> 02:28:01.780]   No, no, it's fun.
[02:28:01.780 --> 02:28:04.180]   The house lands on Dorothy.
[02:28:04.180 --> 02:28:04.580]   It's all right.
[02:28:04.580 --> 02:28:05.020]   It's fine.
[02:28:05.020 --> 02:28:06.500]   We don't have to do it.
[02:28:06.500 --> 02:28:08.740]   I'll leave it as an exercise.
[02:28:08.740 --> 02:28:09.860]   It goes black and white, right?
[02:28:09.860 --> 02:28:11.300]   The page goes black and white.
[02:28:11.300 --> 02:28:12.980]   How do I-- but what do I Google?
[02:28:12.980 --> 02:28:14.940]   Click on the shoes.
[02:28:14.940 --> 02:28:17.020]   Click on the shoes.
[02:28:17.020 --> 02:28:18.020]   And I'll see-- oh, I'm on--
[02:28:18.020 --> 02:28:18.220]   It did.
[02:28:18.220 --> 02:28:19.940]   --that's why I'm not on Google.
[02:28:19.940 --> 02:28:21.460]   I'm on a start page.
[02:28:21.460 --> 02:28:22.620]   I'm on a privacy--
[02:28:22.620 --> 02:28:23.980]   We're respecting Google.
[02:28:23.980 --> 02:28:25.140]   --and brave browser, baby.
[02:28:25.140 --> 02:28:26.500]   Yeah, yeah, that's why.
[02:28:26.500 --> 02:28:29.500]   I respect my privacy.
[02:28:29.500 --> 02:28:31.740]   OK, you click on the shoes.
[02:28:31.740 --> 02:28:34.540]   They click together three times the page worlds around
[02:28:34.540 --> 02:28:36.940]   like you're in a tornado.
[02:28:36.940 --> 02:28:39.260]   And it goes black and white, just like the movie.
[02:28:39.260 --> 02:28:41.900]   Ladies and gentlemen, that concludes this thrilling gripping
[02:28:41.900 --> 02:28:44.180]   edition of this week in Google.
[02:28:44.180 --> 02:28:45.660]   Stacy Higabotham.
[02:28:45.660 --> 02:28:47.020]   Say again?
[02:28:47.020 --> 02:28:48.180]   Click again.
[02:28:48.180 --> 02:28:49.660]   Click the tornado.
[02:28:49.660 --> 02:28:52.140]   Now what-- oh, the house comes out.
[02:28:52.140 --> 02:28:55.220]   And it lands on the witch, twirls around again,
[02:28:55.220 --> 02:28:55.900]   and goes back in.
[02:28:55.900 --> 02:28:56.380]   It's a color.
[02:28:56.380 --> 02:28:56.740]   How cool.
[02:28:56.740 --> 02:28:57.220]   What exciting.
[02:28:57.220 --> 02:28:57.740]   When is Danny--
[02:28:57.740 --> 02:28:59.420]   Now click on the shoes.
[02:28:59.420 --> 02:29:00.180]   But now we did.
[02:29:00.180 --> 02:29:02.100]   Oh, God, it's going to go on.
[02:29:02.100 --> 02:29:03.100]   We're in a loop.
[02:29:03.100 --> 02:29:05.700]   We're stuck in a Wizard of Oz loop.
[02:29:05.700 --> 02:29:09.260]   Stacy Higabotham says, Stacy on IOT.com.
[02:29:09.260 --> 02:29:11.620]   Go and subscribe to her free newsletter.
[02:29:11.620 --> 02:29:13.380]   She's on Twitter at Gigastacey.
[02:29:13.380 --> 02:29:15.180]   And of course, she and Kevin Tofel
[02:29:15.180 --> 02:29:18.740]   do the best darn IOT podcast after our own smart tech today.
[02:29:18.740 --> 02:29:21.260]   Send her snow shoes.
[02:29:21.260 --> 02:29:22.420]   Yeah.
[02:29:22.420 --> 02:29:23.540]   Is it dark out now?
[02:29:23.540 --> 02:29:24.040]   Yes.
[02:29:24.040 --> 02:29:25.180]   It's getting there.
[02:29:25.180 --> 02:29:25.540]   It's a tear.
[02:29:25.540 --> 02:29:26.740]   One more picture of the snow.
[02:29:26.740 --> 02:29:28.860]   Yeah, one more picture of snowpocalypse.
[02:29:28.860 --> 02:29:30.860]   Snowpocalypse.
[02:29:30.860 --> 02:29:32.180]   There's our snow fort down there.
[02:29:32.180 --> 02:29:35.100]   Snow, snow, snow, snow.
[02:29:35.100 --> 02:29:36.540]   It finally stopped.
[02:29:36.540 --> 02:29:38.940]   It did stop snowing, yes.
[02:29:38.940 --> 02:29:39.440]   Nice.
[02:29:39.440 --> 02:29:40.620]   So we're good.
[02:29:40.620 --> 02:29:41.420]   Beautiful.
[02:29:41.420 --> 02:29:41.820]   Beautiful.
[02:29:41.820 --> 02:29:44.340]   Look at the pine trees with the snow on their branches.
[02:29:45.340 --> 02:29:46.660]   So pretty.
[02:29:46.660 --> 02:29:49.060]   So pristine.
[02:29:49.060 --> 02:29:52.660]   And Pruitt is-- almost called you, Ann Higabotham.
[02:29:52.660 --> 02:29:58.420]   And Pruitt is a host of a number of shows on this here network,
[02:29:58.420 --> 02:30:01.860]   including Focus on Photography, Hands on Photography.
[02:30:01.860 --> 02:30:04.420]   Of course, a regular on this week in Google.
[02:30:04.420 --> 02:30:07.500]   Twit.tv/hop, you should really watch Hands on Photography.
[02:30:07.500 --> 02:30:08.540]   It's a great show.
[02:30:08.540 --> 02:30:11.220]   And Focus on Photography is like a round table discussion
[02:30:11.220 --> 02:30:12.180]   about photography, too.
[02:30:12.180 --> 02:30:13.260]   Really excellent shows.
[02:30:13.260 --> 02:30:15.300]   Focus on photography is going to be fun.
[02:30:15.300 --> 02:30:20.580]   We have concert photographer, Mr. Alan Hess.
[02:30:20.580 --> 02:30:21.420]   Oh, I know, Alan.
[02:30:21.420 --> 02:30:21.900]   It's tomorrow.
[02:30:21.900 --> 02:30:23.020]   Oh, that's going to be fun.
[02:30:23.020 --> 02:30:23.940]   Yes.
[02:30:23.940 --> 02:30:25.580]   And he's quite passionate.
[02:30:25.580 --> 02:30:26.220]   I'll say that.
[02:30:26.220 --> 02:30:27.140]   Oh, that--
[02:30:27.140 --> 02:30:30.220]   And boy, you know, it's hard because the lights are weird.
[02:30:30.220 --> 02:30:32.540]   They'll change every millisecond.
[02:30:32.540 --> 02:30:33.460]   Oh, that'll be great.
[02:30:33.460 --> 02:30:35.620]   I'll be sure to listen to that one.
[02:30:35.620 --> 02:30:36.980]   Jeffrey Jarvis.
[02:30:36.980 --> 02:30:40.140]   He is our great friend, Professor of Journalism at CUNY.
[02:30:40.140 --> 02:30:45.940]   He's the Craig Newmark chair of the townite school
[02:30:45.940 --> 02:30:46.740]   of Professor--
[02:30:46.740 --> 02:30:48.540]   Professor.
[02:30:48.540 --> 02:30:49.900]   Where is that lower third of his?
[02:30:49.900 --> 02:30:51.260]   Put the big lower third up second.
[02:30:51.260 --> 02:30:53.140]   By the way, Professor--
[02:30:53.140 --> 02:30:57.980]   There came a moment in the show when I suddenly
[02:30:57.980 --> 02:30:59.940]   went off pink to human.
[02:30:59.940 --> 02:31:02.500]   Yeah, we've been working on you, and we're pretty soon.
[02:31:02.500 --> 02:31:03.860]   I think we're going to get--
[02:31:03.860 --> 02:31:08.740]   it's the new cyborg with the plastic-like flesh.
[02:31:08.740 --> 02:31:10.380]   That's very realistic.
[02:31:10.380 --> 02:31:11.340]   Yes.
[02:31:11.340 --> 02:31:14.260]   Buzzmachine.com is his blog, although he also
[02:31:14.260 --> 02:31:17.740]   crosses on Medium because Ev needs the money.
[02:31:17.740 --> 02:31:19.820]   And he's at Jeff Jarvis on the Twitter.
[02:31:19.820 --> 02:31:21.940]   What's your Twitter handle, and is it underscore?
[02:31:21.940 --> 02:31:22.340]   It's underscore-proof.
[02:31:22.340 --> 02:31:23.820]   It's underscore-proof.
[02:31:23.820 --> 02:31:25.180]   We should mention that too.
[02:31:25.180 --> 02:31:26.060]   Thank you very much.
[02:31:26.060 --> 02:31:27.140]   Thank you all for being here.
[02:31:27.140 --> 02:31:29.540]   We do this week in Google every Wednesday, 130 Pacific,
[02:31:29.540 --> 02:31:32.020]   430 Eastern, 2130 UTC.
[02:31:32.020 --> 02:31:34.860]   You can watch us do at live@twit.tv/live.
[02:31:34.860 --> 02:31:37.020]   There's also an audio stream there.
[02:31:37.020 --> 02:31:39.300]   You can also subscribe to the show.
[02:31:39.300 --> 02:31:41.020]   In fact, just go to the website, twi--
[02:31:41.020 --> 02:31:42.460]   .tv/twig.
[02:31:42.460 --> 02:31:45.820]   Click the Subscribe to audio or Subscribe to video button.
[02:31:45.820 --> 02:31:47.060]   We'll help you do it.
[02:31:47.060 --> 02:31:49.140]   Or you can go to your favorite podcast application
[02:31:49.140 --> 02:31:51.540]   and search for this week in Google.
[02:31:51.540 --> 02:31:55.620]   Subscribing is a good thing, as Martha Stewart would say.
[02:31:55.620 --> 02:31:57.140]   Thank you all for being here.
[02:31:57.140 --> 02:31:59.900]   We'll see you next time on this week in Google.
[02:31:59.900 --> 02:32:00.900]   Bye-bye.
[02:32:00.900 --> 02:32:03.900]   [MUSIC PLAYING]
[02:32:03.900 --> 02:32:06.900]   [MUSIC PLAYING]
[02:32:06.900 --> 02:32:09.900]   [MUSIC PLAYING]
[02:32:09.900 --> 02:32:12.480]   (upbeat music)

