;FFMETADATA1
title=Wear Your Dadgum Schnutenpulli!
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=601
genre=Podcast
comment=https://twit.tv/twig
copyright=These podcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2021
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.960]   It's time for Twig this week in Google's special guest for you today, Dr. Noreet Weisplat.
[00:00:04.960 --> 00:00:10.160]   She wrote a book called "The Tech Lash and Tech Crisis Communication, How Tech Journalism
[00:00:10.160 --> 00:00:13.000]   Has Changed Over the Last Four Years."
[00:00:13.000 --> 00:00:14.480]   I think you'll be interested.
[00:00:14.480 --> 00:00:20.440]   Also, we'll talk about the new features Google's dropping on Pixel phones, buy-by at a cardboard,
[00:00:20.440 --> 00:00:22.360]   and what the heck are NFTs?
[00:00:22.360 --> 00:00:26.080]   It's all coming up next on Twig.
[00:00:26.080 --> 00:00:32.080]   This is Twig.
[00:00:32.080 --> 00:00:39.520]   This is Twig.
[00:00:39.520 --> 00:00:46.280]   This week in Google, Episode 601, recorded Wednesday, March 3, 2021.
[00:00:46.280 --> 00:00:49.080]   Where your dad, Gumschneuttenpully.
[00:00:49.080 --> 00:00:51.880]   This week in Google is brought to you by Melissa.
[00:00:51.880 --> 00:00:56.720]   Like expired milk, 30% of your customer's data goes bad every year.
[00:00:56.720 --> 00:00:58.160]   That's money down the drain.
[00:00:58.160 --> 00:01:03.660]   Visit Melissa's developer portal for free access to data quality APIs, demos, and code
[00:01:03.660 --> 00:01:04.660]   samples.
[00:01:04.660 --> 00:01:12.520]   Fresh it up your sour data today with 1000 records clean free at Melissa.com/twit.
[00:01:12.520 --> 00:01:15.240]   And buy Uber for business.
[00:01:15.240 --> 00:01:19.360]   Right now, for a limited time, receive a $50 voucher when you create your first vouchers
[00:01:19.360 --> 00:01:21.960]   campaign and spend $200.
[00:01:21.960 --> 00:01:26.440]   Go to uber.com/twig to learn more.
[00:01:26.440 --> 00:01:28.640]   And buy cash fly.
[00:01:28.640 --> 00:01:31.720]   Give your users the seamless online experience they want.
[00:01:31.720 --> 00:01:37.520]   Power your site or app with cash flies, CDN, and be 30% faster than the competition.
[00:01:37.520 --> 00:01:42.320]   Learn more at twit.cashfly.com.
[00:01:42.320 --> 00:01:43.320]   It's time for Twig.
[00:01:43.320 --> 00:01:46.680]   This week in Google, the show we talk about the latest news from, well, whatever the hell
[00:01:46.680 --> 00:01:48.120]   we want to talk about.
[00:01:48.120 --> 00:01:49.800]   Google being one of them.
[00:01:49.800 --> 00:01:52.880]   Facebook, Twitter, all the verses.
[00:01:52.880 --> 00:01:55.160]   @pruit is here from Hands-On Photography.
[00:01:55.160 --> 00:01:56.160]   Hello, Aunt.
[00:01:56.160 --> 00:01:57.880]   Hello, Mr. LePorte.
[00:01:57.880 --> 00:01:58.880]   Good to see you.
[00:01:58.880 --> 00:01:59.880]   Mr. Jarvis.
[00:01:59.880 --> 00:02:00.880]   JJ's here.
[00:02:00.880 --> 00:02:01.880]   Jeff Jarvis.
[00:02:01.880 --> 00:02:02.880]   Wait a minute.
[00:02:02.880 --> 00:02:04.880]   I got to get my special.
[00:02:04.880 --> 00:02:05.880]   Uh oh.
[00:02:05.880 --> 00:02:06.880]   Uh oh.
[00:02:06.880 --> 00:02:07.880]   Take a breath.
[00:02:07.880 --> 00:02:08.880]   Take a breath.
[00:02:08.880 --> 00:02:13.120]   Jeff Jarvis is the letter to our professor for journalistic innovation at the Craig Newmar
[00:02:13.120 --> 00:02:14.120]   Newmar.
[00:02:14.120 --> 00:02:18.760]   Graduate School of Journalism at the City University of New York, not to be confused
[00:02:18.760 --> 00:02:19.760]   with NYU.
[00:02:19.760 --> 00:02:20.760]   No, he's not.
[00:02:20.760 --> 00:02:21.760]   Jay Rose.
[00:02:21.760 --> 00:02:22.760]   No.
[00:02:22.760 --> 00:02:26.160]   Anyway, great to see you.
[00:02:26.160 --> 00:02:27.560]   JeffBuzz machine.com.
[00:02:27.560 --> 00:02:32.880]   And I want you to introduce our special guest, Stacey has the day off and you have brought
[00:02:32.880 --> 00:02:37.120]   along a friend and I thought it'd be good if you introduced her.
[00:02:37.120 --> 00:02:38.760]   The brilliant Dr.
[00:02:38.760 --> 00:02:46.440]   near it, Weiss Black, who is a former tech journalist, former tech PR person who had
[00:02:46.440 --> 00:02:50.160]   wrote a wonderful book I know because I've lurbed it and even though it includes quotes
[00:02:50.160 --> 00:02:57.800]   for me, that upside, that is right up our alley, which is about tech coverage and when
[00:02:57.800 --> 00:03:04.200]   it shifted from optimistic to dystopian and moral panic and all that.
[00:03:04.200 --> 00:03:08.680]   And she has a great theory about that, which of course I'll let her say.
[00:03:08.680 --> 00:03:12.840]   But near it was a researcher at you.
[00:03:12.840 --> 00:03:15.840]   Yes, she got it right.
[00:03:15.840 --> 00:03:16.840]   Get it right.
[00:03:16.840 --> 00:03:25.400]   She's a Trojan and her book is coming out March 24 and the book title is the tech clash
[00:03:25.400 --> 00:03:29.560]   and tech crisis communication.
[00:03:29.560 --> 00:03:30.560]   Thank you, Noree.
[00:03:30.560 --> 00:03:31.560]   Welcome to the show.
[00:03:31.560 --> 00:03:32.560]   It's nice to have you.
[00:03:32.560 --> 00:03:33.560]   Glad to be here.
[00:03:33.560 --> 00:03:34.640]   Thank you for having me.
[00:03:34.640 --> 00:03:42.280]   So I want to break down your thesis here by starting first with what is the tech clash?
[00:03:42.280 --> 00:03:44.640]   What's going on?
[00:03:44.640 --> 00:03:46.880]   Like the definition?
[00:03:46.880 --> 00:03:50.800]   Yeah, I mean, what are we talking about here, the tech clash?
[00:03:50.800 --> 00:03:58.480]   Well, the tech clash is a summary of the past few years where we have this really strong
[00:03:58.480 --> 00:04:05.840]   and widespread negative reaction to the growing power and influence of big tech specifically
[00:04:05.840 --> 00:04:09.360]   the large companies here in Silicon Valley.
[00:04:09.360 --> 00:04:15.520]   And we have specific sectors that are more backlash like social media and companies that
[00:04:15.520 --> 00:04:18.880]   are more backlash like Facebook as you can guess.
[00:04:18.880 --> 00:04:26.280]   But it's basically been much more critical to the tech industry than before.
[00:04:26.280 --> 00:04:32.360]   Can you specifically focus on tech journalism and the way tech journalists have been covering
[00:04:32.360 --> 00:04:35.400]   technology, which I'm very interested in.
[00:04:35.400 --> 00:04:38.640]   I've been a tech journalist now for several decades.
[00:04:38.640 --> 00:04:41.720]   I don't actually, Stacy says I'm not a journalist right?
[00:04:41.720 --> 00:04:43.720]   I'm a tech pundit.
[00:04:43.720 --> 00:04:44.720]   Easy, easy.
[00:04:44.720 --> 00:04:45.720]   Oh, long time.
[00:04:45.720 --> 00:04:46.720]   I'll start.
[00:04:46.720 --> 00:04:50.200]   Okay, you really want to know since the 70s.
[00:04:50.200 --> 00:04:51.200]   Yeah.
[00:04:51.200 --> 00:04:56.120]   So I started writing for Bite Magazine and InfoWorld and it was downhill from then.
[00:04:56.120 --> 00:04:59.240]   Before or after the Apple II?
[00:04:59.240 --> 00:05:04.880]   After the Apple II, I started writing for Atari magazines, believe it or not.
[00:05:04.880 --> 00:05:05.880]   Oh, wow.
[00:05:05.880 --> 00:05:06.880]   In the 70s.
[00:05:06.880 --> 00:05:11.440]   And my first piece in Bite was in the 1984 Macintosh release issue.
[00:05:11.440 --> 00:05:14.320]   I reviewed some Macintosh software.
[00:05:14.320 --> 00:05:15.320]   Oh, wow.
[00:05:15.320 --> 00:05:18.960]   And then for InfoWorld, I think I was also doing Mac software at the time, writing about
[00:05:18.960 --> 00:05:20.680]   Mac software at the time.
[00:05:20.680 --> 00:05:22.560]   So now I feel bad at it.
[00:05:22.560 --> 00:05:23.560]   You.
[00:05:23.560 --> 00:05:24.560]   No, you don't need to ask me.
[00:05:24.560 --> 00:05:25.560]   I'm just curious.
[00:05:25.560 --> 00:05:30.840]   So you did interview a lot of people, including for some reason, Jeff Jarvis.
[00:05:30.840 --> 00:05:32.800]   From all the best.
[00:05:32.800 --> 00:05:34.600]   All the best.
[00:05:34.600 --> 00:05:36.360]   So what was your conclusion?
[00:05:36.360 --> 00:05:37.680]   Has tech journalism changed?
[00:05:37.680 --> 00:05:39.320]   You call it the evolution of tech journalism.
[00:05:39.320 --> 00:05:41.560]   How has it changed?
[00:05:41.560 --> 00:05:42.560]   It changed a lot.
[00:05:42.560 --> 00:05:48.320]   So the book and you're going to last this chapter pre-tech-less era is how I call this.
[00:05:48.320 --> 00:05:49.320]   That's me, pre-history.
[00:05:49.320 --> 00:05:51.400]   You might as well just say ancient times.
[00:05:51.400 --> 00:05:52.400]   Okay.
[00:05:52.400 --> 00:05:58.920]   So it's actually starting from the 80s till now to show the difference in the power relations
[00:05:58.920 --> 00:06:05.040]   between the tech giants and the media and the PR practices and how tech journalists used
[00:06:05.040 --> 00:06:06.840]   to work.
[00:06:06.840 --> 00:06:12.000]   And also, of course, the state of mind that was more utopian than dystopian.
[00:06:12.000 --> 00:06:18.240]   And then in the tech-less, which you asked about, is the roots of the change and the
[00:06:18.240 --> 00:06:20.200]   correct respect of the coverage?
[00:06:20.200 --> 00:06:26.120]   Yeah, we actually talk about that a lot on this show because I was certainly a tech utopian.
[00:06:26.120 --> 00:06:27.120]   I was not.
[00:06:27.120 --> 00:06:32.920]   I took great pride and pains not to be a flack for the tech companies.
[00:06:32.920 --> 00:06:33.920]   Yeah.
[00:06:33.920 --> 00:06:34.920]   You were never a fanboy.
[00:06:34.920 --> 00:06:37.920]   No, I was sort of myself representing the user.
[00:06:37.920 --> 00:06:44.760]   And often that was in the face of complete mistreatment by the tech industry.
[00:06:44.760 --> 00:06:47.720]   But at the same time, and I think you were kind of the same way too, Jeff, I was pretty
[00:06:47.720 --> 00:06:49.040]   optimistic.
[00:06:49.040 --> 00:06:52.080]   You might still be about, especially the internet.
[00:06:52.080 --> 00:06:57.720]   I still am, but the difference is I think I confess the problem with the optimism is
[00:06:57.720 --> 00:07:00.720]   that it left us vulnerable to the manipulation.
[00:07:00.720 --> 00:07:03.800]   Yeah, you're probably right.
[00:07:03.800 --> 00:07:08.320]   And of course, I paired up initially with the John C. Devorak, whose whole shtick was
[00:07:08.320 --> 00:07:10.320]   tech cynicism.
[00:07:10.320 --> 00:07:13.840]   Yeah, like this will never work.
[00:07:13.840 --> 00:07:14.840]   That's not.
[00:07:14.840 --> 00:07:18.200]   In fact, he got a lot of heat very famously when the Macintosh came out for saying nobody
[00:07:18.200 --> 00:07:19.200]   needs a mouse.
[00:07:19.200 --> 00:07:20.200]   What's that up?
[00:07:20.200 --> 00:07:22.280]   That's stupid.
[00:07:22.280 --> 00:07:25.400]   But what I learned, but working with John is generally he was right.
[00:07:25.400 --> 00:07:31.920]   You know, about 80% of the time, any new innovation really was stupid in the long run.
[00:07:31.920 --> 00:07:39.400]   So I learned to temper my wide-eyed, you know, I guess Pollyanna-ish look at technology with
[00:07:39.400 --> 00:07:40.400]   this.
[00:07:40.400 --> 00:07:41.400]   Right.
[00:07:41.400 --> 00:07:42.400]   So there was a shift in what's cynicism.
[00:07:42.400 --> 00:07:43.400]   Yeah.
[00:07:43.400 --> 00:07:48.800]   What's fascinating about Neurids research is that she pegs, I love her talk about this,
[00:07:48.800 --> 00:07:51.480]   but she pegs a moment when it changed.
[00:07:51.480 --> 00:07:52.840]   Oh, that's what fascinated me.
[00:07:52.840 --> 00:07:55.200]   I didn't really get that there was a moment.
[00:07:55.200 --> 00:07:56.200]   Over to you, Neurid.
[00:07:56.200 --> 00:07:58.040]   When did the honeymoon end?
[00:07:58.040 --> 00:07:59.040]   Hmm.
[00:07:59.040 --> 00:08:00.480]   November 2016.
[00:08:00.480 --> 00:08:03.040]   Do you have a date?
[00:08:03.040 --> 00:08:04.040]   Wow.
[00:08:04.040 --> 00:08:05.040]   In November 2016.
[00:08:05.040 --> 00:08:06.040]   Wow.
[00:08:06.040 --> 00:08:07.040]   Really?
[00:08:07.040 --> 00:08:08.040]   November 2016.
[00:08:08.040 --> 00:08:09.040]   I have to check my calendar.
[00:08:09.040 --> 00:08:10.040]   What happened in November 2016?
[00:08:10.040 --> 00:08:11.040]   Oh, what happened?
[00:08:11.040 --> 00:08:14.000]   Donald Trump became the president.
[00:08:14.000 --> 00:08:16.320]   Oh, okay.
[00:08:16.320 --> 00:08:17.320]   So the election-
[00:08:17.320 --> 00:08:18.320]   And you should shift there.
[00:08:18.320 --> 00:08:22.160]   The election of Trump in November of 2016.
[00:08:22.160 --> 00:08:29.400]   How did that, but how would that affect our coverage as a tech press of technology?
[00:08:29.400 --> 00:08:37.920]   So first, let's say the technology became much more politicized, but we put that aside.
[00:08:37.920 --> 00:08:42.560]   The tech people, whether they were journalists or workers in the companies, they were all
[00:08:42.560 --> 00:08:49.160]   in the state of reckoning with their influence and asking, "How did we get here?"
[00:08:49.160 --> 00:08:53.040]   And then everybody started to blame the platforms for the rights better.
[00:08:53.040 --> 00:08:54.040]   Oh, interesting.
[00:08:54.040 --> 00:08:55.040]   Things like that.
[00:08:55.040 --> 00:08:59.640]   And then it all became more critical.
[00:08:59.640 --> 00:09:02.320]   You did content analysis, right?
[00:09:02.320 --> 00:09:05.760]   You did analysis of the actual coverage.
[00:09:05.760 --> 00:09:07.800]   So I'm going to share something with you, Nari.
[00:09:07.800 --> 00:09:11.160]   And if you had interviewed me for this book, I would have shared this with you.
[00:09:11.160 --> 00:09:15.280]   I wrote this and sent this as a memo to our staff.
[00:09:15.280 --> 00:09:17.240]   The memo is called "Twit After The Election."
[00:09:17.240 --> 00:09:19.440]   Oh, I never knew this.
[00:09:19.440 --> 00:09:20.440]   Yeah, yeah.
[00:09:20.440 --> 00:09:21.440]   I don't think I sent it to you.
[00:09:21.440 --> 00:09:23.560]   I think I sent it to our on-air hosts and so forth.
[00:09:23.560 --> 00:09:28.680]   And in other words, I said, I was spending a lot of time talking with family co-workers,
[00:09:28.680 --> 00:09:32.760]   friends and fans about last Tuesday's election and how it might affect what we do and say
[00:09:32.760 --> 00:09:36.160]   "Twit," I'm curious, Nari, if this is consonant with your theory.
[00:09:36.160 --> 00:09:42.760]   In other words, what is our responsibility as broadcasters at this time?
[00:09:42.760 --> 00:09:46.680]   So I reiterated our mission statement, "Twit exists to serve and engage a global community
[00:09:46.680 --> 00:09:50.920]   of tech enthusiasts by giving them the information they need to use tech to make their lives
[00:09:50.920 --> 00:09:51.920]   better."
[00:09:51.920 --> 00:09:54.680]   I said, "We have a global, smart, diverse audience.
[00:09:54.680 --> 00:09:57.480]   Some in our community are thrilled with the results of the election, many are not.
[00:09:57.480 --> 00:10:02.320]   I don't think we serve anyone by complaining about how it turned out or looking for fault
[00:10:02.320 --> 00:10:03.760]   or blame.
[00:10:03.760 --> 00:10:08.000]   So I didn't want us to say, "Oh, it's the fault of big tech for the result."
[00:10:08.000 --> 00:10:13.280]   Politics per se is not our beat and not why our community comes to us.
[00:10:13.280 --> 00:10:16.960]   I suggest we try to stick to tech as much as possible.
[00:10:16.960 --> 00:10:24.040]   Then a lot of this was, how do we incorporate our political feelings and beliefs into what
[00:10:24.040 --> 00:10:26.600]   we talk about as tech journalists?
[00:10:26.600 --> 00:10:30.280]   And I think we keep Jarvis from getting rid of all of our listeners.
[00:10:30.280 --> 00:10:31.760]   Well, I should have sent this to you, Jeff.
[00:10:31.760 --> 00:10:35.640]   I propose we address politics only when there is a technology angle and it's appropriate
[00:10:35.640 --> 00:10:36.640]   to the show.
[00:10:36.640 --> 00:10:38.680]   Does Facebook have an obl-- this is 2016.
[00:10:38.680 --> 00:10:41.280]   Does Facebook have an obligation to block fake news?
[00:10:41.280 --> 00:10:43.400]   What was the role of Twitter in Trump's election?
[00:10:43.400 --> 00:10:45.800]   Are Trump's policies good or bad for Silicon Valley?
[00:10:45.800 --> 00:10:50.560]   Twig and Twig will inevitably broach these subjects.
[00:10:50.560 --> 00:10:52.000]   We did during Obama's administration.
[00:10:52.000 --> 00:10:56.680]   We'll continue to do so now.
[00:10:56.680 --> 00:11:02.480]   And then I also addressed conspiracy theory even at this time.
[00:11:02.480 --> 00:11:06.080]   There's one particularly thorny area where you answers are not always so easily distinguishing
[00:11:06.080 --> 00:11:13.120]   fact from fiction from faith.
[00:11:13.120 --> 00:11:17.320]   So I talked about climate.
[00:11:17.320 --> 00:11:18.400]   We have an audience and a voice.
[00:11:18.400 --> 00:11:21.520]   We do have a responsibility not to maintain a false neutrality in one case.
[00:11:21.520 --> 00:11:27.760]   There's a clear, bright language we can never cross and I said racism, discrimination, sexual
[00:11:27.760 --> 00:11:32.200]   preference, gender choice and all of those things.
[00:11:32.200 --> 00:11:40.960]   So I guess agree with what you are saying, Nuri, is I did see the election as something
[00:11:40.960 --> 00:11:46.520]   that we had to consider as a tech journalistic entity.
[00:11:46.520 --> 00:11:51.480]   So more than that and more than the content analysis that Jeff mentioned, what is done
[00:11:51.480 --> 00:11:53.800]   and I'm a big data analytic kind of a girl.
[00:11:53.800 --> 00:11:59.960]   So I looked at the companies and their picks during the year and I analyzed those picks
[00:11:59.960 --> 00:12:05.200]   of covers like the main, the biggest stories they have during the years.
[00:12:05.200 --> 00:12:11.840]   And in the what I call pre-tech clash, most of them were innovation journalism or product
[00:12:11.840 --> 00:12:12.840]   journalism.
[00:12:12.840 --> 00:12:17.200]   And by that I mean product launches either software or hardware.
[00:12:17.200 --> 00:12:18.200]   We did a lot of that.
[00:12:18.200 --> 00:12:19.200]   Yep.
[00:12:19.200 --> 00:12:20.200]   Yep.
[00:12:20.200 --> 00:12:25.160]   And so of course all the IPOs and you know, M&As and things like that.
[00:12:25.160 --> 00:12:29.720]   So that was the normal big headlines in the tech news.
[00:12:29.720 --> 00:12:38.720]   But when I analyzed 2017, most picks were negative, text candles and most of them were
[00:12:38.720 --> 00:12:46.560]   like fake news after the Las Vegas shooting which involves Twitter, Google and Facebook.
[00:12:46.560 --> 00:12:51.800]   And we had the Russian interference and all the investigations starting in Congress.
[00:12:51.800 --> 00:12:54.800]   So all those headlines were not there before, right?
[00:12:54.800 --> 00:13:01.000]   So we had investigations and fines and privacy issues and all of them were in the tech coverage
[00:13:01.000 --> 00:13:02.640]   all the year, all the time.
[00:13:02.640 --> 00:13:03.640]   But they were less visible.
[00:13:03.640 --> 00:13:04.640]   Right.
[00:13:04.640 --> 00:13:07.400]   Because there was less coverage of those issues.
[00:13:07.400 --> 00:13:14.400]   And the shift that I'm showing in the book is that since 2017, those are the salient, you
[00:13:14.400 --> 00:13:16.920]   know, the major stories in the tech coverage.
[00:13:16.920 --> 00:13:17.920]   I think that's fair.
[00:13:17.920 --> 00:13:22.000]   I'm looking at our rundowns from late 2016 and early 2017.
[00:13:22.000 --> 00:13:25.640]   I have a record of every show we've done.
[00:13:25.640 --> 00:13:33.960]   And I think that's actually fair that it did somewhat change our kind of focus.
[00:13:33.960 --> 00:13:39.640]   But in my defense, I always felt a little guilty about just talking about shiny things.
[00:13:39.640 --> 00:13:45.240]   And I think that happened earlier for me because I started becoming aware of the climate consequences
[00:13:45.240 --> 00:13:50.640]   of filling landfills with two-year-old smartphones.
[00:13:50.640 --> 00:13:52.600]   And so I think we kind of tried to downplay that.
[00:13:52.600 --> 00:13:55.320]   I certainly addressed those issues in the years before that.
[00:13:55.320 --> 00:13:56.320]   But I think you're exactly right.
[00:13:56.320 --> 00:14:02.440]   I think that we did shift our coverage became less about what's the next new thing and what's
[00:14:02.440 --> 00:14:08.080]   the big IPO and more about how tech influences society.
[00:14:08.080 --> 00:14:11.040]   And I think you're right off and negatively.
[00:14:11.040 --> 00:14:14.400]   And Jeff's always yelling me for that, right, Jeff?
[00:14:14.400 --> 00:14:16.640]   Yeah, I am.
[00:14:16.640 --> 00:14:18.240]   Where do you think it goes, near it?
[00:14:18.240 --> 00:14:20.200]   Do you think it changes again?
[00:14:20.200 --> 00:14:26.400]   Or do you think this is the path we're going to be on for the foreseeable future?
[00:14:26.400 --> 00:14:29.520]   So the theme of the book is pendulum swings.
[00:14:29.520 --> 00:14:34.320]   And I'm showing how in the pre-tech last year we had several of them.
[00:14:34.320 --> 00:14:39.720]   Like think about the positive coverage in the dot com bubble and then after that, how
[00:14:39.720 --> 00:14:41.920]   would the coverage after the burst?
[00:14:41.920 --> 00:14:46.480]   I mean, the tech CEOs were God and then they became dog, right?
[00:14:46.480 --> 00:14:48.320]   So we had that before.
[00:14:48.320 --> 00:14:54.320]   But what I'm showing since the tech version up is that even with the pandemic and we had
[00:14:54.320 --> 00:14:57.760]   this very short second honeymoon of more or so.
[00:14:57.760 --> 00:14:58.760]   Yeah.
[00:14:58.760 --> 00:14:59.760]   Great for the economic.
[00:14:59.760 --> 00:15:00.760]   The zoom honeymoon.
[00:15:00.760 --> 00:15:01.760]   Yeah.
[00:15:01.760 --> 00:15:08.800]   It was so short and all the techless subject and issues resurfaced again very quickly.
[00:15:08.800 --> 00:15:11.560]   So actually the techless is here to stay.
[00:15:11.560 --> 00:15:15.560]   So we went from one extreme to the other, but this extreme is here.
[00:15:15.560 --> 00:15:16.560]   How do you measure?
[00:15:16.560 --> 00:15:18.120]   We're not going back to the other one, definitely.
[00:15:18.120 --> 00:15:19.120]   How do you measure?
[00:15:19.120 --> 00:15:20.200]   Do you do content analysis?
[00:15:20.200 --> 00:15:25.960]   How do you, since you're data driven, what is, what are the data points for this?
[00:15:25.960 --> 00:15:32.080]   So I collected the tech coverage of the big tech companies from both traditional media
[00:15:32.080 --> 00:15:33.760]   and tech blogs.
[00:15:33.760 --> 00:15:37.840]   And then I mapped their, as I said, the yearly timeline.
[00:15:37.840 --> 00:15:42.800]   After that, I looked at each really big story and analyzed their response.
[00:15:42.800 --> 00:15:48.120]   So I took the press releases, spokesperson statement to journalists and everything that
[00:15:48.120 --> 00:15:52.800]   I could use about how they reacted to everything that's happening.
[00:15:52.800 --> 00:15:53.800]   And how then--
[00:15:53.800 --> 00:15:55.040]   The reaction is a data point as well.
[00:15:55.040 --> 00:15:59.600]   So responses backlist as well, because I'm also showing the coverage of how the journalists
[00:15:59.600 --> 00:16:03.000]   look at those responses and say it's BS.
[00:16:03.000 --> 00:16:08.360]   And so it's back and forth between how the tech companies present the stories and how
[00:16:08.360 --> 00:16:09.800]   the media does it.
[00:16:09.800 --> 00:16:15.120]   So it's not just the big data shows with the big stories, but then the content analysis
[00:16:15.120 --> 00:16:17.760]   go deeper into the actual content.
[00:16:17.760 --> 00:16:21.200]   Well Jeff knows I eliminated the Google change log right about that time.
[00:16:21.200 --> 00:16:23.360]   I didn't want to talk about that anymore.
[00:16:23.360 --> 00:16:25.360]   He made me bring it back, so.
[00:16:25.360 --> 00:16:26.360]   I didn't.
[00:16:26.360 --> 00:16:28.880]   Let me ask you two questions there, near it.
[00:16:28.880 --> 00:16:30.160]   I'm curious from that.
[00:16:30.160 --> 00:16:33.440]   One is from the two perspectives you just mentioned.
[00:16:33.440 --> 00:16:42.280]   On the journalist side, did they feel guilty and had to overcompensate for their utopianism
[00:16:42.280 --> 00:16:45.200]   once tech became a whipping boy?
[00:16:45.200 --> 00:16:53.080]   On the tech side, did the tech people understand the problem they had with their hubris and
[00:16:53.080 --> 00:16:58.080]   attitude and the people didn't like them?
[00:16:58.080 --> 00:17:02.680]   Yeah, so let me answer that in a few ways.
[00:17:02.680 --> 00:17:05.080]   There are many factors that play here.
[00:17:05.080 --> 00:17:08.200]   So first there's the power relations between the two groups.
[00:17:08.200 --> 00:17:12.880]   So when we were in the phase of innovation journalism and everything is shiny and cool
[00:17:12.880 --> 00:17:19.560]   and innovations are basically good for society, then the tech companies had this power and
[00:17:19.560 --> 00:17:24.080]   we all know they're in famous secrecy and limited access and the tech journalists just
[00:17:24.080 --> 00:17:28.160]   want to be, as I said, closer to God.
[00:17:28.160 --> 00:17:33.040]   And that made some of the tension that we have today I think.
[00:17:33.040 --> 00:17:42.680]   And then when it's moved to tech is negative and ruined society phase, tech are more the
[00:17:42.680 --> 00:17:47.360]   offensive and they need always to react about their new scandal of the week, right?
[00:17:47.360 --> 00:17:54.520]   So the tech journalists saw that when they dig up and find more harm and have real impact
[00:17:54.520 --> 00:18:00.520]   in the world, it's actually good journalism and more journalists join the effort.
[00:18:00.520 --> 00:18:07.560]   So now the relationship is much different.
[00:18:07.560 --> 00:18:14.920]   I'm curious to address you.
[00:18:14.920 --> 00:18:17.360]   She started in the dark side.
[00:18:17.360 --> 00:18:19.440]   She started in PR.
[00:18:19.440 --> 00:18:23.800]   Went to the late side and then went to the ivory tower.
[00:18:23.800 --> 00:18:25.760]   What made you decide to do research on this?
[00:18:25.760 --> 00:18:30.520]   How did you end up choosing the academic?
[00:18:30.520 --> 00:18:38.640]   Yeah, so when I covered the tech ecosystem in Israel that was in the early 2000s, we were
[00:18:38.640 --> 00:18:42.720]   in the innovation journalism phase and everything was exciting and Israel is the startup nation
[00:18:42.720 --> 00:18:47.120]   and all the coverage was about all the cool things coming out of Israel.
[00:18:47.120 --> 00:18:54.040]   And right about that time I finished my MA in communication and political science and
[00:18:54.040 --> 00:18:58.760]   when I looked for academic studies about my occupation, my passion, tech journalism,
[00:18:58.760 --> 00:19:06.320]   I found this depressing void of almost nothing about this field and I was like, why does
[00:19:06.320 --> 00:19:13.560]   nobody focusing on the tech media agenda and the interplay there between all the forces?
[00:19:13.560 --> 00:19:19.080]   So basically I decided to do it myself and that resulted with my PhD in communication,
[00:19:19.080 --> 00:19:20.720]   researching the tech media.
[00:19:20.720 --> 00:19:26.480]   But that was tough a decade ago because all my colleagues and professors are in political
[00:19:26.480 --> 00:19:27.800]   communication.
[00:19:27.800 --> 00:19:33.280]   So one of the reviewers actually wrote, who cares about tech news?
[00:19:33.280 --> 00:19:35.280]   They're not important.
[00:19:35.280 --> 00:19:36.280]   Wow.
[00:19:36.280 --> 00:19:39.120]   FII Leo, they're not important.
[00:19:39.120 --> 00:19:41.800]   Well, I think actually, you know, I understand why they think that.
[00:19:41.800 --> 00:19:47.920]   I think tech news is often viewed in the same way that, you know, automobile food news
[00:19:47.920 --> 00:19:52.920]   is where it's, you know, car and driver is not considered a journalistic entity as much
[00:19:52.920 --> 00:19:57.240]   as, you know, an arm of the big three automakers.
[00:19:57.240 --> 00:20:01.680]   But that's why I've from day one, and I think maybe I'm a little bit of a maverick in this
[00:20:01.680 --> 00:20:08.200]   business, very consciously decided not to do that to kind of renovate or rejuvenate.
[00:20:08.200 --> 00:20:14.960]   Well, to use your retinalgies, if autos had been covered as a societal phenomenon with
[00:20:14.960 --> 00:20:20.360]   their impact on cities and on life in America and on pollution and such would have been
[00:20:20.360 --> 00:20:22.560]   a big difference, but they weren't.
[00:20:22.560 --> 00:20:23.560]   Yeah.
[00:20:23.560 --> 00:20:30.280]   So just podcasting happened and blogs to, there were people who were not mainstream tech journalists
[00:20:30.280 --> 00:20:33.760]   who absolutely had an adversarial relationship.
[00:20:33.760 --> 00:20:38.920]   But I don't, Nariit, you probably don't know this, but I don't talk to PR people ever.
[00:20:38.920 --> 00:20:40.400]   I make a point of it.
[00:20:40.400 --> 00:20:43.080]   We don't do loners for the most part.
[00:20:43.080 --> 00:20:47.320]   And sometimes we have to, but we really, I really endeavor to keep us at arms length
[00:20:47.320 --> 00:20:51.040]   from the tech companies and from public relations firms.
[00:20:51.040 --> 00:20:54.080]   I have a strong antipathy towards them.
[00:20:54.080 --> 00:20:57.120]   So you're not alone in this.
[00:20:57.120 --> 00:20:58.120]   Yeah.
[00:20:58.120 --> 00:21:02.800]   Well, now it's probably a little bit more common, but for 40 years, I've been making
[00:21:02.800 --> 00:21:06.440]   a point of that because I always made sure it was unclear in my mind.
[00:21:06.440 --> 00:21:11.480]   You heard about our mission statement that I was an ombudsman for the user, not for the
[00:21:11.480 --> 00:21:14.120]   tech industry.
[00:21:14.120 --> 00:21:17.320]   But I can see why your professor would have looked at this and said, Oh, yeah, well, is
[00:21:17.320 --> 00:21:22.320]   there a name for that Jeff genre publishing or niche publishing?
[00:21:22.320 --> 00:21:24.760]   Well, we could say the service journalism is what we call it.
[00:21:24.760 --> 00:21:25.760]   Yeah, service journalism.
[00:21:25.760 --> 00:21:26.760]   That's it.
[00:21:26.760 --> 00:21:28.920]   And I think for now, I have a very different view.
[00:21:28.920 --> 00:21:31.440]   I think journalism should be a service as a whole.
[00:21:31.440 --> 00:21:34.440]   So I think that's a, that's a, but who do they serve as the question?
[00:21:34.440 --> 00:21:37.120]   They speak truth to power, right?
[00:21:37.120 --> 00:21:41.800]   And you know, what is it?
[00:21:41.800 --> 00:21:46.720]   What is the role of the journalist is to make the discomfort, the comfortable.
[00:21:46.720 --> 00:21:47.920]   Yeah, yeah, yeah, yeah.
[00:21:47.920 --> 00:21:50.520]   You know, all of that.
[00:21:50.520 --> 00:21:54.880]   And I think that perhaps service journalism has never viewed as, that's never been viewed
[00:21:54.880 --> 00:22:00.240]   as its role, its role, just like belt weight journalism in Washington, DC, its role is
[00:22:00.240 --> 00:22:01.760]   access.
[00:22:01.760 --> 00:22:05.440]   And you can't risk access by speaking truth to power.
[00:22:05.440 --> 00:22:06.440]   It doesn't work.
[00:22:06.440 --> 00:22:07.440]   Go ahead.
[00:22:07.440 --> 00:22:08.440]   I'm sorry.
[00:22:08.440 --> 00:22:09.720]   Is anyone even an actual go ahead?
[00:22:09.720 --> 00:22:15.240]   Has anyone even discussed in the idea that these big journalistic companies have shareholders
[00:22:15.240 --> 00:22:21.200]   stand or two, and regardless of how great these writers are, it still comes down to
[00:22:21.200 --> 00:22:22.200]   any clicks.
[00:22:22.200 --> 00:22:26.600]   So editors are going to have to make things clickable and sometimes put in something
[00:22:26.600 --> 00:22:33.400]   out there that's just a little bit off the wall is what's going to get those clicks.
[00:22:33.400 --> 00:22:39.000]   Are you fine and stuff like that in your, in your day, in your research?
[00:22:39.000 --> 00:22:49.440]   Well, I think you're touching the how, well, tech journalists blame the tech platforms
[00:22:49.440 --> 00:22:58.080]   for their change in business models and how they do things and some blame the video for
[00:22:58.080 --> 00:23:01.400]   going to all these click bites due to technology.
[00:23:01.400 --> 00:23:08.840]   But that's not actually, I think, a huge part of the story, if you ask me.
[00:23:08.840 --> 00:23:16.200]   Maybe Jeff, what's your number?
[00:23:16.200 --> 00:23:17.200]   I don't know.
[00:23:17.200 --> 00:23:25.560]   I think that we feed off of conflict, which is what I think Ants Point really is.
[00:23:25.560 --> 00:23:27.960]   And editor looks and said, oh, good.
[00:23:27.960 --> 00:23:28.960]   There's an enemy.
[00:23:28.960 --> 00:23:30.200]   There's a bad guy.
[00:23:30.200 --> 00:23:31.920]   There's a victim.
[00:23:31.920 --> 00:23:33.920]   And we can portray it that way.
[00:23:33.920 --> 00:23:38.800]   And I'll agree with Ant that I think that that becomes, it doesn't matter what the fight
[00:23:38.800 --> 00:23:39.800]   is.
[00:23:39.800 --> 00:23:40.800]   Oh, good.
[00:23:40.800 --> 00:23:41.800]   There's a fight.
[00:23:41.800 --> 00:23:42.800]   Let's promote it.
[00:23:42.800 --> 00:23:43.800]   Is that what you're just kind of saying, Ants?
[00:23:43.800 --> 00:23:44.800]   Right.
[00:23:44.800 --> 00:23:47.520]   And that means I think that, yeah, I totally agree that if there is any bias in the media
[00:23:47.520 --> 00:23:48.840]   is that it's pro-conflict.
[00:23:48.840 --> 00:23:49.840]   Yes.
[00:23:49.840 --> 00:23:51.680]   I think it's conflict.
[00:23:51.680 --> 00:23:52.680]   Absolutely.
[00:23:52.680 --> 00:23:57.560]   That's why Leah, when I fight so much, it's just for that reason, just we do it for the
[00:23:57.560 --> 00:23:58.560]   close.
[00:23:58.560 --> 00:24:02.160]   Well, yeah, yeah, I won it works.
[00:24:02.160 --> 00:24:07.120]   That's really ruined all journalism, if you ask me.
[00:24:07.120 --> 00:24:09.280]   And to also, that's fine.
[00:24:09.280 --> 00:24:15.640]   This is why we have articles such as the evil list listing the third and most dangerous
[00:24:15.640 --> 00:24:21.440]   evil companies in tech, because that's like the headline to put on such a story.
[00:24:21.440 --> 00:24:22.440]   That's doubly bad.
[00:24:22.440 --> 00:24:24.520]   It's a listical and it's the evil list.
[00:24:24.520 --> 00:24:25.520]   It's bad.
[00:24:25.520 --> 00:24:27.320]   Every respect possible.
[00:24:27.320 --> 00:24:28.320]   Let me take a little break.
[00:24:28.320 --> 00:24:29.320]   Hold on a second, Jeff.
[00:24:29.320 --> 00:24:30.320]   Hold that question.
[00:24:30.320 --> 00:24:31.320]   Hold that thought.
[00:24:31.320 --> 00:24:32.320]   Break our guest.
[00:24:32.320 --> 00:24:33.480]   This is great.
[00:24:33.480 --> 00:24:37.400]   I'm really thrilled to have her even though I'm breaking my heart.
[00:24:37.400 --> 00:24:42.960]   Dr. Nierit Weissblatt is the author of the Techlash and the Tech Crisis Communication
[00:24:42.960 --> 00:24:45.720]   Techlashbook.com.
[00:24:45.720 --> 00:24:51.240]   It comes out March 24th, but you can pre-order it on Amazon right now.
[00:24:51.240 --> 00:24:53.000]   It's great to have you, Nierit.
[00:24:53.000 --> 00:24:58.480]   And we will be back with more in just a second, but it's time for a little word from our sponsor.
[00:24:58.480 --> 00:25:01.200]   In this case, it's Melissa.
[00:25:01.200 --> 00:25:02.200]   Did you know?
[00:25:02.200 --> 00:25:05.280]   Have you ever forgotten to check the date in a carton of milk?
[00:25:05.280 --> 00:25:07.000]   It just happened to me just the other day.
[00:25:07.000 --> 00:25:11.680]   My coffee tasted a little strange and I realized, "Oh, I know why."
[00:25:11.680 --> 00:25:18.720]   Like milk, if you've got customer data, customer lists, address lists, your customer data goes
[00:25:18.720 --> 00:25:19.720]   bad.
[00:25:19.720 --> 00:25:23.840]   In fact, on average, about 30% goes bad every year.
[00:25:23.840 --> 00:25:26.400]   It's slowly rotting away.
[00:25:26.400 --> 00:25:28.040]   Melissa is the address expert.
[00:25:28.040 --> 00:25:32.200]   Make sure your data is accurate and current so you reach the right customers.
[00:25:32.200 --> 00:25:34.560]   They've been doing this for a long time for 35 years.
[00:25:34.560 --> 00:25:37.480]   They've helped businesses maintain fresh data.
[00:25:37.480 --> 00:25:39.280]   It's not just addresses, by the way.
[00:25:39.280 --> 00:25:44.120]   You can verify addresses, emails, phone numbers, and names.
[00:25:44.120 --> 00:25:45.920]   You can do it in a variety of ways, too.
[00:25:45.920 --> 00:25:48.160]   You can do it kind of on demand.
[00:25:48.160 --> 00:25:49.520]   They have a secure FTP server.
[00:25:49.520 --> 00:25:54.200]   You can upload your address list to contact list to or customer list to and download it
[00:25:54.200 --> 00:25:55.480]   fixed.
[00:25:55.480 --> 00:25:59.120]   But more often people use the real-time version of Melissa.
[00:25:59.120 --> 00:26:00.880]   Melissa can be a web service.
[00:26:00.880 --> 00:26:04.720]   They have a very strong API, it can be software as a service.
[00:26:04.720 --> 00:26:11.280]   That means a lot of companies integrate Melissa into their customer service portals or into
[00:26:11.280 --> 00:26:14.400]   their data entry for customers when the customer is giving an address.
[00:26:14.400 --> 00:26:17.720]   I can't tell you how many times I've transposed the numbers in my home address.
[00:26:17.720 --> 00:26:24.320]   Melissa fixes that and a lot more for 240 plus countries and territories.
[00:26:24.320 --> 00:26:28.680]   You can do it right at the point of entry, which means you're saving time, you're saving
[00:26:28.680 --> 00:26:32.080]   money from day one.
[00:26:32.080 --> 00:26:36.360]   Only valid billing and shipping addresses are captured and used in your system.
[00:26:36.360 --> 00:26:40.560]   They can add consumer demographic information to public records like property and mortgage
[00:26:40.560 --> 00:26:43.480]   data, marital status, social media handles.
[00:26:43.480 --> 00:26:49.200]   You can really develop a rich customer database so you can understand and know your customer
[00:26:49.200 --> 00:26:50.200]   better.
[00:26:50.200 --> 00:26:55.880]   Because they are totally committed to data security, privacy and compliance.
[00:26:55.880 --> 00:26:59.360]   Their HIPAA compliant, GDPR compliant, SOC2 compliant.
[00:26:59.360 --> 00:27:05.080]   They undergo continuous independent security audits so you know they keep your data safe.
[00:27:05.080 --> 00:27:11.280]   They're utterly dedicated to your data security and have the strongest controls, industry
[00:27:11.280 --> 00:27:15.440]   best practice safeguards while processing your data.
[00:27:15.440 --> 00:27:18.920]   Melissa's flexible deployment options mean you can use it in any way you want on-prem
[00:27:18.920 --> 00:27:21.840]   in the cloud FTP.
[00:27:21.840 --> 00:27:22.840]   I want you to try it.
[00:27:22.840 --> 00:27:25.840]   Over 10,000 businesses trust the address experts.
[00:27:25.840 --> 00:27:29.640]   There's no reason for you to put up with sour customer data.
[00:27:29.640 --> 00:27:35.400]   Go to Melissa.com/twit right now, M-E-L-I-S-S-A.com/twit.
[00:27:35.400 --> 00:27:36.760]   They actually have a developer portal.
[00:27:36.760 --> 00:27:42.480]   You can take a look at their APIs, log on, sign up, start playing in the sandbox anytime
[00:27:42.480 --> 00:27:45.960]   and you'll automatically get 1,000 records cleaned for free.
[00:27:45.960 --> 00:27:50.600]   But only if you use that address, Melissa.com/twit.
[00:27:50.600 --> 00:27:55.000]   Take your Christmas card list or some other list and give it a try and see what they can
[00:27:55.000 --> 00:27:56.000]   do.
[00:27:56.000 --> 00:27:57.000]   It's pretty impressive.
[00:27:57.000 --> 00:28:00.120]   Melissa, the address experts at Melissa.com/twit.
[00:28:00.120 --> 00:28:03.600]   Thank you, Melissa, for supporting this week in Google.
[00:28:03.600 --> 00:28:08.120]   Thank you, dear listener, for supporting us by using that address, Melissa.com/twit.
[00:28:08.120 --> 00:28:11.720]   Sorry, Jeff, didn't mean to interrupt.
[00:28:11.720 --> 00:28:12.720]   Continue.
[00:28:12.720 --> 00:28:14.240]   Do you remember your question?
[00:28:14.240 --> 00:28:17.120]   I hope I didn't knock it out of your head.
[00:28:17.120 --> 00:28:18.120]   Turn him up.
[00:28:18.120 --> 00:28:19.120]   Turn him up.
[00:28:19.120 --> 00:28:20.120]   I don't know.
[00:28:20.120 --> 00:28:21.120]   My fault.
[00:28:21.120 --> 00:28:22.120]   My fault.
[00:28:22.120 --> 00:28:23.120]   Okay.
[00:28:23.120 --> 00:28:24.120]   Okay.
[00:28:24.120 --> 00:28:25.120]   Now I can.
[00:28:25.120 --> 00:28:26.120]   Yeah, no problem.
[00:28:26.120 --> 00:28:27.120]   I'm just curious.
[00:28:27.120 --> 00:28:32.040]   If you were in charge of com at a tech company today, pick your tech company and they're
[00:28:32.040 --> 00:28:33.040]   it.
[00:28:33.040 --> 00:28:34.040]   Is there any way out for them?
[00:28:34.040 --> 00:28:35.040]   What would you do?
[00:28:35.040 --> 00:28:37.480]   Is there a new kind of honesty and transparency?
[00:28:37.480 --> 00:28:41.800]   Will they never be believed and trusted?
[00:28:41.800 --> 00:28:45.680]   So I won't be in that position, I think.
[00:28:45.680 --> 00:28:49.760]   It's one of the most difficult jobs in the world right now.
[00:28:49.760 --> 00:28:55.240]   But yeah, so as you remember from the book, what I found is they usually put out the same
[00:28:55.240 --> 00:28:59.040]   playbook, what I call the tech PR template for crisis.
[00:28:59.040 --> 00:29:01.480]   They always do the same responses.
[00:29:01.480 --> 00:29:06.000]   And one of the book's messages, I think, is that it's, of course, not enough because
[00:29:06.000 --> 00:29:10.560]   I documented that it's back last heavily.
[00:29:10.560 --> 00:29:12.320]   So should they react?
[00:29:12.320 --> 00:29:13.960]   It's a brilliant question.
[00:29:13.960 --> 00:29:20.520]   I think one of the best quotes in the books are yours, actually, attaching that we look
[00:29:20.520 --> 00:29:23.400]   at tech as black boxes producing black boxes.
[00:29:23.400 --> 00:29:28.160]   So yes, transparency and they need to educate more about the complexity of the nuances,
[00:29:28.160 --> 00:29:36.720]   the issues they're dealing with and showing the humanity inside and things of that nature.
[00:29:36.720 --> 00:29:40.520]   But also I think at that time when we see all the wars between them, it's also a very
[00:29:40.520 --> 00:29:41.520]   important thing.
[00:29:41.520 --> 00:29:45.400]   So they need to be more united because like there are problems that are dealing with,
[00:29:45.400 --> 00:29:48.720]   it's the whole sector that is dealing with.
[00:29:48.720 --> 00:29:53.880]   And if they won't deal with them together, it's going to be more damage.
[00:29:53.880 --> 00:30:01.000]   Are there any examples you can remember, call the mind of a crisis response done well
[00:30:01.000 --> 00:30:02.000]   by a tech company.
[00:30:02.000 --> 00:30:04.600]   I'm trying to think myself, I can't think of any.
[00:30:04.600 --> 00:30:11.280]   So the thing that there's a no win here because they are doing what the crisis communication
[00:30:11.280 --> 00:30:13.520]   101 tells them to do.
[00:30:13.520 --> 00:30:20.280]   They're specifying what they've done, the good intentions, they've built something
[00:30:20.280 --> 00:30:25.200]   good and they have previous good deeds which they always specify and great policies in
[00:30:25.200 --> 00:30:26.200]   place.
[00:30:26.200 --> 00:30:30.560]   But our product, our platform was manipulated and misused by bad malicious actors.
[00:30:30.560 --> 00:30:39.920]   We always have this victim feeling of we were good and versus the outside malicious entities.
[00:30:39.920 --> 00:30:47.280]   Then the other thing is that they always do those apology tours which I called pseudo apologies.
[00:30:47.280 --> 00:30:48.280]   Because they say we apologize.
[00:30:48.280 --> 00:30:50.760]   What Andrew Cuomo is doing right now.
[00:30:50.760 --> 00:30:55.920]   Is he apologizing or just denying?
[00:30:55.920 --> 00:30:59.520]   I tweeted today that if your apology begins with an if clause, maybe I should shut you
[00:30:59.520 --> 00:31:00.520]   if I did that.
[00:31:00.520 --> 00:31:02.520]   I don't remember doing that.
[00:31:02.520 --> 00:31:04.080]   If you were offended by it.
[00:31:04.080 --> 00:31:07.920]   If in any way that's not the right.
[00:31:07.920 --> 00:31:10.640]   The opportunity for companies these days is data breaches.
[00:31:10.640 --> 00:31:16.560]   Almost every company has to announce, oh gee, I'm sorry, your customer records have been
[00:31:16.560 --> 00:31:18.040]   giving up to hackers.
[00:31:18.040 --> 00:31:22.120]   I mean, clearly Equifax is the exact wrong way to handle that.
[00:31:22.120 --> 00:31:27.440]   I'm trying to think of, because actually maybe not Equifax's way of handling it was making
[00:31:27.440 --> 00:31:30.440]   more money by offering.
[00:31:30.440 --> 00:31:34.000]   So wrong depends on who you're talking to.
[00:31:34.000 --> 00:31:38.000]   If you're a stakeholder, you're pretty happy about it.
[00:31:38.000 --> 00:31:40.720]   I can't think of the reputation on the other hand.
[00:31:40.720 --> 00:31:41.720]   Yeah, that's true.
[00:31:41.720 --> 00:31:43.800]   It hurts the reputation, doesn't it?
[00:31:43.800 --> 00:31:50.800]   But you look at, and I don't want to get ahead of us, but the Google story today.
[00:31:50.800 --> 00:31:52.480]   Well, actually, it's funny.
[00:31:52.480 --> 00:31:55.280]   I was going to actually go into that because that's a perfect example.
[00:31:55.280 --> 00:31:57.080]   I think it fits right in with this.
[00:31:57.080 --> 00:32:00.840]   So Google announced, and it's in the Wall Street Journal of all places.
[00:32:00.840 --> 00:32:04.400]   I don't know, is that Wall Street Journal crowing a little bit?
[00:32:04.400 --> 00:32:09.160]   Because Google's going to have to stop selling ads based on your specific web browsing.
[00:32:09.160 --> 00:32:12.920]   Paul Therat was skeptical earlier on Windows Weekly.
[00:32:12.920 --> 00:32:17.200]   Apparently, Google, and this is, it's one of those things.
[00:32:17.200 --> 00:32:21.040]   Yeah, I'm going to give up smoking next year.
[00:32:21.040 --> 00:32:22.520]   Google, it's March.
[00:32:22.520 --> 00:32:23.800]   Plans next year.
[00:32:23.800 --> 00:32:25.560]   It's March that you could do it this year.
[00:32:25.560 --> 00:32:28.160]   It's more like, it's more like next year.
[00:32:28.160 --> 00:32:31.360]   I have the cure for cancer and you don't.
[00:32:31.360 --> 00:32:34.640]   So Wednesday, I could give it up, but you can.
[00:32:34.640 --> 00:32:39.600]   Google said it plans to stop next year using or investing in.
[00:32:39.600 --> 00:32:44.280]   We're going to continue through 2021, but next year we'll stop investing in tracking
[00:32:44.280 --> 00:32:49.960]   technologies that uniquely identify web users as they move from site to site across the
[00:32:49.960 --> 00:32:50.960]   Internet.
[00:32:50.960 --> 00:32:56.000]   This is one of the many things Google and many, many others do with tracking cookies.
[00:32:56.000 --> 00:33:00.760]   In fact, I highly recommend Steve Gibson's show yesterday.
[00:33:00.760 --> 00:33:02.640]   He called it DNS collusion.
[00:33:02.640 --> 00:33:11.560]   It turns out that of the top thousand websites, 10% of them are using a DNS trick in the
[00:33:11.560 --> 00:33:19.000]   CNAME field to follow you around, not using, I mean, it's really appalling what they're
[00:33:19.000 --> 00:33:20.000]   doing.
[00:33:20.000 --> 00:33:21.000]   It's very sneaky.
[00:33:21.000 --> 00:33:22.080]   It's pretty technical.
[00:33:22.080 --> 00:33:25.920]   So I'll let Steve explain it in the security now.
[00:33:25.920 --> 00:33:34.640]   But the point, I guess, is Google may say, well, we've decided not to use tracking cookies,
[00:33:34.640 --> 00:33:39.000]   but I've always thought Google probably has other means of doing the same thing.
[00:33:39.000 --> 00:33:41.960]   Google has a bottom line to meet.
[00:33:41.960 --> 00:33:43.520]   Yeah, right.
[00:33:43.520 --> 00:33:44.520]   Google's 52%.
[00:33:44.520 --> 00:33:47.280]   But they also have the tool to get there.
[00:33:47.280 --> 00:33:50.280]   They have the first party data.
[00:33:50.280 --> 00:33:51.920]   And they don't need third party data.
[00:33:51.920 --> 00:33:52.920]   Yeah, right.
[00:33:52.920 --> 00:33:57.320]   Pretty pretty because they know where you as a user have gone, point one, point two.
[00:33:57.320 --> 00:34:03.400]   Evidently, they're going to have your local browser is going to kind of type you.
[00:34:03.400 --> 00:34:08.440]   So you're in more control of that, which I've actually argued for for years when I try
[00:34:08.440 --> 00:34:11.360]   to get Google to share kind of types with publishers.
[00:34:11.360 --> 00:34:14.520]   But now Google's going to say we can do that kind of on our own.
[00:34:14.520 --> 00:34:20.560]   So it's perfect example of regulatory capture where everybody screamed, cookies are evil,
[00:34:20.560 --> 00:34:22.080]   third party duty is evil.
[00:34:22.080 --> 00:34:23.080]   We're going to get you Google.
[00:34:23.080 --> 00:34:26.800]   We're going to demonize all that stuff if Google said, oh, OK, no cookies.
[00:34:26.800 --> 00:34:29.760]   And then the publishers say, but we don't have any first party data.
[00:34:29.760 --> 00:34:30.760]   That's not fair.
[00:34:30.760 --> 00:34:36.600]   Google has already responded what I was just talking about reading on in the article.
[00:34:36.600 --> 00:34:42.840]   The company last year said they would stop using third party cookies in 2022.
[00:34:42.840 --> 00:34:48.360]   Now the company's saying neither will it build alternative tracking technologies or use those.
[00:34:48.360 --> 00:34:49.360]   Right.
[00:34:49.360 --> 00:34:50.440]   Or yeah, right.
[00:34:50.440 --> 00:34:53.440]   Or use those being developed by other entities.
[00:34:53.440 --> 00:35:03.480]   Like I would imagine the CNAME collusion, which is offered by Adobe oracle and Salesforce
[00:35:03.480 --> 00:35:06.000]   among others to replace third party cookies for it.
[00:35:06.000 --> 00:35:07.280]   Only add buying tools.
[00:35:07.280 --> 00:35:13.800]   Google says its ad buying tools will use new technologies it has been developing with others
[00:35:13.800 --> 00:35:17.480]   in what it calls a privacy sandbox.
[00:35:17.480 --> 00:35:21.040]   They've been working with publishers on this is regulatory capture right here.
[00:35:21.040 --> 00:35:25.040]   Yeah, six or eight months to target ads without collecting information about individuals from
[00:35:25.040 --> 00:35:27.120]   multiple websites.
[00:35:27.120 --> 00:35:32.920]   As an example, one such technology analyzes users browsing habits on their own devices.
[00:35:32.920 --> 00:35:37.200]   And in other words, so it's doing on device analysis locally.
[00:35:37.200 --> 00:35:41.880]   And then allows advertisers to target aggregated groups of users with similar interests.
[00:35:41.880 --> 00:35:45.360]   They call them cohorts rather than individual users.
[00:35:45.360 --> 00:35:46.600]   Here's a jock.
[00:35:46.600 --> 00:35:48.040]   Here's a nerd.
[00:35:48.040 --> 00:35:49.520]   This is what Facebook does.
[00:35:49.520 --> 00:35:52.600]   Facebook never says here's what Leo LePort wants to know.
[00:35:52.600 --> 00:35:54.320]   They say here are a thousand people likely.
[00:35:54.320 --> 00:35:58.400]   Oh, LePort that you could target because they all have the same interest.
[00:35:58.400 --> 00:36:00.800]   So there's a story.
[00:36:00.800 --> 00:36:03.680]   Now we're going to ask Noree.
[00:36:03.680 --> 00:36:08.880]   Here's the story. You can see already where the tech journalists are going.
[00:36:08.880 --> 00:36:14.680]   Yeah, yeah, well, sure Google or its regulatory capture Google's pulling up the ladder because
[00:36:14.680 --> 00:36:16.640]   it's already one.
[00:36:16.640 --> 00:36:18.440]   How could Google have handled this better?
[00:36:18.440 --> 00:36:20.440]   And how should we handle this?
[00:36:20.440 --> 00:36:27.800]   Well, I think it's similar to all ban political advertising at all.
[00:36:27.800 --> 00:36:28.800]   Yes, it is.
[00:36:28.800 --> 00:36:29.800]   Yes.
[00:36:29.800 --> 00:36:35.200]   So it always goes back to we ask them to do one thing and then just like Jeff said, but
[00:36:35.200 --> 00:36:41.800]   I think a step back, the whole tech was things started because micro targeting became this
[00:36:41.800 --> 00:36:47.800]   evil force of the source of evil in the world.
[00:36:47.800 --> 00:36:50.720]   And it was because of things like the Russian interference.
[00:36:50.720 --> 00:36:57.920]   So back then everybody looked at micro targeting as the worst thing on the internet.
[00:36:57.920 --> 00:37:06.480]   And now we have Facebook changing the conversations showing, okay, if we don't have targeted things,
[00:37:06.480 --> 00:37:09.600]   how small businesses are going to reach their audience.
[00:37:09.600 --> 00:37:15.080]   So you see also Facebook going out with other messages trying at least to change the framing
[00:37:15.080 --> 00:37:16.240]   of it's not that evil.
[00:37:16.240 --> 00:37:22.560]   It's actually very helpful, specifically on the pandemic where small companies are hurt.
[00:37:22.560 --> 00:37:23.800]   And so that's it.
[00:37:23.800 --> 00:37:27.200]   It's a thing that I think they're doing well actually now.
[00:37:27.200 --> 00:37:34.320]   Of course, Apple precipitated all this by changing its ID for advertisers and using its
[00:37:34.320 --> 00:37:35.320]   ATT technology.
[00:37:35.320 --> 00:37:38.600]   And that's the one Facebook's really saying, oh, it's not just us.
[00:37:38.600 --> 00:37:39.600]   You heard Apple.
[00:37:39.600 --> 00:37:42.320]   It's all the small businesses in all the world.
[00:37:42.320 --> 00:37:50.680]   Google put its finger to the wind and said, hmm, well, I have to say I remain skeptical.
[00:37:50.680 --> 00:37:55.880]   Google by the way says its announcement does not cover its ad tools and unique identifiers
[00:37:55.880 --> 00:38:00.120]   for mobile apps just for websites.
[00:38:00.120 --> 00:38:04.040]   Wall Street Journal has decided to take this as a good sign.
[00:38:04.040 --> 00:38:07.880]   This is the quote, but its plan is the latest sign that the tide might be turning on user
[00:38:07.880 --> 00:38:10.120]   tracking more broadly.
[00:38:10.120 --> 00:38:13.000]   And I might say it's just going underground.
[00:38:13.000 --> 00:38:19.120]   And we use that term regularly for a capture, but that's essentially saying the big incumbents
[00:38:19.120 --> 00:38:23.360]   who are already making billions of dollars can handle this kind of thing.
[00:38:23.360 --> 00:38:24.360]   They're fine.
[00:38:24.360 --> 00:38:25.360]   They can handle it.
[00:38:25.360 --> 00:38:27.680]   We've got to go to the Clio.
[00:38:27.680 --> 00:38:29.280]   So we've been talking to about the devices.
[00:38:29.280 --> 00:38:33.400]   The more that happens locally on your device, all the intelligence is now going into your
[00:38:33.400 --> 00:38:34.400]   phone.
[00:38:34.400 --> 00:38:35.400]   It can handle it.
[00:38:35.400 --> 00:38:41.120]   It can do a lot of ad targeting logic locally.
[00:38:41.120 --> 00:38:43.280]   And they just say, oh, that's the choice for ads.
[00:38:43.280 --> 00:38:44.280]   Give them this one.
[00:38:44.280 --> 00:38:45.280]   Yeah.
[00:38:45.280 --> 00:38:46.280]   Right.
[00:38:46.280 --> 00:38:47.280]   Related story.
[00:38:47.280 --> 00:38:48.280]   Go ahead.
[00:38:48.280 --> 00:38:49.280]   Go ahead.
[00:38:49.280 --> 00:38:50.280]   Go ahead to that.
[00:38:50.280 --> 00:38:55.520]   The main difference is that when the media is attacking the actual fundamentals of your
[00:38:55.520 --> 00:38:59.720]   business, like the business model you have, PR can't fix it.
[00:38:59.720 --> 00:39:00.720]   PR can help.
[00:39:00.720 --> 00:39:04.680]   Because you're not going to change the fundamentals of your business because you don't have any
[00:39:04.680 --> 00:39:06.320]   incentives to do so.
[00:39:06.320 --> 00:39:11.920]   So no matter, you know, messaging you go without, it's not going to help.
[00:39:11.920 --> 00:39:17.120]   So really what you're saying, it's interesting after the tech lashes, not only has tech journalism
[00:39:17.120 --> 00:39:24.560]   redefined itself, but it's made it harder for tech companies and PR companies to frame
[00:39:24.560 --> 00:39:26.360]   the conversation.
[00:39:26.360 --> 00:39:29.640]   They need to rethink how they do their job.
[00:39:29.640 --> 00:39:33.680]   Even when they did specify their, you know, corrective actions.
[00:39:33.680 --> 00:39:37.360]   So these are the steps we're going to do to improve the issue and moving forward, those
[00:39:37.360 --> 00:39:39.680]   are the future steps we're going to do.
[00:39:39.680 --> 00:39:44.280]   Even those corrective actions, as I said, backlash and gut criticism.
[00:39:44.280 --> 00:39:45.280]   Interesting.
[00:39:45.280 --> 00:39:47.720]   It's because it's adversarial now.
[00:39:47.720 --> 00:39:49.040]   But isn't that a good thing?
[00:39:49.040 --> 00:39:53.520]   Shouldn't journalists be adversarial to the field they cover?
[00:39:53.520 --> 00:39:54.520]   I know Jeff's everybody.
[00:39:54.520 --> 00:39:55.520]   I'm upset when you're right.
[00:39:55.520 --> 00:39:58.720]   And I asked them, of course, they will say that's our job.
[00:39:58.720 --> 00:40:00.400]   We're just doing our job.
[00:40:00.400 --> 00:40:01.400]   Right.
[00:40:01.400 --> 00:40:02.400]   Yeah.
[00:40:02.400 --> 00:40:03.400]   We're not, we're not here to.
[00:40:03.400 --> 00:40:06.240]   But no, your attitude is the right attitude.
[00:40:06.240 --> 00:40:08.760]   Even though you screw it up and mess it up all the time.
[00:40:08.760 --> 00:40:12.440]   But speaking for the user, speaking for the user is a better way, right?
[00:40:12.440 --> 00:40:14.280]   It's not between the journalist and the company.
[00:40:14.280 --> 00:40:17.440]   I'm not out to get Apple or Google or Facebook.
[00:40:17.440 --> 00:40:18.440]   All right.
[00:40:18.440 --> 00:40:20.920]   I'm out to represent the interests of the people who use it.
[00:40:20.920 --> 00:40:25.480]   Which is why I like so much near its analysis, which you started talking to us today, is
[00:40:25.480 --> 00:40:27.080]   that it's a power analysis.
[00:40:27.080 --> 00:40:33.920]   And if you look at the power of media, the technology, that doesn't include the public
[00:40:33.920 --> 00:40:35.520]   and the users and the impact.
[00:40:35.520 --> 00:40:37.320]   And that's where we should be starting.
[00:40:37.320 --> 00:40:43.160]   And the problem is that if it's constantly hostile, that doesn't help much either.
[00:40:43.160 --> 00:40:46.880]   I saw a newspaper somewhere in the US today said, well, we're going to stop doing restaurant
[00:40:46.880 --> 00:40:50.520]   reviews because we don't want to hurt the restaurants.
[00:40:50.520 --> 00:40:52.520]   Well, okay.
[00:40:52.520 --> 00:40:57.880]   But you could do the best take out things in Cincinnati, whatever the city was, I forget.
[00:40:57.880 --> 00:40:58.880]   Right.
[00:40:58.880 --> 00:41:02.840]   There's other ways you could do that that would serve both the ear and the restaurant.
[00:41:02.840 --> 00:41:05.720]   This attitude of, well, I'm going to be tough all the time.
[00:41:05.720 --> 00:41:07.320]   That's how I show myself.
[00:41:07.320 --> 00:41:15.200]   No, the utopian stuff was, the fanboy stuff was bad, the dystopian moral panic is bad.
[00:41:15.200 --> 00:41:17.800]   Neither serves the public in the end.
[00:41:17.800 --> 00:41:21.360]   It's why I so much liked the analysis that there it did.
[00:41:21.360 --> 00:41:26.680]   Well, it gets to me is it seems like a lot of journalism, if it comes off as happy, go
[00:41:26.680 --> 00:41:30.560]   like you fill in, you know, warm and stuff, it's false.
[00:41:30.560 --> 00:41:35.280]   But if it comes off as I'm against this, I didn't like this, yada, yada, yada, you're
[00:41:35.280 --> 00:41:36.280]   too aggressive.
[00:41:36.280 --> 00:41:40.520]   And I don't, is that just a societal thing?
[00:41:40.520 --> 00:41:41.520]   Where is that?
[00:41:41.520 --> 00:41:49.040]   Because if I could speak out about a camera that I use and said it, I didn't like it,
[00:41:49.040 --> 00:41:53.520]   people are going to say, hey, he's against that camera manufacturer for whatever reason.
[00:41:53.520 --> 00:41:57.600]   When the fact of the matter is that the tech just isn't there.
[00:41:57.600 --> 00:42:01.080]   But if I gush about the camera, then they're going to call me a fan.
[00:42:01.080 --> 00:42:02.080]   Right.
[00:42:02.080 --> 00:42:03.640]   It's like you can't win.
[00:42:03.640 --> 00:42:04.640]   Yeah.
[00:42:04.640 --> 00:42:06.680]   I've been doing both of these facilities.
[00:42:06.680 --> 00:42:09.040]   I'm being truthful on both sides of it.
[00:42:09.040 --> 00:42:13.320]   And I see that a lot with journalism and makes me wonder, you know, what's going through
[00:42:13.320 --> 00:42:16.880]   those editors mind and what's going through the people that are putting the content out,
[00:42:16.880 --> 00:42:18.960]   it's going through their minds.
[00:42:18.960 --> 00:42:25.840]   So I think we need to make a difference between products reviews, which is one type of journalism
[00:42:25.840 --> 00:42:31.080]   in tech and all the other coverage that is more into the big tech companies, power and
[00:42:31.080 --> 00:42:34.280]   influence, which is a different type of journalism.
[00:42:34.280 --> 00:42:40.240]   So in the product, the tech company, that's still powered, it's still a product, depending
[00:42:40.240 --> 00:42:41.320]   on the tech company.
[00:42:41.320 --> 00:42:46.800]   When you start talking about Google, search is their product advertising is their product.
[00:42:46.800 --> 00:42:47.800]   Right.
[00:42:47.800 --> 00:42:48.800]   Yeah.
[00:42:48.800 --> 00:42:52.360]   But when you're talking about a camera, for example, that's what I meant.
[00:42:52.360 --> 00:42:57.640]   But it's a different type of, you can either like the specs and the usage or not.
[00:42:57.640 --> 00:43:02.800]   And it's different from hearing about antitrust monopoly power or content moderation.
[00:43:02.800 --> 00:43:06.000]   So those are different type of issues there.
[00:43:06.000 --> 00:43:10.080]   And one of the reasons that we have the tactics is because of the companies that the big tech
[00:43:10.080 --> 00:43:11.080]   -- bigness.
[00:43:11.080 --> 00:43:15.720]   So they're so big and they have such, you know, huge scale is that they're at a place
[00:43:15.720 --> 00:43:17.160]   of getting scrutiny.
[00:43:17.160 --> 00:43:20.520]   If nothing else, it's because of how big and powerful they are.
[00:43:20.520 --> 00:43:22.680]   And it's not like they're getting much power for all the best big.
[00:43:22.680 --> 00:43:27.640]   So the focus on them is because of their growing power.
[00:43:27.640 --> 00:43:31.500]   And that's the tech journalist saying we need to hold power to account and speak to
[00:43:31.500 --> 00:43:32.500]   power.
[00:43:32.500 --> 00:43:35.160]   And that's exactly why we're doing it now and not one day.
[00:43:35.160 --> 00:43:38.240]   We're this small startup in a garage or something.
[00:43:38.240 --> 00:43:39.240]   Right.
[00:43:39.240 --> 00:43:43.920]   There's another dynamic at play that's really playing out dramatically, which is -- and
[00:43:43.920 --> 00:43:45.040]   it also has to do with power.
[00:43:45.040 --> 00:43:49.520]   It used to be there's tech journalism and there's tech companies.
[00:43:49.520 --> 00:43:56.960]   But tech journalism, like every other form of journalism, has been completely dismantled
[00:43:56.960 --> 00:44:00.040]   by kind of a more Democrat.
[00:44:00.040 --> 00:44:03.340]   I mean, there's -- is Marques Brownlee a traditional tech journalist?
[00:44:03.340 --> 00:44:04.340]   I'd say no.
[00:44:04.340 --> 00:44:07.980]   There are a lot of YouTube tech, quote, "people were covering tech."
[00:44:07.980 --> 00:44:09.260]   Let's put it that way.
[00:44:09.260 --> 00:44:14.460]   And they're not very much not in the corporate mold of a tech journalist of even five years
[00:44:14.460 --> 00:44:19.820]   ago, let alone the ZD net, Zif Davis Euro or the -- or the IDG here.
[00:44:19.820 --> 00:44:21.980]   Or tech tech director who does some of the best work out there.
[00:44:21.980 --> 00:44:22.980]   Yeah.
[00:44:22.980 --> 00:44:23.980]   Blogs are a good example.
[00:44:23.980 --> 00:44:26.300]   Blogs and YouTube.
[00:44:26.300 --> 00:44:29.660]   There are a lot more people covering tech than ever before.
[00:44:29.660 --> 00:44:34.860]   The standards they operate with, which this is my personal pet peeve, the ethical standards
[00:44:34.860 --> 00:44:40.560]   they operate with are very widely and are never really fully revealed.
[00:44:40.560 --> 00:44:42.240]   I think it's a different world.
[00:44:42.240 --> 00:44:46.480]   It's not a monolithic -- you can't say there's tech journalism anymore.
[00:44:46.480 --> 00:44:48.080]   Everybody covers tech.
[00:44:48.080 --> 00:44:49.080]   I can't agree more.
[00:44:49.080 --> 00:44:53.360]   The book touches the difference between tech bloggers and tech journalists a lot, even
[00:44:53.360 --> 00:44:55.560]   though I get curious as I'm for doing that.
[00:44:55.560 --> 00:44:59.300]   I'm showing why I'm keeping the divide between tech journalists and tech bloggers in some
[00:44:59.300 --> 00:45:00.300]   cases.
[00:45:00.300 --> 00:45:01.300]   And I'm showing how --
[00:45:01.300 --> 00:45:02.300]   I appreciate that.
[00:45:02.300 --> 00:45:03.300]   Thank you.
[00:45:03.300 --> 00:45:10.900]   I appreciate that because it's two different worlds and two different disciplines, if you
[00:45:10.900 --> 00:45:17.860]   will, going into it that a tech commentator or a tech pundit just may not understand,
[00:45:17.860 --> 00:45:19.980]   in my opinion.
[00:45:19.980 --> 00:45:24.060]   So the way I'm looking at it is, again, I'm a communication researcher is through the
[00:45:24.060 --> 00:45:25.900]   lens of agenda setting.
[00:45:25.900 --> 00:45:32.740]   So when I'm looking at the agenda, when it comes to product launches and the first row
[00:45:32.740 --> 00:45:36.100]   when we had events live, those were the tech bloggers, right?
[00:45:36.100 --> 00:45:38.860]   Because we wanted them to do the hands-on review.
[00:45:38.860 --> 00:45:44.540]   So they were the agenda setters when it comes to new products.
[00:45:44.540 --> 00:45:49.140]   But when it comes to, I don't know, the Congress investigation about the Russian interference,
[00:45:49.140 --> 00:45:52.500]   it will be the New York Times, Washington Post and all the traditional media outlets that
[00:45:52.500 --> 00:45:54.100]   have tech coverage.
[00:45:54.100 --> 00:45:55.460]   So that's the difference.
[00:45:55.460 --> 00:46:03.980]   And they have, as Leo said, different ethical framework to work because the subjects are
[00:46:03.980 --> 00:46:09.220]   -- their importance is different or their impact is different.
[00:46:09.220 --> 00:46:10.860]   It's changing so rapidly.
[00:46:10.860 --> 00:46:14.820]   It's funny because I've always -- it's another hot button for me.
[00:46:14.820 --> 00:46:17.380]   This is a very hot button topic for me, Duryan.
[00:46:17.380 --> 00:46:19.740]   I'm sorry.
[00:46:19.740 --> 00:46:26.940]   Another hot topic for me is the relationship between tech companies and their PR arms and
[00:46:26.940 --> 00:46:33.580]   tech journalists very much has been impacted by the growth of tech journalism.
[00:46:33.580 --> 00:46:38.740]   When I was on TV or writing for magazines, I was treated as a tech journalist.
[00:46:38.740 --> 00:46:45.060]   As soon as I started doing it in podcasts, it was like, who are you?
[00:46:45.060 --> 00:46:47.020]   I want to see some tear sheets.
[00:46:47.020 --> 00:46:54.380]   There's no freaking tear sheets from a podcast.
[00:46:54.380 --> 00:46:59.380]   I have to say, tech PR is, forgive me, horrible.
[00:46:59.380 --> 00:47:00.780]   These people are idiots.
[00:47:00.780 --> 00:47:05.420]   Okay, I'm going to stop now.
[00:47:05.420 --> 00:47:09.540]   Honestly, I know they're well-meaning and mostly very nice people.
[00:47:09.540 --> 00:47:13.300]   You don't get into PR if you don't like people and you're not nice.
[00:47:13.300 --> 00:47:19.780]   I don't think that they -- whether they're in-house or an agency, I don't think they
[00:47:19.780 --> 00:47:21.460]   do a very good job at all.
[00:47:21.460 --> 00:47:24.420]   That's one of the reasons I don't ever want to talk to them again.
[00:47:24.420 --> 00:47:29.580]   So what the book shows is that tech journalists reflected on their relationship with tech
[00:47:29.580 --> 00:47:33.380]   PR, the other side, the dark side, the enemy side, as you said.
[00:47:33.380 --> 00:47:38.700]   They said, okay, so back then in the glorious days, we had computer magazines and we had
[00:47:38.700 --> 00:47:39.700]   first releases in car.
[00:47:39.700 --> 00:47:43.260]   Then you knew who was the power.
[00:47:43.260 --> 00:47:44.260]   Yeah.
[00:47:44.260 --> 00:47:47.860]   And they mainly dictated we've done a lot of copy paste.
[00:47:47.860 --> 00:47:51.140]   We're sorry for that time, professional life.
[00:47:51.140 --> 00:47:55.460]   But yeah, most of the coverage was promotional from those press releases and what they wanted
[00:47:55.460 --> 00:47:57.420]   to present.
[00:47:57.420 --> 00:48:05.200]   But the problem is that everybody wanted more tech information because tech became
[00:48:05.200 --> 00:48:07.220]   more integrated in everything in our lives.
[00:48:07.220 --> 00:48:12.860]   And then what's happening, the power shift here, is that the companies became more secretive
[00:48:12.860 --> 00:48:13.860]   with limited access.
[00:48:13.860 --> 00:48:18.340]   And then they can choose which journalists they invite for a conversation and whether
[00:48:18.340 --> 00:48:22.500]   it's with the background or background.
[00:48:22.500 --> 00:48:28.300]   And then the journalists complained, well, if you speak critically, you're just not entering
[00:48:28.300 --> 00:48:29.300]   the door.
[00:48:29.300 --> 00:48:30.300]   You can't go there.
[00:48:30.300 --> 00:48:31.780]   They won't invite you to anything.
[00:48:31.780 --> 00:48:36.660]   And that was a lot of frustration that was building up for years.
[00:48:36.660 --> 00:48:42.180]   And now they're glad that they can be both critical and have an interview.
[00:48:42.180 --> 00:48:45.700]   But then what happened is it's not on background and you're inside.
[00:48:45.700 --> 00:48:52.580]   The CEO just gives you the PR talking points and did not really say anything that he wanted.
[00:48:52.580 --> 00:48:53.580]   Never.
[00:48:53.580 --> 00:48:54.580]   He didn't want to review it.
[00:48:54.580 --> 00:48:56.060]   Oh, I never interviewed CEOs.
[00:48:56.060 --> 00:48:59.980]   I was offered Bill Gates with his contacts and they said, okay, what are your questions?
[00:48:59.980 --> 00:49:01.540]   I said, I don't submit questions ahead of time.
[00:49:01.540 --> 00:49:02.540]   This is what you have to.
[00:49:02.540 --> 00:49:06.740]   If you want to talk to Bill, I said, well, thanks for the hustling.
[00:49:06.740 --> 00:49:09.500]   Leo hasn't been invited to Apple in how many years?
[00:49:09.500 --> 00:49:12.540]   How many, 10, 10, 11 years?
[00:49:12.540 --> 00:49:16.020]   I hate these companies.
[00:49:16.020 --> 00:49:17.020]   I love technologies.
[00:49:17.020 --> 00:49:18.020]   I love Geeks.
[00:49:18.020 --> 00:49:19.020]   I love engineers.
[00:49:19.020 --> 00:49:20.020]   I love technology.
[00:49:20.020 --> 00:49:21.020]   I love technologists.
[00:49:21.020 --> 00:49:25.180]   I really hate the marketing shell around them.
[00:49:25.180 --> 00:49:27.100]   I'm not a fan.
[00:49:27.100 --> 00:49:34.620]   So this is, I'll let you handle this conversation, Jeff, because my antipathy is showing.
[00:49:34.620 --> 00:49:35.620]   And I want to...
[00:49:35.620 --> 00:49:40.620]   I just want to bring up something else.
[00:49:40.620 --> 00:49:42.300]   So, it was interesting lately, there was when the Facebook oversight board released its first
[00:49:42.300 --> 00:49:47.860]   opinions, they offered them on embargo, which is legal, Leo won't do partly because
[00:49:47.860 --> 00:49:48.860]   he can't keep a secret.
[00:49:48.860 --> 00:49:50.780]   No, I make that joke about that.
[00:49:50.780 --> 00:49:54.020]   I refuse to do embargoes or NDAs.
[00:49:54.020 --> 00:49:56.900]   Again, there's a pattern here.
[00:49:56.900 --> 00:49:59.620]   I don't play this game.
[00:49:59.620 --> 00:50:01.900]   Leo won't play that game.
[00:50:01.900 --> 00:50:05.660]   A couple of researchers, and I was offered it too, but I just didn't have time, so I
[00:50:05.660 --> 00:50:08.140]   said don't care.
[00:50:08.140 --> 00:50:13.020]   But one important researcher got the material that I had before, so she was able to write
[00:50:13.020 --> 00:50:17.900]   a really good report for a legal blog.
[00:50:17.900 --> 00:50:21.020]   And this is fairly normal in our world, right?
[00:50:21.020 --> 00:50:31.220]   But the anti-tech research community went berserk on her and tore her apart because she
[00:50:31.220 --> 00:50:34.860]   got early access to the information.
[00:50:34.860 --> 00:50:35.980]   She still wrote a tough report.
[00:50:35.980 --> 00:50:37.820]   She's very tough on them.
[00:50:37.820 --> 00:50:41.860]   But it was fascinating to see this clash of these cultures all coming in together.
[00:50:41.860 --> 00:50:45.740]   Everybody's now gathering around tech in a different way.
[00:50:45.740 --> 00:50:49.300]   The rules we used to have don't apply anymore.
[00:50:49.300 --> 00:50:51.500]   Yeah, I think everyone...
[00:50:51.500 --> 00:50:55.380]   No matter what you and your research world thinks.
[00:50:55.380 --> 00:51:02.420]   I don't remember the specifics of the story.
[00:51:02.420 --> 00:51:07.420]   Yeah, I'm trying to leave people out of it.
[00:51:07.420 --> 00:51:13.420]   Is it proper for a researcher to get access?
[00:51:13.420 --> 00:51:17.140]   I think so, specifically if it's her expertise.
[00:51:17.140 --> 00:51:21.580]   The thing is that I think your touching is that it wasn't in the narrative what you wrote,
[00:51:21.580 --> 00:51:24.180]   and that's where it's backlash, right?
[00:51:24.180 --> 00:51:26.540]   Right.
[00:51:26.540 --> 00:51:31.140]   And the problem with something out of the narrative is that it's problematic because
[00:51:31.140 --> 00:51:36.140]   you again said something important in the book is that the media works as a herd, right?
[00:51:36.140 --> 00:51:42.200]   So it's this pack mentality that if the specific stories are the newsworthy stories and the
[00:51:42.200 --> 00:51:48.780]   framing is a specific framing by which we work with, all the other stories or framings
[00:51:48.780 --> 00:51:56.100]   are kind of out of the picture, specifically in the main prestigious outlets that dictate
[00:51:56.100 --> 00:51:59.300]   what is news and what's the framing of the news.
[00:51:59.300 --> 00:52:04.660]   So if you're out of the problem, I think, I'm touching.
[00:52:04.660 --> 00:52:06.020]   I had it back to you, Leo.
[00:52:06.020 --> 00:52:07.540]   We can move on to that.
[00:52:07.540 --> 00:52:12.060]   I will take a break momentarily and then we'll come back with our guests.
[00:52:12.060 --> 00:52:18.620]   It's really a fascinating conversation, I have to say.
[00:52:18.620 --> 00:52:23.980]   Dr. Nerrit Weissblatt is the author of The Techlash, which will be available for pre-order
[00:52:23.980 --> 00:52:29.740]   now and available on your book, Stand March 24th Techlash book.
[00:52:29.740 --> 00:52:33.540]   If you want to know more on our Twitter handle, which I love is Dr. Techlash.
[00:52:33.540 --> 00:52:38.380]   So if you don't mind, I'm going to say Dr. Techlash is with us.
[00:52:38.380 --> 00:52:45.100]   Also Annapurit, Jeff Jarvis, who is Dr. Morl Panek, and we will have more in a moment.
[00:52:45.100 --> 00:52:46.100]   Dr. Gutenberg.
[00:52:46.100 --> 00:52:48.340]   Dr. Gutenberg, yeah.
[00:52:48.340 --> 00:52:54.140]   So today brought to you by Uber, but a special part of Uber, Uber for business.
[00:52:54.140 --> 00:52:56.540]   This is something that kind of speaks to me.
[00:52:56.540 --> 00:52:58.740]   We always want to reward our employees.
[00:52:58.740 --> 00:53:02.940]   Yesterday, everybody came in early at 8 in the morning.
[00:53:02.940 --> 00:53:03.940]   Thank you, Ant.
[00:53:03.940 --> 00:53:04.940]   Thank you, John.
[00:53:04.940 --> 00:53:05.980]   Thank you, Anthony.
[00:53:05.980 --> 00:53:12.140]   So we could cover that ridiculous Microsoft Ignite event, whatever the hell that was yesterday.
[00:53:12.140 --> 00:53:16.340]   And if I had thought about it, I would have sent them a voucher from Uber for Business
[00:53:16.340 --> 00:53:22.140]   for breakfast, or maybe send them a voucher for an Uber to come on in, that kind of thing.
[00:53:22.140 --> 00:53:25.820]   If you're having a hard time getting people to show up or stay engaged in virtual team
[00:53:25.820 --> 00:53:32.980]   meetings or events, if you want to spiff employees or customers with a ride or food,
[00:53:32.980 --> 00:53:34.220]   Uber for business is for you.
[00:53:34.220 --> 00:53:40.620]   Over 160,000 companies use Uber for business to improve customer and employee satisfaction.
[00:53:40.620 --> 00:53:46.740]   You can order a ride, but you can also order meals through Uber Eats.
[00:53:46.740 --> 00:53:48.060]   You're having a meeting.
[00:53:48.060 --> 00:53:50.140]   You want some prospects to come to the meeting.
[00:53:50.140 --> 00:53:51.620]   You say, "Hey, come to our meeting.
[00:53:51.620 --> 00:53:55.220]   We're going to talk about this, but I'd like to buy you a cup of coffee."
[00:53:55.220 --> 00:53:57.060]   You send them an Uber for business.
[00:53:57.060 --> 00:53:58.060]   Voucher.
[00:53:58.060 --> 00:53:59.060]   Now, here's why you'll like this.
[00:53:59.060 --> 00:54:00.060]   It's very easy.
[00:54:00.060 --> 00:54:01.180]   You can sign up for free.
[00:54:01.180 --> 00:54:04.860]   You can immediately, I mean, like literally, as soon as you sign up, start delivering extra
[00:54:04.860 --> 00:54:07.260]   value to the people who matter most to your business.
[00:54:07.260 --> 00:54:09.980]   Vouchers are very easy for you to send.
[00:54:09.980 --> 00:54:13.100]   They're very easy for your customer or colleague to redeem.
[00:54:13.100 --> 00:54:14.540]   You get total control.
[00:54:14.540 --> 00:54:16.300]   I mean, you could say, "Who gets it?
[00:54:16.300 --> 00:54:18.460]   Who can use it when they expire?"
[00:54:18.460 --> 00:54:22.500]   You can even say, "I only want to cover half the ride or half the meal."
[00:54:22.500 --> 00:54:24.420]   You could select a portion.
[00:54:24.420 --> 00:54:25.820]   Vouchers can be shared via email.
[00:54:25.820 --> 00:54:29.860]   They can be shared by text, and they can be redeemed with a single tap.
[00:54:29.860 --> 00:54:31.940]   So it's very easy for everybody involved.
[00:54:31.940 --> 00:54:33.140]   Here's the best part.
[00:54:33.140 --> 00:54:39.820]   You only pay for the rides they take or the meals they order.
[00:54:39.820 --> 00:54:41.460]   Send these out.
[00:54:41.460 --> 00:54:42.460]   It's great.
[00:54:42.460 --> 00:54:43.460]   People love it.
[00:54:43.460 --> 00:54:45.780]   Half the time they don't use it costs you nothing.
[00:54:45.780 --> 00:54:49.220]   Right now, for a limited time, you can get a $50 voucher when you create your first Vouchers
[00:54:49.220 --> 00:54:51.940]   campaign and spend $200 or more.
[00:54:51.940 --> 00:54:56.580]   Go to uber, uber, uber.com/twig to learn more.
[00:54:56.580 --> 00:54:57.580]   This is such a good idea.
[00:54:57.580 --> 00:54:58.580]   Such a nice thing.
[00:54:58.580 --> 00:55:02.940]   I really love the idea of, you know, we try to do things like this for our employees,
[00:55:02.940 --> 00:55:07.140]   but you know, sending so many flowers, that's nice, but it's something they can use.
[00:55:07.140 --> 00:55:08.140]   This is better.
[00:55:08.140 --> 00:55:09.580]   Send them dinner.
[00:55:09.580 --> 00:55:10.580]   Send them a ride.
[00:55:10.580 --> 00:55:11.580]   Uber.com/twig.
[00:55:11.580 --> 00:55:12.580]   Uber.com/twig.
[00:55:12.580 --> 00:55:16.500]   Some curtearms and conditions apply.
[00:55:16.500 --> 00:55:18.900]   Thank you, Uber, for giving me some good ideas.
[00:55:18.900 --> 00:55:21.060]   I'm sorry I didn't do that for you yesterday, Ant.
[00:55:21.060 --> 00:55:24.100]   So, you can still see me some Popeyes.
[00:55:24.100 --> 00:55:25.100]   Did we see?
[00:55:25.100 --> 00:55:26.820]   Oh, Popeyes for business.
[00:55:26.820 --> 00:55:28.380]   Now there's a business plan.
[00:55:28.380 --> 00:55:32.700]   That's a big new sponsor you got there, fella.
[00:55:32.700 --> 00:55:34.100]   I like the Uber for business.
[00:55:34.100 --> 00:55:35.100]   I do.
[00:55:35.100 --> 00:55:36.100]   Yeah.
[00:55:36.100 --> 00:55:37.940]   Did you see any of that Microsoft event?
[00:55:37.940 --> 00:55:38.940]   You probably didn't, Jeff.
[00:55:38.940 --> 00:55:40.140]   It's not in your beat.
[00:55:40.140 --> 00:55:42.380]   No, just to watch the little tiny bit.
[00:55:42.380 --> 00:55:43.380]   I don't know.
[00:55:43.380 --> 00:55:44.380]   It was so bizarre.
[00:55:44.380 --> 00:55:45.380]   Ant, what do you think?
[00:55:45.380 --> 00:55:47.660]   I never asked you.
[00:55:47.660 --> 00:55:50.380]   You left before I got the chance to ask you.
[00:55:50.380 --> 00:55:54.100]   It was one of those things of where I was asking myself, why?
[00:55:54.100 --> 00:55:55.100]   Why?
[00:55:55.100 --> 00:56:01.220]   You know, because it's nice to know that this technology is out there, but VR has just sort
[00:56:01.220 --> 00:56:02.940]   of died down, in my opinion.
[00:56:02.940 --> 00:56:03.940]   Yes.
[00:56:03.940 --> 00:56:05.260]   I'm a VR skeptic.
[00:56:05.260 --> 00:56:06.260]   I really am.
[00:56:06.260 --> 00:56:07.260]   Yeah.
[00:56:07.260 --> 00:56:12.820]   And I get the potential for it, but yet at the same time, I don't see it being implemented
[00:56:12.820 --> 00:56:19.260]   anywhere that regular people are going to dive in and just start spending money on
[00:56:19.260 --> 00:56:20.260]   it.
[00:56:20.260 --> 00:56:23.180]   So that's why I just said, why have this?
[00:56:23.180 --> 00:56:28.380]   Microsoft announced at their Ignite Conference, which is a conference for developers and IT
[00:56:28.380 --> 00:56:30.140]   people they announced.
[00:56:30.140 --> 00:56:32.860]   Really, it's not a new technology.
[00:56:32.860 --> 00:56:34.140]   It's a basket.
[00:56:34.140 --> 00:56:38.140]   This is what Microsoft does lately is they take a bunch of stuff and put it in a basket.
[00:56:38.140 --> 00:56:40.620]   They're calling mesh.
[00:56:40.620 --> 00:56:44.900]   But the thing that you'll most easily recognize is the hollow lens and they've augmented reality
[00:56:44.900 --> 00:56:51.740]   and the meetings that some people are in the space, but some people are joining you holographically
[00:56:51.740 --> 00:56:54.380]   virtually.
[00:56:54.380 --> 00:56:58.700]   I think maybe it wasn't the best keynote because it kind of implied that all of this
[00:56:58.700 --> 00:57:00.380]   would be done underwater.
[00:57:00.380 --> 00:57:05.140]   And I don't think that's the case.
[00:57:05.140 --> 00:57:07.100]   The whole thing was kind of like what?
[00:57:07.100 --> 00:57:11.220]   With whales swimming around and stuff, it was a little bit strange.
[00:57:11.220 --> 00:57:14.820]   Is it Microsoft always about five years behind everything else?
[00:57:14.820 --> 00:57:22.540]   You know, no, they actually have a very active R&D division.
[00:57:22.540 --> 00:57:24.060]   But they discovered search.
[00:57:24.060 --> 00:57:25.060]   I know.
[00:57:25.060 --> 00:57:26.060]   I know.
[00:57:26.060 --> 00:57:27.060]   I know.
[00:57:27.060 --> 00:57:28.060]   They go.
[00:57:28.060 --> 00:57:29.060]   Gates didn't think the internet was going anywhere.
[00:57:29.060 --> 00:57:30.060]   I know.
[00:57:30.060 --> 00:57:31.060]   They had this hollow lens.
[00:57:31.060 --> 00:57:34.220]   This really was this is five year old technology.
[00:57:34.220 --> 00:57:36.260]   I think that's why I was mostly disappointed.
[00:57:36.260 --> 00:57:41.500]   Hallens was invented almost exactly released almost exactly five years ago, two years ago
[00:57:41.500 --> 00:57:44.780]   the last update and nothing since then.
[00:57:44.780 --> 00:57:46.940]   See, this is exactly what Near Eats talking about.
[00:57:46.940 --> 00:57:48.500]   I am a skeptic.
[00:57:48.500 --> 00:57:51.100]   This was a great thing five years ago.
[00:57:51.100 --> 00:57:53.980]   Now, just more big tech.
[00:57:53.980 --> 00:57:54.980]   More big tech.
[00:57:54.980 --> 00:57:55.980]   More big tech.
[00:57:55.980 --> 00:57:58.260]   Some type of nice implementation.
[00:57:58.260 --> 00:58:03.140]   Well, it's the case, Doree, that a lot of tech companies, this is one thing that has
[00:58:03.140 --> 00:58:04.140]   changed.
[00:58:04.140 --> 00:58:08.660]   It's not just Donald Trump's election or whatever the seminal events were.
[00:58:08.660 --> 00:58:14.580]   It is the case that when technology was young, there were a lot of green fields and a lot
[00:58:14.580 --> 00:58:17.860]   of easy fruit to pick.
[00:58:17.860 --> 00:58:23.060]   But now here we are in a mature time and the phone is pretty mature and you know, what
[00:58:23.060 --> 00:58:24.500]   we do is pretty mature.
[00:58:24.500 --> 00:58:30.020]   I think tech companies don't have the luxury of saying, "Oh, that's an obvious next thing
[00:58:30.020 --> 00:58:31.860]   to do."
[00:58:31.860 --> 00:58:36.260]   They have to work harder and we as customers are not being very helpful in telling them
[00:58:36.260 --> 00:58:37.940]   what we want.
[00:58:37.940 --> 00:58:42.020]   I think they're thrown, we have an expression in the US, I don't know what you say in Israel.
[00:58:42.020 --> 00:58:44.220]   We throw spaghetti against the wall.
[00:58:44.220 --> 00:58:47.860]   You might throw hummus against the wall.
[00:58:47.860 --> 00:58:51.220]   Hummus always sticks, so that's not good.
[00:58:51.220 --> 00:58:54.380]   You throw spaghetti against the wall and you see what sticks.
[00:58:54.380 --> 00:58:58.900]   I feel like tech companies, and this is a really good example.
[00:58:58.900 --> 00:58:59.900]   This is out of nowhere.
[00:58:59.900 --> 00:59:02.660]   They're going, "What's the next big thing?"
[00:59:02.660 --> 00:59:07.500]   And a number of them have come up with this idea that it's augmented reality/virtual reality.
[00:59:07.500 --> 00:59:09.860]   And a lot of us users are going, "Really?"
[00:59:09.860 --> 00:59:14.780]   Do you think that's, let me ask you about this because I want to get an opinion.
[00:59:14.780 --> 00:59:19.740]   Do you think that's something that's also the reason for this tech lash?
[00:59:19.740 --> 00:59:22.700]   I mean, it's not as easy as it used to be.
[00:59:22.700 --> 00:59:24.220]   Sure, sure.
[00:59:24.220 --> 00:59:29.780]   The book specifies that it's not only the reckoning from Trump election or the bigness
[00:59:29.780 --> 00:59:30.780]   that I mentioned.
[00:59:30.780 --> 00:59:35.340]   It's the accumulation of many issues at once that created this tech lash.
[00:59:35.340 --> 00:59:40.460]   So it was also, as you said, that abreaches and sexual harassment and discrimination.
[00:59:40.460 --> 00:59:47.060]   So we had that issues happening, but also, and you can have it now, is it's not the innovation
[00:59:47.060 --> 00:59:52.060]   journalism we used to have because we used to be really enthusiastic about everything
[00:59:52.060 --> 00:59:54.540]   that is new and exciting.
[00:59:54.540 --> 00:59:59.980]   And now we're, you can see it in your episodes of this week in technology and Google and
[00:59:59.980 --> 01:00:03.460]   all the other things that you read the news.
[01:00:03.460 --> 01:00:06.460]   And you say, "That's not that big of a deal.
[01:00:06.460 --> 01:00:07.460]   It's not exciting."
[01:00:07.460 --> 01:00:09.580]   And it's, so what's new?
[01:00:09.580 --> 01:00:10.580]   It's not as exciting.
[01:00:10.580 --> 01:00:16.580]   It used to be because those are like small changes to things that you already used to
[01:00:16.580 --> 01:00:17.580]   do.
[01:00:17.580 --> 01:00:19.140]   We were so excited.
[01:00:19.140 --> 01:00:24.660]   We were so excited to go to an Apple event in 2007.
[01:00:24.660 --> 01:00:26.660]   Steve Jobs announces the iPhone.
[01:00:26.660 --> 01:00:30.540]   And it's like, I mean, as journalists were supposed to be sitting on our hands the whole
[01:00:30.540 --> 01:00:32.700]   time, and it was everything I could do.
[01:00:32.700 --> 01:00:36.340]   And I think I failed not to leap to my feet and cheer.
[01:00:36.340 --> 01:00:40.580]   In 2010, Apple's announces the iPad.
[01:00:40.580 --> 01:00:42.820]   You can think of these important.
[01:00:42.820 --> 01:00:45.260]   And so there was a reason we were cheer-leadering.
[01:00:45.260 --> 01:00:46.900]   These were really big innovations.
[01:00:46.900 --> 01:00:47.900]   It was innovation.
[01:00:47.900 --> 01:00:49.820]   They were break-thing.
[01:00:49.820 --> 01:00:52.500]   Those are ground-breaking things.
[01:00:52.500 --> 01:00:53.500]   Yeah, yeah, yeah.
[01:00:53.500 --> 01:00:56.900]   So let me try another theory then.
[01:00:56.900 --> 01:01:01.380]   Even when Facebook just started, it was this small startup doing something really, really
[01:01:01.380 --> 01:01:03.380]   good, connecting people.
[01:01:03.380 --> 01:01:07.980]   And when Netflix started, we stopped with the envelope and moved to streaming.
[01:01:07.980 --> 01:01:13.460]   So those are all new big, huge things that shifted our usage of technology.
[01:01:13.460 --> 01:01:17.860]   But now it's just got used to it, and we take it for granted.
[01:01:17.860 --> 01:01:24.260]   Now it's like TikTok and then Snapchat No Beard filter is the hot thing.
[01:01:24.260 --> 01:01:25.260]   What?
[01:01:25.260 --> 01:01:28.660]   He's got no beard.
[01:01:28.660 --> 01:01:31.020]   Oh, well, he has a little beard.
[01:01:31.020 --> 01:01:33.900]   At the bottom, that's disgusting.
[01:01:33.900 --> 01:01:37.300]   And that's how it's hard to get excited about that, Nereet.
[01:01:37.300 --> 01:01:39.300]   I mean, it really is hard.
[01:01:39.300 --> 01:01:44.860]   You can only get so excited about C. Channing's.
[01:01:44.860 --> 01:01:47.100]   We do a pretty good job around here, but go ahead.
[01:01:47.100 --> 01:01:48.100]   I'm sorry.
[01:01:48.100 --> 01:01:49.980]   But Ratatouille, the TikTok musical, that's another matter.
[01:01:49.980 --> 01:01:50.980]   That's a different matter.
[01:01:50.980 --> 01:01:51.980]   Oh, gosh, no.
[01:01:51.980 --> 01:01:53.740]   So why was the theory here?
[01:01:53.740 --> 01:01:54.740]   We tried this out.
[01:01:54.740 --> 01:01:55.740]   We tried this out.
[01:01:55.740 --> 01:01:58.740]   And I liked your point about timing.
[01:01:58.740 --> 01:02:04.620]   Had this been announced last year with the whole mesh, what it had made a difference because
[01:02:04.620 --> 01:02:10.140]   of where we were as a nation and everybody is just trying to get used to this whole being
[01:02:10.140 --> 01:02:16.500]   sheltering in place and locked down and not able to get out and see people.
[01:02:16.500 --> 01:02:19.220]   The same way Zoom took advantage of it.
[01:02:19.220 --> 01:02:20.500]   Do you think it would have been better?
[01:02:20.500 --> 01:02:21.980]   I think it would have.
[01:02:21.980 --> 01:02:22.980]   Yeah.
[01:02:22.980 --> 01:02:26.980]   Well, I mean, you also have the problem that this stuff takes a while to develop.
[01:02:26.980 --> 01:02:29.340]   It's hard to know what's going on inside these big companies.
[01:02:29.340 --> 01:02:30.340]   That's, I think, another thing.
[01:02:30.340 --> 01:02:32.500]   I don't know if you covered this at all, Nereet.
[01:02:32.500 --> 01:02:38.940]   But the challenge I always have is you tend to personify companies like Apple and Microsoft
[01:02:38.940 --> 01:02:45.500]   and Google because we don't see into what's really going on.
[01:02:45.500 --> 01:02:53.140]   And we don't, for me, because I don't get to know the people behind this intentionally,
[01:02:53.140 --> 01:02:56.100]   we kind of anthropomorphize these corporations.
[01:02:56.100 --> 01:03:03.420]   We ascribe motives to them that really aren't corporate motives, they're human motives.
[01:03:03.420 --> 01:03:05.340]   We say Apple's trustworthy.
[01:03:05.340 --> 01:03:08.660]   You know, Google's shifty, Facebook's evil.
[01:03:08.660 --> 01:03:12.260]   Those aren't really accurate.
[01:03:12.260 --> 01:03:16.820]   And so it's hard, do you consider that at all?
[01:03:16.820 --> 01:03:22.180]   And one of the problems that tech journalism faces is we're mostly not business journalists,
[01:03:22.180 --> 01:03:24.460]   so we don't really know how to think about these companies.
[01:03:24.460 --> 01:03:28.860]   And as a hangover from the old days when we were cheerleading, we still have this notion
[01:03:28.860 --> 01:03:33.380]   that Apple's is, I confront this every time we do Mac break quickly, that Apple's somehow
[01:03:33.380 --> 01:03:36.980]   this magical company that will take whatever field it decides to do the next big thing
[01:03:36.980 --> 01:03:38.980]   and will revolutionize.
[01:03:38.980 --> 01:03:39.980]   Cars!
[01:03:39.980 --> 01:03:40.980]   Yeah.
[01:03:40.980 --> 01:03:41.980]   Right.
[01:03:41.980 --> 01:03:42.980]   And that's not true.
[01:03:42.980 --> 01:03:48.020]   It's a terrible expectation to put on a company and it also hurts your ability to interpret
[01:03:48.020 --> 01:03:50.180]   what they're up to.
[01:03:50.180 --> 01:03:54.980]   So most of it was on the shoulders of the founders and CEOs.
[01:03:54.980 --> 01:03:55.980]   Right.
[01:03:55.980 --> 01:04:04.380]   So the personality was mainly about those geniuses doing those new innovations and make the world
[01:04:04.380 --> 01:04:05.380]   a better place, right?
[01:04:05.380 --> 01:04:08.460]   That was the narrative of the years.
[01:04:08.460 --> 01:04:14.780]   And now I would say that the tech journalists, when they look at those tech CEOs, they want
[01:04:14.780 --> 01:04:16.700]   to take them down from those.
[01:04:16.700 --> 01:04:17.700]   To put problems.
[01:04:17.700 --> 01:04:21.740]   Right, because we don't want you to be from studying everything.
[01:04:21.740 --> 01:04:28.160]   So now we're going to say that you're evil and you have all those other incentives to
[01:04:28.160 --> 01:04:29.160]   do.
[01:04:29.160 --> 01:04:32.020]   It's like we're like jilted lovers.
[01:04:32.020 --> 01:04:33.020]   We got our hearts broken.
[01:04:33.020 --> 01:04:35.020]   We are the divorce phase.
[01:04:35.020 --> 01:04:37.020]   We're in a divorce phase.
[01:04:37.020 --> 01:04:43.620]   You know, because I think a lot of people still think Apple, Steve Jobs, Microsoft Bill
[01:04:43.620 --> 01:04:47.660]   Gates, Facebook, Mark Zuckerberg, Google Larry and Sergey.
[01:04:47.660 --> 01:04:49.420]   That's the personification.
[01:04:49.420 --> 01:04:54.020]   I don't know if that was even true back in the day because Microsoft's a company with
[01:04:54.020 --> 01:04:58.900]   tens of thousands of employees and many, many managers and many executives.
[01:04:58.900 --> 01:04:59.900]   Right.
[01:04:59.900 --> 01:05:00.900]   It becomes a company no matter what.
[01:05:00.900 --> 01:05:03.220]   It then companies a company and company do what company do.
[01:05:03.220 --> 01:05:04.740]   I have another theory here.
[01:05:04.740 --> 01:05:07.020]   I want to play this off.
[01:05:07.020 --> 01:05:08.020]   There.
[01:05:08.020 --> 01:05:09.020]   Pendulum I buy and I think that's right.
[01:05:09.020 --> 01:05:10.820]   But as you say, the pendulum doesn't go back.
[01:05:10.820 --> 01:05:13.180]   It went all the way one way.
[01:05:13.180 --> 01:05:18.260]   As I'm dealing with Gutenberg, sorry, that's a drinking game.
[01:05:18.260 --> 01:05:21.420]   Everybody drink Gutenberg.
[01:05:21.420 --> 01:05:25.580]   We go from the early day of technology where, wow, look at all the things it can do.
[01:05:25.580 --> 01:05:27.780]   And then we go to, oh, look at all the things it can do.
[01:05:27.780 --> 01:05:29.260]   We got to control that.
[01:05:29.260 --> 01:05:33.260]   And then the next phase I think is where we're starting to head into.
[01:05:33.260 --> 01:05:36.780]   I don't know how long it will take is, oh, that's boring.
[01:05:36.780 --> 01:05:40.980]   And then what happens is, oh, what can I make with this?
[01:05:40.980 --> 01:05:45.700]   Well, you know, it struck me that I said this on the show many times, that it took 150 years
[01:05:45.700 --> 01:05:48.660]   after the invention of printing to invent the newspaper.
[01:05:48.660 --> 01:05:52.620]   That was creation not in the technology of printing, but with printing.
[01:05:52.620 --> 01:05:54.500]   Because printing by then was everybody knew how to do it.
[01:05:54.500 --> 01:05:55.500]   It was boring.
[01:05:55.500 --> 01:05:56.500]   There was no big deal.
[01:05:56.500 --> 01:05:58.740]   The Thirty Years War was over.
[01:05:58.740 --> 01:06:01.820]   Now innovations on top of it started to come.
[01:06:01.820 --> 01:06:03.500]   And I think we're a long way from that.
[01:06:03.500 --> 01:06:11.020]   But I wonder if it's not joy to horror, to control, to boredom, to invention.
[01:06:11.020 --> 01:06:14.100]   That's not a different cycle.
[01:06:14.100 --> 01:06:22.460]   So one cycle that I think analyzed the things that you did now is a gardener cycle when
[01:06:22.460 --> 01:06:24.860]   they're talking about the threat of its illusion.
[01:06:24.860 --> 01:06:28.500]   But first you are really enthusiastic about something.
[01:06:28.500 --> 01:06:33.660]   And then, oh no, look at all the unintended consequences and how it's bad.
[01:06:33.660 --> 01:06:38.260]   And then after the happened now, it's got to get to a middle ground that, yeah, we handle
[01:06:38.260 --> 01:06:40.900]   it now and we use it and forget about it.
[01:06:40.900 --> 01:06:45.020]   So different technologies go through this cycle.
[01:06:45.020 --> 01:06:50.780]   And I think social media now is in the, oh no, what it does to society, and I think you're
[01:06:50.780 --> 01:06:54.740]   looking and they escape around of having more middle ground.
[01:06:54.740 --> 01:06:56.180]   And good luck with that.
[01:06:56.180 --> 01:07:04.300]   I just want to mention real quickly the launch is going on right now for Elon Musk's star.
[01:07:04.300 --> 01:07:05.300]   What is it?
[01:07:05.300 --> 01:07:06.300]   His starship?
[01:07:06.300 --> 01:07:07.300]   Go ahead and show it, John.
[01:07:07.300 --> 01:07:10.420]   The rocket that will be going, you can show it, John.
[01:07:10.420 --> 01:07:11.580]   Do you have it?
[01:07:11.580 --> 01:07:12.580]   There we go.
[01:07:12.580 --> 01:07:13.580]   It's just launched.
[01:07:13.580 --> 01:07:18.180]   And in about four minutes, now remember, it's done this several times successfully.
[01:07:18.180 --> 01:07:22.100]   But in four minutes, it's going to do the turnaround and attempt to land.
[01:07:22.100 --> 01:07:26.460]   And the last couple of times it's exploded on landing, which SpaceX was quick to point
[01:07:26.460 --> 01:07:27.620]   out, it's not a failure.
[01:07:27.620 --> 01:07:28.620]   It's not a failure.
[01:07:28.620 --> 01:07:29.980]   It just blew up.
[01:07:29.980 --> 01:07:32.100]   So we'll watch with the interest to see.
[01:07:32.100 --> 01:07:38.780]   It looks like such a different focused spurt of the fire at the bottom.
[01:07:38.780 --> 01:07:40.900]   You think there's a noticeable difference?
[01:07:40.900 --> 01:07:41.900]   Yeah.
[01:07:41.900 --> 01:07:42.900]   Yeah.
[01:07:42.900 --> 01:07:43.900]   It usually is kind of bigger and more.
[01:07:43.900 --> 01:07:44.900]   It's much more condensed.
[01:07:44.900 --> 01:07:45.900]   Yeah.
[01:07:45.900 --> 01:07:46.900]   Yeah.
[01:07:46.900 --> 01:07:47.900]   And of course, the fins on this are--
[01:07:47.900 --> 01:07:48.900]   The fins on this are significant.
[01:07:48.900 --> 01:07:49.900]   I'm sorry.
[01:07:49.900 --> 01:07:50.900]   We don't know.
[01:07:50.900 --> 01:07:52.420]   They have the same thing.
[01:07:52.420 --> 01:07:56.820]   The fins are designed to help it do the flip and landing procedure.
[01:07:56.820 --> 01:08:03.620]   But this is the vehicle that will bring humans to Mars.
[01:08:03.620 --> 01:08:05.580]   Probably tomorrow, I think Elon said it'll happen.
[01:08:05.580 --> 01:08:07.820]   No, Thursday, Friday.
[01:08:07.820 --> 01:08:08.820]   No.
[01:08:08.820 --> 01:08:13.460]   Although, Elon has said he's going to build 100 of these vehicles this year.
[01:08:13.460 --> 01:08:17.420]   So he's really planning an exodus to Mars.
[01:08:17.420 --> 01:08:18.420]   So I don't know.
[01:08:18.420 --> 01:08:19.860]   Should we stick with this for a little bit, John?
[01:08:19.860 --> 01:08:20.860]   I want to see the flip.
[01:08:20.860 --> 01:08:22.300]   If the flip is imminent.
[01:08:22.300 --> 01:08:25.300]   At some point in the show today, Leo, I have an assignment for you.
[01:08:25.300 --> 01:08:26.300]   Yes.
[01:08:26.300 --> 01:08:28.260]   I want you to explain NFTs to me.
[01:08:28.260 --> 01:08:29.900]   Yeah, I do want to.
[01:08:29.900 --> 01:08:33.820]   In fact, we'll mention this as we're waiting for the flip and landing.
[01:08:33.820 --> 01:08:34.820]   My friend--
[01:08:34.820 --> 01:08:35.820]   It's pointed to me too.
[01:08:35.820 --> 01:08:36.820]   Yeah.
[01:08:36.820 --> 01:08:41.380]   So the story with NFTs, which stands for non-fungible tokens.
[01:08:41.380 --> 01:08:42.820]   So a dollar bill is fungible.
[01:08:42.820 --> 01:08:43.820]   What?
[01:08:43.820 --> 01:08:44.820]   That just rolls off the tongue.
[01:08:44.820 --> 01:08:46.300]   Well, but it makes sense if you think about it.
[01:08:46.300 --> 01:08:47.580]   A dollar bill is fungible, right?
[01:08:47.580 --> 01:08:48.780]   It's infinitely fungible.
[01:08:48.780 --> 01:08:51.260]   One dollar bill is exactly like any other.
[01:08:51.260 --> 01:08:52.700]   And it can be exchanged for any other.
[01:08:52.700 --> 01:08:54.620]   It's completely fungible.
[01:08:54.620 --> 01:08:56.220]   Non-fungible tokens are one of a kind.
[01:08:56.220 --> 01:08:58.540]   They cannot be exchanged for anything else.
[01:08:58.540 --> 01:09:05.300]   The idea is, well, if you go to nba topshot.com, you're buying an NBA highlight, which have
[01:09:05.300 --> 01:09:07.940]   sold for hundreds, even thousands of dollars.
[01:09:07.940 --> 01:09:12.420]   And you have the one and only-- not copy.
[01:09:12.420 --> 01:09:14.660]   I don't know, writes to it.
[01:09:14.660 --> 01:09:15.660]   Artworks been sold that way.
[01:09:15.660 --> 01:09:16.660]   Elon Musk's--
[01:09:16.660 --> 01:09:18.740]   I don't know what to call her.
[01:09:18.740 --> 01:09:21.220]   Baby Mama, is that OK?
[01:09:21.220 --> 01:09:22.860]   The mother of his children?
[01:09:22.860 --> 01:09:23.860]   Child?
[01:09:23.860 --> 01:09:25.340]   It's a fact.
[01:09:25.340 --> 01:09:26.340]   Partner?
[01:09:26.340 --> 01:09:27.340]   Partner?
[01:09:27.340 --> 01:09:28.340]   That's fine.
[01:09:28.340 --> 01:09:29.340]   But I don't know if they're still partners, to be honest with you.
[01:09:29.340 --> 01:09:34.260]   The only thing we know for sure is they have a child together.
[01:09:34.260 --> 01:09:44.060]   Anyway, Grimes, she's a kind of outrageous rock star performer, sold an unbelievable
[01:09:44.060 --> 01:09:53.540]   $5.8 million worth of her artwork as digital versions as NFTs in 28 minutes.
[01:09:53.540 --> 01:09:58.940]   So she made-- now, I've been mentioning this story a couple of times and it shows what
[01:09:58.940 --> 01:10:02.780]   I didn't think of as, well, who spent $300,000 for Grimes' digital artwork?
[01:10:02.780 --> 01:10:07.020]   And then I realized, I wonder if she knows anybody with a lot of money.
[01:10:07.020 --> 01:10:09.860]   Who can move markets?
[01:10:09.860 --> 01:10:10.860]   Who can move markets.
[01:10:10.860 --> 01:10:15.020]   I mean, to Elon Musk, $5.8 million is nothing.
[01:10:15.020 --> 01:10:16.180]   That's cigarette money.
[01:10:16.180 --> 01:10:18.180]   OK, the rocket is smoking.
[01:10:18.180 --> 01:10:22.580]   So I think it's either-- is this good, John, the smoking?
[01:10:22.580 --> 01:10:23.580]   That's fine, OK?
[01:10:23.580 --> 01:10:24.580]   [LAUGHTER]
[01:10:24.580 --> 01:10:25.580]   Cross and fingers.
[01:10:25.580 --> 01:10:28.260]   It looks like the cigar I smoked last year.
[01:10:28.260 --> 01:10:37.500]   Anyway, these NFTs are all the rage, whether it's artwork, NBA top shots, NBA highlights.
[01:10:37.500 --> 01:10:41.060]   You may remember we talked about CryptoKitties a year or two ago.
[01:10:41.060 --> 01:10:45.540]   These were digital cats that could breed interbreed and people were spending millions
[01:10:45.540 --> 01:10:46.540]   to buy this.
[01:10:46.540 --> 01:10:47.860]   This is pure speculation.
[01:10:47.860 --> 01:10:49.260]   That's, I think, the bottom line.
[01:10:49.260 --> 01:10:54.580]   So Trey Radcliffe, one of my friends and a great photographer today-- in fact, I tried
[01:10:54.580 --> 01:10:55.580]   to get him on the show.
[01:10:55.580 --> 01:10:56.580]   I haven't heard from me.
[01:10:56.580 --> 01:10:57.580]   He's in New Zealand.
[01:10:57.580 --> 01:10:59.140]   He may be asleep.
[01:10:59.140 --> 01:11:00.140]   Said, "I will send you."
[01:11:00.140 --> 01:11:01.140]   Let me see if I can find his email.
[01:11:01.140 --> 01:11:05.660]   He said, "I will send you one of my artworks as an NFT."
[01:11:05.660 --> 01:11:08.740]   I said, "Oh, it's coming down.
[01:11:08.740 --> 01:11:09.740]   It's coming down.
[01:11:09.740 --> 01:11:10.740]   It's flipped.
[01:11:10.740 --> 01:11:11.740]   It's flipped.
[01:11:11.740 --> 01:11:12.740]   Let's see what's going on here."
[01:11:12.740 --> 01:11:17.900]   So, it's got to flip over, obviously, so it can land.
[01:11:17.900 --> 01:11:18.900]   This feels like we're watching--
[01:11:18.900 --> 01:11:19.900]   It's good camera work.
[01:11:19.900 --> 01:11:20.900]   --Buck Rogers.
[01:11:20.900 --> 01:11:21.900]   Yeah, exactly.
[01:11:21.900 --> 01:11:25.660]   It's Flash Gordon in the 21st century.
[01:11:25.660 --> 01:11:26.660]   [LAUGHTER]
[01:11:26.660 --> 01:11:28.300]   Ha, ha, ha.
[01:11:28.300 --> 01:11:30.940]   You save every one of us?
[01:11:30.940 --> 01:11:33.260]   Anyway, we'll keep watching this while I talk.
[01:11:33.260 --> 01:11:34.260]   That's fine.
[01:11:34.260 --> 01:11:37.180]   But, you know, this time, don't lose the password, huh?
[01:11:37.180 --> 01:11:41.220]   So he said, "I wanted to offer you one of my Burning Man photo NFTs as a gift for being
[01:11:41.220 --> 01:11:42.220]   an awesome dude.
[01:11:42.220 --> 01:11:43.340]   Thank you, Trey.
[01:11:43.340 --> 01:11:45.060]   You can do whatever you want with it.
[01:11:45.060 --> 01:11:47.740]   One idea is to auction it off for a charity, if you like.
[01:11:47.740 --> 01:11:51.300]   But hey, it will be a little blockchain gift for my friend."
[01:11:51.300 --> 01:11:53.780]   And I said, "I promise not to resell it.
[01:11:53.780 --> 01:11:55.980]   I don't know what I can do with it.
[01:11:55.980 --> 01:11:57.140]   Do I print it?
[01:11:57.140 --> 01:11:59.220]   What can I do with it?"
[01:11:59.220 --> 01:12:00.820]   But I do promise not to resell it.
[01:12:00.820 --> 01:12:04.900]   But what I'd like to get to is get Trey on and explain this because obviously he's got
[01:12:04.900 --> 01:12:09.980]   a handle on whatever this is, this NFT thing, non-fungible tokens.
[01:12:09.980 --> 01:12:11.540]   They're the opposite of dollar bills.
[01:12:11.540 --> 01:12:12.580]   Well, let's trust me about it.
[01:12:12.580 --> 01:12:14.300]   I was trying to get my head around it.
[01:12:14.300 --> 01:12:18.940]   You know, I learned that at the beginning of copyright, the argument was this is good
[01:12:18.940 --> 01:12:22.820]   for authors, but what it really did was the booksellers, one of the authors to be able
[01:12:22.820 --> 01:12:25.380]   to own it so they could sell it to the booksellers.
[01:12:25.380 --> 01:12:29.300]   And then it made creativity into a tradable asset.
[01:12:29.300 --> 01:12:31.500]   Yeah, although...
[01:12:31.500 --> 01:12:34.300]   So I wonder in this case...
[01:12:34.300 --> 01:12:35.300]   Oh, look at this.
[01:12:35.300 --> 01:12:37.500]   Oh, this is so buckroggers.
[01:12:37.500 --> 01:12:39.180]   I cannot believe this.
[01:12:39.180 --> 01:12:40.700]   Oh, I see now, Jesus.
[01:12:40.700 --> 01:12:42.260]   Oh my God.
[01:12:42.260 --> 01:12:43.660]   So this is where, of course...
[01:12:43.660 --> 01:12:44.660]   Is it going to do it?
[01:12:44.660 --> 01:12:45.660]   It failed in the past.
[01:12:45.660 --> 01:12:49.140]   But you know, Elon, he's going to figure it out.
[01:12:49.140 --> 01:12:52.020]   They've got to land exactly upright, otherwise it won't stand.
[01:12:52.020 --> 01:12:54.180]   And I think it succeeded.
[01:12:54.180 --> 01:13:00.980]   Ladies and gentlemen, Starship has landed six minutes and 27 seconds into its flight.
[01:13:00.980 --> 01:13:02.300]   It's still burning at the bottom.
[01:13:02.300 --> 01:13:03.300]   I don't know.
[01:13:03.300 --> 01:13:04.300]   No, that's just...
[01:13:04.300 --> 01:13:05.300]   Wait a minute.
[01:13:05.300 --> 01:13:10.700]   You know, a lot of the clouds, I didn't know this until I learned something, are water vapor
[01:13:10.700 --> 01:13:11.900]   in on these launches.
[01:13:11.900 --> 01:13:16.180]   They use water vapor to cool the launching pad.
[01:13:16.180 --> 01:13:18.220]   And so a lot of what you think is smoke...
[01:13:18.220 --> 01:13:19.220]   Something's burning down there.
[01:13:19.220 --> 01:13:20.220]   Still standing.
[01:13:20.220 --> 01:13:21.220]   Something's burning.
[01:13:21.220 --> 01:13:24.460]   You know, that's the jet, the little jet.
[01:13:24.460 --> 01:13:25.460]   The little jet is...
[01:13:25.460 --> 01:13:27.460]   As long as it doesn't get bigger, it's getting bigger.
[01:13:27.460 --> 01:13:28.460]   It doesn't get any bigger.
[01:13:28.460 --> 01:13:29.460]   It's got to...
[01:13:29.460 --> 01:13:30.460]   I don't know.
[01:13:30.460 --> 01:13:31.460]   I don't know.
[01:13:31.460 --> 01:13:32.460]   We're going to see...
[01:13:32.460 --> 01:13:35.940]   Elon, you're going out there with the fire force.
[01:13:35.940 --> 01:13:41.380]   As nutty as he is, he's really amazing to at the same time.
[01:13:41.380 --> 01:13:42.380]   I don't know.
[01:13:42.380 --> 01:13:47.860]   He's as confusing as non-fungible tokens.
[01:13:47.860 --> 01:13:54.100]   I still look at that and just marvel at just the brains behind making that happen.
[01:13:54.100 --> 01:13:58.020]   Yet you go downtown, Petaluma, and people can't parallel apart.
[01:13:58.020 --> 01:13:59.020]   I know.
[01:13:59.020 --> 01:14:01.020]   Actually, if you had a Tesla...
[01:14:01.020 --> 01:14:02.020]   Downtown where?
[01:14:02.020 --> 01:14:03.940]   It would parallel apart for you.
[01:14:03.940 --> 01:14:04.940]   Petaluma.
[01:14:04.940 --> 01:14:05.940]   Is it a town where?
[01:14:05.940 --> 01:14:06.940]   Petaluma.
[01:14:06.940 --> 01:14:07.940]   Is it a town where?
[01:14:07.940 --> 01:14:08.940]   Petaluma.
[01:14:08.940 --> 01:14:09.940]   Is it a town where?
[01:14:09.940 --> 01:14:10.940]   Petaluma.
[01:14:10.940 --> 01:14:11.940]   Is it a town where?
[01:14:11.940 --> 01:14:12.940]   Petaluma.
[01:14:12.940 --> 01:14:13.940]   Is it a town where?
[01:14:13.940 --> 01:14:14.940]   Petaluma.
[01:14:14.940 --> 01:14:15.940]   Is it a town where?
[01:14:15.940 --> 01:14:16.940]   Petaluma.
[01:14:16.940 --> 01:14:24.940]   The story behind this one is that the city of the town, a little town we live in, of Petaluma,
[01:14:24.940 --> 01:14:34.300]   banned gas stations, first content in the country, to ban gas stations.
[01:14:34.300 --> 01:14:41.340]   Part of the reason for doing that, besides the fact that I do believe that...
[01:14:41.340 --> 01:14:45.140]   I'm looking for the clip.
[01:14:45.140 --> 01:14:46.300]   Here it is up here.
[01:14:46.300 --> 01:14:47.300]   Is this it?
[01:14:47.300 --> 01:14:48.300]   No.
[01:14:48.300 --> 01:14:51.340]   No foreign fans allowed at Tokyo Olympics.
[01:14:51.340 --> 01:14:53.180]   Oh, that's a coma.
[01:14:53.180 --> 01:14:54.180]   Yeah.
[01:14:54.180 --> 01:14:56.260]   Let me open this up.
[01:14:56.260 --> 01:14:58.540]   Just as the setup.
[01:14:58.540 --> 01:15:02.100]   Of course, electric vehicles are big in California, and they're taking off.
[01:15:02.100 --> 01:15:06.660]   California said they will only allow electric vehicles in the coming decades.
[01:15:06.660 --> 01:15:10.900]   Also, here in Petaluma, we have a number of areas of downtown.
[01:15:10.900 --> 01:15:14.700]   You don't even know this, but there's a big area in the downtown that can't be used,
[01:15:14.700 --> 01:15:16.700]   because it was a gas station.
[01:15:16.700 --> 01:15:20.820]   When I moved here, it was a Chevron station, and the tanks leaked as all gas station tanks
[01:15:20.820 --> 01:15:24.140]   do, and it can't be remediated except for millions of dollars so nobody can use that
[01:15:24.140 --> 01:15:25.140]   plot of land.
[01:15:25.140 --> 01:15:29.660]   There are three or four of those in Petaluma, old gas stations that are gone, but the land
[01:15:29.660 --> 01:15:30.660]   is useless.
[01:15:30.660 --> 01:15:31.660]   Yeah, you're talking that.
[01:15:31.660 --> 01:15:33.620]   Yeah, I think it's a good thing.
[01:15:33.620 --> 01:15:38.700]   So this is the story from Como News, because our city council, which had a two-year moratorium
[01:15:38.700 --> 01:15:41.260]   on building gas stations, finally said, "You know, we have enough.
[01:15:41.260 --> 01:15:42.420]   We don't need any more.
[01:15:42.420 --> 01:15:44.180]   No more gas stations in Petaluma."
[01:15:44.180 --> 01:15:45.180]   Here's the story.
[01:15:45.180 --> 01:15:50.020]   One West Coast city is banning the construction of new gas stations.
[01:15:50.020 --> 01:15:56.660]   City leaders in the Northern California town of Petamula believe this is the first
[01:15:56.660 --> 01:15:58.700]   span of its kind in the U.S.
[01:15:58.700 --> 01:15:59.700]   What?
[01:15:59.700 --> 01:16:00.700]   What?
[01:16:00.700 --> 01:16:01.700]   What?
[01:16:01.700 --> 01:16:02.700]   What?
[01:16:02.700 --> 01:16:03.700]   What?
[01:16:03.700 --> 01:16:04.700]   What?
[01:16:04.700 --> 01:16:05.700]   What?
[01:16:05.700 --> 01:16:06.700]   What?
[01:16:06.700 --> 01:16:07.700]   Petamula.
[01:16:07.700 --> 01:16:09.580]   Okay, that's where we live in Petamula.
[01:16:09.580 --> 01:16:12.500]   All right, that was just inside baseball.
[01:16:12.500 --> 01:16:14.500]   There was no reason to do that.
[01:16:14.500 --> 01:16:15.740]   Sorry, I'm not even going to.
[01:16:15.740 --> 01:16:16.740]   Sorry, you're great.
[01:16:16.740 --> 01:16:17.740]   We'll get back to the show.
[01:16:17.740 --> 01:16:19.740]   That's for all of our questions.
[01:16:19.740 --> 01:16:20.740]   Anyway, in FTS.
[01:16:20.740 --> 01:16:21.740]   We do hear.
[01:16:21.740 --> 01:16:23.220]   Do you have a take?
[01:16:23.220 --> 01:16:27.660]   Do you have a take and read on these NFTs?
[01:16:27.660 --> 01:16:29.220]   This is just wild.
[01:16:29.220 --> 01:16:34.340]   I had just one thought, really stupid, crazy one, when you talked about Elon Musk may be
[01:16:34.340 --> 01:16:35.500]   funded it.
[01:16:35.500 --> 01:16:38.340]   I'm binge watching Breaking Bad.
[01:16:38.340 --> 01:16:44.980]   So there's a period where Walter White, to launder his money, using soul goodness as
[01:16:44.980 --> 01:16:52.060]   a site that his son actually made for donation to Walter White.
[01:16:52.060 --> 01:16:53.060]   That's right.
[01:16:53.060 --> 01:16:55.220]   For his cancer treatment, which he doesn't have, right?
[01:16:55.220 --> 01:16:59.820]   His money with actually Russian bots.
[01:16:59.820 --> 01:17:01.820]   Oh my God.
[01:17:01.820 --> 01:17:03.540]   That's right.
[01:17:03.540 --> 01:17:08.140]   Normal people in the U.S. paying for his cancer treatment, but it was actually Walter White
[01:17:08.140 --> 01:17:10.180]   and his money using chocolate mens.
[01:17:10.180 --> 01:17:12.580]   So that's the only thought I had.
[01:17:12.580 --> 01:17:14.220]   You talked about it.
[01:17:14.220 --> 01:17:18.260]   Lindsey Lohan sold an NFT for $59,000.
[01:17:18.260 --> 01:17:23.060]   Mark Cuban says you got to invest in NFTs.
[01:17:23.060 --> 01:17:26.620]   This is a Grimes art piece, "Death of the Old."
[01:17:26.620 --> 01:17:31.300]   This sold for $400,000.
[01:17:31.300 --> 01:17:34.260]   But somebody pointed out, we were talking about this on Twitter on Sunday.
[01:17:34.260 --> 01:17:38.100]   I think it was Lance Unenoff pointed out, you know, this has been going on.
[01:17:38.100 --> 01:17:41.060]   And going on for years in the fine art world.
[01:17:41.060 --> 01:17:42.980]   The art business is a Basquiat.
[01:17:42.980 --> 01:17:47.100]   I don't think Basquiat's paintings are that gorgeous, but they sell for tens of millions
[01:17:47.100 --> 01:17:50.060]   of dollars because it's speculation.
[01:17:50.060 --> 01:17:51.060]   It's a...
[01:17:51.060 --> 01:17:52.060]   Yeah.
[01:17:52.060 --> 01:17:54.060]   So the problem is that it's...
[01:17:54.060 --> 01:17:58.820]   To me, it's the last gasp of the property metaphor that copyright started, that acts
[01:17:58.820 --> 01:18:04.700]   as if creativity is a tangible thing as opposed to an act.
[01:18:04.700 --> 01:18:11.220]   And if you look at part of me and Ratatouille, the musical, there were many contributions.
[01:18:11.220 --> 01:18:13.940]   I'm going to bring this in every time I can.
[01:18:13.940 --> 01:18:15.780]   I'm going to get us a new drinking game.
[01:18:15.780 --> 01:18:17.340]   It's in the drinking game.
[01:18:17.340 --> 01:18:18.340]   You're at...
[01:18:18.340 --> 01:18:20.420]   Yeah, you have to drink if he says it.
[01:18:20.420 --> 01:18:21.420]   Don't do it.
[01:18:21.420 --> 01:18:22.420]   Don't do it.
[01:18:22.420 --> 01:18:23.980]   And can't stand musicals.
[01:18:23.980 --> 01:18:25.980]   So that's why.
[01:18:25.980 --> 01:18:32.900]   So, but there was a string of creativity there where everyone got to contribute to it.
[01:18:32.900 --> 01:18:37.100]   And for once didn't stop it because they recognized, as I said in my tweet, that value
[01:18:37.100 --> 01:18:43.300]   redounded to their Rat, and they created value because no one owned it.
[01:18:43.300 --> 01:18:47.540]   Instead, everyone contributed and everyone benefited according to their desires.
[01:18:47.540 --> 01:18:48.540]   Maybe it was just attention.
[01:18:48.540 --> 01:18:50.420]   Maybe it was making the musical happen.
[01:18:50.420 --> 01:18:53.100]   Maybe it was feeling smart with your friends.
[01:18:53.100 --> 01:18:55.180]   Whatever it was, it was a different structure.
[01:18:55.180 --> 01:18:59.740]   Whereas NFTs seem to be the exact opposite where they make everything into a tradable
[01:18:59.740 --> 01:19:00.740]   property.
[01:19:00.740 --> 01:19:01.740]   I have it.
[01:19:01.740 --> 01:19:02.740]   Yeah.
[01:19:02.740 --> 01:19:04.100]   Here is a painting.
[01:19:04.100 --> 01:19:06.460]   I'm going to show you a painting.
[01:19:06.460 --> 01:19:08.540]   This is a Basquiat.
[01:19:08.540 --> 01:19:09.540]   You like it?
[01:19:09.540 --> 01:19:10.540]   Yeah.
[01:19:10.540 --> 01:19:15.940]   How much do you think it's worth?
[01:19:15.940 --> 01:19:17.380]   I would have swined it out.
[01:19:17.380 --> 01:19:19.740]   That doesn't include the person walking by it, by the way.
[01:19:19.740 --> 01:19:21.500]   Just the painting.
[01:19:21.500 --> 01:19:23.220]   That's $110 million.
[01:19:23.220 --> 01:19:25.220]   Oh, shoot.
[01:19:25.220 --> 01:19:29.980]   A $110 million sold auction at Christie's a couple of years ago.
[01:19:29.980 --> 01:19:30.980]   Wow.
[01:19:30.980 --> 01:19:31.980]   That's a nice idea.
[01:19:31.980 --> 01:19:33.980]   Art selling my daughter's paintings.
[01:19:33.980 --> 01:19:35.060]   She's five and a half.
[01:19:35.060 --> 01:19:37.220]   I bet you can make a lot of money near it.
[01:19:37.220 --> 01:19:38.980]   It looks like that.
[01:19:38.980 --> 01:19:43.740]   She says, "Yeah, it looks like you."
[01:19:43.740 --> 01:19:47.940]   Line 78, at least swoops to someone.
[01:19:47.940 --> 01:19:50.780]   Actually, I'm trying to get her on hands on photography.
[01:19:50.780 --> 01:19:52.260]   I met her a couple of years ago.
[01:19:52.260 --> 01:19:57.380]   She's an Instagram influencer, and I know she doesn't really care to hear that, but she
[01:19:57.380 --> 01:19:58.380]   is.
[01:19:58.380 --> 01:20:03.900]   She has an NFT, and it just sold a couple hours ago for about $17,000.
[01:20:03.900 --> 01:20:08.620]   She just uses her iPhone because she doesn't like to use her camera.
[01:20:08.620 --> 01:20:14.020]   She uses her iPhone to snap photos and to edit photos and make them all mystical and
[01:20:14.020 --> 01:20:15.020]   funny and beautiful.
[01:20:15.020 --> 01:20:16.020]   Oh, they're beautiful.
[01:20:16.020 --> 01:20:17.020]   They're really cool.
[01:20:17.020 --> 01:20:18.020]   I love this.
[01:20:18.020 --> 01:20:20.140]   She's a super talented creator.
[01:20:20.140 --> 01:20:24.140]   She decided to jump on this and sold her first one today.
[01:20:24.140 --> 01:20:28.020]   I'm looking at that and it makes me happy to see that a creator is able to...
[01:20:28.020 --> 01:20:31.180]   I'm a little nervous in the art.
[01:20:31.180 --> 01:20:33.300]   This is a cinemagraph, right?
[01:20:33.300 --> 01:20:38.420]   It's a still picture, but some of it's in motion.
[01:20:38.420 --> 01:20:39.580]   That's problem number one.
[01:20:39.580 --> 01:20:42.580]   You can't put that on the wall.
[01:20:42.580 --> 01:20:44.340]   You can't even print it.
[01:20:44.340 --> 01:20:49.500]   It has to be digital for it to be perceived.
[01:20:49.500 --> 01:20:54.860]   NFTs have solved, in at least this respect, is using blockchain.
[01:20:54.860 --> 01:20:58.940]   You can be the unique one and only owner of this document.
[01:20:58.940 --> 01:21:02.540]   It may be infinitely reproducible because it's digital.
[01:21:02.540 --> 01:21:07.220]   It can be perfectly reproduced infinitely, but only you own it.
[01:21:07.220 --> 01:21:09.780]   It's up to you whether to reproduce it, I guess.
[01:21:09.780 --> 01:21:10.940]   But blockchain allows that.
[01:21:10.940 --> 01:21:15.420]   Yeah, because ownership brings rights under the copyright rule.
[01:21:15.420 --> 01:21:17.020]   Blockchain allows that.
[01:21:17.020 --> 01:21:22.860]   NFTs all use blockchain to prove ownership as far as I know.
[01:21:22.860 --> 01:21:25.220]   I don't know.
[01:21:25.220 --> 01:21:28.420]   This is another problem in tech journalism.
[01:21:28.420 --> 01:21:31.980]   When you get to my age...
[01:21:31.980 --> 01:21:32.980]   You've seen it all.
[01:21:32.980 --> 01:21:34.620]   It stops making sense.
[01:21:34.620 --> 01:21:36.740]   I don't understand this at all.
[01:21:36.740 --> 01:21:45.660]   I understand how older people felt back in 1984 when the Macintosh came out.
[01:21:45.660 --> 01:21:47.260]   I don't understand.
[01:21:47.260 --> 01:21:48.980]   Why would you want a computer on your desk?
[01:21:48.980 --> 01:21:50.660]   Because it makes no sense at all.
[01:21:50.660 --> 01:21:54.260]   I'm not at your age yet and there's a lot of days where I still stay.
[01:21:54.260 --> 01:21:56.340]   You're old before your time, man.
[01:21:56.340 --> 01:21:57.340]   What is it for?
[01:21:57.340 --> 01:21:58.340]   I'm old-ish.
[01:21:58.340 --> 01:22:00.580]   I will definitely say I'm old-ish.
[01:22:00.580 --> 01:22:01.980]   Yeah, yeah.
[01:22:01.980 --> 01:22:02.980]   Yeah.
[01:22:02.980 --> 01:22:04.940]   Old and wise, man.
[01:22:04.940 --> 01:22:06.420]   Old and wise.
[01:22:06.420 --> 01:22:09.140]   Let me take a break.
[01:22:09.140 --> 01:22:10.140]   Another break here.
[01:22:10.140 --> 01:22:12.060]   Actually, do we have a change?
[01:22:12.060 --> 01:22:13.060]   Oh, we do.
[01:22:13.060 --> 01:22:14.060]   We do.
[01:22:14.060 --> 01:22:15.860]   Thank you, Jason.
[01:22:15.860 --> 01:22:18.340]   Jason stuck some stuff in the change log.
[01:22:18.340 --> 01:22:21.700]   Let's do that and then we'll take a break right after that.
[01:22:21.700 --> 01:22:23.380]   I want to give another big plug.
[01:22:23.380 --> 01:22:31.780]   To Techlash, the book, our guest is the author.
[01:22:31.780 --> 01:22:34.460]   It's really wonderful to have you, Nereet.
[01:22:34.460 --> 01:22:35.620]   You can get it at...
[01:22:35.620 --> 01:22:36.620]   What's the website?
[01:22:36.620 --> 01:22:37.620]   Techlash.
[01:22:37.620 --> 01:22:38.620]   The book?
[01:22:38.620 --> 01:22:39.620]   Is that it?
[01:22:39.620 --> 01:22:44.300]   Techlashbook.com is just me putting info, but it's actually on Amazon and all the other.
[01:22:44.300 --> 01:22:48.660]   It's a novel and the publisher, Emerald Publishing, everywhere.
[01:22:48.660 --> 01:22:50.340]   Doctor Techlash.
[01:22:50.340 --> 01:22:54.980]   Actually, we should point out it's expensive book because it's an academic book, right?
[01:22:54.980 --> 01:22:56.620]   It's not intended for a public book.
[01:22:56.620 --> 01:23:01.580]   Yeah, it's an academic publisher, academic book, but although it's for scholars and students
[01:23:01.580 --> 01:23:03.580]   who want to know about...
[01:23:03.580 --> 01:23:05.580]   For all kinds of folks, it's fascinating.
[01:23:05.580 --> 01:23:08.580]   It's called the "Pelting Ministry Tech, General Tech, PR professionals."
[01:23:08.580 --> 01:23:10.700]   Well, especially because it's data-driven.
[01:23:10.700 --> 01:23:11.780]   It's not just your idea.
[01:23:11.780 --> 01:23:12.780]   It's based on...
[01:23:12.780 --> 01:23:14.780]   It's based on...
[01:23:14.780 --> 01:23:15.940]   It's a research base, yeah.
[01:23:15.940 --> 01:23:18.580]   Yeah, a lot of research.
[01:23:18.580 --> 01:23:22.420]   Doctor Weissblatt was a research fellow at the University of Southern California, Annenberg
[01:23:22.420 --> 01:23:27.180]   School for Communication and Journalism, which is almost as famous as the Craig Neumark
[01:23:27.180 --> 01:23:30.580]   Graduate School journalism at the City University of New York.
[01:23:30.580 --> 01:23:32.700]   I don't know who this Annenberg guy is.
[01:23:32.700 --> 01:23:35.580]   But I'm sure he's just as good as Craig Neumark.
[01:23:35.580 --> 01:23:36.980]   His day is gone.
[01:23:36.980 --> 01:23:38.260]   Yeah, probably, you know what?
[01:23:38.260 --> 01:23:41.060]   A lot of people have no idea.
[01:23:41.060 --> 01:23:44.300]   But Annenberg is at... or what TV Guide is, right?
[01:23:44.300 --> 01:23:47.100]   TV Guide, except I was a critic there once.
[01:23:47.100 --> 01:23:53.100]   Yes, you're the last remaining mention of TV Guide in the world.
[01:23:53.100 --> 01:23:54.100]   Congratulations.
[01:23:54.100 --> 01:23:55.100]   Congratulations.
[01:23:55.100 --> 01:23:56.100]   Congratulations.
[01:23:56.100 --> 01:23:57.980]   He's a former TV Guide critic, right?
[01:23:57.980 --> 01:23:59.940]   You probably didn't know that when you interviewed him.
[01:23:59.940 --> 01:24:00.940]   I know.
[01:24:00.940 --> 01:24:01.940]   It's written in my book.
[01:24:01.940 --> 01:24:02.940]   Oh, it's in the book.
[01:24:02.940 --> 01:24:03.940]   Wow.
[01:24:03.940 --> 01:24:04.940]   I mentioned that.
[01:24:04.940 --> 01:24:05.940]   Wow.
[01:24:05.940 --> 01:24:06.940]   Wow.
[01:24:06.940 --> 01:24:07.940]   I cannot escape.
[01:24:07.940 --> 01:24:08.940]   He's back.
[01:24:08.940 --> 01:24:11.220]   And he's not dead yet.
[01:24:11.220 --> 01:24:12.940]   It's time for...
[01:24:12.940 --> 01:24:17.900]   The Google Change Log.
[01:24:17.900 --> 01:24:19.900]   The thing blew up afterwards.
[01:24:19.900 --> 01:24:21.820]   Oh, the rocket blew up afterwards.
[01:24:21.820 --> 01:24:22.820]   You were right there.
[01:24:22.820 --> 01:24:23.820]   I told you.
[01:24:23.820 --> 01:24:24.820]   It had a little fire at the bottom.
[01:24:24.820 --> 01:24:25.660]   I told you it was on fire.
[01:24:25.660 --> 01:24:29.460]   It sat there for a while, thinking, and then decided to blow up.
[01:24:29.460 --> 01:24:32.700]   Hey, you know, one step at a time.
[01:24:32.700 --> 01:24:34.700]   Hey, man.
[01:24:34.700 --> 01:24:36.100]   Hi.
[01:24:36.100 --> 01:24:37.940]   I'm not sure we should be going to Mars.
[01:24:37.940 --> 01:24:39.180]   It was a good article.
[01:24:39.180 --> 01:24:41.540]   Where was it, The Atlantic, I think, online?
[01:24:41.540 --> 01:24:42.540]   Maybe it's not a good...
[01:24:42.540 --> 01:24:45.460]   Maybe it's really not where you ought to be going, but that's...
[01:24:45.460 --> 01:24:46.460]   It's still...
[01:24:46.460 --> 01:24:48.980]   I love space exploration.
[01:24:48.980 --> 01:24:51.900]   March Pixel Feature Drop.
[01:24:51.900 --> 01:24:54.060]   If those are forwards, it makes no sense to you.
[01:24:54.060 --> 01:24:55.860]   See your doctor.
[01:24:55.860 --> 01:24:57.700]   Mark is the month.
[01:24:57.700 --> 01:24:58.980]   Pixel is the phone.
[01:24:58.980 --> 01:25:03.060]   Feature Drop is something Google does every few months to their Pixel phones.
[01:25:03.060 --> 01:25:07.500]   And boy, this is why you want a Pixel phone.
[01:25:07.500 --> 01:25:12.380]   The Feature Drop includes underwater photography.
[01:25:12.380 --> 01:25:13.380]   The recorder?
[01:25:13.380 --> 01:25:15.660]   Explain that to us, Ant.
[01:25:15.660 --> 01:25:17.820]   It's more so about the UI.
[01:25:17.820 --> 01:25:21.100]   You get the particular phone case.
[01:25:21.100 --> 01:25:22.100]   You still need a house.
[01:25:22.100 --> 01:25:24.220]   You can't just take the phone down below.
[01:25:24.220 --> 01:25:25.220]   Right.
[01:25:25.220 --> 01:25:29.660]   And so you have the UI that's enhanced for that case to allow you to take photographs.
[01:25:29.660 --> 01:25:35.900]   Life proof has had waterproof cases out for a handful of years now, especially more so
[01:25:35.900 --> 01:25:37.780]   for the iPhone.
[01:25:37.780 --> 01:25:43.100]   When I used to run a smartphone photographers community, friend of mine, Mr. Mike Sweeney,
[01:25:43.100 --> 01:25:49.860]   he took some amazing shots with his iPhone 4 in the pool, but he had a life proof case.
[01:25:49.860 --> 01:25:54.460]   And it was easy because of the way the iPhone camera interface was.
[01:25:54.460 --> 01:25:57.980]   He could see it pretty clearly and be able to tap and do what he needed to do and control
[01:25:57.980 --> 01:25:59.820]   its motion and stuff like that.
[01:25:59.820 --> 01:26:07.140]   So what's happening here is that the Pixel is actually adding features for dive case connector.
[01:26:07.140 --> 01:26:11.980]   So if you have a dive case that's built to use the Pixel phone, which is nice because
[01:26:11.980 --> 01:26:15.860]   you could use night sight, you could use portrait mode if you get a really good looking
[01:26:15.860 --> 01:26:16.860]   fish.
[01:26:16.860 --> 01:26:17.860]   Yeah.
[01:26:17.860 --> 01:26:25.780]   So it works with the Kraken Sport Housing, which is a very good name for a sport housing.
[01:26:25.780 --> 01:26:31.940]   That's just one of a number of features in the feature drop measure, heart and respiratory
[01:26:31.940 --> 01:26:33.580]   rate in Google Fit.
[01:26:33.580 --> 01:26:37.380]   This is, we mentioned this a couple of weeks ago, where you could just point your camera
[01:26:37.380 --> 01:26:40.820]   at you and you could see how you're breathing.
[01:26:40.820 --> 01:26:44.780]   There also is a backup, cloud backup for the recorder app, which should have had all
[01:26:44.780 --> 01:26:45.780]   long.
[01:26:45.780 --> 01:26:47.020]   I'm just kind of surprised it didn't.
[01:26:47.020 --> 01:26:52.140]   But the recorder app is a very nice way of making, you know, dictating audio recordings.
[01:26:52.140 --> 01:26:57.500]   There's a smart compose being added to Gboard, Google's keyboard.
[01:26:57.500 --> 01:26:59.500]   That's very handy.
[01:26:59.500 --> 01:27:01.340]   Pixel stand has a new bedtime.
[01:27:01.340 --> 01:27:02.540]   I have a Pixel stand.
[01:27:02.540 --> 01:27:04.100]   I don't know why, but I do.
[01:27:04.100 --> 01:27:06.340]   Has a new bedtime screen and read the sound.
[01:27:06.340 --> 01:27:07.340]   Why are you such a shmock?
[01:27:07.340 --> 01:27:08.340]   I'm a shmock.
[01:27:08.340 --> 01:27:09.340]   It's not the best.
[01:27:09.340 --> 01:27:10.940]   It's a, you know, it's a G charger.
[01:27:10.940 --> 01:27:12.540]   It's an easel charger.
[01:27:12.540 --> 01:27:15.300]   It's not the best, but I guess I'll put my Pixel on it.
[01:27:15.300 --> 01:27:17.980]   It's apparently it's going to now tell me it's time for bed.
[01:27:17.980 --> 01:27:19.380]   Wonderful.
[01:27:19.380 --> 01:27:24.340]   And speaking of NFTs, there's new wallpaper.
[01:27:24.340 --> 01:27:26.740]   This is for Black History Month.
[01:27:26.740 --> 01:27:33.220]   In the curated culture section, it's actually, it's not for Black History Month.
[01:27:33.220 --> 01:27:34.220]   That was last month.
[01:27:34.220 --> 01:27:39.940]   This is International Women's Day coming up March 8th and this is focusing on the strength
[01:27:39.940 --> 01:27:45.460]   and transformation of women illustrated by Spanish duo, Casheta Jack.
[01:27:45.460 --> 01:27:46.460]   Casheta Jack.
[01:27:46.460 --> 01:27:48.020]   I don't know how you pronounce that.
[01:27:48.020 --> 01:27:52.460]   Anyway, lots of new stuff for your Pixel phone.
[01:27:52.460 --> 01:27:55.740]   Developer Preview 1.1 for Android 12 is out now.
[01:27:55.740 --> 01:27:59.500]   Some big bug fixes.
[01:27:59.500 --> 01:28:01.260]   Chrome 89 is coming out.
[01:28:01.260 --> 01:28:03.660]   Google's really been beefing up Chrome.
[01:28:03.660 --> 01:28:06.140]   There's a lot of competition for Chrome now.
[01:28:06.140 --> 01:28:09.180]   And I think even though it's the number one browser, they're working hard to make sure
[01:28:09.180 --> 01:28:10.180]   that they stay.
[01:28:10.180 --> 01:28:11.180]   Selfie.
[01:28:11.180 --> 01:28:14.660]   Yeah, they stay number one.
[01:28:14.660 --> 01:28:17.500]   Chrome 89 will have several enhancements.
[01:28:17.500 --> 01:28:23.620]   Chrome Profiles are revamped to the new modern page.
[01:28:23.620 --> 01:28:29.380]   A reading list, which is something that Safari's had for a while where you can be on a page.
[01:28:29.380 --> 01:28:32.260]   You can tap the star icon in the address bar.
[01:28:32.260 --> 01:28:36.020]   And in addition to making a bookmark, which that's always done, you can now say, "Mark
[01:28:36.020 --> 01:28:38.220]   is read."
[01:28:38.220 --> 01:28:40.100]   I don't think it's Mark is read.
[01:28:40.100 --> 01:28:41.620]   I think it's Mark is read.
[01:28:41.620 --> 01:28:43.740]   Oh, maybe it is Mark is read.
[01:28:43.740 --> 01:28:46.980]   The reading list folder is partitioned by read and unread.
[01:28:46.980 --> 01:28:50.020]   OK, OK, so I guess Mark is read.
[01:28:50.020 --> 01:28:52.540]   Mark is read.
[01:28:52.540 --> 01:28:55.260]   And then tab search is coming to desktop.
[01:28:55.260 --> 01:28:57.220]   It's not a reading list.
[01:28:57.220 --> 01:28:58.060]   It's a read list.
[01:28:58.060 --> 01:29:03.500]   It's a read list, which I guess you don't want to go back to a site you already read.
[01:29:03.500 --> 01:29:04.500]   I don't know.
[01:29:04.500 --> 01:29:08.740]   That's more like history, I guess, of the things you've been looking up.
[01:29:08.740 --> 01:29:13.860]   And here is the tab search, which has been around in Chrome OS.
[01:29:13.860 --> 01:29:16.660]   You might be used to this already.
[01:29:16.660 --> 01:29:21.940]   Yeah, you could tap the drop down icon in the top right corner or you shift command
[01:29:21.940 --> 01:29:26.220]   A on the Mac to get a list of pages open across all windows.
[01:29:26.220 --> 01:29:29.300]   This is where people have a lot of tabs.
[01:29:29.300 --> 01:29:32.660]   You read, are you a pro tab browser user?
[01:29:32.660 --> 01:29:34.660]   You have a hundred tabs at the top.
[01:29:34.660 --> 01:29:35.660]   200.
[01:29:35.660 --> 01:29:36.660]   200.
[01:29:36.660 --> 01:29:41.220]   See, I thought, if you'd ask me, I want to predict researcher, right?
[01:29:41.220 --> 01:29:45.140]   Researcher, you open up the tabs, you open them all up, you want to keep them all open.
[01:29:45.140 --> 01:29:46.140]   That's what I thought.
[01:29:46.140 --> 01:29:47.140]   People like you.
[01:29:47.140 --> 01:29:48.500]   For some reason, I close tabs as I go.
[01:29:48.500 --> 01:29:50.340]   I don't know why.
[01:29:50.340 --> 01:29:51.740]   Anyway, there are a few.
[01:29:51.740 --> 01:29:54.180]   Those are sensible.
[01:29:54.180 --> 01:29:55.380]   I'm not a researcher.
[01:29:55.380 --> 01:29:57.620]   Maybe that's why.
[01:29:57.620 --> 01:30:01.180]   Google is no longer selling cardboard.
[01:30:01.180 --> 01:30:02.180]   Remember Jeff?
[01:30:02.180 --> 01:30:03.780]   We all came back from Google I/O.
[01:30:03.780 --> 01:30:04.780]   We were so thrilled.
[01:30:04.780 --> 01:30:06.180]   It was so exciting.
[01:30:06.180 --> 01:30:11.620]   We got these boxes that you folded up and it made little VR goggles.
[01:30:11.620 --> 01:30:13.860]   You put your phone in it.
[01:30:13.860 --> 01:30:16.060]   Then they gave it away at Google I/O.
[01:30:16.060 --> 01:30:17.900]   Gosh, that must have been five years ago, right?
[01:30:17.900 --> 01:30:18.900]   A long time ago.
[01:30:18.900 --> 01:30:19.900]   A long time ago.
[01:30:19.900 --> 01:30:20.900]   It was like it.
[01:30:20.900 --> 01:30:21.900]   Yeah.
[01:30:21.900 --> 01:30:24.460]   The car, the way back, Gina Trapani was making hers.
[01:30:24.460 --> 01:30:25.660]   She actually succeeded.
[01:30:25.660 --> 01:30:29.100]   She distracted you as they went over the Golden Gate Bridge by doing her cardboard.
[01:30:29.100 --> 01:30:30.100]   That's right.
[01:30:30.100 --> 01:30:31.100]   That's exactly right.
[01:30:31.100 --> 01:30:32.100]   Yes.
[01:30:32.100 --> 01:30:34.100]   I think they're exciting and sick.
[01:30:34.100 --> 01:30:35.100]   Yeah.
[01:30:35.100 --> 01:30:36.660]   Then they say there's no new.
[01:30:36.660 --> 01:30:39.540]   So, well, the story is it's gone.
[01:30:39.540 --> 01:30:41.700]   It wasn't exciting enough.
[01:30:41.700 --> 01:30:43.780]   Google doesn't kill things now.
[01:30:43.780 --> 01:30:45.020]   I got to sell them anymore.
[01:30:45.020 --> 01:30:46.420]   It was seven years ago.
[01:30:46.420 --> 01:30:48.780]   It was 2014 when they launched that.
[01:30:48.780 --> 01:30:49.780]   Wow.
[01:30:49.780 --> 01:30:53.180]   But, you know, they've been slowly killing.
[01:30:53.180 --> 01:30:55.580]   They killed the VR, the daydream things.
[01:30:55.580 --> 01:30:56.580]   Daydream, too.
[01:30:56.580 --> 01:30:57.580]   Yeah.
[01:30:57.580 --> 01:31:00.100]   I admit I loved daydream.
[01:31:00.100 --> 01:31:06.140]   Not necessarily for the VR experience, but I would always go and sit in my little armchair
[01:31:06.140 --> 01:31:11.660]   over here in my office and just fire up Netflix or fire Hulu, put on my headphones.
[01:31:11.660 --> 01:31:14.660]   And it is just immersive and take me away.
[01:31:14.660 --> 01:31:18.700]   It knows a nice way to watch movies just by myself.
[01:31:18.700 --> 01:31:23.220]   I had to make sure Kylo wasn't chewing up anything or the hard heads were tearing up
[01:31:23.220 --> 01:31:24.980]   something, but it was great.
[01:31:24.980 --> 01:31:26.740]   I loved it.
[01:31:26.740 --> 01:31:33.340]   Google has created a new audio codec, a new high quality, but low bit rate audio codec
[01:31:33.340 --> 01:31:37.020]   called Lyra or Lyra.
[01:31:37.020 --> 01:31:40.220]   You'll see it on Duo, but other apps soon.
[01:31:40.220 --> 01:31:46.380]   It offers natural-setting voice chat with as little as 3K per second of network bandwidth.
[01:31:46.380 --> 01:31:51.180]   Would you like to hear a little Lyra or Lyra here?
[01:31:51.180 --> 01:31:52.180]   Let's play it.
[01:31:52.180 --> 01:31:54.260]   Well, let's just mute.
[01:31:54.260 --> 01:31:58.900]   Google Duo on Android is using a new audio technology so that people have high quality
[01:31:58.900 --> 01:32:03.180]   and reliable audio during their video calls on any network.
[01:32:03.180 --> 01:32:05.220]   This audio technology is called Lyra.
[01:32:05.220 --> 01:32:06.220]   Lyra.
[01:32:06.220 --> 01:32:10.020]   It develops specifically for one year on a low scan with a black screen.
[01:32:10.020 --> 01:32:13.620]   So it doesn't sound great, but it's usable.
[01:32:13.620 --> 01:32:18.460]   And 3K is a low bandwidth.
[01:32:18.460 --> 01:32:25.900]   I'm trying to remember the analog phone network is a 4-bit network.
[01:32:25.900 --> 01:32:30.620]   It develops specifically for one year on a low bandwidth connection, like changing.
[01:32:30.620 --> 01:32:31.620]   Life change.
[01:32:31.620 --> 01:32:35.980]   And what you just saw in Herden Action was it compressing the sound of my voice in real
[01:32:35.980 --> 01:32:41.780]   time to the point that it can run at 3Kbps and still sound like me.
[01:32:41.780 --> 01:32:47.500]   This means it could even work on an old dial-up modem operating over a landline.
[01:32:47.500 --> 01:32:48.500]   Last year.
[01:32:48.500 --> 01:32:51.060]   So, let's bring that back.
[01:32:51.060 --> 01:32:53.380]   He goes on and on.
[01:32:53.380 --> 01:32:58.940]   And if you have a Nest Hub, which I do, this made it to the change log.
[01:32:58.940 --> 01:33:00.340]   Look, we don't judge.
[01:33:00.340 --> 01:33:01.580]   If it's a change we put in there.
[01:33:01.580 --> 01:33:06.860]   There are three new clock faces on your Nest Hub.
[01:33:06.860 --> 01:33:08.940]   Three, count them three.
[01:33:08.940 --> 01:33:14.940]   And finally one that shows the time and weather together.
[01:33:14.940 --> 01:33:20.700]   There's timeless light, timeless dark and weather.
[01:33:20.700 --> 01:33:25.660]   And that's the Google change log.
[01:33:25.660 --> 01:33:27.660]   Leo.
[01:33:27.660 --> 01:33:28.900]   Yes?
[01:33:28.900 --> 01:33:35.300]   I have found the video of the rud.
[01:33:35.300 --> 01:33:36.900]   We have video of the rud.
[01:33:36.900 --> 01:33:37.900]   The rud.
[01:33:37.900 --> 01:33:38.900]   What's the rud?
[01:33:38.900 --> 01:33:40.500]   The rapid unplanned disassembly.
[01:33:40.500 --> 01:33:43.300]   The rapid unplanned disassembly of the rocket.
[01:33:43.300 --> 01:33:46.300]   Here it comes.
[01:33:46.300 --> 01:33:47.300]   This is the rud.
[01:33:47.300 --> 01:33:49.700]   It's like a sort of suspension.
[01:33:49.700 --> 01:33:52.780]   So if it was a slightly little faster.
[01:33:52.780 --> 01:33:54.980]   Whoa, whoa, whoa, whoa.
[01:33:54.980 --> 01:33:55.980]   Oh my god.
[01:33:55.980 --> 01:33:56.980]   There you go.
[01:33:56.980 --> 01:33:58.780]   There's your methane leak.
[01:33:58.780 --> 01:34:00.780]   There's your methane leak right there.
[01:34:00.780 --> 01:34:03.020]   That reminds me of Dad in the good old days.
[01:34:03.020 --> 01:34:05.020]   Oh, wow.
[01:34:05.020 --> 01:34:06.020]   Dad had methane leaks.
[01:34:06.020 --> 01:34:08.020]   It's like that.
[01:34:08.020 --> 01:34:12.780]   So there's your rud.
[01:34:12.780 --> 01:34:13.780]   I like that.
[01:34:13.780 --> 01:34:14.780]   Did you make that up, John?
[01:34:14.780 --> 01:34:15.780]   That's good.
[01:34:15.780 --> 01:34:16.780]   Yeah.
[01:34:16.780 --> 01:34:18.100]   Is that a technical term that he used?
[01:34:18.100 --> 01:34:19.580]   The SpaceX technical term.
[01:34:19.580 --> 01:34:21.060]   The rud.
[01:34:21.060 --> 01:34:28.180]   Did we talk about, I don't think we did, the Abe Lincoln deep fake from my heritage?
[01:34:28.180 --> 01:34:30.580]   We did it on Sunday.
[01:34:30.580 --> 01:34:31.580]   That was on Sunday.
[01:34:31.580 --> 01:34:32.580]   Yeah.
[01:34:32.580 --> 01:34:34.660]   Was it a deep fake or was it a deep fake?
[01:34:34.660 --> 01:34:36.100]   Well, you be the judge.
[01:34:36.100 --> 01:34:41.580]   Would you like to see old Abe as you've never seen him before?
[01:34:41.580 --> 01:34:43.980]   I've seen everything using this.
[01:34:43.980 --> 01:34:48.060]   I'm glad you're bringing this up because I'm curious to know if Mr. Jarvis would submit
[01:34:48.060 --> 01:34:51.300]   one of his photos from his family.
[01:34:51.300 --> 01:34:57.780]   For score and seven years ago, our ancestors dreamed that we would build our family tree
[01:34:57.780 --> 01:34:58.780]   and make fascinating.
[01:34:58.780 --> 01:35:02.780]   Abe Lincoln, do an ad for my heritage.
[01:35:02.780 --> 01:35:06.340]   I mean, it's my heritage.
[01:35:06.340 --> 01:35:12.180]   But what's cool about this, and I'm going to close the ad now, is I'm going to find some
[01:35:12.180 --> 01:35:18.220]   others because you can use these on your own ancestors.
[01:35:18.220 --> 01:35:25.500]   And if you have pictures, let me find this because the Abe Lincoln...
[01:35:25.500 --> 01:35:28.100]   She's using Gutenberg.
[01:35:28.100 --> 01:35:29.100]   Yeah, Gutenberg.
[01:35:29.100 --> 01:35:31.620]   We can reanimate Gutenberg.
[01:35:31.620 --> 01:35:32.620]   They call it deep.
[01:35:32.620 --> 01:35:34.060]   I have mine right here.
[01:35:34.060 --> 01:35:35.900]   You ready for this?
[01:35:35.900 --> 01:35:36.900]   Yeah.
[01:35:36.900 --> 01:35:38.900]   It looks like.
[01:35:38.900 --> 01:35:41.540]   So I'll give you an example.
[01:35:41.540 --> 01:35:42.540]   There you go.
[01:35:42.540 --> 01:35:43.540]   That's exactly it.
[01:35:43.540 --> 01:35:45.380]   You've seen them, I see.
[01:35:45.380 --> 01:35:48.060]   This is a picture of grandpa and grandma.
[01:35:48.060 --> 01:35:49.820]   You probably have a picture like that.
[01:35:49.820 --> 01:35:50.820]   But imagine...
[01:35:50.820 --> 01:35:54.340]   Oh, that's creepy.
[01:35:54.340 --> 01:35:58.300]   I've been told by people who've done this to their own ancestors that it's fine for
[01:35:58.300 --> 01:36:04.740]   other people's ancestors, but you really don't want to do this to anybody you know.
[01:36:04.740 --> 01:36:06.140]   You're new, yeah.
[01:36:06.140 --> 01:36:09.140]   Imagine that.
[01:36:09.140 --> 01:36:20.060]   So, what they do, I guess, is take a real face, take the picture, and then apply the orientation
[01:36:20.060 --> 01:36:23.900]   in the head direction of the eyes to this selected face.
[01:36:23.900 --> 01:36:27.580]   And so it is a little bit of a hybrid of a deep...
[01:36:27.580 --> 01:36:32.940]   The best I saw, you know, that old lady who restored the painting horribly?
[01:36:32.940 --> 01:36:33.940]   Yes.
[01:36:33.940 --> 01:36:37.820]   It looks like the potato head that she did of...
[01:36:37.820 --> 01:36:38.820]   Yeah.
[01:36:38.820 --> 01:36:42.340]   It's a little creepy, but it worked.
[01:36:42.340 --> 01:36:48.380]   My hair just got sold.
[01:36:48.380 --> 01:36:54.300]   Francisco Partners is acquiring MyHeritage for $600 million.
[01:36:54.300 --> 01:36:56.300]   Take that for your NFT.
[01:36:56.300 --> 01:37:00.020]   What is there, MyHeritage, actually do?
[01:37:00.020 --> 01:37:01.020]   They're a genealogy.
[01:37:01.020 --> 01:37:02.860]   They're like ancestry.com.
[01:37:02.860 --> 01:37:03.860]   They're a genealogy.
[01:37:03.860 --> 01:37:08.460]   Oh, so this was just a PR trick on top of it.
[01:37:08.460 --> 01:37:09.460]   Yeah, it worked.
[01:37:09.460 --> 01:37:10.460]   They're from Israel, I should mention.
[01:37:10.460 --> 01:37:11.460]   It's not their heritage.
[01:37:11.460 --> 01:37:13.380]   They're a profitable company.
[01:37:13.380 --> 01:37:14.380]   They're a company.
[01:37:14.380 --> 01:37:17.980]   Let's people test their DNA and then track their family lineage.
[01:37:17.980 --> 01:37:18.980]   Actually...
[01:37:18.980 --> 01:37:19.980]   Oh, okay.
[01:37:19.980 --> 01:37:20.980]   So it's just like ancestry.com.
[01:37:20.980 --> 01:37:24.220]   They're actually 62 million users.
[01:37:24.220 --> 01:37:27.500]   This is the second big sale of a DNA company, though.
[01:37:27.500 --> 01:37:36.980]   Of course, 23andMe did a SPAC merger with Richard Branson's Virgin Group.
[01:37:36.980 --> 01:37:41.900]   So I think this is also a little clarion call that the companies are starting to buy up
[01:37:41.900 --> 01:37:43.300]   your DNA.
[01:37:43.300 --> 01:37:46.220]   Just a little word of note.
[01:37:46.220 --> 01:37:49.260]   Did you see the 17th century letters?
[01:37:49.260 --> 01:37:50.260]   There were...
[01:37:50.260 --> 01:37:51.260]   I was glad you brought this up.
[01:37:51.260 --> 01:37:56.180]   I watched an entire hour-long presentation today from the scientists who did this.
[01:37:56.180 --> 01:37:57.180]   So these are letters.
[01:37:57.180 --> 01:38:00.940]   There's a stock of 3,000 of them that didn't get delivered.
[01:38:00.940 --> 01:38:05.500]   And you could not really buy envelopes pre-made until the 1830s.
[01:38:05.500 --> 01:38:10.300]   So people do is they folded the letters up in an origami way and then tucked it in or
[01:38:10.300 --> 01:38:12.420]   sealed it with wax.
[01:38:12.420 --> 01:38:13.420]   And so they have these letters.
[01:38:13.420 --> 01:38:15.980]   And if they opened it up, they ruined it.
[01:38:15.980 --> 01:38:18.060]   So they used phenomenal.
[01:38:18.060 --> 01:38:21.100]   They had scientists around the world working on this project.
[01:38:21.100 --> 01:38:25.900]   They had an origami expert from MIT who supervised the algorithmic...
[01:38:25.900 --> 01:38:26.900]   I didn't know that.
[01:38:26.900 --> 01:38:28.140]   ...to do scientists to work with him.
[01:38:28.140 --> 01:38:29.140]   Oh, it's fascinating.
[01:38:29.140 --> 01:38:30.140]   That's so cool.
[01:38:30.140 --> 01:38:34.300]   They had three people who understand early handwriting.
[01:38:34.300 --> 01:38:35.300]   They had two...
[01:38:35.300 --> 01:38:40.380]   It was a special scanner that had normally done for dental work.
[01:38:40.380 --> 01:38:45.540]   And so they managed to take this little thing and scan every layer of it, understand what
[01:38:45.540 --> 01:38:49.420]   the order was of the terms because it could all be different.
[01:38:49.420 --> 01:38:52.900]   In other words, they're trying to read the text without opening it.
[01:38:52.900 --> 01:38:53.900]   As you say, opening it.
[01:38:53.900 --> 01:38:54.900]   Exactly.
[01:38:54.900 --> 01:38:55.900]   And they read the text.
[01:38:55.900 --> 01:38:56.900]   Wow.
[01:38:56.900 --> 01:39:03.620]   So I was mesmerized today watching these scientists and humanists talk about this.
[01:39:03.620 --> 01:39:04.620]   Academics.
[01:39:04.620 --> 01:39:05.620]   Just like Neurith are the greatest people.
[01:39:05.620 --> 01:39:10.260]   They actually do real work of research, unlike us who blather.
[01:39:10.260 --> 01:39:12.180]   So they did all this so you can unfold this.
[01:39:12.180 --> 01:39:16.940]   Now then, as I say, there's about 3,000 of them because there were two places that had
[01:39:16.940 --> 01:39:21.100]   the same name, one at the Hague and one in France and things got misdelivered.
[01:39:21.100 --> 01:39:24.900]   And so they just sat there for years, years, years, years, years, a whole bucket of them.
[01:39:24.900 --> 01:39:30.060]   Then there's other stuff like when ships would get captured by the British Navy, they would
[01:39:30.060 --> 01:39:32.700]   have the bag of mail from the captured ships.
[01:39:32.700 --> 01:39:37.900]   Some of those are still untouched, not even taken out of the bags in all these years.
[01:39:37.900 --> 01:39:45.300]   So now this allows research to go into all these artifacts and without ruining them,
[01:39:45.300 --> 01:39:49.180]   understand every layer, understand the order and read the text on them in the ink.
[01:39:49.180 --> 01:39:51.020]   It's just amazing.
[01:39:51.020 --> 01:39:52.260]   I was a golfer.
[01:39:52.260 --> 01:39:56.220]   It's called X-ray micro-tomography.
[01:39:56.220 --> 01:39:57.220]   That's what they used.
[01:39:57.220 --> 01:40:02.220]   It was a paper in nature that has the details and the images and it's phenomenal.
[01:40:02.220 --> 01:40:04.260]   Here's another phenomenal story.
[01:40:04.260 --> 01:40:10.980]   If you listen to somebody playing the piano, I think probably if you're a piano player,
[01:40:10.980 --> 01:40:12.580]   you can imagine their hands in the notes.
[01:40:12.580 --> 01:40:20.540]   But this is an AI that extracted the notes from raw audio and generated a video of the
[01:40:20.540 --> 01:40:23.340]   hand and the body playing the notes.
[01:40:23.340 --> 01:40:31.820]   On the left, the actual player, on the right, a 3D animation based on the sound.
[01:40:31.820 --> 01:40:35.700]   It's pretty darn close.
[01:40:35.700 --> 01:40:36.700]   From massive presses.
[01:40:36.700 --> 01:40:38.220]   I don't know how to play the piano.
[01:40:38.220 --> 01:40:41.140]   Yeah, well, from now on, Tom Hanks can do that.
[01:40:41.140 --> 01:40:42.140]   Wait a minute.
[01:40:42.140 --> 01:40:43.140]   What?
[01:40:43.140 --> 01:40:47.500]   This is a Tom and Jerry cat concerto.
[01:40:47.500 --> 01:40:49.460]   You can do that too.
[01:40:49.460 --> 01:40:51.220]   Massive technology.
[01:40:51.220 --> 01:40:56.220]   C-A-I don't remember that one.
[01:40:56.220 --> 01:40:57.620]   Here's from a soul.
[01:40:57.620 --> 01:41:01.660]   If you watched soul the other night, I know a lot of you did.
[01:41:01.660 --> 01:41:05.140]   The pick started at the old fashioned way.
[01:41:05.140 --> 01:41:07.740]   It's some guy with rubber fingers.
[01:41:07.740 --> 01:41:10.500]   I don't know how to do it.
[01:41:10.500 --> 01:41:12.700]   Anyway, there you go.
[01:41:12.700 --> 01:41:16.140]   AI at work.
[01:41:16.140 --> 01:41:19.020]   It's impressive.
[01:41:19.020 --> 01:41:20.020]   Yeah.
[01:41:20.020 --> 01:41:21.020]   Pretty cool.
[01:41:21.020 --> 01:41:23.020]   That is, it is actually.
[01:41:23.020 --> 01:41:24.620]   Any stories I missed?
[01:41:24.620 --> 01:41:27.500]   There's quite a few.
[01:41:27.500 --> 01:41:31.260]   Oh, I thought you would be interested because you live near New York.
[01:41:31.260 --> 01:41:33.500]   You work in New York.
[01:41:33.500 --> 01:41:37.020]   This is from a DNAinfo.com.
[01:41:37.020 --> 01:41:45.380]   Nicole Levy, who is the writer, but is writing about the research of a guy named Gabor Zell,
[01:41:45.380 --> 01:41:50.220]   who is, no, I'm sorry, Craig Neville Manning.
[01:41:50.220 --> 01:41:51.220]   I'm sorry.
[01:41:51.220 --> 01:41:52.220]   I apologize.
[01:41:52.220 --> 01:41:53.220]   I give credit where credits do.
[01:41:53.220 --> 01:41:55.140]   Gabor Zell tweeted it.
[01:41:55.140 --> 01:42:02.700]   There's Greg Neville Manning, as the chief technology officer at Google's Sidewalk Labs.
[01:42:02.700 --> 01:42:09.340]   He takes the four or five train normally in New York City, but he took the sixth train
[01:42:09.340 --> 01:42:14.740]   and he noticed something very interesting about the streets on the stops.
[01:42:14.740 --> 01:42:21.220]   They mirrored the conversion from Fahrenheit to Celsius.
[01:42:21.220 --> 01:42:27.620]   If you know that minus 10 degrees Celsius is 14 degrees Fahrenheit, then follow the New
[01:42:27.620 --> 01:42:31.140]   York City sixth train uptown.
[01:42:31.140 --> 01:42:36.740]   The 23rd street is minus five degrees, 32nd street zero.
[01:42:36.740 --> 01:42:39.420]   The third street, 32nd, close enough, right?
[01:42:39.420 --> 01:42:40.420]   Okay.
[01:42:40.420 --> 01:42:41.420]   Okay.
[01:42:41.420 --> 01:42:42.420]   Oh, you actually know the streets.
[01:42:42.420 --> 01:42:43.420]   41st, 42nd.
[01:42:43.420 --> 01:42:44.420]   Yeah, you do.
[01:42:44.420 --> 01:42:45.420]   Grand Central Station, right?
[01:42:45.420 --> 01:42:46.420]   51st Street.
[01:42:46.420 --> 01:42:47.420]   Well, it's close.
[01:42:47.420 --> 01:42:48.420]   It's 50th, 50, 10 degrees.
[01:42:48.420 --> 01:42:51.420]   50th Street's accurate.
[01:42:51.420 --> 01:42:52.460]   Yeah, 68th Street.
[01:42:52.460 --> 01:42:53.460]   That's where 100 college is.
[01:42:53.460 --> 01:42:54.460]   Hunter College.
[01:42:54.460 --> 01:43:02.100]   That's 20 degrees, 77th Street, 25 degrees centigrade Celsius, and the 86th Street where
[01:43:02.100 --> 01:43:07.620]   you can, by the way, change to the four or five train is 30 degrees Celsius.
[01:43:07.620 --> 01:43:10.940]   I don't know if there's any meaning to that at all.
[01:43:10.940 --> 01:43:18.380]   I don't think we're assuming that the New York subway planners knew that.
[01:43:18.380 --> 01:43:19.380]   Okay.
[01:43:19.380 --> 01:43:22.140]   So I got one more question for Nirid, if I may?
[01:43:22.140 --> 01:43:23.140]   Yes.
[01:43:23.140 --> 01:43:29.060]   I'm eager to hear her thoughts about Facebook and Australia and who came out better than
[01:43:29.060 --> 01:43:30.060]   that.
[01:43:30.060 --> 01:43:35.100]   Yeah, there's some evidence that in fact, for the few days that Facebook was not referring
[01:43:35.100 --> 01:43:42.220]   people to Australian news products, there was a 24% drop in traffic to those Australian
[01:43:42.220 --> 01:43:43.900]   news sites.
[01:43:43.900 --> 01:43:44.900]   Wow.
[01:43:44.900 --> 01:43:45.900]   Imagine that.
[01:43:45.900 --> 01:43:50.820]   Yeah, that was a classical case of them, did they do them, did they don't?
[01:43:50.820 --> 01:43:54.980]   Which I know, we just sent them so.
[01:43:54.980 --> 01:43:58.940]   Because we saw the different reaction, Google versus Facebook, which again, it's because
[01:43:58.940 --> 01:44:04.180]   they have different business model and relationship with publishers.
[01:44:04.180 --> 01:44:07.740]   The way it covered was of course, everything Facebook do is wrong.
[01:44:07.740 --> 01:44:12.660]   So no matter what they want you to do, that was the framing.
[01:44:12.660 --> 01:44:19.540]   What I think that is interesting here is that when I spoke with tech journalists about
[01:44:19.540 --> 01:44:26.700]   their dependence on the tech platform, they said, "Well, it's not like, if you're looking
[01:44:26.700 --> 01:44:31.740]   for it being the reason why we're tough on them because we're blaming them and we are
[01:44:31.740 --> 01:44:32.740]   dependent on them."
[01:44:32.740 --> 01:44:34.460]   No, that's not the case.
[01:44:34.460 --> 01:44:38.980]   We're actually in some ways grateful because they give us a lot of traffic.
[01:44:38.980 --> 01:44:45.020]   So Google actually pays our salaries and half of our traffic comes from Google.
[01:44:45.020 --> 01:44:48.820]   So it's not like that we're mad at Google because of that.
[01:44:48.820 --> 01:44:53.380]   So when they were honest, they were actually saying, "No, the relationship is really beneficial
[01:44:53.380 --> 01:44:57.380]   for us."
[01:44:57.380 --> 01:45:00.580]   Superimmertox, not so honest, obviously.
[01:45:00.580 --> 01:45:03.740]   He doesn't want to hear that.
[01:45:03.740 --> 01:45:08.020]   Well when they're attacking the tech platforms, they're also attacking their competition.
[01:45:08.020 --> 01:45:11.020]   That's right.
[01:45:11.020 --> 01:45:14.100]   Wall Street Journal doesn't like Google.
[01:45:14.100 --> 01:45:15.740]   Murdoch doesn't like Facebook.
[01:45:15.740 --> 01:45:16.740]   Yeah.
[01:45:16.740 --> 01:45:20.100]   That's taking money out of their mouth.
[01:45:20.100 --> 01:45:21.100]   Not anymore though.
[01:45:21.100 --> 01:45:24.420]   I think you're going to have to think dude, if they don't, analysis is right.
[01:45:24.420 --> 01:45:26.740]   It's pretty accurate.
[01:45:26.740 --> 01:45:29.780]   Last break, then we'll wrap things up.
[01:45:29.780 --> 01:45:36.780]   It's been great to have our guest, Dr. Niri Weisblatt, Dr. Techlash on the Twitter.
[01:45:36.780 --> 01:45:42.260]   She has just written a book called the Techlash and Tech Crisis Communication from Emerald
[01:45:42.260 --> 01:45:43.260]   Publishing.
[01:45:43.260 --> 01:45:44.260]   You can pre-order on Amazon.
[01:45:44.260 --> 01:45:46.860]   That'll be released March 24th.
[01:45:46.860 --> 01:45:49.820]   It's been really nice to have you stick around.
[01:45:49.820 --> 01:45:53.540]   If you want to give us a pick of the week, that's what we do next and you're more than
[01:45:53.540 --> 01:45:54.540]   welcome.
[01:45:54.540 --> 01:45:56.420]   Just something you're interested in.
[01:45:56.420 --> 01:45:58.380]   I know we don't want to jump you.
[01:45:58.380 --> 01:46:00.940]   Oh yeah, you picked your book.
[01:46:00.940 --> 01:46:01.940]   Good.
[01:46:01.940 --> 01:46:02.940]   Good thinking.
[01:46:02.940 --> 01:46:07.940]   That's marketing.
[01:46:07.940 --> 01:46:09.020]   We'll talk about that.
[01:46:09.020 --> 01:46:10.020]   Of course.
[01:46:10.020 --> 01:46:11.020]   What was I thinking?
[01:46:11.020 --> 01:46:12.940]   What should I pick this week?
[01:46:12.940 --> 01:46:14.420]   I showed it.
[01:46:14.420 --> 01:46:17.300]   I brought to you by literally quite literally by CashFly.
[01:46:17.300 --> 01:46:20.220]   It's our content delivery network, our CDN.
[01:46:20.220 --> 01:46:23.900]   CashFly has been innovating content delivery since 1999.
[01:46:23.900 --> 01:46:30.020]   We've been using them since the year 2010, maybe even a little bit earlier.
[01:46:30.020 --> 01:46:33.020]   CashFly now is something new that I think is going to be really interesting for those
[01:46:33.020 --> 01:46:36.060]   of you who stream live video.
[01:46:36.060 --> 01:46:37.980]   Ultra low latency streaming.
[01:46:37.980 --> 01:46:41.740]   I'm not talking the WebRTC solution.
[01:46:41.740 --> 01:46:43.300]   You might have used in the past.
[01:46:43.300 --> 01:46:44.780]   No, no.
[01:46:44.780 --> 01:46:48.540]   This is latency of less than one second.
[01:46:48.540 --> 01:46:50.980]   One second.
[01:46:50.980 --> 01:46:52.740]   There are a lot more perks as well.
[01:46:52.740 --> 01:46:53.740]   You can play it anywhere.
[01:46:53.740 --> 01:46:58.900]   Their HTML5 player offers easy support anywhere you are with an SDK available for even better
[01:46:58.900 --> 01:47:00.500]   mobile support.
[01:47:00.500 --> 01:47:04.860]   Whether you need your player to run on websites, applications, mobile devices, whatever platform
[01:47:04.860 --> 01:47:06.260]   they've got you covered.
[01:47:06.260 --> 01:47:11.140]   Of course, because CashFly is all over the world, 50 points of presence all over the
[01:47:11.140 --> 01:47:17.940]   world of the fastest CDN for throughput globally, you get global delivery on their low latency
[01:47:17.940 --> 01:47:18.940]   network.
[01:47:18.940 --> 01:47:21.500]   Streams will be streaming quickly anywhere you have viewers.
[01:47:21.500 --> 01:47:24.020]   It doesn't matter what content they're on.
[01:47:24.020 --> 01:47:26.940]   Scales, basically infinitely.
[01:47:26.940 --> 01:47:32.620]   Their Ultra low latency platform can deliver video to more than a million users concurrently.
[01:47:32.620 --> 01:47:36.100]   And in just thousands of synchronous streams.
[01:47:36.100 --> 01:47:37.940]   That ingest is very reliable.
[01:47:37.940 --> 01:47:40.980]   It's designed for transmuxing thousands of streams simultaneously.
[01:47:40.980 --> 01:47:47.660]   With live failover, they can ingest RTMP, RTMPS, SRT and more to deliver ultra low latency
[01:47:47.660 --> 01:47:50.380]   SLDP and HLS streams.
[01:47:50.380 --> 01:47:52.460]   And they can even do that simultaneously.
[01:47:52.460 --> 01:47:56.860]   Get a solution that's tailored to you from CashFly.
[01:47:56.860 --> 01:48:01.580]   All builds on top of their reliable, robust, global network with ingest where you need
[01:48:01.580 --> 01:48:04.100]   it and delivery where you need it.
[01:48:04.100 --> 01:48:10.300]   And 24/7, 365 day, your priority support, they're always there when you need them.
[01:48:10.300 --> 01:48:11.300]   Imagine.
[01:48:11.300 --> 01:48:19.260]   Less than a second latency, a million concurrent streams with 100% SLA CashFly is up to five
[01:48:19.260 --> 01:48:22.980]   times faster than other CDNs.
[01:48:22.980 --> 01:48:27.420]   They pioneered the first any cast CDN infrastructure way back in 2002.
[01:48:27.420 --> 01:48:32.380]   Their best top technology automatically finds the fastest route to and from customer origin
[01:48:32.380 --> 01:48:36.140]   across their global network of pops for maximum performance and reliability.
[01:48:36.140 --> 01:48:37.140]   We don't care about any of that.
[01:48:37.140 --> 01:48:41.940]   We just know CashFly works and it's worked so well for us for more than a decade.
[01:48:41.940 --> 01:48:42.940]   They're also great people.
[01:48:42.940 --> 01:48:45.660]   They're helping during this COVID crisis.
[01:48:45.660 --> 01:48:51.020]   They're supporting the world central kitchen already donated more than $50,000.
[01:48:51.020 --> 01:48:52.940]   I always like to mention that because I'm proud.
[01:48:52.940 --> 01:48:59.160]   Right now, if you want, you can get a complimentary detail analysis of your usage trends and current
[01:48:59.160 --> 01:49:04.460]   CDN bill if you go to twit.cashfly.com.
[01:49:04.460 --> 01:49:08.220]   See if you're overpaying as much as 20% or more for CDN.
[01:49:08.220 --> 01:49:15.780]   Find out more about this brand new ultra low latency streaming platform at twit.cashfly.com.
[01:49:15.780 --> 01:49:17.220]   Thank you and I mean it.
[01:49:17.220 --> 01:49:22.460]   Thank you, CashFly, for supporting this week in Google.
[01:49:22.460 --> 01:49:28.620]   I'll give you another plug techlashbook.com.
[01:49:28.620 --> 01:49:29.620]   That's the website.
[01:49:29.620 --> 01:49:32.980]   You also have a blog people can read and a lot more.
[01:49:32.980 --> 01:49:34.300]   It's really been a pleasure having you.
[01:49:34.300 --> 01:49:36.380]   Thank you for joining us.
[01:49:36.380 --> 01:49:37.380]   My pleasure.
[01:49:37.380 --> 01:49:38.980]   Dr. Nerit, why splat?
[01:49:38.980 --> 01:49:39.980]   Or is it vice?
[01:49:39.980 --> 01:49:40.980]   You like vice-plat?
[01:49:40.980 --> 01:49:44.540]   Well, in Hebrew it's vice, but in here.
[01:49:44.540 --> 01:49:45.540]   Vice.
[01:49:45.540 --> 01:49:46.860]   Yeah, my Hebrew is not so good.
[01:49:46.860 --> 01:49:47.860]   So good.
[01:49:47.860 --> 01:49:48.860]   America's the best at everything.
[01:49:48.860 --> 01:49:51.140]   Yeah, we mess it all up.
[01:49:51.140 --> 01:49:53.140]   That's why we can't have nice things.
[01:49:53.140 --> 01:49:55.140]   You can't have nice things, no.
[01:49:55.140 --> 01:50:00.940]   One Jeff Jarvis says, "In this deeply researched work, Nerit Vice Blots provides an invaluable
[01:50:00.940 --> 01:50:06.380]   record of tech media's mood swing as its portrayal of Silicon Valley lurched from utopian
[01:50:06.380 --> 01:50:07.380]   to dystopian."
[01:50:07.380 --> 01:50:09.820]   You're thinking about me when you wrote that, aren't you?
[01:50:09.820 --> 01:50:12.900]   This is much more than a book about tech's PR problems.
[01:50:12.900 --> 01:50:17.020]   Vice Blots' trenchant analysis of the news industry restores nuance to the debate over
[01:50:17.020 --> 01:50:18.300]   technology and society.
[01:50:18.300 --> 01:50:20.460]   Well, now I have to read it.
[01:50:20.460 --> 01:50:21.460]   You do.
[01:50:21.460 --> 01:50:22.460]   Yes.
[01:50:22.460 --> 01:50:23.460]   You'll enjoy it.
[01:50:23.460 --> 01:50:24.460]   I guarantee you.
[01:50:24.460 --> 01:50:25.460]   Jeff, a number of the week.
[01:50:25.460 --> 01:50:26.460]   Skip over my quotes.
[01:50:26.460 --> 01:50:27.460]   Okay.
[01:50:27.460 --> 01:50:29.900]   Well, so this is actually related to our last moment here.
[01:50:29.900 --> 01:50:32.660]   Germans have coined more than 1200 words.
[01:50:32.660 --> 01:50:33.660]   I'm talking about corona.
[01:50:33.660 --> 01:50:34.660]   I saw this in fact.
[01:50:34.660 --> 01:50:36.940]   I was going to ask you about this.
[01:50:36.940 --> 01:50:38.340]   Like Munchut's mode.
[01:50:38.340 --> 01:50:40.500]   That's one of my favorites.
[01:50:40.500 --> 01:50:43.620]   So Munchut's mode is mouth protection fashion.
[01:50:43.620 --> 01:50:44.620]   Munchut's.
[01:50:44.620 --> 01:50:45.620]   Munchut's.
[01:50:45.620 --> 01:50:46.620]   Munchut's.
[01:50:46.620 --> 01:50:47.620]   Munchut's protection.
[01:50:47.620 --> 01:50:48.620]   Munchut is fashion.
[01:50:48.620 --> 01:50:49.620]   Or.
[01:50:49.620 --> 01:50:50.620]   What does this exist?
[01:50:50.620 --> 01:50:51.620]   It's exist.
[01:50:51.620 --> 01:50:52.620]   Condom.
[01:50:52.620 --> 01:50:54.620]   What does that mean?
[01:50:54.620 --> 01:50:55.620]   A face condom.
[01:50:55.620 --> 01:50:57.460]   It's a mask.
[01:50:57.460 --> 01:50:58.460]   A mask.
[01:50:58.460 --> 01:51:01.100]   But they have actually a lot of words for masks.
[01:51:01.100 --> 01:51:02.100]   I like a.
[01:51:02.100 --> 01:51:03.100]   A shooting.
[01:51:03.100 --> 01:51:04.100]   Holy.
[01:51:04.100 --> 01:51:06.540]   Which is a snout sweater.
[01:51:06.540 --> 01:51:07.540]   A pullover.
[01:51:07.540 --> 01:51:09.860]   Ah, you value a shooting bully.
[01:51:09.860 --> 01:51:11.100]   A shooting bully.
[01:51:11.100 --> 01:51:13.100]   That's what we're doing.
[01:51:13.100 --> 01:51:14.100]   That's what we're doing.
[01:51:14.100 --> 01:51:15.100]   That's what we're doing.
[01:51:15.100 --> 01:51:16.100]   That's a little boring.
[01:51:16.100 --> 01:51:17.100]   Go ahead.
[01:51:17.100 --> 01:51:18.100]   Go ahead and read that.
[01:51:18.100 --> 01:51:20.220]   should be the name of the episode.
[01:51:20.220 --> 01:51:22.980]   - You win Shkun pulie.
[01:51:22.980 --> 01:51:25.600]   Spookshut's term.
[01:51:25.600 --> 01:51:27.360]   - Spookshut's shkun.
[01:51:27.360 --> 01:51:28.180]   - Shkun.
[01:51:28.180 --> 01:51:30.060]   - Shkun is a spit protection umbrella.
[01:51:30.060 --> 01:51:34.940]   We talked about this before and in Dutch,
[01:51:34.940 --> 01:51:39.940]   Hamsteron is to stockpile items to hamster items.
[01:51:39.940 --> 01:51:40.860]   - Oh, yes.
[01:51:40.860 --> 01:51:45.580]   - And then there was one more I like to hear where it wasn't.
[01:51:47.080 --> 01:51:49.340]   - Andeut hau mete gazelle shaft,
[01:51:49.340 --> 01:51:53.140]   one and a half meter society for social distancing.
[01:51:53.140 --> 01:51:57.700]   - This is because German loves these omnibus words, right?
[01:51:57.700 --> 01:52:00.740]   Where we would have string three different nouns,
[01:52:00.740 --> 01:52:03.320]   you know, together to form a sentence,
[01:52:03.320 --> 01:52:06.500]   they make it all one word, like a big choo choo train.
[01:52:06.500 --> 01:52:08.500]   They've always done that.
[01:52:08.500 --> 01:52:09.340]   I like that.
[01:52:09.340 --> 01:52:11.500]   I think that's, that makes it very--
[01:52:11.500 --> 01:52:12.620]   - Those are the four new words.
[01:52:12.620 --> 01:52:14.220]   - Yeah, 12 hundred new words.
[01:52:14.220 --> 01:52:19.220]   - The four is that a lockdown with multiple extensions
[01:52:19.220 --> 01:52:22.320]   is a salami lockdown.
[01:52:22.320 --> 01:52:23.480]   - We've got one of those.
[01:52:23.480 --> 01:52:25.200]   - It's places rather than a single stroke.
[01:52:25.200 --> 01:52:27.640]   - It's salami lockdown right now.
[01:52:27.640 --> 01:52:28.480]   - It's salami lockdown.
[01:52:28.480 --> 01:52:30.400]   - Unless you're in Texas or Mississippi,
[01:52:30.400 --> 01:52:32.480]   in which case the salami's been sliced.
[01:52:32.480 --> 01:52:37.120]   - I'm gonna put on my shkun pulley.
[01:52:37.120 --> 01:52:38.320]   - That's a good look at shkun pulley.
[01:52:38.320 --> 01:52:39.480]   - You got that.
[01:52:39.480 --> 01:52:40.320]   - But shkun pulley.
[01:52:40.320 --> 01:52:41.800]   - But shkun pulley.
[01:52:41.800 --> 01:52:44.580]   - Mr. and-- - All my gizikt kon don.
[01:52:44.580 --> 01:52:46.220]   - I like shkun pulley.
[01:52:46.220 --> 01:52:47.220]   'Cause the word shkun pulley.
[01:52:47.220 --> 01:52:48.060]   - Shkun pulley.
[01:52:48.060 --> 01:52:49.380]   - Just seems like such a good word.
[01:52:49.380 --> 01:52:50.900]   Such a good word.
[01:52:50.900 --> 01:52:52.260]   - Todum is pretty funny too.
[01:52:52.260 --> 01:52:53.940]   Face codum is pretty funny too, but you're right.
[01:52:53.940 --> 01:52:54.940]   - Shkun pulley.
[01:52:54.940 --> 01:52:56.500]   - Near it, do you ever speak Yiddish at all
[01:52:56.500 --> 01:52:57.940]   to any of your older family members?
[01:52:57.940 --> 01:52:59.100]   Does any of them speak Yiddish?
[01:52:59.100 --> 01:52:59.940]   - My grandmother.
[01:52:59.940 --> 01:53:00.780]   - Grandma.
[01:53:00.780 --> 01:53:02.620]   'Cause I bet Yiddish would have a hell
[01:53:02.620 --> 01:53:04.020]   of a good time with these words.
[01:53:04.020 --> 01:53:05.260]   - Oh, oh yeah.
[01:53:05.260 --> 01:53:06.340]   - Yeah, yeah.
[01:53:06.340 --> 01:53:08.340]   Shkun pulley almost is Yiddish.
[01:53:08.340 --> 01:53:10.780]   (laughing)
[01:53:10.780 --> 01:53:13.720]   - Hey, I'm Prue, your pick of the week.
[01:53:13.720 --> 01:53:14.920]   - How can I top that?
[01:53:14.920 --> 01:53:16.240]   - Shkun pulley.
[01:53:16.240 --> 01:53:17.080]   - Yeah.
[01:53:17.080 --> 01:53:19.600]   (laughing)
[01:53:19.600 --> 01:53:21.080]   - Love it.
[01:53:21.080 --> 01:53:23.880]   I saw Mr. Jarvis was tweeting previously
[01:53:23.880 --> 01:53:28.400]   about his anniversary during the COVID lockdown.
[01:53:28.400 --> 01:53:32.200]   And I found this story on CBS News.
[01:53:32.200 --> 01:53:36.200]   And it's another COVID lockdown anniversary celebration
[01:53:36.200 --> 01:53:39.520]   from the funny Mr. Jim Gaffigan.
[01:53:39.520 --> 01:53:40.640]   - Oh, I love Jim, you guys.
[01:53:40.640 --> 01:53:42.600]   - He's been watching him on YouTube.
[01:53:42.600 --> 01:53:46.320]   He's been quite a treat to watch this past year.
[01:53:46.320 --> 01:53:47.780]   - Can I play this, you think?
[01:53:47.780 --> 01:53:50.520]   Just, you should be able to not play.
[01:53:50.520 --> 01:53:51.720]   - I'm a little bit crucial to go through.
[01:53:51.720 --> 01:53:53.600]   - Yeah, we'll just, oh, there's a commercial first.
[01:53:53.600 --> 01:53:55.160]   - Jesus, he's just been doing a lot of stuff
[01:53:55.160 --> 01:53:57.040]   with this family and--
[01:53:57.040 --> 01:53:58.680]   - Here's Jane Paulie.
[01:53:58.680 --> 01:54:00.880]   - Not necessarily doing a standup performances
[01:54:00.880 --> 01:54:02.120]   when you think of him, but it's just been
[01:54:02.120 --> 01:54:04.920]   a nice getaway from the mess.
[01:54:04.920 --> 01:54:06.160]   - Yeah, let me play it.
[01:54:06.160 --> 01:54:11.000]   Jane Paulie, it looks like CBS This Morning introducing,
[01:54:11.000 --> 01:54:13.400]   Sunday morning, I mean, introducing Jim Gaffigan.
[01:54:13.400 --> 01:54:14.560]   - Here's Jim Gaffigan.
[01:54:14.560 --> 01:54:17.840]   - My anniversary is coming up,
[01:54:17.840 --> 01:54:21.360]   and I still haven't gotten my life anything.
[01:54:21.360 --> 01:54:23.860]   I know, I know, I'm horrible.
[01:54:23.860 --> 01:54:27.920]   But how do you celebrate a full year
[01:54:27.920 --> 01:54:29.840]   of living with the coronavirus?
[01:54:29.840 --> 01:54:30.760]   - Oh, that anniversary.
[01:54:30.760 --> 01:54:33.360]   - I guess it may have been a grueling 12 months,
[01:54:33.360 --> 01:54:36.720]   but I'd like to focus on the positives for a moment.
[01:54:36.720 --> 01:54:40.640]   Okay, enough of that.
[01:54:40.640 --> 01:54:41.480]   (laughing)
[01:54:41.480 --> 01:54:43.280]   - No, no, no, no, no, no, no, no, no, no, no, no, no,
[01:54:43.280 --> 01:54:45.160]   Jim Gaffigan, you can watch the rest
[01:54:45.160 --> 01:54:47.240]   at the CBS News.com.
[01:54:47.240 --> 01:54:50.800]   I really like Jim Gaffigan, he's every man, I guess.
[01:54:50.800 --> 01:54:52.160]   That's probably my--
[01:54:52.160 --> 01:54:53.520]   - I love Jim Gaffigan.
[01:54:53.520 --> 01:54:55.760]   I watch everyone of his standups.
[01:54:55.760 --> 01:54:57.200]   - I have positive things.
[01:54:57.200 --> 01:54:58.640]   - Mike, go ahead.
[01:54:58.640 --> 01:55:02.280]   - I have a positive thing to add.
[01:55:02.280 --> 01:55:07.280]   As Israeli, I should mention Israel and its vaccination.
[01:55:07.280 --> 01:55:12.000]   Now topped on five million people.
[01:55:12.000 --> 01:55:13.840]   - You're close to 100%, aren't you?
[01:55:13.840 --> 01:55:18.680]   - So in the older, it's 99%
[01:55:18.680 --> 01:55:20.640]   - Isn't that great?
[01:55:20.640 --> 01:55:23.800]   - And also young people are like 60 or 70%.
[01:55:23.800 --> 01:55:26.040]   Like most of Israel are just vaccinated,
[01:55:26.040 --> 01:55:26.880]   which is amazing.
[01:55:26.880 --> 01:55:28.280]   - So they are on the lookout.
[01:55:28.280 --> 01:55:30.600]   - Nice.
[01:55:30.600 --> 01:55:32.840]   - Was your question yet in the hospitalizations
[01:55:32.840 --> 01:55:37.280]   and the state of the pandemic?
[01:55:37.280 --> 01:55:39.200]   Are you seeing the impact?
[01:55:39.200 --> 01:55:41.520]   - Of course, it's going down dramatically.
[01:55:41.520 --> 01:55:45.000]   And the ones that are do end up in the hospital
[01:55:45.000 --> 01:55:45.800]   didn't get the vaccine.
[01:55:45.800 --> 01:55:48.080]   So those who did are not there.
[01:55:48.080 --> 01:55:50.280]   - Jeff has had his, right?
[01:55:50.280 --> 01:55:51.720]   You had both of yours now, Jeff, right?
[01:55:51.720 --> 01:55:52.960]   - Yep, yep.
[01:55:52.960 --> 01:55:54.280]   - Did you have any reaction to it?
[01:55:54.280 --> 01:55:57.560]   - Second one was, first shot was really weird.
[01:55:57.560 --> 01:56:01.240]   It was two weeks after I had a delayed reaction.
[01:56:01.240 --> 01:56:04.800]   My arm got sore two weeks later and fever and stuff.
[01:56:04.800 --> 01:56:07.360]   The second one, the day after I felt pretty crappy,
[01:56:07.360 --> 01:56:08.760]   but I still functioned.
[01:56:08.760 --> 01:56:09.920]   In fact, I think it was on the show.
[01:56:09.920 --> 01:56:12.240]   So you can debate that.
[01:56:12.240 --> 01:56:13.080]   The chat room will.
[01:56:13.080 --> 01:56:16.520]   - So that's been a week or two.
[01:56:16.520 --> 01:56:18.160]   You'll be pretty safe.
[01:56:18.160 --> 01:56:19.000]   - Same to take.
[01:56:19.000 --> 01:56:19.840]   - You'll be pretty good.
[01:56:19.840 --> 01:56:20.680]   - Yeah.
[01:56:20.680 --> 01:56:23.200]   - My behavior is not going to change at all.
[01:56:23.200 --> 01:56:25.320]   - It's still going to be the same.
[01:56:25.320 --> 01:56:26.160]   - But I feel it's freaked.
[01:56:26.160 --> 01:56:27.200]   - Same annoying jerk.
[01:56:27.200 --> 01:56:28.040]   Is that what you're saying?
[01:56:28.040 --> 01:56:28.880]   - Jerk that I am.
[01:56:28.880 --> 01:56:30.520]   (laughing)
[01:56:30.520 --> 01:56:32.680]   - Actually, Steve Gibson has also had both of his
[01:56:32.680 --> 01:56:34.520]   and he did have a strong reaction to the second.
[01:56:34.520 --> 01:56:35.600]   He felt pretty ill.
[01:56:35.600 --> 01:56:36.440]   - He did.
[01:56:36.440 --> 01:56:37.280]   - For an evening.
[01:56:37.280 --> 01:56:38.800]   But that's good.
[01:56:38.800 --> 01:56:40.280]   You kind of hope for that reaction
[01:56:40.280 --> 01:56:41.280]   'cause that means your body is--
[01:56:41.280 --> 01:56:42.120]   - You do.
[01:56:42.120 --> 01:56:42.960]   I got a little freaked the first shot
[01:56:42.960 --> 01:56:43.800]   that I had no reaction.
[01:56:43.800 --> 01:56:45.880]   I thought, oh, you know, did I get water
[01:56:45.880 --> 01:56:46.720]   or something?
[01:56:46.720 --> 01:56:47.560]   What's wrong?
[01:56:47.560 --> 01:56:51.920]   - And I, as much younger men will be waiting a while.
[01:56:51.920 --> 01:56:53.200]   No, I'm just kidding.
[01:56:53.200 --> 01:56:54.040]   I missed it by--
[01:56:54.040 --> 01:56:56.040]   - Connecticut dropped the age of 55.
[01:56:56.040 --> 01:56:57.800]   - Ah, moving to Connecticut.
[01:56:57.800 --> 01:56:59.200]   Neri, have your kids,
[01:56:59.200 --> 01:57:02.000]   are your kids old enough to be in school?
[01:57:02.000 --> 01:57:04.360]   - My daughter is in online learning
[01:57:04.360 --> 01:57:05.760]   in Cupertino School District,
[01:57:05.760 --> 01:57:07.800]   which is neither online or learning.
[01:57:07.800 --> 01:57:08.800]   - Yeah.
[01:57:08.800 --> 01:57:09.640]   (laughing)
[01:57:09.640 --> 01:57:10.480]   - Yeah.
[01:57:10.480 --> 01:57:11.320]   - Oh boy.
[01:57:11.320 --> 01:57:12.800]   - What grade is she in?
[01:57:12.800 --> 01:57:13.640]   - Kinder.
[01:57:13.640 --> 01:57:16.640]   - Yeah, that's gotta be really hard for a kid that age
[01:57:16.640 --> 01:57:17.960]   or six year, five or six years.
[01:57:17.960 --> 01:57:19.400]   - And apparent too.
[01:57:19.400 --> 01:57:21.000]   - Yeah, yeah.
[01:57:21.000 --> 01:57:22.360]   Hard for everybody.
[01:57:22.360 --> 01:57:23.840]   I'm sure you're looking forward to the day
[01:57:23.840 --> 01:57:25.920]   when first grade starts in the fall
[01:57:25.920 --> 01:57:27.880]   and your kid can go back to school.
[01:57:27.880 --> 01:57:29.360]   - Actually, they are reopening,
[01:57:29.360 --> 01:57:32.360]   but in a very hybrid, funny way of two days a week
[01:57:32.360 --> 01:57:33.360]   for two hours.
[01:57:33.360 --> 01:57:34.200]   - Yes.
[01:57:34.200 --> 01:57:35.040]   - So we'll see about that.
[01:57:35.040 --> 01:57:36.800]   - That's what's happening in Petemula.
[01:57:36.800 --> 01:57:37.800]   (laughing)
[01:57:37.800 --> 01:57:38.640]   Permetchumla.
[01:57:38.640 --> 01:57:41.160]   (laughing)
[01:57:41.160 --> 01:57:43.320]   'Cause we have a senior in high school
[01:57:43.320 --> 01:57:47.680]   and he got noticed that April 17th,
[01:57:47.680 --> 01:57:49.520]   they'll be going in small groups back in the school.
[01:57:49.520 --> 01:57:50.360]   So I'm not gonna do that.
[01:57:50.360 --> 01:57:51.280]   I wanna waste a time.
[01:57:51.280 --> 01:57:52.720]   It's another month.
[01:57:52.720 --> 01:57:54.560]   But at least he can graduate, he can walk
[01:57:54.560 --> 01:57:56.320]   and they'll have some sort of graduation,
[01:57:56.320 --> 01:57:58.200]   which is a big thing.
[01:57:58.200 --> 01:57:59.800]   - Oh good, oh good.
[01:57:59.800 --> 01:58:00.640]   - Yeah.
[01:58:00.640 --> 01:58:03.360]   - I mean everybody shot by the end of May.
[01:58:03.360 --> 01:58:05.440]   - That's the really amazing wonderful news.
[01:58:05.440 --> 01:58:07.360]   - For those who are catching up with Israel.
[01:58:07.360 --> 01:58:10.680]   We will have 100% coverage.
[01:58:10.680 --> 01:58:11.960]   They're saying the US government's saying.
[01:58:11.960 --> 01:58:14.120]   - Of those who take it, that's the next issue.
[01:58:14.120 --> 01:58:18.040]   - Well, I noticed there's a lot less virus denial going on.
[01:58:18.040 --> 01:58:19.320]   Have you noticed that?
[01:58:19.320 --> 01:58:22.520]   People are not quite so adamant that they're not gonna--
[01:58:22.520 --> 01:58:24.320]   - Everybody knows people who've gotten it.
[01:58:24.320 --> 01:58:26.520]   And so I'm not too weird.
[01:58:26.520 --> 01:58:27.760]   - Yeah, yeah.
[01:58:27.760 --> 01:58:30.720]   No, I have a feeling that that's just more old news.
[01:58:30.720 --> 01:58:31.560]   - Yeah.
[01:58:31.560 --> 01:58:33.400]   How about in your community,
[01:58:33.400 --> 01:58:34.240]   because of course--
[01:58:34.240 --> 01:58:35.080]   - I think it's more old news now.
[01:58:35.080 --> 01:58:36.400]   - I understand African Americans,
[01:58:36.400 --> 01:58:38.200]   black people are very sensitive to this
[01:58:38.200 --> 01:58:40.920]   after the Tuskegee experiment, I shouldn't laugh.
[01:58:40.920 --> 01:58:44.600]   Horrific public health failure
[01:58:44.600 --> 01:58:47.760]   for American black people.
[01:58:47.760 --> 01:58:51.720]   So I've heard that there's kind of a natural resistance.
[01:58:51.720 --> 01:58:54.040]   Is it, do you still notice that among friends and family?
[01:58:54.040 --> 01:58:54.880]   - Yeah.
[01:58:54.880 --> 01:58:55.920]   - Yeah.
[01:58:55.920 --> 01:58:57.320]   - I've seen it both ways actually.
[01:58:57.320 --> 01:58:59.320]   Pretty split down the nose.
[01:58:59.320 --> 01:59:00.160]   - How do you feel about it?
[01:59:00.160 --> 01:59:01.000]   You're gonna do it?
[01:59:01.000 --> 01:59:02.000]   - I speak with back home.
[01:59:02.000 --> 01:59:06.320]   I would do it, but I'm not rushing for it
[01:59:06.320 --> 01:59:10.120]   because I know there are people that need it way more
[01:59:10.120 --> 01:59:10.960]   than I do.
[01:59:10.960 --> 01:59:12.720]   I'm in fairly good shape.
[01:59:12.720 --> 01:59:13.920]   I take care of myself.
[01:59:13.920 --> 01:59:16.840]   And so I'd rather somebody else get it.
[01:59:16.840 --> 01:59:18.760]   - Like me, I need it more than you do.
[01:59:18.760 --> 01:59:21.360]   But I'm not gonna get it.
[01:59:21.360 --> 01:59:22.760]   - You know, it really needs a teacher's
[01:59:22.760 --> 01:59:23.960]   not my workers. - You do, oh man.
[01:59:23.960 --> 01:59:24.800]   - Yeah.
[01:59:24.800 --> 01:59:29.600]   So anyway, I hope everybody is getting it the minute
[01:59:29.600 --> 01:59:31.240]   they came, my mom has got her first shot.
[01:59:31.240 --> 01:59:33.000]   She's gonna point it for the second shot.
[01:59:33.000 --> 01:59:34.920]   She's 88, so it was very--
[01:59:34.920 --> 01:59:36.440]   - Was it hard, what state of she in?
[01:59:36.440 --> 01:59:37.720]   - Rhode Island. - What state of she in?
[01:59:37.720 --> 01:59:38.640]   - Rhode Island.
[01:59:38.640 --> 01:59:39.480]   - Was it hard?
[01:59:39.480 --> 01:59:40.320]   - Yeah, it was hard.
[01:59:40.320 --> 01:59:41.600]   - She had a-- - It's so damn different.
[01:59:41.600 --> 01:59:43.400]   - Rhode Island's a mess.
[01:59:43.400 --> 01:59:47.640]   She had an appointment and showed up
[01:59:47.640 --> 01:59:48.760]   and they said, "Oh, we sent everybody a home,
[01:59:48.760 --> 01:59:50.120]   it was too icy.
[01:59:50.120 --> 01:59:51.960]   I'm 88 years old, I made it."
[01:59:51.960 --> 01:59:56.520]   But they said, "No one's here, you can't get the shot."
[01:59:56.520 --> 01:59:58.880]   So she had a remake it, she got it at CVS,
[01:59:58.880 --> 02:00:01.240]   which I think is probably what we're gonna do.
[02:00:01.240 --> 02:00:03.760]   The drugstores in California are giving me shots.
[02:00:03.760 --> 02:00:07.000]   So we're looking forward to it.
[02:00:07.000 --> 02:00:09.200]   And I'm sure-- - I was gonna drive
[02:00:09.200 --> 02:00:12.120]   for the second shot, I was gonna have to drive
[02:00:12.120 --> 02:00:13.640]   to more than two hours.
[02:00:13.640 --> 02:00:14.480]   - Wow.
[02:00:14.480 --> 02:00:16.040]   - To the south part of the state where they had it.
[02:00:16.040 --> 02:00:18.920]   And then colleagues of mine's husband
[02:00:18.920 --> 02:00:19.960]   was getting it the same place.
[02:00:19.960 --> 02:00:21.120]   So we do this.
[02:00:21.120 --> 02:00:23.240]   And the morning she said, "Oh, they switched this."
[02:00:23.240 --> 02:00:24.320]   I said, "Oh, they switched me."
[02:00:24.320 --> 02:00:25.680]   And I looked at my email, it was hidden.
[02:00:25.680 --> 02:00:27.680]   Thank you, Google. - Yikes.
[02:00:27.680 --> 02:00:28.760]   - And I would have gone to the wrong place.
[02:00:28.760 --> 02:00:29.920]   They just switched it the last minute,
[02:00:29.920 --> 02:00:32.520]   but it was pretty amazing, the process.
[02:00:32.520 --> 02:00:35.440]   It's heartwarming to get it.
[02:00:35.440 --> 02:00:37.760]   - Dr. Serals, who hosts our floss weekly show
[02:00:37.760 --> 02:00:40.040]   on Wednesday mornings, was missing today
[02:00:40.040 --> 02:00:41.440]   because he was to get his shot.
[02:00:41.440 --> 02:00:43.160]   But I noticed him messaging us.
[02:00:43.160 --> 02:00:44.600]   He says, "I've been in line an hour.
[02:00:44.600 --> 02:00:45.680]   Now it's an hour and a half."
[02:00:45.680 --> 02:00:47.160]   There was quite a long wait.
[02:00:47.160 --> 02:00:49.200]   So he's in California.
[02:00:49.200 --> 02:00:51.120]   He's in California. - Three hours.
[02:00:51.120 --> 02:00:53.120]   - Oh, he went to Dodger Stadium.
[02:00:53.120 --> 02:00:54.040]   - Santa Barbara.
[02:00:54.040 --> 02:00:55.920]   - There's your mistake.
[02:00:55.920 --> 02:00:57.600]   - Dude, I imagine it's a little frustrating
[02:00:57.600 --> 02:00:59.360]   is your family can all get it in Israel
[02:00:59.360 --> 02:01:01.840]   and you've got to wait for how long here to get it.
[02:01:01.840 --> 02:01:06.560]   - So a month ago, all of them finished the second dose
[02:01:06.560 --> 02:01:11.560]   and got the green passport saying they can go everywhere.
[02:01:11.560 --> 02:01:14.160]   - So jealous.
[02:01:14.160 --> 02:01:15.440]   Can you e-dine in?
[02:01:15.440 --> 02:01:16.800]   Can you go to concerts?
[02:01:16.800 --> 02:01:18.360]   Can you touch people?
[02:01:18.360 --> 02:01:20.880]   - They started shows, yeah, shows and things.
[02:01:20.880 --> 02:01:22.960]   They're just for those who have green passport.
[02:01:22.960 --> 02:01:23.800]   - That's wonderful.
[02:01:23.800 --> 02:01:25.120]   Where in Israel are you from?
[02:01:25.120 --> 02:01:27.960]   - North, Haifa.
[02:01:27.960 --> 02:01:28.960]   - Haifa.
[02:01:28.960 --> 02:01:29.800]   - Haifa.
[02:01:29.800 --> 02:01:31.160]   - But I live near Tel Aviv most of my life.
[02:01:31.160 --> 02:01:32.360]   - Yeah, I've been to Haifa.
[02:01:32.360 --> 02:01:34.600]   We were in Israel last year.
[02:01:34.600 --> 02:01:35.840]   I really enjoyed it.
[02:01:35.840 --> 02:01:37.240]   That's so much fun. - Back when we could travel.
[02:01:37.240 --> 02:01:38.400]   - Back two years. - Back two years.
[02:01:38.400 --> 02:01:39.480]   - Is it two years now, John?
[02:01:39.480 --> 02:01:40.600]   I guess it is, yeah.
[02:01:40.600 --> 02:01:43.240]   Last year I was sitting here, stuck.
[02:01:43.240 --> 02:01:44.840]   (laughs)
[02:01:44.840 --> 02:01:46.680]   At the end of 2019, we went,
[02:01:46.680 --> 02:01:48.600]   but we, gosh, we had a great time.
[02:01:48.600 --> 02:01:49.440]   I really enjoyed it.
[02:01:49.440 --> 02:01:50.720]   It was so much fun.
[02:01:50.720 --> 02:01:51.680]   And we visited Haifa.
[02:01:51.680 --> 02:01:53.920]   My friend, as I was mentioning earlier,
[02:01:53.920 --> 02:01:56.800]   is from Natanya, on the seaside.
[02:01:56.800 --> 02:01:58.680]   Very beautiful area.
[02:01:58.680 --> 02:02:02.720]   Thank you, Noreet, Dr. Techlash.
[02:02:02.720 --> 02:02:04.320]   It's been great having you.
[02:02:04.320 --> 02:02:07.160]   TheBookTechlashBook.com, Dr. Noreet Weisplat.
[02:02:07.160 --> 02:02:09.120]   Have a wonderful day.
[02:02:09.120 --> 02:02:11.920]   And we'll see you soon, I hope.
[02:02:11.920 --> 02:02:13.960]   - Hope so too.
[02:02:13.960 --> 02:02:14.840]   - Take care.
[02:02:14.840 --> 02:02:15.880]   Thank you, Jeff Jarvis.
[02:02:15.880 --> 02:02:17.560]   Wait a minute, wait a minute.
[02:02:17.560 --> 02:02:20.680]   Noreet had a nice short intro.
[02:02:20.680 --> 02:02:21.840]   He's the director of the town.
[02:02:21.840 --> 02:02:23.800]   - I bet she had a long academic program.
[02:02:23.800 --> 02:02:25.400]   - Yeah, I could have read the long one, but I didn't.
[02:02:25.400 --> 02:02:27.440]   - She will, she'll be the chair soon, no.
[02:02:27.440 --> 02:02:28.760]   - The director of the Townite Center
[02:02:28.760 --> 02:02:30.240]   for the Entrepreneurial Journalism
[02:02:30.240 --> 02:02:33.520]   at the Craig Newmark Graduate School of Journalism
[02:02:33.520 --> 02:02:35.800]   at the City University of New York,
[02:02:35.800 --> 02:02:38.520]   not affiliated with the Edinburgh School of Journalism
[02:02:38.520 --> 02:02:40.440]   at USC.
[02:02:40.440 --> 02:02:41.440]   - No way.
[02:02:41.440 --> 02:02:42.520]   - No way. - We have all the money.
[02:02:42.520 --> 02:02:43.520]   - Man.
[02:02:43.520 --> 02:02:44.360]   - We have all the money.
[02:02:44.360 --> 02:02:47.920]   - Buzzmachine.com is his blog, his books.
[02:02:47.920 --> 02:02:50.160]   And what book would you like to plug today?
[02:02:50.160 --> 02:02:52.040]   You've mentioned Gutenberg the geek.
[02:02:52.040 --> 02:02:53.920]   - No, that's okay.
[02:02:53.920 --> 02:02:54.960]   I'm just as soon as I get that.
[02:02:54.960 --> 02:02:56.400]   So I finished the new one.
[02:02:56.400 --> 02:02:58.120]   I told you that last week and I'm now selling it.
[02:02:58.120 --> 02:02:58.960]   - You finished?
[02:02:58.960 --> 02:02:59.800]   - So I'd like to plug you.
[02:02:59.800 --> 02:03:01.160]   I'd like to plug is it an editor
[02:03:01.160 --> 02:03:02.840]   who would like a book about books.
[02:03:02.840 --> 02:03:04.920]   - Do you have a title?
[02:03:04.920 --> 02:03:08.520]   - Gutenberg, yeah, the Gutenberg parenthesis.
[02:03:08.520 --> 02:03:10.280]   - The Google, I like that.
[02:03:10.280 --> 02:03:11.520]   See, that's a bestseller.
[02:03:12.720 --> 02:03:16.440]   - Any editor worth her salt
[02:03:16.440 --> 02:03:19.280]   is gonna call Jeff tomorrow and say,
[02:03:19.280 --> 02:03:22.960]   Jeff, we would love your book here at Simon & Schuster,
[02:03:22.960 --> 02:03:23.800]   Hashet.
[02:03:23.800 --> 02:03:27.200]   Who else?
[02:03:27.200 --> 02:03:28.280]   I don't know who else there is in the world.
[02:03:28.280 --> 02:03:30.280]   - Random house for university press.
[02:03:30.280 --> 02:03:31.120]   - One of them.
[02:03:31.120 --> 02:03:31.960]   - Yeah, that is.
[02:03:31.960 --> 02:03:34.280]   - That is such a natural, how could you,
[02:03:34.280 --> 02:03:36.740]   I mean, you put that up, a nice display
[02:03:36.740 --> 02:03:37.880]   in the window of the bookstore,
[02:03:37.880 --> 02:03:40.280]   the Gutenberg parenthesis, the whole stack
[02:03:40.280 --> 02:03:42.120]   will be gone in the end of the day.
[02:03:42.120 --> 02:03:43.440]   - Yeah, it's amazing.
[02:03:43.440 --> 02:03:45.200]   Well, good.
[02:03:45.200 --> 02:03:48.920]   I hope, you know, from our mouth to publisher's ear,
[02:03:48.920 --> 02:03:49.760]   I hope they're listening.
[02:03:49.760 --> 02:03:50.600]   - Yes.
[02:03:50.600 --> 02:03:53.640]   - And Prude hosts hands on photography.
[02:03:53.640 --> 02:03:56.080]   You got another photographer interview coming up?
[02:03:56.080 --> 02:04:01.800]   - This week is no interview,
[02:04:01.800 --> 02:04:04.720]   but it's still gonna be a nice fun chat in discussion.
[02:04:04.720 --> 02:04:05.560]   - Good.
[02:04:05.560 --> 02:04:06.400]   - Talk about some lenses,
[02:04:06.400 --> 02:04:09.080]   but we do have some interviews coming up in the future
[02:04:09.080 --> 02:04:10.040]   and I can't wait to show you.
[02:04:10.040 --> 02:04:10.880]   - I'm actually mad at you.
[02:04:10.880 --> 02:04:13.480]   - I also wanna talk about a book since you're talking books.
[02:04:13.480 --> 02:04:14.320]   - Oh, good, yeah.
[02:04:14.320 --> 02:04:19.520]   - This is one that I finally got around to reading
[02:04:19.520 --> 02:04:22.800]   from our beloved John McWhorter.
[02:04:22.800 --> 02:04:24.040]   - Oh, keen back.
[02:04:24.040 --> 02:04:25.400]   - Isn't it great?
[02:04:25.400 --> 02:04:27.440]   - Yes, love it.
[02:04:27.440 --> 02:04:28.760]   - I really did enjoy that.
[02:04:28.760 --> 02:04:29.600]   - Did you?
[02:04:29.600 --> 02:04:31.480]   - I shared it with the family, you know,
[02:04:31.480 --> 02:04:32.920]   because the hard heads and I,
[02:04:32.920 --> 02:04:35.840]   we'd been having some discussions here and there
[02:04:35.840 --> 02:04:38.240]   because again, they're older and starting to see
[02:04:38.240 --> 02:04:39.800]   more of the world and be a little bit--
[02:04:39.800 --> 02:04:41.520]   - He's a little bit more at his hard heads or his son.
[02:04:41.520 --> 02:04:42.520]   - I'm just trying to.
[02:04:42.520 --> 02:04:44.960]   - What do you tell him?
[02:04:44.960 --> 02:04:47.520]   Are you of the persuasion?
[02:04:47.520 --> 02:04:49.120]   Don't talk black, talk,
[02:04:49.120 --> 02:04:50.440]   stand in American English,
[02:04:50.440 --> 02:04:52.280]   you'll go farther, you'll do better.
[02:04:52.280 --> 02:04:55.320]   Or do you celebrate, as McWhorter does,
[02:04:55.320 --> 02:04:59.640]   black English as being a completely legitimate language?
[02:04:59.640 --> 02:05:05.960]   - More so along the lines of BU.
[02:05:05.960 --> 02:05:06.800]   - There you go.
[02:05:06.800 --> 02:05:07.960]   - BU who you are when you speak.
[02:05:07.960 --> 02:05:08.800]   - Yeah, yeah, yeah, yeah.
[02:05:08.800 --> 02:05:10.000]   - You could like someone else,
[02:05:10.000 --> 02:05:12.080]   that's my primary message.
[02:05:12.080 --> 02:05:15.160]   But I want them to understand, you know,
[02:05:15.160 --> 02:05:17.560]   the nuance of black English, you know,
[02:05:17.560 --> 02:05:19.360]   'cause a lot of people just don't know,
[02:05:19.360 --> 02:05:20.200]   including myself.
[02:05:20.200 --> 02:05:22.120]   - A lot of people think it's ignorant or it's southern
[02:05:22.120 --> 02:05:22.960]   and it's neither.
[02:05:22.960 --> 02:05:23.920]   - I always know the differences.
[02:05:23.920 --> 02:05:24.760]   - Yeah.
[02:05:24.760 --> 02:05:25.600]   - Oh.
[02:05:25.600 --> 02:05:26.440]   - Right.
[02:05:26.440 --> 02:05:28.000]   - And it's neither, you know, but also understand,
[02:05:28.000 --> 02:05:31.680]   you know, proper conjugation of verbs, you know.
[02:05:31.680 --> 02:05:34.680]   - So if you like that, McWhorter has a very good podcast
[02:05:34.680 --> 02:05:37.280]   on Slate called "The Lexicon Valley"
[02:05:37.280 --> 02:05:38.320]   and he talks about--
[02:05:38.320 --> 02:05:40.840]   - "Lixicon Valley", I listen to that every week.
[02:05:40.840 --> 02:05:42.880]   - Oh, okay, never mind.
[02:05:42.880 --> 02:05:44.480]   It's a good recommendation, isn't it?
[02:05:44.480 --> 02:05:45.320]   Isn't it fun?
[02:05:45.320 --> 02:05:46.240]   I really like his stuff.
[02:05:46.240 --> 02:05:47.080]   Yeah.
[02:05:47.080 --> 02:05:49.280]   And actually, it's really Jeff's recommendation,
[02:05:49.280 --> 02:05:50.320]   'cause you were reading our,
[02:05:50.320 --> 02:05:53.240]   what is it, our bastard language, Jeff.
[02:05:53.240 --> 02:05:54.080]   - I think that's the one you know.
[02:05:54.080 --> 02:05:55.720]   - Yeah, and recommended it.
[02:05:55.720 --> 02:05:57.160]   I started picking up all his books.
[02:05:57.160 --> 02:05:58.280]   I love linguists.
[02:05:58.280 --> 02:06:01.560]   I love the subject of language is fascinating.
[02:06:01.560 --> 02:06:02.400]   Yeah.
[02:06:02.400 --> 02:06:04.320]   Good recommendation.
[02:06:04.320 --> 02:06:05.520]   I was gonna say I'm mad at you, Aunt,
[02:06:05.520 --> 02:06:08.360]   because in one of our meetings, you mentioned
[02:06:08.360 --> 02:06:12.520]   that Sony had just shipped a new 20 millimeter F1.8 lens
[02:06:12.520 --> 02:06:14.840]   and I ended up buying it.
[02:06:14.840 --> 02:06:15.760]   It's all your fault.
[02:06:15.760 --> 02:06:16.760]   - Oh.
[02:06:16.760 --> 02:06:17.600]   - But it's fun.
[02:06:17.600 --> 02:06:18.440]   - You did get it.
[02:06:18.440 --> 02:06:19.280]   - I did.
[02:06:19.280 --> 02:06:20.120]   - I knew you would get it.
[02:06:20.120 --> 02:06:21.960]   - I love me some fixed primes.
[02:06:21.960 --> 02:06:22.800]   I love 'em.
[02:06:22.800 --> 02:06:24.080]   They're just great.
[02:06:24.080 --> 02:06:25.280]   And it's a beautiful lens.
[02:06:25.280 --> 02:06:26.360]   It's a really nice lens.
[02:06:26.360 --> 02:06:27.760]   - It was a great price for it.
[02:06:27.760 --> 02:06:29.040]   - And it was very inexpensive, yeah.
[02:06:29.040 --> 02:06:31.200]   Well, for that kind of thing,
[02:06:31.200 --> 02:06:32.040]   that's right.
[02:06:32.040 --> 02:06:33.960]   It's because more than a fine watch,
[02:06:33.960 --> 02:06:37.560]   but it was. (laughing)
[02:06:37.560 --> 02:06:38.880]   Well, go ahead and try to take pictures
[02:06:38.880 --> 02:06:41.200]   through your fine watch, I ask you.
[02:06:41.200 --> 02:06:42.480]   Thank you, Aunt.
[02:06:42.480 --> 02:06:43.320]   Thank you, Jeff.
[02:06:43.320 --> 02:06:44.320]   Thank you, Noread.
[02:06:44.320 --> 02:06:45.560]   It's been really great having you.
[02:06:45.560 --> 02:06:48.560]   This show is a Wednesday afternoon production,
[02:06:48.560 --> 02:06:52.360]   130 Pacific, 430 Eastern, 2130 UTC.
[02:06:52.360 --> 02:06:53.920]   I say that only because if you want,
[02:06:53.920 --> 02:06:58.080]   you can watch us do it live at twit.tv/liveaudio.
[02:06:58.080 --> 02:07:00.120]   Live videos you're seeing right here.
[02:07:00.120 --> 02:07:02.000]   If you're doing the live thing,
[02:07:02.000 --> 02:07:03.560]   anytime of the day or night,
[02:07:03.560 --> 02:07:05.360]   our chat room is always open for you.
[02:07:05.360 --> 02:07:07.920]   irc.twit.tv.
[02:07:07.920 --> 02:07:09.000]   That's the web interface,
[02:07:09.000 --> 02:07:11.280]   but you can also use an IRC client.
[02:07:11.280 --> 02:07:12.720]   It's a really great community of people
[02:07:12.720 --> 02:07:14.920]   talking about, sometimes about the things
[02:07:14.920 --> 02:07:16.240]   we're talking about,
[02:07:16.240 --> 02:07:18.280]   but always something interesting.
[02:07:18.280 --> 02:07:19.880]   If you want an on-demand version of the show,
[02:07:19.880 --> 02:07:22.360]   you can download audio or video from our website,
[02:07:22.360 --> 02:07:24.640]   twit.tv/twig.
[02:07:24.640 --> 02:07:25.720]   You can also get it from,
[02:07:25.720 --> 02:07:27.000]   there's a YouTube channel.
[02:07:27.000 --> 02:07:29.320]   In fact, Twit has a master YouTube channel,
[02:07:29.320 --> 02:07:31.640]   which is youtube.com/twit.
[02:07:31.640 --> 02:07:33.680]   And then there are links to all the other shows,
[02:07:33.680 --> 02:07:37.040]   channels including youtube.com/thisweekin.
[02:07:37.040 --> 02:07:40.320]   Google, honestly, the easiest thing to do,
[02:07:40.320 --> 02:07:42.880]   get yourself a podcast client
[02:07:42.880 --> 02:07:44.800]   and download it, subscribe, really.
[02:07:44.800 --> 02:07:47.600]   And then that way you'll have it the minute it's available
[02:07:47.600 --> 02:07:49.280]   on any platform of your choice.
[02:07:49.280 --> 02:07:53.160]   If you do, use one of those iTunes or Apple podcasts
[02:07:53.160 --> 02:07:55.680]   or Google podcasts or pocket casts,
[02:07:55.680 --> 02:07:58.400]   please do us a favor, write and review.
[02:07:58.400 --> 02:08:03.400]   That way people will know to stay well away from this show
[02:08:03.400 --> 02:08:04.960]   or you can give us an ice review,
[02:08:04.960 --> 02:08:06.640]   which would be even better.
[02:08:06.640 --> 02:08:07.480]   Thanks for joining us.
[02:08:07.480 --> 02:08:10.560]   We'll see you next time on this week in Google.
[02:08:10.560 --> 02:08:11.400]   Bye bye.
[02:08:11.400 --> 02:08:14.480]   (upbeat music)
[02:08:14.480 --> 02:08:17.720]   If you like Android with a heavy dose of fun and entertainment,
[02:08:17.720 --> 02:08:20.000]   then you're gonna love all about Android.
[02:08:20.000 --> 02:08:21.160]   It's me, Jason Howell,
[02:08:21.160 --> 02:08:24.280]   along with my co-hosts Ron Richards and Florence Ion.
[02:08:24.280 --> 02:08:27.600]   Every Tuesday we discuss the news items that matter most,
[02:08:27.600 --> 02:08:30.280]   the hardware and devices that are running Android
[02:08:30.280 --> 02:08:32.360]   and the apps that run on top of them.
[02:08:32.360 --> 02:08:35.200]   Plus we answer your email each and every week.
[02:08:35.200 --> 02:08:37.480]   That's all about Android on Twit.tv.
[02:08:37.480 --> 02:08:40.060]   (upbeat music)
[02:08:40.060 --> 02:08:42.640]   (upbeat music)
[02:08:42.640 --> 02:08:45.220]   (upbeat music)
[02:08:45.220 --> 02:08:47.800]   (upbeat music)
[02:08:47.800 --> 02:08:52.800]   ( Pass)

