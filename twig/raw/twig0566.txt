;FFMETADATA1
title=Thunderbolt and Lightning
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=566
genre=Podcast
comment=https://twit.tv/twig
copyright=These podcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.800]   It's time for Twig this week in Google and Pruitt Jeff Jarvis and a very special guest from TechDirt.
[00:00:06.800 --> 00:00:13.120]   Mike Masnick joins us. We'll talk about section 230 and how the Senate keeps trying to take it down
[00:00:13.120 --> 00:00:19.520]   along with encryption. We'll talk about Parler and their Bannon users now. This week, we cancel
[00:00:19.520 --> 00:00:28.240]   Culture, Twitch, YouTube, Reddit, so many people canceled and a way to buy a card game invented by
[00:00:28.240 --> 00:00:36.240]   the CIA. It's all coming up next on Twig. This week in Google comes to you from our LastPass
[00:00:36.240 --> 00:00:41.600]   studios. Stay in control when it comes to your company's access points and authentication. LastPass
[00:00:41.600 --> 00:00:47.200]   makes security simple for your remote workforce. Check out lastpass.com/twit to learn more.
[00:00:50.000 --> 00:01:02.240]   Podcasts you love. This is Twig. This is Twig. This is Twig. This week in Google,
[00:01:02.240 --> 00:01:08.800]   episode 566, recorded Wednesday, July 1, 2020. Thunderbolt and Lightning.
[00:01:08.800 --> 00:01:15.840]   This week in Google is brought to you by Wasabi Hot Cloud Storage. Thinking about moving your data
[00:01:15.840 --> 00:01:22.480]   storage to the cloud? Wasabi is enterprise-class cloud storage at 1/5th of Amazon S3 and faster
[00:01:22.480 --> 00:01:28.560]   than the competition with no fees for egress or API requests and no complex storage tiers.
[00:01:28.560 --> 00:01:36.160]   Start a free trial at wasabi.com and do the code TWIT. And by LastPass. Give your IT
[00:01:36.160 --> 00:01:41.280]   Department a break and supply them with the tools that really protect your business.
[00:01:41.280 --> 00:01:48.480]   Visit LastPass.com/twit to find out how they can help you. It's time for Twig. This week in Google
[00:01:48.480 --> 00:01:55.360]   is showing you the latest news from everywhere including Google. And it's back to have you at
[00:01:55.360 --> 00:02:03.600]   hands on wellness. Always a pleasure to see the beautiful face and the bald
[00:02:03.600 --> 00:02:14.800]   peat of Mr. Pruitt. Clean is a whistle today. Also with us Jeff Jarvis. Wait a minute.
[00:02:14.800 --> 00:02:24.400]   Get my crib sheet. The Leonard Brown Professor for journalistic innovation at the Craig Newmark
[00:02:24.400 --> 00:02:29.520]   Graduate School of Journalism at the City University of New York. And also blogger Buzz
[00:02:29.520 --> 00:02:36.720]   Machine Duck. And I'm a very happy professor and blogger today because I worship our guests.
[00:02:36.720 --> 00:02:43.040]   I was jumping up and down in my seat with his latest 230 trick we talked about last week.
[00:02:43.040 --> 00:02:48.880]   He does God's work. He has the right attitude. He's smart. He tears down other people so I don't
[00:02:48.880 --> 00:02:54.800]   have to. And now you can introduce. We actually talk about Mike Masnick all the time we have for
[00:02:54.800 --> 00:03:00.320]   years. His tech dirt blog is really one of the best covering the intersection of technology
[00:03:00.320 --> 00:03:03.600]   and politics. It's great to have you on Mike. Good to have you. Yeah. Thanks for having me.
[00:03:03.600 --> 00:03:12.640]   Every week my ears buzz. Yeah. Actually last week we were talking about your very clever idea to
[00:03:12.640 --> 00:03:20.000]   create a kind of permanent post explaining Section 230. And it's divided up into like responses to
[00:03:20.000 --> 00:03:26.000]   common errors people make about Section 230. Everybody from the New York Times to this show.
[00:03:26.000 --> 00:03:30.960]   It's pretty common people misunderstood. If I still understand what the
[00:03:30.960 --> 00:03:38.080]   section. Yeah. You do me a big favor. Can you violate quarantine and go to New York and
[00:03:38.080 --> 00:03:46.080]   walk into Joe Scarborough's studio and sit him the F down and explain what the F Section 230 is.
[00:03:46.960 --> 00:03:54.080]   There's a full moral panic tirade every morning. Oh, here it comes. Here it comes. Oh, no.
[00:03:54.080 --> 00:04:01.280]   This is he's not the only one. Oh, God, that's true. God, no, that's true.
[00:04:01.280 --> 00:04:05.920]   This is the post we mentioned last week. Hello, you've been referred here because you're wrong
[00:04:05.920 --> 00:04:13.440]   about Section 230 of the Communications Decency Act. And which is great because we all need this
[00:04:13.440 --> 00:04:20.960]   link so that we can send people. And then it has if you want if you said and then various things
[00:04:20.960 --> 00:04:26.400]   you might have said like, well, what's a company that starts like that starts moderating content.
[00:04:26.400 --> 00:04:31.840]   It's not a platform. It's a publisher. And then Mike says, I regret to inform you you are wrong.
[00:04:31.840 --> 00:04:38.000]   You are full of crap. So honestly, it is complicated. It's hard to understand. There's really two
[00:04:38.000 --> 00:04:45.520]   parts to 230. And so it's it's confusing to people, none less confused, none more confused than the
[00:04:45.520 --> 00:04:50.320]   Congress of the United States of America, which consistently seems to me not only misunderstand
[00:04:50.320 --> 00:04:54.640]   230, even though they enacted it as part of the Communications Decency Act, the only part that's
[00:04:54.640 --> 00:05:00.560]   still around. But they constantly trying to undermine it lately, mostly with the Earn Act.
[00:05:00.560 --> 00:05:01.840]   Yeah.
[00:05:02.720 --> 00:05:11.440]   And I'm glad you've taken this on because honestly, I can't. Sometimes I feel like I am the last man
[00:05:11.440 --> 00:05:21.200]   fighting this fire. But you and Jeff Kossle. Yeah. Yeah. It's only 26 words, but it seems to be
[00:05:21.200 --> 00:05:26.320]   hard to understand. Yeah. Well, the thing is, if you actually read it, it shouldn't be that
[00:05:26.320 --> 00:05:30.240]   hard to understand. I think part of the problem is that a lot of the people criticizing it have
[00:05:30.240 --> 00:05:34.000]   never even bothered to read it, even though it is pretty short and sweet.
[00:05:34.000 --> 00:05:40.640]   But if they haven't read it, then or if they read it and they still don't understand it,
[00:05:40.640 --> 00:05:47.120]   they can read Jeff's book, which is quite readable and really enjoyable. Even if you're not deep in
[00:05:47.120 --> 00:05:52.080]   the weeds on these things, I actually, the funny thing I've said about Jeff's book is that when I
[00:05:52.080 --> 00:05:57.680]   got it, I figured, I'll flip through it and skim it. But I know the story of 230. And I know the law,
[00:05:57.680 --> 00:06:02.240]   and I know the history and the cases and all that kind of stuff. And it just sucked me in because
[00:06:02.240 --> 00:06:06.240]   it's so well written and so interesting. And it has all sorts of information and
[00:06:06.240 --> 00:06:12.080]   details that I didn't even know, even though I kind of live in this world. So it's a great book.
[00:06:12.080 --> 00:06:17.920]   I'm sure you guys have recommended it before. But I think Jeff Kossle, if the 26 words that
[00:06:17.920 --> 00:06:21.920]   created the internet, please do pick it up. I have it. I am ready.
[00:06:24.480 --> 00:06:32.160]   You should. I really does. It sucks you in. I know because I mean, you think here's a book
[00:06:32.160 --> 00:06:37.120]   about a lot, like an entire book about a single law about the internet, how interesting can it be.
[00:06:37.120 --> 00:06:40.640]   And it is the type of book that normally I would get and put on my shelf and never actually read.
[00:06:40.640 --> 00:06:43.120]   But I am telling you, it is worth actually trying to read it.
[00:06:43.120 --> 00:06:46.000]   I put it there so people think I've read it. That's the whole right.
[00:06:46.000 --> 00:06:51.440]   That would be me just sort of a poser with it. Oh, as Jeff says, yeah, right.
[00:06:52.640 --> 00:06:59.440]   Why is 230 important? I mean, what Jeff's book, the subtitle says, it created the internet,
[00:06:59.440 --> 00:07:05.760]   created the modern internet. It's kind of incredible to think about it, but you look at kind of the
[00:07:05.760 --> 00:07:12.400]   history of how the internet came about. And even if you go back like 100 years and you go to the
[00:07:12.400 --> 00:07:16.640]   history of like television and radio and especially radio and how that came about,
[00:07:16.640 --> 00:07:22.240]   we're in the early days radio had a chance to be sort of the proto-internet where it could be
[00:07:22.240 --> 00:07:27.680]   anybody communicating with anybody. And it switched. And there are powers that be that sort of
[00:07:27.680 --> 00:07:33.920]   forced it into being just a broadcast medium. So, you know, a sort of one to many situation,
[00:07:33.920 --> 00:07:39.600]   and you lost the ability for it to be, you know, one to one, one to many kind of communications.
[00:07:39.600 --> 00:07:44.240]   I think the intranquarkoni actually said that. He said, why would you want to do one to many?
[00:07:44.240 --> 00:07:48.080]   That seems like waste. It was not his intention, certainly.
[00:07:49.840 --> 00:07:55.040]   And then you have something like section 230, which somewhat accidentally really
[00:07:55.040 --> 00:08:02.800]   internet to be this platform that could do, you know, many to many communication and allow
[00:08:02.800 --> 00:08:08.400]   people to have their voice online. And, you know, some people like to claim that it's like the
[00:08:08.400 --> 00:08:16.000]   biggest gift to big tech or whatever. But I think it's actually the biggest gift to free speech
[00:08:16.000 --> 00:08:24.960]   because it really set it up so that internet sites could host speech without being afraid of it,
[00:08:24.960 --> 00:08:30.560]   of being sued out of existence because somebody posted something that was defamatory or otherwise
[00:08:30.560 --> 00:08:36.080]   violated the law. It's why we can have a chatroom. It's why your blog, people's blogs can have
[00:08:36.080 --> 00:08:42.720]   comments. You know, Google has the resources to protect itself, but do you to protect yourself
[00:08:42.720 --> 00:08:46.160]   because your blog comments? So it's important that we have that.
[00:08:46.160 --> 00:08:50.800]   And I would go even further than that. The things that some people don't understand is that, you
[00:08:50.800 --> 00:08:55.440]   know, 230 technically protects users as well. So like the comment space, you know, if you post
[00:08:55.440 --> 00:08:59.840]   something on Facebook and then the comment space beneath your post, if somebody says something
[00:08:59.840 --> 00:09:05.200]   there, you want to be protected. And 230 does that 230 protects you. It protects their cases
[00:09:05.200 --> 00:09:11.360]   involving people forwarding an email and getting sued because they forwarded an email and 230
[00:09:11.360 --> 00:09:15.440]   protected them also. So it does a whole bunch of things that actually protects the free speech of
[00:09:15.440 --> 00:09:20.160]   everybody using the internet. And without it, it would, you know, it would stifle speech and
[00:09:20.160 --> 00:09:24.960]   create a real chilling effect on the internet and the way it functions. And we'd have something
[00:09:24.960 --> 00:09:30.880]   very different, probably something a lot more akin to broadcast television and radio rather
[00:09:30.880 --> 00:09:34.400]   than, you know, something where anybody can communicate exactly why the broadcasters and the
[00:09:34.400 --> 00:09:38.240]   radio people want it that way. Yes. Yeah. Why is this?
[00:09:39.120 --> 00:09:46.160]   They're so easy to misconstrued this this this section 230 because so many people are getting
[00:09:46.160 --> 00:09:52.160]   it wrong and don't quite understand it. Is it the language or what is it? Because nobody seems to
[00:09:52.160 --> 00:09:59.360]   get this right. Yeah, I wish I knew right there. Like, I kind of wish I could go into some of the
[00:09:59.360 --> 00:10:02.720]   the brains of the people who are misconstruing it because some are doing it deliberately.
[00:10:03.760 --> 00:10:11.440]   You know, some, I think, are, you know, I think a lot of people just think that this is the way it
[00:10:11.440 --> 00:10:16.240]   should be. And they don't bother to read the law and they assume that the law was put in place
[00:10:16.240 --> 00:10:21.600]   for a certain reason or somebody, you know, said that the law should be this way for a certain reason.
[00:10:21.600 --> 00:10:29.040]   And then people have just run with it. And it's really strange because certainly among politicians,
[00:10:29.040 --> 00:10:33.440]   they know what the law says and they're just deliberately misrepresenting it and show you have
[00:10:33.440 --> 00:10:39.200]   a bunch of senators, mainly, who have, you know, gone out of the way to misrepresent what the law
[00:10:39.200 --> 00:10:43.360]   says. And then what's funny, of course, is now they're introducing all these bills to try and turn
[00:10:43.360 --> 00:10:49.680]   the law into what they said it already said. It's sort of indicated that they know that they were
[00:10:49.680 --> 00:10:56.000]   being misleading before. Mike, what drives me crazy is that there are media lawyers, media
[00:10:56.000 --> 00:11:03.200]   executives and editors who still get it wrong, who think that if they, because they go to the
[00:11:03.200 --> 00:11:09.120]   pro, what section do they fix? They think that it's prior to that. And they think that if they
[00:11:09.120 --> 00:11:15.440]   moderate any public comment and miss something, they are more liable than if they didn't, which is
[00:11:15.440 --> 00:11:20.160]   exactly what two, they were there to fix. I was to get people both the sword and the shield.
[00:11:20.160 --> 00:11:26.080]   And to this day, to this day, I see people in the media industry who are so ignorant of their own
[00:11:26.080 --> 00:11:30.800]   business and the law around it, that they still say, Oh, no, no, no, I can't moderate anything,
[00:11:30.800 --> 00:11:36.720]   because that'll make me more liable. Well, I agree. And I make fun of those people all the time. I'm
[00:11:36.720 --> 00:11:43.920]   going to do a very, very narrow bit of defense for some of those people. Because I think the first
[00:11:43.920 --> 00:11:51.440]   time I really saw it pointed out, as directly incorrectly, as this was actually in a wired
[00:11:51.440 --> 00:11:57.360]   piece about Facebook about four years ago, or something, it was like the cover story about Mark
[00:11:57.360 --> 00:12:03.520]   Zuckerberg. And twice in that article, they say that Facebook decided that they would not do any
[00:12:03.520 --> 00:12:07.520]   moderation, because if they did, they would lose 230, which is again, is the exact opposite of what
[00:12:07.520 --> 00:12:12.720]   the law says. The law says, you can moderate and you're not liable for it. And I like called out
[00:12:12.720 --> 00:12:23.680]   the wired reporters for saying it. And sort of the what I heard back, second hand, not directly
[00:12:23.680 --> 00:12:30.160]   from the wired reporters, but also from some people at Facebook, was effectively like, yes,
[00:12:30.160 --> 00:12:38.000]   we know that the law actually says the opposite of that. But that law is only for the US. And because
[00:12:38.000 --> 00:12:44.000]   as Facebook, we wanted to put in place some sort of concept or set of rules that applied
[00:12:44.000 --> 00:12:49.680]   beyond just the US, the easiest thing to do was to say, don't moderate, because then you could be
[00:12:49.680 --> 00:12:55.680]   liable. And and somehow that got morphed into the idea that that is what the law said, which is the
[00:12:55.680 --> 00:13:01.520]   and I can understand, like, if you're trying to come up with some sort of set of global rules,
[00:13:01.520 --> 00:13:07.280]   you can't rely on the language of 230. But that's that's not a good defense of it. But that's kind
[00:13:07.280 --> 00:13:15.200]   of where I think some of that came. This morning on morning Joe, as my blood pressure goes sky high
[00:13:15.200 --> 00:13:21.760]   when I see the moral panic coming, he honest to God said, the Washington Post doesn't put in Nazis.
[00:13:21.760 --> 00:13:27.680]   Why should you? You should be liable for putting in Nazis thinking that this is the, by the way,
[00:13:27.680 --> 00:13:31.680]   Joe Scarborough is the guy who can't edit himself because he goes on for 20 minutes asking one question.
[00:13:31.680 --> 00:13:38.640]   Imagine two billion Joe Scarborough's and you got to edit all of them. It's absurd. And there's no
[00:13:38.640 --> 00:13:43.040]   respect for our understanding of the value of the public conversation. That's what brothers
[00:13:43.040 --> 00:13:48.320]   mean. Yeah. And I mean, the sort of related issue to that is that what he's really mad at is the
[00:13:48.320 --> 00:13:53.920]   First Amendment and not Section 230, right? Because yeah, the Washington Post doesn't have,
[00:13:53.920 --> 00:13:59.920]   you know, Nazis, but then again, you know, sometimes the New York Times up opinion sections.
[00:13:59.920 --> 00:14:10.800]   But it's the First Amendment that allows that. I mean, like, you can say, you know,
[00:14:10.800 --> 00:14:16.640]   Nazi supportive things that is that is legal. It's, it's, you know, hideous and
[00:14:16.640 --> 00:14:21.120]   disgusting, but it is allowed under the First Amendment is the First Amendment that protects
[00:14:21.120 --> 00:14:25.520]   that. And I think a lot of people confuse that. And then if we get back to the media getting it
[00:14:25.520 --> 00:14:30.560]   wrong, right? The New York Times seems to get the 230 issue wrong all the time. And they had that,
[00:14:30.560 --> 00:14:34.800]   you know, that one giant headline once that said, you know, the law that allows for a hate speech
[00:14:34.800 --> 00:14:40.320]   online and blame 230. And then they had to write a tiny little correction that said, oh,
[00:14:40.320 --> 00:14:44.400]   actually, it's the First Amendment, which is, you know, kind of kind of a big mistake because,
[00:14:44.400 --> 00:14:49.200]   you know, you can change 230. There are all these bills around to try and change 230. But changing
[00:14:49.200 --> 00:14:52.400]   the First Amendment is a slightly bigger process. And I don't think anyone's really trying to do
[00:14:52.400 --> 00:14:58.720]   that right now. Speaking of changes, the Earn It Act was marked up today and changed or this,
[00:14:58.720 --> 00:15:04.720]   I guess it was today. And it's, yeah, they released the new bill today. They'll mark it up tomorrow.
[00:15:04.720 --> 00:15:11.200]   Okay. And propose a change that eliminates the teeth, which I guess is a victory. In some
[00:15:11.200 --> 00:15:19.040]   degrees, people who haven't been following the story, the Earn It Act is a creation of Lindsey Graham
[00:15:19.040 --> 00:15:25.600]   and Richard Blumenthal, which is kind of a right there, a marriage made in hell. And they wanted to,
[00:15:25.600 --> 00:15:32.880]   some see it as a kind of a covert way to undermine encryption. They may not need it anymore now
[00:15:32.880 --> 00:15:39.600]   that there's a absolutely overt proposal to undermine encryption. But the idea was, if you, if you
[00:15:39.600 --> 00:15:47.200]   don't follow, quote, best practices, you could lose your Section 230 protection. They, Mike,
[00:15:47.200 --> 00:15:51.920]   if I'm reading this right, they seem to have eliminated that you might lose your Section 230
[00:15:51.920 --> 00:15:59.280]   protection. Yeah, the Earn It Act is no longer about earning your anything. Right. They pulled it
[00:15:59.280 --> 00:16:03.520]   out, but they kept the name. And they kept, they kept this commission, right? The idea behind the
[00:16:03.520 --> 00:16:08.640]   original bill was that you'd have this commission, which, you know, was designed so that they could
[00:16:08.640 --> 00:16:14.000]   pretend it was a balanced commission, but it really wasn't. And the Attorney General was able to put
[00:16:14.000 --> 00:16:18.640]   his hand on the scale entirely and say, like, this is what platforms have to do. And if that
[00:16:18.640 --> 00:16:23.520]   includes getting rid of encryption, then that would, that would be one of the items. And so now
[00:16:23.520 --> 00:16:29.760]   they still have the commission and the weird sort of pretend balance of the commission. But then
[00:16:29.760 --> 00:16:33.600]   there's nothing like they'll come out with a set of best practices that nobody has to follow. And
[00:16:33.600 --> 00:16:38.880]   there's no legal penalty if you don't follow it. So they pulled that part of the bill. It's possible
[00:16:38.880 --> 00:16:43.520]   that if the bill became law and this commission comes out and they do set up a bunch of best
[00:16:43.520 --> 00:16:48.480]   practices, I could see Congress coming back and then later trying to put those best practices into
[00:16:48.480 --> 00:16:56.640]   the law in some way. But it's not. And so the only thing that's really in the bill now that changes
[00:16:56.640 --> 00:17:04.800]   the law is that they add a new section to 230 that says that what is now referred to as CSAM child
[00:17:04.800 --> 00:17:12.080]   sexual abuse material is no longer covered by section 230. I like which. I like your line. The
[00:17:12.080 --> 00:17:17.680]   artist formerly known as child porn. Yes. Well, one of the fun things that the bill actually,
[00:17:17.680 --> 00:17:23.600]   if you go through the end of the amendment that was put out today, is that it goes through
[00:17:23.600 --> 00:17:28.880]   everywhere in the federal register that says child pornography and says replace that with
[00:17:28.880 --> 00:17:34.000]   CSA. Just over and over. There's like four pages of like, oh, we have child pornography in the law
[00:17:34.000 --> 00:17:38.480]   here and here and here and here. And now just like cross it out, put in CSAM instead. So yes,
[00:17:38.480 --> 00:17:44.720]   that's the new term because child pornography is no longer allowed. I mean, that sounds bad.
[00:17:47.040 --> 00:17:52.320]   Actually, you also make an excellent case, which is that big tech seems to be taking the rap
[00:17:52.320 --> 00:17:59.920]   for child sexual abuse material as opposed to the creators thereof. Like it's all your fault
[00:17:59.920 --> 00:18:05.680]   and fix it big tech. In fact, Ron Wyden, I didn't realize this. But again, this is what we learn
[00:18:05.680 --> 00:18:14.720]   reading tech dirt has a little known proposal to encourage enforcement of child protection laws
[00:18:15.520 --> 00:18:21.200]   in lieu of going after big tech here. Yeah. And yeah, for some reason, his bill didn't get
[00:18:21.200 --> 00:18:25.040]   very much attention. I saw he just put out a statement about the new earned act saying that
[00:18:25.040 --> 00:18:30.720]   it's a problem and again, pointing to his alternative, which is basically saying like,
[00:18:30.720 --> 00:18:36.080]   you know, forced the real laws. Right. Like the real problem is that the law enforcement,
[00:18:36.080 --> 00:18:41.040]   the DOJ and others are not enforcing it. And if you look through the details, like the DOJ
[00:18:41.040 --> 00:18:48.800]   actually was required by Congress to and has been allocated a whole bunch of money to go after
[00:18:48.800 --> 00:18:57.680]   people who are engaged in CSAM, which is the correct term now. And they haven't done it. And
[00:18:57.680 --> 00:19:01.120]   they're supposed to put out a report like every couple of years or something. I forget the exact
[00:19:01.120 --> 00:19:04.960]   details and they haven't done it. Like they literally have just ignored what Congress told
[00:19:04.960 --> 00:19:10.560]   them to do and what Congress allocated for them. And then they blame the different tech
[00:19:10.560 --> 00:19:16.800]   companies. And the sort of related issue to all of this is that the tech companies effectively all
[00:19:16.800 --> 00:19:23.120]   got together and put together this voluntary system where they are reporting all of the different
[00:19:23.120 --> 00:19:28.000]   you know, when they come across any kind of of this content, they're reporting it to Nick
[00:19:28.000 --> 00:19:32.720]   Mac, which the National Center for Missing and Exploited Children. And they put together this
[00:19:32.720 --> 00:19:37.680]   amazing system that allows them to share the content with the other platforms in a
[00:19:37.680 --> 00:19:42.480]   hashed form. They're not sending around this material, but in a hash form. So they can identify
[00:19:42.480 --> 00:19:49.360]   it and block it and stop it. And it's an incredible, voluntary initiative that they've put together.
[00:19:49.360 --> 00:19:54.480]   And that's actually being leveraged against them. The reason this bill came about in the
[00:19:54.480 --> 00:19:59.680]   first place was because there were these reports about how much content, how much of these
[00:19:59.680 --> 00:20:07.120]   sending to the database these platforms have done. So yes, like Facebook has identified a whole
[00:20:07.120 --> 00:20:12.560]   bunch of really, really awful content. And they are reporting it and helping to make sure that
[00:20:12.560 --> 00:20:17.040]   that gets blocked across the internet and not just on Facebook. And they're being blamed for it.
[00:20:17.040 --> 00:20:21.840]   And so, you know, this bill, again, it's targeting the wrong thing. It's not targeting the actual
[00:20:21.840 --> 00:20:25.520]   problem. It's kind of like blaming the testing for the coronavirus.
[00:20:25.520 --> 00:20:32.320]   It doesn't sound fair at all. If the big tech companies are actually trying to say,
[00:20:32.320 --> 00:20:36.960]   Hey, these are bad actors or what have you. They're not necessarily
[00:20:37.520 --> 00:20:40.480]   harboring it on their platforms. They're just saying, Hey, we found something.
[00:20:40.480 --> 00:20:45.360]   They were trying to use us. They revealed how much there is. And that's right. Everybody.
[00:20:45.360 --> 00:20:50.480]   But I think that points to an underlying there's an underlying thing going on here that a lot of
[00:20:50.480 --> 00:20:57.040]   this is just theater that it is it's a convenient political weapon that can be wielded against big
[00:20:57.040 --> 00:21:02.400]   tech by the right primarily. You know, it's their fault. It's their fault. It's their fault.
[00:21:02.400 --> 00:21:08.320]   It's their fault. No, it's not just the right to it's it's the right Joe Biden is Joe Biden
[00:21:08.320 --> 00:21:13.040]   against to feel up to 30. Yeah, it's just driving me nuts. I know people who tried to get into
[00:21:13.040 --> 00:21:21.040]   the campaign and say, stop, stop. Yeah. It's yeah, this one, this issue is not just the right. It's
[00:21:21.040 --> 00:21:25.200]   in a ticket. You know, it's all a Democrat. Absolutely. Right. And there are other Democrats
[00:21:25.200 --> 00:21:31.600]   who are supporting it as well. And you know, the more you look, the deeper you look behind it,
[00:21:31.600 --> 00:21:36.560]   you realize like the lobbyists who are actually working for it are basically like the who's who
[00:21:36.560 --> 00:21:42.320]   of the big internet company enemies. So like there are Hollywood lobbyists who are pushing this
[00:21:42.320 --> 00:21:48.400]   bill very heavily. And so like the joke that somebody made and I forget who told it to me. So
[00:21:48.400 --> 00:21:55.040]   I should give credit for it and I won't. But like I was saying that like, you know, Hollywood
[00:21:55.040 --> 00:21:58.880]   might want to think twice, you know, especially as like more and more people from Hollywood are
[00:21:58.880 --> 00:22:07.200]   being accused of various not such good behavior and of promoting certain things like, you know,
[00:22:07.200 --> 00:22:12.320]   so someone said, you know, if if a Hollywood production has somebody who is, you know,
[00:22:12.320 --> 00:22:19.040]   credibly accused of, you know, being a predator of some kind, like maybe they should lose the
[00:22:19.040 --> 00:22:25.120]   copyright on those films because that's basically what the structure of the unit act was. And so
[00:22:26.320 --> 00:22:33.040]   or you have like some telco companies have been lobbying for this just as a way to kind of,
[00:22:33.040 --> 00:22:37.840]   you know, take a stick to the internet companies that they feel are taking their money. And then
[00:22:37.840 --> 00:22:43.600]   the other the other batch of lobbyists, which I find funny are sort of the old school tech companies,
[00:22:43.600 --> 00:22:49.680]   the ones who miss the boat being, you know, Oracle and IBM who have also been lobbying for
[00:22:49.680 --> 00:22:54.880]   for getting rid of 230 because they don't rely on 230 because they're business because they
[00:22:54.880 --> 00:23:00.240]   pick the wrong business model. There is genuine anti encryption sentiment and that's kind of
[00:23:00.240 --> 00:23:06.240]   come forth now Graham Blackburn and cotton have both have are sponsoring this so-called law so
[00:23:06.240 --> 00:23:12.240]   called. It's very clear lawful access to encrypted data act, which essentially
[00:23:12.240 --> 00:23:19.440]   insists that law law enforcement should have plain text of any encrypted data without saying
[00:23:19.440 --> 00:23:24.720]   exactly how it's to be done. I wonder if that's one of the reasons the earn it
[00:23:24.720 --> 00:23:27.760]   act lost his teeth. They don't need it anymore now that they've got the
[00:23:27.760 --> 00:23:34.480]   lawful access. There's been this weird discussion where some people are sort of making that claim.
[00:23:34.480 --> 00:23:39.120]   I think it is related to that. Like I think they put together this bill in part because they knew
[00:23:39.120 --> 00:23:44.640]   they had to do something to sort of claim that there was no encryption issue with the with the
[00:23:44.640 --> 00:23:48.880]   Earned Act. There is still a little bit of worry about how encryption could sneak back into the
[00:23:48.880 --> 00:23:57.760]   Earned Act. This the LAED bill probably has no chance of passing but the funniest the funniest
[00:23:57.760 --> 00:24:04.480]   thing I saw was I got a press release when that bill came out. I got a press release from this
[00:24:04.480 --> 00:24:12.080]   group and I'm blanking on their name but it's it's an advocacy group that's been around forever
[00:24:12.080 --> 00:24:17.440]   that advocates against porn just in general like they think porn is evil and they think it should
[00:24:17.440 --> 00:24:24.240]   all be completely blocked on the internet. And they sent out a thing praising this new bill
[00:24:24.240 --> 00:24:30.320]   because they said it proves that the Earned Act is not about encryption because this bill is
[00:24:30.320 --> 00:24:34.960]   about encryption and therefore we should pass both of them which doesn't make any sense.
[00:24:34.960 --> 00:24:43.520]   It is not consistent in any way shape or form but it's I mean there's just so much so much nonsense
[00:24:44.320 --> 00:24:48.480]   and I just feel like every two days or something somebody produces a bill that
[00:24:48.480 --> 00:24:54.480]   doesn't understand how technology or the internet works at all or why any of this stuff is important
[00:24:54.480 --> 00:25:00.080]   and it just seems somewhat performative to say like we're standing up to these big internet
[00:25:00.080 --> 00:25:04.720]   companies. And it's not purely performative it's you know we're four months away from election.
[00:25:04.720 --> 00:25:11.120]   Yes it's really if it's performance it's performance with the goal of impressing the voters if nothing
[00:25:11.120 --> 00:25:16.400]   else. So Mike I want to pass the election Graham. Yeah yeah yeah yeah yeah sir.
[00:25:16.400 --> 00:25:22.000]   I mentioned this in the show last week so I won't bore folks again Mike but I want to send
[00:25:22.000 --> 00:25:26.400]   you. I was part of a this will take two minutes. Transatlantic high level working group for
[00:25:26.400 --> 00:25:32.880]   content moderation and freedom of expression that's the end of it which which proposes a different
[00:25:32.880 --> 00:25:37.440]   more flexible framework for accountability and transparency instead of the kind of
[00:25:37.440 --> 00:25:40.480]   regulation we have in the heat speech laws and stuffs all sent it to you because I think you're
[00:25:40.480 --> 00:25:44.320]   planning interesting. Yeah I want to actually we're gonna take a break but I would love to talk a
[00:25:44.320 --> 00:25:52.640]   little bit because really all of these laws would impact American you know our American laws.
[00:25:52.640 --> 00:25:58.960]   But there is a global issue you know you've got on tech there Brazil has proposed a fake
[00:25:58.960 --> 00:26:04.160]   news law that says you know internet users are guilty until proven innocent this demands
[00:26:04.160 --> 00:26:10.320]   constant logging from ISPs. So there's a global issue for sure going in Europe just there was
[00:26:10.320 --> 00:26:14.720]   just a report out in Europe I think last week like you probably don't know what to do that said
[00:26:14.720 --> 00:26:20.640]   that basically was envious of China. Yeah that's a purposely saying how to do it don't they?
[00:26:20.640 --> 00:26:26.000]   China's doing it right. They know how to do it man. Not only they they clobber COVID but they
[00:26:26.000 --> 00:26:34.080]   know how to keep a lid on these big tech companies. Yeah I mean it was it was a report prepared for
[00:26:34.080 --> 00:26:38.480]   the European Parliament by an outside group so there are questions it wasn't necessarily the
[00:26:38.480 --> 00:26:43.520]   European Parliament endorsing it but it was a like hey that great firewall what an idea.
[00:26:43.520 --> 00:26:50.160]   I really wouldn't get a hooted off the continent is just frightening. Yeah let's take a little break
[00:26:50.160 --> 00:26:55.600]   it's so good to have you Mike Masnick from tech dirt dot com ant pruit from hands on photography
[00:26:55.600 --> 00:27:05.840]   Jeff Jarvis from the Craig Newmark etc and our show they brought to you by wasabi not the hot
[00:27:05.840 --> 00:27:11.680]   stuff you get with your sushi but it is hot stuff it's hot cloud storage the perfect solution for
[00:27:11.680 --> 00:27:22.080]   anyone who is generating terabytes of data weekly and is and going out buying more storage all the
[00:27:22.080 --> 00:27:29.920]   time wasabi is the is your is your savior it's it's better than on-prem storage it's more secure than
[00:27:29.920 --> 00:27:35.440]   on-prem storage and they have quite a bit of capacity they're they're ready and willing to help
[00:27:35.440 --> 00:27:42.800]   you with your capacity issues wasabi is 80% cheaper than Amazon's s3 it's significantly cheaper
[00:27:42.800 --> 00:27:48.960]   it's also significantly frankly cheaper than on-prem storage typically you could store data in the
[00:27:48.960 --> 00:27:54.400]   cloud wasabi for less than just the maintenance fees just the maintenance fees on the same amount
[00:27:54.400 --> 00:28:01.760]   of on-prem storage and you know people I think maybe the argument is yeah but if we don't control
[00:28:01.760 --> 00:28:06.960]   it it's you know it's out there in the cloud somewhere let me tell you it's safer in the cloud
[00:28:06.960 --> 00:28:16.480]   than it would be in your server closet 11 nines of durability that's one file every 649,000 years
[00:28:16.480 --> 00:28:21.920]   you're not even going to lose that because they do integrity checking every 90 days on every file
[00:28:21.920 --> 00:28:27.920]   on wasabi they're hosted in redundant premier tier four data center facilities highly secure
[00:28:27.920 --> 00:28:33.920]   you and the and the other thing is your data is secure by default encrypted always at rest
[00:28:33.920 --> 00:28:38.800]   even if you don't specify encryption they have access control mechanisms things like bucket
[00:28:38.800 --> 00:28:45.520]   policies and ACLs so you can grant permissions to people who have need access and prevent people
[00:28:45.520 --> 00:28:50.800]   who don't from getting something you can even I love this part designate data as immutable it
[00:28:50.800 --> 00:28:57.760]   cannot be changed it cannot be erased or altered protecting you not only from the ransomware
[00:28:57.760 --> 00:29:03.280]   guy waiting to jump but also from yourself from fumble fingered employees
[00:29:03.280 --> 00:29:09.920]   a HIPAA compliant FINRA compliant CJIS compliant this is the way you want to store the data and
[00:29:09.920 --> 00:29:17.040]   did I mention 80% cheaper than amazon s3 and up to six times faster plus you know things like
[00:29:17.040 --> 00:29:21.520]   they don't charge for egress you know I you know that it hits me every time you know I got
[00:29:21.520 --> 00:29:26.240]   transfer something awesome s3 and say well that'll that'll cost you there's no they don't have
[00:29:26.240 --> 00:29:32.320]   those complex storage tiers no API requests just a no charge for API requests oh yes by the way
[00:29:32.320 --> 00:29:36.720]   they support the s3 API so you already have tools that work with it it is really a great
[00:29:36.720 --> 00:29:40.880]   solution if you're a managed service provider and you're selling storage you can actually you'll
[00:29:40.880 --> 00:29:46.880]   love this you can earn more and charge less everybody is happy now there's two ways to pay
[00:29:46.880 --> 00:29:55.360]   there's pay as you go flat rate 599 a month for a terabyte or if you know you're going to be using
[00:29:55.360 --> 00:30:01.200]   a certain amount of data you can get the reserve capacity storage you buy cloud storage kind of
[00:30:01.200 --> 00:30:06.560]   like you buy on prem storage you say all right I'm going to purchase this amount of cloud storage
[00:30:06.560 --> 00:30:11.520]   in a one three or five year increment you get bigger discounts for both longer terms and
[00:30:11.520 --> 00:30:16.960]   greater capacity and you it's locked in you know how much it's going to cost that's another thing
[00:30:16.960 --> 00:30:21.600]   I'm trying to knock down all the pins all the reasons people say no no we have to have we have
[00:30:21.600 --> 00:30:26.960]   to buy another sand no we have to do no you don't you need wasabi it's just great you just pour your
[00:30:26.960 --> 00:30:32.640]   data up to the cloud boom you're done calculate the savings for yourself start a free trial of
[00:30:32.640 --> 00:30:38.320]   storage for a month see what it's like go to wasabi.com you know what try all your s3 tools on it see if
[00:30:38.320 --> 00:30:44.080]   it's faster we know it's less expensive click the free trial link at wasabi.com and use the offer
[00:30:44.080 --> 00:30:50.560]   code twit then join the movement migrate your data to the cloud with confidence W-A-S-A-B-I
[00:30:51.120 --> 00:30:58.720]   the offer code is TWIT I am a fan as you know I'm friends with the the founder David friend and
[00:30:58.720 --> 00:31:05.760]   I just this is a great service wasabi W-A-S-A-B-I.com offer code is twit
[00:31:05.760 --> 00:31:17.360]   back we go to our show this has been a big story from the past please mr j so micromanaging
[00:31:17.360 --> 00:31:25.520]   of it the the the protectionism that occurs in the industries that are threatened by this I'm just
[00:31:25.520 --> 00:31:31.440]   trying to find it right now so in my in my research on Gutenberg I have just reread the book media at
[00:31:31.440 --> 00:31:38.080]   war 1995 by Gwyneth Jack away it's an academic book it's about radio at war or newspapers at
[00:31:38.080 --> 00:31:43.440]   war with radio actually put it properly and and I remembered a couple things they did have you
[00:31:43.440 --> 00:31:50.240]   ever hear of the built more agreement this radio no so in 1933 when newspapers were fearing that
[00:31:50.240 --> 00:31:54.640]   that this radio thing was going to come in and they were going to have news on it and F that we
[00:31:54.640 --> 00:31:58.800]   don't want that that's they can't do it well they're they're all idiots and we are the only ones who
[00:31:58.800 --> 00:32:05.040]   have any hold on truth think about this is the first real competitor to the medium of print radio
[00:32:05.040 --> 00:32:11.440]   so they they went after them and they they had a meeting at the built more which they agreed that
[00:32:11.440 --> 00:32:17.760]   CBS and NBC would abandon news gathering they would be forced to pay for news coming from three
[00:32:17.760 --> 00:32:25.520]   wire services they they would not be allowed to put any advertisements on anything related to news
[00:32:25.520 --> 00:32:31.680]   they'd be limited to news boltons of five minutes and their commentators were prohibited from
[00:32:31.680 --> 00:32:39.760]   discussing news less than 12 hours old so this is what the newspaper industry attempted to do
[00:32:39.760 --> 00:32:45.440]   it lasted until 1938 but peered out because some newspapers owned radio stations and didn't like
[00:32:45.440 --> 00:32:49.200]   it and the wire services wanted to sell the radio stations and so they didn't like it so it went
[00:32:49.200 --> 00:32:54.400]   away the newspapers tried other tactics right they threatened to stop printing radio schedules
[00:32:54.400 --> 00:32:59.520]   you know like TV listings in their papers but the readers hated that so they said FU we want the
[00:32:59.520 --> 00:33:04.240]   radio schedules they had to do that they lobbied to have radio regulated but this is really cool
[00:33:04.240 --> 00:33:09.680]   they lobbied to have radio regulated by the federal government as indeed occurred and then
[00:33:09.680 --> 00:33:14.640]   they said that any companies that are regulated by the federal government should not be allowed to
[00:33:14.640 --> 00:33:21.680]   cover congress and shouldn't be allowed into the press gallery oh wow wonderful little yeah isn't
[00:33:21.680 --> 00:33:27.440]   that great they they blamed radio for taking advertising revenue from them but the depression
[00:33:27.440 --> 00:33:33.760]   is probably what killed more or newspapers and as Jack away said it was all cloaked in a self-important
[00:33:33.760 --> 00:33:38.400]   sacred rhetoric and we're the ones to give you the news we understand what's what
[00:33:38.400 --> 00:33:44.000]   they also feared that's the end familiar it's amazing it's all it's all exactly right
[00:33:44.000 --> 00:33:48.400]   they said that the radio through the magic inherent in the human voice i'm quoting here for a book
[00:33:48.400 --> 00:33:53.840]   called propaganda the news has means of appealing to the lower nerve centers on creating emotions
[00:33:53.840 --> 00:34:02.080]   and hearing mistakes for thoughts radio is just showbiz they said we're the voice in your head
[00:34:02.960 --> 00:34:07.520]   the sense of hearing does not satisfy the same intellectual craving as the sense of reading
[00:34:07.520 --> 00:34:20.480]   all right most folks are i-minded so they they uh yeah but it's exactly exactly parallel today
[00:34:20.480 --> 00:34:26.560]   right people radio is crap people are it's filled with crap people are too stupid to realize it
[00:34:26.560 --> 00:34:31.280]   they're going to be affected by it we have to clean it up we have to stop it from happening
[00:34:32.240 --> 00:34:37.840]   when was what year was that 1933 is when it started and it ran for quite some time
[00:34:37.840 --> 00:34:42.720]   because i mean if you think about it in a way that's exactly what Joseph Gebels did
[00:34:42.720 --> 00:34:47.680]   with radio in Nazi Germany i mean so so the argument the argument was that radio was going to be
[00:34:47.680 --> 00:34:55.440]   used but also i would think that that um but FDR also used it right FDR fireside one has a new deal
[00:34:55.440 --> 00:35:00.400]   and most newspapers of the time were republican and oppose the new deal so he said f them i'm
[00:35:00.400 --> 00:35:07.040]   gonna go around them and do fireside chats uh yeah right and so and it proved to be very
[00:35:07.040 --> 00:35:13.680]   tuned are we doomed to repeat this cycle forever yes on and on and on it happened again with
[00:35:13.680 --> 00:35:21.600]   television it happened again with uh telcos go the rbox going into news yep same exact thing
[00:35:21.600 --> 00:35:26.160]   happened and there's this i'm gonna read a quote if i may jack away the author from
[00:35:28.080 --> 00:35:33.760]   an actual academic unlike me um where the hell did i put it now
[00:35:33.760 --> 00:35:43.200]   I'm sorry i messed this up having been presented with a new technology contemporary actors voice
[00:35:43.200 --> 00:35:47.680]   their concerns about how the new medium will change their lives and in doing so reveal their
[00:35:47.680 --> 00:35:52.640]   vulnerabilities in their hopes of technological deliverance is reflected the ways in which the
[00:35:52.640 --> 00:35:57.760]   current lives fall short and their fears of technological danger can be heard what they hold
[00:35:57.760 --> 00:36:03.040]   sacred and are most afraid of losing listening to fears about the impact of new media is much
[00:36:03.040 --> 00:36:08.720]   like interpreting dreams that lovely these are the collective nightmares of people or an
[00:36:08.720 --> 00:36:15.200]   institution about the potential dangers of changing the familiar media ecology beautifully said and
[00:36:15.200 --> 00:36:22.160]   she wrote this book in 95 she wrote this but she had to have finished it before the web yeah for
[00:36:22.160 --> 00:36:27.920]   the internet to change any of that coming and what the parallels are just magnificent yeah history
[00:36:27.920 --> 00:36:34.960]   has a way of echoing yeah yes yeah always does it's kind of depressing actually i feel like yes
[00:36:34.960 --> 00:36:42.720]   we never just want to stay in our four walls yeah well i think it leads to the people who know
[00:36:42.720 --> 00:36:49.840]   the history to uh that's right into uh a habit of of screaming at people thank god jeff jarvis reads
[00:36:49.840 --> 00:36:58.320]   the old books so this was uh the week for cancel culture uh i could just go through all the people
[00:36:58.320 --> 00:37:04.880]   who have been banned or blocked or kicked from youtube and facebook and it's funny because this
[00:37:04.880 --> 00:37:10.880]   is the this is the back and forth the reaction and then the reaction and even parlor
[00:37:11.760 --> 00:37:19.840]   to start banning parlor had to start banning people with a regular parlor is the last passion
[00:37:19.840 --> 00:37:26.880]   of freedom of expression yeah no how could this happen yeah i actually created a parlor account i
[00:37:26.880 --> 00:37:32.800]   was mortified because when you first created a count it immediately tweets on your behalf whatever
[00:37:32.800 --> 00:37:39.920]   you call it it immediately says oh leo's i'm parlor everybody it's like oh shh so just a word
[00:37:39.920 --> 00:37:46.160]   warning when you first sign up sign up with a uh a deleted that post a second it's a name uh oh
[00:37:46.160 --> 00:37:51.280]   man how embarrassing and then apparently they're offering parlor which has been around for a
[00:37:51.280 --> 00:37:58.160]   couple of years it's a twitter you know clone basically a competitor uh and was discovered just
[00:37:58.160 --> 00:38:05.280]   recently uh by members of the republican party uh and the trump campaign um and has been you know
[00:38:05.280 --> 00:38:13.280]   touted as the a bastion of free speech safe from the cancel culture um and of course you're
[00:38:13.280 --> 00:38:19.440]   immediately offered when you join uh a ray of right wing news organizations like bright part
[00:38:19.440 --> 00:38:24.960]   bright part yeah that's the first thing so you you kind of know maybe they don't mind that so much
[00:38:24.960 --> 00:38:30.240]   although they're at great pains to say look look oh no no we have no political point of view we just
[00:38:30.240 --> 00:38:35.040]   we're just you know we're just here doing our job um they they did offer i think they first
[00:38:35.040 --> 00:38:41.040]   offer 20,000 then up to the 30,000 to uh to any liberal pundit who was willing to come on
[00:38:41.040 --> 00:38:47.520]   and be a target boy uh on the uh side i don't know if they've awarded that money or not but now
[00:38:47.520 --> 00:38:55.040]   they're off actually uh starting to uh starting to ban accounts already so yeah they uh uh but
[00:38:55.040 --> 00:38:59.760]   what's funny though is they they sort of keep changing the reasons why their banning accounts
[00:38:59.760 --> 00:39:05.680]   and then everybody's trying all the the fans and supporters of parlor are trying to justify it
[00:39:05.680 --> 00:39:10.000]   and and i keep trying to point out that like the reasons that they say it's okay for parlor
[00:39:10.000 --> 00:39:15.840]   do it are the same reasons why all these other companies twitter and reddit and youtube and twitch
[00:39:15.840 --> 00:39:20.560]   are are banning people they have rules people violate the rules and so then you get you get in
[00:39:20.560 --> 00:39:25.680]   trouble for it and that's the same exact reason that parlor is gaming and you know i just i find
[00:39:25.680 --> 00:39:31.280]   it hilarious that parlor claimed that that you know oh yeah we we're only the only content
[00:39:31.280 --> 00:39:37.680]   moderation we do is based on the FCC which doesn't apply to the internet uh and uh and the supreme
[00:39:37.680 --> 00:39:42.480]   court of the united states and their their communities are all i don't want when i see it
[00:39:42.480 --> 00:39:48.720]   right but the funniest thing is like if you read through their their entire community guidelines
[00:39:49.280 --> 00:39:57.200]   and i said this uh in my post like it feels like you know some 20 something tech guy went to like
[00:39:57.200 --> 00:40:02.480]   the wikipedia page for exceptions to the person on the bike i copied the headings and then just
[00:40:02.480 --> 00:40:08.080]   put in what they think it all means which has nothing to do with like the actual you know uh uh you
[00:40:08.080 --> 00:40:15.680]   know very clearly laid out limits to to the first amendment uh which you know involve lengthy trials
[00:40:15.680 --> 00:40:20.240]   and and careful analysis and yet parlor's just like you know no no we're going we're going to
[00:40:20.240 --> 00:40:26.160]   all those rules uh except if you uh have uh a username that we find offensive then we'll kick you off
[00:40:26.160 --> 00:40:33.040]   and it's like that's not that's not against the first amendment right you know it's these are hard
[00:40:33.040 --> 00:40:37.680]   these are really hard thorny issues although parlor did something right that maybe these other
[00:40:37.680 --> 00:40:44.880]   guys uh should do neil ipetel called it the reverse 230 clause where you're you're you're on the hook
[00:40:44.880 --> 00:40:51.040]   for parlor's legal expenses if they get sued and uh as you point out mike i bet Ted cruzle
[00:40:51.040 --> 00:40:58.160]   starts supporting section 230 once he realizes he's gonna be playing if parlor gets sued that's
[00:40:58.160 --> 00:41:02.960]   yeah i mean one of the points i made like a lot of people called out that the uh that indemnity clause
[00:41:02.960 --> 00:41:09.200]   you know the thing is like that indemnity clause is actually in a lot of different uh social media
[00:41:09.200 --> 00:41:14.320]   sites and or used to be i saw a few of them have pulled it i think twitter used to have it and
[00:41:14.320 --> 00:41:22.320]   pulled it i think twitch did the same um but um youtube still has a very similar uh indemnity clause
[00:41:22.320 --> 00:41:28.240]   but the thing is it never matters because of section 230 right the only reason that right coming to play
[00:41:28.240 --> 00:41:33.280]   is if you didn't have section 230 and the legal fees might actually you know be substantial and
[00:41:33.280 --> 00:41:38.080]   might actually matter and a platform might want to shift those over but it's funny because you know
[00:41:38.080 --> 00:41:42.880]   Ted cruzle has been one of the the most vocal opponents of section 230 and the one of the most
[00:41:42.880 --> 00:41:48.640]   vocal misrepresenters of 230 and yet and here he is now being like the most vocal supporter of parlor
[00:41:48.640 --> 00:41:54.400]   and i and i honestly think that you know if 231 away and he realized what legal liability he
[00:41:54.400 --> 00:41:59.600]   just put on himself he might rethink that stance if if that is he were intellectually honest well
[00:41:59.600 --> 00:42:04.720]   that's what i that what makes me wonder if all of this is not just grandstanding and you know
[00:42:04.720 --> 00:42:10.880]   this not it has no nobody's gonna do anything so is the season yeah uh white supremacist
[00:42:10.880 --> 00:42:20.000]   david duke and richard spencer band uh from youtube um let's see facebook uh i'm sorry reddit killed
[00:42:20.000 --> 00:42:26.240]   a number i think several uh thousand as i remember um about two thousand two thousand sub-readits
[00:42:26.240 --> 00:42:35.600]   including the donald and all was in that shop office uh the the whole david duke thing on youtube that
[00:42:35.600 --> 00:42:40.240]   that made me scratch my head a little bit now i'll be the first to tell you i never went to look up
[00:42:40.240 --> 00:42:45.040]   his youtube channel so i don't know what was on you know fan of the grand dragon is that what you're
[00:42:45.040 --> 00:42:51.280]   saying clearly but it made me wonder you know after seeing that uh like what content was being
[00:42:51.280 --> 00:42:57.280]   displayed and knowing that it's david duke how much content was it was it just two videos was
[00:42:57.280 --> 00:43:04.000]   it a hundred videos how long have they been there and if it's been more than a week what the hell
[00:43:04.000 --> 00:43:14.400]   took youtube so long well yeah i don't think there's any defense of keeping that necessarily up i think
[00:43:14.400 --> 00:43:20.640]   you know youtube stands for the longest time was that they you know they didn't want to be accused
[00:43:20.640 --> 00:43:27.680]   of bias right uh and this was this is the whole thing why so many different different sites have
[00:43:27.680 --> 00:43:33.680]   sort of tiptoed around this is because as soon as they uh enforce the rules in a way that that
[00:43:33.680 --> 00:43:40.400]   happens to impact a republican or or supporter of trump suddenly they're accused of bias even if
[00:43:40.400 --> 00:43:46.320]   they actually are treating other others equally um and so you know a lot of these platforms have
[00:43:46.320 --> 00:43:50.800]   really really tiptoed around these things and youtube was definitely one of them and they basically
[00:43:50.800 --> 00:43:55.840]   said well if it's not directly violating our policies then we're going to leave it even if
[00:43:55.840 --> 00:44:01.440]   even if it is you know horrible and awful and eventually they said you know okay we have to
[00:44:01.440 --> 00:44:06.800]   we have to adjust our policies even further so there's there's a big there's a big balance beam
[00:44:06.800 --> 00:44:12.000]   which is going to cause me greater pain yes right and is it going to cause me greater pain to
[00:44:12.000 --> 00:44:16.560]   piss off Donald trump or is it going to cause me greater pain to piss off black lives matter
[00:44:16.560 --> 00:44:24.000]   and the scale is shifted so now youtube acts i mean i would say it's go ahead a hypothetical
[00:44:24.000 --> 00:44:30.720]   would be uh david duke was was clever about the content that that he and his team produced where
[00:44:30.720 --> 00:44:37.120]   it didn't necessarily come off his hate speech is that the argument uh it no i don't think they
[00:44:37.120 --> 00:44:43.840]   feel any need to justify it well i think that it so that goes back to my first question what took so
[00:44:43.840 --> 00:44:48.960]   long right i i i think why i do think it is part of it that they they actually were somewhat careful
[00:44:48.960 --> 00:44:55.520]   and if you and not that i spent much time uh paying attention to to his youtube feed or or the related
[00:44:55.520 --> 00:45:02.640]   youtube feeds either but they actually do tip toe themselves a little bit um to try and present it in
[00:45:02.640 --> 00:45:08.640]   you know sort of a buttoned up light they're they're they're horrible viewpoints um but i i think
[00:45:08.640 --> 00:45:15.040]   you know it goes beyond that scale uh you know the scale suggests there's sort of like two sides
[00:45:15.040 --> 00:45:20.080]   to this and i think it's it it is a lot more complicated than that and that you know one of the things
[00:45:20.080 --> 00:45:24.640]   that i keep trying to point out to people is that every content moderation decision involves trade
[00:45:24.640 --> 00:45:30.320]   offs and it's not just one or the other it involves a whole long list of of trade offs and you go
[00:45:30.320 --> 00:45:34.640]   through the list of options that you have and every one of them is bad and that's a problem that i
[00:45:34.640 --> 00:45:38.480]   think people don't quite get they assume that there's like there's obvious answer that if we just do
[00:45:38.480 --> 00:45:43.360]   this we just get rid of this then then we've solved everything and yet the the real thing that happens
[00:45:43.360 --> 00:45:50.160]   is you know every one of these has some issue that you know we'll come back to buy you no matter what
[00:45:50.160 --> 00:45:56.080]   choice you make and it it's this you know the people who are doing this job it puts them in this
[00:45:56.080 --> 00:46:00.560]   impossible position where they're trying to balance so many different interests and no matter what
[00:46:00.560 --> 00:46:06.080]   choice they make is is not going to work in some ways going to cause some other problem and and i
[00:46:06.080 --> 00:46:10.320]   don't know you know frankly how how people can do that job when they know that every decision they
[00:46:10.320 --> 00:46:15.200]   make is is a bad one and they only have bad choices including doing nothing but that is one of the
[00:46:15.200 --> 00:46:21.840]   choices and so often like when you just have bad choices in front of you doing nothing is seems
[00:46:21.840 --> 00:46:28.720]   like the best choice so so i just got to tell it around mike you're hired tomorrow by a sucker
[00:46:28.720 --> 00:46:34.720]   and huge money oh don't fall for it mike he does this to us every week don't fall for it
[00:46:35.200 --> 00:46:41.040]   go ahead what what are you what do you what should facebook do what i mean just laid out
[00:46:41.040 --> 00:46:50.560]   the gordier knot that is facebook what do you what would you do uh well i i wrote a paper last year
[00:46:50.560 --> 00:46:57.840]   that lays out what i think these sites should do that they probably will not do but what i think
[00:46:57.840 --> 00:47:03.920]   they should do is effectively take themselves out of this business but enable everybody else to
[00:47:03.920 --> 00:47:10.240]   be in that business and and what i mean by that is that they should restructure things so that they
[00:47:10.240 --> 00:47:15.680]   are not a silo that controls everything where they have to make all the decisions but they
[00:47:15.680 --> 00:47:20.720]   effectively open up their platform so that anyone can build an implementation can build
[00:47:20.720 --> 00:47:27.440]   their own facebook or could build their own facebook filters and allow anyone to come in and make
[00:47:27.440 --> 00:47:32.000]   those decisions and then allow anyone to adjust those or to make their own decisions and sort of
[00:47:32.000 --> 00:47:37.440]   go back to what was the sort of promise of the early internet of you know pushing the power
[00:47:37.440 --> 00:47:44.960]   out to the ends of the network let it be in parlors bloom exactly but allow them allow them to
[00:47:44.960 --> 00:47:50.960]   communicate with each other federate and and it could be federated it could be there's all
[00:47:50.960 --> 00:47:56.000]   different ways that you could do it but you can put in place some ways of doing that where there
[00:47:56.000 --> 00:48:01.680]   are incentives for for better overall behavior and the the analogy that i use and it's not a
[00:48:01.680 --> 00:48:07.040]   perfect analogy and you can criticize it but the analogy that i use is email where email you know
[00:48:07.040 --> 00:48:13.840]   for the most part is based on these open protocols smtp or uh i map and and whatnot and anyone can
[00:48:13.840 --> 00:48:18.560]   build their own implementation of it anyone can put together an email server or you have companies
[00:48:18.560 --> 00:48:23.520]   that come in and offer it and obviously you have gmail being you know probably the biggest provider
[00:48:23.520 --> 00:48:30.400]   of email out there but google is actually incented not to be awful with with gmail because if you
[00:48:30.400 --> 00:48:34.800]   don't like what they're doing or you don't feel safe using their product it's very easy to switch
[00:48:34.800 --> 00:48:39.120]   to some other email provider and when you switch you don't lose access to everybody you can still
[00:48:39.120 --> 00:48:45.680]   communicate with your entire uh book you can export your your all of your email people can
[00:48:45.680 --> 00:48:50.320]   always reach you or you can set up things in different ways you can have a gmail address but
[00:48:50.320 --> 00:48:55.680]   use a different client or you can have a different email address that is not gmail and use gmail
[00:48:55.680 --> 00:49:00.240]   as your client like you can mix and match and and you can you know add in different filters and
[00:49:00.240 --> 00:49:04.080]   different tools and different people can build different things to go on top of it and you have
[00:49:04.080 --> 00:49:08.880]   this structure that allows for a lot more experimentation a lot more competition and a lot more incentive
[00:49:08.880 --> 00:49:14.720]   for good behavior while pushing the power out to the ends and not just relying on one central source
[00:49:14.720 --> 00:49:20.000]   to control everything and if you don't like it you're you're stuck what's the my i i said you just
[00:49:20.000 --> 00:49:24.000]   what's the business incentive to do that though basically you're getting you saying give up
[00:49:25.120 --> 00:49:30.400]   well i mean i think google's pretty happy with gmail and what they've gotten out of it might not
[00:49:30.400 --> 00:49:35.040]   have the same margins as other parts but this that protocol existed before google invented gmail
[00:49:35.040 --> 00:49:38.960]   sure so it's not like google invented email and then said hey why don't you all do it too
[00:49:38.960 --> 00:49:44.560]   and and so i think well i i think you're right like there is some something that has to give in that
[00:49:44.560 --> 00:49:49.280]   but part of my argument is that the cost of continuing to control everything gets higher and higher and
[00:49:49.280 --> 00:49:55.120]   we got to make the pain so high that they finally say well it's it's getting there and i also think
[00:49:55.120 --> 00:49:59.760]   that there are some potential interesting other business models uh and you know the one that gets
[00:49:59.760 --> 00:50:04.480]   the most attention and i'm not endorsing this because everybody gets mad at me if i if i well
[00:50:04.480 --> 00:50:10.400]   either way uh no one is gonna get mad at you here mike well maybe jesso watch it right watch it
[00:50:11.600 --> 00:50:19.680]   and well i will pre-roll my eyes and say there is the potential of of very uh with some of the
[00:50:19.680 --> 00:50:25.840]   like cryptocurrency possibilities to create business models around protocols that are different
[00:50:25.840 --> 00:50:31.600]   where the incentive is to have more people just using the protocol overall and not just sucking up
[00:50:31.600 --> 00:50:35.840]   everybody's data and making use of it and so i think there's some potential there i think there
[00:50:35.840 --> 00:50:40.400]   are a couple other business model ideas that could work as well and like the only way we find out is
[00:50:40.400 --> 00:50:46.480]   if we allow for that experimentation to happen isn't isn't uh at jack um before covid wasn't he
[00:50:46.480 --> 00:50:51.440]   toying with that with the with the no platform and building on top again right this yeah so he
[00:50:51.440 --> 00:50:55.600]   and and he he credited my paper which was a little bit scary nice yeah
[00:50:55.600 --> 00:51:03.440]   in in in helping him make that decision he read some other stuff too it's not it's not all my fault
[00:51:03.440 --> 00:51:09.440]   and i know that that i you know i know that that twitter folks are still exploring that and they've
[00:51:09.440 --> 00:51:12.800]   they've reached out to a bunch of people and i know that people are kind of working on like
[00:51:12.800 --> 00:51:18.560]   how would that look uh and though you know the one thing that i've the deeper you go into this and the
[00:51:18.560 --> 00:51:22.320]   more discussions you have is that again like everything else you start to go down different
[00:51:22.320 --> 00:51:27.120]   paths for like how how would this work and how how could this look and and no matter what path you
[00:51:27.120 --> 00:51:32.000]   go down you do run into challenges and you run into hurdles and it's not clear what will work and
[00:51:32.000 --> 00:51:36.960]   and if you go through the thought process of saying like well what if we we set this up sooner or later
[00:51:36.960 --> 00:51:41.120]   you're going to to come across the situation where you say well what happens when you know
[00:51:41.120 --> 00:51:48.480]   whatever the Nazis take over this part of of the world you know and and and it will create challenges
[00:51:48.480 --> 00:51:52.800]   and i know that like on the the content moderation question you know there are some people out there
[00:51:52.800 --> 00:51:57.680]   who say like oh you know they embrace my paper more than i do and they're like well this will solve
[00:51:57.680 --> 00:52:01.520]   all the content moderation problems and i'm saying no like no matter what you're still going to have
[00:52:01.520 --> 00:52:06.800]   content moderation questions but i think that this approach allows for more experimentation
[00:52:06.800 --> 00:52:11.280]   and somebody who's probably a lot smarter than i am will actually figure it out by not just
[00:52:11.280 --> 00:52:17.280]   limiting it to to you know a few giant companies within a 50 mile radius of where i'm sitting right
[00:52:17.280 --> 00:52:21.200]   now when this all started to come in so i'll start becoming a problem a couple of years ago
[00:52:21.200 --> 00:52:28.720]   Corey Doctorow told us uh this is where geeks have to step up and invent yes 20 new face books
[00:52:28.720 --> 00:52:34.240]   i don't see fate for any publicly held company saying hey you know what we got a new idea we're
[00:52:34.240 --> 00:52:39.040]   just going to give away our intellectual property and let everybody do it but i could see
[00:52:39.040 --> 00:52:44.400]   many people coming along and saying well we you know we need to make a better one i mean in a way
[00:52:44.400 --> 00:52:51.360]   isn't parlor a response to twitter and if they were and so is mastodon um yeah is that is that
[00:52:51.360 --> 00:52:55.360]   viable doing it that way i just don't see publicly held couples all they're doing is trying to copy
[00:52:55.360 --> 00:52:59.520]   what was rather than trying to invent something new i've been arguing that the that the internet so
[00:52:59.520 --> 00:53:04.000]   far is made for speaking no one's making it for listening that well this is giving away
[00:53:04.160 --> 00:53:07.680]   this would do that giving away the facebook platform or the twitter platform would not
[00:53:07.680 --> 00:53:12.480]   create something new it would just create more facebook yeah well we don't know right you don't
[00:53:12.480 --> 00:53:17.120]   know it has people yeah if you if you allow for the experimentation you might begin to see some
[00:53:17.120 --> 00:53:20.720]   some really interesting things the other thing that that you know Corey's argument is a little
[00:53:20.720 --> 00:53:26.000]   bit more nuanced than that even and i and i agree with Corey on this one i think that it is important
[00:53:26.000 --> 00:53:30.880]   his argument is not just that you want people to create 20 facebook's but you want them to to
[00:53:31.440 --> 00:53:37.200]   without needing facebook to say okay you want them to be able to go in and suck out facebook's data
[00:53:37.200 --> 00:53:42.960]   right and so he he's trying to force the same kind of thing that i'm doing but doing it without
[00:53:42.960 --> 00:53:47.760]   the permission of of those large because there could be a legal framework to do that you could see
[00:53:47.760 --> 00:53:52.720]   yes you could see that be kind of almost an eminent domain a government saying all right that's our
[00:53:52.720 --> 00:53:58.240]   data you got to let it free right but right now the law is actually the opposite and this is partly
[00:53:58.240 --> 00:54:05.760]   like facebook's doing right i mean they have filed yeah i mean they they filed these the big case that
[00:54:05.760 --> 00:54:10.640]   they did was against this this company called power.com that tried to build like a unified
[00:54:10.640 --> 00:54:15.440]   interface for all the different social media right companies is about a decade ago and so
[00:54:15.440 --> 00:54:23.440]   you could give power your login so it was authorized but facebook said that that was unauthorized access
[00:54:23.440 --> 00:54:28.880]   and it violated the computer fraud and abuse act which is you know. It's supposed to be about
[00:54:28.880 --> 00:54:33.440]   hacking and yet the courts bought that argument and the court said yeah that's right so because of
[00:54:33.440 --> 00:54:39.840]   that facebook is able to block access to to their service and so that makes it much harder to build
[00:54:39.840 --> 00:54:46.240]   that what what Corey refers to is adversarial interoperability which i love i i also think is
[00:54:46.240 --> 00:54:52.560]   really important it's a great phrase Dan go ahead i'm sorry and i interrupted you did you no no he said
[00:54:52.560 --> 00:54:56.480]   i'm muted myself sorry but no i was just saying that's pretty much what we were saying last week
[00:54:56.480 --> 00:55:03.280]   about these extra spin-offs if you will of different options for these social media platforms that's
[00:55:03.280 --> 00:55:08.640]   pretty much the same thing yeah well i'd love to see it i don't see it happening but it'd be nice
[00:55:08.640 --> 00:55:16.560]   where's your paper published mic it was through the night institute at columbia so and the the
[00:55:16.560 --> 00:55:21.840]   it's called protocols not platforms if you do a search on protocols not platforms yeah it should
[00:55:21.840 --> 00:55:29.040]   be the top result and it's it's at the night institute at columbia it's very sensible sweet
[00:55:29.040 --> 00:55:34.000]   what's your background like how did you start uh how did you get to be so smart yeah
[00:55:34.000 --> 00:55:39.840]   it's the first guy i've ever met who's as smart as Corey dr oaken explain Corey to me so i
[00:55:39.840 --> 00:55:48.880]   i'm very grateful yeah my background is not that interesting i i i have a degree of all things in
[00:55:48.880 --> 00:55:54.960]   industrial and labor relations nice uh and so if you want to know about labor disputes in the
[00:55:54.960 --> 00:56:00.320]   early history of unions i'm your man it shows you a high threshold for boring topics so that's
[00:56:00.320 --> 00:56:05.920]   very useful i think it's an unsolvable one yeah insoluble problems that's exactly right yeah
[00:56:05.920 --> 00:56:11.360]   but yeah but i just you know i have always had a real fascination with sort of technology and
[00:56:11.360 --> 00:56:18.640]   innovation and you know subscribe to wired from day one uh and and was sort of deep in in that
[00:56:18.640 --> 00:56:26.160]   world and um and i went to to business school um to get our you know one of those horrific mba things
[00:56:26.160 --> 00:56:33.040]   um with the intention of you know going to work in silicon valley and and working for an you know
[00:56:33.040 --> 00:56:39.840]   innovative company a startup and i i left business school and i went to one large company for a
[00:56:39.840 --> 00:56:47.440]   little while which was intel and saw how that worked or didn't work uh and then went to a startup
[00:56:47.440 --> 00:56:55.200]   in the 90s and saw how that didn't work uh and decided i was having a lot more fun commenting and
[00:56:55.200 --> 00:57:01.440]   thinking through the issues rather than actually having to to implement them at scale or dealing
[00:57:01.440 --> 00:57:06.960]   with venture capitalists and and all of that kind of fun stuff and then you know now has spent 20
[00:57:06.960 --> 00:57:11.840]   some odd years just uh talking about this that's really amazing how many people are texture is
[00:57:11.840 --> 00:57:20.160]   tech dirt uh it also depends on how you count as with so many things uh but we're we're four full-time
[00:57:20.160 --> 00:57:25.200]   people and then we have some freelancers and contractors so we're between four and eight depending on
[00:57:25.200 --> 00:57:31.120]   how you count and tech dirt is ad supported but there's a patreon page as well you sell gear and
[00:57:31.120 --> 00:57:38.480]   so forth tech dirt uh dot com there's all sorts of ways it's not called gear it's called merch
[00:57:38.480 --> 00:57:47.520]   merch come on i'm sorry i'm not good at this as you know i'm not good at this um nice and he's
[00:57:47.520 --> 00:57:53.840]   even got a game a card game yeah yeah yeah i don't get the card game collective all this is that was
[00:57:53.840 --> 00:57:58.240]   that was uh we we've been doing this is a bizarre thing that we've sort of come across recently which
[00:57:58.240 --> 00:58:02.560]   is um we've been making games we're actually working on this has not been released yet but
[00:58:02.560 --> 00:58:08.400]   since it's relevant to the topic we've been working on a game that will uh turn the players into a
[00:58:08.400 --> 00:58:16.640]   trust and safety team for a fictional uh uh social media network and and force people to make these
[00:58:16.640 --> 00:58:23.280]   decisions and uh and as i said uh then later regret whatever decision they make so we we had
[00:58:23.280 --> 00:58:27.840]   hope to have that out a few months ago and then you know the world kind of blew up so there was
[00:58:27.840 --> 00:58:34.400]   no twitter strings with mike and jeff kossen and me and there was we should make 230 the Broadway
[00:58:34.400 --> 00:58:41.840]   musical or something and i said uh the board game and mike said oh working on it on it and as nix on
[00:58:41.840 --> 00:58:48.560]   it yep so we should have that but the the game that is on there is uh it's actually the cia internally
[00:58:48.560 --> 00:58:54.000]   used board games for training and they perhaps stupidly admitted that at south by south west
[00:58:54.000 --> 00:59:00.080]   and so uh someone filed a foyer freedom of information act request oh so you're not joking
[00:59:00.080 --> 00:59:06.880]   when you say this this has been declassified you're not joking a legitimate honest-to-goodness uh
[00:59:06.880 --> 00:59:13.120]   oh my god declassified all the cia training game and they released it and and i know copyright law
[00:59:13.120 --> 00:59:18.080]   well enough to say if is a product created by the federal government yeah it's it's in the public
[00:59:18.080 --> 00:59:23.440]   domain we can take it it was heavily redacted uh the design was not great so we had to update the
[00:59:23.440 --> 00:59:28.480]   design and fill in a lot of the blanks of of the secret stuff the cia doesn't want us to know
[00:59:28.480 --> 00:59:36.240]   and and we turned into a game and we put it on kickstarter and it's it's actually you know i would say i
[00:59:36.240 --> 00:59:40.880]   will i will admit it is not the greatest game in the world i think there are better games out there
[00:59:40.880 --> 00:59:49.520]   the cia is perhaps not the best game development it it is a fun game it's the most accurate game in
[00:59:49.520 --> 00:59:56.080]   the world it may that if you're looking for simulations of global global uh this is great and here's your
[00:59:56.080 --> 01:00:01.760]   choice here's your chance to get it for 25 off oh god i i think we met that code may not we should
[01:00:01.760 --> 01:00:07.440]   have taken that down i think the code ended so uh we're still i first now uh uh next day who's trying
[01:00:07.440 --> 01:00:12.800]   to get the fun say who knew we would still be saying it's staying inside here we are july first
[01:00:12.800 --> 01:00:18.880]   who to thunk it what a great idea i think that's hysterical i love that it's a fun game i mean i
[01:00:18.880 --> 01:00:22.880]   actually do still play it i play with my kids believe it or risk a little bit or i mean it's
[01:00:22.880 --> 01:00:28.160]   strategic no it's uh it's less strategic than it should be i'll tell you like when we started
[01:00:28.160 --> 01:00:31.920]   putting it together we you know we put up on kickstarter and we got all these backers and we said you
[01:00:31.920 --> 01:00:36.960]   know hey look we want to and we're working with like an actual game developer who's developed a
[01:00:36.960 --> 01:00:41.360]   whole bunch of board games we said look we can make this game better and a little bit more like a
[01:00:41.360 --> 01:00:47.280]   a board game you would really like and people like no we want the original cia version you know
[01:00:47.280 --> 01:00:52.640]   that's the one they had we wanted as true to to that as possible and so it's it's a training game
[01:00:52.640 --> 01:00:57.440]   like it's it's really designed to teach you about like all the different ways that the cia can spy
[01:00:57.440 --> 01:01:05.840]   on you uh and and so it is it is educational but it is it is fun you're sort of it's a it's a there's
[01:01:05.840 --> 01:01:09.760]   there is strategy to it you're basically trying to solve different world crises
[01:01:09.760 --> 01:01:13.760]   with different techniques to get information and at the same time you're trying to put
[01:01:13.760 --> 01:01:21.120]   uh you know hurdles in front of all of the other players wow so there's there's legitimately a
[01:01:21.120 --> 01:01:26.160]   card called red tape like you can put red tape onto another player and slip them down
[01:01:26.160 --> 01:01:35.600]   i want red tape that's hysterical now is is red tape classified as political military
[01:01:35.600 --> 01:01:43.920]   economic or a weapon i honestly don't remember oh that's hysterical that's really it's like it's
[01:01:43.920 --> 01:01:50.720]   fun yet depressing all the same at the same time precisely uh mike mazniks here so is aunt
[01:01:50.720 --> 01:01:56.960]   pruit jeff javis uh mike you you know you noticed we haven't mentioned google really yet the show
[01:01:56.960 --> 01:02:02.080]   is called this week in google so we do we pay lip service to the title by doing something we call
[01:02:02.080 --> 01:02:07.920]   the google changelog that's coming up uh next what's new at google but first a word from our
[01:02:07.920 --> 01:02:13.600]   sponsor you may have noticed we're here in the last pass studios that's because we're big fans
[01:02:13.600 --> 01:02:20.080]   been using last pass i have personally for more than a decade uh joe seagris joined us actually
[01:02:20.080 --> 01:02:24.880]   went and talked to uh steve gibson of our security now show steve got to see all the source code
[01:02:24.880 --> 01:02:30.320]   helped joe helped him understand everything last pass was doing and steve gave it his absolute
[01:02:30.320 --> 01:02:36.000]   seal of approval he started using it uh and then we started using it uh in our business too because
[01:02:36.000 --> 01:02:42.560]   after all you can have you know the best uh operational security in the world but if your
[01:02:42.560 --> 01:02:48.160]   employees don't they're the weakest link so especially now as employees are going home and
[01:02:48.160 --> 01:02:52.640]   they've got the keys to the kingdom they've got passwords to your bank accounts your databases
[01:02:52.640 --> 01:02:57.840]   your customer records everything you need to keep that stuff safe and secure using last pass
[01:02:57.840 --> 01:03:05.040]   and business has really made a difference your IT department has a big job i mean not only are
[01:03:05.040 --> 01:03:12.160]   people going home but you've got more appliances more devices more applications new threats and
[01:03:12.160 --> 01:03:17.920]   new regulations strong security is not easy fortunately last pass is here to help your IT
[01:03:17.920 --> 01:03:24.560]   department with strong security that's easy to use and easy to manage last pass lets you secure
[01:03:24.560 --> 01:03:31.200]   every entry point from shadow IT to apps to mobile and cloud services their access solutions
[01:03:31.200 --> 01:03:36.720]   give you visibility and control over every access point to your organization and really that is
[01:03:36.720 --> 01:03:43.040]   what you're going for here of course it starts with you with authentication and that's really
[01:03:43.040 --> 01:03:48.000]   where last pass sings and it's more than just password management employees can access a variety
[01:03:48.000 --> 01:03:55.760]   of applications and devices they can use single sign-on of course passwords with auto fill they
[01:03:55.760 --> 01:03:59.840]   also do authentication better than anybody else not only they take advantage of the biometric
[01:03:59.840 --> 01:04:05.520]   authentication and modern smartphones but they also do contextual authentication things like
[01:04:05.520 --> 01:04:11.440]   geolocation and ip address and and last pass identity will give you a simple and integrative
[01:04:11.440 --> 01:04:18.160]   view across all access and authentication tests so you know who's accessing what when and where
[01:04:18.160 --> 01:04:22.480]   and the best part about last pass the thing that's really kind of impressive to me usually we think
[01:04:22.480 --> 01:04:30.320]   of the trade-off between security and convenience last pass can increase your security but will not
[01:04:30.320 --> 01:04:36.480]   impact productivity in fact employees our employees love last pass they they use it because it makes
[01:04:36.480 --> 01:04:42.480]   it easier for them and auto fills passwords the single sign-on is so great it's better than passwords
[01:04:42.480 --> 01:04:46.880]   and more convenient they don't need to understand you know what's going on
[01:04:46.880 --> 01:04:53.600]   from our it point of view all they know is it's easier to do what they need to get done even sharing
[01:04:53.600 --> 01:04:59.840]   passwords which is tough now that we're all working at home last pass makes securely security
[01:04:59.840 --> 01:05:08.400]   effortless remember your passwords are entryways into your business spreadsheets sticky notes
[01:05:08.400 --> 01:05:13.840]   or as one of our engineers did public websites with your passwords those are not secure last
[01:05:13.840 --> 01:05:20.400]   pass is password management secures it all so you don't have to of course strong encryption last pass
[01:05:20.400 --> 01:05:27.680]   works on every device you have uh the vault is never decrypted anywhere but on device your password
[01:05:27.680 --> 01:05:32.880]   is never transmitted to last pass these are all the things you care about and last pass does it all
[01:05:32.880 --> 01:05:38.080]   right secure your business give your IT department the tools to keep your business safe is at last
[01:05:38.080 --> 01:05:42.800]   pass dot com slash to it to find out how they can help you and your business stay productive and
[01:05:42.800 --> 01:05:50.800]   secure no matter where your employees are and many of them are home as as as as ant is last pass
[01:05:50.800 --> 01:05:56.560]   dot com slash to it we thank them so much uh for keeping the lights on here at the studio so we
[01:05:56.560 --> 01:06:01.440]   appreciate it thank you last pass last pass dot com slash to it somebody the chatroom rocky
[01:06:01.440 --> 01:06:09.920]   horror saying we should rename twig to this week in leo's gang this week in in gang less no uh
[01:06:09.920 --> 01:06:14.400]   this is freaking whatever but you know google kind of says it all right because it's you know
[01:06:14.400 --> 01:06:19.200]   it's about the google verse it's about the world that we're all living in what do you think about
[01:06:19.200 --> 01:06:26.000]   the uh the facebook boycotts uh certainly it's something to pay attention to but i've seen many
[01:06:26.000 --> 01:06:30.320]   people say you know what facebook makes most of its money on the long tail of small advertisers
[01:06:30.320 --> 01:06:36.720]   they don't care you know the top 100 brands are only six percent of total facebook advertising
[01:06:36.720 --> 01:06:40.640]   mark's taking it seriously he's meeting with the groups behind the boycott
[01:06:40.640 --> 01:06:47.360]   they are you seem to be even changing um some of the things they do on facebook but this ad boy
[01:06:47.360 --> 01:06:53.440]   cut jeff this this isn't really something mark's worried about is it um i think there's a larger
[01:06:53.440 --> 01:07:00.240]   brand damage and you know the problem i have and full disclosure is i raise money from my school
[01:07:00.240 --> 01:07:04.640]   from facebook i receive nothing personally from any of the platforms end of disclosure um is
[01:07:04.640 --> 01:07:09.040]   that facebook is constantly trying to catch up with them with moral questions and that's just
[01:07:09.040 --> 01:07:12.720]   not good he's got to get it i keep on saying you know they've got to have a north star they've got
[01:07:12.720 --> 01:07:18.480]   to have a strong view of what they do and do not want on facebook what it stands for and why it
[01:07:18.480 --> 01:07:22.480]   exists but instead it's just always somebody's after them and then they'll oh okay if i do this
[01:07:22.480 --> 01:07:27.360]   will you stop yelling at me yeah it's more reaction it's more reaction it is more than
[01:07:27.360 --> 01:07:32.960]   the name of anything else move faster break things it always has been right that's their motto yep
[01:07:32.960 --> 01:07:38.800]   like what do you think yeah i mean i i think it's interesting i think it will have some impact and
[01:07:38.800 --> 01:07:44.640]   i think that that they at least realize that like it's it's it's really bad pr right now to have all
[01:07:44.640 --> 01:07:49.440]   these giant companies basically saying that they were pulling out you know the the point that i
[01:07:49.440 --> 01:07:53.440]   that struck me is interesting is that you know going back to the argument about section 230
[01:07:53.440 --> 01:07:59.520]   one of the points that a lot of people a lot of critics raise about 230 is that because the law
[01:07:59.520 --> 01:08:05.680]   you know gives you know blanket immunity to the to the platforms for not moderating that they
[01:08:05.680 --> 01:08:10.720]   have no incentive to moderate and i think that this is a really good example that that's not true
[01:08:10.720 --> 01:08:15.520]   that there are other ways to have incentive it's not just the law you know if users are getting
[01:08:15.520 --> 01:08:21.760]   upset that's incentive if your advertisers are getting upset that's incentive if the the media
[01:08:21.760 --> 01:08:26.160]   is turning against you it hasn't very much has in facebook's case that's incentive and so i think
[01:08:26.160 --> 01:08:31.920]   this is another example of like the nature of 230 which allows for these changes to be made without
[01:08:31.920 --> 01:08:36.560]   having to go to a giant commission at the government and say like is this an okay best practice
[01:08:36.560 --> 01:08:43.440]   is that it it allows for the platforms to change and experiment and so i think that this is a good
[01:08:43.440 --> 01:08:50.000]   example of ways that different parties can you know apply pressure to facebook whether or not
[01:08:50.000 --> 01:08:55.920]   this one works the fact that these kinds of things are out there is is i think a good sign and so
[01:08:55.920 --> 01:08:59.440]   it'll be interesting to see what happens it'll be interesting to see how much facebook actually
[01:08:59.440 --> 01:09:05.040]   does change follow question like what do you think of the specific demands of the group
[01:09:08.000 --> 01:09:15.120]   you know i'm less impressed by them i feel that they're a little bit um that they don't necessarily
[01:09:15.120 --> 01:09:20.480]   take into account the reality of of the the difficult to impossible choices that facebook is
[01:09:20.480 --> 01:09:25.760]   trying to make in all these situations so you know i think they're a little bit unrealistic
[01:09:25.760 --> 01:09:31.840]   and i also think you know as a side note a bunch of the companies i think that have pulled ads were
[01:09:31.840 --> 01:09:37.680]   probably uh struggling in general because of the the pandemic that we're living through and we're
[01:09:37.680 --> 01:09:42.240]   probably looking to decrease advertising and realize that this is a way to decrease advertising but
[01:09:42.240 --> 01:09:48.960]   get good media attention well not only that but but you leave her uh some other point as both
[01:09:48.960 --> 01:09:51.920]   twitter and facebook to the end of the year what they're really doing is they don't want to be near
[01:09:51.920 --> 01:09:55.600]   any controversy they don't they hate being near news they don't want to be near politics right
[01:09:55.600 --> 01:09:59.840]   this they they just basically said until the elections over we're not gonna be near any human
[01:09:59.840 --> 01:10:05.600]   beings right and and we get good press coverage for it in the meantime which sort of makes up for the
[01:10:05.600 --> 01:10:11.840]   loss of advertising um timing yeah yes you can see that marketing guy coming and say hey it's win win
[01:10:11.840 --> 01:10:18.960]   yeah um but you know it's it's interesting i mean it's interesting to see how these changes
[01:10:18.960 --> 01:10:24.160]   go take take place and sort of you know the the different campaigns and and public pressure
[01:10:24.160 --> 01:10:29.520]   is actually a pretty effective tool uh you know even when i don't agree with the the overall aims
[01:10:29.920 --> 01:10:36.080]   um you know it's fascinating to see it in practice they uh NAACP the anti-deformation league
[01:10:36.080 --> 01:10:42.560]   color of change have all uh arranged to meet with Cheryl Schalz-Sandberg and Chris Cox the
[01:10:42.560 --> 01:10:49.520]   returned by the way wow the returned product officer at facebook christ-cocks yeah he left like
[01:10:49.520 --> 01:10:56.400]   in a huff a year ago and i you know i like it here after i'll never mind uh and they want
[01:10:56.400 --> 01:11:02.240]   Zuckerberg to be there um facebook says uh yep mark's gonna join so he's gonna meet with them
[01:11:02.240 --> 01:11:07.040]   i think that's the least he can do is is at least listen to their concerns
[01:11:07.040 --> 01:11:13.120]   what are their concerns this is in person or or um unbiracial i'm sure it's virtual
[01:11:13.120 --> 01:11:19.440]   what i hope it's virtual yeah i mean they're not gonna all get together in a room no
[01:11:20.800 --> 01:11:29.120]   no uh so what do they want what what what would well i mean i know what they're saying but
[01:11:29.120 --> 01:11:31.440]   but what would they really like facebook to do
[01:11:31.440 --> 01:11:40.480]   to do well i think you know this is this is the issue with like all of these questions around
[01:11:40.480 --> 01:11:45.680]   trust and safety and content moderation they want uh less of the bad stuff and more of the good stuff
[01:11:45.680 --> 01:11:51.120]   whatever if yeah if you ask them to define those things it's a well you should know it when you see
[01:11:51.120 --> 01:11:57.520]   all means of being good stuff yeah yeah yeah so the ADL is part of the clearest the ADL says
[01:11:57.520 --> 01:12:02.000]   get rid of hate okay the ADL has a definition of hate usually for doesn't have an addition
[01:12:02.000 --> 01:12:07.360]   a definition of hate right and when when that which is defined as hate turns out to be the
[01:12:07.360 --> 01:12:11.440]   president of the United States and his party well now let's get in as mike was saying that's
[01:12:11.440 --> 01:12:16.320]   gets to be pretty uncomfortable who would have thought i would have a headline here that says
[01:12:16.320 --> 01:12:24.480]   twitch bans the president of the united states temporary that's like the world turned upside down
[01:12:24.480 --> 01:12:30.480]   right uh you know and and i think the president was probably celebrating that moment too just just
[01:12:30.480 --> 01:12:36.320]   for a few minutes proves this point you know what i mean another headline boom yeah um yeah and that
[01:12:36.320 --> 01:12:39.920]   was the first thing everybody's asked me is well what's what's president trump doing on twitch what
[01:12:39.920 --> 01:12:44.960]   is he playing a game what is it maybe he's playing that cia game i don't know but no i think president
[01:12:44.960 --> 01:12:53.280]   i think that uh yeah pewdiepie i think honestly uh and this is hard to say i think it's kind of
[01:12:53.280 --> 01:12:58.800]   shameful i mean the president of the united states needs a has i think has the right to reach out to
[01:12:58.800 --> 01:13:04.320]   the american people and it's just like i think it's shameful when the networks refuse uh any president
[01:13:04.320 --> 01:13:09.600]   uh time to speak but it's these days that was a my day that's the old days when the president said
[01:13:09.600 --> 01:13:15.200]   i'm gonna get nbc cbs and abc on the phone i have something to say tonight uh it's the same thing
[01:13:15.200 --> 01:13:20.640]   only it's now a much broader doesn't doesn't the president have a right to that bully pulpit that's
[01:13:20.640 --> 01:13:26.080]   that's part of the job that's why we elect him it doesn't make sense it's if it's someone that
[01:13:26.080 --> 01:13:33.200]   we the people elected you know what is you know it should have this last yeah whether we're
[01:13:33.200 --> 01:13:39.680]   suffering issue all right right sorry it's their right to understand it's their right to yeah
[01:13:39.680 --> 01:13:45.200]   certainly right the president has a right to speak but that doesn't mean that a private company has
[01:13:45.200 --> 01:13:52.160]   to understand to carry their speech right i mean uh you know there there are appropriate things for
[01:13:52.160 --> 01:13:56.720]   for different platforms or different vehicles to carry in the same way that you wouldn't expect like
[01:13:56.720 --> 01:14:02.880]   you know espn to to carry the president's speech because it's not the right audience
[01:14:02.880 --> 01:14:08.640]   or nickelodeon or whatever um you know if they decide that it's not right or not appropriate for
[01:14:08.640 --> 01:14:13.920]   their vehicle then they they should you know that's freedom of association as well absolutely and
[01:14:13.920 --> 01:14:17.680]   it's it's not like you know if the president wants to say something it's not like he doesn't have
[01:14:17.680 --> 01:14:23.760]   ways to get that message out even if the various internet platforms say not through us i i do and
[01:14:23.760 --> 01:14:27.200]   i understand that i'm not saying there should be is that there ought to be a law that clearly is a law
[01:14:27.200 --> 01:14:31.680]   it's called the first amendment you don't have to yeah but uh devil's advocate but well i'm not even
[01:14:31.680 --> 01:14:34.640]   playing devil's advocate i do feel like um
[01:14:34.640 --> 01:14:42.720]   if this is part of the pain you know all of this there's all these different levers that
[01:14:42.720 --> 01:14:49.200]   different groups are pulling to create pain for these uh social uh platforms to push them in a
[01:14:49.200 --> 01:14:58.160]   direction that people want but i think ultimately it bothers me if the elected leader of our country
[01:14:59.520 --> 01:15:05.840]   is not allowed to use these platforms to speak what what do they have to do with country
[01:15:05.840 --> 01:15:11.760]   what do they like to lead to your country is balsanaro right i'm sorry mr good wouldn't please god wouldn't
[01:15:11.760 --> 01:15:18.560]   please us but balsanaro was elected right i mean yeah but well or or or i'm sorry i'm gonna go there
[01:15:18.560 --> 01:15:25.760]   if it's hitler right hitler was not hitler was not you know he was not fully elected so that's all right
[01:15:25.840 --> 01:15:29.840]   well he was the she was the legal head yeah he was the legal head made himself
[01:15:29.840 --> 01:15:36.320]   more sorry sorry godwin please give me a break i think mike um mike is suspended godwin's law for
[01:15:36.320 --> 01:15:40.320]   the last i think so i think a couple of more so no there is it there has to be a limit leo
[01:15:40.320 --> 01:15:45.520]   there has to be a limit where you say we're not going to um then but yeah yeah i argued that facebook
[01:15:45.520 --> 01:15:52.400]   should leave it up but should say much a model behavior of disapproving of the essence of it and
[01:15:52.400 --> 01:15:57.680]   safe this is here here's why it's here but by it being here we are not endorsing this i you know and
[01:15:57.680 --> 01:16:04.000]   by the way i as you i think everybody knows i'm no friend of the president but um and i understand
[01:16:04.000 --> 01:16:11.520]   that twitch should not let uh richard spencer or david duke have a stream but uh by the virtue of his
[01:16:11.520 --> 01:16:17.360]   office he is in a different category sure and and i think that's true and i think that's it's actually
[01:16:17.360 --> 01:16:22.320]   why what twitter did you know a month ago was so interesting after going back and forth where a
[01:16:22.320 --> 01:16:28.480]   lot of people were asking them to take down that that account they decided to just add more content
[01:16:28.480 --> 01:16:33.520]   to it and and put more context to it and saying things like this this does violate our policy
[01:16:33.520 --> 01:16:38.320]   that seems like a fair response yeah and and and facebook last week announced that they're
[01:16:38.320 --> 01:16:41.920]   going to start doing the same thing after originally saying that they wouldn't do that that's right
[01:16:41.920 --> 01:16:46.240]   they're they're now saying that they'll do it and and to me that is that is a pro free speech it's
[01:16:46.240 --> 01:16:52.160]   adding more speech right and not removing it and recognizing that the president by the nature of
[01:16:52.160 --> 01:16:57.760]   being the president um you know is in a unique position and therefore has unique rules and some
[01:16:57.760 --> 01:17:01.680]   people get upset about that and say well you know everybody should be treated exactly the same
[01:17:01.680 --> 01:17:06.960]   but but the president is not the same as everybody else yeah um
[01:17:06.960 --> 01:17:15.200]   what else jeff what what what's next what do we tell oh we haven't even talked about anything and
[01:17:15.200 --> 01:17:20.160]   you know i'll tell you one thing i really loving so apple changed how ios 14 works with privacy in
[01:17:20.160 --> 01:17:26.160]   a very aggressive way um you know they're they're surfacing all sorts of stuff like the apple id
[01:17:26.160 --> 01:17:31.440]   for advertising which you can now like when you first install an app say yeah don't do that
[01:17:31.440 --> 01:17:37.920]   which advertisers are terrified about um they also are showing all sorts of privacy violations
[01:17:37.920 --> 01:17:43.440]   tick-tock the first to bit but now that there's 56 different apps that spy on your clipboard
[01:17:43.440 --> 01:17:50.160]   even when you're not running the app and apple's new notifications are letting people know about that
[01:17:50.160 --> 01:17:57.360]   um apple's turning out to be i think it's kind of interesting just by a slight change to ios which
[01:17:57.360 --> 01:18:04.240]   is widely used of course in the us they turn out to be narcing on a lot of these uh things and i
[01:18:04.240 --> 01:18:11.600]   have to say at this point i would not be using tick-tock anymore the country of india has banned yeah
[01:18:12.160 --> 01:18:18.160]   tick-tock and 59 other apps well that's for another reason well they're quote chinese apps
[01:18:18.160 --> 01:18:24.560]   uh and that's because of border tensions uh share it the uc browser and tick-tock
[01:18:24.560 --> 01:18:29.360]   yeah it's not because of privacy violations although they claim it's because they're worried that those
[01:18:29.360 --> 01:18:36.080]   apps uh were engaged in activities that were prejudicial to the sovereignty integrity and
[01:18:36.080 --> 01:18:44.080]   defense of india uh they can't apparently do this this is you know we forget that the first amendment
[01:18:44.080 --> 01:18:49.920]   is a unique and wonderful piece of uh the american constitution but not widespread
[01:18:49.920 --> 01:18:58.960]   um anything to say about that either one of those i would not use tick-tock pretty bad tick-tock
[01:18:58.960 --> 01:19:07.680]   what pretty damn bad what did what did you guys think yeah i mean it's it is these things get
[01:19:07.680 --> 01:19:13.200]   more and more complicated i'm not going to defend tick-tock because i think yeah i agree that that
[01:19:13.200 --> 01:19:19.520]   it seems that they rushed into a lot of this uh without much thought and then there is a new excuse
[01:19:19.520 --> 01:19:24.000]   though this is the zoom excuse you know we're just trying to make a nice product here we didn't
[01:19:24.000 --> 01:19:31.120]   really expect anybody to bother it uh check out bus us it's is the same theory of move fast and
[01:19:31.120 --> 01:19:36.320]   break stuff yeah it's the same theory yeah maybe it is that i mean it's yeah but it's also impugent
[01:19:36.320 --> 01:19:41.920]   impugent tension sure but it's also i mean it's it's also the nature of innovation right and like
[01:19:41.920 --> 01:19:47.520]   sort of how how it works on this idea of like you know the minimum viable product and and you know
[01:19:47.520 --> 01:19:52.640]   getting stuff out there quick and iterating um and that is how a lot of innovation happens and so
[01:19:52.640 --> 01:19:57.920]   like i can see both sides of it and i can completely understand the argument that like this looks
[01:19:57.920 --> 01:20:03.200]   really bad and they should do better and i agree with that but i also the one sort of hesitation
[01:20:03.200 --> 01:20:07.600]   the one point where i step back a little bit as i say do we even get these innovations in the first
[01:20:07.600 --> 01:20:11.840]   place if you say you have to have it perfect the first time out and i think we would probably end
[01:20:11.840 --> 01:20:16.400]   up losing a lot of the innovations that eventually do come out of this process and it's a very messy
[01:20:16.400 --> 01:20:19.840]   process and there are obvious problems with it and that's that is what we're talking about and i
[01:20:19.840 --> 01:20:24.800]   don't mean to diminish that and i don't mean to excuse like all the horrible things that that is
[01:20:24.800 --> 01:20:30.240]   within the tiktok app or even the mistakes that i think zoom has made and and is now rushing to
[01:20:30.240 --> 01:20:36.320]   try and fix um but you know i think watching how these companies respond to this information as
[01:20:36.320 --> 01:20:40.400]   it comes out is the most important thing and like you know zoom has actually been a really
[01:20:40.400 --> 01:20:45.840]   interesting case study in that they seem to be one of the rare cases where they're they appear to
[01:20:45.840 --> 01:20:50.000]   be taking all these issues very seriously you know i've brought on really good people and have been
[01:20:50.000 --> 01:20:55.680]   very transparent about all the changes that they're making we'll see about tiktok um but hasn't zoom
[01:20:55.680 --> 01:21:01.040]   been talking out of both sides of its mouth with well we're we're encrypt everything is going to be
[01:21:01.040 --> 01:21:05.360]   encrypted and we can't see it but yet we still have the keys already still talking that story
[01:21:05.360 --> 01:21:10.560]   they've been changing that you know as as they've gotten more and more pushback on on the setup of
[01:21:10.560 --> 01:21:16.960]   how they were doing it um they they've been changing but again like the the theme of all of all of this
[01:21:16.960 --> 01:21:21.760]   is that every one of the choices that they make has trade-offs right and understanding which of
[01:21:21.760 --> 01:21:27.840]   the which of the bad decisions you have to make it is really difficult and it's really you know
[01:21:27.840 --> 01:21:33.760]   it's it's fun to criticize them because i do that all the time but recognizing like being in their
[01:21:33.760 --> 01:21:38.880]   shoes like i don't know exactly which decision i would make either right i can see you smiling
[01:21:38.880 --> 01:21:44.160]   right now as you talk about oh i say that all the time as jeff knows and aunt knows about
[01:21:44.160 --> 01:21:49.440]   facebook and google and twitter as well you know these are tough decisions it's interesting that apple
[01:21:49.440 --> 01:21:54.160]   for whatever reasons of its own has decided to come step forward and become the defender they just
[01:21:54.160 --> 01:22:00.720]   turned down a bunch of uh web uis proposed by the w3c because they would enable fingerprinting on
[01:22:00.720 --> 01:22:04.720]   safari and they said you know we're not going to implement there's no reason an app need you know
[01:22:04.720 --> 01:22:10.480]   a web app needs access to the accelerometer of the gps coordinates except that there is if you want
[01:22:10.480 --> 01:22:16.720]   to make your web browser be you know support application like behavior on the internet which
[01:22:16.720 --> 01:22:22.160]   many people do there's good reason for those uis and so i don't think the w3c is proposing them
[01:22:22.160 --> 01:22:28.800]   out of uh some sort of secret cabal with advertisers but i think it's also interesting that apple
[01:22:28.800 --> 01:22:33.440]   said yeah and we don't think so uh because they could be used to fingerprint you i mean things like
[01:22:33.440 --> 01:22:39.760]   exactly how much ram you have uh why does a browser need to be able to report that i just i and so
[01:22:39.760 --> 01:22:46.160]   you you nailed it mike there are reasons people do this not necessarily nefarious but i would also
[01:22:46.160 --> 01:22:51.200]   submit there's really reasons to say no yeah i don't run facebook or i don't run instagram i don't
[01:22:51.200 --> 01:22:58.240]   put tiktok on my phone anymore because basically i think most apps these days are really a wrapper
[01:22:58.240 --> 01:23:05.120]   around data collection tools yes yeah most what can we do to make it sexy so that you'll install it
[01:23:05.120 --> 01:23:10.560]   so that we can find out everything you're doing and sell it that's yes that's the business we're in
[01:23:10.560 --> 01:23:16.240]   right now so yeah you know there's also the the level where you'll see those little reports to say
[01:23:16.240 --> 01:23:23.520]   hey send this crash report or something like that for like a adobe there's some privacy implications
[01:23:23.520 --> 01:23:30.560]   there too generally my friends on mac break weekly yell at me because when you install apps uh on
[01:23:30.560 --> 01:23:36.720]   apple's devices there's often there's always a checkbox do you want to send data back to the app
[01:23:36.720 --> 01:23:41.760]   developer uh and i always say yeah because i want to help them be able to make a better app right
[01:23:41.760 --> 01:23:46.960]   and they said because you have that that mindset of a developer i think you are a delenix guy i
[01:23:46.960 --> 01:23:51.360]   would like to know that you know i want to know when you're opening it and why and how long you spent
[01:23:51.360 --> 01:23:57.600]   and but they say no Leo that's you're just enabling tiktok to collect that information
[01:23:57.600 --> 01:24:05.280]   you're given them all the jewels that they're trying to mine yeah yeah so uh i i choose to say yes
[01:24:05.280 --> 01:24:11.040]   and then not install apps and then i guess the in apps i install i'm tacitly saying go ahead
[01:24:11.040 --> 01:24:18.160]   collect what you need relax it's okay Leo it's okay it's gonna be all right oh no face recognition
[01:24:18.160 --> 01:24:24.320]   software finally as mike maznick puts it actually tim kushin puts it on tector gets around to
[01:24:24.320 --> 01:24:32.720]   arresting an innocent person uh this is a pretty horrific story uh that comes out of a detroit
[01:24:32.720 --> 01:24:43.600]   detroit police department uh got a grainy grainy picture uh from a cctv camera uh the worst yeah
[01:24:44.080 --> 01:24:50.480]   the worst it was a low res screen grab to boot uh of a robbery occurring and they fed it through
[01:24:50.480 --> 01:24:56.160]   who knows might have been clear view ai whatever they were using for face recognition and uh came up
[01:24:56.160 --> 01:25:00.720]   with uh this guy i'm not gonna say his name because the poor guy's had enough trouble uh he got a
[01:25:00.720 --> 01:25:06.000]   call from police police department saying come on in you're gonna be arrested he says at first i
[01:25:06.000 --> 01:25:11.840]   thought i was a prank and ignored it and now or later when he pulled into his driveway in farmington
[01:25:11.840 --> 01:25:17.600]   hills a police car pulled up behind him blocked him two officers got out handcuffed him in front
[01:25:17.600 --> 01:25:23.440]   of his wife and two young daughters they wouldn't say why is being arrested just showed him a piece
[01:25:23.440 --> 01:25:30.320]   of paper with his photo and the words felony warrant and larceny this is the worst part when his wife
[01:25:30.320 --> 01:25:36.720]   said where are you taking my husband the officer says google it like i don't even know what that's
[01:25:36.720 --> 01:25:41.360]   supposed to mean google it what the hell are you talking about where are you taking him
[01:25:41.360 --> 01:25:46.640]   uh so the show is finally about google yeah finally see i got the word googling
[01:25:46.640 --> 01:25:55.600]   i had a work on it but i did so uh in 40 minutes in we got it we got the word in um so unfortunately um
[01:25:55.600 --> 01:26:02.240]   oh by the way the police said well wait a minute we didn't just use the face recognition
[01:26:02.240 --> 01:26:07.520]   we showed uh him his driver's license photo to the lost prevention person at the store
[01:26:07.520 --> 01:26:14.720]   and she supposedly identified him in any event they eventually had to uh let him go
[01:26:14.720 --> 01:26:22.480]   and apologize but the poor guy went through hell uh including being held in jail for several hours
[01:26:22.480 --> 01:26:30.000]   before being released in a thousand dollar bond or 18 hours and 18 hours yeah 18 hours yeah 18
[01:26:30.000 --> 01:26:36.160]   now yeah it's good thing he had a thousand bucks he was in there for 18 18 hours in a holding cell
[01:26:36.160 --> 01:26:43.280]   he's now he's now suing good so the ACLU took up his case and they're they're suing over that uh
[01:26:43.280 --> 01:26:51.040]   and by the way had they bothered to ask or investigate he he had now a buy he couldn't have done it
[01:26:51.040 --> 01:26:57.040]   he had posted a video to his instagram account at that time on his way up the park see you see
[01:26:57.920 --> 01:27:04.160]   social media is good there you go so i got google and you got that in so well done jeff we've
[01:27:04.160 --> 01:27:08.640]   we've fulfilled our missions we can go home happy i do not mean to make light of the
[01:27:08.640 --> 01:27:14.560]   terrible story but it's terrible and this is why everybody uh and i think eventually this is going
[01:27:14.560 --> 01:27:19.440]   to happen including congress now is talking for putting a face recognition on hold of course he's
[01:27:19.440 --> 01:27:24.720]   black i should have mentioned that the poor guy is black and that's why he was recognized
[01:27:25.520 --> 01:27:30.400]   that you know i don't keep it damaged it was a white guy this it was still terrible but but
[01:27:30.400 --> 01:27:37.520]   the false positives in face recognition are so high yeah probably put any black guy in front of
[01:27:37.520 --> 01:27:44.480]   that face recognition and say oh yeah he did it he looks guilty oh lord it's flat wrong one i don't
[01:27:44.480 --> 01:27:50.480]   know the go ahead go ahead no no you i don't know the law or anything like far as all of the
[01:27:50.480 --> 01:27:56.800]   extensive of of warrants and whatnot but it seemed a little bizarre that they walked up and just
[01:27:56.800 --> 01:28:02.080]   immediately slapped the handcuffs on them i thought they at least had to tell them you know what's going
[01:28:02.080 --> 01:28:06.960]   on and start going through the Miranda right stuff well this is the other problem right in
[01:28:06.960 --> 01:28:13.440]   policing in general but with his face recognition they can the police consider that ample evidence
[01:28:13.440 --> 01:28:19.440]   this guy did it okay so they treated him as a perp right they didn't treat him as a suspect
[01:28:19.440 --> 01:28:26.240]   or let's investigate no no the fit the computer said he did it okay that was sufficient to them
[01:28:26.240 --> 01:28:35.600]   in fact the contractors that supplied the ai system even said maybe this is you know retro
[01:28:35.600 --> 01:28:40.320]   actively a match using facial recognition alone is not a means for positive identification
[01:28:40.320 --> 01:28:46.560]   well what do you make this stuff for all right so anyway let's hope this is this was going to happen
[01:28:46.560 --> 01:28:54.240]   uh fortunately nobody was injured uh but it's you know shameful and it just proves why this has
[01:28:54.240 --> 01:29:00.240]   got to stop and i think give me facial recognition to make autofocus even better there you go that's all
[01:29:00.240 --> 01:29:08.080]   i mean put it in the camera that's what i want yeah that's all i need yeah um we could actually go on
[01:29:08.080 --> 01:29:12.960]   there's more uh according to business insider leak documents show how police use social media
[01:29:12.960 --> 01:29:18.800]   and private slack channels to track protesters george froid floyd protesters
[01:29:18.800 --> 01:29:25.840]   um but i you know it's too depressing there's a large rise no but this is this is an example this
[01:29:25.840 --> 01:29:30.560]   is an example of of kind of what mike was saying earlier i'm stretching it mike but what the hell
[01:29:30.560 --> 01:29:38.000]   um is that when possible you blame the technology whereas what the last few weeks have shown us is
[01:29:38.000 --> 01:29:43.600]   there is a systemic issue in police and the institution of policing in the united states
[01:29:43.600 --> 01:29:49.280]   and the fact that they misuse technology is only one of a myriad of problems there you go yeah
[01:29:49.280 --> 01:29:55.600]   and i'll i'll connect it to another story just for fun which is the the the discussion on
[01:29:55.600 --> 01:30:00.560]   encryption uh and you have all these police who keep keep saying we have to have back doors to
[01:30:00.560 --> 01:30:05.200]   encryption we have to break encryption because we can't find out any information anymore and yet
[01:30:05.200 --> 01:30:10.320]   in both of these stories what did we see we saw police who if they use technology properly could
[01:30:10.320 --> 01:30:16.560]   have actually gotten useful information from from social media all these sources social media or
[01:30:16.560 --> 01:30:21.680]   or whatever you know but you know i had a story not too long ago that that sort of touched on this
[01:30:21.680 --> 01:30:27.600]   with these examples of like the fbi tracked down somebody who had had lit a fire lit a police car
[01:30:27.600 --> 01:30:33.920]   on fire by you know i forget the exact details it was this crazy string of of things where they
[01:30:33.920 --> 01:30:38.000]   there's a woman who is wearing a shirt that had a saying on it and they tracked that shirt to
[01:30:38.000 --> 01:30:42.720]   etzi and they found a review that matched her name and they found her linked in profile
[01:30:42.720 --> 01:30:47.360]   police work that's yeah and it was like actual detective work man it's baby
[01:30:47.360 --> 01:30:53.440]   but but in that same story there was also examples of the fbi you know arresting people based on
[01:30:53.440 --> 01:30:59.120]   social media posts where they were sarcastic right you know satirical posts rather than any
[01:30:59.120 --> 01:31:05.280]   actual criminal behavior and so you have all of these things where you know law enforcement really
[01:31:05.280 --> 01:31:10.080]   they have all these new tools but they haven't figured out how to use them and you know they sort
[01:31:10.080 --> 01:31:15.680]   of jump into the sort of lazy explanations where if we think this is a crime it's a crime right
[01:31:15.680 --> 01:31:20.640]   and that creates all sorts of problems and so you know there's there's a real issue here where
[01:31:20.640 --> 01:31:25.760]   if we're going to have law enforcement doing this before we say let's break encryption you know let's
[01:31:25.760 --> 01:31:29.200]   figure out if there's a way that they can actually use the technology that they have in front of them
[01:31:29.200 --> 01:31:35.440]   we have the best high def picture ever of everything that's going on come on give me a break they just
[01:31:35.440 --> 01:31:40.880]   don't like these little one or two blank pixels they want to see the whole thing they want to be
[01:31:40.880 --> 01:31:46.400]   perfect no blank pixels somebody the chatroom says they're Barnaby jonesing it they're doing it man
[01:31:46.400 --> 01:31:55.280]   they're looking today's the day the california consumer privacy protection act goes into effect
[01:31:55.840 --> 01:32:01.280]   you're in charge the world now california it's us baby forget gdpr we got the ccpa
[01:32:01.280 --> 01:32:06.240]   i don't know what's going to happen although i do see a lot of companies now putting this
[01:32:06.240 --> 01:32:14.800]   ccpa to cisclamers and trying to uh trying to yay yeah at least cyay yeah it gives internet
[01:32:14.800 --> 01:32:21.360]   users in california hence the world the right to request businesses not to sell uh or even
[01:32:21.360 --> 01:32:27.440]   and even delete their personal information kind of like gdpr but there's still questions
[01:32:27.440 --> 01:32:31.840]   according to ad week curse ad week would be all over this about what counts is selling
[01:32:31.840 --> 01:32:37.920]   information in which party manages opt out ccpa defines a sale is selling renting releasing
[01:32:37.920 --> 01:32:42.960]   disclosing disseminating making available transferring or otherwise communicating orally and
[01:32:42.960 --> 01:32:47.680]   writing our bioelectronic or other means a consumer's personal information by the business to another
[01:32:47.680 --> 01:32:55.680]   business or a third party for monetary or other valuable consideration it's a very interesting
[01:32:55.680 --> 01:33:01.840]   definition of selling yeah well you can put away as a soreness and just yeah right by by the way
[01:33:01.840 --> 01:33:05.840]   it doesn't have to be for money doesn't have to be for money valuable consideration could be
[01:33:05.840 --> 01:33:12.720]   mutual benefit uh was ad week assuming that there's a third party managing all of this and this isn't
[01:33:12.720 --> 01:33:17.120]   just a government managing all of these these checks and balances coming in for people to want
[01:33:17.120 --> 01:33:26.000]   to opt out uh that's an interesting question no i think that at least with gdpr it's up to it's
[01:33:26.000 --> 01:33:31.280]   up to us for instance to enforce yeah it's it's the companies that have to enforce it yeah the uh
[01:33:31.280 --> 01:33:37.600]   the california attorney general can go after companies that don't do it um and then there's
[01:33:37.600 --> 01:33:43.360]   you know there are other aspects to to it it's it's it's going to be a mess just as gdpr was a mess
[01:33:43.360 --> 01:33:49.120]   and and if you look at kind of the results of gdpr in a lot of cases it's really just given more power
[01:33:49.120 --> 01:33:53.360]   to the big companies that can that can deal with it and create all sorts of problems for the for
[01:33:53.360 --> 01:33:58.880]   the smaller guys really true that's that's unfortunately really true although i welcome these protections
[01:33:58.880 --> 01:34:05.440]   i think we need them i i think having protections is good i mean the ccpa uh what bothers me is that
[01:34:05.440 --> 01:34:11.680]   it was it was a very rushed job and it's why like you know part of it went into four six months ago
[01:34:11.680 --> 01:34:17.600]   without the actual regulations is the new regulations that went into force today uh but because it just
[01:34:17.600 --> 01:34:22.320]   wasn't ready because they just kind of rushed the whole thing and and privacy you know if the stuff
[01:34:22.320 --> 01:34:26.960]   we were talking about before is complex and crazy and has all different trade-offs privacy is uh is
[01:34:26.960 --> 01:34:34.080]   you know an entirely different level of of trade-offs and complexity uh and and you know that's not the
[01:34:34.080 --> 01:34:38.720]   kind of thing that you should rush a law through and so i am supportive of the idea of better
[01:34:38.720 --> 01:34:43.200]   protecting privacy in so many different ways and i think the companies are terrible at it but i
[01:34:43.200 --> 01:34:49.440]   do not think that this is the the proper vehicle for doing it there will be an extension to it because
[01:34:49.440 --> 01:34:55.120]   as uh Mike knows here in california we have we've decided that the assembly doesn't want to do any
[01:34:55.120 --> 01:35:00.000]   work so they've decided to look at voters vote vote there will be a ballot initiative in november
[01:35:00.000 --> 01:35:06.720]   called the california privacy rights act which would expand uh the definitions of the ccpa
[01:35:07.280 --> 01:35:13.840]   uh make it even more dramatic uh for instance a business would be any entity that buys
[01:35:13.840 --> 01:35:18.480]   sells or shares the personal information of 100,000 or more consumers or households
[01:35:18.480 --> 01:35:26.320]   so the previous threshold 50,000 uh by increasing that number the idea is protect small businesses
[01:35:26.320 --> 01:35:32.720]   so that's good um and under ccpa consumers have the right to know what pieces of information a
[01:35:32.720 --> 01:35:38.560]   company has collected over a 12 month period the ballot initiative would extend that period to any
[01:35:38.560 --> 01:35:44.640]   time so long as it takes proportion effort whatever the hell that means um they would also you know
[01:35:44.640 --> 01:35:52.640]   the problem here is the same as before is that there is this this this saying selling your data
[01:35:52.640 --> 01:35:57.760]   is not defined right data is a transactional among parties and who owns it what it is it's the same
[01:35:57.760 --> 01:36:03.440]   as saying get rid of hate it's tough what's hate yes and they're leaving it just drives me nuts
[01:36:03.440 --> 01:36:07.840]   well and to answer your question aunt the uh the ballot initiative does in fact propose
[01:36:07.840 --> 01:36:14.240]   creating a uh an agency to enforce the california privacy protection agency
[01:36:14.240 --> 01:36:19.440]   and right enforcement so some of the stuff with the ballot initiative is a little bit sketchy too
[01:36:19.440 --> 01:36:23.440]   because the whole reason we had the ccpa in the first place is because the same guy got a ballot
[01:36:23.440 --> 01:36:29.280]   initiative in california on the ballot that was even worse initially and the ccpa was that's right
[01:36:29.280 --> 01:36:35.600]   was that's right it was made use the yeah right we will we will pass this you know hastily written
[01:36:35.600 --> 01:36:40.640]   law that is not as crazy as your ballot initiative if you drop the ballot initiative and so he dropped
[01:36:40.640 --> 01:36:46.240]   the ballot initiative to pass the ccpa ccpa put it into effect and six months later he's back with
[01:36:46.240 --> 01:36:49.920]   another ballot initiative and you're like wait i thought we had a deal where you were gonna back
[01:36:49.920 --> 01:36:55.840]   oh i didn't realize this is from that same guy oh that's interesting same guy oh so aunt who has
[01:36:55.840 --> 01:37:01.440]   just moved to california you're gonna get used to this we tend to have very big ballots with lots
[01:37:01.440 --> 01:37:05.840]   of initiatives because it's fairly easy to put an initiative on the ballot and a lot of mr kooky
[01:37:05.840 --> 01:37:12.640]   his hell the most famous one prop 65 which was the one that mandated that anybody any place that
[01:37:12.640 --> 01:37:18.640]   has cancerous chemicals and it has to notify which has had the kind of unintended end result that
[01:37:18.640 --> 01:37:25.520]   there's a sign on everything with a prop 65 warning that if you notice that right everywhere you go
[01:37:25.520 --> 01:37:30.400]   oh yeah this oh you can get cancer here oh you sure you can't get cancer that box it caused
[01:37:30.400 --> 01:37:35.040]   you cancer but they but they ended in the consequences yeah we have to do it so we get we get a lot of
[01:37:35.040 --> 01:37:40.080]   those in our initiative i've seen some of that type of stuff on the ballots back in carol i'm
[01:37:40.080 --> 01:37:45.040]   not surprised i'm sure it's you know it's legislators who don't want to get beyond the hook for making
[01:37:45.040 --> 01:37:50.320]   any any real loss yeah well it's the same thing why we now have to click through on every web page
[01:37:50.320 --> 01:37:56.080]   saying like okay privacy this cookie cookie cookie right because we need attention to any of that
[01:37:56.080 --> 01:38:01.360]   right same thing it's meaningless same thing most of those by the way don't have a i don't want
[01:38:01.360 --> 01:38:07.040]   you to do that right they just all you do is say i agree would you leave me alone i agree
[01:38:07.040 --> 01:38:12.480]   well my favorite are the ones that say i agree or they just have an extra close it i'm like so
[01:38:12.480 --> 01:38:18.720]   if i could i said what happened right now what happens if i just close it is that an acknowledgement
[01:38:18.720 --> 01:38:23.360]   is that a decline or ask yeah ask microsoft they've done that in some of their pop-ups before
[01:38:23.360 --> 01:38:30.720]   hey scoop from kara swisher she's just tweeted you can officially call it techa palooza
[01:38:30.720 --> 01:38:35.760]   representative david chicholini has told me in an interview today the four CEOs of the most
[01:38:35.760 --> 01:38:42.080]   powerful tech companies in the world apple facebook google and amazon cook zuckerberg
[01:38:42.080 --> 01:38:51.120]   patchi and bezos have agreed to appear at a late july hearing on anti trust that's a big big
[01:38:51.120 --> 01:38:57.200]   oh by popcorn futures that's gonna be one we might stream we'll stream that live we got to stream
[01:38:57.200 --> 01:39:03.280]   that live is it it's i can where can i i mean that's she's been can she streams can i have a
[01:39:03.280 --> 01:39:08.400]   c-span yeah it's like nasa right it's we paid for it yeah because it's a washington post it's
[01:39:08.400 --> 01:39:12.000]   what you know yeah washington post on your time and put it up yeah probably the main
[01:39:12.000 --> 01:39:16.400]   c-span on your government or really runs that stuff too although i don't you probably know this
[01:39:16.400 --> 01:39:22.720]   mike but we we like to stream the space launches if we stream nasa tv and so last time we streamed the
[01:39:22.720 --> 01:39:27.360]   the dragon crew launch national geographic to down everything yes saying i wrote about that i
[01:39:27.360 --> 01:39:34.560]   wrote about everybody got we own space that's ours yeah yeah just a switch again happens every
[01:39:34.560 --> 01:39:40.640]   time again and and this is i really like your point of view you cannot impute uh uh malice
[01:39:40.640 --> 01:39:48.000]   when just simple stupidity or or even just mistakes apply and in this case there's just a checkbox
[01:39:48.000 --> 01:39:54.640]   national geographic either did or didn't check that said you know we own this and and the the real
[01:39:54.640 --> 01:40:00.400]   error is youtube's content id system which is so automated and so fast that there's and really
[01:40:00.400 --> 01:40:06.400]   the appeal process takes forever it's crazy hey good news the supreme court agrees
[01:40:06.400 --> 01:40:12.400]   an eight to one decision ladies and gentlemen i got to see sui they see who the dissenter was
[01:40:12.400 --> 01:40:20.080]   uh on this one booking dot com had tried to register its name with the pto the patent office
[01:40:20.080 --> 01:40:25.520]   rejected the filing saying that's generic you can't you can't trademark booking
[01:40:25.520 --> 01:40:33.520]   you can't trademark that booking said well no wait a minute so Ruth Bader Ginsburg in the
[01:40:33.520 --> 01:40:39.920]   majority said the public perception of a name is the core issue if booking dot com or generic
[01:40:39.920 --> 01:40:45.920]   we might expect consumers to understand travelocity to be a booking dot com but they don't they know
[01:40:45.920 --> 01:40:49.680]   better who was the dissent i couldn't say gosh darn it
[01:40:49.680 --> 01:40:55.120]   so this this actually involves my old career when i worked for advance
[01:40:55.120 --> 01:41:02.880]   we had uh for example new jersey online which we called njo but the url was nj.com everybody was
[01:41:02.880 --> 01:41:09.600]   confused as hell so we finally went with nj.com as the brand and the url knowing that we would
[01:41:09.600 --> 01:41:14.800]   not get a trademark or we have problems with the trademark claims because it was generic now
[01:41:14.800 --> 01:41:22.720]   nj.com al.com for alabama um nola.com no longer there. That's right yeah you know they uh they
[01:41:22.720 --> 01:41:29.840]   they're the well jac is a is not a generic right it stands for something whereas nj is very
[01:41:29.840 --> 01:41:35.120]   jr. Yeah it's the jersey yeah so you could we couldn't claim ownership of a jersey but we met
[01:41:35.120 --> 01:41:40.400]   they now can claim ownership of nj.com it sounds kind of retroactive though like you have to
[01:41:40.400 --> 01:41:45.280]   establish that everybody knows what booking dot com is and then you can say oh yeah that's our
[01:41:45.280 --> 01:41:50.000]   trademark it's like you can't i mean how would you defend it if it didn't exist and you say i know
[01:41:50.000 --> 01:41:55.680]   i want it it's a it steven briar was the dissenting uh justice but i don't think he wrote it just
[01:41:55.680 --> 01:42:04.080]   said i don't like it i don't like it i haven't yet um so anyway that you know among meaningless
[01:42:04.080 --> 01:42:09.680]   supreme court rulings that that probably is right up there but so i know you discussed it on on
[01:42:09.680 --> 01:42:16.160]   your 83 other shows boss non-stop i'm sure what but i'm curious uh my apple micro no no no
[01:42:16.160 --> 01:42:23.840]   apple um microsoft closing its stores well it's tied into the apple thing yeah they were losing
[01:42:23.840 --> 01:42:30.640]   money there they just there was a big red blot on there i always felt sorry for the staff like i'm
[01:42:30.640 --> 01:42:34.800]   almost as cool as an apple guy i yeah i mean they were always empty did you ever go buy one first of
[01:42:34.800 --> 01:42:38.240]   all they made one by my daughter's computer they made a big mistake because they look like apple
[01:42:38.240 --> 01:42:43.920]   stores and they're near apple stores so the the comparison is vivid as you walk by one it looks
[01:42:43.920 --> 01:42:49.200]   like a party you know people are laughing and it's yeah they're practically doing marimba conga line
[01:42:49.200 --> 01:42:54.960]   is and then next door it's like da da da da you hear the crickets
[01:42:54.960 --> 01:43:02.080]   uh paul tharad said the the squeaky sign on the hinge is the wind
[01:43:04.720 --> 01:43:10.960]   anyway they weren't very successful uh they're closing them i made it more than it is which was
[01:43:10.960 --> 01:43:15.200]   kind of the writing on the wall for yeah that's my job is to blow things out of proportion
[01:43:15.200 --> 01:43:22.080]   is the writing on the wall for the post-pc era that at microsoft just you know microsoft knows its
[01:43:22.080 --> 01:43:28.240]   business is not computers or selling computers or even windows its business is the cloud
[01:43:28.800 --> 01:43:35.040]   and in fact it's a great business they they were smart they they moved their whole business
[01:43:35.040 --> 01:43:40.560]   to something that everybody's going to be coming to um and they were smart and so the stores have
[01:43:40.560 --> 01:43:45.840]   no real that's all in the deller that's all in the deller that's such an idyller yeah so were they
[01:43:45.840 --> 01:43:52.800]   as smart okay question then um who did a better pivot microsoft or networks
[01:43:55.840 --> 01:44:01.120]   uh i would like to say netflix had already had that in the cards anyway from the get-go
[01:44:01.120 --> 01:44:08.880]   well do you remember though how much uh a pro-brium that read Hastings got when he said
[01:44:08.880 --> 01:44:13.840]   we're going to split into two businesses the dvd business yeah and the and the
[01:44:13.840 --> 01:44:20.720]   springing business quickster yeah and uh good memory and people thought
[01:44:21.520 --> 01:44:26.800]   no i was used to mine not your you're how are you doing you insane person you
[01:44:26.800 --> 01:44:34.160]   and of course he was exactly right yeah but i think you know i think the netflix uh disruption
[01:44:34.160 --> 01:44:38.960]   and and change was a more linear one like you can see the easy path there the train was where
[01:44:38.960 --> 01:44:44.800]   the microsoft change that's you know that's a completely different business and it involved
[01:44:44.800 --> 01:44:52.320]   like a very different set of of skills and outlook and structure to the business in fact and it very
[01:44:52.320 --> 01:44:58.480]   much is you know nadela's ability to come in and completely move that company in a very very
[01:44:58.480 --> 01:45:02.560]   different direction is really really impressive when you think about it whereas you know the netflix
[01:45:02.560 --> 01:45:07.600]   i think everybody kind of understood like that's where netflix has to go but that was not nearly as
[01:45:07.600 --> 01:45:12.160]   obvious with microsoft so i i would like to get some microsoft netflix actually made two pivots
[01:45:12.880 --> 01:45:18.160]   both of them ek and you know the economic exigencies required but the pivot from
[01:45:18.160 --> 01:45:23.280]   streaming other people's content to making their own was sure arguably much more significant and
[01:45:23.280 --> 01:45:28.800]   and properly executed they became the dominant content creator and if that very well that's true
[01:45:28.800 --> 01:45:34.720]   yeah so i would say i'm not sure which one you were talking about ant i uh i would say the pivot
[01:45:34.720 --> 01:45:39.280]   the second pivot might have been more important not more prescient because they knew they were losing
[01:45:39.280 --> 01:45:45.040]   movies all the movie companies were saying you can't have the no i was just saying that it seems like
[01:45:45.040 --> 01:45:51.520]   netflix had already had that in the cards before we even conceived it as consumers right where
[01:45:51.520 --> 01:45:58.480]   microsoft at the hand were saying you know what we're getting our butts kicked on this particular
[01:45:58.480 --> 01:46:03.520]   side of things that the market and we're getting our butts kicked over here but on the enterprise
[01:46:03.520 --> 01:46:08.640]   side of things we seem to keep doing our thing and doing okay so let's just go ahead and move
[01:46:09.200 --> 01:46:15.120]   cloud wise with the azure and all that good stuff and in that i think that's most impressive there
[01:46:15.120 --> 01:46:20.160]   well here's the interesting thing that i brought up after drinking the apple kool-aid and
[01:46:20.160 --> 01:46:26.640]   basking in the reality distortion field and enjoying the excitement of apple silicon it kind of came
[01:46:26.640 --> 01:46:35.200]   to me apples making this change also in a post-pc world and apples doubling down on computers
[01:46:36.160 --> 01:46:40.960]   fortunately they have mobile and they're doing very well in mobile which microsoft is not so
[01:46:40.960 --> 01:46:45.040]   microsoft didn't have that and i don't know if that's an advantage to apple or disadvantage it's
[01:46:45.040 --> 01:46:50.480]   keeping them in the hardware game when it may in fact be that the future of computing is cloud
[01:46:50.480 --> 01:46:55.520]   based and all you need is some sort of thin client to access it and won't really matter
[01:46:55.520 --> 01:46:59.360]   well then what does apple have to offer in that world you know what i i realized there is a
[01:46:59.360 --> 01:47:04.640]   path forward for apple as a fashion accessory because if paul throt said this when you okay so
[01:47:04.640 --> 01:47:08.800]   you're gonna need something you're thin client apple can make the best looking
[01:47:08.800 --> 01:47:15.040]   clients with the best battery life and the coolest and the thinnest and in the way they
[01:47:15.040 --> 01:47:19.600]   already are doing that so there is a path forward to them they'll be the yeah but in client company
[01:47:19.600 --> 01:47:24.080]   it's not as much money as microsoft's gonna make who's i mean i do i do think they have they have
[01:47:24.080 --> 01:47:29.120]   a challenge in the services side of things and i think apple apple has realized that and you know
[01:47:29.120 --> 01:47:35.840]   the most interesting thing that i have for people to say is like why does an apple buy box or drop
[01:47:35.840 --> 01:47:40.400]   box or something like that and build a services business on top of that you know they have i
[01:47:40.400 --> 01:47:46.400]   cloud but that is you know not quite the same thing right now well as you know that's historically
[01:47:46.400 --> 01:47:52.000]   really hard to do you have this big cancer clash you don't take a scumbie that is terrible at
[01:47:52.000 --> 01:47:57.440]   surfaces and is terrible at cloud and just buy a cloud company and say see we fixed it because
[01:47:58.160 --> 01:48:05.440]   that's you know yeah and apple is not i mean they bought i certainly bought companies but
[01:48:05.440 --> 01:48:12.800]   they don't like it they have not done done the the really big massive purchases and and
[01:48:12.800 --> 01:48:17.840]   figuring out ways to move those in house and that is yes a an arena that is very very difficult to
[01:48:17.840 --> 01:48:22.480]   get right and apple knows that actually apple has said that specifically we don't want to have to
[01:48:22.480 --> 01:48:27.040]   do all of that culture adjustment so that we can acquire a big company i mean and you could look at
[01:48:27.040 --> 01:48:33.280]   all the wreckage of you know what was it compact uh you know uh i mean i you must have gone on a
[01:48:33.280 --> 01:48:40.400]   go you know yeah hp compact or um Warner Brothers AOL and or you know time Warner AOL there's been a
[01:48:40.400 --> 01:48:46.960]   lot of those bad acquisitions so anyway it's interesting to think of of the Microsoft store
[01:48:46.960 --> 01:48:52.640]   somehow tying into the apple silicon story uh two different takes on what the future of computing
[01:48:52.640 --> 01:48:57.840]   will look like perhaps that's my if i were Mike Masnick or somebody with his brain so i'd write a
[01:48:57.840 --> 01:49:03.760]   i'd write a think piece on that but i'm not i don't i've the other day i started writing a
[01:49:03.760 --> 01:49:08.160]   blog just because i thought you know i really probably should organize whatever this mush is up here
[01:49:08.160 --> 01:49:12.960]   and because i realized that my job really is just to have a thought speak it and it goes and it's gone
[01:49:12.960 --> 01:49:17.840]   and i don't have to be held accountable or anything for the age it's great i love it
[01:49:17.840 --> 01:49:21.920]   and so i thought i should start writing a little bit because that forces a discipline but then i
[01:49:21.920 --> 01:49:28.160]   look at people like you Mike or Ben Thompson and i go i don't i don't even know how to start thinking
[01:49:28.160 --> 01:49:32.400]   that thinking that hard deep stuff that's why i don't write yeah it's hard
[01:49:32.400 --> 01:49:43.440]   i need a thesis what i have no thesis i have thesis free let's do play the drums the google
[01:49:43.440 --> 01:49:56.880]   changelog this is where we pay lip service to being called this week in google google sheets
[01:49:56.880 --> 01:50:02.640]   will soon be able to auto complete data for you google's can become the auto complete company
[01:50:02.640 --> 01:50:08.240]   so one thing they really do yeah it really really really amused me yeah like oh you actually
[01:50:08.240 --> 01:50:13.040]   should be making profit this quarter we're gonna just put that in yeah the the risk of this is it
[01:50:13.040 --> 01:50:18.080]   becomes Microsoft clippy i see you're trying i see you're trying to make profit can i help
[01:50:18.080 --> 01:50:27.920]   that would be an interesting lawsuit on the 230 front yeah yeah yeah really who's liable for
[01:50:27.920 --> 01:50:34.720]   that if you screw up my balance sheet they call it uh it's kind of it's kind of a smart fill it's
[01:50:34.720 --> 01:50:42.160]   kind of like smart compose gmail finish your sentences for you uh i don't know google explains
[01:50:42.160 --> 01:50:46.640]   say you have a column full of names but you want to split it into two columns by the way i do this
[01:50:46.640 --> 01:50:52.240]   all the time as you start typing the first names into a column like in other words you start doing
[01:50:52.240 --> 01:50:59.840]   this manually sheets will say oh i get it you're trying to idiot you mora help and it'll just fill
[01:50:59.840 --> 01:51:04.720]   it in for you look at that formula suggestion i guess that'll be useful that's perfect for
[01:51:04.720 --> 01:51:11.200]   someone like me that that hates spreadsheets and yeah i've never been a spreadsheet person only
[01:51:11.200 --> 01:51:17.440]   if i'm doing like a um a massive data load into the database yeah that was it and that's only because
[01:51:17.440 --> 01:51:23.520]   it's a flat file that's right for years i've spent hours like trying to figure out stupid things
[01:51:23.520 --> 01:51:30.560]   like this you know i get the city and state in separate fields in the zip code how do i and
[01:51:30.560 --> 01:51:36.640]   it's just a panel but but you know now google do it for you by the way smart complete is also coming to
[01:51:36.640 --> 01:51:43.600]   google messages or smart compose i guess so as you just said it is the all complete that for you
[01:51:43.600 --> 01:51:48.400]   you don't even have to think now you don't even have to say it maybe it'll write my blog posts for me
[01:51:48.400 --> 01:51:58.640]   yeah exactly yeah i want i need a leo complete holy cow did you hear that yeah jeez right there
[01:51:59.520 --> 01:52:07.200]   you're going to sleep good tonight holy that was killed that was quite a thunderbolt there that if
[01:52:07.200 --> 01:52:14.320]   we lose power we do have a generator but it takes a few minutes to come in so wow um meet is uh being
[01:52:14.320 --> 01:52:22.560]   upgraded in many ways as google scrambles google must have just like why is zoom beating i know michael
[01:52:22.560 --> 01:52:29.120]   what is with zoom where oh look here's one of those cookie things uh i don't even have a close i just
[01:52:29.120 --> 01:52:36.880]   have except it's just accept all right i thought i turned i supposedly in ublock origin if you turn
[01:52:36.880 --> 01:52:46.240]   on i thought there was a way in settings if you turn on jeez louise did i want to do these louise
[01:52:46.240 --> 01:52:52.000]   no no i love it are you kidding we don't get thunder and lightning here in california you don't know
[01:52:52.000 --> 01:52:59.360]   just wind earthquakes just earthquakes uh and they're quieter they're much quieter here comes another
[01:52:59.360 --> 01:53:09.200]   one wow so how many are you counting the seconds uh no i forgot how to do that seven seconds a mile
[01:53:09.200 --> 01:53:16.160]   per mile i remember that thought it was five i just go to dark sky and look at the uh it just like at
[01:53:16.160 --> 01:53:22.160]   the i look at the radar map what are you talking about exactly what he had crazy google meet is
[01:53:22.160 --> 01:53:29.200]   going to be upgraded for education users uh blah blah blah when somebody has to join a meeting or
[01:53:29.200 --> 01:53:33.600]   knocks they won't be able to knock again if you are if you reject them this is always a problem with
[01:53:33.600 --> 01:53:39.440]   these meetings you know interlopers and a knock will no longer show up after a moderator rejects
[01:53:39.440 --> 01:53:44.720]   it twice i guess there's a problem in classrooms where you get kids just knock knock knockin on
[01:53:44.720 --> 01:53:50.640]   meetings door um educators will be able to mute all participants at the same time
[01:53:50.640 --> 01:53:56.080]   disable inter-meeting chat for participants is all about teachers and students right yeah and
[01:53:56.080 --> 01:54:01.840]   restrict who can present do you use meet in uh for your classrooms no we're using the reasons
[01:54:01.840 --> 01:54:07.520]   then we started with with meet but um google got hit by such surprise the quality the video quality
[01:54:07.520 --> 01:54:13.440]   was terrible it really does tear up yeah um they they just got zapped
[01:54:13.440 --> 01:54:21.520]   so my friend uh chris mark wort who is uh really great photographer has created a new
[01:54:21.520 --> 01:54:30.800]   uh website called uh sensei.photo and it's one-on-one uh teaching i'm trying to find the name of the
[01:54:30.800 --> 01:54:36.800]   program he uses because he said oh we found a really good program for education he started it
[01:54:36.800 --> 01:54:42.640]   like a month or so yeah it's brand new he's doing portfolio reviews and so forth
[01:54:42.640 --> 01:54:48.480]   i'll find the i'll find the name of it but uh yeah he we talked about it because he's he found a much
[01:54:48.480 --> 01:54:53.360]   better solution you're gonna hear yeah you find it's not a decision designed for teaching i will
[01:54:53.360 --> 01:54:58.880]   i'll find out and i'll send it to you um shoot i wish i could remember i can't remember enough
[01:54:58.880 --> 01:55:04.720]   tough my head either but i remember remember i'm talking about it yeah i wonder what he was
[01:55:04.720 --> 01:55:12.640]   friday i spent six solid straight hours on zoom no break oh there is really something uh called zoom
[01:55:12.640 --> 01:55:19.920]   fatigue isn't there yeah but he's you know and i also think i used to have to commute an hour and
[01:55:19.920 --> 01:55:28.000]   three quarters each way true so do you miss your train town i miss listening to more books this is
[01:55:28.000 --> 01:55:31.520]   what he's using and actually a lot of schools use it it's called big blue button you've probably tried
[01:55:32.400 --> 01:55:38.800]   so i have a lot of schools use this it's designed for online learning you tell the dean
[01:55:38.800 --> 01:55:49.040]   let the dean know anyway moving right along with them i am so easily sidetracked so squirrel
[01:55:49.040 --> 01:55:55.920]   so squirrel what did you say something so apple for a while has used the one feature in its new
[01:55:55.920 --> 01:56:02.320]   phones is the yelter wideband chip the u1 chip that knows where you are in space and it's used
[01:56:02.320 --> 01:56:06.480]   it's for its airdrop feature the feature allows you to take a photo on a phone and share it to
[01:56:06.480 --> 01:56:11.760]   somebody else and using this u1 chip with another person with a u1 chip you can aim so if there's
[01:56:11.760 --> 01:56:15.440]   ten people standing here and i want to share it with that one i can actually aim it at that one
[01:56:15.440 --> 01:56:22.800]   uh google is now rolling out their version of airdrop it's called nearby sharing
[01:56:23.520 --> 01:56:26.720]   they but they've been way behind on this one of course it's fitting because apple's stolen
[01:56:26.720 --> 01:56:33.040]   everything from android for this new version of android
[01:56:33.040 --> 01:56:37.200]   you get to cotta and fugue that was perfect timing
[01:56:37.200 --> 01:56:47.280]   i feel like this is a uh vincent vincent price movie here we're just just tell twitter i love
[01:56:53.200 --> 01:56:57.520]   get some thunder
[01:56:57.520 --> 01:57:04.640]   thunder and lightning very very frightening all right enough of that sorry i got distracted
[01:57:04.640 --> 01:57:08.240]   and you see the problem you see the problem uh
[01:57:08.240 --> 01:57:16.800]   more mike is saying how long do you do this jesus oh it goes on for hours you guys have no
[01:57:16.800 --> 01:57:22.000]   light we're almost done we're i swear to god we're almost all right i'm so sorry mike did they warn
[01:57:22.000 --> 01:57:28.480]   you uh now you know now you know i had a sense my my kids are probably running wild in the next
[01:57:28.480 --> 01:57:33.920]   room well if any point you want to leave you can't you know this is fun it's fun good i mean
[01:57:33.920 --> 01:57:38.000]   we're thrilled to have you we were anytime you want to come back by the way i should mention mike
[01:57:38.000 --> 01:57:44.560]   has his own podcast at tech dirt um tell us about your podcast there at tech dirt uh yeah i mean
[01:57:44.560 --> 01:57:51.440]   it's you know it's it's a regular normal sort of podcast uh uh the thunder like this one
[01:57:51.440 --> 01:57:58.640]   no not like this one uh you know as basically i'm usually just trying to interview somebody who
[01:57:58.640 --> 01:58:04.240]   is doing interesting work you know in and around the kind of stuff that we talk about and it's usually
[01:58:04.240 --> 01:58:09.040]   sort of you know 35 to 45 minutes um don't show off now that's
[01:58:10.480 --> 01:58:15.200]   no but it's you know about we do you know we've been doing a lot of stuff about section 230 lately
[01:58:15.200 --> 01:58:19.520]   and you know all the different kind of legal messes generally we're going to have something
[01:58:19.520 --> 01:58:24.400]   on the urnit act next week so good all that kind of stuff look up the tech dirt podcast and
[01:58:24.400 --> 01:58:30.800]   iTunes or wherever you get your podcasts you put it along does your average podcast episode run
[01:58:30.800 --> 01:58:40.320]   mike it's in that 35 to 45 minute range oh wow wow it now just that's that's lazy
[01:58:40.320 --> 01:58:47.120]   show instead yeah so this is this is condensed that's he probably even make like his succinct it
[01:58:47.120 --> 01:58:52.640]   doesn't get distracted things like that so google now has a new health care
[01:58:52.640 --> 01:59:00.400]   we can't make this up i love it i love it i love it
[01:59:00.400 --> 01:59:05.120]   just step in you can you add sort of like a flickering effect to yeah the lights should go down
[01:59:05.760 --> 01:59:09.040]   just get that underneath light you know the bores carloff
[01:59:09.040 --> 01:59:11.920]   and now very
[01:59:11.920 --> 01:59:20.320]   bored
[01:59:20.320 --> 01:59:30.800]   from the from the crypt the crypt kicker he brought him out of the desk pretty soon wind shifted
[01:59:31.360 --> 01:59:38.160]   um uh dam paneson's story with cbs he talked to joe corkery of uh director product management
[01:59:38.160 --> 01:59:43.920]   health care and life science at google cloud they uh they have a new api the health care api
[01:59:43.920 --> 01:59:50.560]   to let uh to support health care data interoperability so that's a good thing it supports a dicom
[01:59:50.560 --> 02:00:00.240]   digital edgy imaging and communications and medicine uh hl7 version 2 and f h i r fast health care
[02:00:00.240 --> 02:00:07.840]   interoperability resources google expands its free retail listings into search as pandemic hits
[02:00:07.840 --> 02:00:17.280]   ad sales not just facebook that's suffering from the pandemic we all are we all are um they're going
[02:00:17.280 --> 02:00:24.320]   to uh uh it was a experiment in the shopping tag they're going to tab they're going to expand it
[02:00:25.120 --> 02:00:29.600]   as ever advertisers just step away from the ad buy
[02:00:29.600 --> 02:00:36.000]   moving on i don't have anything to say about that finally i should have mentioned this last week i
[02:00:36.000 --> 02:00:42.720]   knew about it and i forgot google is finally letting you use a fi number and a voice number on the
[02:00:42.720 --> 02:00:47.360]   same account this was i've been a google you had big complaints about that i put it in there i
[02:00:47.360 --> 02:00:52.880]   had to give up my google voice account when i got google fi if i wanted to use the same number
[02:00:53.760 --> 02:00:57.760]   and now you'll be able to forward voice calls to fi you're going to get some of that functionality
[02:00:57.760 --> 02:01:02.960]   back which is weird because for the longest time we thought they were killing google voice
[02:01:02.960 --> 02:01:08.800]   but you know google you know that you know how that is google is a funny thing you spend so much
[02:01:08.800 --> 02:01:14.560]   time trying to ride things out with google thinking you're going to fix this or improve that but yet
[02:01:14.560 --> 02:01:19.200]   there's the other side of the corn where you know uh they're going to kill this thing any day now
[02:01:19.200 --> 02:01:26.560]   yeah and you just don't know there's no no rhyme nor reason as an original google voice user from
[02:01:26.560 --> 02:01:32.160]   the very very beginning i have been dreading dreading the the possibility that they might kill it
[02:01:32.160 --> 02:01:38.160]   it's great me too me too yep but see that's the sad thing because i when i got fi i kept the
[02:01:38.160 --> 02:01:42.720]   number because well that's the number i use but then i lost all functionality and voice and it was
[02:01:42.720 --> 02:01:48.400]   kind of frustrating right so i i give future generations will not have to suffer my pain and
[02:01:48.400 --> 02:01:52.480]   isn't that all about all your complaint before that and they listened to you and
[02:01:52.480 --> 02:01:57.920]   teaching us to wait i did it for you google is not going to reopen its offices next week they're
[02:01:57.920 --> 02:02:05.840]   pushing it back till september uh smart i think i'm i've been counting the seconds jeff for you
[02:02:05.840 --> 02:02:11.440]   since you don't know it's moving away i just want to say it's going actually no they we're having a
[02:02:11.440 --> 02:02:16.080]   bad core coming right over oh yeah i think you're looking at the dark yeah are you looking at dark
[02:02:16.080 --> 02:02:24.640]   sky you're looking at the i'm now looking at acuweather nice so we reviewed some time ago did you ever
[02:02:24.640 --> 02:02:33.920]   try the folkles and i know anthony loved them these were uh heads up smart glasses uh they had a
[02:02:33.920 --> 02:02:39.760]   little you see you can see on these they had a little projector um and you would put your notifications
[02:02:39.760 --> 02:02:44.880]   heads up unlike google glass you actually could continue to look at things and do things uh they
[02:02:44.880 --> 02:02:49.520]   were preparing folkles too we knew all about it we were very excited anthony's very excited
[02:02:49.520 --> 02:02:52.000]   nope not gonna happen because google just bought them
[02:02:52.000 --> 02:03:00.880]   uh they started as thalmic labs in 22 they're now at 2012 they're not called north and uh we
[02:03:00.880 --> 02:03:08.480]   don't know how much google paid uh rick osterlo says uh he cites north's strong technology foundation
[02:03:08.480 --> 02:03:13.120]   so google may not have given up on glass this is actually a better glass the folkles
[02:03:13.520 --> 02:03:17.360]   don't i'm not doing it again no i'm not doing it again uh oh no google
[02:03:17.360 --> 02:03:20.800]   still sitting in the closet i'm still bitter
[02:03:20.800 --> 02:03:28.640]   right after i started it twit that's uh about the time when mr. Nielsen's review
[02:03:28.640 --> 02:03:34.720]   yeah on has on tech i saw those things for like five seconds if that didn't really get to spend
[02:03:34.720 --> 02:03:40.960]   time with them though yeah i didn't either anthony's keeping them all to itself you had to go in
[02:03:40.960 --> 02:03:44.480]   he had to go in and get fitted that was the only one the negative of what you had to go in and get
[02:03:44.480 --> 02:03:48.960]   fitted for your glass i did oh yeah and then i bought the prescription lenses like an idiot yeah
[02:03:48.960 --> 02:03:57.360]   well you know in for 1500 bucks in for a pound yeah in for 2000 don't go all the way
[02:03:57.360 --> 02:04:02.480]   uh google is going to have an event and we're going to cover it uh one week from today
[02:04:02.480 --> 02:04:10.240]   uh it's going to be uh kind of a smart home event smart home virtual hay google smart home keynote
[02:04:11.120 --> 02:04:17.520]   uh it was scheduled i think for google i.o this you know we had there's been no hide nor hair of
[02:04:17.520 --> 02:04:22.160]   whatever they were going to do it i.o including the pixel 4a but this might be the beginning of a
[02:04:22.160 --> 02:04:28.080]   kind of a avalanche of things from that would have been a google i.o this will be the smart home
[02:04:28.080 --> 02:04:35.120]   summit keynote uh by mccayley turner the product management director of the smart home ecosystem
[02:04:36.080 --> 02:04:40.640]   we're going to have mica sergeant and matthew cast dally host our coverage because they are the
[02:04:40.640 --> 02:04:48.720]   hosts of smart tech today so they know about this stuff which i can't claim here come the kids i
[02:04:48.720 --> 02:04:54.720]   hear the kids mike here they come i was wondering if i was wondering if they were that loud yes
[02:04:54.720 --> 02:04:59.360]   morning yeah they're on their way like i should complain about about random noise here
[02:05:02.560 --> 02:05:07.920]   i was a little miffed when i got the notice from youtube tv that my subscription which was
[02:05:07.920 --> 02:05:12.880]   recently raised from 35 to 50 dollars is now going to 65 dollars
[02:05:12.880 --> 02:05:17.840]   hey but but there's good news they've added the cw so
[02:05:17.840 --> 02:05:22.320]   that's worth that's worth the extra that woof
[02:05:22.320 --> 02:05:32.080]   um they they got a bunch of new crap channels um the viacom cbs family bet cmt comedy central mtv
[02:05:32.080 --> 02:05:39.920]   mtv is still a thing nickelodeon paramount network tv land and v h one uh and then b8
[02:05:39.920 --> 02:05:47.680]   bt her mtv two mtv classic nik jr nik tun's t nik all coming in a later date that's worth 15
[02:05:47.680 --> 02:05:57.600]   dollars yep i got this email right before um all about android recorded yesterday and i was just
[02:05:57.600 --> 02:06:05.840]   so far up and pissed off all of us Jason howl and and and Florence and ron they they discussed
[02:06:05.840 --> 02:06:10.560]   it on the show yesterday there's a really good discussion they hit a lot of good points that
[02:06:10.560 --> 02:06:15.760]   regular people like me were yelling about with this mess is just well google says and i don't
[02:06:15.760 --> 02:06:20.080]   think it's completely unfair that the costs of the programming have gone up but this is
[02:06:20.080 --> 02:06:25.360]   really now they're cable company they're exactly they're another cable company it's no different
[02:06:25.360 --> 02:06:31.360]   from the people that i cut they have recreated the cable company and so now they're making the
[02:06:31.360 --> 02:06:36.160]   exact same arguments about exactly we're gonna we're gonna see like you know the carriage fights
[02:06:36.160 --> 02:06:41.520]   that they have with cable where you know someone's gonna threaten to pull their content and and the
[02:06:41.520 --> 02:06:47.200]   prices just keep getting up and and up i find it a little ironic at least that you know youtube
[02:06:47.200 --> 02:06:53.040]   effectively became mtv right it sort of took over the mantle for what mtv was when it launched and now
[02:06:53.040 --> 02:06:57.760]   they're they're pulling mtv into youtube but i find that at least a little interesting isn't it
[02:06:57.760 --> 02:07:06.400]   so why but mtv isn't mtv anymore no reality has been prolonged yeah um sling tv's response
[02:07:06.400 --> 02:07:14.160]   we are not going to hike our prices but will i get the cw might not age well no i know they're
[02:07:14.160 --> 02:07:20.480]   sorry already yes sony getting out of the game uh it's got uh yeah basically i i blew the headline
[02:07:20.480 --> 02:07:27.440]   here i should the headline should be google invents cable television right yeah yeah uh but then again
[02:07:27.440 --> 02:07:34.240]   we remember we also talked about amazon potentially doing something like this with with prime so um
[02:07:34.240 --> 02:07:39.600]   hey give me a holler mr day so let me know what you get yeah amazon just added this is not a part
[02:07:39.600 --> 02:07:44.560]   of the change look but amazon just added a uh feature so you can watch along with up to a hundred
[02:07:44.560 --> 02:07:50.400]   friends to watch that i think that's cool i'll be fun yeah that's really cool well that's it
[02:07:50.400 --> 02:07:52.400]   that's the google change
[02:07:52.400 --> 02:07:58.960]   i thought that was the end of the show no that was just the end of the change car we're not even
[02:07:58.960 --> 02:08:04.160]   clear actually no i'm gonna go all in favor we're gonna we're gonna wrap things up but first
[02:08:04.160 --> 02:08:07.200]   actually first well i gotta do this right this is
[02:08:07.200 --> 02:08:15.120]   this is where we insert thunder into the show no
[02:08:17.200 --> 02:08:22.400]   we're gonna do it's time for our picks of the week coming up next actually
[02:08:22.400 --> 02:08:29.920]   coming up right now why don't we get ant uh pruett's pick of the week my friend all right well i have
[02:08:29.920 --> 02:08:35.600]   two in uh for the most part sir i'm just going to say these picks are me
[02:08:35.600 --> 02:08:44.320]   uh the five pick me i pick you ant pruett yeah i don't normally toot my own horn but this time i
[02:08:44.320 --> 02:08:52.080]   am today um i want to do a cross promo for hands on tech yes my review what you're doing uh did
[02:08:52.080 --> 02:08:59.600]   the mke 400 which is a long name for a shotgun mic by sin hyzer and i had a lot of fun uh testing
[02:08:59.600 --> 02:09:05.360]   that out wait a minute wait a minute i love the start of this of this as you're setting up the mic
[02:09:05.360 --> 02:09:10.320]   getting ready getting the lights really getting the camera ready and then oh oh well mr spurt
[02:09:10.960 --> 02:09:16.880]   and then there's that and that was the other thing i wanted to share with my twins oh that is my
[02:09:16.880 --> 02:09:22.240]   tweets that was the other thing that what i wanted to have is my pick because we all know all of the
[02:09:22.240 --> 02:09:28.320]   crap that we're dealing with in society and i figured why not make something viral worth being
[02:09:28.320 --> 02:09:34.800]   viral you know so go out there y'all are watching twitter that's so hard that retweets our bros
[02:09:34.800 --> 02:09:40.400]   some freaking love around here yeah spread some love and it's funny because ant you look so serious
[02:09:40.400 --> 02:09:47.440]   well and and mr leport you know i'm fairly proud i don't share a lot of stuff i i every now and
[02:09:47.440 --> 02:09:52.320]   then i'll do some behind the scenes uh things forest photography and stuff from my people that
[02:09:52.320 --> 02:09:58.720]   follow me on instagram but most of the time i'm really private i know i know i told you know i told
[02:09:58.720 --> 02:10:03.200]   queen earlier i said you never know when i'm recording and right then i was actually testing to
[02:10:03.200 --> 02:10:10.160]   try to get ready for twig and uh oh this was just now yeah this is just earlier today oh
[02:10:10.160 --> 02:10:16.960]   oh that's great this is like honey good luck i know yeah i know you know that's yeah i pray for
[02:10:16.960 --> 02:10:23.520]   you hanjur you're going this is real life i'll see you in ten hours she's my heart she's my queen
[02:10:23.520 --> 02:10:29.120]   and i don't deserve her but again just spread some love ricks on five in our chat room says that's
[02:10:29.120 --> 02:10:36.720]   not the pick of the week that's your peck of the week that's right oh how about you Jeff Jarvis
[02:10:36.720 --> 02:10:48.960]   your peck of the week oh well sorry nobody likes me um oh i screwed up my lighting um so wow it's
[02:10:48.960 --> 02:10:54.160]   scary gods are angry with me don't do two quick things on the bottom of all the rijis added in
[02:10:54.160 --> 02:10:58.240]   a few weeks ago i showed my the eye cuts my hair who did a very good job last week um
[02:10:58.880 --> 02:11:05.760]   uh did a pop up pod he was cut he didn't use that for me but now there's a version of it at the
[02:11:05.760 --> 02:11:12.880]   bottom of the rundown uh under other for the office the pop up wearable tent terrible tent for
[02:11:12.880 --> 02:11:19.120]   covid-19 protection i could walk around in that actually i think so yeah i was thinking i was going
[02:11:19.120 --> 02:11:24.480]   to teach in that every student in it too your hands there is a kind of i think they need a flap
[02:11:24.480 --> 02:11:30.400]   to protect the hand egress port yes i don't know what we're going to do with that but
[02:11:30.400 --> 02:11:36.080]   so that i have an actual number which is that on the conversation which is where academics
[02:11:36.080 --> 02:11:44.560]   try to speak english to the real world uh they did a study of australian tweets um 74.2 million
[02:11:44.560 --> 02:11:52.000]   tweets using the we feel tool and they found that unlike it's the opposite crime when the temperature
[02:11:52.000 --> 02:11:59.120]   gets higher crimes go up on twitter when the temperature gets colder people get angrier
[02:11:59.120 --> 02:12:07.760]   i think people are generally angrier now just because they're quarantined i've never seen more
[02:12:07.760 --> 02:12:14.320]   angry everywhere i go by the way my friend rich de murrow who's the uh ktla tech guy and fill in
[02:12:14.320 --> 02:12:23.280]   for me on uh the tech guy uh show actually has tested that pod uh he uh he actually did this for
[02:12:23.280 --> 02:12:30.400]   his ktla weather report and uh he's gonna walk around his neighborhood kind of looks like jude
[02:12:30.400 --> 02:12:37.840]   law in the movie contagion spreading spreading for sythia look at that yeah i love that guy
[02:12:37.840 --> 02:12:43.920]   greek he's such a cool cat yeah look at that see walk around you're safe little dino
[02:12:43.920 --> 02:12:49.600]   little dino this would be so useful i hope he kept it for this was last year i hope he kept it for
[02:12:49.600 --> 02:12:58.160]   covid this was i guess on shark tank i don't know if they got investment wow wow mike i don't want
[02:12:58.160 --> 02:13:03.680]   to put you on the spot uh do you have something you would like to yeah i pick i do actually i i got
[02:13:03.680 --> 02:13:07.600]   about a 15 minute warning before the show that i needed to come up with me you know but there's
[02:13:07.600 --> 02:13:11.040]   something you do that you read that you love there's something you want to tell the world without
[02:13:11.040 --> 02:13:16.000]   i'm sure yeah no i this sort of gets back to some of the conversation that that we had throughout
[02:13:16.000 --> 02:13:20.800]   this this entire thing which is that a couple weeks ago this new organization or really two new
[02:13:20.800 --> 02:13:26.720]   organizations launched uh which is the trust and safety professional association and the trust
[02:13:26.720 --> 02:13:31.600]   and safety foundation and i actually think they're really interesting organizations that people
[02:13:31.600 --> 02:13:39.280]   should pay attention to uh and i have a a some connection to them that i'll explain in a second but
[02:13:39.280 --> 02:13:44.080]   it's these organizations they're trying to sort of you know make that the whole trust and safety
[02:13:44.080 --> 02:13:50.320]   content moderation field more professionalized and and provides some training and education in
[02:13:50.320 --> 02:13:55.840]   that area and and just letting people know that it is a field and that it is a profession and that
[02:13:55.840 --> 02:14:00.800]   it's not just mark zuckerberg and jack dorsey uh sitting in their office deciding who to delete
[02:14:01.040 --> 02:14:06.160]   um and uh i think they're they're doing some really interesting things so there's some really
[02:14:06.160 --> 02:14:13.920]   really smart people behind it um and and my very limited connection to them is that um
[02:14:13.920 --> 02:14:19.440]   my organization has been writing up case studies of content moderation decisions that are being
[02:14:19.440 --> 02:14:25.280]   published by the trust and safety foundation so so every week a couple of uh case studies on the
[02:14:25.280 --> 02:14:31.200]   the impossible choices that everybody's making oh that's so great uh where can we find that t s
[02:14:31.200 --> 02:14:38.640]   p a dot info oh no no that's the yeah t yes that is okay that is it t s p a dot info okay uh and
[02:14:38.640 --> 02:14:43.680]   yep that's it and then the the foundation i think there's probably a link from there to the foundation
[02:14:43.680 --> 02:14:49.440]   but i'm cool i'm blanking on it what the foundation one is well it's easy to remember t s p a dot
[02:14:49.440 --> 02:14:57.440]   t s f dot foundation oh well that's even easier yes yes s f dot foundation cool and right now
[02:14:57.440 --> 02:15:04.000]   very cool from there there's uh the case studies and those are case studies that we've been putting
[02:15:04.000 --> 02:15:10.320]   together for them so i'm going to give karsten uh my pick of the week this week because he found
[02:15:10.320 --> 02:15:18.080]   something on tecter store that he's giving to his son as a mask the content of this mask is no longer
[02:15:18.080 --> 02:15:24.880]   available due to a copyright claim man yes we should all be wearing that and you're what's nice is
[02:15:24.880 --> 02:15:31.600]   you're donating uh proceeds uh to matt medshire up to a five hundred thousand dollar um
[02:15:31.600 --> 02:15:36.400]   matt maximum donation so that's really really that is awesome and of course it's important
[02:15:36.400 --> 02:15:40.720]   you have to show show the show the the full picture of it because it also has the uh
[02:15:41.200 --> 02:15:48.000]   there there's a different image of it that's the full the inside though inside you'll be seeing the
[02:15:48.000 --> 02:15:54.640]   sad youtube guy that's so funny so there's a message for you and there's a message oh i see
[02:15:54.640 --> 02:16:01.440]   is that the inside of the outside that's the whole got it got it got it got it that's really clever
[02:16:01.440 --> 02:16:07.280]   i wish i we have it we have a t-shirt version of that that's been popular for a few years but
[02:16:07.280 --> 02:16:12.080]   we just launched the mask right we see that a lot on our content in fact thanks to the takata and
[02:16:12.080 --> 02:16:17.280]   fugan d major i think we'll be seeing it again this week yeah so as the eye of the storm i think
[02:16:17.280 --> 02:16:23.200]   that should be out of copyright yeah i would think so but i just read an article yeah about
[02:16:23.200 --> 02:16:30.080]   guy who post sees a professor of music and he post videos with his classical music in it and uh
[02:16:30.080 --> 02:16:37.200]   gets taken out all the time yep yep yep yep uh this was fun thank you all for being
[02:16:37.200 --> 02:16:42.560]   here aunt pruit we're going to catch your review on hands-on tech of that sanheiser shotgun that
[02:16:42.560 --> 02:16:48.800]   sounds really good shotgun mic let's shotgun mic shotgun mic very important thank you yeah and
[02:16:48.800 --> 02:16:55.680]   uh and of course hands-on wellness and hands-on photography and hands-on this week in google
[02:16:55.680 --> 02:17:02.800]   uh yep with us jeff javis wait a minute oh no no no no don't bother oh come on jeff he's the
[02:17:02.800 --> 02:17:08.880]   director of the town i sent a for entrepreneurial journalism at the craig new mark graduate school
[02:17:08.880 --> 02:17:13.360]   of journalism at the city university of new york it's a running joke mic because craig listens
[02:17:13.360 --> 02:17:20.080]   to hear that each and every week well he he should he should he put up his money there i'm sure if
[02:17:20.080 --> 02:17:23.600]   you're going to put your name on something you should hear it when it's when it's actually an
[02:17:23.600 --> 02:17:28.800]   action yeah yeah i would do that this is the you know the modern version of the sign on the
[02:17:28.800 --> 02:17:34.720]   building this is this is how the modern way to get your name out there that's right and mike maznick
[02:17:34.720 --> 02:17:40.240]   it's such a pleasure to have you on have we ever met i feel like we have been on our shows before
[02:17:40.240 --> 02:17:45.920]   at something i i think i was on your show many years ago yeah um like i can't remember how long
[02:17:45.920 --> 02:17:50.880]   i believe it was i believe it was but i apologize for not getting you on again soon i i was i was
[02:17:50.880 --> 02:17:56.240]   probably terrible so no i don't think it was i don't know you know you're more than welcome any
[02:17:56.240 --> 02:18:01.040]   i am the president of the mike maznick fan club too yeah i also thought you know it all because
[02:18:01.040 --> 02:18:06.560]   because you're so ry i do you're in the sky because you're right about things but you're so ry i
[02:18:06.560 --> 02:18:12.480]   thought you'd be a little growlier you're just you're really nice guy i have this yeah there's
[02:18:12.480 --> 02:18:20.560]   this weird thing where people who have not met me assume that i am uh much meaner uh than i uh
[02:18:20.560 --> 02:18:26.160]   actually seem to be well so i'm as like is this pin name the other thing i love about like is he
[02:18:26.160 --> 02:18:33.600]   is balanced he he backs up his his opinions with facts but he always attempts to be balanced and
[02:18:33.600 --> 02:18:39.680]   i think he saw that on the show today and gosh i hate that so uh yeah no it's really keeping us
[02:18:39.680 --> 02:18:44.640]   honest and all damn you it's uh it's a pleasure having you on mike we really appreciate it thanks
[02:18:44.640 --> 02:18:48.560]   for having me if people aren't regular uh readers detector listeners to the tector podcast you
[02:18:48.560 --> 02:18:54.240]   should be you're missing out you really really are ladies and gentlemen that concludes this week's
[02:18:54.240 --> 02:19:00.640]   thunder and lightning very very frightening edition of this week in google i'm glad you were here i
[02:19:00.640 --> 02:19:09.920]   think you probably are Dorothy Dorothy come back Dorothy so uh we do this show every every wednesday
[02:19:09.920 --> 02:19:18.320]   130 pacific four three eastern 2030 utc you can watch uh the craziness live with all of the copyright
[02:19:18.320 --> 02:19:25.120]   violations left in if you go to twit.tv/live there's audio and video there you can catch uh fully
[02:19:25.120 --> 02:19:32.720]   expregated versions of the show at twit.tv/twig on youtube of course as long as they'll leave it up
[02:19:32.720 --> 02:19:36.720]   and uh if you can't find it in all those places you know the best thing to do would be just fire up
[02:19:36.720 --> 02:19:41.840]   a podcast program uh launch your like pocket caster over make sure you subscribe don't just
[02:19:41.840 --> 02:19:49.440]   just listen subscribe subscribe get every episode we appreciate it thank you for being here well and
[02:19:49.440 --> 02:19:52.960]   stacy by the way good luck with your move she's not here this week because this is the day of the
[02:19:52.960 --> 02:19:59.920]   move i hope there's no lightning up her way in seattle but she'll be honest as it all i hope so
[02:19:59.920 --> 02:20:06.720]   that was scary that was really scary um so we'll be uh we'll be finding out how the move went next week
[02:20:06.720 --> 02:20:11.760]   on this week in google we'll see you then bye bye hi i'm jason howl host of all about android
[02:20:11.760 --> 02:20:16.240]   where each week i'm joined by ron richards florence ion and a rotating crew of android
[02:20:16.240 --> 02:20:21.520]   journalists developers and enthusiasts where we talk about the latest news hardware and apps
[02:20:21.520 --> 02:20:26.960]   for the android faithful you can subscribe by going to twit.tv/aa or find the show in your
[02:20:26.960 --> 02:20:40.800]   podcatcher of choice that's all about android

