;FFMETADATA1
album=This Week in Google
genre=Podcast
encoded_by=Uniblab 5.3
title=Thirsty Grindfluencer
language=English
artist=Leo Laporte, Jeff Jarvis, Stacey Higginbotham, Ant Pruitt
album_artist=TWiT
publisher=TWiT
track=724
date=2023
TRDA=2023-07-13
comment=<p>Threads launch, Amazon Prime Day, Anthropic&\#039\;s Claude AI, NotebookLM</p>\

encoder=Lavf60.3.100

[00:00:00.000 --> 00:00:02.720]   It's time for Twig this week in Google.
[00:00:02.720 --> 00:00:05.000]   Stacey, Ant, and Jeff are here.
[00:00:05.000 --> 00:00:10.000]   We're gonna talk about Threads 100 million users strong now.
[00:00:10.000 --> 00:00:13.000]   What does this mean for the Fediverse?
[00:00:13.000 --> 00:00:15.400]   We'll also talk about Amazon Prime Day.
[00:00:15.400 --> 00:00:19.800]   You won't believe how much money Amazon made yesterday.
[00:00:19.800 --> 00:00:23.600]   Oh, and by the way, it's just a little online boutique, right?
[00:00:23.600 --> 00:00:25.400]   That's what Amazon's telling the EU.
[00:00:25.400 --> 00:00:28.000]   All that and more coming up next on Twig.
[00:00:28.000 --> 00:00:30.600]   [MUSIC]
[00:00:30.600 --> 00:00:34.000]   Podcasts you love from people you trust.
[00:00:34.000 --> 00:00:35.000]   [MUSIC]
[00:00:35.000 --> 00:00:37.000]   This is Twig.
[00:00:37.000 --> 00:00:42.000]   [MUSIC]
[00:00:42.000 --> 00:00:44.000]   This is Twig.
[00:00:44.000 --> 00:00:51.000]   This week in Google, episode 724, recorded Wednesday, July 12th, 2023.
[00:00:51.000 --> 00:00:53.000]   Thirsty, grind-fluencer.
[00:00:53.000 --> 00:00:59.000]   This week at Google is brought to you by AG1. Take ownership of your health with a simpler,
[00:00:59.000 --> 00:01:05.000]   effective investment with AG1. Try AG1 to get a free one-year supply of vitamin D
[00:01:05.000 --> 00:01:09.000]   and five free AG1 travel packs with your first purchase of a subscription.
[00:01:09.000 --> 00:01:13.000]   Go to drinkag1.com/twig.
[00:01:13.000 --> 00:01:15.000]   And by "Twig."
[00:01:15.000 --> 00:01:19.000]   Thank you for listening. We're an ad-supported network, so that means we're always looking
[00:01:19.000 --> 00:01:23.000]   for new partners with products and services to benefit our audience.
[00:01:23.000 --> 00:01:28.000]   With our tailored host red ads, like this, you'll get an authentic and proper introduction
[00:01:28.000 --> 00:01:30.000]   to your brand with every ad read.
[00:01:30.000 --> 00:01:34.000]   You want to know more? Visit twit.tv/advertise
[00:01:34.000 --> 00:01:36.000]   and launch your campaign today.
[00:01:36.000 --> 00:01:37.000]   [MUSIC]
[00:01:37.000 --> 00:01:43.000]   It's time for Twig. This week in Google will show we get together with a couple of my favorite friends
[00:01:43.000 --> 00:01:47.000]   and talk about whatever the hell's on our minds.
[00:01:47.000 --> 00:01:53.000]   Stacey Higginbotham is here from Stacey on IoT and the IoT podcast with Kevin Tofol. Hi, Stacey.
[00:01:53.000 --> 00:01:55.000]   Hello, y'all.
[00:01:55.000 --> 00:01:58.000]   Hello. Good to see you.
[00:01:58.000 --> 00:02:04.000]   Also with us, Mr. Ant Pruitt of Hands-On Ant.
[00:02:04.000 --> 00:02:06.000]   Where did you get that shirt?
[00:02:06.000 --> 00:02:09.000]   I don't know. It was on the top of my stack and my closet.
[00:02:09.000 --> 00:02:10.000]   That's a great shirt.
[00:02:10.000 --> 00:02:11.000]   That's all it matters.
[00:02:11.000 --> 00:02:13.000]   Look at that. It says, "This week in tech."
[00:02:13.000 --> 00:02:15.000]   It's got the twit logo on it.
[00:02:15.000 --> 00:02:17.000]   It's quite nice on it. Do we sell those?
[00:02:17.000 --> 00:02:18.000]   I don't know. We should.
[00:02:18.000 --> 00:02:19.000]   It's nice.
[00:02:19.000 --> 00:02:21.000]   I mean, if you need a model, I'm your man.
[00:02:21.000 --> 00:02:22.000]   Yeah, okay.
[00:02:22.000 --> 00:02:24.000]   The only case.
[00:02:24.000 --> 00:02:25.000]   True.
[00:02:25.000 --> 00:02:26.000]   They only come in beefy.
[00:02:26.000 --> 00:02:27.000]   Size B.
[00:02:27.000 --> 00:02:28.000]   Size B.
[00:02:28.000 --> 00:02:31.000]   No, it'll just make you look like Ant.
[00:02:31.000 --> 00:02:33.000]   Are you an Arnold's pop club?
[00:02:33.000 --> 00:02:34.000]   Yes.
[00:02:34.000 --> 00:02:35.000]   This is through.
[00:02:35.000 --> 00:02:37.000]   Yeah, he's an Arnold's pop club.
[00:02:37.000 --> 00:02:39.000]   And also with us.
[00:02:39.000 --> 00:02:43.000]   Would you hand me the card? I can't read his intro without the card.
[00:02:43.000 --> 00:02:50.000]   Ladies and gentlemen, I give you Jeff Jarvis, the Leonard Taub Professor for journalistic innovation at the...
[00:02:50.000 --> 00:03:12.000]   ...
[00:03:12.000 --> 00:03:14.000]   ...
[00:03:14.000 --> 00:03:16.000]   ...
[00:03:16.000 --> 00:03:20.000]   ...
[00:03:20.000 --> 00:03:22.000]   ...
[00:03:22.000 --> 00:03:24.000]   ...
[00:03:24.000 --> 00:03:26.000]   ...
[00:03:26.000 --> 00:03:30.000]   ...
[00:03:30.000 --> 00:03:33.000]   ...
[00:03:33.000 --> 00:03:36.000]   ...
[00:03:36.000 --> 00:03:38.000]   ...
[00:03:38.000 --> 00:03:46.000]   ...
[00:03:46.000 --> 00:03:49.000]   ...
[00:03:49.000 --> 00:03:52.000]   ...
[00:03:52.000 --> 00:03:54.000]   ...
[00:03:54.000 --> 00:03:56.000]   ...
[00:03:56.000 --> 00:03:58.000]   ...
[00:03:58.000 --> 00:04:00.000]   ...
[00:04:00.000 --> 00:04:02.000]   ...
[00:04:02.000 --> 00:04:03.000]   ...
[00:04:03.000 --> 00:04:05.000]   ...
[00:04:05.000 --> 00:04:11.720]   No, but you know it's funny when I read it I do hear your voice when I read it, which is interesting. I think a good writer
[00:04:11.720 --> 00:04:16.180]   You kind of hear their voice when you're reading their prose
[00:04:16.180 --> 00:04:21.780]   They're text and I definitely hear your I hear your voice to Stacey when I read your yep website
[00:04:21.780 --> 00:04:26.300]   Bill that makes sense. I I write like I talk. Yeah
[00:04:26.300 --> 00:04:32.360]   Devorach taught me that he says I always he says I always read my stuff after I read my columns
[00:04:32.360 --> 00:04:37.420]   I read it out loud to see if it's in my voice and that's that's so funny as those to imagine Devorach
[00:04:37.420 --> 00:04:43.000]   Very distinctive voice
[00:04:43.000 --> 00:04:48.080]   So I guess we have to talk about threads because it launched
[00:04:48.080 --> 00:04:52.840]   Right after the show last week right in less than a week
[00:04:52.840 --> 00:04:56.000]   Almost as many listeners as his show has
[00:04:56.000 --> 00:04:59.200]   100 million users
[00:04:59.200 --> 00:05:01.600]   100
[00:05:01.600 --> 00:05:07.440]   Million users half on iOS and half on Android is best we can tell which is interest. Yeah
[00:05:07.440 --> 00:05:11.700]   Yeah, that is interesting because you know the brands are all on iOS and
[00:05:11.700 --> 00:05:14.920]   There there
[00:05:14.920 --> 00:05:22.640]   Holy yeah, what percentage of that hundred million is brands it felt like they were just waiting for somewhere to be
[00:05:22.640 --> 00:05:25.040]   what percentage of it was
[00:05:26.360 --> 00:05:32.320]   Met a nudging folks into getting into it versus people saying huh. I'm actually curious about this
[00:05:32.320 --> 00:05:34.160]   Let me go ahead and sign up
[00:05:34.160 --> 00:05:38.280]   Because I'm pretty sure my sister-in-law the nudge that's happening
[00:05:38.280 --> 00:05:42.280]   Yeah, my sister-in-law who's on Instagram
[00:05:42.280 --> 00:05:48.800]   Knew about it, which was unusual because normally no clue. Right. It's not it's not her thing
[00:05:48.800 --> 00:05:53.080]   But she hadn't signed up. She's oh, that's interesting
[00:05:54.160 --> 00:06:02.000]   Instagram does kind of incur encourage you think to join threads and this is the strength of it threads is a Twitter clone created by meta
[00:06:02.000 --> 00:06:05.480]   really created by the Instagram division of meta and
[00:06:05.480 --> 00:06:12.080]   Has taken off it's pretty obvious why it's taken off one because of Instagram
[00:06:12.080 --> 00:06:15.240]   Right and the sign up process very straightforward
[00:06:15.240 --> 00:06:20.240]   Maybe even too straightforward because you have to have your Instagram username is your yeah threads username
[00:06:20.240 --> 00:06:25.840]   Yeah, and it also brings over the people you follow and who follow you so you if you allow it
[00:06:25.840 --> 00:06:32.360]   And I'm sure most people do that's the default so you you kind of instantly have a group of people to follow that's one of the down sites
[00:06:32.360 --> 00:06:39.840]   To Twitter and even more so in Mastodon is if you could figure out how to get in and sign up then what?
[00:06:39.840 --> 00:06:48.200]   Which is why portability of your social graph is gonna be so important and and once things are really federated if they really are
[00:06:48.280 --> 00:06:54.040]   It opens the door for other small networks to start because you could have the starter kid or friends move over there
[00:06:54.040 --> 00:06:58.640]   Well, and that's an interesting point. We're gonna get to that actually because there are some
[00:06:58.640 --> 00:07:06.960]   Interesting mismatches in in the Fediverse and and and activity pub and threads
[00:07:06.960 --> 00:07:07.680]   but
[00:07:07.680 --> 00:07:16.480]   Threads also learned a lesson that meta wasn't available to meta or even Instagram when they launched which was the algorithmic feed the TikTok
[00:07:17.040 --> 00:07:24.240]   Style feed and so unless you take steps to avoid it and it's not not obvious how to do this when you are on threads
[00:07:24.240 --> 00:07:27.600]   It looks just like Twitter except you see people you're not following or in Minnesota
[00:07:27.600 --> 00:07:34.280]   There isn't and there is a non obvious way to fix that because that's the problem. I have with this platform
[00:07:34.280 --> 00:07:36.280]   it's pretty and
[00:07:36.280 --> 00:07:39.940]   And I'm not seeing a bunch of junk, but I'm also not seeing
[00:07:39.940 --> 00:07:43.760]   Things that I'm truly interested in I think for
[00:07:44.640 --> 00:07:51.260]   The beginning it's a good way to do it because you immediately have a feed that's full of stuff. Okay, and it's probably interesting
[00:07:51.260 --> 00:07:54.400]   Yeah, there's people to follow yeah, and so I there
[00:07:54.400 --> 00:07:59.440]   Masara Adam a sir who runs Instagram and is kind of the lead voice and this says yeah
[00:07:59.440 --> 00:08:04.520]   We're gonna have a what they call a following feed Twitter added that for you feed and the same thing
[00:08:04.520 --> 00:08:09.040]   It's horrible. It was the same idea and it all people learned this from TikTok even when
[00:08:09.040 --> 00:08:12.120]   YouTube started there wasn't really an algorithmic feed
[00:08:12.120 --> 00:08:16.800]   But what once everybody saw how effective that was on YouTube and then TikTok adopted it
[00:08:16.800 --> 00:08:20.040]   I think it's it's the it's the thing everybody does because you
[00:08:20.040 --> 00:08:26.120]   You know when you first in the early days Twitter you join it and then it's like well, okay now what there's nobody
[00:08:26.120 --> 00:08:29.960]   Yeah, I was like blue sky. I came to a party and nobody's there. Yeah, it's like blue sky
[00:08:29.960 --> 00:08:33.640]   So it really threads instantly feels like something's going on. Let me
[00:08:33.640 --> 00:08:37.960]   I'll show you how to I think I've been told how to do this. Let me turn on
[00:08:39.160 --> 00:08:42.240]   My screen mirroring so I'm gonna go to Airplay one
[00:08:42.240 --> 00:08:48.280]   Benito is spinning still but as soon as I could yeah, there it goes. So now let me show you
[00:08:48.280 --> 00:08:52.080]   I'll go into threads. Can you see my threads here?
[00:08:52.080 --> 00:08:55.360]   He's trying to still happen
[00:08:55.360 --> 00:08:59.880]   Takes a little while to get going so yeah all the brands
[00:08:59.880 --> 00:09:07.240]   So what was that and then the second part of the equation was everybody Elon's just been you know
[00:09:07.240 --> 00:09:12.400]   Driving driving the the airplane into the ground and so people were looking for it
[00:09:12.400 --> 00:09:17.680]   So this is this is threads right now. This is my threads by the way there is no desktop version
[00:09:17.680 --> 00:09:19.520]   That's where we had to airplay it from my iPhone
[00:09:19.520 --> 00:09:24.440]   Mm-hmm see it you can run it on desktop if you're running windows and you install Android
[00:09:24.440 --> 00:09:31.360]   The Android subsystem you have all Android. Yeah, my Chromebook is no problem. I want to be sure that's right. That's right
[00:09:31.360 --> 00:09:35.920]   so anyway, this is how you do it and you go to your account and
[00:09:36.480 --> 00:09:42.560]   The and you hit this menu in the upper right hand corner, which is settings. Okay, and then you go to notifications
[00:09:42.560 --> 00:09:45.280]   Okay threads and replies
[00:09:45.280 --> 00:09:45.840]   Okay
[00:09:45.840 --> 00:09:46.520]   and
[00:09:46.520 --> 00:09:52.560]   I'm told and I think it does work because it seems to be doing it from for me is you make everything for people you follow
[00:09:52.560 --> 00:09:58.440]   From people you follow from people you follow I don't want to see anything from anybody but people I follow
[00:09:58.440 --> 00:10:05.240]   Oh, but then I also have to turn on Android's notifications. No, you don't know no no cuz I don't yeah
[00:10:05.240 --> 00:10:08.440]   See I have my notifications paused. I don't I don't want notifications. Okay great
[00:10:08.440 --> 00:10:15.240]   But it see this is why it's not obvious that happens to change also what you're seeing now on threads except
[00:10:15.240 --> 00:10:19.680]   I am there you go. You saw the thing that was at the top is gone. That was somebody
[00:10:19.680 --> 00:10:24.280]   I wasn't following these are all people I'm following now. Okay, well, I meant not carnage for life. So maybe not
[00:10:24.280 --> 00:10:31.560]   Oh, no, that's because Alex Stamos who I do follow replied do it. So that is one thing that'll happen to see that
[00:10:32.120 --> 00:10:35.640]   Well, I don't care to see they'll give you a following only feed
[00:10:35.640 --> 00:10:43.000]   I agree, but but right now I'm only seeing stuff that is either people I follow or has been replied to her reread threaded
[00:10:43.000 --> 00:10:47.800]   I guess you call it by people I follow okay, so far I'm seeing that
[00:10:47.800 --> 00:10:57.080]   So it is a lot of brands. There's the New York Times NPR, which famously left Twitter after Elon accused it of being government funded media
[00:10:57.080 --> 00:11:00.320]   Immediately joined threads
[00:11:00.800 --> 00:11:07.120]   There's a lot of people who have been looking like Reuters there for for somewhere to be that's not tons of those kinds of places
[00:11:07.120 --> 00:11:09.720]   There's George to K right didn't show up on
[00:11:09.720 --> 00:11:17.480]   Mastodon yet. Yeah, it also does a good job with video you can see its Instagram heritage and I think you probably appreciate the images
[00:11:17.480 --> 00:11:19.580]   Look good. How good the images look images
[00:11:19.580 --> 00:11:23.680]   Plus the way it does the image slideshow you can do paren or amis with it
[00:11:23.680 --> 00:11:25.840]   Which is people have been playing with that a little bit
[00:11:25.840 --> 00:11:30.680]   So I haven't any images somebody read the book and they put up screenshots with things
[00:11:30.680 --> 00:11:36.720]   Underlined yeah, see that like six screenshots. Yeah, is that great?
[00:11:36.720 --> 00:11:40.400]   So so it's like a Twitter with a very good
[00:11:40.400 --> 00:11:42.600]   graphical
[00:11:42.600 --> 00:11:45.000]   Interface, you know for video and for
[00:11:45.000 --> 00:11:51.840]   For pictures. I don't think it does audio standalone yet and there are no there's no spaces
[00:11:52.120 --> 00:11:59.000]   There's no a lot of the features that we love here's Patrick Mahomes the quarterback for the Kansas City Chiefs
[00:11:59.000 --> 00:12:02.720]   I didn't expect I'm here following Patrick Mahomes, but looks like you are
[00:12:02.720 --> 00:12:10.800]   You know why because this was his first tweet was a video of him going I'm here. I'm here. I'm here
[00:12:10.800 --> 00:12:17.040]   And I thought okay, I'm gonna follow you just because of that notice by the way these plus signs
[00:12:17.360 --> 00:12:22.280]   There's Jim Costas. I can't make that bigger, but there's a little plus sign in his head if I
[00:12:22.280 --> 00:12:28.840]   And this is also smart. I'm looking at this feed. I go. Oh, you know, I didn't know Jim Costa of CNN was here
[00:12:28.840 --> 00:12:35.560]   I could just tap it follow him and so it's very easy to add people your followers. So I think that this is
[00:12:35.560 --> 00:12:40.280]   It's cleverly done. It's I think it's well done now. Here's the question
[00:12:40.280 --> 00:12:44.600]   Okay, first of all did this rehabilitate Zuck
[00:12:45.640 --> 00:12:48.000]   Some people are calling it sucks 2.0. I
[00:12:48.000 --> 00:12:54.640]   Didn't want to join this and I haven't joined it because I don't like the data grab that's happening
[00:12:54.640 --> 00:13:01.040]   I hate being like I'm not on Facebook like I'm not either. Yeah, yeah
[00:13:01.040 --> 00:13:04.880]   I'm not I am on Instagram, but I'm I don't have the app downloaded
[00:13:04.880 --> 00:13:10.120]   I have none of this because I don't want to be part of that and I was kind of shocked at all these people are like
[00:13:10.120 --> 00:13:11.320]   Wow, there's so many people
[00:13:11.320 --> 00:13:18.180]   I'm like, can we not talk about like how Europe's like mmm? That's doesn't really handle privacy to the point where we're comfortable with it
[00:13:18.180 --> 00:13:19.160]   It's a little different
[00:13:19.160 --> 00:13:23.520]   It's threads saying we don't want to be in Europe because we are concerned about
[00:13:23.520 --> 00:13:26.000]   the data
[00:13:26.000 --> 00:13:31.380]   Rules in Europe and we don't want to deal with that yet. So it's not Europe saying you can't be here
[00:13:31.380 --> 00:13:36.160]   It's threads saying well, right? Well, is Europe saying you need to abide by these rules in
[00:13:36.800 --> 00:13:42.000]   I don't know if I want to play your game. Yeah, and that's not clear by the way that that's not gonna that
[00:13:42.000 --> 00:13:47.520]   They're not gonna figure that out change because it can't really I mean not being in Europe is a big deal, right?
[00:13:47.520 --> 00:13:56.680]   For for any social yeah, I think so, but here's the data link to you grabbing a lot of data. Yeah, here's the here's the data
[00:13:56.680 --> 00:14:03.520]   This is thank you Apple because Apple does force companies to publish this including health and fitness
[00:14:03.520 --> 00:14:05.680]   financial info
[00:14:05.680 --> 00:14:07.480]   Contact info
[00:14:07.480 --> 00:14:11.120]   browsing history usage data diagnostics purchases location
[00:14:11.120 --> 00:14:15.400]   Contact search history identifiers sensitive info and other data
[00:14:15.400 --> 00:14:23.880]   In other words everything mmm everything. Yeah, that's a lot of data that and I'm not Facebook is not I
[00:14:23.880 --> 00:14:29.080]   Mean I know it's Facebook. I know they're grabbing everything they can but that's why I got off Facebook in the first place
[00:14:29.080 --> 00:14:32.840]   So I'm kind of like yeah, maybe I'm just not a well
[00:14:32.840 --> 00:14:39.440]   Where is the outcry from the masses about this collection? I think people were so desperate for replacement to Twitter
[00:14:39.440 --> 00:14:43.040]   Okay, we'll just give it all
[00:14:43.040 --> 00:14:47.640]   Our job is journalists
[00:14:47.640 --> 00:14:48.680]   We're all lakes
[00:14:48.680 --> 00:14:55.880]   I think we're sitting down on the job because we're not explaining this to people and I also think people don't understand the risk to
[00:14:55.880 --> 00:15:01.760]   They're I'm actually writing about risk and data privacy right now, and it's a frickin nightmare cuz yeah, but Stacy
[00:15:01.760 --> 00:15:06.360]   It's a lot most people a lot of people do what I did so well
[00:15:06.360 --> 00:15:10.040]   I won't have Facebook on my phone, but I then put Instagram or what's app on their phone, huh?
[00:15:10.040 --> 00:15:17.080]   Right do you have what's app on your I am I do have what's up on but what's app is encrypted and no no no
[00:15:17.080 --> 00:15:20.080]   What's up action no no no no no no no
[00:15:20.080 --> 00:15:25.440]   Look at the health look at the health notice and what's app on the I for well you don't have an iPhone
[00:15:25.440 --> 00:15:29.100]   But I don't know I feel good the app itself is grabbing the same information
[00:15:29.840 --> 00:15:31.840]   David Leo
[00:15:31.840 --> 00:15:42.880]   But most people most normal people are already giving meta all that information anyway
[00:15:42.880 --> 00:15:48.520]   Can you get in touch with all of these Congress folks out here and share that screen that you just share with our Twitter folks because
[00:15:48.520 --> 00:15:54.280]   All of their worried about all their worried about his tick-tock and what it's that hysterical and this is this yeah
[00:15:54.280 --> 00:15:56.280]   Just this egregious right so
[00:15:57.080 --> 00:16:02.480]   That does bring me to to the second point which is this is I think good for the Fediverse
[00:16:02.480 --> 00:16:09.560]   Because for somebody like you Stacy you could you could put a mastodon app for instance on your phone
[00:16:09.560 --> 00:16:15.280]   And if you look at the the privacy card for Mastodon zero nothing
[00:16:15.280 --> 00:16:21.880]   right and and this is the beauty part thanks to if and and well this will be a good question if they do this if
[00:16:21.880 --> 00:16:24.840]   Threads goes ahead and and as they have promised
[00:16:25.720 --> 00:16:27.720]   incorporates activity pub
[00:16:27.720 --> 00:16:31.800]   Then you could follow let's say you did want to follow Patrick Mahomes
[00:16:31.800 --> 00:16:38.280]   He's on threads. It's not on Mastodon. Mm-hmm. You could follow on your Mastodon and since get all of his threads
[00:16:38.280 --> 00:16:42.520]   He could follow you from from Twitch social our Mastodon
[00:16:42.520 --> 00:16:46.400]   I don't know any other Mastodon since not any other because a few have said we're not gonna have anything to do with this
[00:16:46.400 --> 00:16:47.920]   But the the ones that are not
[00:16:47.920 --> 00:16:52.840]   Defederating meta and and you would have a perfect back and forth conversation
[00:16:52.840 --> 00:16:57.240]   I was gonna work as I heard you talk about it briefly on on the show Sunday
[00:16:57.240 --> 00:17:04.320]   Like what is meta getting out of not joining an activity pub nothing so it goes against their business
[00:17:04.320 --> 00:17:11.160]   Logic right it kind of maybe if you want to like really screw Elon Musk this would be a good way to do it
[00:17:11.160 --> 00:17:14.520]   So here's an interesting post from the new stack better PR
[00:17:14.520 --> 00:17:19.680]   This is Richard McManus writing threads adopting activity pub makes sense
[00:17:19.840 --> 00:17:23.760]   But it won't be easy and I'll go to his is conclusion. It's early days
[00:17:23.760 --> 00:17:30.560]   But in my humble experience Richard McManus senior editor of the new stack writes threads feels like a text-based version of Instagram
[00:17:30.560 --> 00:17:39.800]   That's accurate the content is a mix of aspirational and motivational and the current algorithmic timeline is peppered with celebrities and influencers peddling their memes
[00:17:39.800 --> 00:17:45.040]   Perhaps the biggest challenge integrating with Fediverse apps like Mastodon will be the cultural differences
[00:17:45.360 --> 00:17:50.720]   Between the two communities, but but I'm not worried about that because it's like parallel rivers
[00:17:50.720 --> 00:17:57.560]   Just because you tap into something from one doesn't mean the whole river comes through that okay pipeline. She said I
[00:17:57.560 --> 00:18:04.240]   Hope meta does successfully adopt the protocol so that Mastodon users like me can add a few thread users to their feeds
[00:18:04.240 --> 00:18:10.280]   The ideal outcome would be a bunch of new apps getting built that tap into both Mastodon and thread social graphs
[00:18:11.240 --> 00:18:14.560]   But he does say it's in the interest of meta
[00:18:14.560 --> 00:18:22.840]   He's promised it and meta has actually put a software engineer Ben Savage on the activity pub working group in the W3C
[00:18:22.840 --> 00:18:29.640]   They have continued to make the steps that they would need to make there are some technical issues
[00:18:29.640 --> 00:18:36.000]   But I think at this point they've really promised that they would do this it doesn't let's face it
[00:18:36.000 --> 00:18:38.240]   does it hurt meta if
[00:18:39.120 --> 00:18:44.280]   Stacey who's never gonna have threads on her phone follows Patrick Mahomes on
[00:18:44.280 --> 00:18:51.080]   Mastodon it actually helps it makes threads more valuable to Patrick Mahomes exactly because he can get more people
[00:18:51.080 --> 00:18:59.240]   Exactly, okay, and maybe right all those brands will be super thrilled sure and maybe even at Patrick Mahomes at threads. Net
[00:18:59.240 --> 00:19:06.060]   Notice you know somebody a mess and it says always on threads and goes over and follows a month read it doesn't hurt
[00:19:06.060 --> 00:19:12.580]   It doesn't suck enough day enough people for a way. Mm-hmm. Those are people like you may Stacy who would never join it in the first place
[00:19:12.580 --> 00:19:20.420]   Right here's the thing to that for the business perspective is that a brand that's gonna be scared of going on Mastodon
[00:19:20.420 --> 00:19:24.780]   Or just simply not understanding it. Yeah, they get it for free threads. Yeah, and
[00:19:24.780 --> 00:19:28.460]   You know if you want to complain about your Delta flight
[00:19:28.460 --> 00:19:34.340]   Then you'll do it through threads and they'll and that's how they'll you know kind of recapture that old threat Twitter
[00:19:34.900 --> 00:19:42.060]   Service angle, okay. Yeah, they wouldn't have to follow so that's interesting and we know that's kind of an unknown if I at reply
[00:19:42.060 --> 00:19:47.260]   Delta on Mastodon do they see it on threads not clear?
[00:19:47.260 --> 00:19:53.680]   It that could be implemented that way and it might not be I would hope it would I would hope it would be and I think you're right
[00:19:53.680 --> 00:19:58.720]   There's a man like yeah, I think yeah, I think and charge like API access
[00:19:58.720 --> 00:20:01.440]   No, right because this activity put activity put okay
[00:20:02.260 --> 00:20:08.700]   So here's the here's another contrarian point of view that will make you feel better Stacy from the jog blog
[00:20:08.700 --> 00:20:14.660]   Jog is Jason O Gilbert Facebook's threads is so depressing. I saw like a
[00:20:14.660 --> 00:20:17.100]   $19 turkey sandwich at an airport
[00:20:17.100 --> 00:20:22.140]   God I could he writes threads is depressing. I couldn't click on it
[00:20:22.140 --> 00:20:25.740]   Well, you're gonna get it anyway, cuz I'm gonna read it to you
[00:20:25.740 --> 00:20:29.820]   Every part of threads existence makes me shake my head
[00:20:30.300 --> 00:20:36.140]   Twitter selling itself to Elon Musk because he offered a stupid high price Elon Musk properly ruining Twitter
[00:20:36.140 --> 00:20:43.860]   So badly that any alternative looks palatable even one run by mark my other platform enabled a little literal genocide
[00:20:43.860 --> 00:20:51.220]   Zuckerberg he's talking about me and more the bland market tested design the thirsty grind
[00:20:51.220 --> 00:20:53.560]   Fluencers by the way, I'm adding that to my
[00:20:56.980 --> 00:21:04.920]   And thirsty grind flanzers. Yeah. Yeah, those are the ones who are influencers who are grinding hard to create thirsty
[00:21:04.920 --> 00:21:08.220]   Content so you will follow them going to update my profile
[00:21:08.220 --> 00:21:16.980]   Posting well, it's not a done there's the thirsty grind flanzers posting with the energy of a puppy with zoomies
[00:21:16.980 --> 00:21:24.740]   The looming heavy breathing presence of suck the corporateness of it all
[00:21:25.340 --> 00:21:28.940]   Just all of it man every part of it sucks
[00:21:28.940 --> 00:21:31.540]   Here's Johnny bones
[00:21:31.540 --> 00:21:39.140]   Threading what's up everyone to which sucks is one thing that's up is the number of world champion MMA fighters on threads
[00:21:39.140 --> 00:21:41.740]   especially now that you're here
[00:21:41.740 --> 00:21:45.060]   Yeah, it does make me kind of herb up in my mouth
[00:21:45.060 --> 00:21:54.700]   What does threads feel like he says Johnny John O Gilbert threads feels like when a local restaurant you enjoy opens a location in an airport
[00:21:54.700 --> 00:22:00.380]   Oh, it feels like a Twitter alternatives one one post
[00:22:00.380 --> 00:22:06.820]   Show us pick the best okay. It feels like a Twitter alternative you would order from Brookstone
[00:22:06.820 --> 00:22:16.860]   It feels like if an entire social network was those posts that tell you what successful entrepreneurs do before 6 a.m
[00:22:16.860 --> 00:22:18.980]   You know
[00:22:18.980 --> 00:22:24.060]   See why did he put this this headline on here because if it'd been something else I probably would have read
[00:22:24.060 --> 00:22:30.740]   It's very funny it feels like watching a PowerPoint from the brand research team where they tell you that pop tarts is
[00:22:30.740 --> 00:22:33.220]   crushing it on social
[00:22:33.220 --> 00:22:37.660]   It feels like casual Friday on LinkedIn we've seen those
[00:22:37.660 --> 00:22:45.500]   Then here's a here's a he's
[00:22:45.500 --> 00:22:51.860]   Really dresses this up with some actual threads. Here's mark Cuban posting what up mr. Beast
[00:22:52.700 --> 00:22:58.540]   To which Jake Paul says giving five thousand dollars to someone who re threads this
[00:22:58.540 --> 00:23:01.180]   To which Gary V replies
[00:23:01.180 --> 00:23:03.820]   focused as if
[00:23:03.820 --> 00:23:11.300]   And then apparently posts a emoji that cannot be reproduced so I was like is that a question mark like no
[00:23:11.300 --> 00:23:16.220]   Gary V Gary V ever asked questions. Yeah, you know only give us only statements only
[00:23:16.220 --> 00:23:18.140]   why
[00:23:18.140 --> 00:23:24.460]   Wow currently there's no way to only see posts from the people you're following continues jog you click on your home page
[00:23:24.460 --> 00:23:25.420]   You hear friends are up
[00:23:25.420 --> 00:23:29.820]   But guess what it's time for an epic meme from the official sales force account
[00:23:29.820 --> 00:23:34.780]   As young Sheldon once said bazinga
[00:23:34.780 --> 00:23:41.940]   So it's a it's really here's some more backstreet boys. Oh my god. We're back again
[00:23:41.940 --> 00:23:47.060]   McDonald's hi from Grimace say it back, please
[00:23:48.060 --> 00:23:50.620]   Ellen DeGeneres welcome to gay Twitter
[00:23:50.620 --> 00:23:52.780]   Netflix
[00:23:52.780 --> 00:23:57.900]   Threads is kind of like love is blind because everybody is all about the engagement
[00:23:57.900 --> 00:24:06.900]   Oh my god, I didn't turn. Oh my god, you know, it's funny because there's so much of this like brand content trying really hard to
[00:24:06.900 --> 00:24:12.580]   To do outdo everybody else thirsty grind fluencing thirsty cry fluencing and
[00:24:14.180 --> 00:24:18.860]   It I for some reason I can see behind the brand to exactly what you just said
[00:24:18.860 --> 00:24:25.180]   Jeff, it's like I can see some you know 20 something. Mm-hmm saying. Oh, yeah
[00:24:25.180 --> 00:24:27.700]   I got the Wendy's account. I'm so excited on it
[00:24:27.700 --> 00:24:32.940]   And so in a way, it's more personal
[00:24:32.940 --> 00:24:39.940]   Than a brand to me like I see the person behind the brand and it's kind of funny, you know anyway
[00:24:39.940 --> 00:24:43.940]   Those tips you gave me about potentially that fix it. No
[00:24:44.260 --> 00:24:50.500]   When I sense I've refreshed it takes a while maybe it's back. No, it's back to show me all of these plus marks
[00:24:50.500 --> 00:24:54.940]   I know and but but be patient because I think it takes a while to take okay
[00:24:54.940 --> 00:24:59.500]   I think it does actually work in fact that was I was kind of not following Google
[00:24:59.500 --> 00:25:06.020]   I had the same experience in Google, but I'm not following Google anything. What does Google say anything interesting is cereal soup
[00:25:10.340 --> 00:25:13.120]   Is a hot dog a sandwich? I don't know
[00:25:13.120 --> 00:25:17.500]   Stuff and it has a hundred and twenty two replies
[00:25:17.500 --> 00:25:25.900]   Yeah, people love those questions, but you can't so I can understand why a brand wouldn't isn't gonna want to post that
[00:25:25.900 --> 00:25:32.740]   Inanity on Twitter anymore. No, cuz they're gonna say will our white people supreme? Oh, yeah, you know
[00:25:32.740 --> 00:25:39.020]   It's gonna it's you don't even it's gonna evolve so I think brands were thirsty for this. Oh, yeah
[00:25:39.020 --> 00:25:44.380]   I saw a story. I didn't put it in the rundown. Oh, I was all story. Just saying exactly that the headline was the brands can't wait
[00:25:44.380 --> 00:25:47.340]   Oh, they're so happy. I'm from Alberta. They're so happy
[00:25:47.340 --> 00:25:56.620]   He says the vibes on threads are bad. Have you ever been high or drunk and you walk into a CVS and the security guard is staring at you?
[00:25:56.620 --> 00:26:02.460]   Just maintain everybody that that's speaking once
[00:26:02.460 --> 00:26:06.100]   That's what threads is
[00:26:06.100 --> 00:26:13.340]   It's deodorants locked behind plastic. It's tiktok. Hype houses. It's Joe Biden's re-election campaign
[00:26:13.340 --> 00:26:21.980]   It's a sneaker collab between Nike and JP Morgan. It's your favorite stand-up comic showing up in a commercial for Carvanna
[00:26:21.980 --> 00:26:25.460]   Okay
[00:26:25.460 --> 00:26:30.060]   It's better than Twitter of course needs an editor. No, I think it's great. I love it
[00:26:30.060 --> 00:26:33.060]   It's better than Twitter. Of course, maybe I was his editor. Maybe that's why
[00:26:34.100 --> 00:26:40.780]   Which has Berlin 1937 vibes this this guy has no chill. He just needs like a little
[00:26:40.780 --> 00:26:45.620]   Yes, it's funny
[00:26:45.620 --> 00:26:50.620]   Some of it, okay. He is funny, but then he like keeps going like yeah
[00:26:50.620 --> 00:26:57.460]   You gotta be funny is knowing when to stop Jeff and I are my god Jeff you and I same page still agreeing this week
[00:26:57.460 --> 00:26:59.460]   Something's wrong
[00:26:59.460 --> 00:27:02.140]   Something's very wrong here
[00:27:02.460 --> 00:27:07.480]   Final story Twitter Twitter is so threatened by this that they're threatening to sue
[00:27:07.480 --> 00:27:13.740]   The intellectual property property of all the any of those no, of course not
[00:27:13.740 --> 00:27:18.540]   Plus these were employees who left well you fired them
[00:27:18.540 --> 00:27:25.580]   Yeah, you fire people. Yeah, they're extra motivated to go. So you know, I'm but didn't give them the severance
[00:27:25.580 --> 00:27:32.260]   Yes, I don't compete there. They could you know the threads has been very clear. No, there's no former Twitter employees
[00:27:32.260 --> 00:27:37.540]   Working on this product, but if if there were sure some would volunteer what would be wrong at that
[00:27:37.540 --> 00:27:47.380]   You know Elon fires you denies you severance and then gets upset that you go to work for meta my question the lawyer or
[00:27:47.380 --> 00:27:52.700]   A group of lawyers that decided to send that information over to meta
[00:27:52.700 --> 00:27:58.460]   Did they actually send that thinking okay Twitter has a leg to stand on in this situation?
[00:27:58.460 --> 00:28:03.740]   I think they just stick to check. I think they said you're gonna pay us an advance. Yes. Yeah, just stick to check
[00:28:03.740 --> 00:28:06.180]   Okay, all right cool cuz that's the other thing
[00:28:06.180 --> 00:28:11.780]   No one wants to work for Elon because he doesn't pay his bills right right? He didn't yeah
[00:28:11.780 --> 00:28:16.020]   So Larry Ellison gave him a billion dollars of Oracle. Mm-hmm
[00:28:16.020 --> 00:28:21.860]   But he's not paying his Oracle bill like this guy will Elon will bite the hand to feed you. He's another Trump, right?
[00:28:21.860 --> 00:28:26.100]   So I wouldn't work for him for free. I'd make sure I got the money up front
[00:28:27.300 --> 00:28:36.180]   Anyway, yeah, that's ironic. He's here's another one. He's suing Wachtel the law firm the Twitter hired to make him buy Twitter
[00:28:36.180 --> 00:28:40.300]   Because
[00:28:40.300 --> 00:28:44.380]   He's he's suing them because as the Twitter board left
[00:28:44.380 --> 00:28:51.980]   They gave they paid Wachtel 90 million dollars. They said thank you. He just paid 44 billion. You made him pay
[00:28:52.220 --> 00:28:59.980]   Here's your money Elon who is required by the way to pay them the when you buy a company you absorb all their
[00:28:59.980 --> 00:29:02.420]   contracts
[00:29:02.420 --> 00:29:07.660]   Is furious that he they got paid 90 million so he's suing them to get the money back
[00:29:07.660 --> 00:29:14.340]   He's so Trump I I don't you know, I'm actually starting to worry about his mental health
[00:29:14.340 --> 00:29:16.380]   I think there's something bad going on to be honest
[00:29:16.380 --> 00:29:21.660]   But anyway, I think it's people realize that there actually are no real consequences to behaving
[00:29:22.660 --> 00:29:24.260]   and
[00:29:24.260 --> 00:29:26.700]   if you realize that then
[00:29:26.700 --> 00:29:33.660]   Sure, why wouldn't you? Yeah, yes douche day on twig another we've ever used that word before
[00:29:33.660 --> 00:29:38.700]   Well, it is Wednesday, but okay, we can do the show on douche day if you want
[00:29:38.700 --> 00:29:44.460]   All right, I want to take a I guess we could take a little break. Can I mention one thing? I'm exhausted
[00:29:44.460 --> 00:29:47.260]   That's the note we're gonna end on
[00:29:47.260 --> 00:29:55.420]   I am so ashamed I think it's a show title personally. What were you saying? Mr. Jarvis?
[00:29:55.420 --> 00:29:57.780]   Well, I just I just wanted to note
[00:29:57.780 --> 00:30:04.060]   Have you looked at the at the alternative algorithms on blue sky recently?
[00:30:04.060 --> 00:30:11.020]   You mean the loose guy those are lists list. Yeah, the list. Yeah, I know they like to go with blue sky
[00:30:11.020 --> 00:30:17.540]   You know a bluesy so this is to me that in ways a sad thing is that bye-bye T2 blue sky spill
[00:30:17.540 --> 00:30:22.340]   Which was gonna be the new my Twitter you think I'll continue on I think there's a lot of oil
[00:30:22.340 --> 00:30:24.900]   It was I wish to me I wish to more loyalty to it
[00:30:24.900 --> 00:30:29.820]   So there's all kinds of weird less than there, right? It's or let me let me look here
[00:30:29.820 --> 00:30:35.060]   So here I am on blue sky this there's furries and you go to you go to my feeds the left my feeds
[00:30:35.060 --> 00:30:40.100]   And then you notice a setting is on the upper right and the upper right. This is the ones I'm following
[00:30:40.500 --> 00:30:46.420]   Discover a new fan then there's some other feeds that people created what science what's hot classic?
[00:30:46.420 --> 00:30:48.380]   black sky
[00:30:48.380 --> 00:30:50.380]   home plus
[00:30:50.380 --> 00:30:55.020]   But there's things like furries as you keep it going down of course are you surprised Jeff?
[00:30:55.020 --> 00:30:58.140]   Not at all new skis
[00:30:58.140 --> 00:31:04.340]   Which is not about bacon, but a first post from new users or about news and or about news art
[00:31:04.340 --> 00:31:08.340]   There's a lot of stuff in gardening Japanese cluster
[00:31:08.860 --> 00:31:16.160]   There's one that's just a picture a better film feed for movie lovers film sky
[00:31:16.160 --> 00:31:19.740]   Yeah, this is interesting. I mean these are lists, right? That's all they are
[00:31:19.740 --> 00:31:23.420]   Yeah, but what it shows is the possibility. I think of
[00:31:23.420 --> 00:31:26.100]   rate your own
[00:31:26.100 --> 00:31:26.620]   algorithms
[00:31:26.620 --> 00:31:29.780]   Yeah, I think that's and so I could imagine
[00:31:29.780 --> 00:31:37.980]   Blue sky being really good at this and ant sane finally my people are here my photography and football and dad people are all here
[00:31:37.980 --> 00:31:43.580]   Because I can finally find them. Do you think maybe what'll happen is we'll have niche?
[00:31:43.580 --> 00:31:49.300]   Social networks that the blue sky will be for certain certain eventually become for a certain kind of person
[00:31:49.300 --> 00:31:53.860]   I hope not because wouldn't that be a bit of an echo chamber and
[00:31:53.860 --> 00:32:01.940]   Well people want echo put us right down the road that we're going right now far as all of the the stuff that you see on the Twitter verse and
[00:32:01.940 --> 00:32:06.500]   Nobody ever sees all of Twitter as
[00:32:07.580 --> 00:32:13.860]   Right no two people see the same Twitter you the and so the idea of trending is so ridiculous because
[00:32:13.860 --> 00:32:21.780]   Probably the biggest trend is a tiny tiny percentage point zero zero zero something of the total of Twitter
[00:32:21.780 --> 00:32:26.820]   We're all seeing a tiny window and it's better if we do actually you don't want to see everything
[00:32:26.820 --> 00:32:31.580]   Okay, that's what people get mad when you see too much. So no, I think we're already there, yeah
[00:32:31.580 --> 00:32:35.340]   Okay, people also don't want to post to 15 different social no
[00:32:36.060 --> 00:32:39.420]   That's why there's tools out there. So you don't have to do that. I guess
[00:32:39.420 --> 00:32:46.780]   Brands have to use those tools like Hootsuite and stuff, but if there's an API if there's an API if you're a normal
[00:32:46.780 --> 00:32:52.860]   You pick one eventually or no, do you think what do you think that that threads has no hashtags?
[00:32:52.860 --> 00:32:59.100]   Yeah, I tried that out just to see if the past has no good work they say they're gonna add that too
[00:32:59.940 --> 00:33:06.700]   If you are an android you can turn on the beta version of the threads app and some of those features will appear cool
[00:33:06.700 --> 00:33:09.260]   Because they're trying them out
[00:33:09.260 --> 00:33:11.900]   I
[00:33:11.900 --> 00:33:15.300]   Think they'll probably have much of the features that they they have
[00:33:15.300 --> 00:33:21.420]   Quote tweets, which is something Mastodon has refused so far. Yeah, and that's been used to good purpose
[00:33:21.420 --> 00:33:25.580]   I think on threads. I think the quote tweets are good. I wonder what their moderation
[00:33:25.580 --> 00:33:28.620]   strategy is because
[00:33:28.660 --> 00:33:32.660]   You know when when musk came around for for Twitter his whole
[00:33:32.660 --> 00:33:34.460]   free speech
[00:33:34.460 --> 00:33:38.780]   Pitch was big, but he also talked a lot about you know how many bots are here
[00:33:38.780 --> 00:33:44.700]   That was like his reason for not wanting to buy was because of all of the bots and he said he's gonna fix this and that but
[00:33:44.700 --> 00:33:50.980]   I haven't heard any mention about bots on threads even though my feed had a ton of them
[00:33:50.980 --> 00:33:57.780]   Were they bots or brands bots not brands like just random huh?
[00:33:58.060 --> 00:34:00.980]   Joe 98743 star
[00:34:00.980 --> 00:34:04.020]   With gibberish on it or even nothing at all
[00:34:04.020 --> 00:34:08.100]   Well, that's it see that's a thing that it's you know
[00:34:08.100 --> 00:34:13.980]   Instagram has that new car smell, but that's gonna wear off pretty darn. I mean threads as that car smell as well
[00:34:13.980 --> 00:34:20.060]   We're off pretty quick. Isn't it? You should just call it Instagram cuz that's it really is it is it is
[00:34:20.060 --> 00:34:24.140]   It's what happens when people stop. I mean like
[00:34:25.180 --> 00:34:31.180]   It feels so thrown together. Is this like something Facebook's really gonna be behind for the next year? Well, they are now
[00:34:31.180 --> 00:34:35.180]   That's the fat. It's the fastest app launch in history
[00:34:35.180 --> 00:34:38.820]   Yeah, I think it's it. It's a thumb in the eye to
[00:34:38.820 --> 00:34:42.340]   Musk it's an opportunity to grab advertising
[00:34:42.340 --> 00:34:45.900]   revenue from there when they figure out how to do that and it's really have
[00:34:45.900 --> 00:34:47.740]   facilitated
[00:34:47.740 --> 00:34:50.220]   Zach right. Oh, yeah, I think so
[00:34:50.220 --> 00:34:53.900]   Nobody's talking about his failed metaverse. Nobody's talking about
[00:34:54.780 --> 00:34:58.860]   uh, you know Facebook well, some people are talking about Facebook and genocide, but
[00:34:58.860 --> 00:35:00.540]   um
[00:35:00.540 --> 00:35:04.380]   Yeah, it's a great piece and the which you'll get to later in the rundown about about um
[00:35:04.380 --> 00:35:06.940]   Facebook of the metaverse
[00:35:06.940 --> 00:35:12.460]   Uh, yeah, it makes you forget that. Yeah, you I saw your uh, your thread about that as a matter of fact and that
[00:35:12.460 --> 00:35:19.260]   Bookmarked it because of it. All right. Now we can take a break now that Stacy has provided a buffer between douche day
[00:35:19.260 --> 00:35:23.580]   Oh wait a minute. I said it. That's not how it works, sir, but
[00:35:23.580 --> 00:35:25.580]   Oh
[00:35:25.580 --> 00:35:27.580]   Gotta go on for another
[00:35:27.580 --> 00:35:34.060]   That's interesting if I every if I every time I say douche day we have to do another five minutes on the show
[00:35:34.060 --> 00:35:40.380]   That's interesting. Oh my gosh. That would be like my literal night. Oh, that's so much fun. Imagine. We're almost at the end
[00:35:40.380 --> 00:35:44.940]   Stacy can see the waffle. Oh, let me say douche day
[00:35:44.940 --> 00:35:50.300]   Oh, that would be the worst and it came for me initially
[00:35:50.300 --> 00:35:56.860]   It's the reset button and it's where we do that she accuses us of being douches and it just it's a beautiful
[00:35:56.860 --> 00:36:00.940]   You know what you need right now, Stacy? You need a refreshing
[00:36:00.940 --> 00:36:03.900]   beverage a nutritional
[00:36:03.900 --> 00:36:12.940]   Supplement that will make you feel good that will make your blood go through your body and and they'll put little happy faces on all the cells
[00:36:12.940 --> 00:36:18.620]   I'm talking about our sponsor hg1 the daily foundational nutrition
[00:36:19.180 --> 00:36:25.340]   Supplement that supports whole body health and I will editorialize here and tastes great. I love it
[00:36:25.340 --> 00:36:30.940]   That I think it was you aunt told me about ag1 through a science driven formulation of vitamins
[00:36:30.940 --> 00:36:35.820]   probiotics whole food sourced nutrients ag1 delivers
[00:36:35.820 --> 00:36:43.500]   comprehensive support for the brain gut and immune system just mixed your ag1 scoop with 12 ounces of water
[00:36:43.500 --> 00:36:45.580]   I start my day with it since 2010
[00:36:46.060 --> 00:36:52.780]   ag1 has improved their formula 52 times in the constant pursuit of making the best
[00:36:52.780 --> 00:36:55.420]   foundational nutrition supplement
[00:36:55.420 --> 00:37:02.220]   Possible with high quality ingredients and rigorous standards ag1 has become a part of millions of daily routines
[00:37:02.220 --> 00:37:06.380]   They save you money each serving costs less than three dollars a day when you subscribe
[00:37:06.380 --> 00:37:13.980]   ag1 ag1 makes it easier for you to drink the highest quality supplements whether it's improving digestion
[00:37:14.460 --> 00:37:17.340]   Or supporting you with sleep ag1 is the best bang
[00:37:17.340 --> 00:37:22.380]   For your buck with just one scoop ag1 is a simple drinkable
[00:37:22.380 --> 00:37:26.460]   Daily habit. I like it so much now. I actually look forward to it
[00:37:26.460 --> 00:37:29.180]   It's like I jump out a bit going. Oh, gotta go get my ag1
[00:37:29.180 --> 00:37:37.180]   So if you're looking to take ownership of your health with a simpler effective investment start with ag1 try ag1 to get a free one
[00:37:37.180 --> 00:37:42.940]   Year supply of vitamin d and I love these travel packs five free ag1 travel packs
[00:37:43.420 --> 00:37:49.100]   With your first purchase of a subscription go to drink ag1.com/twig
[00:37:49.100 --> 00:37:51.580]   go to drink
[00:37:51.580 --> 00:37:57.420]   ag1.com/twig and check it out
[00:37:57.420 --> 00:38:05.420]   Ag1 appreciate them sending us to travel paths because hard hit those great and the family went back yeast to go visit
[00:38:05.420 --> 00:38:09.900]   Relatives and hard hit tried to take my container of ag1
[00:38:10.620 --> 00:38:13.580]   No, dude, that's not yours. No, that's not just worse
[00:38:13.580 --> 00:38:19.900]   It's like what I gotta take my ag1. I said the travel pack so you're not taking old dad gum jar
[00:38:19.900 --> 00:38:21.820]   go strong to
[00:38:21.820 --> 00:38:23.420]   He was packing it
[00:38:23.420 --> 00:38:29.100]   Literally went and grabbed it. You do I have to say you do kind of get used to having that every morning and you kind of look forward to it
[00:38:29.100 --> 00:38:33.820]   It's really interesting hard hit approves too. We are in the middle of uh amazon prime day
[00:38:33.820 --> 00:38:38.140]   Oh, yeah day two. It's a 48 hour event started yesterday
[00:38:38.700 --> 00:38:40.700]   Already in the first
[00:38:40.700 --> 00:38:44.620]   24 hours prime day has pushed us online sales up
[00:38:44.620 --> 00:38:50.380]   6% but get ready for this because this is the number I like amazon
[00:38:50.380 --> 00:38:54.620]   It's estimated worldwide amazon will
[00:38:54.620 --> 00:38:59.420]   Ring up 12.9 billion dollars in sales
[00:38:59.420 --> 00:39:03.020]   Over the two days yesterday was already 6.4 billion
[00:39:03.020 --> 00:39:06.140]   in one day
[00:39:06.140 --> 00:39:08.140]   two days 12.9 billion
[00:39:08.140 --> 00:39:12.300]   Wow, did they have a breakout of what most people are buying?
[00:39:12.300 --> 00:39:13.900]   I haven't seen a lot
[00:39:13.900 --> 00:39:18.220]   The one thing that I did see was like a 47 inch television that was
[00:39:18.220 --> 00:39:21.420]   like 150 dollars or something like that and
[00:39:21.420 --> 00:39:24.300]   I'm not saying that was the best television, but it
[00:39:24.300 --> 00:39:27.900]   I thought about it because it could go in the garage
[00:39:27.900 --> 00:39:31.260]   Right, you know
[00:39:31.260 --> 00:39:36.460]   50 bucks it is kind of tempting you know, it's like the doorbuster deals on the black friday, right?
[00:39:36.460 --> 00:39:40.140]   And then people would line up. This is taken completely taken over
[00:39:40.140 --> 00:39:43.500]   Uh from black friday 6.4 billion yesterday
[00:39:43.500 --> 00:39:45.500]   2% off by n95 masks
[00:39:45.500 --> 00:39:51.580]   Do you still wear masks around? Oh, yeah, he does. Oh, oh, yeah
[00:39:51.580 --> 00:39:55.820]   I was the only person in all of england in the mask. Yeah, I wore a mask
[00:39:55.820 --> 00:39:57.260]   I was on the plane
[00:39:57.260 --> 00:39:58.300]   Plus I get to the airport
[00:39:58.300 --> 00:40:02.220]   You know, I'm not you know that I'm in the story dad gets to airport 14 hours early
[00:40:02.220 --> 00:40:07.500]   I'm not bad. Yeah, so I wore my mask for 12 hours solid. So
[00:40:07.500 --> 00:40:11.420]   You know, it's funny when we went to uh, europe
[00:40:11.420 --> 00:40:18.220]   I did wear my mask in the airport and on the plane and got there and then lisa said what do you look like an idiot take it off
[00:40:18.220 --> 00:40:23.020]   And I'd never wore it again even in I've there it was this the
[00:40:23.020 --> 00:40:27.020]   Press of the crowd at the Vatican to see the right sistine chapel
[00:40:27.660 --> 00:40:31.580]   From and it's people from all over the world. I'd be paranoid now
[00:40:31.580 --> 00:40:38.220]   Didn't didn't catch anything didn't even get a cold out of it. I don't know. I I don't know what to think anyway
[00:40:38.220 --> 00:40:40.780]   get your masks cheap
[00:40:40.780 --> 00:40:45.740]   Uh the growth uh year over year and prime day 5.96
[00:40:45.740 --> 00:40:51.180]   It's the single biggest e commerce day this this year so far. Well, that's obvious, right
[00:40:51.180 --> 00:40:53.900]   uh categories that were up
[00:40:53.900 --> 00:40:56.860]   uh appliances
[00:40:56.940 --> 00:41:02.140]   Up 37 percent. Okay. That makes sense. I guess it is a tv and appliance. I don't know
[00:41:02.140 --> 00:41:08.700]   I was gonna say blender robot vacuums. That's what people are buying. Oh, I bet toys up 27 percent
[00:41:08.700 --> 00:41:11.420]   Apparel. That's also 26 percent
[00:41:11.420 --> 00:41:14.380]   Electronics were only up 12 percent
[00:41:14.380 --> 00:41:20.540]   So, you know in days gone by people you would I would have thought you go to amazon to buy books and electronics
[00:41:20.540 --> 00:41:23.420]   But no clothing
[00:41:23.420 --> 00:41:25.900]   Boy, that's not what I would have thought toys
[00:41:26.140 --> 00:41:28.140]   For clothes. Yeah, that's hard
[00:41:28.140 --> 00:41:32.700]   Uh, here's the maybe a little scarier stat buy now pay later. Oh
[00:41:32.700 --> 00:41:35.500]   6.4 percent of the total orders
[00:41:35.500 --> 00:41:40.220]   461 million dollars. That's up almost 20 percent over last year
[00:41:40.220 --> 00:41:46.380]   Buy now pay later talking to your kids about buy now paid later. I think it's really important like my parents
[00:41:46.380 --> 00:41:48.940]   I remember having the credit card talk with me about that
[00:41:48.940 --> 00:41:54.780]   So yeah, I'd be talking to your like grown up. Yeah, like aunt your age. I guess
[00:41:55.580 --> 00:42:01.020]   College boy. I have to get in his ear quite often because boy he likes to buy stuff
[00:42:01.020 --> 00:42:06.140]   And I'm like dude stop it. Nope. You're not doing that. Yes fun having the box arriving it
[00:42:06.140 --> 00:42:13.660]   It's addictive. That's the problem. Yeah, Michael. This was cute cubie. See my father-in-law used to buy cap and money and stuff from cubie
[00:42:13.660 --> 00:42:19.020]   That's I never got that habit. My mom did I'm surprised you didn't actually
[00:42:19.020 --> 00:42:22.380]   Yeah, you were tailor made for
[00:42:22.380 --> 00:42:24.380]   Mr. Instagram
[00:42:24.380 --> 00:42:31.660]   They couldn't reach me through the tv so they found another way they reached out and they got me an instagram
[00:42:31.660 --> 00:42:34.700]   Uh
[00:42:34.700 --> 00:42:43.580]   Shoppers will find deals for electronics six peeking at 16 off listed price. That's not a huge. That's not that's why I said
[00:42:43.580 --> 00:42:48.140]   They're not that great. Yeah. No. Yeah, and
[00:42:49.100 --> 00:42:54.220]   Amazon seems to be taking a page out of alberts and slash Safeway and marking up their prices before
[00:42:54.220 --> 00:43:01.580]   I saw a can in our sixth deal for 20 off listed there, but
[00:43:01.580 --> 00:43:03.820]   I know that's
[00:43:03.820 --> 00:43:05.420]   baloney because
[00:43:05.420 --> 00:43:11.580]   Last month that same can in our six was 20 off just on a random day. So yeah, see yeah
[00:43:11.580 --> 00:43:16.540]   Curbside pickup was used in one fifth of all the orders yesterday
[00:43:18.140 --> 00:43:23.500]   Yo, this is basically just a way to get you to buy stuff you don't need like if you need something
[00:43:23.500 --> 00:43:27.660]   I know I sound like your grandma, but bear with me if you think you need something
[00:43:27.660 --> 00:43:33.900]   Write it down. Shave up for it a week later put a dime in that pink bank every week
[00:43:33.900 --> 00:43:36.540]   And by the time you're buying it
[00:43:36.540 --> 00:43:40.220]   You're grandma bicycle and then when you get out of your wrong
[00:43:40.220 --> 00:43:41.740]   Look at it
[00:43:41.740 --> 00:43:48.140]   Keep an eye on it and if it gets better priced then you get it and if you're going to prime day
[00:43:48.140 --> 00:43:54.780]   Look at your list. See if things are on sale, but otherwise sees practical life acts. I know man
[00:43:54.780 --> 00:43:58.620]   I'm just um wait. Wait. Wait. Go back to Leo. You said 20% were
[00:43:58.620 --> 00:44:01.260]   Curbside pickup is that wild?
[00:44:01.260 --> 00:44:05.900]   What do you mean curbside? You mean go to the box you go to those lockers? I guess right
[00:44:05.900 --> 00:44:09.660]   Um that much volume. No, that can't be shoppers will find me
[00:44:10.140 --> 00:44:13.420]   Seattle and I'm not picking anything up curbside. What's happening?
[00:44:13.420 --> 00:44:16.860]   Uh
[00:44:16.860 --> 00:44:21.580]   This is from adobe which does the analytics for this weirdly enough adobe analytics insights
[00:44:21.580 --> 00:44:27.180]   Curbside pickup was used in 20 percent of online orders on july 11th yesterday
[00:44:27.180 --> 00:44:33.260]   For retailers who offer this service. Oh, it's oh, it's not just prime day
[00:44:33.260 --> 00:44:37.580]   Yeah, oh like best because there are some retailers
[00:44:38.140 --> 00:44:40.700]   So like targe and stuff like that. Ah, you're right
[00:44:40.700 --> 00:44:42.780]   in fact, uh
[00:44:42.780 --> 00:44:48.060]   That was kind of the part of the point of this prime day is becoming one of the biggest e-commerce moments of the year
[00:44:48.060 --> 00:44:50.940]   for everybody, but
[00:44:50.940 --> 00:44:56.620]   Yeah, but as consumers latch on to major discounts from a number of different retailers
[00:44:56.620 --> 00:45:00.220]   So it's becoming like black friday. It's becoming a national. Okay
[00:45:00.220 --> 00:45:08.060]   Holiday, okay. It's not becoming a national holiday. It's becoming a marketing extravaganza for companies that want to get you
[00:45:08.060 --> 00:45:10.860]   to buy stuff you don't need. I'm done. I'm done
[00:45:10.860 --> 00:45:14.860]   Give me my chair. I'm gonna yell at some people
[00:45:14.860 --> 00:45:19.580]   I like the irc
[00:45:19.580 --> 00:45:26.860]   This is uh birk saying led tape on sale for $37 down from $50 is still a crappy deal
[00:45:26.860 --> 00:45:30.140]   Burke, you sound like you were burnt sometime
[00:45:30.140 --> 00:45:33.180]   Haven't gotten over it
[00:45:33.180 --> 00:45:36.540]   So yeah, the curbside pickup was for retail with other retailers
[00:45:36.540 --> 00:45:41.580]   Amazon doesn't have curbside. They have those whole lockers lockers. Yeah
[00:45:41.580 --> 00:45:45.980]   uh smartphones almost half of online sales
[00:45:45.980 --> 00:45:51.180]   People are becoming comfortable shopping on small screens says adobe
[00:45:51.180 --> 00:45:55.820]   Um, anyway, very I mean I shop. Yeah
[00:45:55.820 --> 00:46:01.660]   I shop on the couch when I'm bored. I'm like, oh, let's see what's let's see what north stress
[00:46:01.660 --> 00:46:03.660]   Do you shop while you're watching tv
[00:46:03.660 --> 00:46:07.740]   Or doing a podcast no
[00:46:07.740 --> 00:46:12.780]   During this podcast. Yes all the time. I'm like ai
[00:46:12.780 --> 00:46:17.020]   And jeff when you talked about my grandma bike
[00:46:17.020 --> 00:46:20.620]   Were you the great? Were you talking about me? Were you like was that a little?
[00:46:20.620 --> 00:46:24.300]   Swipe at my tricycle. Yes
[00:46:24.300 --> 00:46:31.020]   In a word because you know, we look for those things. It's like the howard stern show we bust each other
[00:46:31.900 --> 00:46:33.900]   How we show love
[00:46:33.900 --> 00:46:39.260]   No, I did not find that
[00:46:39.260 --> 00:46:42.220]   You need a little horn on it. I do need a horn
[00:46:42.220 --> 00:46:44.700]   Right
[00:46:44.700 --> 00:46:46.860]   It has a bell, but that doesn't do anything
[00:46:46.860 --> 00:46:53.420]   Yeah, well, lisa. I love I love the fact you're going so fast. You need the rear view mirror
[00:46:53.420 --> 00:47:00.940]   No, the rear view mirror is important when you're biking because you want to see that car before it wax into your
[00:47:00.940 --> 00:47:02.940]   back
[00:47:02.940 --> 00:47:08.700]   Trust me. No, I do I use the river. That's a that's a safety. Yeah safety thing
[00:47:08.700 --> 00:47:12.380]   My helmet I should show you my helmet my helmet also
[00:47:12.380 --> 00:47:16.860]   Uh has lights blinking on it and it has a blinker so I could push a button
[00:47:16.860 --> 00:47:22.140]   There's a button on the thing. I push the button and it goes left left left right right right. I remember seeing that as
[00:47:22.140 --> 00:47:25.900]   Yes, I want that. I want that it also is blue too. What is it?
[00:47:26.460 --> 00:47:31.340]   It's a it's a levol l i v a l l birk or somebody would you bring me my levol
[00:47:31.340 --> 00:47:36.380]   Helmet out there. It also says blue too. So you can listen to your or you can take phone calls on it
[00:47:36.380 --> 00:47:43.260]   I can't fear you. I want my tricycle
[00:47:43.260 --> 00:47:45.740]   I like the wind is rushing by
[00:47:45.740 --> 00:47:52.700]   You're on the helmet slow down slow down. Yeah, so I can hear you
[00:47:53.740 --> 00:47:56.380]   You'll never believe where i'm calling you from
[00:47:56.380 --> 00:48:04.620]   My tricycle. I want to ride my tricycle. I love these levol l i v a l l
[00:48:04.620 --> 00:48:12.220]   Helmets first of all they don't look too geeky right. Yeah, I'm a little vice. You're on a little visor. I like it
[00:48:12.220 --> 00:48:14.540]   Uh and then here if I push
[00:48:14.540 --> 00:48:17.580]   This it looks like a riot cop
[00:48:17.580 --> 00:48:20.940]   If I push this button, it'll talk to you here
[00:48:23.260 --> 00:48:27.020]   Oh, wow. Yeah, and then it has little blinking blinking lights in the back
[00:48:27.020 --> 00:48:30.540]   No, I really like this. Oh man. Is that on sale for prime day?
[00:48:30.540 --> 00:48:35.740]   I don't know but check it out. Yeah, well, because I'll tell you what I feel so uh unsafe
[00:48:35.740 --> 00:48:38.780]   Riding a bicycle on city streets. I agree
[00:48:38.780 --> 00:48:40.780]   Well, especially when you're going on
[00:48:40.780 --> 00:48:46.380]   To get your office one of the reasons I got the trikes because I thought well, it's it's a little bit more of a
[00:48:46.380 --> 00:48:51.340]   Visual presence on the street. Don't run over grandma
[00:48:51.740 --> 00:48:55.420]   Yeah, that was part of it is like senior citizen here. Yeah
[00:48:55.420 --> 00:49:01.100]   I used to have a recumbent trike. I still have it actually prime day deal. I didn't know you're 30
[00:49:01.100 --> 00:49:04.140]   30 off on the levos, which is it really a
[00:49:04.140 --> 00:49:07.180]   The recumbent bike is really low like your head is
[00:49:07.180 --> 00:49:13.980]   Like down here and yeah, and you have to have a big flag so that people that even see you and I thought this is really
[00:49:13.980 --> 00:49:17.980]   I stopped riding with somebody through a bottle up my heart. It was definitely a nerd
[00:49:19.420 --> 00:49:24.620]   But this is pretty nerdy. Oh, oh, these are not unreasonable. No, they're good. No, they're good highly recommend them
[00:49:24.620 --> 00:49:27.260]   Love them that can be my pick of the week
[00:49:27.260 --> 00:49:32.940]   Uh, all right. Let's see what else is going on here lina con
[00:49:32.940 --> 00:49:37.340]   Is taking on the world's biggest tech companies and
[00:49:37.340 --> 00:49:44.700]   Um, this is of course the wall street journal. I have I know every you tell me
[00:49:45.500 --> 00:49:50.460]   They're good the news departments good reliable trustworthy journalists
[00:49:50.460 --> 00:49:53.580]   What stacy says it
[00:49:53.580 --> 00:49:54.780]   I have friends who work for the
[00:49:54.780 --> 00:49:57.980]   It's not the it's not the editor. I understand it's not the opinion section
[00:49:57.980 --> 00:50:01.660]   But I have to say that a lot of times you feel like they're kind of
[00:50:01.660 --> 00:50:08.380]   Got an axe to grind against big tech. Uh, I feel like that and I feel like this is a little bit
[00:50:08.380 --> 00:50:12.060]   Slanted when it says well, she's losing
[00:50:12.940 --> 00:50:16.140]   So there but she did lose a big case
[00:50:16.140 --> 00:50:17.980]   Yesterday
[00:50:17.980 --> 00:50:24.380]   Microsoft is trying to block the acquisition of blizzard activation a big gaming company by microsoft
[00:50:24.380 --> 00:50:26.460]   it's one of the biggest tech acquisitions of all time
[00:50:26.460 --> 00:50:31.820]   and uh, they sued in court they asked for an injunction
[00:50:31.820 --> 00:50:34.940]   To prevent microsoft from going ahead and doing it
[00:50:34.940 --> 00:50:42.780]   Because even though they're under investigation microsoft could just move ahead with the acquisition and then say there now you break it up
[00:50:42.780 --> 00:50:48.300]   You do something so my so the ftcs thought you know, they are going to continue this investigation and
[00:50:48.300 --> 00:50:51.980]   There's a hearing in august with a administrative judge
[00:50:51.980 --> 00:50:55.020]   To decide whether they should actively block it
[00:50:55.020 --> 00:50:56.460]   um
[00:50:56.460 --> 00:50:57.420]   but
[00:50:57.420 --> 00:51:00.140]   This might have been a mistake on the part of the ftc because
[00:51:00.140 --> 00:51:04.620]   When they asked for the injunction microsoft fought back and fought back hard
[00:51:04.620 --> 00:51:07.500]   And a judge in san francisco
[00:51:07.500 --> 00:51:12.220]   Has now ruled against the ftc in such a dramatic way that
[00:51:12.780 --> 00:51:17.740]   People like paul tharat said it's over this acquisition is gonna have to is still out
[00:51:17.740 --> 00:51:22.860]   Yeah, and I think the thinking is that the the deal has a
[00:51:22.860 --> 00:51:25.420]   breakup clause
[00:51:25.420 --> 00:51:27.420]   on the 18th less than a week
[00:51:27.420 --> 00:51:30.860]   And so the thing is that they'll just do it now
[00:51:30.860 --> 00:51:37.740]   And you know in the next week and say to the uk knee knee knee knee or sue us fire a finest do something who cares?
[00:51:37.740 --> 00:51:39.020]   We don't care
[00:51:39.020 --> 00:51:41.020]   It's a lot harder. I guess once it's happened
[00:51:41.660 --> 00:51:42.620]   Uh
[00:51:42.620 --> 00:51:45.260]   The judge was fairly brutal
[00:51:45.260 --> 00:51:51.340]   In this case saying not to ask these days what kind of judge was it?
[00:51:51.340 --> 00:51:55.100]   Uh federal district judge jacklin scott corley pointed by
[00:51:55.100 --> 00:51:57.420]   Don't know
[00:51:57.420 --> 00:52:00.380]   That's what i'm just i think we have always have to ask now. Oh
[00:52:00.380 --> 00:52:04.140]   Yeah, the federal judiciary is getting more and more suspect
[00:52:04.140 --> 00:52:05.180]   Anyway
[00:52:05.180 --> 00:52:10.860]   Uh, she wrote that the ftc failed to show evidence backing of its claim that microsoft was likely to withhold activisions
[00:52:11.180 --> 00:52:13.740]   Blockbuster games from competitors such as sony in fact
[00:52:13.740 --> 00:52:19.580]   Microsoft has made 10-year deals with sony and others to make sure those games are still available the judge
[00:52:19.580 --> 00:52:26.380]   noted those deals which would expand consumer access to its biggest game franchise call of duty
[00:52:26.380 --> 00:52:35.660]   Uh, the judge was pretty clear that the ftc had not proven its case and he's allowing it you know did not give them that injunction
[00:52:35.660 --> 00:52:39.740]   uh anti trust experts expect that
[00:52:40.700 --> 00:52:42.700]   the ftc will appeal
[00:52:42.700 --> 00:52:44.060]   but
[00:52:44.060 --> 00:52:49.180]   The pundits i've heard talking today don't think there's much merit in that and they think now because of this
[00:52:49.180 --> 00:52:55.420]   Judgment that the administrative court judge in august will probably just say yeah, you got no case and that's that
[00:52:55.420 --> 00:52:58.380]   and the uk which is
[00:52:58.380 --> 00:53:00.540]   fighting it over grounds that it would somehow
[00:53:00.540 --> 00:53:03.340]   monopolize a non-existent
[00:53:03.340 --> 00:53:06.060]   cloud gaming business
[00:53:07.100 --> 00:53:12.140]   Really it's not a business. You know and then who will just kill stadia. Yeah, yeah stadia
[00:53:12.140 --> 00:53:18.140]   Yeah, so uh, I think this is probably amazon still has what where was amazon's cloud gaming?
[00:53:18.140 --> 00:53:19.420]   Luna
[00:53:19.420 --> 00:53:24.620]   Luna and and and vidiya has g force now and they're few but they're all tiny
[00:53:24.620 --> 00:53:27.900]   They're not oh, yeah, it's not a it's not a big business and so
[00:53:27.900 --> 00:53:30.540]   you know some people said that the uh
[00:53:31.340 --> 00:53:37.020]   You have to see forgot to bring its crystal ball or time machine to the court because it's all about the you know
[00:53:37.020 --> 00:53:39.020]   Well, this is what might happen
[00:53:39.020 --> 00:53:41.980]   Uh, or what if this happens in any event?
[00:53:41.980 --> 00:53:47.260]   Uh, the real question is does this hobble in a con in her attempt to go after the shed?
[00:53:47.260 --> 00:53:50.220]   I was trying to think back what what other cases is that funny?
[00:53:50.220 --> 00:53:53.340]   Unlosing the street. Yeah, um
[00:53:53.340 --> 00:54:00.300]   She said i'm certainly not someone who thinks success is marked by a 100 percent court record
[00:54:00.940 --> 00:54:03.820]   If you never bring those hard cases, there's a cost to that
[00:54:03.820 --> 00:54:09.340]   You know vc's only win or hit it out of the park what 30 percent of the time or right?
[00:54:09.340 --> 00:54:13.900]   Not that so right prosecutors are supposed to work on them as they actually take the cases
[00:54:13.900 --> 00:54:16.860]   They know they are confident with it. But there's a difference in any trust
[00:54:16.860 --> 00:54:22.940]   We actually have a lot of issues with that, but yeah, there's also a difference in any trust because I think bringing these cases by itself
[00:54:22.940 --> 00:54:30.460]   forwards the notion that you got to be thoughtful about these mergers and and and there's some oversight
[00:54:30.460 --> 00:54:32.460]   That actually is a greater
[00:54:32.460 --> 00:54:35.580]   I think it's a greater danger if you bring the case and lose
[00:54:35.580 --> 00:54:39.580]   Warning does that important if you back it up then emboldens people?
[00:54:39.580 --> 00:54:41.580]   Yeah, I think there are a lot of companies though
[00:54:41.580 --> 00:54:49.020]   Like microsoft certainly apple that don't want to go to court if they don't have to because there's discovery stuff comes out. Oh, yeah
[00:54:49.020 --> 00:54:53.340]   Yeah, um, and so there is it it is a little bit of a threat
[00:54:53.340 --> 00:54:56.060]   I would say
[00:54:56.060 --> 00:55:01.500]   But you're right if they never if the ftc loses every case then it's not then it doesn't have so much power
[00:55:01.500 --> 00:55:08.140]   I'm trying to think of what else I really don't know and I would like the ftc to be a little bit more activist here because I think we are antitrust
[00:55:08.140 --> 00:55:18.700]   Regime has been very very backward like very old school. I agree and and as much as I love technology
[00:55:18.700 --> 00:55:23.500]   I think it's really important that not big tech's not going to regulate itself
[00:55:24.380 --> 00:55:26.380]   So and you know what do you love?
[00:55:26.380 --> 00:55:31.340]   I love technology, but in the last like year or so have I been thinking about it?
[00:55:31.340 --> 00:55:34.800]   I like engineers. I like
[00:55:34.800 --> 00:55:39.340]   Real hard. Yeah, but technology today
[00:55:39.340 --> 00:55:46.060]   Is really like the financial like the financial industry was back in the 80s like when we were all like
[00:55:46.060 --> 00:55:54.300]   Reading tom wolfbooks and it was people who are gaming the system. The system doesn't feel really really good points. Stacy really good point culturally
[00:55:54.300 --> 00:55:58.940]   I like that play with a little more so so it's uh bonfire of the vanities
[00:55:58.940 --> 00:56:02.300]   Watch
[00:56:02.300 --> 00:56:04.460]   You're like
[00:56:04.460 --> 00:56:06.780]   Jarvis
[00:56:06.780 --> 00:56:14.300]   Talk to the class about your premise here to explore that would you all right bonfire the vanities. Let's go
[00:56:14.300 --> 00:56:17.820]   No, I'll give you some aminitually
[00:56:17.820 --> 00:56:22.620]   I'll give you some an edition Alex cantor wits who does the big tech newsletter
[00:56:23.180 --> 00:56:29.740]   Has complained about the financialization of technology and I think that's what you're talking about and that's as vc money
[00:56:29.740 --> 00:56:33.740]   Also the jerkification of technology to by all it goes hand in hand a couple things
[00:56:33.740 --> 00:56:41.660]   I I think what we've had and we have lionized tech and given it a pass for far too long based on the fact that they
[00:56:41.660 --> 00:56:45.500]   They used to be building things in their garage and that hasn't been true since
[00:56:45.500 --> 00:56:48.060]   since the 80s forever in you
[00:56:48.060 --> 00:56:49.180]   I mean
[00:56:49.180 --> 00:56:52.540]   And hell the garage in selective valley costs four million dollars to have so
[00:56:53.340 --> 00:56:58.700]   Yeah, and when I think about like the the people I talked to even
[00:56:58.700 --> 00:57:01.980]   I would say it started happening around
[00:57:01.980 --> 00:57:04.540]   2006 2007
[00:57:04.540 --> 00:57:09.820]   Is when people started talking. I mean there was always like, you know the stock option people right
[00:57:09.820 --> 00:57:13.740]   Those the sales culture and tech has always been the sales culture and tech
[00:57:13.740 --> 00:57:20.940]   But those people are now in charge and that has kind of eaten over everything and you get these people who are doing like
[00:57:21.500 --> 00:57:26.620]   It's like the app for it's like the uber for this this right so it's like
[00:57:26.620 --> 00:57:31.420]   Building these apps and things that are very divorced from the infrastructure itself
[00:57:31.420 --> 00:57:33.660]   And something that might have come about from things like
[00:57:33.660 --> 00:57:38.540]   You no longer had to come construct a server rack to run any tech thing you
[00:57:38.540 --> 00:57:44.700]   You've made tech very accessible to people who are not necessarily technically savvy. I don't know
[00:57:44.700 --> 00:57:49.500]   Well, that's not a bad thing. That's a good thing. No, I don't think it's a bad thing but I do think it
[00:57:50.140 --> 00:57:51.660]   I
[00:57:51.660 --> 00:57:53.980]   Mean it's kind of like when people are like well
[00:57:53.980 --> 00:57:58.780]   It used to be so cool used to have to build your own master don server if you want it now look at all these losers
[00:57:58.780 --> 00:58:03.980]   Who don't really want to be here. There's there's plus us and minuses to that accessibility
[00:58:03.980 --> 00:58:07.740]   I would argue that's not the problem. There's a big plus to know that
[00:58:07.740 --> 00:58:14.140]   Anybody who has a vision for how something could be it used to be yeah, you'd have to know pearl
[00:58:14.140 --> 00:58:18.780]   And and be able to you know write a cgi script or something
[00:58:18.780 --> 00:58:23.740]   I mean there was a much higher barrier to entry the fact that the barrier entry is lowered is good
[00:58:23.740 --> 00:58:29.820]   I don't think however the entry of big money and VCs and the perverse
[00:58:29.820 --> 00:58:32.620]   Incentives that they bring with them is a good thing
[00:58:32.620 --> 00:58:36.700]   Because they force you to quick exits they force you to quick
[00:58:36.700 --> 00:58:40.060]   Capitalization, I mean it's not it's not as good
[00:58:40.060 --> 00:58:42.220]   That's one of the they're driving
[00:58:42.220 --> 00:58:47.580]   Like the they would never be in there driving this if it weren't easy to do now that everyone can do it
[00:58:47.820 --> 00:58:53.980]   They're like well shit. Everyone can do it. Let's throw a bunch of money at this guy. Yeah, okay. I see what you're saying. Yeah. Yeah, right? Yeah
[00:58:53.980 --> 00:59:00.540]   But but I think it's good for us for a small person small, you know two-man shop or whatever two-person shop
[00:59:00.540 --> 00:59:04.140]   I have my own company because yeah, look at this exactly exactly
[00:59:04.140 --> 00:59:05.900]   What we're doing here
[00:59:05.900 --> 00:59:07.340]   I couldn't have done
[00:59:07.340 --> 00:59:12.300]   20 years ago because it'd have to have millions of dollars for a grass valley switcher and you know
[00:59:12.300 --> 00:59:14.700]   You'd have to have a tv tower and all sorts of stuff
[00:59:14.700 --> 00:59:19.020]   By the way, I like the new stacey higginbotham's boujee seal of approval
[00:59:19.020 --> 00:59:19.980]   I just saw that
[00:59:19.980 --> 00:59:21.980]   I don't know what it means
[00:59:21.980 --> 00:59:27.500]   But thank you joe spazito for once again providing us with graphic amusement in our club
[00:59:27.500 --> 00:59:31.820]   Actually, oh, maybe once in a while you shouldn't show it on the screen
[00:59:31.820 --> 00:59:37.500]   You should let the people who are in the club if you were in the club what's missing you'd know. Yeah. Yeah
[00:59:37.500 --> 00:59:42.860]   Yeah, uh, you could sell sticker packs. Oh
[00:59:43.420 --> 00:59:49.660]   And then oh, oh, here's what it is your christmas card this year. Yeah ready. Yeah, is there an oh, oh, oh because there should be
[00:59:49.660 --> 00:59:55.260]   Oh, yeah, that's next you give out when you sign up. This is your tote bag
[00:59:55.260 --> 01:00:01.340]   You get a sticker pack and up your christmas card is a bingo card and then you play it joe's already
[01:00:01.340 --> 01:00:04.380]   from your lips
[01:00:04.380 --> 01:00:11.900]   Nice
[01:00:11.900 --> 01:00:13.900]   Great
[01:00:13.900 --> 01:00:16.780]   Oh my god
[01:00:16.780 --> 01:00:19.820]   Can we figure out a way to make these uh happen?
[01:00:19.820 --> 01:00:27.980]   Tie yeah tie no you got to redo stacey's those curses mother plucker
[01:00:27.980 --> 01:00:31.820]   I didn't see that one
[01:00:31.820 --> 01:00:38.780]   Oh, we could come up with some others that was my that was like my worst moment joe
[01:00:39.660 --> 01:00:41.660]   At least make it douche day
[01:00:41.660 --> 01:00:46.860]   You know what I said it
[01:00:46.860 --> 01:00:50.940]   Maybe I don't
[01:00:50.940 --> 01:00:58.780]   Uh, if you're not a member of club we got to work on this we've really got to make this happen if you're not a member of club twit
[01:00:58.780 --> 01:01:04.540]   Mr. Joe we need to talk don't join because we will get stickers in no, I don't know
[01:01:05.660 --> 01:01:09.660]   How can we do that? I don't know there's there's gotta be a way. I'll tell you what if you join now
[01:01:09.660 --> 01:01:15.180]   Put a little asterisk next to your membership saying I joined on the condition that there'd be some stickers
[01:01:15.180 --> 01:01:20.700]   You said there would be stickers said that would be stickers. It's the premium
[01:01:20.700 --> 01:01:24.060]   Oh for seven dollars and fifty cents
[01:01:24.060 --> 01:01:29.900]   Then there we go. There we go. Now. We got it. We love uh, we love our club
[01:01:29.900 --> 01:01:34.860]   Sign up for two years and you get sick and they make they make it all uh possible
[01:01:35.260 --> 01:01:36.860]   Club twit is
[01:01:36.860 --> 01:01:42.540]   Increasingly important part of uh the way we stay on the air if you are not a club twit member
[01:01:42.540 --> 01:01:44.620]   I implore you to consider
[01:01:44.620 --> 01:01:49.980]   Seven bucks a month gets you ad free versions of all the shows because you're giving us money. We don't need advertisers
[01:01:49.980 --> 01:01:52.940]   Uh, and we don't need their tracking or any of that stuff
[01:01:52.940 --> 01:01:58.700]   So that's one benefit, but you also get shows that you don't get anywhere else like hands on mac and tush hands on windows
[01:01:58.700 --> 01:02:01.180]   we've got the
[01:02:01.500 --> 01:02:06.620]   Home theater geek show with scott wilkinson. I know you do a lot of good things in fact coming up
[01:02:06.620 --> 01:02:13.820]   We've got a big event. Mm-hmm. Mm-hmm. That's uh, yeah, I think uh, I've been trying to talk to lisa about this
[01:02:13.820 --> 01:02:19.900]   We're gonna. Oh, you're doing tomorrow's the ai show hang with adjacent it's the beginning and jeff you're invited to that
[01:02:19.900 --> 01:02:22.060]   If you can go to i force me i can't yeah
[01:02:22.060 --> 01:02:24.460]   But but we'll try to find a time that works for you
[01:02:24.460 --> 01:02:30.940]   Uh, because we are preparing the ai show in it's gonna be in the club but then on uh july 14th after tomorrow
[01:02:31.500 --> 01:02:35.260]   Uh, five p.m. Pacific apm eastern. It's the insight to it after hours
[01:02:35.260 --> 01:02:41.820]   Now you can tell me lisa said oh, we gotta go to that. I said lisa. I think it's better if the bosses aren't there
[01:02:41.820 --> 01:02:46.940]   Okay, let me just say this. I wanted to hang out with my squad
[01:02:46.940 --> 01:02:49.180]   Who's your squad?
[01:02:49.180 --> 01:02:54.300]   Everybody that works in there. You don't want the bosses around. I wanted to hang out with the squad and just
[01:02:54.300 --> 01:02:55.980]   shoot the
[01:02:55.980 --> 01:02:57.580]   Yeah, and
[01:02:57.580 --> 01:02:59.740]   We don't do that. Okay. Okay. The what?
[01:02:59.740 --> 01:03:01.740]   Should stop. Oh, i'm sorry. I
[01:03:01.740 --> 01:03:08.300]   Sorry people
[01:03:08.300 --> 01:03:16.140]   After worse now, so what are we gonna do lisa? We're gonna come for half an hour maybe yeah, you can come by but we made a reservation
[01:03:16.140 --> 01:03:21.660]   Here's why we made a reservation at the caviar bar for six. Wow. Well, let me go with two
[01:03:21.660 --> 01:03:28.940]   So we're gonna forget the squad champagne and caviar is at six. So we thought we'd come by
[01:03:29.180 --> 01:03:32.140]   Say hello we'd wave we do a little thing
[01:03:32.140 --> 01:03:34.700]   Hang up with grande weldington while you're there
[01:03:34.700 --> 01:03:41.420]   Uh come on by we'll probably kick you up. We'll briefly be here. Yeah
[01:03:41.420 --> 01:03:45.100]   No, no, you should see to look on her face
[01:03:45.100 --> 01:03:49.340]   We just want to come briefly because I I want to it should be unfettered unchained
[01:03:49.340 --> 01:03:54.380]   Yeah, it was gonna be fun. Hang out and hi lisa wave. You're on the camera. You gotta wait
[01:03:55.500 --> 01:03:59.180]   What oh gosh what happened with the war? All right. Oh boy. No
[01:03:59.180 --> 01:04:05.980]   They can only make fun of us. Okay. Okay. Gotcha. Okay. Uh, I don't know what she's talking about
[01:04:05.980 --> 01:04:08.780]   But anyway, uh if you are not yet a member of the club
[01:04:08.780 --> 01:04:13.820]   These are the kinds of fun events you're missing. You're also missing access to the discord those special shows
[01:04:13.820 --> 01:04:20.060]   It's seven bucks a month. I tell you about the club members that I met and boston and love you said there were some some club members
[01:04:20.060 --> 01:04:24.860]   There. Yeah, yeah, i said on the show before oh, I don't know. Yeah, maybe you said it before so you get it
[01:04:24.860 --> 01:04:26.220]   Because it's just where you've been
[01:04:26.220 --> 01:04:32.380]   So I was in uh, sittandrews and then I was in london to do a lot of event with alan rusperer prospect
[01:04:32.380 --> 01:04:35.740]   And then I was in boston at heverell at the um
[01:04:35.740 --> 01:04:41.580]   Museum of printing and there were a lot of twig fans at both events
[01:04:41.580 --> 01:04:44.380]   And I said to them
[01:04:44.380 --> 01:04:49.500]   Are you remember the club and most of them said yes, nice. The arrest said they would be nice
[01:04:50.060 --> 01:04:57.020]   That's great. Thank all the folks who showed up at both events was wonderful to see you really appreciated and join the club
[01:04:57.020 --> 01:05:01.420]   Yeah, and any you know, I also want to make sure that all you know
[01:05:01.420 --> 01:05:05.660]   If you're not a member of the club, that's fine. We love it that you watch you listen
[01:05:05.660 --> 01:05:11.500]   Uh, you'll get ads, but you don't mind that and I I appreciate anybody who listens at any time
[01:05:11.500 --> 01:05:17.500]   The club is just something we added a couple of years ago to kind of help out through the rough patches and so far it's been
[01:05:17.900 --> 01:05:21.660]   Vital so if you can if you can afford it if not, don't worry about it
[01:05:21.660 --> 01:05:24.140]   We still offer all these shows for free including this one
[01:05:24.140 --> 01:05:28.300]   Unfortunately, you will not get the ribs that i'm bringing for the event. Oh
[01:05:28.300 --> 01:05:31.900]   Or the stickers or the stickers or the stickers
[01:05:31.900 --> 01:05:35.180]   Got down. Yeah ribs and stickers
[01:05:35.180 --> 01:05:45.980]   I don't know what it's kind of down market before we we got sidetracked by stickers. Okay, okay
[01:05:46.700 --> 01:05:48.700]   You were being bougie. I'm trying to remember
[01:05:48.700 --> 01:05:53.420]   Bougie Stacy. Let me do an ad that's how oh, I don't have an ad wait a minute. Just did it dad
[01:05:53.420 --> 01:05:55.500]   I thought that was an ad
[01:05:55.500 --> 01:05:57.340]   Well, it kind of was yeah
[01:05:57.340 --> 01:06:01.020]   Yeah, it was we would take that out for people or members of the club. They wouldn't hear that right?
[01:06:01.020 --> 01:06:02.540]   Is this true? Yeah
[01:06:02.540 --> 01:06:05.340]   We'll be uh, we'll be back with more news in just a bit
[01:06:05.340 --> 01:06:12.460]   Everyone deserves to feel connected. That's why cocks has high speed internet to fit any budget for real
[01:06:12.460 --> 01:06:15.020]   Learn more at cocks.com/acp
[01:06:15.820 --> 01:06:21.100]   Non-transferable one per household application and eligibility decisions are made by the FCC other restrictions apply
[01:06:21.100 --> 01:06:26.540]   Oh, there is no ad so here we are. We're back
[01:06:26.540 --> 01:06:29.820]   um
[01:06:29.820 --> 01:06:33.660]   Oh, I love this we were talking go ahead. This is kind of along the lines of the uh
[01:06:33.660 --> 01:06:38.380]   Regulation thing because it turns out in some to some in some regards. We're letting the EU
[01:06:38.380 --> 01:06:41.580]   regulate big tech
[01:06:42.060 --> 01:06:48.380]   There is something called a flop a very large online platform. This is under the digital services act
[01:06:48.380 --> 01:06:54.940]   The EU has now added there's seven have they've announced the 17 companies that are vlop's
[01:06:54.940 --> 01:06:57.180]   that include
[01:06:57.180 --> 01:06:59.180]   Ali boba's aliexpress
[01:06:59.180 --> 01:07:06.540]   Amazon apple and their app store booking face dot com facebook google play google maps google shopping
[01:07:06.540 --> 01:07:10.540]   Instagram linkedin pinterest snapchat tick tok twitter
[01:07:11.180 --> 01:07:13.180]   weirdly wiki pedia
[01:07:13.180 --> 01:07:19.740]   YouTube and a european retailer zalondo and then very large online search engines
[01:07:19.740 --> 01:07:27.260]   Are being and google search? These are companies that have to google is the londo flop. Yeah. Well, these are companies
[01:07:27.260 --> 01:07:32.620]   So the dsa is about social and disinformation. So these are companies that have
[01:07:32.620 --> 01:07:38.540]   a large enough footprint in the EU. I think 15 percent of the EU
[01:07:39.500 --> 01:07:41.500]   uses them
[01:07:41.500 --> 01:07:46.060]   And it gives them responsibilities to protect their users from illegal content
[01:07:46.060 --> 01:07:51.580]   counterfeit or illegal products hate speech and so forth
[01:07:51.580 --> 01:07:54.700]   Amazon
[01:07:54.700 --> 01:08:02.060]   Complains saying we're not a vlop. We're just this little obscure internet boutique
[01:08:04.220 --> 01:08:08.940]   Boy, that's the headline from the register obscure internet boutique Amazon
[01:08:08.940 --> 01:08:12.220]   sues eu for card calling it a very large
[01:08:12.220 --> 01:08:15.340]   online platform amazon actually said, you know, we
[01:08:15.340 --> 01:08:18.460]   We've done a lot to protect
[01:08:18.460 --> 01:08:24.620]   our customers of as majority of revenue comes from retail, which isn't covered by the dsa
[01:08:24.620 --> 01:08:26.860]   and uh
[01:08:26.860 --> 01:08:31.500]   We have done but amazon's an advertising company big advertising company
[01:08:32.140 --> 01:08:39.420]   Social media company in a movie studio. Yeah, amazon spokesperson said the dsa was designed to address systemic risks
[01:08:39.420 --> 01:08:46.620]   posed by very large companies with advertising as their primary revenue and that distribute speech and information
[01:08:46.620 --> 01:08:54.780]   Uh, we're we're a retailer. So amazon does more advertising than the magazine industry. I agree. Yes, it's a man. I think so
[01:08:54.780 --> 01:08:58.860]   Um and and it's try. Yeah, nice try basically
[01:08:59.820 --> 01:09:06.140]   Um, so we could tie this into our conversation earlier stacy about regulating big tech
[01:09:06.140 --> 01:09:09.500]   Um, the eu seems to have no problem
[01:09:09.500 --> 01:09:12.060]   Not only doing it but winning
[01:09:12.060 --> 01:09:14.860]   Right
[01:09:14.860 --> 01:09:17.260]   Well, I think I mean they wrote their own laws. So
[01:09:17.260 --> 01:09:22.780]   I think a lot of their laws around this are newer and more
[01:09:22.780 --> 01:09:28.460]   applicable to the era we're in whereas like the ftc's kind of running with some
[01:09:29.260 --> 01:09:33.020]   old school anti-compete plus the eu has had a different
[01:09:33.020 --> 01:09:35.340]   metric or
[01:09:35.340 --> 01:09:40.460]   framework for anti-competitive behavior than the us which has been driven by consumer crisis
[01:09:40.460 --> 01:09:44.060]   And I do think lina con and others have said we need to update our laws
[01:09:44.060 --> 01:09:49.500]   Uh, yeah, we do like that's going to happen though. Well, we can't even get a jwah
[01:09:49.500 --> 01:09:55.580]   The ftc has been asking for regulations on data usage and privacy since 2013
[01:09:55.980 --> 01:10:03.020]   Okay, they've been anticipating problems from so and another story in this week the eu just
[01:10:03.020 --> 01:10:04.860]   Negotiated
[01:10:04.860 --> 01:10:09.660]   an agreement such that uh data can pass from the eu the us
[01:10:09.660 --> 01:10:16.220]   So they managed to uh, oh is it shrimps three now? I mean where are we with shrimp?
[01:10:16.220 --> 01:10:22.380]   Um, that noir of does that solve some of the issues
[01:10:22.380 --> 01:10:25.500]   uh
[01:10:25.500 --> 01:10:28.460]   with well, you know, there were a lot of problems with
[01:10:28.460 --> 01:10:32.540]   was the most recent one with a company uh storing its
[01:10:32.540 --> 01:10:39.260]   Data in uh, not storing european users data in the country that they're in I can't even remember there's been so many of them
[01:10:39.260 --> 01:10:40.940]   jeez
[01:10:40.940 --> 01:10:42.700]   anyway
[01:10:42.700 --> 01:10:44.620]   So there is a new there's a new framework
[01:10:44.620 --> 01:10:50.140]   Mother plucker
[01:10:50.140 --> 01:10:55.100]   All the air feels like it went out of the room. Did I say something bad?
[01:10:55.820 --> 01:11:02.460]   It's like all right did all of us get low blood sugar at the same time. No, no, no, no
[01:11:02.460 --> 01:11:04.780]   What happened? No, I just I just yeah
[01:11:04.780 --> 01:11:13.100]   I was I was reading about the eu so you know how I like try to fact check us live. So yeah, yeah, thanks for doing that. I appreciate it
[01:11:13.100 --> 01:11:14.540]   Yeah
[01:11:14.540 --> 01:11:17.420]   All right, well, let's you know what this would be better. Let's talk about Wimbledon
[01:11:17.420 --> 01:11:20.380]   It's time for ai
[01:11:20.380 --> 01:11:21.500]   News
[01:11:21.500 --> 01:11:23.500]   All right, Jeff likes this one
[01:11:23.500 --> 01:11:25.500]   Jeff is a very big
[01:11:25.500 --> 01:11:26.940]   uh
[01:11:26.940 --> 01:11:30.780]   Tennis fan right? Yep. Am I right you go to the us open every year?
[01:11:30.780 --> 01:11:32.780]   You're just a blessing right? Yeah
[01:11:32.780 --> 01:11:39.180]   Uh Wimbledon which is on right now is considering replacing line judges out
[01:11:39.180 --> 01:11:42.300]   with
[01:11:42.300 --> 01:11:46.220]   You like that? Is that good? Very good. That was very good. That was surprising
[01:11:46.220 --> 01:11:49.660]   Trying to wake everybody up with ai
[01:11:50.780 --> 01:11:54.620]   So the yeah, those are the guys who shout, you know out you got a problem with that
[01:11:54.620 --> 01:11:59.500]   No, in fact, I don't even understand why they're having humans do it. Thank you
[01:11:59.500 --> 01:12:01.100]   I think is more
[01:12:01.100 --> 01:12:04.540]   I think the people that would be against it are the traditionalists because
[01:12:04.540 --> 01:12:09.340]   Sports are pretty freaking traditional especially at that level. Yeah
[01:12:09.340 --> 01:12:14.220]   They asked about only wearing white at Wimbledon as a tradition
[01:12:14.220 --> 01:12:18.940]   Ask john mac and roe who's of course famous for screaming at line judges
[01:12:19.420 --> 01:12:23.660]   He says I think tennis is one of the he told the radio times in the uk
[01:12:23.660 --> 01:12:26.460]   I think tennis is one of the few sports where you don't need
[01:12:26.460 --> 01:12:29.100]   umpires or linesman
[01:12:29.100 --> 01:12:34.220]   If you have this equipment and it's accurate isn't it nice to know the krick calls being made right?
[01:12:34.220 --> 01:12:39.660]   He says had I had it from the very beginning. I would have been more boring, but I would have won more
[01:12:39.660 --> 01:12:42.060]   Right. He's still fighting
[01:12:42.060 --> 01:12:45.340]   Wow
[01:12:45.340 --> 01:12:47.340]   But I but yeah, why not use those?
[01:12:49.180 --> 01:12:51.660]   Well, is there an argument? I mean
[01:12:51.660 --> 01:12:56.780]   You're either out or you're not out but like with umpires and strikes and like
[01:12:56.780 --> 01:12:58.780]   Is there a place?
[01:12:58.780 --> 01:13:01.820]   I'm not making the argument for Wimbledon because that feels pretty cut and dry
[01:13:01.820 --> 01:13:08.940]   Is there an argument for other areas where it's kind of like you could do it as accurately? I mean umpires notoriously
[01:13:08.940 --> 01:13:11.340]   Yeah, uh inconsistent truly don't know
[01:13:11.340 --> 01:13:17.820]   In fact why we have replay one of the things that happens with the baseball game is the batters get to know the umpires strike zone
[01:13:18.060 --> 01:13:23.740]   Yep from umpire to umpire. I can change, you know and real technically it's from the letters to the knees
[01:13:23.740 --> 01:13:27.980]   But you know and the and the width of the plate, but the umpires
[01:13:27.980 --> 01:13:32.300]   Often strike zone is higher or lower. Yep, and you get to know it right
[01:13:32.300 --> 01:13:37.180]   So it would make a lot more sense if you had a machine do it if it could do it accurately
[01:13:37.180 --> 01:13:41.980]   I guess it would still have to do it's on but it's based on the player too. That's the problem changes. Yeah
[01:13:41.980 --> 01:13:43.580]   Yeah
[01:13:43.580 --> 01:13:46.300]   But I mean, you know you can readjust so the camera says well
[01:13:46.300 --> 01:13:50.860]   There's the letters there's his knees. That's the strike zone and then the player squats down
[01:13:50.860 --> 01:13:53.260]   Although some people could argue like oh
[01:13:53.260 --> 01:13:59.260]   Well, we have learned how to work with this system and if you change it on us, that's I mean, that's
[01:13:59.260 --> 01:14:05.740]   Baseball there was a great story in the Atlantic this month about trying to save baseball because uh it turned out
[01:14:05.740 --> 01:14:08.140]   Never been a great baseball story never
[01:14:08.140 --> 01:14:10.620]   The new yorker tries to make it so
[01:14:10.620 --> 01:14:13.420]   Never brought your angel
[01:14:13.900 --> 01:14:15.900]   Baseball some of the best baseball
[01:14:15.900 --> 01:14:18.460]   For me
[01:14:18.460 --> 01:14:23.260]   Only being more boring the going to a baseball game is reading about it
[01:14:23.260 --> 01:14:27.420]   Four thousands of words of the yorker. I I bought
[01:14:27.420 --> 01:14:34.620]   Angels books. I bought George and will's books. I love baseball. Oh, oh, oh say no more
[01:14:34.620 --> 01:14:42.060]   He's a great writer. Oh my all right. Anyway, somebody's not a great thinker
[01:14:42.300 --> 01:14:45.420]   The problem with baseball just because his politics don't agree with yours
[01:14:45.420 --> 01:14:50.220]   The problem with baseball is the games have been getting longer every year by about three minutes
[01:14:50.220 --> 01:14:52.620]   Yeah, well, they they put in the
[01:14:52.620 --> 01:14:56.300]   Did they just change the rules of the master now?
[01:14:56.300 --> 01:14:59.980]   This is what they had to do because they looked at the stats
[01:14:59.980 --> 01:15:03.340]   And you know in 10 years games are half an hour longer
[01:15:03.340 --> 01:15:10.140]   Yeah on average if this keeps up pretty soon they'll be all day be like cricket. All right. Well, there were commercial art in it
[01:15:10.300 --> 01:15:15.420]   Well, yeah, maybe there's a anyway part of it is the rituals that both pitchers and batters go through
[01:15:15.420 --> 01:15:18.220]   in between every pitch, you know the better steps out of the
[01:15:18.220 --> 01:15:20.460]   Out of the
[01:15:20.460 --> 01:15:22.460]   box
[01:15:22.460 --> 01:15:26.540]   And the pitch is going
[01:15:26.540 --> 01:15:28.540]   It's a bunch of guys with ticks
[01:15:28.540 --> 01:15:34.220]   So yeah, they instituted a 30 second pitch clock and it's games are now averaging two hours and 27 minutes
[01:15:34.220 --> 01:15:39.500]   It's a good article if you like baseball articles in the Atlantic about this
[01:15:39.820 --> 01:15:43.740]   What you just told us the whole story in about two paragraphs
[01:15:43.740 --> 01:15:47.020]   Shorters
[01:15:47.020 --> 01:15:53.740]   You don't you don't scratch your groin as much and they made the bases bigger so that your chance of stealing is a little
[01:15:53.740 --> 01:15:55.900]   Slightly better
[01:15:55.900 --> 01:15:57.900]   But this is a perfect game
[01:15:57.900 --> 01:16:00.460]   because
[01:16:00.460 --> 01:16:06.540]   Okay
[01:16:06.860 --> 01:16:12.060]   I think it is the base ball baseball to be honest with you. I really do I don't think the sports can last much longer
[01:16:12.060 --> 01:16:14.220]   they're trying
[01:16:14.220 --> 01:16:15.900]   but
[01:16:15.900 --> 01:16:17.900]   Tennis is tennis still watch golf
[01:16:17.900 --> 01:16:20.620]   There you're gonna still watch baseball
[01:16:20.620 --> 01:16:25.980]   Well, but look at that the fact that the Saudi money is coming into golf is coming into tennis
[01:16:25.980 --> 01:16:28.060]   It's coming into all the sports. It's going to become
[01:16:28.060 --> 01:16:36.300]   A sports washing industry. Yeah, what are they washing? Are they laundering their ill-gotten oil games because those are so legal?
[01:16:36.380 --> 01:16:38.380]   What that would be yes
[01:16:38.380 --> 01:16:43.580]   They're not ill there. Yeah, you're right. They're not even gotten it's the things they do to maintain their power like
[01:16:43.580 --> 01:16:48.300]   Dismember journalists from the Washington Post. Yeah, right. I mean, yeah
[01:16:48.300 --> 01:16:53.020]   That turned dark
[01:16:53.020 --> 01:16:55.020]   All kinds of
[01:16:55.020 --> 01:17:02.060]   Or every every topics a d-day topic. New York Times fired their entire sports department
[01:17:02.380 --> 01:17:05.260]   Well, not firing their moving other jobs, but they're
[01:17:05.260 --> 01:17:13.420]   Closing it. Yeah. Oh good. They're reassigning them. It makes it makes sense because they bought the athletic and the athletic was way better, right? Yeah
[01:17:13.420 --> 01:17:16.300]   The athletics told me
[01:17:16.300 --> 01:17:18.300]   Did they have layoff so at the athletic
[01:17:18.300 --> 01:17:23.420]   Didn't they say they think yes, so pretty soon ai will be line judges at Wimbledon
[01:17:23.420 --> 01:17:27.660]   They'll be writing the story how much how long before we get the ai tennis players
[01:17:27.740 --> 01:17:32.780]   Don't would be no my god. It'll be just a bunch of api calls from Derek various
[01:17:32.780 --> 01:17:37.560]   Fed into chat gpt that'll generate a
[01:17:37.560 --> 01:17:42.320]   Oh, no, it was out advantage
[01:17:42.320 --> 01:17:45.420]   ai macken row
[01:17:45.420 --> 01:17:49.180]   Yeah, you're right. This doesn't sound like fun. Does it sounds exciting
[01:17:49.180 --> 01:17:53.820]   I actually heartened by and I've said I mentioned this before I like chess to play chess pretty seriously
[01:17:53.820 --> 01:18:01.100]   Did as a kid and for a while they thought that ai was going to kill chess when when deep blue beat gary kaspar off the world champion
[01:18:01.100 --> 01:18:05.500]   And it and it is true that the machines actually now play chess far better than any human
[01:18:05.500 --> 01:18:10.380]   And at the time I was worried a lot of people were worried that the people would stop playing chess
[01:18:10.380 --> 01:18:14.220]   It's like well, what's the point if if you know your your phone can beat you
[01:18:14.220 --> 01:18:17.420]   And no, in fact more people play chess than ever before
[01:18:17.420 --> 01:18:21.420]   Uh, sometimes they do it with the help of machines
[01:18:21.900 --> 01:18:26.460]   Uh, you know, if you're gonna be world champion you're gonna have to train with a computer and so forth
[01:18:26.460 --> 01:18:31.180]   But is it also an accessibility thing? Um, no, I think what it really is
[01:18:31.180 --> 01:18:34.300]   Anybody can go to walmart and pick up a chest. Yeah, that's right
[01:18:34.300 --> 01:18:38.620]   And I think that we celebrate what humans can do even if a machine can do it better
[01:18:38.620 --> 01:18:47.340]   It doesn't mean that we don't celebrate the human achievement of it. Okay. Well, has the machine taught humans new moves and new strategies to
[01:18:47.340 --> 01:18:49.340]   To some degree. Yes
[01:18:49.340 --> 01:18:55.500]   I mean, mostly what you would use as a champion what you know grandmaster you would use a machine to investigate lines and stuff
[01:18:55.500 --> 01:19:00.140]   But ultimately your judgment is is going to be paramount
[01:19:00.140 --> 01:19:03.020]   One thing that's happened is kind of weird
[01:19:03.020 --> 01:19:09.420]   Uh, you know one of this can happen because at chess game even though it's very very complex is solvable, right?
[01:19:09.420 --> 01:19:13.180]   You could say well this move if you follow it all the way to the end you're gonna win
[01:19:13.180 --> 01:19:18.940]   Humans can't do that they can only do you know a little bit ahead but nevertheless machines could solve it
[01:19:19.020 --> 01:19:21.020]   So it could be theoretically solvable
[01:19:21.020 --> 01:19:27.180]   It gets much less complex with fewer pieces. So if you get down to a handful of pieces
[01:19:27.180 --> 01:19:32.940]   The machine can say in every possible position. This is a win. This is a win. That's a loss. That's a draw. That's a win
[01:19:32.940 --> 01:19:34.940]   That's why so they have tables now
[01:19:34.940 --> 01:19:41.420]   Of positions in the end game all of which have been solved like just completely solved like oh you win here or you lose here
[01:19:41.420 --> 01:19:44.620]   And masters have started memorizing those so they know
[01:19:45.500 --> 01:19:49.740]   This is a win. This is a loss and this is how you play so it has changed the end game a little bit
[01:19:49.740 --> 01:19:54.220]   Change the opening charts if yeah, but the middle is so complex and a machine
[01:19:54.220 --> 01:19:58.460]   Is not quite as
[01:19:58.460 --> 01:20:03.420]   Surpassing as as it is in the other parts of the game and there's you know
[01:20:03.420 --> 01:20:07.980]   Sure a car can drive a marathon in 10 minutes, right
[01:20:07.980 --> 01:20:14.060]   Or a minute, but that doesn't mean a marathoner isn't that that's not still a thing right?
[01:20:14.380 --> 01:20:20.460]   Human running there car cannot drive a marathon in a minute 10 minutes though at least not safely
[01:20:20.460 --> 01:20:23.660]   Let's see. Okay. Wait a minute. Let me just eat right now
[01:20:23.660 --> 01:20:26.460]   It's like a mile an hour
[01:20:26.460 --> 01:20:31.020]   Lesson how long would it take Leo and his grandma bike?
[01:20:31.020 --> 01:20:35.420]   We take one hour 18 18 minutes no
[01:20:35.420 --> 01:20:39.980]   A formula one vehicle could do a marathon in probably
[01:20:39.980 --> 01:20:43.580]   12 minutes. Yeah, so all right anyway
[01:20:43.820 --> 01:20:49.020]   That doesn't mean people don't run anymore. Right right? All right good point. So I think
[01:20:49.020 --> 01:20:56.380]   Line judges at Wimbledon. Okay. Yes. We agree. Yeah, and this Stacy going back to your argument about
[01:20:56.380 --> 01:21:00.620]   They're saying they they had to make adjustments to
[01:21:00.620 --> 01:21:06.300]   To understand the nuance of the umpire. So now you're making them retrain my argument would be
[01:21:06.300 --> 01:21:09.820]   Are are you against making baseball?
[01:21:10.380 --> 01:21:14.060]   Right. You know are you against having the correct call in the games?
[01:21:14.060 --> 01:21:19.820]   So if you want this AI here, you're gonna get a better call every time you come to the plate. So shut up and
[01:21:19.820 --> 01:21:24.220]   What is truth really?
[01:21:24.220 --> 01:21:28.460]   Ask Elon
[01:21:28.460 --> 01:21:30.700]   Good one
[01:21:30.700 --> 01:21:37.100]   Yes, yes, I'm I'm yeah, that was some devil's advocacy continuing in our AI segment anthropic
[01:21:38.380 --> 01:21:42.780]   This is the name that keeps coming up alongside of the big names that we all know about
[01:21:42.780 --> 01:21:48.060]   Google's bard and open a eyes chat gpt microsoft spingshot
[01:21:48.060 --> 01:21:50.780]   anthropic
[01:21:50.780 --> 01:21:53.660]   Is another one of the big AI startups effect they raised?
[01:21:53.660 --> 01:22:00.060]   160 people they raised I think over a hundred million dollars. No, I'm sorry over a billion dollars
[01:22:00.060 --> 01:22:06.540]   Uh to create a AI they are it's just a few weeks before they're gonna release clud
[01:22:06.540 --> 01:22:08.540]   Good
[01:22:08.540 --> 01:22:10.700]   Good
[01:22:10.700 --> 01:22:16.460]   New AI just not a good name the new Pierre maybe but good the new AI chat bot
[01:22:16.460 --> 01:22:19.820]   Uh, they're interested in Francisco. So I don't know why they're calling it clud
[01:22:19.820 --> 01:22:22.540]   Um
[01:22:22.540 --> 01:22:28.780]   There wasn't maybe to get the EU on board. Oh, that's it. That's it. There's a great piece though in the New York times
[01:22:28.780 --> 01:22:34.220]   Sub the headline is inside the white hot center of AI doomerism
[01:22:35.420 --> 01:22:42.220]   Anthropic apparently all the people working in anthropic are convinced that the AI apocalypse is just around the corner
[01:22:42.220 --> 01:22:47.020]   They're long-termers. They're long-termers and I'm glad I'm glad Kevin roose at last
[01:22:47.020 --> 01:22:52.300]   Starts to write about that. There's more people he could have talked to but at last he's starting to acknowledge
[01:22:52.300 --> 01:22:55.660]   That these guys are are cult members
[01:22:55.660 --> 01:23:02.140]   He writes the ones doing this stuff and throw picks employees aren't just worried that their apple break or users won't like it
[01:23:02.140 --> 01:23:04.780]   They're scared at a deep existential level
[01:23:05.340 --> 01:23:07.340]   About the very idea of what they're doing
[01:23:07.340 --> 01:23:14.620]   Building powerful AI models and releasing them into the hands of people who might use them to do terrible and destructive
[01:23:14.620 --> 01:23:22.780]   Things many of them at anthropic believe that AI models are rapidly approaching a level where they might be considered artificial general intelligence
[01:23:22.780 --> 01:23:29.180]   AGI and they fear if they're not carefully controlled these systems could take over and destroy us
[01:23:31.020 --> 01:23:35.500]   And throw picks chief scientist Jared Kaplan says it's five to ten years away
[01:23:35.500 --> 01:23:38.940]   the AI uprising
[01:23:38.940 --> 01:23:44.940]   All right, if you come in for me you better pack really is that what he he idiratically said that or
[01:23:44.940 --> 01:23:49.340]   That's the way they are. That's where these guys are super serious about the stuff. I
[01:23:49.340 --> 01:23:51.820]   Last week I mentioned
[01:23:51.820 --> 01:23:58.140]   Emil Taurus and tim nick eber who are really on top of of this also this week our friend near wise plat
[01:23:59.180 --> 01:24:07.020]   Line 71 did kind of a taxonomy dr. Nies folks. Oh, that's interesting. So she's moved now from tech journalism to a AI
[01:24:07.020 --> 01:24:10.540]   That's interesting good for her. She just watch it. She's watching. She's watching
[01:24:10.540 --> 01:24:13.740]   Yeah moral panicking
[01:24:13.740 --> 01:24:18.220]   Roost writes not every conversation I had at anthropic revolved around existential risk
[01:24:18.220 --> 01:24:20.620]   But dread was a dominant theme at times
[01:24:20.620 --> 01:24:22.460]   I felt like a food writer
[01:24:22.460 --> 01:24:28.540]   Who was assigned to cover a trending new restaurant only to discover that the kitchen staff wanted to talk about nothing but food poisoning?
[01:24:28.860 --> 01:24:30.860]   [Laughter]
[01:24:30.860 --> 01:24:37.900]   One anthropic worker told me he routinely had trouble falling asleep because he was so worried about AI
[01:24:37.900 --> 01:24:46.380]   Another predicted between bites of his lunch that there was a 20% chance that a rogue AI would destroy humanity within the next decade
[01:24:46.380 --> 01:24:51.340]   Then why are they doing what they're doing? This is the financialization issue. I'm like guys
[01:24:51.340 --> 01:24:57.580]   Yeah, it's marketing. It's all the cognitive dissonance is keeping you up at night quit stop
[01:24:58.460 --> 01:25:05.500]   And so it's it's big swing it's big swing and read Richards, you know, it's I think they're there's there's
[01:25:05.500 --> 01:25:08.460]   To defend them they're thinking
[01:25:08.460 --> 01:25:14.780]   Okay, so what we're gonna do is develop an AI with safeguards with guard rates
[01:25:14.780 --> 01:25:21.340]   Well, they're thinking I got to get mine while I can really they're all they're thinking I'm gonna make a fortune because I'm gonna be worried about the future of mankind
[01:25:22.060 --> 01:25:29.580]   And I and your money is best in my hands is your campland Kaplan explained that the gloomy vibe wasn't intentional. It's just what happens
[01:25:29.580 --> 01:25:38.460]   But it's just what happens when anthropic employees see how fast their technology is improving. It's just what happens
[01:25:38.460 --> 01:25:43.820]   It does have a little self promotion promotional clearly doesn't it?
[01:25:43.820 --> 01:25:47.260]   My BS meter has gone way off. Yeah
[01:25:47.260 --> 01:25:49.100]   Way off thing is too
[01:25:49.100 --> 01:25:53.100]   So so there's if you if you do go to that thread and go down algorithm watch
[01:25:53.100 --> 01:25:57.900]   Reinterpreted near its post to the companies involved. So you have
[01:25:57.900 --> 01:26:02.860]   Panic marketing open AI and deep mind and anthropic and Microsoft
[01:26:02.860 --> 01:26:07.580]   They're really trying to say look how powerful we are stop us before we kill mankind
[01:26:07.580 --> 01:26:10.780]   Then you have panic as a business in near its view
[01:26:10.780 --> 01:26:13.420]   Where you have these
[01:26:13.420 --> 01:26:17.740]   Charities that are here or not for profits that are hugely funded
[01:26:17.740 --> 01:26:24.460]   Open philanthropy future of life future of humanity institute. This is what a mule torus writes about this
[01:26:24.460 --> 01:26:29.820]   So so good and they're making a fortune on this this kind of moral entrepreneurship
[01:26:29.820 --> 01:26:36.940]   Of having all this money to give away and then you have the people who are actually worried about the current problems of AI like
[01:26:36.940 --> 01:26:39.580]   dare institute, which is their
[01:26:41.260 --> 01:26:43.260]   tiblica brew and and
[01:26:43.260 --> 01:26:46.380]   Emily bender and marker Mitchell and those folks and
[01:26:46.380 --> 01:26:48.940]   It's it's ridiculous
[01:26:48.940 --> 01:26:55.500]   Spread now and and and and you know, I've been I've defended geeks. I've liked geeks. I've written books about geeks
[01:26:55.500 --> 01:27:02.300]   But these AI boys these long-termers scare me scare me a hell of a lot more than a item. Here's the
[01:27:02.300 --> 01:27:05.660]   picture the venn diagram, I guess of
[01:27:06.380 --> 01:27:10.860]   From algorithm watch of promoters of AI panic and anti panic
[01:27:10.860 --> 01:27:12.940]   Open AI
[01:27:12.940 --> 01:27:18.540]   Is it under the term AI panic marketing deep mind and throw pick microsoft and google?
[01:27:18.540 --> 01:27:26.140]   Panic is a business the future of humanity institute open philanthropy center for AI safety future of life twitter
[01:27:26.140 --> 01:27:31.820]   Anti well elan elan yeah anti panic
[01:27:32.380 --> 01:27:36.540]   Data and society AI now birtman Klein center mozilla the 80
[01:27:36.540 --> 01:27:42.460]   Adelavless institute and human rights folks. That's the tim net gebrew branch algorithm watch
[01:27:42.460 --> 01:27:50.060]   European center for non-profit law again. This is inspired by europe wise plaats structure. I think it's a very good structure of how to look at this
[01:27:50.060 --> 01:27:51.420]   yeah
[01:27:51.420 --> 01:27:53.980]   uh, well, this is good, you know, this is kind of what i've been
[01:27:53.980 --> 01:28:00.060]   Asking about is how is it that these people who are should know better than anybody?
[01:28:00.540 --> 01:28:03.260]   I mean, i'm not an AI expert. They say it's dangerous
[01:28:03.260 --> 01:28:06.940]   Don't they have standing to know that it's dangerous?
[01:28:06.940 --> 01:28:11.820]   No, but it sure seems to me like it's like what are you talking about?
[01:28:11.820 --> 01:28:14.780]   And why aren't you stopping this?
[01:28:14.780 --> 01:28:17.980]   Part of this is their belief that they will reach
[01:28:17.980 --> 01:28:25.260]   uh general intelligence and super intelligence they keep up in it and that's alone is bs
[01:28:25.260 --> 01:28:27.500]   I think it's too much uh
[01:28:27.500 --> 01:28:29.500]   sci-fi part, it's like
[01:28:29.580 --> 01:28:32.860]   it's also like hanging out with that one person who's like
[01:28:32.860 --> 01:28:38.860]   Oh my god, they're they're like eating dessert with you and they're like, oh my god. This is gonna make me so fat
[01:28:38.860 --> 01:28:41.420]   It's so bad for me and you're like then stop it
[01:28:41.420 --> 01:28:44.940]   And yeah, it's just it's it's
[01:28:44.940 --> 01:28:47.180]   Annoying
[01:28:47.180 --> 01:28:49.500]   And it's especially annoying what it's like
[01:28:49.500 --> 01:28:54.780]   Oh, it's not that i'm just gonna you know gain a few pounds or this is gonna make me feel gross later
[01:28:55.180 --> 01:28:57.980]   It's oh, i'm just gonna kill the entire human race. I'm like
[01:28:57.980 --> 01:29:03.900]   Those are very different scales. It's annoying when it's small scale and when it's large scale like this you get no sympathy for that
[01:29:03.900 --> 01:29:06.460]   none
[01:29:06.460 --> 01:29:09.500]   Sorry, I have strong feelings. I just wonder what's going on. I uh
[01:29:09.500 --> 01:29:13.740]   uh
[01:29:13.740 --> 01:29:15.340]   They
[01:29:15.340 --> 01:29:19.020]   Should we can what do you think should we continue working on AI?
[01:29:19.020 --> 01:29:21.580]   Sure
[01:29:21.580 --> 01:29:29.820]   Sure, do you think my question is more like do you think this is even meaningful like or is it just spicy auto correct?
[01:29:29.820 --> 01:29:33.660]   I think right now. Yeah
[01:29:33.660 --> 01:29:40.300]   Well, I think it's very meaningful. I think it can be used to help. I mean, it's already being used to help lower
[01:29:40.300 --> 01:29:46.620]   Uh increase productivity. So I've already used it today to lower the amount of grunt stupid work
[01:29:46.620 --> 01:29:49.420]   I do which i'm all for because then I can spend more time
[01:29:49.900 --> 01:29:52.940]   Right calling people d bags. That's that's kind of he
[01:29:52.940 --> 01:29:57.100]   That's kind of the equivalent and that's a win for society
[01:29:57.100 --> 01:30:04.140]   That's the equivalent of using a combine harvester to harvest your wheat or you know a ho to get the weeds
[01:30:04.140 --> 01:30:10.460]   Uh out of your garden. It's just spicy auto correct also helps too. I mean, yeah. Yeah. It's a tool in other words
[01:30:10.460 --> 01:30:15.500]   Yeah, but it doesn't take over one time. It doesn't it doesn't think the combine harvesters going to take over the world
[01:30:15.500 --> 01:30:17.420]   right, no
[01:30:17.420 --> 01:30:19.420]   Yeah, I mean if you look at
[01:30:19.420 --> 01:30:22.700]   If you wouldn't want to lie under one. No, that would be
[01:30:22.700 --> 01:30:28.620]   Well, if you look at yeah, how people view robots, you know, I'm gonna go well a spicy harvester or harvester compound
[01:30:28.620 --> 01:30:33.900]   I might take over the world a spicy harvester. That sounds like dinner spicy harvest
[01:30:33.900 --> 01:30:37.580]   God i'm totally fine
[01:30:37.580 --> 01:30:43.820]   Google's medical ai chat but chatbot is already be tested in hospitals may have clinics
[01:30:45.020 --> 01:30:48.860]   The story says there's a few errors too. This seems like a bad idea
[01:30:48.860 --> 01:30:55.500]   I'm just saying it's not an existential threat, but it just seems like a bad use of ai maybe why if it inspires
[01:30:55.500 --> 01:30:58.860]   New well, here's the deal
[01:30:58.860 --> 01:31:01.100]   if you give people
[01:31:01.100 --> 01:31:06.460]   A tool that says I can help inspire you to make better decisions. I think that's good
[01:31:06.460 --> 01:31:12.060]   What happens then is oh here's comes our oh buddy financialization comes in and says oh
[01:31:12.700 --> 01:31:17.020]   This can do it so much faster and then we don't need you know, we can cut down
[01:31:17.020 --> 01:31:20.300]   on people by waiting room and you know, y'all
[01:31:20.300 --> 01:31:21.900]   80% wait in room time in the
[01:31:21.900 --> 01:31:25.580]   Well or nurses in the er and instead of having a doctor
[01:31:25.580 --> 01:31:31.020]   We'll just run this ai and that a the nurse will do our have to actually there was a nurse that was suing
[01:31:31.020 --> 01:31:32.700]   I think it was in the wall street journal about this
[01:31:32.700 --> 01:31:35.260]   Like the ai made a decision and the nurse couldn't
[01:31:35.260 --> 01:31:41.580]   Couldn't question it even though she knew the call it was that was not a point that's bad of Margaret Mitchell
[01:31:42.380 --> 01:31:46.460]   And stochastic parrots, which is right these things make errors
[01:31:46.460 --> 01:31:51.420]   Partly because of the way they're trained and we got to pay attention to that
[01:31:51.420 --> 01:31:56.620]   But we also the problem is humans look at a computer say oh computer gave us the answer
[01:31:56.620 --> 01:32:00.780]   It must be true and that's the that's the secondary risk of all this is
[01:32:00.780 --> 01:32:04.540]   Is the schmuck lawyer who used chat gpt
[01:32:07.660 --> 01:32:12.300]   But but see here's this I think that's the primary risk actually is that we people
[01:32:12.300 --> 01:32:18.300]   It's not stupid people. It's gross financial interest that is going to drive people to say
[01:32:18.300 --> 01:32:23.020]   to drive organizations or ownership to say oh
[01:32:23.020 --> 01:32:26.780]   Let's just let the ai do it. Yeah, let us start there at the top
[01:32:26.780 --> 01:32:30.780]   But and I I hesitate calling them stupid people. I think it's just normal people
[01:32:30.780 --> 01:32:36.220]   Who are told computers don't make mistakes. They're right and they're you know and and it's our job
[01:32:36.220 --> 01:32:40.220]   It's incumbent upon us as tech journalists to say no no, that's not true
[01:32:40.220 --> 01:32:45.500]   These are unreliable and you shouldn't trust them garbage. It's not stupidity. It's just you know
[01:32:45.500 --> 01:32:49.180]   We haven't done the it's yeah. We haven't done the job. We have to do of telling them
[01:32:49.180 --> 01:32:53.340]   You know again and again computers make mistakes. Most people know that by now
[01:32:53.340 --> 01:32:58.780]   I hope so this day and age but they but ai somehow seems like a superior kind of computer
[01:32:58.780 --> 01:33:02.460]   Well, it's not just that we think that day like you hear people talk about
[01:33:04.060 --> 01:33:12.460]   We're trying to get to a world where human judgment doesn't matter where you can offset human judgment and the cost of it and
[01:33:12.460 --> 01:33:19.500]   the equivocacy of it the the ability to make those find the nuance because not everyone's going to make the same
[01:33:19.500 --> 01:33:21.900]   Decision the same way, right?
[01:33:21.900 --> 01:33:22.940]   So we
[01:33:22.940 --> 01:33:29.020]   Computers if you it will make the same decision the same way every time and we we trust that because we're like yes
[01:33:29.580 --> 01:33:33.820]   That's right when we start letting people make those decisions
[01:33:33.820 --> 01:33:38.060]   They can be gamed and we fundamentally hate when people get gamed, right?
[01:33:38.060 --> 01:33:42.940]   It's kind of like talking about that's the mistake assuming that the computer doesn't have biases
[01:33:42.940 --> 01:33:50.220]   That doesn't have flaws. It has it's just game further up in the system. The humans that put it together
[01:33:50.220 --> 01:33:54.540]   Put those flaws in they built them in because it's made by humans
[01:33:55.020 --> 01:34:01.100]   So maybe a computer could be a perfect line judge, but I definitely don't think a computer could be a perfect physician
[01:34:01.100 --> 01:34:03.900]   No, no, no
[01:34:03.900 --> 01:34:07.900]   It shouldn't be used as such to be something. It shouldn't be promised as such. That's the other
[01:34:07.900 --> 01:34:13.420]   Part of this problem with the doomerism is they're over promising the power. Yeah, sorry had I just heard you talking
[01:34:13.420 --> 01:34:15.260]   No, I'm just saying it should just be supplemental
[01:34:15.260 --> 01:34:21.100]   The AI yes be supplemental augmenting intelligence. Well, I'll give you an example a physician
[01:34:22.140 --> 01:34:24.140]   Is really two skills
[01:34:24.140 --> 01:34:34.700]   One skill is a memory that can remember all the diagnostic information remember all the possible illnesses and put the two and two together and say you've got Epstein bar syndrome
[01:34:34.700 --> 01:34:39.180]   It's the second part is the person who is a human who can
[01:34:39.180 --> 01:34:46.060]   Interface with a human yeah and talk to them and help them. Okay. Dr. House could not talk to him
[01:34:46.060 --> 01:34:49.580]   Yeah, he had the previous number he was number one not number two
[01:34:50.300 --> 01:34:57.340]   And and truthfully a computer probably could do a better job of diagnosing of remembering all the symptoms and all the diseases
[01:34:57.340 --> 01:35:02.940]   Here's where it really makes a difference. I think is when I had I had a vascularitis or something
[01:35:02.940 --> 01:35:07.100]   And I had fevers and I had a problem in the temple right
[01:35:07.100 --> 01:35:15.340]   And I took all the symptoms to end up for doctors and it was blind men in the elephant right right the cardiologist says it's cardiology
[01:35:15.340 --> 01:35:20.380]   The rheumatologist says it's right the finally it was one guy who happened to be the right guy
[01:35:20.380 --> 01:35:28.540]   Whereas if you could feed all the symptoms in and maybe drive the cardiologist to say no this isn't cardiology actually it's
[01:35:28.540 --> 01:35:34.380]   Something else there's a big if but yes, that's the that's the idea is that you thought in theory
[01:35:34.380 --> 01:35:38.860]   Create a perfect diagnostic machine they might argue with the machine and say no this stupid
[01:35:38.860 --> 01:35:43.580]   I still think you'd want you know humans and they have a treatment end but but you want to
[01:35:44.380 --> 01:35:47.980]   Aspiring possible diagnosis exactly maybe the computer could say well
[01:35:47.980 --> 01:35:52.860]   There's four possibilities given these symptoms there's four possibilities here are the four
[01:35:52.860 --> 01:36:00.140]   And that might make the cardiologist think a little harder about the others that were cardiology related I guess and the other thing that can happen
[01:36:00.140 --> 01:36:02.620]   Which which llms right now don't do
[01:36:02.620 --> 01:36:10.460]   But you want to design it in such a way that it says here's why this diagnosis comes up because there's n percent with this symptom
[01:36:10.700 --> 01:36:14.460]   Right you want to start to tie it to that so that the doctor could be part of the logic of it
[01:36:14.460 --> 01:36:18.300]   So we're getting in our yeah, that's that's the key part because yeah
[01:36:18.300 --> 01:36:20.780]   There are issues like
[01:36:20.780 --> 01:36:22.060]   if if the
[01:36:22.060 --> 01:36:30.380]   Diagnosed the computer diagnostic says oh, I'm basing this diagnosis on the fact that they've got like high white blood cell counts
[01:36:30.380 --> 01:36:36.220]   If they're on a drug that promotes high white blood cell counts and the doctor knows that they can discount that right?
[01:36:36.220 --> 01:36:39.260]   Well, the computer should know it too. I mean the all of this depends
[01:36:39.260 --> 01:36:43.340]   Well, yeah, you're having perfect information has the data. It's got a head of computer can ask
[01:36:43.340 --> 01:36:51.500]   I think that's a new test, you know and say well, but what about this? What's working in our discord? It's just it's a good tool
[01:36:51.500 --> 01:36:58.620]   It's good for looking at cancer x-rays and say and seeing patterns that the human eye doesn't see
[01:36:58.620 --> 01:37:05.180]   We shouldn't use the tool so we're getting our reason. Well, this court has a good example. This is my automatrist
[01:37:06.060 --> 01:37:09.900]   Has automatic machines that measure what your vision numbers are we've done this you go to the automatrist
[01:37:09.900 --> 01:37:11.900]   They sit down from the machine goes
[01:37:11.900 --> 01:37:14.860]   Focuses focuses focuses comes up with the
[01:37:14.860 --> 01:37:22.380]   Prescription, but then he still does it manually himself to double check and refine it and generate the prescription, right?
[01:37:22.380 --> 01:37:24.940]   That's awesome better. That's yours. Not do that better
[01:37:24.940 --> 01:37:31.340]   I haven't been in a couple years. I just can't answer that but I love that idea. Yeah, I love that idea. That's a nice combination
[01:37:31.340 --> 01:37:32.540]   Yeah
[01:37:32.540 --> 01:37:38.540]   I went to the obtima's a couple of weeks ago optometrist a couple of weeks ago and she put a meta quest on my head
[01:37:38.540 --> 01:37:40.860]   Of the our thing
[01:37:40.860 --> 01:37:41.420]   Really?
[01:37:41.420 --> 01:37:45.260]   So they used to do I don't know if this is better. I don't think it's better
[01:37:45.260 --> 01:37:47.260]   They used to you put your chin on the thing
[01:37:47.260 --> 01:37:50.860]   And you look through the thing and it tests your peripheral vision and you have a clicker
[01:37:50.860 --> 01:37:55.500]   And when you can see the light yep, you click it right and it goes all around testing your peripheral vision
[01:37:55.500 --> 01:37:58.460]   Now they put a VR headset on me
[01:37:59.500 --> 01:38:02.460]   And I kind of do the same thing, but I don't think it's as good
[01:38:02.460 --> 01:38:05.900]   I think your obtima's trust is charging you way too
[01:38:05.900 --> 01:38:09.420]   You know, I wanted to say
[01:38:09.420 --> 01:38:14.620]   Can we go back to the the old school way of doing this? So sometimes you move a little too far too fast
[01:38:14.620 --> 01:38:18.620]   Did I see the big E please? Yeah, so well
[01:38:18.620 --> 01:38:25.820]   There's no tracking inside of the the oculus, right? I'm sure there's well. I mean, I don't know but let's I track it
[01:38:25.820 --> 01:38:31.660]   I'm not worried about the privacy thing. Oh, I see what you're saying. Yeah. Well, if you move your head, I don't know
[01:38:31.660 --> 01:38:37.900]   Because that's the thing I've heard about because how else are they gonna just a thing? They must right they must
[01:38:37.900 --> 01:38:40.700]   Hmm. I'm trying to think if I move my head around
[01:38:40.700 --> 01:38:45.980]   I guess that's the point of it is you don't have to put your chin on a you don't have to keep your head still as you move around
[01:38:45.980 --> 01:38:48.460]   Yeah, you don't have to touch this gross thing even though
[01:38:48.460 --> 01:38:54.300]   Instead your whole face is on the roof rule is not because you moved your head to see over here
[01:38:54.460 --> 01:38:59.580]   Yeah, that's why though it was with you, right? So you don't you can't do that. Yeah, I want you can't say
[01:38:59.580 --> 01:39:03.180]   Oh, what's over there because as soon as you look over there, you're still looking at the same
[01:39:03.180 --> 01:39:08.220]   Yeah, I was now you need to go interview. I thought it was a terrible idea
[01:39:08.220 --> 01:39:13.580]   Now you need to go interview. She's a good optometrist. I need to get it. Good optometrist
[01:39:13.580 --> 01:39:14.700]   without the mologist
[01:39:14.700 --> 01:39:16.060]   uh optometrist
[01:39:16.060 --> 01:39:19.740]   Ophthalmologist is a physician. I need this
[01:39:20.300 --> 01:39:25.420]   You go to an opt opt opt you go to a physician. Yes to get your eyes checked for your glasses
[01:39:25.420 --> 01:39:29.820]   Oh, yeah, he lives in New York or outside a new drawer. There's there's a lot of them there
[01:39:29.820 --> 01:39:31.900]   Okay
[01:39:31.900 --> 01:39:34.860]   I don't need an ophthalmologist unless I have something going on
[01:39:34.860 --> 01:39:40.620]   Well, but how are you gonna know what you have going on unless you have the optometrist
[01:39:40.620 --> 01:39:46.460]   Does all the diagnostics and then if my you know if my eyeball pressure is too high
[01:39:46.860 --> 01:39:49.900]   She sends me to the ophthalmologist for glaucoma test
[01:39:49.900 --> 01:39:56.860]   I guess you can afford an ophthalmologist. Do you have eye insurance?
[01:39:56.860 --> 01:40:00.380]   Yeah, but it's terrible. Eye insurance is terrible
[01:40:00.380 --> 01:40:03.580]   Oh, jeff has good eye insurance
[01:40:03.580 --> 01:40:06.300]   That's what i'm guessing if he's going to an op op
[01:40:06.300 --> 01:40:08.460]   I don't even know speaking
[01:40:08.460 --> 01:40:10.700]   I'm not your doctor. Did you see what the
[01:40:10.700 --> 01:40:14.620]   But the producers said about the writers guild strike
[01:40:15.180 --> 01:40:17.180]   Who I don't know which producer it was
[01:40:17.180 --> 01:40:23.260]   Were they how they how did they go on the record with that? Yeah in an interview
[01:40:23.260 --> 01:40:31.500]   Uh the dub okay here we go hollywood studios wga strike endgame is to let writers go broke
[01:40:31.500 --> 01:40:40.300]   Uh one industry veteran. This is from deadline intimate with a point of view of studio ceos
[01:40:41.100 --> 01:40:45.100]   Said I think we're in for a long strike and they're going to let it bleed out
[01:40:45.100 --> 01:40:48.940]   Uh the idea being uh
[01:40:48.940 --> 01:40:55.820]   What you know now that they're on strike the end this is a studio executive who told deadline without you know
[01:40:55.820 --> 01:40:57.660]   Revealing his name
[01:40:57.660 --> 01:41:03.900]   The endgame is to allow things to drag on until the writers guild starts losing their apartments and losing their houses
[01:41:03.900 --> 01:41:10.860]   That's what big businesses do to smaller businesses, right when it comes to yeah
[01:41:11.020 --> 01:41:15.420]   I just can't believe they were like who thought this would like that's going to drive people
[01:41:15.420 --> 01:41:19.340]   Well in a way to stay out as long as they can. Yeah, we're gonna
[01:41:19.340 --> 01:41:25.340]   We're gonna we're in this for long haul. Go ahead. Keep striking. You're gonna lose your place. That's why they're saying it, right
[01:41:25.340 --> 01:41:30.460]   Acknowledging the cold as ice. This is deadline again acknowledging the cold as ice approach
[01:41:30.460 --> 01:41:37.180]   Several other sources reiterated the statement one insider called it a cruel but necessary evil
[01:41:39.180 --> 01:41:43.900]   You know, I can't wait for the guy who comes on and is like well at least we're not sending the pinkertons after them
[01:41:43.900 --> 01:41:47.900]   I think somebody did it could be worse. Yeah
[01:41:47.900 --> 01:41:49.580]   the uh
[01:41:49.580 --> 01:41:54.780]   spokesperson official spokesperson the motion pictures picture and television producers
[01:41:54.780 --> 01:42:02.460]   Association said these anonymous people are not speaking on behalf of the amp dp remember companies who are committed to reaching a deal
[01:42:02.460 --> 01:42:05.420]   And getting our history back to work. There is a negative
[01:42:05.980 --> 01:42:09.580]   For the producers of course, which is they can't produce anything but crap
[01:42:09.580 --> 01:42:12.380]   Until the race come back
[01:42:12.380 --> 01:42:16.220]   So well even when the writers come back a lot of its crap. Yeah, well, that's true
[01:42:16.220 --> 01:42:19.900]   Uh
[01:42:19.900 --> 01:42:23.660]   Okay, what else so much ai stuff there's tons of it more ai stuff
[01:42:23.660 --> 01:42:26.540]   if you um
[01:42:26.540 --> 01:42:28.540]   you pick
[01:42:28.540 --> 01:42:30.540]   um
[01:42:30.940 --> 01:42:53.180]   S
[01:42:53.180 --> 01:42:56.780]   And the reason is so she she wrote a book called confessions of a bed wetter
[01:42:57.580 --> 01:43:05.260]   Uh, the book has unfortunately been pirated and is on what they call shadow library websites like bibliotic library genesis
[01:43:05.260 --> 01:43:13.980]   Z library or available in bulk via torrent systems. So she says she believes the ai is scraping these pirate sites
[01:43:13.980 --> 01:43:15.980]   because
[01:43:15.980 --> 01:43:17.980]   she feels
[01:43:17.980 --> 01:43:19.500]   that
[01:43:19.500 --> 01:43:20.700]   chat gpt
[01:43:20.700 --> 01:43:25.980]   She says here in an open aisute the tree offers exhibits showing that when prompted
[01:43:26.620 --> 01:43:28.940]   chat gpt will summarize their books
[01:43:28.940 --> 01:43:32.940]   Which it couldn't do unless it had seen the copy about it
[01:43:32.940 --> 01:43:37.420]   Silverman's bed wetter is the first book shown being summarized by chat gpt in the exhibits
[01:43:37.420 --> 01:43:42.540]   golden's book error rat is used as an example as his cotteries book sandman slim
[01:43:42.540 --> 01:43:46.700]   So
[01:43:46.700 --> 01:43:48.460]   They're fun. Yeah, I can read the book
[01:43:48.460 --> 01:43:53.260]   There in fact somebody did this to my last books and they're doing it right now to the new one
[01:43:53.660 --> 01:43:58.540]   Where they read it and they sell their own summary. They're free to pay that's this entire show
[01:43:58.540 --> 01:44:03.820]   Just reading other people's enterprise journalism and summarizing it
[01:44:03.820 --> 01:44:08.300]   Right, that's not illegal. They're on a copy right being for transformative
[01:44:08.300 --> 01:44:13.020]   I think it's transformative as can be now the question is did they buy the original copy?
[01:44:13.020 --> 01:44:17.580]   Do they have the right to go to the copy that may be a question but once they do so one is fine
[01:44:17.580 --> 01:44:19.180]   $120 book
[01:44:19.180 --> 01:44:22.540]   And now i've read it and now I can do with it what I want and I can summarize it for you
[01:44:23.340 --> 01:44:24.140]   and um
[01:44:24.140 --> 01:44:27.260]   So this will be interesting to see what the court says because you're right that
[01:44:27.260 --> 01:44:32.540]   It's not like they're reproducing actual verbatim passages from the book. They're summarizing it
[01:44:32.540 --> 01:44:37.260]   It's the essence of copyright says that you can copyright the treatment of information
[01:44:37.260 --> 01:44:41.820]   But not the information itself because in an enlightened society you can't own information
[01:44:41.820 --> 01:44:44.220]   meanwhile, there's a google suit at the same time
[01:44:44.220 --> 01:44:46.700]   down line
[01:44:46.700 --> 01:44:48.700]   67 just got filed as a
[01:44:48.700 --> 01:44:51.180]   class action suit
[01:44:51.260 --> 01:44:53.260]   Which tries to bring against bard
[01:44:53.260 --> 01:44:55.340]   Let's try it unnamed
[01:44:55.340 --> 01:45:00.620]   Complaintance trying to come up with the class action with multiple different tax on this
[01:45:00.620 --> 01:45:05.660]   All the install information belong to real people who shared it online for specific purposes
[01:45:05.660 --> 01:45:08.540]   So they're trying to argue that anything you shared online in public
[01:45:08.540 --> 01:45:13.420]   And google learns from it is theft. Here's a here's a hypothetical
[01:45:13.420 --> 01:45:20.700]   Wikipedia probably somewhere in an article about Sarah Silverman talks about events that are described in that book
[01:45:21.340 --> 01:45:28.460]   Mm-hmm because some editor of wikipedia read the book. Yeah and wrote the article. That's not copyright infringement
[01:45:28.460 --> 01:45:32.780]   Is the only so this is what the judge is going to have to decide is the only difference
[01:45:32.780 --> 01:45:37.900]   That that the web equi-pedi editor bought the book and read it
[01:45:37.900 --> 01:45:42.860]   Versus chat gpt finding a copy of it online and not pay wikipedia
[01:45:42.860 --> 01:45:46.780]   gone to library number one oh and yeah and
[01:45:46.780 --> 01:45:49.020]   and by the way
[01:45:49.020 --> 01:45:52.940]   Chat gpt does not retain the book right once it maps
[01:45:52.940 --> 01:45:58.940]   Relationships the books mutilist to them in fact what we don't know is it may well be that chat gpt
[01:45:58.940 --> 01:46:05.820]   Or any of these is regurgitating somebody else's regurgitation. Yes. Yes, so it may be that chat gpt
[01:46:05.820 --> 01:46:07.820]   Actually did ingest as it did wikipedia
[01:46:07.820 --> 01:46:14.140]   And is repeating something it read on wikipedia that is a repeat of something the editor read on in the book
[01:46:15.260 --> 01:46:18.620]   So I think this is a going to be a very hard case to prove. I understand
[01:46:18.620 --> 01:46:21.340]   Sarah Silverman's point of view
[01:46:21.340 --> 01:46:23.340]   But I think it's a pretty hard case to prove
[01:46:23.340 --> 01:46:30.060]   Uh, and if and even if it's very lussock famously said fair use is the right to hire an attorney if you win
[01:46:30.060 --> 01:46:33.580]   Uh, what the damages might be the cost of the hardcover book
[01:46:33.580 --> 01:46:37.980]   Yeah, right. I mean what it's right. What are you getting? Yeah, what what did you lose?
[01:46:37.980 --> 01:46:42.780]   Very interesting very interesting case the google suit
[01:46:43.580 --> 01:46:46.380]   Says the one is a new york times best selling author
[01:46:46.380 --> 01:46:51.020]   Unnamed whose work was used to train google's ai power chat bot bard
[01:46:51.020 --> 01:46:56.700]   Another is an actor who posts educational material online and believes her work was used to train google products
[01:46:56.700 --> 01:47:02.380]   That will one day make her obsolete two of the plaintiffs are minors six and 13 year olds respectively
[01:47:02.380 --> 01:47:07.820]   Whose guardians are concerned that their online activity is being tracked and harvested by google
[01:47:07.820 --> 01:47:11.180]   So this is completely completely different issues
[01:47:11.740 --> 01:47:14.780]   One is the harvesting of minors data, which is illegal
[01:47:14.780 --> 01:47:19.980]   And there is a there's a six every service out there would not allow a six year old right
[01:47:19.980 --> 01:47:26.940]   Audit right you have to lie in order to get your stuff online. I think these are all going to be thrown out
[01:47:26.940 --> 01:47:33.020]   Uh, although that is like I think there is an interesting using age of people
[01:47:33.020 --> 01:47:34.540]   to
[01:47:34.540 --> 01:47:40.380]   To kind of differentiate more of these suits and if you look at like when the ftc did actually win against amazon one of their
[01:47:40.940 --> 01:47:44.460]   Uh suits was about collecting data from kids
[01:47:44.460 --> 01:47:52.300]   Um under 16 and then not disposing not getting if they can prove that then we got them they got them under kappa
[01:47:52.300 --> 01:47:54.940]   So that's but that's a kappa suit
[01:47:54.940 --> 01:48:01.340]   Not i i think what but i think well people use that as a way to start these kinds of suits
[01:48:01.340 --> 01:48:03.420]   But i think it does bring the
[01:48:03.420 --> 01:48:05.500]   13 is clearly yeah
[01:48:05.500 --> 01:48:09.980]   But that's why it shouldn't be online. It shouldn't be in this i don't think it should be in this suit
[01:48:10.540 --> 01:48:13.260]   The other this is a plaintiff every l's chasing law firm
[01:48:13.260 --> 01:48:19.260]   Yeah, the other plaintiff says my work was used to train google products that'll one day make my job obsolete
[01:48:19.260 --> 01:48:22.300]   Well, sorry. Well, wam wam nuggies
[01:48:22.300 --> 01:48:29.900]   That's completely different issue than the third yeah, right all of us. That's a completely different issue than a 13 year old
[01:48:29.900 --> 01:48:35.420]   So I yeah, this is a this is a junk suit. I don't i'm not going to be covering that
[01:48:36.460 --> 01:48:38.460]   Well, you just did my fault
[01:48:38.460 --> 01:48:44.460]   Um, but but meanwhile what's happening i think is that is you're gonna see places come along and say well in the meantime
[01:48:44.460 --> 01:48:49.260]   We're gonna do a clean version so shutters stock. I think we might have talked about this before
[01:48:49.260 --> 01:48:51.980]   Um, well, he's doing this too
[01:48:51.980 --> 01:48:53.980]   No, right they're doing that
[01:48:53.980 --> 01:48:56.780]   But what's interesting leo is that let's say that let's say this there's a
[01:48:56.780 --> 01:49:01.660]   Suit a training that is that that is licensed. Oh, okay. Yes. Oh, I got you
[01:49:01.660 --> 01:49:04.300]   That's like what did you mean my clean? I got you now. Okay
[01:49:04.860 --> 01:49:10.700]   But what if you wanted to clean up a learning set if if open AI loses and they have to take out a hundred books
[01:49:10.700 --> 01:49:12.700]   Let's say you can't back it out
[01:49:12.700 --> 01:49:15.420]   You can't actually you can
[01:49:15.420 --> 01:49:22.700]   How so all you're gonna do is retrain the models and they're retraining models all the time. Oh, okay?
[01:49:22.700 --> 01:49:23.900]   so
[01:49:23.900 --> 01:49:27.900]   This is actually something I learned about because again that ftc lawsuit because
[01:49:27.900 --> 01:49:34.620]   Amazon part of the settlement was that they would have to eliminate any work product that used some of their ill-gotten
[01:49:34.780 --> 01:49:36.060]   data
[01:49:36.060 --> 01:49:38.060]   Ill-gotten data
[01:49:38.060 --> 01:49:42.060]   So yeah, I mean it's expensive, but you're also retraining your models often
[01:49:42.060 --> 01:49:45.660]   Now is there a way to audit to make sure that's happened?
[01:49:45.660 --> 01:49:48.060]   not really but
[01:49:48.060 --> 01:49:54.700]   Going into this all the way back in like 2016 2017 there was this kind of idea they call it ML ops
[01:49:54.700 --> 01:49:57.180]   and the idea is
[01:49:57.180 --> 01:50:00.620]   Responsible companies and they've been talking about this for a while is you have to think about
[01:50:01.260 --> 01:50:07.980]   Where your training data comes from improving that out that you have rights to it and companies have been doing that for quite some time
[01:50:07.980 --> 01:50:11.980]   Sorry, Bruce snire proposes that there be a
[01:50:11.980 --> 01:50:15.180]   fund that
[01:50:15.180 --> 01:50:18.700]   Creators of AI technologies pay a small fee into
[01:50:18.700 --> 01:50:20.540]   uh
[01:50:20.540 --> 01:50:25.580]   Without all our writings and photos that AI companies using to train their models they'd have nothing to sell
[01:50:25.580 --> 01:50:27.100]   So
[01:50:27.100 --> 01:50:30.060]   We're owed profit says Bruce for data power
[01:50:30.060 --> 01:50:32.220]   Historical
[01:50:32.220 --> 01:50:35.900]   I respect the hell out of Bruce. I think it's the dumbest idea i've heard in years what
[01:50:35.900 --> 01:50:39.420]   Because you're you know it's a tax on reading in the end
[01:50:39.420 --> 01:50:43.020]   It is a tax on reading that if this company comes along and it reads the open internet
[01:50:43.020 --> 01:50:48.620]   And then says well you gotta pay a tax on that to pay to every citizen because you read what we said in the open on the internet
[01:50:48.620 --> 01:50:50.860]   I think it's a terrible idea
[01:50:50.860 --> 01:50:53.740]   You disagree?
[01:50:54.940 --> 01:50:59.500]   I think to make a tax on reading anthropomorphizes it. It's not that it's just tax on scraping
[01:50:59.500 --> 01:51:05.100]   That uh if a if a company writes a tool that scrapes the public internet for data
[01:51:05.100 --> 01:51:07.660]   it should have to
[01:51:07.660 --> 01:51:11.100]   License that data and since you can't say well that data is owned by ant
[01:51:11.100 --> 01:51:15.820]   You don't have a license you have a license you have license you know, so what you do is you say
[01:51:15.820 --> 01:51:21.420]   Well, we're gonna pay a penny per megabyte. We're gonna pay it into fun and everybody will do the old copyright
[01:51:21.900 --> 01:51:25.500]   mentality of earth that i don't know you could think of it more like instead of
[01:51:25.500 --> 01:51:30.700]   Instead of thinking like copyright think of it as like a gasoline tax for wear and tear on the road
[01:51:30.700 --> 01:51:33.180]   Yeah, exactly. So the internet is a public road. There you go
[01:51:33.180 --> 01:51:38.060]   We're all throwing our data on it perfect and else pay into a fund that comes out to us
[01:51:38.060 --> 01:51:43.180]   Perfect analogy, right? Yeah, all right. It's a gas. All right. So so so I
[01:51:43.180 --> 01:51:49.260]   Earlier today I talked to Richard Jingeris as a google is the senior vp news and he told me an amazing story from korea
[01:51:49.340 --> 01:51:52.540]   He had just been there and in korea google's
[01:51:52.540 --> 01:51:55.340]   This is gonna be relevant. I promise you
[01:51:55.340 --> 01:51:57.100]   in korea
[01:51:57.100 --> 01:52:02.940]   Gukles a market share is much smaller smaller than anywhere else. It's they're lose to I think it's called
[01:52:02.940 --> 01:52:05.500]   What's it called a big sir site there?
[01:52:05.500 --> 01:52:08.700]   Mmm, I forget the name of it, but the big site
[01:52:08.700 --> 01:52:15.020]   Uh that has all the news it's it's more like a yahoo and everybody goes to it and all their news is in it
[01:52:15.020 --> 01:52:17.020]   And they license the news
[01:52:17.020 --> 01:52:21.260]   And jingeris said a few years ago he went and he said you're gonna regret this
[01:52:21.260 --> 01:52:28.460]   Because you're gonna want to build your own relationships with customers and you're not building it because everybody gets the news from this big portal
[01:52:28.460 --> 01:52:34.220]   And you're gonna hate this so he goes back and in fact, yes, they hate it. They said you were so right
[01:52:34.220 --> 01:52:36.780]   We don't have anything and they tried to push
[01:52:36.780 --> 01:52:42.220]   The portal to link to them to link to the news producers and the portal came back and said well
[01:52:42.220 --> 01:52:47.580]   Only if you will link to certain number of pages where there's only four ads and you're not allowed to promote your brand
[01:52:47.580 --> 01:52:51.340]   You're not allowed to navigate anything. You're not allowed to sell your own tax basically
[01:52:51.340 --> 01:52:53.660]   Oh
[01:52:53.660 --> 01:52:59.180]   They're trapped and so it's the exact opposite of what's happening in Canada and in australia
[01:52:59.180 --> 01:53:02.060]   Where the publishers are saying we want links
[01:53:02.060 --> 01:53:07.180]   Give us links, please we need links. They have value to us and we can't get them
[01:53:07.180 --> 01:53:11.260]   It's the mirror image of the other places, which is kind of so hilarious. I think
[01:53:11.900 --> 01:53:17.740]   Well, it just goes to show that like there's value in aggregators and you're gonna have to figure out how to
[01:53:17.740 --> 01:53:22.620]   How to monetize or figure out business models that work for that because people
[01:53:22.620 --> 01:53:25.340]   I mean, I guess you could have our
[01:53:25.340 --> 01:53:31.020]   Why do we not have RSS feeds anymore? What happened? I know I know the goal is to get let's get they wonder on
[01:53:31.020 --> 01:53:33.900]   We still have RSS feeds out there
[01:53:33.900 --> 01:53:35.180]   um
[01:53:35.180 --> 01:53:36.540]   They're just
[01:53:36.540 --> 01:53:38.620]   We don't have got an reader out there
[01:53:39.580 --> 01:53:45.420]   Yeah, because there's still there's still some other services there. There's still feedly and stuff like that still doing their thing
[01:53:45.420 --> 01:53:47.500]   That I still use
[01:53:47.500 --> 01:53:49.740]   Yeah, you got all the readers the problem is you got you guys
[01:53:49.740 --> 01:53:52.940]   You're both right stacy's right in the in the big companies
[01:53:52.940 --> 01:53:58.780]   Dave whiner says that rsts has made successful in martin s and holds the senior vp news at the new york times
[01:53:58.780 --> 01:54:06.060]   Chose to put RSS feeds out of the times. That's what made it popular. That's what made people realize the value, right?
[01:54:06.540 --> 01:54:10.940]   So if you don't have a lot of feeds whatever reader you have is no good on the other hand
[01:54:10.940 --> 01:54:13.580]   If people don't have a convenient reader to use like google reader
[01:54:13.580 --> 01:54:17.180]   Then the company the media company say oh, let's stop making it
[01:54:17.180 --> 01:54:21.580]   Yeah, so just stop with this RSS stuff. It's just voice time. I get it
[01:54:21.580 --> 01:54:26.940]   I I hear the chief twit somewhere out there in the hall screaming
[01:54:26.940 --> 01:54:31.180]   But I don't know if it's screaming for joy or screaming of happiness, but something happened
[01:54:31.180 --> 01:54:36.300]   I can't take it anymore. I just had to leave those of you who don't see you can show the chair
[01:54:36.300 --> 01:54:40.540]   I think yeah, there there is. Oh, it's mutiny. He's he's had it
[01:54:40.540 --> 01:54:44.220]   Yes, I heard you
[01:54:44.220 --> 01:54:48.940]   You wrote the rule. I heard you screaming and I was like whoa. I don't know what that screaming is
[01:54:48.940 --> 01:54:52.060]   The fourth wall has been broken korea
[01:54:52.060 --> 01:54:57.340]   Yeah, it was as I said korea in a story. He's like, oh, I got I'm safe
[01:54:57.340 --> 01:55:04.380]   Yeah, I get a bathroom break and coffee put my headphones in yeah, we did do a google story good on us
[01:55:04.780 --> 01:55:10.540]   Yeah, we did we had to do it without you now. We can blame the reason we don't do google in the show. It's all leiswell
[01:55:10.540 --> 01:55:12.780]   I just walked away. That's all
[01:55:12.780 --> 01:55:17.980]   Uh, um, have we concluded that story? We did
[01:55:17.980 --> 01:55:25.900]   It's over in fact it was over quite a while ago and we had to vamp because you were off lolly gang and around out there screaming things
[01:55:25.900 --> 01:55:29.020]   We're terrible at vamping good lord
[01:55:30.700 --> 01:55:34.940]   I was gonna break the fourth wall, but I thought no no I had to have a cup of coffee. I couldn't take it
[01:55:34.940 --> 01:55:39.020]   I wasn't gonna break it. I did that. I did that during her last time. Oh no a jar of a story
[01:55:39.020 --> 01:55:43.020]   You guys get ad breaks. I don't get nothing. I gotta sit here the whole time
[01:55:43.020 --> 01:55:47.900]   And by the way, I'm gonna wrap this up because I gotta ride my tricom and it's getting dark. Oh, yeah
[01:55:47.900 --> 01:55:55.180]   So, uh, you have a light on the tric? Yeah, but i'm not riding in the dark. It's bad enough right in the daylight. It's dangerous out there
[01:55:55.180 --> 01:56:00.540]   Well, wait, how do you how do you does your helmet do left turn right turn? It does. Yeah, that's why
[01:56:00.780 --> 01:56:02.540]   I'm the handlebar you press it goes
[01:56:02.540 --> 01:56:04.540]   On the handlebar you don't have to help oh
[01:56:04.540 --> 01:56:08.540]   Oh
[01:56:08.540 --> 01:56:15.820]   Next time you're out here this because waffles. I'm hungry. Yeah next time we're out here jeff will ride across the golden gate bridge on our bus
[01:56:15.820 --> 01:56:19.420]   So much wrong
[01:56:19.420 --> 01:56:21.820]   Well, okay. All right, so i'm gonna give you one of my numbers here
[01:56:21.820 --> 01:56:27.260]   Um, wait a minute. We okay, but this is an early number. Okay. It's an early number tick tock tick tock
[01:56:27.820 --> 01:56:30.860]   Corner here the scariest bridge in america
[01:56:30.860 --> 01:56:36.700]   Frank garufy jr. A fan of of twig who sent this to me and he's so right
[01:56:36.700 --> 01:56:40.460]   All right, and I nearly had a heart attack on this bridge
[01:56:40.460 --> 01:56:43.100]   And it's a business opportunity
[01:56:43.100 --> 01:56:45.900]   You will see that's necessary for people like me
[01:56:45.900 --> 01:56:52.540]   Terrifying to cross first off. It's really high nearly 200 feet in spots
[01:56:52.540 --> 01:56:55.340]   And it's 4.3 miles long
[01:56:55.660 --> 01:56:56.940]   End to end
[01:56:56.940 --> 01:57:01.980]   First some motorists getting behind the wheel and driving across the chris is inside addition
[01:57:01.980 --> 01:57:03.260]   We're gonna go somewhere
[01:57:03.260 --> 01:57:09.500]   Keep going wait wait wait. It's going so what happened was I suffered a major panic attack my peripheral vision went black
[01:57:09.500 --> 01:57:14.540]   I thought she's my spirit animal to on traffic carol and kasey is so afraid
[01:57:14.540 --> 01:57:19.740]   She actually hires a guy to do the drive. Oh, this is so stupid. I can't even believe this
[01:57:19.900 --> 01:57:25.180]   Driveovers takes carolent. This is the the golden this I would hire him in a scope a bridge
[01:57:25.180 --> 01:57:30.060]   She's scared of the bay bridge. That was like the bay bridge. It's oh, it's not the bay bridge
[01:57:30.060 --> 01:57:33.260]   It's the Delaware. Oh, it's can't island express
[01:57:33.260 --> 01:57:37.500]   I would hire him to drive over the bridge
[01:57:37.500 --> 01:57:40.060]   Would you feel safe if you were driving over the bridge?
[01:57:40.060 --> 01:57:44.220]   I was because I wouldn't pass out from what's so scary about this bridge again
[01:57:44.220 --> 01:57:48.380]   Because it well, I was on this bridge. This is the one that finally did be in
[01:57:49.420 --> 01:57:55.660]   I was coming back. It was icy. I didn't know my tires were pretty bold the wind was really high and I was fish tailing around on the
[01:57:55.660 --> 01:58:01.500]   Oh, wow. Oh, because it's scary. Okay. This is Chesapeake barrier as low a truck has fallen off this bridge
[01:58:01.500 --> 01:58:06.060]   It's the nice lady says oh, I've been across Chesapeake Bay Bridge. Oh, that's a long one
[01:58:06.060 --> 01:58:12.700]   It's two and point two point four miles. That's a long one. Yeah. It's a long long and it's very high and very very steep
[01:58:12.700 --> 01:58:17.820]   Uh, yeah, so he makes a good business. He does this every day driving people back and forth
[01:58:18.220 --> 01:58:20.220]   I have video of you on this bridge
[01:58:20.220 --> 01:58:27.660]   Good call scooter
[01:58:27.660 --> 01:58:32.940]   I don't know which is worse riding a hoverboard or jumping off the bridge frankly
[01:58:32.940 --> 01:58:41.180]   All right. We are going by palms or sweating horribly right now. Wow. Well, you're intentionally scaring yourself. I don't understand it
[01:58:41.180 --> 01:58:47.420]   Oh, oh, you're so cool. I think he's really trying to rehabilitate himself. Okay. Let's do a quick change
[01:58:47.420 --> 01:58:50.220]   Log here. We go play the play the drums play the cattle drums
[01:58:50.220 --> 01:59:01.500]   Notebook lm. This is actually a kind of dual ai
[01:59:01.500 --> 01:59:04.140]   changelog story googles
[01:59:04.140 --> 01:59:07.180]   Ai powered notes app is coming
[01:59:07.180 --> 01:59:10.700]   It's technically launching today for a few people
[01:59:11.820 --> 01:59:19.580]   This was project tailwind. It gives you an AI and they showed this I think at google. Io and ai model trained of the documents
[01:59:19.580 --> 01:59:22.140]   You tell it to look at
[01:59:22.140 --> 01:59:29.340]   Uh small group of users will get this according to a google blog post lm and notebook lm stands for language model
[01:59:29.340 --> 01:59:32.380]   Of course, but it's not a large language model. It's your
[01:59:32.380 --> 01:59:34.940]   Notice steven johnson the famous author
[01:59:34.940 --> 01:59:39.900]   Is the editorial director and uh, they so they hired a writer who's written many books
[01:59:40.220 --> 01:59:44.140]   Because they wanted to know well, how do you take all your notes and all your material what a good idea
[01:59:44.140 --> 01:59:49.260]   A smart i'm going to go down and visit his team at his invitation on the 25th
[01:59:49.260 --> 01:59:55.820]   I was hanging out with a couple of geeky friends one who used to work at meta another guy who's a coder been doing it for years
[01:59:55.820 --> 02:00:01.500]   And uh, brock was the former meta guy brought out this little recording said you might have to record this conversation
[02:00:01.500 --> 02:00:04.540]   We're just sitting around the table talking so we he records like 10 minutes
[02:00:04.540 --> 02:00:09.820]   And then he says well, here's the notes from our conversation apparently he has it set up so damn it loads
[02:00:10.220 --> 02:00:15.900]   It loads the audio to drop box uses whisper ai to transcribe it uses chat gpt
[02:00:15.900 --> 02:00:17.260]   to
[02:00:17.260 --> 02:00:19.980]   generate notes from the conversation and
[02:00:19.980 --> 02:00:21.420]   That's paid
[02:00:21.420 --> 02:00:25.500]   Take a way list an item list of things to do based on it
[02:00:25.500 --> 02:00:28.780]   So he says here's the notes from our conversation. That's pretty cool
[02:00:28.780 --> 02:00:32.460]   And it was mentioned as a try to do this show well
[02:00:32.460 --> 02:00:35.740]   No, let me say
[02:00:35.740 --> 02:00:39.820]   This would be like five minutes. Yeah, the show would be three hours
[02:00:39.820 --> 02:00:44.540]   This conversation that we had was just as discursive and stupid as our show
[02:00:44.540 --> 02:00:51.180]   And and it made it very it did a very good job of it and really made me think this is a future of show notes
[02:00:51.180 --> 02:00:51.820]   I have
[02:00:51.820 --> 02:00:55.580]   Propiled many friends. Yeah, who are using who have a second?
[02:00:55.580 --> 02:00:59.020]   character in zoom
[02:00:59.020 --> 02:01:02.700]   Yes to keep track of it. Yeah, yeah to do the notes
[02:01:02.780 --> 02:01:06.700]   So that's the idea of a notebook lm is you you give it all of your
[02:01:06.700 --> 02:01:13.020]   Texts or whatever for instance in your class. This is for a computer science class
[02:01:13.020 --> 02:01:19.260]   And then it makes the notes and then it does a document. I think this is great if it does a good job
[02:01:19.260 --> 02:01:25.500]   It's fantastic and if it's using the data, you know where it came from. It's not making crap up right right
[02:01:25.500 --> 02:01:30.780]   If if so my child is used this my child has an audio processing disorder
[02:01:30.860 --> 02:01:33.660]   So it can be very hard for them to take in information
[02:01:33.660 --> 02:01:39.580]   Auditorially, so they actually have used things like otter has a service that does this
[02:01:39.580 --> 02:01:42.700]   The challenge is they have to get
[02:01:42.700 --> 02:01:48.620]   The recording permission they have to a get permission but then they have to get the recording close up enough
[02:01:48.620 --> 02:01:51.660]   to the teacher to get
[02:01:51.660 --> 02:01:56.060]   Or like access to a soundboard if you're in a in a classroom, right?
[02:01:56.060 --> 02:02:00.780]   To get a good enough recording to make the notes worthwhile because otherwise it's
[02:02:00.780 --> 02:02:04.780]   a little the transmission does talk in the classroom from other students confuse it or
[02:02:04.780 --> 02:02:07.420]   it can
[02:02:07.420 --> 02:02:11.260]   Brock had a little this device was you know just a little wafer
[02:02:11.260 --> 02:02:15.420]   And you could put this up by the teacher it had a good microphone and apparently
[02:02:15.420 --> 02:02:19.500]   I mean we were sitting around a table. It was in the middle. It got the entire conversation
[02:02:19.500 --> 02:02:24.140]   In fact, it was kind of the insights that came up with were pretty it even recognized his
[02:02:24.140 --> 02:02:26.780]   Charlie's son came in
[02:02:26.780 --> 02:02:33.180]   And he's just graduated from pritzkers because he's you know working as an intern and he's talking about a photo shoot that he did
[02:02:33.180 --> 02:02:35.740]   And then and the AI said
[02:02:35.740 --> 02:02:39.420]   A young man named zack came came in and started talking about photography
[02:02:39.420 --> 02:02:42.060]   He was the things that we decided he should do
[02:02:42.060 --> 02:02:43.980]   Was really great
[02:02:43.980 --> 02:02:47.420]   Brock rak said well, what are some tips for what you tell people when you take pictures?
[02:02:47.420 --> 02:02:50.700]   He summarized it the AI did a great job of summarizing it
[02:02:51.500 --> 02:02:58.460]   Uh, and then I said well who owns the ad agency you're working for the AI said do some research into ad agency ownership
[02:02:58.460 --> 02:03:06.060]   It was pretty it was actually really good. I could see as a student. This would be revolutionary
[02:03:06.060 --> 02:03:13.260]   Revolutionary so although some of the value of taking notes is actually the process. I agree. Yes. I agree
[02:03:13.260 --> 02:03:17.820]   So you should probably do both right do your notes supplement, but then supplement
[02:03:18.220 --> 02:03:23.820]   So does do they use uh otter AI just or is there a special version of it that that they use?
[02:03:23.820 --> 02:03:26.780]   They've used different versions. Well, there's one for education. Look at this
[02:03:26.780 --> 02:03:29.660]   Oh
[02:03:29.660 --> 02:03:34.620]   Oh, this is cool. Oh, this is a good use of AI
[02:03:34.620 --> 02:03:37.420]   I completely agree. This is yeah
[02:03:37.420 --> 02:03:39.420]   It's right destroying me and trying not so much
[02:03:39.420 --> 02:03:44.060]   I mean it kind of depends on your I mean some professors might be like well
[02:03:44.060 --> 02:03:47.740]   The value is in actually taking the notes yourself, which my job would apply with
[02:03:48.140 --> 02:03:50.140]   But I can't do that
[02:03:50.140 --> 02:03:52.940]   Do they have a um
[02:03:52.940 --> 02:03:57.660]   Special uh, what do you call it? Um, they're not an idea of 504 no because they're not in a public school
[02:03:57.660 --> 02:04:03.260]   Uh, I thought well, and I think in our state, I think even private schools have to offer that
[02:04:03.260 --> 02:04:08.940]   Oh, but you know, my child is such a like non disruptive and a pretty decent student who works very hard
[02:04:08.940 --> 02:04:13.900]   So no one is there a problem with this that's the worst thing. You need to be a sneaky wheel
[02:04:14.780 --> 02:04:17.980]   Otherwise, nobody agrees him down. It's so important
[02:04:17.980 --> 02:04:22.140]   I think we had to be the squeaky wheel in our school
[02:04:22.140 --> 02:04:25.100]   I agree. Yeah
[02:04:25.100 --> 02:04:29.580]   Uh android 14 beta 4 let's pixel devices automatically unlock when you type in the pin
[02:04:29.580 --> 02:04:35.020]   Why is that a news story? I don't know sounds like that's how it works, but okay
[02:04:35.020 --> 02:04:40.860]   It's something fail. Oh, the sound of a pin dropping
[02:04:41.100 --> 02:04:46.060]   Was so quiet after that bit of the change law. You could hear a pin drop. Yeah
[02:04:46.060 --> 02:04:49.100]   Oh, google
[02:04:49.100 --> 02:04:53.820]   I got google app rolling out fight you missed every all this you're a slap at that
[02:04:53.820 --> 02:05:00.140]   You miss some of the best stuff there google app is rolling out a finance watch list stock widget
[02:05:00.140 --> 02:05:04.940]   Uh, who would wait what who cares google news?
[02:05:04.940 --> 02:05:08.220]   Offering free four month New York times trial
[02:05:08.460 --> 02:05:12.540]   I shouldn't poo poo this because Jason has worked so hard putting this list together
[02:05:12.540 --> 02:05:15.980]   It's not his fault. He said they're back saying. Yeah. Yeah, what are you what are you?
[02:05:15.980 --> 02:05:22.540]   Hicking me around it's not his fault that google's, you know, well, he did he did add some value to that first story there
[02:05:22.540 --> 02:05:27.660]   Uh, he said it's small but not needed to hit enter after the pin has it been on android
[02:05:27.660 --> 02:05:32.700]   On stock android and yeah, I agree with them on that because that is a bit of having it in there
[02:05:32.700 --> 02:05:35.260]   You put that on and it's like
[02:05:35.260 --> 02:05:38.860]   And I don't need this extra stuff. I hit that last no I turned that on
[02:05:38.860 --> 02:05:42.140]   The enter having to hit enter because otherwise the bad guy
[02:05:42.140 --> 02:05:46.780]   Doesn't need to know how long your pin is you just keeps entering numbers to accept it
[02:05:46.780 --> 02:05:50.060]   Okay, but if he needs to say that's all there is enter
[02:05:50.060 --> 02:05:52.300]   Okay
[02:05:52.300 --> 02:05:54.300]   All right security
[02:05:54.300 --> 02:05:58.780]   Uh, in fact, I thought that was always an option. Maybe it's only an iOS
[02:05:58.780 --> 02:06:01.260]   I thought there was always an option to turn that enter on and off
[02:06:01.260 --> 02:06:05.180]   Uh, get your four months New York times trial for free
[02:06:05.180 --> 02:06:08.460]   From google news. That's pretty amazing that google's becoming a
[02:06:08.460 --> 02:06:12.220]   Marketing agent for the new york times
[02:06:12.220 --> 02:06:18.300]   Google play changes policy on tokenized digital assets
[02:06:18.300 --> 02:06:21.900]   Allowing nft's in apps and games
[02:06:21.900 --> 02:06:24.620]   Well, it's about time
[02:06:24.620 --> 02:06:33.420]   Um, that's cray cray. I just don't think nft's have a place in apps and games. Although I was thinking
[02:06:34.700 --> 02:06:36.700]   Spotify has announced that they're gonna allow
[02:06:36.700 --> 02:06:41.420]   Artists to offer nft's on Spotify that you could just buy
[02:06:41.420 --> 02:06:48.780]   And I think that maybe they're still around yeah, they're still around but uh, but the mistake people made was assuming
[02:06:48.780 --> 02:06:52.220]   Was some sort of investment vehicle right it was a speculative vehicle
[02:06:52.220 --> 02:06:57.740]   But if you say I like taylor swift and I really want to support her i'm or I like ants photos
[02:06:57.740 --> 02:06:59.340]   I said from day one that's different
[02:06:59.340 --> 02:07:03.740]   If it's another way for creators to be able to earn donation wages
[02:07:03.740 --> 02:07:08.700]   I'm totally for it. Just don't buy it thinking. Oh, I'm gonna make with some money. I'm gonna go make bank on this
[02:07:08.700 --> 02:07:11.100]   Taylor Swift identity
[02:07:11.100 --> 02:07:13.420]   It is like honestly
[02:07:13.420 --> 02:07:15.020]   concert
[02:07:15.020 --> 02:07:19.100]   Concert merchandise or something some of that is worth money later on don't that's true
[02:07:19.100 --> 02:07:23.660]   But really you wouldn't encourage people to buy a beanie babies and leave them in the box
[02:07:23.660 --> 02:07:26.140]   Just because you know in 10 years is gonna be worse
[02:07:26.140 --> 02:07:29.260]   No, I would not encourage anyone to buy beanie babies at all
[02:07:29.260 --> 02:07:34.700]   Um, and that's the google change log. Thank you, Jason. Oh, mr
[02:07:34.700 --> 02:07:38.540]   I appreciate it in honor of that. I'm using an all about android mug
[02:07:38.540 --> 02:07:41.580]   For my uh my coffee
[02:07:41.580 --> 02:07:43.020]   Thank you
[02:07:43.020 --> 02:07:47.340]   Don't shed it. Don't cry Jason. We'll be back tomorrow 1 p.m
[02:07:47.340 --> 02:07:50.460]   Pacific in our club twit discord
[02:07:51.020 --> 02:07:55.820]   We are doing more information gathering and research and brainstorming for the AI show which
[02:07:55.820 --> 02:07:59.500]   I might be pulling off to the side of the road to do it tomorrow. I'm gonna see
[02:07:59.500 --> 02:08:01.660]   I have a 130 appointment in kinetic
[02:08:01.660 --> 02:08:02.940]   Jason would yeah
[02:08:02.940 --> 02:08:09.180]   Well, well that's just this week. What next week will we'll work around your schedule because I would I would you know like you to be part of that
[02:08:09.180 --> 02:08:13.180]   Um, I'm very excited. I think we really do need a yeah
[02:08:13.180 --> 02:08:17.580]   A um a show. I'm coming around to that
[02:08:17.580 --> 02:08:20.220]   Uh, you had a great conversation
[02:08:20.860 --> 02:08:21.900]   in
[02:08:21.900 --> 02:08:23.660]   London
[02:08:23.660 --> 02:08:24.700]   with
[02:08:24.700 --> 02:08:26.860]   Alan russ bridger russ burger
[02:08:26.860 --> 02:08:31.820]   former editor bridger for the editor of the guardian now editor prospect magazine
[02:08:31.820 --> 02:08:37.100]   And you can see this uh on the prospect magazine website prospect magazine dot co dot
[02:08:37.100 --> 02:08:43.580]   UK actually it's a youtube video so you could also see it on youtube on there nice on their youtube channel
[02:08:43.580 --> 02:08:47.020]   Nice conversation. It was for alan is brilliant. It was a great conversation
[02:08:47.100 --> 02:08:52.220]   Thank you for the plug this week in google. I appreciate what line is this on there so I can go back
[02:08:52.220 --> 02:08:54.620]   Oh, I found it save you up for 78 got it
[02:08:54.620 --> 02:08:55.500]   Thank you
[02:08:55.500 --> 02:09:03.500]   And I think in the next week or so we'll have video up from the conversation that march march in wickory and then flake good and dug
[02:09:03.500 --> 02:09:06.140]   um
[02:09:06.140 --> 02:09:08.140]   Grab
[02:09:08.140 --> 02:09:09.020]   Doug wilson
[02:09:09.020 --> 02:09:09.980]   Sorry, dog
[02:09:09.980 --> 02:09:15.420]   And I had with uh frank romano at the museum of printing and havoral mass which was just great
[02:09:16.060 --> 02:09:21.580]   Um, I'll also put a video I got to actually type on a line of type for the first time. Oh, you're kidding
[02:09:21.580 --> 02:09:24.540]   That I broke it
[02:09:24.540 --> 02:09:27.340]   A minute
[02:09:27.340 --> 02:09:30.780]   I fixed it. They're messing with you. I was so scared. I was so scared
[02:09:30.780 --> 02:09:33.660]   It bent a matrix, but he
[02:09:33.660 --> 02:09:40.060]   Oh my gosh, where is this on the rundown here? This is one of the type. This is one of the lines that I typed
[02:09:40.060 --> 02:09:42.620]   Right here. Oh, look at that. What did you write?
[02:09:43.420 --> 02:09:46.460]   I publish or perish. Oh good. I like it. That's good
[02:09:46.460 --> 02:09:51.980]   Kudos to you. What would you if you so you you get how many characters
[02:09:51.980 --> 02:09:55.100]   Well, it depends on the line and the and the and the
[02:09:55.100 --> 02:09:57.260]   font size
[02:09:57.260 --> 02:10:00.220]   And I would I would really have to really it depends on the line and on the type
[02:10:00.220 --> 02:10:03.740]   What would you write? What would you you know, you only get one line
[02:10:03.740 --> 02:10:07.660]   On this one or the name or where does it name? No, I wouldn't
[02:10:07.660 --> 02:10:12.140]   What would you write? What would you say and dominate create and dominate?
[02:10:13.180 --> 02:10:17.020]   Dominate. Yep. Period. Just dominate not create dominate. Just dominate
[02:10:17.020 --> 02:10:23.100]   So that'll that'll be up a little bit too is a great conversation about about
[02:10:23.100 --> 02:10:25.100]   shift happens
[02:10:25.100 --> 02:10:32.540]   And martians book and then glen and martian went up to mean to be on press for the printing of shift happens for two
[02:10:32.540 --> 02:10:33.980]   Oh, fawns. Oh, wow
[02:10:33.980 --> 02:10:37.260]   very nice
[02:10:37.260 --> 02:10:39.420]   What so what is it?
[02:10:39.420 --> 02:10:43.020]   What is the idea behind being up for the is that the entire print run?
[02:10:43.020 --> 02:10:48.060]   Yeah, they want to there they're a little antenna. You have to make sure it's beautiful. Yeah. I
[02:10:48.060 --> 02:10:51.100]   Yeah, I I truly don't know like
[02:10:51.100 --> 02:10:57.260]   Okay, if it's a lot of photos. It's not just text. Yeah, yeah
[02:10:57.260 --> 02:11:04.860]   The the guy who does the day in the lifebooks. What was his name? I forgotten now. He's just done here in saw Salido. I love him
[02:11:05.820 --> 02:11:09.180]   uh, I was to I interviewed him some time ago and
[02:11:09.180 --> 02:11:16.300]   Those are such beautiful books. He would go to china where they print him. Yes, exactly check the proofs to make sure
[02:11:16.300 --> 02:11:22.140]   That they match. Yeah, don't they say Rick's moles. Rick small and that's it. Thank you. Yeah. He's a friend of mine too
[02:11:22.140 --> 02:11:25.980]   Oh what a great guy. Yeah, just a wonderful guy. They send you proofs
[02:11:25.980 --> 02:11:29.020]   But you really want to be at the press you kind of have to keep an eye on it
[02:11:29.020 --> 02:11:34.060]   Has aunt ever had a conversation with Rick? I have not but thank you for the oh, yes
[02:11:34.460 --> 02:11:38.860]   Great. We'll get you. That'd be a great look at you hooked up rich sweetheart is unless he's one of my
[02:11:38.860 --> 02:11:46.140]   Just saw Salido. Yeah, it's funny. You mentioned saw Salido hardhead recently went down into saw Salido for a photo walk
[02:11:46.140 --> 02:11:48.620]   Love it down there. It's beautiful. Yeah
[02:11:48.620 --> 02:11:51.420]   Um
[02:11:51.420 --> 02:11:57.980]   Actually, you know be interesting to talk to him about uh, national geographic firing everybody he used to be a photographer for them
[02:11:57.980 --> 02:12:01.740]   So that would be very interesting. All right
[02:12:02.460 --> 02:12:07.660]   Uh, I think that's a good that's a rap kids. I'm gonna get my trike here. Oh before we do that
[02:12:07.660 --> 02:12:11.100]   We've got to do your picks that we can stay tuned stay tuned
[02:12:11.100 --> 02:12:14.060]   No
[02:12:14.060 --> 02:12:16.380]   I want to actually do a little pitch here
[02:12:16.380 --> 02:12:23.420]   For our incredible uh ad sales folks. Yeah, and our and really in a way a pitch for you our audience
[02:12:23.420 --> 02:12:26.060]   We got a great qualified audience
[02:12:26.060 --> 02:12:30.140]   Nielsen says a 56 percent of podcast listeners
[02:12:30.860 --> 02:12:35.580]   Pay more attention when a host reads the ad that's why we do those host read ads
[02:12:35.580 --> 02:12:39.500]   72 percent of our listeners have a job function
[02:12:39.500 --> 02:12:46.140]   uh related directly to technology 87 percent are involved with tech it decisions
[02:12:46.140 --> 02:12:49.500]   We've got top earners listening
[02:12:49.500 --> 02:12:53.420]   You guys 66 percent of our audience earns over a hundred thousand annually
[02:12:53.420 --> 02:12:57.180]   Uh almost a quarter of them over 200,000 annually
[02:12:57.740 --> 02:13:01.500]   Great people and I know you have a great product. Wouldn't you like to
[02:13:01.500 --> 02:13:06.860]   Advertise on our shows to bring your product to our audience. That's what we do
[02:13:06.860 --> 02:13:09.820]   And I think we've got the best team in the world to do this
[02:13:09.820 --> 02:13:13.660]   Not just at least some my wife. I'm a little prejudiced on that one
[02:13:13.660 --> 02:13:16.620]   But I love max and ryan our salespeople
[02:13:16.620 --> 02:13:23.500]   Uh, you can give them a call and then uh, they will talk with you there really I think experts in marketing
[02:13:23.500 --> 02:13:24.780]   They will help you
[02:13:24.780 --> 02:13:29.660]   Market your products not just you know, you give us money. We read ads. It's a really great relationship
[02:13:29.660 --> 02:13:32.300]   We also have an incredible continuity department
[02:13:32.300 --> 02:13:34.780]   headed by debbie and we've got viva
[02:13:34.780 --> 02:13:39.260]   Uh and sabastian and they will give you full service
[02:13:39.260 --> 02:13:44.380]   Everything from copywriting to graphic design, Anthony nelson does great graphics work
[02:13:44.380 --> 02:13:49.820]   All our ads are embedded in the content as you know, which means they're unique every time
[02:13:49.820 --> 02:13:52.860]   We guarantee over delivery on impressions
[02:13:53.420 --> 02:13:57.260]   Uh, we have onboarding services really white glove onboarding service
[02:13:57.260 --> 02:14:01.260]   We give you detailed reporting free of cost when you're our direct client
[02:14:01.260 --> 02:14:05.660]   You get courtesy commercials. You can share on your social media and your landing pages
[02:14:05.660 --> 02:14:11.020]   We also put you lots of freebies like we'll put you in our newsletter that goes at the thousands of fans
[02:14:11.020 --> 02:14:15.020]   We we've had some recession bonuses social media promotion
[02:14:15.020 --> 02:14:16.700]   Of course comes along with it
[02:14:16.700 --> 02:14:21.020]   And we even give you value ads that you don't have to buy shows and ads you don't have to buy
[02:14:21.500 --> 02:14:25.100]   I I could give you testimonial after testimonial. Let me pick one from
[02:14:25.100 --> 02:14:28.380]   You probably seen the ads we do for the thinks canary
[02:14:28.380 --> 02:14:30.700]   Haroon mirror who
[02:14:30.700 --> 02:14:32.860]   You know as founder that company said quote
[02:14:32.860 --> 02:14:38.700]   We expected twit to work well for us because we were long-time listeners who over the years bought many of the products and services
[02:14:38.700 --> 02:14:40.700]   We learned about on various shows
[02:14:40.700 --> 02:14:45.340]   Uh, hooran says we were not disappointed the combination of the very personal ad reads
[02:14:45.340 --> 02:14:50.700]   And the careful selection of products that twit largely believes in give the ads an authentic
[02:14:51.260 --> 02:14:55.260]   Trusted voice that works really well for products like ours 10 out of 10. We'll use again
[02:14:55.260 --> 02:15:01.340]   Thank you haroon. We love you and your product and we're really glad to do those ads. That's the that's a big part of it is
[02:15:01.340 --> 02:15:03.660]   It's a genuine endorsement
[02:15:03.660 --> 02:15:06.060]   from people that you
[02:15:06.060 --> 02:15:12.620]   Uh, your customers will you know trust our listeners are very intelligent. They're very engaged. They are tech savvy
[02:15:12.620 --> 02:15:16.700]   It's a great place to advertise. So I just little pitch for our ad team
[02:15:17.100 --> 02:15:22.460]   You can launch your campaign today break out of the advertising norm and grow your brand by giving an authentic introduction
[02:15:22.460 --> 02:15:31.260]   Uh, for your products and services to a qualified audience by experts. They trust check out what we have to offer a twit.tv/advertise
[02:15:31.260 --> 02:15:38.540]   That's the cold action. Just go to the website twit.tv/ advertise you can send an email from there fell out of form if you want
[02:15:38.540 --> 02:15:46.140]   Uh, but learn more and I think really if you've got a product you want to bring out to an audience of a great audience of engaged listeners
[02:15:46.140 --> 02:15:50.060]   This is the place to do a twit.tv/ advertise
[02:15:50.060 --> 02:15:57.740]   Now it's time for our pick of the week. Let's start with Stacy's thing. Can I call it a thing?
[02:15:57.740 --> 02:16:10.940]   You can Stacy's thing. Not it's it's not always a thing as it were but I was gonna show off a smart button and it didn't arrive in time. Oh, I can't show
[02:16:12.140 --> 02:16:16.700]   A smile. I know that's how I felt. So instead we're just gonna do a quick latency test
[02:16:16.700 --> 02:16:21.580]   And I'm gonna tell you about different ways I use sensors that might be surprising
[02:16:21.580 --> 02:16:30.140]   Um, so this is last week. I showed you the Roku stuff. This is the open close sensor for that. Um, and I was just
[02:16:30.140 --> 02:16:35.660]   I don't know I ran out of buttons because I don't have a smart book basically
[02:16:35.660 --> 02:16:38.700]   So I was like, oh, you know what I need more buttons
[02:16:40.860 --> 02:16:45.180]   I can press to like indicate like an on air or on a call like because my kids
[02:16:45.180 --> 02:16:49.260]   Right now and they do you have an on air like outside your your office
[02:16:49.260 --> 02:16:53.500]   No, and half the time my office is my door is usually open
[02:16:53.500 --> 02:17:00.300]   Because I'm not always recording, but I am sometimes on zoom calls and no one can tell because I'm like
[02:17:00.300 --> 02:17:06.300]   Typing furiously on my notes, you know, and just whatever so I have created
[02:17:07.100 --> 02:17:10.380]   I use this Roku thing. So now you can check latency on this device
[02:17:10.380 --> 02:17:13.980]   I open it. Oh my then
[02:17:13.980 --> 02:17:17.260]   Ta-da. Oh look the lights change. Oh
[02:17:17.260 --> 02:17:20.700]   Is it is it supposed to work that way or did you break it?
[02:17:20.700 --> 02:17:24.060]   No, no
[02:17:24.060 --> 02:17:30.300]   This is just a rule. So I use I you know again when he takes you apart turn on the lights
[02:17:30.300 --> 02:17:33.900]   Yeah, well, it's change color and when I put you back together
[02:17:35.020 --> 02:17:41.100]   Wow, here's the issue. You're also seeing the latency. Yes. Wow. Yes a little bit. Yes
[02:17:41.100 --> 02:17:44.780]   How do we fix that? We are way to fix that?
[02:17:44.780 --> 02:17:47.900]   Use better sensors. Okay
[02:17:47.900 --> 02:17:53.020]   I thought it was kind of maybe inherent in Wi-Fi, you know in the communication
[02:17:53.020 --> 02:17:55.020]   I know this is this is a proprietary
[02:17:55.020 --> 02:17:58.540]   signal that goes to a base station that then goes to the
[02:17:58.540 --> 02:18:02.940]   Cloud that then goes to that's the problem is it goes to the cloud is the
[02:18:03.660 --> 02:18:05.660]   Problem that's not words. Yeah, but
[02:18:05.660 --> 02:18:09.740]   The point is now you got to see two things one
[02:18:09.740 --> 02:18:12.540]   latency on the Roku stuff that I've been testing
[02:18:12.540 --> 02:18:18.220]   Um the review the formal review will be out Friday, but then you also got to see like
[02:18:18.220 --> 02:18:24.700]   I actually we we have this deal where my husband's office is also our guest room. Mm-hmm and
[02:18:24.700 --> 02:18:33.500]   There are lots of LEDs on computer equipment this man has like lights and buttons and rules and bubbles and printers
[02:18:33.660 --> 02:18:39.340]   and like when you when you turn out the lights it it's like that drives Lisa crazy
[02:18:39.340 --> 02:18:42.540]   She does not like it that everything has a light on it these days
[02:18:42.540 --> 02:18:45.180]   drives her nuts so I
[02:18:45.180 --> 02:18:50.780]   Yeah, that's that's one of the reasons why I got an additional smart button and you can use any kind of smart button
[02:18:50.780 --> 02:18:55.020]   but just tie all that into I like using a
[02:18:55.020 --> 02:18:57.580]   What are those called?
[02:18:57.580 --> 02:19:01.260]   The long ones surge protectors. Oh, okay doing a smart surge protector
[02:19:01.260 --> 02:19:05.580]   So you can program certain things like I don't actually love when our Wi-Fi goes off
[02:19:05.580 --> 02:19:09.020]   But it's plugged in down there too. So I turned the led off on the euro
[02:19:09.020 --> 02:19:13.500]   I plugged that into the surge protector, but then I did the surge protector
[02:19:13.500 --> 02:19:20.460]   So only certain of the outlets are turned off and then I created a button. It sounds like a lot jeff is yawning
[02:19:20.460 --> 02:19:29.900]   You give the guests my privacy has been violated. I finally just sued under jade car
[02:19:30.220 --> 02:19:35.260]   You give the guests a button and you're like hey the lights bother you
[02:19:35.260 --> 02:19:40.540]   Boom in this case you get an open closed sensor, but
[02:19:40.540 --> 02:19:47.420]   It's whatever I have lying around at the time. So there you go button. You have an open closed sensor that'll work
[02:19:47.420 --> 02:19:49.580]   Very nice
[02:19:49.580 --> 02:19:53.900]   Tastes tasty ways and turn that off again open it up again. Well, well the cameras on you. Let's count
[02:19:53.900 --> 02:19:55.100]   I was just curious
[02:19:55.100 --> 02:20:01.820]   1001 1000 2 1000 3 1000 4 1005 so five seconds. That's not the end of the world
[02:20:01.820 --> 02:20:08.780]   It's pretty long though. I mean I have some latency in my hu lights, but it's about a second or two. It's not five seconds
[02:20:08.780 --> 02:20:12.620]   Right, it's it's a again the roku stuff. I showed you last week
[02:20:12.620 --> 02:20:15.740]   That's what you're seeing right there today. That's the roku
[02:20:15.740 --> 02:20:20.780]   Close sensor. Do you think it would be better this button that you uh that you didn't get yet?
[02:20:21.180 --> 02:20:24.380]   With it with it be lower. Yes, because it's a matter certified by
[02:20:24.380 --> 02:20:29.820]   Matter talks about like a matter controller. So it's going to be boom local
[02:20:29.820 --> 02:20:32.860]   Interesting
[02:20:32.860 --> 02:20:35.420]   Maybe next week. We'll hope
[02:20:35.420 --> 02:20:36.700]   Okay
[02:20:36.700 --> 02:20:40.860]   Jeff do you have a number of the week? I do I have a number then I have a fun thing
[02:20:40.860 --> 02:20:45.500]   Okay, the number is very quickly from the deloitte digital media trends
[02:20:45.500 --> 02:20:48.460]   Just to a paul old farts out there
[02:20:49.580 --> 02:20:53.740]   younger generations online experiences have become a meaningful part of their lives
[02:20:53.740 --> 02:21:02.140]   Yes, so generation z and millennials being the young kids. Yes generation x boomers and matures being the old farts us. Okay
[02:21:02.140 --> 02:21:04.380]   Old fart
[02:21:04.380 --> 02:21:06.380]   All right now
[02:21:06.380 --> 02:21:08.380]   Are you you're not a you're not a
[02:21:08.380 --> 02:21:11.260]   Boomer born in 78
[02:21:11.260 --> 02:21:17.820]   No, I'm not a boomer. How about gen x? I was a latch key child gen x gen x is old farts. No
[02:21:18.140 --> 02:21:22.700]   Yeah, I thought we were x that's what Jeff just said. Well, you're about to see how old farty they are. Okay
[02:21:22.700 --> 02:21:27.740]   So ask the question. We're using line of type. I believe
[02:21:27.740 --> 02:21:30.540]   Screw you. I believe
[02:21:30.540 --> 02:21:35.820]   Online experiences are meaningful replacements for in-person experiences old farts
[02:21:35.820 --> 02:21:43.500]   19 kids 50 percent say they believe that online experiences are meaningful replacements for in-person experiences
[02:21:43.500 --> 02:21:47.340]   So all the old farts are out there are getting appalled right now. Oh no the internet's are uh
[02:21:47.980 --> 02:21:49.980]   Real life no
[02:21:49.980 --> 02:21:55.020]   This is so the green is the generation z and millennials and the black is the old farts
[02:21:55.020 --> 02:22:00.700]   Actually not more time generation x when is x begin set 16 70
[02:22:00.700 --> 02:22:04.460]   When is generation gen x begin?
[02:22:04.460 --> 02:22:06.540]   68
[02:22:06.540 --> 02:22:08.540]   Okay, no thereabouts
[02:22:08.540 --> 02:22:13.100]   So anybody anybody uh 40 or under over I should say
[02:22:13.100 --> 02:22:14.780]   um
[02:22:14.780 --> 02:22:16.780]   Millennials typically begin at 82
[02:22:17.420 --> 02:22:19.420]   Yeah
[02:22:19.420 --> 02:22:21.260]   Really wow
[02:22:21.260 --> 02:22:28.860]   Yeah, these are such I wonder if really real sociologists use these terms or if it's just us gen x includes those according to
[02:22:28.860 --> 02:22:36.060]   I I bird Dola calm between 1965 and 1981
[02:22:36.060 --> 02:22:39.660]   Okay, yeah, okay
[02:22:39.660 --> 02:22:44.860]   So I spend more time interacting with others on social media than in the physical world
[02:22:45.580 --> 02:22:53.340]   Old farts 20 kids 48 the only thing that's weird to me is how low the 48 is
[02:22:53.340 --> 02:22:55.980]   It's less than half
[02:22:55.980 --> 02:23:01.180]   Uh of gen z and millennials spend time interacting with others and social media more time
[02:23:01.180 --> 02:23:07.260]   And with others it yeah, it seems like it should be a higher number, but okay. They still socialize a lot
[02:23:07.260 --> 02:23:13.660]   That was my number then I have it there in school. Yeah, that's true. That's yeah, but that's interacting with others
[02:23:14.220 --> 02:23:16.220]   in the physical world, right
[02:23:16.220 --> 02:23:20.700]   Right. Well, that's what I'm saying. Oh, I see half the time. That percentage might be so high. Oh, I get it
[02:23:20.700 --> 02:23:24.220]   So maybe the other half they're online and that's it the rest of the time they're online
[02:23:24.220 --> 02:23:29.020]   I specialize in just a video games and I do in the physical world 40
[02:23:29.020 --> 02:23:32.700]   Wow
[02:23:32.700 --> 02:23:38.620]   See I am in the green box on all of these not the black box. I sure you're weird. I am the opposite of uh
[02:23:38.620 --> 02:23:42.300]   There's other stuff in this that which you might find interesting. I just want to wait short
[02:23:42.300 --> 02:23:47.100]   You could take a quick look. What is your methodology good in your opinion? I don't know it's 2000 people
[02:23:47.100 --> 02:23:50.140]   It's that's pretty good enough to fill a thing
[02:23:50.140 --> 02:23:59.100]   So you get enough to make a pdf over Jeff you're good enough to fill a thing and that's all that matters
[02:23:59.100 --> 02:24:02.140]   All right. The fun moment I have
[02:24:02.140 --> 02:24:08.700]   Is and we'll have a Leo accent moment here. I mean just come back from scotland where they fry freaking everything
[02:24:09.100 --> 02:24:11.820]   This is Tony's chip shop yum
[02:24:11.820 --> 02:24:15.100]   And in this case chips or french fries
[02:24:15.100 --> 02:24:17.420]   Yes, yeah
[02:24:17.420 --> 02:24:20.620]   Huge amounts of french fries. Look at all his french fries. He's a whole
[02:24:20.620 --> 02:24:23.420]   Now you got the fish. Yeah
[02:24:23.420 --> 02:24:28.140]   Okay, you can turn the volume up so you can do an accent moment here. All right. Here we go
[02:24:28.140 --> 02:24:30.860]   It's got a
[02:24:30.860 --> 02:24:34.700]   Sticky steps nice little ginships get them real volume
[02:24:34.700 --> 02:24:37.740]   They enter the box
[02:24:37.740 --> 02:24:43.180]   Efforts what happens after they put them in the box
[02:24:43.180 --> 02:24:48.460]   Then you order them two hours. Yeah, and they're gonna get soggy in the box
[02:24:48.460 --> 02:24:55.740]   They're frying everything
[02:24:55.740 --> 02:25:00.780]   Everything is fries a fry pizza slices. They've asked everything
[02:25:01.660 --> 02:25:05.180]   All in the same oil. It's done the fish. No, it's different
[02:25:05.180 --> 02:25:11.820]   In soil bins. It's a whole you have you ever seen an oil fryer that huge no it is an entire
[02:25:11.820 --> 02:25:14.460]   Tik-tok account if you go and look
[02:25:14.460 --> 02:25:20.060]   Take me you're gonna see nothing but things Tony fries. Oh, I got a thing
[02:25:20.060 --> 02:25:23.580]   Did you know you can go to in and out and get your fries well done?
[02:25:23.580 --> 02:25:26.220]   Oh, why are you going in and out?
[02:25:26.220 --> 02:25:29.340]   In and outs overrated
[02:25:29.500 --> 02:25:35.500]   Geez, I never knew I went with an in and out expert. He said you should get him. Well done. I said really he said yeah
[02:25:35.500 --> 02:25:39.100]   It can he said you can get him extra. Well done if you really want to go crazy
[02:25:39.100 --> 02:25:41.660]   I say you should hit the accelerator in your car
[02:25:41.660 --> 02:25:45.740]   Keep on going. No, they're not burned. They're just nice and crispy
[02:25:45.740 --> 02:25:48.620]   Try how you'll like them
[02:25:48.620 --> 02:25:54.460]   I don't have in and out where I live. Oh, I'm so sorry. Yeah, I'm okay with that too. What do you have where you live?
[02:25:54.460 --> 02:25:57.820]   Nothing
[02:25:57.820 --> 02:26:00.940]   That was really sad
[02:26:00.940 --> 02:26:04.140]   So sad
[02:26:04.140 --> 02:26:10.220]   I was like, I don't have good hamburgers. Okay, and often I have peteries. I got nothing here
[02:26:10.220 --> 02:26:13.020]   Nothing you regret leaving breakfast tacos
[02:26:13.020 --> 02:26:17.980]   So much, but I don't regret living in see no that but the food in Austin
[02:26:17.980 --> 02:26:23.500]   There was a great piece in I think the New Yorker about about Austin and how it's changed. I don't know if you read that
[02:26:23.500 --> 02:26:26.460]   We cannot be talking about food right now. Okay. Oh, yeah. Okay
[02:26:27.340 --> 02:26:32.220]   Maybe aunt can give us a thing. All right. Well, I'm gonna do my thing is a shout out
[02:26:32.220 --> 02:26:37.420]   Well, my first thing is a shout out to the wonderful twit staff here mr
[02:26:37.420 --> 02:26:41.020]   Jammerby and mr. Burke because I need a taller desk chair
[02:26:41.020 --> 02:26:47.100]   Um or just maybe a new chair because apparently 230 pounds is too much for my chair
[02:26:47.100 --> 02:26:50.220]   So I'm just sort of shrinking at the desk
[02:26:50.220 --> 02:26:51.660]   And uh mr
[02:26:51.660 --> 02:26:55.980]   Jammer v came up with this beautiful option here a hydraulic gas
[02:26:56.540 --> 02:27:00.060]   Lift cylinder that's going to be going to support my heavy ass
[02:27:00.060 --> 02:27:07.340]   It turns out and it's going to raise my it's an easy thing to replace the hydraulics in office chairs
[02:27:07.340 --> 02:27:11.020]   So we're going to really place that yeah raise my seat up a little bit more
[02:27:11.020 --> 02:27:14.300]   So I don't have a sore floppy wrist while i'm typing
[02:27:14.300 --> 02:27:17.100]   Um, will this work on my chair? Uh
[02:27:17.100 --> 02:27:21.980]   Works on most chairs just one size one size fits all
[02:27:23.100 --> 02:27:26.620]   Um, well, no one size fits up to 400 pounds and then you gotta go to
[02:27:26.620 --> 02:27:37.020]   400 should probably do it aunt. I think so. I think nice. I'm gonna order this because my I have um
[02:27:37.020 --> 02:27:39.020]   a uh
[02:27:39.020 --> 02:27:42.860]   Oh, it's a nice. It's a good office chairs. It is steel. It's what they call it the uh
[02:27:42.860 --> 02:27:47.980]   Steelcase. It's a nice steel case, but it's syncs. That's what i'm in
[02:27:47.980 --> 02:27:52.540]   Yeah, it's syncs like after a few years. It just that's what slowly my chair
[02:27:52.620 --> 02:27:57.580]   It's slowly syncs the air kind of goes out of this what's going on. So this would just I could just put this in my steel case, john
[02:27:57.580 --> 02:28:00.220]   Where did you find out? Look at that
[02:28:00.220 --> 02:28:03.180]   Look at that. Look at that. Mr. Jim. I'm gonna buy this right now
[02:28:03.180 --> 02:28:09.740]   So it just fits you just put it in and because yeah, I noticed that that's the piston in that thing just seems like it just goes in
[02:28:09.740 --> 02:28:12.380]   That's all it is. Yeah, okay
[02:28:12.380 --> 02:28:17.740]   My next pick is uh this morning. I was on floss weekly with mr. Dr. You were on I was on
[02:28:17.740 --> 02:28:19.980]   Nice
[02:28:19.980 --> 02:28:25.900]   Mr. Fips was was going to be on but he's been dealing with a lot of that red hats red hat lennox mess
[02:28:25.900 --> 02:28:30.860]   Yeah, so I filled in and we interviewed mr. Jonathan Bennett. He's the host of the untitled
[02:28:30.860 --> 02:28:34.860]   Untitled lennox show. We love that show. Yeah, and it was a lot of fun
[02:28:34.860 --> 02:28:40.140]   So make sure you go check that out twit.tv slash f l o s s floss as mr
[02:28:40.140 --> 02:28:42.860]   Jim would be brings in a chair. That's a regular chair
[02:28:46.460 --> 02:28:52.780]   It would actually raise it up. Did I just buy an extended cylinder? I don't know what I needed to extend it
[02:28:52.780 --> 02:28:55.660]   Okay, so that's gonna raise it up. Yeah, that's what I did
[02:28:55.660 --> 02:28:59.580]   You can lower it too. How's it gonna fit behind the table? How's he gonna fit his arm?
[02:28:59.580 --> 02:29:04.940]   He's sitting on a crappy old chair here. This isn't the cylinders for my desk. This doesn't go up or down or anything
[02:29:04.940 --> 02:29:11.100]   And you wanted to send out a shout out to Terrell Woods. Yeah, and my last shout out
[02:29:12.300 --> 02:29:19.500]   Oh, wait a minute. Actually, I have the cylinder here. Oh, it just came it came. It's here. Thank you again, mr
[02:29:19.500 --> 02:29:25.500]   Jim or let's let's see if aunt can visually pump iron with it or that. Oh wow. That's okay
[02:29:25.500 --> 02:29:30.540]   So that'll fit in. I don't know. I mean, can you push it down and pull it up? Oh, no, I'm not that tough
[02:29:30.540 --> 02:29:35.420]   I don't think so. You know, heck no, that's nice though. Nice. Thank you mr. Jim or be
[02:29:35.420 --> 02:29:38.060]   And who is Terrell C woods?
[02:29:38.060 --> 02:29:40.060]   Terrell C woods
[02:29:40.940 --> 02:29:43.020]   He is a fan here at twit
[02:29:43.020 --> 02:29:45.820]   Oh nice. Awesome photographer
[02:29:45.820 --> 02:29:51.180]   And he's probably one of the most supportive people I've met since coming to twit when I came out here
[02:29:51.180 --> 02:29:55.660]   He is one of the first people to reach out and has been super supportive of me. Oh
[02:29:55.660 --> 02:30:02.940]   Supportive of the network. He listens to twig. Hello, Terrell regularly. Hold on there. Oh, there's more
[02:30:02.940 --> 02:30:05.340]   but um
[02:30:05.340 --> 02:30:10.780]   Yeah, I tried to stay in touch with them. Mr. Terrell has had gotten sick. Oh, no
[02:30:11.100 --> 02:30:13.100]   Oh, I have a bad saying about this
[02:30:13.100 --> 02:30:17.100]   He sent this to me. Oh about a year and a half ago. Yeah
[02:30:17.100 --> 02:30:22.380]   Here at twit mccallen and I just wanted to say mr. Rell. Thank you for your friendship
[02:30:22.380 --> 02:30:27.100]   He was late to rest this past saturday. I'm sorry and um
[02:30:27.100 --> 02:30:30.380]   Dude, I got all my tears out so i'm not going to cry
[02:30:30.380 --> 02:30:34.220]   But I just want to say thank you for everything you've done for me and the family
[02:30:34.220 --> 02:30:36.700]   If we go to his tour the page right now
[02:30:37.260 --> 02:30:41.020]   His last tweet is of the heart hit that just shows
[02:30:41.020 --> 02:30:47.580]   Support and the love that he had for us. I am so sorry. I'm so grateful. So mr. Terrell
[02:30:47.580 --> 02:30:51.340]   I'm going to pour this poured out for terrell for you
[02:30:51.340 --> 02:30:54.060]   Oh
[02:30:54.060 --> 02:30:56.060]   Rest easy my friend
[02:30:56.060 --> 02:31:01.100]   We have so few listeners. We don't like any of the lose any of them. So uh, I'm glad that uh
[02:31:01.100 --> 02:31:06.780]   Glad to know I just had he ever come up here. He didn't come up here, but he was constantly in our
[02:31:07.580 --> 02:31:14.300]   Social media feeds and he was always sharing our shows just super super super bad. I never met him
[02:31:14.300 --> 02:31:16.700]   Good people great photographer
[02:31:16.700 --> 02:31:18.220]   um
[02:31:18.220 --> 02:31:24.620]   I probably well, I'll tell this I'll tell this in the post show. We I got okay, I can share but I'll say that for post show
[02:31:24.620 --> 02:31:26.940]   Okay, but thank you mr. Terrell
[02:31:26.940 --> 02:31:32.300]   And uh, we're sorry to uh to his family and friends
[02:31:33.580 --> 02:31:37.740]   We're uh, sorry to lose celebrate your life, sir. Look at that. Celebrate there. It is. Yeah
[02:31:37.740 --> 02:31:40.780]   Here's his uh, yeah most of his tweets are
[02:31:40.780 --> 02:31:43.660]   Yeah
[02:31:43.660 --> 02:31:45.660]   Yeah
[02:31:45.660 --> 02:31:46.540]   Oh
[02:31:46.540 --> 02:31:48.300]   Nice. Thank you, sir. Yeah
[02:31:48.300 --> 02:31:53.740]   Well, uh to his family condolences and uh, I guess Lisa known because of all of them
[02:31:53.740 --> 02:32:00.300]   Uh, well that's on that note. I think maybe time to wrap this guy up. I um
[02:32:01.500 --> 02:32:06.780]   Thank you all for being here stay well and stay healthy. We don't want to we don't want to drink too much of this mccallen
[02:32:06.780 --> 02:32:08.780]   You're not touching that. No, no
[02:32:08.780 --> 02:32:11.740]   That's mine
[02:32:11.740 --> 02:32:18.300]   And and is of course our community manager and club twit and he is a great guy to hang out with
[02:32:18.300 --> 02:32:21.980]   That's one of the things that makes club twit so special. So thank you aunt
[02:32:21.980 --> 02:32:28.140]   Uh, and of course his website aunt pruit.com and if you want to look at his beautiful photography aunt pruit.com slash
[02:32:28.940 --> 02:32:35.020]   Prince and for all of you club twit members. We are working on a photo walk here. Oh fun
[02:32:35.020 --> 02:32:39.500]   Um, i'm trying to figure out some dates, but in the meantime club twit members
[02:32:39.500 --> 02:32:45.260]   Make sure you check out the event coming up august 4th for a live photo critique
[02:32:45.260 --> 02:32:49.820]   Uh, and i'm calling it coffee time. That'll be fun. That's what it's going to be based on. That's in the club
[02:32:49.820 --> 02:32:54.060]   Check it out there in the discord and I hope you do more of these. That's a great thing. Yeah, thank you
[02:32:54.060 --> 02:32:58.700]   Uh, jeff jivers is the director of the townite center for entrepreneurial journalism
[02:32:58.700 --> 02:33:00.700]   where at the
[02:33:00.700 --> 02:33:02.860]   craig new mark graduate school of journalism
[02:33:02.860 --> 02:33:09.580]   At the city university of new york his new book is now available at everywhere including amazon
[02:33:09.580 --> 02:33:13.180]   Blackstone books. It's the gutenberg parenthesis
[02:33:13.180 --> 02:33:19.660]   And if you go to gutenberg parenthesis.com you will find uh many ways to purchase it
[02:33:19.660 --> 02:33:25.020]   So uh, congratulations on that book. Yeah, absolutely great to have you jeff
[02:33:25.580 --> 02:33:29.340]   Stacy higgin botham stacy on iot.com is her website
[02:33:29.340 --> 02:33:35.420]   Check it out there. There's a great podcast too. She does with kevin toffle all about iot. It's called the iot show
[02:33:35.420 --> 02:33:37.900]   Thank you stacy
[02:33:37.900 --> 02:33:40.300]   It's called the iot podcast
[02:33:40.300 --> 02:33:46.540]   Technically it's the internet of things podcast. Oh even better the internet of things podcast
[02:33:46.540 --> 02:33:49.900]   Thanks to all our grind influencers for a joint
[02:33:51.420 --> 02:33:56.380]   grind fluency grind fluencers hello grind fluency. Thank you for being here
[02:33:56.380 --> 02:34:01.340]   We do this week in google wednesdays at about 2 p.m. Pacific 5 p.m. Eastern
[02:34:01.340 --> 02:34:04.300]   2100 utc you can watch us do it live at
[02:34:04.300 --> 02:34:07.340]   Live dot twit dot tv. There's actually watch or listen
[02:34:07.340 --> 02:34:13.260]   There's live and audio and video streams there if you're watching live chat with us in our irc open to all
[02:34:13.260 --> 02:34:15.660]   You can use a browser irc
[02:34:15.660 --> 02:34:18.220]   dot twit dot tv
[02:34:19.260 --> 02:34:25.340]   Join the fun gang in there or of course if you're a club member get behind the velvet rope in our club twit
[02:34:25.340 --> 02:34:27.900]   discord with ant
[02:34:27.900 --> 02:34:30.300]   Pruitt's seal of approval
[02:34:30.300 --> 02:34:35.660]   And uh, we gotta get some stickers. I think you're right. We got hey you come join
[02:34:35.660 --> 02:34:43.820]   All you have to do is go to twitter tv slash club twit and find out more
[02:34:43.820 --> 02:34:48.380]   Uh after the fact on demand versions of this show available to it dot tv slash twig
[02:34:48.780 --> 02:34:51.260]   There's a youtube channel dedicated to this week in google
[02:34:51.260 --> 02:34:54.940]   And of course you can subscribe in your favorite podcast player
[02:34:54.940 --> 02:34:57.260]   That's probably the best way to do it and that way you'll get it automatically
[02:34:57.260 --> 02:35:01.180]   The minute it's available. Thank you for being here everybody. We'll see you next time
[02:35:01.180 --> 02:35:03.740]   Bye-bye on this week in google
[02:35:03.740 --> 02:35:06.060]   Bye-bye
[02:35:06.060 --> 02:35:11.180]   Hey there scott wilkinson here in case you hadn't heard home theater geeks is back
[02:35:11.180 --> 02:35:15.260]   Each week I bring you the latest audio video news
[02:35:15.740 --> 02:35:20.780]   Tips and tricks to get the most out of your av system product reviews and more
[02:35:20.780 --> 02:35:25.660]   You can enjoy home theater geeks only if you're a member of club twit
[02:35:25.660 --> 02:35:32.780]   Which costs seven bucks a month or you can subscribe to home theater geeks by itself for only two ninety nine a month
[02:35:32.780 --> 02:35:37.980]   I hope you'll join me for a weekly dose of home theater geeky-tooth
[02:35:38.700 --> 02:35:40.700]   You
[02:35:40.700 --> 02:35:56.140]   Here's how I pick my numbers when I play the new pick five from the virginia lottery. I call it the wheel
[02:35:56.140 --> 02:35:58.780]   We're not to fifty thousand dollars
[02:35:58.780 --> 02:36:05.420]   I've got all the numbers on here plus one extra slot where my wife gets to pick the number five numbers zero through nine
[02:36:05.900 --> 02:36:08.140]   Babe what a lippy burger and fries, please
[02:36:08.140 --> 02:36:16.620]   No, I meant the wheel the what how you choose is up to you play in store in app or online today
[02:36:16.620 --> 02:36:19.420]   Visit the alottery.com/pick five

