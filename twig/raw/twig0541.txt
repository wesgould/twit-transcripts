;FFMETADATA1
title=Translucentized!
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=541
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:01.000]   It's time for Twig.
[00:00:01.000 --> 00:00:04.360]   This week in Google, I'm Jason Howell, filling in for Leo LaPorte this week.
[00:00:04.360 --> 00:00:06.560]   We've got Jeff Jarvis, we've got Matthew Ingram.
[00:00:06.560 --> 00:00:09.920]   We spend a lot of time talking about the consumer electronics show.
[00:00:09.920 --> 00:00:11.800]   Google, of course, has announcements there.
[00:00:11.800 --> 00:00:13.920]   Announcements from all sorts of companies.
[00:00:13.920 --> 00:00:16.440]   OnePlus has a concept phone that they show off.
[00:00:16.440 --> 00:00:21.760]   Samsung has a number of announcements, including the neon artificial humans, chatbot thing that's
[00:00:21.760 --> 00:00:22.760]   really strange.
[00:00:22.760 --> 00:00:27.920]   Plus, we talk a little bit about a leaked memo from BOSS, from Facebook.
[00:00:27.920 --> 00:00:31.840]   It's really interesting, and Fries is apparently going away.
[00:00:31.840 --> 00:00:34.400]   Well, it's really kind of uncertain or sad if it does.
[00:00:34.400 --> 00:00:37.600]   All that more coming up next on this week in Google.
[00:00:37.600 --> 00:00:41.280]   This week in Google is brought to you from LastPass Studios.
[00:00:41.280 --> 00:00:44.780]   Securing every access point in your company doesn't have to be a challenge.
[00:00:44.780 --> 00:00:50.600]   LastPass unifies access and authentication to make securing your employees simple and secure.
[00:00:50.600 --> 00:00:56.640]   Check out lastpass.com/twit to learn more.
[00:00:56.640 --> 00:01:03.640]   Yes, you love.
[00:01:03.640 --> 00:01:07.560]   This is Twig.
[00:01:07.560 --> 00:01:13.840]   This week in Google, episode 541, recorded Wednesday, January 8, 2020.
[00:01:13.840 --> 00:01:16.280]   Translucentized.
[00:01:16.280 --> 00:01:19.480]   This episode of This Week in Google is brought to you by LastPass.
[00:01:19.480 --> 00:01:24.520]   LastPass is a personal password manager and identity solution for businesses that helps
[00:01:24.520 --> 00:01:27.400]   secure everywhere you work and live.
[00:01:27.400 --> 00:01:31.040]   One password gets you in, and LastPass takes care of the rest.
[00:01:31.040 --> 00:01:36.040]   Visit lastpass.com/twit to learn more.
[00:01:36.040 --> 00:01:37.200]   It's time for Twig.
[00:01:37.200 --> 00:01:41.120]   This week in Google, Leel Report, of course, is in Vegas.
[00:01:41.120 --> 00:01:43.520]   This is Consumer Electronics Show Week.
[00:01:43.520 --> 00:01:50.800]   So, Leos in Vegas, along with Ampruit, they are both just traversing the many halls of
[00:01:50.800 --> 00:01:54.760]   the Consumer Electronics Show and checking out all the stuff that we're just going to
[00:01:54.760 --> 00:01:56.400]   talk about here in the studio.
[00:01:56.400 --> 00:01:57.400]   I'm Jason Howell.
[00:01:57.400 --> 00:02:01.520]   Always happy to fill in when Leo is out on this week in Google.
[00:02:01.520 --> 00:02:07.080]   And joining me today, of course, Jeff Jarvis, your first Twig of 2020 of the '20s.
[00:02:07.080 --> 00:02:09.240]   I know it's been gone for a month.
[00:02:09.240 --> 00:02:10.240]   I missed you Twig.
[00:02:10.240 --> 00:02:12.880]   Kind of feels that way, doesn't it?
[00:02:12.880 --> 00:02:14.880]   It's feeling the same way.
[00:02:14.880 --> 00:02:17.440]   And I'm loving that I can say the '20s now.
[00:02:17.440 --> 00:02:22.680]   For some reason, I enjoy the fact that the '20s is no longer the old timey '20s.
[00:02:22.680 --> 00:02:23.680]   It's like the future.
[00:02:23.680 --> 00:02:24.680]   But let me be clear.
[00:02:24.680 --> 00:02:26.240]   Let me be clear.
[00:02:26.240 --> 00:02:29.280]   The decade does not end until the end of this year.
[00:02:29.280 --> 00:02:31.280]   It's been an awful decade.
[00:02:31.280 --> 00:02:32.280]   The '20s.
[00:02:32.280 --> 00:02:35.280]   The '20s start in 2020.
[00:02:35.280 --> 00:02:37.560]   We're going to have this discussion.
[00:02:37.560 --> 00:02:42.000]   I'm pretty much every show of this network.
[00:02:42.000 --> 00:02:43.640]   I get what you're saying.
[00:02:43.640 --> 00:02:45.640]   I would think you would be the...
[00:02:45.640 --> 00:02:46.960]   No, no, no, no, no.
[00:02:46.960 --> 00:02:54.640]   I will go with the 21st century started in 2001 because that's an ordinal.
[00:02:54.640 --> 00:02:56.920]   But the '20s are not an ordinal.
[00:02:56.920 --> 00:02:58.920]   The '20s are the '20s.
[00:02:58.920 --> 00:03:01.000]   Jeff, Jeff, do you have to...
[00:03:01.000 --> 00:03:02.000]   Any 10 years is a decade.
[00:03:02.000 --> 00:03:03.000]   I've got to step in, Jeff.
[00:03:03.000 --> 00:03:08.720]   The only thing you cannot say is that this is the beginning of the 201st decade.
[00:03:08.720 --> 00:03:09.720]   That is incorrect.
[00:03:09.720 --> 00:03:10.720]   That would be incorrect.
[00:03:10.720 --> 00:03:12.120]   Whatever I would say it is the end of a decade.
[00:03:12.120 --> 00:03:14.160]   It wasn't the end of the decade.
[00:03:14.160 --> 00:03:16.400]   A decade is any 10-year period.
[00:03:16.400 --> 00:03:19.560]   A decade just started two seconds ago.
[00:03:19.560 --> 00:03:22.440]   I'm just trying to keep the attention from Matthew here, Michael.
[00:03:22.440 --> 00:03:23.440]   Yeah, right.
[00:03:23.440 --> 00:03:24.440]   Well, I'm curious.
[00:03:24.440 --> 00:03:27.080]   Okay, so we know where you stand, Jeff Jarvis.
[00:03:27.080 --> 00:03:28.080]   What about you, Matthew Ingram?
[00:03:28.080 --> 00:03:34.440]   Matthew Ingram, of course, Chief Digital Writer at CGR.org.
[00:03:34.440 --> 00:03:38.920]   What do you think on this hot topic?
[00:03:38.920 --> 00:03:43.520]   So I think Jeff is technically correct, but it feels as though...
[00:03:43.520 --> 00:03:49.280]   I mean, people just like round numbers, and I think they like to start new things.
[00:03:49.280 --> 00:03:52.200]   So it works better to start with a round number.
[00:03:52.200 --> 00:03:53.200]   Yeah.
[00:03:53.200 --> 00:03:57.800]   There's nothing quite like a nice round number, I totally agree.
[00:03:57.800 --> 00:04:05.640]   The way that I stand on this is when we think of like compilation CDs or CDs, that's so
[00:04:05.640 --> 00:04:09.400]   ancient, compilation albums of like decades.
[00:04:09.400 --> 00:04:11.320]   We include 1980 in the '80s.
[00:04:11.320 --> 00:04:17.640]   We include 1990 in the '90s albums of the greatest hits of the decade.
[00:04:17.640 --> 00:04:20.680]   So therefore, in my mind, it makes sense.
[00:04:20.680 --> 00:04:22.240]   Sorry, Jeff.
[00:04:22.240 --> 00:04:23.240]   Sorry.
[00:04:23.240 --> 00:04:24.240]   You win.
[00:04:24.240 --> 00:04:25.240]   You're outnumbered.
[00:04:25.240 --> 00:04:26.240]   Ha ha ha.
[00:04:26.240 --> 00:04:34.080]   So it's good to have you both here.
[00:04:34.080 --> 00:04:35.080]   Is Stacy at CES?
[00:04:35.080 --> 00:04:37.640]   Is that why she's not on today?
[00:04:37.640 --> 00:04:38.640]   That is correct.
[00:04:38.640 --> 00:04:41.040]   So she is wandering the halls.
[00:04:41.040 --> 00:04:47.760]   And Kevin are both finding all the best IoT things at CES.
[00:04:47.760 --> 00:04:48.760]   Okay.
[00:04:48.760 --> 00:04:56.120]   I just put up, I just saw this, a Weber Connect Smart Grilling Hub, an IoT grill.
[00:04:56.120 --> 00:04:57.120]   Weber Connect.
[00:04:57.120 --> 00:04:58.120]   A what?
[00:04:58.120 --> 00:05:00.120]   Smart Grilling Hub.
[00:05:00.120 --> 00:05:01.120]   Hub.
[00:05:01.120 --> 00:05:05.920]   So your Weber grill could now be connected to the internet.
[00:05:05.920 --> 00:05:06.920]   Okay.
[00:05:06.920 --> 00:05:08.720]   Why?
[00:05:08.720 --> 00:05:10.240]   Because everything's connected to the internet.
[00:05:10.240 --> 00:05:11.240]   It should be.
[00:05:11.240 --> 00:05:12.240]   It's going to be the law.
[00:05:12.240 --> 00:05:15.280]   Yeah, at some point, it's going to be weird if you have something that doesn't connect
[00:05:15.280 --> 00:05:16.800]   to the internet.
[00:05:16.800 --> 00:05:20.240]   I just don't know why my grill needs to be on the internet.
[00:05:20.240 --> 00:05:23.880]   Maybe they'll start profiling people that way, like, you know, Homeland Security, if
[00:05:23.880 --> 00:05:26.600]   you don't, if you have devices that aren't connected.
[00:05:26.600 --> 00:05:28.040]   It'll be suspicious.
[00:05:28.040 --> 00:05:29.680]   Well, that's the guardian.
[00:05:29.680 --> 00:05:35.000]   When the guardian did the Snowden story, they assumed they were doing good hygiene by
[00:05:35.000 --> 00:05:38.760]   getting burner phones and turned out, no, no, no, no, that makes you more suspicious.
[00:05:38.760 --> 00:05:39.760]   Yeah.
[00:05:39.760 --> 00:05:41.960]   And if you use Tor, that's a red flag.
[00:05:41.960 --> 00:05:47.200]   As soon as you use Tor, it's like, oh, yeah, what are you up to?
[00:05:47.200 --> 00:05:48.440]   Wait a minute.
[00:05:48.440 --> 00:05:49.440]   Exactly.
[00:05:49.440 --> 00:05:51.440]   What are you trying to hide?
[00:05:51.440 --> 00:05:52.440]   Exactly.
[00:05:52.440 --> 00:05:53.440]   Okay.
[00:05:53.440 --> 00:05:54.440]   So connected to grill.
[00:05:54.440 --> 00:05:56.600]   Yeah, you're right.
[00:05:56.600 --> 00:05:57.600]   Everything's just going to be connected.
[00:05:57.600 --> 00:05:59.840]   Did you see the, um, the Sherman bot?
[00:05:59.840 --> 00:06:00.840]   Yes.
[00:06:00.840 --> 00:06:02.600]   So what was the name of that thing?
[00:06:02.600 --> 00:06:04.400]   The Sherman robot.
[00:06:04.400 --> 00:06:05.400]   Okay.
[00:06:05.400 --> 00:06:09.360]   I'm happy we're starting with the really, the great products from consumer like Toronto
[00:06:09.360 --> 00:06:15.320]   show, um, Charman's toilet paper robot.
[00:06:15.320 --> 00:06:18.960]   It's a, it's a robot that brings you toilet paper when you need it.
[00:06:18.960 --> 00:06:19.960]   Okay.
[00:06:19.960 --> 00:06:20.960]   Wow.
[00:06:20.960 --> 00:06:21.960]   We started out here.
[00:06:21.960 --> 00:06:22.960]   Yeah.
[00:06:22.960 --> 00:06:25.120]   Enough to already have it there.
[00:06:25.120 --> 00:06:26.120]   You've got some issues.
[00:06:26.120 --> 00:06:28.560]   This is a handy.
[00:06:28.560 --> 00:06:29.560]   The robot.
[00:06:29.560 --> 00:06:30.560]   That's what it's called.
[00:06:30.560 --> 00:06:31.560]   The roll.
[00:06:31.560 --> 00:06:32.560]   Yeah.
[00:06:32.560 --> 00:06:37.520]   So this assumes that although you couldn't come up with toilet paper to keep by the toilet,
[00:06:37.520 --> 00:06:40.320]   you remembered to stock the toilet bot.
[00:06:40.320 --> 00:06:41.320]   Right.
[00:06:41.320 --> 00:06:43.640]   So that you could call it.
[00:06:43.640 --> 00:06:49.360]   And I believe it requires you use your smartphone app in order to summon it.
[00:06:49.360 --> 00:06:53.000]   So you know, some people would say, you know, it's not a good idea to use your smartphone
[00:06:53.000 --> 00:06:55.640]   while you're using, but come on.
[00:06:55.640 --> 00:06:57.200]   That's where everybody uses their phone.
[00:06:57.200 --> 00:06:58.200]   Is it not?
[00:06:58.200 --> 00:06:59.200]   Yeah.
[00:06:59.200 --> 00:07:00.200]   Come on.
[00:07:00.200 --> 00:07:01.200]   What are you going to read?
[00:07:01.200 --> 00:07:04.720]   You're going to read the shampoo bottles like some kind of barbarian.
[00:07:04.720 --> 00:07:07.040]   No, you're going to get in there.
[00:07:07.040 --> 00:07:09.000]   Do your thing and get out.
[00:07:09.000 --> 00:07:12.120]   No need to spend any extra time there.
[00:07:12.120 --> 00:07:16.480]   That's not a room that anyone needs to spend extra time in.
[00:07:16.480 --> 00:07:17.480]   Thank you though, roll bot.
[00:07:17.480 --> 00:07:18.480]   I appreciate your talk.
[00:07:18.480 --> 00:07:20.480]   Can we talk about the most important thing at CES?
[00:07:20.480 --> 00:07:21.480]   All right.
[00:07:21.480 --> 00:07:23.120]   What do you think is the most important thing at CES?
[00:07:23.120 --> 00:07:24.120]   Jeff Jarvis.
[00:07:24.120 --> 00:07:30.320]   The Fiesta Red Samsung Galaxy Chromebook.
[00:07:30.320 --> 00:07:32.560]   It's a pretty nice looking device I have to say.
[00:07:32.560 --> 00:07:33.560]   It really is.
[00:07:33.560 --> 00:07:35.520]   It made me very, very happy.
[00:07:35.520 --> 00:07:38.480]   It doesn't have LTE, but that's okay.
[00:07:38.480 --> 00:07:41.040]   It has everything else.
[00:07:41.040 --> 00:07:46.320]   It, I think a good processor, you tell me.
[00:07:46.320 --> 00:07:47.920]   And it's the i5, I think.
[00:07:47.920 --> 00:07:49.920]   It's below there.
[00:07:49.920 --> 00:07:51.920]   It's a good one.
[00:07:51.920 --> 00:08:00.680]   It has a pen and it has a 4K screen, 19 and 6 kind of unfortunately, but that's where
[00:08:00.680 --> 00:08:02.800]   the world is going.
[00:08:02.800 --> 00:08:10.560]   And it looks like Google cooperated and this is the new Pixel Rank Chromebook.
[00:08:10.560 --> 00:08:12.560]   Pixelbook level.
[00:08:12.560 --> 00:08:13.560]   Yeah.
[00:08:13.560 --> 00:08:16.520]   It starts at $999, so this is an expensive.
[00:08:16.520 --> 00:08:18.760]   This is a go up to a tera-like.
[00:08:18.760 --> 00:08:23.240]   I think there's a gray, there's gray, your standard gray.
[00:08:23.240 --> 00:08:26.680]   There's boring gray and fiesta red.
[00:08:26.680 --> 00:08:31.760]   It's like a really nice machine.
[00:08:31.760 --> 00:08:37.840]   It's 2.3 pounds, which is really light lighter than the Chroma Pixel.
[00:08:37.840 --> 00:08:38.920]   Very thin.
[00:08:38.920 --> 00:08:42.600]   The only complaint I heard from anybody is the result of its thinness.
[00:08:42.600 --> 00:08:45.200]   The travel on the keyboard is not quite what it was.
[00:08:45.200 --> 00:08:46.760]   But it doesn't have a console.
[00:08:46.760 --> 00:08:47.760]   Okay.
[00:08:47.760 --> 00:08:51.640]   So I got to try it first, but I'm looking forward.
[00:08:51.640 --> 00:08:52.640]   My machine is wonderful.
[00:08:52.640 --> 00:08:56.320]   I love my Chroma Pixel, but it's just, I pound on it so much.
[00:08:56.320 --> 00:08:59.600]   It's, is it wearing at this point?
[00:08:59.600 --> 00:09:01.600]   Is it starting to kind of work out?
[00:09:01.600 --> 00:09:02.600]   It's wearing.
[00:09:02.600 --> 00:09:03.600]   Okay.
[00:09:03.600 --> 00:09:10.500]   I know this is, this is probably heresy, but if it's, if it's a thousand dollars or so,
[00:09:10.500 --> 00:09:12.600]   why wouldn't I just get a MacBook Air?
[00:09:12.600 --> 00:09:17.280]   Because I, because Matthew, Matthew, for what you just had to go through.
[00:09:17.280 --> 00:09:20.120]   You had to install a driver.
[00:09:20.120 --> 00:09:22.160]   What is this thing you call a driver?
[00:09:22.160 --> 00:09:24.560]   So this is the thing you call it.
[00:09:24.560 --> 00:09:25.560]   It's all.
[00:09:25.560 --> 00:09:26.560]   I know what you mean.
[00:09:26.560 --> 00:09:27.560]   Okay.
[00:09:27.560 --> 00:09:33.240]   I just, the whole damn world of the web is there at my beck and call and that's all
[00:09:33.240 --> 00:09:34.240]   I need.
[00:09:34.240 --> 00:09:35.240]   Yeah.
[00:09:35.240 --> 00:09:36.240]   That's it.
[00:09:36.240 --> 00:09:37.240]   I don't edit video.
[00:09:37.240 --> 00:09:39.000]   If I edit a video, it wouldn't be great.
[00:09:39.000 --> 00:09:46.600]   But other than that, it's, I've never had to hassle with, with cruff, with, with reinstalling
[00:09:46.600 --> 00:09:47.600]   things.
[00:09:47.600 --> 00:09:48.600]   This machine did slow down.
[00:09:48.600 --> 00:09:50.480]   I got a little bit pokey.
[00:09:50.480 --> 00:09:52.200]   So I said, okay, what the hell?
[00:09:52.200 --> 00:09:54.360]   Rebuild it took literally two minutes.
[00:09:54.360 --> 00:09:55.360]   Yep.
[00:09:55.360 --> 00:09:56.360]   Literally.
[00:09:56.360 --> 00:09:57.360]   Yeah.
[00:09:57.360 --> 00:10:03.240]   It's just, it's just, it's, it doesn't get in the way of life anymore.
[00:10:03.240 --> 00:10:04.240]   Right?
[00:10:04.240 --> 00:10:05.240]   Right.
[00:10:05.240 --> 00:10:13.240]   So it's like, it's like when telephones went from having to say, centering, central,
[00:10:13.240 --> 00:10:18.160]   connect me to a telephone you picked up and dialed, right?
[00:10:18.160 --> 00:10:19.960]   It's easy to remember those days.
[00:10:19.960 --> 00:10:22.960]   Oh, screw you.
[00:10:22.960 --> 00:10:27.320]   Pennsylvania, six, one thousand.
[00:10:27.320 --> 00:10:33.680]   I'm telling you, I've been on a Chromebook now for well more than three years and I wouldn't,
[00:10:33.680 --> 00:10:35.120]   I wouldn't, I wouldn't go back.
[00:10:35.120 --> 00:10:36.120]   I love it.
[00:10:36.120 --> 00:10:37.120]   Love it.
[00:10:37.120 --> 00:10:41.400]   I mean, my Chromebook, the, the Pixelbook is what I use here on all of my shows.
[00:10:41.400 --> 00:10:45.880]   I use it for everything that I do here on a, in a, from a mobile sense.
[00:10:45.880 --> 00:10:50.880]   But I'm sitting at my desk and I'm using a Mac, for what reason?
[00:10:50.880 --> 00:10:54.960]   Probably just because in that environment, I can spread everything out on a couple of
[00:10:54.960 --> 00:10:57.760]   screens and I like to be able to work like that.
[00:10:57.760 --> 00:10:59.600]   I think you could do that with a Chromebook, right?
[00:10:59.600 --> 00:11:02.880]   Can you mirror to a couple of different screens and everything?
[00:11:02.880 --> 00:11:04.360]   So I could split it out.
[00:11:04.360 --> 00:11:10.320]   I don't, I don't see in my, in my everyday life, what going 100% Chromebook would really
[00:11:10.320 --> 00:11:14.880]   limit me because I don't do much of anything like you, Jeff, anymore.
[00:11:14.880 --> 00:11:19.400]   Um, on a computer that a Chromebook doesn't already do, most of everything that I do is
[00:11:19.400 --> 00:11:21.720]   in the web, except for music production.
[00:11:21.720 --> 00:11:25.360]   And that would be the one thing that was, that was going to be the other one had been
[00:11:25.360 --> 00:11:28.520]   programming, but now that you can, you can run Linux on it.
[00:11:28.520 --> 00:11:29.520]   Yeah.
[00:11:29.520 --> 00:11:30.520]   Yeah.
[00:11:30.520 --> 00:11:31.520]   Absolutely.
[00:11:31.520 --> 00:11:36.000]   So, so then when I think of a thousand dollars for a Chromebook, like one hand, I get it because
[00:11:36.000 --> 00:11:40.400]   I'm using one, you know, the Pixelbook can be that expensive as well.
[00:11:40.400 --> 00:11:42.800]   And I love the Pixelbook that I have right now.
[00:11:42.800 --> 00:11:48.040]   So I understand the value, but at the same time, it's also kind of a luxury item.
[00:11:48.040 --> 00:11:49.560]   What is your phone cost?
[00:11:49.560 --> 00:11:50.800]   What is your phone cost?
[00:11:50.800 --> 00:11:54.120]   Well, phones cost upwards of a thousand dollars too.
[00:11:54.120 --> 00:11:55.120]   Yeah.
[00:11:55.120 --> 00:11:59.240]   And it's got a total screen compared, you know, so it's, it's, and we use it constantly.
[00:11:59.240 --> 00:12:00.240]   Yeah.
[00:12:00.240 --> 00:12:02.320]   I, I get so tired of the tech sites because they did it again.
[00:12:02.320 --> 00:12:03.320]   The CES.
[00:12:03.320 --> 00:12:06.920]   Well, I don't know if you're not everybody can once a Chromebook because that we've heard
[00:12:06.920 --> 00:12:08.520]   this spiel a million times already.
[00:12:08.520 --> 00:12:09.520]   Yeah.
[00:12:09.520 --> 00:12:10.520]   Right.
[00:12:10.520 --> 00:12:13.240]   And it's not just the 80s, they get it.
[00:12:13.240 --> 00:12:15.200]   But I, I, it's been important for me.
[00:12:15.200 --> 00:12:19.200]   The reason I'm happy is I want a premium Chromebook out there at this level of standard.
[00:12:19.200 --> 00:12:20.200]   Yeah, me too.
[00:12:20.200 --> 00:12:24.120]   And when Google didn't come up with a new Chromebook Pixel and they come up with a go,
[00:12:24.120 --> 00:12:28.200]   I got worried that they were going to abandon that high end of the market.
[00:12:28.200 --> 00:12:32.160]   And I'm of course, the high end.
[00:12:32.160 --> 00:12:37.360]   So that is one of the things I like about the MacBook Air is the build quality and the,
[00:12:37.360 --> 00:12:39.720]   you know, it's not just that I like Apple.
[00:12:39.720 --> 00:12:46.800]   I mean, I, I use Linux on the desktop, use Windows if I have to, but I like the MacBook
[00:12:46.800 --> 00:12:49.160]   partly because of the way it's built.
[00:12:49.160 --> 00:12:55.560]   And I've been looking for a Pixelbook that had the same sort of level of, you know, the
[00:12:55.560 --> 00:12:57.040]   books all as craftsmanship.
[00:12:57.040 --> 00:13:02.640]   I would, I would put the, the Pixelbook up against the Mac, especially when I hear Mac
[00:13:02.640 --> 00:13:04.320]   owners not complaining about keyboards and stuff.
[00:13:04.320 --> 00:13:05.320]   Yeah.
[00:13:05.320 --> 00:13:08.920]   If you get, if you get the low end Samsung Chromebook, absolutely not.
[00:13:08.920 --> 00:13:09.920]   It's titty.
[00:13:09.920 --> 00:13:10.920]   Absolutely.
[00:13:10.920 --> 00:13:14.360]   But the Pixelbook Go is back level quality.
[00:13:14.360 --> 00:13:15.360]   Yes.
[00:13:15.360 --> 00:13:16.360]   Okay.
[00:13:16.360 --> 00:13:17.360]   Yeah.
[00:13:17.360 --> 00:13:21.400]   And I have still not seen the Pixelbook go in person to make that, that determination.
[00:13:21.400 --> 00:13:23.040]   I would say that about the Pixelbook.
[00:13:23.040 --> 00:13:24.040]   I'm a pixel book.
[00:13:24.040 --> 00:13:25.040]   I'm sorry, but the Pixelbook.
[00:13:25.040 --> 00:13:26.040]   Oh, okay.
[00:13:26.040 --> 00:13:27.040]   All right.
[00:13:27.040 --> 00:13:29.960]   Because I would say I would definitely say that about the Pixelbook and the Go.
[00:13:29.960 --> 00:13:31.880]   Kevin said the keyboard is just as good.
[00:13:31.880 --> 00:13:32.880]   Okay.
[00:13:32.880 --> 00:13:33.880]   The screen is better.
[00:13:33.880 --> 00:13:36.720]   I did, I did go to the Best Buy and I did touch it.
[00:13:36.720 --> 00:13:37.720]   And it's very, very nice.
[00:13:37.720 --> 00:13:38.720]   Nicely built.
[00:13:38.720 --> 00:13:41.080]   And aluminum body, like an aluminum build.
[00:13:41.080 --> 00:13:45.000]   So if that's something that you really like your laptops to have, it's not that.
[00:13:45.000 --> 00:13:46.680]   It's going to be more of a plastic approach.
[00:13:46.680 --> 00:13:50.240]   But yeah, people seem to really like it.
[00:13:50.240 --> 00:13:52.160]   I have yet to see it in person.
[00:13:52.160 --> 00:13:54.880]   So anyway, so that just made me happy out of CES.
[00:13:54.880 --> 00:13:57.240]   I didn't expect big book news out of CES.
[00:13:57.240 --> 00:14:01.400]   I thought it was going to be another, you know, Samsung this and another ISIS that and
[00:14:01.400 --> 00:14:04.000]   pieces that and there's some of that going on.
[00:14:04.000 --> 00:14:08.200]   There's some other nice machines coming out, but this, this looks like a high level machine.
[00:14:08.200 --> 00:14:10.880]   And what was yours there, Jason?
[00:14:10.880 --> 00:14:12.240]   This, this Pixelbook?
[00:14:12.240 --> 00:14:14.520]   This is what this is a couple of years old now?
[00:14:14.520 --> 00:14:20.360]   Well, I think you got to go to the boss and say you need a new one, don't you?
[00:14:20.360 --> 00:14:21.480]   Well, I mean, that's the thing.
[00:14:21.480 --> 00:14:25.560]   Like when that's why I was asking you how yours has has fared.
[00:14:25.560 --> 00:14:27.960]   This device still works great.
[00:14:27.960 --> 00:14:32.320]   Like I couldn't think of a reason why I don't continue to use it.
[00:14:32.320 --> 00:14:33.320]   Maybe I should be saying that out loud.
[00:14:33.320 --> 00:14:34.760]   It's very simple.
[00:14:34.760 --> 00:14:36.600]   It's consumerist disease.
[00:14:36.600 --> 00:14:37.600]   Yeah.
[00:14:37.600 --> 00:14:38.600]   Right.
[00:14:38.600 --> 00:14:39.600]   I'm kind of proud of myself.
[00:14:39.600 --> 00:14:43.080]   Like what you know, that's fine with it.
[00:14:43.080 --> 00:14:44.080]   What's that?
[00:14:44.080 --> 00:14:49.640]   Do you think you'd notice a difference with the speed like with a new processor or more
[00:14:49.640 --> 00:14:50.640]   RAM?
[00:14:50.640 --> 00:14:53.360]   All it really matters is how many tabs you're running.
[00:14:53.360 --> 00:14:54.360]   Yeah.
[00:14:54.360 --> 00:14:56.320]   And I don't run many tabs.
[00:14:56.320 --> 00:14:57.320]   Really?
[00:14:57.320 --> 00:15:02.520]   The favorite king of tabs is the head of Nimen lab.
[00:15:02.520 --> 00:15:09.280]   But he pridefully has like literally 200 tabs open all the time on his chrome.
[00:15:09.280 --> 00:15:10.280]   How do you do that?
[00:15:10.280 --> 00:15:12.840]   I know some might even beat him though.
[00:15:12.840 --> 00:15:18.680]   So Mike Masnick from Tector is close to 500 is standard.
[00:15:18.680 --> 00:15:22.200]   How do you navigate that?
[00:15:22.200 --> 00:15:23.680]   I don't even understand.
[00:15:23.680 --> 00:15:27.720]   I don't even understand how you do that and how you're efficient like with 500 tabs open.
[00:15:27.720 --> 00:15:28.720]   Like you're not.
[00:15:28.720 --> 00:15:30.840]   That's just random noise.
[00:15:30.840 --> 00:15:33.360]   And you're like I have to imagine in that regard.
[00:15:33.360 --> 00:15:35.240]   I would love to hear an explanation of it.
[00:15:35.240 --> 00:15:39.180]   I have to imagine in that regard, you're still only working with like the visible like
[00:15:39.180 --> 00:15:42.400]   10 tabs or whatever and everything else is just pushed off.
[00:15:42.400 --> 00:15:45.160]   You can't bring yourself to close it because you don't want to lose it or something.
[00:15:45.160 --> 00:15:46.160]   I don't know.
[00:15:46.160 --> 00:15:50.480]   One tab starts playing music and then you can't figure which one it is.
[00:15:50.480 --> 00:15:51.480]   Shoot.
[00:15:51.480 --> 00:15:52.480]   And you have 500.
[00:15:52.480 --> 00:15:53.480]   No, thank you.
[00:15:53.480 --> 00:15:54.480]   That's my name.
[00:15:54.480 --> 00:15:58.040]   It's like how Gmail introduced search instead of sorting.
[00:15:58.040 --> 00:16:01.920]   You don't actually sort through all the tabs.
[00:16:01.920 --> 00:16:05.360]   You just open a new one whenever you need it.
[00:16:05.360 --> 00:16:11.000]   And if your machine isn't slowing down with that management process, if you want to call
[00:16:11.000 --> 00:16:15.640]   it that, then there's no real reason to close those tabs anyways.
[00:16:15.640 --> 00:16:19.280]   But I can't understand like I asked him, how could it not slow down?
[00:16:19.280 --> 00:16:24.240]   If you're using Chrome, each one of those tabs is a separate browser instance and it's
[00:16:24.240 --> 00:16:26.040]   using RAM.
[00:16:26.040 --> 00:16:27.040]   How the hell?
[00:16:27.040 --> 00:16:29.520]   He must have 800 gigabytes of RAM.
[00:16:29.520 --> 00:16:34.520]   So Matthew, they did do some change sometime back where they kind of it recognizes an unused
[00:16:34.520 --> 00:16:35.520]   tab.
[00:16:35.520 --> 00:16:37.520]   Oh, got throttles and down.
[00:16:37.520 --> 00:16:41.480]   That was a little while ago, I think.
[00:16:41.480 --> 00:16:45.840]   Still, still that just seems like a data point that you're that you're bragging.
[00:16:45.840 --> 00:16:50.440]   But it's like, yeah, it's absolutely nothing.
[00:16:50.440 --> 00:16:52.760]   It's meaningless one upmanship.
[00:16:52.760 --> 00:16:53.760]   Totally.
[00:16:53.760 --> 00:16:57.400]   Although, I love you, Mike, I love your work.
[00:16:57.400 --> 00:16:59.560]   He's been on Tech News Weekly a number of times.
[00:16:59.560 --> 00:17:00.560]   Oh, yeah.
[00:17:00.560 --> 00:17:02.040]   He's been on that work a number of times and everything.
[00:17:02.040 --> 00:17:03.040]   But he's insane.
[00:17:03.040 --> 00:17:04.040]   But oh my goodness.
[00:17:04.040 --> 00:17:05.040]   I just don't understand.
[00:17:05.040 --> 00:17:07.040]   Have you ever seen him do a PowerPoint?
[00:17:07.040 --> 00:17:08.040]   No.
[00:17:08.040 --> 00:17:14.760]   So he used to come to a conference I did in Toronto and his his PowerPoints are so in
[00:17:14.760 --> 00:17:23.280]   a standard 15, 20 minute talk, he will use 400 slides and they just go they go by second.
[00:17:23.280 --> 00:17:25.200]   They're literally only on there for a second.
[00:17:25.200 --> 00:17:29.320]   So it's an image or a word and it's amazing.
[00:17:29.320 --> 00:17:32.560]   It's like a musical performance.
[00:17:32.560 --> 00:17:35.080]   It's like, Larry, do you ever see a Larry Lusig?
[00:17:35.080 --> 00:17:37.600]   Yeah, that's what it reminded me of.
[00:17:37.600 --> 00:17:38.600]   Yeah.
[00:17:38.600 --> 00:17:40.480]   Yeah, which is also a performance.
[00:17:40.480 --> 00:17:41.480]   Really is.
[00:17:41.480 --> 00:17:46.440]   We made an exception for Mike because our rule was no PowerPoints.
[00:17:46.440 --> 00:17:49.840]   Like, no one would play like a virtuoso.
[00:17:49.840 --> 00:17:50.840]   Yeah.
[00:17:50.840 --> 00:17:55.120]   He's such a virtuoso level it up.
[00:17:55.120 --> 00:17:56.120]   Wow.
[00:17:56.120 --> 00:17:57.480]   Now I got to see it.
[00:17:57.480 --> 00:17:58.840]   I can't believe I'm saying this.
[00:17:58.840 --> 00:18:00.480]   Now I've got to see his PowerPoint presentation.
[00:18:00.480 --> 00:18:02.880]   Get him on to do a PowerPoint.
[00:18:02.880 --> 00:18:04.840]   Come on and bring your PowerPoint next time.
[00:18:04.840 --> 00:18:06.480]   So what else is big at CES?
[00:18:06.480 --> 00:18:07.480]   Well, let's see here.
[00:18:07.480 --> 00:18:09.880]   I mean, people, this is a Google show.
[00:18:09.880 --> 00:18:15.480]   So we could talk about the announcement that Google had there, Google kind of focused their
[00:18:15.480 --> 00:18:20.560]   announcement almost entirely, if not entirely, on assistant features.
[00:18:20.560 --> 00:18:22.760]   They announced a number of new features.
[00:18:22.760 --> 00:18:28.480]   Hagey, read this page is where you're on an article and you want to read it, but you don't
[00:18:28.480 --> 00:18:29.480]   want to read it.
[00:18:29.480 --> 00:18:31.440]   You want to hear it, be read to you.
[00:18:31.440 --> 00:18:34.000]   Now there are a number of apps that do this that you can find.
[00:18:34.000 --> 00:18:35.480]   So stick there for a second.
[00:18:35.480 --> 00:18:36.480]   Yeah.
[00:18:36.480 --> 00:18:41.960]   So if I'm on my phone and I have a page and I say, "Hagey, read this page," I get that.
[00:18:41.960 --> 00:18:46.680]   But how do I get that on my assistant device?
[00:18:46.680 --> 00:18:47.680]   Do you?
[00:18:47.680 --> 00:18:48.680]   I don't know.
[00:18:48.680 --> 00:18:49.920]   That's actually a really good question.
[00:18:49.920 --> 00:18:56.400]   This might be a mobile only feature because it doesn't make as much sense on like a Google
[00:18:56.400 --> 00:18:57.400]   home.
[00:18:57.400 --> 00:19:02.080]   I could go to sleep having read five Matthew columns that I haven't read yet.
[00:19:02.080 --> 00:19:03.720]   Although that would be really cool.
[00:19:03.720 --> 00:19:06.480]   Hagey, read this column by Matthew Ingram.
[00:19:06.480 --> 00:19:09.480]   Blow me into a happiness of the text.
[00:19:09.480 --> 00:19:10.480]   Yes.
[00:19:10.480 --> 00:19:17.280]   There's nothing quite like falling asleep at night to have you in your journals and news.
[00:19:17.280 --> 00:19:19.760]   Do they have Matthew on Calm.com yet?
[00:19:19.760 --> 00:19:22.600]   I don't know, but they probably should.
[00:19:22.600 --> 00:19:25.920]   Matthew, I'm going to be on Calm.
[00:19:25.920 --> 00:19:26.920]   We can...
[00:19:26.920 --> 00:19:27.920]   Hashtag sponsor.
[00:19:27.920 --> 00:19:29.840]   Yes, we can maybe see if we can make that happen.
[00:19:29.840 --> 00:19:32.640]   Hagey, turn on the lights at 6 p.m.
[00:19:32.640 --> 00:19:36.880]   So scheduleable actions, which you could do through the app before.
[00:19:36.880 --> 00:19:41.560]   Now you can do it with your voice if you're thinking about it in that moment.
[00:19:41.560 --> 00:19:43.320]   You could set up a schedule with your voice.
[00:19:43.320 --> 00:19:45.200]   So that's kind of nice.
[00:19:45.200 --> 00:19:47.880]   Do either of you have the smart displays of any kind?
[00:19:47.880 --> 00:19:48.880]   I do right now.
[00:19:48.880 --> 00:19:49.880]   What do you do?
[00:19:49.880 --> 00:19:56.560]   Well, you're going to get some new features to your smart display.
[00:19:56.560 --> 00:19:59.920]   You're going to get a sticky note feature.
[00:19:59.920 --> 00:20:03.520]   Hagey, leave a note that says, and then whatever your note says.
[00:20:03.520 --> 00:20:04.520]   I just tried.
[00:20:04.520 --> 00:20:06.200]   It's not out there yet, right?
[00:20:06.200 --> 00:20:07.440]   Just said, "Sorry, I can't do that, though."
[00:20:07.440 --> 00:20:09.680]   Yeah, I don't know if these are actually released or available.
[00:20:09.680 --> 00:20:10.680]   No, these are all just announcements.
[00:20:10.680 --> 00:20:11.680]   They're not.
[00:20:11.680 --> 00:20:12.680]   Oh, okay.
[00:20:12.680 --> 00:20:13.680]   That's a reality.
[00:20:13.680 --> 00:20:17.680]   So we're telling you about it now, and then you will forget about them, and then they will
[00:20:17.680 --> 00:20:20.840]   launch somewhere down the line, and you won't know that they have launched.
[00:20:20.840 --> 00:20:21.840]   Right, right.
[00:20:21.840 --> 00:20:22.840]   Six of us will say almost a year.
[00:20:22.840 --> 00:20:23.840]   Was it?
[00:20:23.840 --> 00:20:24.840]   Yes.
[00:20:24.840 --> 00:20:25.840]   Was that an IO?
[00:20:25.840 --> 00:20:27.240]   That's how this works.
[00:20:27.240 --> 00:20:29.600]   You'll totally forget about it.
[00:20:29.600 --> 00:20:32.040]   You can pay speed dial options to the lock screen.
[00:20:32.040 --> 00:20:35.840]   So if you have particular numbers that you want to have easily accessible, you can do
[00:20:35.840 --> 00:20:38.320]   that on your smart displays.
[00:20:38.320 --> 00:20:40.520]   Oh, interpretable?
[00:20:40.520 --> 00:20:42.680]   What's confusing to me here is some of this is smart.
[00:20:42.680 --> 00:20:44.080]   That's what I was talking about before.
[00:20:44.080 --> 00:20:45.880]   Some of it is mobile appropriate.
[00:20:45.880 --> 00:20:47.160]   Some of it is smart display appropriate.
[00:20:47.160 --> 00:20:48.160]   Right, right.
[00:20:48.160 --> 00:20:49.160]   Yeah, it kind of...
[00:20:49.160 --> 00:20:52.600]   And suppose one thing, assistant?
[00:20:52.600 --> 00:20:53.600]   Sure.
[00:20:53.600 --> 00:20:59.720]   Yes, some of these will apply to one and not the other, it sounds like.
[00:20:59.720 --> 00:21:05.400]   Interpreter mode, which I think applies to the smart displays, and actually there were
[00:21:05.400 --> 00:21:09.480]   a number of partners, including American Airlines, that are utilizing this.
[00:21:09.480 --> 00:21:10.480]   Essentially what it allows for.
[00:21:10.480 --> 00:21:13.120]   It's a small bit in their lounges.
[00:21:13.120 --> 00:21:14.120]   That's right.
[00:21:14.120 --> 00:21:21.120]   So you would have an American Airlines would have a Nest Hub in their lounge, and it would
[00:21:21.120 --> 00:21:26.640]   essentially be in an interpreter mode so that providing better customer support, essentially,
[00:21:26.640 --> 00:21:31.880]   with no human translator available, you could use the Nest Hub instead.
[00:21:31.880 --> 00:21:38.800]   I was at Bellevue Hospital, which if you understand Bellevue, could be a straight line.
[00:21:38.800 --> 00:21:41.800]   But I was there for the World Trade Center Health Organization.
[00:21:41.800 --> 00:21:45.240]   On every desk, they had these phones with two earpieces.
[00:21:45.240 --> 00:21:46.240]   I thought, "Why?"
[00:21:46.240 --> 00:21:48.840]   It was so they could reach the translators.
[00:21:48.840 --> 00:21:53.040]   Because when you're in the city hospital in New York, your dealer, God knows how many
[00:21:53.040 --> 00:21:58.760]   languages, and they have translators there at the ready all the time to be able to deal
[00:21:58.760 --> 00:22:01.240]   with medical professional and the patient.
[00:22:01.240 --> 00:22:02.240]   Fascinating to me.
[00:22:02.240 --> 00:22:09.360]   Wow, so the Nest Hub, the Google Assistant, could come in and change, put some people
[00:22:09.360 --> 00:22:11.560]   out of work, unfortunately.
[00:22:11.560 --> 00:22:13.160]   I wasn't going to make a Bellevue crack.
[00:22:13.160 --> 00:22:14.160]   I'm glad I didn't.
[00:22:14.160 --> 00:22:17.240]   Yeah, I got it there quickly.
[00:22:17.240 --> 00:22:18.240]   I know, I know.
[00:22:18.240 --> 00:22:19.240]   I know the reflex.
[00:22:19.240 --> 00:22:20.240]   Yeah, I got it.
[00:22:20.240 --> 00:22:21.240]   I saved you there.
[00:22:21.240 --> 00:22:24.960]   You owe me one.
[00:22:24.960 --> 00:22:30.200]   If you've ever fired off a hot word on one of your devices and didn't intend for it,
[00:22:30.200 --> 00:22:37.160]   which I feel like happens to me every day, and sometimes multiple times during a show,
[00:22:37.160 --> 00:22:39.880]   as is the case on all that Android.
[00:22:39.880 --> 00:22:45.120]   And that happens, you can then say, "Hey, G, that wasn't meant for you."
[00:22:45.120 --> 00:22:46.120]   And the history of that action...
[00:22:46.120 --> 00:22:48.200]   Gee, I had invoked my right to be forgotten.
[00:22:48.200 --> 00:22:49.200]   Yes, that's like...
[00:22:49.200 --> 00:22:50.200]   Interesting.
[00:22:50.200 --> 00:22:54.840]   Right, right away it will erase that action or erase the recorded audio.
[00:22:54.840 --> 00:22:56.480]   It'll be like, "Oh, I'm sorry."
[00:22:56.480 --> 00:22:57.480]   So if you say...
[00:22:57.480 --> 00:22:58.480]   And that feature is available.
[00:22:58.480 --> 00:23:00.640]   Hey, G, how is it?
[00:23:00.640 --> 00:23:01.640]   It is available now.
[00:23:01.640 --> 00:23:02.640]   Yes, it is now.
[00:23:02.640 --> 00:23:03.640]   You can do it right now.
[00:23:03.640 --> 00:23:04.640]   Yes, that's been available.
[00:23:04.640 --> 00:23:09.400]   I'm surprised that they announced it because it's been available since, I believe, December.
[00:23:09.400 --> 00:23:10.400]   Oh, okay.
[00:23:10.400 --> 00:23:11.400]   I missed that.
[00:23:11.400 --> 00:23:13.840]   Yeah, we did it on the show a few weeks ago, and we all said, "Well, we didn't know about
[00:23:13.840 --> 00:23:14.840]   it."
[00:23:14.840 --> 00:23:15.840]   Oh, okay.
[00:23:15.840 --> 00:23:16.840]   Yeah.
[00:23:16.840 --> 00:23:21.000]   So if you accidentally said, "Hey, G, how do you dispose of a body?"
[00:23:21.000 --> 00:23:26.400]   And then you decided that you didn't want to say that, you could say, "That wasn't for
[00:23:26.400 --> 00:23:27.400]   you."
[00:23:27.400 --> 00:23:29.000]   Right, you've got an undo.
[00:23:29.000 --> 00:23:32.200]   Of course, we're trusting Google that the undo actually works.
[00:23:32.200 --> 00:23:33.200]   Yes, that's...
[00:23:33.200 --> 00:23:35.760]   Well, we're trusting Google about a lot, aren't we?
[00:23:35.760 --> 00:23:36.760]   That's true.
[00:23:36.760 --> 00:23:37.760]   I'm trying with that.
[00:23:37.760 --> 00:23:40.520]   I actually welcome my new master.
[00:23:40.520 --> 00:23:47.200]   I had a discussion over the holidays, actually, with a family member about this very subject.
[00:23:47.200 --> 00:23:54.760]   And they said, so I asked them if they had a smart assistant made by any of the various
[00:23:54.760 --> 00:24:00.800]   companies, and they said no, and that they had no intention of ever doing that because
[00:24:00.800 --> 00:24:03.760]   they didn't want companies listening to them.
[00:24:03.760 --> 00:24:07.560]   So then we moved on to a different topic.
[00:24:07.560 --> 00:24:10.560]   Okay, then I'll go over here now.
[00:24:10.560 --> 00:24:16.800]   Yeah, I actually had this conversation on one of the shows at the tail end of last month
[00:24:16.800 --> 00:24:24.160]   leading up to Christmas because one of the gifts that I got my parents was a Google Home
[00:24:24.160 --> 00:24:25.720]   package with a smart light.
[00:24:25.720 --> 00:24:30.400]   My thought being, "See, I just awoke my phone."
[00:24:30.400 --> 00:24:33.160]   It's going to happen like two or three more times during this show.
[00:24:33.160 --> 00:24:38.280]   My thought being, my dad took a spill a couple of months ago and it happened at night.
[00:24:38.280 --> 00:24:41.840]   My mom wasn't there, and he basically just laid there until the morning, until there
[00:24:41.840 --> 00:24:45.320]   was light to be able to call someone.
[00:24:45.320 --> 00:24:49.480]   And so I was like, "Well, Google Home with a smart light, this could be a really great
[00:24:49.480 --> 00:24:55.520]   way for you to use the hot word, turn on a light in your home and then be able to find
[00:24:55.520 --> 00:24:56.520]   a new device."
[00:24:56.520 --> 00:24:57.520]   Oh, I see.
[00:24:57.520 --> 00:24:58.520]   Oh.
[00:24:58.520 --> 00:25:00.360]   But I now you could also have a call, right?
[00:25:00.360 --> 00:25:01.360]   That's true.
[00:25:01.360 --> 00:25:02.360]   You could also do that.
[00:25:02.360 --> 00:25:03.360]   Right?
[00:25:03.360 --> 00:25:04.360]   Yeah.
[00:25:04.360 --> 00:25:05.360]   You could call someone through it.
[00:25:05.360 --> 00:25:10.160]   But I didn't think about the fact that there are plenty of people who just have already
[00:25:10.160 --> 00:25:13.080]   decided like, "Heck no, I don't want that in my home."
[00:25:13.080 --> 00:25:19.760]   So this particular gift is almost the kind of gift you have to know for certain someone
[00:25:19.760 --> 00:25:23.560]   how they feel about it before you buy it for them because you could just be giving them
[00:25:23.560 --> 00:25:26.520]   something that they want nothing to do with.
[00:25:26.520 --> 00:25:30.360]   Reminds me of the great Seinfeld episode, which Jerry gave his parents the fruit of the
[00:25:30.360 --> 00:25:31.360]   month club.
[00:25:31.360 --> 00:25:32.720]   Why would you do that?
[00:25:32.720 --> 00:25:34.880]   Who needs this much fruit?
[00:25:34.880 --> 00:25:36.520]   I'm just done with this more fruit coming.
[00:25:36.520 --> 00:25:37.520]   I don't want more fruit.
[00:25:37.520 --> 00:25:38.520]   Why do I want that many great fruits?
[00:25:38.520 --> 00:25:39.520]   Right?
[00:25:39.520 --> 00:25:40.520]   It's the same kind of thing too.
[00:25:40.520 --> 00:25:42.960]   Why would you do that?
[00:25:42.960 --> 00:25:45.520]   These companies don't need my private information.
[00:25:45.520 --> 00:25:47.280]   Same thing as fruit.
[00:25:47.280 --> 00:25:48.280]   Yeah.
[00:25:48.280 --> 00:25:51.000]   Basically the same thing.
[00:25:51.000 --> 00:25:53.200]   So that's, I think that's about it.
[00:25:53.200 --> 00:25:59.720]   That and Google had a couple of slides that go down into a ball pit at CES.
[00:25:59.720 --> 00:26:01.200]   So if you're there, you can ride on the bus.
[00:26:01.200 --> 00:26:02.200]   They do.
[00:26:02.200 --> 00:26:04.720]   We have video of Ant and Leo going down on the slides.
[00:26:04.720 --> 00:26:06.040]   Not that I've seen.
[00:26:06.040 --> 00:26:07.040]   I want that.
[00:26:07.040 --> 00:26:08.880]   I hope that they have.
[00:26:08.880 --> 00:26:11.200]   And if they do that, I hope that they shoot it.
[00:26:11.200 --> 00:26:12.200]   I'll request it.
[00:26:12.200 --> 00:26:13.200]   All right.
[00:26:13.200 --> 00:26:20.120]   We do have a picture of Leo in the Segway S pod doing doing his best.
[00:26:20.120 --> 00:26:21.520]   Wally in the what now?
[00:26:21.520 --> 00:26:22.520]   Wally future.
[00:26:22.520 --> 00:26:23.520]   It's the wheelchair.
[00:26:23.520 --> 00:26:26.720]   Oh, the chair is saying me the chair thing.
[00:26:26.720 --> 00:26:28.720]   You know, right?
[00:26:28.720 --> 00:26:29.720]   Does that go upstairs?
[00:26:29.720 --> 00:26:30.720]   Holders though.
[00:26:30.720 --> 00:26:37.440]   No, no, it's this is Dean Cayman is no longer associated with the company.
[00:26:37.440 --> 00:26:38.440]   So.
[00:26:38.440 --> 00:26:41.720]   Oh, wow.
[00:26:41.720 --> 00:26:44.080]   He did have an amazing wheelchair that went upstairs.
[00:26:44.080 --> 00:26:48.560]   Yeah, that's how he first got big.
[00:26:48.560 --> 00:26:50.040]   And it stood up as well.
[00:26:50.040 --> 00:26:51.040]   Yes.
[00:26:51.040 --> 00:26:52.040]   Yeah.
[00:26:52.040 --> 00:26:53.040]   I remember seeing that.
[00:26:53.040 --> 00:26:55.040]   So it looks like a cradle for Leo.
[00:26:55.040 --> 00:26:56.840]   It looks like he's being hit.
[00:26:56.840 --> 00:27:00.000]   It kind of looks like the doctor evil chair, but with wheels.
[00:27:00.000 --> 00:27:01.000]   It does a little.
[00:27:01.000 --> 00:27:03.560]   Yeah, but no couple of holders.
[00:27:03.560 --> 00:27:06.320]   So when he does a show, he could just like wheel in here.
[00:27:06.320 --> 00:27:07.320]   I like that idea.
[00:27:07.320 --> 00:27:08.320]   Right into place.
[00:27:08.320 --> 00:27:09.320]   He could actually.
[00:27:09.320 --> 00:27:10.320]   He could.
[00:27:10.320 --> 00:27:14.120]   This kind of reminds me of his chair that you're not allowed to sit in.
[00:27:14.120 --> 00:27:16.040]   That's what I'm talking about the doctor evil chair.
[00:27:16.040 --> 00:27:17.040]   It's right over there.
[00:27:17.040 --> 00:27:18.040]   Look at that.
[00:27:18.040 --> 00:27:19.040]   Oh, I see.
[00:27:19.040 --> 00:27:20.040]   Oh, you really mean that?
[00:27:20.040 --> 00:27:21.040]   Oh, they'd be doctor evil chair.
[00:27:21.040 --> 00:27:22.040]   Maybe got it.
[00:27:22.040 --> 00:27:24.160]   Maybe we need to take one of those doctor evil chairs and put a couple of wheels on it.
[00:27:24.160 --> 00:27:25.440]   And we have our own.
[00:27:25.440 --> 00:27:27.000]   It's almost the same thing.
[00:27:27.000 --> 00:27:28.000]   Yeah.
[00:27:28.000 --> 00:27:30.680]   It could be a little project, a twit project.
[00:27:30.680 --> 00:27:31.920]   Take us three years.
[00:27:31.920 --> 00:27:37.520]   But do you, how do you lean like to make it go and stop just leaning back forwards and
[00:27:37.520 --> 00:27:38.520]   back?
[00:27:38.520 --> 00:27:39.520]   That's a good question.
[00:27:39.520 --> 00:27:40.520]   I don't know how it operates.
[00:27:40.520 --> 00:27:41.520]   I don't know.
[00:27:41.520 --> 00:27:47.600]   You think that's coming soon.
[00:27:47.600 --> 00:27:48.600]   Top speed.
[00:27:48.600 --> 00:27:54.240]   It's meant for someone who is disabled in some motion sense.
[00:27:54.240 --> 00:27:55.240]   Right.
[00:27:55.240 --> 00:27:56.840]   They might have the level lean.
[00:27:56.840 --> 00:27:57.840]   Right.
[00:27:57.840 --> 00:28:00.360]   Well, then how that definitely needs turn indicators.
[00:28:00.360 --> 00:28:02.040]   This has not been thought through.
[00:28:02.040 --> 00:28:06.040]   Oh, the S-Pod is controlled using a little joystick on the right side of the seat.
[00:28:06.040 --> 00:28:07.040]   Oh, okay.
[00:28:07.040 --> 00:28:08.040]   Okay.
[00:28:08.040 --> 00:28:09.040]   All right.
[00:28:09.040 --> 00:28:12.800]   Well, that makes more sense.
[00:28:12.800 --> 00:28:13.800]   Interesting.
[00:28:13.800 --> 00:28:14.800]   Okay.
[00:28:14.800 --> 00:28:15.800]   Cool.
[00:28:15.800 --> 00:28:16.800]   24 miles an hour.
[00:28:16.800 --> 00:28:17.800]   That is pretty fast.
[00:28:17.800 --> 00:28:18.800]   That's pretty fast.
[00:28:18.800 --> 00:28:19.800]   Totally.
[00:28:19.800 --> 00:28:20.800]   Man.
[00:28:20.800 --> 00:28:21.800]   Yeah.
[00:28:21.800 --> 00:28:22.800]   That's like that.
[00:28:22.800 --> 00:28:27.800]   That reminds me of the other Seinfeld episode when George was being changed.
[00:28:27.800 --> 00:28:31.560]   In the electrified scooters with the old people.
[00:28:31.560 --> 00:28:36.040]   Do you have a Seinfeld episode queued up for every story that we have at the Red House?
[00:28:36.040 --> 00:28:37.760]   That was a great episode.
[00:28:37.760 --> 00:28:39.120]   I'm impressed by your Seinfeld.
[00:28:39.120 --> 00:28:41.280]   No, it was a great episode.
[00:28:41.280 --> 00:28:42.280]   I enjoyed Seinfeld.
[00:28:42.280 --> 00:28:44.800]   I don't remember these things off on the fly though.
[00:28:44.800 --> 00:28:46.440]   Yeah, I don't remember that one.
[00:28:46.440 --> 00:28:47.440]   I thought I saw every episode.
[00:28:47.440 --> 00:28:48.440]   You don't?
[00:28:48.440 --> 00:28:49.440]   Oh, hold on.
[00:28:49.440 --> 00:28:50.440]   Hold on.
[00:28:50.440 --> 00:28:51.440]   Now we can't play it.
[00:28:51.440 --> 00:28:52.440]   We're going to find it.
[00:28:52.440 --> 00:28:54.440]   We can't play it.
[00:28:54.440 --> 00:28:55.440]   No.
[00:28:55.440 --> 00:28:56.920]   What about a small portion?
[00:28:56.920 --> 00:29:00.520]   I mean, we could, but yeah, we might get it out if we do.
[00:29:00.520 --> 00:29:01.520]   Fair use.
[00:29:01.520 --> 00:29:02.520]   Yeah.
[00:29:02.520 --> 00:29:04.920]   Let's see if there's an image.
[00:29:04.920 --> 00:29:06.000]   We're discussing it.
[00:29:06.000 --> 00:29:08.120]   It's journalism.
[00:29:08.120 --> 00:29:09.120]   What would think?
[00:29:09.120 --> 00:29:10.120]   Okay.
[00:29:10.120 --> 00:29:11.120]   Yeah.
[00:29:11.120 --> 00:29:13.720]   Fair use only counts once you get to court.
[00:29:13.720 --> 00:29:14.720]   Hmm.
[00:29:14.720 --> 00:29:15.720]   True.
[00:29:15.720 --> 00:29:16.720]   Here's a gift.
[00:29:16.720 --> 00:29:17.720]   Is it a gift enough?
[00:29:17.720 --> 00:29:19.720]   I think a gift is a gift possible.
[00:29:19.720 --> 00:29:20.720]   Maybe.
[00:29:20.720 --> 00:29:23.160]   I've heard no directives around gifts.
[00:29:23.160 --> 00:29:25.000]   This is not settled law.
[00:29:25.000 --> 00:29:26.000]   So.
[00:29:26.000 --> 00:29:27.000]   Hold on.
[00:29:27.000 --> 00:29:29.200]   I'm putting it into the rundown.
[00:29:29.200 --> 00:29:30.600]   The bottom of the grill.
[00:29:30.600 --> 00:29:31.600]   George.
[00:29:31.600 --> 00:29:33.120]   I know it's just his cabinet pretty well.
[00:29:33.120 --> 00:29:34.120]   So I think.
[00:29:34.120 --> 00:29:35.120]   Okay.
[00:29:35.120 --> 00:29:36.120]   So there it is.
[00:29:36.120 --> 00:29:40.440]   It's in the rundown under George next to George under CES.
[00:29:40.440 --> 00:29:43.360]   Let's see here.
[00:29:43.360 --> 00:29:44.360]   It's just poor old Giffy.
[00:29:44.360 --> 00:29:45.360]   Surely that's okay.
[00:29:45.360 --> 00:29:47.400]   Yeah, that's got to be fine.
[00:29:47.400 --> 00:29:54.400]   If YouTube starts taking down videos because of Giffy loops, then that's a big story in
[00:29:54.400 --> 00:29:55.400]   and of itself.
[00:29:55.400 --> 00:29:59.720]   Yeah, we're not getting notices from Giffy yet.
[00:29:59.720 --> 00:30:01.720]   So we're fine.
[00:30:01.720 --> 00:30:05.440]   Actually, that's a great that's a great find.
[00:30:05.440 --> 00:30:06.720]   All these Seinfeld gifts.
[00:30:06.720 --> 00:30:07.720]   Jesus.
[00:30:07.720 --> 00:30:08.720]   Yeah.
[00:30:08.720 --> 00:30:09.720]   So, okay.
[00:30:09.720 --> 00:30:14.120]   So this is your, this is your workspace for the episode.
[00:30:14.120 --> 00:30:19.400]   Every story that we do, you've got to find a Seinfeld gift that applies to it.
[00:30:19.400 --> 00:30:23.560]   This is your toolbox.
[00:30:23.560 --> 00:30:24.560]   So let's see here.
[00:30:24.560 --> 00:30:30.400]   Yes, we talked about the really important things, the Charm and Toilet Paper Robot.
[00:30:30.400 --> 00:30:36.200]   And you have a strange, very strange neon artificial human thing.
[00:30:36.200 --> 00:30:38.960]   So I still don't know that I understand this.
[00:30:38.960 --> 00:30:39.960]   I don't understand at all.
[00:30:39.960 --> 00:30:41.480]   I was hoping to explain it to me.
[00:30:41.480 --> 00:30:42.480]   Well, so, okay.
[00:30:42.480 --> 00:30:46.000]   So, and it's a Samsung, Samsung unveiled this.
[00:30:46.000 --> 00:30:50.880]   It's the neon artificial intelligent humanoid chatbot.
[00:30:50.880 --> 00:30:51.960]   And it's like human size.
[00:30:51.960 --> 00:30:55.840]   So when you go there, I guess, like I've seen some, some tweets and everything where people
[00:30:55.840 --> 00:30:56.840]   walk up to it.
[00:30:56.840 --> 00:31:02.880]   It's a huge screen, high res screen, human size humanoid on the screen, you know, basically
[00:31:02.880 --> 00:31:05.200]   looking right at you.
[00:31:05.200 --> 00:31:07.400]   And it's not a smart assistant.
[00:31:07.400 --> 00:31:10.240]   So this is not like Bixby 2.0.
[00:31:10.240 --> 00:31:16.200]   This is essentially meant to be like having a conversation with a real human and you know,
[00:31:16.200 --> 00:31:18.520]   they behave like them, different gestures and everything.
[00:31:18.520 --> 00:31:26.040]   They control facial movements and all this kind of stuff to make it look very, very real.
[00:31:26.040 --> 00:31:32.920]   They can develop memories and learn skills like a human, supposedly.
[00:31:32.920 --> 00:31:38.400]   And what they describe as the proprietary technology that's included here are two engines.
[00:31:38.400 --> 00:31:43.200]   There's the Core R3, which is the reality, real time and responsive engine.
[00:31:43.200 --> 00:31:46.560]   It's what makes it respond in a lifelike way.
[00:31:46.560 --> 00:31:52.800]   So what it looks like as it is pretending to be human and then spectra, which is intelligence,
[00:31:52.800 --> 00:31:57.760]   learning, emotions and memory, they say that's still in the developmental stages, but that
[00:31:57.760 --> 00:32:03.280]   we're going to find more of a preview later this year at Neon World 2020.
[00:32:03.280 --> 00:32:06.040]   Something that we've never heard of before.
[00:32:06.040 --> 00:32:07.040]   I don't know.
[00:32:07.040 --> 00:32:08.040]   I don't know.
[00:32:08.040 --> 00:32:09.560]   Is this supposed to be like a companion?
[00:32:09.560 --> 00:32:11.440]   Like I need a companion in my life.
[00:32:11.440 --> 00:32:12.440]   So I get a neon chat.
[00:32:12.440 --> 00:32:13.440]   It's not a theory.
[00:32:13.440 --> 00:32:14.920]   It's not it doesn't answer questions.
[00:32:14.920 --> 00:32:16.920]   Because it says it's not for information.
[00:32:16.920 --> 00:32:17.920]   Right.
[00:32:17.920 --> 00:32:18.920]   It's not for information.
[00:32:18.920 --> 00:32:23.120]   So it's for like creating a relationship with and like getting to know and it knows
[00:32:23.120 --> 00:32:29.840]   you and teaching its skills, maybe making it a travel agent or I don't know.
[00:32:29.840 --> 00:32:32.040]   It's a big question mark for me.
[00:32:32.040 --> 00:32:37.720]   I'm not entirely sure what the purpose is, but maybe this is the beginning of the future
[00:32:37.720 --> 00:32:42.080]   where we're all having normal conversations with human beings.
[00:32:42.080 --> 00:32:47.120]   I mean, it seems like a natural kind of thing to be unassisted.
[00:32:47.120 --> 00:32:50.960]   Like it seems as though if it's a chat bot, why couldn't you just ask it?
[00:32:50.960 --> 00:32:55.760]   What's the weather going to be like or but they seem to specifically say it's not for
[00:32:55.760 --> 00:32:56.760]   that.
[00:32:56.760 --> 00:33:04.240]   Yeah, like they want it to be well, yeah, they want it to be limited like a human is.
[00:33:04.240 --> 00:33:07.080]   Yeah, but then what's the point of that?
[00:33:07.080 --> 00:33:08.600]   Like wouldn't it be better?
[00:33:08.600 --> 00:33:09.600]   Super human.
[00:33:09.600 --> 00:33:12.040]   Well, we've got enough limited human.
[00:33:12.040 --> 00:33:13.040]   The humans around already.
[00:33:13.040 --> 00:33:14.040]   It's true.
[00:33:14.040 --> 00:33:19.000]   It's kind of I'm looking at a scene that video that's on BGR.com just to look at what it
[00:33:19.000 --> 00:33:20.000]   looks like.
[00:33:20.000 --> 00:33:25.080]   And it looks like that kind of that Star Trek thing where you're caught in the human being
[00:33:25.080 --> 00:33:26.920]   in a two dimensional space.
[00:33:26.920 --> 00:33:27.920]   Yeah.
[00:33:27.920 --> 00:33:28.920]   Yeah.
[00:33:28.920 --> 00:33:34.320]   Do you remember Jeff there used to be a virtual person who would greet you at the Newark
[00:33:34.320 --> 00:33:35.320]   airport?
[00:33:35.320 --> 00:33:40.840]   There was a like a hologram and it was only there for.
[00:33:40.840 --> 00:33:46.000]   Well, it was just in the airport when you walked into the.
[00:33:46.000 --> 00:33:48.320]   Various airports have that one where it's kind of project.
[00:33:48.320 --> 00:33:49.320]   Yeah, yeah, it used to be there.
[00:33:49.320 --> 00:33:52.640]   It's projected onto a small human shaped screen kind of.
[00:33:52.640 --> 00:33:53.640]   Yeah.
[00:33:53.640 --> 00:33:54.640]   Yeah.
[00:33:54.640 --> 00:33:57.240]   And it would go through a feel all kind of.
[00:33:57.240 --> 00:33:59.400]   And then they got rid of it, I guess.
[00:33:59.400 --> 00:34:00.720]   And welcome to the.
[00:34:00.720 --> 00:34:05.120]   I'm sure somebody being being it's Jersey, somebody probably punched it in the face virtual
[00:34:05.120 --> 00:34:06.120]   face.
[00:34:06.120 --> 00:34:07.120]   Probably.
[00:34:07.120 --> 00:34:09.760]   It seems terribly helpful.
[00:34:09.760 --> 00:34:11.760]   It's for sure.
[00:34:11.760 --> 00:34:12.760]   Ouch.
[00:34:12.760 --> 00:34:16.840]   So, so there was the neon project that is very confusing.
[00:34:16.840 --> 00:34:25.200]   Samsung also announced an invisible AI powered or driven keyboard for phones.
[00:34:25.200 --> 00:34:27.120]   Did you see this?
[00:34:27.120 --> 00:34:31.320]   Basically, selfie, selfie camera powered keyboard, right?
[00:34:31.320 --> 00:34:32.920]   Yeah, selfie type.
[00:34:32.920 --> 00:34:35.320]   So imagine you got a foldable phone.
[00:34:35.320 --> 00:34:37.040]   I think this is one example.
[00:34:37.040 --> 00:34:41.080]   And you fold it out so that it's sitting on the on the table kind of propped up like
[00:34:41.080 --> 00:34:42.080]   that.
[00:34:42.080 --> 00:34:44.240]   The selfie camera is projected out.
[00:34:44.240 --> 00:34:47.360]   So it sees the table in front of you.
[00:34:47.360 --> 00:34:51.240]   And you can put your hands down on the table and type like you normally would.
[00:34:51.240 --> 00:34:54.280]   There's no keyboard that's like projected onto the table.
[00:34:54.280 --> 00:34:58.280]   You're literally just putting your hands where the keys would be.
[00:34:58.280 --> 00:35:04.600]   And so I guess this this requires a certain level of like knowledge of like the proper
[00:35:04.600 --> 00:35:06.760]   way of typing, I would guess.
[00:35:06.760 --> 00:35:11.880]   And you're, you know, it basically the selfie camera watches as you type whatever you're
[00:35:11.880 --> 00:35:15.600]   going to type through muscle memory, suppose.
[00:35:15.600 --> 00:35:20.040]   And the AI is able to decipher what you're typing as you do.
[00:35:20.040 --> 00:35:22.800]   That's not going to work for us to finger type this.
[00:35:22.800 --> 00:35:24.400]   That's what I'm saying.
[00:35:24.400 --> 00:35:25.400]   Yeah, right.
[00:35:25.400 --> 00:35:26.400]   Like you got to have.
[00:35:26.400 --> 00:35:30.280]   I can barely find the keys when you can actually see them on the keyboard.
[00:35:30.280 --> 00:35:32.040]   Yeah, this is peak.
[00:35:32.040 --> 00:35:33.040]   I'm a champion.
[00:35:33.040 --> 00:35:34.040]   Yeah.
[00:35:34.040 --> 00:35:36.400]   I'm a very good touch.
[00:35:36.400 --> 00:35:39.280]   I bet I could go as fast as you with two fingers.
[00:35:39.280 --> 00:35:42.920]   I first learned to type after sixth grade because my parents said you're going to fail
[00:35:42.920 --> 00:35:46.320]   school if they try to read your handwriting kid.
[00:35:46.320 --> 00:35:52.800]   The thing I want is I want something where I can type anything with one hand like what
[00:35:52.800 --> 00:35:55.400]   I'm walking or something.
[00:35:55.400 --> 00:36:01.440]   So they have they have keyboards that are basically a ball shaped device.
[00:36:01.440 --> 00:36:03.560]   And you have to train yourself obviously to use it.
[00:36:03.560 --> 00:36:08.840]   You can type almost everything with a single ball shaped keyboard.
[00:36:08.840 --> 00:36:09.840]   Wow.
[00:36:09.840 --> 00:36:13.200]   I mean, you look like you look like a weirdo, but right.
[00:36:13.200 --> 00:36:15.000]   But that's not normal.
[00:36:15.000 --> 00:36:18.240]   Yeah, it's not it's not widespread yet.
[00:36:18.240 --> 00:36:22.600]   Someday that that keyboard ball is going to be a big.
[00:36:22.600 --> 00:36:29.800]   I remember this cyborg the guy at U of T who had a webcam and all that stuff.
[00:36:29.800 --> 00:36:33.840]   He had a keyboard strapped to his wrist and he would type away on that.
[00:36:33.840 --> 00:36:35.600]   It was right, right.
[00:36:35.600 --> 00:36:37.200]   Oh, it's looking.
[00:36:37.200 --> 00:36:43.560]   There's also the tap strap, which is around each of your knuckles.
[00:36:43.560 --> 00:36:45.280]   And you you tap thing.
[00:36:45.280 --> 00:36:47.080]   I'm not sure how that works.
[00:36:47.080 --> 00:36:48.360]   But that's what I want.
[00:36:48.360 --> 00:36:50.280]   And I want to be able to know.
[00:36:50.280 --> 00:36:52.480]   Yeah, I think so.
[00:36:52.480 --> 00:36:55.240]   Look up tap strap.
[00:36:55.240 --> 00:36:56.240]   Tap wearable keyboard.
[00:36:56.240 --> 00:37:03.360]   In fact, July 3, 2018, this company called Twit had a review of it.
[00:37:03.360 --> 00:37:04.360]   Yes.
[00:37:04.360 --> 00:37:05.520]   I think you guys did do it.
[00:37:05.520 --> 00:37:06.960]   Never heard of that.
[00:37:06.960 --> 00:37:14.040]   I yeah, I'm trying to see who you can tap on your own with it.
[00:37:14.040 --> 00:37:15.040]   Leo and Megan.
[00:37:15.040 --> 00:37:16.040]   Was that there you go.
[00:37:16.040 --> 00:37:17.440]   Well, there she's opening it up.
[00:37:17.440 --> 00:37:18.440]   Yeah.
[00:37:18.440 --> 00:37:19.440]   Yeah.
[00:37:19.440 --> 00:37:20.440]   Okay, right.
[00:37:20.440 --> 00:37:21.440]   Okay.
[00:37:21.440 --> 00:37:22.440]   Are you going to get in trouble for showing this?
[00:37:22.440 --> 00:37:23.440]   I know exactly.
[00:37:23.440 --> 00:37:28.480]   This is one case where we can feel pretty confident that we're okay.
[00:37:28.480 --> 00:37:29.800]   Twit won't do anything to us.
[00:37:29.800 --> 00:37:30.800]   We're Twit.
[00:37:30.800 --> 00:37:31.800]   It's okay.
[00:37:31.800 --> 00:37:33.800]   We're a we're twig.
[00:37:33.800 --> 00:37:34.800]   Yeah, that's true.
[00:37:34.800 --> 00:37:35.800]   We're twig.
[00:37:35.800 --> 00:37:36.800]   Yeah, that's right.
[00:37:36.800 --> 00:37:40.160]   Oh, maybe they will do something different then.
[00:37:40.160 --> 00:37:41.400]   That's weird looking.
[00:37:41.400 --> 00:37:45.520]   The image shows you tight on the video.
[00:37:45.520 --> 00:37:49.200]   You can type on a table or type on your knee or anything at all.
[00:37:49.200 --> 00:37:54.600]   But right now anything else while you're showing it's just yeah, it's feeling where your
[00:37:54.600 --> 00:37:56.320]   hands are moving.
[00:37:56.320 --> 00:37:57.320]   Exactly.
[00:37:57.320 --> 00:37:58.320]   Okay.
[00:37:58.320 --> 00:38:00.520]   I'd like that.
[00:38:00.520 --> 00:38:01.520]   I'm too clumsy though.
[00:38:01.520 --> 00:38:03.080]   I'll screw it up.
[00:38:03.080 --> 00:38:04.080]   Yeah.
[00:38:04.080 --> 00:38:05.080]   Wow.
[00:38:05.080 --> 00:38:10.680]   And you could do other things like take out the garbage or without taking it off.
[00:38:10.680 --> 00:38:11.680]   Right.
[00:38:11.680 --> 00:38:14.880]   I know you're typing things while you're taking out the garbage.
[00:38:14.880 --> 00:38:18.200]   You come back in and maybe I'll be with the letter F.
[00:38:18.200 --> 00:38:19.200]   Just in number time.
[00:38:19.200 --> 00:38:23.480]   Have you ever tried one of the ones that projects the keyboard on to the on to the
[00:38:23.480 --> 00:38:24.480]   view?
[00:38:24.480 --> 00:38:28.040]   I have tried one and it's really weird.
[00:38:28.040 --> 00:38:31.960]   I mean as you would expect it just there's no travel.
[00:38:31.960 --> 00:38:37.800]   Yeah, there's no travel like you it's just it's strange typing on a flat surface like
[00:38:37.800 --> 00:38:38.800]   that.
[00:38:38.800 --> 00:38:42.560]   It's probably the kind of thing that you get used to it the more you do it and everything.
[00:38:42.560 --> 00:38:48.560]   But when I tried that it even though it seemed like it should be obvious it was really really
[00:38:48.560 --> 00:38:49.560]   difficult for me.
[00:38:49.560 --> 00:38:51.880]   I mean people got used to virtual phone keyboards.
[00:38:51.880 --> 00:38:53.880]   I remember having a debate with a friend.
[00:38:53.880 --> 00:38:58.720]   In fact, she still has a a blackberry because it has a physical keyboard.
[00:38:58.720 --> 00:39:03.120]   She just never she could never get used to a virtual keyboard.
[00:39:03.120 --> 00:39:04.120]   Yeah.
[00:39:04.120 --> 00:39:05.120]   Yeah.
[00:39:05.120 --> 00:39:09.360]   I remember the early, you know, first couple of years of typing on the the virtual keyboard.
[00:39:09.360 --> 00:39:15.200]   Was it isn't a blackberry just a matter of patriotism in Canada?
[00:39:15.200 --> 00:39:16.480]   I guess a little bit for her.
[00:39:16.480 --> 00:39:17.480]   It was the keyboard.
[00:39:17.480 --> 00:39:19.600]   I don't think she cares who owns it or where it's based.
[00:39:19.600 --> 00:39:22.400]   It was literally the only one you could get with a physical keyboard.
[00:39:22.400 --> 00:39:23.400]   Yeah.
[00:39:23.400 --> 00:39:24.520]   I lost this for a while.
[00:39:24.520 --> 00:39:27.120]   I was so happy just yesterday I was going through drawers looking for something and I
[00:39:27.120 --> 00:39:29.040]   found my beloved.
[00:39:29.040 --> 00:39:31.560]   Oh, trio.
[00:39:31.560 --> 00:39:33.440]   I love the trio.
[00:39:33.440 --> 00:39:34.440]   Wow.
[00:39:34.440 --> 00:39:35.440]   It was the greatest.
[00:39:35.440 --> 00:39:36.440]   It really was.
[00:39:36.440 --> 00:39:40.640]   Now it was more of a handspring guy.
[00:39:40.640 --> 00:39:41.640]   You would be.
[00:39:41.640 --> 00:39:44.640]   Now settle down.
[00:39:44.640 --> 00:39:50.720]   I've had a Newton power up and I don't know.
[00:39:50.720 --> 00:39:51.720]   I can't find that.
[00:39:51.720 --> 00:39:53.480]   I don't know which power thing to use for.
[00:39:53.480 --> 00:39:54.480]   I got to find that.
[00:39:54.480 --> 00:39:55.480]   Yeah.
[00:39:55.480 --> 00:39:57.960]   I know that that was back in the days of totally before USB charging.
[00:39:57.960 --> 00:39:58.960]   Yeah.
[00:39:58.960 --> 00:39:59.960]   Totally proprietary.
[00:39:59.960 --> 00:40:00.960]   Everybody had their own.
[00:40:00.960 --> 00:40:05.960]   Everybody had their own and I had a bin full of those, which I threw out when we moved.
[00:40:05.960 --> 00:40:06.960]   No.
[00:40:06.960 --> 00:40:08.800]   My office is a museum.
[00:40:08.800 --> 00:40:10.200]   I have a good technology.
[00:40:10.200 --> 00:40:11.200]   Me too.
[00:40:11.200 --> 00:40:14.800]   I've got the original flip from the Motorola.
[00:40:14.800 --> 00:40:15.800]   Ooh.
[00:40:15.800 --> 00:40:16.800]   Yeah.
[00:40:16.800 --> 00:40:17.800]   I have my Osborne one.
[00:40:17.800 --> 00:40:21.920]   It's my pride and joy.
[00:40:21.920 --> 00:40:22.920]   What do I have?
[00:40:22.920 --> 00:40:23.920]   Give a wing.
[00:40:23.920 --> 00:40:24.920]   No, I have.
[00:40:24.920 --> 00:40:25.920]   I'm going to get it on this part.
[00:40:25.920 --> 00:40:28.320]   It's not a good question to ask.
[00:40:28.320 --> 00:40:29.820]   Geez.
[00:40:29.820 --> 00:40:31.840]   How could you think such a thing up behind?
[00:40:31.840 --> 00:40:32.840]   I'm.
[00:40:32.840 --> 00:40:33.840]   Thank you.
[00:40:33.840 --> 00:40:34.840]   Sorry.
[00:40:34.840 --> 00:40:39.280]   I have the Nexus Q. That's all I have.
[00:40:39.280 --> 00:40:42.280]   It's the Nexus Q, sad trombone.
[00:40:42.280 --> 00:40:43.280]   Let's see.
[00:40:43.280 --> 00:40:44.280]   I have the Qcat.
[00:40:44.280 --> 00:40:45.280]   Do you have the Qcat?
[00:40:45.280 --> 00:40:46.280]   Oh, the Qcat.
[00:40:46.280 --> 00:40:47.280]   I've got a Qcat somewhere.
[00:40:47.280 --> 00:40:48.280]   Yeah.
[00:40:48.280 --> 00:40:51.280]   We got a brilliant technology.
[00:40:51.280 --> 00:40:58.560]   For you kids out there, the idea was that no one in the world was going to type in these
[00:40:58.560 --> 00:41:00.600]   things they call URLs.
[00:41:00.600 --> 00:41:07.080]   So you were going to sit tethered to your desktop machine and your den with a very
[00:41:07.080 --> 00:41:11.040]   long cord and a scanner and publishers were going to get in the act here.
[00:41:11.040 --> 00:41:13.840]   They were going to license this technology because it was so special.
[00:41:13.840 --> 00:41:19.600]   They were going to put barcodes with every ad and every story.
[00:41:19.600 --> 00:41:24.880]   So you would scan that so that your computer would then go to that URL with it.
[00:41:24.880 --> 00:41:28.240]   You have to tire your little fingers to open it in.
[00:41:28.240 --> 00:41:30.320]   And it was hopefully shaped like a cat.
[00:41:30.320 --> 00:41:33.280]   So you can remember what is the dorkiest thing.
[00:41:33.280 --> 00:41:34.800]   I remember the founder had this.
[00:41:34.800 --> 00:41:36.240]   He was just such a slick.
[00:41:36.240 --> 00:41:37.240]   Really?
[00:41:37.240 --> 00:41:41.160]   I don't know how that even made it to the marketplace.
[00:41:41.160 --> 00:41:43.840]   Huge gold rings and gold buttons and things.
[00:41:43.840 --> 00:41:48.600]   It just also just to, yeah, it's said this spelled failure.
[00:41:48.600 --> 00:41:52.320]   I mean, it made it to the marketplace because it came out in 2000 and wasn't everything.
[00:41:52.320 --> 00:41:54.280]   No, because it was stupid publishers.
[00:41:54.280 --> 00:41:55.280]   I guess.
[00:41:55.280 --> 00:41:56.280]   Yeah.
[00:41:56.280 --> 00:41:58.680]   Maybe it was all free with wired magazines.
[00:41:58.680 --> 00:41:59.680]   It was wired.
[00:41:59.680 --> 00:42:00.680]   Yeah.
[00:42:00.680 --> 00:42:05.720]   With whatever issue that was.
[00:42:05.720 --> 00:42:08.160]   By 2001, it was done.
[00:42:08.160 --> 00:42:10.320]   2001 and done.
[00:42:10.320 --> 00:42:11.800]   Oh boy.
[00:42:11.800 --> 00:42:14.720]   Surgeons were a thing there.
[00:42:14.720 --> 00:42:17.880]   And though, no one really needed to plug in a URL.
[00:42:17.880 --> 00:42:18.880]   You just do a search.
[00:42:18.880 --> 00:42:20.520]   Well, you had to go through Yahoo.
[00:42:20.520 --> 00:42:21.520]   You know, Yahoo.
[00:42:21.520 --> 00:42:22.520]   Yeah, that's true.
[00:42:22.520 --> 00:42:23.520]   And Yahoo had to, right.
[00:42:23.520 --> 00:42:27.760]   You remember when you had a list of the new sites of the day?
[00:42:27.760 --> 00:42:29.240]   Yes.
[00:42:29.240 --> 00:42:30.720]   That's when the web was that small.
[00:42:30.720 --> 00:42:31.720]   Yeah.
[00:42:31.720 --> 00:42:37.880]   So footnote, I was working as a Gloven Mail in the financial reporting section.
[00:42:37.880 --> 00:42:43.640]   And I put together a list of places you could get stock quotes online.
[00:42:43.640 --> 00:42:48.040]   And there were only about nine or something like that.
[00:42:48.040 --> 00:42:51.280]   And just for fun, I called it the high-tech investor.
[00:42:51.280 --> 00:42:56.840]   And that was website of the month in Worth magazine, 1995.
[00:42:56.840 --> 00:42:57.840]   Yeah.
[00:42:57.840 --> 00:42:58.840]   Yeah.
[00:42:58.840 --> 00:42:59.840]   Yeah.
[00:42:59.840 --> 00:43:00.840]   Thank you.
[00:43:00.840 --> 00:43:01.840]   I had a few.
[00:43:01.840 --> 00:43:04.120]   I had a hot side of the day a couple of times.
[00:43:04.120 --> 00:43:05.120]   Yucky.
[00:43:05.120 --> 00:43:06.480]   The yucky is site on the internet.
[00:43:06.480 --> 00:43:07.760]   It was one of mine.
[00:43:07.760 --> 00:43:08.760]   Nice.
[00:43:08.760 --> 00:43:09.760]   Nice.
[00:43:09.760 --> 00:43:10.760]   Yeah.
[00:43:10.760 --> 00:43:11.760]   Wow.
[00:43:11.760 --> 00:43:12.760]   That's a real feather in your cap there.
[00:43:12.760 --> 00:43:13.760]   Sure is.
[00:43:13.760 --> 00:43:14.760]   It's on my resume still.
[00:43:14.760 --> 00:43:15.760]   Yeah.
[00:43:15.760 --> 00:43:18.920]   So we've got that for a frame it.
[00:43:18.920 --> 00:43:19.920]   Put that on your wall.
[00:43:19.920 --> 00:43:20.920]   All right.
[00:43:20.920 --> 00:43:21.920]   Back to the future.
[00:43:21.920 --> 00:43:22.920]   All right.
[00:43:22.920 --> 00:43:23.920]   I love these mini tangents.
[00:43:23.920 --> 00:43:24.920]   We are so old.
[00:43:24.920 --> 00:43:28.800]   It's so old.
[00:43:28.800 --> 00:43:31.800]   One plus has...
[00:43:31.800 --> 00:43:37.840]   They were setting everybody up to be wowed at CES because they were talking about this
[00:43:37.840 --> 00:43:42.400]   thing called Concept One where they were going to show off the future of One Plus
[00:43:42.400 --> 00:43:45.120]   design at CES.
[00:43:45.120 --> 00:43:48.080]   And so sure enough, they had their announcement.
[00:43:48.080 --> 00:43:50.160]   I don't know if it was an event.
[00:43:50.160 --> 00:43:53.520]   I think it was just like an information announcement at CES.
[00:43:53.520 --> 00:43:58.720]   Concept One, which is essentially it's a McLaren edition version of the One Plus 70 Pro.
[00:43:58.720 --> 00:43:59.720]   Wow.
[00:43:59.720 --> 00:44:00.720]   Not a mistake.
[00:44:00.720 --> 00:44:01.720]   Real leather.
[00:44:01.720 --> 00:44:03.640]   Which One Plus has done this in the past.
[00:44:03.640 --> 00:44:07.840]   They have a relationship with McLaren, the automaker.
[00:44:07.840 --> 00:44:12.520]   And so in some of their previous phones, they've had like McLaren editions with kind
[00:44:12.520 --> 00:44:18.520]   of stylings that are borrowed or inspired by McLaren and through a direct partnership
[00:44:18.520 --> 00:44:19.520]   with McLaren.
[00:44:19.520 --> 00:44:22.840]   But this Concept One kind of takes that one step further.
[00:44:22.840 --> 00:44:27.800]   Yes, it kind of looks like car interior in the design.
[00:44:27.800 --> 00:44:32.280]   But the glass panel that you see there on the back, that's where the cameras are, the
[00:44:32.280 --> 00:44:34.880]   rear facing cameras of which I think there are three.
[00:44:34.880 --> 00:44:42.520]   But you can't see them because on the Concept One, that glass is electrochromic similar
[00:44:42.520 --> 00:44:47.640]   to the electrochromic glass that's in the McLaren 720S supercar.
[00:44:47.640 --> 00:44:54.440]   So what it allows for is it allows for the phone to make that glass dark so that the
[00:44:54.440 --> 00:45:00.800]   cameras aren't visible or transparent or what is it?
[00:45:00.800 --> 00:45:01.800]   Translucent transparent?
[00:45:01.800 --> 00:45:02.800]   I don't know what the word is.
[00:45:02.800 --> 00:45:05.440]   I hope transparent for the photo quality.
[00:45:05.440 --> 00:45:06.440]   Transparent.
[00:45:06.440 --> 00:45:08.040]   Transparent is the one you're so thankful for.
[00:45:08.040 --> 00:45:09.640]   Yeah, there we go.
[00:45:09.640 --> 00:45:12.640]   So that the cameras can be seen and used, right?
[00:45:12.640 --> 00:45:15.880]   Because if that filter is on, the pictures would come out very very dark.
[00:45:15.880 --> 00:45:17.880]   Who wants to see a camera?
[00:45:17.880 --> 00:45:18.880]   Interesting.
[00:45:18.880 --> 00:45:19.880]   Yeah, so on what hand?
[00:45:19.880 --> 00:45:20.880]   It is pretty.
[00:45:20.880 --> 00:45:24.720]   I'm kind of like, okay, that's an interesting thing to hang your concept on.
[00:45:24.720 --> 00:45:30.600]   At the same time, I'm very intrigued by the idea of cameras now having the ability to
[00:45:30.600 --> 00:45:37.480]   have an actual filter, like an actual, not a software filter, but a hardware filter for
[00:45:37.480 --> 00:45:39.720]   very bright conditions, let's say.
[00:45:39.720 --> 00:45:43.680]   Maybe this is an opportunity to kind of put a filter in between.
[00:45:43.680 --> 00:45:46.000]   It says it can change the opacity.
[00:45:46.000 --> 00:45:47.000]   Yeah.
[00:45:47.000 --> 00:45:49.000]   So it's like a Dreamliner window.
[00:45:49.000 --> 00:45:51.280]   Have you guys been on a Dreamliner for that?
[00:45:51.280 --> 00:45:52.280]   No.
[00:45:52.280 --> 00:45:56.920]   The Dreamliner windows are electric luminescent or whatever you call it.
[00:45:56.920 --> 00:45:58.320]   Oh, I have been on one of those.
[00:45:58.320 --> 00:45:59.320]   Yeah.
[00:45:59.320 --> 00:46:02.760]   Right, so you can manually turn them up and down and then the flight attendants can make
[00:46:02.760 --> 00:46:04.040]   every window just dark.
[00:46:04.040 --> 00:46:05.040]   Yeah, yeah.
[00:46:05.040 --> 00:46:07.240]   Kind of pisses me off.
[00:46:07.240 --> 00:46:08.240]   But it's weird.
[00:46:08.240 --> 00:46:12.120]   It's not like the old ones where it's either open or shut.
[00:46:12.120 --> 00:46:14.600]   There's a whole bunch of gradations in between.
[00:46:14.600 --> 00:46:15.600]   Right.
[00:46:15.600 --> 00:46:16.600]   Yeah.
[00:46:16.600 --> 00:46:17.600]   Right.
[00:46:17.600 --> 00:46:18.600]   It's a good idea.
[00:46:18.600 --> 00:46:19.600]   Yeah.
[00:46:19.600 --> 00:46:27.520]   So I don't know when or if we see this coming to market because it is a concept.
[00:46:27.520 --> 00:46:28.520]   I don't want to see.
[00:46:28.520 --> 00:46:34.880]   You see, I always thought the concept cars were dumb because you can't get them.
[00:46:34.880 --> 00:46:37.960]   So what's the point of showing them to us?
[00:46:37.960 --> 00:46:40.920]   And so I don't want to see that concept thing come into our world.
[00:46:40.920 --> 00:46:44.280]   We might do this, but then again, we might not.
[00:46:44.280 --> 00:46:48.760]   So this, in this case, it says the phone is basically the same, like the phone itself
[00:46:48.760 --> 00:46:49.760]   is.
[00:46:49.760 --> 00:46:54.280]   So the concept is just the camera and the filter and the.
[00:46:54.280 --> 00:46:58.040]   And everything else is very, very much the same as the 17 Pro.
[00:46:58.040 --> 00:47:00.720]   I'm not mistaken.
[00:47:00.720 --> 00:47:02.760]   So, so kind of neat.
[00:47:02.760 --> 00:47:04.880]   I mean, that's different.
[00:47:04.880 --> 00:47:09.320]   But man, they really, you know, we're promoting this leading up to CES and everybody was like,
[00:47:09.320 --> 00:47:11.360]   oh, is this their foldable entry?
[00:47:11.360 --> 00:47:13.080]   You know, are they going to show off foldable tech?
[00:47:13.080 --> 00:47:17.000]   And so I think some people were a little let down by this, but the more I thought about
[00:47:17.000 --> 00:47:20.720]   it tomorrow, I was like, all right, maybe it's not the most amazing announcement, but
[00:47:20.720 --> 00:47:22.320]   it is an interesting feature.
[00:47:22.320 --> 00:47:25.960]   I would actually love to have that in a phone to have like an actual hardware filter, like
[00:47:25.960 --> 00:47:29.640]   an ND filter of some sort that you could turn on or off.
[00:47:29.640 --> 00:47:30.640]   I think that's pretty.
[00:47:30.640 --> 00:47:33.040]   So I kind of like that.
[00:47:33.040 --> 00:47:36.280]   It would be really interesting if they could do it on the front facing camera.
[00:47:36.280 --> 00:47:37.280]   If they could.
[00:47:37.280 --> 00:47:38.280]   Yeah.
[00:47:38.280 --> 00:47:46.600]   I just like hide it behind the screen and then just translucent tight, translucent eyes that
[00:47:46.600 --> 00:47:49.600]   portion of the screen just long enough to take a picture.
[00:47:49.600 --> 00:47:50.600]   Yeah.
[00:47:50.600 --> 00:47:51.600]   Translucent eyes.
[00:47:51.600 --> 00:47:55.000]   Soon to be a Webster word of the day.
[00:47:55.000 --> 00:47:56.360]   You heard him hear words.
[00:47:56.360 --> 00:47:57.840]   Soon to be a word.
[00:47:57.840 --> 00:48:00.000]   No one has ever used that word before.
[00:48:00.000 --> 00:48:01.240]   Carsten invented it.
[00:48:01.240 --> 00:48:07.720]   When you hear that, you can say you were there when Carsten invented translucent eyes.
[00:48:07.720 --> 00:48:13.960]   It was an amazing afternoon that day on Twitter.
[00:48:13.960 --> 00:48:18.840]   There were other things, but I don't know if they were as important.
[00:48:18.840 --> 00:48:25.160]   TCL, the TV manufacturer has a number of phones that they're finally coming out with.
[00:48:25.160 --> 00:48:28.520]   One of them that they showed off was a foldable phone concept.
[00:48:28.520 --> 00:48:32.520]   Jeff is a concept phone to show you.
[00:48:32.520 --> 00:48:37.680]   Someone showed off a TV that would rotate so that it was important.
[00:48:37.680 --> 00:48:40.480]   It's in the Weber Girls story.
[00:48:40.480 --> 00:48:45.760]   It's a Samsung, what's it called?
[00:48:45.760 --> 00:48:46.760]   Zero.
[00:48:46.760 --> 00:48:47.760]   The Sarah.
[00:48:47.760 --> 00:48:48.760]   Zero.
[00:48:48.760 --> 00:48:49.760]   Zero.
[00:48:49.760 --> 00:48:50.760]   Yeah, rotates.
[00:48:50.760 --> 00:48:53.640]   And so I guess it could show the Nero or not Nero.
[00:48:53.640 --> 00:48:54.640]   What's the name of it?
[00:48:54.640 --> 00:48:55.640]   What do they call their?
[00:48:55.640 --> 00:48:56.640]   The Neo.
[00:48:56.640 --> 00:48:57.640]   No, neon.
[00:48:57.640 --> 00:48:58.640]   The neon.
[00:48:58.640 --> 00:48:59.640]   Yeah.
[00:48:59.640 --> 00:49:00.640]   Oh, yeah.
[00:49:00.640 --> 00:49:01.640]   Right.
[00:49:01.640 --> 00:49:02.640]   Yeah.
[00:49:02.640 --> 00:49:03.640]   Because then it could show a person.
[00:49:03.640 --> 00:49:04.640]   That's right.
[00:49:04.640 --> 00:49:05.640]   Yeah.
[00:49:05.640 --> 00:49:10.800]   It's designed for mirroring your phone and all those vertical YouTube and TikTok videos
[00:49:10.800 --> 00:49:16.800]   that you might be playing on it.
[00:49:16.800 --> 00:49:22.760]   See it, see that says possibly the biggest phone accessory ever.
[00:49:22.760 --> 00:49:25.200]   There's some truth to that.
[00:49:25.200 --> 00:49:26.200]   Yeah.
[00:49:26.200 --> 00:49:29.360]   And CES is still going.
[00:49:29.360 --> 00:49:31.120]   Although is it wrapping up now?
[00:49:31.120 --> 00:49:33.280]   Is tomorrow the last day or is it Friday?
[00:49:33.280 --> 00:49:34.280]   I never know.
[00:49:34.280 --> 00:49:36.000]   It's the last day of tomorrow is the last day.
[00:49:36.000 --> 00:49:37.000]   All right.
[00:49:37.000 --> 00:49:38.000]   So CES is rounding out.
[00:49:38.000 --> 00:49:40.840]   We've probably got all the news from CES.
[00:49:40.840 --> 00:49:41.840]   That's most important.
[00:49:41.840 --> 00:49:42.840]   We're going to get.
[00:49:42.840 --> 00:49:43.840]   Yeah, that we're going to get.
[00:49:43.840 --> 00:49:47.800]   Oneplus did also announce something called Optimize Charging.
[00:49:47.800 --> 00:49:53.000]   This isn't limited to the concept that they showed off by any means.
[00:49:53.000 --> 00:49:57.200]   I think they're going to roll this out to many of their current phones.
[00:49:57.200 --> 00:50:02.320]   But essentially the idea here is that when we plug our phones in at night and we charge
[00:50:02.320 --> 00:50:03.620]   them up.
[00:50:03.620 --> 00:50:07.400]   Next to the time what's happening is our battery is charged up to 100% and keeps charging,
[00:50:07.400 --> 00:50:08.800]   keeps charging, keeps charging.
[00:50:08.800 --> 00:50:09.800]   Which is bad.
[00:50:09.800 --> 00:50:13.160]   Which is bad for battery, the life of the battery.
[00:50:13.160 --> 00:50:19.320]   So what this would do is it would hold it at 80% and over time it would understand when
[00:50:19.320 --> 00:50:23.800]   you normally take it off the charger, let's say in the morning, and it would only allow
[00:50:23.800 --> 00:50:25.200]   it to go up to 100%.
[00:50:25.200 --> 00:50:31.920]   I think like 90 minutes before you are expected to take it off the charger to gain more life
[00:50:31.920 --> 00:50:32.920]   than you're bad.
[00:50:32.920 --> 00:50:36.620]   It's a charger that communicates with the phone and turns itself off when it's full.
[00:50:36.620 --> 00:50:38.620]   Wouldn't that be easier?
[00:50:38.620 --> 00:50:43.860]   Well, but then when you take your phone off the charger, it would have depleted down to
[00:50:43.860 --> 00:50:45.420]   no, no, no.
[00:50:45.420 --> 00:50:46.420]   Oh, I see.
[00:50:46.420 --> 00:50:48.260]   Well, but the phone is also.
[00:50:48.260 --> 00:50:50.020]   It has to keep it topped up.
[00:50:50.020 --> 00:50:51.820]   Yeah, tops it up.
[00:50:51.820 --> 00:50:56.460]   And by the way, when was the last time you guys have had a battery just die in your phone
[00:50:56.460 --> 00:50:58.260]   such that you had to replace the battery?
[00:50:58.260 --> 00:51:00.420]   Oh, well, that's a really great question.
[00:51:00.420 --> 00:51:01.420]   Long time ago.
[00:51:01.420 --> 00:51:02.420]   Long time.
[00:51:02.420 --> 00:51:03.420]   Yeah.
[00:51:03.420 --> 00:51:05.740]   So I don't know if this is a huge problem way to be solved.
[00:51:05.740 --> 00:51:10.220]   So I did a bit of research into this because I was concerned about it.
[00:51:10.220 --> 00:51:13.500]   Someone asked me about it or told me you shouldn't do that.
[00:51:13.500 --> 00:51:21.380]   And so I looked into it a bit and there was a battery technologist who said that's technically
[00:51:21.380 --> 00:51:22.380]   true.
[00:51:22.380 --> 00:51:29.460]   If you leave it at 100, it will decrease the lifespan of the battery, but it probably isn't
[00:51:29.460 --> 00:51:34.580]   going to decrease it like it'll wear out faster, meaning it'll be done in like two years.
[00:51:34.580 --> 00:51:39.380]   But most people replace their phone every couple of years anyway.
[00:51:39.380 --> 00:51:43.820]   So he said you'd have to keep it for three or four years to really notice.
[00:51:43.820 --> 00:51:44.820]   Yeah.
[00:51:44.820 --> 00:51:48.820]   Although, I mean, I give OnePlus props in this regard.
[00:51:48.820 --> 00:51:53.180]   When you look at it from the perspective of, you know, we're putting a lot of crap into
[00:51:53.180 --> 00:51:57.100]   the world, into our landfills and stuff.
[00:51:57.100 --> 00:52:02.380]   This is a technology improvement that actually encourages people to hold onto their devices
[00:52:02.380 --> 00:52:03.380]   longer.
[00:52:03.380 --> 00:52:04.380]   Yeah.
[00:52:04.380 --> 00:52:06.900]   It at least paves the way for it in one perspective.
[00:52:06.900 --> 00:52:08.540]   So I give him props for that.
[00:52:08.540 --> 00:52:12.740]   And I'm probably the wrong person to ask as far as how long I hold onto a device because
[00:52:12.740 --> 00:52:15.060]   I use so many of them for my job.
[00:52:15.060 --> 00:52:16.060]   Yeah.
[00:52:16.060 --> 00:52:18.900]   You know, I go through them way more than a normal person.
[00:52:18.900 --> 00:52:24.420]   I do feel like, I know we've talked about this before on the show that people are maybe
[00:52:24.420 --> 00:52:31.900]   not updating their devices as frequently because the new ones actually aren't dramatically
[00:52:31.900 --> 00:52:36.340]   better than for the things that most normal people use.
[00:52:36.340 --> 00:52:42.180]   You know, if you want the leather one with the translucent or whatever thing then great.
[00:52:42.180 --> 00:52:48.460]   But if you just want a phone that works and has a half decent camera, you know, probably
[00:52:48.460 --> 00:52:51.780]   one from a year or two ago is still pretty good.
[00:52:51.780 --> 00:52:52.780]   Yep.
[00:52:52.780 --> 00:52:53.780]   Absolutely.
[00:52:53.780 --> 00:52:54.780]   So that's CES.
[00:52:54.780 --> 00:52:59.900]   We've got a whole lot more to talk about, but we do have to take a break.
[00:52:59.900 --> 00:53:03.860]   So let's take a quick break and thank the sponsor of this episode of this week in Google.
[00:53:03.860 --> 00:53:11.540]   This week in Google is brought to you by LastPass 17.8 million people over 61,000 businesses
[00:53:11.540 --> 00:53:13.380]   trust LastPass.
[00:53:13.380 --> 00:53:15.540]   I love that LastPass.
[00:53:15.540 --> 00:53:18.540]   And if you haven't used it, you should definitely check it out yourself.
[00:53:18.540 --> 00:53:23.500]   LastPass is an award winning security solution that helps individuals and businesses navigate
[00:53:23.500 --> 00:53:27.660]   their online lives easily and securely.
[00:53:27.660 --> 00:53:30.820]   And they have a number of plans that you can choose from, be it personal or business.
[00:53:30.820 --> 00:53:35.980]   You can choose from personal plans like free, premium or families.
[00:53:35.980 --> 00:53:40.460]   And then of course they have business plans, teams, enterprise, MFA or identity.
[00:53:40.460 --> 00:53:45.860]   If you go to lastpass.com/twit, you're going to find all the details that you need for
[00:53:45.860 --> 00:53:50.460]   each plan to find out which one's going to work best for you.
[00:53:50.460 --> 00:53:53.420]   And there's a number of reasons why LastPass is awesome.
[00:53:53.420 --> 00:53:54.980]   It generates strong passwords.
[00:53:54.980 --> 00:53:57.300]   Makes it easy to generate a strong password.
[00:53:57.300 --> 00:54:00.220]   So you aren't coming up with it on the fly, which I love.
[00:54:00.220 --> 00:54:05.620]   You can share passwords or notes within LastPass to employees or family members.
[00:54:05.620 --> 00:54:11.480]   LastPass for business offers flexible password management, single sign on and multi-factor
[00:54:11.480 --> 00:54:15.140]   authentication options, which I use.
[00:54:15.140 --> 00:54:16.580]   It can go on any device anywhere.
[00:54:16.580 --> 00:54:23.660]   No matter what you're using, iOS, Android, Chromebook, laptop, MacBook, whatever you happen to have,
[00:54:23.660 --> 00:54:29.140]   LastPass can go on there monitoring and inserting your passwords as needed.
[00:54:29.140 --> 00:54:32.500]   Also dynamically creating new entries when you sign up for something new.
[00:54:32.500 --> 00:54:37.700]   That's the beauty of having LastPass on all those devices when you sign up for something.
[00:54:37.700 --> 00:54:39.940]   Holds personal or corporate credit cards.
[00:54:39.940 --> 00:54:44.500]   You can also put pictures of your passport or other important documents that you want
[00:54:44.500 --> 00:54:49.700]   to be secured and use LastPass as a secure vault for that stuff.
[00:54:49.700 --> 00:54:55.740]   And now offers passwordless login options for employees, which increases security and
[00:54:55.740 --> 00:54:57.700]   productivity.
[00:54:57.700 --> 00:54:59.500]   And it really is ahead of its time.
[00:54:59.500 --> 00:55:00.580]   LastPass security is awesome.
[00:55:00.580 --> 00:55:06.740]   They engage trusted world class third party security firms to conduct routine audits and
[00:55:06.740 --> 00:55:08.740]   testing of their service and infrastructure.
[00:55:08.740 --> 00:55:12.500]   They have a detailed review of their controls and processes.
[00:55:12.500 --> 00:55:16.780]   That's the gold standard for confirming the security and reliability.
[00:55:16.780 --> 00:55:23.780]   And sensitive data is encrypted at the device level with AES-256 before syncing with TLS
[00:55:23.780 --> 00:55:26.060]   to protect from man in the middle attacks.
[00:55:26.060 --> 00:55:29.100]   We of course use LastPass Enterprise here at Twit.
[00:55:29.100 --> 00:55:33.820]   It just makes it easy for us to have access to our passwords for all the sites that we
[00:55:33.820 --> 00:55:38.860]   have to have to visit in order to kind of keep coming up with the news that we do for
[00:55:38.860 --> 00:55:39.860]   the shows.
[00:55:39.860 --> 00:55:45.340]   I use it to store my credentials for the different news sites that I belong to and also kind
[00:55:45.340 --> 00:55:48.660]   of interconnecting between my personal and my work account.
[00:55:48.660 --> 00:55:50.700]   They make it really easy to do that.
[00:55:50.700 --> 00:55:55.260]   You need LastPass for you and your business with their amazing features that will improve
[00:55:55.260 --> 00:55:59.740]   security across your company and make life easier for your users.
[00:55:59.740 --> 00:56:04.780]   Visit lastpass.com/twit to find out how they can help you.
[00:56:04.780 --> 00:56:12.380]   That's lastpass.com/twit and we thank LastPass for their support and for keeping us safe
[00:56:12.380 --> 00:56:15.820]   online with good password management skills.
[00:56:15.820 --> 00:56:16.820]   Love it.
[00:56:16.820 --> 00:56:19.020]   So let's see here.
[00:56:19.020 --> 00:56:21.300]   Jeff, I'm curious to know how you feel about this.
[00:56:21.300 --> 00:56:28.420]   Google News is getting rid of print publications, no more digital versions of print publication
[00:56:28.420 --> 00:56:31.580]   magazines, that sort of stuff in Google News.
[00:56:31.580 --> 00:56:35.060]   Apparently, they're refunding people who have active subscriptions.
[00:56:35.060 --> 00:56:38.740]   They started this back in 2012 and it's been through a number of different iterations over
[00:56:38.740 --> 00:56:39.740]   the years.
[00:56:39.740 --> 00:56:41.580]   So I'm curious to hear Matthew about this too.
[00:56:41.580 --> 00:56:46.180]   My guess is when the web came out, I worked for Steve Newhouse at Advanced Publications
[00:56:46.180 --> 00:56:51.060]   and he said, "If we handed over this new thing, the web, the internet to the newspaper
[00:56:51.060 --> 00:56:54.540]   publishers, all they would do is put up PDFs of their publications."
[00:56:54.540 --> 00:56:56.060]   And indeed, that happened like crazy.
[00:56:56.060 --> 00:57:00.220]   And indeed, to this day, you see that all the time, "Oh, you can get the PDF for the
[00:57:00.220 --> 00:57:01.220]   paper."
[00:57:01.220 --> 00:57:02.220]   Grandpa.
[00:57:02.220 --> 00:57:07.180]   And the ego of the editor still says, "That's what people really want.
[00:57:07.180 --> 00:57:11.060]   It's my judgment and my design and my this and my that."
[00:57:11.060 --> 00:57:17.980]   And the truth is, nobody wants here's old stinky print Gutenberg layout.
[00:57:17.980 --> 00:57:23.060]   And so my guess is that this is something they did to suck up to publishers and their
[00:57:23.060 --> 00:57:27.000]   egos, which is a lot of what these both Facebook and Google do is to try to just keep them
[00:57:27.000 --> 00:57:31.440]   out of lobbying Brussels and Washington against them.
[00:57:31.440 --> 00:57:33.240]   And nobody wanted it.
[00:57:33.240 --> 00:57:34.240]   That's my guess.
[00:57:34.240 --> 00:57:36.520]   Matthew, what do you think?
[00:57:36.520 --> 00:57:40.040]   So I think you're definitely on the right track.
[00:57:40.040 --> 00:57:47.280]   I do know a couple of people who, in fact, a friend who was just here over the holidays,
[00:57:47.280 --> 00:57:54.960]   who downloads the PDF version basically of the newspaper because she wants to read it
[00:57:54.960 --> 00:57:58.240]   in that way and while she's traveling.
[00:57:58.240 --> 00:58:08.680]   And I ask her why and she's old, you know, not ancient, and she just likes it better.
[00:58:08.680 --> 00:58:12.520]   But I would have to do that in different pieces.
[00:58:12.520 --> 00:58:16.760]   Especially when she's complaining about how long it takes to download the newspaper over
[00:58:16.760 --> 00:58:19.200]   our slow internet.
[00:58:19.200 --> 00:58:22.000]   And I keep saying, you know, you could just go to the website.
[00:58:22.000 --> 00:58:23.000]   It's a lot faster.
[00:58:23.000 --> 00:58:27.880]   But she wants to see it all laid out the way, you know, it would be in the newspaper.
[00:58:27.880 --> 00:58:30.480]   There's an art to the presentation of a newspaper.
[00:58:30.480 --> 00:58:31.480]   Yeah.
[00:58:31.480 --> 00:58:32.480]   She's just used to it.
[00:58:32.480 --> 00:58:34.480]   Yeah, I do use this too.
[00:58:34.480 --> 00:58:39.360]   And I think, but there are services that do that.
[00:58:39.360 --> 00:58:44.600]   And so I guess Google thought, you know, why are we competing in this business?
[00:58:44.600 --> 00:58:46.360]   Why are we doing this?
[00:58:46.360 --> 00:58:49.000]   There's other places people can go to do that.
[00:58:49.000 --> 00:58:50.000]   Yeah.
[00:58:50.000 --> 00:58:51.000]   Yeah.
[00:58:51.000 --> 00:58:55.760]   I know Apple has been very friendly with subscriptions lately where they've, you know,
[00:58:55.760 --> 00:58:57.720]   subscribed with Google and contribute with Google.
[00:58:57.720 --> 00:58:59.840]   They're trying to be very friendly to publishers on that.
[00:58:59.840 --> 00:59:00.840]   But this was kind of ridiculous.
[00:59:00.840 --> 00:59:01.840]   Carson, were you trying to say something?
[00:59:01.840 --> 00:59:02.840]   Where are you going to say, Carson?
[00:59:02.840 --> 00:59:08.120]   Oh, I was just going to say, Apple News is also Apple's News Plus service.
[00:59:08.120 --> 00:59:11.880]   They basically they bought texture and are trying to do very, very similar things.
[00:59:11.880 --> 00:59:12.880]   Same thing.
[00:59:12.880 --> 00:59:14.760]   And they're, yeah, they're going nowhere on that as well.
[00:59:14.760 --> 00:59:15.760]   Yeah.
[00:59:15.760 --> 00:59:17.800]   This is actually restarted by the magazine industry.
[00:59:17.800 --> 00:59:20.600]   Yeah, this is just something that no one really wants.
[00:59:20.600 --> 00:59:23.040]   I mean, for sure.
[00:59:23.040 --> 00:59:29.840]   But I remember when, I mean, you would get digital versions of even wired magazine, Conde
[00:59:29.840 --> 00:59:31.000]   Nast was the worst.
[00:59:31.000 --> 00:59:37.240]   And to download a single issue of the magazine would be hundreds of megabytes, which at
[00:59:37.240 --> 00:59:42.680]   the time, you know, when you didn't have 200 meg, a second internet connection.
[00:59:42.680 --> 00:59:47.400]   So it was because they basically just took a picture, a high res picture of every page
[00:59:47.400 --> 00:59:49.600]   and then put it into a PDF.
[00:59:49.600 --> 00:59:50.440]   Yeah.
[00:59:50.440 --> 00:59:53.440]   And told the advertisers, this is this maintains your waterfall.
[00:59:53.440 --> 01:00:00.120]   Matthew, Canadian question for you, La Press spent a reported $25 million in Montreal to
[01:00:00.120 --> 01:00:02.800]   shift everybody to iPad.
[01:00:02.800 --> 01:00:05.200]   Then recently they became a not-for-profit.
[01:00:05.200 --> 01:00:07.120]   Is the iPad things strategy still there?
[01:00:07.120 --> 01:00:09.560]   Do they get rid of that?
[01:00:09.560 --> 01:00:10.560]   So it is still there.
[01:00:10.560 --> 01:00:14.640]   I'm not 100% clear on how things are going.
[01:00:14.640 --> 01:00:16.800]   I know they were.
[01:00:16.800 --> 01:00:22.600]   It's a bit of a unique market in a way, the Quebec market, partly because of language
[01:00:22.600 --> 01:00:23.680]   and culture, I think.
[01:00:23.680 --> 01:00:30.880]   And so it did a little better there than it did, say, when the Toronto Star tried it.
[01:00:30.880 --> 01:00:31.880]   The Toronto Star.
[01:00:31.880 --> 01:00:32.880]   Well, the Star did try it?
[01:00:32.880 --> 01:00:33.880]   Oh, yeah.
[01:00:33.880 --> 01:00:41.080]   They sort of famously blew, I think it was $35 million or it might have been more than
[01:00:41.080 --> 01:00:51.560]   that they licensed the software and all the other stuff that Quebec War had used for tablets.
[01:00:51.560 --> 01:00:54.360]   And then basically nobody wanted it.
[01:00:54.360 --> 01:00:58.000]   It might as well set that money on fire in the backyard.
[01:00:58.000 --> 01:01:02.640]   It produced nothing effectively, business-wise.
[01:01:02.640 --> 01:01:04.880]   But I think it's still technically going.
[01:01:04.880 --> 01:01:08.440]   I don't know how many people use it.
[01:01:08.440 --> 01:01:16.400]   Yeah, it's unfortunately the post-media, which is the other, another big chain.
[01:01:16.400 --> 01:01:17.400]   Disaster is tragic.
[01:01:17.400 --> 01:01:18.760]   It tried something similar.
[01:01:18.760 --> 01:01:21.720]   Yeah, blew a ton of money on a tablet strategy.
[01:01:21.720 --> 01:01:28.480]   They were hoping that the tablet would be for leaning back on the couch, you know, at
[01:01:28.480 --> 01:01:30.080]   the end of the day.
[01:01:30.080 --> 01:01:34.880]   And then it just didn't happen.
[01:01:34.880 --> 01:01:37.080]   They weren't alone in thinking that.
[01:01:37.080 --> 01:01:38.960]   No, no, they weren't.
[01:01:38.960 --> 01:01:39.960]   Yeah.
[01:01:39.960 --> 01:01:40.960]   What's happening with tablets now?
[01:01:40.960 --> 01:01:43.880]   Oh, and their content on the tablet was exclusive.
[01:01:43.880 --> 01:01:45.600]   So for both the Star.
[01:01:45.600 --> 01:01:46.600]   Right.
[01:01:46.600 --> 01:01:48.600]   So you could only get stuff on the tablet.
[01:01:48.600 --> 01:01:51.800]   I forgot, News Corp did this too, Birdock did this too for a while.
[01:01:51.800 --> 01:01:54.280]   He had a whole huge staff devoted to this.
[01:01:54.280 --> 01:01:55.280]   Yep.
[01:01:55.280 --> 01:01:56.280]   That's right.
[01:01:56.280 --> 01:01:57.280]   But to your bigger question.
[01:01:57.280 --> 01:01:58.280]   That was the daily.
[01:01:58.280 --> 01:01:59.280]   Right, the daily.
[01:01:59.280 --> 01:02:00.280]   Yeah, that's right.
[01:02:00.280 --> 01:02:01.880]   I used to buy magazine money on it.
[01:02:01.880 --> 01:02:06.920]   That was 60 million, I think, the daily.
[01:02:06.920 --> 01:02:08.120]   Yeah, I think so.
[01:02:08.120 --> 01:02:09.360]   I used to buy magazines on the pound.
[01:02:09.360 --> 01:02:10.360]   I started a magazine.
[01:02:10.360 --> 01:02:11.360]   I love magazines.
[01:02:11.360 --> 01:02:13.760]   I really wear my blood.
[01:02:13.760 --> 01:02:16.320]   I haven't bought a magazine in years.
[01:02:16.320 --> 01:02:17.320]   Mm-hmm.
[01:02:17.320 --> 01:02:23.680]   See, my mom still buys magazines by the pound and I tried to give her texture and she was,
[01:02:23.680 --> 01:02:26.480]   she just had no use for it at all.
[01:02:26.480 --> 01:02:27.480]   Really?
[01:02:27.480 --> 01:02:28.480]   Yeah.
[01:02:28.480 --> 01:02:29.480]   It's so locked into the physical.
[01:02:29.480 --> 01:02:30.480]   I mean, it is like, yeah.
[01:02:30.480 --> 01:02:31.480]   And a product.
[01:02:31.480 --> 01:02:32.480]   It's what you get used to.
[01:02:32.480 --> 01:02:33.480]   Yeah.
[01:02:33.480 --> 01:02:34.480]   It's what you get used to.
[01:02:34.480 --> 01:02:38.520]   Lots of, you know, younger folks are happy to consume content on their phones.
[01:02:38.520 --> 01:02:42.680]   But I think if you're older, that's just four and then flipping pages.
[01:02:42.680 --> 01:02:49.520]   No, she has no problem with doing things on her phone either.
[01:02:49.520 --> 01:02:50.520]   It's just one.
[01:02:50.520 --> 01:02:52.520]   Was it the metaphor?
[01:02:52.520 --> 01:02:53.520]   The visual metaphor.
[01:02:53.520 --> 01:02:59.160]   Yeah, the magazines are magazines there and websites are websites and the UI for one
[01:02:59.160 --> 01:03:01.600]   does not work on the other.
[01:03:01.600 --> 01:03:02.600]   Yeah.
[01:03:02.600 --> 01:03:08.760]   And the sort of the flip board, you know, page flipping kind of UI thing.
[01:03:08.760 --> 01:03:12.920]   I know a bunch of people who felt like it's supposed to make you feel more comfortable.
[01:03:12.920 --> 01:03:17.000]   Like it's a magazine, but it actually, I think in some cases, can do the opposite because
[01:03:17.000 --> 01:03:23.280]   you're thinking, well, why am I flipping like a virtual page that doesn't make any sense?
[01:03:23.280 --> 01:03:24.280]   Yeah.
[01:03:24.280 --> 01:03:25.280]   Right.
[01:03:25.280 --> 01:03:26.280]   Well, yeah.
[01:03:26.280 --> 01:03:32.760]   Yeah, like sometimes when I think about like the like earlier days of getting a magazine
[01:03:32.760 --> 01:03:36.840]   and like relaxing, you know, sit down on the couch flipping through a magazine, I don't
[01:03:36.840 --> 01:03:43.280]   get that same kind of relaxing feeling when I've got a display in front of me.
[01:03:43.280 --> 01:03:48.160]   Now, now I maybe do, but back then I could totally see myself resisting to it.
[01:03:48.160 --> 01:03:50.120]   You totally can just lie lie down.
[01:03:50.120 --> 01:03:51.120]   Now I can.
[01:03:51.120 --> 01:03:52.120]   Yeah.
[01:03:52.120 --> 01:03:55.440]   Now I can't sit there and just swipe for hours.
[01:03:55.440 --> 01:03:57.280]   I try not to is the thing.
[01:03:57.280 --> 01:03:59.520]   And maybe that's the thing.
[01:03:59.520 --> 01:04:00.760]   That's the thing about magazines.
[01:04:00.760 --> 01:04:05.640]   That's kind of appealing is like you're not going to be distracted in a million other different
[01:04:05.640 --> 01:04:06.840]   directions.
[01:04:06.840 --> 01:04:07.840]   This is the thing.
[01:04:07.840 --> 01:04:09.440]   We want to be looking at this magazine.
[01:04:09.440 --> 01:04:10.440]   Yeah.
[01:04:10.440 --> 01:04:14.760]   I had this conversation with a friend about the Kindle.
[01:04:14.760 --> 01:04:17.760]   And I said, you know, I can read books on my tablet.
[01:04:17.760 --> 01:04:21.920]   And he said, yeah, but then you'll get pop ups and you'll go to some other application
[01:04:21.920 --> 01:04:25.080]   and he said, when I'm reading a book, I just want to read the book.
[01:04:25.080 --> 01:04:30.760]   I don't want message notifications or, you know, yeah, which is a fair point.
[01:04:30.760 --> 01:04:35.560]   I completely agree with that.
[01:04:35.560 --> 01:04:36.560]   Let's see here.
[01:04:36.560 --> 01:04:39.000]   Well, this was this seemed like big news.
[01:04:39.000 --> 01:04:40.480]   When was this late last week?
[01:04:40.480 --> 01:04:44.840]   This medium post Ross La Lajanes.
[01:04:44.840 --> 01:04:46.240]   Is that how you say it's not?
[01:04:46.240 --> 01:04:47.240]   Yeah.
[01:04:47.240 --> 01:04:52.200]   Once Google's top public policy executive employee since 2008, he left Google back in
[01:04:52.200 --> 01:04:53.280]   April.
[01:04:53.280 --> 01:04:56.520]   He wrote on medium last week that he was actually pushed out.
[01:04:56.520 --> 01:05:02.720]   He had been advocating for a formal human rights program in Google, said every time he
[01:05:02.720 --> 01:05:08.920]   recommended the program, senior executives looked for reasons to say no.
[01:05:08.920 --> 01:05:12.600]   Google ultimately chose not to double down on human rights.
[01:05:12.600 --> 01:05:13.600]   Go away Google.
[01:05:13.600 --> 01:05:14.600]   It just woke up again.
[01:05:14.600 --> 01:05:15.600]   Go away Google.
[01:05:15.600 --> 01:05:16.600]   It just woke up again.
[01:05:16.600 --> 01:05:17.600]   Jeez.
[01:05:17.600 --> 01:05:18.600]   I swear.
[01:05:18.600 --> 01:05:19.600]   Not for you.
[01:05:19.600 --> 01:05:20.600]   Not for you.
[01:05:20.600 --> 01:05:25.600]   Exactly.
[01:05:25.600 --> 01:05:26.600]   Yeah.
[01:05:26.600 --> 01:05:28.000]   So he's saying he was pushed out.
[01:05:28.000 --> 01:05:31.800]   So many changes happened right about the time that we started hearing about Dragonfly
[01:05:31.800 --> 01:05:36.320]   and all the internal machinations around that.
[01:05:36.320 --> 01:05:38.120]   And he says, Google's changed.
[01:05:38.120 --> 01:05:39.120]   Don't be evil.
[01:05:39.120 --> 01:05:42.320]   Used to make used to actually mean something.
[01:05:42.320 --> 01:05:45.240]   Now it's just an item at the bottom.
[01:05:45.240 --> 01:05:47.880]   I guess they've completely walked away from it at this point.
[01:05:47.880 --> 01:05:49.480]   It doesn't mean anything.
[01:05:49.480 --> 01:05:55.480]   They're chasing profits and stock prices and human rights doesn't mean anything to them.
[01:05:55.480 --> 01:06:01.520]   What do you think the motto now is only as evil as necessary?
[01:06:01.520 --> 01:06:02.520]   Yeah.
[01:06:02.520 --> 01:06:03.520]   Right.
[01:06:03.520 --> 01:06:04.520]   Right.
[01:06:04.520 --> 01:06:05.520]   Maybe a little evil.
[01:06:05.520 --> 01:06:11.600]   It's disappointing that they downgraded that view.
[01:06:11.600 --> 01:06:15.400]   As we said on the show many, many times it was really meant as a license to employees
[01:06:15.400 --> 01:06:19.040]   to say keep us from being evil because being evil is bad business.
[01:06:19.040 --> 01:06:22.040]   Problem now I think for all of them is there's so many definitions of evil.
[01:06:22.040 --> 01:06:23.040]   Yeah.
[01:06:23.040 --> 01:06:24.040]   It's the same problem with Facebook.
[01:06:24.040 --> 01:06:26.000]   I was in a huge discussion today on Twitter.
[01:06:26.000 --> 01:06:28.680]   It was tiring because I've had it a million times.
[01:06:28.680 --> 01:06:31.320]   You know, they should get rid of fake stuff.
[01:06:31.320 --> 01:06:33.640]   Well, who's going to find one fake?
[01:06:33.640 --> 01:06:38.280]   What's fake to one party is going to be, you know, orthodoxy to another and then they're
[01:06:38.280 --> 01:06:40.280]   going to get mad at them and they're stuck in the middle.
[01:06:40.280 --> 01:06:43.040]   And, you know, what are you going to do?
[01:06:43.040 --> 01:06:45.360]   Or Jack Dorsey?
[01:06:45.360 --> 01:06:51.080]   You really believe that he should pull down Trump's account and single handedly should
[01:06:51.080 --> 01:06:54.960]   go up against the firestorm that would exist against him?
[01:06:54.960 --> 01:07:01.240]   You know, I get it that they should have their standards, but they're in a position now where
[01:07:01.240 --> 01:07:07.320]   they've had known for so long believe in the platform belief that there's no expectation
[01:07:07.320 --> 01:07:08.880]   as to how they can do it.
[01:07:08.880 --> 01:07:09.880]   Yeah.
[01:07:09.880 --> 01:07:13.040]   And I think it's I think it's Matthew.
[01:07:13.040 --> 01:07:14.040]   Sorry.
[01:07:14.040 --> 01:07:15.040]   I must have been.
[01:07:15.040 --> 01:07:18.720]   Yeah, I thought he I mean, I thought he made some good points.
[01:07:18.720 --> 01:07:26.800]   I do think Google has maybe moved away from some of the sort of core principles or attitudes
[01:07:26.800 --> 01:07:28.880]   that it had.
[01:07:28.880 --> 01:07:33.680]   It is a massive, massive corporation and, you know, it wants to do things like move into
[01:07:33.680 --> 01:07:35.680]   China, I suppose.
[01:07:35.680 --> 01:07:41.400]   I guess I was a little so I I didn't realize so read the end to the end that he was running
[01:07:41.400 --> 01:07:43.040]   for office.
[01:07:43.040 --> 01:07:49.040]   And then my perspective changed because I thought if he's running for something, this is a
[01:07:49.040 --> 01:07:51.240]   pretty good platform, right?
[01:07:51.240 --> 01:07:52.600]   To campaign on.
[01:07:52.600 --> 01:07:59.000]   I think there's a lot of kind of market out there for the Google bashing or Facebook
[01:07:59.000 --> 01:08:02.880]   bashing tech bashing kind of platform.
[01:08:02.880 --> 01:08:09.560]   So that to me maybe made me think not that he's making any of this up, but but it but
[01:08:09.560 --> 01:08:11.440]   playing it up, I guess makes for a good.
[01:08:11.440 --> 01:08:12.440]   That's really important.
[01:08:12.440 --> 01:08:18.120]   Yeah, I didn't get that that that should be like at the top.
[01:08:18.120 --> 01:08:22.040]   That now similar to this, did you all read the boss post?
[01:08:22.040 --> 01:08:25.760]   Yeah, which I thought was actually on the right.
[01:08:25.760 --> 01:08:27.040]   I thought it was good.
[01:08:27.040 --> 01:08:28.040]   I put it on there.
[01:08:28.040 --> 01:08:32.400]   I don't know if you saw that in time right before we went up.
[01:08:32.400 --> 01:08:33.600]   Jason's sort of if you saw it.
[01:08:33.600 --> 01:08:34.600]   Yes.
[01:08:34.600 --> 01:08:35.600]   Yes.
[01:08:35.600 --> 01:08:36.600]   Yes.
[01:08:36.600 --> 01:08:38.800]   The memo that basically he posted.
[01:08:38.800 --> 01:08:43.240]   So it was on his behind the scenes wall.
[01:08:43.240 --> 01:08:44.240]   Right.
[01:08:44.240 --> 01:08:45.240]   Right.
[01:08:45.240 --> 01:08:48.280]   And he was he was just trying to think through.
[01:08:48.280 --> 01:08:57.040]   And I think it was actually kind of well said and he believes that Facebook did get
[01:08:57.040 --> 01:09:03.080]   Trump elected, but not for the reasons that everyone says it's simply because they used
[01:09:03.080 --> 01:09:05.960]   the ad tools better than anybody.
[01:09:05.960 --> 01:09:08.920]   It wasn't because of micro targeting and it wasn't because of his information.
[01:09:08.920 --> 01:09:11.320]   It was because of smart advertising.
[01:09:11.320 --> 01:09:13.520]   And but he's also caution in the company.
[01:09:13.520 --> 01:09:16.800]   Don't change things to stop that because that's what that's what we are.
[01:09:16.800 --> 01:09:19.960]   And if somebody was used it smartly, they shouldn't if they don't use it smartly.
[01:09:19.960 --> 01:09:21.520]   And that's that's kind of that.
[01:09:21.520 --> 01:09:24.280]   It's like the United States Postal Service shouldn't have said we're going to get rid
[01:09:24.280 --> 01:09:29.880]   of direct mail because Richard Nixon's using it, you know.
[01:09:29.880 --> 01:09:32.360]   He also went for any rational.
[01:09:32.360 --> 01:09:35.480]   I think it was very much was you also went through a good riff which I'm glad to see to
[01:09:35.480 --> 01:09:43.500]   do good versus I'm glad to see one is Cambridge Analytica is F.O.S. full of poop never was
[01:09:43.500 --> 01:09:49.120]   all powerful and all knowing people I know in the data world have pooped it and made fun
[01:09:49.120 --> 01:09:50.120]   of it forever.
[01:09:50.120 --> 01:09:54.600]   And it's being treated as this big evil behemoth that's changing people's minds.
[01:09:54.600 --> 01:09:59.840]   And no, it's another you know live from the folks who brought you by part.
[01:09:59.840 --> 01:10:02.520]   The other thing he said and there was every time he said media gets this wrong media gets
[01:10:02.520 --> 01:10:07.720]   this wrong he says well, you know, that's kind of on us because we don't tell him anything.
[01:10:07.720 --> 01:10:13.480]   And it's true and they've got to recognize that their secrecy is going to yield people
[01:10:13.480 --> 01:10:18.800]   filling in blanks with the wrong stuff and that's on us in media to get in his wrong.
[01:10:18.800 --> 01:10:22.360]   But people go to presumptions because they don't know things because the company doesn't
[01:10:22.360 --> 01:10:25.480]   say things which is not good for the company in the end and maybe they can learn that.
[01:10:25.480 --> 01:10:26.480]   But I don't know.
[01:10:26.480 --> 01:10:28.720]   Yeah, that was a good point.
[01:10:28.720 --> 01:10:34.280]   I thought that was a good point especially he also said along the same lines he said,
[01:10:34.280 --> 01:10:39.200]   you know, we get a lot of criticism about things but he said that's we should we should
[01:10:39.200 --> 01:10:40.200]   get a lot of criticism.
[01:10:40.200 --> 01:10:41.200]   Yeah.
[01:10:41.200 --> 01:10:42.200]   Yeah.
[01:10:42.200 --> 01:10:45.840]   We're a huge company and we affect people's lives in really important ways.
[01:10:45.840 --> 01:10:50.800]   And that's something that we that's a responsibility that we should feel inside and if people
[01:10:50.800 --> 01:10:55.000]   are continually yelling at us and holding us to account even if some of what they say
[01:10:55.000 --> 01:10:58.560]   is not 100% true we should we deserve it.
[01:10:58.560 --> 01:11:03.480]   We should we should effectively be able to defend ourselves.
[01:11:03.480 --> 01:11:10.320]   And I thought there were I mean his point about, you know, sure I want Trump to lose
[01:11:10.320 --> 01:11:15.040]   and but please don't rig the algorithm to make that happen because we shouldn't do that
[01:11:15.040 --> 01:11:21.480]   is a good I mean obviously that's that's the way Facebook should behave but he extended
[01:11:21.480 --> 01:11:27.000]   it to cover not fact checking political ads which I don't think he actually said he would
[01:11:27.000 --> 01:11:34.080]   defend that policy even if it meant that Trump was reelected and I I don't think I don't
[01:11:34.080 --> 01:11:37.880]   buy the argument that they shouldn't fact check political ads.
[01:11:37.880 --> 01:11:40.480]   I mean the fact check other things if anything.
[01:11:40.480 --> 01:11:41.480]   If anything, if anything,
[01:11:41.480 --> 01:11:42.480]   We have a disagreement.
[01:11:42.480 --> 01:11:43.480]   One more.
[01:11:43.480 --> 01:11:44.480]   Sorry.
[01:11:44.480 --> 01:11:45.480]   Why wouldn't I do that?
[01:11:45.480 --> 01:11:50.400]   Well, you and I have a disagreement a lot of times so we got to you know, I a few things.
[01:11:50.400 --> 01:11:54.120]   One is a nice thing this all the time.
[01:11:54.120 --> 01:11:55.280]   This is their standard company line.
[01:11:55.280 --> 01:11:58.480]   Do you really want Facebook to be the arbiter of truth?
[01:11:58.480 --> 01:12:03.360]   If truth were easy to establish, then we wouldn't need lots of journalists to get to
[01:12:03.360 --> 01:12:04.360]   it.
[01:12:04.360 --> 01:12:08.240]   Fact checking agencies are presumed by the right wing to all be left wing and they're
[01:12:08.240 --> 01:12:10.520]   not necessarily wrong about that.
[01:12:10.520 --> 01:12:14.280]   And part of the other problem is that are things taking down disproportionately on the right
[01:12:14.280 --> 01:12:15.280]   wing?
[01:12:15.280 --> 01:12:17.680]   Yes, because they tend to use these techniques more.
[01:12:17.680 --> 01:12:19.680]   Don't at me.
[01:12:19.680 --> 01:12:25.360]   So again, as I was saying before, they're in a they're in a dicey position.
[01:12:25.360 --> 01:12:27.160]   Point two, but then is.
[01:12:27.160 --> 01:12:32.440]   Well, see, I was in them.
[01:12:32.440 --> 01:12:33.440]   You can't.
[01:12:33.440 --> 01:12:35.440]   But Aaron, go for it.
[01:12:35.440 --> 01:12:41.400]   Well, but Aaron, pull offer says today, if you're NBC or CBS, you're not allowed to
[01:12:41.400 --> 01:12:42.400]   fact check ads.
[01:12:42.400 --> 01:12:45.280]   You can't pull ads off.
[01:12:45.280 --> 01:12:47.480]   Pop politicians can say whatever the heck they want on broadcast.
[01:12:47.480 --> 01:12:49.480]   Everybody talks about how broadcast TV is regulated.
[01:12:49.480 --> 01:12:50.480]   Yeah, it is.
[01:12:50.480 --> 01:12:53.800]   And part of the regulation is you can't.
[01:12:53.800 --> 01:12:57.920]   And so what is it we expect Facebook to do?
[01:12:57.920 --> 01:12:58.920]   Are politicians lie?
[01:12:58.920 --> 01:13:00.400]   We all know they lie.
[01:13:00.400 --> 01:13:04.400]   It's up to you, the voter decide whether you want them to lie or not.
[01:13:04.400 --> 01:13:07.560]   If I like their lies, that's exactly why how Trump got in office.
[01:13:07.560 --> 01:13:11.320]   Suddenly, if we make them tell the truth, he's not going to.
[01:13:11.320 --> 01:13:14.480]   Everybody's looking for an easy solution to the problem that we have, which is much more
[01:13:14.480 --> 01:13:19.000]   fundamental in society, which is that we're highly divided, partly because of media, because
[01:13:19.000 --> 01:13:23.080]   there's huge amounts of racism and fear in this society.
[01:13:23.080 --> 01:13:25.360]   And that's where we are.
[01:13:25.360 --> 01:13:29.840]   And you live, Matthew, in the nice land I want to retire to, and then won't take me.
[01:13:29.840 --> 01:13:34.600]   Somebody was telling me just the other day, there was Michael Moore's gun show.
[01:13:34.600 --> 01:13:38.520]   I was reminding this that he went to, he said that what separates Canada from the US
[01:13:38.520 --> 01:13:41.120]   is that the US is all about fear and consumerism.
[01:13:41.120 --> 01:13:48.640]   He was on the US border and it was wires and alarms and everything over his home.
[01:13:48.640 --> 01:13:51.800]   And he went across to Canada and he just opened people's doors and walked into their house
[01:13:51.800 --> 01:13:53.800]   and said, "Hi, I'm Michael Moore."
[01:13:53.800 --> 01:13:56.000]   Because the door was open.
[01:13:56.000 --> 01:14:00.440]   It's a lot ingrained in our society and we're not going to fix that overnight by telling
[01:14:00.440 --> 01:14:03.920]   Facebook to get rid of politicians' lies.
[01:14:03.920 --> 01:14:08.720]   Yeah, I guess I mean, I appreciate your point.
[01:14:08.720 --> 01:14:15.680]   And I think I see where you're coming from, but I wonder if they can fact check news articles
[01:14:15.680 --> 01:14:19.840]   using third party fact checkers, why can't they fact check political ads?
[01:14:19.840 --> 01:14:24.760]   I mean, if we're going to do one, if we're going to do one, why don't you do the other?
[01:14:24.760 --> 01:14:27.160]   Why can't they take annotations?
[01:14:27.160 --> 01:14:28.560]   Because they're politicians is what they argue with.
[01:14:28.560 --> 01:14:31.600]   They're public figures is the argument.
[01:14:31.600 --> 01:14:35.560]   There are those inside Facebook who agree with you and those obviously who disagree with
[01:14:35.560 --> 01:14:40.080]   you because that side has won so far from what I've heard.
[01:14:40.080 --> 01:14:43.320]   I just think the other part of this is scale.
[01:14:43.320 --> 01:14:46.560]   If you play, and I love to do this every once in a while, and I go into the Facebook ad
[01:14:46.560 --> 01:14:49.440]   tool and I recommend calling it up.
[01:14:49.440 --> 01:14:54.600]   If you search for Facebook ad database or something, it'll come up and you look on a
[01:14:54.600 --> 01:14:58.560]   word, the volume of ads is phenomenal.
[01:14:58.560 --> 01:15:01.640]   And they're not all from politicians very importantly.
[01:15:01.640 --> 01:15:04.120]   They're from Planned Parenthood.
[01:15:04.120 --> 01:15:05.480]   They're from the NRA.
[01:15:05.480 --> 01:15:08.440]   They're from all kinds of organizations that have something to say.
[01:15:08.440 --> 01:15:11.520]   They're from people who just want to put their money out because they know that they'll get
[01:15:11.520 --> 01:15:17.680]   seen because they put money into it just like a mobile oil used to put ads on the op-ed
[01:15:17.680 --> 01:15:21.800]   page of the New York Times when people still butt print.
[01:15:21.800 --> 01:15:25.280]   So it's a forum for discussion too.
[01:15:25.280 --> 01:15:29.160]   And at Facebook, it's a tremendous scale.
[01:15:29.160 --> 01:15:30.160]   And you know what's going to happen?
[01:15:30.160 --> 01:15:33.200]   They start protecting ads and they're going to take an ad down and then there's going
[01:15:33.200 --> 01:15:37.160]   to be a huge fear about how there's sensory and political discussion.
[01:15:37.160 --> 01:15:38.160]   Yeah.
[01:15:38.160 --> 01:15:40.240]   There are no ways to issue it.
[01:15:40.240 --> 01:15:45.720]   As an example, how do you fact check an ad that says the Democrats want to take away
[01:15:45.720 --> 01:15:46.720]   your guns?
[01:15:46.720 --> 01:15:47.720]   Right.
[01:15:47.720 --> 01:15:51.520]   Because that's in some cases true.
[01:15:51.520 --> 01:15:53.800]   Yes, and that's totally fair.
[01:15:53.800 --> 01:16:02.040]   But what if the ad says, you know, Obama invaded Iraq in 1987?
[01:16:02.040 --> 01:16:04.480]   Well, that clearly is factually inaccurate.
[01:16:04.480 --> 01:16:06.800]   So that's just a fact.
[01:16:06.800 --> 01:16:08.000]   It's not an opinion.
[01:16:08.000 --> 01:16:10.800]   It's not a difference of context.
[01:16:10.800 --> 01:16:12.400]   It's just factually uncrew.
[01:16:12.400 --> 01:16:17.400]   But most of the claims are like the one that Carson just said rather than the one that
[01:16:17.400 --> 01:16:18.400]   used.
[01:16:18.400 --> 01:16:19.400]   Agreed.
[01:16:19.400 --> 01:16:23.840]   And I think, you know, the other side of this coin is Twitter saying they're not going
[01:16:23.840 --> 01:16:28.040]   to carry paid political ads at all.
[01:16:28.040 --> 01:16:31.880]   Now they have to define what a political ad is.
[01:16:31.880 --> 01:16:38.480]   So if it's an ad about nature and climate change, well, that's a political topic.
[01:16:38.480 --> 01:16:39.480]   I agree.
[01:16:39.480 --> 01:16:41.040]   It's a complex issue.
[01:16:41.040 --> 01:16:42.040]   Yeah.
[01:16:42.040 --> 01:16:46.320]   That's for Chevron or now legal that adds against Chevron or not.
[01:16:46.320 --> 01:16:47.320]   Right.
[01:16:47.320 --> 01:16:48.320]   Exactly.
[01:16:48.320 --> 01:16:51.160]   I've been doing a lot of my Gutenberg research.
[01:16:51.160 --> 01:16:55.800]   So I've been doing a lot of a lot, a lot of reading about the early days of publishing
[01:16:55.800 --> 01:17:02.440]   in the news and it's just simply true that every country and every regime that tried
[01:17:02.440 --> 01:17:08.440]   to control the printing press and tried to tamp down speech lost and lost more than
[01:17:08.440 --> 01:17:10.200]   just that battle.
[01:17:10.200 --> 01:17:12.720]   They were left behind.
[01:17:12.720 --> 01:17:16.160]   And, you know, I quick to point out I'm not a libertarian.
[01:17:16.160 --> 01:17:17.760]   I'm about to sound like one.
[01:17:17.760 --> 01:17:21.040]   I'm a morning Kamala Harris Democrat.
[01:17:21.040 --> 01:17:27.440]   But this research makes me more and more and more a free speech absolutist.
[01:17:27.440 --> 01:17:32.800]   And just say that it's the public conversation and we all have the right to judge on our
[01:17:32.800 --> 01:17:33.800]   own.
[01:17:33.800 --> 01:17:38.480]   And journalism's job is to help people judge if they trust us enough to care.
[01:17:38.480 --> 01:17:46.160]   But trying to tamp down speech just makes me more and more nervous as things go by.
[01:17:46.160 --> 01:17:52.760]   I was at a meeting recently to try to with people who were called in to talk about what
[01:17:52.760 --> 01:17:57.400]   we do about Facebook and political ads in 2020 and no, no, no, no.
[01:17:57.400 --> 01:18:02.800]   I looked around the room and I saw a room that was majority vast majority white men.
[01:18:02.800 --> 01:18:07.240]   And I said, I'm uncomfortable sitting in a room where a bunch of white people are trying
[01:18:07.240 --> 01:18:13.360]   to decide what people can and cannot say when you have a world where the people who were
[01:18:13.360 --> 01:18:17.560]   never allowed to speak in mainstream media now finally have a voice.
[01:18:17.560 --> 01:18:24.800]   There was a great, great New York Times op ed a week ago.
[01:18:24.800 --> 01:18:25.800]   About Twitter.
[01:18:25.800 --> 01:18:26.800]   Yeah.
[01:18:26.800 --> 01:18:27.800]   Yeah.
[01:18:27.800 --> 01:18:28.800]   I thought it was really good.
[01:18:28.800 --> 01:18:30.560]   It was a good piece.
[01:18:30.560 --> 01:18:34.760]   We're in a different world.
[01:18:34.760 --> 01:18:40.080]   I mean, I get your point about being a free speech absolutist, but the vast quantities
[01:18:40.080 --> 01:18:43.400]   of our speech are controlled by private corporations.
[01:18:43.400 --> 01:18:46.440]   And that's a place we have not been before.
[01:18:46.440 --> 01:18:50.400]   That's like, you know, we all live inside a giant shopping mall.
[01:18:50.400 --> 01:18:55.400]   And so we get to say the things that those companies allow us to say Facebook monetizes
[01:18:55.400 --> 01:19:01.520]   that speech and they pick specific things to monetize and things not to monetize.
[01:19:01.520 --> 01:19:04.600]   And we don't know how they pick those things.
[01:19:04.600 --> 01:19:08.840]   What you just described is our industry as journalism media.
[01:19:08.840 --> 01:19:12.320]   Yeah, but our industry was not anywhere near the kind of scale we're talking about.
[01:19:12.320 --> 01:19:15.960]   It has never been a newspaper or a media company.
[01:19:15.960 --> 01:19:21.120]   Not even Fox News is anything like the scale of Facebook.
[01:19:21.120 --> 01:19:22.840]   But but it's not broadcast.
[01:19:22.840 --> 01:19:23.840]   It's not mass media.
[01:19:23.840 --> 01:19:26.440]   It's not showing the same thing to everybody.
[01:19:26.440 --> 01:19:28.960]   It is a platform that you make their decisions.
[01:19:28.960 --> 01:19:36.880]   And I don't understand the scale argument where, I mean, the.
[01:19:36.880 --> 01:19:46.280]   I mean, one paper or one news, maybe one one NBC news or one San Francisco Chronicle didn't
[01:19:46.280 --> 01:19:47.840]   reach everybody.
[01:19:47.840 --> 01:19:55.840]   But like the the national news reached had the same approximate reach as Facebook does
[01:19:55.840 --> 01:19:58.240]   in America.
[01:19:58.240 --> 01:20:01.240]   So no two people see the same Facebook.
[01:20:01.240 --> 01:20:03.120]   Everybody who watched CBS saw the same CBS.
[01:20:03.120 --> 01:20:04.120]   Yeah.
[01:20:04.120 --> 01:20:05.120]   And I agree with you.
[01:20:05.120 --> 01:20:08.120]   So CBS had a much bigger reach than Facebook.
[01:20:08.120 --> 01:20:10.400]   A single company controls all of that.
[01:20:10.400 --> 01:20:11.400]   Yes.
[01:20:11.400 --> 01:20:12.400]   Yes.
[01:20:12.400 --> 01:20:13.400]   CBS.
[01:20:13.400 --> 01:20:15.840]   So that has never reached that than an individual entity on Facebook.
[01:20:15.840 --> 01:20:16.840]   Yes.
[01:20:16.840 --> 01:20:18.000]   Facebook does not have a lot.
[01:20:18.000 --> 01:20:20.560]   When we talk about Facebook, it has this huge reach.
[01:20:20.560 --> 01:20:23.920]   It's not presenting the same thing to everybody on the earth.
[01:20:23.920 --> 01:20:25.680]   And instead is people having conversations.
[01:20:25.680 --> 01:20:26.680]   It's not content.
[01:20:26.680 --> 01:20:27.680]   It's not media.
[01:20:27.680 --> 01:20:28.840]   It's conversation.
[01:20:28.840 --> 01:20:30.600]   But the conversation is not what we're talking about.
[01:20:30.600 --> 01:20:33.640]   We're talking about advertising and advertising in particular.
[01:20:33.640 --> 01:20:35.480]   In fact, micro targeting.
[01:20:35.480 --> 01:20:40.880]   If you listen to Alex Stamos and others, micro targeting actually makes things worse.
[01:20:40.880 --> 01:20:48.120]   If you can micro target specific disinformation to specific people, that's a potential democratic
[01:20:48.120 --> 01:20:49.120]   nightmare.
[01:20:49.120 --> 01:20:52.520]   Well, I'm going to argue contrary again.
[01:20:52.520 --> 01:20:58.120]   And it's a piece I'm going to want you to write in defense of targeting because because
[01:20:58.120 --> 01:21:02.080]   what offends me is mass media that treats us all the same and expects we're all going
[01:21:02.080 --> 01:21:06.680]   to be melted pot into the same beast, which is going to look like white people who look
[01:21:06.680 --> 01:21:07.960]   like me.
[01:21:07.960 --> 01:21:11.400]   And what targeting does micro targeting is kind of a scare word.
[01:21:11.400 --> 01:21:12.800]   Let's just call it targeting.
[01:21:12.800 --> 01:21:17.200]   A, all media have died into targeting better and better and better forever.
[01:21:17.200 --> 01:21:18.760]   The internet finally enables it.
[01:21:18.760 --> 01:21:22.920]   B, targeting makes advertising more relevant and efficient.
[01:21:22.920 --> 01:21:29.680]   And if you are AOC or if you're a small school board campaign or if you're a movement of
[01:21:29.680 --> 01:21:36.200]   wearing the parkland t-shirt and you want to do guns, this allows you to go to people
[01:21:36.200 --> 01:21:37.840]   at a very efficient level.
[01:21:37.840 --> 01:21:42.360]   Without targeting, you end up having to be Michael Bloomberg buying a Super Bowl ad against
[01:21:42.360 --> 01:21:46.320]   Philip, a legendary Donald Trump buying a Super Bowl ad.
[01:21:46.320 --> 01:21:48.000]   That's what we're trying to get away from.
[01:21:48.000 --> 01:21:51.200]   But you're describing how Donald Trump won.
[01:21:51.200 --> 01:21:56.480]   Donald Trump won because Brad or scally, micro targeted specific voters and convinced them
[01:21:56.480 --> 01:21:58.280]   not to go to the polls.
[01:21:58.280 --> 01:22:01.720]   Hillary Clinton could have done the exact same thing.
[01:22:01.720 --> 01:22:04.600]   Hillary Clinton could have done the exact, go on, not just convinced people not to go
[01:22:04.600 --> 01:22:05.600]   to the polls.
[01:22:05.600 --> 01:22:08.760]   But Hillary Clinton could have used the exact same tools and didn't.
[01:22:08.760 --> 01:22:09.760]   Exactly.
[01:22:09.760 --> 01:22:16.560]   You're only arguing against targeting because the guy you don't like won.
[01:22:16.560 --> 01:22:28.240]   I remember all the praise that the liberal journalism establishment gave Obama in '28.
[01:22:28.240 --> 01:22:30.240]   >> 2012 for his use.
[01:22:30.240 --> 01:22:32.240]   >> That's the way they use technology.
[01:22:32.240 --> 01:22:33.240]   >> Yep.
[01:22:33.240 --> 01:22:38.280]   >> I'm looking through right now at the Facebook ad library and I just searched on the word
[01:22:38.280 --> 01:22:39.760]   climate.
[01:22:39.760 --> 01:22:43.360]   Tom Steyer is there, another damn billionaire.
[01:22:43.360 --> 01:22:51.560]   But otherwise, it is organizations of a fairly wide range plus brute, I don't know why they're
[01:22:51.560 --> 01:22:55.400]   there.
[01:22:55.400 --> 01:23:03.320]   The climate list, Yale climate connections, climate reality, alliance for climate education.
[01:23:03.320 --> 01:23:07.120]   Now by the way, some of these of course could be fronts for disinformation.
[01:23:07.120 --> 01:23:08.120]   I don't know.
[01:23:08.120 --> 01:23:09.640]   I haven't gone into detail on the ads.
[01:23:09.640 --> 01:23:17.920]   But my point is that you can start to, part of what the First Amendment in the United
[01:23:17.920 --> 01:23:21.480]   States protects is not just the right to speak but also the right to assemble.
[01:23:21.480 --> 01:23:26.360]   And targeting enables assembly and assembly is what enables action and enables movements
[01:23:26.360 --> 01:23:27.520]   to start.
[01:23:27.520 --> 01:23:32.240]   And if you have to depend upon money and gatekeepers still, that's the world we were in and that's
[01:23:32.240 --> 01:23:36.880]   the world that I celebrate, the hegemony that I celebrate being torn apart.
[01:23:36.880 --> 01:23:38.600]   And targeting is part of that.
[01:23:38.600 --> 01:23:39.600]   >> We have a gatekeeper.
[01:23:39.600 --> 01:23:41.600]   We have a massive multi-billion dollar.
[01:23:41.600 --> 01:23:42.600]   >> No, they're not gatekeepers.
[01:23:42.600 --> 01:23:43.600]   That's the 100 billion dollars.
[01:23:43.600 --> 01:23:47.160]   >> No, you just spent 10 minutes complaining about how they're not gatekeeping.
[01:23:47.160 --> 01:23:50.080]   You just spent, you can't have it both ways either Matthew, right?
[01:23:50.080 --> 01:23:52.640]   You just spent 10 minutes complaining that they're not gatekeeping.
[01:23:52.640 --> 01:23:56.920]   >> They're making decisions that we don't understand based on criteria that they don't
[01:23:56.920 --> 01:23:58.200]   tell us about.
[01:23:58.200 --> 01:24:03.040]   And they control the information that billions of people get.
[01:24:03.040 --> 01:24:04.040]   That's a gatekeeper.
[01:24:04.040 --> 01:24:05.040]   >> The ads they're not.
[01:24:05.040 --> 01:24:07.200]   >> So, sure they are.
[01:24:07.200 --> 01:24:12.040]   >> No, say, you pay for targeting and you get it.
[01:24:12.040 --> 01:24:13.040]   >> Right.
[01:24:13.040 --> 01:24:17.520]   >> And you and many like you have complained, well, they should be gatekeeping that and
[01:24:17.520 --> 01:24:18.720]   they're not.
[01:24:18.720 --> 01:24:22.760]   So that now you turn around and say that, well, they are gatekeeping it.
[01:24:22.760 --> 01:24:23.760]   >> They are.
[01:24:23.760 --> 01:24:24.760]   >> Of course they are.
[01:24:24.760 --> 01:24:25.760]   >> Of course they are.
[01:24:25.760 --> 01:24:30.960]   >> What are the criteria that they give you to target on?
[01:24:30.960 --> 01:24:33.640]   Do you know how those fit into the algorithm, the ad algorithm?
[01:24:33.640 --> 01:24:37.000]   Do you know how they fit into how you see things in your newsfeed?
[01:24:37.000 --> 01:24:38.080]   No.
[01:24:38.080 --> 01:24:40.840]   How often you see an ad, where you see an ad?
[01:24:40.840 --> 01:24:42.520]   So sure, you can pick categories.
[01:24:42.520 --> 01:24:44.600]   I've seen the ad tool.
[01:24:44.600 --> 01:24:50.240]   But I don't understand, no one understands, except half a dozen people at Facebook.
[01:24:50.240 --> 01:24:52.520]   How is that a where people see things that went?
[01:24:52.520 --> 01:24:55.720]   >> Is it working too well or not well enough, Matt?
[01:24:55.720 --> 01:24:57.200]   >> Right, right, right.
[01:24:57.200 --> 01:24:59.000]   >> We don't know.
[01:24:59.000 --> 01:25:01.960]   We don't know how it works.
[01:25:01.960 --> 01:25:03.400]   And they're not telling anyone.
[01:25:03.400 --> 01:25:04.920]   >> Because it's part of my problem.
[01:25:04.920 --> 01:25:05.920]   >> Here's another way to look at it.
[01:25:05.920 --> 01:25:09.240]   Here's Travis Smith for North Carolina Senate.
[01:25:09.240 --> 01:25:10.240]   Right?
[01:25:10.240 --> 01:25:15.640]   There's a young guy who's running for the Senate in North Carolina, tiny, tiny constituency
[01:25:15.640 --> 01:25:17.480]   that he wants to reach.
[01:25:17.480 --> 01:25:22.960]   In the past, he'd have to pay for incredibly inefficient advertising in newspapers and
[01:25:22.960 --> 01:25:23.960]   television.
[01:25:23.960 --> 01:25:26.320]   It couldn't afford it, couldn't do it.
[01:25:26.320 --> 01:25:29.560]   Now he can reach people in those neighborhoods.
[01:25:29.560 --> 01:25:32.720]   And if he wants to go after young people who care about the climate, why not?
[01:25:32.720 --> 01:25:33.720]   Why can't he?
[01:25:33.720 --> 01:25:34.960]   Those are the people who are more likely to come out.
[01:25:34.960 --> 01:25:36.960]   That's exactly what the campaigns do anyway.
[01:25:36.960 --> 01:25:40.840]   And he can do it with incredible efficiency and expensive.
[01:25:40.840 --> 01:25:44.080]   And that, I think, is going to help democracy in the long run.
[01:25:44.080 --> 01:25:49.120]   Because we're going to have more people able to contribute and able to participate in ways
[01:25:49.120 --> 01:25:54.320]   that they were cut off from before because either editors or budgets kept them from doing
[01:25:54.320 --> 01:25:55.320]   it.
[01:25:55.320 --> 01:26:01.960]   >> Right, except in this case, we have thousands of editors, more if you include algorithms.
[01:26:01.960 --> 01:26:06.200]   We just don't know who they are or what principles they operate on.
[01:26:06.200 --> 01:26:08.120]   It's a giant black box.
[01:26:08.120 --> 01:26:09.120]   So war.
[01:26:09.120 --> 01:26:11.680]   >> So was every news reporter.
[01:26:11.680 --> 01:26:19.520]   >> Come on, we did so much less a black box than any other advertising method in the world.
[01:26:19.520 --> 01:26:20.800]   >> I think that's an illusion.
[01:26:20.800 --> 01:26:26.440]   You see the outside of the box and there are little pictures of levers on it and then you
[01:26:26.440 --> 01:26:27.800]   click the pictures.
[01:26:27.800 --> 01:26:30.040]   But we have no idea what happens after that.
[01:26:30.040 --> 01:26:34.800]   >> I have no idea what happens if I put an ad on TV.
[01:26:34.800 --> 01:26:35.800]   That's for sure.
[01:26:35.800 --> 01:26:41.040]   >> Right, but everybody admits that they don't understand what happens after that.
[01:26:41.040 --> 01:26:42.040]   Facebook?
[01:26:42.040 --> 01:26:43.040]   >> How is that better?
[01:26:43.040 --> 01:26:44.040]   >> Facebook?
[01:26:44.040 --> 01:26:48.520]   So the way the TV broadcast is not controlled by an algorithm.
[01:26:48.520 --> 01:26:54.520]   It's controlled by a bunch of idiots at some network TV headquarters.
[01:26:54.520 --> 01:27:02.680]   My point is there is a sophisticated software intelligence that Facebook put together that
[01:27:02.680 --> 01:27:06.800]   is controlling those things that you just described and we don't know anything about
[01:27:06.800 --> 01:27:08.840]   it and how it operates.
[01:27:08.840 --> 01:27:13.680]   We're just basically taking it on faith that when we click a picture of an option on the
[01:27:13.680 --> 01:27:18.720]   outside of the box, that it will do what it says on the box.
[01:27:18.720 --> 01:27:20.680]   So that concerns me.
[01:27:20.680 --> 01:27:25.840]   >> All right, we've got some reason.
[01:27:25.840 --> 01:27:29.640]   >> I've been staying out of the way of this one.
[01:27:29.640 --> 01:27:39.960]   >> Ducking the ball going back and forth, trying to bob and weave.
[01:27:39.960 --> 01:27:45.280]   Where I stand is I'm just utterly confused when it comes to this topic because I identify
[01:27:45.280 --> 01:27:46.520]   on both sides.
[01:27:46.520 --> 01:27:53.800]   Like on one hand, I completely agree with you, Jeff, that there is such a thing as having
[01:27:53.800 --> 01:27:57.440]   the ability to exercise free speech.
[01:27:57.440 --> 01:28:02.160]   On the other hand, I agree with what Matthew is saying, that the scale and the control
[01:28:02.160 --> 01:28:10.760]   of a single company having access and such influence over such a wide range of communication
[01:28:10.760 --> 01:28:17.320]   throughout humanity, throughout the technology infused humanity that we live in today.
[01:28:17.320 --> 01:28:18.600]   I get confused by it.
[01:28:18.600 --> 01:28:20.960]   Like honestly, I get overwhelmed by it because I see-
[01:28:20.960 --> 01:28:22.960]   >> I think we have less control.
[01:28:22.960 --> 01:28:23.960]   >> What's that?
[01:28:23.960 --> 01:28:24.960]   >> I understand that argument.
[01:28:24.960 --> 01:28:30.280]   But there are far more voices that could ever before could get in.
[01:28:30.280 --> 01:28:33.200]   So even though it's, yes, it's going through a few companies now, for now, I don't think
[01:28:33.200 --> 01:28:36.800]   that's going to last.
[01:28:36.800 --> 01:28:38.680]   There's more voices that we could ever have.
[01:28:38.680 --> 01:28:43.280]   So there's less control than we had in the days of Matthews and my business in newspapers
[01:28:43.280 --> 01:28:47.600]   where you had one or two newspapers in a town.
[01:28:47.600 --> 01:28:48.600]   >> And I agree.
[01:28:48.600 --> 01:28:53.280]   So there's more people inside the giant shopping mall that Facebook controls.
[01:28:53.280 --> 01:28:56.560]   And they let you put up posters outside the crazy freezer, whatever.
[01:28:56.560 --> 01:28:59.960]   And you think that constitutes freedom of communication?
[01:28:59.960 --> 01:29:02.600]   >> I think it's a lot better than what we had before, yes.
[01:29:02.600 --> 01:29:03.760]   And I think that it's not forever.
[01:29:03.760 --> 01:29:05.600]   And I think it's not forever.
[01:29:05.600 --> 01:29:09.560]   So the other thing is, I think that the internet right now is at a stage, I'm about to write
[01:29:09.560 --> 01:29:13.480]   a post, I haven't written yet, but I'll give you a preview.
[01:29:13.480 --> 01:29:18.360]   The internet has been written so far as all about speaking, not about listening.
[01:29:18.360 --> 01:29:21.280]   The internet is about the freedom of speech that everybody can speak.
[01:29:21.280 --> 01:29:29.080]   And the next phase we need in this net is one of judgment selection, expertise, authority,
[01:29:29.080 --> 01:29:30.640]   and so on.
[01:29:30.640 --> 01:29:34.920]   And I don't remember the name of Samir Aurora, do you remember that name, Matthew?
[01:29:34.920 --> 01:29:41.360]   He was the CEO of Glam, which was a big blog network back in the morning.
[01:29:41.360 --> 01:29:45.120]   So Samir has a new company that he's talked about, hardly at all, we're going to write
[01:29:45.120 --> 01:29:47.520]   about soon, called Sage.
[01:29:47.520 --> 01:29:49.600]   And it's not really up yet.
[01:29:49.600 --> 01:29:51.600]   But it's an expert network.
[01:29:51.600 --> 01:29:56.480]   What Samir found was that he could take 100 experts and have them pick experts and he
[01:29:56.480 --> 01:30:01.400]   gets to 1,000 experts, and then the AI learns what they're doing, and they can get to 2,500
[01:30:01.400 --> 01:30:02.400]   experts.
[01:30:02.400 --> 01:30:06.840]   The first topic he's tackling is just travel, destinations, because that's a very finite
[01:30:06.840 --> 01:30:07.840]   thing.
[01:30:07.840 --> 01:30:12.160]   He's not doing something complex like news, politics.
[01:30:12.160 --> 01:30:16.840]   But in that area, then he can find out who he has credibility and who does not, and has
[01:30:16.840 --> 01:30:22.280]   a whole way to make that judgment so that you can come in and find an expert in sushi,
[01:30:22.280 --> 01:30:29.600]   or find an expert in keto in Tokyo, and start to understand that level of expertise around
[01:30:29.600 --> 01:30:30.600]   that.
[01:30:30.600 --> 01:30:33.480]   So I think we're going to find ourselves in new structures.
[01:30:33.480 --> 01:30:38.440]   What Twitter and Facebook and the web have allowed is everyone to speak, and as you can
[01:30:38.440 --> 01:30:40.400]   hear, I celebrate that.
[01:30:40.400 --> 01:30:44.000]   But it's messy, and it's not as useful as we want it to be.
[01:30:44.000 --> 01:30:48.640]   It's not the Yahoo days of, "Hey, we have five new sites on the web today.
[01:30:48.640 --> 01:30:49.640]   Here they are."
[01:30:49.640 --> 01:30:52.480]   So it's gotten so huge that we can't deal with it.
[01:30:52.480 --> 01:30:55.760]   And I think we're going to start to experiment more and more and more with systems of quality.
[01:30:55.760 --> 01:30:59.920]   Now the problem with that is that's going to be exclusionary again.
[01:30:59.920 --> 01:31:00.920]   What's the black box there?
[01:31:00.920 --> 01:31:02.960]   There's going to be all kinds of problems there.
[01:31:02.960 --> 01:31:06.440]   But there's a flight to quality we're dying for here.
[01:31:06.440 --> 01:31:10.560]   And the way we're approaching that now is by trying to tamp down the crap.
[01:31:10.560 --> 01:31:17.040]   What we should be trying to do is find and define and highlight quality.
[01:31:17.040 --> 01:31:18.040]   But we'll see.
[01:31:18.040 --> 01:31:19.040]   It's Fais.
[01:31:19.040 --> 01:31:22.120]   I'm fond of saying it's 1475 in Gutenberg years.
[01:31:22.120 --> 01:31:24.400]   It's early days, folks.
[01:31:24.400 --> 01:31:25.560]   Early days.
[01:31:25.560 --> 01:31:30.640]   I think it's easy for me to get overwhelmed and confused through all of this because of
[01:31:30.640 --> 01:31:36.240]   all the changes that we've seen, even in the past couple of years, it's, I'm sure you
[01:31:36.240 --> 01:31:40.160]   would all agree, it's dizzying how quickly things are moving right now.
[01:31:40.160 --> 01:31:43.040]   And how chaotic it all feels.
[01:31:43.040 --> 01:31:47.240]   I would hope to have some sort of assurance, even though I know that's impossible, some
[01:31:47.240 --> 01:31:52.640]   sort of assurance, Jeff, that if what you're saying is true, that five years down the line
[01:31:52.640 --> 01:31:57.680]   or however long it takes to get to this place where, hey, that was the painful part and
[01:31:57.680 --> 01:31:58.680]   now we're to this.
[01:31:58.680 --> 01:31:59.680]   Sorry, bud.
[01:31:59.680 --> 01:32:00.680]   You know what I mean?
[01:32:00.680 --> 01:32:01.680]   Like there are no assurances.
[01:32:01.680 --> 01:32:02.680]   Nope.
[01:32:02.680 --> 01:32:03.680]   Nope.
[01:32:03.680 --> 01:32:06.720]   I think that's what holds people back to kind of truly buying.
[01:32:06.720 --> 01:32:11.920]   You know what was between the invention of printing and today?
[01:32:11.920 --> 01:32:13.960]   The 30 years war.
[01:32:13.960 --> 01:32:14.960]   Yeah.
[01:32:14.960 --> 01:32:15.960]   Right.
[01:32:15.960 --> 01:32:17.600]   Right.
[01:32:17.600 --> 01:32:22.600]   And much more and peasants wars and the reformation and all kinds of stuff.
[01:32:22.600 --> 01:32:25.600]   We're going to go through huge and painful disruption.
[01:32:25.600 --> 01:32:31.160]   I think it's just inevitable that we'll have that, but we have choices now.
[01:32:31.160 --> 01:32:33.960]   So we've got to try to inform those choices.
[01:32:33.960 --> 01:32:37.920]   And my problem with regulation in Europe is that it presumes that the Internet has done
[01:32:37.920 --> 01:32:42.640]   and it ain't by a long shot.
[01:32:42.640 --> 01:32:45.520]   So no, I have no comfort for you at all, Jason.
[01:32:45.520 --> 01:32:51.320]   They hide in a dog house somewhere because it's going to get worse.
[01:32:51.320 --> 01:32:52.960]   All right.
[01:32:52.960 --> 01:32:55.120]   Well, that's optimistic.
[01:32:55.120 --> 01:32:58.120]   The Google change log.
[01:32:58.120 --> 01:33:00.080]   Oh, I'm awake.
[01:33:00.080 --> 01:33:02.600]   I'm awake again.
[01:33:02.600 --> 01:33:03.600]   I'm ready.
[01:33:03.600 --> 01:33:04.600]   Let's do this.
[01:33:04.600 --> 01:33:07.320]   It's time for the Google change log.
[01:33:07.320 --> 01:33:08.320]   Thank you, Carson.
[01:33:08.320 --> 01:33:09.320]   Bravo.
[01:33:09.320 --> 01:33:14.360]   Carson, they're with the horns to wake us up and cheer us up a little bit.
[01:33:14.360 --> 01:33:16.360]   That was a doozy right there.
[01:33:16.360 --> 01:33:17.360]   All right.
[01:33:17.360 --> 01:33:20.600]   So what things are happening in the world of Google that has nothing to do with what
[01:33:20.600 --> 01:33:21.600]   we're just talking about.
[01:33:21.600 --> 01:33:23.880]   New travel search features.
[01:33:23.880 --> 01:33:27.320]   Aren't you excited to hear about this?
[01:33:27.320 --> 01:33:31.040]   New travel search features are released today.
[01:33:31.040 --> 01:33:35.660]   See within search, something called when to visit a feature that shows peak traveling
[01:33:35.660 --> 01:33:41.600]   season in a location that might be searching for cost for travel in those peak seasons.
[01:33:41.600 --> 01:33:46.480]   This is such a change of pace from where we were 60 seconds ago.
[01:33:46.480 --> 01:33:55.160]   Also where to stay featured shows best places to stay, what their close to average cost
[01:33:55.160 --> 01:33:56.160]   of a hotel there.
[01:33:56.160 --> 01:33:57.600]   I'm the optimist.
[01:33:57.600 --> 01:33:59.560]   And personalized hotel recommendations.
[01:33:59.560 --> 01:34:00.560]   Are you?
[01:34:00.560 --> 01:34:01.560]   Yeah.
[01:34:01.560 --> 01:34:05.200]   So there you go.
[01:34:05.200 --> 01:34:07.160]   Travel features to look forward to.
[01:34:07.160 --> 01:34:13.760]   Or maybe you're really interested in AI development with Google.
[01:34:13.760 --> 01:34:19.120]   If so, you might be interested in some new features with the coral hardware kits for
[01:34:19.120 --> 01:34:20.600]   AI development.
[01:34:20.600 --> 01:34:22.400]   Coral accelerator module.
[01:34:22.400 --> 01:34:26.080]   Here's a bunch of things I don't quite understand because I'm not developing these things, but
[01:34:26.080 --> 01:34:31.520]   multi-chip package with custom edge TPU and PCI and USB interfaces, shipping Q1 and Q2
[01:34:31.520 --> 01:34:32.920]   in 2020.
[01:34:32.920 --> 01:34:36.720]   Also the coral dev board mini which is just tensor on a chip.
[01:34:36.720 --> 01:34:37.720]   Yes.
[01:34:37.720 --> 01:34:38.720]   Yes.
[01:34:38.720 --> 01:34:40.520]   Tensor processing units on a chip.
[01:34:40.520 --> 01:34:47.120]   Small low power, low cost alternative to the coral dev board with MediaTek 8167S system
[01:34:47.120 --> 01:34:51.520]   on a chip and coral accelerator module.
[01:34:51.520 --> 01:34:52.520]   That's the first time.
[01:34:52.520 --> 01:34:53.920]   Do you understand what you just said?
[01:34:53.920 --> 01:34:54.920]   No.
[01:34:54.920 --> 01:35:00.240]   But aren't those specs sexy?
[01:35:00.240 --> 01:35:03.360]   Thank you for admitting it.
[01:35:03.360 --> 01:35:06.680]   Sometimes it is right down the specs and hope that the right person hears it and goes,
[01:35:06.680 --> 01:35:08.560]   "Oh, okay, I care about that."
[01:35:08.560 --> 01:35:09.560]   Stacy will be back.
[01:35:09.560 --> 01:35:10.560]   Yes, exactly.
[01:35:10.560 --> 01:35:12.560]   If Stacy was here, she'd care.
[01:35:12.560 --> 01:35:14.240]   She'd tell all of us what that all means.
[01:35:14.240 --> 01:35:18.600]   Put this on the hold so we can get Stacy to explain it.
[01:35:18.600 --> 01:35:22.960]   If you happen to order a pixel slate, this is totally more in my wheelhouse.
[01:35:22.960 --> 01:35:27.240]   If you ordered a pixel slate on Black Friday, you may be wondering, "Why don't I have that
[01:35:27.240 --> 01:35:29.760]   pixel slate I ordered on Black Friday?"
[01:35:29.760 --> 01:35:34.880]   Well, apparently they've all been really delayed and you're not alone.
[01:35:34.880 --> 01:35:35.880]   Many people have been affected by it.
[01:35:35.880 --> 01:35:36.880]   They'll work.
[01:35:36.880 --> 01:35:37.880]   Yeah.
[01:35:37.880 --> 01:35:41.800]   So much so that Google says they sold too many compared to their stock.
[01:35:41.800 --> 01:35:44.360]   That's been the reason for the delay.
[01:35:44.360 --> 01:35:50.680]   Now they say they should start shipping mid-January, so mid-month, probably not more than a week
[01:35:50.680 --> 01:35:52.440]   from now, hopefully.
[01:35:52.440 --> 01:35:55.000]   They will include a $50 appeasement.
[01:35:55.000 --> 01:35:56.000]   So you get a--
[01:35:56.000 --> 01:35:58.360]   Which, by the way, by the way, I read that.
[01:35:58.360 --> 01:36:01.120]   Isn't that a weird appeasement?
[01:36:01.120 --> 01:36:03.320]   Brazed to give to consumers.
[01:36:03.320 --> 01:36:05.320]   Yeah, appeasement is a little strange.
[01:36:05.320 --> 01:36:06.320]   Appeasement payment.
[01:36:06.320 --> 01:36:07.800]   Appeasement payment.
[01:36:07.800 --> 01:36:13.960]   We want to appease you here, have $50 to spend in our store.
[01:36:13.960 --> 01:36:18.400]   So look for that if you want the slate.
[01:36:18.400 --> 01:36:23.760]   Climacel is apparently partnering with Google Cloud to launch new high-resolution forecasting
[01:36:23.760 --> 01:36:31.400]   models for weather data, a model with forecasting over 48 hours, resolution of 2 kilometers,
[01:36:31.400 --> 01:36:36.440]   15-minute time stamps, and it will serve as the foundation for weather products from
[01:36:36.440 --> 01:36:42.160]   Climacel that actually do things like predict floods, air quality, all that kind of stuff.
[01:36:42.160 --> 01:36:46.760]   And apparently they're making the data sets publicly available for anyone to use.
[01:36:46.760 --> 01:36:52.040]   So that could be handy to all five of you.
[01:36:52.040 --> 01:36:57.640]   Google Play Movies and TV is going to gain support for HDR10+ in 2020.
[01:36:57.640 --> 01:37:00.720]   This according to Samsung at CES.
[01:37:00.720 --> 01:37:03.040]   So Samsung apparently made this announcement.
[01:37:03.040 --> 01:37:07.680]   I think it was in connection with some of their TVs that have this feature.
[01:37:07.680 --> 01:37:11.400]   Samsung is behind the HDR10+ standard.
[01:37:11.400 --> 01:37:14.200]   Oh, well then that makes more sense, even.
[01:37:14.200 --> 01:37:19.480]   So basically this is how to do HDR without paying Dolby a whole bunch of money.
[01:37:19.480 --> 01:37:20.480]   Got it.
[01:37:20.480 --> 01:37:25.680]   Alright, and that makes a lot more sense why Samsung would be the ones to make this announcement.
[01:37:25.680 --> 01:37:27.280]   I was like, why wouldn't that come from Google?
[01:37:27.280 --> 01:37:29.120]   But there you go.
[01:37:29.120 --> 01:37:36.920]   And finally Google is testing the ability for searchers to add comments to query results
[01:37:36.920 --> 01:37:38.520]   that are related to TV shows.
[01:37:38.520 --> 01:37:43.200]   So if you go online and you do a search for the bachelor while the bachelor's playing,
[01:37:43.200 --> 01:37:48.280]   you have the ability to drop comments in real time with other people who are doing the same.
[01:37:48.280 --> 01:37:55.360]   So it's almost like Twitter, a Twitter conversation in real time during a live event.
[01:37:55.360 --> 01:37:56.360]   So that's kind of...
[01:37:56.360 --> 01:37:57.360]   Through search, which is what's weird.
[01:37:57.360 --> 01:37:58.360]   Yeah, kind of neat.
[01:37:58.360 --> 01:37:59.360]   For sure.
[01:37:59.360 --> 01:38:00.360]   That will go well.
[01:38:00.360 --> 01:38:02.760]   97th effort from Google to get social.
[01:38:02.760 --> 01:38:05.120]   Yeah, exactly.
[01:38:05.120 --> 01:38:06.120]   Very disconnected.
[01:38:06.120 --> 01:38:07.120]   I don't know.
[01:38:07.120 --> 01:38:09.440]   I find that very strange for some reason they're doing that.
[01:38:09.440 --> 01:38:10.440]   One that didn't make it in there.
[01:38:10.440 --> 01:38:14.400]   And thank you to ScooterX for putting this in the chat room.
[01:38:14.400 --> 01:38:19.960]   The January security patch for Pixel devices is rolling out.
[01:38:19.960 --> 01:38:23.160]   If you haven't got it already, I think it started yesterday.
[01:38:23.160 --> 01:38:25.280]   Factory images are posted.
[01:38:25.280 --> 01:38:26.960]   The OTAs are live.
[01:38:26.960 --> 01:38:33.320]   So if you like security and you like updates on your Pixel, then you'll love this update.
[01:38:33.320 --> 01:38:36.120]   And that's the Google change log.
[01:38:36.120 --> 01:38:41.120]   And some...
[01:38:41.120 --> 01:38:42.120]   I heard the buttons.
[01:38:42.120 --> 01:38:43.120]   You did.
[01:38:43.120 --> 01:38:44.120]   Those buttons were loud.
[01:38:44.120 --> 01:38:45.120]   I heard the buttons.
[01:38:45.120 --> 01:38:46.120]   It sounded like a guitar.
[01:38:46.120 --> 01:38:47.120]   It's like a guitar.
[01:38:47.120 --> 01:38:48.120]   It's like a guitar.
[01:38:48.120 --> 01:38:50.120]   You hear the fingers moving on the fret.
[01:38:50.120 --> 01:38:51.120]   Totally.
[01:38:51.120 --> 01:38:53.280]   You hear what's going on behind the artistry.
[01:38:53.280 --> 01:38:58.640]   Speaking of Pixel real quick here, there was a leak.
[01:38:58.640 --> 01:39:01.920]   Well a few little bits and pieces before we get into, because I know we need to move
[01:39:01.920 --> 01:39:02.920]   on.
[01:39:02.920 --> 01:39:08.960]   But Pixel 4A, apparently some case renders have leaked on this.
[01:39:08.960 --> 01:39:09.960]   So if you...
[01:39:09.960 --> 01:39:13.920]   And I mentioned this because Carson, I know how much of a fanboy you are of the Pixel
[01:39:13.920 --> 01:39:14.920]   3A.
[01:39:14.920 --> 01:39:15.920]   So nice.
[01:39:15.920 --> 01:39:16.920]   B2.
[01:39:16.920 --> 01:39:17.920]   The rumors.
[01:39:17.920 --> 01:39:18.920]   And is that your phone right now, Jeff?
[01:39:18.920 --> 01:39:19.920]   Oh yeah, I love it.
[01:39:19.920 --> 01:39:20.920]   Okay, awesome.
[01:39:20.920 --> 01:39:21.920]   Yeah, it is a first chance.
[01:39:21.920 --> 01:39:24.160]   Is this something we agree about?
[01:39:24.160 --> 01:39:25.160]   Absolutely.
[01:39:25.160 --> 01:39:26.960]   I bought it for my whole family.
[01:39:26.960 --> 01:39:27.960]   This is...
[01:39:27.960 --> 01:39:28.960]   I'm going to throw mine out now.
[01:39:28.960 --> 01:39:29.960]   Jesus.
[01:39:29.960 --> 01:39:31.600]   Don't.
[01:39:31.600 --> 01:39:32.600]   Not yet at least.
[01:39:32.600 --> 01:39:34.640]   Let's throw it out until at least Google I/O.
[01:39:34.640 --> 01:39:37.960]   Because then you can replace it with a 4A, probably.
[01:39:37.960 --> 01:39:40.800]   There's not going to be an XL version according to rumors.
[01:39:40.800 --> 01:39:42.520]   It's just going to be one size.
[01:39:42.520 --> 01:39:43.520]   Oh, that's what we need.
[01:39:43.520 --> 01:39:44.520]   Yeah, kind of a bummer.
[01:39:44.520 --> 01:39:45.520]   You'd be getting the smaller size.
[01:39:45.520 --> 01:39:46.520]   I like your style.
[01:39:46.520 --> 01:39:47.520]   Because I'm a big guy.
[01:39:47.520 --> 01:39:48.520]   Well, big guy.
[01:39:48.520 --> 01:39:50.320]   Now take a look at this and you'll see...
[01:39:50.320 --> 01:39:51.760]   One of you buy Carson for everybody.
[01:39:51.760 --> 01:39:53.320]   Did you buy the XL or do you bought the...
[01:39:53.320 --> 01:39:55.040]   I bought the XL, yes.
[01:39:55.040 --> 01:39:56.040]   Oh, okay.
[01:39:56.040 --> 01:39:57.040]   Okay.
[01:39:57.040 --> 01:39:58.040]   Good boy.
[01:39:58.040 --> 01:40:02.240]   Take a look at the back and you'll notice that the Pixel 4 signature square camera module
[01:40:02.240 --> 01:40:08.320]   area is still there, except that it only has one camera, which makes sense of the 3A
[01:40:08.320 --> 01:40:11.360]   only had one camera, of course.
[01:40:11.360 --> 01:40:15.280]   The 4A will still have one camera if these renders are to be believed.
[01:40:15.280 --> 01:40:16.280]   It's just...
[01:40:16.280 --> 01:40:17.280]   And the fingerprint sensor.
[01:40:17.280 --> 01:40:18.280]   And the fingerprint sensor.
[01:40:18.280 --> 01:40:20.280]   The damn face thing.
[01:40:20.280 --> 01:40:21.280]   Yeah.
[01:40:21.280 --> 01:40:22.280]   Yeah.
[01:40:22.280 --> 01:40:25.240]   But I just feel like that square module just looks a little strange.
[01:40:25.240 --> 01:40:26.240]   It looks a little...
[01:40:26.240 --> 01:40:27.240]   And look there.
[01:40:27.240 --> 01:40:28.240]   Look.
[01:40:28.240 --> 01:40:29.240]   And I had phone...
[01:40:29.240 --> 01:40:30.240]   It's so nice.
[01:40:30.240 --> 01:40:31.240]   Yeah.
[01:40:31.240 --> 01:40:35.840]   Carson, I fear these are the pixels for old farts and you're now officially at old farts.
[01:40:35.840 --> 01:40:37.840]   Oh, absolutely.
[01:40:37.840 --> 01:40:38.840]   Absolutely.
[01:40:38.840 --> 01:40:39.840]   No doubt about that.
[01:40:39.840 --> 01:40:41.400]   Look, the 3A was a great phone.
[01:40:41.400 --> 01:40:44.400]   It was probably a great phone of last year.
[01:40:44.400 --> 01:40:46.920]   What's the price of a 3A?
[01:40:46.920 --> 01:40:47.920]   Well, 300.
[01:40:47.920 --> 01:40:49.920]   Is it 300 or 400?
[01:40:49.920 --> 01:40:50.920]   Wow.
[01:40:50.920 --> 01:40:52.640]   400, but I mean you can get it cheaper than that.
[01:40:52.640 --> 01:40:55.200]   You can get it in the 200s if you get it on sale.
[01:40:55.200 --> 01:40:56.200]   Wow.
[01:40:56.200 --> 01:40:58.320]   I was seeing it pretty low for the holiday season.
[01:40:58.320 --> 01:41:04.400]   Yeah, it was 280 when I bought it for life and sun.
[01:41:04.400 --> 01:41:05.560]   And I mean so worth it.
[01:41:05.560 --> 01:41:10.560]   I mean worth it arguably at $400 but incredibly worth it at 280.
[01:41:10.560 --> 01:41:14.000]   I'll be curious to see what they priced the 4A.
[01:41:14.000 --> 01:41:15.760]   Hopefully they keep it at that $400 range.
[01:41:15.760 --> 01:41:18.120]   I think that would be important.
[01:41:18.120 --> 01:41:21.320]   There will also be a Samsung unpacked event that happens.
[01:41:21.320 --> 01:41:24.200]   They've announced that February 11th, 11 a.m.
[01:41:24.200 --> 01:41:28.280]   That's where they're going to unveil or expected to unveil the Samsung Galaxy S11.
[01:41:28.280 --> 01:41:32.360]   Or supposedly the S11 is not going to be the name of it.
[01:41:32.360 --> 01:41:34.720]   It's going to be the S20.
[01:41:34.720 --> 01:41:37.800]   Some leakers have said that's going to happen.
[01:41:37.800 --> 01:41:38.800]   So...
[01:41:38.800 --> 01:41:39.800]   Because it's 2020?
[01:41:39.800 --> 01:41:40.800]   I guess so.
[01:41:40.800 --> 01:41:42.800]   Yes, I am so in favor of this.
[01:41:42.800 --> 01:41:44.560]   It's not a lot.
[01:41:44.560 --> 01:41:50.880]   So you can just have the 20 galaxy, the 21 galaxy.
[01:41:50.880 --> 01:41:51.880]   Oh, okay.
[01:41:51.880 --> 01:41:52.880]   So that would be, yeah.
[01:41:52.880 --> 01:41:54.560]   It's like the 20 Buick.
[01:41:54.560 --> 01:41:55.560]   Yeah.
[01:41:55.560 --> 01:41:56.560]   Yes, exactly.
[01:41:56.560 --> 01:41:57.560]   Okay.
[01:41:57.560 --> 01:41:58.560]   Sure.
[01:41:58.560 --> 01:41:59.560]   I can get behind that.
[01:41:59.560 --> 01:42:03.200]   They might also possibly show off the next fold.
[01:42:03.200 --> 01:42:04.920]   And we will be doing coverage of that.
[01:42:04.920 --> 01:42:07.720]   Leo and I know are guaranteed to be on set for that.
[01:42:07.720 --> 01:42:09.800]   Where is it being held in New York?
[01:42:09.800 --> 01:42:12.200]   San Francisco, I believe.
[01:42:12.200 --> 01:42:13.200]   Yes.
[01:42:13.200 --> 01:42:15.760]   Yes, you are correct.
[01:42:15.760 --> 01:42:18.880]   You are correct, sir.
[01:42:18.880 --> 01:42:19.880]   Anything else?
[01:42:19.880 --> 01:42:20.880]   Anything that we've missed?
[01:42:20.880 --> 01:42:21.880]   Oh, yeah.
[01:42:21.880 --> 01:42:24.520]   This is for red photos.
[01:42:24.520 --> 01:42:25.520]   Okay.
[01:42:25.520 --> 01:42:26.520]   Yeah.
[01:42:26.520 --> 01:42:28.520]   I could show the software.
[01:42:28.520 --> 01:42:29.520]   That's pretty weird.
[01:42:29.520 --> 01:42:30.520]   Show the software.
[01:42:30.520 --> 01:42:31.520]   Wait, what?
[01:42:31.520 --> 01:42:34.840]   There is an infrared camera on the Pixel 4, right?
[01:42:34.840 --> 01:42:37.640]   That's how you do the fingers, the face scanning.
[01:42:37.640 --> 01:42:42.080]   So if you go, I don't know if you still have, if you have my overhead, we didn't set it
[01:42:42.080 --> 01:42:46.160]   up prior to the show, but it's probably already set up for our last nights, all about
[01:42:46.160 --> 01:42:47.160]   Android.
[01:42:47.160 --> 01:42:49.160]   But there is an app called Hedge Camera.
[01:42:49.160 --> 01:42:50.160]   There you go.
[01:42:50.160 --> 01:42:51.160]   Let's see here.
[01:42:51.160 --> 01:42:52.160]   Oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh, oh,
[01:42:52.160 --> 01:42:53.160]   there we go.
[01:42:53.160 --> 01:42:54.160]   There we go.
[01:42:54.160 --> 01:42:55.160]   That's a better shot.
[01:42:55.160 --> 01:42:56.160]   Hedge Camera.
[01:42:56.160 --> 01:42:57.160]   There we go.
[01:42:57.160 --> 01:42:58.960]   I've got my infrared shot.
[01:42:58.960 --> 01:42:59.960]   Okay.
[01:42:59.960 --> 01:43:02.480]   Jeremy, turn off all the lights in the studio.
[01:43:02.480 --> 01:43:03.480]   Okay.
[01:43:03.480 --> 01:43:04.720]   So let's see what happens.
[01:43:04.720 --> 01:43:05.720]   Oh, he did.
[01:43:05.720 --> 01:43:06.720]   Hi.
[01:43:06.720 --> 01:43:07.720]   How's it going?
[01:43:07.720 --> 01:43:08.720]   I'm in the black hole.
[01:43:08.720 --> 01:43:09.720]   Oh, cool.
[01:43:09.720 --> 01:43:13.520]   A crisp and clear VGA quality video.
[01:43:13.520 --> 01:43:17.800]   So yeah, if you want to do that, now you can.
[01:43:17.800 --> 01:43:23.040]   I don't know why you want to do that, but you can.
[01:43:23.040 --> 01:43:24.800]   Is it now completely dark in the studio?
[01:43:24.800 --> 01:43:25.800]   Yeah.
[01:43:25.800 --> 01:43:26.800]   Oh, it's very twilight.
[01:43:26.800 --> 01:43:27.800]   Yeah.
[01:43:27.800 --> 01:43:28.800]   Oh, I like that.
[01:43:28.800 --> 01:43:29.800]   Oh, it's mystery.
[01:43:29.800 --> 01:43:30.800]   Mystery host.
[01:43:30.800 --> 01:43:31.800]   That's right.
[01:43:31.800 --> 01:43:33.800]   Matthew, you and I stand out now.
[01:43:33.800 --> 01:43:35.400]   Yeah, sure do.
[01:43:35.400 --> 01:43:37.800]   I could take an image.
[01:43:37.800 --> 01:43:39.320]   Yeah, there we go.
[01:43:39.320 --> 01:43:42.520]   I'll replace myself with my infrared shot.
[01:43:42.520 --> 01:43:49.080]   So that's perfect if you want to do a show about haunted houses or something and creepy
[01:43:49.080 --> 01:43:50.080]   like that.
[01:43:50.080 --> 01:43:51.080]   Or privacy.
[01:43:51.080 --> 01:43:52.080]   Let's do that.
[01:43:52.080 --> 01:43:53.080]   That's a haunted house.
[01:43:53.080 --> 01:43:54.080]   It doesn't want to be known.
[01:43:54.080 --> 01:43:58.680]   Yeah, we've got haunted house expert, Karsten on the line.
[01:43:58.680 --> 01:44:01.840]   He builds them every year.
[01:44:01.840 --> 01:44:03.440]   You like to scare people, Karsten?
[01:44:03.440 --> 01:44:04.440]   Is that it?
[01:44:04.440 --> 01:44:05.440]   I like to entertain.
[01:44:05.440 --> 01:44:06.440]   I like to.
[01:44:06.440 --> 01:44:09.440]   You like to scare people.
[01:44:09.440 --> 01:44:10.880]   You like to scare people.
[01:44:10.880 --> 01:44:13.440]   You have something else in common with Jeff Jarvis.
[01:44:13.440 --> 01:44:14.440]   Hey, hey.
[01:44:14.440 --> 01:44:18.440]   Just scares people like the dentist.
[01:44:18.440 --> 01:44:19.440]   Right.
[01:44:19.440 --> 01:44:20.440]   All right.
[01:44:20.440 --> 01:44:21.440]   I think we're good.
[01:44:21.440 --> 01:44:26.440]   How's your cold hanging up there, fella?
[01:44:26.440 --> 01:44:30.440]   Well, my voice is getting a little crackly, but that's okay.
[01:44:30.440 --> 01:44:32.440]   You need a fisherman.
[01:44:32.440 --> 01:44:35.440]   Yes, except apparently I need one of those.
[01:44:35.440 --> 01:44:36.440]   Everybody needs.
[01:44:36.440 --> 01:44:39.440]   I learned that I needed one of those before the show today.
[01:44:39.440 --> 01:44:40.440]   I'd never heard of them.
[01:44:40.440 --> 01:44:41.440]   The fisherman's friends were very loyal.
[01:44:41.440 --> 01:44:42.440]   Never heard of fisherman's friends.
[01:44:42.440 --> 01:44:45.440]   They're all like fishermen need them specifically though.
[01:44:45.440 --> 01:44:46.440]   Yeah.
[01:44:46.440 --> 01:44:47.440]   Like, do they?
[01:44:47.440 --> 01:44:48.440]   Anyway.
[01:44:48.440 --> 01:44:50.440]   And if I'm not really a fisherman, so they don't know if I'm allowed.
[01:44:50.440 --> 01:44:53.440]   Well, there is one more California story.
[01:44:53.440 --> 01:44:54.440]   Okay.
[01:44:54.440 --> 01:44:58.160]   Well, I guess California and West Coast, not an East Coast story.
[01:44:58.160 --> 01:45:00.800]   And I never fully understood the phenomenon of this.
[01:45:00.800 --> 01:45:07.160]   I think it's because I wasn't there 20 years ago, but fries.
[01:45:07.160 --> 01:45:08.160]   Fries.
[01:45:08.160 --> 01:45:09.160]   Big deal.
[01:45:09.160 --> 01:45:11.400]   The question is, is fries in trouble?
[01:45:11.400 --> 01:45:13.720]   They lost their call about the lease.
[01:45:13.720 --> 01:45:15.440]   People are saying that the shelves are empty.
[01:45:15.440 --> 01:45:20.320]   Fries is saying, no, no, no, it's just because we changed our whole model to a cons-- to consign
[01:45:20.320 --> 01:45:21.320]   to the independent model.
[01:45:21.320 --> 01:45:23.320]   Because that works so well.
[01:45:23.320 --> 01:45:24.320]   Yeah.
[01:45:24.320 --> 01:45:25.320]   Exactly.
[01:45:25.320 --> 01:45:27.480]   And fries was worshiped.
[01:45:27.480 --> 01:45:30.600]   And I started going to California Tech days.
[01:45:30.600 --> 01:45:32.200]   I just-- I kind of understood it.
[01:45:32.200 --> 01:45:36.280]   If you were going to go in and make a board and get some resistors and capacitors and
[01:45:36.280 --> 01:45:39.000]   things, you could do it there.
[01:45:39.000 --> 01:45:40.760]   And I thought, I love this place.
[01:45:40.760 --> 01:45:44.920]   But I could never get-- once I was inside, I just kind of said, is there a there?
[01:45:44.920 --> 01:45:45.920]   Oh, is there a there?
[01:45:45.920 --> 01:45:46.920]   Fries was so wonderful.
[01:45:46.920 --> 01:45:47.920]   Okay.
[01:45:47.920 --> 01:45:49.920]   So we can wrap some eyes about fries for a minute.
[01:45:49.920 --> 01:45:53.200]   It's-- okay.
[01:45:53.200 --> 01:45:54.840]   Everyone's been to Radio Shack.
[01:45:54.840 --> 01:45:57.120]   Everyone knows Radio Shack.
[01:45:57.120 --> 01:46:10.560]   Imagine Radio Shack but like the size of a Walmart and just rows of boards and capacitors
[01:46:10.560 --> 01:46:13.160]   and things that--
[01:46:13.160 --> 01:46:18.560]   Yeah, and amps and things you don't even understand.
[01:46:18.560 --> 01:46:25.280]   And just being able to walk through and smell the electronics is just such a nice thing.
[01:46:25.280 --> 01:46:30.720]   There's nothing quite like the smell of transistors in the morning.
[01:46:30.720 --> 01:46:32.200]   Lyrical almost.
[01:46:32.200 --> 01:46:37.280]   Was it a good place to buy a laptop?
[01:46:37.280 --> 01:46:38.920]   I don't know.
[01:46:38.920 --> 01:46:41.320]   No, it's not a place for buying finished products.
[01:46:41.320 --> 01:46:42.720]   Maybe the build on laptops.
[01:46:42.720 --> 01:46:43.720]   It's-- yeah.
[01:46:43.720 --> 01:46:48.400]   It's a place-- if you want to build a computer, it was a place to--
[01:46:48.400 --> 01:46:51.400]   to buy the parts to build that computer.
[01:46:51.400 --> 01:46:57.280]   And in the day in Silicon Valley, if you were really cool and hip, right, that had some
[01:46:57.280 --> 01:46:58.280]   cred.
[01:46:58.280 --> 01:47:04.440]   Now, does anybody really build boards anymore?
[01:47:04.440 --> 01:47:08.480]   Well, gamers build game PCs but that's a pretty niche market.
[01:47:08.480 --> 01:47:09.480]   Yeah.
[01:47:09.480 --> 01:47:10.480]   Not as much--
[01:47:10.480 --> 01:47:18.360]   I mean, with the maker movement now, there's a lot of board building and buying of front
[01:47:18.360 --> 01:47:19.360]   products, but--
[01:47:19.360 --> 01:47:21.520]   Not enough to support huge storage levels.
[01:47:21.520 --> 01:47:26.000]   No, I mean, you get all that stuff from AliExpress now.
[01:47:26.000 --> 01:47:27.000]   So there's a point--
[01:47:27.000 --> 01:47:28.000]   Off, yeah.
[01:47:28.000 --> 01:47:29.000]   Right.
[01:47:29.000 --> 01:47:30.000]   Right.
[01:47:30.000 --> 01:47:32.640]   I've never set foot in a fries before.
[01:47:32.640 --> 01:47:33.640]   You haven't.
[01:47:33.640 --> 01:47:34.640]   No.
[01:47:34.640 --> 01:47:35.640]   I've lived out here.
[01:47:35.640 --> 01:47:36.640]   And you probably won't.
[01:47:36.640 --> 01:47:37.640]   Yeah, it sounds like it.
[01:47:37.640 --> 01:47:41.640]   Yeah, I mean, I've lived out here since '98, but I've never--
[01:47:41.640 --> 01:47:46.040]   I mean, moving through a consignment model is not a good sign.
[01:47:46.040 --> 01:47:47.040]   Let's put it that way.
[01:47:47.040 --> 01:47:48.040]   Yeah.
[01:47:48.040 --> 01:47:54.160]   So it makes those shelves look pretty empty, pretty sparse.
[01:47:54.160 --> 01:47:55.800]   So pour one out for the fries.
[01:47:55.800 --> 01:47:59.160]   They had an odd cowboy movement motif as well.
[01:47:59.160 --> 01:48:00.160]   Oh, really?
[01:48:00.160 --> 01:48:01.160]   No sense.
[01:48:01.160 --> 01:48:08.600]   Well, no, there are-- here, let me find the one in Burbank.
[01:48:08.600 --> 01:48:09.600]   This one, yes.
[01:48:09.600 --> 01:48:10.600]   Oh, that's nice.
[01:48:10.600 --> 01:48:17.440]   There are a bunch of fries that had weird art installation fronts.
[01:48:17.440 --> 01:48:22.520]   This was an alien crashed into it, and there was actually a UFO inside.
[01:48:22.520 --> 01:48:23.520]   That's awesome.
[01:48:23.520 --> 01:48:26.760]   And there are a bunch of other ones that--
[01:48:26.760 --> 01:48:27.760]   I see.
[01:48:27.760 --> 01:48:28.760]   That--
[01:48:28.760 --> 01:48:29.760]   Oh, wow.
[01:48:29.760 --> 01:48:30.760]   Oh, OK.
[01:48:30.760 --> 01:48:31.760]   Yes.
[01:48:31.760 --> 01:48:32.760]   All right, that's smart.
[01:48:32.760 --> 01:48:33.760]   Yeah.
[01:48:33.760 --> 01:48:34.760]   That's so geeky.
[01:48:34.760 --> 01:48:35.760]   Yeah.
[01:48:35.760 --> 01:48:36.760]   Love it.
[01:48:36.760 --> 01:48:39.680]   Well, I hope they put some money away for a rainy day.
[01:48:39.680 --> 01:48:40.680]   Yeah.
[01:48:40.680 --> 01:48:41.680]   Yes, indeed.
[01:48:41.680 --> 01:48:47.400]   All right, let's do some picks and numbers and stuffs and things and all that.
[01:48:47.400 --> 01:48:48.400]   Kind of stuff.
[01:48:48.400 --> 01:48:50.880]   Starting with you, Jeff, what do you got for your number?
[01:48:50.880 --> 01:48:54.360]   I think it's old news that Google's going to end the double Dutch Irish sandwich, so
[01:48:54.360 --> 01:48:56.800]   I went to that one.
[01:48:56.800 --> 01:49:00.640]   Twitter has a new portal for academic researchers, which I'll just mention.
[01:49:00.640 --> 01:49:06.080]   But the thing that kind of scared me as somebody who works at a university is that Americans
[01:49:06.080 --> 01:49:10.680]   rank a Google internship over a Harvard degree.
[01:49:10.680 --> 01:49:11.680]   Really?
[01:49:11.680 --> 01:49:17.360]   60% would recommend the Google internship over 40% for a Harvard degree.
[01:49:17.360 --> 01:49:23.440]   The question I had about this story is, is this the good forbs or the bad forbs?
[01:49:23.440 --> 01:49:25.200]   That's exactly what I was going to ask.
[01:49:25.200 --> 01:49:26.200]   Exactly.
[01:49:26.200 --> 01:49:27.880]   It's a contributor at Forbes, so who knows?
[01:49:27.880 --> 01:49:30.880]   And it's a survey that he led at Kaplan.
[01:49:30.880 --> 01:49:33.840]   Now, Kaplan, you know, he sized the company--
[01:49:33.840 --> 01:49:34.840]   He's pretty good.
[01:49:34.840 --> 01:49:38.560]   --based on a survey of 2,000 adults conducted in December by Quest.
[01:49:38.560 --> 01:49:39.560]   So that sounds OK.
[01:49:39.560 --> 01:49:43.200]   It sounds like he asked the question.
[01:49:43.200 --> 01:49:46.960]   There are very few believers in the work readiness of college graduates.
[01:49:46.960 --> 01:49:53.400]   Only 13% of adults and 11% of C-level executives and 6% of college and university of trustees
[01:49:53.400 --> 01:49:59.120]   strongly agree with the statements about the work readiness of graduates.
[01:49:59.120 --> 01:50:00.680]   That's scary in a couple of ways.
[01:50:00.680 --> 01:50:02.280]   One, just people won't go to college.
[01:50:02.280 --> 01:50:08.120]   But two, the reason we're in this mess is because people aren't educated.
[01:50:08.120 --> 01:50:12.640]   And the more cooties that education gets, the worse off it's going to be.
[01:50:12.640 --> 01:50:17.440]   That's the downward spiral we're on as we're losing the enlightenment.
[01:50:17.440 --> 01:50:21.800]   So that's why Cheery Optimistic Number of the Week.
[01:50:21.800 --> 01:50:25.280]   Well, I am uncheared.
[01:50:25.280 --> 01:50:32.240]   Yeah, I probably shouldn't say this, but it reminds me of how Ivanka Trump was on the
[01:50:32.240 --> 01:50:37.400]   stage at CES and made the comment that college is overrated.
[01:50:37.400 --> 01:50:38.400]   She did?
[01:50:38.400 --> 01:50:39.400]   She mentioned that.
[01:50:39.400 --> 01:50:48.000]   I will say I have talked to lots of well-educated people with professional backgrounds who voted
[01:50:48.000 --> 01:50:50.960]   for Trump and believe all sorts of ridiculous things.
[01:50:50.960 --> 01:50:56.000]   So I don't think education is a cure.
[01:50:56.000 --> 01:50:57.000]   Yeah.
[01:50:57.000 --> 01:50:58.000]   Yeah.
[01:50:58.000 --> 01:51:01.200]   Oh, well, that's a point.
[01:51:01.200 --> 01:51:03.200]   What stuff you got, Matthew?
[01:51:03.200 --> 01:51:05.040]   What's in your stuff?
[01:51:05.040 --> 01:51:06.040]   Let's see.
[01:51:06.040 --> 01:51:08.560]   What do I have?
[01:51:08.560 --> 01:51:13.400]   I did notice Twitter announced something they're changing.
[01:51:13.400 --> 01:51:19.800]   They say they're going to add some changes to the way you can sort of restrict participants
[01:51:19.800 --> 01:51:20.880]   in a conversation.
[01:51:20.880 --> 01:51:28.600]   So when you create a tweet, you'll be able to select whether you want it to go to everyone,
[01:51:28.600 --> 01:51:32.880]   whether you want everyone to be able to reply, whether you want only the people you mentioned
[01:51:32.880 --> 01:51:37.200]   in the tweet to be able to reply, or whether you actually don't want anybody to reply.
[01:51:37.200 --> 01:51:39.160]   And it's just a statement that you're posting.
[01:51:39.160 --> 01:51:42.440]   So that'll be interesting to see if they actually do do it.
[01:51:42.440 --> 01:51:44.080]   What do you think of that?
[01:51:44.080 --> 01:51:48.640]   My fear about that, Matthew, is that if I say something stupid, that happens once in
[01:51:48.640 --> 01:51:55.480]   a decade and the decade is not over yet, and you want to correct me.
[01:51:55.480 --> 01:51:56.960]   And I'm not there to call you out, right?
[01:51:56.960 --> 01:51:57.960]   What happens?
[01:51:57.960 --> 01:51:58.960]   Yeah.
[01:51:58.960 --> 01:51:59.960]   Yeah.
[01:51:59.960 --> 01:52:00.960]   So that is a problem.
[01:52:00.960 --> 01:52:08.040]   I actually saw a comment from someone that said they're going to miss the ratio on tweets.
[01:52:08.040 --> 01:52:18.400]   So if you see tweets that have way more replies than likes or retweets, that's getting ratioed.
[01:52:18.400 --> 01:52:23.440]   And you know that that is a horrible tweet and that most people disagree.
[01:52:23.440 --> 01:52:28.800]   It's like an instantaneous sort of market test of that idea.
[01:52:28.800 --> 01:52:34.040]   And that is an interesting feature in a way, although I don't think Twitter did that deliberately.
[01:52:34.040 --> 01:52:39.200]   So you won't get that and you may get lots more tweets than, no, they didn't do anything
[01:52:39.200 --> 01:52:40.200]   deliberately.
[01:52:40.200 --> 01:52:41.480]   But I don't know.
[01:52:41.480 --> 01:52:42.480]   It's going to be interesting.
[01:52:42.480 --> 01:52:48.400]   I think it will help people who routinely get trolled and attacked all the time in their
[01:52:48.400 --> 01:52:49.400]   mentions.
[01:52:49.400 --> 01:52:54.240]   So that will, like most things, it's probably got lots of great features for people who
[01:52:54.240 --> 01:52:55.240]   need it.
[01:52:55.240 --> 01:52:57.440]   And it's probably going to have downsides as well.
[01:52:57.440 --> 01:53:00.880]   And unintended consequences too.
[01:53:00.880 --> 01:53:01.880]   Yeah, global set.
[01:53:01.880 --> 01:53:02.880]   Is that up now, Matthew?
[01:53:02.880 --> 01:53:04.560]   Is that now current or this?
[01:53:04.560 --> 01:53:06.960]   No, it's coming.
[01:53:06.960 --> 01:53:10.680]   And as a number of people pointed out, Twitter often says things are coming and then they
[01:53:10.680 --> 01:53:11.680]   don't come.
[01:53:11.680 --> 01:53:14.960]   So it's still vaporware at this point, I think.
[01:53:14.960 --> 01:53:15.960]   Yeah.
[01:53:15.960 --> 01:53:18.920]   They say they're running experiments right now, but that they will launch it later this
[01:53:18.920 --> 01:53:20.560]   year.
[01:53:20.560 --> 01:53:22.000]   I did want to mention one other thing.
[01:53:22.000 --> 01:53:23.560]   If I could.
[01:53:23.560 --> 01:53:25.640]   We don't really have time to go into it.
[01:53:25.640 --> 01:53:32.600]   I don't think, but I've been discussing on, CGR has a discussion platform called GALI
[01:53:32.600 --> 01:53:37.360]   that I'm involved with and where we do interviews with experts about various topics.
[01:53:37.360 --> 01:53:44.720]   And this week, the topic is YouTube and disinformation and specifically radicalization.
[01:53:44.720 --> 01:53:49.680]   So there's been a bunch of attention and the kind of rabbit hole effect where YouTube's
[01:53:49.680 --> 01:53:55.360]   recommendation algorithm pushes people towards more and more radical viewpoints or conspiracy
[01:53:55.360 --> 01:53:57.200]   theories or whatever.
[01:53:57.200 --> 01:54:00.160]   And so we've had a series of interviews.
[01:54:00.160 --> 01:54:07.760]   There was a study that came out just before Christmas in which the researchers said they
[01:54:07.760 --> 01:54:10.200]   showed that this does not happen.
[01:54:10.200 --> 01:54:15.560]   And in fact, YouTube actually has a de-radicalizing effect.
[01:54:15.560 --> 01:54:21.440]   There was a huge amount of criticism about this study and the way it was done.
[01:54:21.440 --> 01:54:27.520]   And so I spoke to the researcher, one of the co-authors and I also spoke to Kevin Rus of
[01:54:27.520 --> 01:54:35.840]   the New York Times and to Dipan Gosh, who's a fellow at the Harvard Shorenstein Center.
[01:54:35.840 --> 01:54:40.640]   And in particular, the reason I spoke to Kevin was because this researcher specifically
[01:54:40.640 --> 01:54:46.560]   called at the New York Times for its story about how someone was radicalized by YouTube.
[01:54:46.560 --> 01:54:51.440]   It's a huge amount of debate about that topic.
[01:54:51.440 --> 01:54:55.720]   And so it's been fascinating to dig into it.
[01:54:55.720 --> 01:55:00.080]   Anyway, the interview is at galley.cjr.org.
[01:55:00.080 --> 01:55:01.080]   Nice.
[01:55:01.080 --> 01:55:02.080]   Interesting.
[01:55:02.080 --> 01:55:08.960]   Yeah, I read that the medium piece that I think you're talking about that's in the
[01:55:08.960 --> 01:55:12.040]   rundown today and kind of came out of it scratching my head.
[01:55:12.040 --> 01:55:14.960]   I was like, "Okay, well now I don't know where.
[01:55:14.960 --> 01:55:17.960]   I don't know what to believe anymore."
[01:55:17.960 --> 01:55:18.960]   You're just confused.
[01:55:18.960 --> 01:55:19.960]   You know what?
[01:55:19.960 --> 01:55:20.960]   Jason, I've got a cold.
[01:55:20.960 --> 01:55:21.960]   It's just a cold.
[01:55:21.960 --> 01:55:22.960]   It's the cold.
[01:55:22.960 --> 01:55:23.960]   Yeah.
[01:55:23.960 --> 01:55:24.960]   Thank you.
[01:55:24.960 --> 01:55:28.400]   I mean, the bottom line is it's difficult to make any conclusive statements because we
[01:55:28.400 --> 01:55:33.360]   don't get enough data from YouTube to do the research that needs to be done.
[01:55:33.360 --> 01:55:35.600]   Yeah, Matthew, we're absolutely right.
[01:55:35.600 --> 01:55:36.960]   That's the first problem.
[01:55:36.960 --> 01:55:40.080]   And Twitter is the best and they're trying to get better.
[01:55:40.080 --> 01:55:43.960]   They have, as I mentioned, this new portal for researchers, Facebook and YouTube are
[01:55:43.960 --> 01:55:44.960]   awful and community data.
[01:55:44.960 --> 01:55:48.120]   The other problem is, tell me if I'm wrong here.
[01:55:48.120 --> 01:55:53.520]   I know you will, how we cover studies, academic studies in media, right?
[01:55:53.520 --> 01:55:57.840]   We take everything as the final word when not understanding that it's a process.
[01:55:57.840 --> 01:56:02.760]   That studies come after and they do a small slice and they try to go after one thing that's
[01:56:02.760 --> 01:56:06.640]   additive and something that people can test and they can argue with and they can recreate
[01:56:06.640 --> 01:56:08.800]   or not.
[01:56:08.800 --> 01:56:11.880]   But media comes along and says, "Wine will save you.
[01:56:11.880 --> 01:56:17.320]   Mine will kill you every other day and never understanding this additive process of research."
[01:56:17.320 --> 01:56:20.880]   I think I'm a little bit of that in this case.
[01:56:20.880 --> 01:56:23.280]   There was, but there's also another interesting aspect.
[01:56:23.280 --> 01:56:29.280]   If you look at the things that this co-author has written on Medium and on Twitter, I think
[01:56:29.280 --> 01:56:36.360]   there's a push for, if you think of academic research as media or content, there's a push
[01:56:36.360 --> 01:56:43.360]   to make your research more interesting or to get more attention for it because by doing
[01:56:43.360 --> 01:56:51.560]   that, you then get research grants or you get a higher profile in your industry or whatever.
[01:56:51.560 --> 01:56:58.280]   I've noticed at least more and more research papers that are being much more controversial
[01:56:58.280 --> 01:57:04.440]   or taking a much more, even the titles that they use for papers are because they're basically
[01:57:04.440 --> 01:57:09.880]   trolling journalists to try and get them to write the stories that you're talking about.
[01:57:09.880 --> 01:57:11.320]   Which is why the conversation started.
[01:57:11.320 --> 01:57:14.960]   You know the site called the conversation?
[01:57:14.960 --> 01:57:20.240]   Universities subsidize it to get journalists to take academic research and then translate
[01:57:20.240 --> 01:57:25.040]   it into human speak so that that research gets more attention and more impact.
[01:57:25.040 --> 01:57:26.760]   But what you just said, Matthew, is interesting.
[01:57:26.760 --> 01:57:36.320]   And of course before, so I just, hold on a second.
[01:57:36.320 --> 01:57:42.720]   So I'm doing my Gutenberg research and there's a survey, a series of books, like 70 books
[01:57:42.720 --> 01:57:46.880]   from the company Brill, this book costs $185.
[01:57:46.880 --> 01:57:50.120]   I got it from the New York Public Library, thank you very much New York Public Library.
[01:57:50.120 --> 01:57:51.120]   And why?
[01:57:51.120 --> 01:57:54.000]   Because if 200 people buy it, that's fine, that's a good business bottle.
[01:57:54.000 --> 01:57:56.240]   The author is probably wrote it for free.
[01:57:56.240 --> 01:57:58.360]   It's a bunch of academic papers.
[01:57:58.360 --> 01:58:00.760]   That model starts to go away.
[01:58:00.760 --> 01:58:05.920]   So what you're raising the curtain on since now is your term to be dystopian, Matthew,
[01:58:05.920 --> 01:58:08.400]   is academic clickbait.
[01:58:08.400 --> 01:58:09.400]   No?
[01:58:09.400 --> 01:58:10.400]   Yeah.
[01:58:10.400 --> 01:58:11.400]   Yeah.
[01:58:11.400 --> 01:58:14.160]   And I think it's a real phenomenon.
[01:58:14.160 --> 01:58:19.360]   It has, I've at least noticed it in researchers that I've talked to have noticed it as well.
[01:58:19.360 --> 01:58:23.640]   There are sites now that specialize in just that kind of research.
[01:58:23.640 --> 01:58:30.760]   They're effectively content farms, but for clickbait academic papers.
[01:58:30.760 --> 01:58:38.120]   So what do the, you'd think there'd be some kind of reputational harm to the academic
[01:58:38.120 --> 01:58:39.440]   who participates in that?
[01:58:39.440 --> 01:58:43.960]   Or are they just public or fair institutions?
[01:58:43.960 --> 01:58:48.960]   I mean, I think I would hope that eventually if you did enough of that, that there would
[01:58:48.960 --> 01:58:57.240]   be reputational harm, but they're just the focus that academia has on how many papers
[01:58:57.240 --> 01:59:01.200]   of you published and what journals have you been in and who have you been cited by.
[01:59:01.200 --> 01:59:07.080]   I mean, there's definitely, it's not that different from how many articles did you write
[01:59:07.080 --> 01:59:12.120]   today and did they get on TechMeeM and how many clicks did you get?
[01:59:12.120 --> 01:59:14.720]   You moved from publisher parish to click or die.
[01:59:14.720 --> 01:59:15.720]   Yeah.
[01:59:15.720 --> 01:59:19.960]   And people do what you incentivize them to do, you know, effectively.
[01:59:19.960 --> 01:59:26.160]   So there'll be no place in the world for smart, educated people like Kirsten who make up entirely
[01:59:26.160 --> 01:59:27.160]   new words.
[01:59:27.160 --> 01:59:28.160]   Yeah.
[01:59:28.160 --> 01:59:30.000]   There's no place in the world for me.
[01:59:30.000 --> 01:59:31.000]   Like translucent.
[01:59:31.000 --> 01:59:33.000]   What was the word again?
[01:59:33.000 --> 01:59:34.000]   What was the word?
[01:59:34.000 --> 01:59:35.000]   Translucent eyes.
[01:59:35.000 --> 01:59:36.000]   Translucent eyes.
[01:59:36.000 --> 01:59:37.000]   Yes.
[01:59:37.000 --> 01:59:38.000]   Translucent eyes.
[01:59:38.000 --> 01:59:39.000]   Translucent eyes.
[01:59:39.000 --> 01:59:40.000]   Mm hmm.
[01:59:40.000 --> 01:59:41.000]   Oh.
[01:59:41.000 --> 01:59:42.000]   Translucent.
[01:59:42.000 --> 01:59:43.000]   Translucent.
[01:59:43.000 --> 01:59:46.840]   Maybe we can hone this a little bit.
[01:59:46.840 --> 01:59:47.840]   That's a different thing.
[01:59:47.840 --> 01:59:48.840]   Yeah.
[01:59:48.840 --> 01:59:49.840]   You can improve on Kirsten.
[01:59:49.840 --> 01:59:50.840]   It's true.
[01:59:50.840 --> 01:59:51.840]   It's true.
[01:59:51.840 --> 01:59:52.840]   Trying to like make it a verb.
[01:59:52.840 --> 01:59:53.840]   Show title?
[01:59:53.840 --> 01:59:54.840]   Yeah.
[01:59:54.840 --> 01:59:55.840]   It is.
[01:59:55.840 --> 01:59:56.840]   Yeah.
[01:59:56.840 --> 01:59:57.840]   Probably the show title.
[01:59:57.840 --> 02:00:00.440]   My thing isn't a thing that you can do.
[02:00:00.440 --> 02:00:03.200]   It's just a thing that I saw on Twitter that I thought was neat.
[02:00:03.200 --> 02:00:05.080]   This is how I am doing today.
[02:00:05.080 --> 02:00:07.720]   I'm just putting something in here that I think is neat.
[02:00:07.720 --> 02:00:15.800]   From KBHD on Twitter tweeted out from CES a fully functional piano that is made entirely
[02:00:15.800 --> 02:00:17.800]   of 1+7 tees.
[02:00:17.800 --> 02:00:19.280]   Nice.
[02:00:19.280 --> 02:00:20.960]   And I just, it's so nerdy.
[02:00:20.960 --> 02:00:21.960]   I love it.
[02:00:21.960 --> 02:00:25.320]   It's like, it's like the combination of things that I love.
[02:00:25.320 --> 02:00:27.880]   Technology and music and doing neat things.
[02:00:27.880 --> 02:00:30.480]   I don't know if you have any audio on this, but you can hear it.
[02:00:30.480 --> 02:00:32.000]   I mean, it sounds pretty good.
[02:00:32.000 --> 02:00:34.800]   Are the phones making the noise then?
[02:00:34.800 --> 02:00:38.000]   Or is it just being used as a keyboard into a move?
[02:00:38.000 --> 02:00:39.600]   Well, that's a good question.
[02:00:39.600 --> 02:00:44.160]   I mean, I don't know if each phone is outputting its own sound.
[02:00:44.160 --> 02:00:45.160]   That's a really good question.
[02:00:45.160 --> 02:00:46.800]   It should be really good in the best, don't think.
[02:00:46.800 --> 02:00:49.080]   I don't think that would work.
[02:00:49.080 --> 02:00:54.240]   I mean, that is so sweet looking.
[02:00:54.240 --> 02:00:55.240]   I love it.
[02:00:55.240 --> 02:00:59.040]   I don't love to be able to make non-
[02:00:59.040 --> 02:01:01.240]   The middle of your minuet, one of the phone's rings.
[02:01:01.240 --> 02:01:02.240]   Yes.
[02:01:02.240 --> 02:01:06.360]   Or accidentally backs out to the home screen right in the middle.
[02:01:06.360 --> 02:01:09.680]   So that's a $3,000 keyboard or?
[02:01:09.680 --> 02:01:14.600]   Well, yeah, I guess the 70s, how much are they?
[02:01:14.600 --> 02:01:16.960]   They're like 600 to pop, I believe.
[02:01:16.960 --> 02:01:19.000]   500 somewhere around there.
[02:01:19.000 --> 02:01:21.120]   I can't have any of them.
[02:01:21.120 --> 02:01:22.880]   Yeah, I'm guessing.
[02:01:22.880 --> 02:01:24.720]   There's probably like 12 phones.
[02:01:24.720 --> 02:01:25.720]   Ish.
[02:01:25.720 --> 02:01:27.440]   How many, how many, let's do the math?
[02:01:27.440 --> 02:01:30.240]   How many keys on it two keys each or four?
[02:01:30.240 --> 02:01:31.840]   Divided by three equals the phone.
[02:01:31.840 --> 02:01:32.840]   That's right.
[02:01:32.840 --> 02:01:33.840]   It was a three phone.
[02:01:33.840 --> 02:01:35.040]   88 keys, yeah.
[02:01:35.040 --> 02:01:36.320]   Does that include the black keys?
[02:01:36.320 --> 02:01:37.320]   Yes.
[02:01:37.320 --> 02:01:38.320]   Are they white keys?
[02:01:38.320 --> 02:01:39.320]   Yeah, yeah.
[02:01:39.320 --> 02:01:40.320]   Oh, wait.
[02:01:40.320 --> 02:01:41.320]   That does include the black keys.
[02:01:41.320 --> 02:01:46.000]   Roughly, I'm counting 17 phones just by looking at the video.
[02:01:46.000 --> 02:01:47.000]   That doesn't work.
[02:01:47.000 --> 02:01:48.000]   It could be off.
[02:01:48.000 --> 02:01:49.000]   It could be off.
[02:01:49.000 --> 02:01:50.000]   But--
[02:01:50.000 --> 02:01:51.000]   That math doesn't work.
[02:01:51.000 --> 02:01:52.000]   That's super cool.
[02:01:52.000 --> 02:01:53.000]   I love it.
[02:01:53.000 --> 02:01:54.000]   It is cool.
[02:01:54.000 --> 02:01:55.000]   And it sounded good.
[02:01:55.000 --> 02:01:56.480]   Like it sounds great.
[02:01:56.480 --> 02:01:59.120]   But again, you run into that kind of--
[02:01:59.120 --> 02:02:03.720]   that disconnect of what we were talking about earlier, of typing on a flat surface.
[02:02:03.720 --> 02:02:04.720]   Yeah.
[02:02:04.720 --> 02:02:05.720]   Doesn't work.
[02:02:05.720 --> 02:02:06.720]   It's the same thing with--
[02:02:06.720 --> 02:02:07.720]   Haptic feedback.
[02:02:07.720 --> 02:02:09.200]   Yeah, you need a little buzz when you hit it.
[02:02:09.200 --> 02:02:11.200]   That would be nice.
[02:02:11.200 --> 02:02:12.200]   All right.
[02:02:12.200 --> 02:02:14.880]   Let's stop this madness now.
[02:02:14.880 --> 02:02:16.880]   Jason, Jason, you're going to the store.
[02:02:16.880 --> 02:02:17.880]   What are you going to buy?
[02:02:17.880 --> 02:02:19.640]   Night quill, and I'm going to go to sleep.
[02:02:19.640 --> 02:02:20.640]   Oh.
[02:02:20.640 --> 02:02:22.680]   17, 1 plus T.
[02:02:22.680 --> 02:02:23.680]   Fisherman's friend.
[02:02:23.680 --> 02:02:24.680]   Fisherman's friend.
[02:02:24.680 --> 02:02:25.680]   Fisherman's friend.
[02:02:25.680 --> 02:02:28.360]   You're going to walk in and say, do you have a Fisherman's friend?
[02:02:28.360 --> 02:02:30.280]   You're like, huh?
[02:02:30.280 --> 02:02:33.520]   Yeah, I've never heard of it before.
[02:02:33.520 --> 02:02:35.240]   What can I say?
[02:02:35.240 --> 02:02:36.240]   This was a lot of fun.
[02:02:36.240 --> 02:02:37.240]   It was terrible.
[02:02:37.240 --> 02:02:41.640]   And it was enjoyable being in the middle of the tennis match in the middle of the show.
[02:02:41.640 --> 02:02:42.640]   So thank you for allowing me to be--
[02:02:42.640 --> 02:02:44.640]   We've got that a long time, right, Matthew?
[02:02:44.640 --> 02:02:46.640]   We used to do that a lot more.
[02:02:46.640 --> 02:02:48.720]   So this was a nice gentle war.
[02:02:48.720 --> 02:02:49.720]   Okay.
[02:02:49.720 --> 02:02:55.240]   I will peel back the curtain just a slight bit and let you know that during that back
[02:02:55.240 --> 02:03:00.160]   and forth, I got a message from my wife that said, hey, I can't find the keys for the
[02:03:00.160 --> 02:03:01.160]   sequoia.
[02:03:01.160 --> 02:03:02.160]   I need to pick up the girls.
[02:03:02.160 --> 02:03:03.160]   Where are they?
[02:03:03.160 --> 02:03:04.160]   Oh, oh, oh, oh.
[02:03:04.160 --> 02:03:08.720]   I had that panic moment of like, oh, no, did I bring the keys and she has no way to go
[02:03:08.720 --> 02:03:09.920]   pick up our kids?
[02:03:09.920 --> 02:03:11.840]   And so you guys were battling.
[02:03:11.840 --> 02:03:14.640]   I was like messaging back and forth with her.
[02:03:14.640 --> 02:03:16.040]   That's why I wasn't talking initially.
[02:03:16.040 --> 02:03:18.520]   And then trying to enter back into the conversation.
[02:03:18.520 --> 02:03:20.240]   I was like, oh my God, this is just not--
[02:03:20.240 --> 02:03:21.640]   Did you have trouble, Jason?
[02:03:21.640 --> 02:03:22.640]   No, no, no, no.
[02:03:22.640 --> 02:03:23.640]   I knew where they were.
[02:03:23.640 --> 02:03:24.640]   No, okay.
[02:03:24.640 --> 02:03:25.640]   They were in the little--
[02:03:25.640 --> 02:03:27.640]   Your just used in the gym bag.
[02:03:27.640 --> 02:03:29.040]   Go from the sympathy in the gym bag.
[02:03:29.040 --> 02:03:30.640]   I was a little worried there first.
[02:03:30.640 --> 02:03:32.280]   I was thinking, oh no, what's going to happen?
[02:03:32.280 --> 02:03:33.280]   But then I--
[02:03:33.280 --> 02:03:34.280]   It's the other thing I do.
[02:03:34.280 --> 02:03:35.280]   Yeah.
[02:03:35.280 --> 02:03:37.200]   But then I realized I remembered where they were.
[02:03:37.200 --> 02:03:39.000]   That's not usually how my brain works.
[02:03:39.000 --> 02:03:40.920]   So I'm happy about that.
[02:03:40.920 --> 02:03:45.640]   Matthew Ingram, chief digital writer for the Columbia journalism review, CJR.org.
[02:03:45.640 --> 02:03:47.240]   Matthew, I love doing shows with you.
[02:03:47.240 --> 02:03:48.240]   Thank you so much for hopping on.
[02:03:48.240 --> 02:03:49.240]   Well, you're just about to wrap them in.
[02:03:49.240 --> 02:03:50.840]   This week in Google this week.
[02:03:50.840 --> 02:03:52.880]   It was great to see you again.
[02:03:52.880 --> 02:03:58.560]   And of course, Jeff Jarvis, Buzzmachine.com at Jeff Jarvis on Twitter.
[02:03:58.560 --> 02:04:01.520]   Pleasure to be with all of you, including an even Carston.
[02:04:01.520 --> 02:04:02.520]   That's right.
[02:04:02.520 --> 02:04:06.840]   Thank you, big thank you to Carston, actually, especially because Carston, you were jumping
[02:04:06.840 --> 02:04:09.880]   in there on that conversation when I wasn't, so I appreciate that.
[02:04:09.880 --> 02:04:14.480]   I got your back, thank you, Carston, for everything that you do with Twig.
[02:04:14.480 --> 02:04:15.480]   Thanks, Steve.
[02:04:15.480 --> 02:04:17.320]   Do you have a signal there of--
[02:04:17.320 --> 02:04:19.920]   Like, camera on for me?
[02:04:19.920 --> 02:04:20.920]   Was that me?
[02:04:20.920 --> 02:04:21.920]   Yes.
[02:04:21.920 --> 02:04:24.400]   I was just having a little signal of--
[02:04:24.400 --> 02:04:25.920]   Like, I can't go.
[02:04:25.920 --> 02:04:31.080]   When security now-- Leo said, when security now goes, once he's going into us a little
[02:04:31.080 --> 02:04:32.080]   like we--
[02:04:32.080 --> 02:04:33.080]   Yeah.
[02:04:33.080 --> 02:04:34.080]   Right.
[02:04:34.080 --> 02:04:35.080]   Leo-- he knows.
[02:04:35.080 --> 02:04:36.080]   Steve knows.
[02:04:36.080 --> 02:04:37.080]   Leo can go to the bathroom.
[02:04:37.080 --> 02:04:38.080]   Right.
[02:04:38.080 --> 02:04:39.080]   Leo's doing the board in there, right?
[02:04:39.080 --> 02:04:40.080]   Right.
[02:04:40.080 --> 02:04:41.080]   Right.
[02:04:41.080 --> 02:04:42.080]   Right.
[02:04:42.080 --> 02:04:44.080]   Do you have a big studio signal that says--
[02:04:44.080 --> 02:04:45.480]   Get me off the camera.
[02:04:45.480 --> 02:04:46.480]   No.
[02:04:46.480 --> 02:04:47.480]   No.
[02:04:47.480 --> 02:04:48.480]   No, I don't.
[02:04:48.480 --> 02:04:49.960]   I just kind of sit here and wait.
[02:04:49.960 --> 02:04:52.280]   And then once the camera goes off of me, I itch.
[02:04:52.280 --> 02:04:53.280]   And go off.
[02:04:53.280 --> 02:04:54.280]   I could finally itch.
[02:04:54.280 --> 02:04:55.280]   I was--
[02:04:55.280 --> 02:04:56.280]   I was--
[02:04:56.280 --> 02:04:58.280]   So if you started hacking or coughing or something.
[02:04:58.280 --> 02:04:59.280]   Yeah.
[02:04:59.280 --> 02:05:01.520]   If the camera's not on me, I do have the ability to mute my egg.
[02:05:01.520 --> 02:05:02.520]   Yeah.
[02:05:02.520 --> 02:05:03.520]   Yeah.
[02:05:03.520 --> 02:05:04.520]   Yeah.
[02:05:04.520 --> 02:05:05.520]   Okay.
[02:05:05.520 --> 02:05:06.520]   So I can at least do that.
[02:05:06.520 --> 02:05:08.520]   But yeah, it would be weird if the camera was on the wide.
[02:05:08.520 --> 02:05:11.960]   And I'm like, you know, motioning to Carston.
[02:05:11.960 --> 02:05:12.960]   So--
[02:05:12.960 --> 02:05:13.960]   Kill it.
[02:05:13.960 --> 02:05:16.960]   I just wait until he takes one of your cameras.
[02:05:16.960 --> 02:05:18.080]   All right.
[02:05:18.080 --> 02:05:26.000]   So, twitter.tv/twig is where you can go to find all the information about this show,
[02:05:26.000 --> 02:05:30.280]   all of the episodes that have ever been recorded of this week in Google could be found there,
[02:05:30.280 --> 02:05:35.640]   all of your subscribe links, audio, video, details about when we record, which happens
[02:05:35.640 --> 02:05:42.600]   to be every Wednesday, 4 p.m. Eastern, 1 p.m. Pacific, 2100 UTC I'm imagining next week.
[02:05:42.600 --> 02:05:47.960]   And we back to the normal lineup that would be Jeff, Stacey, Anne Pruitt, and of course,
[02:05:47.960 --> 02:05:54.800]   Leo Le Porte sitting in his chair, whether it has wheels or not, remains to be seen.
[02:05:54.800 --> 02:05:56.240]   We'll check in on that next week.
[02:05:56.240 --> 02:05:58.360]   And of course, Carston will be back next week as well.
[02:05:58.360 --> 02:06:01.840]   I will not, but I always enjoy sitting in this chair for this week in Google.
[02:06:01.840 --> 02:06:05.000]   So thank you for welcoming on the show once again.
[02:06:05.000 --> 02:06:06.000]   And we'll see you next week.
[02:06:06.000 --> 02:06:07.000]   Take care, everybody.
[02:06:07.000 --> 02:06:07.000]   Bye.
[02:06:07.000 --> 02:06:17.000]   [MUSIC]
[02:06:17.000 --> 02:06:27.000]   [BLANK_AUDIO]

