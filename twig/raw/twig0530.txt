;FFMETADATA1
title=Grippy Rubber Bottom
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=530
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.080]   It's time for Twig this week in Google. Kevin Tofel's sitting in for Jeff Jarvis.
[00:00:04.080 --> 00:00:08.960]   Stacey Higginbotham and Aunt Puritt are also here. We will talk about the big Google event.
[00:00:08.960 --> 00:00:14.560]   Why was it so slow? But what were the highlights? We'll also talk about the new ambient computing
[00:00:14.560 --> 00:00:22.160]   that Google's promoting and what it really means to you and the things we said goodbye to this week.
[00:00:22.160 --> 00:00:24.080]   It's all coming up next on Twig.
[00:00:26.560 --> 00:00:32.320]   Podcasts you love. From people you trust. This is Twig.
[00:00:32.320 --> 00:00:45.520]   This is Twig. This week in Google, episode 530, recorded Wednesday, October 16th, 2019.
[00:00:45.520 --> 00:00:52.240]   Rippy Rubberboden. This week in Google is brought to you by ExpressVPN. Protect your online privacy
[00:00:52.240 --> 00:00:59.760]   with one click. It's that easy. For three extra months free with a one-year package, go to expressvpn.com/twig.
[00:00:59.760 --> 00:01:08.400]   And by Taylor Store. Taylor Store makes high-quality dress shirts that are fully customizable by you.
[00:01:08.400 --> 00:01:13.600]   With their exclusive trial price, each new customer gets their dress shirt starting at $39.
[00:01:13.600 --> 00:01:19.120]   From the basic essentials to the most high-end details, Taylor Store has you covered. Go to
[00:01:19.120 --> 00:01:26.240]   taylorstore.com/twig and use the code Twig. And by World Wide Technology.
[00:01:26.240 --> 00:01:31.280]   World Wide Technology's Advanced Technology Center is like no other testing and research lab
[00:01:31.280 --> 00:01:35.600]   with more than a half billion dollars worth of equipment including OEMs like NetApp
[00:01:35.600 --> 00:01:41.600]   and its virtual so you can access it 24/7. To learn more and get insights into all the
[00:01:41.600 --> 00:01:48.880]   ATC offers, go to www.wt.com/twig. It's time for a twig this week in Google.
[00:01:48.880 --> 00:01:56.240]   This is going to be the apology show. Stacey Higginbotham is here from Stacey on IOT, Gigas Stacey,
[00:01:56.240 --> 00:02:04.400]   Hi Stacey, you're wearing your lovely Balkan peasant blouse today. Yes, yes, I decided to color it up
[00:02:04.400 --> 00:02:10.000]   this time. Beautiful. You don't look like Princess Leia. Oh, I can't remember who did the photo,
[00:02:10.000 --> 00:02:17.120]   but I have to remember. Oh, I want to show it. It's so amazing. Ant is also here. Ant Pruitt. Yes, I am.
[00:02:17.120 --> 00:02:22.320]   He is our guy, hands-on photography and a brand new show coming soon. Coming soon.
[00:02:22.320 --> 00:02:27.200]   Do we have a tease for that yet that we can play? Uh, maybe tease? Not yet. Not yet.
[00:02:27.200 --> 00:02:36.320]   It's murder. Hey, I recognize that sound. That's Kevin, the laugh of Kevin Tofol.
[00:02:36.880 --> 00:02:42.640]   The tired laugh of Kevin. Tired laugh of Kevin. Kevin about Chromebooks.com,
[00:02:42.640 --> 00:02:49.040]   former giga-omer like Stacey, and filling in today for Jeff Jarvis, who is on the road.
[00:02:49.040 --> 00:02:57.760]   Zeev Zoolander, after yesterday or last week's episode, where Stacey really looked like Princess
[00:02:57.760 --> 00:03:04.320]   Leia. She had her headphones on. She was wearing a white down jacket with a big high collar.
[00:03:05.040 --> 00:03:10.160]   And we were talking about how Ant really is the Bob Ross of photography. And if he only had a giant
[00:03:10.160 --> 00:03:18.720]   curly hairdo, it'd be perfect. So Zeev did a little Photoshop with Ant retouching Stacey.
[00:03:18.720 --> 00:03:24.080]   Wow, that thing is gold. It's awesome. It was fantastic. I really appreciated it.
[00:03:24.080 --> 00:03:29.680]   Nice job Zeev Zoolander in our, this is in our Twit Forum, a Twit. Community. If you want to
[00:03:29.680 --> 00:03:34.640]   download a copy, I think Ant tweeted it as well. I did. You saw a happy little tree.
[00:03:34.640 --> 00:03:41.200]   Exactly. Don't you think Ant kind of is the Bob Ross of Twit? I mean, kind of think yeah.
[00:03:41.200 --> 00:03:48.560]   You're a warm, relaxed, that's a good thing. You're forgiving.
[00:03:48.560 --> 00:03:54.560]   He's calling. Just like it's all good. Yeah. He makes everybody just feel better. I do.
[00:03:54.560 --> 00:03:59.360]   I do love treats. I try to just relax when I'm editing photos. So maybe I see where you
[00:03:59.360 --> 00:04:03.360]   where you can make that equation. But that's what hands on photography is going to be.
[00:04:03.360 --> 00:04:10.240]   And I say, just, I told you, make it Bob Ross. We will have some editing segments of my
[00:04:10.240 --> 00:04:15.200]   shots and even some of the listener shots on hands on photography. And I think it's.
[00:04:15.200 --> 00:04:16.480]   Nice. Ooh. Puffy.
[00:04:16.480 --> 00:04:20.320]   Nice sent you shots. And have you had puppy clouds? Puppy little clouds? Yes.
[00:04:20.320 --> 00:04:23.280]   Happy little trees. Happy little trees.
[00:04:23.280 --> 00:04:28.720]   I know what you're looking or you're dressing as for Halloween. That's all I can say.
[00:04:30.000 --> 00:04:35.840]   So I do and they were castigating me in the forums because we got a little heated last week and I
[00:04:35.840 --> 00:04:41.840]   stomped all over Stacy's many brilliant thoughts because I was. All winded points.
[00:04:41.840 --> 00:04:49.680]   No, you you're thoughtful and and I'm just loud and obnoxious. So I apologize.
[00:04:49.680 --> 00:04:55.840]   And I'm going to stay out of your way today. It's going to be a very different show.
[00:04:55.840 --> 00:05:03.360]   Right. I should also point out that I'm going to be gone for a month.
[00:05:03.360 --> 00:05:10.240]   I won't be back here till November 20th. So these shows are really going to be.
[00:05:10.240 --> 00:05:14.960]   This is it. And I wonder how relaxed I'll be when I get back from vacation. Probably pretty.
[00:05:14.960 --> 00:05:24.400]   Somebody says they want you to be the Bob Ross, not the Sam Kinison.
[00:05:24.400 --> 00:05:28.160]   Oh man. Oh boy. Yeah. Say it. Say it.
[00:05:28.160 --> 00:05:32.400]   You can't do it.
[00:05:32.400 --> 00:05:32.800]   You can't do it either.
[00:05:32.800 --> 00:05:32.800]   Yeah.
[00:05:32.800 --> 00:05:34.800]   I'm Kinison with hilarious.
[00:05:34.800 --> 00:05:46.560]   So yesterday, yesterday we got up early. I got up early and I watched the event. Jason Howell,
[00:05:46.560 --> 00:05:49.120]   weren't you there? I think I was.
[00:05:49.120 --> 00:05:53.840]   You just don't remember? I think I was. This all feels familiar for some reasons.
[00:05:53.840 --> 00:05:59.760]   A lot of people were disappointed with Google's event yesterday. They said,
[00:05:59.760 --> 00:06:01.040]   "Yeah, it was boring."
[00:06:01.040 --> 00:06:06.800]   Why were they disappointed? Is it because we already knew what was coming?
[00:06:06.800 --> 00:06:11.200]   It'd be hard for Google to get any excitement going about, "Hey, and it's got two cameras."
[00:06:11.200 --> 00:06:14.160]   So maybe that's it.
[00:06:14.160 --> 00:06:16.480]   I thought it was.
[00:06:16.480 --> 00:06:17.920]   Go ahead.
[00:06:19.440 --> 00:06:25.520]   It was because of the leaks, everything was known, and you knew right up front that they were just
[00:06:25.520 --> 00:06:30.080]   going to own it because as soon as Rick Osterlo got on stage within about a minute behind them,
[00:06:30.080 --> 00:06:33.680]   he said, "We're going to talk about new products today." And they showed the entire lineup right
[00:06:33.680 --> 00:06:40.800]   up front. They didn't hide it. They didn't hide it. So it's hard. I mean, they embraced these leaks
[00:06:40.800 --> 00:06:44.560]   over the past several months at some point and just said, "We're just going to start putting our
[00:06:44.560 --> 00:06:50.480]   own stuff out here and keep people talking." And that's smart. But that makes for a very challenging
[00:06:50.480 --> 00:06:56.320]   event to have the excitement. And I will say this, having any Liba which they're cool.
[00:06:56.320 --> 00:07:01.280]   Oh, it was cool. But she was low energy. She really had much, like you said, energy wise,
[00:07:01.280 --> 00:07:06.800]   but it's nice that she's... It was nice that she was there. And the funny thing, when I go to
[00:07:06.800 --> 00:07:12.480]   these events, I look back at the teleprompters behind us to see what they're about to say.
[00:07:13.200 --> 00:07:17.360]   So during the Annie Liba with Seivent with Lily Lin, and I know Lily from working with her,
[00:07:17.360 --> 00:07:23.040]   she's in PR at Google. She's fantastic. Oh, poor Lily. I felt bad for Lily. I was feeling poor.
[00:07:23.040 --> 00:07:31.040]   Lily had questions that were better questions than she asked. But because Annie was kind of zig-zagging
[00:07:31.040 --> 00:07:38.000]   around rambling a little bit, it didn't work. Those questions didn't work. So Lily made do,
[00:07:38.000 --> 00:07:41.600]   and she did a great job given the situation, my opinion. And it's not a knock against Annie
[00:07:41.600 --> 00:07:46.640]   Liba with. I mean, she's a fantastic photographer. It was awesome to see her there, but a little
[00:07:46.640 --> 00:07:52.000]   low energy. And that didn't help is all I was going to say. Yeah, I was also disappointed. You
[00:07:52.000 --> 00:07:56.240]   didn't suffer this because you at least were able to see the pictures over Annie Liba with us.
[00:07:56.240 --> 00:08:01.440]   But those of us watching on the stream, they kept cutting away from the pictures to Annie and Lily.
[00:08:01.440 --> 00:08:06.720]   Really, fortunately TechCrunch has many of these pictures, but we didn't get to see the pictures
[00:08:06.720 --> 00:08:11.840]   anywhere. Oh, what a shame they were asking. It looks great. Actually, there's just one picture,
[00:08:11.840 --> 00:08:17.840]   unfortunately. Oh, what a shame because she got great pictures of Megan Rapinoe. She got pictures
[00:08:17.840 --> 00:08:24.000]   of people I don't know, but they just signed some Rapinoe shots. Oh, man. Yeah, two of them.
[00:08:24.000 --> 00:08:32.560]   And honestly, they look like she just used whatever DSLR or whatever equipment she normally uses.
[00:08:32.560 --> 00:08:37.840]   They were that good and they were taken with the Pixel phone. Although somebody did point out,
[00:08:37.840 --> 00:08:46.800]   you could give Annie Liba with Annie. It's like saying, look,
[00:08:46.800 --> 00:08:51.600]   Ant can lift this bottle. It's so light. It's like, well, yeah, because he's.
[00:08:51.600 --> 00:08:57.520]   So I wish I would have loved have seen those images. You know, the one I wanted to see was of the
[00:08:57.520 --> 00:09:02.400]   and Annie Liba. It's talked about it of the cadet, the military academy cadet,
[00:09:02.400 --> 00:09:07.120]   Citadel boots or Citadel. Okay. And the boots she had worn all four years of the Citadel.
[00:09:07.120 --> 00:09:12.880]   And we saw it for a second. And I would have really liked it. It's a story.
[00:09:12.880 --> 00:09:19.360]   Photography is about the story. It's not about the megapixel. She's so good. I feel bad for
[00:09:19.360 --> 00:09:23.680]   Ivy Ross to be honest as well. Ivy Ross, you know, I saw a bunch of
[00:09:25.680 --> 00:09:31.440]   twerps for one of a better word on Reddit saying when that old lady came out, she seemed so
[00:09:31.440 --> 00:09:35.600]   unexcited about the Chromebook. They didn't know who Ivy Ross is.
[00:09:35.600 --> 00:09:42.800]   I mean, whose Ivy Ross? Industrial design. She's. She gave Google the material aesthetic.
[00:09:42.800 --> 00:09:45.760]   She's the one that's put fabric and I think she's their head designer.
[00:09:45.760 --> 00:09:52.000]   And a legendary designer. You know, I would say she's as well known in design as Annie Liba.
[00:09:52.000 --> 00:09:59.440]   If it's is photography. But if you don't know that, you were like, why is this woman talking
[00:09:59.440 --> 00:10:03.360]   about the Chromebook? And she they said on Reddit, she doesn't she doesn't even seem like she's
[00:10:03.360 --> 00:10:09.120]   excited about it. Some people when they're nervous, their energy goes down. Not everyone is a show
[00:10:09.120 --> 00:10:13.520]   man or show woman on stage. They're passionate about the product. And I'm actually honored Google
[00:10:13.520 --> 00:10:18.640]   for bringing it. You know, sometimes companies to get women on stage or people of color on stage
[00:10:18.640 --> 00:10:24.400]   will find out. They're like, is there anybody like get that intern? Right. But I honored Google for
[00:10:24.400 --> 00:10:30.160]   bringing out their head designer to talk about the Chromebook. Right. Yeah. That's what it should
[00:10:30.160 --> 00:10:33.920]   be mean, subject matter expert. Yeah. Oh, please don't.
[00:10:33.920 --> 00:10:42.240]   We don't know any of those words before we move on. I actually found on the Google blog,
[00:10:42.960 --> 00:10:49.360]   a listing with a link to the to any photos. Oh, good. Oh, nice. Yeah. On line 24 in the notes,
[00:10:49.360 --> 00:10:52.640]   you can take a look and there's a link in there. Oh, how long have you scrolled down?
[00:10:52.640 --> 00:10:56.880]   Scroll down and you'll see that that cadet picture, for example. Yep. That's the link.
[00:10:56.880 --> 00:11:03.120]   Full collection. Nice. A couple of it. There you go. Now you can see. Oh, man. Oh, good. I'm so
[00:11:03.120 --> 00:11:09.120]   glad because these are really stunning images. Yes. She talked about how she did it, which she took
[00:11:09.120 --> 00:11:14.080]   two pictures. Here's an example, a guy taking a selfie of himself. And actually, it's fun because
[00:11:14.080 --> 00:11:20.080]   if you look in the left corner of the mirror, you could see Annie's hand holding a pixel four.
[00:11:20.080 --> 00:11:27.600]   The guy's apparently using a pixel three, I guess. And then next to it, his clothes hanging on the
[00:11:27.600 --> 00:11:33.040]   door. And I thought that was a really interesting idea. She's an artist.
[00:11:33.040 --> 00:11:39.520]   It is. I think the cadet picture is the next one, if I recall. Oh, look at that.
[00:11:39.520 --> 00:11:43.120]   So she's at Citadel, which is actually a high school, right? It's not a college.
[00:11:43.120 --> 00:11:46.320]   Oh, no, no. It's a college. It's a college. Okay. Yeah, Charleston.
[00:11:46.320 --> 00:11:53.120]   Yeah. Very well-known military school, very tough, rigid, not a US military academy. It's
[00:11:53.120 --> 00:11:58.720]   a private, but it is a very tough school. And look at those are the boots she wore for four years.
[00:11:58.720 --> 00:12:05.280]   There's a big contrast between her dress blues and her graduation outfit and the boots she wore
[00:12:05.280 --> 00:12:10.000]   for those four years. It's very, it's a beautiful shot. Just a gorgeous shot.
[00:12:10.000 --> 00:12:16.720]   If you're looking at that at this page, scroll up to where, or she's shooting Miss Rapino.
[00:12:16.720 --> 00:12:24.080]   See that? Yeah, yeah. On the pier there. Yeah. No, you go back, Carson, you went too fast. There.
[00:12:24.080 --> 00:12:30.000]   Right there. You notice the rig that she's holding. Oh, she's not just holding the camera by itself,
[00:12:30.000 --> 00:12:36.880]   is she? Right. And I tried to mention this in our live coverage, that Apple and everybody else
[00:12:36.880 --> 00:12:42.640]   will have these ads after the phones are announced. It says, hey, this ad was created using with our
[00:12:42.640 --> 00:12:50.160]   phones. The difference is people like Miss Annie is a pro. Yeah. She understands I need to be stable.
[00:12:50.160 --> 00:12:56.320]   So she has this rig on that camera. And there was also another shot. I don't think it's on this
[00:12:56.320 --> 00:13:01.920]   page, but I noticed it in the stream. She had a soft box on the set. Oh, yeah. That's extra lighting.
[00:13:01.920 --> 00:13:06.880]   That's a whole different thing. You know, so that's how those shots are going to look as great as
[00:13:06.880 --> 00:13:11.760]   they look because she's a professional photographer and she knows the fundamentals of shooting. It's
[00:13:11.760 --> 00:13:17.520]   not just that camera. There's more to it. I always say that when they show the shot on iPhone stuff,
[00:13:17.520 --> 00:13:23.520]   is a pro. The gear isn't as important as knowing what they're doing. Composition.
[00:13:23.520 --> 00:13:28.320]   Composition. I have to say, my favorite part of the event. I'm curious what you guys thought was
[00:13:28.320 --> 00:13:34.720]   Mark Levoire. He is the guy who was at I think was at Stanford as a professor of meritos now.
[00:13:34.720 --> 00:13:41.280]   Expert on computational photography. He's really the guy. His explanation on HDR.
[00:13:41.280 --> 00:13:47.760]   And he left Stanford to go to Google. And yeah, I thought that was a that was what I would have
[00:13:47.760 --> 00:13:54.160]   liked to see more of that throughout the event. That was fantastic. I mean, that's probably my
[00:13:54.160 --> 00:14:00.080]   favorite part of the event as well. And just what I loved about it besides not getting too
[00:14:00.080 --> 00:14:06.400]   down in the weeds, he explained everything in in a way you can all understand, but also even
[00:14:06.400 --> 00:14:12.080]   gave tips like when you use the new Pixel 4 camera where we have our hybrid digital zoom,
[00:14:12.080 --> 00:14:20.960]   optical digital, don't crop in, zoom in, frame your photo and just take the picture and trust it.
[00:14:20.960 --> 00:14:26.320]   And I actually took one of those today and he's right. It works the way he said. It's fantastic.
[00:14:26.320 --> 00:14:32.080]   Yeah. Stop cropping. Start zooming. That's going to be something everybody's going to have to remember.
[00:14:32.080 --> 00:14:38.000]   And now we're on the habit of taking an image and zooming in on it in lightroom or snap seed.
[00:14:38.000 --> 00:14:42.480]   And that's how we zoom in. And that will not be as good. That'll that's the old kind of traditional
[00:14:42.480 --> 00:14:47.200]   digital zoom. These cameras are much smarter. They're better now because you couldn't do that in the
[00:14:47.200 --> 00:14:51.760]   past. You just hit that piece of zoom and it would just fall apart on your skull. God, I was awful.
[00:14:51.760 --> 00:14:57.840]   Yeah, I was always I was taught zoom with your feet. Right. You're still right, by the way.
[00:14:58.560 --> 00:15:03.520]   But I have to say, even the Pixel 3 XL, I was in New York last year with the 3 XL.
[00:15:03.520 --> 00:15:10.320]   And I was outside the Broadway show of the Harry Potter and the Cursed Child. And they had
[00:15:10.320 --> 00:15:17.040]   a really beautiful sculpture, but it was up on top of the roof of the building. And I was able to zoom
[00:15:17.040 --> 00:15:23.040]   in with the Pixel 3 XL because I was kind of testing it and I was really impressed. So that's
[00:15:23.040 --> 00:15:28.800]   been around. But I but this is what's so great about the situation we're in right now. And by the
[00:15:28.800 --> 00:15:35.600]   way, give Apple credit to because they're doing amazing great stuff and I don't know if you saw
[00:15:35.600 --> 00:15:43.120]   did you see the Verge article where they compared Pixel 4 images to Apple of iPhone 11 pro images.
[00:15:43.120 --> 00:15:46.880]   And it's it's really interesting there. There there. There's no clear winner.
[00:15:46.880 --> 00:15:50.640]   Right. It's going to come down to personal preference.
[00:15:50.640 --> 00:15:54.720]   Apple's going to get better too because their deep fusion software is coming out sometime in
[00:15:54.720 --> 00:16:01.120]   the future. But but but Mark. Yeah. Mark LaVoy did the same wink wink because remember he was showing
[00:16:01.120 --> 00:16:05.520]   the image of the moon. He took a jam saying here we can give you a moon shot. Here you go. Yeah.
[00:16:05.520 --> 00:16:12.000]   But then the the sky is bright, but the scenery below is dark dark. He said we can't fix that
[00:16:12.000 --> 00:16:17.840]   right now. Stay tuned. So the strong impression and actually Google did this last time. Remember
[00:16:17.840 --> 00:16:23.840]   there was a there's this is the Verge picture. Look at this one though. The red. So the on the right
[00:16:23.840 --> 00:16:28.240]   is the picture with the iPhone on the left is a picture with the Google.
[00:16:28.240 --> 00:16:34.480]   Pixel for I don't the promise. I don't know which red is correct. Red is historically
[00:16:34.480 --> 00:16:41.120]   hard for digital photography. There's the the Google's is much more toned down. It's almost a brick red.
[00:16:41.120 --> 00:16:45.840]   Whereas the iPhones is a fire engine red. One of those is wrong.
[00:16:45.840 --> 00:16:50.000]   All right. One of them is a little. I think the fire engine rate is a little too saturated.
[00:16:50.000 --> 00:16:54.800]   Maybe that's it. But that's my actually scroll down a little bit, Carsten.
[00:16:54.800 --> 00:16:58.240]   Because I think we're missing the none on the other way the other way the top of the photo.
[00:16:58.240 --> 00:17:04.560]   Because the yeah because the problem as you can see is there is a very bright light coming from
[00:17:04.560 --> 00:17:11.040]   the sky above right through those windows. And so Google toned its picture down so that it's not
[00:17:11.040 --> 00:17:15.840]   blown out with the skylight. Apple did something else. It's pictures brighter.
[00:17:15.840 --> 00:17:22.240]   I think the highlights might be blown in the sky. So that's a choice though. The software makes
[00:17:22.240 --> 00:17:30.400]   that's what's amazing when when the HDR software was first implemented. I believe it was around
[00:17:30.400 --> 00:17:37.680]   Nexus 5, Nexus 6, somewhere in that area. I didn't like it at first. I thought here's it.
[00:17:38.960 --> 00:17:43.200]   Get this one. This is the. Yeah. Look at that. It was a Tom Warren whoever wrote the.
[00:17:43.200 --> 00:17:48.720]   Tom Warren. Yeah. So, yes, it's center it. Yeah. Get the line out of the way.
[00:17:48.720 --> 00:17:54.560]   So on the left is the pixel 4, which I think looks better. It's a little darker
[00:17:54.560 --> 00:17:58.960]   than the iPhone. And this is portrait mode. Now you could scroll all the way to the left.
[00:17:58.960 --> 00:18:05.120]   That's the iPhone version. Yeah. That's too blown out. It's blown out. And he just has.
[00:18:05.920 --> 00:18:10.160]   It looks like a can. He looks. He doesn't look like a person almost. He looks.
[00:18:10.160 --> 00:18:14.880]   Oh, right. Like that's HDR, but Apple will get better with this in time.
[00:18:14.880 --> 00:18:18.240]   Yeah. This is pretty quick. Keep working that pretty deep fusion. I think.
[00:18:18.240 --> 00:18:23.760]   And you could get this out of the pixel 4 really easily just by just by pushing one slider in
[00:18:23.760 --> 00:18:30.400]   their photos. Just by just this is just push the shadows up a tiny bit and this would become
[00:18:31.440 --> 00:18:38.400]   this shot in a second. My only beef with the pixel shot is the white balance. Looks a little too cool.
[00:18:38.400 --> 00:18:44.000]   But again, that's my preference. Again, and again, they've got a slider for that.
[00:18:44.000 --> 00:18:50.000]   Yeah. Or you can, you know, do it post. I mean, honestly, any picture you get can
[00:18:50.000 --> 00:18:56.560]   but but can be changed. But what I think the point of all of this is most people aren't going to do
[00:18:56.560 --> 00:19:02.480]   post processing. Oh, the hair on this is interesting. Tom said the color was accurate on the pixel,
[00:19:02.480 --> 00:19:07.600]   but the detail was more accurate with the iPhone. So. And it's definitely warmer.
[00:19:07.600 --> 00:19:13.840]   Super warm versus cold. Yeah. He says though, that's the color that one of the pixel color is
[00:19:13.840 --> 00:19:19.360]   the actual color for hair. So see the thing is to me, and I'm not a professional photographer. So
[00:19:19.360 --> 00:19:25.200]   and you you tell me if I'm wrong, it's not all about just capturing a photo of what you saw these
[00:19:25.200 --> 00:19:31.360]   days. It's being creative and making the picture the way you want it to be. Like I do a lot of approach.
[00:19:31.360 --> 00:19:37.280]   Is that? Yeah. That is exactly my approach. There's a lot of times I'm out because I like doing a
[00:19:37.280 --> 00:19:43.280]   lot of street photography first and foremost. And I'll snap someone's image while I'm out there.
[00:19:43.280 --> 00:19:49.680]   And when I get back to my editing station and what have you, I'm visualizing that moment when I was
[00:19:49.680 --> 00:19:53.520]   out there and what I felt and that's what you're trying to duplicate that. Right. And that's what
[00:19:53.520 --> 00:19:58.800]   goes into the post-process. Anybody who's ever taken a picture of a sunset knows that what you
[00:19:58.800 --> 00:20:05.440]   felt and what you saw cannot be captured in the camera. Nope. It just can't. Your eyes are much
[00:20:05.440 --> 00:20:10.400]   better at receiving the light and processing it than than these high dollar cameras are.
[00:20:10.400 --> 00:20:15.200]   The point though is that most people by a camera phone don't want to do posts. They want to take
[00:20:15.200 --> 00:20:22.880]   a picture and it's done. A filter at best. So I would imagine both Apple and Google's real goal is
[00:20:23.360 --> 00:20:30.240]   not to sneeze during the show. No, whatever bless you. Thank goodness I had the phone to capture all that.
[00:20:30.240 --> 00:20:34.480]   Oh yeah. Holyophobic coating. Yeah. Well, look, it came right off.
[00:20:34.480 --> 00:20:47.440]   The Apple and Google's goal is to make it be, this is the, we call it IQ image quotient.
[00:20:48.160 --> 00:20:54.240]   That this is the best out of the box by itself without any posts. This is what people,
[00:20:54.240 --> 00:20:58.080]   real people, regular people. And I presume they focus group in all sorts of stuff.
[00:20:58.080 --> 00:21:04.800]   Samsung does a lot of post-processing in the camera and a lot of people hate what Samsung does
[00:21:04.800 --> 00:21:13.120]   with their images. So it would now be a good time to show an unedited photo from the Pixel 4 XL.
[00:21:13.120 --> 00:21:18.400]   One that somebody named Kevin Tofel might have snapped. I'm not naming names. Yeah, let's see.
[00:21:18.400 --> 00:21:22.240]   Do you have a card? Name and names. I have a link there.
[00:21:22.240 --> 00:21:31.120]   Let's see. Where is that? I can line 42. I get that's the easiest way to find things.
[00:21:31.120 --> 00:21:35.440]   I took the Pixel 4 XL outside last night. See it. I have it here.
[00:21:35.440 --> 00:21:39.440]   That's not line 42 anymore. But yeah, it's moved down. I have it. It says,
[00:21:39.440 --> 00:21:43.040]   as soon as it loads and Google Photos, we'll see it.
[00:21:43.040 --> 00:21:48.400]   So I wanted to see the astrophotography that they talked about there.
[00:21:48.400 --> 00:21:56.960]   And this is, I have a lot of light pollution in my area. I took the Pixel 4 XL, put it on a tripod,
[00:21:56.960 --> 00:22:02.320]   didn't set it up for night set or anything, it just said, take a photo. And it said,
[00:22:02.320 --> 00:22:07.520]   okay. And it said its own timer for the exposure at this particular one, I think, was three minutes.
[00:22:07.520 --> 00:22:14.080]   What? Three minutes. It will go up to four. So you don't have to say, was it pitch dark when you
[00:22:14.080 --> 00:22:21.360]   took this? It was only 8 to 8.15 PM. So not, it was dark, but not as dark as it should, you know,
[00:22:21.360 --> 00:22:28.400]   it should be if I was taking real astrophotography photos. In any case, if you zoom in, if you can,
[00:22:28.400 --> 00:22:33.200]   because it doesn't look that impressive there, but now when you zoom in and start looking around,
[00:22:34.400 --> 00:22:38.640]   you can see I've got a lot of points of light. That's kind of neat. And there's a lot of light
[00:22:38.640 --> 00:22:44.720]   pollution where you are. Yes. Yes. I mean, I've been scrolling around on my phone with this and going,
[00:22:44.720 --> 00:22:51.680]   wow. Are there a million points of light? A million points of light? Yep. Wouldn't be prudent.
[00:22:51.680 --> 00:22:58.240]   So you would want to go somewhere where there's no light pollution from cities and stuff. Yeah.
[00:22:58.240 --> 00:23:02.320]   Really get that. Absolutely. Yeah. I'll never see the Milky Way where I live, but in, you know,
[00:23:02.320 --> 00:23:08.080]   there's no sunlight. Because I'm going to be somewhere like that. I'm in the middle of the
[00:23:08.080 --> 00:23:14.080]   Dead Sea. I'm going to be in places like that. Yeah. I am going to be in the pyramids in Egypt.
[00:23:14.080 --> 00:23:18.080]   I'm going to be Petra and Jordan. I'm going to be in Athens. And I don't have a pixel four and
[00:23:18.080 --> 00:23:24.160]   it kills me. I would really love that you do have that a seven or five a good camera. And I have an
[00:23:24.160 --> 00:23:30.640]   iPhone pro, you know, 11 pro max. I think the bulb mode. You know, I'll take, I'll take good
[00:23:30.640 --> 00:23:36.320]   pictures, but I just would love to have that one. I'm going to bring a pixel three XL.
[00:23:36.320 --> 00:23:43.840]   This is the camera to see the pocket. So close. My pixel four will come while I'm gone.
[00:23:43.840 --> 00:23:49.680]   In addition to the way it's handled in the light, look at the clarity of the foliage right there.
[00:23:49.680 --> 00:23:54.400]   Now what's interesting is I'm going to bet that that foliage in those three minutes moved a little
[00:23:54.400 --> 00:24:00.240]   bit. Exactly. They're not going to be complete. Well, I would say the stars probably did too,
[00:24:00.240 --> 00:24:06.080]   which tells you instead of seeing, you know, strings of light, right? Exactly. It's
[00:24:06.080 --> 00:24:10.560]   compensating for all that based on the exposure time. That's just beautiful. Nice work. So what
[00:24:10.560 --> 00:24:16.480]   that's crazy. Wait, I took the photo. Yeah. What are you talking about? Oh, yeah. Nice work.
[00:24:16.480 --> 00:24:19.360]   Mr. Tuffle. All I do is hit a button and walk away.
[00:24:19.360 --> 00:24:26.640]   So, and I think that was the goal. There's lots more to talk about that event had a lot.
[00:24:26.640 --> 00:24:29.600]   And I know, Kevin, you probably want to talk about the pixel book go.
[00:24:29.600 --> 00:24:34.880]   The she's just not here because I'd love to hear what Jeff has to think about the pixel book.
[00:24:34.880 --> 00:24:41.040]   Hold your thoughts because I want to do it. I'd add. But when we come back, we'll talk about
[00:24:41.040 --> 00:24:47.280]   it. It's funny because nine to five Google was right. I mean, they had the images and
[00:24:47.280 --> 00:24:52.960]   everything before the event took all the surprise. Oh, the way. Don't. Yes. Yes. But I had the very
[00:24:52.960 --> 00:24:58.240]   first image and they, yeah, whatever. You had it. Sorry about
[00:24:58.240 --> 00:24:59.960]   K
[00:24:59.960 --> 00:25:04.960]   I get no listen, I give them a lot of credit. They came up with the whole device. They had a prototype
[00:25:04.960 --> 00:25:10.480]   and images. I had some of the first images earlier in the year, but kudos to them because they really
[00:25:10.480 --> 00:25:16.800]   they killed it. That was awesome. I dropped the wait a minute. I was wondering. I'm like,
[00:25:16.800 --> 00:25:25.280]   what is we doing? Thank you. Thank you. Thank you. He came all the way from Melbourne, Australia
[00:25:25.280 --> 00:25:29.280]   to pick up my ad copy. I appreciate it. Oh,
[00:25:29.280 --> 00:25:37.760]   Stephen Wozniak, ladies and gentlemen in the studio today. Our show today brought to you by
[00:25:37.760 --> 00:25:44.000]   Express VPN. So I'm going to trip. Maybe you heard. I know I talk about it too much. I'm sorry.
[00:25:44.560 --> 00:25:48.000]   But I don't blame you. I'm going to be in hotels. I'm going to be in coffee shops. I'm going to
[00:25:48.000 --> 00:25:55.520]   get in Wi-Fi wherever I can get it in some pretty sketch places in Egypt, in Israel, in Dubai. I
[00:25:55.520 --> 00:26:00.480]   want to protect myself. Lots of snoop and eyeballs. You don't know what you're going to get. I'm
[00:26:00.480 --> 00:26:04.480]   bringing Express VPN. You better believe I'm bringing Express VPN. It's already on all my
[00:26:04.480 --> 00:26:10.720]   devices anyway. I love Express VPN. It is a VPN, a virtual private network that protects your
[00:26:10.720 --> 00:26:18.560]   privacy, keeps you secure no matter where you are, even at home. And I have to say, it's so fast.
[00:26:18.560 --> 00:26:23.120]   When sometimes when you use a VPN, you feel like, Oh, it's I'm slogging through molasses. You're
[00:26:23.120 --> 00:26:28.240]   not Express VPN. They have servers all over the world. So you're, you know, you can use a server
[00:26:28.240 --> 00:26:33.040]   near you or a server in a country that you want to appear in. If I want to watch Netflix,
[00:26:33.040 --> 00:26:36.880]   while I'm in Dubai, I'll just log in in the United States and I'm going to be able to watch my
[00:26:36.880 --> 00:26:45.520]   Netflix or my BBC or whatever. But it's fast too. In fact, I have a perfect proof of that because
[00:26:45.520 --> 00:26:49.920]   I turned it on on my iPhone. It's really easy to turn it on and off with the Express VPN app. No
[00:26:49.920 --> 00:26:56.320]   settings changes or anything. Just press a button, click your your secure. But I forgot I turned it
[00:26:56.320 --> 00:27:03.280]   on and I left it on for a couple of days at home. I didn't even notice I didn't even notice. I
[00:27:03.280 --> 00:27:09.120]   don't think you can do that with any other VPN. It is it is fast. We know it's secure because they
[00:27:09.120 --> 00:27:14.000]   have had audit they completed a third part third party independent audit that says, yes,
[00:27:14.000 --> 00:27:18.240]   their privacy policy is exactly what they say they do not log they do not keep track of what
[00:27:18.240 --> 00:27:23.680]   you're doing you can even pay for it with Bitcoin if you want to be completely anonymous. Furthermore,
[00:27:23.680 --> 00:27:29.840]   they use this new trusted server technology, which in effect puts the VPN server on their end
[00:27:30.800 --> 00:27:36.080]   in a sandbox. It cannot write to the hard drive. It lives in memory. When you log out, it
[00:27:36.080 --> 00:27:43.760]   shut down and a new one gets started. So there is no record of your visit and the third party
[00:27:43.760 --> 00:27:50.640]   audit confirmed. That's exactly what their server technology does exactly what it said it would do.
[00:27:50.640 --> 00:27:58.320]   Trusted server works 160 locations, 94 countries. CNET said it's their number one VPN provider.
[00:27:58.320 --> 00:28:05.600]   I say it's the number one VPN. I love it. 30 day money back guarantee. So if you're not 100%
[00:28:05.600 --> 00:28:11.920]   satisfied, you no charge internet without borders internet that's secure internet that's anonymous.
[00:28:11.920 --> 00:28:17.920]   This is what you're looking for in a virtual private network. Express VPN. I want you to try it
[00:28:17.920 --> 00:28:24.800]   with a very nice deal that brings it below $7 a month. Less than seven bucks a month right now.
[00:28:24.800 --> 00:28:30.400]   If you go to express VPN.com/twig, you'll get three months, three additional months free when you buy
[00:28:30.400 --> 00:28:36.320]   a one year package. That's the best deal. Three additional months free when you buy a one year
[00:28:36.320 --> 00:28:40.640]   package and you will want to. But as I said, you got a 30 day money back guarantee. Express
[00:28:40.640 --> 00:28:48.960]   VPN.com/twig. Do that TWIG because then they'll know you saw it here and that's good for us.
[00:28:48.960 --> 00:28:54.720]   We really like these guys. Express really a good company doing a great job. It's the one I use
[00:28:54.720 --> 00:29:00.720]   the one I recommend. Windows Mac iOS Android. You can even put it Linux. Yes, you could even put it
[00:29:00.720 --> 00:29:06.880]   on your router router, which I think is a really good way to use a VPN. So everybody in the house
[00:29:06.880 --> 00:29:15.840]   is safe. They have a VPN for your Wi-Fi router express VPN.com/twig. They really know what they're doing.
[00:29:21.040 --> 00:29:27.680]   All right. It has that funny grippy rubber bottom. And I'm not talking about it.
[00:29:27.680 --> 00:29:36.800]   I'm talking about the Pixelbook go. You nailed it right, Kevin? Everything you thought.
[00:29:36.800 --> 00:29:44.560]   Well, yes, because I have been tracking the baseboard that's inside there called Atlas for
[00:29:44.560 --> 00:29:51.520]   about 18 months. Oh, wow. And I bring that up for a very specific reason. And I'll get to that in a
[00:29:51.520 --> 00:29:58.320]   few minutes. I wrote a post about three months ago, maybe even four months ago, because based on
[00:29:58.320 --> 00:30:05.760]   what I was tracking, based on the code commits I saw for Alice, and based on geek bench benchmarks,
[00:30:05.760 --> 00:30:12.080]   I wrote a post saying it may not make sense to wait for the next Pixelbook. And I didn't.
[00:30:12.080 --> 00:30:20.080]   I bought a higher end Acer Chromebook spin with 16 gig of RAM for much less than Google is selling
[00:30:20.080 --> 00:30:29.360]   this for with 16 gig of RAM. This the Pixelbook go is not for me. Who's it for? Well, that's the
[00:30:29.360 --> 00:30:36.240]   question. It doesn't have a pen. It doesn't have a fingerprint reader. No, it is just as expensive
[00:30:37.760 --> 00:30:41.040]   as a Pixelbook, right? It's pretty much the high price spread.
[00:30:41.040 --> 00:30:47.520]   Base it is because you can go up to 1399 and get the 4K screen and 16 gig of RAM and a core i7.
[00:30:47.520 --> 00:30:55.200]   Wow. I have a couple issues with this. First of all, I think, and I will be talking to Google
[00:30:55.200 --> 00:30:58.640]   later this week, actually. I'm going to ask this question. I don't know if they're going to answer
[00:30:58.640 --> 00:31:06.640]   it. Did the plans for Atlas change? Because there were a lot of early code commits that showed
[00:31:06.640 --> 00:31:12.800]   that it was going to have faster memory. I'm sorry, faster storage with NVMe. That was yanked.
[00:31:12.800 --> 00:31:18.640]   It's all really meant to get an answer to that. All I can do is ask. I don't know.
[00:31:18.640 --> 00:31:25.600]   I don't know. I suspect it was changed because there are several high-end Chromebooks out there
[00:31:25.600 --> 00:31:31.360]   that cost less, give you more performance, and they weren't there 18 months ago. They're available
[00:31:31.360 --> 00:31:38.880]   now, obviously. What Google basically did, in my opinion, it's a fact that they took the guts of
[00:31:38.880 --> 00:31:48.240]   the Pixel Slate from a year ago, repackaged them into the Pixelbook Go and made it a clam shell.
[00:31:48.240 --> 00:31:53.920]   Yes, they reduced the price because with the Pixel Slate, you had to pay an extra $150 to $200
[00:31:53.920 --> 00:32:03.440]   for a keyboard. I paid for a Core i5 with 8GB of RAM, and then I paid another $200 for a keyboard.
[00:32:03.440 --> 00:32:06.880]   Obviously, this comes to the keyboard because it's a clam shell. It's a laptop.
[00:32:06.880 --> 00:32:13.200]   But if you look, and I don't know if we have any images, if you look at the Pixelbook Go from the
[00:32:13.200 --> 00:32:21.920]   side, I have a Pixel Slate here, and it looks just like this from the side. The USB ports are in the
[00:32:21.920 --> 00:32:29.680]   same spot, everything. All the guts of the Slate are in here. The display is here, too. They remove
[00:32:29.680 --> 00:32:36.480]   the display and put in the new HushType keyboard on top of where the display was and added a display
[00:32:36.480 --> 00:32:45.440]   for the clam shell and called it a day. I'm just not overwhelmed by this decision, but I get it
[00:32:45.440 --> 00:32:50.880]   because there's perfect picture. That's exactly what the Slate looks like from the side.
[00:32:51.520 --> 00:32:59.040]   The base of the Pixelbook Go. I get it. I think the market changed on them in the last 18 months,
[00:32:59.040 --> 00:33:04.400]   and they decided, "We can't compete on price because we don't get the bulk discounts on Intel
[00:33:04.400 --> 00:33:08.080]   processors that everybody gets because we don't sell a lot of laptops compared to
[00:33:08.080 --> 00:33:14.800]   Asus or Acer or Lenovo or Dell." They changed it up and they changed the target audience to...
[00:33:16.160 --> 00:33:21.120]   They say people on the go, but my comment to that was, "Aren't we all on the go?" I mean,
[00:33:21.120 --> 00:33:28.160]   really, that's kind of lame, but it is lightweight. It is thin, but I do think it's expensive
[00:33:28.160 --> 00:33:34.720]   for what you're getting. The chips inside here are still the older Y Series 8th gen Intel processors.
[00:33:34.720 --> 00:33:39.920]   They're not going to be used by developers. They're not going to be used in enterprise,
[00:33:39.920 --> 00:33:41.680]   not with the folks. Would the stadia folks want this?
[00:33:42.880 --> 00:33:47.360]   I thought maybe, and I put a post out the day before the event, saying maybe it's a showcase for
[00:33:47.360 --> 00:33:54.240]   stadia, and we'll know if they include a year's worth of stadia access and so on. Obviously,
[00:33:54.240 --> 00:33:59.840]   they didn't do that. I was wrong on that and whatever, but I was just trying to put the pieces
[00:33:59.840 --> 00:34:06.000]   together. Instead, this is basically a Pixelbook for the masses, but it's a Pixelbook that's
[00:34:06.000 --> 00:34:12.560]   a year old for the masses, if that makes sense, because the interns are just not that exciting.
[00:34:13.440 --> 00:34:16.720]   But the outside with the sticky rubber bottom is neat.
[00:34:16.720 --> 00:34:23.600]   Yeah. That's why I think maybe not masses. Maybe it's a student laptop.
[00:34:23.600 --> 00:34:26.640]   Yes, I would agree with that. It's a student Chromebook.
[00:34:26.640 --> 00:34:31.760]   Students are going to lose pens. Students don't want or need fingerprint. They do want sticky
[00:34:31.760 --> 00:34:38.800]   bottoms. Some of them have sticky bottoms. It depends on the age of the student, I guess,
[00:34:38.800 --> 00:34:42.320]   but this seems like the problem is it's not student priced.
[00:34:42.320 --> 00:34:49.040]   Not starting at 650 for the core M3 with the Giga Brown.
[00:34:49.040 --> 00:34:55.600]   Air compared to any MacBook that you'd be buying for a student. I think this is a perfect student.
[00:34:55.600 --> 00:35:00.400]   No, but the point is you could go get the Acer that Kevin forgot for 650
[00:35:00.400 --> 00:35:05.760]   that's got higher specs in every respect. There are plenty of Chromebooks that have better specs
[00:35:05.760 --> 00:35:09.280]   for less. You don't have a gripy bottom.
[00:35:09.280 --> 00:35:15.360]   I think the appeal here, compared to the higher performing Chromebooks that you can get for
[00:35:15.360 --> 00:35:21.520]   comparable or lower prices, it's light and thin compared to those. This is literally a 10th of a
[00:35:21.520 --> 00:35:26.720]   pound lighter than the Pixelbook was. And that was pretty light at 2.4. This is 2.3 pounds.
[00:35:26.720 --> 00:35:32.560]   It's a little fashionable with the color 10 AP displays, perfectly fine for students.
[00:35:34.240 --> 00:35:38.080]   If this came in at $4.99, wow, then we'd have a game changer, I think.
[00:35:38.080 --> 00:35:43.360]   650 to start, and then 850 just to jump up to the core i5.
[00:35:43.360 --> 00:35:49.760]   I noticed during the keynote, they didn't mention the price of them. I had to wait until the keynote
[00:35:49.760 --> 00:35:55.760]   was over and look it up to see the price. And I was really disappointed to see that i5 pricing.
[00:35:55.760 --> 00:36:04.080]   And that's with 8GB. If you want 16GB, now you jump up to at least $9.99. And then if you want the
[00:36:04.080 --> 00:36:09.120]   4K display, that is only available on the Core i7. So you have to pay for the i7.
[00:36:09.120 --> 00:36:11.040]   So you have to pay $8,000, right?
[00:36:11.040 --> 00:36:12.960]   And they're here at a MacBook.
[00:36:12.960 --> 00:36:17.840]   Right, in 1399 at that point with 256 giga storage.
[00:36:17.840 --> 00:36:24.160]   It's just that I think they kind of got pushed out of their own market by their partners, quite
[00:36:24.160 --> 00:36:24.560]   honestly.
[00:36:24.560 --> 00:36:30.000]   Well, that's because Google isn't a hardware company. I mean, and they were trying to
[00:36:31.600 --> 00:36:38.240]   we'll get to that, I'm sure. But a lot of people I talked to didn't really disagree with me. And
[00:36:38.240 --> 00:36:44.640]   it was almost as if they put this out because it was expected to have a Pixelbook. So they just
[00:36:44.640 --> 00:36:46.400]   met their time-
[00:36:46.400 --> 00:36:50.080]   They were expected to have a Pixel watch too. They didn't bother with that.
[00:36:50.080 --> 00:36:51.200]   Yeah, I wanted to watch.
[00:36:51.200 --> 00:36:54.240]   The expectation doesn't necessarily mean they're going to do it.
[00:36:54.240 --> 00:37:01.440]   The good news is for Chrome OS that there are a lot of companies making Chrome OS devices.
[00:37:02.000 --> 00:37:02.320]   Yes.
[00:37:02.320 --> 00:37:06.560]   It's Google's can declare victory. They don't need to make them.
[00:37:06.560 --> 00:37:07.600]   No.
[00:37:07.600 --> 00:37:09.680]   Of course, that's true of Android too, isn't it?
[00:37:09.680 --> 00:37:11.920]   Why do they keep making phones? Especially.
[00:37:11.920 --> 00:37:14.480]   And I saw a lot of people complaining about the price.
[00:37:14.480 --> 00:37:17.760]   The Pixel 4 is a fairly expensive phone.
[00:37:17.760 --> 00:37:23.040]   I really think their focus was much more on design this year than any year before.
[00:37:23.040 --> 00:37:24.320]   For the Pixelbook.
[00:37:24.320 --> 00:37:29.040]   The Pixelbook go for the buds for the, I mean, the 4 and all of their products.
[00:37:29.040 --> 00:37:32.480]   That is why they brought out their lead designer, Ivy Ross, to talk about it.
[00:37:32.480 --> 00:37:37.920]   Yeah, they really told us a design story this year rather than a specs story.
[00:37:37.920 --> 00:37:39.920]   But really, what is this?
[00:37:39.920 --> 00:37:40.400]   And that's...
[00:37:40.400 --> 00:37:41.280]   Go ahead.
[00:37:41.280 --> 00:37:44.880]   Well, that's what Apple's done for decades. So if you look at, I mean,
[00:37:44.880 --> 00:37:49.520]   think about all the times Johnny Ives is coming on and said aluminium in an Apple event, right?
[00:37:49.520 --> 00:37:55.840]   So they're just, they're following along a bit with that and trying to, I mean,
[00:37:55.840 --> 00:37:59.520]   in a way this is good because it's Google trying to be more human and approach people
[00:37:59.520 --> 00:38:02.400]   where they're at as opposed to like throwing their engineering
[00:38:02.400 --> 00:38:06.880]   everything over the wall and just saying, "Here you go."
[00:38:06.880 --> 00:38:13.360]   I didn't feel that way about the Pixelbook far as you're saying, they're acting human.
[00:38:13.360 --> 00:38:17.840]   I felt more that way when they mentioned the Nest information and how they worked with the
[00:38:17.840 --> 00:38:23.680]   mics and making it feel more comfortable in the home and making home feel a little more natural
[00:38:23.680 --> 00:38:28.720]   to have technology in there and giving you that dream world of the Jetsons where you can just
[00:38:28.720 --> 00:38:29.920]   speak into the air.
[00:38:29.920 --> 00:38:35.920]   Possibly the best thing they announced as somebody who has a lot of Nest devices is the Nest Cloud
[00:38:35.920 --> 00:38:43.280]   Recording Plan, the new flat rate pricing on cloud recording for as many devices as you have,
[00:38:43.280 --> 00:38:50.000]   $10 a month for a 10-day history, $30 a month for a 30-day history, $5 a month for a 5-day history.
[00:38:50.480 --> 00:38:55.280]   And see, I think that's brilliant because they're going to sell a lot more cameras because in the
[00:38:55.280 --> 00:39:02.000]   past every camera you had to have a subscription for. I have three Nest cameras of Hello Doorbell
[00:39:02.000 --> 00:39:09.600]   and by the way, Stacey, I love, you know, I replaced the ring with a hello on your recommendation.
[00:39:09.600 --> 00:39:14.000]   The best part is, first of all, there's no delay. There's no lag between somebody at the door ringing
[00:39:14.000 --> 00:39:19.920]   it. And because I have a home hub, Nest Home Max, Hub Max, when they press the doorbell,
[00:39:20.320 --> 00:39:27.200]   the Max immediately puts video up and says, "Someone's at the front door." And I can see them
[00:39:27.200 --> 00:39:33.280]   immediately. Yeah. Yeah. It's so much better. A little thing, right? Yeah. That's why I told
[00:39:33.280 --> 00:39:37.600]   you to get it. You were smart. That was exactly the right recommend. It's like night and day,
[00:39:37.600 --> 00:39:42.640]   and I thought that Nest was amazing. I mean, I was really happy with the Nest, but there was always
[00:39:42.640 --> 00:39:50.560]   that lag. You always saw the back of the AWS guys. He drove off. There he goes. By the way,
[00:39:50.560 --> 00:39:56.080]   those are the old plans. The new plan is six and $12. Oh, oh, I'm sorry. That was the old plan.
[00:39:56.080 --> 00:40:03.920]   Right. The new plan, I'm sorry, $6 for 30 days. Compare that to $5 for five days, $12 for 60 days.
[00:40:03.920 --> 00:40:07.360]   You're exactly right. That made me happy. Now won't be available till next year.
[00:40:08.480 --> 00:40:13.600]   But you will get the option to switch, and I will immediately because I have four devices.
[00:40:13.600 --> 00:40:18.880]   But they're smart because I'm much more likely to buy more now. It's all about the ecosystem.
[00:40:18.880 --> 00:40:20.800]   Yeah. Absolutely. It's a little bit of a system play.
[00:40:20.800 --> 00:40:25.120]   Did you know Leo? We talked about this. Stacy and I talked about this this morning on our
[00:40:25.120 --> 00:40:31.040]   podcast. Did you know the Nest is always recording? Yes. That's the other difference. The hello
[00:40:31.040 --> 00:40:37.280]   are the women. The Nest is always recording. No, the hello is always recording. Nest hello. Yes.
[00:40:37.280 --> 00:40:41.840]   Nest hello. Oh, yeah. The ring is not. And that was always the other problem with the ring.
[00:40:41.840 --> 00:40:47.520]   It only recorded when there was motion. So yeah, I can always, and that's probably why it's quick
[00:40:47.520 --> 00:40:53.120]   to pick up a picture. It doesn't have to boot turn on turn on the camera. Wake up.
[00:40:53.120 --> 00:40:59.200]   How long? Wake up, Deborah. Yeah. I think that is really, really nice. I just
[00:40:59.200 --> 00:41:05.760]   I'm a big fan of that. And it makes you want to get more nest hubs. It makes you want to, you know,
[00:41:05.760 --> 00:41:11.200]   I'm all in now on the ecosystem. That's the Amazon approach. Hooky and yeah,
[00:41:11.200 --> 00:41:15.360]   but Amazon, I think, missed the boat a little bit. Ring is Amazon. They've acquired all the
[00:41:15.360 --> 00:41:20.320]   stuff. They've got the they've got everything. But I think that nest is actually doing a better job.
[00:41:20.320 --> 00:41:24.640]   That's that's been our I mean, that's been kind of our experience.
[00:41:24.640 --> 00:41:31.840]   But my family is so conditioned to Madam A, right, even though I have Google stuff around the house,
[00:41:31.840 --> 00:41:37.440]   they don't nobody says hello. You know Guillermo. Everybody's saying hello. Shlomo.
[00:41:37.440 --> 00:41:43.120]   Micah and Matthew on their smart tech today are trying to come up with new names. But Andy
[00:41:43.120 --> 00:41:51.760]   and I co already says, serious slo mo Google is Guillermo. Echo is Al Alio. Sh
[00:41:51.760 --> 00:41:59.840]   Alio. Shio. Alio. Shio. Alio. Shio. And I don't know who you Cortana is, but nobody ever says it.
[00:41:59.840 --> 00:42:08.800]   So I like Madam A. I like your mad amazing. Actually, he calls Cortana Bixby and Bixby Cortana.
[00:42:08.800 --> 00:42:13.520]   That helps confuse the issue. I don't know. I don't know. Again, Bixby never comes up in
[00:42:13.520 --> 00:42:20.720]   conversation. It's just a jab. It's just a jab. You were talking Stacy about new chips. Is this a
[00:42:20.720 --> 00:42:27.280]   chip that's appearing in the phone? Well, to be clear, we think it's a new chip. They didn't talk
[00:42:27.280 --> 00:42:30.640]   much about it. Did they Kevin? The machine learning chip in the new nest.
[00:42:30.640 --> 00:42:36.080]   Oh, this is in the nest. This is in the nest. And I do have one. I have not even
[00:42:36.080 --> 00:42:41.040]   powered it up yet. Can I just say I like that color much better than the.
[00:42:41.040 --> 00:42:45.840]   Yeah. Can I just say I hate Kevin Tofel because he got everything in a bag.
[00:42:45.840 --> 00:42:51.040]   I guess I should put that core I seven pixel but go aside and
[00:42:51.040 --> 00:42:56.800]   shut up. Turn around the the new mini. Doesn't it have a little hook? No, Kevin?
[00:42:56.800 --> 00:43:02.240]   It does. It does have a hook. Why do they do that from day one? What does an Amazon do that in the
[00:43:02.240 --> 00:43:08.560]   dot? That's so obvious. Yeah. Well, I think because a lot of people are making third parties
[00:43:08.560 --> 00:43:14.080]   are making little holders and all that and magnet. And magnet now. Is that what you do?
[00:43:14.080 --> 00:43:19.360]   I want to pop that on my well, I just like I love my cameras because of the magnet now
[00:43:19.360 --> 00:43:26.080]   because I can stick it on bridges and banisters outdoor cam does that it has you you have a
[00:43:26.080 --> 00:43:28.560]   mount but then that makes it very easy to swivel in position.
[00:43:28.560 --> 00:43:34.640]   But I just like the idea. I feel like that's a natural thing to do with those little minis
[00:43:34.640 --> 00:43:38.720]   is put a hook in the wall hanging on there. You'll have a wire coming down to the plugs. You have
[00:43:38.720 --> 00:43:44.240]   to hang it over a plug. But that's just a natural out of the way thing. My counter space is kind of
[00:43:44.240 --> 00:43:52.560]   dominated by echoes and homes and it's just it'll it'll keep for your breakfast laptop because I
[00:43:52.560 --> 00:43:58.000]   don't have my blender anymore. And my breakfast with the the acoustics as well, I would think
[00:43:58.000 --> 00:44:01.760]   for music. Oh, good point. Hey, how does it sound? Have you played it? Have you
[00:44:01.760 --> 00:44:06.560]   am I not only speaking any sounds? I don't expect these things to plug it in dummy.
[00:44:06.560 --> 00:44:12.320]   I have I honestly I have been on the go like you would not believe. So they said better sound.
[00:44:12.320 --> 00:44:19.200]   They said twice the base whatever that means. What is what is two X base feels like twice the
[00:44:19.200 --> 00:44:25.920]   base? I really say I don't know. Is it twice is loud? Twice is rich? What is it like three
[00:44:25.920 --> 00:44:31.920]   inch speakers inside of these? They can't be a good base. Yeah, it's maybe it doesn't sound good,
[00:44:31.920 --> 00:44:37.920]   but it does sound better. The original the original sounded really not awesome.
[00:44:37.920 --> 00:44:41.440]   Okay, better than always better than the dot though, right? The dot was the worst.
[00:44:41.440 --> 00:44:48.480]   Yeah. Yeah. Yeah. I don't listen to music of a dot. So I'm like sure.
[00:44:48.480 --> 00:44:53.840]   Got better with their their their newest dot got a little better and a little bit on the original
[00:44:53.840 --> 00:44:58.720]   dot. That's the yeah, they're whatever the dot three, whatever the Amazon if you give the
[00:44:58.720 --> 00:45:04.800]   original back to them, they'll give you like five bucks. What? Trades in? Yes. Trades in. Yeah.
[00:45:04.800 --> 00:45:07.440]   Yes. So Kevin plug it in. I want to hear it.
[00:45:07.440 --> 00:45:13.280]   Just put them on the spot. Why don't you? All right. Yeah. I want to hear I want to hear if
[00:45:13.280 --> 00:45:20.160]   it's got two X base, whatever that is. I go home. I can tell you that I'm very impressed by the
[00:45:20.160 --> 00:45:27.040]   yes, the color, but these mesh coverings. Did you happen to notice that they talked about
[00:45:27.040 --> 00:45:34.080]   they are using recycled plastic bottles? Yeah. So one plastic bottle makes two mesh covers for
[00:45:34.080 --> 00:45:39.360]   the nice. They're nice. That's so good. They really emphasize how they're you know,
[00:45:39.360 --> 00:45:44.160]   they're buying carbon credits or zero-vucion equivalent. So this is this is part of the
[00:45:44.160 --> 00:45:48.080]   grand trust strategy. And we'll talk about this when we start talking about ambient computing.
[00:45:48.080 --> 00:45:55.040]   But this is this is part of the we're not evil. We love you. We love the environment. We value
[00:45:55.040 --> 00:46:04.080]   what you value. Yes. So does GLADOS. Yeah. Under 50 million in investment or renewable energy.
[00:46:04.080 --> 00:46:07.760]   You know, when I think this is actually important because when I think about Stadia,
[00:46:09.200 --> 00:46:16.960]   all of the work for gaming in Stadia is done on Google servers out there somewhere.
[00:46:16.960 --> 00:46:21.840]   That's nice. There's no heat. There's no, you know, you don't have to pay attention to it at
[00:46:21.840 --> 00:46:26.480]   your electric bill. But somewhere there are massive gaming machines. Somebody's paying
[00:46:26.480 --> 00:46:32.560]   somewhere in North Carolina. You know, there's these giant farms. And I honestly think that
[00:46:34.320 --> 00:46:39.760]   you know, we've done it in so many ways in our lives. But that it's doing us a disservice
[00:46:39.760 --> 00:46:45.040]   because we're getting disconnected from the actual cost, the actual energy cost of what we're
[00:46:45.040 --> 00:46:50.080]   doing. And I just think if all these people subscribe to Stadia, they're going to have to build more
[00:46:50.080 --> 00:46:56.400]   and more centers and network operations centers. There is a point at which it won't make sense.
[00:46:56.400 --> 00:47:00.320]   And then we'll start seeing, and this is why we're talking about the computing going to the edge
[00:47:00.320 --> 00:47:05.920]   very broadly is because right now, if you look at the data generated by things at the edge or
[00:47:05.920 --> 00:47:12.160]   things trying to consume data, you know, CDNs happen because we were trying to consume data.
[00:47:12.160 --> 00:47:14.880]   So it moved out. We'll see that happen probably with Stadia.
[00:47:14.880 --> 00:47:19.120]   And in Syria, you're going to move those operations centers somewhere where it's renewable energy.
[00:47:19.120 --> 00:47:22.640]   You know, it's hydro because that's cheap. All right.
[00:47:22.640 --> 00:47:30.000]   Oh, yeah. And in some ways, it's awesome because Google and Facebook and Microsoft have invested
[00:47:30.560 --> 00:47:37.280]   a lot of money and intelligence in creating the best performance per watt.
[00:47:37.280 --> 00:47:40.560]   It's in their interest. It's in their economic interest. Yeah.
[00:47:40.560 --> 00:47:45.200]   So if we're all running these, it's kind of like Bitcoin mining when all these people were
[00:47:45.200 --> 00:47:51.200]   running crappy Bitcoin, you're like, no, no, no, no, no. It's too much cost right there on the energy
[00:47:51.200 --> 00:47:57.120]   side. Let somebody who knows what they're doing, do it. Which is worse. A million Xboxes or a
[00:47:57.120 --> 00:48:01.440]   million people playing on servers. I'm pretty sure I'm pretty sure Google is going to spend a lot
[00:48:01.440 --> 00:48:08.160]   less money on their on their machine than I spent on my Stadia launches November 19th,
[00:48:08.160 --> 00:48:12.080]   9am Pacific time. I did buy the founders edition. Oh, you did.
[00:48:12.080 --> 00:48:18.720]   You know, I didn't want to, but I did. I got one of those. What did they compare the controller
[00:48:18.720 --> 00:48:23.440]   to a knife? By the way, I liked that. I liked that. I like the new. I want to hold something I
[00:48:23.440 --> 00:48:28.320]   can stab people with one of the games. It wasn't a great to see Barrett Sunday Thurston, who's
[00:48:28.320 --> 00:48:34.080]   done on our shows many, many, many of us. We love Barrett today. And I guess Google hired him to be,
[00:48:34.080 --> 00:48:39.120]   you know, kind of a pretend journalist in their videos for all this stuff. But he was so good. It
[00:48:39.120 --> 00:48:43.440]   was good. It was really nice to see him. Yeah. I really liked seeing him. I did like the narrative
[00:48:43.440 --> 00:48:51.360]   about the controllers, because if you think back to the NES and how that controller was just a flat
[00:48:51.360 --> 00:48:57.680]   rectangular device, and it felt horrible trying to play games for hours on end and how they went
[00:48:57.680 --> 00:49:02.560]   through the evolution of the controller has got to be a little more ergonomic. But you know,
[00:49:02.560 --> 00:49:09.120]   even though we mo was just like a candy bar, right? It wasn't an ergonomic in any way. I mean,
[00:49:09.120 --> 00:49:14.640]   it's taken us a while. It has been a while. And as somebody who suffered for gamers thumb,
[00:49:14.640 --> 00:49:20.320]   with gamers thumb for many decades, I'm glad Stadia is going to be a challenge for them. We
[00:49:20.320 --> 00:49:24.960]   were just talking on Windows weekly because Microsoft's X cloud, which is a similar idea is coming.
[00:49:24.960 --> 00:49:30.400]   Microsoft's known for gaming. They have a lot of titles. Google has to, I don't know, it's going
[00:49:30.400 --> 00:49:35.040]   to take time. Make a deal. You have to buy the title, which is weird. I'm sure we don't know,
[00:49:35.040 --> 00:49:40.480]   but I'm guessing Microsoft's service will have a pass kind of like Apple Arcade, where you pay a
[00:49:40.480 --> 00:49:45.440]   flat rate and you get a bunch of games, not with Google, you play the $10 and you got to buy the
[00:49:45.440 --> 00:49:51.040]   games and they live on their server, not on your computer. And that's that's a good associate of
[00:49:51.040 --> 00:49:55.200]   costs, right? Don't you think that's fair? If it's, you know what, it depends what they charge,
[00:49:55.200 --> 00:49:59.200]   but I think they're in a charge 60 bucks just like if you bought the game. Oh, that's so good.
[00:49:59.200 --> 00:50:04.640]   Okay. Okay. They can always be relevant. I mean, like, they buy one copy, right?
[00:50:04.640 --> 00:50:10.480]   No, I don't need games. You don't need a computer to play. There's if you, but they're going to do
[00:50:10.480 --> 00:50:16.800]   AAA titles. If you have their company to that's a AAA title. That's a that's a high end gaming title.
[00:50:16.800 --> 00:50:22.800]   If you have their controller and if you have a Android phone, an Android phone,
[00:50:22.800 --> 00:50:28.240]   Chromebook, which is really I think, right? That's dongle attached to your TV. All you need is a
[00:50:28.240 --> 00:50:34.720]   dongle attached to your TV and their controller and you can play whatever game you want. At launch,
[00:50:34.720 --> 00:50:40.720]   according to ours, Technica, the controller will only work wirelessly when playing via a Chromecast
[00:50:40.720 --> 00:50:49.840]   Ultra on a TV. So you'll have to wire it for your phone or your Chromebook. It will be
[00:50:49.840 --> 00:50:54.480]   a great game on their phone. Not sure about that. Oh, a lot of people play games on their phones.
[00:50:54.480 --> 00:51:00.480]   I'm not one of them. Paul was his pick of the week was it a thing that you put your phone on
[00:51:00.480 --> 00:51:05.280]   that holds your controller so that you could play with a controller.
[00:51:05.280 --> 00:51:10.640]   Oh, it's okay. It just last week. Sony announced that you can play their
[00:51:10.640 --> 00:51:18.480]   titles on a phone on any Android phone now. What? Yeah. Do you have to have a PlayStation?
[00:51:18.480 --> 00:51:24.880]   You have to have a PlayStation. I think it works. I think it works with their version of
[00:51:25.440 --> 00:51:32.000]   XCloud, Stadia, whatever the PlayStation goes. I have to ask some hardcore gamers because I don't know.
[00:51:32.000 --> 00:51:39.200]   It strikes me. Gaming is kind of a puzzle to me. It's very stratified. So there are people who
[00:51:39.200 --> 00:51:44.960]   are PC gamers. And that's all they want to do. And they mock console gamers. And there are
[00:51:44.960 --> 00:51:50.480]   people who console gamers and they mock casual gamers. And then there are casual gamers, which I
[00:51:50.480 --> 00:51:54.320]   think is probably the largest number. There are people who play on a phone or a tablet. I think
[00:51:54.320 --> 00:52:00.240]   they've been playing a lot of candy crush. They spent a ton of money because a PC gamer spent 60
[00:52:00.240 --> 00:52:07.120]   bucks for Call of Duty and then maybe 10 bucks for DLC. But a casual game. I spent $300 on Simpsons
[00:52:07.120 --> 00:52:14.000]   donuts without even blinking. Oh my god. My daughter has spent like $600 on Porsus, virtual
[00:52:14.000 --> 00:52:18.480]   horses and accessories. Does she ask? She's a good girl. She asks you first, right? Oh, yeah.
[00:52:18.480 --> 00:52:24.160]   This is a birthday of money and things like that in her own money. But just like Michael does that too.
[00:52:24.160 --> 00:52:28.960]   Still a crime. His family and friends are 16 year old know that the best gift for him is a steam
[00:52:28.960 --> 00:52:35.680]   card. And then oh my gosh, buying a steam card for someone is just not buying any steam related
[00:52:35.680 --> 00:52:40.000]   stuff other than the card is ridiculously difficult. No, we let Michael buy everything else. He gets
[00:52:40.000 --> 00:52:44.880]   the steam card puts it a credit on his account. And I see the all the steam charges go through my
[00:52:44.880 --> 00:52:51.840]   credit card and I see them on my email. Every night I go home steam steam steam steam. So I don't I
[00:52:51.840 --> 00:52:56.160]   don't I've never added it up. But I guarantee you he's right up there with your daughter. I mean,
[00:52:56.160 --> 00:53:00.640]   and he's not hardcore though. Right? Oh, he's fairly hardcore. This is the PlayStation store.
[00:53:00.640 --> 00:53:06.720]   I was there you go. Yeah. Yeah. You can stream any you can basically play your PlayStation from any
[00:53:06.720 --> 00:53:10.960]   answer. Here was my question. If you're a console gamer, do you want to do that? Or do you want to
[00:53:10.960 --> 00:53:17.360]   go home and play on your 4K TV? If I'm commuting, if I'm on the if I'm on the bus. Mary Jo fully.
[00:53:17.360 --> 00:53:25.760]   Yeah, if I still took the subway and if I could play this on the subway, then Mary Jo fully said
[00:53:25.760 --> 00:53:30.960]   that everybody on the subway in Manhattan is on their phone playing a game. I didn't know they're
[00:53:30.960 --> 00:53:34.480]   playing games. I thought other texting snap chatting, they're doing other stuff. She said no,
[00:53:34.480 --> 00:53:41.120]   they're all playing games. I sat next to someone. Yeah, for five hours they paid some sort of
[00:53:42.480 --> 00:53:47.520]   not like the same candy crush. Yeah, you're swiping a game. Yeah. And I was just like,
[00:53:47.520 --> 00:53:52.560]   that is a really long time to play a mindless game. But that's the whole point. It's mindless.
[00:53:52.560 --> 00:53:59.200]   Right. You're stuck in that. That's the game that she plays Lisa plays a game where there's candy
[00:53:59.200 --> 00:54:04.480]   and there's swiping. It's like bejeweled or with a little wizard guy and there's like
[00:54:04.480 --> 00:54:10.960]   candies. It just takes you away. It's actually a fun game. I've played it. And then she also plays
[00:54:10.960 --> 00:54:15.920]   words with friends. So that's it. You know, but those are that's a casual gamer. That's the other
[00:54:15.920 --> 00:54:24.720]   segment. You make you make paper clips and yell at farmers with the games. You cannot you cannot
[00:54:24.720 --> 00:54:29.920]   talk about casual game. Anyone's casual games habits. And then you're the terrorizing good guy.
[00:54:29.920 --> 00:54:34.560]   That is the most wonderful, most casual game. This is the best. All right, I'm going to show
[00:54:34.560 --> 00:54:38.560]   you because you mock it, but it is the best don't mock it. It is the ultimate casual game.
[00:54:38.560 --> 00:54:46.960]   Decisionproblem.com/paperclips. Show my screen. You start with a box of paper clips.
[00:54:46.960 --> 00:54:51.280]   That looks riveting. Oh, it's even more riveting. Let me make this big because this is the whole
[00:54:51.280 --> 00:54:57.040]   interface right here. You have a button that says make paper clips. You could set the price. You can
[00:54:57.040 --> 00:55:02.800]   raise or lower the price per clip. You can eventually buy marketing. Let's make a paper clip. Look,
[00:55:02.800 --> 00:55:06.400]   we made a paper clip. Now we're going to make another paper clip. Now we're making another.
[00:55:06.400 --> 00:55:12.880]   Okay. Oh boy, I'm making the clips. Make-in clips. Click-in, click-in, click-in. I've made so many
[00:55:12.880 --> 00:55:20.960]   clips. Okay. Okay now. Why is this happening? Okay. You know what Stacy? I defy you. I asked
[00:55:20.960 --> 00:55:26.960]   that question myself. Go download this game on your iPhone or Android phone or go to decisionproblem.com/paperclips
[00:55:26.960 --> 00:55:33.440]   is free. And just start. I'm just saying I defy you to play. You're just, you're just, you're just
[00:55:33.440 --> 00:55:39.200]   more complicated. It gets so intense. Let me show you. You use up the entire universe. It's
[00:55:39.200 --> 00:55:47.040]   wonderful. I have done that and I will show you. I have made 30 times 10 to the three, six,
[00:55:47.040 --> 00:55:50.800]   nine, 12. I don't know how many paper clips. Did you have to click that many kind times? No,
[00:55:50.800 --> 00:55:55.840]   no, no, no, no. Eventually you get a wire. Here, wait a minute. No, I just, I earned five bucks.
[00:55:55.840 --> 00:56:02.000]   Look, Karsten, I can buy an auto clipper. It's not a, zoom out for five bucks. Oh, okay. Now I got
[00:56:02.000 --> 00:56:08.640]   an auto clipper. I really like this game. And then you're not taking, well, you eventually,
[00:56:08.640 --> 00:56:14.640]   you generate an artificial intelligence, which makes the paper tips for you. But then what happens
[00:56:14.640 --> 00:56:20.480]   is you forget to tell the artificial intelligence once you've made a billion paper clips, you can
[00:56:20.480 --> 00:56:27.520]   stop. So it eventually consumes all the resources on the earth and turns them into paper clips,
[00:56:27.520 --> 00:56:33.120]   at which point the AI says, well, we must explore space. So it sends out drones.
[00:56:33.120 --> 00:56:38.720]   Haven't you eventually you consume as I have here, haven't you the entire universe? And there's
[00:56:38.720 --> 00:56:45.200]   nothing more to do. You've, you've actually turned the entire universe into paper clips. So there's
[00:56:45.200 --> 00:56:50.960]   a problem with that. There's nobody buying paper clips. It's an old problem with that.
[00:56:50.960 --> 00:56:55.680]   Okay. So the problem is not a problem. There's no one's buying. It is, it is a,
[00:56:56.800 --> 00:57:00.240]   it is actually a well-known thought experiment in artificial intelligence. Yeah.
[00:57:00.240 --> 00:57:07.280]   If you don't tell the, the AI is stopped. All right. It will optimize for making paper clips.
[00:57:07.280 --> 00:57:11.840]   And AI's are good enough. That is, that is brilliant. I'll give you that. But I'm not going to play
[00:57:11.840 --> 00:57:16.720]   this game. So much ones. So while you're making paper clips, I was looking at
[00:57:16.720 --> 00:57:21.280]   a setting, I was stalling. Let me do it. And then when we come back, we're going to hear the mini.
[00:57:21.280 --> 00:57:25.680]   And then I do want to talk about whatever this chip is in the nest that you're talking about.
[00:57:25.680 --> 00:57:31.120]   Because I, Stacy's our, our, our silicon guru. Well, it ties back to our other,
[00:57:31.120 --> 00:57:34.800]   it'll tie back to ambient computing. And I don't have the silicon, like, I don't have a block
[00:57:34.800 --> 00:57:37.680]   diagram. So I don't know what it's doing. It's too ambient computing. Can you talk about that?
[00:57:37.680 --> 00:57:40.640]   A hundred percent. And so can Kevin. So we'll get there.
[00:57:40.640 --> 00:57:43.280]   But first I'm going to show you my shirt.
[00:57:43.280 --> 00:57:50.160]   My tail is store shirt. I love this. Blaming.
[00:57:50.160 --> 00:57:55.200]   Isn't that great? This is going on the cruise. Nice.
[00:57:55.200 --> 00:57:58.160]   This is going on the cruise. This is from Taylor store.
[00:57:58.160 --> 00:58:04.480]   Folks, if you don't know yet about Taylor store, go to Taylor store.com/twig.
[00:58:04.480 --> 00:58:09.200]   Let me tell you about this. I've always, all my life, I've wanted a custom shirt tailored to me.
[00:58:09.200 --> 00:58:15.520]   All my life. I thought I had to go to Hong Kong to get it. You do not. Taylor store. It's a great
[00:58:15.520 --> 00:58:20.240]   Swedish company. So we know it's, I just love the Swedes. They come up with great stuff. They
[00:58:21.360 --> 00:58:28.160]   have an app. You put on your phone, you Android or iOS, you position it, they tell you how to
[00:58:28.160 --> 00:58:32.000]   position it. You stand in the app, you take a picture, you turn sideways, you take a picture.
[00:58:32.000 --> 00:58:37.920]   That's it. They send your measurements. They're using artificial intelligence, machine learning
[00:58:37.920 --> 00:58:43.440]   and statistics to figure out now, you're, I'm going to think, did you do this yet?
[00:58:43.440 --> 00:58:48.640]   I haven't done it yet. I need you. You're so strong and you've got a big chest. I want you to do
[00:58:48.640 --> 00:58:53.440]   it because I want you to see if it'll work. Yeah, I would be a good test. I have a normal body
[00:58:53.440 --> 00:58:57.680]   and it worked out of the box. It fits. It could by best. Yeah, see, he's going to be a challenge.
[00:58:57.680 --> 00:59:02.160]   I think it's going to be a good challenge. We're going to see Jason Howell, who's extraordinarily tall,
[00:59:02.160 --> 00:59:09.200]   like eight or nine feet, his, he likes longer shirt tails. Right. And so he didn't like him.
[00:59:09.200 --> 00:59:15.520]   They're too short. So this is the beauty part. If it doesn't fit, no problem. They said, fine.
[00:59:15.520 --> 00:59:19.520]   Oh, we'll make another one. You keep that one or donate it or do whatever you want with it.
[00:59:19.520 --> 00:59:23.120]   You don't even have to send it back. So cool. You don't even have to send it back.
[00:59:23.120 --> 00:59:26.560]   The other thing that's really fun. Now you can get some kind of standard shirts.
[00:59:26.560 --> 00:59:31.600]   They have all kinds of fabrics, but they also have all kinds of settings. You could have cufflinks.
[00:59:31.600 --> 00:59:37.920]   Look, I got double buttons on the on this one. You can have piping. You can have different spread.
[00:59:37.920 --> 00:59:42.080]   This is a spread collar, but you can also get a preppy style collar button down.
[00:59:42.720 --> 00:59:47.120]   Like a hundred different options. You get it pleated back. So you can get the exact
[00:59:47.120 --> 00:59:52.000]   precise shirt you want or you can choose if you're not the kind of person that likes to do that.
[00:59:52.000 --> 00:59:54.800]   I actually enjoy it. But if you're not the kind of person who wants to do that,
[00:59:54.800 --> 01:00:00.400]   because I like the paperclip game. So of course, you can also get some, you know, like standard
[01:00:00.400 --> 01:00:06.000]   shirts, but they're going to fit. They're going to fit beautifully. And this perfect fit guarantee
[01:00:06.000 --> 01:00:10.320]   takes away all the risk and ordering. It's not even like you package it up and send it back.
[01:00:10.320 --> 01:00:15.280]   You just keep it and they'll send you the right size. Oh, another thing I have to really admire them.
[01:00:15.280 --> 01:00:20.800]   So they're Swedish. They're very conscientious. It's a 100% carbon neutral business. These shirts
[01:00:20.800 --> 01:00:26.320]   are made in Sri Lanka. In fact, this is another nice thing. They gave the seamstress's
[01:00:26.320 --> 01:00:31.040]   camera phones and they take pictures of your shirt as being made and they email them to you.
[01:00:31.040 --> 01:00:38.080]   So you're going to see your shirt being made. It is a completely conscious company. And so these
[01:00:38.080 --> 01:00:43.040]   people have, there's not a sweatshop. They have great jobs. They, by the way, if you're ever in
[01:00:43.040 --> 01:00:47.920]   Sri Lanka, Taylor Store invites you to tour their factory. Actually, it's more than factories now.
[01:00:47.920 --> 01:00:52.400]   They have one, there's one town in Sri Lanka. Everybody works for Taylor Store. They outgrow it.
[01:00:52.400 --> 01:00:57.200]   So now they're going to this town next door, but they love Taylor Store because they pay well.
[01:00:57.200 --> 01:01:02.480]   They are conscientious. They take good care of their employees. They're carbon neutral. I just
[01:01:02.480 --> 01:01:10.720]   love these guys. Ready made garments? Forget it. Off the rack, forget it. You deserve a shirt that's
[01:01:10.720 --> 01:01:19.680]   tailored exactly to your size. This is Taylor Store. Get the size me app. And then once you do it,
[01:01:19.680 --> 01:01:25.840]   man, you're going to love it because you just, I've now ordered several dozen shirts on Taylor Store.
[01:01:25.840 --> 01:01:31.920]   I'm so in love with it. Now we got a very good trial for you. Each customer, if your new customer
[01:01:31.920 --> 01:01:38.160]   gets a dress shirt starting at $39, it's 50% off the regular price. So this is a great way to try it.
[01:01:38.160 --> 01:01:47.120]   $39 plus free shipping. It's Taylor Store, T-A-I-L-O-R Store.com/Twig. Off-R-Code Twig. Free shipping.
[01:01:47.120 --> 01:01:52.240]   You'll, some terms and conditions apply. They'll explain it all to you. Taylor Store.com/Twig.
[01:01:52.240 --> 01:01:57.200]   Do use the off-code twigs so they know you saw it here because we want them to know,
[01:01:57.200 --> 01:02:01.840]   because we want them to come back because I want to buy more shirts forever and ever. Isn't that
[01:02:01.840 --> 01:02:05.680]   great? The full name is looking sharp. I got some really great shirts. All the cruise shirts
[01:02:05.680 --> 01:02:12.880]   ever got a black one. I got a royal blue one that Robert was, Bob was about to steal.
[01:02:12.880 --> 01:02:18.640]   Next try. I said, "No, it fits me perfectly. You can't have it." By the way, that's another
[01:02:18.640 --> 01:02:23.120]   thing. All right, nobody else can get it. No sharing. It's not extra large. It's not large.
[01:02:23.120 --> 01:02:31.280]   It's Leo. Taylor Store.com/Twig. You saw how nicely it comes in the Taylor Store and the
[01:02:31.280 --> 01:02:36.720]   nice bag. I have to get me an ant-size shirt. Seriously, I can't believe you haven't done that yet.
[01:02:36.720 --> 01:02:43.520]   We'll say it yet. We'll say it yet. Taylor Store.com/Twig. Off-R-Code Twig. Taylor Store.com/Twig.
[01:02:43.520 --> 01:02:50.400]   All right. We have fired up the new Google Mini. They said, "To X base, you can hang it on the wall.
[01:02:50.400 --> 01:02:56.800]   Kevin Tofel has one. Make it make noise." I don't want to blow everybody's ears out.
[01:02:56.800 --> 01:03:02.800]   Carsten, you tell me if I'm going to blow it to the scooty. I'm ready for all that base.
[01:03:02.800 --> 01:03:09.760]   You can say, "Hey." You don't have to say, "Hey." Yeah, no. I have Spotify on here,
[01:03:09.760 --> 01:03:14.960]   some fresh vines, whatever. I will place them with it.
[01:03:14.960 --> 01:03:19.360]   Yeah, but please, please, please, please, please, something that's going to get you down.
[01:03:19.360 --> 01:03:22.240]   Base. We won't base. This has some base, I think.
[01:03:22.240 --> 01:03:28.640]   Right. I listen to it during the ad. All about that base by Scott Bradley's jukebox.
[01:03:28.640 --> 01:03:35.360]   Please don't. No. No, yes. No. Play the other day. Whatever it doesn't get taken to.
[01:03:35.360 --> 01:03:42.080]   Let me just play what I have queued up. Yes, good. Take it from there. So, I have the Mini
[01:03:42.880 --> 01:03:49.040]   set to the minimum volumes and I'll bring it up. I'll hit play and...
[01:03:49.040 --> 01:03:54.480]   Oh, listen to that base. I already hear it. I am surprised.
[01:03:54.480 --> 01:03:56.880]   And it seems that good. It sounds good to me.
[01:03:56.880 --> 01:03:58.640]   Sounds great. Well, yeah, really. It's up to you.
[01:03:58.640 --> 01:04:04.880]   I think that's a surprise. It can be that.
[01:04:04.880 --> 01:04:06.320]   It can be bottom for something that's small.
[01:04:06.320 --> 01:04:11.360]   I'm surprised. I mean, it's not obviously a direct comparison.
[01:04:11.360 --> 01:04:12.720]   I don't have another one here.
[01:04:12.720 --> 01:04:20.000]   But in your... So, I think honestly, the Google Home Max is the single best smart speaker out there.
[01:04:20.000 --> 01:04:22.560]   It sounds fantastic. I'm in love with it. But it's this.
[01:04:22.560 --> 01:04:23.360]   This is a tank.
[01:04:23.360 --> 01:04:25.360]   And it weighs a lot.
[01:04:25.360 --> 01:04:28.640]   Because you know I'm all about that base, about that base.
[01:04:28.640 --> 01:04:32.240]   No, table. I'm all about that base, about that base.
[01:04:32.240 --> 01:04:33.520]   No, table.
[01:04:33.520 --> 01:04:36.640]   That sounds pretty good. That's considering the size it does.
[01:04:36.640 --> 01:04:38.880]   But we're hearing it through microphone, through compression,
[01:04:39.360 --> 01:04:41.920]   through Skype. What does it sound like to you? That's really what matters.
[01:04:41.920 --> 01:04:47.920]   I feel like it can easily fill this office, which is like 12 by 13.
[01:04:47.920 --> 01:04:48.480]   Oh, nice.
[01:04:48.480 --> 01:04:49.200]   I'm impressed.
[01:04:49.200 --> 01:04:51.920]   You should let him listen to a Beatles song,
[01:04:51.920 --> 01:04:53.440]   because that's what he listens to all the time.
[01:04:53.440 --> 01:04:54.320]   And he can actually do it.
[01:04:54.320 --> 01:04:55.440]   He's okay with Beatles.
[01:04:55.440 --> 01:04:56.640]   No, they'll take us down.
[01:04:56.640 --> 01:04:57.360]   Oh, no.
[01:04:57.360 --> 01:04:59.120]   That part of the song of a...
[01:04:59.120 --> 01:05:01.760]   I won't say that to you, although the new Abbey Road remaster was gone.
[01:05:01.760 --> 01:05:02.720]   I was going to ask you.
[01:05:02.720 --> 01:05:04.160]   Oh, I love it.
[01:05:04.160 --> 01:05:05.680]   Isn't it great to hear those outtakes?
[01:05:05.680 --> 01:05:07.840]   Had you heard any of those before?
[01:05:08.480 --> 01:05:09.200]   No.
[01:05:09.200 --> 01:05:09.920]   No.
[01:05:09.920 --> 01:05:12.160]   Not to get off topic, but you brought it up.
[01:05:12.160 --> 01:05:12.800]   So...
[01:05:12.800 --> 01:05:14.080]   No, I want to talk about it.
[01:05:14.080 --> 01:05:15.200]   I bought it immediately.
[01:05:15.200 --> 01:05:16.320]   I bought Sergeant Pepper.
[01:05:16.320 --> 01:05:17.040]   I bought the White.
[01:05:17.040 --> 01:05:20.800]   I think I'm just going to buy the entire Beatles catalog 50 years later,
[01:05:20.800 --> 01:05:21.600]   all over again.
[01:05:21.600 --> 01:05:27.200]   So the one outtake I love the best is the ballad of John and Yoko,
[01:05:27.200 --> 01:05:32.080]   where John says to presumably Ringo.
[01:05:32.080 --> 01:05:34.560]   He says, Ringo, you got to speed it up a little bit.
[01:05:34.560 --> 01:05:37.920]   He goofed because Paul actually plays the drums on that song.
[01:05:37.920 --> 01:05:39.040]   Oh, that's hysterical.
[01:05:39.040 --> 01:05:40.400]   Because Ringo was not there.
[01:05:40.400 --> 01:05:42.640]   So what you know what Paul does without missing a beat?
[01:05:42.640 --> 01:05:43.360]   Okay, George.
[01:05:43.360 --> 01:05:48.320]   But only you would know what's going on there.
[01:05:48.320 --> 01:05:52.160]   I thought that was the one where Ringo says,
[01:05:52.160 --> 01:05:54.880]   "Either I'll play it faster or you guys come in slower."
[01:05:54.880 --> 01:05:56.080]   That's another one, right?
[01:05:56.080 --> 01:05:57.200]   That's a different one.
[01:05:57.200 --> 01:05:59.040]   That's the one that Ringo sings on.
[01:05:59.040 --> 01:06:01.920]   He's like, "I came into early or you guys just came into me."
[01:06:01.920 --> 01:06:02.080]   It's called in...
[01:06:02.080 --> 01:06:04.000]   Oh my God.
[01:06:04.000 --> 01:06:05.600]   It's so great to hear that.
[01:06:05.600 --> 01:06:06.400]   It's awesome.
[01:06:06.400 --> 01:06:08.560]   It's nice is it's fresh.
[01:06:08.560 --> 01:06:10.080]   You're hearing...
[01:06:10.080 --> 01:06:11.280]   I know it's 50 years...
[01:06:11.280 --> 01:06:11.600]   What?
[01:06:11.600 --> 01:06:12.800]   What?
[01:06:12.800 --> 01:06:13.360]   Exactly.
[01:06:13.360 --> 01:06:16.960]   What are you wondering about?
[01:06:16.960 --> 01:06:18.720]   What part of this do you not understand?
[01:06:18.720 --> 01:06:19.440]   Because this is...
[01:06:19.440 --> 01:06:21.040]   Are you all still speaking English?
[01:06:21.040 --> 01:06:24.080]   I didn't understand a word of that just now.
[01:06:24.080 --> 01:06:24.320]   You know?
[01:06:24.320 --> 01:06:27.600]   Well, Tolkien live up Pudlin.
[01:06:27.600 --> 01:06:28.160]   Oh, okay.
[01:06:28.160 --> 01:06:35.760]   So what's good about it is you're hearing with new ears the songs.
[01:06:36.480 --> 01:06:39.360]   You're hearing these guys 50 years ago, young...
[01:06:39.360 --> 01:06:42.160]   This was the last album they ever recorded together.
[01:06:42.160 --> 01:06:45.120]   So there's a little...
[01:06:45.120 --> 01:06:46.000]   Maybe some tension.
[01:06:46.000 --> 01:06:47.360]   I don't know, but they still love each other.
[01:06:47.360 --> 01:06:48.240]   You can hear that.
[01:06:48.240 --> 01:06:50.960]   And it made it all fresh and new again.
[01:06:50.960 --> 01:06:54.000]   I am so glad they're releasing these outtakes.
[01:06:54.000 --> 01:06:55.360]   I just think they're amazing.
[01:06:55.360 --> 01:06:57.120]   They're not outtakes.
[01:06:57.120 --> 01:06:57.760]   They're not outtakes.
[01:06:57.760 --> 01:06:59.440]   They're additional takes of the same song.
[01:06:59.440 --> 01:06:59.840]   Correct.
[01:06:59.840 --> 01:07:00.240]   Yeah.
[01:07:00.240 --> 01:07:03.200]   So you can hear them doing Rocky Raccoon and kind of...
[01:07:03.200 --> 01:07:08.080]   Or O'Blady O'Bladock and kind of getting it closer to the song.
[01:07:08.080 --> 01:07:08.720]   It's just...
[01:07:08.720 --> 01:07:09.520]   I want to hear more.
[01:07:09.520 --> 01:07:10.720]   Here in the creative energy.
[01:07:10.720 --> 01:07:11.680]   Okay, fine.
[01:07:11.680 --> 01:07:12.400]   I dig that.
[01:07:12.400 --> 01:07:14.480]   Are you going to buy it?
[01:07:14.480 --> 01:07:15.840]   Yeah, it's my favorite album.
[01:07:15.840 --> 01:07:17.360]   So it's my favorite album.
[01:07:17.360 --> 01:07:18.640]   It's me too.
[01:07:18.640 --> 01:07:20.880]   I think it was the first album I ever bought myself.
[01:07:20.880 --> 01:07:22.960]   It was Abbey Road.
[01:07:22.960 --> 01:07:24.800]   It was 1972-70.
[01:07:24.800 --> 01:07:25.360]   When was it?
[01:07:25.360 --> 01:07:25.920]   '72.
[01:07:25.920 --> 01:07:27.760]   No, '69, it must have been...
[01:07:27.760 --> 01:07:28.320]   '69.
[01:07:28.320 --> 01:07:29.520]   No, '69.
[01:07:29.520 --> 01:07:30.720]   So I was 13.
[01:07:30.720 --> 01:07:32.240]   It was my first album.
[01:07:33.040 --> 01:07:35.760]   And I'll never forget putting it down and hearing...
[01:07:35.760 --> 01:07:38.800]   And going, "How are they doing that?"
[01:07:38.800 --> 01:07:39.440]   That is...
[01:07:39.440 --> 01:07:40.080]   That is...
[01:07:40.080 --> 01:07:41.600]   I've never heard that sound before.
[01:07:41.600 --> 01:07:46.320]   And that's one of the very few albums and maybe the first of the Beatles
[01:07:46.320 --> 01:07:49.120]   that actually used eight tracks to record, not four or two.
[01:07:49.120 --> 01:07:49.760]   Oh.
[01:07:49.760 --> 01:07:50.320]   Oh.
[01:07:50.320 --> 01:07:50.880]   Yeah.
[01:07:50.880 --> 01:07:51.440]   Interesting.
[01:07:51.440 --> 01:07:52.960]   Yeah, because they really were playing with it.
[01:07:52.960 --> 01:07:54.240]   But I'm right.
[01:07:54.240 --> 01:07:55.680]   It was not the last album released.
[01:07:55.680 --> 01:07:57.360]   Let it be was the last album released.
[01:07:57.360 --> 01:07:58.000]   Correct.
[01:07:58.000 --> 01:07:58.240]   Correct.
[01:07:58.240 --> 01:08:00.800]   But Abbey Road was recorded after Let it Be.
[01:08:02.000 --> 01:08:04.880]   So this was the last album they recorded together.
[01:08:04.880 --> 01:08:06.480]   And something is poignant.
[01:08:06.480 --> 01:08:09.200]   It's the first song I learned how to play on guitar.
[01:08:09.200 --> 01:08:11.760]   Well, and something which is a George...
[01:08:11.760 --> 01:08:14.240]   There are two George Harrison compositions on this.
[01:08:14.240 --> 01:08:14.960]   Something and...
[01:08:14.960 --> 01:08:18.000]   What's the other one on here?
[01:08:18.000 --> 01:08:21.200]   Oh, "Bosifas"?
[01:08:21.200 --> 01:08:23.280]   Mom, is it "Why My Guitar Gently Weeps?"
[01:08:23.280 --> 01:08:24.080]   I can't close.
[01:08:24.080 --> 01:08:26.800]   I hate that song so much.
[01:08:26.800 --> 01:08:27.120]   What?
[01:08:27.120 --> 01:08:28.800]   We...
[01:08:28.800 --> 01:08:29.840]   I don't friend you.
[01:08:29.840 --> 01:08:30.320]   What?
[01:08:30.320 --> 01:08:30.800]   I know.
[01:08:31.520 --> 01:08:33.520]   I am not doing the podcasting or anything.
[01:08:33.520 --> 01:08:34.080]   Why am I...
[01:08:34.080 --> 01:08:34.560]   Why?
[01:08:34.560 --> 01:08:37.040]   I just had to throw a monkey wrench in this.
[01:08:37.040 --> 01:08:38.160]   Frank Sinatra.
[01:08:38.160 --> 01:08:43.440]   Frank Sinatra said something was the greatest love song ever written.
[01:08:43.440 --> 01:08:45.680]   George Harrison.
[01:08:45.680 --> 01:08:46.720]   But this was late.
[01:08:46.720 --> 01:08:49.200]   In fact, I love the text in the book because
[01:08:49.200 --> 01:08:51.840]   Paul kind of refers to that.
[01:08:51.840 --> 01:08:52.640]   He talks about...
[01:08:52.640 --> 01:08:53.680]   Here comes the sun.
[01:08:53.680 --> 01:08:54.720]   Here comes the sun's the other one.
[01:08:54.720 --> 01:08:55.840]   And that is perhaps best.
[01:08:55.840 --> 01:08:56.800]   Perhaps best.
[01:08:56.800 --> 01:08:57.280]   It's really beautiful.
[01:08:57.280 --> 01:08:58.000]   George Harrison's song.
[01:08:58.000 --> 01:08:59.120]   It's a beautiful song.
[01:08:59.120 --> 01:09:01.280]   And hearing George play it in the...
[01:09:01.280 --> 01:09:02.720]   In a demo.
[01:09:02.720 --> 01:09:03.440]   There's a demo.
[01:09:03.440 --> 01:09:03.840]   A demo.
[01:09:03.840 --> 01:09:04.320]   That's right.
[01:09:04.320 --> 01:09:05.200]   It's really good.
[01:09:05.200 --> 01:09:09.760]   So what you get is four discs.
[01:09:09.760 --> 01:09:10.720]   And a great book.
[01:09:10.720 --> 01:09:12.560]   I think the book is worthwhile.
[01:09:12.560 --> 01:09:14.080]   But you get four discs.
[01:09:14.080 --> 01:09:16.720]   Disc one is Giles Martin's remix.
[01:09:16.720 --> 01:09:18.320]   He's George Martin's son.
[01:09:18.320 --> 01:09:19.840]   So he's been...
[01:09:19.840 --> 01:09:21.680]   One of the things he's been doing with this project
[01:09:21.680 --> 01:09:25.840]   is taking the masters and remixing him in stereo,
[01:09:25.840 --> 01:09:27.440]   according to the notes.
[01:09:27.440 --> 01:09:28.880]   A lot of times the stereo mixes...
[01:09:28.880 --> 01:09:30.480]   I don't know this late in the game,
[01:09:30.480 --> 01:09:31.440]   maybe this is not the case,
[01:09:31.440 --> 01:09:33.040]   but in early Beatles,
[01:09:33.040 --> 01:09:35.680]   the stereo mixes were not done for the Britain
[01:09:35.680 --> 01:09:36.240]   British market.
[01:09:36.240 --> 01:09:37.520]   They were done for the US market.
[01:09:37.520 --> 01:09:39.600]   And they were done really well.
[01:09:39.600 --> 01:09:40.240]   They were terrible.
[01:09:40.240 --> 01:09:40.960]   They were awful.
[01:09:40.960 --> 01:09:41.920]   They were terrible.
[01:09:41.920 --> 01:09:43.600]   They were just thrown out.
[01:09:43.600 --> 01:09:44.880]   Oh, these Americans, they don't know.
[01:09:44.880 --> 01:09:45.360]   They don't know.
[01:09:45.360 --> 01:09:46.320]   So...
[01:09:46.320 --> 01:09:48.160]   And I don't...
[01:09:48.160 --> 01:09:50.480]   By Abbey Road, they must have been doing it in stereo
[01:09:50.480 --> 01:09:52.160]   for everybody if they're doing a track.
[01:09:52.160 --> 01:09:55.360]   But anyway, Giles takes the notes,
[01:09:55.920 --> 01:09:59.280]   remixes based on what he thinks was the goal, I guess.
[01:09:59.280 --> 01:09:59.600]   Right?
[01:09:59.600 --> 01:10:00.400]   Am I right, Kevin?
[01:10:00.400 --> 01:10:00.800]   I don't...
[01:10:00.800 --> 01:10:03.760]   Yeah, no, it was to replicate what the Beatles wanted.
[01:10:03.760 --> 01:10:05.040]   It just sounded like at the time.
[01:10:05.040 --> 01:10:05.360]   Right.
[01:10:05.360 --> 01:10:08.080]   And I think the remixes are beautiful.
[01:10:08.080 --> 01:10:14.240]   George and Giles worked on Love, the Cirque du Soleil remix,
[01:10:14.240 --> 01:10:18.160]   and it blew me away if you get a chance to see that in Las Vegas, too.
[01:10:18.160 --> 01:10:20.560]   And so I think these remixes are nice,
[01:10:20.560 --> 01:10:21.920]   because it's the same album.
[01:10:21.920 --> 01:10:24.240]   You don't like the remix.
[01:10:24.240 --> 01:10:25.360]   I'm sorry, Kevin!
[01:10:25.360 --> 01:10:26.000]   I've seen it.
[01:10:26.000 --> 01:10:27.120]   I've seen it a dozen times.
[01:10:27.120 --> 01:10:27.680]   She hates the Beatles?
[01:10:27.680 --> 01:10:29.280]   I've seen it a dozen times.
[01:10:29.280 --> 01:10:31.760]   No, it's okay if you hate America, but if you hate Beatles...
[01:10:31.760 --> 01:10:32.000]   Yeah.
[01:10:32.000 --> 01:10:33.520]   That's it.
[01:10:33.520 --> 01:10:34.080]   That's it.
[01:10:34.080 --> 01:10:34.560]   That's it.
[01:10:34.560 --> 01:10:35.600]   I should have liked that song.
[01:10:35.600 --> 01:10:38.640]   Every CES, I say Stacy.
[01:10:38.640 --> 01:10:39.920]   I'm taking you to the Love Show.
[01:10:39.920 --> 01:10:40.880]   You're going to love Ray.
[01:10:40.880 --> 01:10:42.160]   It's awesome.
[01:10:42.160 --> 01:10:45.440]   And she weasels her way out every year.
[01:10:45.440 --> 01:10:46.640]   Smart woman.
[01:10:46.640 --> 01:10:48.560]   Ant and I are going to CES this year.
[01:10:48.560 --> 01:10:48.960]   It's going to be...
[01:10:48.960 --> 01:10:50.720]   Everybody's going to love this year.
[01:10:50.720 --> 01:10:52.720]   It's going to be Antleo's Excellent Adventure.
[01:10:52.720 --> 01:10:54.480]   I will get tickets.
[01:10:55.120 --> 01:10:58.480]   For you, Ant, but only if Stacy goes.
[01:10:58.480 --> 01:11:01.280]   You don't get to go if Stacy doesn't go.
[01:11:01.280 --> 01:11:02.400]   Chat room, save us.
[01:11:02.400 --> 01:11:03.760]   Stacy, you're going to CES this year?
[01:11:03.760 --> 01:11:06.480]   I am, but it may be that it's always...
[01:11:06.480 --> 01:11:07.760]   Everybody's going to love.
[01:11:07.760 --> 01:11:08.560]   It's never...
[01:11:08.560 --> 01:11:09.840]   It's never on when I'm there.
[01:11:09.840 --> 01:11:11.120]   We're always...
[01:11:11.120 --> 01:11:12.080]   There's like...
[01:11:12.080 --> 01:11:13.040]   It's true, Kevin.
[01:11:13.040 --> 01:11:15.520]   They don't do it Monday night and Wednesday night I leave.
[01:11:15.520 --> 01:11:17.520]   You're on the wrong mic.
[01:11:17.520 --> 01:11:21.360]   Can you change your mic so that you're on the good mic?
[01:11:21.360 --> 01:11:23.840]   It's not going to work, Stacy.
[01:11:23.840 --> 01:11:27.360]   I just want a perfectly lupable version of She's So Heavy.
[01:11:27.360 --> 01:11:29.200]   That's all I'm in the world.
[01:11:29.200 --> 01:11:32.560]   There is Take 4 She's So Heavy on the new release.
[01:11:32.560 --> 01:11:35.840]   She's fantastic.
[01:11:35.840 --> 01:11:37.360]   And it gives you insight into the song.
[01:11:37.360 --> 01:11:38.640]   Right, Kevin?
[01:11:38.640 --> 01:11:40.240]   Yes, absolutely.
[01:11:40.240 --> 01:11:41.040]   I just want that song to be on the line.
[01:11:41.040 --> 01:11:41.840]   Take 4.
[01:11:41.840 --> 01:11:47.920]   For people who don't want to drop the money on the vinyl or the CDs or whatever,
[01:11:47.920 --> 01:11:49.920]   most of the streaming services now have it.
[01:11:49.920 --> 01:11:50.400]   Which surprised me.
[01:11:50.400 --> 01:11:51.600]   So like I don't want to Spotify.
[01:11:51.600 --> 01:11:54.000]   I bought it just because I feel like the Beatles need the money.
[01:11:54.000 --> 01:11:56.560]   Yeah, just a little more.
[01:11:56.560 --> 01:12:00.400]   I don't know why I bought it.
[01:12:00.400 --> 01:12:02.800]   Stacy, say something.
[01:12:02.800 --> 01:12:03.360]   So...
[01:12:03.360 --> 01:12:04.240]   Hello, it might matter.
[01:12:04.240 --> 01:12:05.200]   Yeah, much better.
[01:12:05.200 --> 01:12:05.440]   Yeah, yeah.
[01:12:05.440 --> 01:12:05.760]   All right.
[01:12:05.760 --> 01:12:06.160]   Much better.
[01:12:06.160 --> 01:12:07.440]   And you're going to the Love Show.
[01:12:07.440 --> 01:12:09.040]   Now say something about Google.
[01:12:09.040 --> 01:12:11.440]   Could I talk about ambient computing?
[01:12:11.440 --> 01:12:12.800]   First, please.
[01:12:12.800 --> 01:12:15.920]   I want a commitment that you're going to go to love with us.
[01:12:15.920 --> 01:12:19.200]   I've already booked my tickets in my hotel.
[01:12:19.200 --> 01:12:20.400]   So if it works in my place...
[01:12:20.400 --> 01:12:22.080]   Tuesday night is love night.
[01:12:22.080 --> 01:12:25.360]   Oh, I definitely can say no to that.
[01:12:25.360 --> 01:12:29.120]   Can we go to a matinee?
[01:12:29.120 --> 01:12:30.720]   Yeah, baby.
[01:12:30.720 --> 01:12:32.160]   Kevin, I feel your pain.
[01:12:32.160 --> 01:12:33.840]   I'm seeing what you're dealing with now.
[01:12:33.840 --> 01:12:34.320]   Thank you.
[01:12:34.320 --> 01:12:34.800]   Kevin.
[01:12:34.800 --> 01:12:38.000]   I can't go because I'm staying all the way down in the other side of Vegas.
[01:12:38.000 --> 01:12:41.360]   It's not that far.
[01:12:41.360 --> 01:12:42.640]   So I'm not like the Beatles too.
[01:12:42.640 --> 01:12:43.760]   I'm saved.
[01:12:43.760 --> 01:12:44.480]   Do you know what to be?
[01:12:44.480 --> 01:12:44.480]   We're staying.
[01:12:44.480 --> 01:12:45.360]   Are we staying at?
[01:12:45.360 --> 01:12:46.320]   Do you know how to do everything we've done?
[01:12:46.320 --> 01:12:47.600]   I don't have anything against the Beatles.
[01:12:48.160 --> 01:12:50.000]   You have to do everything Leo does, Ant.
[01:12:50.000 --> 01:12:50.880]   Oh, man.
[01:12:50.880 --> 01:12:53.360]   Yes, Leo and Ant's excellent adventure.
[01:12:53.360 --> 01:12:54.080]   Didn't you see?
[01:12:54.080 --> 01:12:56.240]   It's going to be fun.
[01:12:56.240 --> 01:12:57.600]   We're going to be joined at the hip.
[01:12:57.600 --> 01:12:58.480]   I'm all in.
[01:12:58.480 --> 01:12:59.840]   Actually, it's going to be really fun because
[01:12:59.840 --> 01:13:04.480]   not only are Ant and I going to be kind of babes in Toyland,
[01:13:04.480 --> 01:13:06.000]   kind of wandering around wide-eyed,
[01:13:06.000 --> 01:13:11.680]   but we're going to meet up with Samable Sammit in the North Hall to look at car stuffs.
[01:13:11.680 --> 01:13:14.640]   We're going to meet up with Scott Wilkinson if he's there.
[01:13:14.640 --> 01:13:16.480]   I think he's going to be for the TV stuff.
[01:13:16.480 --> 01:13:18.480]   We're going to meet up with Dicty Bartolo.
[01:13:18.480 --> 01:13:21.680]   We're going to the Sands basement with a king of junky gadgets.
[01:13:21.680 --> 01:13:23.520]   It's going to be so much fun.
[01:13:23.520 --> 01:13:24.480]   It's going to be so much fun.
[01:13:24.480 --> 01:13:27.440]   And we've committed for this.
[01:13:27.440 --> 01:13:28.240]   We've committed to...
[01:13:28.240 --> 01:13:29.600]   What did I say?
[01:13:29.600 --> 01:13:30.480]   60 segments?
[01:13:30.480 --> 01:13:31.280]   No, no.
[01:13:31.280 --> 01:13:32.000]   30.
[01:13:32.000 --> 01:13:32.560]   30.
[01:13:32.560 --> 01:13:33.840]   I didn't say you didn't say that many.
[01:13:33.840 --> 01:13:34.960]   30 segments.
[01:13:34.960 --> 01:13:36.960]   Well, 30 segments.
[01:13:36.960 --> 01:13:38.240]   We talked you down from 40.
[01:13:38.240 --> 01:13:39.280]   It was 40.
[01:13:39.280 --> 01:13:41.120]   I thought, hey, we can easily do 20 a day.
[01:13:41.120 --> 01:13:41.760]   But anyway, all right.
[01:13:41.760 --> 01:13:43.760]   No, you're doing 10 a day for 30 days.
[01:13:43.760 --> 01:13:44.960]   Okay, 10 a day for today.
[01:13:44.960 --> 01:13:46.720]   But then, on Thursday...
[01:13:46.720 --> 01:13:47.920]   On Thursday...
[01:13:47.920 --> 01:13:49.120]   And he's going to punch you.
[01:13:49.120 --> 01:13:51.600]   On Thursday, it's going to happen.
[01:13:51.600 --> 01:13:53.200]   No, I've seen Ant.
[01:13:53.200 --> 01:13:57.040]   I met Ant for the first time at CES and he was delightfully calm and pleasant.
[01:13:57.040 --> 01:13:58.160]   You know, he's as sweet of him.
[01:13:58.160 --> 01:13:58.640]   Yep.
[01:13:58.640 --> 01:14:00.960]   I was like, what is happening here?
[01:14:00.960 --> 01:14:02.080]   This guy is just like...
[01:14:02.080 --> 01:14:02.960]   He brought me down.
[01:14:02.960 --> 01:14:04.800]   Like all my energy went down a little bit,
[01:14:04.800 --> 01:14:06.080]   and I was like, how can we last?
[01:14:06.080 --> 01:14:07.200]   I'm going to tell you the truth.
[01:14:07.200 --> 01:14:09.920]   It's the little guys who put you on edge.
[01:14:09.920 --> 01:14:11.440]   The big guys...
[01:14:11.440 --> 01:14:12.400]   It's like a big dog.
[01:14:12.400 --> 01:14:13.120]   They got nothing to prove.
[01:14:13.120 --> 01:14:13.840]   Nothing to prove.
[01:14:13.840 --> 01:14:14.480]   It's just like dogs.
[01:14:14.480 --> 01:14:14.960]   The little dogs...
[01:14:14.960 --> 01:14:15.840]   Nothing to prove.
[01:14:15.840 --> 01:14:16.240]   Nothing to prove.
[01:14:16.240 --> 01:14:16.720]   Big dogs.
[01:14:16.720 --> 01:14:17.440]   Just relax.
[01:14:17.440 --> 01:14:19.600]   Kevin doesn't put me on edge.
[01:14:19.600 --> 01:14:22.960]   No, just a little dog.
[01:14:22.960 --> 01:14:23.920]   Kevin, he's picking up.
[01:14:23.920 --> 01:14:27.600]   No, ambient computing.
[01:14:27.600 --> 01:14:28.000]   Yes.
[01:14:28.000 --> 01:14:28.560]   Go.
[01:14:28.560 --> 01:14:29.360]   Google, Google.
[01:14:29.360 --> 01:14:32.400]   Okay, so...
[01:14:32.400 --> 01:14:33.600]   I was like, should I introduce this?
[01:14:33.600 --> 01:14:34.480]   We should let it happen.
[01:14:34.480 --> 01:14:35.520]   She's wishing to get it.
[01:14:35.520 --> 01:14:37.200]   No, no, no.
[01:14:37.200 --> 01:14:38.480]   Oh, you need it.
[01:14:38.480 --> 01:14:39.840]   I'm just going to put this on the screen.
[01:14:39.840 --> 01:14:41.440]   That's what I'm talking about it.
[01:14:41.440 --> 01:14:42.800]   Oh, you need it.
[01:14:42.800 --> 01:14:46.240]   So this is actually Kevin's take from the show,
[01:14:46.240 --> 01:14:47.040]   and it's a good one.
[01:14:47.040 --> 01:14:48.880]   Kevin wrote about this.
[01:14:48.880 --> 01:14:49.600]   Oh, sorry.
[01:14:49.600 --> 01:14:53.200]   You got to open my site more than one
[01:14:53.200 --> 01:14:54.240]   every two weeks.
[01:14:54.240 --> 01:14:55.920]   All right, so...
[01:14:55.920 --> 01:14:58.240]   I subscribed.
[01:14:58.240 --> 01:14:59.120]   I don't get that.
[01:14:59.120 --> 01:15:02.640]   Google talked about this at I/O.
[01:15:02.640 --> 01:15:04.800]   They talked about this concept of ambient computing,
[01:15:04.800 --> 01:15:07.760]   which I think Kevin and I have been talking about for years.
[01:15:07.760 --> 01:15:09.200]   And Kevin has talked about since what...
[01:15:09.200 --> 01:15:11.120]   Who talked about it yesterday,
[01:15:11.120 --> 01:15:12.160]   2013, I think.
[01:15:12.640 --> 01:15:13.600]   I mean, 13.
[01:15:13.600 --> 01:15:14.400]   Yeah.
[01:15:14.400 --> 01:15:17.520]   It's the idea that Google has all the information
[01:15:17.520 --> 01:15:19.200]   or could get all the information it needs
[01:15:19.200 --> 01:15:22.000]   to be this real assistant in your life.
[01:15:22.000 --> 01:15:24.480]   And not an assistant that's actually tied to an echo,
[01:15:24.480 --> 01:15:27.360]   where a lot of people think Madam A is tied to.
[01:15:27.360 --> 01:15:32.240]   But just, hey, gee, help me out here in this situation.
[01:15:32.240 --> 01:15:35.760]   And Google has all the pieces to make that really come together
[01:15:35.760 --> 01:15:37.360]   in a way that's really awesome.
[01:15:37.360 --> 01:15:39.920]   And they showed that today, or yesterday.
[01:15:39.920 --> 01:15:42.000]   Kevin's going to tell you more about this,
[01:15:42.000 --> 01:15:43.440]   because he does it really well.
[01:15:43.440 --> 01:15:47.360]   Oh, Kevin was checking for more songs with bass.
[01:15:47.360 --> 01:15:53.360]   I was trying to set you up because you're doing a good job on this.
[01:15:53.360 --> 01:15:55.520]   No, no, it was a great setup.
[01:15:55.520 --> 01:15:57.200]   But you could speak about this just as easily,
[01:15:57.200 --> 01:15:59.440]   because we have been talking about this for so long.
[01:15:59.440 --> 01:16:01.920]   And in fact, we started talking about this
[01:16:01.920 --> 01:16:06.000]   when they put Google now on the watch.
[01:16:06.000 --> 01:16:07.600]   And I said, "Context is king."
[01:16:08.240 --> 01:16:11.760]   And yesterday at the Google event,
[01:16:11.760 --> 01:16:13.600]   yeah, sure, it was all about devices.
[01:16:13.600 --> 01:16:15.440]   But the fact of the matter is,
[01:16:15.440 --> 01:16:19.840]   all those devices are just sensors and input for the smart home.
[01:16:19.840 --> 01:16:22.640]   But the problem is the smart home has not been smart.
[01:16:22.640 --> 01:16:24.720]   It's not taking advantage of all that data
[01:16:24.720 --> 01:16:30.000]   and doing something with it that makes it beneficial to people alone.
[01:16:30.000 --> 01:16:34.320]   But finally, aside from the chips and the silicon,
[01:16:34.320 --> 01:16:36.960]   the cameras, the microphones, the screens,
[01:16:37.680 --> 01:16:42.160]   they have unified everything under this new, improved Google Assistant.
[01:16:42.160 --> 01:16:47.040]   So by taking the software to tie all these signals together,
[01:16:47.040 --> 01:16:50.800]   the home can start doing things on its own that help you out.
[01:16:50.800 --> 01:16:55.520]   So if you leave the house and you forgot to set your alarm,
[01:16:55.520 --> 01:16:57.840]   your Nest alarm, for example, the home can say,
[01:16:57.840 --> 01:17:01.840]   "Oh, I noticed that you've left the geo-versary of your house."
[01:17:01.840 --> 01:17:02.560]   Yeah.
[01:17:02.560 --> 01:17:03.280]   Exactly.
[01:17:03.280 --> 01:17:05.840]   And it can set the alarm for you proactively.
[01:17:05.840 --> 01:17:09.600]   Or maybe you've gone to sleep and you've left on appliances or lights.
[01:17:09.600 --> 01:17:11.440]   Huh, nobody's moving in the house.
[01:17:11.440 --> 01:17:14.080]   I don't see any motion that probably sleep.
[01:17:14.080 --> 01:17:15.600]   I'm going to shut these lights.
[01:17:15.600 --> 01:17:19.520]   So really, the ambient computing is part of the story here
[01:17:19.520 --> 01:17:22.000]   because Google Assistant is the software
[01:17:22.000 --> 01:17:23.760]   that ties the smart home together now.
[01:17:23.760 --> 01:17:26.720]   And I would say it even goes beyond the phone.
[01:17:26.720 --> 01:17:28.320]   Sorry, I'm going to jump in and then leave.
[01:17:28.320 --> 01:17:28.880]   Go, go.
[01:17:28.880 --> 01:17:33.520]   So those are great smart home examples.
[01:17:33.520 --> 01:17:38.640]   But if you think about having the earbuds and then having things like your phone around you all the time,
[01:17:38.640 --> 01:17:43.280]   we're seeing Google try to pick those in with the earbuds.
[01:17:43.280 --> 01:17:47.760]   You know, they understand like ambient noise and can adjust sound related to that.
[01:17:47.760 --> 01:17:53.920]   So Google's like, the whole idea is making your life easier and Lord help us.
[01:17:53.920 --> 01:17:57.520]   Yes, their helpful idea is really great marketing around this.
[01:17:57.520 --> 01:17:58.480]   But it really is.
[01:17:58.480 --> 01:18:03.360]   It's like, if you give us everything we want to know about you and your surroundings
[01:18:03.360 --> 01:18:06.000]   and we can really make your life easier.
[01:18:06.000 --> 01:18:06.800]   You'll think less.
[01:18:06.800 --> 01:18:08.640]   You'll have less mental overhead.
[01:18:08.640 --> 01:18:09.440]   Wouldn't that be nice?
[01:18:09.440 --> 01:18:11.680]   Do you think that trades worse?
[01:18:11.680 --> 01:18:16.000]   I think we're going to have it like yes and no.
[01:18:16.000 --> 01:18:19.440]   And today it's worth it.
[01:18:19.440 --> 01:18:21.760]   And I love a lot of things about it.
[01:18:21.760 --> 01:18:29.840]   I say no because I think we are moving towards a more surveillance heavy state
[01:18:30.480 --> 01:18:36.800]   in the government itself and having Google or anyone have all of that information becomes a problem.
[01:18:36.800 --> 01:18:42.080]   And that's where the no is coming in because right now I kind of have a lot of distrust
[01:18:42.080 --> 01:18:44.160]   around what our government is doing around the state.
[01:18:44.160 --> 01:18:48.400]   Well, if you watched the democratic debate last night, there was a consensus among all
[01:18:48.400 --> 01:18:54.560]   what have it, 253 candidates on stage that these companies should be broken up, that they're too
[01:18:54.560 --> 01:18:55.280]   powerful.
[01:18:55.280 --> 01:19:00.400]   I mean, there were some dissenters, but you know, there was pretty much a consensus
[01:19:00.400 --> 01:19:02.160]   that these companies should be broken up.
[01:19:02.160 --> 01:19:04.160]   And the thing is I would like the choice.
[01:19:04.160 --> 01:19:09.760]   I would like to be able to bathe in the warm waters of Google's ambient computing.
[01:19:09.760 --> 01:19:12.800]   If it's my choice, I want to do it.
[01:19:12.800 --> 01:19:17.040]   I want to do it with full knowledge of what I'm giving them, of what I'm trading away.
[01:19:17.040 --> 01:19:20.880]   I don't think it's right for government or anybody else say,
[01:19:20.880 --> 01:19:22.480]   well, Leo, you're ignorant.
[01:19:22.480 --> 01:19:24.960]   You couldn't possibly know what Google's going to do with this.
[01:19:24.960 --> 01:19:26.080]   We won't let you.
[01:19:26.080 --> 01:19:29.440]   I think everybody should be given an informed choice,
[01:19:29.440 --> 01:19:31.040]   but they should be given a choice.
[01:19:31.040 --> 01:19:34.640]   That's why I like Google's the way Google is going about this.
[01:19:34.640 --> 01:19:35.120]   Transparency.
[01:19:35.120 --> 01:19:40.160]   Better than anyone because they say they are recording you.
[01:19:40.160 --> 01:19:44.800]   They are very upfront about the fact that they are recording everything you do.
[01:19:44.800 --> 01:19:52.240]   And here's the page on the web that you can go to to delete every recording we have of you.
[01:19:52.240 --> 01:19:52.720]   Right.
[01:19:52.720 --> 01:19:54.160]   Or just delete last week's.
[01:19:54.160 --> 01:19:54.720]   What have you.
[01:19:54.720 --> 01:19:59.120]   By the way, Apple's added that now with Siri, you can say delete the recordings.
[01:19:59.120 --> 01:20:00.480]   Amazon did it first.
[01:20:00.480 --> 01:20:01.440]   Google's doing it now.
[01:20:01.440 --> 01:20:02.720]   They're all doing that.
[01:20:02.720 --> 01:20:04.960]   You can with your voice, say, delete my recordings.
[01:20:04.960 --> 01:20:05.760]   It's fine.
[01:20:05.760 --> 01:20:06.240]   Google.
[01:20:06.240 --> 01:20:10.000]   I don't care if Google saves my freakin' recordings.
[01:20:10.000 --> 01:20:13.600]   I really fear, and this is the Jeff Jarvis moment.
[01:20:13.600 --> 01:20:16.640]   Thank you, Matt.
[01:20:16.640 --> 01:20:17.440]   You missed the Jarvis?
[01:20:17.440 --> 01:20:23.920]   Fear people have, somewhat irrational fear people have of technology and computing
[01:20:23.920 --> 01:20:28.880]   is going to lead to regulation that prevents this kind of information.
[01:20:28.880 --> 01:20:29.880]   I think-
[01:20:29.880 --> 01:20:31.040]   And I don't want that to happen.
[01:20:31.040 --> 01:20:33.120]   I don't think it has to.
[01:20:33.120 --> 01:20:35.920]   And like, what Google's calling ambient computing,
[01:20:35.920 --> 01:20:39.600]   let's think about, remember we've talked about it a couple of times on the show,
[01:20:39.600 --> 01:20:43.920]   this concept of ambient privacy, which is with all of this data being sucked up.
[01:20:43.920 --> 01:20:48.560]   There is the ability of people and entities knowing where you are and what you're doing
[01:20:48.560 --> 01:20:53.120]   in all aspects of your life that could be discomforting.
[01:20:53.120 --> 01:20:55.120]   And not because you're doing anything wrong, just because
[01:20:57.600 --> 01:21:03.120]   nobody's going to look good if they're being looked at 24/7 through a microscope.
[01:21:03.120 --> 01:21:04.400]   So I think-
[01:21:04.400 --> 01:21:04.880]   I do.
[01:21:04.880 --> 01:21:05.440]   We need to be-
[01:21:05.440 --> 01:21:09.600]   Well, Leo, I'm not going there.
[01:21:09.600 --> 01:21:11.920]   Not at all.
[01:21:11.920 --> 01:21:16.480]   But that's a subjective, I mean, if you feel that way, fine, but I don't want to be told
[01:21:16.480 --> 01:21:19.280]   that I can't be looked at 24/7 under a microscope.
[01:21:19.280 --> 01:21:20.960]   No, that's my choice.
[01:21:20.960 --> 01:21:23.680]   The issue isn't that Google's collecting it.
[01:21:23.680 --> 01:21:28.400]   The issue is that our government can come along or an entity that has the power to
[01:21:28.400 --> 01:21:35.280]   detain you or to negatively affect your life in a really tangible way,
[01:21:35.280 --> 01:21:39.440]   can come along and use that data for ill.
[01:21:39.440 --> 01:21:45.280]   But we're asking the government the same party to legislate this.
[01:21:45.280 --> 01:21:46.800]   We are.
[01:21:46.800 --> 01:21:47.840]   That's a-
[01:21:47.840 --> 01:21:49.040]   You can't have a-
[01:21:49.040 --> 01:21:50.480]   Are they trust-
[01:21:50.480 --> 01:21:51.040]   Are they trust-
[01:21:51.040 --> 01:21:51.680]   Are they trust-
[01:21:51.680 --> 01:21:52.560]   That's the thing.
[01:21:52.560 --> 01:21:53.760]   Where's the cost?
[01:21:53.760 --> 01:21:54.720]   What's the cost?
[01:21:54.720 --> 01:21:55.920]   It's going to make it all happy for people.
[01:21:55.920 --> 01:21:59.040]   Why should anybody be able to tell me I can't have Google looking up my butt?
[01:21:59.040 --> 01:22:01.120]   I think we're talking about two different things.
[01:22:01.120 --> 01:22:04.240]   I'm not saying that Google can't gather this data.
[01:22:04.240 --> 01:22:06.480]   If I want to opt in to get this data, that's fine.
[01:22:06.480 --> 01:22:06.960]   Good.
[01:22:06.960 --> 01:22:07.440]   All right, you say it.
[01:22:07.440 --> 01:22:07.760]   Optics.
[01:22:07.760 --> 01:22:08.080]   We need rules-
[01:22:08.080 --> 01:22:09.280]   No, no.
[01:22:09.280 --> 01:22:14.000]   We need rules that dictate how that data will be used in by whom.
[01:22:14.000 --> 01:22:16.960]   So we need the equivalent of a legit search warrant.
[01:22:16.960 --> 01:22:18.480]   I wouldn't go that far.
[01:22:18.480 --> 01:22:24.000]   I would say we need full transparency and disclosure and then the choice.
[01:22:24.000 --> 01:22:29.120]   And it's certainly up to anybody to write, well, here's why you don't want to give them
[01:22:29.120 --> 01:22:30.640]   that information and so forth.
[01:22:30.640 --> 01:22:33.120]   There's sure-
[01:22:33.120 --> 01:22:37.360]   You know, of course, constitutional restrictions, search warrants and all of that.
[01:22:37.360 --> 01:22:41.840]   You know, I don't want the Constitution to be undermined.
[01:22:41.840 --> 01:22:47.120]   And so the right against unlawful search and seizure should apply to this too.
[01:22:47.120 --> 01:22:47.840]   Yes.
[01:22:47.840 --> 01:22:49.520]   I'm not saying I'm being a nat.
[01:22:49.520 --> 01:22:53.920]   Did you read the New York Times article probably a week and a half ago about people in my neck
[01:22:53.920 --> 01:22:58.640]   of the woods using Palantir and other companies to-
[01:22:58.640 --> 01:23:00.240]   Palantir's problematic, I agree.
[01:23:00.240 --> 01:23:04.160]   But it's not just Palantir.
[01:23:04.160 --> 01:23:08.000]   I mean, Google, in Facebook have some of the same information.
[01:23:08.000 --> 01:23:14.240]   They're just not at this moment making it available as a service to the government, for example.
[01:23:14.240 --> 01:23:15.360]   But they could.
[01:23:15.360 --> 01:23:18.400]   And so, and this is where it starts.
[01:23:18.400 --> 01:23:23.920]   We need to, if not, and we can't just shut down everything by saying,
[01:23:23.920 --> 01:23:29.040]   "I don't want regulation," because regulation should come from us having conversations about
[01:23:29.040 --> 01:23:33.920]   what we want to see and what we value as a society, as a democratic society.
[01:23:33.920 --> 01:23:39.200]   And what's happening today is every time we try to have those conversations,
[01:23:39.200 --> 01:23:43.360]   we get shut down or we're like, we're not able to meet in the middle and talk about it.
[01:23:43.360 --> 01:23:49.120]   We're just like, "I don't want any regulation. It's my right," or, "I don't want any of this data
[01:23:49.120 --> 01:23:53.760]   anywhere." So, I would like to start trying to have these conversations.
[01:23:53.760 --> 01:23:56.400]   Yes, I think you're right.
[01:23:56.400 --> 01:23:58.560]   And I'm not going to shout techno panic.
[01:23:58.560 --> 01:23:59.920]   Technopanic!
[01:23:59.920 --> 01:24:01.600]   Technopanic!
[01:24:01.600 --> 01:24:02.960]   You did that to system, sir.
[01:24:02.960 --> 01:24:03.920]   Get out.
[01:24:03.920 --> 01:24:06.320]   No, it's just because I'm channeling Jeff.
[01:24:06.320 --> 01:24:12.960]   I think this stuff should be regulated, but boy, I did get a little chill down my spine when I heard
[01:24:13.440 --> 01:24:19.360]   Elizabeth Warren and Bernie Sanders and Kamala Harris and all these candidates last night saying,
[01:24:19.360 --> 01:24:25.440]   "Yeah, we've got a break up big tech," because I just feel like the way they're going to break it up
[01:24:25.440 --> 01:24:26.960]   is with a buzz saw.
[01:24:26.960 --> 01:24:30.080]   They're not really going to break up tech.
[01:24:30.080 --> 01:24:30.480]   They can't.
[01:24:30.480 --> 01:24:31.840]   I don't think they can.
[01:24:31.840 --> 01:24:33.040]   This is campaign talk.
[01:24:33.040 --> 01:24:34.960]   But still...
[01:24:34.960 --> 01:24:42.400]   I mean, heck, Warren is so up in arms about Facebook, but yet she still uses her account for
[01:24:42.400 --> 01:24:43.280]   campaigning.
[01:24:43.280 --> 01:24:43.840]   Yeah.
[01:24:43.840 --> 01:24:44.880]   Well, she has to.
[01:24:44.880 --> 01:24:48.640]   I mean, if she's not on Facebook, she'd work in the election.
[01:24:48.640 --> 01:24:52.000]   John Constantine, I think it was on TechCrunch had a great proposal.
[01:24:52.000 --> 01:24:53.600]   Here's the solution.
[01:24:53.600 --> 01:24:57.200]   Facebook should not sell political ads.
[01:24:57.200 --> 01:24:58.560]   Period.
[01:24:58.560 --> 01:24:59.280]   Simple enough.
[01:24:59.280 --> 01:24:59.600]   Yeah.
[01:24:59.600 --> 01:25:02.960]   And then if a candidate wants to put out a message, they put it on their page,
[01:25:02.960 --> 01:25:04.640]   they can lie if they want whatever.
[01:25:04.640 --> 01:25:06.480]   They just shouldn't sell political ads.
[01:25:06.480 --> 01:25:07.440]   That's too simple to...
[01:25:07.440 --> 01:25:09.360]   It's a very simple solution.
[01:25:09.360 --> 01:25:14.880]   They make a lot of money, but they still will make a lot of money.
[01:25:14.880 --> 01:25:17.200]   They're not making...
[01:25:17.200 --> 01:25:19.360]   That's not the biggest money flowing in.
[01:25:19.360 --> 01:25:22.160]   They should just stop selling campaign ads.
[01:25:22.160 --> 01:25:25.360]   That's the problem in a nutshell.
[01:25:25.360 --> 01:25:28.080]   That's the Russian's bottom last time.
[01:25:28.080 --> 01:25:29.200]   They should just not have them.
[01:25:29.200 --> 01:25:30.720]   They can have groups all they want.
[01:25:30.720 --> 01:25:34.080]   And if people want to share it back and forth, and that's fine.
[01:25:34.080 --> 01:25:36.320]   But the ads, I think, are the...
[01:25:36.320 --> 01:25:38.080]   Maybe I'm wrong, but I agree with Konstein.
[01:25:38.080 --> 01:25:39.840]   I think that that was exactly the right.
[01:25:39.840 --> 01:25:41.920]   Stations tomorrow.
[01:25:41.920 --> 01:25:42.880]   What's happening tomorrow?
[01:25:42.880 --> 01:25:44.000]   Well, Mark is talking...
[01:25:44.000 --> 01:25:50.160]   Mark will tell us all what he thinks about who should do what on Facebook tomorrow.
[01:25:50.160 --> 01:25:51.360]   I'm so done with that.
[01:25:51.360 --> 01:25:54.240]   And let's just skip it until then.
[01:25:54.240 --> 01:25:55.520]   I'm so done.
[01:25:55.520 --> 01:25:58.240]   I'm so done with this whole thing.
[01:25:58.240 --> 01:25:59.040]   It's so sad.
[01:25:59.040 --> 01:26:02.720]   So I have a favor to ask of you, Kevin Tofel.
[01:26:02.720 --> 01:26:04.000]   Oh, what's that?
[01:26:04.000 --> 01:26:05.440]   Do you still have your mini plugged in?
[01:26:05.440 --> 01:26:07.200]   I do.
[01:26:07.200 --> 01:26:08.000]   Would you say...
[01:26:08.000 --> 01:26:10.080]   Okay, you got it.
[01:26:10.080 --> 01:26:10.480]   I don't...
[01:26:10.480 --> 01:26:11.920]   You're going to bloop it later.
[01:26:11.920 --> 01:26:15.040]   And I apologize to everybody at home for what I'm about to say.
[01:26:15.040 --> 01:26:16.000]   Say "hot word."
[01:26:16.000 --> 01:26:17.040]   Hey, hot word.
[01:26:17.040 --> 01:26:19.280]   Talk like ISA.
[01:26:19.280 --> 01:26:22.160]   Just try it.
[01:26:22.160 --> 01:26:22.800]   Hey, Google.
[01:26:22.800 --> 01:26:24.240]   Talk like ISA.
[01:26:24.240 --> 01:26:27.520]   Hey, Esa Ray here.
[01:26:27.520 --> 01:26:29.680]   I let my voice to your Google Assistant.
[01:26:29.680 --> 01:26:32.560]   So you can hear me do things like answer your questions,
[01:26:32.560 --> 01:26:33.680]   breathe you on the weather,
[01:26:33.680 --> 01:26:36.960]   and tell jokes while the regular Assistant voice does the rest.
[01:26:36.960 --> 01:26:37.920]   Let's do this thing.
[01:26:37.920 --> 01:26:40.400]   So you now have Esa Ray.
[01:26:40.400 --> 01:26:41.440]   Hey, Google.
[01:26:41.440 --> 01:26:42.800]   So, John...
[01:26:42.800 --> 01:26:46.400]   Yeah, she sounds very robotic.
[01:26:46.400 --> 01:26:49.840]   She sounds more robotic than the Assistant.
[01:26:49.840 --> 01:26:50.160]   Right.
[01:26:50.160 --> 01:26:52.160]   So I had John Legend for a long time,
[01:26:52.160 --> 01:26:54.480]   but apparently as of October 10th,
[01:26:54.480 --> 01:26:56.800]   Esa Ray is also an option.
[01:26:56.800 --> 01:26:59.520]   Yeah, the mic's off all right.
[01:26:59.520 --> 01:27:02.480]   You don't want to send your Google?
[01:27:03.440 --> 01:27:07.200]   No, I use like the Australian woman accent.
[01:27:07.200 --> 01:27:08.880]   You use red or whatever.
[01:27:08.880 --> 01:27:11.440]   I forget what colors it is, but yes.
[01:27:11.440 --> 01:27:13.440]   I like John Legend.
[01:27:13.440 --> 01:27:15.520]   I have John Legend wake me up every morning.
[01:27:15.520 --> 01:27:17.840]   But now I have Esa wake me up every morning.
[01:27:17.840 --> 01:27:20.800]   And I have a question for these two.
[01:27:20.800 --> 01:27:24.160]   We talked about this ambient computing.
[01:27:24.160 --> 01:27:27.360]   What do you think is the next phase?
[01:27:27.360 --> 01:27:29.920]   What could potentially be the next milestone?
[01:27:29.920 --> 01:27:32.800]   If you look in your crystal ball and say,
[01:27:32.800 --> 01:27:34.480]   "Hey, this is the next offering
[01:27:34.480 --> 01:27:36.400]   that could really help out in the home
[01:27:36.400 --> 01:27:39.520]   and help people be even more comfortable with smart tech."
[01:27:39.520 --> 01:27:41.680]   Ooh, you want to have a fun game?
[01:27:41.680 --> 01:27:43.680]   Let's write the word on a piece of paper, Kevin,
[01:27:43.680 --> 01:27:44.960]   and see if we write the same word.
[01:27:44.960 --> 01:27:45.760]   Please.
[01:27:45.760 --> 01:27:51.360]   I don't think we will because the tail end of Ant's question,
[01:27:51.360 --> 01:27:52.720]   and I don't have any paper.
[01:27:52.720 --> 01:27:54.480]   What's the paper?
[01:27:54.480 --> 01:27:56.160]   I'll go first.
[01:27:56.160 --> 01:27:57.200]   I'll go first.
[01:27:57.200 --> 01:27:57.680]   Right.
[01:27:57.680 --> 01:27:58.160]   Right.
[01:27:58.160 --> 01:27:58.640]   So...
[01:27:58.640 --> 01:27:59.760]   Wait a minute, let me take notes.
[01:27:59.760 --> 01:28:01.360]   Answer the question again.
[01:28:01.360 --> 01:28:02.480]   What will the next...
[01:28:02.480 --> 01:28:03.120]   What is it?
[01:28:03.120 --> 01:28:04.400]   The phase of ambient computing be...
[01:28:04.400 --> 01:28:06.160]   Yeah, what's the next milestone?
[01:28:06.160 --> 01:28:07.600]   Because this is a big milestone,
[01:28:07.600 --> 01:28:09.600]   as Miss Stacy mentions,
[01:28:09.600 --> 01:28:11.280]   with we're getting the software there,
[01:28:11.280 --> 01:28:13.360]   and now we have these chips in place
[01:28:13.360 --> 01:28:16.080]   to do it all right there on the device.
[01:28:16.080 --> 01:28:20.320]   What's the next milestone in this phase of ambient computing?
[01:28:20.320 --> 01:28:22.320]   Getting more comfortable.
[01:28:22.320 --> 01:28:24.080]   So Stacy's already written it down.
[01:28:24.080 --> 01:28:26.160]   I have thought of a word...
[01:28:26.160 --> 01:28:26.640]   Now that you've asked it that way,
[01:28:26.640 --> 01:28:27.760]   I kind of have a different...
[01:28:27.760 --> 01:28:28.480]   Oh.
[01:28:28.480 --> 01:28:29.280]   Ah.
[01:28:29.280 --> 01:28:31.520]   So I'm like, "Oh, wait."
[01:28:32.240 --> 01:28:33.760]   So I'll give my word,
[01:28:33.760 --> 01:28:35.920]   because the second time you ask that,
[01:28:35.920 --> 01:28:37.840]   you didn't put the scary part in which it's good,
[01:28:37.840 --> 01:28:40.240]   because my first answer would have been scary.
[01:28:40.240 --> 01:28:40.560]   Okay.
[01:28:40.560 --> 01:28:42.160]   The one word is...
[01:28:42.160 --> 01:28:43.200]   Presence.
[01:28:43.200 --> 01:28:44.960]   That was my word.
[01:28:44.960 --> 01:28:46.480]   Oh my God.
[01:28:46.480 --> 01:28:49.680]   You guys should play a password,
[01:28:49.680 --> 01:28:50.880]   or whatever that game is.
[01:28:50.880 --> 01:28:52.720]   We should do an IoT podcast together.
[01:28:52.720 --> 01:28:54.240]   What's happening?
[01:28:54.240 --> 01:28:55.120]   What is presence?
[01:28:55.120 --> 01:28:56.480]   Two berries and a pikres.
[01:28:56.480 --> 01:28:58.480]   Hey kids, what's presence?
[01:28:59.360 --> 01:29:03.680]   So presence is the next step in context of the smart home,
[01:29:03.680 --> 01:29:07.760]   where it knows where a specific person is in the home.
[01:29:07.760 --> 01:29:10.160]   So when I walk into the room,
[01:29:10.160 --> 01:29:11.760]   my lighting preferences go on,
[01:29:11.760 --> 01:29:13.680]   as opposed to somebody else's.
[01:29:13.680 --> 01:29:14.320]   I like that.
[01:29:14.320 --> 01:29:14.880]   I dig that.
[01:29:14.880 --> 01:29:17.600]   And Google's actually sort of working with...
[01:29:17.600 --> 01:29:20.240]   So presence is a key part of any contextual awareness.
[01:29:20.240 --> 01:29:24.880]   And Google's working on it with the voice understanding,
[01:29:24.880 --> 01:29:28.320]   or attempts to understand that I'm asking for things like call mom.
[01:29:29.040 --> 01:29:30.080]   And then it calls my mom,
[01:29:30.080 --> 01:29:32.560]   but if my husband asked for call mom, it calls his mom.
[01:29:32.560 --> 01:29:35.920]   So just imagine that applied to your location in your home,
[01:29:35.920 --> 01:29:39.040]   or the fact that you're the person driving the car at the new home.
[01:29:39.040 --> 01:29:41.680]   My hub, Max, when I walk in front of it, it sees me.
[01:29:41.680 --> 01:29:42.720]   And it's...
[01:29:42.720 --> 01:29:43.760]   So that was a win.
[01:29:43.760 --> 01:29:44.240]   ...it was up my calendar and stuff.
[01:29:44.240 --> 01:29:44.800]   So that's kind of...
[01:29:44.800 --> 01:29:45.600]   That was gonna be my second thing,
[01:29:45.600 --> 01:29:47.440]   was computer vision was gonna be my...
[01:29:47.440 --> 01:29:49.040]   That goes here and...
[01:29:49.040 --> 01:29:50.480]   It can.
[01:29:50.480 --> 01:29:52.560]   It can also do a lot more.
[01:29:52.560 --> 01:29:53.280]   But yes.
[01:29:53.280 --> 01:29:57.760]   When Bill Gates, 20 or 30 years ago,
[01:29:57.760 --> 01:29:59.200]   became the richest man in the world,
[01:29:59.200 --> 01:30:03.040]   and he built his underground bunker in the Seattle area,
[01:30:03.040 --> 01:30:06.400]   one of the things he put in, everybody was so...
[01:30:06.400 --> 01:30:08.960]   Oh, this is so modern, so forward thinking.
[01:30:08.960 --> 01:30:11.120]   Every guest who was invited to stay at the house
[01:30:11.120 --> 01:30:12.000]   would be given a little...
[01:30:12.000 --> 01:30:13.040]   Some sort of...
[01:30:13.040 --> 01:30:14.640]   A little NFC card or RFI card.
[01:30:14.640 --> 01:30:15.360]   Yeah, RFI card.
[01:30:15.360 --> 01:30:15.840]   Yep.
[01:30:15.840 --> 01:30:16.800]   And when he walked into a room,
[01:30:16.800 --> 01:30:22.240]   his favorite or her favorite art would appear in the magic frames of the art.
[01:30:22.240 --> 01:30:23.520]   Right? That's presence.
[01:30:23.520 --> 01:30:24.160]   Yes.
[01:30:24.160 --> 01:30:24.560]   Yes.
[01:30:24.560 --> 01:30:27.200]   And where it gets interesting, though,
[01:30:27.200 --> 01:30:30.560]   and what I think is kind of fun to think about is
[01:30:30.560 --> 01:30:34.800]   if Kevin and I are in the same place and are like,
[01:30:34.800 --> 01:30:36.080]   we're in the same room,
[01:30:36.080 --> 01:30:37.840]   whose preferences win or...
[01:30:37.840 --> 01:30:38.560]   Mine.
[01:30:38.560 --> 01:30:40.960]   What does the assistant do?
[01:30:40.960 --> 01:30:42.960]   I'm like, are we gonna have to listen to my...
[01:30:42.960 --> 01:30:44.880]   While my guitar gently weeps?
[01:30:44.880 --> 01:30:46.080]   So if you want to take it further,
[01:30:46.080 --> 01:30:47.520]   then you have to start thinking about like,
[01:30:47.520 --> 01:30:50.960]   how the digital assistants for each person mesh,
[01:30:50.960 --> 01:30:53.280]   or does a person need their own digital assistant?
[01:30:53.280 --> 01:30:55.200]   And then the family gets a digital assistant.
[01:30:55.200 --> 01:30:56.240]   It's kind of fun to think about.
[01:30:56.240 --> 01:30:58.320]   It'll meet in the middle and play Rocky Vercoon.
[01:30:58.320 --> 01:31:00.080]   That's a good sign.
[01:31:00.080 --> 01:31:03.920]   I have to figure that this house that he built in Medina, Washington,
[01:31:03.920 --> 01:31:08.480]   for 154 million dollars is now 40 years later,
[01:31:08.480 --> 01:31:12.560]   kind of a museum of out of technology.
[01:31:12.560 --> 01:31:14.000]   I'm sure it's been up to...
[01:31:14.000 --> 01:31:15.680]   Oh, is that on Lake Union?
[01:31:15.680 --> 01:31:16.400]   Yeah.
[01:31:16.400 --> 01:31:17.360]   You've seen it?
[01:31:17.360 --> 01:31:18.640]   I've seen it from my friend's boat.
[01:31:18.640 --> 01:31:20.000]   There's a bunch of houses.
[01:31:20.000 --> 01:31:20.560]   A million?
[01:31:20.560 --> 01:31:21.200]   That's like a complex.
[01:31:21.200 --> 01:31:21.600]   Oh, yeah.
[01:31:21.600 --> 01:31:22.240]   It's like...
[01:31:22.240 --> 01:31:23.040]   I don't remember.
[01:31:23.040 --> 01:31:25.360]   It's like 80,000 square feet or something.
[01:31:25.360 --> 01:31:27.760]   It's a million dollars a year in property taxes alone.
[01:31:27.760 --> 01:31:30.880]   I think the sound system is running on a Zoom.
[01:31:30.880 --> 01:31:33.200]   What you don't see is a lot of it is underground.
[01:31:33.200 --> 01:31:34.880]   You're just seeing the surface buildings.
[01:31:34.880 --> 01:31:36.000]   There's a lot of it's underground,
[01:31:36.000 --> 01:31:37.840]   including a big parking garage.
[01:31:37.840 --> 01:31:38.880]   A Zoom, yeah.
[01:31:38.880 --> 01:31:41.840]   Everybody gets a Zoom when they check in.
[01:31:41.840 --> 01:31:44.720]   It's like when you go to those hotels
[01:31:44.720 --> 01:31:49.040]   and they've got the 30 pin docks for your clock radio.
[01:31:49.040 --> 01:31:51.040]   We're hip and with it.
[01:31:51.040 --> 01:31:54.960]   Technology changes way too fast.
[01:31:54.960 --> 01:31:55.600]   Clearly.
[01:31:55.600 --> 01:31:56.080]   Yeah.
[01:31:56.080 --> 01:31:57.600]   You can't really build it into a house.
[01:31:57.600 --> 01:31:59.040]   But that's...
[01:31:59.040 --> 01:32:01.760]   I honestly think that we're really getting to the step.
[01:32:01.760 --> 01:32:04.480]   I saw this right away when Amazon released the Echo,
[01:32:04.480 --> 01:32:06.240]   the idea of talking to your house.
[01:32:06.240 --> 01:32:08.160]   Those devices kind of disappear.
[01:32:08.160 --> 01:32:11.360]   And that's what to me, ambient computing is.
[01:32:11.360 --> 01:32:13.680]   It's not the vice tied to a device.
[01:32:13.680 --> 01:32:14.640]   It's just ambient.
[01:32:14.640 --> 01:32:15.440]   It's around you.
[01:32:15.440 --> 01:32:18.720]   And anytime you want something you ask for it,
[01:32:18.720 --> 01:32:21.760]   and your little plastic pal helps you somehow.
[01:32:21.760 --> 01:32:24.400]   And that's cool.
[01:32:24.400 --> 01:32:26.960]   But they also could be creepy to some.
[01:32:26.960 --> 01:32:27.200]   Yeah.
[01:32:27.200 --> 01:32:29.600]   And after that, you won't ask it.
[01:32:29.600 --> 01:32:31.440]   It will suggest to you.
[01:32:31.440 --> 01:32:31.840]   Oh yeah.
[01:32:31.840 --> 01:32:32.240]   Let's see.
[01:32:32.240 --> 01:32:36.400]   That's the next phase is how are we going to get people more comfortable
[01:32:36.400 --> 01:32:39.520]   with knowing that these devices are here in our...
[01:32:39.520 --> 01:32:40.000]   Here's an example.
[01:32:40.000 --> 01:32:41.280]   ...quoting quote surveilling,
[01:32:41.280 --> 01:32:43.840]   but it's also something that's useful in your house.
[01:32:43.840 --> 01:32:45.680]   There are six kitchens in this house.
[01:32:45.680 --> 01:32:46.480]   Just six.
[01:32:46.480 --> 01:32:47.280]   Very modern.
[01:32:47.280 --> 01:32:48.640]   Look at the size of the TV.
[01:32:48.640 --> 01:32:49.440]   Just six.
[01:32:49.440 --> 01:32:50.720]   Oh man.
[01:32:50.720 --> 01:32:51.440]   It's massive.
[01:32:51.440 --> 01:32:53.760]   It's like 42 inch TV in the kitchen.
[01:32:53.760 --> 01:32:56.480]   Oh, MG.
[01:32:56.480 --> 01:32:56.720]   OK.
[01:32:56.720 --> 01:32:59.760]   I'm just saying, you know, that's the problem with this.
[01:32:59.760 --> 01:33:00.320]   Yikes.
[01:33:00.320 --> 01:33:03.440]   Uh, I thought you were going to say,
[01:33:03.440 --> 01:33:05.680]   look how small that TV is for a kitchen.
[01:33:05.680 --> 01:33:06.560]   That's what I'm saying.
[01:33:06.560 --> 01:33:07.600]   It is small for the kitchen.
[01:33:07.600 --> 01:33:09.040]   It's a 42 inch TV.
[01:33:09.040 --> 01:33:10.480]   That's the problem is that, you know,
[01:33:10.480 --> 01:33:12.240]   technology ages so fast.
[01:33:12.240 --> 01:33:15.920]   So in a way, you better not build it into the house.
[01:33:15.920 --> 01:33:17.600]   You know, you better let Google take over.
[01:33:17.600 --> 01:33:21.120]   And I do think that people...
[01:33:23.600 --> 01:33:27.600]   ...see different people have different places
[01:33:27.600 --> 01:33:29.040]   where their creepy line is crossed.
[01:33:29.040 --> 01:33:30.320]   Mm-hmm.
[01:33:30.320 --> 01:33:34.400]   Well, and I actually, I wrote this in last week's newsletter.
[01:33:34.400 --> 01:33:38.400]   I talked to somebody who did focus groups around Madam A.
[01:33:38.400 --> 01:33:40.080]   And he said in the focus groups,
[01:33:40.080 --> 01:33:41.920]   there was a very clear delineation of people
[01:33:41.920 --> 01:33:45.920]   who associated Madam A with this embodiment
[01:33:45.920 --> 01:33:47.520]   of a digital assistant in the cloud.
[01:33:47.520 --> 01:33:49.920]   So it was everywhere, which is kind of how I think of it.
[01:33:49.920 --> 01:33:52.960]   But there was a really large group of people
[01:33:52.960 --> 01:33:56.960]   who also thought of Madam A as being tied to a particular device.
[01:33:56.960 --> 01:33:58.720]   That's what they don't want.
[01:33:58.720 --> 01:33:59.200]   Mm-hmm. Yeah.
[01:33:59.200 --> 01:34:00.400]   Right.
[01:34:00.400 --> 01:34:04.320]   And so I think part of this is education,
[01:34:04.320 --> 01:34:06.160]   part of this is, again, the trust.
[01:34:06.160 --> 01:34:08.800]   Because these companies are going to know so much about you
[01:34:08.800 --> 01:34:10.240]   that if you don't trust them,
[01:34:10.240 --> 01:34:14.000]   you're not going to welcome them into your home in life.
[01:34:14.000 --> 01:34:18.080]   And honestly, you know, some people will never be convinced.
[01:34:18.080 --> 01:34:19.120]   Some people are like,
[01:34:19.120 --> 01:34:21.840]   "I can walk over and turn the lights on for the switch."
[01:34:21.840 --> 01:34:24.480]   And I don't think those are actually the use cases
[01:34:24.480 --> 01:34:26.160]   that will get people excited about this.
[01:34:26.160 --> 01:34:29.760]   I think it's probably more the security and monitoring kind of things.
[01:34:29.760 --> 01:34:33.440]   Or like, I call it education.
[01:34:33.440 --> 01:34:36.800]   So things that will educate you or make you do things better
[01:34:36.800 --> 01:34:39.200]   because they're just simply smarter, like the June oven.
[01:34:39.200 --> 01:34:42.800]   So yeah, I think there's--
[01:34:42.800 --> 01:34:44.400]   There's what's going to stop this.
[01:34:44.400 --> 01:34:45.280]   There's going to stop this.
[01:34:45.280 --> 01:34:48.560]   Here's the thing that's going to be the problem is interoperability.
[01:34:48.560 --> 01:34:50.000]   And somewhere on your refrigerator.
[01:34:50.000 --> 01:34:51.360]   Well, that will be a problem too.
[01:34:51.360 --> 01:34:52.480]   But interoperability.
[01:34:52.480 --> 01:34:55.840]   So you do different things with different things?
[01:34:55.840 --> 01:34:57.120]   No, that's not what you want.
[01:34:57.120 --> 01:34:58.400]   No, I think of--
[01:34:58.400 --> 01:34:59.920]   Madam A is--
[01:34:59.920 --> 01:35:00.560]   No, that's dumb.
[01:35:00.560 --> 01:35:04.080]   Madam A is my IOT and speakers solution.
[01:35:04.080 --> 01:35:06.720]   Google is my thing that knows stuff.
[01:35:06.720 --> 01:35:07.840]   Yeah, but that's dumb.
[01:35:07.840 --> 01:35:08.480]   Who was it?
[01:35:08.480 --> 01:35:09.920]   Somebody just said, or maybe it was--
[01:35:09.920 --> 01:35:10.480]   Wow.
[01:35:10.480 --> 01:35:11.680]   --with us weekly.
[01:35:11.680 --> 01:35:13.360]   That I think it was Paul saying,
[01:35:13.360 --> 01:35:15.520]   "I've got Echo and Google devices everywhere."
[01:35:15.520 --> 01:35:18.720]   But everybody's used to saying the A word.
[01:35:18.720 --> 01:35:18.880]   Yeah.
[01:35:18.880 --> 01:35:20.560]   And nobody ever says the G word.
[01:35:20.560 --> 01:35:21.120]   All right.
[01:35:21.120 --> 01:35:25.920]   It's-- that's a semantic burden that we shouldn't have to carry.
[01:35:25.920 --> 01:35:26.400]   You know, we're--
[01:35:26.400 --> 01:35:26.960]   I don't know.
[01:35:26.960 --> 01:35:27.920]   We're going to be giving a five.
[01:35:27.920 --> 01:35:29.120]   Paul, wait, wait.
[01:35:29.120 --> 01:35:31.520]   So you do ask certain friends for certain things.
[01:35:31.520 --> 01:35:34.560]   Like, I've got a buddy that I'll call to go out and meet for Jin.
[01:35:34.560 --> 01:35:35.760]   You know, because she's a big Jin fan.
[01:35:35.760 --> 01:35:37.920]   I've got another buddy I meet for cake.
[01:35:37.920 --> 01:35:39.760]   Because she's the only one of my friends that eats cake.
[01:35:39.760 --> 01:35:42.160]   Wouldn't you like it if all your buddies like Jin and cake?
[01:35:42.160 --> 01:35:42.720]   That's awesome.
[01:35:42.720 --> 01:35:43.920]   Yeah, that would be amazing.
[01:35:43.920 --> 01:35:45.280]   But it's not the way the world works.
[01:35:45.280 --> 01:35:45.600]   So--
[01:35:45.600 --> 01:35:47.360]   It is the way digital world could work.
[01:35:47.360 --> 01:35:48.720]   My point.
[01:35:48.720 --> 01:35:49.760]   It could.
[01:35:49.760 --> 01:35:50.560]   Why should you have--
[01:35:50.560 --> 01:35:51.760]   that's an artificial distinction.
[01:35:51.760 --> 01:35:52.800]   But when you're--
[01:35:52.800 --> 01:35:53.120]   So you need--
[01:35:53.120 --> 01:35:56.640]   When you've got plastic pals, you shouldn't--
[01:35:56.640 --> 01:36:01.040]   You shouldn't even have to say the keyword as you pointed out.
[01:36:01.040 --> 01:36:02.400]   They should know what you want.
[01:36:02.400 --> 01:36:05.920]   Or you should just say out loud, boy, I sure like a cup of hot tea right now.
[01:36:05.920 --> 01:36:08.080]   Yeah, but that's a totalitarian viewpoint.
[01:36:08.080 --> 01:36:10.640]   Well, your creepy line is not my creepy line.
[01:36:10.640 --> 01:36:14.880]   Well, and you might end up buying a digital assistant and being able to
[01:36:14.880 --> 01:36:16.800]   apply it to all of your devices.
[01:36:16.800 --> 01:36:19.360]   And then later, you may buy a different version.
[01:36:19.360 --> 01:36:23.200]   So maybe Apple's series suddenly gets loads better and everyone goes out and buy
[01:36:23.200 --> 01:36:24.560]   Siri and applies it across.
[01:36:24.560 --> 01:36:29.360]   If we're talking about interoperability, I think we have to figure out what layer.
[01:36:29.360 --> 01:36:32.960]   So if you're talking about interoperability at the digital assistant layer,
[01:36:32.960 --> 01:36:34.720]   we're not there yet, but we could be there.
[01:36:34.720 --> 01:36:35.360]   That could get--
[01:36:35.360 --> 01:36:36.400]   This was interesting.
[01:36:36.400 --> 01:36:38.320]   That kept home automation from happening.
[01:36:38.320 --> 01:36:47.120]   So I would argue that now we have interoperability between most of our devices
[01:36:47.120 --> 01:36:49.040]   through a digital assistant platform.
[01:36:49.040 --> 01:36:50.880]   I really believe that.
[01:36:50.880 --> 01:36:52.720]   That's true.
[01:36:52.720 --> 01:36:57.200]   I can ask, well, no, because the Hello Doorbell rings my Google device.
[01:36:57.200 --> 01:36:58.400]   I've largely solved this.
[01:36:58.400 --> 01:37:01.360]   And Google has largely solved this.
[01:37:01.360 --> 01:37:05.360]   They've all largely solved the IoT.
[01:37:05.360 --> 01:37:08.960]   Everyone talking in different languages problem.
[01:37:08.960 --> 01:37:12.000]   Okay.
[01:37:12.000 --> 01:37:15.520]   Carsten's like, and that's the final word.
[01:37:15.520 --> 01:37:17.120]   [laughter]
[01:37:17.120 --> 01:37:17.680]   You're wrong.
[01:37:17.680 --> 01:37:20.720]   We're moving on to new problems.
[01:37:20.720 --> 01:37:26.400]   Daydream is dead.
[01:37:26.400 --> 01:37:26.960]   Do you care?
[01:37:26.960 --> 01:37:27.680]   Nobody cares.
[01:37:27.680 --> 01:37:28.720]   No.
[01:37:28.720 --> 01:37:30.080]   Was it ever alive?
[01:37:30.080 --> 01:37:31.040]   Was it ever alive?
[01:37:31.040 --> 01:37:33.360]   People need content for that, right?
[01:37:33.360 --> 01:37:33.760]   Oh, yeah.
[01:37:33.760 --> 01:37:35.440]   I feel sad with their content.
[01:37:35.440 --> 01:37:38.080]   But does Samsung do its gear VR either?
[01:37:38.080 --> 01:37:38.640]   I don't think so.
[01:37:38.640 --> 01:37:39.600]   That's dead too.
[01:37:39.600 --> 01:37:43.360]   I think I'm one of the few people that actually still use the Daydream,
[01:37:43.360 --> 01:37:44.960]   because it was really nice.
[01:37:44.960 --> 01:37:45.840]   It was comfy.
[01:37:45.840 --> 01:37:48.320]   No, VR is dead, period.
[01:37:48.320 --> 01:37:50.000]   Well, see, I didn't use it for VR.
[01:37:50.000 --> 01:37:52.960]   I just used it for that Hulu or Netflix.
[01:37:52.960 --> 01:37:54.720]   It was great.
[01:37:54.720 --> 01:37:56.960]   It was my sleep mask.
[01:37:56.960 --> 01:37:58.960]   Locked in, and, you know, it was immersive.
[01:37:58.960 --> 01:38:04.880]   I made the mistake of the first time I tried to do Netflix on the Daydream.
[01:38:04.880 --> 01:38:06.160]   I watched hardcore Henry.
[01:38:06.160 --> 01:38:09.600]   Oh, that must have made you nauseous.
[01:38:09.600 --> 01:38:12.320]   Yeah, there was vomiting involved.
[01:38:12.320 --> 01:38:12.960]   Oh, man.
[01:38:12.960 --> 01:38:14.560]   Oh, that's the movie.
[01:38:14.560 --> 01:38:17.600]   It's all first person, like, running around.
[01:38:17.600 --> 01:38:19.200]   Oh, there's a bless your heart quick right now.
[01:38:19.200 --> 01:38:21.520]   Clips.
[01:38:21.520 --> 01:38:22.560]   Clips is dead.
[01:38:22.560 --> 01:38:24.320]   I came so close to buying that.
[01:38:24.320 --> 01:38:26.000]   That was the little camera you just put there,
[01:38:26.000 --> 01:38:28.960]   and it would automatically get you the best pictures.
[01:38:28.960 --> 01:38:30.640]   I guess people thought that was too creepy.
[01:38:30.640 --> 01:38:31.280]   That was silly.
[01:38:31.280 --> 01:38:31.760]   Yeah.
[01:38:31.760 --> 01:38:32.480]   And creepy.
[01:38:32.480 --> 01:38:33.600]   Silly and creepy.
[01:38:33.600 --> 01:38:34.640]   That's a bad combination.
[01:38:34.640 --> 01:38:37.600]   And then Stacey wrote an article,
[01:38:37.600 --> 01:38:43.200]   "Why Google Risked Customer Goodwill to Kill."
[01:38:43.200 --> 01:38:44.560]   There's a lot of coz in this.
[01:38:44.560 --> 01:38:45.760]   Sorry.
[01:38:45.760 --> 01:38:46.240]   I told it.
[01:38:46.240 --> 01:38:47.520]   Can you rewrite the headline without the--
[01:38:47.520 --> 01:38:48.720]   Yeah, yeah.
[01:38:48.720 --> 01:38:53.280]   "Why Google Risked Customer Goodwill to Kill works with Nest."
[01:38:53.280 --> 01:38:56.000]   Why did they do that?
[01:38:56.000 --> 01:38:59.440]   Oh, see, this actually talks about some of this stuff,
[01:38:59.440 --> 01:38:59.920]   like the future of the arm.
[01:38:59.920 --> 01:39:01.760]   I gotta get the newsletter too.
[01:39:01.760 --> 01:39:02.880]   Jell Hosepads.
[01:39:02.880 --> 01:39:04.160]   It shouldn't do that every time.
[01:39:04.160 --> 01:39:06.720]   I'm sorry.
[01:39:06.720 --> 01:39:08.320]   Oh, don't apologize.
[01:39:08.320 --> 01:39:10.560]   I'm gonna yell at my IDA.
[01:39:10.560 --> 01:39:11.920]   No, no, no, don't apologize.
[01:39:11.920 --> 01:39:12.800]   This is good.
[01:39:12.800 --> 01:39:14.880]   We have ad blockers on our studio computers.
[01:39:14.880 --> 01:39:15.680]   So--
[01:39:15.680 --> 01:39:16.080]   Ad?
[01:39:16.080 --> 01:39:16.560]   So--
[01:39:16.560 --> 01:39:18.960]   Oh, that's why I'm running UBlock on it.
[01:39:18.960 --> 01:39:19.040]   It's all college.
[01:39:19.040 --> 01:39:21.440]   Arjun, so there's no way it could know that it saw this.
[01:39:21.440 --> 01:39:23.120]   We wouldn't know that we've been there.
[01:39:23.120 --> 01:39:23.680]   Oh.
[01:39:23.680 --> 01:39:24.240]   Okay.
[01:39:24.240 --> 01:39:24.960]   That makes me--
[01:39:24.960 --> 01:39:26.000]   You're not letting you track me.
[01:39:26.000 --> 01:39:27.120]   It's totally our fault.
[01:39:27.120 --> 01:39:28.080]   It is not your fault.
[01:39:28.080 --> 01:39:30.000]   I am disabling UBlock for this site.
[01:39:30.000 --> 01:39:31.760]   So I will see all the ads.
[01:39:31.760 --> 01:39:33.280]   There are no other ads on it.
[01:39:33.280 --> 01:39:33.680]   I know.
[01:39:33.680 --> 01:39:35.600]   You all have first person ads on this.
[01:39:35.600 --> 01:39:36.560]   This is very well done.
[01:39:36.560 --> 01:39:36.960]   Thank you.
[01:39:36.960 --> 01:39:40.080]   So there's like a logo for somebody in the corner,
[01:39:40.080 --> 01:39:40.640]   but that's it.
[01:39:40.640 --> 01:39:40.960]   Yeah.
[01:39:40.960 --> 01:39:41.600]   Very nice.
[01:39:41.600 --> 01:39:42.560]   Well done.
[01:39:42.560 --> 01:39:44.000]   Beautiful.
[01:39:44.000 --> 01:39:44.320]   Yeah.
[01:39:44.320 --> 01:39:45.440]   And I could pick heaven.
[01:39:45.440 --> 01:39:46.240]   Woo!
[01:39:46.240 --> 01:39:46.800]   Yeah.
[01:39:46.800 --> 01:39:47.280]   Yeah.
[01:39:47.280 --> 01:39:48.960]   Actually, Kevin should be the one wooing, I guess.
[01:39:48.960 --> 01:39:49.600]   But I'm excited.
[01:39:49.600 --> 01:39:50.240]   Woo!
[01:39:50.240 --> 01:39:51.680]   Woo!
[01:39:51.680 --> 01:39:52.960]   So tell us about this.
[01:39:52.960 --> 01:39:54.480]   Because this really upset people
[01:39:54.480 --> 01:39:56.640]   when they abandon works with Nest.
[01:39:56.640 --> 01:39:57.920]   Oh, yeah.
[01:39:57.920 --> 01:40:01.360]   So now they've gotten back into--
[01:40:01.360 --> 01:40:04.000]   they've solved a lot of the problems
[01:40:04.000 --> 01:40:05.600]   that people were most upset about.
[01:40:05.600 --> 01:40:07.280]   So back when they killed works with Nest,
[01:40:07.280 --> 01:40:09.200]   they were like, we've got to kill this.
[01:40:09.200 --> 01:40:11.440]   They did a terrible job explaining why.
[01:40:11.440 --> 01:40:15.760]   So basically what happened is when they decided to kill it,
[01:40:15.760 --> 01:40:17.760]   what was going to happen for people's devices
[01:40:17.760 --> 01:40:19.520]   is Nest used to always--
[01:40:19.520 --> 01:40:22.080]   Nest devices have the ability to trigger their own events.
[01:40:22.080 --> 01:40:23.360]   They were like their own little brains
[01:40:23.360 --> 01:40:24.640]   inside the smart home.
[01:40:24.640 --> 01:40:26.400]   And Google was like, we're going to make the brain
[01:40:26.400 --> 01:40:27.840]   Google Assistant and Google Assistant
[01:40:27.840 --> 01:40:29.200]   will control all the devices.
[01:40:29.200 --> 01:40:31.360]   And people were like, but I have a Nest device
[01:40:31.360 --> 01:40:33.520]   that talks to my Hugh Light bulbs and--
[01:40:33.520 --> 01:40:34.480]   Oh, shh.
[01:40:34.480 --> 01:40:35.280]   Shh.
[01:40:35.280 --> 01:40:38.640]   We're getting back to it.
[01:40:38.640 --> 01:40:40.720]   This is a negative side of ambient computing
[01:40:40.720 --> 01:40:43.120]   is that you hear voices a lot.
[01:40:43.120 --> 01:40:44.720]   And I've gotten used to it.
[01:40:44.720 --> 01:40:45.680]   Have you gotten used to it?
[01:40:45.680 --> 01:40:49.520]   Like my series, "Babbling" in all the time in the kitchen.
[01:40:49.520 --> 01:40:52.320]   I'm just so glad you all have joined me.
[01:40:52.320 --> 01:40:53.360]   Yeah.
[01:40:53.360 --> 01:40:55.840]   There's just voices like that.
[01:40:55.840 --> 01:40:58.720]   Constantly babbling in the background.
[01:40:58.720 --> 01:40:59.840]   And I just accept it.
[01:40:59.840 --> 01:41:01.280]   Yeah, it just goes away eventually.
[01:41:01.280 --> 01:41:02.320]   I just pretend it's all carsten.
[01:41:02.320 --> 01:41:03.120]   All right.
[01:41:03.120 --> 01:41:05.280]   That was terrible.
[01:41:05.280 --> 01:41:05.920]   That's what I do.
[01:41:05.920 --> 01:41:07.120]   That's my solution.
[01:41:07.120 --> 01:41:08.320]   All the voices are carsten.
[01:41:08.320 --> 01:41:09.520]   It's all made.
[01:41:09.520 --> 01:41:12.240]   If you had the slightest bit of mental illness
[01:41:12.240 --> 01:41:14.720]   in this modern world, it would be challenging.
[01:41:14.720 --> 01:41:15.440]   It could.
[01:41:15.440 --> 01:41:17.440]   Yeah.
[01:41:17.440 --> 01:41:21.680]   Or Google could become your friendly voice in your head.
[01:41:21.680 --> 01:41:22.480]   That's an interesting question.
[01:41:22.480 --> 01:41:23.200]   I wonder.
[01:41:23.200 --> 01:41:24.240]   Yeah.
[01:41:24.240 --> 01:41:25.040]   Anyway, go ahead.
[01:41:25.040 --> 01:41:26.080]   I'm sorry.
[01:41:26.080 --> 01:41:27.280]   That's OK.
[01:41:27.280 --> 01:41:31.040]   Anyway, so if your Hugh Light's talked to your
[01:41:31.040 --> 01:41:34.400]   Nest thermostat, now they would have to talk
[01:41:34.400 --> 01:41:35.360]   to the Google Assistant.
[01:41:35.360 --> 01:41:37.680]   And people were like, ah, I don't like that.
[01:41:37.680 --> 01:41:38.400]   Rightly so.
[01:41:38.400 --> 01:41:41.040]   So then Google was like, OK, we hear you.
[01:41:41.040 --> 01:41:42.800]   We're going to let you keep your Nest accounts.
[01:41:42.800 --> 01:41:45.680]   And you just won't get anything new.
[01:41:45.680 --> 01:41:46.080]   Later.
[01:41:46.080 --> 01:41:48.080]   But yeah.
[01:41:48.080 --> 01:41:51.680]   And most people, I asked Google, they would not tell me
[01:41:51.680 --> 01:41:54.000]   how they plan to--
[01:41:54.000 --> 01:41:56.800]   how many people actually didn't--
[01:41:56.800 --> 01:41:57.760]   oh, what's the word?
[01:41:57.760 --> 01:41:58.960]   Didn't switch over.
[01:41:58.960 --> 01:41:59.440]   Am I great?
[01:41:59.440 --> 01:42:00.160]   Oh, great.
[01:42:00.160 --> 01:42:00.640]   Am I great?
[01:42:00.640 --> 01:42:01.040]   Hey, great.
[01:42:01.040 --> 01:42:01.600]   That's the word.
[01:42:01.600 --> 01:42:02.160]   Am I great?
[01:42:02.160 --> 01:42:04.720]   So now what they've got with this new thing,
[01:42:04.720 --> 01:42:07.520]   the Works with Assistant program,
[01:42:07.520 --> 01:42:11.520]   will let certain third party companies
[01:42:11.520 --> 01:42:13.600]   talk directly to your Nest devices.
[01:42:13.600 --> 01:42:15.520]   So it's just like the old days.
[01:42:15.520 --> 01:42:18.480]   But now Google's saying to become a third party who
[01:42:18.480 --> 01:42:21.040]   has that ability, you have to pass a security
[01:42:21.040 --> 01:42:24.160]   certification exam every year.
[01:42:24.160 --> 01:42:25.520]   And that's why Google did this.
[01:42:25.520 --> 01:42:27.440]   Because they had to--
[01:42:27.440 --> 01:42:29.280]   the Verge actually had a great headline on this.
[01:42:29.280 --> 01:42:31.040]   I'm really pissed that I didn't think of it.
[01:42:31.040 --> 01:42:32.720]   Because I even thought about Cambridge Analytica
[01:42:32.720 --> 01:42:33.440]   why I was writing.
[01:42:33.440 --> 01:42:34.080]   Ah.
[01:42:34.080 --> 01:42:36.080]   But they were like, Google wants to prevent
[01:42:36.080 --> 01:42:37.760]   Cambridge Analytica in the smart home.
[01:42:37.760 --> 01:42:38.960]   And that's what they wanted.
[01:42:38.960 --> 01:42:40.320]   That was why they were trying to lock this down.
[01:42:40.320 --> 01:42:42.160]   That's a good point.
[01:42:42.160 --> 01:42:42.880]   Yes.
[01:42:42.880 --> 01:42:45.440]   They had all these third party companies
[01:42:45.440 --> 01:42:49.760]   accessing tens of different APIs on different devices.
[01:42:49.760 --> 01:42:55.360]   And so now they've locked that down, hopefully.
[01:42:55.360 --> 01:42:57.440]   And now they're starting to open it back up again.
[01:42:57.440 --> 01:42:58.880]   So now you've got those people who
[01:42:58.880 --> 01:43:02.000]   are allowed to use these things or talk to Nest directly.
[01:43:02.000 --> 01:43:05.200]   The other thing they did is establish home routines.
[01:43:05.200 --> 01:43:08.640]   And these are easy routines that basically--
[01:43:08.640 --> 01:43:10.320]   Google's making the first ones.
[01:43:10.320 --> 01:43:13.040]   And then later next year, third parties can also
[01:43:13.040 --> 01:43:14.880]   submit routines as well.
[01:43:14.880 --> 01:43:20.320]   But popular ones might be, hey, your Nest protect is going off.
[01:43:20.320 --> 01:43:25.600]   Let's flash the hue lights so people can see that there's
[01:43:25.600 --> 01:43:28.800]   smoke in the building.
[01:43:28.800 --> 01:43:32.320]   And then they also, for smart home people,
[01:43:32.320 --> 01:43:34.720]   they're at some point in time that they were not clear
[01:43:34.720 --> 01:43:37.600]   about are going to let us play with the devices
[01:43:37.600 --> 01:43:39.840]   and have access to our Nest devices.
[01:43:39.840 --> 01:43:41.840]   And part of this is, anytime you're
[01:43:41.840 --> 01:43:45.440]   going to give access to a third party to your data from Nest,
[01:43:45.440 --> 01:43:46.880]   you have to opt into that.
[01:43:46.880 --> 01:43:50.080]   And Google's going to make it very apparent what you're sharing.
[01:43:50.080 --> 01:43:53.120]   So that's what all of this is.
[01:43:53.120 --> 01:43:54.800]   Transparency.
[01:43:54.800 --> 01:43:55.920]   It's transparency.
[01:43:55.920 --> 01:43:58.080]   It's trying to make it more secure.
[01:43:58.080 --> 01:44:00.240]   And it's also locking--
[01:44:00.240 --> 01:44:03.520]   I mean, it's locking down the ecosystem.
[01:44:03.520 --> 01:44:07.440]   But it's still trying to give third parties and customers
[01:44:07.440 --> 01:44:08.640]   the ability to play with others.
[01:44:08.640 --> 01:44:11.920]   And I think that only came about because we had this Wild
[01:44:11.920 --> 01:44:14.720]   West era where some things were allowed to become popular.
[01:44:14.720 --> 01:44:16.960]   At least something good came out of Cambridge,
[01:44:16.960 --> 01:44:18.880]   and with a lesson learned.
[01:44:18.880 --> 01:44:21.360]   But that's-- but yeah, if we don't learn the lessons,
[01:44:21.360 --> 01:44:25.600]   then it really is worth nothing.
[01:44:25.600 --> 01:44:27.200]   Hey, let's play the trumpets because I
[01:44:27.200 --> 01:44:30.000]   think it's a quick change log, a couple of highlights,
[01:44:30.000 --> 01:44:32.000]   and then we're going to get you pics of the week.
[01:44:32.000 --> 01:44:34.000]   Play those trumpets, Carsten.
[01:44:34.000 --> 01:44:36.000]   [MUSIC PLAYING]
[01:44:36.000 --> 01:44:38.000]   The Google change log.
[01:44:38.000 --> 01:44:40.000]   [MUSIC PLAYING]
[01:44:40.000 --> 01:44:42.000]   [MUSIC PLAYING]
[01:44:42.000 --> 01:44:45.680]   Really good news if you use Google Maps.
[01:44:45.680 --> 01:44:49.120]   Especially if you're blind, they have added in-depth walking
[01:44:49.120 --> 01:44:52.040]   directions with detailed voice guidance.
[01:44:52.040 --> 01:44:55.680]   So it's like descriptive audio for maps.
[01:44:55.680 --> 01:45:00.080]   And Google rolled this out on World Sight Day.
[01:45:00.080 --> 01:45:02.320]   In-depth walking instructions in Google Maps,
[01:45:02.320 --> 01:45:04.920]   including the distance to your next turn, a warning
[01:45:04.920 --> 01:45:07.000]   if it's a busy intersection ahead,
[01:45:07.000 --> 01:45:08.880]   notifying you if you go off route.
[01:45:08.880 --> 01:45:11.040]   It's available in English for the US and Japanese,
[01:45:11.040 --> 01:45:12.040]   for Japan.
[01:45:12.040 --> 01:45:15.080]   More languages and countries are coming.
[01:45:15.080 --> 01:45:15.600]   So--
[01:45:15.600 --> 01:45:16.520]   Good work, good work.
[01:45:16.520 --> 01:45:20.160]   Yeah, we had a group of people in here.
[01:45:20.160 --> 01:45:23.880]   I think it was Sunday for Twit, one of whom was blind.
[01:45:23.880 --> 01:45:27.960]   But all three worked for an NGO in the UK
[01:45:27.960 --> 01:45:29.800]   to promote accessibility.
[01:45:29.800 --> 01:45:31.120]   They were really happy about this.
[01:45:31.120 --> 01:45:33.320]   They were actually about to go to Google and then Microsoft
[01:45:33.320 --> 01:45:35.640]   and Apple and talk about accessibility.
[01:45:35.640 --> 01:45:38.760]   And I asked them, I said, do you think Google and Apple
[01:45:38.760 --> 01:45:41.200]   and Microsoft are doing a good job making their products
[01:45:41.200 --> 01:45:42.040]   accessible?
[01:45:42.040 --> 01:45:44.800]   And they said, yes, absolutely.
[01:45:44.800 --> 01:45:48.360]   There's things that could be approved, but--
[01:45:48.360 --> 01:45:50.560]   Just a little guy, I says, not doing so well.
[01:45:50.560 --> 01:45:51.200]   Yeah.
[01:45:51.200 --> 01:45:52.400]   I mean, these guys are big enough.
[01:45:52.400 --> 01:45:54.920]   And I think they're committed enough.
[01:45:54.920 --> 01:45:58.440]   Google calls its security key the Titan.
[01:45:58.440 --> 01:46:02.000]   They are now making-- this is kind of like a Yubiki.
[01:46:02.000 --> 01:46:04.160]   And in fact, Yubiki's making this one.
[01:46:04.160 --> 01:46:05.000]   They're working with them.
[01:46:05.000 --> 01:46:06.240]   Yeah, they're making this one.
[01:46:06.240 --> 01:46:08.560]   In fact, I have this Yubiki.
[01:46:08.560 --> 01:46:12.360]   Google's going to brand it their USBC Titan security key.
[01:46:12.360 --> 01:46:13.160]   But that's exactly--
[01:46:13.160 --> 01:46:15.120]   I'm so glad they're making it with Yubiki,
[01:46:15.120 --> 01:46:16.960]   because they--
[01:46:16.960 --> 01:46:20.040]   They had problems with security on their last one.
[01:46:20.040 --> 01:46:22.000]   They were on the verge of completely
[01:46:22.000 --> 01:46:24.400]   Sherlocking Yubiki with their problems.
[01:46:24.400 --> 01:46:25.680]   Yeah, I agree.
[01:46:25.680 --> 01:46:27.320]   Although there are a number of companies--
[01:46:27.320 --> 01:46:30.320]   I just bought, in effect, I'll do a review of an open source
[01:46:30.320 --> 01:46:33.120]   key company out of Germany that make open source keys.
[01:46:33.120 --> 01:46:34.760]   But this is the Yubiki version.
[01:46:34.760 --> 01:46:37.680]   And I think you can tell it's exactly the same
[01:46:37.680 --> 01:46:39.520]   with the buttons on the side.
[01:46:39.520 --> 01:46:41.160]   And all I do is-- I love this.
[01:46:41.160 --> 01:46:41.680]   I love it.
[01:46:41.680 --> 01:46:42.760]   I have a dongle, right?
[01:46:42.760 --> 01:46:44.720]   A dongle to my dongle.
[01:46:44.720 --> 01:46:46.680]   This is on a chain, so I don't lose it.
[01:46:46.680 --> 01:46:50.320]   It's a USB-C to USB-A adapter, so that makes it work.
[01:46:50.320 --> 01:46:53.920]   The only thing I need is USB-C to lightning,
[01:46:53.920 --> 01:46:55.360]   because I can't use this even the iPhone.
[01:46:55.360 --> 01:46:56.840]   Oh, it's a iPhone.
[01:46:56.840 --> 01:46:58.880]   And by the way, I know that's my barcode.
[01:46:58.880 --> 01:47:01.120]   And if anybody wants to go to the gym on my behalf,
[01:47:01.120 --> 01:47:03.080]   please feel free.
[01:47:03.080 --> 01:47:05.920]   I have the original Titan security
[01:47:05.920 --> 01:47:09.320]   key, which I locked down my Chromebook and my online accounts.
[01:47:09.320 --> 01:47:12.880]   It frustrated the crap out of me that it was USB-A when I
[01:47:12.880 --> 01:47:14.320]   have all USB-C devices.
[01:47:14.320 --> 01:47:14.800]   Yeah, crazy.
[01:47:14.800 --> 01:47:16.160]   They needed to make this.
[01:47:16.160 --> 01:47:16.680]   Good one.
[01:47:16.680 --> 01:47:19.040]   Because they're all in on USB-C with their phones
[01:47:19.040 --> 01:47:21.400]   and with their Chromebooks.
[01:47:21.400 --> 01:47:24.040]   The last holdout is Apple.
[01:47:24.040 --> 01:47:25.440]   Everything else works with this.
[01:47:25.440 --> 01:47:26.160]   It's Apple.
[01:47:26.160 --> 01:47:27.880]   But actually, the iPad even works with it.
[01:47:27.880 --> 01:47:30.960]   It's just the iPhone that does work with it.
[01:47:30.960 --> 01:47:33.360]   But this is a great way to go for two-factor.
[01:47:33.360 --> 01:47:37.200]   It's a hardware dongle, better than SMS.
[01:47:37.200 --> 01:47:40.120]   I don't know if it's better than an authenticator.
[01:47:40.120 --> 01:47:43.040]   I think it is.
[01:47:43.040 --> 01:47:44.480]   And I actually should have brought this up
[01:47:44.480 --> 01:47:45.400]   at our last passive.
[01:47:45.400 --> 01:47:47.680]   And I'll ask Steve Gibson about this.
[01:47:47.680 --> 01:47:49.720]   But understand how an authenticator works.
[01:47:49.720 --> 01:47:53.000]   There's a secret code that's yours and yours alone.
[01:47:53.000 --> 01:47:55.080]   And then it mashes that up with the current time of day
[01:47:55.080 --> 01:47:57.760]   to give you a six-digit code that changes every 30 seconds.
[01:47:57.760 --> 01:47:58.240]   Every 30 seconds.
[01:47:58.240 --> 01:48:02.840]   But that secret code is just really another password.
[01:48:02.840 --> 01:48:04.480]   It's just another password.
[01:48:04.480 --> 01:48:05.480]   Not only that.
[01:48:05.480 --> 01:48:09.080]   If you have a secret code, you can make the authenticator work.
[01:48:09.080 --> 01:48:09.800]   Yeah.
[01:48:09.800 --> 01:48:13.200]   And if the authenticator apps that are on your phone,
[01:48:13.200 --> 01:48:15.960]   your phone runs out of battery, well, it's kind of useless.
[01:48:15.960 --> 01:48:17.200]   So I'd rather have the key.
[01:48:17.200 --> 01:48:19.040]   I think the key is good now, though.
[01:48:19.040 --> 01:48:21.960]   If you get jacked, then the guy's
[01:48:21.960 --> 01:48:23.320]   going to grab your keys.
[01:48:23.320 --> 01:48:25.320]   You could chop your hands off anyway, so it doesn't really matter.
[01:48:25.320 --> 01:48:26.680]   But your keys and your phone.
[01:48:26.680 --> 01:48:27.880]   And then you pass it.
[01:48:27.880 --> 01:48:30.600]   It's a little harder to get my keys than it is to get my phone.
[01:48:30.600 --> 01:48:32.400]   But strong piece of advice.
[01:48:32.400 --> 01:48:33.520]   I know you did this, Kevin.
[01:48:33.520 --> 01:48:35.400]   In fact, Google does it automatically
[01:48:35.400 --> 01:48:37.240]   with their security system.
[01:48:37.240 --> 01:48:38.640]   Get two.
[01:48:38.640 --> 01:48:41.440]   Because what you don't want to lose this.
[01:48:41.440 --> 01:48:42.400]   Oh, yeah.
[01:48:42.400 --> 01:48:45.600]   If you get two, Google, Twitter, Facebook, everywhere
[01:48:45.600 --> 01:48:48.800]   you use two factor, we'll let you register more than one device.
[01:48:48.800 --> 01:48:50.200]   You want to register at least two.
[01:48:50.200 --> 01:48:51.920]   I actually have three registered.
[01:48:51.920 --> 01:48:54.120]   So if you lose it, you're not at all.
[01:48:54.120 --> 01:48:54.720]   Oh, look.
[01:48:54.720 --> 01:48:56.160]   Yeah, that might be a problem.
[01:48:56.160 --> 01:48:57.800]   But you don't keep those on your key chain.
[01:48:57.800 --> 01:49:00.120]   You keep those somewhere safe, a safe deposit box
[01:49:00.120 --> 01:49:02.680]   and a secret compartment underneath your desk.
[01:49:02.680 --> 01:49:05.720]   Oh, no, forget I ever said that.
[01:49:05.720 --> 01:49:06.160]   Google--
[01:49:06.160 --> 01:49:06.720]   At your gym.
[01:49:06.720 --> 01:49:07.640]   At your gym.
[01:49:07.640 --> 01:49:08.520]   Bill Gates Space.
[01:49:08.520 --> 01:49:11.520]   I'm praying somebody goes to work out for me.
[01:49:11.520 --> 01:49:13.880]   I am a Leola Porte.
[01:49:13.880 --> 01:49:16.640]   I'm going into work out, yeah.
[01:49:16.640 --> 01:49:20.360]   Google shares downtown West Master Plan for mixed use San Jose
[01:49:20.360 --> 01:49:22.680]   campus.
[01:49:22.680 --> 01:49:25.480]   For the last several years, they've been planning a campus,
[01:49:25.480 --> 01:49:31.000]   but they hadn't really given San Jose a master plan.
[01:49:31.000 --> 01:49:33.240]   This is it.
[01:49:33.240 --> 01:49:35.560]   Like their Mountain View campus, this is not the Mountain View
[01:49:35.560 --> 01:49:35.920]   campus.
[01:49:35.920 --> 01:49:38.240]   This is another Google campus.
[01:49:38.240 --> 01:49:41.040]   3,000 to 5,000 residential units.
[01:49:41.040 --> 01:49:41.680]   That's interesting.
[01:49:41.680 --> 01:49:44.080]   You want to live in Google?
[01:49:44.080 --> 01:49:47.000]   The building will accommodate 15 to 20,000 Googlers.
[01:49:47.000 --> 01:49:49.320]   There'll be an event space for the company.
[01:49:49.320 --> 01:49:50.240]   That's actually good.
[01:49:50.240 --> 01:49:51.400]   That's what Apple's done that way.
[01:49:51.400 --> 01:49:52.440]   They don't have to rent space.
[01:49:52.440 --> 01:49:53.840]   Right.
[01:49:53.840 --> 01:49:59.000]   Google said it's a 50/50 of site area of office to other uses.
[01:49:59.000 --> 01:50:03.040]   So half of it is something that the city of San Jose can use.
[01:50:03.040 --> 01:50:03.880]   That's a good idea.
[01:50:03.880 --> 01:50:04.320]   Nice.
[01:50:04.320 --> 01:50:07.160]   Is it really right next to where the sharks play
[01:50:07.160 --> 01:50:08.320]   based on that top map?
[01:50:08.320 --> 01:50:09.320]   Yeah.
[01:50:09.320 --> 01:50:09.820]   Yeah.
[01:50:09.820 --> 01:50:11.680]   Goodness is traffic.
[01:50:11.680 --> 01:50:13.840]   Well, see this Caltrain?
[01:50:13.840 --> 01:50:14.480]   Yeah.
[01:50:14.480 --> 01:50:16.120]   Train goes right there.
[01:50:16.120 --> 01:50:17.360]   OK.
[01:50:17.360 --> 01:50:18.920]   OK.
[01:50:18.920 --> 01:50:21.600]   I think part is going to go right about there too.
[01:50:21.600 --> 01:50:21.600]   Nice.
[01:50:21.600 --> 01:50:22.600]   Bar would be nice too.
[01:50:22.600 --> 01:50:23.120]   OK.
[01:50:23.120 --> 01:50:24.120]   It sounds like a good plan.
[01:50:24.120 --> 01:50:25.120]   Caltrain's great.
[01:50:25.120 --> 01:50:27.400]   I used to take Caltrain every day to work,
[01:50:27.400 --> 01:50:28.320]   and it was wonderful.
[01:50:28.320 --> 01:50:30.360]   I really enjoyed taking the train.
[01:50:30.360 --> 01:50:31.120]   I like Caltrain.
[01:50:31.120 --> 01:50:31.480]   Yeah.
[01:50:31.480 --> 01:50:32.320]   It's a train system.
[01:50:32.320 --> 01:50:33.480]   Yeah.
[01:50:33.480 --> 01:50:35.760]   Hardly anybody jumps in front of it anymore.
[01:50:35.760 --> 01:50:38.120]   So it pretty much is reliable.
[01:50:38.120 --> 01:50:39.160]   Thank goodness.
[01:50:39.160 --> 01:50:41.680]   That's actually-- I'm sure it's true in the subway.
[01:50:41.680 --> 01:50:43.520]   It's true of our smart system.
[01:50:43.520 --> 01:50:46.200]   It works flawlessly until somebody jumps in front of it.
[01:50:46.200 --> 01:50:47.360]   Please don't do that.
[01:50:47.360 --> 01:50:48.360]   Yeah.
[01:50:48.360 --> 01:50:49.360]   Please.
[01:50:49.360 --> 01:50:50.360]   I beg of you.
[01:50:50.360 --> 01:50:51.360]   You're ruining my day.
[01:50:51.360 --> 01:50:52.360]   You're ruining my day.
[01:50:52.360 --> 01:50:53.360]   You're ruining my day.
[01:50:53.360 --> 01:50:54.360]   Yeah.
[01:50:54.360 --> 01:50:56.760]   I'm going to be late for work because of you.
[01:50:56.760 --> 01:51:01.880]   YouTube gets alleged copyright troll to agree to stop trolling YouTubers.
[01:51:01.880 --> 01:51:04.120]   This is victory.
[01:51:04.120 --> 01:51:06.680]   This was a lawsuit YouTube filed last August.
[01:51:06.680 --> 01:51:14.880]   Christopher Brady was issuing false DMC takedowns to other YouTubers under the agreement
[01:51:14.880 --> 01:51:18.320]   he's banned from submitting any notices of alleged copyright infringement.
[01:51:18.320 --> 01:51:22.440]   That misrepresent the material hosted on YouTube.
[01:51:22.440 --> 01:51:29.040]   This is a real problem with the automated takedown process is it's easy to cause havoc.
[01:51:29.040 --> 01:51:30.440]   Well, wait.
[01:51:30.440 --> 01:51:33.440]   So basically he just has to use the system as intended.
[01:51:33.440 --> 01:51:34.440]   That's the victory.
[01:51:34.440 --> 01:51:35.440]   Yes.
[01:51:35.440 --> 01:51:36.440]   But he didn't--
[01:51:36.440 --> 01:51:37.440]   Pretty much.
[01:51:37.440 --> 01:51:41.800]   So he targeted a couple of Minecraft and gaming creators using false copyright claim
[01:51:41.800 --> 01:51:42.800]   takedowns.
[01:51:42.800 --> 01:51:47.720]   The company removed the videos as YouTube is required to do when a claim is submitted.
[01:51:47.720 --> 01:51:52.120]   It's happened to us many times.
[01:51:52.120 --> 01:51:57.720]   But what Brady was doing was using copyright strikes as a way to pressure creators into
[01:51:57.720 --> 01:51:59.120]   paying him money.
[01:51:59.120 --> 01:52:01.400]   It's really was more of a blackmail scheme.
[01:52:01.400 --> 01:52:02.400]   So extortion.
[01:52:02.400 --> 01:52:03.400]   Extortion.
[01:52:03.400 --> 01:52:04.400]   Yes, right.
[01:52:04.400 --> 01:52:05.400]   Yes, shame if anything.
[01:52:05.400 --> 01:52:06.400]   So did they get him under Rico?
[01:52:06.400 --> 01:52:07.400]   Oh, yes.
[01:52:07.400 --> 01:52:08.400]   Oh, that'd be great.
[01:52:08.400 --> 01:52:10.360]   That means they could take everything, right?
[01:52:10.360 --> 01:52:13.560]   So, but this was a settlement with Google, not anything else.
[01:52:13.560 --> 01:52:17.680]   He said, well, Google's coming to court, but I gather this was an out of court settlement.
[01:52:17.680 --> 01:52:23.880]   I, Christopher L. Brady, admit that I sent dozens of notice to YouTube falsely claiming
[01:52:23.880 --> 01:52:27.400]   that material uploaded by YouTube users infringed my copyrights.
[01:52:27.400 --> 01:52:32.680]   I apologize to the YouTube users that I directly impacted by my actions to the YouTube community
[01:52:32.680 --> 01:52:34.440]   and to YouTube itself.
[01:52:34.440 --> 01:52:38.080]   OK, that's not very effective, but OK, whatever.
[01:52:38.080 --> 01:52:40.280]   $25,000 in damages, too.
[01:52:40.280 --> 01:52:43.080]   And he can't do it ever again.
[01:52:43.080 --> 01:52:44.480]   He can't do it ever again.
[01:52:44.480 --> 01:52:46.960]   It's actually a big problem on that platform.
[01:52:46.960 --> 01:52:52.640]   We get takedowns all the time for all sorts of nutty reasons, not for extortion.
[01:52:52.640 --> 01:52:58.520]   Most often, I think it's just flawed content ID that it thinks it heard something.
[01:52:58.520 --> 01:53:01.080]   Today, this show almost certainly get taken down.
[01:53:01.080 --> 01:53:02.080]   Right.
[01:53:02.080 --> 01:53:03.080]   Because it's a music.
[01:53:03.080 --> 01:53:04.080]   But that's the thing.
[01:53:04.080 --> 01:53:06.600]   And it's a ray ain't happy either.
[01:53:06.600 --> 01:53:08.360]   I thought it was all automated.
[01:53:08.360 --> 01:53:09.360]   It is.
[01:53:09.360 --> 01:53:11.160]   So, well, it isn't automated.
[01:53:11.160 --> 01:53:12.400]   It's content ID.
[01:53:12.400 --> 01:53:16.800]   But well, for instance, when we streamed the Apple event on YouTube, Apple has a lawyer
[01:53:16.800 --> 01:53:22.760]   found us connected with YouTube, took our live stream down for how long was it?
[01:53:22.760 --> 01:53:23.760]   Carson, weeks.
[01:53:23.760 --> 01:53:24.760]   It was a couple of weeks.
[01:53:24.760 --> 01:53:25.760]   I remember that.
[01:53:25.760 --> 01:53:27.760]   Just over 45 days.
[01:53:27.760 --> 01:53:29.800]   45 days.
[01:53:29.800 --> 01:53:33.200]   So we stopped streaming Apple content on our YouTube stream.
[01:53:33.200 --> 01:53:35.560]   When Apple does an event, we don't put it on YouTube anymore.
[01:53:35.560 --> 01:53:36.560]   All right.
[01:53:36.560 --> 01:53:37.560]   That's nice.
[01:53:37.560 --> 01:53:38.560]   It's not legal.
[01:53:38.560 --> 01:53:39.560]   It's fair use.
[01:53:39.560 --> 01:53:40.560]   It's commentary.
[01:53:40.560 --> 01:53:41.560]   It's not.
[01:53:41.560 --> 01:53:43.600]   But it was a more broken system.
[01:53:43.600 --> 01:53:46.160]   It's just a broken system.
[01:53:46.160 --> 01:53:47.160]   A couple of quickies.
[01:53:47.160 --> 01:53:51.440]   Oh, that's the Google change log.
[01:53:51.440 --> 01:53:59.720]   UK has dropped its porn block.
[01:53:59.720 --> 01:54:01.040]   This was such a bad idea.
[01:54:01.040 --> 01:54:02.240]   They were going to get you.
[01:54:02.240 --> 01:54:07.320]   If you wanted to watch porn in the UK, you had to register and prove that you were over
[01:54:07.320 --> 01:54:08.320]   18.
[01:54:08.320 --> 01:54:14.880]   Among all the registrars, one of them was the largest porn distributor in the world.
[01:54:14.880 --> 01:54:18.320]   So you go to the porn distributor, prove you're over 18.
[01:54:18.320 --> 01:54:21.480]   They now have everything, including your driver's license.
[01:54:21.480 --> 01:54:24.120]   Then the other place you could go was a pub.
[01:54:24.120 --> 01:54:29.560]   You go to a pub, provide ID, and the pub would give you a waiver.
[01:54:29.560 --> 01:54:34.680]   This was such a terrible idea that finally the UK just said, "I'll forget it."
[01:54:34.680 --> 01:54:35.680]   Oh, my goodness.
[01:54:35.680 --> 01:54:38.040]   It's got bigger problems.
[01:54:38.040 --> 01:54:39.040]   Yeah.
[01:54:39.040 --> 01:54:40.040]   Yeah.
[01:54:40.040 --> 01:54:41.840]   They delayed it.
[01:54:41.840 --> 01:54:42.840]   They deferred it.
[01:54:42.840 --> 01:54:43.840]   They said, "No, no, we're going to do it."
[01:54:43.840 --> 01:54:44.840]   Finally, they have just...
[01:54:44.840 --> 01:54:48.200]   So someone walked into the bar and asked Sam for a waiver.
[01:54:48.200 --> 01:54:49.200]   Yeah.
[01:54:49.200 --> 01:54:50.200]   Yeah.
[01:54:50.200 --> 01:54:53.560]   Ask Woody because Woody'll give you the waiver.
[01:54:53.560 --> 01:54:55.920]   And he'll sell you an ounce if you ask.
[01:54:55.920 --> 01:54:58.240]   Huawei reports stronger sales growth.
[01:54:58.240 --> 01:55:01.760]   How about this?
[01:55:01.760 --> 01:55:07.040]   The Trump administration's blocking of Huawei gear in the United States has really hurt
[01:55:07.040 --> 01:55:14.160]   Huawei to the tune of a 25% increase in sales.
[01:55:14.160 --> 01:55:15.680]   Most of that, obviously not in the US.
[01:55:15.680 --> 01:55:18.400]   All of that in China, I would guess.
[01:55:18.400 --> 01:55:19.400]   Right.
[01:55:19.400 --> 01:55:24.400]   But what happens is, of course, Chinese people, patriotically, said, "Well, the hell with
[01:55:24.400 --> 01:55:27.720]   that, we're buying Huawei."
[01:55:27.720 --> 01:55:31.680]   So to kind of backfire it a little bit, if that's what they were trying to do, it was
[01:55:31.680 --> 01:55:32.680]   punished for that.
[01:55:32.680 --> 01:55:35.680]   They were last week when I said the Chinese seem to be very patriotic.
[01:55:35.680 --> 01:55:36.680]   They are very...
[01:55:36.680 --> 01:55:37.680]   Yeah.
[01:55:37.680 --> 01:55:38.680]   Yep.
[01:55:38.680 --> 01:55:39.680]   Yup.
[01:55:39.680 --> 01:55:43.680]   Sales from January to September, $86 billion.
[01:55:43.680 --> 01:55:45.180]   Man.
[01:55:45.180 --> 01:55:50.080]   And they sold like 110 million handsets, which is a good number.
[01:55:50.080 --> 01:55:52.040]   That's a decent number.
[01:55:52.040 --> 01:55:56.280]   Huawei's laughing to the bank.
[01:55:56.280 --> 01:55:57.280]   Did you...
[01:55:57.280 --> 01:55:58.280]   Do you...
[01:55:58.280 --> 01:55:59.280]   Anybody play Fortnite?
[01:55:59.280 --> 01:56:00.280]   They will be no sir.
[01:56:00.280 --> 01:56:01.280]   Do your kids play Fortnite?
[01:56:01.280 --> 01:56:02.280]   They don't play it anymore.
[01:56:02.280 --> 01:56:03.280]   Did you stop?
[01:56:03.280 --> 01:56:05.040]   My son does.
[01:56:05.040 --> 01:56:11.560]   So I wish I'd seen this, but apparently they have seasons.
[01:56:11.560 --> 01:56:12.560]   Fortnite has seasons.
[01:56:12.560 --> 01:56:13.560]   Right.
[01:56:13.560 --> 01:56:16.600]   And was it season 10 at the close of it?
[01:56:16.600 --> 01:56:19.440]   A black hole devoured the world, and that was it.
[01:56:19.440 --> 01:56:20.680]   Screen went dark, and that was it.
[01:56:20.680 --> 01:56:21.680]   It's over.
[01:56:21.680 --> 01:56:22.680]   No more Fortnite.
[01:56:22.680 --> 01:56:23.680]   Seriously.
[01:56:23.680 --> 01:56:24.680]   No more Fortnite for a little while.
[01:56:24.680 --> 01:56:25.680]   Oh, shoot.
[01:56:25.680 --> 01:56:27.320]   Fortnite was down for like two days.
[01:56:27.320 --> 01:56:28.720]   This is marketing genius.
[01:56:28.720 --> 01:56:29.720]   It's brilliant.
[01:56:29.720 --> 01:56:30.720]   It really was.
[01:56:30.720 --> 01:56:32.480]   Oh, Zach plays, right?
[01:56:32.480 --> 01:56:34.440]   Zach plays a little.
[01:56:34.440 --> 01:56:38.160]   No, he mostly plays Nintendo stuff.
[01:56:38.160 --> 01:56:39.520]   It is brilliant marketing.
[01:56:39.520 --> 01:56:41.320]   So, you know, there was an island.
[01:56:41.320 --> 01:56:42.960]   It was a battle royale game.
[01:56:42.960 --> 01:56:44.760]   The bus would drop you over the island.
[01:56:44.760 --> 01:56:45.760]   The bus is gone.
[01:56:45.760 --> 01:56:46.760]   The island is gone.
[01:56:46.760 --> 01:56:47.760]   The map is gone.
[01:56:47.760 --> 01:56:49.200]   There's just darkness.
[01:56:49.200 --> 01:56:53.320]   A black hole consumed all of Fortnite world.
[01:56:53.320 --> 01:56:56.200]   Now they've relaunched a brand new location.
[01:56:56.200 --> 01:56:59.720]   The new island, according to the Verge, looks wilder and more untamed.
[01:56:59.720 --> 01:57:02.480]   Plenty of forests, mountains and lakes to explore.
[01:57:02.480 --> 01:57:04.400]   Fewer city and urban locales.
[01:57:04.400 --> 01:57:07.440]   You just need a couple days off of rest is what it sounds like.
[01:57:07.440 --> 01:57:08.720]   The battle bus is back though.
[01:57:08.720 --> 01:57:11.400]   This is chapter two.
[01:57:11.400 --> 01:57:20.320]   And there's new gameplay features including fishing, swimming, boats and pogo sticks.
[01:57:20.320 --> 01:57:23.680]   I thought the idea was like destroy everybody.
[01:57:23.680 --> 01:57:24.680]   So you're going to take time off.
[01:57:24.680 --> 01:57:28.560]   If you can do it with a pogo stick, more power to you.
[01:57:28.560 --> 01:57:29.560]   Alrighty.
[01:57:29.560 --> 01:57:33.720]   Yeah, I guess, you know, if there's fish in hooks hurt though, if 100 go in, only one
[01:57:33.720 --> 01:57:34.720]   comes out.
[01:57:34.720 --> 01:57:37.200]   I'm thinking the one is not going to be fishing.
[01:57:37.200 --> 01:57:41.000]   But you know, maybe you stay there, you fish a little bit, let them all kill each other
[01:57:41.000 --> 01:57:42.000]   and you win.
[01:57:42.000 --> 01:57:43.000]   I don't know.
[01:57:43.000 --> 01:57:45.560]   It's a better strategy than the one.
[01:57:45.560 --> 01:57:46.560]   Well, everyone else.
[01:57:46.560 --> 01:57:47.560]   Yeah, I don't know.
[01:57:47.560 --> 01:57:48.560]   That is strategy.
[01:57:48.560 --> 01:57:53.160]   Yeah, isn't that you got to give epic some credit?
[01:57:53.160 --> 01:57:56.200]   Really really smart stuff.
[01:57:56.200 --> 01:58:02.280]   And I'm thinking Father Robert might have had something to do with this.
[01:58:02.280 --> 01:58:08.800]   The Vatican has launched a click to pray wearable rosary.
[01:58:08.800 --> 01:58:14.360]   It has an app capitalized, maybe it's a hundred ten bucks.
[01:58:14.360 --> 01:58:15.600]   It's intended for it.
[01:58:15.600 --> 01:58:18.480]   I got to think Father Roberts involved here.
[01:58:18.480 --> 01:58:22.280]   Tech savvy youngsters to attract them to the church.
[01:58:22.280 --> 01:58:23.800]   They click to pray.
[01:58:23.800 --> 01:58:24.800]   E rosary.
[01:58:24.800 --> 01:58:28.200]   It's a wearable device connected to a mobile app that's activated by making the sign of
[01:58:28.200 --> 01:58:30.080]   the cross.
[01:58:30.080 --> 01:58:31.760]   The device can be worn as a bracelet.
[01:58:31.760 --> 01:58:38.560]   It's got ten consecutive black agate and hematite rosary beads plus a data storing smart cross.
[01:58:38.560 --> 01:58:39.560]   There it is.
[01:58:39.560 --> 01:58:41.520]   That's the smart cross.
[01:58:41.520 --> 01:58:45.360]   Once activated, the wearer could choose to pray the standard rosary, a contemplative rosary
[01:58:45.360 --> 01:58:50.240]   or a thematic rosary, which will be updated throughout the year.
[01:58:50.240 --> 01:58:55.080]   The Vatican says the device part of the Pope's worldwide prayer network is designed as a
[01:58:55.080 --> 01:59:01.360]   tech-based teaching tool for learning how to pray the rosary for peace in the world.
[01:59:01.360 --> 01:59:06.520]   The app features personalized religious content health tracking.
[01:59:06.520 --> 01:59:08.480]   It's on sale now for 99 Euro.
[01:59:08.480 --> 01:59:13.760]   Talk about ambient prayer.
[01:59:13.760 --> 01:59:14.760]   Ambient prayer.
[01:59:14.760 --> 01:59:16.560]   All right, let's take...
[01:59:16.560 --> 01:59:17.560]   Health tracking.
[01:59:17.560 --> 01:59:18.560]   Health tracking.
[01:59:18.560 --> 01:59:19.760]   Can't get the app and...
[01:59:19.760 --> 01:59:22.160]   Oh, so-and-so needs last rights.
[01:59:22.160 --> 01:59:23.160]   Yeah.
[01:59:23.160 --> 01:59:24.160]   Got to run.
[01:59:24.160 --> 01:59:25.160]   Got to run.
[01:59:25.160 --> 01:59:27.040]   I think Father Roberts thought this went up.
[01:59:27.040 --> 01:59:28.880]   I just feels that way to me.
[01:59:28.880 --> 01:59:31.240]   The chat room clearly feels that way right now.
[01:59:31.240 --> 01:59:34.480]   It's got LEDs that we know it was Padre S.J.
[01:59:34.480 --> 01:59:35.960]   Unbelievable.
[01:59:35.960 --> 01:59:40.320]   Our show today, we're going to get our picks of the week standby.
[01:59:40.320 --> 01:59:47.640]   Our show today brought to you by worldwide technology, WWT and their ATC, their Advanced
[01:59:47.640 --> 01:59:48.640]   Technology Center.
[01:59:48.640 --> 01:59:49.640]   They built...
[01:59:49.640 --> 01:59:50.640]   They started building this 10 years ago.
[01:59:50.640 --> 01:59:58.360]   Now it has more than half a billion dollars, half a billion dollars in equipment from all
[01:59:58.360 --> 02:00:00.680]   the big enterprise OEMs.
[02:00:00.680 --> 02:00:06.640]   Keep partners ranging from heavyweights like NetApp and Cisco and VMware to the little
[02:00:06.640 --> 02:00:12.760]   guys emerging disruptors that you need to know about like Tanium and Equinix and Expanse.
[02:00:12.760 --> 02:00:14.720]   You know WWT, I'm sure.
[02:00:14.720 --> 02:00:20.000]   Customers who have been with WWT often have been there for a decade or more.
[02:00:20.000 --> 02:00:24.280]   They are a trusted partner for enterprise technology.
[02:00:24.280 --> 02:00:28.280]   And this ATC originally built for WWT's engineers.
[02:00:28.280 --> 02:00:33.080]   They would use these environments to spin up proofs of concept and pilots that use the
[02:00:33.080 --> 02:00:37.680]   sandbox to experiment with different interactions and technologies.
[02:00:37.680 --> 02:00:40.960]   That way they could recommend the right solutions to customers.
[02:00:40.960 --> 02:00:45.160]   It also means that they could go from concept to delivery in much less time.
[02:00:45.160 --> 02:00:47.640]   I mean it's a huge boon.
[02:00:47.640 --> 02:00:51.400]   But now ATC is making this available to you.
[02:00:51.400 --> 02:00:53.120]   And that is pretty amazing.
[02:00:53.120 --> 02:01:00.080]   On demand and schedulable labs, things like NetApp's cloud volumes on tap, on tap on flash,
[02:01:00.080 --> 02:01:05.640]   NetApp disaster recovery as a service, plus hundreds of other labs representing all the
[02:01:05.640 --> 02:01:11.760]   newest advances in things like flash storage, multi-home cloud, hyper converged infrastructure,
[02:01:11.760 --> 02:01:14.280]   cloud data management.
[02:01:14.280 --> 02:01:16.080]   This is lab as a service.
[02:01:16.080 --> 02:01:19.080]   I'm going to coin that last lab as a service.
[02:01:19.080 --> 02:01:25.360]   It's a dedicated lab space within the Advanced Technology Center where you as a WWT customer
[02:01:25.360 --> 02:01:30.120]   can perform programmatic testing of your own using this incredible half billion dollar
[02:01:30.120 --> 02:01:32.000]   infrastructure.
[02:01:32.000 --> 02:01:34.360]   And because it's virtual, you don't have to go to St. Louis to do it.
[02:01:34.360 --> 02:01:38.120]   You can do it anywhere in the world and you can do it 24/7.
[02:01:38.120 --> 02:01:39.560]   This is such a great idea.
[02:01:39.560 --> 02:01:41.400]   We've been talking about it all summer.
[02:01:41.400 --> 02:01:42.880]   It's finally here.
[02:01:42.880 --> 02:01:48.040]   They have opened their digital platform encompassing the ATC ecosystem.
[02:01:48.040 --> 02:01:53.480]   This lab as a service creates a multiplier effect of knowledge, speed, agility, anytime
[02:01:53.480 --> 02:01:56.880]   anywhere around the world for WWT customers.
[02:01:56.880 --> 02:01:58.120]   You get access to articles.
[02:01:58.120 --> 02:01:59.720]   You get case studies.
[02:01:59.720 --> 02:02:02.880]   You get hands on with these new technologies.
[02:02:02.880 --> 02:02:06.400]   All sorts of tools that make a difference in today's fast moving enterprise technology
[02:02:06.400 --> 02:02:07.400]   world.
[02:02:07.400 --> 02:02:09.400]   You need WWT.
[02:02:09.400 --> 02:02:11.960]   Don't do it on your own.
[02:02:11.960 --> 02:02:14.440]   Do it with WWT, a trusted partner.
[02:02:14.440 --> 02:02:19.680]   Learn more about WWT, the ATC to sign up for access to this new on-demand lab platform.
[02:02:19.680 --> 02:02:20.680]   It's simple.
[02:02:20.680 --> 02:02:24.040]   Just go to www.wt.com/twit.
[02:02:24.040 --> 02:02:27.640]   World Wide Technology simplifies the complex.
[02:02:27.640 --> 02:02:32.960]   www.wt.com/twit.
[02:02:32.960 --> 02:02:34.760]   Really a great idea.
[02:02:34.760 --> 02:02:39.520]   We're really proud to be partnered with WWT, delivering business and technology outcomes
[02:02:39.520 --> 02:02:43.680]   around the world.
[02:02:43.680 --> 02:02:45.280]   I don't think you hate America.
[02:02:45.280 --> 02:02:47.280]   I think you hate the Beatles.
[02:02:47.280 --> 02:02:49.280]   No, you think both.
[02:02:49.280 --> 02:02:54.440]   I was about to say, I think now people are going to start finding me and trying to hunt
[02:02:54.440 --> 02:02:57.120]   me down for hating both America and the Beatles.
[02:02:57.120 --> 02:03:00.200]   I'm pretty sure that's punishable by death.
[02:03:00.200 --> 02:03:02.960]   Kevin, how can we get her to love?
[02:03:02.960 --> 02:03:03.960]   How can we get her to love?
[02:03:03.960 --> 02:03:05.640]   We've got to get her to love.
[02:03:05.640 --> 02:03:08.960]   I'm going to put it on our calendar and we're just going to drag her there.
[02:03:08.960 --> 02:03:11.160]   I will find a mindlessly followed.
[02:03:11.160 --> 02:03:13.440]   All four of us will be going.
[02:03:13.440 --> 02:03:14.720]   You don't have to sit next to me.
[02:03:14.720 --> 02:03:16.800]   Stacey, you could sit next to Aunt.
[02:03:16.800 --> 02:03:17.800]   You could have anything.
[02:03:17.800 --> 02:03:20.520]   It could be an aunt and toful sandwich.
[02:03:20.520 --> 02:03:21.520]   We'll leave early together.
[02:03:21.520 --> 02:03:23.520]   I'll be over here with some chills.
[02:03:23.520 --> 02:03:28.800]   Stacey and I are actually staying at the Mirage, which is where the love show is.
[02:03:28.800 --> 02:03:29.800]   Oh, wow.
[02:03:29.800 --> 02:03:31.520]   Please, it's just downstairs.
[02:03:31.520 --> 02:03:32.520]   Wow.
[02:03:32.520 --> 02:03:33.520]   I know.
[02:03:33.520 --> 02:03:37.600]   It's not playing when I'm there normally.
[02:03:37.600 --> 02:03:39.680]   Otherwise, I totally would have gone.
[02:03:39.680 --> 02:03:41.960]   I've seen it twice now.
[02:03:41.960 --> 02:03:43.360]   And I want to see it three times.
[02:03:43.360 --> 02:03:45.720]   What's your favorite part, Kevin?
[02:03:45.720 --> 02:03:49.680]   Well, my favorite part is the part I haven't seen yet because they've read, done, and
[02:03:49.680 --> 02:03:51.680]   all my guitar gently weeps.
[02:03:51.680 --> 02:03:52.680]   Oh, stay here.
[02:03:52.680 --> 02:03:53.680]   Favorite song.
[02:03:53.680 --> 02:03:54.680]   Shut up.
[02:03:54.680 --> 02:03:56.640]   I'm serious though.
[02:03:56.640 --> 02:03:57.760]   They have.
[02:03:57.760 --> 02:04:01.560]   It was nice before, but now they've added a lot of technology to it.
[02:04:01.560 --> 02:04:02.560]   Trust me.
[02:04:02.560 --> 02:04:03.640]   Oh, it's high tech.
[02:04:03.640 --> 02:04:05.200]   You know what?
[02:04:05.200 --> 02:04:09.440]   I'm going to make a plea because I know that people watch this show.
[02:04:09.440 --> 02:04:13.920]   I remember we got an invitation to go backstage and see the stage and the technology.
[02:04:13.920 --> 02:04:14.920]   Huge amount.
[02:04:14.920 --> 02:04:17.120]   This is a custom built space just for love.
[02:04:17.120 --> 02:04:19.080]   And I remember they sent us an email.
[02:04:19.080 --> 02:04:24.560]   If you're watching, if you can get us backstage, Stacey won't be able to say no.
[02:04:24.560 --> 02:04:25.560]   That's true.
[02:04:25.560 --> 02:04:26.880]   There's IOT in there.
[02:04:26.880 --> 02:04:27.880]   I got to go.
[02:04:27.880 --> 02:04:28.880]   Oh, there's that.
[02:04:28.880 --> 02:04:31.520]   Oh, I did that with the car show.
[02:04:31.520 --> 02:04:36.320]   I actually tweeted something about car at CES and they're like, "Hey, come see the show
[02:04:36.320 --> 02:04:40.040]   tonight and then see the second show behind the stage and my wife and I went."
[02:04:40.040 --> 02:04:41.400]   And it was phenomenal.
[02:04:41.400 --> 02:04:47.240]   The amount of technology, timing, communications, it's amazing.
[02:04:47.240 --> 02:04:50.200]   I've seen every Cirque du Soleil show in Vegas, I think now.
[02:04:50.200 --> 02:04:53.080]   It's really, really wonderful.
[02:04:53.080 --> 02:04:58.120]   I love the resident shows at Vegas because they have custom built theaters.
[02:04:58.120 --> 02:04:59.880]   They can do such amazing things.
[02:04:59.880 --> 02:05:01.320]   It's so much fun.
[02:05:01.320 --> 02:05:02.320]   All right.
[02:05:02.320 --> 02:05:05.400]   Well, Stacey, you know, if you want to.
[02:05:05.400 --> 02:05:06.400]   You don't have to.
[02:05:06.400 --> 02:05:07.400]   Could we, though?
[02:05:07.400 --> 02:05:12.040]   I'm just thinking, I know you're going to be really busy, but maybe if Ant and I in our
[02:05:12.040 --> 02:05:16.360]   excellent adventure could meet up with you for an hour, you could show us five cool IOT
[02:05:16.360 --> 02:05:17.360]   things.
[02:05:17.360 --> 02:05:18.360]   That'll be really fun.
[02:05:18.360 --> 02:05:19.360]   Please and thank you.
[02:05:19.360 --> 02:05:20.360]   Would you do that?
[02:05:20.360 --> 02:05:23.720]   I'm kind of sure we can make that happen.
[02:05:23.720 --> 02:05:24.720]   Kevin will be with Kevin.
[02:05:24.720 --> 02:05:25.720]   You're there.
[02:05:25.720 --> 02:05:26.720]   Right?
[02:05:26.720 --> 02:05:27.720]   Both of you.
[02:05:27.720 --> 02:05:28.720]   Unless I'm at the Beatles show, yes.
[02:05:28.720 --> 02:05:29.720]   Yes, I will be there.
[02:05:29.720 --> 02:05:31.360]   Oh, my goodness.
[02:05:31.360 --> 02:05:33.760]   What is your pick of the week, Ms. Higginmont?
[02:05:33.760 --> 02:05:34.760]   Ms. Stacey?
[02:05:34.760 --> 02:05:36.840]   Let's see.
[02:05:36.840 --> 02:05:40.280]   I'm going to go with, I got a new device, but I'm going to show that to you next week because
[02:05:40.280 --> 02:05:41.920]   I haven't had a chance to play with it.
[02:05:41.920 --> 02:05:44.840]   So I'm going to give you an article from the New Yorker.
[02:05:44.840 --> 02:05:47.120]   Can a machine learn to write for the New Yorker?
[02:05:47.120 --> 02:05:48.120]   Oh, wow.
[02:05:48.120 --> 02:05:51.720]   Mostly because it's very well written.
[02:05:51.720 --> 02:05:56.120]   And at first I was like, oh, this guy is so hysterical.
[02:05:56.120 --> 02:05:58.600]   It's a humorous article.
[02:05:58.600 --> 02:06:02.280]   Well, it starts out humorous.
[02:06:02.280 --> 02:06:04.480]   But it's actually quite serious.
[02:06:04.480 --> 02:06:11.920]   And he talks to some very legit people like David Farrucci, who was the guy behind Watson.
[02:06:11.920 --> 02:06:12.920]   And Ilya...
[02:06:12.920 --> 02:06:17.320]   From the man from uncle?
[02:06:17.320 --> 02:06:20.160]   No, no, no.
[02:06:20.160 --> 02:06:21.920]   The OpenAI guy.
[02:06:21.920 --> 02:06:33.400]   What they did is they fed the New Yorker articles into the OpenAI GPT-2 database, which lets
[02:06:33.400 --> 02:06:35.840]   you, which writes on behalf of people.
[02:06:35.840 --> 02:06:38.960]   And so it learned how to write like the New Yorker.
[02:06:38.960 --> 02:06:40.920]   And it kind of freaked him out a lot.
[02:06:40.920 --> 02:06:45.000]   It was just a nice humanizing article for this sort of thing.
[02:06:45.000 --> 02:06:48.640]   And I think I learned something.
[02:06:48.640 --> 02:06:50.840]   You know, the Yorker does have kind of a distinct style.
[02:06:50.840 --> 02:06:56.000]   I guess it would be possible to absorb the style and...
[02:06:56.000 --> 02:06:58.040]   And you know, it did a good job.
[02:06:58.040 --> 02:06:59.360]   It really did.
[02:06:59.360 --> 02:07:02.560]   Oh, actually, it's really good.
[02:07:02.560 --> 02:07:07.280]   By that I mean, it seemed to want to distinguish my feelings from my thoughts, to put it another
[02:07:07.280 --> 02:07:08.280]   way.
[02:07:08.280 --> 02:07:12.120]   Smart composed seemed to want to know me.
[02:07:12.120 --> 02:07:14.760]   That was artificially generated.
[02:07:14.760 --> 02:07:15.760]   Yeah.
[02:07:15.760 --> 02:07:19.720]   And he threw a quote in there from Stephen Pinker and then he had like, "Fakes Stephen
[02:07:19.720 --> 02:07:20.720]   Pinker" in there.
[02:07:20.720 --> 02:07:22.200]   "Fakes Stephen Pinker."
[02:07:22.200 --> 02:07:23.200]   Yeah.
[02:07:23.200 --> 02:07:29.000]   So for all we know, "Fakes Stephen Pinker" wrote his last four books.
[02:07:29.000 --> 02:07:32.960]   The results of the first year of this work are promising, but the big issues are about
[02:07:32.960 --> 02:07:34.200]   to be addressed.
[02:07:34.200 --> 02:07:39.680]   I asked Amote if we should be worried about AI surpassing humans in an array of specialized
[02:07:39.680 --> 02:07:40.680]   fields.
[02:07:40.680 --> 02:07:44.680]   "No, I think we can understand it's not going to be a society where people are robots,"
[02:07:44.680 --> 02:07:45.680]   he said.
[02:07:45.680 --> 02:07:46.680]   "The safety of any..."
[02:07:46.680 --> 02:07:47.680]   This is the robot.
[02:07:47.680 --> 02:07:50.840]   This is why you can't trust them.
[02:07:50.840 --> 02:07:52.920]   He said he stopped writing...
[02:07:52.920 --> 02:07:58.680]   He started putting his notes in his prompts, but it started generating realistic quotes.
[02:07:58.680 --> 02:07:59.680]   And so he had to...
[02:07:59.680 --> 02:08:00.680]   It's confusing.
[02:08:00.680 --> 02:08:01.680]   He had to stop.
[02:08:01.680 --> 02:08:03.320]   Was that real or was it generating?
[02:08:03.320 --> 02:08:06.520]   He was forgetting like what was real or what was fake.
[02:08:06.520 --> 02:08:07.520]   Wow.
[02:08:07.520 --> 02:08:09.160]   This is a good article.
[02:08:09.160 --> 02:08:13.040]   And by the way, I am, you know, the New Yorker, which is a print magazine.
[02:08:13.040 --> 02:08:15.040]   This is nicely produced for the web.
[02:08:15.040 --> 02:08:17.720]   Oh, they have a really good web team.
[02:08:17.720 --> 02:08:23.400]   And I have always liked the New Yorker because they write about so many things that...
[02:08:23.400 --> 02:08:26.320]   Yeah, their tech coverage has gotten really good, I think.
[02:08:26.320 --> 02:08:27.320]   Yeah, but they...
[02:08:27.320 --> 02:08:32.480]   I mean, like the art, when they write about an artist or even a dance show, they always
[02:08:32.480 --> 02:08:39.600]   have links to more content, basically, that helps make the writing come alive.
[02:08:39.600 --> 02:08:40.600]   I like it.
[02:08:40.600 --> 02:08:41.600]   Very good.
[02:08:41.600 --> 02:08:43.880]   I've been a reader for my whole life, I think.
[02:08:43.880 --> 02:08:48.920]   My dad subscribed and as soon as I could pick up a magazine, I probably started reading
[02:08:48.920 --> 02:08:52.480]   it mostly for the cartoons.
[02:08:52.480 --> 02:08:53.480]   Thank you.
[02:08:53.480 --> 02:08:54.480]   That's what I read when I was a kid.
[02:08:54.480 --> 02:08:55.480]   Yeah, good pick.
[02:08:55.480 --> 02:08:56.480]   Really good pick.
[02:08:56.480 --> 02:08:58.920]   That's where you get your twisted sense of humor.
[02:08:58.920 --> 02:08:59.920]   Indeed.
[02:08:59.920 --> 02:09:00.920]   Ant.
[02:09:00.920 --> 02:09:01.920]   You got a pick for us?
[02:09:01.920 --> 02:09:03.280]   Oh, this is John Seabrook wrote this.
[02:09:03.280 --> 02:09:04.960]   Oh, he's one of my favorite writers.
[02:09:04.960 --> 02:09:05.960]   Oh, nice.
[02:09:05.960 --> 02:09:06.960]   Ant.
[02:09:06.960 --> 02:09:14.280]   My pick this week is a little bit different, a little bit more on the inspirational side.
[02:09:14.280 --> 02:09:19.600]   As usual, you know, you know I'm a big fan of that little university in Clemson, South
[02:09:19.600 --> 02:09:20.600]   Carolina.
[02:09:20.600 --> 02:09:29.800]   Well, I met a guy several years ago over Twitter and his name is Jock McKissick.
[02:09:29.800 --> 02:09:33.000]   I knew of Jock McKissick as a Clemson football player.
[02:09:33.000 --> 02:09:39.080]   I watched him play on the defensive line and just crushed people with his athletic prowess,
[02:09:39.080 --> 02:09:45.520]   of course, but Jock didn't necessarily want to try to go to the NFL.
[02:09:45.520 --> 02:09:47.600]   He wanted to be an actor.
[02:09:47.600 --> 02:09:49.840]   He wanted to be a star on the screen.
[02:09:49.840 --> 02:09:51.200]   Good for him.
[02:09:51.200 --> 02:09:58.480]   And here in that back then from him, somebody that grew up in I believe it's Opelaca, Alabama.
[02:09:58.480 --> 02:10:01.160]   And can you just imagine how many people told him?
[02:10:01.160 --> 02:10:02.160]   You are crazy.
[02:10:02.160 --> 02:10:04.040]   That's so stupid.
[02:10:04.040 --> 02:10:07.520]   You need to go get a real job, if you will.
[02:10:07.520 --> 02:10:14.720]   But he continued to pursue it and went at it and got all of his support from the coaching
[02:10:14.720 --> 02:10:19.800]   staff at the time at Clemson University was able to attend some classes.
[02:10:19.800 --> 02:10:25.160]   And you know, here it took him about four years before he finally got a credit.
[02:10:25.160 --> 02:10:30.400]   But he kept working at it, started his own little production and started writing.
[02:10:30.400 --> 02:10:34.560]   And now I think he has 36 credits.
[02:10:34.560 --> 02:10:35.560]   There he is.
[02:10:35.560 --> 02:10:37.120]   He's done his own short films.
[02:10:37.120 --> 02:10:39.160]   He's been in a couple of big screen films.
[02:10:39.160 --> 02:10:42.800]   He's a regular on I believe it's called Queen of the South.
[02:10:42.800 --> 02:10:49.600]   It's a TV show on USA and he's just absolutely crushing it.
[02:10:49.600 --> 02:10:52.560]   The first time I saw him on TV it was on the blacklist.
[02:10:52.560 --> 02:10:56.000]   He came across the screen and I was like, "Wait a minute, is that Jock?"
[02:10:56.000 --> 02:10:57.000]   Holy crap, that's Jock.
[02:10:57.000 --> 02:11:00.360]   So I get on Twitter and it's like, "Dude, you're on black list."
[02:11:00.360 --> 02:11:04.240]   You know, and he's just so not a lot.
[02:11:04.240 --> 02:11:09.760]   But at the same time when he's not on the screen, he's trying to tell people, "Hey,
[02:11:09.760 --> 02:11:11.560]   be in there and do the work.
[02:11:11.560 --> 02:11:13.280]   Keep fighting for your dreams."
[02:11:13.280 --> 02:11:15.880]   Just keep trying and keep grinding.
[02:11:15.880 --> 02:11:16.880]   Keep grinding.
[02:11:16.880 --> 02:11:17.880]   That's nice.
[02:11:17.880 --> 02:11:21.880]   So, Jock McKissick, shout out to you or as you like to say salute.
[02:11:21.880 --> 02:11:22.880]   Salute.
[02:11:22.880 --> 02:11:23.880]   Nice.
[02:11:23.880 --> 02:11:27.680]   Mr. Kevin Tofel, what's your thing this week?
[02:11:27.680 --> 02:11:33.280]   So, I kind of feel bad because every time I bring a new thing to the show lately, it's
[02:11:33.280 --> 02:11:36.800]   like programming and that's because of my classes and we're still doing...
[02:11:36.800 --> 02:11:37.800]   I like that.
[02:11:37.800 --> 02:11:42.720]   Yeah, we're still doing our Dweinos in assembly code.
[02:11:42.720 --> 02:11:43.720]   Yes.
[02:11:43.720 --> 02:11:50.920]   So my pick is actually something I stumbled on just yesterday and it is a tutorial that
[02:11:50.920 --> 02:11:57.400]   for just a few bucks, you can get yourself a cheap little Arduino and you can basically
[02:11:57.400 --> 02:12:03.840]   start learning about machine learning and train a model or several models with speech
[02:12:03.840 --> 02:12:07.440]   recognition, gesture recognition, person detection.
[02:12:07.440 --> 02:12:09.440]   And I'm not going to lie here.
[02:12:09.440 --> 02:12:12.520]   I've been talking to Stacy about trying to get more into coding and stuff.
[02:12:12.520 --> 02:12:18.000]   So, Stacy, this is sort of for you too because I know you like the machine learning aspect
[02:12:18.000 --> 02:12:19.000]   of things.
[02:12:19.000 --> 02:12:21.200]   But this is definitely a great tutorial.
[02:12:21.200 --> 02:12:23.880]   Look at the gestures and the emojis.
[02:12:23.880 --> 02:12:24.880]   Right.
[02:12:24.880 --> 02:12:32.000]   And it's not going to cost you an arm and a leg to get a little Arduino BLE device.
[02:12:32.000 --> 02:12:34.240]   It's the Nano 33 BLE since.
[02:12:34.240 --> 02:12:37.600]   It's cheap and you can learn an awful lot.
[02:12:37.600 --> 02:12:40.640]   It's think about what Google and all the other companies are doing.
[02:12:40.640 --> 02:12:44.880]   You can do the same thing on a much smaller scale and learn a heck of a lot.
[02:12:44.880 --> 02:12:47.760]   You would like what I just got, Kevin Tofel.
[02:12:47.760 --> 02:12:48.760]   What's that?
[02:12:48.760 --> 02:12:50.760]   The Amazon Deep Racer arrived.
[02:12:50.760 --> 02:12:52.800]   Oh my gosh, it finally came.
[02:12:52.800 --> 02:12:56.000]   I think I ordered that like a year ago.
[02:12:56.000 --> 02:12:57.000]   Yeah.
[02:12:57.000 --> 02:12:59.640]   Now this is well beyond my abilities.
[02:12:59.640 --> 02:13:01.000]   When did I show up?
[02:13:01.000 --> 02:13:02.000]   Yeah.
[02:13:02.000 --> 02:13:06.760]   Well, it's at home in a box and I'm not going to get to do it until after I get back.
[02:13:06.760 --> 02:13:09.160]   But this is not a toy.
[02:13:09.160 --> 02:13:15.960]   It's not a remote control vehicle, but it's to teach you what Amazon calls reinforcement
[02:13:15.960 --> 02:13:19.760]   learning, which is a kind of, I guess, a kind of machine learning.
[02:13:19.760 --> 02:13:22.280]   It's a little road racer.
[02:13:22.280 --> 02:13:23.880]   You build a track for it.
[02:13:23.880 --> 02:13:27.400]   You teach it autonomous driving.
[02:13:27.400 --> 02:13:28.840]   You want to come over and play with it?
[02:13:28.840 --> 02:13:29.840]   That's cool.
[02:13:29.840 --> 02:13:30.840]   We can do it.
[02:13:30.840 --> 02:13:31.840]   That is freaking cool.
[02:13:31.840 --> 02:13:35.240]   So I just wanted to let you know I have it, but I mean, this is...
[02:13:35.240 --> 02:13:39.600]   This is going to take some time to get into.
[02:13:39.600 --> 02:13:43.160]   And maybe I should send it to Kevin since he likes his programming.
[02:13:43.160 --> 02:13:46.480]   Stacey and I were just talking about that device a couple of weeks ago.
[02:13:46.480 --> 02:13:48.640]   They amassed it years ago.
[02:13:48.640 --> 02:13:50.920]   Years ago, yes.
[02:13:50.920 --> 02:13:54.640]   And we thought maybe they just kind of shut it down because nobody seemed to have them
[02:13:54.640 --> 02:13:58.120]   other than a couple beta testers a year, a year and a half ago.
[02:13:58.120 --> 02:13:59.800]   So it's amazing that they're shipping now.
[02:13:59.800 --> 02:14:02.600]   I bought it when they showed it at whatever event it was.
[02:14:02.600 --> 02:14:08.640]   I thought this is great, which was dumb of me, but I did.
[02:14:08.640 --> 02:14:09.640]   And now I have it.
[02:14:09.640 --> 02:14:11.120]   You have any illnesses, all of this.
[02:14:11.120 --> 02:14:12.720]   I have a real problem.
[02:14:12.720 --> 02:14:13.720]   I do.
[02:14:13.720 --> 02:14:15.640]   You are going to learn something amazing.
[02:14:15.640 --> 02:14:16.640]   So do it.
[02:14:16.640 --> 02:14:17.640]   Yes.
[02:14:17.640 --> 02:14:18.640]   What is reinforced by learning?
[02:14:18.640 --> 02:14:26.360]   Oh, that's where you tell the Google, where you tell the Google, where you tell the model
[02:14:26.360 --> 02:14:27.840]   what you want to have happen.
[02:14:27.840 --> 02:14:30.280]   And every time that it happens, it does it achieves it.
[02:14:30.280 --> 02:14:32.040]   You're like, yes, do it more.
[02:14:32.040 --> 02:14:34.320]   Otherwise you shock it.
[02:14:34.320 --> 02:14:40.400]   No, that's how they trained the Go model.
[02:14:40.400 --> 02:14:41.400]   Oh, interesting.
[02:14:41.400 --> 02:14:45.920]   I know for years I had a screensaver called Brev Walker, which was like that.
[02:14:45.920 --> 02:14:50.000]   It would try to walk, but it would start with no legs, no information about it.
[02:14:50.000 --> 02:14:52.120]   And then we'd try different configurations.
[02:14:52.120 --> 02:14:56.480]   And if you kept running iteration after iteration and hundreds of thousands of iterations, you'd
[02:14:56.480 --> 02:14:58.800]   actually get a four-legged walking creature.
[02:14:58.800 --> 02:15:00.440]   It was a really fun thing.
[02:15:00.440 --> 02:15:02.200]   So I think this is kind of like that.
[02:15:02.200 --> 02:15:04.200]   So, and then I've wanted to think of plug.
[02:15:04.200 --> 02:15:05.200]   Oh, go ahead.
[02:15:05.200 --> 02:15:06.200]   Sorry.
[02:15:06.200 --> 02:15:09.360]   I was going to tell you for people who want to know more, AlphaGo Zero starting from scratch.
[02:15:09.360 --> 02:15:10.680]   There's a whole deep mind.
[02:15:10.680 --> 02:15:16.800]   There's a whole article on how they used reinforcement learning to train.
[02:15:16.800 --> 02:15:18.240]   Oh, so, okay.
[02:15:18.240 --> 02:15:20.160]   So I thought they let it just go.
[02:15:20.160 --> 02:15:21.160]   So they were giving it.
[02:15:21.160 --> 02:15:22.920]   That's what they're doing.
[02:15:22.920 --> 02:15:27.200]   You're giving it an outcome and you let it just optimize for that outcome, kind of like
[02:15:27.200 --> 02:15:28.200]   your Brev Walker.
[02:15:28.200 --> 02:15:29.200]   Yes.
[02:15:29.200 --> 02:15:30.200]   Okay.
[02:15:30.200 --> 02:15:32.280]   So you don't have to shock it or praise it.
[02:15:32.280 --> 02:15:34.840]   There's no carrots or sticks involved.
[02:15:34.840 --> 02:15:35.840]   Sorry, yes.
[02:15:35.840 --> 02:15:36.840]   Yes.
[02:15:36.840 --> 02:15:37.840]   Okay.
[02:15:37.840 --> 02:15:38.840]   So in other words, I can set up my Robo-Racer.
[02:15:38.840 --> 02:15:43.760]   I can set up my Robo-Racer and say, "I want you to go around this track."
[02:15:43.760 --> 02:15:48.640]   They provide you very thoughtfully with a half a roll of masking tape.
[02:15:48.640 --> 02:15:50.800]   So you can set up a track.
[02:15:50.800 --> 02:15:52.360]   And then I could say, "Okay."
[02:15:52.360 --> 02:15:55.880]   And then just tell it, figure out how to get around this track and then it will just
[02:15:55.880 --> 02:15:58.080]   run over and over and over and over and over.
[02:15:58.080 --> 02:15:59.080]   Wow.
[02:15:59.080 --> 02:16:00.080]   Wow.
[02:16:00.080 --> 02:16:01.080]   I can't wait.
[02:16:01.080 --> 02:16:02.080]   Man, that's nuts.
[02:16:02.080 --> 02:16:03.080]   That's going to be fun.
[02:16:03.080 --> 02:16:04.080]   That's going to be really fun.
[02:16:04.080 --> 02:16:05.080]   That's awesome.
[02:16:05.080 --> 02:16:07.400]   I want to give a plug to Carsten.
[02:16:07.400 --> 02:16:11.520]   When are you taking your time off to do this pretty soon?
[02:16:11.520 --> 02:16:13.800]   I'm not actually taking much time off.
[02:16:13.800 --> 02:16:17.200]   I'm going to be off on Friday and Sunday.
[02:16:17.200 --> 02:16:23.080]   Every year for the last few years, Carsten has taken time off around this time of year
[02:16:23.080 --> 02:16:26.280]   to do something I think really that helps people.
[02:16:26.280 --> 02:16:30.080]   It's kind of a habitat for humanity but for ghosts.
[02:16:30.080 --> 02:16:36.240]   He builds a haunted house for the high school and it's De Anza High School where his kids
[02:16:36.240 --> 02:16:38.800]   go and El Sabrani, California.
[02:16:38.800 --> 02:16:41.320]   And it's expensive, isn't it, Carsten?
[02:16:41.320 --> 02:16:42.960]   It costs me a bit.
[02:16:42.960 --> 02:16:47.160]   I want to become an advanced spooker.
[02:16:47.160 --> 02:16:53.240]   So I'm going to give you a little money on Patreon and now you will get your very first
[02:16:53.240 --> 02:16:56.320]   payment because it's currently at $0.
[02:16:56.320 --> 02:16:57.880]   But I will encourage- I really want money.
[02:16:57.880 --> 02:17:01.320]   I just want people, if you're in the Bay Area-
[02:17:01.320 --> 02:17:02.720]   To go to the haunted house.
[02:17:02.720 --> 02:17:10.440]   If you like Halloween next Saturday, we will be having a haunted house at De Anza High
[02:17:10.440 --> 02:17:13.600]   School on 5,000 Valley View Road in El Sabrani.
[02:17:13.600 --> 02:17:14.600]   Oh, it looks spooky.
[02:17:14.600 --> 02:17:17.920]   From 4 o'clock until 9 o'clock at night.
[02:17:17.920 --> 02:17:21.080]   Four to five is for kids who don't like being scared.
[02:17:21.080 --> 02:17:22.920]   There won't be any scary people in-
[02:17:22.920 --> 02:17:24.160]   No jump scares.
[02:17:24.160 --> 02:17:25.160]   That's what really scares me.
[02:17:25.160 --> 02:17:27.000]   Just walking around and looking at the things.
[02:17:27.000 --> 02:17:30.480]   And from five to nine, then you can have people jump out.
[02:17:30.480 --> 02:17:34.120]   So can I have my $10?
[02:17:34.120 --> 02:17:35.560]   I got a free ticket.
[02:17:35.560 --> 02:17:36.560]   That's all right.
[02:17:36.560 --> 02:17:37.560]   That's good enough.
[02:17:37.560 --> 02:17:42.400]   Yeah, it's on Patreon if you want to know more at patreon.com/carstenbondie.
[02:17:42.400 --> 02:17:44.240]   And there's Frank.
[02:17:44.240 --> 02:17:45.480]   You built that last year.
[02:17:45.480 --> 02:17:47.000]   You're doing something frank like this year though.
[02:17:47.000 --> 02:17:48.880]   I know because you injured yourself.
[02:17:48.880 --> 02:17:50.280]   Oh man.
[02:17:50.280 --> 02:17:51.280]   Yeah.
[02:17:51.280 --> 02:17:55.480]   It's not a good project unless I injure myself.
[02:17:55.480 --> 02:17:59.760]   Do you want to see the 2018 version?
[02:17:59.760 --> 02:18:05.680]   Here you go.
[02:18:05.680 --> 02:18:06.680]   People are going in.
[02:18:06.680 --> 02:18:08.600]   This is the little kid version though, right?
[02:18:08.600 --> 02:18:09.600]   So this is-
[02:18:09.600 --> 02:18:10.600]   This is crazy.
[02:18:10.600 --> 02:18:11.600]   This is crazy.
[02:18:11.600 --> 02:18:12.600]   This is crazy.
[02:18:12.600 --> 02:18:13.600]   This is crazy.
[02:18:13.600 --> 02:18:14.600]   This is crazy.
[02:18:14.600 --> 02:18:15.600]   This is crazy.
[02:18:15.600 --> 02:18:16.600]   This is crazy.
[02:18:16.600 --> 02:18:17.600]   This is crazy for Deanna.
[02:18:17.600 --> 02:18:18.600]   I see you.
[02:18:18.600 --> 02:18:19.600]   For the school.
[02:18:19.600 --> 02:18:20.600]   For the French teacher students association.
[02:18:20.600 --> 02:18:21.600]   Nice.
[02:18:21.600 --> 02:18:22.600]   Good.
[02:18:22.600 --> 02:18:23.600]   Very good.
[02:18:23.600 --> 02:18:32.680]   It's a public school in a district that is not all that well-funded.
[02:18:32.680 --> 02:18:35.880]   So we try to do our part to-
[02:18:35.880 --> 02:18:38.560]   And Carsten, are you the only- are you like the chief builder?
[02:18:38.560 --> 02:18:39.560]   I feel like-
[02:18:39.560 --> 02:18:40.840]   I'm pretty much the only builder.
[02:18:40.840 --> 02:18:45.280]   Yeah, you're like this- all of this high tech stuff is Carsten's doing.
[02:18:45.280 --> 02:18:46.280]   Which is kind of neat.
[02:18:46.280 --> 02:18:48.280]   It's amazing Carsten's doing it.
[02:18:48.280 --> 02:18:49.280]   Yeah, yeah.
[02:18:49.280 --> 02:18:53.440]   This is really- if we could figure out a way to tap this energy.
[02:18:53.440 --> 02:18:56.600]   We'd have a much scarier twig.
[02:18:56.600 --> 02:18:57.600]   Thank you Carsten.
[02:18:57.600 --> 02:18:58.600]   That's awesome.
[02:18:58.600 --> 02:18:59.600]   Nice work.
[02:18:59.600 --> 02:19:00.600]   And thank you Stacey Higgenbotham.
[02:19:00.600 --> 02:19:05.720]   Stacey on IOT.com is her fabulous podcast she does with Kevin Tofel.
[02:19:05.720 --> 02:19:08.680]   You can find out more at her website Stacey on IOT.com.
[02:19:08.680 --> 02:19:13.280]   And by the way, subscribe to the newsletter and it will stop bugging you after a while.
[02:19:13.280 --> 02:19:15.680]   She's @Giggastacey on the Twitter.
[02:19:15.680 --> 02:19:18.720]   Kevin Tofel is about Chromebooks.com.
[02:19:18.720 --> 02:19:19.720]   That's his site.
[02:19:19.720 --> 02:19:21.160]   He's also on the Stacey on IOT.
[02:19:21.160 --> 02:19:24.840]   He actually just called the IOT podcast because they're both hosts.
[02:19:24.840 --> 02:19:27.040]   @KevinC Tofel on the Twitter.
[02:19:27.040 --> 02:19:28.120]   Thank you for filling in for Jeff.
[02:19:28.120 --> 02:19:29.120]   I really appreciate it.
[02:19:29.120 --> 02:19:30.120]   Oh, my pleasure.
[02:19:30.120 --> 02:19:31.120]   My pleasure.
[02:19:31.120 --> 02:19:36.960]   Thanks to Aunt Pruitt, our newest, bestest buddy on Twitch.
[02:19:36.960 --> 02:19:37.960]   We love having you here.
[02:19:37.960 --> 02:19:43.200]   You came all the way up from Carolina just to be part of our family and brought his family
[02:19:43.200 --> 02:19:45.000]   and everything and they're all settling in, right?
[02:19:45.000 --> 02:19:46.000]   Yes, sir.
[02:19:46.000 --> 02:19:47.000]   Good to be here.
[02:19:47.000 --> 02:19:48.000]   They like to school.
[02:19:48.000 --> 02:19:49.000]   Yes, they do.
[02:19:49.000 --> 02:19:50.000]   Good.
[02:19:50.000 --> 02:19:51.480]   I think she's working hard now.
[02:19:51.480 --> 02:19:56.000]   She's busting her butt out there and trying to build that brand and I couldn't be more
[02:19:56.000 --> 02:19:57.560]   proud of this.
[02:19:57.560 --> 02:19:58.760]   And I can't be more proud of you.
[02:19:58.760 --> 02:20:01.760]   We got two shows, Hands Up Photography's already out.
[02:20:01.760 --> 02:20:02.760]   Twitter.tv/hop.
[02:20:02.760 --> 02:20:03.760]   Hop.
[02:20:03.760 --> 02:20:04.760]   We will be recording this week.
[02:20:04.760 --> 02:20:06.760]   I have the first episode tomorrow.
[02:20:06.760 --> 02:20:09.600]   I've got a promo if you want to see it.
[02:20:09.600 --> 02:20:11.160]   Oh, I asked you, didn't I?
[02:20:11.160 --> 02:20:12.160]   Well, maybe.
[02:20:12.160 --> 02:20:14.160]   Well, when you asked me, I didn't have it.
[02:20:14.160 --> 02:20:15.160]   Oh.
[02:20:15.160 --> 02:20:16.160]   But now I do.
[02:20:16.160 --> 02:20:17.160]   Oh, well, let's see.
[02:20:17.160 --> 02:20:18.160]   Watch.
[02:20:18.160 --> 02:20:19.160]   Yeah, yeah.
[02:20:19.160 --> 02:20:24.760]   I'll be sure to tell her that.
[02:20:24.760 --> 02:20:25.760]   It's a very Bob Ross.
[02:20:25.760 --> 02:20:26.760]   Kind of thing.
[02:20:26.760 --> 02:20:27.760]   Hey, folks.
[02:20:27.760 --> 02:20:33.360]   I'm Matt Pruitt and welcome to Hands On Photography here on Twit.tv.
[02:20:33.360 --> 02:20:37.200]   Each and every week, we're going to take a look at how you can get the most out of your
[02:20:37.200 --> 02:20:41.640]   camera so you can start sharing and posting some awesome photography.
[02:20:41.640 --> 02:20:47.480]   I don't care if you have a smartphone or an action camera, DSLR, mirrorless, whatever it
[02:20:47.480 --> 02:20:50.040]   is, we're going to get the most out of your camera.
[02:20:50.040 --> 02:20:54.080]   We'll also get into different tips and tricks to help make your video look better.
[02:20:54.080 --> 02:21:00.000]   So be sure to hit that subscribe button and check us out each week here on Twit.tv.
[02:21:00.000 --> 02:21:01.000]   Hands On Photography.
[02:21:01.000 --> 02:21:06.920]   And there's a new show coming from Ant that will allegedly be kind of photography focused
[02:21:06.920 --> 02:21:07.920]   in a different way.
[02:21:07.920 --> 02:21:08.920]   We'll talk about that.
[02:21:08.920 --> 02:21:09.920]   That was great.
[02:21:09.920 --> 02:21:10.920]   That was great.
[02:21:10.920 --> 02:21:11.920]   Yeah.
[02:21:11.920 --> 02:21:12.920]   That was great.
[02:21:12.920 --> 02:21:14.920]   Ant, you should do like a, well, no.
[02:21:14.920 --> 02:21:15.920]   Almost.
[02:21:15.920 --> 02:21:20.760]   It's a lone episode for how to shoot for the holidays, how to shoot like new babies, things
[02:21:20.760 --> 02:21:21.760]   like that.
[02:21:21.760 --> 02:21:23.600]   Like not, I mean.
[02:21:23.600 --> 02:21:24.600]   That's another show.
[02:21:24.600 --> 02:21:28.040]   Well, I mean, I don't know if there's enough content.
[02:21:28.040 --> 02:21:30.000]   This show is retouching.
[02:21:30.000 --> 02:21:31.600]   That show would be a good idea though.
[02:21:31.600 --> 02:21:34.440]   I think we should do that show and make it so.
[02:21:34.440 --> 02:21:35.440]   We do have some ideas.
[02:21:35.440 --> 02:21:37.440]   I guess we're coming.
[02:21:37.440 --> 02:21:38.440]   Shooting the act.
[02:21:38.440 --> 02:21:40.240]   Shooting at something in the world.
[02:21:40.240 --> 02:21:42.520]   Not just the act, but like everything tied to that one thing.
[02:21:42.520 --> 02:21:45.680]   You'll be shooting your baby and retouching it or whatever.
[02:21:45.680 --> 02:21:46.680]   I don't know.
[02:21:46.680 --> 02:21:47.680]   Absolutely.
[02:21:47.680 --> 02:21:49.400]   It's called ambient photography.
[02:21:49.400 --> 02:21:50.400]   Ambient.
[02:21:50.400 --> 02:21:53.600]   You can like stand still.
[02:21:53.600 --> 02:21:54.600]   Stand still.
[02:21:54.600 --> 02:21:55.600]   Pet.
[02:21:55.600 --> 02:21:56.600]   I will not be here next week.
[02:21:56.600 --> 02:21:57.600]   I will not be here the week after.
[02:21:57.600 --> 02:21:58.600]   I will not be here the week after that.
[02:21:58.600 --> 02:22:00.080]   I will not be here the week after that.
[02:22:00.080 --> 02:22:01.880]   I am going far, far away.
[02:22:01.880 --> 02:22:03.720]   We'll try not to burn down to studios.
[02:22:03.720 --> 02:22:04.760]   You're going to have a lot of fun.
[02:22:04.760 --> 02:22:09.720]   I know we're bringing in guest hosts so the twigs show never ends, but I will not be part
[02:22:09.720 --> 02:22:12.880]   of it sad to say as I go on vacation through.
[02:22:12.880 --> 02:22:15.240]   I will be back on November 20th.
[02:22:15.240 --> 02:22:21.880]   Will you be posting any pictures and maybe a Google Photos shared album?
[02:22:21.880 --> 02:22:22.880]   That's a good idea.
[02:22:22.880 --> 02:22:24.320]   I hadn't really thought about doing that.
[02:22:24.320 --> 02:22:26.120]   I will probably blog them.
[02:22:26.120 --> 02:22:31.120]   I have a smug mug page at www.leo.camera.
[02:22:31.120 --> 02:22:33.120]   I will probably put my best shots there.
[02:22:33.120 --> 02:22:34.120]   Maybe on Flickr.
[02:22:34.120 --> 02:22:36.680]   Then I will do the postcard thing.
[02:22:36.680 --> 02:22:38.840]   I did this last year.
[02:22:38.840 --> 02:22:41.640]   I set a postcard every day from the trip.
[02:22:41.640 --> 02:22:43.920]   I picked one shot and then a postcard.
[02:22:43.920 --> 02:22:47.720]   I am going to send them here so I am sure the host will share some of them with me.
[02:22:47.720 --> 02:22:49.840]   There will be lots of ways to keep up with me.
[02:22:49.840 --> 02:22:51.360]   I don't expect anybody to do that.
[02:22:51.360 --> 02:22:52.800]   He is not using Instagram.
[02:22:52.800 --> 02:22:54.120]   Forget I was here.
[02:22:54.120 --> 02:22:55.120]   No, I know.
[02:22:55.120 --> 02:22:56.800]   I am not using Facebook or Instagram.
[02:22:56.800 --> 02:22:57.800]   That's right.
[02:22:57.800 --> 02:22:58.960]   We will save travels.
[02:22:58.960 --> 02:22:59.960]   Thank you.
[02:22:59.960 --> 02:23:00.960]   Thank you all.
[02:23:00.960 --> 02:23:06.400]   We do this week in Google every Wednesday about 130 Pacific 430 Eastern 2030 UTC.
[02:23:06.400 --> 02:23:10.400]   You can stop by and watch live or listen live at Twit.TV/live.
[02:23:10.400 --> 02:23:16.880]   If you are doing it live, you should definitely be in the chat room at IRC.Twit.TV.
[02:23:16.880 --> 02:23:21.320]   But a lot of people, the vast majority, download the show's audio and video either from our
[02:23:21.320 --> 02:23:26.840]   website, Twit.TV/Twig or by subscribing in your favorite podcast application.
[02:23:26.840 --> 02:23:31.120]   If you are listening at your convenience, you can still interact with us because we have
[02:23:31.120 --> 02:23:34.320]   a brand new forum at Twit.Community.
[02:23:34.320 --> 02:23:35.480]   You can use your web browser.
[02:23:35.480 --> 02:23:36.480]   There are also apps.
[02:23:36.480 --> 02:23:37.480]   It is a PWA.
[02:23:37.480 --> 02:23:42.040]   You can easily put it on any device you have just by saving it to the device.
[02:23:42.040 --> 02:23:45.040]   I am really happy with how the community has turned out.
[02:23:45.040 --> 02:23:50.240]   We have, I don't know how many members, but there are about 12,000 visits a day now, something
[02:23:50.240 --> 02:23:51.240]   like that.
[02:23:51.240 --> 02:23:52.240]   It is very busy.
[02:23:52.240 --> 02:23:54.000]   It is a great way to talk back.
[02:23:54.000 --> 02:23:55.000]   It is in there.
[02:23:55.000 --> 02:23:56.640]   All our hosts are in there.
[02:23:56.640 --> 02:23:58.280]   We would love to have you.
[02:23:58.280 --> 02:23:59.280]   Twit.Community.
[02:23:59.280 --> 02:24:01.120]   There it is.
[02:24:01.120 --> 02:24:02.680]   Thanks everybody for joining us.
[02:24:02.680 --> 02:24:06.280]   I will see you in a month on This Week in Google.
[02:24:06.280 --> 02:24:06.640]   Bye-bye.
[02:24:06.640 --> 02:24:13.640]   [MUSIC]
[02:24:13.640 --> 02:24:16.220]   (upbeat music)
[02:24:16.220 --> 02:24:18.220]   You

