;FFMETADATA1
title=Punch Me in the HÃ¶vding
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=483
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.680]   It's time for Twig. This week in Google, we've got a big show for you. Jeff Jarvis and Matthew Ingram are here.
[00:00:05.680 --> 00:00:12.400]   We'll talk about a surprising revelation by Facebook right as the show began.
[00:00:12.400 --> 00:00:21.200]   Also the Google Change Log. And what's this? A new device has entered the studio. We'll talk all about it next on Twig.
[00:00:21.200 --> 00:00:27.360]   Netcast you love. From people you trust.
[00:00:27.680 --> 00:00:31.680]   This is Twig.
[00:00:31.680 --> 00:00:33.680]   This is Twig.
[00:00:33.680 --> 00:00:43.840]   This is Twig. This week in Google, episode 483 recorded Wednesday, November 21st, 2018.
[00:00:43.840 --> 00:00:46.560]   Punch me in the hufting.
[00:00:46.560 --> 00:00:52.560]   This week in Google is brought to you by Slidebelts by Brig Taylor. High quality, comfortable,
[00:00:52.560 --> 00:00:58.160]   ratchet belts that are easy to adjust. If you want a better belt, go to slidebelts.com/twit
[00:00:58.160 --> 00:01:06.240]   and use the code "Twit" for 20% off. And by Brex, the first corporate credit card for startups.
[00:01:06.240 --> 00:01:12.640]   Get the card free and Twit listeners get Brex card fees waived in perpetuity at brex.com/twit.
[00:01:12.640 --> 00:01:18.080]   And by Rocket Mortgage from Quick and Loans. Introducing Ray Shield Approval. If you're in
[00:01:18.080 --> 00:01:23.040]   the market to buy a home, Ray Shield Approval locks your rate up for up to 90 days while you shop.
[00:01:23.040 --> 00:01:28.720]   It's a real game changer. Learn more and get started at Rocket Mortgage.com/Twig.
[00:01:28.720 --> 00:01:33.360]   It's time for Twig this week in Google. The show, the Pre-Thanksgiving edition.
[00:01:33.360 --> 00:01:37.600]   Of this week in Google, Stacey Higginbotham is off building her Gantt chart.
[00:01:37.600 --> 00:01:42.240]   Remember that, Jeff? Last year, she had a Gantt chart for holiday preparations?
[00:01:42.240 --> 00:01:46.320]   If Jarvis does not. Well, she's got it. She's got to tell all the robots what to do.
[00:01:46.320 --> 00:01:53.040]   Yeah, non-trivial task in a home like Stacey's. Jeff Jarvis, Professor of
[00:01:53.040 --> 00:01:57.200]   Journalism, he's actually the Leonard Taparvassal of Journalism. I'm talking like that because I got
[00:01:57.200 --> 00:02:04.000]   a crown. Oh, I love that. Do you have the temporary on right now? I have the temp on now.
[00:02:04.000 --> 00:02:07.920]   Oh, I hate that. I'm running out of body parts, man. They're taking them all.
[00:02:07.920 --> 00:02:15.040]   Buzzmachine.com is where he blogs that other guy, laughing. Why? That's the famous Canadian
[00:02:15.040 --> 00:02:21.360]   Matthew Ingram. He writes for the Columbia Review of Journalism or Columbia Journalism Review.
[00:02:21.360 --> 00:02:25.120]   He's Chief Digital Writer. You're his suitably different, Matthew.
[00:02:25.120 --> 00:02:32.960]   Yeah, it's a winner thing. It's a playoff. I have Matthew. I have the perfect thing
[00:02:32.960 --> 00:02:39.200]   for both of us. What's that? If you go, I'll be holding on. Shoot. I got to find a home. One
[00:02:39.200 --> 00:02:43.280]   second, one second. Oh, no, where to go? Where to go? Where to go? The punch line. The lights in the
[00:02:43.280 --> 00:02:46.800]   beard. The lights go in the beard. Yeah. Christmas lights in your beard.
[00:02:46.800 --> 00:02:53.600]   Yeah. I'm going to try growing like a big mountain man. You know, like, I feel like I should grow.
[00:02:53.600 --> 00:02:57.360]   I got the gray beards on the show today. I should ask you tough questions.
[00:02:57.360 --> 00:03:04.800]   Well, we're tool white guys and hoodies. Black. Black hoodies. There we go.
[00:03:04.800 --> 00:03:10.720]   Oh, my. Oh, no, please, please do not do that.
[00:03:11.920 --> 00:03:14.720]   I'm thinking about it. I'm thinking about it. These lights for your beard. But that means you
[00:03:14.720 --> 00:03:20.240]   have a flash. They flash. Yeah. Well, if you do that, let me know because I will send you the,
[00:03:20.240 --> 00:03:25.840]   I got those eyelashes. I never had the guts to wear them that light up. What a kickstarter.
[00:03:25.840 --> 00:03:30.480]   Oh, that was one of one of Leo's best kickstrokers silly. Were they Christmas islands?
[00:03:30.480 --> 00:03:33.920]   Still waiting for the unicorn that farts rainbows. That never happened.
[00:03:33.920 --> 00:03:40.640]   They were, I don't remember. It was dumb. The sad thing. And I think I bet this happens not,
[00:03:40.640 --> 00:03:44.720]   is not unusual. They had it on Kickstarter. I put in some money.
[00:03:44.720 --> 00:03:50.640]   And then of course they were immediately copied by Chinese knockoffs, which you can get on Amazon
[00:03:50.640 --> 00:03:57.440]   for a tenth of price. I had to wait for mine. It was a bad, bad all around. Yeah, I got them.
[00:03:57.440 --> 00:04:05.520]   They're just, they're called F dot lashes or flashes. Okay. Fine, fresh, fierce,
[00:04:06.480 --> 00:04:13.520]   interactive LED lashes. They raised $113,000 some time ago.
[00:04:13.520 --> 00:04:21.200]   And they laugh at the back. Have you ever worn them? No. What would I do with these?
[00:04:21.200 --> 00:04:26.160]   Why did you buy them? I don't. I think we, I think we bear us to be the door. I think it was one
[00:04:26.160 --> 00:04:30.000]   of those cases where, you know, because the game is, can we get Leo to buy something on the show?
[00:04:30.000 --> 00:04:34.880]   You still have not convinced me to buy a game. No, it isn't. No, I never bought a
[00:04:34.880 --> 00:04:37.840]   roadie manic. I have some. I want you to get a roadie manic.
[00:04:37.840 --> 00:04:46.560]   The staff. You know, you know what? I will not be getting. I know the staff does want the
[00:04:46.560 --> 00:04:52.000]   roadie manic. I will not be getting smart contact lenses that can tell my blood sugar.
[00:04:52.000 --> 00:04:58.800]   No. Now my initial take on this was, and I actually mentioned this on the radio show,
[00:04:58.800 --> 00:05:05.840]   once again, Silicon Valley over promises and under delivers. But somebody said to me, no,
[00:05:05.840 --> 00:05:09.680]   this is, this is actually a good thing because unlike Theranos,
[00:05:09.680 --> 00:05:17.680]   Verily, which is Google's health, Alphabet's health science division, once they figured out,
[00:05:17.680 --> 00:05:21.360]   it can't be done, announced it and said, yeah, we're not going to do this.
[00:05:21.360 --> 00:05:24.800]   Harder than we thought. Yeah, that's, that's totally unlike Silicon Valley.
[00:05:24.800 --> 00:05:31.200]   Right. So I have to revise my initial disdain to say, well, at least they had the, you know,
[00:05:31.200 --> 00:05:35.920]   the courtesy to say, nah, that we, we talked about this, yeah, it turns out to be a lot harder to
[00:05:35.920 --> 00:05:41.840]   measure blood glucose in your tears because it's not consistent, I guess. They thought diabetics
[00:05:41.840 --> 00:05:49.200]   cried sugar, but apparently they don't. So this was something that sounds like a,
[00:05:49.200 --> 00:05:54.320]   sounds like a kind of dog ate my homework sort of excuse to me. Like why, why not just try harder?
[00:05:54.320 --> 00:06:00.560]   Ben, come on. It says in their posts, they're going to continue with other products. We remain
[00:06:00.560 --> 00:06:05.520]   committed to improving the lives of people with diabetes, including through improved methods for
[00:06:05.520 --> 00:06:11.520]   inexpensive and unobtrusive glucose sensing. This is the holy grail for health sciences,
[00:06:11.520 --> 00:06:19.200]   is a way to measure glucose without a pinprick. And in fact, Apple has made a big deal about how
[00:06:19.200 --> 00:06:23.840]   someday the Apple Watch will be able to do that. And no one has yet to be able to come up with an
[00:06:23.840 --> 00:06:29.040]   un-noninvasive. The best they can come up with is constant monitoring with that little patch,
[00:06:29.040 --> 00:06:33.200]   but it is, but it has little filaments that you inject. It's still, yeah, wait a minute.
[00:06:33.200 --> 00:06:40.880]   I think my flashes are here. Where'd you get those? Put them on. You already own them?
[00:06:40.880 --> 00:06:42.720]   And you didn't tell me?
[00:06:42.720 --> 00:06:52.000]   That's Father Robert Ballis there in effigy. He's now at the Vatican. If the Pope saw this.
[00:06:52.400 --> 00:06:54.400]   Not good.
[00:06:54.400 --> 00:06:58.800]   Bad news. Father Robert, I'd Father Robert.
[00:06:58.800 --> 00:07:05.360]   So he already did this as a project. Is he living in Rome? Oh, yeah. Like at the Vatican?
[00:07:05.360 --> 00:07:10.240]   He overlooks. Really? St. Mark's? What is it? Can we get? Can we get like,
[00:07:10.240 --> 00:07:16.720]   in several visits? Yes. What, what is he doing? Just being a
[00:07:17.600 --> 00:07:24.000]   priest. Last I heard. Okay. So Father Robert Ballisaire is a Jesuit. We called him the digital
[00:07:24.000 --> 00:07:28.800]   Jesuit. Worked for us for several years as a reporter and host of our shows. He's great guys,
[00:07:28.800 --> 00:07:35.440]   total geek. The whole time he worked for us, the Vatican was pulling at him. At one point,
[00:07:35.440 --> 00:07:41.920]   they offered him a bishopric. Wow. But I think that's the right word. They offered him a bishopric.
[00:07:43.120 --> 00:07:48.800]   And he turned it down because he would have had to become a not a Jesuit. It would have been a
[00:07:48.800 --> 00:07:56.560]   different, whatever they call that brother order. Order. Order is a good name. And the Jesuits are
[00:07:56.560 --> 00:08:02.400]   a very, you know, they have some strict rules. They sure do. Yeah. And the Pope is a Jesuit.
[00:08:02.400 --> 00:08:08.800]   So that's kind of the connection is that he's one of us, right? And so eventually,
[00:08:08.800 --> 00:08:12.560]   you know, at some point, if you're a priest, you can't really keep saying no to Rome.
[00:08:13.520 --> 00:08:20.400]   If Rome wants to go, right? They answer as the old, as the old rye bread commercial say,
[00:08:20.400 --> 00:08:26.560]   or the old kosher hot dogs say to a higher authority. Wasn't that the kosher hot dogs?
[00:08:26.560 --> 00:08:31.680]   We had to go higher authority. So the higher authority said you're getting out here.
[00:08:31.680 --> 00:08:38.880]   I think he's in charge of some sort of outreach kind of a thing. But honestly, I think what he
[00:08:38.880 --> 00:08:43.920]   really does, and I hope I'm not talking out of school when I say this, but because he is relatively
[00:08:43.920 --> 00:08:49.600]   young, I mean, they're all 80. And he runs the Twitter account or yeah, he's he's actually represents
[00:08:49.600 --> 00:08:56.640]   for them. And he's a geek. He understands. Yes, he literally runs social media. And he's he's the
[00:08:56.640 --> 00:09:02.640]   guy they run stuff through to make sure that it's, you know, that's cool. Yeah, it's a good job.
[00:09:02.640 --> 00:09:09.120]   Yeah, very cool. And but he was telling me he's such a geek that they had they have,
[00:09:09.120 --> 00:09:14.960]   is it called a conclave? They have an event? Yes. The Sinat or something, when all the all the
[00:09:14.960 --> 00:09:18.080]   Cardinals and everybody get together and he's there. He's not a Cardinal. He's just a priest,
[00:09:18.080 --> 00:09:24.640]   but he's there. And they all speak Italian. So he said the languages of Rome are Latin,
[00:09:24.640 --> 00:09:32.080]   somewhat Italian. And I can't. Where is Francis from? He's Argentinian, so I think Spanish, right?
[00:09:32.080 --> 00:09:38.160]   Spanish. So those are the languages and his Spanish is very good. His Latin is Metzameza and his
[00:09:38.160 --> 00:09:44.720]   Italian is the weakest. So he took the Bing translator and put it on the table in front of
[00:09:44.720 --> 00:09:48.560]   him on a smartphone. And it would listen that he could kind of understand the time the Bing
[00:09:48.560 --> 00:09:55.120]   translator would translate it and text simultaneous translation. I mean, this is kind of remarkable.
[00:09:55.120 --> 00:09:58.880]   It was good enough for him to follow what was going on. It could have avoided the 30 years war,
[00:09:58.880 --> 00:10:05.760]   this way. Yeah. Although the last communication we have from him is I'm being sent off to study Italian.
[00:10:05.760 --> 00:10:12.400]   Well, it shouldn't be that hard. I mean, to speak Italian, you just speak Spanish,
[00:10:12.400 --> 00:10:19.120]   Pavley. That's what I always thought. Or you add an O to an English word like airport, though.
[00:10:19.120 --> 00:10:26.720]   Exactly. It's not that hard. Anyway, he's, he's great. And he did say,
[00:10:27.760 --> 00:10:32.240]   if you go out, if you at least he said this to me, and listen, I'm sure it applies to you guys,
[00:10:32.240 --> 00:10:37.280]   that he will, he will get you in places that you know, awesome. They like the catacombs.
[00:10:37.280 --> 00:10:41.600]   Wow. Like the catacombs. Yeah. I wanted to go there last time I was there, but it was closed.
[00:10:41.600 --> 00:10:48.000]   Yeah. Well, I would just like to see Padre and have a nice pasta and wine with him and know that
[00:10:48.000 --> 00:10:52.240]   I'm talking to somebody who's into that. That'd be, that'd be just, you won't have a mess with him.
[00:10:52.240 --> 00:10:57.920]   He said, we eat, we eat spaghetti every meal. Oh, that's terrible. He's so good for sushi or something.
[00:10:57.920 --> 00:11:02.800]   Go for sushi. He'd be much happier. He said, we live within 500 feet of some of the best
[00:11:02.800 --> 00:11:07.200]   restaurants in the world. And we spads spaghetti. We'll get it. We'll get a hamburger.
[00:11:07.200 --> 00:11:13.440]   Oh, I could tell if Padre is, you're watching, I'll take you out to do it.
[00:11:13.440 --> 00:11:18.000]   We love Father Robert. We miss him. And he'll be back in January. He comes back for CES.
[00:11:18.560 --> 00:11:22.640]   He got permission to come back four times a year for big. I'll take him for steak Florentine.
[00:11:22.640 --> 00:11:28.800]   We ever had that? No. I've heard. I made the mistake of ordering it at a restaurant in
[00:11:28.800 --> 00:11:35.760]   Peruja. And someone said it's, it's a big steak. And I said, I like big steaks. You know, I like,
[00:11:35.760 --> 00:11:40.800]   in fact, I'm a little upset that I haven't been able to get a nice big steak in Italy. And they
[00:11:40.800 --> 00:11:47.120]   said, well, it's a really big steak. I'm just, but I thought, great. I like big steaks. It's,
[00:11:47.120 --> 00:11:52.800]   it was probably 22 ounces. It had to be the whole quarter. The size of your head.
[00:11:52.800 --> 00:11:58.240]   Is it a porter? Yes. It's the whole port. So normally you'd get a two bone out of that.
[00:11:58.240 --> 00:12:01.840]   You'd get fillet out of that. You'd get ribeye out of that. The whole thing.
[00:12:01.840 --> 00:12:05.520]   And it serves the beans as if you needed something else.
[00:12:05.520 --> 00:12:10.000]   And canalini beans and lemon wedges. Wow.
[00:12:11.360 --> 00:12:17.440]   I used, I was there with Bobby Goshu was, I think the international editor at time
[00:12:17.440 --> 00:12:24.320]   for a while. Anyway, he, he also ordered one, which, yeah, we should have just shared one.
[00:12:24.320 --> 00:12:29.520]   Well, that's, I've had these, but you have for two. Yeah. And they carve it up. Good idea.
[00:12:29.520 --> 00:12:30.240]   Yeah. Idea.
[00:12:30.240 --> 00:12:38.160]   We have straight far. Boy, have we ever. And why? But that's okay. It's going to be that kind of
[00:12:38.160 --> 00:12:43.360]   show. And sometimes it is squirrel. I got one. I got a good one. Let me take a break. And then
[00:12:43.360 --> 00:12:50.400]   we come back. I'll give you a good one for, for both of you, which is what's going on in Europe
[00:12:50.400 --> 00:12:57.280]   with the link thing. Mm hmm. Yeah. Mm hmm. You'll be talking about that for a couple hours. So let's
[00:12:57.280 --> 00:13:03.440]   get a commercial. It's time for a word from slide belts. This is a great holiday gift.
[00:13:04.240 --> 00:13:10.800]   I am like many people. Belts never served me very well because the problem with belts
[00:13:10.800 --> 00:13:17.120]   is that, you know, it's basically caveman technology. Take a piece of leather, punch five holes in it,
[00:13:17.120 --> 00:13:22.720]   and hope one of them works. But the problem is now, you know, it's never, it's either too tight or
[00:13:22.720 --> 00:13:27.120]   too loose. Your pants fall down or you can barely breathe. It's not a great solution. Slide belts
[00:13:27.120 --> 00:13:32.720]   is a modern world solution to an age old problem. How to keep your pants up. Slide belts
[00:13:34.000 --> 00:13:39.360]   are a great gift for dad. Yeah, see, because it's a Twitter. That's how you know, right?
[00:13:39.360 --> 00:13:44.080]   They don't have, they don't have, by the way, this is the buckle and the belt comes separately
[00:13:44.080 --> 00:13:48.400]   because they're in the belts are interchangeable and they have all kinds of belts. Everything from
[00:13:48.400 --> 00:13:54.000]   beautiful full grain and top grain leather like this to canvas, animal friendly, vegan.
[00:13:54.000 --> 00:14:00.640]   So they call them straps because they're kind of like watch bands. So what you do is you get
[00:14:00.640 --> 00:14:05.840]   your belt and you put it in the buckle and you can't get the buckles engraved. They come in a variety
[00:14:05.840 --> 00:14:12.400]   of looks. This is the chrome engraved buckle. You see, I put it in there and now it's, but these
[00:14:12.400 --> 00:14:17.360]   are easy to change. So, you know, you get get a buckle that says, you know, Twitter, whatever you
[00:14:17.360 --> 00:14:22.240]   want on it. And then I love this when you put the belt on, it's got these ratchets 32 of them.
[00:14:22.240 --> 00:14:24.720]   This is a patent technology. Listen to the sound.
[00:14:27.120 --> 00:14:32.160]   The belt now, it's really good. It fits much better than a belt with just a few holes in it.
[00:14:32.160 --> 00:14:37.040]   And notice that's when you're putting it on it goes, but when you're loosening it after big
[00:14:37.040 --> 00:14:44.800]   Thanksgiving day dinner, it's silent. So no one will know. They just hear this in the morning
[00:14:44.800 --> 00:14:51.440]   and then they don't hear anything as, as the evening progresses. I love slide belts. 32 adjustments
[00:14:51.440 --> 00:14:56.560]   means it'll fit you better than any belt you've ever worn before. And because they have so many
[00:14:56.560 --> 00:15:01.760]   different designs and styles, they're great for around the house at the office for holiday parties.
[00:15:01.760 --> 00:15:06.560]   Let me show you another one. This is the, I love this one. This is the antique brass. This is how
[00:15:06.560 --> 00:15:12.560]   they come to like in gift sets. So they're beautiful antique brass. And this is a the Navy canvas.
[00:15:12.560 --> 00:15:18.800]   It's very pretty. There's one other buckle I want to show you. If you go to slidebeltsplural.com/twit,
[00:15:18.800 --> 00:15:22.640]   you can get 20% off your order when you use the offer code twit. You might want to order,
[00:15:22.640 --> 00:15:33.600]   yes, the survival built 2.0. It looks like an innocuous belt buckle. But should you be out camping
[00:15:33.600 --> 00:15:40.400]   and you need to light a fire or open a bottle or have a flashlight utility belt looks like a
[00:15:40.400 --> 00:15:47.280]   normal belt, but look, there's a knife in it. It's sharp too. There is, there's a flashlight in it.
[00:15:47.280 --> 00:15:53.600]   It's very bright despite its tiny size. And you can, this is a fire starter. So you can use a
[00:15:53.600 --> 00:16:00.720]   knife to set sparks on the fire starter. This is literally, you could be lost in the wilderness with
[00:16:00.720 --> 00:16:06.720]   nothing but a belt. You might look weird, but you'd be able to cook, eat,
[00:16:06.720 --> 00:16:15.200]   hunt small animals. This is, this would be a great gift. A survival for, you know,
[00:16:16.000 --> 00:16:20.240]   kids coming back from college, groomsmen, if you got a wedding coming up, slidebelts by
[00:16:20.240 --> 00:16:26.640]   Brig Taylor are high quality, but they have a variety of prices. They have some really nice
[00:16:26.640 --> 00:16:30.640]   gifts by the way in the gift set tab, but I have to tell you, those are already discounted. So the
[00:16:30.640 --> 00:16:36.480]   20% off does not apply to those, but every other belt. And they now offer watches with similar
[00:16:36.480 --> 00:16:42.560]   swappable watch bands, which is really nice too. All slidebelts come with a one year warranty,
[00:16:42.560 --> 00:16:49.760]   free exchanges and no hassle returns. It is a great gift idea. Go to slidebelts.com/twit.
[00:16:49.760 --> 00:16:55.120]   Use the offer code twit at checkout and you'll get 20% off your order. It's not too late to shop
[00:16:55.120 --> 00:17:01.520]   for the holidays. I think, I think Hanukkah's early this year, right? So hustle over there,
[00:17:01.520 --> 00:17:12.080]   slidebelts.com/twit. So they tried it in Spain and it didn't work so high.
[00:17:12.080 --> 00:17:14.960]   In Germany, kind of first. Do you know what that was called?
[00:17:14.960 --> 00:17:18.640]   Leitsung Zeitzreifenhaben. Leitsung Schutzrecht.
[00:17:18.640 --> 00:17:28.160]   Shall we play the reggae? There is a song. Google News is now making noise that EU,
[00:17:28.160 --> 00:17:34.720]   so this, I'm conflating this maybe with the copyright law. I know there's parts of the same
[00:17:34.720 --> 00:17:47.280]   laws chapters 11 and 13. Article 13 would introduce the copyright. Article 11 would introduce the
[00:17:47.280 --> 00:17:58.160]   link text. So the link text, so news publishers in Spain complained that Google was free riding
[00:17:58.160 --> 00:18:04.000]   on their content because in the search results, they would include snippets from the article,
[00:18:04.000 --> 00:18:10.320]   not the whole article, right? Yeah, just snippets. And they said, well, we want,
[00:18:10.320 --> 00:18:14.720]   there's, Google should pay us for the use of those snippets to which Google replied,
[00:18:14.720 --> 00:18:23.360]   fine, see ya, and left Spain, which meant all of those newspapers drastically lost traffic
[00:18:23.360 --> 00:18:28.960]   because you couldn't Google them, right? Jeff is right. You couldn't Google News.
[00:18:29.920 --> 00:18:35.840]   So in Germany, first, they tried to define a snippet, how much was more than less than a
[00:18:35.840 --> 00:18:40.160]   snippet and they failed. They tried to do all kinds of things in the law. At the end of the day,
[00:18:40.160 --> 00:18:45.440]   basically what happened was in the German law, they said that Google has to have permission
[00:18:45.440 --> 00:18:52.720]   to do this. And Google said, we're back. And so publishers tried to withdraw the permission
[00:18:52.720 --> 00:18:57.440]   and not do it. They found after, I think it was two to three weeks, this was a disaster. They all
[00:18:57.440 --> 00:18:59.600]   gave Google permission. In Spain,
[00:18:59.600 --> 00:19:04.000]   Axel Springer said they lost 30%, 40% of their traffic.
[00:19:04.000 --> 00:19:06.560]   And by the way, no love lost between Axel Springer and Google.
[00:19:06.560 --> 00:19:08.720]   Oh, God, no, the Axel Springer started wars against Google.
[00:19:08.720 --> 00:19:10.240]   Yeah, they may be the number one in the Google.
[00:19:10.240 --> 00:19:15.840]   They didn't allow any permission structure. They just said, you must pay.
[00:19:15.840 --> 00:19:21.200]   That's when Google said, no, we won't. We can't, we're sending you traffic. We're sending you
[00:19:21.200 --> 00:19:25.280]   people. No, we're not paying for content. It's not like, no, I want to not content.
[00:19:25.280 --> 00:19:31.040]   I want to, I'm trying to play the other side here. It is their content in the snippet,
[00:19:31.040 --> 00:19:33.120]   but it's not like it's the whole article, right? It's just,
[00:19:33.120 --> 00:19:38.800]   exactly. One of the things I've seen research on is that, because the argument is, the snippet
[00:19:38.800 --> 00:19:42.640]   is too long. It's too much content. The truth is what I've seen in research and what I've learned
[00:19:42.640 --> 00:19:48.240]   from my own experiences, the longer the excerpt, the better the link performance.
[00:19:48.240 --> 00:19:51.440]   So what you want as the publisher is that somebody clicks that link.
[00:19:52.080 --> 00:19:56.160]   So the thesis is, well, if you put the snippet, they're going to read the story and say, oh, fine,
[00:19:56.160 --> 00:20:04.080]   I got it and not click the link, which does happen. Yeah, of course, if you see a headline that says,
[00:20:04.080 --> 00:20:12.720]   Matthew Reagan grows beard, and I don't want to know anymore. I'm sorry, Matthew, then that,
[00:20:12.720 --> 00:20:18.640]   then yeah, I've learned everything I needed to learn. And the headline did that. That's been
[00:20:18.640 --> 00:20:24.400]   true forever. It's like walking back to the newsstand. Is it what I'm seeing right here?
[00:20:24.400 --> 00:20:31.520]   I just searched for Khashoggi. And in this search results for USA Today, there's the headline,
[00:20:31.520 --> 00:20:36.800]   and then there's three lines with ellipsis. So they're doing some sort of editorializing,
[00:20:36.800 --> 00:20:41.120]   right? They're snippeting. It's more than just taking the first three lines of the article.
[00:20:41.120 --> 00:20:44.320]   I guess. I don't know. There's no-
[00:20:44.320 --> 00:20:48.800]   Go to, I don't know, check it. Click on the earth. Right. So number one USA Today,
[00:20:48.800 --> 00:20:57.600]   Breitbart is number two, no ellipsis, but three lines. And then there's a hashtag news about
[00:20:57.600 --> 00:21:04.160]   the show, and click on the news link for the story, the very top. I'm pointing to my screen,
[00:21:04.160 --> 00:21:08.000]   as if you can see it. Yeah, I get it. Right. So this is the snippets they're talking about.
[00:21:08.000 --> 00:21:10.880]   This is more look how short those are. They're a sentence.
[00:21:11.600 --> 00:21:15.600]   Right. If that, yeah, because they're all ending with ellipsis because they don't actually get to
[00:21:15.600 --> 00:21:19.760]   the period. So, the headlines get a little bit of the lead. President Donald Trump acknowledged
[00:21:19.760 --> 00:21:24.720]   Tuesday's Saudi crown prince, Mohammed bin Salman, could have known of the murder of ah, dot dot dot.
[00:21:24.720 --> 00:21:30.240]   Right. Justin off to tell you if this search result is what you're looking for.
[00:21:30.240 --> 00:21:35.200]   Yeah. The truth is, the truth is the publishers are not as stupid as they seem here. They're not
[00:21:35.200 --> 00:21:39.600]   trying to get paid for content. They're just trying to get any way they can to get some of
[00:21:39.600 --> 00:21:45.680]   Google's money because they lost money by not offering advertisers a full deal. So they're just
[00:21:45.680 --> 00:21:52.880]   trying to blackmail Google or Facebook into paying the money because arms for the poor.
[00:21:52.880 --> 00:21:59.360]   And we should point out, we should point out this has been going on since 2006. Yes. So
[00:21:59.360 --> 00:22:06.400]   Belgium, I think, was the first one to complain. But then it spread basically through Europe.
[00:22:06.400 --> 00:22:12.400]   Spain was the first one to to really put the paddle to the floor, I think, Google yanked the entire
[00:22:12.400 --> 00:22:17.600]   service. But this is a debate that's been going on for over a decade. So by the way, I just went to
[00:22:17.600 --> 00:22:24.480]   duck duck go in the news section. They do the same exact thing. Yeah. Yeah. Every search. Every
[00:22:24.480 --> 00:22:29.760]   search engine does because the headline is probably not enough to give you an eye. And they do it,
[00:22:29.760 --> 00:22:35.120]   by the way, if I search for a twit, they do the same thing because the headline isn't enough
[00:22:36.160 --> 00:22:41.680]   to. Okay. This is why I don't like duck duck go. I search for twit. What do I get?
[00:22:41.680 --> 00:22:45.840]   Man trapped is wild birds using glue and put them in cages just like Mr. Twit.
[00:22:45.840 --> 00:22:53.920]   Come on. That's a relevant result. These are ridiculous. Why did you do that?
[00:22:53.920 --> 00:22:59.280]   Why did I do what? Trap birds with glue? Yeah. I'm not Mr. Twit. I'm chief to it.
[00:23:01.760 --> 00:23:05.840]   Pumbler look at the O's. If you go to the New York Times, public heard, I'm not through public
[00:23:05.840 --> 00:23:11.440]   urge to listen for Twit to woo amid concern over Tawny owl decline.
[00:23:11.440 --> 00:23:19.440]   You did kind of take that word from the birds. I think the bird took it from me, but that's
[00:23:19.440 --> 00:23:27.600]   another story. So Twit hits the fan. Fackless, twit. Adam best scolds representative Scalise.
[00:23:27.600 --> 00:23:33.600]   Twit hits the fan. Trump goes nuclear. Kansas City mom and online hit after telling off
[00:23:33.600 --> 00:23:43.440]   prissy Twit. Anyway, anyway, so the excerpts, it's ridiculous to charge money for this.
[00:23:43.440 --> 00:23:51.120]   It's ridiculous on on its face. It's it's what Jeremy called nonsense on stilts. I mean,
[00:23:51.120 --> 00:23:56.960]   it's just a ridiculous line nonsense on stuff. It doesn't it's also they have no leverage because
[00:23:57.600 --> 00:24:01.920]   Google has all the leverage in this relationship, right? All Google has to do is they did to Spain.
[00:24:01.920 --> 00:24:06.080]   Well, in Google said, you have a choice if you're a publisher, you can include
[00:24:06.080 --> 00:24:12.080]   something in your robots.txt file that prevents Google from indexing your site.
[00:24:12.080 --> 00:24:16.960]   And they're not doing that problem solved. So yeah, so so that is another answer.
[00:24:16.960 --> 00:24:23.840]   Nevertheless, this is probably going to become the law right? This new copyright law.
[00:24:23.840 --> 00:24:30.000]   It's headed. It seems that way. Yeah. And that's our article 11 right now.
[00:24:30.000 --> 00:24:33.920]   It's article 13 is also dangerous because it's the one that's aimed at YouTube.
[00:24:33.920 --> 00:24:38.720]   And makes the published it takes away all the safe harbors and makes the publisher responsible
[00:24:38.720 --> 00:24:42.400]   for anything that's put up that might have copyright. And so publishers got so this is going to kill
[00:24:42.400 --> 00:24:47.920]   the meme is literally is going to kill the modern day alphabet of the meme. Because like the DMCA
[00:24:47.920 --> 00:24:55.760]   didn't exist. There's no protection. Anything that's even remotely copyrightable. You have to
[00:24:55.760 --> 00:25:03.120]   prevent it from being uploaded if you can, not just take it down when someone says it's copyrighted,
[00:25:03.120 --> 00:25:09.920]   but prevent being uploaded in the first place. Here's YouTube's response hash tag, save your
[00:25:09.920 --> 00:25:15.600]   internet. Article 13 is written by the European Parliament. Oh, wait a minute. That's a snippet.
[00:25:15.600 --> 00:25:24.000]   I'll just leave that out. By the way, we do snippets too. Yeah. And we don't have we don't honor robots
[00:25:24.000 --> 00:25:32.480]   text. So Google's in a better position than we are. Is this going to pass? Probably. No, yeah.
[00:25:32.480 --> 00:25:39.920]   Yeah, it seems that way. And so so Google as you start off the the the stippity in here, Richard
[00:25:39.920 --> 00:25:45.280]   Jinger is the senior vice president for Google News was in a European tour this week where he
[00:25:45.280 --> 00:25:51.440]   to his friends, he was putting up photos of him eating oysters on the sand. But to the world,
[00:25:51.440 --> 00:25:54.160]   he was saying, you do this. I pull Google News out of Europe.
[00:25:54.160 --> 00:26:02.000]   Not Google's search results. Google News. Google News. He didn't say he would. He said
[00:26:02.000 --> 00:26:08.640]   that Google would consider it. If this happens, it would be a shame if something happened to your
[00:26:08.640 --> 00:26:17.040]   nice news index you got there. Yeah. Yeah. Now mind you, because of GDPR, the general data
[00:26:17.040 --> 00:26:22.880]   protection regulations, if I when I was just in Europe last week, I tried to read the LA Times,
[00:26:22.880 --> 00:26:27.760]   I can't. So a lot of them are publishers. Shut off because they don't want to go to the
[00:26:27.760 --> 00:26:31.840]   effort on GDPR. And it's not worth it. It's just really not worth it because they have no way to
[00:26:31.840 --> 00:26:37.120]   monetize European readers. So screw them. So the man is bulk and I is not from China, but from Europe.
[00:26:38.000 --> 00:26:44.960]   I think one of the risks with particularly with the copyright end of it is there is in the US
[00:26:44.960 --> 00:26:51.280]   and in other countries like Canada, the term fair use or in Canada and Britain, it's called fair
[00:26:51.280 --> 00:27:00.800]   dealing, a sort of clause that basically allows you to use copyrighted works in certain ways
[00:27:01.840 --> 00:27:08.640]   for artistic purposes, for education, for criticism. Effectively, this copyright
[00:27:08.640 --> 00:27:17.760]   regulation would would make fair use or fair dealing not exist. So you would not be allowed
[00:27:17.760 --> 00:27:24.320]   to use any type of copyrighted content, even a tiny, tiny bit for some alternate purpose like
[00:27:24.320 --> 00:27:31.520]   artistic or education. Or or or comment or satire, right? Or promotion. This throws
[00:27:32.000 --> 00:27:39.360]   fair use out of Europe. Oh, yeah. Pretty much. So, you know, I mentioned this a couple of weeks
[00:27:39.360 --> 00:27:45.040]   ago when we did the Apple, the live stream of the Apple event, which we do every time Apple has a
[00:27:45.040 --> 00:27:49.680]   keynote, we stream the keynote and comment on top of it. And our defense is that's fair use
[00:27:49.680 --> 00:27:56.320]   because it's for commentary purposes. And as you may remember, YouTube got a takedown request from
[00:27:56.320 --> 00:28:02.080]   Apple not to take down the edited video, but to kill our live stream, which killed our live stream
[00:28:02.080 --> 00:28:10.720]   for two weeks. We we defended it. We, you know, we said no, it's not. And Google said, okay, well,
[00:28:10.720 --> 00:28:15.600]   if we don't get a response from Apple in 16 days, you'll be back up. So two weeks later,
[00:28:15.600 --> 00:28:21.280]   we're back up on YouTube live. Oh, because Apple didn't well, yeah, but it's still scary. It's
[00:28:21.280 --> 00:28:26.320]   terrifying because I mean, it's definitely has a chilling effect because Apple could take us down
[00:28:26.320 --> 00:28:31.520]   for two weeks, basically at any time. And that's a punishment because it's not just the Apple event.
[00:28:31.520 --> 00:28:38.720]   It's in our entire live stream on YouTube live for two or three weeks. And so that's a significant
[00:28:38.720 --> 00:28:44.400]   burden. You should be afraid of train. Well, our I'm not.
[00:28:46.320 --> 00:28:55.040]   Defense is it's fair use. Yeah. So in Europe, Apple could do the same thing. And there'd be no
[00:28:55.040 --> 00:28:57.920]   defense. You're done. Right. You would have no appeal.
[00:28:57.920 --> 00:29:08.240]   And I think the it's interesting the last time I looked at fair use in the US, there was a ruling
[00:29:08.240 --> 00:29:16.240]   that I'm trying to remember the name of it, but effectively said that companies like Google or
[00:29:16.240 --> 00:29:23.360]   Apple or, you know, Time Warner have to consider fair use before they make a claim.
[00:29:23.360 --> 00:29:28.560]   Not later have somebody say, Hey, that's fair use. They actually have to actively consider it.
[00:29:28.560 --> 00:29:33.760]   And if it's shown that they didn't, that can basically ruin a case for them.
[00:29:33.760 --> 00:29:37.440]   That's kind of that's pretty strong protections. Yeah, that's unusual because really,
[00:29:37.440 --> 00:29:42.000]   my understanding of fair use has always been it's a defense so that they can stop you. They
[00:29:42.000 --> 00:29:46.480]   could shut you down your defense when you go to court your honor. This was fair use. And then the
[00:29:46.480 --> 00:29:50.560]   judge has three three different criteria that he's supposed to use for four different criteria
[00:29:50.560 --> 00:29:54.880]   that's supposed to use to, you know, how much of the material was used. If there was a loss of
[00:29:54.880 --> 00:30:01.920]   value to the company, things like that. Transfibrative change. And so then the judge rules. So the
[00:30:01.920 --> 00:30:07.440]   fair use is a defense. It's right. But this sounds like it's a little bit more now, which is good.
[00:30:07.440 --> 00:30:11.680]   There's strengthening it in the US. That's why this decision was important because it's
[00:30:11.680 --> 00:30:16.720]   specifically said you can't just take everything down and then wait for somebody to claim fair use.
[00:30:16.720 --> 00:30:22.240]   You have to actively consider it. So this is part of the problem is this,
[00:30:22.240 --> 00:30:30.240]   the internet's so global as goes the EU to some degree. So goes the rest of the world. If the
[00:30:30.240 --> 00:30:35.600]   whatever the lowest standard is, right? I mean, I that's the risk. I mean,
[00:30:35.600 --> 00:30:44.400]   you've got, you know, the EU is a lot of countries. They are maybe not as economically important
[00:30:44.400 --> 00:30:50.320]   individually as the US, but together, that's a pretty big market, especially if you want to
[00:30:50.320 --> 00:30:57.280]   expand outside of the US. And so maybe, you know, some companies might decide, well, we just won't
[00:30:57.280 --> 00:31:02.240]   have anything to do with the EU, but that's not a choice that a global company can make.
[00:31:04.160 --> 00:31:08.880]   So what so YouTube, I mean, this is what Google's always done is they have different rules is
[00:31:08.880 --> 00:31:15.600]   what GDPR did. Although you can see how GDPR leaks in this case in mostly good ways into our lives
[00:31:15.600 --> 00:31:20.320]   in the US. Facebook, for instance, has to offer a feature at least to people in the EU to delete
[00:31:20.320 --> 00:31:24.160]   their data from Facebook. And most companies like Facebook just say, well, we'll make this
[00:31:24.160 --> 00:31:31.520]   available to everybody. That's is that distracting having a a big? I'm hit no time. I should probably
[00:31:31.520 --> 00:31:35.920]   take that. Okay, a little father, Robert is blinking his antennae on me.
[00:31:35.920 --> 00:31:45.440]   So, well, and it's of course we have no say about this. According to the Guardian article,
[00:31:45.440 --> 00:31:51.760]   the proposals were overwhelmingly backed by members of the European Parliament in September.
[00:31:51.760 --> 00:31:57.440]   But Google is hoping to influence the European Commission and EU member states before it's confirmed.
[00:31:58.640 --> 00:32:03.200]   And the problem here, of course, is that publishers and media companies are using all their political
[00:32:03.200 --> 00:32:07.280]   capital to try to get this passed. This is protection of legislation.
[00:32:07.280 --> 00:32:15.520]   Well, I will continue to follow it. It seems like it seems like the news is worse and worse, however.
[00:32:15.520 --> 00:32:21.520]   I think in a way, that and the link tax, the theme that sort of runs through them is
[00:32:22.640 --> 00:32:31.760]   lots of big publishers, music companies, sort of content owners feel like they've been getting
[00:32:31.760 --> 00:32:38.480]   ripped off since the internet was invented. And so all of these things are ways of them trying
[00:32:38.480 --> 00:32:43.920]   to claw back some of the money that they feel Google and Facebook and other companies are making
[00:32:43.920 --> 00:32:47.920]   at their expense. Which of course is not the case because it's just Google and Facebook and
[00:32:47.920 --> 00:32:54.320]   company just competed in a new reality. When I was in Munich a few weeks ago and spoke to the
[00:32:54.320 --> 00:33:00.080]   Munich media and tag media days. And the whole presentation was me, unfortunately, there was
[00:33:00.080 --> 00:33:05.360]   nobody in the audience, so nobody heard it. But it's me going through every one of these cases of
[00:33:05.360 --> 00:33:10.640]   legislation and regulation and court cases lately and saying here's the unintended consequences.
[00:33:10.640 --> 00:33:15.520]   The effort was to take away power from Google and Facebook. In each case, it gave them more power.
[00:33:16.560 --> 00:33:23.120]   And take GDPR. American publishers can't afford to and don't bother with dealing with this,
[00:33:23.120 --> 00:33:26.800]   but Google and Facebook are the only companies that are big enough where it doesn't affect them,
[00:33:26.800 --> 00:33:28.560]   it's easy to do it. Fine, okay fine, we'll do it.
[00:33:28.560 --> 00:33:32.160]   Right to be forgotten, Google has more power.
[00:33:32.160 --> 00:33:37.920]   Nets stay gay, the hate speech law, Facebook has more power. They backfire in every way.
[00:33:37.920 --> 00:33:45.120]   Yeah, I think the main thing with a lot of those rules is that Google and Facebook can
[00:33:45.120 --> 00:33:54.800]   afford to pay whatever's required to sort of get into, you know, to play along with those rules,
[00:33:54.800 --> 00:34:00.080]   but lots of smaller companies gain. So they're just excluded from the market, which gives even
[00:34:00.080 --> 00:34:05.760]   more power to the large incumbents. There's no chance that Google will give
[00:34:05.760 --> 00:34:12.640]   pittance to these news companies. No, no, no, because what's the precedent that sets?
[00:34:13.440 --> 00:34:17.840]   Then I can, for Buzz machine, I can say, I'm going to set a price in Google, you've got to pay me.
[00:34:17.840 --> 00:34:24.720]   I know, of course, Google's not going to. And then, so Google will say, well, I guess we got to cut
[00:34:24.720 --> 00:34:29.840]   off Buzz machine. And so you're not in search. And so we have a worse search and sort of ruins
[00:34:29.840 --> 00:34:34.480]   the web. That's what the Europeans are doing here. They are ruining the web.
[00:34:34.480 --> 00:34:42.480]   I know you're killing the open internet. And I think it's, you know, fair use is a sort of
[00:34:43.120 --> 00:34:49.680]   esoteric concept. And it's a, it's a sort of slippery legal concept. There's four factors.
[00:34:49.680 --> 00:34:50.800]   It's hard to explain.
[00:34:50.800 --> 00:34:54.000]   Larry, Larry, let's just say fair use is the right to hire a lawyer.
[00:34:54.000 --> 00:34:55.760]   Yeah. It's a defense.
[00:34:55.760 --> 00:35:00.800]   You can't just say this is fair use. And that is, and it's up to a court, etc. But the principle,
[00:35:00.800 --> 00:35:08.960]   like, think of all the artistic creations, you know, entire genres of music, like hip hop and
[00:35:08.960 --> 00:35:17.280]   rap that have been created using samples from other media. That kind of thing would effectively be
[00:35:17.280 --> 00:35:23.920]   outlawed. The ability to remix bits and pieces of media has been a huge part of media, all kinds
[00:35:23.920 --> 00:35:28.240]   of media. Although there have been many, many lawsuits by artists who've been sampled without
[00:35:28.240 --> 00:35:32.560]   permission. They're have, they're have. And I kind of understand how artists feel. What you're saying,
[00:35:32.560 --> 00:35:38.560]   though, is, okay, if you're a creator, just keep in mind, this is good for everybody.
[00:35:38.560 --> 00:35:41.360]   And to be a little less of a tight ass.
[00:35:41.360 --> 00:35:47.600]   And obviously it depends on how you do it. I mean, if you're, if your song is, you know, 90%
[00:35:47.600 --> 00:35:54.960]   someone else is a sample of someone else's song, then that seems over the top. But if you're, if you're,
[00:35:54.960 --> 00:36:02.160]   you know, girl talk or something like that, and you, you, you sample 100 different things and you
[00:36:02.160 --> 00:36:07.520]   hear tiny snippets of each. How is that not a new creation? Well, here's an interesting one of
[00:36:07.520 --> 00:36:13.520]   those example of this is weird Al Yankovich who writes parody songs. But the rules for permission.
[00:36:13.520 --> 00:36:19.600]   But he, but well, what's interesting is he doesn't have to, because their parodies provided
[00:36:19.600 --> 00:36:28.240]   he's parodizing the song, or the artist who performs or wrote the song. For instance, he couldn't take
[00:36:28.240 --> 00:36:35.440]   a Prince song and rewrite the lyrics and then make it be critical of the president.
[00:36:36.240 --> 00:36:42.320]   That wouldn't be fair use. But if he's, uses it to paradise Prince, that's fair use.
[00:36:42.320 --> 00:36:49.520]   He also weirdo asks every artist before he does a parody, which he doesn't have to do.
[00:36:49.520 --> 00:36:54.960]   That's all he doesn't have to do, but that's polite. Yeah. So like to ask, but also,
[00:36:54.960 --> 00:36:58.400]   if you're an artist and you are asked, it would be polite to give permission.
[00:36:58.400 --> 00:37:04.400]   Because this is all about creative, you know, flow and everybody, it's good for everybody if
[00:37:04.400 --> 00:37:07.600]   you allow creative flow. Otherwise, everything gets stopped up.
[00:37:07.600 --> 00:37:13.520]   Another thing to say here is that Matthew, you and I in our business is that if we were not
[00:37:13.520 --> 00:37:20.560]   copying from each other and quoting each other in news, we'd all be doomed. You as a columnist and
[00:37:20.560 --> 00:37:26.720]   critic, you spend your day quote, "stippeting others." Well, as I pointed out, that's the whole
[00:37:26.720 --> 00:37:35.200]   Twitter network. Yeah. We don't do any research. We just leech. We are leech. We do no reportage.
[00:37:35.200 --> 00:37:39.600]   I do sometimes have my own ideas, but no, I see your point. You don't know what I mean.
[00:37:39.600 --> 00:37:43.360]   No, and we have our own ideas too, but we base it all about it. And not just you, but any
[00:37:43.360 --> 00:37:47.360]   newspaper out there, any news show out commentary is. Right. Yeah.
[00:37:47.360 --> 00:37:54.480]   And I think there's to sort of take a completely, you know, copyright maximalist
[00:37:55.040 --> 00:38:01.040]   point of view, which is what this law would do, is really going to cut off a huge amount of
[00:38:01.040 --> 00:38:09.360]   creative work. I mean, will it stop pirates? Yes, but it will also stop anyone from using those
[00:38:09.360 --> 00:38:13.840]   things in a creative way. Well, and I always say this when it comes down to stuff like this,
[00:38:13.840 --> 00:38:18.800]   it doesn't really stop pirates because pirates are, by definition, criminals, and they don't care
[00:38:18.800 --> 00:38:26.480]   what the laws are. In fact, laws only stop honest people. True. Can I make a bumper sticker of that?
[00:38:26.480 --> 00:38:33.760]   Yeah. Piracy almost always is not thwarted by any of this stuff, including copy protection,
[00:38:33.760 --> 00:38:39.840]   everything else, because pirates just circumvent, blithely, and go on with their, go on, and
[00:38:39.840 --> 00:38:45.840]   it's never slowed it down. If memes are criminalized, only criminals will produce memes.
[00:38:46.880 --> 00:38:51.920]   And they'll all be on a channel. Pardon me for this Gutenbergian moment here.
[00:38:51.920 --> 00:38:58.080]   But part of the fundamental problem is that we still think in a Gutenberg notion of content,
[00:38:58.080 --> 00:39:03.920]   of an idea that we're making it something to fill a container. That's not what we're doing.
[00:39:03.920 --> 00:39:10.960]   That's not what a news organization is, we're causing much of this problems. They are in the
[00:39:10.960 --> 00:39:16.640]   service business. They're using various tools to accomplish that service. But as long as they
[00:39:16.640 --> 00:39:20.240]   think that they're just in the business of making a product called content and it's theirs and they
[00:39:20.240 --> 00:39:25.440]   own it, it's not the true value of what's there is the information inside and you cannot copyright
[00:39:25.440 --> 00:39:34.400]   information. It's the last dying gasp of the old content industry. They're trying to use
[00:39:34.400 --> 00:39:42.160]   governments. It's a pretty big gasp though. I mean, if you think of the number of content
[00:39:42.160 --> 00:39:49.600]   companies that as far as they're concerned that their product is what matters. I was just
[00:39:49.600 --> 00:39:54.320]   ranting about this is sort of unrelated or tangentially related, but I was ranting about
[00:39:54.320 --> 00:40:00.240]   a piece I read at a respectable publication that I won't name because lots of places do it.
[00:40:00.240 --> 00:40:08.160]   A 1200, probably 1500 word article, really smart article, referred to all this stuff and did not
[00:40:08.160 --> 00:40:16.240]   link a single time to this is on the internet did not link single time to anywhere to the things
[00:40:16.240 --> 00:40:22.640]   they were describing to anyone who had written about that thing because the idea is it's just
[00:40:22.640 --> 00:40:27.200]   like Facebook. They want to keep you on their side as much as possible and any links should
[00:40:27.200 --> 00:40:32.560]   only go to their stuff so that you will be trapped there and then hopefully maybe you'll buy something.
[00:40:32.560 --> 00:40:41.040]   I mean, that's just such a fundamentally backwards idea. Anyway, makes me mad.
[00:40:41.040 --> 00:40:45.440]   I don't know what we're going to do about it, but it's kind of up to the EU at this point, right?
[00:40:45.440 --> 00:40:51.200]   Well, one thing it says too is that the only thing I try to say to Europeans is who the hell
[00:40:51.200 --> 00:40:55.680]   is going to invest in anything related to the internet in Europe. That's interesting.
[00:40:55.680 --> 00:40:59.040]   And they constantly complain and whine that, well, we don't have our Google. Well, the way you
[00:40:59.040 --> 00:41:01.760]   get to Google is by investing in risking their risk.
[00:41:01.760 --> 00:41:05.280]   They're risk. I mean, only because it's hard on Twitter, a search engine in Europe.
[00:41:05.280 --> 00:41:08.640]   Yeah. Yeah. There's no way you're going to ask there.
[00:41:08.640 --> 00:41:14.080]   And I do think, you know, I have a lot of friends in Europe, I like Europe.
[00:41:14.080 --> 00:41:14.640]   I love Europe.
[00:41:14.640 --> 00:41:21.200]   This is not an anti Europe comment, but it feels like some of the motivation, particularly for
[00:41:21.200 --> 00:41:27.840]   actions against Google and Facebook is the feeling that they are American entities that are kind of
[00:41:27.840 --> 00:41:30.800]   stomping all over Europe and ruining everything.
[00:41:30.800 --> 00:41:35.760]   Yeah, to be clear here, I'm not saying all of Europe, you know, save your
[00:41:35.760 --> 00:41:41.760]   note at me, but I am saying powerful European publishers and politicians are ruining the net.
[00:41:41.760 --> 00:41:51.040]   And we thought that China was the entity ruining the net or that Russia was Europe's doing damage here.
[00:41:51.040 --> 00:41:54.240]   Oh, it's depressing.
[00:41:54.240 --> 00:41:55.680]   It is depressing.
[00:41:56.480 --> 00:42:02.640]   Here is a scary. Here's something to be thankful for.
[00:42:02.640 --> 00:42:07.840]   Here is a scary robot that you won't see in production.
[00:42:07.840 --> 00:42:15.120]   This is a shaft robot. Google, when Andy Rubin was still there, bought a lot of robotics companies,
[00:42:15.120 --> 00:42:19.920]   like Boston Dynamics and Shaft. They've been, they sold off Boston Dynamics. They've been trying
[00:42:19.920 --> 00:42:25.760]   to sell shaft because Google quite rightly realizes they got enough problems. They shouldn't get any
[00:42:25.760 --> 00:42:29.600]   creepier. They can't sell shafts, so they're shutting it down.
[00:42:29.600 --> 00:42:33.440]   They try some pink though. It's pink. That means it's very friendly.
[00:42:33.440 --> 00:42:37.680]   What if I can get another on, on, on, for me,
[00:42:37.680 --> 00:42:46.560]   so the business side will be shuttered. Google says it's helping staff find new roles.
[00:42:46.560 --> 00:42:54.800]   Alphabet owns shaft. Here's the DARPA grand challenge. Eight tasks
[00:42:55.520 --> 00:42:58.880]   and walking. All of this done by this robot.
[00:42:58.880 --> 00:43:05.920]   I guess though, the research, I mean, I hope it's not, you know, dead. I mean, I hope that,
[00:43:05.920 --> 00:43:07.680]   well, maybe I do. I don't know.
[00:43:07.680 --> 00:43:09.760]   See, this is, I'm going to say it. I'm going to say it.
[00:43:09.760 --> 00:43:12.080]   This is technology.
[00:43:12.080 --> 00:43:16.720]   It's silly of us. Yes, it is because every time we hear somebody say, "Oh, that's creepy.
[00:43:16.720 --> 00:43:18.560]   It's a machine." It's just a machine.
[00:43:18.560 --> 00:43:23.920]   And there is a reason you want to buy fetal robots because as in this, you know, environment,
[00:43:24.560 --> 00:43:28.160]   they're designed for humans. They're designed for bipedal navigation.
[00:43:28.160 --> 00:43:33.360]   And so if a robot's coming into rescue people, they need to be able to operate in an environment
[00:43:33.360 --> 00:43:38.960]   designed for people like go upstairs and open doors and all of that stuff. And so there's weapons,
[00:43:38.960 --> 00:43:42.720]   fire weapon. Hey, knock it off or disarm a weapon.
[00:43:42.720 --> 00:43:49.280]   The good news, hey, here's, I'll put a happy gloss on that. One would hope that if it's a robot
[00:43:49.280 --> 00:43:54.160]   firing a weapon, it's firing a weapon and another robot. Look, it can draw better circles than I can.
[00:43:54.160 --> 00:43:57.040]   Oh, my God. That's terrible. It's a terrible circle.
[00:43:57.040 --> 00:44:02.800]   It's good enough. Look, it can turn wrenches. This is the DARPA grand challenge.
[00:44:02.800 --> 00:44:09.040]   So they design these challenges for robots. And this is the shaft robot. Here, it's getting a hose.
[00:44:09.040 --> 00:44:13.360]   So that, again, is designed for a human, but it's able to get the hose and connect it.
[00:44:13.360 --> 00:44:16.240]   Can it make a nice mutton lettuce and tomato sandwich?
[00:44:16.240 --> 00:44:18.720]   Inevitably, if you could do the one, you could do the other.
[00:44:19.680 --> 00:44:25.280]   So there was a robot. There was a story about a robot, a company that got a lot of investment
[00:44:25.280 --> 00:44:30.800]   to make her to have robots make pizza. It got millions of dollars. I forgot the name of it.
[00:44:30.800 --> 00:44:34.800]   But the pizza was terrible. Oh, yes. It doesn't make the robot made it.
[00:44:34.800 --> 00:44:41.360]   You know what? A human can make terrible pizza too. That's true. It's not
[00:44:41.920 --> 00:44:51.360]   exclusively the realm of the robots. Have you played with the
[00:44:51.360 --> 00:44:57.600]   pixels? Neither of you have a Pixel 3. No, I, you know, first time, first time,
[00:44:57.600 --> 00:45:03.680]   I keep saying I'm, I don't have a phone in me. You don't, the night site, the new night site,
[00:45:03.680 --> 00:45:08.800]   the camera, the night site looks like a nice set of mine. Yeah. I haven't used it yet, but I got it.
[00:45:09.440 --> 00:45:14.480]   I have the Huawei P20 Pro, as I think that's actually a very good. Yeah. Yeah. That's a very good,
[00:45:14.480 --> 00:45:20.480]   I bet you the camera or cameras. I don't know what to make of this leak. This is a
[00:45:20.480 --> 00:45:26.800]   ledge photos of a Pixel 3 light. This might be for you, Jeff. The Sargo. I'm not light. I'm just
[00:45:26.800 --> 00:45:36.000]   satisfied. Again, from Russia. And this, this has a Snapdragon 670 and, and this intrigues me,
[00:45:36.000 --> 00:45:44.320]   a headphone jack. What? Yeah. I don't know. Did you see the rumors about Samsung's giant phone?
[00:45:44.320 --> 00:45:48.480]   Yeah. There's like 15 cameras or something. Yes, 10. I don't think it's quite that many.
[00:45:48.480 --> 00:45:52.560]   It's a lot. It was like six or something or seven. I don't know.
[00:45:52.560 --> 00:45:57.440]   It's like blades on razors. Now they're just like, what the hell is this?
[00:45:57.440 --> 00:46:04.880]   But it's 20 cameras on there. It's six cameras. Okay. It's their top secret Galaxy S phone.
[00:46:04.880 --> 00:46:11.760]   It's a 5G phone with six cameras. The problem is, and you're going to just see weirder and weirder
[00:46:11.760 --> 00:46:18.720]   stuff, phone sales are just flat. Yeah. Yeah. Yeah. And so, and Samsung and Google all are
[00:46:18.720 --> 00:46:22.800]   challenged to come up with something that makes people want to run to the market. But look at this
[00:46:22.800 --> 00:46:29.760]   guy, Jeff. I don't need any phone. I could not be more of a gadget freak and Google fanboy and all
[00:46:29.760 --> 00:46:34.800]   that. And there's nothing to guess. The problem is I'm satisfied. I'm highly satisfied with my
[00:46:34.800 --> 00:46:40.320]   Pixel 2. Yeah. It's a good phone. And I think if you look at Apple's results, same problem.
[00:46:40.320 --> 00:46:44.080]   I think you're seeing. Yeah. It's the same problem. People think their phones are fine.
[00:46:44.080 --> 00:46:47.360]   Yeah. You know what you need? You need to give away motorized shoes.
[00:46:47.360 --> 00:46:54.400]   Okay. That's the rundown. That's the rundown. Motorized shoes.
[00:46:55.120 --> 00:47:02.400]   Google applied for a patent. It's called a reality footwear for VR because it'll allow you to walk
[00:47:02.400 --> 00:47:06.960]   in place and believe you're walking through the woods even though you're not running into furniture.
[00:47:06.960 --> 00:47:11.040]   But don't they just use treadmills or fancy treadmills?
[00:47:11.040 --> 00:47:20.240]   In the movies, they actually made it because we, by the way, the guy, the guy needs to go on a diet.
[00:47:21.520 --> 00:47:24.720]   He looks exactly like somebody who plays a lot of VR looks. Yeah.
[00:47:24.720 --> 00:47:33.120]   It's funny that the guy in the, this is for a patent application. He's a little portly.
[00:47:33.120 --> 00:47:39.680]   Oh, portly. But yeah. So the idea here, I know I would fall and break my ass in these things in a
[00:47:39.680 --> 00:47:46.400]   second. Are they roller skates or just shoes that notice their shoes that are motorized so you
[00:47:46.400 --> 00:47:52.720]   walk in place, but the motor is there, I guess, so that you, because you could run versus a treadmill
[00:47:52.720 --> 00:47:57.200]   Matthew, you can go this way and that way and turn around and walk this way and so on.
[00:47:57.200 --> 00:47:59.680]   They have an omnidirectional treadmill, though.
[00:47:59.680 --> 00:48:05.520]   Really? Yeah, they do. In fact, we sent Jason Howell down to try one out. It's the same kind of
[00:48:05.520 --> 00:48:11.040]   omnidirectional treadmill that's used in the walk and then you run. But it's a big honking thing.
[00:48:11.040 --> 00:48:15.760]   And it's something, by the way, you don't see in the movie, it's noisy as hell, especially as you
[00:48:15.760 --> 00:48:24.400]   start moving. Oh, yeah. So you'd have to have, I don't know, your plugs in can fix that.
[00:48:24.400 --> 00:48:29.440]   They can fix that. They can fix anything. So, and this is just, we should point out, just a pat and
[00:48:29.440 --> 00:48:32.240]   just a pat. We don't know. We don't know. We don't know. We don't have a patent. Everything.
[00:48:32.240 --> 00:48:38.320]   Just in case. It's just a defensive move than anything else. That's an interesting idea.
[00:48:39.840 --> 00:48:47.440]   We've been waiting for our Pixel Slate. Google says they're starting to come. Oh, no, that was a
[00:48:47.440 --> 00:48:52.880]   mistake. Oh, really? Are we not coming? I don't know. Because this is puzzling because I asked Jason
[00:48:52.880 --> 00:48:58.720]   Howell who ordered one yesterday. He said, yeah, they say mine's coming today or tomorrow. But now,
[00:48:58.720 --> 00:49:05.440]   according to Android police, it turns out those notices were a mistake. Oh, man.
[00:49:07.200 --> 00:49:16.640]   Candy from the mouth of geeks. Oh, damn it. Oh, this week, some pre-order customers
[00:49:16.640 --> 00:49:21.520]   incorrectly received a note with delivery timing for their Pixel Slate.
[00:49:21.520 --> 00:49:26.720]   Corrections will be sent in the following days. Oh, man.
[00:49:26.720 --> 00:49:34.400]   You know, that's worse than the other thing Apple does, which is when you order like a new
[00:49:34.400 --> 00:49:40.640]   Apple device, you get the accessories weeks earlier and you get all excited. And it's just the case.
[00:49:40.640 --> 00:49:43.840]   That's even worse. It's on its way.
[00:49:43.840 --> 00:49:50.800]   So I don't know what's happening with the Slate. We'll have to get Kevin Tofol on when they actually
[00:49:50.800 --> 00:49:56.640]   come out. And I didn't realize this. And apparently no one else did because
[00:49:56.640 --> 00:50:04.080]   the ad age story reads, YouTube is now showing Hollywood support, ad supported Hollywood movies
[00:50:04.640 --> 00:50:12.880]   and they started doing it in October, but nobody noticed it. So you could get Terminator or
[00:50:12.880 --> 00:50:17.680]   legally blonde for free with ads inside, just like we had work television.
[00:50:17.680 --> 00:50:23.040]   It's pretty smart, actually. Yeah. I wonder how bad the ads are.
[00:50:23.040 --> 00:50:26.800]   I bet lots of people will do that. Yeah.
[00:50:26.800 --> 00:50:32.960]   Has anybody watched any movies on Google on YouTube with ads?
[00:50:32.960 --> 00:50:38.800]   Anybody in the chatroom? I wonder. I mean, does this because they chop
[00:50:38.800 --> 00:50:44.640]   a lot of movies on TV once you once once VCRs became available, widely available and now DVRs
[00:50:44.640 --> 00:50:49.600]   and on demand and streaming. It was like, why would you ever watch a movie with commercials?
[00:50:49.600 --> 00:50:57.200]   And it's just horrible. So now so that created the pop up ad that covers part of the lower
[00:50:57.200 --> 00:51:02.400]   bit of the screen or the or the bugs that sit there while the show is on.
[00:51:02.400 --> 00:51:07.840]   Yeah, don't you hate that? Okay. So here's legally blonde free.
[00:51:07.840 --> 00:51:13.280]   I'll probably classic movie. Let's recognize. Not a bad, not a bad choice.
[00:51:13.280 --> 00:51:18.160]   I'm going to log out though, because if I don't sign out, I'm already to read.
[00:51:18.160 --> 00:51:21.360]   I wouldn't get any ads anyway. So I'm going to sign out.
[00:51:21.360 --> 00:51:24.720]   Okay. You got to go to copyright poll to take down because of this.
[00:51:24.720 --> 00:51:30.640]   Probably see the chilling effect. He says, I'm not showing it.
[00:51:30.640 --> 00:51:38.080]   You better show it, buddy. Here's legally blonde with commercials. We're showing the commercials.
[00:51:38.080 --> 00:51:41.760]   Oh, let's take a take down notice once because of a commercial.
[00:51:41.760 --> 00:51:47.120]   Oh, we've gotten take down. No, but usually because of the thing that's different about
[00:51:47.120 --> 00:51:52.480]   stuff that's downloadable on YouTube is that you can turn it around right away.
[00:51:52.480 --> 00:51:57.840]   The thing that YouTube live is really sticklers. If you only get one strike,
[00:51:57.840 --> 00:52:02.400]   not three, and they take it down for weeks. So I don't see any ads in here.
[00:52:02.400 --> 00:52:07.840]   Maybe they don't have ads. Maybe they're going to have ads.
[00:52:07.840 --> 00:52:15.280]   Because if you're a hulu or something, you can't get past a certain point in the scrub.
[00:52:15.280 --> 00:52:18.000]   Right. So this is your app for commercial.
[00:52:18.000 --> 00:52:22.080]   These are all free with ads on YouTube. Rocky 4,
[00:52:22.080 --> 00:52:28.480]   zookeeper. They're not the best movies. I think legally blonde is agent Cody Banks.
[00:52:28.480 --> 00:52:31.600]   Haking Cody Banks. Are you saying that's not one of the best movies?
[00:52:31.600 --> 00:52:38.640]   One and two. Rocky 2, Rocky 3, Rocky. Rocky. That's a good movie. The Terminator, the original.
[00:52:38.640 --> 00:52:40.640]   Classic. Classic. This is sad.
[00:52:40.640 --> 00:52:46.240]   What? All dogs. These are the movies that you could get for 99 cents in the videos.
[00:52:46.240 --> 00:52:48.320]   Yeah. Yeah. Yeah. That's right. They're being a bin.
[00:52:48.320 --> 00:52:53.760]   Yeah. So this is basically like the bin at the gas station with all the CHS movies.
[00:52:53.760 --> 00:53:00.800]   So those are some quality movies. Some of the pink pants.
[00:53:00.800 --> 00:53:03.920]   It seems like it's going to be a little sad. It's kind of got probably more titles in here than
[00:53:03.920 --> 00:53:06.640]   they were. It's like an author seeing those things in a remainder bin. Yeah.
[00:53:06.640 --> 00:53:12.400]   Okay. Some of these are more recent.
[00:53:14.480 --> 00:53:19.040]   Some Wu Dang. Oh, that's good. Zero dreams of sushi.
[00:53:19.040 --> 00:53:24.000]   Is that in here? Yeah. Oh, that's a great movie. Yeah, it's going to be highly recommended.
[00:53:24.000 --> 00:53:35.440]   This is quite a few. Oh, Muthai giant. Muthai giant. Hello. Seven foot gentle giant. Barney
[00:53:35.440 --> 00:53:41.280]   Emerald is drugged and robbed while on holiday in Pataya. He befriends two Thai sisters,
[00:53:41.280 --> 00:53:45.920]   one who can speak English, another who is a Muay Thai kickboxing champion.
[00:53:45.920 --> 00:53:51.840]   He stays with him until he can recover his passport after eating some spicy some tum.
[00:53:51.840 --> 00:53:55.600]   Yeah. Classic movie. I've seen that multiple times. That's the snippet.
[00:53:55.600 --> 00:54:02.880]   It's a good movie. No, it's probably not. I have to sign in to confirm my age.
[00:54:07.600 --> 00:54:14.160]   The comments are funny. You can comment even on YouTube paid movies apparently or unpaid.
[00:54:14.160 --> 00:54:21.600]   So I have a little something I'm going to show you that just came. All right.
[00:54:21.600 --> 00:54:27.760]   We've got the privacy clip on it, but I'm going to take it off. And we'll talk about that in a
[00:54:27.760 --> 00:54:33.200]   second. You're watching this week in Google our pre Thanksgiving day festivities with Jeff Jarvis
[00:54:33.920 --> 00:54:40.960]   from CUNY and buzz machine.com Matthew Ingram from the Columbia journalism review. And oh,
[00:54:40.960 --> 00:54:47.920]   hey, what's going on with that city in Toronto? We'll be talking about that soon. Yeah, the sidewalk
[00:54:47.920 --> 00:54:56.800]   sidewalks. We'll talk about that too. The dystopia in Toronto, the smart city of surveillance.
[00:54:58.400 --> 00:55:04.240]   But this is according to the intercept. But first a word from our sponsor. If you have a business,
[00:55:04.240 --> 00:55:08.480]   you probably have corporate cards and you may have the corporate card from the bank and so
[00:55:08.480 --> 00:55:12.960]   forth. Those have been nothing but problems for us. That's why we've moved to Brexit. The first
[00:55:12.960 --> 00:55:20.480]   corporate credit card for start ups. Very easy. Five minute online application. The underwriting
[00:55:20.480 --> 00:55:27.840]   is based on your cash in your bank account. So that means Brexit can offer your company 10 to
[00:55:27.840 --> 00:55:34.080]   20 time higher limits than other corporate credit cards. And there's no personal liability. Plus
[00:55:34.080 --> 00:55:41.120]   great high value rewards tailored to modern businesses. So you get seven times the reward on
[00:55:41.120 --> 00:55:45.840]   ride share three times the points on restaurant and travel, double points on software. There's no
[00:55:45.840 --> 00:55:50.720]   limit on how many points you can earn. And points can be redeemed for statement credit on transactions.
[00:55:50.720 --> 00:55:55.760]   So that's good as cash. Exclusive offers with some of the best technology brands and services,
[00:55:55.760 --> 00:56:04.000]   Amazon Web Services, Google Salesforce, WeWork. See, Brexit is underwriting the company, not you.
[00:56:04.000 --> 00:56:09.200]   So there's no minimum operating history or painful paper application. No personal liability.
[00:56:09.200 --> 00:56:14.080]   They merely use the cash raised by your business to extend credit. That means no credit score,
[00:56:14.080 --> 00:56:20.000]   no social security number, not even a security deposit. It's a Visa card. So you can use it
[00:56:20.000 --> 00:56:26.720]   anywhere. And cards are instantly issued to employees. They get a virtual card where you can set limits
[00:56:26.720 --> 00:56:31.600]   and control spend and then physical credit cards set in the mail. I got mine the next day.
[00:56:31.600 --> 00:56:36.480]   Every employee can have a corporate card with real time limits that can be adjusted by the boss,
[00:56:36.480 --> 00:56:41.920]   the administrator. That's really nice. And one of the things I really like for as the user of the
[00:56:41.920 --> 00:56:47.520]   card. So we used it at a restaurant the other night. And I got a text immediately from Brex saying,
[00:56:47.520 --> 00:56:51.120]   Hey, we saw you just charged a meal. Take a picture of the receipt.
[00:56:51.120 --> 00:56:55.840]   What? Okay. And reply to this message. So I did. I took a picture of the receipt and
[00:56:55.840 --> 00:57:00.000]   reply to the message while I'm sitting there. I mean, we hadn't even left yet. It's matched. It says,
[00:57:00.000 --> 00:57:06.320]   is this this this transaction? Yes. And you're done. You don't have to save receipts. Just throw
[00:57:06.320 --> 00:57:12.640]   it out now. Because it's in the statement. You know in the statement exactly what you spent money on.
[00:57:12.640 --> 00:57:18.800]   It works with major accounting software programs. So it's very easy to get data from Brex into them.
[00:57:18.800 --> 00:57:24.160]   Look, you got to join the thousands of startups and tech companies who are using Brex B-R-E-X
[00:57:24.160 --> 00:57:28.800]   right now to manage their growing business needs and earn valuable rewards while they do so.
[00:57:28.800 --> 00:57:34.640]   Get the card free. And because you're listening to this show as a Twit listener,
[00:57:34.640 --> 00:57:41.840]   no fees ever forever. Card fees are waived in perpetuity. But to take advantage of that,
[00:57:41.840 --> 00:57:48.320]   you got to go to Brex B-R-E-X dot com slash Twit. B-R-E-X dot com slash Twit. We know you need a corporate
[00:57:48.320 --> 00:57:54.880]   credit card. Why not use one that works better? Brex dot com slash Twit. And we thank them for
[00:57:54.880 --> 00:58:01.840]   their support. And it's nice. I would show you, but I don't want you. It's a nice black card.
[00:58:01.840 --> 00:58:08.800]   It's nice. I like using it. The smart city of surveillance. I don't know. This is the intercept.
[00:58:08.800 --> 00:58:15.760]   Sometimes I have to bite my tongue. It's Keysight in Toronto, which is a big kind of...
[00:58:15.760 --> 00:58:20.800]   Are you familiar with it? Matthew? It's a big warehouse district right now.
[00:58:20.800 --> 00:58:28.160]   That's being complimentary. It's really a lot of nothing.
[00:58:28.160 --> 00:58:37.360]   So it's what used to be the old sort of port or part of it when there was a big sugar terminal
[00:58:37.360 --> 00:58:43.680]   there. Now there's condos. But there's still a lot of land that is just nothing empty.
[00:58:43.680 --> 00:58:51.360]   Buildings, parking lots, weed, infested things. Yeah. It doesn't look great. So it's a joint
[00:58:51.360 --> 00:58:55.200]   effort from the Canadian government agency Waterfront Toronto and Google's
[00:58:55.200 --> 00:59:02.080]   Sidewalk Labs. They want to take 12 acres. The intercept says of the valuable waterfront,
[00:59:02.080 --> 00:59:06.720]   just southeast of downtown Toronto. I guess it's not that valuable. Not as valuable as it used to be.
[00:59:07.600 --> 00:59:12.480]   And they're pitching Keysight as a solution to everything from traffic congestion and
[00:59:12.480 --> 00:59:17.680]   rising housing prices. Again, I'm reading the intercept to environmental pollution. The proposal
[00:59:17.680 --> 00:59:22.640]   for Keysight... I'm saying it right. Keysight, right? Keysight, yeah. It's spelled quayside, but
[00:59:22.640 --> 00:59:30.640]   as I learned quickly. Yeah, it's key like the British... The natives call it Keysight. It includes
[00:59:30.640 --> 00:59:37.360]   a centralized identity management system through which "each resident accesses public services."
[00:59:37.360 --> 00:59:42.080]   Such as library cards and healthcare. Super helpful. Yeah.
[00:59:42.080 --> 00:59:42.480]   Yep.
[00:59:42.480 --> 00:59:51.280]   The driverless cars, mixed-use spaces that change according to market demand, heated streets.
[00:59:51.280 --> 00:59:54.480]   In Toronto, you need heated streets. Yeah, I'm in favor of that.
[00:59:55.280 --> 01:00:01.760]   Sensor-enabled waste separation. That's of garbage, not of people.
[01:00:01.760 --> 01:00:11.280]   Well, it depends. You're a wasteoid. Go there. The algorithm determines who survives and who
[01:00:11.280 --> 01:00:17.040]   doesn't. The idea is it's a laboratory for some of these concepts. And people don't...
[01:00:17.040 --> 01:00:17.520]   Right.
[01:00:17.520 --> 01:00:21.040]   They volunteer to live there, right? Yeah. Eoretically.
[01:00:23.760 --> 01:00:26.240]   I mean... You will live there.
[01:00:26.240 --> 01:00:27.200]   Yeah. What do you mean?
[01:00:27.200 --> 01:00:29.200]   I don't think it's being required. Nobody's...
[01:00:29.200 --> 01:00:39.200]   But the big issue is sort of how much control Google per se will have over, say, personal data.
[01:00:39.200 --> 01:00:47.120]   There's... And intellectual property that comes out of it. It's supposed to be a partnership.
[01:00:48.160 --> 01:00:54.560]   So there's this sort of creepy Google aspect and the centralized information databases aspect.
[01:00:54.560 --> 01:01:00.560]   But there's also a sort of functional question about how much the city is sort of turning over
[01:01:00.560 --> 01:01:05.920]   to Google to say, "Do whatever you want. Build whatever you want. We don't care. Take the data and do
[01:01:05.920 --> 01:01:14.320]   whatever you want." So the issue is how much control there is on what Google does and doesn't do.
[01:01:14.880 --> 01:01:20.560]   This is kind of in a microcosm what's going on in general, which is that the tech bros think
[01:01:20.560 --> 01:01:25.600]   they've got a solution for every problem. And if you just... If government would just get it,
[01:01:25.600 --> 01:01:31.520]   Larry Page practically said it at Google I/O, just give us an island. Let us, you know,
[01:01:31.520 --> 01:01:34.240]   get out of the way and let us solve the world's problems.
[01:01:34.240 --> 01:01:37.520]   And I think there are a couple of new mearers.
[01:01:37.520 --> 01:01:44.160]   There is a libertarian streak in Silicon Valley that government just slows things down,
[01:01:44.160 --> 01:01:47.600]   doesn't help the less government the better, and that corporations,
[01:01:47.600 --> 01:01:54.240]   it's kind of Adam Smith's hand of the market.
[01:01:54.240 --> 01:01:57.920]   This is an anti-government though. This is a pro-service.
[01:01:57.920 --> 01:02:06.240]   I think it is a little anti-government. So I agree that the sort of perspective is government is slow.
[01:02:06.240 --> 01:02:11.520]   Government doesn't have enough information to make the right decisions. We have lots of information.
[01:02:11.520 --> 01:02:14.800]   Government always is talking about this privacy stuff.
[01:02:14.800 --> 01:02:20.160]   So if you give us all your information, we'll be able to make better decisions about when
[01:02:20.160 --> 01:02:26.000]   to get your garbage, how to separate it, how to offer you services. I mean, there's obviously
[01:02:26.000 --> 01:02:29.760]   huge benefits. I would buy an apartment there in a flash.
[01:02:29.760 --> 01:02:34.640]   I mean, again, I have a Chromebook.
[01:02:34.640 --> 01:02:38.480]   I have a Huawei P20 Pro, so I know that all my data...
[01:02:38.480 --> 01:02:39.520]   You're giving China that information.
[01:02:39.520 --> 01:02:42.640]   All my data is back up in Beijing, and that's fine with me.
[01:02:42.640 --> 01:02:47.440]   This is where the controversy gets a little hotter. Anna Kavukian, who is
[01:02:47.440 --> 01:02:55.360]   Ontario's former privacy commissioner, was on the project and she resigned. She was brought on,
[01:02:55.360 --> 01:03:00.560]   according to the Intercept, by Sidewalk Toronto, as a consultant to help institute a proactive
[01:03:00.560 --> 01:03:05.120]   privacy by design framework. She was initially told that all data collected from residents
[01:03:05.120 --> 01:03:10.400]   would be deleted and rendered unidentifiable, but she resigned when she learned that third
[01:03:10.400 --> 01:03:14.400]   parties would be able to access identifiable information gathered at Keysight.
[01:03:14.400 --> 01:03:22.000]   I imagined us creating a smart city of privacy as opposed to a smart city of surveillance.
[01:03:22.000 --> 01:03:29.520]   And she resigned. Google Sidewalk Labs says, "Well, no, we are committed to the principles of privacy
[01:03:29.520 --> 01:03:37.680]   by design. However, the question of whether other companies involved in the Keysight project
[01:03:37.680 --> 01:03:42.640]   would be required to be private as well is unlikely to be worked out soon and may be out of our hands."
[01:03:42.640 --> 01:03:49.200]   I mean, let's be reasonable. There's no way Google would do any of this stuff
[01:03:49.200 --> 01:03:54.080]   if they had to delete all the data immediately and not use it in any way.
[01:03:54.080 --> 01:03:56.720]   Like, that just doesn't make any sense. That's the whole point.
[01:03:56.720 --> 01:03:58.000]   Wouldn't enable services.
[01:03:58.640 --> 01:04:04.960]   Right. But also, you know, I mean, some of the value to Google, there's the philanthropic value
[01:04:04.960 --> 01:04:09.840]   of creating a better city using technology. But there's also, for instance, imagine that they would,
[01:04:09.840 --> 01:04:16.160]   Waymo would put cars there and it would be a great test bed to see what what urban
[01:04:16.160 --> 01:04:21.200]   environment. Right. So, by the way, wouldn't you want to live here? I want to live here.
[01:04:21.200 --> 01:04:25.440]   This looks beautiful. But I don't think they could do the things they're talking about
[01:04:25.440 --> 01:04:29.040]   without a certain amount of personal data. The big issue.
[01:04:29.040 --> 01:04:34.160]   The biggest. It's not about the data. It's about the transparency permission.
[01:04:34.160 --> 01:04:38.160]   Uber has our personal information. My gas company has personal information.
[01:04:38.160 --> 01:04:40.160]   My phone has more than anything. Yeah.
[01:04:40.160 --> 01:04:45.840]   But so, the big issue, as with all of those things, is how much and when and under what
[01:04:45.840 --> 01:04:50.640]   circumstances and what are they allowed to do with it and who are they allowed to give it to
[01:04:50.640 --> 01:04:54.480]   and how much transparency do you have over what they do with it?
[01:04:54.480 --> 01:05:02.480]   What if, what if, see, I, what, what if you're like me and Jeff and you don't really give it damn?
[01:05:02.480 --> 01:05:08.720]   And but in return for giving up our privacy, we feel like we get something of real value.
[01:05:08.720 --> 01:05:13.600]   We get to live in this beautiful place and this utopia where the kids can run in the street
[01:05:13.600 --> 01:05:17.760]   because cars don't hit them and I can bicycle and there's, you know, there's no distinction.
[01:05:17.760 --> 01:05:22.000]   It looks like here between sidewalk. You can fry an egg on the sidewalk in December because
[01:05:22.000 --> 01:05:27.360]   it's heated. It's a heated street. So there's no snow removal. There's, I mean,
[01:05:27.360 --> 01:05:32.160]   I would live there even if somebody knew all about my toilet habits. Who cares?
[01:05:32.160 --> 01:05:39.600]   And I think there's a fair trade. Is there a company you would not trust to run that?
[01:05:39.600 --> 01:05:43.520]   Would you live in Uberville? You know, I wouldn't trust is the government.
[01:05:43.520 --> 01:05:47.200]   Oh, libertarian. Yes, you, California. Yeah.
[01:05:47.200 --> 01:05:52.800]   I wouldn't trust the government with it because they have, they can do bad things to me.
[01:05:52.800 --> 01:05:56.960]   They have guns and prisons. And to be fair, to be fair, they have all your information as well.
[01:05:56.960 --> 01:05:59.200]   And they already have it. And really that's a real concern.
[01:05:59.200 --> 01:06:02.160]   They often do do bad things with it and give it to people and sell it.
[01:06:02.160 --> 01:06:05.520]   That's the real concern is that Google will gather it all and then the government will come and get it.
[01:06:05.520 --> 01:06:13.840]   That is one risk for sure. I mean, to me, it's everybody, I think, well, with a few exceptions
[01:06:13.840 --> 01:06:18.880]   and they live in cabins in the woods somewhere with a few exceptions,
[01:06:18.880 --> 01:06:23.520]   I think everybody would be willing to make a trade that involves them giving up some personal
[01:06:23.520 --> 01:06:29.920]   information. People do already for Gmail or Facebook or lots of free services. But the question is
[01:06:29.920 --> 01:06:36.480]   kind of where on the continuum of we own all your information or get access to all your information,
[01:06:36.480 --> 01:06:40.880]   is this going to be? I'm just saying it should be, I should be allowed to make that choice. I,
[01:06:40.880 --> 01:06:44.320]   of course, if somebody doesn't want to do that, they shouldn't live in Hooverville.
[01:06:44.320 --> 01:06:50.000]   But everybody else, what was I was talking about in the weekend about celebration,
[01:06:50.000 --> 01:06:54.480]   the Disney built city in Florida. If you don't want it, don't live there.
[01:06:54.480 --> 01:06:59.280]   Disney, I do not want to have my information. There's your limit.
[01:06:59.280 --> 01:07:05.600]   Yeah. Disney is, I draw the line at Disney. But I, you know, this, there seems like a fair trade
[01:07:05.600 --> 01:07:08.960]   to me and I would like the choice to do it, I guess is what I'm saying.
[01:07:09.600 --> 01:07:14.800]   Yeah. And I think you should have. And the only, my only fear would be that if,
[01:07:14.800 --> 01:07:20.320]   and I think what some of the critics of this project are saying is if controls aren't put in
[01:07:20.320 --> 01:07:26.240]   place before it's built, it'll just be a kind of slippery slope town into, you know,
[01:07:26.240 --> 01:07:31.200]   the worst possible scenario. And then you will have made a decision.
[01:07:31.200 --> 01:07:33.520]   Google's doing, sorry, Matthew.
[01:07:34.160 --> 01:07:41.680]   No, go ahead. What Google sidewalk should be doing is proposing very publicly sets of
[01:07:41.680 --> 01:07:47.840]   rules for this so that they can be open discussion. And it's kind of like, well,
[01:07:47.840 --> 01:07:51.440]   I'm going to go two sides of this. It's kind of like a condo board or a co-op board, I should say.
[01:07:51.440 --> 01:07:59.120]   But I will also say this, a worst example of democracy I've ever experienced is a co-op board.
[01:07:59.120 --> 01:08:03.120]   Yeah. Right. They're terrible. That's the worst.
[01:08:03.120 --> 01:08:07.200]   Yeah. Oh, it's always so petty tyrant who's just wants some power.
[01:08:07.200 --> 01:08:12.000]   Yeah. Yeah. So I was going to say, your committee was bad.
[01:08:12.000 --> 01:08:18.640]   Yeah. Same thing. There's nothing. The smaller the issue, the bigger the fight.
[01:08:18.640 --> 01:08:26.000]   And you could argue, I think if you were defending Google, which I'm not, but I could be, is that
[01:08:26.000 --> 01:08:32.480]   governments do make lots of really dumb and expensive, and in fact, dangerous decisions.
[01:08:32.960 --> 01:08:38.560]   Because they don't have enough information. And so theoretically, at least more information
[01:08:38.560 --> 01:08:45.040]   could produce better decisions. Well, here's a company I don't fully trust. Facebook,
[01:08:45.040 --> 01:08:52.880]   20, 39 minutes ago, let's see, 5 p.m. on the day before Thanksgiving.
[01:08:52.880 --> 01:09:01.680]   Admitted that they, not only did they hire the defenders, here's the tweet from John Passatano,
[01:09:02.320 --> 01:09:06.480]   the finers, the finers. Did I see defenders? Well, they were defending Facebook.
[01:09:06.480 --> 01:09:07.760]   Same thing. Yeah. Same thing.
[01:09:07.760 --> 01:09:11.840]   Did we ask them to work on George Soros, Elliott Shrig writes? Oh, yes.
[01:09:11.840 --> 01:09:18.800]   In j, yes. So Elliott Shrig is, by the way, the fall guy for this. He is the outgoing head of
[01:09:18.800 --> 01:09:24.880]   Google P.R. He's already left. He's already left. So Google, I have Facebook. I'm sorry, not Google.
[01:09:24.880 --> 01:09:30.080]   So it's clear that Sheryl Sandberg and Mark Zuckerberg have said, great.
[01:09:30.080 --> 01:09:32.080]   Elliott's leaving anyway. Elliott.
[01:09:32.080 --> 01:09:36.560]   From under the bus. You did it, right? Did we, Elliott's writing?
[01:09:36.560 --> 01:09:40.480]   Oh, this came out as 5 p.m. Did we ask what they did it?
[01:09:40.480 --> 01:09:46.720]   Did we ask them to work on George Soros? Yes. In January 2018, investor and philanthropist George
[01:09:46.720 --> 01:09:52.960]   Soros attacked Facebook, by the way, nothing I haven't done. In a speech at Davos calling us
[01:09:52.960 --> 01:09:59.200]   a menace to society. We had almost no study about this. These are, these are Jewish executives.
[01:09:59.200 --> 01:10:03.760]   I know. I could have known better. I could have known the symbolism of going after George Soros.
[01:10:03.760 --> 01:10:08.560]   Because he's Jewish and it's an anti and many of the people. It's an anti-Semitic meme.
[01:10:08.560 --> 01:10:13.200]   It's an anti-Semitic meme. We had not heard such criticism from him before
[01:10:13.200 --> 01:10:16.320]   and wanted to determine if he had any financial motivation.
[01:10:16.320 --> 01:10:22.640]   Well, he's new. You ask. You research. The finers researched this using public information. Later,
[01:10:22.640 --> 01:10:27.760]   when the freedom from Facebook campaign emerged as a so-called grass, so-called,
[01:10:28.800 --> 01:10:34.000]   grassroots coalition, the team asked the finers to help us understand the group behind them.
[01:10:34.000 --> 01:10:40.400]   They learned that George Soros was funding several of the coalition members. They prepared
[01:10:40.400 --> 01:10:44.480]   documents and distributed those to the press to show this was not simply a spontaneous
[01:10:44.480 --> 01:10:50.960]   grassroots movement, but part of the world Jewish conspiracy. No, I added that part.
[01:10:53.360 --> 01:11:00.720]   So is this what others funding freedom from Facebook include? The CWA union,
[01:11:00.720 --> 01:11:08.800]   Jewish Voice for Peace, move on. Public citizen. So the worst people.
[01:11:08.800 --> 01:11:16.560]   Horrible, horrible liberals. It's liberals. So now what do you say, Jeff?
[01:11:16.560 --> 01:11:23.280]   I've been very upset about this. And my disclosure here, I raised money from Facebook for this.
[01:11:23.920 --> 01:11:27.040]   I'm independent of Facebook. I received money personally from Facebook for any of the platforms
[01:11:27.040 --> 01:11:35.120]   and of disclosure. They make it re I try to defend the internet and thus I defend the agents who
[01:11:35.120 --> 01:11:38.480]   were building what I think are very good and important things that enabled good things on the
[01:11:38.480 --> 01:11:43.520]   internet. I end up trying to defend Facebook, but boy, they make it hard. An example like this.
[01:11:43.520 --> 01:11:52.800]   I mean, think for two effing seconds. You don't go attacking George Soros. If you want to ask
[01:11:52.800 --> 01:11:56.960]   publicly, if you want to criticize them publicly, if you want to disagree with them publicly,
[01:11:56.960 --> 01:12:01.920]   fine, but you don't do it sub-rosa. Well, in particular, you don't do it using a group
[01:12:01.920 --> 01:12:09.920]   to finders that is known for doing this kind of hit piece. The worst and stupidest thing Facebook
[01:12:09.920 --> 01:12:16.800]   has done. And this goes back to the episode of trending and the employed people there who were
[01:12:16.800 --> 01:12:23.040]   accused of anti conservative bias, right? They go overboard. So whenever you have a Facebook event,
[01:12:23.040 --> 01:12:28.240]   whatever Zuckerberg has invited people to headquarters, they go overboard trying to invite
[01:12:28.240 --> 01:12:32.560]   an equal number or greater number of conservatives. And the problem is, as we've talked on this show
[01:12:32.560 --> 01:12:36.320]   often, as I say all the time, there's one media outlet in this country that's conservative and
[01:12:36.320 --> 01:12:39.840]   that's Fox News. And the rest is liberal. We were liberals don't admit that, but that's another
[01:12:39.840 --> 01:12:44.000]   discussion. So what happens is you can't just invite Fox News. So you invite the next one,
[01:12:44.000 --> 01:12:48.000]   the next one, the next one, before long, you have Breitbart in the room. Before long,
[01:12:48.000 --> 01:12:52.640]   you've hired the definers. Before long, you've not used your own standards to say, I don't care
[01:12:52.640 --> 01:12:56.960]   for conservative or liberal. Do I want to be associated with those people? So the paradox here
[01:12:56.960 --> 01:13:02.000]   is that by trying to be more balanced, they're making the exact same mistake we make in journalism
[01:13:02.000 --> 01:13:08.080]   with false balance. And they're putting themselves in the company of bad people.
[01:13:08.880 --> 01:13:15.920]   I think they also, to me, this is a sign of just how desperate things have become at Facebook,
[01:13:15.920 --> 01:13:23.360]   because I think they've clearly said to someone, to Elliot or to whoever, we have to do whatever we
[01:13:23.360 --> 01:13:30.240]   can. We have to hire all the usual terrible lobbying firms. We have to hire all the usual,
[01:13:30.240 --> 01:13:36.560]   you know, bad actors to do this stuff, because I think they feel that they're behind the
[01:13:36.560 --> 01:13:42.080]   April in Washington, which they are. A couple of things to note about this, one,
[01:13:42.080 --> 01:13:45.760]   that it was released at 5pm the day before Thanksgiving, which is a news hole.
[01:13:45.760 --> 01:13:54.080]   And they knew that. So they buried it. Actually, Elliot came, Elliot's the fact that he was taking
[01:13:54.080 --> 01:13:59.600]   the fall came out earlier. Yes, but this piece came out 45 minutes ago.
[01:14:01.040 --> 01:14:06.560]   Point two, I find it almost impossible to believe that Cheryl Sandberg did not know that this was
[01:14:06.560 --> 01:14:10.880]   going on. I know Elliot Shrek is going to take the fall for it. But are you telling me the chief
[01:14:10.880 --> 01:14:16.240]   operating officer had no idea? So here's the question to me. Here's the parlor game to me.
[01:14:16.240 --> 01:14:23.280]   Is who takes the next fall? Because Facebook famously has fired nobody for anything. So Elliot
[01:14:23.280 --> 01:14:27.120]   took the fall and I don't, he was on the way out. So it was easy. He was on the way out. So this
[01:14:27.120 --> 01:14:32.240]   was easy, but he took the fall for this. But the question is, does Cheryl Sandberg stay COO?
[01:14:32.240 --> 01:14:35.360]   Does Mark Zuckerberg stay chairman? He says he isn't leaving.
[01:14:35.360 --> 01:14:39.440]   Mark, it's a lot of these going to leave the company. Mark Sullivan wrote a call on yesterday,
[01:14:39.440 --> 01:14:43.360]   which I haven't even read yet, but I saw her last night in the Washington Post where she said
[01:14:43.360 --> 01:14:48.960]   that Zuckerberg should step down as chairman so that there is true oversight.
[01:14:48.960 --> 01:14:56.400]   I don't know that that's our business to say or not. Mark Zuckerberg told CNN today.
[01:14:56.400 --> 01:15:02.960]   I am not stepping down as Facebook chair. This is a lot of the criticism around the biggest
[01:15:02.960 --> 01:15:06.240]   issues has been fair, but I do think if we're going to be real, there's this bigger picture
[01:15:06.240 --> 01:15:11.200]   at Wells, Zuckerberg said, which is that we, I don't know what this means, but you'll have to
[01:15:11.200 --> 01:15:15.440]   explain it to me, which is that we have a different worldview than some of the folks
[01:15:15.440 --> 01:15:22.640]   who are covering us. I noticed that too. And it's a very strange statement. But I think what he means
[01:15:22.640 --> 01:15:30.960]   is we think connecting the world and giving everyone the ability to say things and share things is good
[01:15:30.960 --> 01:15:37.760]   and the people who cover us do not. Yeah, here's another way to put it. Matthew,
[01:15:37.760 --> 01:15:43.760]   I think you're right. And I think that when Zuckerberg, the problem is they feel constrained
[01:15:43.760 --> 01:15:48.320]   to say what they really think, which is the odd thing. When Zuckerberg said after the election,
[01:15:48.320 --> 01:15:54.960]   when he would he mocked the idea that Facebook itself changed the results of the election.
[01:15:54.960 --> 01:15:59.200]   And he had dated it back that up in terms of knowing how many people actually saw things.
[01:15:59.200 --> 01:16:04.800]   I think that he was probably right in saying that. However, in a PR sense, it was stupid as hell,
[01:16:04.800 --> 01:16:12.960]   because it was it came off as a form of arrogance and nonchalance. And so if he said what he really
[01:16:12.960 --> 01:16:19.040]   thought if his worldview is I have data and no, I think you all are overreacting. I think it's a
[01:16:19.040 --> 01:16:23.200]   small number of people doing some bad stuff and we were we were slow when we did it, right?
[01:16:23.200 --> 01:16:28.080]   But if he said that, he gets smashed. So instead, he says things like that like that in that statement,
[01:16:28.080 --> 01:16:34.000]   which nobody knows what that can means. They've got to get to a point of honesty and bluntness
[01:16:34.000 --> 01:16:39.440]   and transparency. And we're going to disagree with them sometimes at that, but then give us data,
[01:16:39.440 --> 01:16:45.360]   show us the data that you have that backs up what the impact really is.
[01:16:45.360 --> 01:16:53.280]   But it's this is it's all disturbing because it because it can what bothers me is it hurts the
[01:16:53.280 --> 01:17:01.200]   internet. He talked about Cheryl Sandberg. He said, Cheryl's a really important part of this
[01:17:01.200 --> 01:17:05.440]   company is leading a lot of the efforts for a lot of the biggest issues we have. She's been an
[01:17:05.440 --> 01:17:08.960]   important partner to me for 10 years. I'm really proud of the work we've done together.
[01:17:08.960 --> 01:17:14.560]   I hope that we work together for decades more to come. That sounds like I'm behind you 1000%.
[01:17:14.560 --> 01:17:20.160]   1000%. Somebody in the chat room and I'm trying to find the bit of the clipper. He says this says
[01:17:20.160 --> 01:17:27.360]   that he blames Jeff Bezos and the Washington Post. Maybe that's a confusion with somebody else. But
[01:17:33.680 --> 01:17:40.880]   I don't know what to say at this point. Anyway, they tried to flush it down the news hole.
[01:17:40.880 --> 01:17:46.880]   And at least here, we're talking about it.
[01:17:46.880 --> 01:17:48.880]   Did we work on this?
[01:17:48.880 --> 01:17:59.200]   And I think if you guys both read the big New York Times feature, right?
[01:17:59.200 --> 01:18:02.400]   That's what this is all, of course, what still is all coming from the last year.
[01:18:02.400 --> 01:18:08.320]   And I decided last week not to spend a lot of time on it. Jeff and I, Stacey talked about it
[01:18:08.320 --> 01:18:13.760]   before the show, but we had just come out. And so I decided not to spend a lot of time on the
[01:18:13.760 --> 01:18:19.200]   show talking about it. But we could talk about it now. One week later, the Times had, they'd say,
[01:18:19.200 --> 01:18:27.600]   50 inside sources, delay, deny and deflect how Facebook's leaders fought through crisis.
[01:18:27.600 --> 01:18:29.280]   And that's where the George Soros relevant.
[01:18:29.280 --> 01:18:34.320]   That's to me in that story, the shocking bad thing about the story was the Soros angle.
[01:18:34.320 --> 01:18:38.240]   The rest of it wasn't so much an expose to me as a TikTok, as we say in the field.
[01:18:38.240 --> 01:18:43.760]   It was stuff we pretty much already knew, but took us through the details and fleshed it out.
[01:18:43.760 --> 01:18:47.040]   But I don't think there was anything in that story that we besides the Soros thing that was
[01:18:47.040 --> 01:18:53.520]   terribly illuminating, or even in the search of an expose is it was it put it all in one place
[01:18:53.520 --> 01:18:57.360]   and you say, oh boy. And there was a lot of yelling and stuff.
[01:18:57.360 --> 01:19:02.000]   So I see, by the way, this has cost Mark personally and has cost Facebook.
[01:19:02.000 --> 01:19:09.360]   Facebook stock down 40% since July. Zuckerberg lost $17.4 billion in wealth this year.
[01:19:09.360 --> 01:19:16.480]   There is a consequence. I, you know, Mark is so wealthy, so virtually infinitely wealthy that
[01:19:16.480 --> 01:19:19.760]   that's meaningless. It's paper money, but still.
[01:19:19.760 --> 01:19:25.440]   Here's the voice that I trust in this discussion, which is Alex Stenbos.
[01:19:26.160 --> 01:19:31.760]   Yeah. And I saw him at an event last Wednesday was it was chat about its rule. We're off the
[01:19:31.760 --> 01:19:37.280]   record. So I get maybe I'm not even supposed to say I saw him, but but Alex Stenbos, the former
[01:19:37.280 --> 01:19:44.080]   chief security officer at Facebook who left who left in this, but but the New York Times,
[01:19:44.080 --> 01:19:48.800]   you know, he's been pushing back. He's been critical of Facebook. He's been saying what
[01:19:48.800 --> 01:19:54.640]   Facebook and he missed or did wrong, but he's also pushing back on this coverage in a very
[01:19:54.640 --> 01:19:59.120]   intelligent and savvy way. And so all I can say is this, I was very impressed with Alex. I was
[01:19:59.120 --> 01:20:05.040]   very impressed with his candor. And and he is pushing back on some of this coverage.
[01:20:05.040 --> 01:20:10.400]   Here's the opinion. PC Woten wrote in the Washington Post. Yes. Facebook made mistakes in 2016,
[01:20:10.400 --> 01:20:15.760]   but we weren't the only ones. Yes, he said, Sheryl Sandberg yelled at me.
[01:20:18.800 --> 01:20:29.760]   He had gone to public. Well, at least gone to the board and said he had no confidence that we've
[01:20:29.760 --> 01:20:34.560]   found everything the Russians were up to at Facebook. He didn't go public. No, well, public to the
[01:20:34.560 --> 01:20:38.960]   board. Let's put it that way. And it was quite possible things could get worse before they got
[01:20:38.960 --> 01:20:44.640]   better. Sandberg, as the Times investigation reported, felt blindsided by this and yelled at him.
[01:20:45.680 --> 01:20:51.440]   So he confirmed that detail. So the narrative around his departure, which was
[01:20:51.440 --> 01:20:56.240]   the narrative based in large part on New York Times reporting, was that
[01:20:56.240 --> 01:21:05.280]   Stamos, when Facebook came out with its own internal security report during the 2016,
[01:21:05.280 --> 01:21:14.560]   the run up to the election, that Sandberg and others put pressure on him not to say that it was
[01:21:14.560 --> 01:21:19.120]   the Russians. And in fact, the word Russian doesn't appear anywhere in the report.
[01:21:19.120 --> 01:21:26.640]   There's a kind of veiled reference to the fact that Facebook has no reason to believe that
[01:21:26.640 --> 01:21:33.120]   US intelligence isn't correct in their view, which of course was that the Russians were involved.
[01:21:33.120 --> 01:21:40.240]   But it doesn't specifically say, so he's pushed back in particular on that narrative that he had
[01:21:40.240 --> 01:21:47.520]   a fight with Cheryl, who wanted him to downplay the Russian aspect. And presumably he's free
[01:21:47.520 --> 01:21:52.720]   to speak now that he's left. He said, it's not that cotton dried. There were decisions
[01:21:52.720 --> 01:22:01.120]   made at the time about what they could reliably say, how far should they go? Obviously hindsight
[01:22:01.120 --> 01:22:07.520]   being 2020, they probably should have said Russians were involved, but it was a fluid situation.
[01:22:09.040 --> 01:22:14.320]   I think there's so many issues that happened. Russian media manipulation is one of them.
[01:22:14.320 --> 01:22:20.080]   But here's his final paragraph. Finally, US citizens must adjust to a media environment in
[01:22:20.080 --> 01:22:25.120]   which several dozen gatekeepers no longer control what's newsworthy. We've talked about this a lot.
[01:22:25.120 --> 01:22:28.960]   While the platforms that bring hundreds of new media outlets to your phone need to improve
[01:22:28.960 --> 01:22:34.480]   protections against abuse in a free society will always be vulnerable to the injection of
[01:22:34.480 --> 01:22:39.920]   narratives from the enemies of democracy, both foreign and domestic. Last line of defense will
[01:22:39.920 --> 01:22:44.720]   always be citizens who are willing to question what they see and hear, even when it means questioning
[01:22:44.720 --> 01:22:50.720]   our own beliefs. This is so, so important because it is the reality we have is that we have now an
[01:22:50.720 --> 01:22:57.040]   abundance of speech. There are not gatekeepers. This all at all, I think, is a good thing. And
[01:22:57.040 --> 01:23:02.160]   what it means is responsibility now falls to everyone for what to decide that they want to
[01:23:02.160 --> 01:23:06.560]   believe or not and have some basis to do that. And we have to feed that we in media, we,
[01:23:06.560 --> 01:23:11.360]   the former gatekeepers have to feed that in new ways. But at the end of the day,
[01:23:11.360 --> 01:23:20.320]   everyone can speak. And that's just where we are. And by the way, Alex also says frequently
[01:23:20.320 --> 01:23:24.240]   that the other problem, and I have heard this from all of the platforms,
[01:23:24.240 --> 01:23:27.440]   vehemently, and this goes not just the Trump administration. This goes very much to the
[01:23:27.440 --> 01:23:34.160]   Obama administration is that government did not share information. Government was not at the least
[01:23:34.160 --> 01:23:40.320]   bit helpful pre 2016 election. Whatever they knew, they weren't sharing and they weren't given
[01:23:40.320 --> 01:23:44.800]   any tips to the platform. As the platform often didn't know to look for Russians early enough,
[01:23:44.800 --> 01:23:51.280]   government probably did, but government was shy about this so that there is fault across many
[01:23:51.280 --> 01:23:55.440]   lines here. Let me ask both of you guys something. Do you really think that the,
[01:23:56.080 --> 01:24:00.560]   we know with what the Russians did, they, you know, created a botch of sock puppets made ads,
[01:24:00.560 --> 01:24:05.040]   they targeted different opinions, they cried, create strife. But honestly, do you really think
[01:24:05.040 --> 01:24:13.840]   that effort was a decisive factor in the 2016 election? Do you want to go first, Jeff? I don't,
[01:24:13.840 --> 01:24:20.960]   but I'm curious what you guys. Yeah, I think it was so close that it's hard to say that it didn't
[01:24:20.960 --> 01:24:26.080]   for 70,000 votes could 70,000 people have somehow indirectly been influenced by this?
[01:24:26.080 --> 01:24:33.040]   Well, if it was that close, right, but that means that's 49.9%.
[01:24:33.040 --> 01:24:39.760]   You know, I'm going to agree with you. It's it was not right. It should have been
[01:24:39.760 --> 01:24:44.560]   close to that. It would have done. And I will say again, and I'll get tweets for this and hey,
[01:24:44.560 --> 01:24:50.240]   put people, it's my fault, not Leo's. It's Fox News. Do this Fox News created the country word
[01:24:50.240 --> 01:24:57.600]   right now. And we have created by not serving half of America. We created that void in vacuum
[01:24:57.600 --> 01:25:01.360]   and liberal media, Fox News, they used it. I think you can blame CNN too, just as much.
[01:25:01.360 --> 01:25:05.440]   Yes, I think so. Because of single Trump rally. Yes. I've actually,
[01:25:05.440 --> 01:25:13.760]   I've talked to a number of people who specialize in this research in particular and ask them that
[01:25:13.760 --> 01:25:22.320]   question is, do they think that Facebook and particularly Russian trolls swung the election
[01:25:22.320 --> 01:25:32.240]   in any sense of that term? And I would say most of the ones I've spoken to don't believe that it did.
[01:25:32.240 --> 01:25:40.080]   So they, and the main reason is because research shows that content that you see online,
[01:25:40.880 --> 01:25:45.040]   whether it's ads or just regular content doesn't convince you to do anything.
[01:25:45.040 --> 01:25:50.800]   So the if you try and measure people's, I mean, look at the number of people who click on ads.
[01:25:50.800 --> 01:25:57.360]   It's the fraction of 1% that online content reinforces things that you already believe.
[01:25:57.360 --> 01:26:05.200]   And it pushes you in directions you are already going, but it doesn't change minds in that sense.
[01:26:05.200 --> 01:26:13.360]   And so did it maybe give a boost to someone a little bit? Perhaps did it kind of encourage people to
[01:26:13.360 --> 01:26:21.840]   think things even more strongly that they already thought? Yes. And the big debate in this research
[01:26:21.840 --> 01:26:29.680]   is it was a very, very close election. And so you don't have to show a huge amount of impact to sort
[01:26:29.680 --> 01:26:35.200]   of tip things over. And that's why I think there's still disagreement about sort of who's to blame.
[01:26:35.200 --> 01:26:42.480]   Can you put, can you, given that it's close, which had more influence Russians throwing out some junk
[01:26:42.480 --> 01:26:50.320]   or Comey? But the point is, if it's close, then half the nation feels that way.
[01:26:50.320 --> 01:26:56.400]   So the fact is it was close. So the other thing that, so it was maybe
[01:26:56.400 --> 01:27:02.000]   influenceable, but it wasn't influenceable because you took the vast majority of people and changed
[01:27:02.000 --> 01:27:06.160]   their minds. But the other thing that had already made up their minds by far.
[01:27:06.160 --> 01:27:11.600]   I think the other thing that may have played a role, which is incredibly, in fact, almost impossible
[01:27:11.600 --> 01:27:20.880]   to measure, is who didn't vote? And did some of this information cause people not to vote.
[01:27:20.880 --> 01:27:25.120]   That's, it's almost, you can measure people who voted, you can ask them why they voted the way they
[01:27:25.120 --> 01:27:30.800]   did. You can look at how they voted before. It's very difficult to measure the impact on people
[01:27:30.800 --> 01:27:36.960]   who didn't vote. Here's what gets me about the PR thing here. And Lord knows I'm no PR
[01:27:36.960 --> 01:27:45.200]   guy man, and I'm not exactly a politician in any way. And you might hoot at this. But handled
[01:27:45.200 --> 01:27:53.520]   properly. I believe that Facebook could have presented itself as a victim. Yes. And that's right.
[01:27:54.080 --> 01:28:01.600]   It's not unlike Tylenol, right? Where it depends on your response. It depends on how open you are.
[01:28:01.600 --> 01:28:06.000]   It depends on how much you really are the victim, how you're not a willing agent or an unwilling
[01:28:06.000 --> 01:28:10.400]   agent of bad things going on. It depends on how diligent you are. It depends on a lot of things.
[01:28:10.400 --> 01:28:11.280]   It's not just a PR.
[01:28:11.280 --> 01:28:14.240]   Slam. That was not fly at all.
[01:28:14.240 --> 01:28:21.200]   There's no way Facebook was a victim. Well, but that's where I'm not trying to justify Facebook
[01:28:21.200 --> 01:28:25.440]   here. I'm just I'm trying to give a scenario that said if this had happened five years ago,
[01:28:25.440 --> 01:28:32.320]   that's a reasonable. I think that's a reasonable view. I disagree. I disagree.
[01:28:32.320 --> 01:28:35.360]   I think they were. Matthew, I think that again, I'm not trying to justify that. I'm going to be
[01:28:35.360 --> 01:28:38.080]   careful to say this. I don't want people going to say hey, Jarvis says Facebook is a victim.
[01:28:38.080 --> 01:28:42.960]   To some extent, they are though, Matthew. They are is that they were targeted.
[01:28:42.960 --> 01:28:47.440]   And they didn't. But look, they didn't do, but they were targeted.
[01:28:47.440 --> 01:28:54.080]   But this company has hundreds of billions of dollars, has tens of thousands of smart people.
[01:28:54.080 --> 01:29:00.240]   Its business is to run that network. And according to that New York Times story,
[01:29:00.240 --> 01:29:09.040]   until midway through 2016, there was no one at Facebook whose business it was to think about
[01:29:09.040 --> 01:29:14.000]   misinformation and how that might be the platform might be used. We agree.
[01:29:14.000 --> 01:29:19.440]   There's no one. No one. No one. No one. This company is over a decade old.
[01:29:19.440 --> 01:29:25.120]   We know you and I know since we're old people, we've been online for a long time. We've watched
[01:29:25.120 --> 01:29:32.560]   IRC. We've watched web forums. We've seen the rise of 4chan. We know that when you connect
[01:29:32.560 --> 01:29:39.120]   people online and there's that sort of disinhibition effect of being online, bad things can happen.
[01:29:39.120 --> 01:29:42.480]   Facebook should have known and should have done something.
[01:29:43.040 --> 01:29:47.280]   I don't think they could have seen Russian interference the way it happened.
[01:29:47.280 --> 01:29:52.160]   I think they did. I think they should disagree. I disagree. And let's remember our government
[01:29:52.160 --> 01:29:59.680]   didn't see it either and didn't act on it as well. So I agree with you is people acting badly.
[01:29:59.680 --> 01:30:06.320]   Yes. And they all Google and Facebook both managed to deal with that when it came to
[01:30:06.320 --> 01:30:12.960]   financial motivation and spam. It's a different issue to do with psychological motivation,
[01:30:12.960 --> 01:30:16.400]   political motivation. It's harder for a whole bunch of reasons, but they didn't pay attention
[01:30:16.400 --> 01:30:22.400]   to resources to that. So you and I agree there. But I don't think it's clear how much they could
[01:30:22.400 --> 01:30:28.080]   have. I think it's so unfortunate. This information like what the Russians told
[01:30:28.080 --> 01:30:34.800]   it has been a function of international politics for 50 years. I mean, this is something that was
[01:30:34.800 --> 01:30:45.760]   invented by the US, but not the US. I think it has been in the US. In some cases, created by the US,
[01:30:45.760 --> 01:30:51.120]   this is a known phenomenon. What I'm saying is if you've created a giant platform that you're
[01:30:51.120 --> 01:30:55.360]   making tens of hundreds of billions of dollars from and you're connecting billions of people
[01:30:55.360 --> 01:31:00.000]   around the world, it's incumbent on you to think about. And one of the things I criticize both
[01:31:00.000 --> 01:31:06.400]   Google and Facebook for is not thinking about the just thinking about all the good ways in which
[01:31:06.400 --> 01:31:12.400]   your technology can help people. If you're going to build something that large, it's incumbent on
[01:31:12.400 --> 01:31:19.680]   you to think about how it could be used against people or in bad ways. And it's incumbent on you
[01:31:19.680 --> 01:31:25.680]   to try and stop that, not to continually apologize after it happens.
[01:31:26.640 --> 01:31:31.440]   We're not agreeing as much as I think you're trying to say, all I'm trying to say is,
[01:31:31.440 --> 01:31:36.240]   because I agree, they should have done more. Maybe they couldn't have seen everything you
[01:31:36.240 --> 01:31:40.960]   think they could have seen, but that's a matter of degree. They should have seen this as a responsibility,
[01:31:40.960 --> 01:31:44.160]   they should have invested more resources. We're agreeing about all of that. What I'm trying to
[01:31:44.160 --> 01:31:50.960]   say is that if they had done that, if they had devoted resources, if they had been transparent,
[01:31:50.960 --> 01:31:55.040]   if they had been collaborative, if they had done all of that, and then the Russians hit, they could
[01:31:55.040 --> 01:31:59.360]   have said, we too were a victim here. They could have.
[01:31:59.360 --> 01:32:03.280]   Because they didn't do all those things, no, you're absolutely right, it wouldn't fly,
[01:32:03.280 --> 01:32:06.320]   but they could have. That's all we're saying. That's all I'm saying.
[01:32:06.320 --> 01:32:08.400]   If they had been a completely different company. Yeah.
[01:32:08.400 --> 01:32:13.360]   And I think the United States was sitting ducks anyway, because of our division,
[01:32:13.360 --> 01:32:18.640]   it was easy to drive the wedge. Yeah. Well, there's a chicken, there's a chicken egg there, too.
[01:32:18.640 --> 01:32:21.440]   Well, we've been divided for a few years now.
[01:32:22.080 --> 01:32:26.800]   Yeah. Let's play some trumpets because it's time for the Google change law.
[01:32:26.800 --> 01:32:31.200]   The Google change the subject.
[01:32:31.200 --> 01:32:39.280]   We need trumpets for that. Hey, Carson, when you get bored of anything we're talking about,
[01:32:39.280 --> 01:32:42.720]   just play trumpet. Change the subject. Change the subject.
[01:32:42.720 --> 01:32:50.640]   New from Google, this was a little complicated. Google Assistant on iOS has been updated,
[01:32:50.640 --> 01:32:58.560]   so that you can now issue OK, Google commands on your iPhone, but you have to do it by
[01:32:58.560 --> 01:33:07.040]   calling Siri first. And so. Who's going to do that?
[01:33:07.040 --> 01:33:11.920]   I don't know. Well, the only reason you might do it is if you have smart home stuff that's only
[01:33:11.920 --> 01:33:16.000]   compatible with your Google home. I guess. Yeah. So you. I like this. You're going to say,
[01:33:16.000 --> 01:33:24.320]   Hey, S O K G. Yo Amazon. Yo. Anyway, read up the.
[01:33:24.320 --> 01:33:31.760]   Read up on it from the Virgis article where they just explain exactly how you do it. You basically,
[01:33:31.760 --> 01:33:44.000]   and I'm sorry. Everybody woke up, both my, my pixel, my pixel and my iPhone both woke up on
[01:33:44.000 --> 01:33:52.240]   that one. And Siri said, very funny, boss. I mean, not funny, but funny. And my.
[01:33:52.240 --> 01:34:03.120]   Wow. My pixel said, welcome to the waking world. Oh, OK. So there you go. The new version of
[01:34:03.120 --> 01:34:08.400]   where I was message. I know. Welcome to the waking world. It's like a matrix kind of.
[01:34:10.720 --> 01:34:16.640]   And then it says, did you sleep well? Well, I eat the blue pill. What happened? That's nice.
[01:34:16.640 --> 01:34:22.960]   Where OS version H update improves battery saver and standby. I don't know anybody who's
[01:34:22.960 --> 01:34:30.000]   still wearing watch OS, but if you are where OS I am, good. Now you can update and get better app
[01:34:30.000 --> 01:34:38.560]   switching and better battery life and a whole lot more version H. I was like, once ago. And then
[01:34:39.200 --> 01:34:43.120]   I got stymied at putting the darn little tiny pin thing with the band.
[01:34:43.120 --> 01:34:49.680]   And I have put it on. That's where Apple really did a good job because it's very easy to swap
[01:34:49.680 --> 01:34:58.400]   bands on the Apple watches. Yeah. I've got a Moto 360 and it. It dies about a little afternoon.
[01:34:58.400 --> 01:35:02.240]   So how old is that about 10 years old? Matthew? That's the nice.
[01:35:02.240 --> 01:35:06.320]   No, it's nice. I like it. Yeah, I like it. I like it. It's going through the morning.
[01:35:07.360 --> 01:35:09.920]   Yeah, I'll wait through the morning. Yeah.
[01:35:09.920 --> 01:35:15.280]   Mickey Mouse is 90th anniversary is coming up. You know what that means?
[01:35:15.280 --> 01:35:22.240]   Time for a new car copyright law. But besides that. Oh, yeah. I'm the update the copyright law.
[01:35:22.240 --> 01:35:29.120]   But besides that, you could celebrate with your Google home. There is a exhibition in New York.
[01:35:29.120 --> 01:35:37.680]   I didn't know this Mickey the true original exhibition. And it's at the 60th, 60 10th Avenue.
[01:35:37.680 --> 01:35:42.800]   I don't know what's there. Something. It's $38 though. But that's a New York,
[01:35:42.800 --> 01:35:47.760]   that in New York money, that's like a buck 50. You can get you can get a bowl or something for that.
[01:35:47.760 --> 01:35:55.360]   That is all driven by Google home. Many a special interactive experience.
[01:35:56.080 --> 01:36:00.080]   It's the last room in the exhibit. So, you know, hold on. Hold on to your hats.
[01:36:00.080 --> 01:36:08.240]   The Google mini also has a Mickey's game show. Just say, hey, goog, play Mickey's game show.
[01:36:08.240 --> 01:36:13.600]   You'll team up with Daisy Donald Goofy or Minnie to answer Mickey trivia questions.
[01:36:13.600 --> 01:36:16.400]   Think how much Disney pay Google for this?
[01:36:16.400 --> 01:36:22.560]   Otterbox. I think this is kind of fun. Otterbox has created a custom base accessory to make your
[01:36:22.560 --> 01:36:29.120]   Google home mini look like Mickey Mouse with like with his ears. And you could say,
[01:36:29.120 --> 01:36:35.840]   Google play Mickey Mouse adventure right to the ears. Talk right to the ears. Happy birthday,
[01:36:35.840 --> 01:36:44.320]   Mickey. Googles. Find my device. The next generation will now be able to look around for
[01:36:44.320 --> 01:36:49.680]   your device inside some buildings. This is what's new support for indoor maps to help you find
[01:36:49.680 --> 01:36:55.040]   your device in airports, malls or other large buildings. In other words, your house is right
[01:36:55.040 --> 01:36:59.520]   out. But any public building that's been mapped also means Google knows where you've been.
[01:36:59.520 --> 01:37:05.040]   Google knows where you are. That app is not already anyway. That'll get pushed out.
[01:37:05.040 --> 01:37:10.400]   It's not. I don't think it's out yet, but it's going to get pushed out. And there is a very special
[01:37:10.400 --> 01:37:16.720]   page mapping Thanksgiving brought to you by Google Maps and Google News Lab search trends.
[01:37:17.840 --> 01:37:24.480]   The number one search trend I'm so depressed yesterday or no today was outlet mall.
[01:37:24.480 --> 01:37:32.960]   Outlet. You cheap bastards by retail. Yeah. These are the most uniquely popular stops during
[01:37:32.960 --> 01:37:40.240]   the Thanksgiving holiday on Thanksgiving tree farm takes over from outlet mall Friday,
[01:37:40.240 --> 01:37:49.600]   scenic overlook. Just place of your side. Yeah. And then overall outlet mall,
[01:37:49.600 --> 01:37:53.280]   number one tree farm, number two, scenic overlook, number three, electronic store,
[01:37:53.280 --> 01:38:00.720]   number four, video game store, number five by state, the most uniquely popular searches
[01:38:00.720 --> 01:38:06.240]   during Thanksgiving by state. For some reason, in California, it's city courthouse.
[01:38:09.360 --> 01:38:14.640]   In New York, it's music venue. We don't have Canada on here, but I bet you it's something
[01:38:14.640 --> 01:38:20.640]   like Maine's historical landmark. Who types in music? Oh, I see it's the rest of the Pacific
[01:38:20.640 --> 01:38:24.000]   Pacific. There's a music venue. Yeah. Oh, I see. Okay. It's just there. Okay. They're all
[01:38:24.000 --> 01:38:27.520]   adding up in the music. Why is everybody looking for the courthouse in California?
[01:38:27.520 --> 01:38:33.200]   In Oregon, it's feed store. In Washington state, it's bus company.
[01:38:33.200 --> 01:38:35.040]   This makes no sense. Oh, rental.
[01:38:36.880 --> 01:38:42.720]   Again, these are most uniquely popular. So it's the, I don't know what that you can.
[01:38:42.720 --> 01:38:46.400]   Car stereo store. Wait a minute. Who has a car stereo?
[01:38:46.400 --> 01:38:51.280]   Looking for car stereo stores. Oh, the fine folks in, what is that? What state is that?
[01:38:51.280 --> 01:38:56.960]   Arizona? What? What is going on in Arizona? I can't find any place to fix my eight track.
[01:38:56.960 --> 01:39:01.520]   I need a car stereo store. Petaluma used to have one, but it's long gone.
[01:39:01.520 --> 01:39:04.400]   Yeah. I mean, that's who even, I mean, that's where their search
[01:39:04.400 --> 01:39:08.800]   works. They would exist anymore. Car stereo store. Can you put in an an an an an
[01:39:08.800 --> 01:39:12.640]   right on the money? Yeah. Put some Google into my radio.
[01:39:12.640 --> 01:39:19.120]   State government's a big search in Indiana. Car racetrack. Big search in.
[01:39:19.120 --> 01:39:21.040]   Okay. I don't believe any of this.
[01:39:21.040 --> 01:39:27.600]   In what's, I wish I knew my state's better. What state is this pink one? They're looking for
[01:39:27.600 --> 01:39:32.000]   sandwich shops. Tennessee and Ohio. Virginia is West Virginia.
[01:39:32.000 --> 01:39:36.480]   Sandwich shops. Well, that's fair. Yeah. I would go along with that.
[01:39:36.480 --> 01:39:39.360]   An American restaurant, a popular search, wherever that is.
[01:39:39.360 --> 01:39:44.800]   Arkansas. Arkansas. But state government, man, they must be having to make me go.
[01:39:44.800 --> 01:39:49.280]   Searching for the state government there, huh? But you learned, is that something that you
[01:39:49.280 --> 01:39:53.840]   learned at Harvard? You know, your state's there, Carson. You learned that at Harvard?
[01:39:53.840 --> 01:39:57.760]   You're embarrassing, huh, Leo? He's a Harvard boy. I do not know my state.
[01:39:57.760 --> 01:40:01.520]   I know he had edges. Well, you're Canadian. You're not expected to know anything inside the
[01:40:01.520 --> 01:40:08.160]   yeah. We're tested on it. Were you? Oh, yeah. You're kidding. Yeah. No. Obviously, I never was.
[01:40:08.160 --> 01:40:12.240]   You guys don't don't get tested on Canadian provinces. Yeah, we don't know. Saskatchewan. No.
[01:40:12.240 --> 01:40:18.000]   It's easy, though. Canada is like stripes. Yeah, it's very simple. Well, except Ontario,
[01:40:18.000 --> 01:40:22.160]   which is very wild. This is confusing. This is like all these little plots of land.
[01:40:22.160 --> 01:40:29.680]   I tried to explain to a guy in Amsterdam once that after driving 17 hours in a car,
[01:40:29.680 --> 01:40:35.920]   I was only halfway across the province of Ontario. Yeah. Yeah. Number one search in Nevada for
[01:40:35.920 --> 01:40:44.480]   Thanksgiving. Parking garage. Well, next to the CEO. That's important.
[01:40:44.480 --> 01:40:51.760]   In New York City today, they're searching for arts. It's arts centers, then cake shop storage
[01:40:51.760 --> 01:40:56.560]   facilities. Very popular. We're going to be searching for heat tomorrow. It's going to be
[01:40:56.560 --> 01:41:01.840]   nine degrees. Do you think I will get snow next in two weeks when we come to this the big apple?
[01:41:01.840 --> 01:41:06.960]   I don't know. I would like that. I hope not because I was trying to get out of New York last
[01:41:06.960 --> 01:41:13.040]   Thursday to go to Stockholm. No, I'm 10 hours in the airport. It was it was torture. I got out.
[01:41:13.040 --> 01:41:19.680]   Most of the flights were leaving and coming back. Yeah. It was brutal. I'm going to be
[01:41:19.680 --> 01:41:24.080]   facing the roof. However, there's a quick story here. So I met all these wonderful people. I met a
[01:41:24.080 --> 01:41:29.280]   woman who runs a thing called lemonade where she was going to Africa to help people in trauma,
[01:41:29.280 --> 01:41:33.360]   change their lives. There's a guy who runs. Oh, sorry. I'm not done. What?
[01:41:33.360 --> 01:41:41.440]   Carson hit the button. No, Carson was giving me a single enough subject. Change the subject.
[01:41:41.440 --> 01:41:48.080]   So I met a guy who was going to Africa to work on food security with people. They had to fly to
[01:41:48.080 --> 01:41:53.200]   Rwanda and walk across a border. His mother and sister lost their homes in paradise. He lost
[01:41:53.200 --> 01:41:58.720]   things in paradise yet. He's still going to Africa to help people. I met this incredibly talented
[01:41:58.720 --> 01:42:03.440]   new music cellist named Ashley Bathgate. Please, everybody look her up. She's really good.
[01:42:03.440 --> 01:42:08.160]   She played for you or? No, but I looked up the video. I looked up the videos the next day and I
[01:42:08.160 --> 01:42:12.080]   said I was in the presence of this awe-inspiring talent. I just said, oh, it's nice. You play the
[01:42:12.080 --> 01:42:19.280]   cello. So there was a silver lining to the snow crop. But oh, my lord, it was just awful. So Leo,
[01:42:19.280 --> 01:42:24.400]   you could be here for two weeks. Yeah. Actually, if I am, I'm coming to New Jersey to visit you.
[01:42:24.400 --> 01:42:29.280]   Yes, you are. Yes, you are. We had a little premature marriage like, but now you can complete
[01:42:29.280 --> 01:42:31.280]   the Google.
[01:42:31.280 --> 01:42:41.840]   Wow.
[01:42:45.280 --> 01:42:54.480]   I didn't know there was spoken word involved. That is Ashley Bathgate playing Why Women Weep.
[01:42:54.480 --> 01:43:05.200]   It's the quickest way to rejoin the ocean. Wow. That's kind of pretty. Yeah. All right, let's take a
[01:43:05.200 --> 01:43:08.800]   break and then we're going to get your picks. There's a lot more stuff to talk about, but I've
[01:43:08.800 --> 01:43:15.040]   just run out of energy and time and I've got a turkey. Actually, I got a ham to put in the
[01:43:15.040 --> 01:43:22.960]   oven. Ham takes a lot longer than turkey to cook, but it cooks more uniformly and it's all dark meat.
[01:43:22.960 --> 01:43:32.320]   No, it's the new weight meat. Well, my ham, I don't know. It's a little like a dark meat.
[01:43:32.320 --> 01:43:38.320]   It's the new white meat. It's the other one. Is it a yum? Is it a yum only bad at goal?
[01:43:38.320 --> 01:43:44.320]   I know it is not. It is a city what they call a city ham. It was corn cob smoked in a barn in Vermont.
[01:43:45.200 --> 01:43:49.520]   Okay. That sounds great. No, it's going to be delicious. What time should we come over?
[01:43:49.520 --> 01:43:55.840]   One o'clock tomorrow. All right. Should be done. You're all invited. The ham goes in the oven
[01:43:55.840 --> 01:44:01.360]   at four a.m. tomorrow. Jesus. Well, this is the June oven. We'll know when to turn on.
[01:44:01.360 --> 01:44:06.480]   No, it's not. It's a slow cook. Slow eight hour cook. And I'm
[01:44:06.480 --> 01:44:12.320]   I couldn't the June do it because it's too big. It won't fit. It's a 16 pound ham.
[01:44:12.880 --> 01:44:17.040]   Whoa, that's an entire pig. Yeah. Does it have the apple on his mouth? Geez.
[01:44:17.040 --> 01:44:20.960]   Oh, it's just it's just it's actually like it's like one buttock.
[01:44:20.960 --> 01:44:25.280]   Wow. It's a large must have been a large pig, but it's well.
[01:44:25.280 --> 01:44:32.240]   Commercial hogs are the size of a VW box. Yeah. The I'm going to brine it in apple cider
[01:44:32.240 --> 01:44:38.480]   as soon as I get home. Oh, man, I'm getting hungry. Yeah. And then I got got a lasagna I made on
[01:44:38.480 --> 01:44:42.880]   Monday. I made lasagnas. I made a red one with red sauce and a green one with pesto.
[01:44:42.880 --> 01:44:50.240]   For the FedEx me some ham? Yeah, I will have enough to fit. Because I was planning for 16.
[01:44:50.240 --> 01:44:54.080]   Because I don't know why I thought there'd be 16. I think it's gonna be like five people.
[01:44:54.080 --> 01:45:00.880]   Perfect. Put some in a backpack. A little less popular. These days are we Leo?
[01:45:00.880 --> 01:45:05.120]   FedEx. I thought there'd be a lot more people coming. This happened last time I cooked for
[01:45:05.120 --> 01:45:12.720]   Thanksgiving. I overdid it a little bit. Our show today brought to you by Rocket Mortgage home
[01:45:12.720 --> 01:45:17.760]   for the holidays. Right? It's nice. If you're looking for a new home, you know, it's a really
[01:45:17.760 --> 01:45:21.520]   important purchase. This is where you and your family will be enjoying the holiday Thanksgiving
[01:45:21.520 --> 01:45:28.320]   and Christmas and you know, you'll be gathering around the hearth for family meals. It's a big
[01:45:28.320 --> 01:45:32.320]   deal. You're buying your home. It's also a big purchase. Right? It's the biggest check you'll ever
[01:45:32.320 --> 01:45:35.040]   write. I'm not talking about for the house. Just the down payment alone.
[01:45:35.040 --> 01:45:39.920]   So it's kind of nervous making when you're buying a house. You got to find the right place.
[01:45:39.920 --> 01:45:45.680]   And you're going to need a loan. So can I recommend the best lender in the country?
[01:45:45.680 --> 01:45:51.280]   The number one lender in the country. Quick and loans. Now, nine years in a row since 2010,
[01:45:51.280 --> 01:45:56.160]   number one in customer satisfaction, according to JD Power for mortgage origination.
[01:45:56.160 --> 01:46:01.200]   The last five years for mortgage approval. That's a lot of number one awards there.
[01:46:01.200 --> 01:46:07.280]   Also number one in volume since December, beating out the big bank. It's because the customer comes
[01:46:07.280 --> 01:46:12.080]   first at quick and loans. For instance, Rocket Mortgage. This is the entirely online mortgage
[01:46:12.080 --> 01:46:17.600]   approval process they created for us geeks. So we could do everything we need to do to get a
[01:46:17.600 --> 01:46:22.640]   home loan on our phone or our tablet or our desktop. Phone's perfect. You go out to an open house
[01:46:22.640 --> 01:46:28.000]   say, let's get this fire up rocket mortgage dot com slash twig. Please use that. That way we get
[01:46:28.000 --> 01:46:34.800]   credit rocket mortgage dot com slash twig. And you'll begin the three step power buying process.
[01:46:34.800 --> 01:46:42.000]   Step one. No, no 20 page, you know, application notes trip to the bank. You just answer a few
[01:46:42.000 --> 01:46:46.720]   simple questions. They'll run a credit check and give you pre-qualified approval. Boom,
[01:46:46.720 --> 01:46:52.800]   that's it. They'll you get to choose the term of your loan, the rate, the the down payment. And by
[01:46:52.800 --> 01:46:57.760]   the way, they have very good rates, very competitive rates, a variety of different loan products.
[01:46:57.760 --> 01:47:02.560]   You pick the one you want, then step two without any intervention on your part in most cases,
[01:47:02.560 --> 01:47:08.560]   they will verify your income assets and credit. And they do this in less than 24 hours to give
[01:47:08.560 --> 01:47:15.760]   you verified approval. Now you've got a letter you are you are basically a cash buyer. You go
[01:47:15.760 --> 01:47:19.280]   right to the front of the line, you got a letter you could show the seller or your realtor
[01:47:19.280 --> 01:47:24.800]   that says you've got verified approval. That is a great, great thing to have. That's power.
[01:47:25.520 --> 01:47:29.680]   Step three kicks in. Once you're verified, you qualify for their all new exclusive rate shield
[01:47:29.680 --> 01:47:33.920]   approval. They lock the rate. Now this is a big deal. Rates are going up. I don't know why it's
[01:47:33.920 --> 01:47:38.240]   going on in Canada, but in the United States rates are going on. And that means it's a little scary
[01:47:38.240 --> 01:47:41.520]   when you're out there buying because there's pressure like we got to buy this house before the
[01:47:41.520 --> 01:47:46.640]   rates go up. It's going to cost us more. Not with rate shield approval. Quick and loans will lock
[01:47:46.640 --> 01:47:52.800]   your rate for up to 90 days while you shop up to three months. The rates can go up, but yours won't.
[01:47:53.440 --> 01:48:00.240]   Actually, if the rates drop, yours will drop, but either way you win. That's exactly what you'd
[01:48:00.240 --> 01:48:06.560]   expect from America's best mortgage lender. Get started at rocketmortgage.com/twig.
[01:48:06.560 --> 01:48:11.200]   Rate shield approval is only valid on certain 30-year purchase transactions. Additional
[01:48:11.200 --> 01:48:15.680]   conditions or exclusions may apply based on quick and loans data in comparison to public data
[01:48:15.680 --> 01:48:21.120]   records, equal housing, lender license, all 50 states, and MLS consumeraccess.org number 30,
[01:48:21.120 --> 01:48:27.280]   rocketmortgage.com/twig. Get a nice new home for the holidays.
[01:48:27.280 --> 01:48:34.240]   All right. I'm going to show you my pick of the week. I'll start. Oh, no, that's impolite.
[01:48:34.240 --> 01:48:40.320]   Let me let you. I'll do mine last. I'll let you start, Matthew Ingram, because you are a guest.
[01:48:40.320 --> 01:48:48.880]   Thank you. This is actually from the rundown, but we didn't get to it. I just thought it was
[01:48:48.880 --> 01:48:58.400]   fascinating. Airbnb is going to let you stay with Mongolian tribespeople if you want to.
[01:48:58.400 --> 01:49:03.920]   But they don't have a street address. How are you going to find them, Matthew?
[01:49:03.920 --> 01:49:08.000]   But you would use what three words?
[01:49:08.000 --> 01:49:11.120]   Which we've talked about in the show, what three words. Yeah.
[01:49:11.120 --> 01:49:15.920]   So here's a real use of it. Yeah, which is fascinating. Sort of the way that they
[01:49:16.560 --> 01:49:22.000]   use a unique combination of words for places that don't have a location. Obviously, if you're
[01:49:22.000 --> 01:49:28.000]   sleeping in a tent in the forest, on the steps or whatever, in Mongolia, you're probably not
[01:49:28.000 --> 01:49:31.200]   going to have a street address. I just think it's a firecaving.
[01:49:31.200 --> 01:49:37.040]   We need for your cabin, right, Matthew? Yeah. We actually have a 911 address. We had to get one
[01:49:37.040 --> 01:49:42.560]   so they could find you and give you CPR or whatever. But before that, it was just
[01:49:43.440 --> 01:49:48.240]   third house on the left. So I thought this would be fascinating to go and live with
[01:49:48.240 --> 01:49:56.960]   Mongolian reindeer herders. You get to milk the reindeer. You get to sleep in a tent in the woods.
[01:49:56.960 --> 01:50:02.800]   Sounds fascinating. And because they're nomadic, there are three words get updated.
[01:50:02.800 --> 01:50:09.040]   Yeah. They use the service in a major city, I guess, that updates it whenever they move.
[01:50:09.040 --> 01:50:15.200]   Isn't that hysterical? So if you go to the what three words map,
[01:50:15.200 --> 01:50:26.480]   here, I'll put it in right now for the Mongolian herders. The three words are evaluate video nails.
[01:50:26.480 --> 01:50:34.640]   So let me enter. By the way, what was that? We just, I just, hey, I asked, I sent away for my
[01:50:35.040 --> 01:50:41.520]   address. I never got that. Maybe sent away for I thought you just, they were giving you free
[01:50:41.520 --> 01:50:48.000]   plaques with your address on it. I sent a, oh, wow. You can't get there from here. There is no
[01:50:48.000 --> 01:50:55.440]   evaluate video nails. Maybe that was just a equivalent of 555-1234. It may have changed.
[01:50:55.440 --> 01:51:00.320]   Yeah, that's that's a fake one. Oh, that's cool. That's so cool.
[01:51:00.320 --> 01:51:06.880]   Two words you can now, but really do you want to live in a tent with nomadic Mongolian? Yeah.
[01:51:06.880 --> 01:51:11.120]   Rain deer horser. That's going to be fascinating. Those are your types.
[01:51:11.120 --> 01:51:18.160]   It looks like a teepee. Well, what's the difference? What is a yurt? Oh, you're so much nicer than
[01:51:18.160 --> 01:51:22.160]   it's. I know what's the definition of a yurt. It's technically a yurt is circular. Circular.
[01:51:22.160 --> 01:51:29.040]   Oh, that's true. That's true. That's good. Okay. Here's it. This is my yurt. That's a yurt.
[01:51:29.040 --> 01:51:35.280]   That would be nice. That's the sort of your palace. That's it. That's a yuppy yurt.
[01:51:35.280 --> 01:51:41.920]   I will get you a more. This is a big thing. This is a bougie.
[01:51:41.920 --> 01:51:47.520]   Out your way it is. Yeah. But I actually wanted it. Not in the normal world. I'm not allowed
[01:51:47.520 --> 01:51:51.680]   because I'm in farm country to build any more on my property because I'm within a hundred feet
[01:51:51.680 --> 01:51:55.200]   of a farm. Yeah, you can't build within a hundred feet of a farm. It's some weird law.
[01:51:56.000 --> 01:52:01.840]   But this is a temporary building. Yeah, if it's movable, I bet you could build.
[01:52:01.840 --> 01:52:06.320]   That's exactly right. It's like a tent, except it's not. It's a yurt.
[01:52:06.320 --> 01:52:13.120]   So all you have to do is build it on stringers and then they can pick it up and put it on a truck.
[01:52:13.120 --> 01:52:18.880]   Yeah. See? It's a little wooden platform. Nice. Yeah. As some yurt.
[01:52:20.160 --> 01:52:28.800]   What is your number of the week, JJ? So I think I'll do the wire cutter Black Friday page,
[01:52:28.800 --> 01:52:34.960]   which is constantly being updated even as prices go up and down. Okay. So it's a useful little tool
[01:52:34.960 --> 01:52:40.800]   here to find if you're a cheap bastard, you can find bargains for your loved ones on Black Friday.
[01:52:40.800 --> 01:52:45.920]   It's funny. I mean, it's changing and adding all the time. These companies like wire cutter and
[01:52:45.920 --> 01:52:54.560]   Thrillist and others basically treat this like an invasion. They've got the desk and they've got
[01:52:54.560 --> 01:53:01.200]   people at tables and they've got a war room and it's crazy. But what's good about the wire cutter
[01:53:01.200 --> 01:53:05.920]   is they tell you if it's actually a deal because it's too bad. They tell you whether it's any good
[01:53:05.920 --> 01:53:11.200]   or not. And is it really a deal? Yeah. A huge proportion. So the fossil to Android smartwatch
[01:53:11.200 --> 01:53:16.080]   normally 200 is 150. 150. Nice. Which is a good deal. It's a 3G. That was a good deal.
[01:53:16.080 --> 01:53:20.160]   But it's a good, but that would be past Matthews minus 1G.
[01:53:20.160 --> 01:53:29.440]   You get no G's on yours, Matthew. So, so, so I was looking at this and I saw bike helmets on
[01:53:29.440 --> 01:53:34.640]   there and it reminded me of what I saw in Stockholm. Have you heard? This is not a number, but screw
[01:53:34.640 --> 01:53:40.000]   it. Have you heard of the hoo-ding? Of course. Everybody's heard of the hoo-ding.
[01:53:40.000 --> 01:53:45.600]   The hoo-ding? How do you say the hoo-ding? The hoo-ding is an airbag like sounds.
[01:53:45.600 --> 01:53:53.360]   Oh, and it's a dark. It inflates. Well, so, yeah, so it's not, it doesn't inflate normally. It only
[01:53:53.360 --> 01:54:03.040]   inflates if you fall. And it's got helium and it's charged. Isn't that phenomenal?
[01:54:03.040 --> 01:54:08.000]   Yeah. You have to wear kind of a scarf thing. You wear the scarfy thing, right? So I met with
[01:54:08.000 --> 01:54:11.680]   it with a media executive and she, she bicycled, because of course it's Sweden, to the, to the
[01:54:11.680 --> 01:54:16.640]   hotel for breakfast. And she, she was wearing the hoo-ding. Oh, so everybody in Sweden wears a
[01:54:16.640 --> 01:54:21.600]   hoo-ding. They wear the hoo-ding. Pretty much. I can't remember. There's another video,
[01:54:21.600 --> 01:54:26.000]   there's another video on that that shows it inflating from, from ground up. I could wear
[01:54:26.000 --> 01:54:31.120]   a great idea. I think it's a wonderful idea. I want one. I could just wear it like that.
[01:54:31.120 --> 01:54:35.600]   But is it? I thought that's what I thought I was going to expect her to wear that all the time.
[01:54:36.640 --> 01:54:43.520]   Here is, here is Willett Pop, hoof-ding 2.0. Isn't that amazing? Wow.
[01:54:43.520 --> 01:54:48.800]   I went just like to wear that periodically trigger it as I was walking down the street.
[01:54:48.800 --> 01:54:52.240]   Willett Pop, this is a new hoof-ding game.
[01:54:52.240 --> 01:54:58.800]   Oh, curves with the thing.
[01:55:00.000 --> 01:55:04.320]   Is he going to just throw himself on the ground? I guess so. Like watch.
[01:55:04.320 --> 01:55:11.920]   Nope. Oh, the fear is that you go over a curb and you trigger the hoof-ding.
[01:55:11.920 --> 01:55:15.920]   No, no, doesn't trigger it. It's fine. So that's, I think,
[01:55:15.920 --> 01:55:19.760]   driving into a building. False triggers of a hoof-ding might be a problem.
[01:55:19.760 --> 01:55:23.600]   Oh, okay. So is he going to do this? Oh, no. Oh, oh.
[01:55:23.600 --> 01:55:30.560]   But he's just going over big chunks of cement now. It's quite the retro looking bike.
[01:55:30.560 --> 01:55:38.080]   I like it. They use stunt people to simulate hoof-ding. Yes. Hopping.
[01:55:38.080 --> 01:55:44.480]   Okay. I just thought I would share that. But you're right, Leo. I wish we were constantly inflated
[01:55:44.480 --> 01:55:48.000]   all the time. I would love to ride around New York City with a inflated hoof-ding.
[01:55:52.720 --> 01:55:58.880]   Is he a few word and you know how that word in New York? I think that's the woman who was in the
[01:55:58.880 --> 01:56:07.360]   first. Isn't it? What's her name? She's great. She was also in California. She's a sweet. I love
[01:56:07.360 --> 01:56:12.400]   this. I could just watch this all day. I know. If you were in New York, someone would try to
[01:56:12.400 --> 01:56:17.040]   punch you to trigger it. Punch me in the hoof-ding, will you? It's like 300 euros.
[01:56:18.000 --> 01:56:24.480]   What? Okay. It's like 300 euros. Once it inflates, you can't fix it. Right. So it's a one-shot hoof-ding.
[01:56:24.480 --> 01:56:29.920]   I got it. Well, of course it has a black box on it. So they ask you to send in the black box.
[01:56:29.920 --> 01:56:32.960]   If it inflates, it's less appealing. Oh, well, it did. Yes.
[01:56:32.960 --> 01:56:39.040]   The hoof-ding. Invented by, I think she said two young Swedish women who have this idea
[01:56:39.040 --> 01:56:45.760]   for the hoof-ding. I kind of want one. I have a Bluetooth enabled helmet with lights that lights
[01:56:45.760 --> 01:56:51.040]   up. It'll answer my phone. I can listen to books. It's got links. It's got all sorts of stuff.
[01:56:51.040 --> 01:56:58.640]   Because I got for myself and Lisa for the holidays, I got electric bikes because I'm now an e-bike
[01:56:58.640 --> 01:57:06.560]   fanatic. I love my e-bikes. So does it just help you or does it do it? Well, it's pedal assist,
[01:57:06.560 --> 01:57:10.560]   which means you have to pedal for it to do anything, but you don't have to pedal hard.
[01:57:12.000 --> 01:57:16.240]   You just kind of go like this and you're going 20 miles an hour of hell. It's like,
[01:57:16.240 --> 01:57:23.360]   do you adjust the aid? Yeah, there's five steps. So step one is kind of most like bicycling with
[01:57:23.360 --> 01:57:29.680]   a little help. Kind of what you think a e-bike is. Step five, you start to pedal and you go,
[01:57:29.680 --> 01:57:37.920]   so fun. But in America, I don't know what the rules are in Canada, but in America, you know,
[01:57:37.920 --> 01:57:42.320]   go 20 miles an hour on this thing where it's no longer a bicycle. It's a scooter,
[01:57:42.320 --> 01:57:49.360]   your moped or something. So 20 miles an hour. No, no, it's a well, yeah, it gets more complicated.
[01:57:49.360 --> 01:57:54.160]   For a scooter, you do. Yeah. So if so 20, but people hack these all the time, but you don't want
[01:57:54.160 --> 01:58:01.200]   to go 30 miles an hour on a bicycle. That's just dangerous. Sure you do. Well, you can downhill if
[01:58:01.200 --> 01:58:10.320]   you want, but it's fun. It's really fun. I love it. I'm a big fan. I went to rad power for the first
[01:58:10.320 --> 01:58:14.960]   two. And I'm still waiting for my super 73, but that's been held up by these tariffs.
[01:58:14.960 --> 01:58:22.160]   So I ended up just getting a couple of rad powers and they came very fast. But these are
[01:58:22.160 --> 01:58:25.360]   these are really cool little bikes. They're really fun to ride highly recommend them. They're
[01:58:25.360 --> 01:58:30.400]   going to have a big $200 off black Friday sale if you're interested. Nice. They're not an average
[01:58:30.400 --> 01:58:36.720]   house. How much is it cost? I think well, I paid 1600. I think there's the red rover.
[01:58:36.720 --> 01:58:42.960]   This is the one Lisa likes got 300 bucks off. So that's good enough. I'm told there's so
[01:58:42.960 --> 01:58:47.120]   places where you think they're going to start renting them in New York in addition to
[01:58:47.120 --> 01:58:56.720]   city bikes. These electric bikes are the future. I mean, I thought you need to have your hoofding.
[01:58:56.720 --> 01:59:01.600]   I think I might need a hoofding now because I got upset with people in New York. You're in New York.
[01:59:01.600 --> 01:59:07.040]   You got to get killed and people don't have help with some. Yeah. Well, I wear a helmet,
[01:59:07.040 --> 01:59:12.480]   but a helmet is really just an eggshell for the brain. Yeah. So I think I'm going to have to get
[01:59:12.480 --> 01:59:17.680]   leather. You need a body hoofding. I need a whole hoofding. You're like a Michelin man kind of thing.
[01:59:20.080 --> 01:59:26.720]   I'll wear my puffy jacket. So here it is, ladies and gentlemen. Wow. The portal is here. Oh my
[01:59:26.720 --> 01:59:34.800]   lord, it's huge. I think it's huge. This is the Facebook device that's designed. Facebook isn't
[01:59:34.800 --> 01:59:42.080]   just in your home. It took over your home. That's a big screen. Well, and the other thing is,
[01:59:42.080 --> 01:59:48.160]   of course, you have to have a Facebook account. Although as I found out, because I, as you know,
[01:59:48.160 --> 01:59:54.160]   deactivated my account, as I found out, if you deactivate your account, oh, you know what?
[01:59:54.160 --> 02:00:00.240]   It's when did you deactivate it? Right after I logged in. So actually, I can't demo it. I
[02:00:00.240 --> 02:00:05.840]   guess by unplugging it, it doesn't have any memory. It now needs me to log back in and everything.
[02:00:05.840 --> 02:00:11.680]   So I'm sorry to say I won't be able to give you a full demo. Was that like a 12, 13 inch screen?
[02:00:11.680 --> 02:00:15.840]   Yeah, it's yeah, it's kind of yeah. It's a big screen and it rotates. And actually,
[02:00:15.840 --> 02:00:20.000]   most of the time you're going to use it like this because in the portrait mode,
[02:00:20.000 --> 02:00:24.240]   because then you can see the whole person's body and face. It's a hold it up like it's a phone.
[02:00:24.240 --> 02:00:32.560]   It's a giant. It's the world's biggest phone. Hello. I'm here. Hello. It kind of looks like
[02:00:32.560 --> 02:00:39.280]   the 17 inch Tesla screen. It's pretty big. Yeah, it does a bit. Yeah. Yeah. So the idea of it is,
[02:00:39.280 --> 02:00:43.840]   I guess, okay, so this is going to be a process because I have to reactivate my Facebook account,
[02:00:43.840 --> 02:00:49.360]   log in, then you can deactivate because it's using messenger. Well, what Facebook doesn't really
[02:00:49.360 --> 02:00:54.000]   kind of emphasize. They don't they never delete your account. Facebook messenger doesn't stop working
[02:00:54.000 --> 02:01:00.000]   when you deactivate your face. Oh, really? I'm interesting. So if you and I'm going to do a full
[02:01:00.000 --> 02:01:06.080]   review on the new screen savers, I'll have it all set up again. But if you deactivate your account,
[02:01:06.080 --> 02:01:09.840]   you don't get your pictures. Otherwise, it's a very nice slideshow of your Facebook pictures.
[02:01:09.840 --> 02:01:18.240]   You choose the topics or the people or the folders from Facebook. And so you get it's got time of day.
[02:01:18.240 --> 02:01:25.440]   It's got a and then it's got a Amazon's Echo built in. So you can use do some echo things.
[02:01:25.440 --> 02:01:33.680]   And if you want to call, you say, Hey, portal call Jeff and it will call you and it'll do a video
[02:01:33.680 --> 02:01:39.680]   call. This is a very high def camera. It's a 4k camera. And at first, we follow as you too,
[02:01:39.680 --> 02:01:43.760]   right? Well, and at first, everybody thought, Oh, ha ha, that's creepy a Facebook camera that
[02:01:43.760 --> 02:01:48.560]   follows you around. And it does very slowly follows you around. But what I realized is that's
[02:01:48.560 --> 02:01:54.160]   not the real threat here. The real threat is Facebook has a wide angle 4k picture of your room at all
[02:01:54.160 --> 02:02:01.520]   times. So following you is just a side effect of how high resolution this is. So it could just
[02:02:01.520 --> 02:02:06.240]   take a portion of that. And you know, as you move, and it does a good job, it follows you around slowly.
[02:02:07.200 --> 02:02:13.200]   See, I think it was the Wall Street Journal. Their review was this would be a great device
[02:02:13.200 --> 02:02:19.520]   if it came from literally any other buddy. Russell Holly and Android at Android Central said
[02:02:19.520 --> 02:02:26.560]   it's his favorite way to video chat. It's a heck of a lot of fun. Yeah, it would be so much cooler
[02:02:26.560 --> 02:02:36.560]   if it didn't come Facebook. But I mean, it's also expensive. The little one that Russell's using
[02:02:36.560 --> 02:02:43.840]   is 200 bucks, but this giant one's $300. The sound quality is pretty good. It does have
[02:02:43.840 --> 02:02:48.400]   Amazon's Echo in it. So that's kind of cool. Although you can't do things like watch YouTube
[02:02:48.400 --> 02:02:56.080]   videos. All the only thing the video is good for is video conferencing. So full review, I got two of
[02:02:56.080 --> 02:03:01.760]   them because I foolishly thought you had have to. But in fact, you can call anybody with messenger
[02:03:01.760 --> 02:03:07.600]   and do a video phone call. So you don't really need two of them. But anybody I got them.
[02:03:07.600 --> 02:03:12.320]   Anybody want to be on a permanent line? I think I'm a San Juan of my heart.
[02:03:12.320 --> 02:03:16.400]   Otherwise, you know, there'd be only three people in the world you could call who chose to buy that.
[02:03:16.400 --> 02:03:21.840]   But everybody has Facebook messenger. I called Lisa and she didn't even know I had it. And she
[02:03:21.840 --> 02:03:26.240]   just picked up on Facebook messenger on her phone. And so I was able to see her and everything.
[02:03:26.240 --> 02:03:32.720]   It does come with a handy dandy privacy cap for the camera, which I've already lost.
[02:03:32.720 --> 02:03:37.920]   You put it on the desk, I thought. It's just a piece of, yeah. It's just a piece of pla- oh,
[02:03:37.920 --> 02:03:43.440]   here it is. Yeah, yeah. It's just literally a piece of pla- that's otherwise known as an
[02:03:43.440 --> 02:03:48.960]   afterthought. Better than duct tape. And privacy is always an option. You just put it right over
[02:03:48.960 --> 02:03:54.480]   that there. And then no one can see you from the face. It's the video chastity belt.
[02:03:55.840 --> 02:04:02.320]   Yeah, I suppose the microphone still works, but maybe not. I think it's kind of cool.
[02:04:02.320 --> 02:04:06.000]   In the Russell Hollie's review, he talks about the good things. And he says,
[02:04:06.000 --> 02:04:10.400]   "Among the bad things, Facebook has partial access to a camera at microphone in my house."
[02:04:10.400 --> 02:04:15.840]   But I don't think- I mean, honestly, I don't think Amazon's listening to you.
[02:04:15.840 --> 02:04:19.920]   I don't think Google's listening to you. And I don't think Facebook's listening and looking at you.
[02:04:19.920 --> 02:04:23.040]   But nevertheless, the optics, if you will or not.
[02:04:23.040 --> 02:04:32.800]   I remember when the first reports came out that AT&T had allowed the NSA to basically tap into
[02:04:32.800 --> 02:04:38.800]   one of its main lines, and they were basically recording the phone calls-
[02:04:38.800 --> 02:04:41.920]   Yeah, they had a room in the San Francisco Switching office.
[02:04:41.920 --> 02:04:47.920]   So I remember talking to someone at the time, and when the news first started coming out.
[02:04:50.480 --> 02:04:53.760]   If you actually did that, there would be so much data.
[02:04:53.760 --> 02:04:54.480]   You can't.
[02:04:54.480 --> 02:04:59.280]   There would be no way you could A, store it, B, search it, C, do anything with it.
[02:04:59.280 --> 02:05:01.520]   It would just be impossible.
[02:05:01.520 --> 02:05:05.200]   All right, I'm going to log in just so you can see it work.
[02:05:05.200 --> 02:05:07.440]   So that looks really heavy.
[02:05:07.440 --> 02:05:13.440]   Yeah, it's not portable. It has a handle, but it's not that heavy, but you're not going to
[02:05:13.440 --> 02:05:14.800]   carry it around. It's not a big box.
[02:05:14.800 --> 02:05:19.120]   It's ungainly. Yeah, that's what it is. So you're not going to carry it around. You're going to
[02:05:19.120 --> 02:05:24.240]   put it somewhere where you want to make video calls.
[02:05:24.240 --> 02:05:35.280]   You got to go to Facebook.com/device and then enter in this code, W-F-Y-Q-M-Y.
[02:05:35.280 --> 02:05:41.440]   And then don't ask me to confirm my login again.
[02:05:41.440 --> 02:05:44.080]   Okay, confirm.
[02:05:45.520 --> 02:05:51.280]   And I think I'm logged in. Success. Now I can show you.
[02:05:51.280 --> 02:05:54.400]   There's... Oh, there you are.
[02:05:54.400 --> 02:05:54.960]   There I am.
[02:05:54.960 --> 02:06:03.120]   It has Pandora and Spotify on it. I'm going to call this one kitchen because that's where it's going
[02:06:03.120 --> 02:06:04.160]   to end up.
[02:06:04.160 --> 02:06:05.680]   Oh, that's what you're going to call me.
[02:06:05.680 --> 02:06:07.200]   Yeah, I can call you. Should I call you?
[02:06:07.200 --> 02:06:09.840]   Sure. Hold on. Just see if I... What would I call you?
[02:06:10.800 --> 02:06:15.360]   I don't know what will happen. That's...
[02:06:15.360 --> 02:06:17.440]   You want to see how the smart camera works?
[02:06:17.440 --> 02:06:22.240]   Here's how the smart camera works. Turn on the camera and microphone.
[02:06:22.240 --> 02:06:25.520]   Okay. It says it's calling you.
[02:06:25.520 --> 02:06:28.400]   Oh, it is. Yeah, well, I hear something.
[02:06:28.400 --> 02:06:37.200]   How do you answer it?
[02:06:38.080 --> 02:06:39.840]   Well, I'm... Wait a second.
[02:06:39.840 --> 02:06:40.560]   Don't do anything.
[02:06:40.560 --> 02:06:41.120]   Was it calling you?
[02:06:41.120 --> 02:06:42.880]   Don't do anything yet.
[02:06:42.880 --> 02:06:46.240]   No, I was calling... No, I was using text.
[02:06:46.240 --> 02:06:47.040]   Okay, hold on.
[02:06:47.040 --> 02:06:47.920]   Don't do anything yet.
[02:06:47.920 --> 02:06:49.920]   No, it wasn't me.
[02:06:49.920 --> 02:06:52.960]   Tap the center button in the top of the portal.
[02:06:52.960 --> 02:06:55.360]   Just turn them on.
[02:06:55.360 --> 02:06:58.800]   Now I'm calling you.
[02:06:58.800 --> 02:07:03.040]   Oh. Hi, Jeff.
[02:07:03.040 --> 02:07:07.440]   Hello, Leo. Look at that. I got double Jeff.
[02:07:08.320 --> 02:07:08.800]   Wow.
[02:07:08.800 --> 02:07:10.640]   See, I thought I could really use this as the...
[02:07:10.640 --> 02:07:13.360]   As the...
[02:07:13.360 --> 02:07:14.000]   For the show.
[02:07:14.000 --> 02:07:15.600]   Now watch. I know.
[02:07:15.600 --> 02:07:16.240]   What was it?
[02:07:16.240 --> 02:07:18.320]   Okay, so watch. Now you see me?
[02:07:18.320 --> 02:07:20.400]   Now watch. I can dodge out of the way.
[02:07:20.400 --> 02:07:23.760]   And the camera will follow me slowly.
[02:07:23.760 --> 02:07:26.720]   Only you can see that, though.
[02:07:26.720 --> 02:07:29.360]   I know. We're setting the camera up so that you can see it.
[02:07:29.360 --> 02:07:32.080]   Here we go.
[02:07:36.320 --> 02:07:38.560]   So as I move around the camera,
[02:07:38.560 --> 02:07:40.960]   because it's just a slice of the 4K camera.
[02:07:40.960 --> 02:07:43.520]   Ah, I see.
[02:07:43.520 --> 02:07:46.160]   It's how long I need.
[02:07:46.160 --> 02:07:47.440]   I can't get away from it.
[02:07:47.440 --> 02:07:49.520]   But it doesn't move real fast,
[02:07:49.520 --> 02:07:50.320]   because otherwise.
[02:07:50.320 --> 02:07:51.680]   But this is the best part.
[02:07:51.680 --> 02:07:52.400]   Ready, Jeff?
[02:07:52.400 --> 02:07:54.080]   Get ready for this.
[02:07:54.080 --> 02:07:55.040]   Okay.
[02:07:55.040 --> 02:07:56.080]   You're going to like this.
[02:07:56.080 --> 02:08:00.800]   Oh, no, not that.
[02:08:00.800 --> 02:08:01.440]   Yes, this.
[02:08:01.440 --> 02:08:03.200]   Come on.
[02:08:03.200 --> 02:08:04.960]   Do it.
[02:08:04.960 --> 02:08:05.760]   Do it, man.
[02:08:05.760 --> 02:08:06.640]   Do it.
[02:08:06.640 --> 02:08:07.840]   Do I have to drag it?
[02:08:07.840 --> 02:08:08.800]   What is the story?
[02:08:08.800 --> 02:08:10.640]   Is it filters?
[02:08:10.640 --> 02:08:10.880]   Yeah.
[02:08:10.880 --> 02:08:12.720]   Is it going to play?
[02:08:12.720 --> 02:08:14.400]   Hello, Jeff.
[02:08:14.400 --> 02:08:15.920]   What do you think?
[02:08:15.920 --> 02:08:16.880]   Hi.
[02:08:16.880 --> 02:08:18.640]   Hi.
[02:08:18.640 --> 02:08:19.120]   I am.
[02:08:19.120 --> 02:08:20.640]   Hi.
[02:08:20.640 --> 02:08:20.880]   Hello.
[02:08:20.880 --> 02:08:21.840]   Hi.
[02:08:21.840 --> 02:08:23.360]   It's actually very good.
[02:08:23.360 --> 02:08:24.400]   It's actually very good.
[02:08:24.400 --> 02:08:25.520]   It does a very good job.
[02:08:25.520 --> 02:08:28.320]   Now I think Apple does similar things.
[02:08:28.320 --> 02:08:31.920]   But what it's doing is I'm putting faces on.
[02:08:33.280 --> 02:08:35.680]   It's kind of a Snapchat filter effect.
[02:08:35.680 --> 02:08:38.400]   I wonder where they got that idea.
[02:08:38.400 --> 02:08:39.120]   Yeah.
[02:08:39.120 --> 02:08:40.800]   Where do they think of this?
[02:08:40.800 --> 02:08:42.880]   There were some scary Halloween filters.
[02:08:42.880 --> 02:08:44.800]   I can't find them.
[02:08:44.800 --> 02:08:47.200]   I can't put filters on though.
[02:08:47.200 --> 02:08:47.920]   Yeah, you can.
[02:08:47.920 --> 02:08:49.440]   Where are they?
[02:08:49.440 --> 02:08:50.000]   They're in there.
[02:08:50.000 --> 02:08:51.040]   I don't see them.
[02:08:51.040 --> 02:08:52.080]   They're in there somewhere.
[02:08:52.080 --> 02:08:53.200]   Hey, Jeff.
[02:08:53.200 --> 02:08:53.920]   Come on over.
[02:08:53.920 --> 02:08:55.040]   We're having a party.
[02:08:55.040 --> 02:08:57.360]   Where are they?
[02:08:57.360 --> 02:08:58.080]   They're out there.
[02:08:58.080 --> 02:08:59.600]   I can add people.
[02:08:59.600 --> 02:09:01.200]   No, I don't want to do that.
[02:09:01.200 --> 02:09:02.000]   I'm not.
[02:09:02.000 --> 02:09:08.800]   Oh, did you see?
[02:09:08.800 --> 02:09:09.200]   I lost you.
[02:09:09.200 --> 02:09:10.480]   Oh, no, I lost you.
[02:09:10.480 --> 02:09:12.720]   Can you see the tears coming out of my eyes?
[02:09:12.720 --> 02:09:14.080]   No, I can't find you anymore.
[02:09:14.080 --> 02:09:14.640]   Don't show Jeff.
[02:09:14.640 --> 02:09:15.360]   Just show me.
[02:09:15.360 --> 02:09:15.920]   There you go.
[02:09:15.920 --> 02:09:22.480]   So you get the idea.
[02:09:22.480 --> 02:09:23.520]   Here's a strawberry hat.
[02:09:23.520 --> 02:09:27.200]   It's your hivding.
[02:09:27.200 --> 02:09:28.080]   It's my hivding.
[02:09:28.080 --> 02:09:29.280]   I got my hivdings on.
[02:09:30.080 --> 02:09:30.720]   Keep the cat.
[02:09:30.720 --> 02:09:32.640]   Hi, Jeff.
[02:09:32.640 --> 02:09:34.880]   It's amazing what technology can do.
[02:09:34.880 --> 02:09:36.480]   How useful it is.
[02:09:36.480 --> 02:09:38.640]   What life would be without this?
[02:09:38.640 --> 02:09:40.560]   So, I mean, this is kind of cool.
[02:09:40.560 --> 02:09:41.920]   This is pretty well done, actually.
[02:09:41.920 --> 02:09:43.040]   In the face right now.
[02:09:43.040 --> 02:09:43.440]   Nice.
[02:09:43.440 --> 02:09:44.000]   It's very good.
[02:09:44.000 --> 02:09:46.960]   Yeah, the blues brothers.
[02:09:46.960 --> 02:09:48.080]   What do you want for this?
[02:09:48.080 --> 02:09:48.560]   How about this?
[02:09:48.560 --> 02:09:48.720]   Good.
[02:09:48.720 --> 02:09:51.040]   Uh, I don't know what this one will do.
[02:09:51.040 --> 02:09:53.520]   Or why.
[02:09:53.520 --> 02:09:55.440]   Okay.
[02:09:55.440 --> 02:09:58.000]   Apparently, I have a,
[02:09:58.000 --> 02:09:59.920]   it looks like a panda bear on my head.
[02:09:59.920 --> 02:10:02.320]   Flying in airplane.
[02:10:02.320 --> 02:10:02.800]   Flying in airplane.
[02:10:02.800 --> 02:10:03.760]   It's my airplane hat.
[02:10:03.760 --> 02:10:07.040]   Here's a, for relaxation, there's a cat.
[02:10:07.040 --> 02:10:09.680]   It is very realistic.
[02:10:09.680 --> 02:10:10.640]   Wow.
[02:10:10.640 --> 02:10:10.880]   You know?
[02:10:10.880 --> 02:10:11.920]   It is.
[02:10:11.920 --> 02:10:12.720]   What do you think, Jeff?
[02:10:12.720 --> 02:10:14.080]   I like it.
[02:10:14.080 --> 02:10:14.640]   I like it.
[02:10:14.640 --> 02:10:16.240]   I could turn it, uh,
[02:10:16.240 --> 02:10:17.600]   I could turn it this way, although.
[02:10:17.600 --> 02:10:19.600]   I think you're mostly going to want to use it that way.
[02:10:19.600 --> 02:10:21.360]   I'll try the same thing.
[02:10:21.360 --> 02:10:21.680]   Yeah.
[02:10:21.680 --> 02:10:24.080]   Oh, funny.
[02:10:24.080 --> 02:10:25.280]   I, I, I, I, I wrote it.
[02:10:25.280 --> 02:10:25.840]   You should leave.
[02:10:25.840 --> 02:10:27.200]   You should leave yours.
[02:10:28.000 --> 02:10:28.480]   Okay.
[02:10:28.480 --> 02:10:30.880]   Uh, in a horizontal, leave yours in landscape mode.
[02:10:30.880 --> 02:10:35.520]   Um, anyway, I, I don't know what, what do you think?
[02:10:35.520 --> 02:10:37.520]   It's actually pretty cool.
[02:10:37.520 --> 02:10:40.720]   I don't mind face, I don't, I honestly don't fear Facebook.
[02:10:40.720 --> 02:10:43.280]   In my, you know, spying on me.
[02:10:43.280 --> 02:10:44.800]   Why would they, what would they gain that?
[02:10:44.800 --> 02:10:45.440]   What would they, you know?
[02:10:45.440 --> 02:10:49.920]   Um, I think though that they, you know, clearly this is a product
[02:10:49.920 --> 02:10:53.760]   they had for a while and they, and they just kind of finally said,
[02:10:53.760 --> 02:10:55.360]   there's no good time to put this out.
[02:10:56.080 --> 02:10:57.120]   Let's just put it at now.
[02:10:57.120 --> 02:10:59.200]   Let's say it, it was not popular.
[02:10:59.200 --> 02:11:00.560]   We'll blame it on Elliot Shrike.
[02:11:00.560 --> 02:11:00.880]   Right.
[02:11:00.880 --> 02:11:04.480]   It's Elliot's, Elliot, the outgoing portal guy.
[02:11:04.480 --> 02:11:06.800]   Tom said, um, this is my favorite one.
[02:11:06.800 --> 02:11:13.200]   It's the first use of a, of, of, uh, uh, what we're trying to say,
[02:11:13.200 --> 02:11:14.320]   augmented, uh, AR.
[02:11:14.320 --> 02:11:15.360]   Yeah.
[02:11:15.360 --> 02:11:17.280]   That kind of just, it's pretty good.
[02:11:17.280 --> 02:11:18.240]   Fluidly fits.
[02:11:18.240 --> 02:11:18.480]   Yeah.
[02:11:18.480 --> 02:11:21.840]   Obviously, I mean, one thing Facebook does have is really good engineers.
[02:11:21.840 --> 02:11:24.960]   And I wonder, uh, if Colleen Kelly, our former video
[02:11:25.520 --> 02:11:28.400]   engineer who works at Facebook now doing a lot of video stuff for them.
[02:11:28.400 --> 02:11:29.920]   I wonder what her hand was in this.
[02:11:29.920 --> 02:11:31.040]   Cause you wanted to Facebook.
[02:11:31.040 --> 02:11:31.440]   Oh, yeah.
[02:11:31.440 --> 02:11:32.320]   She works at Facebook.
[02:11:32.320 --> 02:11:37.520]   One of the things that I, um, we really wanted to do with our avatars.
[02:11:37.520 --> 02:11:42.080]   You know, when, for those of you who've seen our video, we have Jeff and Matthew
[02:11:42.080 --> 02:11:44.880]   in television screens, but they're in landscape mode.
[02:11:44.880 --> 02:11:46.800]   I really prefer to have them in portrait mode.
[02:11:46.800 --> 02:11:47.280]   Mm.
[02:11:47.280 --> 02:11:49.200]   And I asked Colleen, I said, can we do that?
[02:11:49.200 --> 02:11:50.720]   And she said, uh, she looked into it.
[02:11:50.720 --> 02:11:51.760]   She said, not really.
[02:11:51.760 --> 02:11:54.080]   It needs some pretty expensive gear.
[02:11:55.120 --> 02:11:59.840]   And I find it interesting that this is really designed to be in portrait mode.
[02:11:59.840 --> 02:12:02.720]   So Leo, you're going to, you're going to send those to all of us then for Christmas.
[02:12:02.720 --> 02:12:03.440]   Is that the deal?
[02:12:03.440 --> 02:12:04.000]   You know what?
[02:12:04.000 --> 02:12:07.840]   The only reason I actually, my initial thought was this would be awesome for the show.
[02:12:07.840 --> 02:12:12.560]   I just put these on the table with me and, uh, and I guess we just do it like that.
[02:12:12.560 --> 02:12:20.640]   But, um, I realized that there's no way to get a feed back to you, except from this camera.
[02:12:20.640 --> 02:12:20.880]   Yeah.
[02:12:20.880 --> 02:12:21.200]   Right.
[02:12:21.200 --> 02:12:22.400]   So I'm watching the wrong thing.
[02:12:22.400 --> 02:12:25.120]   And we don't have really a way to get a feed out of it, except to shoot it.
[02:12:25.120 --> 02:12:25.280]   Yeah.
[02:12:25.280 --> 02:12:27.920]   So I don't want to put that in my suitcase.
[02:12:27.920 --> 02:12:28.960]   Yeah.
[02:12:28.960 --> 02:12:30.720]   Well, there's a smaller one.
[02:12:30.720 --> 02:12:42.160]   I can't do this, but it doesn't, it doesn't let me do these things.
[02:12:42.160 --> 02:12:43.200]   You don't have those things.
[02:12:43.200 --> 02:12:44.240]   Oh, no, I don't.
[02:12:44.240 --> 02:12:47.920]   Ladies and gentlemen, I'm on your head.
[02:12:47.920 --> 02:12:50.720]   They may be denying.
[02:12:50.720 --> 02:12:52.160]   They may be delaying.
[02:12:52.160 --> 02:12:54.640]   They may be deflecting, but they're pretty damn good.
[02:12:54.640 --> 02:12:55.760]   Put it a cat on my head.
[02:12:55.760 --> 02:13:02.000]   And at the end of the day, at the end of the day, isn't that was what matters?
[02:13:02.000 --> 02:13:05.920]   Matthew Ingram, the Columbia journalism review, CJR.org.
[02:13:05.920 --> 02:13:07.760]   He's their chief digital writer.
[02:13:07.760 --> 02:13:11.200]   You can follow him on the Twitter M A T H E W I.
[02:13:11.200 --> 02:13:15.200]   You may say, I think it's a comment on math.
[02:13:15.200 --> 02:13:19.360]   Math, you, E, but no, it's his name.
[02:13:19.360 --> 02:13:20.240]   Matthew.
[02:13:21.200 --> 02:13:22.000]   Thank you, Matt.
[02:13:22.000 --> 02:13:23.600]   It's great to have you happy.
[02:13:23.600 --> 02:13:26.560]   You're not doing Thanksgiving, so just like happy Thursday.
[02:13:26.560 --> 02:13:27.440]   You already did it, right?
[02:13:27.440 --> 02:13:27.840]   Thank you.
[02:13:27.840 --> 02:13:28.000]   Yeah.
[02:13:28.000 --> 02:13:28.800]   Yeah, it was last month.
[02:13:28.800 --> 02:13:30.320]   We did ours a long time ago.
[02:13:30.320 --> 02:13:32.640]   So happy Thursday tomorrow.
[02:13:32.640 --> 02:13:33.040]   Thank you.
[02:13:33.040 --> 02:13:33.360]   Yeah.
[02:13:33.360 --> 02:13:36.720]   So this is apology month in Canada.
[02:13:36.720 --> 02:13:37.520]   Is it?
[02:13:37.520 --> 02:13:40.000]   Yeah, they don't want to apologize to people.
[02:13:40.000 --> 02:13:41.360]   Every month is apology month.
[02:13:41.360 --> 02:13:41.760]   Yes.
[02:13:41.760 --> 02:13:45.200]   To Jeff Jarvis, I wish you.
[02:13:45.200 --> 02:13:46.960]   That's very cool.
[02:13:46.960 --> 02:13:49.200]   Oh, look, the cat is appearing now on her.
[02:13:49.200 --> 02:13:50.560]   The cat is appearing on her heads.
[02:13:51.120 --> 02:13:52.560]   Oh, that's cool.
[02:13:52.560 --> 02:13:54.080]   Only one of you can be the cat.
[02:13:54.080 --> 02:13:56.160]   I could put these.
[02:13:56.160 --> 02:13:56.560]   Let's see.
[02:13:56.560 --> 02:14:05.760]   That's funny, even if you're far away, it puts a cat on you.
[02:14:05.760 --> 02:14:10.080]   Jeff is at, he is, well, let me view it right.
[02:14:10.080 --> 02:14:12.160]   The Leonard Taill professor for journalistic innovation
[02:14:12.160 --> 02:14:14.800]   at the Craig Newmark's graduate school of journalism
[02:14:14.800 --> 02:14:16.160]   at the City University of New York.
[02:14:16.160 --> 02:14:19.120]   If you were vertical, my lower third would fit.
[02:14:19.120 --> 02:14:20.400]   Yeah, actually it would, wouldn't it?
[02:14:20.880 --> 02:14:23.920]   He blogs at buzzmachine.com and joins us each and every week.
[02:14:23.920 --> 02:14:25.520]   Right here.
[02:14:25.520 --> 02:14:27.680]   Are you going to be back next week or are you traveling?
[02:14:27.680 --> 02:14:28.960]   Next week I'm here, we got with that.
[02:14:28.960 --> 02:14:30.560]   I'm not, but then I'm here for the rest of the year.
[02:14:30.560 --> 02:14:31.120]   All right.
[02:14:31.120 --> 02:14:32.000]   Great to have you.
[02:14:32.000 --> 02:14:33.920]   Happy Thanksgiving, Jeff to you.
[02:14:33.920 --> 02:14:36.000]   Is Jay coming home for the Thanksgiving?
[02:14:36.000 --> 02:14:36.880]   He just arrived.
[02:14:36.880 --> 02:14:38.720]   I had eight hours from Boston.
[02:14:38.720 --> 02:14:41.600]   So I'm about to go out and say hello to Jay Kajulia.
[02:14:41.600 --> 02:14:42.080]   Well, have a--
[02:14:42.080 --> 02:14:43.680]   And yours?
[02:14:43.680 --> 02:14:44.480]   Are yours home?
[02:14:44.480 --> 02:14:45.360]   Yes, they are.
[02:14:45.360 --> 02:14:45.760]   And we're all--
[02:14:45.760 --> 02:14:47.040]   Well, one of those working there, yes.
[02:14:47.040 --> 02:14:48.480]   One of them is right across the hall.
[02:14:48.480 --> 02:14:49.760]   Thank you, Jeff.
[02:14:49.760 --> 02:14:51.120]   Thank you everybody for joining us.
[02:14:51.120 --> 02:14:52.960]   We do this week in Google every Wednesday,
[02:14:52.960 --> 02:14:56.000]   about 130 Pacific 430 Eastern.
[02:14:56.000 --> 02:14:58.880]   That would be 2130 UTC.
[02:14:58.880 --> 02:15:00.480]   If you want to stop by and watch live,
[02:15:00.480 --> 02:15:01.040]   you can.
[02:15:01.040 --> 02:15:02.960]   Live audio and video are available
[02:15:02.960 --> 02:15:04.000]   from a variety of sources,
[02:15:04.000 --> 02:15:07.120]   but they're all aggregated at twit.tv/live.
[02:15:07.120 --> 02:15:09.440]   If you're doing that, join us in the chat room,
[02:15:09.440 --> 02:15:12.160]   irc.twit.tv.
[02:15:12.160 --> 02:15:15.280]   So you could participate in the back talk.
[02:15:15.280 --> 02:15:16.640]   You can also sit in the studio,
[02:15:16.640 --> 02:15:17.680]   which would be a lot of fun.
[02:15:18.640 --> 02:15:20.960]   All you have to do is email tickets@twit.tv.
[02:15:20.960 --> 02:15:21.760]   We'll put a chair out for you.
[02:15:21.760 --> 02:15:22.560]   We had a great studio.
[02:15:22.560 --> 02:15:23.680]   It was full house today.
[02:15:23.680 --> 02:15:24.400]   We really do.
[02:15:24.400 --> 02:15:27.680]   We have visitors from Tinley Park, Illinois,
[02:15:27.680 --> 02:15:32.640]   from Brentwood, California, and from Mexico.
[02:15:32.640 --> 02:15:34.960]   And they all now think they're going to get him tomorrow.
[02:15:34.960 --> 02:15:38.000]   They're all coming over for him.
[02:15:38.000 --> 02:15:39.760]   Nice.
[02:15:39.760 --> 02:15:41.120]   Nice.
[02:15:41.120 --> 02:15:42.000]   You're all invited.
[02:15:42.000 --> 02:15:43.840]   So thank you for--
[02:15:43.840 --> 02:15:44.720]   Thank you for being here.
[02:15:44.720 --> 02:15:45.040]   He's joking.
[02:15:45.040 --> 02:15:45.520]   He's joking.
[02:15:45.520 --> 02:15:46.080]   He's really appreciated.
[02:15:46.080 --> 02:15:47.280]   I may not be joking.
[02:15:47.280 --> 02:15:50.880]   I think there's going to be a lot of extra food.
[02:15:50.880 --> 02:15:53.200]   Thank you, everybody, for joining us.
[02:15:53.200 --> 02:15:55.120]   We will see you next time.
[02:15:55.120 --> 02:15:56.880]   Happy Thanksgiving if you're in the US.
[02:15:56.880 --> 02:15:59.120]   If not, happy Thursday.
[02:15:59.120 --> 02:16:02.080]   We'll see you next time on This Week in Cucobody.
[02:16:02.080 --> 02:16:12.080]   [Music]

