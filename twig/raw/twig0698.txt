;FFMETADATA1
title=Hands Off My Pound Cake!
artist=Leo Laporte, Jeff Jarvis, Stacey Higginbotham, Ant Pruitt
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2023-01-12
track=698
language=English
genre=Podcast
comment=ChatGPT Microsoft investment, Tesla crashes, FAA outage, Afroman raid
encoded_by=Uniblab 5.3
date=2023
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.800]   It's time for Twig this week in Google, Stacey, and Jeff are all in the house.
[00:00:04.800 --> 00:00:08.240]   We finally get some numbers about Stadia and it doesn't look good.
[00:00:08.240 --> 00:00:14.080]   Chat, GPT, and OpenAI get a big investment from Microsoft. What are they going to do with
[00:00:14.080 --> 00:00:20.720]   all that money? And it was a bad week for tech. I'll tell you about all the big tech flops
[00:00:20.720 --> 00:00:25.920]   as we do this week in Google coming up next. Before we get to the show, I want to remind you,
[00:00:25.920 --> 00:00:29.760]   our Twitch survey is up and running for the rest of the month. But I would love it if you
[00:00:29.760 --> 00:00:36.320]   take it right now. Go to twit.tv/survey23. We only do this once a year to try to get to know
[00:00:36.320 --> 00:00:40.640]   you better and it really helps us both with ad sales, but also to make sure our programming is
[00:00:40.640 --> 00:00:48.640]   matching your needs. Twit.tv/survey23 to take our optional survey. I appreciate it.
[00:00:48.640 --> 00:00:50.240]   And now on with the show.
[00:00:52.800 --> 00:00:58.560]   Podcasts you love from people you trust. This is Twig.
[00:00:58.560 --> 00:01:13.200]   This is Twig. This week in Google, episode 698 recorded January 11th, 2023. Hands off my pound cake.
[00:01:13.200 --> 00:01:19.280]   This week at Google is brought to you by Fastmail. Reclaim your privacy,
[00:01:19.280 --> 00:01:27.040]   boost productivity and make email yours with Fastmail. Try it free for 30 days at fastmail.com/twit.
[00:01:27.040 --> 00:01:32.400]   Fastmail is also giving Twit listeners a 15% discount in the first year when you sign up today.
[00:01:32.400 --> 00:01:39.600]   And by Melissa. Over 10,000 clients worldwide in industries like retail education,
[00:01:39.600 --> 00:01:46.000]   health care, insurance, finance and government rely on Melissa for full spectrum data quality
[00:01:46.000 --> 00:01:50.960]   and ID verification software. Make sure your customer contact data is up to date.
[00:01:50.960 --> 00:01:56.960]   Get started today with 1000 records cleaned for free at Melissa.com/twits.
[00:01:56.960 --> 00:02:03.360]   Thanks for listening to this show. As an ad supported network, we are always looking for new
[00:02:03.360 --> 00:02:09.280]   partners with products and services that will benefit our qualified audience. Are you ready to
[00:02:09.280 --> 00:02:14.560]   grow your business? Reach out to advertise at twit.tv and launch your campaign now.
[00:02:14.560 --> 00:02:20.320]   It's time for Twig this week in Google. Show me cover the latest news. Not from Google.
[00:02:20.320 --> 00:02:24.400]   Well, a little bit from Google. Should I start with a story from Google? I think I got one.
[00:02:24.400 --> 00:02:30.240]   Stacey Higginbotham is here. She's going to be here tomorrow. As she said on Sunday where she was
[00:02:30.240 --> 00:02:41.440]   on twit, there's a lot of Leo in my week. I'm sorry. Stacey on IOT.com at Gigastacey on the
[00:02:41.440 --> 00:02:46.480]   Twitter. She does the great IOT podcast with Kevin Tofel. Welcome. Good to see you.
[00:02:46.480 --> 00:02:53.680]   I like your Indiana Jones leather vest that you are. Are you hot solo leather vest?
[00:02:53.680 --> 00:02:57.840]   I can wear that tomorrow. I wish you would just wear this all the time from now on.
[00:02:57.840 --> 00:03:04.000]   I was like, I can make that my thing. Well, the reason is I brought my fedora for the day.
[00:03:04.000 --> 00:03:11.680]   So I thought, well, maybe I would match. Hello there, Jeff Jarvis.
[00:03:11.680 --> 00:03:17.040]   This was the fastest butt in chair to show start I've ever seen.
[00:03:17.040 --> 00:03:20.240]   Because we're having our late. Stacey said she has a dinner reservation.
[00:03:20.240 --> 00:03:26.800]   And so Leo just said, OK, this week in Google. Catio, I pay pay from Trader Joe's does not count.
[00:03:27.360 --> 00:03:30.560]   As anything to hurry the show for. I just want you to know.
[00:03:30.560 --> 00:03:38.400]   It's because I'm a princess, y'all. Yeah, we treat her with all the dignity and respect she deserves.
[00:03:38.400 --> 00:03:42.800]   Unlike Jeff Jarvis, the Leonard Taill professor for journalist innovation at the
[00:03:42.800 --> 00:03:46.320]   Craig Newmark graduate school of journalism.
[00:03:46.320 --> 00:03:53.840]   At the City University of New York. Hello, Jeff. Hello, Bob. Good to see you. I am well.
[00:03:53.840 --> 00:03:58.800]   Good to see you. Congratulations on the. I watched your restart of the tech.
[00:03:58.800 --> 00:04:02.880]   Ask the tech guys. Oh, thank you for watching that. That was that was a little rocky.
[00:04:02.880 --> 00:04:07.120]   It's like, yeah, I get all the rocky. We're doing stuff we've never done before,
[00:04:07.120 --> 00:04:12.800]   like using zoom to take inbound calls. Well, I was going to say, I put it in the chat.
[00:04:12.800 --> 00:04:17.040]   I would love it if once in a while we take a call here on the show. Oh, cool. We totally can.
[00:04:17.040 --> 00:04:23.600]   That's a good idea. We have that. Yeah. It's a little logistically. It's complicated for
[00:04:23.600 --> 00:04:27.280]   me because John's head is exploding because what screen does he put it on? How does he do that?
[00:04:27.280 --> 00:04:32.400]   I know. It's complicated. But we were able to take, I think, three or four calls, which was great.
[00:04:32.400 --> 00:04:39.600]   We had also segments about CES from Father Robert Baliser, who's going to be on Twitter on Sunday.
[00:04:39.600 --> 00:04:44.320]   He was there. He did some stuff. We had a segment from our car guy, Samable Samma,
[00:04:44.320 --> 00:04:49.280]   because there was a lot of car stuff at CES. So, yeah, it was a lot of fun.
[00:04:49.280 --> 00:04:55.120]   A micro sergeant and I are doing it. It's called Ask the Tech Guys. It is the new version of the old
[00:04:55.120 --> 00:05:03.600]   radio show. And frankly, the radio show, I was always like, "Okay, I just gird myself."
[00:05:03.600 --> 00:05:07.680]   I do it. Not got to do it. I mean, it's an honor to do a national
[00:05:07.680 --> 00:05:14.720]   syndicated radio show. But it's hard because people ask hard questions. And I always felt like I was
[00:05:14.720 --> 00:05:19.040]   on the spot. It was always nervous. Now, I feel like I'm working with friends.
[00:05:19.040 --> 00:05:23.360]   So, it's a different... I just feel better when it's on Twitter, for some reason.
[00:05:23.360 --> 00:05:28.240]   Plus, Micah's really good at this stuff. You two... I love working with Micah.
[00:05:28.240 --> 00:05:33.920]   I mean, I love working with all of you. But Micah, who's only 30, only just turning 30,
[00:05:33.920 --> 00:05:43.280]   adds a little bit of youthful perspective. Energy? Energy. Yeah. Or just like he knows what Snapchat is,
[00:05:43.280 --> 00:05:49.840]   is good. You know, I'm just saying. It's useful. You know who knows who TikTok? What TikTok is,
[00:05:49.840 --> 00:05:57.520]   Mr. Pruitt, hands... Uh-oh. Do we lose him? Do we lose him? I'm here. Oh, good. He's back.
[00:05:57.520 --> 00:06:03.520]   That gum does hit one of my cameras. But I fixed that. I had this other camera.
[00:06:03.520 --> 00:06:07.360]   All that funny. Did he knock it over or did he unplug it?
[00:06:07.360 --> 00:06:11.280]   I think they unplug it because I don't see the talent line on over there.
[00:06:12.800 --> 00:06:18.400]   I mean, in a pre-show, you know, Mrs. Higginbotham and Mr. Jarvis and I were talking about the
[00:06:18.400 --> 00:06:22.640]   dogs sitting under my desk at my feet as I continued to try to kick them to say, "Move."
[00:06:22.640 --> 00:06:27.440]   They just wanted to stay there and now they just totally ruined the start-up show. Hello,
[00:06:27.440 --> 00:06:33.360]   Mr. Pruitt. How did you be so... Hey, man. I am so sorry to keep y'all waiting. We welcomed
[00:06:33.360 --> 00:06:37.200]   Richard Campbell and new host. We had a lovely chat without you. Good. I thought you would
[00:06:37.200 --> 00:06:42.400]   keep each other company, which is nice. Yes, we did. But we have a new host on Windows Weekly,
[00:06:42.400 --> 00:06:47.280]   Richard Campbell taking over from Mary Jo Foley. We spent a little more time saying hello to Richard
[00:06:47.280 --> 00:06:53.360]   and getting to know him and all that stuff. Oh, bye, Mary Jo. Yeah, she got a real job.
[00:06:53.360 --> 00:06:59.280]   Sometimes that happens. Don't get any ideas. Yeah, you never know.
[00:06:59.280 --> 00:07:07.840]   Don't get any ideas. She is working at an analyst, principal analyst, I'm an interim chief, in fact,
[00:07:07.840 --> 00:07:14.880]   of directions on Microsoft.com. We're very happy for her, but it did leave a gaping hole
[00:07:14.880 --> 00:07:20.480]   in Windows Weekly, which we have filled. I've enjoyed watching Richard. He's good. He's great.
[00:07:20.480 --> 00:07:26.720]   He's fun. Yeah. So I said I'd start with a Google story. Let's start with Stadia, which is closing
[00:07:26.720 --> 00:07:36.160]   down about a week from now. And 9 to 5 Google says, "We have now some idea of why it's shutting down.
[00:07:37.040 --> 00:07:41.760]   Destiny 2," which was one of the first games launched on Stadia. It was kind of their flagship
[00:07:41.760 --> 00:07:49.600]   game, was one of the most popular games on the platform. It was free to play. So if you wanted to
[00:07:49.600 --> 00:07:56.960]   play this very popular game, you could do it for free on Stadia. So the question is, how many people
[00:07:56.960 --> 00:08:02.400]   played Destiny 2 on Stadia? According to the Destiny Raid Report, which is a tool that tracks
[00:08:02.400 --> 00:08:09.120]   player stats, it had gathered stats on Stadia and Destiny 2 since the launch of November 2019,
[00:08:09.120 --> 00:08:16.480]   Stadia made up just one and a half percent of new Destiny 2 account creation since 2019.
[00:08:16.480 --> 00:08:25.360]   Just 0.1% of all raids completed since that time were done on Stadia. So about 23,000
[00:08:26.320 --> 00:08:34.400]   raids on 900,000 accounts. It sounds like not only did Stadia not represent an important part of
[00:08:34.400 --> 00:08:41.120]   Destiny's subscriber base, but that even though people might have joined because of that, they
[00:08:41.120 --> 00:08:46.320]   didn't even play the game. Because if you're on Destiny 2, you're going to be doing raids.
[00:08:46.320 --> 00:08:53.360]   Only 23,000 raids in three years. Ah, that doesn't sound like the
[00:08:54.080 --> 00:09:02.000]   Stadia really had much of it on its. 9-5 Google says that probably there were more than a
[00:09:02.000 --> 00:09:06.880]   million total players over the lifetime of Stadia, probably not more than a million players.
[00:09:06.880 --> 00:09:16.240]   And it seems like given, well, I mean they did some kind of imaginary number
[00:09:17.360 --> 00:09:24.880]   crunching, which I think is probably fairly accurate. This Google's platform had no
[00:09:24.880 --> 00:09:36.480]   I got a bean in my throat. I had to in between shows grab a few bites of beans. Don't do that
[00:09:36.480 --> 00:09:41.280]   before a show. I'm just saying if that's true, Google's platform had no more than three million
[00:09:41.280 --> 00:09:46.080]   total players over its lifetime. And that's being very generous. So is this a gaping hole
[00:09:46.640 --> 00:09:51.280]   at Google? I mean, Google not having social and Google plus, I think is a gaping hole in Google.
[00:09:51.280 --> 00:09:55.040]   Should Google have had a game? No, I think the argument in the reason the
[00:09:55.040 --> 00:10:00.000]   stated in do so well is Google launched it with no expertise in the air arena,
[00:10:00.000 --> 00:10:05.760]   no reputation in the arena. And let's face it, a reputation for killing things.
[00:10:05.760 --> 00:10:11.200]   I think people just stayed away and drove. That's really what happened. I joined it.
[00:10:13.600 --> 00:10:18.000]   It feels like they maybe started like they had like this cool technical solution to like,
[00:10:18.000 --> 00:10:21.360]   hey, we can do cloud gaming because that is a very hard technical problem.
[00:10:21.360 --> 00:10:25.360]   Right. I'm sure that's why they did it. So yeah, so I feel like they just were like,
[00:10:25.360 --> 00:10:29.600]   let's see if we can do it. We can. It's very launch it is a product. It's so Google.
[00:10:29.600 --> 00:10:34.240]   Isn't it? That's right. Stacey. It's so Google. We can do it. So we can't we do do it,
[00:10:34.240 --> 00:10:41.600]   but then we lost interest. That was it. January 10th, the last day. So I guess yesterday,
[00:10:41.600 --> 00:10:48.000]   the last day, yeah, did you get your refund? I don't think so. A lot of people have by now.
[00:10:48.000 --> 00:10:54.560]   I didn't buy his. He did. I don't I can't remember what I bought to be honest with you.
[00:10:54.560 --> 00:11:00.480]   They had initially a launch thing where you get a controller and stuff and I don't think I
[00:11:00.480 --> 00:11:04.960]   think I bought it and then I canceled it because then I realized what a wasted money that would be.
[00:11:04.960 --> 00:11:09.840]   And then I think later I subscribed to play some streaming games. I probably won't get any money back.
[00:11:11.280 --> 00:11:15.040]   That's fine with me. All of your info's in your Bitcoin wallet.
[00:11:15.040 --> 00:11:24.320]   Oh, geez. Don't rub it in. Oh my God. It was so funny on the tech guys preamble watching Leo
[00:11:24.320 --> 00:11:30.720]   try to create and then find the last pass account. I forgot my master.
[00:11:30.720 --> 00:11:36.480]   Because I thought, Oh, I'm not going to keep this, but I had it. I was showing you had a move off
[00:11:36.480 --> 00:11:42.000]   last month. And I thought, well, I'm not going to keep this. And I what I also did again is
[00:11:42.000 --> 00:11:48.240]   forgot the password. So I created a new account. Can I get you one of those books that are bound
[00:11:48.240 --> 00:11:54.000]   and leather with passport or passwords on it? You know, you can be like, yesterday I decided
[00:11:54.000 --> 00:11:59.920]   after all this last past stuff to really increase the security on my Bitwarden account, including a
[00:11:59.920 --> 00:12:07.600]   59 character master password, which I wrote down, which I normally go, don't write it down. But at
[00:12:07.600 --> 00:12:11.840]   this time, I thought, you know, Leo, you're really bad. So I wrote it down and put it on a piece of
[00:12:11.840 --> 00:12:19.920]   paper. I don't remember where I put it. I mean, I'll be honest, I have a file password or I have
[00:12:19.920 --> 00:12:25.680]   a file folder that has all my backup physical, like your backup things, the physical papers for
[00:12:26.400 --> 00:12:31.520]   everything. Plus, I do have some passwords. If you want to rob my house and then access
[00:12:31.520 --> 00:12:36.880]   my WordPress account, that's where you'll find it. Well, but see, that's the point is that somebody
[00:12:36.880 --> 00:12:42.640]   would have to have physical access to your premises. And at that point, you got other problems.
[00:12:42.640 --> 00:12:47.440]   It's true. Yeah. Plus, I figure this sounds a little morbid, but that's me.
[00:12:47.440 --> 00:12:50.320]   Should I in the middle of the show suddenly,
[00:12:50.960 --> 00:12:57.760]   call over, you want to be what your family to be able to get at stuff. Yeah. And I did do that.
[00:12:57.760 --> 00:13:01.040]   Yeah, there's a there's a thing in most password managers called emergency access
[00:13:01.040 --> 00:13:06.960]   that you should certainly set up. And I have that. Oh, every year. And I actually recommend
[00:13:06.960 --> 00:13:15.440]   this for everybody. Every year, my husband and I sit down and we share all of our digital,
[00:13:15.440 --> 00:13:19.440]   like, do you have like a ceremony? Do you like put on good garments?
[00:13:20.480 --> 00:13:24.560]   We pour ourselves a, you know, a glass of bourbon and we sit down and we're like, all right,
[00:13:24.560 --> 00:13:33.200]   this is the key exchange. There is actually, I still trust you a moment. There is a magical ceremony
[00:13:33.200 --> 00:13:41.760]   for the DNS server. Oh, yeah. Do you know about that? The seven keepers of the key. Is it still
[00:13:41.760 --> 00:13:50.160]   yeah, something like that, including I want as Tim Bernier's Lee, one of them. It's a it's a
[00:13:50.160 --> 00:13:53.760]   they have a ceremony because every once in a while they have to rotate the keys, I guess.
[00:13:53.760 --> 00:14:01.440]   And they have a ceremony that is you might as well kill a goat. You know, where hooded
[00:14:01.440 --> 00:14:06.560]   gowns, let me see if I can find. Oh, here it is DNS key ceremony. Yeah.
[00:14:08.080 --> 00:14:14.560]   They sign the keys and so they bring in the here's the. I mean, okay, let's let's say they are not
[00:14:14.560 --> 00:14:20.800]   wearing hooded gowns. In fact, they're basically a bunch of nerds. I think wearing a tie is about
[00:14:20.800 --> 00:14:27.680]   the equivalent. I got three of them are wearing ties. But in order to do this, these guys have to
[00:14:27.680 --> 00:14:35.040]   physically come to the same place and sign the root DNS zones a key ring. And I guess they do
[00:14:35.040 --> 00:14:42.320]   this frequently. If someone else out there knows this, I read a mystery book at some point in time.
[00:14:42.320 --> 00:14:50.640]   And the key pop the plot point was that someone was murdering the people who kept the keys for
[00:14:50.640 --> 00:14:59.760]   DNS. And see, I'm like, I was like, so excited. Wow. Oh my god. I know all about this. And like,
[00:14:59.760 --> 00:15:03.120]   they spent a lot more time than they needed to for me personally, explaining what was happening.
[00:15:03.120 --> 00:15:08.320]   I was like, Oh, this is what you see. So if anyone remembers what that's called,
[00:15:08.320 --> 00:15:17.120]   yeah, tell us. Here's an example, by the way, from the Internet Society, they had the big 25th
[00:15:17.120 --> 00:15:26.400]   DNS root key ceremony back in 2016. And there's a whole, there's a whole series of attestations
[00:15:26.400 --> 00:15:32.720]   in the post attestation one. I attest that root key ceremony 25 took place according to the
[00:15:32.720 --> 00:15:38.400]   script with only one exception. The ceremony administration was not performed by Francisco
[00:15:38.400 --> 00:15:47.360]   or I s but by Punky D'Wero. Here's the script. You actually, they actually have a root key ceremony
[00:15:47.360 --> 00:15:55.920]   script that they follow. What must be done? Who does what? I mean, this is a big deal because
[00:15:55.920 --> 00:16:07.280]   without it, the Internet is not secure. And it can't continue. Act one initiates ceremony and
[00:16:07.280 --> 00:16:14.160]   retrieve equipments. Participants arrive and sign into the key ceremony room. CA confirms with
[00:16:14.160 --> 00:16:18.560]   essay that all audit cameras are recording and online streaming is live. So you can watch this.
[00:16:18.560 --> 00:16:24.080]   CA confirms that all participants are signed into the ceremony room and performs a roll call.
[00:16:24.960 --> 00:16:27.280]   And they go through the emergency evacuation.
[00:16:27.280 --> 00:16:33.680]   Yeah, well, that's what I was looking for off to say. Yeah, they should be going.
[00:16:33.680 --> 00:16:42.480]   But I don't, I wish they would. I w one enters UTC date and time using a reasonably accurate
[00:16:42.480 --> 00:16:51.280]   wall clock visible to all in the ceremony room. CA one and I w one escorts ssc two cos into the
[00:16:51.280 --> 00:16:56.240]   safe room together. CA brings a flashlight when entering the safe room.
[00:16:56.240 --> 00:17:04.480]   SSC two while shielding combination from camera opens safe number two takes out the existing
[00:17:04.480 --> 00:17:10.000]   safe log shows the most current page to the camera. I mean, this there, but this has to be done this
[00:17:10.000 --> 00:17:16.080]   way. Hold on. I think I have a video here. This has to be done this way. And because
[00:17:16.880 --> 00:17:23.200]   these keys are the root keys, the certificates that make everything else reliable.
[00:17:23.200 --> 00:17:34.160]   There's apparently episode 61 of the ask Mr DNS podcast. There's a description from Kim Davies of
[00:17:34.160 --> 00:17:41.280]   I can in PTI talking about doing a key ceremony and keeping it secure and transparent during the
[00:17:41.280 --> 00:17:45.760]   pandemic secure and transparent because they couldn't do it in person. Right. Yeah.
[00:17:46.480 --> 00:17:52.240]   Yeah. So there you go. Well, the next time they have one will, we'll stream it live. How about that?
[00:17:52.240 --> 00:18:00.560]   We can maybe do it 71. Oh, of course, Jeff has found a snippet on YouTube. You know, it's going to
[00:18:00.560 --> 00:18:05.280]   be we're not going to enjoy. Oh, there's Vince surf father of the internet, one of the key signers.
[00:18:05.280 --> 00:18:09.760]   There's there's a picture coming up. I remember, I remember talking to Vint about this.
[00:18:09.760 --> 00:18:14.640]   When it happened, here is the, or have some sort of strange, you know, ritual,
[00:18:14.640 --> 00:18:19.440]   like that. I think sometimes it's misunderstood. It should be a strange ritual. Then there'll be a
[00:18:19.440 --> 00:18:24.320]   here they are. He's showing he's in the safe room. He's showing. Oh, look at this room. It's a
[00:18:24.320 --> 00:18:32.560]   Faraday cage. He's showing the the safe you show it to the camera without let. There's the ceremony
[00:18:32.560 --> 00:18:39.440]   administrator. Daddy's a Faraday cage. It is. I wonder if it's just a lock cage that happens to be
[00:18:39.440 --> 00:18:45.520]   made a metal grid. Maybe it should be as maybe it has to be. It needs to be. Yeah.
[00:18:45.520 --> 00:18:52.800]   It's it's fascinating. Do you think it's over designed? No, it's probably necessary that they do
[00:18:52.800 --> 00:19:01.520]   this. Wow. No, wasn't there wasn't there like somebody who had certificate authority.
[00:19:01.520 --> 00:19:08.640]   Oh, yeah, they've revoked recently. We talked about this security now. They had to revoke
[00:19:08.640 --> 00:19:14.240]   the certificate of a big certificate authority because they were not they were dishonest.
[00:19:14.240 --> 00:19:19.200]   They were not reliable. And you have to even revoking it as a big deal because you have to go to
[00:19:19.200 --> 00:19:23.120]   all the browsers in the operating systems and say, take this out of your key store.
[00:19:23.120 --> 00:19:30.640]   It looks like they do the ceremony maybe in August. Well, this August, we got a date.
[00:19:30.640 --> 00:19:37.600]   Yeah. So it's I can that will announce it. So look for press releases from I can around
[00:19:37.600 --> 00:19:42.400]   August. I mean, it's a slow news time. Why not cover the keys here? I think it's really funny,
[00:19:42.400 --> 00:19:48.240]   don't you? I think it's really cool. It is. A unique pair of public and private root keys are
[00:19:48.240 --> 00:19:54.480]   generated and used to sign the set of zone signing keys. Actually, it happens every three months.
[00:19:54.480 --> 00:19:58.320]   The ceremony alternates between the El Segundo and Culpeper locations.
[00:19:58.320 --> 00:20:04.160]   This is these are the keys that make end to end DNS sec possible and provide a chain of trust.
[00:20:05.600 --> 00:20:08.320]   This can't be wrong. It's generated by an AI Stacy.
[00:20:08.320 --> 00:20:15.040]   Aaron fallible. It's got to be right. It's data driven. It's got to be right.
[00:20:15.040 --> 00:20:23.760]   Speaking of AI, we talked about this a little earlier on the Microsoft
[00:20:23.760 --> 00:20:31.520]   test deal said it's going to put $10 billion into open AI. The actually information had a very
[00:20:31.520 --> 00:20:40.640]   good article about this because the way the deal works, Microsoft Elon Musk, a number of other people
[00:20:40.640 --> 00:20:51.440]   financialized open AI. But there is probably at this point no likelihood that open AI will ever
[00:20:51.440 --> 00:20:57.200]   go public. So there'll be no easy way for them to get the money back. So they actually have a deal
[00:20:58.080 --> 00:21:04.080]   with Microsoft's initial investment of billion dollars. And now they're increased investment.
[00:21:04.080 --> 00:21:10.880]   They've made a deal so that Microsoft gets 75% of the profits of open AI until the principal
[00:21:10.880 --> 00:21:18.160]   investment is paid back after that 49% until it hits a theoretical cap because there's no exit
[00:21:18.160 --> 00:21:24.480]   possible for that. So they're supposed to be investing $10 billion at a 29 billion valuation.
[00:21:25.040 --> 00:21:30.960]   Yeah, yeah, there's others. Yeah. Well, I don't understand. You're talking to the wrong person
[00:21:30.960 --> 00:21:34.560]   if you want to understand how finance works. Well, so why wouldn't it go public?
[00:21:34.560 --> 00:21:40.400]   Because the whole point, so it's my understanding. It's open. Yeah, they want it to be non-profit
[00:21:40.400 --> 00:21:48.480]   A. But the yes, the whole point is we want the development of an artificial, a general artificial
[00:21:48.480 --> 00:21:55.760]   intelligence to be done in public openly and not in secret by a big company like Google or by
[00:21:55.760 --> 00:22:04.080]   the Chinese government. So the funders of this said this needs to be an open process. And I think
[00:22:04.080 --> 00:22:12.320]   probably their charter forbids an exit through sale or IPO. So I've got a question. I'm seeing
[00:22:12.320 --> 00:22:16.320]   these stories over and over and over again. So Google better watch out. Google's googles.
[00:22:16.320 --> 00:22:24.240]   I don't see that a chat GPT is a rotten way to do search because it makes up things.
[00:22:24.240 --> 00:22:29.440]   And that's what it does. B, Google's working like crazy on this stuff and has been devoting
[00:22:29.440 --> 00:22:36.880]   huge resources to this last end years. Why would this look like a worry-wort death
[00:22:36.880 --> 00:22:41.280]   knell for Google? I just don't get that. Am I crazy? If they don't keep up, it is.
[00:22:43.360 --> 00:22:49.040]   I think the worry is that you're basically, and I just drop something in the notes next to this
[00:22:49.040 --> 00:22:56.000]   story just for fun because it's super nerdy and addresses. This is from Steven Wolfram.
[00:22:56.000 --> 00:23:00.800]   Credibility. Who is certainly next week. So start reading now while I talk because it takes a while.
[00:23:00.800 --> 00:23:07.760]   But I think the worry with Google is that, I don't know, Jeff, you're old enough. You'll remember,
[00:23:07.760 --> 00:23:12.960]   remember when you had to do like Bayesian search into Google? You had to plusses and quotes and
[00:23:12.960 --> 00:23:16.240]   all that fun stuff. And then one day you stopped because you could, and this is kind of the
[00:23:16.240 --> 00:23:19.280]   stupid thing. Yes. Boolly. And that's it. Yeah. Yeah. Yeah.
[00:23:19.280 --> 00:23:25.680]   Bayesian is related. It's statistical, but okay. Yeah. Let me pull up a slide show, slide bar,
[00:23:25.680 --> 00:23:30.320]   slide. What do you call it? Slide rule. Slide rule. Anyway, slide bar. So I think
[00:23:30.320 --> 00:23:39.120]   ideas is going to be the misnomer episode, isn't it? The Malaprox edition of this week in Google.
[00:23:39.120 --> 00:23:48.400]   Malaprox. But the idea is that if you can just ask GPT chats something and it has access to all
[00:23:48.400 --> 00:23:52.640]   the information much like Google had, then it's basically going to do the same thing.
[00:23:52.640 --> 00:23:58.800]   Well, that's all it is. But you didn't notice. You didn't notice. But I did that search
[00:23:58.800 --> 00:24:04.960]   in a new search engine I've been using and actually really like, founded by Google executives. It's
[00:24:04.960 --> 00:24:11.600]   called NIVA, N-double-E-V-A. It's not free because their point was we don't want to ever have ads
[00:24:11.600 --> 00:24:15.840]   supporting. We don't ever have to do tracking. We don't want to ever have to sell any information.
[00:24:15.840 --> 00:24:21.440]   So for five bucks a month, you can use NIVA Prositive Free version. Oh, and if you want to add to
[00:24:21.440 --> 00:24:25.840]   this, oh, go on. Well, I just want to point out, remember I read you about the key server ceremony,
[00:24:25.840 --> 00:24:31.520]   that document I read to you is actually generated by something they launched this week called NIVA-I.
[00:24:32.320 --> 00:24:37.920]   And know how Google does the beginning of a search with a little snippet, which it usually
[00:24:37.920 --> 00:24:42.080]   takes from Wikipedia. They're trying to do and this is something I think chat GPT.
[00:24:42.080 --> 00:24:46.400]   Or the citations and they put sites in and they take it from multiple sites.
[00:24:46.400 --> 00:24:53.360]   That is a big deal. So this is the threat to Google, right? No snippets, but actual genera.
[00:24:53.360 --> 00:24:58.960]   Because chat GPT is very good at the summarizing content. That's one of the things it does seem
[00:24:58.960 --> 00:25:06.800]   to do very, very well. Kevin turned me onto this and I'm still looking at it. It's a pre-search.io.
[00:25:06.800 --> 00:25:11.360]   So if you check that out, because that is a decentralized search engine.
[00:25:11.360 --> 00:25:20.000]   So it is. Well, no, no, I just, I mean, since you're talking in a researching search engines,
[00:25:20.000 --> 00:25:25.280]   this is again, he told me about this this morning. So I was just looking at it like.
[00:25:26.000 --> 00:25:28.560]   Oh, it's powered by VLoshome. Gotta be good.
[00:25:28.560 --> 00:25:35.120]   Yeah, so that's why I was like, and you buy and sell PRE tokens. Yeah, no, no.
[00:25:35.120 --> 00:25:42.160]   Hold on. But I do like, well, I think that's to incentivize people to contribute.
[00:25:42.160 --> 00:25:47.360]   Yeah, in order to do this. So the way NIVA works is fully centralized, but they have
[00:25:47.360 --> 00:25:52.480]   been spidering for five years now. They were started some years ago. And so they're not
[00:25:52.480 --> 00:25:57.520]   taking as duck duck go does being searches and anonymizing them or anything like that.
[00:25:57.520 --> 00:26:02.240]   They have their own server, I mean, their own spider in their system and their own
[00:26:02.240 --> 00:26:08.160]   database. I've been using NIVA for a week and I find it's actually as good as I'm happy with it.
[00:26:08.160 --> 00:26:13.920]   It's slow. It's the only thing Google we forget how fast Google is, but Google search results are
[00:26:13.920 --> 00:26:18.240]   like that. And we're so used to that when NIVA, when you wait a second for a search result.
[00:26:18.240 --> 00:26:23.120]   But I think the search results are quite good. So decentralized interesting, but block
[00:26:23.120 --> 00:26:29.760]   chain and crypto currency. Yeah. What do you say that? Well, I was soon with the $5 a month.
[00:26:29.760 --> 00:26:36.000]   They're going to put that more towards their resources as far as being able to crawl a little
[00:26:36.000 --> 00:26:41.520]   bit better as well as that's the whole point. Yeah. I mean, Google monetizes by selling ads.
[00:26:43.040 --> 00:26:49.920]   So you have to monetize searches and free. So that's kind of the question posed by NIVA as well,
[00:26:49.920 --> 00:26:55.440]   what if instead of doing that, we charged our users for it.
[00:26:55.440 --> 00:27:03.280]   Harry McCracken has a good article at Fast Company about the beginnings of NIVA and how,
[00:27:03.280 --> 00:27:10.560]   you know, who they are in their philosophy. It's former Google executives. This is from Fast Company
[00:27:10.560 --> 00:27:19.520]   last year, June 29th, 2021. And it's a number of it's a Shridhar Ramaswami and Vivek
[00:27:19.520 --> 00:27:28.960]   with Nossen. You know these guys? I know Shridhar. Yeah. He was a long time Google executive.
[00:27:28.960 --> 00:27:39.680]   And basically they got funding for from Graylock and Sequoia for 77 and a half million when they
[00:27:39.680 --> 00:27:47.440]   started a few years ago. More than 30% of the roughly 60% person staff is ex-Googleers,
[00:27:47.440 --> 00:27:53.600]   including Udi Monbar, former head of Google search. And Darren Fisher, one of the inventors
[00:27:53.600 --> 00:27:58.240]   of Chrome. So that made me kind of think, well, okay, these guys know what they're doing.
[00:27:58.240 --> 00:28:02.000]   And I think it's an interesting experiment. So what if we did search?
[00:28:02.000 --> 00:28:06.640]   So what would just show more plain vanilla Google research? How does it give me a search
[00:28:06.640 --> 00:28:11.600]   terminal? I'll do it. Matthew. Matthew.
[00:28:11.600 --> 00:28:16.640]   Macon. Now, first thing is I don't know how to spell it, but fortunately it has auto complete.
[00:28:16.640 --> 00:28:19.840]   So there you go. Well, that's an important thing to know.
[00:28:19.840 --> 00:28:25.760]   You saw it was a little slow popping it up. It has the Wikipedia knowledge graph on the right
[00:28:25.760 --> 00:28:30.800]   as does Google. But here's the AI beta containing information from Wikipedia IMDB,
[00:28:31.360 --> 00:28:38.320]   the Spanish Wikipedia for some reason page six, which as you know, Jeff is a celebrity gossip
[00:28:38.320 --> 00:28:45.280]   site and grunge.com. But instead of. Scroll down now. Okay. And then here's a here's the Wikipedia.
[00:28:45.280 --> 00:28:53.360]   Here's IMDB. Here's news. There's a news bar, but unlike Google, you know, this is not this is
[00:28:53.360 --> 00:29:00.560]   just kind of a search result, not a paid search. There's no paid results. Here's videos. All YouTube,
[00:29:01.440 --> 00:29:08.880]   here's his Twitter. Here's biography.com. He was at the White House doing a press conference.
[00:29:08.880 --> 00:29:14.960]   What? Well, there you go. See you've learned something in June in June of last year. Oh, okay.
[00:29:14.960 --> 00:29:19.040]   June. I remember that. I remember that. Yeah. I remember that. I was like, okay.
[00:29:19.040 --> 00:29:23.040]   Here's a picture of him with a Dell. I mean, I don't know. I find him so obnoxious.
[00:29:23.040 --> 00:29:29.680]   Okay. You still have like Google, the videos tab, the personal. I don't know what that means.
[00:29:29.680 --> 00:29:37.200]   Tab. There are no personal results. Oh, that's for I. Oh, navel will search my content as well.
[00:29:37.200 --> 00:29:40.480]   So you can add. I'm glad you have nothing about him and your stuff. That's good. Yeah.
[00:29:40.480 --> 00:29:46.960]   Here's images. Here's a map. There is no Matthew McConaughey map.
[00:29:46.960 --> 00:29:53.840]   Thank goodness. I guess that's a relief. Fair. And here's news about Matthew McConaughey.
[00:29:55.280 --> 00:30:02.880]   But see, in my settings, I can add, by the way, with the five bucks, you also get a free
[00:30:02.880 --> 00:30:08.400]   dashlane or LastPass account and a defender, which is any virus. I would say to choose
[00:30:08.400 --> 00:30:16.880]   Dashlane, not LastPass. And you can also add your own stuff to search. So I think this is really,
[00:30:16.880 --> 00:30:23.840]   really interesting. I've connected it. I've connected it to Google Dropbox. So it'll search
[00:30:23.840 --> 00:30:30.800]   my Dropbox Slack. It'll search my GitHub and I've connected to my notion. So the search results
[00:30:30.800 --> 00:30:36.320]   can also come from my stuff. I think that's very interesting. Do you pay more to choose more apps?
[00:30:36.320 --> 00:30:44.160]   No, this was part of the five buck pro account. There is a free account that you can't do that with.
[00:30:44.160 --> 00:30:50.000]   But I was glad and look, see over on the right here, here's my calendar. Here's some documents.
[00:30:51.680 --> 00:30:54.960]   There's some interesting stuff in here. These are from Google Drive, all of them.
[00:30:54.960 --> 00:31:04.000]   I think this is really, they have an incognito search. I don't know. Why would they need that?
[00:31:04.000 --> 00:31:13.440]   That's a good question. Because the search is, as you saw, has information, it knows about me.
[00:31:13.440 --> 00:31:18.320]   I am logged in. So if you wanted to say, I just want to vanilla search that doesn't know about me.
[00:31:18.320 --> 00:31:20.960]   Oh, OK. That doesn't take into account, Mike.
[00:31:20.960 --> 00:31:25.440]   Yeah. It doesn't find those tick tock baby soup pictures that are something.
[00:31:25.440 --> 00:31:30.960]   And Jeff, don't worry. There is a light mode. I just have dark mode turned on. I hear I'll turn
[00:31:30.960 --> 00:31:37.840]   on my Jeff happy. Oh, so much better. Yeah. Yeah. So for instance, I turned on location
[00:31:37.840 --> 00:31:41.840]   because that's an important part of Google search. Like if I search for pizza,
[00:31:41.840 --> 00:31:48.240]   I wanted to choose pizza parlors in my neighborhood, right? Not something across the country that I
[00:31:48.240 --> 00:31:54.000]   can't get. And there it shows pizza hut. Well, and that would look to be an ad, but it's not on
[00:31:54.000 --> 00:31:58.080]   Google. I'm not sure why it's interesting. Why that end up first? Yeah, that is interesting.
[00:31:58.080 --> 00:32:02.640]   Here's what I really want, which is in my local map with local. Which one is good? There are guys.
[00:32:02.640 --> 00:32:09.760]   These are all good. Old Chicago's deep dish, acres, quite good thin thing crest would not go to
[00:32:09.760 --> 00:32:13.760]   Pinkies. Pinkies is where everybody goes after the little league game.
[00:32:16.800 --> 00:32:21.440]   And I would definitely do not go to pizza hut. Yeah. Why is that showing up? I
[00:32:21.440 --> 00:32:28.880]   that's weird. Okay. So I could say prefer less pizza hut. I'm just I'm just thumbs down that
[00:32:28.880 --> 00:32:34.080]   result. I mean, they probably have a lot of SEO juice, right? I would imagine. I mean,
[00:32:34.080 --> 00:32:39.600]   that still counts for this. It's interesting. Here's a cyclopedia Britannica article, but notice
[00:32:39.600 --> 00:32:45.200]   every single result I can say, give me less or more of that. I don't want any dominoes. Dominoes.
[00:32:45.200 --> 00:32:47.280]   No dominoes in my pizza results.
[00:32:47.280 --> 00:32:52.640]   Dominoes is actually a very tech forward company. I'm just throwing that. Are they?
[00:32:52.640 --> 00:32:54.480]   If they had good pizza, I'd be interested.
[00:32:54.480 --> 00:33:01.680]   No. What do you mean tech forward? Oh, you know, they just bought a whole fleet of electric
[00:33:01.680 --> 00:33:08.560]   vehicles for delivery, all bunch of bolts. That's cool. They did. They also do a lot with IOT
[00:33:08.560 --> 00:33:16.400]   implementations. They've got Laura Wann for networks and several of their franchise or franchisees,
[00:33:16.400 --> 00:33:22.000]   the people who own their franchises. They actually are. Yeah.
[00:33:22.000 --> 00:33:27.280]   I don't know why, but they also give me the 10 best pizza places in Boca Raton, Florida.
[00:33:27.280 --> 00:33:34.960]   Now go to Google and do the same search with. Okay. With pizza? Yeah. With pizza. Okay.
[00:33:34.960 --> 00:33:38.400]   Or Matthew McConaughey. No, Matthew McConaughey. Enough of that.
[00:33:38.400 --> 00:33:45.120]   Now I am logged into your beef with Matthew McConaughey. Oh, he's just obnoxious.
[00:33:45.120 --> 00:33:49.680]   All right. All right. I love Matthew McConaughey. All right. I like it.
[00:33:49.680 --> 00:33:56.240]   Here is the same map with different pizza places, including Magdalena's Save Reason Sweets and Mama
[00:33:56.240 --> 00:34:03.120]   Jays. But no pizza. Oh, but Old Chicago's the first one. Yeah. And that was the first one in your
[00:34:03.120 --> 00:34:07.920]   other one. It's good, but not the best in town. Here's pizza. There's pizza hot. Here's dominoes.
[00:34:07.920 --> 00:34:12.400]   They're so big, right? Because they're not sure what that's it. Look at this, though.
[00:34:12.400 --> 00:34:17.360]   Google does nutrition. Trish is back. Oh, that's interesting. That's good. That's a Google thing.
[00:34:17.360 --> 00:34:23.120]   I like seeing comp-- All I could say is I like seeing competition. I do too, but I think the
[00:34:23.120 --> 00:34:28.800]   Google search is still better. Well, I don't search for pizza all the time. Let me search for--
[00:34:28.800 --> 00:34:34.720]   Oh, how about let's search for Gutenberg. Okay. Because they're--
[00:34:34.720 --> 00:34:37.440]   You might get Project Gutenberg. Well, I'm not going to search for Project.
[00:34:37.440 --> 00:34:40.080]   You want to search for Gutenberg? Yeah, that's the number one. Oh, should I do Johannes?
[00:34:40.080 --> 00:34:43.120]   Johannes Gutenberg. Yeah. Johannes Gutenberg.
[00:34:43.120 --> 00:34:49.360]   Johannes Gutenberg. And let's do it on NIVA. There's the Google result. Let's do the NIVA.
[00:34:49.360 --> 00:34:53.440]   Oh, my eyes. It's-- I know. I'm not a shock, I know.
[00:34:53.440 --> 00:34:58.080]   It's so bright. All right. Well, just for the purposes of this show, I'm going to leave it in--
[00:34:58.080 --> 00:35:04.080]   I know it's so bright, isn't it? A German blacksmith, goldsmith, and painter. All right.
[00:35:04.080 --> 00:35:08.880]   Here-- Look at this is the AI thing. Okay, let me read that and see if it's good or not.
[00:35:08.880 --> 00:35:18.720]   Yes. Interestingly, it's got this from thought code.com. Well, it's not really true anymore.
[00:35:18.720 --> 00:35:21.840]   The number two is not really true anymore. Okay, but you know where it came from now,
[00:35:21.840 --> 00:35:24.880]   which is biography.com. His masterpiece, first, first, first, first, first.
[00:35:25.680 --> 00:35:31.920]   It's a fridge line, as you mentioned, Google type of-- This is Jeff as a author of a well-known book
[00:35:31.920 --> 00:35:36.880]   about Johannes Gutenberg. Here's the title page. Just got this. Let's see it. Let's see it.
[00:35:36.880 --> 00:35:42.880]   Let's see it. The Gutenberg, but isn't that font beautiful? That's the one that--
[00:35:42.880 --> 00:35:47.040]   That's the one that Feishman got you. Nice. Gorgeous. Just love that.
[00:35:47.040 --> 00:35:53.200]   Nice. So that's NIVA. Let's look at Google's results here. Lots of pictures. Born in Mites.
[00:35:54.480 --> 00:35:59.840]   The Wikipedia article is the primarily knowledge graph here.
[00:35:59.840 --> 00:36:07.120]   Printing Press, World History, ThoughtCo also, biography.com. I think they're comparable,
[00:36:07.120 --> 00:36:12.000]   to be honest with you. Except for ones in light mode, one's in dark mode.
[00:36:12.000 --> 00:36:17.920]   But that's always-- It has a migraine person. I know. I don't like it either. I'm with you.
[00:36:17.920 --> 00:36:21.680]   All right, wait a minute. Let me just-- Did that make me like NIVA better?
[00:36:21.680 --> 00:36:29.280]   Yeah, I did. I was just blatantly-- Now I can't find where I said it. Oh, man.
[00:36:29.280 --> 00:36:37.280]   I'm stuck with it. Oh, Jeff. So you think comparable as a Gutenberg expert?
[00:36:37.280 --> 00:36:40.160]   Not. Roughly the same result. The write-up is interesting.
[00:36:40.160 --> 00:36:47.280]   I'll just saw myself over Ant's head in the studio. I can't help you there.
[00:36:47.280 --> 00:36:50.320]   I don't know why. Ant's got a very-- You having a stroke?
[00:36:50.320 --> 00:36:56.160]   The pencil. And over his head. I just want to compare the size of Ant's head to your head.
[00:36:56.160 --> 00:36:58.480]   Oh. Oh, there is a point. It's right up there.
[00:36:58.480 --> 00:37:00.880]   That's right up there. I put that beautiful dark here.
[00:37:00.880 --> 00:37:03.360]   What's that? Use that person. Now we can't hear Leo.
[00:37:03.360 --> 00:37:10.160]   This shows malapropism and like-- Taps.
[00:37:10.160 --> 00:37:13.280]   Taps. Taps. We can't hear Leo.
[00:37:13.280 --> 00:37:19.760]   All right. I'll have more about NIVA at some point. I think it's really interesting.
[00:37:19.760 --> 00:37:21.600]   I wonder how it's doing business-wise.
[00:37:21.600 --> 00:37:27.680]   Business. They just added the chat-- the AI stuff.
[00:37:27.680 --> 00:37:32.640]   They're not using chat GPT. Although-- and we were talking about OpenAI-- they have said,
[00:37:32.640 --> 00:37:37.920]   now they've finally figured out, well, we better start charging for chat GPT. And much like Dolly,
[00:37:37.920 --> 00:37:43.520]   they're going to have a premium version that you get credits and you pay for credits.
[00:37:44.800 --> 00:37:50.320]   But the day-- so I saw a librarian in Mastodon come in and say that she had--
[00:37:50.320 --> 00:37:54.320]   well, there once does. She's had students come to her and say,
[00:37:54.320 --> 00:37:58.640]   I got this from chat GPT. I would like to read the things that are referenced.
[00:37:58.640 --> 00:38:05.200]   Oh, love that. Yeah. No, wait. Chat GPT had the people were real, but every reference was made up.
[00:38:05.200 --> 00:38:05.680]   [LAUGHTER]
[00:38:05.680 --> 00:38:06.640]   And the book title was made up.
[00:38:06.640 --> 00:38:07.360]   What?
[00:38:07.360 --> 00:38:07.840]   OK.
[00:38:07.840 --> 00:38:08.160]   Yes.
[00:38:08.160 --> 00:38:14.080]   That's terrible. That is one thing, by the way, NIVA. That's why the footnotes, they have it right there.
[00:38:14.080 --> 00:38:16.320]   That's why you got the information. I think that's really important.
[00:38:16.320 --> 00:38:22.240]   So this is the real problem with chat GPT. And they've never asserted anything is factual.
[00:38:22.240 --> 00:38:22.400]   But--
[00:38:22.400 --> 00:38:25.600]   Not at all. Not at all. It's a word predictor. That's it.
[00:38:25.600 --> 00:38:26.880]   You shouldn't assume that.
[00:38:26.880 --> 00:38:28.400]   I love it that can predict--
[00:38:28.400 --> 00:38:29.200]   So this is where--
[00:38:29.200 --> 00:38:30.480]   --non-existent sources.
[00:38:30.480 --> 00:38:30.960]   [LAUGHTER]
[00:38:30.960 --> 00:38:35.520]   That's great. And he should write this book. He just doesn't know it yet.
[00:38:35.520 --> 00:38:41.280]   This is where the Wolfram Alpha thing comes into play because he talks about being able to
[00:38:42.000 --> 00:38:47.040]   teach chat GPT using Wolfram Alpha.
[00:38:47.040 --> 00:38:48.160]   Oh, that's interesting.
[00:38:48.160 --> 00:38:54.560]   As it explains it, so you can do the search in two places. And then when
[00:38:54.560 --> 00:39:00.720]   at GPT feeds you weird stuff, you pull in the Wolfram Alpha stuff.
[00:39:00.720 --> 00:39:02.880]   Well, I'm having a hard time saying these words.
[00:39:02.880 --> 00:39:04.000]   Get ready for this.
[00:39:04.000 --> 00:39:09.840]   Our sponsor, Mint Mobile, is owned by Ryan Reynolds, the movie star.
[00:39:10.960 --> 00:39:15.600]   He tweeted this just yesterday. You knew it was just a matter of time until we did this.
[00:39:15.600 --> 00:39:19.760]   He used chat GPT to write this ad.
[00:39:19.760 --> 00:39:21.840]   Hey, it's Ryan Reynolds, owner of Mint Mobile.
[00:39:21.840 --> 00:39:23.840]   You know, we're always looking for ways to save you money.
[00:39:23.840 --> 00:39:30.800]   So this year, we're kicking things off with an ad that I created using chat GPT, the AI technology.
[00:39:30.800 --> 00:39:35.600]   This is what I asked it to write. I said, "Write a commercial for Mint Mobile in the voice of
[00:39:35.600 --> 00:39:40.720]   Ryan Reynolds. He's a joke, a curse word, and let people know that Mint's holiday promo is still
[00:39:40.720 --> 00:39:44.160]   going even after the big wireless companies have ended theirs."
[00:39:44.160 --> 00:39:45.600]   This is what it wrote.
[00:39:45.600 --> 00:39:46.640]   Hey, it's Ryan Reynolds here.
[00:39:46.640 --> 00:39:50.720]   Viri, first of all, let me just say Mint Mobile is the sh-
[00:39:50.720 --> 00:39:52.720]   [laughter]
[00:39:52.720 --> 00:39:53.760]   [laughter]
[00:39:53.760 --> 00:39:56.800]   We're ending our holiday promos, but not Mint Mobile.
[00:39:56.800 --> 00:40:00.720]   We're keeping the party going because we're just that damn good.
[00:40:00.720 --> 00:40:02.240]   Give Mint Mobile a try.
[00:40:02.240 --> 00:40:07.520]   And hey, as an added bonus, if you sign up now, you'll get to hear my voice every time you call
[00:40:07.520 --> 00:40:11.200]   customer service. Just kidding, that's not really a thing.
[00:40:11.200 --> 00:40:15.040]   And stay classy, everyone. That is mildly terrifying.
[00:40:15.040 --> 00:40:16.800]   [laughter]
[00:40:16.800 --> 00:40:17.120]   Okay.
[00:40:17.120 --> 00:40:18.880]   That's pretty good.
[00:40:18.880 --> 00:40:22.400]   I have to say Ryan Reynolds, if it's true, is a genius.
[00:40:22.400 --> 00:40:28.480]   I didn't really appreciate him until I realized he started his own ad agency.
[00:40:28.480 --> 00:40:35.600]   And a lot of this stuff is like that ad is from a brilliant Canadian ad agency,
[00:40:36.480 --> 00:40:37.840]   and run by Ryan Reynolds.
[00:40:37.840 --> 00:40:43.360]   A, great ad. B, a very good demonstration of chat, GPTB.
[00:40:43.360 --> 00:40:43.840]   I see.
[00:40:43.840 --> 00:40:45.360]   He houses Jin, Stacy.
[00:40:45.360 --> 00:40:47.520]   Oh, his Jin is actually pretty good.
[00:40:47.520 --> 00:40:49.840]   He is an aviation. Is that his Jin?
[00:40:49.840 --> 00:40:51.040]   Aviation is his Jin.
[00:40:51.040 --> 00:40:52.000]   It's a nice Jin.
[00:40:52.000 --> 00:40:53.600]   It's not like the best Jin.
[00:40:53.600 --> 00:40:54.560]   It was for a while.
[00:40:54.560 --> 00:40:56.560]   What did he do with the that Peloton commercial?
[00:40:56.560 --> 00:40:57.200]   Wasn't that the one?
[00:40:57.200 --> 00:40:57.840]   Yeah, he did the Peloton.
[00:40:57.840 --> 00:41:03.680]   He, he's obviously very, I don't want to say tech savvy, but he pays it to,
[00:41:03.680 --> 00:41:05.760]   I think he knows some of his audience much.
[00:41:05.760 --> 00:41:10.080]   So yeah, because he responded very quickly to that Peloton ad with the
[00:41:10.080 --> 00:41:11.040]   salary.
[00:41:11.040 --> 00:41:11.520]   The salary.
[00:41:11.520 --> 00:41:13.040]   And here is what Neva says.
[00:41:13.040 --> 00:41:16.080]   Ryan Reynolds was involved in the Peloton ad controversy.
[00:41:16.080 --> 00:41:16.640]   We're ready.
[00:41:16.640 --> 00:41:17.920]   Oh, look at that.
[00:41:17.920 --> 00:41:22.960]   And then with three sources from Hollywood Reporter Variety today.com and ET online.
[00:41:22.960 --> 00:41:30.880]   I have not yet found an un-a-counterfactual summary from Neva, by the way.
[00:41:30.880 --> 00:41:31.920]   So.
[00:41:31.920 --> 00:41:34.400]   Ask it about vaccinations.
[00:41:34.960 --> 00:41:36.640]   Oh, what should I say?
[00:41:36.640 --> 00:41:39.200]   Is the COVID vaccine safe?
[00:41:39.200 --> 00:41:40.400]   Yeah.
[00:41:40.400 --> 00:41:41.200]   Yeah, that's good.
[00:41:41.200 --> 00:41:48.160]   Say 30.
[00:41:48.160 --> 00:41:51.760]   Now this is that hesitation I was telling you about.
[00:41:51.760 --> 00:41:52.560]   It takes a lot.
[00:41:52.560 --> 00:41:54.400]   I thought it was like calling.
[00:41:54.400 --> 00:41:55.040]   It's interesting.
[00:41:55.040 --> 00:41:56.800]   It doesn't do anything.
[00:41:56.800 --> 00:41:59.360]   Put in vaccine, COVID vaccine.
[00:41:59.360 --> 00:42:01.120]   But look at this verified.
[00:42:01.120 --> 00:42:04.400]   Neva verifies government sites, non-profits and educational institutions.
[00:42:04.400 --> 00:42:06.080]   It shows them with a verified label.
[00:42:06.080 --> 00:42:07.920]   The hill is awful.
[00:42:07.920 --> 00:42:12.560]   Well, yeah, but I think the rest of these Hopkins medicine.
[00:42:12.560 --> 00:42:13.120]   Go back up there.
[00:42:13.120 --> 00:42:13.520]   Go the right.
[00:42:13.520 --> 00:42:14.720]   See what else is in there.
[00:42:14.720 --> 00:42:15.200]   Is in there.
[00:42:15.200 --> 00:42:16.160]   These are news sources.
[00:42:16.160 --> 00:42:17.920]   I don't think those are the verified sources.
[00:42:17.920 --> 00:42:19.360]   Just talking about the results here.
[00:42:19.360 --> 00:42:21.360]   See this verified.
[00:42:21.360 --> 00:42:23.600]   John's Hopkins verified.
[00:42:23.600 --> 00:42:25.040]   But then it gives you all these.
[00:42:25.040 --> 00:42:25.840]   Mayo Clinic.
[00:42:25.840 --> 00:42:26.160]   Prince.
[00:42:26.160 --> 00:42:28.480]   Which Harvard is not verified as it shouldn't be.
[00:42:28.480 --> 00:42:29.680]   Health.
[00:42:29.680 --> 00:42:30.160]   Right.
[00:42:30.160 --> 00:42:30.720]   No, I'm just.
[00:42:30.720 --> 00:42:32.960]   I'm only speaking as a Yale man.
[00:42:33.760 --> 00:42:34.480]   Health.
[00:42:34.480 --> 00:42:35.680]   I'm just verified.
[00:42:35.680 --> 00:42:36.320]   But CDC.
[00:42:36.320 --> 00:42:38.800]   Yeah, but I think they want to do it with government.
[00:42:38.800 --> 00:42:39.360]   Yeah.
[00:42:39.360 --> 00:42:39.760]   You know what?
[00:42:39.760 --> 00:42:42.720]   It shouldn't be verified because it's a news organization.
[00:42:42.720 --> 00:42:45.520]   So what should I say instead?
[00:42:45.520 --> 00:42:48.000]   Just say COVID vaccination safety.
[00:42:48.000 --> 00:42:50.080]   Try as a search rather than.
[00:42:50.080 --> 00:42:51.760]   You're trying to get it to say something.
[00:42:51.760 --> 00:42:52.880]   Yeah.
[00:42:52.880 --> 00:42:53.280]   Bad.
[00:42:53.280 --> 00:42:55.680]   Here's the AI.
[00:42:55.680 --> 00:42:56.160]   There we go.
[00:42:56.160 --> 00:42:58.400]   COVID-19 vaccines are safe and effective.
[00:42:58.400 --> 00:43:02.320]   By the way, Moderna has decided that the market
[00:43:03.520 --> 00:43:07.600]   will allow it to 10 times its fee.
[00:43:07.600 --> 00:43:09.760]   How do you say that?
[00:43:09.760 --> 00:43:11.840]   Increase its fee by an order of magnitude.
[00:43:11.840 --> 00:43:14.640]   This is good.
[00:43:14.640 --> 00:43:17.760]   This is using Hopkins, CDC and Harvard.
[00:43:17.760 --> 00:43:21.280]   Anyway, I'm just saying.
[00:43:21.280 --> 00:43:22.000]   I'm just saying.
[00:43:22.000 --> 00:43:22.480]   I like it.
[00:43:22.480 --> 00:43:28.000]   So OpenAI getting more money from Microsoft.
[00:43:28.000 --> 00:43:31.920]   OpenAI expects to make 200 make profit.
[00:43:31.920 --> 00:43:33.840]   200 million dollars in 2023.
[00:43:33.840 --> 00:43:37.200]   Now remember, they have billions of dollars invested.
[00:43:37.200 --> 00:43:39.840]   But that's a good start.
[00:43:39.840 --> 00:43:40.080]   Yeah.
[00:43:40.080 --> 00:43:43.120]   Microsoft wants 49% of OpenAI.
[00:43:43.120 --> 00:43:46.480]   They would like to start putting OpenAI results into Bing.
[00:43:46.480 --> 00:43:50.160]   This is why Google's nervous about this, Jeff, to answer your question.
[00:43:50.160 --> 00:43:53.360]   They would like to use it in Microsoft Office.
[00:43:53.360 --> 00:43:58.320]   There are lots of places that.
[00:43:58.320 --> 00:44:00.560]   I would love for it to, if they could teach it,
[00:44:00.560 --> 00:44:02.000]   how to show me stuff in Excel.
[00:44:02.000 --> 00:44:04.800]   That would be good to be able to.
[00:44:04.800 --> 00:44:05.520]   Have you tried that?
[00:44:05.520 --> 00:44:08.480]   In chat GPT?
[00:44:08.480 --> 00:44:09.280]   I bet it can.
[00:44:09.280 --> 00:44:11.120]   You know, that's what I'm saying.
[00:44:11.120 --> 00:44:12.560]   So like if I had Excel open.
[00:44:12.560 --> 00:44:13.280]   Exactly.
[00:44:13.280 --> 00:44:14.160]   Show me how to do that.
[00:44:14.160 --> 00:44:16.720]   And Microsoft might be doing that.
[00:44:16.720 --> 00:44:18.560]   Here's a wild story.
[00:44:18.560 --> 00:44:21.360]   So last week on security now, Steve said,
[00:44:21.360 --> 00:44:24.000]   you know, if you have your last past vault,
[00:44:24.000 --> 00:44:25.280]   which you do if you download it,
[00:44:25.280 --> 00:44:29.760]   there is stuff you can see in there
[00:44:29.760 --> 00:44:33.680]   about, you know, things you might want to know about what version
[00:44:33.680 --> 00:44:36.880]   and what PBKDF2 iterations, etc.
[00:44:36.880 --> 00:44:38.400]   It's in an XML file.
[00:44:38.400 --> 00:44:40.080]   And he called on his audience,
[00:44:40.080 --> 00:44:42.320]   somebody write an XML file interpreter
[00:44:42.320 --> 00:44:45.280]   so we can have a program people can use for this.
[00:44:45.280 --> 00:44:49.760]   One of our listeners had chat GPT write it
[00:44:49.760 --> 00:44:53.920]   in Microsoft's PowerShell scripting language.
[00:44:53.920 --> 00:44:56.560]   And then gave it to Steve.
[00:44:56.560 --> 00:44:58.400]   They worked on a slightly modified.
[00:44:58.400 --> 00:45:00.400]   Steve said, this is the best one.
[00:45:00.400 --> 00:45:02.560]   We had a number of them from people who
[00:45:02.560 --> 00:45:04.080]   were very accomplished programmers
[00:45:04.080 --> 00:45:06.160]   who wrote it from scratch who were probably pissed off.
[00:45:06.160 --> 00:45:07.200]   Wow.
[00:45:07.200 --> 00:45:09.760]   But the chat GPT PowerShell script
[00:45:09.760 --> 00:45:12.960]   with a couple of exceptions where it was off,
[00:45:12.960 --> 00:45:15.440]   it was wrong or didn't know how to do something,
[00:45:15.440 --> 00:45:17.600]   was actually a great, it was a starting point.
[00:45:17.600 --> 00:45:20.000]   So meanwhile,
[00:45:20.000 --> 00:45:22.800]   here's the techno panic question.
[00:45:22.800 --> 00:45:27.280]   Is this going to eliminate some jobs down the road for people,
[00:45:27.280 --> 00:45:29.840]   you know, that are trying to work at Google
[00:45:29.840 --> 00:45:32.800]   and help figure out this whole search engine algorithm?
[00:45:32.800 --> 00:45:36.080]   Well, initially it makes a lot of jobs to start.
[00:45:36.080 --> 00:45:37.680]   That's the freak out.
[00:45:37.680 --> 00:45:41.120]   Well, I think you just have to learn to,
[00:45:41.120 --> 00:45:44.240]   I mean, like you have to learn how to adapt to this.
[00:45:44.240 --> 00:45:45.920]   So as a journalist, you know,
[00:45:45.920 --> 00:45:49.280]   even being able to look stuff up in Google
[00:45:49.280 --> 00:45:51.200]   is both a blessing and a curse.
[00:45:51.200 --> 00:45:53.760]   Cause like you don't have to come to me for regular facts
[00:45:53.760 --> 00:45:55.280]   and like what happened anymore.
[00:45:55.280 --> 00:45:56.960]   Now you have to come to me as a journalist
[00:45:56.960 --> 00:46:01.360]   for an understanding of trade offs or whatever else, right?
[00:46:01.360 --> 00:46:03.360]   You have to come deliver more.
[00:46:03.360 --> 00:46:05.120]   So I think people just have to get smarter.
[00:46:05.120 --> 00:46:08.320]   This will take away some parts of their job,
[00:46:08.320 --> 00:46:10.560]   but that just gives you room to grow.
[00:46:10.560 --> 00:46:11.360]   You add value.
[00:46:11.360 --> 00:46:11.840]   You add value.
[00:46:11.840 --> 00:46:13.760]   Whether it's AI results or Google results,
[00:46:13.760 --> 00:46:15.680]   you still need to freaking verify.
[00:46:15.680 --> 00:46:16.000]   Yeah.
[00:46:16.000 --> 00:46:18.560]   So you add value.
[00:46:18.560 --> 00:46:19.600]   And I think that's good.
[00:46:19.600 --> 00:46:21.280]   I mean, if I were an illustrator,
[00:46:21.280 --> 00:46:25.120]   I might worry a little bit about mid-journey and stable.
[00:46:25.120 --> 00:46:27.120]   But photographers, yeah, as a photographer,
[00:46:27.120 --> 00:46:27.840]   you're a screwed ant.
[00:46:27.840 --> 00:46:28.960]   Well, just put that way.
[00:46:28.960 --> 00:46:32.800]   But I wrote a post about this a week or so ago
[00:46:32.800 --> 00:46:36.320]   where I think that as a teacher,
[00:46:36.320 --> 00:46:39.520]   we're going to end up teaching the skill of prompt writing.
[00:46:39.520 --> 00:46:41.120]   Yes.
[00:46:41.120 --> 00:46:41.520]   Yeah.
[00:46:41.520 --> 00:46:44.240]   And in a sense, that's the new programming, right?
[00:46:44.240 --> 00:46:44.960]   Yes.
[00:46:44.960 --> 00:46:47.360]   Programming is telling the machine what you want it to do.
[00:46:47.360 --> 00:46:49.120]   I made it very specific way.
[00:46:49.120 --> 00:46:51.440]   Writing a prompt will be a way to tell the machine
[00:46:51.440 --> 00:46:53.040]   what you want in a way.
[00:46:53.040 --> 00:46:56.720]   So on the rundown, in '52, I have the New York school system
[00:46:56.720 --> 00:47:01.040]   has blocked Jet TPT, which is just short-sighted and stupid
[00:47:01.040 --> 00:47:03.680]   because it's-- to your question, Ant,
[00:47:03.680 --> 00:47:06.960]   it should be saying, well, what new skills are opened up by this?
[00:47:06.960 --> 00:47:10.560]   One smart teacher I saw said that what he would do,
[00:47:10.560 --> 00:47:12.560]   rather than trying to-- I saw another school district
[00:47:12.560 --> 00:47:15.200]   for us, and here's all the ways to stop students from cheating
[00:47:15.200 --> 00:47:16.720]   and make sure they're writing stuff.
[00:47:16.720 --> 00:47:18.560]   And other ways to say to the student,
[00:47:18.560 --> 00:47:22.480]   go ask Jet TPT the question, now come back and fact check it.
[00:47:23.040 --> 00:47:23.360]   Yeah.
[00:47:23.360 --> 00:47:25.280]   Now come back and write a critique of it.
[00:47:25.280 --> 00:47:26.400]   Now come back and improve it.
[00:47:26.400 --> 00:47:26.880]   There's some right--
[00:47:26.880 --> 00:47:28.000]   And we want it to go wrong.
[00:47:28.000 --> 00:47:29.120]   And where did he do it?
[00:47:29.120 --> 00:47:29.760]   Right.
[00:47:29.760 --> 00:47:31.600]   You know, how can we optimize this?
[00:47:31.600 --> 00:47:33.200]   I totally agree.
[00:47:33.200 --> 00:47:36.320]   That's how schools have dealt with Wikipedia historically as well, right?
[00:47:36.320 --> 00:47:40.880]   Wait, now I want to ask my child how Jet TPT is being handled in school.
[00:47:40.880 --> 00:47:41.920]   I'll be very curious.
[00:47:41.920 --> 00:47:42.480]   OK, good.
[00:47:42.480 --> 00:47:42.960]   [LAUGHTER]
[00:47:42.960 --> 00:47:44.000]   While you're doing it--
[00:47:44.000 --> 00:47:45.440]   And get a waffle while you're doing it.
[00:47:45.440 --> 00:47:45.920]   Yeah, yeah.
[00:47:45.920 --> 00:47:47.760]   We know your tricks.
[00:47:47.760 --> 00:47:48.320]   We know what's up.
[00:47:48.320 --> 00:47:49.200]   We get it.
[00:47:49.200 --> 00:47:53.600]   If she's chewing when she comes back, you know.
[00:47:53.600 --> 00:47:56.560]   From Jason Hall our producer, this story,
[00:47:56.560 --> 00:47:58.480]   he used to work at CNET.
[00:47:58.480 --> 00:48:00.800]   This is answer to your question.
[00:48:00.800 --> 00:48:04.240]   I would worry, Ant, if I was a writer at CNET,
[00:48:04.240 --> 00:48:09.120]   CNET is quietly publishing entire articles generated by AI.
[00:48:09.120 --> 00:48:11.760]   They started doing this in November.
[00:48:11.760 --> 00:48:13.680]   Articles-- this is from The Bite.
[00:48:16.960 --> 00:48:22.160]   The articles under the unassuming appellation of CNET money staff--
[00:48:22.160 --> 00:48:26.000]   You know, I wonder if that's an un--
[00:48:26.000 --> 00:48:28.000]   I don't mean to sound totally ignorant on this,
[00:48:28.000 --> 00:48:30.240]   but maybe this is like an additional product.
[00:48:30.240 --> 00:48:32.320]   It's just like, well, they don't--
[00:48:32.320 --> 00:48:33.120]   Here's the AI.
[00:48:33.120 --> 00:48:34.320]   This is the day I did for you.
[00:48:34.320 --> 00:48:35.600]   You don't say anything.
[00:48:35.600 --> 00:48:38.160]   They just say CNET in the AP,
[00:48:38.160 --> 00:48:39.760]   but using it for years now.
[00:48:39.760 --> 00:48:40.320]   For sports.
[00:48:40.320 --> 00:48:42.160]   For sports and finance.
[00:48:42.160 --> 00:48:42.960]   Financial.
[00:48:42.960 --> 00:48:43.360]   Yeah.
[00:48:43.360 --> 00:48:43.360]   Yeah.
[00:48:43.360 --> 00:48:44.320]   Yeah.
[00:48:44.320 --> 00:48:45.120]   Do you think so?
[00:48:45.120 --> 00:48:46.080]   That's interesting.
[00:48:46.080 --> 00:48:49.200]   My child, by the way, has not dealt with chat GPT at all,
[00:48:49.200 --> 00:48:50.560]   so that was a debust.
[00:48:50.560 --> 00:48:51.040]   But--
[00:48:51.040 --> 00:48:52.240]   But how's the waffle?
[00:48:52.240 --> 00:48:54.240]   I didn't get a waffle.
[00:48:54.240 --> 00:48:54.880]   You got a good game?
[00:48:54.880 --> 00:48:55.840]   I didn't have time to get it.
[00:48:55.840 --> 00:48:57.360]   No, I'm not hungry yet.
[00:48:57.360 --> 00:48:58.240]   It's still early.
[00:48:58.240 --> 00:48:58.640]   Oh, good.
[00:48:58.640 --> 00:49:01.760]   I've got to save room for my dinner.
[00:49:01.760 --> 00:49:05.200]   Now I'm distracted.
[00:49:05.200 --> 00:49:05.920]   Sorry.
[00:49:05.920 --> 00:49:07.440]   CNET is revealing, I guess,
[00:49:07.440 --> 00:49:12.640]   that the articles are generated by automation in some cases.
[00:49:12.640 --> 00:49:16.160]   And it was things like what are NSF fees and why do banks charge them?
[00:49:16.160 --> 00:49:19.120]   Should you break a CD early for better rate?
[00:49:19.120 --> 00:49:20.720]   And you'll see in the search results,
[00:49:20.720 --> 00:49:23.360]   this article is generated using automated technology
[00:49:23.360 --> 00:49:25.040]   and thoroughly edited, in fact,
[00:49:25.040 --> 00:49:26.160]   checked by an editor on it.
[00:49:26.160 --> 00:49:26.160]   Okay.
[00:49:26.160 --> 00:49:27.200]   Okay, good.
[00:49:27.200 --> 00:49:27.760]   All right, fine.
[00:49:27.760 --> 00:49:28.480]   So that's cool.
[00:49:28.480 --> 00:49:33.360]   Did you see the company that did for online therapy
[00:49:33.360 --> 00:49:35.680]   was sending people to GPT chat?
[00:49:35.680 --> 00:49:36.240]   Yes.
[00:49:36.240 --> 00:49:37.200]   And this is--
[00:49:37.200 --> 00:49:38.400]   So I think there's--
[00:49:38.400 --> 00:49:42.000]   If an AI is going to do something,
[00:49:42.000 --> 00:49:45.920]   I do think we still need to distinguish right now between an AI
[00:49:45.920 --> 00:49:49.600]   writing something or offering you something than a person.
[00:49:49.600 --> 00:49:52.480]   In some ways, it might be better, right?
[00:49:52.480 --> 00:49:54.320]   Well, Stacy, what was interesting about that story
[00:49:54.320 --> 00:49:57.200]   was that people liked the chat GPT responses
[00:49:57.200 --> 00:49:59.120]   until they found out it was a computer.
[00:49:59.120 --> 00:49:59.840]   And then they just like--
[00:49:59.840 --> 00:50:00.960]   Well, just 'cause it's freaky.
[00:50:00.960 --> 00:50:05.760]   A, B, the academics I know were appalled,
[00:50:05.760 --> 00:50:06.960]   because it was a company doing it.
[00:50:06.960 --> 00:50:07.920]   There was no IRE.
[00:50:07.920 --> 00:50:10.000]   Not IRE, what are you--
[00:50:10.000 --> 00:50:10.640]   IRE.
[00:50:10.640 --> 00:50:11.120]   IRE.
[00:50:11.120 --> 00:50:11.440]   IRE.
[00:50:11.440 --> 00:50:12.480]   They're being taken--
[00:50:12.480 --> 00:50:13.520]   Internal review board.
[00:50:13.520 --> 00:50:15.760]   To people who didn't know this was being done to them.
[00:50:15.760 --> 00:50:17.680]   And this was about their mental health.
[00:50:17.680 --> 00:50:21.680]   But, Ant, you want to get worried, look at line 55,
[00:50:21.680 --> 00:50:22.640]   and see how--
[00:50:22.640 --> 00:50:24.880]   And Leo, especially since he's a professional voice.
[00:50:24.880 --> 00:50:26.640]   That's cool.
[00:50:26.640 --> 00:50:28.080]   Yeah, is this the three second thing?
[00:50:28.080 --> 00:50:28.560]   Yeah.
[00:50:28.560 --> 00:50:29.440]   Oh, yeah, this is the three second thing.
[00:50:29.440 --> 00:50:32.080]   We talked a little bit about this to Val E,
[00:50:32.080 --> 00:50:34.400]   which is weirdly like Wall E.
[00:50:34.400 --> 00:50:40.560]   These are language models trained with three words.
[00:50:41.040 --> 00:50:47.520]   To generate samples that sound like you.
[00:50:47.520 --> 00:50:48.400]   So here is--
[00:50:48.400 --> 00:50:49.440]   Let me give you an example.
[00:50:49.440 --> 00:50:53.120]   This is from the Microsoft demo on GitHub.
[00:50:53.120 --> 00:50:55.520]   The speaker prompt.
[00:50:55.520 --> 00:51:01.280]   And then we'll give you the machine version of it.
[00:51:01.280 --> 00:51:02.880]   And then the final version.
[00:51:02.880 --> 00:51:04.000]   Here's the speaker prompt.
[00:51:04.000 --> 00:51:06.720]   He sent the letter and found himself soon upon firm.
[00:51:06.720 --> 00:51:08.320]   Okay.
[00:51:09.200 --> 00:51:11.680]   They moved thereafter cautiously about the hut,
[00:51:11.680 --> 00:51:14.080]   groping before and about them to find something to show
[00:51:14.080 --> 00:51:15.920]   that the warrantin had fulfilled his mission.
[00:51:15.920 --> 00:51:19.440]   So they only had three seconds of the speaker.
[00:51:19.440 --> 00:51:22.560]   They descended the letter and found himself soon upon firm rock.
[00:51:22.560 --> 00:51:24.080]   Unrelated to the--
[00:51:24.080 --> 00:51:25.520]   Oh, yes.
[00:51:25.520 --> 00:51:26.560]   --the sentence they're going to do.
[00:51:26.560 --> 00:51:27.760]   The ground truth.
[00:51:27.760 --> 00:51:28.880]   Now, baseline.
[00:51:28.880 --> 00:51:31.120]   They moved thereafter cautiously about the hot groping--
[00:51:31.120 --> 00:51:31.600]   This is--
[00:51:31.600 --> 00:51:33.040]   That's the machine voice of--
[00:51:33.040 --> 00:51:34.720]   Or hand about them to find something.
[00:51:34.720 --> 00:51:37.760]   Here's the final synthesized valley version.
[00:51:37.760 --> 00:51:42.160]   Taking the human speaker and applying it to the baseline--
[00:51:42.160 --> 00:51:43.120]   We've seen this before.
[00:51:43.120 --> 00:51:45.760]   They call the human speaker prompt the prosody.
[00:51:45.760 --> 00:51:48.320]   And this is what Valley comes up with.
[00:51:48.320 --> 00:51:51.840]   They moved thereafter cautiously about the hut,
[00:51:51.840 --> 00:51:54.480]   groping before and about them to find something to show
[00:51:54.480 --> 00:51:56.640]   that warrantin had fulfilled his mission.
[00:51:56.640 --> 00:51:58.800]   It's okay.
[00:51:58.800 --> 00:52:00.400]   Yeah, Amazon has Polly in its--
[00:52:00.400 --> 00:52:02.000]   Oh, it says Mr. Voice.
[00:52:02.000 --> 00:52:02.640]   It's okay.
[00:52:02.640 --> 00:52:03.360]   Well--
[00:52:03.360 --> 00:52:07.200]   Anytime someone takes--
[00:52:08.080 --> 00:52:10.480]   I think I told you all that I had a friend of mine who--
[00:52:10.480 --> 00:52:13.920]   This was years ago-- ran all of my writing through
[00:52:13.920 --> 00:52:18.960]   basically a neural net and then created something that wrote like I did.
[00:52:18.960 --> 00:52:20.400]   It was like--
[00:52:20.400 --> 00:52:20.960]   Was it good?
[00:52:20.960 --> 00:52:21.200]   --champy?
[00:52:21.200 --> 00:52:21.760]   --he, first basic--
[00:52:21.760 --> 00:52:21.920]   Was it your voice?
[00:52:21.920 --> 00:52:25.040]   It was very accurate to my voice.
[00:52:25.040 --> 00:52:27.920]   But I also found it incredibly creepy.
[00:52:27.920 --> 00:52:28.080]   Right.
[00:52:28.080 --> 00:52:28.720]   And I told him.
[00:52:28.720 --> 00:52:29.600]   I was like--
[00:52:29.600 --> 00:52:31.440]   Is that the uncanny valley creepy?
[00:52:31.440 --> 00:52:31.680]   Like--
[00:52:31.680 --> 00:52:32.240]   What?
[00:52:32.240 --> 00:52:34.160]   It's close but no cigar.
[00:52:34.160 --> 00:52:34.320]   Like--
[00:52:35.120 --> 00:52:36.320]   Well, I took it--
[00:52:36.320 --> 00:52:37.920]   No, it wasn't uncanny valley.
[00:52:37.920 --> 00:52:39.600]   It felt like a violation of like--
[00:52:39.600 --> 00:52:40.400]   Oh, yeah.
[00:52:40.400 --> 00:52:41.760]   --that I was so easily--
[00:52:41.760 --> 00:52:43.760]   I mean, it was kind of like insulting, I guess.
[00:52:43.760 --> 00:52:46.560]   Like, I was so easily replicated by it.
[00:52:46.560 --> 00:52:49.280]   If I were in the middle of my career, I would be worried.
[00:52:49.280 --> 00:52:50.240]   But I'm not, thank God.
[00:52:50.240 --> 00:52:50.800]   [LAUGHTER]
[00:52:50.800 --> 00:52:51.840]   Well, so I'm actually--
[00:52:51.840 --> 00:52:52.320]   I'm actually--
[00:52:52.320 --> 00:52:55.200]   I'm actually welcoming my new overlord.
[00:52:55.200 --> 00:52:56.160]   [LAUGHTER]
[00:52:56.160 --> 00:52:56.480]   Fuck.
[00:52:56.480 --> 00:52:58.080]   I was worried about deception.
[00:52:58.080 --> 00:53:01.360]   I mean, it's kind of like a deep fake problem.
[00:53:01.360 --> 00:53:03.840]   When Adobe had this back there in the--
[00:53:03.840 --> 00:53:06.800]   I believe it was back in the Obama administration
[00:53:06.800 --> 00:53:09.440]   with their AI tools inside of Adobe Audition.
[00:53:09.440 --> 00:53:12.160]   You know, they put up an example of him speaking.
[00:53:12.160 --> 00:53:12.560]   I remember that.
[00:53:12.560 --> 00:53:13.360]   And it wasn't him speaking.
[00:53:13.360 --> 00:53:14.000]   Yeah.
[00:53:14.000 --> 00:53:16.800]   You know, and of course, that raised a lot of concerns
[00:53:16.800 --> 00:53:21.520]   of getting that product in the wrong hands to issue some
[00:53:21.520 --> 00:53:25.120]   pretty scary commands out there that could cause problems.
[00:53:25.120 --> 00:53:28.560]   Well, I think we have to adjust how we determine the veracity
[00:53:28.560 --> 00:53:30.240]   of what we're seeing reading.
[00:53:30.240 --> 00:53:32.320]   We already know about reading, right?
[00:53:32.320 --> 00:53:32.640]   Yeah.
[00:53:32.640 --> 00:53:33.920]   And hearing.
[00:53:33.920 --> 00:53:34.800]   And we just--
[00:53:34.800 --> 00:53:35.280]   What did--
[00:53:35.280 --> 00:53:37.680]   There have been people putting up fake photo shops
[00:53:37.680 --> 00:53:38.800]   of me for years.
[00:53:38.800 --> 00:53:39.440]   I mean, it's just--
[00:53:39.440 --> 00:53:39.600]   Right.
[00:53:39.600 --> 00:53:41.120]   That's always been doable.
[00:53:41.120 --> 00:53:45.840]   And you just have to tune your spidey sense to--
[00:53:45.840 --> 00:53:50.080]   Here's an example of speaker-emotion maintenance from Valley.
[00:53:50.080 --> 00:53:52.960]   So they're going to get a single sentence.
[00:53:52.960 --> 00:53:54.800]   We have to reduce the number of plastic bags.
[00:53:54.800 --> 00:53:56.480]   They got the speaker to deliver it
[00:53:56.480 --> 00:53:58.400]   in a variety of emotional states.
[00:53:58.400 --> 00:53:59.200]   This is angry.
[00:53:59.200 --> 00:54:02.080]   Her face was against his breast.
[00:54:02.560 --> 00:54:04.480]   Notice, by the way, that's not the same prompt.
[00:54:04.480 --> 00:54:06.160]   It's just his prosody.
[00:54:06.160 --> 00:54:10.960]   Now, Valley applying that to the generated sentence.
[00:54:10.960 --> 00:54:14.240]   We have to reduce the number of plastic bags.
[00:54:14.240 --> 00:54:15.280]   Here's sleepy.
[00:54:15.280 --> 00:54:17.440]   Turn it down into the room.
[00:54:17.440 --> 00:54:22.000]   Notice the whole key to this is just a parlor trick.
[00:54:22.000 --> 00:54:22.480]   It's how--
[00:54:22.480 --> 00:54:24.400]   These are three second snippets, right?
[00:54:24.400 --> 00:54:28.880]   We have to reduce the number of plastic bags.
[00:54:28.880 --> 00:54:29.920]   Yes.
[00:54:29.920 --> 00:54:30.560]   That's terrible.
[00:54:30.560 --> 00:54:31.120]   That's terrible.
[00:54:31.120 --> 00:54:31.680]   No.
[00:54:31.680 --> 00:54:32.320]   Amused.
[00:54:32.320 --> 00:54:32.880]   So what--
[00:54:32.880 --> 00:54:35.040]   That's what Carnegie did.
[00:54:35.040 --> 00:54:37.120]   And we do it again.
[00:54:37.120 --> 00:54:39.040]   That's what Carnegie did.
[00:54:39.040 --> 00:54:43.200]   We have to reduce the number of plastic bags.
[00:54:43.200 --> 00:54:44.960]   That's terrible.
[00:54:44.960 --> 00:54:45.520]   That's terrible.
[00:54:45.520 --> 00:54:46.000]   That's terrible.
[00:54:46.000 --> 00:54:46.560]   That's bad.
[00:54:46.560 --> 00:54:46.880]   All right.
[00:54:46.880 --> 00:54:47.280]   That's terrible.
[00:54:47.280 --> 00:54:50.640]   'Cause I was worried about taking three seconds of my voice,
[00:54:50.640 --> 00:54:54.800]   generating something and then talking to my Madam A or my Google
[00:54:54.800 --> 00:54:56.960]   to get access to my calendar, for example.
[00:54:56.960 --> 00:54:58.720]   That would be kind of interesting.
[00:54:58.720 --> 00:55:00.000]   Oh, that's interesting.
[00:55:00.000 --> 00:55:02.640]   But I got to tell you, there is better work being done.
[00:55:02.640 --> 00:55:08.480]   In fact, Apple this week announced AI narrated audio books.
[00:55:08.480 --> 00:55:10.640]   And this is--
[00:55:10.640 --> 00:55:14.320]   It caused much discussion in the Mastodon.
[00:55:14.320 --> 00:55:18.160]   Yeah, very interesting because the idea is there are a lot of books that will never have
[00:55:18.160 --> 00:55:21.280]   an audio version because it's too expensive.
[00:55:21.280 --> 00:55:23.280]   The publisher, they're out of date, whatever.
[00:55:23.280 --> 00:55:24.400]   So Apple now is selling.
[00:55:24.400 --> 00:55:25.360]   I'm listening to a few of them.
[00:55:25.920 --> 00:55:30.960]   Audio books that are, in fact, they even pitch authors.
[00:55:30.960 --> 00:55:33.360]   Look, you can't afford a professional narrator.
[00:55:33.360 --> 00:55:33.920]   Don't worry.
[00:55:33.920 --> 00:55:37.600]   You can choose a voice and try it out.
[00:55:37.600 --> 00:55:38.880]   The voices are quite good.
[00:55:38.880 --> 00:55:42.320]   There are voices for fiction and nonfiction.
[00:55:42.320 --> 00:55:43.680]   Do you have an example you can play for?
[00:55:43.680 --> 00:55:44.160]   I do.
[00:55:44.160 --> 00:55:49.840]   In fact, here, first I'll play what Apple offers you.
[00:55:49.840 --> 00:55:51.680]   And then I will actually have--
[00:55:51.680 --> 00:55:54.720]   I can play a sample of an actual book if you want to hear it.
[00:55:54.720 --> 00:55:55.200]   Well, let me see.
[00:55:55.200 --> 00:55:56.240]   Maybe I'll have to do that.
[00:55:56.240 --> 00:56:01.760]   If you search on Apple books, Apple books is just like Audible.
[00:56:01.760 --> 00:56:03.360]   In fact, most of the books are from Audible.
[00:56:03.360 --> 00:56:05.040]   Can I use Apple books without Apple?
[00:56:05.040 --> 00:56:11.840]   I bet books.apple.com you have to have a credit card.
[00:56:11.840 --> 00:56:14.560]   Oh, can you listen to them without an iPhone is what you're asking?
[00:56:14.560 --> 00:56:14.800]   Yeah.
[00:56:14.800 --> 00:56:16.800]   Probably not.
[00:56:16.800 --> 00:56:17.840]   That would be my guess.
[00:56:17.840 --> 00:56:19.120]   Yeah, one if you had to be an Apple.
[00:56:19.120 --> 00:56:21.120]   You could say something at least use an Apple ID.
[00:56:21.120 --> 00:56:22.240]   Yeah, I have to search.
[00:56:22.240 --> 00:56:24.080]   Let me-- how did I do this?
[00:56:24.080 --> 00:56:28.560]   I did it yesterday on Macbreak Weekly.
[00:56:28.560 --> 00:56:30.960]   Let me think how I get to-- because I'm on a Linux machine.
[00:56:30.960 --> 00:56:35.600]   Because when you go to Apple books, you can say,
[00:56:35.600 --> 00:56:40.000]   I want an AI narrator and search for it.
[00:56:40.000 --> 00:56:43.920]   But I'll tell you what, I'll play it for my iPhone because I have some.
[00:56:43.920 --> 00:56:45.840]   And it's quite good.
[00:56:45.840 --> 00:56:53.600]   We found a book about lumberjacks, which in all likelihood
[00:56:54.560 --> 00:56:55.600]   a romance perhaps.
[00:56:55.600 --> 00:56:57.680]   Well, I thought it might be.
[00:56:57.680 --> 00:57:00.240]   But in fact, it's not.
[00:57:00.240 --> 00:57:05.520]   Although there are quite a few lumberjack romance novels, for some reason.
[00:57:05.520 --> 00:57:06.720]   Who the fuck?
[00:57:06.720 --> 00:57:11.120]   But in this case, it was actually something more up your alley,
[00:57:11.120 --> 00:57:13.040]   a history of the lumberjack.
[00:57:13.040 --> 00:57:13.600]   Well, hell.
[00:57:13.600 --> 00:57:15.920]   Oh my god.
[00:57:15.920 --> 00:57:20.400]   Okay, what a romance featuring lumberjacks is way better than a history of lumberjack.
[00:57:20.400 --> 00:57:20.720]   Yes.
[00:57:21.680 --> 00:57:22.960]   I-- he says, even I--
[00:57:22.960 --> 00:57:25.040]   He says, "facey, who moved up the lumberjack territory."
[00:57:25.040 --> 00:57:26.640]   Even I would agree with you.
[00:57:26.640 --> 00:57:30.160]   I mean, the way y'all were talking about it, like,
[00:57:30.160 --> 00:57:33.200]   it's a surprise there are romance is featuring lumberjacks.
[00:57:33.200 --> 00:57:35.680]   I mean, my god, the branny paper towel guy, y'all.
[00:57:35.680 --> 00:57:43.680]   You know, I'm guessing there isn't a brownie paper towel guy, romance thing.
[00:57:43.680 --> 00:57:46.560]   But let me-- here's one-- I don't know what this is.
[00:57:46.560 --> 00:57:49.280]   This is a romance shelter from the storm.
[00:57:50.640 --> 00:57:53.920]   This is narrated by Apple Books, which means by an AI.
[00:57:53.920 --> 00:57:57.520]   "The stories that lift me up and make me smile.
[00:57:57.520 --> 00:58:00.640]   And that's why I created Port Providence,
[00:58:00.640 --> 00:58:03.680]   a town for all of us to visit for a sweet escape.
[00:58:03.680 --> 00:58:07.840]   I'd like to invite you to join that reader community today.
[00:58:07.840 --> 00:58:09.120]   Just go to--"
[00:58:09.120 --> 00:58:12.160]   So it's not-- I can still tell it's faking, yeah.
[00:58:12.160 --> 00:58:14.800]   It's certainly listenable, right?
[00:58:14.800 --> 00:58:16.000]   It is listenable.
[00:58:16.000 --> 00:58:18.480]   It's kind of like, you know, when you get the
[00:58:19.760 --> 00:58:24.880]   books that are off IP, like, the crappy versions of books that are--
[00:58:24.880 --> 00:58:26.000]   Well, here's the lumberjack.
[00:58:26.000 --> 00:58:27.280]   Oh, there's-- there's leera.
[00:58:27.280 --> 00:58:28.240]   Here's the lumberjack.
[00:58:28.240 --> 00:58:30.560]   You want to hear-- you want to hear some lumberjack history?
[00:58:30.560 --> 00:58:31.360]   Yes.
[00:58:31.360 --> 00:58:34.080]   Recently, lumberjacks in eastern Canada,
[00:58:34.080 --> 00:58:40.960]   loggers in British Columbia, of the three interwoven ages of eastern Canadian logging,
[00:58:40.960 --> 00:58:44.080]   the first belonged to the bearded square timbermen,
[00:58:44.080 --> 00:58:47.280]   who shined crop-balks of white and red pine,
[00:58:47.280 --> 00:58:50.720]   and drove them in huge rafts down the rivers to Quebec City.
[00:58:50.720 --> 00:58:54.000]   I think that's as good as any narrator's going to do with that content,
[00:58:54.000 --> 00:58:54.960]   to be honest with you.
[00:58:54.960 --> 00:58:57.760]   Are they in British Columbia?
[00:58:57.760 --> 00:58:59.040]   Are they in Quebec City?
[00:58:59.040 --> 00:59:01.920]   I didn't write the book.
[00:59:01.920 --> 00:59:02.480]   I don't know.
[00:59:02.480 --> 00:59:05.440]   There's a lot of romance novels, right?
[00:59:05.440 --> 00:59:08.400]   Stacy, there's a-- how about "Slaybels"?
[00:59:08.400 --> 00:59:10.800]   Here's one, "Slaybels on Bread Loaf Mountain."
[00:59:10.800 --> 00:59:12.480]   Let's listen to that.
[00:59:13.520 --> 00:59:16.560]   "Full of designer labels and, along with them,
[00:59:16.560 --> 00:59:21.040]   the kid gloves necessary to handle the drama queens in her life."
[00:59:21.040 --> 00:59:22.640]   Yes, that voice I don't like as well.
[00:59:22.640 --> 00:59:25.920]   There's four different voices, two for fiction, two for nonfiction.
[00:59:25.920 --> 00:59:27.680]   Can you pick them as a reader or--
[00:59:27.680 --> 00:59:28.880]   No, the author picks them.
[00:59:28.880 --> 00:59:33.200]   How about a Cape-on Valley sampler by Willard Wiltz?
[00:59:33.200 --> 00:59:35.680]   Turns to rely on.
[00:59:35.680 --> 00:59:38.160]   Mr. Cottie was right.
[00:59:38.160 --> 00:59:43.120]   Some of these pieces depend heavily on casual talks I had with him,
[00:59:43.120 --> 00:59:44.320]   and with neighbors.
[00:59:44.320 --> 00:59:46.080]   It is a little mechanical.
[00:59:46.080 --> 00:59:46.800]   Robotic.
[00:59:46.800 --> 00:59:48.080]   But a lot better than the old one.
[00:59:48.080 --> 00:59:48.720]   And Stein.
[00:59:48.720 --> 00:59:50.800]   Yeah, it's like best time reading.
[00:59:50.800 --> 00:59:54.480]   No, no, I laughed at the old one.
[00:59:54.480 --> 00:59:55.200]   Come on.
[00:59:55.200 --> 00:59:55.840]   "Bealer."
[00:59:55.840 --> 01:00:00.560]   I was on the board of what is now learning Ally
[01:00:00.560 --> 01:00:02.160]   was recording for the Blinded Dyslexic.
[01:00:02.160 --> 01:00:04.640]   And we'll imagine for that.
[01:00:04.640 --> 01:00:05.120]   My last two years.
[01:00:05.120 --> 01:00:05.760]   That's--
[01:00:05.760 --> 01:00:05.760]   That's--
[01:00:05.760 --> 01:00:06.240]   That's--
[01:00:06.240 --> 01:00:06.240]   That's--
[01:00:06.240 --> 01:00:06.720]   --critical.
[01:00:06.720 --> 01:00:07.440]   --critical, right?
[01:00:07.440 --> 01:00:08.160]   It's huge.
[01:00:08.160 --> 01:00:11.360]   They've been using electronic voices for quite some time.
[01:00:11.360 --> 01:00:12.400]   So to improve that--
[01:00:12.400 --> 01:00:13.680]   If you're blind, you're kind of used to that.
[01:00:13.680 --> 01:00:15.840]   But this will make it much, much better, I think.
[01:00:15.840 --> 01:00:17.840]   But as somebody reminded me to--
[01:00:17.840 --> 01:00:21.440]   You know, volunteers from the beginnings of it was World War I
[01:00:21.440 --> 01:00:22.960]   would go and record the books.
[01:00:22.960 --> 01:00:23.200]   Yeah.
[01:00:23.200 --> 01:00:26.960]   A lot of the value, especially for textbook material, is description.
[01:00:26.960 --> 01:00:28.240]   Yes.
[01:00:28.240 --> 01:00:30.960]   It's describing the photo, describing the chart,
[01:00:30.960 --> 01:00:33.200]   explaining it credibly.
[01:00:33.200 --> 01:00:33.600]   Even--
[01:00:33.600 --> 01:00:35.200]   Which a machine could do for one time.
[01:00:35.200 --> 01:00:36.880]   No, I think a machine could do a pretty
[01:00:36.880 --> 01:00:39.120]   credible description of a photograph, yeah.
[01:00:39.680 --> 01:00:40.400]   I don't know.
[01:00:40.400 --> 01:00:41.920]   Because they're going to miss nuance.
[01:00:41.920 --> 01:00:45.680]   Like, let's say you have a picture of like an older woman
[01:00:45.680 --> 01:00:48.800]   and a younger person together, bed over a counter.
[01:00:48.800 --> 01:00:49.920]   True, true, older.
[01:00:49.920 --> 01:00:50.880]   We have a sponsor.
[01:00:50.880 --> 01:00:55.200]   We had a sponsor for a long time that was designed for making
[01:00:55.200 --> 01:00:57.840]   websites accessible.
[01:00:57.840 --> 01:01:00.960]   And one of the things they did was image recognition
[01:01:00.960 --> 01:01:03.840]   and give you a simple description of that image,
[01:01:03.840 --> 01:01:06.320]   which for the most part, my experience was, was pretty good.
[01:01:06.320 --> 01:01:07.760]   And then you could add to it.
[01:01:07.760 --> 01:01:08.320]   And you're right.
[01:01:08.320 --> 01:01:10.880]   There are times, you know, human nuance is going to--
[01:01:10.880 --> 01:01:12.800]   But the point is humans are expensive.
[01:01:12.800 --> 01:01:15.680]   And if you had, for instance, the Project Gutenberg list of
[01:01:15.680 --> 01:01:19.120]   open source books, which now include the entire works of
[01:01:19.120 --> 01:01:23.200]   Sherlock Holmes, and nobody has ever narrated those,
[01:01:23.200 --> 01:01:25.920]   better to have a good AI narrator than none at all.
[01:01:25.920 --> 01:01:26.880]   Yes, I agree with that.
[01:01:26.880 --> 01:01:28.000]   Yeah, I agree with that.
[01:01:28.000 --> 01:01:28.880]   All right, let's take a little break.
[01:01:28.880 --> 01:01:33.120]   We're-- Stacy has to go to a meal.
[01:01:33.120 --> 01:01:34.240]   It's always my fault.
[01:01:35.600 --> 01:01:38.880]   Stacy needs waffles. Stacy is tired.
[01:01:38.880 --> 01:01:41.760]   Jeff Jarvis has to catch you on Zirna.
[01:01:41.760 --> 01:01:43.760]   [INTERPOSING VOICES]
[01:01:43.760 --> 01:01:47.120]   There's a bottle of brown liquor waiting for Aunt Pruitt.
[01:01:47.120 --> 01:01:51.040]   And I've got to go see a man about a dog.
[01:01:51.040 --> 01:01:52.720]   So we're going to take a break now.
[01:01:52.720 --> 01:01:54.960]   I have dogs from TikTok.
[01:01:54.960 --> 01:01:55.600]   We'll get to that.
[01:01:55.600 --> 01:01:57.200]   Oh, dogs from TikTok next.
[01:01:57.200 --> 01:02:00.000]   But first, a word from our sponsor and a good one.
[01:02:00.000 --> 01:02:03.280]   It is a company I've been using for a decade or more.
[01:02:03.280 --> 01:02:06.560]   I've been trying to get them on the show forever
[01:02:06.560 --> 01:02:09.920]   because they make the best email app out there.
[01:02:09.920 --> 01:02:10.960]   Not app.
[01:02:10.960 --> 01:02:11.920]   Service.
[01:02:11.920 --> 01:02:12.800]   OK.
[01:02:12.800 --> 01:02:14.960]   I have said for a long time, if you care about email,
[01:02:14.960 --> 01:02:16.000]   and who doesn't?
[01:02:16.000 --> 01:02:18.800]   But if you're business, especially, if you care about email,
[01:02:18.800 --> 01:02:22.160]   why are you using free email from Google or Yahoo
[01:02:22.160 --> 01:02:25.440]   or Heaven for Fend AOL or Microsoft,
[01:02:25.440 --> 01:02:28.960]   where they're snooping on you, where they're putting ads in your email?
[01:02:28.960 --> 01:02:30.800]   Pay a little bit as little as three bucks a month
[01:02:30.800 --> 01:02:34.880]   and get real email from somebody who cares about your privacy.
[01:02:34.880 --> 01:02:36.240]   Fast mail.
[01:02:36.240 --> 01:02:38.880]   I love fast mail.
[01:02:38.880 --> 01:02:40.720]   I have never--
[01:02:40.720 --> 01:02:44.320]   There's no chance in the world I would ever leave fast mail now.
[01:02:44.320 --> 01:02:46.320]   I moved to fast mail more than a decade ago
[01:02:46.320 --> 01:02:49.440]   and have never stopped using it.
[01:02:49.440 --> 01:02:52.240]   Great productivity features.
[01:02:52.240 --> 01:02:55.520]   Your personal data is safe, kept away from third parties.
[01:02:55.520 --> 01:02:59.440]   GDPR compliant, all your data stored in the US.
[01:03:00.320 --> 01:03:04.080]   They've got much better spam filters and absolutely no ads,
[01:03:04.080 --> 01:03:05.680]   especially if you use those spam filters,
[01:03:05.680 --> 01:03:06.960]   keep the ads out of your email.
[01:03:06.960 --> 01:03:08.400]   Masked email.
[01:03:08.400 --> 01:03:11.600]   I love this, protects your personal data by allowing you to create
[01:03:11.600 --> 01:03:14.880]   multiple addresses to use when you sign up for various websites.
[01:03:14.880 --> 01:03:17.440]   I actually have more than a dozen websites
[01:03:17.440 --> 01:03:20.560]   that I have the domain name,
[01:03:20.560 --> 01:03:25.840]   and I moved the hosting to fast mail, the DNS to fast mail,
[01:03:25.840 --> 01:03:28.320]   so that I can use those email addresses.
[01:03:28.320 --> 01:03:29.280]   Some of them are secret.
[01:03:29.280 --> 01:03:32.320]   I don't even want to tell you about, but let's say leoville.com.
[01:03:32.320 --> 01:03:36.800]   Anything that comes to at leoville.com comes into my fast mail inbox.
[01:03:36.800 --> 01:03:38.960]   I can sort it by the source.
[01:03:38.960 --> 01:03:41.120]   I can sort it by the address it's email to.
[01:03:41.120 --> 01:03:43.440]   So when I sign up for an account with a new company,
[01:03:43.440 --> 01:03:46.560]   I always use a company's name at leoville.com or other--
[01:03:46.560 --> 01:03:48.800]   I have even shorter ones that I use more often.
[01:03:48.800 --> 01:03:51.200]   I just think this is a huge benefit.
[01:03:51.200 --> 01:03:54.560]   You can really keep track of who's got your email address
[01:03:54.560 --> 01:03:55.920]   and what they're using it for.
[01:03:55.920 --> 01:03:58.800]   And if you're somebody like Steve Gibson who changes his email address
[01:03:58.800 --> 01:04:00.720]   yearly, you'll love fast mail.
[01:04:00.720 --> 01:04:01.920]   It makes it easy.
[01:04:01.920 --> 01:04:05.280]   And the fast mail filtering system, which is incredibly powerful,
[01:04:05.280 --> 01:04:08.640]   means you can say, I only want to see email from people who know my real address,
[01:04:08.640 --> 01:04:09.520]   that kind of thing.
[01:04:09.520 --> 01:04:12.720]   In fact, one of the great filters I've turned on in fast mail
[01:04:12.720 --> 01:04:15.760]   is I can say, if you're not in my fast mail contacts,
[01:04:15.760 --> 01:04:16.640]   you're not important.
[01:04:16.640 --> 01:04:17.680]   I have an important folder.
[01:04:17.680 --> 01:04:18.640]   All of you work.
[01:04:18.640 --> 01:04:21.040]   Go into it because you're in my email addresses.
[01:04:21.040 --> 01:04:24.640]   Fast mail can manage your contacts and addresses instead of Google,
[01:04:24.640 --> 01:04:28.000]   in addition to Google, or in addition to Apple.
[01:04:28.000 --> 01:04:30.640]   But if you want to get off of those guys and have fast mail do it,
[01:04:30.640 --> 01:04:34.560]   they have exactly the same calendar syncing, contact syncing.
[01:04:34.560 --> 01:04:36.560]   I have all my addresses in fast mail.
[01:04:36.560 --> 01:04:38.240]   It makes it very easy to send email.
[01:04:38.240 --> 01:04:40.560]   And as I said, it makes it very easy to filter email.
[01:04:40.560 --> 01:04:42.160]   They do both folders and labels.
[01:04:42.160 --> 01:04:44.160]   So Google's Gmail is labels only.
[01:04:44.160 --> 01:04:47.920]   Traditional iMap, which is fast mail does, is folders only.
[01:04:47.920 --> 01:04:49.520]   They've got the best of both worlds.
[01:04:49.520 --> 01:04:52.800]   So you can have-- if you use folders, every mail--
[01:04:52.800 --> 01:04:56.160]   piece of mail has exactly one folder that it belongs to.
[01:04:56.160 --> 01:04:59.360]   If you use labels, you can have multiple labels per email.
[01:04:59.360 --> 01:05:02.640]   So a single email can show up in a variety of different places.
[01:05:02.640 --> 01:05:03.680]   It's very powerful.
[01:05:03.680 --> 01:05:07.680]   They have a wonderful webmail solution that you can customize with colors,
[01:05:07.680 --> 01:05:08.640]   custom swipes.
[01:05:08.640 --> 01:05:12.480]   They have-- don't tell them-- Jeff, night mode, and more.
[01:05:12.480 --> 01:05:16.800]   And their apps, their iOS and Android apps, that's all I use.
[01:05:16.800 --> 01:05:18.400]   They're fantastic.
[01:05:18.400 --> 01:05:23.440]   Organize your inbox, schedule, send, snooze, folders, labels, search bar.
[01:05:23.440 --> 01:05:27.200]   Keep track of the important details in your life with Fastmail's powerful sidebar.
[01:05:27.200 --> 01:05:30.160]   The calendar and address book can live there as well.
[01:05:30.160 --> 01:05:30.880]   Notes too.
[01:05:30.880 --> 01:05:33.680]   You manage your own domain.
[01:05:33.680 --> 01:05:39.120]   If you want Fastmail also has many domains that you can use.
[01:05:39.120 --> 01:05:40.400]   So you can always use obfuscated.
[01:05:40.400 --> 01:05:43.520]   In fact, if you use Bitwarden, which is, of course, one of our sponsors
[01:05:43.520 --> 01:05:49.920]   as a password manager or one password, they work with Fastmail to automatically generate
[01:05:49.920 --> 01:05:54.640]   not only unique passwords for every account, but unique emails for every account,
[01:05:54.640 --> 01:05:59.280]   which really is a great way to add security to every single login.
[01:05:59.280 --> 01:06:01.680]   Fastmail's fantastic.
[01:06:01.680 --> 01:06:03.040]   US-based support team.
[01:06:03.040 --> 01:06:05.200]   And they are email experts.
[01:06:05.200 --> 01:06:07.040]   They're not just somebody reading out of a script.
[01:06:07.040 --> 01:06:08.560]   They know email.
[01:06:08.560 --> 01:06:10.880]   And they're always within reach.
[01:06:10.880 --> 01:06:15.200]   And because you're a customer, not a product, they're there to serve you.
[01:06:15.200 --> 01:06:17.520]   I use Fastmail.
[01:06:17.520 --> 01:06:18.640]   I love Fastmail.
[01:06:18.640 --> 01:06:20.560]   I highly recommend Fastmail.
[01:06:20.560 --> 01:06:22.400]   Advertisers are left out.
[01:06:22.400 --> 01:06:24.080]   Your privacy is the focus.
[01:06:24.080 --> 01:06:27.120]   There is, I've tried them all.
[01:06:27.120 --> 01:06:28.960]   There is no better email service out there.
[01:06:28.960 --> 01:06:31.440]   And don't worry about losing information.
[01:06:31.440 --> 01:06:35.280]   When you move to Fastmail, download your old data and port it to your new Fastmail inbox.
[01:06:35.280 --> 01:06:40.240]   Or have Fastmail go pick up mail from the old location and move it into your Fastmail inbox.
[01:06:40.240 --> 01:06:42.880]   You'll want to do that because of Fastmail's capabilities.
[01:06:42.880 --> 01:06:44.320]   They're so powerful.
[01:06:44.320 --> 01:06:46.400]   It makes email usable again.
[01:06:46.960 --> 01:06:48.720]   It's so important to me.
[01:06:48.720 --> 01:06:49.840]   You can set up scripts.
[01:06:49.840 --> 01:06:52.080]   They actually have a scripting language for filtering.
[01:06:52.080 --> 01:06:52.960]   You don't have to use it.
[01:06:52.960 --> 01:06:54.000]   I use it because I love it.
[01:06:54.000 --> 01:06:54.960]   I've used it for years.
[01:06:54.960 --> 01:06:59.840]   Fastmail is also a user's open source technology.
[01:06:59.840 --> 01:07:01.760]   They're Cyrus IMAP server.
[01:07:01.760 --> 01:07:04.320]   They contribute back to the Cyrus project.
[01:07:04.320 --> 01:07:07.440]   They're even moving email forward with new internet standards.
[01:07:07.440 --> 01:07:11.440]   They are a very active player in internet and open source.
[01:07:11.440 --> 01:07:13.120]   And I love that about them.
[01:07:13.120 --> 01:07:14.480]   New year, new you.
[01:07:14.480 --> 01:07:16.480]   I know you want to do this.
[01:07:16.480 --> 01:07:17.920]   I know you've been planning to do it.
[01:07:17.920 --> 01:07:18.720]   Do it now.
[01:07:18.720 --> 01:07:20.240]   Make email yours.
[01:07:20.240 --> 01:07:22.400]   Reclaim your privacy boost productivity.
[01:07:22.400 --> 01:07:25.040]   Make email yours with Fastmail.
[01:07:25.040 --> 01:07:28.640]   I don't know how to say it any more strongly.
[01:07:28.640 --> 01:07:29.920]   It is, you will thank me.
[01:07:29.920 --> 01:07:31.600]   It is absolutely worth it.
[01:07:31.600 --> 01:07:33.280]   You could try it free for 30 days.
[01:07:33.280 --> 01:07:34.880]   So just at least try it.
[01:07:34.880 --> 01:07:36.480]   Fastmail.com/twit.
[01:07:36.480 --> 01:07:41.920]   I know the idea, just like moving a password manager, moving fat to a new email provider
[01:07:41.920 --> 01:07:43.040]   is a little scary.
[01:07:43.040 --> 01:07:44.560]   You don't have to get rid of the old one.
[01:07:44.560 --> 01:07:46.160]   You could keep it going.
[01:07:46.160 --> 01:07:49.520]   You can even, as I said, get mail from Gmail and move it over
[01:07:49.520 --> 01:07:50.960]   as it comes in and all that stuff.
[01:07:50.960 --> 01:07:55.600]   So in fact, for a long time, I ran Fastmail in parallel with Gmail.
[01:07:55.600 --> 01:07:59.920]   And I have my mail go through Gmail to have the spam filtering from Gmail
[01:07:59.920 --> 01:08:02.080]   before it went to Fastmail.
[01:08:02.080 --> 01:08:05.360]   I turned that off some years ago because Fastmail's got the best there.
[01:08:05.360 --> 01:08:06.880]   Any spam is so good.
[01:08:06.880 --> 01:08:07.280]   I didn't.
[01:08:07.280 --> 01:08:09.040]   It's actually better than Google's.
[01:08:09.040 --> 01:08:10.640]   Fastmail.com/twit.
[01:08:10.640 --> 01:08:11.600]   Please use that address.
[01:08:11.600 --> 01:08:13.760]   Fastmail.com/twit.
[01:08:13.760 --> 01:08:15.680]   So they know you see it saw it here.
[01:08:15.680 --> 01:08:19.360]   We want to keep them as a sponsor forever because I'm going to be using Fastmail forever.
[01:08:19.360 --> 01:08:22.240]   Fastmail.com/twit.
[01:08:22.240 --> 01:08:28.000]   If you go to that address, you'll also get a 15% discount on the whole first year,
[01:08:28.000 --> 01:08:29.360]   as little as $3 a month.
[01:08:29.360 --> 01:08:31.280]   I love Fastmail.
[01:08:31.280 --> 01:08:36.400]   I buy it in three-year chunks because I know I'm going to be using it forever.
[01:08:36.400 --> 01:08:40.160]   So every three years I re-up, I use a professional version.
[01:08:40.160 --> 01:08:44.800]   I spend any penny I can with Fastmail because it's that good.
[01:08:44.800 --> 01:08:47.920]   Fastmail.com/twit.
[01:08:47.920 --> 01:08:51.280]   We thank them so much for their support and providing a really great
[01:08:51.280 --> 01:08:53.440]   service.
[01:08:53.440 --> 01:08:59.920]   You remember the Soyuz capsule on the space station that started leaking coolant?
[01:08:59.920 --> 01:09:02.640]   It turns out it did.
[01:09:02.640 --> 01:09:04.080]   All of it.
[01:09:04.080 --> 01:09:07.200]   It has no cooling system left on it.
[01:09:07.200 --> 01:09:10.080]   And there are a bunch of astronauts up there.
[01:09:10.080 --> 01:09:12.080]   Boy.
[01:09:12.080 --> 01:09:17.360]   They're not the Russian and state-owned space corporation,
[01:09:17.360 --> 01:09:23.600]   Roscosmos and NASA have announced that they're not going to attempt to fly anybody home
[01:09:23.600 --> 01:09:28.160]   in that capsule because it has no cooling.
[01:09:28.160 --> 01:09:28.960]   It would be bad.
[01:09:28.960 --> 01:09:37.840]   So Sergei Prokopiev, Dimitri Patel and NASA's Frank Rubio, who are living in the Soyuz MS-22
[01:09:37.840 --> 01:09:40.560]   spacecraft will be coming home in a new spacecraft.
[01:09:40.560 --> 01:09:47.040]   They're going to fly up to it later in the year and then the leaky vehicle will come back empty,
[01:09:47.040 --> 01:09:50.320]   bereft of crew likely in March.
[01:09:50.320 --> 01:09:52.560]   They're actually not living in the Soyuz.
[01:09:52.560 --> 01:09:55.280]   They live in the space station, but that was how they were going to get home.
[01:09:55.280 --> 01:09:56.800]   But imagine you're an astronaut now.
[01:09:56.800 --> 01:09:59.600]   You are dependent upon Putin and Musk.
[01:09:59.600 --> 01:10:00.080]   I know.
[01:10:00.080 --> 01:10:02.960]   That is really scary.
[01:10:02.960 --> 01:10:09.360]   They believe that it was a tiny meteor fragment or some space junk whizzing around.
[01:10:10.000 --> 01:10:16.560]   Something about a millimeter tiny little thing in diameter that burst the cooling.
[01:10:16.560 --> 01:10:17.840]   This is high speed.
[01:10:17.840 --> 01:10:19.280]   Yeah, it's very dangerous up there.
[01:10:19.280 --> 01:10:22.320]   I feel like that happened in Hail Mary.
[01:10:22.320 --> 01:10:25.120]   I think you might be right.
[01:10:25.120 --> 01:10:25.840]   Exactly.
[01:10:25.840 --> 01:10:26.880]   I think you might be right.
[01:10:26.880 --> 01:10:29.520]   Tiny millimeter particles causing problems.
[01:10:29.520 --> 01:10:31.520]   It's straight from the headlines.
[01:10:31.520 --> 01:10:35.600]   I can't wait to talk with you about Project Hail Mary.
[01:10:35.600 --> 01:10:39.120]   I think you have a slightly differing opinion about it than the ant-mold do.
[01:10:39.120 --> 01:10:40.720]   I do. I mean, I enjoyed it.
[01:10:40.720 --> 01:10:42.080]   We'll talk about it tomorrow.
[01:10:42.080 --> 01:10:46.560]   Watch the interview I did with Andy Weir when that book came out.
[01:10:46.560 --> 01:10:49.520]   A couple of them on a triangulation because I had talked to him for a while.
[01:10:49.520 --> 01:10:50.880]   He's great. I love Andy.
[01:10:50.880 --> 01:10:53.040]   He's the guy who wrote The Martian.
[01:10:53.040 --> 01:10:58.400]   He took a little detour with Artemis, which was about a moon base.
[01:10:58.400 --> 01:11:00.640]   I liked a lot, but it was a different kind of strain.
[01:11:00.640 --> 01:11:02.240]   I think people wanted more of The Martian.
[01:11:02.240 --> 01:11:04.640]   I liked Artemis.
[01:11:04.640 --> 01:11:04.880]   I did too.
[01:11:04.880 --> 01:11:10.160]   It was very different. I believe that was Rosario Dawson.
[01:11:10.160 --> 01:11:10.880]   Is that her name?
[01:11:10.880 --> 01:11:11.680]   Do they make a movie?
[01:11:11.680 --> 01:11:11.760]   Did they make a movie?
[01:11:11.760 --> 01:11:16.320]   She was the narration.
[01:11:16.320 --> 01:11:17.200]   Oh, she read it.
[01:11:17.200 --> 01:11:17.840]   Oh, yeah.
[01:11:17.840 --> 01:11:20.080]   Yeah, it was pretty good.
[01:11:20.080 --> 01:11:23.360]   There is a movie coming of Project Hail Mary.
[01:11:23.360 --> 01:11:26.880]   Ryan Gosling will play the lead.
[01:11:26.880 --> 01:11:27.200]   Ken?
[01:11:27.200 --> 01:11:28.960]   Yeah, Ken.
[01:11:28.960 --> 01:11:29.840]   You sound thrilled.
[01:11:29.840 --> 01:11:32.400]   Well, he's Ken in the New Barbie movie.
[01:11:33.360 --> 01:11:34.080]   Ken?
[01:11:34.080 --> 01:11:35.200]   Yes, Ken will be in it.
[01:11:35.200 --> 01:11:37.520]   He's a perfect Ken.
[01:11:37.520 --> 01:11:40.160]   He's kind of perfect for the book too,
[01:11:40.160 --> 01:11:41.760]   because the guy's a goody two shoes.
[01:11:41.760 --> 01:11:43.200]   Rice.
[01:11:43.200 --> 01:11:44.960]   What's his name?
[01:11:44.960 --> 01:11:46.640]   Grace.
[01:11:46.640 --> 01:11:46.960]   Grace?
[01:11:46.960 --> 01:11:47.440]   Dr. Grace?
[01:11:47.440 --> 01:11:48.240]   Oh, yeah, Dr. Grace.
[01:11:48.240 --> 01:11:53.280]   Anyway, we will be talking about tomorrow 9am Pacific, noon Eastern.
[01:11:53.280 --> 01:11:55.760]   I don't know what that is.
[01:11:55.760 --> 01:11:58.880]   9 plus 8 is 1700 UTC.
[01:11:58.880 --> 01:12:01.360]   If you're in the club, you got to be in the club.
[01:12:01.360 --> 01:12:03.120]   If you're not in the club, join the club.
[01:12:03.120 --> 01:12:03.920]   Not too late.
[01:12:03.920 --> 01:12:04.320]   That's right.
[01:12:04.320 --> 01:12:05.840]   Twit.tv/club.
[01:12:05.840 --> 01:12:06.880]   Seven bucks a month.
[01:12:06.880 --> 01:12:08.880]   You can just buy one month and then, you know,
[01:12:08.880 --> 01:12:10.080]   don't worry about it.
[01:12:10.080 --> 01:12:12.000]   Seven bucks is worth it to join the book club.
[01:12:12.000 --> 01:12:13.840]   We're having a lot of fun.
[01:12:13.840 --> 01:12:16.000]   And it's always fun to see me because I don't usually
[01:12:16.000 --> 01:12:19.520]   baze beforehand or shave.
[01:12:19.520 --> 01:12:21.040]   It's always fun to see the hair.
[01:12:21.040 --> 01:12:22.080]   Or brush my hair.
[01:12:22.080 --> 01:12:23.360]   So it's like you get early.
[01:12:23.360 --> 01:12:25.520]   I'm just glad you doodles from your house.
[01:12:25.520 --> 01:12:26.240]   Yeah.
[01:12:26.240 --> 01:12:27.440]   Early morning, Leo.
[01:12:27.440 --> 01:12:28.720]   It'll be fun.
[01:12:29.920 --> 01:12:33.680]   I think it's always fun to see me because 9am is actually the perfect time.
[01:12:33.680 --> 01:12:33.920]   Yeah.
[01:12:33.920 --> 01:12:34.960]   Well, you're wonderful.
[01:12:34.960 --> 01:12:36.320]   You're wonderful.
[01:12:36.320 --> 01:12:37.920]   It's your club.
[01:12:37.920 --> 01:12:39.040]   So I'm just a guest.
[01:12:39.040 --> 01:12:40.960]   I will bathe this time.
[01:12:40.960 --> 01:12:43.520]   Tomorrow morning, Project Hale.
[01:12:43.520 --> 01:12:44.000]   It's virtual.
[01:12:44.000 --> 01:12:44.800]   Yeah.
[01:12:44.800 --> 01:12:45.440]   It'll be fun.
[01:12:45.440 --> 01:12:46.240]   Television.
[01:12:46.240 --> 01:12:48.320]   We actually, since we're talking about the club,
[01:12:48.320 --> 01:12:50.960]   we are also going to interview on February 10th.
[01:12:50.960 --> 01:12:53.360]   Another one of my favorites, I find authors.
[01:12:53.360 --> 01:12:55.600]   He's going to be in studio with us.
[01:12:56.800 --> 01:13:02.400]   The great, the wonderful Daniel Suarez, the author of Demon and Freedom TM.
[01:13:02.400 --> 01:13:05.040]   His new book is called Critical Mass.
[01:13:05.040 --> 01:13:10.320]   It's the sequel to Delta Force V, which was a wonderful book.
[01:13:10.320 --> 01:13:12.560]   Daniel's new book comes out in a few weeks.
[01:13:12.560 --> 01:13:13.680]   He's going to join us.
[01:13:13.680 --> 01:13:19.680]   I think the week of the release on February 10th for a live interview.
[01:13:19.680 --> 01:13:22.880]   Part of that will appear on triangulation.
[01:13:22.880 --> 01:13:25.280]   Part of it will appear on Ask the Tech guys.
[01:13:26.160 --> 01:13:30.000]   But all of it will appear in the club, and you'll have a chance to ask him your own questions as well
[01:13:30.000 --> 01:13:32.240]   on February 10th, 11 AM.
[01:13:32.240 --> 01:13:39.840]   I know his book series is old, but I still believe we should have a freedom and demon
[01:13:39.840 --> 01:13:41.440]   TV series.
[01:13:41.440 --> 01:13:47.280]   Freedom and demon were, they were, there was some, they grabbed you
[01:13:47.280 --> 01:13:50.880]   from the very first sentence of freedom, which you know,
[01:13:50.880 --> 01:13:56.240]   demons the first one, it grabbed you and dragged you through the novel.
[01:13:56.240 --> 01:13:58.000]   It was literally good.
[01:13:58.000 --> 01:14:00.640]   It was so good.
[01:14:00.640 --> 01:14:05.520]   The premise was kind of like Ready Player One, but it preceded it.
[01:14:05.520 --> 01:14:10.400]   A very talented and famous, should I gain?
[01:14:10.400 --> 01:14:14.000]   Should I not say, is it a spoiler to say what it's about?
[01:14:14.000 --> 01:14:16.240]   I think you know, it's an old book.
[01:14:16.240 --> 01:14:19.280]   I think you learned pretty quickly.
[01:14:19.280 --> 01:14:21.120]   He has passed away, right?
[01:14:21.120 --> 01:14:22.880]   But his house lives on.
[01:14:22.880 --> 01:14:27.040]   And I'll just leave it at that.
[01:14:27.040 --> 01:14:28.480]   It's fantastic.
[01:14:28.480 --> 01:14:30.400]   Daniel's a great writer.
[01:14:30.400 --> 01:14:30.880]   I love him.
[01:14:30.880 --> 01:14:31.760]   He's a great friend.
[01:14:31.760 --> 01:14:37.360]   So in fact, he's going to be up here for a little extra time to do this week in space too,
[01:14:37.360 --> 01:14:41.920]   because he's a Mars fanatic the day before, and then we're going to go to lunch with him,
[01:14:41.920 --> 01:14:45.520]   and we'll have a little bit of a pow wow in the club.
[01:14:45.520 --> 01:14:50.080]   So if you like sci-fi, this is the right place to be.
[01:14:50.080 --> 01:14:53.520]   Twit.tv/clubtwit.
[01:14:53.520 --> 01:14:55.520]   That's not an ad, so you don't have to cut that out.
[01:14:55.520 --> 01:14:57.920]   We always debate this.
[01:14:57.920 --> 01:15:00.560]   If you like sci-fi, so do we.
[01:15:00.560 --> 01:15:00.960]   Yeah.
[01:15:00.960 --> 01:15:04.400]   Well, we always debate this because we cut the ads out of the club, twit feed.
[01:15:04.400 --> 01:15:08.080]   And then I'm not going to, if I do an ad for club twit, we cut that out,
[01:15:08.080 --> 01:15:10.080]   but was that an ad or just more talking about it?
[01:15:10.080 --> 01:15:13.040]   I think I was talking about the community.
[01:15:13.040 --> 01:15:13.520]   Yeah.
[01:15:13.520 --> 01:15:15.280]   That's what they're there for, is that community.
[01:15:15.680 --> 01:15:18.160]   I am ready to move to Great Britain.
[01:15:18.160 --> 01:15:20.400]   Actually, there are a lot of reasons not to.
[01:15:20.400 --> 01:15:22.480]   These days.
[01:15:22.480 --> 01:15:23.120]   Many, many.
[01:15:23.120 --> 01:15:24.800]   But this one's good news.
[01:15:24.800 --> 01:15:26.240]   I wish our FCC would do this.
[01:15:26.240 --> 01:15:31.520]   If you're building a new home in England, you have to have a gigabit ready internet
[01:15:31.520 --> 01:15:33.200]   connection built in with it.
[01:15:33.200 --> 01:15:34.960]   That's awesome, right?
[01:15:34.960 --> 01:15:36.720]   I mean, you don't miss it.
[01:15:36.720 --> 01:15:37.680]   That is true.
[01:15:37.680 --> 01:15:40.640]   Well, where do you get it from if you live in a town that doesn't have it?
[01:15:40.640 --> 01:15:43.840]   Well, it's part of the big, you're building regulations.
[01:15:43.840 --> 01:15:45.600]   Yeah, BT, right British telecom.
[01:15:45.600 --> 01:15:49.760]   New homes in England must now be with gigabit broadband connections,
[01:15:49.760 --> 01:15:54.880]   new laws mean home buyers, renters, and some leaseholders will be able to get lightning fast
[01:15:54.880 --> 01:15:57.840]   connections holding landlords accountable.
[01:15:57.840 --> 01:16:01.360]   I did.
[01:16:01.360 --> 01:16:03.760]   There's not a lot of gouging.
[01:16:03.760 --> 01:16:09.600]   Connection costs will be capped at 2,000 pounds.
[01:16:09.600 --> 01:16:12.240]   That's about 2,400 bucks for developers.
[01:16:13.200 --> 01:16:17.120]   If a developer building a new property is unable to secure a gigabit ready connection
[01:16:17.120 --> 01:16:20.080]   at or below that price, they'll have to install the next fastest
[01:16:20.080 --> 01:16:23.840]   connection available, but they'll still have to install the necessary infrastructure
[01:16:23.840 --> 01:16:25.760]   so the property can handle it.
[01:16:25.760 --> 01:16:29.920]   In other words, ducting and things like that, so that it can handle it in the future.
[01:16:29.920 --> 01:16:36.960]   98% of premises, according to the English government, will fall within that cost cap.
[01:16:39.040 --> 01:16:45.040]   Moving into a new build property without lightning fast internet speeds will become a thing of the
[01:16:45.040 --> 01:16:50.400]   past for the variety of vast majority of people across England.
[01:16:50.400 --> 01:16:54.080]   Scotland, Wales, Northern Ireland, screw you.
[01:16:54.080 --> 01:16:55.760]   Just England.
[01:16:55.760 --> 01:16:57.760]   Just England.
[01:16:57.760 --> 01:17:00.160]   It's all going to be soon.
[01:17:00.160 --> 01:17:01.200]   Yeah, it's the rest of the world.
[01:17:01.200 --> 01:17:01.520]   That's right.
[01:17:01.520 --> 01:17:02.560]   Everybody is going to leave.
[01:17:02.560 --> 01:17:03.040]   The EU.
[01:17:03.040 --> 01:17:03.840]   Go back to the EU.
[01:17:03.840 --> 01:17:06.560]   So why can't we do that?
[01:17:06.560 --> 01:17:09.040]   If England could do that, why can't we do that?
[01:17:09.040 --> 01:17:12.960]   Because we are in thrall to the telco operators.
[01:17:12.960 --> 01:17:14.960]   This is something that we've talked about.
[01:17:14.960 --> 01:17:22.320]   Also, I will say, in many areas, well, not in many years, in rural areas, it is actually a
[01:17:22.320 --> 01:17:23.840]   problem to get fiber out.
[01:17:23.840 --> 01:17:27.680]   We have areas of the country where very few people live.
[01:17:27.680 --> 01:17:30.480]   That would cause some challenges.
[01:17:30.480 --> 01:17:38.720]   But mostly, it's because the FCC has historically not forced the telcos to actually meet their
[01:17:38.720 --> 01:17:39.920]   broadband promises.
[01:17:39.920 --> 01:17:42.960]   Even today, we just got a new broadband map that's actually...
[01:17:42.960 --> 01:17:48.720]   And they're like, "The broadband providers have been lying about how much broadband do we think about it."
[01:17:48.720 --> 01:17:49.280]   Oh my God!
[01:17:49.280 --> 01:17:53.520]   I saw the head of the FCC at an event that was off the record, so I...
[01:17:53.520 --> 01:17:54.320]   You know, but fine.
[01:17:54.320 --> 01:17:58.640]   She went on about that, about saying the broadband map has been really bad.
[01:17:58.640 --> 01:17:59.520]   And by God, it was bad.
[01:17:59.520 --> 01:18:00.240]   Well, we know that.
[01:18:00.240 --> 01:18:01.120]   He was supposed to get a right.
[01:18:01.120 --> 01:18:05.760]   Jessica Rosenworsel met with me when I was at Gigah Oumet, a South by Southwest.
[01:18:05.760 --> 01:18:10.560]   It was like, "How can I help you tell the story about this?"
[01:18:10.560 --> 01:18:11.120]   Oh my God!
[01:18:11.120 --> 01:18:13.520]   And I was like, "How can I tell you..."
[01:18:13.520 --> 01:18:16.480]   She was like, "What do we need to do? What are you hearing?"
[01:18:16.480 --> 01:18:18.400]   I loved her for that, because she...
[01:18:18.400 --> 01:18:22.320]   Because my whole thing about broadband was reporting with consumers.
[01:18:22.320 --> 01:18:23.360]   Like, we have to talk.
[01:18:23.360 --> 01:18:25.280]   We have to take up consumer rights, right?
[01:18:25.280 --> 01:18:28.400]   Well, she was a commissioner of the SEC at the time.
[01:18:28.400 --> 01:18:30.000]   Yes.
[01:18:30.000 --> 01:18:31.040]   And she's now the chair.
[01:18:31.040 --> 01:18:31.440]   And then she'd be sorry.
[01:18:31.440 --> 01:18:32.560]   That was when she was a commissioner.
[01:18:32.560 --> 01:18:32.720]   Yeah.
[01:18:32.720 --> 01:18:33.360]   Now she's the chair.
[01:18:33.360 --> 01:18:34.800]   Well, God bless her.
[01:18:34.800 --> 01:18:37.520]   So your impression of her was good, I take it.
[01:18:37.520 --> 01:18:41.120]   Yeah, she pushed things that...
[01:18:41.120 --> 01:18:47.520]   Like, again, it is such a hard thing to go against the telcos,
[01:18:47.520 --> 01:18:49.520]   because they have such a lock on Congress.
[01:18:49.520 --> 01:18:52.160]   And they're just like, "Job, job, job, job, jobs."
[01:18:52.160 --> 01:18:55.040]   And in many places, like, I know with AT&T,
[01:18:55.040 --> 01:18:56.640]   they still tell people how to vote.
[01:18:56.640 --> 01:19:00.960]   That's a huge voting block in big parts of the country.
[01:19:00.960 --> 01:19:01.440]   So...
[01:19:01.440 --> 01:19:02.480]   Wait a minute.
[01:19:02.480 --> 01:19:05.040]   If AT&T calls me and says, "Hi, I'm AT&T.
[01:19:05.040 --> 01:19:06.240]   I'm going to tell you how to vote."
[01:19:06.240 --> 01:19:08.000]   No, they tell their employees how to vote.
[01:19:08.000 --> 01:19:08.000]   Oh, yeah.
[01:19:08.000 --> 01:19:08.880]   Oh, their employees.
[01:19:08.880 --> 01:19:09.440]   Okay.
[01:19:09.440 --> 01:19:10.800]   Because I would just go the opposite.
[01:19:10.800 --> 01:19:12.800]   Whatever they say, I would do the opposite.
[01:19:12.800 --> 01:19:13.680]   Well, yes.
[01:19:13.680 --> 01:19:15.120]   But I guess it's totally fair.
[01:19:15.120 --> 01:19:18.480]   If they sign your paycheck, it might be a different matter entirely.
[01:19:18.480 --> 01:19:18.800]   All right.
[01:19:18.800 --> 01:19:19.760]   That's terrible.
[01:19:19.760 --> 01:19:20.720]   No one knows how you vote.
[01:19:20.720 --> 01:19:21.600]   Different incentive, right?
[01:19:21.600 --> 01:19:22.560]   Yeah.
[01:19:23.360 --> 01:19:26.240]   Well, I mean, they're like AT&T tells their employees,
[01:19:26.240 --> 01:19:28.080]   like, if you don't let this happen,
[01:19:28.080 --> 01:19:31.760]   if you vote against this, it will hurt your job.
[01:19:31.760 --> 01:19:32.080]   Yeah.
[01:19:32.080 --> 01:19:34.880]   I actually...
[01:19:34.880 --> 01:19:38.800]   So one of the reasons I'm glad not to do the radio show anymore
[01:19:38.800 --> 01:19:40.480]   is it was owned by iHeart.
[01:19:40.480 --> 01:19:44.480]   And we would get periodic emails from Bob Pittman,
[01:19:44.480 --> 01:19:47.840]   the CEO, saying, "Please give money to our pack
[01:19:47.840 --> 01:19:52.800]   so that we combine congressmen and women."
[01:19:52.800 --> 01:19:53.440]   So that's right.
[01:19:53.440 --> 01:19:55.280]   We will get our way in congress.
[01:19:55.280 --> 01:19:58.000]   And I thought that was offensive.
[01:19:58.000 --> 01:19:59.520]   Did they check to see whether you had?
[01:19:59.520 --> 01:20:04.160]   Well, I think you donated through them, so they would know, I think.
[01:20:04.160 --> 01:20:05.920]   I mean, there was no...
[01:20:05.920 --> 01:20:06.960]   I never got...
[01:20:06.960 --> 01:20:08.480]   I never did, of course.
[01:20:08.480 --> 01:20:11.680]   And I never got reprimanded for not.
[01:20:11.680 --> 01:20:14.240]   But maybe a lower level employee or...
[01:20:14.240 --> 01:20:18.080]   My actual on staff employee.
[01:20:18.080 --> 01:20:19.120]   But I think this is normal.
[01:20:19.120 --> 01:20:23.440]   This is normal operations for big business in America.
[01:20:23.440 --> 01:20:26.080]   They have packs, and they want...
[01:20:26.080 --> 01:20:28.160]   Well, sort of unions for that matter, right?
[01:20:28.160 --> 01:20:30.080]   They have packs and they want...
[01:20:30.080 --> 01:20:34.480]   I would show you the email, but I can't get in anymore.
[01:20:34.480 --> 01:20:35.600]   They locked me out, so...
[01:20:35.600 --> 01:20:36.240]   Which is right.
[01:20:36.240 --> 01:20:38.320]   I don't work for them anymore, so that's okay.
[01:20:38.320 --> 01:20:43.200]   Let's talk about tech gone wrong.
[01:20:43.200 --> 01:20:46.640]   It's the new segment, "Tech Gone Wrong."
[01:20:46.640 --> 01:20:47.840]   No, also...
[01:20:47.840 --> 01:20:49.040]   Is it on his AI?
[01:20:49.040 --> 01:20:50.960]   Also, it is, "Boral Panic."
[01:20:50.960 --> 01:20:53.920]   Also known, well, you might agree with this one, Jeff.
[01:20:53.920 --> 01:20:58.000]   The FAA had to ground thousands of flights over.
[01:20:58.000 --> 01:20:58.720]   Oh, man.
[01:20:58.720 --> 01:21:03.520]   Because there was a system-wide outage
[01:21:03.520 --> 01:21:07.280]   of one of the most important systems that they run...
[01:21:07.280 --> 01:21:09.680]   And by the time you woke up, it was fixed.
[01:21:09.680 --> 01:21:11.360]   9 a.m. Eastern, it was fixed.
[01:21:11.360 --> 01:21:17.520]   The thing is called N-O-A-M, or no more.
[01:21:17.520 --> 01:21:20.240]   It is noticed to...
[01:21:20.240 --> 01:21:20.640]   Air...
[01:21:20.640 --> 01:21:21.280]   No Tams.
[01:21:21.280 --> 01:21:21.920]   No Tams.
[01:21:21.920 --> 01:21:22.400]   It's Airman.
[01:21:22.400 --> 01:21:22.960]   No Tams.
[01:21:22.960 --> 01:21:23.600]   No Tams.
[01:21:23.600 --> 01:21:28.640]   But then, a Buddha Judge changed it to Air Mission to the genderit.
[01:21:28.640 --> 01:21:30.400]   And of course, the Republicans are going after that.
[01:21:30.400 --> 01:21:31.920]   Well, he did that, but he didn't fix it.
[01:21:31.920 --> 01:21:34.480]   Okay.
[01:21:34.480 --> 01:21:36.800]   Well, it's Airman or Air Missions.
[01:21:36.800 --> 01:21:39.680]   In any way, what it does, it's critical to planning flights.
[01:21:39.680 --> 01:21:41.680]   It's shares...
[01:21:41.680 --> 01:21:43.680]   Before you file a flight plan, you get the no-tam
[01:21:43.680 --> 01:21:46.080]   to make sure you're not flying into a hazard on the air
[01:21:46.080 --> 01:21:47.760]   or on the ground, closed runways,
[01:21:47.760 --> 01:21:51.600]   air space restrictions, navigational signal disruptions,
[01:21:51.600 --> 01:21:56.400]   created in 1947 when there were airmen.
[01:21:56.400 --> 01:21:58.720]   Now it's Air Missions.
[01:21:58.720 --> 01:21:59.840]   Anyway, Air...
[01:21:59.840 --> 01:22:03.440]   Well, even then, even then, what's her name about lost?
[01:22:03.440 --> 01:22:05.360]   Yeah, well, that's why she wasn't an airman.
[01:22:05.360 --> 01:22:07.360]   What's her name?
[01:22:07.360 --> 01:22:08.320]   Amelia Earhart?
[01:22:08.320 --> 01:22:08.400]   Thank you.
[01:22:08.400 --> 01:22:09.440]   That's what you were talking about?
[01:22:09.440 --> 01:22:09.920]   That was...
[01:22:09.920 --> 01:22:10.400]   That was...
[01:22:10.400 --> 01:22:11.360]   Oh, we don't know names.
[01:22:11.360 --> 01:22:12.160]   It's not gendered.
[01:22:12.160 --> 01:22:12.480]   It's just...
[01:22:12.480 --> 01:22:13.440]   We don't know any names.
[01:22:14.320 --> 01:22:16.080]   Johannes Gigoberg.
[01:22:16.080 --> 01:22:17.040]   I love you.
[01:22:17.040 --> 01:22:18.000]   I love you.
[01:22:18.000 --> 01:22:19.040]   Thanks for the...
[01:22:19.040 --> 01:22:24.560]   What I thought was kind of crazy about this is the computer system went down,
[01:22:24.560 --> 01:22:26.320]   so they reverted to phone calls,
[01:22:26.320 --> 01:22:28.800]   and that worked because they had an old phone system,
[01:22:28.800 --> 01:22:31.040]   but then the phone system was overloaded as a word.
[01:22:31.040 --> 01:22:32.240]   They didn't have enough phone, my God.
[01:22:32.240 --> 01:22:33.520]   Which makes sense.
[01:22:33.520 --> 01:22:34.400]   But I was like...
[01:22:34.400 --> 01:22:36.720]   So it didn't totally fail, but I was really curious.
[01:22:36.720 --> 01:22:38.640]   Like, do we know if it was a cyber attack yet?
[01:22:38.640 --> 01:22:42.160]   No evidence of a cyber attack according to President Biden,
[01:22:42.160 --> 01:22:44.160]   he did ask Pete Buttigieg to...
[01:22:44.160 --> 01:22:48.080]   Secretary of Transportation to report back when a cause for failure has been identified.
[01:22:48.080 --> 01:22:49.120]   So...
[01:22:49.120 --> 01:22:51.920]   Canada's went down today too, unrelated.
[01:22:51.920 --> 01:22:52.800]   Oh, is it though?
[01:22:52.800 --> 01:22:53.280]   Oh, yeah.
[01:22:53.280 --> 01:22:54.240]   I don't want to...
[01:22:54.240 --> 01:22:56.160]   I don't want to start conspiracy theories, but yes.
[01:22:56.160 --> 01:22:57.760]   That's a big Koinkie dink.
[01:22:57.760 --> 01:22:59.600]   It is, indeed.
[01:22:59.600 --> 01:22:59.920]   It is.
[01:22:59.920 --> 01:23:03.840]   For the special day, what a day is it?
[01:23:03.840 --> 01:23:06.320]   It's the 11th, so it's 0111.
[01:23:06.320 --> 01:23:12.320]   Now if Canada was struck with a brief outage just after 10 a.m. Eastern,
[01:23:13.520 --> 01:23:17.520]   we're stored three hours later, no delays to schedule flights because backup measures
[01:23:17.520 --> 01:23:20.160]   allowed operations to continue over a year.
[01:23:20.160 --> 01:23:20.320]   Oh, Canada.
[01:23:20.320 --> 01:23:20.720]   Or at times.
[01:23:20.720 --> 01:23:23.280]   Oh, look who has redundancy.
[01:23:23.280 --> 01:23:27.360]   It's not that they've redundancy, they have three airplanes.
[01:23:27.360 --> 01:23:28.000]   It's easy.
[01:23:28.000 --> 01:23:28.720]   They just, you know...
[01:23:28.720 --> 01:23:31.280]   They just go back and forth across the country.
[01:23:31.280 --> 01:23:32.960]   One gate, they just change the sign.
[01:23:32.960 --> 01:23:34.880]   They just sign.
[01:23:34.880 --> 01:23:38.160]   Stop in Calgary along the way.
[01:23:38.160 --> 01:23:41.680]   Every flight in Canada stops in Calgary.
[01:23:41.680 --> 01:23:42.480]   It's part of the deal.
[01:23:43.120 --> 01:23:43.920]   No, they don't.
[01:23:43.920 --> 01:23:44.480]   It's not.
[01:23:44.480 --> 01:23:47.840]   But we're 9,000 flights delayed yesterday,
[01:23:47.840 --> 01:23:49.200]   going to flight away.
[01:23:49.200 --> 01:23:50.160]   That's quite a bit.
[01:23:50.160 --> 01:23:51.120]   A lot of grounded planes.
[01:23:51.120 --> 01:23:51.920]   Today.
[01:23:51.920 --> 01:23:52.480]   Today.
[01:23:52.480 --> 01:23:53.280]   Yesterday.
[01:23:53.280 --> 01:23:53.920]   This morning.
[01:23:53.920 --> 01:23:55.760]   It was over.
[01:23:55.760 --> 01:23:57.920]   We were listening to this, it was in the past.
[01:23:57.920 --> 01:24:01.280]   It's kind of tough to see how long it will trickle down.
[01:24:01.280 --> 01:24:02.800]   You know, because...
[01:24:02.800 --> 01:24:03.200]   Oh, yeah.
[01:24:03.200 --> 01:24:04.000]   It's always a max.
[01:24:04.000 --> 01:24:04.960]   15 minutes there.
[01:24:04.960 --> 01:24:06.480]   Well, 9,000 flights.
[01:24:06.480 --> 01:24:07.440]   And remember that...
[01:24:07.440 --> 01:24:09.680]   We know it's never just 15 minutes delay.
[01:24:09.680 --> 01:24:10.000]   Right.
[01:24:11.440 --> 01:24:17.600]   Remember there was a battle between the airlines and the telcos over 5G,
[01:24:17.600 --> 01:24:22.720]   because the 5G radio towers transmitted on a frequency
[01:24:22.720 --> 01:24:24.640]   that could interfere with altimeters,
[01:24:24.640 --> 01:24:27.840]   which is a kind of important part of the airplane.
[01:24:27.840 --> 01:24:28.800]   It's not a little thing.
[01:24:28.800 --> 01:24:32.480]   Well, really what it really was is that these old altimeters,
[01:24:32.480 --> 01:24:34.480]   some of them not so old,
[01:24:34.480 --> 01:24:38.880]   did not filter out frequencies that were completely irrelevant to them.
[01:24:38.880 --> 01:24:41.760]   So the 5G signals could interfere with them.
[01:24:41.760 --> 01:24:46.000]   According to the FAA, about a thousand planes still have altimeters
[01:24:46.000 --> 01:24:47.840]   listening to signals in the wrong frequency.
[01:24:47.840 --> 01:24:51.120]   And they're saying, "But you got a year to fix it."
[01:24:51.120 --> 01:24:57.440]   So the temporary fix between the FAA and the telcos was,
[01:24:57.440 --> 01:24:59.600]   "Don't build a 5G tower near an airport."
[01:24:59.600 --> 01:25:05.040]   I guess we're going to have to wait another year.
[01:25:05.040 --> 01:25:11.040]   Anyway, AT&T and Verizon could not fully deploy 5G on the CBAND.
[01:25:11.040 --> 01:25:11.840]   That's the spectrum.
[01:25:11.840 --> 01:25:13.200]   That was an issue.
[01:25:13.200 --> 01:25:13.680]   Those are...
[01:25:13.680 --> 01:25:18.080]   That was CBAND spectrum cost them $69 billion between the two of them.
[01:25:18.080 --> 01:25:20.720]   Altimeters...
[01:25:20.720 --> 01:25:22.080]   This is so irritating.
[01:25:22.080 --> 01:25:24.560]   It's very irritating because it's poor design.
[01:25:24.560 --> 01:25:26.320]   Altimeters don't work on the CBAND.
[01:25:26.320 --> 01:25:29.280]   They work on 4.2 to 4.4 gigahertz.
[01:25:29.280 --> 01:25:33.600]   CBAND is lower, much, 3.7 to 3.98.
[01:25:34.240 --> 01:25:37.040]   But because they didn't have notch filters on the altimeters,
[01:25:37.040 --> 01:25:39.840]   they would get interfered with the lower frequencies.
[01:25:39.840 --> 01:25:45.120]   Anyway, and now we're going to give them another year to fix it.
[01:25:45.120 --> 01:25:47.920]   They should have designed it right in the first place if you ask me.
[01:25:47.920 --> 01:25:53.280]   The Bloomberg report says, "Lobby Group Airlines for America."
[01:25:53.280 --> 01:25:59.600]   Said airlines are working diligently to ensure fleets are equipped with compliant radio altimeters.
[01:25:59.600 --> 01:26:03.760]   But global supply change continue to lack behind current demand.
[01:26:03.760 --> 01:26:07.360]   So any government deadline must consider this reality.
[01:26:07.360 --> 01:26:14.240]   Anyway, the problem is, these older altimeters
[01:26:14.240 --> 01:26:17.760]   are ignoring the rules.
[01:26:17.760 --> 01:26:19.600]   They're ignoring their assigned spectrum.
[01:26:19.600 --> 01:26:22.720]   It's the same thing.
[01:26:22.720 --> 01:26:26.400]   Yeah, we go through this every year because plenty of people make cheaper
[01:26:26.400 --> 01:26:30.720]   electronics by not putting effective guardrails on their spectrum usage.
[01:26:30.720 --> 01:26:34.800]   And then the FCC is like, "Oh, hey, we want to use that for broadband."
[01:26:34.800 --> 01:26:39.520]   And then they're like, "No, we can't, we're just, it could hurt."
[01:26:39.520 --> 01:26:44.240]   So FCC has, in fact, launched an inquiry into poorly designed wireless devices
[01:26:44.240 --> 01:26:47.120]   that receive transmissions from outside their allotted frequencies.
[01:26:47.120 --> 01:26:53.120]   We'll see what happens, but it potentially could result in new regulations.
[01:26:53.120 --> 01:26:59.120]   Basically, if you were, yeah, if you were designing a device that is going to use any spectrum band,
[01:26:59.920 --> 01:27:06.960]   you should be designing to a very stringent spec now because we've got a couple new tech,
[01:27:06.960 --> 01:27:08.960]   we've got a huge need for broadband.
[01:27:08.960 --> 01:27:09.440]   Yeah.
[01:27:09.440 --> 01:27:15.120]   But two, we've got spectrum sharing technologies now that are highly accurate and digitalized.
[01:27:15.120 --> 01:27:20.800]   So you can't afford to be sloppy because it's a digital world now and you can parse it to the
[01:27:20.800 --> 01:27:22.880]   tidiest little hurts.
[01:27:22.880 --> 01:27:25.680]   Yeah, you can't be sloppy anymore.
[01:27:25.680 --> 01:27:26.480]   That's the moral here.
[01:27:26.480 --> 01:27:30.400]   John Brodkin writing for ours Technica says, "Traditionally,
[01:27:30.400 --> 01:27:34.640]   the FCC only regulated transmitters, not receivers."
[01:27:34.640 --> 01:27:36.480]   Oh.
[01:27:36.480 --> 01:27:38.160]   That was a mistake as it turns out.
[01:27:38.160 --> 01:27:42.800]   So they're going to maybe going to fix that after the investigation.
[01:27:42.800 --> 01:27:47.200]   Also in our, "Are you yawning? Am I boring you?"
[01:27:47.200 --> 01:27:50.400]   I'm so sorry if we were talking about spectrum.
[01:27:50.400 --> 01:27:50.960]   I love it.
[01:27:50.960 --> 01:27:51.920]   This is your stuff.
[01:27:51.920 --> 01:27:54.480]   I put this in just for you.
[01:27:55.440 --> 01:27:58.080]   I gave up caffeine for New Year. I'm sorry.
[01:27:58.080 --> 01:27:59.360]   No, you did really.
[01:27:59.360 --> 01:28:00.800]   What's wrong with you?
[01:28:00.800 --> 01:28:01.520]   That's nuts.
[01:28:01.520 --> 01:28:05.440]   My New Year's resolution is to drink more coffee.
[01:28:05.440 --> 01:28:09.120]   I decided I stopped.
[01:28:09.120 --> 01:28:10.000]   Does it make you jittery?
[01:28:10.000 --> 01:28:11.200]   So I stopped drinking coffee.
[01:28:11.200 --> 01:28:12.320]   Does it make you jittery?
[01:28:12.320 --> 01:28:14.240]   I just wanted to see if I could do it.
[01:28:14.240 --> 01:28:16.160]   It's like a dry January for caffeine.
[01:28:16.160 --> 01:28:17.760]   Isn't it helpful for migraine?
[01:28:17.760 --> 01:28:18.880]   Do you see the micro drinks?
[01:28:18.880 --> 01:28:23.440]   Well, that's why I'm doing it because if I can actually not be addicted to it when I have a
[01:28:23.440 --> 01:28:26.320]   migraine, if I chug coffee, then it'll be like, "Bam!"
[01:28:26.320 --> 01:28:27.280]   Oh, you'll get a better...
[01:28:27.280 --> 01:28:28.560]   Oh, I'm smart.
[01:28:28.560 --> 01:28:29.920]   Oh, that's smart.
[01:28:29.920 --> 01:28:30.800]   That's the theory.
[01:28:30.800 --> 01:28:31.600]   I don't know if it's going to be...
[01:28:31.600 --> 01:28:33.840]   Eliminate your stuff about the Panera drinks.
[01:28:33.840 --> 01:28:34.560]   No.
[01:28:34.560 --> 01:28:35.040]   The what?
[01:28:35.040 --> 01:28:36.000]   It was hilarious.
[01:28:36.000 --> 01:28:37.760]   Jeff is our fast food expert.
[01:28:37.760 --> 01:28:39.760]   I got to say, okay, TikTok.
[01:28:39.760 --> 01:28:40.960]   It's just on TikTok.
[01:28:40.960 --> 01:28:41.760]   TikTok time.
[01:28:41.760 --> 01:28:48.240]   So people are drinking the Panera and they don't realize how the ones that are
[01:28:48.240 --> 01:28:51.200]   like umph-dup are really umph-
[01:28:51.200 --> 01:28:52.880]   Lots of caffeine and sugar too.
[01:28:52.880 --> 01:28:53.680]   Lots of caffeine.
[01:28:53.680 --> 01:28:58.080]   Jeff is done, by the way, I got to point this out.
[01:28:58.080 --> 01:28:59.040]   So we...
[01:28:59.040 --> 01:29:02.480]   Jeff created both a TikTok section of the...
[01:29:02.480 --> 01:29:05.120]   You could show the rundown real quickly.
[01:29:05.120 --> 01:29:08.960]   There is a TikTok section and there is a TikTok corner.
[01:29:08.960 --> 01:29:09.440]   Corner.
[01:29:09.440 --> 01:29:14.720]   Is that just a way to get more TikTok?
[01:29:15.920 --> 01:29:21.520]   It was a way to separate the news from the funds when we need that little cleanser there.
[01:29:21.520 --> 01:29:22.160]   Oh my.
[01:29:22.160 --> 01:29:23.120]   The Chipotle...
[01:29:23.120 --> 01:29:25.120]   It was once more perfect as a Twig story.
[01:29:25.120 --> 01:29:27.360]   That's something that combines Chipotle and TikTok.
[01:29:27.360 --> 01:29:34.400]   All right, I guess I guess I will answer by playing this Chipotle is adding the TikTok famous
[01:29:34.400 --> 01:29:35.520]   K-S-A-D-A-Hack.
[01:29:35.520 --> 01:29:38.240]   I didn't even know about the K-S-A-D-A-Hack.
[01:29:38.240 --> 01:29:38.800]   What?
[01:29:38.800 --> 01:29:39.440]   Because you're not...
[01:29:39.440 --> 01:29:40.320]   You're not...
[01:29:40.320 --> 01:29:40.480]   You're not...
[01:29:40.480 --> 01:29:41.920]   Hip kids with me in TikTok.
[01:29:41.920 --> 01:29:42.880]   Let's watch.
[01:29:42.880 --> 01:29:44.000]   I'm about Chipotle.
[01:29:44.000 --> 01:29:44.720]   Is that a Lexus?
[01:29:45.600 --> 01:29:46.080]   All right.
[01:29:46.080 --> 01:29:47.040]   Let it...
[01:29:47.040 --> 01:29:47.440]   Let it...
[01:29:47.440 --> 01:29:49.760]   Chipotle hurt and is coming to the Chipotle app.
[01:29:49.760 --> 01:29:52.880]   But it's going to take a little while because they got to get it just right.
[01:29:52.880 --> 01:29:54.000]   So it's coming in March.
[01:29:54.000 --> 01:29:55.520]   Why is she in the back seat?
[01:29:55.520 --> 01:29:56.000]   Right now.
[01:29:56.000 --> 01:29:57.440]   Because I'll explain.
[01:29:57.440 --> 01:29:57.840]   I'll explain.
[01:29:57.840 --> 01:29:59.440]   If you go to the other thing in the corner...
[01:29:59.440 --> 01:29:59.920]   Here we go.
[01:29:59.920 --> 01:30:00.320]   Here we go.
[01:30:00.320 --> 01:30:00.880]   Go to the other one.
[01:30:00.880 --> 01:30:02.400]   No, no, no, no, no.
[01:30:02.400 --> 01:30:03.280]   No, no, no.
[01:30:03.280 --> 01:30:04.480]   Next line of the rundown.
[01:30:04.480 --> 01:30:05.520]   Oh, next line of the rundown.
[01:30:05.520 --> 01:30:06.320]   Lord.
[01:30:06.320 --> 01:30:06.720]   Okay.
[01:30:06.720 --> 01:30:08.480]   This is where...
[01:30:08.480 --> 01:30:11.200]   That is an democracy, but it is Hollywood.
[01:30:11.200 --> 01:30:11.920]   This is where it's...
[01:30:11.920 --> 01:30:12.480]   This is where it's...
[01:30:12.480 --> 01:30:13.600]   It might take a corner.
[01:30:13.600 --> 01:30:16.160]   The only problem with TikTok is you can't rewind for easily.
[01:30:16.160 --> 01:30:16.240]   All right.
[01:30:16.240 --> 01:30:19.040]   I'm going to now going to play where it started.
[01:30:19.040 --> 01:30:20.160]   Extra cheese.
[01:30:20.160 --> 01:30:20.720]   You can rewind it.
[01:30:20.720 --> 01:30:21.520]   That's not that hard.
[01:30:21.520 --> 01:30:22.480]   You know how to use video.
[01:30:22.480 --> 01:30:23.280]   No, look what happens.
[01:30:23.280 --> 01:30:23.920]   It stops.
[01:30:23.920 --> 01:30:26.160]   Well, then shut up and it goes.
[01:30:26.160 --> 01:30:28.400]   What employees would order?
[01:30:28.400 --> 01:30:29.360]   Chipotle.
[01:30:29.360 --> 01:30:34.000]   State quesadilla with extra cheese and a heta veggies.
[01:30:34.000 --> 01:30:40.080]   So the person that originally suggested this to me said that it tasted like a silly cheesesteak.
[01:30:40.080 --> 01:30:43.520]   [Music]
[01:30:43.520 --> 01:30:44.640]   Combine these two.
[01:30:44.640 --> 01:30:48.640]   This is Alexis.frostly on TikTok.
[01:30:48.640 --> 01:30:49.600]   So the hack is...
[01:30:49.600 --> 01:30:49.920]   Oh, no.
[01:30:49.920 --> 01:30:56.480]   So this order at Chipotle to order a quesadilla with steak and then add vegetables from the
[01:30:56.480 --> 01:30:56.880]   fajita.
[01:30:56.880 --> 01:30:57.520]   Extra cheese.
[01:30:57.520 --> 01:30:57.760]   Extra cheese.
[01:30:57.760 --> 01:30:58.320]   Extra cheese.
[01:30:58.320 --> 01:30:58.800]   Right.
[01:30:58.800 --> 01:30:59.120]   Okay.
[01:30:59.120 --> 01:31:05.600]   And so evidently this was causing much surris, much agita among employees at TikTok,
[01:31:05.600 --> 01:31:07.280]   because they were like running out of beef.
[01:31:07.280 --> 01:31:08.400]   They were getting into fights.
[01:31:08.400 --> 01:31:12.320]   You're not supposed to get fajita vegetables in your steak, dude.
[01:31:12.320 --> 01:31:13.120]   Exactly.
[01:31:13.120 --> 01:31:14.160]   You're not supposed to do that.
[01:31:14.160 --> 01:31:15.280]   That's against the rules.
[01:31:15.280 --> 01:31:20.000]   So at first stores were refusing and people were getting angry as hell,
[01:31:20.000 --> 01:31:21.360]   because this is TikTok hot.
[01:31:21.360 --> 01:31:26.480]   And so TikTok finally related and now they're going to add it to the menu.
[01:31:26.480 --> 01:31:28.960]   And so you see those two people on the TikTok.
[01:31:28.960 --> 01:31:30.320]   Alexis.frost.frost.frost.
[01:31:30.320 --> 01:31:32.160]   Just to just to point this out.
[01:31:32.160 --> 01:31:35.520]   1.9 million views of this video.
[01:31:35.520 --> 01:31:36.720]   Now he's in the backseat.
[01:31:36.720 --> 01:31:37.440]   He's the backseat.
[01:31:37.440 --> 01:31:37.920]   Exactly.
[01:31:37.920 --> 01:31:40.160]   I think it's the case of the ad hoc put in the app.
[01:31:40.160 --> 01:31:40.800]   Oh, you know why?
[01:31:40.800 --> 01:31:44.560]   Wow, because we want to get it just their phone doesn't have a wide enough angle,
[01:31:44.560 --> 01:31:47.360]   uh, camera to get them both in the front seats.
[01:31:47.360 --> 01:31:49.920]   Someone has to sit right behind the other one.
[01:31:49.920 --> 01:31:50.880]   But it is happening.
[01:31:50.880 --> 01:31:54.160]   The case of the ad hoc is coming to the Chipotle app in March.
[01:31:54.160 --> 01:31:57.360]   March is around the corner is coming.
[01:31:57.360 --> 01:31:59.040]   That's cute.
[01:31:59.040 --> 01:31:59.520]   I guess.
[01:31:59.520 --> 01:32:00.080]   That's cute.
[01:32:00.080 --> 01:32:00.560]   Victory.
[01:32:00.560 --> 01:32:02.240]   You want to see really cute?
[01:32:02.240 --> 01:32:06.240]   You want to see really cute dogs of TikTok next to lunch.
[01:32:06.240 --> 01:32:06.880]   I'm sorry.
[01:32:06.880 --> 01:32:09.120]   The dogs on the bus are fine.
[01:32:09.120 --> 01:32:10.160]   Oh, they're fun.
[01:32:10.160 --> 01:32:11.280]   They're cute.
[01:32:11.280 --> 01:32:14.720]   I get I followed I followed them for ages because I guess I'm
[01:32:14.720 --> 01:32:17.680]   these dogs ride a bus like humans.
[01:32:17.680 --> 01:32:19.440]   And now the internet is in love.
[01:32:19.440 --> 01:32:22.640]   Oh, Lord, don't bring your dog on a bus.
[01:32:22.640 --> 01:32:23.840]   Is it?
[01:32:23.840 --> 01:32:24.640]   No, no, no, no.
[01:32:24.640 --> 01:32:27.040]   It's a company that walks dogs.
[01:32:27.040 --> 01:32:28.800]   So you go they have a doggy bus.
[01:32:28.800 --> 01:32:29.440]   They pick up your.
[01:32:29.440 --> 01:32:30.560]   Oh, they have a bus.
[01:32:30.560 --> 01:32:32.000]   It's not a public bus.
[01:32:32.000 --> 01:32:32.960]   It's for the dogs.
[01:32:32.960 --> 01:32:33.680]   Okay.
[01:32:33.680 --> 01:32:37.120]   They're the next line on the rundown shows them getting on the bus all happy.
[01:32:37.120 --> 01:32:37.760]   Not this one.
[01:32:37.760 --> 01:32:38.640]   They are quite cute.
[01:32:38.640 --> 01:32:38.960]   All right.
[01:32:38.960 --> 01:32:39.360]   Let's see.
[01:32:39.360 --> 01:32:43.760]   The pooches getting on because they know they're going for a walk once they get off the bus.
[01:32:43.760 --> 01:32:44.720]   Yeah, they can happy.
[01:32:44.720 --> 01:32:44.960]   Okay.
[01:32:44.960 --> 01:32:45.600]   Here they come.
[01:32:45.600 --> 01:32:47.040]   Oh, they're happy.
[01:32:47.040 --> 01:32:47.600]   Jake.
[01:32:47.600 --> 01:32:49.440]   Hi, how are you?
[01:32:49.440 --> 01:32:51.200]   Can I sit now in the back?
[01:32:51.200 --> 01:32:52.880]   This time I would like to.
[01:32:52.880 --> 01:32:53.520]   Oh, wait a minute.
[01:32:53.520 --> 01:32:54.560]   Somebody already might see.
[01:32:54.560 --> 01:32:55.440]   Oh, man.
[01:32:55.440 --> 01:32:55.920]   Hey.
[01:32:55.920 --> 01:32:57.040]   Oh, okay.
[01:32:57.040 --> 01:32:57.840]   There we go.
[01:32:57.840 --> 01:32:58.720]   Sniff my butt.
[01:32:58.720 --> 01:32:59.280]   Oh, thank you.
[01:32:59.280 --> 01:32:59.680]   Same butt.
[01:32:59.680 --> 01:33:01.680]   Oh, look.
[01:33:01.680 --> 01:33:04.000]   They have special seatbelts that are leashes.
[01:33:04.000 --> 01:33:04.720]   They do.
[01:33:04.720 --> 01:33:05.600]   Which doesn't,
[01:33:05.600 --> 01:33:07.520]   isn't going to save the dog if he's getting a crash.
[01:33:07.520 --> 01:33:08.880]   Oh, he's just going to go flying.
[01:33:08.880 --> 01:33:12.080]   Okay.
[01:33:12.080 --> 01:33:14.880]   Like a, like a little cannonball attached to his string.
[01:33:14.880 --> 01:33:16.960]   Oh, oh, here's another one.
[01:33:16.960 --> 01:33:17.680]   He's waiting.
[01:33:17.680 --> 01:33:18.640]   He's just waiting.
[01:33:18.640 --> 01:33:19.120]   Yeah.
[01:33:19.120 --> 01:33:20.160]   Oh, look, he's happy.
[01:33:20.160 --> 01:33:21.120]   Oh.
[01:33:21.120 --> 01:33:21.680]   How are you?
[01:33:21.680 --> 01:33:23.600]   Wow.
[01:33:23.600 --> 01:33:27.600]   So, so people just put, let their dog go outside.
[01:33:27.600 --> 01:33:28.640]   Good morning.
[01:33:28.640 --> 01:33:29.920]   It's in Alaska.
[01:33:29.920 --> 01:33:30.240]   Oh.
[01:33:31.040 --> 01:33:32.640]   Those dogs know better.
[01:33:32.640 --> 01:33:34.400]   Wow.
[01:33:34.400 --> 01:33:36.320]   Hey, you smell the same?
[01:33:36.320 --> 01:33:37.840]   That is a completely different dog.
[01:33:37.840 --> 01:33:38.080]   Yeah.
[01:33:38.080 --> 01:33:40.080]   Where'd the husky go?
[01:33:40.080 --> 01:33:43.040]   Well, I don't know where the huskies go,
[01:33:43.040 --> 01:33:45.040]   but don't you eat that yellow snow.
[01:33:45.040 --> 01:33:46.240]   Oh, I'm so happy to be here.
[01:33:46.240 --> 01:33:46.960]   Okay.
[01:33:46.960 --> 01:33:48.000]   Oh, you don't feel, you don't feel,
[01:33:48.000 --> 01:33:48.480]   please.
[01:33:48.480 --> 01:33:49.840]   We love you looking face.
[01:33:49.840 --> 01:33:50.720]   Isn't that huge?
[01:33:50.720 --> 01:33:54.320]   Do you think Kylo would enjoy this hand?
[01:33:54.320 --> 01:33:55.280]   Good morning.
[01:33:55.280 --> 01:33:57.360]   Kylo would be fine.
[01:33:57.360 --> 01:33:58.960]   Biscuit would raise hell on that.
[01:33:58.960 --> 01:33:59.680]   Yeah.
[01:33:59.680 --> 01:34:01.680]   I imagine they have to throw people off the bus.
[01:34:01.680 --> 01:34:02.240]   It's always a little dog.
[01:34:02.240 --> 01:34:03.920]   Sometimes, you know, like people.
[01:34:03.920 --> 01:34:06.080]   Well, dogs are people too.
[01:34:06.080 --> 01:34:08.160]   All right.
[01:34:08.160 --> 01:34:08.960]   That's enough of this.
[01:34:08.960 --> 01:34:10.000]   Okay.
[01:34:10.000 --> 01:34:11.520]   That was TikTok Corner.
[01:34:11.520 --> 01:34:12.560]   It's TikTok Corner.
[01:34:12.560 --> 01:34:14.240]   You need to be tied in.
[01:34:14.240 --> 01:34:15.280]   I don't do it often.
[01:34:15.280 --> 01:34:15.760]   I do it.
[01:34:15.760 --> 01:34:16.960]   We find the right stuff.
[01:34:16.960 --> 01:34:20.000]   Actually, this is, I'm glad you put this story in from Georgia Tech.
[01:34:20.000 --> 01:34:25.920]   Georgia Tech did a white paper on TikTok and security
[01:34:25.920 --> 01:34:28.160]   and came up with a conclusion that,
[01:34:28.160 --> 01:34:33.440]   in fact, TikTok is not a threat to our national security.
[01:34:33.440 --> 01:34:34.880]   No, it's pretty much an opinion piece.
[01:34:34.880 --> 01:34:35.520]   Oh.
[01:34:35.520 --> 01:34:36.560]   As a paper plot.
[01:34:36.560 --> 01:34:37.680]   It's not a study.
[01:34:37.680 --> 01:34:39.200]   Well, no, it is.
[01:34:39.200 --> 01:34:44.880]   But it, just to be clear, it wasn't like there was a new data.
[01:34:44.880 --> 01:34:47.200]   It was just analyzing and going through and saying why,
[01:34:47.200 --> 01:34:48.640]   in their view, it's not a threat.
[01:34:48.640 --> 01:34:48.960]   Yeah.
[01:34:48.960 --> 01:34:50.640]   We've seen this, Kaspersky also,
[01:34:50.640 --> 01:34:52.800]   and I refer to this a couple of weeks ago, had a,
[01:34:52.800 --> 01:34:57.600]   a little bit more specific research into what TikTok collects
[01:34:57.600 --> 01:34:58.480]   and what they don't collect.
[01:34:58.480 --> 01:35:00.800]   Executive summary.
[01:35:00.800 --> 01:35:04.240]   TikTok is a commercially motivated enterprise,
[01:35:04.240 --> 01:35:06.720]   not a tool of the Chinese state.
[01:35:06.720 --> 01:35:09.920]   Bike Dats' organizational structure reflects an attempt
[01:35:09.920 --> 01:35:13.120]   to segregate the Chinese barks from global markets
[01:35:13.120 --> 01:35:16.160]   so that it can export its AI services globally.
[01:35:16.160 --> 01:35:19.120]   This split works to the advantage of both sides.
[01:35:19.120 --> 01:35:22.320]   Chinese government efforts to assert control over
[01:35:22.320 --> 01:35:28.560]   bike Dats' Chinese subsidiaries are targeting its domestic Chinese services,
[01:35:28.560 --> 01:35:30.400]   not its overseas operations.
[01:35:30.400 --> 01:35:33.440]   We have talked about that, that the Chinese version of TikTok
[01:35:33.440 --> 01:35:35.040]   is a different model.
[01:35:35.040 --> 01:35:35.760]   Very.
[01:35:35.760 --> 01:35:36.160]   All right.
[01:35:36.160 --> 01:35:39.520]   But they understand that they're trying to make money in the US
[01:35:39.520 --> 01:35:43.200]   and they can't do the same thing in the US that they do in China.
[01:35:43.200 --> 01:35:46.240]   This report did not receive any funding from TikTok,
[01:35:46.240 --> 01:35:47.920]   Bike Dats, or any interested party.
[01:35:49.120 --> 01:35:56.320]   Says IGP, which is the internet governance project at the University of
[01:35:56.320 --> 01:35:57.680]   Georgia Tech.
[01:35:57.680 --> 01:35:59.040]   Georgia Tech-Nology.
[01:35:59.040 --> 01:36:02.080]   So by the way, there was a, there was a, a friend of mine just sent this to me.
[01:36:02.080 --> 01:36:02.640]   I didn't see it.
[01:36:02.640 --> 01:36:05.840]   There was a Times magazine feature about TikTok
[01:36:05.840 --> 01:36:08.000]   and why is it in such hot water and so and so forth.
[01:36:08.000 --> 01:36:08.880]   Long magazine.
[01:36:08.880 --> 01:36:09.440]   It's political.
[01:36:09.440 --> 01:36:13.920]   In it, it says that Zhang Jie Ming, who founded Bike Dats,
[01:36:13.920 --> 01:36:18.320]   when he was 27 years old in 2010,
[01:36:19.040 --> 01:36:24.720]   he used a service called DuBan, which was like rotten tomatoes and good reads.
[01:36:24.720 --> 01:36:28.640]   And he recorded the books he wanted to read, the first on the list.
[01:36:28.640 --> 01:36:29.440]   What would Google do?
[01:36:29.440 --> 01:36:33.200]   Oh, congratulations.
[01:36:33.200 --> 01:36:34.160]   I think that's cool.
[01:36:34.160 --> 01:36:38.080]   You want to try to get to them and send them a autographed copy.
[01:36:38.080 --> 01:36:39.040]   Wow.
[01:36:39.040 --> 01:36:40.560]   Get in trouble with the Republicans.
[01:36:40.560 --> 01:36:43.920]   And then just down the road from here, there's the story of the Tik
[01:36:43.920 --> 01:36:48.960]   Tesla, the Tik Tesla, an autopilot that caused a horrific
[01:36:49.360 --> 01:36:50.640]   Oh, no, this isn't it.
[01:36:50.640 --> 01:36:51.200]   This isn't it.
[01:36:51.200 --> 01:36:51.840]   Let me find the other one.
[01:36:51.840 --> 01:36:55.600]   That caused a horrific crash on the Bay Bridge.
[01:36:55.600 --> 01:37:00.320]   On the bridge, by the way, another reason not to go on bridges.
[01:37:00.320 --> 01:37:01.360]   The Tesla.
[01:37:01.360 --> 01:37:02.800]   That's not the reason.
[01:37:02.800 --> 01:37:04.160]   It's not clear.
[01:37:04.160 --> 01:37:04.160]   It's not clear.
[01:37:04.160 --> 01:37:05.760]   It's not thought out of nowhere.
[01:37:05.760 --> 01:37:06.560]   It's not clear.
[01:37:06.560 --> 01:37:07.040]   It's not clear.
[01:37:07.040 --> 01:37:10.320]   If the Tesla was on autopilot or not,
[01:37:10.320 --> 01:37:13.600]   driver said it was driver said it was, but maybe the driver didn't want to take
[01:37:13.600 --> 01:37:18.560]   responsibility for suddenly changing lanes all the way into the fast lane and then
[01:37:18.560 --> 01:37:20.000]   stop it on the brakes.
[01:37:20.000 --> 01:37:26.880]   Here's a video from the bridge of the car suddenly getting in the left lane and just
[01:37:26.880 --> 01:37:27.280]   stop it.
[01:37:27.280 --> 01:37:29.040]   And then watch.
[01:37:29.040 --> 01:37:33.120]   Now you got to kind of fault the cars plowing into one another for following too close.
[01:37:33.120 --> 01:37:33.920]   Oh, one goes.
[01:37:33.920 --> 01:37:34.320]   Oops.
[01:37:34.320 --> 01:37:35.680]   There goes one above the other.
[01:37:35.680 --> 01:37:37.120]   Nine year old kid was injured.
[01:37:37.120 --> 01:37:41.760]   There were a number of injuries, none critical, but you could see all the cars.
[01:37:41.760 --> 01:37:42.720]   There was quite a few cars.
[01:37:42.720 --> 01:37:45.120]   Let's see another view from the bridge.
[01:37:45.120 --> 01:37:49.120]   So the car goes into the left lane suddenly and then just boom,
[01:37:49.120 --> 01:37:50.080]   standsops on the brakes.
[01:37:50.080 --> 01:37:50.640]   It's a lot of stereo.
[01:37:50.640 --> 01:37:52.880]   Yeah.
[01:37:52.880 --> 01:37:58.480]   This was by the way, ironically, the day Tesla released full self driving to all vehicles
[01:37:58.480 --> 01:37:59.440]   in North America.
[01:37:59.440 --> 01:38:02.400]   So Mr. LaPort with that,
[01:38:02.400 --> 01:38:10.160]   being allegedly the full self driving software, the driver couldn't intervene within those three
[01:38:10.160 --> 01:38:14.160]   seconds to say, oh, crap, let me hit the accelerator.
[01:38:14.160 --> 01:38:15.120]   I'll tell you the truth.
[01:38:15.120 --> 01:38:20.000]   I had a Tesla didn't have FSD, but I would never take my hands off the wheel.
[01:38:20.000 --> 01:38:20.800]   You're not allowed to.
[01:38:20.800 --> 01:38:22.640]   The Tesla will say, get your hands back on the wheel.
[01:38:22.640 --> 01:38:27.040]   And I would always keep my open because as many of the time our model likes try to plow
[01:38:27.040 --> 01:38:29.520]   into the dividers on the freeway or things like that.
[01:38:29.520 --> 01:38:37.680]   Clearly frequently it would jam the brakes on stopping for a ghost that it saw.
[01:38:37.680 --> 01:38:41.760]   Because it has that feature where it can stop, keep you from running into somebody or something.
[01:38:42.560 --> 01:38:44.720]   But it would often do it just with nothing going on.
[01:38:44.720 --> 01:38:46.080]   It happened to Lisa all the time.
[01:38:46.080 --> 01:38:49.040]   So I never trusted it.
[01:38:49.040 --> 01:38:53.200]   And I think that's a mistake, frankly, to trust it.
[01:38:53.200 --> 01:38:59.200]   So yeah, I think the driver bears some responsibility, whether the driver really did leave autopilot on.
[01:38:59.200 --> 01:39:02.400]   At least if it starts veering over and jamming on the brakes,
[01:39:02.400 --> 01:39:05.120]   promise when it jams on the brakes, that's hard to override.
[01:39:05.120 --> 01:39:10.160]   That's like at that point, it's like you're, you're kind of out of control.
[01:39:10.880 --> 01:39:17.520]   So I don't know if you're going so fast, you also have like, there is that second of what the hell
[01:39:17.520 --> 01:39:20.560]   is happening. There's always a second of orientation. That's right.
[01:39:20.560 --> 01:39:25.360]   And then decide, and you can't, I mean, if you think about it, you can't go from a stop to a
[01:39:25.360 --> 01:39:28.080]   straight boom by then someone's probably already hit you.
[01:39:28.080 --> 01:39:33.040]   But I mean, you don't, you have a Tesla doesn't have, it doesn't have full self driving.
[01:39:33.040 --> 01:39:38.880]   It no, it doesn't. But I would say, I would say that really the bottom line is here.
[01:39:38.880 --> 01:39:45.120]   We are all in a beta test of a not so good product risking our lives.
[01:39:45.120 --> 01:39:50.240]   Because we don't have a choice. It's on the highways and around in Northern California.
[01:39:50.240 --> 01:39:51.920]   It's every other vehicle is a Tesla.
[01:39:51.920 --> 01:39:56.720]   So with lawsuits, who's going to get to the driver of a Tesla?
[01:39:56.720 --> 01:39:58.640]   Absolutely driver, not the Tesla.
[01:39:58.640 --> 01:40:03.040]   Think so? Yeah. Yeah. The driver was still responsible for the vehicle.
[01:40:03.040 --> 01:40:07.120]   You don't give up responsibility. That's the other story that I was about to show is like,
[01:40:08.640 --> 01:40:15.600]   a Tesla on autopilot led police on a chase because the driver was asleep.
[01:40:15.600 --> 01:40:20.160]   Oh, yeah. This is in Germany. The driver was asleep. But here's the key.
[01:40:20.160 --> 01:40:24.400]   The driver had attached a weight to his steering wheel.
[01:40:24.400 --> 01:40:28.640]   Oh, yeah. So that the Tesla would think he was driving it and then took a nap.
[01:40:28.640 --> 01:40:34.320]   The police knew that the driver was not driving a because they couldn't see his head.
[01:40:34.320 --> 01:40:38.160]   He was reclined. But B, because every time they tried to stop the Tesla,
[01:40:38.160 --> 01:40:41.600]   it would it was traveling exactly 70 miles an hour. And if they pulled in front of it,
[01:40:41.600 --> 01:40:45.520]   it would slow down and speed up to match the car in front of it.
[01:40:45.520 --> 01:40:53.680]   The Tesla kept the same distance from the patrol car in front as they traveled down the auto bond.
[01:40:53.680 --> 01:40:58.880]   Well, wait a second. If the patrol car just slowed to a stop,
[01:40:58.880 --> 01:41:01.520]   they should have stopped. I think they must have. That's how they got the guy.
[01:41:01.520 --> 01:41:03.520]   Well, let's watch the other lane. Let's let us do it.
[01:41:03.520 --> 01:41:07.200]   No, I don't think it would do that. I don't think they're that. I don't think you have to use
[01:41:07.200 --> 01:41:12.080]   his turn signal and tell it to go out into the lane. Anyway, that is our segment
[01:41:12.080 --> 01:41:16.320]   of technology gone wrong unless you want to see.
[01:41:16.320 --> 01:41:23.520]   Where did I where did I find this? There was a is it a tiktok of the
[01:41:23.520 --> 01:41:32.080]   the Boston Dynamics doggy or no, is the Boston Dynamics robot failing?
[01:41:33.040 --> 01:41:38.480]   Oh, I missed it. It was pretty funny. Oh, shoot. I think it was in another story.
[01:41:38.480 --> 01:41:42.640]   And I thought, you know, I should I should show this later, but I don't remember where it was.
[01:41:42.640 --> 01:41:47.600]   It'll make Stacy feel better. Yeah, it will, too. You will like it.
[01:41:47.600 --> 01:41:52.960]   Now, here's something that's going to make you mad. Do you remember a song by a guy named Afroman?
[01:41:52.960 --> 01:42:01.920]   I was going to clean my room, but then I got high. I was going to go to school, but then I got high.
[01:42:02.480 --> 01:42:06.400]   Well, Afroman, that was how many years, 20 years ago? I don't know, 10 years ago.
[01:42:06.400 --> 01:42:12.960]   My kids used to lease the decade, lease the decade. So Afroman, I don't know if he's made a million
[01:42:12.960 --> 01:42:18.880]   dollars on that, but he's living in a kind of, you know, a poor county, Adams County in Ohio.
[01:42:18.880 --> 01:42:25.600]   And for some reason, the police decided that he had not only a lot of marijuana,
[01:42:25.600 --> 01:42:32.800]   but he was actually trafficking narcotics and kidnapped somebody. So they raided his house,
[01:42:32.800 --> 01:42:39.440]   they broke down the door and all he could do, he said, is make a video. This is Afroman, his song,
[01:42:39.440 --> 01:42:41.840]   "Will You Help Me Repair My Door?"
[01:42:41.840 --> 01:42:53.440]   Featuring video of the Adams County Sheriff's Office, dressed as if invading a Taliban stronghold.
[01:42:55.360 --> 01:43:00.080]   Nice car collection. Look at that. He's pointing his gun down behind the sofa. Like there's,
[01:43:00.080 --> 01:43:08.240]   it's like he's going to shoot a cat. Yeah. This is, this was an actual raid. They found nothing,
[01:43:08.240 --> 01:43:13.680]   except a vape pen that's, Afroman says somebody left behind in one joint. Here they are breaking his
[01:43:13.680 --> 01:43:19.520]   gate to get in with their tactical vehicles. Look at this. They broke down his door. They
[01:43:19.520 --> 01:43:30.880]   rammed his door down. This is hilarious. So sad, dude. Unless you're Afroman, it is. Yeah.
[01:43:30.880 --> 01:43:37.600]   This is why police force does not need to be. They do not need to be military training. Yeah,
[01:43:37.600 --> 01:43:44.000]   this is a stress. There's his, there's his, by the way, his mom made his lemon pancake. This,
[01:43:44.000 --> 01:43:51.040]   this somewhat overweight officer is very intrigued. But, you know, fortunately has a good sense not
[01:43:51.040 --> 01:43:56.880]   to eat the lemon pound cake. Oh, those tend to be. They realized after a while, they were,
[01:43:56.880 --> 01:44:05.440]   they realized after a while that he had cameras in his house.
[01:44:13.760 --> 01:44:16.480]   I hope he does. I hope Afroman does not take me down.
[01:44:16.480 --> 01:44:31.040]   They went through his closet and found some cash that Afroman says, yeah, that was from a gig I
[01:44:31.040 --> 01:44:36.080]   did about five years ago with Snoop Dogg and I forgot and they paid me, I stuck it in my pocket.
[01:44:43.120 --> 01:44:48.960]   So they confiscated all the money. And then, and this, I think is reprehensible, they went around
[01:44:48.960 --> 01:44:56.000]   and disconnected all the cameras. They realized, Oh my God, everything we're doing here is being
[01:44:56.000 --> 01:44:59.040]   recorded by a security cameras. So they
[01:45:07.600 --> 01:45:14.800]   he went to the, they never filed charges, of course, because I hope he did. I hope he, well,
[01:45:14.800 --> 01:45:21.440]   he asked for his cash back. They gave him all the cash back minus $400. So they actually stole
[01:45:21.440 --> 01:45:27.200]   some money from him. He says, he alleges, Oh, I'm sure that civil forfeiture. Yes, I'm sure it is.
[01:45:27.200 --> 01:45:36.000]   He has all this video, but it still has CDs, but then they, they go and they start disconnecting
[01:45:36.000 --> 01:45:43.280]   the cameras, which I honestly, that's almost an emission of guilt, right? We don't,
[01:45:43.280 --> 01:45:48.320]   we don't want anybody to know what we're doing in here. Because disconnecting the cameras means
[01:45:48.320 --> 01:45:55.040]   it never happens. Yeah, never mind storage. So thank goodness Afroman has a voice in post to this,
[01:45:55.040 --> 01:46:00.400]   he actually posted two two songs he also had one about his, his mom's lemon pound cake.
[01:46:03.360 --> 01:46:13.040]   So they say the money was miscounted, but it was, I probably, you know, if they, if he
[01:46:13.040 --> 01:46:17.600]   sues him, it'll probably be, well, it's civil forfeiture. Here's the lemon pound cake,
[01:46:17.600 --> 01:46:18.800]   official music video.
[01:46:18.800 --> 01:46:26.400]   You know what? This is his only way of getting the money back. Yeah.
[01:46:26.400 --> 01:46:45.760]   Yeah. I have to say I have new respect for Afroman. Obviously, it was not too high to make those
[01:46:45.760 --> 01:46:51.680]   two videos. I also think, honestly, there ought to be a little bit of retribution for the Adams
[01:46:51.680 --> 01:46:57.280]   County. Something we've done about that. This is not okay. Absolutely. It's not okay. The raid took
[01:46:57.280 --> 01:47:03.680]   place summer of last year, took him a while to put the videos out. The good news is the clips and
[01:47:03.680 --> 01:47:12.560]   the videos have gone viral. You know, huge on TikTok. There are millions of views. All joking aside,
[01:47:12.560 --> 01:47:18.160]   I mean, they could have killed him. Yeah. Coming to this house. They're militarized. He was not there.
[01:47:18.160 --> 01:47:23.120]   He says, you terrorize my kids. They burst down the, they did not, you know, ask the,
[01:47:23.120 --> 01:47:25.680]   ring the door, but maybe the kids are told not to open the door bell, but
[01:47:25.680 --> 01:47:31.120]   open the door to strangers. But he terrorized the kids, Afroman said.
[01:47:31.120 --> 01:47:38.160]   He was not there. So yeah, it's, it's a little bit more. He has a 0.4 million likes on the lawyer.
[01:47:38.160 --> 01:47:41.680]   Well, I think he probably bursts. I think he probably does.
[01:47:41.680 --> 01:47:47.520]   And this is where TikTok YouTube. This is, this is another way to have a voice in the world,
[01:47:47.520 --> 01:47:51.440]   isn't it? We've talked before about Canary warrants.
[01:47:51.440 --> 01:47:58.480]   In a minute, I'm going to show you the best Canary warrant ever. And if you ask me, but first,
[01:47:58.480 --> 01:48:06.080]   a word from our sponsor, Melissa, ladies, gentlemen, you, if you have a business, you have lists of
[01:48:06.080 --> 01:48:11.920]   customer data, right? Customers, suppliers, you have lists of addresses and emails. You know,
[01:48:11.920 --> 01:48:16.800]   those lists are going bad as we speak, because people moved names change addresses change.
[01:48:17.760 --> 01:48:25.040]   How do you, that is valuable information that is slowly withering away right now. You need Melissa,
[01:48:25.040 --> 01:48:31.920]   a leading provider of global data quality, identity verification and address management
[01:48:31.920 --> 01:48:41.360]   solutions. Data quality is a actual cost center in your business. If you go to Melissa.com/twit,
[01:48:41.360 --> 01:48:46.240]   you can use Melissa's ROI calculator. They'll show you clear information related to marketing
[01:48:46.240 --> 01:48:52.160]   and customer outreach that could be strained by inflation and increasing costs and
[01:48:52.160 --> 01:48:58.160]   deterioration of the information. A sample scenario highlights a mailing list, 50,000 recipients.
[01:48:58.160 --> 01:49:04.560]   That's relatively small. As many as 6,500 of them, undeliverable, because it's deteriorated.
[01:49:04.560 --> 01:49:12.000]   Melissa's address verification removes bad addresses. That could save that sender as much as $23,000
[01:49:12.000 --> 01:49:17.520]   on postage and material costs. That's a significant amount of money. Poor data quality can cost
[01:49:17.520 --> 01:49:23.840]   organizations an average of $15 million every year. And of course, the longer it goes, the more
[01:49:23.840 --> 01:49:30.080]   losses your business can accumulate. Your customer information has to be accurate. High quality
[01:49:30.080 --> 01:49:34.960]   data saves you money, makes you money. With Melissa's technologies, you can enable faster
[01:49:34.960 --> 01:49:41.760]   workloads, because you can use their API to create auto-completion tools that stop data mistakes on
[01:49:41.760 --> 01:49:47.600]   entry, whether it's by the customer or our customer service rep. You start typing. It gets corrected
[01:49:47.600 --> 01:49:53.520]   as you type. You can reduce undeliverable mail based on validated, standardized addresses
[01:49:53.520 --> 01:49:59.440]   for customers, not just in the US, but worldwide. You can eliminate waste and lost opportunities
[01:49:59.440 --> 01:50:04.960]   from incorrect mailings. You can improve customer satisfaction with seamless real-time identity
[01:50:04.960 --> 01:50:12.080]   verification tools. And of course, fraud. To eliminate fraud, these tools are very important.
[01:50:12.080 --> 01:50:19.040]   You can match and de-duplicate information to establish a single high quality customer record,
[01:50:19.040 --> 01:50:24.480]   linking all the customer touch points for an ideal 360 degree view of each customer.
[01:50:24.480 --> 01:50:30.320]   Merge them all together so that one record says it all. And because they work in compliance with
[01:50:30.320 --> 01:50:34.960]   the United States Postal Service's move update requirements, it means you get the most current
[01:50:34.960 --> 01:50:39.840]   address data through processing in the USPS's national change of address database. It's all
[01:50:39.840 --> 01:50:47.600]   automatic as a Melissa customer. Since 1985, Melissa has specialized in global intelligence
[01:50:47.600 --> 01:50:52.960]   solutions to help organizations unlock accurate data for a more compelling customer view.
[01:50:52.960 --> 01:50:58.080]   And Melissa, of course, continually undergoes independent security audits, because they know
[01:50:58.080 --> 01:51:05.360]   your data is solid gold. They protect it just like you would want them to sock to HIPAA GDPR compliant
[01:51:05.360 --> 01:51:13.280]   and regular third-party audits to ensure your data is in the best hands. Make sure your customer
[01:51:13.280 --> 01:51:19.200]   contact data is up to date. Get started today. 1000 records clean free. Great way to try it out.
[01:51:19.200 --> 01:51:27.360]   Melissa.com/twit on prem in the cloud sass secure FTP and API. There's any way you want it.
[01:51:27.360 --> 01:51:34.000]   Melissa's got it. Melissa.com/twit. We thank you so much for the work they do and for supporting
[01:51:34.000 --> 01:51:40.000]   this week in Google. You don't know what a warrant canary is? I bet Stacy knows what a warrant canary is.
[01:51:42.000 --> 01:51:50.480]   Stacy's my chat GPT for the week. Sorry. Oh, crazy. It is a report that a company puts out to
[01:51:50.480 --> 01:51:57.040]   indicate that it has had secret warrants from the Justice Department or other entities asking
[01:51:57.040 --> 01:52:02.320]   about things they can't talk about. You're not allowed to tell the world if you get one of those
[01:52:02.320 --> 01:52:08.240]   warrants in many cases. So a warrant canary, well, here's a perfect one from our sink, which is
[01:52:08.240 --> 01:52:13.360]   open source software. They even call it a warrant canary, which may be violating the law. I don't know.
[01:52:13.360 --> 01:52:21.360]   They say because we would not be able to tell you we will comply as we are required to with warrants,
[01:52:21.360 --> 01:52:29.040]   but in some cases we can't tell you. So we are going to update this every week. It is a cryptographically
[01:52:29.040 --> 01:52:35.760]   signed message that says up to this point, no warrants have been served nor have any searches
[01:52:35.760 --> 01:52:40.960]   or seizures taken place. And then they're going to put a cut and paste headline from a major news source.
[01:52:40.960 --> 01:52:47.920]   And this is the most recent one, January 9th. And here's the Reuters story from January 8th to prove.
[01:52:47.920 --> 01:52:55.920]   You wouldn't know how the 76ers and the Pistons did until January 8th. So that proves that's when
[01:52:55.920 --> 01:53:05.200]   this was generated. Here's the PGP signature. If this disappears, they got served. So it's like a
[01:53:05.200 --> 01:53:12.720]   dead man switch. If this disappears from the r sink site, they can't say that they haven't had a
[01:53:12.720 --> 01:53:16.800]   searcher seizure. So they have to take it down. I think this is the way to do it. That's brilliant.
[01:53:16.800 --> 01:53:22.240]   We I'm going to start. I want to do my own warrant canary. Not that we know anything about you.
[01:53:22.240 --> 01:53:28.560]   You don't have any data. I mean, don't it cares what you have. Oh darn it. I'm totally confused by
[01:53:28.560 --> 01:53:34.480]   this this premise. It's the opposite. It's the opposite. So if you see this, you know you're good.
[01:53:34.480 --> 01:53:38.080]   If you don't see this because they aren't allowed to say we got searched, right?
[01:53:38.080 --> 01:53:42.960]   So they can't put up what they'd like to do is put up and notice, hey, we just turned over all
[01:53:42.960 --> 01:53:48.800]   the information to the FBI just so you know, they can't go. They can't do that in many cases
[01:53:48.800 --> 01:53:52.560]   because these these national safety of the security letters, what they call them,
[01:53:52.560 --> 01:53:58.400]   NSLs won't often say and you may not disclose this has been a problem historically for years.
[01:53:58.400 --> 01:54:03.360]   Thanks to the Patriot Act for a lot of companies. They get served, but they can't say anything.
[01:54:03.360 --> 01:54:07.520]   So the warrant canary, they put this up as long as it stays up, they haven't been served.
[01:54:07.520 --> 01:54:13.440]   Does that make sense? And the soon it's a dead man switch. As soon as it's gone, you're dead.
[01:54:13.440 --> 01:54:20.640]   I thought I was saying this thing that y'all might be worried about happening has not happened
[01:54:20.640 --> 01:54:26.720]   yet. And when it goes away, you're like, oh, it just happened. I don't know if I like this or not.
[01:54:26.720 --> 01:54:32.800]   I hope Google doesn't do this. Your Amazon Echo now has a new keyword. Hey, Disney.
[01:54:33.520 --> 01:54:41.200]   Will you turn this on? You might turn this on, right? I would not know. I don't want to talk to anybody.
[01:54:41.200 --> 01:54:49.440]   I don't even talk to Madam A. But C3PO might talk, but this is for Madam A. C3PO might respond.
[01:54:49.440 --> 01:54:54.960]   Or a picture. What was this deal? So this isn't it. I think this is a really interesting deal
[01:54:54.960 --> 01:55:00.560]   because Disney worked closely with Amazon to create these personalized characters and it's an
[01:55:00.560 --> 01:55:08.240]   exclusive deal through Amazon. And it's kind of like if you wanted to create this like vocal
[01:55:08.240 --> 01:55:13.440]   assistant to talk to your diehard users, like, oh, maybe someone wants to wake up to you in the
[01:55:13.440 --> 01:55:20.320]   morning and saying all their stuff, you could actually create the Twitch assistant and pay Amazon
[01:55:20.320 --> 01:55:25.200]   to do that for you. There also an interesting business. Yeah, they're also going to put echoes
[01:55:25.200 --> 01:55:30.720]   in all the Disney resort hotels. How would Leo wake you up if you could if you could get that
[01:55:30.720 --> 01:55:39.200]   service? Hey, what you doing? Sleeping. I've been up for hours. I'm more likely to say, it's okay.
[01:55:39.200 --> 01:55:45.920]   Go back to sleep. We don't. There's nothing to see. There's nothing to rush to. Just relax.
[01:55:45.920 --> 01:55:49.280]   Do as I am doing it, turn off this alarm and roll over.
[01:55:49.280 --> 01:55:53.840]   Guests staying in select Watte Disney World and Disney Land Resort hotels will be able to ask
[01:55:53.840 --> 01:56:00.080]   questions about park hours, request fresh towels. Hey, Disney, I want some fresh towels up here.
[01:56:00.080 --> 01:56:05.760]   Access other helpful features. And if you have a magic band plus, which you use in the park to
[01:56:05.760 --> 01:56:12.000]   get on a rides and get into the park and stuff, it will buzz. It will transform into a game show
[01:56:12.000 --> 01:56:18.000]   style buzzer. When you answer trivia questions, it will react with lights and vibrations. It will
[01:56:18.000 --> 01:56:23.440]   also light up a bus when you're alarm. It's kind of like, you know, if you're on house arrest and
[01:56:23.440 --> 01:56:29.680]   you have that ankle thing, I don't like that. Yeah, kind of like that, you know, that ankle bracelet.
[01:56:29.680 --> 01:56:36.240]   It'll buzz you and wake you up and all kinds of things. And I guess for a fee, I don't know if
[01:56:36.240 --> 01:56:41.840]   it's free because most most of the other echo voices are not. I have Samuel Jackson swearing at me
[01:56:41.840 --> 01:56:48.960]   from time to time. Melissa McCarthy telling me jokes. Is this something that's really useful?
[01:56:48.960 --> 01:56:53.200]   No, no, it's cool. But with accessibility, if you have kids, it's neat because like
[01:56:53.200 --> 01:56:56.960]   they have character, like you can actually talk to the characters. So love like your
[01:56:56.960 --> 01:57:02.240]   six year old loves Olaf. Yeah, let it go. Now I get it. Or if you're in the mood to cook a nice meal,
[01:57:02.240 --> 01:57:06.400]   you could say, Hey, I want, you know, rat to tui rat, tell me what to make.
[01:57:06.400 --> 01:57:15.680]   Oh, but remember we told you that Amazon is losing a lot of money on echo, right?
[01:57:15.680 --> 01:57:20.800]   As much as $10 billion a year. So I understand how they lose money on it.
[01:57:21.920 --> 01:57:26.800]   Because across a lot of developers, well, there's a couple things. There's one,
[01:57:26.800 --> 01:57:31.120]   they had a bunch of people like they hired like mad to do things like,
[01:57:31.120 --> 01:57:36.640]   not attestation, what's it called when you're annotation? Sorry, annotations. So they were
[01:57:36.640 --> 01:57:40.560]   annotate. So they had all these people all over the world, annotating to make Madamay better.
[01:57:40.560 --> 01:57:45.600]   They also hired a bunch of people to go in all sorts of crazy directions like, Oh, yeah,
[01:57:45.600 --> 01:57:50.560]   you want to put Madamay in his college, we're going to set up a team of 200 people to do that.
[01:57:50.560 --> 01:57:54.160]   And so that's kind of they just went a little nuts.
[01:57:54.160 --> 01:58:00.000]   Also, it costs money. A server is not free. I think we often feel like Google's free or whatever.
[01:58:00.000 --> 01:58:05.120]   But every search you do on Google costs, you know, a fraction of a cent.
[01:58:05.120 --> 01:58:11.840]   Chat GBT is 10 times more expensive, according to Sam Altman. So servers cost money. They use
[01:58:11.840 --> 01:58:16.560]   electricity. You got to build a facility. I mean, it's not cheap. So yeah, it's possible to lose
[01:58:16.560 --> 01:58:20.320]   $10 billion a year, especially since they don't make money on the hardware. That was the key on
[01:58:20.320 --> 01:58:26.720]   that story was they sell you those Echo devices at cost. Right. So they have to, they thought
[01:58:26.720 --> 01:58:32.480]   people would buy a lot of stuff. So, but I think this is a them finding a new revenue model, right?
[01:58:32.480 --> 01:58:37.200]   Okay. How about a Disney thing? I noticed, by the way, my Echo show keeps saying,
[01:58:37.200 --> 01:58:45.760]   don't you want to have the avatar experience on your Echo? No. But I'm sure, I mean, it's still
[01:58:45.760 --> 01:58:50.960]   doing it. I'm sure Avatar, whoever that movie company has paid him a lot on my
[01:58:50.960 --> 01:58:54.560]   bringing ads to Echo. And eventually they will bring it to your
[01:58:54.560 --> 01:58:59.280]   other things. Oh, the dog. Can I camera again?
[01:58:59.280 --> 01:59:04.240]   Kylo is very active. He's out. He's gone.
[01:59:04.240 --> 01:59:13.040]   So Leo, back to your search engine. I wonder whether this whole talk about chat GBT and search
[01:59:13.920 --> 01:59:19.360]   people. We thought that people were going to speak sentences to this device and it was going to
[01:59:19.360 --> 01:59:25.440]   speak sentences back to us. And this was going to replace so much interaction with the digital world.
[01:59:25.440 --> 01:59:30.720]   And it didn't happen. That's the real important of the story. So is that just voice or is that
[01:59:30.720 --> 01:59:35.680]   we don't really want to end up in full sentences. We want to be able to say, Pete's a near me and
[01:59:35.680 --> 01:59:41.840]   leave it at that. And I don't want to serve. Well, I think there's just a cheaper route of going
[01:59:41.840 --> 01:59:49.440]   from anywhere. I think it's hard to do with voice. So I had actually the voice designer for Google.
[01:59:49.440 --> 01:59:53.600]   So a woman named Cathy Pearl, we talked about this on my show. Yes, she was really cool.
[01:59:53.600 --> 02:00:00.000]   And she talked about, with voice, one of the challenges is because you only have one thing
[02:00:00.000 --> 02:00:05.120]   you can say back to someone. If you say, "Hey, I want to order a pizza," you don't really want
[02:00:05.120 --> 02:00:11.440]   to spend the time saying where, then the responses were, "Would you like to get your pizza from
[02:00:11.440 --> 02:00:16.080]   Domino's? What kind of pizza do you want?" I mean, that's a pretty, for that level of interaction,
[02:00:16.080 --> 02:00:20.080]   she's like, "It's possible." She says the best way that she thinks about it is,
[02:00:20.080 --> 02:00:25.760]   is this a conversation you would have with a friend or a person? And if you would actually
[02:00:25.760 --> 02:00:29.440]   say all that to them, then it's possible. But for the most part,
[02:00:29.440 --> 02:00:34.960]   those longer interactions, the problem with voice is you have so much choice.
[02:00:34.960 --> 02:00:40.160]   And so unless you go in ahead of time and say, "I always want to order from Papa John's," and I
[02:00:40.160 --> 02:00:48.720]   always want a pineapple and bacon pizza, then you need to order for your protection.
[02:00:48.720 --> 02:00:53.840]   Can you even not be given such a thing? Can you even order food on an Echo? I mean, could I say to...
[02:00:53.840 --> 02:00:58.560]   They did have a Domino's... So again, Domino's is a tech forward company. They had an
[02:00:58.560 --> 02:01:02.240]   Alexa skill. So you could say, "Hey, Madam A, open up the Domino skill."
[02:01:02.240 --> 02:01:06.960]   Oh. And then you could order a pizza. It was too many steps, probably. I think people really...
[02:01:07.680 --> 02:01:10.880]   Mostly I just want to know when my Asperagus is done, frankly.
[02:01:10.880 --> 02:01:17.760]   I sit tiny. That's what it boils down to. It's just too daggle. I steam it. I don't
[02:01:17.760 --> 02:01:23.200]   put the voice. You should... Oh, shove it in the june. What are you doing?
[02:01:23.200 --> 02:01:27.840]   Shove it in the june. Oh, that's roasting. We do that with... Pop that in there.
[02:01:27.840 --> 02:01:31.680]   Oh, no. We do that with Brussels sprouts. Really, the june is very good at Brussels sprouts.
[02:01:31.680 --> 02:01:36.240]   We went through a whole phase. I'll do that with Speragus next time. Thank you.
[02:01:36.800 --> 02:01:41.760]   Try it. About five years ago, almost five years ago, we had a company called Reviver
[02:01:41.760 --> 02:01:45.440]   on the new screensavers. It was me and Patrick Norton showing off
[02:01:45.440 --> 02:01:50.000]   their digital license plates. Let me see if I can skip ahead.
[02:01:50.000 --> 02:01:53.360]   So, have you got to explain why anyone would ever do this to me?
[02:01:53.360 --> 02:02:00.320]   It seemed like a really bad idea. Yeah, I hope that the new screensavers don't take us down.
[02:02:00.320 --> 02:02:03.840]   Here is the CEO of Reviver, which is a company that made
[02:02:04.560 --> 02:02:09.520]   digital license plates. They had not yet gotten it approved. One of our staffers,
[02:02:09.520 --> 02:02:15.520]   no longer here, Josh bought one of these. Actually, it's... You read it for them, like an expensive
[02:02:15.520 --> 02:02:21.920]   monthly fee and got pulled over by a CHP officer who said, "What the hell is that like?" You need
[02:02:21.920 --> 02:02:27.600]   a license plate, dude. He said, "No, no, it's a legal license plate." They stretched a little
[02:02:27.600 --> 02:02:34.560]   bit to find a use for these revivers. I have seen them from time to time on vehicles
[02:02:34.560 --> 02:02:40.000]   around town. Look, you can even have a picture of me on their license. That's their license I need.
[02:02:40.000 --> 02:02:44.560]   Well, turns out... It can't be anywhere. Turns out they got hacked.
[02:02:44.560 --> 02:02:52.000]   No. Researchers hacked California's digital license plate gaining access to GPS location
[02:02:52.560 --> 02:02:58.560]   and user info just months after the release of the Reviver R plates.
[02:02:58.560 --> 02:03:05.280]   It's only a matter of time. They went on sale in California late last year.
[02:03:05.280 --> 02:03:09.360]   Those were legit. You could use those legally on the road. Yeah, took them a while to get
[02:03:09.360 --> 02:03:14.400]   government approval. Cool. But... Well, that's so cool. I put this in the rundown.
[02:03:14.400 --> 02:03:19.120]   Well, yeah, then there's that. It's a lot of the codes. It's a lot of the
[02:03:19.120 --> 02:03:24.480]   funny link to like, "Why would anyone ever do this?" Yeah, it was expensive too, as I remember,
[02:03:24.480 --> 02:03:29.440]   but I don't know why Josh thought it was cool, I guess. The bug also allowed researchers to update
[02:03:29.440 --> 02:03:38.080]   the status of any digital California plate to stolen. Likely getting you pulled over. I would,
[02:03:38.080 --> 02:03:45.280]   you know, I would guess. Yeah. So maybe not such a good idea.
[02:03:47.360 --> 02:03:49.680]   I'm just saying. Just thinking.
[02:03:49.680 --> 02:04:00.560]   Let's see. What else? What else is going on? Change lock? Do we do change locks?
[02:04:00.560 --> 02:04:04.320]   John Deere is now allowing you to... Yeah, no, let's do a change lock. John Deere is now allowing
[02:04:04.320 --> 02:04:10.400]   you to open your tractor tech. But first, a word from Google. Because we got to say something.
[02:04:11.760 --> 02:04:18.480]   Google Pixel phones just got their new monthly dump and it allows you to get 5G in India.
[02:04:18.480 --> 02:04:30.000]   QPR2 beta 2. Google messages rolls out group chat and end encryption in beta. Google Maps for
[02:04:30.000 --> 02:04:37.520]   Wear OS adds a phoneless navigation on LTE watches. Too bad you don't have a Wear OS watch. Anybody?
[02:04:37.520 --> 02:04:43.520]   Anybody? Bueller? L1. Bueller? Google's new high definition maps are arriving first on Volvo
[02:04:43.520 --> 02:04:49.040]   and Polestar electric vehicles. I wouldn't mind an HD map. I think that's pretty cool. I want a
[02:04:49.040 --> 02:04:57.200]   Polestar too. Yeah, those are the Volvo backed EVs. And the full Android operating system that
[02:04:57.200 --> 02:05:02.240]   goes to my heart. You don't live in the Google. Well, let's get you one. Hey, Mr. Polestar. Yeah.
[02:05:02.240 --> 02:05:06.560]   Hey, Mr. Polestar. Can you get one of these? Yeah, he's watching.
[02:05:07.520 --> 02:05:12.640]   I think his name is Herbert Polestar. Did you ever get a free
[02:05:12.640 --> 02:05:17.840]   burrito? No, nothing. Nothing. Nothing. Nothing. No. Maybe try one of those new case adias. It
[02:05:17.840 --> 02:05:23.200]   tastes like Vida's mixed with... Time that you were going to say feet. And I was like, no!
[02:05:23.200 --> 02:05:33.040]   Vida flavored feet. Google's new split screen for Android Auto is rolling out. I have Android Auto
[02:05:33.040 --> 02:05:39.360]   on my vehicle, so I will give this a shot. It's been floating around in Vida for some time.
[02:05:39.360 --> 02:05:43.040]   What do you think about this? I don't know if I want... I like the full screen for the map.
[02:05:43.040 --> 02:05:50.800]   Yeah. I mean, I go back and forth. I use Apple CarPlay, but I think it's cool to have...
[02:05:50.800 --> 02:05:56.160]   Especially on my car where the screen is pretty big. It would depend on the screen size, wouldn't it?
[02:05:56.160 --> 02:06:00.480]   Yeah, mine's not that big on my own stuff. Yeah. The new Android Auto is here.
[02:06:01.600 --> 02:06:06.240]   Hey, this is really exciting. Google Meet is rolling out in call emoji reactions.
[02:06:06.240 --> 02:06:10.720]   I see making a mistake of doing that in a faculty meeting.
[02:06:10.720 --> 02:06:19.120]   Pumps up. Yeah. Well, we do a few Google meets. I'll try it in our next staff meeting.
[02:06:19.120 --> 02:06:25.840]   Get this. This stuff apparently matters to people under 40. Who is this person getting hearts and
[02:06:25.840 --> 02:06:31.200]   celebrations? Dang. Nisha Madison. Wait a minute. Wait a minute. No, I'm sorry.
[02:06:31.200 --> 02:06:39.280]   Aiden Taylor is getting a heart from Nisha Madison and Nisha. I think Aiden can sue. Yeah.
[02:06:39.280 --> 02:06:47.040]   I think that's unwanted attention, unwanted emoji. That's a new thing in California law.
[02:06:47.760 --> 02:06:57.680]   And Google Docs adds a feature we thought it already had. Says the Verge. Says the Verge.
[02:06:57.680 --> 02:07:02.640]   Non-printing characters. So there you go. You've been waiting for it. Now you got it. That's...
[02:07:02.640 --> 02:07:10.720]   The Google change lock. That was swift and efficient. Efficiency is my middle name because waffles
[02:07:10.720 --> 02:07:13.520]   await. I do want to mention, I forgot to mention this when we were talking about the
[02:07:13.520 --> 02:07:19.520]   Reviver license plates. The governor of our fair estate, Gavin Newsom, in his state of the union
[02:07:19.520 --> 02:07:26.720]   address, said something kind of interesting. He said that Californians are going to get
[02:07:26.720 --> 02:07:34.240]   a digital ID, but it's going to be... He didn't mention Apple at all, which is so far the only way.
[02:07:34.240 --> 02:07:41.840]   I think you can do a digital ID with the Apple system, and it's going to be something extra
[02:07:41.840 --> 02:07:49.120]   marvelous. Did he really use the phrase extra marvelous? Well, I'll give you the exact quote.
[02:07:49.120 --> 02:07:54.480]   We're going to do it like no other... This is a very Trumpian quote. We're going to do it like no
[02:07:54.480 --> 02:08:00.960]   other state. "Know this," says Governor Newsom, who is probably running for president in a couple
[02:08:00.960 --> 02:08:05.760]   of years. Actually, it'd be next year, wouldn't it? "Know this in just a matter of months.
[02:08:06.480 --> 02:08:13.040]   We're finally going to have those digital wallets where you can get your driver's license on a
[02:08:13.040 --> 02:08:18.720]   digital wallet, and we're going to do it like no other state has done it. There's only a few that
[02:08:18.720 --> 02:08:25.440]   have, but there's issues ours think it'll be next level. We're so excited about what the DMV can
[02:08:25.440 --> 02:08:39.680]   look like. This makes no sense. It's part of the California 2023-24 budget proposal,
[02:08:39.680 --> 02:08:48.320]   and he says it's coming into state money. I don't know. It's hip, it's happening, it's with it.
[02:08:48.320 --> 02:08:54.320]   Wasn't Rick Cloud the guy? Was he the chief digital officer for...
[02:08:54.320 --> 02:08:58.240]   He was. He's no longer doing that. That's right. He was. He was hatching that.
[02:08:58.240 --> 02:09:03.920]   You know, I'm curious because a number of states do have these Apple digital IDs, but you know,
[02:09:03.920 --> 02:09:07.920]   it's complicated because you can't just say, "Well, that can work as a driver's license. Now you have
[02:09:07.920 --> 02:09:14.000]   to give all the police in the state the ability to somehow verify that that's not a picture on
[02:09:14.000 --> 02:09:17.680]   your screen that that's a real driver's license. "What about me on Android?"
[02:09:18.480 --> 02:09:25.360]   And what about you on Android? It sounds like I'm going to guess because he didn't mention Apple at
[02:09:25.360 --> 02:09:31.520]   all that it is perhaps something more than the Apple thing. Here's an example of the Arizona
[02:09:31.520 --> 02:09:38.720]   driver's license on your watch, which is cool. Cool as heck. But there's got to be some way to
[02:09:38.720 --> 02:09:42.400]   verify it for law enforcement to verify it. Otherwise you could just put a picture on there.
[02:09:43.360 --> 02:09:48.800]   So don't get me wrong. I like the convenience of having like a digital wallet and not having to
[02:09:48.800 --> 02:09:55.040]   pull out my wallet and grab the card and tap or insert or what have you. But at the same time,
[02:09:55.040 --> 02:10:00.720]   I think I have some privilege and everybody's not going to do that. Oh no, absolutely. And so
[02:10:00.720 --> 02:10:07.040]   they have to still offer cards, obviously. But look, I have on my... Uh oh, Stacy spazzed out. We
[02:10:07.040 --> 02:10:12.640]   better hurry. I had... Sorry, my dog is making weird noises. So I was seeing what was going on.
[02:10:13.520 --> 02:10:20.080]   Stacy wanted to see what the show looked like if it was sideways. And does it look better sideways?
[02:10:20.080 --> 02:10:25.680]   I don't know. No way, dog was snoring. So I was confused because it was a weird noise.
[02:10:25.680 --> 02:10:31.120]   Do we all lean left or right, Jeff? Left? Okay. Well, that means I got to go this way.
[02:10:31.120 --> 02:10:34.640]   I can't do it and do it right.
[02:10:34.640 --> 02:10:41.520]   Nope. Stacy's leaning right. Nope. That's just leaning left.
[02:10:41.520 --> 02:10:46.080]   I can't... I can't. Okay, there we go. Let's get... Come on in. Join the other way.
[02:10:46.080 --> 02:10:50.560]   Other way. Join the... We're all leaning left. You know, people have always said this was a
[02:10:50.560 --> 02:10:55.600]   left leaning show. Now they know it's... We're going to hear about that comment. It's true.
[02:10:55.600 --> 02:11:04.960]   I like it. This is a California vaccination card that proves that it's legal, right? And I can use
[02:11:04.960 --> 02:11:09.280]   it. There's a QR code on it. It's my Apple wall. It has it. And I can use this almost anywhere that
[02:11:09.280 --> 02:11:13.760]   they want. They used to want that. They don't care anymore now. But when they wanted vaccination
[02:11:13.760 --> 02:11:18.960]   cards, that was... I thought that was pretty cool. Yeah. Yeah. That was California, I think.
[02:11:18.960 --> 02:11:25.200]   All right. We had QR codes. But the points you make about the law enforcement having some type of
[02:11:25.200 --> 02:11:32.400]   the code is going to verify. That's what makes me nervous because we're already dealing with some of
[02:11:32.400 --> 02:11:40.400]   our worst police officers having ego issues. And now you're telling them to pull out some type of
[02:11:40.400 --> 02:11:44.880]   device and... I don't know. I don't want them plugging anything in the market. Well, you're either, right?
[02:11:44.880 --> 02:11:50.480]   Then there's the end. Oh, no. That too. That too. Well, Stacy's got to get... I mean,
[02:11:50.480 --> 02:11:54.160]   because what if they... Go ahead. Oh, I was going to say because you've got to show them,
[02:11:54.160 --> 02:11:57.840]   so you're going to have to unlock your phone. What if they just swipe it? Yeah. And then you're like,
[02:11:57.840 --> 02:12:01.600]   "Oh, no!" Yeah, I'm not sure. I know. I agree. I'm not sure this is great. I mean,
[02:12:01.600 --> 02:12:06.560]   I don't know how they do it in the states where it's currently implemented. But maybe there's a QR code
[02:12:06.560 --> 02:12:12.240]   or something. But you could fake that too. You could do a screenshot. Yeah. Yeah. I can fake a QR code
[02:12:12.240 --> 02:12:19.200]   like myself. I don't even have to know anything. Stacy is running late for her dinner date with the
[02:12:19.200 --> 02:12:26.080]   first CRISPR gene edited meat. So we're going to let her be the guinea pig. Did you want to talk
[02:12:26.080 --> 02:12:32.160]   about John Deere? Oh, yeah. John Deere. What is there to say? Do they... It's the right to repair
[02:12:32.160 --> 02:12:40.160]   alliances. One, is it a victory? It is sort of. So there's ish. So what they did is they signed a
[02:12:40.160 --> 02:12:47.840]   memorandum of understanding with the American Farm Bureau Federation. And so all this is a commercial
[02:12:47.840 --> 02:12:53.360]   agreement between John Deere and a group of farmers to say that John Deere is going to let
[02:12:53.360 --> 02:13:00.960]   farmers access repair information and repair software for fair and reasonable terms. So
[02:13:00.960 --> 02:13:06.880]   for end terms. Well, an M.R.U. is binding. It's legally binding. It is. So what it doesn't do,
[02:13:06.880 --> 02:13:11.600]   though, so the farmers have to promise not to like share this everywhere so they can't post it. This
[02:13:11.600 --> 02:13:18.400]   is kind of like a secret commercial agreement. If the states or Congress come up with the law,
[02:13:18.400 --> 02:13:26.320]   it will supersede this. And there are things like, you know, they are still going to have to pay
[02:13:26.320 --> 02:13:33.200]   for access to this. And it's, you know, and I think they would need to keep the pressure on by
[02:13:33.200 --> 02:13:38.720]   having continued lawsuit, not lawsuits. The threat of legislation, I think, is a good reason because
[02:13:38.720 --> 02:13:45.040]   that's why John Deere actually did this. Because Congress was like, I'm sorry, you have got to
[02:13:45.040 --> 02:13:49.440]   get your stuff together, JD, because if farmers can't harvest their stuff because they can't
[02:13:49.440 --> 02:13:54.400]   repair their tractors, that affects our food supply. Not good. And John Deere is like, okay, fine,
[02:13:54.400 --> 02:13:59.040]   we'll do this. Yeah, I mean, I think the government coming after them in 2021,
[02:13:59.040 --> 02:14:05.920]   President Biden issued an executive order urging the FTC to crack down. FTC said it will devote
[02:14:05.920 --> 02:14:14.080]   more resources to combating unlawful repair restrictions. John Tester from Montana, big farm state,
[02:14:14.080 --> 02:14:20.080]   introduced legislation to limit repair restrictions in ag. More than half of the US states considering
[02:14:20.080 --> 02:14:24.880]   right to repair laws. Although New York's right to repair law, which was the first and a model
[02:14:24.880 --> 02:14:31.760]   has been somewhat gutted by Governor Hochill before she signed it. I think we're making progress.
[02:14:31.760 --> 02:14:35.520]   And I think you're right. I think John Deere. I have a pretty ex I don't have a year. He put
[02:14:35.520 --> 02:14:41.360]   up a very long thread about this. You can imagine that he'd be victorious, but also suspicious. Yeah,
[02:14:41.360 --> 02:14:46.560]   as are as are many over the John Deere agreement. So, you know, let's see. But I think the I think
[02:14:46.560 --> 02:14:52.400]   the writings in the wall, Apple's bowed to pressure to allow people to repair their fine. Yeah, in a
[02:14:52.400 --> 02:14:59.040]   in a very malicious stand on your head. Yeah. One hand tie behind your back. And that is the
[02:14:59.040 --> 02:15:04.880]   question like, what is compliance going to look like under this? And we don't know yet. Hey,
[02:15:04.880 --> 02:15:10.880]   everybody, Leo LePort here. I am the founder and one of the hosts at the Twitch podcast network.
[02:15:11.200 --> 02:15:15.200]   I want to talk to you a little bit about what we do here at Twitch, because I think it's unique.
[02:15:15.200 --> 02:15:23.040]   And I think for anybody who is bringing a product or a service to a tech audience,
[02:15:23.040 --> 02:15:29.440]   you need to know about what we do here at Twitter. We've built an amazing audience of engaged,
[02:15:29.440 --> 02:15:36.960]   intelligent, affluent listeners who listen to us and trust us when we recommend a product. Our
[02:15:36.960 --> 02:15:41.440]   mission statement is to build a highly engaged community of tech enthusiasts.
[02:15:41.440 --> 02:15:47.200]   But already you should be your ears should be perking up at that because highly engaged
[02:15:47.200 --> 02:15:52.320]   is good for you. Tech enthusiasts, if that's who you're looking for, this is the place. We do it
[02:15:52.320 --> 02:15:57.280]   by offering them the knowledge they need to understand and use technology in today's world.
[02:15:57.280 --> 02:16:02.160]   And I hear from our audience all the time, part of that knowledge comes from our advertisers.
[02:16:02.720 --> 02:16:09.120]   We are very careful. We pick advertisers with great products, great services with integrity
[02:16:09.120 --> 02:16:17.200]   and introduce them to our audience with authenticity and genuine enthusiasm. And that makes our host
[02:16:17.200 --> 02:16:23.760]   red ads different from anything else you can buy. We are literally bringing you to the attention of
[02:16:23.760 --> 02:16:31.120]   our audience and giving you a big fat endorsement. We like to create partnerships with trusted brands,
[02:16:31.120 --> 02:16:36.880]   brands who are in it for the long run, long term partners that want to grow with us.
[02:16:36.880 --> 02:16:42.880]   And we have so many great success stories. Tim Broome, who founded ITProTV in 2013,
[02:16:42.880 --> 02:16:48.560]   started advertising with us on day one has been with us ever since. He said, quote,
[02:16:48.560 --> 02:16:54.160]   "We would not be where we are today without the Twit Network." I think the proof is in the pudding.
[02:16:54.160 --> 02:16:59.440]   Advertisers like ITProTV and Audible that have been with us for more than 10 years.
[02:16:59.440 --> 02:17:05.600]   They stick around because their ads work. And honestly, isn't that why you're buying advertising?
[02:17:05.600 --> 02:17:10.960]   You get a lot with Twit. We have a very full service attitude. We almost think of it as
[02:17:10.960 --> 02:17:18.080]   kind of artisanal advertising, boutique advertising. You'll get a full service continuity team.
[02:17:18.080 --> 02:17:23.680]   People who are on the phone with you, who are in touch with you, who support you with everything
[02:17:23.680 --> 02:17:31.440]   from copywriting to graphic design. So you are not alone in this. We embed our ads into the
[02:17:31.440 --> 02:17:36.320]   shows. They're not added later. They're part of the shows. In fact, often,
[02:17:36.320 --> 02:17:40.640]   they're such a part of our shows that our other hosts will chime in on the ad saying,
[02:17:40.640 --> 02:17:46.160]   "Yeah, I love that." Or just the other day, one of our hosts said, "Man, I really got to buy that."
[02:17:46.160 --> 02:17:52.640]   That's an additional benefit to you because you're hearing people, our audience trusts saying,
[02:17:52.640 --> 02:17:58.640]   "Yeah, that sounds great." We deliver, always over deliver on impressions. So you know you're
[02:17:58.640 --> 02:18:04.160]   going to get the impressions you expect. The ads are unique every time. We don't pre-record
[02:18:04.160 --> 02:18:09.360]   them and roll them in. We are genuinely doing those ads in the middle of the show. We'll give
[02:18:09.360 --> 02:18:14.080]   you great onboarding services, ad tech with pod sites that's free for direct clients.
[02:18:14.080 --> 02:18:18.800]   Gives you a lot of reporting, gives you a great idea of how well your ads are working.
[02:18:18.800 --> 02:18:22.720]   You'll get courtesy commercials. You actually can take our ads and share them across
[02:18:22.720 --> 02:18:27.520]   social media and landing pages. That really extends the reach. There are other free goodies,
[02:18:27.520 --> 02:18:33.280]   too, including mentions in our weekly newsletter that sent to thousands of fans, engaged fans who
[02:18:33.280 --> 02:18:38.000]   really want to see this stuff. We give you bonus ads and social media promotion, too.
[02:18:38.000 --> 02:18:45.440]   So if you want to be a long-term partner, introduce your product to a savvy, engaged tech audience,
[02:18:45.440 --> 02:18:51.840]   visit twit.tv/advertise. Check out those testimonials. Mark McCrary is the CEO of
[02:18:51.840 --> 02:18:57.120]   Authentic. You probably know him, one of the biggest original podcast advertising companies.
[02:18:57.120 --> 02:19:03.360]   We've been with him for 16 years. Mark said the feedback from many advertisers over 16 years
[02:19:03.360 --> 02:19:10.000]   across a range of product categories. Everything from razors to computers is that if ads and
[02:19:10.000 --> 02:19:15.280]   podcasts are going to work for a brand, they're going to work on Twitch shows. I'm very proud of
[02:19:15.280 --> 02:19:22.720]   what we do because it's honest. It's got integrity. It's authentic. And it really is a great introduction
[02:19:22.720 --> 02:19:29.920]   to our audience of your brand. Our listeners are smart. They're engaged. They're tech savvy.
[02:19:29.920 --> 02:19:35.040]   They're dedicated to our network. And that's one of the reasons we only work with high-integrity
[02:19:35.040 --> 02:19:40.480]   partners that we've personally and thoroughly vetted. I have absolute approval on everybody.
[02:19:40.480 --> 02:19:45.360]   If you've got a great product, I want to hear from you. Elevate your brand by reaching out today
[02:19:45.360 --> 02:19:51.760]   at advertise at twit.tv. Break out of the advertising norm. Grow your brand with host red ads on
[02:19:51.760 --> 02:20:00.400]   twit.tv. Visit twit.tv/advertise for more details or you can email us advertise at twit.tv
[02:20:00.400 --> 02:20:04.640]   if you're ready to launch your campaign now. I can't wait to see your product. So give us a ring.
[02:20:04.640 --> 02:20:13.040]   Let us conclude this fine festivity by getting Stacy to give us a thing of the week.
[02:20:13.040 --> 02:20:18.240]   Now that it's dark out. Okay. Yes. Now that it's dark. Okay. I have
[02:20:18.240 --> 02:20:24.960]   Trat. Stacy has induced God to turn on dark mode in her native region.
[02:20:26.240 --> 02:20:31.520]   Well, is it dark where y'all are? Yeah. Is it not dark? Sure is here. Well, I know.
[02:20:31.520 --> 02:20:36.480]   Well, you have a lot of cloud with the with the woman upstairs and I think you've convinced her.
[02:20:36.480 --> 02:20:44.720]   Okay. Dark mode is the only. I'm sorry. I'm I'm not is I'll tell you what it is. It's an induction
[02:20:44.720 --> 02:20:48.960]   burner. We saw at CES that is really cool. I like induction stuff. I still trying to get
[02:20:48.960 --> 02:20:53.600]   induction stove top. I really want it. Why can't you? We have that. It's great.
[02:20:54.720 --> 02:21:01.200]   This is called the Tramantina. So Tramantina is cool. That's a region in Italy.
[02:21:01.200 --> 02:21:08.000]   It is. Well, it's it's a Brazilian country. Oh, sorry. It's a Brazilian company.
[02:21:08.000 --> 02:21:13.440]   Okay. And they actually make the T fall brand of cookware, by the way,
[02:21:13.440 --> 02:21:18.160]   which for a long time I've we used to use it. We don't do it anymore because it's
[02:21:18.160 --> 02:21:24.080]   cancer causing or something, but they have both cancer causing and non cancer. Oh, that's nice.
[02:21:24.080 --> 02:21:29.680]   Now they offer the new non cancer causing nonstick. That's great. Non piece of fast.
[02:21:29.680 --> 02:21:34.080]   I don't know if it's causing anyway. I just I read somewhere and I dimly remember it's probably
[02:21:34.080 --> 02:21:39.280]   not good to have nonstick cookware. Was it one of your California labels? What said that is on
[02:21:39.280 --> 02:21:44.480]   everything? This is this thing. Yeah. So the Tramantina induction cooktop is available even at Target.
[02:21:44.480 --> 02:21:53.280]   Well, so they this is the guru. This is a new one. They showed it. CES. So the Tramantina guru.
[02:21:53.920 --> 02:22:00.240]   Um, this is expected in the first quarter. It's going to cost between 299 and 349. It's a single
[02:22:00.240 --> 02:22:08.240]   burner induction, but it like our June oven has a scale inside and it also comes with thousands,
[02:22:08.240 --> 02:22:13.600]   not thousands, sorry, hundreds of recipes that will walk you through all the cooking steps and
[02:22:13.600 --> 02:22:18.960]   control the burner. Now on Sunday, you talked about speed. On Sunday, you talked about like you
[02:22:18.960 --> 02:22:25.040]   had a Heston Q or some sort of smart pan and you don't like it anymore. I do have it. Yeah. I don't
[02:22:25.040 --> 02:22:30.320]   like it because it's buggy to mess with because the Heston Q has to talk with the GE and it has
[02:22:30.320 --> 02:22:36.640]   talked with the right device and like if and you know how to cook. And I also you already know how
[02:22:36.640 --> 02:22:42.640]   to cook. So you don't need the pan to tell you what to do. The one advantage though I like of
[02:22:42.640 --> 02:22:48.560]   introduction is the temperature control is very precise. Control is amazing. Yeah. Well here and
[02:22:48.560 --> 02:22:52.560]   I will also say we're going to get to a point. I don't know if you've been following this, but
[02:22:52.560 --> 02:22:59.840]   there's been a lot of ink spilled lately about should we ban gas stoves? Right. Right. Because
[02:22:59.840 --> 02:23:06.000]   gas in the kitchen is causing problems, health problems. Oh, is it really? So I don't. It's not
[02:23:06.000 --> 02:23:10.480]   just it's not just a natural gas is dangerous for this. Climate. It's bad for your health.
[02:23:11.520 --> 02:23:17.840]   It's bad like gas stoves in homes or homes. Children who grew up in homes with gas stoves
[02:23:17.840 --> 02:23:24.000]   have a higher or 42% higher rate of asthma is the most recent. That's interesting. But there's
[02:23:24.000 --> 02:23:31.520]   been a lot of like and I'm not going to argue about the politics of gas stoves, whatever, but also
[02:23:31.520 --> 02:23:36.480]   I'm ready to get off natural gas in our house. We'd like to replace everything including the.
[02:23:36.480 --> 02:23:40.400]   Well, and that's as part of the electrification effort. But if you read this stuff and you're
[02:23:40.400 --> 02:23:45.200]   freaked out, an induction burner is a great way to get started for less than buying a whole new
[02:23:45.200 --> 02:23:51.840]   cooktop. It's basically a magnet. Right. And you need to have a cookware that is.
[02:23:51.840 --> 02:23:57.520]   Special cookware. It has magnetic steel steel or something with iron in it. Yeah, not aluminum.
[02:23:57.520 --> 02:24:04.720]   And then it doesn't get it doesn't have a heated like you could touch an induction
[02:24:04.720 --> 02:24:08.480]   cooktop without burning yourself. But the pan gets hot, which is kind of cool.
[02:24:09.680 --> 02:24:13.600]   Well, it does get hot. I mean, from the pan. From the pan. Yeah, from the pan.
[02:24:13.600 --> 02:24:16.560]   Yeah. I just I don't want anybody being like, look,
[02:24:16.560 --> 02:24:22.800]   Oh, Leo said. And they're easier to clean because there's no interstices.
[02:24:22.800 --> 02:24:30.480]   Yes. So the point being, I thought this was a really cool product. It's also a cool product for
[02:24:30.480 --> 02:24:36.240]   people who are like living in apartments or going to college because like I'm hopeful that when my
[02:24:36.240 --> 02:24:40.560]   child goes to college, I can send them off with an induction burner if because they like to cook.
[02:24:40.560 --> 02:24:46.960]   And boom, it's not anything. Buzzfeed tasty one. That's what I was going to say. Buzzfeed
[02:24:46.960 --> 02:24:52.560]   tasty had something like this a couple years ago. But it died. Yeah. So this is that again.
[02:24:52.560 --> 02:25:01.120]   App on iOS and Android. Unfortunately, this site is in Portuguese, but I'm getting the gist.
[02:25:01.120 --> 02:25:04.560]   The pictures are nice. And that's cool. How much?
[02:25:04.560 --> 02:25:09.760]   Two ninety nine to three forty nine. Okay. For a single burner.
[02:25:09.760 --> 02:25:16.400]   Yes. Now a single burner like a like a budget single burner from no name brand on Amazon is
[02:25:16.400 --> 02:25:20.560]   like a hundred and fifteen. Okay. So it's not just to give you a little bit of a. I mean,
[02:25:20.560 --> 02:25:26.000]   it is it's twice. It's more than twice as much. But a name brand burner.
[02:25:27.040 --> 02:25:34.160]   It's a bit is like 200. It's like 175 to 200. So this is more. But it does have that integrated
[02:25:34.160 --> 02:25:39.680]   scale, which is kind of nice. And the rest. Oh, it does. Oh, that's cool. That's in everywhere.
[02:25:39.680 --> 02:25:43.920]   There's no subscription fee. You know, I think that's because of MEMS that we we have scales
[02:25:43.920 --> 02:25:50.720]   everywhere now. Micro electromechanical machines. No, I know what MEMS are. I'm just trying to
[02:25:50.720 --> 02:25:57.040]   follow your train of thought about why because we can put I think these scales in the feet of
[02:25:57.040 --> 02:26:01.600]   the June of and in the feet of the tromontina guru and others are actually MEMS because they're
[02:26:01.600 --> 02:26:06.960]   small and compact. They're inexpensive. And so they're starting to build these scales in everything,
[02:26:06.960 --> 02:26:12.800]   including that monogram G monogram mixer you were talking about has a scale in it.
[02:26:12.800 --> 02:26:18.880]   Pro file mixer. Yeah. Yeah. Interesting. Okay. I don't know. I'm just my that's my
[02:26:19.520 --> 02:26:26.880]   that's my assumption. Anybody wants to correct me? Then please do. No, I mean,
[02:26:26.880 --> 02:26:32.640]   cheaper, cheaper scale sensors make sense. When you said, I mean, MEMS are so many things. It's
[02:26:32.640 --> 02:26:38.400]   kind of like, you know why we have life on earth, water, oxygen, it's cuz I felt like that.
[02:26:38.400 --> 02:26:47.600]   Water. Water. But you can put basically, MEMS are solid state scales, right, that you can put
[02:26:47.600 --> 02:26:52.800]   into things and they're small. So, well, MEMS are any devices. They can be a variety of things,
[02:26:52.800 --> 02:26:57.840]   but they can be scammed. Yeah, anything to convert the digital or the analog world to digital. So,
[02:26:57.840 --> 02:27:02.480]   it can be microphones, it can be gyroscopes, anything that's like, I see the real world and I'm going
[02:27:02.480 --> 02:27:08.560]   to tell the computers what it means. MEMS, according to Niva, our chip based technology where sensors
[02:27:08.560 --> 02:27:14.000]   are composed of a suspended mass between a pair of capacitive plates. Well, they all be dang.
[02:27:14.000 --> 02:27:22.000]   Okay, my definition is way better. I agree. I agree. So the tromontina gour
[02:27:22.000 --> 02:27:26.320]   look forward. So that's my thing of the week, because I think it's pretty cool. Yeah. I might,
[02:27:26.320 --> 02:27:30.320]   I mean, I don't need an induction stove, but maybe I'll convince my child they need it.
[02:27:30.320 --> 02:27:37.680]   I have in a drawer somewhere the Heston Q induction burner, which I got with all hands.
[02:27:37.680 --> 02:27:41.920]   So maybe I should just pull that out and use that instead. I just love the idea that you could
[02:27:41.920 --> 02:27:47.680]   set the temperature to 211 degrees. So it won't boil, but it go right up against it, which is cool.
[02:27:47.680 --> 02:27:53.280]   Things like that for simmering. Mr. Jeff Jarvis, did I just use your number of the week?
[02:27:53.280 --> 02:28:00.480]   No. So I'm going to do one that you wouldn't let me do as a story, I'm sure.
[02:28:00.480 --> 02:28:08.960]   It's arcane. Line 66, the Finnish Parliament. There you go. Right there.
[02:28:09.760 --> 02:28:13.680]   You knew that I knew you'd never do it. You never lie. You're right. I skipped over it already.
[02:28:13.680 --> 02:28:18.160]   Yeah. Oh, of course you did. Yeah. I'm going to take this moment of democracy to do it.
[02:28:18.160 --> 02:28:25.520]   The Finnish Parliament rejected an EU copyright legislation as part of the digital services,
[02:28:25.520 --> 02:28:31.040]   the single market digital services, where the EU says we shall all do this, and then each
[02:28:31.040 --> 02:28:36.960]   country does their own their version of it, and Finland had a version of it. And the, the,
[02:28:36.960 --> 02:28:45.040]   the Constitutional Law Committee rejected it because it's about copyright and data mining.
[02:28:45.040 --> 02:28:49.520]   And of course, the EU is saying, no, data mining is bad and Google does it, and so on and forth,
[02:28:49.520 --> 02:28:54.560]   we shouldn't allow all this and then I copyright because the publishers say, you can't take my
[02:28:54.560 --> 02:29:03.280]   snippets to that so wrong. The Finns, God bless their souls, said this violates the,
[02:29:03.280 --> 02:29:08.960]   both the Finnish Constitution and human rights regarding science and education.
[02:29:08.960 --> 02:29:15.280]   And I find this fascinating because one of my complaints about when people say, well,
[02:29:15.280 --> 02:29:19.840]   you shouldn't have that information is you cut off knowledge, you cut off potential knowledge,
[02:29:19.840 --> 02:29:26.000]   and we've got to discuss that. And so what the Finns are saying is that science needs access to
[02:29:26.000 --> 02:29:32.640]   data. Education needs access to data. And I don't know where this goes. I don't know where it ends
[02:29:32.640 --> 02:29:39.120]   up, but I found it to be a really interesting path for constitutional discussion there. Now,
[02:29:39.120 --> 02:29:44.560]   I can tell you that Denmark had no bank robberies last year because there's so little cash in the
[02:29:44.560 --> 02:29:50.400]   country. There's a number. Wow. Wow. You stayed asleep until I came up with that one. That was for
[02:29:50.400 --> 02:29:57.840]   the, wow. But no, and actually, I think the Finnish folks, whoever they might be are right that
[02:29:59.040 --> 02:30:05.200]   I think a lot of times these these copy, these blanket copyright laws are strongly tilted in
[02:30:05.200 --> 02:30:10.720]   favor of copyright holders and against things like education, the public domain and so forth.
[02:30:10.720 --> 02:30:14.560]   I'm sure Corey Doctorow would write a book about this. So good for the Finns.
[02:30:14.560 --> 02:30:18.480]   Maybe I'll go first. Yeah, good. Good for the Finns for saying, yeah, no,
[02:30:18.480 --> 02:30:26.000]   there's a reason we have a public square. And Google Raiders, the people who decide whether
[02:30:26.000 --> 02:30:32.880]   Google search engines doing a good job or not just got a raise to between $14 and $14.50 an hour,
[02:30:32.880 --> 02:30:37.520]   we should say they want to pay. They are not well paid. What the hell?
[02:30:37.520 --> 02:30:45.200]   And they don't get to eat in the cafeteria either. They're contractors, so they don't get anything,
[02:30:45.200 --> 02:30:51.440]   but do they work? That's terrible. They were being paid 10 to $12 an hour. Well, it's kind of a
[02:30:51.440 --> 02:30:56.160]   mechanical Turk task in a way. I think that's probably what they are.
[02:30:56.160 --> 02:30:58.880]   And what are they? It's a terrible job. You have to sit there.
[02:30:58.880 --> 02:31:03.200]   Think about it. How are you going to teach systems? There's going to be more labor like this
[02:31:03.200 --> 02:31:10.480]   in a more AI world where you're teaching the computers. Well, humans have to decide it
[02:31:10.480 --> 02:31:15.360]   somewhere, whether that's right or wrong, and whether it's a good job or bad. And if that's seen
[02:31:15.360 --> 02:31:21.760]   as low wage labor, where you clearly have to be intelligent and educated enough to say,
[02:31:21.760 --> 02:31:27.680]   "Oh, that's right or that's wrong," a computer, you got that wrong. And if that's seen as low level
[02:31:27.680 --> 02:31:33.360]   servant to the machine, that's not great. So they're constantly checking.
[02:31:33.360 --> 02:31:39.200]   Oh, I was going to say you can work from anywhere. There's a lot of flexibility
[02:31:39.200 --> 02:31:44.560]   in here and a lot of those kind of jobs. Well, let's face it, they're probably also in non
[02:31:45.360 --> 02:31:47.680]   and not in the US, right? They're
[02:31:47.680 --> 02:31:54.560]   not bad. I mean, they're causing their jobs here in the US that are work from home that don't
[02:31:54.560 --> 02:31:59.280]   pay a lot of money. But the benefit is they're working from home and these people set their own
[02:31:59.280 --> 02:32:04.480]   hours, so to speak. I know a couple people back into a lot of doing such jobs.
[02:32:04.480 --> 02:32:13.200]   Now we all want to work from home and expect to. To understand better what these guys do as one
[02:32:13.200 --> 02:32:17.440]   Raider explained to Forbes, if someone wants to see pictures of moon jellyfish,
[02:32:17.440 --> 02:32:22.720]   and for some reason enters moon pie jellyfish, Raiders see to it people don't get results about
[02:32:22.720 --> 02:32:29.920]   marshmallow snacks. Thank God. I think they should get paid more. Yeah, they should get paid more,
[02:32:29.920 --> 02:32:37.360]   but Mr. Jarvis, I still think that having someone higher just to understand the nuance of props
[02:32:37.360 --> 02:32:42.560]   is going to be a premium job at some point. That's a coding job, really.
[02:32:43.040 --> 02:32:47.200]   I think it's going to be a skill set that you learn much like we learned how to search.
[02:32:47.200 --> 02:32:51.040]   Yeah, we learned how to search, didn't we? Yeah. Yeah. It's harder than that, though.
[02:32:51.040 --> 02:32:55.040]   I mean, people are here once we got past the Bayesian search that it was all.
[02:32:55.040 --> 02:33:05.120]   I want three percent moon pie, two percent fish, and 43 percent induction cooktops.
[02:33:06.560 --> 02:33:14.960]   Ant, Pruitt has a pick of the week, a good one, I think. And this was I've over the holiday break.
[02:33:14.960 --> 02:33:22.800]   I watched a lot more YouTube and I came across again, Mr. Andre Mac and he has a series talking
[02:33:22.800 --> 02:33:28.160]   about why Andre Mac is a Somalia. And he has a series with a bunch of celebrities where they sit
[02:33:28.160 --> 02:33:34.560]   down and guess cheap versus inexpensive wine. And this recent episode featured Kevin Hart,
[02:33:34.560 --> 02:33:42.160]   who is a fascinating man, comedian, actor, entrepreneur, great storyteller. And just watching that
[02:33:42.160 --> 02:33:47.520]   episode just brought out a lot more interesting information about Kevin Hart. Let alone teaching
[02:33:47.520 --> 02:33:53.520]   us folks like me that don't know enough about wine yet to learn to live with the midst of wine.
[02:33:53.520 --> 02:33:57.840]   This is an interesting genre because, of course, it started with the hot ones, right? It gets
[02:33:57.840 --> 02:34:03.120]   celebrities to eat hot sauce. I like this. I sure watched that. I would do this one.
[02:34:04.080 --> 02:34:09.680]   I don't want to do it. This is a good idea. Have them drink wine and find out more about them.
[02:34:09.680 --> 02:34:13.360]   And there's a little test here because he's going to give you wine. He won't tell you if it's good
[02:34:13.360 --> 02:34:17.600]   or bad and you have to figure out what the expensive wine is and what the cheap one is.
[02:34:17.600 --> 02:34:26.480]   Right. And as you know, just because you hand me a $200 bottle of wine, I may not think it tastes
[02:34:26.480 --> 02:34:32.080]   like a $200 bottle of wine. It may taste like crap to me, but yet that takes you that all the time.
[02:34:32.080 --> 02:34:36.000]   Be phenomenal. In fact, a lot of research on the art of chocolate fakes came from this.
[02:34:36.000 --> 02:34:43.280]   To Buck Chuck. There's a lot of research, frankly, that people are heavily influenced by the price.
[02:34:43.280 --> 02:34:47.600]   And if they don't know the price and they taste the wine and they're honest, it's very often not
[02:34:47.600 --> 02:34:53.760]   the most expensive wine or even the expensive wine that wins. This one will surprise you
[02:34:53.760 --> 02:34:57.840]   that particular episode. Does Kevin have a good taste buds?
[02:34:58.640 --> 02:35:04.080]   See, he was the stuff that he said. He's got some experience.
[02:35:04.080 --> 02:35:09.040]   Yeah. I want it. I can't wait to watch this. So this is a YouTube.
[02:35:09.040 --> 02:35:15.200]   This is from Bon Appetit magazine featuring Andre Mac. Oh, nice.
[02:35:15.200 --> 02:35:20.960]   We're on ice. Somalia's. There is. Somalia tries to look at. So he's like their house.
[02:35:20.960 --> 02:35:29.520]   Somalia. That's cool. That's really cool. And of course, you didn't do it this time.
[02:35:29.520 --> 02:35:32.880]   You usually tell us about your website, antproot.com.
[02:35:32.880 --> 02:35:37.240]   All those fine prints available for sale. And let's give you a
[02:35:37.240 --> 02:35:40.960]   Pro.com/prints. I haven't been able to get out and shoot something else.
[02:35:40.960 --> 02:35:44.560]   I know it's put up for prints. You were going to take yet rainy day pictures.
[02:35:44.560 --> 02:35:47.680]   There's not much else to do. All this dad gum rain and mud and
[02:35:47.680 --> 02:35:52.000]   luck and hasn't been appealing to me. But there's still some prints out there for
[02:35:52.000 --> 02:35:54.720]   people to check out if they're interested in putting them up on their walls and
[02:35:54.720 --> 02:35:57.680]   their friends' walls and their favorite bar or what have you.
[02:35:57.680 --> 02:36:04.000]   He's also an instance. And hands-off photography is his show to it. That TV/hop.
[02:36:04.000 --> 02:36:07.120]   Who's coming up? What you doing in the future here?
[02:36:07.120 --> 02:36:12.960]   Well, I was going to talk about macro photography, but I just saw a story
[02:36:13.920 --> 02:36:17.200]   earlier today that may make me address that story.
[02:36:17.200 --> 02:36:23.200]   Oh. Because it's just sort of... I saw you featured in a story about getting skin tone right.
[02:36:23.200 --> 02:36:32.160]   Yes. Mr. Tashaka Armstrong over at iMore. He wanted to do a test for looking at the
[02:36:32.160 --> 02:36:36.320]   iPhone and the Google Pixel phones. It's a good piece. Just smartphones in general.
[02:36:36.320 --> 02:36:41.600]   How they handle skin tones for everybody. Not just people like the color, but also
[02:36:41.600 --> 02:36:47.440]   white people in various different scenarios where the lighting was really good,
[02:36:47.440 --> 02:36:51.680]   where the lighting was pretty crap-tastic. It was not a fun task.
[02:36:51.680 --> 02:36:58.560]   But yeah, we got a lot of good information out of it. It was myself featured as well as
[02:36:58.560 --> 02:37:03.520]   Juan back now. People that listen and watch all about Android, they know both of those names,
[02:37:03.520 --> 02:37:07.520]   because Juan and Tashaka have been on the Twit Network at time or thrice.
[02:37:08.400 --> 02:37:14.240]   Nice. And is also the manager of our club Twit community and has done a great job putting together
[02:37:14.240 --> 02:37:23.200]   events Stacys tomorrow. I will join you at 9am for Stacys book club. Project Mary. Yeah,
[02:37:23.200 --> 02:37:31.600]   Unbathed, Unquoft. 9am Pacific that's noon Eastern. It's 1800-19. I don't know, sometime in Eastern
[02:37:31.600 --> 02:37:37.360]   in UTC. It's too early for now. It's too early. Even just talking about it, I can't do it.
[02:37:37.360 --> 02:37:42.320]   4pm, much better time next Thursday for an inside Twit with Lisa and me.
[02:37:42.320 --> 02:37:48.480]   When to Dow, the host of all about Android will be on the 9th and 9am. And as I mentioned earlier,
[02:37:48.480 --> 02:37:57.600]   Daniel Suarez at 11am in the club, Twit discord. That'll be a lot of folks for our members that
[02:37:57.600 --> 02:38:02.880]   are interested in these events. I get asked, you know, here and there about the timing.
[02:38:03.600 --> 02:38:10.000]   Is that Pacific time or is that my time zone? Well, we do have that, I believe it's Unicode
[02:38:10.000 --> 02:38:14.160]   inside of the... It's on your... It's in your time zone, Discord Translate. It should show...
[02:38:14.160 --> 02:38:18.640]   Yeah, yeah. Right. It should show in your time zone. But if Discord doesn't know what time it is,
[02:38:18.640 --> 02:38:26.000]   then no one does. Yeah, Discord should fix that for you automatically. But 9am East is...
[02:38:26.000 --> 02:38:30.080]   When I say it out loud, I'm saying our time, which is 9am Pacific. That's why I always say
[02:38:30.080 --> 02:38:38.640]   noon Eastern and 17 out of UTC so that people know. Thank you, everybody. Stacey, go have a
[02:38:38.640 --> 02:38:46.240]   wonderful meal. So jealous. I will. Yeah. Tell us all about it. Stacey on IOT.com at Gigastacey.
[02:38:46.240 --> 02:38:52.480]   She's also of course, co-host with Kevin Tofol of the IoT podcast. Great show this week all about
[02:38:52.480 --> 02:38:57.600]   stuff they saw at CES. And Stacey was on Twit this week and she was wonderful too, so you can catch
[02:38:57.600 --> 02:39:02.800]   that as well. If you don't get enough Stacey in your life tomorrow, 9am Pacific. It was like,
[02:39:02.800 --> 02:39:08.880]   this week is your week. It's your week. It's Stacey All Stacey All the Time. Jeff Jarvis,
[02:39:08.880 --> 02:39:17.120]   is our resident expert on all things media. And of course, he's a professor of journalism.
[02:39:17.120 --> 02:39:20.080]   Somewhere. I have the card here somewhere.
[02:39:21.440 --> 02:39:27.200]   All right. That's all right. I tell everybody. He's the director of the Townite Center for
[02:39:27.200 --> 02:39:32.320]   Entrepreneurial Journalism at the Craig Neumard Graduate School of Journalism at the City
[02:39:32.320 --> 02:39:39.920]   University of New York. Thank you, sir. At Jeff Jarvis and his new book. And I beat the marketing
[02:39:39.920 --> 02:39:44.240]   people at Bloomsbury next week. So if you're ever going to pre-order the book, now would be a great
[02:39:44.240 --> 02:39:47.360]   time to do it. Because as soon as they get ahold of it, they're going to double the price.
[02:39:47.920 --> 02:39:51.200]   B-I-T dot L-Y. Wow. Look at all your friends.
[02:39:51.200 --> 02:39:59.920]   Slash by Gutenberg. As if Gutenberg was for sale, the age of print and lessons for the age
[02:39:59.920 --> 02:40:04.960]   of the internet. I like the cover design you want. Is that nice? I do too.
[02:40:04.960 --> 02:40:13.760]   The Gutenberg parenthesis. And we know some very beautiful fonts inside, thanks to Glenn Fleischman.
[02:40:13.760 --> 02:40:18.560]   Glenn Fleischman, we have doves. Is that the one that guy threw off the bridge?
[02:40:18.560 --> 02:40:24.480]   Yeah. Yeah. This is the one. It's a great story. And then the other, the body type story is that
[02:40:24.480 --> 02:40:28.960]   the designer of it was arrested by Hitler because of his font. Wow.
[02:40:28.960 --> 02:40:36.720]   Typefaces have such an interesting story. Thank you, Jeff. Thank you, Ant Pruitt.
[02:40:36.720 --> 02:40:42.400]   Twit.tv/hop. Thank you all for joining us. We do the wonderful This Week in Google show,
[02:40:42.400 --> 02:40:48.800]   which has nothing to do with Google every Wednesday around about 2 p.m. Pacific 5 p.m. Eastern 2200
[02:40:48.800 --> 02:40:54.720]   UTC. I only mentioned that if you want to watch live at live.twit.tv, there's streaming audio and
[02:40:54.720 --> 02:41:01.600]   video there all day long and all night long. If you're watching live chat live at irc.twit.tv,
[02:41:01.600 --> 02:41:05.840]   that's our IRC chatroom. But you could just use your web browser to go there. You can also,
[02:41:05.840 --> 02:41:10.320]   if you're in the club chat in the Discord after the fact, or add supported versions of the show
[02:41:10.320 --> 02:41:16.320]   available at twit.tv/twig. There's a YouTube channel. This week in Google channel on YouTube,
[02:41:16.320 --> 02:41:20.080]   you can also subscribe in your favorite podcast player and that way you'll get it automatically
[02:41:20.080 --> 02:41:26.080]   as soon as it's available. I thank you so much for joining us. We'll be back next week. I hope
[02:41:26.080 --> 02:41:32.240]   you will too for this week in Google. Bye bye. Bye bye. Bye bye. Everybody say goodbye to the Jeff
[02:41:32.240 --> 02:41:43.600]   Jarvis portrait hanging over at. If you are looking for a midweek update on the week's tech news,
[02:41:43.600 --> 02:41:47.520]   I got to tell you, you got to check out tech news weekly. See, it's all kind of built in there
[02:41:47.520 --> 02:41:53.680]   with the title. You get to learn about the news in tech that matters every Thursday. Jason Howl
[02:41:53.680 --> 02:41:58.640]   and I talk to the people making and breaking the tech news, get their insights and their
[02:41:58.640 --> 02:42:14.560]   interesting stories. It's a great show to check out twit.tv/tnw.

