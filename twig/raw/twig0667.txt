;FFMETADATA1
title=Scuds Off the Bow of Sullivan
artist=Leo Laporte, Jeff Jarvis, Ant Pruitt
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2022-06-09
track=667
language=English
genre=Podcast
comment=Twitter bots, NY Right to Repair, meme stock trading fix, USB-C in EU
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.040]   This week on this week in Google Stacey has the week off. We'll explain why.
[00:00:05.040 --> 00:00:10.440]   Jeff Jarvis and Aunt Pruitt are here. We'll talk about Elon Musk. He's really
[00:00:10.440 --> 00:00:14.920]   dragging his heels with Twitter. Now they're giving him the fire hose. Will that be
[00:00:14.920 --> 00:00:19.520]   enough? New York State passes the first ever right to repair law for electronics
[00:00:19.520 --> 00:00:27.440]   and rewriting Wall Street's rulebook. SEC is trying to fix the meme stock problem.
[00:00:27.440 --> 00:00:32.480]   You'll be interested to hear how they have they proposed doing it. It's all coming up next on Twig.
[00:00:32.480 --> 00:00:48.720]   Podcasts you love from people you trust. This is Twig. This week in Google,
[00:00:48.720 --> 00:00:57.920]   Episode 667 recorded Wednesday, June 8th, 2022. Scuds off the bow of Sullivan.
[00:00:57.920 --> 00:01:02.480]   This week in Google is brought to you by HackerRank. It's time to reboot your
[00:01:02.480 --> 00:01:06.240]   technical interviews with HackerRank's easy-to-use tools. With a pre-made
[00:01:06.240 --> 00:01:10.600]   question library, code, playback, and built-in whiteboard, you'll be conducting
[00:01:10.600 --> 00:01:15.040]   better technical interviews and instantly identifying the right talent. Go to
[00:01:15.040 --> 00:01:22.760]   hackerrank.com/twig to start a better tech interview free today. And by Melissa.
[00:01:22.760 --> 00:01:27.960]   Make sure your customer contact data is up-to-date. Try Melissa's APIs in the
[00:01:27.960 --> 00:01:32.240]   developer portal. It's easy to log on, sign up, and start playing in the API
[00:01:32.240 --> 00:01:40.000]   sandbox 24/7. Get started today with 1000 records clean for free at Melissa.com/twits.
[00:01:40.000 --> 00:01:45.840]   And by Hover. Whether you're a developer, photographer, or small business, Hover
[00:01:45.840 --> 00:01:50.280]   has something for you to expand your projects and get the visibility you want.
[00:01:50.280 --> 00:01:56.400]   Go to hover.com/twit to get 10% off your first purchase of any domain extension for
[00:01:56.400 --> 00:02:03.120]   the entire first year. It's time for Twig this week in Google. The show we cover
[00:02:03.120 --> 00:02:05.720]   everything but pretty much everything but Google. But we'll get a little Google
[00:02:05.720 --> 00:02:11.000]   in here. I bet. Joining us right now, hands-on photography host, the master of
[00:02:11.000 --> 00:02:17.280]   ceremonies in Club Twit, and a general all-around good guy Clemson fan, Ant-Pruit.
[00:02:17.280 --> 00:02:23.280]   Hello, Ant. Is that a Clemson cockroach over your left shoulder? What is that?
[00:02:23.280 --> 00:02:31.680]   That is actually a Clemson Ant. Ant. Clemson Tigers? Oh, I get it. Oh, is that Ant?
[00:02:31.680 --> 00:02:36.480]   Because of yours, that actually they're mascot. Look here, sir.
[00:02:36.480 --> 00:02:43.200]   The Tiger, eat the Ant. I'm just saying. How dare you. Or step on it. Okay. Very cute.
[00:02:43.200 --> 00:02:49.000]   A Clemson Ant. I love it. I get it. A visual pun, ladies and gentlemen. Also here.
[00:02:49.000 --> 00:02:53.640]   That was a care package. That's very sweet. So some listeners say that to you or family.
[00:02:53.640 --> 00:02:58.560]   Listener. Very nice. Thank you listeners. You guys are great. We have a great audience.
[00:02:58.560 --> 00:03:01.800]   I just love them. Indeed. Also here, the Leonard Tap Professor for
[00:03:01.800 --> 00:03:10.440]   journalistic innovation at graduate school journalism at the Sit D University of New
[00:03:10.440 --> 00:03:18.240]   York. Hello, Mr. J. Good to see you. How are you? I am well. I am very well. You know
[00:03:18.240 --> 00:03:24.560]   who's not well? Stacey Higginbotham. She couldn't be with us. Bless her heart.
[00:03:24.560 --> 00:03:29.720]   Good day. Bless your heart because she's in Puerto Rico rescuing her daughter. Well,
[00:03:29.720 --> 00:03:34.240]   Stacey, having just gotten over her 11 day bout of COVID, then tweeted, guess where I
[00:03:34.240 --> 00:03:37.520]   have to go. She's she tweeted that she was going to Puerto Rico because her daughter
[00:03:37.520 --> 00:03:43.600]   was there on a field trip, I guess. School trip. Wow. Came down with it. And so Stacey
[00:03:43.600 --> 00:03:47.000]   has to go and isolate with her. I don't know if they're back yet. I have no idea what
[00:03:47.000 --> 00:03:54.520]   the latest is. I just saw that tweet and said, Oh, geez. Yay. Yay. Karumba. So I'm
[00:03:54.520 --> 00:03:59.400]   sorry that Stacey's not with us, but and I, she's of course doing the most important
[00:03:59.400 --> 00:04:02.880]   job she does. Yeah. I think she was going to be gone anyway at a conference or something,
[00:04:02.880 --> 00:04:08.280]   wasn't she? Oh, okay. That's right. She's supposed to be in a conference. Okay. Yeah.
[00:04:08.280 --> 00:04:13.160]   Okay. So everybody lost Stacey this week. Child is still positive after day five. She
[00:04:13.160 --> 00:04:19.960]   tweets this variant ain't messing around. Y'all. But she's still blogging. She's still writing
[00:04:19.960 --> 00:04:27.040]   about stuff. She wrote about Apple's home kit announcements and matter. She was very excited
[00:04:27.040 --> 00:04:29.400]   about that. I was really looking forward to having her on to talk about that, but she'll
[00:04:29.400 --> 00:04:33.960]   do it next week if we can get her back for daughter. And her daughter's fine, right? She
[00:04:33.960 --> 00:04:40.840]   just, you know, you can't travel if you've tested positive. I like Puerto Rico. I wouldn't
[00:04:40.840 --> 00:04:51.880]   mind a week in Puerto Rico. I should have volunteered. Also, thanks to, is this, was this, did Anthony
[00:04:51.880 --> 00:04:58.900]   do this? Anthony Nielsen? This is the thumbnail from last week's show. Best thumbnail. I
[00:04:58.900 --> 00:05:04.080]   will know. I want to complain. These things just keep getting better and better. You got
[00:05:04.080 --> 00:05:08.120]   a hat and straw. The rest of the rest of the story. Totally. I'd. It's the thumbnail. So
[00:05:08.120 --> 00:05:14.480]   I can't I can't show it. But yeah, wow. Yeah, you didn't get Google Eyes or anything yet.
[00:05:14.480 --> 00:05:21.360]   You just got a kind of way to have Google Eyes, apparently. And Jeff when you just you
[00:05:21.360 --> 00:05:26.120]   look like a crazy character was having enough for it. Yeah, I was I was getting into an
[00:05:26.120 --> 00:05:31.560]   app. I was for the good of the show. I was sacrificing every bit of dignity I ever had.
[00:05:31.560 --> 00:05:35.440]   You are correct because I was just sitting that judging all three of you.
[00:05:35.440 --> 00:05:45.440]   You always do some nail. I have episode 666. That will give you a na evil show. Holy cow.
[00:05:45.440 --> 00:05:56.040]   So much fun. All right. Let's see. We talked about actually, Charles Samberg quitting came
[00:05:56.040 --> 00:05:59.400]   in during the show, didn't it last week? Yes, it is. We have talked about that right at
[00:05:59.400 --> 00:06:04.920]   the top. We don't have any more information about that. No, the Wall Street Journal just
[00:06:04.920 --> 00:06:10.160]   speculated. There was nothing to note in their story about it. Why? Cheryl Samberg quit Facebook's
[00:06:10.160 --> 00:06:16.640]   meta. That dovetailed with it. Well, wait a minute, a company investigation into her
[00:06:16.640 --> 00:06:23.200]   activities. Is this about her and her relationship with Bobby Kotick, who is the CEO of Activision?
[00:06:23.200 --> 00:06:35.000]   She lobbied a UK tabloid not to print an article about Kotick. So they this was a clip job.
[00:06:35.000 --> 00:06:37.800]   They were trying to pull out everything they could do. I read the whole thing. There was
[00:06:37.800 --> 00:06:43.120]   nothing there. Okay. Okay. I think it's completely reasonable that Cheryl is stepping down to
[00:06:43.120 --> 00:06:48.240]   spend more time with her money. She's getting married next month. She's got a family. And
[00:06:48.240 --> 00:06:53.120]   I do think she has political ambitions in 2024. I really do. This is the beginning
[00:06:53.120 --> 00:06:58.120]   of that. Yeah. Yeah. That's fine. She's earned this. Now, here's the pile on.
[00:06:58.120 --> 00:07:07.720]   The latest news from Elon. Oh boy. I don't want it. I don't want it. He's trying to get
[00:07:07.720 --> 00:07:15.440]   out of it. Twitter says no. They, Elon's big demand is tell me about the bots like you
[00:07:15.440 --> 00:07:21.200]   didn't know ahead of time. He, when he signed the deal, said I'm not doing any due diligence.
[00:07:21.200 --> 00:07:25.760]   I'm just brilliant. This reminds me of a former boss of mine, Halsey Miner. Do you know the
[00:07:25.760 --> 00:07:30.800]   name Halsey Miner? Oh God. Yeah. I do Halsey Miner. He founded CNET. And I worked for him
[00:07:30.800 --> 00:07:37.400]   briefly in the early days of CNET. He finally let me go and said go to ZNET DD or something.
[00:07:37.400 --> 00:07:44.120]   Don't, don't bug us here. Was, but I had no rancor. He was a smart guy. He was a hedge
[00:07:44.120 --> 00:07:49.960]   fun guy. He started CNET. Did very well made a lot of money. But, but Halsey famously,
[00:07:49.960 --> 00:07:55.920]   I think he's bankrupt now. He's in tax trouble for sure. But famously bought a race horse
[00:07:55.920 --> 00:08:02.360]   by looking in its eyes and saying I can tell it's a winner. Uh, by the way. Yeah, that's
[00:08:02.360 --> 00:08:06.960]   right. Race horse is not a winner. But that's neither here nor there. He came from good
[00:08:06.960 --> 00:08:11.800]   Virginia stock and he could look at a horse and say that is a winner. Apparently not.
[00:08:11.800 --> 00:08:16.760]   Anyway, I feel like Elon Musk said, I've looked into the eyes of Twitter. I can tell it's worth
[00:08:16.760 --> 00:08:24.520]   $44 billion. Now he says, wait a minute. There's an awful lot of bots. Uh, Twitter said, no,
[00:08:24.520 --> 00:08:30.680]   no, no, we're, you know, A, you already said no due diligence. B we say there's 5% and
[00:08:30.680 --> 00:08:36.160]   that's that. Now they say we are going to comply. Well, but comply. What they're doing
[00:08:36.160 --> 00:08:41.360]   is calling his bluff. They're saying, okay, okay, Elon, here's the fire hose. Oh, that
[00:08:41.360 --> 00:08:49.440]   all lives away. Yeah, have fun. 500 million tweets, half a billion tweets daily. Uh, the
[00:08:49.440 --> 00:08:54.480]   fire hose is famously something every, you know, people wanted, but very few could get.
[00:08:54.480 --> 00:08:58.120]   I think the library of Congress still has access to it. Very few, very few have the analytical
[00:08:58.120 --> 00:09:03.280]   power to deal with it. Right. Well, Elon, it's, it's, it's the equivalent of when you're
[00:09:03.280 --> 00:09:10.280]   doing a discovery in a legal case, delivering a truckload of boxes saying, oh, you wanted
[00:09:10.280 --> 00:09:17.160]   that data. Here you go. Uh, in, I don't have a problem with him saying, you know what,
[00:09:17.160 --> 00:09:21.040]   I want this product, but you got to fix it up a little bit. We do the same thing when
[00:09:21.040 --> 00:09:25.600]   it comes to just buying regular day to day stuff, whether it be cars or houses and what
[00:09:25.600 --> 00:09:30.480]   not. I don't have a problem with that. The problem I have is him just sort of being,
[00:09:30.480 --> 00:09:36.400]   uh, I don't know how to say it, but he knows there's bots out there. He's got a gazillion
[00:09:36.400 --> 00:09:40.760]   followers and he knows everything that responds to him. It's pretty much a bunch of bots.
[00:09:40.760 --> 00:09:46.440]   How does this, he probably runs a few bots himself. I've been, I've been, uh, asserted.
[00:09:46.440 --> 00:09:51.600]   Um, it's a little different. It says, if you went to a car dealership, uh, you sign
[00:09:51.600 --> 00:09:56.840]   on the dot online, you, you said, I'll take it and then you, you know, decided, Oh, well,
[00:09:56.840 --> 00:10:01.200]   we met maybe look, I better look under the hood first. He agreed not, he, no, no, no,
[00:10:01.200 --> 00:10:05.960]   not it was done. Right. He didn't, I'm not saying that like he's already bought the car.
[00:10:05.960 --> 00:10:10.400]   I'm saying, when you go to look for a home, no, no, but Twitter's in to do some sort of
[00:10:10.400 --> 00:10:14.600]   yeah, you do. Little diligence. He waved that Twitter's pointed. Yes. And that, that's
[00:10:14.600 --> 00:10:20.000]   a good example. And if you buy a home with no conditions, you bought it. You don't have
[00:10:20.000 --> 00:10:24.520]   an out saying all the home inspection. Nope. You didn't, you didn't specify that. Oh, only
[00:10:24.520 --> 00:10:29.440]   if I get financing. Nope. You didn't specify as easy as it is. Yeah. By the house, right?
[00:10:29.440 --> 00:10:35.000]   Or the only out here is a billion bucks. Right. And it may not even be the out. He may not
[00:10:35.000 --> 00:10:38.560]   even be able to pay the breakup fee and get out of it. Twitter could hold his feet to
[00:10:38.560 --> 00:10:43.680]   the fire and say, no, you agreed contractually. You're bound. I hope that he doesn't end up
[00:10:43.680 --> 00:10:47.960]   buying it, but I hope also hope they take him. Well, in the meantime, so the whole penalty
[00:10:47.960 --> 00:10:53.320]   could be just, just nothing. He could still end up having to pay the full bill. And yeah,
[00:10:53.320 --> 00:10:59.480]   the penalty is that it's made the full bill. All right. Okay. So it's possible and probably
[00:10:59.480 --> 00:11:03.960]   likely that he's just trying to get a lower price. But again, it's just like the house
[00:11:03.960 --> 00:11:08.040]   analogy is much better than the car analogy. Thank you, Jeff. Yeah. House. Yeah. He bought
[00:11:08.040 --> 00:11:12.680]   the house. He said, yeah, I'll pay you the money. No, I'm going to buy it as he is. Wave
[00:11:12.680 --> 00:11:21.160]   inspections. You don't then get to change it. And Twitter has a contractual, you know,
[00:11:21.160 --> 00:11:25.680]   he has a contractual obligation. Twitter could enforce that. They could say, no, you know,
[00:11:25.680 --> 00:11:30.240]   however, Musk says, I'm not until I get this information about bots. I'm not going to do
[00:11:30.240 --> 00:11:34.440]   the deal. So they said, well, here, now, by the way, this is not had not been announced.
[00:11:34.440 --> 00:11:39.240]   This is according to a person familiar with the company's thinking. The board is going
[00:11:39.240 --> 00:11:45.880]   to give him the fire hose, which means he could then pipe that half billion tweets into some
[00:11:45.880 --> 00:11:51.920]   computer and he'll come up with some absolute BS analysis. I found 40 billion bots, but,
[00:11:51.920 --> 00:11:57.000]   but and he'll probably get the headlines out of that because tech press is really stupid.
[00:11:57.000 --> 00:12:02.560]   Legally, it ain't going to give them out. The Washington Post says, when Musk signed the
[00:12:02.560 --> 00:12:06.360]   initial deal by the company in April, he waved a right to look deeply at Twitter's finances
[00:12:06.360 --> 00:12:10.280]   and inner workings. The purchase agreement requires that Musk go through with the deal
[00:12:10.280 --> 00:12:17.320]   unless he could show the company misled him or a major event has changed its value. And
[00:12:17.320 --> 00:12:24.560]   the company didn't make any claims that I know of about bots. So it's hard to invest
[00:12:24.560 --> 00:12:31.040]   in this. Let's say this is October 2022, because isn't that about the time all of this should
[00:12:31.040 --> 00:12:38.080]   be finalized roughly around that time? Just like that. So he says, you know what? Nah,
[00:12:38.080 --> 00:12:42.720]   I don't want it. They go to court. They said Twitter has the legal right to take them to
[00:12:42.720 --> 00:12:49.320]   court. Yep. And the court sides with Twitter. What happens? Is it jail time? Is it? No,
[00:12:49.320 --> 00:12:57.480]   he owes us. It's garnish in his wages. It's just wages. Sheriff comes over and says,
[00:12:57.480 --> 00:13:03.440]   give me your money. They told me about what we're going to ask is I don't understand
[00:13:03.440 --> 00:13:07.800]   law. I think actually, and you you make an excellent point. And I think that's the other
[00:13:07.800 --> 00:13:14.720]   thing. Elon, like other famous Huxters of the 21st century, knows that he's above the law
[00:13:14.720 --> 00:13:23.920]   and probably doesn't have to worry about it. Just that. Just that. He's too big to fail.
[00:13:23.920 --> 00:13:33.680]   The lawyers from Skadden ARPS slate meager and flam. That's a great, as a great firm.
[00:13:33.680 --> 00:13:42.480]   That's a great, Elon's lawyers. Skadden ARPS slate meager and flam say must have must have
[00:13:42.480 --> 00:13:50.200]   a complete and accurate understanding of the very core of Twitch business model. It's
[00:13:50.200 --> 00:13:55.560]   active user base. Twitter's latest offer to simply provide additional details regarding
[00:13:55.560 --> 00:13:59.000]   the company's own testing methodologies, whether through written materials or verbal
[00:13:59.000 --> 00:14:05.880]   explanations is tantamount to refusing Mr. Musk's data request. I just see what I just
[00:14:05.880 --> 00:14:10.920]   it's. I the only thing I blame Elon for at this point is just making a mess and a muddle
[00:14:10.920 --> 00:14:17.040]   of all this. People are leaving Twitter. Twitter employees are very anxious over everything.
[00:14:17.040 --> 00:14:22.280]   It's it's it's important people have been fired and it's trolling. It's pure troll.
[00:14:22.280 --> 00:14:30.360]   It's destructive troll and and a lot of shareholders. I think we'll end up suing him, not just for
[00:14:30.360 --> 00:14:34.080]   his late disclosure, but for all the game places. He's already being really affected.
[00:14:34.080 --> 00:14:39.440]   The price he is being sued. Yeah. But that that along. But I think that was the you violated
[00:14:39.440 --> 00:14:44.080]   the rules suit. I think there's another suit here to say that you manipulated the stock
[00:14:44.080 --> 00:14:54.280]   in the end. And you and you are you harmed the company. So annoying. He is. But all the
[00:14:54.280 --> 00:15:00.080]   the the the the the the stands, the stands we call them the Twitter. The Musk stands are
[00:15:00.080 --> 00:15:05.440]   tiring. Anything he does is just brilliant. And you don't give him credit. And what's
[00:15:05.440 --> 00:15:10.120]   your problem, man? Well, the pile on now that Texas Attorney General who has problems of
[00:15:10.120 --> 00:15:17.320]   his own has launched an investigation against Twitter for allegedly misreporting fake bar
[00:15:17.320 --> 00:15:25.680]   accounts. Attorney General Paxson says Twitter has until June 27th to respond. Ken Paxton.
[00:15:25.680 --> 00:15:34.160]   This is what it's just a publicity stunt. Is it coincidental since he's always Texan?
[00:15:34.160 --> 00:15:40.200]   It's not coincidental. No, not the links and some revenues and tax revenues to that state.
[00:15:40.200 --> 00:15:47.240]   The subtext of all of this is Twitter banned President Trump. Elon has said multiple times
[00:15:47.240 --> 00:15:52.280]   now they should not have done it. It was stupid. And he would reinstall President Trump. By
[00:15:52.280 --> 00:15:56.160]   the way, we should point out what Twitter they didn't ban Trump for a long time. There
[00:15:56.160 --> 00:16:00.600]   are a lot of people saying they should have banned him sooner. They'd only ban him for
[00:16:00.600 --> 00:16:11.360]   an encouraging sedition against the United States to overturn election results. That's
[00:16:11.360 --> 00:16:17.440]   treasonous behavior. They banned him appropriately and they banned him permanently. This, however,
[00:16:17.440 --> 00:16:24.480]   offends his fellow seditionists, including A.G. Paxton. So they're all just piling on.
[00:16:24.480 --> 00:16:27.480]   And then the New York Times, I didn't put this in the rundown, but I got pissed off to
[00:16:27.480 --> 00:16:33.280]   put it on Twitter, which is what I do with everything that pisses me off these days.
[00:16:33.280 --> 00:16:39.160]   Poor little Paxton, Paxton kind of has some political benefit here. I mean, that angling
[00:16:39.160 --> 00:16:45.200]   of he did a cynical act and we're going to give him the credit for that and then say,
[00:16:45.200 --> 00:16:49.640]   Hey, he could get credit for doing this with the right wing. His job is to represent the
[00:16:49.640 --> 00:16:56.680]   people of the great state of Texas and their interests. Period. Not to gain political.
[00:16:56.680 --> 00:17:05.080]   Points. Yep. Media points. We got a mess. We got a mess on our hands, folks. Twitter
[00:17:05.080 --> 00:17:17.840]   is reassuring its staff. They say the shareholders will vote by August. The staff, understandably,
[00:17:17.840 --> 00:17:24.480]   a little anxious. The lawyer told them today that the deal to sell the company is still
[00:17:24.480 --> 00:17:30.400]   progressing that the shareholder vote will occur late next month or early August. The
[00:17:30.400 --> 00:17:35.080]   company's waiting for the SEC to approve the proxy after which it will be sent to shareholders.
[00:17:35.080 --> 00:17:39.200]   This is coming from Vijaya Gotti, Twitter's head of legal and policy. This is that in all
[00:17:39.200 --> 00:17:45.440]   hands. Twitter has and will continue to cooperatively share information with Mr. Must to consummate
[00:17:45.440 --> 00:17:50.320]   the transaction in accordance with the terms of the merger agreement. I say, I say, we
[00:17:50.320 --> 00:17:58.960]   believe this agreement is in the best interest of all shareholders. The company said, well,
[00:17:58.960 --> 00:18:03.920]   I say we intend to close the transaction and enforce the merger agreement and forget that
[00:18:03.920 --> 00:18:11.160]   one. And enforce the merger agreement at the agreed price and terms and forces the operative
[00:18:11.160 --> 00:18:18.480]   word there. Again, that word and what does it mean to someone who doesn't care? That
[00:18:18.480 --> 00:18:24.400]   feels they're above the law. Well, he maybe he should care. The court could say, you owe
[00:18:24.400 --> 00:18:31.320]   in billions of dollars. Yeah. And when the court says it, you got to pay. However, given
[00:18:31.320 --> 00:18:37.360]   our courts these days, you'd write in this guy like I said, it's not like they're going
[00:18:37.360 --> 00:18:43.000]   to garnish his wages. No, but they could take his Tesla stock. I mean, there are things they
[00:18:43.000 --> 00:18:49.600]   could do. Okay. Employees were very concerned about work from home. Twitter has, as you,
[00:18:49.600 --> 00:18:55.880]   as you may remember, said you can work from home forever. All right. Yeah. Elon, you know,
[00:18:55.880 --> 00:19:02.280]   memo to his to his Tesla employees said, you better get the hell back in here. And we
[00:19:02.280 --> 00:19:07.960]   want at least 40 hours a week from you. And it better be in the place where your major
[00:19:07.960 --> 00:19:14.880]   business is done, not some remote office. You got it. You got to come in. Gaddy did say
[00:19:14.880 --> 00:19:20.080]   remote told the employees remote work is not protected by the merger agreement. So there's
[00:19:20.080 --> 00:19:27.920]   no guarantee. Oh, he long gets to his side. So that caught say again, now if you're a
[00:19:27.920 --> 00:19:32.160]   Twitter employee decisions for their lives, they move because the company told them you're
[00:19:32.160 --> 00:19:36.040]   not you don't ever have to come back. You can do what you wanted. So sure. Now, I mean,
[00:19:36.040 --> 00:19:39.880]   Elon is reducing the value of this company, nibbling away at the value of this company
[00:19:39.880 --> 00:19:45.120]   bid by bit, whether he buys it or not, which is too bad. I mean, I'm not a, you know, I
[00:19:45.120 --> 00:19:48.280]   don't think the word would world would be worse off if there were no Twitter, but what
[00:19:48.280 --> 00:19:53.280]   I don't see is a hobbled Twitter. I mean, this is what I'm going to disagree once again.
[00:19:53.280 --> 00:19:57.400]   And I was just at a conference at University of Virginia, our friend, Stephen Vadianathan
[00:19:57.400 --> 00:20:02.040]   put on. And there was a lot of discussion there.
[00:20:02.040 --> 00:20:07.720]   Siva hates Facebook. What's his opinion on Twitter? He hates social media. He hates the
[00:20:07.720 --> 00:20:11.160]   idea of connecting all mankind. Okay. This is where he I love him. I respect him. But
[00:20:11.160 --> 00:20:18.600]   you know, really? Yeah, he's great on that. Yeah, he's brilliant on that. Yeah. But a
[00:20:18.600 --> 00:20:27.640]   lot of the discussion was around the creation of counter publics as it's called online, you
[00:20:27.640 --> 00:20:32.360]   know, as possible because of the Twitter, what's a counter public? And to dismiss it, a smaller
[00:20:32.360 --> 00:20:37.560]   public that's not represented like, like, black Twitter, like LGBTQ Twitter, like,
[00:20:37.560 --> 00:20:43.560]   any group doesn't have the chance, well, more than affinity, any group that doesn't have
[00:20:43.560 --> 00:20:49.480]   the power under the view of what is normally considered the public.
[00:20:49.480 --> 00:20:54.440]   It gives a voice to outman mainstream. Yes, exactly. Exactly. It's John, John Warner is the
[00:20:54.440 --> 00:20:59.080]   academic who came up with counter publics. That's a good way to put it. Okay. I like that. Yeah.
[00:20:59.080 --> 00:21:03.720]   And so, and so, you know, when you say, oh, we're better off about Twitter, well, no, a lot has
[00:21:03.720 --> 00:21:07.320]   been built there that you and I don't see. No, that's right. Yeah. That is critical.
[00:21:07.320 --> 00:21:12.520]   And you can say the same thing for Facebook. You can in a lot of ways. Yeah. Yeah.
[00:21:12.520 --> 00:21:16.440]   Any online community, right? Yeah. And that's not to say they're perfect. It's not to say there
[00:21:16.440 --> 00:21:20.760]   aren't a lot of flaws, that's they couldn't be done far better or that it won't be done far better.
[00:21:20.760 --> 00:21:28.840]   But as of today, people built something there and to get that just thrown away is a problem.
[00:21:28.840 --> 00:21:37.320]   Yeah. Are you being facetious with him not really caring about the connection of people?
[00:21:37.320 --> 00:21:44.040]   No, no, no. No, he's not that he doesn't care. He says, I don't want to misquote him here and we
[00:21:44.040 --> 00:21:46.600]   should have models. We would try to get them all. We've been trying. We really have.
[00:21:47.480 --> 00:21:53.560]   But he wrote his latest book about Facebook, which I have somewhere over there,
[00:21:53.560 --> 00:22:05.240]   basically says that to connect all of mankind without the guard rails in was irresponsible and
[00:22:05.240 --> 00:22:13.240]   and ill-fated from the start. Okay. So I'll agree that it was the guard rail of a
[00:22:14.440 --> 00:22:21.400]   28 cent stamp was fine. Well, that's not that's a one to one. I think you're right. To me,
[00:22:21.400 --> 00:22:26.520]   and you're right. The what fascinates me is that is that the postal service was the original internet.
[00:22:26.520 --> 00:22:33.960]   But except except your your mail ended up on the bulletin board of the town square for all the
[00:22:33.960 --> 00:22:39.160]   sea, which is the difference, right? Or if you wanted to put a 28, if you wanted to reach 100
[00:22:39.160 --> 00:22:45.960]   people, you had to get by 128 cents stamps. His position is under mind's democracy. The book is
[00:22:45.960 --> 00:22:52.600]   anti social media, how Facebook disconnects us and undermines democracy. He's been on the show
[00:22:52.600 --> 00:22:58.280]   before I love see that smart guy. He's just very, very busy guys traveling a lot. He's doing a
[00:22:58.280 --> 00:23:05.400]   lot of conferences, but we will get him on. It's this is a tough one. You know, there are both
[00:23:05.400 --> 00:23:10.600]   arguments are valid. Oh, absolutely. That's why there's a discussion. That's what
[00:23:10.600 --> 00:23:14.200]   Siva brought together with about 25 academics. Yeah, it's good for him.
[00:23:14.200 --> 00:23:19.640]   For him, because it was a discussion about deliberation. Yeah, and it was fascinating
[00:23:19.640 --> 00:23:24.840]   because some of the academics said delibera, you know, this idea that we want to have deliberation
[00:23:24.840 --> 00:23:32.840]   as a as an ideal. One of them said brilliantly, one view is that you can't deliberate at this scale.
[00:23:33.960 --> 00:23:38.200]   Another view is when you can deliberate at a smaller scale, is that what we want? Well,
[00:23:38.200 --> 00:23:43.800]   as somebody said there, well, your your town council or your faculty meeting are a deliberative
[00:23:43.800 --> 00:23:48.760]   scale that works, but they're hell, right? We hate them. But but the question is hard.
[00:23:48.760 --> 00:23:54.200]   They get the job. Yeah, it's painful. But it's it's that's it makes a difference. You got to do it.
[00:23:54.200 --> 00:24:00.280]   Yeah, I mean, you're right. It's a flippant thing for me to say we'd be better off without Twitter.
[00:24:00.280 --> 00:24:05.240]   That's and that's not certainly what I want. So here's here's a quote that I put in my book
[00:24:05.240 --> 00:24:10.840]   manuscript from Siva. Facebook is just too big to govern, he said. We are all victims of his
[00:24:10.840 --> 00:24:16.760]   success. It's a story of the hubris of good intentions, a missionary spirit and ideology
[00:24:16.760 --> 00:24:21.800]   that sees computer code is a universal solvent for all human problems. I don't disagree with
[00:24:21.800 --> 00:24:28.280]   about that. I think that no, and that's why hubris about it. I love their their project. What is
[00:24:28.280 --> 00:24:35.000]   it? Green Twitter? Twitter? Green? What is the thing that Jack Blue Sky that Jack Dorsey funded?
[00:24:35.000 --> 00:24:42.600]   I love Mastodon and then we run a Mastodon instance at twit.social and I I really think that a decentralized
[00:24:42.600 --> 00:24:49.480]   federated Twitter like place would be a much better place. Except I agree. I absolutely
[00:24:49.480 --> 00:24:55.240]   because then you really could create your your out. You know, you could have a black mastodon.
[00:24:55.240 --> 00:24:59.880]   You could have a whole place. Yes. And you could also say there's bad speech out there.
[00:24:59.880 --> 00:25:05.640]   Leave it. It's there always is. Yeah. Let me ask you this Leo. Yeah. I agree with you, but
[00:25:05.640 --> 00:25:14.440]   but the yes, but that I I grapple with is that if if we agree that we should we should
[00:25:14.440 --> 00:25:22.360]   moderate out of the world, obviously child porn and harassment, let's say. If it's distributed,
[00:25:23.560 --> 00:25:29.160]   you you kind of can't. It's well, you can and you can't in places. So tell me about that.
[00:25:29.160 --> 00:25:32.680]   Right now, child porn is going to happen. It happens and it's going to happen.
[00:25:32.680 --> 00:25:37.400]   And you can't there's always going to be place people are going to go and they're going to exchange
[00:25:37.400 --> 00:25:43.320]   stuff with a Mastodon like solution. You might have somebody set up a Mastodon that's full of
[00:25:43.320 --> 00:25:49.080]   child porn. Now they have legal restrictions. You know, they're they're running up against the
[00:25:49.080 --> 00:25:57.080]   fellow of the law, but let's let's pretend that's not the case. Here's the beauty. Any other Mastodon
[00:25:57.080 --> 00:26:03.640]   instance could choose to ignore it could could choose to block it if they want or not. So to
[00:26:03.640 --> 00:26:10.760]   emerge at norm of the entirety of Mastodon communities together by their individual decisions,
[00:26:10.760 --> 00:26:15.400]   decide what what makes up. You're not going to put the clubhouse out of business just as you can't stop
[00:26:17.320 --> 00:26:21.960]   currently in the real world. You can't stop them from gathering at somebody's house. You can't,
[00:26:21.960 --> 00:26:27.720]   you know, that's up to the law to stop. You can stop it that way. But you can isolate them. You can
[00:26:27.720 --> 00:26:33.000]   you can keep them out of the mainstream by just not following them. I do that with GAB on my
[00:26:33.000 --> 00:26:40.600]   my Mastodon instance. That's the only other Mastodon I don't follow. I don't allow Federation with
[00:26:40.600 --> 00:26:45.240]   but I do allow Federation with others, which means anybody can on my who's a member of
[00:26:45.240 --> 00:26:51.000]   Twitter social can follow anybody else. In fact, I think recently I took GAB off that list,
[00:26:51.000 --> 00:26:56.040]   presuming if somebody wants to follow GAB, that's fine. It doesn't solve the problem of
[00:26:56.040 --> 00:27:02.040]   somebody from GAB adding me. And then I, you know, I might see that. So let's imagine you're a
[00:27:02.040 --> 00:27:11.400]   regulator. And another life I could imagine you would have been. And you get a law passed saying
[00:27:11.400 --> 00:27:17.000]   that vaccine disinformation is illegal. Forget, let's say you're in the UK, we don't have a first
[00:27:17.000 --> 00:27:24.760]   amendment. Right. In the architecture of discord. Not discord. I'm talking about Mastodon, but
[00:27:24.760 --> 00:27:30.680]   Mastodon sorry, Mastodon Mastodon in the architecture of Mastodon. Discord has a regulator. Could you do
[00:27:30.680 --> 00:27:36.040]   anything? Not no, because nobody runs mast. There's no centralized Mastodon. You would have to go
[00:27:36.040 --> 00:27:42.120]   after every single Mastodon server and say, if you just like a blog, just like
[00:27:42.120 --> 00:27:48.760]   forums, it's much more like a forum like forums, forums that interoperate. Think of it that
[00:27:48.760 --> 00:27:54.280]   is interoperability is new. It's not the old forums. You have, it's more like usenet, I guess.
[00:27:54.280 --> 00:27:58.360]   It's kind of like usenet. Yeah. But it's a much better more elegant system. But it's that it's
[00:27:58.360 --> 00:28:04.040]   that idea. So you have discrete spaces, which would be forums, but but you can follow anybody on
[00:28:04.040 --> 00:28:08.360]   any other forum, you can follow anybody on any of the other Mastodon. And that becomes part of
[00:28:08.360 --> 00:28:13.480]   your Mastodon feed. Not everybody else's, by the way, just yours. Right. Right. So it gives you kind of
[00:28:13.480 --> 00:28:18.520]   the best of both worlds, I think. Yeah, exactly. So with usenet, I'm just trying to play this out.
[00:28:18.520 --> 00:28:23.240]   This is really helpful for me. Was that the same case then that you couldn't have erased
[00:28:23.240 --> 00:28:26.920]   something across all of usenet because it was distributed and that was served from the
[00:28:26.920 --> 00:28:32.440]   was no central. There's no central authority. And I presume in Twitter, green or whatever it is,
[00:28:32.440 --> 00:28:38.840]   what is it? Green blue sky blue sky. I mean, not blue. Blue sky. I assume that has a similar,
[00:28:38.840 --> 00:28:44.200]   you know, honestly, I think blue sky, by the way, has the creator of Mastodon is on their advisory
[00:28:44.200 --> 00:28:51.560]   board. I'm also planning to, sorry, what are you doing? Do not mess with your settings.
[00:28:51.560 --> 00:28:57.880]   Hit the wrong button. It's from very, very bright to very, very dark.
[00:28:59.240 --> 00:29:04.040]   So I actually plan to interview somebody high up at blue sky pretty soon.
[00:29:04.040 --> 00:29:08.440]   Well, I can learn more. I'd be curious how much like Mastodon, Mastodon has
[00:29:08.440 --> 00:29:12.920]   stayed the test of time. I mean, there have been other attempts like identical and
[00:29:12.920 --> 00:29:19.800]   status net, um, GNU social. This has really lasted and I think works quite well.
[00:29:19.800 --> 00:29:25.640]   The only thing that hurts Mastodon is it's not as fast and exciting and sexy as Twitter is
[00:29:26.280 --> 00:29:30.600]   because here's a big blob of everything. Right. And I think that's, that's the,
[00:29:30.600 --> 00:29:36.040]   that's the interesting issue to me. Um, is that the beauty of Twitter is that you can do
[00:29:36.040 --> 00:29:42.360]   something and anybody who's on Twitter can see it on Mastodon or discord. Well, there's a
[00:29:42.360 --> 00:29:47.480]   discovery issue. Blue sky. Everybody can see it, but there is a discovery issue. Exactly.
[00:29:47.480 --> 00:29:52.200]   And so breaking out and breaking through if we think in a, so let me show you this unity basis,
[00:29:52.200 --> 00:29:56.120]   this works, this is a media basis as a problem. This is Twitter.social, which has
[00:29:56.120 --> 00:30:02.440]   I've set up kind of to look a little bit like tweet tech. So in this second, the first column is just,
[00:30:02.440 --> 00:30:06.840]   you know, uh, I can get rid of that. Oops. I don't want to log out. That's the wrong button.
[00:30:06.840 --> 00:30:11.240]   The first column is just for tweeting and stuff like that. This second column is
[00:30:11.240 --> 00:30:16.920]   my home. That's who I follow. That's your Twitter feed. It's, uh, it's not algorithmic. There is no
[00:30:16.920 --> 00:30:21.880]   algorithm. It's, it's completely chronological. And I control that by just following somebody.
[00:30:21.880 --> 00:30:26.760]   I can follow somebody locally and I can, on my Twitter.social or in most of these are not on
[00:30:26.760 --> 00:30:33.880]   Twitter.social. Uh, this person is at rage.love. That's a completely different Mastodon instance.
[00:30:33.880 --> 00:30:39.240]   So you follow them and then you'll see it just like in your Twitter feed. There's a central
[00:30:39.240 --> 00:30:43.560]   column here, which is notifications. That's just so I know somebody mentions me. I don't have to do
[00:30:43.560 --> 00:30:49.000]   that. And then here in this third column, you can have a federated timeline, which is just
[00:30:49.000 --> 00:30:56.360]   everything. That's the fire hose of every other Mastodon instance I'm federated with. Yes.
[00:30:56.360 --> 00:31:00.920]   Everybody. Okay. And that's for, that's a useful thing for discovery. There's a local timeline,
[00:31:00.920 --> 00:31:07.800]   which is even people I don't follow. Hey, Galia saying she's saying boo. Uh, that's everybody on
[00:31:07.800 --> 00:31:13.320]   Twitter.social, whether I'm following them or not. Right. So you could see what's going on in that
[00:31:13.320 --> 00:31:19.800]   particular server. There is some discovery stuff too. There's explore. It's not, you know, there's
[00:31:19.800 --> 00:31:24.120]   hash, you know, this is trending. There's it's, as you can see, it's not very active.
[00:31:24.120 --> 00:31:30.120]   But there's some stuff going on and that could be more depending on how people, how people use it. So,
[00:31:30.120 --> 00:31:36.760]   I think this is, I think that, you know, this has been going on for a while. And I think
[00:31:36.760 --> 00:31:43.880]   creator was named Oigen Rochko. Yeah. Well, he's a, yeah, you, you, Jean or you, Jean. Okay.
[00:31:43.880 --> 00:31:50.120]   Yeah. You, G-E-N pronunciation. Yeah. What, if we're German to be Oregon? He's German. So,
[00:31:50.120 --> 00:31:55.160]   it's probably what it is then. I think it's German. Yeah. What, what, where did he come from?
[00:31:55.160 --> 00:31:59.720]   Do you know? Uh, you know, I don't know much about him, actually. That's a really good.
[00:32:01.000 --> 00:32:06.280]   It's interesting. Yeah. So he's chief executive officer of, he, of Mastodon. So there is an
[00:32:06.280 --> 00:32:11.240]   entity of Mastodon. Yeah. But that's just the code. That's the code base. And by the way,
[00:32:11.240 --> 00:32:17.640]   it's open source. So it's been forked multiple times. Truth social. Trump's is a fork of Mastodon.
[00:32:17.640 --> 00:32:24.840]   So, yeah, did they get out of trouble with, um, what is it, the GPL?
[00:32:26.600 --> 00:32:32.680]   Trump and social. Uh, yeah. I don't know because they violated his, uh, his GPL for sure.
[00:32:32.680 --> 00:32:40.280]   But whether he's going to pursue it, I don't know. So, uh, he's German born. Let me see if I can
[00:32:40.280 --> 00:32:47.640]   find out more about him. I bet he has by now he has a, uh, a, uh, Wikipedia, uh, entry chief
[00:32:47.640 --> 00:32:52.280]   executive officer, but that just means he's responsible for the, you know, he does not have
[00:32:52.280 --> 00:32:57.880]   a Wikipedia. That's, that's, uh, that's kind of too long. Well, you mentioned it by tomorrow,
[00:32:57.880 --> 00:33:02.520]   somebody might have a great, uh, my, all my experience interacting with him has been great.
[00:33:02.520 --> 00:33:07.480]   Uh, he really cares. He does this, you know, out of the, I don't, he doesn't make a lot of money.
[00:33:07.480 --> 00:33:14.920]   Um, right. Uh, I don't pay him anything for Mastodon. You don't have to. It's open source.
[00:33:16.120 --> 00:33:22.920]   It's a, I think this is exactly. So let's say Twitter poofed, you know, Elon, Elon killed it.
[00:33:22.920 --> 00:33:29.640]   It's interesting when Elon first put in the bid for Twitter, we had hundreds of people flock
[00:33:29.640 --> 00:33:35.000]   to Twitter. That social. I had five or 600 new members, but nothing happened. It was never got,
[00:33:35.000 --> 00:33:40.040]   it's still a backwater kind of, uh, you know, they used it for a while and they went back to Twitter.
[00:33:40.040 --> 00:33:48.120]   But if Twitter went away, uh, or something, I think that Mastodon is a very credible
[00:33:48.120 --> 00:33:54.360]   alternative that solves a lot of these problems. You'll be interesting if Twitter today said,
[00:33:54.360 --> 00:34:01.720]   we're going to allow someone to export all the identities out of Twitter so that you could
[00:34:01.720 --> 00:34:06.520]   reimport them somewhere else. Well, that might be an interesting poison pill. I don't think at
[00:34:06.520 --> 00:34:13.560]   this point, uh, I don't think the board, uh, is right now, but yeah, but they hit, they did a poison
[00:34:13.560 --> 00:34:19.560]   pill for about four seconds and then took it back as they wanted the 54 20 is share. Uh, but I think
[00:34:19.560 --> 00:34:25.000]   that would be really interesting. I'm, they may not be able to do it at this point. You probably,
[00:34:25.000 --> 00:34:30.280]   if you're in a sale of contract, you can't say, Oh, here's all this stuff. I'm going to give it away.
[00:34:30.280 --> 00:34:34.280]   So I bet they can't, but that would be really interesting. You know what, Elon, if you really
[00:34:34.280 --> 00:34:38.840]   want to do a good thing with Twitter, that would be a good thing to do. Make X, make it possible to
[00:34:38.840 --> 00:34:43.800]   export everything, make the fire hose available to anybody who wanted it. You know, there are things
[00:34:43.800 --> 00:34:49.320]   you could do with Twitter that would be great to make it more of a public entity and a public
[00:34:49.320 --> 00:34:55.080]   value, open source, the code. There's lots of things you could do. I think blue sky was a very
[00:34:55.080 --> 00:34:59.320]   good idea. By the way, and I've mentioned this before, blue sky is funded and there's nothing
[00:34:59.320 --> 00:35:05.080]   you like to do about it. Yeah. And I got a question for you, Ann, since you are a social there at
[00:35:05.080 --> 00:35:11.960]   that I promise you, I'm not. Well, no, but you're, you're, you're bringing people in your, your
[00:35:11.960 --> 00:35:18.760]   community manager community manager, right? So I'm curious what you've, what you've learned in
[00:35:18.760 --> 00:35:25.320]   that experience as community manager at Twit. And let me just say, I'd be curious at various
[00:35:25.320 --> 00:35:29.720]   answers. What you learned about functionality, what you've learned about people, what you've
[00:35:29.720 --> 00:35:34.920]   learned about what people like. I mean, yes, it's just Twit and Twit's a friendly place. But
[00:35:34.920 --> 00:35:41.560]   what have you found in your experience? Well, I think whether it be in Twitter is a lot easier
[00:35:41.560 --> 00:35:47.400]   for me because it's, it's such a big community. And I put that in quotes. Everybody just, just
[00:35:47.400 --> 00:35:53.480]   loves on everybody here. So there's really not much to worry about, just making sure everyone's
[00:35:53.480 --> 00:35:59.320]   happy and have somewhere to converse, whether they want to talk about code and Linux or whether
[00:35:59.320 --> 00:36:06.360]   they want to talk about sports. And it just, it's just been really, really easy. Now,
[00:36:06.360 --> 00:36:11.720]   trying to manage something like a photographer's community, which I did a long time ago,
[00:36:11.720 --> 00:36:20.600]   that was a pain in the butt because people just had egos, you know, there's one thing that makes
[00:36:20.600 --> 00:36:26.680]   the discord really easy to moderate and really successful, which is you have to pay seven bucks
[00:36:26.680 --> 00:36:34.600]   a month to be in the club. And having a bar of any kind. Yeah, we have no, there's zero trolling
[00:36:34.600 --> 00:36:38.600]   because nobody's no, the troll is not gonna spend seven bucks just to get kicked out.
[00:36:38.600 --> 00:36:46.440]   Sorry. No refunds. So that eliminates, you know, there are, there are problems occasionally,
[00:36:46.440 --> 00:36:51.000]   but they're minor because there's skin in the gazal lot of skin in the game. So that's number one.
[00:36:51.000 --> 00:36:56.600]   And by the way, even though in order to pay seven bucks a month, I guess we have to have your credit
[00:36:56.600 --> 00:37:02.520]   card and a lot of people in the discord use handles, we don't know who they are. That's fine.
[00:37:02.520 --> 00:37:09.640]   And I don't have any problem with that same thing in our chat. I also run a free community
[00:37:09.640 --> 00:37:16.280]   twit.community. And I love that. And that one is free and it has more problems. There's
[00:37:16.280 --> 00:37:21.320]   some there was there is trolling occasionally and stuff. But it is also a very good place for
[00:37:21.320 --> 00:37:30.120]   conversation. So part of that is there's this kind of self selecting nature of it, right?
[00:37:30.120 --> 00:37:35.480]   Yeah. And there's there's one because it's not seven bucks. There's more issues. Absolutely.
[00:37:35.480 --> 00:37:42.520]   When I really just saw a smartphone photographers community, I battled every
[00:37:42.520 --> 00:37:49.480]   damn gum week with with just egos because everybody they wanted to be judged on their
[00:37:49.480 --> 00:37:52.920]   photography yet they didn't want to be judged on the photography, you know,
[00:37:52.920 --> 00:37:59.160]   they say, Hey, critique my photograph. And you tell them, Hey, well, I think this could be better or
[00:37:59.160 --> 00:38:03.800]   this should could look like this and yada yada yada. They get defensive and then they start throwing
[00:38:03.800 --> 00:38:09.560]   stones and then it tell you no cannons better than Nikon and Nikon is better than Sony and so
[00:38:09.560 --> 00:38:16.280]   it's just a bunch of that just ego stuff. And it was never any real community of people trying to
[00:38:16.280 --> 00:38:21.160]   help other photographers out about with the craft and help them get better instead of just,
[00:38:21.160 --> 00:38:24.280]   you know, yeah, we have that. We have to make sure nicer than artists.
[00:38:24.280 --> 00:38:28.680]   And I think we're saying, well, okay, I'm going to show you a thread that's going on right now in
[00:38:28.680 --> 00:38:35.000]   the twit community in the in the discourse, not discord discourse forums, the open for that
[00:38:35.000 --> 00:38:40.760]   community. We have a really nice guy, P holder who has just taken on himself to become a moderator.
[00:38:40.760 --> 00:38:46.760]   So thank you. He does a great job. So a guy came in this last right after twit saying the
[00:38:46.760 --> 00:38:50.760]   assumption seems to be that all the listeners share the politics and views of the people in the show.
[00:38:50.760 --> 00:38:56.200]   And then P holder says the assumption seems to be your views are not so fragile. They can survive
[00:38:56.200 --> 00:39:01.400]   your exposure to someone else's point of view to which RJ replies, it seems to me a show wants
[00:39:01.400 --> 00:39:05.960]   to maximize its audience would seek to acknowledge and not everyone listening shares their exact
[00:39:05.960 --> 00:39:09.560]   point of view and black and forth, back and forth, stop whining, blah, blah, blah.
[00:39:09.560 --> 00:39:15.640]   And then sorry to interrupt, you know, I have a question. I mean,
[00:39:15.640 --> 00:39:22.120]   I have to say itself corrects a little bit occasionally will boot people.
[00:39:22.120 --> 00:39:29.880]   You know, P holder has had to boot some people. So have I. So something completely opens,
[00:39:29.880 --> 00:39:36.680]   always going to have a little bit of that. This is life. One thing I will tell you, I know for a fact,
[00:39:36.680 --> 00:39:43.640]   like a garden, if you don't tend to, yes, you've got to moderate, you've got to have a presence.
[00:39:43.640 --> 00:39:50.040]   Ideally, in all the twit stuff, all the hosts would be active and present because our presence
[00:39:50.040 --> 00:39:55.080]   lifts the conversation. Yes, sir. I'm sorry. I'll do it more often.
[00:39:55.080 --> 00:39:57.320]   Well, you don't have to. I'm not saying that to you, particularly.
[00:39:57.320 --> 00:40:00.440]   But this is why Ant has his farmer's hat last all the time.
[00:40:00.440 --> 00:40:05.000]   Yeah. And that's why I'm in there all the time. And I mean, it's at least my responsibility.
[00:40:05.000 --> 00:40:09.400]   The other thing is if there is a bad apple, you have to get rid of them quickly.
[00:40:09.400 --> 00:40:13.880]   You have to aggressively moderate. This is something Twitter does not do because of free speech.
[00:40:13.880 --> 00:40:19.000]   But I believe in any public form, you have to moderate quickly. Because what will happen
[00:40:19.000 --> 00:40:23.720]   like in a garden, the weeds will push out the good people and it's a vicious circle. And pretty
[00:40:23.720 --> 00:40:29.640]   soon, everything's forchan. So nobody, because nobody wants to be in a place where they're kind of
[00:40:29.640 --> 00:40:34.360]   stuff is going on. No, we learned that. I mean, I learned that in 1994,
[00:40:34.360 --> 00:40:40.920]   late, day five, we started our first forums on ng.com. The first, the first sign of trouble,
[00:40:40.920 --> 00:40:46.680]   we started the forums, people, you know, we had one, all the sports and my boss said,
[00:40:46.680 --> 00:40:50.520]   we really wanted us to emphasize high school wrestling. And he was right because high school
[00:40:50.520 --> 00:40:53.880]   wrestling doesn't get the attention that football basketball baseball get, right?
[00:40:53.880 --> 00:40:59.640]   So, oh, please for us. This is great. Right. And huge traffic was wonderful. And then someday,
[00:40:59.640 --> 00:41:02.440]   and we didn't, we didn't know anything about moderation. This is 95.
[00:41:02.440 --> 00:41:10.920]   Someday somebody comes in and starts a thread about coach Nutreber. He said, oh, we better watch this.
[00:41:10.920 --> 00:41:17.480]   And so we hired moderators. We didn't use all the stuff we learned. And originally,
[00:41:17.480 --> 00:41:21.640]   we thought that the moderator would be the host and also the person who killed stuff.
[00:41:21.640 --> 00:41:25.320]   And then we got on somebody who had experience with this at early bulletin boards. And he said,
[00:41:25.320 --> 00:41:30.120]   no, no, no, no. The mayor is not the cop who also kisses the baby. Yeah, that's right.
[00:41:30.120 --> 00:41:34.440]   Right. And you got to have great. By the way, since we're talking about Twitter and interactivity,
[00:41:34.440 --> 00:41:41.320]   Tony Hale just tweeted. They've added a new feature to Twitter blue. Oh, which is top articles,
[00:41:41.320 --> 00:41:45.880]   which I think we all like. You can now get the top articles from the people you follow and also
[00:41:45.880 --> 00:41:50.120]   from the people they follow. So it's a way to expand out the next. Oh, and this is what they
[00:41:50.120 --> 00:41:55.080]   bought when they bought Nuzzle. Nuzzle had friends, the friends, they had, and then it was friends
[00:41:55.080 --> 00:41:59.880]   of friends. So there's, they're adding a Nuzzle feature. So here it is. So I just opened up my
[00:41:59.880 --> 00:42:05.000]   Twitter and I'm a Twitter blue, as we all are the three of us, Twitter blue subscriber. Get
[00:42:05.000 --> 00:42:09.400]   more news people they follow expands your results showing the most shared articles from the people
[00:42:09.400 --> 00:42:14.920]   you follow, plus the people they follow. And you you have to turn that on. So I'll turn that on.
[00:42:14.920 --> 00:42:21.160]   I will just there. Yeah. Oh, so this is just like Nuzzle now. That's hysterical. So Nuzzle will have
[00:42:21.160 --> 00:42:25.000]   one more. If they're going to add all the Nuzzle features, there'll be one more column that's
[00:42:25.000 --> 00:42:31.320]   basically stuff that nobody else mentioned that is worth a little editorial, you know. By the way,
[00:42:31.320 --> 00:42:36.200]   do you think this is one of the stories of my feed? How San Francisco became a failed city?
[00:42:36.200 --> 00:42:40.360]   Do you think it's a failed city? Well, this is a result to the election. We had yesterday that
[00:42:40.360 --> 00:42:44.600]   California primary, their attorney general who was very progressive,
[00:42:44.600 --> 00:42:50.920]   chase a Bowdoin got thrown out by a landslide, which which is the polls did not predict, by the
[00:42:50.920 --> 00:42:59.960]   way, they thought it was going to be a very close race. It was not. I don't have enough to know about
[00:42:59.960 --> 00:43:06.440]   it. I do understand why the residents of San Francisco threw him out because he got the blame
[00:43:06.440 --> 00:43:14.040]   rightly or wrongly for a very big rise in minor crimes, smashing grabs, smashing grabs,
[00:43:14.040 --> 00:43:19.480]   you know, burglaries, and of course, the rise in homelessness downtown,
[00:43:19.480 --> 00:43:27.080]   fentanyl abuse, fentanyl deaths, and he got blamed for all of that. So whether that what I don't know
[00:43:27.080 --> 00:43:33.080]   is if that's accurate or not, he was very progressive. His parents, he's a deputy public defender,
[00:43:33.080 --> 00:43:41.160]   defender, and his parents were radicals. So he came, in fact, there were some concern because
[00:43:41.160 --> 00:43:45.880]   his parents, Kathy Booty and Dave Gilbert were weather out at underground members.
[00:43:45.880 --> 00:43:52.360]   And when he was 14 months old, they were arrested and convicted of murder in a brain
[00:43:52.360 --> 00:43:59.160]   robbery. She got 20 years to life. He got 75 years to life. He was raised by adoptive parents.
[00:43:59.160 --> 00:44:07.400]   Guess who? Bernadine Dorn. So he was very radical in his upbringing, Bernadine Dorn,
[00:44:07.400 --> 00:44:17.880]   another well-known weather underground member. So he came in saying, we're going to deal with
[00:44:17.880 --> 00:44:24.600]   this in a different way. And most of the complaints are smashing grab and public urination
[00:44:25.480 --> 00:44:32.280]   about San Francisco. Yeah. But I tell you what, it's bad. Lisa and I went to a Michelin
[00:44:32.280 --> 00:44:38.360]   two or three star restaurant downtown. Very excited, beautiful restaurant, lovely.
[00:44:38.360 --> 00:44:42.120]   But in order to get there, we had to walk through a homeless encampment one block away from the
[00:44:42.120 --> 00:44:46.280]   front door. There was a guy defecating on the street, which really kind of put us off our dinner.
[00:44:47.720 --> 00:44:56.280]   5pm. And this is endemic downtown San Francisco. And it's a problem. I don't know if I know it's
[00:44:56.280 --> 00:45:05.160]   not, but he's fault. Although prosecutions under him went down by about 50%. So he said he wasn't
[00:45:05.160 --> 00:45:14.920]   going to seek charges for a lot of things like minor drug offenses, gang memberships. He was
[00:45:16.040 --> 00:45:20.520]   trying to change things. Well, it's the problem is if you go too far, I know this is way off the
[00:45:20.520 --> 00:45:26.360]   topic of the show, but it's overcorrecting blue. But you end up in a Giuliani territory,
[00:45:26.360 --> 00:45:32.360]   the broken glass. Yeah. So that, yeah, the squeegees guys on the street corner were a
[00:45:32.360 --> 00:45:40.200]   lifestyle problem for us privileged people who had jobs and cars. But you go too far, you arrest
[00:45:40.200 --> 00:45:47.320]   a lot of people, they had up in jail for a long time for what are minor offenses. Although I got
[00:45:47.320 --> 00:45:53.560]   to point out, you know, that broken glass theory was Malcolm Gladwell popularized that. And of course,
[00:45:53.560 --> 00:46:01.320]   Rudy Gialint, Judy Lianney, ran on that. If we fix the little things, you know, stop graffiti,
[00:46:01.320 --> 00:46:08.920]   stop broken windows, stop the squeegee men, everything gets better. Northeastern did a study on it and
[00:46:08.920 --> 00:46:16.600]   they said we've debunked it. It's not true. Yes. It's not true. So I don't know, maybe there's
[00:46:16.600 --> 00:46:23.640]   debate in social science circles about it. It's, Corey Doctorow calls those just so stories
[00:46:23.640 --> 00:46:29.800]   where they're so neat and pat and they make so much sense. And you read, you know, Malcolm Gladwell
[00:46:29.800 --> 00:46:35.960]   and you go, Oh, that makes so much sense. That's obviously true. But life is much more complicated.
[00:46:35.960 --> 00:46:40.200]   It's like filter bubbles. Yeah. Now we're seeing that no,
[00:46:40.200 --> 00:46:45.640]   filter bubbles don't really exist. Another favorite now people are going nuts with is that
[00:46:45.640 --> 00:46:55.560]   the admission that studies that said that the time spent on screens was a cause of team depression
[00:46:55.560 --> 00:47:01.880]   and stuff. And now the data is saying, it's a result of it, perhaps. Well, and or it may be more
[00:47:01.880 --> 00:47:07.560]   about what you're actually doing. Right. And so this is early days, we need the research, we need
[00:47:07.560 --> 00:47:11.640]   the data, we need the interpretation. But it's early days to think, I found it, I know the cause
[00:47:11.640 --> 00:47:17.000]   of the root of all problems that that leads to get ready and moral panic. We have problems in
[00:47:17.000 --> 00:47:22.440]   the society and they may be bigger than anything the district attorney can do or even a mayor
[00:47:22.440 --> 00:47:28.200]   can solve. I mean, London Breeze, Mayor San Francisco is very good. But the homeless problem in
[00:47:28.200 --> 00:47:32.440]   San Francisco is virtually intractable. But it's always been Leo, when I lived there,
[00:47:32.440 --> 00:47:40.200]   San Francisco was the place that dreamers came at the end of the rainbow. And you always had more
[00:47:40.200 --> 00:47:43.640]   of that there than any other city I've lived in. New York has plenty of problems. Chicago
[00:47:43.640 --> 00:47:47.880]   had plenty of problems that lived in these other cities. But San Francisco was just a drew,
[00:47:47.880 --> 00:47:55.320]   a huge population of people who ended up on the streets, succeeding in society otherwise.
[00:47:55.320 --> 00:48:00.040]   Right. And so it required you put an obligation of social infrastructure on the city.
[00:48:00.040 --> 00:48:06.040]   And Ronald Reagan, when he was governor, closed the mental institutions, probably rightly so,
[00:48:06.040 --> 00:48:11.160]   his idea of creating many small halfway houses was probably the right thing to do,
[00:48:11.160 --> 00:48:15.720]   but they never created the halfway house. But it also led to police dealing with mental health
[00:48:15.720 --> 00:48:21.080]   problems. Well, and there is some evidence, I think that the problem in San Francisco
[00:48:21.080 --> 00:48:27.160]   also comes from the fact that the police hate booting and have decided just not to do anything.
[00:48:27.160 --> 00:48:34.040]   Like they're just turning and by the way, this what happened in Uvaldi is a crisis across the
[00:48:34.040 --> 00:48:42.280]   country apparently. Police turning their head away from crime because they don't like the
[00:48:42.280 --> 00:48:46.840]   administration or they don't like this or they don't like that, or they don't like the people
[00:48:46.840 --> 00:48:52.840]   calling to defund the police or for whatever reason. But Dean said, you know, one of his last
[00:48:52.840 --> 00:49:02.200]   prosecutions, he shut down a big ring of people reselling stolen goods.
[00:49:02.200 --> 00:49:08.840]   He he uncovered it that DA's office uncovered it. They couldn't get the police
[00:49:08.840 --> 00:49:14.680]   to help them in the arrest. They had to rent you halls to go in and arrest.
[00:49:14.680 --> 00:49:19.080]   Yeah, the police said, yeah, no, we're not going to help you here because this you're just trying
[00:49:19.080 --> 00:49:25.000]   to score political capital before this recall. And so he had to rent you halls to do it.
[00:49:25.000 --> 00:49:31.320]   So there's a, you know what, life is complicated. These just so stories are very appealing.
[00:49:31.320 --> 00:49:34.120]   It's wonderful to think, Oh, I know what's wrong. We can fix it.
[00:49:34.120 --> 00:49:40.840]   But it's it's a chaotic system and it's not easy to know what the causes of things are.
[00:49:41.640 --> 00:49:45.960]   I mean, income inequality is getting pretty bad in this country. Look at, look at that.
[00:49:45.960 --> 00:49:48.200]   Cool. You know, look at that.
[00:49:48.200 --> 00:49:55.560]   All right. Boy, we got philosophical fast on this. Stacy wasn't here to stop us.
[00:49:55.560 --> 00:50:02.600]   Let's take a little break. We've got lots more to talk about. I might even do a change log.
[00:50:02.600 --> 00:50:10.840]   I'm feeling frisky. Some cool stuff. Some cool stuff. Our show today brought to you by hacker rank.
[00:50:11.640 --> 00:50:17.000]   Between deadlines and frustrating interview tools that aren't doing the job for technical
[00:50:17.000 --> 00:50:21.560]   interviews, conducting a technical interview might be the last thing you have time for. But you
[00:50:21.560 --> 00:50:27.000]   know what's the most important thing you do? But what was it like the last time, especially now that
[00:50:27.000 --> 00:50:31.160]   you're doing them over Zoom, you spend the first 10 minutes of your interviews, just, you know,
[00:50:31.160 --> 00:50:35.400]   trying to get the environment right to share code from a bunch of different documents,
[00:50:35.400 --> 00:50:40.680]   wasting your time, maybe even your candidates time. Hacker ranks got a solution. Hacker ranks
[00:50:40.680 --> 00:50:47.080]   a place people go to get jobs and to hire in technology. It's a great place. I hang out there
[00:50:47.080 --> 00:50:51.480]   because they have these puzzles designed to help you do better with the interview process
[00:50:51.480 --> 00:50:56.280]   as an applicant. But I love doing these programming puzzles. There's so much fun. You can do them for
[00:50:56.280 --> 00:51:04.200]   fun. They have developed something for the hirer, the employer, an IDE, an integrated development
[00:51:04.200 --> 00:51:11.160]   environment for the tech interview process. So cool. With a set of easy to use interview tools,
[00:51:11.160 --> 00:51:17.320]   you'll quickly find the best developers for your technical projects. You get a pre-made question
[00:51:17.320 --> 00:51:21.560]   library with more than 2,500 questions. So you don't have to spend hours trying to think up
[00:51:21.560 --> 00:51:27.800]   coding questions. You know, all the questions, the best practices questions are in there.
[00:51:27.800 --> 00:51:32.920]   A code playback feature, you know, sometimes you'll get the candidate to do some coding. You want
[00:51:32.920 --> 00:51:37.480]   to watch what they're doing. With the code playback, you can review their coding approach, score their
[00:51:37.480 --> 00:51:41.960]   skill levels. You've got a built-in whiteboard. You both can see. So if you want to try some
[00:51:41.960 --> 00:51:46.360]   collaboration stuff, see how problems are solved in real time, it's all there for you.
[00:51:46.360 --> 00:51:53.400]   This is just one more reason you should check out HackerRank. Time to reboot your technical
[00:51:53.400 --> 00:52:00.440]   interview process with HackerRank. Click interview done. Start using HackerRank for free today.
[00:52:01.080 --> 00:52:06.200]   See how much better a technical interview can be? Reboot those technical interviews with HackerRank's
[00:52:06.200 --> 00:52:10.760]   easy to use tools. With a pre-made question library, code playback, built-in whiteboard,
[00:52:10.760 --> 00:52:15.960]   you'll be conducting better technical interviews and instantly identifying the right talent. Go
[00:52:15.960 --> 00:52:22.760]   to hackerrank.com/twig to start a better tech interview for free today. HackerRank,
[00:52:22.760 --> 00:52:33.640]   h-a-c-k-e-r-r-a-n-k, hackerrank.com/twig. Thank you, HackerRank, for supporting Twig and for
[00:52:33.640 --> 00:52:38.680]   those great problems. I love them. And now back to Skadden, ARPS, Slate, Meagre, and Flom.
[00:52:38.680 --> 00:52:46.360]   Usually you just say Skadden ARPS. I see that all the time, Skadden ARPS. But I love the full name.
[00:52:46.360 --> 00:52:50.520]   I just have to give them the full name. New York State has passed the first ever right to repair
[00:52:50.520 --> 00:52:56.440]   law for electronics. There are other right to repair laws. I remember hearing there's dozens of
[00:52:56.440 --> 00:53:04.280]   these states that have been planning to do this. The first, well, yeah, in a way, the first for
[00:53:04.280 --> 00:53:12.920]   consumer electronics, Colorado passed and a much needed right to repair law for electric wheelchairs.
[00:53:12.920 --> 00:53:19.240]   This was a big issue for people in chairs. They couldn't fix their own chair. Sometimes you'd
[00:53:19.240 --> 00:53:26.440]   wait weeks or months for repairs from an off from the official repairs. So Colorado fixed that.
[00:53:26.440 --> 00:53:32.680]   New York State has just passed their Fair Repair Act. Now it is a little limited. It requires all
[00:53:32.680 --> 00:53:39.080]   manufacturers who sell digital electronic products in the state to make tools, parts, and instructions
[00:53:39.080 --> 00:53:44.680]   for repair available to consumers and independent shops. This is the kind of thing Apple hated,
[00:53:44.680 --> 00:53:50.280]   lobbied against like crazy. It's awaiting signature by the governor. It'll take effect one year
[00:53:50.280 --> 00:53:57.320]   after it's signed. I fix it called it a giant leap for repair kind. But
[00:53:57.320 --> 00:54:06.840]   it's interesting because it does have exceptions for home appliances, medical devices. You can
[00:54:06.840 --> 00:54:14.360]   actually almost see the money moving from lobbyists hands into the pockets of the state assembly.
[00:54:15.320 --> 00:54:21.480]   Home appliances, medical devices, medical devices like wheelchairs and all the premium
[00:54:21.480 --> 00:54:26.360]   tech and agricultural equipment. Of course, part of the right to repair is just fight with John Deere.
[00:54:26.360 --> 00:54:34.040]   Yeah. So Apple, I guess, just lost the lobbying battle. They didn't pay enough to get the
[00:54:34.040 --> 00:54:40.200]   get exempted out of this. Massachusetts has a law on automobile data, Colorado, the bill on
[00:54:40.200 --> 00:54:45.880]   wheelchairs, and now New York State for consumer electronic devices. That's a big deal.
[00:54:45.880 --> 00:54:50.040]   That's a deal. I should know this because I do try to watch various switch shows. But there's
[00:54:50.040 --> 00:54:56.120]   so many of them. I miss it. Have you tried to repair an iPhone? We did. Not in the whole
[00:54:56.120 --> 00:55:03.640]   cell. So this was, I use the term malicious compliance. That's like when you pay, you know,
[00:55:03.640 --> 00:55:07.480]   you have to pay a $100,000 tax bill and you give them a million pennies.
[00:55:07.480 --> 00:55:17.160]   Malicious compliance. So Apple's got a, you know, self repair thing. First of all, it's limited
[00:55:17.160 --> 00:55:22.760]   only to the very newest stuff. So it's an iPhone 12 or 13 with a brand new iPhone SE. That's it.
[00:55:22.760 --> 00:55:26.840]   But Micah happened to have an iPhone 12. I try to give him an SE, he said, no, it's too old. I can't.
[00:55:26.840 --> 00:55:31.240]   So he doesn't need a new battery in his iPhone 12. It's only a year old, but he said, all right,
[00:55:31.240 --> 00:55:37.560]   I'm going to order a battery. You give, you know, they charge you more than $1,000 for
[00:55:37.560 --> 00:55:46.680]   two big cases worth 76 pounds of equipment. And gigantic. It's like crazy. Micah got it all.
[00:55:46.680 --> 00:55:52.680]   Now you're like, you're a roadie taking a trunk worth of sound equipment with your gear and stuff.
[00:55:52.680 --> 00:55:58.040]   Yeah. Well, and this is the same stuff that Apple uses in the stores. It's not necessarily
[00:55:58.040 --> 00:56:04.840]   stuff you need. I fix it. Doesn't they, they've got kind of low end ways of getting all of this done.
[00:56:04.840 --> 00:56:12.120]   But if you went to the Apple store, let me see if I can find this. Micah video, because wait till
[00:56:12.120 --> 00:56:17.560]   you see it. Was it under a tech break? Probably was, right? Yes, sir. Yeah. Tech break.
[00:56:17.560 --> 00:56:24.280]   I have somebody else's video on YouTube. You want Michael? Yeah. What?
[00:56:26.840 --> 00:56:29.880]   Pocket operator for Pixel. We do a lot of tech breaks.
[00:56:29.880 --> 00:56:37.160]   Here we go. God, I didn't realize we had that many. Holy cow, here we go. So here's the,
[00:56:37.160 --> 00:56:42.680]   here's the equipment that Micah, there's the cases. Okay. The big cases are as big as he is.
[00:56:42.680 --> 00:56:46.520]   He is. Now you have seven days. You got to return them. Otherwise, they're going to charge you more
[00:56:46.520 --> 00:56:50.840]   than a thousand bucks for this gear. So if you never use otherwise, oh, yeah. I mean, you do
[00:56:50.840 --> 00:56:57.000]   you don't need this. This is a big press. One of them is a heater and one of them is a press
[00:56:57.000 --> 00:57:02.600]   to put the phone back together. Again, that's the press. Looks like an espresso machine with a
[00:57:02.600 --> 00:57:09.000]   big lever. Because the phones glue together, the heater loosens the glue. So it's a little oven
[00:57:09.000 --> 00:57:16.280]   to loosen the glue. But here's the problem. That and the battery were set, sent separately.
[00:57:16.920 --> 00:57:23.880]   The battery didn't arrive. One day goes by two, three, four, five, six, seven on the seventh day.
[00:57:23.880 --> 00:57:29.560]   Micah calls Apple. Apple says, no, no, this is handled by spot. A company called Spot.
[00:57:29.560 --> 00:57:33.640]   He calls Spot, Spot says, he says, the battery hasn't come yet. They said, well, that's not our
[00:57:33.640 --> 00:57:36.360]   problem. You have seven days. If you don't return it, we're going to charge you.
[00:57:36.360 --> 00:57:46.040]   So that's the book. So we have all this stuff, but we don't have the one thing, the two ounce part
[00:57:47.000 --> 00:57:52.680]   that you need to fix it. I think Apple doesn't really care. I mean, you can make a lot of excuses
[00:57:52.680 --> 00:57:57.240]   like, well, the battery's lithium-ion, so it has to be shipped separately. Blah, blah, blah.
[00:57:57.240 --> 00:58:05.000]   Yeah. Here it is. Two hours left. It arrived. But too late, Micah's in the car because he doesn't want
[00:58:05.000 --> 00:58:14.920]   to have to pay $1,049 for this stuff. Now, do they charge? Even for getting the deposit for
[00:58:14.920 --> 00:58:19.960]   not returning it. Is there a fee for-- Yeah. There's $49.00. You pay for this whole thing?
[00:58:19.960 --> 00:58:24.680]   $49.00 rental and $49.00 for the-- It ends up, so we hand it together. It's almost exactly what
[00:58:24.680 --> 00:58:31.080]   you would pay if you gave it to Apple to fix. The coincidence, I think. But you have a right to
[00:58:31.080 --> 00:58:38.600]   repair. Yeah. You wanted to repair it yourself. It's just Apple's middle finger compliance.
[00:58:38.600 --> 00:58:46.920]   Yeah, it sure is. So obviously, our advice is don't get Apple to do it.
[00:58:46.920 --> 00:58:52.200]   I guess if you were a third-party repair shop, you would buy those tools. You probably already
[00:58:52.200 --> 00:58:56.520]   have them. But I think you have to have a separate set for each model, by the way, because it's all
[00:58:56.520 --> 00:59:04.440]   just exactly-- Oh, geez. So-- No, you don't have-- See, this is part of it. It's the only Apple had
[00:59:04.440 --> 00:59:10.200]   these tools for the longest time until now. But you break iFix has the means to heat up and pull
[00:59:10.200 --> 00:59:14.680]   up-- Yeah. I mean, if you go to iFix it to replace an iPhone 12 battery, they will sell you a battery
[00:59:14.680 --> 00:59:22.440]   and they will-- But it may not be from Apple, right? And they will sell you a little thing you put in
[00:59:22.440 --> 00:59:27.560]   the microwave oven, a little bolster that you put on it to heat up the phone to loosen the glue. They
[00:59:27.560 --> 00:59:34.360]   have little spudgers, little picks that you pry the thing apart with and all that. So yeah, you can
[00:59:34.360 --> 00:59:42.440]   get the same stuff and it's cheaper. Let me see. Here's the iPhone 12. Let's see, battery replacement.
[00:59:42.440 --> 00:59:51.720]   Difficulty moderate. I think that's generous. You need a Pendelobe screwdriver, an eye opener,
[00:59:51.720 --> 00:59:58.360]   a set of opening picks, a suction handle, a tri-point screwdriver, a spudger, tweezers, tweezers.
[00:59:58.360 --> 01:00:02.920]   But they-- You know, to their credit, there's the eye opener that you put in the microwave to heat
[01:00:02.920 --> 01:00:08.280]   up. Here's the suction cups to open it up. What do you want to do this yourself?
[01:00:08.280 --> 01:00:13.400]   Oh, God. This is what all of that Apple stuff does. I don't want to put a screen protector on it.
[01:00:13.400 --> 01:00:18.440]   Yeah. I'll above the screw it up. But you know, you can do it yourself. There's some screws and,
[01:00:18.440 --> 01:00:23.240]   oh, yeah, I, you know, let Apple do it. But that's the whole point, isn't it?
[01:00:23.240 --> 01:00:28.760]   I'd ask Mr. Burke to do it. I trust him. He'll let Burke do it. That's my model.
[01:00:29.560 --> 01:00:36.680]   So I put up a video from Mac Rumer's under that story on the rundown. And so they got the
[01:00:36.680 --> 01:00:39.720]   battery and they're doing it. And it looks like hell. It looks like utter hell.
[01:00:39.720 --> 01:00:43.320]   Yeah. I mean, Micah could have done it. He would have done it. He's so small. Yeah.
[01:00:43.320 --> 01:00:50.360]   He's got little fingers. So this is, by the way, I'm at step 32. And I haven't even removed the battery.
[01:00:53.720 --> 01:01:01.800]   So, you know, yeah, look at, I love I fix it. God bless them. They've been making this available
[01:01:01.800 --> 01:01:08.600]   forever. And, you know, Apple now makes an official way to do it, which seems to me to be kind of
[01:01:08.600 --> 01:01:15.000]   dragging your feet compliance. Yeah, the, I think the Verge did it. Everybody's done it now.
[01:01:15.000 --> 01:01:21.880]   This is, this is other world computing. Yeah. Yeah. I don't know. This is Mac Rumer's. I was
[01:01:21.880 --> 01:01:25.320]   there advertising. That's what I put up. Yeah. So, yeah.
[01:01:25.320 --> 01:01:31.720]   There you have it. So you have a law now that says you have a right to repair, but it, it could
[01:01:31.720 --> 01:01:35.400]   have mattered. Well, I wonder, you know, I mean, with companies acting like this,
[01:01:35.400 --> 01:01:43.400]   malicious compliance, you know, here's a law I think should be passed globally. Ontario,
[01:01:43.400 --> 01:01:51.240]   Canada, the province in Canada has passed a law to force companies to allow you to disconnect
[01:01:51.240 --> 01:02:00.200]   when you're off work. As of June 2nd, employers in Ontario with 25 or more employees must have a
[01:02:00.200 --> 01:02:05.320]   written policy with regard to disconnecting. Disconnecting from work means not engaging in
[01:02:05.320 --> 01:02:10.120]   work-related communications. Emails, telephone calls, video calls, the sending or reviewing of
[01:02:10.120 --> 01:02:15.160]   other messages so as to be free from the performance of work. Yeah, just tell them.
[01:02:15.160 --> 01:02:22.840]   Kudos, kudos. There are a lot of business. We don't, we don't expect, you know, but there are
[01:02:22.840 --> 01:02:28.040]   businesses where if the boss sends an email out in the middle of the night, you're expected to respond
[01:02:28.040 --> 01:02:34.760]   within an hour. The IT guy, or they should have to respond. That's different. Yeah,
[01:02:34.760 --> 01:02:38.120]   it's different for those folks. But, you know, God bless him. Yeah, I've seen.
[01:02:38.840 --> 01:02:44.760]   Jammer Bee came in the middle of the night Sunday morning because her power went out and he had
[01:02:44.760 --> 01:02:51.480]   to reboot everything. Right? So go ahead, star. He's a star though. He's different. Yeah.
[01:02:51.480 --> 01:02:57.000]   I didn't make him do it. He just did it. Although he just did it. It's a good thing he did.
[01:02:57.000 --> 01:03:05.720]   Yeah. It's his job, he says. And here's another one, Apple, and not going to be happy about,
[01:03:05.720 --> 01:03:13.640]   but the EU is now mandating USB-C for all phones sold in the EU by autumn of next year.
[01:03:13.640 --> 01:03:17.640]   Oh, I bet that's 24. Which USB-C? Well,
[01:03:17.640 --> 01:03:25.320]   what do you know? This is all these different USB-C. Yeah, but yeah, but standardize that. No.
[01:03:25.320 --> 01:03:30.920]   I mean, there's Thunderbolt 3, there's Thunderbolt 4, there's USB, but that's all about data.
[01:03:32.200 --> 01:03:38.840]   They've mandate the whole and you have to have a charging. It has to be chargeable through that
[01:03:38.840 --> 01:03:42.600]   hole. It has to be able to charge. They're not saying it has to be Thunderbolt 4, USB 3,
[01:03:42.600 --> 01:03:48.600]   or anything like that. But you got to at least be able to charge it by USB-C. So that's good.
[01:03:48.600 --> 01:03:58.280]   That's good. But like how Ray Gunn has in the IRC, so USB-C is already five years old, seven years old,
[01:03:58.280 --> 01:04:04.760]   wants this goes into effect. Are we expecting another standard? Better not, thanks a couple years.
[01:04:04.760 --> 01:04:11.960]   Well, never say never in technology, right? Right. RS-232C, I miss it.
[01:04:11.960 --> 01:04:21.320]   I want a 29 pin port. I think it's safe to say USB-C will be around for a few more years.
[01:04:22.920 --> 01:04:30.840]   The thing is, we all have USB-C chargers and cables now, right? This laptop doesn't come,
[01:04:30.840 --> 01:04:37.640]   laptops for years had proprietary chargers, even Dell. Now it just does USB-G. I can run it on any
[01:04:37.640 --> 01:04:44.600]   USB-C charger. Yep. My mouse. Yep. That's how it should be. You're right, there'll be another standard.
[01:04:44.600 --> 01:04:51.240]   But now it's hard enough to go through a standards process. Now you're going to have to go and get
[01:04:51.240 --> 01:04:56.840]   legislation written to permit a different plug when there's some functionality that you want.
[01:04:56.840 --> 01:05:04.920]   I think this makes sense. Everybody has a USB-C or will from now on have USB-C chargers and cables.
[01:05:04.920 --> 01:05:11.000]   They should be interoperable. The industry should have done this without legislation.
[01:05:11.000 --> 01:05:15.800]   They bought their own trouble by Apple particularly did this. Oh yeah. If the industry had said,
[01:05:16.360 --> 01:05:20.520]   you know, and they've got plenty of trade. The industry did, which for the most part, remember,
[01:05:20.520 --> 01:05:27.480]   was micro-USB and they really was crappy. Almost everybody but Apple's been USB-C for years.
[01:05:27.480 --> 01:05:34.520]   It's this is aimed at Apple. Yeah. And so now if something better comes along, there's a degree
[01:05:34.520 --> 01:05:39.080]   of difficulty of getting to it is now higher. This is one of those cases where it shouldn't
[01:05:39.080 --> 01:05:41.880]   have been legislation. Logistics should have been threatened that Apple should have been
[01:05:42.440 --> 01:05:47.800]   conceded. That's a good point because let's say there is this new super port.
[01:05:47.800 --> 01:05:54.600]   The good thing about USB-C is it has transitioned the other and what's inside has changed considerably
[01:05:54.600 --> 01:05:59.320]   as you point out. Which caused the confusion. Yeah. Yeah, but not overcharging. The charging
[01:05:59.320 --> 01:06:03.480]   has been consistent. So I mean there's PD so it has changed a little bit. There's quick charging
[01:06:03.480 --> 01:06:07.960]   and so forth. But the fundamental ability to charge that's been the same as long as that
[01:06:07.960 --> 01:06:13.640]   port's been around. So the data changes and this doesn't preclude that. So if you want Thunderbolt
[01:06:13.640 --> 01:06:21.560]   5 on USB-C, presuming you can do it, but USB-C has gone from, I mean Type-C has gone from USB 2.1
[01:06:21.560 --> 01:06:31.160]   to USB 3.1, 3.2, Thunderbolt 3, Thunderbolt 4, which is USB 4. So it's handled for major data
[01:06:31.160 --> 01:06:37.640]   transitions without a problem. I think that's likely that'll be for a while. I see your point though.
[01:06:37.640 --> 01:06:45.160]   If somebody said, "Well, I think the next big thing is fire wire," they couldn't put it on a phone.
[01:06:45.160 --> 01:06:47.080]   I think a parallel port.
[01:06:47.080 --> 01:06:53.800]   Scuzzy. Everything should be a scuzzy. Everything is a scuzzy. I used to have to rewire.
[01:06:53.800 --> 01:07:00.360]   When I had my Osborne 1 and I had a neck impact printer, I was re-riering cables and I'm not you.
[01:07:00.360 --> 01:07:03.800]   Are you soldering them? Oh yeah. Oh yeah. Back in the day.
[01:07:03.800 --> 01:07:06.520]   Oh no. Switch that one and that one.
[01:07:06.520 --> 01:07:11.320]   Here's the cheeky. Yeah, you get the pin outs and you hope that you have different color wires
[01:07:11.320 --> 01:07:16.440]   for each one. Right. Oh man. I've disordered the course a lot. I'm sure. I think I'll work
[01:07:16.440 --> 01:07:20.360]   on a bit of that. I stayed away from that. Never made cables.
[01:07:20.360 --> 01:07:25.480]   But you did get up in the middle of the night when duty called.
[01:07:26.680 --> 01:07:32.200]   I did. I had to do that a lot. I know you do. Unfortunately. Yeah. Unfortunately is right.
[01:07:32.200 --> 01:07:42.760]   Let's see. Speaking of new rules, the SEC is investigating. This is a good article from a
[01:07:42.760 --> 01:07:50.600]   New York Times deal book. New rules a year after the meme stock frenzy. Now, they're not
[01:07:51.880 --> 01:08:00.280]   going to say you can't buy game stock. They're not going to say what you can buy or not. But what
[01:08:00.280 --> 01:08:06.120]   they are concerned about is what happened with Robinhood. A number of retail brokers,
[01:08:06.120 --> 01:08:12.520]   including Robinhood during the rally when game stop is going up, halted trading, right?
[01:08:12.520 --> 01:08:19.320]   Or limited how many shares you could buy. And at some point, I think some of them said you can't
[01:08:19.320 --> 01:08:24.600]   sell your shares. And as the shares started to crash, that pissed some people off. A number of
[01:08:24.600 --> 01:08:30.680]   hedge funds also lost a lot of money. But they're not going to outlaw meme stocks. You can't.
[01:08:30.680 --> 01:08:39.560]   Right. That's insane. But what they can push for is a change to the rules on something called
[01:08:39.560 --> 01:08:44.840]   payment for order flow. We talked about this is a complicated story. I mean,
[01:08:44.840 --> 01:08:49.560]   explain it to people. Forgive me for launching this. I wish Stacy were here to blame her.
[01:08:49.560 --> 01:08:54.680]   Stacy, what's payment for order flow? Because she's so good at that.
[01:08:54.680 --> 01:08:59.240]   She's I will pull a Stacy and try to explain it. We've talked about this before with Robinhood.
[01:08:59.240 --> 01:09:05.240]   Why is Robinhood free? You might ask. Right. How can you have a stock? I mean,
[01:09:05.240 --> 01:09:09.960]   you know, traditionally, when you buy stocks, you'd pay a commission. You'd pay Schwab a commission,
[01:09:09.960 --> 01:09:17.240]   right? All of a sudden, a long comes Robin weight on the process. It's not like instant either.
[01:09:17.240 --> 01:09:22.520]   Well, long comes Robinhood, which people have celebrated because it democratizes stocks.
[01:09:22.520 --> 01:09:26.280]   It's free. I just want to share that stock you pay for the stock, but you don't have to
[01:09:26.280 --> 01:09:31.160]   bear commission, which makes it one of the reasons there's volatility because it doesn't cost. If
[01:09:31.160 --> 01:09:35.400]   there's if it doesn't cost you to do a transaction, you might buy and sell, buy and sell, buy and sell.
[01:09:36.520 --> 01:09:39.960]   So how does Robinhood make money? And we talked about this a while ago on the show.
[01:09:39.960 --> 01:09:45.240]   They make money because they don't execute the orders.
[01:09:45.240 --> 01:09:52.520]   They sell the right to execute those trades to bigger firms, to wholesalers,
[01:09:52.520 --> 01:10:00.200]   like Citadel securities. They sell. So they charge a commission in effect, not to you,
[01:10:00.200 --> 01:10:09.960]   but to Citadel. Well, why would Citadel pay? Because now Citadel gets, this happens all instantly,
[01:10:09.960 --> 01:10:17.240]   right? Gets fast signals about stock movement and can buyer sell on trade on their own accounts
[01:10:17.240 --> 01:10:23.160]   and make money because they have advanced warning that a lot of people are buying AMC.
[01:10:25.240 --> 01:10:34.680]   So Citadel is in effect, you have an advantage in the stock market if there's an information
[01:10:34.680 --> 01:10:40.680]   gap. If you know more than the other guy, you can make money. That's what they're paying for.
[01:10:40.680 --> 01:10:46.600]   And that's what Robinhood is using to fund their business. It is problematic because
[01:10:46.600 --> 01:10:54.600]   the information inequality is not between Citadel and Merrill Lynch. It's between Citadel and you.
[01:10:55.320 --> 01:11:04.520]   Right. So you're, in fact, even Robinhood users might be paying more for a share of that stock
[01:11:04.520 --> 01:11:11.000]   than they should be because of this process. Citadel might in fact end up saying, well,
[01:11:11.000 --> 01:11:15.000]   the price for that stock is about 30 when it's really about 25 if you went some other way.
[01:11:15.000 --> 01:11:21.880]   So there's all sorts of problems. It does disadvantage less well-informed players.
[01:11:23.880 --> 01:11:28.120]   Well, I don't know. How is this supposed to remedy that?
[01:11:28.120 --> 01:11:33.800]   It makes it illegal. But it would also probably put Robinhood out of business.
[01:11:33.800 --> 01:11:43.560]   Or they would have to start charging for commissions for transactions. Brokers would need to develop
[01:11:43.560 --> 01:11:50.440]   new business models. Some major wholesalers told the times that the SEC had refused their input,
[01:11:50.440 --> 01:11:54.360]   but the big trading firms argue the reported fix would only hurt the little guys.
[01:11:54.360 --> 01:12:02.040]   Former SEC chief economist, S.P. Kotari, told Deal Book, the view is that payment for order flows
[01:12:02.040 --> 01:12:07.800]   somehow compromises market integrity. But the evidence shows retail investors are getting a good
[01:12:07.800 --> 01:12:15.320]   deal. Not sure about that. Not sure about that. This is a question.
[01:12:18.920 --> 01:12:23.880]   Going way back, you needed a street next to the wall where people traded stuff, and you had to
[01:12:23.880 --> 01:12:31.560]   have somebody there to do it. Hence the name Wall Street. But there's no reason you need a broker
[01:12:31.560 --> 01:12:36.840]   technologically today. Well, yeah, what does a broker do? You do because you have to have somebody
[01:12:36.840 --> 01:12:41.080]   who is licensed to buy and sell stocks. That's what I'm saying. Technologically.
[01:12:41.080 --> 01:12:43.400]   Oh, no. But that's how it works. But that's how it works. But that's how it works.
[01:12:43.400 --> 01:12:47.720]   But that's how it works. Well, oh, I see. Yeah, yeah, you're right. Just like you buy anything else.
[01:12:47.720 --> 01:12:49.720]   Wait a minute. Wait a minute. You don't need a middleman. What do you say?
[01:12:49.720 --> 01:12:55.320]   You don't need a middleman. Right now you do. Legally, you pay a lot of money to have a
[01:12:55.320 --> 01:12:59.800]   seat on the New York Stock Exchange so you can buy and sell stocks. But that's just an artificial
[01:12:59.800 --> 01:13:06.600]   construct. It'd be everything. And it'd be like if you needed an agent to sell your thing on eBay.
[01:13:06.600 --> 01:13:10.280]   No, you just go to eBay and you sell it directly. It's a marketplace.
[01:13:12.760 --> 01:13:20.600]   And God help me. NFTs. So there is a good point, which I guess Katari is making, which is people who
[01:13:20.600 --> 01:13:26.200]   couldn't or wouldn't buy stocks in the past because of commissions. And commissions used to be a lot
[01:13:26.200 --> 01:13:31.880]   higher than they are. All of this is pushed the commissions down anyway. And a lot of big brokers
[01:13:31.880 --> 01:13:36.120]   like Schwab now offer commission free trading as a result. Just to compete. I was just going to
[01:13:36.120 --> 01:13:41.720]   just mention that I don't know if commissions war is the actual problem. I think it's easier now
[01:13:41.720 --> 01:13:46.360]   because you get to buy portions of shares. Well, that's another that's that's something
[01:13:46.360 --> 01:13:51.880]   that yeah, they they do. That's an interesting one too. Right. Especially for shares of thousand
[01:13:51.880 --> 01:14:00.200]   dollars and you have a thousand dollar piece of I don't know if say Nike or whatever. And you
[01:14:00.200 --> 01:14:05.320]   average average Joe probably can't afford it, but they want a piece of that I and say, you know,
[01:14:05.320 --> 01:14:10.840]   let me send twenty dollars here and twenty dollars there. I'm honestly not. I mean, this is very
[01:14:10.840 --> 01:14:15.800]   elitist, but I'm not a big fan of people buying individual stocks. And it really comes down to
[01:14:15.800 --> 01:14:22.680]   that information disparity. You just agree with you as an individual. I know and we don't have the
[01:14:22.680 --> 01:14:29.320]   information that institutional history's have. And that's who you're competing with. And so I
[01:14:29.320 --> 01:14:33.640]   think your vote should look more into one. I'm not going to say because that would sound like
[01:14:33.640 --> 01:14:38.760]   I'm giving advice. Never mind. You can give advice. Just say, but I'm an idiot. So don't pay attention
[01:14:38.760 --> 01:14:43.880]   or something. That's what I say. Yeah, I think is more along the lines of looking at different
[01:14:43.880 --> 01:14:48.120]   funds. People look at it in next funds. Absolutely. Diversity. Yeah. You know,
[01:14:48.120 --> 01:14:53.960]   you know, I for for investing in your retirement, I love the target date funds.
[01:14:53.960 --> 01:14:59.080]   Those those those do a pretty good job. They rebalance your portfolios. You get older to lower
[01:14:59.080 --> 01:15:05.080]   risk and all of that. But in any event, you know, that's always information is the whole thing.
[01:15:06.120 --> 01:15:12.040]   Remember what a great book by Michael Lewis flash was a flash boy.
[01:15:12.040 --> 01:15:19.160]   Flash boys flash boys. It's just so brilliant. Yeah. And he talks about the the rush the
[01:15:19.160 --> 01:15:25.320]   race to create a fiber optic line from the Chicago exchange to the New York exchange. But
[01:15:25.320 --> 01:15:32.600]   but fiber optics and speed of light, right? But yeah, they were trying to create a pet with
[01:15:32.600 --> 01:15:39.960]   it completely straight line because a turn makes a little bit longer and a millisecond, a millionth
[01:15:39.960 --> 01:15:46.440]   of a second difference with computerized training can be the difference between winning and losing.
[01:15:46.440 --> 01:15:53.960]   So if you could get a completely straight, shortest point, but sure is this between two points
[01:15:53.960 --> 01:15:59.320]   from the Chicago board of exchange to the New York Stock Exchange. Or actually, it's not the
[01:15:59.320 --> 01:16:03.080]   New York Stock Exchange anymore. As Michael Lewis pointed out, some some place some windowless
[01:16:03.080 --> 01:16:09.000]   building in New Jersey. But if you can get a straight shot, you might have a millionth of a
[01:16:09.000 --> 01:16:14.200]   second advantage over somebody else, which is enough for you to win to make money. So the
[01:16:14.200 --> 01:16:17.960]   characters at the beginning of the book are just great. They're literally going to people who own
[01:16:17.960 --> 01:16:22.520]   property to say, can I dig a hole here and what it's worth to get the straightest line. Yeah,
[01:16:22.520 --> 01:16:28.120]   which is to say that the Bloomberg and Reuters and those companies do not sell content. They sell
[01:16:28.120 --> 01:16:35.480]   speed. Yes. And once once the former head of Reuters used to say that after the first three
[01:16:35.480 --> 01:16:42.440]   milliseconds, all of Reuters content is an aftermarket. And this also points out with something
[01:16:42.440 --> 01:16:49.240]   that I always have this debate that it isn't really about the quarterly report or no, you know,
[01:16:49.240 --> 01:16:55.000]   R&D or any of the any of the numbers that we are always talking about. The value of the stock
[01:16:55.000 --> 01:16:59.880]   really is what somebody will pay for it. So having knowledge about what people what price people
[01:16:59.880 --> 01:17:05.640]   are paying a little early, it's like knowing who's going to win the race a little bit early.
[01:17:05.640 --> 01:17:11.000]   You can lay a bet on that horse a millisecond before it crosses the line. No, no, no, no,
[01:17:11.000 --> 01:17:14.680]   because it already crossed the line a millisecond before anybody else knows across the line. That
[01:17:14.680 --> 01:17:21.160]   was the whole that was the whole premise of that Paul Newman, Robert Redford movie.
[01:17:23.400 --> 01:17:27.000]   What was it was a great con? It was a wire wire? Oh, right. Right. Right. Yeah.
[01:17:27.000 --> 01:17:32.120]   Is that they knew ahead of time who was going to win the race. So they lay a bet and then the
[01:17:32.120 --> 01:17:39.800]   waste results would come in a second later. And I want to. It was the same scam. So you you win
[01:17:39.800 --> 01:17:46.120]   in the stock market now, not sting the sting. You win in the stock market now, not because you've
[01:17:46.120 --> 01:17:52.440]   been reading the financials very carefully. I mean, you can. I mean, obviously, that's what
[01:17:52.440 --> 01:18:00.440]   the Wizard of Omaha does, but Warren Buffett, but most but really what's really happening is
[01:18:00.440 --> 01:18:05.560]   these hyper fast stock trading. And it's it's come done very, very quickly. And it's done on
[01:18:05.560 --> 01:18:10.440]   information. And the information the only information that really matters is what people are going to
[01:18:10.440 --> 01:18:19.640]   pay for this stock a second from now. Yeah, it's a bit speculative. Yeah, it's fascinating. But
[01:18:19.640 --> 01:18:24.440]   it's also why I think individuals, I tell I mean, I don't know. I'm not giving advice either. I'm
[01:18:24.440 --> 01:18:31.000]   an idiot, but but it's what I tell my kids because they have to listen to me is you can't win that
[01:18:31.000 --> 01:18:36.200]   one because you're you're not an institutional investor. You don't have a fiber optic line to
[01:18:36.200 --> 01:18:45.080]   the Chicago board of trade. Sorry, somebody doesn't like me. It doesn't like this. Stop spreading
[01:18:45.080 --> 01:18:51.640]   false infoses web 4338. I don't know what which particular false false. Yeah, tell me what's
[01:18:51.640 --> 01:18:57.080]   false and I'll tell everybody what you say. All transactions, including computer trades,
[01:18:57.080 --> 01:19:03.480]   have to go through a dealer. Didn't I say that? I think I said that. Yeah, he did. I was asking
[01:19:03.480 --> 01:19:08.680]   why that's the right theoretically, what that is to be the case, what value do they actually have?
[01:19:08.680 --> 01:19:13.400]   Yeah, but they extract value. The part of the point of this story is the middleman,
[01:19:13.400 --> 01:19:17.400]   the deal with the middleman are as always are extracting value more than they're at it.
[01:19:17.400 --> 01:19:23.240]   He says, you are misinformed. It's explicit in series nine and 63 broker exams. Okay.
[01:19:23.240 --> 01:19:29.960]   I think you're making it up now. Now I think you're making it up.
[01:19:32.680 --> 01:19:39.560]   Anyway, the SEC takes it seriously. They're about to, SEC's Gary Gensler is expected to
[01:19:39.560 --> 01:19:45.240]   preview new market rules about a year after shares of GameStop and others shot up in the meme
[01:19:45.240 --> 01:19:50.840]   stock training frenzy is not to make those illegal. It's to, and I knew when I launched this,
[01:19:50.840 --> 01:19:57.080]   that it was going to take a lot of explaining, but it's to stop this payment on for order flow.
[01:19:58.920 --> 01:20:05.160]   It is controversial because it does allow more people to get in the stock market,
[01:20:05.160 --> 01:20:12.440]   which I would submit is something that maybe should be phrased is allow more
[01:20:12.440 --> 01:20:18.360]   suckers to get in the stock market. It's something only the guys, the institutional guys want.
[01:20:18.360 --> 01:20:23.480]   Yeah, yeah, we want more suckers, more people and it pushes their wallet bigger.
[01:20:26.280 --> 01:20:31.560]   Let's see. Where are we time wise? Let's take a little break. Should we do a change log? Did you
[01:20:31.560 --> 01:20:37.000]   do? This has been we haven't gone anywhere. I know we have we are we are stuck in the mud.
[01:20:37.000 --> 01:20:41.960]   We're still in the top of the road section of the run. We will do a change log when we come back.
[01:20:41.960 --> 01:20:49.080]   And of course I have some nice TikTok things. Oh boy. Oh, I know you all look forward to
[01:20:49.080 --> 01:20:57.480]   our generous plus your heart. This episode brought to you by Melissa information, right?
[01:20:57.480 --> 01:21:01.800]   The quality of your data. That's the difference between winning and losing, not just in the stock
[01:21:01.800 --> 01:21:10.760]   market, but in business. Melissa says poor data quality can cost organizations an average of 15
[01:21:10.760 --> 01:21:16.040]   million dollars a year and the longer poor quality data stays in your system, the more losses you
[01:21:16.040 --> 01:21:22.200]   can accumulate. Why does poor data cost you? Well, let's say you're sending bills to the wrong address
[01:21:22.200 --> 01:21:27.880]   or five catalogs to the same address to ensure your business is successful. Your customer
[01:21:27.880 --> 01:21:34.440]   information has got to be accurate. Melissa is a leading provider of global data quality
[01:21:34.440 --> 01:21:38.760]   and address management solutions. And by the way, there's another side to getting good
[01:21:38.760 --> 01:21:43.880]   customer data. That's customer service. I mean, imagine you've got a phone call. You're dealing with
[01:21:43.880 --> 01:21:48.840]   a frustrated customer and then you address them with the wrong name or say, oh, you live in Florida,
[01:21:48.840 --> 01:21:54.200]   right? And they live in Washington and oh man, that can get awkward. Having the right information
[01:21:54.200 --> 01:22:00.600]   is pretty important. And for that, you need Melissa's identity solutions. Melissa's real time identity
[01:22:00.600 --> 01:22:08.680]   verification service includes ID identity and document verification, age authentication,
[01:22:08.680 --> 01:22:15.640]   and global watchlist screening to establish the identity of a customer or satisfy your compliance
[01:22:15.640 --> 01:22:21.560]   requirements, any money laundering, things like that KYC easily tailored the service to your specific
[01:22:21.560 --> 01:22:27.240]   signup process and risk management requirements to ensure fast onboarding or e-commerce checkout
[01:22:27.240 --> 01:22:33.960]   while protecting you against fraud. With Melissa, you reduce risk. You'll ensure compliance and
[01:22:33.960 --> 01:22:39.400]   you keep customers happy. Now that sounds like a win all around. Protect your data from decay,
[01:22:39.400 --> 01:22:47.960]   rot corruption with 2.1 billion, billion with a be clean, validated records. You'll be ensuring
[01:22:47.960 --> 01:22:53.720]   compliance and any money laundering politically exposed persons, the bank secrecy act. You could
[01:22:53.720 --> 01:22:59.000]   score and target customers with detailed demographic and firmographic data. It depends. You can complete
[01:22:59.000 --> 01:23:04.840]   customer records, add missing names, addresses, phone numbers, email addresses. And don't worry,
[01:23:04.840 --> 01:23:10.920]   your data is safe with Melissa. They undergo continuous independent security audits to make
[01:23:10.920 --> 01:23:15.400]   sure their security is good, their privacy is good. That's why they can tell you they're
[01:23:15.400 --> 01:23:22.120]   SOC 2 HIPAA and GDPR compliant. With Melissa, you can verify addresses, emails, phone numbers,
[01:23:22.120 --> 01:23:28.040]   names, and you can do it in real time. In over 240 countries and territories, you can do it at the
[01:23:28.040 --> 01:23:34.200]   point of entry. They have on-prem solutions. They have SaaS solutions. You can do batch address
[01:23:34.200 --> 01:23:39.240]   cleaning by just uploading a file to their secure FTP servers and downloading the process
[01:23:39.240 --> 01:23:45.640]   cleaned up list. You can do identity verification, geo-coding, convert addresses into latitude and
[01:23:45.640 --> 01:23:53.640]   longitude. You can remove 95% of bad email addresses from your database. And of course,
[01:23:53.640 --> 01:23:58.040]   you can deploy it any way that suits your needs, your business size, your budget.
[01:23:58.040 --> 01:24:05.000]   On-prem web service, secure FTP, software as a service, or Melissa's great API. They even have
[01:24:05.000 --> 01:24:10.440]   apps on iOS and Android, the lookups apps, that will let you search addresses, names, and more at
[01:24:10.440 --> 01:24:15.480]   your fingertips. So bottom lines to make sure your customer contact data is up to date.
[01:24:15.480 --> 01:24:20.760]   Trimalist is APIs in the developer portal. It's easy to log on, sign up, and start playing in the
[01:24:20.760 --> 01:24:32.120]   API sandbox 24/7. Get started today with 1000 records cleaned for free at Melissa.com/twit.
[01:24:32.120 --> 01:24:39.240]   That's Melissa.com/twit. We thank you so much for the support of this week in Google.
[01:24:39.240 --> 01:24:44.360]   Let's do the change. Let's throw everybody off. Let's just knock them off.
[01:24:44.360 --> 01:24:49.640]   Yeah, geez. Geez. Geez. Geez. Yes. It's time.
[01:24:49.640 --> 01:24:55.800]   How exciting. I'm going to sell this one. You're going to feel so good.
[01:24:55.800 --> 01:24:59.640]   For like, this is a return to the change law. It's even bigger deal.
[01:24:59.640 --> 01:25:03.640]   This is so exciting. Everything you're about to hear is going to change your life.
[01:25:03.640 --> 01:25:12.440]   Google Fi is expanding coverage on the Pixel with the Wi-Fi W Plus network. Remember Google Fi?
[01:25:13.160 --> 01:25:18.760]   I'm a Fi customer. Actually, this is meaningful to me. Fi always, as promised, was with the right
[01:25:18.760 --> 01:25:27.800]   hardware, your phone can use T-Mobile. Sprint, of course, that's now merged. Wi-Fi, U.S. Cellular.
[01:25:27.800 --> 01:25:34.520]   Now, there is something, this comes from Google's internal area, 120 incubator, called a Ryan
[01:25:34.520 --> 01:25:42.920]   Wi-Fi. If you are a venue with Wi-Fi, a coffee shop, a concert venue, a hotel,
[01:25:42.920 --> 01:25:49.720]   you can sell your Wi-Fi capacity to sell your networks. Google's calling this a W Plus network.
[01:25:49.720 --> 01:26:00.360]   And it is one more way that you can get bandwidth on your Google Fi phone. Google goes to businesses
[01:26:00.360 --> 01:26:06.200]   operating public areas, telling them you can get a new revenue stream for your existing network.
[01:26:06.200 --> 01:26:11.160]   There's no capture portal or anything. You just turn on a Ryan Wi-Fi monetization.
[01:26:11.160 --> 01:26:15.400]   Apparently, you don't even need a new router or new software. And then
[01:26:15.400 --> 01:26:23.800]   Google, your Google Fi phone will automatically connect to a Ryan as a Wi-Fi thing. So, I could
[01:26:23.800 --> 01:26:28.200]   walk into a coffee shop, not even get a pop-up that says, "Would you like to use our coffee shop?
[01:26:28.200 --> 01:26:31.880]   You don't need to know the password or anything." But the phone will know about it because they've
[01:26:31.880 --> 01:26:37.800]   signed up with a Ryan and your Fi phone will use it. I think that's a good idea. It competes
[01:26:37.800 --> 01:26:44.760]   with XFINities. Wi-Fi access points all over town thing. Cox does that. A few other cable companies.
[01:26:44.760 --> 01:26:51.560]   Beta number three for Android 13. I'm not touching it. Not going anywhere near it.
[01:26:51.560 --> 01:26:59.960]   Very happy with my Pixel 6 Plus on 12 platform stability. That is an important
[01:26:59.960 --> 01:27:04.840]   landmark in the development of Android 13, which probably will come out this fall.
[01:27:05.480 --> 01:27:12.920]   You can hear all about it. It's good to hear that they said that key word. Just stabilization.
[01:27:12.920 --> 01:27:17.720]   It's just going to be great and solid. People have to give me all of these bells and whistles.
[01:27:17.720 --> 01:27:24.280]   Just make it work. So, that forms stability. It's really more meaningful to developers.
[01:27:24.280 --> 01:27:30.200]   It means, "Okay, we're not going to add anything that you don't know about. This API is fixed.
[01:27:30.200 --> 01:27:35.000]   It's done." And so, now you can start writing your apps with confidence. You don't have to make
[01:27:35.000 --> 01:27:43.800]   any big changes. But it's also a big step forward for 13. Tablet users can now join the public beta
[01:27:43.800 --> 01:27:47.960]   as well. You have to have us one of these selected manufacturers.
[01:27:47.960 --> 01:27:54.040]   Have we talked about the tablet market before? Well, on the Android side of things, because it
[01:27:54.040 --> 01:28:00.360]   seems like iPad is just everywhere. When you hear a tablet, they never say an Android tablet is
[01:28:00.360 --> 01:28:10.360]   always iPad. Is this something that you should just let this go? Yeah. Because, I mean, yes,
[01:28:10.360 --> 01:28:18.840]   Samsung's are nice. But when people say tablet, tablet is almost like the way Xerox was synonymous
[01:28:18.840 --> 01:28:28.520]   with making photocopies. Yeah. Yes, I don't think, yes, you should not. Well, I'm prejudiced.
[01:28:28.520 --> 01:28:36.440]   I think iPad is a tablet that heads and shoulders above anything. I guess if you get the Samsung,
[01:28:36.440 --> 01:28:40.520]   that's a pretty good tablet. The problem isn't the Samsung. The hardware is great.
[01:28:40.520 --> 01:28:45.880]   The problem is the software in Android is just not good. Yeah. Yeah. That's what I'm saying.
[01:28:45.880 --> 01:28:50.040]   Should Google just let that go? Well, you know what? That's what they announced at I/O that they're
[01:28:50.040 --> 01:28:56.680]   "Oh, we're not going to make a tablet." No. Don't go crazy here. But we really think tablets are great
[01:28:56.680 --> 01:29:03.720]   on Android. And so Android 13 does have some things. Taskbars for tablets has some things that will
[01:29:03.720 --> 01:29:09.480]   make apps that are designed for a smaller screen scale better on a larger screen. That was one of
[01:29:09.480 --> 01:29:13.880]   the problems with tablets. A lot of Android apps would just be like a phone sized on that table.
[01:29:13.880 --> 01:29:19.160]   Yeah, a little pot, like a little tiny window there. Yeah. Yeah. So I think Google's in two years.
[01:29:19.160 --> 01:29:24.840]   Well, they're making noises that they really want to make this work. So, I don't know, put 13 on your
[01:29:24.840 --> 01:29:32.600]   tablet and see. I dare you. Again, my tablet that I have is not an Android tablet. Yeah.
[01:29:32.600 --> 01:29:38.200]   Jason Howell, the host of all that Android is our producer. He probably has an opinion on this.
[01:29:38.200 --> 01:29:43.400]   He says he's running 13. Are you running on a tablet though, Jason? He says it's fine.
[01:29:43.400 --> 01:29:50.040]   Okay, fine. It's a fine look at operating system.
[01:29:52.440 --> 01:29:59.320]   Android 12 beta ends with QPR3. So that means I will be automatically unenrolled.
[01:29:59.320 --> 01:30:05.240]   I'll be I'll be normal again, which is nice because, you know, people were saying, oh, the June,
[01:30:05.240 --> 01:30:11.640]   the June update is out for pixels. And I go and I realize, oh, I'm on an Android 12 beta.
[01:30:11.640 --> 01:30:20.520]   So I don't it doesn't that I'm not in the same cadence. So QPR3 and the June pixel feature drop
[01:30:20.520 --> 01:30:26.680]   launched today. You don't have to take any further actions. I won't. We are now like officially on
[01:30:26.680 --> 01:30:34.280]   just Android 12. And we don't have to do anything. After three months of testing,
[01:30:34.280 --> 01:30:39.880]   Android 12 QPR3 with the June security patches rolling out today. For those of you in the beta
[01:30:39.880 --> 01:30:46.600]   program, that means I'll get it tonight when I go home. And and now we'll all be 12.1 for reels.
[01:30:49.080 --> 01:30:56.920]   Okay. Unless you went to 12 L, right? Jason, that that I don't know. It's so confusing. This 12
[01:30:56.920 --> 01:31:04.680]   and 12 L thing. Jason says, what tablet I can't put it on tablet. Jason, go out and buy a Samsung
[01:31:04.680 --> 01:31:10.920]   tablet on my on my dime. They're cheap. Yeah. God, get lost. I ordered one when they announced it
[01:31:10.920 --> 01:31:18.920]   with the note or not the note, the S 22 Ultra. I bought an S 22 Ultra. And I thought I bought
[01:31:18.920 --> 01:31:24.840]   a Samsung Galaxy Note 8. Was it whatever it is? The 8? The new one? But I
[01:31:24.840 --> 01:31:28.440]   that nothing ever arrived. So I guess I didn't.
[01:31:28.440 --> 01:31:33.640]   Did you still account sir? I still be waiting. I wanted it best by that. I should probably
[01:31:33.640 --> 01:31:39.240]   log in shouldn't I? Oh, now I just remembered. You know, I do that sometimes I buy something and
[01:31:39.240 --> 01:31:46.360]   I forget. I just figure, well, they'll send it to me, right? When the time comes, it'll be a surprise.
[01:31:46.360 --> 01:31:50.760]   And that has happened to me, especially with like Kickstarter. I'll buy something.
[01:31:50.760 --> 01:31:59.640]   And then like a year later, I got a piece of luggage like this aluminum bag. I said, what is this?
[01:31:59.640 --> 01:32:03.000]   Oh, you ordered this a long time ago.
[01:32:03.000 --> 01:32:11.080]   To keep you signed in, we need to confirm it's you. I just logged in. What do you want? All right,
[01:32:11.080 --> 01:32:19.480]   I'll log in. Send me a verification code. He thought he ordered it best by I thought I did.
[01:32:19.480 --> 01:32:24.760]   You probably probably ordered it directly from the Samsung site or something instead.
[01:32:24.760 --> 01:32:33.000]   Dear, probably. But that's the first thing I come to my hand. Did I really buy it? Did they
[01:32:33.000 --> 01:32:38.120]   charge me for my email? Such a mess. Oh, yeah. Good. They did send me a can. My email is such a mess.
[01:32:38.680 --> 01:32:47.400]   Yeah, I can. I just I bought a Mac studio from a company in April and I never heard they charged
[01:32:47.400 --> 01:32:53.320]   me immediately $4,000. Never heard anything from them. I finally sent a note just the other day. I
[01:32:53.320 --> 01:33:01.320]   said, Hey, you know, remember that Mac I bought? Where the hell is it? I remember that Mac. Where
[01:33:01.320 --> 01:33:07.480]   the hell is it? And they said, Oh, yeah, we, you know, thanks for the money. But we never really,
[01:33:07.480 --> 01:33:14.440]   we never got it. So they said, You want your money back? I said, Yeah, I want to let those things
[01:33:14.440 --> 01:33:19.560]   so bad. I want my money back because you're not going to send me something. So I want my money back.
[01:33:19.560 --> 01:33:26.680]   So then they sent me a text message that said your money is back, but I haven't seen it. Oh, geez.
[01:33:27.480 --> 01:33:35.480]   So how would I know order status, right? Oh, no, that's from February 2020. I guess
[01:33:35.480 --> 01:33:41.640]   maybe I didn't order it. Dude, we're not from there. You order history,
[01:33:41.640 --> 01:33:46.920]   order history. They ain't no one. What did you supposedly order again? That when Samsung announced
[01:33:46.920 --> 01:33:52.120]   their new S 22, they have it. They asked, Well, can you search for S 22 in your email and see if you
[01:33:52.120 --> 01:33:58.440]   got an order confirmation? You're too reasonable and rational. I guess I could do that. Meanwhile,
[01:33:58.440 --> 01:34:04.440]   June's pixel feature drop while we move on through the sorry, I wasted your time going through my
[01:34:04.440 --> 01:34:11.720]   mail at a glance flashlight. What? And a doorbell alert and pocket operator music maker.
[01:34:11.720 --> 01:34:17.000]   You figure out what the hell that is because I don't have a nobody got time. So Nest doorbell
[01:34:17.000 --> 01:34:25.400]   video feed. Some of you have had this for a while. I do have a Nest hello doorbell. So I should.
[01:34:25.400 --> 01:34:31.560]   So I'll see that on my at a glance settings. When your torches on written by a bridge,
[01:34:31.560 --> 01:34:38.360]   when your torches on at a glance will prominently note that and let you quickly turn it off with a
[01:34:38.360 --> 01:34:44.680]   tap if the blinding light doesn't give you a hint. That's always one of the I enjoy telling
[01:34:44.680 --> 01:34:49.080]   somebody that their that their torch is on on their phone when they don't know it. I think it's a
[01:34:49.080 --> 01:34:55.480]   well, polite things you can do. Now they've taken this away from me. So this is a common thing like
[01:34:55.480 --> 01:35:01.480]   people are walking around for me. People are walking around like the big bright light in their pocket.
[01:35:01.480 --> 01:35:08.920]   And they don't know that a lot. I have to when I take the dogs out in the evenings,
[01:35:08.920 --> 01:35:13.240]   I usually use that torch. Well, I'll kill you. And I totally forget about it. Yeah,
[01:35:13.240 --> 01:35:18.280]   totally forget about it. So what do you go up to them and you tap on the show? Excuse me,
[01:35:18.280 --> 01:35:23.480]   sir, your torches on. And they're always grateful. Thank you so very much. Because I say it nicely,
[01:35:23.480 --> 01:35:28.120]   though, like you're an idiot. Hey, don't do that. Don't do that. You know what? You're still gonna
[01:35:28.120 --> 01:35:33.960]   have to do that because how are they going to tell you your torches on with the at a glance settings.
[01:35:33.960 --> 01:35:38.520]   If you're looking at your phone, you probably know your light is on. It's no, you don't. No,
[01:35:38.520 --> 01:35:43.080]   I see people know people working on it. There it is. You're looking at your screen. You're
[01:35:43.080 --> 01:35:48.040]   not looking at the right exactly behind it. You can't see the glow behind it. You're looking at your
[01:35:48.040 --> 01:35:53.800]   screen. Okay. All right. All right. So now you're going to have a notification that says,
[01:35:53.800 --> 01:36:00.440]   Hey, dummy, you're the flashlight son. And there will be dummy. I'm in there will be air
[01:36:00.440 --> 01:36:08.280]   quality information decks warnings for your area. So it'll say, Hey, if you notice, it's hard to
[01:36:08.280 --> 01:36:13.320]   breathe. Well, you're right. And then this pocket operator, this is actually very cool. I do know
[01:36:13.320 --> 01:36:20.200]   what this pocket operator is. I was just mocking. Do you know a company called Teenage Engineering?
[01:36:20.200 --> 01:36:28.280]   I actually bought one of these and make little pocket synthesizers that are so cute and so much
[01:36:28.280 --> 01:36:35.240]   fun. I didn't I give mine to you, Jason? Do you have my pocket operator? He's a smooth operator.
[01:36:35.880 --> 01:36:39.720]   I didn't give it to you. Who did I give? I gave it to somebody that the cutest little thing.
[01:36:39.720 --> 01:36:44.760]   Dude, you can't find his pocket. Well, the reason is I'm not an absolutely order.
[01:36:44.760 --> 01:36:50.040]   I thought this was really cute, but I know I'm not a musician. I shouldn't have one of these things.
[01:36:50.040 --> 01:36:55.880]   Anyway, they have now a software based pocket operator, music maker, you can do on your Android
[01:36:55.880 --> 01:37:01.880]   phone. I'm sure you do this on all about Android. Jason, I reviewed it. Nice.
[01:37:03.560 --> 01:37:08.360]   So pocket operators, very cool. Here's what it looks like. So it's just really a little kind of
[01:37:08.360 --> 01:37:12.600]   fun little synthesizer. You don't have to be an instrument, a musician to do it or anything.
[01:37:12.600 --> 01:37:21.160]   Google Wallet now will support vaccine cards, digital vaccine cards. There's a conversation mode
[01:37:21.160 --> 01:37:27.000]   in sound amplifier, which is actually kind of nice. You could use it as kind of a hearing aid,
[01:37:27.000 --> 01:37:32.600]   put the phone on the desk in between you, have your headphones on, and it's going to know to
[01:37:32.600 --> 01:37:38.680]   amplify just the voice and remove the background noise. You want to point your camera at the person
[01:37:38.680 --> 01:37:46.520]   you want to talk to. And a new trio of curated culture wallpapers from Jan Bostard.
[01:37:46.520 --> 01:37:54.360]   It's pronounced Bastard. Jan Bastard celebrating Pride Month.
[01:37:55.880 --> 01:38:04.040]   All right. He's French. He was born in Zadagosa, Spain. He now is in Ren, France. He's pronounced
[01:38:04.040 --> 01:38:10.200]   Bastard. Bastard. Android Auto for phone screens officially dying for everyone?
[01:38:10.200 --> 01:38:16.600]   It was never made any sense. Yeah. I mean, you standard auto still around when I get in the car,
[01:38:16.600 --> 01:38:20.040]   I have Android Auto on my car screen. But why did you have Android Auto on your phone? Like,
[01:38:20.040 --> 01:38:24.200]   you're going to hold your phone ear while you're driving. But well, if you didn't have, if you had
[01:38:24.200 --> 01:38:29.320]   a car that wasn't available for you, put it on, all it really did was take features away because
[01:38:29.320 --> 01:38:34.760]   you're driving for you. Right. Right. Which it should. Anyway, no, apparently nobody used it.
[01:38:34.760 --> 01:38:39.080]   And now you'll get a little notice that says it's going to stop working soon. So it is. Hey,
[01:38:39.080 --> 01:38:42.920]   it's Google. We kill things. We kill things. We know how we know how to do it.
[01:38:42.920 --> 01:38:51.000]   Change log includes things going away too. $100 off on the Pixel 6 Pro. It's the first direct
[01:38:51.000 --> 01:38:55.080]   discount in the US Google store. If you've been wanting to buy one of those, I know you had,
[01:38:55.080 --> 01:38:58.040]   is it settled down for you? And are you still having problems with it?
[01:38:58.040 --> 01:39:06.040]   It's not as much, but it's way better than what it used to be. And the blue to the camera toggle
[01:39:06.040 --> 01:39:11.480]   off here and there. That's blue to my Bluetooth. I really do. But yeah, it's way better than what
[01:39:11.480 --> 01:39:16.440]   the pictures are great. That was within like the, I think that was the March.
[01:39:17.800 --> 01:39:23.160]   That was a big update that fixed the last stuff. Yeah. And do you ever take pictures with your
[01:39:23.160 --> 01:39:30.120]   Pixel 6? Oh, yeah. Yeah. Yeah. It's really good. The camera's fine. Oh, it's totally fine. Yeah.
[01:39:30.120 --> 01:39:34.920]   How do you like yours, Jeff? Do you are your pictures? I like it. In fact, in fact, I,
[01:39:34.920 --> 01:39:39.320]   we have a family of groundhogs living under our garden shed.
[01:39:39.320 --> 01:39:46.520]   I looked over and I'm far away sitting on the deck working. Yes, I was working on the deck.
[01:39:47.320 --> 01:39:51.080]   And I get up to go take a picture and get closer and they skitter underneath.
[01:39:51.080 --> 01:39:56.840]   So I'm going to be far, far away and I use the zoom in and I get that right now. Yeah.
[01:39:56.840 --> 01:40:03.000]   Yeah, it works well. Very nice. And that's the Google change log.
[01:40:03.000 --> 01:40:13.080]   Google paying $100 million to Illinois residents. Illinois is one of the few states in the nation
[01:40:13.080 --> 01:40:19.000]   to have an anti-biometrics law, the Illinois Biometric Information Privacy Act.
[01:40:19.000 --> 01:40:25.960]   Google Photos allegedly violated it with its face recognition. And yeah, they've agreed to pay
[01:40:25.960 --> 01:40:32.360]   $100 million to settle a class action lawsuit. It was the face grouping. Two dollars a person.
[01:40:32.360 --> 01:40:37.640]   Yeah, probably. You don't get, you know, the lawyers. I think it's 300 bucks. Yeah.
[01:40:37.640 --> 01:40:43.960]   Oh, that's not bad 300. It's pretty good. Oh, really? Yeah. It alleges that the face
[01:40:43.960 --> 01:40:48.440]   grouping tool which automatically identifies your face in photos and videos uploaded to photos,
[01:40:48.440 --> 01:40:57.080]   violates BIPA. I can see why Google would do that though, right? To let you know there's a,
[01:40:57.080 --> 01:41:03.320]   there's a picture of you up there. If you are or were an Illinois resident who appeared in a photo
[01:41:03.320 --> 01:41:11.080]   or video on Google Photos between May 1st, 2015 and April 25th, 2022, you have until September 24th
[01:41:11.080 --> 01:41:16.760]   of this year to submit a claim on the settlement's website. You'll get somewhere, as Jeff said,
[01:41:16.760 --> 01:41:21.720]   between $200 and $400 depending on court related expenses and how many people file a claim.
[01:41:21.720 --> 01:41:28.040]   So there's a big pool. I probably shouldn't be mentioning this because, you know, you're not
[01:41:28.040 --> 01:41:33.240]   going to get as much. If the pool has a lot of members. If your wild reach, yes, you're going to get
[01:41:33.240 --> 01:41:36.280]   millions more to apply for it. Well, I don't live in Illinois.
[01:41:36.280 --> 01:41:40.760]   And I presume that Google isn't doing it anymore. So there you go.
[01:41:40.760 --> 01:41:47.800]   Why, Jeff, why should we care about this? The Taco Bell of the future?
[01:41:47.800 --> 01:41:54.040]   I didn't put this one in there. Oh, but it's kind of a brutalist, a brutalist Taco Bell,
[01:41:54.040 --> 01:42:01.880]   right? And you don't even see anybody, the food gets lowered in the manic bank.
[01:42:01.880 --> 01:42:09.880]   I like that. Oh, is it? Is it? Yeah, that was just like, you know, like the drive through, right?
[01:42:09.880 --> 01:42:16.360]   Yes. Yeah, you order you have a QR code, you drive up. For all we know, there's robots upstairs
[01:42:16.360 --> 01:42:21.400]   making the food. You never see a human. That's what happens when you just said, I said no ice.
[01:42:21.400 --> 01:42:27.880]   This is in Minnesota and Brooklyn Park. It's all QR code focused.
[01:42:27.880 --> 01:42:33.080]   So I'm unhappy with Taco Bell right now. Why? Because they got rid of lemonade and they have
[01:42:33.080 --> 01:42:40.440]   like strawberry lemonade and it's trically sweet and awful. So my normal order was two bean burritos,
[01:42:40.440 --> 01:42:49.880]   no one in the lemonade. Here is Taco Bell. Here's, here's sliced alone, pulling up to a Taco Bell
[01:42:49.880 --> 01:42:57.320]   in the future. He did not realize that Taco Bell was the only restaurant to survive the franchise
[01:42:57.320 --> 01:43:01.400]   once. So? So now all restaurants are Taco Bell.
[01:43:01.400 --> 01:43:09.480]   All restaurants are Taco Bell. It looks just like the one in Minnesota. Yeah, exactly.
[01:43:09.480 --> 01:43:16.040]   All restaurants are Taco Bell and all doors open sideways.
[01:43:23.080 --> 01:43:29.080]   And the piano guy sings the Jolly Green Giant song. So is the, I never saw this movie is the
[01:43:29.080 --> 01:43:33.400]   premise that I did best for the most known as traveling in time and he entered the future.
[01:43:33.400 --> 01:43:40.680]   Oh yeah. Oh, there you go. That by the way, that groundbreaking new Taco Bell location
[01:43:40.680 --> 01:43:46.840]   will be opening tomorrow. See, we're right on top of the news here.
[01:43:46.840 --> 01:43:49.960]   Nice. That works. Actually it opened yesterday.
[01:43:50.760 --> 01:43:57.240]   No, well, okay. Cows close enough for us. All right. I got one I love because you had,
[01:43:57.240 --> 01:44:03.480]   you had two dolly stories in here, but the one I really like is a thread of, of Kermit the Frog
[01:44:03.480 --> 01:44:09.160]   in every movie. What is explained, dolly? What is dolly? dolly is artificial intelligence where
[01:44:09.160 --> 01:44:13.480]   you tell it to draw a picture of something and it will do that. And it may be something
[01:44:13.480 --> 01:44:17.880]   that's more, maybe something that will give you nightmares tonight. But you can have more,
[01:44:17.880 --> 01:44:24.040]   it's getting smarter and smarter. So if you said, I want to see Kermit the Frog in Blade Runner 2049,
[01:44:24.040 --> 01:44:27.400]   you might get something like this. Keep going through this thread. It's amazing.
[01:44:27.400 --> 01:44:32.520]   Wow. If you said Kermit the Frog in the Matrix, you might get something like it.
[01:44:32.520 --> 01:44:37.080]   It kind of looks like a teenage mutant Ninja Turtle now. Kermit the Frog and Spirited Away
[01:44:37.080 --> 01:44:42.680]   2001. He's got a big pot belly. Kermit the Frog and Star Wars.
[01:44:42.680 --> 01:44:50.840]   This is perfect, right? Yeah. Or yeah. Yeah. Dolly, you're good. Avatar the Last Airbender.
[01:44:50.840 --> 01:44:55.240]   Just on to just on to Wally. Wally from Dolly.
[01:44:55.240 --> 01:44:59.960]   It's the Princess Kaguya. I'm talking about you in the community.
[01:44:59.960 --> 01:45:06.680]   Wow. Now, usually you though, you have to keep trying until you get one that you really like,
[01:45:06.680 --> 01:45:11.400]   right? Oh, exactly. In the family guy, there's Kermit. This is good.
[01:45:11.960 --> 01:45:16.680]   This is Ryan Budapest Hotel. So I'm sorry if you're listening and you can't see these, but
[01:45:16.680 --> 01:45:23.560]   what can I say? I don't know. Just look for Dolly Kermit the Frog. You probably can find it.
[01:45:23.560 --> 01:45:29.240]   It's a Twitter thread. Yeah. Dolly's kind of cool. It is.
[01:45:29.240 --> 01:45:37.160]   It is. Yeah. It's kind of cool. Mad Max. Yeah. These are really good.
[01:45:37.160 --> 01:45:44.840]   I don't understand how it knows the dark night. Wow. Will he walk on the chocolate factory?
[01:45:44.840 --> 01:45:52.280]   I like what it's doing to the eyes. Pan's labyrinth. Yeah. It's like what you did to yourself
[01:45:52.280 --> 01:45:59.800]   with me last time. Yeah. This is better than a Snapchat filter. Kermit the Frog in the office.
[01:45:59.800 --> 01:46:06.440]   Very cool. Yeah. So good news for teenagers in California.
[01:46:06.440 --> 01:46:16.840]   The state of California has made a law. It goes into effect July 1st that public high schools can
[01:46:16.840 --> 01:46:23.320]   start no earlier than 8.30 in the morning and middle schools no earlier than 8 a.m. It's long
[01:46:23.320 --> 01:46:28.840]   been observed that teenagers need to sleep more and their sleep cycles are shifted.
[01:46:28.840 --> 01:46:33.080]   It makes perfect sense. When I was a teenager I'd go to bed at one every night and want to sleep
[01:46:33.080 --> 01:46:39.720]   till 11, 9 or 10, 11. You have teenage boys and I think as a teenage girl living with you too.
[01:46:39.720 --> 01:46:47.720]   Yes. Yes. But dude they are already like in school for an hour a day. It's awful.
[01:46:47.720 --> 01:46:53.720]   Why even bother? Well the hours should start later.
[01:46:54.760 --> 01:46:59.960]   I tell them all the time they have it so good. They're never in class. Fortunately they're doing
[01:46:59.960 --> 01:47:06.280]   well with their grades. So they're still-- I your father used to have to walk to school 40 miles
[01:47:06.280 --> 01:47:11.640]   in the snow. So they're uphill and all the way and uphill coming home. Are they still zooming?
[01:47:11.640 --> 01:47:18.920]   No sir. No sir. They were-- They do go in a class. Okay. But school is out now. School
[01:47:18.920 --> 01:47:23.880]   is in our suite. If you were unlucky enough to take zero period in, because your boys were
[01:47:23.880 --> 01:47:31.560]   athletes, I bet you they did, you got to go in like at 7 a.m. Right? They get-- Well that's the
[01:47:31.560 --> 01:47:39.560]   thing. They get there I believe it's eight o'clock and it starts at 8.15 or some crazy time like that.
[01:47:39.560 --> 01:47:45.400]   But then there's other days that it starts later. Oh. 8.30. Well and I'm like good news.
[01:47:45.400 --> 01:47:49.640]   Why are y'all starting so late? It's going to-- You can't start any earlier than 8.30 starting
[01:47:49.640 --> 01:47:55.080]   July 1st. And then they're done by 11 o'clock. I think that's really good. Really good. Done for
[01:47:55.080 --> 01:47:59.880]   the day by 11 o'clock. Well, all right. They have a weird sketch. That's not normal. They have some
[01:47:59.880 --> 01:48:05.960]   weird-- They're working. They're working the schedule or something. Time for a digital detox
[01:48:05.960 --> 01:48:13.080]   friends. According to Axios, Jeff calls this moral panic. Of course. How did you know I did that?
[01:48:13.080 --> 01:48:17.800]   How did you know I put that in there? Deep down you know the truth. You are hopelessly addicted to
[01:48:17.800 --> 01:48:24.520]   the phone or iPad or computer. Computer writes Erica Pandy in Axios. You're reading the computer.
[01:48:24.520 --> 01:48:29.480]   You're reading this on. It's like puffing three packs of cigarettes in the car. Windows up. Kids
[01:48:29.480 --> 01:48:35.480]   jamming back. You know it's not great for you or them. Time for a digital detox. Just stop Axios.
[01:48:35.480 --> 01:48:41.800]   Stop. You're an-- And by the way, you're an online service. So stop. Just stop. Stop.
[01:48:41.800 --> 01:48:49.960]   Stop. Click bait. There is a-- There are a lot of people going around making money going on TV
[01:48:49.960 --> 01:48:56.840]   shows saying, you know, there's stuff's bad for you and your kids. Oh yeah. A lot of-- Not a moral
[01:48:56.840 --> 01:49:02.360]   panic entrepreneur is their fault. Oh, that's a-- You made that up just now. No, I didn't. No,
[01:49:02.360 --> 01:49:09.080]   it's a-- It's a-- It's a-- Okay. Yeah. Okay. But there is some evidence that too much screen time's
[01:49:09.080 --> 01:49:17.000]   not good for you. Well, again, I just-- What's her name? I'm having a liking on her name. Dana Boyd?
[01:49:17.000 --> 01:49:23.880]   No, no, no. John Donovan? No. Wait a minute here. No. She's a journalist. She was the Wall Street
[01:49:23.880 --> 01:49:29.480]   Journal. And half away? No, she started the thing to do a general-- A man of a world in tech and Craig
[01:49:29.480 --> 01:49:35.000]   Newmark funded her and I should know her name. But anyway, she just did a piece last week. Had he
[01:49:35.000 --> 01:49:45.640]   her? Oh, stop. Craig Newmark? Well played, jammer bee. She just did a piece last week saying,
[01:49:45.640 --> 01:49:53.000]   I thought I said this earlier on the show, that-- Well, Oops, the research said that the problem was
[01:49:53.000 --> 01:50:00.200]   time spent on screens and that's not the problem and it's really the activities that may be a problem
[01:50:00.200 --> 01:50:05.000]   and all the research has to start all over again now. You would-- You would-- You would probably
[01:50:05.000 --> 01:50:10.920]   stipulate this one. A Baylor University study found that screen time is ruining relationships
[01:50:10.920 --> 01:50:17.880]   as one partner feels phone snubbed by the other. We've all been in that situation. You're at the
[01:50:17.880 --> 01:50:23.640]   table, you're having a nice dinner, maybe you went to a fancy restaurant and your wife-- I think I put
[01:50:23.640 --> 01:50:28.680]   that in last week. And your wife bursts into flame. No. And your-- They call it "fubby." And your partner
[01:50:28.680 --> 01:50:34.840]   is-- is "fubbing"? Fubbing. Phone snubbing. Fubbing. Fubbing. Fubbing. They're looking at the phone
[01:50:34.840 --> 01:50:39.640]   all the time or maybe they're taking pictures for their Instagram feed. Or maybe your wife as
[01:50:39.640 --> 01:50:45.640]   happens with me is that, hey look that up for you. That happens to me all the time. Actually,
[01:50:45.640 --> 01:50:51.880]   I say to Lisa, would you look that up for me? Yeah, say it. There's a restaurant in the East
[01:50:51.880 --> 01:50:56.760]   Village of Manhattan that has boxes for you to stash your phones during the meal. Oh, oh, just screw me.
[01:50:56.760 --> 01:51:07.880]   Pay attention to your own lives and leave us alone, nanny. Sushi lounge in Hoboken, New Jersey. I
[01:51:07.880 --> 01:51:14.360]   can't imagine going to Hoboken for sushi, but okay, tried reconnect Tuesdays which gave customers 20
[01:51:14.360 --> 01:51:19.800]   percent off if they kept their phones locked away in a box for dinner. Anything to get people to go
[01:51:19.800 --> 01:51:23.880]   and see if you go to Hoboken. What difference is it to you sushi guys? Yeah, really? Do I eat
[01:51:23.880 --> 01:51:30.760]   your fish or not? And by the way, it takes a long time at a good sushi place for the sushi to arrive.
[01:51:30.760 --> 01:51:36.760]   So what are you going to do? They got to make it. I get the printings, but yeah, that's none of
[01:51:36.760 --> 01:51:43.880]   their business. That's obnoxious, yeah. This is a silly, silly story. But it really is. Yeah. That's
[01:51:43.880 --> 01:51:50.680]   all about balance. That's the thing that no one seems to print. It's just have some balance. Have
[01:51:50.680 --> 01:51:56.200]   yourself some screen time. Have yourself away from the screen. They all just say, put the phone
[01:51:56.200 --> 01:52:04.200]   down. Get away from the screens. Do you remember that Twitter survey you had us do where it was
[01:52:04.200 --> 01:52:09.480]   tell you this world leaders, you know, he's a world leader, but he's saying stuff that's not true.
[01:52:09.480 --> 01:52:16.840]   Should you ban him? Remember that? And my gut feeling about it was Twitter said, oh, we want to get
[01:52:16.840 --> 01:52:22.120]   your advice on what how to deal with this so we can change our policy for world leaders. But my gut
[01:52:22.120 --> 01:52:26.360]   was it was more Twitter saying, see, this is so hard. You can't really blame us.
[01:52:26.360 --> 01:52:35.480]   Education is we want to think. Well, it turns out they got 49,000 people taking that survey.
[01:52:35.480 --> 01:52:42.840]   They had said, you know, we're going to take this feedback under advisement more than a year since
[01:52:42.840 --> 01:52:51.480]   they announced the survey. They have done nothing. Shocking, well, right now, let's give them a little
[01:52:51.480 --> 01:52:56.360]   a little bit of slack because they're busy. Yeah, they said consideration. They said consideration.
[01:52:56.360 --> 01:53:02.600]   Yeah. Twitter spokesperson Trenton Kennedy would not comment whether Elon Musk's pending
[01:53:02.600 --> 01:53:08.600]   acquisition has had an effect on efforts to revamp the world leaders policy. But he said the company
[01:53:08.600 --> 01:53:13.480]   is comment, right? Well, they're working on it. He says they're still distilling the results of the
[01:53:13.480 --> 01:53:19.960]   survey. He ain't getting tequila, buddy. No matter how much he distill it and considering next steps
[01:53:19.960 --> 01:53:26.200]   during this process, we've also engaged experts, including NGOs, governments, academics,
[01:53:26.200 --> 01:53:31.800]   and civil society to ensure we're hearing as many diverse and thoughtful perspectives as possible.
[01:53:31.800 --> 01:53:34.920]   Where do you go to get civil society? They have a phone number.
[01:53:34.920 --> 01:53:40.840]   What does he say? Lots of people will claim to be representing civil society.
[01:53:40.840 --> 01:53:43.800]   Really? Tons of organizations. Tons of organizations.
[01:53:43.800 --> 01:53:49.160]   But where do they get off? I represent society. Yeah.
[01:53:49.160 --> 01:53:55.240]   How do you? I mean, well, you go to a whole bunch of NGOs. Like if you want to find out what's
[01:53:55.240 --> 01:53:57.320]   going on, then I understand it. Right. So go to the right.
[01:53:57.320 --> 01:54:04.440]   Watch academics. But who do you go to get civil society input? The civil society incorporated?
[01:54:04.440 --> 01:54:09.320]   Pretty much. Yeah. Okay. More civil society entrepreneurs. Yeah. Okay.
[01:54:09.320 --> 01:54:16.920]   Civil society incorporated. Anyway, that's they're not going to do anything.
[01:54:16.920 --> 01:54:23.480]   But they did make us do the survey. And we did it. And it was fun and it was difficult and it was
[01:54:23.480 --> 01:54:31.560]   educational. It showed you how I do this, right? Nothing's first phone will come out July 12th.
[01:54:31.560 --> 01:54:38.680]   I'm sure Jason and company talked about this yesterday on all about Android. So Carl Pay,
[01:54:38.680 --> 01:54:47.480]   who was the founder of OnePlus and kind of famous marketing nutball, but made some pretty darn good
[01:54:47.480 --> 01:54:53.000]   phones at his time. He left one plus and he started one plus went and merged with its parent company
[01:54:53.000 --> 01:55:02.520]   Oppo. And he started a new company called Nothing. Okay. We weren't really sure what nothing was up
[01:55:02.520 --> 01:55:08.760]   to, but it turns out nothing is going to release a phone to nothing phone. It's our first smartphone
[01:55:08.760 --> 01:55:13.160]   and our most important product. Nothing said in its announcement. The real start of Nothing's
[01:55:13.160 --> 01:55:21.560]   journey to make tech fun again and an invitation to unlearn everything the industry has taught us.
[01:55:21.560 --> 01:55:29.560]   Have we learned nothing? The phone, the phone, it was actually, they were showing it off at Mobile
[01:55:29.560 --> 01:55:35.000]   World Congress. So we kind of had a thought they might be doing this. Phone will be powered by
[01:55:35.000 --> 01:55:41.400]   Qualcomm, a Snapdragon. It will run nothing. OS very lightweight. A modified version of Android
[01:55:41.400 --> 01:55:47.480]   that company says captures the best features of the OS and distills it to just the essentials.
[01:55:47.480 --> 01:55:51.640]   Essential. Wasn't that another phone company? That was another phone. Yeah, they went out of
[01:55:51.640 --> 01:55:57.160]   business. Andy Rubin's essential. Oh yeah. The platform sounds a lot like that by the way. Andy
[01:55:57.160 --> 01:56:03.000]   Rubin leaves Google. He's the guy invented Android kind of startup company. This is going to be so
[01:56:03.000 --> 01:56:11.080]   exciting. I bought an essential phone. Yep. That's it. The platform's parachute though. Yeah.
[01:56:11.240 --> 01:56:16.920]   Oh, he did all right. Yeah. The platform's interface will feature bespoke fonts, colors,
[01:56:16.920 --> 01:56:22.360]   design elements and sounds as well. Sounds like they got Johnny I've under the hood there.
[01:56:22.360 --> 01:56:25.960]   Live event in London, live streaming the website. You know what? I,
[01:56:25.960 --> 01:56:31.880]   Jerry's still out. Could be great. It just worries me. It reminds me a lot of the essential
[01:56:31.880 --> 01:56:35.320]   phone, which I did buy. Didn't I give it to you? And who did I give that to?
[01:56:36.280 --> 01:56:46.200]   No, somebody. Not me, sir. Yeah. I should mention passkey real quickly. This is something Apple
[01:56:46.200 --> 01:56:53.480]   talked about Monday on its WWDC event, making it a complete hat trick because Microsoft's been
[01:56:53.480 --> 01:57:00.280]   talking about it and Google's been talking about it. This will kill the password. Hallelujah.
[01:57:01.400 --> 01:57:09.080]   Have come with iOS 16 and macOS Ventura. The idea is that you will log in to your phone
[01:57:09.080 --> 01:57:14.760]   proving you are you. And then from then on, whenever you go to a website, it'll just say,
[01:57:14.760 --> 01:57:20.440]   oh, hi, Leo, and let you write in no more passwords. It's more secure. It's fishing proof.
[01:57:20.440 --> 01:57:25.160]   Because your phone is linked to your computer. Yeah. Well, because also your phone
[01:57:25.160 --> 01:57:30.600]   has fingerprint or face ID. And so it really is using biometrics to a certain
[01:57:30.600 --> 01:57:35.160]   ascertain that you are you. And if somebody steals your phone, they can't unlock it.
[01:57:35.160 --> 01:57:39.160]   Right. That's the theories that well, they can't even unlock it.
[01:57:39.160 --> 01:57:49.000]   It's a new digital key tied to your biometrics. To create a passkey, use touch ID or face ID to
[01:57:49.000 --> 01:57:55.480]   authenticate on a website and you're done. And from then on, when you log into the site, again,
[01:57:55.480 --> 01:58:00.840]   pass keys allow you to prove who you are by using your biometrics face ID fingerprint.
[01:58:00.840 --> 01:58:06.120]   You don't have to type in a passphrase. This is this is basically huge.
[01:58:06.120 --> 01:58:13.880]   I guess if if you try to use your your fingerprint on the phone so many times and it fails to read
[01:58:13.880 --> 01:58:19.800]   it, it usually forces you to put in your pass phrase. Yeah. Right. So then you would have to use
[01:58:19.800 --> 01:58:24.200]   a passphrase. So if you have to do that, I guess there's some signal that says, okay,
[01:58:24.200 --> 01:58:28.440]   this phone was a lot, but it wasn't unlocked with biometrics. No, I don't know. No, no, no, no.
[01:58:28.440 --> 01:58:32.920]   If you can unlock it, I'm sure that that counts. It's okay. I was curious. But what
[01:58:32.920 --> 01:58:37.480]   happens, you go to that site, it then says, let's let's see you. Oh, yeah, good. That's you.
[01:58:37.480 --> 01:58:42.120]   So you're still going to still going to do the biometrics each time. It sounds like I got to do
[01:58:42.120 --> 01:58:47.640]   it. See, Gibson raised the issue. Oh, well, that's all well and good. But what will happen if you
[01:58:47.640 --> 01:58:51.320]   decide I don't want to use a iPhone, I want to use an injury phone. Can you export that or do
[01:58:51.320 --> 01:58:58.760]   you have to start over? Apple's, I'm told by one of our listeners that Apple did address this
[01:58:58.760 --> 01:59:05.720]   at WWDC later yesterday and said there will be a way to export your pass keys from your iCloud,
[01:59:05.720 --> 01:59:11.160]   a store in iCloud. So if you can export it and import it somewhere else, and it is an industry
[01:59:11.160 --> 01:59:15.960]   wide standards, the Fido Alliance. So that may be the most important thing Apple announced on
[01:59:15.960 --> 01:59:21.240]   Monday. I mean, they was just in passing, but that's huge, right? Was everything to stop Google
[01:59:21.240 --> 01:59:25.640]   Landroid from doing the same thing? No, Google's already said they're going to do it. And Microsoft
[01:59:25.640 --> 01:59:31.240]   has said they're going to do it. So you got the big three. Oh, that's why it's a big deal. Yeah.
[01:59:31.240 --> 01:59:41.160]   Yeah. Yeah. Yeah. Let's see. Good article in Tech Dirt today about the new mayor, your new mayor.
[01:59:41.160 --> 01:59:44.280]   Well, it's not your mayor, is he? Well, he kind of is. You work in
[01:59:44.280 --> 01:59:49.240]   a city. Yes, he is because I'm a city employee. So yeah, Eric Adams, Mayor of New York City,
[01:59:49.240 --> 01:59:54.040]   has paused the city's affordable broadband plan.
[01:59:54.040 --> 02:00:02.360]   They had planned the city had done a lot of research. They had planned to spend $2.1 billion
[02:00:02.360 --> 02:00:09.000]   to make sure everybody in New York had access, inexpensive access to high-speed internet,
[02:00:09.000 --> 02:00:16.040]   saving on average a customer of $40 a month. It would expand internet access to 1.2 million households
[02:00:16.040 --> 02:00:24.600]   in New York City. Carl Bodie writing in Tech Dirt makes the probable accurate assumption that it was
[02:00:24.600 --> 02:00:30.840]   the phone companies like Verizon who got to the city and said, "Oh, you know, you don't want to
[02:00:30.840 --> 02:00:35.240]   compete with us, do you? That's why that's the argument against all municipal Wi-Fi." Yeah,
[02:00:35.240 --> 02:00:38.360]   Philadelphia, whether that year ago. You don't want to compete with us, do you?
[02:00:38.360 --> 02:00:45.880]   Verizon, of course, has not been a very good incumbent in New York City.
[02:00:45.880 --> 02:00:52.120]   There are stories supposedly the last pay phone was hauled out of the street in New York last week.
[02:00:52.120 --> 02:00:54.520]   Yeah, but then it turns out there's more pay phones still around.
[02:00:54.520 --> 02:00:55.960]   Yeah, they're just not owned by the city.
[02:00:55.960 --> 02:01:04.760]   Yeah, it's kind of a shame. This was, I think, an historic plan, but the phone companies don't
[02:01:04.760 --> 02:01:13.480]   like it when you compete with them. So never mind. You like those scooters? Bird is laying off
[02:01:13.480 --> 02:01:20.920]   almost a quarter of its staff. Meanwhile, electric scooters are getting a second chance in some cities.
[02:01:20.920 --> 02:01:22.360]   It says the New York Times.
[02:01:22.360 --> 02:01:29.800]   And the New York Times is on it. I remember when the first bird scooters showed up in San Francisco.
[02:01:30.520 --> 02:01:35.560]   They littered on their literature. They were strewn everywhere. They were strewn everywhere.
[02:01:35.560 --> 02:01:42.600]   You would trip over them. I went to a Facebook F8 in San Jose, and they were just there. I
[02:01:42.600 --> 02:01:45.320]   knew I got run over three times. They were thick there. Yeah.
[02:01:45.320 --> 02:01:55.720]   So that's why I think companies are struggling a little bit. But apparently, the New York Times
[02:01:55.720 --> 02:02:06.520]   says, we rented scooters in LA, in Santa Monica, and they had a no-go zone. So you go, you ride,
[02:02:06.520 --> 02:02:10.920]   you scooter up to the beach area, the boardwalk, and it just stopped. So you can't go.
[02:02:10.920 --> 02:02:16.760]   Wow. Yeah. They geo-fenced it off. Wow. They literally fenced it.
[02:02:16.760 --> 02:02:23.800]   Chicago, among the places that have required people to lock scooters to bike racks or other fixed
[02:02:23.800 --> 02:02:29.080]   objects, instead of just lying them on the ground. New York has pledged dedicated lanes and parking
[02:02:29.080 --> 02:02:34.120]   zones for scooters. I don't know. I think there are people who love scooters. People who, you know,
[02:02:34.120 --> 02:02:40.040]   we shouldn't have to have a car to get around a city. We do have mass transit, but a lot of
[02:02:40.040 --> 02:02:49.160]   cities don't have great mass transit, including LA. Nope. But LA distances don't work with a scooter.
[02:02:49.160 --> 02:02:52.760]   That's true. You can't ever go from Pasadena to Santa Monica to work on a scooter.
[02:02:52.760 --> 02:02:59.080]   Well, you're not as different. I'll use it in downtown. Or San Francisco.
[02:02:59.080 --> 02:03:04.680]   To the Dolby Max. Right. Oh, yeah. You know, I've ridden scooters around the city. Yeah.
[02:03:04.680 --> 02:03:12.440]   I mean, I feel Dolby riding a scooter at my age. Yeah. It's not a good one. I would totally do it
[02:03:12.440 --> 02:03:18.120]   now, considering it's almost $7 a gallon here. That's true. That's true. I've almost told the
[02:03:18.120 --> 02:03:23.720]   hardheads that old dad might be on that scooter, but they're lucky. I'm a little too heavy for
[02:03:23.720 --> 02:03:29.560]   just a little. Can I do a number, Jeff? I'm sure I think I know which one of
[02:03:29.560 --> 02:03:34.600]   these you're going to do is probably do know this. I have this. You have others. I don't want
[02:03:34.600 --> 02:03:42.200]   to steal, you know, if it's a valuable number for you. A Google employee named Emma Haruka
[02:03:43.400 --> 02:03:55.720]   has calculated Pi to the 100 trillionth digit farther than any human for 100 trillions. And by the way,
[02:03:55.720 --> 02:04:03.000]   it's a little disappointing. She got the computer ran for months, finally got to the 100th
[02:04:03.000 --> 02:04:08.920]   trillionth digit. And you know what it was? Zero. Please. Well, that doesn't count, right?
[02:04:08.920 --> 02:04:12.440]   No accounts because there's something after it. If there were nothing after it, maybe not.
[02:04:13.080 --> 02:04:20.840]   But is it possible that you get to the end of the 200 trillionth we actually saw Pi?
[02:04:20.840 --> 02:04:22.760]   No, no. How do we know that you can't?
[02:04:22.760 --> 02:04:29.080]   It's an irrational number. How do we know? Okay, that's a good question.
[02:04:29.080 --> 02:04:36.280]   How do we know that Pi is irrational? That's an infinitely repeating number. I think we do.
[02:04:36.280 --> 02:04:40.840]   I think somebody proved it. But I don't know. I'm not a mathematician. I'm not either.
[02:04:41.880 --> 02:04:46.280]   They did sort of. This is a good chat. Somebody in the chat said, did they check her work? Yes.
[02:04:46.280 --> 02:04:51.720]   They sort of did. They spot checked it by checking some of the digits prior to the,
[02:04:51.720 --> 02:04:58.680]   obviously you can't check the final digit. She had in 2019 calculated 31 trillion
[02:04:58.680 --> 02:05:05.320]   digits, which was a record at the time. Pi has been 20% time. Yeah, my personal passion.
[02:05:05.320 --> 02:05:11.400]   Proof that Pi is irrational. There it is. Thank you. It was proven in the 1700s, says
[02:05:11.400 --> 02:05:19.880]   Jammer B. Okay. Wikipedia says it was proven in the 1700s, 1700s of Pi is irrational.
[02:05:19.880 --> 02:05:27.800]   This is interesting. Google will not say how much it costs. It is a demo, obviously,
[02:05:27.800 --> 02:05:32.760]   of Google's compute engine. That's what she used. Listen to how much computation though.
[02:05:33.320 --> 02:05:44.040]   It took 157 days, 128,000, no, I'm sorry, 128 virtual processors, 864 gigabytes of memory.
[02:05:44.040 --> 02:05:51.720]   And here's my number of the week, 82,000 terabytes of data, which is the same amount of storage as
[02:05:51.720 --> 02:06:00.840]   2,598 years worth of HD movies. Oh, geez. Who does HD anymore? Let's get an up-to-date number, Google.
[02:06:01.720 --> 02:06:06.760]   So now if you put every number on top of each other in 12 points, type in each one, what would it reach?
[02:06:06.760 --> 02:06:11.720]   Wow, did the calculation using a freely available program called Ycruncher?
[02:06:11.720 --> 02:06:18.280]   Worked with its creator, Alexander Ye to verify the result is correct. Also used an algorithm that
[02:06:18.280 --> 02:06:22.120]   makes it possible to generate specific digits of Pi without knowing the previous ones letting
[02:06:22.120 --> 02:06:27.880]   near verify that some of the final digits are correct. So she did check her work.
[02:06:29.240 --> 02:06:34.040]   Wow. And Google said, go ahead and do it. It's a great ad for Google Cloud compute.
[02:06:34.040 --> 02:06:43.640]   She's a developer advocate. She loves Pi. What do you think about this? I don't know enough about
[02:06:43.640 --> 02:06:47.400]   it, Jeff, to have an opinion. There's a YouTuber,
[02:06:47.400 --> 02:06:57.240]   Jordan Shanks. He's a comedian in Australia who's been posting videos critical of the former
[02:06:57.240 --> 02:07:02.120]   deputy premier of New South Wales, John Barrie, Laura, Barbara, Laura,
[02:07:02.120 --> 02:07:11.400]   Barbara, yeah, John Barrie, Laura, who sued and sued the comedian. He sued Google.
[02:07:11.400 --> 02:07:18.280]   sued the pocket at Google because a comic prize, no money, saying you should have taken this down.
[02:07:18.280 --> 02:07:25.000]   He won federal court justice. Stephen Reyer is in Australia ruled that Barry Lara had been
[02:07:25.000 --> 02:07:30.840]   left traumatized by a campaign of relentless cyberbullying by Jordan Shanks. He uses the
[02:07:30.840 --> 02:07:37.080]   on-screen name of friendly geordies. Google had failed to adhere to its own policies
[02:07:37.080 --> 02:07:43.000]   by doing nothing to prevent Mr. Hanks. Mr. Shanks hates speech cyberbullying and harassment
[02:07:43.000 --> 02:07:51.640]   ordered Google to pay $715,000 a figure which could rise if a cost order is made against the tech
[02:07:51.640 --> 02:07:54.840]   company. So that's just punitive damages, I guess.
[02:07:54.840 --> 02:08:03.560]   So it worries me, in the US right now, we'd be protected against that to an extent we would
[02:08:03.560 --> 02:08:08.280]   believe with Sullivan case, which says you have if you're a public figure, you have to show
[02:08:08.280 --> 02:08:15.720]   actual malice and so on and so forth. But look at the giant emperor herd case, where they
[02:08:15.720 --> 02:08:21.800]   determined actual malice to the $212 million, or I guess the punitive is $10 million,
[02:08:21.800 --> 02:08:28.120]   whatever it was, it was a lot of money. And now there's a guardian story saying that
[02:08:28.120 --> 02:08:33.720]   Google may not have to pay because US law would be ruling in some cases here. I don't understand how
[02:08:33.720 --> 02:08:41.080]   that works. I don't get that. But the fear is you have in the US, you have Justice Thomas has been
[02:08:41.640 --> 02:08:49.560]   shooting scuds across the bow of Sullivan again and again and again, because the right way wants to
[02:08:49.560 --> 02:08:55.880]   punish big media and make that what's right we can do it now, whether it's abortion or anything
[02:08:55.880 --> 02:09:06.200]   else, they want to let loose the dogs of lawyers on people as a way to chill a criticism. And so I
[02:09:06.200 --> 02:09:13.880]   fear that this will be a preview of losing Sullivan in the US and if politicians can sue,
[02:09:13.880 --> 02:09:19.480]   and even if they don't win, right, slap stuff, even if they just take you to court and the lawyers
[02:09:19.480 --> 02:09:27.560]   cost you a fortune, if their cases are not thrown out, because they sue critics, oh man, we're
[02:09:27.560 --> 02:09:32.520]   even more doomed than we already are. Yeah, this is a good case for us because it's
[02:09:32.520 --> 02:09:36.760]   Australian. We don't know what the politics of it are with the Barri Laro's politics are,
[02:09:36.760 --> 02:09:45.560]   what friendly Jordies was up to. He accused Barri Laro of lying to anti-corruption committee,
[02:09:45.560 --> 02:09:53.320]   conducting extramarital affair. Barri Laro did sue the comedian who settled in November last year.
[02:09:53.320 --> 02:09:54.600]   That's right, that's right, thank you.
[02:09:54.600 --> 02:09:59.240]   Provided an apology and edited the videos, so he went after Google after he went after
[02:09:59.240 --> 02:10:05.640]   the comedian. In a scathing judgment, the judge said shanks had run a relentless cyberbullying
[02:10:05.640 --> 02:10:11.320]   campaign against Barri Laro, which caused him to leave public office prematurely.
[02:10:11.320 --> 02:10:16.520]   Now, I don't know, maybe the guy was a horrific troll. Maybe, I don't know. I don't know.
[02:10:16.520 --> 02:10:21.720]   But when you protect speech, you protect the worst of it. That's our...
[02:10:21.720 --> 02:10:26.600]   But it does sound malicious. I mean, it sounds like it could have been malicious.
[02:10:27.400 --> 02:10:31.880]   Might have been. And you might have lost it in the US courts. I don't know.
[02:10:31.880 --> 02:10:35.320]   I'm being more generic in my worry.
[02:10:35.320 --> 02:10:41.320]   Interesting case. Maybe some of our Australian listeners will explain.
[02:10:41.320 --> 02:10:47.960]   There's probably a lot more. When they get up, there's a lot more to this that we don't know about.
[02:10:52.440 --> 02:10:59.240]   You want to look at the greatest... The trippiest tech glitch ever?
[02:10:59.240 --> 02:11:03.640]   Yes. We can wrap this up with the trippiest... Oh, wrap up already?
[02:11:03.640 --> 02:11:08.520]   Yeah, we're already. I can say that some of the best time. Time for a katjui baby.
[02:11:08.520 --> 02:11:13.160]   It's katjui pippy time. So this is a conference.
[02:11:13.160 --> 02:11:16.760]   Yeah. And there's something to try, Kaster.
[02:11:16.760 --> 02:11:19.240]   Yeah, I can make this happen right now, right here.
[02:11:20.120 --> 02:11:24.920]   There's really only four people on stage, but there's something wrong with the screen.
[02:11:24.920 --> 02:11:30.600]   And I hope you're not an epileptic because that's seizure material. That's terrible.
[02:11:30.600 --> 02:11:35.400]   So let's do it in the video feedback. For those who aren't on...
[02:11:35.400 --> 02:11:42.760]   Should we give a warning? Oh, I thought that maybe you were gonna be talking about.
[02:11:42.760 --> 02:11:45.320]   Sorry. I hope it didn't.
[02:11:47.880 --> 02:11:51.560]   Let's take a break. Come back. Picks of the week items of the week.
[02:11:51.560 --> 02:11:56.680]   That kind of thing our show today brought to you by... Is that right, Hover?
[02:11:56.680 --> 02:12:05.240]   Yes. Oh, I love Hover. Love them. Hover is my domain registrar. I should explain. This is where
[02:12:05.240 --> 02:12:09.320]   I get my domains. And I love it. Anytime I get a good idea for a domain... Actually,
[02:12:09.320 --> 02:12:14.760]   I think anybody around here might get me ran off and registered a domain in the middle of
[02:12:14.760 --> 02:12:20.840]   one of our broadcasts once I remember doing iOS today. People everywhere around
[02:12:20.840 --> 02:12:26.920]   to it are registering domains at Hover. Why do we like Hover? Because they're great. They're simple.
[02:12:26.920 --> 02:12:33.640]   They're not fancy. They don't make you go through eight pages of other things you could buy from them.
[02:12:33.640 --> 02:12:38.360]   For instance, when you buy a domain name at Hover, you get who is privacy built in.
[02:12:38.360 --> 02:12:43.320]   You don't have to pay extra for that because when you register domain name your
[02:12:44.280 --> 02:12:49.160]   name, address, and phone number public information. So you want to have who is privacy. They know that.
[02:12:49.160 --> 02:12:56.520]   So they just provide it. If you are... This is a campaign I've been on lately in the radio show.
[02:12:56.520 --> 02:13:00.840]   If you live on email, email is important to you. I get somebody calls on the radio show for people
[02:13:00.840 --> 02:13:06.040]   and say, "I can't get into my email account. I'm one woman who something went wrong with her
[02:13:06.040 --> 02:13:10.360]   Gmail account. She went down to the Gmail office and Irvine and banged on the door and I said,
[02:13:11.240 --> 02:13:16.120]   "That helps." She said, "No. Nobody's going to fix it because it's free." I get people saying,
[02:13:16.120 --> 02:13:21.880]   "My AOL account's not working anymore. My Yahoo account. If email is important to you, you should
[02:13:21.880 --> 02:13:27.080]   pay for it." Now, the good news is, with Hover, you don't have to pay a lot. Plus,
[02:13:27.080 --> 02:13:34.840]   your email is not some Gmail@yahoo.com. It's your domain name. It could be your family name,
[02:13:34.840 --> 02:13:41.720]   your business name, your nickname, your handle, whatever you want it to be. So it's really personal.
[02:13:41.720 --> 02:13:50.920]   If you're a pizza parlor, you can get Geno's pizza, Geno's dot pizza and have email at
[02:13:50.920 --> 02:13:57.640]   genos.ps and I mean, that wouldn't that be great? Wouldn't that be great? Hover can tie your domain
[02:13:57.640 --> 02:14:03.560]   name to your email so that when it renews, your domain renews, your mailbox renews. It's a no-brainer
[02:14:03.560 --> 02:14:07.640]   solution for business owners. You really need to have your business name and your email address.
[02:14:07.640 --> 02:14:11.400]   Easy to set up. You can add as many mailboxes to your domain as you need.
[02:14:11.400 --> 02:14:20.520]   It works with web if you want to use your web or any email app. It's iMap, real iMap email,
[02:14:20.520 --> 02:14:25.560]   and they have a web interface. I think Hover email is a great solution for people who are
[02:14:25.560 --> 02:14:29.480]   struggling with their email. But there's so much more you could do with your own domain name. You
[02:14:29.480 --> 02:14:34.920]   got a blog? Well, you got to have your own hosting name, right? You got a portfolio or an artist,
[02:14:34.920 --> 02:14:40.680]   a photographer? Definitely. I have Leo.camera for my pictures. Building an online store?
[02:14:40.680 --> 02:14:45.960]   Yes, I got it. Hover, of course I did. Maybe you just want to make a more memorable redirect to
[02:14:45.960 --> 02:14:53.240]   your LinkedIn page. Looking for work? You know, hireme.com. Something like that. The prices are great too.
[02:14:53.240 --> 02:15:00.280]   Very affordable. You get pro-level tools. If you are an expert in DNS, I do all my own DNS at hover.com,
[02:15:00.280 --> 02:15:04.760]   but they also have Hover Connect, which works with many services. You just a couple of clicks
[02:15:04.760 --> 02:15:10.760]   and you're connected, so your website goes to your new domain. It's private. It's secure. It's fast.
[02:15:10.760 --> 02:15:16.360]   It's easy. And at Hover, you are a customer, not a source of data. So take back control of your
[02:15:16.360 --> 02:15:23.640]   data with reliable, tracker-free email from Hover and a domain name from Hover. I own dozens of
[02:15:23.640 --> 02:15:31.560]   domain names. Look at all the TLDs now. Finance, financial fish, Leo.fish, fishing.
[02:15:31.560 --> 02:15:38.280]   Fun. I do have Lottlefun, L-O-T-L dot F-U-N. I do have that. I love that.
[02:15:38.280 --> 02:15:44.040]   So just go on and on and on. When I was going to do a podcast called Leo on the line,
[02:15:44.040 --> 02:15:49.640]   L-O-T-L, I immediately, anytime I have an idea, I register the domain name. And at Hover,
[02:15:49.640 --> 02:15:55.720]   it's affordable. It's easy. Auto-renew makes it simple and it's completely secure and private.
[02:15:55.720 --> 02:16:03.560]   Plus you get email. At Hover, you're not a source of data. You are their customer. Great support
[02:16:03.560 --> 02:16:10.600]   and great people. Hover.com/twit, whether you're a developer, photographer, small business,
[02:16:10.600 --> 02:16:15.880]   Hover has something for you to expand your projects and get the visibility you want. Go to Hover.com/twit
[02:16:15.880 --> 02:16:20.920]   right now. Make sure you do that so they know you saw it here and you'll get 10% off your first
[02:16:20.920 --> 02:16:28.280]   purchase of any domain extension for the whole first year. Hover, h-o-v-e-r dot com slash twit,
[02:16:28.280 --> 02:16:35.720]   10% off your domain extension for a full year. Thank you, Hover, for your support. Gumby says,
[02:16:36.520 --> 02:16:39.800]   "So kachoy pepe is macaroni and cheese for rich people."
[02:16:39.800 --> 02:16:44.760]   Grown-ups. Grown-ups. I like mac and cheese.
[02:16:44.760 --> 02:16:50.920]   That's really funny. Yeah. And you know, there are lots of grown-up mac and cheeses.
[02:16:50.920 --> 02:16:54.680]   We have lobster mac and cheese, all kinds of mac and cheese. Yeah.
[02:16:54.680 --> 02:17:01.080]   Let's do your thing, Ant. You got something for us. We always end with you. We should start
[02:17:01.080 --> 02:17:07.000]   with you for a change. Sure. Yeah, sure. Hold on. I got a track and field time.
[02:17:07.000 --> 02:17:13.240]   That's part of my wackin'. Yeah. This is a track and field national championships that's on my
[02:17:13.240 --> 02:17:18.200]   brain because, well, of course, I'm a Clemson fan. So there's a lot of Clemson kids that qualify
[02:17:18.200 --> 02:17:25.160]   for the Nationals and then it's in Eugene, Oregon, where hard hit is aspiring to go one day and be
[02:17:25.160 --> 02:17:30.520]   an Oregon duck and be an Olympian and folks that are interested in track and field, check it out.
[02:17:30.520 --> 02:17:33.320]   Both your sons are really good runners, aren't they?
[02:17:33.320 --> 02:17:42.760]   Yeah, they do all right. But he's a proud pop of them. Don't let them fool you.
[02:17:42.760 --> 02:17:45.960]   That's awesome. They do all right. That's great. I got to keep them humble.
[02:17:45.960 --> 02:17:52.520]   But yeah, it starts. Can you stream them? They will be streaming at 430 Pacific as of,
[02:17:52.520 --> 02:17:56.920]   yeah, actually right now they should be streaming on ESPNU, I believe. Oh, good.
[02:17:56.920 --> 02:18:03.720]   If you have that subscription, so yeah, check that out. My next one, this was sent to me from
[02:18:03.720 --> 02:18:10.040]   one of my friends. She says she wanted to send it out to all the people of color she knows and
[02:18:10.040 --> 02:18:16.200]   I thought it was interesting and it's called turn signal. And actually, I wanted to ask y'all
[02:18:16.200 --> 02:18:21.240]   about this too, just to get your perspective. It's basically an app that's going to allow you to
[02:18:22.120 --> 02:18:27.880]   basically connect with a lawyer when you get into a traffic stop. Oh my god.
[02:18:27.880 --> 02:18:35.000]   That's brilliant. You fired up and it allows you to connect to a lawyer to be right there.
[02:18:35.000 --> 02:18:42.840]   I have my attorney here with me. Wow. It's not free. It's like $60 a year,
[02:18:42.840 --> 02:18:50.040]   but they also offer, I guess you can say a scholarship, if you will, for people that are
[02:18:50.040 --> 02:18:55.000]   under a certain income bracket to get it for free for a year that I want to say to folks in Brooklyn
[02:18:55.000 --> 02:19:02.440]   are getting it for free. It started by the whole team is all black dudes, the CEOs of black dude,
[02:19:02.440 --> 02:19:08.920]   and they put this thing together. And I thought it was an interesting idea. But yes.
[02:19:08.920 --> 02:19:16.760]   But the first thing that popped in my head is an experience that I had. Several years ago at CES,
[02:19:17.400 --> 02:19:24.920]   I was in a lift. And the lift driver was being idiotic on the streets and we got pulled over.
[02:19:24.920 --> 02:19:31.320]   Okay. So when we got pulled over, my first instinct is I need to have my phone open and
[02:19:31.320 --> 02:19:35.640]   record him because this was, this could have been really, really bad because he was swerving and
[02:19:35.640 --> 02:19:42.280]   just being idiotic on the streets. So I had my phone out and had it recorded just to protect myself and
[02:19:43.240 --> 02:19:50.440]   just just human nature. The police officers, they came up and they were quite belligerent
[02:19:50.440 --> 02:19:56.040]   about my phone. And I told them, look, I'm just trying to make sure I don't get into any type of
[02:19:56.040 --> 02:20:01.480]   mess that that I can't prove. You know, and they were, I'm thinking, we're with, we're having
[02:20:01.480 --> 02:20:08.040]   a right this, right. So I'm thinking if I had an app like this, does this make the police officers
[02:20:08.040 --> 02:20:14.760]   more belligerent? Oh, I guarantee you. Having a lawyer on the line. On the other hand,
[02:20:14.760 --> 02:20:20.680]   if they're intelligent, they might have to moderate their belligerents a little bit because you got
[02:20:20.680 --> 02:20:26.920]   your lawyer on the line. Yeah. So I guess it's what your experience has been up to now, you know,
[02:20:26.920 --> 02:20:32.600]   right? I thought it was a good idea. But at the same time, that was the first thing that popped
[02:20:32.600 --> 02:20:35.960]   in my head when it was shared with me was how those cops were yelling at me. That's how they
[02:20:35.960 --> 02:20:40.200]   get you. My phone out. That's how they get you. You're hands. That's what they kept saying. I
[02:20:40.200 --> 02:20:45.080]   need to see your hands, sir. And both of them came over to my window. I'm in the back seat.
[02:20:45.080 --> 02:20:51.160]   And you're not driving lift. I'm not even driving. But they came over to my window and said,
[02:20:51.160 --> 02:20:56.680]   I need to see your hands. So we couldn't they see him when you were holding up the phone and
[02:20:56.680 --> 02:21:04.200]   video them? Sure. Officers see these are my hands. No, no, this is this is intimidation. It is
[02:21:04.760 --> 02:21:09.480]   in almost every jurisdiction that I know of, it's absolutely legal to record officers.
[02:21:09.480 --> 02:21:14.920]   Yeah. And they mentioned that inside of the app, they mentioned that on their website,
[02:21:14.920 --> 02:21:21.000]   the turn signal website. Right now they're only available in like five states at the moment,
[02:21:21.000 --> 02:21:25.640]   because it's fairly new and it's a miniscule. Where you're allowed to practice law is an issue,
[02:21:25.640 --> 02:21:29.960]   too. Yeah, that's probably why. They probably need lawyers in various states to make it work.
[02:21:29.960 --> 02:21:34.200]   What a good idea. They're working on the rule. It is a great idea. Turn signal without an A,
[02:21:34.200 --> 02:21:38.520]   turn signal. There's a guy on TikTok who a white guy,
[02:21:38.520 --> 02:21:44.280]   he's a black guy would not get away with this. He constantly appears to be the whole count.
[02:21:44.280 --> 02:21:50.200]   I forget the count name, but he goes and he's recording cops and they always get pissed or
[02:21:50.200 --> 02:21:53.400]   they always do. But every time he shows it, they're getting pissed off and asking for his
[02:21:53.400 --> 02:21:58.280]   identification. He says, and he just quotes a lot of them and says, unless you have cause for
[02:21:58.280 --> 02:22:05.080]   me saying that I broke the law, no, and he hangs for the minute. You won't carry. Yeah, but it is
[02:22:05.080 --> 02:22:08.440]   scary. I was very proud of Henry. I've told this story before he when he was in college,
[02:22:08.440 --> 02:22:14.280]   there was a protest going on and he went out to take pictures of it, I think for the campus newspaper
[02:22:14.280 --> 02:22:20.920]   and the police sat him down and said, give me the camera. I want to erase that. And he said,
[02:22:20.920 --> 02:22:27.800]   no, I have the right to take these pictures. This is protected, protected activity. I'm a
[02:22:27.800 --> 02:22:32.040]   news gathering. And the police made him sit there and cool his heels for quite a while, but they
[02:22:32.040 --> 02:22:37.000]   did not take his camera and he ended up going home with those pictures. They will intimidate the
[02:22:37.000 --> 02:22:41.720]   hell out of you. And you know what? If I were black, I'd be very nervous that they might do more,
[02:22:41.720 --> 02:22:49.160]   to be honest. Yeah, I, it, my pardon me, it's fresh and my hands were tied. I was in the back of
[02:22:49.160 --> 02:22:59.400]   that car. My driver was a, I guess he was Middle Eastern. Do they arrest him? No, they didn't.
[02:22:59.400 --> 02:23:03.480]   Throw it in the ticket. We were there for quite a bit. And it was the two police officers were
[02:23:03.480 --> 02:23:09.720]   there in just in camo. The Vegas, the Vegas police are scary, but they, I think they kind of have to
[02:23:09.720 --> 02:23:18.680]   be. They have to be. I get it. Yeah. But I just say, the driver was not driving well. So
[02:23:19.320 --> 02:23:22.600]   if they had listened to you, you probably would have been agreeing with the cops.
[02:23:22.600 --> 02:23:29.400]   I was. That's the whole thing. That's the weird part of all. Yeah. But at the same time,
[02:23:29.400 --> 02:23:34.920]   it was like, no, we need to see your hands. But they, I can understand why they had to rest.
[02:23:34.920 --> 02:23:40.680]   They didn't want you recording. My hands on the address. There's been, of course, a lot of cases
[02:23:40.680 --> 02:23:45.400]   where police will play popular music, hoping that you can't post this video, because they'll be at
[02:23:45.400 --> 02:23:50.600]   take. Yeah. Yeah. Yeah. Exactly. I think Congress is considering a law against that.
[02:23:50.600 --> 02:23:57.480]   Look, there are plenty of good cops. And I don't think the world would be very good without police,
[02:23:57.480 --> 02:24:03.880]   but at the same time, if you're, if you're not. I'm not here and say defund police. No, you're
[02:24:03.880 --> 02:24:08.440]   never going to say that. If you're a good cop, you shouldn't, you know, this is, you're doing your
[02:24:08.440 --> 02:24:15.000]   duty. And it is our right as citizens to record that. And that's the, that's the law.
[02:24:15.880 --> 02:24:21.720]   Oh, wow. Yeah. I wanted to run that by you guys. Just to get you the interesting. Good find.
[02:24:21.720 --> 02:24:26.600]   I showed before we have a shortcut I've showed on the air that somebody wrote for, if you're
[02:24:26.600 --> 02:24:31.320]   getting pulled over, that does a whole bunch of things says I'm being pulled over sends messages
[02:24:31.320 --> 02:24:35.720]   to family and friends. I mean, below starts recording audio of the interaction, which is not as
[02:24:35.720 --> 02:24:45.320]   us. All right. And plays a laugh track during the entire interaction, which usually diffuses the
[02:24:45.320 --> 02:24:54.520]   situation. Finally, finally, let's order a print from aunt. Oh, is that pretty? Yeah. Lastly,
[02:24:54.520 --> 02:25:00.440]   order a print at print.com slash prints. And that's an important help me pay for these hard hits.
[02:25:00.440 --> 02:25:06.840]   It's lovely school bills. I just, we do pay a salary. I'm not. They do.
[02:25:06.840 --> 02:25:13.000]   They do. It's not working for free, but I agree. We want to support you in every way possible.
[02:25:13.000 --> 02:25:17.800]   And he has such great photography. And you know what? What an opportunity to get some beautiful
[02:25:17.800 --> 02:25:23.240]   art on your walls. So I agree. You tip to 100%. Thank you. So I want to get this peaceful sunset
[02:25:23.240 --> 02:25:28.840]   in the park. That's pretty. That's actually Sonoma County. Yeah, I believe it. I've seen it.
[02:25:29.480 --> 02:25:36.600]   Yep. It's a good place to take pictures, isn't it? Oh, the Golden Gate Bridge. Yeah. Lots of good
[02:25:36.600 --> 02:25:42.520]   images. The most popular one is there's a plane. It's called Sunset Flight. It's probably the most
[02:25:42.520 --> 02:25:50.360]   popular one. That's gorgeous too. Very nice. Find art America.com. You can just search for
[02:25:50.360 --> 02:25:58.040]   Aunt Pruitt. You will find a gallery. Oh, yeah. Just go to his website. There you go. You went
[02:25:58.040 --> 02:26:04.360]   to hover, obviously. Thank you, Aunt. Thank you, sir. Number, Mr. Jarvis.
[02:26:04.360 --> 02:26:09.160]   I've got a one there to take longer and plus Stacy, I probably want to yell at me. So I'll hold
[02:26:09.160 --> 02:26:16.200]   the off-com till next week. Have you seen the video of the Jubilee of the Oh, you must have met the
[02:26:16.200 --> 02:26:21.000]   Queen video? Oh, there are so many good videos from the Jubilee. Is this this isn't the one with
[02:26:21.000 --> 02:26:25.960]   Paddington the Bear? No. Oh, I want to show that one too. Well, okay, we'll show this first though.
[02:26:25.960 --> 02:26:32.040]   Play this. This was no music and it's you're safe. It's lovely. And normally on these picnic sites,
[02:26:32.040 --> 02:26:37.240]   you meet nobody, but there was two hikers coming towards us. Oh, we should mention, by the way,
[02:26:37.240 --> 02:26:44.200]   that this is Queen Elizabeth's Jubilee year, 75 years on the throne. 70. 70 years on the throne,
[02:26:44.200 --> 02:26:51.480]   which is longer than any monarch ever. Yes. Yeah. Platinum. Yeah. Platinum Jubilee. So,
[02:26:52.200 --> 02:26:59.240]   here is one of our protection guys. And normally, you meet nobody, but there was two hikers
[02:26:59.240 --> 02:27:03.640]   coming towards us and the Queen would always stop and say hello. And it was two Americans on a
[02:27:03.640 --> 02:27:08.600]   walking holiday. And it was clear from the moment that we first stopped, they hadn't recognized the
[02:27:08.600 --> 02:27:13.320]   Queen, which is fine. And the American gentleman was telling the Queen where he came from, where
[02:27:13.320 --> 02:27:18.840]   they were going to next and where they'd been to in Britain. And I could see it coming and sure
[02:27:18.840 --> 02:27:24.280]   enough, he said, "Oh Majesty, where do you live?" She said, "Well, I live in London for a holiday
[02:27:24.280 --> 02:27:29.560]   home, just the other side of the hills." And he said, "Well, how often have you been coming up here?"
[02:27:29.560 --> 02:27:33.960]   "Oh," she said, "I've been coming up here ever since I was little girl, so over 80 years."
[02:27:33.960 --> 02:27:38.440]   And you can see the clogs thinking, "Well, if you've been coming up before 80 years,
[02:27:38.440 --> 02:27:43.400]   you must have met the Queen." And the Queen was a flash, says, "Well, I haven't. The dickier
[02:27:43.400 --> 02:27:50.360]   meets a regular leg." So the guy said, "He's met the Queen, what she like. And because I was with her
[02:27:50.360 --> 02:27:54.600]   a long time when I knew I could pull her leg, I said, "Oh, she can be very cantankerous at times,
[02:27:54.600 --> 02:28:00.280]   but she's got a lovely sense of humour." And the next thing I knew, this guy comes around,
[02:28:00.280 --> 02:28:03.640]   "Put his arm around my shoulder and before I could see what was happening,
[02:28:03.640 --> 02:28:12.120]   he gets his camera, gives it to the Queen, and says, 'Can you take a picture of the Queen?' And we
[02:28:12.120 --> 02:28:16.600]   never let on, and we waved goodbye. And then, in emergency, he said to me, 'I'd love to be a
[02:28:16.600 --> 02:28:20.520]   fly in the wall when he shows us photographs through friends in America.'" "Oh, can you imagine?
[02:28:20.520 --> 02:28:29.400]   All right, I've got it now that you've said this, I have to show you Queen Elizabeth taking
[02:28:29.400 --> 02:28:33.640]   tea with Paddington. Do you think there are people who haven't seen it? Is it worth playing?"
[02:28:33.640 --> 02:28:37.240]   "I haven't seen it." "Okay, good. Anne is our every man.
[02:28:39.960 --> 02:28:45.480]   She recorded this at Buckingham Palace, kept its secret from her family for a month
[02:28:45.480 --> 02:28:52.280]   because it had to be obviously..." "This is not easy to record too because you're recording to a
[02:28:52.280 --> 02:28:57.800]   blank space." "Yeah, she's not actually talking to anybody. Here, let me play, it's on YouTube if
[02:28:57.800 --> 02:29:02.840]   you want to see it all. And there is music in this, but I think it's royal music, so I think we're
[02:29:02.840 --> 02:29:09.880]   probably okay. Her butler's getting the tea with the royal cozy, which looks like
[02:29:09.880 --> 02:29:15.160]   a crown, and taking a very long walk through Buckingham Palace."
[02:29:15.160 --> 02:29:19.000]   "Well, I mean, it is the palace." "It is. Yeah, it's quite a beautiful,
[02:29:19.000 --> 02:29:23.880]   beautiful stroll he's taking." "The tea's gonna get cold by the tummy." "I know why they need a
[02:29:23.880 --> 02:29:28.840]   crown cozy. There's some McClair's."
[02:29:28.840 --> 02:29:36.840]   "Thank you for having me. I do hope you're having a lovely Jubilee." "That's Paddington."
[02:29:37.800 --> 02:29:44.760]   "Tea? Oh, yes, please." "He's drinking it out of the pot."
[02:29:44.760 --> 02:29:56.680]   "The butler says, 'No, put the pot down.' So, panning it does, but unfortunately..."
[02:29:56.680 --> 02:30:04.520]   "Oh, he first he pours the queen. A drop, that's all that's left." "Never mind."
[02:30:05.480 --> 02:30:07.720]   "And then he puts it down on the eclairs."
[02:30:07.720 --> 02:30:18.040]   "Or his hand, and they squirts the butler." "The queen is amused." "She's very lovely."
[02:30:18.040 --> 02:30:26.600]   "Perhaps he would like a marmalade sandwich. I always keep one for emergencies." "And his hats."
[02:30:26.600 --> 02:30:30.840]   "So do I." "In her purse." "I keep mine in here."
[02:30:34.840 --> 02:30:39.400]   "This is the best for later, but this is the very best part. They open the window,
[02:30:39.400 --> 02:30:44.920]   and this was shown on the screen to these people as they're cheering."
[02:30:44.920 --> 02:30:59.400]   "How did you believe him?" "And thank you for everything." "That's very kind."
[02:31:00.760 --> 02:31:04.920]   "Awwww." "You Brits are lucky. What do we got?"
[02:31:04.920 --> 02:31:13.160]   "And by the way, that drum line, watch this drum line. They're gonna play We Will Rock You,
[02:31:13.160 --> 02:31:17.320]   watch this." "And she's playing the couple on side." "Wow."
[02:31:17.320 --> 02:31:25.320]   "It's a heck of a drum line."
[02:31:27.560 --> 02:31:32.360]   "Dude, I love snare drum." "Oh man." "Planum Jubilee."
[02:31:32.360 --> 02:31:38.120]   " As representing the people who have rebelled against you."
[02:31:38.120 --> 02:31:43.320]   "We win our own way." "And even though some were trying to bring back."
[02:31:43.320 --> 02:31:51.000]   "We won our own monarch." "We certainly do appreciate her as quite a monarch."
[02:31:51.000 --> 02:31:56.520]   "Pretty cool." "Isn't that sweet?" "Thank you, Aunt Pruitt. Hands-on photography."
[02:31:57.400 --> 02:31:59.720]   "Twit.tv/hop. What's coming up?"
[02:31:59.720 --> 02:32:07.240]   "Oh, well this week we're going to sort of rehash a previous conversation about printing photos,
[02:32:07.240 --> 02:32:13.160]   but we're going to talk about selling your photos." "Oh, check it out." "Twit.tv/hop."
[02:32:13.160 --> 02:32:18.040]   "Just did a little of that, didn't we?" "Mm-hmm." "I can't." "I can't." "It did."
[02:32:18.040 --> 02:32:26.040]   "Excellent. Twit.tv/hop." "Jeff Jarvis is..." "Wait a minute." "Why do I put this away?"
[02:32:26.600 --> 02:32:32.200]   "The director of the Townite Center for Entrepreneurial Tourism at the Great New
[02:32:32.200 --> 02:32:36.920]   Bar." "Gradual School of Journalism at the City University of New York."
[02:32:36.920 --> 02:32:40.520]   "Great to have you. Buzzmachine.com." "And is going to be busy
[02:32:40.520 --> 02:32:46.280]   for the next few weeks because he is also community manager at Club Twit.
[02:32:46.280 --> 02:32:51.800]   And the Book Club Stacey's Book Club is a week from now. If Stacey doesn't, if Stacey can't make
[02:32:51.800 --> 02:32:56.440]   it back from Puerto Rico, I'll do it because I've been reading it and I'm loving this. It's William
[02:32:56.440 --> 02:33:02.120]   Gibson's... I'm sorry, Neil Stevenson's latest... "New Stephen termination shock and I know you hated
[02:33:02.120 --> 02:33:11.320]   it so I'll take over." "John and I are reading it. I'm not finished. I've only got six days to read
[02:33:11.320 --> 02:33:16.040]   12 hours so I've got to get through about it. Listen to 12 hours." "It's helped me to stay away
[02:33:16.040 --> 02:33:23.320]   from that book because it made me angry quite." "What angered you?" "I just see privilege, man.
[02:33:23.320 --> 02:33:29.240]   Just... I look at... It does start with the Queen of the Netherlands, yeah."
[02:33:29.240 --> 02:33:35.080]   "Netherlands, yeah. I go down the road to buy gasoline for the car and seeing that it's,
[02:33:35.080 --> 02:33:39.640]   you know, damn there's seven bucks a gallon and then there's these homeless people next to me.
[02:33:39.640 --> 02:33:47.480]   And all that is while I have my audiobook playing in my ear and these people are talking about
[02:33:47.480 --> 02:33:55.000]   having tea and sulfur and just like, "Nah dude, I need to turn this off because I'm getting angry."
[02:33:55.000 --> 02:34:02.680]   "Okay, well in that case I better host this book club. It's 9am, June 16th. We'll let the
[02:34:02.680 --> 02:34:07.160]   commies stay out of it. No, you can join. You can join and give us your point of view.
[02:34:07.160 --> 02:34:12.280]   You're going to do... This is your idea to do a members fireside chat on July 7th.
[02:34:12.280 --> 02:34:18.440]   That's kind of neat. That'll be fun. And then of course Alex Lindsay has an "Ask Me Anything"
[02:34:18.440 --> 02:34:24.360]   coming up July 14th. These are events we do inside our Discord. Club Twitch is really three benefits.
[02:34:24.360 --> 02:34:30.840]   Add free versions of all the shows we do because you asked us for that. No tracking, no ads, nothing.
[02:34:30.840 --> 02:34:34.920]   You also get access to the Discord which has shows that we don't, you know, put out publicly
[02:34:34.920 --> 02:34:40.760]   like our Untitled Linux Show, the Stacey's Book Club, the Gizfiz. It also has conversations about
[02:34:40.760 --> 02:34:44.200]   all kinds of things Geeks love. And as I mentioned, because you're paying seven bucks,
[02:34:44.200 --> 02:34:50.360]   the conversations are always good. Great people in there. And you get the Twitch Plus feed where
[02:34:50.360 --> 02:34:57.240]   stuff that we talk about before and after the shows and other places shows up. So you get a
[02:34:57.240 --> 02:35:04.280]   lot of benefit I think from your $7 a month. That's it. Twitch.tv/clubtuit. We'd love to have you
[02:35:04.840 --> 02:35:10.840]   be in the club. Come on now, man. Join us in the club. So members in the Discord. I know I don't
[02:35:10.840 --> 02:35:16.360]   do the DMs a lot because there's no way I can keep up with them. But don't be surprised if you get
[02:35:16.360 --> 02:35:22.680]   a DM for me asking them about a sit-down. Good. I want to do these hangouts. Good.
[02:35:22.680 --> 02:35:31.960]   Yeah. Thank you, Ann. And we do have a dedicated Minecraft server, two of them actually, for Discord.
[02:35:31.960 --> 02:35:36.440]   And it went down. I didn't realize this when our power went out on Sunday. Of course, the Minecraft
[02:35:36.440 --> 02:35:41.800]   server went down too. So I have fixed it, rebooted it. It's all running fine. Go on in there. If you're
[02:35:41.800 --> 02:35:47.800]   a member of a club to it or if you're not yet whitelisted in there, go to the Let's Play section
[02:35:47.800 --> 02:35:56.280]   of Club to it. And I will add your name to the list. We do really it's having a lot of fun in those
[02:35:56.280 --> 02:36:01.240]   Minecraft servers as well. Club to it. Thank you, everybody, for participating. We do this week
[02:36:01.240 --> 02:36:09.240]   in Google every Wednesday, 2 p.m. Pacific 5 p.m. Eastern 2100 UTC. Join us live. If you wish,
[02:36:09.240 --> 02:36:15.480]   we have audio and video streams at live.twit.tv. We also have a live chatroom at IRC.twit.tv
[02:36:15.480 --> 02:36:21.800]   that's open to all like the Discord chatroom. But this one's open to all. We also have free
[02:36:21.800 --> 02:36:28.200]   versions of the show available and supported at twit.tv/twig. There's a YouTube channel and
[02:36:28.200 --> 02:36:33.240]   supported. It's actually a good place if you want to share a bit of the show with somebody.
[02:36:33.240 --> 02:36:37.720]   You can just snip a little bit on the YouTube channel and send that off. And of course, the best
[02:36:37.720 --> 02:36:42.040]   way to get it probably is subscribe because it is a podcast and you can get it automatically.
[02:36:42.040 --> 02:36:46.600]   The minute it's available, pick up a podcast player and search for this week in Google.
[02:36:46.600 --> 02:36:52.200]   Subscribe. And if that player has reviews, please leave us a nice review. Five stars. We'd appreciate
[02:36:52.200 --> 02:36:57.720]   it. Thank you. That's it for this week in Google for this week. We'll see you next time. Bye-bye.
[02:36:57.720 --> 02:37:03.080]   Don't miss all about Android every week. We talk about the latest news,
[02:37:03.080 --> 02:37:08.760]   hardware, apps, and now all the developer-y goodness happening in the Android ecosystem.
[02:37:08.760 --> 02:37:14.280]   I'm Jason Howell, also joined by Ron Richards, Florence Ion, and our newest co-host on the panel,
[02:37:14.280 --> 02:37:19.880]   When To Dao Who Brings Her Developer Chops. Really great stuff. We also invite people from all
[02:37:19.880 --> 02:37:25.480]   over the Android ecosystem to talk about this mobile platform we love so much. Join us every
[02:37:25.480 --> 02:37:35.800]   Tuesday, all about Android, on twit.tv.
[02:37:35.800 --> 02:37:38.380]   (upbeat music)
[02:37:38.380 --> 02:37:40.960]   (upbeat music)

