;FFMETADATA1
title=Movin' On Up
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=366
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.540]   It's time for Twig. This week in Google's Stacey Higginbotham is here. She's got a report from the Intel developers forum.
[00:00:06.540 --> 00:00:11.300]   That's where she is right now. Kevin Marks joins us from his backyard and from New Jersey.
[00:00:11.300 --> 00:00:17.580]   It's Jeff Jarvis. We're going to talk about the latest from Google and give you a demo of the new Google video calling app.
[00:00:17.580 --> 00:00:19.580]   It's all coming up next on Twig.
[00:00:19.580 --> 00:00:24.620]   Netcast you love.
[00:00:24.620 --> 00:00:26.620]   From people you trust.
[00:00:26.620 --> 00:00:31.620]   This is Twig.
[00:00:31.620 --> 00:00:39.620]   Bandwidth for this week in Google is provided by cash fly. C A C H E F L Y dot com.
[00:00:39.620 --> 00:00:51.620]   This is Twig. This week in Google. Episode 366 recorded Wednesday, August 17th 2016.
[00:00:51.620 --> 00:01:00.620]   Moving on up. This week in Google is brought to you by automatic, the small adapter that turns your clunker into a smarter connected car.
[00:01:00.620 --> 00:01:06.620]   For more information on their brand new automatic pro adapter visit automatic dot com slash twit.
[00:01:06.620 --> 00:01:11.620]   And enter the limited time offer code Twit for $20 off a new device.
[00:01:11.620 --> 00:01:18.620]   And by the ring video doorbell. With ring you can see and talk to anyone at your door.
[00:01:18.620 --> 00:01:23.620]   You can see anywhere in the world using your smartphone. It's like caller ID for your home.
[00:01:23.620 --> 00:01:28.620]   Go to ring dot com slash Twig and get $50 off one of their ring of security kits.
[00:01:28.620 --> 00:01:31.620]   The bundle kit or the pro bundle kit with their limited time offer.
[00:01:31.620 --> 00:01:38.620]   Time for Twig. This week in Google. The Googlers are assembling.
[00:01:38.620 --> 00:01:43.620]   Jeff Jarvis is here from the City University of New York. He's a professor of journalism.
[00:01:43.620 --> 00:01:47.620]   The Townite Center there. Actually you just started your own new semester.
[00:01:47.620 --> 00:01:51.620]   I did. I did. I was brainwashing the incoming class. I saw you in a picture of them.
[00:01:51.620 --> 00:01:56.620]   They all look so smart and young and lively. It's really neat. That's exciting.
[00:01:56.620 --> 00:01:59.620]   It is exciting. Oh, you know, I was thinking you'd be a good teacher.
[00:01:59.620 --> 00:02:03.620]   I'll come and do a talk anytime. Yeah.
[00:02:03.620 --> 00:02:11.620]   I if you but I my son is about to graduate from college and he's a journalism major and I said you should go.
[00:02:11.620 --> 00:02:13.620]   Yes, yes, yes. Yes.
[00:02:13.620 --> 00:02:17.620]   So maybe we can talk about that too. Let's do.
[00:02:17.620 --> 00:02:25.620]   I'd love for him to what he says he wants to do. I think his probably a smart thing is get a job first work for a little while and then go to graduate school.
[00:02:25.620 --> 00:02:30.620]   We have a fair amount of that. Yeah. Why do you need a graduate school degree as a journalist?
[00:02:30.620 --> 00:02:34.620]   I've I've never understood that. That's Stacy Higginbotham. She is a journalist.
[00:02:34.620 --> 00:02:42.620]   She's a real journalist. Unlike me, she's a real journalist and currently is doing what most of the time is.
[00:02:42.620 --> 00:02:47.620]   Doing what most real journalists are doing her own thing at Stacy on IOT.com.
[00:02:47.620 --> 00:02:52.620]   She's currently at the Intel Developers Forum at Moscone Center in San Francisco. Hi, Stacy.
[00:02:52.620 --> 00:03:01.620]   Hi. And Kevin Marks is joining us. He is he's had so many jobs. He's decided not to have any more jobs.
[00:03:01.620 --> 00:03:06.620]   Well, I'm trying some new things, but I'm doing little bits of journalism too now.
[00:03:06.620 --> 00:03:07.620]   Are you?
[00:03:07.620 --> 00:03:16.620]   I'm trying to do a thing. Yeah. Nice. Kevin is a much valued advocate for the open web and the end what he calls the Indian web.
[00:03:16.620 --> 00:03:21.620]   Nonetheless, nonetheless, I'm peeved at Kevin right now. Oh, good. We can have a fight on the show.
[00:03:21.620 --> 00:03:25.620]   What have I done? Because I was going to have a joke that normally my face is all pink.
[00:03:25.620 --> 00:03:27.620]   Our rats.
[00:03:27.620 --> 00:03:35.620]   Day, mine isn't and his is and the joke for me today would have been that you know that that Jarvis was named after me and the next thing named after me was Fuchsia.
[00:03:35.620 --> 00:03:39.620]   I'm going to have a new Google operating system.
[00:03:39.620 --> 00:03:44.620]   My face is taken. Kevin gets the fuchsia joke.
[00:03:44.620 --> 00:03:50.620]   I don't know where to begin. This is a we're this is going to be a jam-packed episode.
[00:03:50.620 --> 00:03:54.620]   I wouldn't mind starting with you, Stacy. You're at IDF.
[00:03:54.620 --> 00:03:58.620]   It's ongoing. In fact, you're missing a session right now that you really probably should be at.
[00:03:58.620 --> 00:04:03.620]   Yeah, how to design my own smart home using Intel's new jewel module.
[00:04:03.620 --> 00:04:08.620]   What is jewel? It's a new dev board like Edison only smaller. It's got.
[00:04:08.620 --> 00:04:14.620]   I'm trying to remember if it has a Curie or not. You guys have to forgive me because oh my God, I've had very little sleep.
[00:04:14.620 --> 00:04:20.620]   You're jet lagged. I'm sure. Well, I did. I had to get up early this morning and yesterday morning.
[00:04:20.620 --> 00:04:22.620]   Did you fly in? Oh, you didn't fly in this morning. You thought you'd.
[00:04:22.620 --> 00:04:27.620]   No, I flew it. No, but I did have to. I had it like a seven at the seven o'clock call for rehearsals.
[00:04:27.620 --> 00:04:30.620]   Oh, that's right. You did a session. Was that this morning?
[00:04:30.620 --> 00:04:35.620]   Yes, I interviewed Intel's head of IOT. You know, I'm not going to say the name.
[00:04:35.620 --> 00:04:39.620]   We talked about that. It's fun. It was a mercy. It was.
[00:04:39.620 --> 00:04:44.620]   Nice. So there you go. You didn't have to say his full name.
[00:04:44.620 --> 00:04:48.620]   I didn't. He actually had to say mine, which, you know, heard about.
[00:04:48.620 --> 00:04:58.620]   We tried. We really, really tried to train you on how to say Marty's name, but I guess it didn't stick.
[00:04:58.620 --> 00:05:04.620]   You know, the night after I said it perfectly like three times and I still got myself.
[00:05:04.620 --> 00:05:08.620]   You know, Stacy is I always say, you know, you don't want to hear me introduce these people.
[00:05:08.620 --> 00:05:12.620]   You want to hear them tell you about themselves? What's always do that or sometimes I'll say,
[00:05:12.620 --> 00:05:16.620]   if I don't know somebody's name, I'll say, and how do you spell that?
[00:05:16.620 --> 00:05:20.620]   Dr. Venkata, Renducintala also known as Merti.
[00:05:20.620 --> 00:05:21.620]   Yes.
[00:05:21.620 --> 00:05:27.620]   He is the president, client and Internet of Things, businesses, and systems architecture group.
[00:05:27.620 --> 00:05:29.620]   Wow. What a title.
[00:05:29.620 --> 00:05:33.620]   Yes. He's a former Qualcommer. He was he was been there.
[00:05:33.620 --> 00:05:36.620]   He had been a Qualcomm forever. So Intel getting him was a big coup.
[00:05:36.620 --> 00:05:40.620]   So I would say actually, if you wanted to pick a big theme for the show,
[00:05:40.620 --> 00:05:48.620]   it's that Intel is actually signaling very strongly that it's going to be okay with non-X86 architectures.
[00:05:48.620 --> 00:05:52.620]   So the big thing they did was they announced a partnership.
[00:05:52.620 --> 00:05:55.620]   Sorry, they announced that it they had taken an arm.
[00:05:55.620 --> 00:05:58.620]   They licensed arm. It was an architecture license, which kind of licenses.
[00:05:58.620 --> 00:06:00.620]   I don't think it was an architecture license.
[00:06:00.620 --> 00:06:03.620]   I was trying to find someone who had said that and I could not.
[00:06:03.620 --> 00:06:09.620]   So I can't tell you if it's architecture or not, but they're using it to manufacture arm-based chips.
[00:06:09.620 --> 00:06:19.620]   And so this is big for two reasons. One, Intel's, they have billions of dollars invested in their fabrication plants.
[00:06:19.620 --> 00:06:22.620]   And they have to keep those things running all the time.
[00:06:22.620 --> 00:06:25.620]   It costs them huge amounts of money.
[00:06:25.620 --> 00:06:29.620]   This gets them manufacturing the chips at the edge, basically.
[00:06:29.620 --> 00:06:34.620]   So they may have not one on mobile, but they're like, eh, we'll just make them instead.
[00:06:34.620 --> 00:06:41.620]   So it's a really interesting strategy because, of course, traditionally, you think of arm and Intel at odds.
[00:06:41.620 --> 00:06:45.620]   They're competing architectures. But of course, Intel has a lot of fabs.
[00:06:45.620 --> 00:06:51.620]   They have a 10 nanometer process and it makes perfect sense.
[00:06:51.620 --> 00:06:54.620]   If you can't beat them, join them. They're licensed the architecture.
[00:06:54.620 --> 00:06:58.620]   You know, arm doesn't make its own chips. It licenses it to other manufacturers.
[00:06:58.620 --> 00:07:04.620]   Why shouldn't Intel manufacture arm processors like Samsung and LG and everybody else?
[00:07:04.620 --> 00:07:09.620]   And the cool thing, what you'll see, my hunch is you'll see a company like Apple,
[00:07:09.620 --> 00:07:12.620]   because Intel has the most advanced manufacturing.
[00:07:12.620 --> 00:07:18.620]   Take a look at this and say, hmm, and start moving their manufacturing from like Samsung,
[00:07:18.620 --> 00:07:22.620]   maybe not SMC, over for a variety of reasons.
[00:07:22.620 --> 00:07:30.620]   Interesting. Yeah. TSMC, the Taiwan Silicon Manufacturing Company mix, looks like it's going to have an exclusive this time around on the new iPhone.
[00:07:30.620 --> 00:07:32.620]   Oh, that makes sense.
[00:07:32.620 --> 00:07:38.620]   For last year, iPhone, there was this whole battle going on with, well, whose chips are better.
[00:07:38.620 --> 00:07:43.620]   Apple had was sourcing chips from TSMC. And was it Samsung? Was the other source?
[00:07:43.620 --> 00:07:46.620]   Samsung, they had two different. This is super nerdy.
[00:07:46.620 --> 00:07:50.620]   They were manufacturing using two different processes.
[00:07:50.620 --> 00:07:55.620]   And I can't remember who was doing which one, but one was like a FinFET process.
[00:07:55.620 --> 00:07:57.620]   Right. Right. And yeah.
[00:07:57.620 --> 00:08:00.620]   And then people were going back and forth with benchmarks.
[00:08:00.620 --> 00:08:05.620]   Oh, you want the TSMC chip, but it was crazy. You can't tell a difference.
[00:08:05.620 --> 00:08:09.620]   But I think it's interesting. I don't think I think Apple doesn't want to buy anything from Samsung at all.
[00:08:09.620 --> 00:08:10.620]   Right.
[00:08:10.620 --> 00:08:11.620]   And so it makes sense.
[00:08:11.620 --> 00:08:15.620]   And at the same time, you don't want a single source something that's that important.
[00:08:15.620 --> 00:08:20.620]   If TSMC has a fire and can't build any chips, you're in trouble.
[00:08:20.620 --> 00:08:21.620]   I don't think multiple--
[00:08:21.620 --> 00:08:22.620]   That everyone would be in trouble.
[00:08:22.620 --> 00:08:24.620]   Well, they wouldn't be alone exactly.
[00:08:24.620 --> 00:08:25.620]   Yeah.
[00:08:25.620 --> 00:08:32.620]   So I thought that was probably the biggest story was that Intel's going to license arm and start manufacturing arm chips.
[00:08:32.620 --> 00:08:38.620]   And then, yes. And then they showed off this little project Euclid, which is this little candy bar-sized device.
[00:08:38.620 --> 00:08:41.620]   Oh, I should have tried to steal one from the demos.
[00:08:41.620 --> 00:08:42.620]   [LAUGHTER]
[00:08:42.620 --> 00:08:43.620]   Oh.
[00:08:43.620 --> 00:08:46.620]   What happened to your klepto tendencies?
[00:08:46.620 --> 00:08:48.620]   I know. Well, they guard these things pretty well.
[00:08:48.620 --> 00:08:49.620]   I got to be honest.
[00:08:49.620 --> 00:08:57.620]   Anyway, this is for robotics. And this is cool because it has a camera with some computer vision.
[00:08:57.620 --> 00:09:04.620]   It has sensors on it. And the idea is you can-- and it supports two different robotics frameworks.
[00:09:04.620 --> 00:09:09.620]   You can build these apps like a follow me app in 20 seconds.
[00:09:09.620 --> 00:09:13.620]   They have this great GUI interface kind of combined with an IDE.
[00:09:13.620 --> 00:09:18.620]   And you just are like, "I want to turn on this type of intelligence and this sensor."
[00:09:18.620 --> 00:09:20.620]   And this one, and you check off these boxes.
[00:09:20.620 --> 00:09:25.620]   And then it basically flashes it to the Euclid and you stick it on your robot.
[00:09:25.620 --> 00:09:26.620]   And it happens.
[00:09:26.620 --> 00:09:33.620]   I know. First quarter 2017.
[00:09:33.620 --> 00:09:34.620]   And we have no word on pricing.
[00:09:34.620 --> 00:09:37.620]   I was like, "Is it $100?" Like, more or less.
[00:09:37.620 --> 00:09:39.620]   He's like, "I'm not telling you."
[00:09:39.620 --> 00:09:43.620]   Intel's real sense technology is used in some computers.
[00:09:43.620 --> 00:09:48.620]   And if you go to see a 49ers game, and I'm sure it's true if you go see a Cowboys game,
[00:09:48.620 --> 00:09:53.620]   or a Jets game, or a Giants game, or a Giants game, or a Giants game.
[00:09:53.620 --> 00:09:57.620]   Or a Jets game, or a Giants game.
[00:09:57.620 --> 00:10:03.620]   They have this kind of medieval renaissance fairer outside the front.
[00:10:03.620 --> 00:10:06.620]   And one of the booths is the Intel RealSense booth.
[00:10:06.620 --> 00:10:10.620]   And it's kind of cool because it'll take a picture of you and face paint you
[00:10:10.620 --> 00:10:13.620]   with the 49er colors or whatever in real time.
[00:10:13.620 --> 00:10:16.620]   Kind of like Masquerade does or the Snapchat things.
[00:10:16.620 --> 00:10:19.620]   But that's the kind of technology that's in here.
[00:10:19.620 --> 00:10:24.620]   And I think they have that here. They had like a get your picture or portrait painted like an Italian master.
[00:10:24.620 --> 00:10:25.620]   Exactly.
[00:10:25.620 --> 00:10:26.620]   Yeah.
[00:10:26.620 --> 00:10:27.620]   Which is very applicable.
[00:10:27.620 --> 00:10:28.620]   Same booth.
[00:10:28.620 --> 00:10:29.620]   Same booth.
[00:10:29.620 --> 00:10:30.620]   Same booth.
[00:10:30.620 --> 00:10:36.620]   Repurposed. Instead of yellow and gold they have silver and black or whatever.
[00:10:36.620 --> 00:10:37.620]   They have something else.
[00:10:37.620 --> 00:10:43.620]   I'm also interested in, and I know you, it's probably not up your alley because it's, I don't know if this, well,
[00:10:43.620 --> 00:10:47.620]   might have an impact in IOT devices.
[00:10:47.620 --> 00:10:49.620]   It's something they're calling Crosspoint.
[00:10:49.620 --> 00:10:55.620]   This is going to be a joint venture with Crucial, a micron that makes the Crucial thing.
[00:10:55.620 --> 00:11:04.620]   And it's a new kind of memory that crosses the line between DRAM,
[00:11:04.620 --> 00:11:08.620]   traditional RAM, and storage, NAND storage.
[00:11:08.620 --> 00:11:14.620]   It's a thousand times faster than traditional NAND drives.
[00:11:14.620 --> 00:11:22.620]   It's not quite as fast as RAM, but it's fast enough to be used in lieu of RAM.
[00:11:22.620 --> 00:11:30.620]   So imagine instead of the traditional setup on a PC where you have storage that loads stuff into RAM that the CPU gets access to,
[00:11:30.620 --> 00:11:41.620]   and there's bottlenecks all along the way, instead you have a huge chunk of Crosspoint memory that might be terabytes that is used as RAM as well.
[00:11:41.620 --> 00:11:44.620]   And it does make sense in IOT where speed is not critical.
[00:11:44.620 --> 00:11:49.620]   It would greatly simplify IOT devices because you don't have to have discrete RAM and storage.
[00:11:49.620 --> 00:11:51.620]   It can all be one thing.
[00:11:51.620 --> 00:11:57.620]   Now Intel actually announced this. Intel and Micron announced this last year, believe it or not.
[00:11:57.620 --> 00:11:59.620]   I think they are announcing, did they announce a ship date?
[00:11:59.620 --> 00:12:00.620]   Is that what they...
[00:12:00.620 --> 00:12:03.620]   This year is the following.
[00:12:03.620 --> 00:12:09.620]   And the other thing is it's both a thousand times faster and it can last through a thousand times more data rights,
[00:12:09.620 --> 00:12:15.620]   which is interesting when you're upgrading algorithms and things like that for artificial intelligence.
[00:12:15.620 --> 00:12:20.620]   But it's a new type of memory, so yes, like you said.
[00:12:20.620 --> 00:12:23.620]   And this has been a 10-year effort.
[00:12:23.620 --> 00:12:35.620]   And again, this is why Intel, becoming a manufacturer is really interesting because they've spent a lot of money in effort thinking about new ways to just build chips.
[00:12:35.620 --> 00:12:40.620]   And 3D Crosspoint is a new way to build memory.
[00:12:40.620 --> 00:12:43.620]   So I think this is cool.
[00:12:43.620 --> 00:12:48.620]   I mean, I will always think semiconductor manufacturing is cool because I'm a big nerd.
[00:12:48.620 --> 00:13:00.620]   Well, and I think Kevin, you probably can weigh on in this, but this is the first fundamental architecture change in how computers work since the Alan Turing conceived of a Turing machine.
[00:13:00.620 --> 00:13:10.620]   I mean, the idea of having, of not having separate RAM, separate memory and separate storage, but of combining the two is amazing.
[00:13:10.620 --> 00:13:15.620]   Well, I mean, Turing's abstraction, we didn't really...
[00:13:15.620 --> 00:13:16.620]   He didn't mention...
[00:13:16.620 --> 00:13:18.620]   He didn't mention the storage in RAM.
[00:13:18.620 --> 00:13:19.620]   His was an imaginary take.
[00:13:19.620 --> 00:13:22.620]   But when we started building them, that's what we did.
[00:13:22.620 --> 00:13:29.620]   It's more of a challenge to the von Neumann architecture where with this emotion of a CPU that has a small number of registers,
[00:13:29.620 --> 00:13:33.620]   and then successive layers of slower storage outside there.
[00:13:33.620 --> 00:13:40.620]   So if you actually look at it, there's a sort of hierarchy of speed between the different layers of the stack,
[00:13:40.620 --> 00:13:42.620]   and this is blurring a couple of the layers.
[00:13:42.620 --> 00:13:46.620]   Because in a sense, SSDs are kind of... they're kind of RAM anyway.
[00:13:46.620 --> 00:13:48.620]   They're treating memory as if it was storage.
[00:13:48.620 --> 00:13:50.620]   Yeah, they're just slow RAM. They're random access though.
[00:13:50.620 --> 00:13:52.620]   Yeah, they're random access.
[00:13:52.620 --> 00:13:58.620]   You don't have the same performance penalty of seeking that you do with spending metal disks and things.
[00:13:58.620 --> 00:14:05.620]   But it's still... it's a layer of like... is it in the CPU?
[00:14:05.620 --> 00:14:09.620]   Is it on the chip? Is there a cache there? Is the cache there? As stuff fans out.
[00:14:09.620 --> 00:14:15.620]   And a lot of performance work is spent working on when things are moving from one cache to another in the stack.
[00:14:15.620 --> 00:14:21.620]   So, I'm not sure how big a difference it makes to actual engineering designs,
[00:14:21.620 --> 00:14:26.620]   because a lot of engineering is spent thinking about those transitions already.
[00:14:26.620 --> 00:14:31.620]   It's just... you know, here's why I'm thrilled to see it.
[00:14:31.620 --> 00:14:34.620]   I was a little worried about Intel, to be frank.
[00:14:34.620 --> 00:14:37.620]   And it's nice to see that they have been innovated.
[00:14:37.620 --> 00:14:42.620]   This reminds me a little bit of IBM in the day, where they really have deep R&D labs,
[00:14:42.620 --> 00:14:45.620]   and they have some really interesting stuff they're coming up with.
[00:14:45.620 --> 00:14:50.620]   Stacey, what is the sense at the conference, are people excited about these new technologies?
[00:14:50.620 --> 00:14:55.620]   Most people are here kind of sad because they feel like none of these things are ready to take off.
[00:14:55.620 --> 00:15:02.620]   In a sense that would mitigate some of the loss of the PC business, for example, are not lost.
[00:15:02.620 --> 00:15:06.620]   Well, no, I mean, you're right. I mean, it's been hurting Intel badly, right?
[00:15:06.620 --> 00:15:10.620]   So, yeah, and I do think that we're going to see...
[00:15:10.620 --> 00:15:16.620]   I don't know if Intel will be as big as it ever was, but I don't think it's going to go away.
[00:15:16.620 --> 00:15:22.620]   And they have... it'll be really interesting to see the fights that develop,
[00:15:22.620 --> 00:15:26.620]   because Intel's actually coming after almost everyone.
[00:15:26.620 --> 00:15:31.620]   They're like, "Okay, fine, we don't want anything at the edge, but we're coming after the gateway boxes.
[00:15:31.620 --> 00:15:35.620]   We're coming after the cellular ran business, radio access networks.
[00:15:35.620 --> 00:15:38.620]   We're coming after the cellular equipment business in the core of the network,
[00:15:38.620 --> 00:15:42.620]   and then again, where they've always been strong in the data center and in the cloud.
[00:15:42.620 --> 00:15:49.620]   But they are coming after with the FPGAs and the Nirvana by, they're like, "Ha ha, in video.
[00:15:49.620 --> 00:15:53.620]   We're coming after you." Intel and Nvidia had this little spat over benchmarking
[00:15:53.620 --> 00:15:55.620]   in the last couple days.
[00:15:55.620 --> 00:15:58.620]   Yeah, yeah. We'll see about that one.
[00:15:58.620 --> 00:16:00.620]   Yeah, I'm like...
[00:16:00.620 --> 00:16:04.620]   Yeah, I'm not sure I'd go head to head with Nvidia at this point.
[00:16:04.620 --> 00:16:11.620]   But I... so anything else... I mean, making arm chips is kind of amazing.
[00:16:11.620 --> 00:16:15.620]   This cross-point technology is very interesting, and the fact that it's so close, what else?
[00:16:15.620 --> 00:16:19.620]   I'm trying to think of the cool stuff that I have seen some fun things.
[00:16:19.620 --> 00:16:23.620]   I've been hanging around in the maker area, so I saw like toys battle.
[00:16:23.620 --> 00:16:27.620]   I mean, some of this is just stuff you see at every kind of maker-fare kind of conference,
[00:16:27.620 --> 00:16:28.620]   so I'm trying to think of...
[00:16:28.620 --> 00:16:30.620]   That real sense thing sounds really cool.
[00:16:30.620 --> 00:16:32.620]   Did anybody build anything with that?
[00:16:32.620 --> 00:16:35.620]   There's some robots. There's actually a robot.
[00:16:35.620 --> 00:16:39.620]   There's a demo here of a robot inventory management system.
[00:16:39.620 --> 00:16:43.620]   I know you guys are like, "Oh my God, kill me. I would have built battlebots."
[00:16:43.620 --> 00:16:46.620]   No, Amazon needs these, I'm sure.
[00:16:46.620 --> 00:16:50.620]   Yes, it's this robot that goes zooming along your shelves,
[00:16:50.620 --> 00:16:53.620]   and it scans to see what you're missing, what you have.
[00:16:53.620 --> 00:16:55.620]   It saves like a lot of work.
[00:16:55.620 --> 00:17:00.620]   Yeah. If Walmart's going to compete with Amazon, which they apparently want to do,
[00:17:00.620 --> 00:17:06.620]   they're going to need some way to make it possible to use their stores as fulfillment centers or something.
[00:17:06.620 --> 00:17:08.620]   So maybe this is what that's aimed at.
[00:17:08.620 --> 00:17:09.620]   There you go.
[00:17:09.620 --> 00:17:11.620]   Oh, go ahead.
[00:17:11.620 --> 00:17:14.620]   I was going to say Intel finally delivered on their silicon photonics.
[00:17:14.620 --> 00:17:15.620]   What's that?
[00:17:15.620 --> 00:17:19.620]   I mean, silicon photonics is light waves on a chip,
[00:17:19.620 --> 00:17:22.620]   including data with light instead of electrons.
[00:17:22.620 --> 00:17:23.620]   Wow.
[00:17:23.620 --> 00:17:28.620]   So they had missed a couple deadlines, but finally today they showed it,
[00:17:28.620 --> 00:17:34.620]   and it's a little laser integrated onto a chip, and it's like zoop, zoop,
[00:17:34.620 --> 00:17:37.620]   and things go really fast.
[00:17:37.620 --> 00:17:38.620]   Wow.
[00:17:38.620 --> 00:17:40.620]   That was my scientific explanation.
[00:17:40.620 --> 00:17:45.620]   Here's a scientific explanation on the relative speeds of cross point versus hard drives.
[00:17:45.620 --> 00:17:49.620]   In the time it takes a hard drive, if a storage device were a runner,
[00:17:49.620 --> 00:17:52.620]   to sprint the length of a basketball court,
[00:17:52.620 --> 00:17:56.620]   NAND memory, solid state drives, could run a marathon,
[00:17:56.620 --> 00:18:00.620]   and X-Point technology could circle the globe.
[00:18:00.620 --> 00:18:03.620]   Oh, that's my point.
[00:18:03.620 --> 00:18:04.620]   I hate this.
[00:18:04.620 --> 00:18:06.620]   It's so marketing.
[00:18:06.620 --> 00:18:08.620]   But I like it.
[00:18:08.620 --> 00:18:12.620]   Maybe it's because I spent a lot of my helps trying to explain stuff to real people.
[00:18:12.620 --> 00:18:14.620]   How many chips do you pile upon each other?
[00:18:14.620 --> 00:18:16.620]   They're going to tell them we get you to the moon.
[00:18:16.620 --> 00:18:17.620]   Yeah.
[00:18:17.620 --> 00:18:20.620]   Well, that is one of the things that's interesting, actually about cross point technology,
[00:18:20.620 --> 00:18:23.620]   is it's a lot more dense than a D-Ray,
[00:18:23.620 --> 00:18:28.620]   8 to 10 times more dense, because they're doing this kind of stacked layers of memory.
[00:18:28.620 --> 00:18:32.620]   So you're going to get a lot of storage in a very small space.
[00:18:32.620 --> 00:18:35.620]   And stacking is the new way to get around Moore's law.
[00:18:35.620 --> 00:18:36.620]   Maybe we need a stacking law.
[00:18:36.620 --> 00:18:37.620]   Oh, interesting.
[00:18:37.620 --> 00:18:38.620]   Oh, really?
[00:18:38.620 --> 00:18:39.620]   Oh.
[00:18:39.620 --> 00:18:41.620]   Instead of trying to increase density in two dimensions,
[00:18:41.620 --> 00:18:44.620]   they're putting more layers on top of each other and cross-connecting them.
[00:18:44.620 --> 00:18:45.620]   Yeah.
[00:18:45.620 --> 00:18:46.620]   Right.
[00:18:46.620 --> 00:18:48.620]   I think this is really exciting.
[00:18:48.620 --> 00:18:50.620]   I hope this isn't pie in the sky.
[00:18:50.620 --> 00:18:53.620]   I hope it's not like the equivalent of nuclear fusion.
[00:18:53.620 --> 00:18:56.620]   It seems to me this could completely change computing.
[00:18:56.620 --> 00:19:01.620]   And IoT, big time, because this is something that can last a really long time,
[00:19:01.620 --> 00:19:05.620]   use very little battery, and it's cheap and not complex to make,
[00:19:05.620 --> 00:19:07.620]   is exactly what you need for IoT.
[00:19:07.620 --> 00:19:10.620]   I don't know that it's not complex to make.
[00:19:10.620 --> 00:19:14.620]   Well, well, I'm sure it is initially, and it's not cheap initially.
[00:19:14.620 --> 00:19:19.620]   But I'm assuming Moore's new law will lower the price of this.
[00:19:19.620 --> 00:19:20.620]   Chris Annich's law.
[00:19:20.620 --> 00:19:21.620]   Chris Annich's law.
[00:19:21.620 --> 00:19:22.620]   I like it.
[00:19:22.620 --> 00:19:23.620]   I'm trying to think of the CEO of Micron.
[00:19:23.620 --> 00:19:24.620]   We could--
[00:19:24.620 --> 00:19:25.620]   Merti's law.
[00:19:25.620 --> 00:19:26.620]   I'm on a whole league.
[00:19:26.620 --> 00:19:27.620]   You had Murphy's law.
[00:19:27.620 --> 00:19:29.620]   Now you have Merti's law.
[00:19:29.620 --> 00:19:30.620]   Yeah.
[00:19:30.620 --> 00:19:32.620]   You just tell him, "Make a law."
[00:19:32.620 --> 00:19:34.620]   It doesn't matter what it is.
[00:19:34.620 --> 00:19:35.620]   It'll catch on.
[00:19:35.620 --> 00:19:38.620]   So we're going to take a break, but I'm curious.
[00:19:38.620 --> 00:19:42.620]   I want you to, Jeff, explain why journalism school, because--
[00:19:42.620 --> 00:19:44.620]   Oh, you're on the hook.
[00:19:44.620 --> 00:19:48.620]   I let you off the hook, but I'm going to put you back on that hook.
[00:19:48.620 --> 00:19:49.620]   All right.
[00:19:49.620 --> 00:19:53.620]   Just a second, especially since my son says, "Mm, maybe I will go to J School."
[00:19:53.620 --> 00:19:56.620]   Our show today brought to you by the new automatic.
[00:19:56.620 --> 00:19:57.620]   Did you have one there?
[00:19:57.620 --> 00:19:58.620]   Did you see it?
[00:19:58.620 --> 00:19:59.620]   Stacy?
[00:19:59.620 --> 00:20:02.620]   No, I haven't seen the new one.
[00:20:02.620 --> 00:20:05.620]   I just-- I've seen them before and played with them.
[00:20:05.620 --> 00:20:07.620]   Well, I love the old automatic.
[00:20:07.620 --> 00:20:09.620]   I have them in all my cars.
[00:20:09.620 --> 00:20:16.620]   The idea of the automatic, of course, is it uses the OBD2 port in your car, which every car built since 1996, even my Tesla has.
[00:20:16.620 --> 00:20:18.620]   It's right under the steering wheel.
[00:20:18.620 --> 00:20:19.620]   You'll see it there.
[00:20:19.620 --> 00:20:25.620]   You connect the OBD2 device, the automatic, onto that, and pair it with your phone by Bluetooth.
[00:20:25.620 --> 00:20:29.620]   Now, your car is part of your quantified life.
[00:20:29.620 --> 00:20:32.620]   It's the obvious thing.
[00:20:32.620 --> 00:20:36.620]   When a check engine light comes on, you can see what's going on.
[00:20:36.620 --> 00:20:39.620]   Actually, the app is very cool because it'll also tell you the nearest repair shop.
[00:20:39.620 --> 00:20:41.620]   But it does a whole lot more.
[00:20:41.620 --> 00:20:57.620]   It'll keep track of-- for instance, it'll pair gas usage, accelerator usage, brake usage, and put it all together in a little trip packet that I have with this and that uploading to my Evernote.
[00:20:57.620 --> 00:21:06.620]   So every time I take a trip to my car, I know exactly how much it costs, how many times I brake hard, how many times I went to accelerate it too fast, exactly the map of my trip.
[00:21:06.620 --> 00:21:08.620]   It's really awesome.
[00:21:08.620 --> 00:21:09.620]   This is even better.
[00:21:09.620 --> 00:21:12.620]   The new, get ready, automatic pro is here.
[00:21:12.620 --> 00:21:13.620]   What are they adding?
[00:21:13.620 --> 00:21:15.620]   What could you possibly add to something that's so perfect?
[00:21:15.620 --> 00:21:16.620]   3G.
[00:21:16.620 --> 00:21:17.620]   Dun, dun, dun.
[00:21:17.620 --> 00:21:21.620]   Unlimited 3G with no subscription.
[00:21:21.620 --> 00:21:23.620]   What?
[00:21:23.620 --> 00:21:26.620]   Oh, it's built into the price of the automatic.
[00:21:26.620 --> 00:21:29.620]   So I guess it's like the Kindle whisper thing, right?
[00:21:29.620 --> 00:21:31.620]   When Amazon was doing that.
[00:21:31.620 --> 00:21:33.620]   So the adapter plugs in.
[00:21:33.620 --> 00:21:37.620]   Your driving data is relayed over 3G.
[00:21:37.620 --> 00:21:40.620]   You could track everything in your automatic pro app.
[00:21:40.620 --> 00:21:45.620]   And because it's on 3G, you could do crash alerts, trained responders.
[00:21:45.620 --> 00:21:49.620]   This is like, you know, like on-stars on the Ready 24/7.
[00:21:49.620 --> 00:21:54.620]   Contact you and emergency services and loved ones if there's a serious accident.
[00:21:54.620 --> 00:21:55.620]   What?
[00:21:55.620 --> 00:21:57.620]   This is so cool.
[00:21:57.620 --> 00:21:59.620]   You'll know where your car is all the time.
[00:21:59.620 --> 00:22:05.620]   Now this is something I love about the Tesla app is I could see a map when Lisa takes my car off where she is.
[00:22:05.620 --> 00:22:07.620]   Now the automatic will do that too.
[00:22:07.620 --> 00:22:09.620]   It makes your car so smart.
[00:22:09.620 --> 00:22:14.620]   It gives you so much information about what's going on in your car.
[00:22:14.620 --> 00:22:17.620]   Literally a map of where your car is right now.
[00:22:17.620 --> 00:22:19.620]   There are lots of apps too.
[00:22:19.620 --> 00:22:25.620]   If you've got a team driver, you can use the automatic pro or the regular automatic to help them be better drivers.
[00:22:25.620 --> 00:22:30.620]   Even an Android turn off texting during their trip.
[00:22:30.620 --> 00:22:32.620]   You can see all the apps that it pairs with your Nest.
[00:22:32.620 --> 00:22:34.620]   It'll turn on the thermostat when you're on your way home.
[00:22:34.620 --> 00:22:38.620]   If this than that, you can ask your Amazon Echo how much gas is left in the car.
[00:22:38.620 --> 00:22:43.620]   If you track business expenses, you can use Concur, Expensify, FreshBooks.
[00:22:43.620 --> 00:22:46.620]   They all interface to the automatic.
[00:22:46.620 --> 00:22:49.620]   You can keep track of business mileage automatically.
[00:22:49.620 --> 00:22:53.620]   You can even tie it to your job own up.
[00:22:53.620 --> 00:22:55.620]   I'm not sure how that would work.
[00:22:55.620 --> 00:22:57.620]   You walk two miles, but you drove 43.
[00:22:57.620 --> 00:22:58.620]   I don't know.
[00:22:58.620 --> 00:23:00.620]   Really neat stuff.
[00:23:00.620 --> 00:23:01.620]   Are you interested?
[00:23:01.620 --> 00:23:06.620]   Go to automatic.com/twit for more information.
[00:23:06.620 --> 00:23:09.620]   The automatic pro now you'd expect is to cost a lot more.
[00:23:09.620 --> 00:23:12.620]   The base automatic, 99.95.
[00:23:12.620 --> 00:23:15.620]   The automatic pro, $129.95.
[00:23:15.620 --> 00:23:16.620]   That's all.
[00:23:16.620 --> 00:23:19.620]   When you use our exclusive offer code TWIT, you'll save $20.
[00:23:19.620 --> 00:23:23.620]   That pretty much brings it down to the original price.
[00:23:23.620 --> 00:23:28.620]   You're getting all that extra functionality basically for free.
[00:23:28.620 --> 00:23:33.620]   Automatic.com/twit.
[00:23:33.620 --> 00:23:35.620]   Time for your new automatic.
[00:23:35.620 --> 00:23:38.620]   I am so excited about this.
[00:23:38.620 --> 00:23:39.620]   I really am.
[00:23:39.620 --> 00:23:41.620]   You knew about it already.
[00:23:41.620 --> 00:23:43.620]   They must have announced it earlier.
[00:23:43.620 --> 00:23:45.620]   They announced it today.
[00:23:45.620 --> 00:23:51.620]   Another note about this from a news not necessarily a selling on people perspective,
[00:23:51.620 --> 00:23:56.620]   but automatic is funded in part by USAA, the insurance company.
[00:23:56.620 --> 00:24:03.620]   Having the 3G capability is essential for being used for any sort of insurance efforts.
[00:24:03.620 --> 00:24:06.620]   My hunch is, we'll see this soon.
[00:24:06.620 --> 00:24:09.620]   I'm a USAA insurance customer.
[00:24:09.620 --> 00:24:12.620]   I have a USAA investment in banking account too.
[00:24:12.620 --> 00:24:14.620]   That's great.
[00:24:14.620 --> 00:24:16.620]   I knew they were an investor, but that's really good.
[00:24:16.620 --> 00:24:21.620]   Automatic, just like it sounds, automatic.com/twit.
[00:24:21.620 --> 00:24:23.620]   Find out about the new automatic pro.
[00:24:23.620 --> 00:24:26.620]   That is really, really awesome.
[00:24:26.620 --> 00:24:28.620]   Really, really awesome.
[00:24:28.620 --> 00:24:31.620]   Back we come to this week in Google.
[00:24:31.620 --> 00:24:35.620]   Anything else before we move on from the Intel developers forums, Tacey?
[00:24:35.620 --> 00:24:37.620]   Have you ever seen anything happening behind me?
[00:24:37.620 --> 00:24:39.620]   Somebody sneaking up behind you.
[00:24:39.620 --> 00:24:44.620]   She's in the press room right now.
[00:24:44.620 --> 00:24:45.620]   I am.
[00:24:45.620 --> 00:24:48.620]   You can tell because no one here is well dressed.
[00:24:48.620 --> 00:24:50.620]   Except the waiter who was walking by and talking to him.
[00:24:50.620 --> 00:24:54.620]   If they had only gone to J-school, they'd be well dressed, right, Jeff Jarvis?
[00:24:54.620 --> 00:24:57.620]   Yeah, you bet.
[00:24:57.620 --> 00:24:59.620]   So I got an undergrad degree at Northwestern.
[00:24:59.620 --> 00:25:00.620]   I did not get a graduate degree.
[00:25:00.620 --> 00:25:01.620]   I got jobs.
[00:25:01.620 --> 00:25:02.620]   A couple things.
[00:25:02.620 --> 00:25:04.620]   In my day, young children.
[00:25:04.620 --> 00:25:07.620]   In my day, you know, the way you worked up was that I went to work for the Berlin,
[00:25:07.620 --> 00:25:10.620]   and I will Hawkeye, and the Great Free Press, and I worked up and up and up and up.
[00:25:10.620 --> 00:25:13.620]   Chicago Tribune's, I was just going to say, "I'm going to say I'm going to tie a mink."
[00:25:13.620 --> 00:25:15.620]   That's how you got the added training.
[00:25:15.620 --> 00:25:16.620]   That doesn't exist anymore.
[00:25:16.620 --> 00:25:18.620]   That path doesn't exist.
[00:25:18.620 --> 00:25:24.620]   One, two, a lot of our students, our median age is 26, 27.
[00:25:24.620 --> 00:25:26.620]   A lot of our students are career changers.
[00:25:26.620 --> 00:25:31.620]   So they're coming to graduate school in journalism to start in journalism, which makes a great deal of sense.
[00:25:31.620 --> 00:25:38.620]   If you have an undergrad degree in journalism, what we're finding is people are coming back even later in their career,
[00:25:38.620 --> 00:25:42.620]   some right out of college, some later because they want to considerably advance their skills.
[00:25:42.620 --> 00:25:44.620]   That's what I told Henry to do.
[00:25:44.620 --> 00:25:46.620]   I said, "Get some real-world experience."
[00:25:46.620 --> 00:25:51.620]   He wants to work for Vice this summer as an internship, something like that.
[00:25:51.620 --> 00:25:52.620]   I said, "That's great."
[00:25:52.620 --> 00:25:54.620]   He wants to, I think he wants to be more in production.
[00:25:54.620 --> 00:25:58.620]   I said, "That's not a less of a writer, more of video."
[00:25:58.620 --> 00:26:02.620]   He looks at me and says, "Boy, what you got is an easy job, so I want to do that."
[00:26:02.620 --> 00:26:10.620]   I think he fantasizes about taking a twit over in a couple of years.
[00:26:10.620 --> 00:26:12.620]   Well, it's kind of neat to train him.
[00:26:12.620 --> 00:26:15.620]   If you look at some of the families that have trained their own-
[00:26:15.620 --> 00:26:16.620]   Absolutely.
[00:26:16.620 --> 00:26:19.620]   ...hearers like the new houses in advance and so on.
[00:26:19.620 --> 00:26:21.620]   The DeSullinsburgers.
[00:26:21.620 --> 00:26:22.620]   The Murdochs.
[00:26:22.620 --> 00:26:23.620]   They get-
[00:26:23.620 --> 00:26:24.620]   Yeah, they're great.
[00:26:24.620 --> 00:26:27.620]   They get certain jobs as they go and learn the way up.
[00:26:27.620 --> 00:26:31.620]   If you ever want me to talk to Henry about-
[00:26:31.620 --> 00:26:32.620]   I would.
[00:26:32.620 --> 00:26:33.620]   ...he was in career as a little.
[00:26:33.620 --> 00:26:35.620]   I'd really be more than happy to sit down with him.
[00:26:35.620 --> 00:26:39.620]   I told him all about you and I told him all about Jake too.
[00:26:39.620 --> 00:26:45.620]   I said, "Jeff's great guy and he will be a very good mentor for you."
[00:26:45.620 --> 00:26:46.620]   The Bradley's.
[00:26:46.620 --> 00:26:49.620]   I don't know if I answered Stacey or not.
[00:26:49.620 --> 00:26:51.620]   You have yet to convince me.
[00:26:51.620 --> 00:26:53.620]   I'm sorry.
[00:26:53.620 --> 00:26:56.620]   Did you get a journalism degree, Stacey?
[00:26:56.620 --> 00:26:57.620]   I did.
[00:26:57.620 --> 00:27:00.620]   I have a B.J. from the University of Austin.
[00:27:00.620 --> 00:27:01.620]   Nice.
[00:27:01.620 --> 00:27:03.620]   Or a University of Texas at Austin.
[00:27:03.620 --> 00:27:04.620]   Yeah.
[00:27:04.620 --> 00:27:09.620]   But the idea of going back to school in journalism seems strange.
[00:27:09.620 --> 00:27:15.620]   Well, I think if you were lucky enough to have somebody like Jeff as a professor that would change the equation.
[00:27:15.620 --> 00:27:22.620]   Because of course, journalism is changing rapidly and probably a lot of journalism schools are trying to figure it out.
[00:27:22.620 --> 00:27:24.620]   I have no idea.
[00:27:24.620 --> 00:27:25.620]   That's true.
[00:27:25.620 --> 00:27:26.620]   Here's how you write a lead.
[00:27:26.620 --> 00:27:30.620]   Here's how you file your copy.
[00:27:30.620 --> 00:27:37.620]   But I think when you have somebody like Jeff who's definitely got his finger on the pulse of what's happening and what's changing.
[00:27:37.620 --> 00:27:43.620]   It's also if you're someone like Stacey at All sincerity, you're teaching yourself, you're working at places where you're in vidney.
[00:27:43.620 --> 00:27:44.620]   This is the vidney new things.
[00:27:44.620 --> 00:27:51.620]   A lot of people who go out of J School land in newspapers that aren't changing.
[00:27:51.620 --> 00:27:55.620]   And the only way they can get these new and they're not training anybody.
[00:27:55.620 --> 00:27:57.620]   They're not updating your skills at all.
[00:27:57.620 --> 00:28:02.620]   So the only way they're going to get to learn about new stuff is to go to school.
[00:28:02.620 --> 00:28:03.620]   Could you teach it all yourself?
[00:28:03.620 --> 00:28:05.620]   Yeah, you could, but you're busy as hell.
[00:28:05.620 --> 00:28:08.620]   You know, being forced to write 87 blog posts a day.
[00:28:08.620 --> 00:28:11.620]   It's the way you break out and try to move up in the world.
[00:28:11.620 --> 00:28:19.620]   And then also these days, you know, I just, when I brainwashed the class today, you know, I took them through all kinds of new jobs that didn't exist five years ago.
[00:28:19.620 --> 00:28:21.620]   Product development is a huge new field.
[00:28:21.620 --> 00:28:23.620]   Audience development, though I hate the title, is important.
[00:28:23.620 --> 00:28:26.620]   Social media, web video, data journalism.
[00:28:26.620 --> 00:28:31.620]   These are all specialties where we've got, frankly, got to do a better job too of teaching greater specialty.
[00:28:31.620 --> 00:28:34.620]   Giving every student, it's what I call skills transcript.
[00:28:34.620 --> 00:28:38.620]   That every student has to have a certain level of skills across a wide range of things now.
[00:28:38.620 --> 00:28:45.620]   Every student has to know social media and data and obviously the web and web video and so on.
[00:28:45.620 --> 00:28:51.620]   But then they need, in our research with employers, they need what we call superpowers.
[00:28:51.620 --> 00:28:52.620]   You need at least one.
[00:28:52.620 --> 00:28:57.620]   You need to be really good at all of that and plus knowing stories and knowing how to do facts and all that.
[00:28:57.620 --> 00:29:08.620]   But you also might need to be a specialist in audience development or in social media or in web video so that you have that extra value in getting a job.
[00:29:08.620 --> 00:29:15.620]   And so they can come and they can concentrate enough or become a documentary filmmaker or whatever the hell they want.
[00:29:15.620 --> 00:29:17.620]   I would really love to learn data journalism.
[00:29:17.620 --> 00:29:20.620]   If I were to go back to school right now, I think that's fascinating.
[00:29:20.620 --> 00:29:23.620]   There's a new kind of investigative reporting.
[00:29:23.620 --> 00:29:24.620]   Yes.
[00:29:24.620 --> 00:29:31.620]   There's a San Marcos, Texas State University, which is not like LBJ's home school.
[00:29:31.620 --> 00:29:32.620]   Yes.
[00:29:32.620 --> 00:29:39.620]   So they actually have a data journalism master's program and I've actually thought about, I'm like,
[00:29:39.620 --> 00:29:41.620]   "Why didn't you love that one?"
[00:29:41.620 --> 00:29:51.620]   See now that we're all working, it seems like sex to luxury to be able to take a year or two and go to school would be an incredible luxury.
[00:29:51.620 --> 00:29:52.620]   Yes.
[00:29:52.620 --> 00:29:58.620]   I'm like, "Can I just take some of these classes every now and then and work on it while I actually do my job?"
[00:29:58.620 --> 00:30:00.620]   You might be able to.
[00:30:00.620 --> 00:30:02.620]   No, no, they're actually, I've talked to them before.
[00:30:02.620 --> 00:30:09.620]   We did, I've done some projects with local journalists down here and they're like, "Yes, you should come."
[00:30:09.620 --> 00:30:10.620]   So, one day.
[00:30:10.620 --> 00:30:15.620]   Yeah, because that's the chance to go through stats and data and visualization and all that too.
[00:30:15.620 --> 00:30:16.620]   There's great programs there.
[00:30:16.620 --> 00:30:19.620]   Plus, we have an entrepreneurial program where you learn to start a business and do so.
[00:30:19.620 --> 00:30:22.620]   The new social journalism program where we can reinvent journalism.
[00:30:22.620 --> 00:30:24.620]   I'm working on a new degree right now.
[00:30:24.620 --> 00:30:30.620]   So, yeah, if I thought that I were leading students astray, I'd obviously be a horrible fraud.
[00:30:30.620 --> 00:30:34.620]   But one thing I haven't learned in journalism school is how to adjust this camera.
[00:30:34.620 --> 00:30:36.620]   You should teach that.
[00:30:36.620 --> 00:30:44.620]   Actually, I was, you could also use data, big data, journalism and investigative journalism for advocacy purposes.
[00:30:44.620 --> 00:30:53.620]   I was just reading about Mr. Trump's new campaign manager who is former, was he executive editor at the University of Michigan?
[00:30:53.620 --> 00:30:56.620]   He's the executive editor, chairman of Bright Bar.
[00:30:56.620 --> 00:30:58.620]   Chairman of Bright Bar.
[00:30:58.620 --> 00:31:11.620]   So, he is obviously a smart fellow because besides doing the advocacy blogging at Bright Bar, which is very clearly aimed at promoting an agenda,
[00:31:11.620 --> 00:31:22.620]   he also created a foundation to do, and spent money on trying to get deep data information that they could then go to mainstream press like the New York Times with.
[00:31:22.620 --> 00:31:26.620]   And say, look, we've dug up the data here.
[00:31:26.620 --> 00:31:30.620]   And that wins them over in the way that the advocacy does not.
[00:31:30.620 --> 00:31:33.620]   Steve Bannon, he says, "Naman."
[00:31:33.620 --> 00:31:35.620]   Jay Rosen wrote it.
[00:31:35.620 --> 00:31:36.620]   I mean, I'm sorry not Jay Rosen.
[00:31:36.620 --> 00:31:37.620]   He linked to something today.
[00:31:37.620 --> 00:31:43.620]   Ben Smith, the editor of Buzzfeed, I'm putting it on the feed right now, wrote a good piece today,
[00:31:43.620 --> 00:31:48.620]   arguing that this is the final merger of media and campaigns.
[00:31:48.620 --> 00:31:49.620]   Interesting.
[00:31:49.620 --> 00:31:55.620]   But you know what, that happened a long time ago with Carl Rove and Roger Ailes.
[00:31:55.620 --> 00:32:02.620]   I mean, I remember when Nixon used admin, it was like, "Oh my God, what a revolution."
[00:32:02.620 --> 00:32:08.620]   And now it's like, that's clearly how you have to win a campaign.
[00:32:08.620 --> 00:32:12.620]   I don't know, we got a little sidetracked on the journalism.
[00:32:12.620 --> 00:32:14.620]   Stacey's fault, Blame Stacey.
[00:32:14.620 --> 00:32:17.620]   You know what, I love talking about this stuff.
[00:32:17.620 --> 00:32:19.620]   I think it's...
[00:32:19.620 --> 00:32:21.620]   Did you see the Mother Jones thing today?
[00:32:21.620 --> 00:32:25.620]   Oh, about the prisons and the cost of reporting the story?
[00:32:25.620 --> 00:32:26.620]   Yeah, that was interesting.
[00:32:26.620 --> 00:32:29.620]   So basically, they wrote it in the chat room.
[00:32:29.620 --> 00:32:35.620]   But they wrote a piece about, you know, they did that great investigative work on private prisons.
[00:32:35.620 --> 00:32:39.620]   And it basically was like an 18 month journalism project.
[00:32:39.620 --> 00:32:43.620]   And they say it cost them about $350,000 to do.
[00:32:43.620 --> 00:32:47.620]   And they got about $5,000 in advertising on it, despite getting a million views.
[00:32:47.620 --> 00:32:51.620]   And so they're saying, "We want to keep doing this.
[00:32:51.620 --> 00:32:54.620]   And the way we're going to keep doing this is if you pay us to keep doing it.
[00:32:54.620 --> 00:33:01.620]   So please sign up for subscriptions to us at $15 a month and support us doing this kind of work."
[00:33:01.620 --> 00:33:05.620]   So they're basically going for the NPR model, which is, you know...
[00:33:05.620 --> 00:33:07.620]   Yeah, which the Guardian is doing as well.
[00:33:07.620 --> 00:33:11.620]   A cast finder at the end of the Guardian wrote a wonderful piece, basically saying, "Here's why you need us."
[00:33:11.620 --> 00:33:15.620]   And their membership plan has kind of shifted toward patronage.
[00:33:15.620 --> 00:33:19.620]   And I think there isn't enough patronage to support all the journalism in the world,
[00:33:19.620 --> 00:33:22.620]   but the fine journalism, like Mother Jones and the Guardian.
[00:33:22.620 --> 00:33:25.620]   And when I pay the New York Times, I'm paying them not to get access to content.
[00:33:25.620 --> 00:33:27.620]   I'm paying them out of patronage and on a support.
[00:33:27.620 --> 00:33:28.620]   No, is that right?
[00:33:28.620 --> 00:33:34.620]   And yet, didn't the Wall Street Journal just the other day, and I saw you gloating about this in Facebook?
[00:33:34.620 --> 00:33:36.620]   No, I said I wasn't gloating.
[00:33:36.620 --> 00:33:40.620]   Whereby, I was gloating.
[00:33:40.620 --> 00:33:41.620]   #gloating.
[00:33:41.620 --> 00:33:45.620]   I'm gloating.
[00:33:45.620 --> 00:33:48.620]   It has started to restructure its paywall.
[00:33:48.620 --> 00:33:50.620]   You've ricked some of the wall there.
[00:33:50.620 --> 00:33:53.620]   Yeah, giving people more ways to read without paying.
[00:33:53.620 --> 00:33:56.620]   It passes and social links and that kind of stuff.
[00:33:56.620 --> 00:33:58.620]   Yeah, and there was also a piece of...
[00:33:58.620 --> 00:34:00.620]   Does that mean that their paywall isn't working for them?
[00:34:00.620 --> 00:34:03.620]   Because if it doesn't work for the Wall Street Journal, it won't work for anybody.
[00:34:03.620 --> 00:34:06.620]   It means that there are things they can't do, right?
[00:34:06.620 --> 00:34:11.620]   The reason they had to buy market watch way back in the day was to get more reach so they could get that kind of advertising.
[00:34:11.620 --> 00:34:15.620]   They want to get more conversion and more sampling so they need to get more people in.
[00:34:15.620 --> 00:34:21.620]   They want to reduce the cost of their subscriber acquisition cost, whether you're a magazine or a website.
[00:34:21.620 --> 00:34:22.620]   You have to pay to market.
[00:34:22.620 --> 00:34:25.620]   So if you people will sample your content, that's a hell of a lot more efficient.
[00:34:25.620 --> 00:34:36.620]   So in a sense, giving up some money in the paywall for day passes or sampling or social links is a way to get people in as marketing.
[00:34:36.620 --> 00:34:43.620]   There was another piece just out this week that said that basically apart from the New York Times and the Journal at all,
[00:34:43.620 --> 00:34:45.620]   paywalls are not working for newspapers.
[00:34:45.620 --> 00:34:46.620]   That was...
[00:34:46.620 --> 00:34:48.620]   They're not tech-jerk, wasn't it? Yeah.
[00:34:48.620 --> 00:34:49.620]   Yeah.
[00:34:49.620 --> 00:34:51.620]   Well, I'm not surprised.
[00:34:51.620 --> 00:34:57.620]   I mean, there is the counter example of people like, I think that's working Jessica Lesson and Ben Thompson,
[00:34:57.620 --> 00:34:59.620]   it's a trajectory, Jessica Lesson.
[00:34:59.620 --> 00:35:00.620]   It's a very high level.
[00:35:00.620 --> 00:35:02.620]   Yeah, but I mean, well, okay.
[00:35:02.620 --> 00:35:12.620]   Admittedly, and she's $400 a year and doesn't need more than maybe a few thousand subscribers for it to be sensible and profitable.
[00:35:12.620 --> 00:35:16.620]   She could stand a few more bricks out of the wall because I haven't paid the 400 for Jessica.
[00:35:16.620 --> 00:35:17.620]   That's the problem.
[00:35:17.620 --> 00:35:20.620]   That's why you take the bricks out of the wall. There's a promotional value.
[00:35:20.620 --> 00:35:22.620]   And that's what Ben Thompson does.
[00:35:22.620 --> 00:35:27.620]   He gives away a considerable number of one article a week and then you pay and you get more.
[00:35:27.620 --> 00:35:32.620]   Does anybody also have a windowing strategy or where you get them later or is that someone else?
[00:35:32.620 --> 00:35:33.620]   I don't know if he does.
[00:35:33.620 --> 00:35:36.620]   I think Philip Elmer DeWitt that we were talking to.
[00:35:36.620 --> 00:35:37.620]   Oh, that's who...
[00:35:37.620 --> 00:35:38.620]   Okay, yes, sorry.
[00:35:38.620 --> 00:35:39.620]   His Apple 2.0 blog.
[00:35:39.620 --> 00:35:43.620]   Philip, of course, was at Fortune, as were you, I know.
[00:35:43.620 --> 00:35:47.620]   And left not so long ago to create a blog.
[00:35:47.620 --> 00:35:48.620]   And that's exactly what he does.
[00:35:48.620 --> 00:35:52.620]   It's free to read after a few days.
[00:35:52.620 --> 00:35:55.620]   So, you know, we need all these different...
[00:35:55.620 --> 00:35:57.620]   This would happen with podcasting.
[00:35:57.620 --> 00:36:01.620]   We had to figure out all these different ways to monetize and to figure out which ones work.
[00:36:01.620 --> 00:36:08.620]   The nice thing about podcasting, our advantage in podcasting is we can do ads that are not completely annoying and they don't carry malware.
[00:36:08.620 --> 00:36:16.620]   I mean, I think we can do ads that serve our audience to some degree as well as the content.
[00:36:16.620 --> 00:36:18.620]   But they're less trackable.
[00:36:18.620 --> 00:36:22.620]   Yeah, and so far that doesn't matter so much.
[00:36:22.620 --> 00:36:26.620]   What it does to our advertisers, what it does mean is that advertisers are going to...
[00:36:26.620 --> 00:36:34.620]   It may mean we'll never get out from under direct response ads that we won't be able to get much brand advertising, some say.
[00:36:34.620 --> 00:36:35.620]   I disagree.
[00:36:35.620 --> 00:36:40.620]   And I think brands really can't track TV ads either.
[00:36:40.620 --> 00:36:45.620]   They're used to doing research and figuring out whether the ads are working.
[00:36:45.620 --> 00:36:48.620]   I don't think trackable...
[00:36:48.620 --> 00:36:51.620]   You can track a banner ad really well, right?
[00:36:51.620 --> 00:36:53.620]   Does that help them be more effective?
[00:36:53.620 --> 00:36:54.620]   I don't think so.
[00:36:54.620 --> 00:36:55.620]   No.
[00:36:55.620 --> 00:36:57.620]   And neither neither native advertising.
[00:36:57.620 --> 00:36:59.620]   How trackable is that?
[00:36:59.620 --> 00:37:03.620]   The holy grail is to get from ad to intent.
[00:37:03.620 --> 00:37:05.620]   And to purchase obviously.
[00:37:05.620 --> 00:37:07.620]   I always say it's extremely hard to...
[00:37:07.620 --> 00:37:12.620]   If we don't produce a return on investment for our advertisers, they shouldn't buy ads with us.
[00:37:12.620 --> 00:37:13.620]   Right.
[00:37:13.620 --> 00:37:16.620]   And ultimately, that's the final metric.
[00:37:16.620 --> 00:37:18.620]   It's the only metric that matters.
[00:37:18.620 --> 00:37:19.620]   And they just have to have some...
[00:37:19.620 --> 00:37:22.620]   You know, we consider Leo opening up a store...
[00:37:22.620 --> 00:37:24.620]   We're back in the days of the trio blog.
[00:37:24.620 --> 00:37:26.620]   And it was a great blog and it was amazing.
[00:37:26.620 --> 00:37:28.620]   There was a blog about one product.
[00:37:28.620 --> 00:37:31.620]   But I was a fanatic trio user in the day.
[00:37:31.620 --> 00:37:32.620]   So you read it?
[00:37:32.620 --> 00:37:33.620]   It's a whole IAM children.
[00:37:33.620 --> 00:37:34.620]   Yeah.
[00:37:34.620 --> 00:37:39.620]   And he started opening up a store selling accessories, cases and all that stuff.
[00:37:39.620 --> 00:37:41.620]   And that became the core of the business.
[00:37:41.620 --> 00:37:45.620]   And for the trio and then a few of the follow-up things, I don't know what happened to them.
[00:37:45.620 --> 00:37:47.620]   But the notion of commerce.
[00:37:47.620 --> 00:37:51.620]   Have you ever thought of just using Best Buy Amazon APIs and...
[00:37:51.620 --> 00:37:52.620]   You've done that.
[00:37:52.620 --> 00:37:53.620]   ...and started a commerce opportunity?
[00:37:53.620 --> 00:37:54.620]   I think we do that.
[00:37:54.620 --> 00:37:55.620]   I think...
[00:37:55.620 --> 00:37:56.620]   So a couple of things.
[00:37:56.620 --> 00:37:58.620]   We used to have a...
[00:37:58.620 --> 00:38:00.620]   I think we might still have a page that says
[00:38:00.620 --> 00:38:04.620]   "Not only here are our sponsors, but if you want to support us by this through this Amazon link..."
[00:38:04.620 --> 00:38:05.620]   Oh, okay.
[00:38:05.620 --> 00:38:09.620]   We used to have a product picks page.
[00:38:09.620 --> 00:38:12.620]   I don't think we ever brought that back, but eventually we could.
[00:38:12.620 --> 00:38:14.620]   It's, you know, I mean, it's some income.
[00:38:14.620 --> 00:38:15.620]   It's not enough.
[00:38:15.620 --> 00:38:18.620]   It's not a huge amount income, especially when you have to hire somebody to do it.
[00:38:18.620 --> 00:38:19.620]   Yeah, that's true.
[00:38:19.620 --> 00:38:20.620]   I'm...
[00:38:20.620 --> 00:38:24.620]   We're actually very happy with our kind of simple model.
[00:38:24.620 --> 00:38:25.620]   Yeah.
[00:38:25.620 --> 00:38:27.620]   You're driving a Tesla product?
[00:38:27.620 --> 00:38:28.620]   It works.
[00:38:28.620 --> 00:38:29.620]   Yeah, don't mess with it.
[00:38:29.620 --> 00:38:30.620]   Why break?
[00:38:30.620 --> 00:38:31.620]   I'm serious.
[00:38:31.620 --> 00:38:32.620]   Like, why break?
[00:38:32.620 --> 00:38:33.620]   You don't have to take over the world.
[00:38:33.620 --> 00:38:35.620]   No, in fact, that's the other thing.
[00:38:35.620 --> 00:38:39.620]   At some point, any entrepreneur has to grapple with the idea.
[00:38:39.620 --> 00:38:41.620]   Am I gonna...
[00:38:41.620 --> 00:38:43.620]   Is this a lifestyle business?
[00:38:43.620 --> 00:38:46.620]   Is this an Uber unicorn or is it something in between?
[00:38:46.620 --> 00:38:49.620]   And I think we made this something in between, which is we want to be...
[00:38:49.620 --> 00:38:51.620]   We're not trying to get bigger just better.
[00:38:51.620 --> 00:38:55.620]   And, you know, our revenues got up steadily every year.
[00:38:55.620 --> 00:38:58.620]   We're making a decent amount of money now.
[00:38:58.620 --> 00:39:03.620]   So, yeah, why break it?
[00:39:03.620 --> 00:39:04.620]   Not that I want to talk about myself.
[00:39:04.620 --> 00:39:06.620]   Let's talk about Duo.
[00:39:06.620 --> 00:39:09.620]   Or let's talk on Duo.
[00:39:09.620 --> 00:39:10.620]   You want to talk on Duo?
[00:39:10.620 --> 00:39:11.620]   So it came out today.
[00:39:11.620 --> 00:39:12.620]   I'm waiting for a couple of days ago.
[00:39:12.620 --> 00:39:13.620]   I'm waiting for Aloe.
[00:39:13.620 --> 00:39:14.620]   Where's Aloe coming?
[00:39:14.620 --> 00:39:15.620]   I'm too...
[00:39:15.620 --> 00:39:19.620]   If you go into the place store, you couldn't say...
[00:39:19.620 --> 00:39:20.620]   Yeah, I'm registered for it.
[00:39:20.620 --> 00:39:21.620]   Come on, yeah.
[00:39:21.620 --> 00:39:22.620]   Yeah, I saw that.
[00:39:22.620 --> 00:39:23.620]   That was weird.
[00:39:23.620 --> 00:39:24.620]   Yeah, but I still do it set up.
[00:39:24.620 --> 00:39:25.620]   People also installed Aloe.
[00:39:25.620 --> 00:39:26.620]   I was like, no, they didn't.
[00:39:26.620 --> 00:39:28.620]   [laughter]
[00:39:28.620 --> 00:39:30.620]   Now, but I have registered somehow.
[00:39:30.620 --> 00:39:32.620]   I guess I went to a website.
[00:39:32.620 --> 00:39:37.620]   So when I went to the place store before it either came out, it said, "registered."
[00:39:37.620 --> 00:39:40.620]   And then automatically I got a notification when Duo came out and said,
[00:39:40.620 --> 00:39:41.620]   "Okay, you can download it now.
[00:39:41.620 --> 00:39:43.620]   I presume I'll get the same thing with Aloe."
[00:39:43.620 --> 00:39:44.620]   I presume so.
[00:39:44.620 --> 00:39:49.620]   These are both announced at the Google I/O developers conference.
[00:39:49.620 --> 00:39:53.620]   Duo is Google's FaceTime, basically.
[00:39:53.620 --> 00:39:56.620]   Except unlike FaceTime, it's a completely cross-platform.
[00:39:56.620 --> 00:39:58.620]   It's based on an open standard as well, WebRTC.
[00:39:58.620 --> 00:39:59.620]   Right?
[00:39:59.620 --> 00:40:01.620]   This is just a WebRTC client, Kevin, right?
[00:40:01.620 --> 00:40:02.620]   I think so.
[00:40:02.620 --> 00:40:03.620]   Yeah.
[00:40:03.620 --> 00:40:04.620]   Which is easy to do.
[00:40:04.620 --> 00:40:08.620]   It kind of begs the question, why did it take them so long to get this out?
[00:40:08.620 --> 00:40:11.620]   Well, Bob, can I just do WebRTC on iOS?
[00:40:11.620 --> 00:40:13.620]   Because I don't actually have WebRTC in OS.
[00:40:13.620 --> 00:40:16.620]   Oh, iOS was the hangout.
[00:40:16.620 --> 00:40:21.620]   Yeah, so there's no WebRTC in Safari, and you can't run another browser runtime.
[00:40:21.620 --> 00:40:23.620]   So you've got to do it.
[00:40:23.620 --> 00:40:24.620]   That's probably what it takes.
[00:40:24.620 --> 00:40:30.620]   Because you could crank this out pretty quickly using a WebView, right?
[00:40:30.620 --> 00:40:33.620]   Anyway, it is point to point only.
[00:40:33.620 --> 00:40:36.620]   A couple of interesting things people noticed, for instance,
[00:40:36.620 --> 00:40:38.620]   you do not need a Google account.
[00:40:38.620 --> 00:40:42.620]   When you put it on a phone, you'll tie it to your phone's number.
[00:40:42.620 --> 00:40:47.620]   Some people complain, saying, "Well, I don't want to have it on all my different devices."
[00:40:47.620 --> 00:40:51.620]   No, but that's the point, is this is like your phone device.
[00:40:51.620 --> 00:40:53.620]   It's like making a phone call.
[00:40:53.620 --> 00:40:55.620]   So I'll call you Jeff so we can see.
[00:40:55.620 --> 00:40:57.620]   It's a little dark in here.
[00:40:57.620 --> 00:41:04.620]   By the way, because I had talked to Jeff before, his icon was right there on the front screen.
[00:41:04.620 --> 00:41:06.620]   This is kind of fun.
[00:41:06.620 --> 00:41:10.620]   Watch, I tap my picture, and I'm full screen, and then he's full screen.
[00:41:10.620 --> 00:41:11.620]   I don't know what that's good for.
[00:41:11.620 --> 00:41:13.620]   Hey, I'm true.
[00:41:13.620 --> 00:41:15.620]   Let me turn that volume one down all the way.
[00:41:15.620 --> 00:41:18.620]   I didn't even know I could change the volume.
[00:41:18.620 --> 00:41:19.620]   It's very simple.
[00:41:19.620 --> 00:41:21.620]   The point is, there's very few controls.
[00:41:21.620 --> 00:41:24.620]   You could flip the camera from front to back and back to front.
[00:41:24.620 --> 00:41:28.620]   I don't know what else you can do with it.
[00:41:28.620 --> 00:41:29.620]   We can talk.
[00:41:29.620 --> 00:41:31.620]   We have a nice conversation.
[00:41:31.620 --> 00:41:34.620]   I guess one of the best things is IOS and Android.
[00:41:34.620 --> 00:41:37.620]   It is not available there, and I'm seeing Jeff's picture.
[00:41:37.620 --> 00:41:40.620]   It is not available for desktop.
[00:41:40.620 --> 00:41:44.620]   There are WebRTC clients, but they don't interoperate with this.
[00:41:44.620 --> 00:41:47.620]   IOS and Android only.
[00:41:47.620 --> 00:41:52.620]   This is Florence Ions article going through some of the points.
[00:41:52.620 --> 00:41:53.620]   The knock knock.
[00:41:53.620 --> 00:41:56.620]   Let me hang up, and you can call me Jeff.
[00:41:56.620 --> 00:41:59.620]   Show my phone, if you would, Josh.
[00:41:59.620 --> 00:42:03.620]   The knock knock thing, they talked about this at Google I/O.
[00:42:03.620 --> 00:42:08.620]   When he starts to call me, I'll immediately get a live image of Jeff, and so I can decide
[00:42:08.620 --> 00:42:11.620]   whether to pick up based on, oh, I can see him.
[00:42:11.620 --> 00:42:13.620]   I still haven't answered the call yet.
[00:42:13.620 --> 00:42:14.620]   I wish I could see it.
[00:42:14.620 --> 00:42:15.620]   I wish I were brighter.
[00:42:15.620 --> 00:42:17.620]   Let me turn this up all the way.
[00:42:17.620 --> 00:42:18.620]   Let me turn this up.
[00:42:18.620 --> 00:42:19.620]   There we go.
[00:42:19.620 --> 00:42:20.620]   Turn off auto.
[00:42:20.620 --> 00:42:21.620]   Turn it up all the way.
[00:42:21.620 --> 00:42:22.620]   All right.
[00:42:22.620 --> 00:42:24.620]   Now, call me again, Jeff, and hung up on you.
[00:42:24.620 --> 00:42:25.620]   Oh, okay.
[00:42:25.620 --> 00:42:26.620]   It's strictly right.
[00:42:26.620 --> 00:42:27.620]   It gave up.
[00:42:27.620 --> 00:42:31.620]   See, now you can see it, right?
[00:42:31.620 --> 00:42:32.620]   That, by the way, was from the desktop.
[00:42:32.620 --> 00:42:33.620]   I haven't answered yet.
[00:42:33.620 --> 00:42:35.620]   He's answered my call.
[00:42:35.620 --> 00:42:39.620]   I don't get audio, I think, and then I swipe up.
[00:42:39.620 --> 00:42:40.620]   I feel very low.
[00:42:40.620 --> 00:42:43.620]   I'm just from kind of this dim black and white guy to the colorful.
[00:42:43.620 --> 00:42:44.620]   Dude, the pink guy.
[00:42:44.620 --> 00:42:45.620]   The pink guy, yeah.
[00:42:45.620 --> 00:42:47.220]   Picture is good, right?
[00:42:47.220 --> 00:42:48.220]   Look how good the picture is.
[00:42:48.220 --> 00:42:49.620]   I think it works great.
[00:42:49.620 --> 00:42:52.620]   Doesn't, you can't do sideways though, right?
[00:42:52.620 --> 00:42:53.620]   Or can you?
[00:42:53.620 --> 00:42:55.620]   What happens if I turn it sideways?
[00:42:55.620 --> 00:42:56.620]   Do you know?
[00:42:56.620 --> 00:42:57.620]   Oh, no.
[00:42:57.620 --> 00:42:58.620]   So we can.
[00:42:58.620 --> 00:43:03.620]   So we could use this, I guess, on the show, except we can't get rid of these controls, but
[00:43:03.620 --> 00:43:04.620]   maybe we can.
[00:43:04.620 --> 00:43:06.620]   I haven't played with it that much.
[00:43:06.620 --> 00:43:07.620]   Okay, yeah.
[00:43:07.620 --> 00:43:08.620]   All right.
[00:43:08.620 --> 00:43:11.620]   So we could try to force you to use this for me in the show.
[00:43:11.620 --> 00:43:12.620]   Yes.
[00:43:12.620 --> 00:43:13.620]   We could.
[00:43:13.620 --> 00:43:14.620]   Next time in a hotel.
[00:43:14.620 --> 00:43:15.620]   I would.
[00:43:15.620 --> 00:43:16.620]   You know what?
[00:43:16.620 --> 00:43:17.620]   It would probably work better, wouldn't it?
[00:43:17.620 --> 00:43:19.620]   So does it work on tablets or any other ones?
[00:43:19.620 --> 00:43:20.620]   Because of the phone.
[00:43:20.620 --> 00:43:23.620]   It was designed for phones, they said, but I think it works on tablets.
[00:43:23.620 --> 00:43:28.620]   I think you could put it on your iOS device if you had a Google voice number, for instance,
[00:43:28.620 --> 00:43:32.620]   and you could get, because the way you verify the numbers, it sends a text.
[00:43:32.620 --> 00:43:35.620]   If you are on the same phone, it will auto enter the text, right?
[00:43:35.620 --> 00:43:37.620]   But I noticed that if it doesn't do that.
[00:43:37.620 --> 00:43:40.620]   Yeah, I think I put it on my iPad, actually.
[00:43:40.620 --> 00:43:43.100]   You could enter the text in by hand.
[00:43:43.100 --> 00:43:45.140]   So I think you can use it on a tablet.
[00:43:45.140 --> 00:43:46.140]   Quality looks good.
[00:43:46.140 --> 00:43:47.140]   Yeah.
[00:43:47.140 --> 00:43:48.140]   Quality looks great.
[00:43:48.140 --> 00:43:49.860]   Actually, I'm blown away by the quality.
[00:43:49.860 --> 00:43:52.700]   It's better than we should probably start using it.
[00:43:52.700 --> 00:43:54.460]   Actually, we can't use this.
[00:43:54.460 --> 00:43:56.340]   You know why we can't get it off the phone.
[00:43:56.340 --> 00:43:57.340]   Yeah.
[00:43:57.340 --> 00:43:59.620]   We can only, we'd have to hook a phone up to our system.
[00:43:59.620 --> 00:44:01.620]   Skype of Saurus is a Windows machines.
[00:44:01.620 --> 00:44:04.980]   When you could, um, Chromecast it.
[00:44:04.980 --> 00:44:05.980]   Oh.
[00:44:05.980 --> 00:44:07.980]   I could Chromecast it.
[00:44:07.980 --> 00:44:10.980]   That would hurt the latency at all.
[00:44:10.980 --> 00:44:11.980]   Would it?
[00:44:11.980 --> 00:44:12.980]   No, it doesn't.
[00:44:12.980 --> 00:44:15.860]   You'd have to Chromecast the whole thing.
[00:44:15.860 --> 00:44:17.580]   It doesn't have many controls.
[00:44:17.580 --> 00:44:20.140]   I mean, if there's a negative, it's not very fancy.
[00:44:20.140 --> 00:44:22.140]   It's a video only.
[00:44:22.140 --> 00:44:26.860]   It doesn't work with any other Google product, including Aloe.
[00:44:26.860 --> 00:44:35.020]   You already have video calling probably on Facebook Messenger and WhatsApp Messenger
[00:44:35.020 --> 00:44:38.460]   and Skype and so do many of the people you converse with.
[00:44:38.460 --> 00:44:44.740]   So that's probably the biggest knock and it's true of any of them is you have to have somebody
[00:44:44.740 --> 00:44:46.340]   that's using it on your phone book.
[00:44:46.340 --> 00:44:49.940]   Now, the way we did this is Jeff's in my context list.
[00:44:49.940 --> 00:44:53.500]   So he showed up in my Aloe context.
[00:44:53.500 --> 00:44:56.540]   Once he, I'm sorry, your Duo context, once he installed Duo.
[00:44:56.540 --> 00:44:58.380]   So that's pretty transparent.
[00:44:58.380 --> 00:44:59.620]   You just have to get everybody you notice.
[00:44:59.620 --> 00:45:03.980]   So the market position, what's, what's the advantage of Duo versus everything else?
[00:45:03.980 --> 00:45:04.980]   Just cross platform?
[00:45:04.980 --> 00:45:05.980]   I don't know.
[00:45:05.980 --> 00:45:08.500]   Kevin, why is Google doing this?
[00:45:08.500 --> 00:45:09.500]   Who knows?
[00:45:09.500 --> 00:45:15.060]   You know, they showed it off IO and they said the point of this is that it's really simple.
[00:45:15.060 --> 00:45:16.700]   That was their, their pictures as far as like a tell.
[00:45:16.700 --> 00:45:17.700]   It's like it's one.
[00:45:17.700 --> 00:45:18.700]   It is.
[00:45:18.700 --> 00:45:22.820]   I mean, the thing is that video calling is like, it's not magic anymore.
[00:45:22.820 --> 00:45:24.380]   It's a, it's something anyone can do.
[00:45:24.380 --> 00:45:25.380]   It's ubiquitous.
[00:45:25.380 --> 00:45:27.060]   It's the Netflix of your phone.
[00:45:27.060 --> 00:45:31.340]   You know, like five, five years ago when we were playing around with this, it was, it
[00:45:31.340 --> 00:45:32.340]   was hard.
[00:45:32.340 --> 00:45:34.940]   You know, actually 10 years ago, we were playing around with this computer's only.
[00:45:34.940 --> 00:45:38.100]   But the point is it's now, it's now table stakes.
[00:45:38.100 --> 00:45:40.620]   All the, all the things can do video chat.
[00:45:40.620 --> 00:45:44.060]   And so I think they've just tried to wrap this up in the simplest possible thing.
[00:45:44.060 --> 00:45:49.540]   They've tried to do the phone number so that it just feels like I've made a video call.
[00:45:49.540 --> 00:45:54.260]   And then it, then that's the thing that you can, you can work for Android and iOS.
[00:45:54.260 --> 00:45:56.060]   I mean, the thing is you could do this with Hangouts already.
[00:45:56.060 --> 00:45:57.060]   That's a bit of a slightly weird.
[00:45:57.060 --> 00:45:59.740]   Yeah, but Hangouts are always so quirky.
[00:45:59.740 --> 00:46:01.300]   Well, hangouts.
[00:46:01.300 --> 00:46:07.340]   Hangouts always has like the app has accreted so much stuff that it's quite hard to work
[00:46:07.340 --> 00:46:09.060]   out what you're doing with it.
[00:46:09.060 --> 00:46:12.500]   So they announced this week that they're dropping Hangouts on air as well.
[00:46:12.500 --> 00:46:15.700]   So they may be slimming this down a bit and making it less of a sort of Swiss army knife
[00:46:15.700 --> 00:46:16.700]   thing.
[00:46:16.700 --> 00:46:23.220]   But you know, there was also like links in with Google, um, class and all sorts of like
[00:46:23.220 --> 00:46:24.860]   other random bits pieces that join together.
[00:46:24.860 --> 00:46:26.820]   So if they're actually going to streamline these products, that would be good.
[00:46:26.820 --> 00:46:27.820]   But it seems to be doing this.
[00:46:27.820 --> 00:46:31.260]   It seems to be adding more new ones rather than saying, Oh, of the six chat app.
[00:46:31.260 --> 00:46:34.060]   So we've got let's consolidate them and make them coherent.
[00:46:34.060 --> 00:46:37.300]   I've still got six ways of getting text messages on my phone.
[00:46:37.300 --> 00:46:39.980]   Three of them controlled by Google and it's confusing as anything.
[00:46:39.980 --> 00:46:42.540]   So it's a single function thing.
[00:46:42.540 --> 00:46:44.100]   It makes it a bit more sense as that.
[00:46:44.100 --> 00:46:50.540]   But I'm slightly puzzled by it and I'm not sure, you know, how I'd use it.
[00:46:50.540 --> 00:46:55.500]   I also, um, I'm probably more likely to use Facebook messages video jack because it's
[00:46:55.500 --> 00:46:57.660]   in the client that I'm actually talking to people on.
[00:46:57.660 --> 00:46:58.660]   Yeah.
[00:46:58.660 --> 00:47:01.260]   Nobody wants to make video calls.
[00:47:01.260 --> 00:47:02.260]   No, that's not true.
[00:47:02.260 --> 00:47:03.260]   Okay.
[00:47:03.260 --> 00:47:09.220]   So my daughter, who's nine and kids who are younger, that's what they expect.
[00:47:09.220 --> 00:47:10.220]   They do.
[00:47:10.220 --> 00:47:11.220]   Oh, that's interesting.
[00:47:11.220 --> 00:47:12.220]   Okay.
[00:47:12.220 --> 00:47:15.420]   So like if I call her and I call her on the phone, she actually holds the phone in front
[00:47:15.420 --> 00:47:16.420]   of it.
[00:47:16.420 --> 00:47:17.420]   She does.
[00:47:17.420 --> 00:47:18.420]   This is how she talks on the phone.
[00:47:18.420 --> 00:47:19.420]   No matter what, really.
[00:47:19.420 --> 00:47:20.420]   Right.
[00:47:20.420 --> 00:47:23.100]   Um, so I thought that was the Kim Kardashian thing.
[00:47:23.100 --> 00:47:24.100]   Oh, yes.
[00:47:24.100 --> 00:47:25.100]   Right.
[00:47:25.100 --> 00:47:26.100]   But she's too young.
[00:47:26.100 --> 00:47:27.100]   But there is that as well.
[00:47:27.100 --> 00:47:32.980]   There is the talking to your phone on speakerphone is a thing that's a reality TV trope that people
[00:47:32.980 --> 00:47:33.980]   have picked up on it.
[00:47:33.980 --> 00:47:34.980]   Yeah.
[00:47:34.980 --> 00:47:35.980]   Is that what that is?
[00:47:35.980 --> 00:47:38.860]   When people are working on the street talking like this, yeah, I'm equivalent of the old
[00:47:38.860 --> 00:47:40.100]   French cigarette thing.
[00:47:40.100 --> 00:47:41.100]   Yeah.
[00:47:41.100 --> 00:47:44.780]   Well, I think it did start with the Kardashians because of course, in order to video people
[00:47:44.780 --> 00:47:46.460]   having fun because you have to do that.
[00:47:46.460 --> 00:47:47.460]   Oh, so obnoxious.
[00:47:47.460 --> 00:47:48.460]   It's really obnoxious.
[00:47:48.460 --> 00:47:54.180]   But it's interesting how that's become a carant and it is the worst thing ever.
[00:47:54.180 --> 00:47:59.180]   You can hear the call.
[00:47:59.180 --> 00:48:02.180]   It's just so annoying.
[00:48:02.180 --> 00:48:05.180]   It's just kind of just looks should be banned.
[00:48:05.180 --> 00:48:09.380]   So, so mine is doing it looking for a person's face.
[00:48:09.380 --> 00:48:11.380]   She's not doing it because.
[00:48:11.380 --> 00:48:12.380]   No, no, she's more, more, more, more.
[00:48:12.380 --> 00:48:15.380]   No, that's why I'm interested because she's a new generation and she is doing it.
[00:48:15.380 --> 00:48:20.380]   So that's like my friend who's got a four year old, he's travels like 200 and something
[00:48:20.380 --> 00:48:21.380]   odd days a year.
[00:48:21.380 --> 00:48:23.380]   And his daughter doesn't even know what a phone call is.
[00:48:23.380 --> 00:48:28.820]   Like when she saw me, she was over at our house and she saw me talking on my phone,
[00:48:28.820 --> 00:48:30.740]   she just, she's like, what are you doing?
[00:48:30.740 --> 00:48:32.460]   And I was like, well, I'm talking on the phone.
[00:48:32.460 --> 00:48:34.100]   She's like, they can't see you.
[00:48:34.100 --> 00:48:36.660]   And I was like, well, yeah.
[00:48:36.660 --> 00:48:39.380]   And she's like, how are you talking on the phone?
[00:48:39.380 --> 00:48:40.380]   It was fun.
[00:48:40.380 --> 00:48:43.020]   You know, I thought was interesting on Twitter on Sunday.
[00:48:43.020 --> 00:48:44.500]   We had Alec among others.
[00:48:44.500 --> 00:48:46.700]   Alex Wilham was a millennial.
[00:48:46.700 --> 00:48:51.260]   And he said, I don't have a phone icon on the front of my smartphone anymore.
[00:48:51.260 --> 00:48:53.060]   I don't, I took that off.
[00:48:53.060 --> 00:48:54.060]   Wow.
[00:48:54.060 --> 00:48:57.660]   And I thought about it and I thought, you know, I never use the phone either.
[00:48:57.660 --> 00:48:58.660]   Yeah.
[00:48:58.660 --> 00:49:01.460]   If I'm going to, if I'm going to call somebody, I'll call them director.
[00:49:01.460 --> 00:49:04.940]   I'll say, okay, Google maybe, but I'm never sorry.
[00:49:04.940 --> 00:49:06.300]   I'm not talking to you.
[00:49:06.300 --> 00:49:08.140]   Google so go away.
[00:49:08.140 --> 00:49:10.180]   I never use that.
[00:49:10.180 --> 00:49:14.740]   So I'm going to, I'm going to try as an experiment, I'm removing the phone icon from my, from
[00:49:14.740 --> 00:49:15.740]   my phone.
[00:49:15.740 --> 00:49:18.260]   Oh, so you're like an aging millennial now?
[00:49:18.260 --> 00:49:19.260]   Yeah.
[00:49:19.260 --> 00:49:21.140]   I want to be like you young people.
[00:49:21.140 --> 00:49:22.300]   I, I'm not a millennial.
[00:49:22.300 --> 00:49:25.460]   I'm an X or you're an X or one of my boomer.
[00:49:25.460 --> 00:49:26.940]   We're boomers, right?
[00:49:26.940 --> 00:49:27.940]   Jeff.
[00:49:27.940 --> 00:49:28.940]   Yeah, because of boomers.
[00:49:28.940 --> 00:49:30.980]   I say, because I lost in the middle.
[00:49:30.980 --> 00:49:31.980]   Yeah.
[00:49:31.980 --> 00:49:36.820]   And then there's the wise, like why?
[00:49:36.820 --> 00:49:37.820]   So okay.
[00:49:37.820 --> 00:49:38.900]   So all right, I'll stand corrected.
[00:49:38.900 --> 00:49:42.980]   I actually do use a FaceTime every time I call my mom.
[00:49:42.980 --> 00:49:47.020]   I was going to say every week, but every time I call my mom, she likes that.
[00:49:47.020 --> 00:49:51.020]   So when you're visiting with somebody or you miss somebody or a family member, it's video
[00:49:51.020 --> 00:49:52.020]   calls are great.
[00:49:52.020 --> 00:49:53.020]   Yeah.
[00:49:53.020 --> 00:49:54.020]   I'm after the show.
[00:49:54.020 --> 00:49:57.820]   My heart stopped as to video of my daughter and see how the first day of school went.
[00:49:57.820 --> 00:49:59.980]   So oh, today's the first day of school.
[00:49:59.980 --> 00:50:00.980]   Yeah.
[00:50:00.980 --> 00:50:01.980]   Yeah.
[00:50:01.980 --> 00:50:11.420]   No, we do about some, some UK and randomly mixture of Skype and Facebook messenger.
[00:50:11.420 --> 00:50:14.780]   I think Skype's even suffering from this because it is built into all the messenger
[00:50:14.780 --> 00:50:18.020]   programs now and you already have somebody in the messenger program just makes sense
[00:50:18.020 --> 00:50:20.100]   to do a video call that way.
[00:50:20.100 --> 00:50:21.100]   Yeah.
[00:50:21.100 --> 00:50:25.020]   This curiosity, I don't know, does Facebook still use Skype?
[00:50:25.020 --> 00:50:28.180]   They used to or they have their own protocol.
[00:50:28.180 --> 00:50:29.780]   No, they have to write stuff.
[00:50:29.780 --> 00:50:30.780]   Yeah.
[00:50:30.780 --> 00:50:35.500]   Everybody, I think part, I'll bet you the number one reason for Duo is to raise awareness
[00:50:35.500 --> 00:50:38.500]   of WebRTC, which is a great technology.
[00:50:38.500 --> 00:50:40.860]   And I don't think is widely known.
[00:50:40.860 --> 00:50:42.580]   But the thing is it's still a silo.
[00:50:42.580 --> 00:50:45.940]   It doesn't actually interoperate with WebRTC as far as I can tell.
[00:50:45.940 --> 00:50:46.940]   No, it doesn't.
[00:50:46.940 --> 00:50:47.940]   That's true.
[00:50:47.940 --> 00:50:48.940]   That's a stupid thing.
[00:50:48.940 --> 00:50:49.940]   Yeah.
[00:50:49.940 --> 00:50:54.940]   I mean, the thing that Hangouts is built on the same basic stack and it was designed to
[00:50:54.940 --> 00:50:58.540]   go between desktop and phone and go everywhere.
[00:50:58.540 --> 00:51:00.860]   But part of that is what makes it a little bit clunky to use.
[00:51:00.860 --> 00:51:04.220]   Whereas I think this is they started from, okay, I want to one button where they call
[00:51:04.220 --> 00:51:09.700]   people and they've got the knock knock thing, which is I'm not completely convinced by that
[00:51:09.700 --> 00:51:10.700]   proposition.
[00:51:10.700 --> 00:51:14.420]   I haven't actually been through the, do you have to approve people before they can do that
[00:51:14.420 --> 00:51:15.420]   to you?
[00:51:15.420 --> 00:51:16.420]   No.
[00:51:16.420 --> 00:51:17.580]   You can block them.
[00:51:17.580 --> 00:51:20.820]   But if you may already have flake expose themselves to you.
[00:51:20.820 --> 00:51:21.820]   Right.
[00:51:21.820 --> 00:51:23.140]   That's the bit that makes me agree.
[00:51:23.140 --> 00:51:24.140]   I don't want to.
[00:51:24.140 --> 00:51:29.140]   That's the first thought I had is, oh, I know what I'm going to be getting.
[00:51:29.140 --> 00:51:31.340]   But that's probably why it uses phone numbers, right?
[00:51:31.340 --> 00:51:32.740]   Because that's presumed to be a little more.
[00:51:32.740 --> 00:51:36.540]   But how does it then know that the other person has?
[00:51:36.540 --> 00:51:37.540]   Duo.
[00:51:37.540 --> 00:51:39.220]   Well, I don't know.
[00:51:39.220 --> 00:51:42.700]   It does because as soon as you installed Duo, you're suddenly showed up.
[00:51:42.700 --> 00:51:44.100]   Well, you're in their directory.
[00:51:44.100 --> 00:51:45.100]   Yeah.
[00:51:45.100 --> 00:51:47.340]   So they then know everybody who has Duo.
[00:51:47.340 --> 00:51:48.340]   Oh, right.
[00:51:48.340 --> 00:51:51.340]   In the same way, what's that knows who you've got?
[00:51:51.340 --> 00:51:52.340]   What's happened?
[00:51:52.340 --> 00:51:53.340]   Who's just a phone number, right?
[00:51:53.340 --> 00:51:54.340]   Right.
[00:51:54.340 --> 00:51:55.340]   Yeah.
[00:51:55.340 --> 00:51:57.860]   What's app uses the phone number to figure out who they know?
[00:51:57.860 --> 00:51:58.860]   Yeah.
[00:51:58.860 --> 00:52:02.060]   So if I have a bunch of people in my phone, like my work contacts as part of my Google
[00:52:02.060 --> 00:52:06.180]   account, those people are going to automatically be able to call me if I download Duo and they
[00:52:06.180 --> 00:52:07.180]   have it.
[00:52:07.180 --> 00:52:08.180]   Yep.
[00:52:08.180 --> 00:52:09.180]   Oh, that sucks.
[00:52:09.180 --> 00:52:10.700]   Well, do you there any have your phone number?
[00:52:10.700 --> 00:52:13.100]   I know, but they could call you on the phone.
[00:52:13.100 --> 00:52:15.460]   But I have my curlers in.
[00:52:15.460 --> 00:52:18.180]   I don't like, well, I guess I ignore them.
[00:52:18.180 --> 00:52:19.500]   I don't have to see their faces.
[00:52:19.500 --> 00:52:21.340]   You can disable that part.
[00:52:21.340 --> 00:52:24.060]   Oh, this should be a way to forward a voice.
[00:52:24.060 --> 00:52:25.060]   Wouldn't that be nice?
[00:52:25.060 --> 00:52:27.940]   That's exactly or at least you have to throw the cameras in as you can on the Skype.
[00:52:27.940 --> 00:52:29.780]   Just I'm going to do a voice calls on a video call.
[00:52:29.780 --> 00:52:30.780]   Yeah.
[00:52:30.780 --> 00:52:31.780]   Right.
[00:52:31.780 --> 00:52:32.780]   There's a one by option for that.
[00:52:32.780 --> 00:52:33.780]   Yeah.
[00:52:33.780 --> 00:52:35.340]   But this, but yeah, the phone number by anything is a bit weird.
[00:52:35.340 --> 00:52:36.940]   Signal does this too, which is even we're there.
[00:52:36.940 --> 00:52:39.420]   So you know, signal was the like the encrypted chat app.
[00:52:39.420 --> 00:52:40.420]   Oh, yeah.
[00:52:40.420 --> 00:52:43.340]   And it's secure and it's supposed to be a good thing for journalists to use for sources
[00:52:43.340 --> 00:52:47.100]   and stuff like that, except that because it uses phone number, it does the girlfriend
[00:52:47.100 --> 00:52:48.620]   just join signal with it.
[00:52:48.620 --> 00:52:51.860]   It's like my friend probably just joined signal to do something confidential.
[00:52:51.860 --> 00:52:54.980]   You notify me about that is not actually a good signal.
[00:52:54.980 --> 00:52:55.980]   It's terrible.
[00:52:55.980 --> 00:52:56.980]   That's terrible.
[00:52:56.980 --> 00:52:59.700]   Because that's a leak.
[00:52:59.700 --> 00:53:02.060]   It's an information leak, a metadata leak.
[00:53:02.060 --> 00:53:03.700]   It's not even metadata.
[00:53:03.700 --> 00:53:04.700]   It's real data.
[00:53:04.700 --> 00:53:06.620]   So, you know, I mean, what's that?
[00:53:06.620 --> 00:53:07.860]   What's that was very successful with this?
[00:53:07.860 --> 00:53:09.340]   So that's the model they're copying.
[00:53:09.340 --> 00:53:11.460]   So what's that said, okay, you've got a phone number.
[00:53:11.460 --> 00:53:12.460]   We will use the phone number.
[00:53:12.460 --> 00:53:14.980]   All you have to do will bootstrap off that.
[00:53:14.980 --> 00:53:18.620]   We're just replacing text messaging with our infrastructure.
[00:53:18.620 --> 00:53:22.500]   So instead of actually paying the phone company, you're just paying data and you're probably
[00:53:22.500 --> 00:53:23.540]   not paying much for data.
[00:53:23.540 --> 00:53:28.700]   The larger story here has nothing to do with duo, but just the fact that the carrier's
[00:53:28.700 --> 00:53:33.100]   infrastructure for making phone calls is rapidly being usurped just as the cable company's
[00:53:33.100 --> 00:53:35.900]   has been by the internet and increasing.
[00:53:35.900 --> 00:53:40.980]   I mean, your daughter probably won't make telephone calls in her life.
[00:53:40.980 --> 00:53:45.300]   But she'll be doing data calls from now on.
[00:53:45.300 --> 00:53:49.420]   Was it 2012 or 2014 that data surpassed voice?
[00:53:49.420 --> 00:53:52.140]   But the carriers have known this was coming for a long time.
[00:53:52.140 --> 00:53:53.900]   They tried to do a bunch of things to stop it.
[00:53:53.900 --> 00:53:56.900]   The FCC was like, stop trying to do that.
[00:53:56.900 --> 00:54:01.980]   And now they've kind of accepted it to a certain extent.
[00:54:01.980 --> 00:54:08.420]   They built all these apps of their own trying to kind of compete with the massive web companies.
[00:54:08.420 --> 00:54:13.140]   And though, and Kevin, I don't know if you know about this, did you see how the EU is
[00:54:13.140 --> 00:54:18.020]   looking at imposing some of the same burdens on the infrastructure?
[00:54:18.020 --> 00:54:22.780]   So the Facebooks and Skype so the world as they are on carriers is part of kind of a
[00:54:22.780 --> 00:54:24.580]   telecom relations.
[00:54:24.580 --> 00:54:25.580]   Yes.
[00:54:25.580 --> 00:54:26.580]   No, maybe.
[00:54:26.580 --> 00:54:27.580]   Yes.
[00:54:27.580 --> 00:54:28.580]   I've seen bits of that.
[00:54:28.580 --> 00:54:32.780]   I've actually followed the latest edition, but they've had they've done effectively is
[00:54:32.780 --> 00:54:34.540]   it sort of common carrier type rules.
[00:54:34.540 --> 00:54:35.540]   Yes.
[00:54:35.540 --> 00:54:37.620]   So the BBC done things about broadcasting.
[00:54:37.620 --> 00:54:40.460]   So they basically tried to take television broadcasting rules and apply that to online
[00:54:40.460 --> 00:54:46.540]   video and things, which is a less coherent mapping because obviously, and the problem
[00:54:46.540 --> 00:54:50.460]   is that the EU rules were all written at the time when there was a statement of a new
[00:54:50.460 --> 00:54:54.180]   broadcast, a state monopoly phone company.
[00:54:54.180 --> 00:54:58.740]   And in lots of European companies, they're still kind of is, but that has changed.
[00:54:58.740 --> 00:55:01.620]   And so they're going, they're sort of, they've got a mapping problem.
[00:55:01.620 --> 00:55:03.260]   They're trying to make sense of that.
[00:55:03.260 --> 00:55:06.580]   And I haven't seen the specific ones about the phone things here.
[00:55:06.580 --> 00:55:12.620]   I mean, it's, is it nine, eleven type regs and those kinds of things or?
[00:55:12.620 --> 00:55:16.780]   I'm waiting for my Forbes quote of the day to get out of my way so I can.
[00:55:16.780 --> 00:55:20.140]   Oh, we've all been there.
[00:55:20.140 --> 00:55:21.140]   Okay.
[00:55:21.140 --> 00:55:22.140]   So let's see.
[00:55:22.140 --> 00:55:23.700]   Who stops stop?
[00:55:23.700 --> 00:55:24.700]   Okay.
[00:55:24.700 --> 00:55:29.700]   So it's, it is the European Commission is preparing to announce a review of the EU's
[00:55:29.700 --> 00:55:32.420]   E privacy law later this year.
[00:55:32.420 --> 00:55:36.860]   And it will include new measures forcing quote unquote over the top messaging services to
[00:55:36.860 --> 00:55:40.380]   follow the same kinds of privacy rules that telcos do.
[00:55:40.380 --> 00:55:45.460]   So this is Facebook, five, oh, there's, there's noise.
[00:55:45.460 --> 00:55:46.460]   That's all right.
[00:55:46.460 --> 00:55:47.460]   We barely agree.
[00:55:47.460 --> 00:55:48.460]   We barely agree.
[00:55:48.460 --> 00:55:49.460]   Etc.
[00:55:49.460 --> 00:55:50.460]   Viber all these.
[00:55:50.460 --> 00:55:54.220]   You know, there's kind of an irony there because I would say in some cases, these are
[00:55:54.220 --> 00:55:55.620]   much more private systems.
[00:55:55.620 --> 00:55:58.260]   For instance, duo is end to end encrypted.
[00:55:58.260 --> 00:56:00.340]   Your phone call, isn't it?
[00:56:00.340 --> 00:56:02.020]   You know, the governments hate that.
[00:56:02.020 --> 00:56:04.060]   I know, I know.
[00:56:04.060 --> 00:56:06.340]   So I get, I misinterpreted that.
[00:56:06.340 --> 00:56:11.380]   I thought they wanted the internet communications to rise to the level of the telcos privacy.
[00:56:11.380 --> 00:56:13.660]   They want them to fall to the level of telco privacy.
[00:56:13.660 --> 00:56:17.100]   Well, that's the hub of this is some of this is interception rules.
[00:56:17.100 --> 00:56:20.620]   So that's the, that's the place where the, we want to be able to wiretap you and the British
[00:56:20.620 --> 00:56:26.940]   government has been making noises along these lines about outlawing encryption.
[00:56:26.940 --> 00:56:30.540]   And the change of prime minister was not make a lot of difference because the, the prime
[00:56:30.540 --> 00:56:32.660]   is the previous home secretary was pushing this very hard.
[00:56:32.660 --> 00:56:35.820]   Yeah, to really amaze the snoopers charter sponsor.
[00:56:35.820 --> 00:56:36.820]   Exactly.
[00:56:36.820 --> 00:56:38.860]   So there is, there is boy.
[00:56:38.860 --> 00:56:40.860]   So there's that level of staff.
[00:56:40.860 --> 00:56:46.660]   The other thing is that they have the sort of the actual privacy things is data protection
[00:56:46.660 --> 00:56:52.300]   staff where they say in order to share information about people, you have to have consent and
[00:56:52.300 --> 00:56:55.460]   you have to be able to give that information to people.
[00:56:55.460 --> 00:57:00.740]   So in, in turn, in like in the American companies, they're, they're correct in this database
[00:57:00.740 --> 00:57:02.980]   of who knows whom and the contacts and stuff like that.
[00:57:02.980 --> 00:57:03.980]   The meta data.
[00:57:03.980 --> 00:57:06.900]   And they're using that to, to cross construct other things.
[00:57:06.900 --> 00:57:10.660]   In the EU that, that would, that would require them to file some forms and make sure that
[00:57:10.660 --> 00:57:12.940]   they're in regulations.
[00:57:12.940 --> 00:57:17.940]   So it's a sort of a slight difference of regulatory point of view there.
[00:57:17.940 --> 00:57:23.140]   But the, the intersection staff is, is, is, you know, going to be tricky.
[00:57:23.140 --> 00:57:25.740]   And again, I'm not sure that's, that's consistently agreed across you.
[00:57:25.740 --> 00:57:26.740]   Right.
[00:57:26.740 --> 00:57:30.060]   Because well, I think that's why you're seeing a rush, a land rush for these encrypted applications,
[00:57:30.060 --> 00:57:31.700]   why what's happened?
[00:57:31.700 --> 00:57:39.020]   And Facebook and Google are all adopting end to end encryption to preempt any measures
[00:57:39.020 --> 00:57:40.020]   by governments.
[00:57:40.020 --> 00:57:41.620]   Although it doesn't mean the government can't do it.
[00:57:41.620 --> 00:57:44.660]   But what it does do is that it means the government now has to face the prospect of
[00:57:44.660 --> 00:57:48.100]   losing Facebook and losing what's app.
[00:57:48.100 --> 00:57:51.780]   And you saw what happened in Brazil when they tried to shut down what's that.
[00:57:51.780 --> 00:57:52.780]   Yeah.
[00:57:52.780 --> 00:57:53.780]   Yeah.
[00:57:53.780 --> 00:57:58.620]   I mean, I, I understand Putin's government has, you know, Putin signed an order that required
[00:57:58.620 --> 00:57:59.620]   that.
[00:57:59.620 --> 00:58:01.660]   I don't know what the upshot of it is.
[00:58:01.660 --> 00:58:03.100]   I haven't heard anything since.
[00:58:03.100 --> 00:58:08.660]   I'm sure his state police told him, well, you can order us to do that.
[00:58:08.660 --> 00:58:10.380]   That doesn't mean we can.
[00:58:10.380 --> 00:58:15.660]   Well, but they, I mean, but that's, you know, in Russia, they have their own Google equivalent,
[00:58:15.660 --> 00:58:16.660]   their own Facebook equivalent.
[00:58:16.660 --> 00:58:17.660]   They can be you are too.
[00:58:17.660 --> 00:58:18.660]   Right.
[00:58:18.660 --> 00:58:19.660]   Yeah.
[00:58:19.660 --> 00:58:20.660]   Yeah.
[00:58:20.660 --> 00:58:26.900]   So the even Putin is going to throw Facebook out of Russia or what's app or any number of
[00:58:26.900 --> 00:58:27.900]   apps or Google.
[00:58:27.900 --> 00:58:28.900]   I'm not sure.
[00:58:28.900 --> 00:58:31.980]   I'm not sure what the Russian penetration is there.
[00:58:31.980 --> 00:58:33.420]   I'm actually trying to be recently.
[00:58:33.420 --> 00:58:34.980]   Maybe that's why you can do that there.
[00:58:34.980 --> 00:58:38.140]   But it would also explain why Google might rush to get this stuff out and Facebook might
[00:58:38.140 --> 00:58:44.140]   rush to get this stuff out now so that it is a little harder to to force.
[00:58:44.140 --> 00:58:51.420]   And it's the crypto community has been working hard to encourage this and to push this for
[00:58:51.420 --> 00:58:53.420]   a while and adjust it.
[00:58:53.420 --> 00:58:57.260]   So you actually got perfect forward secrecy and things like that make a make a difference.
[00:58:57.260 --> 00:58:58.260]   Yeah.
[00:58:58.260 --> 00:59:03.820]   Perfect forward secrecy is crucial because that way, you know, even if they've been collecting
[00:59:03.820 --> 00:59:07.540]   it, they can't in retroactively decrypt it.
[00:59:07.540 --> 00:59:08.540]   Right.
[00:59:08.540 --> 00:59:12.780]   If they get hold of your key, they can't decrypt previous calls, which is a problem with PGP
[00:59:12.780 --> 00:59:17.500]   and the sort of first pass of encryption models is that once you have the private key, then
[00:59:17.500 --> 00:59:19.100]   you could decrypt everything that's there.
[00:59:19.100 --> 00:59:23.100]   All the emails I've sent with my PGP key, which is why, by the way, you should change
[00:59:23.100 --> 00:59:25.020]   your PGP key fairly regularly.
[00:59:25.020 --> 00:59:29.100]   But all the emails I've used the PGP on would be then compromised the minute they get the
[00:59:29.100 --> 00:59:31.780]   key, not with perfect forward secrecy.
[00:59:31.780 --> 00:59:33.940]   Those remain encrypted conversations.
[00:59:33.940 --> 00:59:34.940]   Yes.
[00:59:34.940 --> 00:59:38.300]   It's basically automating that key changing.
[00:59:38.300 --> 00:59:43.300]   Yeah.
[00:59:43.300 --> 00:59:44.300]   All right.
[00:59:44.300 --> 00:59:45.300]   Fuchsia.
[00:59:45.300 --> 00:59:49.780]   That's Kevin Mark's skin tone.
[00:59:49.780 --> 00:59:53.180]   And how do you use a different color backdrop to make me look less pink?
[00:59:53.180 --> 00:59:55.820]   It's appropriate that you're here, Kevin, because you're probably the only person that
[00:59:55.820 --> 00:59:57.780]   explains could explain.
[00:59:57.780 --> 00:59:58.860]   I've been waiting for this.
[00:59:58.860 --> 00:59:59.860]   What this is all about.
[00:59:59.860 --> 01:00:01.980]   So I need to read about it first, but okay.
[01:00:01.980 --> 01:00:05.820]   Oh, well, I'll tell you, I'll tell you a little, what I know about it at Google posted
[01:00:05.820 --> 01:00:10.780]   on GitHub, an open source version of what they're saying will be a new operating system.
[01:00:10.780 --> 01:00:18.420]   It uses a little kernel, which is a kind of a real time, extra small kernel.
[01:00:18.420 --> 01:00:25.180]   And it is according to Google appropriate for every operating system, every setup from
[01:00:25.180 --> 01:00:30.260]   IoT all the way up to desktop.
[01:00:30.260 --> 01:00:34.980]   And a lot of what we've gleaned, we've actually learned from just going to the GitHub post,
[01:00:34.980 --> 01:00:38.340]   because all the source code is already up.
[01:00:38.340 --> 01:00:41.780]   And you can see what kernel they call the kernel, the magenta kernel, but it is based
[01:00:41.780 --> 01:00:44.700]   on little kernel.
[01:00:44.700 --> 01:00:45.860]   I said called little kernel.
[01:00:45.860 --> 01:00:46.860]   I think it's called little.
[01:00:46.860 --> 01:00:48.740]   So this is post Linux.
[01:00:48.740 --> 01:00:49.740]   Yeah.
[01:00:49.740 --> 01:00:50.740]   Yeah.
[01:00:50.740 --> 01:00:53.580]   Instead of Linux, yeah.
[01:00:53.580 --> 01:00:57.580]   And see relationship with LK.
[01:00:57.580 --> 01:01:04.620]   LK is a kernel design for small systems typically embedded.
[01:01:04.620 --> 01:01:07.300]   So it's a real time operating system for embedded.
[01:01:07.300 --> 01:01:09.860]   Fuchsia could be used that way.
[01:01:09.860 --> 01:01:15.980]   But magenta has additional features like first class user mode support, an object handle
[01:01:15.980 --> 01:01:21.540]   system and capability based security model that little kernel does not have, presumably
[01:01:21.540 --> 01:01:25.020]   because they want to make it available in the desktop as well.
[01:01:25.020 --> 01:01:27.700]   So it's into this fuchsia thing is very interesting.
[01:01:27.700 --> 01:01:31.980]   Why Google already has two operating systems, Chrome OS and Android.
[01:01:31.980 --> 01:01:36.380]   Well, part of it is that there's a, there's a both on Linux and they've done some work
[01:01:36.380 --> 01:01:38.380]   to converge their Linux kernel between them.
[01:01:38.380 --> 01:01:40.180]   But that's not, I'm not sure that's fully pleated.
[01:01:40.180 --> 01:01:43.340]   I forgot the name of the project, but they did some work to try and do that.
[01:01:43.340 --> 01:01:48.540]   But then there's, there's a bunch of sort of baked in assumptions in Linux that may make
[01:01:48.540 --> 01:01:50.380]   it harder to do some, some things.
[01:01:50.380 --> 01:01:51.380]   Yeah.
[01:01:51.380 --> 01:01:55.660]   The obvious one is the way audio works there, which is clearly worse on Linux that it is
[01:01:55.660 --> 01:01:56.660]   a lot of latency.
[01:01:56.660 --> 01:01:57.660]   IOS kernel.
[01:01:57.660 --> 01:01:58.660]   Yeah.
[01:01:58.660 --> 01:02:02.340]   Because it's, because it's a push model rather than a pull model, which means you end up
[01:02:02.340 --> 01:02:03.820]   accumulating buffers.
[01:02:03.820 --> 01:02:07.780]   So it may be that they've, they've started to step back and say, rather than try and
[01:02:07.780 --> 01:02:11.380]   make that kind of deep change to Linux, it may be easier to start with something else
[01:02:11.380 --> 01:02:15.020]   and just put, you know, the, our system that we're on top.
[01:02:15.020 --> 01:02:16.420]   But the other thing is, you know, this is Google.
[01:02:16.420 --> 01:02:19.540]   It may be an experiment just because Google is probably something doesn't mean this is
[01:02:19.540 --> 01:02:21.060]   their strategic direction.
[01:02:21.060 --> 01:02:24.900]   They, they have lots of parallel things going on at once.
[01:02:24.900 --> 01:02:27.860]   The difference between them and Apple is they'd do them slightly more in public.
[01:02:27.860 --> 01:02:30.340]   For all we know, this is somebody's 20% project, right?
[01:02:30.340 --> 01:02:31.340]   I mean, right.
[01:02:31.340 --> 01:02:32.340]   Yeah.
[01:02:32.340 --> 01:02:35.940]   Apple built several different operating system in things internally, but only shipped a few
[01:02:35.940 --> 01:02:37.180]   of them.
[01:02:37.180 --> 01:02:40.380]   And, and Google is probably doing the same thing, but maybe with a slightly more visibility
[01:02:40.380 --> 01:02:41.380]   here.
[01:02:41.380 --> 01:02:46.660]   The tagline, and maybe you can help us understand this, pink plus purple equals fuchsia.
[01:02:46.660 --> 01:02:50.180]   Now, I do remember there was a pink operating system.
[01:02:50.180 --> 01:02:53.380]   This was an eye, this was an Apple IBM joint venture, right?
[01:02:53.380 --> 01:02:54.380]   Yes.
[01:02:54.380 --> 01:02:55.380]   But I don't know if that's what they mean.
[01:02:55.380 --> 01:02:57.380]   I'm not sure what the, what the references there.
[01:02:57.380 --> 01:02:58.980]   I'm, yeah, that was a long time ago.
[01:02:58.980 --> 01:02:59.980]   That was like 20 years ago.
[01:02:59.980 --> 01:03:00.980]   Yeah, I don't think it could be that.
[01:03:00.980 --> 01:03:02.540]   And I don't know what purple is.
[01:03:02.540 --> 01:03:07.260]   The only purple I can remember is Lib purple, which is the, the libraries that allow you
[01:03:07.260 --> 01:03:11.260]   to do messaging with pigeon and other messaging programs.
[01:03:11.260 --> 01:03:12.900]   So I'm not sure what pink plus purple equals.
[01:03:12.900 --> 01:03:17.060]   I'm not quite sure what that, maybe they just, maybe it's just a color lesson.
[01:03:17.060 --> 01:03:19.060]   I know.
[01:03:19.060 --> 01:03:25.100]   Some day will all know, I think it's intentionally unclear, which is fun.
[01:03:25.100 --> 01:03:28.860]   What's the new wave Google plus?
[01:03:28.860 --> 01:03:34.540]   Oh, Google plus gosh, I still, that still breaks my heart.
[01:03:34.540 --> 01:03:36.460]   We hardly knew you hardly knew you.
[01:03:36.460 --> 01:03:37.460]   No one knew you.
[01:03:37.460 --> 01:03:41.300]   That was the problem.
[01:03:41.300 --> 01:03:42.300]   So, yeah.
[01:03:42.300 --> 01:03:48.540]   So, so my sort of bottom line here is it's another operating system experiment at Google.
[01:03:48.540 --> 01:03:51.820]   They've, there's lots of things they could be planning to use it for.
[01:03:51.820 --> 01:03:52.820]   We don't know yet.
[01:03:52.820 --> 01:03:53.820]   It doesn't have Java in it.
[01:03:53.820 --> 01:03:55.820]   It uses Dart, right?
[01:03:55.820 --> 01:03:58.540]   Well, I'm not suspicious that they use Dart.
[01:03:58.540 --> 01:03:59.540]   It's based on Dart.
[01:03:59.540 --> 01:04:00.540]   They said it's written in Dart.
[01:04:00.540 --> 01:04:01.540]   It's based on Dart.
[01:04:01.540 --> 01:04:02.540]   Yeah.
[01:04:02.540 --> 01:04:05.580]   But Dart, you know, if it's actually a color that doesn't make any difference, you know,
[01:04:05.580 --> 01:04:09.220]   if they, what they would want to do is get a stack up running or it, they can run, you
[01:04:09.220 --> 01:04:12.300]   know, Chrome and Android and things on top of it.
[01:04:12.300 --> 01:04:13.780]   Is Dart LL, what is it?
[01:04:13.780 --> 01:04:14.780]   LVL, what is it?
[01:04:14.780 --> 01:04:15.780]   LLVM, what is it?
[01:04:15.780 --> 01:04:16.780]   Dart.
[01:04:16.780 --> 01:04:17.780]   Yeah.
[01:04:17.780 --> 01:04:18.780]   Yeah, Google can buy it to LLVM.
[01:04:18.780 --> 01:04:21.060]   I mean, Dart is basically like mutant JavaScript.
[01:04:21.060 --> 01:04:22.860]   That's a bit more powerful.
[01:04:22.860 --> 01:04:25.060]   Yeah, but an operating system written in JavaScript.
[01:04:25.060 --> 01:04:27.060]   Now the future is here.
[01:04:27.060 --> 01:04:30.500]   Well, but we've had those, you know.
[01:04:30.500 --> 01:04:32.740]   The only toys.
[01:04:32.740 --> 01:04:34.820]   That was Palm OS and Firefox OS.
[01:04:34.820 --> 01:04:35.820]   We've had those.
[01:04:35.820 --> 01:04:38.420]   I mean, my TV is being run by one.
[01:04:38.420 --> 01:04:39.420]   Right.
[01:04:39.420 --> 01:04:40.420]   The LG TV that has a--
[01:04:40.420 --> 01:04:41.420]   I do too.
[01:04:41.420 --> 01:04:42.420]   It's Palm OS.
[01:04:42.420 --> 01:04:43.420]   It's so funny.
[01:04:43.420 --> 01:04:44.420]   I look at it and go, oh.
[01:04:44.420 --> 01:04:45.420]   This is kind of--
[01:04:45.420 --> 01:04:50.020]   There's no cards, but I feel like there's-- in that interface, there's stuff popping up.
[01:04:50.020 --> 01:04:52.220]   I feel like those could be cards.
[01:04:52.220 --> 01:04:53.220]   Yes.
[01:04:53.220 --> 01:04:55.300]   They just haven't popped them up yet or something.
[01:04:55.300 --> 01:04:58.300]   A little cards at the bottom that turn into full screen apps.
[01:04:58.300 --> 01:04:59.300]   Yeah.
[01:04:59.300 --> 01:05:01.700]   It's kind of fun.
[01:05:01.700 --> 01:05:08.180]   But yeah, you know, there's-- so it's a project.
[01:05:08.180 --> 01:05:11.140]   We don't know what size of a project is.
[01:05:11.140 --> 01:05:15.100]   And to say, oh, this is going to take over from the other ones, well, that would be involved
[01:05:15.100 --> 01:05:17.500]   quite a lot of change and not that likely.
[01:05:17.500 --> 01:05:18.500]   But you can think--
[01:05:18.500 --> 01:05:21.500]   I think the reason there's a speculation-- I mean, that's obviously true.
[01:05:21.500 --> 01:05:25.340]   The reason there's a speculation is you can think of some business reasons why Google
[01:05:25.340 --> 01:05:28.780]   would want to get out from under Java, would want to get out from under Linux.
[01:05:28.780 --> 01:05:32.620]   Samsung's doing Tizen for kind of the same reason they want to get out from under Google.
[01:05:32.620 --> 01:05:33.620]   Android.
[01:05:33.620 --> 01:05:34.620]   Yeah.
[01:05:34.620 --> 01:05:36.820]   So you can kind of understand that.
[01:05:36.820 --> 01:05:41.980]   But at some point, you know, for it to be useful as an operating system, you have to put
[01:05:41.980 --> 01:05:45.940]   a web browser on it, at which point you've put Chrome on it, at which point you've recreated
[01:05:45.940 --> 01:05:46.940]   Chrome OS.
[01:05:46.940 --> 01:05:51.060]   It's the missing plumbing, with some different plumbing, which is a perfect sensible thing
[01:05:51.060 --> 01:05:52.060]   to do.
[01:05:52.060 --> 01:05:56.420]   Android, there's more baggage there, but they're working on making that work because they're
[01:05:56.420 --> 01:05:58.700]   doing the Android on Chrome thing as well.
[01:05:58.700 --> 01:06:01.300]   So in principle, you can do that.
[01:06:01.300 --> 01:06:06.300]   In practice, there's a bunch of work to do to make those bits combine.
[01:06:06.300 --> 01:06:09.100]   And there's still the work to actually get the thing ported to a bunch of lower-level
[01:06:09.100 --> 01:06:10.900]   drivers and stuff like that.
[01:06:10.900 --> 01:06:14.660]   So when Firefox would bring in their things up, they were basically building something
[01:06:14.660 --> 01:06:18.140]   that would run on top of an Android phone because that's what exists.
[01:06:18.140 --> 01:06:19.540]   And this would be the same thing.
[01:06:19.540 --> 01:06:23.820]   That's the question of what layer in the stack are you suddenly just deciding things are
[01:06:23.820 --> 01:06:24.820]   different?
[01:06:24.820 --> 01:06:29.660]   We'll be talking about kernels next week on security now.
[01:06:29.660 --> 01:06:36.140]   We were talking on a twit about micro kernels versus, you know, whatever the opposite is,
[01:06:36.140 --> 01:06:39.940]   big normal kernels, and tiny kernel and little kernel.
[01:06:39.940 --> 01:06:43.140]   And Steve wanted to get some, wanted to clarify everything for us.
[01:06:43.140 --> 01:06:47.700]   So if you're interested in kernels, the notion of kernels, having to do with this as well
[01:06:47.700 --> 01:06:54.220]   with Fuchsia next Wednesday at security now, Google is killing Hangouts on air or, well,
[01:06:54.220 --> 01:07:00.020]   at least shifting it away from Google+, and making it YouTube live.
[01:07:00.020 --> 01:07:00.860]   Another blow to Hangouts.
[01:07:00.860 --> 01:07:03.300]   I just don't get what's going on with Hangouts.
[01:07:03.300 --> 01:07:04.300]   I really don't.
[01:07:04.300 --> 01:07:05.860]   I don't either.
[01:07:05.860 --> 01:07:07.500]   It can't die soon enough for me.
[01:07:07.500 --> 01:07:08.500]   You don't like it?
[01:07:08.500 --> 01:07:10.140]   Well, you don't need to use it.
[01:07:10.140 --> 01:07:11.140]   Right.
[01:07:11.140 --> 01:07:12.140]   No, I know.
[01:07:12.140 --> 01:07:15.460]   But every time I try to use it, just it never worked.
[01:07:15.460 --> 01:07:16.780]   I love it in theory.
[01:07:16.780 --> 01:07:19.380]   I love the idea that I could be talking to someone and be like, hey, let's take this
[01:07:19.380 --> 01:07:24.460]   to what I am, and be like, hey, let's take a divorce, or let me show you something, you
[01:07:24.460 --> 01:07:25.860]   know, on video.
[01:07:25.860 --> 01:07:28.940]   But it's not that easy.
[01:07:28.940 --> 01:07:29.940]   I don't like it.
[01:07:29.940 --> 01:07:30.940]   Yeah.
[01:07:30.940 --> 01:07:31.940]   I don't like it.
[01:07:31.940 --> 01:07:35.340]   Well, Google even says when you get Google Fi, oh, don't use Hangouts anymore.
[01:07:35.340 --> 01:07:36.860]   You should be using messages.
[01:07:36.860 --> 01:07:37.860]   Right.
[01:07:37.860 --> 01:07:38.860]   Yes.
[01:07:38.860 --> 01:07:39.860]   Yes.
[01:07:39.860 --> 01:07:40.860]   That's--
[01:07:40.860 --> 01:07:43.420]   Which is a very, by the way, nothing program doesn't do anything.
[01:07:43.420 --> 01:07:44.420]   Yeah.
[01:07:44.420 --> 01:07:45.420]   Yeah.
[01:07:45.420 --> 01:07:52.020]   They had the SMS app that was part of the built in Android one, the source one.
[01:07:52.020 --> 01:07:53.660]   And then they said, oh, use Hangouts.
[01:07:53.660 --> 01:07:56.100]   And then they don't missches.
[01:07:56.100 --> 01:07:57.100]   And then there's Google Voice.
[01:07:57.100 --> 01:07:58.100]   So I've got three separate--
[01:07:58.100 --> 01:07:59.100]   I know.
[01:07:59.100 --> 01:08:01.780]   --Google apps that want to take over where it's in it.
[01:08:01.780 --> 01:08:02.780]   No.
[01:08:02.780 --> 01:08:07.540]   Not to mention Facebook Messenger, which I used for a while.
[01:08:07.540 --> 01:08:11.940]   I can't wait to-- I guess-- will Alo be-- will it take over for Hangouts?
[01:08:11.940 --> 01:08:12.940]   Will it be the new thing?
[01:08:12.940 --> 01:08:15.980]   Well, but I suspect that's what they're thinking.
[01:08:15.980 --> 01:08:20.460]   They're saying, OK, we're going to really factor this into separate stuff.
[01:08:20.460 --> 01:08:24.620]   And obviously, it's much more fun to work on a shoddy new product than it is to keep
[01:08:24.620 --> 01:08:25.620]   the old one running.
[01:08:25.620 --> 01:08:29.100]   And that's, by the way, was it you who said that that's the structural problem within
[01:08:29.100 --> 01:08:30.660]   Google?
[01:08:30.660 --> 01:08:34.380]   Does the engineers are allowed to choose what projects they want to work on?
[01:08:34.380 --> 01:08:37.820]   So you always-- all the shiny new stuff gets all the attention.
[01:08:37.820 --> 01:08:42.420]   And it's hard to get a good engineer to keep working on the kind of maintenance of the
[01:08:42.420 --> 01:08:43.420]   machine.
[01:08:43.420 --> 01:08:44.420]   I'm not sure that's funny.
[01:08:44.420 --> 01:08:46.260]   I think maintenance is respected there as well.
[01:08:46.260 --> 01:08:47.420]   They do reward that too.
[01:08:47.420 --> 01:08:51.420]   So it's not just like-- but Apple has that problem too.
[01:08:51.420 --> 01:08:57.780]   Apple is very bad at-- it's been in the past, oh, let's make a new thing rather than maintain
[01:08:57.780 --> 01:08:58.780]   the old one.
[01:08:58.780 --> 01:09:01.620]   Yeah, nobody's maintaining iTunes apparently.
[01:09:01.620 --> 01:09:02.620]   Right.
[01:09:02.620 --> 01:09:04.180]   So do you remember iChat?
[01:09:04.180 --> 01:09:05.180]   iChat was actually pretty cool.
[01:09:05.180 --> 01:09:06.180]   iChat was good.
[01:09:06.180 --> 01:09:07.180]   Yeah, it was standard-spaced.
[01:09:07.180 --> 01:09:08.180]   They did it on the phone.
[01:09:08.180 --> 01:09:09.180]   Wasn't it XMMP?
[01:09:09.180 --> 01:09:10.180]   XMPP?
[01:09:10.180 --> 01:09:11.180]   It was XMPP.
[01:09:11.180 --> 01:09:13.180]   XMPP would interoperate with--
[01:09:13.180 --> 01:09:15.180]   That's what-- by the way, can I just--
[01:09:15.180 --> 01:09:17.860]   The video chat on that was standardized as well.
[01:09:17.860 --> 01:09:18.860]   Yeah.
[01:09:18.860 --> 01:09:21.660]   And then they did a part of that to iOS.
[01:09:21.660 --> 01:09:23.740]   And then they went away and built FaceTime.
[01:09:23.740 --> 01:09:26.100]   And Steve Jobs says, oh, we're open source this tomorrow.
[01:09:26.100 --> 01:09:27.100]   And you know--
[01:09:27.100 --> 01:09:28.100]   You never did.
[01:09:28.100 --> 01:09:29.100]   Never did.
[01:09:29.100 --> 01:09:30.100]   We're still waiting.
[01:09:30.100 --> 01:09:31.100]   Yeah.
[01:09:31.100 --> 01:09:35.940]   So yeah, there's-- to say this-- actually the company that's most care hearing about this
[01:09:35.940 --> 01:09:36.940]   has been Facebook.
[01:09:36.940 --> 01:09:41.580]   And even there, they bought another company because the other company is successful.
[01:09:41.580 --> 01:09:46.500]   But if you actually look at the way that Messenger works, it's a lot more coherent than
[01:09:46.500 --> 01:09:48.220]   the Google thing was.
[01:09:48.220 --> 01:09:50.780]   How old would you guess Hangouts is?
[01:09:50.780 --> 01:09:52.980]   Don't say if you know.
[01:09:52.980 --> 01:09:54.980]   Where did it come out?
[01:09:54.980 --> 01:09:56.500]   Yeah, don't try to figure it out.
[01:09:56.500 --> 01:09:57.980]   It was five years, 10 years.
[01:09:57.980 --> 01:09:59.820]   How long have we had it a long time?
[01:09:59.820 --> 01:10:01.220]   It feels like we've had a long time.
[01:10:01.220 --> 01:10:02.220]   Yeah.
[01:10:02.220 --> 01:10:03.220]   Three years old.
[01:10:03.220 --> 01:10:04.220]   You're right, Jeff.
[01:10:04.220 --> 01:10:05.220]   Three years old.
[01:10:05.220 --> 01:10:06.220]   Wow.
[01:10:06.220 --> 01:10:07.220]   That's all it is.
[01:10:07.220 --> 01:10:08.220]   Wow.
[01:10:08.220 --> 01:10:14.140]   It would be a little bit of good data journalism to do a kind of half-life of Google projects.
[01:10:14.140 --> 01:10:15.700]   Wouldn't that be interesting?
[01:10:15.700 --> 01:10:18.980]   Well, that's the site-death page on IndieWeb.
[01:10:18.980 --> 01:10:19.980]   You've seen that.
[01:10:19.980 --> 01:10:26.220]   It's IndieWeb.org/site-hive-and-death has the list of all the things that have been abandoned
[01:10:26.220 --> 01:10:28.860]   and have lost people's data.
[01:10:28.860 --> 01:10:32.100]   And it's a long list.
[01:10:32.100 --> 01:10:41.460]   So by the way, how do you feel about XMPP disappearing?
[01:10:41.460 --> 01:10:44.140]   I was really excited about XMPP.
[01:10:44.140 --> 01:10:47.860]   And I was really disappointed that Google abandoned it.
[01:10:47.860 --> 01:10:52.420]   Was there a good technical reason for that, Kevin?
[01:10:52.420 --> 01:10:54.100]   It's a complicated protocol.
[01:10:54.100 --> 01:10:59.460]   It was very XML-heavy and there was a bunch of craft in it.
[01:10:59.460 --> 01:11:00.940]   Okay.
[01:11:00.940 --> 01:11:04.100]   You could probably make a case that you could do things more optimally than sending stuff
[01:11:04.100 --> 01:11:05.100]   that way.
[01:11:05.100 --> 01:11:09.900]   But there was a nice interaction with it.
[01:11:09.900 --> 01:11:14.820]   It was used by Facebook and Google and AOL and a bunch of people.
[01:11:14.820 --> 01:11:15.940]   You could actually interop with it.
[01:11:15.940 --> 01:11:20.340]   And then that gradually got broken.
[01:11:20.340 --> 01:11:24.580]   I feel like all of this that we're talking about would have been eliminated if everybody
[01:11:24.580 --> 01:11:26.460]   just got in behind XMPP.
[01:11:26.460 --> 01:11:32.780]   To some extent, but the problem is it was bound to email addresses.
[01:11:32.780 --> 01:11:33.780]   It was federatable.
[01:11:33.780 --> 01:11:35.860]   Well, that's another thing, by the way.
[01:11:35.860 --> 01:11:40.820]   Why are we bound to phone numbers, especially if the telephone service is done?
[01:11:40.820 --> 01:11:42.660]   Why is POTS our unique number?
[01:11:42.660 --> 01:11:44.340]   Why is it an email address?
[01:11:44.340 --> 01:11:49.140]   Yeah, can you imagine a date pretty soon when you, just as you don't have a land lot,
[01:11:49.140 --> 01:11:50.740]   you don't have a phone.
[01:11:50.740 --> 01:11:51.980]   You have a connected computer.
[01:11:51.980 --> 01:11:52.980]   You have a...
[01:11:52.980 --> 01:11:53.980]   What do you need a land lot?
[01:11:53.980 --> 01:11:55.540]   And a phone number is not memorable.
[01:11:55.540 --> 01:11:56.540]   Why a phone number?
[01:11:56.540 --> 01:11:58.820]   Why not an email address or something else?
[01:11:58.820 --> 01:11:59.900]   But why not an email?
[01:11:59.900 --> 01:12:01.740]   And XMPP was interoperable.
[01:12:01.740 --> 01:12:02.780]   It was federatable.
[01:12:02.780 --> 01:12:04.300]   It had all these...
[01:12:04.300 --> 01:12:05.460]   It was very flexible.
[01:12:05.460 --> 01:12:08.380]   Yeah, I know it was XML, but it was very...
[01:12:08.380 --> 01:12:11.140]   Because of that, it was very parsable and extensible.
[01:12:11.140 --> 01:12:12.940]   It was highly extensible.
[01:12:12.940 --> 01:12:13.940]   Yep.
[01:12:13.940 --> 01:12:15.420]   I just...
[01:12:15.420 --> 01:12:16.420]   That makes me sad.
[01:12:16.420 --> 01:12:19.340]   Anyway, here's the list of site deaths.
[01:12:19.340 --> 01:12:23.980]   When sites go offline, taking your content with them.
[01:12:23.980 --> 01:12:26.140]   And you can see them all.
[01:12:26.140 --> 01:12:27.140]   It's your scroll.
[01:12:27.140 --> 01:12:29.700]   Upcoming ones and then...
[01:12:29.700 --> 01:12:32.180]   Any day now, paper data app, get Toriys.
[01:12:32.180 --> 01:12:37.340]   Are you doing physical devices too or just software services and software products?
[01:12:37.340 --> 01:12:38.340]   We could do physical...
[01:12:38.340 --> 01:12:39.340]   We're like a sample editor.
[01:12:39.340 --> 01:12:42.380]   It's a wiki, but it was mostly software products.
[01:12:42.380 --> 01:12:43.540]   It started out with...
[01:12:43.540 --> 01:12:44.540]   Yeah, we've...
[01:12:44.540 --> 01:12:45.540]   This is fun.
[01:12:45.540 --> 01:12:48.700]   Oh yeah, claim ID.
[01:12:48.700 --> 01:12:51.580]   I was really into that.
[01:12:51.580 --> 01:12:53.180]   Everpix, remember that?
[01:12:53.180 --> 01:12:55.500]   Oh man, this is depressing.
[01:12:55.500 --> 01:12:56.500]   Lava bit.
[01:12:56.500 --> 01:12:59.380]   We know why they went out of business.
[01:12:59.380 --> 01:13:00.380]   This is fun.
[01:13:00.380 --> 01:13:02.020]   I'm glad somebody put this together.
[01:13:02.020 --> 01:13:05.580]   What's the CMS on this, by the way?
[01:13:05.580 --> 01:13:06.580]   Is this a wiki?
[01:13:06.580 --> 01:13:07.580]   It's Media Wiki.
[01:13:07.580 --> 01:13:08.580]   Media Wiki.
[01:13:08.580 --> 01:13:09.580]   Yeah.
[01:13:09.580 --> 01:13:10.580]   Love Media Wiki.
[01:13:10.580 --> 01:13:11.580]   Thank you Media Wiki.
[01:13:11.580 --> 01:13:15.180]   So it's kind of heavyweight wiki, but it works.
[01:13:15.180 --> 01:13:16.740]   It's the job done.
[01:13:16.740 --> 01:13:17.740]   Yeah.
[01:13:17.740 --> 01:13:18.740]   Twitpick.
[01:13:18.740 --> 01:13:19.740]   Remember them?
[01:13:19.740 --> 01:13:20.740]   Glad they went away.
[01:13:20.740 --> 01:13:25.300]   Well, they kind of got eaten by the rest of...
[01:13:25.300 --> 01:13:28.180]   They're still around.
[01:13:28.180 --> 01:13:29.180]   Some day Twitter.
[01:13:29.180 --> 01:13:31.140]   Is Twitter on this list?
[01:13:31.140 --> 01:13:33.380]   Oh, I know.
[01:13:33.380 --> 01:13:34.380]   You know what?
[01:13:34.380 --> 01:13:35.540]   I'm too sorry.
[01:13:35.540 --> 01:13:36.940]   No, Twitter is...
[01:13:36.940 --> 01:13:39.220]   I didn't you love the article.
[01:13:39.220 --> 01:13:41.460]   Twitter is a honeypot for A-holes.
[01:13:41.460 --> 01:13:42.460]   Well researched.
[01:13:42.460 --> 01:13:44.820]   Yeah, it was.
[01:13:44.820 --> 01:13:47.740]   And it kind of said it all.
[01:13:47.740 --> 01:13:50.940]   And Twitter's response was the most anemic response ever.
[01:13:50.940 --> 01:13:52.660]   Whatever they've always made it.
[01:13:52.660 --> 01:13:57.460]   So I mean, the interesting thing for me reading that was remembering Ariel's initial complaints
[01:13:57.460 --> 01:13:59.100]   about it because they brought up Ariel.
[01:13:59.100 --> 01:14:01.500]   I didn't realize Ariel had been...
[01:14:01.500 --> 01:14:02.500]   Yeah, yeah.
[01:14:02.500 --> 01:14:04.620]   Or very early on.
[01:14:04.620 --> 01:14:05.620]   She's wonderful.
[01:14:05.620 --> 01:14:07.340]   What a terrible story.
[01:14:07.340 --> 01:14:08.340]   Yeah.
[01:14:08.340 --> 01:14:09.340]   And that's how this begins.
[01:14:09.340 --> 01:14:13.100]   This is Charlie Walsall's Buzzfeed article.
[01:14:13.100 --> 01:14:16.060]   Inside Twitter's 10 year failure to stop harassment.
[01:14:16.060 --> 01:14:20.300]   But I didn't realize it was one of the very first people to be harassed was Ariel Waldman.
[01:14:20.300 --> 01:14:24.220]   In 2008 when Twitter was about a year old.
[01:14:24.220 --> 01:14:26.580]   And Jack Dorsey promised to fix it.
[01:14:26.580 --> 01:14:27.580]   Never did.
[01:14:27.580 --> 01:14:28.580]   Nobody fixed it.
[01:14:28.580 --> 01:14:29.580]   Never did.
[01:14:29.580 --> 01:14:30.580]   She still uses Twitter.
[01:14:30.580 --> 01:14:33.380]   She still loves Twitter.
[01:14:33.380 --> 01:14:34.380]   Because what?
[01:14:34.380 --> 01:14:35.380]   Stockholm syndrome?
[01:14:35.380 --> 01:14:36.380]   Because...
[01:14:36.380 --> 01:14:37.380]   Well because...
[01:14:37.380 --> 01:14:38.380]   No, this was people who are still there.
[01:14:38.380 --> 01:14:39.380]   I mean the thing is in...
[01:14:39.380 --> 01:14:42.700]   Have an issue case it was someone who'd been stalking or elsewhere had moved on to Twitter
[01:14:42.700 --> 01:14:43.700]   as well.
[01:14:43.700 --> 01:14:44.700]   And Twitter gave them...
[01:14:44.700 --> 01:14:47.380]   Twitter was like fertilizer.
[01:14:47.380 --> 01:14:53.020]   It was like sunshine, rain and just everything it needed to grow.
[01:14:53.020 --> 01:14:55.580]   It was full food over the bridge.
[01:14:55.580 --> 01:14:56.580]   Yeah.
[01:14:56.580 --> 01:14:59.780]   I just linked to my piece I read in 2014 on this which was...
[01:14:59.780 --> 01:15:00.780]   Which was...
[01:15:00.780 --> 01:15:01.780]   Which was...
[01:15:01.780 --> 01:15:05.980]   For me it was a structural thing which was the thing that they changed.
[01:15:05.980 --> 01:15:10.780]   At the time, looking back at the responses they made to Ariel in 2008, they were basically
[01:15:10.780 --> 01:15:16.540]   saying no, no, Twitter isn't a platform for harassment because you choose what you see.
[01:15:16.540 --> 01:15:21.260]   It's not a place that people can just come at you.
[01:15:21.260 --> 01:15:24.500]   You have to go to your app to see it and by default you won't see it in your stream.
[01:15:24.500 --> 01:15:28.380]   And that was true in 2008 and they broke that gradually over the years.
[01:15:28.380 --> 01:15:33.340]   And they switched it from a place where your primary view was of things you'd chosen to
[01:15:33.340 --> 01:15:34.340]   follow.
[01:15:34.340 --> 01:15:36.260]   Like it was.
[01:15:36.260 --> 01:15:42.300]   So now the most urgent thing that can happen is somebody has added you which means it's
[01:15:42.300 --> 01:15:44.980]   become spoken email inbox.
[01:15:44.980 --> 01:15:51.060]   And also under your tweet any response from any random person is shown in chronological
[01:15:51.060 --> 01:15:52.940]   order and threaded.
[01:15:52.940 --> 01:15:55.340]   So it's also brought in the worst of blog comments as well.
[01:15:55.340 --> 01:15:59.740]   So they managed to combine the worst of email addresses having an open address that you
[01:15:59.740 --> 01:16:06.220]   can't turn stuff off with the worst of blog comments in the service of increasing interaction.
[01:16:06.220 --> 01:16:09.980]   And as a friend of mine as Google said long ago, it's the problem.
[01:16:09.980 --> 01:16:14.220]   Kevin, we've talked about this too, that when things are sender controlled, the recipient
[01:16:14.220 --> 01:16:15.740]   becomes the victim.
[01:16:15.740 --> 01:16:16.740]   Yes.
[01:16:16.740 --> 01:16:17.740]   Yeah.
[01:16:17.740 --> 01:16:26.460]   So as you saw that Leslie Jones, victim of Twitter, some pumpery just started a hashtag
[01:16:26.460 --> 01:16:30.660]   supporting Gabby Douglas for all the hell she's gone.
[01:16:30.660 --> 01:16:32.180]   Why do we keep going back there?
[01:16:32.180 --> 01:16:33.180]   It's not that good.
[01:16:33.180 --> 01:16:35.060]   I think we can do without it.
[01:16:35.060 --> 01:16:36.940]   Why do people keep going back?
[01:16:36.940 --> 01:16:38.900]   Why is Stephen Fry back on Twitter?
[01:16:38.900 --> 01:16:40.340]   Why did Leslie Jones go back?
[01:16:40.340 --> 01:16:45.220]   Because they suspended my own operas.
[01:16:45.220 --> 01:16:48.380]   But that wasn't that was the guy.
[01:16:48.380 --> 01:16:49.980]   It was the least of it.
[01:16:49.980 --> 01:16:53.460]   And it's like we want to like we want to stay on Twitter.
[01:16:53.460 --> 01:16:54.460]   But why?
[01:16:54.460 --> 01:16:56.020]   I don't understand the loyalty to it.
[01:16:56.020 --> 01:16:57.340]   Well, there's two things going on there.
[01:16:57.340 --> 01:17:02.940]   Well, one is it's the memory of when it was good in the same way that we keep using email,
[01:17:02.940 --> 01:17:04.500]   even though most of it is spam.
[01:17:04.500 --> 01:17:09.820]   We kind of remember when getting an email from someone you didn't know was that.
[01:17:09.820 --> 01:17:10.820]   Like me and Taco Bell.
[01:17:10.820 --> 01:17:12.980]   The style you're saying or Chipotle.
[01:17:12.980 --> 01:17:19.500]   No, it's so it's there is a set of us who got on Twitter early who had this mode of talking
[01:17:19.500 --> 01:17:20.700]   in public and having a call.
[01:17:20.700 --> 01:17:25.300]   It was so awesome in the early days that it picks up on the the blogging model as well
[01:17:25.300 --> 01:17:28.940]   of that semi overlapping public and the ability to see bits.
[01:17:28.940 --> 01:17:33.220]   But and I keep trying to use, you know, status net or the open and it just doesn't have the
[01:17:33.220 --> 01:17:34.220]   same.
[01:17:34.220 --> 01:17:37.540]   Yeah, it doesn't have the critical mass.
[01:17:37.540 --> 01:17:39.660]   It gains gains from scale.
[01:17:39.660 --> 01:17:45.900]   I mean, but the problem is the other thing that's the reason this is hard is that Twitter
[01:17:45.900 --> 01:17:51.300]   is built to move things between these different subgroups.
[01:17:51.300 --> 01:17:53.820]   And so it started out with just the just the subgroups.
[01:17:53.820 --> 01:17:57.820]   But then there's ways of bridging between them with hashtags with hat replies and so
[01:17:57.820 --> 01:18:01.620]   on so that you can move stuff in one place to another.
[01:18:01.620 --> 01:18:09.980]   But it's hard to tell what is, you know, just in systematic terms, what is the big trend
[01:18:09.980 --> 01:18:15.540]   thing that we should all be seeing and a sort of attack on somebody else without doing content
[01:18:15.540 --> 01:18:19.380]   analysis without actually checking it closely.
[01:18:19.380 --> 01:18:22.180]   And that's the piece that's the bit that's structurally difficult.
[01:18:22.180 --> 01:18:27.140]   The other thing is Paul Ford called it the other day Twitter is the angry social network,
[01:18:27.140 --> 01:18:29.420]   which I thought was a very good way of signing it up.
[01:18:29.420 --> 01:18:32.740]   Twitter is basically the place you go to shout out the cloud.
[01:18:32.740 --> 01:18:36.060]   When you have bad service, you go and shout out at companies on Twitter.
[01:18:36.060 --> 01:18:38.780]   And this is actually a good business for Twitter and to some extent for the companies
[01:18:38.780 --> 01:18:42.740]   because they're actually getting this feedback and the ability to respond to people who the
[01:18:42.740 --> 01:18:44.580]   most upset customers in real time.
[01:18:44.580 --> 01:18:47.620]   So there is a sort of structural value in that.
[01:18:47.620 --> 01:18:52.060]   It was also the place where you complained about your government and were able to start
[01:18:52.060 --> 01:18:53.540]   revolutions and things and so on.
[01:18:53.540 --> 01:18:57.620]   Paul, where you tore it out in the government like launching a presidential campaign at
[01:18:57.620 --> 01:18:58.620]   that?
[01:18:58.620 --> 01:19:06.140]   But the challenge is it's a bit like, you know the problem with Facebook is that everyone
[01:19:06.140 --> 01:19:11.500]   you see on Facebook has more friends than you and it's having a better time because A,
[01:19:11.500 --> 01:19:15.540]   the people who have more friends spread more widely and B, you only post the positive things
[01:19:15.540 --> 01:19:16.580]   on Facebook.
[01:19:16.580 --> 01:19:22.100]   So you have this effect that it feels like your life is compared to what you see on Facebook.
[01:19:22.100 --> 01:19:27.860]   Well Twitter, everyone you see on Twitter is angrier than you and also the anger is getting
[01:19:27.860 --> 01:19:33.260]   more traction in yours because for the same effect, the angry things get traction, they're
[01:19:33.260 --> 01:19:37.700]   spread, they're retweeted, they're shared, that is amplified round in the loop.
[01:19:37.700 --> 01:19:42.100]   So you know most tweets are, if you actually just like look at a stream of tweets at random,
[01:19:42.100 --> 01:19:44.700]   most tweets are anodyne and calm and so on.
[01:19:44.700 --> 01:19:47.340]   But that's not the perception you get when you look at Twitter, you see it being this
[01:19:47.340 --> 01:19:50.340]   place that people shout at each other because that's what's amplified.
[01:19:50.340 --> 01:19:53.140]   And therefore you start treating it as the place you go to shout at people.
[01:19:53.140 --> 01:19:57.620]   And so they've managed to take it from this, the place where you would just like send notes
[01:19:57.620 --> 01:20:00.700]   about what you're doing your day and your friends would see them and tweet about your
[01:20:00.700 --> 01:20:05.620]   lunch or whatever it is to this place where it's the place you go to shout at people that
[01:20:05.620 --> 01:20:06.620]   you don't know.
[01:20:06.620 --> 01:20:09.060]   Why would you want to go there?
[01:20:09.060 --> 01:20:11.380]   I can understand why you'd want to shout there.
[01:20:11.380 --> 01:20:12.740]   But why would you?
[01:20:12.740 --> 01:20:17.620]   I've learned about so many new to, I mean like I follow such a diverse group of people.
[01:20:17.620 --> 01:20:18.620]   Yes.
[01:20:18.620 --> 01:20:22.780]   And a lot of them are super nerdy and they'll start talking about, I don't know, a new programming
[01:20:22.780 --> 01:20:25.620]   language or something they've seen that they're excited about.
[01:20:25.620 --> 01:20:27.940]   I go to Hacker News for that.
[01:20:27.940 --> 01:20:30.620]   I go to, there's lots of other places you can get that.
[01:20:30.620 --> 01:20:36.020]   There are, but I mean Hacker News, it's already been written by the time it's on Hacker News.
[01:20:36.020 --> 01:20:38.420]   So I agree with Stacey.
[01:20:38.420 --> 01:20:43.460]   I see people like, you know, I just put something on the, on the, on the, uh, run down a second
[01:20:43.460 --> 01:20:51.460]   ago from Ben, um, Benedict Evans, uh, Mark Andreessen, towards Josh Marshall tweets.
[01:20:51.460 --> 01:20:53.460]   I mean, there's a Fred Wilson tweets.
[01:20:53.460 --> 01:20:58.180]   There's just all kinds of amazing people there who I wouldn't see otherwise.
[01:20:58.180 --> 01:21:04.500]   And I mean, the other thing is I, I actually feel like I have a nice community on Twitter.
[01:21:04.500 --> 01:21:10.100]   I have a lot of people who are like, engage with me on, you know, crazy questions about
[01:21:10.100 --> 01:21:15.700]   smart homes or just tell me that I'm wrong in a respectful way and then educate me, but
[01:21:15.700 --> 01:21:16.700]   not in a different way.
[01:21:16.700 --> 01:21:18.700]   Not some woods, Stacey, not some wood.
[01:21:18.700 --> 01:21:19.700]   I, I guess yes.
[01:21:19.700 --> 01:21:23.180]   But, but I feel like, I don't know.
[01:21:23.180 --> 01:21:26.260]   I, I like it, but I also feel that most human beings are good.
[01:21:26.260 --> 01:21:27.740]   So I do too.
[01:21:27.740 --> 01:21:28.740]   I used to anyway.
[01:21:28.740 --> 01:21:29.740]   I do too.
[01:21:29.740 --> 01:21:30.740]   No, it's the bad apples, the rules.
[01:21:30.740 --> 01:21:32.540]   The word I swear to God.
[01:21:32.540 --> 01:21:35.700]   It's pretty, pretty is ruined, my opinion, if humanity.
[01:21:35.700 --> 01:21:38.780]   That's reason enough not to go there.
[01:21:38.780 --> 01:21:39.940]   That was the Twitter that was built.
[01:21:39.940 --> 01:21:45.500]   It was the thing that they were saying in response to error was you choose who you see,
[01:21:45.500 --> 01:21:48.180]   you choose who you hear from, and you've got to make your choices.
[01:21:48.180 --> 01:21:51.980]   So part of it was, was that, and those of us who spent time deciding who we follow it
[01:21:51.980 --> 01:21:54.420]   and so on, that, that still works.
[01:21:54.420 --> 01:22:01.060]   But the challenges for the, you know, the sign up flow now forces you to follow publishing
[01:22:01.060 --> 01:22:05.300]   entities, but famous people, verified people, news sources and so on.
[01:22:05.300 --> 01:22:07.420]   It says pick one of these, pick one of these, pick one of these.
[01:22:07.420 --> 01:22:10.020]   We're not going to let you go through until you've got 30 people in your, in your following
[01:22:10.020 --> 01:22:12.060]   stream so you have something in your stream.
[01:22:12.060 --> 01:22:18.940]   So the sense of actually choosing people to follow, you know, organically has gone.
[01:22:18.940 --> 01:22:22.140]   And they may have needed to do that to, to get people to sign up at scale.
[01:22:22.140 --> 01:22:27.220]   But what it means is most people's perception of Twitter is that it's not that place where
[01:22:27.220 --> 01:22:28.540]   you have conversations with people.
[01:22:28.540 --> 01:22:32.140]   It's a place where famous people talk to each other and use sort of a shout and to the
[01:22:32.140 --> 01:22:33.140]   void at them.
[01:22:33.140 --> 01:22:37.460]   I just, Twitter makes me feel like a battered husband.
[01:22:37.460 --> 01:22:40.940]   And I suspect Ariel Wollman feels the same way.
[01:22:40.940 --> 01:22:45.620]   And, and I feel like I just keep making excuses for it and it keeps going back and it keeps
[01:22:45.620 --> 01:22:46.620]   the question.
[01:22:46.620 --> 01:22:50.820]   Is, you know, because there was a lot of conflict with the Olympics that Twitter was quick taking
[01:22:50.820 --> 01:22:52.420]   out anything with the IOC to say.
[01:22:52.420 --> 01:22:53.420]   Yeah.
[01:22:53.420 --> 01:22:54.420]   Oh, yeah.
[01:22:54.420 --> 01:22:55.420]   They take that.
[01:22:55.420 --> 01:22:56.420]   They take that.
[01:22:56.420 --> 01:22:57.420]   Yeah.
[01:22:57.420 --> 01:22:58.420]   All right.
[01:22:58.420 --> 01:22:59.420]   So tomorrow you're in charge of Twitter.
[01:22:59.420 --> 01:23:00.420]   Oh, I don't want to be in charge of Twitter.
[01:23:00.420 --> 01:23:01.420]   No, you fix it.
[01:23:01.420 --> 01:23:02.420]   I'm going to shut it down.
[01:23:02.420 --> 01:23:03.420]   If I were in charge of it, I'd shut it down.
[01:23:03.420 --> 01:23:07.820]   I'd give the stockholders, give the shareholders their money back and say, thank you very much.
[01:23:07.820 --> 01:23:08.820]   Bye bye.
[01:23:08.820 --> 01:23:11.220]   Well, I, I take that.
[01:23:11.220 --> 01:23:14.300]   What do you want to do?
[01:23:14.300 --> 01:23:18.660]   You know what we, we have, and I apologize for bringing this up again because we've really
[01:23:18.660 --> 01:23:19.660]   talked about this.
[01:23:19.660 --> 01:23:21.060]   Hash this to death.
[01:23:21.060 --> 01:23:25.860]   Add infinitum, a nauseam for years.
[01:23:25.860 --> 01:23:28.060]   And this is part of the abuse cycle.
[01:23:28.060 --> 01:23:29.940]   And, but how could you fix this?
[01:23:29.940 --> 01:23:30.940]   What would you do?
[01:23:30.940 --> 01:23:32.420]   But it's so great, but there's so much there.
[01:23:32.420 --> 01:23:33.420]   Okay.
[01:23:33.420 --> 01:23:34.420]   So the point is there isn't a quick fix.
[01:23:34.420 --> 01:23:37.580]   The problem is it is a cultural problem and you would have to disentangle the cultural
[01:23:37.580 --> 01:23:38.580]   elements in it.
[01:23:38.580 --> 01:23:43.900]   So if I was put in charge of Twitter, I would hire a bunch of sociologists and analysts
[01:23:43.900 --> 01:23:50.340]   of that nature to study this more closely and not just use simple engineering metrics
[01:23:50.340 --> 01:23:51.340]   like engagement.
[01:23:51.340 --> 01:23:52.340]   Bring data more than one.
[01:23:52.340 --> 01:23:53.340]   What do you have to do?
[01:23:53.340 --> 01:23:54.340]   Go ahead.
[01:23:54.340 --> 01:23:55.340]   Sorry.
[01:23:55.340 --> 01:23:57.020]   I was going to say bring data Boyd on.
[01:23:57.020 --> 01:23:59.420]   She can hire a film like herself.
[01:23:59.420 --> 01:24:01.700]   But, you know, she's, she's busy.
[01:24:01.700 --> 01:24:06.980]   But yeah, but people, you know, basically hire a team of people like Dana to analyze
[01:24:06.980 --> 01:24:08.940]   this and look at it from those perspectives.
[01:24:08.940 --> 01:24:15.940]   Like what is this doing?
[01:24:15.940 --> 01:24:17.500]   How is this affecting things?
[01:24:17.500 --> 01:24:18.860]   But also have this sense of, you know, the point is if you think about it as publics,
[01:24:18.860 --> 01:24:23.740]   this is sort of literary theory thing of each work has a public, each tweet has a public,
[01:24:23.740 --> 01:24:25.900]   each person's set of tweets has a public.
[01:24:25.900 --> 01:24:31.340]   And the idea is the public is the people that that thing is was written for and then
[01:24:31.340 --> 01:24:33.940]   the people who respond to it and go to that.
[01:24:33.940 --> 01:24:41.220]   And look at it in those terms and rethink it as this network of overlapping publics and
[01:24:41.220 --> 01:24:46.380]   think about how you can decide that rather than building a single overall ranking and
[01:24:46.380 --> 01:24:52.460]   collection and most popular and most treated, work at how you can make those publics coexist.
[01:24:52.460 --> 01:24:58.420]   I also think we just have to have to get to the point where the problem, you're going
[01:24:58.420 --> 01:24:59.420]   to have trolls.
[01:24:59.420 --> 01:25:00.420]   You have trolls in life.
[01:25:00.420 --> 01:25:01.420]   You have criminals in life.
[01:25:01.420 --> 01:25:02.420]   You have people who need beds in life.
[01:25:02.420 --> 01:25:06.060]   It's the problem with Twitter, the problem with all of this is the encouragement that
[01:25:06.060 --> 01:25:09.540]   the same people give them and the encouragement they get to do that.
[01:25:09.540 --> 01:25:10.540]   Oh, that's so funny.
[01:25:10.540 --> 01:25:11.540]   Oh, it's so wonderful.
[01:25:11.540 --> 01:25:13.540]   Let's go after.
[01:25:13.540 --> 01:25:17.900]   And the reward systems are set up wrong and we've got to change that fundamentally.
[01:25:17.900 --> 01:25:19.900]   We've got to change the rest of society, Kevin.
[01:25:19.900 --> 01:25:22.260]   I think you're right.
[01:25:22.260 --> 01:25:24.140]   It's not just a society.
[01:25:24.140 --> 01:25:25.540]   There is a difference.
[01:25:25.540 --> 01:25:28.980]   There is a set of affordances to amplify certain behaviors.
[01:25:28.980 --> 01:25:34.300]   So classically, if you're having a discussion on an email list, it will end up being a back
[01:25:34.300 --> 01:25:38.300]   and forth with you quoting each other because that's how you discuss an email list.
[01:25:38.300 --> 01:25:41.020]   If you're having a discussion on a wiki, it will end up in an edit wall because that's
[01:25:41.020 --> 01:25:42.860]   how you debate on wikis.
[01:25:42.860 --> 01:25:45.420]   You delete each other's stuff until there's something left.
[01:25:45.420 --> 01:25:48.900]   And that can be a different, lead to a different outcome.
[01:25:48.900 --> 01:25:51.140]   At least the wiki there will be something at the end of it.
[01:25:51.140 --> 01:25:53.060]   You may have deleted all the argument but there will be something there.
[01:25:53.060 --> 01:25:56.980]   Whereas the email list, all there is is this giant cross ongoing exchange that nobody cares
[01:25:56.980 --> 01:25:58.700]   about in the end.
[01:25:58.700 --> 01:26:05.820]   Twitter had picked up something from the blogging world which was this sense that you can't
[01:26:05.820 --> 01:26:09.420]   see the whole conversation but you can see bits of it and follow parts of it and make
[01:26:09.420 --> 01:26:10.980]   sense.
[01:26:10.980 --> 01:26:14.300]   But they atomized into these small pieces that were kind of composable so you could
[01:26:14.300 --> 01:26:19.340]   have a conversation that went back and forth without the effort of doing the block quote
[01:26:19.340 --> 01:26:23.580]   response type stuff that we do when we write the longer blog post.
[01:26:23.580 --> 01:26:29.740]   But as I say, the change they made in emphasizing at replies without a sense of who you were
[01:26:29.740 --> 01:26:35.660]   following kind of broke that model in that they've got bits of it that can bring back
[01:26:35.660 --> 01:26:36.820]   but they changed the default.
[01:26:36.820 --> 01:26:42.580]   So the defaults are designed to get stuff to flow more quickly and amplify it.
[01:26:42.580 --> 01:26:47.460]   And if you look at it as our goal is to get stuff to spread more, that's what you do.
[01:26:47.460 --> 01:26:51.260]   But actually a very small amount of Twitter is that stuff that should spread that far
[01:26:51.260 --> 01:26:55.420]   and cross all these groups and there's much more value in the stuff that happens within
[01:26:55.420 --> 01:26:56.420]   groups.
[01:26:56.420 --> 01:26:59.420]   So modeling that better and understanding how you could do that would be the interesting
[01:26:59.420 --> 01:27:00.420]   part.
[01:27:00.420 --> 01:27:03.620]   And they've probably spent a bunch of time looking at this and trying to make sense of
[01:27:03.620 --> 01:27:10.860]   it but they have been very focused for obvious and sensible reasons on making sure that
[01:27:10.860 --> 01:27:15.820]   the people who have millions of followers and who are public figures have that work
[01:27:15.820 --> 01:27:21.020]   for them and they somehow lost the middle of people who suddenly become famous or suddenly
[01:27:21.020 --> 01:27:25.980]   have their thing take off and have sort of transitioned from I'm talking to 20 friends
[01:27:25.980 --> 01:27:29.740]   to I'm suddenly in front of the entire world and things are going weird.
[01:27:29.740 --> 01:27:31.500]   Like Gabby Douglas.
[01:27:31.500 --> 01:27:32.500]   Gabby Douglas.
[01:27:32.500 --> 01:27:34.340]   That's so tragic.
[01:27:34.340 --> 01:27:40.580]   But Gabby does, you know, you could predict that because she was on television and she
[01:27:40.580 --> 01:27:42.580]   had been pushed up from that platform.
[01:27:42.580 --> 01:27:47.100]   Yeah, why does being intelligent make you a target, a legitimate target?
[01:27:47.100 --> 01:27:52.060]   Yeah, the argument is, oh, you're a public, you deserve this.
[01:27:52.060 --> 01:27:53.980]   She's an athlete.
[01:27:53.980 --> 01:27:55.820]   But it means that you're a target for attention.
[01:27:55.820 --> 01:27:59.380]   You suddenly have a large amount of attention.
[01:27:59.380 --> 01:28:03.860]   They can predict that they know to do this for, you know, contestants in American Idol
[01:28:03.860 --> 01:28:04.860]   things like that.
[01:28:04.860 --> 01:28:08.220]   They'll set them up, they'll have someone work it out so that they've filtered and modeling
[01:28:08.220 --> 01:28:09.220]   that.
[01:28:09.220 --> 01:28:14.820]   But the tougher thing is when somebody, you know, makes that, invents the hashtag that
[01:28:14.820 --> 01:28:18.540]   catches the political zeitgeist and then they're rocketed to them and then they become the
[01:28:18.540 --> 01:28:22.700]   target of the opposing faction and who will then try and tear them down and work that
[01:28:22.700 --> 01:28:23.700]   out.
[01:28:23.700 --> 01:28:25.700]   And that's when the harassment piles.
[01:28:25.700 --> 01:28:29.500]   I feel like it's facilitated and this, the Gabby Douglas thing is a great example.
[01:28:29.500 --> 01:28:34.260]   It's facilitated this kind of gotcha quick to judge.
[01:28:34.260 --> 01:28:35.260]   Oh, yeah.
[01:28:35.260 --> 01:28:36.260]   Meaningless dietary.
[01:28:36.260 --> 01:28:39.260]   People have always been like that.
[01:28:39.260 --> 01:28:43.940]   Yeah, but no, of course they have, but they haven't had a platform and now you can trash
[01:28:43.940 --> 01:28:44.940]   somebody.
[01:28:44.940 --> 01:28:45.940]   I mean, you can really trash somebody.
[01:28:45.940 --> 01:28:47.540]   You can cause somebody to lose their job.
[01:28:47.540 --> 01:28:51.380]   You can put people, you know, in her riff, you can have people kill himself.
[01:28:51.380 --> 01:28:55.860]   I mean, she was devastated because she didn't put her hand over her heart.
[01:28:55.860 --> 01:28:56.860]   Right.
[01:28:56.860 --> 01:28:58.020]   I mean, this is ridiculous.
[01:28:58.020 --> 01:28:59.020]   This is ridiculous.
[01:28:59.020 --> 01:29:03.660]   You could do that with a television station or a newspaper.
[01:29:03.660 --> 01:29:09.140]   Not in anywhere near this kind of this way, another massive feed that was always in your
[01:29:09.140 --> 01:29:10.140]   way.
[01:29:10.140 --> 01:29:11.140]   Yeah.
[01:29:11.140 --> 01:29:12.140]   No, this is just terrible.
[01:29:12.140 --> 01:29:13.140]   It's just terrible.
[01:29:13.140 --> 01:29:14.740]   I don't want to talk about it anymore.
[01:29:14.740 --> 01:29:16.900]   My personal choice is not to have anything to do with it.
[01:29:16.900 --> 01:29:20.740]   I don't even want to talk about what, you know, with her Twitter anymore.
[01:29:20.740 --> 01:29:25.380]   Ford had an event in the Silicon Valley right before IDF coincidence.
[01:29:25.380 --> 01:29:29.780]   I don't know in which they announced by 2021.
[01:29:29.780 --> 01:29:30.780]   Wait a minute.
[01:29:30.780 --> 01:29:31.780]   What?
[01:29:31.780 --> 01:29:32.780]   Let me check.
[01:29:32.780 --> 01:29:33.780]   That's five years from now.
[01:29:33.780 --> 01:29:36.500]   They're going to have a fleet of type four fully autonomous cars operating in a ride
[01:29:36.500 --> 01:29:38.340]   hailing service.
[01:29:38.340 --> 01:29:40.380]   What?
[01:29:40.380 --> 01:29:47.380]   You think that's possible five years from now that we'll be ride hailing a driverless vehicle?
[01:29:47.380 --> 01:29:51.460]   Um, no.
[01:29:51.460 --> 01:29:56.700]   It's so funny because for years, for years when Alan Malali was a CEO and it was, and
[01:29:56.700 --> 01:29:59.780]   people were starting to talk about autonomous vehicles, I would ask Alan every time I interviewed
[01:29:59.780 --> 01:30:00.780]   him.
[01:30:00.780 --> 01:30:02.540]   So what's going on with four autonomous vehicles?
[01:30:02.540 --> 01:30:04.100]   He said, Oh no, people love to drive.
[01:30:04.100 --> 01:30:05.900]   We're never going to do autonomous vehicles.
[01:30:05.900 --> 01:30:07.460]   I said, come on.
[01:30:07.460 --> 01:30:08.820]   You got a, you got a skunk work.
[01:30:08.820 --> 01:30:10.220]   So you got a place in the back there.
[01:30:10.220 --> 01:30:11.220]   You're doing it.
[01:30:11.220 --> 01:30:13.300]   No, people love to drive.
[01:30:13.300 --> 01:30:17.620]   Now they've said, now level four is not fully autonomous.
[01:30:17.620 --> 01:30:20.180]   It's one level below.
[01:30:20.180 --> 01:30:22.580]   So you do need, I guess, a driver.
[01:30:22.580 --> 01:30:25.620]   I'm not clear what Ford's saying they're going to do here.
[01:30:25.620 --> 01:30:31.180]   So to get a fully autonomous car like level five is at NIST levels, we need to have a
[01:30:31.180 --> 01:30:37.140]   regulatory overhaul and insurance overhaul in a lot of big conversations.
[01:30:37.140 --> 01:30:41.740]   So the idea that that's all going to happen before 2021, I think is ludicrous.
[01:30:41.740 --> 01:30:42.740]   Yeah.
[01:30:42.740 --> 01:30:47.860]   So, and I think the media is somewhat complicit in talking about autonomous vehicles and being
[01:30:47.860 --> 01:30:50.660]   like, this is a self-driving car.
[01:30:50.660 --> 01:30:53.540]   When in fact, we shouldn't be calling them that.
[01:30:53.540 --> 01:30:56.820]   We kind of got in trouble with that in Tesla, with the autopilot.
[01:30:56.820 --> 01:30:58.820]   Tesla also called it autopilot.
[01:30:58.820 --> 01:30:59.820]   Yeah.
[01:30:59.820 --> 01:31:01.940]   And I think they were wrong to do that.
[01:31:01.940 --> 01:31:02.940]   I think there still are.
[01:31:02.940 --> 01:31:03.940]   Yeah.
[01:31:03.940 --> 01:31:05.220]   They've stopped doing it in China.
[01:31:05.220 --> 01:31:06.220]   Yes.
[01:31:06.220 --> 01:31:10.820]   But I think that this idea is great.
[01:31:10.820 --> 01:31:14.020]   And we have a lot of technology that's going to get us there by 2021.
[01:31:14.020 --> 01:31:17.380]   We're going to have some really awesome vehicles on the road.
[01:31:17.380 --> 01:31:23.340]   And our participation could be very little, but we're not going to be able to hop in our
[01:31:23.340 --> 01:31:28.660]   little pods and have it zip us off places and then go zip off and park on its own.
[01:31:28.660 --> 01:31:33.860]   No, they're saying level four, but they're also saying that the biggest cost of having
[01:31:33.860 --> 01:31:36.420]   a ride sharing service is the driver.
[01:31:36.420 --> 01:31:38.340]   So it implies they're going to get rid of the driver.
[01:31:38.340 --> 01:31:40.780]   So I don't know exactly.
[01:31:40.780 --> 01:31:45.420]   Maybe I will have to sit behind the wheel of my tax tab just to make sure it doesn't run
[01:31:45.420 --> 01:31:46.420]   into something.
[01:31:46.420 --> 01:31:47.420]   No way.
[01:31:47.420 --> 01:31:48.420]   You can do that.
[01:31:48.420 --> 01:31:49.980]   Because if you got what is that massively trash?
[01:31:49.980 --> 01:31:52.660]   No, that's not going to work.
[01:31:52.660 --> 01:31:58.180]   No, so the point is it'll be a system that works in certain areas.
[01:31:58.180 --> 01:31:59.980]   And it doesn't try and drive everywhere.
[01:31:59.980 --> 01:32:00.980]   And it has--
[01:32:00.980 --> 01:32:01.980]   Yeah.
[01:32:01.980 --> 01:32:05.060]   It's basically like an automated bus route.
[01:32:05.060 --> 01:32:08.940]   I guess when they say they plan to have a fleet, it could be a fleet of 100 vehicles
[01:32:08.940 --> 01:32:10.860]   and it could be in Nebraska.
[01:32:10.860 --> 01:32:11.860]   We don't.
[01:32:11.860 --> 01:32:12.860]   We're not sure what that means exactly.
[01:32:12.860 --> 01:32:15.700]   I think that would be a great place, actually.
[01:32:15.700 --> 01:32:16.700]   Yeah.
[01:32:16.700 --> 01:32:17.700]   Yeah.
[01:32:17.700 --> 01:32:18.700]   Yeah.
[01:32:18.700 --> 01:32:19.700]   Huge.
[01:32:19.700 --> 01:32:21.820]   It's an easier problem in lots of ways, yes.
[01:32:21.820 --> 01:32:29.220]   Tesla says that their next-- well, rumor says that Tesla's next version will be fully
[01:32:29.220 --> 01:32:31.820]   autonomous.
[01:32:31.820 --> 01:32:37.700]   Autopilot 2.0.
[01:32:37.700 --> 01:32:41.340]   This is the Model 3?
[01:32:41.340 --> 01:32:46.420]   Well, Elon Musk's goal is by 2019 to have a fully autonomous.
[01:32:46.420 --> 01:32:53.020]   According to Jalopnik, Tesla's next version of Autopilot may go fully autonomous.
[01:32:53.020 --> 01:32:58.820]   Now version 8 of the software is due soon, I think, right?
[01:32:58.820 --> 01:33:00.620]   I don't know if they're talking about that.
[01:33:00.620 --> 01:33:06.020]   They're talking about a new sensor suite that will allow level 3 autonomous driving, potentially
[01:33:06.020 --> 01:33:10.180]   level 4 fully autonomous driving in a not too distant future.
[01:33:10.180 --> 01:33:18.060]   More radar, front facing radar, plus side radar, plus a triple camera system.
[01:33:18.060 --> 01:33:22.500]   So they're really trying to increase the capabilities of the car.
[01:33:22.500 --> 01:33:26.780]   Right now, I have a camera in the front of camera in the back and I think radar and I
[01:33:26.780 --> 01:33:27.780]   can't remember.
[01:33:27.780 --> 01:33:31.140]   It's not anywhere near enough sensors to really do even level 3.
[01:33:31.140 --> 01:33:33.300]   Man, I've hopped a curb.
[01:33:33.300 --> 01:33:34.300]   Yeah.
[01:33:34.300 --> 01:33:37.700]   The sensors did not help me in that situation.
[01:33:37.700 --> 01:33:39.660]   So I don't know.
[01:33:39.660 --> 01:33:47.100]   I can't decide if this is hype that years off, kind of like artificial intelligence.
[01:33:47.100 --> 01:33:48.580]   We have to get around.
[01:33:48.580 --> 01:33:49.580]   I mean, but in a way--
[01:33:49.580 --> 01:33:53.460]   And you're right, there's a huge regulatory hurdle too, not just a technical hurdle.
[01:33:53.460 --> 01:33:57.620]   But this actually, by talking about it and setting these deadlines, even if we don't
[01:33:57.620 --> 01:34:00.900]   quite meet them in the way we hoped, it does get people excited.
[01:34:00.900 --> 01:34:05.260]   It gets-- I mean, legislators are like, oh, now we should think about self-driving cars.
[01:34:05.260 --> 01:34:06.260]   Right.
[01:34:06.260 --> 01:34:07.260]   I think that's the one thing.
[01:34:07.260 --> 01:34:10.660]   He puts-- it puts-- it puts-- you know, osmotic conversation going on.
[01:34:10.660 --> 01:34:11.660]   That's the problem.
[01:34:11.660 --> 01:34:12.660]   And you have stage competing with each other.
[01:34:12.660 --> 01:34:15.860]   We'll be the first state with autonomous vehicles and all that kind of stuff.
[01:34:15.860 --> 01:34:16.860]   Yeah.
[01:34:16.860 --> 01:34:17.860]   Yeah.
[01:34:17.860 --> 01:34:18.860]   So it's a PR thing.
[01:34:18.860 --> 01:34:19.860]   I think you're right.
[01:34:19.860 --> 01:34:21.580]   But did you guys see about Tesla camping?
[01:34:21.580 --> 01:34:22.580]   No.
[01:34:22.580 --> 01:34:23.580]   It's exciting.
[01:34:23.580 --> 01:34:25.220]   It's a new kind of clamping.
[01:34:25.220 --> 01:34:26.700]   What is Tesla camping?
[01:34:26.700 --> 01:34:29.340]   So there's a Bloomberg had a story about it.
[01:34:29.340 --> 01:34:34.340]   And I thought this was great because they people drive their Tesla Model 3s back out
[01:34:34.340 --> 01:34:38.860]   into the woods and they leave them all night because you can have, you know, air conditioning
[01:34:38.860 --> 01:34:42.900]   and bugs don't get in or whatever.
[01:34:42.900 --> 01:34:43.900]   Yes.
[01:34:43.900 --> 01:34:44.900]   I think this is awesome.
[01:34:44.900 --> 01:34:45.900]   Wow.
[01:34:45.900 --> 01:34:46.900]   So--
[01:34:46.900 --> 01:34:48.500]   I mean, he lived in his trunk?
[01:34:48.500 --> 01:34:50.580]   Well, I mean, he filled the seats back.
[01:34:50.580 --> 01:34:52.980]   You can see the pictures if he's scrolled down.
[01:34:52.980 --> 01:34:55.180]   He's kind of cheering right this.
[01:34:55.180 --> 01:34:56.180]   Oh, camping mode.
[01:34:56.180 --> 01:34:58.380]   Well, I could do this in my Model X. Easy.
[01:34:58.380 --> 01:34:59.380]   Yeah.
[01:34:59.380 --> 01:35:03.460]   I think we'll have developers doing this in the parking lot of Google soon.
[01:35:03.460 --> 01:35:05.060]   So there's-- yeah, there's exactly.
[01:35:05.060 --> 01:35:06.060]   There's--
[01:35:06.060 --> 01:35:07.060]   I'll be doing it.
[01:35:07.060 --> 01:35:08.060]   I can do this in my--
[01:35:08.060 --> 01:35:09.060]   In my--
[01:35:09.060 --> 01:35:11.500]   But your air conditioning doesn't run.
[01:35:11.500 --> 01:35:14.060]   No, but it doesn't run all night without, you know, I--
[01:35:14.060 --> 01:35:18.660]   There's enough-- but you're saying there's enough battery in there to really do-- there's
[01:35:18.660 --> 01:35:20.860]   USB ports to keep your phone going.
[01:35:20.860 --> 01:35:24.140]   There's dome lights that LED lights that could run all night.
[01:35:24.140 --> 01:35:26.140]   There's air filtration fans.
[01:35:26.140 --> 01:35:29.140]   It's like a portable house you bring to the woods.
[01:35:29.140 --> 01:35:30.140]   I mean, really--
[01:35:30.140 --> 01:35:33.780]   Oh, he also says, do yourself a favor.
[01:35:33.780 --> 01:35:36.300]   Pick up a portable electric espresso maker, a kettle.
[01:35:36.300 --> 01:35:37.900]   They plug right into the car.
[01:35:37.900 --> 01:35:38.900]   What the what?
[01:35:38.900 --> 01:35:41.500]   Now, really, do you have enough juice to do this?
[01:35:41.500 --> 01:35:42.500]   Hmm?
[01:35:42.500 --> 01:35:43.980]   That's what I thought was awesome.
[01:35:43.980 --> 01:35:45.580]   He's talking about it.
[01:35:45.580 --> 01:35:46.900]   It barely used any.
[01:35:46.900 --> 01:35:48.620]   Oh, I got to try this.
[01:35:48.620 --> 01:35:51.420]   Well, I just work in California where it's cool at night.
[01:35:51.420 --> 01:35:52.900]   Yeah, I'm going to try to work some work.
[01:35:52.900 --> 01:35:57.300]   Well, that's why it would be great in Texas, because like, I want to go camping, but you're
[01:35:57.300 --> 01:35:58.300]   really--
[01:35:58.300 --> 01:36:01.380]   Well, Theo, you can fold up your Casper mattress in the back.
[01:36:01.380 --> 01:36:02.380]   Yeah.
[01:36:02.380 --> 01:36:07.700]   You'd have-- they'd have to give you like a camping vacuum pump to like, look it back
[01:36:07.700 --> 01:36:10.940]   down into its original packaging.
[01:36:10.940 --> 01:36:11.940]   I don't know.
[01:36:11.940 --> 01:36:14.340]   I thought this was hilarious and awesome.
[01:36:14.340 --> 01:36:15.340]   Go people.
[01:36:15.340 --> 01:36:18.580]   He had to throw a towel over the 17-inch screen of the phone.
[01:36:18.580 --> 01:36:21.500]   And Frank has to be too bright.
[01:36:21.500 --> 01:36:22.500]   That's a feature for me.
[01:36:22.500 --> 01:36:24.060]   My daughter, she likes having a phone.
[01:36:24.060 --> 01:36:25.060]   A little nightlight.
[01:36:25.060 --> 01:36:26.060]   Yeah, yeah.
[01:36:26.060 --> 01:36:30.820]   So I'm going to say like, it doesn't quite add up, because an RV costs less than a Tesla.
[01:36:30.820 --> 01:36:31.820]   Yeah.
[01:36:31.820 --> 01:36:33.380]   Well, the same order by the two is a Tesla.
[01:36:33.380 --> 01:36:35.060]   If you've already got a Tesla, just--
[01:36:35.060 --> 01:36:36.060]   Yeah, I'm not going to--
[01:36:36.060 --> 01:36:37.060]   I never--
[01:36:37.060 --> 01:36:38.820]   Well, you can limit it now.
[01:36:38.820 --> 01:36:41.340]   You may need to if you've already got a Tesla.
[01:36:41.340 --> 01:36:44.340]   But also, they have infrastructure.
[01:36:44.340 --> 01:36:45.340]   Yeah, yeah.
[01:36:45.340 --> 01:36:46.340]   They're a cost of hookups.
[01:36:46.340 --> 01:36:47.340]   You can go and like plug your thing in and--
[01:36:47.340 --> 01:36:50.900]   But the cool thing about this is you do have LTE.
[01:36:50.900 --> 01:36:52.380]   You have power.
[01:36:52.380 --> 01:36:53.860]   You have USB.
[01:36:53.860 --> 01:36:56.980]   You have a giant battery.
[01:36:56.980 --> 01:36:58.700]   You just need the Tesla toilet.
[01:36:58.700 --> 01:36:59.700]   Oh.
[01:36:59.700 --> 01:37:01.300]   Yeah, that is--
[01:37:01.300 --> 01:37:02.300]   That is--
[01:37:02.300 --> 01:37:03.300]   That's an issue.
[01:37:03.300 --> 01:37:04.300]   You know what?
[01:37:04.300 --> 01:37:07.260]   What you may need is a sort of large solar panel to lay down so that you can line in the
[01:37:07.260 --> 01:37:09.020]   morning it'll recharge the car.
[01:37:09.020 --> 01:37:10.500]   Camp next to a supercharger.
[01:37:10.500 --> 01:37:11.500]   You're saying--
[01:37:11.500 --> 01:37:14.300]   Because I can't afford a Tesla, I'm going to sell my house and just buy that.
[01:37:14.300 --> 01:37:15.300]   And I'll live in it.
[01:37:15.300 --> 01:37:16.300]   Yeah, exactly.
[01:37:16.300 --> 01:37:17.940]   I might be doing the same.
[01:37:17.940 --> 01:37:18.940]   Maybe our new studio.
[01:37:18.940 --> 01:37:19.940]   Who knows?
[01:37:19.940 --> 01:37:20.940]   I don't know.
[01:37:20.940 --> 01:37:22.220]   Audi's cars will be able to tell drivers.
[01:37:22.220 --> 01:37:25.300]   I think every car should have this when the red light turns green.
[01:37:25.300 --> 01:37:27.020]   I didn't get this one, Leo.
[01:37:27.020 --> 01:37:28.940]   I didn't understand what the benefit of this one was.
[01:37:28.940 --> 01:37:29.940]   Well--
[01:37:29.940 --> 01:37:31.700]   I think it should be when a green light's about to turn.
[01:37:31.700 --> 01:37:35.220]   I know we've got yellow lights, but some yellow lights are shorter than others.
[01:37:35.220 --> 01:37:38.420]   The idea is sometimes you're at a red light.
[01:37:38.420 --> 01:37:44.820]   You want to just close your eyes for a minute or cut your nails or text.
[01:37:44.820 --> 01:37:50.460]   Now the car will show the time remaining before a light turns green.
[01:37:50.460 --> 01:37:54.740]   And then maybe Italy-- how does it know though?
[01:37:54.740 --> 01:37:56.140]   Because it's got this data.
[01:37:56.140 --> 01:37:59.020]   Oh, the city's publishing this, huh?
[01:37:59.020 --> 01:38:02.820]   You can know people are going to jump the-- I'm telling you, I'm counting the days till
[01:38:02.820 --> 01:38:04.220]   there's an accident around now.
[01:38:04.220 --> 01:38:05.220]   Yeah, because you can get these.
[01:38:05.220 --> 01:38:07.220]   People are going to jump the light.
[01:38:07.220 --> 01:38:11.900]   That was hard for people who run an orange light as I like to do.
[01:38:11.900 --> 01:38:13.860]   It's great for drag racing.
[01:38:13.860 --> 01:38:14.780]   Orange light.
[01:38:14.780 --> 01:38:16.020]   Orange thing is an orange light.
[01:38:16.020 --> 01:38:17.860]   Is that what you've been telling yourself that is?
[01:38:17.860 --> 01:38:18.860]   That's what you call it.
[01:38:18.860 --> 01:38:19.860]   Red.
[01:38:19.860 --> 01:38:20.860]   Yellow light turns red.
[01:38:20.860 --> 01:38:23.140]   It's red when you're in the middle of the intersection.
[01:38:23.140 --> 01:38:24.540]   Oh, that's a good name for it.
[01:38:24.540 --> 01:38:26.340]   I'll go with that from now on.
[01:38:26.340 --> 01:38:31.060]   You're a-- you show you the yellow both ways.
[01:38:31.060 --> 01:38:32.060]   Yeah.
[01:38:32.060 --> 01:38:33.060]   Before it's red and before it's green.
[01:38:33.060 --> 01:38:34.060]   Oh.
[01:38:34.060 --> 01:38:35.060]   Yeah.
[01:38:35.060 --> 01:38:36.060]   Oh.
[01:38:36.060 --> 01:38:37.060]   That's a good idea just to let you know.
[01:38:37.060 --> 01:38:38.060]   Yes.
[01:38:38.060 --> 01:38:41.100]   It doesn't buzz you to stop you from clipping your nails, but you shouldn't be doing that
[01:38:41.100 --> 01:38:42.100]   anyway.
[01:38:42.100 --> 01:38:48.660]   I'm Tim Berners-Lee's plan to reclaim the internet from Facebook and Google.
[01:38:48.660 --> 01:38:52.700]   I was slightly amused by a side of giving that I wrote another article about this right
[01:38:52.700 --> 01:38:55.860]   after the Centralized Web Summit, which actually mentioned more things.
[01:38:55.860 --> 01:38:56.860]   Oh.
[01:38:56.860 --> 01:38:58.860]   Well, David Weinberger's a pretty good guy there.
[01:38:58.860 --> 01:39:01.500]   I was teasing one bird about that.
[01:39:01.500 --> 01:39:03.940]   So there's a bunch of things going on.
[01:39:03.940 --> 01:39:07.860]   So the decentralized Web Summit happened in June at Internet Archive, and a bunch of
[01:39:07.860 --> 01:39:11.940]   people came, including Tim Berners-Lee and everyone who's working on all of these projects
[01:39:11.940 --> 01:39:12.940]   and work on that.
[01:39:12.940 --> 01:39:20.460]   And this one is sort of highlighting solid, which is Tim's research project MIT.
[01:39:20.460 --> 01:39:22.660]   It's not a W3C thing.
[01:39:22.660 --> 01:39:28.420]   It's based on linked data, but it's basically a privately funded group there that's trying
[01:39:28.420 --> 01:39:29.420]   to build something.
[01:39:29.420 --> 01:39:32.620]   Is it a silo for your personal data?
[01:39:32.620 --> 01:39:37.700]   It's supposed to be a sort of-- you store it on your own server.
[01:39:37.700 --> 01:39:41.900]   So it has sort of some individual-- the base head is you store it on your own server.
[01:39:41.900 --> 01:39:46.900]   And you bring the app to it, and it gets the data from it there, and then sends it back.
[01:39:46.900 --> 01:39:49.540]   So it's that kind of model.
[01:39:49.540 --> 01:39:54.540]   So a third party like Google or Facebook could ask for data from my pod.
[01:39:54.540 --> 01:39:55.540]   It'd bring the pod.
[01:39:55.540 --> 01:40:01.820]   And I could charge them for that, or I'd have permissions.
[01:40:01.820 --> 01:40:02.820]   That's the idea.
[01:40:02.820 --> 01:40:07.380]   I mean, the thing-- you know, the slightly frustration with me is that we have the social
[01:40:07.380 --> 01:40:12.340]   web working group at W3C that's been trying to fit these different components together.
[01:40:12.340 --> 01:40:15.420]   And so there's an indie web group set of people there.
[01:40:15.420 --> 01:40:17.300]   There's a linked data set of people there.
[01:40:17.300 --> 01:40:19.260]   There's a bunch of people who came from actively streams.
[01:40:19.260 --> 01:40:22.620]   And we're trying to work out the models of how these things connect together.
[01:40:22.620 --> 01:40:29.140]   And solid has been some contributions to that group, but they haven't-- I think they've
[01:40:29.140 --> 01:40:32.500]   put one spec into the group so far.
[01:40:32.500 --> 01:40:36.300]   Whereas we've-- the indie web has put three or four specs in with micro-pub is kind of
[01:40:36.300 --> 01:40:38.860]   a recommendation this week and so on.
[01:40:38.860 --> 01:40:40.740]   So we're trying to make this stuff fit together.
[01:40:40.740 --> 01:40:43.940]   But Tim has not been promoting the W3C part of this.
[01:40:43.940 --> 01:40:46.180]   He's been promoting his special project, which makes sense.
[01:40:46.180 --> 01:40:47.740]   If you are someone, what are you working on?
[01:40:47.740 --> 01:40:48.740]   They'll talk about that.
[01:40:48.740 --> 01:40:50.180]   And I'll talk about indie web stuff.
[01:40:50.180 --> 01:40:51.500]   We'll talk about third stuff.
[01:40:51.500 --> 01:40:55.060]   But I think the interesting part is where we're trying to get these specs to work together.
[01:40:55.060 --> 01:40:57.900]   And there is a part of the social web working group.
[01:40:57.900 --> 01:41:01.140]   There is a paper that describes the different projects we've got and how we're trying to
[01:41:01.140 --> 01:41:02.140]   make them interoperate.
[01:41:02.140 --> 01:41:03.940]   And that's an interesting one to look at.
[01:41:03.940 --> 01:41:07.180]   I'll try and find a link for that.
[01:41:07.180 --> 01:41:12.260]   Because that social web protocols thing that Amy Guy has written.
[01:41:12.260 --> 01:41:15.860]   That sort of describes different protocols we've got and how they connect together.
[01:41:15.860 --> 01:41:19.060]   And how the indie web ones connect with the activity stream ones that connect with the
[01:41:19.060 --> 01:41:22.300]   ones that have come from the other group.
[01:41:22.300 --> 01:41:24.580]   So we're trying to make these things fit together.
[01:41:24.580 --> 01:41:28.580]   We've got-- the indie web approach has been-- will make some very small point protocols
[01:41:28.580 --> 01:41:30.340]   that the recent comment.
[01:41:30.340 --> 01:41:32.220]   And then you can connect things together with that.
[01:41:32.220 --> 01:41:36.460]   There are other critical discussions here that are trying to be more comprehensive.
[01:41:36.460 --> 01:41:44.300]   That are trying to give you an inbox and an outbox and build something that's closer to
[01:41:44.300 --> 01:41:47.540]   a sort of a more complete session at work rather than a sort of start with your website
[01:41:47.540 --> 01:41:48.900]   and build up model.
[01:41:48.900 --> 01:41:52.660]   And then Solid is in that realm, but taking it a stage further.
[01:41:52.660 --> 01:41:56.820]   So it's saying we're going to use the link data model, which describes resources on the
[01:41:56.820 --> 01:42:01.060]   web and lets you connect them together and express things in the Tim Burnsley vision
[01:42:01.060 --> 01:42:06.940]   that he's been pushing for a couple of decades now as the sort of the post web web of the
[01:42:06.940 --> 01:42:08.180]   web of linked data.
[01:42:08.180 --> 01:42:12.140]   So it's trying to use that world view and connect that in with the web.
[01:42:12.140 --> 01:42:16.620]   And the challenge with all of these is can we actually get to interoperate or do we only
[01:42:16.620 --> 01:42:19.900]   interoperate with things that are running the same code base that are actually the same
[01:42:19.900 --> 01:42:20.900]   thing.
[01:42:20.900 --> 01:42:23.940]   And that's the piece that's hard.
[01:42:23.940 --> 01:42:29.540]   And the mapping between I think is the important bit here.
[01:42:29.540 --> 01:42:32.220]   Very good.
[01:42:32.220 --> 01:42:34.860]   I will find you the article I wrote that has.
[01:42:34.860 --> 01:42:40.100]   I will read your article too.
[01:42:40.100 --> 01:42:44.220]   But yeah, so the social web working group is the sort of the W3C group that's trying
[01:42:44.220 --> 01:42:48.220]   to put this stuff together.
[01:42:48.220 --> 01:42:53.820]   So that's, I'll put the link to that in the chat as well.
[01:42:53.820 --> 01:42:57.220]   And that's this, there's a series of drafts and candidate recommendations that are coming
[01:42:57.220 --> 01:42:59.500]   out of that group.
[01:42:59.500 --> 01:43:02.660]   And social web protocols is the one that explains the connection between the different ones and
[01:43:02.660 --> 01:43:04.620]   how we try to make the work together.
[01:43:04.620 --> 01:43:08.860]   Candidate recommendations are the ones that we think are in the state where they're implementable.
[01:43:08.860 --> 01:43:14.260]   And then there are working drafts that are trying to build different pieces of this but
[01:43:14.260 --> 01:43:21.180]   are not ready for, it's basically gathering implementations and trying to converge.
[01:43:21.180 --> 01:43:29.780]   So the micro-pub is a candidate recommendation that's derived from the new web work.
[01:43:29.780 --> 01:43:35.260]   Web mention is a, I think it's a draft working draft, it seems to be in that list.
[01:43:35.260 --> 01:43:37.500]   But basically we've got a set of these different protocols and we're trying to make them all
[01:43:37.500 --> 01:43:38.500]   fit together.
[01:43:38.500 --> 01:43:39.500]   And the--
[01:43:39.500 --> 01:43:40.500]   >> Web mention is a candidate recommendation.
[01:43:40.500 --> 01:43:44.300]   >> Web mention is candidate recommendation as well.
[01:43:44.300 --> 01:43:45.300]   Yeah.
[01:43:45.300 --> 01:43:46.300]   >> This is interesting.
[01:43:46.300 --> 01:43:49.540]   >> So there's basically there's been a lot of us trying to work on different bits of
[01:43:49.540 --> 01:43:55.620]   this over the last two years now, this group has been chartered.
[01:43:55.620 --> 01:44:00.460]   And Solid is one of the-- is a research-- is Tim's research group at MIT and has people
[01:44:00.460 --> 01:44:02.940]   that are part of this group as well.
[01:44:02.940 --> 01:44:06.180]   But what I would say is if you're interested in this stuff, have a look at the social web
[01:44:06.180 --> 01:44:10.420]   working group stuff because we've got a bunch of action to operating drafts and things there.
[01:44:10.420 --> 01:44:12.220]   And there's connections to the solid work there as well.
[01:44:12.220 --> 01:44:16.260]   The link data notifications came out of the solid group that's in there as a working draft.
[01:44:16.260 --> 01:44:22.540]   >> W3.org/wikysasocialwg for social web working.
[01:44:22.540 --> 01:44:23.540]   >> Yes.
[01:44:23.540 --> 01:44:24.540]   >> Capital S, I think you did.
[01:44:24.540 --> 01:44:25.540]   >> Oh, it's capital.
[01:44:25.540 --> 01:44:26.540]   >> K-sensitive capital.
[01:44:26.540 --> 01:44:27.540]   >> It's a wiki.
[01:44:27.540 --> 01:44:28.540]   >> It's a wiki.
[01:44:28.540 --> 01:44:29.540]   >> No, it does work.
[01:44:29.540 --> 01:44:30.540]   >> Okay.
[01:44:30.540 --> 01:44:31.540]   >> Social WG.
[01:44:31.540 --> 01:44:33.940]   >> Who put these purple links in here?
[01:44:33.940 --> 01:44:36.780]   These look suspiciously like Stacy's interests.
[01:44:36.780 --> 01:44:38.780]   >> Oh, I didn't actually-- I didn't--
[01:44:38.780 --> 01:44:39.780]   >> What I didn't get--
[01:44:39.780 --> 01:44:40.780]   >> I didn't try to drop anything.
[01:44:40.780 --> 01:44:43.860]   >> What I learned is a hired consultant to auto-didact physicists.
[01:44:43.860 --> 01:44:44.860]   So maybe that's a Kevin Marks.
[01:44:44.860 --> 01:44:46.860]   >> This is a Kevin Marks.
[01:44:46.860 --> 01:44:48.860]   >> This was a fun one.
[01:44:48.860 --> 01:44:49.860]   >> All right.
[01:44:49.860 --> 01:44:50.860]   >> This is fascinating.
[01:44:50.860 --> 01:44:52.460]   >> What is it?
[01:44:52.460 --> 01:44:53.460]   >> So--
[01:44:53.460 --> 01:44:54.460]   >> This is from Eon.
[01:44:54.460 --> 01:44:56.540]   The reason I thought I might be used, Stacy, I know you like to read Eon.
[01:44:56.540 --> 01:44:57.540]   >> I do.
[01:44:57.540 --> 01:44:59.060]   Well, Kevin and I have a lot of similar interests.
[01:44:59.060 --> 01:45:00.060]   I'm not going to lie.
[01:45:00.060 --> 01:45:01.060]   >> Yes, that's true.
[01:45:01.060 --> 01:45:04.060]   >> We do tend to no doubt together.
[01:45:04.060 --> 01:45:10.100]   So Sabine Hersonfeld, she's a research physicist.
[01:45:10.100 --> 01:45:13.460]   And she said, one of the problems you have as a research physicist is all these people
[01:45:13.460 --> 01:45:17.740]   who have strange theories who contact your physics department and want to tell you about
[01:45:17.740 --> 01:45:18.900]   them.
[01:45:18.900 --> 01:45:20.860]   And you try and be nice and do that.
[01:45:20.860 --> 01:45:25.460]   >> She put a note up on her blog offering physics consultations, talk to a physicist,
[01:45:25.460 --> 01:45:27.740]   call me on Skype $50 per 20 minutes.
[01:45:27.740 --> 01:45:28.740]   >> Yes.
[01:45:28.740 --> 01:45:31.260]   >> Is that where you got your idea, Kevin?
[01:45:31.260 --> 01:45:34.060]   >> This is exactly where I got the idea.
[01:45:34.060 --> 01:45:35.060]   >> Okay.
[01:45:35.060 --> 01:45:36.620]   >> So she says, okay.
[01:45:36.620 --> 01:45:37.620]   And she talks about what happened.
[01:45:37.620 --> 01:45:39.380]   And she found it was actually really interesting.
[01:45:39.380 --> 01:45:43.740]   There's a sort of set of people who learn about physics from the media, who have some
[01:45:43.740 --> 01:45:49.580]   sort of loose understanding of how it works, but have taken some piece of visualization
[01:45:49.580 --> 01:45:51.380]   or a central explanation to how it works.
[01:45:51.380 --> 01:45:52.380]   >> Absolutely misunderstood.
[01:45:52.380 --> 01:45:58.020]   >> And so the service that she provides is they ring her up and say, so I think we can
[01:45:58.020 --> 01:46:01.100]   get perpetual energy from this because of this, this, this, this, and this.
[01:46:01.100 --> 01:46:05.660]   And she says, the thing that you've misunderstood is this piece and you should read a paper
[01:46:05.660 --> 01:46:06.660]   about this.
[01:46:06.660 --> 01:46:07.660]   >> How useful.
[01:46:07.660 --> 01:46:10.300]   >> And do it from that point of view.
[01:46:10.300 --> 01:46:11.300]   >> Does she get calls?
[01:46:11.300 --> 01:46:15.700]   >> And she says, you got a lot of calls, you got enough calls that she had to recruit
[01:46:15.700 --> 01:46:17.580]   other graduate students to respond to this.
[01:46:17.580 --> 01:46:18.580]   >> That's so awesome.
[01:46:18.580 --> 01:46:22.860]   >> And based upon this pricing, just talking to Kevin for the length of the show, we've
[01:46:22.860 --> 01:46:25.860]   actually had what, let's say $300 I think.
[01:46:25.860 --> 01:46:26.860]   >> That's true.
[01:46:26.860 --> 01:46:27.860]   I should ask you an invoice.
[01:46:27.860 --> 01:46:32.060]   So I thought that, I also did this, I put it up on Twitter and said, interesting business
[01:46:32.060 --> 01:46:35.980]   model, if you're interested, you want to talk to me for the 20 minutes for $50, I'll
[01:46:35.980 --> 01:46:36.980]   do that too.
[01:46:36.980 --> 01:46:39.780]   And I've had some people respond and actually has some interesting conversations out of
[01:46:39.780 --> 01:46:40.780]   it.
[01:46:40.780 --> 01:46:41.780]   >> So, yeah.
[01:46:41.780 --> 01:46:45.900]   >> I thought about just saying hi, but then I was like, no, too rich from my blood.
[01:46:45.900 --> 01:46:50.060]   >> Well, here's what this reminds me of is this recent article in the New York Times
[01:46:50.060 --> 01:46:53.500]   of elsewhere, debunking chem trails.
[01:46:53.500 --> 01:46:57.020]   We've all seen these con trails from jets in the sky.
[01:46:57.020 --> 01:46:58.020]   It's commonplace.
[01:46:58.020 --> 01:46:59.500]   I've seen them since I was a kid.
[01:46:59.500 --> 01:47:04.060]   But apparently there are a group of conspiracy theories who are convinced, I'd never heard
[01:47:04.060 --> 01:47:10.700]   of this, who are convinced that these are actually government planes spraying toxic chemicals.
[01:47:10.700 --> 01:47:12.380]   >> You're going to get the email now.
[01:47:12.380 --> 01:47:17.180]   >> Gene, altering concoctions, testing weapons of war.
[01:47:17.180 --> 01:47:24.980]   So somebody decided to appear reviewed, study.
[01:47:24.980 --> 01:47:33.300]   And scientists agreed, well, not all 77 scientists, 76 of them said they had no evidence of secret
[01:47:33.300 --> 01:47:39.620]   large scale spraying programs and could easily explain those trails as condensation, not
[01:47:39.620 --> 01:47:41.260]   spraying.
[01:47:41.260 --> 01:47:47.740]   There was one scientist, one who said, well.
[01:47:47.740 --> 01:47:51.540]   So even in this case, you're never going to get 100% agreement.
[01:47:51.540 --> 01:47:54.740]   But that's an example of something where I didn't know this.
[01:47:54.740 --> 01:47:57.460]   Is it widely believed that we are being sprayed?
[01:47:57.460 --> 01:48:00.260]   >> There's this widely with topics to chase.
[01:48:00.260 --> 01:48:01.260]   No.
[01:48:01.260 --> 01:48:03.340]   But it's widely spoken about.
[01:48:03.340 --> 01:48:07.740]   There's a sort of coalition of people who talk about this and link to each other.
[01:48:07.740 --> 01:48:14.740]   And because of the Facebook and Twitter application models, the internet, they can fight each
[01:48:14.740 --> 01:48:15.740]   other.
[01:48:15.740 --> 01:48:18.140]   >> I'm telling you, it's all Twitter's fault.
[01:48:18.140 --> 01:48:23.340]   >> But literally if you sign up for one of these sites on Facebook, if you follow them,
[01:48:23.340 --> 01:48:26.460]   it will recommend the other eight of you.
[01:48:26.460 --> 01:48:28.580]   It's a very well-colorated cluster.
[01:48:28.580 --> 01:48:31.420]   And it connects to some of the other ones as well.
[01:48:31.420 --> 01:48:44.860]   And the challenge, it is, 17% said they believed in a secret large scale atmospheric program
[01:48:44.860 --> 01:48:50.860]   or slap to be true or partly true, 17%.
[01:48:50.860 --> 01:48:55.340]   >> I would love for someone to do, I think Gawker actually for a while did something like
[01:48:55.340 --> 01:48:58.020]   it wasn't called camping with the crazies, but it was like-
[01:48:58.020 --> 01:48:59.700]   >> That's a good name.
[01:48:59.700 --> 01:49:05.540]   >> They hung out with conspiracy theorists and cults and they reported on them what these
[01:49:05.540 --> 01:49:11.260]   people believed in just showing how many groups of weird there are.
[01:49:11.260 --> 01:49:14.780]   And I think it'd just be a fascinating podcast because sometimes you stumble across these
[01:49:14.780 --> 01:49:21.660]   weird areas of the internet and you're like, wow, they're really people that believe the
[01:49:21.660 --> 01:49:28.020]   flat earth or I didn't know those people still existed until whoever that was got all excited.
[01:49:28.020 --> 01:49:30.020]   I just love that.
[01:49:30.020 --> 01:49:31.020]   I'd love people.
[01:49:31.020 --> 01:49:34.020]   >> I don't know if you want to fuel that fire however.
[01:49:34.020 --> 01:49:35.420]   >> Yeah, I don't think so.
[01:49:35.420 --> 01:49:37.780]   >> Same with the anti-vaxxers and all that.
[01:49:37.780 --> 01:49:38.780]   >> Yeah.
[01:49:38.780 --> 01:49:40.580]   >> The people who believe Wi-Fi is bad for you.
[01:49:40.580 --> 01:49:45.100]   >> There's a guy who lives in Petalumo who comes by here periodically with his laptop and
[01:49:45.100 --> 01:49:50.100]   his laptop because he's a Windows developer to enlist us to help stop Wi-Fi in the public
[01:49:50.100 --> 01:49:51.100]   schools.
[01:49:51.100 --> 01:49:56.740]   And I said, buddy, you got the wrong person for that.
[01:49:56.740 --> 01:50:03.900]   Jason Pontin who edits the MIT editorial review did a, I found out about this article on Facebook
[01:50:03.900 --> 01:50:07.980]   when he put a link to it on his Facebook and wrote something that I thought was really
[01:50:07.980 --> 01:50:08.980]   good on all of this.
[01:50:08.980 --> 01:50:13.980]   My own experience as a science and technology editor is that conspiracy theories are impervious
[01:50:13.980 --> 01:50:15.860]   to evidence.
[01:50:15.860 --> 01:50:20.100]   People who like these sorts of theories are the kinds of people who like these theories.
[01:50:20.100 --> 01:50:25.900]   Conspiracy theories satisfy a deep need to think history is rational even if the reasons
[01:50:25.900 --> 01:50:27.380]   are occluded.
[01:50:27.380 --> 01:50:32.100]   People who like conspiracy theories need to self-identify as savvy souls who can see through
[01:50:32.100 --> 01:50:37.180]   the propaganda that includes the sight of sheeple.
[01:50:37.180 --> 01:50:40.020]   Showing people why they're wrong about a theory just makes them dig in deeper.
[01:50:40.020 --> 01:50:41.020]   They get angry.
[01:50:41.020 --> 01:50:47.980]   In the end, conspiracy theories collapse like drunkards fall apart slowly than all at once.
[01:50:47.980 --> 01:50:51.740]   Here we all pretend that a large number of Americans never actually believed X or supported
[01:50:51.740 --> 01:50:57.180]   Y because national life must go on and it's intolerable to our civic religion of debit,
[01:50:57.180 --> 01:51:03.900]   credit, and elitism to admit that half of us don't know our butts from the hole in the
[01:51:03.900 --> 01:51:05.940]   ground.
[01:51:05.940 --> 01:51:10.220]   And then he links to this New York Times story about chem trails.
[01:51:10.220 --> 01:51:11.220]   Wow.
[01:51:11.220 --> 01:51:15.820]   I thought that was a good way to put that.
[01:51:15.820 --> 01:51:18.500]   I think it's connected to things that actually happen.
[01:51:18.500 --> 01:51:21.980]   We do spray chemicals from the air because that's how we do crop dusting but there's
[01:51:21.980 --> 01:51:25.100]   done with small planes that are very low to the ground because otherwise the universe.
[01:51:25.100 --> 01:51:28.300]   Every conspiracy theory is somewhat believable.
[01:51:28.300 --> 01:51:33.660]   There are also people who have called for atmospheric geoengineering to end global warming
[01:51:33.660 --> 01:51:34.660]   and things like that.
[01:51:34.660 --> 01:51:35.660]   That's another realm of violence.
[01:51:35.660 --> 01:51:42.660]   So you can find papers from sensible scientists who will say, "Could we fix global warming
[01:51:42.660 --> 01:51:45.460]   by filling the atmosphere with dust or something like that?"
[01:51:45.460 --> 01:51:51.140]   And so there's a series of things you can join the dots to but then you decide every
[01:51:51.140 --> 01:51:57.020]   streak of cloud in the sky is a chem trail from a plane that's trying to kill you and
[01:51:57.020 --> 01:51:58.780]   that's when it gets a bit weird.
[01:51:58.780 --> 01:51:59.780]   Yeah.
[01:51:59.780 --> 01:52:02.420]   Hey guys, I think you all are all wonderful.
[01:52:02.420 --> 01:52:03.780]   Is it time to go?
[01:52:03.780 --> 01:52:05.020]   It's time for me to go.
[01:52:05.020 --> 01:52:06.220]   You guys can keep talking about it.
[01:52:06.220 --> 01:52:07.220]   No, we should wrap it up.
[01:52:07.220 --> 01:52:09.740]   You said, "You warned me.
[01:52:09.740 --> 01:52:10.740]   You warned me.
[01:52:10.740 --> 01:52:11.740]   So we're going to let Stacey go.
[01:52:11.740 --> 01:52:13.940]   Read an ad and then we'll come back with our picks of the week."
[01:52:13.940 --> 01:52:15.380]   Stacey, thank you so much.
[01:52:15.380 --> 01:52:16.980]   Have fun at IDF.
[01:52:16.980 --> 01:52:18.780]   Have a great conversation with your daughter.
[01:52:18.780 --> 01:52:20.220]   Are you going to use duo?
[01:52:20.220 --> 01:52:23.140]   Oh no, we're going to use Hangouts.
[01:52:23.140 --> 01:52:27.460]   We have a sticker sharing relationship on Hangouts that we just keep going.
[01:52:27.460 --> 01:52:28.460]   That's so sweet.
[01:52:28.460 --> 01:52:29.460]   Oh my goodness.
[01:52:29.460 --> 01:52:30.460]   Alright.
[01:52:30.460 --> 01:52:31.460]   Well, Stacey and I are.
[01:52:31.460 --> 01:52:32.460]   It's also good.
[01:52:32.460 --> 01:52:33.460]   I don't have anything for you this week.
[01:52:33.460 --> 01:52:34.460]   So we don't have to know.
[01:52:34.460 --> 01:52:37.020]   Stacey and IOT, you always have to look for us.
[01:52:37.020 --> 01:52:38.020]   You're really in brains.
[01:52:38.020 --> 01:52:43.620]   Stacey and IOT.com at Gigastacey on Twitter if you still want to use that.
[01:52:43.620 --> 01:52:44.620]   Thank you, Stacey.
[01:52:44.620 --> 01:52:45.620]   Thanks.
[01:52:45.620 --> 01:52:46.620]   Take care.
[01:52:46.620 --> 01:52:51.300]   Our show today brought to you by something Stacey, I'm sure would endorse and support.
[01:52:51.300 --> 01:52:52.300]   I think she even has one.
[01:52:52.300 --> 01:52:54.940]   The Ring, video, doorbell.
[01:52:54.940 --> 01:52:56.700]   I have one right here.
[01:52:56.700 --> 01:52:57.820]   Well, actually I went on my door.
[01:52:57.820 --> 01:52:58.980]   I think maybe I put it on my door.
[01:52:58.980 --> 01:53:04.340]   The Ring video, doorbell, lets you see and talk to and hear somebody at your front door.
[01:53:04.340 --> 01:53:07.460]   Whether they're ringing the doorbell or just moving around out front.
[01:53:07.460 --> 01:53:08.460]   It is awesome.
[01:53:08.460 --> 01:53:15.340]   It replaces your wired or unwired doorbell with a very nice chime that will ring inside
[01:53:15.340 --> 01:53:21.260]   your house, but will also let you answer your doorbell using your smartphone or tablet wherever
[01:53:21.260 --> 01:53:22.500]   you are anywhere in the world.
[01:53:22.500 --> 01:53:24.740]   Yes, it's internet connected.
[01:53:24.740 --> 01:53:29.500]   And now Ring has a great deal on their security bundle kit.
[01:53:29.500 --> 01:53:36.500]   If you go to Ring.com/Twig, you could save a significant amount on a variety of Ring Video
[01:53:36.500 --> 01:53:38.100]   Doorbell kits.
[01:53:38.100 --> 01:53:41.700]   Whether it's just the basic Ring.
[01:53:41.700 --> 01:53:44.020]   What is that thing next to the Ring?
[01:53:44.020 --> 01:53:45.580]   I don't know what that is.
[01:53:45.580 --> 01:53:47.100]   I'm going to have to look at that now.
[01:53:47.100 --> 01:53:48.660]   This is something new it looks like.
[01:53:48.660 --> 01:53:53.300]   They also have a bundle kit that has the Ring and the Stick Up Cam, which is awesome.
[01:53:53.300 --> 01:53:55.740]   That gives you the Stick Up Cam.
[01:53:55.740 --> 01:54:00.580]   It gives you a camera kind of much like the Ring Video Doorbell.
[01:54:00.580 --> 01:54:03.820]   Oh, it's a solar security sign.
[01:54:03.820 --> 01:54:04.820]   Oh, that's nice.
[01:54:04.820 --> 01:54:06.260]   So you can say protected by Ring.
[01:54:06.260 --> 01:54:07.260]   You'll love it.
[01:54:07.260 --> 01:54:12.100]   You can also get with one of their bundles, you get the solar panel, which allows your
[01:54:12.100 --> 01:54:15.980]   Stick Up Cam to work without ever being wired.
[01:54:15.980 --> 01:54:16.980]   Love that.
[01:54:16.980 --> 01:54:21.340]   And the Chime, which plugs into any standard power outlet and works with your Ring Video
[01:54:21.340 --> 01:54:26.900]   Doorbell so that you know you have a visitor, even if your phone is in the other room.
[01:54:26.900 --> 01:54:32.060]   Ring is great, especially summertime when bad guys often will come to your door, especially
[01:54:32.060 --> 01:54:34.580]   while you're at work or on vacation to see if anybody's home.
[01:54:34.580 --> 01:54:37.700]   If no one answers the doorbell, they're going to go around back and break in.
[01:54:37.700 --> 01:54:39.940]   But see, you'll always answer the doorbell.
[01:54:39.940 --> 01:54:45.420]   Even if you're in Paris or London or Stockholm, there are two kinds of Ring Video Doorbells.
[01:54:45.420 --> 01:54:49.260]   There's the Ring that I have, which has the battery, your long battery.
[01:54:49.260 --> 01:54:51.740]   But if you don't need a battery, if you're using a wired doorbell, get the Ring Video
[01:54:51.740 --> 01:54:53.400]   Doorbell Pro.
[01:54:53.400 --> 01:54:55.220]   It's a slider slimmer.
[01:54:55.220 --> 01:55:00.460]   It also has an HD, well, both are HD, but it has a 1080p camera.
[01:55:00.460 --> 01:55:01.460]   Really great picture.
[01:55:01.460 --> 01:55:03.380]   I just saw one for the first time the other day.
[01:55:03.380 --> 01:55:08.540]   And you're going to get lots off by getting one of the Ring of Security bundle kits.
[01:55:08.540 --> 01:55:14.340]   So check them all out at RingRNG.com/Twig.
[01:55:14.340 --> 01:55:18.980]   I always know who's coming and going at my house, even if they don't ring the doorbell.
[01:55:18.980 --> 01:55:21.900]   Thanks to my Ring Video Doorbell.
[01:55:21.900 --> 01:55:22.900]   I love this now.
[01:55:22.900 --> 01:55:26.900]   They'll sell you a little, one of those little security signs to put out front.
[01:55:26.900 --> 01:55:28.380]   Oh, it's solar too.
[01:55:28.380 --> 01:55:29.940]   Oh, that's cool.
[01:55:29.940 --> 01:55:31.820]   That's nice.
[01:55:31.820 --> 01:55:34.820]   Ring.com/Twig.
[01:55:34.820 --> 01:55:38.820]   We thank you for their support of this week in Google.
[01:55:38.820 --> 01:55:45.020]   Well, we lost Stacy, but that doesn't mean we get to go home yet because it's time for
[01:55:45.020 --> 01:55:46.620]   our picks of the week.
[01:55:46.620 --> 01:55:47.620]   Let's start with you, Kevin.
[01:55:47.620 --> 01:55:52.540]   I'm sure you have a few things you'd like to promote with the IndieWeb.
[01:55:52.540 --> 01:56:00.060]   Well, the big one coming up is IndieWebCampNewYork, which is the 27th and 28th of August.
[01:56:00.060 --> 01:56:07.220]   I want to encourage Jeff to come along and send his generous of students along as well.
[01:56:07.220 --> 01:56:12.940]   The links 2016.indeweb.org/NYC2.
[01:56:12.940 --> 01:56:14.300]   Sign up there.
[01:56:14.300 --> 01:56:18.980]   There's space for 20 or 30 people to come along.
[01:56:18.980 --> 01:56:21.260]   It should be live streaming it as well.
[01:56:21.260 --> 01:56:25.820]   Basically, the IndieWebCamp is the two-day event where we get together to talk about
[01:56:25.820 --> 01:56:33.660]   building our own websites, spend the first day is initial show and tell of what you've
[01:56:33.660 --> 01:56:35.500]   made and discussions.
[01:56:35.500 --> 01:56:38.940]   The Sunday is a sort of hacking day and then it ends with a demo of things we've built
[01:56:38.940 --> 01:56:39.940]   over the weekend.
[01:56:39.940 --> 01:56:41.380]   We've done lots of these in different cities.
[01:56:41.380 --> 01:56:44.220]   We've already done one in New York this year.
[01:56:44.220 --> 01:56:47.260]   And that one was snowed out because it was done during the blizzard.
[01:56:47.260 --> 01:56:48.540]   That shouldn't happen this time, right?
[01:56:48.540 --> 01:56:52.620]   Oh, that's right.
[01:56:52.620 --> 01:56:54.140]   But that's coming up.
[01:56:54.140 --> 01:57:00.620]   We also have the Homebrew website clubs in lots of cities next Wednesday including San
[01:57:00.620 --> 01:57:07.620]   Francisco, Portland, Brighton and places in Germany and Sweden as well.
[01:57:07.620 --> 01:57:10.740]   I can't remember exactly which ones I have in Sweden.
[01:57:10.740 --> 01:57:14.500]   The other news was the thing I mentioned briefly in the social worker group, which is that
[01:57:14.500 --> 01:57:19.820]   micro-pub is now a candidate recommendation, which is the last stage before it becomes
[01:57:19.820 --> 01:57:23.700]   a full draft, a full publication.
[01:57:23.700 --> 01:57:31.380]   Which means this is a really good time to test out a micro-pub with yourself.
[01:57:31.380 --> 01:57:36.780]   Micro-pub is the specification that lets you remote post to another site.
[01:57:36.780 --> 01:57:43.220]   So you basically authorize somebody to post on your website and then that gets sent out.
[01:57:43.220 --> 01:57:50.860]   We've built this to connect things together in different indie websites.
[01:57:50.860 --> 01:57:58.100]   There's also a site called silo.pub that will connect to sites like WordPress and Blogger
[01:57:58.100 --> 01:58:02.820]   and Tumblr and Twitter so that you can post to those using this protocol as well.
[01:58:02.820 --> 01:58:06.940]   So it's a strong protocol for letting you publish from one site to another.
[01:58:06.940 --> 01:58:11.260]   We've got a set of implementations and as it's in CI, it's a really good time for you
[01:58:11.260 --> 01:58:14.060]   to test against it and try things out.
[01:58:14.060 --> 01:58:16.060]   Very nice.
[01:58:16.060 --> 01:58:17.060]   Very nice.
[01:58:17.060 --> 01:58:18.060]   Jeff Jarvis.
[01:58:18.060 --> 01:58:19.060]   You're typically...
[01:58:19.060 --> 01:58:20.060]   Oh, let me see here.
[01:58:20.060 --> 01:58:21.500]   I don't know if you want to show this or not.
[01:58:21.500 --> 01:58:23.140]   You may not want to because it's political.
[01:58:23.140 --> 01:58:24.140]   Oh, go ahead.
[01:58:24.140 --> 01:58:28.180]   But the video that has been going all around the Twitter in the last couple hours is the
[01:58:28.180 --> 01:58:29.180]   says who video.
[01:58:29.180 --> 01:58:30.180]   Have you seen this?
[01:58:30.180 --> 01:58:31.180]   No.
[01:58:31.180 --> 01:58:38.180]   So Trump's lawyer is on CNN and the correspondent says, well, you're behind and you complain.
[01:58:38.180 --> 01:58:39.180]   All right.
[01:58:39.180 --> 01:58:40.180]   Well, let me ask you about this.
[01:58:40.180 --> 01:58:46.460]   So you say it's not a shake up, but you guys are down and it makes sense that there would...
[01:58:46.460 --> 01:58:48.780]   It says who says who says all the polls.
[01:58:48.780 --> 01:58:49.780]   Most of them.
[01:58:49.780 --> 01:58:50.780]   All of them.
[01:58:50.780 --> 01:58:51.780]   That says who?
[01:58:51.780 --> 01:58:52.780]   That's why I just told you I am to prove the truth.
[01:58:52.780 --> 01:58:53.780]   That's why I'm going to prove the truth.
[01:58:53.780 --> 01:58:54.780]   Which polls?
[01:58:54.780 --> 01:58:55.780]   All of them.
[01:58:55.780 --> 01:58:56.780]   And your question is?
[01:58:56.780 --> 01:58:57.780]   Okay.
[01:58:57.780 --> 01:58:58.780]   So my question is...
[01:58:58.780 --> 01:58:59.780]   That's enough.
[01:58:59.780 --> 01:59:00.780]   I don't...
[01:59:00.780 --> 01:59:01.780]   It is really surprising when...
[01:59:01.780 --> 01:59:02.780]   Says who?
[01:59:02.780 --> 01:59:05.780]   That solves who means the meme will be all around the world.
[01:59:05.780 --> 01:59:06.780]   Says who.
[01:59:06.780 --> 01:59:07.780]   Get ready.
[01:59:07.780 --> 01:59:08.780]   We're going to see it everywhere.
[01:59:08.780 --> 01:59:09.780]   Says who.
[01:59:09.780 --> 01:59:10.780]   So a couple of them.
[01:59:10.780 --> 01:59:11.780]   Okay.
[01:59:11.780 --> 01:59:12.780]   So my question is...
[01:59:12.780 --> 01:59:13.780]   That's enough.
[01:59:13.780 --> 01:59:14.780]   I don't...
[01:59:14.780 --> 01:59:15.780]   I don't...
[01:59:15.780 --> 01:59:22.540]   So a couple other Trump moments without adding in political analysis.
[01:59:22.540 --> 01:59:23.540]   There was an analysis.
[01:59:23.540 --> 01:59:24.620]   I loved this one.
[01:59:24.620 --> 01:59:26.300]   I thought that was really interesting.
[01:59:26.300 --> 01:59:28.660]   They did a syntactic analysis.
[01:59:28.660 --> 01:59:30.940]   Well, no, it was a platform analysis.
[01:59:30.940 --> 01:59:32.860]   And an emotion analysis as well.
[01:59:32.860 --> 01:59:33.860]   That's right.
[01:59:33.860 --> 01:59:34.860]   Yeah.
[01:59:34.860 --> 01:59:40.100]   The over the top wacky tweets come from Android and they come from Trump's own phone.
[01:59:40.100 --> 01:59:43.020]   The other tweets come from iOS or the web client.
[01:59:43.020 --> 01:59:46.580]   And so for example, the last 24 hours, I think that actually Donald Trump has been locked
[01:59:46.580 --> 01:59:47.580]   up somewhere.
[01:59:47.580 --> 01:59:48.580]   And it's totally...
[01:59:48.580 --> 01:59:50.380]   You bet he has.
[01:59:50.380 --> 01:59:51.380]   24 hours.
[01:59:51.380 --> 01:59:53.740]   There's been no like-pants, Cedric Blake.
[01:59:53.740 --> 01:59:55.060]   Donald, come here for a second.
[01:59:55.060 --> 01:59:59.620]   I have a fabulous to tell Stata you're going to love.
[01:59:59.620 --> 02:00:01.820]   And then they took his phone.
[02:00:01.820 --> 02:00:02.820]   So it's so funny.
[02:00:02.820 --> 02:00:03.820]   So it's so funny.
[02:00:03.820 --> 02:00:04.820]   Look at the source.
[02:00:04.820 --> 02:00:06.460]   If it comes from Android, that means it's Donald.
[02:00:06.460 --> 02:00:10.620]   That means it's a little bit, shall we say, more passionate.
[02:00:10.620 --> 02:00:13.100]   This is actually a really good example of data analysis.
[02:00:13.100 --> 02:00:14.100]   It really is.
[02:00:14.100 --> 02:00:15.780]   That we were talking about.
[02:00:15.780 --> 02:00:18.580]   And if you just...
[02:00:18.580 --> 02:00:24.820]   Everybody knows the politicians' celebrities and many others have people tweeting for them.
[02:00:24.820 --> 02:00:28.260]   The question is, it seems like Donald tweets for himself.
[02:00:28.260 --> 02:00:31.460]   It turns out he also has people tweeting for him.
[02:00:31.460 --> 02:00:35.700]   And it's actually fairly easy to figure out which of Mr. Trump's tweets are his and which
[02:00:35.700 --> 02:00:37.660]   are from his team.
[02:00:37.660 --> 02:00:42.140]   And this data analysis, even down to which words are most likely to be from Android,
[02:00:42.140 --> 02:00:45.380]   which from iPhone, the Android iPhone thing made it kind of easy, right?
[02:00:45.380 --> 02:00:50.020]   It did, but then backed up the data analysis to show that there were two different voices.
[02:00:50.020 --> 02:00:52.380]   And also there was a time analysis.
[02:00:52.380 --> 02:00:54.340]   It's really interesting.
[02:00:54.340 --> 02:00:58.620]   And it has been 24 hours with no Android tweets.
[02:00:58.620 --> 02:01:01.340]   I checked before we got on the show.
[02:01:01.340 --> 02:01:10.580]   And lots and lots of Facebook, but the Facebook has the same milk toasty voice as the iOS tweets.
[02:01:10.580 --> 02:01:11.580]   Very interesting.
[02:01:11.580 --> 02:01:18.940]   So there's also another study that stately did of Trump searches by state.
[02:01:18.940 --> 02:01:21.060]   Like other people searching?
[02:01:21.060 --> 02:01:22.060]   Yes.
[02:01:22.060 --> 02:01:26.700]   What people search on and where is it here?
[02:01:26.700 --> 02:01:27.700]   Are they Trump?
[02:01:27.700 --> 02:01:29.500]   So I don't understand.
[02:01:29.500 --> 02:01:32.300]   Some people searching for about Trump related things.
[02:01:32.300 --> 02:01:33.300]   Yes.
[02:01:33.300 --> 02:01:34.300]   Yes.
[02:01:34.300 --> 02:01:41.100]   So Trump rally, what happens if Trump wins California's where to move if Trump wins.
[02:01:41.100 --> 02:01:43.140]   I love it in the state of Washington.
[02:01:43.140 --> 02:01:49.380]   Trump voodoo doll is the number one related search.
[02:01:49.380 --> 02:01:55.140]   However, in the Keystone state, it's how to build a wall.
[02:01:55.140 --> 02:01:57.980]   In Florida, it's the best words.
[02:01:57.980 --> 02:02:01.940]   Louisiana, it's Obama birth certificate.
[02:02:01.940 --> 02:02:05.060]   It's in Texas, contrast Texas to California.
[02:02:05.060 --> 02:02:07.500]   In California, where to move if Trump wins.
[02:02:07.500 --> 02:02:10.140]   In Texas, what happens if Trump wins?
[02:02:10.140 --> 02:02:14.580]   And of course, in Hawaii, it's Miss Teen USA.
[02:02:14.580 --> 02:02:18.700]   And apparently in Alaska, nothing.
[02:02:18.700 --> 02:02:20.980]   Nobody wants to know.
[02:02:20.980 --> 02:02:23.940]   They're a say, "Vell to be part of Russia."
[02:02:23.940 --> 02:02:27.580]   Trump with his good relationship with Putin, he's probably going to give it back to Russia.
[02:02:27.580 --> 02:02:29.660]   That's pretty funny.
[02:02:29.660 --> 02:02:31.460]   That is pretty funny.
[02:02:31.460 --> 02:02:32.460]   Wow.
[02:02:32.460 --> 02:02:34.460]   I don't know how a stately decided.
[02:02:34.460 --> 02:02:35.940]   Yeah, methodology maybe.
[02:02:35.940 --> 02:02:38.100]   What was a Trump tweet?
[02:02:38.100 --> 02:02:40.100]   You know, is Taco Bowl really a Trump tweet?
[02:02:40.100 --> 02:02:42.940]   They came up with a long list and then looked at a state by state.
[02:02:42.940 --> 02:02:45.540]   So it's not the best, so we'll say the methodology.
[02:02:45.540 --> 02:02:46.940]   But I enjoyed it.
[02:02:46.940 --> 02:02:47.940]   So.
[02:02:47.940 --> 02:02:52.140]   Mine is a little more tech focused on...
[02:02:52.140 --> 02:02:56.860]   In October 1991, Linus Torvalds released Linux to the world.
[02:02:56.860 --> 02:03:02.420]   Less than two years later, a gentleman now deceased in a very sad story.
[02:03:02.420 --> 02:03:05.180]   Ian Murdock created Debian.
[02:03:05.180 --> 02:03:06.180]   The Ian was his name.
[02:03:06.180 --> 02:03:08.620]   Debbie was the name of his wife.
[02:03:08.620 --> 02:03:11.940]   Yesterday was the 33rd birthday.
[02:03:11.940 --> 02:03:12.940]   33rd?
[02:03:12.940 --> 02:03:13.940]   Yeah.
[02:03:13.940 --> 02:03:14.940]   Is that right?
[02:03:14.940 --> 02:03:15.940]   Can that possibly be right?
[02:03:15.940 --> 02:03:18.340]   23rd birthday of Debian.
[02:03:18.340 --> 02:03:20.780]   Debian day celebrated each year.
[02:03:20.780 --> 02:03:26.780]   Debian is unfortunately a little bit eclipsed by Ubuntu, which is really a derivative of Debian.
[02:03:26.780 --> 02:03:30.500]   But if you've been thinking about Linux, I love Debian.
[02:03:30.500 --> 02:03:37.460]   Debian.org is not supported as Ubuntu is by a company but is fully community supported.
[02:03:37.460 --> 02:03:42.820]   It is, as I said, the basis for not only Ubuntu but a great many Linux distributions.
[02:03:42.820 --> 02:03:45.260]   Why not use the source material?
[02:03:45.260 --> 02:03:46.300]   It's really great.
[02:03:46.300 --> 02:03:49.700]   And something I got to say is it's so easy now to install Linux.
[02:03:49.700 --> 02:03:53.860]   You install Debian and it's going to recognize almost all of your hardware out of the box.
[02:03:53.860 --> 02:03:59.060]   Linux has made huge strides in PC hardware compatibility.
[02:03:59.060 --> 02:04:04.220]   And since, frankly, most of the time, all you really need to use is a browser.
[02:04:04.220 --> 02:04:07.780]   And Chrome and Chromium are available, of course, on Linux.
[02:04:07.780 --> 02:04:09.420]   You're not even sacrificing anything.
[02:04:09.420 --> 02:04:15.540]   And gaining a whole lot, including nobody spying on you, no advertising, no compelled
[02:04:15.540 --> 02:04:22.020]   forced upgrades, just a rock solid operating system that's actually pretty fun to use.
[02:04:22.020 --> 02:04:25.460]   So happy birthday, happy 23rd birthday.
[02:04:25.460 --> 02:04:26.460]   That's a sweet.
[02:04:26.460 --> 02:04:27.460]   Yeah.
[02:04:27.460 --> 02:04:31.580]   It's a nice story, really.
[02:04:31.580 --> 02:04:32.940]   Debian is a great operating system.
[02:04:32.940 --> 02:04:33.940]   It's free.
[02:04:33.940 --> 02:04:37.140]   It's completely free and it's all community supported.
[02:04:37.140 --> 02:04:40.540]   I imagine there are a few people at indie web camp who use Debian.
[02:04:40.540 --> 02:04:43.340]   I should think so.
[02:04:43.340 --> 02:04:44.340]   Yeah.
[02:04:44.340 --> 02:04:47.580]   Kind of the indie web camp of operating systems.
[02:04:47.580 --> 02:04:51.500]   Hey, thanks so much to Stacey Higginbotham once again.
[02:04:51.500 --> 02:04:56.220]   Sorry, we had to let her go, but she's always welcome.
[02:04:56.220 --> 02:04:57.540]   She'll be back next week.
[02:04:57.540 --> 02:05:00.780]   Our first show from the new brick house, I'm sorry, Eastside Studio.
[02:05:00.780 --> 02:05:02.260]   We're calling it the Eastside.
[02:05:02.260 --> 02:05:04.300]   I was wondering, you're also changing the name.
[02:05:04.300 --> 02:05:09.300]   Well, it's not going to be all brick anymore for one thing.
[02:05:09.300 --> 02:05:16.580]   And we thought we should give it a new name, the studios on the west side of Petaluma.
[02:05:16.580 --> 02:05:19.380]   The new studio will be on the northeast side.
[02:05:19.380 --> 02:05:22.340]   Yeah, northeast side.
[02:05:22.340 --> 02:05:28.700]   And we're moving on Sunday, our very first show.
[02:05:28.700 --> 02:05:31.580]   So when you get off...
[02:05:31.580 --> 02:05:33.860]   Plus there's a theater song.
[02:05:33.860 --> 02:05:38.940]   When you get off the freeways and over on that side of town.
[02:05:38.940 --> 02:05:43.420]   So the last exit in Petaluma, the Petaluma North exit is right there.
[02:05:43.420 --> 02:05:45.060]   It's very easy to get to.
[02:05:45.060 --> 02:05:46.060]   So you'll go through.
[02:05:46.060 --> 02:05:47.620]   Oh, so that's where you are in the brewery, right?
[02:05:47.620 --> 02:05:48.620]   Right, the brewery.
[02:05:48.620 --> 02:05:49.620]   Next to La Benitez.
[02:05:49.620 --> 02:05:50.620]   Yeah.
[02:05:50.620 --> 02:05:51.620]   Yeah.
[02:05:51.620 --> 02:05:54.500]   We got an I-Hop, we got an Applebee's, we got a Burger King, we got a Jack in the box
[02:05:54.500 --> 02:05:55.500]   and we got a lot of things.
[02:05:55.500 --> 02:05:56.500]   We're moving to America.
[02:05:56.500 --> 02:05:57.500]   We're moving to America.
[02:05:57.500 --> 02:05:58.500]   We're moving on America.
[02:05:58.500 --> 02:05:59.500]   We're going to make America great.
[02:05:59.500 --> 02:06:00.860]   No antique shops there.
[02:06:00.860 --> 02:06:01.860]   Yep.
[02:06:01.860 --> 02:06:07.100]   No, as a matter of fact, that's another reason to go there and lots of parking.
[02:06:07.100 --> 02:06:09.100]   So that's where we'll be next week.
[02:06:09.100 --> 02:06:10.980]   Far away is up from your whole new walk.
[02:06:10.980 --> 02:06:14.860]   Just as close as our home is equidistant to the two studios.
[02:06:14.860 --> 02:06:15.860]   So that's nice.
[02:06:15.860 --> 02:06:17.060]   Yeah, that's really nice.
[02:06:17.060 --> 02:06:19.220]   Kevin Marks is at Kevin Marks dot com.
[02:06:19.220 --> 02:06:21.300]   He's also indie web camp.
[02:06:21.300 --> 02:06:27.860]   Make sure you go to indywebcamp dot org to keep up on what's going on with the move
[02:06:27.860 --> 02:06:32.620]   to keep the web free open and ours.
[02:06:32.620 --> 02:06:33.620]   Hours.
[02:06:33.620 --> 02:06:34.620]   Exactly.
[02:06:34.620 --> 02:06:41.180]   And I think it's very interesting to see you all at the end of the video and Verizon in which
[02:06:41.180 --> 02:06:42.980]   case it's theirs.
[02:06:42.980 --> 02:06:43.980]   Never mind.
[02:06:43.980 --> 02:06:44.980]   It's too complicated.
[02:06:44.980 --> 02:06:49.780]   Jeff Jarvis, professor of journalism at the city university of New York.
[02:06:49.780 --> 02:06:55.140]   Author of what would Google do, public parts, scootenberg, the geek, geek-sparing gifts.
[02:06:55.140 --> 02:06:56.980]   He's also on buzzmachine.com.
[02:06:56.980 --> 02:07:00.740]   That's where he blogs and often writes on medium as well.
[02:07:00.740 --> 02:07:02.780]   Thank you so much, both of you.
[02:07:02.780 --> 02:07:03.780]   Really good show.
[02:07:03.780 --> 02:07:04.580]   Cheers.
[02:07:04.580 --> 02:07:05.580]   He's been polished.
[02:07:05.580 --> 02:07:08.220]   Eventually looked very similar.
[02:07:08.220 --> 02:07:12.340]   One of the reasons there's a gap behind me now is we actually took that out.
[02:07:12.340 --> 02:07:13.500]   Wall out.
[02:07:13.500 --> 02:07:16.260]   How many settings?
[02:07:16.260 --> 02:07:17.780]   How many?
[02:07:17.780 --> 02:07:18.780]   One fewer.
[02:07:18.780 --> 02:07:21.380]   So we'll have four sets plus my studio.
[02:07:21.380 --> 02:07:22.380]   So five total.
[02:07:22.380 --> 02:07:23.380]   Okay.
[02:07:23.380 --> 02:07:24.380]   Yeah.
[02:07:24.380 --> 02:07:25.380]   So one fewer.
[02:07:25.380 --> 02:07:26.380]   We're only losing one set.
[02:07:26.380 --> 02:07:27.380]   The tall thing.
[02:07:27.380 --> 02:07:28.380]   Yeah, the tall one, exactly.
[02:07:28.380 --> 02:07:29.780]   Yeah, which you never use, right?
[02:07:29.780 --> 02:07:30.780]   I booth.
[02:07:30.780 --> 02:07:31.780]   Yeah, we know.
[02:07:31.780 --> 02:07:33.740]   We seemed like a good idea.
[02:07:33.740 --> 02:07:34.740]   We got the living room.
[02:07:34.740 --> 02:07:35.740]   We got the round table.
[02:07:35.740 --> 02:07:36.740]   We got the news set.
[02:07:36.740 --> 02:07:37.740]   We got the radio corner.
[02:07:37.740 --> 02:07:39.300]   And my office is going to be identical.
[02:07:39.300 --> 02:07:41.700]   My office will be an extinguisher.
[02:07:41.700 --> 02:07:42.700]   Wow.
[02:07:42.700 --> 02:07:44.260]   So yeah.
[02:07:44.260 --> 02:07:45.260]   Thank you all for being here.
[02:07:45.260 --> 02:07:46.100]   We'll see you next time.
[02:07:46.100 --> 02:07:47.100]   Bye.
[02:07:47.100 --> 02:07:53.100]   Bye.
[02:07:53.100 --> 02:07:55.680]   (upbeat music)
[02:07:55.680 --> 02:07:58.740]   [MUSIC PLAYING]

