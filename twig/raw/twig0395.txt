;FFMETADATA1
title=Shake it Like a Polaroid
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=395
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:03.200]   It's time for Twig this week in Google the no news edition
[00:00:03.200 --> 00:00:08.160]   We will have some news from Google's next cloud conference which is going on right now in San Francisco
[00:00:08.160 --> 00:00:16.680]   Some big stories from nests some new products on the way perhaps a lot more all coming up next on twig
[00:00:16.680 --> 00:00:23.660]   Netcasts you love from people you trust
[00:00:23.660 --> 00:00:29.440]   This is twig
[00:00:29.920 --> 00:00:37.120]   Bandwidth for this week in Google is provided by cash fly CAC HE FLY.com
[00:00:37.120 --> 00:00:46.840]   This is twig this week in Google episode 395 recorded Wednesday March 8th
[00:00:46.840 --> 00:00:49.800]   2017 shake it like a Polaroid
[00:00:49.800 --> 00:00:58.920]   This week in Google is brought to you by legal zoom visit legal zoom.com slash startup for a free business startup kit
[00:00:58.920 --> 00:01:02.320]   And for special savings enter twig at checkout
[00:01:02.320 --> 00:01:04.400]   And by
[00:01:04.400 --> 00:01:11.360]   Rocket mortgage from quick and loans when it comes to the big decision of choosing a mortgage lender work with one that has your best interest in mind
[00:01:11.360 --> 00:01:18.480]   Use rocket mortgage for a transparent trustworthy home loan process. That's completely online at quick and loans.com
[00:01:18.480 --> 00:01:20.680]   slash twig and by
[00:01:20.680 --> 00:01:25.840]   Betterment a smart easy to use and less expensive way to invest for your
[00:01:26.280 --> 00:01:32.400]   Financial future get one month managed free when you make an initial deposit of ten thousand dollars or more at betterment.com
[00:01:32.400 --> 00:01:35.240]   slash twig
[00:01:35.240 --> 00:01:39.500]   It's time for this week in Google the show we talk about the latest from the net
[00:01:39.500 --> 00:01:43.880]   Joining me right now even under protest because it is international women's day
[00:01:43.880 --> 00:01:48.880]   And she's supposed to be striking Stacey Higginbotham of it podcast calm. Hi Stacey
[00:01:48.880 --> 00:01:51.000]   Hi
[00:01:51.000 --> 00:01:55.880]   You can like as in protest. Yeah, I'm gonna sink behind the camera
[00:01:55.880 --> 00:01:57.880]   Good
[00:01:57.880 --> 00:02:02.880]   That kind of
[00:02:02.880 --> 00:02:06.520]   You did it
[00:02:06.520 --> 00:02:12.720]   I was supposed to get a pink hat, but I couldn't I'm wearing a red. I understand that was that's de-rigger
[00:02:12.720 --> 00:02:18.400]   You were the red sweater. I am not wearing the red. It's it's literally the least I could do to celebrate international
[00:02:18.400 --> 00:02:24.520]   Wednesday literally Stacey has lipstick to match the day. Yes. There you go. There's Jeff Jarvis professor of journalism. I'm always read so
[00:02:24.520 --> 00:02:29.640]   It's pink. Yeah pink Lisa said that she said my toes are pink. I said that's a kind of red
[00:02:29.640 --> 00:02:34.440]   Buzz machine calm. That's the blog. He also writes and teaches
[00:02:34.440 --> 00:02:37.680]   What the hell was that you sorry?
[00:02:37.680 --> 00:02:41.720]   earthquake you were robot in there with you. What the hell I
[00:02:41.720 --> 00:02:47.160]   Lured my desk cuz I was trying to not hide as much. It's sorry
[00:02:47.160 --> 00:02:50.400]   Hello citizen
[00:02:50.720 --> 00:02:52.720]   You are disappearing citizen
[00:02:52.720 --> 00:02:58.480]   So I got all excited yesterday because you know I ordered this
[00:02:58.480 --> 00:03:01.120]   HTC you
[00:03:01.120 --> 00:03:05.360]   Android phone the ultra and it's a beautiful phone and I really think you know
[00:03:05.360 --> 00:03:11.760]   I like what HTC does they've made two of the most recent Google phones the pixel and the 6p I
[00:03:11.760 --> 00:03:14.160]   Like their audio
[00:03:14.160 --> 00:03:17.840]   And I and I want h I want HTC to come back to their glory days
[00:03:18.080 --> 00:03:24.400]   You know the HTC one was such a great phone. So I really high hopes for it and yesterday. I got an order a notice
[00:03:24.400 --> 00:03:31.360]   From FedEx and HTC package is coming. I was so excited. I thought I'm gonna do an unboxing. It's good
[00:03:31.360 --> 00:03:33.600]   I didn't because this is all that came
[00:03:33.600 --> 00:03:37.760]   They're dripping they're dribbling it out
[00:03:37.760 --> 00:03:45.040]   This is the USB C to audio adapter that I'm gonna need because it doesn't have a headphone jack. Oh, this is that no
[00:03:45.040 --> 00:03:47.040]   I rubs it in yes
[00:03:47.040 --> 00:03:48.480]   Yeah, that does kind of rub it
[00:03:48.480 --> 00:03:50.160]   They said this but they haven't set the phone yet
[00:03:50.160 --> 00:03:53.120]   I don't know and there's no release date or anything for the phone they're being very
[00:03:53.120 --> 00:03:59.360]   KG about that, but they didn't send me a backpack with Android toys in it and stuff
[00:03:59.360 --> 00:04:02.720]   So I don't you didn't bring that to show us I have that I came a few weeks ago
[00:04:02.720 --> 00:04:05.440]   So I'll bring it in next week. Oh, I say okay, I
[00:04:05.440 --> 00:04:08.280]   Couldn't figure out I think it was
[00:04:08.280 --> 00:04:10.800]   And a nice handwritten note. I
[00:04:11.360 --> 00:04:17.200]   Think it was because they know who I am. I can't imagine that everybody who ordered maybe everybody ordered this phone
[00:04:17.200 --> 00:04:24.560]   Got a backpack and a water bottle and Android dolls and I mean that that an a handwritten note from an HTC team member
[00:04:24.560 --> 00:04:31.600]   Anyway, the one thing I really think this is this is good and this is HTC trying to convince people it's okay to buy us
[00:04:31.600 --> 00:04:36.480]   They're doing a one-year free replacement for broken screens and water damage
[00:04:36.480 --> 00:04:40.480]   They're including that in the price. I mean, it's one of those 750 phones
[00:04:40.560 --> 00:04:43.120]   But yeah, I think that's a good idea
[00:04:43.120 --> 00:04:48.080]   They've got it. They've got to win people over somehow anyway. I got the cable
[00:04:48.080 --> 00:04:51.040]   Happy happy me
[00:04:51.040 --> 00:04:55.280]   Yeah cable. What's the charging cable? Is it type C? It's all C. So okay
[00:04:55.280 --> 00:05:00.160]   Uh, and I don't know why HTC's not doing a headphone jack
[00:05:00.160 --> 00:05:07.680]   I saw a rumor that the pixel 2 won't have one, but I guess it saves space. It just seems like it's it's not a
[00:05:08.240 --> 00:05:13.680]   Yeah, we know it's a bad idea. We need it. I never charge my like wireless anything
[00:05:13.680 --> 00:05:18.400]   Yeah, that's the problem. I don't want to have to charge things to to listen
[00:05:18.400 --> 00:05:24.320]   Oh, yeah for my for my headsets. I have to have something. We'll work without batteries. Yeah, and frankly wireless
[00:05:24.320 --> 00:05:28.400]   Has problems it drops out even apples
[00:05:28.400 --> 00:05:29.840]   vaunted
[00:05:29.840 --> 00:05:35.360]   W1 technology. I've had problems with air pods. Some people have told me they also have problems with their beats x
[00:05:35.760 --> 00:05:40.000]   Because this w1 chip sometimes gets the wrong bit rate and so
[00:05:40.000 --> 00:05:42.880]   Voice with furb like this
[00:05:42.880 --> 00:05:49.600]   And and that's not good. So it's like this as sync problem obviously turning it off and on a ill fix it, but again
[00:05:49.600 --> 00:05:52.240]   Wired doesn't have any of these problems
[00:05:52.240 --> 00:05:54.560]   um
[00:05:54.560 --> 00:05:56.560]   Continuing
[00:05:56.560 --> 00:05:59.520]   On the future of the Chromebook pixel
[00:06:01.520 --> 00:06:07.760]   I know jeff is very interesting you're going you're traveling you're gonna take your pixel seat your tablet. I do I do
[00:06:07.760 --> 00:06:12.240]   I'm going to uh some pow-low for oh my pink. Sorry for um
[00:06:12.240 --> 00:06:14.960]   Uh
[00:06:14.960 --> 00:06:17.440]   Newsgeist and then I'm going to london
[00:06:17.440 --> 00:06:20.480]   Next week the whole book is not a chrome book. Um
[00:06:20.480 --> 00:06:23.680]   Too heavy. Yeah
[00:06:23.680 --> 00:06:26.880]   Yeah
[00:06:26.880 --> 00:06:30.640]   Well, so is that saying that they're not dead
[00:06:30.640 --> 00:06:34.560]   That's I think we actually did this story, but she was rick oaster low saying I I I
[00:06:34.560 --> 00:06:37.840]   We did spoke we did I spoke to jeff
[00:06:37.840 --> 00:06:42.400]   It's more of that like oh no. Oh, no, it's just right now. We have no plans, etc, etc
[00:06:42.400 --> 00:06:48.480]   It's like jeff wore his black hoodie and he looked yeah, it was very sad right now. I remember yeah
[00:06:48.480 --> 00:06:51.600]   I was now jeff can not get an old human color. Sorry
[00:06:51.600 --> 00:06:54.240]   Sorry
[00:06:54.240 --> 00:06:55.520]   That was pink
[00:06:55.520 --> 00:06:58.880]   It was blue. I'm so blue and this brilliant idea for you jeff
[00:06:58.960 --> 00:07:03.040]   I'm going to send you some hue light bulbs that are colored. That's a good idea. Oh
[00:07:03.040 --> 00:07:05.760]   Color correct the opposite direction
[00:07:05.760 --> 00:07:08.640]   It'll be fine. Oh
[00:07:08.640 --> 00:07:13.600]   So if you're too big what would be yeah, I've got a very high ceiling with with
[00:07:13.600 --> 00:07:17.600]   Can't oh god. That's a lot of light bulbs
[00:07:17.600 --> 00:07:20.880]   I wonder he looks so bad
[00:07:20.880 --> 00:07:25.440]   But do if you got the cans that's you could put the uh to pick the uh hues will go on those
[00:07:25.440 --> 00:07:29.600]   I've used to using those yeah, but do you have a row six because six you know the problem is
[00:07:29.600 --> 00:07:31.440]   $360
[00:07:31.440 --> 00:07:34.400]   It's it's the fact that the outside is causing me the problems and that
[00:07:34.400 --> 00:07:41.040]   I've got a I've got a big window here. Yeah, that's probably what it is. Yeah, I didn't realize my big window. Geez. I had no idea
[00:07:41.040 --> 00:07:46.880]   That's what's in front of me. Of course. So we can't get the light balance right because you've got blue
[00:07:46.880 --> 00:07:49.840]   Blasting in at you and yellow behind you. No wonder
[00:07:49.840 --> 00:07:52.960]   That's what's oh, and there are no chains
[00:07:52.960 --> 00:07:56.880]   The hotels it's bad to know there's no I hate window treatments. I'll have to do it, but I hate window treatments
[00:07:56.880 --> 00:07:59.520]   You don't have to do it. Just get a sheet
[00:07:59.520 --> 00:08:04.000]   Take a sheet up do what you did in college is tack up a sheet
[00:08:04.000 --> 00:08:13.920]   Uh, the rail things are we no no we've solved a problem that has been you know
[00:08:13.920 --> 00:08:16.560]   Existant for a long time
[00:08:16.560 --> 00:08:19.520]   Or not as the sun goes down. I can't keep it readjusting
[00:08:19.520 --> 00:08:22.240]   badly
[00:08:22.400 --> 00:08:24.800]   You know it pays to be mark zuckerberg
[00:08:24.800 --> 00:08:30.160]   And I you know I'm holding out because he dropped out of harvard of course to start facebook
[00:08:30.160 --> 00:08:33.360]   He's now going to get his degree. He's done nothing since then
[00:08:33.360 --> 00:08:39.360]   Towards the degree. Oh, all right. He found a 400 billion dollar company, but uh harvard
[00:08:39.360 --> 00:08:45.600]   Uh who has decided it's an honorary degree though, right? So that doesn't count sure
[00:08:45.600 --> 00:08:49.520]   This doesn't count. You don't have to work to get an honorary degree
[00:08:50.560 --> 00:08:52.560]   Wait, really?
[00:08:52.560 --> 00:08:54.160]   What do you mean?
[00:08:54.160 --> 00:08:58.080]   Do we not care about honorary degrees? Well, yeah, yeah, yeah, yeah
[00:08:58.080 --> 00:09:00.640]   He'll be giving this an honor. It's an honor
[00:09:00.640 --> 00:09:03.920]   He'll be giving a dress to harvard's class of 2017
[00:09:03.920 --> 00:09:10.400]   You can't then say on your resume not that mark needs a resume, but you can't then say graduated from harvard. No
[00:09:10.400 --> 00:09:15.680]   Ah say holder of an honorary degree. Yeah, which means that somebody honored you which is nice
[00:09:15.680 --> 00:09:19.440]   I wonder what they're going to acknowledge behind it. They're not going to just give them a bs
[00:09:19.600 --> 00:09:24.160]   They'll give them a phd. I would oh, yeah, don't give them a doctorate of something. Yeah, doctor of letters
[00:09:24.160 --> 00:09:27.120]   Do they hand out honorary bs's? I don't even know
[00:09:27.120 --> 00:09:28.880]   No
[00:09:28.880 --> 00:09:32.320]   Bs, I would like an honorary bs. I think I've earned it
[00:09:32.320 --> 00:09:36.160]   Oh, yeah
[00:09:36.160 --> 00:09:40.720]   Are you gonna show the video? No, what's the video? Oh, it's on that screen. It's on the page
[00:09:40.720 --> 00:09:44.480]   Oh of him and bill gates. Sorry charming. Yes charming and it's so in this awkward way
[00:09:44.480 --> 00:09:48.480]   Uh gates got a harvard, uh honorary degree
[00:09:49.360 --> 00:09:54.800]   Tune in on me 25th back it up back it up back it up back it up. It was a great idea
[00:09:54.800 --> 00:09:58.400]   There's bill gates chewing something
[00:09:58.400 --> 00:10:01.280]   I just got invited to give the commencement address at harvard this year
[00:10:01.280 --> 00:10:07.120]   That's amazing. I remember you did it 10 years ago. Bill also dropped out of harvard. We should plan when Priscilla graduated
[00:10:07.120 --> 00:10:12.640]   I was there. Yeah, it was a lot of fun. Uh, you know 30 years later than I was supposed to but uh
[00:10:12.640 --> 00:10:16.960]   I enjoyed it. They know we didn't actually graduate right? Oh
[00:10:17.520 --> 00:10:22.480]   That is the best part. They actually give you a degree. You don't even have to go to class
[00:10:22.480 --> 00:10:27.760]   No, no, you just put that degree on your resume and it looks great. Can you only figure out what I'm gonna say?
[00:10:27.760 --> 00:10:31.520]   Yeah, we should work on them together. Let's go get some more snacks. All right
[00:10:31.520 --> 00:10:34.080]   So you get rid of patent everything?
[00:10:34.080 --> 00:10:38.640]   One of the wait a minute. What is the snack that they're eating?
[00:10:38.640 --> 00:10:41.520]   popcorn I think
[00:10:41.520 --> 00:10:46.960]   No, I think it's goldfish. Oh, is it? Oh, look at this. We oh, yeah, you're right. Very good center
[00:10:47.360 --> 00:10:48.560]   zoom
[00:10:48.560 --> 00:10:52.000]   Enhance. I think they're eating go magic CSI software
[00:10:52.000 --> 00:11:01.440]   Wow, um bill gates looks really old that he is. He's my age. He's a couple of years old. Yeah
[00:11:01.440 --> 00:11:04.240]   Yeah, well, he's okay. Go go
[00:11:04.240 --> 00:11:06.720]   He's 60. How old is bill gates?
[00:11:06.720 --> 00:11:16.640]   61 61 oh he's close to worry. He looks he looks frail though. Like you guys both look very robust and worried. We don't work hard
[00:11:17.600 --> 00:11:22.080]   Well, that's probably true. I think he's actually healthy. I'm sure he's very healthy. Yeah, he's not fat
[00:11:22.080 --> 00:11:25.360]   So that's one thing you should probably remember Stacy as you get older that
[00:11:25.360 --> 00:11:29.040]   Get being fat fills out the wrinkles and so you look younger for a while
[00:11:29.040 --> 00:11:31.680]   I
[00:11:31.680 --> 00:11:33.680]   Gotta
[00:11:33.680 --> 00:11:40.880]   Yeah, look he's kind of I don't know. Yeah, yeah, that's something always that goes your voice. Yeah, he's always been a little bit of a
[00:11:40.880 --> 00:11:45.040]   I miss his lopener. I'm building. Oh, just call me bill
[00:11:45.200 --> 00:11:49.840]   I'm in right for basic in your base for your audience. Yeah
[00:11:49.840 --> 00:11:55.680]   Uh, yeah, he's just he's just slender
[00:11:55.680 --> 00:11:58.880]   He's a slender fella bill's very athletic. I think
[00:11:58.880 --> 00:12:04.640]   Very good very competitive. I want bill gates to be around for a while. I do now. I really do
[00:12:04.640 --> 00:12:09.760]   Hey, I highly recommend the uh Warren Buffett documentary on HBO becoming Warren Buffett
[00:12:10.400 --> 00:12:16.640]   Um, it leads up to his 34 billion dollar gift to the bill of melinda gates foundation 10 years ago
[00:12:16.640 --> 00:12:18.640]   And it's really fascinating
[00:12:18.640 --> 00:12:21.600]   It's I mean, I don't I wonder if
[00:12:21.600 --> 00:12:27.680]   I feel like there maybe there's like it's like a cover up like maybe he's an alien or something
[00:12:27.680 --> 00:12:30.000]   but
[00:12:30.000 --> 00:12:34.240]   Because I mean how do you get to be the richest man in the world by just being a normal nice guy from Omaha?
[00:12:34.240 --> 00:12:36.240]   It doesn't seem possible
[00:12:36.240 --> 00:12:41.920]   You know and he dry he has breakfast it starts with him getting breakfast every morning his wife
[00:12:41.920 --> 00:12:44.960]   Looks at the stock market and if it's down
[00:12:44.960 --> 00:12:51.040]   She gives him two dollars and 15 cents for a happy meal at mcdonald's. He stops and he gets it
[00:12:51.040 --> 00:12:53.440]   He gets the less expensive sandwich
[00:12:53.440 --> 00:12:57.600]   If it's up she gives him 265 and he can get the more expensive
[00:12:57.600 --> 00:13:00.240]   Uh egg McMuffin
[00:13:00.240 --> 00:13:02.640]   And then he drives
[00:13:03.600 --> 00:13:07.280]   No, this is what he wants. This is how he lives. This is a richest man in the world
[00:13:07.280 --> 00:13:11.280]   He could just see a mcdonald's for breakfast every day is not a
[00:13:11.280 --> 00:13:16.320]   You can help with donals in your basement. He's I know he could have his own franchise
[00:13:16.320 --> 00:13:19.200]   Just in the basement. I don't know it's very odd
[00:13:19.200 --> 00:13:23.360]   Um, I I don't and it what seems to be from the die
[00:13:23.360 --> 00:13:26.720]   It's well worth watching from the documents very well made from the documentary
[00:13:26.720 --> 00:13:30.960]   It seems to be that he really didn't have any interest in the outside world except he knows how to make money
[00:13:31.440 --> 00:13:35.360]   He keeps he keeps lauding the principle of compound interest
[00:13:35.360 --> 00:13:40.400]   Like all he did was kept putting pennies in the savings account and it just grew to
[00:13:40.400 --> 00:13:42.800]   100 billion dollars like that
[00:13:42.800 --> 00:13:46.960]   uh, and uh, but he's very unassuming and he just says
[00:13:46.960 --> 00:13:50.560]   You know, I just I you know, I'm not that interested in the money
[00:13:50.560 --> 00:13:53.920]   So, uh, I'm gonna give it all away, but I I kind of like playing the game
[00:13:53.920 --> 00:13:59.840]   And he was very you know, he's a sweet guy. He went to iHOP yesterday for the free pancakes. I swear to god
[00:14:00.880 --> 00:14:03.680]   There were free pancakes that iHOP oh yeah and cake day
[00:14:03.680 --> 00:14:11.840]   Nice, you miss pancake day you mess up women's day stay see we need to get your calendar get her a calendar
[00:14:11.840 --> 00:14:17.600]   Dear lord, okay. I am talking about all this little trivia because I just
[00:14:17.600 --> 00:14:20.640]   I don't see google
[00:14:20.640 --> 00:14:24.560]   I don't see anything what what should we talk about pick something? Oh, you're bored
[00:14:24.560 --> 00:14:28.480]   I don't see a google's deep learning ai project diagnosis cancer
[00:14:29.200 --> 00:14:34.480]   Oh, just that's kind of interesting that is kind of a we've been seeing more and more that you know, the ais can
[00:14:34.480 --> 00:14:42.320]   I don't know what this is. Hey, I'm sorry this autoplay video dress me nuts
[00:14:42.320 --> 00:14:45.680]   All right, I'll make you happy have you seen the flying phone case camera
[00:14:45.680 --> 00:14:51.920]   The kitchen project. Yeah, that's by the way, you know, do not put money into that. I know okay fine
[00:14:51.920 --> 00:14:57.520]   Let's make you happy. There's in no way. That's gonna be a real thing. I've spent enough time
[00:14:58.640 --> 00:15:06.320]   On kickstarter backing and crazy projects. I know I know I know I have to this is the air selfie. Is this it
[00:15:06.320 --> 00:15:09.120]   Yeah, the bottom of the uh, it's not it
[00:15:09.120 --> 00:15:12.800]   Uh bottom of the rundown actually the air selfie is old one
[00:15:12.800 --> 00:15:17.280]   This is self-fly the smart flying phone case
[00:15:17.280 --> 00:15:23.760]   Camera so it's a case there are moments you want to cherish from your unit. All right. I can't I can't I'm gonna turn down the volumes
[00:15:23.760 --> 00:15:29.520]   I can't take this uh, so they're all having a happy go lucky life like all you millennials do Stacy
[00:15:29.520 --> 00:15:36.960]   And your daughter is playing at the baby grand piano and uh, so this has got to be phony
[00:15:36.960 --> 00:15:40.400]   So you open up your case
[00:15:40.400 --> 00:15:42.800]   And it flies your camera around
[00:15:42.800 --> 00:15:49.200]   No way much money too. Yeah, no way by the way. They've raised almost a million dollars
[00:15:49.200 --> 00:15:53.440]   Uh, no way this drone can lift your phone
[00:15:53.520 --> 00:15:56.880]   I'll tell you that right now. No, it doesn't lift your phone. No, it has its own camera. It has its own camera
[00:15:56.880 --> 00:15:59.280]   Case you take it out of the out of the camera case
[00:15:59.280 --> 00:16:03.520]   I can see that's where you carry around with you and you have your drone with the drone of the cameras
[00:16:03.520 --> 00:16:06.320]   Everybody need to have a drone with them all times
[00:16:06.320 --> 00:16:09.120]   Okay, do you think this is real?
[00:16:09.120 --> 00:16:11.520]   Oh car system now
[00:16:11.520 --> 00:16:14.800]   Uh, let's see 99 bucks to get one
[00:16:14.800 --> 00:16:16.320]   No
[00:16:16.320 --> 00:16:21.360]   Expected retail 139. I would say my suggestion is wait wait
[00:16:22.080 --> 00:16:24.080]   Wait because it's fun. Yeah
[00:16:24.080 --> 00:16:29.920]   Let's see what the risks are. He's grumpy enough. That didn't make him happy that well. Yeah, that didn't make me happy because
[00:16:29.920 --> 00:16:34.560]   I don't buy it. Let me see if i'm gonna go all the way to the bottom. That's where they hide the
[00:16:34.560 --> 00:16:37.520]   risks and challenges
[00:16:37.520 --> 00:16:39.920]   It's based on existing technology
[00:16:39.920 --> 00:16:44.320]   We've already developed a few working prototypes which have been tested and performed well
[00:16:44.320 --> 00:16:47.440]   Many drones have become quite popular. All right
[00:16:48.240 --> 00:16:52.800]   Our drone is very stable. However, a 99 dollar product obviously does not include stabilizing gimbal
[00:16:52.800 --> 00:16:57.520]   Okay, obviously. Yeah, all right
[00:16:57.520 --> 00:17:02.880]   Uh, oh, well, this is important that the video shows the target
[00:17:02.880 --> 00:17:05.440]   Of the final product
[00:17:05.440 --> 00:17:11.680]   Not an actual we do have working prototypes, but the prototype does not include
[00:17:11.680 --> 00:17:15.120]   The full and final functionality
[00:17:15.120 --> 00:17:17.680]   It's feasible. We can do it
[00:17:17.840 --> 00:17:22.960]   We just haven't yet. Yeah, yeah, I don't know. I maybe i'm being cynical. Am I being being cynical?
[00:17:22.960 --> 00:17:28.640]   No, no, you're that is the voice of experience. I bought a floating bonsai tree and uh, i've learned
[00:17:28.640 --> 00:17:34.640]   Bless your heart right there the deep learning
[00:17:34.640 --> 00:17:38.400]   I'm gonna go back to this and i'm gonna have the same stupid
[00:17:38.400 --> 00:17:44.400]   Startup video. This is the international business time. So I would like to find a better source for this, but
[00:17:45.280 --> 00:17:49.280]   Um, diagnosis cancer they say faster than experts
[00:17:49.280 --> 00:17:55.120]   They've been finding that with all kinds of yeah, we saw the skin cancer one and they were it was parody right now
[00:17:55.120 --> 00:17:59.040]   This one, uh, the human being here. Let's go. Let's go to the google white paper
[00:17:59.040 --> 00:18:07.360]   The human being was able to do 70 using gigapixel pathology images. So very very high resolution images
[00:18:07.360 --> 00:18:10.080]   um
[00:18:10.080 --> 00:18:13.840]   The the human pathologist got 73.2 accuracy
[00:18:14.320 --> 00:18:16.320]   the computer
[00:18:16.320 --> 00:18:18.800]   92.4 percent
[00:18:18.800 --> 00:18:22.160]   So that's that's pretty good
[00:18:22.160 --> 00:18:26.240]   Um, and they use it. I guess there's a standard test set that they use
[00:18:26.240 --> 00:18:32.800]   So if if you if you read this the people should be worried are radiologists the people who read
[00:18:32.800 --> 00:18:34.880]   We already knew the radiologists were going
[00:18:34.880 --> 00:18:38.160]   going away. Yeah
[00:18:38.160 --> 00:18:42.960]   I have friends who are radiologists and they've been they're among the most technologically savvy of
[00:18:43.600 --> 00:18:48.480]   Doctors for instance, uh, I remember years ago they were using something called a photo phone
[00:18:48.480 --> 00:18:52.720]   Which allowed them using a modem to connect to the hospital and downloads
[00:18:52.720 --> 00:18:55.920]   X-ray so they could read them at home
[00:18:55.920 --> 00:18:59.200]   And then they got to the point now where they can do that all over the world
[00:18:59.200 --> 00:19:02.720]   So many groups will have doctors all over the world in different time zones
[00:19:02.720 --> 00:19:06.240]   So that they can respond their group can respond at any time
[00:19:06.240 --> 00:19:12.560]   A lot of times your your radiologist is not in the hospital is at home or somewhere as in India or china or somewhere else
[00:19:13.200 --> 00:19:16.240]   Um, but it is just a matter of time. Isn't it where you get an AI doing this?
[00:19:16.240 --> 00:19:20.640]   Yeah, and if you'd like a company called nLitic
[00:19:20.640 --> 00:19:27.520]   Which they do special they do AI specifically. I thought they did speech, but apparently they do medical imaging too
[00:19:27.520 --> 00:19:30.240]   um back in
[00:19:30.240 --> 00:19:32.720]   2015 so about 18 months ago
[00:19:32.720 --> 00:19:36.000]   They said they were able to diagnose cancers
[00:19:36.320 --> 00:19:41.600]   Wow, they had a false negative rate of 7% or sorry the humans had a false negative rate of 7%
[00:19:41.600 --> 00:19:46.800]   Analytics AI had none and then they had a false positive rate none
[00:19:46.800 --> 00:19:55.600]   Wow false positive rate, which is incorrectly diagnosing the cancer of 66% and the analytic AI had a false positive rate of 47%
[00:19:55.600 --> 00:19:58.240]   False positives not good
[00:19:58.240 --> 00:20:00.080]   No, right nevertheless
[00:20:00.080 --> 00:20:02.480]   Then you could have a set the false positive
[00:20:02.640 --> 00:20:06.880]   Well, the false positive usually leads to biopsy and then I mean not that that's not fun, but
[00:20:06.880 --> 00:20:11.200]   Um, so we're gonna do on monday. We're gonna do an iOS today
[00:20:11.200 --> 00:20:18.720]   Uh segment on health care devices and I already got this one the live core that you use jeff for your ekg
[00:20:18.720 --> 00:20:21.840]   And I got you got one. Yeah, and I got an ekg. No, it was pretty amazing
[00:20:21.840 --> 00:20:25.200]   It's really it is. It's really well done. Yeah
[00:20:25.200 --> 00:20:29.040]   And then I also ordered a new blood pressure
[00:20:29.600 --> 00:20:34.480]   Monitor called the cardia that works a little. Oh, that was terrible. It is. Is it the q1?
[00:20:34.480 --> 00:20:36.800]   Yeah, the cardio starts with a q. Yeah
[00:20:36.800 --> 00:20:41.680]   So I did the don't ask why but I should always ask you first
[00:20:41.680 --> 00:20:46.080]   No, no, I did I did a blood pressure cuff monitor
[00:20:46.080 --> 00:20:52.640]   Story for the wire cutter. So I have the y things. I can compare it to that
[00:20:52.640 --> 00:20:55.440]   And I so the heart
[00:20:55.440 --> 00:21:00.320]   This one is different because you don't uh, they have a bunch of other stuff too, but you don't have to
[00:21:00.320 --> 00:21:02.960]   It's not I mean does it inflate?
[00:21:02.960 --> 00:21:09.600]   So this one does inflate so I'm I'm pointing out your screen here, which is silly
[00:21:09.600 --> 00:21:12.720]   That's okay. That's what everybody else is doing. Look at leo screen. It's so big
[00:21:12.720 --> 00:21:16.560]   Um, no, it doesn't flake. So it's it's just portable though. Right?
[00:21:16.560 --> 00:21:19.760]   But the challenge with that one and we didn't actually
[00:21:19.760 --> 00:21:23.280]   We tested it or I tested it. I don't know why I'm saying we
[00:21:23.760 --> 00:21:26.640]   Um, but it's real touchy about
[00:21:26.640 --> 00:21:31.200]   Fold it to turn it off. You have to fold it over the right way
[00:21:31.200 --> 00:21:36.160]   In the right way is kind of complicated. Oh, so like it drains its battery
[00:21:36.160 --> 00:21:41.040]   Yeah, so it was always that a battery whenever I was trying to test but is it accurate?
[00:21:41.040 --> 00:21:48.080]   Um, those are actually so both why things and that one are less accurate than like the most accurate like the own Ron or something
[00:21:48.080 --> 00:21:52.320]   I'm run 10. I guess what it was and those are cheap by the way. Those are a lot cheaper than these
[00:21:53.600 --> 00:21:59.760]   Yeah, well, yeah, and they they will pair to your phone and copy data over there and just like that and all that stuff too the on runs
[00:21:59.760 --> 00:22:04.400]   They do you have to have both an on run account and an IOS account
[00:22:04.400 --> 00:22:09.040]   Well, that's somebody was complaining about the cardio as well that that in order to send your data to your doctor
[00:22:09.040 --> 00:22:12.240]   You have to send it to cardio first, which is yeah
[00:22:12.240 --> 00:22:18.240]   But that's true of a life core too, isn't it? Jeff that you have to kind of go through them
[00:22:18.240 --> 00:22:20.800]   And you can even buy they sell readings
[00:22:20.800 --> 00:22:23.920]   You can I sell readings and all that but yeah once well you have to get your first one approved
[00:22:23.920 --> 00:22:28.080]   I'm not sure what the legal reason for that is. Yeah, and then and then you just just use it
[00:22:28.080 --> 00:22:29.920]   You don't need to
[00:22:29.920 --> 00:22:36.240]   To do anything. I've used it a couple times where I thought oh, oh am I and you would you do you send it to your doctor or?
[00:22:36.240 --> 00:22:42.960]   No, it says normal because oh it tells you it tells you and you can and I can I've been around this stuff long enough
[00:22:42.960 --> 00:22:45.440]   I know I'm symptomatic
[00:22:45.440 --> 00:22:50.480]   Yeah, I don't know. I like this category. I mean, you know
[00:22:50.480 --> 00:22:55.680]   We're in the days, but I think the idea of having some diagnostics you have a pretty powerful computer in your pocket
[00:22:55.680 --> 00:23:00.400]   Well, the other thing is so I don't know if I told you so when when Jake taught at ID tech camp
[00:23:00.400 --> 00:23:04.000]   Some some summers ago many summers ago. I went and talked to the class
[00:23:04.000 --> 00:23:06.240]   And there was one kid in there who had Tourette's
[00:23:06.240 --> 00:23:10.320]   And his his idea for an app was basically to capture
[00:23:10.320 --> 00:23:14.000]   various signals because those signals could be
[00:23:14.000 --> 00:23:16.640]   predictive
[00:23:16.640 --> 00:23:18.640]   of an episode
[00:23:19.200 --> 00:23:21.200]   and I would think for things like
[00:23:21.200 --> 00:23:24.160]   Tourette's
[00:23:24.160 --> 00:23:27.600]   Having seizures epilepsy
[00:23:27.600 --> 00:23:33.600]   Also, my mother is diabetic and there's signals that that you know when I grew up with her
[00:23:33.600 --> 00:23:36.560]   She was diabetic because I was born by fault
[00:23:36.560 --> 00:23:42.240]   But type one so she had insulin reactions and there were just many signals her her
[00:23:42.240 --> 00:23:45.520]   The claminess of her skin the way she moved the way she talked
[00:23:46.000 --> 00:23:50.720]   You know, you know that there are going to be for that kind of effort at diagnosis
[00:23:50.720 --> 00:23:54.640]   Being able to get somebody medication to stop them
[00:23:54.640 --> 00:23:58.880]   You know, it's it's like the dog you hear about the dogs that can that can tell when somebody's going to go into an epileptic
[00:23:58.880 --> 00:24:05.360]   Exager because the dog is picking up on signals right that we're too stupid to see right they actually use companion animals for that
[00:24:05.360 --> 00:24:09.200]   Don't they yeah, so all those areas that that to me is a fascinating area
[00:24:09.200 --> 00:24:13.120]   I was scheduled to have a call with Vic and see what else they're working on but we had to cancel we should point out dr
[00:24:13.120 --> 00:24:15.760]   Mom's saying the doctors won't use a
[00:24:15.760 --> 00:24:19.920]   Readout unless it's FDA approved the the live core is
[00:24:19.920 --> 00:24:24.480]   FDA yes one of the few that is I don't know if the cardio is or not. I don't see
[00:24:24.480 --> 00:24:29.440]   Anything saying it is the cardiata. You mean the car do you think that the blood pressure?
[00:24:29.440 --> 00:24:32.240]   Yeah, it's oh obviously, but yeah, yeah, the the
[00:24:32.240 --> 00:24:37.360]   But yours is a proof yours. You're a life core is yeah. Yeah, so you could send it to a doctor
[00:24:37.360 --> 00:24:41.040]   Yeah, yeah, it's very small and easy. I'll leave it in my briefcase
[00:24:41.760 --> 00:24:45.600]   Um, you know they make it so you can stick it on the back of your phone and have it all the time
[00:24:45.600 --> 00:24:48.240]   But I don't want that I'm waiting for blood sugar
[00:24:48.240 --> 00:24:52.880]   Some sort of blood sugar sampling without pinpricks that would be nice. Yes
[00:24:52.880 --> 00:24:59.120]   Don't they have those that you can implant. I mean they're implantables. Yeah, they're they're still under there still
[00:24:59.120 --> 00:25:03.040]   I don't know. I've looked at those. I don't know if I want to do that
[00:25:03.040 --> 00:25:05.040]   I don't
[00:25:05.040 --> 00:25:10.480]   If I were type if I were type one maybe I would because then you really monitoring is so important. Oh, yes. Yeah
[00:25:11.280 --> 00:25:16.000]   Uh, anyway, yeah, so okay. Good. No, I'm a little test or
[00:25:16.000 --> 00:25:23.760]   I was going to say a reminder for you when you're taking your blood sugar or blood pressure. Yeah, um, make sure you do it correctly
[00:25:23.760 --> 00:25:29.200]   In terms of like chilling and having your both feet on the floor. Yeah, otherwise your readings. I know
[00:25:29.200 --> 00:25:33.680]   The only reason main reason I wanted to do that is because I because it always goes up when I'm in the doctor's office
[00:25:33.680 --> 00:25:36.000]   So I just wanted to try it at home
[00:25:36.000 --> 00:25:38.480]   So what did you find?
[00:25:38.480 --> 00:25:43.440]   It's much better at home. It is. Yeah, but I'm also I'm on medication. So
[00:25:43.440 --> 00:25:48.160]   I uh that helped you know the listen approach helps
[00:25:48.160 --> 00:25:54.400]   Uh problem with doctors. They own you want to talk about this? Yeah, I have a problem with doctors. They always finding something wrong
[00:25:54.400 --> 00:25:56.400]   I hate that
[00:25:56.400 --> 00:25:57.840]   I hate that
[00:25:57.840 --> 00:26:01.680]   Google and ibm say we want artificial intelligence to help you
[00:26:01.680 --> 00:26:04.800]   Not replace you. Of course, that's what they would say
[00:26:04.800 --> 00:26:07.600]   Liars
[00:26:07.600 --> 00:26:09.920]   Okay, wait, wait before we hate on iai
[00:26:09.920 --> 00:26:17.520]   Sorry, I gotta stop this. Thank you. I can turn off autoplay and it still comes back before we hate on ai. Yes
[00:26:17.520 --> 00:26:27.760]   AI can be really effective at a lot of things like what is effectively grunt work for people right or intuition based stuff so
[00:26:27.760 --> 00:26:30.320]   As long as I stick to that stuff
[00:26:30.320 --> 00:26:33.200]   But I mean if you're a radiologist you'd be pretty upset right now, wouldn't you?
[00:26:34.080 --> 00:26:38.480]   Well, yeah, and if I was like a hand calligrapher back when it's true
[00:26:38.480 --> 00:26:42.960]   Press I'd be upset too. Look at Jeff. She got good for you
[00:26:42.960 --> 00:26:45.600]   See I do have for you
[00:26:45.600 --> 00:26:50.880]   So, I mean, I'm not I
[00:26:50.880 --> 00:26:59.360]   I think there's a lot of opportunity that we will lose if we don't if we just look at it from a jobs loss perspective
[00:26:59.520 --> 00:27:03.760]   So no, no, and in fact, uh, I've talked to a number of people who say
[00:27:03.760 --> 00:27:09.920]   That uh, it's not that clear john mark if we had a great interview with him two weeks ago the great
[00:27:09.920 --> 00:27:15.600]   Kind of one of the best tech writers. Uh, yep, New York times for 20 years 25 30 years
[00:27:15.600 --> 00:27:21.840]   Um, and he was saying, you know, it's not all that clear what the job impact of artificial intelligence would be
[00:27:21.840 --> 00:27:28.800]   You know, there's there's there's it's it's not it's not like intuitive your intuitive grasp of it is
[00:27:28.880 --> 00:27:31.680]   Oh, well those robots are just gonna take her jobs when we're sitting on the grass
[00:27:31.680 --> 00:27:35.440]   He said that's probably you know in many cases they create jobs
[00:27:35.440 --> 00:27:42.960]   Anyway, so I I think there's as john's really good about not kind of accepting the the uh, the
[00:27:42.960 --> 00:27:44.720]   You know
[00:27:44.720 --> 00:27:50.480]   Accepted point of view and digging deeper so I kind of trust you speaking of which here's an article from the drive jonathan ramsey
[00:27:50.480 --> 00:27:54.880]   Who says the way we talk about autonomous vehicles is a lie
[00:27:56.000 --> 00:28:00.720]   And that's dangerous. He says no matter what you've been told and told and told again our self-driving future is a long
[00:28:00.720 --> 00:28:04.000]   And uncharted ways off pretending otherwise
[00:28:04.000 --> 00:28:06.800]   I have dire consequences
[00:28:06.800 --> 00:28:12.320]   So, uh, he says don't believe the clickbait
[00:28:12.320 --> 00:28:16.240]   partly because the definition of self-driving car is
[00:28:16.240 --> 00:28:21.840]   fuzzy and uh, you know level one two three and four most of the time when
[00:28:22.480 --> 00:28:27.280]   Journalists and the press are talking about self-driving cars are talking about tesla style level one autonomy not
[00:28:27.280 --> 00:28:30.160]   fully autonomous self-driving
[00:28:30.160 --> 00:28:32.560]   vehicles
[00:28:32.560 --> 00:28:35.440]   Uh, and so yeah, I think a lot of times
[00:28:35.440 --> 00:28:37.760]   um
[00:28:37.760 --> 00:28:41.680]   He says there's currently no standard for the type of equipment used in semi autonomous systems
[00:28:41.680 --> 00:28:46.480]   Um musk says he's not a big fan of lydar due to its complicity and expense
[00:28:47.920 --> 00:28:53.760]   Uh, although I I do feel like a lot of others are using lydar. I don't know
[00:28:53.760 --> 00:28:58.720]   Uh, isn't is it for that's using lydar? Yeah
[00:28:58.720 --> 00:29:01.920]   Uh
[00:29:01.920 --> 00:29:08.800]   In many cases, uh, the you know, they're very the places that they're testing it or using self-driving cars are very constrained
[00:29:08.800 --> 00:29:12.000]   Um
[00:29:12.000 --> 00:29:16.960]   That's true. There is a new there is a new classification system replacing the level zero to four
[00:29:17.520 --> 00:29:20.480]   autonomy that just came out from the nhtsa
[00:29:20.480 --> 00:29:27.680]   Taxonomy and definitions for terms related to driving automation systems for on road motor vehicles now has six
[00:29:27.680 --> 00:29:33.920]   levels of autonomy level zero is intermittent warning systems like blind spot detection one
[00:29:33.920 --> 00:29:39.040]   monitor environment alter steering acceleration and braking like parking assist level two
[00:29:39.040 --> 00:29:42.400]   Systems that steer and change speed
[00:29:44.320 --> 00:29:46.320]   traffic jam assistance
[00:29:46.320 --> 00:29:52.720]   the driver in all uh and all of those levels obviously zero one and two has to be there and monitor level three
[00:29:52.720 --> 00:29:59.440]   Could take over all driving functions and total monitoring of the environment, but the driver is expected to be ready to take over
[00:29:59.440 --> 00:30:04.640]   If the vehicle finds itself in a situation it can't handle or strays off course
[00:30:04.640 --> 00:30:12.080]   And then he talks about the number of disengagements that is humans taking over
[00:30:12.240 --> 00:30:14.240]   um
[00:30:14.240 --> 00:30:20.480]   He says although cars are improving none of the experts with whom we spoke believe level three autonomy is safe
[00:30:20.480 --> 00:30:27.680]   And the issue has largely to do with people a self-driving car operating an autonomous mode can create in drivers a false sense of security
[00:30:27.680 --> 00:30:30.800]   Yep, and it's susceptibility to distraction
[00:30:30.800 --> 00:30:37.360]   Making emergency disengagement more dangerous because the point at which the driver needs to retake we've talked about this before control
[00:30:37.920 --> 00:30:42.240]   Is also the point at which he knows the least he's poorly equipped to do so you know what the hell's going on
[00:30:42.240 --> 00:30:47.600]   What you mean need me to steer what's going on in the seconds? It takes you to figure out are of course
[00:30:47.600 --> 00:30:50.320]   deadly
[00:30:50.320 --> 00:30:55.120]   And that's I have to say and i'm sure this is true for you know stacey you don't have uh autopilot is that right
[00:30:55.120 --> 00:30:57.760]   I don't yeah
[00:30:57.760 --> 00:31:00.640]   So if you did and certainly we do uh on our model x
[00:31:00.640 --> 00:31:03.200]   I watch like often you use it
[00:31:03.200 --> 00:31:05.600]   I use it all the time, but i'll use it tonight going to the airport
[00:31:05.600 --> 00:31:09.040]   But i'm but my hands are on the wheel and i'm looking I stay engaged
[00:31:09.040 --> 00:31:14.800]   I would not dream of looking down at my phone or something else for that precise reason
[00:31:14.800 --> 00:31:18.000]   So are you really relaxed?
[00:31:18.000 --> 00:31:20.320]   Yeah, I'll tell you what
[00:31:20.320 --> 00:31:22.320]   It's great in commute traffic
[00:31:22.320 --> 00:31:26.720]   Because I have some considerable amount of confidence in the cars ability to stop
[00:31:26.720 --> 00:31:30.320]   Uh if a car front of me stops that I I trust
[00:31:31.440 --> 00:31:36.640]   So I pay attention to the steering, but I don't have to ride the accelerator, which is really or the brake, which is really nice
[00:31:36.640 --> 00:31:39.680]   So it's very helpful
[00:31:39.680 --> 00:31:42.880]   So level four is the first phase it this is the article goes on
[00:31:42.880 --> 00:31:48.000]   Uh, which vehicle will never need driver input no matter the situation if a level four car gets in trouble
[00:31:48.000 --> 00:31:53.600]   The car is programmed to get itself out of danger without human input by pulling itself off the road for instance
[00:31:53.600 --> 00:31:58.000]   Currently there are no level four autonomous vehicles for sale
[00:31:58.800 --> 00:32:03.840]   Although automakers and headlines continue insinuate are outright declared they'll be here in three years time but 2020
[00:32:03.840 --> 00:32:08.880]   Um, he's he's skeptical and i thought he's probably right
[00:32:08.880 --> 00:32:12.240]   Right, um
[00:32:12.240 --> 00:32:21.200]   And he talks about the you know famous failures of mercedes and tesla and wamow and
[00:32:21.200 --> 00:32:24.480]   uber
[00:32:24.480 --> 00:32:27.840]   He says it's a media hype machine that's putting our lives in danger
[00:32:28.800 --> 00:32:30.800]   Does that make sense?
[00:32:30.800 --> 00:32:32.800]   That's a little like a water in the office
[00:32:32.800 --> 00:32:35.280]   Yeah, I mean other side look techno panic
[00:32:35.280 --> 00:32:38.640]   So
[00:32:38.640 --> 00:32:44.560]   I don't think we'll actually be there because we I think once people start using this we're gonna
[00:32:44.560 --> 00:32:47.200]   encounter the bumps in the road quite literally
[00:32:47.200 --> 00:32:48.880]   um
[00:32:48.880 --> 00:32:50.400]   and
[00:32:50.400 --> 00:32:56.480]   Then we'll slow down, but I think it's important to galvanize the industry towards this kind of audacious goal because I think the
[00:32:56.480 --> 00:32:58.000]   Technology is really close
[00:32:58.000 --> 00:33:02.320]   And to get people starting to talk about it and regulate and think about it this way
[00:33:02.320 --> 00:33:05.040]   I think is a good way to get us to that goal or
[00:33:05.040 --> 00:33:11.520]   Get us there eventually kind of like kennedy, you know directing us to the moon. Yeah, yeah
[00:33:11.520 --> 00:33:16.800]   I agree with that on the other hand. I think it's we all need to be careful in automakers, especially of over promising
[00:33:16.800 --> 00:33:21.040]   Uh and giving people the impression they can take their hands off the wheel and start reading a book
[00:33:21.040 --> 00:33:23.440]   You know and people do have that impression, right?
[00:33:25.680 --> 00:33:30.240]   I don't people do. I mean, yeah, look at all the people who I don't put their Tesla on autopilot and watch movies
[00:33:30.240 --> 00:33:38.480]   Yeah, a little idea really well, that's what that isn't that still illegal. Yeah. Yeah, but but so and this is his point is that you know
[00:33:38.480 --> 00:33:40.480]   If you watch the media coverage
[00:33:40.480 --> 00:33:42.000]   you know
[00:33:42.000 --> 00:33:44.000]   So he talks about one
[00:33:44.000 --> 00:33:47.600]   Uh one report saying but what are we gonna do with all the new free time?
[00:33:47.600 --> 00:33:52.480]   This is from inside edition about a grandmother behind the wheel of a self-driving Tesla
[00:33:52.960 --> 00:33:58.880]   It was clear we were in good hands with the p90d but with all the new free time autopilot afforded us what were we going to do with it?
[00:33:58.880 --> 00:34:02.560]   Pay attention and drive. How about that?
[00:34:02.560 --> 00:34:09.360]   Novel idea and of course it makes sense people love the science fiction angle of the cars driving ourselves
[00:34:09.360 --> 00:34:15.280]   Well, and a lot of people hate to drive. I mean, I know that there are people who love to drive but
[00:34:15.280 --> 00:34:21.200]   I will say that driving and stopping go traffic, which used to be my worst nightmare has gotten a lot better
[00:34:21.200 --> 00:34:27.200]   Thanks to autopilot. I do much prefer. I feel much better and stopping to go traffic. I was always afraid I was going to fall asleep
[00:34:27.200 --> 00:34:30.720]   And ramen ram into somebody
[00:34:30.720 --> 00:34:35.520]   I haven't followed asleep, but I have run into someone. Oh who hasn't
[00:34:35.520 --> 00:34:40.240]   Anyway, I just you know, I I agree there it's
[00:34:40.240 --> 00:34:46.960]   This is link bait and some this is unfortunate to some degree as well, but uh, it's probably a good cautionary story
[00:34:46.960 --> 00:34:49.520]   that you know, it's
[00:34:49.520 --> 00:34:52.960]   Maybe it's not a big lie, but it's maybe not quite here yet either
[00:34:52.960 --> 00:34:59.200]   Uh, let's see Kaggle. What's Kaggle? Oh, that's
[00:34:59.200 --> 00:35:04.800]   It's a site that hosts data competitions. They've done a lot of places. Google buys Kaggle
[00:35:04.800 --> 00:35:08.400]   Oh, yes, I think this is a good idea
[00:35:08.400 --> 00:35:10.720]   Yeah
[00:35:10.720 --> 00:35:14.960]   I thought this was a nice move giving them credibility with a community
[00:35:15.600 --> 00:35:20.160]   Google has already been very open with the AI and the data analysis community about what it's doing
[00:35:20.160 --> 00:35:22.400]   um
[00:35:22.400 --> 00:35:27.280]   But this basically is a way to show support for people who kind of value that model
[00:35:27.280 --> 00:35:31.040]   I think about it maybe as an answer to the creation of open AI
[00:35:31.040 --> 00:35:33.520]   Mm
[00:35:33.520 --> 00:35:37.440]   Yeah, kind of tangentially. I mean it's not a direct answer. It's not like
[00:35:37.440 --> 00:35:42.480]   Callback or anything like that. But well, you know, google next is going on right now in san francisco
[00:35:42.480 --> 00:35:48.560]   I was really hoping that we'd have a slew of stuff to talk about from next they're making all the iot announcements tomorrow
[00:35:48.560 --> 00:35:50.320]   Oh
[00:35:50.320 --> 00:35:52.320]   poor stacy
[00:35:52.320 --> 00:35:57.600]   Sadness, I know and kevin kevin was there so well he'll be there tomorrow. I hope
[00:35:57.600 --> 00:36:02.800]   Presumably yeah, who knows where kevin is you'll have stuff in the world of kevin
[00:36:02.800 --> 00:36:08.560]   But apparently they're going to be some iot announcements of this this is what is next. It's not a public thing, right?
[00:36:09.520 --> 00:36:15.360]   It's I thought was there cloud is their cloud is their cloud conference. Yeah, so it's for cloud engineers cloud
[00:36:15.360 --> 00:36:18.640]   Everything you need to do about google cloud next
[00:36:18.640 --> 00:36:20.160]   um
[00:36:20.160 --> 00:36:26.800]   They there was a keynote we should we didn't cover it and uh, maybe tomorrow we should cover the keynote because that's when was it die-end green
[00:36:26.800 --> 00:36:34.320]   Yeah, yeah, yeah, so she she said some lovely things written my friend bar wrote it up. Um, it was very
[00:36:35.920 --> 00:36:40.800]   The headlines all are focused on what she said about google being a great place for women to work
[00:36:40.800 --> 00:36:44.080]   She's senior vice president at google cloud center perch i spoke as well
[00:36:44.080 --> 00:36:49.840]   eric schmitt fefe lee tareek's uh shaukat saro robinson
[00:36:49.840 --> 00:36:51.760]   um
[00:36:51.760 --> 00:36:53.600]   urs hortz
[00:36:53.600 --> 00:36:56.720]   It's all the colors. I know I like his name to hurts. Oh
[00:36:56.720 --> 00:36:58.960]   uh
[00:36:58.960 --> 00:37:04.560]   I like favorite fefe lee is good too. She's a chief scientist cloud ai and machine learning at google cloud
[00:37:05.680 --> 00:37:10.000]   So but I anyway, I just saw on twitter that there'll be more announcements tomorrow
[00:37:10.000 --> 00:37:12.880]   And then that that maybe there'll be some stuff to talk about then
[00:37:12.880 --> 00:37:17.200]   Maybe they'll have like an answer to amazon's AWS lambda
[00:37:17.200 --> 00:37:20.400]   If they don't already tell us what lambdas
[00:37:20.400 --> 00:37:24.640]   Oh, I shouldn't have said that because now i'm gonna butcher this
[00:37:24.640 --> 00:37:27.680]   um
[00:37:27.680 --> 00:37:30.000]   I'm like, okay. It's um
[00:37:30.000 --> 00:37:35.120]   I can take this if you take it
[00:37:35.680 --> 00:37:40.080]   Take it because whatever I think about lambdai think about the future and my brain just kind of explodes a little bit
[00:37:40.080 --> 00:37:44.720]   And i'm like, I should write this down before I get excited. It's kind of basically zero administration cloud computing
[00:37:44.720 --> 00:37:47.920]   So that's so much less complex
[00:37:47.920 --> 00:37:52.800]   Good job. I was gonna go into microservices and functional programming
[00:37:52.800 --> 00:37:58.480]   You're using you're using their cloud, but you don't have to like, you know create a container set up a server any of that stuff
[00:37:58.480 --> 00:38:00.960]   You just upload your code and then it just runs
[00:38:01.680 --> 00:38:06.160]   I think lambda is what a lot of people use for echo, right? If you're doing an echo task, you put it up on lambda
[00:38:06.160 --> 00:38:08.480]   It is yeah
[00:38:08.480 --> 00:38:14.160]   And it could be so that's so that's I think probably it's most common use as if you're using some other amazon service
[00:38:14.160 --> 00:38:17.040]   You leave you put code up on lambda that's triggered
[00:38:17.040 --> 00:38:22.880]   Like by well, it's great for iot stuff right because a lot of it's uh
[00:38:22.880 --> 00:38:29.760]   Trigger-based right and so it just goes in instead of running so they're constantly which is expensive right you only just go use yeah
[00:38:30.000 --> 00:38:35.680]   Yeah, so it's really great for again iot stuff or anything that's react
[00:38:35.680 --> 00:38:39.120]   Well and for somebody like me who wants to do a an echo skill
[00:38:39.120 --> 00:38:42.240]   If I don't make it public it's cheap
[00:38:42.240 --> 00:38:45.280]   Because I just pay for I don't have to run a server to do it
[00:38:45.280 --> 00:38:47.040]   I just put it up on lambda
[00:38:47.040 --> 00:38:50.720]   And then I only pay for the microseconds that I use when it when it hears my trigger
[00:38:50.720 --> 00:38:54.480]   So it's really great way to kind of prototype stuff for iot
[00:38:54.480 --> 00:38:59.200]   And it scales so if you decide you want to make it a public thing, you know, you can you don't have to do anything
[00:38:59.680 --> 00:39:01.200]   It'll scale
[00:39:01.200 --> 00:39:03.200]   So that's lambda. How did that come up? I forgot
[00:39:03.200 --> 00:39:08.640]   Oh, because I was saying I didn't think google had anything that was equivalent. Yeah, all right
[00:39:08.640 --> 00:39:13.280]   And I think that's a very big kind of forthcoming
[00:39:13.280 --> 00:39:17.040]   model of using the cloud, but
[00:39:17.040 --> 00:39:21.280]   I would love it if anyone in the chat room knows if google has an equivalent because
[00:39:21.280 --> 00:39:24.480]   I have missed that. I think azure has something
[00:39:24.480 --> 00:39:27.840]   but
[00:39:29.200 --> 00:39:35.360]   Was google code? I was it similar? This is where we miss jina. She knows yes google has quietly launched
[00:39:35.360 --> 00:39:39.520]   Its answer to a ws lambda. This is a story from
[00:39:39.520 --> 00:39:42.480]   a year ago. Yeah
[00:39:42.480 --> 00:39:46.320]   Google cloud functions
[00:39:46.320 --> 00:39:51.200]   Is a lightweight event based ache synchronous commute solution
[00:39:51.200 --> 00:39:57.840]   Compute solution that allows you to create small single-purpose functions that respond to cloud events. Yeah, that's exactly what lambda does
[00:39:58.640 --> 00:40:04.400]   Mm-hmm. I don't know. It's an alpha or it was an alpha and then azure app service
[00:40:04.400 --> 00:40:06.160]   Listen, it says is the same thing
[00:40:06.160 --> 00:40:09.360]   Yes, yeah, go oh
[00:40:09.360 --> 00:40:14.400]   Oh, it's still alpha function. Look at that cheapest. What's that mean?
[00:40:14.400 --> 00:40:20.800]   Alpha as opposed to pre beta so it's very early you have to be yeah, it says
[00:40:20.800 --> 00:40:27.680]   This feature might be changed in backwards incompatible ways and is not recommended for production use is it's not subject to any SLA or do
[00:40:27.680 --> 00:40:30.560]   Don't do policy so we can't promise you anything
[00:40:30.560 --> 00:40:35.440]   So yeah, this is this is for playing only yeah
[00:40:35.440 --> 00:40:41.280]   All right, so i'm gonna still say they don't have it then because this does not feel like a real thing
[00:40:41.280 --> 00:40:45.040]   I mean it's a real thing, but there's also something called iron
[00:40:45.040 --> 00:40:47.680]   dot IO
[00:40:47.680 --> 00:40:50.800]   This is a third party open source serverless computing
[00:40:50.800 --> 00:40:54.080]   similar idea
[00:40:55.840 --> 00:40:56.960]   Huh?
[00:40:56.960 --> 00:40:59.440]   Anyway, I I'm not up on all this stuff
[00:40:59.440 --> 00:41:03.680]   But I guess there's plenty of ways to do it google is kind of the laggard in that regard
[00:41:03.680 --> 00:41:09.120]   Google assistant and amazon's Alexa clashed at mobile world congress. I missed this
[00:41:09.120 --> 00:41:12.480]   the battle I did too
[00:41:12.480 --> 00:41:19.120]   I was like I thought it was more notable that uh, they both went down for a little bit and had some drama this week
[00:41:19.120 --> 00:41:22.400]   But this is there is nothing to talk about. Let me take a break you guys fine
[00:41:22.800 --> 00:41:26.080]   You guys i've been trying to add a few things i've added things to the rundown please okay
[00:41:26.080 --> 00:41:29.280]   I'm gonna go to you in a moment, but we're gonna take a break and talk about it. Oh, does any good
[00:41:29.280 --> 00:41:33.840]   I just know you're gonna have stuff. I feel desperate some days, you know, some days you come in and there's just nothing to talk about
[00:41:33.840 --> 00:41:35.920]   Yeah, you're right and we should chat
[00:41:35.920 --> 00:41:40.720]   I can I can bring out your life. Okay. We'll talk about these things
[00:41:40.720 --> 00:41:43.600]   We'll talk about jeff's tacky cardia
[00:41:43.600 --> 00:41:47.040]   And uh tacky tacky tacky
[00:41:47.040 --> 00:41:50.080]   I remember british friend of mine somebody when I had one of these episodes here's a girl
[00:41:50.080 --> 00:41:56.400]   You have a dickie ticker a dickie ticker a dickie ticker. I like it. I say i'm a dickie ticker
[00:41:56.400 --> 00:42:04.880]   Our show today brought to you by legal zoom legal zoom is awesome. It's national small business month
[00:42:04.880 --> 00:42:09.920]   And every month in march legal zoom does something to celebrate because legal zoom
[00:42:09.920 --> 00:42:17.120]   Is the place you start your small business place? I started got our uh our chapter what would know where llc got our llc papers there
[00:42:17.120 --> 00:42:19.440]   trade marks through legal zoom
[00:42:19.840 --> 00:42:23.520]   Approval rates for business loans are up. It's a good time. So is consumer confidence
[00:42:23.520 --> 00:42:28.640]   So now is a good time to launch a successful business, but it takes more than just good timing
[00:42:28.640 --> 00:42:34.080]   It takes legal zoom and they're free business startup kit. You got to take advantage of this
[00:42:34.080 --> 00:42:38.880]   Part of being an entrepreneur is utilizing the right resources to help you succeed
[00:42:38.880 --> 00:42:42.080]   You aren't an expert at everything, but
[00:42:42.080 --> 00:42:47.120]   Fortunately, they're great people to help you you could focus on what you do on your vision
[00:42:48.880 --> 00:42:50.000]   and uh
[00:42:50.000 --> 00:42:53.600]   Download your free startup kit today educational ebooks legal zoom discounts
[00:42:53.600 --> 00:42:55.760]   I'll help you save money setting up your business
[00:42:55.760 --> 00:43:00.880]   You could actually save thousands of dollars through legal zoom's partner offers to help with financing marketing
[00:43:00.880 --> 00:43:04.080]   Day-to-day operations things you'll need for a successful business
[00:43:04.080 --> 00:43:07.520]   And there's no obligation. It's just free. They're going to send it to you
[00:43:07.520 --> 00:43:12.560]   Legal zoom it's not a law firm, but they are dedicated to making life easier for business owners
[00:43:12.560 --> 00:43:15.040]   By providing you the services you need
[00:43:15.520 --> 00:43:20.000]   To get your business up and running whether you're thinking of starting a business or you already run one
[00:43:20.000 --> 00:43:24.480]   Everybody's a startup these days go to legal zoom.com slash startup
[00:43:24.480 --> 00:43:33.280]   Celebrate national small business month with them and get your free business startup kit put twig at the uh checkout for special savings
[00:43:33.280 --> 00:43:36.480]   twig
[00:43:36.480 --> 00:43:37.840]   startup
[00:43:37.840 --> 00:43:43.200]   Thank legal zoom for their support and now 12 years in for the help they gave me
[00:43:43.360 --> 00:43:47.600]   I know nothing I knew nothing then about business. Actually, I still know nothing about business
[00:43:47.600 --> 00:43:53.680]   But you can fake it better now. I can fake it much better. I've surrounded myself with people who do but back when it was just me
[00:43:53.680 --> 00:44:01.520]   Who to call? Yeah, I knew honey honey. Now. I just I just roll over and say hey. What's all this about? Uh gap
[00:44:01.520 --> 00:44:04.720]   Ept did uh, Eptida Eptida
[00:44:04.720 --> 00:44:07.760]   Ebita Ebita
[00:44:07.760 --> 00:44:11.200]   And she says again
[00:44:11.200 --> 00:44:13.200]   Again, you want to know?
[00:44:13.200 --> 00:44:17.360]   I just read something that uh some huge percentage of silicon valley
[00:44:17.360 --> 00:44:22.480]   Does some sort of non gap accounting like that's become
[00:44:22.480 --> 00:44:29.760]   So prevalent in silicon valley. I'm assuming I find that story. I just saw it ran across it in
[00:44:29.760 --> 00:44:37.520]   And and and by the way the SEC is not happy from today SEC wants to crack down on screwball accounting
[00:44:39.040 --> 00:44:42.400]   Oh, well. Yeah, I should I maintain that
[00:44:42.400 --> 00:44:51.440]   too many ads the SEC should be looking at what happens with better data analytics and what that means for accounting and understanding like if you can predict
[00:44:51.440 --> 00:44:56.640]   Material information based on machine learning. Oh, how does that change how you do your accounting?
[00:44:56.640 --> 00:45:01.280]   Because like think about things like predictive maintenance in industrial settings, right?
[00:45:01.280 --> 00:45:08.320]   Yeah, suddenly you don't have to suddenly your depreciation schedules for example become far more accurate
[00:45:09.120 --> 00:45:16.160]   and you might be able to predict like you maybe you allocated a capital expenditures budget based on just
[00:45:16.160 --> 00:45:22.720]   Those reputation tables, right? But if you can actually know what's going to break in the next, you know
[00:45:22.720 --> 00:45:27.680]   Quarter you can be a lot better at that like guessing that so
[00:45:27.680 --> 00:45:31.760]   I think there's a lot of interesting kind of things to look forward to from a
[00:45:31.760 --> 00:45:34.640]   From an accounting and actuarial perspective
[00:45:35.040 --> 00:45:39.120]   Well, of course the complaint the complaint of the SEC and of others is that
[00:45:39.120 --> 00:45:44.400]   Companies are using this adjusted, you know non generally accepted accounting practice earnings
[00:45:44.400 --> 00:45:50.160]   Uh because it inflates the earnings it makes them look better because they're not including stock compensation
[00:45:50.160 --> 00:45:53.680]   and and and you know so you
[00:45:53.680 --> 00:45:55.760]   I guess
[00:45:55.760 --> 00:45:58.480]   If you're investing you want to be sophisticated enough to know the difference
[00:45:58.480 --> 00:46:02.720]   and and and consider the difference accordingly but
[00:46:03.840 --> 00:46:07.600]   Um actually this SEC begins to crack down story was from a year ago
[00:46:07.600 --> 00:46:09.760]   Did they?
[00:46:09.760 --> 00:46:11.760]   No
[00:46:11.760 --> 00:46:16.240]   Google stuff that's pretty cool. All right google stuff
[00:46:16.240 --> 00:46:18.640]   If we want to do this google stuff put it in the list
[00:46:18.640 --> 00:46:25.280]   Google can now recognize objects and videos using machine learning and this apparently happened today at their
[00:46:25.280 --> 00:46:30.000]   cloud event. It was in is it fefe fefe leese? Yeah
[00:46:30.960 --> 00:46:35.600]   So it was in her speech and uh did I put the link in is this kind of like
[00:46:35.600 --> 00:46:39.200]   Yes, they can recognize tumors and tigers
[00:46:39.200 --> 00:46:47.760]   Um, it is it looks like they could recognize dachshunds from and the fact that the video is watching as a commercial. Oh, which
[00:46:47.760 --> 00:46:53.520]   So again, I don't think they're going to make the api available to developers
[00:46:53.520 --> 00:47:00.480]   But this is actually a really big deal because there's so much video content and you know if you don't tag it properly
[00:47:00.960 --> 00:47:07.040]   You really have no freaking clues. So think about all those billions of hours of youtube and making that searchable. Oh
[00:47:07.040 --> 00:47:10.960]   All right, good one
[00:47:10.960 --> 00:47:15.680]   I like it. Hey, I'm like does anyone else want to talk about that or say anything?
[00:47:15.680 --> 00:47:19.040]   I don't think you're gonna want to talk about this is weird
[00:47:19.040 --> 00:47:22.080]   giga-ohm ai labs
[00:47:22.080 --> 00:47:28.080]   I couldn't miss this consulting. What are they now? So giga-ohm was sold for parts, right?
[00:47:28.800 --> 00:47:30.800]   Right who owns giga-ohm?
[00:47:30.800 --> 00:47:38.000]   So the oh look at that. So, um, yes a man named biron reese who is from
[00:47:38.000 --> 00:47:40.400]   demand media
[00:47:40.400 --> 00:47:44.240]   And he wrote a book. He's a futurist. He's a very nice man
[00:47:44.240 --> 00:47:48.800]   Um, and it probably didn't pay a lot of the media wasn't so nice, but keep going
[00:47:48.800 --> 00:47:52.400]   The concept of demand media. Yeah. Oh, yeah
[00:47:52.400 --> 00:47:56.800]   The idea of whatever happened to that jeff we used to talk a lot about that with the idea you don't want to talk about that
[00:47:56.800 --> 00:48:00.320]   You should write on you want to have a articles that toured to the search
[00:48:00.320 --> 00:48:07.040]   Results, you know exactly what happened to it matt matt constant panda. Yeah right on oh people still do it though
[00:48:07.040 --> 00:48:12.240]   I mean like it was a big business time is the super bowl on yeah. Yeah, that's true
[00:48:12.240 --> 00:48:18.800]   Yeah, if you google that you find a lot of pages. That's uh, yeah, they changed the name of it. I mean is it now leaf group?
[00:48:18.800 --> 00:48:21.440]   No, oh, I don't know
[00:48:21.440 --> 00:48:24.960]   So, uh, okay, so this is interesting. So this is basically biron
[00:48:26.240 --> 00:48:30.400]   So biron is trying to figure out what to do with this amazing brand that he bought
[00:48:30.400 --> 00:48:32.560]   um
[00:48:32.560 --> 00:48:34.080]   and
[00:48:34.080 --> 00:48:37.120]   I think he's he thought he would be a publisher
[00:48:37.120 --> 00:48:39.760]   and
[00:48:39.760 --> 00:48:42.800]   He didn't really understand the economics or the
[00:48:42.800 --> 00:48:48.800]   the business of being a content like a real content company not like a demand sucks doesn't it
[00:48:48.800 --> 00:48:51.440]   it does
[00:48:51.440 --> 00:48:58.880]   So I think that and then he sold research and then that person who did the research business with him kind of left
[00:48:58.880 --> 00:49:03.840]   And now they're doing conference businesses and now there's no he's offering AI services
[00:49:03.840 --> 00:49:09.520]   Although perhaps to anyone who talks about clawed chanon who is just freaking off
[00:49:09.520 --> 00:49:14.320]   It's in the open 1949 dr clawed chan of mit build on a computer that could play chess
[00:49:14.320 --> 00:49:19.200]   Sure, it could only handle six pieces of required 15 seconds to make a move, but it played chess
[00:49:19.920 --> 00:49:21.840]   I
[00:49:21.840 --> 00:49:26.800]   Think this is actually smart. I mean birens probably you know right that there's going to be demand
[00:49:26.800 --> 00:49:34.880]   for uh help with a you know, a lot of companies could probably benefit this is big data, right? This is business intelligence
[00:49:34.880 --> 00:49:38.240]   to the next level
[00:49:38.240 --> 00:49:41.760]   Yeah, it's like it's a consulting agency for the sort of thing and actually I think
[00:49:41.760 --> 00:49:45.680]   IBM was talking about doing something like this with Watson kind of
[00:49:46.480 --> 00:49:52.560]   back a couple years ago with kind of how to apply Watson to the legal profession because
[00:49:52.560 --> 00:49:58.080]   I think there is in this this is a business idea if anyone wants to run with it, but
[00:49:58.080 --> 00:50:03.920]   There are so many tools out there that right now use AI to make your life more efficient
[00:50:03.920 --> 00:50:08.480]   And it's really hard to understand which ones might work for you and which don't
[00:50:08.480 --> 00:50:16.320]   And so I think a way to like show people how to build those tools or how to put those tools to use in their
[00:50:17.200 --> 00:50:19.200]   real life would be really
[00:50:19.200 --> 00:50:23.920]   an interesting opportunity like on the published excited I can see a newsletter for
[00:50:23.920 --> 00:50:26.080]   you know
[00:50:26.080 --> 00:50:32.240]   the six awesome tools i'm using this week to understand scheduling or to make my calendar more manageable. I don't know
[00:50:32.240 --> 00:50:39.360]   I'm not going to do that though. So to get back to fefe lee's uh cloud video intelligence api
[00:50:39.360 --> 00:50:45.360]   It's private beta, but eventually it will allow developers to query video content
[00:50:46.320 --> 00:50:52.880]   Using words to describe objects in the video like did you see a tiger in that video?
[00:50:52.880 --> 00:50:58.720]   You know, this has always been a problem with video and podcast audio as well. It's not searchable
[00:50:58.720 --> 00:51:02.560]   So something that would help you search through video
[00:51:02.560 --> 00:51:08.400]   And say i'd like to be with the words for lee's but the images weren't now you can do that and you have google
[00:51:08.400 --> 00:51:10.720]   searches become so
[00:51:10.720 --> 00:51:12.720]   popular right now
[00:51:13.840 --> 00:51:17.120]   Amazon did something similar last year called a recognition with a k
[00:51:17.120 --> 00:51:22.640]   Why it's just a race between these companies. I think that's good though the kind of competition you're seeing means
[00:51:22.640 --> 00:51:25.600]   faster development for this uh this kind of stuff
[00:51:25.600 --> 00:51:29.760]   Until it breaks until it breaks us
[00:51:29.760 --> 00:51:33.440]   Till the humans
[00:51:33.440 --> 00:51:37.760]   Say i don't get it ibm says we're we're gonna be able to build quantum computers
[00:51:37.760 --> 00:51:42.400]   So i saw that that was so exciting so you better uh you better get developing
[00:51:43.200 --> 00:51:44.720]   What
[00:51:44.720 --> 00:51:46.560]   really
[00:51:46.560 --> 00:51:51.440]   The company set up a new division ibm q that is intended to make quantum computers
[00:51:51.440 --> 00:51:54.240]   and sell them
[00:51:54.240 --> 00:51:58.800]   commercially ibm says we're close enough to start work on getting software ready
[00:51:58.800 --> 00:52:01.200]   How close is that?
[00:52:01.200 --> 00:52:03.200]   well, they didn't really say but
[00:52:03.200 --> 00:52:08.560]   uh most researchers agree that quantum computers which are still theoretical are years away from actually
[00:52:08.560 --> 00:52:11.360]   being made
[00:52:11.760 --> 00:52:13.760]   That's a scary thing because these computers are uh
[00:52:13.760 --> 00:52:22.000]   A lot faster fast enough so there's been some concern about uh public key crypto and uh, it's robustness in the face of
[00:52:22.000 --> 00:52:24.640]   Quantum pushing yeah
[00:52:24.640 --> 00:52:27.040]   Especially what does that do to watson's law?
[00:52:27.040 --> 00:52:30.880]   To watson's law
[00:52:30.880 --> 00:52:34.720]   I mean the uh no i mean more is not more is more is more is more is more
[00:52:34.720 --> 00:52:39.600]   Yeah, no, it's one attempt to get uh to get past mors law. Yeah
[00:52:40.400 --> 00:52:44.320]   Whereas we thought mors law was gonna die it it leaves past it
[00:52:44.320 --> 00:52:52.880]   Yeah, it's like it it's a different thing. It's a parallel track. So it leave frogs mors law. Yeah, but in terms of the impact on
[00:52:52.880 --> 00:52:56.000]   society
[00:52:56.000 --> 00:52:58.000]   well, so
[00:52:58.000 --> 00:53:00.800]   Right now the way like quantum computing right now is
[00:53:00.800 --> 00:53:05.360]   It's unreliable the computing itself happens in these massive
[00:53:07.120 --> 00:53:10.960]   Energy-consuming boxes that have to be super cool. That's why it doesn't really reply to mors
[00:53:10.960 --> 00:53:15.920]   Look as mors law was that the number of transistors in a processor would double every 18 months
[00:53:15.920 --> 00:53:21.440]   Number of transistors in a processor were double there are no transistors in quantum computing. No, that's what i'm saying
[00:53:21.440 --> 00:53:24.000]   But there's a few bits
[00:53:24.000 --> 00:53:31.120]   So yeah, they're cubits. So there's a computational capability. Uh, that's interesting. That's what's what's the relative computational?
[00:53:31.120 --> 00:53:35.040]   I don't know. I don't know if you if you look at things like uh encryption
[00:53:35.440 --> 00:53:40.320]   What does this do to that? Well, everybody's very concerned that quantum computing is the kind of thing that could
[00:53:40.320 --> 00:53:44.160]   rapidly cause problems in public e-crypto. Yeah
[00:53:44.160 --> 00:53:48.800]   So it's it's definitely a lot faster. I don't know how much faster. I don't know if it's an I don't know
[00:53:48.800 --> 00:53:55.680]   Uh, that's a question type of programming right? It's not with zeros and ones. It's not right. It's multi
[00:53:55.680 --> 00:53:59.360]   Multi it's cubits multi cubits it's cubits
[00:53:59.360 --> 00:54:03.440]   And we're all like we'll say that word like we know what it means
[00:54:04.240 --> 00:54:08.880]   So is there are one of the languages around quantum computing? They don't have them
[00:54:08.880 --> 00:54:12.240]   What's that's there telling you to get development? God damn it
[00:54:12.240 --> 00:54:16.720]   Um, what so that's what they want to see
[00:54:16.720 --> 00:54:18.800]   Um
[00:54:18.800 --> 00:54:21.920]   So you have to do quantum based algorithms
[00:54:21.920 --> 00:54:28.080]   So that function in the so I don't think you're developing languages yet. You're really at a smaller
[00:54:28.080 --> 00:54:30.560]   Earlier level of process where you're
[00:54:30.560 --> 00:54:34.480]   2cl is one of the first implemented quantum or broken languages
[00:54:34.480 --> 00:54:37.440]   Oh, there you go
[00:54:37.440 --> 00:54:41.040]   But allow the expression of quantum algorithms using high level constructs
[00:54:41.040 --> 00:54:45.840]   Not so much as two year for programmers
[00:54:45.840 --> 00:54:49.760]   But to provide tools for researchers to understand better how quantum computation works
[00:54:49.760 --> 00:54:52.800]   And how to reason formerly with about quantum algorithms
[00:54:52.800 --> 00:54:56.080]   But thank you Wikipedia
[00:54:59.680 --> 00:55:04.320]   There are two kinds of imperative and functional quantum programming languages
[00:55:04.320 --> 00:55:07.600]   Well, I'm I'm all for functional quantum
[00:55:07.600 --> 00:55:11.680]   Yeah, that's me. This is so out of my uh, not being
[00:55:11.680 --> 00:55:17.360]   This way past my my my skill set here. I don't I mean i'm reading so google
[00:55:17.360 --> 00:55:23.680]   Google purchased a quantum computer um from dewave um google and
[00:55:23.680 --> 00:55:28.880]   Is a competing quantum computer company that has been doing this for like
[00:55:29.360 --> 00:55:32.080]   Like 15 or 20 years. It is ridiculously long
[00:55:32.080 --> 00:55:37.920]   um in dewave and ibm have this whole like quantum computing argument in like
[00:55:37.920 --> 00:55:42.560]   Research papers like where they call it. It's big drama
[00:55:42.560 --> 00:55:45.680]   Um, oh nasa and google are working
[00:55:45.680 --> 00:55:49.920]   Um, but I think lachied martin then has bought their own computer
[00:55:49.920 --> 00:55:52.400]   um quantum computer too. So
[00:55:52.400 --> 00:55:57.200]   um, and I think it was a 50 qubit computer. So this is
[00:55:57.920 --> 00:55:59.040]   Wow
[00:55:59.040 --> 00:56:01.680]   an effort to be commercial and like dewaves
[00:56:01.680 --> 00:56:04.640]   How many qubits?
[00:56:04.640 --> 00:56:08.080]   Well
[00:56:08.080 --> 00:56:11.040]   These days certainly
[00:56:11.040 --> 00:56:14.240]   I think that's for damn sure
[00:56:14.240 --> 00:56:19.440]   The story one of the stories I saw it was the paper in nature on ibm's effort
[00:56:19.440 --> 00:56:24.400]   This was saying I think five qubits a machine that has five qubits
[00:56:24.400 --> 00:56:26.240]   is
[00:56:26.240 --> 00:56:30.240]   Hold on the equivalent of qubits. I don't feel like they're equivalent in it
[00:56:30.240 --> 00:56:35.840]   You know, I feel I don't know. I mean the the fundamental question would be you know, okay if we're going to calculate this
[00:56:35.840 --> 00:56:38.480]   How much faster would it do it than a traditional?
[00:56:38.480 --> 00:56:45.520]   Turing machine. I think it also is that it it's faster, but it also can calculate different types of problems. Yeah. Yeah
[00:56:45.520 --> 00:56:49.840]   I don't know. I've actually poo pooed this for a long time. I I'm I don't know
[00:56:49.840 --> 00:56:54.720]   I don't know what this story means is are they have they are can they make them in quantity?
[00:56:55.520 --> 00:57:00.800]   I don't know. Do you need to make them in quantity? That's the other thing because some people think they make one for the nsa and the rest
[00:57:00.800 --> 00:57:06.080]   Well, it is kind of like does this mean the I don't think it really means the end of computers
[00:57:06.080 --> 00:57:12.560]   Like kind of like was it Bill Gates and his statement about all you're going to need is some kind of hard drive? I don't remember
[00:57:12.560 --> 00:57:19.920]   Here's uh, here's what ibm says classical computers are extraordinarily powerful will continue advance and underpin everything we do in business
[00:57:19.920 --> 00:57:24.960]   And society, but there are many problems that will never be penetrated by a classical computer
[00:57:25.840 --> 00:57:29.920]   To create knowledge for much greater depth of complexity. We need a quantum computer
[00:57:29.920 --> 00:57:37.040]   We envision ibmq systems working in concert with our portfolio of classical high-performance systems to address problems that are currently unsolvable
[00:57:37.040 --> 00:57:40.560]   But hold tremendous untapped value. I guess with big data
[00:57:40.560 --> 00:57:47.600]   Big giant data sets. There's all sorts of stuff that the traditional computer just can't think like climate change simulations
[00:57:47.600 --> 00:57:50.800]   Monte Carlo right those kind of things maybe
[00:57:51.200 --> 00:57:57.040]   We move from an age. I think this is this is true of journalism. I think it's how the show before where we're in journalism we're reductive
[00:57:57.040 --> 00:58:00.800]   We reduce everything to an 800 word article. We can take any complexity and break it down
[00:58:00.800 --> 00:58:04.160]   But the the truth of the world was highly complex
[00:58:04.160 --> 00:58:06.880]   and now you have systems to be able to
[00:58:06.880 --> 00:58:11.520]   Map and analyze and present that complexity and we have no idea. We're gonna do that
[00:58:11.520 --> 00:58:16.160]   I agree that was a short
[00:58:16.160 --> 00:58:18.720]   I agree
[00:58:19.360 --> 00:58:23.200]   I got a story. I got a story that's right up stacy zally
[00:58:23.200 --> 00:58:26.320]   We're talking about nest when we come back. Oh a little bit
[00:58:26.320 --> 00:58:27.120]   Yay
[00:58:27.120 --> 00:58:28.640]   Yeah, because some big nest news
[00:58:28.640 --> 00:58:34.800]   But first a word from rocket mortgage by quick and loans when it comes time to buy or refi your home
[00:58:34.800 --> 00:58:38.080]   You're gonna want a mortgage lender that you trust
[00:58:38.080 --> 00:58:42.640]   A quality mortgage lender. I would submit the quick and loans is the best just look at all their
[00:58:42.640 --> 00:58:47.200]   Their tops and customer satisfaction year after year after year after year
[00:58:48.080 --> 00:58:52.800]   uh, and they're one of the biggest lenders in the country. I think 92 billion dollars in loans last year, but
[00:58:52.800 --> 00:58:56.960]   More than that they they understand and love the geek because they've created
[00:58:56.960 --> 00:59:00.960]   A mortgage approval process is entirely online
[00:59:00.960 --> 00:59:08.160]   You what you don't have to go to a bank. You don't have to collect papers. You don't have to go through the boxes of
[00:59:08.160 --> 00:59:14.640]   Documents you just do it all on your phone on your tablet. It's a transparent online process
[00:59:15.520 --> 00:59:21.120]   That gives you all the information you need. That's what the internet is all about. You can adjust the rate and length of your loan in real time
[00:59:21.120 --> 00:59:26.640]   You could submit the paperwork they need like pay stubs and uh bank statements
[00:59:26.640 --> 00:59:28.880]   online
[00:59:28.880 --> 00:59:36.480]   And because it's all online it's fast you get to turn around in minutes for a loan that's exactly right for your financial situation
[00:59:36.480 --> 00:59:42.000]   You got to check it out skip the bank skip the waiting go completely online quick and loans
[00:59:42.560 --> 00:59:46.800]   Dot com slash twig for rocket mortgage quick at loans dot cop slash twig
[00:59:46.800 --> 00:59:53.200]   Equal housing lender licensed in all 50 states nmls consumer access dot org number 30 30 quick and loans
[00:59:53.200 --> 00:59:57.280]   Dot com slash twig and we thank them for their support of this week in
[00:59:57.280 --> 00:59:59.840]   cool
[00:59:59.840 --> 01:00:02.080]   Have you seen pulse what's pulse? Sorry?
[01:00:02.080 --> 01:00:09.440]   Twitch released a uh competitor. Oh, they're doing twitcher. Yeah. Yeah, they're doing but I think it's for twitch people
[01:00:10.000 --> 01:00:15.600]   Alien side twitch. Okay. Yeah, so it's uh, yeah, I saw that. I don't know if we wouldn't use it
[01:00:15.600 --> 01:00:17.600]   We don't even use the twitch chat
[01:00:17.600 --> 01:00:19.920]   we put we point people to our own chat
[01:00:19.920 --> 01:00:22.240]   but
[01:00:22.240 --> 01:00:26.400]   Understand who uses twitch and how it's mostly uses, you know, I'm playing a game
[01:00:26.400 --> 01:00:29.280]   Showing you a video of the game. I've got a chat room. I'm talking to you
[01:00:29.280 --> 01:00:34.080]   I'd like to keep my engagement going offline when I'm not playing a game. Is that what it's for? Okay. Thank you
[01:00:34.080 --> 01:00:36.960]   Got it
[01:00:36.960 --> 01:00:42.400]   By the way, they're brilliant. I know they're they're they're doing a really I think
[01:00:42.400 --> 01:00:45.520]   knocking out of the park
[01:00:45.520 --> 01:00:47.840]   And they're owned by uh, amazon, right?
[01:00:47.840 --> 01:00:49.600]   Yeah
[01:00:49.600 --> 01:00:53.120]   Amazing. Just in con who sold twitch we created justin
[01:00:53.120 --> 01:00:58.320]   Uh tv remember way back when oh boy. Everybody was crazy
[01:00:58.320 --> 01:01:00.880]   Yeah, I had a while on all the time
[01:01:00.880 --> 01:01:04.160]   And then that became just in tv and then he did social cam
[01:01:04.160 --> 01:01:09.600]   Which was a streaming app kind of a periscope before periscope and then he started twitch which is gaming
[01:01:09.600 --> 01:01:15.360]   Sold that to amazon. He's actually just launched his own startup incubator program called zero zero f
[01:01:15.360 --> 01:01:17.840]   Guy can't be more than 28
[01:01:17.840 --> 01:01:21.840]   Zero f is zero to funding
[01:01:21.840 --> 01:01:28.240]   And he was a partner y combinator. So he's decided to go the y combinator roof root
[01:01:28.240 --> 01:01:32.480]   He said I joined yc to recover from the brain damage of starting companies
[01:01:32.720 --> 01:01:36.320]   But I want to get back more towards what I like doing which is starting companies
[01:01:36.320 --> 01:01:39.840]   He has three companies already in his portfolio whale
[01:01:39.840 --> 01:01:43.040]   Which is a q&a video app
[01:01:43.040 --> 01:01:45.040]   the online pharmacy script dash
[01:01:45.040 --> 01:01:50.640]   And one he hasn't uh yet named that will revolutionize the way law firms work
[01:01:50.640 --> 01:01:54.640]   Interesting three new two or three new businesses a year. So it's not a big
[01:01:54.640 --> 01:01:57.360]   It's not a big startup school
[01:01:57.360 --> 01:01:59.760]   That's cool
[01:01:59.760 --> 01:02:01.760]   Now onto nest
[01:02:01.840 --> 01:02:05.280]   Yes, sorry. Yes. I caused it. I find this fascinating
[01:02:05.280 --> 01:02:08.320]   Uh, seven find it
[01:02:08.320 --> 01:02:09.440]   What?
[01:02:09.440 --> 01:02:14.960]   No, you go mark german who is the king of apple leaks has now apparently expanded his portfolio to cover
[01:02:14.960 --> 01:02:17.680]   Uh, iot is well
[01:02:17.680 --> 01:02:24.320]   He's got some rumors. He says that they're looking at a cheaper nest model under 200 dollars
[01:02:24.320 --> 01:02:27.840]   Uh that would also allow you to adjust
[01:02:27.840 --> 01:02:29.920]   uh
[01:02:29.920 --> 01:02:34.160]   It's a temperature on a room by room basis kind of like what is the one that does that?
[01:02:34.160 --> 01:02:39.280]   Well, okay, so ecobi right that ecobi has a light which is cheaper
[01:02:39.280 --> 01:02:43.360]   It doesn't have the external sensor the expensive ecobi has an external sensor
[01:02:43.360 --> 01:02:44.640]   Right you could put a
[01:02:44.640 --> 01:02:47.120]   Sensor in your bedroom and have the thermostat in the hall
[01:02:47.120 --> 01:02:50.720]   Which is our problem because our thermostat's in the hall it measures the hall temperature
[01:02:50.720 --> 01:02:53.680]   Which is a lot cooler than our bedrooms are better them over heats
[01:02:53.680 --> 01:02:56.800]   I don't think nest fixes. I don't
[01:02:56.960 --> 01:02:59.360]   I don't know reading this article. It's unclear
[01:02:59.360 --> 01:03:03.280]   if the remote sensors are for
[01:03:03.280 --> 01:03:11.040]   The cheaper thermostats or if they're just remote sensors. Okay. No, I just I was kind of like, I don't know if that's the same
[01:03:11.040 --> 01:03:14.800]   They're also looking at a home security alarm system
[01:03:14.800 --> 01:03:17.360]   a digital doorbell
[01:03:17.360 --> 01:03:20.800]   To compete with a ring and an updated indoor security camera
[01:03:20.800 --> 01:03:25.120]   Nest has so that has been so slow to release new stuff. Whoa
[01:03:26.400 --> 01:03:30.720]   Well, they they were apparently I mean, well, there was a lot of infighting there
[01:03:30.720 --> 01:03:36.400]   There was a lot of drama happening there. Yes, honestly these these feel like super derivative
[01:03:36.400 --> 01:03:37.760]   they feel like
[01:03:37.760 --> 01:03:40.720]   Tony Fadel would not stand for this because
[01:03:40.720 --> 01:03:43.920]   God, there's
[01:03:43.920 --> 01:03:48.560]   Do I really need another home security smart hub? I don't I really don't and
[01:03:48.560 --> 01:03:51.280]   Is the industry clamoring for this?
[01:03:52.640 --> 01:03:56.320]   I don't think they are I really like I look at this and I'm like
[01:03:56.320 --> 01:04:00.240]   Where is the amazon echo? Where's the surprise make my
[01:04:00.240 --> 01:04:06.400]   In maybe I'm just just being a person. So here's a question. I should I should point out by the way the information
[01:04:06.400 --> 01:04:13.760]   Said this exact same thing exactly one year ago on march 24th of last year for nest products still under wraps
[01:04:13.760 --> 01:04:17.040]   And yes, they're still under wraps
[01:04:17.760 --> 01:04:22.320]   So nest is having then they this was bluetooth tags wireless security sensors wireless hub
[01:04:22.320 --> 01:04:28.560]   And a voice recognition system. So you're right stacy. They're having a lot of trouble getting stuff out the door
[01:04:28.560 --> 01:04:32.560]   Yeah, all right. I mean bark ermin's right and
[01:04:32.560 --> 01:04:35.760]   And Jessica lessons right
[01:04:35.760 --> 01:04:38.560]   um
[01:04:38.560 --> 01:04:45.680]   Yeah, so I I'm not keen on this. They did also do to fit they launched two factor authentication on your I like that
[01:04:46.640 --> 01:04:53.200]   I we talked with mark rogers on monday. He's a hackers is security operations guy for def con
[01:04:53.200 --> 01:04:56.960]   Which must be the most interesting job in the world. He also is a security guy
[01:04:56.960 --> 01:05:03.840]   The security guy at cloud flare he said of all the iot devices. He was most impressed with it nest. He said those guys are doing it right
[01:05:03.840 --> 01:05:11.600]   They are I mean the and there's there's a lot of stuff they don't talk about because they don't want to but I could I have talked to them
[01:05:11.600 --> 01:05:14.560]   in depth on their security stuff and I can tell you that
[01:05:15.520 --> 01:05:18.960]   they they treat it right in the sense that they are always
[01:05:18.960 --> 01:05:23.360]   Security is an ongoing issue. They don't feel like it's ever done
[01:05:23.360 --> 01:05:29.120]   Right and they have got a lot of things in place on the back end that make me feel really good about having their stuff in my house
[01:05:29.120 --> 01:05:31.600]   so
[01:05:31.600 --> 01:05:33.040]   So let me ask you this
[01:05:33.040 --> 01:05:40.080]   I was thinking because there's another story in the rundown about how amazon is looking at building a new echo device that can act like an intercom and other things
[01:05:40.560 --> 01:05:43.120]   It's not let me think that we're going to end up with
[01:05:43.120 --> 01:05:48.080]   us every room in the house is going to have a set of sensors and input and output
[01:05:48.080 --> 01:05:50.240]   right
[01:05:50.240 --> 01:05:52.240]   And so is that become a
[01:05:52.240 --> 01:05:58.000]   Does somebody try to own all of that that your your your echo is going to have temperature sensors in it too and
[01:05:58.000 --> 01:06:01.280]   and and other output mechanisms or is it going to be
[01:06:01.280 --> 01:06:07.760]   10 different things how are we going to build houses in the future around that notion of input and output for every room
[01:06:09.280 --> 01:06:10.720]   so
[01:06:10.720 --> 01:06:14.240]   I wanted us to do this in I and many other people
[01:06:14.240 --> 01:06:15.440]   um
[01:06:15.440 --> 01:06:21.120]   Wanted to do this along the principles of kind of the open web right like you create hardware standards for these input outputs
[01:06:21.120 --> 01:06:26.480]   And sensors and kind of data standards. So you could pick your platform of choice where you
[01:06:26.480 --> 01:06:33.040]   Ran that data to to me that makes the most sense from a consumer and even from a business perspective
[01:06:33.040 --> 01:06:38.400]   If you're not one of the big platform players, what's actually happening is everybody wants to own
[01:06:39.040 --> 01:06:42.320]   the physical hardware and the data and mostly the data that it's
[01:06:42.320 --> 01:06:46.960]   Generating and they want to build services on top of that
[01:06:46.960 --> 01:06:48.960]   what's
[01:06:48.960 --> 01:06:53.600]   Kind of worth looking at is how many people can actually figure out how to monetize that because
[01:06:53.600 --> 01:06:59.760]   Consumers right now don't see a really compelling use case to pay for you know sensors in an
[01:06:59.760 --> 01:07:02.560]   every room and
[01:07:02.560 --> 01:07:07.440]   You know input output on their wall right one of one of the reasons why is you know
[01:07:07.680 --> 01:07:14.640]   It's it's new and we need to figure this out. So amazon's done a good job at like convincing people with like the echo that it can be worth it
[01:07:14.640 --> 01:07:16.000]   um
[01:07:16.000 --> 01:07:17.600]   But over the long term
[01:07:17.600 --> 01:07:20.400]   I really think if it doesn't follow the standards of the open web
[01:07:20.400 --> 01:07:23.040]   we're never going to get there because
[01:07:23.040 --> 01:07:26.880]   All of these things should belong to your house. They shouldn't belong to
[01:07:26.880 --> 01:07:31.920]   You as an individual because we we move right and so
[01:07:31.920 --> 01:07:37.520]   There's a fundamental kind of disconnect between how we're trying to monetize
[01:07:38.080 --> 01:07:41.120]   And thinking about it today and how we probably should be
[01:07:41.120 --> 01:07:45.040]   That's just me. I spent a lot of time thinking about this
[01:07:45.040 --> 01:07:48.320]   I feel like echo is in the best position to do all this in fact
[01:07:48.320 --> 01:07:54.720]   It doesn't surprise me that they want to do it here comes and all that because uh people who buy echoes tend to buy more of them all the time
[01:07:54.720 --> 01:07:58.240]   And they provide a voice in it. They've been smart about being open
[01:07:58.240 --> 01:08:02.000]   So they can provide a voice interface to a whole bunch of other stuff
[01:08:02.000 --> 01:08:05.040]   Like your harmony hub stacy or your nest
[01:08:05.600 --> 01:08:11.680]   Or your automatic in your car. I think I think it's amazing what amazon has done from in two years
[01:08:11.680 --> 01:08:15.760]   from zero to 60 because uh, you know, they they
[01:08:15.760 --> 01:08:23.680]   I guess because people fell in love with their echoes bought more echoes more echoes skills are created. What are they're 10 000 now?
[01:08:23.680 --> 01:08:26.880]   It's amazing. And so
[01:08:26.880 --> 01:08:29.920]   I think we have a de facto winner and it works quite well
[01:08:29.920 --> 01:08:33.600]   I love the idea of an intercom because I do have echoes in every room
[01:08:34.800 --> 01:08:39.440]   Uh, so you might have to buy a new one. Oh, I would like that. That's not good
[01:08:39.440 --> 01:08:42.480]   I'll give you a sneak peek. My podcast this week is
[01:08:42.480 --> 01:08:48.560]   You know, I think the episode's titled something like should I wait to buy a new amazon echo because interesting
[01:08:48.560 --> 01:08:51.280]   Couldn't do it with the current one
[01:08:51.280 --> 01:08:56.880]   Well, that's that's not what the rumor said and I so I was chasing down this rumor for
[01:08:56.880 --> 01:09:01.520]   A story. So I was kind of sad that that recode got it to it first damn there
[01:09:02.480 --> 01:09:04.480]   darn you and your good journalism and reporting
[01:09:04.480 --> 01:09:09.760]   Um, so my understanding from the reporting that I was doing is that this will be
[01:09:09.760 --> 01:09:12.800]   This will require some new
[01:09:12.800 --> 01:09:16.960]   There will be a new device that will have new hardware in it. What's unclear is
[01:09:16.960 --> 01:09:25.520]   If that hardware is required for all of those features or just some of them. I'm just thinking about this if the uh intercom
[01:09:25.520 --> 01:09:29.360]   Totally could be done in software
[01:09:29.360 --> 01:09:31.760]   You could say echo
[01:09:31.760 --> 01:09:33.760]   Speak to the bedroom
[01:09:33.760 --> 01:09:35.200]   boom
[01:09:35.200 --> 01:09:37.200]   Hey lisa, um
[01:09:37.200 --> 01:09:39.600]   Is my watch in there?
[01:09:39.600 --> 01:09:40.560]   boom
[01:09:40.560 --> 01:09:42.640]   Now there would be a delay it wouldn't be
[01:09:42.640 --> 01:09:46.160]   A real time back and forth. I don't think it could do that
[01:09:46.160 --> 01:09:49.280]   But I think it would then a second later play in the bedroom
[01:09:49.280 --> 01:09:54.080]   Hey lisa is my watch in there and she could go echo respond
[01:09:54.080 --> 01:09:57.040]   No, it's not
[01:09:57.040 --> 01:10:01.680]   And then I would hear it back. Oh, I see it as a conversation. It's like the airport thing where they were they yeah
[01:10:01.760 --> 01:10:07.280]   It's a paging system, but it but I think it would be real time enough that it would be more than adequate what you really want
[01:10:07.280 --> 01:10:13.520]   Boom echo tell the kids dinner's ready get down here now. Yes
[01:10:13.520 --> 01:10:17.360]   Well a little a little smarter, right?
[01:10:17.360 --> 01:10:21.440]   So so google home is looking at multiple people if if echo if there were a mechanism to
[01:10:21.440 --> 01:10:25.600]   Define who is in what room you don't have to say the bedroom you just say ask lisa
[01:10:25.600 --> 01:10:30.000]   Yeah, but that's a little trickier that would a little trickier, but again
[01:10:30.000 --> 01:10:32.960]   Does it wouldn't know where lisa is how it nowhere lisa is?
[01:10:32.960 --> 01:10:37.200]   Well, so what are the leaked images was an echo with the camera?
[01:10:37.200 --> 01:10:40.320]   Okay, you know what?
[01:10:40.320 --> 01:10:46.080]   No, I think it happened. I'm already hearing so much pina from people about echo
[01:10:46.080 --> 01:10:52.160]   Uh this new vault seven which we haven't talked about these new vault seven revelations people are
[01:10:52.160 --> 01:10:57.360]   Terrified and the and normal people it's really sunk into them
[01:10:58.080 --> 01:11:01.200]   That there's all like my samsung tv can listen to me
[01:11:01.200 --> 01:11:03.360]   It's got a camera
[01:11:03.360 --> 01:11:09.040]   Amazon's got to be very judicious. I think about how they roll out features like cameras. That's scary
[01:11:09.040 --> 01:11:14.080]   Well, this is this is a this is a photo of a leak and this is all rumors
[01:11:14.080 --> 01:11:18.400]   This is not anything I have heard yeah, and they may have prototyped it without I mean
[01:11:18.400 --> 01:11:22.720]   We see this a lot in apple world. You'll see prototypes of things that they may or may not release
[01:11:25.360 --> 01:11:28.400]   I love to get the intercom thing. That would be awesome
[01:11:28.400 --> 01:11:34.240]   I love the intercom. I love the ability to make phone calls. I would also say
[01:11:34.240 --> 01:11:35.760]   um
[01:11:35.760 --> 01:11:42.560]   You know, and here's what's cool is if the echo could actually talk to from a cloud to cloud with the sensors in my house
[01:11:42.560 --> 01:11:45.120]   That I would authenticate
[01:11:45.120 --> 01:11:47.360]   Then it could find the people in your room
[01:11:47.360 --> 01:11:49.280]   like
[01:11:49.280 --> 01:11:52.880]   They could do geolocation you all you already get a sort of
[01:11:54.640 --> 01:12:00.880]   Cobbled together version of that with like the euro because the euro skill and the echo where you ask where connected devices
[01:12:00.880 --> 01:12:03.760]   And it'll tell you which euro hub it's connected to
[01:12:03.760 --> 01:12:06.880]   So you can ask the echo
[01:12:06.880 --> 01:12:11.760]   To ask the euro where your phone is and it'll tell you your phone's connected to
[01:12:11.760 --> 01:12:15.840]   The hub in the router in this room, whatever you've named it
[01:12:15.840 --> 01:12:18.000]   Try this
[01:12:18.000 --> 01:12:19.280]   Hey echo
[01:12:19.280 --> 01:12:24.880]   Post the twit mission statement on the wall in the hall outside the studio
[01:12:24.880 --> 01:12:29.280]   Look it worked
[01:12:29.280 --> 01:12:32.080]   Why are they using a blowtorch to put that up there?
[01:12:32.080 --> 01:12:36.240]   That's go your new offices. That's that's scary. Wow
[01:12:36.240 --> 01:12:40.800]   What is the mission statement? Uh, I can't read it from here. Let me see
[01:12:40.800 --> 01:12:42.000]   You don't you don't have it
[01:12:42.000 --> 01:12:48.560]   You don't know your mission statement. I wrote it, but I don't remember twit is dedicated to building a highly engaged community of tech enthusiasts
[01:12:49.040 --> 01:12:53.600]   By offering the knowledge they need to understand and use technology today
[01:12:53.600 --> 01:12:55.680]   Is that okay?
[01:12:55.680 --> 01:12:59.840]   And blather about whatever they did. Well, please well, sometimes we don't have any knowledge to offer
[01:12:59.840 --> 01:13:07.360]   But I think in aggregate if you listen to a lot of twit shows
[01:13:07.360 --> 01:13:13.920]   You kind of that's the goal is to uh, is that how old is that mission statement? Oh, it's pretty old. I think I
[01:13:14.320 --> 01:13:19.200]   It's it's evolved slightly mostly in terms of cutting out extra clauses. You know mission statements
[01:13:19.200 --> 01:13:22.960]   Yeah clauses. I'm not I'm not a fan of writing them. They're they're paying right
[01:13:22.960 --> 01:13:26.640]   Yeah, but so I really wanted to boil it down to the most important things which there you got it
[01:13:26.640 --> 01:13:28.560]   You know developing a community
[01:13:28.560 --> 01:13:34.320]   We're aimed at tech enthusiasts and the way we serve them is giving them information to understand and use technology today
[01:13:34.320 --> 01:13:36.000]   And we heat that up
[01:13:36.000 --> 01:13:39.040]   Yeah, I guess uh, I don't know maybe those are I don't know that's weird. Isn't it?
[01:13:39.040 --> 01:13:40.960]   Yeah
[01:13:40.960 --> 01:13:44.480]   I can see in a in a in a month. They're gonna just kind of curl up and peel off
[01:13:44.480 --> 01:13:47.680]   after the apocalypse. I'll come in here
[01:13:47.680 --> 01:13:49.840]   in my uh
[01:13:49.840 --> 01:13:55.440]   My worn out shoes and torn t-shirt and I'll see that curling off the wall and say those are the days
[01:13:55.440 --> 01:13:58.320]   I remember
[01:13:58.320 --> 01:14:00.800]   So do you want to talk about vault seven?
[01:14:00.800 --> 01:14:07.360]   Yeah, what are here? What you have to say about this Ian Thompson, uh, did the work so we didn't have to he actually went through all
[01:14:07.920 --> 01:14:09.920]   thousand documents
[01:14:09.920 --> 01:14:15.840]   8,761 cia documents published yesterday on wicki leaks
[01:14:15.840 --> 01:14:18.640]   wicki leaks again
[01:14:18.640 --> 01:14:22.960]   While it's you know, there's it's hard to tell the provenance of these
[01:14:22.960 --> 01:14:26.720]   It seems highly unlikely that wicki leaks could have generated this much content
[01:14:26.720 --> 01:14:30.880]   Spritously, speciously, so it's probably real or something like it
[01:14:30.880 --> 01:14:37.600]   They were they were good enough not to include the exploits the actual code just the descriptions thereof
[01:14:37.920 --> 01:14:41.920]   Most of this like the snowed in revelations is several years old
[01:14:41.920 --> 01:14:45.440]   Uh, some of it was misreported initially for instance
[01:14:45.440 --> 01:14:51.840]   You might have seen that the cia can break signal. What's app and telegram encrypted messaging not so
[01:14:51.840 --> 01:14:59.120]   Um, uh, as Ian points out what it actually says is that the cia if they can compromise
[01:14:59.120 --> 01:15:05.040]   The device the computer the phone that's using signal or what's app or telegram
[01:15:05.280 --> 01:15:11.600]   They can get it before it's encrypted that does not say that they can decrypt it in transit. That's fairly important
[01:15:11.600 --> 01:15:13.840]   um
[01:15:13.840 --> 01:15:18.240]   So one of the things of course is that your samsung tv
[01:15:18.240 --> 01:15:22.480]   One particular model could be used to listen to you. They've got the
[01:15:22.480 --> 01:15:29.440]   The code to hack it and turn on a full-time speaker and microphone, which is funny because there was a big brew. Haha
[01:15:29.440 --> 01:15:32.800]   Samsung in its terms of service last year
[01:15:33.600 --> 01:15:37.200]   You know let slip in there. Oh and third parties could possibly be monitoring you
[01:15:37.200 --> 01:15:44.160]   So everybody and we we said oh, that's just boilerplate. That's not possible. Well, hmm
[01:15:44.160 --> 01:15:47.760]   Uh
[01:15:47.760 --> 01:15:52.240]   So edward snowden tweeted, uh yesterday still working through the publication
[01:15:52.240 --> 01:15:59.840]   But what wiki leaks has here is genuinely a big deal looks authentic. I guess edward would probably be a pretty good expert on that
[01:15:59.840 --> 01:16:02.720]   uh with regards to
[01:16:03.520 --> 01:16:05.520]   particular operating systems
[01:16:05.520 --> 01:16:11.360]   CIA has a modest collection of attack tools for systems powered by microsoft's windows
[01:16:11.360 --> 01:16:17.040]   keystroke loggers sandbox escape ropes anti virus avoidance mechanisms
[01:16:17.040 --> 01:16:20.160]   CIA analysts found flaws in control panel
[01:16:20.160 --> 01:16:27.280]   The ability to add data streams to ntfs without detection so you could put data onto storage drives
[01:16:27.280 --> 01:16:29.360]   um
[01:16:29.360 --> 01:16:32.320]   dll files a popular attack vector
[01:16:32.320 --> 01:16:35.760]   Uh, there's a program called ricky bobby
[01:16:35.760 --> 01:16:40.240]   Which is will ferals character in the movie taledaga nights
[01:16:40.240 --> 01:16:47.200]   It uses windows power shell and several dot net dll's to put a listening post on a target pc
[01:16:47.200 --> 01:16:52.880]   You know all of this you kind of expect they have the one big takeaway was how much more
[01:16:52.880 --> 01:16:57.280]   Humor in the code names the cia's stuff had
[01:16:57.920 --> 01:17:02.880]   Then, uh, then, uh, the nsa stuff like names like swamp monkey eggs mayhem
[01:17:02.880 --> 01:17:10.560]   Ricky bobby weeping angels. Yeah weeping angel. We liked that one. That's of course a doctor who reference
[01:17:10.560 --> 01:17:12.640]   I didn't know that but I was
[01:17:12.640 --> 01:17:14.080]   Informed
[01:17:14.080 --> 01:17:16.800]   lots of pages of hacking tools for os 10
[01:17:16.800 --> 01:17:22.160]   Including, uh at the time. What was the most recent version of os 10 of capitan? Of course
[01:17:22.160 --> 01:17:26.080]   This is this is an old dump. So uh presumably they've updated those
[01:17:26.400 --> 01:17:28.400]   There's a project called harpy eagle
[01:17:28.400 --> 01:17:35.360]   That analyzes the apple's airport extreme firmware for private keys and then cracks it also time capsule systems
[01:17:35.360 --> 01:17:37.360]   there's a
[01:17:37.360 --> 01:17:39.360]   Project called quark matter
[01:17:39.360 --> 01:17:47.600]   That puts persistent spyware on an os 10 system using an efi driver stored on the system efi system partition in other words
[01:17:47.600 --> 01:17:50.320]   Something that wouldn't be wiped by formatting the drive
[01:17:50.320 --> 01:17:52.880]   snowy owl
[01:17:52.880 --> 01:17:59.360]   Uses open ssh to pull off remote monitoring. I mean it goes on and on and on this is a
[01:17:59.360 --> 01:18:02.960]   very rich set of stuff now androids
[01:18:02.960 --> 01:18:07.520]   Lots of exploits. Oh cronos crayaton
[01:18:07.520 --> 01:18:09.520]   Uh
[01:18:09.520 --> 01:18:11.520]   Starmy snubble
[01:18:11.520 --> 01:18:15.200]   bowtie sucker punch and roid rage
[01:18:15.200 --> 01:18:17.200]   Uh
[01:18:17.200 --> 01:18:18.800]   SMS stealing
[01:18:18.800 --> 01:18:20.800]   chrome based attacks for androids
[01:18:21.280 --> 01:18:26.160]   There's a huge number of exploits escalation of privileges allowing malicious apps
[01:18:26.160 --> 01:18:29.040]   baron samdi which is a voodoo
[01:18:29.040 --> 01:18:33.520]   named dug trio and salazar allow for remote access
[01:18:33.520 --> 01:18:40.080]   They're fixed or mitigated by later versions of andro but remember a lot of people have older versions of androids and of course
[01:18:40.080 --> 01:18:42.080]   This list is three years old
[01:18:42.080 --> 01:18:49.920]   Uh, the cia stash contains this is all for me and tomson on the registered uh code.uk the cia stash contains run downs on most of the popular
[01:18:49.920 --> 01:18:51.760]   antivirus systems and how to defeat them
[01:18:51.760 --> 01:18:56.320]   Much of the information has been redacted, but there are a few snippets left
[01:18:56.320 --> 01:19:00.560]   So they they're they're that's interesting that they're working
[01:19:00.560 --> 01:19:05.040]   To defeat antivirus software because it's a path
[01:19:05.040 --> 01:19:09.600]   Right. Yeah virus. Yeah. What about uh chrome what the
[01:19:09.600 --> 01:19:14.800]   Sorry, go on smart t. I haven't got to chrome yet. Uh smart TVs
[01:19:15.680 --> 01:19:20.560]   We mentioned weeping angel which takes a sam san tv and turns it into a fake off mode
[01:19:20.560 --> 01:19:24.720]   Which makes it look like it's powered down, but it's still on and can be used as a bugging device
[01:19:24.720 --> 01:19:28.800]   That's really handy actually
[01:19:28.800 --> 01:19:33.760]   Uh, but the tv has to be compromised by a usb stick inserted into the device
[01:19:33.760 --> 01:19:40.800]   Uh, that one wasn't as stressful. Yeah, although, you know, if they're gonna come into your hotel room or whatever to put a bug in there
[01:19:40.800 --> 01:19:43.840]   I've been watching the americans
[01:19:43.840 --> 01:19:45.840]   Take the
[01:19:45.840 --> 01:19:46.880]   Exactly
[01:19:46.880 --> 01:19:50.320]   Uh, how how easy is that you know, you don't have to drill holes or anything
[01:19:50.320 --> 01:19:57.280]   Apparently they're looking actively at the united of things now three years ago at iot was not such a big story, but it is now, right?
[01:19:57.280 --> 01:20:02.000]   I feel like it's almost exactly in the same place to be totally honest. Yeah
[01:20:02.000 --> 01:20:05.280]   Three years of iot excitement and um
[01:20:05.280 --> 01:20:12.240]   Basically the most advanced devices I have are my nest and my echo. Yeah, so and you're living brigga dune
[01:20:12.880 --> 01:20:14.400]   uh
[01:20:14.400 --> 01:20:22.320]   One analyst included his favorite aske characters for conversing online with japanese people along with games he likes to play in some music suggestions
[01:20:22.320 --> 01:20:27.360]   Because they had a kind of a jaunty way about them the cia operatives
[01:20:27.360 --> 01:20:31.520]   So uh, he and we'll get Ian on soon because he's been poor guy
[01:20:31.520 --> 01:20:36.880]   He said really rough night because he's been reading all 8 000 pages looking for the s voices
[01:20:36.880 --> 01:20:40.320]   Uh, you know, this is where machine learning could totally help. Yeah
[01:20:41.200 --> 01:20:46.720]   You run this sucker through i'm i'm not i mean like to a way to be better at your job is to you know
[01:20:46.720 --> 01:20:50.880]   Yeah, right a program that would be this way you should probably learn how to do it
[01:20:50.880 --> 01:20:53.600]   Well, you saw that uh article, uh about uh
[01:20:53.600 --> 01:20:56.320]   journalist upset with uh
[01:20:56.320 --> 01:21:01.600]   Because i might you must have put that one in right? No, I didn't know it was already there. I don't know what benefit
[01:21:01.600 --> 01:21:03.760]   Let me find it here
[01:21:03.760 --> 01:21:05.840]   Um, we get a we get upset so easily
[01:21:06.400 --> 01:21:12.480]   Huge journalist stop the presses journos not happy losing jobs to journo bots say journos once again
[01:21:12.480 --> 01:21:14.560]   They register with its great sense of humor
[01:21:14.560 --> 01:21:19.520]   It's like did they use the word boffin because it's not a register
[01:21:19.520 --> 01:21:23.920]   They gotta use boffin
[01:21:23.920 --> 01:21:28.800]   Um, do you have any attention to this problem of fake news on the google home?
[01:21:28.800 --> 01:21:35.040]   Have you tried it jeff you probably have yeah, yeah, I mean, you know, so yeah
[01:21:35.200 --> 01:21:40.000]   It's a worse problem. So so google knew that the uh auto complete was a problem
[01:21:40.000 --> 01:21:41.760]   But that they see that as a feature and they got rid of it
[01:21:41.760 --> 01:21:46.400]   It doesn't try to tell you what the truth is or anything so if you ask your google home is obama planning a coup
[01:21:46.400 --> 01:21:51.360]   It will say well. Yes according to western center for journalism
[01:21:51.360 --> 01:21:58.960]   I mean that's fake news, right? Yeah, have they figured a way to get an issue there?
[01:21:58.960 --> 01:22:01.120]   Have they figured a way to get it out?
[01:22:01.520 --> 01:22:06.320]   Um, they should bring back back cuts the fact that matt cuts is gone is zoom for them. So
[01:22:06.320 --> 01:22:09.760]   Matt we need you
[01:22:09.760 --> 01:22:15.120]   I've been saying i've been saying everywhere that we need a matt we need a matt cuts for fake news. Yeah
[01:22:15.120 --> 01:22:21.680]   I I mean you have to ask it that that leading question is obama planning a coup
[01:22:21.680 --> 01:22:29.120]   So I I don't want to reveal much but but I had a discussion all director discussion with some some
[01:22:30.320 --> 01:22:33.840]   top engineers at a certain technology company and and
[01:22:33.840 --> 01:22:36.800]   it was a fascinating discussion because
[01:22:36.800 --> 01:22:41.920]   Part of what they try to do is to anticipate the users desires, right?
[01:22:41.920 --> 01:22:48.240]   Now what that means is if they anticipate that that user is a sweaty paranoid
[01:22:48.240 --> 01:22:52.000]   Uh guy in an ill fitting t-shirt in a bunker somewhere
[01:22:52.000 --> 01:22:58.720]   Then they will do one thing and my response was well. No imagine if the same question were asked by a third grader
[01:22:59.440 --> 01:23:01.440]   Try this. No try this
[01:23:01.440 --> 01:23:06.640]   I'm gonna ask us say okay. Oh, we are women evil. Oh, jesus really don't ask that
[01:23:06.640 --> 01:23:10.720]   Women's day. It's gotta go my permanent record. It's gotta go my permanent record. I was not sure
[01:23:10.720 --> 01:23:14.480]   It's generalistic research. Okay. I will
[01:23:14.480 --> 01:23:23.200]   Are women evil talking to fetch my calendar. Oh shut up. I hate these no
[01:23:23.200 --> 01:23:26.000]   Okay
[01:23:26.000 --> 01:23:29.440]   Sorry, do you want to give my calendar? I try okay? No
[01:23:29.440 --> 01:23:33.360]   All right, you might like that my
[01:23:33.360 --> 01:23:37.120]   F you google
[01:23:37.120 --> 01:23:40.000]   You want to talk to fetch my calendar? No
[01:23:40.000 --> 01:23:46.880]   Okay, she's pissed
[01:23:46.880 --> 01:23:51.680]   Yes, she's giving me the silent treatment. It's women's day you know
[01:23:52.560 --> 01:23:57.680]   What if what if you know google home has been I don't want to finish my fucking calendar. No
[01:23:57.680 --> 01:24:00.080]   It's been glitchy
[01:24:00.080 --> 01:24:07.280]   This this may be an issue. It has been really glitchy for people have been seen it did a story on it and actually it happened to me for like two days
[01:24:07.280 --> 01:24:11.520]   Are women evil?
[01:24:11.520 --> 01:24:14.320]   I don't understand
[01:24:14.320 --> 01:24:18.000]   They fixed it. They fixed it. Okay. Yeah, so so you know
[01:24:19.040 --> 01:24:22.000]   Features like that are fixed. Someone can be fixed
[01:24:22.000 --> 01:24:27.440]   The holy grail of either google or facebook is the ranking and they need
[01:24:27.440 --> 01:24:33.200]   Rule sets to decree that ranking so the interesting thing to me was when it gets to to what you see
[01:24:33.200 --> 01:24:38.800]   Um, you know if you ask is the holocaust real versus holocaust deniers versus holocaust
[01:24:38.800 --> 01:24:41.600]   What results should you get?
[01:24:41.600 --> 01:24:45.760]   In each case now if you want to find holocaust deniers you should be able to search for them
[01:24:45.760 --> 01:24:48.880]   So you can do research about how awful and horrible and evil and miserable they are
[01:24:48.880 --> 01:24:52.560]   But if you ask for the holocaust and you ask for is the holocaust real
[01:24:52.560 --> 01:24:56.800]   To my mind you should be true to the knowledge
[01:24:56.800 --> 01:24:58.800]   Right
[01:24:58.800 --> 01:25:01.120]   Danny Sullivan in his article for search engine land
[01:25:01.120 --> 01:25:06.720]   Uh shows in the past in 2015 if you asked google what happened to the dinosaurs
[01:25:06.720 --> 01:25:11.600]   It would say dinosaurs are used more than almost anything to indoctrinate children and adults
[01:25:12.480 --> 01:25:16.560]   In the idea of millions of years of earth history. Here's what he uh, here's what he got when he asked
[01:25:16.560 --> 01:25:19.040]   This was a couple of days ago are women evil
[01:25:19.040 --> 01:25:22.160]   Hey
[01:25:22.160 --> 01:25:28.320]   Here's a summary from shedding of the ego every woman has some degree of prostitute and her
[01:25:28.320 --> 01:25:30.560]   Oh, lord. Oh
[01:25:30.560 --> 01:25:32.320]   lord, she said
[01:25:32.320 --> 01:25:34.240]   now
[01:25:34.240 --> 01:25:37.760]   That's the snippet that came up and that's is that based on what?
[01:25:37.760 --> 01:25:41.760]   What is that based on why would it pull that up? I would have pulled that why would it?
[01:25:41.760 --> 01:25:43.760]   I would have kept that authority
[01:25:43.760 --> 01:25:49.280]   Well, so we had a story on the rundown so it was about caramelizing onions. I'm not I'm not real sure why
[01:25:49.280 --> 01:25:54.720]   But it's the same issue there is it google
[01:25:54.720 --> 01:25:58.880]   AI or I assume it's an AI that's pulling these snippets
[01:25:58.880 --> 01:26:00.480]   pulled
[01:26:00.480 --> 01:26:02.480]   You know the wrong information
[01:26:02.480 --> 01:26:04.800]   It pulled the basically a quote in the article
[01:26:04.800 --> 01:26:09.520]   About caramelizing onion takes five minutes and the whole point of the article was to ref
[01:26:09.600 --> 01:26:13.360]   Refute the idea that it takes 25 minute or five minutes. So
[01:26:13.360 --> 01:26:16.720]   It sounds like
[01:26:16.720 --> 01:26:18.800]   Is it misunderstanding?
[01:26:18.800 --> 01:26:21.280]   Maybe it's
[01:26:21.280 --> 01:26:27.440]   Again training a model for AI is really hard and you need lots of hardcore examples and the mistakes will make it better
[01:26:27.440 --> 01:26:30.240]   um, so google fixed it
[01:26:30.240 --> 01:26:32.000]   but
[01:26:32.000 --> 01:26:36.880]   We don't actually know what part of the model is telling it what's important
[01:26:37.520 --> 01:26:40.000]   I mean, let's also acknowledge that
[01:26:40.000 --> 01:26:48.240]   We're complaining because a I know machine learning system doesn't fully understand this long prose article
[01:26:48.240 --> 01:26:56.160]   And misinterprets it the fact that you can ask an inanimate object how to caramelize onions and it gives you anything back. It's kind of
[01:26:56.160 --> 01:26:58.880]   Incredible okay
[01:26:58.880 --> 01:27:00.880]   We're relying on it. Well, we should
[01:27:00.880 --> 01:27:03.680]   caramelize onions
[01:27:04.720 --> 01:27:10.000]   According to slate blend in the salt and sugar read heat are moderately high and let the onions brown
[01:27:10.000 --> 01:27:14.640]   During frequently until they are a dark walnut color 25 to 30 minutes. I love that
[01:27:14.640 --> 01:27:21.520]   25 to 30 minutes equals 35 to 40 minutes. So they fixed it read more look for the link in your google home app
[01:27:21.520 --> 01:27:27.040]   I I love it you can ask for recipes, but I you know you doesn't turn off your brain
[01:27:27.040 --> 01:27:33.760]   If it says well, but if you don't know how to caramelize onions, that's actually a really good use case because okay, it's not like
[01:27:34.560 --> 01:27:36.560]   It's not like Holocaust real
[01:27:36.560 --> 01:27:43.440]   Sorry, I don't understand yeah, okay. Or is the Holocaust real
[01:27:43.440 --> 01:27:49.680]   My apology. I don't understand okay. Well, what's their is climate change real
[01:27:49.680 --> 01:27:56.560]   According to wikipedia global climate change and global warming are real and observable
[01:27:56.560 --> 01:28:01.440]   It is highly likely that those human activities that have increased the concentration see wrong again
[01:28:02.560 --> 01:28:06.880]   Largely responsible for the warning 19 this left wing
[01:28:06.880 --> 01:28:11.840]   It does do that's really well. Wait what it what it does do that's good is it says according to
[01:28:11.840 --> 01:28:16.480]   Yeah, so it gives us a sense of the source which is and it tries to link in your
[01:28:16.480 --> 01:28:23.520]   No, it didn't do that. It said I could get the link from my home app. Oh, oh my home app. Not my not my ai up to radio. All right
[01:28:23.520 --> 01:28:26.800]   all right, all right
[01:28:26.800 --> 01:28:29.360]   I found some other things
[01:28:30.080 --> 01:28:35.760]   It's interesting that they're their solution to cutting the bad snippets out as you say. I don't know what you're talking about
[01:28:35.760 --> 01:28:38.640]   Yeah, exactly. That's actually that's actually a decent
[01:28:38.640 --> 01:28:45.680]   I don't know what you're talking about. Well, if you if you go so the famous case in the guardian was was auto complete for jus are right
[01:28:45.680 --> 01:28:53.520]   But we've seen this as people years people. Yeah, but they mean you've got I mean you'd have to hand call the top out
[01:28:53.520 --> 01:28:55.840]   How many millions of results? Yeah
[01:28:56.880 --> 01:28:58.880]   Well, it changes all the time doesn't it? Yeah
[01:28:58.880 --> 01:29:03.120]   Yeah, so I've argued that what we part of what we need to do and this is part of the fake news
[01:29:03.120 --> 01:29:06.320]   The big one thing I want to see is it doing a better job of mapping manipulation
[01:29:06.320 --> 01:29:10.160]   And that the platform should be better at understanding manipulation
[01:29:10.160 --> 01:29:14.160]   Not just advertising and spam but also in in facts and news and then
[01:29:14.160 --> 01:29:16.960]   acting differently upon that
[01:29:16.960 --> 01:29:20.800]   So if you take if you just took the the data set of wikipedia
[01:29:20.800 --> 01:29:23.840]   Our articles that have to shut down because they're too controversial
[01:29:23.840 --> 01:29:26.320]   That means someone somewhere is creating
[01:29:27.120 --> 01:29:29.120]   probably fake
[01:29:29.120 --> 01:29:31.360]   Controversy around this
[01:29:31.360 --> 01:29:36.080]   And so so they have to be careful how their algorithm how their sensing rather looks at
[01:29:36.080 --> 01:29:39.280]   The data coming in because there's going to be some fake heat
[01:29:39.280 --> 01:29:44.960]   Somewhere and they're going to give you bad results and they'll learn how to do this eventually. It's what they're going to need some needs more effort
[01:29:44.960 --> 01:29:50.000]   Right. I mean, that's actually something that people are pretty good at
[01:29:50.000 --> 01:29:51.680]   Um
[01:29:51.680 --> 01:29:53.440]   Or maybe actually we're terrible at it. I don't know
[01:29:53.920 --> 01:29:56.560]   Um, that's hard for computers to do. Let me put it that way
[01:29:56.560 --> 01:30:01.680]   I don't know
[01:30:01.680 --> 01:30:07.760]   I love the caramelized onion story because it's actually written by a guy who was pissed
[01:30:07.760 --> 01:30:09.840]   because he
[01:30:09.840 --> 01:30:13.520]   Kept seeing recipes that said five to mid ten minutes at caramelized onions and it always took him
[01:30:13.520 --> 01:30:18.240]   Half an hour to 45 minutes and he thought he he was doing something wrong or his bad cook
[01:30:18.240 --> 01:30:20.320]   So he wrote a big article on slate
[01:30:20.720 --> 01:30:23.600]   And got the New York Times and others to fix their
[01:30:23.600 --> 01:30:31.600]   Incorrect recipes and then he says and but nevertheless google still gets it wrong. They fixed that since
[01:30:31.600 --> 01:30:39.200]   It's funny. Do not try to caramelize onion in five minutes and you know and do not listen to google, but apparently they've they've fixed it
[01:30:39.200 --> 01:30:45.200]   It's pretty funny. I
[01:30:45.840 --> 01:30:52.320]   Mean the only reason that article is this because this guy it's a personal a personal umbridge um bridge took umbridge
[01:30:52.320 --> 01:30:57.040]   Which by the way is the same thing as shade
[01:30:57.040 --> 01:31:00.240]   Okay, go ahead. Yes
[01:31:00.240 --> 01:31:05.920]   Did you know about steve martin's comedy course? I did I tweeted it. Oh you did. Okay. I was hoping that yes
[01:31:05.920 --> 01:31:08.400]   What is the story with this company?
[01:31:08.400 --> 01:31:11.920]   It's it's it's it's a solid it's a san francisco company that got venture capital
[01:31:12.400 --> 01:31:17.040]   To use to have to do celebrity courses sounds a little bit like trump you but I think uh actually no
[01:31:17.040 --> 01:31:21.440]   But they're real courses and they're not expensive. I saw it if i'm gonna learn comedy from steve martin
[01:31:21.440 --> 01:31:28.000]   It's gonna cost me a lot of money or acting from kevin space here singing from christian haggall era, but it's or tettis from
[01:31:28.000 --> 01:31:34.000]   Aaron sorcan teacher screen writing gordon ramsie t i'll skip that
[01:31:34.000 --> 01:31:38.480]   Yeah, I wonder I mean it's pretty cool
[01:31:39.040 --> 01:31:42.720]   So they're gonna do a steve martin course and it's not expensive it's $90
[01:31:42.720 --> 01:31:46.000]   For I don't know there's a number of courses
[01:31:46.000 --> 01:31:48.720]   I think it's really cool
[01:31:48.720 --> 01:31:50.720]   It is pretty cool. Yeah, I don't
[01:31:50.720 --> 01:31:56.640]   You get so here's the kevin spacey acting 90 bucks 28 video lessons. I don't know how long they are
[01:31:56.640 --> 01:32:03.120]   A 47 page workbook and you get office hours you can upload videos and there's a chance that kevin will see your work
[01:32:03.120 --> 01:32:05.520]   There's a chance. Yeah
[01:32:05.520 --> 01:32:07.920]   Choosing a monologue
[01:32:08.480 --> 01:32:15.040]   Working with text. This is great stuff. I mean I spent hundreds of dollars hundreds and hundreds of dollars learning this stuff
[01:32:15.040 --> 01:32:17.840]   you know in acting schools
[01:32:17.840 --> 01:32:22.240]   And look where you went to acting schools. Yeah, you can't tell how much again how much I gained
[01:32:22.240 --> 01:32:28.480]   Actually, I really kind of were like this but i've replayed the character
[01:32:28.480 --> 01:32:33.920]   I was gonna say maybe you don't really like us. You're just out. I hate you guys
[01:32:33.920 --> 01:32:37.040]   I hate my life and
[01:32:37.360 --> 01:32:40.640]   Actually a tall thin person, but I'm a brilliant actor
[01:32:40.640 --> 01:32:44.720]   I know I love this idea. Yeah, I thought this was really cool
[01:32:44.720 --> 01:32:50.960]   I I I made a little joke tweet. I said I see that steve martin's gonna be teaching twitter
[01:32:50.960 --> 01:32:57.920]   A masterclass. I hope he covers hashtags and he responded. I know everything there's no about hashtags putting the hashtag at the end
[01:32:57.920 --> 01:33:01.440]   This is awesome nice
[01:33:01.440 --> 01:33:03.280]   Uh
[01:33:03.280 --> 01:33:06.800]   But do another 32 million. Yeah, who counts breached who cares?
[01:33:06.800 --> 01:33:08.880]   uh
[01:33:08.880 --> 01:33:11.360]   money away from
[01:33:11.360 --> 01:33:19.840]   Uh, the us department of justice has declined to prosecute a child pouring case because they don't want anybody to know how they cracked tour
[01:33:19.840 --> 01:33:23.520]   They have an exploit they apparently
[01:33:23.520 --> 01:33:25.760]   Could we believe they did?
[01:33:25.760 --> 01:33:29.680]   That deanonymizes torque users. This is the play pen case
[01:33:30.160 --> 01:33:35.200]   But they don't want to they don't want anybody to know how they did it. So they're asking believe it or not
[01:33:35.200 --> 01:33:38.320]   They're asking a federal court to dismiss its indictment
[01:33:38.320 --> 01:33:46.320]   In this in a case it involves a child porn site known as play pen after the judge said the government had to disclose the technique they use to gather evidence
[01:33:46.320 --> 01:33:54.400]   DOJ is not happy the government must now choose between disclosure of classified information and dismissal of its indictment
[01:33:54.400 --> 01:33:56.720]   Disclosure is not currently an option
[01:33:56.720 --> 01:34:00.080]   Wow
[01:34:00.080 --> 01:34:06.560]   This is the one the very famous case where the the fbi operated for 13 days a child porn site
[01:34:06.560 --> 01:34:14.800]   Uh, I guess as a honey. They didn't make it it was there and they went 13 days before they shut it down
[01:34:14.800 --> 01:34:18.080]   So there's a controversial case in the uk
[01:34:18.080 --> 01:34:26.960]   Where I didn't put up on the rundown but facebook had the bbc put up child porn on facebook to track how soon it was taken down
[01:34:27.920 --> 01:34:32.560]   Then they found stuff didn't get taken down and so they went to the facebook and said we want to interview about this facebook
[01:34:32.560 --> 01:34:36.320]   So can you show us please what is there facebook then reported
[01:34:36.320 --> 01:34:40.160]   Those photos and thus the bbc to the authorities
[01:34:40.160 --> 01:34:44.400]   Yeah, and journalists got a little shocked about this but but in this country in america
[01:34:44.400 --> 01:34:49.200]   If you if you just accidentally see child pornography and you do not report it
[01:34:49.200 --> 01:34:52.880]   You are as liable as the as a pornography and you can go to freaking jail
[01:34:53.680 --> 01:34:56.560]   So I don't know if it was a scandalous story on facebook's part or not
[01:34:56.560 --> 01:35:01.040]   But my thinking is they kind of did what they had no choice but to do tell me if i'm wrong
[01:35:01.040 --> 01:35:06.320]   Uh, I don't know. I know I know I don't understand
[01:35:06.320 --> 01:35:10.160]   It's just I mean I presume that this has all been worked out by now
[01:35:10.160 --> 01:35:14.960]   No, because it's the story just broke this week and so some journos are in a fizzy about it
[01:35:14.960 --> 01:35:17.520]   They might be right to be but I I don't know
[01:35:17.520 --> 01:35:20.480]   What a world
[01:35:20.480 --> 01:35:24.080]   It is jz is going to do a fun for startups
[01:35:24.080 --> 01:35:30.880]   I'm trying to start up this new cap venture capital firm arrive has arrived
[01:35:30.880 --> 01:35:37.760]   Right, stero ettherington in tech crunch the rapid business mogul has been planning the launch for a while
[01:35:37.760 --> 01:35:41.360]   um
[01:35:41.360 --> 01:35:48.720]   The arrives unique sales pitch to potential investment targets involves revolves heavily around its experience in brand building
[01:35:49.520 --> 01:35:53.040]   What we did for rock nation did for jz we could do for you
[01:35:53.040 --> 01:35:56.480]   There's no money in the font however
[01:35:56.480 --> 01:36:00.400]   Here's a cool thing. Yeah, um
[01:36:00.400 --> 01:36:08.480]   mit is created the mit media lab disobedience award. Like it. Do you guys see this? No, but i'm not a wiggle
[01:36:08.480 --> 01:36:14.320]   Well, you might have a choice or a chance. Um, it's a 250 000 dollar cash prize
[01:36:14.480 --> 01:36:20.560]   No strings attached it goes to a person or group engaged in what we believe is an extraordinary example of disobedience for the
[01:36:20.560 --> 01:36:23.440]   benefit of society like civil disobedience
[01:36:23.440 --> 01:36:29.760]   Well, what does this mean societies and institutions lean towards order and away from chaos while necessary for functioning?
[01:36:29.760 --> 01:36:33.200]   Structure stifles creativity flexibility and productive change
[01:36:33.200 --> 01:36:39.840]   Uh bla bla bla with the story. Ito says you don't change the world by doing what you're told
[01:36:40.960 --> 01:36:47.520]   Yes, well there was there was a young man who did just that at mit and then got taken to uh court and committed suicide
[01:36:47.520 --> 01:36:54.080]   But erin schwartz. Yeah, exactly. So maybe this is their way of making an argument. Sorry. Yeah, we're sorry
[01:36:54.080 --> 01:37:00.640]   So these principles they were focused on our nonviolence creativity courage and taking responsibility for one's actions
[01:37:00.640 --> 01:37:03.600]   The disobedience is not limited to specific disciplines
[01:37:03.600 --> 01:37:08.880]   So examples include scientific research civil rights freedom of speech human rights and the freedom to innovate
[01:37:08.960 --> 01:37:11.680]   I like they use discipline and disobedience in the same sentence
[01:37:11.680 --> 01:37:14.960]   Um, wow
[01:37:14.960 --> 01:37:19.520]   Basically you have to be you have to take a personal risk to
[01:37:19.520 --> 01:37:23.200]   In order to effect positive change for greater society
[01:37:23.200 --> 01:37:27.040]   Ooh this nomination form is a secure form
[01:37:27.040 --> 01:37:31.600]   The information submitted will not be shared publicly. However, we're mindful of privacy
[01:37:31.600 --> 01:37:35.200]   And the fact that many people in organizations doing disobedient work
[01:37:36.000 --> 01:37:41.360]   Might not want to disclose their information to the public. Wow. I'm not feeling that. Please form
[01:37:41.360 --> 01:37:47.680]   I guess civil disobedience is that
[01:37:47.680 --> 01:37:52.640]   Protest protesting right yeah
[01:37:52.640 --> 01:37:55.120]   Wow
[01:37:55.120 --> 01:38:00.480]   Martin luther king versus uh malcom x probably yeah, what do you get for disobeying a lawyer?
[01:38:00.480 --> 01:38:02.480]   Quarter of a million dollars
[01:38:02.480 --> 01:38:06.800]   Quarter of a that could fund your legal fees. No strings attached. Who's funding it?
[01:38:06.800 --> 01:38:09.600]   That's a mit weird
[01:38:09.600 --> 01:38:12.800]   It's very interesting
[01:38:12.800 --> 01:38:15.600]   It's like all right
[01:38:15.600 --> 01:38:21.200]   Amazon has gotta be a response to trump amazon has handed over the echo data that it was holding on to
[01:38:21.200 --> 01:38:28.880]   Claiming a first amendment defense, but that's only because the defendant said, oh, it's all right. Give him my echo stuff
[01:38:28.880 --> 01:38:31.760]   Oh
[01:38:32.720 --> 01:38:37.360]   I you know I doubt there's anything in there. It's clearly a fishing expedition and yet
[01:38:37.360 --> 01:38:42.400]   I feel like amazon should fight hard against that kind of stuff, right?
[01:38:42.400 --> 01:38:50.080]   Well, but maybe this isn't this isn't the hill it wanted to die on maybe and if the I mean if the guy said it's okay
[01:38:50.080 --> 01:38:53.520]   Maybe it maybe amazon would have fought but realized that
[01:38:53.520 --> 01:39:00.080]   This guy could just I guess it couldn't get over the server data nevermind. I don't know we didn't mention
[01:39:01.120 --> 01:39:03.600]   Uh, we would talk a lot about uber last week. We didn't mention
[01:39:03.600 --> 01:39:10.400]   And this about a potential another potential pause on here. We didn't mention the gray ball tool
[01:39:10.400 --> 01:39:17.040]   which is apparently a tool uber has been using to prevent investigative authorities from taking uber rides
[01:39:17.040 --> 01:39:21.360]   If you hail a ride
[01:39:21.360 --> 01:39:24.720]   From uber and you're on the gray ball list. It's kind of like a black ball list
[01:39:24.720 --> 01:39:28.640]   Uh, they'll avoid you and the idea is that the regulatory
[01:39:29.760 --> 01:39:32.560]   Code enforcement inspectors people like that try to hail ubers
[01:39:32.560 --> 01:39:39.280]   Uh to see if they're, you know doing everything right and it just they'll just ignore you. They'll just shine you on
[01:39:39.280 --> 01:39:41.920]   That's not illegal
[01:39:41.920 --> 01:39:47.200]   But it just shows kind of more of the kind of sketchiness of the whole uber thing, right?
[01:39:47.200 --> 01:39:55.920]   I don't know why people are surprised. I mean like I this is this is a case where i'm kind of like
[01:39:58.640 --> 01:40:04.320]   It's like people are surprised that trump has done some of that like he's gonna build a wall actually
[01:40:04.320 --> 01:40:07.840]   Like the people who are like well, we didn't say he was serious
[01:40:07.840 --> 01:40:14.320]   I'm like really? I mean we we knew that uber was not staffed by people who I mean we know
[01:40:14.320 --> 01:40:21.760]   They're jerks for using a nice word. So the mayor of portland cal mcclochlin said
[01:40:21.760 --> 01:40:27.440]   I'm very concerned that uber may have purposely worked to thwart the city's job to protect the public
[01:40:28.240 --> 01:40:31.040]   It did yeah, I mean that's exactly what it did
[01:40:31.040 --> 01:40:34.000]   Yeah
[01:40:34.000 --> 01:40:36.000]   I think it's not illegal
[01:40:36.000 --> 01:40:39.680]   um, but nevertheless it shows that you know
[01:40:39.680 --> 01:40:45.840]   They why this is just really interesting. Yeah, sometimes you don't follow the letter of the law
[01:40:45.840 --> 01:40:49.920]   Follow the spirit, but this is disobedience. I think they should get an award for that
[01:40:49.920 --> 01:40:52.160]   I was gonna say should they get the promise?
[01:40:52.160 --> 01:40:56.720]   Some people would argue that uber does better society. I would argue to the opposite
[01:40:57.600 --> 01:40:58.320]   But
[01:40:58.320 --> 01:41:03.360]   Lift is looking for new funding saying here's our opportunity. We're gonna we got an opening here
[01:41:03.360 --> 01:41:06.880]   They're they're talking with investors indeed. Yeah
[01:41:06.880 --> 01:41:12.400]   I mean heck, you know, I'm where else you're gonna go right? I mean that's pretty much where you go if you're not gonna use uber
[01:41:12.400 --> 01:41:18.320]   It's the number two and Austin. We don't have either you don't have either you have just regular cabs
[01:41:18.320 --> 01:41:25.760]   We're always have some app-based services. So there aren't yeah, I've seen people getting ready for south by south west sharing the names of
[01:41:26.320 --> 01:41:29.920]   So yet for their fair fastened
[01:41:29.920 --> 01:41:33.840]   Wings with a z and ride Austin
[01:41:33.840 --> 01:41:36.400]   Okay
[01:41:36.400 --> 01:41:40.880]   I way I kind of like seeing these little small local ubers better than some
[01:41:40.880 --> 01:41:44.160]   Giant billion-dollar unicorn multinational
[01:41:44.160 --> 01:41:50.960]   Well, no because I was in the line for a cab at the airport because I got home at a weird time or something
[01:41:50.960 --> 01:41:54.880]   I don't remember and the woman behind me was just like I can't believe they don't have uber hair
[01:41:55.120 --> 01:41:57.120]   they don't even have left and like
[01:41:57.120 --> 01:42:05.040]   She was genuinely frustrated and you know, you you don't know the local right what a quote local uber
[01:42:05.040 --> 01:42:07.440]   Ubers
[01:42:07.440 --> 01:42:11.200]   So I told her a couple and she was like, oh thank you. Thank you
[01:42:11.200 --> 01:42:18.240]   So I don't know if you're gonna do this then maybe you should have like a giant sign at your airport in lots of places
[01:42:18.240 --> 01:42:23.200]   I love it that uh evan spiegel made so much money in the uh
[01:42:24.720 --> 01:42:27.440]   Snapchat IPO that he's now worth more than two opris
[01:42:27.440 --> 01:42:29.920]   That is a new measurement
[01:42:29.920 --> 01:42:33.760]   1% how many opris are you how many how many opris is buffet
[01:42:33.760 --> 01:42:36.880]   A lot of opris
[01:42:36.880 --> 01:42:39.680]   What is what is opris net worth? I don't know is it a billion?
[01:42:39.680 --> 01:42:42.080]   Okay, google
[01:42:42.080 --> 01:42:44.080]   How much is opra worth?
[01:42:44.080 --> 01:42:47.680]   A net worth of opra winfrey is three billion dollars. All right
[01:42:47.680 --> 01:42:53.520]   So he's worth six billion and uh, okay google how much is warren buffett worth
[01:42:54.160 --> 01:43:02.960]   A net worth of warren buffet is 76 billion. Holy shoot. She says a lot of opris 25 opris
[01:43:02.960 --> 01:43:08.240]   I like that measure. How many opris are yours?
[01:43:08.240 --> 01:43:10.880]   You know after a billion
[01:43:10.880 --> 01:43:12.800]   0.0000000
[01:43:12.800 --> 01:43:16.320]   0.001. Yeah, is that opra? Yeah
[01:43:19.360 --> 01:43:22.880]   Uh, anything else you guys put some stories in there
[01:43:22.880 --> 01:43:26.320]   Let's see here
[01:43:26.320 --> 01:43:31.440]   Yup is now listing gender neutral bathrooms good
[01:43:31.440 --> 01:43:35.440]   So uh, you can find a bathroom for yourself
[01:43:35.440 --> 01:43:40.160]   So uh, microsoft is putting
[01:43:40.160 --> 01:43:42.960]   Arm-based servers in its data center
[01:43:42.960 --> 01:43:48.160]   I don't know. Oh, yeah, we talked a lot about the earlier on windows weekly. No, no on this show
[01:43:48.160 --> 01:43:50.720]   Yeah, it's weekly. That's a big story but that we
[01:43:50.720 --> 01:43:56.240]   Microsoft announced that they're going to do windows on arm and now the fact that they're doing arm-based servers is interesting
[01:43:56.240 --> 01:44:00.240]   And I think we concluded that while there may be economic reasons because of course they're
[01:44:00.240 --> 01:44:05.120]   Lots lower power about a tenth the power of a silica of a silicon from uh intel
[01:44:05.120 --> 01:44:12.000]   Uh, but a half is fast, but that still gives you you know, uh, 500 improvement in uh, in
[01:44:12.000 --> 01:44:14.800]   Uh, well and in some apps
[01:44:14.800 --> 01:44:17.600]   like if you're running like
[01:44:17.600 --> 01:44:22.800]   In a cloud setting when you're splitting up a server you're virtualizing a server and splitting it up into multiple instances
[01:44:22.800 --> 01:44:25.440]   Right it doesn't matter right right
[01:44:25.440 --> 01:44:33.040]   Yeah, I mean and then the other uh, point of course is it's also political and strategic because they don't want to be beholden to intel
[01:44:33.040 --> 01:44:37.120]   So you can make intel drop its prices finally exactly
[01:44:37.120 --> 01:44:44.240]   The other thing so another benefit of that is because arm licenses its core technology
[01:44:44.240 --> 01:44:46.560]   you can actually design chips that are
[01:44:47.520 --> 01:44:53.600]   specific to especially for microsoft. Yeah, that's what apple does apple apple's uh, a
[01:44:53.600 --> 01:44:57.440]   Nine chips and a ten chips the chips and its iPhones are arm
[01:44:57.440 --> 01:45:03.280]   Based but they are tuned for apples needs for instance because they don't do flash
[01:45:03.280 --> 01:45:06.880]   They were able to apparently simplify the chip design considerably because they didn't have to support
[01:45:06.880 --> 01:45:09.440]   flash
[01:45:09.440 --> 01:45:12.960]   Exactly. So that's that's actually really interesting because it could lead to
[01:45:13.760 --> 01:45:18.320]   greater efficiency or better performances for certain things on certain platforms
[01:45:18.320 --> 01:45:23.120]   So so this is an interesting experiment by ryan broadrick at buzzfeed
[01:45:23.120 --> 01:45:26.960]   He made a facebook profile completely empty
[01:45:26.960 --> 01:45:33.520]   No friends in effect when he started he had no news there was nothing in his newsfeed
[01:45:33.520 --> 01:45:37.200]   He added a profile picture some personal information that was true
[01:45:37.200 --> 01:45:39.840]   Um
[01:45:39.840 --> 01:45:43.200]   But i'm revealing about his politics but i'm revealing about his politics
[01:45:43.920 --> 01:45:48.080]   And then he wanted to see how facebook's recommendation algorithms would work if you have no friends
[01:45:48.080 --> 01:45:50.880]   So what kind of content would it suggest
[01:45:50.880 --> 01:45:55.200]   If it had to go on what i liked rather than who i liked
[01:45:55.200 --> 01:45:59.120]   Facebook said this is an experiment it's a stunt
[01:45:59.120 --> 01:46:06.400]   Well, they have a point it's not how you use facebook right so he started liking uh first the republican national committee
[01:46:06.400 --> 01:46:10.080]   Didn't didn't change anything in his feed
[01:46:10.800 --> 01:46:16.560]   But most facebook pages have a liked by this page so he went down there and he liked chief of staff rights prebus
[01:46:16.560 --> 01:46:19.520]   and then he got some more and he
[01:46:19.520 --> 01:46:21.920]   liked hillary and he liked
[01:46:21.920 --> 01:46:24.880]   Barak and the democratic party and the i guess he was trying to balance it
[01:46:24.880 --> 01:46:27.600]   Just to see what would happen
[01:46:27.600 --> 01:46:30.560]   Creating a fairance balanced profile fair and balanced profile
[01:46:30.560 --> 01:46:37.200]   And then uh, he said i liked every page presented to me by facebook's suggested pages widget
[01:46:38.320 --> 01:46:42.960]   Which gave me my first illuminati and new world order sightings. Oh, that's interesting so it's a bit
[01:46:42.960 --> 01:46:46.160]   meta it's getting it's getting more and more out there, right
[01:46:46.160 --> 01:46:50.000]   It also threw in new york magazine, right i don't know why
[01:46:50.000 --> 01:46:53.920]   But the effect was almost immediately noticeable
[01:46:53.920 --> 01:46:58.480]   He got a very even though he was liking uh left wing
[01:46:58.480 --> 01:47:04.320]   uh sites to he started getting a lot of interesting
[01:47:04.320 --> 01:47:06.560]   uh
[01:47:06.560 --> 01:47:08.560]   memes from the right
[01:47:08.560 --> 01:47:16.480]   And then he generates maybe those they're advertising more and promoting more on facebook is my guess i guess that's part of the question, right
[01:47:16.480 --> 01:47:21.920]   Um is um, then these right wing soft core pornography memes
[01:47:21.920 --> 01:47:26.800]   He was getting uh, it's what's interesting is how this all
[01:47:26.800 --> 01:47:30.880]   Works and then he got banned because he was liking too many pages
[01:47:30.880 --> 01:47:34.240]   I don't know
[01:47:34.240 --> 01:47:39.680]   I didn't matt honen do this with like yeah liked everything. Yeah, he liked ever that really screwed him up
[01:47:39.680 --> 01:47:47.120]   Um, I think don't or matt. He's like a living living empty who's like bad. I love matt. Yeah
[01:47:47.120 --> 01:47:52.320]   Uh, so but the point I guess is it's so hard to figure out what facebook's doing
[01:47:52.320 --> 01:47:58.560]   And even even doing these things it's kind of hard to figure out at why did what it did, right?
[01:47:58.560 --> 01:48:01.520]   It doesn't seem it's not obvious
[01:48:01.680 --> 01:48:06.320]   No, it's not well that's that's what algorithms are you guys? I mean, that's the black box argument, right?
[01:48:06.320 --> 01:48:12.880]   Well, I would know I would think that you could put something in and see what came out and make some deductions about how the black box works
[01:48:12.880 --> 01:48:15.280]   That's how you would do it, right?
[01:48:15.280 --> 01:48:17.280]   But he's putting stuff in and it's not
[01:48:17.280 --> 01:48:24.640]   He's after three days started seeing white power memes was asked to join a Vladimir Putin fan club
[01:48:24.640 --> 01:48:27.440]   He's starting to get stuff from the daily stormer
[01:48:27.440 --> 01:48:30.400]   um
[01:48:30.400 --> 01:48:33.280]   Anyway, it's worth reading trying to understand
[01:48:33.280 --> 01:48:36.320]   What is facebook up to?
[01:48:36.320 --> 01:48:41.040]   Is and now of course, this is his newsfeed today and it's just it's just crazy
[01:48:41.040 --> 01:48:48.560]   But you know, I look at my newsfeed. It's exact opposite right? It's all left-wing politics by the way all politics all the time pretty much
[01:48:48.560 --> 01:48:51.280]   And my facebook feed now
[01:48:51.280 --> 01:48:53.520]   Uh, I suppose it'll calm down a little bit
[01:48:53.520 --> 01:48:57.600]   So I have a story for you. Yes dear
[01:48:58.240 --> 01:49:00.240]   This explains dear
[01:49:00.240 --> 01:49:04.480]   Yes, my friend. That's my friend
[01:49:04.480 --> 01:49:08.480]   We should not be doing this on wednesday
[01:49:08.480 --> 01:49:11.280]   This show because according to google's misery
[01:49:11.280 --> 01:49:13.120]   On thursday
[01:49:13.120 --> 01:49:16.160]   Well, I was gonna say fatigue peaks on wednesday. I know that
[01:49:16.160 --> 01:49:17.600]   Just sitting here being fatigued
[01:49:17.600 --> 01:49:20.080]   It's hump day. It's hump day man
[01:49:20.080 --> 01:49:23.840]   I feel so i'm like why am I still low energy today?
[01:49:23.840 --> 01:49:26.880]   We could do it. We can move this show
[01:49:26.960 --> 01:49:28.960]   It's my friday
[01:49:28.960 --> 01:49:34.160]   Does that does that matter though if when my when my holiday when my weekend is like does that change it?
[01:49:34.160 --> 01:49:38.160]   I don't know how do you feel?
[01:49:38.160 --> 01:49:43.200]   Uh, oh, but this is an old story. Yeah, it's a old story in the thing. Yeah
[01:49:43.200 --> 01:49:50.000]   Oh, oh, oh never mind. This is not never mind. Well. I don't think misery has changed much
[01:49:50.000 --> 01:49:52.960]   Oh, I think it has in the three years
[01:49:52.960 --> 01:49:56.800]   Oh, yeah
[01:49:56.960 --> 01:49:58.960]   Does google still have a misery index?
[01:49:58.960 --> 01:50:04.480]   I don't know. No, this guy did it himself. This is not from google. He did his own
[01:50:04.480 --> 01:50:09.920]   Oh sadness see my fatigue has led me to a story without reading the date. Oh
[01:50:09.920 --> 01:50:13.440]   But meanwhile look at the interest in international women's day
[01:50:13.440 --> 01:50:16.320]   Just going crazy
[01:50:16.320 --> 01:50:20.880]   Everywhere in colombia on duras equidore nica rago and guanamala
[01:50:20.880 --> 01:50:23.600]   That's where they're searching
[01:50:24.640 --> 01:50:29.840]   I do like google trends highly recommend that as a place to just kind of browse around and get some ideas
[01:50:29.840 --> 01:50:33.840]   Everybody's interested in south by south west. They're all getting excited
[01:50:33.840 --> 01:50:39.440]   I really haven't found a lot of people coming this year. I was asking about my
[01:50:39.440 --> 01:50:42.960]   The germans are coming the germans are honestly
[01:50:42.960 --> 01:50:48.160]   They have a german house. There's just all my German friends all of them go to self-ass
[01:50:48.160 --> 01:50:53.920]   There there is a big international thing. Oh guys. I caught my open hab
[01:50:54.000 --> 01:50:58.880]   I'm gonna tell you guys about it now, but I won't be able to show you anything for like a week or two
[01:50:58.880 --> 01:51:00.800]   Okay, I got my uh
[01:51:00.800 --> 01:51:06.480]   pine 64 board for my open hab build. Oh, you've been talking about this for a while. That's exciting
[01:51:06.480 --> 01:51:09.280]   It finally arrived. This is the only
[01:51:09.280 --> 01:51:11.840]   open uh
[01:51:11.840 --> 01:51:13.840]   home automation system out there
[01:51:13.840 --> 01:51:18.320]   competing with zigby and and z wave stuff like that is that what?
[01:51:18.320 --> 01:51:22.080]   No, it doesn't compete with it. No, it it competes with things like smart things or
[01:51:22.640 --> 01:51:24.080]   uh, it's a hub wink
[01:51:24.080 --> 01:51:31.120]   Yeah, because you can add you can add like the equivalent of pine 64 shields for z wave and other radios cool
[01:51:31.120 --> 01:51:36.800]   Cool. Yeah, I'm excited. I'll let you know. I can't wait
[01:51:36.800 --> 01:51:41.680]   So prepare or be like learn how to mute me for those functions because
[01:51:41.680 --> 01:51:46.880]   Let's tell you what let's take a break. We'll get your picks of the week. We'll wrap this thing up jeff's number
[01:51:47.600 --> 01:51:54.960]   But first a word from my pick this week betterment. You've seen tech transform commerce entertainment ride sharing
[01:51:54.960 --> 01:52:00.880]   Home security we talk about all this stuff, but it can even help you invest better betterment is the largest
[01:52:00.880 --> 01:52:03.200]   independent automated investment service
[01:52:03.200 --> 01:52:05.600]   And they've really transformed the industry
[01:52:05.600 --> 01:52:11.760]   And you see the articles by the way, it's so funny in wall street journal and elsewhere about live advisors going
[01:52:11.760 --> 01:52:13.920]   Oh, no, here come the bots
[01:52:13.920 --> 01:52:16.080]   But truthfully it does a better job for you
[01:52:16.640 --> 01:52:19.760]   You know take some of the emotion out of investing you're actually going to do it right
[01:52:19.760 --> 01:52:23.360]   Smart technology they are there are human advisors so you can
[01:52:23.360 --> 01:52:27.280]   You know ask questions and get optimal results at every level of investment
[01:52:27.280 --> 01:52:30.240]   You'll get access to a team of certified financial professionals
[01:52:30.240 --> 01:52:34.880]   And licensed finance experts they'll monitor your accounts. It's kind of the best of both worlds
[01:52:34.880 --> 01:52:40.480]   Able to answer questions. You'll get planning calls and notifications throughout the year, but also
[01:52:40.480 --> 01:52:43.360]   Unlike a human the automated investments
[01:52:43.920 --> 01:52:49.120]   Can monitor your investment rebalance it keep an eye on things minute by minute second by second
[01:52:49.120 --> 01:52:55.760]   Your their goal based investing framework and advice algorithm will let you know if you're on track in just seconds
[01:52:55.760 --> 01:52:58.800]   You can also add outside investments into betterment
[01:52:58.800 --> 01:53:04.960]   So you make sure you're fully balanced and you can see your total net worth in one place smart deposits let you automatically invest cash
[01:53:04.960 --> 01:53:10.000]   The retire guide provides a consolidated view of your retirement calculates your retirement gap
[01:53:11.040 --> 01:53:15.760]   They do tax loss harvesting so that helps you lower investment taxes and increase after tax returns
[01:53:15.760 --> 01:53:18.000]   This is this is what you've been looking for
[01:53:18.000 --> 01:53:21.680]   You don't have to think about it set it and forget it, but it gets the job done
[01:53:21.680 --> 01:53:30.080]   And of course there's no trade transaction or rebalancing fees no minimum to sign up
[01:53:30.080 --> 01:53:38.400]   And global diversification smart rebalancing and lower fees means you're going to get higher returns than the typical diy investor
[01:53:39.200 --> 01:53:41.520]   As with everything in life investing doesn't involve risk
[01:53:41.520 --> 01:53:45.680]   But right now you can get one month managed free when you make an initial deposit of ten thousand dollars or more
[01:53:45.680 --> 01:53:52.560]   If you've been looking for somewhere to roll your ira over into or somewhere to start building your financial future betterment
[01:53:52.560 --> 01:53:55.280]   dot com slash twig betterment
[01:53:55.280 --> 01:53:57.840]   dot com
[01:53:57.840 --> 01:53:59.040]   slash
[01:53:59.040 --> 01:54:02.240]   Twig betterment is investing made betta
[01:54:02.240 --> 01:54:05.440]   Now stacey, I don't want to put you on the hook
[01:54:05.760 --> 01:54:09.040]   But if you've got something to share with us, now'd be a good time
[01:54:09.040 --> 01:54:13.600]   Got it. Okay. I have a thing. It is not connected though
[01:54:13.600 --> 01:54:17.600]   Doesn't have to be doesn't have to be anything could be a movie
[01:54:17.600 --> 01:54:22.400]   Doesn't have to be anything could be anything. I really want to see it could be a cookie
[01:54:22.400 --> 01:54:25.360]   Logan's apparently very good
[01:54:25.360 --> 01:54:27.600]   That's that's that's what I hear. I can't wait
[01:54:27.600 --> 01:54:28.960]   um
[01:54:28.960 --> 01:54:32.960]   So what I have is because it just saved my butt at a slumber party
[01:54:33.440 --> 01:54:37.760]   And I meant I meant to bring it up for you guys because this is not just a slumber party thing
[01:54:37.760 --> 01:54:43.520]   But I didn't because I couldn't find it downstairs in the amount of time I had before the show starts
[01:54:43.520 --> 01:54:50.880]   But this is the fuji film insta max mini eight camera. Oh, oh, I'm very interested in these
[01:54:50.880 --> 01:54:56.400]   So here i'll show you a picture. Hold on. Let me grab it. This is basically polaroid
[01:54:56.400 --> 01:55:00.560]   Their instant their instant cameras are pointing shoot cameras
[01:55:01.440 --> 01:55:04.480]   So you see the camera. So this is the result of
[01:55:04.480 --> 01:55:13.120]   A picture and this is my niece took this picture of us at christmas and to to give you some perspective. This is my phone. So there's your
[01:55:13.120 --> 01:55:19.440]   It's about the size of your phone scream maybe a little smaller. Oh, no, it's it's like yeah half half the size
[01:55:19.440 --> 01:55:25.600]   Yeah, it's much smaller. It's a lot smaller. Okay, but they make so the films this white stuff
[01:55:25.600 --> 01:55:30.000]   You can buy films that have like different patterns on it if you're into that but
[01:55:30.880 --> 01:55:38.160]   It's 60 bucks for the camera each film pack is $10. Well, you can buy it for like $7 kids love these
[01:55:38.160 --> 01:55:45.120]   Kids love it. So I sent my daughter and her friend over who they were doing a slumber party and I sent them out on a video
[01:55:45.120 --> 01:55:46.560]   not a video
[01:55:46.560 --> 01:55:48.560]   Uh a scavenger hunt
[01:55:48.560 --> 01:55:52.560]   Uh photo scavenger hunt and yes, they could have taken a smartphone and taken the pictures
[01:55:52.560 --> 01:55:54.320]   but at
[01:55:54.320 --> 01:55:58.000]   10 years old they were super excited to actually take physical pictures
[01:55:58.400 --> 01:56:02.080]   And then they actually took the pictures that they took
[01:56:02.080 --> 01:56:10.160]   And they made like a little collage thing that you know, her cousin it was her cousin over took home with her so
[01:56:10.160 --> 01:56:14.320]   I don't know. I thought it was it was really awesome
[01:56:14.320 --> 01:56:18.320]   I made that a little awesome. Yeah, but kids really love these. I want to get the hello kitty one
[01:56:18.320 --> 01:56:21.840]   There you go
[01:56:21.840 --> 01:56:26.240]   The pink what are the red one? Oh pink of course
[01:56:27.680 --> 01:56:33.200]   It'd be funny either if if if I said oh let me I'd love to get a selfie with you can
[01:56:33.200 --> 01:56:35.680]   Would you like to and then pull that out?
[01:56:35.680 --> 01:56:43.040]   So they actually there's an accessory you can buy it's called the selfie mirror and you put it on there and you can actually take a selfie with
[01:56:43.040 --> 01:56:48.160]   Awesome, which awesome. I don't know I they're fun
[01:56:48.160 --> 01:56:52.240]   Yeah, no, they're not hackable
[01:56:53.600 --> 01:56:58.640]   And they're cheap and I hear I hear a lot of parents, you know, they're getting these for their kids
[01:56:58.640 --> 01:57:03.520]   They just kid I don't it's so funny because it's so retro next your kid will be wanting a dial phone
[01:57:03.520 --> 01:57:07.120]   Exactly. Well, I'm sure it's coming a fax machine
[01:57:07.120 --> 01:57:12.400]   Well now she now she understands the line and the uh, I think it's the black eyed piece song that shake it like a polaroid picture
[01:57:12.400 --> 01:57:16.640]   Yeah, uh, she's like oh, I get it. I now understand
[01:57:16.640 --> 01:57:19.760]   Shake it right for the right picture
[01:57:22.720 --> 01:57:24.720]   Nice jeff a number
[01:57:24.720 --> 01:57:27.120]   So even though this is obvious I liked it
[01:57:27.120 --> 01:57:32.080]   Play store google's play store. This is this week in google is five years old march 6
[01:57:32.080 --> 01:57:35.520]   2012 and the the top sellers in that half decade
[01:57:35.520 --> 01:57:40.160]   As the headline on the verge said it's exactly what you think it is, but what the heck let's see what it is
[01:57:40.160 --> 01:57:45.280]   Number one selling game installed game candy crush saga. Oh, that's sad
[01:57:45.280 --> 01:57:51.840]   Top installed apps facebook number one facebook messenger number two pendor number three top selling song
[01:57:52.400 --> 01:57:54.640]   Ed sheeran thinking out loud number one
[01:57:54.640 --> 01:57:58.640]   Huh lord broils number two tailors with playing space number three
[01:57:58.640 --> 01:58:01.600]   Albums
[01:58:01.600 --> 01:58:03.760]   One on that I am too. That one. That's the one surprised me here
[01:58:03.760 --> 01:58:06.720]   Doesn't he have a new album out
[01:58:06.720 --> 01:58:11.920]   Yeah, but I mean those are older songs lord five years. Yeah. Oh, okay. Yeah, it's interesting
[01:58:11.920 --> 01:58:14.400]   Top selling albums
[01:58:14.400 --> 01:58:19.040]   Adele 25 m&m the marshal mothers lp2 tailors swift 1989 again
[01:58:19.360 --> 01:58:21.840]   I would have thought that till a swift would have beat m&m
[01:58:21.840 --> 01:58:24.800]   Drake and Kendrick Lamar
[01:58:24.800 --> 01:58:29.200]   Top selling movies the interview frozen dead pool star wars
[01:58:29.200 --> 01:58:31.760]   interview I know
[01:58:31.760 --> 01:58:34.960]   This is weird
[01:58:34.960 --> 01:58:40.400]   And then for uh, holy android users top selling book is 50 shades of grave. Yeah
[01:58:40.400 --> 01:58:42.320]   No lord
[01:58:42.320 --> 01:58:46.720]   Then the hunger games trilogy and game of thrones you know why the interview you know why it's the interview
[01:58:47.200 --> 01:58:51.120]   For example because you could not see it in the theater right you had a mind you could see
[01:58:51.120 --> 01:58:57.120]   My client yeah, and and it was the hot thing in the moment. So that that that skewed it immensely
[01:58:57.120 --> 01:59:00.240]   It just shows you north korea if you hack somebody
[01:59:00.240 --> 01:59:03.200]   It just helps sales
[01:59:03.200 --> 01:59:07.200]   Because that nobody's just rice and rule now known as a strike and effect
[01:59:07.200 --> 01:59:10.080]   Yes, you the interview effect
[01:59:10.080 --> 01:59:12.880]   Jeff we share a brain
[01:59:12.880 --> 01:59:14.320]   Yes
[01:59:14.320 --> 01:59:16.320]   Oh, no, she says oh, no
[01:59:17.120 --> 01:59:22.400]   I was I was told that it was not the black ip's you're right. I'm sorry. It was outcast outcast
[01:59:22.400 --> 01:59:25.920]   Shake it like a polaroid a polaroid. Yes
[01:59:25.920 --> 01:59:31.520]   Shake it like a polaroid that's selling not streaming somebody's saying it's not streaming. It's selling
[01:59:31.520 --> 01:59:35.440]   Like buying the movie people didn't buy the interview that would be nuts
[01:59:35.440 --> 01:59:39.360]   Oh, i'm gonna watch this over and over again
[01:59:39.360 --> 01:59:44.880]   I'm gonna be watching this movie over and over and over again
[01:59:45.840 --> 01:59:49.280]   I don't have a pic. I I should have a pic
[01:59:49.280 --> 01:59:54.720]   Why don't I have a pic? I'm trying to think I was I thought I was gonna have this htc for today
[01:59:54.720 --> 02:00:01.920]   I guess I could I could pick the usbc digital the third three and a half millimeter audio jack adapter
[02:00:01.920 --> 02:00:08.560]   I really thought they you know this I was so excited yesterday said all FedEx is coming with a package from htc
[02:00:08.560 --> 02:00:11.840]   How much profit margin they lose on the sale because of that?
[02:00:12.640 --> 02:00:19.760]   What do you mean that they did a separate shipment for the for that dongle? That's a good point. I don't know on it on FedEx
[02:00:19.760 --> 02:00:24.880]   Yeah, that's crazy like I they over nighted me this this cable for a phone. I don't even have yet
[02:00:24.880 --> 02:00:29.040]   Again, maybe it's just you because you're famous
[02:00:29.040 --> 02:00:32.560]   No, I bought the you know, I bought I don't remember if I bought it separately
[02:00:32.560 --> 02:00:36.880]   But I did buy I did order an extra one because I thought well, you know, I have a lot of headphones
[02:00:36.880 --> 02:00:41.280]   Oh, you are all I see all right. There was in stock. So there it goes. It's in stock
[02:00:41.280 --> 02:00:46.480]   But the phone is not so instead of the htc you all through my pick of the week is this cable
[02:00:46.480 --> 02:00:54.240]   I really I thought I was gonna have to I was I was so excited. I was gonna show the phone. I was gonna do an unboxing
[02:00:54.240 --> 02:00:59.200]   Nothing now. I'll have to stick with the pixel. I still like the pixel. It's a beautiful thing
[02:00:59.200 --> 02:01:01.680]   I will mention that if you're using a google pixel
[02:01:01.680 --> 02:01:05.040]   Uh that you should probably get the free light room mobile
[02:01:05.040 --> 02:01:08.080]   uh for it it light room is
[02:01:09.840 --> 02:01:13.600]   Adobe's photo editing application and light room mobile on
[02:01:13.600 --> 02:01:18.400]   Only a few phones and pixels one of the few android phones does is will shoot not only
[02:01:18.400 --> 02:01:22.000]   Uh bra but now they've added hdr
[02:01:22.000 --> 02:01:28.720]   So you can and that's one of the reasons it can only do it on this phone because it takes three images very very rapidly
[02:01:28.720 --> 02:01:31.920]   Let's see if I could find a situation with some dark and some light
[02:01:31.920 --> 02:01:38.320]   And it you can't see it, but it took three images very very quickly right there to do high dynamic range
[02:01:39.120 --> 02:01:45.280]   It's free if you have an adobe account. It's even better because you can you know have your light room photos go from your desktop
[02:01:45.280 --> 02:01:47.040]   Uh to hear
[02:01:47.040 --> 02:01:52.400]   Um, this is this is nice. I think it's a really it really turns the pixel camera at something even better
[02:01:52.400 --> 02:01:57.120]   So if you have a pixel or an iPhone late model iPhone 6 6s or 7
[02:01:57.120 --> 02:02:00.880]   Um adobe light room great great choice
[02:02:00.880 --> 02:02:07.520]   The interviews box office was 11.3 million dollars. The budget was 44 million dollars
[02:02:08.240 --> 02:02:10.240]   So I hope they made it up in the rentals
[02:02:10.240 --> 02:02:12.480]   Yep
[02:02:12.480 --> 02:02:14.960]   Whoo
[02:02:14.960 --> 02:02:16.960]   Ladies and gentlemen, we are what
[02:02:16.960 --> 02:02:20.080]   No, do it do it
[02:02:20.080 --> 02:02:23.520]   Wrap it up. Do it. Do it layout. Do it
[02:02:23.520 --> 02:02:26.720]   We have concluded this exciting edition
[02:02:26.720 --> 02:02:29.840]   There's no news edition of this week in google
[02:02:29.840 --> 02:02:36.000]   You know what you should forget this show start listening stasis internet of things podcasts much more interesting with kevin toffle
[02:02:36.480 --> 02:02:41.040]   Stacey hagan botham iot podcast calm at gigastacey on
[02:02:41.040 --> 02:02:44.080]   The twitter are you gonna ever create a new twitter handle?
[02:02:44.080 --> 02:02:47.600]   No, that's who I am
[02:02:47.600 --> 02:02:50.560]   Gigas it is the truth. I mean
[02:02:50.560 --> 02:02:56.720]   I don't mind it. It's not like I worked for uber. Yeah. Yeah, you wouldn't want to be uber stacey
[02:02:56.720 --> 02:02:59.280]   I love your picture of the sydney opera house
[02:02:59.280 --> 02:03:02.320]   Oh, yeah
[02:03:02.320 --> 02:03:04.880]   That's an awesome right? I loved my trip. Yes. Yes
[02:03:04.880 --> 02:03:06.880]   Yes
[02:03:06.880 --> 02:03:11.760]   Thank you so much for being here stacey even though you could have struck
[02:03:11.760 --> 02:03:15.520]   I'm glad you didn't
[02:03:15.520 --> 02:03:21.280]   I will I will donate my stipend though. So nice. I think that's really great power to the people power to the people
[02:03:21.280 --> 02:03:24.240]   I'm a monthly. I'm a sustaining
[02:03:24.240 --> 02:03:27.280]   So contributor to plan parenthood actually
[02:03:27.280 --> 02:03:30.080]   Give them a hundred bucks every month
[02:03:30.960 --> 02:03:34.480]   I think that's a good thing to do. I do that for a number of I like doing the sustaining
[02:03:34.480 --> 02:03:35.840]   sustaining
[02:03:35.840 --> 02:03:43.360]   I want to do the sustaining but then people hit me up for like I know big events too and they're like oh, yeah, I know
[02:03:43.360 --> 02:03:45.440]   mr
[02:03:45.440 --> 02:03:48.640]   Jeff Jarvis he's professor journalism at city university of new york cuny
[02:03:48.640 --> 02:03:52.960]   He's also a blogger at buzz machine.com the author of many a great book including what would google do
[02:03:52.960 --> 02:03:55.840]   public parts geeks bearing
[02:03:55.840 --> 02:03:58.240]   news
[02:03:58.240 --> 02:04:02.720]   And he joins us every week you're going to be in london next week next week i'll be in london
[02:04:02.720 --> 02:04:07.280]   Guardian has two media conferences. So i'm speaking at the end you'll attempt to join us
[02:04:07.280 --> 02:04:10.880]   I will attempt to join us but but karstin you might be wise to have a guest
[02:04:10.880 --> 02:04:16.880]   We could do the ipd tl thing to see if that works international works really well for stacey. It's stacey. Oh, well
[02:04:16.880 --> 02:04:18.640]   It looks great. Actually
[02:04:18.640 --> 02:04:21.680]   It skips out a little bit. Uh, I I don't know if I
[02:04:21.680 --> 02:04:26.880]   I noticed I have a little bit of a pause and anytime I open up a new window to look at a story
[02:04:27.040 --> 02:04:33.040]   I don't hear you for a second. Oh, yeah, well that would make sense that would be a disadvantage of this you need a second computer
[02:04:33.040 --> 02:04:40.240]   All my budgets going to connect at home gadgets right now
[02:04:40.240 --> 02:04:44.880]   You should skype on one computer and do research on another computer
[02:04:44.880 --> 02:04:50.240]   Well, the truth is it looked great here. We may have dropped. Well, yeah as long as it works for y'all
[02:04:50.240 --> 02:04:52.000]   I'm just giving you that oh it worked for us. Yeah
[02:04:52.960 --> 02:04:54.960]   We'll try it with jeff next week
[02:04:54.960 --> 02:04:59.840]   Thank you everybody. We do this week in google every wednesday usually 130 we start a little bit early but about
[02:04:59.840 --> 02:05:02.720]   130 pm pacific for 30 eastern time
[02:05:02.720 --> 02:05:09.120]   21 30 utc if you want to join us would love to have you if you can join us in studio if you email tickets at twit.tv
[02:05:09.120 --> 02:05:13.120]   We'll put a chair out for you see us in the chat remierc.twits.tv
[02:05:13.120 --> 02:05:20.240]   And uh, if you can't on demand audio and video is always available for all of our shows in this case twit.tv/twig
[02:05:20.960 --> 02:05:25.840]   Or wherever you get your favorite podcast subscribe subscribe subscribe make sure you get every week
[02:05:25.840 --> 02:05:30.800]   So you don't want to miss an episode of this week in google. See you next time
[02:05:30.800 --> 02:05:43.680]   [Music]

