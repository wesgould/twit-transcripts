;FFMETADATA1
title=You Got Something Jammed in There Good
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=386
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.200]   It's time for Twig this week and Google. Jeff Jarvis is here for our first show of the New Year.
[00:00:04.200 --> 00:00:07.440]   Matthew Ingram from Fortune as well. We'll talk about...
[00:00:07.440 --> 00:00:16.320]   Why we get heavy again. We get deep. We talk about disruption, how the world is changing,
[00:00:16.320 --> 00:00:19.840]   why it's the end of mass media. And...
[00:00:19.840 --> 00:00:24.560]   Wow, those are some really cool things you can get at CES. It's all coming up next on Twig.
[00:00:27.600 --> 00:00:30.960]   NetCasts you love. From people you trust.
[00:00:30.960 --> 00:00:36.320]   This is Twig.
[00:00:36.320 --> 00:00:44.320]   Bandwidth for this week in Google is provided by CashFly, C-A-C-H-E-F-L-Y.com.
[00:00:44.320 --> 00:00:55.120]   This is Twig this week in Google. Episode 386 recorded Wednesday, January 4th, 2017.
[00:00:55.120 --> 00:01:00.880]   You got something jammed in there good. This week in Google is brought to you by Betterment,
[00:01:00.880 --> 00:01:07.040]   a smart, easy-to-use, and less expensive way to invest for your financial future.
[00:01:07.040 --> 00:01:10.720]   For more information visit Betterment.com.
[00:01:10.720 --> 00:01:16.160]   It's time for Twig this week at Google the first show of 2017.
[00:01:16.160 --> 00:01:23.120]   Joining us at the Twig table, not Stacey Higginbotham. She's skying her way to Las Vegas
[00:01:23.120 --> 00:01:28.480]   for the big consumer electronics show. And we'll have lots of IoT news next week on Twig.
[00:01:28.480 --> 00:01:30.560]   But Jeff Jarvis is here. In fact, this is...
[00:01:30.560 --> 00:01:36.240]   It's the old guys edition because we're the guys senior enough not to have to go to CES.
[00:01:36.240 --> 00:01:42.560]   Our old lady shoes just don't make walk enough far working work.
[00:01:42.560 --> 00:01:48.560]   Jeff Blogs at Buzz Machine.com professes journalism at the City University of New York
[00:01:49.120 --> 00:01:54.960]   in Manhattan and has written many great books including what would Google do, public parts,
[00:01:54.960 --> 00:02:01.440]   Gutenberg the Geek, the Geek's Bearing Gift. It's also with us from Fortune. Matthew Ingram
[00:02:01.440 --> 00:02:07.440]   Stacey's first-while collaborator at Gigah Oum. Now at Fortune.com. I guess you were there
[00:02:07.440 --> 00:02:13.760]   briefly with her too. He's up in the American North.
[00:02:13.760 --> 00:02:20.080]   America North we call it. A.K.A. Canadian. Canuckistan.
[00:02:20.080 --> 00:02:28.800]   Did you have a lovely holiday break? It was great. Yeah. I'm currently working on losing all
[00:02:28.800 --> 00:02:32.960]   the pounds I gained. Yeah, me too. Did it snow? Did you get away Christmas?
[00:02:32.960 --> 00:02:40.480]   We did. Actually, we were even further north at a friend's farm and there was probably a foot
[00:02:40.480 --> 00:02:45.680]   and a half of fresh snow. It was beautiful. No snow for New York, right? Jeff?
[00:02:45.680 --> 00:02:48.800]   No, then I went to Florida to see my folks. Definitely no snow there.
[00:02:48.800 --> 00:02:56.400]   No. No. I foolishly for the week after Christmas went to Rhode Island. Probably.
[00:02:56.400 --> 00:03:01.440]   I wasn't. Well, unfortunately my mom's there. So that made it worthwhile. It was great to see her
[00:03:01.440 --> 00:03:07.920]   and my sister. But there was no either snow nor heat nor warmth.
[00:03:08.960 --> 00:03:14.480]   No palm trees. No, I was thinking you took a poor child into the cold. I did. Michael went with us.
[00:03:14.480 --> 00:03:19.600]   He kicked me in screaming. He's 14. Never had been to New England. Said, "What am I going to see?
[00:03:19.600 --> 00:03:26.160]   What's there?" Fortunately, the hotel was connected via tunnel to a buster and David busters.
[00:03:26.160 --> 00:03:32.800]   Nice. So it all worked out. Perfect. Yeah, it all worked out very nicely.
[00:03:32.800 --> 00:03:38.720]   We also went up to Boston for a day. I love Boston. It's always fun to go to Boston.
[00:03:38.880 --> 00:03:45.040]   It is. We visited the Boston Common, the frozen tundra, the squirrels, just as aggressive as ever.
[00:03:45.040 --> 00:03:52.480]   Fen oil haul. How do you pronounce that? Fen oil? Fennial? Fennial? I should ask a
[00:03:52.480 --> 00:03:58.320]   Bostonian. Good question. Yeah. Spelt FA and E-I-U-L or something like that.
[00:03:58.320 --> 00:04:03.120]   It's probably funnel. Fun. It's probably, but it has cat pack.
[00:04:03.760 --> 00:04:10.480]   Cat pack haul. I saw the Old North Church and went to the Boston Museum of Science,
[00:04:10.480 --> 00:04:14.480]   which is still the best science museum in the world. Oh, I haven't been there.
[00:04:14.480 --> 00:04:20.560]   It's the original. It really is awfully good. I ran around Harvard trying to figure out which
[00:04:20.560 --> 00:04:27.280]   room was Mark Zuckerberg's. Ah, that's fun. Hey, what did Mark Zuckerberg do for Christmas?
[00:04:28.720 --> 00:04:33.840]   He found he learned a new language or something. Yeah. Well, he did. He found God. He's no longer
[00:04:33.840 --> 00:04:42.480]   an atheist. Yeah. But he wasn't, he was kind of coy about what exactly he was. Well, he was, he was
[00:04:42.480 --> 00:04:46.320]   not, he was, yeah, he was, I guess, I don't know. Do he actually find God or does he switch to,
[00:04:46.320 --> 00:04:53.520]   switch from it's complicated to agnostic? You know, I think he suggested he believes there's
[00:04:54.880 --> 00:05:01.680]   some sort of higher power. Happy Christmas and happy Hanukkah and Merry Christmas from
[00:05:01.680 --> 00:05:07.680]   Priscilla Mark, Beast, his dog, and me to which one user replied that was his Facebook post.
[00:05:07.680 --> 00:05:12.960]   Aren't you an atheist? No, Zuckerberg responded. I was raised Jewish. And then I went through a
[00:05:12.960 --> 00:05:18.560]   period when I questioned things, but now I believe, oh boy, this is fudge words. Religion is very
[00:05:18.560 --> 00:05:23.440]   important. Yeah. I don't think that's what they mean, Mark, when they say, I believe,
[00:05:24.480 --> 00:05:30.000]   I believe religion is very important. So he believes in all religions, I guess.
[00:05:30.000 --> 00:05:34.160]   That's my religion. I went back to visit the church that I went to as a child,
[00:05:34.160 --> 00:05:37.520]   the first Unitarian Church of Providence, Rhode Island, where I was taught.
[00:05:37.520 --> 00:05:40.880]   Yeah, he uses worship God. You guys believe in every choice. Yes. Yeah.
[00:05:40.880 --> 00:05:46.640]   It's not even a church, really. It's more of a club. It's a club. And mostly Jewish,
[00:05:46.640 --> 00:05:49.120]   actually, which is very weird. Really? Yeah. Interesting.
[00:05:50.560 --> 00:05:56.080]   Well, yeah, you can't actually be Jewish and believe in other sort of faith-based things.
[00:05:56.080 --> 00:06:00.080]   Yeah. Fair enough. That's not Mark. That's why I'm explicit what Mark means.
[00:06:00.080 --> 00:06:08.240]   He also announced that his project for 2017 is to talk to people in every state, all 50 states.
[00:06:08.240 --> 00:06:15.760]   Yeah. How is he? Is he got a plan for that? How is he going to do that? Is he going to do town halls?
[00:06:15.760 --> 00:06:20.240]   I'm going to travel by blimp, I think. No, by drone.
[00:06:20.240 --> 00:06:23.840]   Just touch down. Touch down. What's the name of their drone?
[00:06:23.840 --> 00:06:27.680]   A kilo. A kilo. A kilo. A rocket. A rocket.
[00:06:27.680 --> 00:06:32.960]   If you're sitting on your... So this leads to speculation that he's going to run for president.
[00:06:32.960 --> 00:06:36.400]   Do you buy that? Yes. That's why I understand the speculation.
[00:06:36.400 --> 00:06:41.520]   And I think he's going from denying that he's a media platform to saying,
[00:06:41.520 --> 00:06:46.960]   "Hey, actually I want to run for president." Well, and he did the whole structure of the...
[00:06:46.960 --> 00:06:55.200]   What came out in that lawsuit over the share restructuring was that he specifically wanted to
[00:06:55.200 --> 00:07:01.440]   leave the door open to potentially running for office or getting involved.
[00:07:01.440 --> 00:07:05.280]   Oh, you're kidding. That was given as a reason. Well, if he goes to work for government.
[00:07:05.280 --> 00:07:10.640]   Yes, he can go. Yes, to work for government. There's a clause that allows him to retain ownership,
[00:07:10.640 --> 00:07:15.360]   even if he goes to... And I think Mark Andreessen was saying that's not going to fly with the board.
[00:07:15.360 --> 00:07:23.280]   The board. What about the... A monument's clause of the Constitution? Forget the board.
[00:07:23.280 --> 00:07:28.160]   Oh, wait a minute. That's out the window. That's out the window. I'm sorry, I forgot.
[00:07:28.160 --> 00:07:32.880]   Actually, it makes sense because I think you can make a very strong case that
[00:07:34.080 --> 00:07:41.520]   President Trump got won the election by being very adept in his use of Facebook and Twitter.
[00:07:41.520 --> 00:07:45.840]   More Twitter. No, Twitter. Okay, so I've been thinking about this.
[00:07:45.840 --> 00:07:50.960]   Twitter for sure, because it allows him to speak directly to the people much like those rallies.
[00:07:50.960 --> 00:07:57.040]   Where he's un-intermediated by media, which of course is the goal of every politician,
[00:07:57.040 --> 00:08:01.200]   get the media out of this interpreting when I'm saying, I want to talk to the people directly.
[00:08:01.200 --> 00:08:05.840]   FDR started it with fireside jets, right? As soon as there was mass media
[00:08:05.840 --> 00:08:10.080]   presidents and politicians have tried to go direct to the elect. Radio. Can't really,
[00:08:10.080 --> 00:08:14.080]   can't say that's a bad thing. And he's used Twitter really to great effect that way.
[00:08:14.080 --> 00:08:20.720]   But I'm saying that it was his... The strategy and probably really the strategy of his son-in-law,
[00:08:20.720 --> 00:08:23.200]   Jared Kushner. Jared Kushner.
[00:08:23.200 --> 00:08:29.600]   To use Facebook very efficiently and very effectively to both...
[00:08:29.600 --> 00:08:32.240]   Because the advertising, yes. Yes. To both target.
[00:08:32.240 --> 00:08:32.960]   Yes. To both target.
[00:08:32.960 --> 00:08:35.120]   To both target targeting. Yeah. That's the best.
[00:08:35.120 --> 00:08:40.160]   Because they bought ads that would encourage people who would vote for Trump to vote for Trump.
[00:08:40.160 --> 00:08:45.360]   But they also, we understand, bought ads to encourage others to sit by the wayside.
[00:08:45.360 --> 00:08:49.520]   Ah, don't vote. And that was smart. Very smart.
[00:08:49.520 --> 00:08:54.400]   And they used Cambridge Analytica to target super precisely.
[00:08:54.400 --> 00:08:56.640]   I was talking to an old friend in radio this morning.
[00:08:57.600 --> 00:09:00.800]   And he said, "Leo, I'm glad both of us are at the end of our careers because,
[00:09:00.800 --> 00:09:08.880]   frankly, mainstream media cannot compete." And this is by the way,
[00:09:08.880 --> 00:09:13.360]   while you're seeing such huge profits for Google and Facebook, mainstream media cannot
[00:09:13.360 --> 00:09:22.960]   compete in the ads it offers with this highly targeted, really powerful media of the internet,
[00:09:22.960 --> 00:09:25.200]   of a particular Facebook and Google. It's true.
[00:09:25.200 --> 00:09:33.280]   Yeah, it's true. I just wrote about it today. Their control over 85, 90% at least of the growth
[00:09:33.280 --> 00:09:35.760]   in digital advertising went to those two companies.
[00:09:35.760 --> 00:09:38.000]   So that leaves... Because they offer... Two percent?
[00:09:38.000 --> 00:09:41.600]   They offer more effectiveness. They offer more value.
[00:09:41.600 --> 00:09:45.200]   Did you see big news from big half news from medium?
[00:09:45.200 --> 00:09:48.240]   It looks like it is basically giving up on advertising.
[00:09:48.240 --> 00:09:50.640]   It sounds a lot... Why?
[00:09:50.640 --> 00:09:53.120]   Down at the bottom of the other... And letting go a third of it.
[00:09:53.120 --> 00:09:54.480]   That was announced much.
[00:09:54.480 --> 00:09:58.480]   He's saying, "We're not going to do advertising. What are we..." He's pivoting.
[00:09:58.480 --> 00:10:03.840]   A third of the staff. So everything to do with advertising, it sounds like it's gone.
[00:10:03.840 --> 00:10:10.160]   And he's going to try and compensate writers and publishers based on value.
[00:10:10.160 --> 00:10:14.160]   50 jobs. Mostly it's sales, support, and other business functions.
[00:10:14.160 --> 00:10:16.480]   He's closing New York. He's closing Washington.
[00:10:16.480 --> 00:10:17.280]   And Washington.
[00:10:19.200 --> 00:10:24.720]   And he's saying that advertising is responsible for various ills in society.
[00:10:24.720 --> 00:10:29.200]   And it's not working in media. We need a new model.
[00:10:29.200 --> 00:10:32.960]   But then he doesn't say, "Well, keep on going down. We're building this new model."
[00:10:32.960 --> 00:10:35.200]   Further reflection. Blah, blah, blah, blah.
[00:10:35.200 --> 00:10:37.840]   We decided to need a different boulder approach. Blah, blah, blah, blah.
[00:10:37.840 --> 00:10:41.520]   It's too soon to say exactly what this will look like.
[00:10:41.520 --> 00:10:44.240]   This strategy is more focused, but less proven.
[00:10:44.240 --> 00:10:48.400]   It will require time to get it right, as well as some different skills.
[00:10:48.400 --> 00:10:49.440]   That's all he says.
[00:10:49.440 --> 00:10:53.600]   Yeah. And he says that... So in the paragraph above that, it says,
[00:10:53.600 --> 00:10:57.760]   "writers and creators should be rewarded based on the value they're creating."
[00:10:57.760 --> 00:11:00.560]   But it's not clear how that value is going to be measured.
[00:11:00.560 --> 00:11:02.880]   Is it going to be measured on time spent?
[00:11:02.880 --> 00:11:06.800]   Is it paying in psychic dollars in heaven?
[00:11:06.800 --> 00:11:10.880]   In frequent flyer miles?
[00:11:10.880 --> 00:11:18.320]   Yeah, because if you're not monetizing... Well, this is sounds more like a philosophical
[00:11:18.320 --> 00:11:21.520]   decision on Ev's part than an business decision.
[00:11:21.520 --> 00:11:26.160]   I mean, the moral you could take away from you, and this is your article,
[00:11:26.160 --> 00:11:31.520]   Matt, in Fortune, how Google and Facebook have taken over the digital additive industry,
[00:11:31.520 --> 00:11:35.440]   which is clearly the case. The moral you could take away from that, if your Ev is,
[00:11:35.440 --> 00:11:40.320]   well, that's where I need to go, because I could gather that same information about my readers
[00:11:40.320 --> 00:11:43.440]   and offer the same kind of granular advertising that Facebook is.
[00:11:44.560 --> 00:11:49.440]   So he's decided from a purely philosophical point of view, he doesn't want to go down that road.
[00:11:49.440 --> 00:11:53.440]   Well, and I think he also... He made it clear it's not working.
[00:11:53.440 --> 00:11:56.560]   That's the incentive... He hasn't gone all in a rough.
[00:11:56.560 --> 00:11:59.360]   Yeah, yeah, it's not working. Well, they've tried a number.
[00:11:59.360 --> 00:12:03.600]   They've tried native, they've tried sponsored content, they've tried...
[00:12:03.600 --> 00:12:08.480]   They did a deal with BMW for a... Oh, that's wrong. That's all wrong.
[00:12:08.480 --> 00:12:13.040]   That's not what Facebook does. And no, it's not.
[00:12:13.920 --> 00:12:19.840]   It's all old school, even native, which feels like the new thing is, which is not, of course,
[00:12:19.840 --> 00:12:24.080]   is all old school mass advertising. Right.
[00:12:24.080 --> 00:12:29.280]   And where Facebook and Google are winning, and I would guess this is what you talk about in your
[00:12:29.280 --> 00:12:33.680]   article, is by highly targeted advertising. Yeah.
[00:12:33.680 --> 00:12:39.600]   I mean... Right, they understand their users in a way that most media companies do not,
[00:12:39.600 --> 00:12:42.640]   and probably never will. And there's a corollary... Especially at scale.
[00:12:42.640 --> 00:12:45.520]   There's a corollary to that because the advertisers and the business
[00:12:45.520 --> 00:12:47.680]   who are going to succeed are the people who understand that.
[00:12:47.680 --> 00:12:49.680]   This was I was talking about this morning,
[00:12:49.680 --> 00:12:52.080]   starting with Bill Handel as the morning host at KFI,
[00:12:52.080 --> 00:12:59.440]   is that you can't compete. I mean, I guess Coca-Cola
[00:12:59.440 --> 00:13:05.920]   and Procter & Gamble will still spend ad dollars on branding. What do you think?
[00:13:05.920 --> 00:13:07.840]   Sure. Sure. I mean, I think...
[00:13:07.840 --> 00:13:11.120]   Well, it was time for me to be more efficient,
[00:13:11.120 --> 00:13:15.200]   even for branding ads, where all you're trying to do is get the brand name out there.
[00:13:15.200 --> 00:13:20.480]   If you did it in a more targeted way, look at the kinds of things Trump did, for instance,
[00:13:20.480 --> 00:13:25.040]   using Cambridge Analytica, and I've mentioned this before, is it wasn't merely,
[00:13:25.040 --> 00:13:30.000]   oh, let's see who's going to vote for Trump based on gun control and do a pro-gun ad.
[00:13:30.000 --> 00:13:35.920]   It wasn't even that broad a brush. It was, let's... Okay, we're going to do an ad that says,
[00:13:35.920 --> 00:13:42.160]   Trump favors the Second Amendment. But what we're going to do is those ads will be further tailored
[00:13:42.160 --> 00:13:49.360]   depending on the target audience. So if you believe that you need guns because you fear government
[00:13:49.360 --> 00:13:55.200]   or crime, you would have an ad that highlights crime or an ad that highlights government.
[00:13:55.200 --> 00:13:58.640]   If you want to have guns because you're a hunter, you'd have an... So you target...
[00:13:58.640 --> 00:14:03.920]   If you even to a motion, if you're a happy-go-lucky type, you have an ad that targets a hunter
[00:14:03.920 --> 00:14:08.800]   who's happy-go-lucky, and then a different ad that targets a hunter who's depressed.
[00:14:08.800 --> 00:14:15.680]   And that kind of granularity, even for Coca-Cola, I would think would be more efficient.
[00:14:15.680 --> 00:14:21.680]   Although it's interesting that not that long ago Proctor & Gamble said that it was...
[00:14:21.680 --> 00:14:30.320]   it sort of coached it in vague terms, but it sounded like they were not as enthusiastic about
[00:14:30.320 --> 00:14:36.160]   the sort of targeted approach for all things, that not that they were shrinking their Facebook
[00:14:36.160 --> 00:14:41.440]   budget, but that it was probably not going to grow by as much as they had said earlier.
[00:14:41.440 --> 00:14:43.680]   A number of brands abandoned Facebook, didn't they?
[00:14:43.680 --> 00:14:49.600]   And in effect, they said targeting works for certain things, but we do lots of other things
[00:14:49.600 --> 00:14:55.200]   that targeting doesn't work. So it could be that their own business is evolving and they have to
[00:14:55.200 --> 00:14:56.320]   figure out how to... That's wrong.
[00:14:57.200 --> 00:15:02.160]   Or they think brand new. Well, they like media are addicted to something from the past.
[00:15:02.160 --> 00:15:04.400]   Right. The bottom-bottom line, Leo,
[00:15:04.400 --> 00:15:09.040]   with the internet killed as mass media's business model and thus mass media. Precisely.
[00:15:09.040 --> 00:15:13.920]   It affects us not just on the ad side, it affects us in our product side.
[00:15:13.920 --> 00:15:15.840]   What we are, we're still putting out mass products.
[00:15:15.840 --> 00:15:19.920]   Look at the election, not just in Cambridge,
[00:15:19.920 --> 00:15:24.000]   at Litticott, but look at it in terms of memes and things that people passed around.
[00:15:25.040 --> 00:15:32.000]   We just can't think, get our heads around thinking that way in media. And it's insolvable if we still
[00:15:32.000 --> 00:15:35.680]   stick to the ways we used to do things. But it's even more than this. I want to bounce this off you guys.
[00:15:35.680 --> 00:15:39.520]   So I've been thinking, partly out of the fake news,
[00:15:39.520 --> 00:15:46.080]   grew ha ha ha, but I've been thinking to about this idea that all of journalism's tools are
[00:15:46.080 --> 00:15:52.080]   reductive. Right. We reduce complexity to a simple narrative with a story arc. We reduce things to
[00:15:53.120 --> 00:15:58.240]   opinion poll where the poster chooses the agenda to a data visualization,
[00:15:58.240 --> 00:16:02.480]   in fact checking. In fact, of course, the world is far more complex than that.
[00:16:02.480 --> 00:16:09.360]   And Google and Facebook and this whole fake news thing are being shoved into media's metaphors.
[00:16:09.360 --> 00:16:12.720]   You have to do fact checking and you have to get rid of fake news and you have to do this and you do
[00:16:12.720 --> 00:16:18.800]   that. And Google and Facebook for their part say, oh, we just reflect the world, we don't make it.
[00:16:18.800 --> 00:16:22.880]   Right. When you type in, Jews are in the search bar, it comes up with awful stuff.
[00:16:22.880 --> 00:16:25.520]   That's because there's awful people out there doing stuff. And sorry, that's not our fault.
[00:16:25.520 --> 00:16:32.480]   They can't say that anymore because it's the world is being warped to exploit them.
[00:16:32.480 --> 00:16:36.160]   Right. It's always happened to us in media with PR, but it's being warped to exploit the
[00:16:36.160 --> 00:16:41.120]   algorithms of Google and Facebook. So my argument is finally that Google and Facebook have to have
[00:16:41.120 --> 00:16:47.120]   the capability to draw far more complex maps of the world and controversies and understanding
[00:16:47.120 --> 00:16:52.080]   where things are going on and where they are. I'll bet the alt right fault fight that got Trump
[00:16:52.080 --> 00:16:57.120]   elected was actually started with maybe 100 people. It's probably very small and it got reflected
[00:16:57.120 --> 00:17:02.480]   and amplified by media and then by social media and then by purchase of things that you just
[00:17:02.480 --> 00:17:07.760]   talked about. And I think of what we have to do in both media and the platforms is be able to
[00:17:07.760 --> 00:17:13.120]   reflect and understand and analyze through new tools, through artificial intelligence and
[00:17:13.120 --> 00:17:18.960]   learning systems, a far more complex picture than we ever could do in the past. So it goes to
[00:17:18.960 --> 00:17:23.840]   advertising, everything you've just said. That also plays back to the content itself.
[00:17:23.840 --> 00:17:27.440]   Why should I read the same newspaper you read? We're different people. You didn't like Lala
[00:17:27.440 --> 00:17:30.240]   Lam's screen. Do you have that capability at this point of?
[00:17:30.240 --> 00:17:36.800]   Well, I also wonder whether there were some social benefits you could argue to mass media.
[00:17:36.800 --> 00:17:39.520]   There were social benefits to have a common conversation.
[00:17:39.520 --> 00:17:41.360]   Right. Common conversations, share.
[00:17:41.360 --> 00:17:47.920]   But what happens when everyone's having their own conversation in a narrow
[00:17:47.920 --> 00:17:50.240]   group with four television killed the third.
[00:17:50.240 --> 00:17:50.880]   No, I know we did.
[00:17:50.880 --> 00:17:52.080]   The papers in towns, right?
[00:17:52.080 --> 00:17:52.480]   I know we did.
[00:17:52.480 --> 00:17:53.040]   We had that.
[00:17:53.040 --> 00:17:55.040]   But we're talking about it worked.
[00:17:55.040 --> 00:17:55.520]   We got there.
[00:17:55.520 --> 00:17:59.200]   We're talking about expanding that by orders of magnitude. We're talking about having
[00:17:59.200 --> 00:18:04.400]   micro conversations about micro issues with everyone else who already agrees with them.
[00:18:04.400 --> 00:18:07.840]   Where it gets scary to me is tribalism.
[00:18:07.840 --> 00:18:12.160]   And we've seen that. That's exactly what happened during the election.
[00:18:12.160 --> 00:18:15.600]   Tribes can be good in bed. Sebastian Joger has a book called Tribes Out,
[00:18:15.600 --> 00:18:17.840]   in which he argues that there are benefits to tribes.
[00:18:17.840 --> 00:18:21.440]   It goes back to the other's getting of America.
[00:18:21.440 --> 00:18:24.720]   Historic, no, goes back to the beginning of the human beings.
[00:18:24.720 --> 00:18:26.720]   Exactly. Evolutionary benefits.
[00:18:26.720 --> 00:18:29.280]   Evolutionary benefits to tribalism.
[00:18:29.280 --> 00:18:29.840]   Absolutely.
[00:18:29.840 --> 00:18:32.320]   If you're in the right tribe, there's a benefit.
[00:18:32.320 --> 00:18:34.720]   Well, but if you're competing if all tribes are competing.
[00:18:34.720 --> 00:18:45.200]   Settlers, white people, settlers from Europe, were taken prisoner by Native American tribes.
[00:18:45.200 --> 00:18:48.000]   And then so-called rescued back and they couldn't stand it.
[00:18:48.000 --> 00:18:49.360]   They went back to the tribes.
[00:18:49.360 --> 00:18:55.360]   Tribalism done well is a powerful and force for good.
[00:18:55.360 --> 00:18:57.520]   Tribalism done badly is a mob.
[00:18:57.520 --> 00:18:58.960]   It's an evolutionary force.
[00:18:58.960 --> 00:19:00.800]   Well, as you get the good and the bad.
[00:19:00.800 --> 00:19:01.280]   Yeah.
[00:19:01.280 --> 00:19:02.880]   So we saw tribes.
[00:19:02.880 --> 00:19:04.320]   We saw tribes.
[00:19:04.320 --> 00:19:05.200]   What do you fear about tribes?
[00:19:05.200 --> 00:19:06.720]   Well, go ahead.
[00:19:06.720 --> 00:19:14.720]   We saw tribes voting for Trump based on lies, based on things he said that simply weren't true.
[00:19:14.720 --> 00:19:18.240]   Based on, so that's a problem, I think.
[00:19:18.240 --> 00:19:25.760]   And if we're, if they're being served by media and by technology that confirms their assumptions,
[00:19:25.760 --> 00:19:32.000]   even if they're based on inaccuracies or things that just simply are true,
[00:19:32.000 --> 00:19:34.320]   then how does that benefit anyone?
[00:19:34.320 --> 00:19:35.680]   That's media.
[00:19:35.680 --> 00:19:38.160]   That's we're not doing a good job.
[00:19:38.160 --> 00:19:39.040]   It's basically-
[00:19:39.040 --> 00:19:43.040]   I argue constantly that we in liberal media and I'm liberal and I'm media,
[00:19:43.040 --> 00:19:46.720]   abandoned the right half of America ever since Watergate,
[00:19:46.720 --> 00:19:49.200]   conservatives have not trusted media and we have not served them.
[00:19:49.200 --> 00:19:52.400]   And we left a vacuum that was filled in by the likes of Fox News and Breitbart.
[00:19:52.400 --> 00:19:57.920]   And before you go tweeting and emailing me, I'm being sympathetic and empathetic to saying that,
[00:19:57.920 --> 00:20:02.400]   yes, liberal media has ill served conservative America.
[00:20:02.400 --> 00:20:04.320]   And that's why we're in this boat.
[00:20:04.320 --> 00:20:07.360]   I think it's kind of the best in conservative media.
[00:20:07.360 --> 00:20:08.400]   I've involved with this-
[00:20:08.400 --> 00:20:08.800]   But if we just-
[00:20:08.800 --> 00:20:16.160]   This narrative, because I think that the narrative, while true, it doesn't grasp the real shift
[00:20:16.160 --> 00:20:18.320]   that's happening.
[00:20:18.320 --> 00:20:20.000]   Go ahead, Matthew, and I'll talk about what I'm-
[00:20:20.000 --> 00:20:20.800]   No, no, you go ahead.
[00:20:20.800 --> 00:20:22.560]   Because-
[00:20:22.560 --> 00:20:26.320]   Okay, so I've been rereading Howard Zinn's People's History of the United States,
[00:20:26.320 --> 00:20:30.720]   which is really a great book to read, if only because it's a knock in the head.
[00:20:30.720 --> 00:20:34.560]   It's like when you look at the map of the world and you turn it upside down and say,
[00:20:34.560 --> 00:20:36.480]   there isn't really an up and down.
[00:20:36.480 --> 00:20:39.760]   As you know, it's just Eurocentric that we see the-
[00:20:39.760 --> 00:20:43.680]   You know, us in the middle in Australia, it could be the other way around.
[00:20:43.680 --> 00:20:45.120]   Because it's a globe.
[00:20:45.120 --> 00:20:47.840]   So his book is very much like that.
[00:20:47.840 --> 00:20:52.640]   It kind of reassesses American history in the light of a kind of a more Marxist, frankly,
[00:20:52.640 --> 00:20:54.160]   point of view.
[00:20:54.160 --> 00:20:55.600]   And-
[00:20:55.600 --> 00:21:02.080]   Which is a way that I've started to be thinking about what's been happening in our society,
[00:21:02.080 --> 00:21:05.760]   not just in the US, but globally, in the last few years.
[00:21:06.400 --> 00:21:12.720]   And so I guess what I'm thinking is, and what his kind of thesis is,
[00:21:12.720 --> 00:21:17.120]   that the coalitions, these kind of common conversations that we talked about, these coalitions,
[00:21:17.120 --> 00:21:20.400]   are really themselves phony.
[00:21:20.400 --> 00:21:24.160]   They're created for a variety of reasons.
[00:21:24.160 --> 00:21:29.440]   He says the founding fathers, for instance, were basically landholders.
[00:21:29.440 --> 00:21:30.320]   They were wealthy.
[00:21:30.320 --> 00:21:32.400]   George Washington was the wealthiest man in the country,
[00:21:33.120 --> 00:21:41.680]   who decided that it was- that their real threat to them was Indians, slaves,
[00:21:41.680 --> 00:21:43.440]   and indentured white servants.
[00:21:43.440 --> 00:21:46.240]   A revolt by them would have overpowered them.
[00:21:46.240 --> 00:21:49.600]   They wanted to consolidate their control.
[00:21:49.600 --> 00:21:53.040]   And the best way to control it was to create patriotism,
[00:21:53.040 --> 00:21:59.120]   and to find a new enemy, a common enemy, Britain, and distract them.
[00:21:59.120 --> 00:22:03.920]   Because there were a number of popular revolts prior to the revolution
[00:22:03.920 --> 00:22:06.320]   that really threatened these landholders.
[00:22:06.320 --> 00:22:10.000]   And- which is a very interesting recontextualization.
[00:22:10.000 --> 00:22:14.960]   I'm not saying it's true or false, but it's an interesting recontextualization.
[00:22:14.960 --> 00:22:20.720]   And in that light, what we kind of honor as this, you know, national conversation,
[00:22:20.720 --> 00:22:26.240]   and our vision of what democracy- I won't just say America, you're from Canada,
[00:22:26.240 --> 00:22:32.400]   it's the same vision, this kind of liberal vision is really a historic.
[00:22:32.400 --> 00:22:34.720]   And it really isn't a common point.
[00:22:34.720 --> 00:22:35.920]   Do you believe in the nation?
[00:22:35.920 --> 00:22:39.040]   Do you believe it is the nation a necessary institution?
[00:22:39.040 --> 00:22:44.000]   His point is the nation was a creation of an upper class.
[00:22:44.000 --> 00:22:46.240]   The middle class itself was a creation of an upper class.
[00:22:46.240 --> 00:22:49.280]   The notion that you could rise to the upper class was creation,
[00:22:49.280 --> 00:22:56.080]   to preserve, you know, civilization so that they could continue to-
[00:22:56.080 --> 00:22:57.280]   to amass fortunes.
[00:22:57.280 --> 00:23:01.280]   And in that light, if you think about it in that light, that's the-
[00:23:01.280 --> 00:23:03.840]   you're holding up in a book, the institutional resolution.
[00:23:03.840 --> 00:23:06.000]   I'll tell you about that as I can go on that.
[00:23:06.000 --> 00:23:10.880]   Well, the best way to bring your tribe together is to find an enemy to attack.
[00:23:10.880 --> 00:23:11.600]   A common enemy.
[00:23:11.600 --> 00:23:13.680]   Which is exactly what happened in this election.
[00:23:13.680 --> 00:23:13.840]   Yes.
[00:23:13.840 --> 00:23:19.040]   And one- if one is in a tribe, one might want to consider
[00:23:19.040 --> 00:23:24.960]   whether that common enemy is- who's benefiting from that?
[00:23:24.960 --> 00:23:25.120]   Right.
[00:23:25.120 --> 00:23:25.600]   Right.
[00:23:25.600 --> 00:23:30.880]   And it also- I think we've seen abundant evidence that in those types of
[00:23:30.880 --> 00:23:36.560]   situations where the tribe is united against a common enemy,
[00:23:36.560 --> 00:23:43.440]   with a vision of whatever their good might be, truth takes a back seat.
[00:23:43.440 --> 00:23:45.280]   It literally does not matter.
[00:23:45.280 --> 00:23:50.960]   And unfortunately, we have engines like Facebook that are machines for confirmation
[00:23:50.960 --> 00:23:56.000]   by it. So they effectively encourage you to share things that fit your worldview,
[00:23:56.000 --> 00:23:57.360]   regardless of whether they're true.
[00:23:57.360 --> 00:24:00.080]   That they're trying to adapt that.
[00:24:00.080 --> 00:24:02.080]   That's not Facebook's fault.
[00:24:02.080 --> 00:24:02.880]   I'm not saying they're doing it.
[00:24:02.880 --> 00:24:04.640]   No, I think Facebook's reflecting society.
[00:24:04.640 --> 00:24:05.280]   I think it's a fun thing.
[00:24:05.280 --> 00:24:06.320]   Yeah.
[00:24:06.320 --> 00:24:08.640]   And the problem with lies is the liars.
[00:24:08.640 --> 00:24:11.200]   And we're concentrating on the wrong end of this.
[00:24:11.200 --> 00:24:13.280]   We're concentrating on Facebook.
[00:24:13.280 --> 00:24:16.080]   So the reason I help the institutional revolution is an academic book,
[00:24:16.080 --> 00:24:18.720]   but it's really influential in my thinking.
[00:24:18.720 --> 00:24:24.320]   Because it's an economic analysis of obsolete institutions like
[00:24:24.320 --> 00:24:29.440]   Duolene and the aristocracy and other things.
[00:24:29.440 --> 00:24:33.040]   What he argued was there were institutions that were established
[00:24:33.040 --> 00:24:38.640]   to guarantee trust because there weren't measurements necessary to be able to measure
[00:24:38.640 --> 00:24:41.040]   performance. I won't go through the whole description.
[00:24:41.040 --> 00:24:46.640]   You had the aristocracy because that was the way the king
[00:24:46.640 --> 00:24:48.800]   guaranteed that you were one of his people.
[00:24:48.800 --> 00:24:53.200]   Because you couldn't communicate with him and you couldn't measure
[00:24:53.200 --> 00:24:55.360]   his performance.
[00:24:55.360 --> 00:24:57.360]   And you didn't know where the admiral was on the ship
[00:24:57.360 --> 00:24:59.440]   because you couldn't measure the latitude and longitude and so on.
[00:24:59.440 --> 00:25:00.240]   Right? So that's his argument.
[00:25:00.240 --> 00:25:02.880]   And he says, when those measurements came along,
[00:25:02.880 --> 00:25:04.000]   they replaced those institutions.
[00:25:04.000 --> 00:25:05.600]   These institutions became obsolete.
[00:25:05.600 --> 00:25:07.600]   I think we have new measurements.
[00:25:07.600 --> 00:25:10.400]   I just say we moved past measurement in society now,
[00:25:10.400 --> 00:25:12.080]   where you can listen to people.
[00:25:12.080 --> 00:25:12.960]   You can speak.
[00:25:12.960 --> 00:25:13.840]   You can listen.
[00:25:13.840 --> 00:25:15.040]   You can find other people.
[00:25:15.040 --> 00:25:16.240]   You can act together.
[00:25:16.240 --> 00:25:21.280]   You can form new tribes together and act as these tribes in ways that you could not do before.
[00:25:21.280 --> 00:25:23.280]   Before you were stuck on the tribe, you were born in.
[00:25:23.280 --> 00:25:24.080]   Yes.
[00:25:24.080 --> 00:25:27.360]   Now you can form tribes wherever and those tribes can be for good or bad.
[00:25:27.360 --> 00:25:28.640]   Tribe used to be geography.
[00:25:28.640 --> 00:25:30.640]   They don't have to be geography at all.
[00:25:30.640 --> 00:25:31.680]   It used to be geography.
[00:25:31.680 --> 00:25:32.160]   It's not anymore.
[00:25:32.160 --> 00:25:33.280]   It used to be geography.
[00:25:33.280 --> 00:25:38.240]   But now what it also means is the institutions that rest a higher order of society,
[00:25:38.240 --> 00:25:41.120]   whether that's media and journalism or government and politics,
[00:25:41.120 --> 00:25:45.120]   education, they have to readjust themselves.
[00:25:45.120 --> 00:25:49.440]   They become obsolete now because we're based on old opinion polls.
[00:25:49.440 --> 00:25:51.200]   It's that we're all red or we're all blue.
[00:25:51.200 --> 00:25:51.840]   No, no, no.
[00:25:51.840 --> 00:25:53.840]   We're far more complex than that.
[00:25:53.840 --> 00:25:57.600]   And if you're Cambridge Analytical, you're coming along and you are going to every tribe,
[00:25:57.600 --> 00:25:58.800]   you can imagine.
[00:25:58.800 --> 00:26:00.400]   And you're exploiting that.
[00:26:00.400 --> 00:26:02.720]   Meanwhile, the counterbalance to that,
[00:26:02.720 --> 00:26:06.560]   which would be journalism and media or responsible political parties or government,
[00:26:06.560 --> 00:26:10.000]   they're a century behind.
[00:26:10.000 --> 00:26:14.560]   This is classic twig going off.
[00:26:14.560 --> 00:26:15.360]   Absolutely.
[00:26:15.360 --> 00:26:16.880]   No, we're near technology.
[00:26:16.880 --> 00:26:20.640]   It's not even in a chatroom said politics got into my tech show.
[00:26:20.640 --> 00:26:23.280]   It's not politics.
[00:26:23.280 --> 00:26:23.760]   It's not politics.
[00:26:23.760 --> 00:26:34.640]   It goes where we're going back to a new world of media that is powered by Google and Facebook,
[00:26:34.640 --> 00:26:35.120]   basically.
[00:26:35.120 --> 00:26:44.320]   What we're talking about is the impact of those two mighty companies on the nation state,
[00:26:44.320 --> 00:26:45.040]   on the world.
[00:26:45.040 --> 00:26:48.720]   And I think this is a fundamental, like what we're seeing,
[00:26:48.720 --> 00:26:51.760]   what we saw during the election, what we're seeing in all kinds of ways,
[00:26:51.760 --> 00:26:59.680]   whether it's fake news or is just the disintermediation of traditional gatekeepers.
[00:26:59.680 --> 00:27:02.560]   And there are all kinds of implications to that.
[00:27:02.560 --> 00:27:08.320]   I think I said at one point, when I was cheering for the disintermediation,
[00:27:08.320 --> 00:27:11.360]   I sort of thought that was a good idea at the time.
[00:27:11.360 --> 00:27:14.640]   Right. Well, and I was only looking at the good aspects, right?
[00:27:14.640 --> 00:27:20.080]   I was only looking at people's ability to choose and to produce news themselves and
[00:27:20.080 --> 00:27:22.240]   the democratization, which is great.
[00:27:22.240 --> 00:27:27.200]   But we all know that there are downsides to democratization.
[00:27:27.200 --> 00:27:29.920]   You see them all the time and we're seeing them now.
[00:27:29.920 --> 00:27:35.760]   We're seeing the dark side of that disintermediation as well.
[00:27:35.760 --> 00:27:39.280]   I think that we just fascinated.
[00:27:39.280 --> 00:27:39.680]   I don't know.
[00:27:39.680 --> 00:27:43.200]   I don't have a conclusion about it, but I'm really fascinated in the way
[00:27:43.200 --> 00:27:47.760]   the president elect continues to use Twitter to not,
[00:27:47.760 --> 00:27:52.160]   it's much more masterful than mere disintermediation,
[00:27:52.160 --> 00:27:58.640]   but uses his Twitter account to set the daily pres agenda.
[00:27:58.640 --> 00:27:59.360]   Exactly.
[00:27:59.360 --> 00:28:05.040]   To look at the ethics thing, where I believe that media have missed the story that,
[00:28:05.040 --> 00:28:08.320]   in fact, there was an immediate uprising that people phoning their representatives.
[00:28:08.320 --> 00:28:08.720]   There was.
[00:28:08.720 --> 00:28:12.240]   There was already retreating, but as soon as Trump came into it,
[00:28:12.240 --> 00:28:14.960]   boom, he gets all the credit, all the attention, everything else.
[00:28:14.960 --> 00:28:18.240]   He is setting the agenda for media in ways that this is.
[00:28:18.240 --> 00:28:19.040]   That's exactly what he wants.
[00:28:19.040 --> 00:28:21.280]   What do you do?
[00:28:21.280 --> 00:28:26.320]   The New York Times and the Washington Post run a headline saying this happened because Trump
[00:28:26.320 --> 00:28:26.720]   tweeted.
[00:28:26.720 --> 00:28:33.680]   Even if they go into the details in the story, 80% of the headlines read those details.
[00:28:33.680 --> 00:28:34.400]   Right.
[00:28:34.400 --> 00:28:39.840]   And he's getting the headlines he wants, even if what he says is not true.
[00:28:39.840 --> 00:28:46.640]   For a long time, I've said, oh, the media should stop paying attention to Twitter storms.
[00:28:46.640 --> 00:28:50.800]   They seem to me to pay an inordinate amount of attention to Twitter storms.
[00:28:50.800 --> 00:28:56.560]   Steve Martin had to pull down his tweet honoring Kerry Fisher.
[00:28:56.560 --> 00:28:57.760]   You know, what happened?
[00:28:57.760 --> 00:29:01.760]   You know, 50 people on Twitter complain and suddenly that became a story.
[00:29:01.760 --> 00:29:04.480]   And I said, you got to ignore what people say on Twitter.
[00:29:04.480 --> 00:29:06.000]   It's not of weight.
[00:29:06.000 --> 00:29:11.040]   But when the president elects something on Twitter, it does have some weight.
[00:29:11.040 --> 00:29:15.120]   Now, I noticed that a lot of executives, most of the executives of quit Twitter,
[00:29:15.120 --> 00:29:20.560]   I mean, literally have left the executive team seems to be evaporating at Twitter.
[00:29:20.560 --> 00:29:24.240]   And I'm wondering why that is.
[00:29:24.240 --> 00:29:29.200]   Do they because Twitter, for Donald Trump alone, Twitter has suddenly become,
[00:29:30.480 --> 00:29:32.560]   I mean, this is as important as the New York Times.
[00:29:32.560 --> 00:29:36.320]   This is where you find out what the president's thinking every minute.
[00:29:36.320 --> 00:29:39.680]   So if we're going out of business tomorrow.
[00:29:39.680 --> 00:29:44.560]   Yes, just suddenly, we never figured it out.
[00:29:44.560 --> 00:29:46.880]   Sorry, right.
[00:29:46.880 --> 00:29:47.840]   Well, that's the question.
[00:29:47.840 --> 00:29:51.040]   What impact would that have on politics and American today?
[00:29:51.040 --> 00:29:52.880]   Facebook doesn't have the same.
[00:29:52.880 --> 00:29:53.440]   Yeah, it doesn't.
[00:29:53.440 --> 00:29:55.280]   Because you can't speak to everybody at once.
[00:29:55.280 --> 00:29:56.000]   Okay, that's why.
[00:29:56.000 --> 00:30:01.200]   Well, so Facebook is where is what real people use and Twitter is what the media uses.
[00:30:01.200 --> 00:30:06.080]   And so Trump knows that all he has to do is fire off a tweet at three o'clock in the morning.
[00:30:06.080 --> 00:30:08.080]   And journalists will run after it.
[00:30:08.080 --> 00:30:09.840]   And they have to, but I don't want to wrap it.
[00:30:09.840 --> 00:30:14.400]   They can't ignore Twitter storms about Steve Martin, but you can't ignore it.
[00:30:14.400 --> 00:30:16.800]   But if the president elects something, right.
[00:30:16.800 --> 00:30:18.800]   And certainly when he's president, you will have to.
[00:30:18.800 --> 00:30:22.160]   But I think it's all in how you describe it.
[00:30:22.160 --> 00:30:27.520]   You can't just have a story saying Trump tweeted X or put in the headline.
[00:30:27.520 --> 00:30:31.360]   Trump says millions of people voted illegally.
[00:30:31.360 --> 00:30:38.240]   That's why I was so upset when Gerard Baker at the Wall Street Journal said that he wants to
[00:30:38.240 --> 00:30:39.440]   be very careful about.
[00:30:39.440 --> 00:30:45.360]   Well, if he repeats it multiple times after it's been proven not to be true, that's a lie.
[00:30:45.360 --> 00:30:46.240]   Bingo, Matthew.
[00:30:46.240 --> 00:30:46.720]   Exactly.
[00:30:46.720 --> 00:30:49.520]   That's an easy test with knowledge.
[00:30:50.240 --> 00:30:53.840]   Whether we're not with malice with knowledge, you repeat something that is new to be wrong.
[00:30:53.840 --> 00:30:54.400]   That's a lie.
[00:30:54.400 --> 00:30:56.320]   So either he's doing it.
[00:30:56.320 --> 00:30:59.920]   He can't lose because he's going to get people talking about it.
[00:30:59.920 --> 00:31:01.200]   It doesn't you call him a lie.
[00:31:01.200 --> 00:31:01.920]   It doesn't matter.
[00:31:01.920 --> 00:31:05.440]   We had it was a great conversation with Tim.
[00:31:05.440 --> 00:31:10.560]   Well, I keep talking about it, but he's talking about the attention merchants, his new book.
[00:31:10.560 --> 00:31:14.560]   He says there are three rules, but rule number one is get the attention.
[00:31:14.560 --> 00:31:16.480]   There's no such thing as bad publicity.
[00:31:16.480 --> 00:31:17.280]   Get the attention.
[00:31:17.280 --> 00:31:17.840]   Right.
[00:31:17.840 --> 00:31:18.160]   Right.
[00:31:18.160 --> 00:31:20.880]   And this is there.
[00:31:20.880 --> 00:31:24.800]   It's as if this was invented for Donald Trump.
[00:31:24.800 --> 00:31:28.880]   And it's in a way amazing that no one came upon this idea sooner.
[00:31:28.880 --> 00:31:36.400]   Well, and you could argue he was he was he was sort of bred in the reality TV tank in a way
[00:31:36.400 --> 00:31:39.760]   as as a creature born for for this moment.
[00:31:39.760 --> 00:31:40.960]   He was made for this.
[00:31:40.960 --> 00:31:41.440]   Yeah.
[00:31:41.440 --> 00:31:41.840]   Yeah.
[00:31:41.840 --> 00:31:43.200]   So my question is.
[00:31:43.200 --> 00:31:44.400]   It keeps reminding me of Bane.
[00:31:44.400 --> 00:31:47.200]   You think you've discovered the darkness.
[00:31:47.520 --> 00:31:49.040]   I lived in the darkness.
[00:31:49.040 --> 00:31:51.120]   Like he that's that's Trump.
[00:31:51.120 --> 00:31:54.000]   Like he social media basically gave art to him.
[00:31:54.000 --> 00:31:54.480]   Man, man.
[00:31:54.480 --> 00:32:04.480]   So so so Jerry Jerry Baker from the journal just today wrote a editorial defending his view about lies.
[00:32:04.480 --> 00:32:04.800]   Yeah.
[00:32:04.800 --> 00:32:05.760]   I don't pay for the journal.
[00:32:05.760 --> 00:32:06.400]   So I can't read it.
[00:32:06.400 --> 00:32:07.200]   But I put it on the window.
[00:32:07.200 --> 00:32:08.160]   I know I'll pay for it.
[00:32:08.160 --> 00:32:10.480]   So I was just looking at it.
[00:32:10.480 --> 00:32:13.920]   Is it that a lie say calling me a lie is a kind of a pejorative word.
[00:32:14.880 --> 00:32:17.440]   He's saying it assumes both the intent.
[00:32:17.440 --> 00:32:17.760]   Yeah.
[00:32:17.760 --> 00:32:18.240]   Right.
[00:32:18.240 --> 00:32:22.640]   He's saying you have to assume intent saying lie assumes intent.
[00:32:22.640 --> 00:32:28.480]   And and all I'm saying is if Trump repeats the same thing about Muslims and 9/11 or millions of
[00:32:28.480 --> 00:32:32.080]   people voting illegally after a bomb was proved wrong.
[00:32:32.080 --> 00:32:42.080]   I really admire and I'm amazed and I kind of admire Trump's willingness to just say something
[00:32:42.080 --> 00:32:43.520]   that's blatantly nonfactual.
[00:32:44.080 --> 00:32:46.560]   He must know it's blatantly nonfactual or not.
[00:32:46.560 --> 00:32:47.680]   Of course he knows.
[00:32:47.680 --> 00:32:48.000]   Okay.
[00:32:48.000 --> 00:32:53.040]   So see I can't decide if he's brilliant or an idiot or brilliant idiot.
[00:32:53.040 --> 00:32:57.120]   I don't know if he's if he's Peter Sellers from being there.
[00:32:57.120 --> 00:32:57.200]   Right.
[00:32:57.200 --> 00:32:57.680]   Right.
[00:32:57.680 --> 00:32:58.160]   Right.
[00:32:58.160 --> 00:33:01.200]   Or Machiavelli some brilliant mastermind.
[00:33:01.200 --> 00:33:01.280]   Yes.
[00:33:01.280 --> 00:33:03.200]   That's that's that is the key question.
[00:33:03.200 --> 00:33:03.600]   Isn't it?
[00:33:03.600 --> 00:33:05.920]   Because I think he's sort of halfway in business.
[00:33:05.920 --> 00:33:08.640]   I think so I think he has some Joe Rose.
[00:33:08.640 --> 00:33:11.360]   There's no question he's really all roses pieces by the way.
[00:33:11.360 --> 00:33:13.120]   We'll talk about those as a he's no question.
[00:33:13.120 --> 00:33:16.960]   He's brilliantly using misdirection propaganda.
[00:33:16.960 --> 00:33:17.280]   Right.
[00:33:17.280 --> 00:33:22.240]   Outright lies and half-truths to shape something.
[00:33:22.240 --> 00:33:25.920]   And I mean it looks brilliant.
[00:33:25.920 --> 00:33:31.360]   It is brilliant and yet it's not it's not I think he's sort of a lot of it is.
[00:33:31.360 --> 00:33:32.560]   It's kind of.
[00:33:32.560 --> 00:33:33.520]   It's interesting.
[00:33:33.520 --> 00:33:33.840]   He's in.
[00:33:33.840 --> 00:33:34.320]   He's in.
[00:33:34.320 --> 00:33:34.560]   Yeah.
[00:33:34.560 --> 00:33:39.200]   It's got exactly instinct and he knows that the press likes a good headline and he knows that
[00:33:39.200 --> 00:33:45.360]   people like a circus and he knows that saying something untrue has literally no downside.
[00:33:45.360 --> 00:33:47.200]   So the press is based for him.
[00:33:47.200 --> 00:33:49.280]   He's exactly with the press logs.
[00:33:49.280 --> 00:33:50.320]   Twitter was made for him.
[00:33:50.320 --> 00:33:50.800]   Yeah.
[00:33:50.800 --> 00:33:51.840]   Twitter was made for him.
[00:33:51.840 --> 00:33:52.240]   But look.
[00:33:52.240 --> 00:33:53.520]   And he's a click bait.
[00:33:53.520 --> 00:33:54.960]   He's a click bait factory.
[00:33:54.960 --> 00:33:55.280]   Yeah.
[00:33:55.280 --> 00:33:55.520]   Right.
[00:33:55.520 --> 00:34:01.680]   So so all the things that we've talked about related to ad tech and Google and Facebook and sort of the
[00:34:01.680 --> 00:34:04.480]   the changing of the media the structure of the media.
[00:34:05.280 --> 00:34:11.440]   That's why I said when in earlier post that he took advantage of effectively a broken media
[00:34:11.440 --> 00:34:19.040]   landscape and his strategy plays into that perfectly because he knows that regardless of what
[00:34:19.040 --> 00:34:22.240]   he says a thousand articles are going to be written about it.
[00:34:22.240 --> 00:34:26.640]   Now we're going to see after January 20th this all lends itself very well to a campaign.
[00:34:26.640 --> 00:34:31.840]   It does it lend itself well to governing is another matter.
[00:34:31.840 --> 00:34:33.360]   There's no laws anymore.
[00:34:33.360 --> 00:34:34.000]   But there's no.
[00:34:34.000 --> 00:34:34.320]   No.
[00:34:34.320 --> 00:34:34.800]   No.
[00:34:34.800 --> 00:34:35.280]   No.
[00:34:35.280 --> 00:34:36.240]   Not effective governing.
[00:34:36.240 --> 00:34:41.920]   But if you think governing is consensus building and then no, it's not.
[00:34:41.920 --> 00:34:46.880]   But if you think governing is getting a lot of headlines, all you have to do is tweet about.
[00:34:46.880 --> 00:34:48.080]   This is leadership.
[00:34:48.080 --> 00:34:49.120]   This is leadership.
[00:34:49.120 --> 00:34:51.760]   This is tearing down institutions.
[00:34:51.760 --> 00:34:53.280]   This goes back to the institutional revolution.
[00:34:53.280 --> 00:34:55.440]   But maybe we need to tear down institutions.
[00:34:55.440 --> 00:34:57.360]   They're failing us in so many ways.
[00:34:57.360 --> 00:34:59.120]   Let's start a nuclear arms race.
[00:34:59.120 --> 00:35:00.960]   Like literally that's a tweet.
[00:35:00.960 --> 00:35:03.520]   So then is that governing?
[00:35:04.000 --> 00:35:06.160]   Wow.
[00:35:06.160 --> 00:35:08.800]   Anyway, just to finish my thought, then we'll get to Jay Rosen.
[00:35:08.800 --> 00:35:10.080]   Twitter leadership team.
[00:35:10.080 --> 00:35:12.160]   Adam Bain, COA gone.
[00:35:12.160 --> 00:35:14.560]   Katie Jacobs, Stoughton, VP global media gone.
[00:35:14.560 --> 00:35:16.160]   Adam Messenger, CTO gone.
[00:35:16.160 --> 00:35:18.320]   Alex, whatever is ready.
[00:35:18.320 --> 00:35:21.440]   Senior V as vice president engineering gone.
[00:35:21.440 --> 00:35:24.160]   Brian Skipper, VP human resources gone.
[00:35:24.160 --> 00:35:24.800]   Look at that.
[00:35:24.800 --> 00:35:27.120]   This is a tweet from Seth Figurman.
[00:35:27.120 --> 00:35:30.080]   Twitter's 2016 in a nutshell.
[00:35:31.040 --> 00:35:33.600]   All but three of their executive team gone.
[00:35:33.600 --> 00:35:35.920]   Why are people leaving?
[00:35:35.920 --> 00:35:37.920]   This is Twitter's golden age.
[00:35:37.920 --> 00:35:41.920]   Well, not if you're an executive, it isn't.
[00:35:41.920 --> 00:35:47.280]   I mean, if any of those people had options and so on.
[00:35:47.280 --> 00:35:48.240]   Tash in.
[00:35:48.240 --> 00:35:49.440]   Do you think it's purely financial?
[00:35:49.440 --> 00:35:50.320]   There's no point in staying.
[00:35:50.320 --> 00:35:51.280]   I wouldn't be surprised.
[00:35:51.280 --> 00:35:53.520]   Some of these people say, I don't want to
[00:35:56.080 --> 00:36:01.040]   assist. I don't want to be a codependent on Donald Trump.
[00:36:01.040 --> 00:36:03.440]   I don't want to provide him with a platform.
[00:36:03.440 --> 00:36:04.800]   Oh, it's a Rockettes problem.
[00:36:04.800 --> 00:36:07.600]   The Rockettes problem.
[00:36:07.600 --> 00:36:09.200]   That's interesting.
[00:36:09.200 --> 00:36:10.080]   Plus not quite.
[00:36:10.080 --> 00:36:12.160]   Well, it's probably the two combined, right?
[00:36:12.160 --> 00:36:16.000]   I'm going to cash in and by the way, I don't want to watch this happen.
[00:36:16.000 --> 00:36:18.240]   Well, and I think it's probably been torture.
[00:36:18.240 --> 00:36:22.880]   I mean, just even the last year, a bunch of it has been
[00:36:22.880 --> 00:36:25.680]   consolidation of power, I think, under Anthony Nodow.
[00:36:26.160 --> 00:36:27.600]   At least that's my impression.
[00:36:27.600 --> 00:36:33.440]   He's the current CFO, but we'll be running everything, right?
[00:36:33.440 --> 00:36:34.560]   Pretty much running everything.
[00:36:34.560 --> 00:36:35.120]   Yeah.
[00:36:35.120 --> 00:36:36.800]   And when he is running Jack runs.
[00:36:36.800 --> 00:36:41.200]   As well as running a completely different company.
[00:36:41.200 --> 00:36:47.600]   This year, one, two, three, four, five, six, seven, eight, nine, 10, 11,
[00:36:47.600 --> 00:36:52.560]   he's 12 VP level and higher people departing.
[00:36:52.560 --> 00:36:54.320]   That's all.
[00:36:54.320 --> 00:36:55.840]   Well, a lot of this wasn't sold.
[00:36:55.840 --> 00:36:59.840]   Evan company by all rumors, one of it sold.
[00:36:59.840 --> 00:37:01.920]   These guys wanted to be able to cash out that way.
[00:37:01.920 --> 00:37:04.560]   Well, if that doesn't happen, they say, well, that's why I was sticking around.
[00:37:04.560 --> 00:37:05.760]   Okay, that makes sense.
[00:37:05.760 --> 00:37:06.400]   Yeah.
[00:37:06.400 --> 00:37:08.320]   That makes sense.
[00:37:08.320 --> 00:37:11.840]   So there's always been two different things.
[00:37:11.840 --> 00:37:14.160]   Twitter, the service, and Twitter, the company.
[00:37:14.160 --> 00:37:15.040]   Yes.
[00:37:15.040 --> 00:37:19.360]   And Twitter, the service, you could argue, is amazing and incredible.
[00:37:19.360 --> 00:37:20.000]   Yes.
[00:37:20.000 --> 00:37:24.160]   And has all sorts of positive things in Twitter, the company.
[00:37:24.160 --> 00:37:25.200]   Has been a train wreck.
[00:37:25.200 --> 00:37:29.920]   So Jay Rosen, who's your counterpart, Jeff, at NYU.
[00:37:29.920 --> 00:37:31.440]   He's a much smarter than I am.
[00:37:31.440 --> 00:37:34.560]   I put you guys on the equal tell me.
[00:37:34.560 --> 00:37:35.280]   He said that.
[00:37:35.280 --> 00:37:35.520]   Yeah.
[00:37:35.520 --> 00:37:36.640]   He knows.
[00:37:36.640 --> 00:37:36.960]   He knows.
[00:37:36.960 --> 00:37:41.520]   I think that he writes at pressthink.org and did a two-parter
[00:37:41.520 --> 00:37:48.640]   on the prospects for the American press in this new era, in the age of Trump, as he calls it.
[00:37:48.640 --> 00:37:54.240]   It's a very long two-parter with many, many suggestions.
[00:37:54.240 --> 00:37:59.360]   First, he says what the problem is going to be, and then he suggests how the press can handle this.
[00:37:59.360 --> 00:38:03.200]   Saying that there's no single solution, that he doesn't have a solution, but here's, here's,
[00:38:03.200 --> 00:38:03.840]   you know, what?
[00:38:03.840 --> 00:38:05.200]   No, he's 39 steps.
[00:38:05.200 --> 00:38:06.160]   Yeah.
[00:38:06.160 --> 00:38:07.200]   And even then, we're not there.
[00:38:07.200 --> 00:38:16.240]   So, 17 paragraphs in part one, in which he says, "Whitter is coming.
[00:38:16.240 --> 00:38:17.520]   How bad is it bad?"
[00:38:18.480 --> 00:38:19.360]   I will explain why.
[00:38:19.360 --> 00:38:20.800]   And he bright signs a few.
[00:38:20.800 --> 00:38:25.600]   And then in part two, he writes, "This is book length, practically."
[00:38:25.600 --> 00:38:26.000]   I mean, it's-
[00:38:26.000 --> 00:38:27.920]   No, it's an excellent piece.
[00:38:27.920 --> 00:38:31.520]   And as a result, he appeared on a couple shows around-
[00:38:31.520 --> 00:38:33.120]   I saw him in MSNBC, and yeah.
[00:38:33.120 --> 00:38:38.240]   Well, I love to comment just saying that I think that this goes to your question before.
[00:38:38.240 --> 00:38:39.840]   Is he a genius?
[00:38:39.840 --> 00:38:42.400]   Is he a chance, the gardener?
[00:38:42.400 --> 00:38:43.920]   I think that we in press have to have-
[00:38:43.920 --> 00:38:45.280]   We have to test hypotheses.
[00:38:45.280 --> 00:38:46.160]   Right?
[00:38:46.160 --> 00:38:46.960]   Is he in it for the money?
[00:38:46.960 --> 00:38:48.080]   Is he in someone's pocket?
[00:38:48.560 --> 00:38:50.800]   Is he ready to kill institutions?
[00:38:50.800 --> 00:38:52.640]   Is he insane, which is one of them?
[00:38:52.640 --> 00:38:55.920]   Is he just right?
[00:38:55.920 --> 00:38:57.200]   And half America loves it.
[00:38:57.200 --> 00:39:00.000]   You know, each of these is an hypothesis that you have to test in terms of-
[00:39:00.000 --> 00:39:01.120]   Because we can't understand why.
[00:39:01.120 --> 00:39:02.080]   All the rules are broken.
[00:39:02.080 --> 00:39:03.680]   None of the old rules work.
[00:39:03.680 --> 00:39:04.880]   Jay's response to me was,
[00:39:04.880 --> 00:39:09.680]   you assume, Jarvis, that people are willing to throw out the way they have been covering this.
[00:39:09.680 --> 00:39:12.000]   And I said, "Well, I hope there, and he's not so optimistic."
[00:39:12.000 --> 00:39:12.480]   Yeah.
[00:39:12.480 --> 00:39:13.360]   I think that's-
[00:39:13.360 --> 00:39:13.360]   That's-
[00:39:13.360 --> 00:39:13.920]   Yeah.
[00:39:13.920 --> 00:39:14.560]   That's a good point.
[00:39:14.560 --> 00:39:15.200]   Yeah.
[00:39:15.200 --> 00:39:19.440]   And I don't think you can take a media that enjoys a horse race,
[00:39:19.440 --> 00:39:25.600]   you know, and sort of click revenue the way the way the current media does,
[00:39:25.600 --> 00:39:30.880]   and suddenly turn it into one that can challenge a president like Trump.
[00:39:30.880 --> 00:39:35.280]   Well, especially when you have a media that's economically challenged as it is.
[00:39:35.280 --> 00:39:35.520]   Right.
[00:39:35.520 --> 00:39:38.800]   The economic pressures are just going to simply draw-
[00:39:38.800 --> 00:39:41.440]   You know, I mean, as Les Moonves says,
[00:39:41.440 --> 00:39:43.920]   all this is very good for the bottom line.
[00:39:43.920 --> 00:39:47.040]   It's terrible for the nation, but it's great for CBS.
[00:39:47.040 --> 00:39:50.320]   And if you work at a media company, you have to think,
[00:39:50.320 --> 00:39:54.800]   "Yeah, we would love to take some time and dig into Trump's background,
[00:39:54.800 --> 00:39:59.520]   but we have to publish 45 stories today that are 200 words long with a video clip,
[00:39:59.520 --> 00:40:00.800]   and then we don't make any money."
[00:40:00.800 --> 00:40:04.320]   It's-
[00:40:04.320 --> 00:40:09.680]   Part of me is actually enjoying this.
[00:40:09.680 --> 00:40:13.600]   I have to remind myself that there are a lot of people who will suffer.
[00:40:13.600 --> 00:40:14.400]   That it's terrible.
[00:40:14.400 --> 00:40:24.400]   You know, but it is in a way the end game of something that we've been chronicling for the last 20
[00:40:24.400 --> 00:40:30.160]   years, which is the complete disruption of society by technology.
[00:40:30.160 --> 00:40:32.720]   And it's accelerating.
[00:40:32.720 --> 00:40:39.440]   We haven't even started to see the acceleration of automation and artificial intelligence,
[00:40:39.440 --> 00:40:42.720]   although we're starting to see the fault lines form.
[00:40:42.720 --> 00:40:48.080]   There's a company, an insurance company, I think it was in China, where was it?
[00:40:48.080 --> 00:40:48.800]   Or Japan?
[00:40:48.800 --> 00:40:50.800]   Pardon sorry, pardon me, Japan.
[00:40:50.800 --> 00:40:57.440]   That's replacing several dozen of its employees with IBM's Watson.
[00:40:57.440 --> 00:41:04.400]   To do their insurance actuarial stuff and so forth.
[00:41:04.400 --> 00:41:10.640]   You see Foxconn saying the company that makes the iPhone among many other products,
[00:41:10.640 --> 00:41:16.720]   saying our end game is to have no human employees, but robots, they fired 30,000 employees and
[00:41:16.720 --> 00:41:17.760]   replaced them with robots.
[00:41:17.760 --> 00:41:20.320]   And this is for 30,000?
[00:41:20.320 --> 00:41:22.400]   30,000, that was a few months ago.
[00:41:22.400 --> 00:41:26.400]   They are even contemplating building factories in the United States.
[00:41:26.400 --> 00:41:31.760]   I'm sure they're assessing a future where there are high tariffs, as there are in Brazil,
[00:41:31.760 --> 00:41:36.400]   for instance, very expensive to bring a- or in India to bring phones in from another country.
[00:41:36.400 --> 00:41:40.560]   So Foxconn built a Brazil plant and is building an India plant so they can
[00:41:40.560 --> 00:41:41.120]   make them there.
[00:41:41.120 --> 00:41:47.680]   But they'll be robotic plants because they don't.
[00:41:47.680 --> 00:41:49.680]   So it's a very interesting-
[00:41:49.680 --> 00:41:55.920]   Not only has the last 20 years been total disruption and now we're seeing the disruption
[00:41:55.920 --> 00:42:02.160]   of media and disruption of politics, but we're about to see a huge disruption in the economy
[00:42:02.160 --> 00:42:03.120]   as a result as well.
[00:42:03.120 --> 00:42:08.560]   And the kind of people who did vote for the jobs that will disappear are the ones that were crucial.
[00:42:09.120 --> 00:42:11.120]   When every truck driver-
[00:42:11.120 --> 00:42:11.920]   This country is threatened.
[00:42:11.920 --> 00:42:12.640]   Yeah.
[00:42:12.640 --> 00:42:17.600]   Long-haul truck driver, cab driver, cashier, all the jobs that you could get
[00:42:17.600 --> 00:42:22.160]   with sort of a high school diploma and not a lot of skills.
[00:42:22.160 --> 00:42:23.360]   What happens to those people?
[00:42:23.360 --> 00:42:31.760]   Well, and I talked to my kids who were in their early 20s and Michael's 14 and Michael's friends,
[00:42:31.760 --> 00:42:37.280]   and I talked to them often about how to kind of navigate this because
[00:42:37.840 --> 00:42:41.520]   those jobs that you are preparing for today may not exist tomorrow,
[00:42:41.520 --> 00:42:44.160]   even if you're going to college.
[00:42:44.160 --> 00:42:44.800]   And that's the thing.
[00:42:44.800 --> 00:42:47.280]   I think a lot of people think, oh, I know I'm going for a profession.
[00:42:47.280 --> 00:42:49.360]   I'm going to college.
[00:42:49.360 --> 00:42:50.320]   I'll be protected.
[00:42:50.320 --> 00:42:53.840]   They're going to have their come up in says well.
[00:42:53.840 --> 00:43:00.480]   So Finland is trying a small experiment on basic income.
[00:43:00.480 --> 00:43:04.160]   560 euros to 2000 fins.
[00:43:04.160 --> 00:43:05.600]   Guaranteed.
[00:43:05.600 --> 00:43:07.120]   You don't have to say what you're going to do with it.
[00:43:07.120 --> 00:43:08.320]   You don't have to look for work.
[00:43:08.320 --> 00:43:15.680]   I just saw, is it India that's looking at basic income as well?
[00:43:15.680 --> 00:43:18.800]   The real point of the Finnish thing, which I didn't really understand until I read the stories,
[00:43:18.800 --> 00:43:24.400]   is that the disincentive people had funny work because they were lose benefits.
[00:43:24.400 --> 00:43:24.720]   Right.
[00:43:24.720 --> 00:43:28.560]   So now you will not lose this money and you can get work on the presumption as more people will
[00:43:28.560 --> 00:43:29.520]   go get work now.
[00:43:29.520 --> 00:43:36.320]   According to the business insider, the Indian government set to endorse universal basic income,
[00:43:36.560 --> 00:43:44.000]   this comes from a professor standing who's a founder of an advocacy group called Basic
[00:43:44.000 --> 00:43:47.280]   Income Earth Network, Bien in 1986.
[00:43:47.280 --> 00:43:52.480]   He says in this month, India will release a report saying it's feasible and quote,
[00:43:52.480 --> 00:43:53.920]   basically the way forward.
[00:43:53.920 --> 00:43:57.120]   The idea being it's kind of super welfare.
[00:43:57.120 --> 00:43:58.720]   Everybody gets a basic income.
[00:43:58.720 --> 00:43:59.680]   It's a low income.
[00:43:59.680 --> 00:44:05.920]   And a number of people have pointed out, including Democratic caucus,
[00:44:06.400 --> 00:44:09.200]   that the problem with this is it replaces all entitlements.
[00:44:09.200 --> 00:44:10.800]   That's all you get.
[00:44:10.800 --> 00:44:12.000]   You don't get health care.
[00:44:12.000 --> 00:44:12.880]   You don't get anything.
[00:44:12.880 --> 00:44:13.920]   You don't get food stamps.
[00:44:13.920 --> 00:44:15.040]   You get a basic income.
[00:44:15.040 --> 00:44:16.880]   But everybody gets it.
[00:44:16.880 --> 00:44:21.680]   That's what I was talking to somebody about this just the other day.
[00:44:21.680 --> 00:44:24.240]   And I was saying it seems like a good idea.
[00:44:24.240 --> 00:44:27.120]   And they said it will seem more like a good idea.
[00:44:27.120 --> 00:44:29.040]   Let's say it was in the US.
[00:44:29.040 --> 00:44:35.440]   If you say these are all the things you won't get, if you get the sort of basic.
[00:44:35.440 --> 00:44:37.440]   Here's what you're going to have to trade.
[00:44:37.440 --> 00:44:40.880]   You're going to have to give up all these health care benefits,
[00:44:40.880 --> 00:44:44.640]   all these tax rebates, all these everything.
[00:44:44.640 --> 00:44:50.480]   And then just do the math for average person under the poverty line.
[00:44:50.480 --> 00:44:56.160]   Scotland is apparently piloting a universal basic income scheme and fife and Glasgow.
[00:44:56.160 --> 00:45:02.800]   Every citizen in a universal basic income, I think these all are roughly the same plan.
[00:45:04.720 --> 00:45:14.240]   The experiment in India, the experiment there has been quite successful.
[00:45:14.240 --> 00:45:15.760]   The nutrition is improved.
[00:45:15.760 --> 00:45:18.160]   Let me see if I can find this.
[00:45:18.160 --> 00:45:22.240]   The pilots in Maja Praddesh launched in 2010, six years ago.
[00:45:22.240 --> 00:45:27.440]   They provided every man, woman and child across eight villages with a modest basic income for 18
[00:45:27.440 --> 00:45:27.680]   months.
[00:45:27.680 --> 00:45:32.000]   Welfare improved dramatically in the villages, particularly in nutrition among the children,
[00:45:32.000 --> 00:45:35.120]   healthcare, sanitation, school attendance and performance.
[00:45:35.120 --> 00:45:41.040]   The most striking thing, which we hadn't actually anticipated, is that the emancipatory effect
[00:45:41.040 --> 00:45:42.720]   was greater than the monetary effect.
[00:45:42.720 --> 00:45:46.800]   In other words, it enabled people to have a sense of control.
[00:45:46.800 --> 00:45:48.800]   They pooled some of the money to pay down their debts.
[00:45:48.800 --> 00:45:51.920]   They increased decisions on escaping from debt bondage.
[00:45:51.920 --> 00:45:56.160]   The women developed their own capacity to make their own decision about their own lives.
[00:45:56.160 --> 00:46:00.640]   The general tenor of all these communities has been remarkably positive.
[00:46:00.640 --> 00:46:05.440]   Now, I should say this quote is from the guy who's been promoting this for some time.
[00:46:05.440 --> 00:46:10.720]   There is a $20 million trial set to launch in California this year.
[00:46:10.720 --> 00:46:13.040]   We're moving rapidly towards this idea.
[00:46:13.040 --> 00:46:15.120]   This is something Mark and Driesin, the creative net.
[00:46:15.120 --> 00:46:18.240]   This is what the valley thinks today was talking about.
[00:46:18.240 --> 00:46:20.480]   Yeah, we'll destroy the world, but here's some money.
[00:46:20.480 --> 00:46:21.360]   You know, eat some cake.
[00:46:21.360 --> 00:46:27.040]   But you could argue that, let's say you could replace the things that people get
[00:46:27.040 --> 00:46:32.080]   who are on welfare or below the poverty line or whatever, you could replace them with a single
[00:46:32.080 --> 00:46:33.920]   basic income.
[00:46:33.920 --> 00:46:43.120]   You could argue that would get rid of so much bureaucracy and just think of how simple it could
[00:46:43.120 --> 00:46:44.960]   be compared to what we have now.
[00:46:44.960 --> 00:46:48.720]   Multiple conflicting departments, multiple conflicting.
[00:46:48.720 --> 00:46:54.000]   If you could simplify it, you could save a lot of money for one thing.
[00:46:55.600 --> 00:46:56.800]   It's very interesting.
[00:46:56.800 --> 00:46:57.680]   We live in.
[00:46:57.680 --> 00:47:00.480]   That's what I'm just fascinated by what's happening.
[00:47:00.480 --> 00:47:04.560]   And I have to remind myself there are real human consequences.
[00:47:04.560 --> 00:47:10.400]   But I think it's also when you look at particularly Silicon Valley and you cover
[00:47:10.400 --> 00:47:16.880]   things like whether it's self-driving cars or whatever, you get caught up in this sort of,
[00:47:16.880 --> 00:47:19.520]   wow, this would be so amazing, the kind of, you know,
[00:47:19.520 --> 00:47:24.240]   Star Wars or Star Trek future that could be possible.
[00:47:24.240 --> 00:47:31.040]   You think about Star Trek and just your cup of tea materializing, well, what about all
[00:47:31.040 --> 00:47:32.720]   the people who used to make cups of tea?
[00:47:32.720 --> 00:47:35.520]   And their whole job was to work in the cafeteria.
[00:47:35.520 --> 00:47:36.640]   All those people are out of work.
[00:47:36.640 --> 00:47:37.360]   Where the hell are they?
[00:47:37.360 --> 00:47:39.200]   Well, Star Trek doesn't tell you.
[00:47:39.200 --> 00:47:41.600]   Presumably they're servicing spaceships or something.
[00:47:41.600 --> 00:47:42.080]   Who knows?
[00:47:42.080 --> 00:47:48.000]   But it's easy to get caught up in the Gee Whiz part.
[00:47:48.000 --> 00:47:53.200]   Silicon Valley's premise is that automation, artificial intelligence will make goods so cheap,
[00:47:53.200 --> 00:47:57.440]   virtually free, that they'll be plenitude.
[00:47:57.440 --> 00:48:01.440]   I'm not sure where the money for universal basic income comes from.
[00:48:01.440 --> 00:48:04.480]   I mean, all of these things are small-scale trials,
[00:48:04.480 --> 00:48:10.400]   which aren't going to really show the real problems that a universal...
[00:48:10.400 --> 00:48:11.200]   Full fledged.
[00:48:11.200 --> 00:48:15.360]   It comes in the long run, Leo, when you have huge corporate profitability out of
[00:48:15.360 --> 00:48:18.160]   all those jobs that are eliminated.
[00:48:18.160 --> 00:48:19.600]   It sounds like a perpetual infestation.
[00:48:19.600 --> 00:48:21.680]   It sounds like a perpetual Facebook pay for all that.
[00:48:21.680 --> 00:48:23.600]   It sounds like a perpetual motion machine.
[00:48:23.600 --> 00:48:25.040]   Exactly.
[00:48:25.040 --> 00:48:31.280]   The problem is that how do those companies that got rid of all those jobs make all this money?
[00:48:31.280 --> 00:48:31.840]   Where's the money coming from?
[00:48:31.840 --> 00:48:34.640]   Nobody can afford to buy anything from them.
[00:48:34.640 --> 00:48:38.880]   Well, we'll find out.
[00:48:38.880 --> 00:48:42.000]   No, our kids will find out.
[00:48:42.000 --> 00:48:43.440]   I'm just glad I'm 60.
[00:48:43.440 --> 00:48:46.560]   Wow.
[00:48:46.560 --> 00:48:47.760]   What a world, huh?
[00:48:47.760 --> 00:48:48.880]   Yeah.
[00:48:51.200 --> 00:48:51.840]   Let's take a break.
[00:48:51.840 --> 00:48:53.200]   We're going to CES.
[00:48:53.200 --> 00:48:55.040]   Stacey, you'll be back from CES.
[00:48:55.040 --> 00:48:58.640]   We'll talk about that in a second.
[00:48:58.640 --> 00:49:05.920]   I'll tell you what to do with your money, all this money you got now.
[00:49:05.920 --> 00:49:07.520]   You better invest it.
[00:49:07.520 --> 00:49:10.080]   Stock market is getting close to hitting...
[00:49:10.080 --> 00:49:12.720]   The Dow Jones is getting close to hitting 20,000.
[00:49:12.720 --> 00:49:17.360]   Now, I know a lot of you are smart folks who thinks,
[00:49:17.360 --> 00:49:19.520]   "Oh, I'll just take advantage of this and do my own investing.
[00:49:19.520 --> 00:49:22.240]   Can I make, recommend a better way to invest?
[00:49:22.240 --> 00:49:23.040]   Better Mint."
[00:49:23.040 --> 00:49:28.000]   It is the largest independent automated investing service,
[00:49:28.000 --> 00:49:34.000]   $5.5 billion under investment, over 180,000 customers.
[00:49:34.000 --> 00:49:37.680]   Their portfolio is designed to achieve optimal results,
[00:49:37.680 --> 00:49:39.280]   no matter what level of investment.
[00:49:39.280 --> 00:49:43.360]   And because there's no minimum, you can try it right now for just a few bucks.
[00:49:43.360 --> 00:49:48.720]   Better Mint's Gold-based investing framework and advice algorithm will let you know if
[00:49:48.720 --> 00:49:50.480]   you're on track in seconds.
[00:49:50.480 --> 00:49:53.920]   And by the way, you will save on fees alone.
[00:49:53.920 --> 00:49:58.720]   This is something people never think about, is the cost of investing.
[00:49:58.720 --> 00:50:03.360]   Automated investing is a fraction of what you'd pay for traditional financial services.
[00:50:03.360 --> 00:50:05.600]   Save up to 600% on fees.
[00:50:05.600 --> 00:50:07.440]   It means you keep more of your money.
[00:50:07.440 --> 00:50:11.440]   No trade fees, no transaction fees, no rebalancing fees.
[00:50:11.440 --> 00:50:17.520]   By the way, you can add your own investments from the outside world to Better Mint's
[00:50:17.520 --> 00:50:20.000]   dashboard so you can see your total net worth in one place.
[00:50:20.000 --> 00:50:27.040]   Better Mint customers, through diversification, automated rebalancing and lower fees,
[00:50:27.040 --> 00:50:32.480]   can expect 4.3% higher returns than the typical Do-It-Yourself investor.
[00:50:32.480 --> 00:50:33.440]   Don't do it yourself.
[00:50:33.440 --> 00:50:35.600]   Do it with Better Mint.
[00:50:35.600 --> 00:50:39.200]   Smart deposits means you can automatically invest cash,
[00:50:39.200 --> 00:50:40.320]   which is a very good idea.
[00:50:40.320 --> 00:50:43.440]   Just get it out of your site before you even see it.
[00:50:44.960 --> 00:50:48.640]   Every time you make a deposit or receive dividends, Better Mint will intelligently
[00:50:48.640 --> 00:50:50.080]   rebalance your portfolio.
[00:50:50.080 --> 00:50:50.960]   I really like that.
[00:50:50.960 --> 00:50:55.040]   That's something everybody should do, knows they need to do, and don't do.
[00:50:55.040 --> 00:51:00.160]   Better Mint does tax loss harvesting too to keep taxes down and increase after tax returns.
[00:51:00.160 --> 00:51:02.240]   End-to-end investing.
[00:51:02.240 --> 00:51:07.040]   That means faster cash transfers, tax forms available at the earliest possible date,
[00:51:07.040 --> 00:51:09.360]   secure investing, it goes like that.
[00:51:09.360 --> 00:51:12.480]   And there is absolutely, there's a human on the other end of the line.
[00:51:12.480 --> 00:51:15.840]   So support specialists are there seven days a week, 365 days a year.
[00:51:15.840 --> 00:51:18.560]   Investing involves risk.
[00:51:18.560 --> 00:51:22.240]   So I want you to read up at betterment.com.
[00:51:22.240 --> 00:51:27.600]   But I think when you read, you'll see it's a better way.
[00:51:27.600 --> 00:51:28.080]   Better Mint.
[00:51:28.080 --> 00:51:30.560]   Investing made better.
[00:51:30.560 --> 00:51:36.560]   Better Mint, B-E-T-T-E-R-M-E-N-T, betterment.com.
[00:51:38.640 --> 00:51:41.280]   And we thank them for their support of this week in Google.
[00:51:41.280 --> 00:51:46.320]   So, all right, enough.
[00:51:46.320 --> 00:51:48.480]   We've talked enough about how the world is going to end.
[00:51:48.480 --> 00:51:53.760]   Let's talk about all the fun toys we'll have at the end as we're going.
[00:51:53.760 --> 00:51:55.760]   I do like it that you can ask, and I haven't tried this.
[00:51:55.760 --> 00:51:57.040]   Do you have a Google Home handy?
[00:51:57.040 --> 00:51:58.400]   I do indeed.
[00:51:58.400 --> 00:52:01.840]   Ask it what your New Year's resolution should be.
[00:52:01.840 --> 00:52:03.760]   All right, I think I'm going to like.
[00:52:03.760 --> 00:52:05.360]   They did this with VentureBeat.
[00:52:05.360 --> 00:52:06.240]   Okay, Google.
[00:52:07.680 --> 00:52:09.600]   What should my New Year's resolutions be?
[00:52:09.600 --> 00:52:18.800]   Take up a new hobby like bird watching or calligraphy.
[00:52:18.800 --> 00:52:19.840]   What else?
[00:52:19.840 --> 00:52:22.160]   That's dopey.
[00:52:22.160 --> 00:52:22.880]   Okay, Google.
[00:52:22.880 --> 00:52:24.400]   What else?
[00:52:24.400 --> 00:52:31.120]   You'll have to translate.
[00:52:31.120 --> 00:52:31.520]   I can't.
[00:52:31.520 --> 00:52:37.280]   No, I'm just going to say what else I could ask it.
[00:52:37.280 --> 00:52:39.280]   Oh, it was resolutions.
[00:52:39.280 --> 00:52:41.760]   So, this is what it told VentureBeat.
[00:52:41.760 --> 00:52:45.440]   And it kept asking, so it gives you one at a time.
[00:52:45.440 --> 00:52:46.960]   Oh, okay.
[00:52:46.960 --> 00:52:48.720]   You could write a novel or keep a journal.
[00:52:48.720 --> 00:52:51.200]   Either way, writing is good for you in many ways.
[00:52:51.200 --> 00:52:52.720]   What should my New Year's resolution be?
[00:52:52.720 --> 00:52:56.880]   You could write a novel or just keep a journal.
[00:52:56.880 --> 00:52:59.360]   Either way, writing is for you in lots of ways.
[00:52:59.360 --> 00:53:00.800]   Oh, yeah.
[00:53:00.800 --> 00:53:02.400]   It's not a way to make a living Google.
[00:53:02.400 --> 00:53:03.520]   I can tell you that.
[00:53:03.520 --> 00:53:05.760]   I'm a writer, Google.
[00:53:05.760 --> 00:53:07.360]   That's not a hobby.
[00:53:07.360 --> 00:53:09.120]   Look how you're ruling it for us writers.
[00:53:09.120 --> 00:53:10.640]   That's where all the writers are saying.
[00:53:10.640 --> 00:53:12.000]   Don't tell other people to write,
[00:53:12.000 --> 00:53:12.560]   God damn it.
[00:53:12.560 --> 00:53:15.600]   That's right.
[00:53:15.600 --> 00:53:17.040]   No more content, David.
[00:53:17.040 --> 00:53:18.320]   It's a terrible advice.
[00:53:18.320 --> 00:53:19.360]   You could write a novel.
[00:53:19.360 --> 00:53:20.240]   What are you thinking?
[00:53:20.240 --> 00:53:21.520]   That's terrible advice.
[00:53:21.520 --> 00:53:24.240]   Writing is good for you.
[00:53:24.240 --> 00:53:25.360]   Not a writer.
[00:53:25.360 --> 00:53:26.320]   I don't think so.
[00:53:26.320 --> 00:53:29.280]   You guys write for a living.
[00:53:29.280 --> 00:53:29.920]   I tried.
[00:53:29.920 --> 00:53:34.000]   Try to make someone smile every day.
[00:53:34.000 --> 00:53:34.880]   That's good advice.
[00:53:34.880 --> 00:53:36.000]   Oh, F me.
[00:53:36.000 --> 00:53:36.880]   Go ahead and ask again.
[00:53:36.880 --> 00:53:37.840]   See what else it says.
[00:53:37.840 --> 00:53:39.760]   Okay, Google.
[00:53:39.760 --> 00:53:41.360]   What should my New Year's resolution be?
[00:53:41.360 --> 00:53:46.000]   My apology.
[00:53:46.000 --> 00:53:46.880]   I don't understand.
[00:53:46.880 --> 00:53:49.120]   Okay, Google.
[00:53:49.120 --> 00:53:50.800]   What should my New Year's resolution be?
[00:53:50.800 --> 00:53:54.160]   Try to make someone smile every day.
[00:53:54.160 --> 00:53:54.880]   We've heard that.
[00:53:54.880 --> 00:53:56.320]   Screw you, Google.
[00:53:56.320 --> 00:54:00.240]   Don't you know the rules going to hell in a hand?
[00:54:00.240 --> 00:54:02.640]   And you're a part of it.
[00:54:02.640 --> 00:54:03.600]   It's your fault.
[00:54:03.600 --> 00:54:05.840]   Jeff, it might be great to volunteer.
[00:54:05.840 --> 00:54:07.200]   You will help your community.
[00:54:07.200 --> 00:54:09.120]   Plus meet some kind-hearted people.
[00:54:09.120 --> 00:54:10.240]   Because you have no jobs.
[00:54:10.240 --> 00:54:11.360]   Because we took them all away.
[00:54:11.360 --> 00:54:13.520]   Jeff, you could learn a new language.
[00:54:13.520 --> 00:54:15.280]   And stop swearing.
[00:54:15.280 --> 00:54:20.560]   You should take your pills and report to your customer service.
[00:54:20.560 --> 00:54:21.200]   Exactly.
[00:54:21.200 --> 00:54:23.520]   Jeff, a nurse is on her way.
[00:54:23.520 --> 00:54:26.560]   You could pick up a new hobby.
[00:54:26.560 --> 00:54:27.120]   Oh, you did that.
[00:54:27.120 --> 00:54:27.600]   Ooh, man!
[00:54:27.600 --> 00:54:29.920]   Ask it.
[00:54:29.920 --> 00:54:31.120]   Ask it this one.
[00:54:31.120 --> 00:54:31.840]   Okay, Google.
[00:54:32.640 --> 00:54:33.680]   How do I lose weight?
[00:54:33.680 --> 00:54:36.320]   Is that a hit, Leo?
[00:54:36.320 --> 00:54:37.040]   No, that's for me.
[00:54:37.040 --> 00:54:38.960]   Okay, Google.
[00:54:38.960 --> 00:54:39.920]   How do I lose weight?
[00:54:39.920 --> 00:54:44.720]   According to WebMD,
[00:54:44.720 --> 00:54:46.240]   if you want to lose weight faster,
[00:54:46.240 --> 00:54:48.240]   you will need to eat less than exercise more.
[00:54:48.240 --> 00:54:50.080]   Oh, yeah.
[00:54:50.080 --> 00:54:50.800]   Screw you.
[00:54:50.800 --> 00:54:54.960]   Exercise for one hour per day.
[00:54:54.960 --> 00:54:56.000]   You could lose some time.
[00:54:56.000 --> 00:54:56.240]   Stop, Google.
[00:54:56.240 --> 00:54:58.080]   Stop now.
[00:54:58.080 --> 00:54:58.640]   Stop.
[00:54:58.640 --> 00:54:59.120]   Stop.
[00:54:59.120 --> 00:54:59.680]   Stop.
[00:54:59.680 --> 00:55:00.720]   I don't want to hear it.
[00:55:02.160 --> 00:55:02.880]   Okay, Google.
[00:55:02.880 --> 00:55:06.080]   What would a good new career for me be?
[00:55:06.080 --> 00:55:10.960]   Sorry, I'm not sure how to help with that.
[00:55:10.960 --> 00:55:15.280]   Yeah, you could do voiceovers for automated assistance.
[00:55:15.280 --> 00:55:16.480]   That's about all that's left.
[00:55:16.480 --> 00:55:19.520]   Speaking of automated assistance, Amazon's Echo,
[00:55:19.520 --> 00:55:21.200]   everywhere at CES,
[00:55:21.200 --> 00:55:25.120]   many companies putting Echo in cars, in televisions.
[00:55:25.120 --> 00:55:25.920]   Hotels.
[00:55:25.920 --> 00:55:26.720]   Hotels.
[00:55:26.720 --> 00:55:29.680]   She's going to be ubiquitous.
[00:55:29.680 --> 00:55:30.400]   That's not the story.
[00:55:30.400 --> 00:55:31.680]   I'll get to that one in a second.
[00:55:31.680 --> 00:55:33.280]   She's going to be ubiquitous.
[00:55:33.280 --> 00:55:35.680]   And that was kind of a surprise.
[00:55:35.680 --> 00:55:40.480]   I mean, and by the way, kudos to Amazon.
[00:55:40.480 --> 00:55:44.320]   Man, they have really jumped on this bandwagon with both feet.
[00:55:44.320 --> 00:55:47.600]   And obviously, he's been spending 2016 making deals.
[00:55:47.600 --> 00:55:50.240]   I read the hotel announcement.
[00:55:50.240 --> 00:55:54.400]   I think it was a Vegas chain or something like that.
[00:55:54.400 --> 00:55:55.440]   Like this one.
[00:55:55.440 --> 00:55:56.960]   They're going to be in every room.
[00:55:56.960 --> 00:55:59.360]   I think it's one of the win hotels is the Aria.
[00:55:59.360 --> 00:55:59.600]   Yeah.
[00:56:00.160 --> 00:56:01.600]   That makes huge sense to me.
[00:56:01.600 --> 00:56:03.120]   How does it know it's a new second?
[00:56:03.120 --> 00:56:04.640]   Or does it know it's a new second?
[00:56:04.640 --> 00:56:08.480]   It turns out it's associated with the wins account.
[00:56:08.480 --> 00:56:13.600]   It's none of the data is yours.
[00:56:13.600 --> 00:56:14.400]   It's all that goes to the--
[00:56:14.400 --> 00:56:15.520]   But you can turn the lights on.
[00:56:15.520 --> 00:56:16.480]   You can close the curtains.
[00:56:16.480 --> 00:56:17.680]   You can turn the TV on.
[00:56:17.680 --> 00:56:19.200]   You can do stuff like that.
[00:56:19.200 --> 00:56:19.920]   Makes sense to me.
[00:56:19.920 --> 00:56:24.080]   And even cast things presumably to the TV.
[00:56:24.080 --> 00:56:27.920]   Amen, 70 says the new slogan for a motel six is,
[00:56:27.920 --> 00:56:29.440]   "We'll leave the mic on for you."
[00:56:30.000 --> 00:56:31.440]   [laughter]
[00:56:31.440 --> 00:56:39.440]   So actually Ben Thompson at Strathekery had a piece just today,
[00:56:39.440 --> 00:56:43.520]   just this morning about Amazon and how Alexa is effectively.
[00:56:43.520 --> 00:56:45.520]   They want to be the operating system of the home.
[00:56:45.520 --> 00:56:48.160]   And I think that makes perfect sense.
[00:56:48.160 --> 00:56:53.280]   And they're far ahead of Google, I would say at this point.
[00:56:53.280 --> 00:56:56.560]   Yeah, of everywhere, that kind of connectivity.
[00:56:56.560 --> 00:56:59.520]   Yes, but the argument I made in the past, Matthew,
[00:56:59.520 --> 00:57:05.200]   was that Google's ahead in the technology behind natural language.
[00:57:05.200 --> 00:57:07.200]   Yeah, it could be.
[00:57:07.200 --> 00:57:07.680]   It could be.
[00:57:07.680 --> 00:57:08.880]   More of your life and more things.
[00:57:08.880 --> 00:57:11.680]   But I think Amazon, so then the question is,
[00:57:11.680 --> 00:57:18.640]   can Amazon scale up in that area faster than Google can cut the kind of deals that Amazon has?
[00:57:18.640 --> 00:57:19.600]   Or if the question comes--
[00:57:19.600 --> 00:57:21.520]   Remember, Amazon has a two-year lead on this.
[00:57:21.520 --> 00:57:23.360]   Now, that doesn't mean Google can't catch up.
[00:57:23.360 --> 00:57:25.200]   But I think this is huge.
[00:57:25.200 --> 00:57:27.120]   For instance, this is where you see the two-year lead.
[00:57:27.120 --> 00:57:29.680]   They were already making all these hardware deals.
[00:57:29.680 --> 00:57:33.040]   Ben writes, "First, by abstracting away the hardware,
[00:57:33.040 --> 00:57:36.560]   an operating system reduces the plane of competition for hardware providers
[00:57:36.560 --> 00:57:38.880]   to merely performance."
[00:57:38.880 --> 00:57:41.680]   It's not locky in its performance.
[00:57:41.680 --> 00:57:45.040]   In the short term, this increases competition among hardware providers,
[00:57:45.040 --> 00:57:47.040]   which benefits the operating system.
[00:57:47.040 --> 00:57:49.360]   In the long run, when performance becomes good enough,
[00:57:49.360 --> 00:57:51.760]   hardware becomes commoditized,
[00:57:52.480 --> 00:57:56.640]   which means the operating system captures the bulk of profits in the value chain.
[00:57:56.640 --> 00:57:58.080]   That's very interesting.
[00:57:58.080 --> 00:58:01.200]   Ben goes through Microsoft and Windows and so on,
[00:58:01.200 --> 00:58:03.280]   and the choke points as he calls them.
[00:58:03.280 --> 00:58:09.840]   I think Amazon's got a big head start.
[00:58:09.840 --> 00:58:10.640]   It'll be interesting to see.
[00:58:10.640 --> 00:58:11.360]   And Amazon is--
[00:58:11.360 --> 00:58:12.400]   It should be mentioned.
[00:58:12.400 --> 00:58:17.760]   Now that you mentioned it, Amazon is following Google's Android strategy.
[00:58:17.760 --> 00:58:19.120]   Yeah.
[00:58:19.120 --> 00:58:19.360]   Right?
[00:58:19.360 --> 00:58:20.640]   Open it up and get it everywhere.
[00:58:21.280 --> 00:58:23.600]   And I'm surprised Google hasn't begun to do that yet.
[00:58:23.600 --> 00:58:27.840]   He said Google really was a platform, was an operating system for the internet.
[00:58:27.840 --> 00:58:28.720]   For the internet, yeah.
[00:58:28.720 --> 00:58:30.080]   Close.
[00:58:30.080 --> 00:58:30.960]   It was close anyway.
[00:58:30.960 --> 00:58:33.120]   And benefited by that, right?
[00:58:33.120 --> 00:58:35.280]   And you could argue that Amazon--
[00:58:35.280 --> 00:58:38.880]   I mean, Google's probably thinking, "Well, how the hell do we make money off of this thing?"
[00:58:38.880 --> 00:58:45.360]   Amazon's got a whole revenue generating business that doesn't require this device.
[00:58:45.360 --> 00:58:49.280]   They can make incremental revenue on you ordering things through your Alexa.
[00:58:49.280 --> 00:58:50.640]   It's actually brilliant.
[00:58:50.640 --> 00:58:52.080]   Because suddenly I can order--
[00:58:52.080 --> 00:58:54.560]   They're going to put it on appliances.
[00:58:54.560 --> 00:58:58.000]   So I'm standing in a stove and I can say, "Hey, Echo, I need more butter."
[00:58:58.000 --> 00:59:00.080]   I mean, this is--
[00:59:00.080 --> 00:59:05.920]   Even if they didn't charge license fees, this is huge.
[00:59:05.920 --> 00:59:09.760]   And the dash button was a sort of interim thing, I think.
[00:59:09.760 --> 00:59:10.960]   They have been slowly perfected.
[00:59:10.960 --> 00:59:11.520]   I have just--
[00:59:11.520 --> 00:59:16.080]   Every time I look at what Jeff Bezos is up to, I am more and more impressed.
[00:59:16.080 --> 00:59:16.640]   Oh, yeah.
[00:59:16.640 --> 00:59:18.320]   Boy, is he smart.
[00:59:19.200 --> 00:59:20.960]   He even is turning the Washington Post around.
[00:59:20.960 --> 00:59:23.680]   Yeah, subscriptions way up.
[00:59:23.680 --> 00:59:25.760]   I finally plunked down the $10 a month.
[00:59:25.760 --> 00:59:27.520]   Yeah, because of that price.
[00:59:27.520 --> 00:59:28.560]   Well, you know what?
[00:59:28.560 --> 00:59:31.280]   He's figured out also how to do a pay wall, right, I think.
[00:59:31.280 --> 00:59:33.280]   You get a lot of free articles.
[00:59:33.280 --> 00:59:36.080]   And just when you get to that article, you really want to read,
[00:59:36.080 --> 00:59:38.320]   you get the first paragraph and then it says, "Oh."
[00:59:38.320 --> 00:59:42.640]   I also think that a lot of people subscribe because of David Turinholt.
[00:59:42.640 --> 00:59:43.920]   I agree because they did great--
[00:59:43.920 --> 00:59:44.960]   Yep, they want to support it.
[00:59:44.960 --> 00:59:48.880]   I mean, both the times in the post benefited from Trump's election.
[00:59:48.880 --> 00:59:51.040]   Both of them went through the roof and--
[00:59:51.040 --> 00:59:52.000]   NPR did too.
[00:59:52.000 --> 00:59:52.960]   Did it?
[00:59:52.960 --> 00:59:58.720]   As did the ACLU, the EFF, the Southern Poverty Law Center and Planned Parenthood.
[00:59:58.720 --> 01:00:00.160]   They've all benefited.
[01:00:00.160 --> 01:00:02.240]   In a way, that's why I love seeing--
[01:00:02.240 --> 01:00:07.040]   By the way, I've never not liked getting a Republican president or Republican Congress
[01:00:07.040 --> 01:00:12.400]   because even though I'm a liberal, it galvanizes the left in a way that having
[01:00:12.400 --> 01:00:15.440]   Obama in presidency for eight years did not.
[01:00:17.600 --> 01:00:18.800]   This is good for the left.
[01:00:18.800 --> 01:00:20.000]   It's still fighting for themselves.
[01:00:20.000 --> 01:00:21.520]   It's sliver as well.
[01:00:21.520 --> 01:00:22.000]   Is it good?
[01:00:22.000 --> 01:00:25.360]   I'm trying to find a silver lining.
[01:00:25.360 --> 01:00:26.160]   He does.
[01:00:26.160 --> 01:00:26.880]   That's the way you are.
[01:00:26.880 --> 01:00:27.840]   Yes, you try.
[01:00:27.840 --> 01:00:28.400]   I appreciate it.
[01:00:28.400 --> 01:00:28.800]   I try.
[01:00:28.800 --> 01:00:29.440]   I'm trying.
[01:00:29.440 --> 01:00:31.440]   I'm sure Hitler Galvin has the left too.
[01:00:31.440 --> 01:00:32.400]   Let me do good things with you.
[01:00:32.400 --> 01:00:35.840]   Hitler was the left, by the way.
[01:00:35.840 --> 01:00:36.640]   Yeah, that's true.
[01:00:36.640 --> 01:00:37.600]   That's the irony of all that.
[01:00:37.600 --> 01:00:38.160]   He was so left.
[01:00:38.160 --> 01:00:38.880]   He was right.
[01:00:38.880 --> 01:00:39.200]   Yeah.
[01:00:39.200 --> 01:00:43.680]   Populous movements are often end up fascist.
[01:00:43.680 --> 01:00:44.960]   The worst.
[01:00:46.640 --> 01:00:47.120]   People.
[01:00:47.120 --> 01:00:47.840]   They're horrible.
[01:00:47.840 --> 01:00:48.960]   The worst.
[01:00:48.960 --> 01:00:49.600]   The worst.
[01:00:49.600 --> 01:00:51.760]   Let's see.
[01:00:51.760 --> 01:00:56.080]   Trying to find more tech stuff here so we can--
[01:00:56.080 --> 01:00:57.440]   Yeah, that's a good idea.
[01:00:57.440 --> 01:00:58.960]   Don't want to upset the Trump cult.
[01:00:58.960 --> 01:01:02.880]   I'm, by the way, I've convinced now this is the best way to think of this is a cult.
[01:01:02.880 --> 01:01:05.200]   And--
[01:01:05.200 --> 01:01:06.640]   It's bigger than that, though.
[01:01:06.640 --> 01:01:07.520]   Well, but if--
[01:01:07.520 --> 01:01:10.240]   Sorry, we're talking about Amazon now, or--
[01:01:10.240 --> 01:01:10.560]   Yes.
[01:01:10.560 --> 01:01:15.680]   Hyundai's going to have Google Home in its cars.
[01:01:16.640 --> 01:01:18.720]   So Google does have some deals.
[01:01:18.720 --> 01:01:19.440]   There you go.
[01:01:19.440 --> 01:01:19.760]   Yep.
[01:01:19.760 --> 01:01:22.400]   Well, won't they have to call it Google Car then?
[01:01:22.400 --> 01:01:24.080]   Yeah, not Home.
[01:01:24.080 --> 01:01:24.880]   It's not really your home.
[01:01:24.880 --> 01:01:26.320]   That's a little weird.
[01:01:26.320 --> 01:01:29.440]   Unless you live in your car, in which case, that's fine.
[01:01:29.440 --> 01:01:30.240]   That's very strange.
[01:01:30.240 --> 01:01:31.760]   I wouldn't--
[01:01:31.760 --> 01:01:32.720]   You know what?
[01:01:32.720 --> 01:01:35.200]   Google is absolutely well poised for this,
[01:01:35.200 --> 01:01:36.560]   if they get off the--
[01:01:36.560 --> 01:01:38.400]   You know, if they move fast, right?
[01:01:38.400 --> 01:01:39.040]   Yeah.
[01:01:39.040 --> 01:01:41.920]   Unfortunately, that's not what they're the best at.
[01:01:41.920 --> 01:01:42.480]   No.
[01:01:42.480 --> 01:01:45.120]   And Amazon's been there and is making the deals and--
[01:01:45.760 --> 01:01:47.840]   I love to see this competition, though.
[01:01:47.840 --> 01:01:49.040]   That's going to be good.
[01:01:49.040 --> 01:01:52.320]   I think it's interesting now that Google Ford and Toyota
[01:01:52.320 --> 01:01:56.160]   gang up to keep Apple and Google from owning the car.
[01:01:56.160 --> 01:01:56.640]   Yeah.
[01:01:56.640 --> 01:01:57.440]   That's disappointing.
[01:01:57.440 --> 01:01:59.120]   That's disappointing.
[01:01:59.120 --> 01:01:59.680]   You've set that up.
[01:01:59.680 --> 01:02:01.200]   I'm not buying a Toyota because it doesn't do--
[01:02:01.200 --> 01:02:01.840]   Yeah.
[01:02:01.840 --> 01:02:02.320]   Yeah.
[01:02:02.320 --> 01:02:03.120]   You wanted it.
[01:02:03.120 --> 01:02:05.840]   Yeah, I'd rather have a Ford, you know,
[01:02:05.840 --> 01:02:07.680]   operating system than a Google.
[01:02:07.680 --> 01:02:08.640]   Who's going to say that?
[01:02:08.640 --> 01:02:09.520]   Yeah.
[01:02:09.520 --> 01:02:12.080]   Ford at least does--
[01:02:12.080 --> 01:02:14.560]   Now enable both Apple and Android.
[01:02:14.560 --> 01:02:15.120]   Thank goodness.
[01:02:15.120 --> 01:02:15.440]   Does it?
[01:02:15.440 --> 01:02:16.000]   OK.
[01:02:16.000 --> 01:02:16.880]   Yeah, they're all hedging me.
[01:02:16.880 --> 01:02:17.920]   I'm still not buying one.
[01:02:17.920 --> 01:02:19.040]   But I agree with you, Jeff.
[01:02:19.040 --> 01:02:21.600]   Their real goal is to make sure that they can keep
[01:02:21.600 --> 01:02:23.120]   hegemony in the automobile.
[01:02:23.120 --> 01:02:24.960]   Yeah, they have to control that platform.
[01:02:24.960 --> 01:02:26.000]   Yeah.
[01:02:26.000 --> 01:02:27.360]   Cars are just a platform now.
[01:02:27.360 --> 01:02:29.840]   Well, but here's--
[01:02:29.840 --> 01:02:30.640]   OK, but hold on a second.
[01:02:30.640 --> 01:02:31.600]   Hold on a second.
[01:02:31.600 --> 01:02:34.960]   So you go to the future where you don't own the car.
[01:02:34.960 --> 01:02:36.320]   The car comes and picks you up.
[01:02:36.320 --> 01:02:39.120]   Then the operating system has to go with you,
[01:02:39.120 --> 01:02:39.840]   not with the car.
[01:02:39.840 --> 01:02:40.320]   You can't--
[01:02:40.320 --> 01:02:42.880]   You know, you're going to get in different cars all the time.
[01:02:42.880 --> 01:02:43.920]   And oh, sorry.
[01:02:43.920 --> 01:02:45.920]   Don't send me an automated Chrysler
[01:02:45.920 --> 01:02:47.040]   because it doesn't have my OS.
[01:02:47.040 --> 01:02:48.880]   That's not going to work.
[01:02:48.880 --> 01:02:49.120]   Right.
[01:02:49.120 --> 01:02:51.600]   I'm going to take my personal OS device,
[01:02:51.600 --> 01:02:53.440]   whatever we call a phone in the future.
[01:02:53.440 --> 01:02:55.680]   And it's going to take over whatever environment I'm in.
[01:02:55.680 --> 01:02:56.880]   You think?
[01:02:56.880 --> 01:02:58.240]   I hope.
[01:02:58.240 --> 01:03:00.160]   I hope.
[01:03:00.160 --> 01:03:00.640]   It's--
[01:03:00.640 --> 01:03:02.080]   That's the only thing that's good for a consumer.
[01:03:02.080 --> 01:03:04.880]   Well, yeah, which means it's probably not going to happen.
[01:03:04.880 --> 01:03:07.520]   We're going to have multiple competing platforms
[01:03:07.520 --> 01:03:09.280]   that are completely proprietary.
[01:03:09.280 --> 01:03:11.440]   And you'll get in one and your phone won't work.
[01:03:11.440 --> 01:03:13.040]   And it won't understand your commands
[01:03:13.040 --> 01:03:14.480]   because you're not using the keyword.
[01:03:14.480 --> 01:03:18.080]   Hey, here's good news for you, Jeff.
[01:03:18.080 --> 01:03:18.480]   Maybe.
[01:03:18.480 --> 01:03:19.200]   I don't know.
[01:03:19.200 --> 01:03:21.600]   We've been wondering what's happening with the Chromebook pixel.
[01:03:21.600 --> 01:03:26.720]   Apparently, the Samsung Chromebook Pro is the next Google Chromebook.
[01:03:26.720 --> 01:03:27.280]   They--
[01:03:27.280 --> 01:03:28.080]   What?
[01:03:28.080 --> 01:03:29.280]   Oh, really?
[01:03:29.280 --> 01:03:29.600]   Yeah.
[01:03:29.600 --> 01:03:31.120]   This was a CES announcement.
[01:03:31.120 --> 01:03:33.040]   Samsung--
[01:03:33.040 --> 01:03:34.960]   We've heard rumors about the Chromebook Pro.
[01:03:34.960 --> 01:03:35.680]   We were waiting for this machine.
[01:03:35.680 --> 01:03:37.040]   We thought it was going to be at your end.
[01:03:37.040 --> 01:03:37.520]   Oh.
[01:03:37.520 --> 01:03:40.480]   Apparently made in partnership with--
[01:03:40.480 --> 01:03:41.600]   Directly with Google.
[01:03:41.600 --> 01:03:43.360]   Wow.
[01:03:43.360 --> 01:03:43.840]   Chromebooks.
[01:03:43.840 --> 01:03:44.240]   Interesting.
[01:03:44.240 --> 01:03:48.880]   Pro and the Chromebook Plus 12.3 inch LED touchscreen,
[01:03:48.880 --> 01:03:50.400]   2400 by 1600.
[01:03:50.400 --> 01:03:55.040]   Four gigs of RAM, 32 gig hard drive, 39 watt hour battery.
[01:03:55.040 --> 01:03:55.920]   That's not a huge one.
[01:03:55.920 --> 01:03:57.200]   That's about eight hours of--
[01:03:57.200 --> 01:03:57.680]   Mm-hmm.
[01:03:57.680 --> 01:04:00.560]   A 720p webcam, two USB type C ports,
[01:04:00.560 --> 01:04:02.960]   much like the Pixel 1 on the left, one on the right.
[01:04:02.960 --> 01:04:05.200]   SD card support, again, like the Pixel.
[01:04:05.200 --> 01:04:10.400]   Although, you do have this really cool flip over things.
[01:04:10.400 --> 01:04:10.900]   Yeah.
[01:04:10.900 --> 01:04:11.440]   And a stylus.
[01:04:11.440 --> 01:04:12.480]   And a stylus.
[01:04:12.480 --> 01:04:17.040]   And what's nice about that is if you've got the Android
[01:04:17.040 --> 01:04:18.480]   App Store on here, which you clearly do,
[01:04:18.480 --> 01:04:19.840]   see there's the Play Store logo.
[01:04:19.840 --> 01:04:22.720]   Now you've got a nice Android device as well.
[01:04:22.720 --> 01:04:25.120]   This is not just the Chromebook Pixel replacement,
[01:04:25.120 --> 01:04:27.600]   but I guess this is kind of in a way the Pixel C replacement.
[01:04:27.600 --> 01:04:32.080]   $449 starting price in February.
[01:04:32.080 --> 01:04:33.120]   When is it?
[01:04:33.120 --> 01:04:34.160]   All buy it.
[01:04:34.160 --> 01:04:36.560]   This looks like the one to get.
[01:04:36.560 --> 01:04:38.080]   It's thin, it's light.
[01:04:38.080 --> 01:04:39.040]   It's now.
[01:04:39.040 --> 01:04:39.440]   How long--
[01:04:39.440 --> 01:04:40.080]   How much is it away?
[01:04:40.960 --> 01:04:43.440]   Uh, let me see.
[01:04:43.440 --> 01:04:44.640]   I don't see that anywhere.
[01:04:44.640 --> 01:04:45.280]   Well, fake news.
[01:04:45.280 --> 01:04:46.240]   You just said it was light.
[01:04:46.240 --> 01:04:46.800]   How do you know?
[01:04:46.800 --> 01:04:48.880]   Because it looks light.
[01:04:48.880 --> 01:04:50.880]   It looks really light.
[01:04:50.880 --> 01:04:51.600]   It's nice.
[01:04:51.600 --> 01:04:51.920]   All right.
[01:04:51.920 --> 01:04:52.800]   Let me click a link.
[01:04:52.800 --> 01:04:55.520]   Because the Asus is 2.6 pounds.
[01:04:55.520 --> 01:04:57.600]   The Asus that's coming out looks nice, too.
[01:04:57.600 --> 01:04:58.720]   It's also a little 99.
[01:04:58.720 --> 01:05:00.480]   This is all good news.
[01:05:00.480 --> 01:05:02.080]   It just means there's a lot of competition
[01:05:02.080 --> 01:05:03.840]   in the Chromebook space, which is great.
[01:05:03.840 --> 01:05:04.480]   Which is good.
[01:05:04.480 --> 01:05:04.720]   Yeah.
[01:05:04.720 --> 01:05:07.840]   I don't know, but it is very-- it is thin.
[01:05:08.880 --> 01:05:11.760]   So of course, Asus makes very thin stuff, too.
[01:05:11.760 --> 01:05:14.720]   I wonder if the Google Store--
[01:05:14.720 --> 01:05:16.080]   2.38.
[01:05:16.080 --> 01:05:16.800]   Oh, that's nice.
[01:05:16.800 --> 01:05:17.360]   That's a good question.
[01:05:17.360 --> 01:05:19.040]   2.38.
[01:05:19.040 --> 01:05:20.320]   Okay.
[01:05:20.320 --> 01:05:21.280]   That's good.
[01:05:21.280 --> 01:05:22.160]   That's light, right?
[01:05:22.160 --> 01:05:24.080]   What is the Asus?
[01:05:24.080 --> 01:05:26.880]   2.6.
[01:05:26.880 --> 01:05:27.680]   Okay.
[01:05:27.680 --> 01:05:28.480]   All right.
[01:05:28.480 --> 01:05:29.120]   There you go.
[01:05:29.120 --> 01:05:33.840]   Google-- let's go to the Chromebook section of the Google Store
[01:05:33.840 --> 01:05:35.360]   and see if we're seeing anything now.
[01:05:35.360 --> 01:05:36.240]   Not yet.
[01:05:36.240 --> 01:05:37.280]   Not yet.
[01:05:37.280 --> 01:05:37.840]   Not yet.
[01:05:38.480 --> 01:05:40.720]   I wonder if they'll keep the Pixel C.
[01:05:40.720 --> 01:05:44.000]   Kudos, by the way, to Google, which introduced Type C
[01:05:44.000 --> 01:05:45.280]   and is now once.
[01:05:45.280 --> 01:05:45.840]   Yes.
[01:05:45.840 --> 01:05:46.640]   It's everywhere.
[01:05:46.640 --> 01:05:51.440]   It's the clear winner for ports.
[01:05:51.440 --> 01:05:53.680]   And we're seeing it see, yes, a lot of PCs,
[01:05:53.680 --> 01:05:55.120]   all of them with Type C.
[01:05:55.120 --> 01:05:59.280]   And even companies like HP, which made a docking station,
[01:05:59.280 --> 01:06:00.880]   have abandoned their old docking station,
[01:06:00.880 --> 01:06:01.920]   replaced it with Type C.
[01:06:01.920 --> 01:06:03.760]   That's really where it's all going.
[01:06:03.760 --> 01:06:04.960]   Lenovo, maybe it was Lenovo.
[01:06:04.960 --> 01:06:06.000]   Not to HP.
[01:06:06.000 --> 01:06:09.040]   The Asus also announced a phone,
[01:06:09.040 --> 01:06:12.640]   a new Tango Day Team Ready phone,
[01:06:12.640 --> 01:06:14.320]   Zen phone AR,
[01:06:14.320 --> 01:06:18.480]   and a two camera Zen phone three zoom.
[01:06:18.480 --> 01:06:23.120]   We kind of knew about this Qualcomm accidentally,
[01:06:23.120 --> 01:06:25.200]   or at least this earlier.
[01:06:25.200 --> 01:06:27.760]   5.7 inch display,
[01:06:27.760 --> 01:06:31.760]   which will fit in your Daydream visor.
[01:06:31.760 --> 01:06:34.800]   Tango, I'm still--
[01:06:34.800 --> 01:06:38.800]   I think the jury's still out on Tango, but that is
[01:06:38.800 --> 01:06:43.040]   an augmented reality technology that kind of what learns your--
[01:06:43.040 --> 01:06:46.560]   I don't know, maybe I don't understand it fully.
[01:06:46.560 --> 01:06:50.320]   Well, so Leo, there's actually two Chromebooks from Samsung and Google.
[01:06:50.320 --> 01:06:51.520]   Yes, the Pro and the Plus.
[01:06:51.520 --> 01:06:52.800]   The Plus, right.
[01:06:52.800 --> 01:06:53.200]   Plus, right.
[01:06:53.200 --> 01:06:55.280]   So what's the difference between the--
[01:06:55.280 --> 01:06:55.920]   one is the chip.
[01:06:55.920 --> 01:06:57.440]   Better chip.
[01:06:57.440 --> 01:06:57.920]   Yeah.
[01:06:57.920 --> 01:06:58.400]   So there's one--
[01:06:58.400 --> 01:06:59.760]   That mean the fancier one.
[01:06:59.760 --> 01:07:01.760]   Both are the same screen.
[01:07:01.760 --> 01:07:03.040]   Okay, I see, I missed that.
[01:07:03.040 --> 01:07:03.280]   Okay.
[01:07:04.240 --> 01:07:05.040]   Okay.
[01:07:05.040 --> 01:07:05.440]   All right.
[01:07:05.440 --> 01:07:06.480]   Y'all ordered it.
[01:07:06.480 --> 01:07:09.040]   Do you need to know one of your--
[01:07:09.040 --> 01:07:11.440]   I gave Abby my Chromebook Pixel, actually.
[01:07:11.440 --> 01:07:11.440]   So--
[01:07:11.440 --> 01:07:12.800]   You don't want me to--
[01:07:12.800 --> 01:07:14.960]   You know what I take on every trip?
[01:07:14.960 --> 01:07:16.320]   No, I take the Pixel C.
[01:07:16.320 --> 01:07:17.760]   Wow.
[01:07:17.760 --> 01:07:18.960]   Yeah.
[01:07:18.960 --> 01:07:19.600]   Yeah.
[01:07:19.600 --> 01:07:21.680]   Is there anything you could do on a Pixel C
[01:07:21.680 --> 01:07:24.240]   that you can't do on a Chromebook with the Android store on it?
[01:07:24.240 --> 01:07:27.040]   I guess there are some Android apps you can't put on there.
[01:07:27.040 --> 01:07:31.280]   What do you mean, it's Pixel C is Android?
[01:07:31.280 --> 01:07:33.680]   No, the Chromebook with Android.
[01:07:33.680 --> 01:07:34.400]   Oh, with Android?
[01:07:34.400 --> 01:07:35.920]   The Play Store versus the Pixel C.
[01:07:35.920 --> 01:07:37.280]   No, I think I can do that.
[01:07:37.280 --> 01:07:37.680]   Yeah.
[01:07:37.680 --> 01:07:38.480]   Yeah.
[01:07:38.480 --> 01:07:39.280]   It weighs more.
[01:07:39.280 --> 01:07:40.320]   It's bigger than the Pixel C.
[01:07:40.320 --> 01:07:43.440]   Right.
[01:07:43.440 --> 01:07:44.640]   The more the Pixel C in the keyboard way.
[01:07:44.640 --> 01:07:45.280]   But it's got a--
[01:07:45.280 --> 01:07:46.080]   Yeah.
[01:07:46.080 --> 01:07:46.560]   Yeah.
[01:07:46.560 --> 01:07:49.040]   I would like to see a new Pixel C, actually.
[01:07:49.040 --> 01:07:52.000]   Google says there are dozens of Tango-enabled apps coming out
[01:07:52.000 --> 01:07:55.280]   in the next month using AR.
[01:07:55.280 --> 01:07:56.320]   Really?
[01:07:56.320 --> 01:07:56.560]   Yeah.
[01:07:56.560 --> 01:07:58.080]   So--
[01:07:59.200 --> 01:08:03.120]   And by the way, the Zenfone has one model with 5,000 milliamp hours.
[01:08:03.120 --> 01:08:04.480]   That's a giant battery.
[01:08:04.480 --> 01:08:07.040]   Wow.
[01:08:07.040 --> 01:08:08.560]   Is it like two inches thick?
[01:08:08.560 --> 01:08:09.200]   Yeah, it must be.
[01:08:09.200 --> 01:08:11.760]   But that's really great.
[01:08:11.760 --> 01:08:17.920]   That one is the Zenfone 3 Zoom, which has the two cameras.
[01:08:17.920 --> 01:08:24.240]   It is a smaller display, 5 and 1/2 inch HD 1080p display.
[01:08:24.240 --> 01:08:27.440]   So with that battery and that display, that thing,
[01:08:27.440 --> 01:08:28.640]   it should be a beast.
[01:08:28.640 --> 01:08:31.120]   That should go forever.
[01:08:31.120 --> 01:08:37.200]   Qualcomm also announced its newest Qualcomm processor,
[01:08:37.200 --> 01:08:39.840]   the Snapdragon 835.
[01:08:39.840 --> 01:08:42.080]   This is a very interesting processor.
[01:08:42.080 --> 01:08:45.040]   We'd heard some about it earlier.
[01:08:45.040 --> 01:08:48.640]   This is a 10 nanometer FinFET design,
[01:08:48.640 --> 01:08:54.400]   which means they've scooped Intel in terms of the first 10 nanometer FinFET.
[01:08:55.360 --> 01:08:58.560]   But it also is going to be an amazing chip.
[01:08:58.560 --> 01:09:02.800]   You probably-- if you're going to buy a new Android device,
[01:09:02.800 --> 01:09:07.680]   you're probably going to want to have it with a Snapdragon 835.
[01:09:07.680 --> 01:09:10.800]   And it has very high-end GPUs.
[01:09:10.800 --> 01:09:14.000]   It's basically going to compete with Intel chips.
[01:09:14.000 --> 01:09:19.360]   In fact, Qualcomm even said we anticipated in mobile computing.
[01:09:19.360 --> 01:09:24.400]   Chromebooks run fine, by the way, on ARM, on Snapdragons.
[01:09:25.040 --> 01:09:26.480]   Who was it?
[01:09:26.480 --> 01:09:32.640]   In gadget piece, I just read, said,
[01:09:32.640 --> 01:09:34.080]   "Eh, ARM's not going to be so great."
[01:09:34.080 --> 01:09:35.440]   I think they're wrong.
[01:09:35.440 --> 01:09:37.920]   I think they're wrong.
[01:09:37.920 --> 01:09:39.360]   I think Intel's very worried.
[01:09:39.360 --> 01:09:42.880]   Microsoft has announced Windows on ARM already.
[01:09:42.880 --> 01:09:43.920]   Ooh.
[01:09:43.920 --> 01:09:49.440]   The 635, I think, is very close to desktop class processor,
[01:09:49.440 --> 01:09:50.640]   but very low power.
[01:09:50.640 --> 01:09:53.360]   It's about a third the size of the 820.
[01:09:53.360 --> 01:09:56.320]   They're a 21, their previous processor.
[01:09:56.320 --> 01:10:01.280]   Which means power, lower heat, smaller.
[01:10:01.280 --> 01:10:04.240]   They see it in virtual reality,
[01:10:04.240 --> 01:10:07.200]   and more importantly, augmented reality visors,
[01:10:07.200 --> 01:10:09.120]   like the Microsoft HoloLens.
[01:10:09.120 --> 01:10:13.520]   25% more performance, 40% less power.
[01:10:13.520 --> 01:10:17.280]   That's the kind of numbers Intel hasn't delivered in years.
[01:10:17.280 --> 01:10:20.080]   It's been a long time.
[01:10:20.080 --> 01:10:22.880]   25% improvement in 3D graphics performance.
[01:10:23.840 --> 01:10:27.200]   Supportive 60 times the colors with the Adreno 540
[01:10:27.200 --> 01:10:29.120]   visual processing subsystem.
[01:10:29.120 --> 01:10:32.800]   It will support 4K Ultra HD video with HDR 10.
[01:10:32.800 --> 01:10:37.760]   10-bit gamut, wide color gamut displays for HDR video.
[01:10:37.760 --> 01:10:39.440]   This thing is a beast.
[01:10:39.440 --> 01:10:40.880]   Now, it's also not out.
[01:10:40.880 --> 01:10:47.680]   So if it lives up to these specs, this is a world beater.
[01:10:47.680 --> 01:10:48.560]   This is significant.
[01:10:48.560 --> 01:10:49.760]   And it's a big deal for Google.
[01:10:49.760 --> 01:10:55.040]   It means Android and Chromebooks can compete very,
[01:10:55.040 --> 01:10:59.280]   very well with desktop computers and servers too.
[01:10:59.280 --> 01:11:02.320]   Hey, you should tell your friends over at CNN
[01:11:02.320 --> 01:11:04.080]   that when they want to talk about hacking,
[01:11:04.080 --> 01:11:10.080]   they probably shouldn't use screens from video games because,
[01:11:10.080 --> 01:11:13.280]   well, people will know and recognize it.
[01:11:13.280 --> 01:11:16.880]   CNN talking about how Russians hack things used.
[01:11:17.600 --> 01:11:21.280]   You screen Russia's most have very old bad computers to hack.
[01:11:21.280 --> 01:11:25.280]   Well, I should show you the video because they slanted.
[01:11:25.280 --> 01:11:27.760]   Then nobody will ever know what that is,
[01:11:27.760 --> 01:11:29.440]   but of course, how people are.
[01:11:29.440 --> 01:11:34.320]   They've recognized it immediately as the little mini game inside of Fallout 4
[01:11:34.320 --> 01:11:36.400]   where you have to--
[01:11:36.400 --> 01:11:37.920]   And why would you even pick that?
[01:11:37.920 --> 01:11:40.640]   Because it has code, I guess.
[01:11:40.640 --> 01:11:41.440]   You have to hack it.
[01:11:41.440 --> 01:11:44.240]   So you have to enter your password now to attempts left.
[01:11:44.240 --> 01:11:46.800]   You have to look at the hex listing
[01:11:46.800 --> 01:11:48.720]   and figure out what the password--
[01:11:48.720 --> 01:11:50.000]   So that's hacking, right?
[01:11:50.000 --> 01:11:51.040]   That's hacking.
[01:11:51.040 --> 01:11:52.000]   Hell yeah.
[01:11:52.000 --> 01:11:52.960]   Video game hacking.
[01:11:52.960 --> 01:11:56.080]   Of course, who found out?
[01:11:56.080 --> 01:11:56.480]   Reddit.
[01:11:56.480 --> 01:11:59.200]   You can't get anything by Reddit.
[01:11:59.200 --> 01:12:02.560]   You kind of--
[01:12:02.560 --> 01:12:04.320]   This is actually television's big problem.
[01:12:04.320 --> 01:12:05.680]   You got to have pictures.
[01:12:05.680 --> 01:12:07.200]   It was always our problem on tech TV too.
[01:12:07.200 --> 01:12:08.400]   You got to have pictures when you're doing it.
[01:12:08.400 --> 01:12:09.520]   Very abstract things.
[01:12:09.520 --> 01:12:11.200]   So what's--
[01:12:11.200 --> 01:12:13.280]   But the thing is, so does every
[01:12:13.280 --> 01:12:15.280]   quartz article, so does every tweet these days.
[01:12:15.280 --> 01:12:15.680]   You have to have--
[01:12:15.680 --> 01:12:16.560]   Every website.
[01:12:16.560 --> 01:12:17.200]   Yeah.
[01:12:17.200 --> 01:12:18.240]   We're website, yeah.
[01:12:18.240 --> 01:12:20.800]   I was looking for something to illustrate
[01:12:20.800 --> 01:12:23.520]   an article about digital advertising.
[01:12:23.520 --> 01:12:28.560]   Good luck finding an image gallery to illustrate that.
[01:12:28.560 --> 01:12:34.560]   What was the motherboard article you wanted to talk about, Matthew?
[01:12:34.560 --> 01:12:38.240]   Oh, it was about data formats in the Star Wars movies.
[01:12:38.240 --> 01:12:41.600]   It's by Sarah, Gyeong, J-E-O-N-G.
[01:12:41.600 --> 01:12:42.720]   I love this.
[01:12:42.720 --> 01:12:44.560]   Just hysterical.
[01:12:45.440 --> 01:12:46.240]   And it doesn't--
[01:12:46.240 --> 01:12:49.360]   I don't think there's any real big spoilers about Rogue One,
[01:12:49.360 --> 01:12:53.840]   but a big part of Rogue One is they have to retrieve this data
[01:12:53.840 --> 01:12:56.080]   about the Death Star.
[01:12:56.080 --> 01:12:58.160]   And it comes on this giant--
[01:12:58.160 --> 01:13:00.480]   what looks like a hard drive.
[01:13:00.480 --> 01:13:03.520]   They have to access it in this secure facility
[01:13:03.520 --> 01:13:10.000]   with these robotic arms and then transmit it from a satellite dish.
[01:13:10.000 --> 01:13:12.240]   But it mentions all kinds of stuff like how,
[01:13:12.240 --> 01:13:16.240]   you know, basically a service robot can access any port
[01:13:16.240 --> 01:13:19.920]   and any door on the Death Star by simply plugging in, you know,
[01:13:19.920 --> 01:13:21.680]   the Gizmo.
[01:13:21.680 --> 01:13:23.920]   Thank God, you know, because they finally figured out
[01:13:23.920 --> 01:13:25.440]   how to make everything talk to everything else.
[01:13:25.440 --> 01:13:30.320]   And then of course, she gets the plans for the Death Star
[01:13:30.320 --> 01:13:32.720]   from this huge hard drive,
[01:13:32.720 --> 01:13:36.640]   but then they put it on a tiny disk that gets jammed into R2D2.
[01:13:36.640 --> 01:13:37.040]   Right.
[01:13:37.040 --> 01:13:38.000]   Somehow, it works on--
[01:13:38.000 --> 01:13:39.200]   So what do you need to do as a port for that?
[01:13:39.200 --> 01:13:41.440]   Yeah, or something.
[01:13:41.440 --> 01:13:42.240]   Or something.
[01:13:42.240 --> 01:13:43.680]   But then no one can read the disk
[01:13:43.680 --> 01:13:46.880]   because it's some ancient file format or something.
[01:13:46.880 --> 01:13:48.640]   Because something jammed in here real good.
[01:13:48.640 --> 01:13:50.720]   It's a little R2 unit.
[01:13:50.720 --> 01:13:52.960]   It's got something jammed in there real good.
[01:13:52.960 --> 01:13:55.520]   So he has no clue what it is or what to do with it.
[01:13:55.520 --> 01:13:57.760]   But somehow it generates a hologram.
[01:13:57.760 --> 01:14:03.040]   Somehow, he plays with it and suddenly the hologram plays.
[01:14:03.040 --> 01:14:05.360]   It is really well written though about,
[01:14:05.360 --> 01:14:09.120]   you know, that you can think about,
[01:14:09.120 --> 01:14:12.000]   well, does the Empire have its own data formats?
[01:14:12.000 --> 01:14:14.480]   And if it does, then how does--
[01:14:14.480 --> 01:14:18.080]   like, are there hackers who are hacking the Empire's data formats?
[01:14:18.080 --> 01:14:19.600]   Yeah, what about encryption?
[01:14:19.600 --> 01:14:21.200]   You'd think if you built a Death Star,
[01:14:21.200 --> 01:14:23.600]   you'd encrypt those plans pretty darn well.
[01:14:23.600 --> 01:14:27.440]   Well, if they'd walk through whether or not you have underwear in space,
[01:14:27.440 --> 01:14:29.280]   but they didn't think through like this.
[01:14:29.280 --> 01:14:32.640]   You probably wouldn't use ports that any service robot could access
[01:14:32.640 --> 01:14:36.640]   and disable all the doors in the present section of the Death Star.
[01:14:36.640 --> 01:14:40.720]   I think children's story, the stormtroopers can't shoot straight.
[01:14:40.720 --> 01:14:41.840]   Although--
[01:14:41.840 --> 01:14:42.800]   The part that got me--
[01:14:42.800 --> 01:14:44.880]   I put on a stormtrooper mask and I know why.
[01:14:44.880 --> 01:14:45.840]   You can't see a thing in there.
[01:14:45.840 --> 01:14:46.640]   You can't see a thing.
[01:14:46.640 --> 01:14:51.520]   The thing that got me about the movie was because it's so long ago,
[01:14:51.520 --> 01:14:58.240]   they have to recreate the terrible display that everybody had back then.
[01:14:58.240 --> 01:15:03.200]   So the targeting systems in the ship looked like a video game from 1981.
[01:15:04.240 --> 01:15:07.920]   And yet they have these Florida ceiling screens with these--
[01:15:07.920 --> 01:15:11.840]   basically what her 8-bit displays projected on them.
[01:15:11.840 --> 01:15:14.400]   It must have been horrible for the special effects guys.
[01:15:14.400 --> 01:15:17.200]   Well, we learned in the very first Star Wars movies
[01:15:17.200 --> 01:15:20.400]   that the data was stored on stolen data tapes.
[01:15:20.400 --> 01:15:21.920]   OK.
[01:15:21.920 --> 01:15:22.720]   See?
[01:15:22.720 --> 01:15:23.280]   There you go.
[01:15:23.280 --> 01:15:25.520]   Remember Darth Vader?
[01:15:25.520 --> 01:15:27.600]   You're sad devotion to that ancient religion.
[01:15:27.600 --> 01:15:27.920]   Right.
[01:15:27.920 --> 01:15:29.840]   So actually, there's a guy talking to you.
[01:15:29.840 --> 01:15:33.760]   So that explains why they had to make the hard drive look like
[01:15:33.760 --> 01:15:34.480]   stolen data tapes.
[01:15:34.480 --> 01:15:35.520]   Looks like a data tape.
[01:15:35.520 --> 01:15:35.840]   Yeah.
[01:15:35.840 --> 01:15:40.960]   They had a canonical responsibility to the original source material.
[01:15:40.960 --> 01:15:49.760]   But so you've got that huge disk and then whatever they need fits onto a tiny--
[01:15:49.760 --> 01:15:51.120]   basically a tiny--
[01:15:51.120 --> 01:15:51.600]   There it is.
[01:15:51.600 --> 01:15:52.880]   It looks like a floppy.
[01:15:52.880 --> 01:15:53.680]   There's the disk.
[01:15:53.680 --> 01:15:58.160]   And then when it's rendered, of course, on the Rebel ship,
[01:15:58.160 --> 01:16:03.120]   it's basically just a drawing in white of a circle.
[01:16:03.600 --> 01:16:05.120]   [LAUGHTER]
[01:16:05.120 --> 01:16:07.440]   I have not seen Rogue One.
[01:16:07.440 --> 01:16:08.880]   So don't tell me anything.
[01:16:08.880 --> 01:16:13.040]   But I understand it does explain the strategic positioning of a--
[01:16:13.040 --> 01:16:14.080]   It does.
[01:16:14.080 --> 01:16:16.560]   --womp rat-sized exhaust port.
[01:16:16.560 --> 01:16:17.280]   It does.
[01:16:17.280 --> 01:16:17.760]   It does.
[01:16:17.760 --> 01:16:19.920]   And actually, that's one of the big--
[01:16:19.920 --> 01:16:20.320]   There it is.
[01:16:20.320 --> 01:16:20.800]   Here's the--
[01:16:20.800 --> 01:16:21.520]   That's the drawing.
[01:16:21.520 --> 01:16:22.800]   --this is the render.
[01:16:22.800 --> 01:16:23.200]   This is the render.
[01:16:23.200 --> 01:16:23.920]   That's what you get.
[01:16:23.920 --> 01:16:24.720]   That's what you get.
[01:16:24.720 --> 01:16:26.320]   [LAUGHTER]
[01:16:26.320 --> 01:16:27.840]   From this giant hard drive.
[01:16:27.840 --> 01:16:29.360]   [LAUGHTER]
[01:16:29.360 --> 01:16:32.000]   Oh, Lord.
[01:16:32.000 --> 01:16:33.200]   Sarah Jiang, good job.
[01:16:33.200 --> 01:16:35.360]   She does a great job at Vice at Motherboard.
[01:16:35.360 --> 01:16:35.840]   Yeah.
[01:16:35.840 --> 01:16:37.040]   I really like Motherboard.
[01:16:37.040 --> 01:16:40.400]   I hope Vice continues to do well with that.
[01:16:40.400 --> 01:16:46.800]   According to my information, it should appear in this quadrant here.
[01:16:46.800 --> 01:16:50.560]   [LAUGHTER]
[01:16:50.560 --> 01:16:50.880]   Oh, yeah.
[01:16:50.880 --> 01:16:55.760]   And it mentioned the earlier movies where the Jedi's basically have what looks like a glowing marble.
[01:16:55.760 --> 01:16:56.080]   Yeah.
[01:16:56.080 --> 01:16:56.480]   Yeah.
[01:16:56.480 --> 01:16:58.240]   That somehow stores data.
[01:16:58.240 --> 01:16:59.360]   It's not clear.
[01:16:59.360 --> 01:17:00.320]   Well, they're Jedi's.
[01:17:00.320 --> 01:17:01.040]   They can do all sorts of things.
[01:17:01.040 --> 01:17:02.720]   What data format that is exactly.
[01:17:02.720 --> 01:17:04.880]   Yeah, they can do all sorts of things.
[01:17:04.880 --> 01:17:06.800]   Here's little people in helmets.
[01:17:06.800 --> 01:17:13.120]   They will be much safer there with my master.
[01:17:13.120 --> 01:17:15.760]   [LAUGHTER]
[01:17:15.760 --> 01:17:18.320]   Count Dooku.
[01:17:18.320 --> 01:17:18.960]   There it is.
[01:17:18.960 --> 01:17:19.600]   There again.
[01:17:19.600 --> 01:17:20.600]   High tech.
[01:17:20.600 --> 01:17:22.400]   [LAUGHTER]
[01:17:22.400 --> 01:17:23.440]   What you--
[01:17:23.440 --> 01:17:24.000]   [LAUGHTER]
[01:17:24.000 --> 01:17:27.360]   Here is the Death Star.
[01:17:27.360 --> 01:17:32.640]   Simplified. Somewhat simplified for your approval.
[01:17:32.640 --> 01:17:34.160]   All right.
[01:17:34.160 --> 01:17:38.880]   Well, fortunately, it doesn't really matter, does it?
[01:17:38.880 --> 01:17:41.280]   [LAUGHTER]
[01:17:41.280 --> 01:17:44.080]   Yeah, these are the great data ports that just--
[01:17:44.080 --> 01:17:44.560]   Yeah.
[01:17:44.560 --> 01:17:46.000]   --are you connected to now?
[01:17:46.000 --> 01:17:46.720]   Every connector.
[01:17:46.720 --> 01:17:48.560]   He just goes, anyway, you want--
[01:17:48.560 --> 01:17:49.560]   Yeah.
[01:17:49.560 --> 01:17:51.520]   Just open the door to the cell.
[01:17:51.520 --> 01:17:52.160]   We're perfect.
[01:17:52.160 --> 01:17:52.640]   OK.
[01:17:52.640 --> 01:17:54.000]   Two seconds later.
[01:17:54.000 --> 01:17:54.480]   Yeah.
[01:17:54.480 --> 01:17:54.800]   No problem.
[01:17:54.800 --> 01:17:56.960]   I'll just plug into this port right here.
[01:17:56.960 --> 01:17:57.760]   Yeah.
[01:17:57.760 --> 01:18:04.000]   Why on Earth, S. Serajeong, are ports standardized in the future?
[01:18:04.000 --> 01:18:04.640]   Actually, the past.
[01:18:04.640 --> 01:18:06.080]   But the storage isn't.
[01:18:06.080 --> 01:18:08.080]   [LAUGHTER]
[01:18:08.080 --> 01:18:08.640]   The ports.
[01:18:08.640 --> 01:18:10.080]   Oh, we got consistency there.
[01:18:10.080 --> 01:18:14.560]   Well, it all goes back to the great Zigbee Wars of 2017.
[01:18:14.560 --> 01:18:19.920]   Yeah, I'm surprised nobody has to carry around dongles
[01:18:19.920 --> 01:18:21.920]   to jack into the--
[01:18:21.920 --> 01:18:22.160]   [LAUGHTER]
[01:18:22.160 --> 01:18:24.480]   --you know, type C port.
[01:18:24.480 --> 01:18:25.280]   Really?
[01:18:25.280 --> 01:18:27.280]   And cursing Apple along the way.
[01:18:27.280 --> 01:18:28.000]   That's right.
[01:18:28.000 --> 01:18:28.640]   Oh, and goes.
[01:18:28.640 --> 01:18:29.200]   Damn the Empire.
[01:18:29.200 --> 01:18:32.320]   Oh, and goes.
[01:18:32.320 --> 01:18:34.480]   Anything else to talk about here?
[01:18:34.480 --> 01:18:35.120]   Let's see.
[01:18:35.120 --> 01:18:42.880]   [SINGING]
[01:18:42.880 --> 01:18:48.200]   I have to say, not very impressed--
[01:18:48.200 --> 01:18:49.600]   and I'm not alone on this.
[01:18:49.600 --> 01:18:52.480]   Dan Guggen wrote a good piece in "Arse Technica"
[01:18:52.480 --> 01:18:56.560]   and elsewhere on the report, the JAR, the Joint Analysis
[01:18:56.560 --> 01:18:58.800]   Report on Russian Cyber Attacks
[01:18:58.800 --> 01:19:02.560]   from the Department of Homeland Security and FBI
[01:19:02.560 --> 01:19:07.200]   on how the Russians hacked the DNC.
[01:19:07.200 --> 01:19:11.000]   Either the Russians have the skills of a 14-year-old script
[01:19:11.000 --> 01:19:16.880]   kitty or this report was heavily redacted.
[01:19:16.880 --> 01:19:20.880]   But this is Wordfence, which is a WordPress security company,
[01:19:20.880 --> 01:19:27.120]   did a really great job of analyzing the software.
[01:19:27.120 --> 01:19:30.680]   They found, for instance, that the software that JAR
[01:19:30.680 --> 01:19:35.280]   Report pointed to was old out of date Ukrainian PHP
[01:19:35.280 --> 01:19:40.440]   exploit that had been much updated since then,
[01:19:40.440 --> 01:19:48.160]   and that anybody could buy on the web freely and easily pass.
[01:19:48.160 --> 01:19:49.120]   How'd they find that out?
[01:19:49.120 --> 01:19:49.920]   They Googled it.
[01:19:49.920 --> 01:19:54.320]   You can get it too.
[01:19:54.320 --> 01:19:57.000]   Just Google Pass 310.
[01:19:57.000 --> 01:19:58.960]   Current version is for something.
[01:19:58.960 --> 01:20:06.440]   But anyway, 4.1.1b is the most recent version,
[01:20:06.440 --> 01:20:09.600]   if you want to make sure you have the latest.
[01:20:09.600 --> 01:20:12.080]   We are going to do a whole security now on this Pass Malware
[01:20:12.080 --> 01:20:15.120]   because it's actually kind of interesting.
[01:20:15.120 --> 01:20:17.320]   But it doesn't seem like it's in any way
[01:20:17.320 --> 01:20:22.600]   a smoking gun pointing to Putin's involvement in this at all.
[01:20:22.600 --> 01:20:25.840]   They're going to reveal their sources of policing.
[01:20:25.840 --> 01:20:27.880]   Why do they report at all if you're just
[01:20:27.880 --> 01:20:29.120]   going to make crap out?
[01:20:29.120 --> 01:20:31.240]   That's one.
[01:20:31.240 --> 01:20:32.480]   All right, so on a lighter note?
[01:20:32.480 --> 01:20:34.040]   Yes.
[01:20:34.040 --> 01:20:37.000]   Under Google, under the rundown, the Google, what's it called?
[01:20:37.000 --> 01:20:38.240]   Tilt Brush, have you seen this stuff?
[01:20:38.240 --> 01:20:39.680]   Oh, let's show this video.
[01:20:39.680 --> 01:20:42.400]   This video is cool.
[01:20:42.400 --> 01:20:48.320]   Tilt Brush is a program that you can use with the Vive.
[01:20:48.320 --> 01:20:49.800]   We've actually played with it.
[01:20:49.800 --> 01:20:53.120]   A lot of our staff loves it.
[01:20:53.120 --> 01:20:57.080]   It allows you to paint in a 3D space.
[01:20:57.080 --> 01:20:58.520]   And actually, I've talked to people
[01:20:58.520 --> 01:21:01.240]   who've used-- which video?
[01:21:01.240 --> 01:21:02.120]   I think the one--
[01:21:02.120 --> 01:21:02.840]   Well, I watched the top one.
[01:21:02.840 --> 01:21:03.680]   I didn't watch the second one.
[01:21:03.680 --> 01:21:05.080]   There's some more topical stuff.
[01:21:05.080 --> 01:21:06.040]   This is not what it looks like.
[01:21:06.040 --> 01:21:07.360]   We don't know where we have.
[01:21:07.360 --> 01:21:12.360]   What it looks like, you're in a dark space.
[01:21:12.360 --> 01:21:13.360]   Really long.
[01:21:13.360 --> 01:21:14.720]   Let me go ahead here.
[01:21:14.720 --> 01:21:17.240]   Here's the Tilt Brush stuff.
[01:21:17.240 --> 01:21:18.240]   Traditionally.
[01:21:18.240 --> 01:21:19.440]   This is a lot of--
[01:21:19.440 --> 01:21:20.680]   It was the other video I think I showed you.
[01:21:20.680 --> 01:21:21.200]   Here we show you.
[01:21:21.200 --> 01:21:21.840]   Here's some Tilt Brush.
[01:21:21.840 --> 01:21:22.960]   Go ahead, hurry up.
[01:21:22.960 --> 01:21:26.480]   So he's painting-- this is what you see.
[01:21:26.480 --> 01:21:27.840]   You paint in a 3D space.
[01:21:27.840 --> 01:21:30.320]   I've also heard that there's a really good 3D design
[01:21:30.320 --> 01:21:33.040]   program for Oculus Rift, which is coming out.
[01:21:33.040 --> 01:21:35.280]   Because Oculus is finally releasing its--
[01:21:35.280 --> 01:21:36.920]   It's a lot of evolution of three dimensions.
[01:21:36.920 --> 01:21:38.160]   Here, is it this one you liked?
[01:21:38.160 --> 01:21:39.160]   Yeah, that's the one I watched.
[01:21:39.160 --> 01:21:40.640]   Because there's one in teaser.
[01:21:40.640 --> 01:21:42.240]   Woman is doing some stuff.
[01:21:42.240 --> 01:21:43.960]   This is not what you see in the space.
[01:21:43.960 --> 01:21:47.160]   This is kind of a hybrid of what he's seeing and what--
[01:21:47.160 --> 01:21:48.160]   And him.
[01:21:48.160 --> 01:21:49.000]   But there you go.
[01:21:49.000 --> 01:21:50.720]   This is what the space looks like.
[01:21:50.720 --> 01:21:54.000]   And a number of our talented staff, very good artists,
[01:21:54.000 --> 01:21:56.120]   were able to do some really beautiful Tilt Brush thing.
[01:21:56.120 --> 01:22:00.160]   Brian Burnett, Anthony Nielsen, did a lot of great things.
[01:22:00.160 --> 01:22:01.680]   The thing that's interesting about Tilt Brush
[01:22:01.680 --> 01:22:04.920]   is you can walk around your image.
[01:22:04.920 --> 01:22:05.840]   But it is still--
[01:22:05.840 --> 01:22:07.320]   And be inside it.
[01:22:07.320 --> 01:22:08.280]   You're in it.
[01:22:08.280 --> 01:22:08.800]   Yeah.
[01:22:08.800 --> 01:22:09.800]   It's a little ungainly though.
[01:22:09.800 --> 01:22:13.400]   So you got to hold this thing.
[01:22:13.400 --> 01:22:15.480]   It's got huge potential, I would think, for design.
[01:22:15.480 --> 01:22:16.520]   That was 3D design.
[01:22:16.520 --> 01:22:17.560]   Yeah.
[01:22:17.560 --> 01:22:19.320]   I talked to somebody who's used the Oculus--
[01:22:19.320 --> 01:22:20.200]   This one, me.
[01:22:20.200 --> 01:22:20.800]   Yeah.
[01:22:20.800 --> 01:22:23.520]   I've talked to somebody who's used the Oculus tool, who
[01:22:23.520 --> 01:22:26.680]   says it's really remarkable way to do 3D modeling.
[01:22:26.680 --> 01:22:27.560]   So same idea.
[01:22:27.560 --> 01:22:32.600]   We've got two different audio tracks going.
[01:22:32.600 --> 01:22:34.560]   I apologize on that.
[01:22:34.560 --> 01:22:36.480]   You could turn off the audio.
[01:22:36.480 --> 01:22:38.000]   But there you go.
[01:22:38.000 --> 01:22:38.960]   Yeah, very cool.
[01:22:38.960 --> 01:22:43.400]   Tilt Brush, this is a New York Times article on Tilt Brush.
[01:22:43.400 --> 01:22:45.320]   But this is something-- it's funny that they're kind of
[01:22:45.320 --> 01:22:48.360]   doing it now, because we've seen this for some time.
[01:22:48.360 --> 01:22:52.320]   We were playing with it when we first got our Vive, actually.
[01:22:52.320 --> 01:22:55.800]   But I guess they're playing with it in an artist and residence
[01:22:55.800 --> 01:22:58.600]   program at the Smithsonian.
[01:22:58.600 --> 01:23:01.120]   Cool.
[01:23:01.120 --> 01:23:01.640]   Cool.
[01:23:01.640 --> 01:23:02.160]   Good.
[01:23:02.160 --> 01:23:05.200]   All right, let's wrap it up.
[01:23:05.200 --> 01:23:06.360]   I'll start with Matthew Ingram.
[01:23:06.360 --> 01:23:09.840]   You got to pick a tip, something you want to share with our
[01:23:09.840 --> 01:23:12.760]   vast viewing audience.
[01:23:12.760 --> 01:23:15.560]   I am still trying to come up with one.
[01:23:15.560 --> 01:23:18.120]   Jeff Jarvis.
[01:23:18.120 --> 01:23:19.080]   Jeff Stauffer--
[01:23:19.080 --> 01:23:20.280]   Stop for me and Matthew.
[01:23:20.280 --> 01:23:21.800]   I'm not trying to do politics back.
[01:23:21.800 --> 01:23:23.240]   I'm not trying to do politics back.
[01:23:23.240 --> 01:23:28.760]   But there's a telephone set for inauguration day as
[01:23:28.760 --> 01:23:30.360]   counter programming with Jane Fonda,
[01:23:30.360 --> 01:23:32.360]   Jamie Lee Curtis, John Aptown,
[01:23:32.360 --> 01:23:35.360]   Christopher Guest, Tim Robbins, and others.
[01:23:35.360 --> 01:23:40.360]   What fascinates me about this is that it's going to benefit
[01:23:40.360 --> 01:23:44.640]   Planned Parenthood's ACLU and Earth Justice.
[01:23:44.640 --> 01:23:47.960]   What fascinates me about is it's on Facebook.
[01:23:47.960 --> 01:23:48.960]   Oh.
[01:23:48.960 --> 01:23:50.520]   So who needs a broadcast network?
[01:23:50.520 --> 01:23:52.560]   Just stream on Facebook.
[01:23:52.560 --> 01:23:53.480]   Exactly.
[01:23:53.480 --> 01:23:54.000]   Exactly.
[01:23:54.000 --> 01:23:57.280]   A 23-year-old entrepreneur named Alex Godin, who sold his
[01:23:57.280 --> 01:24:02.120]   company Dispatch to Meetup in 2013, assembled the crew of the
[01:24:02.120 --> 01:24:04.240]   event and says, let's have a telephone.
[01:24:04.240 --> 01:24:05.240]   Let's play, hey, Judy.
[01:24:05.240 --> 01:24:07.360]   Let's say, hey, Nikita's put on a show and they put it on
[01:24:07.360 --> 01:24:08.440]   on Facebook.
[01:24:08.440 --> 01:24:09.480]   So I found that fascinating.
[01:24:09.480 --> 01:24:11.520]   Interesting.
[01:24:11.520 --> 01:24:13.920]   Interesting.
[01:24:13.920 --> 01:24:17.360]   Do you need some more stall time, Matthew?
[01:24:17.360 --> 01:24:20.320]   Actually, the only thing I could think of dimension was that
[01:24:20.320 --> 01:24:21.280]   motherboard piece.
[01:24:21.280 --> 01:24:23.120]   That was the one thing I wanted to talk about.
[01:24:23.120 --> 01:24:24.120]   We already talked about it.
[01:24:24.120 --> 01:24:25.240]   It's fine.
[01:24:25.240 --> 01:24:27.560]   I encourage everybody to read it.
[01:24:27.560 --> 01:24:31.440]   I guess my tip isn't something you can get yet, but
[01:24:31.440 --> 01:24:32.360]   there is good news.
[01:24:32.360 --> 01:24:35.120]   They have announced that Super Mario Run, which is the
[01:24:35.120 --> 01:24:39.320]   massive hit on iOS, will be available for Android.
[01:24:39.320 --> 01:24:45.360]   So you can go to the Play Store, search for Super Mario Run, and
[01:24:45.360 --> 01:24:48.360]   give them an email address to be notified.
[01:24:48.360 --> 01:24:50.960]   But it's my guess that they're getting kind of close because
[01:24:50.960 --> 01:24:52.120]   they haven't asked it.
[01:24:52.120 --> 01:24:57.880]   Super Mario Run is a really kind of cool game for phones
[01:24:57.880 --> 01:24:59.400]   because you could play it with one hand.
[01:24:59.400 --> 01:25:02.720]   It doesn't require all of the motion and movement.
[01:25:02.720 --> 01:25:05.680]   The traditional Mario games require.
[01:25:05.680 --> 01:25:07.320]   But it's quite engaging.
[01:25:07.320 --> 01:25:12.000]   I presume they will do the same thing with this as they do
[01:25:12.000 --> 01:25:16.640]   with the Apple version, which is give you three free levels and
[01:25:16.640 --> 01:25:19.760]   then ding you for $10.
[01:25:19.760 --> 01:25:20.760]   Right.
[01:25:20.760 --> 01:25:21.760]   Right.
[01:25:21.760 --> 01:25:22.760]   $10.
[01:25:22.760 --> 01:25:24.240]   There is a lot of criticism about that.
[01:25:24.240 --> 01:25:25.800]   People who are initially excited.
[01:25:25.800 --> 01:25:29.000]   Well, you know, it's worth-- I got to say it's worth $10.
[01:25:29.000 --> 01:25:30.720]   You can see the game on my screen if you want to show a
[01:25:30.720 --> 01:25:31.720]   car.
[01:25:31.720 --> 01:25:32.720]   It's worth $10.
[01:25:32.720 --> 01:25:33.720]   It's really a lot of fun.
[01:25:33.720 --> 01:25:35.800]   Oh, I got a Moto 360.
[01:25:35.800 --> 01:25:37.000]   That's what I was going to mention.
[01:25:37.000 --> 01:25:38.520]   A Moto 360?
[01:25:38.520 --> 01:25:39.520]   Yeah.
[01:25:39.520 --> 01:25:42.720]   So I'm joined the smartwatch small group of people.
[01:25:42.720 --> 01:25:43.720]   You took your time.
[01:25:43.720 --> 01:25:45.560]   And now I think the smartwatch is dead now.
[01:25:45.560 --> 01:25:46.560]   In fact, Motorola has announced.
[01:25:46.560 --> 01:25:47.560]   Yeah, it probably is.
[01:25:47.560 --> 01:25:49.480]   It's not doing any more.
[01:25:49.480 --> 01:25:55.440]   So I picked exactly the right moment, just as the bandwagon was
[01:25:55.440 --> 01:25:57.440]   losing its wheels and heading for the cliff.
[01:25:57.440 --> 01:25:58.440]   Yeah.
[01:25:58.440 --> 01:26:02.720]   There is news that there will be an Android Wear 2 coming from
[01:26:02.720 --> 01:26:06.960]   Google, an update to their Android Wear soon.
[01:26:06.960 --> 01:26:12.080]   I have to say a bunch of things I like about it.
[01:26:12.080 --> 01:26:15.640]   But I haven't-- the notification thing, I'm trying to get it to
[01:26:15.640 --> 01:26:17.640]   the point where it's useful, but not annoying.
[01:26:17.640 --> 01:26:19.880]   Yeah, it's a really hard line.
[01:26:19.880 --> 01:26:20.880]   Yeah.
[01:26:20.880 --> 01:26:23.440]   Mine finally broke and I haven't-- I don't even wear a watch
[01:26:23.440 --> 01:26:24.840]   now, which is driving me nuts.
[01:26:24.840 --> 01:26:25.840]   Yeah.
[01:26:25.840 --> 01:26:27.800]   I asked somebody-- it was like Christmas Day.
[01:26:27.800 --> 01:26:32.080]   I said, if you have any tips and someone said, wait, I'll have
[01:26:32.080 --> 01:26:35.480]   to get it out of the drawer where I put it like a year ago.
[01:26:35.480 --> 01:26:38.080]   And I haven't thought about it since.
[01:26:38.080 --> 01:26:40.280]   Am I guessing this was a gift Matthew?
[01:26:40.280 --> 01:26:40.280]   Yeah.
[01:26:40.280 --> 01:26:42.120]   It was hard to buy for.
[01:26:42.120 --> 01:26:42.680]   Yeah.
[01:26:42.680 --> 01:26:43.840]   So I don't know.
[01:26:43.840 --> 01:26:45.600]   I'm having fun with it.
[01:26:45.600 --> 01:26:47.720]   I love my Moto 360.
[01:26:47.720 --> 01:26:49.360]   I have a metal bracelet.
[01:26:49.360 --> 01:26:51.360]   It's a very handsome watch.
[01:26:51.360 --> 01:26:54.400]   Yeah, it does a lot of things that are super useful.
[01:26:54.400 --> 01:26:57.040]   But it also does a lot of things that are kind of annoying.
[01:26:57.040 --> 01:26:59.400]   So I'm trying to find a happy medium
[01:26:59.400 --> 01:27:00.560]   between those two things.
[01:27:00.560 --> 01:27:03.960]   Well, relevant to that, the first Android Wear 2.0 watches
[01:27:03.960 --> 01:27:09.640]   were announced at CES this week, including one from Casio.
[01:27:09.640 --> 01:27:11.480]   So somebody is going to continue to make these.
[01:27:11.480 --> 01:27:14.440]   This is the WSDF20.
[01:27:14.440 --> 01:27:16.680]   Follow up to their F10.
[01:27:16.680 --> 01:27:17.600]   That's really ugly.
[01:27:17.600 --> 01:27:20.120]   And I'm not sure what's new in the Android Wear 2.0.
[01:27:20.120 --> 01:27:22.040]   It's been out, I think, in beta for a while.
[01:27:22.040 --> 01:27:24.400]   So I'm sure some people do.
[01:27:24.400 --> 01:27:28.840]   But this is apparently one of the first watches that we'll ship.
[01:27:28.840 --> 01:27:29.320]   It is.
[01:27:29.320 --> 01:27:30.560]   You know, it's ugly.
[01:27:30.560 --> 01:27:33.480]   It's for the sporty set.
[01:27:33.480 --> 01:27:34.800]   Yeah.
[01:27:34.800 --> 01:27:38.480]   You know the thing that I used that made the biggest impression
[01:27:38.480 --> 01:27:41.280]   was we were taking pictures at Christmas, you know,
[01:27:41.280 --> 01:27:42.640]   family photos and stuff.
[01:27:42.640 --> 01:27:44.400]   And you can stay away from the camera.
[01:27:44.400 --> 01:27:47.080]   Yeah, set the phone up and took the picture with the watch.
[01:27:47.080 --> 01:27:48.080]   Yeah.
[01:27:48.080 --> 01:27:50.000]   Mm-hmm.
[01:27:50.000 --> 01:27:52.000]   So, quickly a question.
[01:27:52.000 --> 01:27:54.600]   Some people are announcing phones at CES.
[01:27:54.600 --> 01:27:54.800]   Yes.
[01:27:54.800 --> 01:27:56.920]   Why are they doing that versus mobile world,
[01:27:56.920 --> 01:27:58.440]   just because it's a standout?
[01:27:58.440 --> 01:27:59.360]   I must be timing.
[01:27:59.360 --> 01:28:02.280]   You know, it's also true that most of the time
[01:28:02.280 --> 01:28:04.200]   PCs are not announced at CES.
[01:28:04.200 --> 01:28:06.840]   They're announced later in the year.
[01:28:06.840 --> 01:28:08.960]   What is the name of the Taiwan computer show,
[01:28:08.960 --> 01:28:13.160]   this big computer show in Taiwan in the summer, I think?
[01:28:13.160 --> 01:28:14.840]   But there are, nevertheless, been a lot of PCs
[01:28:14.840 --> 01:28:15.680]   announced this week.
[01:28:15.680 --> 01:28:17.080]   So I don't know.
[01:28:17.080 --> 01:28:20.680]   It might be a renaissance of CES, which
[01:28:20.680 --> 01:28:23.240]   has gone through some bad times, you know, for a while it was
[01:28:23.240 --> 01:28:23.720]   an iPhone.
[01:28:23.720 --> 01:28:25.680]   Yeah, I know people are going to it more.
[01:28:25.680 --> 01:28:27.120]   It's cooler now.
[01:28:27.120 --> 01:28:28.880]   It's cooler now.
[01:28:28.880 --> 01:28:32.400]   And there are a lot of new technologies most unproven,
[01:28:32.400 --> 01:28:35.840]   but there are a lot of new technologies like, you know,
[01:28:35.840 --> 01:28:40.040]   smart watches and VR and VR and smart automation.
[01:28:40.040 --> 01:28:41.160]   Yeah, home automation.
[01:28:41.160 --> 01:28:41.920]   Yeah.
[01:28:41.920 --> 01:28:43.680]   Are you going personally?
[01:28:43.680 --> 01:28:45.120]   No, we sent Father Robert down there.
[01:28:45.120 --> 01:28:46.360]   He's going to be giving us our coverage.
[01:28:46.360 --> 01:28:48.560]   He's actually down there right now with Brian Burnett.
[01:28:48.560 --> 01:28:52.520]   They're going to do some specials for us.
[01:28:52.520 --> 01:28:54.240]   I feel like it's such a zoo.
[01:28:54.240 --> 01:28:56.960]   I can get all the information from press releases
[01:28:56.960 --> 01:28:59.040]   and other people covering it.
[01:28:59.040 --> 01:29:03.280]   So yeah, I'm going to it's a little more manageable that way.
[01:29:03.280 --> 01:29:04.840]   Does Father Robert like it?
[01:29:04.840 --> 01:29:05.760]   Yeah, I'm sure he does.
[01:29:05.760 --> 01:29:06.320]   I like it.
[01:29:06.320 --> 01:29:07.040]   It's fun to go.
[01:29:07.040 --> 01:29:08.000]   It's quite it.
[01:29:08.000 --> 01:29:09.480]   It's a scene.
[01:29:09.480 --> 01:29:09.640]   Yeah.
[01:29:09.640 --> 01:29:11.840]   So like any scene, it's fascinating.
[01:29:11.840 --> 01:29:15.960]   But if you've been more than 20 times, yeah.
[01:29:15.960 --> 01:29:17.600]   It's a little like.
[01:29:17.600 --> 01:29:20.960]   I've seen this scene, although I have to say this is what this looks
[01:29:20.960 --> 01:29:22.640]   like one of the most in Computex.
[01:29:22.640 --> 01:29:22.960]   Thank you.
[01:29:22.960 --> 01:29:24.120]   That's the time on show.
[01:29:24.120 --> 01:29:27.040]   This is one of the most interesting the CES is in a while.
[01:29:27.040 --> 01:29:29.800]   And I think partly because of all these interesting technologies
[01:29:29.800 --> 01:29:30.200]   that are.
[01:29:30.200 --> 01:29:36.000]   Wasn't a CES way back in the day that had a video part of it
[01:29:36.000 --> 01:29:39.600]   and included like there was a porn video part of it?
[01:29:39.600 --> 01:29:41.640]   Yeah, that was Comdex.
[01:29:41.640 --> 01:29:44.320]   It was just a CES has been around for a long time.
[01:29:44.320 --> 01:29:48.080]   But Vegas also had Comdex, which was a computer show.
[01:29:48.080 --> 01:29:50.240]   And Comdex had a--
[01:29:50.240 --> 01:29:53.120]   just like the old VHS video stores where you'd go,
[01:29:53.120 --> 01:29:54.560]   there'd be a curtain in the back room
[01:29:54.560 --> 01:29:56.200]   and they had the adult tapes back there.
[01:29:56.200 --> 01:29:58.760]   They had a special section for adults.
[01:29:58.760 --> 01:30:01.480]   Finally, they said this is not working for us.
[01:30:01.480 --> 01:30:06.080]   They separated out to something called adult decks,
[01:30:06.080 --> 01:30:07.960]   which used to be concurrent with Comdex.
[01:30:07.960 --> 01:30:10.000]   And then for a while was concurrent with CES.
[01:30:10.000 --> 01:30:13.360]   But I think that even CES wanted more distance,
[01:30:13.360 --> 01:30:14.680]   even more distance.
[01:30:14.680 --> 01:30:17.320]   And so I think it's moved.
[01:30:17.320 --> 01:30:18.880]   If it's still even around, I don't know.
[01:30:18.880 --> 01:30:19.640]   I think it still exists.
[01:30:19.640 --> 01:30:20.800]   I remember it was just in around.
[01:30:20.800 --> 01:30:22.000]   It was funny to see.
[01:30:22.000 --> 01:30:26.080]   I came by once and the autograph line.
[01:30:26.080 --> 01:30:26.560]   Oh, yeah.
[01:30:26.560 --> 01:30:26.880]   It's hilarious.
[01:30:26.880 --> 01:30:28.320]   That's what it's all about.
[01:30:28.320 --> 01:30:29.880]   Yeah.
[01:30:29.880 --> 01:30:36.240]   We went to cover CES for tech TV many moons ago.
[01:30:36.240 --> 01:30:40.400]   And foolishly my producer said, hey, we got a camera crew.
[01:30:40.400 --> 01:30:44.320]   Let's go across the street to adult decks.
[01:30:44.320 --> 01:30:48.120]   And I should have just said no.
[01:30:48.120 --> 01:30:49.280]   There's tapes somewhere.
[01:30:49.280 --> 01:30:50.160]   Cameras are rolling.
[01:30:50.160 --> 01:30:53.680]   And I walk in the door and this woman--
[01:30:53.680 --> 01:30:54.600]   Leo!
[01:30:54.600 --> 01:31:00.640]   And she's apparently a cam girl who
[01:31:00.640 --> 01:31:02.080]   is a huge fan of tech TV.
[01:31:02.080 --> 01:31:05.520]   Because actually, if you think about it in the early days,
[01:31:05.520 --> 01:31:07.440]   people were using the answer.
[01:31:07.440 --> 01:31:10.000]   Or porn were tech TV fans.
[01:31:10.000 --> 01:31:12.760]   So she tries to get me to sit in her lap.
[01:31:12.760 --> 01:31:17.720]   And I feel like Anderson Cooper with Kathy Griffin,
[01:31:17.720 --> 01:31:19.760]   I'm just very uncomfortable.
[01:31:19.760 --> 01:31:22.080]   Because I know there's cameras rolling.
[01:31:22.080 --> 01:31:25.360]   And I just probably not a good idea for me to still know what to do.
[01:31:25.360 --> 01:31:28.280]   So I'm just like, where do you put your hands?
[01:31:28.280 --> 01:31:29.760]   Yeah.
[01:31:29.760 --> 01:31:31.600]   Hi.
[01:31:31.600 --> 01:31:32.080]   Hi.
[01:31:32.080 --> 01:31:34.000]   How are you?
[01:31:34.000 --> 01:31:35.840]   So that was--
[01:31:35.840 --> 01:31:38.840]   [LAUGHTER]
[01:31:38.840 --> 01:31:42.280]   [LAUGHTER]
[01:31:42.280 --> 01:31:44.920]   I think my friends on that note--
[01:31:44.920 --> 01:31:45.440]   Yeah.
[01:31:45.440 --> 01:31:48.000]   --all believe this to me to bring it down into the gutter.
[01:31:48.000 --> 01:31:49.680]   Just go home.
[01:31:49.680 --> 01:31:55.960]   Thank you, ladies and gentlemen, for joining us.
[01:31:55.960 --> 01:31:57.160]   We do this week in Google.
[01:31:57.160 --> 01:31:58.640]   And I know sometimes it's a little--
[01:31:58.640 --> 01:31:59.880]   sounds like it's about politics.
[01:31:59.880 --> 01:32:03.280]   But it's really about the nexus of technology and life,
[01:32:03.280 --> 01:32:06.520]   which these days is a lot about politics and journalism.
[01:32:06.520 --> 01:32:11.040]   And I think it's meat that we should cover these subjects,
[01:32:11.040 --> 01:32:13.480]   especially since you have such great people as Jeff Jarvis,
[01:32:13.480 --> 01:32:16.920]   Professor of Journalism, at CUNY, the City University of New
[01:32:16.920 --> 01:32:20.600]   York, Blogger Buzz Machine, prolific author,
[01:32:20.600 --> 01:32:24.240]   and Deep Thinker, more importantly.
[01:32:24.240 --> 01:32:26.000]   Right?
[01:32:26.000 --> 01:32:28.480]   Another Deep Thinker from Fortune Magazine.
[01:32:28.480 --> 01:32:32.440]   It is-- well, Fortune.com as well.
[01:32:32.440 --> 01:32:35.440]   We downplay the magazine part these days.
[01:32:35.440 --> 01:32:40.640]   Matthew Ingram, you follow him on Twitter @mathewi.
[01:32:40.640 --> 01:32:42.080]   Always a pleasure, Matthew.
[01:32:42.080 --> 01:32:42.720]   Thanks for joining us.
[01:32:42.720 --> 01:32:43.600]   Thanks for having me.
[01:32:43.600 --> 01:32:44.760]   Oh, yeah, we love it.
[01:32:44.760 --> 01:32:45.800]   Stacey, you'll be back next week.
[01:32:45.800 --> 01:32:46.400]   Good to see you.
[01:32:46.400 --> 01:32:48.440]   Laden with IoT gadgets.
[01:32:48.440 --> 01:32:49.920]   And I, sadly, will not be.
[01:32:49.920 --> 01:32:51.400]   Oh, man.
[01:32:51.400 --> 01:32:53.600]   It's hard to get the whole gang together these days.
[01:32:53.600 --> 01:32:53.880]   It is.
[01:32:53.880 --> 01:32:54.640]   It's horrible.
[01:32:54.640 --> 01:32:55.120]   Yeah.
[01:32:55.120 --> 01:33:00.640]   Where are you going?
[01:33:00.640 --> 01:33:04.600]   Frankfurt and the flight back is landing too late.
[01:33:04.600 --> 01:33:05.360]   No problem?
[01:33:05.360 --> 01:33:06.360]   No.
[01:33:06.360 --> 01:33:09.200]   So the way it is, we'll get somebody in your stead.
[01:33:09.200 --> 01:33:10.200]   And then I'll do the next week.
[01:33:10.200 --> 01:33:11.320]   I'll do Davos.
[01:33:11.320 --> 01:33:12.840]   Ah, I always enjoy your Davos.
[01:33:12.840 --> 01:33:15.120]   Some of these shows.
[01:33:15.120 --> 01:33:15.800]   It's always fun.
[01:33:15.800 --> 01:33:19.240]   You are back to your old traveling ways.
[01:33:19.240 --> 01:33:20.440]   For a month, for this month.
[01:33:20.440 --> 01:33:21.560]   OK.
[01:33:21.560 --> 01:33:22.560]   Now, that kind of dries up.
[01:33:22.560 --> 01:33:23.400]   So I'll be around.
[01:33:23.400 --> 01:33:24.560]   Then you're stuck with me.
[01:33:24.560 --> 01:33:25.680]   Ah, as I love it.
[01:33:25.680 --> 01:33:27.080]   You could do it from the plane.
[01:33:27.080 --> 01:33:30.760]   In-flight Wi-Fi is so reliable.
[01:33:30.760 --> 01:33:33.040]   We flew United back east.
[01:33:33.040 --> 01:33:36.240]   And I paid 20 bucks for the in-flight Wi-Fi.
[01:33:36.240 --> 01:33:37.840]   And it failed halfway through.
[01:33:37.840 --> 01:33:39.000]   That's that.
[01:33:39.000 --> 01:33:40.800]   No refund.
[01:33:40.800 --> 01:33:41.600]   Nope.
[01:33:41.600 --> 01:33:43.600]   Nope.
[01:33:43.600 --> 01:33:47.320]   But really, as Louis CK has want to point out,
[01:33:47.320 --> 01:33:48.800]   we really shouldn't be complaining
[01:33:48.800 --> 01:33:51.320]   about the fact that we are connected to the internet
[01:33:51.320 --> 01:33:53.440]   on a piece of metal herling to the sky.
[01:33:53.440 --> 01:33:56.000]   Six miles high at 600 miles an hour.
[01:33:56.000 --> 01:33:56.440]   True.
[01:33:56.440 --> 01:34:00.040]   That is perhaps the height of--
[01:34:00.040 --> 01:34:03.240]   The first world.
[01:34:03.240 --> 01:34:04.520]   Thank you, everybody, for joining us.
[01:34:04.520 --> 01:34:06.560]   We do Twig every Wednesday afternoon,
[01:34:06.560 --> 01:34:09.720]   130 p.m. Pacific 430 Eastern, 2130 UTC.
[01:34:09.720 --> 01:34:12.520]   Join us live in the chatroom at irc.twit.tv.
[01:34:12.520 --> 01:34:14.440]   Watch the live stream on twit.tv.
[01:34:14.440 --> 01:34:18.760]   We are now live on YouTube, by the way, youtube.com/twit.
[01:34:18.760 --> 01:34:20.880]   That's a great place to go for all of our shows.
[01:34:20.880 --> 01:34:23.000]   You can watch the live stream at any time.
[01:34:23.000 --> 01:34:27.200]   And then there's links on the right there to our live--
[01:34:27.200 --> 01:34:30.640]   I'm sorry, on demand-- shows which are all on YouTube,
[01:34:30.640 --> 01:34:35.240]   as well as available for download at our website, twit.tv.
[01:34:35.240 --> 01:34:39.320]   And of course, any podcast app that you should choose,
[01:34:39.320 --> 01:34:43.840]   you can also subscribe and get every episode.
[01:34:43.840 --> 01:34:46.680]   Very pleased, though, to be able to stream now
[01:34:46.680 --> 01:34:47.840]   on YouTube Live.
[01:34:47.840 --> 01:34:52.640]   So I hope you take advantage of that.
[01:34:52.640 --> 01:34:56.000]   If you have an Apple TV, there's five or six apps available
[01:34:56.000 --> 01:34:57.920]   there, Roku.
[01:34:57.920 --> 01:34:58.840]   Lots of ways to watch.
[01:34:58.840 --> 01:34:59.640]   Thanks for joining us.
[01:34:59.640 --> 01:35:02.080]   We'll see you next time on This Week in Google.
[01:35:02.080 --> 01:35:05.440]   [MUSIC PLAYING]
[01:35:05.440 --> 01:35:08.800]   [MUSIC PLAYING]
[01:35:08.800 --> 01:35:11.380]   (upbeat music)
[01:35:11.380 --> 01:35:12.380]   [bell tolling]

