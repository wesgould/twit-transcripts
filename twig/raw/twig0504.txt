;FFMETADATA1
title=Gelato in Perugia With Craig
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=504
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:01.200]   It's time for Twig!
[00:00:01.200 --> 00:00:05.800]   This week in Google Jeff Jarvis and Matthew Ingram are here, lots to talk about.
[00:00:05.800 --> 00:00:09.680]   Holy cow, Julian Assange's arrest can you defend him?
[00:00:09.680 --> 00:00:11.920]   As a journalist? Is it free speech?
[00:00:11.920 --> 00:00:15.760]   The bad news for Facebook just keeps on coming.
[00:00:15.760 --> 00:00:20.280]   And how Assassin's Creed is going to help rebuild Notre Dame.
[00:00:20.280 --> 00:00:22.560]   It's all coming up next on Twig.
[00:00:22.560 --> 00:00:26.960]   Netcast you love.
[00:00:26.960 --> 00:00:28.960]   From people you trust.
[00:00:28.960 --> 00:00:33.960]   This is Twig.
[00:00:33.960 --> 00:00:45.960]   This is Twig. This week in Google, episode 504, recorded Wednesday, April 17th, 2019.
[00:00:45.960 --> 00:00:48.960]   Gelato in PeruÅ¾ia with Greg.
[00:00:48.960 --> 00:00:51.960]   This week in Google is brought to you by Grammarly.
[00:00:51.960 --> 00:00:55.960]   Grammarly is a communication tool that helps people improve their writing
[00:00:55.960 --> 00:00:58.960]   to be mistake-free, clear, and effective.
[00:00:58.960 --> 00:01:06.960]   Start writing confidently by going to grammarly.com/twig and get 20% off a Grammarly Premium account today.
[00:01:06.960 --> 00:01:12.960]   And by WordPress. Turn your dreams into reality and launch your website at WordPress.com.
[00:01:12.960 --> 00:01:18.960]   Get 15% off any new plan at WordPress.com/twig.
[00:01:18.960 --> 00:01:22.960]   It's time for Twig! This week in Google to show where you cover the latest from the Googleverse.
[00:01:22.960 --> 00:01:26.960]   And boy, this is going to be the week that was joining us.
[00:01:26.960 --> 00:01:30.960]   Of course, Jeff Jarvis, welcome. Were you here last week?
[00:01:30.960 --> 00:01:32.960]   Yes, I was. You were, but I was.
[00:01:32.960 --> 00:01:33.960]   Yeah, you and Stacy were.
[00:01:33.960 --> 00:01:34.960]   Oh, good.
[00:01:34.960 --> 00:01:36.960]   Thanks to Jason Howell for filling in.
[00:01:36.960 --> 00:01:38.960]   And then I missed you before that because I was traveling.
[00:01:38.960 --> 00:01:39.960]   So it's worth saying.
[00:01:39.960 --> 00:01:40.960]   You've been back together.
[00:01:40.960 --> 00:01:41.960]   Nice to see you.
[00:01:41.960 --> 00:01:42.960]   Nice to see you.
[00:01:42.960 --> 00:01:43.960]   Hugs.
[00:01:43.960 --> 00:01:46.960]   He's supposed to do this, Jeff.
[00:01:46.960 --> 00:01:48.960]   Heart.
[00:01:48.960 --> 00:01:54.960]   He's the Leonard Tap Professor for journalistic innovation at the Craig Newmark Graduate School of Journalism at the City University of New York.
[00:01:54.960 --> 00:02:01.960]   Buzzmachine.com is his blog. His books are available everywhere, including public parts, what would Google do.
[00:02:01.960 --> 00:02:04.960]   And Gutenberg the geek.
[00:02:04.960 --> 00:02:06.960]   Very nice to see you.
[00:02:06.960 --> 00:02:07.960]   Nice to see you.
[00:02:07.960 --> 00:02:11.960]   Now Stacy is gone again. Where'd she go this time?
[00:02:11.960 --> 00:02:14.960]   She, she, uh, had, she is out with a migraine.
[00:02:14.960 --> 00:02:15.960]   Oh, poor Stacy.
[00:02:15.960 --> 00:02:16.960]   Oh.
[00:02:16.960 --> 00:02:18.960]   So she was, I thought she was playing.
[00:02:18.960 --> 00:02:19.960]   She was planning to be here.
[00:02:19.960 --> 00:02:20.960]   We can go to the moon.
[00:02:20.960 --> 00:02:21.960]   We can't cure a migraine.
[00:02:21.960 --> 00:02:22.960]   Isn't that ridiculous?
[00:02:22.960 --> 00:02:23.960]   Yeah.
[00:02:23.960 --> 00:02:34.960]   But the good offices of Matthew Ingram are always welcome on the show, Chief Digital Writer at CJR.org and a guy who had gelato with Craig Newmark and Perugia.
[00:02:34.960 --> 00:02:35.960]   I did.
[00:02:35.960 --> 00:02:37.960]   He was bragging about that just moments ago.
[00:02:37.960 --> 00:02:38.960]   He wasn't.
[00:02:38.960 --> 00:02:41.960]   We were talking about Craig Newmark because it was a brag.
[00:02:41.960 --> 00:02:42.960]   It was a humble brag.
[00:02:42.960 --> 00:02:43.960]   Maybe a little bit.
[00:02:43.960 --> 00:02:44.960]   A humble brag.
[00:02:44.960 --> 00:02:45.960]   Right.
[00:02:45.960 --> 00:02:46.960]   How was Perugia this year?
[00:02:46.960 --> 00:02:47.960]   Did you, you don't go to Georgia?
[00:02:47.960 --> 00:02:49.960]   No, I, no, I, no, you were there too.
[00:02:49.960 --> 00:02:50.960]   You were there too.
[00:02:50.960 --> 00:02:51.960]   Oh, yeah.
[00:02:51.960 --> 00:02:52.960]   Yeah.
[00:02:52.960 --> 00:02:53.960]   Yeah.
[00:02:53.960 --> 00:02:54.960]   The weather wasn't that great.
[00:02:54.960 --> 00:02:58.960]   It's a journalism conference in one of the most beautiful towns in Italy, a beautiful medieval town.
[00:02:58.960 --> 00:02:59.960]   Great food.
[00:02:59.960 --> 00:03:02.960]   It's a wonderful conference and great discussions.
[00:03:02.960 --> 00:03:06.960]   I had, I had a debate about European regulation.
[00:03:06.960 --> 00:03:07.960]   Well.
[00:03:07.960 --> 00:03:11.960]   I had a session about the death of the story.
[00:03:11.960 --> 00:03:12.960]   Oh, interesting.
[00:03:12.960 --> 00:03:18.960]   I had a session about things that journalists know about the business of journalism.
[00:03:18.960 --> 00:03:19.960]   What about you, Matthew?
[00:03:19.960 --> 00:03:20.960]   What were yours?
[00:03:20.960 --> 00:03:26.960]   I did a one-on-one with Alan Rusperager, the former Guardian editor.
[00:03:26.960 --> 00:03:27.960]   And I did a.
[00:03:27.960 --> 00:03:28.960]   This new book.
[00:03:28.960 --> 00:03:29.960]   You should plug it.
[00:03:29.960 --> 00:03:31.960]   Breaking the news.
[00:03:31.960 --> 00:03:40.960]   And then I did a one-on-one with Martin Moore, who also has a book about the impact of technology
[00:03:40.960 --> 00:03:42.960]   and politics in society.
[00:03:42.960 --> 00:03:45.960]   And I had a couple of panels as well.
[00:03:45.960 --> 00:03:52.960]   I think the highlight for me was seeing Maria Ressa from Rappler, the usual.
[00:03:52.960 --> 00:03:53.960]   You know, Maria Ressa, Leo?
[00:03:53.960 --> 00:03:54.960]   News site.
[00:03:54.960 --> 00:03:57.960]   I don't, I don't even know Rappler, which is a French.
[00:03:57.960 --> 00:03:58.960]   It's French, Rappler.
[00:03:58.960 --> 00:04:00.960]   Rappler is, she's from Philippines.
[00:04:00.960 --> 00:04:01.960]   Oh, Philippines.
[00:04:01.960 --> 00:04:02.960]   Oh, Philippines.
[00:04:02.960 --> 00:04:05.960]   And very, the bravest journalist I know by far.
[00:04:05.960 --> 00:04:06.960]   Oh, yeah.
[00:04:06.960 --> 00:04:09.960]   She's been arrested now by Duterte eight times or nine times.
[00:04:09.960 --> 00:04:10.960]   Oh, my goodness.
[00:04:10.960 --> 00:04:14.960]   She was arrested again, who he came to Persia.
[00:04:14.960 --> 00:04:16.960]   Oh, that's, that's.
[00:04:16.960 --> 00:04:19.960]   And yet, and yet, soldiers on.
[00:04:19.960 --> 00:04:23.960]   Yeah, and she's relentlessly positive as well, which is amazing.
[00:04:23.960 --> 00:04:24.960]   Wow.
[00:04:24.960 --> 00:04:26.960]   For someone who's been through as much as she has.
[00:04:26.960 --> 00:04:31.960]   This is, you got her, you have to respect people of the press who continue to soldier
[00:04:31.960 --> 00:04:32.960]   on.
[00:04:32.960 --> 00:04:35.960]   And then there's, and then there's Julian Assange.
[00:04:35.960 --> 00:04:36.960]   Yeah.
[00:04:36.960 --> 00:04:38.960]   Were you in Persia when he got arrested?
[00:04:38.960 --> 00:04:40.960]   Because I would have loved her.
[00:04:40.960 --> 00:04:41.960]   Just after.
[00:04:41.960 --> 00:04:43.960]   Oh, man, the conversation there.
[00:04:43.960 --> 00:04:44.960]   Yeah.
[00:04:44.960 --> 00:04:49.960]   So Assange, of course, is the founder of WikiLeaks and was lionized, especially by the left
[00:04:49.960 --> 00:04:53.960]   early on, especially after collateral murder.
[00:04:53.960 --> 00:05:00.680]   That was the material leaked to WikiLeaks by Chelsea Manning, which showed footage of
[00:05:00.680 --> 00:05:06.920]   American drones killing journalists and other innocents and was a big revelation.
[00:05:06.920 --> 00:05:10.920]   Back in the Obama era, of course, Chelsea Manning went to jail.
[00:05:10.920 --> 00:05:14.680]   Obama later commuted her sentence.
[00:05:14.680 --> 00:05:19.960]   They've finally threw Julian out of the Ecuadorian embassy where he'd been hunkered down for,
[00:05:19.960 --> 00:05:20.960]   what is it, seven years?
[00:05:20.960 --> 00:05:21.960]   Seven years.
[00:05:21.960 --> 00:05:22.960]   Yeah.
[00:05:22.960 --> 00:05:23.960]   Initially he was.
[00:05:23.960 --> 00:05:24.960]   Seven years.
[00:05:24.960 --> 00:05:27.600]   He was fleeing a rape charge from Sweden.
[00:05:27.600 --> 00:05:33.800]   That charge eventually dropped, but he still dared not leave the Ecuadorian embassy in London.
[00:05:33.800 --> 00:05:36.280]   No, it hasn't actually technically been dropped.
[00:05:36.280 --> 00:05:37.280]   Oh, he's still there.
[00:05:37.280 --> 00:05:39.280]   They just gave up on a perse.
[00:05:39.280 --> 00:05:40.280]   They were going to perseal it.
[00:05:40.280 --> 00:05:41.280]   Yeah.
[00:05:41.280 --> 00:05:42.280]   Okay.
[00:05:42.280 --> 00:05:44.280]   And I have no comments about those charges.
[00:05:44.280 --> 00:05:48.960]   Assange himself said as soon as he started leaking stuff on WikiLeaks, it's just a matter
[00:05:48.960 --> 00:05:52.080]   of time before they come for me.
[00:05:52.080 --> 00:05:56.760]   He stayed in the Ecuadorian embassy, eventually wearing out his welcome.
[00:05:56.760 --> 00:06:01.120]   The Ecuadorians accused him of new government in Ecuador too had an impact.
[00:06:01.120 --> 00:06:02.120]   Yeah.
[00:06:02.120 --> 00:06:07.520]   However, the Ecuadorian government has been strong armed by the US government over aid
[00:06:07.520 --> 00:06:09.160]   for doing things the US didn't like.
[00:06:09.160 --> 00:06:11.720]   And I have to think this might have, there might have been some pressure on that along
[00:06:11.720 --> 00:06:17.240]   those lines as well because I would imagine as soon as he was thrust out of the embassy
[00:06:17.240 --> 00:06:24.160]   with his cat, the Metropolitan Police in London picked him up at the request of US authorities
[00:06:24.160 --> 00:06:27.040]   and they are now attempting to extradite him to the US.
[00:06:27.040 --> 00:06:35.480]   But the US is not charging him with the Espionage Act famously Obama, the Obama administration
[00:06:35.480 --> 00:06:38.960]   decided that that would be frankly too risky.
[00:06:38.960 --> 00:06:44.880]   They were afraid of using that big gun against Julian Assange and decided not to prosecute
[00:06:44.880 --> 00:06:50.560]   or attempt to prosecute him on those on grounds of espionage because they were afraid that
[00:06:50.560 --> 00:06:55.360]   that could then be used down the road against other journalists.
[00:06:55.360 --> 00:07:01.960]   So, but the Trump administration and the Department of Justice is going after him for hacking because
[00:07:01.960 --> 00:07:08.200]   there's an email that Assange sent to Chelsea Manning saying, right, it was Chelsea Manning
[00:07:08.200 --> 00:07:09.200]   saying, can you-
[00:07:09.200 --> 00:07:10.200]   It was a chat log.
[00:07:10.200 --> 00:07:11.200]   Chat log, not email.
[00:07:11.200 --> 00:07:12.200]   They're chatting about it.
[00:07:12.200 --> 00:07:13.200]   And Chelsea-
[00:07:13.200 --> 00:07:14.920]   I'll get my guys on this to help you.
[00:07:14.920 --> 00:07:15.920]   Right.
[00:07:15.920 --> 00:07:23.240]   She's trying to match a hash for a password because she was trying to get into the files using
[00:07:23.240 --> 00:07:28.320]   the FTP account rather than using her own account when she thought had been overused.
[00:07:28.320 --> 00:07:29.320]   Yeah.
[00:07:29.320 --> 00:07:30.320]   To cover her tracks.
[00:07:30.320 --> 00:07:36.600]   So, I give you all, and you guys know this obviously better than I, but I give everybody
[00:07:36.600 --> 00:07:41.240]   this background information so we can now have this conversation because the US still
[00:07:41.240 --> 00:07:43.920]   is not prosecuting him for espionage.
[00:07:43.920 --> 00:07:45.320]   No, yeah.
[00:07:45.320 --> 00:07:49.160]   Which would raise a First Amendment issue because of course Daniel Ellsberg who leaked
[00:07:49.160 --> 00:07:55.600]   the Pentagon Papers and the Nixon administration very much wanted to prosecute him for espionage.
[00:07:55.600 --> 00:07:57.480]   They did break into a psychiatrist office.
[00:07:57.480 --> 00:07:58.880]   So I think they're going to.
[00:07:58.880 --> 00:07:59.880]   You think they will?
[00:07:59.880 --> 00:08:00.880]   Yeah.
[00:08:00.880 --> 00:08:03.720]   I think this is just the, the same edge of the wedge.
[00:08:03.720 --> 00:08:04.720]   That's my fear anyway.
[00:08:04.720 --> 00:08:05.720]   I think they're-
[00:08:05.720 --> 00:08:11.200]   Now, the extradition agreement apparently he has with the Brits is he can be extradited
[00:08:11.200 --> 00:08:14.160]   only on this specific charge of hacking.
[00:08:14.160 --> 00:08:16.120]   They're at no political charges.
[00:08:16.120 --> 00:08:18.760]   Well, they can't get him and then add charges.
[00:08:18.760 --> 00:08:21.320]   I'm not sure that's what it says.
[00:08:21.320 --> 00:08:27.360]   So it says he can only be extradited for that specific charge, but officials have already
[00:08:27.360 --> 00:08:30.160]   told CNN they're, they're planning more charges.
[00:08:30.160 --> 00:08:31.160]   Interesting.
[00:08:31.160 --> 00:08:32.160]   I mean, as soon as I hear him.
[00:08:32.160 --> 00:08:33.160]   Here's the interesting thing.
[00:08:33.160 --> 00:08:37.440]   Obviously they didn't charge him with interfering in the US election, the Russians.
[00:08:37.440 --> 00:08:42.800]   And obviously the current president has over the time loved, but he leaves for what it
[00:08:42.800 --> 00:08:43.800]   did.
[00:08:43.800 --> 00:08:44.800]   Yeah.
[00:08:44.800 --> 00:08:46.000]   In fact, said that the Russians didn't hack the election.
[00:08:46.000 --> 00:08:49.160]   So there'd be no way the DOJ is going to go after for that.
[00:08:49.160 --> 00:08:50.160]   Although he claimed to know that-
[00:08:50.160 --> 00:08:51.560]   But I wonder his last quote-
[00:08:51.560 --> 00:08:52.560]   I wonder at some point.
[00:08:52.560 --> 00:08:53.560]   Oh, yeah.
[00:08:53.560 --> 00:08:56.600]   And Trump says I know nothing about WikiLeaks, even though he invoked them.
[00:08:56.600 --> 00:08:57.600]   Praise them.
[00:08:57.600 --> 00:08:59.480]   Many dozens of times during the campaign.
[00:08:59.480 --> 00:09:06.200]   I wonder if it's a pro forma prosecution and then Trump pardons him.
[00:09:06.200 --> 00:09:07.520]   Why would they do that?
[00:09:07.520 --> 00:09:08.520]   Well, why would they even-
[00:09:08.520 --> 00:09:11.320]   He not they he.
[00:09:11.320 --> 00:09:12.320]   But they-
[00:09:12.320 --> 00:09:13.320]   It's helpful to-
[00:09:13.320 --> 00:09:14.320]   Work for he.
[00:09:14.320 --> 00:09:15.320]   Don't they?
[00:09:15.320 --> 00:09:18.640]   No, he has the individual pardon power.
[00:09:18.640 --> 00:09:19.640]   Yeah.
[00:09:19.640 --> 00:09:24.760]   I mean, I think the hacking charge or the cracking of password charge is a fig leaf or whatever
[00:09:24.760 --> 00:09:25.760]   you want to call it.
[00:09:25.760 --> 00:09:32.840]   I think it's a Trojan horse or I actually think that they are going to try to make a case.
[00:09:32.840 --> 00:09:37.080]   If you read the affidavit, which goes into a lot more detail than the indictment, they're
[00:09:37.080 --> 00:09:42.360]   talking like 80% of what they describe in there are things that journalists do with
[00:09:42.360 --> 00:09:43.440]   sources all the time.
[00:09:43.440 --> 00:09:46.040]   They're talking about them using a secure drop.
[00:09:46.040 --> 00:09:48.320]   They're talking about them using Jabber talking about-
[00:09:48.320 --> 00:09:49.760]   None of which is illegal.
[00:09:49.760 --> 00:09:50.760]   Right.
[00:09:50.760 --> 00:09:51.760]   None of which is illegal.
[00:09:51.760 --> 00:09:57.200]   But the affidavit says that all of this is part of a conspiracy on the part of the two
[00:09:57.200 --> 00:09:59.720]   of them to get access to classified documents.
[00:09:59.720 --> 00:10:03.400]   According to the latest, according to Motherboard, the government admitted it doesn't even know
[00:10:03.400 --> 00:10:05.200]   if the password was cracked.
[00:10:05.200 --> 00:10:10.280]   An FBI agent admitted in a newly unsealed court document that DOJ does not know whether
[00:10:10.280 --> 00:10:13.040]   Assange's offer to help Manning came to fruition.
[00:10:13.040 --> 00:10:15.760]   So it sounds like a fairly weak case.
[00:10:15.760 --> 00:10:20.080]   Some experts have said they don't think based on what is said in these logs that it would
[00:10:20.080 --> 00:10:21.800]   even be possible.
[00:10:21.800 --> 00:10:24.800]   And there's certainly no evidence that Assange even tried.
[00:10:24.800 --> 00:10:27.600]   I mean, he lied to Chelsea Manning routinely.
[00:10:27.600 --> 00:10:30.120]   He could have just said, "Oh, sure, I'll help you crack that password.
[00:10:30.120 --> 00:10:31.120]   No problem.
[00:10:31.120 --> 00:10:32.360]   I'll get my guys on it."
[00:10:32.360 --> 00:10:34.320]   So this is the issue.
[00:10:34.320 --> 00:10:39.560]   And certainly, while Assange was the darling of the left after collateral murder, he became
[00:10:39.560 --> 00:10:45.720]   less so when he was seen as a Russian operative effectively working for the Russian government
[00:10:45.720 --> 00:10:48.040]   during the 2016 election.
[00:10:48.040 --> 00:10:57.320]   Nevertheless, it does raise the specter of, you know, restraint of free speech.
[00:10:57.320 --> 00:11:02.400]   James Ball writing in the Atlantic says, "You don't have to like Julian Assange to defend
[00:11:02.400 --> 00:11:03.400]   him.
[00:11:03.400 --> 00:11:07.240]   The effort to extradite and prosecute the WikiLeaks founder threatens the free media."
[00:11:07.240 --> 00:11:08.240]   In fact, it's...
[00:11:08.240 --> 00:11:13.920]   In fact, if you look at other people who've been forced to defend Larry Flint, who is
[00:11:13.920 --> 00:11:15.480]   no hero, that's for sure.
[00:11:15.480 --> 00:11:19.320]   You know, you can't choose the people that you build these cases around.
[00:11:19.320 --> 00:11:20.920]   It doesn't mean it's not a threat.
[00:11:20.920 --> 00:11:21.920]   It's the old saying.
[00:11:21.920 --> 00:11:24.760]   The free speech means nothing if you're defending the speech you agree with.
[00:11:24.760 --> 00:11:25.760]   Right.
[00:11:25.760 --> 00:11:26.760]   If it's always people you like.
[00:11:26.760 --> 00:11:27.760]   Right.
[00:11:27.760 --> 00:11:28.760]   Assange...
[00:11:28.760 --> 00:11:29.760]   Right.
[00:11:29.760 --> 00:11:30.760]   Assange...
[00:11:30.760 --> 00:11:31.760]   Go ahead.
[00:11:31.760 --> 00:11:32.760]   Yeah, Russ Bridger wrote it as well.
[00:11:32.760 --> 00:11:33.760]   All right.
[00:11:33.760 --> 00:11:34.760]   But you go first, Leo.
[00:11:34.760 --> 00:11:35.760]   Sorry.
[00:11:35.760 --> 00:11:38.760]   I think that's an A-hole, scratch that.
[00:11:38.760 --> 00:11:39.760]   Assange is an A-hole.
[00:11:39.760 --> 00:11:40.760]   But we're going to have to stand up for him anyway.
[00:11:40.760 --> 00:11:41.760]   What did Russ Bridger write?
[00:11:41.760 --> 00:11:45.760]   James, I think scratch, by the way, is an unfortunate verb in that choice.
[00:11:45.760 --> 00:11:48.760]   Maybe not so accidental, but unfortunate.
[00:11:48.760 --> 00:11:49.760]   Probably not.
[00:11:49.760 --> 00:11:50.760]   No, he's James.
[00:11:50.760 --> 00:11:53.360]   James, by the way, has a book coming out about the Internet.
[00:11:53.360 --> 00:11:54.360]   Let's plug that.
[00:11:54.360 --> 00:11:56.600]   James is a wonderful journalist who worked for Assange.
[00:11:56.600 --> 00:11:57.600]   We can work for him.
[00:11:57.600 --> 00:11:58.600]   We can work for him.
[00:11:58.600 --> 00:11:59.600]   He works for Assange.
[00:11:59.600 --> 00:12:00.600]   So he knows his son.
[00:12:00.600 --> 00:12:01.600]   Yeah.
[00:12:01.600 --> 00:12:02.600]   He knows him.
[00:12:02.600 --> 00:12:03.600]   He knows him.
[00:12:03.600 --> 00:12:04.600]   He volunteered to take Assange as a cat.
[00:12:04.600 --> 00:12:05.600]   Well, the equity-
[00:12:05.600 --> 00:12:06.600]   So, which thing?
[00:12:06.600 --> 00:12:07.600]   Yeah.
[00:12:07.600 --> 00:12:13.880]   Says partnering with Assange was unpleasant, but his work is crucial.
[00:12:13.880 --> 00:12:17.360]   Many conservatives despise him for supposedly, apparently, national security.
[00:12:17.360 --> 00:12:22.720]   Liberals will never forgive him for what he did to Hillary Clinton.
[00:12:22.720 --> 00:12:26.280]   He's an information anarchist dumping vast oceans of material in a cyberspace with barely
[00:12:26.280 --> 00:12:27.920]   a thought for the consequences.
[00:12:27.920 --> 00:12:30.880]   He's often portrayed as a useful idiot to Putin.
[00:12:30.880 --> 00:12:34.400]   He jumped bail in Britain, costing his two trusted supporters a small fortune.
[00:12:34.400 --> 00:12:38.760]   He's rude, aggressive, pompous, self-regarding, unreasonable, and even, as multiple sources
[00:12:38.760 --> 00:12:39.760]   say, "smelly."
[00:12:39.760 --> 00:12:40.760]   Smelly.
[00:12:40.760 --> 00:12:45.840]   There is, in short, not to love about Julian Assange.
[00:12:45.840 --> 00:12:48.520]   But he goes on, of course, and says that it depends.
[00:12:48.520 --> 00:12:51.440]   The laws, particularly in free speech, should not depend on likeability, mental health,
[00:12:51.440 --> 00:12:54.840]   or personal hygiene of those in the firing line.
[00:12:54.840 --> 00:13:00.480]   Assange is now very much a target being threatened, the extradition to the US to face charges.
[00:13:00.480 --> 00:13:02.880]   I wonder, is there any chance, Matthew, have you heard?
[00:13:02.880 --> 00:13:05.920]   Is there any chance the extradition would not be granted?
[00:13:05.920 --> 00:13:07.280]   So I think there is a chance.
[00:13:07.280 --> 00:13:13.760]   I mean, the UK, in particular, if the US didn't take the death penalty off the table, if they
[00:13:13.760 --> 00:13:18.840]   didn't promise that there's no way that the death penalty would become an option.
[00:13:18.840 --> 00:13:22.440]   I don't think the UK would extradite if the death penalty was an option.
[00:13:22.440 --> 00:13:30.960]   So they might resist on that basis, or they might decide that it doesn't justify extradition.
[00:13:30.960 --> 00:13:32.920]   I mean, it's a pretty weak case.
[00:13:32.920 --> 00:13:38.240]   If you look at the indictment, there's no actual proof that Assange did anything except
[00:13:38.240 --> 00:13:41.600]   say something in a chat log.
[00:13:41.600 --> 00:13:49.920]   So it's funny because the Obama administration did not want to prosecute ultimately, and
[00:13:49.920 --> 00:13:55.320]   they wanted to, but they didn't, ultimately, because of exactly this issue.
[00:13:55.320 --> 00:13:56.320]   Is he a journalist?
[00:13:56.320 --> 00:13:57.320]   I think that's the fear.
[00:13:57.320 --> 00:14:03.360]   Fear is that this government, the Trump administration, has been attacking the press verbally and
[00:14:03.360 --> 00:14:07.520]   otherwise, and that this is going to be part of their argument.
[00:14:07.520 --> 00:14:12.520]   The irony of it is that the Trump administration likes Assange and we do it.
[00:14:12.520 --> 00:14:13.520]   That's what that's like.
[00:14:13.520 --> 00:14:14.520]   Right.
[00:14:14.520 --> 00:14:16.680]   When they were doing something, they wanted it.
[00:14:16.680 --> 00:14:17.680]   So it's.
[00:14:17.680 --> 00:14:18.680]   But they could use this.
[00:14:18.680 --> 00:14:22.560]   The last thing the president Trump wants to do is carry President Obama's water.
[00:14:22.560 --> 00:14:23.560]   Right.
[00:14:23.560 --> 00:14:31.280]   But if they want to go after leakers, which I think they do, then they're going to try
[00:14:31.280 --> 00:14:34.200]   to criminalize journalists source relationships.
[00:14:34.200 --> 00:14:35.520]   And this allows them to do that.
[00:14:35.520 --> 00:14:39.120]   And that's the fundamental risk of this.
[00:14:39.120 --> 00:14:40.120]   Right.
[00:14:40.120 --> 00:14:44.680]   Is that if you start, and this has been attacked, in fact, during the Obama administration,
[00:14:44.680 --> 00:14:46.520]   was attacked again and again.
[00:14:46.520 --> 00:14:49.600]   They threw people in jail for not revealing sources.
[00:14:49.600 --> 00:14:56.480]   The fundamental risk in this is if journalists can't use sources safely, sources will dry
[00:14:56.480 --> 00:15:02.240]   up and we won't know what's going on.
[00:15:02.240 --> 00:15:07.920]   And end result of this is the public will lose because there would no way to see through
[00:15:07.920 --> 00:15:09.920]   the veil of government.
[00:15:09.920 --> 00:15:11.400]   Yeah.
[00:15:11.400 --> 00:15:17.520]   Speaking of veils though, and trying to go through a number of them in this story, what
[00:15:17.520 --> 00:15:21.240]   do we imagine that we can lease has on Donald Trump?
[00:15:21.240 --> 00:15:23.040]   Well they might have the dossier.
[00:15:23.040 --> 00:15:27.440]   Well, they are well, the dot we all have the dossier might have the tape.
[00:15:27.440 --> 00:15:29.400]   We all have the tape because I'd like to see it.
[00:15:29.400 --> 00:15:30.960]   If there's a tape, no, we have the dossier.
[00:15:30.960 --> 00:15:31.960]   Oh, the tape.
[00:15:31.960 --> 00:15:32.960]   We need the tape.
[00:15:32.960 --> 00:15:33.960]   They might have the tape.
[00:15:33.960 --> 00:15:34.960]   Okay.
[00:15:34.960 --> 00:15:36.520]   They, you know, okay.
[00:15:36.520 --> 00:15:42.120]   So that now if the president believed that was the case, that would explain why even though
[00:15:42.120 --> 00:15:46.760]   Assange could have been a Russian cutout acting on his behalf during the election, he
[00:15:46.760 --> 00:15:49.920]   damn well doesn't want the guy out of the Ecuadorian embassy.
[00:15:49.920 --> 00:15:51.960]   He wants him somewhere.
[00:15:51.960 --> 00:15:54.800]   By the way, the Ecuadorian took away the deal.
[00:15:54.800 --> 00:16:02.720]   I wonder whether there's not a scenario where oddly he gets jailed and oddly he gets prosecuted.
[00:16:02.720 --> 00:16:06.560]   But there's a talking about, you know, trust, but willing to offer.
[00:16:06.560 --> 00:16:07.560]   He just did it.
[00:16:07.560 --> 00:16:09.720]   He just offered his own employees pardons.
[00:16:09.720 --> 00:16:10.720]   Yeah.
[00:16:10.720 --> 00:16:14.560]   Yeah, which by the way, I believe is illegal to.
[00:16:14.560 --> 00:16:15.560]   It's pretty illegal.
[00:16:15.560 --> 00:16:16.560]   Yeah.
[00:16:16.560 --> 00:16:20.640]   Because you're supporting a witness if you say, hey, just even the same thing and I will
[00:16:20.640 --> 00:16:23.240]   pardon you when the time comes.
[00:16:23.240 --> 00:16:26.240]   Even the fact that that happened and no one really said anything.
[00:16:26.240 --> 00:16:27.800]   And we all just moved on.
[00:16:27.800 --> 00:16:29.440]   It's my fault.
[00:16:29.440 --> 00:16:31.960]   The state of affairs is incredible.
[00:16:31.960 --> 00:16:32.960]   Incredible.
[00:16:32.960 --> 00:16:39.920]   So I just use the scenario in which Assange is prosecuted on the lease charge and there's
[00:16:39.920 --> 00:16:44.680]   already a deal in play, a quiet deal in place that go through this and then you'll double
[00:16:44.680 --> 00:16:48.440]   jeopardy all that will, I'll pardon you for everything you've done and we're done.
[00:16:48.440 --> 00:16:49.440]   Oh, why?
[00:16:49.440 --> 00:16:50.440]   Why bother?
[00:16:50.440 --> 00:16:53.440]   Because he might have things on Trump.
[00:16:53.440 --> 00:16:54.440]   I don't.
[00:16:54.440 --> 00:16:55.440]   Yeah.
[00:16:55.440 --> 00:17:00.600]   I mean, if anybody in the administration knows Assange at all, I'm sure that guy would turn
[00:17:00.600 --> 00:17:02.680]   on you in a second right after.
[00:17:02.680 --> 00:17:05.680]   Yeah, but we're not talking about.
[00:17:05.680 --> 00:17:09.960]   I know they're not genius over there, but but someone will have thought of that, presumably.
[00:17:09.960 --> 00:17:12.600]   Yeah, you don't want to get fed with Assange.
[00:17:12.600 --> 00:17:14.600]   But he kept who was the size.
[00:17:14.600 --> 00:17:20.760]   Yeah, the other guy was in notorious, you know, right.
[00:17:20.760 --> 00:17:24.160]   Again, though, we got to defend him because that's the problem.
[00:17:24.160 --> 00:17:25.160]   That's yeah.
[00:17:25.160 --> 00:17:26.160]   I mean, it's he's hard to defend.
[00:17:26.160 --> 00:17:29.280]   You're forced to defend them, even though you don't want to defend them.
[00:17:29.280 --> 00:17:30.280]   You have.
[00:17:30.280 --> 00:17:31.280]   So what about this question?
[00:17:31.280 --> 00:17:37.760]   What if he had been if a Democrat were in the White House and he were charged with interfering
[00:17:37.760 --> 00:17:40.440]   with the American election as a dupe on Putin?
[00:17:40.440 --> 00:17:42.000]   That's different.
[00:17:42.000 --> 00:17:44.200]   I mean, things that that is different, right?
[00:17:44.200 --> 00:17:45.200]   Yeah.
[00:17:45.200 --> 00:17:53.680]   But then you're not charging him with doing journalism, charging him with acting as a
[00:17:53.680 --> 00:17:54.680]   foreign agent.
[00:17:54.680 --> 00:17:55.680]   Yes.
[00:17:55.680 --> 00:17:56.760]   Or you I just released emails, man.
[00:17:56.760 --> 00:17:58.840]   I just got information out there.
[00:17:58.840 --> 00:17:59.920]   That's journalism, he would argue.
[00:17:59.920 --> 00:18:00.920]   Well, and it's the fundamental.
[00:18:00.920 --> 00:18:01.920]   I agree with you, Leo.
[00:18:01.920 --> 00:18:02.920]   So that's the argument.
[00:18:02.920 --> 00:18:07.920]   One of the things we talked about on Twitter on this issue was the stark contrast between
[00:18:07.920 --> 00:18:11.320]   what Edward Snowden did in WikiLeaks does.
[00:18:11.320 --> 00:18:17.840]   So Edward Snowden also had a vast trove of information from the NSA that was illegally
[00:18:17.840 --> 00:18:19.320]   exfiltrated.
[00:18:19.320 --> 00:18:21.400]   He knew that he was in jeopardy.
[00:18:21.400 --> 00:18:26.000]   He attempted to do a whistle blowing thing and was rejected by the agency.
[00:18:26.000 --> 00:18:27.640]   So he said, here's what I'm going to do.
[00:18:27.640 --> 00:18:29.080]   I'm going to take this information.
[00:18:29.080 --> 00:18:32.280]   I am going to get it to a number of newspapers.
[00:18:32.280 --> 00:18:37.160]   I'm going to flee the country because I know regardless of what happens, I will be prosecuted
[00:18:37.160 --> 00:18:38.160]   for this.
[00:18:38.160 --> 00:18:43.080]   Newspapers will be able to vet the material and release it with impunity.
[00:18:43.080 --> 00:18:51.320]   And that has a dual effect on that the newspapers with reduction.
[00:18:51.320 --> 00:18:53.280]   Release it with forethought.
[00:18:53.280 --> 00:18:54.280]   And that has a second.
[00:18:54.280 --> 00:18:55.280]   So there's two things.
[00:18:55.280 --> 00:18:57.840]   One, the newspapers aren't going to go to jail because they're newspapers.
[00:18:57.840 --> 00:19:01.480]   But two, only the stuff that's safe to release can be released.
[00:19:01.480 --> 00:19:02.480]   It won't.
[00:19:02.480 --> 00:19:07.200]   In fact, WikiLeaks has been accused with the diplomatic cables that are released of putting
[00:19:07.200 --> 00:19:09.920]   people in jeopardy, putting foreign agents in jeopardy.
[00:19:09.920 --> 00:19:14.000]   Yeah, although there's no evidence, even government sources have said there's no evidence that
[00:19:14.000 --> 00:19:16.520]   any of those cables put anybody in jeopardy.
[00:19:16.520 --> 00:19:22.840]   But nevertheless, Snowden avoided any even whiff of impropriety, the theory being that
[00:19:22.840 --> 00:19:27.120]   the Washington Post, the New York Times, the Guardian, these people are going to go through
[00:19:27.120 --> 00:19:31.600]   it and clean it up, redact it, as you say, and put out the stuff that the people need
[00:19:31.600 --> 00:19:32.600]   to know.
[00:19:32.600 --> 00:19:34.920]   But that's what fascinates me about this, about WikiLeaks.
[00:19:34.920 --> 00:19:36.400]   WikiLeaks is the opposite.
[00:19:36.400 --> 00:19:38.240]   There's no editing, no redaction.
[00:19:38.240 --> 00:19:39.240]   It's a dump.
[00:19:39.240 --> 00:19:40.240]   Literally it is.
[00:19:40.240 --> 00:19:43.360]   He was enraged that the papers were redacted at all.
[00:19:43.360 --> 00:19:45.400]   That's what they released me about.
[00:19:45.400 --> 00:19:52.440]   WikiLeaks in the beginning, before it's on sort of lost his mind.
[00:19:52.440 --> 00:19:58.200]   So as Snowden went through this sort of traditional media route, leak to the papers, and then
[00:19:58.200 --> 00:20:06.200]   they published, WikiLeaks was like this thing outside of all norms of conduct that was
[00:20:06.200 --> 00:20:09.360]   just publishing things and releasing them on the internet.
[00:20:09.360 --> 00:20:16.080]   And what that did was force people to confront sort of new media, if you will.
[00:20:16.080 --> 00:20:17.080]   Exactly.
[00:20:17.080 --> 00:20:18.080]   Everyone can be a journalist.
[00:20:18.080 --> 00:20:19.080]   Everyone can be a publisher.
[00:20:19.080 --> 00:20:20.080]   It's the digital.
[00:20:20.080 --> 00:20:21.000]   Everyone can distribute content.
[00:20:21.000 --> 00:20:22.440]   It's the digital Daniel Ellsberg.
[00:20:22.440 --> 00:20:23.440]   It's the digital.
[00:20:23.440 --> 00:20:24.440]   Yeah, I got papers.
[00:20:24.440 --> 00:20:26.320]   And that changes everything.
[00:20:26.320 --> 00:20:31.200]   No gatekeepers, no, just release whatever information you have.
[00:20:31.200 --> 00:20:34.240]   But obviously there's problems with that.
[00:20:34.240 --> 00:20:40.120]   But I was fascinated by this sort of non-traditional journalistic entity because some of the things
[00:20:40.120 --> 00:20:43.360]   it was doing were clearly journalistic, not all of them.
[00:20:43.360 --> 00:20:47.120]   And I don't know, to be honest, people keep saying, is Assange a journalist?
[00:20:47.120 --> 00:20:48.120]   Was he a journalist?
[00:20:48.120 --> 00:20:49.120]   So I don't know.
[00:20:49.120 --> 00:20:50.120]   What's a journalist?
[00:20:50.120 --> 00:20:53.360]   Here's a fundamental question then.
[00:20:53.360 --> 00:20:57.480]   We accept the First Amendment should protect free speech and that that free speech should
[00:20:57.480 --> 00:21:04.200]   be extended to journalists, newspapers, particularly so that truth can be spoken to
[00:21:04.200 --> 00:21:06.840]   power.
[00:21:06.840 --> 00:21:10.840]   Does the fact that it's a dump versus a redirected...
[00:21:10.840 --> 00:21:12.240]   Does that change that?
[00:21:12.240 --> 00:21:13.240]   It's irrelevant, right?
[00:21:13.240 --> 00:21:14.240]   No.
[00:21:14.240 --> 00:21:16.840]   The First Amendment doesn't protect journalists.
[00:21:16.840 --> 00:21:20.280]   It protects everybody, but against government.
[00:21:20.280 --> 00:21:21.280]   It protects speech.
[00:21:21.280 --> 00:21:27.240]   Restrictions on speech, but the upshot of it is that newspapers can just...
[00:21:27.240 --> 00:21:28.840]   More than impunity publish what they want.
[00:21:28.840 --> 00:21:30.600]   But there's nothing about newspapers in there.
[00:21:30.600 --> 00:21:31.600]   Of course not.
[00:21:31.600 --> 00:21:32.600]   That's the great thing about it.
[00:21:32.600 --> 00:21:36.960]   Well, and the fact that the Founding Fathers, after writing the First Amendment immediately
[00:21:36.960 --> 00:21:41.480]   broke it by restricting what newspapers could write about.
[00:21:41.480 --> 00:21:44.600]   I can't remember what it was, the tax act or something.
[00:21:44.600 --> 00:21:49.400]   It just shows that even the founders didn't really believe in it.
[00:21:49.400 --> 00:21:51.160]   So it's been under assault ever since.
[00:21:51.160 --> 00:21:53.200]   Nevertheless, I think, at least...
[00:21:53.200 --> 00:21:58.160]   And we are, by the way, one of the few, if not only countries that has such a First Amendment,
[00:21:58.160 --> 00:21:59.160]   right?
[00:21:59.160 --> 00:22:00.160]   Amen.
[00:22:00.160 --> 00:22:03.480]   It's got worse and worse and worse with the regulation of the net.
[00:22:03.480 --> 00:22:07.520]   So it's a challenge in the digital age to...
[00:22:07.520 --> 00:22:09.040]   Because I think you can make a reasonable case.
[00:22:09.040 --> 00:22:11.760]   Remember that the First Amendment is limited a little bit?
[00:22:11.760 --> 00:22:17.040]   Was it Felix Frankfurter who said, "But you can't shout fire in a crowded theater if
[00:22:17.040 --> 00:22:18.600]   there isn't a fire?
[00:22:18.600 --> 00:22:19.600]   That's not protected.
[00:22:19.600 --> 00:22:22.080]   So if it endangers people, it's not protected.
[00:22:22.080 --> 00:22:27.840]   Can that be used to say, "Well, these WikiLeaks data dumps endangered people so they aren't...
[00:22:27.840 --> 00:22:29.600]   Those parts of it are not protected."
[00:22:29.600 --> 00:22:34.320]   Actually, the First Amendment rules in all the jurisprudence.
[00:22:34.320 --> 00:22:40.280]   You have to prove that there's a tangible and specific imminent threat.
[00:22:40.280 --> 00:22:45.400]   Tangible and specific imminent threat to specific individuals.
[00:22:45.400 --> 00:22:47.880]   You can't just say, "This is threatening language."
[00:22:47.880 --> 00:22:50.960]   By the way, it was Oliver Wonder Holmes, not Felix Frankfurter.
[00:22:50.960 --> 00:22:52.680]   He actually changed his mind.
[00:22:52.680 --> 00:22:55.840]   The fire in a crowded theater case is fascinating if you look at it.
[00:22:55.840 --> 00:22:57.320]   There's a great article in the Atlantic.
[00:22:57.320 --> 00:22:59.720]   Yeah, that's a great article right there by Trevor.
[00:22:59.720 --> 00:23:03.040]   It's time to stop using that quote, Trevor Tim.
[00:23:03.040 --> 00:23:04.280]   It's hugely problematic.
[00:23:04.280 --> 00:23:09.440]   In fact, Holmes changed his mind later and said it was a dumb decision.
[00:23:09.440 --> 00:23:13.960]   So then you don't think that endangering somebody is...
[00:23:13.960 --> 00:23:18.360]   So that's the question of free speech.
[00:23:18.360 --> 00:23:19.360]   What is the limit?
[00:23:19.360 --> 00:23:20.840]   Yeah, what's the limit?
[00:23:20.840 --> 00:23:21.840]   I know there's been...
[00:23:21.840 --> 00:23:29.640]   I've had discussions with people about the use of radio in Rwanda, for example.
[00:23:29.640 --> 00:23:36.000]   Radio programs, preachers and so on, calling for violence, helped fuel massacres.
[00:23:36.000 --> 00:23:38.320]   We've got lots of examples.
[00:23:38.320 --> 00:23:43.760]   What's apps groups in India that create rape squads?
[00:23:43.760 --> 00:23:46.720]   But is what's apt to blame for that?
[00:23:46.720 --> 00:23:50.480]   I mean, those people could have just been talking to each other around a campfire.
[00:23:50.480 --> 00:23:55.800]   There's nothing about the app itself except that it distributes it much farther in fact.
[00:23:55.800 --> 00:24:00.360]   That's the conversation we have a lot on the show is the weaponization is what makes
[00:24:00.360 --> 00:24:04.720]   it so very different, the power of the internet.
[00:24:04.720 --> 00:24:11.040]   But I think if you're committed to the idea that free speech and freedom of information
[00:24:11.040 --> 00:24:17.680]   has social benefits that outweigh the disadvantages, then you pretty much have to support something
[00:24:17.680 --> 00:24:22.040]   like Wikileaks, even though Julian Assange isn't asshole.
[00:24:22.040 --> 00:24:26.520]   It's interesting because this original fire in a crowded theater, which goes back to World
[00:24:26.520 --> 00:24:32.960]   War I, was decided it was against the secretary of the Socialist Party of America.
[00:24:32.960 --> 00:24:37.880]   He wrote a pamphlet opposing the draft during World War I.
[00:24:37.880 --> 00:24:40.960]   It didn't call for violence, it didn't call for civil disobedience.
[00:24:40.960 --> 00:24:48.400]   The Supreme Court put him in jail because they ruled it was a clear and present danger to
[00:24:48.400 --> 00:24:51.240]   a nation at war.
[00:24:51.240 --> 00:24:57.600]   So I mean, this is far less really what Wikileaks has done is far less.
[00:24:57.600 --> 00:25:04.880]   But meanwhile now, you know, we were talking about this last week a lot in the UK online
[00:25:04.880 --> 00:25:14.160]   arms, content that is not just illegal and harmful, but legal and harmful is to be outlawed.
[00:25:14.160 --> 00:25:19.120]   And the obligation to do something about that will be on the platforms, not on government.
[00:25:19.120 --> 00:25:27.600]   And it's hugely huge chunks of it are so vague that it's going to be impossible to define
[00:25:27.600 --> 00:25:31.440]   bullying, you're not allowed to have bullying language.
[00:25:31.440 --> 00:25:32.440]   This information.
[00:25:32.440 --> 00:25:36.600]   Yeah, there's there's threats to speech all over and in the US too.
[00:25:36.600 --> 00:25:41.200]   I fear there's there's talk about saying, well, we have too much speech.
[00:25:41.200 --> 00:25:45.400]   The New York Times Sunday said the, you know, the only cure is less internet.
[00:25:45.400 --> 00:25:50.360]   It's getting to be really, really, not just for the Internet, just reaches a hole.
[00:25:50.360 --> 00:25:55.280]   Warren and others are talking about scaling back section 230, which gives the platforms
[00:25:55.280 --> 00:25:59.640]   effective immunity for what's on their for our speech for our conversation.
[00:25:59.640 --> 00:26:03.440]   Things, yeah, that could change things tremendously.
[00:26:03.440 --> 00:26:07.080]   We should point out that that's a white paper is not law yet in the right.
[00:26:07.080 --> 00:26:08.600]   But it's going to be.
[00:26:08.600 --> 00:26:12.520]   And well, given what's going on in the UK, it's hard to tell what what is going to happen.
[00:26:12.520 --> 00:26:14.040]   Well, it's chaos over there.
[00:26:14.040 --> 00:26:16.600]   I mean, it's a train wreck.
[00:26:16.600 --> 00:26:21.320]   Actually, it's like a train where each car is a dumpster fire and it's crashing or
[00:26:21.320 --> 00:26:22.320]   ripping.
[00:26:22.320 --> 00:26:23.800]   Well, the bridge is out.
[00:26:23.800 --> 00:26:24.800]   Yeah.
[00:26:24.800 --> 00:26:26.800]   Well, so.
[00:26:26.800 --> 00:26:29.680]   Well, this is a mess.
[00:26:29.680 --> 00:26:34.280]   This is a fine mess you've gotten us into Julian.
[00:26:34.280 --> 00:26:39.360]   It actually seems like the lesser of all these problems, not just this UK online harms white
[00:26:39.360 --> 00:26:49.080]   paper, but the approval now of the EU of the new copyright act.
[00:26:49.080 --> 00:26:50.680]   That's been gone through its final stages.
[00:26:50.680 --> 00:26:52.120]   And this week was finally approved.
[00:26:52.120 --> 00:26:55.200]   Now each country will have to implement it in law.
[00:26:55.200 --> 00:26:57.800]   And there may be some variations there, but that is.
[00:26:57.800 --> 00:27:02.440]   Well, and think about, I know this is in the lineup, I think, what stars entertainment
[00:27:02.440 --> 00:27:03.920]   did with my tweets.
[00:27:03.920 --> 00:27:05.600]   Oh, yeah, we'll get to that one.
[00:27:05.600 --> 00:27:06.600]   Yeah.
[00:27:06.600 --> 00:27:12.520]   I mean, that's an example of what could happen if platforms are incentivized to take things
[00:27:12.520 --> 00:27:19.880]   down before they get into trouble or block things from being uploaded completely.
[00:27:19.880 --> 00:27:22.520]   Last week we talked about, and I won't go through it again.
[00:27:22.520 --> 00:27:29.280]   The reason we talked about a post I wrote about a proposal for internet courts, which
[00:27:29.280 --> 00:27:30.560]   you might sound might sound frightening.
[00:27:30.560 --> 00:27:33.800]   But actually what it says is that that matters with the gallery on the internet should be
[00:27:33.800 --> 00:27:38.720]   settled in courts, not in companies with due process in public where we negotiate our legal
[00:27:38.720 --> 00:27:40.440]   norms.
[00:27:40.440 --> 00:27:44.320]   And the companies, I think, would would love this because they're being put in position
[00:27:44.320 --> 00:27:48.440]   now, whereas Matthew just said, if you don't take it down within 24 hours, you're under
[00:27:48.440 --> 00:27:53.120]   a huge fund, ergo, you are going to play it safe and take down everything you can take
[00:27:53.120 --> 00:27:54.840]   down and cut off the public conversations.
[00:27:54.840 --> 00:27:58.720]   This is what the internet archive was worried about because they got one of those notices
[00:27:58.720 --> 00:28:00.480]   from the French copyright.
[00:28:00.480 --> 00:28:01.480]   Actually,
[00:28:01.480 --> 00:28:03.480]   So it was filled with terrorism.
[00:28:03.480 --> 00:28:07.640]   They asked them to take down things like grateful dead pages because it was terrorist
[00:28:07.640 --> 00:28:10.960]   and they have 24 hours to do so or be blocked.
[00:28:10.960 --> 00:28:12.760]   Massive funds.
[00:28:12.760 --> 00:28:13.760]   Yeah.
[00:28:13.760 --> 00:28:18.160]   And I mean, I like the idea of a court too.
[00:28:18.160 --> 00:28:21.400]   It sounds like a Justice League kind of thing.
[00:28:21.400 --> 00:28:24.360]   But I mean, who is going to be on this court?
[00:28:24.360 --> 00:28:26.320]   Like who's going to decide?
[00:28:26.320 --> 00:28:29.240]   This was a jurist who proposed this.
[00:28:29.240 --> 00:28:31.360]   And the court or the court is a government body.
[00:28:31.360 --> 00:28:39.120]   You have judges, which cover especially trained in the internet and appointed and as you would
[00:28:39.120 --> 00:28:40.720]   judges in any of whose government?
[00:28:40.720 --> 00:28:41.720]   France?
[00:28:41.720 --> 00:28:42.720]   Which government?
[00:28:42.720 --> 00:28:45.160]   Per nation, per nation.
[00:28:45.160 --> 00:28:47.360]   So you can't have an internet country.
[00:28:47.360 --> 00:28:49.520]   You have an internet court in every country dealing with it because you have to because
[00:28:49.520 --> 00:28:52.320]   you have to deal with the laws of that country.
[00:28:52.320 --> 00:28:55.880]   You could the EU theoretically, you could probably have one across the EU like you have
[00:28:55.880 --> 00:28:59.440]   a human rights court across the EU and other courts.
[00:28:59.440 --> 00:29:03.560]   But no, otherwise it would have to be per nation because you're dealing with enforcement
[00:29:03.560 --> 00:29:06.400]   of the laws of that nation.
[00:29:06.400 --> 00:29:15.040]   But it's really a Sophie's choice here because we need to end up with a choice because
[00:29:15.040 --> 00:29:16.040]   volcanize internet.
[00:29:16.040 --> 00:29:18.080]   Yeah, I mean, doesn't sound like-
[00:29:18.080 --> 00:29:20.240]   Well, I know Matthew were already there.
[00:29:20.240 --> 00:29:24.480]   The platform say we will enforce the laws of the nations we're in.
[00:29:24.480 --> 00:29:29.000]   The problem is they're being forced to make legal judgments with no legal authority,
[00:29:29.000 --> 00:29:31.040]   with huge liability.
[00:29:31.040 --> 00:29:34.480]   So what this does is because that's government saying, oh, we don't know how to do this.
[00:29:34.480 --> 00:29:38.680]   So we're going to force you companies to do it with no guidance with vague laws and you're
[00:29:38.680 --> 00:29:40.960]   going to be constantly be afraid that you're going to get some stuff wrong.
[00:29:40.960 --> 00:29:42.440]   We're going to find your asses.
[00:29:42.440 --> 00:29:43.920]   And by the way-
[00:29:43.920 --> 00:29:46.280]   Yeah, because they'll filter everything.
[00:29:46.280 --> 00:29:47.280]   Exactly.
[00:29:47.280 --> 00:29:50.160]   You know, even after the net state gay in Germany, the German government said, oh, they're
[00:29:50.160 --> 00:29:51.480]   taking down too much.
[00:29:51.480 --> 00:29:52.720]   Well, why?
[00:29:52.720 --> 00:29:54.720]   Because they are under a huge liability.
[00:29:54.720 --> 00:30:00.000]   It really is actually almost literally a Hobbesian dilemma.
[00:30:00.000 --> 00:30:01.000]   Yeah.
[00:30:01.000 --> 00:30:07.040]   The Hobbes- this Hobbes choice came from Thomas Hobbes belief that a man must choose between
[00:30:07.040 --> 00:30:11.680]   living in a state of nature, a life which is solitary, poor, nasty, brutish, and short,
[00:30:11.680 --> 00:30:14.200]   or suffering under an arbitrary and absolute government.
[00:30:14.200 --> 00:30:15.600]   Sounds about right.
[00:30:15.600 --> 00:30:18.680]   It's literally a Hobbesian dilemma.
[00:30:18.680 --> 00:30:19.680]   Yeah.
[00:30:19.680 --> 00:30:21.680]   I thought you meant Calvin and Hobbes.
[00:30:21.680 --> 00:30:23.480]   Well, then too.
[00:30:23.480 --> 00:30:30.520]   But honestly, I don't think this is basically there is no choice because there's both
[00:30:30.520 --> 00:30:33.120]   alternatives are terrible.
[00:30:33.120 --> 00:30:34.120]   We've seen government.
[00:30:34.120 --> 00:30:35.520]   We've seen regulation at work.
[00:30:35.520 --> 00:30:37.240]   We've seen governments that is getting working.
[00:30:37.240 --> 00:30:38.880]   That's not working.
[00:30:38.880 --> 00:30:42.720]   And yet we've seen it unregulated internet and that's not working.
[00:30:42.720 --> 00:30:48.160]   I think there's a real risk that countries like China and even Russia are effectively
[00:30:48.160 --> 00:30:49.400]   building their own internet.
[00:30:49.400 --> 00:30:51.440]   Well, we've talked about splinter nets as well.
[00:30:51.440 --> 00:30:52.880]   It won't even be part of it.
[00:30:52.880 --> 00:30:55.520]   The only question is how splinter it will be.
[00:30:55.520 --> 00:30:58.920]   There was a piece arguing that we have four or five internets already.
[00:30:58.920 --> 00:30:59.920]   Yes.
[00:30:59.920 --> 00:31:02.520]   In the authoritarian internet of Silicon Valley, there's the commercial internet of the rest
[00:31:02.520 --> 00:31:03.520]   of America.
[00:31:03.520 --> 00:31:07.640]   There's the bourgeois internet of Europe where they want us to behave.
[00:31:07.640 --> 00:31:10.440]   There's the authoritarian internet of China and Iran.
[00:31:10.440 --> 00:31:15.280]   And there's the misinformation internet of Russia and North Korea.
[00:31:15.280 --> 00:31:21.000]   And I should point out that with each of the 50 states now enforcing their own privacy
[00:31:21.000 --> 00:31:26.880]   and that neutrality laws, there may be an internet for every state in the union.
[00:31:26.880 --> 00:31:31.200]   So that and clearly that's not.
[00:31:31.200 --> 00:31:35.440]   So we're going to have passports to go from one website to another.
[00:31:35.440 --> 00:31:37.000]   Yeah, you know what?
[00:31:37.000 --> 00:31:40.200]   That's actually technically achievable.
[00:31:40.200 --> 00:31:45.000]   Of course, that'll really improve the VPN market.
[00:31:45.000 --> 00:31:50.800]   But we can enforce location blocking.
[00:31:50.800 --> 00:31:56.280]   And I recently, you can only watch this show if you live in California, Texas and Florida.
[00:31:56.280 --> 00:31:58.920]   Where does the internet resistance look like them?
[00:31:58.920 --> 00:31:59.920]   Yeah.
[00:31:59.920 --> 00:32:04.800]   Well, and this is funny because this is a conversation that goes way back to the earliest days of
[00:32:04.800 --> 00:32:05.800]   the internet.
[00:32:05.800 --> 00:32:09.920]   And I participated to some degree in this.
[00:32:09.920 --> 00:32:14.440]   I really encourage people to get hacking skills because I always felt a corporate internet
[00:32:14.440 --> 00:32:18.720]   was going to eventually take over and that the only way to save the internet would be
[00:32:18.720 --> 00:32:26.240]   have a secret net, a dark net that was inhabited by people with the technical skills to go
[00:32:26.240 --> 00:32:28.160]   to create it and live in it.
[00:32:28.160 --> 00:32:30.360]   And I bet that's exactly what'll happen.
[00:32:30.360 --> 00:32:35.160]   I think that's what the indie web and people like that are trying to do is give people the
[00:32:35.160 --> 00:32:38.600]   tools to connect themselves instead of.
[00:32:38.600 --> 00:32:44.840]   Well, certainly they don't want siloed corporate, Twitter, social networks and so forth.
[00:32:44.840 --> 00:32:49.240]   But they still want to live in the public and in the open.
[00:32:49.240 --> 00:32:53.280]   But I think ultimately that's not even going to be possible because of government regulation
[00:32:53.280 --> 00:32:54.280]   and things like that.
[00:32:54.280 --> 00:32:59.800]   Well, and there's actually been a big trend already to people sort of looking for private
[00:32:59.800 --> 00:33:03.800]   places to gather private Facebook groups, you know, WhatsApp groups.
[00:33:03.800 --> 00:33:04.800]   Okay.
[00:33:04.800 --> 00:33:07.000]   By the way, that's an oxymoron, a private Facebook group.
[00:33:07.000 --> 00:33:10.800]   We know that now and we're going to talk about that in a second.
[00:33:10.800 --> 00:33:11.800]   There is a lot to talk about.
[00:33:11.800 --> 00:33:13.840]   I realize now today.
[00:33:13.840 --> 00:33:14.840]   Yep.
[00:33:14.840 --> 00:33:15.840]   All right.
[00:33:15.840 --> 00:33:18.240]   Let's take a break.
[00:33:18.240 --> 00:33:19.400]   Matthew Ingram is here.
[00:33:19.400 --> 00:33:25.440]   He is a digital writer, the chief digital writer at the Columbia journalism review, CJR.org
[00:33:25.440 --> 00:33:28.480]   and always a welcome guest.
[00:33:28.480 --> 00:33:30.240]   You were at Globe and Mail writer where you at the star.
[00:33:30.240 --> 00:33:31.440]   You were at the Globe and Mail.
[00:33:31.440 --> 00:33:32.440]   I was at the Globe, yeah.
[00:33:32.440 --> 00:33:33.440]   Many years ago.
[00:33:33.440 --> 00:33:37.640]   Many years ago, you probably saw him on giga home and fortune.
[00:33:37.640 --> 00:33:41.240]   Now CJR Jeff Jarvis, as I've already mentioned.
[00:33:41.240 --> 00:33:44.760]   Actually, I should read your other title.
[00:33:44.760 --> 00:33:48.160]   Sir Jeff Jarvis, defender of the faith.
[00:33:48.160 --> 00:33:49.320]   Order of the British Empire.
[00:33:49.320 --> 00:33:51.640]   No, no, that's the wrong one.
[00:33:51.640 --> 00:33:52.640]   There he is.
[00:33:52.640 --> 00:33:53.640]   There it is.
[00:33:53.640 --> 00:33:54.640]   Of journalism at CUNY.
[00:33:54.640 --> 00:33:56.240]   How about the shirt version?
[00:33:56.240 --> 00:34:00.640]   By the way, you guys at CUNY and I saw Sarah's tweet.
[00:34:00.640 --> 00:34:02.160]   That was great.
[00:34:02.160 --> 00:34:03.800]   Your Dean's tweet.
[00:34:03.800 --> 00:34:07.320]   Did I, Carson, did I bookmark that somewhere?
[00:34:07.320 --> 00:34:08.320]   I feel inadequate.
[00:34:08.320 --> 00:34:10.760]   My description is nowhere near as long.
[00:34:10.760 --> 00:34:11.760]   I know you should work on it.
[00:34:11.760 --> 00:34:15.040]   There's Sarah Bartlett, the dean of CUNY, the new Mark's School.
[00:34:15.040 --> 00:34:16.040]   It was been on the show.
[00:34:16.040 --> 00:34:18.280]   Scroll down a little bit though, Carson, because the most important part of that tweet
[00:34:18.280 --> 00:34:23.360]   is her pocket protector, which is in fact a truth protector.
[00:34:23.360 --> 00:34:29.640]   This was our tribute to our benefactor and namesake Craig Newmark.
[00:34:29.640 --> 00:34:31.320]   Is he a truth protector?
[00:34:31.320 --> 00:34:33.440]   He also wants pocket protectors.
[00:34:33.440 --> 00:34:34.440]   Oh, did he?
[00:34:34.440 --> 00:34:35.440]   Yeah.
[00:34:35.440 --> 00:34:37.840]   Does he still wear pocket protectors?
[00:34:37.840 --> 00:34:39.280]   No, he doesn't know.
[00:34:39.280 --> 00:34:40.280]   Not anymore.
[00:34:40.280 --> 00:34:43.720]   I had a tech guy pocket protector I used to give out for years.
[00:34:43.720 --> 00:34:46.560]   And before that, we had a ZD in that pocket protector.
[00:34:46.560 --> 00:34:48.520]   But I like to live dangerously.
[00:34:48.520 --> 00:34:51.280]   I have a fountain pen in an unprotected pocket.
[00:34:51.280 --> 00:34:52.280]   It's fair.
[00:34:52.280 --> 00:34:53.280]   It's a pen.
[00:34:53.280 --> 00:34:55.200]   The pen is worth more than a shirt.
[00:34:55.200 --> 00:34:59.080]   Yeah, that's my point of saying the wild side there.
[00:34:59.080 --> 00:35:03.080]   I'm sure.
[00:35:03.080 --> 00:35:07.640]   One thing that pocket protector and the pen cannot do, the pen may be mightier than the
[00:35:07.640 --> 00:35:12.000]   sword, but the pen is not mightier than grammarly.
[00:35:12.000 --> 00:35:17.560]   And I have to say, while I like writing with a pen, my writing is more coherent and certainly
[00:35:17.560 --> 00:35:21.240]   more grammatical when I do it on a computer because of grammarly.
[00:35:21.240 --> 00:35:25.840]   Grammarly is a communication tool that helps people improve their writing to be mistake-free,
[00:35:25.840 --> 00:35:27.400]   clear, and effective.
[00:35:27.400 --> 00:35:31.480]   The thing I find fascinating is the biggest proponents of grammarly are the best writers
[00:35:31.480 --> 00:35:33.400]   I know.
[00:35:33.400 --> 00:35:35.360]   Paul Therat wouldn't write a word without grammarly.
[00:35:35.360 --> 00:35:37.160]   Not because he doesn't know grammar or the spelling.
[00:35:37.160 --> 00:35:38.840]   He's very good at that.
[00:35:38.840 --> 00:35:43.520]   But grammarly does more than just, it's more than a nanny correcting you.
[00:35:43.520 --> 00:35:48.400]   It's a writing assistant that helps you improve your communication, whether it's at school
[00:35:48.400 --> 00:35:52.520]   at work on your website, almost anywhere.
[00:35:52.520 --> 00:35:55.440]   Show your best self through writing.
[00:35:55.440 --> 00:35:58.440]   And by the way, grammarly is available everywhere you write, including online.
[00:35:58.440 --> 00:35:59.760]   There's an online browser extension.
[00:35:59.760 --> 00:36:01.360]   There's a desktop editor.
[00:36:01.360 --> 00:36:05.120]   Even on mobile, there's a mobile keyboard and keyboard checker.
[00:36:05.120 --> 00:36:11.320]   Grammarly comes on Chrome, Firefox, Safari, and Edge on iOS, Android, Windows, and Mac.
[00:36:11.320 --> 00:36:13.800]   They do have a free product, which you should certainly try.
[00:36:13.800 --> 00:36:15.800]   It reviews critical spelling and grammar.
[00:36:15.800 --> 00:36:17.680]   But grammarly premium is so much more.
[00:36:17.680 --> 00:36:19.720]   And that's what I really want you to look at.
[00:36:19.720 --> 00:36:25.080]   It watches spelling and grammar, but it also has advanced punctuation structure.
[00:36:25.080 --> 00:36:28.920]   This is the key stuff, style within context.
[00:36:28.920 --> 00:36:32.600]   So it understands whether you're writing a business proposal or an academic essay or
[00:36:32.600 --> 00:36:39.440]   a casual blog post, not only understands the context, it suggests the appropriate style.
[00:36:39.440 --> 00:36:40.440]   It bluffs me away.
[00:36:40.440 --> 00:36:46.600]   Lisa, who is a good business person, runs our company, tends to be, she's fascist a
[00:36:46.600 --> 00:36:47.600]   lot to do.
[00:36:47.600 --> 00:36:50.200]   So she tends to write short emails.
[00:36:50.200 --> 00:36:53.400]   And everyone's a while, Grammarly said, you know, you could not be a little nicer.
[00:36:53.400 --> 00:36:57.840]   In effect, I think it says, try softening this phrase with this.
[00:36:57.840 --> 00:36:59.640]   You know, you could be a little nicer.
[00:36:59.640 --> 00:37:02.760]   And if I said that she'd bite my head off, but if Grammarly says it, she says, oh, that's
[00:37:02.760 --> 00:37:05.120]   a good point and we'll use it.
[00:37:05.120 --> 00:37:06.120]   It works.
[00:37:06.120 --> 00:37:07.120]   It helps you be more concise.
[00:37:07.120 --> 00:37:08.680]   It'll actually grade readability.
[00:37:08.680 --> 00:37:12.520]   So you can say, you know, I'm writing this for a mass audience.
[00:37:12.520 --> 00:37:14.720]   I want to make this more unintelligible.
[00:37:14.720 --> 00:37:16.680]   I'm writing this for a college essay.
[00:37:16.680 --> 00:37:20.040]   I can, I can use those big words.
[00:37:20.040 --> 00:37:23.800]   It actually does make vocabulary suggestions as well.
[00:37:23.800 --> 00:37:25.720]   No more email typos on the phone.
[00:37:25.720 --> 00:37:26.720]   Imagine that.
[00:37:26.720 --> 00:37:32.240]   Close more deals with work because your emails are more concise, precise.
[00:37:32.240 --> 00:37:34.080]   They say what you want them to say.
[00:37:34.080 --> 00:37:35.080]   Polish your resume.
[00:37:35.080 --> 00:37:36.080]   Get that new job.
[00:37:36.080 --> 00:37:41.480]   And I love the weekly Grammarly email I get, which always makes me feel pretty good saying,
[00:37:41.480 --> 00:37:45.800]   you know, I used more big words and 90% of their other customers and things like that.
[00:37:45.800 --> 00:37:48.160]   It's just fun.
[00:37:48.160 --> 00:37:49.760]   You will love Grammarly Premium.
[00:37:49.760 --> 00:37:50.760]   So here's the deal.
[00:37:50.760 --> 00:37:53.520]   20% off right now in the Grammarly Premium account.
[00:37:53.520 --> 00:37:56.480]   If you go to grammarly.com/twig.
[00:37:56.480 --> 00:37:58.360]   Do I have to spell Grammarly for you?
[00:37:58.360 --> 00:37:59.360]   Probably.
[00:37:59.360 --> 00:38:01.360]   G-R-A-M-M-A-R-L-Y.
[00:38:01.360 --> 00:38:03.360]   There's no E in grammar.
[00:38:03.360 --> 00:38:06.360]   Grammarly.com/twig.
[00:38:06.360 --> 00:38:09.840]   For 20% off your premium account.
[00:38:09.840 --> 00:38:13.200]   By the way, we thank Grammarly for their support of this week in Google.
[00:38:13.200 --> 00:38:21.160]   And we thank you for supporting us by using that URL, Grammarly.com/twig.
[00:38:21.160 --> 00:38:22.520]   I want a truth protector.
[00:38:22.520 --> 00:38:23.520]   I love that.
[00:38:23.520 --> 00:38:25.920]   But I'm not a, I'm not a general student.
[00:38:25.920 --> 00:38:30.960]   So I have, I still have my CUNY hoodie, my town, school hoodie.
[00:38:30.960 --> 00:38:31.960]   I love that thing.
[00:38:31.960 --> 00:38:34.000]   Well, we have to replace that because now we have to have a new mark.
[00:38:34.000 --> 00:38:35.840]   Oh, I should say new mark on it.
[00:38:35.840 --> 00:38:36.840]   Yes.
[00:38:36.840 --> 00:38:37.840]   It does.
[00:38:37.840 --> 00:38:38.840]   We do have those now, yes.
[00:38:38.840 --> 00:38:39.840]   Craig is a sweet guy.
[00:38:39.840 --> 00:38:43.320]   We were talking about him before the show.
[00:38:43.320 --> 00:38:48.280]   He's like, he has the most, he's like the most successful unicorn in Silicon Valley.
[00:38:48.280 --> 00:38:52.960]   They made a billion dollars last year with 80% profit.
[00:38:52.960 --> 00:38:53.960]   No way knows what they make.
[00:38:53.960 --> 00:38:54.960]   But they just as well.
[00:38:54.960 --> 00:38:55.960]   Yes, it's a lot.
[00:38:55.960 --> 00:38:56.960]   50 employees.
[00:38:56.960 --> 00:38:57.960]   50 employees.
[00:38:57.960 --> 00:38:58.960]   Yeah.
[00:38:58.960 --> 00:38:59.960]   And he is very humble.
[00:38:59.960 --> 00:39:00.960]   And he's a sweet guy.
[00:39:00.960 --> 00:39:01.960]   Very humble.
[00:39:01.960 --> 00:39:02.960]   Yeah.
[00:39:02.960 --> 00:39:03.960]   He is amazing.
[00:39:03.960 --> 00:39:06.200]   You know, I hear that you had gelato with him in Perugia.
[00:39:06.200 --> 00:39:07.200]   I did.
[00:39:07.200 --> 00:39:08.200]   It's really.
[00:39:08.200 --> 00:39:10.280]   Where did you hear that from, Leo?
[00:39:10.280 --> 00:39:13.560]   I paid for my own gelato just to be clear.
[00:39:13.560 --> 00:39:15.280]   No, I would make him pay.
[00:39:15.280 --> 00:39:16.760]   He can afford a gelato.
[00:39:16.760 --> 00:39:21.520]   Craig has done more perjournalism probably in the last year or two than anyone in the
[00:39:21.520 --> 00:39:22.760]   previous 50 years.
[00:39:22.760 --> 00:39:27.800]   Now this is where the disclaimer should come in that Facebook, you work with Facebook,
[00:39:27.800 --> 00:39:32.040]   Jeff, on a- I raised money from my school from Facebook, from Craig Newmark and from
[00:39:32.040 --> 00:39:36.400]   Mothers, but I'm independent of all of them and received no money personally from Facebook
[00:39:36.400 --> 00:39:38.160]   or Google or Twitter.
[00:39:38.160 --> 00:39:44.360]   So I'm very curious what you both think about this story that came out from NBC.
[00:39:44.360 --> 00:39:48.800]   Now this is a cache of documents that actually has been around for a while.
[00:39:48.800 --> 00:39:50.840]   The UK government had it for a while.
[00:39:50.840 --> 00:39:53.520]   You've talked about its providence before.
[00:39:53.520 --> 00:39:59.880]   It was a discovery material in a separate trial that the UK government kind of got from
[00:39:59.880 --> 00:40:00.880]   the guy.
[00:40:00.880 --> 00:40:06.640]   Facebook was pissed off about it, but apparently NBC has now seen it combed through the 4,000
[00:40:06.640 --> 00:40:11.880]   pages largely from 2011 to 2015.
[00:40:11.880 --> 00:40:17.560]   And at least according to their characterization, I want to emphasize that because they're not
[00:40:17.560 --> 00:40:19.760]   quoting this verbatim.
[00:40:19.760 --> 00:40:22.760]   They're characterizing what they read.
[00:40:22.760 --> 00:40:26.600]   So it is conceivable that they're mischaracterizing it.
[00:40:26.600 --> 00:40:29.000]   So I want to give Facebook the benefit of that.
[00:40:29.000 --> 00:40:37.560]   However, if their characterization is accurate, this is the smoking gun that is the final nail
[00:40:37.560 --> 00:40:41.760]   in the coffin, the end of Facebook as we know it.
[00:40:41.760 --> 00:40:43.240]   Not to oversell it.
[00:40:43.240 --> 00:40:44.240]   Not to oversell it.
[00:40:44.240 --> 00:40:49.280]   But when I read this, I went, "Oh, MG, I'm sure glad I don't use Facebook."
[00:40:49.280 --> 00:40:53.520]   Let me read, let me just read their NBC characterization.
[00:40:53.520 --> 00:40:56.800]   And I would very much, I want to be fair to Facebook.
[00:40:56.800 --> 00:41:04.720]   So any quibbles or caveats or the documents, which include emails, web chats, presentations,
[00:41:04.720 --> 00:41:10.160]   spreadsheets and meeting summaries, show how Zuckerberg, along with his board and management
[00:41:10.160 --> 00:41:18.040]   team, found ways to tap Facebook's trove of user data, your data, my data, our data,
[00:41:18.040 --> 00:41:24.360]   including information about friends, relationships, even photos as leverage over companies it
[00:41:24.360 --> 00:41:25.360]   partnered with.
[00:41:25.360 --> 00:41:30.360]   In some cases, Facebook would reward favorite companies by giving them access to the data.
[00:41:30.360 --> 00:41:35.600]   In other cases, it would deny data access to rival companies or apps.
[00:41:35.600 --> 00:41:39.640]   For instance, Amazon got extended use of that data because it was spending money on
[00:41:39.640 --> 00:41:44.840]   Facebook advertising and partnering with them on the launch of the fire phone.
[00:41:44.840 --> 00:41:48.960]   On the other hand, Facebook discussed cutting off access to user data for a messaging app
[00:41:48.960 --> 00:41:51.520]   that had grown too popular and was used as a competitor.
[00:41:51.520 --> 00:41:57.960]   This is all they say, but not quoting, they say in the documents.
[00:41:57.960 --> 00:42:02.800]   And even worse all the while, Facebook was formulating a strategy to publicly frame
[00:42:02.800 --> 00:42:09.320]   these moves as a way of protecting user privacy.
[00:42:09.320 --> 00:42:13.160]   It's a win-win.
[00:42:13.160 --> 00:42:20.840]   I shouldn't be shocked, but at this point, this is a criminal breach of our trust.
[00:42:20.840 --> 00:42:24.800]   But I don't know.
[00:42:24.800 --> 00:42:29.240]   The problem here is it's because they're not quoting what data.
[00:42:29.240 --> 00:42:32.680]   There were rules in place for every app builder.
[00:42:32.680 --> 00:42:38.520]   Let's go back to the time when Facebook thought of itself as a platform for apps.
[00:42:38.520 --> 00:42:43.880]   And at that time, when you wrote apps, if you followed certain rules, you got access
[00:42:43.880 --> 00:42:46.800]   to data.
[00:42:46.800 --> 00:42:49.840]   So now data has become the grand scare word.
[00:42:49.840 --> 00:42:52.680]   Oh my God, data.
[00:42:52.680 --> 00:42:55.920]   Well data is just information and it depends on what data.
[00:42:55.920 --> 00:42:57.840]   It depends on what your expectation was.
[00:42:57.840 --> 00:42:59.640]   It depends upon all of that.
[00:42:59.640 --> 00:43:07.400]   So it becomes needless without that kind of specificity as to what it was.
[00:43:07.400 --> 00:43:08.600]   Did they do bad things?
[00:43:08.600 --> 00:43:09.600]   Maybe they did.
[00:43:09.600 --> 00:43:10.600]   Maybe they did.
[00:43:10.600 --> 00:43:11.600]   I don't know.
[00:43:11.600 --> 00:43:16.080]   But this whole notion of that we're going to trade access to data for certain behavior
[00:43:16.080 --> 00:43:18.800]   is the way that Facebook is operating from the beginning.
[00:43:18.800 --> 00:43:22.440]   And by the way, every media company operates.
[00:43:22.440 --> 00:43:26.640]   You buy ads, you get access to data about the users there.
[00:43:26.640 --> 00:43:29.360]   That's the way it's operating for a very long time.
[00:43:29.360 --> 00:43:34.760]   But I think the one thing that you could say about some of what NBC is talking about is
[00:43:34.760 --> 00:43:42.880]   that there's a clear potential antitrust aspect if Facebook is using its users' data
[00:43:42.880 --> 00:43:47.400]   and giving it to certain partners and not to other partners, especially if those other
[00:43:47.400 --> 00:43:50.720]   partners have a messenger app that is a threat to Facebook.
[00:43:50.720 --> 00:43:54.320]   I mean, that's a very clear, like if I was an antitrust lawyer.
[00:43:54.320 --> 00:43:58.000]   But in the years when this was supposedly happening, they weren't as big.
[00:43:58.000 --> 00:43:59.600]   Well, they were still pretty big.
[00:43:59.600 --> 00:44:02.600]   2011 to 2014, they were pretty big.
[00:44:02.600 --> 00:44:03.600]   They were pretty big.
[00:44:03.600 --> 00:44:04.600]   Facebook's response is...
[00:44:04.600 --> 00:44:05.600]   I thought it was 205.
[00:44:05.600 --> 00:44:06.600]   It was 205.
[00:44:06.600 --> 00:44:08.600]   Oh, let me, I'm sorry.
[00:44:08.600 --> 00:44:09.600]   I may be misquoting.
[00:44:09.600 --> 00:44:10.600]   Let me go back.
[00:44:10.600 --> 00:44:11.600]   I thought I could be wrong.
[00:44:11.600 --> 00:44:12.600]   I could be wrong.
[00:44:12.600 --> 00:44:13.600]   2011 to 2015.
[00:44:13.600 --> 00:44:14.600]   Okay.
[00:44:14.600 --> 00:44:15.600]   All right.
[00:44:15.600 --> 00:44:16.600]   They were pretty big.
[00:44:16.600 --> 00:44:20.880]   I don't think that's a very obvious antitrust or potential antitrust.
[00:44:20.880 --> 00:44:25.200]   Facebook's response is that the documents were cherry-picked.
[00:44:25.200 --> 00:44:29.840]   They were cherry-picked during the reason these documents exist.
[00:44:29.840 --> 00:44:37.800]   There was a lawsuit by 643, the creators of the Pekinges app.
[00:44:37.800 --> 00:44:41.160]   Facebook says they cherry-picked those documents from years ago as part of a lawsuit to force
[00:44:41.160 --> 00:44:46.200]   Facebook to share information on friends of the apps' users.
[00:44:46.200 --> 00:44:49.600]   The set of documents by design, because it's being used in a lawsuit, tells only one side
[00:44:49.600 --> 00:44:53.760]   of the story in a mid-important context.
[00:44:53.760 --> 00:44:55.240]   We still stand by the information.
[00:44:55.240 --> 00:44:59.840]   The platform changes, we made it in 2014-15, to prevent people from sharing their friends'
[00:44:59.840 --> 00:45:03.840]   information with developers like the creators of Pekinges.
[00:45:03.840 --> 00:45:07.120]   The documents were selectively leaked as part of what the court found was evidence of a
[00:45:07.120 --> 00:45:11.960]   crime or fraud to publish some, but not all of the internal discussions at Facebook at
[00:45:11.960 --> 00:45:14.400]   the time of our platform changes.
[00:45:14.400 --> 00:45:18.640]   But the facts are clear, Facebook says, and this is actually Facebook's vice president
[00:45:18.640 --> 00:45:21.840]   and deputy general counsel Paul Gruwell.
[00:45:21.840 --> 00:45:22.840]   The facts are clear.
[00:45:22.840 --> 00:45:26.400]   They've never sold people's data.
[00:45:26.400 --> 00:45:29.080]   That's a non-denial denial, because they're not being accused of selling people's data.
[00:45:29.080 --> 00:45:30.080]   They did talk about it.
[00:45:30.080 --> 00:45:31.080]   Yeah.
[00:45:31.080 --> 00:45:33.520]   That's the other thing that comes up in the documents.
[00:45:33.520 --> 00:45:34.520]   They talked about it.
[00:45:34.520 --> 00:45:37.440]   Yeah, and that shouldn't surprise us.
[00:45:37.440 --> 00:45:38.440]   Right?
[00:45:38.440 --> 00:45:42.920]   Media companies, I know they do this far enough to get any damn data.
[00:45:42.920 --> 00:45:44.080]   Talked about whether there was a...
[00:45:44.080 --> 00:45:47.120]   I've sat in media companies where they talked about it as they're a marketplace for our
[00:45:47.120 --> 00:45:48.120]   data.
[00:45:48.120 --> 00:45:51.720]   Indeed, when I worked at Time Inc, we sold data.
[00:45:51.720 --> 00:45:55.040]   We sold your name and your address and what you subscribe to.
[00:45:55.040 --> 00:45:56.040]   We sold lists.
[00:45:56.040 --> 00:45:57.040]   That happens all the time.
[00:45:57.040 --> 00:45:58.040]   That's what we do as part of our business.
[00:45:58.040 --> 00:45:59.040]   Yeah, sure, exactly.
[00:45:59.040 --> 00:46:01.560]   If you've got a mailing list, that's valuable.
[00:46:01.560 --> 00:46:02.560]   You can sell it.
[00:46:02.560 --> 00:46:07.160]   Not just the mailing list, but the data behind it and what could be aggregated around that
[00:46:07.160 --> 00:46:08.920]   by companies like Axion.
[00:46:08.920 --> 00:46:09.920]   Right.
[00:46:09.920 --> 00:46:13.960]   So this has been part of the media business for a very, very long time.
[00:46:13.960 --> 00:46:21.680]   Again, I'm not trying to defend Facebook here, but I am trying to say that...
[00:46:21.680 --> 00:46:25.320]   But we don't know enough to come to grand conclusions that this is...
[00:46:25.320 --> 00:46:27.200]   Oh my God, it's a smoking gun.
[00:46:27.200 --> 00:46:28.880]   It's the worst thing that could happen.
[00:46:28.880 --> 00:46:29.880]   We just don't know enough.
[00:46:29.880 --> 00:46:30.880]   And I think that...
[00:46:30.880 --> 00:46:31.880]   But I think the main difference...
[00:46:31.880 --> 00:46:32.880]   Given the...
[00:46:32.880 --> 00:46:33.880]   One more thing, one more thing.
[00:46:33.880 --> 00:46:34.880]   One more thing.
[00:46:34.880 --> 00:46:40.520]   Given the atmosphere these days, of media coverage in moral panic, my chair is a really
[00:46:40.520 --> 00:46:44.840]   lonely one trying to defend the internet, but I fear if you look at what's happening
[00:46:44.840 --> 00:46:51.200]   with regulation in Europe, this kind of talk without evidence could lead to things like
[00:46:51.200 --> 00:46:53.880]   this from the UK.
[00:46:53.880 --> 00:46:55.960]   And it can hurt the internet.
[00:46:55.960 --> 00:46:58.880]   I wanted to defend the internet, but the Facebook is not the internet.
[00:46:58.880 --> 00:47:02.920]   And in fact, Facebook damages the internet more than any conversation if they're doing
[00:47:02.920 --> 00:47:04.200]   stuff like this.
[00:47:04.200 --> 00:47:06.440]   As you said earlier, you might have to defend...
[00:47:06.440 --> 00:47:09.760]   To go to your view, you might have to defend Julian Assange to defend the speech.
[00:47:09.760 --> 00:47:12.360]   But for Facebook to say, we keep your data private.
[00:47:12.360 --> 00:47:18.400]   And in fact, the very implicit promise of Facebook is you put your private stuff on
[00:47:18.400 --> 00:47:20.200]   there and friends can see it.
[00:47:20.200 --> 00:47:21.200]   Nobody else.
[00:47:21.200 --> 00:47:22.200]   That is...
[00:47:22.200 --> 00:47:23.200]   That is...
[00:47:23.200 --> 00:47:24.200]   That you control who can see your data.
[00:47:24.200 --> 00:47:26.200]   No, I put everything on there as public.
[00:47:26.200 --> 00:47:27.200]   And that's very difficult.
[00:47:27.200 --> 00:47:28.200]   That's your choice, but honestly, Facebook...
[00:47:28.200 --> 00:47:29.200]   Oh yeah, but that's...
[00:47:29.200 --> 00:47:30.200]   But that's...
[00:47:30.200 --> 00:47:31.200]   But that's what Facebook...
[00:47:31.200 --> 00:47:37.320]   I mean, you ask anybody in the street when you share something on Facebook to your family,
[00:47:37.320 --> 00:47:40.720]   do you expect them to sell it to somebody else for...
[00:47:40.720 --> 00:47:41.720]   That's selling it.
[00:47:41.720 --> 00:47:45.280]   Okay, or give it to a favorite partner.
[00:47:45.280 --> 00:47:46.280]   That's right.
[00:47:46.280 --> 00:47:47.280]   What happens, Leo, don't be naive.
[00:47:47.280 --> 00:47:49.480]   That's what happens when an advertiser targets an ad.
[00:47:49.480 --> 00:47:51.880]   They're getting access to the data.
[00:47:51.880 --> 00:47:55.280]   They're making use of that data to target that ad.
[00:47:55.280 --> 00:47:58.120]   And that's one of the reasons I want to understand this better.
[00:47:58.120 --> 00:47:59.120]   Every media company does.
[00:47:59.120 --> 00:48:02.160]   Yes, because NBC could be characterizing...
[00:48:02.160 --> 00:48:03.640]   And by the way, NBC does it.
[00:48:03.640 --> 00:48:04.640]   NBC does it.
[00:48:04.640 --> 00:48:11.400]   But they could be characterizing that kind of behavior as giving data up or actually giving
[00:48:11.400 --> 00:48:12.400]   people the data.
[00:48:12.400 --> 00:48:17.960]   Because Facebook might say, "Well, yes, you can buy an ad against a demographic, but
[00:48:17.960 --> 00:48:23.040]   that doesn't mean we're giving you information about Leo."
[00:48:23.040 --> 00:48:24.760]   And so that's the real question is.
[00:48:24.760 --> 00:48:29.000]   And absolutely, NBC sells ads against the demographic all the time.
[00:48:29.000 --> 00:48:30.000]   Everybody does.
[00:48:30.000 --> 00:48:35.760]   I sat in a meeting with Google once some years ago, where the publishers were all saying
[00:48:35.760 --> 00:48:38.600]   to Google, "Give us data, give us data, give us data."
[00:48:38.600 --> 00:48:41.000]   And Google said, "No."
[00:48:41.000 --> 00:48:45.080]   And they said, "If you want access to the value of that data, you use our ad server
[00:48:45.080 --> 00:48:47.680]   and you get access, but we don't give you the data."
[00:48:47.680 --> 00:48:48.880]   That's the way this operates.
[00:48:48.880 --> 00:48:51.600]   So yes, there's access to the data into that extent.
[00:48:51.600 --> 00:48:54.720]   And yes, you can target things and you can do things.
[00:48:54.720 --> 00:48:59.800]   Where the data is residing, this talk becomes very naive at that point.
[00:48:59.800 --> 00:49:05.160]   So we're also talking about an entity that's much, much larger and has oceans more data
[00:49:05.160 --> 00:49:07.520]   than any media entity that's ever existed.
[00:49:07.520 --> 00:49:08.520]   And I was like, "Yeah, paper."
[00:49:08.520 --> 00:49:12.120]   Your companies are too damn stupid to have done this on their own.
[00:49:12.120 --> 00:49:13.120]   But are you saying...
[00:49:13.120 --> 00:49:14.120]   And we're saying...
[00:49:14.120 --> 00:49:15.120]   The company I know once this should have done this and didn't.
[00:49:15.120 --> 00:49:16.120]   But are you saying...
[00:49:16.120 --> 00:49:19.400]   Users are stupid for trusting that Facebook wouldn't do that?
[00:49:19.400 --> 00:49:22.200]   Are they dumb for not realizing, "Well, everybody does it.
[00:49:22.200 --> 00:49:23.200]   You're stupid."
[00:49:23.200 --> 00:49:26.000]   What's the what that they're doing that you're accusing them of doing here?
[00:49:26.000 --> 00:49:27.000]   Well, that's the question.
[00:49:27.000 --> 00:49:32.120]   If it's right and if it's nothing more than saying, "Hey, Amazon, these people are likely
[00:49:32.120 --> 00:49:35.720]   to want to be stupid enough to want your phone because of this fact and this fact and this
[00:49:35.720 --> 00:49:38.880]   fact, that's the nature of media advertising today."
[00:49:38.880 --> 00:49:39.880]   Absolutely.
[00:49:39.880 --> 00:49:40.880]   Period.
[00:49:40.880 --> 00:49:41.880]   Absolutely.
[00:49:41.880 --> 00:49:42.880]   So we don't...
[00:49:42.880 --> 00:49:43.880]   We're indicting...
[00:49:43.880 --> 00:49:45.520]   And there may be reason to indict Facebook.
[00:49:45.520 --> 00:49:46.960]   We're doing lots of stupid things.
[00:49:46.960 --> 00:49:48.400]   I'm not denying that.
[00:49:48.400 --> 00:49:51.040]   But let's not have the trial without the evidence.
[00:49:51.040 --> 00:49:52.040]   Right.
[00:49:52.040 --> 00:49:58.600]   And to be fair to Facebook, we should point out that the Pekinges app that was in this
[00:49:58.600 --> 00:50:06.680]   lawsuit that this data came from, the entire apps was designed to peek at people in Pekinges.
[00:50:06.680 --> 00:50:10.960]   And the way you've got that information is getting photos not just from you, but from
[00:50:10.960 --> 00:50:21.480]   your friends and Facebook cut them off saying, "You can't get photos not just of the people
[00:50:21.480 --> 00:50:25.760]   who are using the Pekinges app, but their friends and friends of friends."
[00:50:25.760 --> 00:50:30.000]   That's when Facebook very famously turned off that friends of friends feature.
[00:50:30.000 --> 00:50:32.560]   And that's a pretty reprehensible use of that data.
[00:50:32.560 --> 00:50:33.560]   Of that data.
[00:50:33.560 --> 00:50:39.600]   That is because all these things start with good intentions and good use and then bad
[00:50:39.600 --> 00:50:42.480]   people come along and figure out how to exploit it to deal.
[00:50:42.480 --> 00:50:47.680]   And the tech companies never saw enough what could have happened and then they got caught
[00:50:47.680 --> 00:50:49.160]   in arrears.
[00:50:49.160 --> 00:50:50.600]   That's the reality we've got to deal with now.
[00:50:50.600 --> 00:50:54.920]   So now you have to assume the worst more often than we did in the early days of the internet.
[00:50:54.920 --> 00:50:56.920]   We didn't do that.
[00:50:56.920 --> 00:50:57.920]   Right.
[00:50:57.920 --> 00:51:00.920]   All right.
[00:51:00.920 --> 00:51:04.720]   I think that we have to hold off...
[00:51:04.720 --> 00:51:05.720]   We've got to wait for evidence.
[00:51:05.720 --> 00:51:06.720]   Until there's...
[00:51:06.720 --> 00:51:07.720]   And the evidence could be bad.
[00:51:07.720 --> 00:51:09.360]   More than just a characterization of the evidence.
[00:51:09.360 --> 00:51:12.280]   But it's kind of like the bar report.
[00:51:12.280 --> 00:51:15.680]   We've got the four page letter.
[00:51:15.680 --> 00:51:17.640]   This is the four page letter.
[00:51:17.640 --> 00:51:19.800]   So he's going to have a press conference tomorrow at 930.
[00:51:19.800 --> 00:51:27.480]   The onion study is going to do a representative dance on it.
[00:51:27.480 --> 00:51:30.600]   There is of course, in these...
[00:51:30.600 --> 00:51:33.320]   There are email, there are reactions, there are discussions.
[00:51:33.320 --> 00:51:37.360]   But again, a lot of internal company discussions might propose that they do something that
[00:51:37.360 --> 00:51:42.880]   they never do for very good reason and that's not a smoking gun.
[00:51:42.880 --> 00:51:47.960]   I have read some really stupid memos in my day and written a few.
[00:51:47.960 --> 00:51:52.960]   We could do this.
[00:51:52.960 --> 00:51:53.960]   Here's some...
[00:51:53.960 --> 00:51:55.280]   There are a few quotes in here.
[00:51:55.280 --> 00:51:59.720]   In late November 2012, Zuckerberg sent a long email to Facebook's senior leadership team
[00:51:59.720 --> 00:52:04.040]   saying Facebook shouldn't charge developers for access to basic data feeds.
[00:52:04.040 --> 00:52:08.880]   He said that access to Facebook data should be contingent on the developers sharing all
[00:52:08.880 --> 00:52:14.440]   of the social content generated by their apps back to Facebook, something Zuckerberg called
[00:52:14.440 --> 00:52:18.360]   full reciprocity.
[00:52:18.360 --> 00:52:21.960]   The existing arrangement where developers weren't required to share their data back with Facebook
[00:52:21.960 --> 00:52:29.640]   might be "good for the world" but it's not "good for us," Zuckerberg wrote in the email.
[00:52:29.640 --> 00:52:33.920]   This is the kind of cynicism that worries me.
[00:52:33.920 --> 00:52:36.520]   It's the kind of bluntness that happens inside company.
[00:52:36.520 --> 00:52:37.520]   But you're right.
[00:52:37.520 --> 00:52:44.760]   I've been inside company meetings where executives kind of cackle about how can we get as much
[00:52:44.760 --> 00:52:47.560]   money out of subscribers and fool them into...
[00:52:47.560 --> 00:52:56.480]   I was around in my industry when the credit card subscription came in and there were meetings
[00:52:56.480 --> 00:53:00.080]   that I set in of trying to convince people who were dead and stopped reading the magazine
[00:53:00.080 --> 00:53:03.840]   to still charge them for it because they didn't know how to cancel it.
[00:53:03.840 --> 00:53:05.480]   Companies do bad stuff.
[00:53:05.480 --> 00:53:06.480]   Yeah.
[00:53:06.480 --> 00:53:09.520]   Or, and may even talk about bad stuff in their emails.
[00:53:09.520 --> 00:53:13.280]   And they talk about bad stuff and they cackle about bad stuff.
[00:53:13.280 --> 00:53:14.280]   Right.
[00:53:14.280 --> 00:53:15.280]   Right.
[00:53:15.280 --> 00:53:20.640]   It doesn't make them bad or good yet.
[00:53:20.640 --> 00:53:22.200]   Yet.
[00:53:22.200 --> 00:53:29.880]   I have to say, I was really disheartened day before yesterday.
[00:53:29.880 --> 00:53:31.520]   I'm at home and it's a day off.
[00:53:31.520 --> 00:53:33.360]   Lisa texts me.
[00:53:33.360 --> 00:53:38.920]   Notre Dame is burning and it's a terrorist attack.
[00:53:38.920 --> 00:53:40.560]   And of course it isn't.
[00:53:40.560 --> 00:53:41.560]   It wasn't.
[00:53:41.560 --> 00:53:45.080]   It looks like it was arson, whether it's not arson, but accidental whether it was arson
[00:53:45.080 --> 00:53:46.600]   intentional or accidental fire.
[00:53:46.600 --> 00:53:47.600]   They're not sure still.
[00:53:47.600 --> 00:53:48.600]   But not.
[00:53:48.600 --> 00:53:49.880]   Nobody is asserting it was a terrorist attack.
[00:53:49.880 --> 00:53:50.880]   Except...
[00:53:50.880 --> 00:53:51.880]   YouTube.
[00:53:51.880 --> 00:53:55.600]   Where they likened it to 9/11.
[00:53:55.600 --> 00:54:00.320]   They even showed a fact checking article from Wikipedia about 9/11.
[00:54:00.320 --> 00:54:02.280]   They initially, apparently they're automated.
[00:54:02.280 --> 00:54:04.760]   And this is all automated stuff, I'm sure.
[00:54:04.760 --> 00:54:07.160]   Because no sane human would have done this.
[00:54:07.160 --> 00:54:12.800]   They're automated stuff flagged it as potentially fake news.
[00:54:12.800 --> 00:54:16.760]   And they wanted to, and they put their fact checking information up under it.
[00:54:16.760 --> 00:54:21.080]   But this really does kind of underscore why algorithms have a problem.
[00:54:21.080 --> 00:54:22.440]   You know what Leo?
[00:54:22.440 --> 00:54:23.440]   You know what Leo?
[00:54:23.440 --> 00:54:29.320]   I had before that happened and before that came out, I saw many people on Twitter say,
[00:54:29.320 --> 00:54:31.440]   "Oh my God, this reminds me of 9/11."
[00:54:31.440 --> 00:54:32.440]   And it sure did.
[00:54:32.440 --> 00:54:35.800]   When you saw the steeplefall, it looked so much like 9/11.
[00:54:35.800 --> 00:54:41.560]   And so I get the criticism of YouTube in this case and it doesn't help them.
[00:54:41.560 --> 00:54:45.240]   But I also, they're mimicking human behavior.
[00:54:45.240 --> 00:54:46.240]   Yeah.
[00:54:46.240 --> 00:54:47.240]   Great.
[00:54:47.240 --> 00:54:49.240]   I would actually hope for better.
[00:54:49.240 --> 00:54:52.760]   Yeah, that's part of the problem.
[00:54:52.760 --> 00:54:56.600]   Both Lisa and I were very saddened by the thought that somebody could have done this
[00:54:56.600 --> 00:54:58.040]   on purpose as it turned out.
[00:54:58.040 --> 00:55:00.720]   Of course, it wasn't the case.
[00:55:00.720 --> 00:55:01.720]   And it was the...
[00:55:01.720 --> 00:55:06.600]   My favorite story in all of this, which was a, I think, Atlantic story.
[00:55:06.600 --> 00:55:12.640]   The guy who died not long ago, who was an architecture expert.
[00:55:12.640 --> 00:55:15.000]   And he took a detailed laser.
[00:55:15.000 --> 00:55:16.000]   I saw that.
[00:55:16.000 --> 00:55:17.000]   The entire structure.
[00:55:17.000 --> 00:55:19.200]   The footwell helped with the reconstruction.
[00:55:19.200 --> 00:55:21.000]   There was a lovely story.
[00:55:21.000 --> 00:55:27.400]   They built detailed models for when they were doing Assassin's Creed as well.
[00:55:27.400 --> 00:55:29.400]   Oh, wow.
[00:55:29.400 --> 00:55:30.400]   Inside and out.
[00:55:30.400 --> 00:55:31.400]   Yeah.
[00:55:31.400 --> 00:55:35.920]   A YouTube spokesperson said those informational panels are triggered algorithmically.
[00:55:35.920 --> 00:55:38.160]   Our systems sometimes make the wrong call.
[00:55:38.160 --> 00:55:41.320]   We're disabling these panels for live streams related to the fire.
[00:55:41.320 --> 00:55:46.000]   YouTube correctly, this is the verge writing, and quickly identified the Notre Dame fire
[00:55:46.000 --> 00:55:47.920]   as a breaking news event.
[00:55:47.920 --> 00:55:52.320]   Surfaced trusted news outlets near the top of the search results.
[00:55:52.320 --> 00:55:56.840]   So that part of the algorithm, in fact, worked as intended.
[00:55:56.840 --> 00:55:59.040]   Really just getting better at this stuff.
[00:55:59.040 --> 00:56:00.040]   Yeah.
[00:56:00.040 --> 00:56:04.160]   It's not an indictment of YouTube, but it is an indictment of algorithmic.
[00:56:04.160 --> 00:56:09.840]   And that's why every time Mark Zuckerberg says, "Ai's going to solve this problem."
[00:56:09.840 --> 00:56:10.840]   Yeah.
[00:56:10.840 --> 00:56:11.840]   I just...
[00:56:11.840 --> 00:56:12.840]   Yeah.
[00:56:12.840 --> 00:56:15.840]   It's not going to happen.
[00:56:15.840 --> 00:56:18.040]   You're going to Google I/O, right, Jeff?
[00:56:18.040 --> 00:56:19.040]   Yep.
[00:56:19.040 --> 00:56:24.480]   So I'm thinking that's Tuesday is the keynote.
[00:56:24.480 --> 00:56:30.720]   So I'll take some medication to get me over the bridge to come up Wednesday.
[00:56:30.720 --> 00:56:34.320]   I got a bottle of whiskey I'll have for you.
[00:56:34.320 --> 00:56:36.800]   Jeff is not driving, so it's okay.
[00:56:36.800 --> 00:56:38.640]   No, I'll be driving.
[00:56:38.640 --> 00:56:39.640]   That's the problem.
[00:56:39.640 --> 00:56:40.640]   Oh, you're going to drive?
[00:56:40.640 --> 00:56:41.640]   Oh.
[00:56:41.640 --> 00:56:42.640]   Well, how else do I get up there?
[00:56:42.640 --> 00:56:43.640]   Well, I think we could...
[00:56:43.640 --> 00:56:44.640]   Jeff would gladly pay for an Uber.
[00:56:44.640 --> 00:56:45.640]   I said you're a doctor.
[00:56:45.640 --> 00:56:47.560]   No, we'll gladly pay for a car for you.
[00:56:47.560 --> 00:56:49.200]   Well, that's a long way.
[00:56:49.200 --> 00:56:50.200]   Well, it's all right.
[00:56:50.200 --> 00:56:51.200]   It's worth it.
[00:56:51.200 --> 00:56:52.200]   Oh, doctor.
[00:56:52.200 --> 00:56:53.200]   Jason Howell will be going.
[00:56:53.200 --> 00:56:57.920]   I think Florence Ion, both from all about Android.
[00:56:57.920 --> 00:57:00.920]   And Jeff, we will be covering the...
[00:57:00.920 --> 00:57:05.040]   It's going to be a tough week, a big week, because build the Microsoft Developer's Conferences
[00:57:05.040 --> 00:57:07.360]   at the same time again this year.
[00:57:07.360 --> 00:57:08.360]   So Monday will...
[00:57:08.360 --> 00:57:09.360]   Oh, she...
[00:57:09.360 --> 00:57:10.360]   Google Microsoft.
[00:57:10.360 --> 00:57:11.360]   Google Microsoft.
[00:57:11.360 --> 00:57:12.360]   Well, we're going to do both of them.
[00:57:12.360 --> 00:57:14.080]   Because I'm fair.
[00:57:14.080 --> 00:57:20.880]   So Monday will be doing the Microsoft keynote with full knowledge that last year it was so
[00:57:20.880 --> 00:57:24.680]   long they had to have a stretch break in the middle, three and a half hours.
[00:57:24.680 --> 00:57:27.680]   What do they announce that was so...
[00:57:27.680 --> 00:57:28.680]   Nothing.
[00:57:28.680 --> 00:57:29.680]   Nothing.
[00:57:29.680 --> 00:57:34.640]   In fact, you know, to be honest, I seriously considered not covering it, then I thought,
[00:57:34.640 --> 00:57:38.360]   "Well, we're going to do Google's Developer event the next day.
[00:57:38.360 --> 00:57:40.000]   Apple's the next month.
[00:57:40.000 --> 00:57:41.000]   We really have to."
[00:57:41.000 --> 00:57:43.120]   Well, you don't cover F8.
[00:57:43.120 --> 00:57:46.720]   No, I refuse.
[00:57:46.720 --> 00:57:52.160]   We had a couple of times we ran the F8 stuff and it was so horrible that we decided never
[00:57:52.160 --> 00:57:53.160]   to do it again.
[00:57:53.160 --> 00:57:56.600]   And we have not missed anything newsworthy since, I might add.
[00:57:56.600 --> 00:57:57.840]   I was going to go to F8.
[00:57:57.840 --> 00:58:01.960]   I just decided I got too much work at home, so I might go this year.
[00:58:01.960 --> 00:58:05.400]   But we will do the Google keynote.
[00:58:05.400 --> 00:58:06.400]   Right.
[00:58:06.400 --> 00:58:11.160]   First, I'm sorry, the Microsoft keynote at Build, all however many hours.
[00:58:11.160 --> 00:58:14.800]   Then it'll be a special edition of Windows Weekly following that.
[00:58:14.800 --> 00:58:22.640]   The next day we'll do the Google I/O event followed by, I guess, depending on how long
[00:58:22.640 --> 00:58:25.000]   Google at least is a little disciplined with their keynotes.
[00:58:25.000 --> 00:58:26.560]   Oh, they are.
[00:58:26.560 --> 00:58:27.880]   They used to do two days.
[00:58:27.880 --> 00:58:31.760]   That was a tough one for us, but they've got it down to, I think, just a couple hours
[00:58:31.760 --> 00:58:32.760]   now.
[00:58:32.760 --> 00:58:33.760]   So we'll then do...
[00:58:33.760 --> 00:58:35.720]   So are Jason and I going to do something from the scene?
[00:58:35.720 --> 00:58:36.720]   No, I don't think so.
[00:58:36.720 --> 00:58:37.720]   That's too hard.
[00:58:37.720 --> 00:58:41.720]   We'll let you guys enjoy, go look at stuff.
[00:58:41.720 --> 00:58:42.720]   Obseroir.
[00:58:42.720 --> 00:58:43.720]   Obseroir.
[00:58:43.720 --> 00:58:47.000]   Maybe you pick up your new Pixel phone if such a thing.
[00:58:47.000 --> 00:58:48.000]   Yeah.
[00:58:48.000 --> 00:58:49.520]   Well, look at this.
[00:58:49.520 --> 00:58:51.360]   Google teases new Pixel and that's good.
[00:58:51.360 --> 00:58:52.960]   I think it was the cheap one.
[00:58:52.960 --> 00:58:53.960]   No.
[00:58:53.960 --> 00:58:55.960]   Well, why not?
[00:58:55.960 --> 00:59:01.120]   The 3A and 3A XL are set for announcement that day, May 7th.
[00:59:01.120 --> 00:59:03.760]   We've seen a lot of details.
[00:59:03.760 --> 00:59:12.640]   The Google stores page says, "Help is on the way," which is, by the way, the tagline
[00:59:12.640 --> 00:59:15.080]   also for the Avengers Endgame.
[00:59:15.080 --> 00:59:20.840]   Apparently, hotly awaited movie about comic book heroes.
[00:59:20.840 --> 00:59:23.440]   This is the Google store image.
[00:59:23.440 --> 00:59:25.200]   Help is on the way on May 7th.
[00:59:25.200 --> 00:59:28.280]   Something big is coming to the Pixel universe.
[00:59:28.280 --> 00:59:30.120]   So I don't know.
[00:59:30.120 --> 00:59:31.120]   Maybe you...
[00:59:31.120 --> 00:59:34.280]   You've seen us that it's not the 3A, that it's something else in the Pixel world.
[00:59:34.280 --> 00:59:35.280]   Absolutely.
[00:59:35.280 --> 00:59:41.240]   For instance, they already have Avengers in the augmented reality thing in the camera.
[00:59:41.240 --> 00:59:44.680]   I could just be some special Endgame content.
[00:59:44.680 --> 00:59:46.080]   Could be a watch.
[00:59:46.080 --> 00:59:47.520]   It could be a new Pixel book.
[00:59:47.520 --> 00:59:52.720]   There have been rumors that both new watches and a return to the Google Pixel book could
[00:59:52.720 --> 00:59:53.720]   be.
[00:59:53.720 --> 00:59:54.720]   I'm dying for it.
[00:59:54.720 --> 00:59:55.720]   Mine's getting a little on it.
[00:59:55.720 --> 00:59:56.720]   That would be nice.
[00:59:56.720 --> 00:59:57.720]   Yeah.
[00:59:57.720 --> 01:00:00.200]   And I don't think the slate is really worth getting.
[01:00:00.200 --> 01:00:02.200]   So anyway...
[01:00:02.200 --> 01:00:05.680]   Kevin Truffle's happy with his, but...
[01:00:05.680 --> 01:00:08.280]   Yeah, he loves it.
[01:00:08.280 --> 01:00:09.280]   Yeah.
[01:00:09.280 --> 01:00:11.440]   So we will be covering that event.
[01:00:11.440 --> 01:00:15.000]   And then the next day, you're going to come up across the bridge.
[01:00:15.000 --> 01:00:19.760]   I have scattered cupcakes to lure attractive men.
[01:00:19.760 --> 01:00:22.880]   Yeah, mine'll be stale by them.
[01:00:22.880 --> 01:00:28.240]   I want some cute boys to come pick up cupcakes.
[01:00:28.240 --> 01:00:31.680]   So we get what will be a special in studio version of this week in Google.
[01:00:31.680 --> 01:00:37.600]   That'll be May 8th, a few weeks from now.
[01:00:37.600 --> 01:00:42.640]   By the way, speaking of YouTube, I don't know what to make of this Bloomberg article.
[01:00:42.640 --> 01:00:47.680]   I don't even understand what the metric would be, but according to Mark Bergen and Lucas
[01:00:47.680 --> 01:00:52.600]   Shaw writing in Bloomberg, to answer critics, YouTube tries a new metric.
[01:00:52.600 --> 01:00:53.600]   Responsibility.
[01:00:53.600 --> 01:00:56.720]   Yeah, I don't even know what that means.
[01:00:56.720 --> 01:01:00.160]   Bloomberg does not make it clear in any way.
[01:01:00.160 --> 01:01:04.880]   So of course, the traditional reward is views and subscriptions, right?
[01:01:04.880 --> 01:01:07.440]   Well, they also use quality watch time.
[01:01:07.440 --> 01:01:09.240]   Yeah, this is new.
[01:01:09.240 --> 01:01:13.160]   So the Google division introduced two new internal metrics in the past two years for
[01:01:13.160 --> 01:01:18.520]   gauging how well videos are performing according to people familiar with the company's plans.
[01:01:18.520 --> 01:01:21.520]   One tracks the total time people spend on YouTube.
[01:01:21.520 --> 01:01:26.160]   That includes not only watching video, but posting comments and reading comments.
[01:01:26.160 --> 01:01:29.800]   The other is called, and this is the one you were talking about, Matthew, quality watch
[01:01:29.800 --> 01:01:37.400]   time, a squish year's statistic writes Bloomberg with a noble goal to spot content that achieves
[01:01:37.400 --> 01:01:41.600]   something more constructive than just keeping users glued to their phones.
[01:01:41.600 --> 01:01:43.920]   Well, but I don't know what that would be.
[01:01:43.920 --> 01:01:46.080]   And it's not clear how they're coming up with it.
[01:01:46.080 --> 01:01:47.760]   Are they just surveying users?
[01:01:47.760 --> 01:01:50.160]   Did you think this was a quality experience?
[01:01:50.160 --> 01:01:52.440]   Are they testing it with human beings?
[01:01:52.440 --> 01:01:55.600]   Do you think this was a quality suggestion?
[01:01:55.600 --> 01:01:57.360]   It's unclear how they even come up with it.
[01:01:57.360 --> 01:01:59.800]   I mean, it sounds great.
[01:01:59.800 --> 01:02:03.880]   YouTube declined to comment on the new metrics, but a spokeswoman said, there are many metrics
[01:02:03.880 --> 01:02:06.040]   we use to measure success.
[01:02:06.040 --> 01:02:13.800]   They do both platforms do a lot of that of asking people after something.
[01:02:13.800 --> 01:02:15.520]   So I think that's a little likely.
[01:02:15.520 --> 01:02:17.200]   It's such a vague criteria.
[01:02:17.200 --> 01:02:18.200]   Yeah.
[01:02:18.200 --> 01:02:20.200]   Well, it's it's it's hard.
[01:02:20.200 --> 01:02:24.800]   So this is a discussion I had in perusion, but I didn't have any gelato when I was there.
[01:02:24.800 --> 01:02:25.800]   I did have a brush.
[01:02:25.800 --> 01:02:28.200]   I should have.
[01:02:28.200 --> 01:02:29.200]   I should have.
[01:02:29.200 --> 01:02:31.600]   I had no gelato in perusion.
[01:02:31.600 --> 01:02:38.440]   But so so I had this conversation with one of the platform executives a few weeks ago,
[01:02:38.440 --> 01:02:41.840]   where I said, you know, we keep on going to you guys and saying, clean up the content
[01:02:41.840 --> 01:02:42.840]   world.
[01:02:42.840 --> 01:02:44.240]   We won't clean it up ourselves.
[01:02:44.240 --> 01:02:45.240]   Right?
[01:02:45.240 --> 01:02:49.240]   There's a big standards effort in journalism and who's in the room.
[01:02:49.240 --> 01:02:52.320]   RT, European broadcasters union, who's on stage?
[01:02:52.320 --> 01:02:54.400]   RT digital content.
[01:02:54.400 --> 01:02:55.920]   Next, who's a member?
[01:02:55.920 --> 01:02:57.400]   Fox News.
[01:02:57.400 --> 01:03:03.600]   And and forgetting trying to smash Fox News because they do good things and bad things.
[01:03:03.600 --> 01:03:04.760]   So does the New York Times.
[01:03:04.760 --> 01:03:06.520]   So does every organization.
[01:03:06.520 --> 01:03:09.680]   We don't criticize our own field.
[01:03:09.680 --> 01:03:12.920]   We don't hold ourselves to account in our own field anyway.
[01:03:12.920 --> 01:03:15.640]   And we and we're expecting the platforms to know best.
[01:03:15.640 --> 01:03:17.200]   They don't know what quality is.
[01:03:17.200 --> 01:03:18.200]   They don't know what journalism is.
[01:03:18.200 --> 01:03:19.200]   They have no idea.
[01:03:19.200 --> 01:03:20.840]   But we will do it ourselves.
[01:03:20.840 --> 01:03:26.960]   You know, and I'm starting to think that it's time for the anti Pulitzer.
[01:03:26.960 --> 01:03:32.760]   By the way, congratulations to the Pulitzer Pulitzer's.
[01:03:32.760 --> 01:03:37.200]   Some really good work done in the Pulitzer's rewarded yesterday.
[01:03:37.200 --> 01:03:40.400]   I did not get one.
[01:03:40.400 --> 01:03:41.400]   You did not.
[01:03:41.400 --> 01:03:42.400]   Oh, yeah.
[01:03:42.400 --> 01:03:43.400]   South Florida, South Sentinel.
[01:03:43.400 --> 01:03:44.400]   Another year.
[01:03:44.400 --> 01:03:48.680]   Got one for their coverage of the Marjorie Stoneman Douglas High School shooting.
[01:03:48.680 --> 01:03:52.400]   Pittsburgh Post Gazette.
[01:03:52.400 --> 01:03:53.840]   We know what happened in Pittsburgh.
[01:03:53.840 --> 01:03:59.640]   It's a shame that seems like the best way to get a Pulitzer is to cover a mass shooting.
[01:03:59.640 --> 01:04:00.640]   Yeah.
[01:04:00.640 --> 01:04:06.840]   University of Southern California gynecologist George Tindall, who sexually abused hundreds
[01:04:06.840 --> 01:04:10.920]   of students at the campus clinic, the coverage in the LA Times of that.
[01:04:10.920 --> 01:04:12.680]   That definitely deserved an award.
[01:04:12.680 --> 01:04:18.120]   I really liked the New York Times investigation of Trump's finances.
[01:04:18.120 --> 01:04:20.520]   That was a really great piece that the Times.
[01:04:20.520 --> 01:04:22.080]   I worked with Suzanne Craig.
[01:04:22.080 --> 01:04:23.080]   Did you?
[01:04:23.080 --> 01:04:24.080]   At the Globe and Mail, yeah.
[01:04:24.080 --> 01:04:25.080]   Nice.
[01:04:25.080 --> 01:04:27.880]   David Barstow, Suzanne Craig, and Russ Buttoner, Butner.
[01:04:27.880 --> 01:04:30.080]   18 months.
[01:04:30.080 --> 01:04:34.720]   This is why journalism is expensive and hard to do well.
[01:04:34.720 --> 01:04:38.760]   And I don't think the Pulitzer pays you back, but I'm sure the Times is glad to celebrate.
[01:04:38.760 --> 01:04:42.120]   18 months, they worked on that.
[01:04:42.120 --> 01:04:44.080]   So.
[01:04:44.080 --> 01:04:48.840]   It's for fun. I looked into how you're supposed to pronounce it.
[01:04:48.840 --> 01:04:49.840]   Pulitzer.
[01:04:49.840 --> 01:04:50.840]   Pulitzer.
[01:04:50.840 --> 01:04:51.840]   Yeah.
[01:04:51.840 --> 01:04:52.840]   Lots of people say Pulitzer.
[01:04:52.840 --> 01:04:53.840]   Yeah.
[01:04:53.840 --> 01:04:54.840]   It's not Pew.
[01:04:54.840 --> 01:04:55.840]   The Pulitzer's never liked it when people said Pulitzer.
[01:04:55.840 --> 01:04:56.840]   Right.
[01:04:56.840 --> 01:04:59.320]   Is it is it ProPublica or?
[01:04:59.320 --> 01:05:00.320]   Good question.
[01:05:00.320 --> 01:05:01.320]   That I don't know.
[01:05:01.320 --> 01:05:03.400]   I that's a good I say ProPublica.
[01:05:03.400 --> 01:05:04.400]   Yeah.
[01:05:04.400 --> 01:05:05.400]   Yeah.
[01:05:05.400 --> 01:05:06.400]   Publica who says Publica.
[01:05:06.400 --> 01:05:07.400]   Publica.
[01:05:07.400 --> 01:05:08.400]   How about Publica?
[01:05:08.400 --> 01:05:09.400]   Definitely.
[01:05:09.400 --> 01:05:16.400]   Definitely wrong.
[01:05:16.400 --> 01:05:21.640]   And we're Pulitzer's Pulitzer.
[01:05:21.640 --> 01:05:22.640]   Pulitzer.
[01:05:22.640 --> 01:05:24.400]   Because Lily, Pulitzer, Puts.
[01:05:24.400 --> 01:05:25.400]   Puts.
[01:05:25.400 --> 01:05:27.240]   It's more like Paul, I think.
[01:05:27.240 --> 01:05:29.240]   Pulitzer Pulitzer Pulitzer.
[01:05:29.240 --> 01:05:30.240]   Pulitzer.
[01:05:30.240 --> 01:05:31.240]   Publica.
[01:05:31.240 --> 01:05:32.240]   That's maybe a matter of accident.
[01:05:32.240 --> 01:05:33.240]   Yeah.
[01:05:33.240 --> 01:05:34.240]   For Boston.
[01:05:34.240 --> 01:05:35.640]   If I ever get one, I'll know how to pronounce it.
[01:05:35.640 --> 01:05:37.680]   Yeah, you'll learn.
[01:05:37.680 --> 01:05:40.760]   Let's pronounce the Nobel Prize.
[01:05:40.760 --> 01:05:45.840]   Actually, I was looking at the YouTube metrics.
[01:05:45.840 --> 01:05:47.160]   They do have a lot of signals.
[01:05:47.160 --> 01:05:50.600]   Of course, they have the like buttons and they have the, you know, they have a lot, but
[01:05:50.600 --> 01:05:52.160]   they do do surveys as well.
[01:05:52.160 --> 01:05:53.160]   They do.
[01:05:53.160 --> 01:05:54.160]   They do.
[01:05:54.160 --> 01:05:55.160]   Yeah.
[01:05:55.160 --> 01:06:03.760]   Well, as long as we're talking about Facebook, we kind of mentioned this piece in Wired.
[01:06:03.760 --> 01:06:09.040]   Scandals, backstabbing, resignations, reboots, record profits and time bombs.
[01:06:09.040 --> 01:06:10.040]   Mm-hmm.
[01:06:10.040 --> 01:06:11.040]   15 months of--
[01:06:11.040 --> 01:06:12.040]   I didn't get through it all yet.
[01:06:12.040 --> 01:06:13.040]   No, it's very long.
[01:06:13.040 --> 01:06:18.560]   It's as long as the 15 months of fresh, shell inside Facebook.
[01:06:18.560 --> 01:06:19.560]   It is a good piece.
[01:06:19.560 --> 01:06:23.400]   Nicholas Thompson and Fred Vogelstein writing in the business section of Wired.
[01:06:23.400 --> 01:06:27.520]   I was there really interesting reportage in Davos last year.
[01:06:27.520 --> 01:06:28.520]   Oh, yeah.
[01:06:28.520 --> 01:06:33.280]   I was at an event where he cornered Cheryl for quite a long time.
[01:06:33.280 --> 01:06:34.280]   Interesting.
[01:06:34.280 --> 01:06:40.800]   It is kind of interesting how, think about how Wired was covering Facebook and Google,
[01:06:40.800 --> 01:06:45.200]   not that long ago, you know, a few years ago, maybe.
[01:06:45.200 --> 01:06:47.200]   It's been quite a turnaround.
[01:06:47.200 --> 01:06:50.400]   No, but Nick's been, Nick has been reasonable.
[01:06:50.400 --> 01:06:52.400]   Yeah, no, I'm not talking about Nick.
[01:06:52.400 --> 01:06:53.400]   He means, yeah.
[01:06:53.400 --> 01:06:54.400]   That's cool.
[01:06:54.400 --> 01:06:55.400]   Right.
[01:06:55.400 --> 01:06:56.400]   I mean, he's been--
[01:06:56.400 --> 01:06:57.400]   He's been a good streak quality.
[01:06:57.400 --> 01:07:01.920]   Well, I have to say though, I'm going to reiterate something I started to kind of say earlier,
[01:07:01.920 --> 01:07:06.680]   which is if you'd want to defend the internet, you need to also not only defend it against
[01:07:06.680 --> 01:07:10.240]   moral panic and bad governments, but you need to also defend it against bad actors on
[01:07:10.240 --> 01:07:11.240]   the internet.
[01:07:11.240 --> 01:07:12.240]   Yeah.
[01:07:12.240 --> 01:07:14.560]   They do more damage than anybody.
[01:07:14.560 --> 01:07:19.280]   And I would argue that Mark Zuckerberg's primary motivating goal is to become the internet.
[01:07:19.280 --> 01:07:20.280]   Yeah.
[01:07:20.280 --> 01:07:25.560]   And in some countries like Myanmar and Cambodia and the Philippines, Facebook is the internet.
[01:07:25.560 --> 01:07:29.000]   And that's not good, I would argue.
[01:07:29.000 --> 01:07:32.160]   And countries like China, the government is the internet.
[01:07:32.160 --> 01:07:33.240]   Yeah, also not good.
[01:07:33.240 --> 01:07:37.320]   It's not hard to hear the choice, you might say.
[01:07:37.320 --> 01:07:39.600]   Yes, literally.
[01:07:39.600 --> 01:07:42.880]   So why won't be part of the internet resistance?
[01:07:42.880 --> 01:07:45.280]   I can't even scroll through the whole article, let alone read it.
[01:07:45.280 --> 01:07:47.520]   I want to be part of the planetary internet.
[01:07:47.520 --> 01:07:48.520]   Wherever John--
[01:07:48.520 --> 01:07:52.560]   Wherever John will live on Google Island, let's be honest.
[01:07:52.560 --> 01:07:56.200]   Wherever John Perry Barlow is, that's where I want to be.
[01:07:56.200 --> 01:07:57.200]   Yeah.
[01:07:57.200 --> 01:07:58.560]   It's good music, that's for sure.
[01:07:58.560 --> 01:07:59.560]   Yeah.
[01:07:59.560 --> 01:08:03.440]   There was some interesting stuff in that piece though, the wired one.
[01:08:03.440 --> 01:08:04.440]   In particular--
[01:08:04.440 --> 01:08:06.480]   It wasn't a rehash of everything we already know.
[01:08:06.480 --> 01:08:10.000]   Well, there was some, but there was more detail about different things.
[01:08:10.000 --> 01:08:15.160]   So there was a lot more detail about why the guys at Instagram left.
[01:08:15.160 --> 01:08:19.160]   There was-- and we've read a little bit about that, but there was more detail about kind
[01:08:19.160 --> 01:08:21.120]   of how things worked out.
[01:08:21.120 --> 01:08:28.160]   Basically, from the sounds of it, Mark decided to-- that Instagram was effectively
[01:08:28.160 --> 01:08:29.680]   competing with Facebook.
[01:08:29.680 --> 01:08:36.720]   And so he removed a lot of the growth drivers and connections that were helping Instagram.
[01:08:36.720 --> 01:08:42.240]   And then he introduced things that the Instagram guys had always resisted, like hamburger menus
[01:08:42.240 --> 01:08:44.600]   and stuff like that.
[01:08:44.600 --> 01:08:48.560]   Did they imply that he put in hamburger menus to reduce the growth?
[01:08:48.560 --> 01:08:52.320]   Because that would be an interesting use of hamburger menus.
[01:08:52.320 --> 01:08:57.800]   No, they did imply though they suggested that Kevin's system thought some of these changes
[01:08:57.800 --> 01:09:00.040]   were made deliberately to try and believe--
[01:09:00.040 --> 01:09:01.040]   Oh.
[01:09:01.040 --> 01:09:03.280]   --just to get him mad so that he would quit.
[01:09:03.280 --> 01:09:08.840]   But you can't fault Mark for looking at the overall health of the company instead of just
[01:09:08.840 --> 01:09:09.840]   one division.
[01:09:09.840 --> 01:09:10.840]   Of course not.
[01:09:10.840 --> 01:09:11.840]   That's kind of his job.
[01:09:11.840 --> 01:09:15.160]   And it's very similar to what happened with the WhatsApp guys.
[01:09:15.160 --> 01:09:16.160]   Right.
[01:09:16.160 --> 01:09:17.160]   They almost did that.
[01:09:17.160 --> 01:09:18.160]   Great.
[01:09:18.160 --> 01:09:19.160]   Yeah.
[01:09:19.160 --> 01:09:21.560]   Facebook said, look, we're going to do a bunch of stuff.
[01:09:21.560 --> 01:09:24.480]   And I know we said we weren't going to do that, but now we are.
[01:09:24.480 --> 01:09:25.480]   Right.
[01:09:25.480 --> 01:09:26.480]   So long.
[01:09:26.480 --> 01:09:27.480]   Mark's a brick spill.
[01:09:27.480 --> 01:09:28.480]   Mark's a brick spill.
[01:09:28.480 --> 01:09:30.480]   Mark's a very famous leaf for years.
[01:09:30.480 --> 01:09:32.800]   Does it still say I'm CEO, bitch?
[01:09:32.800 --> 01:09:33.800]   No.
[01:09:33.800 --> 01:09:34.800]   He got rid of it.
[01:09:34.800 --> 01:09:35.800]   Oh.
[01:09:35.800 --> 01:09:36.800]   Yeah.
[01:09:36.800 --> 01:09:37.800]   Somebody suggested in the chatroom his card should read.
[01:09:37.800 --> 01:09:40.840]   I'm the internet now, bitch.
[01:09:40.840 --> 01:09:43.240]   Those cards are in a locker along with his flip-flops.
[01:09:43.240 --> 01:09:44.240]   Yeah.
[01:09:44.240 --> 01:09:45.240]   And his hoodies.
[01:09:45.240 --> 01:09:46.240]   No.
[01:09:46.240 --> 01:09:47.240]   Mm-hmm.
[01:09:47.240 --> 01:09:48.640]   Should I play the--
[01:09:48.640 --> 01:09:49.640]   What?
[01:09:49.640 --> 01:09:50.640]   The movie?
[01:09:50.640 --> 01:09:53.240]   The current sweatshirt interview?
[01:09:53.240 --> 01:09:54.240]   No.
[01:09:54.240 --> 01:09:55.240]   This is--
[01:09:55.240 --> 01:09:56.240]   This is--
[01:09:56.240 --> 01:09:57.240]   Hey, everyone.
[01:09:57.240 --> 01:10:00.360]   This is a song we are live from my backyard.
[01:10:00.360 --> 01:10:01.960]   Song of why this.
[01:10:01.960 --> 01:10:03.880]   [MUSIC PLAYING]
[01:10:03.880 --> 01:10:24.520]   This song is from the live stream.
[01:10:24.520 --> 01:10:28.240]   It's from his backyard when Saturday afternoon.
[01:10:28.240 --> 01:10:30.360]   Molly was smoking meat.
[01:10:30.360 --> 01:10:35.480]   Totally realistic looking backyard, right?
[01:10:35.480 --> 01:10:37.120]   I think it's a set.
[01:10:37.120 --> 01:10:38.120]   I think it's a set.
[01:10:38.120 --> 01:10:39.120]   Totally a set.
[01:10:39.120 --> 01:10:40.120]   Totally a set.
[01:10:40.120 --> 01:10:41.640]   There's the extra coming in.
[01:10:41.640 --> 01:10:46.320]   Someone's going to push the fence over the boom mic.
[01:10:46.320 --> 01:10:49.960]   I think they did this song off by this case.
[01:10:49.960 --> 01:10:50.960]   Oh, no.
[01:10:50.960 --> 01:10:52.880]   My face was someone--
[01:10:52.880 --> 01:10:53.880]   I am a human being.
[01:10:53.880 --> 01:10:54.880]   Enjoy.
[01:10:54.880 --> 01:10:55.880]   This is actually a good part.
[01:10:55.880 --> 01:10:56.880]   Show this part.
[01:10:56.880 --> 01:10:57.880]   This is pretty funny.
[01:10:57.880 --> 01:10:58.880]   Oh, no.
[01:10:58.880 --> 01:10:59.880]   It seems I was daydreaming again.
[01:10:59.880 --> 01:11:02.880]   That's why I made clear that you have had subpoenas.
[01:11:02.880 --> 01:11:04.720]   Is that correct?
[01:11:04.720 --> 01:11:12.520]   Mr. Zuckerberg, what is Facebook doing to prevent foreign actors from interfering in
[01:11:12.520 --> 01:11:13.520]   US elections?
[01:11:13.520 --> 01:11:17.120]   We are smoking meat, meat like a brisket.
[01:11:17.120 --> 01:11:18.720]   I'm making meat now.
[01:11:18.720 --> 01:11:19.720]   I'm sorry.
[01:11:19.720 --> 01:11:21.520]   There's no reason to play it.
[01:11:21.520 --> 01:11:22.520]   We're going to be delicious.
[01:11:22.520 --> 01:11:23.520]   Yeah, fuck me.
[01:11:23.520 --> 01:11:28.120]   That's a little time to go out.
[01:11:28.120 --> 01:11:29.960]   But I do enjoy it.
[01:11:29.960 --> 01:11:30.960]   I do enjoy it.
[01:11:30.960 --> 01:11:35.160]   It always seems like a sort of poorly programmed Android show.
[01:11:35.160 --> 01:11:38.120]   I'm frittin' out a little bit.
[01:11:38.120 --> 01:11:42.720]   The reason I thought of that is because in the song he says, "I'm wearing my weekend
[01:11:42.720 --> 01:11:44.600]   purple t-shirt.
[01:11:44.600 --> 01:11:46.440]   At work I wear my green t-."
[01:11:46.440 --> 01:11:48.080]   Oh.
[01:11:48.080 --> 01:11:50.000]   That's what made me think of it.
[01:11:50.000 --> 01:11:51.600]   I think that's old anyway.
[01:11:51.600 --> 01:11:52.680]   Sorry, I even brought it up.
[01:11:52.680 --> 01:11:55.280]   It has no news benefit whatsoever.
[01:11:55.280 --> 01:11:56.280]   Yeah, it's fine.
[01:11:56.280 --> 01:11:57.280]   Sorry.
[01:11:57.280 --> 01:11:58.280]   Yeah.
[01:11:58.280 --> 01:11:59.280]   You're not sorry.
[01:11:59.280 --> 01:12:00.280]   I'm not sorry.
[01:12:00.280 --> 01:12:01.440]   Sorry, not sorry.
[01:12:01.440 --> 01:12:03.280]   What else?
[01:12:03.280 --> 01:12:05.360]   Are we still talking about the word thing?
[01:12:05.360 --> 01:12:06.920]   Yeah, if you want.
[01:12:06.920 --> 01:12:10.280]   Well, the other thing that I thought was interesting, at least, I don't know if anybody
[01:12:10.280 --> 01:12:18.600]   else would be interested, was the sort of drama involving Chris Cox, who was at one time
[01:12:18.600 --> 01:12:21.800]   kind of Mark's right-hand man and effectively man.
[01:12:21.800 --> 01:12:22.800]   Fair hand point.
[01:12:22.800 --> 01:12:24.280]   Most of Facebook, yeah.
[01:12:24.280 --> 01:12:30.920]   And it sounded like there was a pretty significant falling out, in part, because of what Mark
[01:12:30.920 --> 01:12:34.880]   wanted to do with news.
[01:12:34.880 --> 01:12:36.520]   There's a bunch of stuff in there.
[01:12:36.520 --> 01:12:41.720]   And obviously it's a lot of it is hearsay, but it's interesting.
[01:12:41.720 --> 01:12:42.720]   Yeah.
[01:12:42.720 --> 01:12:43.720]   Because that was a pretty big departure.
[01:12:43.720 --> 01:12:46.080]   Yeah, it was a shock when he left.
[01:12:46.080 --> 01:12:47.080]   Mm-hmm.
[01:12:47.080 --> 01:12:51.680]   A lot of people thought he would take over at some point.
[01:12:51.680 --> 01:12:52.680]   Right.
[01:12:52.680 --> 01:12:57.280]   And actually Cox is one of the people who helped Mark get rid of Instagram's system
[01:12:57.280 --> 01:13:03.200]   and slow Instagrams go down south.
[01:13:03.200 --> 01:13:09.280]   The Wired article implies that it was a shift in the power.
[01:13:09.280 --> 01:13:13.640]   Some of the company's most senior executives, notably Chris Cox, thought Facebook needed
[01:13:13.640 --> 01:13:16.920]   to give serious publishers a leg up.
[01:13:16.920 --> 01:13:21.160]   Others pushed back, including Joel Kaplan, a former deputy chief of staff to George W.
[01:13:21.160 --> 01:13:22.160]   Bush.
[01:13:22.160 --> 01:13:23.160]   Facebook's good.
[01:13:23.160 --> 01:13:24.160]   That's the other interesting thing.
[01:13:24.160 --> 01:13:30.720]   So Kaplan's argument apparently was, if we introduce quality rankings, everyone will assume
[01:13:30.720 --> 01:13:31.960]   we're against conservatives.
[01:13:31.960 --> 01:13:36.480]   It says, "Supporting high quality outlets would inevitably make it look like the platform
[01:13:36.480 --> 01:13:38.520]   is supporting liberals."
[01:13:38.520 --> 01:13:40.320]   Which could lead to trouble in Washington and that town.
[01:13:40.320 --> 01:13:41.920]   The member was the guy who sat behind.
[01:13:41.920 --> 01:13:42.920]   He's behind conservatives.
[01:13:42.920 --> 01:13:44.920]   We're right behind Kavanaugh, yeah.
[01:13:44.920 --> 01:13:45.920]   It mentions that too.
[01:13:45.920 --> 01:13:47.800]   It's a reporting form.
[01:13:47.800 --> 01:13:53.240]   But apparently at the end of the climactic meeting on July 9th, Zuckerberg sided with
[01:13:53.240 --> 01:14:00.440]   Kaplan and he tabled the decision about boosting publishers effectively killing the plan to
[01:14:00.440 --> 01:14:01.800]   one person involved in the meeting.
[01:14:01.800 --> 01:14:04.440]   It seemed like a sign of shifting power.
[01:14:04.440 --> 01:14:05.440]   Cox had lost.
[01:14:05.440 --> 01:14:06.440]   Kaplan had won.
[01:14:06.440 --> 01:14:07.440]   And of course the other thing.
[01:14:07.440 --> 01:14:12.000]   The other thing was that news organizations lost big times.
[01:14:12.000 --> 01:14:16.280]   But the other thing they mentioned and I had forgotten about this part was that Chris Cox
[01:14:16.280 --> 01:14:23.960]   apparently was not a fan of the new move towards private encrypted ephemeral messaging.
[01:14:23.960 --> 01:14:26.880]   So he was resisting that.
[01:14:26.880 --> 01:14:28.080]   That was the story we had seen.
[01:14:28.080 --> 01:14:33.240]   Because it came right after Zuckerberg's manifesto about going to Christ in charge of
[01:14:33.240 --> 01:14:36.320]   the Facebook product and all that are represented.
[01:14:36.320 --> 01:14:38.360]   What is that leave?
[01:14:38.360 --> 01:14:40.600]   And by the way, I was all excited about that.
[01:14:40.600 --> 01:14:47.960]   Remember I even reactivated my Facebook account and it's absolutely nothing in that direction.
[01:14:47.960 --> 01:14:52.760]   I now see it as a ruse effectively and I have deactivated.
[01:14:52.760 --> 01:14:55.200]   In fact, deleted my Facebook account.
[01:14:55.200 --> 01:14:57.360]   But I did something the other day.
[01:14:57.360 --> 01:15:01.480]   Remember that when they said they were going to implement some switch where you could clear
[01:15:01.480 --> 01:15:04.960]   your and what was that like it was a year and a half ago?
[01:15:04.960 --> 01:15:07.800]   Tell me once shame on you.
[01:15:07.800 --> 01:15:10.160]   For me twice, I'm leaving Facebook.
[01:15:10.160 --> 01:15:11.600]   For me seven times.
[01:15:11.600 --> 01:15:14.760]   For me every single freaking day.
[01:15:14.760 --> 01:15:16.680]   So maybe I've been fooled again.
[01:15:16.680 --> 01:15:21.000]   Well, they said it was going to take a long time.
[01:15:21.000 --> 01:15:22.520]   Don't leave the.
[01:15:22.520 --> 01:15:24.520]   This is going to take a long time.
[01:15:24.520 --> 01:15:25.520]   We're working on it.
[01:15:25.520 --> 01:15:27.280]   I'll create a new account when we're working on it.
[01:15:27.280 --> 01:15:33.440]   But I did believe this blog post on the Twitter blog when they said we want to make people
[01:15:33.440 --> 01:15:37.840]   feel more safe on Twitter.
[01:15:37.840 --> 01:15:40.400]   Saying that they are going to be more proactive.
[01:15:40.400 --> 01:15:45.360]   In fact, taking action without reports, people who don't feel safe on Twitter shouldn't be
[01:15:45.360 --> 01:15:49.760]   burdened to report abuse to us.
[01:15:49.760 --> 01:15:51.960]   Previously we only reviewed potentially abusive tweets.
[01:15:51.960 --> 01:15:54.440]   If they were reported to us, we know that's not acceptable.
[01:15:54.440 --> 01:15:56.480]   Wow, that's a big change.
[01:15:56.480 --> 01:15:58.080]   So we are making a priority.
[01:15:58.080 --> 01:16:02.520]   We did that earlier this year to take a proactive approach to abuse in addition to relying on
[01:16:02.520 --> 01:16:03.520]   people's.
[01:16:03.520 --> 01:16:05.400]   But is that actually going to change that much?
[01:16:05.400 --> 01:16:10.320]   I mean, lots of the people who've complained about abuse when they flag a tweet.
[01:16:10.320 --> 01:16:13.960]   The response is almost always that doesn't breach our terms and conditions.
[01:16:13.960 --> 01:16:15.960]   Yeah, I saw a shocking one yesterday.
[01:16:15.960 --> 01:16:17.960]   Yeah, I'm some of them are horrible.
[01:16:17.960 --> 01:16:21.080]   And Twitter said, well, it doesn't doesn't violate it.
[01:16:21.080 --> 01:16:26.720]   I mean, that's the problem, not their ability to kind of do it in advance or wait for you
[01:16:26.720 --> 01:16:27.720]   to flag.
[01:16:27.720 --> 01:16:29.920]   It's the criteria they're using.
[01:16:29.920 --> 01:16:33.840]   They say this time last year, zero percent of potentially abusive content was flagged
[01:16:33.840 --> 01:16:34.840]   to our teams.
[01:16:34.840 --> 01:16:37.240]   I think that's too low a number.
[01:16:37.240 --> 01:16:42.600]   Today by using technology, 38 percent of abusive content that's enforced is surfaced
[01:16:42.600 --> 01:16:44.480]   proactively for human technology.
[01:16:44.480 --> 01:16:45.960]   Technology.
[01:16:45.960 --> 01:16:49.960]   We're using technology to keep people safe.
[01:16:49.960 --> 01:16:53.720]   So I reactivate my Twitter account because if that's true, if they if they.
[01:16:53.720 --> 01:16:56.520]   Well, I thought, you know, here's one way to find out.
[01:16:56.520 --> 01:16:57.520]   All right.
[01:16:57.520 --> 01:17:02.120]   I'm going to put my big fat butt on Twitter and see what happens.
[01:17:02.120 --> 01:17:06.600]   Yeah, because you actually I was shocked that you retweeted the Dean's tweet.
[01:17:06.600 --> 01:17:12.240]   Yeah, I thought, well, let's see if they if they're serious about reducing abuse.
[01:17:12.240 --> 01:17:13.240]   Hmm.
[01:17:13.240 --> 01:17:18.080]   Because you know, and somewhere somewhere there's an algorithm that says it's like the old
[01:17:18.080 --> 01:17:22.560]   debtor Canadian is Leo here is Leo not Leo here is Leo not.
[01:17:22.560 --> 01:17:23.560]   Yeah.
[01:17:23.560 --> 01:17:27.000]   Even my wife was shocked to see me tweeting.
[01:17:27.000 --> 01:17:30.320]   Jack Dorsey suggests his big change for Twitter.
[01:17:30.320 --> 01:17:32.320]   Oh, this piss people off.
[01:17:32.320 --> 01:17:36.080]   This is people off in a switch so you can follow topics.
[01:17:36.080 --> 01:17:37.080]   Yeah.
[01:17:37.080 --> 01:17:38.560]   None of those individuals.
[01:17:38.560 --> 01:17:42.920]   He suggests a fundamental change to the social network in which users would follow topics
[01:17:42.920 --> 01:17:44.520]   instead of individuals.
[01:17:44.520 --> 01:17:47.040]   They are an interest based network.
[01:17:47.040 --> 01:17:52.720]   So you'll see content from anyone sharing the same interest as opposed to and by the
[01:17:52.720 --> 01:17:53.920]   way, this just.
[01:17:53.920 --> 01:17:57.360]   This is just the discover tab, right?
[01:17:57.360 --> 01:18:01.400]   Basically, which I never use, which no one ever uses.
[01:18:01.400 --> 01:18:02.400]   Yeah.
[01:18:02.400 --> 01:18:03.400]   Yeah.
[01:18:03.400 --> 01:18:08.120]   So what amazes me is whenever Jack talks, like forget about the wardrobe and all that
[01:18:08.120 --> 01:18:10.280]   forget about the meditating and we're dying.
[01:18:10.280 --> 01:18:11.280]   Yeah, right.
[01:18:11.280 --> 01:18:17.920]   I mean, the thing that always strikes me is it's like a guy who has never used his own
[01:18:17.920 --> 01:18:23.800]   product product is talking like it's like the guy off the street and asked him about
[01:18:23.800 --> 01:18:25.720]   what they should do about Twitter.
[01:18:25.720 --> 01:18:27.120]   It's mind boggling.
[01:18:27.120 --> 01:18:28.960]   I have a lot of respect for Jack Dorsey.
[01:18:28.960 --> 01:18:36.120]   I think he's created some very amazing things, including Square.
[01:18:36.120 --> 01:18:37.120]   Maybe he doesn't use Twitter.
[01:18:37.120 --> 01:18:38.120]   I don't know.
[01:18:38.120 --> 01:18:39.120]   Maybe he doesn't.
[01:18:39.120 --> 01:18:40.120]   Maybe he shouldn't.
[01:18:40.120 --> 01:18:44.760]   He's experienced Twitter is inevitably different from any other person's experience.
[01:18:44.760 --> 01:18:47.000]   There's experience of everything is different.
[01:18:47.000 --> 01:18:48.000]   Yes.
[01:18:48.000 --> 01:18:49.000]   Life.
[01:18:49.000 --> 01:18:50.000]   And his life is diet.
[01:18:50.000 --> 01:18:51.000]   Isn't that weird?
[01:18:51.000 --> 01:18:52.000]   It's normal to fast.
[01:18:52.000 --> 01:18:53.000]   That's normal.
[01:18:53.000 --> 01:18:55.000]   Anyway, that's you saying that.
[01:18:55.000 --> 01:18:57.880]   You are not the judge of weird diets.
[01:18:57.880 --> 01:19:00.680]   Would you like a cupcake, Jeff?
[01:19:00.680 --> 01:19:01.800]   I'm only all cupcake.
[01:19:01.800 --> 01:19:06.640]   By the way, I have been handed a pocket protector.
[01:19:06.640 --> 01:19:12.360]   Apparently I offended my staff that I might get my pen on my nice shirt.
[01:19:12.360 --> 01:19:13.800]   So I have my ZD TV.
[01:19:13.800 --> 01:19:14.800]   ZD.
[01:19:14.800 --> 01:19:15.800]   Yeah.
[01:19:15.800 --> 01:19:16.800]   Or ZD as we call it.
[01:19:16.800 --> 01:19:18.240]   A fed D TV.
[01:19:18.240 --> 01:19:22.400]   And by the way, as soon as we found that out, we changed the name.
[01:19:22.400 --> 01:19:29.280]   Things call it what?
[01:19:29.280 --> 01:19:30.280]   Anything else?
[01:19:30.280 --> 01:19:31.280]   What else should we talk about?
[01:19:31.280 --> 01:19:32.280]   The Secret Service.
[01:19:32.280 --> 01:19:34.960]   This was a strange story.
[01:19:34.960 --> 01:19:42.800]   We talked a couple of weeks ago about the woman who was arrested with Mar-a-Lago carrying
[01:19:42.800 --> 01:19:47.040]   a number of things.
[01:19:47.040 --> 01:19:52.440]   Numerous cell phones and passports.
[01:19:52.440 --> 01:19:58.040]   And I think fairly significantly given that the president was in residence at Mar-a-Lago.
[01:19:58.040 --> 01:20:01.640]   A malware-infested USB stick.
[01:20:01.640 --> 01:20:04.400]   The fact that she got so far is already amazing.
[01:20:04.400 --> 01:20:06.560]   Yes, she also had a laptop.
[01:20:06.560 --> 01:20:07.560]   Oh, yes.
[01:20:07.560 --> 01:20:08.800]   $8,000 in cash.
[01:20:08.800 --> 01:20:10.200]   And a camera detector.
[01:20:10.200 --> 01:20:11.200]   Yes.
[01:20:11.200 --> 01:20:12.200]   A signal detector.
[01:20:12.200 --> 01:20:14.800]   By the way, how does that work?
[01:20:14.800 --> 01:20:17.480]   I guess it's based on the radio signals from the camera.
[01:20:17.480 --> 01:20:21.600]   In watch TV, you've seen them sweep a room for bugs and cameras.
[01:20:21.600 --> 01:20:24.440]   Don't you want to watch my guy, Mar-a-Lago?
[01:20:24.440 --> 01:20:26.040]   No, they make them in China.
[01:20:26.040 --> 01:20:28.040]   They're $9,8 on Amazon.
[01:20:28.040 --> 01:20:29.680]   Yeah, you get on Amazon.
[01:20:29.680 --> 01:20:31.640]   I don't know.
[01:20:31.640 --> 01:20:39.080]   She had nine USB drives, five SIM cards, and a Partridge and a Pear tree.
[01:20:39.080 --> 01:20:44.760]   However, the thing that got my attention from the Miami Herald article about all of this,
[01:20:44.760 --> 01:20:47.080]   is what the Secret Service did.
[01:20:47.080 --> 01:20:49.080]   Yeah, he plugged it into his computer.
[01:20:49.080 --> 01:20:50.880]   What they got her.
[01:20:50.880 --> 01:20:51.880]   What an idiot.
[01:20:51.880 --> 01:20:55.720]   Secret Service agent Samuel Ivanovich, who interviewed Jang on the day of arrest, testified
[01:20:55.720 --> 01:20:56.720]   at her hearing.
[01:20:56.720 --> 01:21:02.760]   He stated, "When another agent put Jang's thumb drive into his computer, okay, red light
[01:21:02.760 --> 01:21:07.480]   bells and flags going up now, it immediately began to install files."
[01:21:07.480 --> 01:21:08.480]   Oh, you think?
[01:21:08.480 --> 01:21:10.840]   A very out of the ordinary event.
[01:21:10.840 --> 01:21:11.840]   A very...
[01:21:11.840 --> 01:21:12.840]   What?
[01:21:12.840 --> 01:21:13.840]   That's not that out of the audience.
[01:21:13.840 --> 01:21:16.440]   Come on, you work at the Secret Service?
[01:21:16.440 --> 01:21:17.440]   A very...
[01:21:17.440 --> 01:21:18.440]   It was new.
[01:21:18.440 --> 01:21:22.240]   Out of the ordinary event that he had never seen happen before.
[01:21:22.240 --> 01:21:25.480]   During this kind of analysis, we stick thumb drives in all the time.
[01:21:25.480 --> 01:21:27.160]   This never happens.
[01:21:27.160 --> 01:21:33.280]   The agent had to immediately stop the analysis to halt any further corruption of his computer.
[01:21:33.280 --> 01:21:36.080]   I love how he says another agent put it into his computer.
[01:21:36.080 --> 01:21:37.080]   Yeah, not me.
[01:21:37.080 --> 01:21:38.080]   Someone else put it in.
[01:21:38.080 --> 01:21:39.080]   It wasn't me.
[01:21:39.080 --> 01:21:40.080]   It wasn't me.
[01:21:40.080 --> 01:21:41.080]   I didn't do it.
[01:21:41.080 --> 01:21:42.080]   Someone from Canada, you don't know.
[01:21:42.080 --> 01:21:43.080]   Yeah, it was Canadian agent.
[01:21:43.080 --> 01:21:44.080]   It was...
[01:21:44.080 --> 01:21:45.080]   Yeah.
[01:21:45.080 --> 01:21:47.840]   I just found a camera protector.
[01:21:47.840 --> 01:21:48.840]   Camera detector.
[01:21:48.840 --> 01:21:49.840]   Yeah.
[01:21:49.840 --> 01:21:50.840]   Very good.
[01:21:50.840 --> 01:21:51.840]   Very good.
[01:21:51.840 --> 01:21:52.840]   It only works if it's a wireless.
[01:21:52.840 --> 01:21:53.840]   You can disable them too.
[01:21:53.840 --> 01:21:54.840]   No, no, not according to this.
[01:21:54.840 --> 01:21:55.840]   Oh, really?
[01:21:55.840 --> 01:21:57.680]   Lightweight battery power device, I put it in the chat that allows users to... not the
[01:21:57.680 --> 01:21:58.680]   chat, but the rundown.
[01:21:58.680 --> 01:21:59.680]   Yeah.
[01:21:59.680 --> 01:22:02.800]   You detect it and if I locate hidden cameras of any kind, it does not matter whether the
[01:22:02.800 --> 01:22:05.680]   camera is wired or wireless transmitting or in standby mode.
[01:22:05.680 --> 01:22:13.000]   If the lens is pointing outward in surveillance mode, like the whole internet, the hidden
[01:22:13.000 --> 01:22:14.880]   camera detector will be able to identify.
[01:22:14.880 --> 01:22:15.880]   That's going to be useless.
[01:22:15.880 --> 01:22:17.600]   It's going to go off all the time.
[01:22:17.600 --> 01:22:19.240]   Okay, let's order one.
[01:22:19.240 --> 01:22:21.360]   Just to see if it notices that I'm on camera.
[01:22:21.360 --> 01:22:25.960]   Through the spy finder lens, a hidden camera lens appears as a bright flickering spot of
[01:22:25.960 --> 01:22:29.360]   light making it easy for the user to identify and locate if necessary.
[01:22:29.360 --> 01:22:30.360]   Interesting.
[01:22:30.360 --> 01:22:31.360]   Handy.
[01:22:31.360 --> 01:22:32.360]   I might buy that.
[01:22:32.360 --> 01:22:33.360]   What?
[01:22:33.360 --> 01:22:34.360]   248 bucks.
[01:22:34.360 --> 01:22:35.360]   Stick that.
[01:22:35.360 --> 01:22:38.360]   I'll put your computer for analysis.
[01:22:38.360 --> 01:22:39.360]   Wow.
[01:22:39.360 --> 01:22:40.360]   Okay.
[01:22:40.360 --> 01:22:43.600]   She had that too.
[01:22:43.600 --> 01:22:48.640]   So there's a deluxe professional camera detector that's $599.
[01:22:48.640 --> 01:22:53.200]   It comes with a backpack.
[01:22:53.200 --> 01:22:56.080]   I do remember buying X-ray specs from the back of a comic book.
[01:22:56.080 --> 01:22:57.080]   Yeah.
[01:22:57.080 --> 01:22:58.800]   I'm sure you would have.
[01:22:58.800 --> 01:23:00.400]   A great disappointment I might have.
[01:23:00.400 --> 01:23:01.400]   And C-Monkeys.
[01:23:01.400 --> 01:23:02.400]   Yeah.
[01:23:02.400 --> 01:23:03.400]   C-Monkeys work.
[01:23:03.400 --> 01:23:04.400]   Don't be not...
[01:23:04.400 --> 01:23:05.400]   They were Brian shrimp.
[01:23:05.400 --> 01:23:06.400]   They were Brian shrimp.
[01:23:06.400 --> 01:23:07.400]   Okay.
[01:23:07.400 --> 01:23:10.160]   C-Monkey by any other name would swim as well.
[01:23:10.160 --> 01:23:13.480]   But the little male C-Monkey did not have a briefcase and a top hat.
[01:23:13.480 --> 01:23:14.480]   No.
[01:23:14.480 --> 01:23:15.480]   No.
[01:23:15.480 --> 01:23:16.480]   No, that was misrepresentation.
[01:23:16.480 --> 01:23:17.480]   Absolutely.
[01:23:17.480 --> 01:23:19.920]   So I'll see.
[01:23:19.920 --> 01:23:22.600]   I'll report back on my experiences using...
[01:23:22.600 --> 01:23:23.600]   It says...
[01:23:23.600 --> 01:23:25.200]   You could go tomorrow at peace.
[01:23:25.200 --> 01:23:26.200]   Yeah.
[01:23:26.200 --> 01:23:29.560]   Never before has the Secret Service had to deal with this type of scenario.
[01:23:29.560 --> 01:23:30.560]   Never saw this.
[01:23:30.560 --> 01:23:32.200]   This never happened.
[01:23:32.200 --> 01:23:33.200]   No one's ever...
[01:23:33.200 --> 01:23:34.200]   Never thought.
[01:23:34.200 --> 01:23:36.000]   It's like computers were just invented.
[01:23:36.000 --> 01:23:40.920]   So, just in case you don't know, I'm sure every single person watching this show knows
[01:23:40.920 --> 01:23:43.520]   that you do not pick up a USB stick off the ground ever.
[01:23:43.520 --> 01:23:45.960]   You'll stick it into your computer ever.
[01:23:45.960 --> 01:23:51.160]   And if you do, make sure it is not a Windows computer and auto run is not turned on.
[01:23:51.160 --> 01:23:52.160]   You could...
[01:23:52.160 --> 01:23:53.160]   Unbelievable.
[01:23:53.160 --> 01:23:55.880]   I guess try it on a Linux computer, although there is...
[01:23:55.880 --> 01:24:00.960]   There are firmware hacks called bad USB that you can put on a USB stick that will infect
[01:24:00.960 --> 01:24:01.960]   anything.
[01:24:01.960 --> 01:24:05.680]   So, essentially, if you're going to analyze a USB stick, you really shouldn't do it by
[01:24:05.680 --> 01:24:08.880]   sticking it into your computer.
[01:24:08.880 --> 01:24:11.240]   This would be a bad idea.
[01:24:11.240 --> 01:24:13.360]   And don't go to China and do that.
[01:24:13.360 --> 01:24:14.560]   Oh, yeah, right.
[01:24:14.560 --> 01:24:18.960]   I think the Chinese secret police would know enough not to do that.
[01:24:18.960 --> 01:24:19.960]   Probably.
[01:24:19.960 --> 01:24:20.960]   Probably.
[01:24:20.960 --> 01:24:24.240]   I think this was the secret agent they sent down there to drive the golf cart.
[01:24:24.240 --> 01:24:25.240]   Obviously.
[01:24:25.240 --> 01:24:26.240]   Yeah.
[01:24:26.240 --> 01:24:27.240]   It's the golf cart guy.
[01:24:27.240 --> 01:24:28.240]   Nice, well smart.
[01:24:28.240 --> 01:24:29.960]   There has to be different levels, right?
[01:24:29.960 --> 01:24:32.440]   Because there's somebody else going to run by the car.
[01:24:32.440 --> 01:24:34.240]   That's going to be not a great job.
[01:24:34.240 --> 01:24:35.840]   This guy is not on the tech team.
[01:24:35.840 --> 01:24:37.240]   Well, not on the tech team.
[01:24:37.240 --> 01:24:41.240]   And I'm sure as soon as this came out, the guys in the tech team are going, "You did
[01:24:41.240 --> 01:24:42.240]   what?"
[01:24:42.240 --> 01:24:43.240]   Yeah.
[01:24:43.240 --> 01:24:49.480]   Because now, I mean, if that computer was on the Wi-Fi at Mar-a-Lago, you're screwed.
[01:24:49.480 --> 01:24:50.480]   Yeah.
[01:24:50.480 --> 01:24:54.280]   I'm sure it's fine.
[01:24:54.280 --> 01:24:55.280]   I'm sure nothing.
[01:24:55.280 --> 01:24:56.280]   What could possibly happen?
[01:24:56.280 --> 01:24:59.520]   I'm sure nothing happened to the president's Android phone.
[01:24:59.520 --> 01:25:06.800]   Well, just wait until president Xi comes out again and he can sweep it.
[01:25:06.800 --> 01:25:13.160]   Illinois Bill, which I thought was a good idea, but maybe Mr. Technopanek, you don't.
[01:25:13.160 --> 01:25:17.320]   There was an Illinois Bill banning eavesdropping by IoT devices.
[01:25:17.320 --> 01:25:18.320]   Oh, yes.
[01:25:18.320 --> 01:25:19.320]   See, I need.
[01:25:19.320 --> 01:25:22.920]   You're looking at the name of the bill even better.
[01:25:22.920 --> 01:25:23.920]   He's dropping.
[01:25:23.920 --> 01:25:28.320]   He keep internet devices safe act.
[01:25:28.320 --> 01:25:29.320]   What is it?
[01:25:29.320 --> 01:25:32.320]   KIDSA was past April 10th.
[01:25:32.320 --> 01:25:35.760]   Did you see the image they used?
[01:25:35.760 --> 01:25:36.760]   Yeah.
[01:25:36.760 --> 01:25:37.760]   It's the...
[01:25:37.760 --> 01:25:38.760]   It's from the Alexa Silver.
[01:25:38.760 --> 01:25:44.680]   Yeah, it's from Saturday Night Live's wonderful skid on the four seniors.
[01:25:44.680 --> 01:25:45.680]   So good.
[01:25:45.680 --> 01:25:48.440]   How many old central page got last night?
[01:25:48.440 --> 01:25:50.440]   Alex Andria?
[01:25:50.440 --> 01:25:51.440]   I guess.
[01:25:51.440 --> 01:25:52.440]   Oh, Destiny.
[01:25:52.440 --> 01:25:53.440]   Oh, Destiny.
[01:25:53.440 --> 01:26:04.160]   By the way, at least we gave one to Lisa's dad who persisted calling it a little.
[01:26:04.160 --> 01:26:05.160]   Nice.
[01:26:05.160 --> 01:26:06.560]   And he says, what's wrong with that?
[01:26:06.560 --> 01:26:07.560]   She responds.
[01:26:07.560 --> 01:26:08.560]   Does she?
[01:26:08.560 --> 01:26:09.560]   Interesting.
[01:26:09.560 --> 01:26:10.560]   He may be.
[01:26:10.560 --> 01:26:11.560]   He actually thinks they should make one.
[01:26:11.560 --> 01:26:12.560]   Right.
[01:26:12.560 --> 01:26:14.560]   They should just take whatever they had in that.
[01:26:14.560 --> 01:26:15.560]   Yeah.
[01:26:15.560 --> 01:26:16.560]   Yeah.
[01:26:16.560 --> 01:26:17.560]   And they should...
[01:26:17.560 --> 01:26:18.560]   Yo.
[01:26:18.560 --> 01:26:19.560]   Even close to Alexa.
[01:26:19.560 --> 01:26:21.240]   Give me a cupcake.
[01:26:21.240 --> 01:26:25.720]   The bill has passed by the Senate says, "No private entity may turn on or enable a digital
[01:26:25.720 --> 01:26:30.880]   device's microphone unless the registered account holder and another user that is setting
[01:26:30.880 --> 01:26:34.840]   up or configuring the device first agrees to the following information in a consumer
[01:26:34.840 --> 01:26:40.120]   agreement or privacy notice notifying the registered account holder one, that the microphone
[01:26:40.120 --> 01:26:44.200]   and the digital device will be turned on or enabled that two, what command or action
[01:26:44.200 --> 01:26:47.280]   will turn on or enable the microphone.
[01:26:47.280 --> 01:26:48.680]   It's not Alex Andria.
[01:26:48.680 --> 01:26:49.680]   It's not Odessa.
[01:26:49.680 --> 01:26:54.960]   Three, the categories of sounds the microphone will be listening for recording or disclosing
[01:26:54.960 --> 01:27:02.200]   and for the categories of third parties to which the sounds may be disclosed.
[01:27:02.200 --> 01:27:06.640]   The bill also requires any recordings or other personal information captured by devices
[01:27:06.640 --> 01:27:12.040]   to protect against unauthorized access, acquisition, destruction, use, modification and disclosure
[01:27:12.040 --> 01:27:13.440]   of the data.
[01:27:13.440 --> 01:27:14.440]   Now here's the thing.
[01:27:14.440 --> 01:27:18.400]   As soon as the lobbyists heard about it, they went in there.
[01:27:18.400 --> 01:27:20.760]   They actually didn't rewrite the law.
[01:27:20.760 --> 01:27:26.160]   They just took out one little line, the line that says it's punishable.
[01:27:26.160 --> 01:27:29.640]   So now there's no Internet association.
[01:27:29.640 --> 01:27:30.640]   The Internet association.
[01:27:30.640 --> 01:27:31.840]   They're getting smart.
[01:27:31.840 --> 01:27:36.640]   Yeah, the original bill would have made this unlawful practice under the Consumer Front
[01:27:36.640 --> 01:27:41.760]   and Deceptive Business Practices Act, which would result in fines of up to $50,000 per
[01:27:41.760 --> 01:27:42.760]   case.
[01:27:42.760 --> 01:27:47.680]   The Internet Association managed to get them to take that line out.
[01:27:47.680 --> 01:27:51.360]   It would create significant legal liability for companies.
[01:27:51.360 --> 01:27:52.360]   They're also...
[01:27:52.360 --> 01:27:58.320]   And I mean, I don't know if you've had this problem, but my device often just randomly
[01:27:58.320 --> 01:28:00.720]   responds to things that aren't even commands.
[01:28:00.720 --> 01:28:02.720]   Like the TV says something or...
[01:28:02.720 --> 01:28:03.720]   Oh my God!
[01:28:03.720 --> 01:28:04.920]   Yeah, I still can't figure out why.
[01:28:04.920 --> 01:28:05.920]   Apple...
[01:28:05.920 --> 01:28:07.000]   Oh well, because it hears things.
[01:28:07.000 --> 01:28:08.120]   I know but it doesn't...
[01:28:08.120 --> 01:28:09.960]   Nothing even close to the name.
[01:28:09.960 --> 01:28:10.960]   You think!
[01:28:10.960 --> 01:28:11.960]   And then it just starts responding.
[01:28:11.960 --> 01:28:12.960]   That's what you say.
[01:28:12.960 --> 01:28:13.960]   Yeah.
[01:28:13.960 --> 01:28:15.760]   It might have heard its name.
[01:28:15.760 --> 01:28:16.760]   I guess.
[01:28:16.760 --> 01:28:20.520]   When we come into the kitchen, we have a Siri HomePod in the kitchen.
[01:28:20.520 --> 01:28:22.040]   And it's usually turned out pretty low.
[01:28:22.040 --> 01:28:27.600]   And I'll hear Siri mumbling to herself in the kitchen like a crazy person.
[01:28:27.600 --> 01:28:29.000]   Just talking on and on and on.
[01:28:29.000 --> 01:28:31.680]   I don't know if Leo never talks to me anymore.
[01:28:31.680 --> 01:28:32.680]   It's like...
[01:28:32.680 --> 01:28:35.320]   And then I told him...
[01:28:35.320 --> 01:28:36.320]   I'm not gonna...
[01:28:36.320 --> 01:28:37.320]   Anyway...
[01:28:37.320 --> 01:28:42.760]   Well, my favorite was the one not that long ago where it recorded a conversation and
[01:28:42.760 --> 01:28:48.840]   then sent it to someone because it misheard the command to record.
[01:28:48.840 --> 01:28:50.000]   That happened to you?
[01:28:50.000 --> 01:28:52.280]   No, to someone I'm trying to remember the story.
[01:28:52.280 --> 01:28:54.400]   Oh, this is a big deal.
[01:28:54.400 --> 01:28:55.400]   It sent...
[01:28:55.400 --> 01:28:58.200]   It actually emailed a copy to someone on the contact list.
[01:28:58.200 --> 01:29:04.280]   A fight between a husband and wife to a former client of that husband who was still in his
[01:29:04.280 --> 01:29:05.280]   contact list.
[01:29:05.280 --> 01:29:06.280]   It sent them.
[01:29:06.280 --> 01:29:07.280]   And the guy went...
[01:29:07.280 --> 01:29:09.920]   You look at the sort of...
[01:29:09.920 --> 01:29:13.680]   The process of mistaken things it had to go through.
[01:29:13.680 --> 01:29:14.680]   Amazon's like...
[01:29:14.680 --> 01:29:15.680]   It was...
[01:29:15.680 --> 01:29:17.160]   Well, first it mistakenly heard a command to record.
[01:29:17.160 --> 01:29:19.120]   That it mistakenly heard.
[01:29:19.120 --> 01:29:20.880]   And then it said, "Do you want me to send this to someone?"
[01:29:20.880 --> 01:29:23.760]   So, and it mistakenly heard someone say, "Yes."
[01:29:23.760 --> 01:29:26.840]   None of that's gonna happen.
[01:29:26.840 --> 01:29:27.840]   No.
[01:29:27.840 --> 01:29:28.840]   Totally.
[01:29:28.840 --> 01:29:30.000]   Except once in a while.
[01:29:30.000 --> 01:29:31.000]   Anyway...
[01:29:31.000 --> 01:29:34.160]   I had the same reaction as you when I first read it, Jeff.
[01:29:34.160 --> 01:29:35.280]   I said, "Oh, great.
[01:29:35.280 --> 01:29:38.800]   This moral panic is gonna mean we can't have nice things anymore.
[01:29:38.800 --> 01:29:44.520]   They're gonna get rid of all, you know, echo and Google Assistant and all that stuff."
[01:29:44.520 --> 01:29:47.640]   So I did kind of feel the same way as you did, Jeff, which is...
[01:29:47.640 --> 01:29:49.320]   I mean, generally they should be transparent.
[01:29:49.320 --> 01:29:50.320]   They should have these rules as a use.
[01:29:50.320 --> 01:29:51.320]   They should tell you.
[01:29:51.320 --> 01:29:52.320]   Yeah.
[01:29:52.320 --> 01:29:53.320]   But the basis of this is...
[01:29:53.320 --> 01:29:56.520]   Let's also recognize state legislators trying to get stories about them.
[01:29:56.520 --> 01:29:57.520]   Yeah.
[01:29:57.520 --> 01:30:01.000]   And actually, they're probably best of both worlds where they passed the law, but it has
[01:30:01.000 --> 01:30:02.000]   no effect.
[01:30:02.000 --> 01:30:04.760]   It's just exactly what they were hoping for.
[01:30:04.760 --> 01:30:10.000]   There was another state legislature that was trying to pass a law that would create a
[01:30:10.000 --> 01:30:14.120]   journalistic license effectively.
[01:30:14.120 --> 01:30:15.800]   Trying to remember which state that was.
[01:30:15.800 --> 01:30:16.800]   Oh, yeah.
[01:30:16.800 --> 01:30:17.800]   Yeah.
[01:30:17.800 --> 01:30:19.960]   No, no, no, no.
[01:30:19.960 --> 01:30:22.480]   A license to commit journalism?
[01:30:22.480 --> 01:30:23.480]   Yeah.
[01:30:23.480 --> 01:30:24.480]   And you'd have to be registered.
[01:30:24.480 --> 01:30:25.480]   Yeah.
[01:30:25.480 --> 01:30:26.480]   I'm a licensed journalist.
[01:30:26.480 --> 01:30:32.480]   The guy who proposed it, apparently, is not a fan of the people who cover the...
[01:30:32.480 --> 01:30:33.480]   Yeah.
[01:30:33.480 --> 01:30:34.480]   ...capital.
[01:30:34.480 --> 01:30:35.480]   Wow.
[01:30:35.480 --> 01:30:36.480]   Mm-hmm.
[01:30:36.480 --> 01:30:39.480]   They have licenses in Italy, actually, which is interesting.
[01:30:39.480 --> 01:30:40.480]   Really?
[01:30:40.480 --> 01:30:41.480]   You have to get a license, yeah.
[01:30:41.480 --> 01:30:42.480]   Well, you don't have to.
[01:30:42.480 --> 01:30:43.480]   So you can practice as a journalist, but you don't get paid as much.
[01:30:43.480 --> 01:30:44.480]   It's like an act record.
[01:30:44.480 --> 01:30:54.480]   So once you get your license, then you can get paid sort of Margaret Rins.
[01:30:54.480 --> 01:30:55.480]   I'm a licensed journalist.
[01:30:55.480 --> 01:30:56.480]   Should we...
[01:30:56.480 --> 01:30:59.480]   We should quickly do the change log and then it's cut and done.
[01:30:59.480 --> 01:31:00.480]   The Google...
[01:31:00.480 --> 01:31:01.480]   Change log.
[01:31:01.480 --> 01:31:09.920]   The Google Pixel camera, and this will get people going, is now looking to see if you're
[01:31:09.920 --> 01:31:12.200]   kissing.
[01:31:12.200 --> 01:31:15.040]   Snog-o-vision.
[01:31:15.040 --> 01:31:17.160]   If you have a Google Pixel, there is AI.
[01:31:17.160 --> 01:31:24.680]   Google actually revealed this in a blog post that it will help you take selfies by looking
[01:31:24.680 --> 01:31:27.560]   for you to smile.
[01:31:27.560 --> 01:31:34.440]   Really Mike Elgin was using a really cool feature of photo booth where when it sees people smile
[01:31:34.440 --> 01:31:39.440]   and takes a picture, so he set up his Pixel last time he was here on a tripod and just
[01:31:39.440 --> 01:31:42.920]   said, "Don't worry about it, but if you look at the camera and smile, it's going to take
[01:31:42.920 --> 01:31:43.920]   a picture."
[01:31:43.920 --> 01:31:45.080]   So he gets all these great pictures.
[01:31:45.080 --> 01:31:47.680]   But now we will know if you're kissing.
[01:31:47.680 --> 01:31:50.160]   They've added kiss detection to photos.
[01:31:50.160 --> 01:31:51.160]   Oh.
[01:31:51.160 --> 01:31:53.400]   Oh, I can see the story now.
[01:31:53.400 --> 01:31:54.800]   You could just see it now.
[01:31:54.800 --> 01:31:55.800]   Yeah.
[01:31:55.800 --> 01:32:01.160]   My way I'll take a picture if you smile.
[01:32:01.160 --> 01:32:05.200]   I like this photo booth feature, and I have a Pixel, but I've really lately been using
[01:32:05.200 --> 01:32:08.160]   the Samsung S10, which I just adore.
[01:32:08.160 --> 01:32:09.880]   You like it better than the Pixel?
[01:32:09.880 --> 01:32:10.880]   Yeah.
[01:32:10.880 --> 01:32:15.760]   Well, the Pixel camera is bested by none, especially night shot.
[01:32:15.760 --> 01:32:18.760]   But it's a little janky in other respects.
[01:32:18.760 --> 01:32:22.880]   It's not a great screen, and I've had problems with everybody has.
[01:32:22.880 --> 01:32:26.080]   I think there's a QC, there's a quality control issue.
[01:32:26.080 --> 01:32:29.680]   But the Samsung is fantastic, and the camera's great in good light.
[01:32:29.680 --> 01:32:32.280]   The only thing it's not as good as a good as--
[01:32:32.280 --> 01:32:33.280]   It's a night shot.
[01:32:33.280 --> 01:32:34.800]   It's a night shot, which it really--
[01:32:34.800 --> 01:32:38.400]   Google somehow, it's doing black magic there.
[01:32:38.400 --> 01:32:43.760]   Google Pay can now automatically import loyalty cards tickets and offers.
[01:32:43.760 --> 01:32:46.440]   All you have to do is give it access to your Gmail.
[01:32:46.440 --> 01:32:47.440]   Uh-oh.
[01:32:47.440 --> 01:32:48.440]   And your--
[01:32:48.440 --> 01:32:49.440]   And your--
[01:32:49.440 --> 01:32:51.440]   --goopay-spied on you.
[01:32:51.440 --> 01:32:52.840]   I actually--
[01:32:52.840 --> 01:32:53.840]   It knows what you bought.
[01:32:53.840 --> 01:32:56.600]   Tripit did that, right, where you give Tripit your Gmail.
[01:32:56.600 --> 01:32:57.600]   Yeah.
[01:32:57.600 --> 01:32:59.440]   I've finally just-- I turned that all off, and now I just--
[01:32:59.440 --> 01:33:00.440]   You used to love that.
[01:33:00.440 --> 01:33:01.440]   Yeah.
[01:33:01.440 --> 01:33:02.440]   You used to love it.
[01:33:02.440 --> 01:33:03.440]   Well, I forward it.
[01:33:03.440 --> 01:33:05.000]   If you forward it to plans it, Tripit, it'll still do it.
[01:33:05.000 --> 01:33:06.840]   But I don't want Tripit going through.
[01:33:06.840 --> 01:33:07.840]   We've heard too many stories.
[01:33:07.840 --> 01:33:11.240]   I love that Google puts things automatically in my calendar, flights and stuff.
[01:33:11.240 --> 01:33:12.240]   I love--
[01:33:12.240 --> 01:33:13.240]   Yeah, me too, actually.
[01:33:13.240 --> 01:33:14.560]   I like that, too.
[01:33:14.560 --> 01:33:18.520]   I miss Google Inbox for many reasons, one of which is that it would put my travel stuff
[01:33:18.520 --> 01:33:19.520]   together in one--
[01:33:19.520 --> 01:33:20.520]   Mm-hmm.
[01:33:20.520 --> 01:33:21.360]   Yeah.
[01:33:21.360 --> 01:33:27.080]   I stopped using Gmail, mostly because I was getting a lot of French spam.
[01:33:27.080 --> 01:33:28.720]   What do you use now?
[01:33:28.720 --> 01:33:31.160]   Fast mail, which is a third page.
[01:33:31.160 --> 01:33:33.360]   Oh, a third-party paid service, a good IMAP service.
[01:33:33.360 --> 01:33:36.840]   But yeah, those Google services, those are nice, and I do miss those.
[01:33:36.840 --> 01:33:37.840]   They're not so.
[01:33:37.840 --> 01:33:42.160]   The other reason I used Gmail for years is because nobody did a better job at spam.
[01:33:42.160 --> 01:33:43.160]   Mm-hmm.
[01:33:43.160 --> 01:33:44.840]   What's your experience on this?
[01:33:44.840 --> 01:33:46.000]   Step John C. de Vorac.
[01:33:46.000 --> 01:33:47.720]   Yeah, right.
[01:33:47.720 --> 01:33:50.200]   I get tons of spam on my Google account now.
[01:33:50.200 --> 01:33:51.200]   Really?
[01:33:51.200 --> 01:33:52.200]   Does it not work?
[01:33:52.200 --> 01:33:53.200]   I don't get any.
[01:33:53.200 --> 01:33:55.440]   OK, so there's something going on.
[01:33:55.440 --> 01:33:56.600]   Yeah, it's an unbelievable.
[01:33:56.600 --> 01:33:58.280]   The filter is almost never wrong.
[01:33:58.280 --> 01:34:01.600]   Oh, man, I get almost nothing but spam.
[01:34:01.600 --> 01:34:03.000]   I don't know.
[01:34:03.000 --> 01:34:05.720]   Yeah, that's why I stopped using it.
[01:34:05.720 --> 01:34:06.720]   Oh.
[01:34:06.720 --> 01:34:07.720]   Er, er.
[01:34:07.720 --> 01:34:11.800]   Maybe you're doing it wrong.
[01:34:11.800 --> 01:34:14.000]   I'm sure I am.
[01:34:14.000 --> 01:34:16.080]   I'm notorious for that.
[01:34:16.080 --> 01:34:17.240]   Why the other day?
[01:34:17.240 --> 01:34:20.160]   Just the other day I stuck a USB drive into a--
[01:34:20.160 --> 01:34:22.240]   That I found on the street.
[01:34:22.240 --> 01:34:25.680]   I found on the street.
[01:34:25.680 --> 01:34:29.680]   I didn't understand this story, but I'm going to have repeated.
[01:34:29.680 --> 01:34:37.320]   The Google Play Store is testing simultaneous downloads, internal app sharing, and more.
[01:34:37.320 --> 01:34:39.960]   I thought it always did simultaneous downloads.
[01:34:39.960 --> 01:34:40.960]   Yeah.
[01:34:40.960 --> 01:34:41.960]   Is that new?
[01:34:41.960 --> 01:34:42.960]   Well, no, it was serial.
[01:34:42.960 --> 01:34:43.960]   It was always--
[01:34:43.960 --> 01:34:45.760]   We don't want to last one after this time.
[01:34:45.760 --> 01:34:46.760]   OK, all right.
[01:34:46.760 --> 01:34:47.760]   Well, now we'll do--
[01:34:47.760 --> 01:34:48.760]   I had another one.
[01:34:48.760 --> 01:34:49.760]   Oh.
[01:34:49.760 --> 01:34:50.760]   That's nice.
[01:34:50.760 --> 01:34:53.800]   Wouldn't it logically take the same amount of time anyway?
[01:34:53.800 --> 01:34:54.800]   Yes.
[01:34:54.800 --> 01:34:55.800]   Theoretically.
[01:34:55.800 --> 01:34:57.440]   If it uses all your bandwidth, yes.
[01:34:57.440 --> 01:34:58.440]   Yeah.
[01:34:58.440 --> 01:34:59.440]   OK.
[01:34:59.440 --> 01:35:00.440]   But it looks better.
[01:35:00.440 --> 01:35:01.440]   It looks like it's doing more.
[01:35:01.440 --> 01:35:02.440]   Yeah.
[01:35:02.440 --> 01:35:03.440]   Yeah.
[01:35:03.440 --> 01:35:04.920]   Apple is serial.
[01:35:04.920 --> 01:35:08.720]   Maybe that's why, because they want to be better than Apple.
[01:35:08.720 --> 01:35:16.920]   Internal app sharing, which is good for businesses, it means that if you're a developer
[01:35:16.920 --> 01:35:21.600]   in a large company, you can share your app internally without having to go through
[01:35:21.600 --> 01:35:22.600]   the Play Store.
[01:35:22.600 --> 01:35:23.600]   Oh.
[01:35:23.600 --> 01:35:24.600]   This is a switch.
[01:35:24.600 --> 01:35:29.800]   It can turn on internal app sharing, so you can download and install test versions
[01:35:29.800 --> 01:35:31.160]   of apps that are shared with you.
[01:35:31.160 --> 01:35:35.840]   I guess anybody could use this, not just internally at a company.
[01:35:35.840 --> 01:35:42.000]   And there is a new interface on Google Play Protect.
[01:35:42.000 --> 01:35:46.120]   The main Protect UI still has the recently scanned apps with the settings to scan the
[01:35:46.120 --> 01:35:51.920]   device and improve harmful app detection if it moved to another screen.
[01:35:51.920 --> 01:35:54.120]   Maybe it confused people.
[01:35:54.120 --> 01:35:58.120]   So settings are now after the gear instead of all on one page.
[01:35:58.120 --> 01:36:04.400]   Maybe they're going to add more settings, so they needed to make some room for it.
[01:36:04.400 --> 01:36:06.240]   The Google Home Hub.
[01:36:06.240 --> 01:36:09.960]   We thought there was going to be a new one, but I guess they're just rebranding it to
[01:36:09.960 --> 01:36:19.720]   the Nest Hub.
[01:36:19.720 --> 01:36:21.520]   It's not really a feature.
[01:36:21.520 --> 01:36:24.520]   I probably didn't have to put that in shape.
[01:36:24.520 --> 01:36:25.520]   I'm not excited.
[01:36:25.520 --> 01:36:26.520]   Yeah, I know.
[01:36:26.520 --> 01:36:27.520]   It goes.
[01:36:27.520 --> 01:36:29.920]   Waymo launches a robo-taxi app on Google Pay.
[01:36:29.920 --> 01:36:32.160]   I'm excited about this.
[01:36:32.160 --> 01:36:34.360]   You could call it Waymo and come up here, Jeff.
[01:36:34.360 --> 01:36:35.360]   Yeah.
[01:36:35.360 --> 01:36:36.360]   That'd be fun.
[01:36:36.360 --> 01:36:37.360]   Yeah.
[01:36:37.360 --> 01:36:38.760]   It would freak on the bridge.
[01:36:38.760 --> 01:36:39.760]   This is a...
[01:36:39.760 --> 01:36:42.960]   It's like every human should.
[01:36:42.960 --> 01:36:45.960]   The commercial robo-taxi service is called Waymo One.
[01:36:45.960 --> 01:36:48.960]   Right now it's in Phoenix.
[01:36:48.960 --> 01:36:53.880]   I imagine it will roll out to a larger area at some point.
[01:36:53.880 --> 01:36:58.240]   Like someone in Phoenix will try it.
[01:36:58.240 --> 01:36:59.640]   Yeah.
[01:36:59.640 --> 01:37:03.400]   You'll be added to a wait list to get the app.
[01:37:03.400 --> 01:37:04.880]   No, no, no, not for the ride.
[01:37:04.880 --> 01:37:05.880]   To get the app.
[01:37:05.880 --> 01:37:09.960]   You'll be able to request rides in the app.
[01:37:09.960 --> 01:37:13.080]   There's an early rider program.
[01:37:13.080 --> 01:37:14.400]   This is coming.
[01:37:14.400 --> 01:37:16.240]   I wonder when we're going to get this in...
[01:37:16.240 --> 01:37:18.240]   I would have tried that if I went in Phoenix.
[01:37:18.240 --> 01:37:19.240]   Yeah.
[01:37:19.240 --> 01:37:22.800]   Next time you're in Phoenix, give it a shot.
[01:37:22.800 --> 01:37:23.800]   I think that's enough.
[01:37:23.800 --> 01:37:25.440]   I think that's quite enough.
[01:37:25.440 --> 01:37:26.440]   That's enough.
[01:37:26.440 --> 01:37:28.680]   Of the Google change log.
[01:37:28.680 --> 01:37:29.680]   That's quite enough.
[01:37:29.680 --> 01:37:33.600]   I was all excited about the Galaxy Fold from Samsung.
[01:37:33.600 --> 01:37:34.600]   Yeah.
[01:37:34.600 --> 01:37:35.600]   They're falling apart.
[01:37:35.600 --> 01:37:36.600]   They're falling apart.
[01:37:36.600 --> 01:37:38.600]   Yes, initial reviews were quite positive.
[01:37:38.600 --> 01:37:40.120]   Exactly what I thought was going to happen.
[01:37:40.120 --> 01:37:41.400]   They were quite positive.
[01:37:41.400 --> 01:37:44.280]   And then it started breaking.
[01:37:44.280 --> 01:37:51.480]   Steve Kovac at CNBC, Mark Gurman at Bloomberg, Dieter Bono the Verge, all reported major
[01:37:51.480 --> 01:37:53.200]   failures of their fold display.
[01:37:53.200 --> 01:37:58.240]   Now these are review units provided to these reporters.
[01:37:58.240 --> 01:38:03.120]   In all three cases, just a couple of days after getting them, Mark is Brownlee having
[01:38:03.120 --> 01:38:06.080]   similar problems.
[01:38:06.080 --> 01:38:11.200]   Bono and Kovac claimed their displays failed without removing the panel's protective film.
[01:38:11.200 --> 01:38:13.280]   Samsung says, "Don't take it off."
[01:38:13.280 --> 01:38:16.960]   Both Gurman and Marcus did remove it.
[01:38:16.960 --> 01:38:18.800]   As you can see, it doesn't look good.
[01:38:18.800 --> 01:38:22.520]   Bono's phone got crimped.
[01:38:22.520 --> 01:38:26.000]   They're not sure how.
[01:38:26.000 --> 01:38:31.440]   Maybe some Zabri got in the hinge.
[01:38:31.440 --> 01:38:39.480]   They just saved me $1,980 because the phone is available at T-Mobile on the 25th and I
[01:38:39.480 --> 01:38:45.960]   was going to run over Get One to review and show because I don't get review units.
[01:38:45.960 --> 01:38:49.880]   By the way, one of the reasons I don't like to get review units is because who knows?
[01:38:49.880 --> 01:38:54.640]   This might be a pre-production issue that isn't going to show up in the retail version.
[01:38:54.640 --> 01:38:59.520]   It's very hard when you're reviewing something that isn't a production version to say anything
[01:38:59.520 --> 01:39:04.280]   because you don't know if the problem you're facing is because it's pre-production or because
[01:39:04.280 --> 01:39:06.640]   it's a real problem.
[01:39:06.640 --> 01:39:10.520]   Nevertheless, I think I'm going to take it seriously enough.
[01:39:10.520 --> 01:39:11.520]   Wait a minute.
[01:39:11.520 --> 01:39:15.440]   Not to spend $2,000 this coming Friday, but to wait a little bit.
[01:39:15.440 --> 01:39:18.920]   Just to see everybody version 1.0 of anything.
[01:39:18.920 --> 01:39:22.280]   Well, I kind of have to and I'm very glad for a second at the S10.
[01:39:22.280 --> 01:39:24.200]   Plus, I love this phone.
[01:39:24.200 --> 01:39:26.800]   I love this phone more than I've loved any phone in years.
[01:39:26.800 --> 01:39:29.480]   It's really, really good.
[01:39:29.480 --> 01:39:33.920]   The funny thing is, all of these guys initially said, "Oh, I get it.
[01:39:33.920 --> 01:39:35.800]   I see now why you want a folding phone."
[01:39:35.800 --> 01:39:39.880]   This thing is incredible until a day later broke.
[01:39:39.880 --> 01:39:41.680]   Yikes.
[01:39:41.680 --> 01:39:46.720]   Incidentally, I think a lot of people bought it because I wasn't able to.
[01:39:46.720 --> 01:39:52.480]   They had it for pre-order on the Samsung page very quickly after the pre-orders opened.
[01:39:52.480 --> 01:39:55.000]   They put up a thing saying, "We've got too many orders.
[01:39:55.000 --> 01:39:58.560]   Can't pre-order it anymore."
[01:39:58.560 --> 01:40:02.040]   Let's talk about the takedown of the takedown.
[01:40:02.040 --> 01:40:05.920]   My favorite part of the takedown is the explanation.
[01:40:05.920 --> 01:40:13.320]   Stars issued a takedown on Twitter of Torrent Freak, which is a really good site that publishes
[01:40:13.320 --> 01:40:18.680]   lots of information about sharing, bit torrents and so forth.
[01:40:18.680 --> 01:40:25.080]   They published an article about how a number of Stars TV episodes had been leaked.
[01:40:25.080 --> 01:40:29.920]   In the article, they had a thumbnail of one of the episodes, not one of the leaked episodes,
[01:40:29.920 --> 01:40:31.960]   but a thumbnail from one of the shows.
[01:40:31.960 --> 01:40:35.000]   No, that is one of the leaked ones.
[01:40:35.000 --> 01:40:38.760]   Oh, it is because it says four screeners only, and that's why they put the...
[01:40:38.760 --> 01:40:39.760]   Well, that's in the article.
[01:40:39.760 --> 01:40:43.400]   I don't know what the thumbnail on Twitter looked like, but that's in the article.
[01:40:43.400 --> 01:40:48.640]   That was for purposes of showing that these leaks probably came from screeners, right?
[01:40:48.640 --> 01:40:49.640]   Yeah.
[01:40:49.640 --> 01:40:56.920]   It was worthy.
[01:40:56.920 --> 01:41:02.480]   Stars yanked it off Twitter, claiming DMCA violation.
[01:41:02.480 --> 01:41:08.000]   Then the EFF wrote about it, and Stars pulled the EFFs.
[01:41:08.000 --> 01:41:09.300]   I think I actually tweeted about it before the EFF, not to brag, but I saw this tweet from
[01:41:09.300 --> 01:41:14.920]   Torrent Freak that said a link to their story had disappeared, that this tweet had disappeared.
[01:41:14.920 --> 01:41:21.080]   I posted something saying this is disturbing, that a link to a news story gets taken down
[01:41:21.080 --> 01:41:22.080]   because of the DMCA.
[01:41:22.080 --> 01:41:24.280]   There's no links to any of the torrents.
[01:41:24.280 --> 01:41:26.360]   There's no links to how to get them.
[01:41:26.360 --> 01:41:28.680]   It's literally just a news story.
[01:41:28.680 --> 01:41:30.600]   Then I got a notification from Twitter.
[01:41:30.600 --> 01:41:32.640]   This is Sunday afternoon.
[01:41:32.640 --> 01:41:33.640]   Your tweet's been removed.
[01:41:33.640 --> 01:41:35.720]   Oh my god, you got removed too.
[01:41:35.720 --> 01:41:36.720]   Yeah.
[01:41:36.720 --> 01:41:44.360]   Then, just because I'm that type of person, I posted a screenshot of that, of the removed
[01:41:44.360 --> 01:41:46.040]   or withheld tweet.
[01:41:46.040 --> 01:41:52.040]   I said, "Gee, it'd be too bad if a bunch of people also shared the link to this news story."
[01:41:52.040 --> 01:41:56.520]   Then that tweet was taken down.
[01:41:56.520 --> 01:42:01.680]   Matthew Ingram of the Columbia Journalism Review and the Electronic Frontier Foundation
[01:42:01.680 --> 01:42:07.960]   tweets also taken down tweets about the tweet, which in itself wasn't really a copyright
[01:42:07.960 --> 01:42:08.960]   violation.
[01:42:08.960 --> 01:42:09.960]   Unbelievable.
[01:42:09.960 --> 01:42:13.360]   I'm just told YouTube was going to take down this episode because you're talking about
[01:42:13.360 --> 01:42:14.360]   YouTube.
[01:42:14.360 --> 01:42:19.080]   YouTube's been really on a rampage taking stuff down of ours.
[01:42:19.080 --> 01:42:21.280]   But I think they have a new content ID stuff.
[01:42:21.280 --> 01:42:23.520]   It's just a little aggressive or whatever.
[01:42:23.520 --> 01:42:34.320]   So the stars explanation was that they had to source this to a third party who went overboard.
[01:42:34.320 --> 01:42:35.320]   We were hacked.
[01:42:35.320 --> 01:42:36.320]   Yeah, right.
[01:42:36.320 --> 01:42:39.520]   That's the old we were hacked.
[01:42:39.520 --> 01:42:41.920]   We were hacked.
[01:42:41.920 --> 01:42:44.200]   So they said, "Because we were hacked, we hiredâ¦"
[01:42:44.200 --> 01:42:47.760]   This makes no sense, by the way.
[01:42:47.760 --> 01:42:51.480]   It recently incurred a security breach, which prompted the company to hire a third party
[01:42:51.480 --> 01:42:55.680]   for copyright enforcement.
[01:42:55.680 --> 01:42:57.480]   Okay.
[01:42:57.480 --> 01:43:04.200]   And the third party apparently felt like the DMCA takedowns were within its scope.
[01:43:04.200 --> 01:43:05.200]   Are thereâ¦
[01:43:05.200 --> 01:43:06.200]   Is your tweet back up?
[01:43:06.200 --> 01:43:07.200]   Yeah.
[01:43:07.200 --> 01:43:12.880]   You notified me, I think, this morning maybe, or that the tweets have been restored.
[01:43:12.880 --> 01:43:15.680]   And it also said that my account would not be penalized.
[01:43:15.680 --> 01:43:17.920]   Oh, congratulations.
[01:43:17.920 --> 01:43:23.240]   So it wasn't a strike in terms of the three or four strikes or whatever you do.
[01:43:23.240 --> 01:43:24.240]   Shoo!
[01:43:24.240 --> 01:43:25.240]   Says Matthew.
[01:43:25.240 --> 01:43:26.240]   Yeah.
[01:43:26.240 --> 01:43:31.240]   I just thought it was outrageous, not just the link, the torrent free link to their story,
[01:43:31.240 --> 01:43:35.080]   but anyone who mentioned that link, other people had their Anne-Marie Brydie, who's
[01:43:35.080 --> 01:43:39.360]   an IP expert and law professor had a tweet of hers taken down.
[01:43:39.360 --> 01:43:40.360]   Jeez.
[01:43:40.360 --> 01:43:42.320]   It was just like they were going bananas.
[01:43:42.320 --> 01:43:43.320]   Yeah.
[01:43:43.320 --> 01:43:44.840]   And of course, Twitter'sâ¦
[01:43:44.840 --> 01:43:48.360]   I wrote this in the thing that I wrote for CGR about it.
[01:43:48.360 --> 01:43:55.960]   The problem is, as Anne-Marie pointed out, there is all kinds of penalties if you don't
[01:43:55.960 --> 01:43:57.160]   take stuff down.
[01:43:57.160 --> 01:44:01.480]   There is zero penalty if you do take stuff down incorrectly.
[01:44:01.480 --> 01:44:02.480]   Right.
[01:44:02.480 --> 01:44:04.920]   With this prior discussion about regulation in Europe, yes.
[01:44:04.920 --> 01:44:05.920]   Exactly.
[01:44:05.920 --> 01:44:10.240]   And so that's why the incentive is to take everything down, just in case.
[01:44:10.240 --> 01:44:13.160]   Well, clearly that's what's going on on YouTube.
[01:44:13.160 --> 01:44:14.520]   It's all going on on Twitter.
[01:44:14.520 --> 01:44:15.960]   It's going on everywhere.
[01:44:15.960 --> 01:44:19.320]   And welcome to the new world of takedowns.
[01:44:19.320 --> 01:44:21.120]   And everybody's going to see this all the time.
[01:44:21.120 --> 01:44:26.440]   And unfortunately, it's going to hit people like us hard.
[01:44:26.440 --> 01:44:28.040]   You know.
[01:44:28.040 --> 01:44:29.760]   But it was worse because it was a news story.
[01:44:29.760 --> 01:44:34.280]   I mean, this reminded me of what they call super injunctions in the UK, where if there
[01:44:34.280 --> 01:44:39.920]   is a case, a super injunction means not only can you not mention the case, you can't even
[01:44:39.920 --> 01:44:42.080]   mention that there's an injunction.
[01:44:42.080 --> 01:44:43.080]   Yeah.
[01:44:43.080 --> 01:44:45.320]   And it's a chilling effect.
[01:44:45.320 --> 01:44:46.320]   Yeah.
[01:44:46.320 --> 01:44:51.160]   It discourages people from doing what they're legally allowed to do.
[01:44:51.160 --> 01:44:54.840]   And this is just a little behind the scenes.
[01:44:54.840 --> 01:44:55.840]   This is theâ¦
[01:44:55.840 --> 01:45:01.960]   When I was playing that songify this, somebody came running in saying, "Don't play that.
[01:45:01.960 --> 01:45:03.760]   We don't want to be taken down."
[01:45:03.760 --> 01:45:04.760]   Right.
[01:45:04.760 --> 01:45:06.360]   And that's the chilling effect.
[01:45:06.360 --> 01:45:09.800]   But that's clear, fair use.
[01:45:09.800 --> 01:45:10.800]   You know that?
[01:45:10.800 --> 01:45:12.240]   I know that.
[01:45:12.240 --> 01:45:13.240]   And they know that.
[01:45:13.240 --> 01:45:14.240]   It's not a question of whetherâ¦
[01:45:14.240 --> 01:45:17.120]   And that bothers me about a lot of these.
[01:45:17.120 --> 01:45:18.120]   It's a chilling effect.
[01:45:18.120 --> 01:45:19.120]   We don't want to be taken down.
[01:45:19.120 --> 01:45:20.120]   Cost is money.
[01:45:20.120 --> 01:45:22.840]   Fair use is complicated.
[01:45:22.840 --> 01:45:24.400]   And it requires a court decision.
[01:45:24.400 --> 01:45:26.960]   And so everybody just pretends that it doesn't exist.
[01:45:26.960 --> 01:45:27.960]   Right.
[01:45:27.960 --> 01:45:31.180]   This is why we need internet courts so that these things are decided where they should
[01:45:31.180 --> 01:45:34.420]   be decided in courts.
[01:45:34.420 --> 01:45:35.580]   Well.
[01:45:35.580 --> 01:45:39.380]   Because right now they're being decided without due to justice.
[01:45:39.380 --> 01:45:40.380]   We go wrong.
[01:45:40.380 --> 01:45:41.380]   I don't know.
[01:45:41.380 --> 01:45:42.380]   Do we?
[01:45:42.380 --> 01:45:47.980]   In a way, I mean, honestly, that would be superior to what is happening, which isâ¦
[01:45:47.980 --> 01:45:48.980]   That's what this guy would say.
[01:45:48.980 --> 01:45:50.980]   I mean, the right to be forgotten.
[01:45:50.980 --> 01:45:53.620]   Who is the judge and the right to be forgotten?
[01:45:53.620 --> 01:45:54.620]   Right.
[01:45:54.620 --> 01:45:55.620]   Google.
[01:45:55.620 --> 01:45:56.620]   Yeah.
[01:45:56.620 --> 01:45:57.620]   Right.
[01:45:57.620 --> 01:45:58.620]   That's a big case.
[01:45:58.620 --> 01:45:59.620]   And there's no transparency.
[01:45:59.620 --> 01:46:00.620]   Yeah.
[01:46:00.620 --> 01:46:01.620]   There's no transparency.
[01:46:01.620 --> 01:46:02.620]   There's no due process.
[01:46:02.620 --> 01:46:09.300]   The person who proposed this from a legal world said that in society we negotiate our
[01:46:09.300 --> 01:46:11.620]   legal norms in public.
[01:46:11.620 --> 01:46:12.620]   Yeah.
[01:46:12.620 --> 01:46:14.620]   And this is happening in private companies where you have no basis.
[01:46:14.620 --> 01:46:15.620]   And it's not the company's fault.
[01:46:15.620 --> 01:46:17.620]   The companies are reinforced to this by government.
[01:46:17.620 --> 01:46:20.860]   But I couldn't believe that I was going to like this proposal.
[01:46:20.860 --> 01:46:21.860]   I like it.
[01:46:21.860 --> 01:46:22.860]   Yeah.
[01:46:22.860 --> 01:46:28.340]   The real issue is that the Constitution was written in so long ago in such a different
[01:46:28.340 --> 01:46:32.020]   era that it is increasingly becoming less.
[01:46:32.020 --> 01:46:35.860]   Be careful, my friend, because that's what people are starting to say is saying, maybe
[01:46:35.860 --> 01:46:37.700]   the First Amendment is not so great.
[01:46:37.700 --> 01:46:38.860]   And we should have less speech.
[01:46:38.860 --> 01:46:40.500]   I hate that talk.
[01:46:40.500 --> 01:46:41.500]   I hate that.
[01:46:41.500 --> 01:46:42.500]   I mean, wouldn't Internet courtsâ¦
[01:46:42.500 --> 01:46:43.500]   I mean, that'sâ¦
[01:46:43.500 --> 01:46:47.060]   Well, the Internet court would enforce the law as it exists.
[01:46:47.060 --> 01:46:48.060]   I guess it could be constitutional.
[01:46:48.060 --> 01:46:49.060]   It's just a vague crap.
[01:46:49.060 --> 01:46:50.060]   It's just a law.
[01:46:50.060 --> 01:46:51.060]   Yeah.
[01:46:51.060 --> 01:46:58.300]   Like the Brits take down in the blue-weight paper they did, take down, as you said earlier,
[01:46:58.300 --> 01:47:03.300]   trolling insult, disinformation.
[01:47:03.300 --> 01:47:05.820]   I mean, there's no question.
[01:47:05.820 --> 01:47:11.420]   There's no question that outsourcing the regulation of speech to massive platforms is
[01:47:11.420 --> 01:47:12.420]   not a great strategy.
[01:47:12.420 --> 01:47:14.420]   No, that's a bad idea.
[01:47:14.420 --> 01:47:16.060]   I'm regulating speech of any sort.
[01:47:16.060 --> 01:47:17.060]   You know, take a break.
[01:47:17.060 --> 01:47:18.060]   Let's take a break.
[01:47:18.060 --> 01:47:19.060]   And it's our last break.
[01:47:19.060 --> 01:47:21.860]   So you guys get your bits and pieces, your toys.
[01:47:21.860 --> 01:47:22.860]   Already for you.
[01:47:22.860 --> 01:47:23.860]   Trigs and berries.
[01:47:23.860 --> 01:47:24.860]   Okay, my bits together.
[01:47:24.860 --> 01:47:26.380]   And catch your bits together.
[01:47:26.380 --> 01:47:35.580]   And I will talk about the best place to exercise your right to free speech, your personal website.
[01:47:35.580 --> 01:47:40.940]   Everybody, every company ought to have a website, a place they can call their own, a place where
[01:47:40.940 --> 01:47:46.620]   your best stuff lives, a place where when people Google you, they find your site.
[01:47:46.620 --> 01:47:51.140]   I tell every teenager, "Get you to WordPress.com.
[01:47:51.140 --> 01:47:52.140]   Create a website.
[01:47:52.140 --> 01:47:53.940]   Get your domain name."
[01:47:53.940 --> 01:47:58.620]   Preferably your own name, put stuff up there so that when people search for you, they find
[01:47:58.620 --> 01:48:00.740]   your best stuff.
[01:48:00.740 --> 01:48:02.260]   It's so important.
[01:48:02.260 --> 01:48:03.700]   And if you're a business, it goes double.
[01:48:03.700 --> 01:48:09.740]   A business that's not online, practically doesn't exist.
[01:48:09.740 --> 01:48:11.380]   Now you may say, "Well, I have a Facebook page.
[01:48:11.380 --> 01:48:12.300]   I have a Twitter account.
[01:48:12.300 --> 01:48:13.500]   You need your own spot.
[01:48:13.500 --> 01:48:16.500]   Sure, you can have your Facebook page and your Twitter feed and all that stuff."
[01:48:16.500 --> 01:48:20.260]   And it should link to your website, but you got to have the website.
[01:48:20.260 --> 01:48:23.540]   And the best place to do it, the easiest place to do it, WordPress.com.
[01:48:23.540 --> 01:48:26.580]   And I know what I aware of, I speak.
[01:48:26.580 --> 01:48:29.100]   Started blogging almost 20 years ago.
[01:48:29.100 --> 01:48:31.340]   And in those days, there weren't a lot of choices.
[01:48:31.340 --> 01:48:38.140]   I used blogger and some weird programs like Gray Matter, moveable type.
[01:48:38.140 --> 01:48:42.020]   But then Matt Monlinweg came along and with WordPress and man, I fell in love.
[01:48:42.020 --> 01:48:43.980]   WordPress was amazing.
[01:48:43.980 --> 01:48:48.820]   LeoLoport.com lives on WordPress.com because they do all the heavy lifting.
[01:48:48.820 --> 01:48:49.820]   They are hosting it.
[01:48:49.820 --> 01:48:50.820]   They keep it secure.
[01:48:50.820 --> 01:48:53.940]   They even get a domain name for you.
[01:48:53.940 --> 01:48:58.380]   So you could focus on the reason you're on the web to show your best site, to build
[01:48:58.380 --> 01:49:02.380]   a fan base, start a blog, open a store, design a portfolio.
[01:49:02.380 --> 01:49:04.860]   They've got powerful site building tools that are easy to use.
[01:49:04.860 --> 01:49:06.340]   You don't have to be a geek.
[01:49:06.340 --> 01:49:07.740]   Thousands of themes.
[01:49:07.740 --> 01:49:15.820]   And the best support, 24 hours a day, even on weekends, from not page turning notebook
[01:49:15.820 --> 01:49:20.900]   jockeys, but real WordPress experts, people who use it and love it themselves.
[01:49:20.900 --> 01:49:22.860]   So they're going to have answers for you.
[01:49:22.860 --> 01:49:23.860]   They're going to have suggestions.
[01:49:23.860 --> 01:49:24.860]   They're going to have ideas.
[01:49:24.860 --> 01:49:26.980]   I even asked them what template should I use?
[01:49:26.980 --> 01:49:31.900]   And they had some great suggestions, WordPress.com.
[01:49:31.900 --> 01:49:36.500]   It lets anyone pursue whatever it is they love by launching a site that's free to start
[01:49:36.500 --> 01:49:40.420]   but can grow with you as you grow all the way up to an online store.
[01:49:40.420 --> 01:49:43.100]   No two week trials, no hidden fees.
[01:49:43.100 --> 01:49:49.540]   And WordPress users own their own content forever, upload anything, text, pictures, video, music,
[01:49:49.540 --> 01:49:51.780]   whatever you want, download it again too.
[01:49:51.780 --> 01:49:53.300]   It's never stuck.
[01:49:53.300 --> 01:49:54.780]   It's not a silo.
[01:49:54.780 --> 01:49:56.580]   It's the worldwide web baby.
[01:49:56.580 --> 01:49:58.300]   And you know what?
[01:49:58.300 --> 01:50:02.380]   It's so good that WordPress now powers 33% of the internet.
[01:50:02.380 --> 01:50:05.500]   One third of all the internet is on WordPress.
[01:50:05.500 --> 01:50:11.660]   And some of the best websites, some of the biggest publications are on WordPress.com.
[01:50:11.660 --> 01:50:15.580]   Most of people use WordPress.com every day to turn their dreams into reality.
[01:50:15.580 --> 01:50:18.020]   Why don't you go to WordPress.com/twig.
[01:50:18.020 --> 01:50:19.220]   Check it out.
[01:50:19.220 --> 01:50:23.500]   If you decide to buy a new plan, you'll get 15% off any new plan purchase with the code
[01:50:23.500 --> 01:50:24.500]   you'll find there.
[01:50:24.500 --> 01:50:27.020]   That's WordPress.com/twig.
[01:50:27.020 --> 01:50:30.900]   15% off your new website at WordPress.com/twig.
[01:50:30.900 --> 01:50:33.380]   Do use that URL so they know you heard it here.
[01:50:33.380 --> 01:50:34.500]   We thank you for your support.
[01:50:34.500 --> 01:50:37.060]   We thank WordPress.com for their support.
[01:50:37.060 --> 01:50:42.860]   Personally, I thank Matt Mullenweig for making some great software and for 12 years at WordPress.
[01:50:42.860 --> 01:50:43.860]   Amen to that, Tom.
[01:50:43.860 --> 01:50:45.740]   Yeah, Matt's a amazing guy.
[01:50:45.740 --> 01:50:46.740]   What a great guy.
[01:50:46.740 --> 01:50:47.740]   He is a great guy.
[01:50:47.740 --> 01:50:48.740]   It's a great product.
[01:50:48.740 --> 01:50:49.740]   He's a great model.
[01:50:49.740 --> 01:50:53.340]   He's a little bit like Craig Newmark where he's one of these guys who's a founder who
[01:50:53.340 --> 01:50:58.820]   just kind of quietly does his stuff and does such a great job.
[01:50:58.820 --> 01:51:01.660]   It's really cool.
[01:51:01.660 --> 01:51:04.660]   Matthew Ingram, Columbia Journalism Review.
[01:51:04.660 --> 01:51:06.860]   Share something with us.
[01:51:06.860 --> 01:51:13.140]   I think I suggested this earlier, but I sort of like the idea that when it comes to rebuilding
[01:51:13.140 --> 01:51:21.700]   Notre Dame, they may wind up using Assassin's Creed because of the designer.
[01:51:21.700 --> 01:51:27.500]   One of the designers for the game said she spent almost two years modeling the inside
[01:51:27.500 --> 01:51:30.220]   of Notre Dame for the game.
[01:51:30.220 --> 01:51:34.340]   Every brick, every piece of wood, every...
[01:51:34.340 --> 01:51:39.380]   So there's this incredible 3D model of what is now gone.
[01:51:39.380 --> 01:51:41.540]   I just find that fascinating.
[01:51:41.540 --> 01:51:43.940]   Thank goodness.
[01:51:43.940 --> 01:51:45.940]   Soon as I was...
[01:51:45.940 --> 01:51:48.700]   Here's, by the way, a picture from Assassin's Creed.
[01:51:48.700 --> 01:51:54.540]   So of the Assassin sitting on the roof looking across, what is this?
[01:51:54.540 --> 01:51:55.740]   18th century Paris?
[01:51:55.740 --> 01:51:57.780]   It looks like it at Notre Dame.
[01:51:57.780 --> 01:51:59.220]   I think so, yeah.
[01:51:59.220 --> 01:52:00.220]   Yeah.
[01:52:00.220 --> 01:52:01.220]   I love Assassin's Creed.
[01:52:01.220 --> 01:52:03.020]   I hadn't played Unity, so I'll have to...
[01:52:03.020 --> 01:52:04.700]   Actually, I think I own it.
[01:52:04.700 --> 01:52:06.100]   I'll have to download it.
[01:52:06.100 --> 01:52:12.820]   Yeah, it's during the French Revolution.
[01:52:12.820 --> 01:52:15.060]   Thank goodness.
[01:52:15.060 --> 01:52:20.180]   Of course, as I'm sure many people did, went back when I saw the fire, went back to my
[01:52:20.180 --> 01:52:24.060]   own pictures of Notre Dame for many, many visits over the years.
[01:52:24.060 --> 01:52:25.060]   And such memories.
[01:52:25.060 --> 01:52:29.260]   And as I looked inside and I saw all those wooden sculptures and, of course, the beautiful
[01:52:29.260 --> 01:52:33.300]   rose windows and I thought, "Oh my God, I hope this isn't lost."
[01:52:33.300 --> 01:52:36.540]   I think this big rose window here on the south faces say...
[01:52:36.540 --> 01:52:39.620]   It sounds like the rose windows are relatively safe.
[01:52:39.620 --> 01:52:40.620]   All of the rose windows.
[01:52:40.620 --> 01:52:41.620]   All of them?
[01:52:41.620 --> 01:52:42.620]   All of them are safe.
[01:52:42.620 --> 01:52:47.260]   What they don't know is what impact the fire had on the masonry.
[01:52:47.260 --> 01:52:48.260]   Right.
[01:52:48.260 --> 01:52:49.260]   So the wood is gone for sure.
[01:52:49.260 --> 01:52:50.260]   Yeah.
[01:52:50.260 --> 01:52:51.260]   But they don't know.
[01:52:51.260 --> 01:52:55.460]   I mean, it's 800 year old, you know, plaster.
[01:52:55.460 --> 01:52:57.900]   It's unclear what heat would do to that.
[01:52:57.900 --> 01:52:58.900]   Wow.
[01:52:58.900 --> 01:53:01.300]   This model is very complete.
[01:53:01.300 --> 01:53:02.300]   Look at this.
[01:53:02.300 --> 01:53:03.300]   Yeah, it's amazing.
[01:53:03.300 --> 01:53:04.300]   This is...
[01:53:04.300 --> 01:53:05.300]   Yeah.
[01:53:05.300 --> 01:53:12.100]   I hope they don't put the cannons back, but the rest of it, that's very cool.
[01:53:12.100 --> 01:53:18.420]   I didn't realize that the gargoyles, most of them are relatively modern.
[01:53:18.420 --> 01:53:20.980]   So I thought they dated back to the 30th century.
[01:53:20.980 --> 01:53:23.980]   Yeah, there was a big remodel in the 19th century, right?
[01:53:23.980 --> 01:53:24.980]   Yeah.
[01:53:24.980 --> 01:53:25.980]   Yeah.
[01:53:25.980 --> 01:53:26.980]   I have a series.
[01:53:26.980 --> 01:53:27.980]   I had that...
[01:53:27.980 --> 01:53:33.580]   So you know the rooster that was on top of the steel part of the spire?
[01:53:33.580 --> 01:53:34.580]   No.
[01:53:34.580 --> 01:53:40.020]   So there was a rooster right at the very, very top of the metal pole on the spire.
[01:53:40.020 --> 01:53:47.060]   And when they put that there in 1935, they put bits of various saints into the rooster.
[01:53:47.060 --> 01:53:48.060]   Oh, how funny.
[01:53:48.060 --> 01:53:49.060]   Yeah.
[01:53:49.060 --> 01:53:52.340]   And so the idea was it was going to be like a spiritual lightning rod.
[01:53:52.340 --> 01:53:54.340]   So they would protect the church.
[01:53:54.340 --> 01:53:55.340]   Yikes.
[01:53:55.340 --> 01:53:56.340]   And the rooster...
[01:53:56.340 --> 01:53:57.340]   The Catholics are very much.
[01:53:57.340 --> 01:53:58.340]   Yeah.
[01:53:58.340 --> 01:54:03.860]   The rooster survived and the crown of thorns was...
[01:54:03.860 --> 01:54:06.500]   Can you imagine being the priest who went in...
[01:54:06.500 --> 01:54:08.060]   You had to go get it.
[01:54:08.060 --> 01:54:09.460]   And there was the fire department chapter.
[01:54:09.460 --> 01:54:11.060]   He was the head of the fire brigade, yeah.
[01:54:11.060 --> 01:54:16.420]   It was the same guy who ran into the Bataclan nightclub after the mass shooting there.
[01:54:16.420 --> 01:54:20.540]   But can you imagine being that guy and he's carrying in his hands whether you believe
[01:54:20.540 --> 01:54:22.460]   it's the actual crown of thorns or not?
[01:54:22.460 --> 01:54:24.220]   He probably does.
[01:54:24.220 --> 01:54:26.220]   The crown of thorns.
[01:54:26.220 --> 01:54:31.180]   I remember going to when I was in Italy, we went into the catacombs.
[01:54:31.180 --> 01:54:33.420]   I think it was a CZ.
[01:54:33.420 --> 01:54:39.180]   And so St. Francis is there and there are all these relics, bits and pieces of fingers
[01:54:39.180 --> 01:54:43.500]   and toes and whatnot that were passed around for centuries.
[01:54:43.500 --> 01:54:50.060]   And the guy who was doing the tour said, "Every church like this has bits and pieces of what
[01:54:50.060 --> 01:54:51.780]   they say are the true cross."
[01:54:51.780 --> 01:54:52.780]   Right.
[01:54:52.780 --> 01:54:57.620]   And all those bits together, you could build a shopping mall.
[01:54:57.620 --> 01:55:03.500]   There was a very brisk business in relic wall, in relic wall, in the middle ages.
[01:55:03.500 --> 01:55:06.380]   It's kind of hard to know what the provenance of any of that stuff is.
[01:55:06.380 --> 01:55:11.380]   We were in the church in Pisa, it's where the leaning thing is.
[01:55:11.380 --> 01:55:14.060]   But it's actually got a beautiful church as well.
[01:55:14.060 --> 01:55:20.260]   And in the church, there is St. Can't remember his name now, but he's the patron saint.
[01:55:20.260 --> 01:55:24.260]   And so they have him in a sarcophagus on top of the altar.
[01:55:24.260 --> 01:55:28.900]   And it describes how they basically, one guy had to go around and pick up bits of him from
[01:55:28.900 --> 01:55:32.940]   all over the country and then try and put him back together.
[01:55:32.940 --> 01:55:34.220]   This is a fun job.
[01:55:34.220 --> 01:55:38.580]   This is from the grand front door at Notre Dame and you could see how much detail in the
[01:55:38.580 --> 01:55:41.980]   carvings and it would be so sad if that had been lost.
[01:55:41.980 --> 01:55:45.780]   I'm so glad that it's preserved.
[01:55:45.780 --> 01:55:48.780]   I also didn't know one of the towers is a little taller than the other.
[01:55:48.780 --> 01:55:49.780]   Yes.
[01:55:49.780 --> 01:55:53.540]   I don't know if that was intentional.
[01:55:53.540 --> 01:55:56.820]   Sometimes you see that with perspective.
[01:55:56.820 --> 01:55:59.060]   What was it?
[01:55:59.060 --> 01:56:00.060]   Was it the Parthenon?
[01:56:00.060 --> 01:56:04.580]   I think it's the Parthenon where it's actually built a skew just so that it doesn't look
[01:56:04.580 --> 01:56:09.260]   like it's fallen over when you look up at it.
[01:56:09.260 --> 01:56:13.740]   These Greeks, Jeff Jarvis, you've got four different things.
[01:56:13.740 --> 01:56:14.740]   I got two.
[01:56:14.740 --> 01:56:18.860]   I'm going to do my favorite onion headline in quite a while.
[01:56:18.860 --> 01:56:23.820]   "Sheet Buddha Judge Stuns Campaign Crowd" by speaking to manufacturing robots, "Influent
[01:56:23.820 --> 01:56:24.820]   Binary."
[01:56:24.820 --> 01:56:25.820]   Nice.
[01:56:25.820 --> 01:56:27.820]   "South Bend Mayor."
[01:56:27.820 --> 01:56:30.380]   I almost believe it.
[01:56:30.380 --> 01:56:31.380]   His French was excellent.
[01:56:31.380 --> 01:56:32.380]   He did his French.
[01:56:32.380 --> 01:56:35.220]   His Norwegian is excellent too.
[01:56:35.220 --> 01:56:36.220]   Oh man.
[01:56:36.220 --> 01:56:43.420]   So 0101111007, said the 37-year-old South Bend had the animator, the awestruck machines,
[01:56:43.420 --> 01:56:47.460]   delivering the message by admitting a series of high-pitched tones and beats with the perfect
[01:56:47.460 --> 01:56:48.460]   accent.
[01:56:48.460 --> 01:56:49.460]   Nice.
[01:56:49.460 --> 01:56:55.940]   I'll bet if you somehow decoded the binary, it actually says something I'm sure.
[01:56:55.940 --> 01:56:59.940]   At press time, US manufacturing robots had donated $10 million.
[01:56:59.940 --> 01:57:04.620]   "Buddajedge's Campaign" helped surge to the top of the polls.
[01:57:04.620 --> 01:57:05.620]   That is great.
[01:57:05.620 --> 01:57:10.580]   Are you trading in your Kamala hat for a Buddha judge?
[01:57:10.580 --> 01:57:11.580]   No, no, no, no.
[01:57:11.580 --> 01:57:12.580]   I'm still Kamala.
[01:57:12.580 --> 01:57:13.580]   I'm still Kamala.
[01:57:13.580 --> 01:57:14.580]   Kamala.
[01:57:14.580 --> 01:57:15.580]   I think.
[01:57:15.580 --> 01:57:21.140]   Harris "Buddajedge" has weird as a pupper sticker as that would be.
[01:57:21.140 --> 01:57:22.140]   Killer.
[01:57:22.140 --> 01:57:23.540]   Would be a killer team.
[01:57:23.540 --> 01:57:25.660]   Would be Kamala Pete.
[01:57:25.660 --> 01:57:31.540]   But the other thing, Leo, since you are so eager to constantly protest social media, I
[01:57:31.540 --> 01:57:33.740]   finally have the way that you can do it in public.
[01:57:33.740 --> 01:57:34.740]   I'm joining this.
[01:57:34.740 --> 01:57:35.900]   There's only one condition.
[01:57:35.900 --> 01:57:36.900]   Yes.
[01:57:36.900 --> 01:57:38.380]   You have to do it naked.
[01:57:38.380 --> 01:57:39.380]   Oh, what?
[01:57:39.380 --> 01:57:45.100]   Spencer Tunic, who does all these famous naked people on the house.
[01:57:45.100 --> 01:57:46.100]   I've seen his pictures.
[01:57:46.100 --> 01:57:47.100]   Yeah.
[01:57:47.100 --> 01:57:51.340]   He's going to do one in New York to protest censorship on social media.
[01:57:51.340 --> 01:57:54.100]   It's called, what the hell was it I missed it now?
[01:57:54.100 --> 01:57:57.100]   It has a hashtag already.
[01:57:57.100 --> 01:58:00.100]   Hashtag, we even nipple.
[01:58:00.100 --> 01:58:01.100]   We even nipple.
[01:58:01.100 --> 01:58:02.100]   Okay.
[01:58:02.100 --> 01:58:04.100]   This was like a full-time job.
[01:58:04.100 --> 01:58:08.100]   It was a very Canadian moment there for Matthew.
[01:58:08.100 --> 01:58:09.100]   Okay.
[01:58:09.100 --> 01:58:10.100]   Okay.
[01:58:10.100 --> 01:58:11.100]   Okay.
[01:58:11.100 --> 01:58:14.100]   I just love those names Spencer Tunic.
[01:58:14.100 --> 01:58:19.100]   I am not coming out for that.
[01:58:19.100 --> 01:58:21.700]   I'm just going to tell you right now.
[01:58:21.700 --> 01:58:23.700]   No, no, ain't nobody want to see that.
[01:58:23.700 --> 01:58:25.580]   But you've been doing the keto thing.
[01:58:25.580 --> 01:58:29.260]   You're probably in, you're ripped probably now.
[01:58:29.260 --> 01:58:30.260]   If only.
[01:58:30.260 --> 01:58:33.220]   Notice, I'm sitting in front of all these cupcakes.
[01:58:33.220 --> 01:58:34.220]   Cupcakes.
[01:58:34.220 --> 01:58:35.220]   Yeah.
[01:58:35.220 --> 01:58:36.860]   Say your staff is torturing you.
[01:58:36.860 --> 01:58:39.620]   I feel no, I feel nothing.
[01:58:39.620 --> 01:58:40.620]   Yeah.
[01:58:40.620 --> 01:58:41.620]   That's cool.
[01:58:41.620 --> 01:58:42.620]   Right.
[01:58:42.620 --> 01:58:45.140]   I have no, no urges or anything.
[01:58:45.140 --> 01:58:47.620]   No, no, just, just there.
[01:58:47.620 --> 01:58:49.340]   They don't speak to me anymore.
[01:58:49.340 --> 01:58:55.260]   Ladies and gentlemen, that concludes this thrilling and gripping edition of this week
[01:58:55.260 --> 01:58:57.620]   in Google.
[01:58:57.620 --> 01:59:03.620]   Mr. Gelato and Perugia, Matthew Ingram, we thank you so much for joining us.
[01:59:03.620 --> 01:59:05.220]   Chief Digital Writer at CJR.org.
[01:59:05.220 --> 01:59:06.780]   Thank you for having me.
[01:59:06.780 --> 01:59:08.260]   On short notice, no less.
[01:59:08.260 --> 01:59:09.420]   We appreciate that.
[01:59:09.420 --> 01:59:10.420]   Thank you.
[01:59:10.420 --> 01:59:14.940]   Jeff Jarvis, Professor of Journalism at the City University of New York.
[01:59:14.940 --> 01:59:15.940]   Great to have you.
[01:59:15.940 --> 01:59:16.940]   TV Guide.
[01:59:16.940 --> 01:59:17.940]   Form a TV Guide.
[01:59:17.940 --> 01:59:18.940]   That was all this.
[01:59:18.940 --> 01:59:22.980]   I was on my tombstone.
[01:59:22.980 --> 01:59:28.980]   The joke there is that when we last saw Jeff on MSNBC for reasons no one understands,
[01:59:28.980 --> 01:59:31.540]   that was his lower third title.
[01:59:31.540 --> 01:59:35.140]   Former TV Guide critic and blogger Jeff Jones.
[01:59:35.140 --> 01:59:36.140]   Wow.
[01:59:36.140 --> 01:59:37.380]   It's all true.
[01:59:37.380 --> 01:59:38.380]   It's not untrue.
[01:59:38.380 --> 01:59:39.380]   Yeah.
[01:59:39.380 --> 01:59:40.980]   I believe it leads to yours.
[01:59:40.980 --> 01:59:42.380]   Yeah, faint praise.
[01:59:42.380 --> 01:59:43.380]   Yeah.
[01:59:43.380 --> 01:59:44.380]   Thank you, everybody.
[01:59:44.380 --> 01:59:50.980]   I'm going to go smoke my meat, but we're glad you tuned in for this week in Google.
[01:59:50.980 --> 01:59:56.020]   We do the show every Wednesday afternoon, 130 Pacific, 430 Eastern, 2030 UTC.
[01:59:56.020 --> 01:59:59.500]   You can watch or listen live at twit.tv/live.
[01:59:59.500 --> 02:00:03.100]   Download on-demand versions of the show at twit.tv/twig.
[02:00:03.100 --> 02:00:08.420]   But the best thing, the thing that would make my heart go pitapat is if you would subscribe
[02:00:08.420 --> 02:00:11.500]   in your favorite podcatcher that does a number of things.
[02:00:11.500 --> 02:00:15.660]   First of all, guarantees you'll have the show the minute it comes out so you can get
[02:00:15.660 --> 02:00:18.180]   on your other Thursday morning commute.
[02:00:18.180 --> 02:00:22.700]   It also tells the creator of that podcast application that we're popular.
[02:00:22.700 --> 02:00:25.660]   And often that helps us get high in the directories there.
[02:00:25.660 --> 02:00:28.020]   And it also helps with our downloads.
[02:00:28.020 --> 02:00:29.300]   We know that you're watching.
[02:00:29.300 --> 02:00:32.420]   It gives us a signal that people want us to keep doing that show.
[02:00:32.420 --> 02:00:35.820]   So please subscribe in your favorite podcast application.
[02:00:35.820 --> 02:00:36.820]   Thank you for watching.
[02:00:36.820 --> 02:00:38.140]   And we'll see you next time.
[02:00:38.140 --> 02:00:39.140]   And this week in Google.
[02:00:39.140 --> 02:00:40.140]   Bye-bye.
[02:00:40.140 --> 02:00:47.140]   [ Music ]
[02:00:47.140 --> 02:00:50.160]   [Music]

