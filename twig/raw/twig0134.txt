;FFMETADATA1
album=This Week In Google
artist=Leo Laporte, Jeff Jarvis and Gina Trapani
iTunPGAP=0
comment=http://twit.tv/twig134
encoded_by=iTunes v7.0
genre=Tech News
TGID=http://www.podtrac.com/pts/redirect.mp3/twit.cachefly.net/twig0115.mp3
TDES=Hosts: Leo Laporte, Jeff Jarvis, and Gina Trapani\
\
Apple's iPhone 4S keynote, what is PhoneGap, \# on Google +, Google won't screw up Android, and more cloud news.\
\
Download or subscribe to this show at twit.tv/twig.\
\
We invite you to read, add to, and amend our show notes.\
\
Friendfeed links for this episode.\
\
Thanks to Cachefly for the bandwidth for this show.\
\
Running time: 1:29:14
track=134
title=This Week In Google 134: The Leather Bounded Skymall
date=2012
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:08.000]   It's time for Twig this week in Google. Kevin Marks will join us to dissect the whole privacy policy issue with iOS apps.
[00:00:08.000 --> 00:00:13.000]   We'll also talk about why Google might be setting up an antenna farm in Omaha.
[00:00:13.000 --> 00:00:16.000]   It's all coming up next on Twig.
[00:00:16.000 --> 00:00:21.000]   Netcast you love.
[00:00:21.000 --> 00:00:23.000]   From people you trust.
[00:00:23.000 --> 00:00:28.000]   This is Twig.
[00:00:29.000 --> 00:00:37.000]   Bandwidth for this week in Google is provided by CashFly, C-A-C-H-E-F-L-Y.com.
[00:00:37.000 --> 00:00:41.000]   This is Twig. This week in Google.
[00:00:41.000 --> 00:00:47.000]   Recorded February 15th, 2012. The leather-bound Sky Mall.
[00:00:47.000 --> 00:00:56.000]   This week in Google is brought to you by Ford, featuring the EcoBoost engine with turbocharger and direct injection.
[00:00:56.000 --> 00:01:01.000]   Look for EcoBoost on the 2012 Ford Explorer and Edge and the 2013 Escape.
[00:01:01.000 --> 00:01:05.000]   And of course at Ford.com/technology.
[00:01:05.000 --> 00:01:16.000]   It's time for Twig this week in Google and a great panel as always because we've got our regulars, Gina Trippani from SmarterWare.org and ThinkUpApp.
[00:01:16.000 --> 00:01:22.000]   And Jeff Jarvis, professor of journalism at the City University of New York, the author of what would Google do, his newest public parts.
[00:01:22.000 --> 00:01:32.000]   And of course he blogs at Buzzmachine.com. And we add to the mix the great giant brain of Kevin Marks, who is at Tumblevision.tv.
[00:01:32.000 --> 00:01:35.000]   Look at it. You can even see it's giant. It's a giant brain.
[00:01:35.000 --> 00:01:40.000]   So this is the big brain show. I've always said that. Thanks for joining us, Kevin.
[00:01:40.000 --> 00:01:41.000]   I'll try.
[00:01:41.000 --> 00:01:42.000]   You actually...
[00:01:42.000 --> 00:01:44.000]   The orange is behind your apples.
[00:01:44.000 --> 00:01:45.000]   Orange is...
[00:01:45.000 --> 00:01:47.000]   Welcome to California.
[00:01:47.000 --> 00:01:57.000]   Once again, Kevin is killing us by broadcasting from out of the woods with birds chirping and like, you know, trees swaying in the wind behind him.
[00:01:57.000 --> 00:02:00.000]   It's very... It's inspirational people. We should all go outside.
[00:02:00.000 --> 00:02:06.000]   Was it grapes of wrath? I can't remember. But this is how my parents got me to move from Rhode Island to California.
[00:02:06.000 --> 00:02:09.000]   They said, and I think this was... They ripped it off from grapes of wrath.
[00:02:09.000 --> 00:02:12.000]   You'll be able to go outside and pluck an orange from the tree.
[00:02:12.000 --> 00:02:13.000]   I could do that.
[00:02:13.000 --> 00:02:14.000]   You could do this.
[00:02:14.000 --> 00:02:15.000]   It was the avocado tree that got me.
[00:02:15.000 --> 00:02:16.000]   The avocado tree that got me.
[00:02:16.000 --> 00:02:17.000]   The avocado trees?
[00:02:17.000 --> 00:02:18.000]   Yeah.
[00:02:18.000 --> 00:02:19.000]   The avocado tree is pretty good.
[00:02:19.000 --> 00:02:22.000]   They have to try to get in the water plant and diet.
[00:02:22.000 --> 00:02:23.000]   Oh.
[00:02:23.000 --> 00:02:25.000]   Well, you need two, I think. They have to pollinate.
[00:02:25.000 --> 00:02:26.000]   Ah.
[00:02:26.000 --> 00:02:27.000]   That's why.
[00:02:27.000 --> 00:02:30.000]   And, of course, the best is Meyer Lemons.
[00:02:30.000 --> 00:02:31.000]   You should have a tire.
[00:02:31.000 --> 00:02:32.000]   Yes, I have a mire lemon.
[00:02:32.000 --> 00:02:34.000]   Orchard of Meyer Lemons.
[00:02:34.000 --> 00:02:36.000]   Sorry, Jeff.
[00:02:36.000 --> 00:02:38.000]   [laughter]
[00:02:38.000 --> 00:02:41.000]   I just came back from Montreal.
[00:02:41.000 --> 00:02:42.000]   Oh, God.
[00:02:42.000 --> 00:02:44.000]   It's covered with salt on the streets.
[00:02:44.000 --> 00:02:47.000]   It's a wonderful city, but the salt was as thick as snow.
[00:02:47.000 --> 00:02:51.000]   And I slipped and fell in it and just felt like this white ghost.
[00:02:51.000 --> 00:02:52.000]   Oh.
[00:02:52.000 --> 00:02:54.000]   It's a bad time to go to Montreal.
[00:02:54.000 --> 00:02:56.000]   That's life in the winter here.
[00:02:56.000 --> 00:02:58.000]   So, Kevin, put a screen up behind you.
[00:02:58.000 --> 00:02:59.000]   That's what he's like.
[00:02:59.000 --> 00:03:00.000]   [laughter]
[00:03:00.000 --> 00:03:05.000]   Kevin actually asked to join us because he had worked on Google content.
[00:03:05.000 --> 00:03:08.000]   When you were at Google, Kevin is currently at Salesforce.
[00:03:08.000 --> 00:03:12.000]   And he, in between, he was at BT, doing the RIBIT product.
[00:03:12.000 --> 00:03:21.000]   But before that, not so long ago, you were at Google working on profiles and various open--
[00:03:21.000 --> 00:03:22.000]   Open social.
[00:03:22.000 --> 00:03:24.000]   So, part of that was Google contact.
[00:03:24.000 --> 00:03:27.000]   So, I was, yeah, I'm very interested in the whole address book.
[00:03:27.000 --> 00:03:28.000]   The privacy thing.
[00:03:28.000 --> 00:03:34.000]   And that thing, I'll tell you, has just gone crazy even since we talked last week.
[00:03:34.000 --> 00:03:38.000]   It all started when a hacker discovered by using MIT proxy.
[00:03:38.000 --> 00:03:43.480]   He was looking at the traffic coming out of path, discovered that path was uploading the
[00:03:43.480 --> 00:03:50.880]   entire contact database from his phone, doing it with HTTPS.
[00:03:50.880 --> 00:03:53.600]   So, it was encrypted as it was going up.
[00:03:53.600 --> 00:03:56.880]   At the time, there was quite a few arose.
[00:03:56.880 --> 00:04:03.520]   I personally, on this show, I think last week, said, "What did you think they were doing?"
[00:04:03.520 --> 00:04:06.520]   There have been articles written saying, "Well, they could have hashed it."
[00:04:06.520 --> 00:04:10.600]   And it's true, they could have hashed addresses and then compared them with a hash on their
[00:04:10.600 --> 00:04:13.160]   own sign there by protecting privacy.
[00:04:13.160 --> 00:04:18.520]   We've also learned that path not only uploaded them, but kept them for some time.
[00:04:18.520 --> 00:04:23.840]   Dave Moran issued a maya culpa and said, "We're not changed path.
[00:04:23.840 --> 00:04:26.840]   They upgraded it and said, 'We're not going to do it anymore and we're not going to keep
[00:04:26.840 --> 00:04:30.000]   it anymore and we're going to give you a nice big warning."
[00:04:30.000 --> 00:04:31.000]   Instagram.
[00:04:31.000 --> 00:04:36.320]   What you feel like is a whole bunch of other programs immediately scuttled for cover because,
[00:04:36.320 --> 00:04:43.160]   of course, as I had presumed, a widespread practice.
[00:04:43.160 --> 00:04:48.720]   Instagram immediately without saying much changed their upload to "Warn You" ahead of
[00:04:48.720 --> 00:04:50.080]   time.
[00:04:50.080 --> 00:04:52.560]   And now, along our Twitter...
[00:04:52.560 --> 00:04:57.960]   Well, we've now found out that Twitter keeps it for 18 months on the iPhone.
[00:04:57.960 --> 00:05:00.760]   Four Square did it right in the first place.
[00:05:00.760 --> 00:05:05.720]   They've always put a warning up and they only keep it while they're doing the check.
[00:05:05.720 --> 00:05:11.760]   Wouldn't doing it right, though, Kevin B. hashing it?
[00:05:11.760 --> 00:05:13.760]   It depends.
[00:05:13.760 --> 00:05:16.360]   The question is, what are you afraid of?
[00:05:16.360 --> 00:05:18.360]   This comes down to what you're actually afraid of.
[00:05:18.360 --> 00:05:24.080]   Well, and that was my response when somebody tweeted, "Well, they read the Ryan Tate article
[00:05:24.080 --> 00:05:25.080]   on Gawker.
[00:05:25.080 --> 00:05:26.080]   Dave Moran lied."
[00:05:26.080 --> 00:05:28.880]   And I said, "Well, what are you worried about?
[00:05:28.880 --> 00:05:29.880]   They have your stuff."
[00:05:29.880 --> 00:05:31.160]   Yeah, where's the harm?
[00:05:31.160 --> 00:05:37.200]   Are you saying, "Are you asserting the path of selling your email address or information?"
[00:05:37.200 --> 00:05:40.800]   Did you read Arrington's big dogs, Billy, post about this?
[00:05:40.800 --> 00:05:45.280]   Well, and we can go on because MG Seagler and Arrington wrote about it, both of them,
[00:05:45.280 --> 00:05:50.800]   by the way, and per principles and tech crunch, which is a path investor.
[00:05:50.800 --> 00:05:55.360]   And then that got all heated up because then fake Steve Jobs, Dan Lyons wrote an article
[00:05:55.360 --> 00:06:00.800]   saying something about MG being a yapping dog, ankle biter, I think a particularly vicious
[00:06:00.800 --> 00:06:01.800]   ankle biter.
[00:06:01.800 --> 00:06:02.800]   So I think is what he said.
[00:06:02.800 --> 00:06:04.720]   This was such a weak and tech talk.
[00:06:04.720 --> 00:06:05.720]   Oh, really?
[00:06:05.720 --> 00:06:06.720]   Yes.
[00:06:06.720 --> 00:06:07.720]   Oh, I mean, it really made me go.
[00:06:07.720 --> 00:06:12.080]   I'm so glad I just, I do twig and I'm not in that the game of, well, anyway, sorry,
[00:06:12.080 --> 00:06:13.080]   I mean, it's a direct talk.
[00:06:13.080 --> 00:06:14.080]   I agree.
[00:06:14.080 --> 00:06:15.080]   I agree.
[00:06:15.080 --> 00:06:21.480]   In fact, my Twitter response was, you know, my tweeted response was something like, "There's
[00:06:21.480 --> 00:06:26.120]   some irony in MG bemoaning the state of tech journalism.
[00:06:26.120 --> 00:06:27.120]   Fine.
[00:06:27.120 --> 00:06:28.120]   Get out of it.
[00:06:28.120 --> 00:06:33.520]   I've been doing this since 1978 without any of these problems.
[00:06:33.520 --> 00:06:38.440]   If you don't like it, go leave."
[00:06:38.440 --> 00:06:41.680]   But to go back to the question of what's the harm, and we talked about this last week,
[00:06:41.680 --> 00:06:47.640]   I think this is less a discussion about privacy and more a question of permission versus forgiveness.
[00:06:47.640 --> 00:06:48.640]   Right?
[00:06:48.640 --> 00:06:52.240]   So I don't feel like there's any harm in one of these companies having a copy of my address
[00:06:52.240 --> 00:06:53.240]   book per se.
[00:06:53.240 --> 00:06:57.440]   I felt betrayed that these apps were doing this without letting me know.
[00:06:57.440 --> 00:07:01.880]   So for me, this is more about a really, actually, I think it was, it was incredible progress.
[00:07:01.880 --> 00:07:03.480]   I mean, the community policed itself.
[00:07:03.480 --> 00:07:04.960]   You know, there was this expose.
[00:07:04.960 --> 00:07:05.960]   This is what's going on.
[00:07:05.960 --> 00:07:07.360]   The app doesn't let you know.
[00:07:07.360 --> 00:07:12.160]   It was a violation of Apple's terms, which say an app should let a user know when personal
[00:07:12.160 --> 00:07:13.640]   data is being transmitted.
[00:07:13.640 --> 00:07:16.000]   And then all these other apps said, "Oh, you know what?
[00:07:16.000 --> 00:07:17.400]   We should be doing this this way."
[00:07:17.400 --> 00:07:18.400]   Oops.
[00:07:18.400 --> 00:07:19.400]   We're going to use HTTPS.
[00:07:19.400 --> 00:07:22.800]   We're going to hash and we're going to, in the user flow, let you know.
[00:07:22.800 --> 00:07:26.200]   And I think another big point for me that came out of this, because my first reaction
[00:07:26.200 --> 00:07:27.760]   was, "Well, this is Apple's fault.
[00:07:27.760 --> 00:07:28.760]   iOS is insecure."
[00:07:28.760 --> 00:07:29.760]   I agree.
[00:07:29.760 --> 00:07:34.160]   And it has this great permissions model where when you install an app, it asks you, "You know,
[00:07:34.160 --> 00:07:38.960]   Android's permissions model is better than Apple's, but it became really clear that asking
[00:07:38.960 --> 00:07:41.800]   for permission on installation isn't good enough."
[00:07:41.800 --> 00:07:45.040]   I mean, I still have this experience where I'm like installing Pandora, and I'm like,
[00:07:45.040 --> 00:07:46.960]   "Why do they need my address book?
[00:07:46.960 --> 00:07:47.960]   It's a music app."
[00:07:47.960 --> 00:07:52.520]   I think it's come through that these permissions have to be, the user should be prompted within
[00:07:52.520 --> 00:07:53.520]   the flow.
[00:07:53.520 --> 00:07:54.520]   Each time.
[00:07:54.520 --> 00:07:55.520]   Okay, I'm trying to find my friends.
[00:07:55.520 --> 00:07:56.520]   Yes.
[00:07:56.520 --> 00:07:57.520]   Can I scan my address book?
[00:07:57.520 --> 00:07:58.520]   And I think that that's really...
[00:07:58.520 --> 00:07:59.520]   I'm not...
[00:07:59.520 --> 00:08:02.480]   I think you're right, Gina, but isn't that a fairly recent skill, right?
[00:08:02.480 --> 00:08:06.880]   Google+, we talked about this a month ago when Google+ started, is that, and Facebook
[00:08:06.880 --> 00:08:11.720]   was doing the same thing, where you shift to asking at the moment of sharing is, I think,
[00:08:11.720 --> 00:08:17.360]   a fairly recent standard that's actually more recent than these services setting this up.
[00:08:17.360 --> 00:08:20.360]   So I think Leo is right, well, how else do we do it?
[00:08:20.360 --> 00:08:25.520]   You're right that it wasn't open and transparent enough, but I also think that this is something
[00:08:25.520 --> 00:08:26.520]   we're learning.
[00:08:26.520 --> 00:08:28.800]   It's the whole industry's beta.
[00:08:28.800 --> 00:08:30.040]   That is true.
[00:08:30.040 --> 00:08:32.240]   We all are learning, but it is a really good question.
[00:08:32.240 --> 00:08:34.080]   I mean, this is the Zuckerberg approach, right?
[00:08:34.080 --> 00:08:37.360]   It's like, push the boundaries, do stuff that you're not really sure how users are going
[00:08:37.360 --> 00:08:41.480]   to react, and then if there's an uproar, or apologize afterwards, this was...
[00:08:41.480 --> 00:08:45.680]   The permissions, asking permission versus asking for forgiveness approach.
[00:08:45.680 --> 00:08:52.440]   And I really admire companies that we're in a whole new era of data and mobility and connectivity,
[00:08:52.440 --> 00:08:54.640]   and these are things that we are learning.
[00:08:54.640 --> 00:09:00.600]   We are all learning, but it is difficult for me to not feel a little bit betrayed.
[00:09:00.600 --> 00:09:05.280]   Like, hey, I love Four Square, and they're doing this, or Twitter's doing this.
[00:09:05.280 --> 00:09:09.080]   In the end, Facebook was the verge that a great story, and they were like, Facebook
[00:09:09.080 --> 00:09:10.520]   is the white knight in all of this.
[00:09:10.520 --> 00:09:12.640]   Their social graph is all API-based.
[00:09:12.640 --> 00:09:15.040]   They don't have to use your address book, because they already know what your social
[00:09:15.040 --> 00:09:16.040]   graph is.
[00:09:16.040 --> 00:09:18.080]   Yeah, I'm not sure I bought it through the white knight.
[00:09:18.080 --> 00:09:20.880]   They're the white knight only because they already have all that information, right?
[00:09:20.880 --> 00:09:24.400]   Right, and they thought it would be a little after doing this, because they have to compete
[00:09:24.400 --> 00:09:25.400]   with Facebook, right?
[00:09:25.400 --> 00:09:27.880]   These little apps are doing this because they need...
[00:09:27.880 --> 00:09:28.880]   They need...
[00:09:28.880 --> 00:09:30.600]   They are really by the white knight thing, yeah.
[00:09:30.600 --> 00:09:31.600]   Go ahead, Kevin.
[00:09:31.600 --> 00:09:34.960]   Well, so, I mean, there's a bunch of things about this.
[00:09:34.960 --> 00:09:39.840]   One is that the basic problem is that email addresses and phone numbers are insecure anyway.
[00:09:39.840 --> 00:09:41.200]   They're barotokens.
[00:09:41.200 --> 00:09:45.400]   If you have one, you can contact someone, and then you have to install countermeasures
[00:09:45.400 --> 00:09:47.480]   to fight them off.
[00:09:47.480 --> 00:09:49.800]   My home phone number never gets any real phone calls anymore.
[00:09:49.800 --> 00:09:52.920]   It just gets robots to ring me up to annoy me.
[00:09:52.920 --> 00:09:53.920]   And the...
[00:09:53.920 --> 00:09:57.720]   But the model has changed over time.
[00:09:57.720 --> 00:10:00.320]   There's this shocking book that gets shipped to my door that has a phone number everywhere
[00:10:00.320 --> 00:10:01.880]   in town once a year.
[00:10:01.880 --> 00:10:02.880]   And the address...
[00:10:02.880 --> 00:10:03.880]   How dare they?
[00:10:03.880 --> 00:10:04.880]   How dare they address?
[00:10:04.880 --> 00:10:08.640]   They fact you have to pay...
[00:10:08.640 --> 00:10:12.360]   I was incensed when many years ago I wanted an endless number and found out you had to
[00:10:12.360 --> 00:10:14.840]   pay monthly not to be in that book.
[00:10:14.840 --> 00:10:16.600]   That's the model of paying for privacy.
[00:10:16.600 --> 00:10:22.040]   But that was somewhat suggested is where this might head, that you pay to get out of certain
[00:10:22.040 --> 00:10:24.280]   things, which I think is a bit ridiculous.
[00:10:24.280 --> 00:10:25.280]   But...
[00:10:25.280 --> 00:10:29.000]   But it's a model we've used.
[00:10:29.000 --> 00:10:30.000]   But that...
[00:10:30.000 --> 00:10:34.440]   That norm has changed because those phones were attached to buildings.
[00:10:34.440 --> 00:10:35.840]   They're not in your pocket.
[00:10:35.840 --> 00:10:38.280]   And so as we move to mobile phones, the norm changed.
[00:10:38.280 --> 00:10:40.160]   We don't publish all the mobile phone numbers.
[00:10:40.160 --> 00:10:42.720]   We hand them around to construct our own address books and share them.
[00:10:42.720 --> 00:10:45.680]   We don't have a centralized registry.
[00:10:45.680 --> 00:10:51.120]   You know, that norm changed almost invisibly, but it actually makes sense to us.
[00:10:51.120 --> 00:10:55.520]   The other norm is the personal versus business contact information.
[00:10:55.520 --> 00:10:59.280]   The part of the point of a business card is you're handing out a separate contact thing
[00:10:59.280 --> 00:11:03.480]   that isn't your home, that isn't your personal phone number.
[00:11:03.480 --> 00:11:09.120]   It was a corporate facade to have business conversations that are partitioned away from
[00:11:09.120 --> 00:11:10.400]   personal conversations.
[00:11:10.400 --> 00:11:15.160]   And that's also being broken down by the mobile phone as well, because suddenly you're probably
[00:11:15.160 --> 00:11:18.640]   handing out your cell phone instead.
[00:11:18.640 --> 00:11:20.160]   And so that sort of...
[00:11:20.160 --> 00:11:22.200]   The norms are in transition here.
[00:11:22.200 --> 00:11:26.760]   And so people don't pay much attention to it until it comes back and bites them.
[00:11:26.760 --> 00:11:27.760]   And Gina...
[00:11:27.760 --> 00:11:30.960]   I might quibble a little bit with your word betrayed.
[00:11:30.960 --> 00:11:32.400]   I think it's a little bit strong.
[00:11:32.400 --> 00:11:36.000]   I don't think that there was any ill intent from these companies.
[00:11:36.000 --> 00:11:37.000]   Disseal.
[00:11:37.000 --> 00:11:38.000]   And even to see.
[00:11:38.000 --> 00:11:40.600]   I think what it was is that you felt...
[00:11:40.600 --> 00:11:42.520]   I don't know what the word is now.
[00:11:42.520 --> 00:11:43.520]   Miss Led?
[00:11:43.520 --> 00:11:44.520]   Miss Led?
[00:11:44.520 --> 00:11:45.520]   Well, I wasn't informed.
[00:11:45.520 --> 00:11:46.520]   I just wasn't told.
[00:11:46.520 --> 00:11:47.520]   Well, yeah.
[00:11:47.520 --> 00:11:49.160]   I think it was, you know, surprised.
[00:11:49.160 --> 00:11:50.480]   You don't want to be surprised.
[00:11:50.480 --> 00:11:51.480]   It's a holiday in rule.
[00:11:51.480 --> 00:11:52.480]   Right.
[00:11:52.480 --> 00:11:53.480]   And as a public...
[00:11:53.480 --> 00:11:54.480]   Right.
[00:11:54.480 --> 00:11:57.800]   With good intent, they want to offer a service.
[00:11:57.800 --> 00:11:58.800]   They didn't think about it.
[00:11:58.800 --> 00:12:00.360]   They kept the addresses around.
[00:12:00.360 --> 00:12:02.560]   They didn't think far enough.
[00:12:02.560 --> 00:12:06.160]   And when it came out, you said, "Whoa, shouldn't you guys have thought?"
[00:12:06.160 --> 00:12:07.320]   So you were disappointed.
[00:12:07.320 --> 00:12:08.880]   I would argue as much as anything else.
[00:12:08.880 --> 00:12:13.040]   I was disappointed, but I have to tell you, I think that any ethical developer is going
[00:12:13.040 --> 00:12:19.080]   to stop and think when it involves transmitting a user's address book over the wire.
[00:12:19.080 --> 00:12:22.920]   I mean, Marco R. Mann, who created Instapaper, who's cranky and I don't agree with him and
[00:12:22.920 --> 00:12:24.920]   everything, but he wrote this post.
[00:12:24.920 --> 00:12:29.520]   He said, "When I was developing Instapaper, I was very surprised at how much access Apple
[00:12:29.520 --> 00:12:31.840]   gave me to the address book by default.
[00:12:31.840 --> 00:12:36.920]   And I felt kind of dirty when I implemented the Find Friends feature, which just does
[00:12:36.920 --> 00:12:38.800]   it, lets you know, and get...
[00:12:38.800 --> 00:12:42.240]   And I grabbed the addresses and I discard them immediately and I get out of there as
[00:12:42.240 --> 00:12:45.880]   fast as I can because I feel kind of weird being in there and doing that.
[00:12:45.880 --> 00:12:48.960]   And I mean, as a developer, I think I would feel the same way.
[00:12:48.960 --> 00:12:53.040]   I would expect some level of creepy feeling about that.
[00:12:53.040 --> 00:12:55.720]   But I think Dave was like, "Oh, all the apps do this.
[00:12:55.720 --> 00:13:00.360]   This is what we need to have a competitive advantage as an upstart social network to compete against
[00:13:00.360 --> 00:13:02.360]   the likes of Facebook and Twitter.
[00:13:02.360 --> 00:13:03.720]   We need to do this.
[00:13:03.720 --> 00:13:04.880]   Finding Friends is really important.
[00:13:04.880 --> 00:13:06.800]   We have to have people come back to this app.
[00:13:06.800 --> 00:13:11.160]   So we're just going to do it even if that whole thing about how it might be a little
[00:13:11.160 --> 00:13:13.000]   creepy, we're just not going to..."
[00:13:13.000 --> 00:13:14.000]   And that feels...
[00:13:14.000 --> 00:13:15.560]   That's what I felt disappointed in.
[00:13:15.560 --> 00:13:18.160]   I don't think that it should be any surprise that...
[00:13:18.160 --> 00:13:22.360]   I think if somebody says, "Oops, we didn't think of that.
[00:13:22.360 --> 00:13:23.360]   You're right.
[00:13:23.360 --> 00:13:24.360]   Get it.
[00:13:24.360 --> 00:13:25.360]   We shouldn't have done that."
[00:13:25.360 --> 00:13:29.280]   Hey, think better next time versus justifying the behavior.
[00:13:29.280 --> 00:13:30.280]   Right.
[00:13:30.280 --> 00:13:37.120]   But I think the system worked because it was discovered, path immediately, as Mike Harrington
[00:13:37.120 --> 00:13:42.320]   said, on his back and stuck his belly up and said, "I'm sorry, fix it."
[00:13:42.320 --> 00:13:47.400]   And as a result, a lot of apps who didn't really do much of a maya culpa quietly fixed
[00:13:47.400 --> 00:13:48.400]   it.
[00:13:48.400 --> 00:13:49.400]   So...
[00:13:49.400 --> 00:13:52.520]   It was great to see the community police itself in this way.
[00:13:52.520 --> 00:13:54.200]   I think it all worked.
[00:13:54.200 --> 00:13:55.960]   But the risk here is...
[00:13:55.960 --> 00:13:57.440]   Sorry, Janet, go ahead.
[00:13:57.440 --> 00:13:58.440]   No, no, go ahead.
[00:13:58.440 --> 00:14:00.800]   Well, the risk here is I hold my hands the...
[00:14:00.800 --> 00:14:02.520]   I'm not going to do it again, folks.
[00:14:02.520 --> 00:14:06.160]   But these are Vivian Reddy's regulations in 100-some pages.
[00:14:06.160 --> 00:14:11.760]   And in there, one of them is that a company is required to gather the minimum data and
[00:14:11.760 --> 00:14:16.280]   keep it for the minimum amount of time necessary for a specific business task.
[00:14:16.280 --> 00:14:19.640]   And again, as with all these things, that sounds good.
[00:14:19.640 --> 00:14:25.320]   But in that case, the New York Times couldn't gather information on your travel content
[00:14:25.320 --> 00:14:30.360]   behavior and the hope they're going to get advertisers in the future.
[00:14:30.360 --> 00:14:34.200]   There's something to having data that teaches a company something that they don't yet know
[00:14:34.200 --> 00:14:35.400]   they're going to learn.
[00:14:35.400 --> 00:14:39.280]   Now, if it's my own addresses, okay, that's different.
[00:14:39.280 --> 00:14:44.880]   But I think we've got to be careful of restricting knowledge so much that it's just presumed
[00:14:44.880 --> 00:14:45.880]   to be bad.
[00:14:45.880 --> 00:14:47.800]   It's stranger danger comes to data.
[00:14:47.800 --> 00:14:53.120]   Aren't we moving, Kevin, into the big data era where companies see this huge amount of
[00:14:53.120 --> 00:14:54.720]   value in data mining?
[00:14:54.720 --> 00:14:59.760]   And so there's strong incentive now for companies to do this.
[00:14:59.760 --> 00:15:03.840]   But I do think that it's important that we have a permissions-based system.
[00:15:03.840 --> 00:15:04.840]   Right.
[00:15:04.840 --> 00:15:09.800]   And the difference is that things have actually got better.
[00:15:09.800 --> 00:15:12.960]   The previous model was, give me your login, right?
[00:15:12.960 --> 00:15:16.880]   It used to be when you signed up for Facebook or anything else to give us your login.
[00:15:16.880 --> 00:15:19.760]   Give us your username and password for Google and we'll go and login as you and get the
[00:15:19.760 --> 00:15:20.760]   stuff out.
[00:15:20.760 --> 00:15:26.240]   Give us your username and password for Yahoo and Microsoft and whatever, Mac.com, and we'll
[00:15:26.240 --> 00:15:28.040]   get the stuff out that way.
[00:15:28.040 --> 00:15:30.760]   And that was horribly broken and very dangerous.
[00:15:30.760 --> 00:15:33.760]   That meant they could actually completely masquerade as you.
[00:15:33.760 --> 00:15:39.360]   And we fixed that by inventing OAuth so that you can now explicitly give an app permission
[00:15:39.360 --> 00:15:41.840]   to get a certain set of things and not other things.
[00:15:41.840 --> 00:15:45.560]   But at the time we were implementing what we were competing with was that model.
[00:15:45.560 --> 00:15:49.880]   So to begin with, the default permissions were you can get everything you could have
[00:15:49.880 --> 00:15:52.600]   got through having the password.
[00:15:52.600 --> 00:15:54.160]   You can get the whole address book.
[00:15:54.160 --> 00:15:58.840]   You can have a separate API to send email address, email and so on.
[00:15:58.840 --> 00:16:02.000]   But you wanted to make sure it was actually competitive because they actually want the
[00:16:02.000 --> 00:16:03.520]   user's email address.
[00:16:03.520 --> 00:16:06.320]   And potentially they wanted your friends email addresses too.
[00:16:06.320 --> 00:16:11.720]   Facebook bought Octogen, which is the company that wrote all the scrapers that did this.
[00:16:11.720 --> 00:16:14.000]   Because this was a big part of how Facebook built up their grant.
[00:16:14.000 --> 00:16:15.000]   How interesting.
[00:16:15.000 --> 00:16:16.000]   It was interesting.
[00:16:16.000 --> 00:16:18.480]   So there you go.
[00:16:18.480 --> 00:16:19.600]   So there's, yeah.
[00:16:19.600 --> 00:16:25.920]   But there's, and Gmail gathers everyone in every email and puts it in a list.
[00:16:25.920 --> 00:16:28.520]   And that's the database that you have access to.
[00:16:28.520 --> 00:16:32.960]   And that was an issue when we first synced iPhones with Google contacts.
[00:16:32.960 --> 00:16:35.840]   Because suddenly anyone you'd ever email appeared in your iPhone, everyone would cross
[00:16:35.840 --> 00:16:36.840]   about it.
[00:16:36.840 --> 00:16:41.000]   Because they didn't want that set, they wanted a different subset.
[00:16:41.000 --> 00:16:43.840]   And then they deleted them all from their iPhone and then the order completes stop working
[00:16:43.840 --> 00:16:44.840]   Gmail.
[00:16:44.840 --> 00:16:49.000]   So there's, there is some awkward complexity about this.
[00:16:49.000 --> 00:16:50.200]   And yeah, I work for Salesforce.
[00:16:50.200 --> 00:16:54.280]   So big chunk of what Salesforce does is contact management, keeping track of the people you're
[00:16:54.280 --> 00:16:57.000]   selling to your customers and stuff like that.
[00:16:57.000 --> 00:17:03.060]   We have a site called data.com, which is a business directory that is like the phone
[00:17:03.060 --> 00:17:04.060]   book.
[00:17:04.060 --> 00:17:06.320]   You can look up people's current contact information in it.
[00:17:06.320 --> 00:17:08.760]   You can update it and move stuff in and out of that.
[00:17:08.760 --> 00:17:11.880]   And there's APIs and models for doing that as well.
[00:17:11.880 --> 00:17:16.440]   So there are, there's a whole set of things that working different domains.
[00:17:16.440 --> 00:17:22.920]   But the tricky thing is when people feel like they're, that's always been done without
[00:17:22.920 --> 00:17:23.920]   their knowledge.
[00:17:23.920 --> 00:17:25.360]   That's the hard part of it.
[00:17:25.360 --> 00:17:29.880]   But the other part is that these things exist in this awkward space that's in between us.
[00:17:29.880 --> 00:17:32.960]   Me having, you know, Leo's phone number is one.
[00:17:32.960 --> 00:17:35.200]   Me having a scale with phone number doesn't matter because he's on the web anyway.
[00:17:35.200 --> 00:17:39.800]   But me having someone who keeps the secrets phone number is useful to me.
[00:17:39.800 --> 00:17:40.800]   But a problem.
[00:17:40.800 --> 00:17:43.400]   Do you see the, and dead mouse and squillix thing at the Grammys?
[00:17:43.400 --> 00:17:44.680]   Yeah, this is a great story.
[00:17:44.680 --> 00:17:50.400]   So dead mouse and Skrilix were both well known dubstep DJs.
[00:17:50.400 --> 00:17:58.000]   Dead mouse, they, and friends by the way, wore a t-shirt to the Grammys with Skrilix's
[00:17:58.000 --> 00:18:01.080]   phone number on it.
[00:18:01.080 --> 00:18:03.520]   And the tagline, you mad bro.
[00:18:03.520 --> 00:18:09.720]   I think this was somehow a Twitter attribute to Skrilix.
[00:18:09.720 --> 00:18:13.960]   It did in fact win the Grammy for best remix.
[00:18:13.960 --> 00:18:18.440]   Skrilix tried to turn off, turn on call forwarding.
[00:18:18.440 --> 00:18:22.760]   So, and I guess didn't successfully do so.
[00:18:22.760 --> 00:18:23.760]   He tried to forward it.
[00:18:23.760 --> 00:18:25.720]   I gathered it to dead mouse.
[00:18:25.720 --> 00:18:32.480]   And then even if you call the phone number, it's right now a full voicemail box and no
[00:18:32.480 --> 00:18:35.760]   chance of leaving a message yourself.
[00:18:35.760 --> 00:18:39.040]   But that, you know, and dead mouse said, no, I thought, I thought about all of this.
[00:18:39.040 --> 00:18:42.920]   I knew exactly what I was doing.
[00:18:42.920 --> 00:18:45.280]   Wow.
[00:18:45.280 --> 00:18:47.000]   What was the point?
[00:18:47.000 --> 00:18:48.000]   I don't know.
[00:18:48.000 --> 00:18:49.000]   Maybe I don't take.
[00:18:49.000 --> 00:18:50.000]   It's so in Skrilix.
[00:18:50.000 --> 00:18:51.000]   Yeah.
[00:18:51.000 --> 00:18:54.000]   So, yeah, it was just, it was, it was a couple of guys, you know, this was a guy who was
[00:18:54.000 --> 00:18:57.000]   towel snapping, I guess, was the phrase I should use.
[00:18:57.000 --> 00:19:00.800]   And then so Skrilix tries to call forward it to dead mouse.
[00:19:00.800 --> 00:19:05.720]   Dead mouse call forwards it back to Skrilix.
[00:19:05.720 --> 00:19:07.120]   It's all a good fun.
[00:19:07.120 --> 00:19:14.320]   My, my son asked me once to give out his cell phone number on my Twitter feed.
[00:19:14.320 --> 00:19:15.800]   Just he said, well, do you think people text me?
[00:19:15.800 --> 00:19:18.200]   I said, yeah, yeah, they will.
[00:19:18.200 --> 00:19:19.200]   And so he said, we'll do it.
[00:19:19.200 --> 00:19:20.200]   I said, well, no.
[00:19:20.200 --> 00:19:21.280]   And so I did.
[00:19:21.280 --> 00:19:26.040]   And his phone started vibrating and vibrated so much it just fell off the table and continue
[00:19:26.040 --> 00:19:27.040]   to do that.
[00:19:27.040 --> 00:19:30.840]   He would clear it and it would do it all again.
[00:19:30.840 --> 00:19:33.800]   And so finally, I don't know, I don't think he ever changed his phone number.
[00:19:33.800 --> 00:19:36.600]   I think it just, we just went away.
[00:19:36.600 --> 00:19:38.760]   Well, unfortunately, your listeners have memories.
[00:19:38.760 --> 00:19:39.760]   God knows his problem.
[00:19:39.760 --> 00:19:40.760]   I get calls all the time.
[00:19:40.760 --> 00:19:41.760]   I'll get a call.
[00:19:41.760 --> 00:19:44.960]   If I ask for a call, I'll get, I'll get 20 calls right now on this cell phone number.
[00:19:44.960 --> 00:19:46.520]   He's not asking folks.
[00:19:46.520 --> 00:19:47.520]   He's not asking.
[00:19:47.520 --> 00:19:48.960]   Gina, can I ask?
[00:19:48.960 --> 00:19:50.560]   I'm just curious.
[00:19:50.560 --> 00:19:52.840]   So you're setting a standard here, right?
[00:19:52.840 --> 00:19:56.440]   So the obvious, the first layer of being asked is when you sign into the service, it
[00:19:56.440 --> 00:19:58.400]   says we're going to ask for the stuff.
[00:19:58.400 --> 00:20:01.440]   And people say, okay, and they want the service, right?
[00:20:01.440 --> 00:20:03.120]   So they don't pay attention.
[00:20:03.120 --> 00:20:07.640]   So then I think you're saying is at the moment you choose to use that function of saying,
[00:20:07.640 --> 00:20:12.760]   okay, I want to know who I know is in here, then I should tell you, right, that I'm going
[00:20:12.760 --> 00:20:16.880]   to upload your address and I'm going to keep it for an amount of time, right?
[00:20:16.880 --> 00:20:17.880]   Right.
[00:20:17.880 --> 00:20:20.640]   Or say, we're going to scan your address book, but we don't keep this data.
[00:20:20.640 --> 00:20:21.640]   That's one of the problems.
[00:20:21.640 --> 00:20:22.640]   Whichever it does.
[00:20:22.640 --> 00:20:23.640]   But it has to tell you.
[00:20:23.640 --> 00:20:24.640]   Yes.
[00:20:24.640 --> 00:20:25.640]   It does tell you.
[00:20:25.640 --> 00:20:31.000]   The next question I would have is, do you presume some proportion of people won't read
[00:20:31.000 --> 00:20:32.000]   this?
[00:20:32.000 --> 00:20:35.080]   So let's say that they do keep it for 18 months because they do think it's a service and you
[00:20:35.080 --> 00:20:38.240]   did agree to it, but they presume you kind of didn't know that in six months.
[00:20:38.240 --> 00:20:41.080]   They say, hey, you know, we still have your addresses.
[00:20:41.080 --> 00:20:44.760]   You know, where do you think the standard ought to go?
[00:20:44.760 --> 00:20:46.600]   So there was some practice like that.
[00:20:46.600 --> 00:20:53.280]   I mean, if you some of the location services will remind you that Google attitude does send
[00:20:53.280 --> 00:20:55.880]   you an email every so often saying, by the way, we still got your stuff.
[00:20:55.880 --> 00:20:57.680]   Yeah, I like that that Google does.
[00:20:57.680 --> 00:21:02.840]   Yeah, I think the the the the the the the the Yahoo service.
[00:21:02.840 --> 00:21:04.800]   The Yahoo service.
[00:21:04.800 --> 00:21:07.000]   The original was fire eagle.
[00:21:07.000 --> 00:21:08.000]   Thank you.
[00:21:08.000 --> 00:21:09.000]   Yes.
[00:21:09.000 --> 00:21:10.000]   Sorry, Tom Coats.
[00:21:10.000 --> 00:21:11.000]   The late lamented fire.
[00:21:11.000 --> 00:21:16.160]   That established a whole bunch of good precedents around that around how you should handle location
[00:21:16.160 --> 00:21:20.640]   well and part of it was will notify you every so often that, you know, who's got it and
[00:21:20.640 --> 00:21:21.640]   where.
[00:21:21.640 --> 00:21:25.480]   And the issue with, you know, one of the things that's possible with with the OAuth model
[00:21:25.480 --> 00:21:29.960]   is because it's not a password because it's actually a token that is bound to the application,
[00:21:29.960 --> 00:21:34.400]   you can know when that application last accessed your information.
[00:21:34.400 --> 00:21:36.840]   And some of the services show this is some of them don't Facebook.
[00:21:36.840 --> 00:21:40.200]   I think we'll show you when the app last used use that stuff.
[00:21:40.200 --> 00:21:43.440]   I'm not sure that the Google and Twitter give you as much of a good readout of when they
[00:21:43.440 --> 00:21:44.440]   touched it.
[00:21:44.440 --> 00:21:45.920]   But that's actually really important, really useful to know.
[00:21:45.920 --> 00:21:49.680]   It'd be really nice if there was a like a developer dashboard that said, here's here's
[00:21:49.680 --> 00:21:53.600]   the API calls that they made to get your information and what they were looking at and
[00:21:53.600 --> 00:21:54.600]   when.
[00:21:54.600 --> 00:21:55.600]   So they're reading my direct messages.
[00:21:55.600 --> 00:21:57.080]   I wasn't expecting them to do that.
[00:21:57.080 --> 00:22:00.440]   And you know, that will be a nice geeky thing for us to look at.
[00:22:00.440 --> 00:22:02.560]   And those of us who care about it.
[00:22:02.560 --> 00:22:05.800]   But it's still and great for any of the developers too.
[00:22:05.800 --> 00:22:07.280]   So they wouldn't have to sniff the H2G.
[00:22:07.280 --> 00:22:13.880]   I think Apple now is as asking for more explicit.
[00:22:13.880 --> 00:22:16.760]   This is a part of their app store on the desktop.
[00:22:16.760 --> 00:22:22.360]   They're going to ask for more explicit permissions when you first write the application.
[00:22:22.360 --> 00:22:25.120]   It's actually part of the SDK.
[00:22:25.120 --> 00:22:27.160]   You have to check the boxes.
[00:22:27.160 --> 00:22:28.160]   Let Apple know.
[00:22:28.160 --> 00:22:29.160]   Apple will let you know.
[00:22:29.160 --> 00:22:32.520]   Now the interesting thing, and I do blame Apple a little bit for this, is that it was
[00:22:32.520 --> 00:22:34.680]   against Apple's TOS.
[00:22:34.680 --> 00:22:39.800]   Apple does for instance warn you with locations, but they never warned anybody.
[00:22:39.800 --> 00:22:42.880]   Great posting from Dustin Curtis on his blog.
[00:22:42.880 --> 00:22:46.640]   He says, I did a quick survey of 15 popular iOS apps.
[00:22:46.640 --> 00:22:51.320]   13 of them told me they have contacts database with millions of records.
[00:22:51.320 --> 00:22:55.200]   One company's database has Mark Zuckerberg's cell phone number, Larry Ellison's home phone
[00:22:55.200 --> 00:22:59.000]   number and Bill Gates cell phone number.
[00:22:59.000 --> 00:23:01.240]   So any, you know, those apps are changing.
[00:23:01.240 --> 00:23:07.160]   Apple today essentially acknowledged your point, Lisa, by saying, from now on, we are
[00:23:07.160 --> 00:23:08.640]   going to require this.
[00:23:08.640 --> 00:23:09.640]   Yeah.
[00:23:09.640 --> 00:23:10.640]   That's good.
[00:23:10.640 --> 00:23:11.640]   Do they just release a statement today?
[00:23:11.640 --> 00:23:12.640]   Yes.
[00:23:12.640 --> 00:23:14.280]   It's amazing that there's no piece out of them.
[00:23:14.280 --> 00:23:16.520]   Yeah, they're doing their measure twice thing.
[00:23:16.520 --> 00:23:17.520]   It took them a bit.
[00:23:17.520 --> 00:23:18.520]   So good.
[00:23:18.520 --> 00:23:19.520]   I'm really glad to hear that.
[00:23:19.520 --> 00:23:25.720]   First, I don't think for a standard, just find your friends on the social network function.
[00:23:25.720 --> 00:23:28.720]   As far as I'm concerned, you shouldn't have to store my data.
[00:23:28.720 --> 00:23:32.720]   Scan my address book once, let me know who's in at that moment in time, and then in a month
[00:23:32.720 --> 00:23:36.640]   or two inside the app prompt me, say, hey, a few more, few more of your friends might
[00:23:36.640 --> 00:23:38.400]   be here, you know, check again.
[00:23:38.400 --> 00:23:39.400]   That's a good idea.
[00:23:39.400 --> 00:23:40.400]   Yes or no?
[00:23:40.400 --> 00:23:41.400]   Yes.
[00:23:41.400 --> 00:23:43.960]   If you have a feature that you do need to store the data, then yeah, I think saying, you
[00:23:43.960 --> 00:23:48.120]   know, hey, we store this on our servers for six months, like we'll check with you then.
[00:23:48.120 --> 00:23:51.880]   Someone in the chat room brought up a really good point, which is that Windows Vista suffered
[00:23:51.880 --> 00:23:54.920]   from the, you know, too many permissions model, right?
[00:23:54.920 --> 00:23:55.920]   Yes, it was.
[00:23:55.920 --> 00:23:57.880]   I mean, it was so difficult to use Vista, right?
[00:23:57.880 --> 00:24:00.280]   And I don't think it should be that bad.
[00:24:00.280 --> 00:24:03.160]   I mean, there's a good way to implement permissions in a bad way.
[00:24:03.160 --> 00:24:08.960]   But in terms of address book access, absolutely should have been built into the SDK in TIO
[00:24:08.960 --> 00:24:12.000]   S, and I'm really glad to hear that Apple's doing that.
[00:24:12.000 --> 00:24:16.400]   And to the point of, you know, Apple's review process, having been through it myself, Apple
[00:24:16.400 --> 00:24:24.160]   will reject your app if the curve of the rounded corner on your icon isn't correct,
[00:24:24.160 --> 00:24:25.160]   right?
[00:24:25.160 --> 00:24:30.640]   So the fact that they, that knowing that and that they didn't test these apps to see what
[00:24:30.640 --> 00:24:32.440]   data that they were sending a little wire.
[00:24:32.440 --> 00:24:33.440]   I think they knew, Gina.
[00:24:33.440 --> 00:24:34.440]   They knew.
[00:24:34.440 --> 00:24:35.440]   You think that they knew?
[00:24:35.440 --> 00:24:36.920]   I think they were complicit.
[00:24:36.920 --> 00:24:41.080]   I think that that's really the revelation here is that is fit.
[00:24:41.080 --> 00:24:46.080]   And I presume this last week, and it's been confirmed now, that it's a widespread practice
[00:24:46.080 --> 00:24:48.680]   is considered normal behavior.
[00:24:48.680 --> 00:24:51.880]   Apple perfectly well knew it and didn't.
[00:24:51.880 --> 00:24:56.560]   But with the subscriptions model, they're so protective of user data, how they want to
[00:24:56.560 --> 00:24:59.600]   be the only ones who have your, you know, email address.
[00:24:59.600 --> 00:25:03.560]   I think that's because they want to cut off the business for the for the distribution
[00:25:03.560 --> 00:25:04.560]   seller.
[00:25:04.560 --> 00:25:05.560]   That's different.
[00:25:05.560 --> 00:25:06.560]   Yeah, that's a different.
[00:25:06.560 --> 00:25:07.560]   Yeah.
[00:25:07.560 --> 00:25:09.360]   I think that Apple, I'm not going to blame them.
[00:25:09.360 --> 00:25:12.840]   Maybe they felt prey to the same thing that Dave Moore and others did, which is as a moving
[00:25:12.840 --> 00:25:16.320]   target and mores, you know, are not clear.
[00:25:16.320 --> 00:25:20.720]   And perhaps they just didn't, you know, they assumed that this would be understood and
[00:25:20.720 --> 00:25:21.720]   okay.
[00:25:21.720 --> 00:25:22.720]   I don't know.
[00:25:22.720 --> 00:25:23.800]   I'm not going to, I'm not going to scribe.
[00:25:23.800 --> 00:25:26.400]   I don't know what their intent is, but I bet you anything that they knew.
[00:25:26.400 --> 00:25:27.400]   Of course they knew.
[00:25:27.400 --> 00:25:28.720]   I think there's a transition.
[00:25:28.720 --> 00:25:30.960]   I mean, there's a, there's a transition in permission models.
[00:25:30.960 --> 00:25:35.440]   I'm talking about VISTAs and Mac OS permissions is a good point.
[00:25:35.440 --> 00:25:38.480]   You know, the classic computer thing is that you run a program running computer.
[00:25:38.480 --> 00:25:44.600]   You can touch anything on the disk in memory anywhere, or any code, install anything anywhere.
[00:25:44.600 --> 00:25:47.120]   And that is something that is changing.
[00:25:47.120 --> 00:25:50.400]   And then you have, instead you have effectively what we call capability based security.
[00:25:50.400 --> 00:25:53.680]   You say this app wants to be able to do X, Y and Z.
[00:25:53.680 --> 00:25:57.600]   And the, you know, the Facebook permissions model gives, you know, calls those out for
[00:25:57.600 --> 00:25:58.600]   you.
[00:25:58.600 --> 00:26:01.800]   The Android install model calls us out for you and is built around this capability security
[00:26:01.800 --> 00:26:05.440]   model that says this app wants to be able to do X, Y, Z and W.
[00:26:05.440 --> 00:26:08.600]   If it changes with an update, it says you've got to manually agree to this again.
[00:26:08.600 --> 00:26:09.600]   That's right.
[00:26:09.600 --> 00:26:10.600]   And it'll tell you what's true.
[00:26:10.600 --> 00:26:11.600]   I like that.
[00:26:11.600 --> 00:26:14.080]   And the other part of that is that that provides some insulation.
[00:26:14.080 --> 00:26:19.000]   I think part of the reason that the address book is accessible on the, um, the iOS is
[00:26:19.000 --> 00:26:23.320]   that they don't have a share this service the way they do an Android.
[00:26:23.320 --> 00:26:27.480]   Um, you know, an Android, there's a share this service for any app and then hook into
[00:26:27.480 --> 00:26:30.000]   and be, be able to share things.
[00:26:30.000 --> 00:26:33.200]   Um, on iOS, each app is effective in doing that themselves.
[00:26:33.200 --> 00:26:37.160]   So they have to, you know, call the email browser and it's, it's much more like a sort
[00:26:37.160 --> 00:26:40.720]   of classic, um, Mac OS issue of, okay, I'm going to call this thing now.
[00:26:40.720 --> 00:26:42.560]   Now I did access to the address book to do this.
[00:26:42.560 --> 00:26:43.960]   And so they just brought that world view with them.
[00:26:43.960 --> 00:26:47.800]   I'm not sure they, they're actually, you know, bumped into this particular issue.
[00:26:47.800 --> 00:26:50.120]   Um, but that was, that was just as a natural way of doing it.
[00:26:50.120 --> 00:26:55.680]   I suspect the similar thing that went on with, with path and, and co was that their primary
[00:26:55.680 --> 00:26:59.760]   model was probably, um, you know, path used to make you sign up with Facebook.
[00:26:59.760 --> 00:27:00.760]   I think they changed that.
[00:27:00.760 --> 00:27:05.840]   Their primary model was we will use Facebook and Twitter as the distributed contact store.
[00:27:05.840 --> 00:27:09.000]   And then once you've got permission there, you're able to go back and redip and get that
[00:27:09.000 --> 00:27:10.000]   again.
[00:27:10.000 --> 00:27:12.400]   So when they built the email thing, they made it behave the same way.
[00:27:12.400 --> 00:27:14.520]   They'd probably put a wrapper around the, do I know this?
[00:27:14.520 --> 00:27:15.520]   Interesting.
[00:27:15.520 --> 00:27:17.520]   And then implemented that, that with the email.
[00:27:17.520 --> 00:27:18.520]   I think it's very right.
[00:27:18.520 --> 00:27:19.520]   Yeah.
[00:27:19.520 --> 00:27:22.520]   Then the answer was, oh, well, we need to have a copy of this to check it again later because
[00:27:22.520 --> 00:27:26.280]   we, we do want to poll this every couple of weeks and suggest new friends to people.
[00:27:26.280 --> 00:27:30.500]   Um, so I suspect is one of those like, we have this world view that's based on this new
[00:27:30.500 --> 00:27:32.400]   model, a little, a little, a little, a little more.
[00:27:32.400 --> 00:27:33.400]   Yeah.
[00:27:33.400 --> 00:27:34.400]   I think that's right.
[00:27:34.400 --> 00:27:35.400]   There's a danger here.
[00:27:35.400 --> 00:27:38.280]   The, the vista thing that you bring up, I think it's really important is, is that we
[00:27:38.280 --> 00:27:43.280]   are going to get ranks to regulation a lot more demands for opt in.
[00:27:43.280 --> 00:27:45.240]   And so we're going to go tick crazy.
[00:27:45.240 --> 00:27:50.040]   We're going to be told to tick off constantly because some, some lawyer and some legal,
[00:27:50.040 --> 00:27:53.480]   you know, compliance with regulation is going to say that no, no, no, it's not good enough
[00:27:53.480 --> 00:27:56.120]   just to tell you you have to acknowledge.
[00:27:56.120 --> 00:27:57.120]   And so it's that crap.
[00:27:57.120 --> 00:28:00.220]   Every time I go into Starbucks and I've got to say, yeah, yeah, yeah, yeah, I won't do
[00:28:00.220 --> 00:28:01.220]   bad things.
[00:28:01.220 --> 00:28:02.220]   And just want to just take me to the Wi-Fi.
[00:28:02.220 --> 00:28:03.220]   Right?
[00:28:03.220 --> 00:28:04.220]   Even that upsets me.
[00:28:04.220 --> 00:28:08.740]   And we're going to, we're going to have a tick madness hit us, um, constantly going
[00:28:08.740 --> 00:28:11.220]   to sites and sharing data and all kinds of things.
[00:28:11.220 --> 00:28:15.500]   Here's an interesting blog post, Kevin, uh, put in the chat.
[00:28:15.500 --> 00:28:20.620]   Um, on another way to possibly solve this, this comes from a book that O'Reilly is going
[00:28:20.620 --> 00:28:25.260]   to publish called building web reputation systems, a Randy farmer in Bryce Glass.
[00:28:25.260 --> 00:28:31.140]   Uh, he said, they say that, you know, the problem is this, you know, uh, consent dialogue
[00:28:31.140 --> 00:28:32.860]   fatigue.
[00:28:32.860 --> 00:28:39.700]   Um, so they suggest because you are being asked to make a trust decision that reputation
[00:28:39.700 --> 00:28:41.780]   might help solve this.
[00:28:41.780 --> 00:28:44.620]   Kevin, would you explain what they propose?
[00:28:44.620 --> 00:28:45.620]   Sure.
[00:28:45.620 --> 00:28:48.940]   So this was, this kind of discussion we had at, um, inside the workshop a couple of years
[00:28:48.940 --> 00:28:49.940]   ago, maybe.
[00:28:49.940 --> 00:28:53.500]   Um, and the issue is you get these permission dialogues and the default reaction was just
[00:28:53.500 --> 00:28:54.980]   a yes to them because it's in the way.
[00:28:54.980 --> 00:28:55.980]   Okay.
[00:28:55.980 --> 00:28:56.980]   Okay.
[00:28:56.980 --> 00:28:57.980]   Yes.
[00:28:57.980 --> 00:28:58.980]   Yeah.
[00:28:58.980 --> 00:29:02.620]   It reminds you back, back in the day when you use Photoshop, you had to say, okay, three
[00:29:02.620 --> 00:29:03.740]   times to save a file.
[00:29:03.740 --> 00:29:04.740]   Right.
[00:29:04.740 --> 00:29:08.900]   Um, and I watched my graphic designer friends go bang, bang, bang, bang, bang, right?
[00:29:08.900 --> 00:29:10.940]   Without before the dialogue would finish drawing.
[00:29:10.940 --> 00:29:13.300]   And so when it says something else, like the disc is full, they don't really say bang,
[00:29:13.300 --> 00:29:14.940]   bang, bang, and they don't want to wait and save.
[00:29:14.940 --> 00:29:17.020]   Um, because you get habituated into that.
[00:29:17.020 --> 00:29:21.780]   And that was the problem with the original Facebook permissions model is this, that wants,
[00:29:21.780 --> 00:29:23.300]   wants to do stuff to you.
[00:29:23.300 --> 00:29:24.300]   Okay.
[00:29:24.300 --> 00:29:26.140]   So it's, it's, it's in, in the way.
[00:29:26.140 --> 00:29:28.500]   Um, and then that was pretty much it.
[00:29:28.500 --> 00:29:29.620]   Everybody checked everything.
[00:29:29.620 --> 00:29:33.060]   Um, and then they realized that, you know, every quiz app shouldn't really be able to
[00:29:33.060 --> 00:29:34.060]   do everything.
[00:29:34.060 --> 00:29:35.860]   So they, they made the permissions more granular.
[00:29:35.860 --> 00:29:39.060]   And so you can judge by the length of that dialogue, whether it's being ridiculous or
[00:29:39.060 --> 00:29:41.580]   not, but you still basically go, yeah, whatever.
[00:29:41.580 --> 00:29:48.620]   Um, so the, the point of this was, um, this, this idea was when that dialogue comes up,
[00:29:48.620 --> 00:29:51.300]   you don't really have many bases of trusting with that's reasonable or not.
[00:29:51.300 --> 00:29:54.740]   You haven't seen the app yet, you don't, you don't know quite what's going on, but it
[00:29:54.740 --> 00:29:59.100]   could show you, um, your friends who've already installed it as a queue.
[00:29:59.100 --> 00:30:00.100]   That was something that several people suggested.
[00:30:00.100 --> 00:30:01.100]   So you can say, oh, right.
[00:30:01.100 --> 00:30:02.100]   Gene is already using this.
[00:30:02.100 --> 00:30:03.100]   Jeff's using it.
[00:30:03.100 --> 00:30:04.100]   It's probably a good thing.
[00:30:04.100 --> 00:30:05.740]   Um, that, that's reasonable.
[00:30:05.740 --> 00:30:11.420]   But the second piece that was that, um, Randy suggested was, was that the, the cake is a
[00:30:11.420 --> 00:30:16.660]   line bit, which is, um, if somebody, I didn't stores it, you ask them why.
[00:30:16.660 --> 00:30:19.940]   And they can say it, it, it didn't do what it said.
[00:30:19.940 --> 00:30:20.940]   It tricked me.
[00:30:20.940 --> 00:30:25.180]   Um, you know, the classic one was, was you sign up for some Twitter app and it tweets
[00:30:25.180 --> 00:30:28.540]   on your behalf without telling you that was the, you know, that was the sort of evil viral
[00:30:28.540 --> 00:30:29.540]   thing that they did.
[00:30:29.540 --> 00:30:33.060]   The Facebook had some worse ones where it would start using your face in adverts.
[00:30:33.060 --> 00:30:35.420]   Um, still does that by the way.
[00:30:35.420 --> 00:30:41.140]   We had scoble on on Sunday, uh, and asked him, you know, I, cause I get an ad, a sponsored
[00:30:41.140 --> 00:30:44.940]   post for a book that has scoble's recommendation on it.
[00:30:44.940 --> 00:30:46.340]   And I said, Robert, did you know they were doing that?
[00:30:46.340 --> 00:30:47.340]   He said, I had no idea.
[00:30:47.340 --> 00:30:48.340]   Cause you would never see it.
[00:30:48.340 --> 00:30:49.780]   Cause it only shows up in your friend's streams.
[00:30:49.780 --> 00:30:51.500]   So they still do that.
[00:30:51.500 --> 00:30:52.700]   Well, they do that now.
[00:30:52.700 --> 00:30:57.300]   If you've liked the book, so that they, they, they, they will express that endorsement.
[00:30:57.300 --> 00:31:00.740]   Whereas before they were just fish, random friends out of your friend list and say,
[00:31:00.740 --> 00:31:01.820]   you're, your friend likes this thing.
[00:31:01.820 --> 00:31:03.220]   It's only marginally better.
[00:31:03.220 --> 00:31:10.500]   I mean, they're basically using Robert scoble as an endorser, unpaid endorser for a product,
[00:31:10.500 --> 00:31:11.500]   which I think is appalling.
[00:31:11.500 --> 00:31:13.220]   Well, he'll do that for any product anyways.
[00:31:13.220 --> 00:31:14.220]   Yeah.
[00:31:14.220 --> 00:31:19.460]   Well, Robert, but I could say about myself and I hope to God that's not happening to
[00:31:19.460 --> 00:31:21.380]   me and I have no way of knowing.
[00:31:21.380 --> 00:31:22.380]   Right.
[00:31:22.380 --> 00:31:24.460]   You want to, yeah, you only know when somebody else shows it to you.
[00:31:24.460 --> 00:31:25.460]   That's true.
[00:31:25.460 --> 00:31:30.660]   So anyway, so the, but the point of this was that if you can, if you can post, you know,
[00:31:30.660 --> 00:31:36.460]   if in that permission dialogue, it said, Jeff Jarvis, uninstall this app because it,
[00:31:36.460 --> 00:31:38.260]   it didn't, something to ask you for this data.
[00:31:38.260 --> 00:31:39.260]   That's actually really useful.
[00:31:39.260 --> 00:31:40.260]   Yeah.
[00:31:40.260 --> 00:31:42.940]   And it's particularly useful if it's somebody you know, cause then you know how to weigh
[00:31:42.940 --> 00:31:43.940]   that trust.
[00:31:43.940 --> 00:31:46.660]   If it's just a random review from random stranger, that's less useful.
[00:31:46.660 --> 00:31:51.660]   But you know, we all have friends who do read you loads and pay attention to this stuff
[00:31:51.660 --> 00:31:54.260]   and we'll go, actually, you know, this is trying to do this thing that is bad.
[00:31:54.260 --> 00:31:58.140]   And if that shows up in that dialogue, that helps give you a basis for that.
[00:31:58.140 --> 00:32:00.740]   And iOS does something a bit like this.
[00:32:00.740 --> 00:32:03.940]   When you uninstall an app on iOS, it asks you to review it.
[00:32:03.940 --> 00:32:06.060]   But it doesn't use the sort of, actually,
[00:32:06.060 --> 00:32:07.060]   They actually stopped doing that.
[00:32:07.060 --> 00:32:08.180]   You know why?
[00:32:08.180 --> 00:32:13.140]   All the reviews were negative because if you think about it itself, selected for people
[00:32:13.140 --> 00:32:15.260]   who ate apps.
[00:32:15.260 --> 00:32:16.260]   So they stopped it.
[00:32:16.260 --> 00:32:17.260]   Good point.
[00:32:17.260 --> 00:32:23.300]   But yeah, but you know, the other suggestion on this was that when it pops up that dialogue,
[00:32:23.300 --> 00:32:25.380]   it says it wants a hands to your address book.
[00:32:25.380 --> 00:32:27.180]   The developers should put a reason in there.
[00:32:27.180 --> 00:32:28.180]   Yeah, why?
[00:32:28.180 --> 00:32:29.180]   Yes.
[00:32:29.180 --> 00:32:32.380]   So it wants your address book so it can find your friends.
[00:32:32.380 --> 00:32:35.540]   And then if it's something you find something else, then the second you mechanism would
[00:32:35.540 --> 00:32:38.020]   be it said this and it did something else.
[00:32:38.020 --> 00:32:39.540]   And that that would act as the warning.
[00:32:39.540 --> 00:32:43.780]   Now it does, you know, that way you get a distributed trust mechanism and you don't
[00:32:43.780 --> 00:32:47.340]   have to rely on somebody publishing it and making it fast.
[00:32:47.340 --> 00:32:51.380]   And just because it's an app that all the journalists use it suddenly appears.
[00:32:51.380 --> 00:32:52.380]   And it's not the best.
[00:32:52.380 --> 00:32:58.420]   I think Google has a real opportunity here as they have done with latitude to be a leader.
[00:32:58.420 --> 00:33:01.220]   I like that reputation system and maybe they can implement that.
[00:33:01.220 --> 00:33:06.140]   But I just think this is an opportunity for Google or Apple or somebody to be a leader
[00:33:06.140 --> 00:33:09.380]   and say, look, this is how we're going to do it from now on.
[00:33:09.380 --> 00:33:11.820]   What you said you worked on context.
[00:33:11.820 --> 00:33:15.580]   Was there anything going on with Google about protecting that data?
[00:33:15.580 --> 00:33:17.140]   Was it treated at the time?
[00:33:17.140 --> 00:33:21.740]   Because this was a year or so ago as something to be protected.
[00:33:21.740 --> 00:33:26.140]   Yeah, there was always an API for it.
[00:33:26.140 --> 00:33:29.660]   And the permissions model for the API changed a bit over time.
[00:33:29.660 --> 00:33:33.220]   So it was scrapeable.
[00:33:33.220 --> 00:33:34.380]   It wasn't directly scrapeable.
[00:33:34.380 --> 00:33:39.060]   You had to have initially had to have people scraping it by using users login.
[00:33:39.060 --> 00:33:43.980]   And then there was a GData API.
[00:33:43.980 --> 00:33:48.620]   And now there's GData and portable contacts and some other bits of the API there with
[00:33:48.620 --> 00:33:50.620]   a bit more generality.
[00:33:50.620 --> 00:33:58.660]   And now you can request a specific group where the group is either a contact group or what
[00:33:58.660 --> 00:34:00.220]   do you call it?
[00:34:00.220 --> 00:34:02.220]   I would say buzz.
[00:34:02.220 --> 00:34:03.220]   G+ group.
[00:34:03.220 --> 00:34:07.660]   I think the mask is too short as well.
[00:34:07.660 --> 00:34:14.340]   It's a bit confusing because there are three kinds of groups in people contacts now.
[00:34:14.340 --> 00:34:20.220]   But the other thing that's something we talked about would be when the app asks permission
[00:34:20.220 --> 00:34:26.540]   you could say which subset of contacts you give it because that would make a lot of sense.
[00:34:26.540 --> 00:34:29.860]   The UX testing at the time was exactly what Jeff said.
[00:34:29.860 --> 00:34:34.260]   Every time you give someone a choice in that dialog box they get annoyed and exited instead.
[00:34:34.260 --> 00:34:40.380]   And so if you started putting checkboxes in there people would know about click OK.
[00:34:40.380 --> 00:34:43.820]   And as we were at the time trying to stop people asking for use name and password as
[00:34:43.820 --> 00:34:48.900]   a shortcut to that we had to make sure that dialog was less annoying than asking for
[00:34:48.900 --> 00:34:49.900]   use name and password.
[00:34:49.900 --> 00:34:51.820]   Otherwise they would keep bad thing.
[00:34:51.820 --> 00:34:55.980]   I think Gina is on the right point is that coming up with some standards for behavior so
[00:34:55.980 --> 00:35:00.780]   that when you get an Apple app you have faith that it's going to operate in a certain way
[00:35:00.780 --> 00:35:02.980]   means that you don't have to go through that every time.
[00:35:02.980 --> 00:35:05.540]   It's interesting.
[00:35:05.540 --> 00:35:09.220]   Apple's approval process I think makes people feel really safe.
[00:35:09.220 --> 00:35:10.940]   It implies that they're doing that.
[00:35:10.940 --> 00:35:12.260]   It implies that they're doing that.
[00:35:12.260 --> 00:35:16.900]   So I found this so interesting that the community had to police itself and had to get Apple
[00:35:16.900 --> 00:35:17.900]   to change.
[00:35:17.900 --> 00:35:23.660]   So it's just like you can't trust even Apple's stringent approval process to catch everything.
[00:35:23.660 --> 00:35:27.620]   I think it's great that Google is responding to this and that this happened because some
[00:35:27.620 --> 00:35:32.340]   lone hacker started to run this proxy and just sniff what was going across the wire.
[00:35:32.340 --> 00:35:33.700]   It's amazing.
[00:35:33.700 --> 00:35:37.620]   But it kind of goes back to that like me of course I'm from the perspective of open source
[00:35:37.620 --> 00:35:42.820]   and people say oh well you know open source apps are inherently insecure.
[00:35:42.820 --> 00:35:46.620]   But it's this idea that like everybody has to keep an eye on everyone has to review peer
[00:35:46.620 --> 00:35:48.540]   review I guess is the point here.
[00:35:48.540 --> 00:35:51.340]   It is more effective than that.
[00:35:51.340 --> 00:35:52.900]   Right and it's more for regulation too.
[00:35:52.900 --> 00:36:00.220]   If we don't do that then we give the regulators the ammunition to come up with measures that
[00:36:00.220 --> 00:36:01.820]   no one's going to like.
[00:36:01.820 --> 00:36:07.300]   We're going to take a break Kevin Marks is here Gina Trapani Jeff Jarvis.
[00:36:07.300 --> 00:36:12.300]   I guess we could put the coda on this that yes it was a terrible thing.
[00:36:12.300 --> 00:36:14.260]   It's been fixed now.
[00:36:14.260 --> 00:36:19.300]   Let's hope that it brings awareness to every application and I would love to see both Google
[00:36:19.300 --> 00:36:26.900]   with Android and Apple with iOS implement OS wide strategies that work that don't give
[00:36:26.900 --> 00:36:29.820]   you a click fatigue.
[00:36:29.820 --> 00:36:34.140]   And some are you are you now saying it's terrible because you didn't say that a week ago.
[00:36:34.140 --> 00:36:39.740]   No no I'm just I'm just trying to summarize giving Gina her do.
[00:36:39.740 --> 00:36:40.740]   Thank you.
[00:36:40.740 --> 00:36:46.780]   You know I guess it is terrible in the sense that I am the steward of other people's contact
[00:36:46.780 --> 00:36:49.180]   information my contact list.
[00:36:49.180 --> 00:36:56.500]   So as steward I have a responsibility to protect that information and so for a path
[00:36:56.500 --> 00:37:02.020]   or anybody else to trick me into giving them that information without full disclosure is
[00:37:02.020 --> 00:37:04.620]   is really to put me in jeopardy.
[00:37:04.620 --> 00:37:07.860]   It's turning you into dead mouse turning me into dead mouse.
[00:37:07.860 --> 00:37:13.300]   I mean I know I have Steve Martin's private phone numbers and email address in my contact
[00:37:13.300 --> 00:37:17.580]   list and I know he doesn't want anybody to have that.
[00:37:17.580 --> 00:37:19.740]   And I feel a responsibility to protect that.
[00:37:19.740 --> 00:37:26.460]   So in that sense Dave Morin shame on you because he did he didn't steal it from me but he tricked
[00:37:26.460 --> 00:37:28.940]   me into giving it to him.
[00:37:28.940 --> 00:37:31.300]   And so that is an issue I agree with him.
[00:37:31.300 --> 00:37:35.980]   But one of the issues is I think and this is something David body said I think Jeff
[00:37:35.980 --> 00:37:41.980]   has said this before the issue is not necessarily should they have this data is what do they
[00:37:41.980 --> 00:37:43.580]   do with it.
[00:37:43.580 --> 00:37:47.700]   It's not in the inside of trading is illegal you're allowed to have the information you're
[00:37:47.700 --> 00:37:49.420]   not allowed to act on it.
[00:37:49.420 --> 00:37:51.340]   And that's then that's in versus use.
[00:37:51.340 --> 00:37:54.620]   Well but then somebody in the chat room has given a counter example which I also think
[00:37:54.620 --> 00:37:58.260]   if you leave your door open and somebody walks into your house and looks around and then
[00:37:58.260 --> 00:38:03.540]   leaves is still an infringement even if they didn't steal anything.
[00:38:03.540 --> 00:38:04.540]   Bad analogy.
[00:38:04.540 --> 00:38:05.540]   Okay.
[00:38:05.540 --> 00:38:06.540]   All right.
[00:38:06.540 --> 00:38:09.500]   I would say I think Kevin's Kevin's right.
[00:38:09.500 --> 00:38:11.500]   It is hard.
[00:38:11.500 --> 00:38:13.060]   It is a difficult thing.
[00:38:13.060 --> 00:38:14.060]   I'm not chat room.
[00:38:14.060 --> 00:38:18.540]   I'm not being hostile here but I think it's hard to come up with one in real life.
[00:38:18.540 --> 00:38:23.260]   But that's how people I think people do feel some people maybe Gina feel trespassed upon
[00:38:23.260 --> 00:38:26.620]   in the same way you would if somebody walked into your home.
[00:38:26.620 --> 00:38:27.620]   Is that not an accurate.
[00:38:27.620 --> 00:38:31.940]   There's a sense of some problem of violation of you just the line.
[00:38:31.940 --> 00:38:32.940]   Yes.
[00:38:32.940 --> 00:38:35.420]   And that's an apt analogy.
[00:38:35.420 --> 00:38:38.140]   But as a PR move it was bad period.
[00:38:38.140 --> 00:38:39.140]   Yeah.
[00:38:39.140 --> 00:38:42.820]   That's why it turned out though I think that we're becoming hypersensitive to some of
[00:38:42.820 --> 00:38:47.860]   this stuff and some of the data that people have you know can be innocent and is not ill
[00:38:47.860 --> 00:38:53.580]   used the real problem I think here the risk that you were put out was if there was an
[00:38:53.580 --> 00:38:54.580]   insecurity.
[00:38:54.580 --> 00:38:58.060]   I think we all agreed that we didn't know and thought that they were going to do anything
[00:38:58.060 --> 00:38:59.980]   bad with the data that we're going to sell it.
[00:38:59.980 --> 00:39:02.900]   That's the behavior thing that Kevin's talking about and I agree.
[00:39:02.900 --> 00:39:07.460]   So that's not where the risk is that they did something that violated us in some real
[00:39:07.460 --> 00:39:08.460]   way.
[00:39:08.460 --> 00:39:12.580]   The risk was instead our data was somewhere we had you're right.
[00:39:12.580 --> 00:39:14.100]   You know we were responsible for it.
[00:39:14.100 --> 00:39:17.340]   It was then somewhere we didn't necessarily know that.
[00:39:17.340 --> 00:39:21.220]   And if there was a security breach it would have been lost from a place we didn't even
[00:39:21.220 --> 00:39:22.820]   know we had data.
[00:39:22.820 --> 00:39:25.020]   And that's where the practice.
[00:39:25.020 --> 00:39:31.260]   And we carry around in our pockets and give all sorts of people access to all of this information
[00:39:31.260 --> 00:39:32.260]   at all times.
[00:39:32.260 --> 00:39:34.300]   I mean it's all in there.
[00:39:34.300 --> 00:39:40.660]   And so who's it fault you know maybe I shouldn't have added Steve's phone number and emailed
[00:39:40.660 --> 00:39:41.660]   my contact list.
[00:39:41.660 --> 00:39:45.180]   Maybe I should have written it somewhere and put it in a safe.
[00:39:45.180 --> 00:39:46.180]   Right.
[00:39:46.180 --> 00:39:48.900]   And typed it in manually when you want the call.
[00:39:48.900 --> 00:39:50.060]   Tiped it in manual.
[00:39:50.060 --> 00:39:53.220]   I should have memorized it and forgotten the key.
[00:39:53.220 --> 00:39:55.540]   I don't carry around a phone book with you.
[00:39:55.540 --> 00:40:02.300]   Men are from Google plus women are from Pinterest with a great picture of Molly Ringwald.
[00:40:02.300 --> 00:40:04.900]   And what's the other guy Anthony Michael Hall.
[00:40:04.900 --> 00:40:06.780]   Oh I love that.
[00:40:06.780 --> 00:40:07.780]   We'll talk about it.
[00:40:07.780 --> 00:40:12.620]   This is an article in Time magazine but first let's talk about Ford and the new EcoBoost
[00:40:12.620 --> 00:40:13.620]   engines.
[00:40:13.620 --> 00:40:18.420]   I got to drive an EcoBoost when I was shopping for my Mustang a couple of years ago in the
[00:40:18.420 --> 00:40:19.980]   SHO.
[00:40:19.980 --> 00:40:26.620]   This is really a sweet engine design that you know sometimes technology can solve a problem.
[00:40:26.620 --> 00:40:29.900]   The problem people want great gas mileage.
[00:40:29.900 --> 00:40:32.180]   They need great gas mileage.
[00:40:32.180 --> 00:40:36.300]   Governments require great gas mileage but people also want great pickup.
[00:40:36.300 --> 00:40:37.300]   They want speed.
[00:40:37.300 --> 00:40:38.300]   They want power.
[00:40:38.300 --> 00:40:42.380]   How do you make the two match and this is where Ford's just done some really interesting
[00:40:42.380 --> 00:40:44.740]   work with their EcoBoost engines.
[00:40:44.740 --> 00:40:53.260]   They took a conventional gasoline engine and enhanced it to make fuel efficiency standards
[00:40:53.260 --> 00:40:57.340]   and to give you the kind of oomph and pickup that you want.
[00:40:57.340 --> 00:40:58.660]   They call it the EcoBoost engine.
[00:40:58.660 --> 00:41:03.020]   You'll see it in the 2012 Explorer and Edge, the 2013 Escape.
[00:41:03.020 --> 00:41:05.100]   It's been in the SHO for a while.
[00:41:05.100 --> 00:41:06.540]   It combines two technologies.
[00:41:06.540 --> 00:41:09.940]   Direct injection and twin turbo charging.
[00:41:09.940 --> 00:41:15.340]   The direct injection gives you a cooler, denser charge that generates more power per drop
[00:41:15.340 --> 00:41:18.580]   of fuel because it's cooler and it's denser.
[00:41:18.580 --> 00:41:22.940]   Then instead of using one big large turbo and maybe you've driven a turbo engine before
[00:41:22.940 --> 00:41:27.420]   and you've seen that hesitation, it's got two small engine-curbed turbo chargers.
[00:41:27.420 --> 00:41:29.420]   They spool up more quickly so there's no hesitation.
[00:41:29.420 --> 00:41:31.420]   It's very responsive.
[00:41:31.420 --> 00:41:37.300]   What the turbo charger does, it takes energy from the engine's exhaust, rotates those turbine
[00:41:37.300 --> 00:41:43.340]   wheels, compresses the, pressurizes the incoming air and it gives you a lot more power per
[00:41:43.340 --> 00:41:44.340]   liter.
[00:41:44.340 --> 00:41:45.340]   It's all in the EcoBoost engine.
[00:41:45.340 --> 00:41:49.940]   It's kind of an amazing thing and just one of thousands of technological innovations
[00:41:49.940 --> 00:41:52.460]   coming out of the Blue Oval out of Ford.
[00:41:52.460 --> 00:42:00.580]   I want you to check it out at Ford.com/technology or better yet go to your Ford dealer and drive
[00:42:00.580 --> 00:42:01.940]   an EcoBoost engine.
[00:42:01.940 --> 00:42:08.460]   The 2013 Escape which comes in 2012 has a 1.6 and a 2 liter EcoBoost and the 2012 Explorer
[00:42:08.460 --> 00:42:12.660]   and Edge have the 2 liter with a 2 liter EcoBoost engine.
[00:42:12.660 --> 00:42:19.580]   You get an EPA estimate of 28 highway miles per gallon which is amazing for a vehicle of
[00:42:19.580 --> 00:42:20.580]   that size.
[00:42:20.580 --> 00:42:24.540]   They're truly fantastic and they do not hesitate.
[00:42:24.540 --> 00:42:31.780]   You hit that pedal on.
[00:42:31.780 --> 00:42:32.780]   But don't do that.
[00:42:32.780 --> 00:42:35.060]   Ford.com/technology.
[00:42:35.060 --> 00:42:38.100]   We thank them for their support of this week in Google.
[00:42:38.100 --> 00:42:43.700]   Keith Waggstaff writing in Time Magazine talking about the fact that we talked a little
[00:42:43.700 --> 00:42:55.940]   bit about last week that 97% of Pinterest's Facebook fans are women and according to stats,
[00:42:55.940 --> 00:42:59.700]   Google Plus is heavily male.
[00:42:59.700 --> 00:43:02.260]   We don't know exactly.
[00:43:02.260 --> 00:43:03.260]   Maybe a similar number.
[00:43:03.260 --> 00:43:04.260]   I don't know.
[00:43:04.260 --> 00:43:09.620]   My favorite line in this story is if Pinterest is a stylish woman browsing through home decor
[00:43:09.620 --> 00:43:14.940]   magazines, Google Plus is the software engineer staring at a stark white screen.
[00:43:14.940 --> 00:43:15.940]   Yeah.
[00:43:15.940 --> 00:43:16.940]   You can be Bose.
[00:43:16.940 --> 00:43:17.940]   I bet you don't.
[00:43:17.940 --> 00:43:18.940]   Yeah.
[00:43:18.940 --> 00:43:19.940]   Well, I do.
[00:43:19.940 --> 00:43:20.940]   I have Bose.
[00:43:20.940 --> 00:43:21.940]   I do my Pinterest.
[00:43:21.940 --> 00:43:23.700]   There are two.
[00:43:23.700 --> 00:43:24.940]   No surprise here.
[00:43:24.940 --> 00:43:26.340]   This was this had to happen there.
[00:43:26.340 --> 00:43:27.500]   I haven't gone to them yet.
[00:43:27.500 --> 00:43:28.500]   I just saw a tweet on them.
[00:43:28.500 --> 00:43:30.780]   There are now two porn versions of Pinterest.
[00:43:30.780 --> 00:43:33.100]   See, I was this is what I was wondering.
[00:43:33.100 --> 00:43:37.940]   And this there would be more men on Pinterest if they had a hot category or something like
[00:43:37.940 --> 00:43:38.940]   that.
[00:43:38.940 --> 00:43:39.940]   I've joined.
[00:43:39.940 --> 00:43:42.140]   Do we see Mitt Romney's fake.
[00:43:42.140 --> 00:43:46.260]   No, it's really done brilliantly done.
[00:43:46.260 --> 00:43:47.260]   Oh crap.
[00:43:47.260 --> 00:43:49.260]   I'm going to find it.
[00:43:49.260 --> 00:43:50.260]   A picture on a starter.
[00:43:50.260 --> 00:43:51.660]   You're not fake me from me.
[00:43:51.660 --> 00:43:52.660]   Yeah.
[00:43:52.660 --> 00:43:54.660]   Fake Mitt Romney.
[00:43:54.660 --> 00:43:56.700]   I got it.
[00:43:56.700 --> 00:44:00.580]   We should talk about the Romney now has the same the Santoram Google problem as well.
[00:44:00.580 --> 00:44:01.580]   He does.
[00:44:01.580 --> 00:44:02.580]   He's been Google.
[00:44:02.580 --> 00:44:05.260]   I haven't done a search, but I'm not sure I want to, but.
[00:44:05.260 --> 00:44:07.100]   Yeah, no, you probably don't want to.
[00:44:07.100 --> 00:44:08.100]   Yeah.
[00:44:08.100 --> 00:44:11.660]   I mean, interestingly, Pinterest in the UK is majority men.
[00:44:11.660 --> 00:44:14.500]   So this is just just women.
[00:44:14.500 --> 00:44:16.020]   Well, that's just that.
[00:44:16.020 --> 00:44:21.000]   That was kind of, you know, no, I think it proves the the the yeah, the stereotype of
[00:44:21.000 --> 00:44:22.700]   British men is what it does, Kevin.
[00:44:22.700 --> 00:44:23.700]   Yeah, exactly.
[00:44:23.700 --> 00:44:27.700]   So soccer is no football.
[00:44:27.700 --> 00:44:28.700]   Crikey.
[00:44:28.700 --> 00:44:29.700]   Crikey.
[00:44:29.700 --> 00:44:31.700]   Crikey to sport.
[00:44:31.700 --> 00:44:34.700]   I'm trying to pull up.
[00:44:34.700 --> 00:44:35.700]   I don't know.
[00:44:35.700 --> 00:44:36.700]   Is Pinterest down?
[00:44:36.700 --> 00:44:37.700]   Because I'm not getting any.
[00:44:37.700 --> 00:44:38.700]   I'm having issues.
[00:44:38.700 --> 00:44:40.700]   Pinterest too, actually.
[00:44:40.700 --> 00:44:41.700]   Yeah.
[00:44:41.700 --> 00:44:43.340]   We broke Pinterest.
[00:44:43.340 --> 00:44:44.340]   That doesn't seem right.
[00:44:44.340 --> 00:44:47.180]   Well, you just brought men to it.
[00:44:47.180 --> 00:44:48.180]   All these men broke it.
[00:44:48.180 --> 00:44:50.340]   They're like, what is this thing?
[00:44:50.340 --> 00:44:51.340]   Gosh.
[00:44:51.340 --> 00:44:52.340]   There are pictures.
[00:44:52.340 --> 00:44:54.340]   I think we do it.
[00:44:54.340 --> 00:44:55.340]   It's down.
[00:44:55.340 --> 00:44:56.340]   It's.
[00:44:56.340 --> 00:44:57.340]   Wow.
[00:44:57.340 --> 00:44:59.180]   Gentlemen is up.
[00:44:59.180 --> 00:45:00.180]   That's what I use.
[00:45:00.180 --> 00:45:01.180]   It's not a porn site.
[00:45:01.180 --> 00:45:02.660]   It's a mint of manly things.
[00:45:02.660 --> 00:45:04.660]   It's Pinterest for men.
[00:45:04.660 --> 00:45:05.820]   Is it the same company?
[00:45:05.820 --> 00:45:06.820]   No.
[00:45:06.820 --> 00:45:07.820]   No.
[00:45:07.820 --> 00:45:08.820]   Somebody clean the UI.
[00:45:08.820 --> 00:45:09.820]   Somebody clean it.
[00:45:09.820 --> 00:45:10.820]   It's total clone.
[00:45:10.820 --> 00:45:11.820]   I don't care.
[00:45:11.820 --> 00:45:15.820]   I like it because it's like manly things like marine sergeant Rocky Sickman returns home.
[00:45:15.820 --> 00:45:19.540]   Ford F650 truck Jeep.
[00:45:19.540 --> 00:45:21.740]   The douche bag ski carrier.
[00:45:21.740 --> 00:45:27.100]   I like this one from Sean Connery.
[00:45:27.100 --> 00:45:30.780]   I must ask you a question, but I'm shaving it for later.
[00:45:30.780 --> 00:45:36.260]   Leo, Leo, shouldn't you do just a gadget and geek, Pinterest?
[00:45:36.260 --> 00:45:38.100]   That would be a great idea.
[00:45:38.100 --> 00:45:39.940]   I mean, we're going to clone it.
[00:45:39.940 --> 00:45:43.380]   Twitter, Twitter, Twitter, Twitter, Twitter, Twitter, Twitter, Twitter, Twitter, Twitter.
[00:45:43.380 --> 00:45:47.580]   It's the code open source or these clones are just there.
[00:45:47.580 --> 00:45:49.980]   People just building the whole new.
[00:45:49.980 --> 00:45:50.980]   No.
[00:45:50.980 --> 00:45:52.740]   It's the UI all new.
[00:45:52.740 --> 00:45:53.740]   Just yeah.
[00:45:53.740 --> 00:45:54.740]   Okay.
[00:45:54.740 --> 00:45:56.380]   I don't think you could really copyright it.
[00:45:56.380 --> 00:45:58.020]   I mean, Tumblr did it first, right?
[00:45:58.020 --> 00:45:59.020]   It's not.
[00:45:59.020 --> 00:46:03.620]   I don't think you can really say this interfaces is unique.
[00:46:03.620 --> 00:46:11.100]   Google makes a next gen personal communications device and is testing it in employees homes.
[00:46:11.100 --> 00:46:12.100]   I want it now.
[00:46:12.100 --> 00:46:13.260]   I want it to.
[00:46:13.260 --> 00:46:15.780]   It's rumored to be a Sonos like device.
[00:46:15.780 --> 00:46:17.260]   We thought we talked about it last week.
[00:46:17.260 --> 00:46:18.700]   We thought it was going to be released this week.
[00:46:18.700 --> 00:46:19.700]   They didn't do anything.
[00:46:19.700 --> 00:46:21.380]   In fact, I was really pissed off.
[00:46:21.380 --> 00:46:25.900]   That thing we talked about last week that Google TV put on Facebook, but not on Google
[00:46:25.900 --> 00:46:29.380]   Plus was like an updated YouTube app for.
[00:46:29.380 --> 00:46:30.380]   That's all it was.
[00:46:30.380 --> 00:46:33.900]   It's a Google TV and which I by the way, tried to download like a million times and it said,
[00:46:33.900 --> 00:46:35.660]   sorry, we're networked down or something.
[00:46:35.660 --> 00:46:38.940]   I couldn't fake out, fake out, fake out.
[00:46:38.940 --> 00:46:45.700]   So this is called the Android at home tungsten hub or that's what they called it a Google
[00:46:45.700 --> 00:46:46.700]   IO.
[00:46:46.700 --> 00:46:48.740]   So there's there's two things, right?
[00:46:48.740 --> 00:46:52.380]   Is the Android at home control your refrigerator remotely thing?
[00:46:52.380 --> 00:46:53.380]   Yeah.
[00:46:53.380 --> 00:46:54.380]   And then there's this like streaming music device.
[00:46:54.380 --> 00:46:55.380]   I think it's the same thing.
[00:46:55.380 --> 00:46:57.380]   What do you think is the same thing?
[00:46:57.380 --> 00:46:58.380]   Yeah.
[00:46:58.380 --> 00:47:02.860]   Well, but they they asked for two different permissions for testing is what the story said.
[00:47:02.860 --> 00:47:03.860]   Okay.
[00:47:03.860 --> 00:47:05.860]   So either gene is right.
[00:47:05.860 --> 00:47:08.140]   Maybe it's different things.
[00:47:08.140 --> 00:47:09.140]   Mm.
[00:47:09.140 --> 00:47:13.020]   Well, and the other thing is that the other bigger story is that is they're building a
[00:47:13.020 --> 00:47:15.100]   testing lab for hardware.
[00:47:15.100 --> 00:47:16.580]   Google going into the hardware business.
[00:47:16.580 --> 00:47:17.860]   Are they trying to be Apple?
[00:47:17.860 --> 00:47:19.540]   What's happening here?
[00:47:19.540 --> 00:47:22.740]   I hate it that these companies are so jealous of the other guys.
[00:47:22.740 --> 00:47:23.740]   Yeah.
[00:47:23.740 --> 00:47:26.260]   They're all copying each other and just like do what you do.
[00:47:26.260 --> 00:47:27.260]   Be yourself.
[00:47:27.260 --> 00:47:29.700]   Well, the better bit's improved now.
[00:47:29.700 --> 00:47:31.620]   So they are a hardware company, right?
[00:47:31.620 --> 00:47:32.620]   Yes.
[00:47:32.620 --> 00:47:35.260]   Yeah, it's not closed yet, but it's approved by the EU.
[00:47:35.260 --> 00:47:38.660]   So I think that was the last the Motorola deal for the last hurdle for that and the Department
[00:47:38.660 --> 00:47:39.860]   of Justice approved it.
[00:47:39.860 --> 00:47:44.820]   So I think who else is there anyone else they have to get it by?
[00:47:44.820 --> 00:47:45.820]   China.
[00:47:45.820 --> 00:47:46.820]   China.
[00:47:46.820 --> 00:47:47.820]   Yeah.
[00:47:47.820 --> 00:47:54.060]   The last bastion of intellectual property protection.
[00:47:54.060 --> 00:47:59.500]   So yeah, the DOJ today approved Google's 12 and a half million, sorry, billion dollar
[00:47:59.500 --> 00:48:03.100]   bid to buy Motorola mobility.
[00:48:03.100 --> 00:48:05.980]   So it says two days ago and the EU did two days ago.
[00:48:05.980 --> 00:48:11.020]   So Monday's blessings mean Google just needs to clear regulatory hurdles in China, Taiwan
[00:48:11.020 --> 00:48:12.020]   and Israel.
[00:48:12.020 --> 00:48:13.020]   Good luck.
[00:48:13.020 --> 00:48:19.660]   I didn't know that China had any approval over murder.
[00:48:19.660 --> 00:48:20.660]   Geez.
[00:48:20.660 --> 00:48:24.420]   Google's relationship with China's ruling party has been on shaky ground.
[00:48:24.420 --> 00:48:25.420]   Yeah.
[00:48:25.420 --> 00:48:26.420]   Wow.
[00:48:26.420 --> 00:48:27.420]   Why?
[00:48:27.420 --> 00:48:28.420]   Why?
[00:48:28.420 --> 00:48:29.420]   I understand.
[00:48:29.420 --> 00:48:30.420]   Can't you just buy a company?
[00:48:30.420 --> 00:48:40.220]   Why do you have to have China and Taiwan and Israel say, okay?
[00:48:40.220 --> 00:48:43.020]   I thought it was a done deal, but I guess not.
[00:48:43.020 --> 00:48:47.020]   If I went out and bought revision three and I have to get China to say it was okay.
[00:48:47.020 --> 00:48:53.300]   I assume that's a hardware testing lab was totally about Motorola though.
[00:48:53.300 --> 00:48:54.300]   You think so?
[00:48:54.300 --> 00:48:56.100]   You're going to do a phone.
[00:48:56.100 --> 00:48:59.620]   I figured well a phone and some sort of set top box right a Google TV.
[00:48:59.620 --> 00:49:00.620]   Set top box.
[00:49:00.620 --> 00:49:01.620]   Yes.
[00:49:01.620 --> 00:49:02.620]   A Moto Google TV.
[00:49:02.620 --> 00:49:03.620]   Right.
[00:49:03.620 --> 00:49:06.580]   So does that mean they're going to take over product development for Motorola and do it
[00:49:06.580 --> 00:49:09.420]   at Google and just say never mind you guys can make some stuff and we'll get real sell
[00:49:09.420 --> 00:49:11.140]   parts of this when we need to.
[00:49:11.140 --> 00:49:16.420]   Judging by the quality of the Motorola phones, I think they should take it from Motorola.
[00:49:16.420 --> 00:49:17.420]   Yes.
[00:49:17.420 --> 00:49:23.020]   That would be interesting to say how they handle it because I don't make people really nervous
[00:49:23.020 --> 00:49:28.220]   if they don't kind of keep Motorola maybe a little separate.
[00:49:28.220 --> 00:49:32.620]   John Kruber had a great post on his during fireball and blogging and answering the question,
[00:49:32.620 --> 00:49:36.260]   is Apple a software company or hardware company said well arguably software, but really it's
[00:49:36.260 --> 00:49:42.860]   a design company and it's the entire thing he quotes Alan Kay as Steve Jobs did who said
[00:49:42.860 --> 00:49:47.940]   you know if you really care about the software you have to make the hardware and I think you
[00:49:47.940 --> 00:49:53.740]   could make the case that if you really wanted to make the best Android phone we know now.
[00:49:53.740 --> 00:49:56.660]   If you really want to make the best Android phone you better make it yourself if you have
[00:49:56.660 --> 00:50:01.100]   some sort of because I mean there's you know there's such variety and there's so much
[00:50:01.100 --> 00:50:02.260]   crap out there.
[00:50:02.260 --> 00:50:09.220]   Although Samsung is quickly rising to the top I would say they made the last Nexus, the
[00:50:09.220 --> 00:50:15.140]   Galaxy Nexus, the Galaxy S2 they made this note I think they seem to be the winner of
[00:50:15.140 --> 00:50:18.140]   all HTC I thought but not anymore.
[00:50:18.140 --> 00:50:20.140]   H2 doing pretty well.
[00:50:20.140 --> 00:50:27.140]   Is Apple going to be able to stop Samsung cold and it's tracked with all its suits?
[00:50:27.140 --> 00:50:30.940]   You know they're suing now to keep the Galaxy Nexus out of the US.
[00:50:30.940 --> 00:50:31.940]   Can you believe that?
[00:50:31.940 --> 00:50:32.940]   It's ridiculous.
[00:50:32.940 --> 00:50:38.180]   They're really in Germany, Australia.
[00:50:38.180 --> 00:50:42.860]   And you know at first we thought oh this is kind of a covert action that's eventually
[00:50:42.860 --> 00:50:47.420]   going to hit at Google and hit at Android but they're going to go after HTC and LG and
[00:50:47.420 --> 00:50:51.020]   Samsung but now I think it really has a lot to do with the fact that Samsung is starting
[00:50:51.020 --> 00:50:54.860]   I mean they've sold a lot of these notes and I think that they're starting to be a little
[00:50:54.860 --> 00:50:57.100]   worried perhaps.
[00:50:57.100 --> 00:51:01.860]   And somebody thought that maybe the lawsuits were all about the fact that the next iPad
[00:51:01.860 --> 00:51:04.860]   is going to look a little bit like this.
[00:51:04.860 --> 00:51:07.380]   Which would be very funny wouldn't it?
[00:51:07.380 --> 00:51:09.220]   Then they'll see that the Samsung was doing their design again.
[00:51:09.220 --> 00:51:10.220]   I did last time.
[00:51:10.220 --> 00:51:19.500]   Yeah Samsung said well you want to see that we've got to see your iPad 3.
[00:51:19.500 --> 00:51:21.300]   In the chatroom I don't know if this is a joke or not.
[00:51:21.300 --> 00:51:24.580]   Chatroom is talking a couple of people said Apple wants to sue Kodak.
[00:51:24.580 --> 00:51:28.340]   They are suing coat they ask permission because Kodak's in chapter 11 they ask permission
[00:51:28.340 --> 00:51:33.620]   and they ask me to sue these guys too they're on the floor but let's kick comes.
[00:51:33.620 --> 00:51:35.300]   Dog belly.
[00:51:35.300 --> 00:51:38.740]   Good lord they're got the chapter 11 and you want to sue them?
[00:51:38.740 --> 00:51:40.340]   Well this is but I didn't.
[00:51:40.340 --> 00:51:45.940]   Let's know shall we know that Kodak hundred twenty years later is stop making cameras.
[00:51:45.940 --> 00:51:46.940]   Right.
[00:51:46.940 --> 00:51:51.460]   They're not even in that business now they're in the printer business.
[00:51:51.460 --> 00:51:58.300]   Well it's clear Apple wants to make it crystal clear to anybody who would have any questions
[00:51:58.300 --> 00:52:03.300]   that they will be highly aggressive in defending their intellectual property.
[00:52:03.300 --> 00:52:06.220]   Right.
[00:52:06.220 --> 00:52:07.780]   If there were any doubt.
[00:52:07.780 --> 00:52:11.860]   Well the good news was the EO lawsuit was.
[00:52:11.860 --> 00:52:13.060]   That's a good one too yeah.
[00:52:13.060 --> 00:52:16.100]   That was that was and it's only taken 10 years.
[00:52:16.100 --> 00:52:21.540]   So they file these lawsuits mostly in in what is it East Texas?
[00:52:21.540 --> 00:52:22.740]   East Texas yeah.
[00:52:22.740 --> 00:52:26.420]   Because it turns this is kind of one of those bogus I think one of those bogus things but
[00:52:26.420 --> 00:52:33.980]   they believe that juries in East Texas are more pro IP holder rights holders than others.
[00:52:33.980 --> 00:52:38.100]   It's not just that it's also that there's that particular jurisdiction doesn't have many
[00:52:38.100 --> 00:52:40.940]   cases so they can they can come to court quickly.
[00:52:40.940 --> 00:52:41.940]   Ah.
[00:52:41.940 --> 00:52:44.580]   And so that was one of the original reasons whereas if you try and do it in New York there's
[00:52:44.580 --> 00:52:47.580]   a whole bunch of criminal stuff that gets in front of you and that takes person.
[00:52:47.580 --> 00:52:49.980]   There's a still they just kill them in Texas.
[00:52:49.980 --> 00:52:55.700]   I think you could find a not so busy court in a lot of places right.
[00:52:55.700 --> 00:52:58.740]   There was a story I read a couple years ago that there's a there's a building there.
[00:52:58.740 --> 00:52:59.740]   Yes.
[00:52:59.740 --> 00:53:00.740]   Just it.
[00:53:00.740 --> 00:53:01.740]   Yes.
[00:53:01.740 --> 00:53:02.740]   Office after office after office after office just nothing but.
[00:53:02.740 --> 00:53:05.620]   Don't mean this is a great this American life on this.
[00:53:05.620 --> 00:53:06.620]   Yeah.
[00:53:06.620 --> 00:53:07.620]   Yeah.
[00:53:07.620 --> 00:53:08.620]   Yeah.
[00:53:08.620 --> 00:53:09.620]   That's right.
[00:53:09.620 --> 00:53:11.660]   They went and they searched and they're all basically owned by Nathan Mirvold.
[00:53:11.660 --> 00:53:17.020]   You know the handful of people who basically they make this their business.
[00:53:17.020 --> 00:53:24.580]   So a jury in Texas gave proved a lie to the thought that they might somehow be nicer.
[00:53:24.580 --> 00:53:29.340]   They said that those Eolas patents which really would have had they won this case and they
[00:53:29.340 --> 00:53:35.980]   had I think they won once before didn't they would have really changed everything.
[00:53:35.980 --> 00:53:40.740]   They claimed that they invented.
[00:53:40.740 --> 00:53:41.740]   Interactivity.
[00:53:41.740 --> 00:53:42.740]   Yes.
[00:53:42.740 --> 00:53:45.260]   That's a good way to put it.
[00:53:45.260 --> 00:53:46.260]   Yeah.
[00:53:46.260 --> 00:53:50.980]   It was it was what about plugins and they've already had you know so many jobs get Microsoft
[00:53:50.980 --> 00:53:55.860]   and the settlement and there was this whole thing five years ago more where we suddenly
[00:53:55.860 --> 00:53:57.860]   had to change where we.
[00:53:57.860 --> 00:53:58.860]   Right.
[00:53:58.860 --> 00:54:01.700]   Plug-ins in the browser right to get round the lawsuit everyone had to do with JavaScript
[00:54:01.700 --> 00:54:03.020]   rather than do it declaratively.
[00:54:03.020 --> 00:54:08.780]   So they got a patent in 1998 now think if this had been invented by 1998 or not describing
[00:54:08.780 --> 00:54:12.620]   a system that allows a user of a browser program on a computer connected to an open
[00:54:12.620 --> 00:54:18.500]   distributed hypermedia system to access and execute an embedded program object.
[00:54:18.500 --> 00:54:21.500]   Had that been invented before 1998 I think so.
[00:54:21.500 --> 00:54:22.500]   Yeah.
[00:54:22.500 --> 00:54:23.500]   I forgot plugging.
[00:54:23.500 --> 00:54:24.500]   Thanks.
[00:54:24.500 --> 00:54:25.500]   So.
[00:54:25.500 --> 00:54:30.900]   And then they had a patent that allowed a fully interactive embedded applications through
[00:54:30.900 --> 00:54:33.900]   the use of plugins.
[00:54:33.900 --> 00:54:39.300]   They brought people like Vince surf of Google and Tim Berners Lee.
[00:54:39.300 --> 00:54:41.380]   Tim Berners Lee I think was hell.
[00:54:41.380 --> 00:54:48.020]   Pay-on-Y way came they came went down to Little Town in East Texas and they testified
[00:54:48.020 --> 00:54:52.460]   and the jury said you know those are some smart guys.
[00:54:52.460 --> 00:54:55.500]   They say they invented this first we believe them.
[00:54:55.500 --> 00:54:56.500]   Right.
[00:54:56.500 --> 00:55:00.900]   Well I think I mean I think that that was is of a piece with the the soper thing.
[00:55:00.900 --> 00:55:06.420]   I think the difference is now that between now and when these were heard before was that
[00:55:06.420 --> 00:55:09.380]   we now have substantial layman experience of this stuff.
[00:55:09.380 --> 00:55:10.380]   Yes.
[00:55:10.380 --> 00:55:14.740]   So when you start using the browser and you say well there's this embedded thing and they
[00:55:14.740 --> 00:55:16.540]   go well that's that is pretty obvious.
[00:55:16.540 --> 00:55:17.540]   Yeah.
[00:55:17.540 --> 00:55:18.820]   I use stuff like that all the time.
[00:55:18.820 --> 00:55:20.740]   They think they own that.
[00:55:20.740 --> 00:55:23.180]   And I think it was the same with the with the the soper stuff.
[00:55:23.180 --> 00:55:25.780]   You want to change the internet to do what.
[00:55:25.780 --> 00:55:29.900]   And people you know this make the experience this used to be some you know arcane technical
[00:55:29.900 --> 00:55:34.260]   argument that a bunch of us had because we were the nerdy ones whereas now that that
[00:55:34.260 --> 00:55:38.700]   internet experience is so mainstream that you can rely on a jury to be much more reasonable
[00:55:38.700 --> 00:55:43.180]   about it than you would have been able to you know ten years ago where it was very you
[00:55:43.180 --> 00:55:45.700]   know technical and arcane seeming.
[00:55:45.700 --> 00:55:50.220]   Some talk quite a bit of talk this past week over Google launching Google Drive or G Drive
[00:55:50.220 --> 00:55:56.500]   eventually maybe even speculation that Google might buy Dropbox.
[00:55:56.500 --> 00:56:00.740]   Google Docs offers I don't know if it's widely known if you watch the show you know it free
[00:56:00.740 --> 00:56:04.300]   storage for any kind of file.
[00:56:04.300 --> 00:56:06.580]   You can upload any kind of file to Google Docs.
[00:56:06.580 --> 00:56:11.540]   But it doesn't have the the Dropbox's interface right that is just like a another folder on
[00:56:11.540 --> 00:56:12.540]   your computer.
[00:56:12.540 --> 00:56:15.540]   And I think the Google Docs experience is so great such a great product.
[00:56:15.540 --> 00:56:21.740]   I use it with to do text and I mean I would be great purchase for Google although I get
[00:56:21.740 --> 00:56:25.020]   worried when small great companies get acquired because you worry that they're just going
[00:56:25.020 --> 00:56:26.020]   to get abandoned.
[00:56:26.020 --> 00:56:30.620]   But if G Drive if drive I guess is what they're just going to call it just straight up drive
[00:56:30.620 --> 00:56:34.380]   has that same Dropbox kind of experience for cheaper.
[00:56:34.380 --> 00:56:35.860]   That would be fantastic.
[00:56:35.860 --> 00:56:41.620]   There are lots of companies now doing Dropbox like things I've used spider oak SharePoint.
[00:56:41.620 --> 00:56:42.620]   What's that?
[00:56:42.620 --> 00:56:43.620]   Sugar sink.
[00:56:43.620 --> 00:56:45.860]   Was it Wazoo or something?
[00:56:45.860 --> 00:56:46.860]   Wala.
[00:56:46.860 --> 00:56:47.860]   Wala.
[00:56:47.860 --> 00:56:48.860]   Wala.
[00:56:48.860 --> 00:56:52.780]   So there's a ton of people doing this for some reason Dropbox has all the traction and
[00:56:52.780 --> 00:56:55.980]   maybe you can address this you know because one of the reasons has so much traction is
[00:56:55.980 --> 00:56:58.900]   because programs like to do text have it kind of built in.
[00:56:58.900 --> 00:57:02.660]   Is it is there API so much better or was it the adoption rate or what was it?
[00:57:02.660 --> 00:57:06.980]   The API is just great and I'm truthfully I chose it for to do text because it was just
[00:57:06.980 --> 00:57:11.140]   a product that I've been using for a long time and people know the name and the API is
[00:57:11.140 --> 00:57:12.140]   awesome.
[00:57:12.140 --> 00:57:16.500]   They have offer SDKs for iOS and Android and JavaScript and PHP basically any language
[00:57:16.500 --> 00:57:20.140]   you want to build in it's super it's just super easy.
[00:57:20.140 --> 00:57:23.180]   And yeah I've heard of these other products I just I just want those things like I started
[00:57:23.180 --> 00:57:26.620]   using Dropbox and it's loved it and never I never move right to do these other products
[00:57:26.620 --> 00:57:29.700]   have that similar thing where you download this client on your computer and it just creates
[00:57:29.700 --> 00:57:31.380]   other folders same deal same deal.
[00:57:31.380 --> 00:57:32.380]   Same deal.
[00:57:32.380 --> 00:57:36.540]   The reason I use actually not quite as no you know not all of them do that you have a
[00:57:36.540 --> 00:57:43.660]   Dropbox you know like a watch folder but they're all sink in some way but you specify folders
[00:57:43.660 --> 00:57:51.140]   and they're automatically synced as opposed to separate folder a Dropbox folder but I
[00:57:51.140 --> 00:57:55.120]   started looking at these other guys when the issue of Dropbox knowing your encryption
[00:57:55.120 --> 00:58:00.380]   keys came up right and so I thought well I'm not that I'm hiding anything I don't have
[00:58:00.380 --> 00:58:03.340]   anything on there that I really care about but I thought well maybe I should investigate
[00:58:03.340 --> 00:58:07.100]   these that allow you to own your own keys that kind of thing.
[00:58:07.100 --> 00:58:08.300]   Right right.
[00:58:08.300 --> 00:58:11.660]   But you're right Dropbox is easiest and frankly it's hard to move away from because every
[00:58:11.660 --> 00:58:17.100]   app on on the iPhone Android phone and iPad they all support Dropbox.
[00:58:17.100 --> 00:58:21.740]   Yeah yeah it just got that momentum yep and I think Google is going to face that same
[00:58:21.740 --> 00:58:25.420]   issue even though they've got a better brand recognition than say spider oak they're still
[00:58:25.420 --> 00:58:28.500]   going to say face that issue with people just keep using Dropbox so they're gonna have
[00:58:28.500 --> 00:58:31.340]   to buy it I think.
[00:58:31.340 --> 00:58:36.340]   Google is seeking approval for an antenna farm.
[00:58:36.340 --> 00:58:39.300]   They will know everything they will listen to everything.
[00:58:39.300 --> 00:58:40.300]   I'm scared.
[00:58:40.300 --> 00:58:47.100]   It's an Iowa that's the best part of that one it says it's a little go away.
[00:58:47.100 --> 00:58:54.460]   Is it satellite dish phone or yeah yeah because the presumption is that this is them going
[00:58:54.460 --> 00:58:57.900]   into the cable business they'll get TV signals but nobody knows.
[00:58:57.900 --> 00:59:03.700]   I think they're building their own nuclear deterrent fleet.
[00:59:03.700 --> 00:59:09.100]   This right is next to Omaha which isn't no more the strategic air command is based.
[00:59:09.100 --> 00:59:13.540]   And Warren Buffett and Warren Buffett together the Oracle.
[00:59:13.540 --> 00:59:20.260]   That's it and Warren Buffett you got satellites they're building in their application they
[00:59:20.260 --> 00:59:25.540]   said the company wants satellite receiving stations to receive C band and KU band signals
[00:59:25.540 --> 00:59:30.020]   to provide now this is interesting to provide analog and digital audio data and video services
[00:59:30.020 --> 00:59:34.820]   it sounds like they want to get the cable business.
[00:59:34.820 --> 00:59:38.980]   These are the KU and C band are the big issues.
[00:59:38.980 --> 00:59:44.380]   This alternative theory they could be this could be a wide spaces play this could be them
[00:59:44.380 --> 00:59:50.340]   testing out being able to send signals a long way in the old TV bands right.
[00:59:50.340 --> 00:59:55.820]   I have to look at the exact frequencies and so but that no one of the part of the white
[00:59:55.820 --> 01:00:00.140]   spaces was to reuse the old television spectrum because everyone's got cable now so that we
[01:00:00.140 --> 01:00:03.700]   could use that as a super Wi-Fi.
[01:00:03.700 --> 01:00:07.940]   If you want to do that and you want to go a long way you're going to need a big antenna
[01:00:07.940 --> 01:00:09.980]   at the sending end so you can have a small antenna with the receiving end.
[01:00:09.980 --> 01:00:10.980]   I just love these conspiracies.
[01:00:10.980 --> 01:00:12.300]   So that may be part of it too.
[01:00:12.300 --> 01:00:16.580]   They're based on the notion that Apple and Google have so much cash in the bank that they
[01:00:16.580 --> 01:00:21.020]   could just unilaterally say hey guess what we're in the cable business or guess what
[01:00:21.020 --> 01:00:22.020]   we own Hollywood.
[01:00:22.020 --> 01:00:23.540]   Or we own Greece.
[01:00:23.540 --> 01:00:24.540]   We own Greece.
[01:00:24.540 --> 01:00:27.220]   They're apples bigger than Sweden.
[01:00:27.220 --> 01:00:29.980]   So let's buy it.
[01:00:29.980 --> 01:00:34.300]   So it's just I think a lot of this is just like well they got so much money.
[01:00:34.300 --> 01:00:38.300]   Who knows what they could do.
[01:00:38.300 --> 01:00:41.500]   I once said to Nick Denton when he had his prior company moreover I was in the board of
[01:00:41.500 --> 01:00:45.100]   that one and I said Nick you know one of the best things you did before the crash was
[01:00:45.100 --> 01:00:46.100]   raise a lot of money.
[01:00:46.100 --> 01:00:50.380]   He said no it was one of the worst things I did because it allowed the then CEO to go
[01:00:50.380 --> 01:00:53.860]   down all kinds of routes that that person shouldn't have gone down.
[01:00:53.860 --> 01:00:54.860]   Not good to have money.
[01:00:54.860 --> 01:00:56.660]   No it actually isn't.
[01:00:56.660 --> 01:00:57.660]   Yep.
[01:00:57.660 --> 01:00:58.660]   It causes distraction.
[01:00:58.660 --> 01:00:59.660]   It's distracting.
[01:00:59.660 --> 01:01:03.020]   What do we do with our hundred billion dollars in the bank?
[01:01:03.020 --> 01:01:05.740]   Street View they added they added airports.
[01:01:05.740 --> 01:01:11.260]   I guess that's Google Maps but then and then they added that we had it at CES.
[01:01:11.260 --> 01:01:14.740]   Now Google Street View and then they went into stores right now they're going cave
[01:01:14.740 --> 01:01:17.820]   diving in Japan.
[01:01:17.820 --> 01:01:21.100]   Google Street View is adding caves.
[01:01:21.100 --> 01:01:28.780]   They sent several photography crews to shoot long exposures of caves in Japan and you can
[01:01:28.780 --> 01:01:33.140]   I guess you can let's show you show you want to go in.
[01:01:33.140 --> 01:01:36.900]   Should we go for a ride?
[01:01:36.900 --> 01:01:38.620]   These are just images from street.
[01:01:38.620 --> 01:01:40.660]   This is this is an example of not having enough to do.
[01:01:40.660 --> 01:01:41.660]   Yeah too much money.
[01:01:41.660 --> 01:01:44.620]   We were just saying something about too much money.
[01:01:44.620 --> 01:01:45.620]   What are we going to do?
[01:01:45.620 --> 01:01:49.380]   Oh let's just take pictures of caves next next to their going to do a Google Street View
[01:01:49.380 --> 01:01:50.580]   of my nose.
[01:01:50.580 --> 01:01:56.500]   I think this is somewhat someone's really crafty 20% time projects like I know how can
[01:01:56.500 --> 01:01:58.060]   I get to go cave diving in Japan.
[01:01:58.060 --> 01:01:59.780]   I'll take the camera with me.
[01:01:59.780 --> 01:02:00.780]   Yeah.
[01:02:00.780 --> 01:02:02.380]   Oh that's it.
[01:02:02.380 --> 01:02:05.260]   That's probably what it is sure.
[01:02:05.260 --> 01:02:09.140]   They did a nice one where they put the camera on bicycles and yeah I like that.
[01:02:09.140 --> 01:02:10.140]   Yeah.
[01:02:10.140 --> 01:02:11.140]   One thing attacked by the sun again.
[01:02:11.140 --> 01:02:12.140]   Just do.
[01:02:12.140 --> 01:02:13.140]   Oh I like it.
[01:02:13.140 --> 01:02:14.220]   He's got a halo.
[01:02:14.220 --> 01:02:16.140]   Do any of you have the new Google bar yet?
[01:02:16.140 --> 01:02:18.420]   Just is it just me that doesn't have the new Google bar?
[01:02:18.420 --> 01:02:20.020]   Well they got rid of it didn't they?
[01:02:20.020 --> 01:02:21.020]   What?
[01:02:21.020 --> 01:02:22.540]   I never had it.
[01:02:22.540 --> 01:02:26.260]   I'm just the owner of the red bar and they're sticking with the black bar yeah.
[01:02:26.260 --> 01:02:27.260]   Oh yeah.
[01:02:27.260 --> 01:02:29.580]   So they just skipped me on the update.
[01:02:29.580 --> 01:02:32.860]   But the drop down all over the logo isn't there.
[01:02:32.860 --> 01:02:36.740]   The drop down they put the drop down back on the more at the end of the black bar.
[01:02:36.740 --> 01:02:38.500]   Are you not seeing that Leo?
[01:02:38.500 --> 01:02:40.300]   I don't know let me go to Google plus again.
[01:02:40.300 --> 01:02:41.300]   Yeah go to Google plus.
[01:02:41.300 --> 01:02:44.140]   All right and then the more drop down.
[01:02:44.140 --> 01:02:45.820]   That's what that's what I'm supposed to have right?
[01:02:45.820 --> 01:02:48.300]   Yeah that's this is the new bar.
[01:02:48.300 --> 01:02:50.700]   That's what I had yeah and so they took they took the drop down from.
[01:02:50.700 --> 01:02:54.060]   Remember it used to be you'd have to click on the Google logo drop down.
[01:02:54.060 --> 01:02:55.260]   No it's just here.
[01:02:55.260 --> 01:02:57.060]   They removed that yeah.
[01:02:57.060 --> 01:02:58.540]   And then there's even more.
[01:02:58.540 --> 01:03:00.500]   There's even more.
[01:03:00.500 --> 01:03:01.500]   Even more.
[01:03:01.500 --> 01:03:03.140]   What do I get that no I get this.
[01:03:03.140 --> 01:03:04.460]   They really obscure things.
[01:03:04.460 --> 01:03:08.300]   Yeah so really what's happened is I just what I they took long enough to get me the new
[01:03:08.300 --> 01:03:10.940]   Google bar that then went back to the old bar because they'll be like the new Google
[01:03:10.940 --> 01:03:11.940]   bar.
[01:03:11.940 --> 01:03:13.540]   They said they had a mean they said Leo wouldn't like this.
[01:03:13.540 --> 01:03:14.540]   We shouldn't do that.
[01:03:14.540 --> 01:03:17.620]   You'll complain it'll be a problem.
[01:03:17.620 --> 01:03:21.020]   And so they changed it I didn't even notice.
[01:03:21.020 --> 01:03:23.940]   What if they had a Google bar update and nobody came.
[01:03:23.940 --> 01:03:27.060]   Truthfully I didn't notice either when I saw the story I had the good check it.
[01:03:27.060 --> 01:03:28.060]   Isn't that funny.
[01:03:28.060 --> 01:03:29.580]   Yeah I hadn't really noticed.
[01:03:29.580 --> 01:03:30.580]   Wow.
[01:03:30.580 --> 01:03:31.580]   It's probably not fair.
[01:03:31.580 --> 01:03:32.580]   It's just you know.
[01:03:32.580 --> 01:03:36.780]   There's one more story then we're going to get to our tool our number and our tip of
[01:03:36.780 --> 01:03:39.100]   the week by the way Pinterest is back up.
[01:03:39.100 --> 01:03:40.100]   Thank you back.
[01:03:40.100 --> 01:03:41.740]   Just in case you were worried about it.
[01:03:41.740 --> 01:03:44.820]   It's a online pin board of wonderful things.
[01:03:44.820 --> 01:03:47.060]   All right well I got to admit Rami's.
[01:03:47.060 --> 01:03:50.180]   Pinterest.com/fakement mid-romney/pins.
[01:03:50.180 --> 01:03:52.140]   Is it going to am I going to be sorry.
[01:03:52.140 --> 01:03:53.300]   No no no no no no.
[01:03:53.300 --> 01:03:54.300]   It's not x-rated right.
[01:03:54.300 --> 01:03:55.140]   It's not x-rated.
[01:03:55.140 --> 01:03:59.780]   He's only got 534 followers.
[01:03:59.780 --> 01:04:03.540]   His favorite things are.
[01:04:03.540 --> 01:04:06.100]   He's got pet accessories.
[01:04:06.100 --> 01:04:10.700]   Every week and an I invite a few friends over for what we call triple bucker rot night.
[01:04:10.700 --> 01:04:13.860]   We serve cocktails in the bakarak glassware.
[01:04:13.860 --> 01:04:19.900]   Play a few hands of low stakes bakarah and hire our friend Bert Bakkerak to play American
[01:04:19.900 --> 01:04:21.540]   standards.
[01:04:21.540 --> 01:04:22.540]   This is pretty funny.
[01:04:22.540 --> 01:04:26.860]   Now see this is a new use for Pinterest I hadn't really thought about.
[01:04:26.860 --> 01:04:27.860]   I like.
[01:04:27.860 --> 01:04:28.860]   I like fake.
[01:04:28.860 --> 01:04:29.860]   Oh the dog.
[01:04:29.860 --> 01:04:32.860]   Well the dog carrier is funny.
[01:04:32.860 --> 01:04:33.980]   Oh let's go back here.
[01:04:33.980 --> 01:04:35.820]   So these are pet accessories.
[01:04:35.820 --> 01:04:37.700]   Yeah he well you know the whole dog.
[01:04:37.700 --> 01:04:40.420]   I found this in the sky mall catwalk.
[01:04:40.420 --> 01:04:41.420]   Funny.
[01:04:41.420 --> 01:04:49.060]   Oh the wild expensive wine.
[01:04:49.060 --> 01:04:51.500]   Do you guys like sangria?
[01:04:51.500 --> 01:04:56.500]   Wow I'm a big proponent of putting your dogs on a raw diet so much healthier.
[01:04:56.500 --> 01:05:04.940]   You know what I'd like to know is how does he get the cot because the comments are humorous
[01:05:04.940 --> 01:05:07.060]   as well.
[01:05:07.060 --> 01:05:12.300]   So Stephanie says mittens what are you doing flying commercial and reading sky mall is
[01:05:12.300 --> 01:05:14.220]   the jet in the shop.
[01:05:14.220 --> 01:05:15.220]   Mitt response.
[01:05:15.220 --> 01:05:20.740]   Oh Muffie twice a year American airline sends me a special compilation bound in leather.
[01:05:20.740 --> 01:05:25.180]   There's so many great inventions in there.
[01:05:25.180 --> 01:05:26.180]   That's gotta be.
[01:05:26.180 --> 01:05:36.300]   Oh well anyway I'm sorry I got to strike your car easily.
[01:05:36.300 --> 01:05:39.020]   New app for Google TV which rolled out which I can't get.
[01:05:39.020 --> 01:05:40.260]   Did you get it yet?
[01:05:40.260 --> 01:05:41.260]   I did not.
[01:05:41.260 --> 01:05:42.260]   I did not.
[01:05:42.260 --> 01:05:43.260]   I didn't try to.
[01:05:43.260 --> 01:05:50.340]   I tried and it said no I can't update right now but apparently YouTube has made according
[01:05:50.340 --> 01:05:54.380]   to this article and all things deep by Peter Kafka a small but important change in the
[01:05:54.380 --> 01:05:56.500]   way it deals with content owners.
[01:05:56.500 --> 01:06:01.260]   It's now insisting on the ability to play all videos from content partners on all platforms
[01:06:01.260 --> 01:06:02.780]   including mobile phones and connected TVs.
[01:06:02.780 --> 01:06:06.820]   I've run into this frequently where you'll be on your mobile phone and it'll say the
[01:06:06.820 --> 01:06:10.740]   content provider has requested it not play on mobile.
[01:06:10.740 --> 01:06:14.260]   Which is bizarre in the extreme.
[01:06:14.260 --> 01:06:15.660]   It is weird.
[01:06:15.660 --> 01:06:16.660]   Yeah.
[01:06:16.660 --> 01:06:21.140]   So apparently they're not going to allow that anymore.
[01:06:21.140 --> 01:06:24.460]   Is it the man's that mean they're going to stop embed blocking as well because that was
[01:06:24.460 --> 01:06:29.460]   the other thing is some things are not embeddable right play them from the site is that part
[01:06:29.460 --> 01:06:30.460]   of the change or not.
[01:06:30.460 --> 01:06:34.660]   Does not say that it says there will be it says.
[01:06:34.660 --> 01:06:39.140]   That's everywhere on all platforms mobile including mobile phones and connected TVs.
[01:06:39.140 --> 01:06:49.580]   It says all platforms so maybe that would be great if they could force embedding as well.
[01:06:49.580 --> 01:06:52.940]   Peter says I wouldn't be surprised if big Hollywood studios or TV networks also have carve outs
[01:06:52.940 --> 01:06:55.820]   that won't get changed.
[01:06:55.820 --> 01:07:04.380]   But you know if this is the problem with YouTube if you got it whatever they say because it's
[01:07:04.380 --> 01:07:06.580]   so important to be on YouTube.
[01:07:06.580 --> 01:07:10.220]   You know we get our videos pulled down so routinely that I don't even want to be on
[01:07:10.220 --> 01:07:14.060]   YouTube but what are we going to do right.
[01:07:14.060 --> 01:07:18.540]   What are you going to do anything else I don't want to let there's still many many stories
[01:07:18.540 --> 01:07:22.500]   that we didn't get to but I think we should get to we're running out of time so I think
[01:07:22.500 --> 01:07:23.500]   we should get to our.
[01:07:23.500 --> 01:07:25.500]   Okay I mentioned just one quick thing.
[01:07:25.500 --> 01:07:28.420]   The Google solve for X project.
[01:07:28.420 --> 01:07:29.580]   Love it.
[01:07:29.580 --> 01:07:34.940]   Which is wonderful a guy named Omri and I'm going to forget his last name Amrit Raudore
[01:07:34.940 --> 01:07:37.020]   mispronounced the name horribly.
[01:07:37.020 --> 01:07:41.660]   Go look it up he basically did a compiler you did a demonstration of what will happen
[01:07:41.660 --> 01:07:46.380]   when we have a compiler for DNA right and it's really quite wonderful it's it's it's
[01:07:46.380 --> 01:07:50.580]   we're going to get him on he actually is a fan he was in the studio with his son I didn't
[01:07:50.580 --> 01:07:55.860]   even notice because I you know this is kind of like Ted talks that Google does it's called
[01:07:55.860 --> 01:08:03.540]   we solve for X.com and Omri's right here synthetic life tool kits if you want to follow
[01:08:03.540 --> 01:08:10.100]   that and we will we're going to try to get him on to a triangulation I think probably
[01:08:10.100 --> 01:08:11.100]   sometimes.
[01:08:11.100 --> 01:08:12.700]   Wow okay good yeah it's very cool.
[01:08:12.700 --> 01:08:17.380]   It looks really interesting and by the way we were talking about the same site earlier
[01:08:17.380 --> 01:08:24.340]   because there's also a talk here about spray on antennas that would change everything so
[01:08:24.340 --> 01:08:26.780]   which we can't figure out is it a hoax what.
[01:08:26.780 --> 01:08:32.620]   I've seen that before it doesn't seem possible but this guy says the same as spray on the
[01:08:32.620 --> 01:08:38.220]   notion of spray on solar cells yeah so you could spray on a wall in a cell site could
[01:08:38.220 --> 01:08:43.540]   be the wall and they're much more efficient because they're nano capacitors I don't know
[01:08:43.540 --> 01:08:46.300]   anyway we're going to we're going to try to get the guy on our ham nation because these
[01:08:46.300 --> 01:08:51.140]   guys have anything to a lot about antennas but but that's enough of that enough about
[01:08:51.140 --> 01:08:55.220]   that let's get our tip of the week from Miss Jean-Trapani.
[01:08:55.220 --> 01:09:01.180]   Tip of the week this week is a Google image search tip it only works in chrome it's really
[01:09:01.180 --> 01:09:04.300]   cool though and you kind of have to you have to try it to see to see what I'm talking about
[01:09:04.300 --> 01:09:09.460]   so if you go to images.google.com in in chrome and you search you search for images say search
[01:09:09.460 --> 01:09:15.260]   for like exotic fruit you get results back you can say you see something that you want
[01:09:15.260 --> 01:09:19.700]   or see an image that you want to know more about you click and drag it to the top of
[01:09:19.700 --> 01:09:24.340]   the page there'll be a little drop area that'll say drop image here you drop the image there
[01:09:24.340 --> 01:09:28.460]   then it runs a search by image so it'll tell you you know what the image is and give
[01:09:28.460 --> 01:09:31.740]   you just regular search results about it so if you're ever if you ever get an image back
[01:09:31.740 --> 01:09:35.300]   in search results and you're like who is that or what is that just click and drag up
[01:09:35.300 --> 01:09:39.500]   near the search box and it'll run another search based on that image.
[01:09:39.500 --> 01:09:44.260]   Didn't they do that before where you could just drag an image from your desktop over.
[01:09:44.260 --> 01:09:47.540]   Yeah right you so you can write so you can do it from your desktop and now you can do
[01:09:47.540 --> 01:09:49.900]   it from sort of the search results itself.
[01:09:49.900 --> 01:09:56.100]   So if you drag a picture of Leo the port will it go?
[01:09:56.100 --> 01:09:57.620]   Well that's a good question.
[01:09:57.620 --> 01:09:59.460]   Let me do it let me do it.
[01:09:59.460 --> 01:10:05.580]   They do it there they will give you another image if they find that image they'll give
[01:10:05.580 --> 01:10:07.180]   you the caption from it I think.
[01:10:07.180 --> 01:10:16.660]   So this is a picture of me whoops.
[01:10:16.660 --> 01:10:22.100]   Best guest image look for it's doing the face recognition and it will show you the pages
[01:10:22.100 --> 01:10:24.100]   that contain that match.
[01:10:24.100 --> 01:10:27.260]   I don't think it's doing face recognition I think it's using that looking at the page
[01:10:27.260 --> 01:10:31.740]   that has that I think if you picture of someone non-famous it won't work.
[01:10:31.740 --> 01:10:36.580]   Okay non-famous well but but it's got to be somewhat fair that it's got to have images
[01:10:36.580 --> 01:10:37.580]   like that.
[01:10:37.580 --> 01:10:38.580]   Yes.
[01:10:38.580 --> 01:10:42.620]   So these all of these are captioned with my name in some way or the other so of course
[01:10:42.620 --> 01:10:43.620]   it's going to.
[01:10:43.620 --> 01:10:44.620]   Yeah.
[01:10:44.620 --> 01:10:46.220]   Now see it didn't it didn't find anything here.
[01:10:46.220 --> 01:10:47.220]   Okay.
[01:10:47.220 --> 01:10:48.220]   Yeah.
[01:10:48.220 --> 01:10:49.220]   Let's hit.
[01:10:49.220 --> 01:10:50.220]   So it's not that smart.
[01:10:50.220 --> 01:10:52.220]   All right interesting isn't that interesting.
[01:10:52.220 --> 01:10:56.660]   Yeah it is interesting because there are sometimes when you do an image search and you
[01:10:56.660 --> 01:11:00.060]   got that one weird image like what the heck is this.
[01:11:00.060 --> 01:11:03.860]   So I searched for similar images and now it's a bunch of people waving with it.
[01:11:03.860 --> 01:11:09.700]   It's the jazz hands jazz hands search and guitars.
[01:11:09.700 --> 01:11:12.420]   Yeah everybody should do a jazz hand search.
[01:11:12.420 --> 01:11:16.820]   Yeah I'm with Google image search ladies and gentlemen.
[01:11:16.820 --> 01:11:17.820]   It is fun.
[01:11:17.820 --> 01:11:21.260]   You know I'm actually using duck duck go like pretty I've stuck with it really changed
[01:11:21.260 --> 01:11:22.260]   last week.
[01:11:22.260 --> 01:11:27.900]   Yeah for my regular web search and but I use Google still for images maps and so so this
[01:11:27.900 --> 01:11:28.900]   is helpful.
[01:11:28.900 --> 01:11:32.660]   Yeah I want to go just hit their first first day one million searches.
[01:11:32.660 --> 01:11:33.660]   It's pretty good.
[01:11:33.660 --> 01:11:39.260]   There are a few searches where I have missed Google and I've had to adjust my search terms
[01:11:39.260 --> 01:11:43.780]   and I miss one box but but I'm sticking with it for just a little bit longer to see if
[01:11:43.780 --> 01:11:47.660]   I can truly you know not use Google search on a regular.
[01:11:47.660 --> 01:11:50.340]   You saw that Google is now blocking scruggle.
[01:11:50.340 --> 01:11:51.340]   Yes.
[01:11:51.340 --> 01:11:56.180]   Saying it's over over searching they think it's a bot.
[01:11:56.180 --> 01:11:57.180]   Yeah.
[01:11:57.180 --> 01:12:01.900]   And this worries me that that search services that use Google and massage it perhaps to
[01:12:01.900 --> 01:12:06.380]   make it anonymous are going to get this kind of treatment.
[01:12:06.380 --> 01:12:07.380]   This is not treatment.
[01:12:07.380 --> 01:12:13.620]   Yeah I hate to be the Google defender but you know at some point you can say you're using
[01:12:13.620 --> 01:12:16.540]   our service and taking it away from our revenue.
[01:12:16.540 --> 01:12:21.820]   Oh that's basically what what scruggle does is strips out the ads.
[01:12:21.820 --> 01:12:22.820]   Yeah so.
[01:12:22.820 --> 01:12:23.820]   Right.
[01:12:23.820 --> 01:12:27.540]   But duck duck go uses a few different services.
[01:12:27.540 --> 01:12:31.460]   I mean you could argue that it generates signals from lots of different engines kind of
[01:12:31.460 --> 01:12:36.260]   the same way that Google generates signals from web pages or you know social search.
[01:12:36.260 --> 01:12:39.020]   But I do see where you're coming from Jeff.
[01:12:39.020 --> 01:12:42.460]   You know at the point at which it's like hey you're just showing our search results without.
[01:12:42.460 --> 01:12:43.460]   Right.
[01:12:43.460 --> 01:12:44.460]   Yeah.
[01:12:44.460 --> 01:12:45.460]   Scruggle I think is a clear case of.
[01:12:45.460 --> 01:12:46.460]   Yeah.
[01:12:46.460 --> 01:12:48.460]   You know kind of even say we're scraping Google.
[01:12:48.460 --> 01:12:49.460]   Yeah.
[01:12:49.460 --> 01:12:50.460]   Yeah.
[01:12:50.460 --> 01:12:52.460]   Well they just change it to a browser plugin instead.
[01:12:52.460 --> 01:12:55.180]   I'm going to be happy.
[01:12:55.180 --> 01:12:56.460]   Jeff your number of the week.
[01:12:56.460 --> 01:12:58.460]   Alright I'm going to do it.
[01:12:58.460 --> 01:13:01.140]   My friends you were all so wonderful last week.
[01:13:01.140 --> 01:13:02.860]   With the economist debate.
[01:13:02.860 --> 01:13:03.860]   Yes.
[01:13:03.860 --> 01:13:04.860]   Did we win?
[01:13:04.860 --> 01:13:05.860]   Oh well it's not over yet.
[01:13:05.860 --> 01:13:06.860]   That's the point.
[01:13:06.860 --> 01:13:10.740]   We took it from 37% in moments to 70% by the time we were off the air.
[01:13:10.740 --> 01:13:11.820]   Well it slipped folks.
[01:13:11.820 --> 01:13:15.420]   It went to 72 and now it's back to 69.
[01:13:15.420 --> 01:13:23.620]   So friends economist.com slash is a debate or debates debate and you know the side that
[01:13:23.620 --> 01:13:27.420]   I'm on is in favor of the motion and I'm not trying to push this.
[01:13:27.420 --> 01:13:34.300]   The funny was my bet more in this case and Rucheen did try to game.
[01:13:34.300 --> 01:13:35.780]   I would have done this if he didn't do it first.
[01:13:35.780 --> 01:13:39.580]   He did it first and when we try to game it and try to get people to do this and so I
[01:13:39.580 --> 01:13:43.340]   thought well hell I'll do it and I just have more friends than he does because I'm more
[01:13:43.340 --> 01:13:46.700]   public and because Leo the port knows me.
[01:13:46.700 --> 01:13:49.540]   So Jeff you're winning 69 at 31.
[01:13:49.540 --> 01:13:51.620]   What is exactly you would like.
[01:13:51.620 --> 01:13:54.780]   I want 75%.
[01:13:54.780 --> 01:13:55.900]   I want to kill him.
[01:13:55.900 --> 01:13:58.300]   I don't want me to injure him.
[01:13:58.300 --> 01:13:59.780]   No, no I want to kill him.
[01:13:59.780 --> 01:14:01.580]   I want to destroy him.
[01:14:01.580 --> 01:14:06.420]   And in the second of the three statements I gave credit to all of you wonderful twiggers
[01:14:06.420 --> 01:14:08.860]   at the end for doing this with some amusement.
[01:14:08.860 --> 01:14:10.060]   So I thank you for that.
[01:14:10.060 --> 01:14:11.060]   Good.
[01:14:11.060 --> 01:14:12.060]   Everybody should vote.
[01:14:12.060 --> 01:14:13.060]   Vote yes.
[01:14:13.060 --> 01:14:14.900]   Vote early vote often.
[01:14:14.900 --> 01:14:16.580]   These favor the motion.
[01:14:16.580 --> 01:14:20.780]   And even if you voted for Andrew you can change your vote which would make Jeff even happier.
[01:14:20.780 --> 01:14:24.700]   Oh that would that would hurt him more.
[01:14:24.700 --> 01:14:26.300]   You're not a nuclear fool.
[01:14:26.300 --> 01:14:29.620]   God you're worse than Steve Jobs.
[01:14:29.620 --> 01:14:31.620]   Holy cow.
[01:14:31.620 --> 01:14:33.580]   Holy cow.
[01:14:33.580 --> 01:14:35.580]   And did you want to do the Angry Birds number as well?
[01:14:35.580 --> 01:14:39.100]   Oh yeah yeah just I think there's a bit given that we've got Angry Birds behind Kevin
[01:14:39.100 --> 01:14:40.100]   Marks.
[01:14:40.100 --> 01:14:41.180]   They've been battling it out.
[01:14:41.180 --> 01:14:44.900]   Actually I was thinking as a Howard Stern fan I thought Mary Ann from Brooklyn was on
[01:14:44.900 --> 01:14:45.900]   the phone.
[01:14:45.900 --> 01:14:49.300]   But that's a reference only that Howard Stern fans will get.
[01:14:49.300 --> 01:14:53.100]   And that Fred was hitting the button in the Antut studio.
[01:14:53.100 --> 01:14:59.620]   So Angry Birds now that it's on Facebook they're saying their goal is to get one billion players.
[01:14:59.620 --> 01:15:02.780]   One billion players.
[01:15:02.780 --> 01:15:08.140]   Which is you know if you go to Clay Shurkey's cognitive surplus think of all the wonderful
[01:15:08.140 --> 01:15:11.900]   things that we could do for society if we weren't doing this.
[01:15:11.900 --> 01:15:16.260]   Yes how can we how can we embed the world's problems into Angry Birds.
[01:15:16.260 --> 01:15:20.460]   Right they should be doing some sort of calculations some sort of solving of something.
[01:15:20.460 --> 01:15:23.460]   Bigs and the truth.
[01:15:23.460 --> 01:15:24.620]   Tell me if I've done this before.
[01:15:24.620 --> 01:15:28.660]   Have I talked about local before on this show the Android app locale.
[01:15:28.660 --> 01:15:29.980]   I don't think so.
[01:15:29.980 --> 01:15:30.980]   I don't think so.
[01:15:30.980 --> 01:15:32.340]   It's not a diet.
[01:15:32.340 --> 01:15:34.460]   It's locale with an E at the end of it.
[01:15:34.460 --> 01:15:36.180]   This is something that the iPhone does not do.
[01:15:36.180 --> 01:15:42.660]   This is actually a good example of how I think a more liberal permissions structure benefits
[01:15:42.660 --> 01:15:44.380]   folks on the iPhone.
[01:15:44.380 --> 01:15:47.580]   This is a program well I'll show you all set it up.
[01:15:47.580 --> 01:15:53.060]   It's a free download L O C A L E. We're getting over the shoulder shy.
[01:15:53.060 --> 01:15:54.060]   Yes.
[01:15:54.060 --> 01:15:55.620]   Second issue here with our wife.
[01:15:55.620 --> 01:15:58.980]   Put the put the put the put the put the put the put the put the put the put.
[01:15:58.980 --> 01:16:01.820]   So the idea is you can add situations.
[01:16:01.820 --> 01:16:05.780]   The situation I'm going to title this work because I'm going to make this be a geographic
[01:16:05.780 --> 01:16:07.380]   situation.
[01:16:07.380 --> 01:16:13.340]   But the situation can be a battery level a contact name a location orientation or time.
[01:16:13.340 --> 01:16:18.300]   All these location it'll look up where I am and there we go and I can say here I can
[01:16:18.300 --> 01:16:23.020]   narrow it down or I can increase I can narrow the radius or I can increase the radius of
[01:16:23.020 --> 01:16:24.540]   the thing down to 100 meters.
[01:16:24.540 --> 01:16:26.220]   I'm going to make it 100 meters.
[01:16:26.220 --> 01:16:32.260]   So I am at work and now I can have some settings and that one of these is fantastic and I'd
[01:16:32.260 --> 01:16:33.780]   love to see this in to do text.
[01:16:33.780 --> 01:16:35.580]   Astrid which is a to do manager.
[01:16:35.580 --> 01:16:39.900]   Well if you have a list for instance I could say I could have an Astrid list the stuff I
[01:16:39.900 --> 01:16:46.540]   have to do when I'm at work I can add that and then I can say every hour notify me while
[01:16:46.540 --> 01:16:49.180]   I'm at work that I should do this list.
[01:16:49.180 --> 01:16:53.380]   So now whenever I'm at work I've got this to do I can have other settings as well brightness
[01:16:53.380 --> 01:16:59.140]   ringtone so I can have different ringtone for home work driving around screen timeout
[01:16:59.140 --> 01:17:03.740]   volume wallpaper and Wi-Fi I'd love to see more settings in here but these are the ones
[01:17:03.740 --> 01:17:05.460]   that are exposed to the developer.
[01:17:05.460 --> 01:17:09.860]   The most useful one is the Astrid but for instance you could say hey when I'm at work
[01:17:09.860 --> 01:17:15.660]   I really and I do do this I want the ringtone to be silent so that the phone doesn't ring
[01:17:15.660 --> 01:17:18.060]   while I'm on the ear.
[01:17:18.060 --> 01:17:23.380]   You can add these settings you can have multiple locations you have a default location which
[01:17:23.380 --> 01:17:27.540]   is if you are not anywhere in particular so if for instance you do change the ringtone
[01:17:27.540 --> 01:17:33.260]   as silent as soon as you leave work you can have the ringtone be something like the well
[01:17:33.260 --> 01:17:40.140]   tempered clove air and so that would be the default ringtone except when you are at places
[01:17:40.140 --> 01:17:44.980]   where another ringtone is specified you could have different you know you could turn off
[01:17:44.980 --> 01:17:48.460]   Wi-Fi but turn on Bluetooth as you get in the car things like that.
[01:17:48.460 --> 01:17:54.700]   So this is a really great little program it's called locale and I find it very useful.
[01:17:54.700 --> 01:17:59.100]   It also supports something else I've talked about before called Scribel which is I mentioned
[01:17:59.100 --> 01:18:05.900]   this I think on a previous show Scribel is that little app that lets me turn my sleep behavior
[01:18:05.900 --> 01:18:10.740]   change my sleep behavior whenever the phone is tilted it just says keep the screen on
[01:18:10.740 --> 01:18:14.540]   as long as Leo is handling the phone as soon as he puts it down turn it off.
[01:18:14.540 --> 01:18:19.980]   So Scribel is a handy little hack that came up with somebody came up with a Google hack
[01:18:19.980 --> 01:18:20.980]   event.
[01:18:20.980 --> 01:18:25.700]   You can also have Scribel settings modified by locale so that for instance when I'm driving
[01:18:25.700 --> 01:18:30.300]   I turn off Scribel because sometimes the phone is tilted like this and I do want the screen
[01:18:30.300 --> 01:18:31.500]   to go out.
[01:18:31.500 --> 01:18:35.580]   So just very handy I'd love to see more applications for that and I don't think there's an analog
[01:18:35.580 --> 01:18:39.500]   for iOS anything like that I think it's just very cool.
[01:18:39.500 --> 01:18:41.420]   It's similar to Tasker for Android.
[01:18:41.420 --> 01:18:42.660]   Tasker same thing exactly.
[01:18:42.660 --> 01:18:46.300]   Yeah but it looks at the interface looks a little nicer on locale I have to say because
[01:18:46.300 --> 01:18:48.900]   Tasker is kind of a maze of settings.
[01:18:48.900 --> 01:18:55.100]   The prop that's exactly the problem I love Tasker same exact idea but yeah it's kind of
[01:18:55.100 --> 01:18:59.300]   overwhelming because Tasker can do so much more so maybe that's what happened with localis.
[01:18:59.300 --> 01:19:01.980]   They decided that they shouldn't make it so complicated.
[01:19:01.980 --> 01:19:05.540]   So the thing that I was worried about with these apps is like running an app like that
[01:19:05.540 --> 01:19:08.700]   in the background that's constantly checking my location and changing settings does that
[01:19:08.700 --> 01:19:09.700]   drain the battery.
[01:19:09.700 --> 01:19:11.860]   I mean you're the one with six batteries so I don't know.
[01:19:11.860 --> 01:19:15.380]   I keep a battery at all times believe me.
[01:19:15.380 --> 01:19:20.940]   So yeah you're absolutely right I mean that's the real risk on this.
[01:19:20.940 --> 01:19:22.340]   You can have it set.
[01:19:22.340 --> 01:19:27.540]   There's a new locale there's a new beta locale that is more that yes is I think much better
[01:19:27.540 --> 01:19:30.780]   with battery and I actually haven't noticed a lot of battery life loss.
[01:19:30.780 --> 01:19:37.220]   You can tell when locale is active because it does put something in the in the notification.
[01:19:37.220 --> 01:19:40.780]   That's a good question you know anytime you keep the GPS on you got a problem with a locale
[01:19:40.780 --> 01:19:41.860]   can turn off the GPS.
[01:19:41.860 --> 01:19:48.660]   I think if you do use locale you should really set it up to maximize battery life you know
[01:19:48.660 --> 01:19:53.140]   turn off stuff and use it that way and I think the net will be a positive.
[01:19:53.140 --> 01:19:54.620]   Right right.
[01:19:54.620 --> 01:19:57.940]   So that's locale you probably mentioned that on about Android Island.
[01:19:57.940 --> 01:19:58.940]   We talked about Tasker.
[01:19:58.940 --> 01:19:59.940]   Taskers cool.
[01:19:59.940 --> 01:20:03.900]   Yeah I have both and I actually choose to use locale more than I.
[01:20:03.900 --> 01:20:05.900]   Look how it looks nicer fiddly here.
[01:20:05.900 --> 01:20:08.500]   Yeah a lot of little.
[01:20:08.500 --> 01:20:10.220]   And it works great it's nice to have it.
[01:20:10.220 --> 01:20:14.100]   So I have it set for instance when I go to the store it pulls up my shopping list.
[01:20:14.100 --> 01:20:15.260]   Yeah that's so cool.
[01:20:15.260 --> 01:20:17.020]   That's really nice.
[01:20:17.020 --> 01:20:22.260]   You're supposed to do that but that's silly for me.
[01:20:22.260 --> 01:20:27.340]   I'm frustrated because Siri is so great when it works that when it doesn't work it's very
[01:20:27.340 --> 01:20:29.340]   frustrating.
[01:20:29.340 --> 01:20:35.340]   Kevin Marks is at the fabulous sales force but you might want to watch his show Tumblevision
[01:20:35.340 --> 01:20:36.580]   at Tumblevision.tv.
[01:20:36.580 --> 01:20:38.060]   What days do you do that?
[01:20:38.060 --> 01:20:41.100]   Thursday nights at 6 p.m. Pacific 3 p.m. Eastern.
[01:20:41.100 --> 01:20:45.660]   You can watch live at Tumblevision.tv and follow him on Twitter @KevinMarkz.
[01:20:45.660 --> 01:20:46.660]   Thank you so much for being here Kevin.
[01:20:46.660 --> 01:20:47.660]   We really appreciate it.
[01:20:47.660 --> 01:20:48.660]   Kevin let's do it again.
[01:20:48.660 --> 01:20:51.100]   It's 6 o'clock on the West Coast.
[01:20:51.100 --> 01:20:53.660]   Yeah I was going to say you got that switched around.
[01:20:53.660 --> 01:20:56.180]   I was 9 o'clock on these guys.
[01:20:56.180 --> 01:20:57.180]   Thank you.
[01:20:57.180 --> 01:20:58.180]   I just make a job out.
[01:20:58.180 --> 01:20:59.180]   You were listening to him.
[01:20:59.180 --> 01:21:00.180]   Jeff Jarvis.
[01:21:00.180 --> 01:21:01.700]   Have you ever corrected Kevin Marks in life?
[01:21:01.700 --> 01:21:02.700]   That's it.
[01:21:02.700 --> 01:21:03.700]   There you go.
[01:21:03.700 --> 01:21:04.700]   That's it.
[01:21:04.700 --> 01:21:05.700]   You had your shot.
[01:21:05.700 --> 01:21:08.900]   I'm a man with my CD.
[01:21:08.900 --> 01:21:11.460]   Mr. Jeff Jarvis is at the City University of New York.
[01:21:11.460 --> 01:21:13.540]   His book Public Parks is available in bookstores right now.
[01:21:13.540 --> 01:21:17.180]   You can follow his blog at Buzzmachine.com.
[01:21:17.180 --> 01:21:18.180]   Gina Trapani.
[01:21:18.180 --> 01:21:20.180]   There we go.
[01:21:20.180 --> 01:21:21.180]   Yes.
[01:21:21.180 --> 01:21:22.180]   There it is.
[01:21:22.180 --> 01:21:23.180]   There.
[01:21:23.180 --> 01:21:24.180]   SUNY.
[01:21:24.180 --> 01:21:25.180]   You say SUNY or CUNY?
[01:21:25.180 --> 01:21:26.180]   SUNY is State University.
[01:21:26.180 --> 01:21:27.680]   You have to say CUNY.
[01:21:27.680 --> 01:21:31.620]   Gina Trapani is of course at smartaward.org.
[01:21:31.620 --> 01:21:32.620]   It's a great thing.
[01:21:32.620 --> 01:21:33.620]   CUNY graduate.
[01:21:33.620 --> 01:21:34.620]   Are you?
[01:21:34.620 --> 01:21:35.620]   Yes I am.
[01:21:35.620 --> 01:21:36.620]   Oh wow.
[01:21:36.620 --> 01:21:37.620]   Brooklyn College.
[01:21:37.620 --> 01:21:38.620]   Oh what are the chances?
[01:21:38.620 --> 01:21:39.620]   Wow.
[01:21:39.620 --> 01:21:40.620]   Hala.
[01:21:40.620 --> 01:21:42.420]   For micro, for graduate school.
[01:21:42.420 --> 01:21:43.420]   Wow.
[01:21:43.420 --> 01:21:44.420]   Also a smartaward.org.
[01:21:44.420 --> 01:21:45.420]   Yes.
[01:21:45.420 --> 01:21:46.420]   Thank you Gina.
[01:21:46.420 --> 01:21:47.420]   Thank you Jeff.
[01:21:47.420 --> 01:21:48.420]   Thank you Kevin.
[01:21:48.420 --> 01:21:49.420]   Thank you for being here.
[01:21:49.420 --> 01:21:50.420]   We do the show.
[01:21:50.420 --> 01:21:51.420]   1 p.m.
[01:21:51.420 --> 01:21:52.420]   Pacific 4 p.m.
[01:21:52.420 --> 01:21:54.220]   Eastern Time on Twit.tv every Wednesday.
[01:21:54.220 --> 01:21:55.940]   But you can always get the download.
[01:21:55.940 --> 01:21:59.180]   We have audio and video available on the website or on all the places.
[01:21:59.180 --> 01:22:01.660]   You can get to find our podcast to search for.
[01:22:01.660 --> 01:22:02.660]   Twig.
[01:22:02.660 --> 01:22:04.740]   This week in Google.
[01:22:04.740 --> 01:22:09.140]   I have assigned my son the job of writing us a new theme.
[01:22:09.140 --> 01:22:10.140]   We'll see.
[01:22:10.140 --> 01:22:11.140]   Very cool.
[01:22:11.140 --> 01:22:14.780]   I will send you his first mix and you can decide.
[01:22:14.780 --> 01:22:16.420]   It's pretty good.
[01:22:16.420 --> 01:22:18.220]   It's got a great drop.
[01:22:18.220 --> 01:22:19.220]   We'll see.
[01:22:19.220 --> 01:22:22.660]   We'll see you next time on this week in Google.
[01:22:22.660 --> 01:22:23.500]   Thanks for joining us.
[01:22:23.500 --> 01:22:24.500]   Bye.
[01:22:24.500 --> 01:22:29.500]   a.m.
[01:22:29.500 --> 01:22:31.500]   a.m.
[01:22:31.500 --> 01:22:32.500]   .
[01:22:32.500 --> 01:22:34.500]   ♪♪♪

