;FFMETADATA1
title=The Spectacles Spectacular
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=383
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:02.640]   It's time for Twig this week in Google.
[00:00:02.640 --> 00:00:03.960]   They're here.
[00:00:03.960 --> 00:00:06.800]   I'm gonna unbox the Snapchat Spectacles.
[00:00:06.800 --> 00:00:10.680]   We'll talk about the tech summit going on right now in the Trump Tower.
[00:00:10.680 --> 00:00:14.000]   And the Google self-driving car.
[00:00:14.000 --> 00:00:15.200]   It's got a new name.
[00:00:15.200 --> 00:00:17.680]   We'll reveal all next on Twig.
[00:00:17.680 --> 00:00:23.160]   Netcast you love.
[00:00:23.160 --> 00:00:25.000]   From people you trust.
[00:00:28.400 --> 00:00:31.000]   This is Twig.
[00:00:31.000 --> 00:00:34.760]   Bandwidth for this week in Google is provided by cash fly.
[00:00:34.760 --> 00:00:38.160]   C-A-C-H-E-F-L-Y dot com.
[00:00:38.160 --> 00:00:45.880]   This is Twig this week in Google, episode 383.
[00:00:45.880 --> 00:00:50.200]   Recorded Wednesday, December 14, 2016.
[00:00:50.200 --> 00:00:53.240]   The Spectacles Spectacular.
[00:00:53.240 --> 00:00:57.560]   This week in Google is brought to you by FreshBooks, the super simple cloud accounting software.
[00:00:57.560 --> 00:01:03.000]   It's giving thousands of freelancers and small businesses the tools to save time building and get paid faster.
[00:01:03.000 --> 00:01:07.040]   Try it free at freshbooks.com/twig.
[00:01:07.040 --> 00:01:10.960]   It's time for Twig this week in Google, the show where we talk about this week in Google.
[00:01:10.960 --> 00:01:12.320]   And Facebook and Twitter.
[00:01:12.320 --> 00:01:14.760]   And Trump.
[00:01:14.760 --> 00:01:17.280]   You should be a new one this week in Trump.
[00:01:17.280 --> 00:01:19.640]   Jeff Jarvis, you can host it if you want.
[00:01:19.640 --> 00:01:22.440]   Yeah, I don't know if my stomach acid can take it.
[00:01:22.440 --> 00:01:26.960]   Buzzmachine.com, were you buzzed yesterday by the C-130 flying around over me?
[00:01:26.960 --> 00:01:28.200]   No, I wasn't around.
[00:01:28.200 --> 00:01:29.280]   I saw I already had that.
[00:01:29.280 --> 00:01:32.480]   Yeah, if you go to Fifth Avenue, that was in Fifth Avenue.
[00:01:32.480 --> 00:01:34.160]   And it's always crazy there.
[00:01:34.160 --> 00:01:41.240]   You know what's funny is we have helicopters buzzing us all, you know, the coast cars down the road.
[00:01:41.240 --> 00:01:43.000]   There's training missions and stuff.
[00:01:43.000 --> 00:01:46.600]   And we run out, we look up and we go, OK, and we go back in.
[00:01:46.600 --> 00:01:52.480]   But Manhattan is like the same size as Petaloma, but it's got a lot more people.
[00:01:52.480 --> 00:01:53.960]   And all the media.
[00:01:53.960 --> 00:01:57.560]   And so suddenly that's a massive story, right?
[00:01:57.560 --> 00:01:59.480]   It's just it was a military exercise.
[00:01:59.480 --> 00:02:03.120]   But I understand why people are a little a feared and nervous.
[00:02:03.120 --> 00:02:07.160]   Some people thought it was Obama coming to take over.
[00:02:07.160 --> 00:02:10.520]   Seriously, I am not kidding.
[00:02:10.520 --> 00:02:11.880]   I saw on Twitter--
[00:02:11.880 --> 00:02:13.160]   He's still in charge, you know.
[00:02:13.160 --> 00:02:15.000]   I saw on Twitter.
[00:02:15.000 --> 00:02:22.760]   Well, no, but the whole point is that there are people who expect that Obama will prevent
[00:02:22.760 --> 00:02:27.160]   this transition and King himself.
[00:02:27.160 --> 00:02:31.920]   And they expect military action.
[00:02:31.920 --> 00:02:35.040]   And there were people-- see, this is why I love Twitter.
[00:02:35.040 --> 00:02:36.120]   And you know I love Twitter.
[00:02:36.120 --> 00:02:40.680]   Stacey Higginbotham, IOTpodcast.com.
[00:02:40.680 --> 00:02:41.680]   Stacey on IOT.
[00:02:41.680 --> 00:02:44.320]   She's our IOT guru.
[00:02:44.320 --> 00:02:48.640]   And wonderful to have you both from Austin, Texas.
[00:02:48.640 --> 00:02:50.600]   I have a little something.
[00:02:50.600 --> 00:02:53.160]   Is it a minion?
[00:02:53.160 --> 00:02:54.720]   I want it to be a minion.
[00:02:54.720 --> 00:02:57.920]   Like you will have the my minions.
[00:02:57.920 --> 00:02:59.920]   You are my minions.
[00:02:59.920 --> 00:03:00.920]   Oh, you got it.
[00:03:00.920 --> 00:03:02.760]   You didn't have to stand in line?
[00:03:02.760 --> 00:03:05.320]   I took advantage of this thing called eBay.
[00:03:05.320 --> 00:03:08.240]   I don't know how much over the market was it?
[00:03:08.240 --> 00:03:09.640]   It was only 200 some.
[00:03:09.640 --> 00:03:10.640]   Wasn't much.
[00:03:10.640 --> 00:03:12.120]   Oh, so they're down for about thousands.
[00:03:12.120 --> 00:03:13.120]   Yeah, and it was a buy now.
[00:03:13.120 --> 00:03:17.160]   And that's because the store in Manhattan is open all the time, or not all the time, but
[00:03:17.160 --> 00:03:18.400]   all evening.
[00:03:18.400 --> 00:03:20.960]   And so it's a lot and you can make a reservation so it's a lot easier.
[00:03:20.960 --> 00:03:25.600]   So I think people are actually content to make a hundred bucks.
[00:03:25.600 --> 00:03:27.360]   I would be content to make a hundred bucks.
[00:03:27.360 --> 00:03:28.800]   They go, they get a few.
[00:03:28.800 --> 00:03:29.800]   Yeah.
[00:03:29.800 --> 00:03:32.200]   So here you go.
[00:03:32.200 --> 00:03:33.200]   Should I open it?
[00:03:33.200 --> 00:03:34.800]   I mean, it's sealed in the box.
[00:03:34.800 --> 00:03:36.440]   I'll have to charge him.
[00:03:36.440 --> 00:03:38.640]   But I thought it's probably important for me to know about this.
[00:03:38.640 --> 00:03:40.240]   I'm not a big snapper.
[00:03:40.240 --> 00:03:41.560]   It is.
[00:03:41.560 --> 00:03:42.560]   It's totally important.
[00:03:42.560 --> 00:03:45.000]   Yeah, this is something the kids are doing.
[00:03:45.000 --> 00:03:47.160]   Oh, you chose black.
[00:03:47.160 --> 00:03:48.720]   Not coral or turquoise.
[00:03:48.720 --> 00:03:53.960]   Well, okay, call me insane, but I just want I didn't want to look too weird.
[00:03:53.960 --> 00:03:56.560]   I'm going to call you old.
[00:03:56.560 --> 00:03:58.720]   I won't call you and say it.
[00:03:58.720 --> 00:03:59.720]   I'll just.
[00:03:59.720 --> 00:04:00.720]   Oh, now I don't know.
[00:04:00.720 --> 00:04:03.440]   Is this supposed to be speckled like that or is that mold?
[00:04:03.440 --> 00:04:04.800]   I guess it's supposed to be speckled.
[00:04:04.800 --> 00:04:05.800]   That looks legit.
[00:04:05.800 --> 00:04:07.960]   That looks legit.
[00:04:07.960 --> 00:04:09.400]   Smell it and see what happens.
[00:04:09.400 --> 00:04:11.400]   Oh, it's like fine.
[00:04:11.400 --> 00:04:14.240]   Polly, you're a thing.
[00:04:14.240 --> 00:04:16.120]   That's the charger right there.
[00:04:16.120 --> 00:04:17.120]   I'm going to need a.
[00:04:17.120 --> 00:04:18.120]   Oh, yeah.
[00:04:18.120 --> 00:04:23.480]   Because they charge in the case while these are new in the box, kids.
[00:04:23.480 --> 00:04:27.040]   All right, I'm going to put them on.
[00:04:27.040 --> 00:04:29.360]   I don't think there's a charge on them, but I'm going to put them on.
[00:04:29.360 --> 00:04:30.560]   You tell me how good I look.
[00:04:30.560 --> 00:04:31.560]   Goofy time.
[00:04:31.560 --> 00:04:32.560]   Ready?
[00:04:32.560 --> 00:04:39.880]   I actually think for your face, they should be a little bigger Leo, which is quite a.
[00:04:39.880 --> 00:04:43.720]   I have a very they look huge on everybody else, don't they?
[00:04:43.720 --> 00:04:45.840]   And I have such a melon head.
[00:04:45.840 --> 00:04:49.040]   I have the world's most massive head.
[00:04:49.040 --> 00:04:54.360]   And I have to actually buy special wide glasses.
[00:04:54.360 --> 00:04:55.560]   Like the big and tall glasses.
[00:04:55.560 --> 00:04:58.640]   I got a big and tall glasses store.
[00:04:58.640 --> 00:05:00.760]   And these are too small for me, dang it.
[00:05:00.760 --> 00:05:05.240]   I thought if anything would be big enough.
[00:05:05.240 --> 00:05:07.040]   Cara, come here.
[00:05:07.040 --> 00:05:09.920]   Put these on and see how it looks on you.
[00:05:09.920 --> 00:05:12.600]   Cara's a beautiful young woman who has a normal size head.
[00:05:12.600 --> 00:05:13.600]   See, they look.
[00:05:13.600 --> 00:05:14.800]   Oh, Cara, they look good.
[00:05:14.800 --> 00:05:16.560]   They look so good on you.
[00:05:16.560 --> 00:05:19.360]   Oh, I should just give them to Cara.
[00:05:19.360 --> 00:05:22.040]   Oh, my gosh.
[00:05:22.040 --> 00:05:26.600]   I was actually, yeah, I was going to, I think I'm going to keep them because I want, I,
[00:05:26.600 --> 00:05:27.600]   I like the idea.
[00:05:27.600 --> 00:05:32.320]   I've heard that streaming live videos all the rage these days.
[00:05:32.320 --> 00:05:35.440]   So I was thinking maybe I should do some of that.
[00:05:35.440 --> 00:05:37.320]   I don't look like Casey Neistat, that's for sure.
[00:05:37.320 --> 00:05:38.320]   So look at this.
[00:05:38.320 --> 00:05:43.240]   They get a nice USB cable and it's, it's, this is proprietary.
[00:05:43.240 --> 00:05:45.320]   It's not a traditional USB cable.
[00:05:45.320 --> 00:05:48.360]   It's got pogo pins that go in the back of this.
[00:05:48.360 --> 00:05:50.080]   But you know what, John, I'm just going to plug it into the computer.
[00:05:50.080 --> 00:05:52.320]   I don't need to, I don't need a special.
[00:05:52.320 --> 00:05:57.760]   Don't do I have, I have just has to walk three feet to get to the computer.
[00:05:57.760 --> 00:06:00.480]   Computer, special computer.
[00:06:00.480 --> 00:06:01.480]   Okay.
[00:06:01.480 --> 00:06:04.320]   Oh, it's hard.
[00:06:04.320 --> 00:06:11.080]   I, now you know you're old when it's a workout to get up and go inside the table.
[00:06:11.080 --> 00:06:13.480]   Well, when you go that way, yes.
[00:06:13.480 --> 00:06:14.640]   Yeah, that is the long way.
[00:06:14.640 --> 00:06:15.640]   All right.
[00:06:15.640 --> 00:06:21.640]   So I'm going to put them in this box and I have to peel stuff off, peel that off.
[00:06:21.640 --> 00:06:22.640]   Oh, I see.
[00:06:22.640 --> 00:06:26.240]   And I say that I love charging things in their boxes.
[00:06:26.240 --> 00:06:31.640]   I love, I mean, as I've got all these like proprietary cable dongle things.
[00:06:31.640 --> 00:06:32.640]   Yeah, it's open.
[00:06:32.640 --> 00:06:34.040]   I see behind you, you've got a charger.
[00:06:34.040 --> 00:06:35.680]   It's a pain in the butt, right?
[00:06:35.680 --> 00:06:36.680]   Yes.
[00:06:36.680 --> 00:06:39.720]   Behind me, there's a charger and a connected blood cuff, blood pressure cuff.
[00:06:39.720 --> 00:06:40.720]   Oh my God.
[00:06:40.720 --> 00:06:41.720]   Are you okay?
[00:06:41.720 --> 00:06:42.720]   Oh, yeah.
[00:06:42.720 --> 00:06:43.720]   Oh, you know what's cool?
[00:06:43.720 --> 00:06:44.720]   Okay.
[00:06:44.720 --> 00:06:45.720]   She just tested these things.
[00:06:45.720 --> 00:06:47.000]   This is good design too.
[00:06:47.000 --> 00:06:50.400]   So the pogo pins, I was wondering, well, where do I plug these in?
[00:06:50.400 --> 00:06:52.040]   Because you don't see any visible.
[00:06:52.040 --> 00:06:56.360]   The pogo pins are hid behind the hinge on the glasses.
[00:06:56.360 --> 00:07:00.880]   So when you have to plug them in, well, you put them in the case, but there's got to be
[00:07:00.880 --> 00:07:02.520]   a way to connect to the case, right?
[00:07:02.520 --> 00:07:06.480]   And so to the charger in the case, and it just goes, it's not the most.
[00:07:06.480 --> 00:07:07.960]   Oh, yeah, you could see.
[00:07:07.960 --> 00:07:13.120]   Oh, oh, you could tell you're doing it right because the little LED array lights up and
[00:07:13.120 --> 00:07:15.640]   actually they're mostly charged.
[00:07:15.640 --> 00:07:16.640]   They're mostly charged.
[00:07:16.640 --> 00:07:24.760]   So I want to let them sit there for a little bit and throb gently while we do the show.
[00:07:24.760 --> 00:07:28.760]   And maybe a little later in the show, I'll, I'll snapchat this.
[00:07:28.760 --> 00:07:30.600]   I think you snap it now, right?
[00:07:30.600 --> 00:07:31.600]   It's now.
[00:07:31.600 --> 00:07:34.600]   Oh, well, I know the company snap.
[00:07:34.600 --> 00:07:35.600]   Do you.
[00:07:35.600 --> 00:07:37.200]   So do you snapchat it?
[00:07:37.200 --> 00:07:38.760]   You're still snapchatting your video.
[00:07:38.760 --> 00:07:41.720]   Is that how the, is that how the kids are saying it now?
[00:07:41.720 --> 00:07:44.720]   I can't imagine your sn, you really, you snapping everything.
[00:07:44.720 --> 00:07:45.720]   No, let's see.
[00:07:45.720 --> 00:07:46.720]   I don't know.
[00:07:46.720 --> 00:07:49.720]   Turn on your phone's Bluetooth and put on your spectacles.
[00:07:49.720 --> 00:07:51.760]   Install the latest version of snapchat.
[00:07:51.760 --> 00:07:52.760]   Snapchat.
[00:07:52.760 --> 00:07:53.760]   See, still go.
[00:07:53.760 --> 00:07:54.760]   The app still snapchat.
[00:07:54.760 --> 00:07:55.760]   Open.
[00:07:55.760 --> 00:07:58.920]   Snapchat and swipe down to view your snap code.
[00:07:58.920 --> 00:08:02.480]   Look at your snap code and press the button on your spectacles to pair.
[00:08:02.480 --> 00:08:03.480]   Oh, wait a minute.
[00:08:03.480 --> 00:08:05.120]   I got to do that.
[00:08:05.120 --> 00:08:06.120]   I mean, I can't.
[00:08:06.120 --> 00:08:07.120]   We got to do it.
[00:08:07.120 --> 00:08:09.800]   You got to, we got to do the full unboxing.
[00:08:09.800 --> 00:08:11.040]   I got to pair it, right?
[00:08:11.040 --> 00:08:14.960]   Yeah, we got to see the world through Leo's eyes.
[00:08:14.960 --> 00:08:16.520]   More so than usual.
[00:08:16.520 --> 00:08:19.720]   Yeah, frankly, that's all you see around here.
[00:08:19.720 --> 00:08:23.080]   It's going to take me a little bit because I have to download the latest.
[00:08:23.080 --> 00:08:27.360]   Oddly enough, I don't have the latest snapchat on my iPhone.
[00:08:27.360 --> 00:08:29.360]   So Stacey.
[00:08:29.360 --> 00:08:30.360]   Hit me.
[00:08:30.360 --> 00:08:33.760]   Eero in my house.
[00:08:33.760 --> 00:08:36.960]   I got the Google Wi-Fi.
[00:08:36.960 --> 00:08:38.440]   Okay.
[00:08:38.440 --> 00:08:40.360]   Had some, had some problems.
[00:08:40.360 --> 00:08:42.600]   Oh, had to call the Goog.
[00:08:42.600 --> 00:08:43.600]   Oh, okay.
[00:08:43.600 --> 00:08:44.680]   It's had to call the Goog.
[00:08:44.680 --> 00:08:47.720]   So I called the Goog.
[00:08:47.720 --> 00:08:48.720]   They said reset it.
[00:08:48.720 --> 00:08:49.880]   I said, well, how do you reset it?
[00:08:49.880 --> 00:08:53.720]   Well, they don't document this, but there is a button on the thing.
[00:08:53.720 --> 00:08:55.800]   If you plug it in with the button, push that resets it.
[00:08:55.800 --> 00:08:57.200]   So I did reset it.
[00:08:57.200 --> 00:08:59.760]   One of the three units was wonky.
[00:08:59.760 --> 00:09:05.480]   When you reset it, it redownloads the firmware, paired everything's fine.
[00:09:05.480 --> 00:09:06.480]   Some thoughts though.
[00:09:06.480 --> 00:09:07.480]   Okay.
[00:09:07.480 --> 00:09:08.480]   You can't run it in bridge mode.
[00:09:08.480 --> 00:09:13.240]   Now I have, unfortunately, and many, I think at home, will have a situation like this.
[00:09:13.240 --> 00:09:19.200]   I have a router from a cable modem router from my Comcast, my internet service provider
[00:09:19.200 --> 00:09:22.840]   that does DHCP to the networking, the routing.
[00:09:22.840 --> 00:09:25.200]   And in my case, because I have a business class service, I can't turn it off.
[00:09:25.200 --> 00:09:28.200]   I have to pay 18 bucks extra a month to turn it off.
[00:09:28.200 --> 00:09:34.880]   So the Google thing says, well, I see you're double-natted.
[00:09:34.880 --> 00:09:38.760]   You should turn, your best thing to do would be to turn off bridging, turn off for routing
[00:09:38.760 --> 00:09:41.720]   in your router and let us do the job.
[00:09:41.720 --> 00:09:45.000]   But if you can't, we can go in bridge mode, but we should warn you, none of the cool stuff
[00:09:45.000 --> 00:09:46.000]   will work.
[00:09:46.000 --> 00:09:47.000]   None.
[00:09:47.000 --> 00:09:48.000]   Oh.
[00:09:48.000 --> 00:09:51.360]   And somebody told me the hero is really in the same situation.
[00:09:51.360 --> 00:09:55.280]   If they're not fully controlling the routing, obviously, and that makes sense.
[00:09:55.280 --> 00:09:58.960]   There's some of the cool stuff they can't do, like choosing which point you're on and
[00:09:58.960 --> 00:09:59.960]   things.
[00:09:59.960 --> 00:10:00.960]   But, hero doesn't tell you that.
[00:10:00.960 --> 00:10:01.960]   Google tells you that.
[00:10:01.960 --> 00:10:05.240]   So, hero has it in their advanced settings, I think.
[00:10:05.240 --> 00:10:07.280]   So if you go into bridge mode, you get warned.
[00:10:07.280 --> 00:10:09.080]   Because I got a big thing.
[00:10:09.080 --> 00:10:10.440]   So I've never gone into bridge mode.
[00:10:10.440 --> 00:10:11.440]   What about ubiquity?
[00:10:11.440 --> 00:10:14.360]   Because they have their routers that are actually enterprise class.
[00:10:14.360 --> 00:10:15.360]   So guess what?
[00:10:15.360 --> 00:10:16.360]   I just ordered the amplify.
[00:10:16.360 --> 00:10:17.360]   Okay.
[00:10:17.360 --> 00:10:20.560]   Because I want to try them all now.
[00:10:20.560 --> 00:10:23.360]   So I will, you want my update on Plume while you're waiting?
[00:10:23.360 --> 00:10:24.360]   Yes.
[00:10:24.360 --> 00:10:31.840]   So I let my network marinate for a week because you had to let it live and learn.
[00:10:31.840 --> 00:10:33.160]   Live and learn.
[00:10:33.160 --> 00:10:34.360]   So it has done that.
[00:10:34.360 --> 00:10:35.600]   And when I did the testing.
[00:10:35.600 --> 00:10:41.080]   So you can't really use it or you can use it, but you just don't want to test it.
[00:10:41.080 --> 00:10:43.760]   Oh, so before it marinates.
[00:10:43.760 --> 00:10:44.760]   Yes.
[00:10:44.760 --> 00:10:47.040]   So can you test it?
[00:10:47.040 --> 00:10:50.560]   You can use it and you can test it, but the results are going to be different.
[00:10:50.560 --> 00:10:54.320]   Because what it's doing is it's learning your network settings and how things are used.
[00:10:54.320 --> 00:10:56.400]   And optimizing for it.
[00:10:56.400 --> 00:10:57.400]   Okay.
[00:10:57.400 --> 00:10:58.400]   So technically.
[00:10:58.400 --> 00:11:00.000]   It won't be as fast as it's going to be.
[00:11:00.000 --> 00:11:01.000]   Yes.
[00:11:01.000 --> 00:11:02.840]   A more accurate representation is probably.
[00:11:02.840 --> 00:11:03.840]   So that's good.
[00:11:03.840 --> 00:11:06.040]   You have the patience to do that because I do not.
[00:11:06.040 --> 00:11:07.040]   I okay.
[00:11:07.040 --> 00:11:08.320]   So here's where we get into it.
[00:11:08.320 --> 00:11:11.160]   So what we talked about last time with there only being one port.
[00:11:11.160 --> 00:11:12.160]   Yeah.
[00:11:12.160 --> 00:11:15.640]   So I thought I was like, no, no, it all works because some of my devices were connected,
[00:11:15.640 --> 00:11:17.400]   but that's because I had plugged them in some.
[00:11:17.400 --> 00:11:20.960]   I had plugged them into one of the.
[00:11:20.960 --> 00:11:23.440]   Little pluggy things.
[00:11:23.440 --> 00:11:28.640]   So I actually have now decided in my house, it is impractical.
[00:11:28.640 --> 00:11:33.440]   And for anybody who's running a switch or needs to, you know, has a situation where
[00:11:33.440 --> 00:11:35.760]   they want to plug into a LAN.
[00:11:35.760 --> 00:11:37.240]   This is not the group.
[00:11:37.240 --> 00:11:40.160]   This is not the Wi-Fi for you.
[00:11:40.160 --> 00:11:44.120]   You can run it also in bridge mode, but it's complicated.
[00:11:44.120 --> 00:11:47.160]   And if you're buying this, you're probably trying to get coverage without the stress
[00:11:47.160 --> 00:11:49.160]   of an extender.
[00:11:49.160 --> 00:11:52.880]   So I think it kind of takes away any useful there.
[00:11:52.880 --> 00:11:54.400]   I also noticed.
[00:11:54.400 --> 00:11:59.480]   So for the last week, like I haven't been able to turn my lights or work my printer because
[00:11:59.480 --> 00:12:02.680]   they're on the land and work my Sonos.
[00:12:02.680 --> 00:12:04.280]   So sad, Stacey.
[00:12:04.280 --> 00:12:07.920]   But by the way, I think the arrow has killed my Sonos.
[00:12:07.920 --> 00:12:08.920]   What?
[00:12:08.920 --> 00:12:10.600]   We'll talk about that next.
[00:12:10.600 --> 00:12:11.600]   Okay.
[00:12:11.600 --> 00:12:13.840]   Because someone else complained about that, but they found a solution.
[00:12:13.840 --> 00:12:15.640]   Oh, good.
[00:12:15.640 --> 00:12:25.960]   So but the plume Wi-Fi was consistent everywhere, but it was about 60% less than the earos Wi-Fi.
[00:12:25.960 --> 00:12:26.960]   Yeah.
[00:12:26.960 --> 00:12:31.880]   So I was kind of like, I mean, it was still 80 megabits per second to the plumes 140 megabits
[00:12:31.880 --> 00:12:35.960]   per second, because I'm on 150 megabit per second connection.
[00:12:35.960 --> 00:12:37.440]   So I was kind of like, yeah.
[00:12:37.440 --> 00:12:38.440]   You got it right backward.
[00:12:38.440 --> 00:12:40.240]   The earro was 140.
[00:12:40.240 --> 00:12:41.240]   The plume was 80.
[00:12:41.240 --> 00:12:42.240]   Yes, sorry.
[00:12:42.240 --> 00:12:44.440]   Yes, I did get it backwards.
[00:12:44.440 --> 00:12:46.480]   No, but you don't want to see that.
[00:12:46.480 --> 00:12:47.480]   See, that's not mesh.
[00:12:47.480 --> 00:12:50.720]   The promise of mesh is that that's not going to happen.
[00:12:50.720 --> 00:12:52.600]   Because if you do as an extender, that's what happens.
[00:12:52.600 --> 00:12:57.680]   You cut in half your total bandwidth so that they can have a back channel.
[00:12:57.680 --> 00:13:02.160]   And the whole theory behind these apparently loom is really more like an extender system
[00:13:02.160 --> 00:13:07.000]   than it is loom plume.
[00:13:07.000 --> 00:13:10.720]   Plume is more an extender system than it is a mesh system.
[00:13:10.720 --> 00:13:13.480]   And that would kind of explain why you put one in every room.
[00:13:13.480 --> 00:13:14.400]   Yeah.
[00:13:14.400 --> 00:13:15.400]   It's too high.
[00:13:15.400 --> 00:13:16.400]   So I see.
[00:13:16.400 --> 00:13:17.400]   Okay, that's it.
[00:13:17.400 --> 00:13:18.400]   Okay, right.
[00:13:18.400 --> 00:13:19.400]   Yeah.
[00:13:19.400 --> 00:13:20.800]   So I want to try the Orbeez.
[00:13:20.800 --> 00:13:21.800]   That's another one.
[00:13:21.800 --> 00:13:25.240]   Although I'm nervous about Netgear because the word just went out that Netgear has a
[00:13:25.240 --> 00:13:26.240]   massive exploit.
[00:13:26.240 --> 00:13:27.240]   Oh, yeah.
[00:13:27.240 --> 00:13:28.240]   It's firmware.
[00:13:28.240 --> 00:13:29.240]   So I was getting the Orbeez.
[00:13:29.240 --> 00:13:33.280]   Well, yeah, you might want to update before you use it.
[00:13:33.280 --> 00:13:34.840]   So those are the old ones.
[00:13:34.840 --> 00:13:35.840]   Those are the R7000s.
[00:13:35.840 --> 00:13:36.840]   The new ones are fine.
[00:13:36.840 --> 00:13:37.840]   Okay.
[00:13:37.840 --> 00:13:39.880]   But they are.
[00:13:39.880 --> 00:13:42.080]   So yeah, the Orbeez are actually en route to my house.
[00:13:42.080 --> 00:13:43.080]   I believe.
[00:13:43.080 --> 00:13:44.080]   Well, see, I want you.
[00:13:44.080 --> 00:13:47.360]   There's very few people are going to be able to test all of them.
[00:13:47.360 --> 00:13:50.160]   And so we really want to kind of get a sense of what they can all do.
[00:13:50.160 --> 00:13:53.000]   I've decided now you're using the amplifier, right?
[00:13:53.000 --> 00:13:54.960]   No, I'm you didn't get the amplifier.
[00:13:54.960 --> 00:13:55.960]   Okay.
[00:13:55.960 --> 00:13:56.960]   That's the equity.
[00:13:56.960 --> 00:14:01.160]   I ordered the amplifier and I decided to order the there's two these the long range and
[00:14:01.160 --> 00:14:10.160]   the high density high density is the higher and more expensive, more radios, more antennas,
[00:14:10.160 --> 00:14:13.040]   more juice and so theoretically faster.
[00:14:13.040 --> 00:14:15.160]   So I got the, you know, it's not that much more expensive.
[00:14:15.160 --> 00:14:17.120]   I got the HD just to see.
[00:14:17.120 --> 00:14:18.880]   So I'll have more tests.
[00:14:18.880 --> 00:14:20.840]   But right now I'm sticking with the era of the heroes.
[00:14:20.840 --> 00:14:23.480]   The one and partly because I have five units now.
[00:14:23.480 --> 00:14:25.160]   I ended up getting more.
[00:14:25.160 --> 00:14:27.000]   So saturated.
[00:14:27.000 --> 00:14:28.600]   So I've excellent everywhere.
[00:14:28.600 --> 00:14:30.440]   Five bars everywhere.
[00:14:30.440 --> 00:14:33.920]   But all of a sudden the sonos just stops working.
[00:14:33.920 --> 00:14:34.920]   Did you reset it?
[00:14:34.920 --> 00:14:36.720]   Because sometimes you have to reset it.
[00:14:36.720 --> 00:14:38.200]   Two hours.
[00:14:38.200 --> 00:14:44.800]   I got up at 6 a.m. this morning and was cursing and swearing through every room in the house,
[00:14:44.800 --> 00:14:46.040]   resetting everything.
[00:14:46.040 --> 00:14:48.640]   I ended up resetting the whole Eero system.
[00:14:48.640 --> 00:14:51.640]   I ended up resetting the whole Sonos system.
[00:14:51.640 --> 00:14:52.640]   Okay.
[00:14:52.640 --> 00:14:55.360]   And the Sonos comes and goes and I here's my theory.
[00:14:55.360 --> 00:14:58.800]   I have so saturated the spectrum with the Eero.
[00:14:58.800 --> 00:14:59.800]   Right.
[00:14:59.800 --> 00:15:01.560]   It's own little Wi-Fi network.
[00:15:01.560 --> 00:15:02.560]   Yeah.
[00:15:02.560 --> 00:15:03.560]   Yeah.
[00:15:03.560 --> 00:15:05.720]   The 2.4 gigahertz spectrum.
[00:15:05.720 --> 00:15:11.520]   The Eero uses both 2.4 or 5 but it's on 2.4 and I have so saturated it because I mean think
[00:15:11.520 --> 00:15:12.520]   about it.
[00:15:12.520 --> 00:15:16.160]   I've got hundreds of lots of Wi-Fi in the pulsing through the house.
[00:15:16.160 --> 00:15:21.160]   I get frying egg that the Sonos just goes, "Hi, can I give up?"
[00:15:21.160 --> 00:15:22.440]   And I have a boost in everything.
[00:15:22.440 --> 00:15:25.280]   I have the nothing.
[00:15:25.280 --> 00:15:26.280]   So I don't know.
[00:15:26.280 --> 00:15:27.280]   I'm going to call.
[00:15:27.280 --> 00:15:28.640]   I didn't have time this morning to call Sonos.
[00:15:28.640 --> 00:15:31.120]   I'll be calling Sonos and I'll have an update for you.
[00:15:31.120 --> 00:15:32.280]   Are you ready for me to pair?
[00:15:32.280 --> 00:15:34.560]   Did you just kind of confuse the hell out of the Sonos?
[00:15:34.560 --> 00:15:36.560]   I just haven't already done Wi-Fi.
[00:15:36.560 --> 00:15:40.400]   I think I, what it is, is saturated the spectrum and the Sonos can't get through it.
[00:15:40.400 --> 00:15:42.400]   And it's just, it's, but it's frustrating.
[00:15:42.400 --> 00:15:44.840]   It means your neighbors hate you too.
[00:15:44.840 --> 00:15:46.640]   Well, we live in the country.
[00:15:46.640 --> 00:15:49.400]   So they're going to love you as well.
[00:15:49.400 --> 00:15:52.000]   Relatively, but that's actually something to consider.
[00:15:52.000 --> 00:15:56.640]   A lot of these Wi-Fi solutions that are supposedly improve your Wi-Fi like multiple radios and
[00:15:56.640 --> 00:15:58.800]   super are actually terrible.
[00:15:58.800 --> 00:16:01.520]   They suck all the bandwidth out of your neighbors.
[00:16:01.520 --> 00:16:03.200]   They're really terrible for your neighbors.
[00:16:03.200 --> 00:16:04.200]   All right.
[00:16:04.200 --> 00:16:05.200]   Now, what did it say?
[00:16:05.200 --> 00:16:06.200]   It said take a picture.
[00:16:06.200 --> 00:16:07.200]   Where's the button on this?
[00:16:07.200 --> 00:16:08.200]   Here it is.
[00:16:08.200 --> 00:16:09.200]   There's the button.
[00:16:09.200 --> 00:16:13.600]   So I, I press this button and I'm supposed to see a QR code, right?
[00:16:13.600 --> 00:16:14.600]   What happened?
[00:16:14.600 --> 00:16:16.800]   I got to read this again.
[00:16:16.800 --> 00:16:18.280]   It's all the ways for the Snapchat.
[00:16:18.280 --> 00:16:20.200]   Oh, swipe down to view your Snapcode.
[00:16:20.200 --> 00:16:22.040]   Oh, I wasn't viewing my Snapcode.
[00:16:22.040 --> 00:16:23.040]   Okay.
[00:16:23.040 --> 00:16:25.200]   Look at your Snapcode and press the button on the spectacles.
[00:16:25.200 --> 00:16:26.200]   Okay.
[00:16:26.200 --> 00:16:27.200]   There's my Snapcode.
[00:16:27.200 --> 00:16:29.280]   If anybody wants it, you can show my Snapcode.
[00:16:29.280 --> 00:16:31.680]   Oh, Snapchat would like access.
[00:16:31.680 --> 00:16:32.680]   Yes.
[00:16:32.680 --> 00:16:35.160]   Keep looking directly at the Snapcode.
[00:16:35.160 --> 00:16:36.160]   I'm looking.
[00:16:36.160 --> 00:16:37.160]   I'm not.
[00:16:37.160 --> 00:16:39.400]   Spectacles found.
[00:16:39.400 --> 00:16:43.240]   This has to be easy because this is aimed at, you know, name your spectacles.
[00:16:43.240 --> 00:16:45.720]   What should I name them?
[00:16:45.720 --> 00:16:46.720]   Banana.
[00:16:46.720 --> 00:16:49.600]   I was going to say blues brothers come up a lot.
[00:16:49.600 --> 00:16:50.600]   Oh, yeah.
[00:16:50.600 --> 00:16:51.600]   Yeah.
[00:16:51.600 --> 00:16:52.600]   Yeah.
[00:16:52.600 --> 00:16:53.600]   It's dark.
[00:16:53.600 --> 00:16:54.600]   We're wearing sunglasses.
[00:16:54.600 --> 00:16:55.720]   We got a full tank of gas.
[00:16:55.720 --> 00:16:58.200]   I'm going to call it hit it.
[00:16:58.200 --> 00:17:01.960]   Isn't that what they say at the end of that quote?
[00:17:01.960 --> 00:17:02.960]   Hit it.
[00:17:02.960 --> 00:17:07.360]   And then only I will know what I'm talking about, but it's a little blues brothers reference.
[00:17:07.360 --> 00:17:12.480]   These are the hit it spectacles connecting the spectacles.
[00:17:12.480 --> 00:17:13.480]   So exciting.
[00:17:13.480 --> 00:17:15.840]   I can now select an accessory.
[00:17:15.840 --> 00:17:18.440]   Oh, hit it.
[00:17:18.440 --> 00:17:20.160]   See, hit it.
[00:17:20.160 --> 00:17:21.160]   Boom.
[00:17:21.160 --> 00:17:25.080]   It's a little emoji with sunglasses on.
[00:17:25.080 --> 00:17:26.080]   Setting up spectacles.
[00:17:26.080 --> 00:17:27.080]   All right.
[00:17:27.080 --> 00:17:28.600]   So it's fairly easy.
[00:17:28.600 --> 00:17:32.760]   You know, this is, this is what the Eros and the Orbeez and everything.
[00:17:32.760 --> 00:17:36.320]   These are all like the same kind of thing where you impaired.
[00:17:36.320 --> 00:17:37.320]   Okay.
[00:17:37.320 --> 00:17:40.520]   Press once to take a 10 second video snap.
[00:17:40.520 --> 00:17:43.800]   Press again to extend by 10 seconds or press and hold to stop recording.
[00:17:43.800 --> 00:17:48.080]   So I've been reading, there's articles on how to get good snaps.
[00:17:48.080 --> 00:17:53.120]   And one of the things it says is if you triple tap, you get 30 seconds, double tap the side
[00:17:53.120 --> 00:17:55.160]   to check your battery level.
[00:17:55.160 --> 00:17:56.480]   Okay.
[00:17:56.480 --> 00:18:00.040]   If you're running low, put the spectacles in their charging case.
[00:18:00.040 --> 00:18:01.320]   Specs light up when they're charging.
[00:18:01.320 --> 00:18:04.560]   Yeah, I noticed that charging case holds about four full charges.
[00:18:04.560 --> 00:18:05.560]   Oh, that's neat.
[00:18:05.560 --> 00:18:06.560]   So I'm charging the case.
[00:18:06.560 --> 00:18:08.040]   Oh, that's cool.
[00:18:08.040 --> 00:18:09.040]   All right.
[00:18:09.040 --> 00:18:10.040]   All right.
[00:18:10.040 --> 00:18:13.400]   And then I, oh, apparently I have a story already.
[00:18:13.400 --> 00:18:15.200]   All right.
[00:18:15.200 --> 00:18:17.160]   All right.
[00:18:17.160 --> 00:18:18.160]   Get HD.
[00:18:18.160 --> 00:18:20.720]   What does that mean?
[00:18:20.720 --> 00:18:22.800]   By default stories are imported in SD.
[00:18:22.800 --> 00:18:24.360]   You can import your favorite stories in HD.
[00:18:24.360 --> 00:18:25.360]   I got it.
[00:18:25.360 --> 00:18:26.360]   Okay.
[00:18:26.360 --> 00:18:27.360]   All right.
[00:18:27.360 --> 00:18:28.360]   No, no.
[00:18:28.360 --> 00:18:29.360]   All right.
[00:18:29.360 --> 00:18:30.360]   So should I do a story?
[00:18:30.360 --> 00:18:31.360]   Probably.
[00:18:31.360 --> 00:18:32.360]   All right.
[00:18:32.360 --> 00:18:33.360]   All right.
[00:18:33.360 --> 00:18:34.360]   All right.
[00:18:34.360 --> 00:18:35.360]   Look at me now.
[00:18:35.360 --> 00:18:36.360]   Look at me.
[00:18:36.360 --> 00:18:37.360]   All right.
[00:18:37.360 --> 00:18:38.360]   Ready?
[00:18:38.360 --> 00:18:39.360]   MTF it twice for 20 seconds.
[00:18:39.360 --> 00:18:42.360]   This is what happened when Leo got his brand new Snapchat spectacles.
[00:18:42.360 --> 00:18:45.320]   Everybody was so jealous.
[00:18:45.320 --> 00:18:48.320]   They just turned bright green.
[00:18:48.320 --> 00:18:49.720]   Hello everybody.
[00:18:49.720 --> 00:18:51.880]   I'm is it snapping?
[00:18:51.880 --> 00:18:52.880]   Snapchatting?
[00:18:52.880 --> 00:18:53.880]   Snap chatting?
[00:18:53.880 --> 00:18:54.880]   I don't know.
[00:18:54.880 --> 00:18:55.880]   Snapping sounds snappier.
[00:18:55.880 --> 00:18:59.560]   I'm with the kids, man.
[00:18:59.560 --> 00:19:00.920]   Does the light go around in it?
[00:19:00.920 --> 00:19:02.760]   Yeah, that's to let you know that it's going.
[00:19:02.760 --> 00:19:03.760]   That's what it looks like.
[00:19:03.760 --> 00:19:05.200]   Can you see that it's recording?
[00:19:05.200 --> 00:19:06.200]   Yeah.
[00:19:06.200 --> 00:19:08.000]   That's a lot of this, like, from your perspective.
[00:19:08.000 --> 00:19:09.000]   Yeah.
[00:19:09.000 --> 00:19:10.960]   Oh, no, you can't see anything.
[00:19:10.960 --> 00:19:11.960]   Okay.
[00:19:11.960 --> 00:19:12.960]   And now it's a...
[00:19:12.960 --> 00:19:19.240]   So the, the, the thing I read said a couple of things, put your hands in the Snapchat a
[00:19:19.240 --> 00:19:20.240]   lot.
[00:19:20.240 --> 00:19:21.840]   Otherwise, it just looks like a video.
[00:19:21.840 --> 00:19:28.080]   But this way now, you know, it's first person if you do that.
[00:19:28.080 --> 00:19:31.440]   They also said, have a beginning, a middle and an end.
[00:19:31.440 --> 00:19:34.000]   They also said, what else did she say?
[00:19:34.000 --> 00:19:38.080]   Anyway, stuff like that.
[00:19:38.080 --> 00:19:41.680]   I kind of like the idea of just being like, surreptitious videos that you've snapped or
[00:19:41.680 --> 00:19:42.680]   are you thinking?
[00:19:42.680 --> 00:19:43.680]   Yeah, that's surreptitious.
[00:19:43.680 --> 00:19:44.680]   But yeah.
[00:19:44.680 --> 00:19:45.680]   Well, yeah.
[00:19:45.680 --> 00:19:48.000]   I'm, we're, I'm always going to stay away from the guy with the Gooby classes.
[00:19:48.000 --> 00:19:51.880]   Right after the show, I'm going to Vegas.
[00:19:51.880 --> 00:19:54.160]   Okay.
[00:19:54.160 --> 00:19:56.240]   You're going to use it to count cards?
[00:19:56.240 --> 00:19:58.080]   Send it to your, your hedge fund dude in the back.
[00:19:58.080 --> 00:19:59.080]   I bet they don't let you.
[00:19:59.080 --> 00:20:02.480]   What do you think if I go in the casino with this and start, try to play black check?
[00:20:02.480 --> 00:20:03.480]   They're not going to like that.
[00:20:03.480 --> 00:20:04.480]   Yeah.
[00:20:04.480 --> 00:20:05.480]   I think he should read whatever happens.
[00:20:05.480 --> 00:20:08.600]   Were there any stories of, of Google classic casinos?
[00:20:08.600 --> 00:20:11.000]   Oh, probably not.
[00:20:11.000 --> 00:20:12.000]   Probably you don't get through the door.
[00:20:12.000 --> 00:20:13.200]   I will try.
[00:20:13.200 --> 00:20:19.200]   I do, I do have experience with this because one CES, we were going to an event through
[00:20:19.200 --> 00:20:21.600]   a casino with a camera crew.
[00:20:21.600 --> 00:20:23.360]   And I said, get everything.
[00:20:23.360 --> 00:20:26.720]   And we immediately got stopped and said, you have to turn your camera off.
[00:20:26.720 --> 00:20:30.800]   And my camera guy who bless his soul, fought him.
[00:20:30.800 --> 00:20:33.760]   And I said, not physically, but he was, no, I'm not, I'm not, I'm pressed.
[00:20:33.760 --> 00:20:34.760]   I got it.
[00:20:34.760 --> 00:20:37.240]   So I said, no, no, sorry, don't just pretend you're turning it off.
[00:20:37.240 --> 00:20:39.040]   We actually, I think we're streaming live.
[00:20:39.040 --> 00:20:45.040]   Just, yes, in June, 2013, the New Jersey Division of Gaming Enforcement issued a directive for
[00:20:45.040 --> 00:20:47.960]   Atlantic City to ban casino patrons.
[00:20:47.960 --> 00:20:51.000]   They don't want any video, any camera in the casino.
[00:20:51.000 --> 00:20:52.000]   Huh.
[00:20:52.000 --> 00:20:55.400]   Is it because of things like tracking and tracking?
[00:20:55.400 --> 00:20:59.240]   No, I think, well, possibly, but also they just don't want anybody.
[00:20:59.240 --> 00:21:03.480]   It's the same reason the TSA doesn't want you to take pictures at TSA.
[00:21:03.480 --> 00:21:05.480]   Well, that's, that's silly.
[00:21:05.480 --> 00:21:08.200]   Actually, so you're, you're catching people in affairs.
[00:21:08.200 --> 00:21:09.880]   Oh, that's true too.
[00:21:09.880 --> 00:21:12.240]   What happens in Vegas?
[00:21:12.240 --> 00:21:13.240]   Should stay at the same time.
[00:21:13.240 --> 00:21:15.000]   Shows up on Snapchat.
[00:21:15.000 --> 00:21:17.240]   Well, everybody should follow me.
[00:21:17.240 --> 00:21:19.000]   I, I just showed you my thing.
[00:21:19.000 --> 00:21:22.560]   I don't remember what it was, but I'm that guy on Snapchat.
[00:21:22.560 --> 00:21:23.560]   Your handle?
[00:21:23.560 --> 00:21:24.560]   Your handle?
[00:21:24.560 --> 00:21:25.560]   I think I'm chief twit.
[00:21:25.560 --> 00:21:26.560]   I don't know.
[00:21:26.560 --> 00:21:27.560]   Can we watch it on Snapchat now?
[00:21:27.560 --> 00:21:30.560]   Um, I don't know what happens next.
[00:21:30.560 --> 00:21:31.560]   It should be beautiful.
[00:21:31.560 --> 00:21:35.560]   Yes, it's on Snapchat.
[00:21:35.560 --> 00:21:38.360]   You may have to approve it actually.
[00:21:38.360 --> 00:21:40.800]   I don't know what happens next.
[00:21:40.800 --> 00:21:48.440]   Could somebody go look and, and see if I'm, I'm chief twit, twit on the, on the snap.
[00:21:48.440 --> 00:21:49.440]   Hold on.
[00:21:49.440 --> 00:21:51.840]   I don't know how this stuff works.
[00:21:51.840 --> 00:21:53.760]   We find a way to do that.
[00:21:53.760 --> 00:21:59.960]   Snapchat is intentionally, by the way, obstoose because they, that's all, all part of the,
[00:21:59.960 --> 00:22:01.520]   all part of the, the mystique.
[00:22:01.520 --> 00:22:02.520]   All right.
[00:22:02.520 --> 00:22:05.120]   I'm looking for you, chief twit.
[00:22:05.120 --> 00:22:07.280]   So good news, breaking news.
[00:22:07.280 --> 00:22:08.760]   Thank you guys smiling in the chat room.
[00:22:08.760 --> 00:22:12.040]   If you give me a link, I'd appreciate it.
[00:22:12.040 --> 00:22:18.840]   Yahoo says hackers stole data from more than one billion user account.
[00:22:18.840 --> 00:22:19.840]   Shh.
[00:22:19.840 --> 00:22:21.760]   How do they have that many?
[00:22:21.760 --> 00:22:22.760]   Who knew?
[00:22:22.760 --> 00:22:23.760]   God.
[00:22:23.760 --> 00:22:24.760]   Is that true?
[00:22:24.760 --> 00:22:27.920]   Or are you making that up?
[00:22:27.920 --> 00:22:29.920]   I don't know.
[00:22:29.920 --> 00:22:33.680]   Ah, we'll find the story.
[00:22:33.680 --> 00:22:37.760]   Moving on that as we speak, the tech summit is going on is, I don't know.
[00:22:37.760 --> 00:22:40.120]   Is that a fair thing to call it the tech summit?
[00:22:40.120 --> 00:22:42.560]   I think that's what they have called it.
[00:22:42.560 --> 00:22:47.800]   President elect Trump is meeting with Tim Cook, Larry Page, Eric Schmidt, Elon Musk.
[00:22:47.800 --> 00:22:51.200]   If you only run down, there's, there's a layout of where they sat.
[00:22:51.200 --> 00:22:53.720]   Oh, you are good.
[00:22:53.720 --> 00:22:54.720]   You are good.
[00:22:54.720 --> 00:22:58.720]   And there's, and there's hilarious picture of the looks of their faces.
[00:22:58.720 --> 00:22:59.720]   Ah, okay.
[00:22:59.720 --> 00:23:00.880]   Look who's at the table.
[00:23:00.880 --> 00:23:01.880]   Is that what?
[00:23:01.880 --> 00:23:02.880]   Is that the one?
[00:23:02.880 --> 00:23:06.560]   So that's the go to the, the view of the third link there.
[00:23:06.560 --> 00:23:07.560]   Who's that where?
[00:23:07.560 --> 00:23:08.560]   Okay.
[00:23:08.560 --> 00:23:09.560]   Is that Cheryl Sandberg?
[00:23:09.560 --> 00:23:10.800]   That's Cheryl Sandberg on the, yeah.
[00:23:10.800 --> 00:23:11.800]   Larry Page.
[00:23:11.800 --> 00:23:13.960]   Click on the image because you'll see the whole thing.
[00:23:13.960 --> 00:23:15.840]   And who, who's this guy on the left?
[00:23:15.840 --> 00:23:16.840]   They look familiar.
[00:23:16.840 --> 00:23:17.840]   Oh, wait a minute.
[00:23:17.840 --> 00:23:18.840]   That's Jeff Bezos.
[00:23:18.840 --> 00:23:19.840]   Oh my God.
[00:23:19.840 --> 00:23:21.720]   Look at, look at their faces.
[00:23:21.720 --> 00:23:23.040]   Look at their faces.
[00:23:23.040 --> 00:23:24.360]   Ah, they are so sad.
[00:23:24.360 --> 00:23:26.240]   I wouldn't project too much into that.
[00:23:26.240 --> 00:23:30.020]   They could, they could just have been told that the only thing available for lunch is
[00:23:30.020 --> 00:23:31.020]   egg salad.
[00:23:31.020 --> 00:23:32.020]   No.
[00:23:32.020 --> 00:23:33.020]   I love egg salad.
[00:23:33.020 --> 00:23:36.360]   I know I do too, but you know, here's some more expressions.
[00:23:36.360 --> 00:23:37.360]   Yeah.
[00:23:37.360 --> 00:23:39.600]   Grim in a room full of people.
[00:23:39.600 --> 00:23:40.600]   Yeah.
[00:23:40.600 --> 00:23:41.600]   Lot only egg salad.
[00:23:41.600 --> 00:23:42.600]   Come on.
[00:23:42.600 --> 00:23:43.600]   Okay.
[00:23:43.600 --> 00:23:44.600]   I thought you were the president.
[00:23:44.600 --> 00:23:46.440]   This is, this is another one that maybe is more telling.
[00:23:46.440 --> 00:23:47.640]   This is from Reuters.
[00:23:47.640 --> 00:23:51.520]   Um, Trump is speaking, Teal is listening intently.
[00:23:51.520 --> 00:23:55.120]   Tim Cooky is going, I don't know what, what is Tim saying?
[00:23:55.120 --> 00:23:57.960]   Uh, there's another hilarious Tim Cook photo.
[00:23:57.960 --> 00:23:58.960]   Yeah.
[00:23:58.960 --> 00:24:04.860]   And it's for a cats who is the CEO of Oracle, right?
[00:24:04.860 --> 00:24:05.860]   Yeah.
[00:24:05.860 --> 00:24:06.860]   Or COO.
[00:24:06.860 --> 00:24:11.300]   She's the one who said, uh, Mr. President elect, we will be glad to make any database
[00:24:11.300 --> 00:24:12.620]   you need.
[00:24:12.620 --> 00:24:13.620]   It's interesting.
[00:24:13.620 --> 00:24:20.460]   She and Jenny were many of IBM both volunteered to make databases for a, yeah, it's just whatever
[00:24:20.460 --> 00:24:21.460]   he wants to keep track of.
[00:24:21.460 --> 00:24:24.980]   IDM or did that for Hitler?
[00:24:24.980 --> 00:24:25.980]   Exactly.
[00:24:25.980 --> 00:24:27.900]   They've got references.
[00:24:27.900 --> 00:24:32.520]   If you look at the political story on why Jack wasn't invited.
[00:24:32.520 --> 00:24:35.160]   Uh, so oddly, yeah, that would.
[00:24:35.160 --> 00:24:40.520]   Now if you looked, I did see one thing that said, they're all billion dollar plus companies.
[00:24:40.520 --> 00:24:44.360]   So there's a clear line and everybody who's invited was bigger than a big billion dollars.
[00:24:44.360 --> 00:24:46.560]   Oh, there were, there are bigger tech companies that weren't there.
[00:24:46.560 --> 00:24:48.560]   There were a half a dozen of them.
[00:24:48.560 --> 00:24:50.160]   Um, sales force wasn't there.
[00:24:50.160 --> 00:24:51.160]   They're, I thought it was.
[00:24:51.160 --> 00:24:52.160]   That's true.
[00:24:52.160 --> 00:24:55.680]   Benioff, you know, they invited Chesky from, um, Airbnb.
[00:24:55.680 --> 00:24:56.920]   He didn't come.
[00:24:56.920 --> 00:25:02.860]   He couldn't make it Travis Kalanick couldn't make it from, uh, Uber.
[00:25:02.860 --> 00:25:04.500]   That's weird.
[00:25:04.500 --> 00:25:05.500]   That's surprising.
[00:25:05.500 --> 00:25:07.060]   Yeah, it is surprising.
[00:25:07.060 --> 00:25:11.820]   But maybe he legitimately was, there was another story that said that, um, Kalanick and Elon
[00:25:11.820 --> 00:25:15.580]   Musk were having their own meeting and that they were already signed up to be advisors
[00:25:15.580 --> 00:25:16.580]   to Trump.
[00:25:16.580 --> 00:25:17.580]   Okay.
[00:25:17.580 --> 00:25:19.020]   Teal is bringing in everybody, right?
[00:25:19.020 --> 00:25:21.820]   I mean, this is, this is Peter Teal organizing this.
[00:25:21.820 --> 00:25:22.820]   Yep.
[00:25:22.820 --> 00:25:26.340]   But I'm really, I think the pictures at the table are less going to be less telling than
[00:25:26.340 --> 00:25:27.900]   the pictures of them leaving.
[00:25:27.900 --> 00:25:31.960]   And I'm hoping some of them would, we'll, we'll talk about what the conversation was.
[00:25:31.960 --> 00:25:34.100]   It could just be, it could be simple stuff.
[00:25:34.100 --> 00:25:38.980]   I know, you know, one thing that, uh, the president elect is offering them is the inexpensive
[00:25:38.980 --> 00:25:45.120]   repatriation of, uh, their tax money from, you know, for a lower cost.
[00:25:45.120 --> 00:25:48.920]   And I know a lot of them would welcome that for sure.
[00:25:48.920 --> 00:25:50.640]   Here's the funny quote.
[00:25:50.640 --> 00:25:55.660]   You'll hit Trump saying to them, um, you'll call me, you'll call my people.
[00:25:55.660 --> 00:25:56.660]   It doesn't make any difference.
[00:25:56.660 --> 00:25:58.700]   We have no formal chain of command around here.
[00:25:58.700 --> 00:26:00.580]   Yeah, that's a little weird.
[00:26:00.580 --> 00:26:02.140]   That will change when he gets in the White House.
[00:26:02.140 --> 00:26:04.660]   I think that's not the case.
[00:26:04.660 --> 00:26:14.300]   Um, he met with Bill Gates yesterday independently, uh, and, uh, and Kanye.
[00:26:14.300 --> 00:26:15.300]   Yeah.
[00:26:15.300 --> 00:26:17.700]   That's a, that's a day.
[00:26:17.700 --> 00:26:23.020]   That's a, you know, that's a big day when you met with Kanye and Bill Gates in one day.
[00:26:23.020 --> 00:26:25.380]   That's a big day.
[00:26:25.380 --> 00:26:29.340]   So we don't know, but I, you know, there, of course, many of the, uh, people meeting
[00:26:29.340 --> 00:26:38.780]   with him are immigrants, uh, Satya Nadella, uh, Kate's is an immigrant, cats, um, Peter
[00:26:38.780 --> 00:26:40.860]   Teal himself is an immigrant from Germany.
[00:26:40.860 --> 00:26:46.180]   Uh, in fact, much of Silicon Valley was built as we know by immigrants.
[00:26:46.180 --> 00:26:50.140]   So, uh, you know, you know, I don't know if somebody's going to bring the question.
[00:26:50.140 --> 00:26:51.860]   I wonder, is anybody going to challenge him?
[00:26:51.860 --> 00:26:55.360]   Is anybody going to stand up and say, uh, look, you got to help us with immigrants?
[00:26:55.360 --> 00:26:57.000]   This is who builds a Silicon Valley.
[00:26:57.000 --> 00:26:58.840]   We can't be a, we can't be kicking people out.
[00:26:58.840 --> 00:26:59.840]   I don't know.
[00:26:59.840 --> 00:27:02.720]   Or do, or I think if, if I'm them, I sit and listen.
[00:27:02.720 --> 00:27:09.120]   Well, the first level question is, do you go?
[00:27:09.120 --> 00:27:10.640]   Well, obviously you go.
[00:27:10.640 --> 00:27:11.640]   Everybody go went right.
[00:27:11.640 --> 00:27:12.640]   Who did you had?
[00:27:12.640 --> 00:27:13.640]   It's a president.
[00:27:13.640 --> 00:27:14.640]   That's it.
[00:27:14.640 --> 00:27:15.640]   No, that's a question.
[00:27:15.640 --> 00:27:16.640]   It's a question.
[00:27:16.640 --> 00:27:23.080]   Well, you read, of course, Harris, Harris, Fisher's, just brilliant.
[00:27:23.080 --> 00:27:27.520]   I love your article, which he said, you don't go and, and, and Chris Saka, she, she couldn't
[00:27:27.520 --> 00:27:31.000]   get substantive comments from anybody who went or was going at the time.
[00:27:31.000 --> 00:27:35.080]   This was written a couple of days ago, but she did call a investor, Chris Saka, who's
[00:27:35.080 --> 00:27:36.720]   always been outspoken.
[00:27:36.720 --> 00:27:40.440]   And he said, well, what is the quote?
[00:27:40.440 --> 00:27:41.440]   Scroll down a little bit.
[00:27:41.440 --> 00:27:42.440]   It's a really good quote.
[00:27:42.440 --> 00:27:44.400]   Bottom, free bottom.
[00:27:44.400 --> 00:27:45.400]   Yeah.
[00:27:45.400 --> 00:27:50.080]   I'm a little, uh, disadvantage here because I'm trying to, I had this windows PC got rebuilt
[00:27:50.080 --> 00:27:53.040]   last night and it's not fully functional yet.
[00:27:53.040 --> 00:28:01.360]   Um, I can't read it, but he says, funny, in every tech deal I've ever done, the photo
[00:28:01.360 --> 00:28:08.480]   op comes after you signed the papers of Trump publicly commits to embrace science, stops
[00:28:08.480 --> 00:28:13.440]   threatening the censorship of the internet, rejects fake news and denounces hate against
[00:28:13.440 --> 00:28:15.160]   our diverse employees.
[00:28:15.160 --> 00:28:19.680]   Maybe then would it make sense, particularly to visit Trump Tower?
[00:28:19.680 --> 00:28:23.320]   Short of that, they're being used to legitimize a fascist.
[00:28:23.320 --> 00:28:24.320]   Wow.
[00:28:24.320 --> 00:28:31.600]   Leave it to Saka to say the, the, the, the, the, the, here from Felix salmon is the, um, the
[00:28:31.600 --> 00:28:32.600]   layout, I think.
[00:28:32.600 --> 00:28:33.600]   Yes.
[00:28:33.600 --> 00:28:34.600]   That's the one.
[00:28:34.600 --> 00:28:35.600]   That's what he's got.
[00:28:35.600 --> 00:28:36.600]   Click on the image to get the whole image.
[00:28:36.600 --> 00:28:37.600]   Yeah.
[00:28:37.600 --> 00:28:41.000]   Because the, the tweet, uh, cuts it.
[00:28:41.000 --> 00:28:42.760]   I'm really loading very fast.
[00:28:42.760 --> 00:28:47.000]   I also just put up the cook, the, the hilarious cook photo.
[00:28:47.000 --> 00:28:49.000]   The hilarious cook.
[00:28:49.000 --> 00:28:51.840]   Uh, I'm sorry.
[00:28:51.840 --> 00:28:54.080]   I don't know what's going on with this.
[00:28:54.080 --> 00:28:55.360]   You have a gigantic screen.
[00:28:55.360 --> 00:28:56.360]   You can't find it.
[00:28:56.360 --> 00:28:57.360]   Well, we rebuilt it.
[00:28:57.360 --> 00:28:59.400]   It's, uh, why, why would you do that?
[00:28:59.400 --> 00:29:01.240]   Because it was a little slow.
[00:29:01.240 --> 00:29:04.640]   And so a father Robert did brain surgery.
[00:29:04.640 --> 00:29:05.800]   And you know what my mistake is?
[00:29:05.800 --> 00:29:07.640]   I'm using Microsoft's edge browser.
[00:29:07.640 --> 00:29:12.080]   I'm going to stop doing that right now and get chrome.
[00:29:12.080 --> 00:29:13.080]   That's my mistake.
[00:29:13.080 --> 00:29:14.080]   So okay.
[00:29:14.080 --> 00:29:15.080]   Let's parse this.
[00:29:15.080 --> 00:29:22.120]   Here's the, uh, so the kids, Donald Jr. Ivanka Eric are sitting at one end.
[00:29:22.120 --> 00:29:24.040]   With Brad Smith of the New York, who's Brad Smith?
[00:29:24.040 --> 00:29:25.040]   New York Times?
[00:29:25.040 --> 00:29:27.440]   Uh, I assume it's Brad Smith, Microsoft's.
[00:29:27.440 --> 00:29:28.440]   Oh, Microsoft.
[00:29:28.440 --> 00:29:29.440]   Okay.
[00:29:29.440 --> 00:29:30.440]   But I don't know.
[00:29:30.440 --> 00:29:36.800]   Uh, there, you know what, uh, yeah, uh, Brian, uh, Krasnich, that's the CEO of Intel,
[00:29:36.800 --> 00:29:43.720]   and is to a DJ Jr's, uh, right, uh, Alex Carp of Tumblr, Eric Schmidt, Google, Steve
[00:29:43.720 --> 00:29:50.520]   Bannon, uh, who is, uh, advisor to the president, formerly of Breitbart, Rites Priebus, former
[00:29:50.520 --> 00:29:55.200]   RNC, now, she's the chief of staff, Jared Kushner, the son in law, owner of the New
[00:29:55.200 --> 00:30:02.640]   York Observer, who is also now a high level advisor, Chuck Robbins, CEO of Cisco, Cisco,
[00:30:02.640 --> 00:30:06.080]   Gina Remedy of IBM, Sachin Adelev, Microsoft,
[00:30:06.080 --> 00:30:07.080]   Stephen Miller.
[00:30:07.080 --> 00:30:09.740]   Who's that, don't know?
[00:30:09.740 --> 00:30:10.780]   Wilbur Ross and Gary Cohn.
[00:30:10.780 --> 00:30:11.600]   I don't know that end.
[00:30:11.600 --> 00:30:13.540]   Those are two appointees.
[00:30:13.540 --> 00:30:17.120]   Ah, oh, Gary Wilbur Ross's commerce, Gary Cohn.
[00:30:17.120 --> 00:30:18.160]   Okay, he's from--
[00:30:18.160 --> 00:30:19.960]   Carbonate the swan.
[00:30:19.960 --> 00:30:25.300]   He's from Goldman and he's an economic advisor, I think.
[00:30:25.300 --> 00:30:26.300]   Oh, Eli was there.
[00:30:26.300 --> 00:30:28.380]   Yeah, Eli went after all.
[00:30:28.380 --> 00:30:29.380]   Although--
[00:30:29.380 --> 00:30:30.400]   The code.
[00:30:30.400 --> 00:30:34.240]   Safra cats of Oracle, Tim Cook of Apple.
[00:30:34.240 --> 00:30:37.160]   Now take a moment and show the Tim Cook photo.
[00:30:37.160 --> 00:30:40.000]   And then it's teal, trump, and pence.
[00:30:40.000 --> 00:30:42.480]   So that's the center of the table there.
[00:30:42.480 --> 00:30:44.800]   Then to the-- to Pence's right, Sheryl Sandberg,
[00:30:44.800 --> 00:30:48.800]   COO of Facebook, not Mark Zuckerberg, Larry Page,
[00:30:48.800 --> 00:30:49.520]   and Jeff Bezos.
[00:30:49.520 --> 00:30:51.320]   Jeff Bezos ended up going as well.
[00:30:51.320 --> 00:30:53.320]   So some of the people we thought wouldn't go, did go.
[00:30:53.320 --> 00:30:57.840]   So show the picture of Cook if you would.
[00:30:57.840 --> 00:30:59.040]   Yeah, I'm going to have to let it--
[00:30:59.040 --> 00:31:02.280]   I'm going to download Chrome on doing that.
[00:31:02.280 --> 00:31:03.360]   Oh, look at that face.
[00:31:03.360 --> 00:31:04.360]   Oh, Tim.
[00:31:04.360 --> 00:31:06.200]   Oh, Tim, click on it.
[00:31:06.200 --> 00:31:10.320]   Carsten, you'll get it full screen then.
[00:31:10.320 --> 00:31:14.280]   And then the story above all that.
[00:31:14.280 --> 00:31:17.280]   You know, is that maybe the way to do that is to go,
[00:31:17.280 --> 00:31:20.960]   show respect for the office, go, listen,
[00:31:20.960 --> 00:31:24.040]   but don't look too happy while you're there.
[00:31:24.040 --> 00:31:25.440]   I mean, that's the--
[00:31:25.440 --> 00:31:28.520]   that's the diplomatic way to do that.
[00:31:28.520 --> 00:31:29.880]   Well, I think there is--
[00:31:29.880 --> 00:31:31.040]   I think Saka has a point.
[00:31:31.040 --> 00:31:33.280]   There is-- there is a--
[00:31:33.280 --> 00:31:36.440]   if you read Cara's piece, and maybe you
[00:31:36.440 --> 00:31:39.880]   want to read it, Leo, without the certain word in it,
[00:31:39.880 --> 00:31:43.000]   but what she's saying is, oh, hell, we're going to get used.
[00:31:43.000 --> 00:31:44.800]   We're going to be part of his reality show.
[00:31:44.800 --> 00:31:46.920]   Well, that's the big-- that's the big story.
[00:31:46.920 --> 00:31:51.320]   I think that was the kind of the chief theme of this is.
[00:31:51.320 --> 00:31:52.840]   It's a reality show.
[00:31:52.840 --> 00:31:55.520]   And you get invited up and into the tower.
[00:31:55.520 --> 00:31:58.640]   But honestly, this is the kind of conversations
[00:31:58.640 --> 00:32:00.560]   that any president-elect would be having.
[00:32:00.560 --> 00:32:04.800]   In fact, shouldn't we be glad that he's asking people to talk?
[00:32:04.800 --> 00:32:05.480]   What do you think?
[00:32:05.480 --> 00:32:08.040]   I was talking about when Elon Musk,
[00:32:08.040 --> 00:32:10.840]   according to the story and Kalanik,
[00:32:10.840 --> 00:32:14.600]   be advisors to him and more official role in Musk,
[00:32:14.600 --> 00:32:18.720]   especially, I bemoaned that on Twitter, no surprise,
[00:32:18.720 --> 00:32:20.040]   where I stand.
[00:32:20.040 --> 00:32:20.920]   People said, wasn't it better?
[00:32:20.920 --> 00:32:25.240]   And I said, well, if you believe that you can change him,
[00:32:25.240 --> 00:32:28.280]   and it was like, what choice do we have?
[00:32:28.280 --> 00:32:31.480]   You've got to try to influence and change his mind.
[00:32:31.480 --> 00:32:32.840]   No, no, no.
[00:32:32.840 --> 00:32:37.560]   You've got to say, I could see Elon--
[00:32:37.560 --> 00:32:39.200]   When Trump went to the White House,
[00:32:39.200 --> 00:32:41.120]   it sounded like Obama had some influence on him.
[00:32:41.120 --> 00:32:47.120]   I could see Elon saying, look, Mr. President-elect,
[00:32:47.120 --> 00:32:51.440]   you've really got to consider your position on energy,
[00:32:51.440 --> 00:32:54.720]   on renewables, even if you don't live in global warming.
[00:32:54.720 --> 00:32:55.720]   So, all right.
[00:32:55.720 --> 00:32:57.680]   And so, Al Gore went up to visit, New York Times
[00:32:57.680 --> 00:32:58.520]   does a story.
[00:32:58.520 --> 00:33:00.640]   And we just give hopes to environmentalists.
[00:33:00.640 --> 00:33:01.960]   Next thing, what does he do?
[00:33:01.960 --> 00:33:05.720]   He points people who believe the climate change
[00:33:05.720 --> 00:33:08.360]   is the hoax to key positions.
[00:33:08.360 --> 00:33:10.520]   So you get used.
[00:33:10.520 --> 00:33:11.800]   And you've got to decide.
[00:33:11.800 --> 00:33:12.560]   Were you used?
[00:33:12.560 --> 00:33:14.480]   I mean, you're not legitimizing that,
[00:33:14.480 --> 00:33:17.760]   just because Gore was there doesn't legitimize that.
[00:33:17.760 --> 00:33:18.600]   It makes sense.
[00:33:18.600 --> 00:33:20.720]   I think everybody understands.
[00:33:20.720 --> 00:33:21.840]   We don't know yet.
[00:33:21.840 --> 00:33:26.360]   I mean, the sad truth is we have no sense of what Trump
[00:33:26.360 --> 00:33:27.560]   is really going to do because he's--
[00:33:27.560 --> 00:33:29.200]   Right, so now you go.
[00:33:29.200 --> 00:33:30.240]   You go.
[00:33:30.240 --> 00:33:36.560]   But I will say, once or if, he starts doing things
[00:33:36.560 --> 00:33:39.880]   that are abhorrent to you, then yes, you would go--
[00:33:39.880 --> 00:33:41.560]   I mean, going would legitimize you.
[00:33:41.560 --> 00:33:43.480]   But until he actually takes--
[00:33:43.480 --> 00:33:45.120]   I don't think it legitimizes you.
[00:33:45.120 --> 00:33:46.480]   I mean, I think it's for instance.
[00:33:46.480 --> 00:33:47.000]   It does.
[00:33:47.000 --> 00:33:48.440]   It will at a certain point in time.
[00:33:48.440 --> 00:33:52.120]   So he's got an oil-- he's got Rick Perry in at the Department
[00:33:52.120 --> 00:33:53.120]   of Energy.
[00:33:53.120 --> 00:33:54.640]   He's got an oil man--
[00:33:54.640 --> 00:33:55.560]   He's just metal it.
[00:33:55.560 --> 00:33:58.680]   Yeah, so in charge of an interior.
[00:33:58.680 --> 00:34:01.120]   So if you're Elon Musk, you go in and say, look,
[00:34:01.120 --> 00:34:02.000]   I don't like this.
[00:34:02.000 --> 00:34:03.200]   You shouldn't do this.
[00:34:03.200 --> 00:34:03.680]   You got it.
[00:34:03.680 --> 00:34:04.840]   But he already did it.
[00:34:04.840 --> 00:34:05.440]   Well, he did it.
[00:34:05.440 --> 00:34:07.120]   But so what do you walk away?
[00:34:07.120 --> 00:34:09.200]   You've got to continue the conversation.
[00:34:09.200 --> 00:34:10.080]   Resist.
[00:34:10.080 --> 00:34:11.960]   Well, you've been able to add this conversation
[00:34:11.960 --> 00:34:13.280]   because I'm going to get bad.
[00:34:13.280 --> 00:34:14.600]   You resist.
[00:34:14.600 --> 00:34:16.320]   I think it's-- I don't think that's appropriate.
[00:34:16.320 --> 00:34:21.080]   I think the right thing to do is, as with anything,
[00:34:21.080 --> 00:34:23.680]   you're glad to be at the table and have the conversation.
[00:34:23.680 --> 00:34:26.720]   It does not legitimize it to be at the table.
[00:34:26.720 --> 00:34:28.680]   It does after a certain point in time.
[00:34:28.680 --> 00:34:29.080]   Exactly.
[00:34:29.080 --> 00:34:30.360]   And the question is exactly the same.
[00:34:30.360 --> 00:34:30.640]   That's right.
[00:34:30.640 --> 00:34:32.040]   We're not at that point.
[00:34:32.040 --> 00:34:34.440]   I don't think we're at that point in time, though, Jeff.
[00:34:34.440 --> 00:34:34.960]   I'm going to say--
[00:34:34.960 --> 00:34:37.080]   I think that's a legitimate view.
[00:34:37.080 --> 00:34:39.360]   I think we are at that point.
[00:34:39.360 --> 00:34:44.440]   I think we are at that point because he's shown him
[00:34:44.440 --> 00:34:45.080]   his character.
[00:34:45.080 --> 00:34:46.160]   And he's appointed these people.
[00:34:46.160 --> 00:34:47.840]   And I think we're already down that road.
[00:34:47.840 --> 00:34:48.920]   That's a disagreement.
[00:34:48.920 --> 00:34:50.160]   And it's a fine disagreement to have.
[00:34:50.160 --> 00:34:53.200]   But I think it's also legitimate to say, I won't go.
[00:34:53.200 --> 00:34:55.240]   That's what we're disagreeing about, Leo.
[00:34:55.240 --> 00:34:58.520]   Would you think, ill, of someone who said, no, I choose not to go?
[00:34:58.520 --> 00:35:03.280]   I would do exactly what Tim Cook did, which is--
[00:35:03.280 --> 00:35:04.920]   he's clearly not happy being there.
[00:35:04.920 --> 00:35:07.120]   And I don't blame him.
[00:35:07.120 --> 00:35:09.600]   Trump said a lot, among other things, that boycott
[00:35:09.600 --> 00:35:11.640]   Apple after the San Bernardino thing.
[00:35:11.640 --> 00:35:13.640]   Apple has to bring all their manufacturing back
[00:35:13.640 --> 00:35:17.160]   to the United States, so we're going to charge him 35% tariff.
[00:35:17.160 --> 00:35:20.120]   Of course, he also said Apple can bring its money back
[00:35:20.120 --> 00:35:23.360]   at a 10% tax rate instead of 35%.
[00:35:23.360 --> 00:35:28.960]   But I think Tim Cook has reason to be uncomfortable
[00:35:28.960 --> 00:35:30.520]   and showed his discomfort.
[00:35:30.520 --> 00:35:34.760]   Yeah, but you want to be at the table and try to influence him.
[00:35:34.760 --> 00:35:38.160]   And so, Stacey, you would go.
[00:35:38.160 --> 00:35:40.080]   I would go at this point in time, yes.
[00:35:40.080 --> 00:35:41.960]   And I would listen and try to figure out--
[00:35:41.960 --> 00:35:43.680]   I would go forever.
[00:35:43.680 --> 00:35:44.880]   I would go every--
[00:35:44.880 --> 00:35:46.880]   No, because what's--
[00:35:46.880 --> 00:35:48.840]   Let's say he does something crazy.
[00:35:48.840 --> 00:35:52.400]   Like, literally, actually does deport Muslims.
[00:35:52.400 --> 00:35:52.920]   Yeah.
[00:35:52.920 --> 00:35:55.800]   At that point in time, when he invites you
[00:35:55.800 --> 00:35:57.720]   to sit down at the table with him,
[00:35:57.720 --> 00:36:00.080]   you're sitting down with somebody who deported--
[00:36:00.080 --> 00:36:01.280]   Yeah, so you make it clear.
[00:36:01.280 --> 00:36:05.400]   I went so I could yell at him, so I could try to influence him.
[00:36:05.400 --> 00:36:07.040]   I don't think it's OK what he did.
[00:36:07.040 --> 00:36:13.640]   I don't think it's de facto a sign of approval
[00:36:13.640 --> 00:36:15.960]   that you have a conversation with somebody you disagree with.
[00:36:15.960 --> 00:36:17.640]   But it is a big statement, though,
[00:36:17.640 --> 00:36:20.080]   to say that none of the tech--
[00:36:20.080 --> 00:36:23.440]   none of the big CEOs of business will meet with this man
[00:36:23.440 --> 00:36:26.520]   after he's done something like that.
[00:36:26.520 --> 00:36:28.640]   It's drawing a moral line.
[00:36:28.640 --> 00:36:31.880]   And you have to do something pretty significant to hit
[00:36:31.880 --> 00:36:32.440]   that point.
[00:36:32.440 --> 00:36:36.720]   But there's just a point in time where you're like, I'm sorry.
[00:36:36.720 --> 00:36:38.400]   And I'm not saying Trump is a serial killer,
[00:36:38.400 --> 00:36:41.080]   but you probably wouldn't sit down with Hannibal Lecter.
[00:36:41.080 --> 00:36:43.080]   Yes, you would.
[00:36:43.080 --> 00:36:43.680]   Yes, you would.
[00:36:43.680 --> 00:36:45.640]   All right, as a journalist, you totally would.
[00:36:45.640 --> 00:36:46.440]   Well, that's the point.
[00:36:46.440 --> 00:36:49.760]   I think at any point you would, you make it clear.
[00:36:49.760 --> 00:36:50.920]   I don't approve of this.
[00:36:50.920 --> 00:36:54.000]   I'm here to try to talk some sense into this guy.
[00:36:54.000 --> 00:36:55.480]   But you talk to him.
[00:36:55.480 --> 00:37:00.000]   And I think it's a huge mistake.
[00:37:00.000 --> 00:37:02.440]   And I think it comes more from a feeling of revulsion
[00:37:02.440 --> 00:37:05.400]   than a feeling of actual political ardor.
[00:37:05.400 --> 00:37:07.880]   It's more like, oh, I don't want to talk to this guy.
[00:37:07.880 --> 00:37:09.720]   I think if you care, you talk to him.
[00:37:09.720 --> 00:37:10.960]   You keep talking to him.
[00:37:10.960 --> 00:37:15.120]   And you try to convince him when you're being used.
[00:37:15.120 --> 00:37:16.200]   But how are you being used?
[00:37:16.200 --> 00:37:17.160]   You're not being used.
[00:37:17.160 --> 00:37:20.640]   You are being used because, at a certain point in time,
[00:37:20.640 --> 00:37:22.880]   sitting down at the table with the leader who
[00:37:22.880 --> 00:37:27.440]   has done something terrible indicates
[00:37:27.440 --> 00:37:29.720]   that you still respect him as a leader,
[00:37:29.720 --> 00:37:31.360]   that you're still going to the table.
[00:37:31.360 --> 00:37:33.880]   Well, you know what we always say is,
[00:37:33.880 --> 00:37:36.640]   if it's a president, we disagree with you respect the office.
[00:37:36.640 --> 00:37:39.600]   It doesn't necessarily mean you respect a man.
[00:37:39.600 --> 00:37:45.120]   But you could argue that someone has disrespected the office,
[00:37:45.120 --> 00:37:48.400]   has tarnished the office so much that you don't agree.
[00:37:48.400 --> 00:37:49.240]   And that hasn't happened yet.
[00:37:49.240 --> 00:37:50.440]   He's not even in the office.
[00:37:50.440 --> 00:37:51.280]   Right, well, that's what I'm saying.
[00:37:51.280 --> 00:37:53.000]   I'm not saying that that is where we are.
[00:37:53.000 --> 00:37:55.560]   I'm just saying that that is totally something
[00:37:55.560 --> 00:37:57.120]   that could happen.
[00:37:57.120 --> 00:37:58.160]   Hopefully it will not.
[00:37:58.160 --> 00:38:03.360]   I think if I'm Tim Cook, even if I'm revolted by the idea,
[00:38:03.360 --> 00:38:04.240]   I go.
[00:38:04.240 --> 00:38:05.680]   And I think he did go for that reason.
[00:38:05.680 --> 00:38:08.040]   And you look at his expression.
[00:38:08.040 --> 00:38:10.600]   It's easy to get a bad expression on somebody's face
[00:38:10.600 --> 00:38:11.800]   if they're animated.
[00:38:11.800 --> 00:38:13.760]   You could freeze frame any one of these shows
[00:38:13.760 --> 00:38:14.880]   and make us look like.
[00:38:14.880 --> 00:38:16.320]   But--
[00:38:16.320 --> 00:38:17.360]   Oh, it has been done.
[00:38:17.360 --> 00:38:17.880]   Yeah.
[00:38:17.880 --> 00:38:19.720]   So I'm not going to assume.
[00:38:19.720 --> 00:38:22.800]   But that's why I'm most interested in what they say
[00:38:22.800 --> 00:38:25.200]   and how they look as they come out.
[00:38:25.200 --> 00:38:27.800]   I'd like to see the video of that.
[00:38:27.800 --> 00:38:30.480]   And you can't-- even with body language, if not with words.
[00:38:30.480 --> 00:38:32.520]   And I would say even with words, you should say,
[00:38:32.520 --> 00:38:33.160]   I don't know.
[00:38:33.160 --> 00:38:34.360]   Look, this is we're not happy.
[00:38:34.360 --> 00:38:34.880]   In a sense--
[00:38:34.880 --> 00:38:35.800]   We want more H1B.
[00:38:35.800 --> 00:38:36.560]   This happens all the time.
[00:38:36.560 --> 00:38:39.400]   We want more H1B visas.
[00:38:39.400 --> 00:38:40.720]   Whatever.
[00:38:40.720 --> 00:38:41.680]   This happens all the time.
[00:38:41.680 --> 00:38:43.720]   But you're also talking to him like he's
[00:38:43.720 --> 00:38:46.920]   an alleged politician or like an adult.
[00:38:46.920 --> 00:38:52.280]   It's kind of like, again, I'm not saying he's reached this point.
[00:38:52.280 --> 00:38:55.280]   But in some people's minds, he has.
[00:38:55.280 --> 00:38:57.360]   Well, I think that's part of the problem.
[00:38:57.360 --> 00:39:01.200]   I think that's as bad as when the Republicans
[00:39:01.200 --> 00:39:05.440]   refused to have anything to do with President Obama and said,
[00:39:05.440 --> 00:39:08.520]   whatever he says, we're just going to stymie it.
[00:39:08.520 --> 00:39:12.800]   That's exactly where we got into problems in this country.
[00:39:12.800 --> 00:39:16.680]   We need to kind of figure out a way to--
[00:39:16.680 --> 00:39:18.840]   now, maybe you'll say, oh, well, you're
[00:39:18.840 --> 00:39:20.880]   assuming that he's influential.
[00:39:20.880 --> 00:39:22.080]   That he could be influenced.
[00:39:22.080 --> 00:39:23.040]   He's influenceable.
[00:39:23.040 --> 00:39:24.040]   Yes.
[00:39:24.040 --> 00:39:24.440]   Right.
[00:39:24.440 --> 00:39:25.560]   Well, I think we have to.
[00:39:25.560 --> 00:39:27.720]   If not, then what is the other--
[00:39:27.720 --> 00:39:28.880]   I mean, then what do you do?
[00:39:28.880 --> 00:39:31.880]   Is it too soon, Leo, to sign for 600 technology people
[00:39:31.880 --> 00:39:33.440]   who have signed a statement saying that they're not
[00:39:33.440 --> 00:39:34.840]   going to build a Muslim?
[00:39:34.840 --> 00:39:36.000]   No, that's appropriate.
[00:39:36.000 --> 00:39:37.920]   That's exactly what you should do.
[00:39:37.920 --> 00:39:41.840]   And you should go in and talk to Mr. Trump and say,
[00:39:41.840 --> 00:39:44.880]   by the way, don't ask us for help in that,
[00:39:44.880 --> 00:39:47.720]   because that is such an Utre idea.
[00:39:47.720 --> 00:39:50.360]   It's so much against the principles of this great country
[00:39:50.360 --> 00:39:53.080]   that we will absolutely refuse to.
[00:39:53.080 --> 00:39:54.640]   OK, so let me ask the question another way.
[00:39:54.640 --> 00:39:58.040]   So you have a spot at that table today.
[00:39:58.040 --> 00:40:01.000]   If you don't use that to say, we will not
[00:40:01.000 --> 00:40:05.360]   build that registry for you, is that an opportunity wasted?
[00:40:05.360 --> 00:40:05.920]   Possibly.
[00:40:05.920 --> 00:40:08.640]   But you can also say it in an open letter to the president.
[00:40:08.640 --> 00:40:10.240]   You can say it in a press conference.
[00:40:10.240 --> 00:40:11.680]   You can say it in a press conference.
[00:40:11.680 --> 00:40:12.880]   Which means you don't have to be there.
[00:40:12.880 --> 00:40:13.440]   You don't have to be there.
[00:40:13.440 --> 00:40:16.360]   But you have to be there if you want to talk to him.
[00:40:16.360 --> 00:40:17.600]   And by the way, it's not just notice.
[00:40:17.600 --> 00:40:18.200]   It's not just him.
[00:40:18.200 --> 00:40:19.600]   There's a whole--
[00:40:19.600 --> 00:40:21.320]   many of his team there.
[00:40:21.320 --> 00:40:25.160]   Well, but also members of the future cabinet,
[00:40:25.160 --> 00:40:28.200]   his vice president, his advisors.
[00:40:28.200 --> 00:40:33.280]   This is a-- I think you would be wrong to turn down
[00:40:33.280 --> 00:40:34.960]   this opportunity.
[00:40:34.960 --> 00:40:36.560]   However you feel.
[00:40:36.560 --> 00:40:37.880]   This is an opportunity to say--
[00:40:37.880 --> 00:40:39.400]   We do have the full range here.
[00:40:39.400 --> 00:40:42.800]   Stacey is in the moderate and sensible middle.
[00:40:42.800 --> 00:40:44.520]   You say you have to go or to keep on going.
[00:40:44.520 --> 00:40:45.320]   I say don't go.
[00:40:45.320 --> 00:40:47.080]   And Stacey says there's a line.
[00:40:47.080 --> 00:40:47.480]   Well--
[00:40:47.480 --> 00:40:49.040]   Right?
[00:40:49.040 --> 00:40:49.800]   Here's my question.
[00:40:49.800 --> 00:40:51.400]   Do you care more about the country
[00:40:51.400 --> 00:40:54.520]   or about your own personal beliefs in ideology?
[00:40:54.520 --> 00:40:56.560]   It's not just about your own personal beliefs
[00:40:56.560 --> 00:40:58.640]   when you're the CEO of a big company like that.
[00:40:58.640 --> 00:41:01.080]   You are representing an industry.
[00:41:01.080 --> 00:41:01.560]   Right.
[00:41:01.560 --> 00:41:05.160]   But you care about the country more than--
[00:41:05.160 --> 00:41:07.240]   It could be that you care about the country
[00:41:07.240 --> 00:41:09.280]   and that's why you don't meet with him.
[00:41:09.280 --> 00:41:10.240]   I mean, that is still a rational--
[00:41:10.240 --> 00:41:11.640]   That's not a path to progress, though.
[00:41:11.640 --> 00:41:12.720]   I mean, what is that?
[00:41:12.720 --> 00:41:13.320]   Where does that go?
[00:41:13.320 --> 00:41:13.720]   Where's that?
[00:41:13.720 --> 00:41:15.640]   Maybe because then people are like, well,
[00:41:15.640 --> 00:41:17.640]   this guy can't get the job done.
[00:41:17.640 --> 00:41:19.280]   Let's bring Mike Pence on for--
[00:41:19.280 --> 00:41:21.080]   This is exactly what the Republicans did to Obama,
[00:41:21.080 --> 00:41:22.080]   by the way.
[00:41:22.080 --> 00:41:24.080]   I'm not--
[00:41:24.080 --> 00:41:25.400]   I'm not-- to disagree with him.
[00:41:25.400 --> 00:41:26.920]   To show that there's a political force--
[00:41:26.920 --> 00:41:27.480]   You write letters.
[00:41:27.480 --> 00:41:28.120]   You write letters.
[00:41:28.120 --> 00:41:28.960]   You let Congress know.
[00:41:28.960 --> 00:41:29.600]   We disagree.
[00:41:29.600 --> 00:41:30.680]   We forcefully disagree.
[00:41:30.680 --> 00:41:31.840]   We think it's the wrong thing to do.
[00:41:31.840 --> 00:41:34.240]   But first you go and you talk to him and you hear him.
[00:41:34.240 --> 00:41:35.120]   I think you have to--
[00:41:35.120 --> 00:41:37.400]   Well, well, OK, so Jeff may be saying this.
[00:41:37.400 --> 00:41:39.000]   But we're not saying that they shouldn't hear him
[00:41:39.000 --> 00:41:39.800]   at this point in time.
[00:41:39.800 --> 00:41:42.400]   And I think actually Mark Benneyoff's strategy is really--
[00:41:42.400 --> 00:41:45.320]   Why is Benneyoff not there?
[00:41:45.320 --> 00:41:47.000]   Did he get invited?
[00:41:47.000 --> 00:41:51.400]   If he did get invited, I could see Benneyoff deciding not to go.
[00:41:51.400 --> 00:41:54.440]   He's enough of a maverick to just--
[00:41:54.440 --> 00:41:55.200]   Firebrand.
[00:41:55.200 --> 00:41:58.000]   Firebrand to do whatever he wants.
[00:41:58.000 --> 00:41:58.640]   I'm surprised.
[00:41:58.640 --> 00:41:59.480]   I'm surprised.
[00:41:59.480 --> 00:42:00.400]   I'm really surprised.
[00:42:00.400 --> 00:42:01.840]   I thought Musk would be that firebrand
[00:42:01.840 --> 00:42:03.120]   who says I go my own way.
[00:42:03.120 --> 00:42:05.760]   I think Elon is a sensible guy who says--
[00:42:05.760 --> 00:42:07.360]   Musk is pretty coldly practical.
[00:42:07.360 --> 00:42:10.080]   I need to influence the direction
[00:42:10.080 --> 00:42:11.720]   that this next administration takes,
[00:42:11.720 --> 00:42:13.560]   and I'm going to do everything I can to influence it.
[00:42:13.560 --> 00:42:15.000]   And there's also the cynical view
[00:42:15.000 --> 00:42:16.800]   is that I influence it for the benefit of my company
[00:42:16.800 --> 00:42:17.720]   and screw the rats.
[00:42:17.720 --> 00:42:20.400]   But I would be in the room where it happens.
[00:42:20.400 --> 00:42:22.880]   If you're not in the room, you dot--
[00:42:22.880 --> 00:42:24.080]   This is not where it happens.
[00:42:24.080 --> 00:42:25.800]   This is where the cameras come.
[00:42:25.800 --> 00:42:27.480]   Yeah, this is not where it influences--
[00:42:27.480 --> 00:42:28.320]   This is like--
[00:42:28.320 --> 00:42:30.240]   No, this is the reality.
[00:42:30.240 --> 00:42:31.520]   I really do believe that.
[00:42:31.520 --> 00:42:35.280]   I believe that Donald Trump does this for--
[00:42:35.280 --> 00:42:40.080]   This is how he presents and shapes coverage and media.
[00:42:40.080 --> 00:42:44.120]   Yeah, I mean, I understand that that's part of the--
[00:42:44.120 --> 00:42:45.720]   the problem people have with this
[00:42:45.720 --> 00:42:49.600]   is they feel like they're pawns in an attempt
[00:42:49.600 --> 00:42:53.480]   to create stories and create news.
[00:42:53.480 --> 00:42:55.080]   But isn't that how Washington--
[00:42:55.080 --> 00:42:56.880]   And we in media, and we in media--
[00:42:56.880 --> 00:42:59.840]   I mean, ABC News last night led with Kanye West--
[00:42:59.840 --> 00:43:00.320]   Yeah.
[00:43:00.320 --> 00:43:01.920]   --visiting Trump versus Tillerson,
[00:43:01.920 --> 00:43:03.520]   the head of Exxon, being a point of interest.
[00:43:03.520 --> 00:43:04.020]   Interesting.
[00:43:04.020 --> 00:43:04.360]   It's state.
[00:43:04.360 --> 00:43:06.040]   That's bad news judgment.
[00:43:06.040 --> 00:43:07.680]   That's bad judgment.
[00:43:07.680 --> 00:43:09.160]   Well, it depends what you're judging for.
[00:43:09.160 --> 00:43:10.000]   It's probably--
[00:43:10.000 --> 00:43:11.160]   Judging for economics.
[00:43:11.160 --> 00:43:12.320]   It's what people want to see.
[00:43:12.320 --> 00:43:13.400]   Squirrel.
[00:43:13.400 --> 00:43:13.800]   I know.
[00:43:13.800 --> 00:43:14.600]   Squirrel.
[00:43:14.600 --> 00:43:15.320]   I know.
[00:43:15.320 --> 00:43:15.840]   You know what?
[00:43:15.840 --> 00:43:17.880]   Trump is a media genius, and it's
[00:43:17.880 --> 00:43:20.520]   going to be the first new media presidency,
[00:43:20.520 --> 00:43:22.000]   and he's a master of it.
[00:43:22.000 --> 00:43:23.880]   And I told you you should have shut Twitter down
[00:43:23.880 --> 00:43:24.960]   before this happened.
[00:43:24.960 --> 00:43:27.000]   So Twitter, talk to me about Jack and--
[00:43:27.000 --> 00:43:27.840]   All right.
[00:43:27.840 --> 00:43:30.040]   I have my Chrome up so I can now actually look at--
[00:43:30.040 --> 00:43:30.540]   Oh, OK.
[00:43:30.540 --> 00:43:31.200]   I see that's from him.
[00:43:31.200 --> 00:43:33.080]   --and open them, and I can actually participate
[00:43:33.080 --> 00:43:35.640]   in this conversation in a reasonable way.
[00:43:35.640 --> 00:43:36.080]   Here's the--
[00:43:36.080 --> 00:43:36.480]   I'm sorry.
[00:43:36.480 --> 00:43:37.240]   I didn't realize, OK.
[00:43:37.240 --> 00:43:38.880]   Here's the Politico story.
[00:43:38.880 --> 00:43:41.800]   Twitter cut out of Trump Tech meeting over what
[00:43:41.800 --> 00:43:45.920]   failed emoji deal Twitter was told it was--
[00:43:45.920 --> 00:43:47.320]   Oh, this can't be true.
[00:43:47.320 --> 00:43:49.640]   Bounced from Wednesday's meeting between tech executives
[00:43:49.640 --> 00:43:53.520]   and President-elect Donald Trump in retribution
[00:43:53.520 --> 00:43:57.480]   for refusing during the campaign
[00:43:57.480 --> 00:44:03.200]   to allow an emoji version of the hashtag Crooked Hillary.
[00:44:03.200 --> 00:44:03.920]   Oh, my gosh.
[00:44:03.920 --> 00:44:06.120]   That can't possibly be true.
[00:44:06.120 --> 00:44:06.560]   Come on.
[00:44:06.560 --> 00:44:09.760]   Think about the tweets of the Boeing tweets.
[00:44:09.760 --> 00:44:10.280]   Think about how many--
[00:44:10.280 --> 00:44:10.640]   No, no.
[00:44:10.640 --> 00:44:13.080]   I can see the retribution thing I buy.
[00:44:13.080 --> 00:44:14.120]   Oh, oh, I see.
[00:44:14.120 --> 00:44:16.280]   Why the retribution?
[00:44:16.280 --> 00:44:20.040]   But really, they tried to get an emoji version of Crooked
[00:44:20.040 --> 00:44:20.400]   Hillary.
[00:44:20.400 --> 00:44:21.760]   They even tried.
[00:44:21.760 --> 00:44:22.240]   Ah.
[00:44:22.240 --> 00:44:25.320]   Do you think they tried that?
[00:44:25.320 --> 00:44:28.240]   This sounds like fake news.
[00:44:28.240 --> 00:44:29.560]   This sounds like a--
[00:44:29.560 --> 00:44:34.840]   this is a plant by somebody who likes to mess with people.
[00:44:34.840 --> 00:44:36.920]   That can't be true.
[00:44:36.920 --> 00:44:37.840]   Maybe it could.
[00:44:37.840 --> 00:44:40.560]   I don't not believe anything anymore.
[00:44:40.560 --> 00:44:41.480]   I don't not believe anything anymore.
[00:44:41.480 --> 00:44:43.440]   There's no-- there's apps in that part of the problem
[00:44:43.440 --> 00:44:44.000]   with fake news.
[00:44:44.000 --> 00:44:45.800]   I don't not believe anything anymore.
[00:44:45.800 --> 00:44:47.480]   I don't know.
[00:44:47.480 --> 00:44:49.760]   It's absolutely conceivable that there
[00:44:49.760 --> 00:44:50.880]   would be some retribution.
[00:44:50.880 --> 00:44:54.120]   We've seen Donald Trump do that many times, many, many,
[00:44:54.120 --> 00:44:55.080]   many times before.
[00:44:55.080 --> 00:45:01.840]   If you ask me, Donald Trump should be
[00:45:01.840 --> 00:45:03.880]   shaking Jack Dorsey's freaking hand.
[00:45:03.880 --> 00:45:04.400]   I don't--
[00:45:04.400 --> 00:45:05.840]   Oh, God, yeah.
[00:45:05.840 --> 00:45:07.280]   God, yeah.
[00:45:07.280 --> 00:45:12.520]   I mean, again, I think idiot Savant or genius,
[00:45:12.520 --> 00:45:17.800]   I don't know which, but somehow he is a master of manipulation.
[00:45:17.800 --> 00:45:19.960]   You know, probably coming from his background,
[00:45:19.960 --> 00:45:22.280]   running, you know, being part of beauty
[00:45:22.280 --> 00:45:27.480]   pageants, the wrestling, world wrestling, and the apprentice.
[00:45:27.480 --> 00:45:30.320]   I think he's probably learned a lot about media.
[00:45:30.320 --> 00:45:31.520]   Although that's all old media.
[00:45:31.520 --> 00:45:33.520]   He's certainly learned a lot about new media.
[00:45:33.520 --> 00:45:36.240]   They were masterful in manipulating--
[00:45:36.240 --> 00:45:39.320]   and continue to be masterful when they put into Twitter.
[00:45:39.320 --> 00:45:41.560]   I'm surprised he hasn't tweeted the media.
[00:45:41.560 --> 00:45:42.800]   Oh, he will.
[00:45:42.800 --> 00:45:43.520]   Oh, yeah.
[00:45:43.520 --> 00:45:47.680]   His tweets really-- those are late night affairs.
[00:45:47.680 --> 00:45:50.120]   They're usually when he's mad at someone.
[00:45:50.120 --> 00:45:51.920]   Yeah.
[00:45:51.920 --> 00:45:57.200]   I'm glad I'm not in his position because I could see myself doing
[00:45:57.200 --> 00:45:57.720]   that.
[00:45:57.720 --> 00:45:59.560]   I've had-- and Jeff, you've had--
[00:45:59.560 --> 00:46:01.760]   Oh, Lord knows how--
[00:46:01.760 --> 00:46:06.400]   We shouldn't really cast stones in our glasshouses
[00:46:06.400 --> 00:46:10.080]   at people who have intemperate tweets, should we?
[00:46:10.080 --> 00:46:11.280]   He's the president-elect.
[00:46:11.280 --> 00:46:13.080]   It's a little different now.
[00:46:13.080 --> 00:46:16.560]   It's the power-- it's using the power.
[00:46:16.560 --> 00:46:17.680]   Well, things like--
[00:46:17.680 --> 00:46:18.480]   One thing--
[00:46:18.480 --> 00:46:21.080]   I'm going to take down Boeing stock,
[00:46:21.080 --> 00:46:22.840]   or I'm going to take down Lockheed Martin stock.
[00:46:22.840 --> 00:46:23.800]   Or this union guy.
[00:46:23.800 --> 00:46:25.320]   Or this union guy.
[00:46:25.320 --> 00:46:26.720]   That's petty.
[00:46:26.720 --> 00:46:27.440]   It's abusive power.
[00:46:27.440 --> 00:46:29.080]   It's abusive.
[00:46:29.080 --> 00:46:31.160]   Maybe he doesn't think of it as abusive a power.
[00:46:31.160 --> 00:46:32.840]   Maybe he just pissed and he says it.
[00:46:32.840 --> 00:46:33.440]   Oh, he does.
[00:46:33.440 --> 00:46:34.440]   OK.
[00:46:34.440 --> 00:46:36.560]   I heard an interview with Meghan Kelly.
[00:46:36.560 --> 00:46:39.520]   And I read her book, but I also heard an interview with her.
[00:46:39.520 --> 00:46:42.520]   When Trump got mad at her, he said,
[00:46:42.520 --> 00:46:45.120]   I'm going to use my beautiful--
[00:46:45.120 --> 00:46:49.160]   words, "beautiful Twitter account."
[00:46:49.160 --> 00:46:51.920]   And my 17 million followers or whatever
[00:46:51.920 --> 00:46:54.200]   the number is to get you.
[00:46:54.200 --> 00:46:57.400]   So he's very well aware of the power of that.
[00:46:57.400 --> 00:46:59.040]   Oh, yeah.
[00:46:59.040 --> 00:47:03.160]   I would also say the intemperate tweeting thing.
[00:47:03.160 --> 00:47:06.600]   And I may be overstepping, but I think that's a--
[00:47:06.600 --> 00:47:08.360]   that might be a you guys thing.
[00:47:08.360 --> 00:47:09.920]   And maybe it's even a guy thing.
[00:47:09.920 --> 00:47:12.640]   Like, I very rarely tweet without thinking.
[00:47:12.640 --> 00:47:15.480]   Because I'm aware that it's going out a lot of places.
[00:47:15.480 --> 00:47:18.480]   So that means things like--
[00:47:18.480 --> 00:47:21.800]   I don't share information on people.
[00:47:21.800 --> 00:47:23.800]   I don't talk about things that really upset me.
[00:47:23.800 --> 00:47:25.760]   I don't always give my full opinion,
[00:47:25.760 --> 00:47:28.600]   because it would be crazy.
[00:47:28.600 --> 00:47:30.800]   I don't have a lot of leeway for bad tweets.
[00:47:30.800 --> 00:47:32.920]   And you're a good person in this wise Stacy.
[00:47:32.920 --> 00:47:34.560]   And we've always known that about you.
[00:47:34.560 --> 00:47:37.080]   And Jeff and I are far from good people.
[00:47:37.080 --> 00:47:39.880]   Well, I'm about the other end of the spectrum.
[00:47:39.880 --> 00:47:41.920]   But this is why that happens.
[00:47:41.920 --> 00:47:43.880]   We talked about this a couple of years ago,
[00:47:43.880 --> 00:47:46.200]   there was a great article, I think, in the Atlantic.
[00:47:46.200 --> 00:47:48.480]   And it's an understandable confusion,
[00:47:48.480 --> 00:47:53.640]   because Twitter feels like, you know, water cooler talk.
[00:47:53.640 --> 00:47:56.920]   It feels very informal, quick, off the cuff.
[00:47:56.920 --> 00:48:00.080]   And a lot of what we write is written in the style of something
[00:48:00.080 --> 00:48:03.000]   that's an off the cuff, off hand remark.
[00:48:03.000 --> 00:48:07.200]   Unfortunately, the nature of Twitter is it lives forever.
[00:48:07.200 --> 00:48:11.360]   And so at the same time as you're in a medium
[00:48:11.360 --> 00:48:14.760]   that is really looks like and feels like and emotionally
[00:48:14.760 --> 00:48:19.040]   is much like something very off hand and impermanent,
[00:48:19.040 --> 00:48:21.400]   it is the exact opposite.
[00:48:21.400 --> 00:48:24.160]   And so that's where this disconnect happens.
[00:48:24.160 --> 00:48:26.120]   And that's one of the reasons I think kids
[00:48:26.120 --> 00:48:29.520]   don't use Twitter as much as Snapchat.
[00:48:29.520 --> 00:48:31.360]   Yeah, because the impermanence of it.
[00:48:31.360 --> 00:48:32.080]   Stacy, let me--
[00:48:32.080 --> 00:48:33.280]   So yeah, I've been grappling with this.
[00:48:33.280 --> 00:48:36.600]   I started writing a piece, because I got very
[00:48:36.600 --> 00:48:39.360]   intemperate one night when he was--
[00:48:39.360 --> 00:48:40.800]   You used the F word.
[00:48:40.800 --> 00:48:45.600]   I used it in a particular way.
[00:48:45.600 --> 00:48:47.720]   Did you get letters too?
[00:48:47.720 --> 00:48:48.800]   No, no, I just--
[00:48:48.800 --> 00:48:50.560]   I follow you on Twitter.
[00:48:50.560 --> 00:48:51.640]   There's a guy who--
[00:48:51.640 --> 00:48:54.880]   I get an alert when Jeff tweets any time of the day.
[00:48:54.880 --> 00:48:57.800]   This guy tweeted, sent a letter to everybody around me.
[00:48:57.800 --> 00:49:04.200]   So the next day I tweeted that upon reflection and morning
[00:49:04.200 --> 00:49:07.240]   light, I regretted the incivility of one word in the tweet,
[00:49:07.240 --> 00:49:09.560]   but not the rest.
[00:49:09.560 --> 00:49:12.280]   And so I've been thinking about this.
[00:49:12.280 --> 00:49:15.240]   And here I've been writing about the angry white men who
[00:49:15.240 --> 00:49:17.640]   elected Trump, who we didn't listen to.
[00:49:17.640 --> 00:49:19.160]   And I'm saying that hypothetically,
[00:49:19.160 --> 00:49:20.600]   I'm saying that there was an anger there
[00:49:20.600 --> 00:49:22.120]   that we didn't understand, we didn't listen to,
[00:49:22.120 --> 00:49:23.080]   we didn't reflect back.
[00:49:23.080 --> 00:49:23.720]   And more than a few--
[00:49:23.720 --> 00:49:24.640]   Then what am I?
[00:49:24.640 --> 00:49:25.120]   What am I?
[00:49:25.120 --> 00:49:27.280]   I'm being an angry white man.
[00:49:27.280 --> 00:49:28.720]   My response to the angry white man
[00:49:28.720 --> 00:49:30.520]   is to be an angry white man.
[00:49:30.520 --> 00:49:35.840]   And so yeah, I think Stacy, you're right.
[00:49:35.840 --> 00:49:38.400]   Is it a guy thing or just a crazy person thing?
[00:49:38.400 --> 00:49:39.440]   I don't know.
[00:49:39.440 --> 00:49:40.920]   I see plenty of crazy women.
[00:49:40.920 --> 00:49:41.880]   I get the better of me.
[00:49:41.880 --> 00:49:43.720]   It gets the better of me.
[00:49:43.720 --> 00:49:46.360]   Rosie O'Donnell is a classic, right?
[00:49:46.360 --> 00:49:48.200]   Well, she's in a very privileged--
[00:49:48.200 --> 00:49:49.200]   Yeah.
[00:49:49.200 --> 00:49:50.960]   --and she's in a different position.
[00:49:50.960 --> 00:49:53.760]   But hey, you want to talk about actions on Google
[00:49:53.760 --> 00:49:56.920]   and weave and Brillo?
[00:49:56.920 --> 00:49:57.760]   I know you guys do.
[00:49:57.760 --> 00:49:58.280]   We will.
[00:49:58.280 --> 00:49:59.480]   You're trying to change the subject.
[00:49:59.480 --> 00:50:01.120]   And I don't blame you one cotton pick a bit.
[00:50:01.120 --> 00:50:03.040]   In fact, really, we've milked this one of this.
[00:50:03.040 --> 00:50:05.680]   Let me just quickly go through this Yahoo story.
[00:50:05.680 --> 00:50:08.280]   And then I would very much like to talk to you.
[00:50:08.280 --> 00:50:13.840]   Yahoo has-- this is from Yahoo Tech, so I think it's true.
[00:50:13.840 --> 00:50:15.560]   Well, they're quoting the boy genius report.
[00:50:15.560 --> 00:50:18.520]   So I don't understand if this counts
[00:50:18.520 --> 00:50:20.720]   as an official acknowledgement from Yahoo
[00:50:20.720 --> 00:50:22.840]   since it's on a Yahoo page, or it's just
[00:50:22.840 --> 00:50:25.800]   like an automated repeat of the boy genius report.
[00:50:25.800 --> 00:50:28.360]   Yahoo has reportedly confirmed the existence of a hack.
[00:50:28.360 --> 00:50:31.800]   It affects more than one billion user accounts.
[00:50:31.800 --> 00:50:36.320]   Yahoo has said it's likely distinct from that other hack,
[00:50:36.320 --> 00:50:40.280]   you remember, with hundreds of millions of Yahoo customers.
[00:50:40.280 --> 00:50:46.760]   So if, for some reason, CNBC is reporting--
[00:50:46.760 --> 00:50:48.600]   that Yahoo has confirmed the existence of a new hack
[00:50:48.600 --> 00:50:50.320]   and it affects more than a billion users,
[00:50:50.320 --> 00:50:52.520]   and it's a different hack.
[00:50:52.520 --> 00:50:56.160]   So we don't know what I'd like to know
[00:50:56.160 --> 00:50:58.200]   is the time and date of the hack.
[00:50:58.200 --> 00:51:00.200]   So in other words, if you change your password, as I did,
[00:51:00.200 --> 00:51:03.280]   and I hope everybody did, after the first 500 million
[00:51:03.280 --> 00:51:07.880]   people were hacked, do you need to change it again?
[00:51:07.880 --> 00:51:10.800]   Or should you just get off Yahoo completely right now,
[00:51:10.800 --> 00:51:12.800]   say forget it, goodbye.
[00:51:12.800 --> 00:51:14.400]   Unbelievable.
[00:51:14.400 --> 00:51:19.360]   This one, Yahoo believes that it happened in August 2013.
[00:51:19.360 --> 00:51:20.080]   Oh, OK.
[00:51:20.080 --> 00:51:21.760]   So it is a second hack.
[00:51:21.760 --> 00:51:22.960]   It is a second hack.
[00:51:22.960 --> 00:51:23.720]   It believes this--
[00:51:23.720 --> 00:51:25.360]   Before we all learned about the first hack,
[00:51:25.360 --> 00:51:28.120]   so presumably any changes were made after the first hack
[00:51:28.120 --> 00:51:29.280]   also protect us.
[00:51:29.280 --> 00:51:31.080]   However, they have information.
[00:51:31.080 --> 00:51:38.360]   The investigation-- OK, so here's Yahoo's press release.
[00:51:38.360 --> 00:51:40.280]   The stolen user account information
[00:51:40.280 --> 00:51:42.680]   may have included names, email addresses, telephone numbers,
[00:51:42.680 --> 00:51:46.040]   DOBs, hash passwords, and in some cases,
[00:51:46.040 --> 00:51:49.360]   encrypted or unencrypted security questions and answers.
[00:51:49.360 --> 00:51:53.040]   But the information does not include passwords in clear text.
[00:51:53.040 --> 00:51:54.400]   What?
[00:51:54.400 --> 00:51:56.840]   Payment card data or bank account information?
[00:51:56.840 --> 00:51:59.440]   OK.
[00:51:59.440 --> 00:52:01.320]   What passwords are being stored in clear text?
[00:52:01.320 --> 00:52:04.680]   Are those the ones you're just sending over email to people?
[00:52:04.680 --> 00:52:05.400]   Sorry.
[00:52:05.400 --> 00:52:08.920]   No, whether they were storing passwords in clear text,
[00:52:08.920 --> 00:52:09.440]   which they weren't.
[00:52:09.440 --> 00:52:12.560]   Well, they shouldn't be doing that in 2013 event.
[00:52:12.560 --> 00:52:15.320]   I agree.
[00:52:15.320 --> 00:52:18.880]   By the way, I now have to retract my skepticism
[00:52:18.880 --> 00:52:21.600]   over the crooked Hillary emoji.
[00:52:21.600 --> 00:52:22.120]   OK, good.
[00:52:22.120 --> 00:52:22.920]   Sorry, look it up good.
[00:52:22.920 --> 00:52:24.400]   All right.
[00:52:24.400 --> 00:52:28.040]   This is the Medium post from Gary Coby,
[00:52:28.040 --> 00:52:31.160]   Director of Digital Advertising and Fundraising
[00:52:31.160 --> 00:52:33.040]   for the Trump campaign.
[00:52:33.040 --> 00:52:34.720]   From when?
[00:52:34.720 --> 00:52:37.600]   This is 13 November 2016.
[00:52:37.600 --> 00:52:39.600]   More specific-- this is his tweet.
[00:52:39.600 --> 00:52:43.600]   CEO Jack Dorsey personally made a call to restrict us.
[00:52:43.600 --> 00:52:45.160]   We had an upfront deal.
[00:52:45.160 --> 00:52:46.360]   This is from the Trump campaign.
[00:52:46.360 --> 00:52:49.080]   We had an upfront deal with Twitter,
[00:52:49.080 --> 00:52:52.040]   where we commit to spending a certain amount of advertising
[00:52:52.040 --> 00:52:53.680]   and exchange receive.
[00:52:53.680 --> 00:52:59.320]   This counts perks, and this is the key phrase, custom solutions.
[00:52:59.320 --> 00:53:00.880]   $5 million spend.
[00:53:00.880 --> 00:53:02.320]   Blah, blah, blah.
[00:53:02.320 --> 00:53:07.560]   What they wanted was a custom hashtag emoji.
[00:53:07.560 --> 00:53:10.080]   They wanted to launch emojis for the first debate.
[00:53:10.080 --> 00:53:12.880]   One was a contrasting emoji for the hashtag crooked Hillary.
[00:53:12.880 --> 00:53:15.440]   They were going to be featured in our promoted trend.
[00:53:15.440 --> 00:53:17.280]   This is what it was going to look like.
[00:53:17.280 --> 00:53:21.040]   This was designed and approved by Twitter,
[00:53:21.040 --> 00:53:23.120]   probably by an agency inside Twitter,
[00:53:23.120 --> 00:53:24.360]   to be used with crooked Hillary.
[00:53:24.360 --> 00:53:27.200]   It's a hand holding a bag of money.
[00:53:27.200 --> 00:53:33.040]   Then I met with TW in New York at Trump Tower, I guess.
[00:53:33.040 --> 00:53:33.560]   Twitter?
[00:53:33.560 --> 00:53:34.280]   Twitter.
[00:53:34.280 --> 00:53:36.480]   To tweak the already approved emoji designs,
[00:53:36.480 --> 00:53:38.920]   pushing the envelope, the hand money bag emoji
[00:53:38.920 --> 00:53:42.280]   evolved into a running stick figure with a money bag.
[00:53:42.280 --> 00:53:43.240]   Jesus.
[00:53:43.240 --> 00:53:45.440]   TWT thought this had a good chance of getting approved
[00:53:45.440 --> 00:53:48.640]   since all that was changed was a hand to a stick figure.
[00:53:48.640 --> 00:53:52.240]   Anyway, a day after day, Jack Dorsey was never named,
[00:53:52.240 --> 00:53:54.920]   just Adam Bain.
[00:53:54.920 --> 00:53:55.960]   TW told me the news.
[00:53:55.960 --> 00:53:57.320]   No, no, no, no.
[00:53:57.320 --> 00:54:00.400]   Yeah, it was causing a lot of heartburn and big meetings.
[00:54:00.400 --> 00:54:06.320]   In fact, the Trump campaign and the person of Gary Kobe confirmed
[00:54:06.320 --> 00:54:09.520]   they wanted a custom emoji and Jack Dorsey blocked it.
[00:54:09.520 --> 00:54:10.640]   OK.
[00:54:10.640 --> 00:54:14.280]   I now believe that story that was unbelievable.
[00:54:14.280 --> 00:54:16.800]   Ta-da.
[00:54:16.800 --> 00:54:19.760]   The fakest sounding news can sometimes tell.
[00:54:19.760 --> 00:54:22.600]   You just got to do some research.
[00:54:22.600 --> 00:54:24.720]   Just got to believe.
[00:54:24.720 --> 00:54:25.880]   I believe.
[00:54:25.880 --> 00:54:27.360]   That's how crazy this world is.
[00:54:27.360 --> 00:54:30.480]   The things you can't believe are probably true.
[00:54:30.480 --> 00:54:34.640]   I'm just going to hide behind my snap spectacles for now
[00:54:34.640 --> 00:54:35.640]   and record it all.
[00:54:35.640 --> 00:54:36.800]   I am going to record it all.
[00:54:36.800 --> 00:54:41.320]   Hey, what if somebody wore this to Trump Tower for me?
[00:54:41.320 --> 00:54:43.880]   I imagine the Secret Service would tell you to take it off.
[00:54:43.880 --> 00:54:45.000]   Probably, no, no.
[00:54:45.000 --> 00:54:46.480]   Yeah, they take your phone to show, I'm sure.
[00:54:46.480 --> 00:54:48.840]   The Secret Service seems pretty good at their job.
[00:54:48.840 --> 00:54:51.880]   I know they had the offense climbing incidences,
[00:54:51.880 --> 00:54:53.600]   but in general--
[00:54:53.600 --> 00:54:56.920]   So I heard something today from a very reliable news
[00:54:56.920 --> 00:55:02.080]   company who went and did some stuff at Trump Tower with Trump.
[00:55:02.080 --> 00:55:04.000]   When they went to the apartment, evidently,
[00:55:04.000 --> 00:55:07.840]   they had to wear booties to notch the carpeting.
[00:55:07.840 --> 00:55:09.000]   So this is a--
[00:55:09.000 --> 00:55:11.120]   I make all contractors do that when they come to my house.
[00:55:11.120 --> 00:55:12.760]   Yeah, everybody comes to our house, does that too.
[00:55:12.760 --> 00:55:16.760]   But there is, and it may be a character assassination,
[00:55:16.760 --> 00:55:19.160]   but I think it sounds kind of true,
[00:55:19.160 --> 00:55:22.360]   there is the story that our present elect is a germaphobe,
[00:55:22.360 --> 00:55:25.760]   much like how our shoes was, that the betting on the plane,
[00:55:25.760 --> 00:55:27.600]   for instance, has changed-- not really
[00:55:27.600 --> 00:55:30.080]   changed each time it's used, but thrown away
[00:55:30.080 --> 00:55:32.920]   and new betting has purchased.
[00:55:32.920 --> 00:55:35.280]   You notice he never shakes hands.
[00:55:35.280 --> 00:55:36.920]   There's some evidence of that.
[00:55:36.920 --> 00:55:39.880]   Anyway, but booties, I'm with you.
[00:55:39.880 --> 00:55:42.760]   Don't go tramping your dirty contacts
[00:55:42.760 --> 00:55:44.200]   or feet all over my house.
[00:55:44.200 --> 00:55:46.640]   Your dirty journalist feet.
[00:55:46.640 --> 00:55:48.160]   Hey, journalists.
[00:55:48.160 --> 00:55:50.480]   They tran up through mud all the time.
[00:55:50.480 --> 00:55:51.520]   Yeah, we're muckbreakers.
[00:55:51.520 --> 00:55:54.000]   All right, so what did you-- you had something for us, Stacey,
[00:55:54.000 --> 00:55:57.880]   that you were trying to dangle a shiny object in our--
[00:55:57.880 --> 00:56:01.280]   I was, I was like, look at the Google Actions.
[00:56:01.280 --> 00:56:03.520]   Google, home view, guys.
[00:56:03.520 --> 00:56:05.160]   So I'm excited about this.
[00:56:05.160 --> 00:56:06.280]   I'm excited about this.
[00:56:06.280 --> 00:56:07.800]   Yeah, I am, too.
[00:56:07.800 --> 00:56:08.560]   Super stoked.
[00:56:08.560 --> 00:56:09.960]   It's not out yet.
[00:56:09.960 --> 00:56:13.200]   So basically, there's two separate things--
[00:56:13.200 --> 00:56:14.280]   Actions on Google.
[00:56:14.280 --> 00:56:15.800]   Which, did y'all talk about that last week?
[00:56:15.800 --> 00:56:16.760]   Did we talk about that last week?
[00:56:16.760 --> 00:56:17.480]   Did it come out there?
[00:56:17.480 --> 00:56:18.040]   I don't think so.
[00:56:18.040 --> 00:56:18.400]   Let's say--
[00:56:18.400 --> 00:56:19.040]   No, not really no.
[00:56:19.040 --> 00:56:20.160]   Oh, no, because it's Wednesday.
[00:56:20.160 --> 00:56:20.960]   It came out Thursday.
[00:56:20.960 --> 00:56:21.480]   Sorry.
[00:56:21.480 --> 00:56:23.720]   Yeah, it's always hard to know, because we talk about everything
[00:56:23.720 --> 00:56:26.280]   so obsessively all the time.
[00:56:26.280 --> 00:56:28.640]   So let me zoom in on this, and we can actually watch it.
[00:56:28.640 --> 00:56:30.760]   This video, I thought this is big for us
[00:56:30.760 --> 00:56:32.000]   and media, it's big all over.
[00:56:32.000 --> 00:56:32.680]   All right, here we go.
[00:56:32.680 --> 00:56:32.920]   Watch.
[00:56:32.920 --> 00:56:34.320]   I passed it around the journalism school.
[00:56:34.320 --> 00:56:35.920]   So this is a detailed--
[00:56:35.920 --> 00:56:36.880]   Do you have my audio?
[00:56:36.880 --> 00:56:38.040]   Another one before you watch.
[00:56:38.040 --> 00:56:38.520]   Before you watch.
[00:56:38.520 --> 00:56:40.960]   Watch the-- because he has an accent.
[00:56:40.960 --> 00:56:41.160]   Yeah.
[00:56:41.160 --> 00:56:42.160]   Watch the closed caption.
[00:56:42.160 --> 00:56:43.000]   It's hilarious.
[00:56:43.000 --> 00:56:43.840]   Oh, OK.
[00:56:43.840 --> 00:56:44.240]   Wait a minute.
[00:56:44.240 --> 00:56:44.600]   Hold on.
[00:56:44.600 --> 00:56:46.080]   I got to make sure I'm not muted.
[00:56:46.080 --> 00:56:48.320]   I'm muted, OK.
[00:56:48.320 --> 00:56:50.440]   I hear a little puppy.
[00:56:50.440 --> 00:56:52.320]   If I mute my microphone, does that help?
[00:56:52.320 --> 00:56:53.720]   If I mute it on--
[00:56:53.720 --> 00:56:56.560]   It doesn't, because then we can't hear him.
[00:56:56.560 --> 00:56:57.600]   But that's kind of the point.
[00:56:57.600 --> 00:56:58.320]   No, I'm not here.
[00:56:58.320 --> 00:56:58.960]   I don't care.
[00:56:58.960 --> 00:56:59.960]   OK, ready?
[00:56:59.960 --> 00:57:00.800]   Here we go.
[00:57:00.800 --> 00:57:02.720]   An example-- OK, I'll back it up just a little bit.
[00:57:02.720 --> 00:57:03.640]   Here we go.
[00:57:03.640 --> 00:57:06.360]   Through a detailed example of a user interacting
[00:57:06.360 --> 00:57:08.360]   with a conversation action.
[00:57:08.360 --> 00:57:10.400]   Think about something as simple as helping your user
[00:57:10.400 --> 00:57:13.320]   choose what to have for dinner based on their mood
[00:57:13.320 --> 00:57:14.840]   and the ingredients they have around.
[00:57:14.840 --> 00:57:17.720]   Let's call this action personal chef.
[00:57:17.720 --> 00:57:19.800]   The user first needs to invoke your action
[00:57:19.800 --> 00:57:23.200]   with something like, OK, Google, let me talk to personal chef.
[00:57:23.200 --> 00:57:26.320]   This is very similar to what happens with the echo, right?
[00:57:26.320 --> 00:57:27.160]   If you want to play--
[00:57:27.160 --> 00:57:28.160]   No.
[00:57:28.160 --> 00:57:29.040]   It's very different.
[00:57:29.040 --> 00:57:29.800]   And we'll talk about that.
[00:57:29.800 --> 00:57:30.300]   Oh.
[00:57:30.300 --> 00:57:30.800]   Oh.
[00:57:30.800 --> 00:57:32.640]   I can't wait for Stacy's analysis.
[00:57:32.640 --> 00:57:33.140]   Good.
[00:57:33.140 --> 00:57:33.480]   Good.
[00:57:33.480 --> 00:57:35.000]   Continuing on.
[00:57:35.000 --> 00:57:37.320]   The assistant will then introduce your action.
[00:57:37.320 --> 00:57:39.680]   And now the user is talking to you directly.
[00:57:39.680 --> 00:57:42.400]   From this point onwards, you get to interact with the user
[00:57:42.400 --> 00:57:44.480]   and have a conversation.
[00:57:44.480 --> 00:57:48.000]   OK, Google, let me talk to personal chef.
[00:57:48.000 --> 00:57:50.480]   Sure, here's personal chef.
[00:57:50.480 --> 00:57:52.560]   Hi, I'm your personal chef.
[00:57:52.560 --> 00:57:54.240]   What's your favorite for?
[00:57:54.240 --> 00:57:54.400]   Well--
[00:57:54.400 --> 00:57:56.240]   Because it's not just--
[00:57:56.240 --> 00:57:57.760]   it's a new person.
[00:57:57.760 --> 00:57:58.400]   It's a new--
[00:57:58.400 --> 00:58:01.640]   It's a new off to the other--
[00:58:01.640 --> 00:58:05.280]   Yes, that's really interesting because--
[00:58:05.280 --> 00:58:06.200]   well, two reasons.
[00:58:06.200 --> 00:58:09.800]   One, it's like you total new things, so not--
[00:58:09.800 --> 00:58:10.680]   or the echo.
[00:58:10.680 --> 00:58:14.400]   But two, you can create branded voice experiences.
[00:58:14.400 --> 00:58:16.160]   So if you think your personal chef should
[00:58:16.160 --> 00:58:19.000]   sound like that nice lady, great.
[00:58:19.000 --> 00:58:22.400]   You could have your current spokesperson
[00:58:22.400 --> 00:58:24.840]   be your voice from an ad perspective.
[00:58:24.840 --> 00:58:26.520]   I think it's really interesting and really smart.
[00:58:26.520 --> 00:58:27.200]   OK, go.
[00:58:27.200 --> 00:58:29.080]   You might find-- yeah, keep going into how it's made
[00:58:29.080 --> 00:58:30.680]   because I think it'll find it interesting.
[00:58:30.680 --> 00:58:31.960]   It's kind of cold outside.
[00:58:31.960 --> 00:58:34.720]   So I'd like something to warm me up, like a hot soup.
[00:58:34.720 --> 00:58:37.120]   And I want it fast.
[00:58:37.120 --> 00:58:39.680]   All right, what protein would you like to use?
[00:58:39.680 --> 00:58:42.600]   I have some chicken and also some canned tomatoes.
[00:58:42.600 --> 00:58:43.760]   Some canned cermados.
[00:58:43.760 --> 00:58:45.280]   Cansed cermados, what?
[00:58:45.280 --> 00:58:47.120]   I think you can try the chicken cermados.
[00:58:47.120 --> 00:58:47.880]   [LAUGHTER]
[00:58:47.880 --> 00:58:50.760]   I found an example.com.
[00:58:50.760 --> 00:58:52.400]   Sounds good to me.
[00:58:52.400 --> 00:58:56.720]   That's the classic Google auto translate.
[00:58:56.720 --> 00:58:58.960]   I got some canned cermados.
[00:58:58.960 --> 00:59:00.320]   All right.
[00:59:00.320 --> 00:59:04.760]   So it's not like it had a camera in your refrigerator.
[00:59:04.760 --> 00:59:06.160]   He had to tell her what he had.
[00:59:06.160 --> 00:59:07.000]   Yeah, yeah, yeah.
[00:59:07.000 --> 00:59:08.160]   Yes.
[00:59:08.160 --> 00:59:11.000]   But the way that you have to anticipate the conversation
[00:59:11.000 --> 00:59:15.160]   and the way you code that using their AI structure
[00:59:15.160 --> 00:59:17.360]   is really interesting, right, Stacey?
[00:59:17.360 --> 00:59:18.760]   Yes.
[00:59:18.760 --> 00:59:20.160]   Because notice how he--
[00:59:20.160 --> 00:59:22.200]   Speaking, but--
[00:59:22.200 --> 00:59:25.520]   Yes, but notice how he phrased his question.
[00:59:25.520 --> 00:59:27.400]   So he was like, it's hot.
[00:59:27.400 --> 00:59:28.680]   No, it's cold outside.
[00:59:28.680 --> 00:59:30.800]   So I want something to warm me up.
[00:59:30.800 --> 00:59:36.560]   And from that, they took soup in whatever--
[00:59:36.560 --> 00:59:38.280]   and then she asked proteins.
[00:59:38.280 --> 00:59:40.480]   She knew that he wanted a recipe.
[00:59:40.480 --> 00:59:43.040]   I know it was a cooking thing.
[00:59:43.040 --> 00:59:47.840]   But it was actually not a direct request for anything.
[00:59:47.840 --> 00:59:49.600]   And that I think is really cool.
[00:59:49.600 --> 00:59:52.480]   And on the back end, it's really complicated
[00:59:52.480 --> 00:59:55.200]   to get that right.
[00:59:55.200 --> 00:59:59.200]   Despite the cancer needles or cancer models.
[00:59:59.200 --> 01:00:02.000]   Well, ironically, she had a studio he's saying.
[01:00:02.000 --> 01:00:02.520]   Yeah, but--
[01:00:02.520 --> 01:00:04.120]   It was the auto-translate on YouTube.
[01:00:04.120 --> 01:00:05.120]   YouTube, too.
[01:00:05.120 --> 01:00:06.320]   YouTube, yeah.
[01:00:06.320 --> 01:00:08.320]   Maybe they're not the same systems.
[01:00:08.320 --> 01:00:10.880]   I would not.
[01:00:10.880 --> 01:00:12.880]   So this is a pretty rich interaction.
[01:00:12.880 --> 01:00:14.960]   Think about all the sentences I spoke
[01:00:14.960 --> 01:00:17.880]   and how the action needs to extract the meaning out of this.
[01:00:17.880 --> 01:00:19.560]   How would you implement this?
[01:00:19.560 --> 01:00:21.840]   If you're an expert in the area of natural language--
[01:00:21.840 --> 01:00:22.840]   So now this is going to be--
[01:00:22.840 --> 01:00:23.840]   You can use the conversation--
[01:00:23.840 --> 01:00:24.840]   But it's interesting.
[01:00:24.840 --> 01:00:25.800]   --how they would do it.
[01:00:25.800 --> 01:00:26.280]   Yeah.
[01:00:26.280 --> 01:00:27.720]   You want to keep going?
[01:00:27.720 --> 01:00:28.240]   It's actually--
[01:00:28.240 --> 01:00:28.240]   I really--
[01:00:28.240 --> 01:00:28.740]   --really cool.
[01:00:28.740 --> 01:00:28.920]   But it's--
[01:00:28.920 --> 01:00:29.440]   Yeah, it is--
[01:00:29.440 --> 01:00:31.280]   --it allows you to process the raw strings that
[01:00:31.280 --> 01:00:33.640]   contain the spoken text from the user.
[01:00:33.640 --> 01:00:36.960]   You can then use the Actions SDK that includes all the tools
[01:00:36.960 --> 01:00:39.560]   and libraries you need to build the actions.
[01:00:39.560 --> 01:00:42.200]   However, if you don't want to process the user's transcribed
[01:00:42.200 --> 01:00:44.720]   speech yourself, you can use one of the tools that
[01:00:44.720 --> 01:00:47.240]   have integrated with Actions on Google.
[01:00:47.240 --> 01:00:50.000]   One of these tools is API.ai, which
[01:00:50.000 --> 01:00:52.720]   provides an intuitive graphical user interface
[01:00:52.720 --> 01:00:54.760]   to create conversational interfaces.
[01:00:54.760 --> 01:00:56.840]   And it does the heavy lifting in terms
[01:00:56.840 --> 01:00:59.680]   of managing conversational state and filling out slots
[01:00:59.680 --> 01:01:00.720]   informs.
[01:01:00.720 --> 01:01:03.960]   This means you'll no longer need to process the raw strings.
[01:01:03.960 --> 01:01:06.760]   API.ai can do this for you.
[01:01:06.760 --> 01:01:10.440]   To handle a conversation, you use the API.ai developer console
[01:01:10.440 --> 01:01:11.800]   to create an intent.
[01:01:11.800 --> 01:01:14.880]   This is where you define the information you need from the user.
[01:01:14.880 --> 01:01:17.400]   For our example, finding a kitchen recipe,
[01:01:17.400 --> 01:01:19.880]   this would be the type of food, the ingredients,
[01:01:19.880 --> 01:01:22.960]   the temperature, and the cooking time.
[01:01:22.960 --> 01:01:25.360]   You then specify example sentences.
[01:01:25.360 --> 01:01:28.080]   API.ai pauses these sentences and uses them
[01:01:28.080 --> 01:01:29.960]   to train its machine learning algorithm
[01:01:29.960 --> 01:01:33.240]   to process other possible sentences from your users.
[01:01:33.240 --> 01:01:36.960]   You don't have to write regular expressions or a parser.
[01:01:36.960 --> 01:01:39.600]   You can also manually set what the acceptable values are
[01:01:39.600 --> 01:01:41.480]   for each piece of information.
[01:01:41.480 --> 01:01:44.680]   Once this is done, API.ai uses these definitions
[01:01:44.680 --> 01:01:47.360]   to extract meaning out of spoken sentences.
[01:01:47.360 --> 01:01:50.600]   The user can provide information naturally, out of order,
[01:01:50.600 --> 01:01:52.880]   all at once, or in pieces.
[01:01:52.880 --> 01:01:55.640]   The action can ask follow-up questions as needed.
[01:01:55.640 --> 01:01:57.760]   Pretty neat, right?
[01:01:57.760 --> 01:02:00.720]   Once you've set up everything in the API.ai console,
[01:02:00.720 --> 01:02:04.760]   you can then test it immediately with example sentences.
[01:02:04.760 --> 01:02:07.800]   Then you can test your project with the web simulator,
[01:02:07.800 --> 01:02:10.840]   preview it on Google Home, or deploy the full project
[01:02:10.840 --> 01:02:13.800]   at Google, all from within API.ai.
[01:02:13.800 --> 01:02:17.240]   Next, you can connect up an optional webhook to your intent
[01:02:17.240 --> 01:02:19.720]   to allow it to interact with a backend server.
[01:02:19.720 --> 01:02:21.840]   When all the details you need are filled in,
[01:02:21.840 --> 01:02:24.400]   your webhook is called with the appropriate details
[01:02:24.400 --> 01:02:26.760]   provided as JSON data.
[01:02:26.760 --> 01:02:30.200]   So you don't really have to know anything at all about--
[01:02:30.200 --> 01:02:31.040]   I know!
[01:02:31.040 --> 01:02:31.880]   Understanding language.
[01:02:31.880 --> 01:02:33.520]   Bingo, exactly.
[01:02:33.520 --> 01:02:34.520]   Wow.
[01:02:34.520 --> 01:02:36.120]   They give you everything.
[01:02:36.120 --> 01:02:38.520]   And think about all the things--
[01:02:38.520 --> 01:02:40.920]   I could have Google Home talk to people
[01:02:40.920 --> 01:02:44.480]   through one of the things I want to do
[01:02:44.480 --> 01:02:47.080]   is the most common question I get is,
[01:02:47.080 --> 01:02:49.320]   Stacy, I want to start in the smart home.
[01:02:49.320 --> 01:02:50.360]   What should I do?
[01:02:50.360 --> 01:02:52.480]   But there's too many decision trees
[01:02:52.480 --> 01:02:57.200]   that branch out from that for me to create a nice article.
[01:02:57.200 --> 01:03:01.680]   But I could do a chatbot that actually does all that is so--
[01:03:01.680 --> 01:03:04.800]   do you have an Android or an iPhone?
[01:03:04.800 --> 01:03:06.080]   Then I could route them one way.
[01:03:06.080 --> 01:03:10.160]   Do you want to have a hub or do you just want Wi-Fi Bluetooth?
[01:03:10.160 --> 01:03:13.080]   So I could create this conversational interaction that
[01:03:13.080 --> 01:03:14.960]   is way better than doing a flowchart
[01:03:14.960 --> 01:03:18.160]   or a how-to article from my readers, listeners, people.
[01:03:18.160 --> 01:03:20.160]   Yeah.
[01:03:20.160 --> 01:03:22.520]   You going to do that?
[01:03:22.520 --> 01:03:23.360]   Yes.
[01:03:23.360 --> 01:03:24.720]   No, you're not.
[01:03:24.720 --> 01:03:26.720]   Oh, actually, I might be.
[01:03:26.720 --> 01:03:29.480]   I flirt with this all the time.
[01:03:29.480 --> 01:03:35.080]   But then you sit down and it's not as quite as easy as it looks.
[01:03:35.080 --> 01:03:38.360]   No, it's more if you have a big database of stuff.
[01:03:38.360 --> 01:03:40.320]   And you're creating a database.
[01:03:40.320 --> 01:03:41.840]   If you're Epicurious-- yeah, you do.
[01:03:41.840 --> 01:03:43.680]   If you're Epicurious and you have rest--
[01:03:43.680 --> 01:03:44.200]   Right.
[01:03:44.200 --> 01:03:44.840]   --restories, right?
[01:03:44.840 --> 01:03:48.240]   If you have how-to things like Stacey does,
[01:03:48.240 --> 01:03:49.600]   that's what it-- because, interestingly,
[01:03:49.600 --> 01:03:51.480]   all you're doing is creating a bridge between the two
[01:03:51.480 --> 01:03:54.000]   so somebody can get to the information they want.
[01:03:54.000 --> 01:03:56.240]   You're prompting them to make the right kinds of searches,
[01:03:56.240 --> 01:03:56.800]   basically.
[01:03:56.800 --> 01:03:58.320]   Right, Stacey?
[01:03:58.320 --> 01:03:59.520]   That's the hope.
[01:03:59.520 --> 01:04:00.360]   Yeah.
[01:04:00.360 --> 01:04:02.800]   And if they-- now, what they didn't show and what--
[01:04:02.800 --> 01:04:05.360]   I guess I should play with this and see if I can make one that
[01:04:05.360 --> 01:04:07.480]   fails because I'm curious what happens when
[01:04:07.480 --> 01:04:09.160]   your interaction--
[01:04:09.160 --> 01:04:10.160]   Yeah.
[01:04:10.160 --> 01:04:11.440]   --when people doesn't understand you.
[01:04:11.440 --> 01:04:14.080]   Right, what happens then?
[01:04:14.080 --> 01:04:16.960]   So hopefully, in an ideal situation,
[01:04:16.960 --> 01:04:19.960]   it would prompt you with something that might help.
[01:04:19.960 --> 01:04:23.840]   It would give you, like, pay users of you.
[01:04:23.840 --> 01:04:25.240]   I'm not sure what you asked.
[01:04:25.240 --> 01:04:30.520]   Do you want to cook a meal with meat or chicken?
[01:04:30.520 --> 01:04:32.720]   Do you want to make a salad or a breakfast meal?
[01:04:32.720 --> 01:04:37.760]   Well, I guess you could get more complicated.
[01:04:37.760 --> 01:04:39.840]   I always thought we should have some actions that
[01:04:39.840 --> 01:04:42.720]   play-- play, twit segments and things like that.
[01:04:42.720 --> 01:04:43.240]   Oh.
[01:04:43.240 --> 01:04:45.840]   So you can do-- well, you can do that on the Echo.
[01:04:45.840 --> 01:04:46.720]   Oh, OK.
[01:04:46.720 --> 01:04:49.400]   So can I tie this to some other stuff?
[01:04:49.400 --> 01:04:50.000]   Yeah.
[01:04:50.000 --> 01:04:50.560]   Sorry.
[01:04:50.560 --> 01:04:51.480]   I'm getting excited.
[01:04:51.480 --> 01:04:52.200]   No, go get it.
[01:04:52.200 --> 01:04:52.440]   Go get it.
[01:04:52.440 --> 01:04:52.920]   Sorry.
[01:04:52.920 --> 01:04:53.680]   I love it.
[01:04:53.680 --> 01:04:54.200]   I'm so excited.
[01:04:54.200 --> 01:04:55.280]   OK.
[01:04:55.280 --> 01:05:00.920]   So yesterday, also, Microsoft announced its Cortana SDK.
[01:05:00.920 --> 01:05:02.360]   And it's translate stuff.
[01:05:02.360 --> 01:05:05.920]   So you guys should look that up because this is kind of like
[01:05:05.920 --> 01:05:08.480]   what the Echo does with their skills.
[01:05:08.480 --> 01:05:14.000]   So Google Actions is akin to Echo skills, right?
[01:05:14.000 --> 01:05:19.320]   And then Amazon at AWS re-invent put out its own machine
[01:05:19.320 --> 01:05:20.120]   learning stuff.
[01:05:20.120 --> 01:05:23.360]   So it's own artificial intelligence stuff with Amazon Lex.
[01:05:23.360 --> 01:05:26.800]   Is it Amazon Lex or AWS Lex and AWS Poly?
[01:05:26.800 --> 01:05:31.000]   And then-- so what we basically have now
[01:05:31.000 --> 01:05:33.760]   is Microsoft has done an SDK.
[01:05:33.760 --> 01:05:35.960]   Google has an SDK for personal assistant.
[01:05:35.960 --> 01:05:37.240]   And so does Amazon, right?
[01:05:37.240 --> 01:05:45.360]   And now Amazon has done speech to text and text to speech
[01:05:45.360 --> 01:05:48.400]   and computer vision, much like Google has.
[01:05:48.400 --> 01:05:51.240]   Microsoft also did something with translate, which is they
[01:05:51.240 --> 01:05:53.920]   have some really powerful speech stuff.
[01:05:53.920 --> 01:05:54.560]   So I don't know.
[01:05:54.560 --> 01:05:55.400]   Did you guys follow that?
[01:05:55.400 --> 01:05:56.360]   Did that make any sense?
[01:05:56.360 --> 01:05:57.720]   Yeah.
[01:05:57.720 --> 01:06:00.840]   So basically, the battle is being joined.
[01:06:00.840 --> 01:06:00.840]   Yeah.
[01:06:00.840 --> 01:06:01.640]   All the pieces.
[01:06:01.640 --> 01:06:03.680]   We've established what the big pieces are,
[01:06:03.680 --> 01:06:04.960]   and everybody's got something.
[01:06:04.960 --> 01:06:06.880]   And now, next year, we're going to see
[01:06:06.880 --> 01:06:08.520]   what people can do with it.
[01:06:08.520 --> 01:06:09.320]   I'm so excited.
[01:06:09.320 --> 01:06:10.520]   Yeah, it is so great.
[01:06:10.520 --> 01:06:16.840]   So Stacey, if you have Apple, Amazon, and Google,
[01:06:16.840 --> 01:06:18.440]   who are you betting on?
[01:06:18.440 --> 01:06:19.840]   OK, so I have Microsoft--
[01:06:19.840 --> 01:06:20.360]   Who has the right pieces?
[01:06:20.360 --> 01:06:20.880]   Apple and Microsoft.
[01:06:20.880 --> 01:06:21.240]   And Microsoft.
[01:06:21.240 --> 01:06:22.200]   I won't let them even in there.
[01:06:22.200 --> 01:06:24.720]   Apple doesn't have anything because they want to protect
[01:06:24.720 --> 01:06:26.080]   your privacy or something.
[01:06:26.080 --> 01:06:26.840]   They have serious--
[01:06:26.840 --> 01:06:28.320]   They're focused on privacy.
[01:06:28.320 --> 01:06:28.840]   So--
[01:06:28.840 --> 01:06:29.920]   They have serious--
[01:06:29.920 --> 01:06:33.160]   They could theoretically do an Apple device.
[01:06:33.160 --> 01:06:33.680]   So this is--
[01:06:33.680 --> 01:06:35.840]   There's a big question because is it
[01:06:35.840 --> 01:06:37.760]   your voice interaction that's going to win?
[01:06:37.760 --> 01:06:39.800]   How well you can handle speech?
[01:06:39.800 --> 01:06:42.320]   Is it your AI or is it your ecosystem?
[01:06:42.320 --> 01:06:44.360]   I think ecosystem ultimately is what's
[01:06:44.360 --> 01:06:45.320]   going to make the distinction.
[01:06:45.320 --> 01:06:47.680]   Even-- I mean, you could assume, for instance,
[01:06:47.680 --> 01:06:49.720]   Google Home and Echo are roughly equal in ability
[01:06:49.720 --> 01:06:51.880]   to recognize your voice.
[01:06:51.880 --> 01:06:53.640]   I don't think that's true at all.
[01:06:53.640 --> 01:06:59.640]   I think Google has a way better handle on what I actually
[01:06:59.640 --> 01:07:00.320]   want it to do.
[01:07:00.320 --> 01:07:02.240]   So I did a video.
[01:07:02.240 --> 01:07:03.680]   It's the cheesiest video.
[01:07:03.680 --> 01:07:07.520]   But I asked the Echo, what does a dog sound like?
[01:07:07.520 --> 01:07:09.760]   And then I asked Google what a dog sounds like.
[01:07:09.760 --> 01:07:11.760]   And if you want, you can see the video.
[01:07:11.760 --> 01:07:12.120]   No, no.
[01:07:12.120 --> 01:07:12.880]   I agree with you.
[01:07:12.880 --> 01:07:17.480]   So in both cases, I presume they understood what you were asking.
[01:07:17.480 --> 01:07:18.000]   Right.
[01:07:18.000 --> 01:07:18.200]   But--
[01:07:18.200 --> 01:07:19.720]   It was the response that was different.
[01:07:19.720 --> 01:07:21.200]   So I'm not disagree--
[01:07:21.200 --> 01:07:24.880]   That's not what I was saying is, in terms of voice recognition,
[01:07:24.880 --> 01:07:26.520]   understanding your voice.
[01:07:26.520 --> 01:07:27.720]   They're equal.
[01:07:27.720 --> 01:07:29.720]   And it was exactly what I was saying,
[01:07:29.720 --> 01:07:33.200]   which is how the knowledge base, the database,
[01:07:33.200 --> 01:07:34.240]   differs.
[01:07:34.240 --> 01:07:38.920]   And going forward, I think even more important, the API,
[01:07:38.920 --> 01:07:40.240]   the integration.
[01:07:40.240 --> 01:07:43.000]   Right now, there's 5,000 Echo skills.
[01:07:43.000 --> 01:07:45.520]   That gives Echo a real leg up on Google.
[01:07:45.520 --> 01:07:48.160]   But Google has a leg up in terms of understanding
[01:07:48.160 --> 01:07:49.400]   what you're saying.
[01:07:49.400 --> 01:07:51.160]   And when it comes to Knowledge Graph, which
[01:07:51.160 --> 01:07:54.080]   is where the dog bark or the whale sounds come in,
[01:07:54.080 --> 01:07:56.160]   Google has its Knowledge Graph.
[01:07:56.160 --> 01:07:58.120]   Amazon never had a Knowledge Graph.
[01:07:58.120 --> 01:08:00.040]   And Google knows more about you as a person.
[01:08:00.040 --> 01:08:02.040]   They have a more well-rounded view of you.
[01:08:02.040 --> 01:08:03.480]   Amazon knows what you buy.
[01:08:03.480 --> 01:08:05.280]   I mean, Amazon knows some things.
[01:08:05.280 --> 01:08:05.680]   Yeah.
[01:08:05.680 --> 01:08:09.520]   But Amazon's developer platform-- so the way
[01:08:09.520 --> 01:08:12.080]   what we just saw with Google, that
[01:08:12.080 --> 01:08:15.040]   is far more flexible than what Amazon offers people today.
[01:08:15.040 --> 01:08:19.440]   You have to actually type in your commands for things.
[01:08:19.440 --> 01:08:22.160]   You don't get the ability to be like, oh, a protein.
[01:08:22.160 --> 01:08:24.200]   It could also mean chicken beef or--
[01:08:24.200 --> 01:08:24.460]   Yeah.
[01:08:24.460 --> 01:08:28.080]   No, if Google can really make it easy to integrate
[01:08:28.080 --> 01:08:32.600]   artificial intelligence and learning, it'll have it.
[01:08:32.600 --> 01:08:35.040]   So that's what I kind of mean is ultimately the API
[01:08:35.040 --> 01:08:37.000]   is what's going to win.
[01:08:37.000 --> 01:08:41.120]   So Google is in Google's interest to bring this to absolutely
[01:08:41.120 --> 01:08:42.600]   everything that Google does.
[01:08:42.600 --> 01:08:44.800]   And they're going to open it up to other companies.
[01:08:44.800 --> 01:08:48.040]   Amazon has less that they need to do.
[01:08:48.040 --> 01:08:53.080]   Although they're making deals, the late great pebble,
[01:08:53.080 --> 01:08:55.000]   that product that they had to kill
[01:08:55.000 --> 01:08:58.560]   was basically an echo in your pocket, right?
[01:08:58.560 --> 01:09:00.560]   Can I just tell you, I got my refund on that,
[01:09:00.560 --> 01:09:02.120]   and I'm so sad that I'm not going to get it.
[01:09:02.120 --> 01:09:03.640]   Wouldn't we have liked to have that?
[01:09:03.640 --> 01:09:05.600]   Yeah.
[01:09:05.600 --> 01:09:07.960]   And apparently, Google just hired a company.
[01:09:07.960 --> 01:09:11.760]   Google just acquired a company called Chronologics,
[01:09:11.760 --> 01:09:13.800]   which is going to make an Alexa powered--
[01:09:13.800 --> 01:09:16.120]   I always say Alexa, I mean Echo.
[01:09:16.120 --> 01:09:17.240]   I don't want to say the A word.
[01:09:17.240 --> 01:09:20.560]   An Echo powered co-watch, and it's expected
[01:09:20.560 --> 01:09:23.520]   Google will put that into Android Wear.
[01:09:23.520 --> 01:09:28.880]   So talk to your watch, talk to your phone, talk to your house,
[01:09:28.880 --> 01:09:32.160]   talk to your car.
[01:09:32.160 --> 01:09:34.120]   OK, so then the other side to this,
[01:09:34.120 --> 01:09:37.280]   because this is only half the problem.
[01:09:37.280 --> 01:09:39.960]   Half the battle, half the problem, half the setup.
[01:09:39.960 --> 01:09:43.680]   Today-- no, yesterday, Google basically detailed
[01:09:43.680 --> 01:09:47.200]   its plans for Weave and what used to be called Brillo,
[01:09:47.200 --> 01:09:49.040]   and now they're calling-- oh my god, what are they doing?
[01:09:49.040 --> 01:09:50.600]   Android Things.
[01:09:50.600 --> 01:09:51.600]   Thank you.
[01:09:51.600 --> 01:09:54.040]   My brain is not--
[01:09:54.040 --> 01:10:00.000]   Right, so Things is the OS kind of vision for individual devices.
[01:10:00.000 --> 01:10:02.200]   And Weave is a communications protocol
[01:10:02.200 --> 01:10:04.920]   that's going to basically-- Google calls it traits,
[01:10:04.920 --> 01:10:08.080]   but it's like, this is what a light bulb can do.
[01:10:08.080 --> 01:10:09.680]   This is a light bulb that you can turn on,
[01:10:09.680 --> 01:10:11.440]   it can turn off, there's the colors, blah, blah, blah.
[01:10:11.440 --> 01:10:13.120]   So everything that speaks Weave now
[01:10:13.120 --> 01:10:14.520]   knows what a light bulb does.
[01:10:14.520 --> 01:10:17.600]   I'm so glad you're here, because I had no idea
[01:10:17.600 --> 01:10:19.000]   what they were talking about here.
[01:10:19.000 --> 01:10:22.320]   And I was thinking to myself, Stacey will understand this.
[01:10:22.320 --> 01:10:23.560]   I will.
[01:10:23.560 --> 01:10:27.360]   So what's exciting there is Google Home supports Weave.
[01:10:27.360 --> 01:10:30.120]   And Belkin-- OK, here we go.
[01:10:30.120 --> 01:10:35.000]   Belkin, Honeywell, Wink, first alert,
[01:10:35.000 --> 01:10:38.480]   and a bunch of other companies are also supporting Weave
[01:10:38.480 --> 01:10:40.840]   and their products, which means soon those things
[01:10:40.840 --> 01:10:42.480]   will work with Google Home.
[01:10:42.480 --> 01:10:43.880]   Weave was already said that they're
[01:10:43.880 --> 01:10:45.920]   going to put out something-- I talked to Wink,
[01:10:45.920 --> 01:10:47.280]   and they're going to put out something.
[01:10:47.280 --> 01:10:49.160]   I don't have a time frame on that one, though.
[01:10:49.160 --> 01:10:51.320]   So we're about to see a lot more things
[01:10:51.320 --> 01:10:54.600]   to Weave integrations with Google Home.
[01:10:54.600 --> 01:10:56.560]   And then they're also, for those of you guys who've
[01:10:56.560 --> 01:10:59.920]   been following this, Nest had its own version of Weave.
[01:10:59.920 --> 01:11:01.480]   That was called Nest Weave.
[01:11:01.480 --> 01:11:03.560]   And they're going to finally integrate those two things,
[01:11:03.560 --> 01:11:05.280]   so we don't have to think about that anymore.
[01:11:05.280 --> 01:11:05.680]   Good.
[01:11:05.680 --> 01:11:07.680]   Yay.
[01:11:07.680 --> 01:11:09.840]   Well, it makes sense for them to start consolidating
[01:11:09.840 --> 01:11:14.880]   and making a user facing product or having companies
[01:11:14.880 --> 01:11:17.200]   make user facing products.
[01:11:17.200 --> 01:11:17.880]   They saved our customers.
[01:11:17.880 --> 01:11:20.120]   Weave and Brillo two years ago.
[01:11:20.120 --> 01:11:20.360]   Yeah.
[01:11:20.360 --> 01:11:20.840]   They did.
[01:11:20.840 --> 01:11:22.240]   It was a lot easier.
[01:11:22.240 --> 01:11:23.960]   They didn't know what they were quite doing.
[01:11:23.960 --> 01:11:26.880]   And I will say-- and we talk about this on the podcast--
[01:11:26.880 --> 01:11:29.960]   to use Weave, Google's confirmed to me
[01:11:29.960 --> 01:11:33.960]   that you have to use the Weave server.
[01:11:33.960 --> 01:11:36.000]   So you have to use the Google Cloud, which means you're--
[01:11:36.000 --> 01:11:37.640]   if you want to do AWS--
[01:11:37.640 --> 01:11:38.480]   Aha.
[01:11:38.480 --> 01:11:40.240]   And you know why that is?
[01:11:40.240 --> 01:11:40.760]   No.
[01:11:40.760 --> 01:11:41.760]   Yeah.
[01:11:41.760 --> 01:11:43.600]   Yeah, they're doing it for security, AKA.
[01:11:43.600 --> 01:11:46.400]   We want a database of everything you say.
[01:11:46.400 --> 01:11:47.600]   That is the other thing.
[01:11:47.600 --> 01:11:48.040]   Yes.
[01:11:48.040 --> 01:11:49.880]   Yeah, it's for security.
[01:11:49.880 --> 01:11:52.800]   Security is now becoming the word that people use.
[01:11:52.800 --> 01:11:55.800]   When they asked Nintendo-- when they asked me a motto
[01:11:55.800 --> 01:11:59.000]   in Nintendo-- why you could only play the new Mario Run game,
[01:11:59.000 --> 01:12:01.520]   which comes out tomorrow, online.
[01:12:01.520 --> 01:12:03.360]   There's no offline play.
[01:12:03.360 --> 01:12:04.880]   He said security.
[01:12:04.880 --> 01:12:08.680]   And credit to the interviewer at Mashable, who said,
[01:12:08.680 --> 01:12:10.880]   by security, you mean anti-piracy.
[01:12:10.880 --> 01:12:11.720]   You're in.
[01:12:11.720 --> 01:12:12.720]   Yeah.
[01:12:12.720 --> 01:12:13.640]   And he said--
[01:12:13.640 --> 01:12:16.800]   but also credit to Shigeru, who said, yeah.
[01:12:16.800 --> 01:12:18.160]   That's what I mean.
[01:12:18.160 --> 01:12:20.960]   He did three paragraphs on security--
[01:12:20.960 --> 01:12:22.640]   and really, he wasn't what he meant as anti-piracy.
[01:12:22.640 --> 01:12:24.760]   And of course, when Google says security,
[01:12:24.760 --> 01:12:25.840]   they don't mean anti-piracy.
[01:12:25.840 --> 01:12:28.120]   They mean so we can collect all the data.
[01:12:28.120 --> 01:12:29.840]   Well, they mean so they collect all the data,
[01:12:29.840 --> 01:12:31.440]   but they also need to understand--
[01:12:31.440 --> 01:12:33.160]   there's a huge fragmentation problem.
[01:12:33.160 --> 01:12:36.240]   Oh, there's no reason for them to collect all the data.
[01:12:36.240 --> 01:12:37.640]   I'm not saying that.
[01:12:37.640 --> 01:12:39.680]   It's not just not collecting-- it's not just
[01:12:39.680 --> 01:12:40.800]   collecting the data, though.
[01:12:40.800 --> 01:12:43.960]   It's also being able to offer assurances
[01:12:43.960 --> 01:12:50.680]   on to understand what's working with Weave and what isn't.
[01:12:50.680 --> 01:12:53.480]   So you can get all that log data from these devices,
[01:12:53.480 --> 01:12:56.200]   because right now troubleshooting a connected device--
[01:12:56.200 --> 01:12:56.880]   Right.
[01:12:56.880 --> 01:12:58.360]   Oh.
[01:12:58.360 --> 01:12:59.880]   You think troubleshooting network--
[01:12:59.880 --> 01:13:01.400]   That's how I think a lot of people don't know.
[01:13:01.400 --> 01:13:03.240]   Actually, we were talking about this on Windows Weekly
[01:13:03.240 --> 01:13:08.400]   a minute ago, because Microsoft has been talking about a cartana
[01:13:08.400 --> 01:13:11.880]   platform, and it's unclear that initially they implied
[01:13:11.880 --> 01:13:15.480]   that you needed to have a device with a screen to use it.
[01:13:15.480 --> 01:13:15.920]   And Paul was saying--
[01:13:15.920 --> 01:13:16.880]   Oh, but you don't.
[01:13:16.880 --> 01:13:17.720]   Right.
[01:13:17.720 --> 01:13:19.720]   Well, it turns out maybe you don't.
[01:13:19.720 --> 01:13:20.760]   But it was unclear.
[01:13:20.760 --> 01:13:22.280]   And Paul was saying, well, that's just dumb,
[01:13:22.280 --> 01:13:23.960]   because the echo doesn't need a screen.
[01:13:23.960 --> 01:13:26.360]   But the echo really-- in fact, as we know,
[01:13:26.360 --> 01:13:29.480]   Amazon's doing an echo with a screen for the kitchen.
[01:13:29.480 --> 01:13:31.080]   And the echo really does have a screen.
[01:13:31.080 --> 01:13:32.600]   If you have a Kindle Fire tablet,
[01:13:32.600 --> 01:13:36.800]   or you're running the Echo app, you can see what you said.
[01:13:36.800 --> 01:13:40.040]   You can confirm that echo-- you can help echo learn.
[01:13:40.040 --> 01:13:42.440]   If you see the music that's now playing,
[01:13:42.440 --> 01:13:43.520]   you can see a lot of stuff.
[01:13:43.520 --> 01:13:45.440]   So there is a secondary screen.
[01:13:45.440 --> 01:13:49.080]   It's just not always on, but you have it.
[01:13:49.080 --> 01:13:50.680]   And I think there's something to be said for that.
[01:13:50.680 --> 01:13:52.600]   Anyway, we're going to see Cortana.
[01:13:52.600 --> 01:13:55.080]   I still think Apple is not out of this game.
[01:13:55.080 --> 01:13:55.580]   And--
[01:13:55.580 --> 01:13:57.080]   I don't think they're out of it, but they're--
[01:13:57.080 --> 01:13:58.280]   They're behind.
[01:13:58.280 --> 01:14:00.960]   They're vision for HomeKit.
[01:14:00.960 --> 01:14:03.240]   And this is something worth thinking about.
[01:14:03.240 --> 01:14:06.760]   We are very excited about this, because we are super nerds.
[01:14:06.760 --> 01:14:08.960]   And when you talk to other people,
[01:14:08.960 --> 01:14:10.360]   they're not thinking about SDKs.
[01:14:10.360 --> 01:14:11.160]   They're not thinking about that.
[01:14:11.160 --> 01:14:12.360]   They're thinking about the experience.
[01:14:12.360 --> 01:14:13.600]   And Apple's like, you know what?
[01:14:13.600 --> 01:14:15.360]   Everyone pays attention to us.
[01:14:15.360 --> 01:14:18.800]   Let's not blur what's happening with Tech Talk.
[01:14:18.800 --> 01:14:21.360]   Let's just get it one and offer it.
[01:14:21.360 --> 01:14:22.240]   They don't do it in public.
[01:14:22.240 --> 01:14:23.480]   They don't pre-announce.
[01:14:23.480 --> 01:14:25.720]   They just kind of do-- they do it.
[01:14:25.720 --> 01:14:28.320]   And it'll all become full-blown.
[01:14:28.320 --> 01:14:30.120]   That being said, they are behind.
[01:14:30.120 --> 01:14:31.080]   I think they're--
[01:14:31.080 --> 01:14:31.960]   Partners are kind of like--
[01:14:31.960 --> 01:14:32.640]   Let's face it, though.
[01:14:32.640 --> 01:14:33.480]   Google was behind.
[01:14:33.480 --> 01:14:35.680]   Echo's two years older.
[01:14:35.680 --> 01:14:38.200]   And they're catching up pretty quick.
[01:14:38.200 --> 01:14:39.120]   Well, yeah.
[01:14:39.120 --> 01:14:41.960]   Once you've built the kind of paradigm, I guess,
[01:14:41.960 --> 01:14:43.880]   which is kind of what Amazon did,
[01:14:43.880 --> 01:14:46.520]   it's easy to come in and be like, oh, let us improve upon this.
[01:14:46.520 --> 01:14:48.720]   Yeah.
[01:14:48.720 --> 01:14:50.600]   Google, we now understand what Google's
[01:14:50.600 --> 01:14:51.720]   doing with a self-driving car.
[01:14:51.720 --> 01:14:55.600]   It's not going to build a self-driving car.
[01:14:55.600 --> 01:14:58.840]   It's going from being a moonshot to an independent alphabet
[01:14:58.840 --> 01:15:00.440]   company called--
[01:15:00.440 --> 01:15:01.480]   I kind of like this name--
[01:15:01.480 --> 01:15:02.080]   Waymo.
[01:15:02.080 --> 01:15:02.960]   I kind of like it, too.
[01:15:02.960 --> 01:15:04.440]   Waymo.
[01:15:04.440 --> 01:15:05.440]   I like it.
[01:15:05.440 --> 01:15:06.280]   Waymo.
[01:15:06.280 --> 01:15:07.840]   Waymo vehicles.
[01:15:07.840 --> 01:15:09.840]   It will not be a vehicle without steering wheel
[01:15:09.840 --> 01:15:11.600]   and gas and brake.
[01:15:11.600 --> 01:15:16.200]   It will be a platform they sell to other car manufacturers.
[01:15:16.200 --> 01:15:17.360]   So they won't make cars?
[01:15:17.360 --> 01:15:17.920]   Is that--
[01:15:17.920 --> 01:15:18.480]   I could put them--
[01:15:18.480 --> 01:15:19.000]   --with their saying.
[01:15:19.000 --> 01:15:19.520]   --of speculation.
[01:15:19.520 --> 01:15:20.280]   That's what they're saying.
[01:15:20.280 --> 01:15:25.440]   Yeah, I think that's-- well, all of this is speculation,
[01:15:25.440 --> 01:15:26.720]   except for the Waymo part.
[01:15:26.720 --> 01:15:28.160]   I was like, no, they confirmed Waymo.
[01:15:28.160 --> 01:15:28.600]   Yeah.
[01:15:28.600 --> 01:15:31.640]   John Craftchick, who is the new CEO,
[01:15:31.640 --> 01:15:34.520]   told reporters at a press event yesterday
[01:15:34.520 --> 01:15:36.560]   that Waymo is a company with a mission
[01:15:36.560 --> 01:15:38.680]   to make it safe and easy for people and things
[01:15:38.680 --> 01:15:40.480]   to move around.
[01:15:40.480 --> 01:15:42.040]   What you're feeling-- this is all a quote--
[01:15:42.040 --> 01:15:45.080]   what you're feeling from the Waymo team is confidence
[01:15:45.080 --> 01:15:47.520]   that we can bring this technology to people.
[01:15:47.520 --> 01:15:49.000]   We're getting closer, getting ready.
[01:15:49.000 --> 01:15:52.840]   It's time to tell the world about that.
[01:15:52.840 --> 01:15:54.960]   But they-- and he does say our next step as Waymo
[01:15:54.960 --> 01:15:57.040]   will be to let people use our vehicles to do everything,
[01:15:57.040 --> 01:15:58.200]   things like run errands.
[01:15:58.200 --> 01:16:00.840]   So it sounds like-- but I think that they mentioned
[01:16:00.840 --> 01:16:05.360]   that they're partnering with Chrysler, right, Fiat, Chrysler.
[01:16:05.360 --> 01:16:10.200]   And in fact, it's not clear.
[01:16:10.200 --> 01:16:12.960]   I think you're right, Jeff, that this is speculation.
[01:16:12.960 --> 01:16:16.520]   Yeah, I couldn't get a definitive.
[01:16:16.520 --> 01:16:18.080]   There's also the rumors about--
[01:16:18.080 --> 01:16:20.680]   or rumors about-- they're going to work with Chrysler
[01:16:20.680 --> 01:16:21.440]   on the thing.
[01:16:21.440 --> 01:16:21.920]   Right.
[01:16:21.920 --> 01:16:23.800]   The real-- they're going to offer.
[01:16:23.800 --> 01:16:24.160]   You know what?
[01:16:24.160 --> 01:16:26.680]   Let me log into my account, because this is, of course,
[01:16:26.680 --> 01:16:30.400]   Amira Friday, who's got the great connections at Google,
[01:16:30.400 --> 01:16:32.120]   writing for the information.
[01:16:32.120 --> 01:16:33.360]   And I pay money for this.
[01:16:33.360 --> 01:16:34.280]   So let's--
[01:16:34.280 --> 01:16:34.960]   Oh, me too.
[01:16:34.960 --> 01:16:38.040]   Yeah, it's well worth it.
[01:16:38.040 --> 01:16:41.520]   They've been breaking even more stories than ever, frankly.
[01:16:41.520 --> 01:16:43.120]   Yeah, they're doing a great job.
[01:16:43.120 --> 01:16:45.040]   They have a kind of fun business model, too.
[01:16:45.040 --> 01:16:45.760]   Yeah.
[01:16:45.760 --> 01:16:48.240]   400 bucks a year, that's a good business model.
[01:16:48.240 --> 01:16:50.360]   I got it on half off just a couple weeks ago.
[01:16:50.360 --> 01:16:51.320]   Whoa.
[01:16:51.320 --> 01:16:52.320]   Yeah.
[01:16:52.320 --> 01:16:53.520]   Whoa.
[01:16:53.520 --> 01:16:55.080]   Too late for all of you.
[01:16:55.080 --> 01:16:58.000]   Jessica.
[01:16:58.000 --> 01:16:59.440]   You know, this is all part of that.
[01:16:59.440 --> 01:17:00.920]   We've talked about it before.
[01:17:00.920 --> 01:17:05.920]   The new CFO Ruth Porat belt tightening.
[01:17:05.920 --> 01:17:08.280]   And spinning it out of the moon launch
[01:17:08.280 --> 01:17:13.320]   means now it's a company that has to have performance.
[01:17:13.320 --> 01:17:15.240]   They're going to have to do profit loss statements,
[01:17:15.240 --> 01:17:16.880]   and so forth.
[01:17:16.880 --> 01:17:22.120]   So chauffeur.
[01:17:22.120 --> 01:17:23.080]   What is chauffeur?
[01:17:23.080 --> 01:17:24.640]   The broader strategic change allowed
[01:17:24.640 --> 01:17:28.040]   the leaders of chauffeur as the self-driving unit
[01:17:28.040 --> 01:17:30.480]   is known at the company to consider
[01:17:30.480 --> 01:17:32.440]   launching a commercial ride sharing service.
[01:17:32.440 --> 01:17:35.960]   This is a mirror at the information.
[01:17:35.960 --> 01:17:39.400]   With autonomous vehicles by the end of next year.
[01:17:39.400 --> 01:17:42.240]   Like a year from now, there's a lot of rushing going on here.
[01:17:42.240 --> 01:17:45.240]   I mean, we've supposedly--
[01:17:45.240 --> 01:17:47.960]   right, Uber is offering autonomous rides now
[01:17:47.960 --> 01:17:49.320]   in Cleveland and San Francisco.
[01:17:49.320 --> 01:17:49.840]   Right.
[01:17:49.840 --> 01:17:54.560]   But they're still a driver, so you can't really tell if you're--
[01:17:54.560 --> 01:17:56.680]   I mean, that would be like me saying, getting the car,
[01:17:56.680 --> 01:17:59.120]   Jeff, and I'm going to let my Tesla drive us
[01:17:59.120 --> 01:18:02.200]   over the Golden Gate Bridge.
[01:18:02.200 --> 01:18:05.200]   That maybe feel better or worse.
[01:18:05.200 --> 01:18:07.080]   Should make you feel better.
[01:18:07.080 --> 01:18:09.760]   Whether chauffeur can launch-- this is a mirror Friday again.
[01:18:09.760 --> 01:18:12.600]   Whether chauffeur can launch what is called a robo-taxi service
[01:18:12.600 --> 01:18:16.000]   in that time frame depends on the performance of a new self-driving
[01:18:16.000 --> 01:18:18.040]   car prototype manufactured for Google
[01:18:18.040 --> 01:18:21.360]   by Fiat Chrysler.
[01:18:21.360 --> 01:18:23.560]   The first of the prototypes are due to be in chauffeur's hands
[01:18:23.560 --> 01:18:25.960]   by the end of this year.
[01:18:25.960 --> 01:18:29.360]   And then they have a deal to increase production
[01:18:29.360 --> 01:18:34.800]   with an electric hybrid, the Pacifica minivan, which
[01:18:34.800 --> 01:18:37.480]   retails for more than $42,000 without the extra Google
[01:18:37.480 --> 01:18:41.520]   hardware and software into the hundreds of vehicles
[01:18:41.520 --> 01:18:43.600]   car could then be used in the new service.
[01:18:43.600 --> 01:18:47.080]   So maybe, boy, 2017.
[01:18:47.080 --> 01:18:49.120]   This is Russian along, isn't it?
[01:18:49.120 --> 01:18:49.960]   Yeah.
[01:18:49.960 --> 01:18:50.800]   Yeah.
[01:18:50.800 --> 01:18:51.880]   Because I think we were all thinking,
[01:18:51.880 --> 01:18:54.000]   oh, it's going to be 20, 25, 20, 30.
[01:18:54.000 --> 01:18:55.000]   This is way off of that.
[01:18:55.000 --> 01:18:56.440]   They're pushing this.
[01:18:56.440 --> 01:18:59.240]   Well, they said, I mean, everybody's committed to 2020,
[01:18:59.240 --> 01:19:00.840]   I mean, for what it's worth.
[01:19:00.840 --> 01:19:02.560]   And that's coming up.
[01:19:02.560 --> 01:19:05.680]   Sergey Brin, who's had a hand in chauffeur from nearly the beginning,
[01:19:05.680 --> 01:19:07.200]   had been hoping the unit would continue
[01:19:07.200 --> 01:19:10.520]   to work on a system for vehicles without a wheel,
[01:19:10.520 --> 01:19:13.520]   according to Amir's sources, the self-driving car units
[01:19:13.520 --> 01:19:16.080]   former chief, Chris Ermson had also
[01:19:16.080 --> 01:19:17.160]   wanted to pursue this approach.
[01:19:17.160 --> 01:19:21.040]   He left this summer less than a year after Mr. Page hired Mr.
[01:19:21.040 --> 01:19:24.400]   Craft Chick to lead chauffeur and bring much needed structure
[01:19:24.400 --> 01:19:26.320]   and urgency to the program.
[01:19:26.320 --> 01:19:26.840]   So--
[01:19:26.840 --> 01:19:27.720]   Without a wheel?
[01:19:27.720 --> 01:19:28.680]   Like a steering wheel?
[01:19:28.680 --> 01:19:29.680]   Yeah, remember the Google--
[01:19:29.680 --> 01:19:30.240]   Oh, OK.
[01:19:30.240 --> 01:19:33.120]   The little Google card in there-- yeah, no, it has four wheels.
[01:19:33.120 --> 01:19:33.960]   That's-- sorry.
[01:19:33.960 --> 01:19:35.040]   That's where I was like, wait.
[01:19:35.040 --> 01:19:39.160]   Yeah, but this car has no effect.
[01:19:39.160 --> 01:19:41.000]   I haven't written it, but I know people will have it.
[01:19:41.000 --> 01:19:43.200]   And say it's a very uncanny feeling,
[01:19:43.200 --> 01:19:45.280]   because you just get in and it drives off.
[01:19:45.280 --> 01:19:46.600]   But it's like Disneyland, right?
[01:19:46.600 --> 01:19:47.880]   It's like a little thing at Disneyland.
[01:19:47.880 --> 01:19:48.240]   It doesn't have--
[01:19:48.240 --> 01:19:49.920]   Which, by the way, is why voice recognition
[01:19:49.920 --> 01:19:52.200]   and understanding your instructions better be damned
[01:19:52.200 --> 01:19:53.200]   would better be good.
[01:19:53.200 --> 01:19:54.200]   Stop.
[01:19:54.200 --> 01:19:59.040]   You'll end up in a container and on some island somewhere.
[01:19:59.040 --> 01:20:00.520]   What was that show that did that?
[01:20:00.520 --> 01:20:01.560]   That's Silicon Valley.
[01:20:01.560 --> 01:20:02.280]   Oh, that's right.
[01:20:02.280 --> 01:20:03.840]   That's right.
[01:20:03.840 --> 01:20:06.600]   Thank you for recognizing the--
[01:20:06.600 --> 01:20:08.480]   I couldn't handle that show.
[01:20:08.480 --> 01:20:09.600]   You didn't like it?
[01:20:09.600 --> 01:20:10.120]   Ah.
[01:20:10.120 --> 01:20:11.600]   It was too close to life.
[01:20:11.600 --> 01:20:13.000]   I was like, oh, this is not funny.
[01:20:13.000 --> 01:20:13.640]   This is terrible.
[01:20:13.640 --> 01:20:14.960]   That's what Bill Atkinson said.
[01:20:14.960 --> 01:20:16.080]   He said, I can't watch it.
[01:20:16.080 --> 01:20:17.560]   It's too close to the real thing.
[01:20:17.560 --> 01:20:18.720]   I said, I just--
[01:20:18.720 --> 01:20:19.560]   I don't find it funny.
[01:20:19.560 --> 01:20:20.880]   I find it depressing.
[01:20:20.880 --> 01:20:22.440]   Yeah.
[01:20:22.440 --> 01:20:24.040]   Well, I guess I'm just too distant from it.
[01:20:24.040 --> 01:20:25.840]   I don't know.
[01:20:25.840 --> 01:20:27.240]   All the way out there in Petaluma?
[01:20:27.240 --> 01:20:29.200]   Yeah.
[01:20:29.200 --> 01:20:32.520]   And I have a car that goes like--
[01:20:32.520 --> 01:20:35.080]   doors like that.
[01:20:35.080 --> 01:20:37.480]   Uber CEO Travis Kalanek got a test
[01:20:37.480 --> 01:20:39.560]   right on one of Google's Lexus self-driving prototypes
[01:20:39.560 --> 01:20:41.120]   in the fall of 2014.
[01:20:41.120 --> 01:20:43.560]   Within a few months, Kalanek had decided
[01:20:43.560 --> 01:20:45.360]   to develop the technology at Uber
[01:20:45.360 --> 01:20:48.200]   and made a huge acquisition of the team
[01:20:48.200 --> 01:20:50.440]   from Carnegie Mellon.
[01:20:50.440 --> 01:20:50.920]   And now--
[01:20:50.920 --> 01:20:53.240]   And they're picking people up in San Francisco now.
[01:20:53.240 --> 01:20:55.000]   Right.
[01:20:55.000 --> 01:20:56.800]   There is a human driver.
[01:20:56.800 --> 01:20:58.280]   Yes.
[01:20:58.280 --> 01:20:58.680]   I'm sorry.
[01:20:58.680 --> 01:20:59.680]   I just have to interject.
[01:20:59.680 --> 01:21:02.320]   I'm looking at Twitter feed to see what's going on with the event.
[01:21:02.320 --> 01:21:02.920]   Are they--
[01:21:02.920 --> 01:21:06.720]   Petal put up that picture of the Sad Jeff Bezos and said,
[01:21:06.720 --> 01:21:09.880]   this is Amazon's new 404 page.
[01:21:09.880 --> 01:21:11.600]   Sad Jeff.
[01:21:11.600 --> 01:21:13.520]   Sad Jeff Bezos.
[01:21:13.520 --> 01:21:15.520]   So are they still in there, though?
[01:21:15.520 --> 01:21:16.600]   I'm guessing so.
[01:21:16.600 --> 01:21:18.000]   I can't believe they would be.
[01:21:18.000 --> 01:21:19.000]   They can't be.
[01:21:19.000 --> 01:21:21.200]   But I'm not saying anybody come out.
[01:21:21.200 --> 01:21:23.280]   Hasn't Trump gone off to do his steak dinners yet?
[01:21:23.280 --> 01:21:24.280]   Come on.
[01:21:24.280 --> 01:21:24.800]   Yeah.
[01:21:24.800 --> 01:21:26.720]   It's like 6 o'clock.
[01:21:26.720 --> 01:21:29.440]   He does like the early bird special I hear.
[01:21:29.440 --> 01:21:30.720]   Hey, you know what?
[01:21:30.720 --> 01:21:31.120]   No, teasing.
[01:21:31.120 --> 01:21:32.920]   I'm getting hungry, and it's only 5.
[01:21:32.920 --> 01:21:34.200]   I'm teasing.
[01:21:34.200 --> 01:21:34.880]   I joke.
[01:21:34.880 --> 01:21:35.720]   I'm a kidder.
[01:21:35.720 --> 01:21:39.180]   All right.
[01:21:39.180 --> 01:21:39.680]   A toker.
[01:21:39.680 --> 01:21:41.120]   A toker and a midnight smoker.
[01:21:41.120 --> 01:21:42.760]   A head smoker.
[01:21:42.760 --> 01:21:43.480]   Let's see here.
[01:21:43.480 --> 01:21:46.160]   Looking at the Twitter feed.
[01:21:46.160 --> 01:21:48.560]   Yeah, I'm trying to see here.
[01:21:48.560 --> 01:21:53.680]   OK, I just want to say one more thing about Twitter.
[01:21:53.680 --> 01:21:55.320]   The other problem I have with Twitter
[01:21:55.320 --> 01:21:58.640]   is all it takes is a few people to tweet about something,
[01:21:58.640 --> 01:22:02.680]   and it's become a story as if this--
[01:22:02.680 --> 01:22:05.800]   like, the world is rising up in arms
[01:22:05.800 --> 01:22:08.200]   because 10 people tweet something.
[01:22:08.200 --> 01:22:09.480]   And everybody acts that way.
[01:22:09.480 --> 01:22:11.000]   And I don't think that's the case.
[01:22:11.000 --> 01:22:11.600]   Here's the picture.
[01:22:11.600 --> 01:22:13.280]   So that's also a benefit of Twitter, though,
[01:22:13.280 --> 01:22:15.680]   because you can see things that otherwise the media wouldn't
[01:22:15.680 --> 01:22:20.000]   let you see that are arguably worth knowing about.
[01:22:20.000 --> 01:22:22.160]   Jeff does kind of have a vacant stare.
[01:22:22.160 --> 01:22:22.660]   Yeah.
[01:22:22.660 --> 01:22:24.600]   [LAUGHTER]
[01:22:24.600 --> 01:22:25.680]   It's a perfect 404.
[01:22:25.680 --> 01:22:28.040]   It's a great job.
[01:22:28.040 --> 01:22:29.040]   I'm lost.
[01:22:29.040 --> 01:22:31.400]   I don't know where I am.
[01:22:31.400 --> 01:22:33.880]   But again, you can freeze frame anything.
[01:22:33.880 --> 01:22:37.320]   I know, but it's not really fair.
[01:22:37.320 --> 01:22:38.360]   Here's some more.
[01:22:38.360 --> 01:22:39.640]   Here's Elon getting into it.
[01:22:39.640 --> 01:22:42.320]   Look at-- see, I'm telling you, Elon's saying stuff,
[01:22:42.320 --> 01:22:43.640]   and Donald's listening.
[01:22:43.640 --> 01:22:44.640]   Look, see, they're talking.
[01:22:44.640 --> 01:22:49.600]   And then Tim's going, how soon before I get out of here?
[01:22:49.600 --> 01:22:51.520]   Is that Trump water?
[01:22:51.520 --> 01:22:52.560]   It is.
[01:22:52.560 --> 01:22:53.080]   OK.
[01:22:53.080 --> 01:22:54.200]   Oh, it's just curious.
[01:22:54.200 --> 01:22:54.680]   Good catch.
[01:22:54.680 --> 01:22:58.360]   OMG.
[01:22:58.360 --> 01:23:01.560]   Notice no one's drinking it.
[01:23:01.560 --> 01:23:02.880]   The Oracle CEO's got a--
[01:23:02.880 --> 01:23:06.360]   Oh, Safra opened hers.
[01:23:06.360 --> 01:23:08.080]   I mean, maybe they just--
[01:23:08.080 --> 01:23:10.240]   I mean, you'd take it as a souvenir?
[01:23:10.240 --> 01:23:11.360]   I would.
[01:23:11.360 --> 01:23:12.560]   Well, so they didn't have--
[01:23:12.560 --> 01:23:14.240]   Did they have glasses all of them in front of them?
[01:23:14.240 --> 01:23:15.440]   Yeah, they have glasses.
[01:23:15.440 --> 01:23:15.920]   They don't--
[01:23:15.920 --> 01:23:19.840]   But she clearly Safra just drank it right out of the bottle.
[01:23:19.840 --> 01:23:20.680]   Well, yeah.
[01:23:20.680 --> 01:23:21.960]   She was selling red.
[01:23:21.960 --> 01:23:24.560]   Look how-- look at and raptured she is with Elon.
[01:23:24.560 --> 01:23:26.360]   Yeah.
[01:23:26.360 --> 01:23:28.000]   I think Elon's very charismatic.
[01:23:28.000 --> 01:23:30.880]   I wouldn't be surprised if--
[01:23:30.880 --> 01:23:34.200]   but Tim just seems like--
[01:23:34.200 --> 01:23:37.720]   what is going on there?
[01:23:37.720 --> 01:23:39.680]   What is going on?
[01:23:39.680 --> 01:23:41.320]   But Elon's buddies with Teal, right?
[01:23:41.320 --> 01:23:43.480]   They both-- they were together starting PayPal.
[01:23:43.480 --> 01:23:44.760]   I don't know if they're still friends,
[01:23:44.760 --> 01:23:47.400]   but they certainly know each other well.
[01:23:47.400 --> 01:23:48.320]   Here's Eric Schmidt.
[01:23:48.320 --> 01:23:51.760]   He's-- I think Eric's actually checking his Facebook feed.
[01:23:51.760 --> 01:23:56.760]   Larry seems happy.
[01:23:56.760 --> 01:23:59.400]   See, Jeff isn't completely vacant.
[01:23:59.400 --> 01:24:01.240]   They're all talking to Cheryl.
[01:24:01.240 --> 01:24:03.200]   It's kind of neat to see them all in the same room.
[01:24:03.200 --> 01:24:05.840]   I have to say.
[01:24:05.840 --> 01:24:07.320]   Tim is just a sour puss.
[01:24:07.320 --> 01:24:08.280]   He just does not--
[01:24:08.280 --> 01:24:09.640]   there is not one good picture--
[01:24:09.640 --> 01:24:11.360]   not one picture of Tim smiling.
[01:24:11.360 --> 01:24:13.600]   And you know what, if I were Tim, that's probably--
[01:24:13.600 --> 01:24:15.480]   what is that down with the PR people beforehand?
[01:24:15.480 --> 01:24:16.600]   I said, how do I survive this?
[01:24:16.600 --> 01:24:17.840]   Look unhappy.
[01:24:17.840 --> 01:24:19.280]   Yeah.
[01:24:19.280 --> 01:24:22.600]   Look grim.
[01:24:22.600 --> 01:24:24.200]   Interesting.
[01:24:24.200 --> 01:24:25.240]   It is reality showing.
[01:24:25.240 --> 01:24:26.000]   You know what?
[01:24:26.000 --> 01:24:28.440]   We're completely sucked into it, watching it.
[01:24:28.440 --> 01:24:32.880]   There's Safra.
[01:24:32.880 --> 01:24:34.600]   I think Al Gore's just standing in the lobby,
[01:24:34.600 --> 01:24:36.320]   waiting and hoping he'll be invited in.
[01:24:36.320 --> 01:24:37.400]   That looks like-- isn't that Gore?
[01:24:37.400 --> 01:24:37.900]   No.
[01:24:37.900 --> 01:24:41.380]   [LAUGHTER]
[01:24:41.380 --> 01:24:41.820]   All right.
[01:24:41.820 --> 01:24:50.300]   Zenny Gardan says, this is what you look like when you realize
[01:24:50.300 --> 01:24:52.380]   you'll be the first one in the room headed to the camps.
[01:24:52.380 --> 01:24:53.780]   Now, come on.
[01:24:53.780 --> 01:24:55.620]   Now, no one's going to be going.
[01:24:55.620 --> 01:25:02.140]   And I love that story about why Jack Dorsey wasn't invited,
[01:25:02.140 --> 01:25:04.060]   which is now, I think, the case.
[01:25:04.060 --> 01:25:06.580]   All right, still waiting for people exiting.
[01:25:06.580 --> 01:25:09.900]   We'll watch for that.
[01:25:09.900 --> 01:25:12.700]   They've all disappeared.
[01:25:12.700 --> 01:25:15.460]   Puff of smoke, a greasy black puck of puff of smoke.
[01:25:15.460 --> 01:25:19.420]   Let's see, what else?
[01:25:19.420 --> 01:25:21.340]   There's actually a lot of news this week.
[01:25:21.340 --> 01:25:22.340]   Yeah, there is.
[01:25:22.340 --> 01:25:25.380]   Google decided not to give the usual gifts every year.
[01:25:25.380 --> 01:25:28.140]   Google gives phones and Chromebooks and stuff
[01:25:28.140 --> 01:25:28.820]   to its employees.
[01:25:28.820 --> 01:25:30.580]   Instead, they're going to take that $30 million
[01:25:30.580 --> 01:25:31.940]   and give it to Charity.
[01:25:31.940 --> 01:25:32.420]   Nice.
[01:25:32.420 --> 01:25:34.100]   Just like I/O.
[01:25:34.100 --> 01:25:35.220]   Yeah, I think that's great.
[01:25:35.220 --> 01:25:38.020]   By the way, and the right thing to do in both cases.
[01:25:38.020 --> 01:25:38.780]   And incidentally--
[01:25:38.780 --> 01:25:39.940]   We do that for our wedding.
[01:25:39.940 --> 01:25:40.860]   Did you?
[01:25:40.860 --> 01:25:43.620]   You didn't give bridesmaids and--
[01:25:43.620 --> 01:25:46.740]   You did not get candy dalmons or a pack of cards with our name.
[01:25:46.740 --> 01:25:48.980]   You got a-- we donated to Make a Wish.
[01:25:48.980 --> 01:25:50.300]   I was going to do Planned Parenthood,
[01:25:50.300 --> 01:25:52.180]   but my in-laws were against that.
[01:25:52.180 --> 01:25:54.060]   You shouldn't do it, and I'll tell you why,
[01:25:54.060 --> 01:25:58.740]   because it implies that you're planning parenthood.
[01:25:58.740 --> 01:25:59.740]   Yes.
[01:25:59.740 --> 01:26:00.260]   Or not.
[01:26:00.260 --> 01:26:01.980]   But sick kids, everyone could get behind.
[01:26:01.980 --> 01:26:03.940]   Everybody get behind sick kids.
[01:26:03.940 --> 01:26:05.820]   But incidentally, this is the other thing you do,
[01:26:05.820 --> 01:26:07.620]   besides go to those meetings, which I think you do.
[01:26:07.620 --> 01:26:10.900]   Google also is hiring lobbyists.
[01:26:10.900 --> 01:26:14.820]   And in this case, hiring Republican lobbyists
[01:26:14.820 --> 01:26:18.460]   to get into the conversation.
[01:26:18.460 --> 01:26:19.180]   You don't want--
[01:26:19.180 --> 01:26:22.180]   Facebook has always had Republican lobbyists there,
[01:26:22.180 --> 01:26:24.100]   so Google's getting--
[01:26:24.100 --> 01:26:26.860]   Any good business, including, by the way,
[01:26:26.860 --> 01:26:28.380]   I'll point out, the Trump Organization
[01:26:28.380 --> 01:26:31.900]   donates to both parties and wants to have a seat at the table,
[01:26:31.900 --> 01:26:34.140]   no matter who is in the White House,
[01:26:34.140 --> 01:26:36.300]   because you have to do business in that country.
[01:26:36.300 --> 01:26:37.860]   That's part of the deal.
[01:26:37.860 --> 01:26:40.060]   I think-- I haven't really said this to my bosses yet here,
[01:26:40.060 --> 01:26:42.580]   but I think that as a school, we
[01:26:42.580 --> 01:26:45.820]   should be recruiting conservative students.
[01:26:45.820 --> 01:26:46.900]   Well, hell yeah.
[01:26:46.900 --> 01:26:48.740]   Now, it's not going to be a very comfortable position for them.
[01:26:48.740 --> 01:26:50.820]   We have to make a safe space for them, so to speak.
[01:26:50.820 --> 01:26:51.980]   Well, it's a diversity program.
[01:26:51.980 --> 01:26:54.780]   Well, it's also just it's good for all the other students
[01:26:54.780 --> 01:26:57.020]   to be able to have discussions.
[01:26:57.020 --> 01:26:58.740]   Absolutely.
[01:26:58.740 --> 01:27:02.900]   One of my intro to journalism class at UT,
[01:27:02.900 --> 01:27:09.420]   the guy who did some hyper-Christian magazine
[01:27:09.420 --> 01:27:11.700]   was our journalism professor.
[01:27:11.700 --> 01:27:15.820]   And he was-- I mean, this was all these mostly liberals
[01:27:15.820 --> 01:27:18.100]   who go into the media, like, I'm going to change the world
[01:27:18.100 --> 01:27:19.620]   and do good in society.
[01:27:19.620 --> 01:27:23.300]   And he's like this hardcore Christian conservative.
[01:27:23.300 --> 01:27:25.580]   And we were just like, whoa.
[01:27:25.580 --> 01:27:27.140]   It's good for you.
[01:27:27.140 --> 01:27:27.740]   It was.
[01:27:27.740 --> 01:27:28.140]   It's good for you.
[01:27:28.140 --> 01:27:28.640]   Yeah.
[01:27:28.640 --> 01:27:29.140]   Yeah, it is.
[01:27:29.140 --> 01:27:35.060]   It's a great story in The Washington Post
[01:27:35.060 --> 01:27:39.780]   about young children, like five and six-year-olds, who,
[01:27:39.780 --> 01:27:44.980]   even when cameras aren't on them, are doing YouTube videos.
[01:27:44.980 --> 01:27:45.380]   So this is--
[01:27:45.380 --> 01:27:48.380]   So I feel like this is not just YouTube,
[01:27:48.380 --> 01:27:50.620]   but it is also a small part of the population.
[01:27:50.620 --> 01:27:55.300]   But I will say, like, my younger children,
[01:27:55.300 --> 01:27:57.380]   all they know is like FaceTime for interacting
[01:27:57.380 --> 01:27:58.260]   and that sort of thing.
[01:27:58.260 --> 01:28:00.820]   So I can see how they're acting.
[01:28:00.820 --> 01:28:03.700]   The lead is this kid Max, who's six years old
[01:28:03.700 --> 01:28:08.500]   and has learned how to flip bottles so they land upright upside
[01:28:08.500 --> 01:28:09.420]   down.
[01:28:09.420 --> 01:28:10.700]   And he's doing it.
[01:28:10.700 --> 01:28:13.140]   And this is really wild.
[01:28:13.140 --> 01:28:16.860]   He shouts, dude, it landed waves his arms.
[01:28:16.860 --> 01:28:19.300]   He knows just how to overreact to get his audience excited,
[01:28:19.300 --> 01:28:22.540]   which makes them click thumbs up and comment and subscribe.
[01:28:22.540 --> 01:28:22.980]   He jumps.
[01:28:22.980 --> 01:28:23.660]   He wiggles his hips.
[01:28:23.660 --> 01:28:25.380]   He does the dab.
[01:28:25.380 --> 01:28:26.020]   Oh my gosh.
[01:28:26.020 --> 01:28:26.540]   He yells.
[01:28:26.540 --> 01:28:27.180]   It's a kid playing.
[01:28:27.180 --> 01:28:30.140]   This is insane, but no one is watching.
[01:28:30.140 --> 01:28:30.980]   Play.
[01:28:30.980 --> 01:28:32.260]   That's what his kids do.
[01:28:32.260 --> 01:28:34.300]   He's imitating what he sees on the tube.
[01:28:34.300 --> 01:28:36.100]   Well, but where is he?
[01:28:36.100 --> 01:28:37.700]   This is techno panic.
[01:28:37.700 --> 01:28:38.420]   It just drives me--
[01:28:38.420 --> 01:28:38.940]   OK.
[01:28:38.940 --> 01:28:40.700]   --nothing to worry about.
[01:28:40.700 --> 01:28:41.660]   Yeah.
[01:28:41.660 --> 01:28:44.460]   Yeah, I would not.
[01:28:44.460 --> 01:28:46.620]   I mean, if anything, all it does is
[01:28:46.620 --> 01:28:50.620]   show that these parents really show their kids a lot of YouTube
[01:28:50.620 --> 01:28:51.780]   videos.
[01:28:51.780 --> 01:28:52.780]   Well, they watch.
[01:28:52.780 --> 01:28:54.540]   I mean, yeah, they let their kids.
[01:28:54.540 --> 01:28:55.260]   I don't know if--
[01:28:55.260 --> 01:28:58.540]   Well, in some of them do have videos.
[01:28:58.540 --> 01:29:01.740]   But I mean, yeah, my kid shouldn't watch TV.
[01:29:01.740 --> 01:29:03.780]   She watches people on YouTube.
[01:29:03.780 --> 01:29:04.340]   Right.
[01:29:04.340 --> 01:29:05.860]   So that's what she acts like.
[01:29:05.860 --> 01:29:07.300]   You know, that actually does make sense.
[01:29:07.300 --> 01:29:10.180]   I acted like the Van Dyke when I was growing up.
[01:29:10.180 --> 01:29:11.340]   I would fall over furniture.
[01:29:11.340 --> 01:29:11.860]   Yeah.
[01:29:11.860 --> 01:29:13.700]   Speaking of what you do, you see the colorized Van Dyke?
[01:29:13.700 --> 01:29:17.100]   I have seen images from it, but I haven't watched it yet.
[01:29:17.100 --> 01:29:20.780]   So the chair, or he trips over, was this really ugly green?
[01:29:20.780 --> 01:29:21.060]   Yeah.
[01:29:21.060 --> 01:29:22.260]   I'm not thinking that's the color.
[01:29:22.260 --> 01:29:23.180]   No, no, no.
[01:29:23.180 --> 01:29:25.620]   No, you read the whole story, right?
[01:29:25.620 --> 01:29:26.620]   No.
[01:29:26.620 --> 01:29:27.900]   They had-- well, OK.
[01:29:27.900 --> 01:29:29.540]   So in many cases, they had pictures
[01:29:29.540 --> 01:29:31.540]   from the production, color pictures.
[01:29:31.540 --> 01:29:33.220]   So they were able to reproduce the color.
[01:29:33.220 --> 01:29:34.580]   And in cases where they didn't, they
[01:29:34.580 --> 01:29:37.260]   sat down with Carl Reiner and others and said, OK,
[01:29:37.260 --> 01:29:39.820]   what color was that painting?
[01:29:39.820 --> 01:29:41.500]   So don't you remember?
[01:29:41.500 --> 01:29:42.860]   You're old enough.
[01:29:42.860 --> 01:29:44.980]   Furniture was really ugly back then.
[01:29:44.980 --> 01:29:45.820]   Yeah.
[01:29:45.820 --> 01:29:46.780]   It's all weird now.
[01:29:46.780 --> 01:29:48.020]   So here's the question.
[01:29:48.020 --> 01:29:50.180]   The phone--
[01:29:50.180 --> 01:29:50.900]   green.
[01:29:50.900 --> 01:29:51.460]   I saw you--
[01:29:51.460 --> 01:29:52.460]   This is--
[01:29:52.460 --> 01:29:53.340]   office phone.
[01:29:53.340 --> 01:29:55.660]   Now I remember this is why I kind of
[01:29:55.660 --> 01:29:59.420]   went down this whole route because of your post on Facebook.
[01:29:59.420 --> 01:30:00.660]   Welcome to the rattle.
[01:30:00.660 --> 01:30:03.940]   So they didn't know what color Alan Brady's phone was
[01:30:03.940 --> 01:30:04.900]   in his office, I guess.
[01:30:04.900 --> 01:30:07.100]   They didn't have a picture of that.
[01:30:07.100 --> 01:30:08.220]   Or no, no, the home phone.
[01:30:08.220 --> 01:30:09.020]   That was the home phone.
[01:30:09.020 --> 01:30:10.260]   The home phone was a green.
[01:30:10.260 --> 01:30:10.900]   Phone was a green.
[01:30:10.900 --> 01:30:11.900]   Phone was a green.
[01:30:11.900 --> 01:30:14.740]   Stacy, you don't even know what a princess phone is,
[01:30:14.740 --> 01:30:16.020]   let alone all of this.
[01:30:16.020 --> 01:30:17.660]   OK, I know what a princess phone is.
[01:30:17.660 --> 01:30:20.540]   They made them up for when I had my own phone.
[01:30:20.540 --> 01:30:21.900]   You could get them a radio shack.
[01:30:21.900 --> 01:30:22.380]   Yeah.
[01:30:22.380 --> 01:30:23.580]   Yeah.
[01:30:23.580 --> 01:30:25.380]   But you didn't have the black hard rubber
[01:30:25.380 --> 01:30:27.100]   Western electric phones that we all had.
[01:30:27.100 --> 01:30:27.620]   No.
[01:30:27.620 --> 01:30:28.140]   Yeah.
[01:30:28.140 --> 01:30:29.980]   And with the dials--
[01:30:29.980 --> 01:30:33.180]   Nor did I have telegrams.
[01:30:33.180 --> 01:30:34.500]   Somebody said no.
[01:30:34.500 --> 01:30:36.420]   I have Snapchat spectacles.
[01:30:36.420 --> 01:30:38.620]   I know I'm old, but I'm hip.
[01:30:38.620 --> 01:30:41.300]   Look, I'm snapping right now.
[01:30:41.300 --> 01:30:44.100]   My god, what more do you need?
[01:30:44.100 --> 01:30:47.100]   I'm cool.
[01:30:47.100 --> 01:30:48.460]   OK, let me upload that to my story.
[01:30:49.340 --> 01:30:51.020]   [LAUGHTER]
[01:30:51.020 --> 01:30:53.340]   I still haven't found you on Snapchat.
[01:30:53.340 --> 01:30:54.060]   I don't--
[01:30:54.060 --> 01:30:56.260]   I think the chief to it.
[01:30:56.260 --> 01:30:58.940]   I think that I don't know if my stories are getting uploaded.
[01:30:58.940 --> 01:31:00.860]   I don't know.
[01:31:00.860 --> 01:31:02.060]   I think some of it is.
[01:31:02.060 --> 01:31:03.420]   I don't really understand how it works yet.
[01:31:03.420 --> 01:31:05.060]   I'm going to have to perfect this, obviously.
[01:31:05.060 --> 01:31:09.060]   Here, wait a minute.
[01:31:09.060 --> 01:31:10.340]   I'll hold this up.
[01:31:10.340 --> 01:31:11.780]   Look, it's easy.
[01:31:11.780 --> 01:31:13.060]   Get your Snapchat out.
[01:31:13.060 --> 01:31:14.180]   Get your Snapchat out.
[01:31:14.180 --> 01:31:14.700]   OK.
[01:31:14.700 --> 01:31:18.100]   And zoom into that, Carsten.
[01:31:18.100 --> 01:31:18.940]   Zoom into that.
[01:31:18.940 --> 01:31:21.420]   That's my-- can you zoom in?
[01:31:21.420 --> 01:31:22.820]   I don't know if you can.
[01:31:22.820 --> 01:31:23.660]   That's me.
[01:31:23.660 --> 01:31:25.580]   And you just take a picture of that, right?
[01:31:25.580 --> 01:31:27.500]   It's like my QR code.
[01:31:27.500 --> 01:31:28.620]   Ad friends, hold on.
[01:31:28.620 --> 01:31:29.740]   Here I come.
[01:31:29.740 --> 01:31:31.580]   Ad by Snapcode.
[01:31:31.580 --> 01:31:32.660]   I guess I'm Leo Lejord.
[01:31:32.660 --> 01:31:33.380]   I'm not chief to it.
[01:31:33.380 --> 01:31:34.780]   I apologize.
[01:31:34.780 --> 01:31:37.340]   Tap a photo with Snapcode to add their Snapchat.
[01:31:37.340 --> 01:31:38.460]   What?
[01:31:38.460 --> 01:31:39.140]   No, no.
[01:31:39.140 --> 01:31:40.140]   Hold on.
[01:31:40.140 --> 01:31:40.980]   Hold on.
[01:31:40.980 --> 01:31:43.420]   Everybody add me.
[01:31:43.420 --> 01:31:44.340]   Everybody add me.
[01:31:44.340 --> 01:31:46.660]   I'm now cool again.
[01:31:46.660 --> 01:31:49.940]   I'm Leo Leport.
[01:31:49.940 --> 01:31:51.940]   What should I do?
[01:31:51.940 --> 01:31:53.740]   Make it square?
[01:31:53.740 --> 01:31:54.740]   Yeah.
[01:31:54.740 --> 01:31:58.740]   That doesn't matter.
[01:31:58.740 --> 01:31:59.740]   Oops.
[01:31:59.740 --> 01:32:00.660]   You know what?
[01:32:00.660 --> 01:32:02.660]   What's your Snap handle?
[01:32:02.660 --> 01:32:03.660]   Girl.
[01:32:03.660 --> 01:32:04.180]   Crikey.
[01:32:04.180 --> 01:32:04.660]   Hey girl.
[01:32:04.660 --> 01:32:05.260]   I don't--
[01:32:05.260 --> 01:32:05.660]   Oh, Crikey.
[01:32:05.660 --> 01:32:06.660]   Hey girl.
[01:32:06.660 --> 01:32:07.660]   Oh, Crikey.
[01:32:07.660 --> 01:32:08.660]   That's not my Snapchat.
[01:32:08.660 --> 01:32:10.020]   I think it's Higgenbob.
[01:32:10.020 --> 01:32:11.660]   I like it.
[01:32:11.660 --> 01:32:13.660]   I like it.
[01:32:13.660 --> 01:32:15.660]   Add by username.
[01:32:15.660 --> 01:32:16.460]   H5.
[01:32:16.460 --> 01:32:17.460]   I don't have any snaps.
[01:32:17.460 --> 01:32:20.740]   Well, I don't have any matter.
[01:32:20.740 --> 01:32:22.740]   2G's are 1N, G and Higgenbob.
[01:32:22.740 --> 01:32:25.740]   H-I-G-G-I-N-B-O-B.
[01:32:25.740 --> 01:32:27.940]   Two two G.
[01:32:27.940 --> 01:32:31.380]   Why are you again, Leo?
[01:32:31.380 --> 01:32:32.980]   Leo Leport, easily enough.
[01:32:32.980 --> 01:32:33.980]   I'm adding Higgenbob.
[01:32:33.980 --> 01:32:37.260]   I don't know if you're Higgenbob, but I'm adding A Higgenbob.
[01:32:37.260 --> 01:32:39.620]   Oh, now I've added you.
[01:32:39.620 --> 01:32:40.620]   Ah-ha.
[01:32:40.620 --> 01:32:46.420]   Facebook filed a patent last June for a system that uses machine learning to vet
[01:32:46.420 --> 01:32:50.860]   objectionable content and/or fake news.
[01:32:50.860 --> 01:32:51.860]   That'll work.
[01:32:51.860 --> 01:32:52.860]   Didn't he?
[01:32:52.860 --> 01:32:53.860]   Okay.
[01:32:53.860 --> 01:32:58.140]   Didn't someone tell us that was old?
[01:32:58.140 --> 01:33:04.180]   By the way, I don't know about you, but I got my year in review and I'm pissed.
[01:33:04.180 --> 01:33:07.100]   Maybe my year wasn't that good.
[01:33:07.100 --> 01:33:10.500]   Everybody's posting these cool year in reviews from Facebook, you know, because they make
[01:33:10.500 --> 01:33:13.900]   a video of your life.
[01:33:13.900 --> 01:33:17.220]   Maybe I just didn't post enough on Facebook.
[01:33:17.220 --> 01:33:19.940]   Oh, yeah.
[01:33:19.940 --> 01:33:22.060]   I can see your spectacle stories.
[01:33:22.060 --> 01:33:23.820]   Yes, see?
[01:33:23.820 --> 01:33:24.820]   Some of it's there.
[01:33:24.820 --> 01:33:25.820]   I don't know.
[01:33:25.820 --> 01:33:26.820]   What's your username again?
[01:33:26.820 --> 01:33:27.820]   Sorry.
[01:33:27.820 --> 01:33:28.820]   Leo Leport.
[01:33:28.820 --> 01:33:29.820]   It was my fault.
[01:33:29.820 --> 01:33:33.820]   I thought it was a chief to it, which it is in many places, but it isn't in this particular
[01:33:33.820 --> 01:33:34.820]   instance.
[01:33:34.820 --> 01:33:36.820]   Oh, I had to tell them.
[01:33:36.820 --> 01:33:38.300]   It's the same as my Twitter handle.
[01:33:38.300 --> 01:33:39.780]   Yeah, tell your seven-year-old.
[01:33:39.780 --> 01:33:41.380]   You know somebody with spectacles.
[01:33:41.380 --> 01:33:43.460]   Ah, she's 10.
[01:33:43.460 --> 01:33:47.740]   I thought you were 10-year-old, but I thought she was seven.
[01:33:47.740 --> 01:33:50.980]   She'll like you even more.
[01:33:50.980 --> 01:33:51.980]   Not only-
[01:33:51.980 --> 01:33:54.580]   You know, that works with older women, but not with young women.
[01:33:54.580 --> 01:33:55.580]   No.
[01:33:55.580 --> 01:33:56.580]   No.
[01:33:56.580 --> 01:33:59.580]   I could have sworn you were not a day over seven.
[01:33:59.580 --> 01:34:01.580]   It doesn't work.
[01:34:01.580 --> 01:34:02.580]   No.
[01:34:02.580 --> 01:34:03.580]   No.
[01:34:03.580 --> 01:34:04.580]   All right.
[01:34:04.580 --> 01:34:07.780]   We've really lost this show because now we're all involved in our own.
[01:34:07.780 --> 01:34:08.780]   This is a-
[01:34:08.780 --> 01:34:09.780]   We're involved.
[01:34:09.780 --> 01:34:11.620]   This is what's wrong with social media.
[01:34:11.620 --> 01:34:13.220]   It's anti-social media.
[01:34:13.220 --> 01:34:14.220]   Right?
[01:34:14.220 --> 01:34:15.220]   Indeed.
[01:34:15.220 --> 01:34:18.060]   You know what?
[01:34:18.060 --> 01:34:19.460]   No one's 2016 was good.
[01:34:19.460 --> 01:34:23.460]   Somebody says in the chat, "That's kind of true."
[01:34:23.460 --> 01:34:25.100]   I started my own company.
[01:34:25.100 --> 01:34:26.100]   It was good personally.
[01:34:26.100 --> 01:34:27.100]   No, you did.
[01:34:27.100 --> 01:34:28.100]   You know what?
[01:34:28.100 --> 01:34:29.740]   Because you were still fortunate at the beginning of the year.
[01:34:29.740 --> 01:34:30.740]   I was.
[01:34:30.740 --> 01:34:33.580]   And now time is up for sale.
[01:34:33.580 --> 01:34:34.580]   What?
[01:34:34.580 --> 01:34:35.580]   What?
[01:34:35.580 --> 01:34:36.580]   Yeah.
[01:34:36.580 --> 01:34:39.740]   Okay, they've got their bankers evaluating all the questions.
[01:34:39.740 --> 01:34:41.540]   There's a lot of interest in everybody.
[01:34:41.540 --> 01:34:42.540]   It appears.
[01:34:42.540 --> 01:34:43.540]   Probably not.
[01:34:43.540 --> 01:34:47.100]   We're going to hope that Matthew is okay.
[01:34:47.100 --> 01:34:48.100]   That's what we're going to have.
[01:34:48.100 --> 01:34:50.580]   He'll be fine.
[01:34:50.580 --> 01:34:52.260]   And if not, well, he's always got-
[01:34:52.260 --> 01:34:53.260]   We'll always have-
[01:34:53.260 --> 01:34:54.260]   Oh no!
[01:34:54.260 --> 01:34:57.820]   Why are you just posted a video saying, "Watch Uber's self-driving car barrel through a
[01:34:57.820 --> 01:34:58.820]   red light in San Francisco?"
[01:34:58.820 --> 01:34:59.820]   That's like, yeah.
[01:34:59.820 --> 01:35:00.820]   Uh oh.
[01:35:00.820 --> 01:35:01.820]   That's not good.
[01:35:01.820 --> 01:35:02.820]   Nope.
[01:35:02.820 --> 01:35:11.260]   I mean, it's kind of like a human driver.
[01:35:11.260 --> 01:35:12.260]   I don't see it.
[01:35:12.260 --> 01:35:13.260]   I want to show it.
[01:35:13.260 --> 01:35:15.820]   Go ahead on Twitter.
[01:35:15.820 --> 01:35:16.820]   Is it Twitter?
[01:35:16.820 --> 01:35:19.260]   See, I lose out by not being on Twitter.
[01:35:19.260 --> 01:35:20.260]   Here.
[01:35:20.260 --> 01:35:23.420]   I list all the cool kids you're seeing stuff and I'm just not.
[01:35:23.420 --> 01:35:26.380]   Where can I- Where do you want me to put- Oh, we have a chat thing.
[01:35:26.380 --> 01:35:27.380]   Hold on.
[01:35:27.380 --> 01:35:28.380]   Sorry.
[01:35:28.380 --> 01:35:29.380]   Yeah, you put there.
[01:35:29.380 --> 01:35:31.060]   Oh, my chat doesn't work.
[01:35:31.060 --> 01:35:32.460]   I have this issue today.
[01:35:32.460 --> 01:35:34.820]   I've had a bad day with Google in my multiple ways.
[01:35:34.820 --> 01:35:36.380]   You had a bad day.
[01:35:36.380 --> 01:35:37.380]   Da-da-da-da.
[01:35:37.380 --> 01:35:39.900]   Yeah, well, let me chat with y'all.
[01:35:39.900 --> 01:35:41.220]   Jeff, you'll have to put it in.
[01:35:41.220 --> 01:35:43.220]   Oh, now I got to find it again.
[01:35:43.220 --> 01:35:47.460]   Well, here, I'll just stick it in the- I'll stick it in.
[01:35:47.460 --> 01:35:48.460]   Stick it in.
[01:35:48.460 --> 01:35:51.060]   I'll just make a new box, you know.
[01:35:51.060 --> 01:35:52.060]   Make a box, Stacey.
[01:35:52.060 --> 01:35:54.900]   Put it under Stacey's under Stacey's tips.
[01:35:54.900 --> 01:35:55.900]   That's what I did.
[01:35:55.900 --> 01:36:01.580]   I put it under Stacey's thing in bright green URL, erls.
[01:36:01.580 --> 01:36:03.380]   Mm-hmm.
[01:36:03.380 --> 01:36:04.940]   Oh, no.
[01:36:04.940 --> 01:36:06.940]   Thank you.
[01:36:06.940 --> 01:36:08.940]   Uh oh.
[01:36:08.940 --> 01:36:09.940]   Uh oh.
[01:36:09.940 --> 01:36:10.940]   Here it is.
[01:36:10.940 --> 01:36:13.420]   Here's a car running through red light.
[01:36:13.420 --> 01:36:16.060]   This is a- so this is from the Uber?
[01:36:16.060 --> 01:36:17.500]   Oh, it's right behind it.
[01:36:17.500 --> 01:36:18.500]   Okay.
[01:36:18.500 --> 01:36:22.420]   Go full-screen if you would, so we can see all the gory detail.
[01:36:22.420 --> 01:36:23.420]   Here you are.
[01:36:23.420 --> 01:36:27.060]   You're in a regular- oh, it's a cab.
[01:36:27.060 --> 01:36:28.060]   There we go.
[01:36:28.060 --> 01:36:29.060]   Oopsies.
[01:36:29.060 --> 01:36:32.140]   Almost hit a pedestrian even.
[01:36:32.140 --> 01:36:33.740]   I know right where that is.
[01:36:33.740 --> 01:36:35.900]   That's right next to the air buboina center.
[01:36:35.900 --> 01:36:36.900]   Yep.
[01:36:36.900 --> 01:36:37.900]   Okay.
[01:36:37.900 --> 01:36:40.500]   Oops.
[01:36:40.500 --> 01:36:42.820]   It wasn't barreling.
[01:36:42.820 --> 01:36:44.020]   I think that's unfair.
[01:36:44.020 --> 01:36:46.860]   It didn't slow down, however.
[01:36:46.860 --> 01:36:51.980]   Uh are you gonna- now that I have Snapchat spectacles, I don't care about this story, but
[01:36:51.980 --> 01:36:56.500]   Instagram is bringing live video broadcast to US users.
[01:36:56.500 --> 01:37:00.220]   I can't stream live from Snap spectacles.
[01:37:00.220 --> 01:37:01.460]   This is just the Facebook tech.
[01:37:01.460 --> 01:37:04.620]   The Facebook's really- this was the year of Facebook live video, isn't it?
[01:37:04.620 --> 01:37:09.740]   And Facebook is now experimenting with live 360, so you could have a 360-
[01:37:09.740 --> 01:37:14.460]   Do I have to have the Facebook camera to do that, or can I bring a- I don't know, like
[01:37:14.460 --> 01:37:16.340]   a Theta S or something like that?
[01:37:16.340 --> 01:37:20.100]   They're in beta now.
[01:37:20.100 --> 01:37:21.580]   The amazing Fidgee CMO.
[01:37:21.580 --> 01:37:25.780]   I suppose we should mention that John Markoff is retiring from the New York Times.
[01:37:25.780 --> 01:37:28.220]   That made me so sad.
[01:37:28.220 --> 01:37:30.420]   He's actually taking the buyout.
[01:37:30.420 --> 01:37:31.420]   I know.
[01:37:31.420 --> 01:37:32.620]   So it's not really retiring.
[01:37:32.620 --> 01:37:35.940]   It's like- Yeah, I understand he's gonna be on contract writing stuff for them.
[01:37:35.940 --> 01:37:36.940]   So.
[01:37:36.940 --> 01:37:37.940]   Yes.
[01:37:37.940 --> 01:37:39.820]   So is the Times doing buyouts for a lot of people?
[01:37:39.820 --> 01:37:42.820]   Is that- I think that it's kind of ever with us.
[01:37:42.820 --> 01:37:44.380]   Yeah.
[01:37:44.380 --> 01:37:45.380]   He calls it retiring.
[01:37:45.380 --> 01:37:47.700]   Uh he's of course an old friend of the network.
[01:37:47.700 --> 01:37:53.180]   He's been on Twitch some many times, and uh one of the great tech writers just really
[01:37:53.180 --> 01:37:56.420]   talented uh fella.
[01:37:56.420 --> 01:37:57.900]   Machine- is it machines of love in grace?
[01:37:57.900 --> 01:37:58.900]   Yeah.
[01:37:58.900 --> 01:37:59.900]   Was that his book?
[01:37:59.900 --> 01:38:00.900]   Yeah.
[01:38:00.900 --> 01:38:01.900]   That's a good book.
[01:38:01.900 --> 01:38:02.900]   Yes, it said.
[01:38:02.900 --> 01:38:03.900]   Yes.
[01:38:03.900 --> 01:38:04.900]   Yeah.
[01:38:04.900 --> 01:38:05.900]   Yeah.
[01:38:05.900 --> 01:38:10.260]   Really good at uh you know long form and short form reportage.
[01:38:10.260 --> 01:38:14.780]   Kind of an even- you end up now with two camps of tech reporters.
[01:38:14.780 --> 01:38:20.580]   The- the- the- the dystopian's in the- in the extreme optimus, and he will always you know
[01:38:20.580 --> 01:38:22.380]   how to level a head about him in his report.
[01:38:22.380 --> 01:38:23.740]   Did you work with him at the examiner?
[01:38:23.740 --> 01:38:24.740]   No.
[01:38:24.740 --> 01:38:25.740]   No.
[01:38:25.740 --> 01:38:26.940]   I was there so long ago.
[01:38:26.940 --> 01:38:27.940]   Okay.
[01:38:27.940 --> 01:38:33.420]   Yeah, I would- I would divide tech reporters into people who care about tech, and people
[01:38:33.420 --> 01:38:39.120]   who write about features and products, which I feel are totally- it's totally different
[01:38:39.120 --> 01:38:41.120]   styles of journalism, and it's kind of-
[01:38:41.120 --> 01:38:42.120]   There's a third.
[01:38:42.120 --> 01:38:45.340]   And I- and I dearly love the Guardian I work with, but there's a third is there's
[01:38:45.340 --> 01:38:49.940]   Stacy, which is also the star- there's starting to be a tech writer group of people who don't
[01:38:49.940 --> 01:38:50.940]   like tech.
[01:38:50.940 --> 01:38:52.740]   Oh, that's nothing new.
[01:38:52.740 --> 01:38:53.740]   John C.
[01:38:53.740 --> 01:38:54.740]   Yeah, that's-
[01:38:54.740 --> 01:38:55.740]   John C.
[01:38:55.740 --> 01:38:56.740]   Yeah, that's-
[01:38:56.740 --> 01:38:57.740]   Yeah, that's-
[01:38:57.740 --> 01:38:58.740]   Nothing new at all.
[01:38:58.740 --> 01:39:01.780]   In fact, I kind of embraced that.
[01:39:01.780 --> 01:39:05.740]   Oh, I know- I know the big story I wanted to talk about, Magic Leap.
[01:39:05.740 --> 01:39:06.740]   Yeah.
[01:39:06.740 --> 01:39:10.940]   So, uh, not quite Theranos, but-
[01:39:10.940 --> 01:39:13.500]   Speaking of dystopian tech writers.
[01:39:13.500 --> 01:39:14.500]   Yeah.
[01:39:14.500 --> 01:39:17.340]   Nick Statt, famous for that?
[01:39:17.340 --> 01:39:21.980]   Magic Leap was actually way behind like we always expected it was, by the way, it should
[01:39:21.980 --> 01:39:23.500]   be as we always speak.
[01:39:23.500 --> 01:39:24.500]   As we always speak.
[01:39:24.500 --> 01:39:25.500]   Can I just- wait a minute.
[01:39:25.500 --> 01:39:28.860]   I'm gonna get my, uh, my blue pencil out here.
[01:39:28.860 --> 01:39:29.860]   Was it red or blue?
[01:39:29.860 --> 01:39:31.100]   What colors should I use?
[01:39:31.100 --> 01:39:32.100]   Red.
[01:39:32.100 --> 01:39:33.100]   Red.
[01:39:33.100 --> 01:39:34.100]   All right.
[01:39:34.100 --> 01:39:35.100]   And then what do I do?
[01:39:35.100 --> 01:39:39.620]   I put as in an arrow like that.
[01:39:39.620 --> 01:39:41.540]   That would be that way to do it?
[01:39:41.540 --> 01:39:42.540]   No.
[01:39:42.540 --> 01:39:46.980]   You'd cross it out and then put an arrow underneath it and above it put as.
[01:39:46.980 --> 01:39:47.980]   And-
[01:39:47.980 --> 01:39:48.980]   You just do one mind.
[01:39:48.980 --> 01:39:51.020]   I gotta learn about the copy editing thing.
[01:39:51.020 --> 01:39:52.020]   Yes.
[01:39:52.020 --> 01:39:53.020]   Because this is gonna be-
[01:39:53.020 --> 01:39:54.020]   That's the guy that goes to my proof-
[01:39:54.020 --> 01:39:55.020]   This is gonna be fun.
[01:39:55.020 --> 01:39:56.020]   [laughter]
[01:39:56.020 --> 01:40:04.740]   So, Magic Leap has been sung at the praises of Ensung, Google Big Investor and Magic Leap.
[01:40:04.740 --> 01:40:09.420]   The idea is this was one of the augmented reality technologies and many said the best
[01:40:09.420 --> 01:40:10.420]   of them.
[01:40:10.420 --> 01:40:19.300]   But the problem was the technology was- nobody ever really saw it.
[01:40:19.300 --> 01:40:20.300]   And it-
[01:40:20.300 --> 01:40:21.300]   What they did?
[01:40:21.300 --> 01:40:22.300]   Yeah.
[01:40:22.300 --> 01:40:23.300]   They thought people would come back and say, "Oh, I saw it.
[01:40:23.300 --> 01:40:24.300]   It's changed.
[01:40:24.300 --> 01:40:30.580]   Well, and even Magic Leap now is admitted that the video they used to recruit new employees
[01:40:30.580 --> 01:40:35.180]   was completely faked, was done by Weta, the folks who did the special effects for the
[01:40:35.180 --> 01:40:36.180]   Hobbit.
[01:40:36.180 --> 01:40:37.180]   [laughter]
[01:40:37.180 --> 01:40:40.660]   That's so funny.
[01:40:40.660 --> 01:40:41.660]   [laughter]
[01:40:41.660 --> 01:40:48.740]   Again, the information had the story and this was a great story.
[01:40:48.740 --> 01:40:55.340]   And unfortunately, I mean, the video says the games we're playing around the office right
[01:40:55.340 --> 01:40:59.340]   now, this is completely fake.
[01:40:59.340 --> 01:41:03.460]   Now, of course, this is what they want it to be.
[01:41:03.460 --> 01:41:06.980]   The information said, "Well, we got a demo of the Magic Leap.
[01:41:06.980 --> 01:41:08.300]   It's a giant helmet.
[01:41:08.300 --> 01:41:13.300]   You can barely hold your head up, connects to a desktop computer with multiple cables.
[01:41:13.300 --> 01:41:18.740]   It's kind of like HoloLens, which is a Microsoft product that exists right now."
[01:41:18.740 --> 01:41:21.100]   Let me turn the sound off on this.
[01:41:21.100 --> 01:41:28.020]   But the images are in some cases blurrier and more jittery than Microsoft's prototype.
[01:41:28.020 --> 01:41:33.700]   So apparently, the information says the problem lies with Magic Leap-
[01:41:33.700 --> 01:41:39.540]   Magic Leap Scamble on fiber scanning displays, which shines a laser through a fiber optic
[01:41:39.540 --> 01:41:43.300]   cable that moves rapidly back and forth to dry images out of light.
[01:41:43.300 --> 01:41:47.340]   That's actually very similar to the way your old TV set worked.
[01:41:47.340 --> 01:41:52.260]   The company thought the fiber scanning display could be Magic Leap's breakthrough tech,
[01:41:52.260 --> 01:41:56.020]   allowing it to shrink down the extremely expensive hardware used on a previous prototype, a
[01:41:56.020 --> 01:42:01.340]   refrigerated, refrigerated sized device known internally as the Beast.
[01:42:01.340 --> 01:42:07.300]   Magic Leap still has not been able to get fiber scanning to work.
[01:42:07.300 --> 01:42:12.980]   So I'm actually disappointed.
[01:42:12.980 --> 01:42:21.780]   This is why if you're a tech writer and you're pessimistic about it, you're usually right.
[01:42:21.780 --> 01:42:23.700]   That's what I learned from Devorak.
[01:42:23.700 --> 01:42:24.700]   You could look at anything saying...
[01:42:24.700 --> 01:42:27.140]   So that's not always true.
[01:42:27.140 --> 01:42:28.660]   That's not true.
[01:42:28.660 --> 01:42:34.340]   I think you might be right in the short term, but in the long term, a lot of the trends that
[01:42:34.340 --> 01:42:37.660]   we expect to see do actually happen, I guess.
[01:42:37.660 --> 01:42:39.780]   Yeah, but often they take longer.
[01:42:39.780 --> 01:42:42.980]   Well, yeah, but that's hard stuff.
[01:42:42.980 --> 01:42:46.460]   Yeah, no, I agree with you.
[01:42:46.460 --> 01:42:48.220]   But don't get your hopes up.
[01:42:48.220 --> 01:42:52.820]   It doesn't sound like you're going to be getting a Magic Leap helmet anytime soon.
[01:42:52.820 --> 01:42:58.100]   But how many people do you know who went to see it and came back believing they see it?
[01:42:58.100 --> 01:42:59.860]   So I don't know how much they actually saw.
[01:42:59.860 --> 01:43:00.860]   Maybe they did see more.
[01:43:00.860 --> 01:43:03.620]   Maybe the video was bad.
[01:43:03.620 --> 01:43:04.620]   Maybe the further along.
[01:43:04.620 --> 01:43:07.980]   I mean, the part of the problem it said, the story said, is that miniaturizing all that
[01:43:07.980 --> 01:43:08.980]   technology is hard.
[01:43:08.980 --> 01:43:11.180]   That's the correct way it is right now.
[01:43:11.180 --> 01:43:16.860]   Yeah, there's in fact the whole story on why it's so hard to do.
[01:43:16.860 --> 01:43:22.020]   Although some have said this kind of little fairness, like I don't think it's that bad.
[01:43:22.020 --> 01:43:23.620]   I don't think it's a scam.
[01:43:23.620 --> 01:43:27.660]   Let's put it that way.
[01:43:27.660 --> 01:43:34.060]   That's the bots act.
[01:43:34.060 --> 01:43:39.700]   It's passed through the House of Representatives called the Better Online Ticket Sales Act or
[01:43:39.700 --> 01:43:40.700]   Bots Act.
[01:43:40.700 --> 01:43:42.940]   Actually, the bill passed the Senate a week ago.
[01:43:42.940 --> 01:43:44.220]   So now it goes to the White House.
[01:43:44.220 --> 01:43:46.540]   So it is almost a law.
[01:43:46.540 --> 01:43:55.540]   If I remember my schoolhouse rock, jingle, Lin Manuel Moretta, the creator of Hamilton,
[01:43:55.540 --> 01:43:57.060]   one of the strong advocates for this.
[01:43:57.060 --> 01:43:58.060]   It's true.
[01:43:58.060 --> 01:44:00.700]   You can't get tickets to Hamilton because the minute new tickets go and sale, these
[01:44:00.700 --> 01:44:04.780]   bots go out and buy them all up and then try to sell them back to you for thousands of
[01:44:04.780 --> 01:44:05.780]   dollars.
[01:44:05.780 --> 01:44:07.220]   So how can you outlaw them?
[01:44:07.220 --> 01:44:08.620]   How can you really know it's a bot?
[01:44:08.620 --> 01:44:10.660]   A clever bot?
[01:44:10.660 --> 01:44:13.980]   You wouldn't know it's a bot, right?
[01:44:13.980 --> 01:44:20.780]   Well, no, you can easily put in, you can easily put in, yeah, there's also some ways.
[01:44:20.780 --> 01:44:24.180]   Or you prevent somebody from buying more than two tickets every five minutes or whatever.
[01:44:24.180 --> 01:44:26.140]   I mean, it's not.
[01:44:26.140 --> 01:44:28.140]   But you need to make a legal first.
[01:44:28.140 --> 01:44:30.260]   The problem is you can catch them, but it's not illegal.
[01:44:30.260 --> 01:44:32.940]   Now it will be illegal.
[01:44:32.940 --> 01:44:35.940]   Ticket bots are illegal in New York.
[01:44:35.940 --> 01:44:37.660]   They increased the penalties last month.
[01:44:37.660 --> 01:44:39.860]   That didn't stop Broadway sales.
[01:44:39.860 --> 01:44:44.260]   An investigation by the New York State Attorney General found abuses like a single scalper
[01:44:44.260 --> 01:44:49.380]   buying more than a thousand tickets and under a minute for a U2 concert in Madison Square
[01:44:49.380 --> 01:44:53.700]   Garden.
[01:44:53.700 --> 01:44:56.100]   So yeah, actually that's an interesting question.
[01:44:56.100 --> 01:45:00.900]   I think the first step is really make it clearly illegal.
[01:45:00.900 --> 01:45:05.980]   The BotSec makes it illegal to bypass an online security system.
[01:45:05.980 --> 01:45:10.940]   So interesting twist and we're not there yet, but what if I tell Google Home to, hey, buy
[01:45:10.940 --> 01:45:12.500]   these tickets while I'm out?
[01:45:12.500 --> 01:45:14.860]   Yeah, I don't think that would rise to that level.
[01:45:14.860 --> 01:45:15.860]   Good question.
[01:45:15.860 --> 01:45:19.220]   Well, I think the real issue is if people buy me a thousand.
[01:45:19.220 --> 01:45:20.220]   Yeah, thousand tickets.
[01:45:20.220 --> 01:45:21.220]   That's really the issue.
[01:45:21.220 --> 01:45:25.020]   Well, that's kind of an interesting thing when they're writing that law because when
[01:45:25.020 --> 01:45:31.060]   you're writing a law like that, if you ban bots, you ban potentially useful services.
[01:45:31.060 --> 01:45:38.060]   Although you could argue then that by virtue of having broadband in Google Home, I am thus
[01:45:38.060 --> 01:45:39.780]   privileged above other people.
[01:45:39.780 --> 01:45:44.180]   So anyway, don't do that.
[01:45:44.180 --> 01:45:45.580]   Rabbit hole.
[01:45:45.580 --> 01:45:49.740]   You're also privileged by virtue of genetics.
[01:45:49.740 --> 01:45:51.540]   All kinds of things where I live.
[01:45:51.540 --> 01:45:52.540]   What can you do?
[01:45:52.540 --> 01:45:55.820]   It's just life.
[01:45:55.820 --> 01:45:59.420]   How about we take a break and come back with your picks of the week unless there's a story
[01:45:59.420 --> 01:46:00.420]   out of you.
[01:46:00.420 --> 01:46:01.420]   Wow, wow, wow.
[01:46:01.420 --> 01:46:02.420]   Geez.
[01:46:02.420 --> 01:46:03.420]   I know.
[01:46:03.420 --> 01:46:04.420]   Well, we're only an hour and 43 minutes in the show.
[01:46:04.420 --> 01:46:08.300]   Although I think, Carsten, if we can get one of the editors to tighten it up a little
[01:46:08.300 --> 01:46:13.580]   bit, all that stuff where I'm fumpering around because I'm trying to do this show in sunglasses,
[01:46:13.580 --> 01:46:19.180]   that would probably be with no good browser with edge.
[01:46:19.180 --> 01:46:23.060]   It'd be nice to tighten it up a little bit.
[01:46:23.060 --> 01:46:25.820]   So the transcript from the beginning of the meeting is up.
[01:46:25.820 --> 01:46:28.060]   Ah, I just put it up online.
[01:46:28.060 --> 01:46:30.540]   So it looked like Reuters was in the room.
[01:46:30.540 --> 01:46:38.780]   So I guess, is that, it seemed like some people weren't in the room before?
[01:46:38.780 --> 01:46:41.300]   Or maybe they were, I don't know.
[01:46:41.300 --> 01:46:43.760]   If you're really going to do it, you know, if you're really going to make it a reality
[01:46:43.760 --> 01:46:45.820]   show, you got to get press coverage.
[01:46:45.820 --> 01:46:49.780]   Well, by the way, carp is not.
[01:46:49.780 --> 01:46:50.780]   That's David carp.
[01:46:50.780 --> 01:46:53.580]   This is Alex carp who's Alex, your palantier.
[01:46:53.580 --> 01:46:54.580]   Oh, different.
[01:46:54.580 --> 01:46:55.580]   Oh, different.
[01:46:55.580 --> 01:46:56.580]   Different carp.
[01:46:56.580 --> 01:46:58.580]   Thank you for correcting the world.
[01:46:58.580 --> 01:46:59.580]   Yes.
[01:46:59.580 --> 01:47:00.980]   Palantier is very different.
[01:47:00.980 --> 01:47:01.980]   David carp.
[01:47:01.980 --> 01:47:04.700]   David carp created tumbler and is a nice guy.
[01:47:04.700 --> 01:47:05.700]   Yes.
[01:47:05.700 --> 01:47:12.500]   Palantier is, as the name implies, a device that looks, you know, into your inner thoughts
[01:47:12.500 --> 01:47:13.500]   and hopes and wishes.
[01:47:13.500 --> 01:47:17.100]   So this is actually kind of interesting how they position themselves.
[01:47:17.100 --> 01:47:22.580]   So Tim Cook, introducing himself, Tim Cook, very good to be here.
[01:47:22.580 --> 01:47:25.820]   I look forward to talking to the president elect about things that we can do to help
[01:47:25.820 --> 01:47:27.940]   you achieve some of the things you want.
[01:47:27.940 --> 01:47:28.940]   Good.
[01:47:28.940 --> 01:47:29.940]   The tribe very hard.
[01:47:29.940 --> 01:47:31.740]   I'm Safrik Katz, CEO of Oracle.
[01:47:31.740 --> 01:47:34.860]   I'm actually privileged and honored to even be here.
[01:47:34.860 --> 01:47:37.820]   And we're looking forward to helping you and your administration.
[01:47:37.820 --> 01:47:43.420]   Elon Musk, the CEO of SpaceX and Tesla building rockets and cars and solar stuff in the
[01:47:43.420 --> 01:47:44.420]   US.
[01:47:44.420 --> 01:47:50.020]   I'm really excited about expanding our manufacturing footprint footprint in the US.
[01:47:50.020 --> 01:47:51.020]   Good.
[01:47:51.020 --> 01:47:53.220]   By the way, that's a good point.
[01:47:53.220 --> 01:47:54.660]   Tesla makes all its stuff here.
[01:47:54.660 --> 01:47:55.660]   Well, yes.
[01:47:55.660 --> 01:47:56.660]   It's a good.
[01:47:56.660 --> 01:48:01.300]   Eric Schmidt, alphabet Google and completely agree with what's been said.
[01:48:01.300 --> 01:48:03.980]   Really everybody says, I agree.
[01:48:03.980 --> 01:48:04.980]   What they said.
[01:48:04.980 --> 01:48:06.980]   Oh, I love Eric Schmidt.
[01:48:06.980 --> 01:48:11.780]   He continues to amaze and impress with his elocution skills.
[01:48:11.780 --> 01:48:14.140]   Jeff Bezos, Amazon.com.
[01:48:14.140 --> 01:48:18.660]   I'm super excited about the possibility that this could be the innovations administration.
[01:48:18.660 --> 01:48:19.660]   Wow.
[01:48:19.660 --> 01:48:20.660]   Wow.
[01:48:20.660 --> 01:48:22.860]   They're kissing his butt.
[01:48:22.860 --> 01:48:25.420]   See, that just proves what I'm saying.
[01:48:25.420 --> 01:48:27.780]   They want to look, they want to be at the table.
[01:48:27.780 --> 01:48:29.220]   They want to be part of the conversation.
[01:48:29.220 --> 01:48:30.220]   That's the only reason.
[01:48:30.220 --> 01:48:33.260]   Satya just said Satya Nadella, CEO of Microsoft.
[01:48:33.260 --> 01:48:36.460]   Oh, thank you, Satya.
[01:48:36.460 --> 01:48:39.460]   Cheryl Sabrik, Facebook, excited to talk about jobs.
[01:48:39.460 --> 01:48:40.460]   Yeah.
[01:48:40.460 --> 01:48:46.740]   And so did actually Brian Krasenich, which is like, Damon.
[01:48:46.740 --> 01:48:49.060]   And so, name ranking serial number.
[01:48:49.060 --> 01:48:50.060]   I love that.
[01:48:50.060 --> 01:48:57.660]   Basically, like, yeah, Eric Trump, Eric Trump, welcome Ivanka Trump.
[01:48:57.660 --> 01:48:58.820]   I don't know.
[01:48:58.820 --> 01:49:00.540]   I need no introduction.
[01:49:00.540 --> 01:49:03.300]   I am Ivanka Trump.
[01:49:03.300 --> 01:49:04.300]   Ivanka.
[01:49:04.300 --> 01:49:05.300]   Ivanka.
[01:49:05.300 --> 01:49:06.300]   Okay.
[01:49:06.300 --> 01:49:13.820]   I actually, I look at Ivanka and I think she looks like she's the one who got all the
[01:49:13.820 --> 01:49:17.420]   brains because the boys don't look that bright.
[01:49:17.420 --> 01:49:23.180]   I mean, excuse me, but here I am sitting in snap spectacles.
[01:49:23.180 --> 01:49:27.340]   There's no reason for me to have any opinion in that at all.
[01:49:27.340 --> 01:49:28.460]   But no, I look Donald Jr.
[01:49:28.460 --> 01:49:30.220]   He just looks like Donald Jr.
[01:49:30.220 --> 01:49:32.220]   That's what he looks like.
[01:49:32.220 --> 01:49:37.300]   Eric looks like, but what was the kid on the monsters?
[01:49:37.300 --> 01:49:38.300]   Any monster.
[01:49:38.300 --> 01:49:39.740]   Eddie Monster, it's the hair.
[01:49:39.740 --> 01:49:40.740]   Eddie Monster.
[01:49:40.740 --> 01:49:41.740]   Eddie Monster.
[01:49:41.740 --> 01:49:42.740]   Eric is the key.
[01:49:42.740 --> 01:49:43.740]   Yeah.
[01:49:43.740 --> 01:49:44.740]   Yeah.
[01:49:44.740 --> 01:49:45.740]   Okay.
[01:49:45.740 --> 01:49:47.740]   I love it when Stacy goes, I do too.
[01:49:47.740 --> 01:49:48.740]   That could be exciting.
[01:49:48.740 --> 01:49:50.700]   I thought I got exciting news, but it's not real.
[01:49:50.700 --> 01:49:51.700]   No, it's fake.
[01:49:51.700 --> 01:49:52.700]   It's fake.
[01:49:52.700 --> 01:49:53.700]   I'm not even going to go.
[01:49:53.700 --> 01:49:54.700]   Fakeish news.
[01:49:54.700 --> 01:49:56.820]   We love fakeish news.
[01:49:56.820 --> 01:49:59.500]   Our show today brought to you by something very real.
[01:49:59.500 --> 01:50:04.420]   I know because I used it for years, save my keister.
[01:50:04.420 --> 01:50:05.820]   I should take these off.
[01:50:05.820 --> 01:50:08.860]   You can't trust anybody wearing snap spectacles.
[01:50:08.860 --> 01:50:10.860]   I'm talking about fresh books.
[01:50:10.860 --> 01:50:15.900]   When I was a freelancer going up to Canada one week a month, a few years ago, I had to
[01:50:15.900 --> 01:50:18.060]   make my own invoices.
[01:50:18.060 --> 01:50:22.900]   I didn't get paid unless I build them for my time and expenses because I paid the airfare,
[01:50:22.900 --> 01:50:25.980]   the hotel, everything, and I had to get the money back, right?
[01:50:25.980 --> 01:50:27.660]   That's the life of a freelancer.
[01:50:27.660 --> 01:50:29.820]   But the thing is I hated doing invoices.
[01:50:29.820 --> 01:50:32.500]   I hated it so much and I would go kick and screaming.
[01:50:32.500 --> 01:50:36.420]   Poor Amber MacArthur would have to hear me complaining about it every month.
[01:50:36.420 --> 01:50:40.940]   Finally, she said, "Leo, fresh books.
[01:50:40.940 --> 01:50:42.300]   Little Toronto startup.
[01:50:42.300 --> 01:50:46.180]   This is my year 2004, I think.
[01:50:46.180 --> 01:50:52.020]   And they make it so easy to do invoices and so easy to do your bookkeeping.
[01:50:52.020 --> 01:50:56.020]   It's a super intuitive tool that makes it easy to create and send professional invoices,
[01:50:56.020 --> 01:51:00.940]   take it just a few seconds, customize them with your invoice, with your logo, your color
[01:51:00.940 --> 01:51:04.340]   scheme, whatever images you want.
[01:51:04.340 --> 01:51:08.100]   You could chat with your client right in the fresh books interface about the invoice once
[01:51:08.100 --> 01:51:09.100]   they receive it.
[01:51:09.100 --> 01:51:12.420]   You could see which invoices have been sent, which have been paid, which have not been
[01:51:12.420 --> 01:51:20.860]   paid, and when they were viewed very helpful, so they can't say, "I didn't get it."
[01:51:20.860 --> 01:51:26.000]   And this hub is more than just invoices because now you can see your outstanding balances
[01:51:26.000 --> 01:51:30.540]   you're spending, your total profit accounting reports like sales tax and profit and loss.
[01:51:30.540 --> 01:51:31.540]   It is awesome.
[01:51:31.540 --> 01:51:33.180]   FreshBooks.com.
[01:51:33.180 --> 01:51:38.620]   You could track expenses by vendor and category, take expenses of pictures of the expense receipts
[01:51:38.620 --> 01:51:40.740]   and using the app.
[01:51:40.740 --> 01:51:43.140]   Put it right in.
[01:51:43.140 --> 01:51:47.620]   If you do time and hours, it's got a timer on the website also on the app and it just
[01:51:47.620 --> 01:51:49.340]   goes right into the invoice.
[01:51:49.340 --> 01:51:50.740]   It is just the easiest way.
[01:51:50.740 --> 01:51:55.760]   If you're doing this kind of bookkeeping and I hope you are, don't do it the hard
[01:51:55.760 --> 01:51:57.700]   way with a real accounting system.
[01:51:57.700 --> 01:52:00.780]   You got to learn, get a degree in accounting to use it.
[01:52:00.780 --> 01:52:01.780]   I tried that.
[01:52:01.780 --> 01:52:02.780]   It's just too hard.
[01:52:02.780 --> 01:52:03.780]   This is easy.
[01:52:03.780 --> 01:52:05.660]   You know how to use it already.
[01:52:05.660 --> 01:52:06.660]   It's all online.
[01:52:06.660 --> 01:52:07.660]   It's really easy.
[01:52:07.660 --> 01:52:09.100]   They got a great app for Android and iOS.
[01:52:09.100 --> 01:52:12.700]   If you want to try it, we got a 30-day free trial unrestricted.
[01:52:12.700 --> 01:52:14.180]   Get the whole run of the place.
[01:52:14.180 --> 01:52:17.540]   All you have to do is go to freshbooks.com/twig.
[01:52:17.540 --> 01:52:19.860]   FreshBooks.com/twig.
[01:52:19.860 --> 01:52:25.620]   And if you would do me a favor in the form, they say, "How did you hear about us?"
[01:52:25.620 --> 01:52:26.800]   Please put this week in Google.
[01:52:26.800 --> 01:52:30.440]   So Jeff and Stacy and I get credit.
[01:52:30.440 --> 01:52:34.760]   FreshBooks.com/twig for a 30-day free trial.
[01:52:34.760 --> 01:52:40.440]   We thank FreshBooks so much for making this week in Google possible.
[01:52:40.440 --> 01:52:41.840]   Let's see here.
[01:52:41.840 --> 01:52:42.840]   Who wants to start?
[01:52:42.840 --> 01:52:43.840]   Why don't you start?
[01:52:43.840 --> 01:52:44.840]   Stacy, please.
[01:52:44.840 --> 01:52:45.840]   Yes.
[01:52:45.840 --> 01:52:46.840]   Thank you.
[01:52:46.840 --> 01:52:47.840]   Okay.
[01:52:47.840 --> 01:52:51.240]   I don't have a thing this week because I've been testing random things.
[01:52:51.240 --> 01:52:55.820]   But I decided to do things I am getting people as gifts.
[01:52:55.820 --> 01:52:59.300]   So this is gift idea number one.
[01:52:59.300 --> 01:53:01.740]   This is for children.
[01:53:01.740 --> 01:53:04.940]   And have I told you guys about Phoebe and her unicorn yet?
[01:53:04.940 --> 01:53:06.660]   No, Razzle-Dazzle Unicorn.
[01:53:06.660 --> 01:53:07.660]   What is that?
[01:53:07.660 --> 01:53:08.660]   This is the holiday one.
[01:53:08.660 --> 01:53:10.580]   So this is what Calvin and Hobbes now looks like.
[01:53:10.580 --> 01:53:13.460]   I'm going to find one of the things.
[01:53:13.460 --> 01:53:20.620]   So this is like Calvin and Hobbes if Calvin were a girl and had a unicorn and you're
[01:53:20.620 --> 01:53:25.200]   like, Stacy, that sounds so girly, but it's not.
[01:53:25.200 --> 01:53:26.560]   And I'm trying to find.
[01:53:26.560 --> 01:53:28.200]   Okay, here we go.
[01:53:28.200 --> 01:53:29.200]   Oh wait.
[01:53:29.200 --> 01:53:32.200]   Another female unicorn adventure.
[01:53:32.200 --> 01:53:36.680]   Oh, it's on a Kindle or comicsology.
[01:53:36.680 --> 01:53:38.440]   So this is a graphic novel.
[01:53:38.440 --> 01:53:40.000]   Yeah, it's a comic book.
[01:53:40.000 --> 01:53:41.000]   So let's see.
[01:53:41.000 --> 01:53:42.000]   Can you see this one?
[01:53:42.000 --> 01:53:43.160]   Oh, look at that.
[01:53:43.160 --> 01:53:44.160]   It's cute.
[01:53:44.160 --> 01:53:45.160]   Yeah.
[01:53:45.160 --> 01:53:46.160]   Yeah.
[01:53:46.160 --> 01:53:51.180]   No, it's no, it's no, it's programming.
[01:53:51.180 --> 01:53:53.380]   It's a binary tree.
[01:53:53.380 --> 01:53:54.580]   Her dad is a cisaben.
[01:53:54.580 --> 01:53:56.540]   Oh, that's so cute.
[01:53:56.540 --> 01:53:59.420]   So I can't, I can't give you the full there it is.
[01:53:59.420 --> 01:54:01.660]   So it's a, it's a, it's funny.
[01:54:01.660 --> 01:54:03.220]   You'll love reading it.
[01:54:03.220 --> 01:54:04.220]   It's geeky.
[01:54:04.220 --> 01:54:05.220]   She's unique.
[01:54:05.220 --> 01:54:06.940]   She's unique like Calvin was unique.
[01:54:06.940 --> 01:54:10.420]   So I love sharing this with my daughter.
[01:54:10.420 --> 01:54:12.140]   So there's a bunch of these.
[01:54:12.140 --> 01:54:13.260]   I highly recommend them.
[01:54:13.260 --> 01:54:14.980]   I've learned about it from Carrie Doctorow.
[01:54:14.980 --> 01:54:16.720]   So, oh, I love Corey.
[01:54:16.720 --> 01:54:17.720]   Do you know Corey?
[01:54:17.720 --> 01:54:19.760]   Corey, sorry, Corey, not Carrie.
[01:54:19.760 --> 01:54:22.440]   I don't know him personally, but I follow my Twitter and every time we recommend a book
[01:54:22.440 --> 01:54:24.920]   for kids, I'm like, yeah, I mean, it is.
[01:54:24.920 --> 01:54:28.680]   His daughter, his daughter posies your, I think the same age as your daughter.
[01:54:28.680 --> 01:54:30.560]   That's why I look at like, yeah, yeah.
[01:54:30.560 --> 01:54:31.800]   Do more things.
[01:54:31.800 --> 01:54:33.320]   And then the other is a website.
[01:54:33.320 --> 01:54:39.520]   So this is, I, I've been looking for photos on my wall in a friend of mine told me about
[01:54:39.520 --> 01:54:41.600]   this, this guy who is in Texas.
[01:54:41.600 --> 01:54:44.520]   So there's some Texas themed stuff for any Longhorn fans.
[01:54:44.520 --> 01:54:48.540]   But check out these animal photos and their reasonably priced.
[01:54:48.540 --> 01:54:49.800]   They're beautiful.
[01:54:49.800 --> 01:54:53.380]   And I want to get the brown goat number one because this goat makes me laugh.
[01:54:53.380 --> 01:54:55.220]   Look at that goat's expression.
[01:54:55.220 --> 01:54:56.700]   I love it.
[01:54:56.700 --> 01:54:58.640]   So that, those are my two things.
[01:54:58.640 --> 01:54:59.860]   I know it's kind of random.
[01:54:59.860 --> 01:55:03.500]   But, you know, that's the beauty of this show.
[01:55:03.500 --> 01:55:04.500]   Everything we do.
[01:55:04.500 --> 01:55:05.500]   I like that.
[01:55:05.500 --> 01:55:06.500]   I like that.
[01:55:06.500 --> 01:55:07.500]   Everything.
[01:55:07.500 --> 01:55:08.500]   Oh, that's good.
[01:55:08.500 --> 01:55:09.500]   Ramdom.
[01:55:09.500 --> 01:55:10.500]   That's ramdom.
[01:55:10.500 --> 01:55:11.500]   Ramdom.
[01:55:11.500 --> 01:55:12.500]   Ramdom.
[01:55:12.500 --> 01:55:13.500]   So, yes.
[01:55:13.500 --> 01:55:14.620]   Okay.
[01:55:14.620 --> 01:55:16.780]   His photos are really astonishing.
[01:55:16.780 --> 01:55:21.080]   Like he gets some really great expressions on these animals, which sounds weird.
[01:55:21.080 --> 01:55:22.080]   But let's see.
[01:55:22.080 --> 01:55:23.920]   Scroll down to, are you in the, yeah.
[01:55:23.920 --> 01:55:28.460]   He's the modern Autobahn.
[01:55:28.460 --> 01:55:32.180]   If you click on farm, I want to show you the goat because it's, it made me laugh like
[01:55:32.180 --> 01:55:34.180]   out loud.
[01:55:34.180 --> 01:55:35.940]   Okay.
[01:55:35.940 --> 01:55:36.940]   Farm.
[01:55:36.940 --> 01:55:40.380]   Oh, it's not working.
[01:55:40.380 --> 01:55:41.980]   Oh, sadness.
[01:55:41.980 --> 01:55:42.980]   Okay.
[01:55:42.980 --> 01:55:43.980]   Scroll.
[01:55:43.980 --> 01:55:44.980]   Keep scrolling.
[01:55:44.980 --> 01:55:45.980]   There he is.
[01:55:45.980 --> 01:55:46.980]   Round goat number one.
[01:55:46.980 --> 01:55:47.980]   Look at that face.
[01:55:47.980 --> 01:55:48.980]   He's like, what's up?
[01:55:48.980 --> 01:55:49.980]   Right.
[01:55:49.980 --> 01:55:50.980]   And the cynical.
[01:55:50.980 --> 01:55:51.980]   Sorry.
[01:55:51.980 --> 01:55:52.980]   Okay.
[01:55:52.980 --> 01:55:57.980]   So now, now you know what people I know are getting for Christmas issue.
[01:55:57.980 --> 01:56:02.180]   Ah, that's sweet.
[01:56:02.180 --> 01:56:04.260]   Jeff Jarvis, a number.
[01:56:04.260 --> 01:56:06.660]   So it's the, during the year, end of the year time.
[01:56:06.660 --> 01:56:10.220]   So Google's releasing the sort of a search state published popular as popular as popular
[01:56:10.220 --> 01:56:11.220]   that.
[01:56:11.220 --> 01:56:12.220]   I love that.
[01:56:12.220 --> 01:56:13.220]   Yeah.
[01:56:13.220 --> 01:56:14.220]   10 recipes.
[01:56:14.220 --> 01:56:18.940]   Oh, like people search for it over and over again.
[01:56:18.940 --> 01:56:20.180]   What they search for.
[01:56:20.180 --> 01:56:23.700]   And number one, yeah.
[01:56:23.700 --> 01:56:25.100]   Green bean casserole.
[01:56:25.100 --> 01:56:26.100]   Why?
[01:56:26.100 --> 01:56:27.100]   Why?
[01:56:27.100 --> 01:56:28.100]   Why?
[01:56:28.100 --> 01:56:29.100]   Well, it's worse.
[01:56:29.100 --> 01:56:30.100]   No, two.
[01:56:30.100 --> 01:56:32.100]   Why brussel sprouts?
[01:56:32.100 --> 01:56:35.580]   Well, that's because they're all trying to find a way to make them taste good.
[01:56:35.580 --> 01:56:38.220]   Oh, I know my theory of brussel sprouts.
[01:56:38.220 --> 01:56:40.340]   They didn't exist before three mile island.
[01:56:40.340 --> 01:56:43.380]   Oh, no, no, no, it's just little baby cabbages.
[01:56:43.380 --> 01:56:44.380]   They're good.
[01:56:44.380 --> 01:56:45.380]   They're awful.
[01:56:45.380 --> 01:56:46.380]   They're dreadful.
[01:56:46.380 --> 01:56:52.100]   I think that this is an example, probably green beans too, people wanting to make vegetables
[01:56:52.100 --> 01:56:54.220]   taste good because they want to.
[01:56:54.220 --> 01:56:55.220]   Yeah.
[01:56:55.220 --> 01:56:57.220]   Stacey, Stacey, where are you on brussel sprouts?
[01:56:57.220 --> 01:56:58.220]   I love them.
[01:56:58.220 --> 01:56:59.220]   Me too.
[01:56:59.220 --> 01:57:00.220]   I thought you were your soul health mate.
[01:57:00.220 --> 01:57:01.220]   I make them.
[01:57:01.220 --> 01:57:02.220]   Yeah.
[01:57:02.220 --> 01:57:03.220]   How do you make them?
[01:57:03.220 --> 01:57:04.220]   What makes yours so good?
[01:57:04.220 --> 01:57:08.420]   Oh, well, I have many, but I actually have multiple brussel sprout recipes.
[01:57:08.420 --> 01:57:11.540]   I'm thinking you probably don't make your green bean casserole this way.
[01:57:11.540 --> 01:57:18.260]   A mix of two cans of greens cans of green beans, a can of condensed cream of mushroom
[01:57:18.260 --> 01:57:20.420]   soup, topped with fried onions.
[01:57:20.420 --> 01:57:21.980]   And actually I doubt they're actually fried.
[01:57:21.980 --> 01:57:26.460]   They're probably the cans of fried onions that you get in the store and cheddar cheese
[01:57:26.460 --> 01:57:30.460]   and then you bake it until the cheese melts in the onion brown.
[01:57:30.460 --> 01:57:31.460]   So I don't do that.
[01:57:31.460 --> 01:57:34.100]   I have a lemon dill green bean salad.
[01:57:34.100 --> 01:57:35.100]   Sounds good.
[01:57:35.100 --> 01:57:36.100]   That sounds delicious.
[01:57:36.100 --> 01:57:38.100]   I think you might be a good cook.
[01:57:38.100 --> 01:57:39.100]   Yes.
[01:57:39.100 --> 01:57:41.260]   Like you might be right.
[01:57:41.260 --> 01:57:43.020]   Well, I mean, I can follow a recipe.
[01:57:43.020 --> 01:57:44.020]   You might be.
[01:57:44.020 --> 01:57:45.180]   Even without the fancy of it.
[01:57:45.180 --> 01:57:47.900]   I think you might be a good cook.
[01:57:47.900 --> 01:57:48.980]   How do you make your brussel sprouts?
[01:57:48.980 --> 01:57:49.980]   That's very important.
[01:57:49.980 --> 01:57:52.380]   Bacon and balsamic.
[01:57:52.380 --> 01:57:53.380]   Yep.
[01:57:53.380 --> 01:57:54.380]   That's it.
[01:57:54.380 --> 01:57:55.380]   Sate.
[01:57:55.380 --> 01:57:56.380]   Yeah.
[01:57:56.380 --> 01:57:57.380]   Boom.
[01:57:57.380 --> 01:57:58.380]   That's all you need.
[01:57:58.380 --> 01:57:59.340]   Or but you can also shred them into this lovely little salad.
[01:57:59.340 --> 01:58:00.340]   You can make kind of a brussel.
[01:58:00.340 --> 01:58:01.700]   I love coleslaw all the time.
[01:58:01.700 --> 01:58:02.700]   I love coleslaw.
[01:58:02.700 --> 01:58:03.700]   Yeah.
[01:58:03.700 --> 01:58:04.700]   I love coleslaw.
[01:58:04.700 --> 01:58:06.580]   So it's not weird.
[01:58:06.580 --> 01:58:12.180]   Manays cider vinegar celery seed salt pepper yogurt.
[01:58:12.180 --> 01:58:13.780]   I'll have to try that.
[01:58:13.780 --> 01:58:15.420]   To lighten it up a little for the mayonnaise.
[01:58:15.420 --> 01:58:16.420]   Yeah.
[01:58:16.420 --> 01:58:17.420]   Yeah.
[01:58:17.420 --> 01:58:18.420]   Yeah.
[01:58:18.420 --> 01:58:19.420]   Because you don't want mayonnaise.
[01:58:19.420 --> 01:58:20.420]   No.
[01:58:20.420 --> 01:58:21.420]   Number three.
[01:58:21.420 --> 01:58:22.420]   What's number three?
[01:58:22.420 --> 01:58:23.420]   Oh, wait a minute.
[01:58:23.420 --> 01:58:24.420]   This sounds good.
[01:58:24.420 --> 01:58:25.420]   Brussels sprouts with cheese chestnuts.
[01:58:25.420 --> 01:58:26.420]   And I believe that's pronounced chestnut.
[01:58:26.420 --> 01:58:30.420]   Is it pronounced chestnuts or cheese nuts and pancetta?
[01:58:30.420 --> 01:58:31.420]   And cheddar is just fancy.
[01:58:31.420 --> 01:58:32.420]   Bait.
[01:58:32.420 --> 01:58:34.060]   Wait, you don't like any Brussels sprouts?
[01:58:34.060 --> 01:58:35.060]   Why?
[01:58:35.060 --> 01:58:36.220]   If they are burned to a crisp.
[01:58:36.220 --> 01:58:37.220]   Yeah, they're good that way.
[01:58:37.220 --> 01:58:38.220]   You roast.
[01:58:38.220 --> 01:58:39.220]   They are good.
[01:58:39.220 --> 01:58:40.220]   Well, like a rooster.
[01:58:40.220 --> 01:58:41.220]   Yeah.
[01:58:41.220 --> 01:58:42.520]   Hash brown casserole.
[01:58:42.520 --> 01:58:46.460]   If potatoes good cooked twice, it's even better guacamole.
[01:58:46.460 --> 01:58:47.460]   Number four.
[01:58:47.460 --> 01:58:48.460]   Oh, that makes sense.
[01:58:48.460 --> 01:58:49.460]   Sure.
[01:58:49.460 --> 01:58:50.660]   Did I get the peas one?
[01:58:50.660 --> 01:58:53.580]   No, don't put peas in your guacamole.
[01:58:53.580 --> 01:58:55.100]   That's chicken news, Stacy.
[01:58:55.100 --> 01:58:56.100]   Chicken marcella.
[01:58:56.100 --> 01:59:00.060]   Ah, I'm not sure why that's in there.
[01:59:00.060 --> 01:59:01.980]   These are funny that these are so popular.
[01:59:01.980 --> 01:59:02.980]   Chicken tetra zini.
[01:59:02.980 --> 01:59:05.100]   Yeah, who would I have?
[01:59:05.100 --> 01:59:08.260]   That's like from 40 years ago.
[01:59:08.260 --> 01:59:09.780]   Snow ice cream.
[01:59:09.780 --> 01:59:11.340]   Can you make ice cream with snow?
[01:59:11.340 --> 01:59:13.900]   Yes, we did it with my grandparents when I was a kid.
[01:59:13.900 --> 01:59:14.900]   There you go.
[01:59:14.900 --> 01:59:17.020]   Well, now you can find it on Google.
[01:59:17.020 --> 01:59:18.020]   Buttercream.
[01:59:18.020 --> 01:59:19.580]   That's milked with vanilla extract.
[01:59:19.580 --> 01:59:21.300]   Everything's better with buttercream.
[01:59:21.300 --> 01:59:22.580]   That's true.
[01:59:22.580 --> 01:59:27.620]   As Lisa says, I get so disappointed when I find a cupcake has whipped cream frosting.
[01:59:27.620 --> 01:59:29.420]   Oh, I like whipped cream frosting.
[01:59:29.420 --> 01:59:31.100]   Just breaks my heart, she says.
[01:59:31.100 --> 01:59:32.700]   Breaks my heart.
[01:59:32.700 --> 01:59:33.700]   Pork chops.
[01:59:33.700 --> 01:59:34.700]   What?
[01:59:34.700 --> 01:59:35.700]   Pork chops.
[01:59:35.700 --> 01:59:37.900]   I can pick that out.
[01:59:37.900 --> 01:59:40.060]   Number nine, put them in the oven.
[01:59:40.060 --> 01:59:41.140]   Cook them.
[01:59:41.140 --> 01:59:43.580]   And turkey gravy.
[01:59:43.580 --> 01:59:45.700]   Number 10.
[01:59:45.700 --> 01:59:51.540]   I am proud to, my thing is something totally self-serving, but I'm proud to announce the
[01:59:51.540 --> 01:59:57.140]   grand opening of a permanent Twit merchandise store.
[01:59:57.140 --> 01:59:58.140]   Yay!
[01:59:58.140 --> 02:00:02.140]   We've been doing these one-offs.
[02:00:02.140 --> 02:00:07.100]   And Teespring does a great job with them, but we thought we'd, you know, people want...
[02:00:07.100 --> 02:00:13.300]   So a lot of these are designs that we maybe have sold one at a time in the past.
[02:00:13.300 --> 02:00:15.220]   People have asked for them.
[02:00:15.220 --> 02:00:16.900]   It's not a giant store.
[02:00:16.900 --> 02:00:18.500]   There's not a whole lot.
[02:00:18.500 --> 02:00:21.900]   By the way, we still have five hours left in that Twit army, but we'll add more over time.
[02:00:21.900 --> 02:00:23.900]   I think a lot of things will be in there.
[02:00:23.900 --> 02:00:25.500]   You can go to twit.to/store.
[02:00:25.500 --> 02:00:26.500]   Twit.to/store.
[02:00:26.500 --> 02:00:27.500]   That's Twit.2 store.
[02:00:27.500 --> 02:00:34.500]   And we've got already got some good designs.
[02:00:34.500 --> 02:00:35.980]   This is just in time for the holidays.
[02:00:35.980 --> 02:00:37.660]   They Twit merchandise store.
[02:00:37.660 --> 02:00:40.260]   We got to get Fez's in there, Cap's, other things too.
[02:00:40.260 --> 02:00:41.260]   We will.
[02:00:41.260 --> 02:00:42.260]   Yeah, I want a Cap.
[02:00:42.260 --> 02:00:43.260]   I want a Twit Cap.
[02:00:43.260 --> 02:00:44.260]   I want a Beanie.
[02:00:44.260 --> 02:00:45.260]   A Beanie?
[02:00:45.260 --> 02:00:47.100]   You with a propeller?
[02:00:47.100 --> 02:00:48.900]   No, no, no.
[02:00:48.900 --> 02:00:49.900]   I usually have one.
[02:00:49.900 --> 02:00:50.900]   Like a little...
[02:00:50.900 --> 02:00:51.900]   Like, you know, like a little...
[02:00:51.900 --> 02:00:52.900]   Skoll Cap.
[02:00:52.900 --> 02:00:53.900]   Skoll Cap.
[02:00:53.900 --> 02:00:54.900]   Yeah.
[02:00:54.900 --> 02:00:55.900]   Oh.
[02:00:55.900 --> 02:00:56.900]   Do you wear beanies?
[02:00:56.900 --> 02:00:57.900]   Skoll Cap ones?
[02:00:57.900 --> 02:00:58.900]   Not the ones with propellers.
[02:00:58.900 --> 02:00:59.900]   I don't have one of those.
[02:00:59.900 --> 02:01:01.100]   Don't you wear a Skoll Cap Beanies?
[02:01:01.100 --> 02:01:02.100]   Yeah.
[02:01:02.100 --> 02:01:03.460]   I'm trying to imagine you in one.
[02:01:03.460 --> 02:01:04.980]   I will wear one next year.
[02:01:04.980 --> 02:01:09.260]   I had two sitting right here and then I moved them because I was cleaning off my desk.
[02:01:09.260 --> 02:01:10.260]   But...
[02:01:10.260 --> 02:01:11.260]   Yeah.
[02:01:11.260 --> 02:01:13.420]   Well, the screen savers gets its own t-shirt.
[02:01:13.420 --> 02:01:14.420]   Yeah.
[02:01:14.420 --> 02:01:15.780]   There's no Twig t-shirt.
[02:01:15.780 --> 02:01:16.780]   We can...
[02:01:16.780 --> 02:01:17.780]   We'll remedy that.
[02:01:17.780 --> 02:01:20.140]   Twig is mentioned on one of these.
[02:01:20.140 --> 02:01:21.140]   Can we do a...
[02:01:21.140 --> 02:01:23.940]   Jeff's face and I'm a Twit.
[02:01:23.940 --> 02:01:24.940]   Oh, I like that.
[02:01:24.940 --> 02:01:25.940]   I like that.
[02:01:25.940 --> 02:01:26.940]   I like that.
[02:01:26.940 --> 02:01:27.940]   That's good.
[02:01:27.940 --> 02:01:28.940]   We'll get more.
[02:01:28.940 --> 02:01:29.940]   This is just the beginning.
[02:01:29.940 --> 02:01:30.940]   No, I just joke in you.
[02:01:30.940 --> 02:01:31.940]   Just have to act hard.
[02:01:31.940 --> 02:01:32.940]   It doesn't have to be Twit.to.
[02:01:32.940 --> 02:01:33.940]   You could also go...
[02:01:33.940 --> 02:01:35.940]   It's somebody says the.to is confusing.
[02:01:35.940 --> 02:01:36.940]   You can also go...
[02:01:36.940 --> 02:01:39.940]   Because that's our URL shorteners Twit.to.
[02:01:39.940 --> 02:01:41.940]   You can also go teespring.com/stores/twit.
[02:01:41.940 --> 02:01:43.940]   How do we get that to you?
[02:01:43.940 --> 02:01:46.940]   Is there a link for your homepage?
[02:01:46.940 --> 02:01:47.940]   Probably.
[02:01:47.940 --> 02:01:48.940]   Okay.
[02:01:48.940 --> 02:01:49.940]   I'm going to go to the top of the screen.
[02:01:49.940 --> 02:01:54.940]   Oh, is it there?
[02:01:54.940 --> 02:01:59.940]   No, that's what someone was asking.
[02:01:59.940 --> 02:02:00.940]   Well, we have those.
[02:02:00.940 --> 02:02:01.940]   I'll send you one.
[02:02:01.940 --> 02:02:02.940]   We have a few extras.
[02:02:02.940 --> 02:02:03.940]   I'm okay.
[02:02:03.940 --> 02:02:07.940]   I only have three Chashkis on my desk, remember?
[02:02:07.940 --> 02:02:09.940]   You see, that's exactly what happened.
[02:02:09.940 --> 02:02:11.940]   Is everybody said, "Oh, Pablo, I want one."
[02:02:11.940 --> 02:02:17.940]   Then we went and actually offered them and they go, "No, I'm good."
[02:02:17.940 --> 02:02:18.940]   It seemed like a good idea at the time.
[02:02:18.940 --> 02:02:19.940]   No, I'm good.
[02:02:19.940 --> 02:02:22.940]   That's how all bobbleheads start.
[02:02:22.940 --> 02:02:23.940]   Yeah.
[02:02:23.940 --> 02:02:27.940]   Well, there's no link, I guess, yet, but there will be.
[02:02:27.940 --> 02:02:28.940]   We'll put a link on there.
[02:02:28.940 --> 02:02:30.940]   You can remember that Twit.to/store.
[02:02:30.940 --> 02:02:33.940]   What is that, Jeff Jarvis, in your lap?
[02:02:33.940 --> 02:02:34.940]   It's my sad moments.
[02:02:34.940 --> 02:02:35.940]   Oh, it's a Hillary bobble.
[02:02:35.940 --> 02:02:37.940]   Yeah, Hillary bobblehead.
[02:02:37.940 --> 02:02:42.940]   We had in our house giant Hillary and Donald Masks.
[02:02:42.940 --> 02:02:44.940]   And I find that rid of him.
[02:02:44.940 --> 02:02:45.940]   That's not scary.
[02:02:45.940 --> 02:02:46.940]   It was creepy me out.
[02:02:46.940 --> 02:02:48.940]   It was creepy me out, man.
[02:02:48.940 --> 02:02:50.940]   I couldn't take it.
[02:02:50.940 --> 02:02:55.940]   Ladies and gentlemen, we come to the end of this fabulous show.
[02:02:55.940 --> 02:02:58.940]   The Snapchat Spectacle episode.
[02:02:58.940 --> 02:03:00.940]   The Spectacle Spectacular.
[02:03:00.940 --> 02:03:03.940]   Spectacle Spectacular!
[02:03:03.940 --> 02:03:07.940]   And yes, my Snapchat handle, I will correct it now, is Leo Laport.
[02:03:07.940 --> 02:03:08.940]   You're more than welcome.
[02:03:08.940 --> 02:03:14.940]   I will probably be doing a story as we're going to fly down to Vegas tonight for my birthday.
[02:03:14.940 --> 02:03:17.940]   We're going to go to one of my favorite restaurants.
[02:03:17.940 --> 02:03:18.940]   What is your birthday?
[02:03:18.940 --> 02:03:20.940]   Well, my birthday was last month.
[02:03:20.940 --> 02:03:22.940]   Oh, that's what I thought.
[02:03:22.940 --> 02:03:24.940]   Joelle Obashon.
[02:03:24.940 --> 02:03:25.940]   Cool.
[02:03:25.940 --> 02:03:29.940]   And we're going to go there and then we're going to go see David Copperfield.
[02:03:29.940 --> 02:03:30.940]   Do some magic.
[02:03:30.940 --> 02:03:31.940]   Don't disappear.
[02:03:31.940 --> 02:03:33.940]   And then we're going to come back.
[02:03:33.940 --> 02:03:38.940]   And I'm going to wear the ridiculous glasses as much as they let me.
[02:03:38.940 --> 02:03:41.940]   Thank you, everybody, for being here.
[02:03:41.940 --> 02:03:43.940]   Thank you, especially Jeff and Stacy.
[02:03:43.940 --> 02:03:45.940]   Now, we have one more show next week.
[02:03:45.940 --> 02:03:47.940]   And then we'll have a couple of weeks off.
[02:03:47.940 --> 02:03:48.940]   I guess one week off.
[02:03:48.940 --> 02:03:49.940]   One week off.
[02:03:49.940 --> 02:03:50.940]   We'll be back on the fifth.
[02:03:50.940 --> 02:03:52.940]   Stacy and I both have January problems.
[02:03:52.940 --> 02:03:53.940]   We'll figure that out.
[02:03:53.940 --> 02:03:55.940]   January problems, don't we all?
[02:03:55.940 --> 02:03:56.940]   You know.
[02:03:56.940 --> 02:04:01.940]   But we do want your help in putting together a best of, best moments.
[02:04:01.940 --> 02:04:04.940]   One of them's got to be Stacy going, "Ooh, ooh, ooh!"
[02:04:04.940 --> 02:04:05.940]   I do it.
[02:04:05.940 --> 02:04:10.940]   Go to twit.tv/bestof and you can, whatever you know, you don't have to fill it all in,
[02:04:10.940 --> 02:04:12.940]   but whatever information you know, it could just be that.
[02:04:12.940 --> 02:04:17.940]   And help our editors put together a fun best of for that.
[02:04:17.940 --> 02:04:20.940]   We'll be airing the week after Christmas, in between Christmas and New Year's.
[02:04:20.940 --> 02:04:23.940]   Twit.tv/bestof.
[02:04:23.940 --> 02:04:24.940]   Thank you, everybody, for being here.
[02:04:24.940 --> 02:04:30.940]   We do the show every Wednesday, 130 Pacific, 430 Eastern time, 2130 UTC.
[02:04:30.940 --> 02:04:33.940]   You can watch on twit.tv live.
[02:04:33.940 --> 02:04:34.940]   You can stream it.
[02:04:34.940 --> 02:04:35.940]   Yes, you can.
[02:04:35.940 --> 02:04:38.940]   You can also be in the chatroom at irc.twit.tv.
[02:04:38.940 --> 02:04:40.940]   You can also see me snap it.
[02:04:40.940 --> 02:04:47.940]   But if you can't be here in person, you can always get it at twit.tv/twig or wherever
[02:04:47.940 --> 02:04:54.940]   finer shows are aggregated for download on your favorite podcatcher.
[02:04:54.940 --> 02:04:55.940]   Thank you, everybody.
[02:04:55.940 --> 02:04:57.940]   We'll see you next time on This Week in Group.
[02:04:57.940 --> 02:04:58.940]   Bye-bye.
[02:04:58.940 --> 02:05:08.940]   [Music]

