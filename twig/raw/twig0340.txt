;FFMETADATA1
title=Mr. Cook, Decrypt this Phone
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=340
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.000]   It's time for Twig this week in Google, Matthew Ingram, Jeff Jarvis and Steve Gibson.
[00:00:05.000 --> 00:00:12.000]   Join us as we talk about, well it's not a Google story but it's a story that affects everybody, including Google.
[00:00:12.000 --> 00:00:15.000]   The Department of Justice's demand.
[00:00:15.000 --> 00:00:19.000]   The courts demand that Apple decrypt a terrorist's iPhone.
[00:00:19.000 --> 00:00:22.000]   You also find out what Google has to say about it.
[00:00:22.000 --> 00:00:24.000]   That's next on Twig.
[00:00:24.000 --> 00:00:28.000]   Netcast you love.
[00:00:28.000 --> 00:00:30.000]   From people you trust.
[00:00:30.000 --> 00:00:35.000]   This is Twig.
[00:00:35.000 --> 00:00:43.000]   Bandwidth for this week in Google is provided by CashFly, C-A-C-H-E-F-L-Y.com.
[00:00:43.000 --> 00:00:46.000]   Hi everybody, it's time for our annual audience survey.
[00:00:46.000 --> 00:00:49.000]   We'd really like to hear from you.
[00:00:49.000 --> 00:00:53.000]   It helps us understand our audience better, know what you like and don't like how you listen to the show.
[00:00:53.000 --> 00:00:57.000]   It also helps us tell advertisers what kind of people listen.
[00:00:57.000 --> 00:01:01.000]   But I promise you, your feedback is always kept personally anonymous.
[00:01:01.000 --> 00:01:06.000]   All you have to do is visit twit.tv/survey and let us know what you think.
[00:01:06.000 --> 00:01:09.000]   It'll just take a few minutes and it'll help us make Twit even better.
[00:01:09.000 --> 00:01:15.000]   We really appreciate your support and any help you can give us twit.tv/survey.
[00:01:15.000 --> 00:01:31.000]   This is Twig. This Week in Google episode 340, recorded Wednesday, February 17, 2016.
[00:01:31.000 --> 00:01:34.000]   Mr. Cook decrypt this phone.
[00:01:36.000 --> 00:01:41.000]   This Week in Google is brought to you by Gazelle, the online marketplace for buying and selling used gadgets
[00:01:41.000 --> 00:01:46.000]   shop from a variety of certified pre-owned electronics or trade one in for cash.
[00:01:46.000 --> 00:01:50.000]   Give new life to a used device at Gazelle.com today.
[00:01:50.000 --> 00:01:57.000]   And by FreshBooks, the super simple cloud accounting software that's giving thousands of freelancers and small businesses
[00:01:57.000 --> 00:02:00.000]   the tools to save time billing and get paid faster.
[00:02:00.000 --> 00:02:04.000]   Try it free at freshbooks.com/twig.
[00:02:04.000 --> 00:02:06.000]   And by Squarespace.
[00:02:06.000 --> 00:02:10.000]   Make your business and online stores stand out with the only platform
[00:02:10.000 --> 00:02:14.000]   that lets you create, manage and brand your store in a beautiful way.
[00:02:14.000 --> 00:02:17.000]   Enter the offer code Twig to get 10% off.
[00:02:17.000 --> 00:02:19.000]   Squarespace. You should.
[00:02:19.000 --> 00:02:22.000]   It's time for Twig this Week in Google.
[00:02:22.000 --> 00:02:25.000]   The home of Tuvann Throat singing.
[00:02:25.000 --> 00:02:28.000]   Joining, and I'll have to explain that another time.
[00:02:28.000 --> 00:02:30.000]   Joining us right now.
[00:02:30.000 --> 00:02:31.000]   Or you can just demonstrate.
[00:02:31.000 --> 00:02:34.000]   Oh, oh, oh, oh.
[00:02:34.000 --> 00:02:39.000]   Jeff Jarvis, the Tuvann Throat singer.
[00:02:39.000 --> 00:02:44.000]   We've been talking about a new theme song and I have found the perfect theme song, but nobody seems to agree with me anyway.
[00:02:44.000 --> 00:02:48.000]   Jeff is from the City University of New York where he teaches journalism.
[00:02:48.000 --> 00:02:56.000]   He's also at the Tao Center and he's also, of course, the author of many great books, including What Would Google Do?
[00:02:56.000 --> 00:02:57.000]   Public parts.
[00:02:57.000 --> 00:03:00.000]   Geeks bearing gifts.
[00:03:00.000 --> 00:03:02.000]   And blogs@buzzmachine.com.
[00:03:02.000 --> 00:03:03.000]   Joining us also.
[00:03:03.000 --> 00:03:05.000]   A former ink stained wretch to himself.
[00:03:05.000 --> 00:03:07.000]   From the Globe and Mail now.
[00:03:07.000 --> 00:03:09.000]   And then Giga Omen now at Fortune.
[00:03:09.000 --> 00:03:11.000]   Mr. Matthew Ingram.
[00:03:11.000 --> 00:03:15.000]   Who, by the way, is just getting better and better.
[00:03:15.000 --> 00:03:17.000]   I'm serious.
[00:03:17.000 --> 00:03:20.000]   I have been, you know, I'll be reading a fortune article on go.
[00:03:20.000 --> 00:03:21.000]   Oh, this must be Matthew.
[00:03:21.000 --> 00:03:23.000]   I'm not kidding.
[00:03:23.000 --> 00:03:26.000]   You have, you have, I think, more than ever.
[00:03:26.000 --> 00:03:31.000]   You have found your voice and your niche, the place you should be, the stuff you're writing about.
[00:03:31.000 --> 00:03:35.000]   You have, it sounds like you kind of can write about whatever you feel like.
[00:03:35.000 --> 00:03:37.000]   More or less.
[00:03:37.000 --> 00:03:38.000]   Yeah.
[00:03:38.000 --> 00:03:40.000]   You're a senior writer there.
[00:03:40.000 --> 00:03:45.000]   You focus on media and technology, so you're writing about the stuff that I read over and over again.
[00:03:45.000 --> 00:03:51.000]   But I just really enjoy your analysis and.
[00:03:51.000 --> 00:03:52.000]   Thanks.
[00:03:52.000 --> 00:03:53.000]   Please go on.
[00:03:53.000 --> 00:04:02.000]   Well, most recent one we talked a lot about last week, the author's guild is still wrong about Google's book scanning.
[00:04:02.000 --> 00:04:12.000]   It was just, it was, if I'll use a readily word, anodyne, it was, it just cut through all of the grease and the fat.
[00:04:12.000 --> 00:04:13.000]   It's a great word.
[00:04:13.000 --> 00:04:15.000]   It is a great word.
[00:04:15.000 --> 00:04:16.000]   Well, there's a, there's so much.
[00:04:16.000 --> 00:04:17.000]   A $50 word.
[00:04:17.000 --> 00:04:19.000]   Yeah, it's a $40.99.
[00:04:19.000 --> 00:04:26.000]   It's, there's a lot of noise and stuff that makes it hard to kind of see right to the core of it.
[00:04:26.000 --> 00:04:29.000]   And this, boom, you just, you nailed it.
[00:04:29.000 --> 00:04:31.000]   And it's like, what are you thinking?
[00:04:31.000 --> 00:04:32.000]   Margaret Atwood.
[00:04:32.000 --> 00:04:33.000]   So you talked about that on the show?
[00:04:33.000 --> 00:04:34.000]   That was pretty wide.
[00:04:34.000 --> 00:04:37.000]   Someone said, oh, are your ears burning?
[00:04:37.000 --> 00:04:40.000]   Your name came up and I wasn't sure what it was about.
[00:04:40.000 --> 00:04:44.000]   Yeah, I can't remember this short tweet, but absolutely great.
[00:04:44.000 --> 00:04:46.000]   And that one's been going on for so long.
[00:04:46.000 --> 00:04:48.000]   I remember writing about it, you know, in 2000.
[00:04:48.000 --> 00:04:50.000]   2005 is when it started.
[00:04:50.000 --> 00:04:51.000]   J. Louise.
[00:04:51.000 --> 00:04:52.000]   Yeah.
[00:04:52.000 --> 00:05:01.000]   But I thought, you know, Denny Chin was, the judge was really exactly right.
[00:05:01.000 --> 00:05:03.000]   And we'll see what happens when this, I don't know.
[00:05:03.000 --> 00:05:09.000]   Part of me actually wants it to go to the Supreme Court, even though I think it shouldn't,
[00:05:09.000 --> 00:05:16.000]   like there's no, but it, but I would love to read the Supreme Court just definitively saying
[00:05:16.000 --> 00:05:23.000]   that the things that Denny Chin said, that the public benefits of this far away, you know,
[00:05:23.000 --> 00:05:24.000]   any copyright concern.
[00:05:24.000 --> 00:05:28.000]   And then that's what copyright, that's the whole point of copyright in the first place.
[00:05:28.000 --> 00:05:31.000]   And what the authors give revenue stream for authors.
[00:05:31.000 --> 00:05:38.000]   And what the authors give is doing and is really taking it, taking to the Supreme Court,
[00:05:38.000 --> 00:05:44.000]   over fair use, over the definition of fair use, which is great because we need more clarifications.
[00:05:44.000 --> 00:05:46.000]   We definitely do, yeah.
[00:05:46.000 --> 00:05:48.000]   On what fair use is, it's not a law.
[00:05:48.000 --> 00:05:52.000]   It's just kind of a doctrine and we need more clarification.
[00:05:52.000 --> 00:05:56.000]   And there's the four factors and so every time you bring it up, someone will say, well,
[00:05:56.000 --> 00:05:57.000]   what's fair use?
[00:05:57.000 --> 00:05:59.000]   And then you just have to go into this long window.
[00:05:59.000 --> 00:06:00.000]   Right.
[00:06:00.000 --> 00:06:04.000]   You know, you can't just say, oh, well, it's like trying to explain encryption to people
[00:06:04.000 --> 00:06:05.000]   these days.
[00:06:05.000 --> 00:06:06.000]   Yeah.
[00:06:06.000 --> 00:06:07.000]   All right.
[00:06:07.000 --> 00:06:08.000]   We got to do it.
[00:06:08.000 --> 00:06:13.000]   I know this is this week in Google, but the biggest story of the week, the day, the week,
[00:06:13.000 --> 00:06:20.000]   the month and probably the year broke this morning and it's a blockbuster.
[00:06:20.000 --> 00:06:21.000]   Yeah.
[00:06:21.000 --> 00:06:28.600]   Judge has ruled that Apple must, Federal Judge and Riverside, California, help the government
[00:06:28.600 --> 00:06:30.640]   unlock and decrypt an iPhone.
[00:06:30.640 --> 00:06:38.440]   This is, in particular, the iPhone 5C used by the man who shot up the, did the terrorist
[00:06:38.440 --> 00:06:45.440]   attack in San Bernardino, shot up the party, the welfare office party.
[00:06:45.440 --> 00:06:50.880]   Apparently, when the FBI searched his apartment, they found his phone.
[00:06:50.880 --> 00:06:52.800]   The phone is locked.
[00:06:52.800 --> 00:07:03.000]   And as with all modern iPhones encrypted, United States magistrate Sherry Pym wrote that Apple
[00:07:03.000 --> 00:07:08.840]   must provide the FBI with a custom firmware that would allow them to brute force the pass
[00:07:08.840 --> 00:07:09.840]   code.
[00:07:09.840 --> 00:07:11.280]   Apple's reason, but this is what she wrote.
[00:07:11.280 --> 00:07:16.320]   Apple's reasonable technical assistance shall, this is a court order, accomplish the following
[00:07:16.320 --> 00:07:17.480]   three important functions.
[00:07:17.480 --> 00:07:23.640]   It will bypass or disable the auto erase function, whether or not it has been enabled.
[00:07:23.640 --> 00:07:27.920]   Two, it will enable the FBI to submit pass codes to the subject device.
[00:07:27.920 --> 00:07:31.880]   See, the problem right now with an iPhone is if you have a lock and a four digit lock
[00:07:31.880 --> 00:07:37.560]   as all it is, the modern iPhones are six, but I think a 5C, probably a four digit lock,
[00:07:37.560 --> 00:07:39.920]   you can't enter the codes fast.
[00:07:39.920 --> 00:07:40.920]   There's a delay.
[00:07:40.920 --> 00:07:44.320]   And if in some cases, if it's, it can be set up so that if you enter the wrong code
[00:07:44.320 --> 00:07:46.240]   ten times, the whole thing is erased.
[00:07:46.240 --> 00:07:49.800]   The FBI quite rightly is saying, oh, we're not going to try to crack this thing because
[00:07:49.800 --> 00:07:51.760]   we don't want it to be erased.
[00:07:51.760 --> 00:07:55.400]   So one, she wants them to bypass the erase, the auto erase.
[00:07:55.400 --> 00:08:00.760]   Two, she wants them to allow it to you, them to use software to try rapid fire, all the
[00:08:00.760 --> 00:08:01.760]   codes.
[00:08:01.760 --> 00:08:05.800]   There are, if it's four digits, there are only 10,000 codes.
[00:08:05.800 --> 00:08:10.280]   And three, ensure that when the FBI submits pass codes, software running on the device
[00:08:10.280 --> 00:08:15.120]   will not purposely introduce any additional delay between attempts beyond what the hardware
[00:08:15.120 --> 00:08:16.120]   does.
[00:08:16.120 --> 00:08:20.000]   In other words, let them brute force it as quickly as possible.
[00:08:20.000 --> 00:08:25.120]   Can I ask a few things here just just for clarity first, points of order.
[00:08:25.120 --> 00:08:31.600]   Number one, unlocking the phone, obviously separate from the encrypted the phone.
[00:08:31.600 --> 00:08:33.240]   No, no.
[00:08:33.240 --> 00:08:34.240]   So here's the deal.
[00:08:34.240 --> 00:08:38.040]   All iPhones are encrypted.
[00:08:38.040 --> 00:08:42.240]   And of course, if they're encrypted, you can't use them until they're decrypted, entering
[00:08:42.240 --> 00:08:44.320]   the pass code decrypts it.
[00:08:44.320 --> 00:08:46.280]   Does decrypted at from that point?
[00:08:46.280 --> 00:08:47.280]   Yes.
[00:08:47.280 --> 00:08:48.280]   And let me, let me.
[00:08:48.280 --> 00:08:51.280]   So in other words, if, if you were able to get somebody's phone, grab it from their
[00:08:51.280 --> 00:08:55.840]   hands, you'd be after they end up pass code, you'd be able to use it and read everything.
[00:08:55.840 --> 00:09:00.520]   As soon as they shut it off or press the just to turn off the screen button, then you need
[00:09:00.520 --> 00:09:01.520]   the pass code again.
[00:09:01.520 --> 00:09:02.520]   And it has now been re-encrypted.
[00:09:02.520 --> 00:09:07.040]   Well, but so all the data on the phone every time you turn it off is re-encrypted.
[00:09:07.040 --> 00:09:08.040]   Yeah.
[00:09:08.040 --> 00:09:09.040]   Yeah, really?
[00:09:09.040 --> 00:09:10.040]   Yeah.
[00:09:10.040 --> 00:09:13.920]   And Apple, I mean, I forget when exactly this happened.
[00:09:13.920 --> 00:09:16.800]   Maybe you know, Leo, but Apple specifically did that.
[00:09:16.800 --> 00:09:17.800]   iOS eight.
[00:09:17.800 --> 00:09:24.040]   So that your, so that no one could get into your phone, including the government.
[00:09:24.040 --> 00:09:25.040]   Here's the problem.
[00:09:25.040 --> 00:09:30.600]   Apple had a long waiting list of law enforcement officials who were asking them to decrypt
[00:09:30.600 --> 00:09:35.560]   phones and at the time, or unlock, sorry, not decrypt, unlock phones.
[00:09:35.560 --> 00:09:38.680]   And at the time, Apple had the technical means to do so.
[00:09:38.680 --> 00:09:42.880]   So they modified iOS with, I believe it was iOS eight, I'm almost positive.
[00:09:42.880 --> 00:09:48.160]   So that it by default, encrypted phones and Apple would no longer have the ability to
[00:09:48.160 --> 00:09:50.760]   decrypt because they didn't want to do it.
[00:09:50.760 --> 00:09:52.800]   So then they can just say, we don't have the key.
[00:09:52.800 --> 00:09:53.800]   Right.
[00:09:53.800 --> 00:09:56.240]   Whereas before they would have to say, well, we don't want to do that.
[00:09:56.240 --> 00:09:57.240]   And here's why.
[00:09:57.240 --> 00:09:59.280]   Now it's just we can't.
[00:09:59.280 --> 00:10:01.400]   Well, except right.
[00:10:01.400 --> 00:10:02.400]   That they can't.
[00:10:02.400 --> 00:10:03.400]   Yes.
[00:10:03.400 --> 00:10:06.240]   Because the judge has written this order and I've seen a number of experts.
[00:10:06.240 --> 00:10:10.440]   I'm not qualified to weigh in on this, but I've seen a number of experts write pieces
[00:10:10.440 --> 00:10:12.040]   to say, yeah, they could do this.
[00:10:12.040 --> 00:10:13.720]   And in fact, Tim Cook implies that.
[00:10:13.720 --> 00:10:18.840]   Here's the message Tim Cook posted this morning on Apple's site.
[00:10:18.840 --> 00:10:22.720]   The United States government has demanded that Apple take an unprecedented step, which
[00:10:22.720 --> 00:10:25.440]   threatens the security of our customers.
[00:10:25.440 --> 00:10:29.520]   We oppose this order, which has implications far beyond the legal case at hand.
[00:10:29.520 --> 00:10:32.760]   This moment calls for public discussion, by the way, that's what we're going to do right
[00:10:32.760 --> 00:10:34.400]   now.
[00:10:34.400 --> 00:10:37.560]   And we want our customers and people around the country to understand what's at stake,
[00:10:37.560 --> 00:10:39.480]   the need for encryption.
[00:10:39.480 --> 00:10:44.640]   I'm going to read the whole thing, but I'll try to jump around a little bit because it's
[00:10:44.640 --> 00:10:47.360]   kind of long.
[00:10:47.360 --> 00:10:51.200]   But the need for encryption, smartphones led by iPhone and become an essential part of
[00:10:51.200 --> 00:10:52.200]   our lives.
[00:10:52.200 --> 00:10:56.160]   People store a lot of stuff on them, including financial information and health data.
[00:10:56.160 --> 00:11:00.240]   All that information needs to be protected from hackers and criminals.
[00:11:00.240 --> 00:11:06.760]   Customers expect Apple and others to do everything in our power to protect their personal information.
[00:11:06.760 --> 00:11:10.720]   Realizing the security of our personal information, compute our personal safety at risk, this
[00:11:10.720 --> 00:11:16.560]   is why encryption is so important to all of us.
[00:11:16.560 --> 00:11:19.840]   We have even put the data out of our own reach, out of Apple's reach, because we believe the
[00:11:19.840 --> 00:11:24.240]   contents of iPhone are none of our business, your iPhone, not our business.
[00:11:24.240 --> 00:11:26.640]   Okay, that's good.
[00:11:26.640 --> 00:11:27.640]   San Bernardino case.
[00:11:27.640 --> 00:11:30.640]   We were shocked and outraged by the deadly act of terrorism in San Bernardino.
[00:11:30.640 --> 00:11:31.920]   We mourn the loss of life.
[00:11:31.920 --> 00:11:33.160]   We've worked to support the government.
[00:11:33.160 --> 00:11:35.400]   We have no sympathy for terrorists.
[00:11:35.400 --> 00:11:39.280]   When the FBI has requested data that's in our possession, we've provided it.
[00:11:39.280 --> 00:11:42.600]   Apple complies with valid subpoenas and search warrants.
[00:11:42.600 --> 00:11:45.400]   We've also made Apple engineers available to advise the FBI.
[00:11:45.400 --> 00:11:48.920]   We've offered our best ideas and a number of investigative options at their disposal.
[00:11:48.920 --> 00:11:51.680]   We have great respect for the FBI.
[00:11:51.680 --> 00:11:56.240]   But now the US government has asked us for something we simply do not have and something
[00:11:56.240 --> 00:11:58.720]   we continue to consider to dangerous to create.
[00:11:58.720 --> 00:12:00.280]   That's an important phrase.
[00:12:00.280 --> 00:12:02.200]   That's the key of it all.
[00:12:02.200 --> 00:12:05.960]   We don't have it, but we could create it is how I'm reading that.
[00:12:05.960 --> 00:12:13.600]   So effectively he's saying that Apple would have to create a customized version of iOS
[00:12:13.600 --> 00:12:17.040]   that would allow the things that the court order specifically mentions.
[00:12:17.040 --> 00:12:20.160]   And apparently could put it on retroactively on this 5C.
[00:12:20.160 --> 00:12:21.360]   That's what puzzles me.
[00:12:21.360 --> 00:12:22.360]   Yeah.
[00:12:22.360 --> 00:12:24.360]   Yeah, I don't get that either.
[00:12:24.360 --> 00:12:30.120]   What Apple's saying, and I think what security experts are saying, is once Apple creates
[00:12:30.120 --> 00:12:34.200]   that, it's not like it will just get destroyed.
[00:12:34.200 --> 00:12:35.920]   It will live somewhere.
[00:12:35.920 --> 00:12:37.160]   Someone could get their hands on it.
[00:12:37.160 --> 00:12:42.440]   That ability could become available to others, not just to the FBI.
[00:12:42.440 --> 00:12:43.880]   And this is what Tim Cooksius says.
[00:12:43.880 --> 00:12:47.680]   The FBI may use different words to describe his tool, but make no mistake, building a
[00:12:47.680 --> 00:12:53.120]   version of iOS that bypasses security in this way would undeniably create a backdoor.
[00:12:53.120 --> 00:12:56.240]   And while government may argue that it's use would be limited to this case, there's no
[00:12:56.240 --> 00:12:58.920]   way to guarantee such control.
[00:12:58.920 --> 00:13:02.920]   Then that, that, that ladies and gentlemen is the key point.
[00:13:02.920 --> 00:13:03.920]   Right.
[00:13:03.920 --> 00:13:06.440]   I am going to say something you may surprise you.
[00:13:06.440 --> 00:13:10.320]   I think Apple has to and must and should do this.
[00:13:10.320 --> 00:13:16.160]   If Apple has the means to decrypt that phone, which they're, I think admitting they do,
[00:13:16.160 --> 00:13:22.600]   not only are they required to by law, ethically and morally, they are, they ought to do it.
[00:13:22.600 --> 00:13:27.120]   And I know you play, I know you play devil's advocate in these cases, but I don't think
[00:13:27.120 --> 00:13:31.480]   you're going to want to go on the record forever of asking for a permanent backdoor to, to
[00:13:31.480 --> 00:13:33.520]   that's not what's being asked for.
[00:13:33.520 --> 00:13:37.280]   And that's, I think, disingenuous of Tim Cook to imply it.
[00:13:37.280 --> 00:13:38.680]   They're not decrypting, though, right?
[00:13:38.680 --> 00:13:42.880]   They're going to set it up so that the FBI can brute force the password.
[00:13:42.880 --> 00:13:43.880]   Exactly.
[00:13:43.880 --> 00:13:47.960]   And it's with a valid court order.
[00:13:47.960 --> 00:13:52.800]   Now, the question is, does Apple keep cut?
[00:13:52.800 --> 00:13:57.400]   By the way, this puts us in a no different situation than we were in just a year or two
[00:13:57.400 --> 00:14:01.720]   ago with iOS, seven and previous iOS eight.
[00:14:01.720 --> 00:14:05.720]   He puts us in exactly the same position and I would submit we were in no greater risk.
[00:14:05.720 --> 00:14:09.560]   And where Snowden has told us that in the meantime, let me ask one more, one more point
[00:14:09.560 --> 00:14:14.400]   of order, your honor, or chairman or whatever you do in Roberts rules of order.
[00:14:14.400 --> 00:14:18.120]   What is it they could want out of that phone?
[00:14:18.120 --> 00:14:20.640]   Anything that was done in terms of phone calls, there's a separate record of the phone
[00:14:20.640 --> 00:14:24.200]   company, anything done in terms of texts and any communications, there are separate records
[00:14:24.200 --> 00:14:27.200]   elsewhere that they can subpoena elsewhere.
[00:14:27.200 --> 00:14:30.840]   Now, if they, if they, yeah, that's a good one.
[00:14:30.840 --> 00:14:35.160]   What if he went around taking pictures of the crime scene ahead of time?
[00:14:35.160 --> 00:14:37.080]   So so what is that?
[00:14:37.080 --> 00:14:38.080]   What does that give them the case?
[00:14:38.080 --> 00:14:39.080]   The people are dead.
[00:14:39.080 --> 00:14:40.080]   It's a separate.
[00:14:40.080 --> 00:14:42.000]   Let me keep going for one more second, one more second.
[00:14:42.000 --> 00:14:47.440]   So so you can get any communications elsewhere.
[00:14:47.440 --> 00:14:52.280]   If they sent encrypted email, that is a separate act of encryption, right?
[00:14:52.280 --> 00:14:59.400]   So that doesn't, that doesn't, that this doesn't unlock that without that private key.
[00:14:59.400 --> 00:15:02.400]   And so what is it that they expect to get out of this?
[00:15:02.400 --> 00:15:07.200]   So, so this is a very important precedent being set around technology and around safety of
[00:15:07.200 --> 00:15:09.960]   our technologies, especially knowing what we know now.
[00:15:09.960 --> 00:15:14.640]   Thank you, Edward Snowden, about the NSA and DC HQ and what we know about China and Iran
[00:15:14.640 --> 00:15:16.120]   and other countries.
[00:15:16.120 --> 00:15:21.320]   And so I would just suggest you weigh carefully the balance here to say that this is a huge
[00:15:21.320 --> 00:15:26.280]   and important precedent for what end the miscreants are dead.
[00:15:26.280 --> 00:15:27.280]   Are there others involved?
[00:15:27.280 --> 00:15:29.720]   Well, that would, that would be an extra communication.
[00:15:29.720 --> 00:15:30.920]   There are others involved.
[00:15:30.920 --> 00:15:36.160]   There is a man under arrest for providing them with the weapons.
[00:15:36.160 --> 00:15:37.160]   I think it's what it is.
[00:15:37.160 --> 00:15:38.160]   They expect to get here.
[00:15:38.160 --> 00:15:42.400]   They expect to get evidence that would convict this fellow of selling them or providing them
[00:15:42.400 --> 00:15:43.400]   with the weapons.
[00:15:43.400 --> 00:15:46.840]   But that's the guy is facing trial for that.
[00:15:46.840 --> 00:15:51.040]   And they are quite reasonably saying the evidence may be on this phone and we would like access
[00:15:51.040 --> 00:15:52.040]   to this phone.
[00:15:52.040 --> 00:15:56.760]   Let me ask you this, Jeff, would you submit suggest that the, that if with a do warrant,
[00:15:56.760 --> 00:16:02.120]   police should not be allowed to search your premises, even in a locked box on your premises?
[00:16:02.120 --> 00:16:03.120]   It with a do warrant fine.
[00:16:03.120 --> 00:16:07.160]   But if that, if that, if the way they got in the lock box was a master key that could
[00:16:07.160 --> 00:16:10.160]   open any house and any box in any country.
[00:16:10.160 --> 00:16:11.160]   So that's the key.
[00:16:11.160 --> 00:16:12.640]   It's not just this case.
[00:16:12.640 --> 00:16:19.520]   It's that it's that Apple is being required to create a master key that could unlock any
[00:16:19.520 --> 00:16:21.360]   phone, not just this.
[00:16:21.360 --> 00:16:24.480]   And so, and so it, it's interesting.
[00:16:24.480 --> 00:16:30.160]   Art's Technica mentioned in their piece, which is quite good, that Apple has received
[00:16:30.160 --> 00:16:33.920]   multiple requests very similar to this one.
[00:16:33.920 --> 00:16:36.480]   Like recently, and it's probably going to get more.
[00:16:36.480 --> 00:16:38.480]   So it's not just this case.
[00:16:38.480 --> 00:16:42.560]   Whatever happens in this case is going to create a precedent that then makes it easier
[00:16:42.560 --> 00:16:46.920]   for other security agencies to do the same thing to other phones.
[00:16:46.920 --> 00:16:48.560]   It's a couple of things.
[00:16:48.560 --> 00:16:53.840]   First of all, Apple has probably unwittingly revealed something that is kind of a shock
[00:16:53.840 --> 00:16:58.640]   to me, which is that this process apparently can be reversed, that they in fact have the
[00:16:58.640 --> 00:17:00.800]   capability of doing this.
[00:17:00.800 --> 00:17:04.280]   They're just in effect denying it to the government, but they have this capability or
[00:17:04.280 --> 00:17:07.640]   they haven't yet written the tool, but they know how to do it.
[00:17:07.640 --> 00:17:08.960]   That's quite surprising.
[00:17:08.960 --> 00:17:12.720]   Normally, their defense has been, we don't, we can't do it, we don't know how to do it,
[00:17:12.720 --> 00:17:14.360]   there is no way to do it.
[00:17:14.360 --> 00:17:15.360]   That's not what they're saying.
[00:17:15.360 --> 00:17:17.440]   They're saying they choose not to do it.
[00:17:17.440 --> 00:17:21.560]   A, B, there is a legitimate court order.
[00:17:21.560 --> 00:17:26.760]   It's the job of a federal judge to weigh these matters, not you or me.
[00:17:26.760 --> 00:17:30.480]   It's a job of a federal judge, and that's the constitution of this country.
[00:17:30.480 --> 00:17:36.680]   And the rule of law in this country is that we let judges make this determination that
[00:17:36.680 --> 00:17:38.840]   law enforcement comes to them and says,
[00:17:38.840 --> 00:17:43.800]   this is your honor, the case we're pursuing and why is this reasonable search and seizure.
[00:17:43.800 --> 00:17:46.760]   The judge has ruled that it is this is appealable as hell.
[00:17:46.760 --> 00:17:47.760]   Well, it's appealable.
[00:17:47.760 --> 00:17:48.760]   We're going to appeal.
[00:17:48.760 --> 00:17:51.800]   And if it goes to the Supreme Court and the Supreme Court agrees, would you then go along
[00:17:51.800 --> 00:17:52.800]   with it?
[00:17:52.800 --> 00:17:53.800]   At that point, there is no choice.
[00:17:53.800 --> 00:17:54.800]   Yes.
[00:17:54.800 --> 00:17:58.000]   But then that's the country that I'm afraid that Donald Trump is friggin running.
[00:17:58.000 --> 00:17:59.000]   I disagree.
[00:17:59.000 --> 00:18:04.920]   I think that we have, of course, under the Bill of Rights, rights against unreasonable
[00:18:04.920 --> 00:18:12.040]   seats and search and seizure and those very specifically, the Bill of Rights sets a process
[00:18:12.040 --> 00:18:14.080]   for reasonable search and seizure.
[00:18:14.080 --> 00:18:16.880]   There is such a thing as reasonable search and seizure.
[00:18:16.880 --> 00:18:18.600]   It has to be the process.
[00:18:18.600 --> 00:18:20.480]   There has to be probable cause.
[00:18:20.480 --> 00:18:24.960]   And under those circumstances, there is currently a way to reasonably search your home,
[00:18:24.960 --> 00:18:26.520]   reasonably search your stuff.
[00:18:26.520 --> 00:18:28.760]   Alan's two coulds here.
[00:18:28.760 --> 00:18:34.880]   One could, you said is there could be information on that phone that might involve one trial.
[00:18:34.880 --> 00:18:36.640]   Balance Matthews could.
[00:18:36.640 --> 00:18:40.920]   This could be used by authorities good and bad and powers good and bad to unlock every
[00:18:40.920 --> 00:18:43.520]   frigging iPhone in the world.
[00:18:43.520 --> 00:18:44.520]   Reasonable search and seizure.
[00:18:44.520 --> 00:18:48.640]   I would call that an unreasonable search and seizure because the impact on society is worse
[00:18:48.640 --> 00:18:50.640]   than this one case.
[00:18:50.640 --> 00:18:51.640]   Yeah.
[00:18:51.640 --> 00:18:53.280]   And that needs to be discussed and adjudicated.
[00:18:53.280 --> 00:18:58.440]   If it was just unlocking this phone, I think we would all agree that it's in the interest
[00:18:58.440 --> 00:19:02.320]   of the courts and law enforcement and society in general to unlock this.
[00:19:02.320 --> 00:19:03.320]   Okay.
[00:19:03.320 --> 00:19:04.320]   Okay.
[00:19:04.320 --> 00:19:10.520]   So you both agree that if we could just do it for this one phone and it did nothing else,
[00:19:10.520 --> 00:19:16.040]   if there were, if there were a piece of data to the air, some ability to do this otherwise,
[00:19:16.040 --> 00:19:17.040]   you would be okay with it.
[00:19:17.040 --> 00:19:23.280]   Some data that let Apple say, oh yes, we happen to have their code in their on-premises.
[00:19:23.280 --> 00:19:24.280]   So my fear.
[00:19:24.280 --> 00:19:28.480]   And we'll give you the, you know, whatever data you ask for about that person that's open,
[00:19:28.480 --> 00:19:29.480]   we'll give you.
[00:19:29.480 --> 00:19:30.480]   And I'm curious.
[00:19:30.480 --> 00:19:32.160]   I'm not that phone, Dandy.
[00:19:32.160 --> 00:19:38.440]   My fear is the FBI or the NSA or whoever is going to say to Apple, can we just have that
[00:19:38.440 --> 00:19:44.240]   thing that you made that's that's that's that's why we have judges.
[00:19:44.240 --> 00:19:45.480]   That's why we have the bill of rights.
[00:19:45.480 --> 00:19:47.480]   But there's protections against that.
[00:19:47.480 --> 00:19:50.400]   But there's protections against all kinds of things that happen routinely.
[00:19:50.400 --> 00:19:56.440]   Well, I think we should take guns away from all police officers because Leo, Leo, here's
[00:19:56.440 --> 00:19:57.440]   the issue.
[00:19:57.440 --> 00:19:58.440]   So this is Matthew's.
[00:19:58.440 --> 00:20:00.400]   But fine, you've got your American judges and they're wonderful.
[00:20:00.400 --> 00:20:01.880]   They're exceptional and we're special.
[00:20:01.880 --> 00:20:02.880]   We do nothing wrong.
[00:20:02.880 --> 00:20:07.480]   But once this capability exists, it will be the law of the land in China, China and Iran
[00:20:07.480 --> 00:20:09.760]   and Russia like that.
[00:20:09.760 --> 00:20:10.760]   That's the issue.
[00:20:10.760 --> 00:20:11.760]   This is worldwide.
[00:20:11.760 --> 00:20:13.840]   We can't act isolated that, oh, everything's okay here in the US.
[00:20:13.840 --> 00:20:15.200]   In this case, it's fine here.
[00:20:15.200 --> 00:20:19.760]   If that capability exists, every government that can will demand it under law.
[00:20:19.760 --> 00:20:28.680]   I think it's unconscionable for a private company to decide on its own to defy the legal system
[00:20:28.680 --> 00:20:31.840]   in this country and say, no, we're not going to do it.
[00:20:31.840 --> 00:20:32.840]   I think that's unconscionable.
[00:20:32.840 --> 00:20:33.840]   They're going to want to deal with that.
[00:20:33.840 --> 00:20:34.840]   I think that cannot be allowed.
[00:20:34.840 --> 00:20:36.360]   That's because, personally, within their rights.
[00:20:36.360 --> 00:20:41.440]   And at some point, if they're compelled to do so, well, let's say this is the discussion
[00:20:41.440 --> 00:20:45.360]   we need is because of these are implications that should be brought up and the EFFs of
[00:20:45.360 --> 00:20:49.920]   the world and others of the world are going to be friends of the court like crazy smashing
[00:20:49.920 --> 00:20:52.120]   down the doors to say, wait.
[00:20:52.120 --> 00:20:55.800]   And I understand the implications and the precedent of what you're doing here.
[00:20:55.800 --> 00:21:00.360]   But I do want to separate from the conversation, though, is a lot of this comes from this kind
[00:21:00.360 --> 00:21:04.520]   of mistrust of government because of Edward Snowden.
[00:21:04.520 --> 00:21:06.440]   I understand that.
[00:21:06.440 --> 00:21:12.120]   But that is not a legal ground for defying the law.
[00:21:12.120 --> 00:21:14.320]   That is merely a mistrust of government.
[00:21:14.320 --> 00:21:19.920]   And as soon as we allow mistrust of government to run this country, then we have a much larger
[00:21:19.920 --> 00:21:20.920]   thing.
[00:21:20.920 --> 00:21:21.920]   What do you think we got?
[00:21:21.920 --> 00:21:26.240]   I think we got the inability of government to do wiretaps without warrants.
[00:21:26.240 --> 00:21:31.360]   It was because of exactly a case like this where they bugged a phone booth.
[00:21:31.360 --> 00:21:32.360]   Do we stop all warrants?
[00:21:32.360 --> 00:21:33.360]   Do we need to trust government?
[00:21:33.360 --> 00:21:34.360]   Should we stop all warrants?
[00:21:34.360 --> 00:21:35.360]   Should we stop all warrants?
[00:21:35.360 --> 00:21:36.360]   Should we stop all wiretaps?
[00:21:36.360 --> 00:21:37.640]   Oh, here's the limit.
[00:21:37.640 --> 00:21:41.640]   Well, the way the NSA is done, you bet your bloody bibwe show.
[00:21:41.640 --> 00:21:42.640]   Yes.
[00:21:42.640 --> 00:21:44.880]   And we put limits on them.
[00:21:44.880 --> 00:21:49.320]   And that was the problem with warrantless wiretapping that was done by the NSA was exactly
[00:21:49.320 --> 00:21:50.320]   that.
[00:21:50.320 --> 00:21:55.000]   The laws were passed, of which we have no awareness in a secret court that did this.
[00:21:55.000 --> 00:22:00.120]   This all goes to the definition of reasonable, you know, reasonable is going to be redefined.
[00:22:00.120 --> 00:22:01.680]   And who's making the decision?
[00:22:01.680 --> 00:22:03.760]   We don't have access to FISA court rulings.
[00:22:03.760 --> 00:22:06.120]   We don't have access to what they're criteria.
[00:22:06.120 --> 00:22:07.560]   If they decide, I'm not sensitive.
[00:22:07.560 --> 00:22:10.960]   I'm not sensitive to have this ability for every phone, right?
[00:22:10.960 --> 00:22:13.760]   And they convince Apple to give them the master key.
[00:22:13.760 --> 00:22:14.760]   We will never know.
[00:22:14.760 --> 00:22:15.760]   Yeah.
[00:22:15.760 --> 00:22:20.160]   And I'm not insensitive to all of these allegations and the and the in appropriateness of the
[00:22:20.160 --> 00:22:21.160]   FISA court.
[00:22:21.160 --> 00:22:22.840]   And we should fight the FISA court.
[00:22:22.840 --> 00:22:27.760]   But that's a separate, in my opinion, they all have this same tool in Leo.
[00:22:27.760 --> 00:22:32.000]   The FISA court can come and say, ah, now that exists, we will secretly ask for it for lots
[00:22:32.000 --> 00:22:33.000]   and lots and lots of phones.
[00:22:33.000 --> 00:22:34.160]   And you'll never know it.
[00:22:34.160 --> 00:22:36.640]   And therein lies the problem.
[00:22:36.640 --> 00:22:39.480]   It opens the pandora's box.
[00:22:39.480 --> 00:22:42.680]   It on the show, which we put it, the encrypts Pandora's box.
[00:22:42.680 --> 00:22:46.360]   Apple has five days to respond and they haven't yet formally responded.
[00:22:46.360 --> 00:22:49.720]   They've written this public, this open letter.
[00:22:49.720 --> 00:22:53.040]   I don't think that's the proper way to influence the judicial process.
[00:22:53.040 --> 00:22:54.040]   They're certainly.
[00:22:54.040 --> 00:22:56.120]   I'm sure they're doing things behind the scenes as well.
[00:22:56.120 --> 00:22:57.120]   This is a public country.
[00:22:57.120 --> 00:22:59.200]   I don't think it's exactly the problem.
[00:22:59.200 --> 00:23:01.920]   But I think this, I think, well, would you disagree?
[00:23:01.920 --> 00:23:03.160]   See, this is the thing that worries me.
[00:23:03.160 --> 00:23:08.640]   Would you disagree if it, uh, it, Apple appeals and ends up in the Supreme court.
[00:23:08.640 --> 00:23:10.000]   The Supreme court rules the same way.
[00:23:10.000 --> 00:23:11.200]   Would you at that point?
[00:23:11.200 --> 00:23:12.200]   Then what would you disagree?
[00:23:12.200 --> 00:23:14.000]   Oh, I'll disagree to my heart's content.
[00:23:14.000 --> 00:23:17.000]   But when, when Steve Cook says I'm not going to jail, I'll follow the law.
[00:23:17.000 --> 00:23:18.760]   I'll, I'll, I'll understand fully what he's doing.
[00:23:18.760 --> 00:23:19.760]   I'll just hate it.
[00:23:19.760 --> 00:23:20.760]   Right.
[00:23:20.760 --> 00:23:21.760]   That's, that's what it is.
[00:23:21.760 --> 00:23:22.760]   Yes.
[00:23:22.760 --> 00:23:26.920]   But, but knowing what we know now about how our government has behaved, knowing what we
[00:23:26.920 --> 00:23:28.600]   know over now about secret courts.
[00:23:28.600 --> 00:23:32.840]   Thank you, Edward Snowden, knowing what we know now about the differences in technology
[00:23:32.840 --> 00:23:34.200]   and the precedent could be set here.
[00:23:34.200 --> 00:23:36.280]   Because there isn't, we're trying to make analog to the real world.
[00:23:36.280 --> 00:23:39.400]   Oh, there's going to be a single skeleton key that gets into every lock in the world.
[00:23:39.400 --> 00:23:41.040]   Now let me, that's, that's impractical.
[00:23:41.040 --> 00:23:44.400]   Let me give you, let me give you now, let me give you an additional fact and see what
[00:23:44.400 --> 00:23:46.400]   you say.
[00:23:46.400 --> 00:23:50.840]   Apple says the only reason we can do this is because it's an old phone.
[00:23:50.840 --> 00:23:52.640]   It's iOS seven.
[00:23:52.640 --> 00:23:56.600]   Worthy iOS eight or nine, you could ask all you want.
[00:23:56.600 --> 00:23:57.600]   We couldn't do it.
[00:23:57.600 --> 00:23:58.600]   Yeah.
[00:23:58.600 --> 00:24:01.800]   Only reason we can do this is because it's iOS seven.
[00:24:01.800 --> 00:24:02.800]   Now what they're saying?
[00:24:02.800 --> 00:24:03.800]   Yeah.
[00:24:03.800 --> 00:24:04.800]   That is what they're saying.
[00:24:04.800 --> 00:24:05.800]   So that is the case.
[00:24:05.800 --> 00:24:06.800]   No, Apple's not saying anything.
[00:24:06.800 --> 00:24:07.800]   That is the case.
[00:24:07.800 --> 00:24:08.800]   That is the case.
[00:24:08.800 --> 00:24:09.800]   This is an iOS seven phone.
[00:24:09.800 --> 00:24:15.120]   Apple actually did say this in a filing with the judge that it's impossible to do this for
[00:24:15.120 --> 00:24:20.320]   iOS eight or nine, but it can't, but it only can do this because this is an old phone running
[00:24:20.320 --> 00:24:21.320]   iOS seven.
[00:24:21.320 --> 00:24:23.360]   That's only 10% of the current phones out there.
[00:24:23.360 --> 00:24:24.360]   Now what do you say?
[00:24:24.360 --> 00:24:27.640]   So I guess all the terrorists are going to upgrade pretty quickly.
[00:24:27.640 --> 00:24:28.640]   Yeah.
[00:24:28.640 --> 00:24:31.720]   Well, these were dumb terrorists for damn sure.
[00:24:31.720 --> 00:24:36.760]   My concern remains the, the larger precedent that is set here that the, if a capability
[00:24:36.760 --> 00:24:41.600]   opens up to ruin encryption, can the government enforce us to do that?
[00:24:41.600 --> 00:24:44.600]   That were concerned me at any level.
[00:24:44.600 --> 00:24:51.880]   I have to say, by the way, there's Apple have any particular secret sauce here that the
[00:24:51.880 --> 00:24:56.960]   NSA and its geniuses don't have on their own or the CIA or the FBI or any of those places.
[00:24:56.960 --> 00:24:59.320]   Is what they're, why they just asked this?
[00:24:59.320 --> 00:25:03.000]   What does Apple know that they're going to just brute force it themselves?
[00:25:03.000 --> 00:25:04.200]   What is it that they can do?
[00:25:04.200 --> 00:25:06.280]   Do we say Apple's Apple?
[00:25:06.280 --> 00:25:11.960]   So the court order specifically asks Apple to make it easier for the FBI to brute force
[00:25:11.960 --> 00:25:13.160]   the password.
[00:25:13.160 --> 00:25:14.160]   So explain that.
[00:25:14.160 --> 00:25:17.160]   So to remove the restrictions, to remove.
[00:25:17.160 --> 00:25:22.760]   So if you type the password or unlock code too quickly, all these things happen.
[00:25:22.760 --> 00:25:23.560]   So I have to repeat it.
[00:25:23.560 --> 00:25:26.200]   So basically, right, you repeat it too many times.
[00:25:26.200 --> 00:25:27.360]   You do it too quickly.
[00:25:27.360 --> 00:25:31.560]   So the, the order would remove would force Apple to remove those restrictions, not to
[00:25:31.560 --> 00:25:34.640]   unlock it, just to make it easier for the FBI to do it.
[00:25:34.640 --> 00:25:39.960]   Because if, if they had to brute force it, so to fight for some, like 15 years.
[00:25:39.960 --> 00:25:44.680]   Okay, so then to play devil's advocate with the devil Leo for a second, then Apple's
[00:25:44.680 --> 00:25:46.080]   not decrypting the phone.
[00:25:46.080 --> 00:25:48.120]   Apple is enabling them to do so.
[00:25:48.120 --> 00:25:49.120]   Right.
[00:25:49.120 --> 00:25:50.120]   By just making it easier.
[00:25:50.120 --> 00:25:52.640]   Well, Apple's software will decrypt it.
[00:25:52.640 --> 00:25:54.600]   It's allowing them to brute force the lock.
[00:25:54.600 --> 00:25:55.600]   Right.
[00:25:55.600 --> 00:25:56.600]   Yeah.
[00:25:56.600 --> 00:25:59.240]   And it is interesting that this would not apply to every phone.
[00:25:59.240 --> 00:26:05.720]   What if there were a lock box in your house that had a very strong and known to be very
[00:26:05.720 --> 00:26:13.160]   difficult to break lock, but the law enforcement needed to get in that lock box and, and subpoenaed
[00:26:13.160 --> 00:26:21.720]   the lockmaker to help them crack the lock.
[00:26:21.720 --> 00:26:27.800]   What would, what would, how would you feel about that?
[00:26:27.800 --> 00:26:29.640]   Now they have a search warrant in the end.
[00:26:29.640 --> 00:26:31.240]   They have the right to see this.
[00:26:31.240 --> 00:26:32.400]   In the end.
[00:26:32.400 --> 00:26:33.400]   It's locked.
[00:26:33.400 --> 00:26:34.400]   Technically locked.
[00:26:34.400 --> 00:26:35.400]   Yeah.
[00:26:35.400 --> 00:26:36.400]   Would it apply to the only that law?
[00:26:36.400 --> 00:26:37.800]   Any right to privacy.
[00:26:37.800 --> 00:26:39.320]   Can we go walking in the woods?
[00:26:39.320 --> 00:26:41.320]   I don't think that is the larger question.
[00:26:41.320 --> 00:26:42.320]   Truthfully.
[00:26:42.320 --> 00:26:47.200]   I think there's actually a very large question that worries me considerably, which is that
[00:26:47.200 --> 00:26:48.760]   we have a rule of law.
[00:26:48.760 --> 00:26:53.400]   Now, I, I think that it's very much complicated by the international points you brought up.
[00:26:53.400 --> 00:26:54.400]   Yes.
[00:26:54.400 --> 00:26:56.000]   And I'm going to, I'm very concerned.
[00:26:56.000 --> 00:27:01.040]   Table that momentarily, but I feel that we have a rule of law in this country that is
[00:27:01.040 --> 00:27:05.760]   the, the, probably one of the few things that distinguishes us from any other country,
[00:27:05.760 --> 00:27:06.760]   or except Canada.
[00:27:06.760 --> 00:27:07.760]   I love Canada.
[00:27:07.760 --> 00:27:08.760]   Now many other countries.
[00:27:08.760 --> 00:27:10.400]   The Canada doesn't trust us.
[00:27:10.400 --> 00:27:12.280]   Many other countries.
[00:27:12.280 --> 00:27:21.040]   That rule of law is absolutely critical, I believe, to the success and survival of a
[00:27:21.040 --> 00:27:22.040]   nation.
[00:27:22.040 --> 00:27:26.520]   I've been in nations, many of them, where the rule of law is corrupted or damaged.
[00:27:26.520 --> 00:27:32.440]   I'll never forget going to Egypt and the corruption that occurred in Egypt basically
[00:27:32.440 --> 00:27:35.080]   makes society crumble.
[00:27:35.080 --> 00:27:42.160]   And so I think it's so important that we not, that we not disregard the value of living
[00:27:42.160 --> 00:27:48.280]   in a society ruled by laws and, and very often the law does something that, and an
[00:27:48.280 --> 00:27:52.000]   individual doesn't like, right?
[00:27:52.000 --> 00:27:56.080]   And in fact, everything we're talking about here is, you know, you could say, well, that's
[00:27:56.080 --> 00:27:58.680]   a violation of our constitutional rights to privacy.
[00:27:58.680 --> 00:28:03.160]   We don't have a constitutional right to privacy, but we have implicit rights.
[00:28:03.160 --> 00:28:07.160]   And so you could say, you know, all the government is overreaching and we need to, that's against
[00:28:07.160 --> 00:28:08.600]   the rule of law.
[00:28:08.600 --> 00:28:14.000]   I know, I think you got to be very, very careful about assailing the rule of law.
[00:28:14.000 --> 00:28:16.200]   That's the only thing that protects us from the government.
[00:28:16.200 --> 00:28:17.600]   No, I'm not at the sale of the rule of law.
[00:28:17.600 --> 00:28:21.280]   I'm saying what Apple's saying is there needs to be a full discussion about this and not
[00:28:21.280 --> 00:28:23.240]   just to answer this judge like that.
[00:28:23.240 --> 00:28:24.240]   We've got to go.
[00:28:24.240 --> 00:28:25.240]   We've got to see this to the limits.
[00:28:25.240 --> 00:28:26.760]   That's a big deal.
[00:28:26.760 --> 00:28:34.120]   So at, pardon me for what I'm about to do, at Davos, I sat in on a panel on whether your
[00:28:34.120 --> 00:28:39.600]   brain will, will declare you guilty and where we are and the ability, the minority report
[00:28:39.600 --> 00:28:41.000]   pre crime kind of.
[00:28:41.000 --> 00:28:45.840]   Yeah, yeah, or post or post that your brain isn't encrypted.
[00:28:45.840 --> 00:28:46.840]   Right.
[00:28:46.840 --> 00:28:53.680]   There's a precedent that goes even there that, that, that, that is concerning.
[00:28:53.680 --> 00:28:57.200]   And there is, there is a question of, I mean, no, we don't have a constitutional right
[00:28:57.200 --> 00:29:02.880]   to privacy, but we have is a constitutional right to know unreasonable search and seizure
[00:29:02.880 --> 00:29:06.640]   and unwarranted as well.
[00:29:06.640 --> 00:29:12.600]   And we are, we have to be wary, I think you're of setting precedence going forward for new
[00:29:12.600 --> 00:29:13.600]   realms of technology.
[00:29:13.600 --> 00:29:17.520]   And that's why, you know, as I said, I agree to the skeleton key argument because it's
[00:29:17.520 --> 00:29:20.800]   here's, let me, let me, let me, Steve Gibson's in the chat room.
[00:29:20.800 --> 00:29:21.960]   We've had this conversation.
[00:29:21.960 --> 00:29:25.680]   In fact, if you want to try to get Steve on the line, please do, we've had this conversation
[00:29:25.680 --> 00:29:29.640]   with Steve before, Steve says something quite shocked me, which is that Apple and, and
[00:29:29.640 --> 00:29:34.040]   actually I am now, uh, agreeing with him.
[00:29:34.040 --> 00:29:37.920]   Apple should probably go back to the day when they could decrypt, you know, they didn't
[00:29:37.920 --> 00:29:40.640]   encrypt by default.
[00:29:40.640 --> 00:29:45.760]   Because of this, it should be searchable with a warrant in the way that your home is searchable
[00:29:45.760 --> 00:29:46.760]   with a warrant.
[00:29:46.760 --> 00:29:51.920]   Steve is saying, and I, I don't know what he's basing this on, but he says, um, I'm
[00:29:51.920 --> 00:29:59.000]   one, Apple uses their secret code signing key to sign an update that will only operate
[00:29:59.000 --> 00:30:01.000]   with that one phone.
[00:30:01.000 --> 00:30:06.680]   Two, the op, and I think this is actually technically exactly what would happen.
[00:30:06.680 --> 00:30:10.760]   And certainly Steve would know better than I, that too, the updated iOS has weakened
[00:30:10.760 --> 00:30:12.320]   protections.
[00:30:12.320 --> 00:30:15.400]   They weakened it, which then allows brute forcing of the passcode.
[00:30:15.400 --> 00:30:18.160]   And that's what the law enforcement is asking them to do.
[00:30:18.160 --> 00:30:19.160]   And that's the,
[00:30:19.160 --> 00:30:26.320]   whatever, if it was just for that phone, now, what Tim Cook says, what tick says is you've
[00:30:26.320 --> 00:30:30.840]   let the genie out of the bottle because we've now written the code to do that.
[00:30:30.840 --> 00:30:32.320]   We now have the capability.
[00:30:32.320 --> 00:30:36.680]   So law enforcement's going to keep coming to us with subpoenas and warrants saying you've
[00:30:36.680 --> 00:30:38.160]   got to do it with this phone.
[00:30:38.160 --> 00:30:42.240]   It will not, it will not, and, and China, it will be, it will be in every vote.
[00:30:42.240 --> 00:30:43.720]   It'll be required by law.
[00:30:43.720 --> 00:30:46.600]   No, no, no, it won't because Apple has it.
[00:30:46.600 --> 00:30:50.800]   No, it will be required by law to put it in every phone.
[00:30:50.800 --> 00:30:51.800]   It will get out.
[00:30:51.800 --> 00:30:53.440]   No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,
[00:30:53.440 --> 00:30:57.080]   Apple has to do it one, one, one at a time.
[00:30:57.080 --> 00:31:01.360]   So that's not to say Chinese authorities won't send a phone to Apple and say to crypto, they,
[00:31:01.360 --> 00:31:04.080]   that's what they used to do, by the way.
[00:31:04.080 --> 00:31:05.080]   So this is possible.
[00:31:05.080 --> 00:31:06.920]   Has it got to be done for that phone?
[00:31:06.920 --> 00:31:08.360]   Yes, I believe it's Steve.
[00:31:08.360 --> 00:31:10.640]   I believe that Steve is correct.
[00:31:10.640 --> 00:31:14.640]   That technically sounds, and Steve has looked very much into the, into the security of those
[00:31:14.640 --> 00:31:17.000]   phones.
[00:31:17.000 --> 00:31:22.120]   Well then that would remove my main problem, which is that it would somehow become something
[00:31:22.120 --> 00:31:23.960]   that government can use at it.
[00:31:23.960 --> 00:31:26.160]   Oh, as you don't know, don't talk about me yet.
[00:31:26.160 --> 00:31:28.000]   Don't talk about me yet, Matthew.
[00:31:28.000 --> 00:31:30.560]   Don't leave me alone here.
[00:31:30.560 --> 00:31:31.800]   Sorry.
[00:31:31.800 --> 00:31:35.760]   What, what about the international working with Matthew that, that, that once Apple has
[00:31:35.760 --> 00:31:41.680]   proven this capability and demonstrated that they will offer it, then China, Iran, Russia,
[00:31:41.680 --> 00:31:43.640]   will all petition that, get it again.
[00:31:43.640 --> 00:31:46.120]   And then Apple can just drag its feet.
[00:31:46.120 --> 00:31:49.360]   And that's exactly what they, by the way, that's how it was.
[00:31:49.360 --> 00:31:52.120]   Pre iOS eight, that's exactly how it was.
[00:31:52.120 --> 00:31:54.040]   All the court is saying is let's go back.
[00:31:54.040 --> 00:31:55.840]   We just, this is a pre iOS eight phone.
[00:31:55.840 --> 00:32:00.440]   We ask you to do the same thing you do with, used to do with those phones for this phone.
[00:32:00.440 --> 00:32:04.200]   Apple's already said, and I think this is true that since I, one of the reasons they
[00:32:04.200 --> 00:32:07.520]   did it, and you know, it almost feels like a convenience argument.
[00:32:07.520 --> 00:32:12.000]   Apple just didn't want to, they was a long line of law enforcement saying, please decrypt
[00:32:12.000 --> 00:32:13.000]   this phone.
[00:32:13.000 --> 00:32:15.440]   Apple was doing it one by one.
[00:32:15.440 --> 00:32:20.240]   Let's also remember back to Yahoo and China, where a man went to jail for a decade, right?
[00:32:20.240 --> 00:32:23.880]   Because Yahoo had to follow the law of the land and hand over information about it.
[00:32:23.880 --> 00:32:28.680]   And no, Yahoo, Apple doesn't want to be in that position.
[00:32:28.680 --> 00:32:30.080]   Google is going to be in that position.
[00:32:30.080 --> 00:32:32.560]   I understand, but you're doing business in that country.
[00:32:32.560 --> 00:32:35.320]   Well, that's why they don't want to set this president.
[00:32:35.320 --> 00:32:37.560]   But wait a minute, America has the standard.
[00:32:37.560 --> 00:32:41.920]   That's highly hypocritical to say, I mean, I tell people when they go to China, people
[00:32:41.920 --> 00:32:44.000]   say, well, how do I get around the Great Firewall of China?
[00:32:44.000 --> 00:32:46.080]   I said, you shouldn't, you're a guest of the country.
[00:32:46.080 --> 00:32:47.600]   You should adhere to the laws of the country.
[00:32:47.600 --> 00:32:48.600]   Just a little bit.
[00:32:48.600 --> 00:32:49.600]   I don't know what to say.
[00:32:49.600 --> 00:32:50.600]   A Chinese citizen.
[00:32:50.600 --> 00:32:51.600]   Well, but that's the problem, right?
[00:32:51.600 --> 00:32:54.960]   Google and Yahoo want to make money in China, but they don't want to adhere to the laws
[00:32:54.960 --> 00:32:55.960]   of China.
[00:32:55.960 --> 00:33:00.800]   Well, by that logic, Leo, by that logic, Leo, then nothing should be encrypted.
[00:33:00.800 --> 00:33:02.160]   An encryption can be made illegal.
[00:33:02.160 --> 00:33:05.000]   Or you don't do business in those countries.
[00:33:05.000 --> 00:33:07.920]   Or you just make it.
[00:33:07.920 --> 00:33:09.640]   No.
[00:33:09.640 --> 00:33:15.560]   But the theory, I mean, the theory for Google and Apple, certainly for Google, and I think
[00:33:15.560 --> 00:33:20.760]   Facebook, is that being in that country helps you push against those laws.
[00:33:20.760 --> 00:33:24.760]   I'm going to work with the establishment to change.
[00:33:24.760 --> 00:33:25.760]   Right.
[00:33:25.760 --> 00:33:31.320]   Well, and maybe they should just pull up and not do any business in those countries.
[00:33:31.320 --> 00:33:33.320]   But that doesn't seem realistic.
[00:33:33.320 --> 00:33:37.240]   It's not realistic because they're profit-making entities.
[00:33:37.240 --> 00:33:39.960]   So there's a little hypocritical stuff going on here.
[00:33:39.960 --> 00:33:42.520]   Well, we don't want to follow the laws of the country, but we'd like to make the money
[00:33:42.520 --> 00:33:43.520]   of the country.
[00:33:43.520 --> 00:33:46.160]   I think that's a problem ethically.
[00:33:46.160 --> 00:33:47.160]   And I don't--
[00:33:47.160 --> 00:33:48.880]   What if the laws are wrong?
[00:33:48.880 --> 00:33:51.280]   Well, what if somebody, let's say--
[00:33:51.280 --> 00:33:56.600]   What if Apple's new business from the Middle East comes to the United States?
[00:33:56.600 --> 00:33:59.480]   He says, "You know, I think the laws of the United States are wrong, and I'm going to
[00:33:59.480 --> 00:34:00.480]   do what I want to do."
[00:34:00.480 --> 00:34:02.960]   And it might be law-Americans.
[00:34:02.960 --> 00:34:08.520]   What if Apple's doing business in Saudi Arabia and when their employees does something that
[00:34:08.520 --> 00:34:11.040]   requires them to be headed into public square?
[00:34:11.040 --> 00:34:13.320]   Is that should Apple just say, "Okay."
[00:34:13.320 --> 00:34:16.000]   Let's take a break because Steve Gibson is prepared to join us.
[00:34:16.000 --> 00:34:17.320]   I'm really thrilled to have that.
[00:34:17.320 --> 00:34:18.320]   That's great.
[00:34:18.320 --> 00:34:20.000]   This is such a good conversation.
[00:34:20.000 --> 00:34:25.920]   And I'm really glad you got-- we got the smartest minds on this right now.
[00:34:25.920 --> 00:34:29.560]   And this is exactly-- I'm sure what Tim Cook intended with his open letter published this
[00:34:29.560 --> 00:34:30.720]   morning.
[00:34:30.720 --> 00:34:32.840]   And you absolutely Apple's going to appeal it.
[00:34:32.840 --> 00:34:36.840]   And if Scotus takes it, then I'm sure we'll hear from--
[00:34:36.840 --> 00:34:40.040]   Well, that gets us into the other fight going on in Saudi Arabia now.
[00:34:40.040 --> 00:34:42.960]   That's why that's so important, by the way, isn't it?
[00:34:42.960 --> 00:34:43.960]   But they should appeal it.
[00:34:43.960 --> 00:34:44.960]   They should appeal it.
[00:34:44.960 --> 00:34:45.960]   They should appeal it.
[00:34:45.960 --> 00:34:46.960]   They should be tested--
[00:34:46.960 --> 00:34:47.960]   They will.
[00:34:47.960 --> 00:34:49.400]   It should be tested up to the highest court in the land and--
[00:34:49.400 --> 00:34:50.400]   So that's exactly.
[00:34:50.400 --> 00:34:56.600]   And then if the highest court in the land rules, we have agreed as a society, and this
[00:34:56.600 --> 00:35:00.680]   is the only way our society can continue to adhere to that law.
[00:35:00.680 --> 00:35:01.680]   We've got a little breaking news here.
[00:35:01.680 --> 00:35:03.000]   We'll do the commercial first.
[00:35:03.000 --> 00:35:04.000]   Oh, all right.
[00:35:04.000 --> 00:35:05.720]   Steve Gibson and breaking news coming up.
[00:35:05.720 --> 00:35:09.320]   As with all our sponsors, I tell you about companies that are very useful.
[00:35:09.320 --> 00:35:11.400]   Good for you to know Gazelle is a great one.
[00:35:11.400 --> 00:35:14.880]   Gazelle is the trusted online marketplace for selling your old stuff.
[00:35:14.880 --> 00:35:19.520]   So you can get some cash, your old phone, your old tablet, your old computer.
[00:35:19.520 --> 00:35:22.960]   And then now there's something new they've added.
[00:35:22.960 --> 00:35:29.200]   Buying a gently pre-owned device from Gazelle, for buying or for selling.
[00:35:29.200 --> 00:35:37.680]   They have a variety of iPhones for sale, including the 6S, the 6S Plus, the other new stuff.
[00:35:37.680 --> 00:35:43.960]   iPads, Samsung Galaxy phones, each phone, each device fully inspected, backed by a 30
[00:35:43.960 --> 00:35:47.000]   day return policy and sold without carrier contract.
[00:35:47.000 --> 00:35:50.120]   But they do work on all the major carriers, which is really, really nice.
[00:35:50.120 --> 00:35:53.440]   And the price, you get to choose the condition of the phone.
[00:35:53.440 --> 00:35:55.560]   In every case, they're fully functional.
[00:35:55.560 --> 00:35:58.560]   They don't have big scratches in the glass or anything.
[00:35:58.560 --> 00:35:59.720]   And it all works.
[00:35:59.720 --> 00:36:02.560]   But some have gentle signs of where some don't.
[00:36:02.560 --> 00:36:04.400]   So you get to choose and you pay accordingly.
[00:36:04.400 --> 00:36:06.960]   So if you really want to save, you're replacing a broken phone.
[00:36:06.960 --> 00:36:09.800]   You just want to get through the rest of the year to the new iPhone 7 comes out, let's
[00:36:09.800 --> 00:36:10.800]   say.
[00:36:10.800 --> 00:36:13.120]   Or it's for a kid and you don't want to spend a lot of money because you know they're going
[00:36:13.120 --> 00:36:14.120]   to break it again.
[00:36:14.120 --> 00:36:15.960]   Gazelle's a great choice.
[00:36:15.960 --> 00:36:22.120]   They now, this is brand new, provide financing on anything you buy from a firm.
[00:36:22.120 --> 00:36:23.120]   And it's very easy.
[00:36:23.120 --> 00:36:24.720]   You just provide basic information.
[00:36:24.720 --> 00:36:32.160]   They'll get instantly improved on the site and you can pay over three, six or 12 months.
[00:36:32.160 --> 00:36:35.440]   Easy monthly payments, in fact, they'll do it through a bank transfer, a check or a credit
[00:36:35.440 --> 00:36:37.200]   card.
[00:36:37.200 --> 00:36:39.640]   Just like financing with a firm, a checkout.
[00:36:39.640 --> 00:36:41.640]   Actually, I think it's a debit card.
[00:36:41.640 --> 00:36:42.640]   No, it's check.
[00:36:42.640 --> 00:36:44.480]   Yeah, check debit card or bank transfer.
[00:36:44.480 --> 00:36:49.600]   Gazelle offers a 12 month warranty for cell phones and iPads powered by assurance solutions.
[00:36:49.600 --> 00:36:52.520]   So they're partnering up with some really, really great companies.
[00:36:52.520 --> 00:36:59.400]   It's from an assurance, covers water damage, cracked screens, hardware defects and more.
[00:36:59.400 --> 00:37:01.740]   And help is available, of course, 24/7.
[00:37:01.740 --> 00:37:04.720]   From Gazelle to process claims and return your device fast.
[00:37:04.720 --> 00:37:06.440]   Get a new one fast too.
[00:37:06.440 --> 00:37:09.440]   Don't miss out on getting the best value in certified pre-owned devices.
[00:37:09.440 --> 00:37:15.040]   Now it's easy at gazelle.com.
[00:37:15.040 --> 00:37:20.320]   Give new life to used electronics, trade it in for cash or by certified pre-owned.
[00:37:20.320 --> 00:37:27.120]   And get financing and insurance at gazelle.com today.
[00:37:27.120 --> 00:37:28.920]   Gazelle.com.
[00:37:28.920 --> 00:37:29.920]   Steve Gibson joins us.
[00:37:29.920 --> 00:37:31.400]   I'm glad you were listening, Steve.
[00:37:31.400 --> 00:37:35.640]   Yeah, I had some time and I figured I'd put you guys on in the background.
[00:37:35.640 --> 00:37:38.520]   I always love listening to this week in Google.
[00:37:38.520 --> 00:37:44.040]   I'm great to be on with Jeff because I often concur with his sort of extreme views.
[00:37:44.040 --> 00:37:45.320]   Oh, is that what except this case?
[00:37:45.320 --> 00:37:46.720]   Except this case you're going to say, Steve?
[00:37:46.720 --> 00:37:47.720]   Well, I don't know.
[00:37:47.720 --> 00:37:53.560]   What I love about Steve is a great thinker and he's never dogmatic about this stuff.
[00:37:53.560 --> 00:37:54.560]   So what do you think?
[00:37:54.560 --> 00:37:56.920]   First of all, what you said in the chat room, is that accurate, Steve?
[00:37:56.920 --> 00:37:57.920]   Is that?
[00:37:57.920 --> 00:38:02.360]   Yeah, what I wanted to do was if nothing else, in order to have a discussion, we need to
[00:38:02.360 --> 00:38:09.960]   know we need the right technology base and then I think separate the policy from the
[00:38:09.960 --> 00:38:13.920]   technology because they're really separate things.
[00:38:13.920 --> 00:38:20.320]   So what we absolutely know and we've talked about this a number of times in the past and
[00:38:20.320 --> 00:38:30.560]   this has been true for quite a while is that individual iOS updates are per phone.
[00:38:30.560 --> 00:38:36.880]   I remember clearly going over this at some point that the one podcast we did on when we
[00:38:36.880 --> 00:38:42.400]   I think actually it was several podcasts where we really took apart Apple's current security
[00:38:42.400 --> 00:38:44.720]   model and I think it was with iOS 7.
[00:38:44.720 --> 00:38:47.640]   It was the big white paper that they did then.
[00:38:47.640 --> 00:38:54.400]   And what I remember is that every phone is unique in, you know, for whatever, you know,
[00:38:54.400 --> 00:38:59.080]   we'll call it a, you know, it's got its own key or its own serial number.
[00:38:59.080 --> 00:39:10.680]   And so in order for an iOS update to be accepted, it must be signed by Apple and using Apple's
[00:39:10.680 --> 00:39:17.200]   secret code signing key for iOS and be per phone.
[00:39:17.200 --> 00:39:23.480]   And this was an important security measure that prevents other older iOS's from being
[00:39:23.480 --> 00:39:30.520]   installed on a different phone, which would create a downgrade attack on iOS and like
[00:39:30.520 --> 00:39:35.800]   and then allow things that have been previously fixed to reappear.
[00:39:35.800 --> 00:39:40.720]   So Apple has a lot of control over what the phones get.
[00:39:40.720 --> 00:39:45.480]   And I have also been following this story this morning reading the various back and
[00:39:45.480 --> 00:39:46.480]   forths.
[00:39:46.480 --> 00:39:58.040]   And so as I understand it, what the court is ordering Apple to do is to weaken the safeguards
[00:39:58.040 --> 00:40:02.520]   which are in place to prevent brute forcing.
[00:40:02.520 --> 00:40:07.360]   There's an 80 millisecond delay on also some of this is from Matthew Green.
[00:40:07.360 --> 00:40:15.880]   He also posted about this that where in 14, two years ago, he took a strong look at this
[00:40:15.880 --> 00:40:18.440]   exactly this aspect of the iPhone.
[00:40:18.440 --> 00:40:25.720]   And so the idea is they, they, they remove any software imposed delay between guesses
[00:40:25.720 --> 00:40:31.680]   which they're able to remove in order to increase their rate at which they can brute force.
[00:40:31.680 --> 00:40:40.920]   And they disable the 10 hits or 10, 10 misses and the key gets wiped out, thus preventing
[00:40:40.920 --> 00:40:43.920]   the phone from being ever decrypted.
[00:40:43.920 --> 00:40:48.960]   And so the idea is that, and there's something called the acronym is I think DRU.
[00:40:48.960 --> 00:40:52.360]   I can't remember what it stands for, but that's a DFU.
[00:40:52.360 --> 00:40:54.360]   A DFU, right.
[00:40:54.360 --> 00:40:55.360]   That's the ability to.
[00:40:55.360 --> 00:40:57.360]   No, it's not a joke.
[00:40:57.360 --> 00:40:58.360]   Okay.
[00:40:58.360 --> 00:41:00.360]   It's the real name of you.
[00:41:00.360 --> 00:41:07.880]   It's the ability to update the phone through an attached USB connection, which is one of
[00:41:07.880 --> 00:41:11.400]   the, the router's best tricks.
[00:41:11.400 --> 00:41:18.000]   And so the idea is that Apple would, so the FBI would physically and would need to physically
[00:41:18.000 --> 00:41:25.520]   prevent, present the phone to Apple and say, here's the phone we need you to make it possible
[00:41:25.520 --> 00:41:28.240]   for us to brute force.
[00:41:28.240 --> 00:41:39.380]   So Apple would then modify an iOS which it would sign for that phone and then install
[00:41:39.380 --> 00:41:40.940]   in that phone.
[00:41:40.940 --> 00:41:47.700]   And then the one other thing they're asking for is to have electronic access to input
[00:41:47.700 --> 00:41:56.160]   passwords so that some poor FBI intern isn't sitting there going 0, 0, 0, 0, 0, 0, 0, 1,
[00:41:56.160 --> 00:41:57.160]   and so forth.
[00:41:57.160 --> 00:41:59.160]   I think that's where we are.
[00:41:59.160 --> 00:42:03.800]   But you know, other than that, this would not be kind of a global backdoor.
[00:42:03.800 --> 00:42:04.800]   Right.
[00:42:04.800 --> 00:42:05.800]   So this could just be one phone.
[00:42:05.800 --> 00:42:08.120]   This could just apply to that phone.
[00:42:08.120 --> 00:42:12.360]   However, it would be an admission that Apple, that they have this technical, although say
[00:42:12.360 --> 00:42:16.520]   this is, I suspect what they've been doing all along up to iOS eight.
[00:42:16.520 --> 00:42:21.680]   But whatever phone physically would any future phone have to physically be presented to them
[00:42:21.680 --> 00:42:22.680]   to do this?
[00:42:22.680 --> 00:42:23.680]   Yeah.
[00:42:23.680 --> 00:42:25.720]   And it has to be running an older version of the operating system, right?
[00:42:25.720 --> 00:42:30.080]   I believe you can't do this retroactive firmware update on iOS eight.
[00:42:30.080 --> 00:42:31.240]   I don't think so.
[00:42:31.240 --> 00:42:32.240]   I don't know.
[00:42:32.240 --> 00:42:33.240]   I don't know either.
[00:42:33.240 --> 00:42:37.560]   But I believe that Apple's intent with iOS eight was to prevent this from ever coming
[00:42:37.560 --> 00:42:38.560]   up.
[00:42:38.560 --> 00:42:42.920]   And the only reason, according to ours, Technica, the reason this comes up now is because it's
[00:42:42.920 --> 00:42:44.800]   an iOS seven phone.
[00:42:44.800 --> 00:42:46.640]   It's an older phone.
[00:42:46.640 --> 00:42:47.640]   Right.
[00:42:47.640 --> 00:42:54.040]   Let me, this is a thank you to Gadgethog for providing a great quote from a surprising
[00:42:54.040 --> 00:42:55.040]   source.
[00:42:55.040 --> 00:43:05.360]   It was a decision in 1987 by the US Supreme Court six to three in ruling for the police
[00:43:05.360 --> 00:43:09.760]   officers were who were legally searching an apartment for weapons.
[00:43:09.760 --> 00:43:15.680]   Remember, they're looking for weapons violated the Fourth Amendment, the Bill of Rights Amendment
[00:43:15.680 --> 00:43:22.480]   that prevents unlawful search and seizure, unreasonable search and seizure violated the
[00:43:22.480 --> 00:43:26.320]   Fourth Amendment when they slightly move stereo equipment to check the serial numbers
[00:43:26.320 --> 00:43:27.520]   to see if they were stolen.
[00:43:27.520 --> 00:43:31.440]   Remember, they were looking and the search warrant said looking for weapons, but they
[00:43:31.440 --> 00:43:35.600]   end up moving and that was thrown out of court.
[00:43:35.600 --> 00:43:42.680]   Justice Antonin Scalia wrote in the opinion, and it's a great quote.
[00:43:42.680 --> 00:43:49.440]   There's nothing new in the realization that the constitution sometimes insulates the criminality
[00:43:49.440 --> 00:43:55.520]   of a few in order to protect the privacy of us all.
[00:43:55.520 --> 00:43:56.520]   There you go.
[00:43:56.520 --> 00:44:00.760]   There are some stereo systems that could qualify as a weapon.
[00:44:00.760 --> 00:44:04.160]   Well, it's really true them at some point.
[00:44:04.160 --> 00:44:08.680]   And this is about probable cause and about the Fourth Amendment, but it shows you that
[00:44:08.680 --> 00:44:13.240]   first of all, this was Justice Wrenquist's Supreme Court and Scalia, a staunch conservative
[00:44:13.240 --> 00:44:21.080]   who was thought to support Wrenquist, but it's interesting because this is why the Supreme
[00:44:21.080 --> 00:44:23.600]   Court is the Supreme Court.
[00:44:23.600 --> 00:44:26.280]   They did in fact constrain police powers in a search.
[00:44:26.280 --> 00:44:30.200]   You can't just kind of go on a fishing expedition.
[00:44:30.200 --> 00:44:35.480]   But that also encourages me that if a judge and ultimately the Supreme Court says, no,
[00:44:35.480 --> 00:44:36.640]   we want you to decrypt this phone.
[00:44:36.640 --> 00:44:38.520]   That means there is good probable cause.
[00:44:38.520 --> 00:44:41.800]   The police have presented a good probable cause that there's something on that phone
[00:44:41.800 --> 00:44:42.800]   that will be of value.
[00:44:42.800 --> 00:44:43.800]   Jeff?
[00:44:43.800 --> 00:44:44.800]   I have to say one.
[00:44:44.800 --> 00:44:45.800]   Go ahead.
[00:44:45.800 --> 00:44:53.640]   Jeff, do you think at this point that where we are in time, given how far we are, post
[00:44:53.640 --> 00:44:59.480]   Snowden and the Patriot Act and sort of feel that this general feeling that maybe there
[00:44:59.480 --> 00:45:10.160]   was some overreach that the country as a whole has learned its lesson and that or do we just
[00:45:10.160 --> 00:45:15.920]   have to mistrust government and give them as little power as possible?
[00:45:15.920 --> 00:45:18.800]   As always Steve, I expect the best questions from you and I won't have answers for you
[00:45:18.800 --> 00:45:20.640]   the way you have answers for us.
[00:45:20.640 --> 00:45:22.200]   I'm so delighted you're here.
[00:45:22.200 --> 00:45:24.560]   I'm so happy you're here.
[00:45:24.560 --> 00:45:28.040]   I think a few things.
[00:45:28.040 --> 00:45:34.840]   One is that if you were sitting on the Supreme Court, what you have to do is not, as you
[00:45:34.840 --> 00:45:38.640]   just said Steve, you have to separate the technology from the policy and from the law
[00:45:38.640 --> 00:45:43.440]   in this case and not worry about the limitations that happened to be on this particular phone
[00:45:43.440 --> 00:45:46.040]   on this particular OS.
[00:45:46.040 --> 00:45:51.640]   You have to be saying that an ability was demanded of a technology company involving privacy
[00:45:51.640 --> 00:45:58.240]   and no matter what the technology is in the future, we can demand the same thing.
[00:45:58.240 --> 00:46:02.920]   When new technologies, new capabilities, new issues, you get wildly fast computers that
[00:46:02.920 --> 00:46:07.640]   can root force in different ways, what does it matter to them?
[00:46:07.640 --> 00:46:12.840]   The fact that Apple put on things to protect all of us so that any garden variety, crook
[00:46:12.840 --> 00:46:17.760]   and criminal and miscreant couldn't do our phones, when asked to take that off under the
[00:46:17.760 --> 00:46:21.680]   nation's law, whatever the nation is, that's what we have to be concerned about.
[00:46:21.680 --> 00:46:24.720]   We have to somehow rise to the level of principle here.
[00:46:24.720 --> 00:46:32.240]   I've said on the show a couple of times that the law around our protection of privacy in
[00:46:32.240 --> 00:46:34.480]   our males was miswritten to a technology.
[00:46:34.480 --> 00:46:38.680]   It was written to the technology of the US Postal Service and a physical letter.
[00:46:38.680 --> 00:46:42.520]   The law should have been written to the principle to say that our private communications are
[00:46:42.520 --> 00:46:47.600]   presumed private unless sought under a lawful warrant, yada, yada, yada.
[00:46:47.600 --> 00:46:52.400]   That's why our male is still protected, but our emails and our chats and our phones are
[00:46:52.400 --> 00:46:53.400]   not.
[00:46:53.400 --> 00:46:57.160]   The larger question I need to ask first is, what's the principle?
[00:46:57.160 --> 00:46:58.160]   Then you're right, Steve.
[00:46:58.160 --> 00:47:03.320]   The next question is, has the country learned given the lessons of Snowden?
[00:47:03.320 --> 00:47:04.320]   I think so.
[00:47:04.320 --> 00:47:09.760]   I think that the trust that we have in this country is tarnished because of the NSA and
[00:47:09.760 --> 00:47:15.000]   GCHQ, but that's irrelevant in this case because I worry about the lowest common denominator.
[00:47:15.000 --> 00:47:19.240]   For an international company like Apple and Google and Facebook, I have to worry about
[00:47:19.240 --> 00:47:23.760]   the lowest common denominator of freedom around the world because that's the one we'll live
[00:47:23.760 --> 00:47:25.320]   under henceforth.
[00:47:25.320 --> 00:47:29.320]   If China can do it, it doesn't matter whether the US law is better, it might as well happen
[00:47:29.320 --> 00:47:31.080]   here.
[00:47:31.080 --> 00:47:35.840]   We have to look at the precedent at a level of principle and internationally.
[00:47:35.840 --> 00:47:36.840]   That's hard, but I think that's...
[00:47:36.840 --> 00:47:44.040]   I want to see that high and hard test as God helped me agree with Scalia.
[00:47:44.040 --> 00:47:48.160]   He has last laughs that we liberals have to agree with him on that, but I think that
[00:47:48.160 --> 00:47:49.160]   that's the case.
[00:47:49.160 --> 00:47:52.120]   I'm not a libertarian.
[00:47:52.120 --> 00:47:57.280]   I keep on making clear I'm a Hillary Clinton Democrat full disclosure here, but yes, I
[00:47:57.280 --> 00:48:02.200]   think you're right, Steve, or I think your question is right that we can't just hand
[00:48:02.200 --> 00:48:06.040]   over too much power in this realm to government, especially when we know, as Matthew was saying
[00:48:06.040 --> 00:48:08.240]   earlier, that we have secret courts.
[00:48:08.240 --> 00:48:09.240]   We've got to worry about that.
[00:48:09.240 --> 00:48:10.800]   I disagree, though.
[00:48:10.800 --> 00:48:16.320]   I think you're over globalizing this.
[00:48:16.320 --> 00:48:20.440]   For instance, if Apple demonstrates its capability, and by the way, as we now know, it's a very
[00:48:20.440 --> 00:48:24.600]   constrained capability that doesn't apply to 90% of the new phones and none of the new
[00:48:24.600 --> 00:48:30.520]   phones, it doesn't mean that all of a sudden you have to do whatever China says.
[00:48:30.520 --> 00:48:32.520]   You still...
[00:48:32.520 --> 00:48:34.160]   You know, they would...
[00:48:34.160 --> 00:48:35.160]   I think you could fight that many ways.
[00:48:35.160 --> 00:48:36.160]   Well, I'll make it your argument.
[00:48:36.160 --> 00:48:37.160]   I'll make it your argument.
[00:48:37.160 --> 00:48:38.160]   And it doesn't...
[00:48:38.160 --> 00:48:39.160]   That's the law of the land that China...
[00:48:39.160 --> 00:48:40.160]   And China.
[00:48:40.160 --> 00:48:42.440]   But it doesn't change the law of the land in the United States.
[00:48:42.440 --> 00:48:47.480]   You still need a probable cause and due process to get that phone.
[00:48:47.480 --> 00:48:50.960]   It changes the security of the technology and the trust in this technology around the
[00:48:50.960 --> 00:48:51.960]   world.
[00:48:51.960 --> 00:48:52.960]   Steve, where do you stand?
[00:48:52.960 --> 00:48:53.960]   And the law of the land that China is the law of the...
[00:48:53.960 --> 00:48:54.960]   If it is...
[00:48:54.960 --> 00:48:55.960]   If it is, just this...
[00:48:55.960 --> 00:48:56.960]   If it is, Steve...
[00:48:56.960 --> 00:48:57.960]   If it is...
[00:48:57.960 --> 00:48:58.960]   What are your...
[00:48:58.960 --> 00:48:59.960]   Steve?
[00:48:59.960 --> 00:49:00.960]   What are your...
[00:49:00.960 --> 00:49:01.960]   Steve?
[00:49:01.960 --> 00:49:02.960]   What are your...
[00:49:02.960 --> 00:49:03.960]   Steve?
[00:49:03.960 --> 00:49:04.960]   What are your...
[00:49:04.960 --> 00:49:05.960]   Steve?
[00:49:05.960 --> 00:49:06.960]   Steve?
[00:49:06.960 --> 00:49:07.960]   What are your...
[00:49:07.960 --> 00:49:08.960]   Steve?
[00:49:08.960 --> 00:49:09.960]   What are your...
[00:49:09.960 --> 00:49:10.960]   Steve?
[00:49:10.960 --> 00:49:11.960]   Steve?
[00:49:11.960 --> 00:49:12.960]   Steve?
[00:49:12.960 --> 00:49:13.960]   Well, here's my question to you, Steve.
[00:49:13.960 --> 00:49:16.960]   We had talked a couple of weeks ago on a security now.
[00:49:16.960 --> 00:49:23.640]   You said something very surprising, which actually as I thought about it was very sensible, which is that Apple should just go back the way it used to be, which is that encryption was not on by default. Because it was using... new technological capabilities to cause a problem with law enforcement.
[00:49:23.640 --> 00:49:24.640]   You still feel that right?
[00:49:24.640 --> 00:49:42.720]   Yeah, so the position I took was that we have the technology to create in our phone a reasonably secure lock.
[00:49:42.720 --> 00:49:48.760]   And as I understand the Constitution far less well than Jeff does, but as a citizen of the
[00:49:48.760 --> 00:49:53.600]   US, there's this notion that my home is...
[00:49:53.600 --> 00:50:04.600]   is my sanctuary and domain and I have a key to the front door and it is illegal for anyone to come in without my permission except that...
[00:50:04.600 --> 00:50:12.600]   except in the case that the Constitution provides for there being reasonable suspicion and so forth.
[00:50:12.600 --> 00:50:22.600]   And so where I came down on this, I mean, on like exactly where we are in the middle of this really interesting question about, you know,
[00:50:22.600 --> 00:50:32.600]   given that we now have the technology for unbreakable encryption, are we going to create exceptions to that?
[00:50:32.600 --> 00:50:45.600]   And we have exceptions that we've been living under where duly authorized law enforcement can enter a facility if it has reasonable cause.
[00:50:45.600 --> 00:50:53.600]   For doing so, if a judge looking at the evidence says, "Yes, we're going to give you access."
[00:50:53.600 --> 00:51:05.600]   And so my point was there is a technical way, not a backdoor, not a way that weakens anything, which I described on the podcast,
[00:51:05.600 --> 00:51:15.600]   which is every single phone has a unique randomly generated key which Apple stores.
[00:51:15.600 --> 00:51:21.600]   So it's not an algorithm that can get loose. It's not something that China can discover.
[00:51:21.600 --> 00:51:24.600]   It's not something that can be reverse engineered.
[00:51:24.600 --> 00:51:37.600]   It is a... there is no linkage between the phone and the key except that they were created together and Apple has a vault where they store it.
[00:51:37.600 --> 00:51:51.600]   And that without weakening anyone's encryption, anyone's phone in any way, it does allow Apple to respond to an order to make a specific...
[00:51:51.600 --> 00:51:55.600]   one specific phone unlockable.
[00:51:55.600 --> 00:52:03.600]   And in discussing this in subsequent weeks, I added the additional criteria.
[00:52:03.600 --> 00:52:16.600]   Again, it's technology. We can make it work however we want to. It could be designed so that Apple must physically have the phone and have the disassociated key,
[00:52:16.600 --> 00:52:20.600]   which together then allows the unlocking.
[00:52:20.600 --> 00:52:24.600]   Steve, is that true in seven and eight and beyond or just seven?
[00:52:24.600 --> 00:52:27.600]   No, I'm just making up a technology.
[00:52:27.600 --> 00:52:28.600]   Oh, I see.
[00:52:28.600 --> 00:52:44.600]   I was sort of exploring the idea of giving Apple the ability to safely respond to a court order and saying that, you know, as much as possible,
[00:52:44.600 --> 00:52:52.600]   this mimics the existing powers that the state has for conducting searches and seizures.
[00:52:52.600 --> 00:53:08.600]   And I think that's the key, Steve, is that we were talking before you came on about how one of the risks that we were afraid of and others are afraid of is that this ability could basically escape into the wild and be used on any phone.
[00:53:08.600 --> 00:53:23.600]   So if it was restricted in some way, so that it would only work on this one phone, and then the next time the FBI or somebody wanted to do it, they would have to get another order, and then Apple would have to do it for another phone and would have to physically have it,
[00:53:23.600 --> 00:53:35.600]   then that sort of... that would calm my fears to some extent about this master key escaping that would somehow be used by law enforcement or who knows who.
[00:53:35.600 --> 00:53:39.600]   It's interesting because that's exactly how the debate is starting to take shape.
[00:53:39.600 --> 00:53:44.600]   You know, Apple, Tim Cook in his open letter said it was creating a back door.
[00:53:44.600 --> 00:53:47.600]   The White House has now issued a statement.
[00:53:47.600 --> 00:53:57.600]   Josh Earnest talking with reporters said it's important to recognize the government is not asking Apple to redesign its product or, quote, create a new back door to its products.
[00:53:57.600 --> 00:54:03.600]   This is about one phone and one case and a one-off description.
[00:54:03.600 --> 00:54:08.600]   Apple to take an action here that it built into the phone that we all bought.
[00:54:08.600 --> 00:54:10.600]   We all bought with a presumption this couldn't be done.
[00:54:10.600 --> 00:54:16.600]   No, no, no, that 5C was sold before this was possible.
[00:54:16.600 --> 00:54:18.600]   Apple did not really explain.
[00:54:18.600 --> 00:54:19.600]   Let me explain.
[00:54:19.600 --> 00:54:20.600]   Let me explain.
[00:54:20.600 --> 00:54:21.600]   Okay.
[00:54:21.600 --> 00:54:25.600]   The notion that you can change the time delay on trying.
[00:54:25.600 --> 00:54:26.600]   Okay.
[00:54:26.600 --> 00:54:30.600]   We bought the phone in a contract that said this phone is equipped with this.
[00:54:30.600 --> 00:54:32.600]   I didn't even know that, to be honest.
[00:54:32.600 --> 00:54:34.600]   It's like some people did.
[00:54:34.600 --> 00:54:35.600]   Some people did, right?
[00:54:35.600 --> 00:54:36.600]   So it's always worth asking to change.
[00:54:36.600 --> 00:54:38.600]   Let me ask this question at the principal level.
[00:54:38.600 --> 00:54:43.600]   Do you as a citizen have the right to encrypt your communications?
[00:54:43.600 --> 00:54:44.600]   Full stop, simple question.
[00:54:44.600 --> 00:54:45.600]   Absolutely.
[00:54:45.600 --> 00:54:46.600]   Absolutely.
[00:54:46.600 --> 00:54:47.600]   Sure.
[00:54:47.600 --> 00:54:51.600]   Well, then you've just violated kind of everything that you're saying.
[00:54:51.600 --> 00:54:53.600]   No, that's not what this argument is about.
[00:54:53.600 --> 00:54:58.600]   If Apple has a means to decrypt it and the government demands that they do so,
[00:54:58.600 --> 00:55:00.600]   they're Apple has no choice.
[00:55:00.600 --> 00:55:02.600]   And you don't have the right to encrypt.
[00:55:02.600 --> 00:55:03.600]   You do.
[00:55:03.600 --> 00:55:05.600]   That encryption would be that's the point that you are.
[00:55:05.600 --> 00:55:14.600]   No, if I use PGP, which I do routinely, and no one can decrypt it, that's done.
[00:55:14.600 --> 00:55:16.600]   There's not even a question.
[00:55:16.600 --> 00:55:18.600]   There's no court ruling and no mandate.
[00:55:18.600 --> 00:55:19.600]   No warrant.
[00:55:19.600 --> 00:55:20.600]   It can't be done.
[00:55:20.600 --> 00:55:24.600]   That's by the way why Apple changed iOS because they didn't want to be in the position
[00:55:24.600 --> 00:55:25.600]   to be able to do this.
[00:55:25.600 --> 00:55:28.600]   This is not about going forward or current iOS's.
[00:55:28.600 --> 00:55:31.600]   This is about an old iOS, 10% of the iPhone.
[00:55:31.600 --> 00:55:35.600]   Actually, Wired says it was running iOS 9.
[00:55:35.600 --> 00:55:37.600]   Oh, that's interesting.
[00:55:37.600 --> 00:55:40.600]   Because ours says it's 7.
[00:55:40.600 --> 00:55:41.600]   It says it's important.
[00:55:41.600 --> 00:55:43.600]   And they think they can do it.
[00:55:43.600 --> 00:55:45.600]   Well, that was running iOS.
[00:55:45.600 --> 00:55:49.600]   That was the thing I found interesting is Apple effectively admitting that they had the ability
[00:55:49.600 --> 00:55:52.600]   to do it, which I was shocked to read.
[00:55:52.600 --> 00:55:56.600]   Or you surprise, I don't know what to say at this point.
[00:55:56.600 --> 00:55:58.600]   Remember, it's maybe Wired got it wrong.
[00:55:58.600 --> 00:55:59.600]   I don't know.
[00:55:59.600 --> 00:56:00.600]   I'd like to see the filing.
[00:56:00.600 --> 00:56:01.600]   It's in the PDF.
[00:56:01.600 --> 00:56:02.600]   Okay.
[00:56:02.600 --> 00:56:05.600]   Remember that there are sort of degrees of encryption.
[00:56:05.600 --> 00:56:11.600]   We've talked about, for example, iMessage, where the way iMessage works is that Apple has
[00:56:11.600 --> 00:56:12.600]   a key server.
[00:56:12.600 --> 00:56:20.600]   And when you send a message to someone else, Apple sends you the or a group, sends you
[00:56:20.600 --> 00:56:29.600]   the public keys, which match each of the recipients of the message that you're sending.
[00:56:29.600 --> 00:56:37.600]   And the message is encrypted individually, such that it can only be decrypted by the other
[00:56:37.600 --> 00:56:42.600]   person's private key, which has never left their phone.
[00:56:42.600 --> 00:56:45.600]   So, in principle, ooh, that sounds wonderful.
[00:56:45.600 --> 00:56:52.600]   That means that nobody can decrypt these messages except the recipient, except that Apple runs
[00:56:52.600 --> 00:56:59.600]   the key server, and nothing prevents them from including an additional key, which they have
[00:56:59.600 --> 00:57:03.600]   the private key to, or the FBI has the private key to.
[00:57:03.600 --> 00:57:10.600]   So, again, we need to separate policy from technology, which is why I think this is such
[00:57:10.600 --> 00:57:11.600]   an interesting discussion.
[00:57:11.600 --> 00:57:20.600]   And why 2016 is going to be such a fascinating year because we have something in encryption
[00:57:20.600 --> 00:57:24.600]   in math, which is absolute.
[00:57:24.600 --> 00:57:36.600]   And there are, I argue, ways to compromise such that we keep the strength we want while
[00:57:36.600 --> 00:57:41.600]   adding additional privileges if we choose to.
[00:57:41.600 --> 00:57:45.600]   And so we have to decide now if we choose to.
[00:57:45.600 --> 00:57:47.600]   And I mean, just point is right.
[00:57:47.600 --> 00:57:57.600]   Either we have a right to encrypt or we don't, or maybe somewhere in between.
[00:57:57.600 --> 00:57:59.600]   We're going to wrap it up.
[00:57:59.600 --> 00:58:01.600]   And if you want to stick around, Steve, you're welcome to.
[00:58:01.600 --> 00:58:04.600]   If you want to get going, I know your server is still down.
[00:58:04.600 --> 00:58:07.600]   No, he's been, he's being DDoSed.
[00:58:07.600 --> 00:58:09.600]   He's been, been DDoSed for a week.
[00:58:09.600 --> 00:58:13.600]   We had 15 minutes of, of uptime between 1045 and 11 this morning.
[00:58:13.600 --> 00:58:16.600]   Oh, that's probably because he went to school.
[00:58:16.600 --> 00:58:19.600]   First period is always bad for a DDoS attacks, but.
[00:58:19.600 --> 00:58:21.600]   It's not for us.
[00:58:21.600 --> 00:58:23.600]   So for real, it's been a pleasure.
[00:58:23.600 --> 00:58:24.600]   Thank you, Steve.
[00:58:24.600 --> 00:58:25.600]   Thank you.
[00:58:25.600 --> 00:58:26.600]   Thank you.
[00:58:26.600 --> 00:58:27.600]   JRC.com, if you can get there.
[00:58:27.600 --> 00:58:29.600]   Yeah, I tried actually, and it just said connect.
[00:58:29.600 --> 00:58:33.600]   Yeah, he's been DDoSed 13, 13 gigabit attack.
[00:58:33.600 --> 00:58:39.600]   It's a massive, by the way, Steve will be back and we will probably discuss something around these topics.
[00:58:39.600 --> 00:58:40.600]   Steve, Steve, it's the best.
[00:58:40.600 --> 00:58:44.600]   On Tuesday for a security now, right about this time.
[00:58:44.600 --> 00:58:48.600]   I can't find in the court order whether, I can't find where it says iOS 9.
[00:58:48.600 --> 00:58:49.600]   Yeah.
[00:58:49.600 --> 00:58:51.600]   So that's, that's according to Wired.
[00:58:51.600 --> 00:58:55.600]   You know, ultimately though, and, and, and we did not cover this as much as it deserved to get covered.
[00:58:55.600 --> 00:58:59.600]   And I really want to point people to the Harvard Berkman centers.
[00:58:59.600 --> 00:59:00.600]   Excellent.
[00:59:00.600 --> 00:59:04.600]   Excellent discussion of all of these topics that came out a few weeks ago.
[00:59:04.600 --> 00:59:06.600]   It's called Don't Panic.
[00:59:06.600 --> 00:59:13.600]   If you Google Don't Panic and Harvard or Berkman Center, you'll find the PDF making progress on the Going Dark Debate.
[00:59:13.600 --> 00:59:17.600]   And the people brought together for this were amazing.
[00:59:17.600 --> 00:59:25.600]   The conveners were Madels and Bruce Schneier and Jonathan Zittrain, all three really very well known in the security field.
[00:59:25.600 --> 00:59:29.600]   And they brought together some of the best security people to talk about it.
[00:59:29.600 --> 00:59:33.600]   It's hard to bottom line it because there's so much going on in here.
[00:59:33.600 --> 00:59:37.600]   But essentially, they said, Don't panic.
[00:59:37.600 --> 00:59:43.600]   First of all, encryption is absolutely vital for national security as well as individual privacy.
[00:59:43.600 --> 00:59:48.600]   But law enforcement has plenty of other ways to surveil you.
[00:59:48.600 --> 00:59:54.600]   And in fact, with the advent of the Internet of Things and, and widespread Internet access,
[00:59:54.600 --> 01:00:00.600]   there's no issue that the government has more information than ever about bad actors.
[01:00:00.600 --> 01:00:06.600]   And so it's not unreasonable to say, let's preserve the privacy we've had.
[01:00:06.600 --> 01:00:08.600]   And we have.
[01:00:08.600 --> 01:00:11.600]   And of course, this all, they even call it the catalyst.
[01:00:11.600 --> 01:00:14.600]   Apple, Google and others introduce easy to use built-in encryption.
[01:00:14.600 --> 01:00:20.600]   And that's really why this debate is happening is because Apple made encryption a consumer product.
[01:00:20.600 --> 01:00:24.600]   We're in the past, it's only been available to the highly technical users.
[01:00:24.600 --> 01:00:30.600]   Remember when Edward Snowden first wanted to reveal the contents of the treasure trove from the NSA,
[01:00:30.600 --> 01:00:34.600]   he wanted to use PGP with a reporter.
[01:00:34.600 --> 01:00:36.600]   And he said, what's PGP?
[01:00:36.600 --> 01:00:40.600]   I had no idea how to implement it.
[01:00:40.600 --> 01:00:46.600]   But now thanks to these companies, it's really interesting.
[01:00:46.600 --> 01:00:51.600]   There is a statement in here from Jonathan Zittrin, I'm going to go down in the appendix if I can get to it.
[01:00:51.600 --> 01:00:57.600]   And the appendix, each of the signatories, and there are quite a few, has a chance to say their own thing.
[01:00:57.600 --> 01:01:01.600]   Bruce Schneier is of course a personal hero.
[01:01:01.600 --> 01:01:09.600]   And he says, ubiquitous encryption protects us from, protects us much more from bulk surveillance than from targeted surveillance.
[01:01:09.600 --> 01:01:13.600]   For a variety of technical reasons, computer security is extraordinarily weak.
[01:01:13.600 --> 01:01:15.600]   And this guy knows.
[01:01:15.600 --> 01:01:19.600]   It's sufficiently skilled, funded, and motivated attacker wants in your computer therein.
[01:01:19.600 --> 01:01:20.600]   Yeah.
[01:01:20.600 --> 01:01:24.600]   If they're not, it's because you're not high enough on their priority list to bother with.
[01:01:24.600 --> 01:01:30.600]   Wide spread encryption forces the listener whether a foreign government criminal or terrorist to target.
[01:01:30.600 --> 01:01:36.600]   And this hurts repressive governments much more than it hurts terrorists and criminals.
[01:01:36.600 --> 01:01:38.600]   That's a great point, isn't it?
[01:01:38.600 --> 01:01:40.600]   It's really about the photo collection.
[01:01:40.600 --> 01:01:46.600]   Exactly the bulk sort of maths, net sucking and everything as opposed to targeting specific individuals.
[01:01:46.600 --> 01:01:47.600]   Yeah.
[01:01:47.600 --> 01:02:02.600]   And then Jonathan writes, "I empathize with the idea that just how much government can learn about us should not depend on the cat and mouse game of technological measure and counter measure.
[01:02:02.600 --> 01:02:14.600]   Ideally, this is what I was saying, a polity would carefully calibrate its legal authorities to permit access exactly and only where it comports with the imperatives of legitimate security."
[01:02:14.600 --> 01:02:17.600]   In other words, where there's a real security reason.
[01:02:17.600 --> 01:02:22.600]   And with basic human rights as recognized through the protections of conventions and constitutions.
[01:02:22.600 --> 01:02:27.600]   It's a very challenging argument.
[01:02:27.600 --> 01:02:28.600]   Absolutely.
[01:02:28.600 --> 01:02:37.600]   And it's clear when you read the white paper that there wasn't total agreement among all the parties, but boy, one thing they do agree about is surveillance.
[01:02:37.600 --> 01:02:39.600]   Bulk surveillance is easier than ever.
[01:02:39.600 --> 01:02:45.600]   And encryption does not force law enforcement to go dark by any means.
[01:02:45.600 --> 01:02:55.600]   Just to go back to the point about iOS 9, it's NPR, Washington Post, Wired and a couple other sites all said it's running iOS 9.
[01:02:55.600 --> 01:02:59.600]   Of course, they could all be reading off the same exact source as we do in the business.
[01:02:59.600 --> 01:03:00.600]   So you don't know.
[01:03:00.600 --> 01:03:01.600]   As we know, that does happen.
[01:03:01.600 --> 01:03:02.600]   I don't know what you're saying.
[01:03:02.600 --> 01:03:04.600]   I don't know what you're saying.
[01:03:04.600 --> 01:03:06.600]   That never happened.
[01:03:06.600 --> 01:03:07.600]   Never, never happens.
[01:03:07.600 --> 01:03:09.600]   Leo, I'm looking at the document right now.
[01:03:09.600 --> 01:03:13.600]   And one interesting piece of notice is it's not, it wasn't his phone.
[01:03:13.600 --> 01:03:14.600]   It belonged to the state.
[01:03:14.600 --> 01:03:15.600]   Right.
[01:03:15.600 --> 01:03:16.600]   Oh, that's right.
[01:03:16.600 --> 01:03:18.600]   It was, it was a phone provided to him by his employer.
[01:03:18.600 --> 01:03:19.600]   It was a work phone.
[01:03:19.600 --> 01:03:20.600]   Right.
[01:03:20.600 --> 01:03:28.600]   There's no question it does significantly because his employer has given permission for the phone's contents to be read.
[01:03:28.600 --> 01:03:34.600]   And since it's their phone, that's their, their, the, uh, right, the responsible party.
[01:03:34.600 --> 01:03:37.600]   They have the rights to say you can look at it.
[01:03:37.600 --> 01:03:38.600]   Yeah.
[01:03:38.600 --> 01:03:40.600]   It's only technological methods that are preventing them from looking at it.
[01:03:40.600 --> 01:03:43.600]   And it does say that it did receive the last update.
[01:03:43.600 --> 01:03:44.600]   Okay.
[01:03:44.600 --> 01:03:45.600]   So, okay.
[01:03:45.600 --> 01:03:47.600]   That would be iOS 9 and all like.
[01:03:47.600 --> 01:03:48.600]   I also read it.
[01:03:48.600 --> 01:03:49.600]   So there's no secure enclave.
[01:03:49.600 --> 01:03:51.600]   However, on the five C's.
[01:03:51.600 --> 01:03:56.200]   They have multiple, they have multiple backups of this phone already.
[01:03:56.200 --> 01:03:57.200]   So they have.
[01:03:57.200 --> 01:03:59.600]   Oh, that's actually that I guess the phone did.
[01:03:59.600 --> 01:04:00.600]   Yeah.
[01:04:00.600 --> 01:04:01.600]   Okay.
[01:04:01.600 --> 01:04:02.600]   I have a hold on one second.
[01:04:02.600 --> 01:04:05.600]   The beginning of the conversation, you said eight nine.
[01:04:05.600 --> 01:04:07.600]   It's all moot because it can't happen anyway.
[01:04:07.600 --> 01:04:15.600]   So does this mean that the government once they're once they can brute force has more capability to brute force this than we know?
[01:04:15.600 --> 01:04:16.600]   No.
[01:04:16.600 --> 01:04:19.600]   So the biggest difference is hardware difference.
[01:04:19.600 --> 01:04:24.600]   Subsequent iPhones have touch ID and what's something called a secure enclave.
[01:04:24.600 --> 01:04:25.600]   Which is on the chip, right?
[01:04:25.600 --> 01:04:26.600]   Yeah.
[01:04:26.600 --> 01:04:30.600]   And as far as we know, there's no government backdoor ability to crack it.
[01:04:30.600 --> 01:04:31.600]   And that happens.
[01:04:31.600 --> 01:04:32.600]   As far as we know.
[01:04:32.600 --> 01:04:37.600]   Well, but I have to believe that with Apple taking this strong stand today, that that's probably the case.
[01:04:37.600 --> 01:04:39.600]   They seem pretty principled.
[01:04:39.600 --> 01:04:43.600]   Tim Cook seems pretty principled in his argument against this.
[01:04:43.600 --> 01:04:50.600]   So you know, I admire Snowden and what he did.
[01:04:50.600 --> 01:04:52.600]   But I think, tell me if I'm wrong here.
[01:04:52.600 --> 01:04:56.600]   He on a tweet, he basically said, Google silence proves that they're on the wrong side.
[01:04:56.600 --> 01:04:57.600]   They're on the other side.
[01:04:57.600 --> 01:04:58.600]   This has been a couple hours.
[01:04:58.600 --> 01:04:59.600]   Yeah.
[01:04:59.600 --> 01:05:00.600]   You have to go.
[01:05:00.600 --> 01:05:01.600]   Lots of lawyers.
[01:05:01.600 --> 01:05:03.600]   Google has fought around encryption like crazy.
[01:05:03.600 --> 01:05:08.600]   Google's a victim of the NSA was enraged when they heard what was happening.
[01:05:08.600 --> 01:05:12.600]   I think it's a little unfair at this stage.
[01:05:12.600 --> 01:05:17.600]   Now, obviously I'm a Google defender all the time, but all I'm trying to say is.
[01:05:17.600 --> 01:05:18.600]   Are you encrypted?
[01:05:18.600 --> 01:05:20.600]   No, no, I'm not a person.
[01:05:20.600 --> 01:05:22.600]   Next is our encrypted.
[01:05:22.600 --> 01:05:23.600]   Yes.
[01:05:23.600 --> 01:05:25.600]   Since the next six, they've been encrypted.
[01:05:25.600 --> 01:05:31.600]   And I'm first asking basically with their public stand here vis-a-vis Apple, this takes time
[01:05:31.600 --> 01:05:33.600]   to go through a bureaucracy and lawyers and all that.
[01:05:33.600 --> 01:05:35.600]   And they get all kinds of implications.
[01:05:35.600 --> 01:05:41.600]   So if Google comes out with a statement saying screw Apple, I will, I will, you know, be critical
[01:05:41.600 --> 01:05:42.600]   of Google.
[01:05:42.600 --> 01:05:45.600]   But I think it's just a little too soon to condemn Google on this case.
[01:05:45.600 --> 01:05:47.600]   I did email them and I said, what is your stand?
[01:05:47.600 --> 01:05:48.600]   I haven't heard back yet.
[01:05:48.600 --> 01:05:49.600]   I don't expect to right away.
[01:05:49.600 --> 01:05:54.520]   But I do think that for other technology companies, yes, we'll wait and watch.
[01:05:54.520 --> 01:05:58.600]   I don't know what the proper amount of time is, but I agree that's a little soon.
[01:05:58.600 --> 01:06:00.600]   A little bit.
[01:06:00.600 --> 01:06:01.600]   Yeah.
[01:06:01.600 --> 01:06:02.600]   We'll hear from Google, I'm sure.
[01:06:02.600 --> 01:06:03.600]   I think so.
[01:06:03.600 --> 01:06:04.600]   That's the Twitter.
[01:06:04.600 --> 01:06:05.600]   That's the Twitter talking.
[01:06:05.600 --> 01:06:06.600]   Not Edward Snowden.
[01:06:06.600 --> 01:06:07.600]   That's the Twitter talking.
[01:06:07.600 --> 01:06:13.760]   Snowden tweeted a link to a New York Times story, which says the Chinese government is going
[01:06:13.760 --> 01:06:19.600]   to be watching very closely and that if law enforcement agencies push Apple to unlock
[01:06:19.600 --> 01:06:23.000]   the phone, it would embolden Beijing to demand the same.
[01:06:23.000 --> 01:06:28.760]   And I totally agree with you, Jeff, that that's the real concern is that once they show this
[01:06:28.760 --> 01:06:34.880]   capability, then it's a free-for-all with every country.
[01:06:34.880 --> 01:06:36.680]   But it's kind of a cheesy way to--
[01:06:36.680 --> 01:06:38.680]   Okay, but let me rise up.
[01:06:38.680 --> 01:06:44.000]   Let me rise up into the clouds of low oxygen, which is what I specialize in here.
[01:06:44.000 --> 01:06:49.360]   So fine, but I would argue that we're at a point now where we're questioning the very
[01:06:49.360 --> 01:06:53.560]   institution of government and that that's what we see happening in our election right
[01:06:53.560 --> 01:06:54.560]   now.
[01:06:54.560 --> 01:06:56.160]   It's what we see happening around the world.
[01:06:56.160 --> 01:07:02.360]   And technology has to decide and live on its principles as well.
[01:07:02.360 --> 01:07:07.640]   And we as technology users have to expect technology companies to do that and to fight
[01:07:07.640 --> 01:07:10.800]   for us because they do hold this power one way or the other.
[01:07:10.800 --> 01:07:13.720]   We've got to know what their principles are.
[01:07:13.720 --> 01:07:16.520]   And so that to me is that extra governmental?
[01:07:16.520 --> 01:07:17.520]   Yes.
[01:07:17.520 --> 01:07:18.520]   So is life.
[01:07:18.520 --> 01:07:22.800]   So is being able to talk to your priest and not have that revealed to government that
[01:07:22.800 --> 01:07:26.440]   the church came up with its principle and lives by its principle and psychiatrists came
[01:07:26.440 --> 01:07:28.160]   up with their principle and live by their parts.
[01:07:28.160 --> 01:07:30.280]   They were enshrined in law.
[01:07:30.280 --> 01:07:31.280]   Very important.
[01:07:31.280 --> 01:07:37.280]   But yes, I mean, I could I could decide that I am that I am, you know, as if you tell me
[01:07:37.280 --> 01:07:43.480]   things because I am a chief twit that is protected under the Twitter confidentiality agreement.
[01:07:43.480 --> 01:07:44.480]   That's the discussion.
[01:07:44.480 --> 01:07:49.400]   But government, but government has to then enshrine it in law before it's the law.
[01:07:49.400 --> 01:07:50.400]   That's the discussion we have to have.
[01:07:50.400 --> 01:07:53.920]   And that's the precedent that a court will eventually set in this discussion to say that
[01:07:53.920 --> 01:08:00.240]   when you entrust to a technology company, your security.
[01:08:00.240 --> 01:08:04.000]   And that can be so easily violated, then then we have forced an entire industry to not be
[01:08:04.000 --> 01:08:05.920]   trustworthy anymore.
[01:08:05.920 --> 01:08:09.000]   And the technology companies have to decide what their stand is as to what will they do
[01:08:09.000 --> 01:08:10.520]   to fight for us.
[01:08:10.520 --> 01:08:11.800]   And that's where Snowden's right.
[01:08:11.800 --> 01:08:13.960]   And that's where the issue is right now.
[01:08:13.960 --> 01:08:17.600]   And so in a sense, I would argue in a time when I think government institutions are going
[01:08:17.600 --> 01:08:22.920]   to be challenged all around the world, I'm not suggesting now that that, you know, Google
[01:08:22.920 --> 01:08:23.920]   is the new government.
[01:08:23.920 --> 01:08:24.920]   Google doesn't want that job.
[01:08:24.920 --> 01:08:29.440]   But the technology industry, because it is so international, because we depend upon it
[01:08:29.440 --> 01:08:35.240]   in all these ways, it's going to have to stand up to almost quasi legal questions of principle.
[01:08:35.240 --> 01:08:38.640]   According, Loris, let's let's say code is law.
[01:08:38.640 --> 01:08:39.640]   Yeah.
[01:08:39.640 --> 01:08:40.640]   And that's where we are right now.
[01:08:40.640 --> 01:08:41.640]   And that's why this discussion is so important.
[01:08:41.640 --> 01:08:44.040]   And that's why you can't just quickly say, Oh, judge said it.
[01:08:44.040 --> 01:08:45.440]   Okay, sorry guys, we got to do that.
[01:08:45.440 --> 01:08:50.440]   I salute cook for saying this is a much bigger discussion and dammit, we're going to have
[01:08:50.440 --> 01:08:51.440]   it.
[01:08:51.440 --> 01:08:56.120]   And I think the other thing, the other thing that troubles me at least is that I get the
[01:08:56.120 --> 01:09:02.240]   feeling and I don't know this, but I get the feeling that the FBI and other security agencies
[01:09:02.240 --> 01:09:05.840]   have been working on trying to get into iPhones on their own.
[01:09:05.840 --> 01:09:08.120]   They clearly want to set some kind of precedent.
[01:09:08.120 --> 01:09:09.620]   That's why they're doing this.
[01:09:09.620 --> 01:09:13.120]   So they want to be able to say, Look, you did it this one time.
[01:09:13.120 --> 01:09:17.600]   I want you to do that again, do it multiple times or let us do it.
[01:09:17.600 --> 01:09:22.560]   And I think it's that the precedent that's being set set is almost more important than
[01:09:22.560 --> 01:09:24.400]   just getting into this guy's phone.
[01:09:24.400 --> 01:09:25.400]   Absolutely.
[01:09:25.400 --> 01:09:31.320]   So the security agencies to argue in the future, what sort of kind of slippery slope are you
[01:09:31.320 --> 01:09:32.320]   starting on?
[01:09:32.320 --> 01:09:38.960]   And I think that's why Apple's resisting as hard as it is.
[01:09:38.960 --> 01:09:42.520]   It's a great conversation, but there's a lot of other things to talk about.
[01:09:42.520 --> 01:09:43.760]   So we are going to do that.
[01:09:43.760 --> 01:09:49.080]   But I thank Steve for dialing in and joining us and adding a considerable force and weight
[01:09:49.080 --> 01:09:50.080]   to the conversation.
[01:09:50.080 --> 01:09:54.400]   And boy, I can't think of three better people to talk about it.
[01:09:54.400 --> 01:09:55.400]   That's a great subject.
[01:09:55.400 --> 01:09:56.400]   It's a great subject.
[01:09:56.400 --> 01:09:57.400]   Yeah.
[01:09:57.400 --> 01:09:59.920]   It means so many things are crystallized in this example.
[01:09:59.920 --> 01:10:00.920]   Yeah.
[01:10:00.920 --> 01:10:06.640]   And I think putting myself in Tim Cook's shoes, I would do exactly what he did.
[01:10:06.640 --> 01:10:10.280]   Ah, yeah, I don't think he has a choice.
[01:10:10.280 --> 01:10:11.640]   I don't think he has a choice.
[01:10:11.640 --> 01:10:12.640]   All right.
[01:10:12.640 --> 01:10:13.640]   No, I'm not.
[01:10:13.640 --> 01:10:17.400]   But I, but I, but I, but I, but I use one of the things I fear.
[01:10:17.400 --> 01:10:22.400]   We've come to the point now and where we so mistrust government that we essentially want
[01:10:22.400 --> 01:10:24.160]   to throw the baby out with the bathwater.
[01:10:24.160 --> 01:10:27.000]   We just, well, that's just, you know, we can't trust government.
[01:10:27.000 --> 01:10:31.640]   So we can't, we shouldn't, we just forget it.
[01:10:31.640 --> 01:10:39.440]   And we have survived 250 years on the rule of law and on the, on the constitution.
[01:10:39.440 --> 01:10:42.280]   And those are very precious things.
[01:10:42.280 --> 01:10:44.720]   But they got that way by people pushing, right?
[01:10:44.720 --> 01:10:45.720]   Absolutely.
[01:10:45.720 --> 01:10:46.720]   I mean, it has to be a debate.
[01:10:46.720 --> 01:10:47.920]   The debate is not stops.
[01:10:47.920 --> 01:10:49.960]   It is not written in stone.
[01:10:49.960 --> 01:10:54.360]   It's not, you know, it's going to evolve.
[01:10:54.360 --> 01:10:58.800]   But ultimately, you know, the, we didn't have a coup in this country when the Supreme
[01:10:58.800 --> 01:11:02.200]   Court in 2000 ruled that George Bush won the election.
[01:11:02.200 --> 01:11:08.720]   One might argue it was a coup, but that's another, but it was a coup by, by the Supreme
[01:11:08.720 --> 01:11:09.720]   Court.
[01:11:09.720 --> 01:11:10.720]   Yes.
[01:11:10.720 --> 01:11:11.720]   Right.
[01:11:11.720 --> 01:11:15.840]   And because we have all agreed as a society that that's how it should be.
[01:11:15.840 --> 01:11:21.040]   The risk is if you start saying, well, I don't care as technologists, we have the right to
[01:11:21.040 --> 01:11:25.880]   encrypt and we're going to do it whether the Supreme Court says so or not of destroying
[01:11:25.880 --> 01:11:31.360]   something far more important, which is the rule of law and the national polity.
[01:11:31.360 --> 01:11:37.400]   And we need that, I think, or we will descend into, you know, and I totally agree, but there
[01:11:37.400 --> 01:11:42.800]   has to be a process where a security agency says we need into this guy's phone and you
[01:11:42.800 --> 01:11:45.600]   don't need to know why we got an order from the secret court.
[01:11:45.600 --> 01:11:46.600]   That's wrong.
[01:11:46.600 --> 01:11:50.160]   I think, yeah, I think there needs to be a little bit more to the origins of that.
[01:11:50.160 --> 01:11:51.160]   I agree.
[01:11:51.160 --> 01:11:52.160]   I would say three things.
[01:11:52.160 --> 01:11:56.000]   One, there, that we have to look upon this as a level of principles, no matter what the
[01:11:56.000 --> 01:11:58.480]   present technology is, what the president said.
[01:11:58.480 --> 01:12:02.240]   Two, we have to look at this internationally because we have to recognize what's being
[01:12:02.240 --> 01:12:03.240]   done.
[01:12:03.240 --> 01:12:05.080]   And three, we have to do it transparently.
[01:12:05.080 --> 01:12:07.240]   And that's why I'm glad to cook to what it is doing.
[01:12:07.240 --> 01:12:08.240]   Yeah.
[01:12:08.240 --> 01:12:11.080]   You know, this, believe me, if I didn't think this was an important conversation, I wouldn't
[01:12:11.080 --> 01:12:13.480]   have just voted an hour and a half to it.
[01:12:13.480 --> 01:12:14.480]   Jesus really?
[01:12:14.480 --> 01:12:16.120]   Well, an hour anyway.
[01:12:16.120 --> 01:12:17.800]   It's very important.
[01:12:17.800 --> 01:12:21.560]   And it's probably the most important technology as I said at the beginning, the most important
[01:12:21.560 --> 01:12:24.960]   story and technology of the year and maybe of all the year.
[01:12:24.960 --> 01:12:28.840]   But, you know, and I think there's much, many words that will be spoken over this and I
[01:12:28.840 --> 01:12:35.480]   don't know if there's a clear answer, but I would just, I would argue that just as you
[01:12:35.480 --> 01:12:41.640]   quite correctly say, encryption is vital for security and privacy for its citizens, I
[01:12:41.640 --> 01:12:47.160]   would also say that there's a reason we have rule of law because lacking that you have
[01:12:47.160 --> 01:12:53.840]   anarchy and that is even more dangerous to all citizens.
[01:12:53.840 --> 01:12:54.840]   Let us, let's see.
[01:12:54.840 --> 01:12:55.960]   You said you had breaking news.
[01:12:55.960 --> 01:12:58.000]   Is it there's so many things it could be?
[01:12:58.000 --> 01:13:03.040]   Let me just give you some of the things that could be breaking news.
[01:13:03.040 --> 01:13:04.600]   Yahoo, more layoffs.
[01:13:04.600 --> 01:13:07.160]   Something else in there.
[01:13:07.160 --> 01:13:13.120]   Yeah, Twitter, the new GIF button, Google has launched a new service G mailify to give
[01:13:13.120 --> 01:13:19.120]   you Gmail like capabilities in your inbox no matter who you use.
[01:13:19.120 --> 01:13:22.960]   And Facebook announces anyone can use instant articles starting April 12th.
[01:13:22.960 --> 01:13:23.960]   Is it one of those?
[01:13:23.960 --> 01:13:24.960]   A couple of those.
[01:13:24.960 --> 01:13:25.960]   Yep.
[01:13:25.960 --> 01:13:26.960]   There's a lot of things.
[01:13:26.960 --> 01:13:30.320]   I wrote about, I wrote about Giffy today.
[01:13:30.320 --> 01:13:31.320]   Giffy.
[01:13:31.320 --> 01:13:34.920]   I love Giffy or is it Giffy?
[01:13:34.920 --> 01:13:38.960]   Well, they pronounce it Giffy because otherwise, Giffy is a peanut butter.
[01:13:38.960 --> 01:13:41.800]   Oh, I guess in this case, it's it's Giffy.
[01:13:41.800 --> 01:13:43.560]   Giffy and Riffsy, we say it Riffsy.
[01:13:43.560 --> 01:13:44.560]   And Riffsy, right.
[01:13:44.560 --> 01:13:47.800]   So they're the ones behind the gift button.
[01:13:47.800 --> 01:13:49.560]   We'll talk about that momentarily.
[01:13:49.560 --> 01:13:50.560]   Okay.
[01:13:50.560 --> 01:13:51.560]   How about that?
[01:13:51.560 --> 01:13:55.800]   This is a, this is a, oh, and one more thing.
[01:13:55.800 --> 01:13:59.400]   Somehow an on tech got new software that Pixel C that makes it better.
[01:13:59.400 --> 01:14:01.480]   We'll talk about that.
[01:14:01.480 --> 01:14:03.000]   I'll tell you about my debt, Pixel C.
[01:14:03.000 --> 01:14:04.000]   Oh, no.
[01:14:04.000 --> 01:14:05.000]   We'll talk about it.
[01:14:05.000 --> 01:14:06.000]   You've got another one to be happy ending.
[01:14:06.000 --> 01:14:07.000]   It's going to be happy ending.
[01:14:07.000 --> 01:14:08.000]   Oh, it's has a happy ending.
[01:14:08.000 --> 01:14:09.000]   It will.
[01:14:09.000 --> 01:14:10.000]   It will.
[01:14:10.000 --> 01:14:11.000]   A few days.
[01:14:11.000 --> 01:14:12.000]   God damn it.
[01:14:12.000 --> 01:14:13.000]   I love that show.
[01:14:13.000 --> 01:14:19.120]   It's so much fun to talk about this stuff with smart, smart people.
[01:14:19.120 --> 01:14:22.000]   And I'm sorry I swore you could bleep that out right, Jason.
[01:14:22.000 --> 01:14:23.000]   We have.
[01:14:23.000 --> 01:14:24.720]   Oh, that's not a swear.
[01:14:24.720 --> 01:14:25.960]   Oh, it is.
[01:14:25.960 --> 01:14:28.080]   Did you swear?
[01:14:28.080 --> 01:14:29.440]   I didn't even notice.
[01:14:29.440 --> 01:14:30.440]   You did.
[01:14:30.440 --> 01:14:31.440]   You atheists.
[01:14:31.440 --> 01:14:32.440]   Sorry.
[01:14:32.440 --> 01:14:37.440]   I showed a, I'm sorry.
[01:14:37.440 --> 01:14:40.160]   I'm going straight to H.E.
[01:14:40.160 --> 01:14:42.360]   double hockey sticks.
[01:14:42.360 --> 01:14:47.320]   Our should had a brought to you by French books, the super simple cloud accounting software
[01:14:47.320 --> 01:14:51.600]   that's giving thousands of freelancers and small businesses the tools they need to save
[01:14:51.600 --> 01:14:54.040]   time billing to get paid faster.
[01:14:54.040 --> 01:14:57.040]   And I am a believer because believe me, I used fresh books.
[01:14:57.040 --> 01:15:02.920]   When they first started, I, it was like the clouds parted and the heavens began to sing
[01:15:02.920 --> 01:15:08.440]   because I was that freelancer who every month at the end of the month had a good all the
[01:15:08.440 --> 01:15:15.480]   receipts together, get the my file up, the fire up the Microsoft Excel and create an invoice,
[01:15:15.480 --> 01:15:17.760]   set it up, stamp it and mail it.
[01:15:17.760 --> 01:15:24.000]   I was complaining about it to Amber MacArthur because I had to bill Canada and Canadian dollars
[01:15:24.000 --> 01:15:29.200]   no less every month for my expenses and my time.
[01:15:29.200 --> 01:15:32.760]   And Amber said, would you stop complaining and go to fresh books?
[01:15:32.760 --> 01:15:33.760]   I said, what's fresh books?
[01:15:33.760 --> 01:15:34.760]   She showed me.
[01:15:34.760 --> 01:15:35.760]   They had just launched.
[01:15:35.760 --> 01:15:37.480]   It was like 2004.
[01:15:37.480 --> 01:15:43.000]   In the intervening few years, they have grown and gotten better and better.
[01:15:43.000 --> 01:15:44.920]   I did all my invoices with fresh books.
[01:15:44.920 --> 01:15:46.200]   They look great.
[01:15:46.200 --> 01:15:48.240]   I could mail them, but I also could email them and you know what?
[01:15:48.240 --> 01:15:51.080]   I got paid faster, not only because I invoiced on time.
[01:15:51.080 --> 01:15:52.240]   That was a big part.
[01:15:52.240 --> 01:15:53.520]   It was easy to do.
[01:15:53.520 --> 01:15:58.280]   But because there's a pay me button right there in the invoice in the email and the clients
[01:15:58.280 --> 01:16:00.600]   will pay you if you make it easy for them.
[01:16:00.600 --> 01:16:01.920]   Turns out right away.
[01:16:01.920 --> 01:16:05.160]   And if they don't, fresh books follows up automatically.
[01:16:05.160 --> 01:16:07.720]   Plus all those receipts I had in the shoe box.
[01:16:07.720 --> 01:16:10.040]   Now I can just take a picture of them with my smartphone.
[01:16:10.040 --> 01:16:12.760]   They didn't have this capability back in 2004.
[01:16:12.760 --> 01:16:14.360]   I didn't have a smartphone.
[01:16:14.360 --> 01:16:16.120]   I could take a picture.
[01:16:16.120 --> 01:16:22.000]   The fresh books app will automatically get that receipt into the invoice time and hours
[01:16:22.000 --> 01:16:23.000]   too.
[01:16:23.000 --> 01:16:24.720]   The new card reader, this is really sweet.
[01:16:24.720 --> 01:16:28.320]   Man, I didn't even dream of this in 2004.
[01:16:28.320 --> 01:16:35.040]   For people who work in your home, for instance, a high-figh installer, a plumber, they come
[01:16:35.040 --> 01:16:38.360]   to your home with the fresh books app.
[01:16:38.360 --> 01:16:40.960]   They can create an estimate, get your approval.
[01:16:40.960 --> 01:16:43.920]   Show it to you on the phone or email until you get your approval on the phone.
[01:16:43.920 --> 01:16:45.240]   Do the work.
[01:16:45.240 --> 01:16:48.440]   Get the make it invoice right there on the spot.
[01:16:48.440 --> 01:16:49.440]   Get your approval.
[01:16:49.440 --> 01:16:51.880]   And then you can swipe your card in their new card reader.
[01:16:51.880 --> 01:16:55.000]   CMV enabled so they can dip the chip too.
[01:16:55.000 --> 01:16:56.200]   And you get paid then.
[01:16:56.200 --> 01:16:58.240]   Oh my goodness.
[01:16:58.240 --> 01:16:59.600]   This is the new iPhone app.
[01:16:59.600 --> 01:17:00.600]   It's spectacular.
[01:17:00.600 --> 01:17:03.240]   Send an estimate right after the handshake.
[01:17:03.240 --> 01:17:05.760]   Create an invoice and send it in seconds from your phone.
[01:17:05.760 --> 01:17:07.880]   Track billable time anywhere you are.
[01:17:07.880 --> 01:17:09.760]   Track expenses with the camera.
[01:17:09.760 --> 01:17:11.200]   This is sweet.
[01:17:11.200 --> 01:17:13.400]   And it's yours free for the next 30 days.
[01:17:13.400 --> 01:17:16.200]   When you go to freshbooks.com/twig.
[01:17:16.200 --> 01:17:20.000]   And don't forget to tell them you heard about it on this week in Google.
[01:17:20.000 --> 01:17:23.160]   Freshbooks.com/twig.
[01:17:23.160 --> 01:17:25.920]   Start your 30 day free trial right now.
[01:17:25.920 --> 01:17:26.920]   You will thank me.
[01:17:26.920 --> 01:17:27.920]   I promise.
[01:17:27.920 --> 01:17:28.920]   I thank Danber.
[01:17:28.920 --> 01:17:29.920]   I thank your still.
[01:17:29.920 --> 01:17:34.760]   Leo, I think when you started using it, Mike McDermott was still running it out of his
[01:17:34.760 --> 01:17:36.040]   parents basement.
[01:17:36.040 --> 01:17:37.800]   Don't tell me that.
[01:17:37.800 --> 01:17:39.960]   It's in Toronto.
[01:17:39.960 --> 01:17:40.960]   So you know these guys.
[01:17:40.960 --> 01:17:41.960]   Yeah.
[01:17:41.960 --> 01:17:42.960]   Yeah.
[01:17:42.960 --> 01:17:43.960]   Mike and I are old friends.
[01:17:43.960 --> 01:17:44.960]   I love it.
[01:17:44.960 --> 01:17:45.960]   You know what?
[01:17:45.960 --> 01:17:46.960]   Was it really out of his parents basement?
[01:17:46.960 --> 01:17:47.960]   Yeah.
[01:17:47.960 --> 01:17:48.960]   It was for years.
[01:17:48.960 --> 01:17:49.960]   Really?
[01:17:49.960 --> 01:17:50.960]   Yeah.
[01:17:50.960 --> 01:17:55.600]   So we talked about it like as one of the first Web 2.0.
[01:17:55.600 --> 01:17:56.600]   This is how old it is.
[01:17:56.600 --> 01:17:57.600]   Web 2.0 websites.
[01:17:57.600 --> 01:17:58.600]   It was beautiful.
[01:17:58.600 --> 01:17:59.600]   Yeah.
[01:17:59.600 --> 01:18:05.840]   And he started it because he was, I think he was in, he was playing ultimate.
[01:18:05.840 --> 01:18:06.840]   Funny.
[01:18:06.840 --> 01:18:07.840]   Frisbee.
[01:18:07.840 --> 01:18:14.480]   And he wanted, he was doing events for the team and he wanted a way to build.
[01:18:14.480 --> 01:18:18.920]   And he found all the existing ways so frustrating that he decided to create his own.
[01:18:18.920 --> 01:18:23.680]   They're at, this is the team now and they are a good looking bunch including that guy
[01:18:23.680 --> 01:18:27.040]   in the Blue Jays jersey.
[01:18:27.040 --> 01:18:28.120]   Is Mike in his picture?
[01:18:28.120 --> 01:18:31.280]   Is he looking for him?
[01:18:31.280 --> 01:18:32.280]   They've moved.
[01:18:32.280 --> 01:18:35.960]   It's not his parents basement unless his parents live in a fairly large building.
[01:18:35.960 --> 01:18:38.360]   I think they've moved three or four times now.
[01:18:38.360 --> 01:18:39.360]   Yeah.
[01:18:39.360 --> 01:18:40.360]   They've grown.
[01:18:40.360 --> 01:18:42.040]   Last time I saw him I said, are you moving again?
[01:18:42.040 --> 01:18:44.400]   So proud of, well, you should be proud of me.
[01:18:44.400 --> 01:18:46.280]   I'm so thrilled with what that's great company.
[01:18:46.280 --> 01:18:47.280]   It is.
[01:18:47.280 --> 01:18:48.280]   FreshBooks.com.
[01:18:48.280 --> 01:18:50.280]   Well, that's nice.
[01:18:50.280 --> 01:18:52.440]   I mean, maybe we've talked about that before.
[01:18:52.440 --> 01:18:53.720]   That's really cool.
[01:18:53.720 --> 01:18:59.520]   So Brandon Chester wrote a somewhat scathing review of the Pixel C and I think he was not
[01:18:59.520 --> 01:19:00.520]   alone.
[01:19:00.520 --> 01:19:04.280]   Many of us who bought the Google tablet were just kind of felt like the hardware was really
[01:19:04.280 --> 01:19:11.520]   great but that the Android version that came on it, 6.01 or whatever, was just wasn't
[01:19:11.520 --> 01:19:12.520]   all there.
[01:19:12.520 --> 01:19:18.680]   It was a little bit buggy, slow.
[01:19:18.680 --> 01:19:22.040]   And that's kind of what Brandon said.
[01:19:22.040 --> 01:19:26.640]   He reached out to Google and Google gave him an update.
[01:19:26.640 --> 01:19:30.680]   He was offered, he says, the chance to test a new unit that would run a new unreleased
[01:19:30.680 --> 01:19:35.560]   build containing fixes Google plans to release to the public in the future.
[01:19:35.560 --> 01:19:39.000]   Given the fact that Pixel C has solid hardware that's only let down by buggy software, the
[01:19:39.000 --> 01:19:46.600]   chance to see their improvements was welcome.
[01:19:46.600 --> 01:19:48.080]   So he goes through it.
[01:19:48.080 --> 01:19:51.600]   He says, you know, it's better.
[01:19:51.600 --> 01:19:54.760]   Still not perfect.
[01:19:54.760 --> 01:19:57.840]   I still am hoping for Chrome OS on the thing.
[01:19:57.840 --> 01:19:59.680]   I just I really love the hardware.
[01:19:59.680 --> 01:20:00.680]   Yeah.
[01:20:00.680 --> 01:20:02.680]   I'm hoping for any of us.
[01:20:02.680 --> 01:20:03.680]   What happened?
[01:20:03.680 --> 01:20:04.680]   Oh, me.
[01:20:04.680 --> 01:20:06.080]   Did you drop it?
[01:20:06.080 --> 01:20:11.360]   No, it's the Android's dead.
[01:20:11.360 --> 01:20:13.680]   Android has a little red triangle coming out of its tongue.
[01:20:13.680 --> 01:20:14.680]   God bless Google.
[01:20:14.680 --> 01:20:17.480]   You know, I went through a few diagnostics and call them up and I said it's gotten worse
[01:20:17.480 --> 01:20:20.440]   and worse as before this went fully dead.
[01:20:20.440 --> 01:20:22.600]   And no argument, no complaint.
[01:20:22.600 --> 01:20:25.280]   Send me the keyboards broken to their semi both of me in the red way.
[01:20:25.280 --> 01:20:26.480]   And no folks, it's not because it's me.
[01:20:26.480 --> 01:20:30.280]   I just called the number and I'm just some guy with the device.
[01:20:30.280 --> 01:20:33.760]   The Twitter complaint, they jumped on it maybe because it's me, but not the phone.
[01:20:33.760 --> 01:20:34.760]   They were great.
[01:20:34.760 --> 01:20:38.760]   Yeah, it remember when I was on the show from a hotel and the thing went
[01:20:38.760 --> 01:20:39.760]   completely?
[01:20:39.760 --> 01:20:40.760]   Yep.
[01:20:40.760 --> 01:20:44.560]   Brandon says this too, by the way, that would be random crashes.
[01:20:44.560 --> 01:20:45.560]   I couldn't restart it.
[01:20:45.560 --> 01:20:46.560]   I couldn't restart it.
[01:20:46.560 --> 01:20:47.560]   I finally got it to restart.
[01:20:47.560 --> 01:20:48.560]   Happened again.
[01:20:48.560 --> 01:20:50.600]   I was nervous about it ever since.
[01:20:50.600 --> 01:20:56.920]   And then like a week ago, it started doing it where it would just crash or I couldn't
[01:20:56.920 --> 01:21:02.520]   get it going or it would take many, many, many, many attempts to get started.
[01:21:02.520 --> 01:21:04.400]   I finally get it started.
[01:21:04.400 --> 01:21:09.120]   But for God's sakes, so then I rebuild it and it got worse quickly.
[01:21:09.120 --> 01:21:14.080]   And in fact, I was starting at one last time so I could erase, you know, I could clear
[01:21:14.080 --> 01:21:15.080]   the machine.
[01:21:15.080 --> 01:21:16.920]   Then I can't get to it.
[01:21:16.920 --> 01:21:17.920]   I should clear it before.
[01:21:17.920 --> 01:21:18.920]   So it is going to be okay.
[01:21:18.920 --> 01:21:21.080]   Google will erase it if there's any data on there, right?
[01:21:21.080 --> 01:21:22.080]   Yes, of course.
[01:21:22.080 --> 01:21:23.080]   Sure, they will.
[01:21:23.080 --> 01:21:25.600]   They'll hand it right over to the NS.
[01:21:25.600 --> 01:21:28.320]   The FBI gets it first.
[01:21:28.320 --> 01:21:29.680]   By the way, that is encrypted.
[01:21:29.680 --> 01:21:32.920]   All of Google's Nexus devices are encrypted out of the box.
[01:21:32.920 --> 01:21:33.920]   They're encrypted by default.
[01:21:33.920 --> 01:21:35.920]   By default, you can turn it off.
[01:21:35.920 --> 01:21:36.920]   But they aren't encrypted by default.
[01:21:36.920 --> 01:21:41.680]   In fact, with the Nexus 6, the Shamu, the big one, people really complain because it slowed
[01:21:41.680 --> 01:21:46.320]   down and disk performance considerably because I guess it wasn't hardware support.
[01:21:46.320 --> 01:21:50.080]   So is there a reason why the Pixel C doesn't have Chrome OS on it?
[01:21:50.080 --> 01:21:51.080]   Like why?
[01:21:51.080 --> 01:21:52.680]   Well, we heard that story, right?
[01:21:52.680 --> 01:21:58.840]   And I don't know how true it is that it was designed for Chrome OS or some actually
[01:21:58.840 --> 01:22:04.880]   not exactly Chrome OS, a hybrid OS that Google was developing and killed at the last minute.
[01:22:04.880 --> 01:22:08.120]   And some kind of turf war between Android and Chrome.
[01:22:08.120 --> 01:22:10.520]   It sounds like when Andy Rubin left.
[01:22:10.520 --> 01:22:12.280]   Here's the issue, Matthew.
[01:22:12.280 --> 01:22:13.280]   Here's the issue.
[01:22:13.280 --> 01:22:16.720]   I keep on trying to get my head around this because it is I'm in the middle ground, right?
[01:22:16.720 --> 01:22:24.080]   I've got my, my, my, my, my, my, my six, my seven, my nine inch this, my Chromebook.
[01:22:24.080 --> 01:22:28.560]   If if the Pixel C were a Chromebook, it would be, you know, a laptop substitute.
[01:22:28.560 --> 01:22:31.240]   But it wouldn't be though, what I use it for is I'm on the plane.
[01:22:31.240 --> 01:22:33.040]   I'm watching movies.
[01:22:33.040 --> 01:22:36.560]   The downloading onto Chrome OS does not work well.
[01:22:36.560 --> 01:22:38.240]   I've gotten to work yet at all.
[01:22:38.240 --> 01:22:39.240]   Interesting.
[01:22:39.240 --> 01:22:40.240]   No, that's a good question.
[01:22:40.240 --> 01:22:41.760]   It's just not as good at that.
[01:22:41.760 --> 01:22:46.320]   So those, those things that you want to run apps for.
[01:22:46.320 --> 01:22:48.040]   That's what Android is good at.
[01:22:48.040 --> 01:22:49.040]   Okay.
[01:22:49.040 --> 01:22:53.680]   Versus, but as a laptop and a productivity device and getting full value out of the software,
[01:22:53.680 --> 01:22:57.240]   including there's all kinds of things the docs doesn't do on it, it sucks.
[01:22:57.240 --> 01:22:58.720]   So it's stuck in a bad middle ground.
[01:22:58.720 --> 01:23:00.120]   This is where he's right.
[01:23:00.120 --> 01:23:04.120]   It's, it's a less than optimal Android device and a less than it would be a less than optimal
[01:23:04.120 --> 01:23:07.240]   Chrome device or desktop device or laptop substitute.
[01:23:07.240 --> 01:23:11.680]   So they do need to figure out how to get the two OS's together and just feel it's not
[01:23:11.680 --> 01:23:14.720]   like those would be functions and say what functions should it do well?
[01:23:14.720 --> 01:23:16.240]   Let's make it do it well.
[01:23:16.240 --> 01:23:19.080]   And what if Chrome OS had better downloading built in?
[01:23:19.080 --> 01:23:22.240]   Well, let me tell you, this is the story according to Ron Amadio.
[01:23:22.240 --> 01:23:26.160]   This is actually, and while I'm telling this story, Jeff, unplug and replug your headset
[01:23:26.160 --> 01:23:30.200]   because we're getting some, some weird effects on there.
[01:23:30.200 --> 01:23:38.240]   Back in 2014, July 2014, a new REU board, mother board was popping up in the Chrome OS
[01:23:38.240 --> 01:23:41.280]   open source repository.
[01:23:41.280 --> 01:23:46.800]   Further trips to the source code revealed that REU had a light bar like the Pixel C,
[01:23:46.800 --> 01:23:51.640]   USB type C connectors like the Pixel C and NVIDIA Tegra SOC.
[01:23:51.640 --> 01:23:53.240]   Pixel C has the X, X1.
[01:23:53.240 --> 01:23:54.240]   Yeah.
[01:23:54.240 --> 01:23:57.240]   And wireless charging.
[01:23:57.240 --> 01:24:02.880]   And in fact, you see in the source code on the Pixel C, the product name REU.
[01:24:02.880 --> 01:24:08.920]   So this was going to be the launch hardware according to Ron for an all new, all touch
[01:24:08.920 --> 01:24:13.960]   version of Chrome OS, which at some point got canceled.
[01:24:13.960 --> 01:24:17.800]   And it's a really great story if you read through this.
[01:24:17.800 --> 01:24:20.880]   And Ron's done some good reporting, I think, on this.
[01:24:20.880 --> 01:24:27.400]   The Chrome OS was working on a new interface called Project Athena, which added a lot of
[01:24:27.400 --> 01:24:30.360]   functionality based on touchscreen usage.
[01:24:30.360 --> 01:24:35.100]   It's right about the same time, July 2014, that we started to see references to the Pixel
[01:24:35.100 --> 01:24:36.960]   C project REU.
[01:24:36.960 --> 01:24:41.320]   The biggest addition we knew about says Ron was an experimental window switcher, which
[01:24:41.320 --> 01:24:47.080]   would have taken Chrome OS's Windows management UI from a taskbar interface to a cascading,
[01:24:47.080 --> 01:24:53.080]   like rolling thumbnail UI that looks a lot like you see in Marshmallow.
[01:24:53.080 --> 01:24:54.080]   They added swipe gestures.
[01:24:54.080 --> 01:24:58.920]   I don't know if they would have added the media features you are looking for, but Project
[01:24:58.920 --> 01:25:02.320]   Athena never shipped in December 2014.
[01:25:02.320 --> 01:25:05.400]   The project was canceled.
[01:25:05.400 --> 01:25:09.520]   So with no touch interface to run on the 10 inch touchscreen, no mouse to drive the
[01:25:09.520 --> 01:25:15.440]   mouse center Chrome OS, the Pixel C was in a pickle.
[01:25:15.440 --> 01:25:25.520]   And so for a while, they considered dual booting and writing Chrome OS.
[01:25:25.520 --> 01:25:27.360]   But that idea only last about five months.
[01:25:27.360 --> 01:25:31.400]   In July 2015, the dual boot project seems to have been scrapped.
[01:25:31.400 --> 01:25:35.480]   A comment on a REU commit mentioned the cancellation while giving us more evidence is so great
[01:25:35.480 --> 01:25:41.080]   that you can go back through Git commits and look at the comments and learn so much the
[01:25:41.080 --> 01:25:42.880]   comments that abandoned.
[01:25:42.880 --> 01:25:47.080]   Frankenboard is dead.
[01:25:47.080 --> 01:25:48.080]   Frankenboard.
[01:25:48.080 --> 01:25:49.840]   As the weeks went out for beers.
[01:25:49.840 --> 01:25:55.120]   Yeah, well, they came up with Plan C. We got it.
[01:25:55.120 --> 01:25:59.160]   Let's ship it in September, just a couple months later, the Nexus launch event, they
[01:25:59.160 --> 01:26:00.760]   announced the Android 6 power pixel.
[01:26:00.760 --> 01:26:04.440]   So you remember what a shock that was and he was showing the keyboard thing?
[01:26:04.440 --> 01:26:08.480]   This was just two months after Frankenboard was killed.
[01:26:08.480 --> 01:26:13.160]   And then I just remember they didn't announce a ship date, but all of a sudden December
[01:26:13.160 --> 01:26:15.800]   8th, everybody says, oh, it's on them.
[01:26:15.800 --> 01:26:17.640]   It's for sale and you and audit and I bought it.
[01:26:17.640 --> 01:26:20.320]   We all rushed out and bought one.
[01:26:20.320 --> 01:26:23.200]   And as a, you know, I keep on dripping.
[01:26:23.200 --> 01:26:24.920]   So I love and I still love.
[01:26:24.920 --> 01:26:28.720]   I feel I feel disloyal to my neck by my seven inch, right?
[01:26:28.720 --> 01:26:29.720]   Yeah, the Nexus seven.
[01:26:29.720 --> 01:26:31.360]   The Nexus seven is beautiful.
[01:26:31.360 --> 01:26:33.320]   It's not sold anymore.
[01:26:33.320 --> 01:26:34.640]   It's the right size for a pocket.
[01:26:34.640 --> 01:26:36.720]   It's the right size for me sitting on the subway.
[01:26:36.720 --> 01:26:42.320]   The problem with it with the Pixel C is it's just it's so big to hold it on a subway or
[01:26:42.320 --> 01:26:44.280]   a train or something.
[01:26:44.280 --> 01:26:47.480]   And again, it's it's a bad laptop substitute.
[01:26:47.480 --> 01:26:48.480]   Oh, I love it.
[01:26:48.480 --> 01:26:51.840]   It's a too big tablet, but I love it.
[01:26:51.840 --> 01:26:53.800]   The screen is gorgeous.
[01:26:53.800 --> 01:26:58.000]   And I feel like I'm really relieved to hear that Google's working on it.
[01:26:58.000 --> 01:26:59.840]   Like they're not going to abandon it.
[01:26:59.840 --> 01:27:00.840]   Abandon it.
[01:27:00.840 --> 01:27:01.840]   Yeah.
[01:27:01.840 --> 01:27:03.040]   The fixes aren't enough yet.
[01:27:03.040 --> 01:27:04.400]   They fix some of the obvious things that are there.
[01:27:04.400 --> 01:27:06.320]   They're low hanging bad fruit.
[01:27:06.320 --> 01:27:07.320]   Fine.
[01:27:07.320 --> 01:27:08.960]   There's something there.
[01:27:08.960 --> 01:27:14.000]   There's some day in which when I'm traveling around the world, I want to take that as the
[01:27:14.000 --> 01:27:15.000]   only device.
[01:27:15.000 --> 01:27:16.000]   It'll be lighter.
[01:27:16.000 --> 01:27:17.360]   It'll be good on the plane.
[01:27:17.360 --> 01:27:19.920]   It'll be good, but they've got to fix.
[01:27:19.920 --> 01:27:24.480]   They've got to fix the productivity uses because they put the keyboard in there in a way that
[01:27:24.480 --> 01:27:28.680]   you're not going to expect to use docs really well and it doesn't do docs well.
[01:27:28.680 --> 01:27:32.600]   And you've got to expect that it's not going to make apps really awkwardly huge.
[01:27:32.600 --> 01:27:34.240]   And they've got to work on other things as well.
[01:27:34.240 --> 01:27:38.120]   But you can start to see this future, but they've got to care about this.
[01:27:38.120 --> 01:27:39.120]   Yeah.
[01:27:39.120 --> 01:27:42.440]   We're going to call you back, Jeff, because it came back and didn't solve it.
[01:27:42.440 --> 01:27:43.440]   Sorry.
[01:27:43.440 --> 01:27:44.440]   That's OK.
[01:27:44.440 --> 01:27:48.280]   Well, Matthew and I talk about Jiffy and Riffy.
[01:27:48.280 --> 01:27:51.720]   So this I, you know, I love, I use Facebook Messenger.
[01:27:51.720 --> 01:27:53.280]   I use a telegram.
[01:27:53.280 --> 01:27:55.320]   Both have GIF buttons.
[01:27:55.320 --> 01:27:56.320]   Use telegram?
[01:27:56.320 --> 01:27:57.320]   Yeah, love telegram.
[01:27:57.320 --> 01:27:58.320]   Interesting.
[01:27:58.320 --> 01:28:03.320]   I wish other people used it, but since I'm the only one, it's kind of boring.
[01:28:03.320 --> 01:28:10.680]   It's not a great experience, but it's fun because you can type.
[01:28:10.680 --> 01:28:12.280]   Messenger does this too.
[01:28:12.280 --> 01:28:17.600]   You hit the GIF button and then you type a word and it will find matching animated.
[01:28:17.600 --> 01:28:19.280]   You use Slack at all.
[01:28:19.280 --> 01:28:20.680]   Slack, same thing.
[01:28:20.680 --> 01:28:25.280]   So Slack, yeah, their Giffy integration is fantastic.
[01:28:25.280 --> 01:28:26.520]   We use Slack at Fortune.
[01:28:26.520 --> 01:28:28.800]   We use it at Gigam.
[01:28:28.800 --> 01:28:33.560]   And using the right GIF, you know, is a great feeling.
[01:28:33.560 --> 01:28:38.760]   I thought, I have to confess that I actually thought because I'm an old person and words
[01:28:38.760 --> 01:28:43.640]   are my thing, I thought GIFs were kind of dumb and sort of infantile.
[01:28:43.640 --> 01:28:46.440]   No, actually it's old people that love GIFs.
[01:28:46.440 --> 01:28:48.480]   Yeah, well, no, they do.
[01:28:48.480 --> 01:28:53.080]   But I think people actually like them because they can be very effective.
[01:28:53.080 --> 01:28:56.480]   They can trigger, you know, whether it's a laugh or a...
[01:28:56.480 --> 01:28:59.040]   or a smile or...
[01:28:59.040 --> 01:29:03.360]   It's like a teeny, tiny movie, you know, it's like a little...
[01:29:03.360 --> 01:29:07.080]   And so I actually have kind of come around to them in a way.
[01:29:07.080 --> 01:29:09.040]   I felt the same way about emojis.
[01:29:09.040 --> 01:29:14.800]   I thought they were dumb and that kids used them and they were dumbing down the population
[01:29:14.800 --> 01:29:15.800]   or so on.
[01:29:15.800 --> 01:29:21.520]   But there are ways you can communicate visually through things like a GIF or an emoji that
[01:29:21.520 --> 01:29:22.520]   are different than you...
[01:29:22.520 --> 01:29:27.840]   I mean, you could either type a thousand words to try to describe something or you could just,
[01:29:27.840 --> 01:29:31.280]   you know, use a clip of Donald Trump looking like an idiot.
[01:29:31.280 --> 01:29:33.840]   And so it is very powerful.
[01:29:33.840 --> 01:29:40.240]   There was this evolution in Telegram really did it where we went from emoticons, right?
[01:29:40.240 --> 01:29:48.800]   Semi-colon dash, right, to emoji, which basically had really the kind of the same weight as emoticons
[01:29:48.800 --> 01:29:52.600]   except they were easier to figure out in a bigger variety, but they were still tiny.
[01:29:52.600 --> 01:29:54.280]   And then stickers.
[01:29:54.280 --> 01:29:55.760]   We went through this sticker phase.
[01:29:55.760 --> 01:29:57.280]   Yeah, and Facebook like stickers.
[01:29:57.280 --> 01:29:58.280]   Yeah.
[01:29:58.280 --> 01:30:01.120]   Because they want to basically take over emojis and have their own.
[01:30:01.120 --> 01:30:05.160]   There's a revenue model in stickers and still like them using them too.
[01:30:05.160 --> 01:30:09.480]   I have a whole set of Donald Trump stickers.
[01:30:09.480 --> 01:30:15.000]   And the thing that Telegram did that I love is that Telegram tied its stickers to the emoji.
[01:30:15.000 --> 01:30:18.760]   So what you do is you type the thumbs up emoji, but you say, "But I want a sticker."
[01:30:18.760 --> 01:30:22.080]   And then you can get the Donald doing a thumbs up or...
[01:30:22.080 --> 01:30:25.320]   Oh, yeah, so cool.
[01:30:25.320 --> 01:30:29.040]   This is actually probably the most sophisticated use of this.
[01:30:29.040 --> 01:30:35.920]   You know, today my brilliant colleague, Professor Kerry Brown, talked to all of the main journals
[01:30:35.920 --> 01:30:38.480]   and professors today about how to judge social media and that kind of stuff.
[01:30:38.480 --> 01:30:42.720]   I just imagine them all watching the conversation YouTube just had for the last three minutes.
[01:30:42.720 --> 01:30:44.360]   Their heads are going to go slow.
[01:30:44.360 --> 01:30:45.360]   Well, welcome to the news.
[01:30:45.360 --> 01:30:46.360]   So look, I've typed it.
[01:30:46.360 --> 01:30:47.360]   And I was there too.
[01:30:47.360 --> 01:30:48.360]   I was there.
[01:30:48.360 --> 01:30:50.360]   Well, but it's exactly right.
[01:30:50.360 --> 01:30:52.360]   It's much more nuanced than text.
[01:30:52.360 --> 01:30:53.360]   Yeah.
[01:30:53.360 --> 01:30:54.360]   And it's fun.
[01:30:54.360 --> 01:30:56.640]   So you can show the lower part of...
[01:30:56.640 --> 01:30:58.000]   Yeah, you can show the screen.
[01:30:58.000 --> 01:30:59.720]   I don't think there's anything wrong with this, Jason.
[01:30:59.720 --> 01:31:04.280]   So I typed a thumbs up emoji and then it's offering me because I have a lot of sticker
[01:31:04.280 --> 01:31:05.480]   sets.
[01:31:05.480 --> 01:31:09.480]   It's offering me George Costanza Fallout 4.
[01:31:09.480 --> 01:31:11.560]   But I think I'll use the...
[01:31:11.560 --> 01:31:13.060]   Oh!
[01:31:13.060 --> 01:31:14.060]   The Trump.
[01:31:14.060 --> 01:31:15.760]   I mean, but I...
[01:31:15.760 --> 01:31:18.240]   So you could do a heart and then you get all the...
[01:31:18.240 --> 01:31:21.360]   If there are stickers that correspond to hearts, which there aren't.
[01:31:21.360 --> 01:31:22.560]   You bought the stickers?
[01:31:22.560 --> 01:31:23.560]   No, no, no.
[01:31:23.560 --> 01:31:24.960]   This is a nice thing about Telegram.
[01:31:24.960 --> 01:31:25.960]   Everything's free.
[01:31:25.960 --> 01:31:28.320]   But you said there's a business ball on the stickers.
[01:31:28.320 --> 01:31:29.760]   But there is for Facebook.
[01:31:29.760 --> 01:31:30.860]   For Facebook, yeah.
[01:31:30.860 --> 01:31:33.160]   And for others, including...
[01:31:33.160 --> 01:31:35.560]   And this is where the story is leading, perhaps Twitter.
[01:31:35.560 --> 01:31:38.240]   Look, I can also do Taylor Swift.
[01:31:38.240 --> 01:31:39.240]   Thumbs up.
[01:31:39.240 --> 01:31:40.240]   That's a...
[01:31:40.240 --> 01:31:42.400]   So Twitter is a great example.
[01:31:42.400 --> 01:31:48.700]   When it first implemented auto play animated GIFs, I thought, "This is terrible.
[01:31:48.700 --> 01:31:51.060]   This is going to ruin Twitter."
[01:31:51.060 --> 01:31:54.820]   So, you know, and I was very vocal about how and...
[01:31:54.820 --> 01:31:57.020]   And vine auto play and all those other things.
[01:31:57.020 --> 01:32:03.860]   And I was completely wrong because some days, the GIFs that I see that people post are the
[01:32:03.860 --> 01:32:06.620]   most enjoyable point of my day.
[01:32:06.620 --> 01:32:08.380]   Maybe that says a lot about my day.
[01:32:08.380 --> 01:32:09.780]   No, it's true.
[01:32:09.780 --> 01:32:16.800]   But after Jeb Bush posted that photo of his gun or whatever and said America, the anime
[01:32:16.800 --> 01:32:22.120]   GIFs I saw after that, 15 or 20 of them were hysterical.
[01:32:22.120 --> 01:32:23.120]   And so...
[01:32:23.120 --> 01:32:24.120]   What is your...
[01:32:24.120 --> 01:32:25.120]   Well, look, now compare it to...
[01:32:25.120 --> 01:32:26.120]   So now...
[01:32:26.120 --> 01:32:27.120]   And this is why I agree with you.
[01:32:27.120 --> 01:32:28.120]   So this is now...
[01:32:28.120 --> 01:32:30.320]   This is now Messenger.
[01:32:30.320 --> 01:32:34.080]   And this started, I think, really with an Apple keyboard for Jiffy.
[01:32:34.080 --> 01:32:35.080]   Giffy.
[01:32:35.080 --> 01:32:37.640]   Because now I've tied thumbs up as the search.
[01:32:37.640 --> 01:32:39.940]   So I can get a rather large...
[01:32:39.940 --> 01:32:42.040]   And isn't that better than the emoticons?
[01:32:42.040 --> 01:32:45.980]   And many of them are very topical, right?
[01:32:45.980 --> 01:32:46.980]   And so you...
[01:32:46.980 --> 01:32:47.980]   I think Rixie has a keyboard.
[01:32:47.980 --> 01:32:48.980]   Yeah.
[01:32:48.980 --> 01:32:51.760]   I think Rixie and Jiffy both came from third party...
[01:32:51.760 --> 01:32:53.320]   At least the first time I saw them.
[01:32:53.320 --> 01:32:57.700]   Third party keyboards on iOS.
[01:32:57.700 --> 01:32:58.700]   There you go.
[01:32:58.700 --> 01:32:59.700]   There's my thumbs up.
[01:32:59.700 --> 01:33:07.340]   There's actually a Twitter account that I just came across called @slashgiff.
[01:33:07.340 --> 01:33:09.060]   And I'm not sure who does it.
[01:33:09.060 --> 01:33:16.740]   But if you @mention@slashgiff and then you put a word in, it will just randomly reply
[01:33:16.740 --> 01:33:19.540]   to you with a GIF.
[01:33:19.540 --> 01:33:21.540]   So it will just randomly choose.
[01:33:21.540 --> 01:33:26.280]   So if you post love or Trump or thumbs, it will just pick one random.
[01:33:26.280 --> 01:33:27.780]   Is it just GIF?
[01:33:27.780 --> 01:33:29.020]   Is the Twitter handle?
[01:33:29.020 --> 01:33:30.020]   Slashgiff.
[01:33:30.020 --> 01:33:31.020]   So...
[01:33:31.020 --> 01:33:32.020]   S-L-A-S-L-A-S-H?
[01:33:32.020 --> 01:33:33.020]   Yeah.
[01:33:33.020 --> 01:33:34.020]   Yeah.
[01:33:34.020 --> 01:33:35.020]   Giff.
[01:33:35.020 --> 01:33:36.620]   Yeah, because you can't use the...
[01:33:36.620 --> 01:33:37.620]   There it is.
[01:33:37.620 --> 01:33:38.620]   /giff.
[01:33:38.620 --> 01:33:39.620]   I find GIFs for you.
[01:33:39.620 --> 01:33:40.620]   Tweet a search term.
[01:33:40.620 --> 01:33:41.620]   Oh, nice.
[01:33:41.620 --> 01:33:42.620]   Nice.
[01:33:42.620 --> 01:33:47.740]   So you just mentioned @slashgiff and the term and it responds to you with whatever comes
[01:33:47.740 --> 01:33:48.740]   up with...
[01:33:48.740 --> 01:33:50.340]   Oh, I'm gonna follow this call.
[01:33:50.340 --> 01:33:51.340]   It's quite fun.
[01:33:51.340 --> 01:33:52.340]   It's quite fun.
[01:33:52.340 --> 01:33:58.740]   So Twitter is institutionalizing this as every text-based messaging platform should.
[01:33:58.740 --> 01:34:04.780]   And it's interesting when I mentioned this in the post I did about Giffy, my sort of,
[01:34:04.780 --> 01:34:08.420]   you know, the reluctance to see GIFs as a...
[01:34:08.420 --> 01:34:14.860]   Not just my reluctance, but people's reluctance in general to see them as something more than
[01:34:14.860 --> 01:34:18.460]   just a time-wasting goofy thing.
[01:34:18.460 --> 01:34:25.500]   And the COO of Giffy made the point that it's not just cat GIFs or funny things.
[01:34:25.500 --> 01:34:26.820]   It can be lots of other things.
[01:34:26.820 --> 01:34:28.660]   It can convey strong emotion.
[01:34:28.660 --> 01:34:30.740]   It can be a highlight from a sports game.
[01:34:30.740 --> 01:34:32.460]   It can be a score from a game.
[01:34:32.460 --> 01:34:35.020]   It can be a weather report on Slack.
[01:34:35.020 --> 01:34:41.220]   You can actually slash Giffy and put in your area code and it'll show you the weather.
[01:34:41.220 --> 01:34:48.460]   I mean, there's a lot more that can kind of be conveyed in a GIF, in a short animated GIF
[01:34:48.460 --> 01:34:49.820]   than you would think.
[01:34:49.820 --> 01:34:56.340]   So I tweeted, "slashgiff thumbs up," and this is what I got.
[01:34:56.340 --> 01:34:58.580]   You got it, dude.
[01:34:58.580 --> 01:34:59.580]   Which is...
[01:34:59.580 --> 01:35:00.580]   It's a good one.
[01:35:00.580 --> 01:35:03.580]   So it really combines everything into one.
[01:35:03.580 --> 01:35:04.580]   It's a good one.
[01:35:04.580 --> 01:35:05.580]   Yeah.
[01:35:05.580 --> 01:35:06.580]   So what do you think, Jeff?
[01:35:06.580 --> 01:35:07.580]   Is this a crazy...
[01:35:07.580 --> 01:35:08.580]   I think this is great.
[01:35:08.580 --> 01:35:09.580]   No, no, I think...
[01:35:09.580 --> 01:35:12.300]   I'll always say to you, I see GIFs.
[01:35:12.300 --> 01:35:16.860]   Everything can be game and everything can be spammed, and I see a lot of GIF spam now.
[01:35:16.860 --> 01:35:17.860]   Really?
[01:35:17.860 --> 01:35:18.860]   Yeah.
[01:35:18.860 --> 01:35:21.020]   What does it look like?
[01:35:21.020 --> 01:35:26.020]   Well, so not always animated, but, you know, somewhere there's a server that took some
[01:35:26.020 --> 01:35:30.100]   quote that I did, like, "Do what you do best, link to the rest," and made it new.
[01:35:30.100 --> 01:35:35.780]   And now I see that thing coming across with my app name all the time.
[01:35:35.780 --> 01:35:42.340]   And the reason is it's fake spam accounts trying to look real by doing those GIFs.
[01:35:42.340 --> 01:35:44.300]   Okay.
[01:35:44.300 --> 01:35:46.780]   And so it's kind of the only reason they exist.
[01:35:46.780 --> 01:35:50.620]   So anything and everything can be both spammed and gamed.
[01:35:50.620 --> 01:35:51.620]   And that's what that is.
[01:35:51.620 --> 01:35:55.820]   So to put that aside, yeah, I think I think the things you just said about how it can
[01:35:55.820 --> 01:35:59.060]   be used to convey news, if you look at the new courts app, which unfortunately is only
[01:35:59.060 --> 01:36:00.060]   iOS.
[01:36:00.060 --> 01:36:05.700]   It's doing news as a text conversation.
[01:36:05.700 --> 01:36:06.700]   And you want more?
[01:36:06.700 --> 01:36:07.700]   That here's more.
[01:36:07.700 --> 01:36:08.700]   You don't want any more?
[01:36:08.700 --> 01:36:09.700]   That's really interesting.
[01:36:09.700 --> 01:36:11.100]   It's really interesting now imagine using graphics.
[01:36:11.100 --> 01:36:13.580]   We used to call them graphics, call them GIFs, call them whatever you want.
[01:36:13.580 --> 01:36:20.740]   That, as you say, can convey the DAO or convey weather or convey a moment of news or, you
[01:36:20.740 --> 01:36:27.340]   know, the moment when Jeb Bush walked by Carson going to the debate or whatever, you can
[01:36:27.340 --> 01:36:29.540]   convey a lot in that.
[01:36:29.540 --> 01:36:35.780]   And so I used to make fun of dancing GIFs and decry them too.
[01:36:35.780 --> 01:36:37.780]   And a lot of them deserve being decried.
[01:36:37.780 --> 01:36:38.780]   Sure.
[01:36:38.780 --> 01:36:40.260]   Yes, they can still do a lot.
[01:36:40.260 --> 01:36:43.900]   Well, and I remember I keep coming back to whenever something like GIFs comes up.
[01:36:43.900 --> 01:36:46.740]   I come back to what I thought of when Twitter first showed up, which was that it was the
[01:36:46.740 --> 01:36:48.340]   dumbest thing I'd ever seen.
[01:36:48.340 --> 01:36:52.820]   And then no one in the right mind would ever use it for anything.
[01:36:52.820 --> 01:36:55.860]   Clearly a little wrong.
[01:36:55.860 --> 01:36:59.500]   But I'm reminded, you know, even Alexander Graham Bell didn't know what the hell people
[01:36:59.500 --> 01:37:00.500]   were going to do with the telephone.
[01:37:00.500 --> 01:37:01.900]   He just thought it was a good idea.
[01:37:01.900 --> 01:37:03.900]   He didn't even know how people were going to answer it.
[01:37:03.900 --> 01:37:06.980]   He said everybody should say, Oh, boy, boy.
[01:37:06.980 --> 01:37:07.980]   Oh, boy.
[01:37:07.980 --> 01:37:08.980]   Yeah.
[01:37:08.980 --> 01:37:11.060]   So what does the person is being?
[01:37:11.060 --> 01:37:12.300]   Does being give a fight?
[01:37:12.300 --> 01:37:14.180]   Do anything to save Twitter?
[01:37:14.180 --> 01:37:15.620]   No, it's just one more.
[01:37:15.620 --> 01:37:16.860]   No, no, not at all.
[01:37:16.860 --> 01:37:17.860]   Not at all.
[01:37:17.860 --> 01:37:23.140]   But but it is interesting that they, you know, by building it in, they kind of they're taking
[01:37:23.140 --> 01:37:27.980]   advantage of it, but they're also effectively giving the network over to it.
[01:37:27.980 --> 01:37:32.780]   It's interesting too, because it's a step away from the kind of very basic text focused.
[01:37:32.780 --> 01:37:33.780]   Oh, yeah.
[01:37:33.780 --> 01:37:36.660]   Which was my problem was originally Twitter, right?
[01:37:36.660 --> 01:37:41.540]   And my problem with it was I just want to see 140 characters, somebody.
[01:37:41.540 --> 01:37:46.500]   And then we got screenshots and screen captures of things and then and then vine videos auto
[01:37:46.500 --> 01:37:48.740]   played and then GIFs auto played.
[01:37:48.740 --> 01:37:51.780]   And I thought, you know, it's just becoming more like Facebook.
[01:37:51.780 --> 01:37:55.420]   I have to say though, I actually find it more enjoyable.
[01:37:55.420 --> 01:37:57.340]   So again, I was totally wrong.
[01:37:57.340 --> 01:38:05.140]   Unless you think this all dumb and dopey, uh, Riffsey has just raised a considerable
[01:38:05.140 --> 01:38:06.140]   amount of money.
[01:38:06.140 --> 01:38:07.140]   55.
[01:38:07.140 --> 01:38:08.140]   I'm sorry.
[01:38:08.140 --> 01:38:09.140]   GIF.
[01:38:09.140 --> 01:38:10.140]   Giffy.
[01:38:10.140 --> 01:38:12.580]   55 million dollars, giving it a 300 million dollar valuation.
[01:38:12.580 --> 01:38:13.580]   With no revenue.
[01:38:13.580 --> 01:38:19.820]   So I mentioned, I mentioned on Twitter that a maker of animated gifts was worth more than
[01:38:19.820 --> 01:38:27.220]   the Washington Post, which obviously people don't like to think about, particularly
[01:38:27.220 --> 01:38:29.860]   people who probably work at the Washington Post.
[01:38:29.860 --> 01:38:31.580]   But in a way, they are both.
[01:38:31.580 --> 01:38:36.540]   So the point I was trying to make in the post and that the COO was making is Giffy is a
[01:38:36.540 --> 01:38:38.100]   media company.
[01:38:38.100 --> 01:38:44.020]   You may not like the format that the media is in, but this thing is integrated into so
[01:38:44.020 --> 01:38:45.460]   many different things.
[01:38:45.460 --> 01:38:48.420]   It's reaching billions of people theoretically.
[01:38:48.420 --> 01:38:53.980]   It's got partnerships with every conceivable platform from Facebook to Slack to Twitter
[01:38:53.980 --> 01:38:55.180]   to Tinder.
[01:38:55.180 --> 01:38:58.420]   It's got partnerships with movie companies and record labels.
[01:38:58.420 --> 01:39:02.460]   It's not just a website where you go to find a funny cat gif.
[01:39:02.460 --> 01:39:04.940]   Effectively is a media company.
[01:39:04.940 --> 01:39:08.100]   The, of course, the revenue model is actually pretty straightforward.
[01:39:08.100 --> 01:39:12.540]   When a movie comes out, you know, you all of a sudden you start seeing offered to you
[01:39:12.540 --> 01:39:17.540]   hail Caesar Jiffs, for instance, and then everybody goes, Oh yeah.
[01:39:17.540 --> 01:39:21.980]   And that's worth a lot of money as Snapchat has shown us.
[01:39:21.980 --> 01:39:26.540]   This is not the only addition following the addition of a gif button.
[01:39:26.540 --> 01:39:33.300]   Twitter is now bringing video support to direct messages in iOS and Android or on Twitter.com.
[01:39:33.300 --> 01:39:40.060]   Yeah, I'm going to have to turn off the all DMs except all DMs because if I start getting
[01:39:40.060 --> 01:39:41.060]   videos.
[01:39:41.060 --> 01:39:42.060]   I turn that off.
[01:39:42.060 --> 01:39:43.060]   Autoplying in my DMs.
[01:39:43.060 --> 01:39:44.060]   Yeah, I never turn that on.
[01:39:44.060 --> 01:39:45.900]   I only want DMs from people I follow.
[01:39:45.900 --> 01:39:48.220]   It's insane to say anybody can DM me.
[01:39:48.220 --> 01:39:51.620]   I turned it on for a while and it was kind of fun.
[01:39:51.620 --> 01:39:53.460]   It becomes email at that point.
[01:39:53.460 --> 01:39:54.460]   Right?
[01:39:54.460 --> 01:39:55.460]   Yeah.
[01:39:55.460 --> 01:39:58.580]   And nobody was the Twitter gif button, gif button rolled out.
[01:39:58.580 --> 01:39:59.580]   Not yet.
[01:39:59.580 --> 01:40:00.580]   Yeah.
[01:40:00.580 --> 01:40:01.580]   And here's my other question.
[01:40:01.580 --> 01:40:04.580]   Is it as always are they're going to do it only on Twitter.com and not on tweet deck,
[01:40:04.580 --> 01:40:09.060]   which they all know they've abandoned tweet deck.
[01:40:09.060 --> 01:40:10.060]   Where is it?
[01:40:10.060 --> 01:40:11.060]   It's not it's rolling out slowly.
[01:40:11.060 --> 01:40:13.260]   I mean, it's rolling out today, but it's not I don't have it.
[01:40:13.260 --> 01:40:14.260]   Yeah.
[01:40:14.260 --> 01:40:15.260]   I don't have it either.
[01:40:15.260 --> 01:40:18.780]   I never ever ever use Twitter.com never.
[01:40:18.780 --> 01:40:25.220]   Oh, I I do for that very reason because you want the full Twitter experience.
[01:40:25.220 --> 01:40:26.820]   Well, they also normal.
[01:40:26.820 --> 01:40:27.820]   And normal.
[01:40:27.820 --> 01:40:28.820]   Retweets.
[01:40:28.820 --> 01:40:29.820]   Normal comedy on a retweet.
[01:40:29.820 --> 01:40:30.820]   It just it just.
[01:40:30.820 --> 01:40:34.620]   But how do you feel about the what you missed thing?
[01:40:34.620 --> 01:40:37.740]   I kind of I guess that's while you're away.
[01:40:37.740 --> 01:40:39.980]   I guess that's algorithmic, but I like it.
[01:40:39.980 --> 01:40:40.980]   Yeah, it's okay.
[01:40:40.980 --> 01:40:42.980]   As long as it works, I take over the feed.
[01:40:42.980 --> 01:40:48.740]   Yeah, so I'm a little I wrote a whole thing about it because it feels like a slippery slope
[01:40:48.740 --> 01:40:49.740]   to me.
[01:40:49.740 --> 01:40:51.100]   So while you're away is fine.
[01:40:51.100 --> 01:40:52.740]   I have no problem with it.
[01:40:52.740 --> 01:40:55.740]   Lots of people have no problem with it.
[01:40:55.740 --> 01:40:59.580]   And it is an option, but eventually it will become the default.
[01:40:59.580 --> 01:41:04.100]   And so then you want to turn it off and then eventually it will become more while you were
[01:41:04.100 --> 01:41:07.020]   away and less what it used to be.
[01:41:07.020 --> 01:41:10.460]   And you probably won't notice because it's the default.
[01:41:10.460 --> 01:41:12.700]   And so lots of people will never turn it off.
[01:41:12.700 --> 01:41:16.020]   And eventually we will I mean Facebook did exactly the same thing.
[01:41:16.020 --> 01:41:21.860]   It was an option and then it became the default and then turning it off became almost impossible.
[01:41:21.860 --> 01:41:24.340]   And then they hid the way to turn it off.
[01:41:24.340 --> 01:41:28.420]   And now when you do turn it off, they turn it back on and you have to keep turning it
[01:41:28.420 --> 01:41:29.420]   off.
[01:41:29.420 --> 01:41:30.580]   And so no one does it.
[01:41:30.580 --> 01:41:36.180]   And so a you know, huge proportion of people aren't even aware that their feed is being
[01:41:36.180 --> 01:41:37.180]   filtered.
[01:41:37.180 --> 01:41:38.180]   That's concerns me.
[01:41:38.180 --> 01:41:39.740]   Yeah, I agree with you.
[01:41:39.740 --> 01:41:45.140]   I think but I think that while you were away is actually a nice kind of intermediate step
[01:41:45.140 --> 01:41:47.900]   that gives you a little bit of a best of both.
[01:41:47.900 --> 01:41:49.420]   It's not going to stop there.
[01:41:49.420 --> 01:41:52.140]   It's not going to stop there because they need to boost their engagement.
[01:41:52.140 --> 01:41:53.140]   Right.
[01:41:53.140 --> 01:41:54.500]   That's the whole reason they're doing it in the first place.
[01:41:54.500 --> 01:41:58.140]   So in order to boost engagement, they will just keep tweaking it and turning up the volume
[01:41:58.140 --> 01:42:00.980]   on the algorithm.
[01:42:00.980 --> 01:42:04.540]   And then it'll be the default.
[01:42:04.540 --> 01:42:06.740]   Google has launched something called G-mailify.
[01:42:06.740 --> 01:42:09.340]   I'm really thinking this is a good idea.
[01:42:09.340 --> 01:42:12.980]   A way to use Google's best features with non-gmail accounts.
[01:42:12.980 --> 01:42:19.020]   So for instance, I guess you would be giving Google access to your Yahoo mail, your Outlook
[01:42:19.020 --> 01:42:22.180]   mailbox so they could scan it, do spam.
[01:42:22.180 --> 01:42:23.660]   It pulls a reading.
[01:42:23.660 --> 01:42:24.660]   You're even.
[01:42:24.660 --> 01:42:25.660]   Yeah.
[01:42:25.660 --> 01:42:27.540]   And we like it.
[01:42:27.540 --> 01:42:32.540]   In box organization, you'd get Google now benefits because it would be reading your mail.
[01:42:32.540 --> 01:42:33.540]   It's a good idea.
[01:42:33.540 --> 01:42:34.540]   It's a great idea.
[01:42:34.540 --> 01:42:37.740]   And you know, you don't have to use it.
[01:42:37.740 --> 01:42:38.740]   Yep.
[01:42:38.740 --> 01:42:44.180]   I'll have to try it on my, you know, there'll be a good test on the outlook.com account because
[01:42:44.180 --> 01:42:47.820]   if it actually does get the spam, there will be nothing in the mailbox.
[01:42:47.820 --> 01:42:51.180]   Same with the Yahoo, right?
[01:42:51.180 --> 01:42:55.220]   That was actually the first when I switched, I was using Outlook, of course, because that
[01:42:55.220 --> 01:42:58.220]   where I worked required it.
[01:42:58.220 --> 01:43:01.940]   And the thing that really sold me on Gmail was the anti-spam.
[01:43:01.940 --> 01:43:02.940]   Yeah.
[01:43:02.940 --> 01:43:12.180]   It's so flawless and so fast and Outlook was just the worst.
[01:43:12.180 --> 01:43:17.820]   So it's in, you have to sign and enable a gen.
[01:43:17.820 --> 01:43:21.540]   I don't understand how it works exactly.
[01:43:21.540 --> 01:43:30.660]   It's a, there's a blog post, but so starting today, if you use Yahoo or Hotmail or Outlook.com,
[01:43:30.660 --> 01:43:33.700]   all you need to do is open the Gmail app, OIC.
[01:43:33.700 --> 01:43:38.540]   You do it in the Gmail app and then the new Gmail app allows you to sign into those accounts.
[01:43:38.540 --> 01:43:39.540]   And then there's a...
[01:43:39.540 --> 01:43:40.540]   Ah, okay, okay.
[01:43:40.540 --> 01:43:41.540]   Get it.
[01:43:41.540 --> 01:43:42.540]   Gmail will apply.
[01:43:42.540 --> 01:43:44.060]   So it sounds like it doesn't actually modify.
[01:43:44.060 --> 01:43:46.140]   It won't like take a spam out of my Yahoo mail.
[01:43:46.140 --> 01:43:50.500]   I wish it would, but it does when I'm looking at it with a Gmail app.
[01:43:50.500 --> 01:43:51.500]   Right.
[01:43:51.500 --> 01:43:52.500]   I kind of step back from the Gmail app.
[01:43:52.500 --> 01:43:54.500]   I like inbox so much, but it sounds like something.
[01:43:54.500 --> 01:43:55.500]   Yeah, I do too, actually.
[01:43:55.500 --> 01:43:56.500]   Yeah.
[01:43:56.500 --> 01:43:57.500]   I do too.
[01:43:57.500 --> 01:43:58.500]   Yeah.
[01:43:58.500 --> 01:43:59.500]   It's just you and me.
[01:43:59.500 --> 01:44:00.500]   Yeah, you know...
[01:44:00.500 --> 01:44:01.500]   Did you use mailbox?
[01:44:01.500 --> 01:44:02.500]   I've tried them all.
[01:44:02.500 --> 01:44:08.020]   I just started deleting from iOS all my alternate email programs.
[01:44:08.020 --> 01:44:11.140]   And I've yet to find one that just really works for me.
[01:44:11.140 --> 01:44:19.260]   One of the reasons is I need to have PGP or a GPG in my case, open PGP in there for
[01:44:19.260 --> 01:44:20.700]   signing an encryption.
[01:44:20.700 --> 01:44:22.860]   And a lot, most email programs don't.
[01:44:22.860 --> 01:44:25.020]   Yeah, very few unmobile supported.
[01:44:25.020 --> 01:44:28.540]   I keep going back to Thunderbird with a Nigmail, believe it or not.
[01:44:28.540 --> 01:44:29.540]   It's pretty darn good.
[01:44:29.540 --> 01:44:30.540]   Thunderbird is great.
[01:44:30.540 --> 01:44:31.540]   Yeah.
[01:44:31.540 --> 01:44:32.540]   It's free.
[01:44:32.540 --> 01:44:33.540]   Mm-hmm.
[01:44:33.540 --> 01:44:38.420]   Tech editor in chief at Yahoo Tech, Dan Tynan laid off also.
[01:44:38.420 --> 01:44:40.100]   And the hits just keep on coming.
[01:44:40.100 --> 01:44:41.500]   David Pogue is not leaving.
[01:44:41.500 --> 01:44:43.820]   It's moving over to news.
[01:44:43.820 --> 01:44:45.780]   They're only doing four areas now.
[01:44:45.780 --> 01:44:47.580]   They've folded it over.
[01:44:47.580 --> 01:44:49.820]   They're shutting down some of their magazines.
[01:44:49.820 --> 01:44:50.820]   Yeah.
[01:44:50.820 --> 01:44:52.300]   It sounded like at first that they were going to shut down.
[01:44:52.300 --> 01:44:55.900]   Yeah, who tech altogether, but it doesn't look that way.
[01:44:55.900 --> 01:44:57.740]   Caris swisher.
[01:44:57.740 --> 01:45:02.020]   According to sources close to the situation, Yahoo CEO Marissa Meyer has designated Wednesday
[01:45:02.020 --> 01:45:05.500]   as the day of the week to make the massive employee cuts.
[01:45:05.500 --> 01:45:06.500]   Right.
[01:45:06.500 --> 01:45:07.500]   Yay.
[01:45:07.500 --> 01:45:11.220]   So we're just going to do it every Wednesday.
[01:45:11.220 --> 01:45:12.220]   It's cut me day.
[01:45:12.220 --> 01:45:13.220]   It's cut me day.
[01:45:13.220 --> 01:45:15.740]   Well, you don't want to fire somebody on Friday.
[01:45:15.740 --> 01:45:17.860]   They can really put a damper on their weekend.
[01:45:17.860 --> 01:45:18.860]   Right.
[01:45:18.860 --> 01:45:23.260]   You file them on Monday, you know, it's just it's just it's just an insult.
[01:45:23.260 --> 01:45:26.940]   Maybe they could have a party for the people who are being laid off.
[01:45:26.940 --> 01:45:29.900]   Or is it could ride around on a Zambonia?
[01:45:29.900 --> 01:45:34.300]   Food is gone.
[01:45:34.300 --> 01:45:35.860]   Carrie Diamond out.
[01:45:35.860 --> 01:45:37.980]   She was a parenting.
[01:45:37.980 --> 01:45:39.460]   Parenting is gone.
[01:45:39.460 --> 01:45:41.460]   Travel travel.
[01:45:41.460 --> 01:45:42.460]   Auto.
[01:45:42.460 --> 01:45:43.460]   Wish.
[01:45:43.460 --> 01:45:46.260]   See, I didn't even know there is that should have good advertising.
[01:45:46.260 --> 01:45:47.660]   Yeah, who knew they had it?
[01:45:47.660 --> 01:45:48.660]   Yeah.
[01:45:48.660 --> 01:45:52.980]   I mean, I looked at the tech section a lot and there was a lot advertising and they
[01:45:52.980 --> 01:45:58.260]   mixed in the because it was tile based and they mixed in advertising tiles with the
[01:45:58.260 --> 01:46:01.300]   content tiles, which is not my favorite way to.
[01:46:01.300 --> 01:46:04.060]   They also kind of aggregated a lot.
[01:46:04.060 --> 01:46:06.100]   I mean, a lot of it wasn't their stuff.
[01:46:06.100 --> 01:46:07.100]   Yeah.
[01:46:07.100 --> 01:46:10.580]   If they were going to really devote time and resources to it, then they should have done
[01:46:10.580 --> 01:46:13.500]   it like really do it.
[01:46:13.500 --> 01:46:19.420]   So I guess amp has amped up the competition.
[01:46:19.420 --> 01:46:25.380]   Facebook's AMP competitor, instant articles is going to be available to all publishers
[01:46:25.380 --> 01:46:28.500]   as of April 12th to come a year to do it.
[01:46:28.500 --> 01:46:29.500]   It's a big deal.
[01:46:29.500 --> 01:46:30.500]   Yeah.
[01:46:30.500 --> 01:46:31.500]   I have already been a big deal.
[01:46:31.500 --> 01:46:34.860]   Publishers that they, I'm reading a lot more Washington Post now.
[01:46:34.860 --> 01:46:35.860]   A lot more.
[01:46:35.860 --> 01:46:37.980]   Because you see it in your Facebook feed.
[01:46:37.980 --> 01:46:38.980]   Exactly.
[01:46:38.980 --> 01:46:39.980]   And it's fast.
[01:46:39.980 --> 01:46:40.980]   And it's very fast.
[01:46:40.980 --> 01:46:43.380]   It's a good experience.
[01:46:43.380 --> 01:46:47.220]   I have argued to many publishers, they should really consider creating whole new media properties
[01:46:47.220 --> 01:46:48.980]   entirely on Facebook.
[01:46:48.980 --> 01:46:51.900]   Because instant articles now has monetization in there.
[01:46:51.900 --> 01:46:53.380]   And I'll tell you, I'm going to go.
[01:46:53.380 --> 01:46:56.220]   I want to be able to put anything I write as forth.
[01:46:56.220 --> 01:46:59.820]   I want to do it as a long post an article, so to speak.
[01:46:59.820 --> 01:47:01.380]   I want to put it in on instant articles.
[01:47:01.380 --> 01:47:05.340]   I'll make a cup of coffee a year.
[01:47:05.340 --> 01:47:06.340]   But I want to do that.
[01:47:06.340 --> 01:47:12.100]   I'd like to go one step farther and ask Facebook to add an audio post format for, you know,
[01:47:12.100 --> 01:47:13.860]   a kind of sound cloud like audio post.
[01:47:13.860 --> 01:47:14.860]   I expect they will.
[01:47:14.860 --> 01:47:15.860]   Yeah.
[01:47:15.860 --> 01:47:16.860]   I expect they will.
[01:47:16.860 --> 01:47:21.020]   A lot of podcasts is just putting a video with a static picture up.
[01:47:21.020 --> 01:47:24.540]   And because it's, the promise doesn't ought to play audio.
[01:47:24.540 --> 01:47:25.540]   Yeah.
[01:47:25.540 --> 01:47:27.100]   So that's maybe less than desirable.
[01:47:27.100 --> 01:47:31.260]   I'll be interested to see whether, I forget who brought this up in my Twitter feed, but
[01:47:31.260 --> 01:47:38.740]   somebody said how long until someone, a sort of independent journalist, just goes full
[01:47:38.740 --> 01:47:42.300]   on instant articles, publishes everything through instant articles.
[01:47:42.300 --> 01:47:43.620]   Buzzfeed and vice, right?
[01:47:43.620 --> 01:47:46.220]   Aren't they really deprecating their homepage?
[01:47:46.220 --> 01:47:50.940]   Just say we'll be wherever you are, whether it's Snapchat or Facebook or actually fast
[01:47:50.940 --> 01:47:59.100]   company had a huge takeout piece on Buzzfeed that I wrote a post about because they're,
[01:47:59.100 --> 01:48:02.020]   it's fascinating how much that's a data driven company.
[01:48:02.020 --> 01:48:07.420]   It's more than I can go into at the moment, but it's just fascinating how much data there
[01:48:07.420 --> 01:48:09.420]   is below the surface.
[01:48:09.420 --> 01:48:17.140]   But there was a stat in there, 75% or more of Buzzfeed content that Buzzfeed creates never
[01:48:17.140 --> 01:48:18.220]   appears on their website.
[01:48:18.220 --> 01:48:22.260]   So another way, put it another way.
[01:48:22.260 --> 01:48:24.980]   What Jonah told me at a conference, I didn't see it elsewhere.
[01:48:24.980 --> 01:48:25.980]   It was a secret.
[01:48:25.980 --> 01:48:29.260]   Buzzfeed has five billion interactions with people a month.
[01:48:29.260 --> 01:48:32.140]   Only one billion of those interactions occur at Buzzfeed.com.
[01:48:32.140 --> 01:48:35.780]   And Jonah said to him now, Buzzfeed.com is his laboratory.
[01:48:35.780 --> 01:48:38.380]   The business is offsite.
[01:48:38.380 --> 01:48:41.500]   And media companies have to understand how they have to go to users and go to readers
[01:48:41.500 --> 01:48:44.460]   when we want to call them wherever they are.
[01:48:44.460 --> 01:48:50.140]   Now the hard part of that is to full, one monetization, but both AM and IA solve that.
[01:48:50.140 --> 01:48:54.660]   The second problem is how do you build a relationship, which I argue has to be the future of media.
[01:48:54.660 --> 01:48:59.340]   If you're interacting with people all the hell over creation, we've got to work on that.
[01:48:59.340 --> 01:49:01.740]   And the platforms have to help us be able to do that.
[01:49:01.740 --> 01:49:04.300]   But I think that there are ways that that can be done.
[01:49:04.300 --> 01:49:11.700]   And I think Buzzfeed's, in effect, Buzzfeed's pitch, their monetization is their pitch to
[01:49:11.700 --> 01:49:18.060]   brands and advertisers as we understand how content works on all these platforms.
[01:49:18.060 --> 01:49:19.060]   Well, exactly.
[01:49:19.060 --> 01:49:21.980]   They don't sell media.
[01:49:21.980 --> 01:49:22.980]   They don't sell space.
[01:49:22.980 --> 01:49:24.140]   They don't sell audience.
[01:49:24.140 --> 01:49:26.660]   They sell a skill that skill is we can make our crap.
[01:49:26.660 --> 01:49:29.580]   We can make your crap viral too.
[01:49:29.580 --> 01:49:35.500]   And I think it's fascinating to me how much time they spend and how little time, lots
[01:49:35.500 --> 01:49:40.300]   of traditional media companies spend on looking at what people actually do.
[01:49:40.300 --> 01:49:46.020]   So not just do they click and not just do they come back to our website.
[01:49:46.020 --> 01:49:47.620]   What do they do after that?
[01:49:47.620 --> 01:49:52.940]   So the Fast Company article makes clear that clicking is not enough.
[01:49:52.940 --> 01:49:55.180]   That's not what Buzzfeed is interested in.
[01:49:55.180 --> 01:49:56.900]   Sharing is the most important thing.
[01:49:56.900 --> 01:50:06.660]   Yeah, but in that sense of selling that skill of viral because you can sell that.
[01:50:06.660 --> 01:50:10.620]   But in the end, does that really actually lead to real reading?
[01:50:10.620 --> 01:50:14.420]   Chartbeat, as we know, has found clearly that people share and don't read.
[01:50:14.420 --> 01:50:16.900]   So it's not an indication that people have really read it.
[01:50:16.900 --> 01:50:23.180]   And so Mr. journalist or mis-advertiser, just because they shared it doesn't mean crap
[01:50:23.180 --> 01:50:24.180]   in terms of value.
[01:50:24.180 --> 01:50:28.820]   No, but sharing and not reading is better than not sharing and not reading.
[01:50:28.820 --> 01:50:29.820]   But not so sure.
[01:50:29.820 --> 01:50:31.660]   I'm not so sure.
[01:50:31.660 --> 01:50:34.620]   Sharing and not reading doesn't indicate that they've read your precious story.
[01:50:34.620 --> 01:50:38.700]   Sharing and not reading doesn't mean they've absorbed your advertising message.
[01:50:38.700 --> 01:50:41.540]   No, I don't think that that's this.
[01:50:41.540 --> 01:50:47.940]   I think what's waiting to be out there is that the bubble's going to burst on sharing
[01:50:47.940 --> 01:50:49.460]   and say it's worthless.
[01:50:49.460 --> 01:50:50.460]   It was fun.
[01:50:50.460 --> 01:50:52.340]   Well, last but okay, what's next?
[01:50:52.340 --> 01:50:55.700]   I think you have to look at things beyond just the sharing.
[01:50:55.700 --> 01:50:59.860]   You have to look at you have to measure engagement, which is really, really hard to do.
[01:50:59.860 --> 01:51:00.860]   That's the point.
[01:51:00.860 --> 01:51:01.860]   That's the point, Matt.
[01:51:01.860 --> 01:51:06.500]   There's no one saying, all I'm saying is at least they're part way down the road to
[01:51:06.500 --> 01:51:07.500]   doing that.
[01:51:07.500 --> 01:51:11.500]   Lots of traditional media companies are not even, they don't even know the road is there
[01:51:11.500 --> 01:51:12.500]   or how to get there.
[01:51:12.500 --> 01:51:13.500]   They're agreeing.
[01:51:13.500 --> 01:51:14.500]   If they're not doing any of those.
[01:51:14.500 --> 01:51:16.420]   To me, there's levels here.
[01:51:16.420 --> 01:51:19.940]   At level one of metrics in our business is page views.
[01:51:19.940 --> 01:51:23.700]   Each frequency, that's the old mass media business model that's dead.
[01:51:23.700 --> 01:51:25.620]   Next is so-called engagement.
[01:51:25.620 --> 01:51:27.740]   Times spent sharing likes.
[01:51:27.740 --> 01:51:28.860]   That's bubble to burst.
[01:51:28.860 --> 01:51:32.900]   The next one to me that's most important for the future of the business is relationships.
[01:51:32.900 --> 01:51:33.900]   How many people do you know?
[01:51:33.900 --> 01:51:34.900]   What do you know about them?
[01:51:34.900 --> 01:51:36.580]   What value can you bring them as a result?
[01:51:36.580 --> 01:51:39.300]   Then the fourth is journalism is impact.
[01:51:39.300 --> 01:51:43.020]   Impact is really almost a brand question.
[01:51:43.020 --> 01:51:45.380]   The business basis is relationships.
[01:51:45.380 --> 01:51:47.100]   We're really bad at that in our industry.
[01:51:47.100 --> 01:51:48.700]   We don't have relations with people.
[01:51:48.700 --> 01:51:50.180]   We give them a one size fits all product.
[01:51:50.180 --> 01:51:52.420]   We don't know who the hell you are.
[01:51:52.420 --> 01:51:55.140]   As I'm always fond of saying, Google knows where I live and where I work.
[01:51:55.140 --> 01:51:56.140]   My newspaper doesn't.
[01:51:56.140 --> 01:51:57.140]   That's a shame.
[01:51:57.140 --> 01:52:01.900]   And I just wrote a whole post about the Guardian's membership approach as opposed to the sort
[01:52:01.900 --> 01:52:04.780]   of one size fits all paywall approach.
[01:52:04.780 --> 01:52:07.460]   One is, here's a bunch of content we created.
[01:52:07.460 --> 01:52:10.260]   We have no idea whether you're interested in it or not, but you should probably pay
[01:52:10.260 --> 01:52:11.260]   us.
[01:52:11.260 --> 01:52:16.180]   And the other approach is trying to get to know your readers and figure out what it is
[01:52:16.180 --> 01:52:17.860]   they actually want.
[01:52:17.860 --> 01:52:20.580]   I think those are very, very different.
[01:52:20.580 --> 01:52:25.820]   I held a full disclosure that I'm working with the Guardian on membership.
[01:52:25.820 --> 01:52:32.660]   And I had a small event with WBE, East Chicago and WNYC, WGBH, WFMU, and also the Guardian.
[01:52:32.660 --> 01:52:38.780]   And also, I think I mentioned this before, the Leo, Jack Conte from Patreon.
[01:52:38.780 --> 01:52:42.460]   And Jack has really fascinating information.
[01:52:42.460 --> 01:52:46.340]   Now, Jack's just brilliant about when people want to support something, when they want
[01:52:46.340 --> 01:52:51.580]   to become a patron to something, and they support more than one thing, how that kind
[01:52:51.580 --> 01:52:52.580]   of generosity works.
[01:52:52.580 --> 01:52:54.900]   And so it's not about getting access to content.
[01:52:54.900 --> 01:52:56.980]   It's about being part of something and helping something.
[01:52:56.980 --> 01:52:59.140]   And we don't understand that in our business.
[01:52:59.140 --> 01:53:03.100]   Public media begins to understand it, but still in a media-centric way, not in a public-centric
[01:53:03.100 --> 01:53:04.100]   way.
[01:53:04.100 --> 01:53:05.100]   Right.
[01:53:05.100 --> 01:53:11.340]   And in fact, most of the things you see membership-based plans offering are things like go behind the
[01:53:11.340 --> 01:53:13.180]   scenes and get a tour of the newsroom.
[01:53:13.180 --> 01:53:16.300]   Well, actually, no one is really interested in that at all.
[01:53:16.300 --> 01:53:19.180]   What about how can you help us-
[01:53:19.180 --> 01:53:21.580]   Nothing about you, but report this in a story.
[01:53:21.580 --> 01:53:22.580]   Right, exactly.
[01:53:22.580 --> 01:53:23.580]   Yup.
[01:53:23.580 --> 01:53:24.580]   Let's see here.
[01:53:24.580 --> 01:53:31.100]   So I just put up, I don't want to go back to the topic, but I don't know if you care.
[01:53:31.100 --> 01:53:35.620]   I didn't watch it yet, but Fox News says that if Apple wins, ISIS wins.
[01:53:35.620 --> 01:53:36.620]   Okay.
[01:53:36.620 --> 01:53:38.380]   I just thought that's enough.
[01:53:38.380 --> 01:53:39.380]   You don't have to show it.
[01:53:39.380 --> 01:53:40.380]   Yeah.
[01:53:40.380 --> 01:53:42.580]   Did you see the Grammys?
[01:53:42.580 --> 01:53:44.100]   Did you watch Adele?
[01:53:44.100 --> 01:53:45.100]   No.
[01:53:45.100 --> 01:53:47.460]   She was kind of not sounding so good.
[01:53:47.460 --> 01:53:49.020]   She had technical problems, right?
[01:53:49.020 --> 01:53:53.060]   Apparently, the microphone fell into the piano, which is interesting because Google's
[01:53:53.060 --> 01:53:58.380]   ad for the Grammys in some interesting way, presaged this.
[01:53:58.380 --> 01:54:11.100]   This is their "Be Together" not the same as 88 keys on a piano and a virtuoso.
[01:54:11.100 --> 01:54:13.580]   Can really make it sing.
[01:54:13.580 --> 01:54:22.460]   Each one is different, but what if all the keys were the same?
[01:54:22.460 --> 01:54:25.260]   I've got to admit, I watched this the first time and I didn't get it.
[01:54:25.260 --> 01:54:27.220]   Yeah, you have to read the captions.
[01:54:27.220 --> 01:54:32.060]   I thought it's a weird composition, but what the hell?
[01:54:32.060 --> 01:54:33.060]   I think it's interesting.
[01:54:33.060 --> 01:54:41.260]   If all the keys have the same note, I don't mind the second one.
[01:54:41.260 --> 01:54:46.540]   It's not like a gift.
[01:54:46.540 --> 01:54:51.140]   I actually, I thought the Grammys exclusively through Twitter.
[01:54:51.140 --> 01:54:52.140]   You could too.
[01:54:52.140 --> 01:54:54.580]   So I did not have a real time.
[01:54:54.580 --> 01:54:57.260]   And I feel like I sort of watched it.
[01:54:57.260 --> 01:54:58.260]   Here's the...
[01:54:58.260 --> 01:54:59.260]   Boy, I want to see Hamilton.
[01:54:59.260 --> 01:55:00.260]   Geez, I want to see him.
[01:55:00.260 --> 01:55:01.260]   Oh, I know that makes you want to see it.
[01:55:01.260 --> 01:55:02.260]   I tell you.
[01:55:02.260 --> 01:55:03.260]   Oh, my God.
[01:55:03.260 --> 01:55:04.260]   I'm going to come out.
[01:55:04.260 --> 01:55:06.460]   We're going to scalp tickets and we're all going to go.
[01:55:06.460 --> 01:55:08.260]   It's just all go.
[01:55:08.260 --> 01:55:10.620]   Steven Fry has quit Twitter.
[01:55:10.620 --> 01:55:11.620]   Again.
[01:55:11.620 --> 01:55:14.060]   Is he quit it before?
[01:55:14.060 --> 01:55:16.300]   He has taken sabbaticals.
[01:55:16.300 --> 01:55:17.980]   Love the British comedian.
[01:55:17.980 --> 01:55:26.140]   He's very tech savvy, but he just had it after critiques of his BAFTA awards conversation
[01:55:26.140 --> 01:55:29.660]   about, I don't know anyway, who cares?
[01:55:29.660 --> 01:55:33.580]   The real interesting thing is when is Kanye West going to quit Twitter?
[01:55:33.580 --> 01:55:35.740]   Well, I hope he never quit.
[01:55:35.740 --> 01:55:38.140]   He's kind of amusing.
[01:55:38.140 --> 01:55:41.300]   Someone said they should put him on the board or something or give him stock.
[01:55:41.300 --> 01:55:42.740]   He's doing more for Twitter.
[01:55:42.740 --> 01:55:43.940]   It's quite engaging.
[01:55:43.940 --> 01:55:44.940]   Yeah.
[01:55:44.940 --> 01:55:48.820]   West took to Twitter on Saturday to say, "I write this to you, my brothers, while still
[01:55:48.820 --> 01:55:52.940]   53 million dollars in personal debt, please pray we overcome.
[01:55:52.940 --> 01:55:53.940]   This is my true heart."
[01:55:53.940 --> 01:55:56.660]   And he asked Mark for a billion.
[01:55:56.660 --> 01:56:02.820]   And then he says, "Mark Zuckerberg, invest $1 billion into Kanye West's ideas."
[01:56:02.820 --> 01:56:09.420]   After realizing he is the greatest living artist and greatest artist of all time.
[01:56:09.420 --> 01:56:10.660]   Thank you.
[01:56:10.660 --> 01:56:12.740]   I am Kanye.
[01:56:12.740 --> 01:56:14.980]   And then he follows it up with Mark Zuckerberg.
[01:56:14.980 --> 01:56:17.780]   I know it's your birthday, but can you please call me by tomorrow?
[01:56:17.780 --> 01:56:22.340]   There's a bunch we probably don't want to mention on the air because he swears, but some
[01:56:22.340 --> 01:56:23.660]   of them are hilarious.
[01:56:23.660 --> 01:56:29.860]   He also said, "Larry Page, I'm down for your help too."
[01:56:29.860 --> 01:56:31.220]   I think it's performance art.
[01:56:31.220 --> 01:56:32.380]   It could be performance art.
[01:56:32.380 --> 01:56:34.260]   It could be he's actually gone.
[01:56:34.260 --> 01:56:37.860]   I'm torn between performance art and he's actually gone insane.
[01:56:37.860 --> 01:56:39.860]   I think he might be having a sick one.
[01:56:39.860 --> 01:56:40.860]   He has a lot of fun.
[01:56:40.860 --> 01:56:41.860]   Yeah.
[01:56:41.860 --> 01:56:44.580]   It's an interesting turn of events.
[01:56:44.580 --> 01:56:46.620]   You know who has quit Twitter?
[01:56:46.620 --> 01:56:48.380]   Is Mark Andreessen?
[01:56:48.380 --> 01:56:49.380]   What?
[01:56:49.380 --> 01:56:52.180]   Well, he hasn't said he quit.
[01:56:52.180 --> 01:56:54.740]   He last tweeted on February 10th.
[01:56:54.740 --> 01:56:56.220]   What?
[01:56:56.220 --> 01:56:58.060]   That was a week ago.
[01:56:58.060 --> 01:57:04.500]   At least after considering, according to sources, a purchase of Twitter with Silver Lake, and
[01:57:04.500 --> 01:57:07.500]   of course he invented the tweet storm.
[01:57:07.500 --> 01:57:13.900]   Mark Andreessen, one of the writers of the original Mosaic browser, one of the guys behind
[01:57:13.900 --> 01:57:15.580]   that escape.
[01:57:15.580 --> 01:57:17.980]   He tweeted about India.
[01:57:17.980 --> 01:57:20.380]   Yeah, we did go over.
[01:57:20.380 --> 01:57:21.380]   So he did go over.
[01:57:21.380 --> 01:57:25.740]   That was his last tweet was a series of apologies for that.
[01:57:25.740 --> 01:57:28.580]   Oh, that could be really too bad.
[01:57:28.580 --> 01:57:30.060]   It is too bad.
[01:57:30.060 --> 01:57:35.540]   That guy's following him was, I still wish he was writing blog posts because those were
[01:57:35.540 --> 01:57:41.180]   amazing, but his Twitter account was fantastic.
[01:57:41.180 --> 01:57:45.380]   Like, even if you could question that specific tweet.
[01:57:45.380 --> 01:57:50.020]   Well, it was a very good example of what we've talked about, which is it's way too easy
[01:57:50.020 --> 01:57:53.340]   to just write something offhand on Twitter.
[01:57:53.340 --> 01:57:56.940]   And unfortunately, because it's written and because a lot of people see it, it becomes
[01:57:56.940 --> 01:58:02.820]   short as if you wrote an essay and treated it as if it was a carefully thought out pronunciation
[01:58:02.820 --> 01:58:04.260]   prayer announcement.
[01:58:04.260 --> 01:58:05.260]   It clearly wasn't.
[01:58:05.260 --> 01:58:11.500]   I mean, and Mark really objectively apologized as he should because I can't remember what
[01:58:11.500 --> 01:58:13.580]   he said, but it was not very nice.
[01:58:13.580 --> 01:58:15.220]   It was a reference to colonialism.
[01:58:15.220 --> 01:58:16.900]   And it wasn't all that bad, right?
[01:58:16.900 --> 01:58:19.260]   Which is, but that's kind of a third rail.
[01:58:19.260 --> 01:58:21.260]   Yeah, obviously for any reason.
[01:58:21.260 --> 01:58:22.260]   Yeah.
[01:58:22.260 --> 01:58:28.540]   So what it has to do with internet.org and Facebook's attempt to give free basics, give
[01:58:28.540 --> 01:58:30.180]   free internet to India.
[01:58:30.180 --> 01:58:34.380]   Indian government has rejected it saying it's anti net neutrality.
[01:58:34.380 --> 01:58:36.180]   It's zero rating.
[01:58:36.180 --> 01:58:38.980]   Om Malek has been very forthright about that.
[01:58:38.980 --> 01:58:43.700]   And of course, Om has standing to talk about this subject being from India.
[01:58:43.700 --> 01:58:45.620]   He says it is a fascinating.
[01:58:45.620 --> 01:58:47.460]   It's a form of colonialism.
[01:58:47.460 --> 01:58:52.900]   They say when the British East India Company came, they gave a lot of free stuff away and
[01:58:52.900 --> 01:58:54.900]   then they did colonized.
[01:58:54.900 --> 01:58:55.900]   Yeah.
[01:58:55.900 --> 01:59:00.980]   And I mean, I don't have any standing to talk about it because I'm not Indian and I don't,
[01:59:00.980 --> 01:59:03.780]   you know, I get Facebook the same way I get everything else.
[01:59:03.780 --> 01:59:08.100]   I've got lots of internet and, you know, I have money and I'm white and so on.
[01:59:08.100 --> 01:59:13.700]   But but the thing that fascinates me about the topic is you can.
[01:59:13.700 --> 01:59:18.580]   So Mark Zuckerberg, he doesn't want to take over India, obviously, except in financial
[01:59:18.580 --> 01:59:26.220]   terms, maybe I genuinely think he wants to give people free internet, but but because
[01:59:26.220 --> 01:59:31.620]   of history and the culture and the way that Facebook approached it, which and I would argue
[01:59:31.620 --> 01:59:36.380]   they made a mistake in the way they sort of marketed it and the and the way they I don't
[01:59:36.380 --> 01:59:42.420]   think they tried hard enough to understand the country before they came in and said,
[01:59:42.420 --> 01:59:46.260]   Hi, we're Facebook and we're going to give you a dumb down version of the internet.
[01:59:46.260 --> 01:59:50.820]   It's just a fascinating story to me, the whole thing.
[01:59:50.820 --> 01:59:56.940]   Mark's comment was anti-colonialism has been economically catastrophic for the Indian people
[01:59:56.940 --> 01:59:57.940]   for decades.
[01:59:57.940 --> 01:59:58.940]   Why stop now?
[01:59:58.940 --> 02:00:05.940]   The kind of offhand comment that people might say in public and deeply regret moments later
[02:00:05.940 --> 02:00:06.940]   the problem is.
[02:00:06.940 --> 02:00:10.940]   Well, it was because he's a director of Facebook and as I said last week, I suspect that I
[02:00:10.940 --> 02:00:14.100]   would bet you anything that had recent cold.
[02:00:14.100 --> 02:00:17.020]   Zach and said, shoot me a don.
[02:00:17.020 --> 02:00:22.420]   I messed up, you know, and then hold off Twitter for a while, but I do hope he comes back.
[02:00:22.420 --> 02:00:28.460]   And we now have as of one minute ago a response from Sundar Pichai at Google to the Apple
[02:00:28.460 --> 02:00:29.460]   logo.
[02:00:29.460 --> 02:00:33.620]   This is a tweet storm, a five tweet post on Twitter.
[02:00:33.620 --> 02:00:38.060]   Why blog when you can tweet starting with important post by Tim Cook forcing companies
[02:00:38.060 --> 02:00:42.380]   to enable hacking could compromise users' privacy.
[02:00:42.380 --> 02:00:46.180]   Tweet two, we know that law enforcement and intelligence agencies face significant challenges
[02:00:46.180 --> 02:00:49.540]   in protecting the public against crime and terrorism.
[02:00:49.540 --> 02:00:51.260]   Tweet three, we build secure products.
[02:00:51.260 --> 02:00:55.620]   We being Google obviously build secure products to keep your information safe and we give
[02:00:55.620 --> 02:01:01.980]   law enforcement access to data based on valid legal orders for, but that's wholly different
[02:01:01.980 --> 02:01:05.420]   than requiring companies to enable hacking of customer devices and data.
[02:01:05.420 --> 02:01:09.460]   It would be a troubling precedent five looking forward to a thoughtful and open discussion
[02:01:09.460 --> 02:01:11.300]   on this important issue.
[02:01:11.300 --> 02:01:17.020]   A balanced and nuanced response from Sundar Pichai.
[02:01:17.020 --> 02:01:18.020]   And smart.
[02:01:18.020 --> 02:01:19.020]   Yeah.
[02:01:19.020 --> 02:01:21.500]   So Edward Snowden, it may have taken them five hours, but he did.
[02:01:21.500 --> 02:01:25.060]   So did he write that before Snowden's tweet?
[02:01:25.060 --> 02:01:26.740]   It just came out three minutes ago.
[02:01:26.740 --> 02:01:29.100]   It's Snowden three hours ago now, I think.
[02:01:29.100 --> 02:01:30.100]   It is.
[02:01:30.100 --> 02:01:31.100]   You know, it's amazing.
[02:01:31.100 --> 02:01:34.460]   It's really kind of amazing.
[02:01:34.460 --> 02:01:37.140]   This is where the conversation happens is on Twitter.
[02:01:37.140 --> 02:01:41.940]   You know, five individual 140 character posts.
[02:01:41.940 --> 02:01:47.660]   Well, and if you think about it, I actually, when Mark Andreessen and the India thing happened,
[02:01:47.660 --> 02:01:54.540]   I thought if you had tried to describe to someone 10 years ago, Mark Andreessen is going
[02:01:54.540 --> 02:01:59.340]   to post a tweet and then India is going to get upset and Mark Zuckerberg is going to
[02:01:59.340 --> 02:02:03.100]   have to make a public statement on this thing called Facebook.
[02:02:03.100 --> 02:02:05.180]   Like, no one would have understood what you were talking about.
[02:02:05.180 --> 02:02:07.220]   Yeah, you'd be speaking a foreign language.
[02:02:07.220 --> 02:02:08.220]   A tweet.
[02:02:08.220 --> 02:02:09.220]   A tweet?
[02:02:09.220 --> 02:02:12.980]   When it's a we always incident blog post.
[02:02:12.980 --> 02:02:15.780]   Well, we tiny blog post.
[02:02:15.780 --> 02:02:18.060]   All right, let's take a break.
[02:02:18.060 --> 02:02:20.060]   Picks of the week, we'll wrap this thing up in just a bit.
[02:02:20.060 --> 02:02:24.960]   But first a word from our friends at square space, the place to make your next website,
[02:02:24.960 --> 02:02:31.880]   whether you're a blogger, a business person, a restaurateur, a band, a photographer, square
[02:02:31.880 --> 02:02:33.160]   space sites are gorgeous.
[02:02:33.160 --> 02:02:35.940]   They reflect your aesthetic.
[02:02:35.940 --> 02:02:39.820]   They reflect even the shopping cart looks like your site.
[02:02:39.820 --> 02:02:43.580]   So there's, it's just a wonderful experience and very easy.
[02:02:43.580 --> 02:02:50.140]   You don't have to be a guru of the web because a square space has picked the best designers
[02:02:50.140 --> 02:02:52.220]   and the best engineers to design their templates.
[02:02:52.220 --> 02:02:56.700]   Now remember, square space is hosting plus software tightly integrated to give you the
[02:02:56.700 --> 02:02:57.980]   best possible experiences.
[02:02:57.980 --> 02:03:00.180]   The best hosting I know never goes down.
[02:03:00.180 --> 02:03:03.720]   The sites are gorgeous and here's the beauty part.
[02:03:03.720 --> 02:03:07.640]   If you're a developer, the sky's the limit.
[02:03:07.640 --> 02:03:10.200]   It is incredible.
[02:03:10.200 --> 02:03:13.360]   Mobile's built in from responsive designs to a mobile optimized checkout.
[02:03:13.360 --> 02:03:19.000]   You get all of this just, you know, check boxes, drag and drop and then click the developer
[02:03:19.000 --> 02:03:24.440]   button and all of a sudden you can use Git and SFTP and call it customized to your heart's
[02:03:24.440 --> 02:03:25.440]   content.
[02:03:25.440 --> 02:03:27.760]   I mean, this is the most powerful platform I know.
[02:03:27.760 --> 02:03:29.000]   It is incredible.
[02:03:29.000 --> 02:03:31.740]   You can still get a free domain with the annual purchase.
[02:03:31.740 --> 02:03:37.820]   Your site will look like it's designed by a professional because it is incredible 24/7
[02:03:37.820 --> 02:03:38.820]   customer support.
[02:03:38.820 --> 02:03:42.300]   I tell you, when I move my blog to square space, I thought, "Why did I wait so darn
[02:03:42.300 --> 02:03:44.300]   long?"
[02:03:44.300 --> 02:03:45.420]   Stop waiting and do it.
[02:03:45.420 --> 02:03:46.780]   You can try it free right now.
[02:03:46.780 --> 02:03:52.140]   Go to squarespace.com and if you decide to buy, all I ask use the offer code Twig, you'll
[02:03:52.140 --> 02:03:57.940]   get 10% off your new account, squarespace.com.
[02:03:57.940 --> 02:04:00.840]   Don't forget that offer code.
[02:04:00.840 --> 02:04:02.780]   Twig.
[02:04:02.780 --> 02:04:07.320]   Any tips, picks, anything people want to share with us before we wrap this up?
[02:04:07.320 --> 02:04:09.320]   You got a number for us, Jeff?
[02:04:09.320 --> 02:04:10.320]   Sure.
[02:04:10.320 --> 02:04:15.420]   And I can't resist the straight line of this because I'm not a huge TED fan.
[02:04:15.420 --> 02:04:16.420]   Any problem can be solved.
[02:04:16.420 --> 02:04:17.420]   It's like a sitcom.
[02:04:17.420 --> 02:04:19.780]   Any problem can be solved in 42 minutes.
[02:04:19.780 --> 02:04:23.940]   Any problem can be solved in an 18 minute TED talk.
[02:04:23.940 --> 02:04:30.980]   And so, however, Dave Kennedy, David Kennedy, who's now the head of IBM Watson, he sold
[02:04:30.980 --> 02:04:38.300]   Weather Channel to IBM, a fascinating guy, a huge brilliant, brilliant guy in media.
[02:04:38.300 --> 02:04:47.140]   He just announced with Peter D. Amondis an X Prize around Watson and artificial intelligence.
[02:04:47.140 --> 02:04:48.140]   So that's the good part.
[02:04:48.140 --> 02:04:50.540]   $4.5 million per say total $5 million account petition.
[02:04:50.540 --> 02:04:51.540]   This is great.
[02:04:51.540 --> 02:04:57.960]   The thing that gives me the giggles is that the winners are going to present TED talks.
[02:04:57.960 --> 02:05:00.260]   So you think that TED talks are made by algorithms?
[02:05:00.260 --> 02:05:02.060]   I thought they already were.
[02:05:02.060 --> 02:05:03.060]   They all sound alike.
[02:05:03.060 --> 02:05:04.060]   Oh, that's interesting.
[02:05:04.060 --> 02:05:05.060]   It will come to life.
[02:05:05.060 --> 02:05:08.980]   That would be gotten to my giggles out of me.
[02:05:08.980 --> 02:05:17.460]   I do think it's interesting that now we're going to see what happens with AI or human
[02:05:17.460 --> 02:05:23.060]   AI combos, they say, to get this money on the TED stage and then the people in TED and
[02:05:23.060 --> 02:05:25.420]   the audience who will fall over anything.
[02:05:25.420 --> 02:05:28.380]   I'm sorry.
[02:05:28.380 --> 02:05:31.700]   We'll vote on the winner to get this.
[02:05:31.700 --> 02:05:32.700]   Wow.
[02:05:32.700 --> 02:05:33.700]   So that's interesting.
[02:05:33.700 --> 02:05:34.700]   I thought.
[02:05:34.700 --> 02:05:37.380]   Did you read John Markoff's great New York Times article about the choice, the Watson
[02:05:37.380 --> 02:05:43.420]   voice and how they, I guess it's from a book that he's done on computer personalities.
[02:05:43.420 --> 02:05:47.900]   But it was fun to hear the samples of the different voices, including one that was a
[02:05:47.900 --> 02:05:48.900]   childlike voice.
[02:05:48.900 --> 02:05:52.780]   People said that's way too creepy.
[02:05:52.780 --> 02:05:56.460]   I know everything and I'm four years old.
[02:05:56.460 --> 02:05:59.220]   Hey, it's so great to have you, Matthew.
[02:05:59.220 --> 02:06:03.380]   You have anything you want to share with us or should we just roll on out of here?
[02:06:03.380 --> 02:06:04.380]   We can roll on that.
[02:06:04.380 --> 02:06:11.940]   I wanted to mention to people just quickly, if you have a device you want to try a news
[02:06:11.940 --> 02:06:13.940]   app, Jeff mentioned at the courts.
[02:06:13.940 --> 02:06:15.660]   Oh, isn't that wild?
[02:06:15.660 --> 02:06:16.900]   I wish it were on Android.
[02:06:16.900 --> 02:06:17.900]   It's only iOS.
[02:06:17.900 --> 02:06:18.900]   It's a year.
[02:06:18.900 --> 02:06:22.860]   But it will be there's no, there's no technical reason why they couldn't have done it on both
[02:06:22.860 --> 02:06:23.860]   platforms.
[02:06:23.860 --> 02:06:27.060]   It's just it's you're talking with a bot.
[02:06:27.060 --> 02:06:33.020]   And I think it's it's actually not about it's their editors, but it simulates a conversation.
[02:06:33.020 --> 02:06:34.900]   So it's not a real conversation.
[02:06:34.900 --> 02:06:39.180]   I think it'll be even more interesting when it becomes a real conversation and it's embedded
[02:06:39.180 --> 02:06:41.860]   in a messaging service.
[02:06:41.860 --> 02:06:43.900]   It's asking you what's wrong.
[02:06:43.900 --> 02:06:45.860]   Right, right.
[02:06:45.860 --> 02:06:46.860]   And those are automated, I think.
[02:06:46.860 --> 02:06:48.780]   There's a lot of personality.
[02:06:48.780 --> 02:06:49.780]   I think you're right though.
[02:06:49.780 --> 02:06:50.780]   It's obviously editorial.
[02:06:50.780 --> 02:06:52.340]   It's an interesting choice.
[02:06:52.340 --> 02:06:59.540]   Imagine if there was a bot, a quartz bot or whatever in your messaging tool and this
[02:06:59.540 --> 02:07:03.300]   is coming and you can just say, Hey, what's happening today?
[02:07:03.300 --> 02:07:05.500]   And they bought would say, Well, what are you interested in?
[02:07:05.500 --> 02:07:07.340]   You want to know about world news?
[02:07:07.340 --> 02:07:12.740]   And so you start having a conversation with your Amazon Echo maybe.
[02:07:12.740 --> 02:07:13.820]   Yeah, exactly.
[02:07:13.820 --> 02:07:16.500]   I suspect that's why they only put it out on iOS.
[02:07:16.500 --> 02:07:18.940]   They're just gathering data because that's not the end game.
[02:07:18.940 --> 02:07:20.540]   The end game is exactly what it says.
[02:07:20.540 --> 02:07:21.540]   A real.
[02:07:21.540 --> 02:07:22.540]   Yeah.
[02:07:22.540 --> 02:07:23.540]   Yeah.
[02:07:23.540 --> 02:07:25.260]   So why bother developing for a lot of platforms?
[02:07:25.260 --> 02:07:28.700]   You just need to get some information and see how people like it and tailor it a little
[02:07:28.700 --> 02:07:31.620]   bit and then you could put it out as it really is, which is as a bot.
[02:07:31.620 --> 02:07:33.180]   I want it on my Amazon Echo.
[02:07:33.180 --> 02:07:35.620]   I have now bought two more.
[02:07:35.620 --> 02:07:37.620]   Oh, really?
[02:07:37.620 --> 02:07:39.260]   I have four now.
[02:07:39.260 --> 02:07:40.260]   I want it on the show.
[02:07:40.260 --> 02:07:41.140]   Leo, I want it on the desk.
[02:07:41.140 --> 02:07:42.540]   I got one for here.
[02:07:42.540 --> 02:07:43.540]   Oh, good.
[02:07:43.540 --> 02:07:44.540]   Yeah.
[02:07:44.540 --> 02:07:46.980]   One's going to sit on this desk because we talk about it so much.
[02:07:46.980 --> 02:07:48.780]   Ask questions.
[02:07:48.780 --> 02:07:49.780]   Sorry.
[02:07:49.780 --> 02:07:50.780]   Chat room.
[02:07:50.780 --> 02:07:51.780]   You're being replaced.
[02:07:51.780 --> 02:07:53.780]   We can now ask our questions.
[02:07:53.780 --> 02:07:56.540]   I have black tube.
[02:07:56.540 --> 02:07:57.900]   Or leopard skin wrapped if you'd like.
[02:07:57.900 --> 02:08:00.500]   I might get the leopard screen wrap for the yes.
[02:08:00.500 --> 02:08:02.500]   I don't know.
[02:08:02.500 --> 02:08:07.580]   It's so great to have you Matthew Ingram from of course Fortune.com where he is a senior
[02:08:07.580 --> 02:08:11.660]   editor and one of the really just the best guys writing now on technology.
[02:08:11.660 --> 02:08:12.660]   Love reading your stuff.
[02:08:12.660 --> 02:08:13.660]   Thank you.
[02:08:13.660 --> 02:08:15.220]   And I always love it when you're on the show.
[02:08:15.220 --> 02:08:16.220]   Thank you for being here on this.
[02:08:16.220 --> 02:08:17.220]   Thanks for having me.
[02:08:17.220 --> 02:08:18.220]   Pretty important episode.
[02:08:18.220 --> 02:08:19.220]   Yeah.
[02:08:19.220 --> 02:08:20.220]   He's Matthew.
[02:08:20.220 --> 02:08:21.220]   I on the Twitter.
[02:08:21.220 --> 02:08:22.220]   One G.
[02:08:22.220 --> 02:08:23.220]   I had a little bit of the hard way.
[02:08:23.220 --> 02:08:24.220]   One T.
[02:08:24.220 --> 02:08:25.220]   One T.
[02:08:25.220 --> 02:08:26.220]   Is that on the board anymore?
[02:08:26.220 --> 02:08:27.220]   One T.
[02:08:27.220 --> 02:08:29.060]   The second T is written in the game.
[02:08:29.060 --> 02:08:30.060]   Yeah.
[02:08:30.060 --> 02:08:31.060]   I only need one.
[02:08:31.060 --> 02:08:32.060]   What days are you need?
[02:08:32.060 --> 02:08:33.860]   I only got one L.
[02:08:33.860 --> 02:08:34.860]   Jeff Jarvis.
[02:08:34.860 --> 02:08:39.260]   He's got two F's for reasons no one understands.
[02:08:39.260 --> 02:08:40.900]   You'll find him on.
[02:08:40.900 --> 02:08:43.820]   You don't really want to give out the Google plus address still do you?
[02:08:43.820 --> 02:08:47.780]   No, we got to take those off the lower thirds and make them Twitter now.
[02:08:47.780 --> 02:08:49.420]   You know my blog I haven't been doing.
[02:08:49.420 --> 02:08:53.500]   I've got a cross post on the blog and say, yeah, I told you that medium thing would be
[02:08:53.500 --> 02:08:55.580]   bad for you.
[02:08:55.580 --> 02:08:56.940]   Go instant articles.
[02:08:56.940 --> 02:08:57.940]   Instant articles.
[02:08:57.940 --> 02:09:00.140]   I think we should all just use Facebook and give up.
[02:09:00.140 --> 02:09:01.140]   Yep.
[02:09:01.140 --> 02:09:01.980]   It's over.
[02:09:01.980 --> 02:09:03.980]   I for one welcome our new master.
[02:09:03.980 --> 02:09:09.580]   Yeah, Mark, give me a billion dollars worth a try.
[02:09:09.580 --> 02:09:10.580]   Thank you for joining us.
[02:09:10.580 --> 02:09:14.980]   We do this week in Google every Wednesday afternoon 130 Pacific 430 Eastern time 2130
[02:09:14.980 --> 02:09:15.980]   UTC watch live.
[02:09:15.980 --> 02:09:20.420]   You could be in the chat room, but you don't have to because we make audio and video of
[02:09:20.420 --> 02:09:25.900]   the show available on demand after the fact of twit.tv/twig or wherever you subscribe
[02:09:25.900 --> 02:09:27.660]   to your favorite shows because you know what?
[02:09:27.660 --> 02:09:31.660]   We're on all platforms everywhere, including Roku five apps.
[02:09:31.660 --> 02:09:37.820]   We're on a five on the Apple TV, even even on iOS, Android and Windows phone.
[02:09:37.820 --> 02:09:40.060]   And of course, there's plenty of podcast apps out there.
[02:09:40.060 --> 02:09:41.220]   All of them have it.
[02:09:41.220 --> 02:09:47.020]   So subscribe because we want you to come back and we thank you for joining us.
[02:09:47.020 --> 02:09:48.260]   We'll see you next week.
[02:09:48.260 --> 02:09:51.700]   Bye bye.
[02:09:51.700 --> 02:09:58.700]   a.
[02:09:58.700 --> 02:10:01.720]   

