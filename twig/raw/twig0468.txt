;FFMETADATA1
title=Extra Stolen Privacy
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=468
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.700]   It's time for Twig! This week in Google Jeff Jarvis's years, Stacy Higginbotham is here.
[00:00:04.700 --> 00:00:09.520]   I'm here! We're gonna talk about Android 9.
[00:00:09.520 --> 00:00:11.300]   Pi...
[00:00:11.300 --> 00:00:15.200]   We'll also talk about the Google Pixel 3 XL and leaked images.
[00:00:15.200 --> 00:00:21.500]   What is Google gonna do about China and the banning of Infowars?
[00:00:21.500 --> 00:00:23.500]   It's all coming up next, Sound Twig.
[00:00:23.500 --> 00:00:28.300]   Netcast you love.
[00:00:28.300 --> 00:00:30.300]   From people you trust.
[00:00:30.300 --> 00:00:35.300]   This is Twig.
[00:00:35.300 --> 00:00:46.300]   This is Twig. This week in Google, episode 468, recorded Wednesday, August 8th, 2018.
[00:00:46.300 --> 00:00:49.300]   Extra stolen privacy.
[00:00:49.300 --> 00:00:52.300]   This week in Google is brought to you by WordPress.
[00:00:52.300 --> 00:00:55.300]   Reach more customers when you build your business website on WordPress.com.
[00:00:55.300 --> 00:01:02.300]   Plan start at just $4 a month and you can get 15% off any new plan at WordPress.com/Twig.
[00:01:02.300 --> 00:01:07.300]   And buy rocket mortgage from quick and loans, introducing rate shield approval.
[00:01:07.300 --> 00:01:13.300]   If you're in the market to buy a home, rate shield approval locks up your rate for up to 90 days while you shop.
[00:01:13.300 --> 00:01:14.300]   It's a real game changer.
[00:01:14.300 --> 00:01:19.300]   Learn more and get started at rocketmortgage.com/twig.
[00:01:19.300 --> 00:01:21.300]   It's time for Twig! This week in Google, I'm back.
[00:01:21.300 --> 00:01:23.300]   Thank you Jason Halfer.
[00:01:23.300 --> 00:01:26.300]   Filling in for me. He's back, Jeff Jarvis.
[00:01:26.300 --> 00:01:30.300]   From, oh God, there's a long story.
[00:01:30.300 --> 00:01:32.300]   Clickbait.org.
[00:01:32.300 --> 00:01:37.300]   He's a Buzzmachine.com is his blog and of course he's a townite, etc.
[00:01:37.300 --> 00:01:39.300]   I don't put that up.
[00:01:39.300 --> 00:01:42.300]   Professor of Journalism at the City University of New York.
[00:01:42.300 --> 00:01:46.300]   Also with us from Seattle, Stacey Higginbotham.
[00:01:46.300 --> 00:01:48.300]   Stacey on IOT.com.
[00:01:48.300 --> 00:01:51.300]   She'll be going back to Austin next week.
[00:01:51.300 --> 00:01:53.300]   Yep.
[00:01:53.300 --> 00:01:56.300]   To the beautiful Sunny Climb.
[00:01:56.300 --> 00:02:08.300]   We were just talking before the show and I was not here last week so I was not present for the attempts to get the Lenovo Smart Display working.
[00:02:08.300 --> 00:02:10.300]   However, I understand it is now working, Jeff.
[00:02:10.300 --> 00:02:14.300]   Well, yes and no. We tried to get a call going and we couldn't do it.
[00:02:14.300 --> 00:02:15.300]   But using demo.
[00:02:15.300 --> 00:02:16.300]   Do it for full set.
[00:02:16.300 --> 00:02:17.300]   I hadn't done something yet.
[00:02:17.300 --> 00:02:19.300]   Yeah, you could do it with duo.
[00:02:19.300 --> 00:02:23.300]   But I also have four phones around me so I don't really need it to call.
[00:02:23.300 --> 00:02:24.300]   Right.
[00:02:24.300 --> 00:02:35.300]   No, it's a nice, so it is nice to have a, what do we call it, an always on portal to your home is a good way to think about it.
[00:02:35.300 --> 00:02:43.300]   So I actually used similar functionality on the Amazon Echo while I was gone just to check in on the guy house sitting in my dog.
[00:02:43.300 --> 00:02:49.300]   I use it when I'm traveling to talk to my daughter and to show her things.
[00:02:49.300 --> 00:02:53.300]   So again, I think there's a value to that.
[00:02:53.300 --> 00:03:05.300]   No, and I feel like if when it's, it feels first of all unfinished, we had one very few and Jason Howell give us a full review at some point in the future and all about Android and the new screensavers.
[00:03:05.300 --> 00:03:09.300]   But we did, we played with it on the new screensavers on Saturday and it feels unfinished.
[00:03:09.300 --> 00:03:13.300]   I mean, you're supposed to, I kind of think of it as a kitchen TV, right?
[00:03:13.300 --> 00:03:17.300]   Adjunct, but Netflix doesn't work yet.
[00:03:17.300 --> 00:03:23.300]   You know, it's like, it feels like it's an unfinished product, but that's the easy thing to fix in time.
[00:03:23.300 --> 00:03:26.300]   Did you guys not connected? Because Kevin got Netflix working on his.
[00:03:26.300 --> 00:03:27.300]   He did.
[00:03:27.300 --> 00:03:30.300]   We were told it wasn't working yet.
[00:03:30.300 --> 00:03:34.300]   In fact, a lot of what we got from it, we were just going to play Netflix.
[00:03:34.300 --> 00:03:36.300]   I can't do that yet.
[00:03:36.300 --> 00:03:39.300]   I can't show what's on Netflix.
[00:03:39.300 --> 00:03:40.300]   Huh.
[00:03:40.300 --> 00:03:43.300]   Did you connect your Netflix account?
[00:03:43.300 --> 00:03:45.300]   Sorry.
[00:03:45.300 --> 00:03:47.300]   Oh, you're listening to Netflix now.
[00:03:47.300 --> 00:03:49.300]   No, no, that was an audio book.
[00:03:49.300 --> 00:03:52.300]   Why that came on, I don't know.
[00:03:52.300 --> 00:03:57.300]   These devices are, it's not saying it's not telling me I can do it.
[00:03:57.300 --> 00:04:02.300]   Yeah, these devices are, it is obvious, an exercise in frustration anyway.
[00:04:02.300 --> 00:04:11.300]   But a lot of these get sold on what they can do, and then they don't always implement everything right away.
[00:04:11.300 --> 00:04:14.300]   I've noticed that in a lot of my connected devices, and I finally,
[00:04:14.300 --> 00:04:21.300]   it, comedies are getting better now about actually telling you what they do do as opposed to what they one day will do.
[00:04:21.300 --> 00:04:22.300]   Yeah.
[00:04:22.300 --> 00:04:23.300]   Bye.
[00:04:23.300 --> 00:04:26.300]   Yeah, and that's, I think that's a mistake because consumers get them.
[00:04:26.300 --> 00:04:31.300]   I remember, I'm old enough to remember the days of the VIC-20 computer,
[00:04:31.300 --> 00:04:37.300]   where, so there was a lot of interest in home computing in the, what was this, early, mid-80s.
[00:04:37.300 --> 00:04:43.300]   And some of this was, cause Apple, you know, had an Apple computer and stuff, but they were all expensive.
[00:04:43.300 --> 00:04:47.300]   And so, Commodore decided, well, we'll make a $200 home computer, the VIC-20.
[00:04:47.300 --> 00:04:52.300]   But it was so underpowered and so useless, it almost immediately ended up in people's closets.
[00:04:52.300 --> 00:04:59.300]   And I think it's stymied home computing for some years because people said, oh, I tried that.
[00:04:59.300 --> 00:05:07.300]   Same thing, you know, we've seen that, you know, kind of over and over again, where people, you know, try something and then decide,
[00:05:07.300 --> 00:05:09.300]   oh, that's not, you know, this doesn't work.
[00:05:09.300 --> 00:05:11.300]   And so that's a risk with these home assistants.
[00:05:11.300 --> 00:05:14.300]   It's a risk with all technology purchases.
[00:05:14.300 --> 00:05:19.300]   The netbook killed PC sales for years because people bought, oh, $200 computer.
[00:05:19.300 --> 00:05:25.300]   And it was such crap that it killed PC sales for maybe five years.
[00:05:25.300 --> 00:05:27.300]   Did people actually buy netbooks?
[00:05:27.300 --> 00:05:32.300]   Well, that's exactly the point is that they couldn't resist the price point.
[00:05:32.300 --> 00:05:37.300]   We're going to say the same thing about tablets, you know, there's been quite a swing there, right?
[00:05:37.300 --> 00:05:42.300]   So I, I rebox my, my first iPad and then everybody made fun of me properly because it took over the world.
[00:05:42.300 --> 00:05:44.300]   And now nobody buys tablets anymore.
[00:05:44.300 --> 00:05:48.300]   I think that, you know, you can make the case that people did buy tablets,
[00:05:48.300 --> 00:05:51.300]   which is not buying more tablets than when they got is fine.
[00:05:51.300 --> 00:05:54.300]   Android on the Android side and tablets are flop.
[00:05:54.300 --> 00:05:55.300]   No question.
[00:05:55.300 --> 00:05:58.300]   I love my seven, my Nexus seven.
[00:05:58.300 --> 00:05:59.300]   God, I love that.
[00:05:59.300 --> 00:05:59.300]   Why?
[00:05:59.300 --> 00:06:00.300]   So that's another question.
[00:06:00.300 --> 00:06:02.300]   Why did everybody stop making seven and eight inch tablets?
[00:06:02.300 --> 00:06:03.300]   All of a sudden.
[00:06:03.300 --> 00:06:04.300]   Yeah.
[00:06:04.300 --> 00:06:05.300]   Perfect.
[00:06:05.300 --> 00:06:06.300]   HTC.
[00:06:06.300 --> 00:06:07.300]   Didn't they just do it?
[00:06:07.300 --> 00:06:08.300]   No, honor.
[00:06:08.300 --> 00:06:09.300]   Didn't they just do a seven inch?
[00:06:09.300 --> 00:06:11.300]   Oh, that was a seven inch phone.
[00:06:11.300 --> 00:06:12.300]   Never mind.
[00:06:12.300 --> 00:06:17.300]   That's by the way, the answer to the question why people don't do seven inch tablets anymore.
[00:06:17.300 --> 00:06:21.300]   The answer is seven or eight inch phones or six inch phones.
[00:06:21.300 --> 00:06:23.300]   Anyway, I like this.
[00:06:23.300 --> 00:06:24.300]   I agree with you, Jeff.
[00:06:24.300 --> 00:06:26.300]   That was a really nice device.
[00:06:26.300 --> 00:06:29.300]   And the Pixel C pretty much, no.
[00:06:29.300 --> 00:06:34.300]   We've been playing with for a little bit with the Acer Chromebook tablet.
[00:06:34.300 --> 00:06:36.300]   It's a non-starter race.
[00:06:36.300 --> 00:06:37.300]   Is it Asus?
[00:06:37.300 --> 00:06:39.300]   It's one of the ACEs.
[00:06:39.300 --> 00:06:41.300]   Because it's too low powered.
[00:06:41.300 --> 00:06:42.300]   Yeah.
[00:06:42.300 --> 00:06:45.300]   And Chromebook Chrome OS is not ready for a tablet.
[00:06:45.300 --> 00:06:46.300]   No, it's not.
[00:06:46.300 --> 00:06:48.300]   It's a keyboard OS.
[00:06:48.300 --> 00:06:50.300]   Well, it's not just that.
[00:06:50.300 --> 00:06:53.300]   It's just the things like, you know, DRM stuff and other things that don't run well.
[00:06:53.300 --> 00:06:56.300]   We've got to get Samsung has released its S4.
[00:06:56.300 --> 00:06:58.300]   They announced that last week.
[00:06:58.300 --> 00:07:02.300]   And I'll have to see if we can, no, that's the phone.
[00:07:02.300 --> 00:07:05.300]   I should say S4 tab.
[00:07:05.300 --> 00:07:09.300]   And that looks pretty good.
[00:07:09.300 --> 00:07:18.300]   That is an Android tablet, but it is an Android tablet with a lot of Samsung stuff.
[00:07:18.300 --> 00:07:20.300]   And it has a removable keyboard.
[00:07:20.300 --> 00:07:22.300]   Kind of this looks a lot.
[00:07:22.300 --> 00:07:23.300]   It does look nice.
[00:07:23.300 --> 00:07:24.300]   Yeah.
[00:07:24.300 --> 00:07:26.300]   So I guess we'll maybe get a copy.
[00:07:26.300 --> 00:07:29.300]   What about the new smaller windows?
[00:07:29.300 --> 00:07:30.300]   I like that.
[00:07:30.300 --> 00:07:31.300]   I should have brought that in.
[00:07:31.300 --> 00:07:33.300]   I have that in the other room.
[00:07:33.300 --> 00:07:34.300]   The Surface Go?
[00:07:34.300 --> 00:07:35.300]   Surface Go.
[00:07:35.300 --> 00:07:36.300]   I like it.
[00:07:36.300 --> 00:07:38.300]   It's a little underpowered, but it's kind of--
[00:07:38.300 --> 00:07:40.300]   Is the keyboard totally using my keyboard?
[00:07:40.300 --> 00:07:41.300]   It's a little smaller.
[00:07:41.300 --> 00:07:42.300]   It is.
[00:07:42.300 --> 00:07:43.300]   Oh, yeah.
[00:07:43.300 --> 00:07:44.300]   You'll get used to it real quick.
[00:07:44.300 --> 00:07:46.300]   But I'm sorry, real quickly.
[00:07:46.300 --> 00:07:47.300]   But--
[00:07:47.300 --> 00:07:49.300]   Is it an 8-inch or--
[00:07:49.300 --> 00:07:50.300]   It is 10 inches.
[00:07:50.300 --> 00:07:52.300]   It's exactly the same size as an iPad.
[00:07:52.300 --> 00:07:54.300]   It's the same size of prices in iPad.
[00:07:54.300 --> 00:07:56.300]   It's really what it is aimed at.
[00:07:56.300 --> 00:08:01.300]   It's somebody who might buy an iPad, but maybe wants an operating system, a real operating
[00:08:01.300 --> 00:08:02.300]   system.
[00:08:02.300 --> 00:08:03.300]   As opposed to Chrome OS.
[00:08:03.300 --> 00:08:04.300]   Yes.
[00:08:04.300 --> 00:08:05.300]   Or Chrome OS.
[00:08:05.300 --> 00:08:06.300]   Yeah.
[00:08:06.300 --> 00:08:07.300]   Anyway.
[00:08:07.300 --> 00:08:13.300]   It's an interesting marketplace we live in.
[00:08:13.300 --> 00:08:17.300]   I almost feel like-- and I look at Indiegogo and Kickstarter.
[00:08:17.300 --> 00:08:22.300]   And people are just throwing anything they can up against the wall and hoping that it'll
[00:08:22.300 --> 00:08:24.300]   stick, which on the one hand is good.
[00:08:24.300 --> 00:08:27.300]   But on the other hand, you get a lot of weird beasts.
[00:08:27.300 --> 00:08:29.300]   This is the Surface Go.
[00:08:29.300 --> 00:08:30.300]   Oh.
[00:08:30.300 --> 00:08:31.300]   Yeah.
[00:08:31.300 --> 00:08:32.300]   It's cute, isn't it?
[00:08:32.300 --> 00:08:33.300]   Birdie.
[00:08:33.300 --> 00:08:34.300]   Yeah.
[00:08:34.300 --> 00:08:35.300]   Birdie.
[00:08:35.300 --> 00:08:36.300]   It looks like an iPad.
[00:08:36.300 --> 00:08:37.300]   This is detachable.
[00:08:37.300 --> 00:08:38.300]   Yeah.
[00:08:38.300 --> 00:08:39.300]   It's like my--
[00:08:39.300 --> 00:08:40.300]   Has a pen.
[00:08:40.300 --> 00:08:41.300]   Pixel C, yeah.
[00:08:41.300 --> 00:08:42.300]   Yeah.
[00:08:42.300 --> 00:08:46.300]   Actually, I think if you-- the problem-- I'm not a huge Windows fan.
[00:08:46.300 --> 00:08:47.300]   I can use it.
[00:08:47.300 --> 00:08:50.300]   I can tolerate it, but I'm not a huge Windows fan.
[00:08:50.300 --> 00:08:54.300]   So if you like Windows, it's not a bad choice.
[00:08:54.300 --> 00:08:56.300]   It has the kickstand built in.
[00:08:56.300 --> 00:09:01.300]   And it's a nice-- it's a-- it's a good size for either a second computer or a piece.
[00:09:01.300 --> 00:09:04.300]   I love that you have the tiny version of the B.
[00:09:04.300 --> 00:09:05.300]   I know.
[00:09:05.300 --> 00:09:06.300]   Here's the biggest service.
[00:09:06.300 --> 00:09:07.300]   Here's the little service.
[00:09:07.300 --> 00:09:10.300]   You might think about that, but they really go together, don't they?
[00:09:10.300 --> 00:09:12.300]   [LAUGHTER]
[00:09:12.300 --> 00:09:14.300]   My guy, Grandpa.
[00:09:14.300 --> 00:09:15.300]   Oh.
[00:09:15.300 --> 00:09:17.300]   How you been?
[00:09:17.300 --> 00:09:19.300]   Everything going all right?
[00:09:19.300 --> 00:09:20.300]   [LAUGHTER]
[00:09:20.300 --> 00:09:22.300]   Oh, it's the end of Leo's week.
[00:09:22.300 --> 00:09:24.300]   It's puppet time theater.
[00:09:24.300 --> 00:09:29.300]   So the Pixel 3, I'm a-- now I really like the Google Pixel 2 XL.
[00:09:29.300 --> 00:09:31.300]   You're in the screen.
[00:09:31.300 --> 00:09:36.300]   There are a lot of complaints about it, but I think, you know, it's not the greatest OLED
[00:09:36.300 --> 00:09:37.300]   screen out there, but now--
[00:09:37.300 --> 00:09:38.300]   Not fully used to it.
[00:09:38.300 --> 00:09:40.300]   It used to flash on me, but doesn't anymore.
[00:09:40.300 --> 00:09:41.300]   Yeah.
[00:09:41.300 --> 00:09:42.300]   And now I have pie.
[00:09:42.300 --> 00:09:43.300]   Pie.
[00:09:43.300 --> 00:09:44.300]   We have pie.
[00:09:44.300 --> 00:09:45.300]   Pie.
[00:09:45.300 --> 00:09:52.300]   I am a little surprised to get pie so early, but Pixel-- a lot of the features won't really
[00:09:52.300 --> 00:09:54.300]   be cooked fully cooked in the pie.
[00:09:54.300 --> 00:09:58.300]   It's funny how we used to practically wait outside for a new OS version.
[00:09:58.300 --> 00:09:59.300]   I know.
[00:09:59.300 --> 00:10:01.300]   Well, they're not big changes anymore.
[00:10:01.300 --> 00:10:02.300]   This is not--
[00:10:02.300 --> 00:10:06.300]   This one seems-- pie seems to be kind of significant.
[00:10:06.300 --> 00:10:10.300]   There's a lot of the AI stuff built in where it's going to start anticipating what you need
[00:10:10.300 --> 00:10:12.300]   and allocating resources based on what you do.
[00:10:12.300 --> 00:10:13.300]   Right.
[00:10:13.300 --> 00:10:14.300]   So that's the marketing hype.
[00:10:14.300 --> 00:10:16.060]   But do you find that that's the case?
[00:10:16.060 --> 00:10:17.220]   I don't know.
[00:10:17.220 --> 00:10:22.580]   I find that Google is actually pretty good at predicting things like ever-- and actually
[00:10:22.580 --> 00:10:24.700]   do it in a way that's less creepy.
[00:10:24.700 --> 00:10:30.220]   So sometimes it'll just pop random stuff up for me and I'm like, "Oh, cool."
[00:10:30.220 --> 00:10:33.580]   Is this like the Google now used to be?
[00:10:33.580 --> 00:10:37.540]   I think it's a little bit more running it in the back end.
[00:10:37.540 --> 00:10:40.300]   I don't think it's stuff that you would necessarily notice.
[00:10:40.300 --> 00:10:41.300]   Okay.
[00:10:41.300 --> 00:10:45.300]   I haven't had anything yet, but I only have had pie for a couple of days.
[00:10:45.300 --> 00:10:47.940]   Yeah, I haven't noticed anything.
[00:10:47.940 --> 00:10:52.100]   My favorite thing is that the way they've changed the home button.
[00:10:52.100 --> 00:10:55.500]   But we've seen this-- we saw this in the earlier versions.
[00:10:55.500 --> 00:10:57.300]   Now you can swipe between apps.
[00:10:57.300 --> 00:11:00.020]   And of course, you've got to remind people if they've gotten it, you don't get that
[00:11:00.020 --> 00:11:01.020]   automatically.
[00:11:01.020 --> 00:11:02.020]   Yes.
[00:11:02.020 --> 00:11:04.500]   You have to-- is that the case even in the release version?
[00:11:04.500 --> 00:11:05.500]   It is.
[00:11:05.500 --> 00:11:06.500]   Is that right, Carson?
[00:11:06.500 --> 00:11:07.500]   You have to enable that.
[00:11:07.500 --> 00:11:08.500]   So you go to Settings.
[00:11:08.500 --> 00:11:11.220]   You have to change how the home-- I think that makes sense because it is a bit of a
[00:11:11.220 --> 00:11:15.660]   big change to the way the home button operates.
[00:11:15.660 --> 00:11:17.220]   And is it under accessibility?
[00:11:17.220 --> 00:11:18.220]   I bet you it is.
[00:11:18.220 --> 00:11:19.220]   No.
[00:11:19.220 --> 00:11:20.220]   That's the problem.
[00:11:20.220 --> 00:11:21.220]   I can't.
[00:11:21.220 --> 00:11:22.580]   Every time I do it, I forget where it was.
[00:11:22.580 --> 00:11:23.580]   Where is it?
[00:11:23.580 --> 00:11:24.580]   It's under system, I think.
[00:11:24.580 --> 00:11:25.580]   System.
[00:11:25.580 --> 00:11:26.580]   It's just a control.
[00:11:26.580 --> 00:11:27.580]   Gestures.
[00:11:27.580 --> 00:11:28.580]   Yeah, that's it.
[00:11:28.580 --> 00:11:31.020]   So you want active-- nope, that's a squeeze.
[00:11:31.020 --> 00:11:32.020]   Yeah.
[00:11:32.020 --> 00:11:33.020]   That's silly.
[00:11:33.020 --> 00:11:34.020]   Squeezing is silly.
[00:11:34.020 --> 00:11:35.020]   I love the squeeze.
[00:11:35.020 --> 00:11:36.020]   I forgot that it even exists.
[00:11:36.020 --> 00:11:37.020]   I finally took it off.
[00:11:37.020 --> 00:11:38.020]   I finally took it off.
[00:11:38.020 --> 00:11:39.020]   I finally took it off.
[00:11:39.020 --> 00:11:40.220]   Swipe it off to home button.
[00:11:40.220 --> 00:11:41.220]   Yes.
[00:11:41.220 --> 00:11:42.220]   Swipe it off.
[00:11:42.220 --> 00:11:43.220]   System.
[00:11:43.220 --> 00:11:44.220]   Gestures.
[00:11:44.220 --> 00:11:45.220]   Swipe it off.
[00:11:45.220 --> 00:11:46.220]   On home button.
[00:11:46.220 --> 00:11:55.620]   And then-- and so now you can swipe up like this to get recents or my favorite feature,
[00:11:55.620 --> 00:11:59.460]   which isn't immediately obvious, and isn't in fact given away by the name swipe up to
[00:11:59.460 --> 00:12:02.140]   home button is you can swipe sideways.
[00:12:02.140 --> 00:12:08.260]   You could-- and this is right out of iPhone X. But I really like that feature you use it
[00:12:08.260 --> 00:12:09.260]   all the time.
[00:12:09.260 --> 00:12:10.260]   My most common use for it.
[00:12:10.260 --> 00:12:11.260]   Oh.
[00:12:11.260 --> 00:12:12.260]   I'm in a-- nobody knows this.
[00:12:12.260 --> 00:12:15.980]   I'm in a site and I'm trying to enter the password.
[00:12:15.980 --> 00:12:18.900]   So I swipe over to LastPassCopy and swipe back to the site.
[00:12:18.900 --> 00:12:19.900]   It's very convenient.
[00:12:19.900 --> 00:12:22.420]   You learn something every time on Twig.
[00:12:22.420 --> 00:12:23.420]   Wow.
[00:12:23.420 --> 00:12:24.420]   Pi is here, baby.
[00:12:24.420 --> 00:12:28.620]   I don't turn your expensive Microsoft device into a puppet.
[00:12:28.620 --> 00:12:30.380]   And how to swipe up.
[00:12:30.380 --> 00:12:31.380]   What's up?
[00:12:31.380 --> 00:12:32.380]   So--
[00:12:32.380 --> 00:12:33.380]   Wait, where do I turn that on?
[00:12:33.380 --> 00:12:34.380]   Again, I'm in the setting.
[00:12:34.380 --> 00:12:35.380]   System.
[00:12:35.380 --> 00:12:36.380]   System.
[00:12:36.380 --> 00:12:37.380]   We'll walk you through it.
[00:12:37.380 --> 00:12:38.380]   System.
[00:12:38.380 --> 00:12:39.380]   System.
[00:12:39.380 --> 00:12:43.100]   And then swipe up on home button on.
[00:12:43.100 --> 00:12:48.500]   Now and it's funny, even in the illustration, they show that swiping up.
[00:12:48.500 --> 00:12:49.980]   But they don't show there's swipe left.
[00:12:49.980 --> 00:12:51.740]   I don't know why that is.
[00:12:51.740 --> 00:12:54.500]   Is that a swipe right?
[00:12:54.500 --> 00:12:56.580]   Yeah, you're right.
[00:12:56.580 --> 00:12:57.580]   It's swipe right only.
[00:12:57.580 --> 00:13:00.740]   I thought maybe it was swipe left too, but it is only swipe right.
[00:13:00.740 --> 00:13:01.740]   You know, I did just get it.
[00:13:01.740 --> 00:13:05.820]   And I don't know if everyone has this or I was belated, but Gmail just suggested to
[00:13:05.820 --> 00:13:11.940]   me probably four or five days ago to change my swipe settings.
[00:13:11.940 --> 00:13:13.700]   So basic in-- is it inbox?
[00:13:13.700 --> 00:13:16.300]   No, it's Gmail.
[00:13:16.300 --> 00:13:21.660]   And now it let me customize it so I can swipe left or right to delete things and archive
[00:13:21.660 --> 00:13:23.300]   or move things.
[00:13:23.300 --> 00:13:24.300]   Has this happened to you?
[00:13:24.300 --> 00:13:26.020]   Yeah, I see it a lot.
[00:13:26.020 --> 00:13:27.740]   That's the files go feature, right?
[00:13:27.740 --> 00:13:28.740]   Or no?
[00:13:28.740 --> 00:13:32.460]   Yeah, but mine has always been if I moved it one direction, it would archive.
[00:13:32.460 --> 00:13:33.460]   Oh.
[00:13:33.460 --> 00:13:34.460]   And I hate it because I hate archiving.
[00:13:34.460 --> 00:13:35.460]   So you're trying to have mail?
[00:13:35.460 --> 00:13:37.060]   Oh, yeah, yeah, yeah, yeah.
[00:13:37.060 --> 00:13:38.060]   I'm sorry.
[00:13:38.060 --> 00:13:39.060]   It's not files go.
[00:13:39.060 --> 00:13:40.060]   It's Gmail.
[00:13:40.060 --> 00:13:41.060]   Yeah.
[00:13:41.060 --> 00:13:42.780]   Yeah, it's in Gmail.
[00:13:42.780 --> 00:13:44.020]   So I've been loving that.
[00:13:44.020 --> 00:13:49.500]   That is like made my mobile mail just like super manageable.
[00:13:49.500 --> 00:13:50.500]   So--
[00:13:50.500 --> 00:13:53.820]   I don't use Gmail, but if I did, I would.
[00:13:53.820 --> 00:13:57.180]   I was like, go for customization, you guys.
[00:13:57.180 --> 00:13:58.180]   It's awesome.
[00:13:58.180 --> 00:13:59.180]   So what do you think?
[00:13:59.180 --> 00:14:00.180]   The notch?
[00:14:00.180 --> 00:14:01.180]   It's pretty clear now.
[00:14:01.180 --> 00:14:03.460]   We're getting close to the Pixel 3.
[00:14:03.460 --> 00:14:05.020]   And we now see production units.
[00:14:05.020 --> 00:14:10.340]   There was an unboxing by a Ukrainian tech blogger on his telegram channel.
[00:14:10.340 --> 00:14:12.020]   Wow.
[00:14:12.020 --> 00:14:14.580]   And we don't know when this is going to come out.
[00:14:14.580 --> 00:14:16.500]   He shows that it will have Bluetooth.
[00:14:16.500 --> 00:14:18.380]   Well, are those Bluetooth?
[00:14:18.380 --> 00:14:19.380]   I don't think so.
[00:14:19.380 --> 00:14:23.540]   I saw a number of bloggers say it was Bluetooth, but look, see, there's a Type-C connector.
[00:14:23.540 --> 00:14:25.860]   So those are not Bluetooth earbuds in there.
[00:14:25.860 --> 00:14:27.900]   They do look like the Pixel buds, but they're not--
[00:14:27.900 --> 00:14:32.940]   It would make sense because people hate the fact that there are no Type-C headphones out
[00:14:32.940 --> 00:14:33.940]   there.
[00:14:33.940 --> 00:14:36.980]   Well, this one, the last one they offered, Pixel Type-C headphones.
[00:14:36.980 --> 00:14:38.140]   And I think there's also a--
[00:14:38.140 --> 00:14:39.140]   No, they didn't.
[00:14:39.140 --> 00:14:40.140]   They didn't.
[00:14:40.140 --> 00:14:41.140]   No, they didn't.
[00:14:41.140 --> 00:14:42.140]   No, they didn't.
[00:14:42.140 --> 00:14:43.140]   No.
[00:14:43.140 --> 00:14:44.140]   That's a frustration.
[00:14:44.140 --> 00:14:47.260]   This has been the bane of my existence for the longest time.
[00:14:47.260 --> 00:14:50.060]   And I had to finally pony up for Bluetooth.
[00:14:50.060 --> 00:14:54.100]   Well, they did offer-- did they not an adapter, though, that takes a hit regularly?
[00:14:54.100 --> 00:14:57.820]   Yeah, they had a $9 dongle that saw it.
[00:14:57.820 --> 00:14:59.980]   I think the phone came with a dongle.
[00:14:59.980 --> 00:15:01.460]   It came with it, but mine broke.
[00:15:01.460 --> 00:15:02.460]   Right.
[00:15:02.460 --> 00:15:03.460]   And it's too easy.
[00:15:03.460 --> 00:15:04.460]   At least two more.
[00:15:04.460 --> 00:15:05.460]   The goggles are the loosest.
[00:15:05.460 --> 00:15:06.460]   I really hate Type-C.
[00:15:06.460 --> 00:15:07.940]   I really hate losing the headphone jack.
[00:15:07.940 --> 00:15:08.940]   Let's put that up.
[00:15:08.940 --> 00:15:09.940]   I hope that's ridiculous.
[00:15:09.940 --> 00:15:10.940]   So should they bring it back?
[00:15:10.940 --> 00:15:11.940]   Yeah.
[00:15:11.940 --> 00:15:14.740]   Can we stop complaining so much about notches and actually complain about the loss of the
[00:15:14.740 --> 00:15:18.060]   headphone jack, which I feel is much more mainstream than the headphone jack?
[00:15:18.060 --> 00:15:20.260]   It feels gratuitous.
[00:15:20.260 --> 00:15:23.660]   Samsung's able to keep a headphone jack in a phone of the same size.
[00:15:23.660 --> 00:15:25.500]   It seems with just as many features.
[00:15:25.500 --> 00:15:27.100]   It seems gratuitous.
[00:15:27.100 --> 00:15:31.260]   And the fact that Apple did that in the notch and now Google's doing that in the notch,
[00:15:31.260 --> 00:15:33.380]   it just irks her.
[00:15:33.380 --> 00:15:34.620]   Why copy?
[00:15:34.620 --> 00:15:35.780]   Why?
[00:15:35.780 --> 00:15:41.900]   The notch, by the way, seems completely pointless given that you've got a big lip anyway at
[00:15:41.900 --> 00:15:42.900]   the bottom.
[00:15:42.900 --> 00:15:43.900]   I don't know.
[00:15:43.900 --> 00:15:44.900]   I don't know.
[00:15:44.900 --> 00:15:46.900]   Anyway, I can live with the notch.
[00:15:46.900 --> 00:15:49.180]   I live with it on the iPhone 10 headphone jack.
[00:15:49.180 --> 00:15:50.180]   I agree with you, Jeff.
[00:15:50.180 --> 00:15:51.820]   It's a much more serious omission.
[00:15:51.820 --> 00:15:52.820]   Wait, no, that was.
[00:15:52.820 --> 00:15:53.820]   That was Stacy.
[00:15:53.820 --> 00:15:54.820]   I agree with you, Stacy.
[00:15:54.820 --> 00:15:55.820]   It's a much more.
[00:15:55.820 --> 00:15:56.820]   I confuse you.
[00:15:56.820 --> 00:15:57.820]   Is a must.
[00:15:57.820 --> 00:16:00.460]   Stacy was cutting off my notch hatred.
[00:16:00.460 --> 00:16:01.460]   I'm sorry.
[00:16:01.460 --> 00:16:03.860]   It's just like, come on.
[00:16:03.860 --> 00:16:10.260]   This is the unboxing, which I find to be the most frustrating thing I've ever seen because
[00:16:10.260 --> 00:16:16.060]   he's holding his camera with one hand and attempting with his left hand to unbox.
[00:16:16.060 --> 00:16:17.060]   Use your mouth.
[00:16:17.060 --> 00:16:21.060]   And by the way, the very first thing it does in the unboxing is take the phone and put it
[00:16:21.060 --> 00:16:22.060]   aside.
[00:16:22.060 --> 00:16:23.060]   Yeah.
[00:16:23.060 --> 00:16:28.020]   So now the almost the entire length of this is devoted to him attempting to do with one
[00:16:28.020 --> 00:16:31.180]   hand to open paper.
[00:16:31.180 --> 00:16:37.140]   Dude, dude, I know you're merely a Ukrainian blogger on Telegram, but come on.
[00:16:37.140 --> 00:16:39.420]   You're trying to drive us nuts.
[00:16:39.420 --> 00:16:40.420]   We've seen all this.
[00:16:40.420 --> 00:16:41.420]   I don't need to.
[00:16:41.420 --> 00:16:47.900]   He spends in anordinate amount of time on the Sim pin, the Sim poker.
[00:16:47.900 --> 00:16:52.860]   The whole thing is the worst unboxing ever.
[00:16:52.860 --> 00:16:54.420]   Where's the phone?
[00:16:54.420 --> 00:16:55.740]   I took it off.
[00:16:55.740 --> 00:16:57.780]   It's over on the lift.
[00:16:57.780 --> 00:16:58.780]   That's it.
[00:16:58.780 --> 00:17:01.740]   Yeah, I'm thrilled it has that.
[00:17:01.740 --> 00:17:02.740]   I'm thrilled.
[00:17:02.740 --> 00:17:04.580]   Oh, we get to see both sides of it.
[00:17:04.580 --> 00:17:05.580]   Oh, yeah.
[00:17:05.580 --> 00:17:06.580]   Never seen the back.
[00:17:06.580 --> 00:17:07.580]   Eventually he's going to get to the earbuds.
[00:17:07.580 --> 00:17:08.580]   Don't forget it.
[00:17:08.580 --> 00:17:09.580]   I give up.
[00:17:09.580 --> 00:17:18.860]   First, all this rustling.
[00:17:18.860 --> 00:17:24.660]   So this is a pre-release because somebody points out that the camera notification has
[00:17:24.660 --> 00:17:32.020]   the dog food, camera icon is the dog food notification, which means it's a Google employees
[00:17:32.020 --> 00:17:33.460]   device he's testing out.
[00:17:33.460 --> 00:17:35.060]   Oh, so I'm using Triml.
[00:17:35.060 --> 00:17:36.060]   Yeah.
[00:17:36.060 --> 00:17:40.100]   But it's completely credible that this is what it is.
[00:17:40.100 --> 00:17:43.220]   And when did the new phones come out in October or September for Google?
[00:17:43.220 --> 00:17:44.220]   Unknown.
[00:17:44.220 --> 00:17:46.820]   The last time we tried to do it before Apple came out with the iPhone.
[00:17:46.820 --> 00:17:48.980]   They announced October 4 the last year.
[00:17:48.980 --> 00:17:50.780]   So everything's in October 4.
[00:17:50.780 --> 00:17:51.780]   Oh, okay.
[00:17:51.780 --> 00:17:53.260]   And now it's what they actually come out.
[00:17:53.260 --> 00:17:54.260]   I don't know.
[00:17:54.260 --> 00:17:58.460]   But they pushed Android Pie out already.
[00:17:58.460 --> 00:18:01.860]   Kind of makes me think they're maybe doing this sooner.
[00:18:01.860 --> 00:18:07.180]   Well, I want to do Chromebook.
[00:18:07.180 --> 00:18:09.380]   I was like, I don't want to do it.
[00:18:09.380 --> 00:18:10.380]   I'm in one mind.
[00:18:10.380 --> 00:18:11.380]   It's fine as it is.
[00:18:11.380 --> 00:18:12.380]   It's ridiculous.
[00:18:12.380 --> 00:18:13.380]   I don't need one.
[00:18:13.380 --> 00:18:14.380]   I could live another two years on it.
[00:18:14.380 --> 00:18:16.660]   But hey, that's an interesting.
[00:18:16.660 --> 00:18:18.180]   I think you're the only one.
[00:18:18.180 --> 00:18:20.180]   No, we have Elgin.
[00:18:20.180 --> 00:18:23.540]   Elgin wants a new Chromebook too, huh?
[00:18:23.540 --> 00:18:27.180]   Well, he would because he's trying to tell the world that he's the greater lover than
[00:18:27.180 --> 00:18:28.180]   I am.
[00:18:28.180 --> 00:18:29.180]   But he's wrong.
[00:18:29.180 --> 00:18:30.180]   Oh, you two are going to fight.
[00:18:30.180 --> 00:18:31.180]   Oh, yeah.
[00:18:31.180 --> 00:18:32.180]   Yeah.
[00:18:32.180 --> 00:18:34.940]   Fight over who loves Chromebook more.
[00:18:34.940 --> 00:18:35.940]   Pie.
[00:18:35.940 --> 00:18:36.940]   Okay, let's talk about this AI.
[00:18:36.940 --> 00:18:40.540]   I mean, this is the, this is, you know, sometimes when I see AI, I start to just think,
[00:18:40.540 --> 00:18:42.700]   oh, man, that's just like, that's like saying blockchain.
[00:18:42.700 --> 00:18:44.860]   Might as well say, power by blockchain.
[00:18:44.860 --> 00:18:49.380]   It's just, but maybe, maybe, I mean, Google is, you know, the leader, I think.
[00:18:49.380 --> 00:18:51.700]   Google is actually legit when it comes to AI.
[00:18:51.700 --> 00:18:52.700]   Yeah.
[00:18:52.700 --> 00:18:55.980]   They actually, let's put it applied AI.
[00:18:55.980 --> 00:18:59.020]   So they actually do things.
[00:18:59.020 --> 00:19:02.780]   A lot of this stuff, I don't think is actually available yet.
[00:19:02.780 --> 00:19:07.620]   So I know it's part of pie, but like some of the cooler stuff.
[00:19:07.620 --> 00:19:09.260]   Later this year, yeah.
[00:19:09.260 --> 00:19:11.100]   Slices, I think.
[00:19:11.100 --> 00:19:16.180]   And I'm kind of curious because doesn't slices sound like, oh, I always forget what they
[00:19:16.180 --> 00:19:17.180]   call them.
[00:19:17.180 --> 00:19:18.180]   I am an Android.
[00:19:18.180 --> 00:19:19.180]   Instant Android apps.
[00:19:19.180 --> 00:19:20.180]   Yes.
[00:19:20.180 --> 00:19:26.900]   So even if the app's not installed, it will show you a slice of it.
[00:19:26.900 --> 00:19:30.860]   And actually instant apps was if the app was not installed.
[00:19:30.860 --> 00:19:32.540]   Slice may not do that.
[00:19:32.540 --> 00:19:35.900]   But what slice does is it puts chunks of the app into Google search.
[00:19:35.900 --> 00:19:41.060]   So if you type lift into Google search, you'll see the app and it knows where you want it.
[00:19:41.060 --> 00:19:43.180]   And it'll put another information for you there too.
[00:19:43.180 --> 00:19:44.180]   Right.
[00:19:44.180 --> 00:19:45.180]   And the ETA for drivers.
[00:19:45.180 --> 00:19:47.620]   So without launching the lift app, I think this makes a lot of sense.
[00:19:47.620 --> 00:19:48.620]   I like this.
[00:19:48.620 --> 00:19:52.340]   It does, although it's bringing.
[00:19:52.340 --> 00:19:55.780]   I hate that they're doing all of this with, I mean, this says it's your apps.
[00:19:55.780 --> 00:20:00.060]   I hate that all of this is happening within the Android ecosystem as opposed to the broader
[00:20:00.060 --> 00:20:06.220]   web because this ecosystem, which you're going to have is something different here versus
[00:20:06.220 --> 00:20:07.940]   the experience elsewhere.
[00:20:07.940 --> 00:20:10.620]   And these sort of things just drive me absolutely bonkers.
[00:20:10.620 --> 00:20:14.380]   Well, what are slices will work with progressive web apps, in which case?
[00:20:14.380 --> 00:20:16.460]   Well, then they might be.
[00:20:16.460 --> 00:20:17.460]   Yeah.
[00:20:17.460 --> 00:20:22.380]   So among other things, the AI will learn is adaptive battery.
[00:20:22.380 --> 00:20:27.340]   It'll notice which apps you use the most and prioritize the battery for them.
[00:20:27.340 --> 00:20:31.540]   Adaptive brightness, which learns what settings you prefer in different, what brightness settings
[00:20:31.540 --> 00:20:35.580]   you prefer in different locales and then automatically does it.
[00:20:35.580 --> 00:20:39.100]   So you get to work, it'll turn it up, go to bed, it'll turn it down.
[00:20:39.100 --> 00:20:45.900]   App actions predict what you'll want to do next based, this will be very interesting,
[00:20:45.900 --> 00:20:49.500]   based on your context and display that action right in your phone.
[00:20:49.500 --> 00:20:51.460]   So this is a lot what app like what app.
[00:20:51.460 --> 00:20:55.100]   Yeah, I was the audio book I'm listening to.
[00:20:55.100 --> 00:20:57.900]   So it's doing that where and Google news.
[00:20:57.900 --> 00:21:05.500]   So on that screen, it has the apps you can't really see it's on the app screen.
[00:21:05.500 --> 00:21:06.500]   Okay.
[00:21:06.500 --> 00:21:07.740]   Right there, it has two things.
[00:21:07.740 --> 00:21:08.740]   It just two things.
[00:21:08.740 --> 00:21:12.180]   One is the audio book of the Reformation on listening to.
[00:21:12.180 --> 00:21:14.100]   Ooh, how fascinating.
[00:21:14.100 --> 00:21:17.740]   Well, it was Martin Luther's 500th birthday.
[00:21:17.740 --> 00:21:18.740]   It was last year.
[00:21:18.740 --> 00:21:21.580]   Well, it may be of the theses.
[00:21:21.580 --> 00:21:22.580]   The of the theses.
[00:21:22.580 --> 00:21:23.580]   Okay.
[00:21:23.580 --> 00:21:24.740]   The dailing of the 95.
[00:21:24.740 --> 00:21:30.740]   I got to I bought I bought a Luther biography that I started listening to that day.
[00:21:30.740 --> 00:21:34.540]   Which one because this one that I.
[00:21:34.540 --> 00:21:36.340]   One that you like and one that you don't know this one.
[00:21:36.340 --> 00:21:39.180]   Well, there's one that has like Sean Hannity recommendations.
[00:21:39.180 --> 00:21:43.100]   No, this is definitely not Sean Hannity's Luther.
[00:21:43.100 --> 00:21:46.700]   Oh, God, I hope Eric.
[00:21:46.700 --> 00:21:47.700]   No, Max.
[00:21:47.700 --> 00:21:52.660]   Isn't that what is that what Bill O'Reilly was doing for a while is I don't like the
[00:21:52.660 --> 00:21:57.900]   the murder of Kennedy the murder of no, it is not that it is.
[00:21:57.900 --> 00:21:59.700]   I hope it's the truth.
[00:21:59.700 --> 00:22:01.900]   No, Eric with taxes.
[00:22:01.900 --> 00:22:02.900]   Yes, taxes.
[00:22:02.900 --> 00:22:05.340]   No, is that the bad one?
[00:22:05.340 --> 00:22:07.260]   Look at the well, look at the blurbs.
[00:22:07.260 --> 00:22:10.460]   It's a it's a very weird mix.
[00:22:10.460 --> 00:22:13.980]   Really, that's a bad one because it was it was pretty good so far.
[00:22:13.980 --> 00:22:17.060]   And somebody I know who my sister I think the minister said.
[00:22:17.060 --> 00:22:18.980]   Oh, the ministers don't like it.
[00:22:18.980 --> 00:22:23.860]   You, you, it Tucker Carlson, the Washington Times all love it.
[00:22:23.860 --> 00:22:25.340]   Oh, I guess I got.
[00:22:25.340 --> 00:22:28.940]   Oh, my God, you bought a conservative biography of Martin Luther.
[00:22:28.940 --> 00:22:30.300]   Well, he was okay.
[00:22:30.300 --> 00:22:32.340]   So it's so far.
[00:22:32.340 --> 00:22:33.340]   It's been pretty good.
[00:22:33.340 --> 00:22:37.700]   And because one of the problems with Luther is that he is kind of canonized as the founder
[00:22:37.700 --> 00:22:42.700]   of the Protestant denomination, but he was he was a miserable anti-Semite.
[00:22:42.700 --> 00:22:47.100]   And that is that is so far in the book quite a bit.
[00:22:47.100 --> 00:22:52.300]   That acknowledges his is the book that I will recommend highly, highly, highly is the one
[00:22:52.300 --> 00:22:55.500]   that is a is a joint biography of a different one.
[00:22:55.500 --> 00:22:56.500]   Yeah.
[00:22:56.500 --> 00:22:57.500]   Although this one's been good.
[00:22:57.500 --> 00:22:58.500]   Here.
[00:22:58.500 --> 00:23:01.820]   I don't know why maybe other people like it besides John Hannity.
[00:23:01.820 --> 00:23:02.820]   Is that possible?
[00:23:02.820 --> 00:23:03.820]   That's possible.
[00:23:03.820 --> 00:23:06.500]   But he was one of the people like hold on a second here.
[00:23:06.500 --> 00:23:09.700]   It's fatal discord.
[00:23:09.700 --> 00:23:12.100]   It's about Luther and Erasmus.
[00:23:12.100 --> 00:23:13.100]   It's surprising.
[00:23:13.100 --> 00:23:14.700]   Oh, that I would like to read actually.
[00:23:14.700 --> 00:23:16.100]   That's really, really good.
[00:23:16.100 --> 00:23:17.300]   No, I don't want to download it.
[00:23:17.300 --> 00:23:18.300]   Oh, okay.
[00:23:18.300 --> 00:23:27.500]   So my taxes is written in a lot of other books that I understand why, you know, religious
[00:23:27.500 --> 00:23:32.500]   books, but you know, anybody's going to write about Luther is going to be who's bone hofer.
[00:23:32.500 --> 00:23:33.900]   Oh, a.
[00:23:33.900 --> 00:23:38.900]   A victim of the Nazis.
[00:23:38.900 --> 00:23:41.900]   He wrote a book about bone hofer.
[00:23:41.900 --> 00:23:42.900]   One hofer.
[00:23:42.900 --> 00:23:43.900]   One hofer.
[00:23:43.900 --> 00:23:44.900]   Yeah.
[00:23:44.900 --> 00:23:47.100]   Well, anyway, I don't know.
[00:23:47.100 --> 00:23:49.700]   So far, it sounds fine to me.
[00:23:49.700 --> 00:23:53.900]   He wrote a book about miracles, what they are, how they happen.
[00:23:53.900 --> 00:23:56.300]   He wrote a book called The Forgotten Promise of American Liberty.
[00:23:56.300 --> 00:23:57.700]   Yes, that one also.
[00:23:57.700 --> 00:24:02.020]   And if you can keep it, the forgotten promise of American liberty.
[00:24:02.020 --> 00:24:05.420]   I'm going to get in trouble for having said this.
[00:24:05.420 --> 00:24:09.820]   I, you poisoned it.
[00:24:09.820 --> 00:24:11.620]   It poisoned me now.
[00:24:11.620 --> 00:24:12.620]   Oh, gosh.
[00:24:12.620 --> 00:24:13.820]   Just read it and form your own.
[00:24:13.820 --> 00:24:16.620]   So far, it's been very good.
[00:24:16.620 --> 00:24:21.820]   My point was merely that I started reading it when Luther nailed the 90, 95 theses on
[00:24:21.820 --> 00:24:25.900]   the Vittenberg Church door and I'm only about a quarter of the way through it.
[00:24:25.900 --> 00:24:27.220]   So it's a long book.
[00:24:27.220 --> 00:24:29.420]   It's pretty much believed that he didn't really do that.
[00:24:29.420 --> 00:24:30.420]   That's okay.
[00:24:30.420 --> 00:24:32.220]   Yeah, but that's what's been great about them.
[00:24:32.220 --> 00:24:33.740]   It's been a tax book so far.
[00:24:33.740 --> 00:24:37.460]   Is there a huge number of myths about Luther, which are all completely wrong.
[00:24:37.460 --> 00:24:40.620]   So I visited that church in Berlin for no reason.
[00:24:40.620 --> 00:24:41.620]   Yeah.
[00:24:41.620 --> 00:24:42.620]   Well, I'm Berlin.
[00:24:42.620 --> 00:24:43.620]   It's not Berlin.
[00:24:43.620 --> 00:24:44.620]   So there's problem number one.
[00:24:44.620 --> 00:24:45.620]   Yeah.
[00:24:45.620 --> 00:24:46.620]   It wasn't Berlin.
[00:24:46.620 --> 00:24:50.220]   Well, it was his church and it pulled the end up on the door at some point.
[00:24:50.220 --> 00:24:52.620]   But it might have been nailed.
[00:24:52.620 --> 00:24:59.420]   Oh, is it bone hofer who said when they came for the blank?
[00:24:59.420 --> 00:25:01.340]   I know that was Martin.
[00:25:01.340 --> 00:25:02.340]   That was Neemer.
[00:25:02.340 --> 00:25:03.340]   Yeah, right.
[00:25:03.340 --> 00:25:04.340]   Neemer.
[00:25:04.340 --> 00:25:05.340]   Neemer.
[00:25:05.340 --> 00:25:06.340]   Neemer.
[00:25:06.340 --> 00:25:07.340]   Wait, how did we get on here?
[00:25:07.340 --> 00:25:08.340]   Let's.
[00:25:08.340 --> 00:25:09.340]   I don't know.
[00:25:09.340 --> 00:25:10.340]   I don't know.
[00:25:10.340 --> 00:25:11.340]   This show is making me crazy.
[00:25:11.340 --> 00:25:12.580]   We were talking about this.
[00:25:12.580 --> 00:25:14.580]   We were talking about your audio book.
[00:25:14.580 --> 00:25:15.580]   Okay.
[00:25:15.580 --> 00:25:16.580]   Wait.
[00:25:16.580 --> 00:25:21.700]   So here's the question because when Google talks about delivering the apps via context,
[00:25:21.700 --> 00:25:24.220]   I'm curious which context it's getting.
[00:25:24.220 --> 00:25:27.500]   So it may be that you always listen to your audio books at home.
[00:25:27.500 --> 00:25:28.500]   So that might be.
[00:25:28.500 --> 00:25:33.140]   No, because look at, look what's on my suggestions, which is pretty boneheaded gmail, which I
[00:25:33.140 --> 00:25:38.260]   don't use files go, which I had opened when you mentioned it for the first time in a long
[00:25:38.260 --> 00:25:43.700]   time, Google five, well, it's a five phone inbox, another version of gmail, which I don't
[00:25:43.700 --> 00:25:44.860]   use.
[00:25:44.860 --> 00:25:46.820]   And then I don't know what this is.
[00:25:46.820 --> 00:25:49.340]   Hang I think it's the Hangouts notification.
[00:25:49.340 --> 00:25:52.660]   Leo, for me, that line is just recently used apps.
[00:25:52.660 --> 00:25:54.860]   Oh, well, where's your line that I'm sorry.
[00:25:54.860 --> 00:25:55.860]   I'm looking at the wrong line.
[00:25:55.860 --> 00:25:57.500]   Do you go all the way up?
[00:25:57.500 --> 00:25:59.500]   And it's this thing.
[00:25:59.500 --> 00:26:04.220]   Well, no, it's not doing it right below.
[00:26:04.220 --> 00:26:06.380]   It's the same thing.
[00:26:06.380 --> 00:26:07.380]   Not that this one.
[00:26:07.380 --> 00:26:08.580]   There's another line here.
[00:26:08.580 --> 00:26:09.860]   You can't see because it's too dark.
[00:26:09.860 --> 00:26:11.940]   I don't have a line.
[00:26:11.940 --> 00:26:15.700]   So I mean, here comes Carson with his line.
[00:26:15.700 --> 00:26:17.700]   All right, let's see.
[00:26:17.700 --> 00:26:20.460]   Ah, Carson also has a pixel.
[00:26:20.460 --> 00:26:22.860]   Oh, yeah, there you go.
[00:26:22.860 --> 00:26:24.660]   Kimmy wife and Zach.
[00:26:24.660 --> 00:26:26.900]   Those are like people you call.
[00:26:26.900 --> 00:26:29.140]   Why don't I have that line?
[00:26:29.140 --> 00:26:31.380]   Did I somehow have to remind you it's your wife?
[00:26:31.380 --> 00:26:32.380]   Did I have to?
[00:26:32.380 --> 00:26:33.380]   Yeah, that's what it was for you.
[00:26:33.380 --> 00:26:36.660]   As opposed to Kimmy, some other Kimmy, I'm not going to say.
[00:26:36.660 --> 00:26:39.020]   I'm not going to say anything.
[00:26:39.020 --> 00:26:40.660]   But Kimmy that anyway.
[00:26:40.660 --> 00:26:41.900]   Okay.
[00:26:41.900 --> 00:26:42.900]   So I didn't get that.
[00:26:42.900 --> 00:26:44.260]   Is that must be a setting?
[00:26:44.260 --> 00:26:46.060]   I don't know.
[00:26:46.060 --> 00:26:47.420]   It's not a setting I ever made.
[00:26:47.420 --> 00:26:51.580]   Carson, did you put the beta on first or?
[00:26:51.580 --> 00:26:53.540]   And now Burke McQuinn's going.
[00:26:53.540 --> 00:26:58.300]   Hi, Burke.
[00:26:58.300 --> 00:26:59.300]   Hey, hello.
[00:26:59.300 --> 00:27:01.300]   Oh, I'm a sign up on him.
[00:27:01.300 --> 00:27:06.700]   Yeah, on my other phone, which I did have the beta on, it has Google News and the daily
[00:27:06.700 --> 00:27:10.420]   360, which I never ever, the New York Times, I never.
[00:27:10.420 --> 00:27:12.140]   Our official intelligence.
[00:27:12.140 --> 00:27:15.020]   Let's just start official for a reason.
[00:27:15.020 --> 00:27:16.020]   Okay.
[00:27:16.020 --> 00:27:19.620]   Well, no, Google is actually, I mean, some of their suggestions are a little weird, but
[00:27:19.620 --> 00:27:26.940]   like I find that their AI, for example, in Google Docs or what is it called?
[00:27:26.940 --> 00:27:28.340]   Cheats and all of that.
[00:27:28.340 --> 00:27:32.660]   It actually accurately recommends like, we open our show notes or this.
[00:27:32.660 --> 00:27:37.540]   I open my show notes for a twit every day around or every week at the same time.
[00:27:37.540 --> 00:27:40.260]   And it automatically puts that up at the top for me.
[00:27:40.260 --> 00:27:42.060]   Oh, if I'm in.
[00:27:42.060 --> 00:27:43.060]   Yeah.
[00:27:43.060 --> 00:27:44.060]   Oh, yeah, that's right.
[00:27:44.060 --> 00:27:45.060]   It doesn't mean to.
[00:27:45.060 --> 00:27:46.060]   Yes.
[00:27:46.060 --> 00:27:51.340]   And it was that this, this would be similar except now because it's got location from
[00:27:51.340 --> 00:27:56.780]   your phone, if you share it, you can just, I mean, like things like when I get in my
[00:27:56.780 --> 00:28:01.340]   car, for example, I always open maps.
[00:28:01.340 --> 00:28:05.260]   If it can start figuring that kind of stuff out, that's actually kind of valuable.
[00:28:05.260 --> 00:28:07.020]   I don't know if it's going to be, but.
[00:28:07.020 --> 00:28:12.660]   You know what the single use most useful thing to me is the new volume control.
[00:28:12.660 --> 00:28:13.660]   Yeah.
[00:28:13.660 --> 00:28:14.660]   Interface.
[00:28:14.660 --> 00:28:19.940]   When you press a volume up or down button, you get a little screen that pops up that
[00:28:19.940 --> 00:28:24.580]   shows you your volume.
[00:28:24.580 --> 00:28:30.980]   Don't touch Leah shows your volume shows you your vibration status, you know, silent,
[00:28:30.980 --> 00:28:34.340]   vibrating ringer, your music.
[00:28:34.340 --> 00:28:38.260]   So it makes a distinction between ring sounds and music sounds and then lets you with a
[00:28:38.260 --> 00:28:39.940]   touch go right to the settings.
[00:28:39.940 --> 00:28:40.940]   I think that's nice.
[00:28:40.940 --> 00:28:44.140]   But we did all by Android at IO.
[00:28:44.140 --> 00:28:46.020]   That's the thing we were all covalent over.
[00:28:46.020 --> 00:28:47.020]   Yeah.
[00:28:47.020 --> 00:28:48.020]   That's to me.
[00:28:48.020 --> 00:28:52.100]   That's like, isn't it funny how just little that and the swipe or the things I care about,
[00:28:52.100 --> 00:28:56.780]   but I'll be in a whole position for a screenshot.
[00:28:56.780 --> 00:28:58.260]   What is the new screenshot?
[00:28:58.260 --> 00:29:02.940]   So if you do the power button, yeah, and hold that down, it gives you three options,
[00:29:02.940 --> 00:29:04.940]   power off, restart and screenshot.
[00:29:04.940 --> 00:29:07.020]   Oh, well, that's okay.
[00:29:07.020 --> 00:29:10.820]   But I don't think I, I don't think I needed a whole but the only way you had to do it.
[00:29:10.820 --> 00:29:12.180]   No, no, no, the old way was hard.
[00:29:12.180 --> 00:29:15.340]   You had to press these at the same time, two buttons at the same time.
[00:29:15.340 --> 00:29:17.100]   That was kind of a pain in the butt.
[00:29:17.100 --> 00:29:19.940]   Five out of six times, I would screw that up.
[00:29:19.940 --> 00:29:22.100]   Yeah, I would just be like, professionally.
[00:29:22.100 --> 00:29:23.100]   Yeah.
[00:29:23.100 --> 00:29:24.100]   Yeah.
[00:29:24.100 --> 00:29:25.100]   Or the volume would go.
[00:29:25.100 --> 00:29:26.100]   Right.
[00:29:26.100 --> 00:29:27.100]   Yeah.
[00:29:27.100 --> 00:29:28.100]   So now it's a bit weird place to put it.
[00:29:28.100 --> 00:29:29.100]   How do I get a screenshot?
[00:29:29.100 --> 00:29:31.260]   Well, of course you get the power button, hold it down.
[00:29:31.260 --> 00:29:32.260]   Right.
[00:29:32.260 --> 00:29:33.260]   There's also.
[00:29:33.260 --> 00:29:36.660]   That's how it is on the iPad.
[00:29:36.660 --> 00:29:38.460]   Is that how you do it on the iPad?
[00:29:38.460 --> 00:29:40.220]   I don't remember anymore.
[00:29:40.220 --> 00:29:43.540]   No, I think the iPad is still home and power.
[00:29:43.540 --> 00:29:44.540]   Home and power.
[00:29:44.540 --> 00:29:45.540]   Okay.
[00:29:45.540 --> 00:29:46.540]   Yeah.
[00:29:46.540 --> 00:29:48.540]   Which is those dual button things are hard to do.
[00:29:48.540 --> 00:29:49.540]   Yeah.
[00:29:49.540 --> 00:29:50.540]   All right.
[00:29:50.540 --> 00:29:54.460]   So artificial intelligence, I like artificial intelligence.
[00:29:54.460 --> 00:29:59.500]   This is the same artificial intelligence that's going to save us from the robust spam and
[00:29:59.500 --> 00:30:01.260]   hatred and everything else.
[00:30:01.260 --> 00:30:02.260]   Yeah.
[00:30:02.260 --> 00:30:04.220]   AI is helping us with spam.
[00:30:04.220 --> 00:30:11.460]   It is not helping us with hatred as much because you have the training data and people adapt
[00:30:11.460 --> 00:30:12.620]   very well.
[00:30:12.620 --> 00:30:17.100]   We, this is, again, I will say, look, we call it a lot of things AI.
[00:30:17.100 --> 00:30:24.620]   True AI involves applying neural networks to lots of data and having it understand something.
[00:30:24.620 --> 00:30:25.620]   Right.
[00:30:25.620 --> 00:30:26.940]   So that's one version.
[00:30:26.940 --> 00:30:29.900]   There's also other types of AI and training.
[00:30:29.900 --> 00:30:36.740]   But when we start talking about all of this, we have to remember that they're learning
[00:30:36.740 --> 00:30:39.180]   based on the information we've given them.
[00:30:39.180 --> 00:30:45.180]   So unless we're talking about reinforcement learning and then they're learning based on
[00:30:45.180 --> 00:30:47.580]   the rewards we're giving them.
[00:30:47.580 --> 00:30:51.340]   And so we can't expect too much from this.
[00:30:51.340 --> 00:30:53.540]   It's not going to be magic.
[00:30:53.540 --> 00:30:59.860]   So if you want to sign up for digital wellbeing, it's not in there yet.
[00:30:59.860 --> 00:31:04.500]   But you can get in the beta by going.
[00:31:04.500 --> 00:31:06.580]   That's kind of creeped out by that.
[00:31:06.580 --> 00:31:09.740]   By digital wellbeing or by the fact that you had to do the beta or what?
[00:31:09.740 --> 00:31:12.860]   No, by the concept of digital wellbeing.
[00:31:12.860 --> 00:31:14.500]   I'm creeped out about it.
[00:31:14.500 --> 00:31:15.500]   Really?
[00:31:15.500 --> 00:31:16.500]   Yeah.
[00:31:16.500 --> 00:31:19.340]   I'd like some of the things.
[00:31:19.340 --> 00:31:25.180]   It's less nanny state and more like it feels duplicitous to give them all this information
[00:31:25.180 --> 00:31:29.100]   and like have them decide what my digital wellbeing is going to look like.
[00:31:29.100 --> 00:31:31.780]   Is it notifications that are freaking me out?
[00:31:31.780 --> 00:31:35.420]   I mean, I just kind of look at this.
[00:31:35.420 --> 00:31:38.380]   So here's what I think.
[00:31:38.380 --> 00:31:43.740]   I think that it's interesting because of course all these people are doing it and everybody's
[00:31:43.740 --> 00:31:44.820]   doing it now.
[00:31:44.820 --> 00:31:48.620]   Not only is iOS and Android doing it, but YouTube's doing it.
[00:31:48.620 --> 00:31:50.860]   Instagram is doing it.
[00:31:50.860 --> 00:31:53.860]   They're all putting in features that say use this less time.
[00:31:53.860 --> 00:31:55.820]   How much I use it.
[00:31:55.820 --> 00:32:00.060]   I'm going to sleep now, so do some things to make it less attractive.
[00:32:00.060 --> 00:32:03.660]   All of this runs counter to their business model, which is of course the more you use
[00:32:03.660 --> 00:32:05.940]   it, the more money they make.
[00:32:05.940 --> 00:32:07.740]   So you might say, well, why are they doing this?
[00:32:07.740 --> 00:32:09.380]   Well, it's obvious why they're doing it.
[00:32:09.380 --> 00:32:18.340]   They're doing it to put the critics at mind at ease while fully knowing nobody's going
[00:32:18.340 --> 00:32:22.940]   to do this, that it's annoying to everybody.
[00:32:22.940 --> 00:32:27.020]   And so it has this kind of great benefit of it looks like they care.
[00:32:27.020 --> 00:32:32.980]   It puts Congress and other critics at ease and it costs them nothing because you're not
[00:32:32.980 --> 00:32:33.980]   going to do it.
[00:32:33.980 --> 00:32:35.300]   That's my opinion.
[00:32:35.300 --> 00:32:37.100]   I agree.
[00:32:37.100 --> 00:32:45.660]   I think Google is very aware that we're trying to move beyond screens.
[00:32:45.660 --> 00:32:52.180]   And so I would say that this is also in preparation for understanding how to deliver information
[00:32:52.180 --> 00:32:53.660]   through other mediums.
[00:32:53.660 --> 00:32:58.860]   So through maybe voice, maybe speakers, maybe hearables.
[00:32:58.860 --> 00:33:04.220]   So I would look at it more broadly as gathering information about what stresses people out,
[00:33:04.220 --> 00:33:06.740]   what kind of information should be on the phone.
[00:33:06.740 --> 00:33:11.060]   So I would look at this almost as a data grab in some ways.
[00:33:11.060 --> 00:33:12.900]   Isn't that funny?
[00:33:12.900 --> 00:33:18.100]   So now there's three good reasons to do it.
[00:33:18.100 --> 00:33:23.660]   Yeah, I mean, when you see Instagram do something that will to design to reduce your usage of
[00:33:23.660 --> 00:33:29.820]   Instagram, either they're under such intense heat that they have to do something or more
[00:33:29.820 --> 00:33:35.140]   likely their research shows and my informal research would agree, nobody's going to do
[00:33:35.140 --> 00:33:36.140]   that.
[00:33:36.140 --> 00:33:38.140]   I tried it on the iOS I was doing.
[00:33:38.140 --> 00:33:39.740]   I'm doing the iOS 12 beta.
[00:33:39.740 --> 00:33:45.180]   I turned it on and it was so annoying because you would be, you know, you'd be, you wake
[00:33:45.180 --> 00:33:47.540]   up in the little night and you want to play a little Pokemon go.
[00:33:47.540 --> 00:33:53.780]   Who as one does and it'd say you've already done too much of that today or you should
[00:33:53.780 --> 00:33:58.100]   be sleeping and then right under it, there's a button that says, or you could just ignore
[00:33:58.100 --> 00:34:00.260]   this and keep on going.
[00:34:00.260 --> 00:34:03.100]   And then when you hit that, it says, you want me to remind you about this at all?
[00:34:03.100 --> 00:34:05.660]   And you say, no, never, never again.
[00:34:05.660 --> 00:34:10.340]   And I think that this is, that's exact, my behavior is exactly what people are going
[00:34:10.340 --> 00:34:11.340]   to do.
[00:34:11.340 --> 00:34:12.340]   They're going to do it.
[00:34:12.340 --> 00:34:13.340]   I think it's all.
[00:34:13.340 --> 00:34:14.340]   They're going to be annoyed and they're going to turn it off.
[00:34:14.340 --> 00:34:15.340]   It's ask covering.
[00:34:15.340 --> 00:34:16.340]   It's ask covering.
[00:34:16.340 --> 00:34:21.340]   The lawyers who insist that now escalators have to have instructions on how to walk.
[00:34:21.340 --> 00:34:26.620]   Lisa always laughs when we open a bottle and you know, that's got one of those desiccant
[00:34:26.620 --> 00:34:33.900]   packets and it says, do not eat or, you know, our hot tub won't go hotter than 104 degrees
[00:34:33.900 --> 00:34:38.660]   because the state of California has deemed it dangerous to have 105 degree hot tub,
[00:34:38.660 --> 00:34:40.500]   which is my preferred temperature.
[00:34:40.500 --> 00:34:44.740]   Even though I can make my bathtub 110 degrees if I want.
[00:34:44.740 --> 00:34:47.540]   Have you hacked the hot tub?
[00:34:47.540 --> 00:34:50.980]   No, I asked, you know, I went to the hot tub guys, I said, well, how do I hack this?
[00:34:50.980 --> 00:34:53.380]   He said, oh, you can't hack it.
[00:34:53.380 --> 00:34:59.340]   It's, but I did just buy an electric bike, which has also been throttled to 20 miles an
[00:34:59.340 --> 00:35:00.340]   hour.
[00:35:00.340 --> 00:35:03.820]   And I have a, I know, like, come on.
[00:35:03.820 --> 00:35:05.460]   So, but that's apparently fairly easy.
[00:35:05.460 --> 00:35:06.460]   Well, like did you get?
[00:35:06.460 --> 00:35:07.460]   Well, you want to see?
[00:35:07.460 --> 00:35:09.980]   I've shown everybody else has seen it already.
[00:35:09.980 --> 00:35:10.980]   I know.
[00:35:10.980 --> 00:35:11.980]   I figured it.
[00:35:11.980 --> 00:35:14.860]   It's a by electric bike with vestigial pedals.
[00:35:14.860 --> 00:35:18.580]   In other words, they don't really, they have to put pedals on.
[00:35:18.580 --> 00:35:23.940]   Otherwise, it's not an electric bike, but you're not expected to pedal at all.
[00:35:23.940 --> 00:35:26.620]   Oh, I thought the idea was it was helping you.
[00:35:26.620 --> 00:35:27.620]   Yeah.
[00:35:27.620 --> 00:35:28.620]   Yeah.
[00:35:28.620 --> 00:35:29.620]   That's the idea.
[00:35:29.620 --> 00:35:30.620]   Yeah.
[00:35:30.620 --> 00:35:31.620]   Except.
[00:35:31.620 --> 00:35:33.220]   Except sure that's the idea.
[00:35:33.220 --> 00:35:34.220]   Yeah.
[00:35:34.220 --> 00:35:38.060]   If you want a pedal, you can, but you don't have to.
[00:35:38.060 --> 00:35:41.940]   And by putting pedals on there and putting a throttle on there that is limited to the
[00:35:41.940 --> 00:35:44.980]   20 miles an hour, you don't have to have a license.
[00:35:44.980 --> 00:35:46.500]   You don't have to get permission.
[00:35:46.500 --> 00:35:48.340]   You can, you know, it's a bicycle.
[00:35:48.340 --> 00:35:49.340]   It's a bicycle.
[00:35:49.340 --> 00:35:50.340]   He's got pedals.
[00:35:50.340 --> 00:35:51.340]   It's a bicycle.
[00:35:51.340 --> 00:35:52.700]   Anyway, doesn't that look cool?
[00:35:52.700 --> 00:35:58.060]   It looks like a, looks like a one of those, looks like the motorcycle Steve McQueen road
[00:35:58.060 --> 00:35:59.540]   in the great escape.
[00:35:59.540 --> 00:36:02.260]   Looks like when it like an Indian or some of those old fashioned motorcycles.
[00:36:02.260 --> 00:36:03.260]   Yeah.
[00:36:03.260 --> 00:36:04.260]   Isn't that cool?
[00:36:04.260 --> 00:36:05.260]   Yeah.
[00:36:05.260 --> 00:36:08.740]   Some of it, Burke said, Burke's saying he can hack my hot tub.
[00:36:08.740 --> 00:36:11.300]   So maybe that's why he was calling.
[00:36:11.300 --> 00:36:14.860]   Because apparently hacked time and space as well.
[00:36:14.860 --> 00:36:19.500]   If you have a Pixel 2, you can get Android Pie right now, right?
[00:36:19.500 --> 00:36:22.140]   You just, you just update and you should be getting it soon.
[00:36:22.140 --> 00:36:28.300]   If you have an essential phone, their Android 9 update is rolling out.
[00:36:28.300 --> 00:36:29.300]   Oh, yeah.
[00:36:29.300 --> 00:36:31.220]   A non-Google phone is getting it.
[00:36:31.220 --> 00:36:32.220]   Yeah.
[00:36:32.220 --> 00:36:33.220]   Well, that's what happened with the public beta too.
[00:36:33.220 --> 00:36:36.260]   There were a number of phones getting it.
[00:36:36.260 --> 00:36:38.180]   There are only a few essential phones out there.
[00:36:38.180 --> 00:36:39.180]   So, you know, why not?
[00:36:39.180 --> 00:36:40.180]   Easy enough.
[00:36:40.180 --> 00:36:41.980]   I'll give you something.
[00:36:41.980 --> 00:36:43.580]   Now, let me ask you.
[00:36:43.580 --> 00:36:49.420]   Oh, I was also saying you can get the digital well-being now if you go to it in the app store
[00:36:49.420 --> 00:36:51.140]   and sign up for the beta.
[00:36:51.140 --> 00:36:55.660]   And then you'll wait for your, yeah, request an invitation and you'll wait for your email.
[00:36:55.660 --> 00:36:58.180]   I don't think I've gotten mine yet.
[00:36:58.180 --> 00:37:00.140]   Because I really want it.
[00:37:00.140 --> 00:37:03.340]   Because then I can turn it off sooner.
[00:37:03.340 --> 00:37:07.140]   Let me just see if I have it yet.
[00:37:07.140 --> 00:37:09.540]   Sometimes it's, I think it would be nice.
[00:37:09.540 --> 00:37:12.900]   Like it, again, there are very few times when I would be excited about it.
[00:37:12.900 --> 00:37:17.540]   But I would kind of like, like, as I'm standing there in like a day's at 11 o'clock at night,
[00:37:17.540 --> 00:37:23.300]   just scrolling through, you know, Twitter or the New York Times or whatever.
[00:37:23.300 --> 00:37:25.620]   Just be like, "Hey, why don't you go to bed now?"
[00:37:25.620 --> 00:37:26.620]   Yeah.
[00:37:26.620 --> 00:37:27.620]   My Fitbit actually does that.
[00:37:27.620 --> 00:37:29.780]   And I'm like, "Yeah, you know what Fitbit?
[00:37:29.780 --> 00:37:30.780]   Good plan."
[00:37:30.780 --> 00:37:32.380]   I get a lot of those.
[00:37:32.380 --> 00:37:33.380]   A lot of sorts.
[00:37:33.380 --> 00:37:36.060]   I'm getting angry and be awake for two hours.
[00:37:36.060 --> 00:37:38.060]   It's just you and me.
[00:37:38.060 --> 00:37:42.020]   Jeff, we just go like, "Yeah, well, we're anti-authoritarian."
[00:37:42.020 --> 00:37:43.020]   Yeah.
[00:37:43.020 --> 00:37:44.820]   "Some people like to be told what to do.
[00:37:44.820 --> 00:37:46.260]   We do not."
[00:37:46.260 --> 00:37:52.660]   In fact, if you tell us to do something, we're more likely to do the opposite.
[00:37:52.660 --> 00:37:53.660]   Just a little...
[00:37:53.660 --> 00:37:54.660]   Even if it hurts us, yeah.
[00:37:54.660 --> 00:37:56.420]   Even if it's bad.
[00:37:56.420 --> 00:37:57.820]   Yeah.
[00:37:57.820 --> 00:38:02.660]   So, I have not gotten the invitation.
[00:38:02.660 --> 00:38:04.300]   I was hoping by the show I would have.
[00:38:04.300 --> 00:38:06.180]   You go to sign up for the digital webbing.
[00:38:06.180 --> 00:38:07.300]   Actually, you don't do it on your phone.
[00:38:07.300 --> 00:38:08.980]   You do it on the web.
[00:38:08.980 --> 00:38:10.620]   And you can enroll in the beta.
[00:38:10.620 --> 00:38:11.620]   Try it.
[00:38:11.620 --> 00:38:13.780]   Send the email and some...
[00:38:13.780 --> 00:38:15.860]   What do you look up?
[00:38:15.860 --> 00:38:18.060]   Where did I find this?
[00:38:18.060 --> 00:38:19.380]   It's at android.com.
[00:38:19.380 --> 00:38:23.500]   Let me see if you go to...
[00:38:23.500 --> 00:38:26.860]   I think maybe I wonder if you can go from the front page, find it.
[00:38:26.860 --> 00:38:34.260]   Go to learn more about Pi and then tailor to you, blah, blah, blah, just less.
[00:38:34.260 --> 00:38:37.620]   Adaptive battery, adaptive brightness.
[00:38:37.620 --> 00:38:38.620]   Adapt for this.
[00:38:38.620 --> 00:38:40.220]   Adapt for that.
[00:38:40.220 --> 00:38:43.060]   Getting around just got easier.
[00:38:43.060 --> 00:38:44.300]   Digital well-being.
[00:38:44.300 --> 00:38:47.140]   Great technology should help, not distract.
[00:38:47.140 --> 00:38:50.860]   Doesn't that family look really tired like they were up all night on their phones?
[00:38:50.860 --> 00:38:54.060]   Yeah, they've been arguing and fighting and they're trying to get along now, but they're
[00:38:54.060 --> 00:38:55.060]   about to get to work.
[00:38:55.060 --> 00:38:59.780]   And mom, if you keep feeding the kids these simple carbohydrates like orange juice and
[00:38:59.780 --> 00:39:02.380]   Cheerios, of course they're going to be...
[00:39:02.380 --> 00:39:03.380]   Wait, wait.
[00:39:03.380 --> 00:39:04.380]   What is it, mom, for that?
[00:39:04.380 --> 00:39:05.380]   The dad could have given them that.
[00:39:05.380 --> 00:39:06.380]   No, the dad's smart.
[00:39:06.380 --> 00:39:08.340]   He's just drinking coffee.
[00:39:08.340 --> 00:39:09.340]   He's drinking black coffee.
[00:39:09.340 --> 00:39:10.340]   She's just cereal too.
[00:39:10.340 --> 00:39:11.340]   She's in this...
[00:39:11.340 --> 00:39:13.060]   There are the three of them eating cereal.
[00:39:13.060 --> 00:39:16.500]   Maybe he bought it at the grocery store and, you know, that's all I had.
[00:39:16.500 --> 00:39:19.620]   And you got dummy berries, which are probably wax.
[00:39:19.620 --> 00:39:21.540]   And maybe dad's having that toast, maybe not.
[00:39:21.540 --> 00:39:23.700]   It's unclear.
[00:39:23.700 --> 00:39:27.180]   Somebody's not at the table is having milk.
[00:39:27.180 --> 00:39:28.780]   So maybe the photographer.
[00:39:28.780 --> 00:39:29.780]   I don't know.
[00:39:29.780 --> 00:39:32.140]   Why is there a glass of milk just sitting out in the middle of nowhere?
[00:39:32.140 --> 00:39:33.780]   What's going on there?
[00:39:33.780 --> 00:39:34.780]   Is that for Elijah?
[00:39:34.780 --> 00:39:35.780]   All right.
[00:39:35.780 --> 00:39:36.780]   So...
[00:39:36.780 --> 00:39:37.780]   That's for the cereal.
[00:39:37.780 --> 00:39:38.780]   Yeah.
[00:39:38.780 --> 00:39:39.780]   Oh, is that...
[00:39:39.780 --> 00:39:40.780]   Oh, hey, okay.
[00:39:40.780 --> 00:39:41.780]   A little tip to dad.
[00:39:41.780 --> 00:39:42.820]   Get a pitcher.
[00:39:42.820 --> 00:39:44.620]   You can't pour milk from a glass.
[00:39:44.620 --> 00:39:45.620]   Okay?
[00:39:45.620 --> 00:39:46.620]   Just a little tip.
[00:39:46.620 --> 00:39:47.620]   Sure.
[00:39:47.620 --> 00:39:48.620]   Uh-huh.
[00:39:48.620 --> 00:39:49.620]   I'm trying to find...
[00:39:49.620 --> 00:39:50.620]   I just did it.
[00:39:50.620 --> 00:39:51.620]   I just did it.
[00:39:51.620 --> 00:39:52.620]   I got to it.
[00:39:52.620 --> 00:39:53.620]   Okay.
[00:39:53.620 --> 00:39:54.620]   There it is.
[00:39:54.620 --> 00:39:55.620]   Have a pixel.
[00:39:55.620 --> 00:39:56.620]   On the...
[00:39:56.620 --> 00:39:57.620]   By the way, do you like that nice wood grain?
[00:39:57.620 --> 00:40:01.740]   That's exactly the same wood as used in the back of the Lenovo Smart Home.
[00:40:01.740 --> 00:40:02.740]   Makes me feel calm.
[00:40:02.740 --> 00:40:03.740]   This is the way.
[00:40:03.740 --> 00:40:04.900]   So you know it's already working.
[00:40:04.900 --> 00:40:05.900]   It's Scandinavian.
[00:40:05.900 --> 00:40:06.900]   Yeah.
[00:40:06.900 --> 00:40:07.900]   That's that Ikea fake.
[00:40:07.900 --> 00:40:09.580]   I'm calm when I go to work here.
[00:40:09.580 --> 00:40:10.580]   Okay.
[00:40:10.580 --> 00:40:11.580]   Now try...
[00:40:11.580 --> 00:40:13.220]   You can try digital well-being beta now.
[00:40:13.220 --> 00:40:19.660]   Click sign up and you'll get this form and then they'll ignore you.
[00:40:19.660 --> 00:40:20.660]   Or not.
[00:40:20.660 --> 00:40:23.580]   So are you happy with pie?
[00:40:23.580 --> 00:40:25.420]   Is it going to be desserts and start with Q?
[00:40:25.420 --> 00:40:26.420]   Yeah.
[00:40:26.420 --> 00:40:27.420]   Pie is...
[00:40:27.420 --> 00:40:28.420]   I like pie.
[00:40:28.420 --> 00:40:29.420]   What do I do with Q?
[00:40:29.420 --> 00:40:30.420]   I had to make a pie.
[00:40:30.420 --> 00:40:31.420]   They had to.
[00:40:31.420 --> 00:40:32.420]   Miriam...
[00:40:32.420 --> 00:40:34.420]   Miriam Schwar suggested quiche.
[00:40:34.420 --> 00:40:37.700]   That's not a dessert.
[00:40:37.700 --> 00:40:38.700]   That's begin with Q.
[00:40:38.700 --> 00:40:39.700]   It does begin with Q.
[00:40:39.700 --> 00:40:40.700]   It does begin with Q.
[00:40:40.700 --> 00:40:41.700]   It does begin with Q.
[00:40:41.700 --> 00:40:44.340]   But quince jam?
[00:40:44.340 --> 00:40:45.340]   Quince ew.
[00:40:45.340 --> 00:40:46.340]   Yeah.
[00:40:46.340 --> 00:40:47.340]   There's...
[00:40:47.340 --> 00:40:48.340]   Is there like a...
[00:40:48.340 --> 00:40:49.340]   I don't know.
[00:40:49.340 --> 00:40:51.860]   Something with quarters in it that...
[00:40:51.860 --> 00:40:52.860]   Okay.
[00:40:52.860 --> 00:40:53.860]   Sito.
[00:40:53.860 --> 00:40:55.020]   You might like that as a case.
[00:40:55.020 --> 00:40:56.020]   K so.
[00:40:56.020 --> 00:40:57.020]   K so.
[00:40:57.020 --> 00:40:58.660]   She's filled pastry pastry twist.
[00:40:58.660 --> 00:40:59.660]   There we go.
[00:40:59.660 --> 00:41:00.660]   Winter dessert queso.
[00:41:00.660 --> 00:41:01.660]   I have that.
[00:41:01.660 --> 00:41:02.660]   Que sito.
[00:41:02.660 --> 00:41:08.980]   Oddly enough, they don't have quince jam in the suggestions from the Verge.
[00:41:08.980 --> 00:41:09.980]   Obviously...
[00:41:09.980 --> 00:41:12.140]   What do they have?
[00:41:12.140 --> 00:41:13.900]   Queen of puddings.
[00:41:13.900 --> 00:41:14.900]   Queen of puddings.
[00:41:14.900 --> 00:41:15.900]   That's a broad color.
[00:41:15.900 --> 00:41:19.140]   I don't think Android Q, queen of puddings.
[00:41:19.140 --> 00:41:21.660]   That's a very bad lerman kind of a...
[00:41:21.660 --> 00:41:23.100]   I don't think that's going to make it.
[00:41:23.100 --> 00:41:24.100]   None of these...
[00:41:24.100 --> 00:41:25.100]   I get quarks.
[00:41:25.100 --> 00:41:26.100]   That's...
[00:41:26.100 --> 00:41:28.780]   Oh, quarks apparently is not a sight to go to.
[00:41:28.780 --> 00:41:30.260]   It's a forbidden...
[00:41:30.260 --> 00:41:34.740]   For a boughton sight.
[00:41:34.740 --> 00:41:35.740]   So...
[00:41:35.740 --> 00:41:39.980]   Pi, I thought Pi was a good compromise.
[00:41:39.980 --> 00:41:42.620]   It's kind of short.
[00:41:42.620 --> 00:41:43.620]   All the other ones have...
[00:41:43.620 --> 00:41:44.620]   It's a pie joke.
[00:41:44.620 --> 00:41:45.620]   A lot of pie jokes at some point.
[00:41:45.620 --> 00:41:46.620]   Yeah, yeah jokes.
[00:41:46.620 --> 00:41:50.660]   Pi and the nice thing is now we're going to have Pi every Tuesday on L.M.
[00:41:50.660 --> 00:41:51.660]   Android.
[00:41:51.660 --> 00:41:55.020]   They had Oreo Pi yesterday.
[00:41:55.020 --> 00:41:56.860]   That was awesome.
[00:41:56.860 --> 00:41:58.940]   Very inspired.
[00:41:58.940 --> 00:42:00.940]   It's a transitional pie.
[00:42:00.940 --> 00:42:02.940]   A transitional pie.
[00:42:02.940 --> 00:42:05.820]   A bridge building pie.
[00:42:05.820 --> 00:42:15.340]   So did you see the article in the Verge about the magic leap?
[00:42:15.340 --> 00:42:19.260]   I tried magic leap and saw.
[00:42:19.260 --> 00:42:21.260]   The price of my generation.
[00:42:21.260 --> 00:42:22.260]   No.
[00:42:22.260 --> 00:42:26.100]   Adi Robertson, she's saying I tried magic leap and saw a flawed glimpse of mixed reality's
[00:42:26.100 --> 00:42:27.260]   amazing potential.
[00:42:27.260 --> 00:42:30.900]   Yeah, it's almost $3,000.
[00:42:30.900 --> 00:42:31.900]   But it's not...
[00:42:31.900 --> 00:42:32.900]   Well, I'm sorry.
[00:42:32.900 --> 00:42:33.900]   2300.
[00:42:33.900 --> 00:42:35.540]   It's the creator edition.
[00:42:35.540 --> 00:42:37.020]   That's a long-standing tradition.
[00:42:37.020 --> 00:42:38.260]   Google Glass was $1,500.
[00:42:38.260 --> 00:42:42.100]   It got to remind me what you think you very much.
[00:42:42.100 --> 00:42:45.900]   This looks better than Google Glass, sort of.
[00:42:45.900 --> 00:42:47.420]   Well, sort of.
[00:42:47.420 --> 00:42:49.620]   Doesn't work a lot better than HoloLens.
[00:42:49.620 --> 00:42:50.820]   Well, maybe it does a little bit.
[00:42:50.820 --> 00:42:56.220]   Magic leap is supposedly building goggles that can change people's perception of reality.
[00:42:56.220 --> 00:42:58.580]   It's Adi.
[00:42:58.580 --> 00:43:00.260]   And she got to try it.
[00:43:00.260 --> 00:43:04.060]   She said, "Yeah, it's augmented reality.
[00:43:04.060 --> 00:43:07.460]   It's better than what you'd get with an iPhone, but it's not perfect.
[00:43:07.460 --> 00:43:11.660]   You do carry this little puck on your belt that is the processor."
[00:43:11.660 --> 00:43:16.100]   Well, relatively compared to the big computer.
[00:43:16.100 --> 00:43:17.100]   That's not that computer.
[00:43:17.100 --> 00:43:18.100]   Yeah.
[00:43:18.100 --> 00:43:19.100]   True.
[00:43:19.100 --> 00:43:20.460]   And that, by the way, that button, that's a pause button.
[00:43:20.460 --> 00:43:22.660]   They call it reality.
[00:43:22.660 --> 00:43:27.060]   So when you press it, you go back to reality.
[00:43:27.060 --> 00:43:33.980]   That is the traditional VR style controller that you would carry on your wrist.
[00:43:33.980 --> 00:43:39.580]   What's interesting about this is it looks more like spectacles, and that's what they
[00:43:39.580 --> 00:43:41.740]   were going for with the round.
[00:43:41.740 --> 00:43:47.100]   But it doesn't accommodate lenses underneath it, but you can buy prescription lenses that
[00:43:47.100 --> 00:43:49.380]   are magnetic that snap in.
[00:43:49.380 --> 00:43:53.060]   Can I take my Google Glass lenses and repurpose them, please?
[00:43:53.060 --> 00:43:54.060]   Oh, that's right.
[00:43:54.060 --> 00:43:55.260]   And I bought and paid for them?
[00:43:55.260 --> 00:43:59.860]   I think, Jeff, from now on, you should wear your Google Glasses.
[00:43:59.860 --> 00:44:02.300]   You don't have to charge them up or use it.
[00:44:02.300 --> 00:44:04.020]   Can you still run apps on them?
[00:44:04.020 --> 00:44:05.020]   No idea.
[00:44:05.020 --> 00:44:06.020]   Or is it a brick device?
[00:44:06.020 --> 00:44:08.980]   Jeff, help in the name of science.
[00:44:08.980 --> 00:44:09.980]   It hurts too much.
[00:44:09.980 --> 00:44:10.980]   It hurts too much.
[00:44:10.980 --> 00:44:11.980]   It's just a focus heart.
[00:44:11.980 --> 00:44:13.540]   Hey, I bought a pair and I have never even gotten to...
[00:44:13.540 --> 00:44:14.820]   Who has my...
[00:44:14.820 --> 00:44:16.740]   Does Jason have those still?
[00:44:16.740 --> 00:44:19.340]   Jason, can I have my glasses back now?
[00:44:19.340 --> 00:44:20.340]   For the museum.
[00:44:20.340 --> 00:44:21.340]   For the museum?
[00:44:21.340 --> 00:44:23.340]   Actually, I have to take it...
[00:44:23.340 --> 00:44:25.380]   I have the Museum of Dead Technology in my office.
[00:44:25.380 --> 00:44:27.340]   I need to take them in for that.
[00:44:27.340 --> 00:44:28.340]   Exactly.
[00:44:28.340 --> 00:44:30.180]   So would you guys buy this?
[00:44:30.180 --> 00:44:31.180]   Let's ask.
[00:44:31.180 --> 00:44:32.180]   I thought about it.
[00:44:32.180 --> 00:44:33.180]   I thought about it.
[00:44:33.180 --> 00:44:34.180]   Well, of course you did, Leo.
[00:44:34.180 --> 00:44:38.180]   I buy stuff that's that price because I need to...
[00:44:38.180 --> 00:44:40.540]   It's our job to look at this stuff.
[00:44:40.540 --> 00:44:42.460]   Even I can't...
[00:44:42.460 --> 00:44:45.620]   I just don't think this is going to be important.
[00:44:45.620 --> 00:44:46.620]   Honestly.
[00:44:46.620 --> 00:44:47.620]   VR?
[00:44:47.620 --> 00:44:48.620]   VR?
[00:44:48.620 --> 00:44:50.740]   We bought Google Glass.
[00:44:50.740 --> 00:44:51.740]   I didn't buy all of this.
[00:44:51.740 --> 00:44:52.740]   Or Magic Blue.
[00:44:52.740 --> 00:44:53.740]   This is the magic.
[00:44:53.740 --> 00:44:54.740]   HoloLens is actually really interesting.
[00:44:54.740 --> 00:44:56.740]   I really like the HoloLens experience.
[00:44:56.740 --> 00:44:57.740]   It's very...
[00:44:57.740 --> 00:45:00.740]   But it's very limited and Microsoft has made no progress.
[00:45:00.740 --> 00:45:03.460]   Zero, since they released it.
[00:45:03.460 --> 00:45:04.940]   This is how it looks.
[00:45:04.940 --> 00:45:06.940]   What do you think?
[00:45:06.940 --> 00:45:10.380]   Would you think this is you?
[00:45:10.380 --> 00:45:11.380]   It's certainly not me.
[00:45:11.380 --> 00:45:12.380]   I will not.
[00:45:12.380 --> 00:45:14.620]   I can't walk around in the world without reality.
[00:45:14.620 --> 00:45:19.620]   But I would imagine it would be less disturbing than being blocked off in the world.
[00:45:19.620 --> 00:45:23.780]   Yeah, because you are looking at the world through this, but it's stuff superimposed.
[00:45:23.780 --> 00:45:25.740]   And you could move for games that would be amazing.
[00:45:25.740 --> 00:45:28.060]   You could move through a space.
[00:45:28.060 --> 00:45:29.780]   Are you trying to talk me into getting this?
[00:45:29.780 --> 00:45:30.780]   Oh, yeah, you have to.
[00:45:30.780 --> 00:45:33.780]   Do we want to see you in it?
[00:45:33.780 --> 00:45:35.780]   I don't know.
[00:45:35.780 --> 00:45:37.780]   Oh, I didn't see the back by.
[00:45:37.780 --> 00:45:39.620]   Oh, that's serious too.
[00:45:39.620 --> 00:45:40.620]   Yeah.
[00:45:40.620 --> 00:45:42.060]   She said it was pretty comfortable.
[00:45:42.060 --> 00:45:45.140]   Again, this is a prototype.
[00:45:45.140 --> 00:45:52.420]   I mean, not a prototype exactly, but it's not the finished product.
[00:45:52.420 --> 00:45:59.180]   So let me read you Addy's description of the experience.
[00:45:59.180 --> 00:46:05.140]   By the way, Magic Leap is the darling of Silicon Valley.
[00:46:05.140 --> 00:46:07.420]   They've raised $2.3 billion.
[00:46:07.420 --> 00:46:09.180]   First investor was Google.
[00:46:09.180 --> 00:46:10.940]   JP Morgan's put in money.
[00:46:10.940 --> 00:46:18.420]   It was created by Roni Abovitz, who was originally creating a movie and then said, oh, well,
[00:46:18.420 --> 00:46:25.780]   in order for this to work, we need to create this entire augmented reality thing.
[00:46:25.780 --> 00:46:31.580]   He announced Magic Leap in 2012 with a TEDx talk at a rights in which he donned a full
[00:46:31.580 --> 00:46:34.060]   spacesuit and spoke for 30 seconds.
[00:46:34.060 --> 00:46:38.540]   Today he won't even confirm it was him in the spacesuit.
[00:46:38.540 --> 00:46:41.100]   Let's see.
[00:46:41.100 --> 00:46:42.700]   At some point, Robertson has a description.
[00:46:42.700 --> 00:46:47.420]   Oh, here it is.
[00:46:47.420 --> 00:46:53.180]   So she put the Magic Leap on.
[00:46:53.180 --> 00:46:56.500]   When you write about augmented reality headsets, you're supposed to start by describing something
[00:46:56.500 --> 00:47:03.860]   impossible, like a pastel dinosaur stomping its feet in a quiet office space in Florida.
[00:47:03.860 --> 00:47:04.860]   That's where Magic Leap is.
[00:47:04.860 --> 00:47:09.620]   This dinosaur is made of fist-sized blocks that look like candy, and the office belongs
[00:47:09.620 --> 00:47:10.620]   to Magic Leap.
[00:47:10.620 --> 00:47:15.260]   A mysterious start that's been working near total secrecy for seven years.
[00:47:15.260 --> 00:47:17.620]   I should clarify, the dinosaur also isn't real.
[00:47:17.620 --> 00:47:23.020]   It exists only in the lenses of the Magic Leap one, a pair of goggles, et cetera, et cetera.
[00:47:23.020 --> 00:47:28.260]   In reality, the dinosaur I see through the Magic Leap one looks genuinely three-dimensional,
[00:47:28.260 --> 00:47:31.620]   but pieces start getting cut off when I approach it.
[00:47:31.620 --> 00:47:34.940]   When a man walks behind it, I can see him slightly.
[00:47:34.940 --> 00:47:38.340]   My headset doesn't account for relative distance, so it's impossible for somebody to walk in
[00:47:38.340 --> 00:47:42.500]   between me and the dinosaur no matter how close they are.
[00:47:42.500 --> 00:47:46.980]   It's a wonderful, fascinating illusion, maybe the best I've seen in one of these headsets
[00:47:46.980 --> 00:47:50.980]   and far cooler than watching an AR model through an iPhone screen, but it's not the
[00:47:50.980 --> 00:47:56.300]   kind of revolutionary or downright magical advance that Magic Leap has teased for years.
[00:47:56.300 --> 00:47:59.300]   This is the first time a lot of people have seen Magic Leap.
[00:47:59.300 --> 00:48:03.180]   Remember, was it Steven Levy, I think, who went?
[00:48:03.180 --> 00:48:04.180]   No.
[00:48:04.180 --> 00:48:09.300]   Anyway, people have gone and described it.
[00:48:09.300 --> 00:48:12.180]   In Magic Leap, it's probably the best I've ever been allowed to talk about it.
[00:48:12.180 --> 00:48:16.660]   This is the first time we've really seen behind the curtain.
[00:48:16.660 --> 00:48:18.620]   But you really can't show it.
[00:48:18.620 --> 00:48:21.540]   That's going to be the first time to sell this stuff.
[00:48:21.540 --> 00:48:23.060]   You can't really...
[00:48:23.060 --> 00:48:28.740]   Best buy is going to have some that you can go try on.
[00:48:28.740 --> 00:48:31.580]   Best buy?
[00:48:31.580 --> 00:48:33.580]   Someone talks about it.
[00:48:33.580 --> 00:48:36.700]   Best buy is no marketing space, so it makes sense.
[00:48:36.700 --> 00:48:37.700]   Yeah.
[00:48:37.700 --> 00:48:42.140]   I'm trying to find it in the article because I don't remember what retailer it is.
[00:48:42.140 --> 00:48:43.140]   Oh, AT&T.
[00:48:43.140 --> 00:48:45.380]   AT&T is already committed.
[00:48:45.380 --> 00:48:48.900]   Oh, no, they're going to do this later with wireless plans.
[00:48:48.900 --> 00:48:50.100]   I'm sorry.
[00:48:50.100 --> 00:48:52.860]   See, some real tailor will have it in...
[00:48:52.860 --> 00:48:56.620]   You can do a demo at their store, somebody.
[00:48:56.620 --> 00:48:58.060]   That's what Microsoft's doing with HoloLens.
[00:48:58.060 --> 00:49:01.420]   You can go to a Microsoft store and try it.
[00:49:01.420 --> 00:49:03.460]   So there will be a way to try it, but you're exactly right.
[00:49:03.460 --> 00:49:08.580]   I mean, that's one of the problems with VR as well, is that it's hard to do a test drive
[00:49:08.580 --> 00:49:11.140]   before you spend hundreds of dollars on these things.
[00:49:11.140 --> 00:49:15.540]   Well, and it's hard to find a compelling use case that gets you to spend a hundred...
[00:49:15.540 --> 00:49:16.540]   I mean, like...
[00:49:16.540 --> 00:49:17.540]   I see.
[00:49:17.540 --> 00:49:20.020]   AR is not hard to find a compelling use case.
[00:49:20.020 --> 00:49:27.180]   So AR, as it stands today, in industrial stuff, sure, it's compelling in consumer-type things
[00:49:27.180 --> 00:49:28.500]   at that price point.
[00:49:28.500 --> 00:49:31.620]   I still think it's a little hard, even though I think...
[00:49:31.620 --> 00:49:34.740]   I'd pay this price if it were fully functional.
[00:49:34.740 --> 00:49:39.540]   It didn't look like I was wearing ant headgear.
[00:49:39.540 --> 00:49:46.300]   If I didn't look like ant man wearing it, I would pay $2,300 for it if I could walk around
[00:49:46.300 --> 00:49:53.900]   and see what people's names were, get reputation information, look at stuff and say, "Okay,
[00:49:53.900 --> 00:49:55.420]   we're going to be in Barcelona in three weeks.
[00:49:55.420 --> 00:50:00.340]   If I could wear this around Barcelona and hear and see stuff about what I'm looking at,
[00:50:00.340 --> 00:50:01.340]   that would be cool."
[00:50:01.340 --> 00:50:03.300]   I have people pointing that to you all the time.
[00:50:03.300 --> 00:50:08.540]   Do you want it to look normal, like hidden, or do you want it to look like a device on
[00:50:08.540 --> 00:50:10.020]   your face but not quite that diverse?
[00:50:10.020 --> 00:50:11.740]   We're a long way off from it being hidden.
[00:50:11.740 --> 00:50:16.100]   I think that's the dream, right, is that it looks like spectacles, like normal spectacles.
[00:50:16.100 --> 00:50:18.980]   Well, that's why I'm curious, because like...
[00:50:18.980 --> 00:50:24.060]   I don't want to get beat up.
[00:50:24.060 --> 00:50:28.540]   You laugh at people got beat up wearing Google Glass.
[00:50:28.540 --> 00:50:30.460]   I don't want to get beat up.
[00:50:30.460 --> 00:50:34.300]   I don't mind if people know I'm wearing something different.
[00:50:34.300 --> 00:50:35.300]   Okay.
[00:50:35.300 --> 00:50:40.900]   Ideally, they would look like something more normal.
[00:50:40.900 --> 00:50:42.860]   They're getting closer.
[00:50:42.860 --> 00:50:50.540]   If you wore HoloLens around, you'd really look like you were some strange being.
[00:50:50.540 --> 00:50:51.540]   You can't really.
[00:50:51.540 --> 00:50:53.340]   It's a big backpack.
[00:50:53.340 --> 00:50:54.940]   This is a lot smaller.
[00:50:54.940 --> 00:50:57.100]   Maybe I'll get this.
[00:50:57.100 --> 00:50:58.900]   Sorry, Lisa.
[00:50:58.900 --> 00:51:01.300]   Oh, no, no, no.
[00:51:01.300 --> 00:51:04.380]   You don't have to worry.
[00:51:04.380 --> 00:51:11.300]   To my left, there's a 100-inch projection screen television from HySense that's $10,000.
[00:51:11.300 --> 00:51:13.460]   She's already decided she wants that.
[00:51:13.460 --> 00:51:15.180]   We're going to review that in the new screen savers.
[00:51:15.180 --> 00:51:17.140]   So I'm good.
[00:51:17.140 --> 00:51:18.540]   It's a projection TV.
[00:51:18.540 --> 00:51:19.700]   They're back?
[00:51:19.700 --> 00:51:22.020]   Well, see the box below that screen?
[00:51:22.020 --> 00:51:23.020]   It's not fair.
[00:51:23.020 --> 00:51:23.980]   It's eight inches away from the wall.
[00:51:23.980 --> 00:51:24.980]   That's the point.
[00:51:24.980 --> 00:51:26.180]   That's the projector.
[00:51:26.180 --> 00:51:29.100]   It's a very, very short throw projector.
[00:51:29.100 --> 00:51:35.460]   So you can basically put it where the TV is now, put the screen above it.
[00:51:35.460 --> 00:51:37.380]   So the projector is there.
[00:51:37.380 --> 00:51:38.380]   It's projecting it right now.
[00:51:38.380 --> 00:51:40.380]   Oh, that's kind of interesting.
[00:51:40.380 --> 00:51:43.540]   It's projecting it right now from that box below.
[00:51:43.540 --> 00:51:44.820]   Not the big, big box.
[00:51:44.820 --> 00:51:46.460]   That's just something it's sitting on.
[00:51:46.460 --> 00:51:50.220]   That's better than it's UHD 4K.
[00:51:50.220 --> 00:51:51.220]   It looks like a projection.
[00:51:51.220 --> 00:51:52.740]   I would say it looks like a projector.
[00:51:52.740 --> 00:51:54.740]   We're going to-- What's the advantage?
[00:51:54.740 --> 00:51:58.340]   It's a short throw, 100-inch screen, 100-inch.
[00:51:58.340 --> 00:51:59.340]   100-inch.
[00:51:59.340 --> 00:52:00.340]   Got it.
[00:52:00.340 --> 00:52:01.340]   Got it.
[00:52:01.340 --> 00:52:02.340]   Got it.
[00:52:02.340 --> 00:52:03.340]   That's why she wants it.
[00:52:03.340 --> 00:52:07.620]   She wants some time for her Monday Night Football.
[00:52:07.620 --> 00:52:12.260]   We want Jimmy Garoppolo to be in the room with us.
[00:52:12.260 --> 00:52:13.260]   That's what we want.
[00:52:13.260 --> 00:52:15.540]   I'm trying to find-- I'm sorry.
[00:52:15.540 --> 00:52:18.380]   I should have highlighted it or something.
[00:52:18.380 --> 00:52:20.900]   Would you use something to build an app for the Magic Leap?
[00:52:20.900 --> 00:52:24.300]   Because you've got ARKit and you have-- what is Google's?
[00:52:24.300 --> 00:52:25.300]   What's it called?
[00:52:25.300 --> 00:52:27.300]   They're AR Core.
[00:52:27.300 --> 00:52:29.300]   AR Core.
[00:52:29.300 --> 00:52:32.780]   Does Magic Leap have its own version of AR which I'm a jigger?
[00:52:32.780 --> 00:52:33.780]   It must.
[00:52:33.780 --> 00:52:34.780]   But it's not--
[00:52:34.780 --> 00:52:35.780]   Okay, so that's a suck.
[00:52:35.780 --> 00:52:42.100]   What they don't say is what operating system, what the API or SDK looks like, what-- they
[00:52:42.100 --> 00:52:43.300]   don't say anything about that.
[00:52:43.300 --> 00:52:45.460]   It may only be in-house.
[00:52:45.460 --> 00:52:49.820]   This is called the Creators Edition, much like the HoloLens is.
[00:52:49.820 --> 00:52:54.980]   That implies that as a creator of content, you would want to get this.
[00:52:54.980 --> 00:52:58.940]   They're, again, cool use cases.
[00:52:58.940 --> 00:53:00.260]   I would say I would wait.
[00:53:00.260 --> 00:53:02.860]   I wouldn't buy it.
[00:53:02.860 --> 00:53:05.260]   But you should go for it.
[00:53:05.260 --> 00:53:09.900]   [SOUND]
[00:53:09.900 --> 00:53:11.860]   Is there a resale?
[00:53:11.860 --> 00:53:12.860]   No.
[00:53:12.860 --> 00:53:14.260]   No, don't do it.
[00:53:14.260 --> 00:53:15.860]   Actually, don't do it.
[00:53:15.860 --> 00:53:16.860]   Don't do it.
[00:53:16.860 --> 00:53:17.860]   Don't do it.
[00:53:17.860 --> 00:53:18.860]   It's available to creators in City.
[00:53:18.860 --> 00:53:19.860]   Oh, yeah.
[00:53:19.860 --> 00:53:21.540]   Well, that's another thing.
[00:53:21.540 --> 00:53:24.140]   You can only buy it in five cities.
[00:53:24.140 --> 00:53:26.980]   Oh, which five cities?
[00:53:26.980 --> 00:53:28.820]   San Francisco's one of them.
[00:53:28.820 --> 00:53:29.820]   Oh, no surprise.
[00:53:29.820 --> 00:53:32.700]   Sorry, we're not delivering to your area.
[00:53:32.700 --> 00:53:35.500]   Too some.
[00:53:35.500 --> 00:53:40.580]   So but yeah, but if I put a San Francisco zip code, I could get it.
[00:53:40.580 --> 00:53:41.860]   I know that's kind of weird too.
[00:53:41.860 --> 00:53:44.500]   They're not--
[00:53:44.500 --> 00:53:47.020]   Well, as long as Google's last, you had to go in and get trained.
[00:53:47.020 --> 00:53:48.180]   Oh, that must be it, right.
[00:53:48.180 --> 00:53:50.220]   Because you can't just-- but you can't buy it online.
[00:53:50.220 --> 00:54:00.860]   All right, I think we can stop talking about this.
[00:54:00.860 --> 00:54:02.220]   Otherwise, I might buy it.
[00:54:02.220 --> 00:54:05.660]   Otherwise, I might buy it, which is the sport I would enjoy.
[00:54:05.660 --> 00:54:09.740]   No, this morning as I'm reading about it, preparing for the show, I'm thinking--
[00:54:09.740 --> 00:54:12.060]   I really seriously thought, oh, should I get one?
[00:54:12.060 --> 00:54:13.940]   I didn't get the whole lens.
[00:54:13.940 --> 00:54:16.700]   We did get Google Glass.
[00:54:16.700 --> 00:54:18.700]   Maybe that was the lesson learned.
[00:54:18.700 --> 00:54:19.700]   I don't know.
[00:54:19.700 --> 00:54:20.700]   Yeah.
[00:54:20.700 --> 00:54:26.540]   Just wait.
[00:54:26.540 --> 00:54:28.660]   Just wait a little bit.
[00:54:28.660 --> 00:54:29.740]   You'll be OK.
[00:54:29.740 --> 00:54:30.380]   Oh, no.
[00:54:30.380 --> 00:54:31.900]   No, don't misunderstand me.
[00:54:31.900 --> 00:54:35.980]   I don't have any need for this at all.
[00:54:35.980 --> 00:54:40.740]   My only question is, is it important enough that we should talk about it, review it from
[00:54:40.740 --> 00:54:42.660]   a point of view of having used it?
[00:54:42.660 --> 00:54:43.940]   I don't think so.
[00:54:43.940 --> 00:54:46.300]   I think we could trust Addy Robertson and leave it at that.
[00:54:46.300 --> 00:54:47.300]   I think so too.
[00:54:47.300 --> 00:54:48.300]   Yeah.
[00:54:48.300 --> 00:54:49.300]   Yeah.
[00:54:49.300 --> 00:54:50.300]   OK, I agree.
[00:54:50.300 --> 00:54:51.300]   It's a curiosity for quite some time.
[00:54:51.300 --> 00:54:52.300]   It's a curiosity still.
[00:54:52.300 --> 00:54:53.300]   It's not--
[00:54:53.300 --> 00:54:54.300]   If you're--
[00:54:54.300 --> 00:54:56.900]   If you're a view of what Robert says, they're going to invest in this.
[00:54:56.900 --> 00:54:57.900]   Yeah.
[00:54:57.900 --> 00:55:01.540]   Well, and I'm curious if the Verge is going to create like a heads-up display curse, because
[00:55:01.540 --> 00:55:06.540]   remember they did that deep dive into Intel's wireless glasses, the font?
[00:55:06.540 --> 00:55:09.020]   It's like being on the cover of Sports Illustrated.
[00:55:09.020 --> 00:55:10.020]   Yeah.
[00:55:10.020 --> 00:55:11.420]   It's the end.
[00:55:11.420 --> 00:55:15.180]   So it could be if these guys have problems, then I'm calling it.
[00:55:15.180 --> 00:55:17.900]   I'm going to be like, oh, you don't want the Verge to be here.
[00:55:17.900 --> 00:55:19.700]   I'm calling it.
[00:55:19.700 --> 00:55:20.700]   You know what?
[00:55:20.700 --> 00:55:22.380]   I got a good compromise.
[00:55:22.380 --> 00:55:24.940]   We'll get Addy Robertson on one of our shows to describe this.
[00:55:24.940 --> 00:55:25.940]   Good idea.
[00:55:25.940 --> 00:55:27.460]   How about that?
[00:55:27.460 --> 00:55:29.020]   That's the compromise.
[00:55:29.020 --> 00:55:30.780]   And by the way, the Verge didn't buy it either.
[00:55:30.780 --> 00:55:34.740]   They went to match sleep headquarters to try it.
[00:55:34.740 --> 00:55:37.580]   And they got more money than I do, that's for sure.
[00:55:37.580 --> 00:55:38.740]   They went to Florida in July.
[00:55:38.740 --> 00:55:39.740]   That's working hard.
[00:55:39.740 --> 00:55:40.740]   Oh, man.
[00:55:40.740 --> 00:55:43.740]   That's tough work, by the way.
[00:55:43.740 --> 00:55:52.740]   So this year, podcast Expo was in-- or is in August in Philadelphia, which is, by the
[00:55:52.740 --> 00:55:55.220]   way, right now, not a great place to be.
[00:55:55.220 --> 00:55:56.220]   A little hot.
[00:55:56.220 --> 00:55:57.220]   A little hot.
[00:55:57.220 --> 00:56:00.660]   Next year, it's going to be Orlando in August.
[00:56:00.660 --> 00:56:02.820]   Well, you get the cheap--
[00:56:02.820 --> 00:56:06.020]   It tells you something about the podcast industry.
[00:56:06.020 --> 00:56:07.940]   You get the cheap rooms.
[00:56:07.940 --> 00:56:11.380]   Well, so I just looked it up, right?
[00:56:11.380 --> 00:56:13.620]   There's podcast movement.
[00:56:13.620 --> 00:56:14.620]   That's the one.
[00:56:14.620 --> 00:56:15.620]   Podcast movement.
[00:56:15.620 --> 00:56:16.620]   There's podcast multimedia expo.
[00:56:16.620 --> 00:56:18.020]   Oh, I don't know that.
[00:56:18.020 --> 00:56:19.020]   Podcast.
[00:56:19.020 --> 00:56:20.540]   We go to podcast movement.
[00:56:20.540 --> 00:56:21.540]   You do go.
[00:56:21.540 --> 00:56:23.700]   I think Andrew goes to that.
[00:56:23.700 --> 00:56:24.700]   Yeah.
[00:56:24.700 --> 00:56:25.700]   Andrew, was that it last time?
[00:56:25.700 --> 00:56:26.700]   Yeah.
[00:56:26.700 --> 00:56:28.700]   That's the one--
[00:56:28.700 --> 00:56:29.700]   It was in July.
[00:56:29.700 --> 00:56:30.700]   It was already was.
[00:56:30.700 --> 00:56:31.700]   July 26.
[00:56:31.700 --> 00:56:32.700]   July 26.
[00:56:32.700 --> 00:56:34.940]   Yeah, we just missed it.
[00:56:34.940 --> 00:56:36.780]   That was when Google Next was.
[00:56:36.780 --> 00:56:37.780]   Right.
[00:56:37.780 --> 00:56:39.300]   So you couldn't go.
[00:56:39.300 --> 00:56:40.300]   Did Andrew go this year?
[00:56:40.300 --> 00:56:41.300]   Why?
[00:56:41.300 --> 00:56:42.860]   No, because I was at Google.
[00:56:42.860 --> 00:56:44.500]   You see?
[00:56:44.500 --> 00:56:47.500]   So next year, he can go while you stay home.
[00:56:47.500 --> 00:56:48.500]   There we go.
[00:56:48.500 --> 00:56:50.340]   Feed Cheerios to the kid.
[00:56:50.340 --> 00:56:52.380]   All right.
[00:56:52.380 --> 00:56:53.380]   Thank you for the correction.
[00:56:53.380 --> 00:56:54.500]   It's probably Dad.
[00:56:54.500 --> 00:56:58.340]   Dad's known for feeding cereal to children.
[00:56:58.340 --> 00:57:02.140]   My father was famous for home fries.
[00:57:02.140 --> 00:57:03.740]   My dad was famous for pancakes.
[00:57:03.740 --> 00:57:04.740]   Mm.
[00:57:04.740 --> 00:57:06.140]   Yeah, dads are good at pancakes.
[00:57:06.140 --> 00:57:08.260]   I was the waffle guy in our house.
[00:57:08.260 --> 00:57:10.060]   No, I'm the waffle girl.
[00:57:10.060 --> 00:57:11.620]   Mr. waffle.
[00:57:11.620 --> 00:57:12.620]   Dad is pancake, man.
[00:57:12.620 --> 00:57:15.580]   All right, I got a break to the end of the show and I got to hear.
[00:57:15.580 --> 00:57:18.100]   Are you both buying new June ovens?
[00:57:18.100 --> 00:57:19.600]   Shh.
[00:57:19.600 --> 00:57:24.460]   That's coming up as we continue with this edition of the show.
[00:57:24.460 --> 00:57:27.620]   This week in Google, she already talked me into this.
[00:57:27.620 --> 00:57:28.620]   What was it?
[00:57:28.620 --> 00:57:29.620]   $1,400?
[00:57:29.620 --> 00:57:30.620]   Okay.
[00:57:30.620 --> 00:57:31.620]   We're going to go.
[00:57:31.620 --> 00:57:32.620]   She already talked me into that.
[00:57:32.620 --> 00:57:35.020]   She already talked me into that one.
[00:57:35.020 --> 00:57:36.100]   You don't regret it.
[00:57:36.100 --> 00:57:37.820]   The toaster oven with a camera in it.
[00:57:37.820 --> 00:57:38.820]   No, I don't.
[00:57:38.820 --> 00:57:42.260]   We've got a lot of good mileage out of that.
[00:57:42.260 --> 00:57:44.820]   I should replace it.
[00:57:44.820 --> 00:57:46.300]   I should.
[00:57:46.300 --> 00:57:48.140]   Today.
[00:57:48.140 --> 00:57:52.700]   My favorite was when I demonstrated it and I said, you know, you can see what's cooking
[00:57:52.700 --> 00:57:55.740]   in it and there was somebody cooking toast in it right when I opened it up.
[00:57:55.740 --> 00:57:57.820]   I said, who's in our house?
[00:57:57.820 --> 00:58:01.500]   It's edition of this week in Google.
[00:58:01.500 --> 00:58:03.180]   Brought to you by WordPress.com.
[00:58:03.180 --> 00:58:04.660]   I'm a big fan.
[00:58:04.660 --> 00:58:05.660]   That's where my site is.
[00:58:05.660 --> 00:58:10.860]   Actually, I started using WordPress when Matt Mullenweg first created it in early 2000s.
[00:58:10.860 --> 00:58:16.380]   I was initially running it on my own server, but the expense and the time consuming, you
[00:58:16.380 --> 00:58:18.780]   know, keeping it running and all that stuff.
[00:58:18.780 --> 00:58:21.420]   Eventually, I was doing more of that than less blogging.
[00:58:21.420 --> 00:58:23.820]   So I thought, I'm going to WordPress.com.
[00:58:23.820 --> 00:58:26.700]   It's less expensive than paying for my own hosting.
[00:58:26.700 --> 00:58:27.940]   They manage it.
[00:58:27.940 --> 00:58:33.740]   They take care of hosting, security software updates, giving you time to focus on what
[00:58:33.740 --> 00:58:36.380]   you created the site for in the first place.
[00:58:36.380 --> 00:58:41.420]   Your presence on the internet, everybody, everybody needs to have a place of their own,
[00:58:41.420 --> 00:58:46.020]   a home of their own, a room of one zone on the internet, a place where you put up your
[00:58:46.020 --> 00:58:48.020]   best stuff.
[00:58:48.020 --> 00:58:51.980]   It's part of controlling your reputation, if nothing else.
[00:58:51.980 --> 00:58:54.940]   If you're a business, you better put your site up there.
[00:58:54.940 --> 00:58:58.340]   Otherwise, when they Google your business name, they're going to find Yelp or something
[00:58:58.340 --> 00:58:59.900]   like that.
[00:58:59.900 --> 00:59:06.540]   Even if your business is a very, you know, in the present, not a tech business, but you
[00:59:06.540 --> 00:59:11.780]   know, you're cleaning gutters or washing windows or a plumber, you need to have a website.
[00:59:11.780 --> 00:59:16.300]   So I know when I hire somebody, I always check out their website first.
[00:59:16.300 --> 00:59:18.300]   That's how you communicate with your customers.
[00:59:18.300 --> 00:59:20.060]   You may say, I have a Facebook page.
[00:59:20.060 --> 00:59:21.060]   No, that's not yours.
[00:59:21.060 --> 00:59:22.260]   That's Mr. Zuckerberg's.
[00:59:22.260 --> 00:59:23.540]   I have a Twitter feed.
[00:59:23.540 --> 00:59:25.660]   No, that's not yours.
[00:59:25.660 --> 00:59:26.660]   That's Mr. Dorsey's.
[00:59:26.660 --> 00:59:30.380]   You need to have yours at WordPress.com.
[00:59:30.380 --> 00:59:31.780]   No limits.
[00:59:31.780 --> 00:59:34.660]   Create the ultimate online hub that's yours.
[00:59:34.660 --> 00:59:38.060]   And with Room to Grow as you aim higher, they've got great e-commerce options, everything
[00:59:38.060 --> 00:59:41.580]   from a simple buy button to a full online store.
[00:59:41.580 --> 00:59:42.580]   You can upload images.
[00:59:42.580 --> 00:59:43.580]   You can upload video.
[00:59:43.580 --> 00:59:45.620]   You can upload audio.
[00:59:45.620 --> 00:59:50.700]   So it can host all of that import and export content to and from your WordPress website.
[00:59:50.700 --> 00:59:54.380]   If you're on another platform, easy to move, easy peasy.
[00:59:54.380 --> 00:59:57.300]   It's your site, your home, your content.
[00:59:57.300 --> 01:00:02.900]   And with built-in SEO, social media linking and marketing tools, you can grow your audience
[01:00:02.900 --> 01:00:04.860]   and reach new customers.
[01:00:04.860 --> 01:00:07.020]   They've got a great WordPress app on iOS and Android.
[01:00:07.020 --> 01:00:10.260]   It makes it easy to manage your site on the go, not only moderate comments, but post
[01:00:10.260 --> 01:00:12.220]   new content.
[01:00:12.220 --> 01:00:16.380]   And you can launch your website with confidence knowing that they have a fantastic support
[01:00:16.380 --> 01:00:17.380]   team.
[01:00:17.380 --> 01:00:19.260]   They're 24/7.
[01:00:19.260 --> 01:00:23.020]   No wonder 31% of all websites run on WordPress.
[01:00:23.020 --> 01:00:26.340]   That's almost a third of every website in the world.
[01:00:26.340 --> 01:00:29.340]   Many great publications, Paul Therat's site.
[01:00:29.340 --> 01:00:30.500]   One's on WordPress.
[01:00:30.500 --> 01:00:33.620]   Steve Gibson's page, his blog runs on WordPress.
[01:00:33.620 --> 01:00:39.020]   Sure, he could host himself, but it's just so much easier to put it on WordPress.com.
[01:00:39.020 --> 01:00:41.740]   WordPress plans started just $4 a month, too.
[01:00:41.740 --> 01:00:44.900]   So it's a lot less than hosting it yourself.
[01:00:44.900 --> 01:00:46.500]   It's just the way to go.
[01:00:46.500 --> 01:00:51.460]   Right now you'll get 15% off your new plan purchase when you go to WordPress.com/twig.
[01:00:51.460 --> 01:00:52.540]   Stand out from the crowd.
[01:00:52.540 --> 01:00:54.100]   Create your own website.
[01:00:54.100 --> 01:01:00.740]   Put your mark on the world, wordpress.com/twig.
[01:01:00.740 --> 01:01:02.300]   My daughter did that.
[01:01:02.300 --> 01:01:07.580]   She's got poetry on there and video and papers that she's written for school is a really
[01:01:07.580 --> 01:01:08.580]   good idea.
[01:01:08.580 --> 01:01:13.460]   That way, you put your mark on the web and when people search for your name, that's going
[01:01:13.460 --> 01:01:15.180]   to be the first thing they're going to find.
[01:01:15.180 --> 01:01:16.180]   WordPress.
[01:01:16.180 --> 01:01:20.940]   Oh, and by the way, putting it on WordPress is a good idea because it's well indexed by
[01:01:20.940 --> 01:01:21.940]   Google.
[01:01:21.940 --> 01:01:24.020]   That's all that SEO stuff they do.
[01:01:24.020 --> 01:01:25.500]   WordPress.com/twig.
[01:01:25.500 --> 01:01:32.140]   Is it June Oven going to be a picture?
[01:01:32.140 --> 01:01:34.900]   We save it for the end?
[01:01:34.900 --> 01:01:35.900]   We can.
[01:01:35.900 --> 01:01:37.900]   Well, it's up to you.
[01:01:37.900 --> 01:01:40.300]   Okay, if you're going to talk about it at the end, we won't.
[01:01:40.300 --> 01:01:41.460]   We'll save that for the end.
[01:01:41.460 --> 01:01:42.940]   That's fine.
[01:01:42.940 --> 01:01:46.420]   Let's talk about actually the probably the biggest story around Google these days.
[01:01:46.420 --> 01:01:54.180]   First of all, we should say that Google has not announced this, but there was a rumor
[01:01:54.180 --> 01:01:59.220]   that Google was going to work on a censored version of Google search.
[01:01:59.220 --> 01:02:04.380]   This comes from the intercept, Ryan Gallagher, for China.
[01:02:04.380 --> 01:02:07.660]   Leaked documents reveal Google's planning the launch of censored version of its search
[01:02:07.660 --> 01:02:13.460]   engine in China that will blacklist websites and search terms about human rights, democracy,
[01:02:13.460 --> 01:02:19.860]   religion, peaceful protest, all the things that Chinese government doesn't like.
[01:02:19.860 --> 01:02:23.260]   According to the intercept, the project, code named Dragonfly, has been underwaisted
[01:02:23.260 --> 01:02:29.380]   since the spring of last year, was accelerated in December when Sundar Pichai met with a top
[01:02:29.380 --> 01:02:33.300]   Chinese government official.
[01:02:33.300 --> 01:02:38.900]   And there are huge protests at Google from Google employees who say, "No, we got out
[01:02:38.900 --> 01:02:41.460]   of China because we didn't.
[01:02:41.460 --> 01:02:42.460]   For a reason.
[01:02:42.460 --> 01:02:43.460]   For a good reason.
[01:02:43.460 --> 01:02:46.020]   They're human rights record."
[01:02:46.020 --> 01:02:47.820]   So we talked about this last week.
[01:02:47.820 --> 01:02:48.820]   Oh, it's over.
[01:02:48.820 --> 01:02:49.820]   Okay, never mind.
[01:02:49.820 --> 01:02:50.820]   No, no, no, no.
[01:02:50.820 --> 01:02:52.300]   It's a bit of stories kept going.
[01:02:52.300 --> 01:02:53.300]   Yeah.
[01:02:53.300 --> 01:02:54.300]   Yeah, the story kept going.
[01:02:54.300 --> 01:02:56.100]   So last week, it just broke in.
[01:02:56.100 --> 01:02:57.100]   Oh, okay.
[01:02:57.100 --> 01:03:01.660]   Jeff and I were talking about, Jeff is one can imagine was this is evil.
[01:03:01.660 --> 01:03:03.860]   It's a little chadraw line and stick to it.
[01:03:03.860 --> 01:03:05.860]   I didn't think it was evil, but I said I was disappointed.
[01:03:05.860 --> 01:03:06.860]   Yeah.
[01:03:06.860 --> 01:03:11.860]   And I think that I said before when it comes to Apple, for instance, working with the
[01:03:11.860 --> 01:03:16.460]   Chinese government that American companies need to stand up and say, "We're not going
[01:03:16.460 --> 01:03:17.460]   to do it.
[01:03:17.460 --> 01:03:21.220]   We're not going to work in authoritarian regimes, even if we could make a lot of money there."
[01:03:21.220 --> 01:03:26.380]   You could argue that they work with authoritarian regimes right now in the US.
[01:03:26.380 --> 01:03:28.860]   But this is not an authoritarian regime.
[01:03:28.860 --> 01:03:29.860]   What are you going to say?
[01:03:29.860 --> 01:03:30.860]   Come on.
[01:03:30.860 --> 01:03:33.340]   You may not like it, but we do.
[01:03:33.340 --> 01:03:37.380]   This is not comparable to China yet.
[01:03:37.380 --> 01:03:40.020]   There are some practices that are actually.
[01:03:40.020 --> 01:03:42.860]   But I was going to say, I was waiting for-
[01:03:42.860 --> 01:03:44.580]   Folks, you're not an immigrant.
[01:03:44.580 --> 01:03:45.980]   It's okay here.
[01:03:45.980 --> 01:03:46.980]   Right.
[01:03:46.980 --> 01:03:47.980]   Yeah.
[01:03:47.980 --> 01:03:53.180]   Anyway, I was waiting for Google employees to weigh in and-
[01:03:53.180 --> 01:03:54.180]   They have.
[01:03:54.180 --> 01:03:55.180]   They did.
[01:03:55.180 --> 01:03:56.180]   And predictably, they are unhappy.
[01:03:56.180 --> 01:04:04.940]   So I'm curious what happens from that perspective if individual Googlers end up preventing this
[01:04:04.940 --> 01:04:07.580]   or what goes on there.
[01:04:07.580 --> 01:04:12.780]   This is that old argument companies make that, "Well, we have to obey the laws of the
[01:04:12.780 --> 01:04:13.980]   countries we work in.
[01:04:13.980 --> 01:04:16.580]   The thing that's different about Google is you choose to be in them."
[01:04:16.580 --> 01:04:21.260]   Google decided not to do business in China because of its human rights record.
[01:04:21.260 --> 01:04:23.300]   And now they're apparently considering going back.
[01:04:23.300 --> 01:04:27.500]   It's of course tempting because there's a lot of money to be made in China.
[01:04:27.500 --> 01:04:32.940]   There's a billion Chinese people who are active Internet users in many cases.
[01:04:32.940 --> 01:04:34.620]   I'll make a prediction.
[01:04:34.620 --> 01:04:35.620]   Go ahead.
[01:04:35.620 --> 01:04:39.540]   Even if they do everything in China once, which is a lot more now than it would have
[01:04:39.540 --> 01:04:44.740]   been when they left, which is a story up on the rundown, the rules have gotten worse and
[01:04:44.740 --> 01:04:45.740]   worse.
[01:04:45.740 --> 01:04:49.380]   Even if they did everything that China wanted, they'll fail there because you have to be
[01:04:49.380 --> 01:04:50.380]   a Chinese company to succeed.
[01:04:50.380 --> 01:04:51.380]   Yeah.
[01:04:51.380 --> 01:04:52.700]   And they said, "Oh, we'll beat them easy.
[01:04:52.700 --> 01:04:53.700]   Come on."
[01:04:53.700 --> 01:04:57.900]   And Google by do is the Google of China.
[01:04:57.900 --> 01:05:01.420]   So China already blocks Facebook, Twitter, Instagram and Snapchat.
[01:05:01.420 --> 01:05:02.940]   So Google would have to block all that.
[01:05:02.940 --> 01:05:04.940]   This is from the Observer.
[01:05:04.940 --> 01:05:11.260]   Anything that's anti-communism, party content, any political dissidents, of course that's
[01:05:11.260 --> 01:05:12.260]   obvious.
[01:05:12.260 --> 01:05:14.260]   Controversial news content, pornography.
[01:05:14.260 --> 01:05:18.180]   Controversial being defined as things that are critical of the government.
[01:05:18.180 --> 01:05:19.180]   Yeah.
[01:05:19.180 --> 01:05:22.140]   The laws of business or political scandals.
[01:05:22.140 --> 01:05:26.660]   Anything harmful to social stability.
[01:05:26.660 --> 01:05:29.620]   Pornography, gambling and violence.
[01:05:29.620 --> 01:05:31.500]   Winnie the Pooh is banned in China.
[01:05:31.500 --> 01:05:42.980]   And that goes back to the fact that dissidents compared President Xi to a bear during his
[01:05:42.980 --> 01:05:45.860]   visit to the US in 2013.
[01:05:45.860 --> 01:05:51.140]   And the meme comparing a photo of him in Barack Obama to an image of Pooh and Tigger went
[01:05:51.140 --> 01:05:52.300]   viral in China.
[01:05:52.300 --> 01:05:53.300]   She didn't like it.
[01:05:53.300 --> 01:05:54.940]   Winnie the Pooh has been banned ever since.
[01:05:54.940 --> 01:06:00.020]   Google, do you really want to be in a country where an autocratic leader can ban an image
[01:06:00.020 --> 01:06:01.620]   because he doesn't like it?
[01:06:01.620 --> 01:06:03.620]   Because he finds it insulting.
[01:06:03.620 --> 01:06:06.020]   Well, I don't know.
[01:06:06.020 --> 01:06:08.820]   It's just the world now.
[01:06:08.820 --> 01:06:13.820]   What are you going to do about it?
[01:06:13.820 --> 01:06:14.820]   Well, I find interesting.
[01:06:14.820 --> 01:06:19.060]   This is not the first time Google employees have become vocal activists against company
[01:06:19.060 --> 01:06:20.060]   policy.
[01:06:20.060 --> 01:06:22.180]   I can't, not a lot of companies have that problem.
[01:06:22.180 --> 01:06:23.980]   Most employees just go along.
[01:06:23.980 --> 01:06:24.980]   Well, I go along.
[01:06:24.980 --> 01:06:27.980]   Microsoft and where I put up the third one, there was a kind of story here that said
[01:06:27.980 --> 01:06:28.980]   this.
[01:06:28.980 --> 01:06:37.780]   The three that there have been employee revolts on ethical issues at Google and Microsoft
[01:06:37.780 --> 01:06:40.340]   and what was the third one?
[01:06:40.340 --> 01:06:41.340]   Ah.
[01:06:41.340 --> 01:06:42.340]   Twit.
[01:06:42.340 --> 01:06:43.340]   No.
[01:06:43.340 --> 01:06:44.340]   Twit.
[01:06:44.340 --> 01:06:45.340]   Apple?
[01:06:45.340 --> 01:06:50.980]   Yeah, I wouldn't be surprised Apple if Apple employees were.
[01:06:50.980 --> 01:06:55.060]   Those, they're in a highly lucrative field in Amazon.
[01:06:55.060 --> 01:06:56.060]   Amazon.
[01:06:56.060 --> 01:06:57.060]   Yeah.
[01:06:57.060 --> 01:06:58.060]   And there's such competition for workers.
[01:06:58.060 --> 01:06:59.060]   Not Apple though.
[01:06:59.060 --> 01:07:00.060]   Interesting.
[01:07:00.060 --> 01:07:01.060]   Either way.
[01:07:01.060 --> 01:07:02.060]   So.
[01:07:02.060 --> 01:07:04.500]   And not Facebook.
[01:07:04.500 --> 01:07:09.740]   I think, you know, they're secure in their jobs in the sense that if they get fired from
[01:07:09.740 --> 01:07:12.340]   Google, they probably can go work in another company.
[01:07:12.340 --> 01:07:13.340]   That's true.
[01:07:13.340 --> 01:07:18.260]   So this is specifically, it's a story in nationalinterest.org about what they call engineering
[01:07:18.260 --> 01:07:24.060]   insurgency and say that these were three potential protests around the use of AI.
[01:07:24.060 --> 01:07:25.060]   Right.
[01:07:25.060 --> 01:07:28.260]   At Google, it was the drone image AI.
[01:07:28.260 --> 01:07:30.260]   That's right.
[01:07:30.260 --> 01:07:32.740]   It's been on robots.
[01:07:32.740 --> 01:07:36.940]   Is it this what we've been calling for though, is that technologists should be aware of the
[01:07:36.940 --> 01:07:41.940]   consequences of their inventions and actions and should be responsible and should do and
[01:07:41.940 --> 01:07:43.540]   should stand up?
[01:07:43.540 --> 01:07:44.540]   I think so.
[01:07:44.540 --> 01:07:45.540]   Yeah.
[01:07:45.540 --> 01:07:49.940]   I mean, I interviewed, you know, Jonathan Zungar for a project.
[01:07:49.940 --> 01:07:50.940]   He's brilliant.
[01:07:50.940 --> 01:07:51.940]   And he was a Google.
[01:07:51.940 --> 01:07:52.940]   He was a Google engineer.
[01:07:52.940 --> 01:07:53.940]   He was a Google.
[01:07:53.940 --> 01:07:54.940]   He's left with the startup.
[01:07:54.940 --> 01:07:56.260]   He's really smart.
[01:07:56.260 --> 01:08:02.020]   And he said that software engineers have to develop the same kind of standards of behavior
[01:08:02.020 --> 01:08:04.100]   as civil engineers did.
[01:08:04.100 --> 01:08:05.500]   Civil engineer would build a bridge.
[01:08:05.500 --> 01:08:06.500]   Yeah.
[01:08:06.500 --> 01:08:08.060]   And the goal was it better not fall down.
[01:08:08.060 --> 01:08:09.060]   Right.
[01:08:09.060 --> 01:08:10.060]   It fell down.
[01:08:10.060 --> 01:08:11.060]   You have it on your job.
[01:08:11.060 --> 01:08:13.660]   It's a lot easier to see a bridge and see whether it's up or down.
[01:08:13.660 --> 01:08:18.940]   But what's the equivalent in software engineering and the impact you have and the danger you
[01:08:18.940 --> 01:08:19.940]   present.
[01:08:19.940 --> 01:08:23.300]   And then it's a professional standard that has to develop.
[01:08:23.300 --> 01:08:25.820]   I think he's smart and right.
[01:08:25.820 --> 01:08:26.820]   If you throw that at.
[01:08:26.820 --> 01:08:29.580]   So I'm going to take it a step further.
[01:08:29.580 --> 01:08:33.300]   If you build a bridge and call it down.
[01:08:33.300 --> 01:08:34.740]   That is obviously a bad thing.
[01:08:34.740 --> 01:08:39.580]   But what if you build a bridge and it allows movement of populations from one place to
[01:08:39.580 --> 01:08:42.140]   another and thus changes a culture.
[01:08:42.140 --> 01:08:44.780]   Because I think the analogy.
[01:08:44.780 --> 01:08:47.100]   But civil engineers don't actually have to think about that.
[01:08:47.100 --> 01:08:50.940]   And what we're asking technologists to do is actually that step further.
[01:08:50.940 --> 01:08:53.580]   Because you could say, hey, does your code work?
[01:08:53.580 --> 01:08:54.580]   Yeah.
[01:08:54.580 --> 01:08:55.580]   Yeah.
[01:08:55.580 --> 01:08:59.900]   So, and usually if you're thinking about building a bridge, you actually do something
[01:08:59.900 --> 01:09:02.300]   like that with under municipal auspices.
[01:09:02.300 --> 01:09:08.180]   So you have a vote for bond issues to build such bridge or whatever.
[01:09:08.180 --> 01:09:12.460]   So I'm just throwing that out there as a thought process because that's a more democratic
[01:09:12.460 --> 01:09:14.100]   thing to think about.
[01:09:14.100 --> 01:09:17.020]   And we're trying to assign responsibility to these people.
[01:09:17.020 --> 01:09:22.860]   And I don't know how far many whose job is it to look ahead for the impact of some of
[01:09:22.860 --> 01:09:24.180]   these things.
[01:09:24.180 --> 01:09:26.660]   Not just that, you know, anyway.
[01:09:26.660 --> 01:09:28.860]   Well, you're absolutely right.
[01:09:28.860 --> 01:09:34.340]   So, yeah, it's it's it's whose job and how possible is it to really know the impact.
[01:09:34.340 --> 01:09:36.100]   I'm going back to my Gutenberg stuff, right?
[01:09:36.100 --> 01:09:40.060]   It took 100 years to get a lot of the impact in place.
[01:09:40.060 --> 01:09:41.700]   And we're guessing at it and we don't know.
[01:09:41.700 --> 01:09:42.700]   And you're right.
[01:09:42.700 --> 01:09:44.820]   You may be building something that has a positive impact.
[01:09:44.820 --> 01:09:51.500]   And my moral panic arguments is if you cut off potential bad impact, you don't know what
[01:09:51.500 --> 01:09:53.220]   you're losing.
[01:09:53.220 --> 01:09:54.220]   So yeah, it's hard.
[01:09:54.220 --> 01:09:58.220]   But I think I think you have to have some ethic of impact, some ethic of thinking about
[01:09:58.220 --> 01:09:59.220]   this.
[01:09:59.220 --> 01:10:03.380]   Now, I will not go as far as Tristan Harris arguing that, you know, these are all made
[01:10:03.380 --> 01:10:05.500]   to a dictus and that's evil.
[01:10:05.500 --> 01:10:08.220]   That doesn't give us enough agency and enough credit.
[01:10:08.220 --> 01:10:11.780]   We're giving people choices that they can make.
[01:10:11.780 --> 01:10:14.780]   But we've got to have an ethic of worrying about a little bit.
[01:10:14.780 --> 01:10:18.260]   It's interesting because I'm sure that the original leak to the intercept probably came
[01:10:18.260 --> 01:10:20.660]   from a Google employee working on this.
[01:10:20.660 --> 01:10:27.780]   And since the Internet reports that on a number of Google sites, people are saying,
[01:10:27.780 --> 01:10:35.300]   yes, in fact, a number of other Googlers have independently confirmed the plan to Reuters
[01:10:35.300 --> 01:10:39.740]   the Wall Street Journal, the New York Times, the Financial Times Agency, France, press,
[01:10:39.740 --> 01:10:41.940]   vice, vice news in Bloomberg.
[01:10:41.940 --> 01:10:45.060]   One source, this is from the intercept one source who spoke to Bloomberg, characterized
[01:10:45.060 --> 01:10:47.740]   the product as a censorship engine.
[01:10:47.740 --> 01:10:51.580]   Remember Google got out of China in 2010.
[01:10:51.580 --> 01:10:56.020]   At that time saying it was because of Chinese government efforts to limit free speech block
[01:10:56.020 --> 01:10:57.020]   websites.
[01:10:57.020 --> 01:11:01.020]   Oh, and hack Google.
[01:11:01.020 --> 01:11:05.780]   And force Google to change Google rather than the government saying, this is illegal, don't
[01:11:05.780 --> 01:11:08.780]   do this, you choose yes or no.
[01:11:08.780 --> 01:11:11.660]   It's not unlike what's happening in some parts of the European regulation.
[01:11:11.660 --> 01:11:14.540]   We're going to make you do it, Google.
[01:11:14.540 --> 01:11:21.220]   Yeah, but I'm looking at the blog post from March 22nd, 2010.
[01:11:21.220 --> 01:11:26.340]   This followed on the heels of Google announcing that they and 20 other US companies have
[01:11:26.340 --> 01:11:30.660]   been the victims of a cyber attack originating from China.
[01:11:30.660 --> 01:11:34.260]   They were looking for the Gmail accounts of dozens of human rights activists.
[01:11:34.260 --> 01:11:36.220]   And it was at that time.
[01:11:36.220 --> 01:11:37.220]   Remember that?
[01:11:37.220 --> 01:11:38.220]   Yeah, I do.
[01:11:38.220 --> 01:11:41.460]   Yeah, it was at that time they Google.
[01:11:41.460 --> 01:11:42.620]   This is how they did it.
[01:11:42.620 --> 01:11:46.820]   Stop censoring our search services, Google search, Google news and Google images on Google
[01:11:46.820 --> 01:11:53.020]   dot CN, the Chinese version of Google users visiting Google to see and are now simply redirected
[01:11:53.020 --> 01:11:56.940]   to the Hong Kong version where we are offering uncensored search.
[01:11:56.940 --> 01:12:01.780]   So that's been the status quo for the last eight years since then.
[01:12:01.780 --> 01:12:05.380]   So what it sounds like is they want to bring back Google C and in order to do that, of
[01:12:05.380 --> 01:12:10.540]   course, you'd have to comply with those Chinese government regulations about what search engines
[01:12:10.540 --> 01:12:12.460]   can but results they can produce.
[01:12:12.460 --> 01:12:14.660]   I mean, I guess Baidu does the same thing, right?
[01:12:14.660 --> 01:12:17.180]   They're a Chinese search engine, right?
[01:12:17.180 --> 01:12:18.180]   Yeah.
[01:12:18.180 --> 01:12:19.180]   Yes.
[01:12:19.180 --> 01:12:25.700]   And what's interesting is Baidu has some excellent kind of image recognition technology and that
[01:12:25.700 --> 01:12:26.700]   sort of thing.
[01:12:26.700 --> 01:12:30.740]   And I'm very curious what it does with the data it gets in terms of handing things over
[01:12:30.740 --> 01:12:32.540]   to the government.
[01:12:32.540 --> 01:12:33.540]   Right.
[01:12:33.540 --> 01:12:39.500]   And don't forget China has their social IQ score that they're playing with, which if
[01:12:39.500 --> 01:12:43.020]   you think about Google participating in something like that gets.
[01:12:43.020 --> 01:12:49.100]   And incidentally, China has started exporting this social IQ to other countries to, you
[01:12:49.100 --> 01:12:52.060]   know, friendly nations.
[01:12:52.060 --> 01:12:56.460]   There's no question in my mind that this, you know, not only has China become authoritarian
[01:12:56.460 --> 01:13:01.620]   under she much more authoritarian under she who is now president for life, but wants to
[01:13:01.620 --> 01:13:10.860]   export its form of authoritarian rule to other countries using its economics.
[01:13:10.860 --> 01:13:13.540]   I think this Google has to take this pretty seriously.
[01:13:13.540 --> 01:13:14.540]   Yeah.
[01:13:14.540 --> 01:13:18.020]   I think the other thing that's going to happen is I mean, we keep on waiting for China to
[01:13:18.020 --> 01:13:21.100]   export its businesses to the rest of the world.
[01:13:21.100 --> 01:13:24.620]   And the argument that I hear when I talk to people about this is the Chinese market is
[01:13:24.620 --> 01:13:26.900]   just so damned huge.
[01:13:26.900 --> 01:13:28.540]   They don't need to yet.
[01:13:28.540 --> 01:13:31.380]   And they operate under such advantage now.
[01:13:31.380 --> 01:13:36.980]   But at some point, you know, Baidu and WeChat are going to come out into our market and they're
[01:13:36.980 --> 01:13:38.740]   going to come with these limitations.
[01:13:38.740 --> 01:13:44.540]   The, I don't know if you saw that the DNC basically ordered every campaign, every Democrat
[01:13:44.540 --> 01:13:46.820]   to not use phones from Huawei and LTC.
[01:13:46.820 --> 01:13:52.500]   Yeah, this came up because there was a local committee was about to buy a bunch of, I think,
[01:13:52.500 --> 01:13:53.500]   ZTE phones.
[01:13:53.500 --> 01:13:55.220]   Are they buying Lenovo laptops?
[01:13:55.220 --> 01:14:02.900]   I mean, well, but it's a very interesting point.
[01:14:02.900 --> 01:14:08.140]   I mean, ZTE in Huawei are particularly suspect because they are at least partially owned
[01:14:08.140 --> 01:14:12.100]   by the Chinese military, by the government.
[01:14:12.100 --> 01:14:15.100]   One of them was founded by Chinese military.
[01:14:15.100 --> 01:14:19.420]   So their ties are very close to the Chinese government.
[01:14:19.420 --> 01:14:20.900]   Maybe more so than Lenovo.
[01:14:20.900 --> 01:14:21.900]   I don't know.
[01:14:21.900 --> 01:14:22.900]   Yeah, that's a good question.
[01:14:22.900 --> 01:14:24.780]   And we've stopped them from coming.
[01:14:24.780 --> 01:14:28.620]   They've tried to come in several times in various cases with various deals.
[01:14:28.620 --> 01:14:33.340]   I have a very nice Huawei phone, the P20, that is really remarkable phone.
[01:14:33.340 --> 01:14:34.820]   And I don't consider it more dangerous to me.
[01:14:34.820 --> 01:14:37.380]   I always wondered about you, LaPorte.
[01:14:37.380 --> 01:14:39.260]   Which was spy.
[01:14:39.260 --> 01:14:41.180]   I don't know.
[01:14:41.180 --> 01:14:44.700]   I mean, you know, here's where, okay.
[01:14:44.700 --> 01:14:48.140]   This is the far-fetched risk.
[01:14:48.140 --> 01:14:53.660]   If the Chinese were to invade the United States, they'd have a nice dossier on people who are
[01:14:53.660 --> 01:14:55.620]   using their equipment.
[01:14:55.620 --> 01:15:01.180]   If you are a government worker, or you're in the DNC, where you've already been hacked
[01:15:01.180 --> 01:15:06.500]   once, at least once, that would make sense that you wouldn't want to give information
[01:15:06.500 --> 01:15:08.180]   to another country.
[01:15:08.180 --> 01:15:13.860]   If you're a company, there's always the risk of competitive espionage.
[01:15:13.860 --> 01:15:16.860]   So in those cases, yeah.
[01:15:16.860 --> 01:15:18.860]   I don't think China's going to invade us.
[01:15:18.860 --> 01:15:20.420]   So I think I'm okay.
[01:15:20.420 --> 01:15:21.420]   Unless they really want to.
[01:15:21.420 --> 01:15:24.420]   Well, I mean, I don't think Russia's going to invade us, but they're going to invade us
[01:15:24.420 --> 01:15:25.420]   digitally.
[01:15:25.420 --> 01:15:26.420]   Yeah.
[01:15:26.420 --> 01:15:27.420]   They have invaded us virtually.
[01:15:27.420 --> 01:15:28.420]   Yeah, that's an interesting.
[01:15:28.420 --> 01:15:31.900]   So we talk a lot about Russia and their attempt to influence the elections and so forth.
[01:15:31.900 --> 01:15:33.820]   We'll stipulate that that happened.
[01:15:33.820 --> 01:15:35.060]   I think that's pretty clear.
[01:15:35.060 --> 01:15:36.900]   Do you think China is trying to do the same thing?
[01:15:36.900 --> 01:15:38.420]   Have they done the same thing?
[01:15:38.420 --> 01:15:41.620]   I think China is much more interested in competitive intelligence.
[01:15:41.620 --> 01:15:42.620]   Right.
[01:15:42.620 --> 01:15:48.340]   Plenty of examples of them grabbing intelligence from American companies.
[01:15:48.340 --> 01:15:54.940]   And things like getting information for, you know, dissidents.
[01:15:54.940 --> 01:15:56.780]   So I think that's more of its interest.
[01:15:56.780 --> 01:16:03.140]   I don't think China really cares about invading the US or probably messing with our elections
[01:16:03.140 --> 01:16:04.140]   as much as Russia does.
[01:16:04.140 --> 01:16:05.460]   Do you have different geopolitical aims?
[01:16:05.460 --> 01:16:10.180]   They're actually a real economic powerhouse, which Russia is not.
[01:16:10.180 --> 01:16:14.820]   And Russia would love to reclaim some of its territories in the former Soviet Union.
[01:16:14.820 --> 01:16:18.380]   China has its own territory.
[01:16:18.380 --> 01:16:20.100]   They're on territorial aims.
[01:16:20.100 --> 01:16:21.100]   Yeah.
[01:16:21.100 --> 01:16:22.340]   Oh, it's sunshine.
[01:16:22.340 --> 01:16:23.340]   South China Sea.
[01:16:23.340 --> 01:16:27.980]   I'm more scared about Facebook getting my banking information.
[01:16:27.980 --> 01:16:30.980]   This is going to piss me off.
[01:16:30.980 --> 01:16:32.620]   I know that's why I brought it up.
[01:16:32.620 --> 01:16:34.900]   This story was so sensational.
[01:16:34.900 --> 01:16:36.980]   And that misleavingly done.
[01:16:36.980 --> 01:16:41.980]   And that's what TechCrunch said.
[01:16:41.980 --> 01:16:43.820]   They said that the Wall Street Journal over blew this story, that Facebook was looking
[01:16:43.820 --> 01:16:47.700]   for a chat to partner with banks to your chatbots.
[01:16:47.700 --> 01:16:51.980]   But the journal said in its headline anyway, "Give us your data.
[01:16:51.980 --> 01:16:52.980]   Facebook to banks.
[01:16:52.980 --> 01:16:53.980]   Give us your data.
[01:16:53.980 --> 01:16:54.980]   We'll give you our users."
[01:16:54.980 --> 01:17:03.700]   This is why I won't pay for the Wall Street Journal is this kind of technopanic agenda-based
[01:17:03.700 --> 01:17:05.620]   pseudojournalism against technology.
[01:17:05.620 --> 01:17:06.620]   It pisses me off.
[01:17:06.620 --> 01:17:07.620]   Well, come on.
[01:17:07.620 --> 01:17:14.900]   You think that Emily Glazier and Deepa, Sethrahman, Anna Maria, and Rocha, and Adriatus?
[01:17:14.900 --> 01:17:17.060]   They probably didn't write their own headline.
[01:17:17.060 --> 01:17:18.060]   That's why.
[01:17:18.060 --> 01:17:19.060]   So the headline let's throw out.
[01:17:19.060 --> 01:17:20.540]   Headlines are always should be thrown out, right?
[01:17:20.540 --> 01:17:21.540]   Because headline writers...
[01:17:21.540 --> 01:17:24.620]   Well, what we told the headline is how the editors have an impact on the story and know
[01:17:24.620 --> 01:17:26.380]   what's going to get passed around.
[01:17:26.380 --> 01:17:27.380]   So what's the most important thing?
[01:17:27.380 --> 01:17:28.380]   So what's the story say?
[01:17:28.380 --> 01:17:32.660]   The story says that social media giant has asked large US banks to share detailed financial
[01:17:32.660 --> 01:17:36.580]   information about their customers, including card transactions and checking accounts.
[01:17:36.580 --> 01:17:41.100]   And it's not about balances as part of an effort to offer new services to users.
[01:17:41.100 --> 01:17:43.380]   Now write this to write rates.
[01:17:43.380 --> 01:17:49.860]   Facebook, like many services elsewhere, including all over China, is looking at offering a chat
[01:17:49.860 --> 01:17:52.980]   as direct customer service, including banking.
[01:17:52.980 --> 01:17:54.260]   Not a big deal at all.
[01:17:54.260 --> 01:17:55.820]   It's not about Google's data.
[01:17:55.820 --> 01:17:57.700]   They're trying to make it into scare words.
[01:17:57.700 --> 01:18:01.700]   The lead could have got rewritten like the head, but it's irresponsible.
[01:18:01.700 --> 01:18:06.700]   Yeah, in fact, the rest of the article goes on to say Facebook's basically.
[01:18:06.700 --> 01:18:10.980]   And imagine it would you like this considering a feature where a Facebook messenger would
[01:18:10.980 --> 01:18:14.220]   show you're checking account balance, maybe fraud alerts.
[01:18:14.220 --> 01:18:15.460]   If you ask for it.
[01:18:15.460 --> 01:18:16.460]   Yeah.
[01:18:16.460 --> 01:18:17.460]   If you...
[01:18:17.460 --> 01:18:22.020]   Yeah, first of all, you have to say I am a customer of US bank Corp and I want this
[01:18:22.020 --> 01:18:26.620]   to be in my messenger or let me follow the chatbot.
[01:18:26.620 --> 01:18:30.060]   Now I don't know why Facebook's the most important thing is look at all these things you can
[01:18:30.060 --> 01:18:31.060]   do on WeChat.
[01:18:31.060 --> 01:18:32.060]   Well, we should have that.
[01:18:32.060 --> 01:18:33.900]   So Facebook tries to do that and...
[01:18:33.900 --> 01:18:34.900]   Right.
[01:18:34.900 --> 01:18:40.860]   Data privacy is a sticking point in the bank's conversations with Facebook said people familiar
[01:18:40.860 --> 01:18:41.860]   with the matter.
[01:18:41.860 --> 01:18:46.380]   In other words, banks are pushing back saying one large US bank pulled away from the talks
[01:18:46.380 --> 01:18:47.940]   due to privacy concerns.
[01:18:47.940 --> 01:18:50.380]   Which is a PR question.
[01:18:50.380 --> 01:18:54.780]   No, we know the journal is just like this.
[01:18:54.780 --> 01:18:58.540]   You don't know if it's a PR question or if Facebook's asking for more than it might need
[01:18:58.540 --> 01:18:59.540]   for this.
[01:18:59.540 --> 01:19:03.020]   And understanding your customer data is...
[01:19:03.020 --> 01:19:04.940]   That is your gold right now.
[01:19:04.940 --> 01:19:07.420]   All the companies think that that's their big thing.
[01:19:07.420 --> 01:19:09.980]   I don't necessarily agree with all of it.
[01:19:09.980 --> 01:19:15.060]   But Facebook could be asking for more information than they want to give or to be the point
[01:19:15.060 --> 01:19:16.060]   of control for this.
[01:19:16.060 --> 01:19:18.220]   And the banks are like, "Yeah, you know what?
[01:19:18.220 --> 01:19:20.980]   If we give you this, we actually want a little bit more in return."
[01:19:20.980 --> 01:19:23.380]   So it could be PR or negotiation.
[01:19:23.380 --> 01:19:26.220]   By the way, we know Facebook would ask for that.
[01:19:26.220 --> 01:19:27.220]   I mean, that...
[01:19:27.220 --> 01:19:28.220]   Well, I wouldn't they?
[01:19:28.220 --> 01:19:29.220]   Right.
[01:19:29.220 --> 01:19:30.220]   Of course they're going to ask for it.
[01:19:30.220 --> 01:19:31.860]   They may not expect they'll get it.
[01:19:31.860 --> 01:19:34.980]   Yeah, yeah, but they're going to say, "Give us all..."
[01:19:34.980 --> 01:19:35.980]   They're going to start.
[01:19:35.980 --> 01:19:39.860]   The conversation starts with, "Hey, give us all this information and we'll give you this."
[01:19:39.860 --> 01:19:42.540]   And then the bank says, "Oh, that's our customers."
[01:19:42.540 --> 01:19:45.940]   You're jumping right over right there.
[01:19:45.940 --> 01:19:48.740]   That's what TechCrunch gets better than the Wall Street Journal does.
[01:19:48.740 --> 01:19:52.100]   This was the way the Wall Street Journal presents it is, "Give us all this information and
[01:19:52.100 --> 01:19:53.100]   we'll offer you something."
[01:19:53.100 --> 01:19:57.460]   The way TechCrunch presents it is, "No, I can go, I as a customer can ask for my balance
[01:19:57.460 --> 01:20:03.100]   or ask for my credit card purchases through chat and I get it back through the platform,
[01:20:03.100 --> 01:20:04.420]   through Facebook."
[01:20:04.420 --> 01:20:08.060]   That's not Facebook asking them for data that's offering a service to users.
[01:20:08.060 --> 01:20:09.060]   I could be wrong.
[01:20:09.060 --> 01:20:10.820]   I don't know the details here.
[01:20:10.820 --> 01:20:13.820]   But TechCrunch did a far more reasonable version.
[01:20:13.820 --> 01:20:19.100]   TechCrunch just repeated the Facebook spokesperson's point of view.
[01:20:19.100 --> 01:20:21.020]   That's all TechCrunch did.
[01:20:21.020 --> 01:20:22.980]   Which I have a little...
[01:20:22.980 --> 01:20:25.100]   No, no, no, no, no, no.
[01:20:25.100 --> 01:20:27.300]   Because yeah, Facebook really wants to do this.
[01:20:27.300 --> 01:20:28.300]   We know the disclosure.
[01:20:28.300 --> 01:20:33.020]   And by the way, no one thinks that you are somehow magically influenced by Facebook.
[01:20:33.020 --> 01:20:34.020]   That's why I do disclosures by Facebook.
[01:20:34.020 --> 01:20:35.020]   By Facebook.
[01:20:35.020 --> 01:20:36.020]   By Facebook.
[01:20:36.020 --> 01:20:37.020]   Yeah, I do.
[01:20:37.020 --> 01:20:38.020]   Let them do this.
[01:20:38.020 --> 01:20:39.020]   Let them do this.
[01:20:39.020 --> 01:20:40.500]   From Facebook, and I receive no money from them and I'm independent of them.
[01:20:40.500 --> 01:20:45.300]   And we also know that you have a bias toward Facebook because you like it.
[01:20:45.300 --> 01:20:47.220]   I have a bias toward technology.
[01:20:47.220 --> 01:20:48.220]   Yeah.
[01:20:48.220 --> 01:20:49.420]   Well, I don't think this is any technology.
[01:20:49.420 --> 01:20:50.420]   I think...
[01:20:50.420 --> 01:20:51.420]   Oh, yes it is.
[01:20:51.420 --> 01:20:52.420]   Oh, no, no, no.
[01:20:52.420 --> 01:20:54.660]   There's a clear track record.
[01:20:54.660 --> 01:20:56.660]   Facebook has a clear track record.
[01:20:56.660 --> 01:20:58.660]   No, it's not moral panic.
[01:20:58.660 --> 01:20:59.660]   It's not moral panic.
[01:20:59.660 --> 01:21:03.100]   That's Facebook has a clear track record of invasiting our privacy.
[01:21:03.100 --> 01:21:04.500]   It's why I'm not on Facebook.
[01:21:04.500 --> 01:21:06.900]   It's a loathsome operation.
[01:21:06.900 --> 01:21:07.900]   And I wouldn't...
[01:21:07.900 --> 01:21:11.420]   Meanwhile, the journalists, the journalists who want to save you from all this, the journalists
[01:21:11.420 --> 01:21:16.380]   who exposed Cambridge Analytica, the journalists who are against all of this are begging Facebook
[01:21:16.380 --> 01:21:19.820]   for exception so they can make up fake accounts and get your data.
[01:21:19.820 --> 01:21:20.980]   Right.
[01:21:20.980 --> 01:21:23.780]   So that's why I'm not on Facebook because everybody wants to use...
[01:21:23.780 --> 01:21:24.780]   But who's the bad guy in that?
[01:21:24.780 --> 01:21:26.540]   The journalists.
[01:21:26.540 --> 01:21:29.140]   Facebook is also a participant.
[01:21:29.140 --> 01:21:31.100]   The Facebook's holding the rules.
[01:21:31.100 --> 01:21:32.340]   Facebook's saying no.
[01:21:32.340 --> 01:21:35.740]   Okay, but that's mostly because they want to keep it to themselves.
[01:21:35.740 --> 01:21:39.900]   Because Facebook's real advantage.
[01:21:39.900 --> 01:21:44.740]   Facebook's real advantage is having all this information so they can use it for advertising.
[01:21:44.740 --> 01:21:49.420]   Well, let's go back to the point that they're not going to use any banking data for advertising.
[01:21:49.420 --> 01:21:50.820]   They've vowed that.
[01:21:50.820 --> 01:21:51.820]   They didn't vow it.
[01:21:51.820 --> 01:21:56.100]   Facebook spokesperson Elizabeth Diana tells TechCrunch.
[01:21:56.100 --> 01:21:58.300]   It's not asking for credit card transaction data for banks.
[01:21:58.300 --> 01:22:00.380]   They were getting such trouble-fated that.
[01:22:00.380 --> 01:22:04.580]   They already get credit card transaction data.
[01:22:04.580 --> 01:22:09.060]   There are retailers who sell their credit card transaction data to Facebook.
[01:22:09.060 --> 01:22:10.060]   So they already have some...
[01:22:10.060 --> 01:22:14.580]   Two advertisers as well and media companies as well.
[01:22:14.580 --> 01:22:17.260]   I was at a company where we bought it.
[01:22:17.260 --> 01:22:22.820]   But I will say that things like your bank balance being at Facebook is a little worrisome
[01:22:22.820 --> 01:22:24.340]   because Facebook could turn around.
[01:22:24.340 --> 01:22:28.580]   People already use it for things like impacting and deciding your credit score.
[01:22:28.580 --> 01:22:31.700]   What happens if Facebook has this information?
[01:22:31.700 --> 01:22:35.900]   Not for advertising, but just to give people a more complete picture of their user base.
[01:22:35.900 --> 01:22:40.780]   Facebook already works with PayPal in 40 countries to let users get receipts via a messenger
[01:22:40.780 --> 01:22:42.660]   for their purchases.
[01:22:42.660 --> 01:22:45.180]   And I suppose it's possible that Facebook goes, "No, no.
[01:22:45.180 --> 01:22:47.180]   I don't want to see that information."
[01:22:47.180 --> 01:22:52.980]   Listen, Google, Google gets all this now and I'm very grateful because I get my Gmail
[01:22:52.980 --> 01:22:53.980]   too.
[01:22:53.980 --> 01:22:55.620]   It's all on Gmail and I get my...
[01:22:55.620 --> 01:23:01.180]   Oh, your trip to Buenos Aires and Google figures it out and they put the airline reservation
[01:23:01.180 --> 01:23:04.020]   and they put the Google rise.
[01:23:04.020 --> 01:23:06.740]   Yeah, so I stopped doing that hotel all in there.
[01:23:06.740 --> 01:23:08.420]   That's one of the reasons I don't use Gmail anymore.
[01:23:08.420 --> 01:23:09.940]   I use my own email service.
[01:23:09.940 --> 01:23:13.940]   But I do forward to trip it any travel plans I want.
[01:23:13.940 --> 01:23:19.780]   In other words, I actively, instead of passively letting these companies scan my Gmail, I actively
[01:23:19.780 --> 01:23:24.820]   send forward and you can do that with TripIt, forward the emails to them and that's I find
[01:23:24.820 --> 01:23:27.740]   sufficiently convenient.
[01:23:27.740 --> 01:23:29.140]   I think it's not unreasonable.
[01:23:29.140 --> 01:23:32.700]   Now the sad thing is, and the only reason we're fighting about this is because you get
[01:23:32.700 --> 01:23:35.540]   to choose what you want to do, Jeff, and I get to choose what I want to do.
[01:23:35.540 --> 01:23:43.900]   But the vast majority of Facebook users are unaware of whatever the consequences are.
[01:23:43.900 --> 01:23:46.100]   And so they need to be protected.
[01:23:46.100 --> 01:23:54.380]   I think they need to be protected against Facebook's over weaning desire for their personal information.
[01:23:54.380 --> 01:23:56.740]   But they're not going to be because...
[01:23:56.740 --> 01:24:03.060]   In Google, yes, they sell advertising, but Google in many ways uses data to make better
[01:24:03.060 --> 01:24:04.380]   products.
[01:24:04.380 --> 01:24:08.820]   Facebook uses data to sell you at a higher rate to advertisers.
[01:24:08.820 --> 01:24:12.500]   So I mean, there's a slight difference in trust.
[01:24:12.500 --> 01:24:14.340]   You get something from Facebook.
[01:24:14.340 --> 01:24:17.620]   I think obviously the reason people are on Facebook is they consider it...
[01:24:17.620 --> 01:24:21.580]   Because I think most people now understand that there is a leakage of personal information,
[01:24:21.580 --> 01:24:24.980]   there's been enough attention placed that they're willing to do that though because
[01:24:24.980 --> 01:24:25.980]   they don't want to leave Facebook.
[01:24:25.980 --> 01:24:26.980]   That's where all their family and friends are.
[01:24:26.980 --> 01:24:27.980]   And that's how they stand up.
[01:24:27.980 --> 01:24:30.700]   Well, the difference is that I'm sure you're getting publicly on Facebook.
[01:24:30.700 --> 01:24:31.940]   You're getting something of value.
[01:24:31.940 --> 01:24:32.940]   I think Stephanie...
[01:24:32.940 --> 01:24:34.580]   Oh, there she is.
[01:24:34.580 --> 01:24:36.100]   I thought Stacy just fainted.
[01:24:36.100 --> 01:24:37.100]   No, no.
[01:24:37.100 --> 01:24:38.860]   She walked off the show.
[01:24:38.860 --> 01:24:42.580]   So that's it.
[01:24:42.580 --> 01:24:46.420]   Facebook's statement today, according to John Constein, write in TechCrunch, shows more
[01:24:46.420 --> 01:24:52.460]   scruples than Google, which last year's struck ad measurement data deals with data brokers
[01:24:52.460 --> 01:24:56.580]   that have access to 70% of credit and debit card transactions in the US.
[01:24:56.580 --> 01:25:00.020]   That led to a formal complaint from the FTC.
[01:25:00.020 --> 01:25:01.020]   Correction.
[01:25:01.020 --> 01:25:02.020]   Google tells us...
[01:25:02.020 --> 01:25:03.020]   Who the FTC from Epic?
[01:25:03.020 --> 01:25:04.020]   Their big difference.
[01:25:04.020 --> 01:25:05.020]   Right.
[01:25:05.020 --> 01:25:06.020]   Epic complains about everything.
[01:25:06.020 --> 01:25:07.540]   Yeah, Epic complains about everything.
[01:25:07.540 --> 01:25:09.860]   The electronic privacy information center.
[01:25:09.860 --> 01:25:10.860]   Correction.
[01:25:10.860 --> 01:25:16.540]   It tells us the deals are for ad measurement data, not ad targeting, as we originally published.
[01:25:16.540 --> 01:25:24.660]   So, you know, I guess ultimately because of the warring stories here, you believe what
[01:25:24.660 --> 01:25:28.220]   you want to believe or what evidence has led you to believe.
[01:25:28.220 --> 01:25:31.380]   And I believe fully that Facebook would love this information.
[01:25:31.380 --> 01:25:37.500]   I also believe that banks like a lot of companies are saying, "Well, that's a value to us.
[01:25:37.500 --> 01:25:38.900]   What are you going to give us?
[01:25:38.900 --> 01:25:41.180]   We're not just going to give up the information."
[01:25:41.180 --> 01:25:44.780]   But I think if they were given something of value, they probably would.
[01:25:44.780 --> 01:25:49.620]   There are privacy restrictions on what banks can tell people about, "I would presume about
[01:25:49.620 --> 01:25:50.780]   my account, maybe not."
[01:25:50.780 --> 01:25:52.780]   I don't know.
[01:25:52.780 --> 01:25:57.340]   We're all kind of screwed when it comes to privacy one way or the other.
[01:25:57.340 --> 01:25:59.900]   I mean, I can quit Facebook and stop using Gmail.
[01:25:59.900 --> 01:26:05.300]   It's not going to particularly make a difference in how much these companies know about me.
[01:26:05.300 --> 01:26:08.900]   Not that I care, I got nothing to hide, but I still think they should be.
[01:26:08.900 --> 01:26:11.740]   I think they need to be held a little bit accountable, don't you?
[01:26:11.740 --> 01:26:12.940]   Come on, you got to admit that.
[01:26:12.940 --> 01:26:16.140]   Why don't you go to Alex Jones' rant about it?
[01:26:16.140 --> 01:26:18.340]   Oh, I'm not going that far.
[01:26:18.340 --> 01:26:20.940]   I think I'm being very reasonable, Jeff.
[01:26:20.940 --> 01:26:22.580]   I was trying to say that.
[01:26:22.580 --> 01:26:23.580]   I'm being very reasonable.
[01:26:23.580 --> 01:26:27.900]   I don't think that's unreasonable to say, "This is Facebook's business model."
[01:26:27.900 --> 01:26:33.340]   And Mark Zuckerberg has a long and tragic history of moving fast and breaking things.
[01:26:33.340 --> 01:26:34.900]   And then apologizing later.
[01:26:34.900 --> 01:26:36.860]   Come on, that's their business model.
[01:26:36.860 --> 01:26:37.860]   They never even deny it.
[01:26:37.860 --> 01:26:43.540]   In fact, somebody was telling me we had some kids in here who just got on Facebook and
[01:26:43.540 --> 01:26:44.820]   they were talking to a Facebook guy.
[01:26:44.820 --> 01:26:45.940]   He said, "Yeah."
[01:26:45.940 --> 01:26:51.420]   So now our motto is move fast and break a few less things.
[01:26:51.420 --> 01:26:57.100]   Even internally they're saying that.
[01:26:57.100 --> 01:27:02.020]   It's fewer things, by the way.
[01:27:02.020 --> 01:27:05.220]   What are we going to do in full war story?
[01:27:05.220 --> 01:27:06.380]   Which one?
[01:27:06.380 --> 01:27:07.380]   In full war story?
[01:27:07.380 --> 01:27:08.580]   Oh, that's right.
[01:27:08.580 --> 01:27:10.260]   We did that before the show started.
[01:27:10.260 --> 01:27:11.660]   Yeah, we hadn't done that yet.
[01:27:11.660 --> 01:27:12.660]   It's censorship.
[01:27:12.660 --> 01:27:15.140]   Alex Jones in full wars.
[01:27:15.140 --> 01:27:19.780]   First of all, I became first aware of in full wars when a lot of our audience members
[01:27:19.780 --> 01:27:21.740]   mentioned it as a fun thing to read.
[01:27:21.740 --> 01:27:23.940]   They really thought of it as entertainment.
[01:27:23.940 --> 01:27:26.900]   Now this is probably eight years ago.
[01:27:26.900 --> 01:27:27.900]   That's how people in Austin.
[01:27:27.900 --> 01:27:29.820]   So he's from Austin.
[01:27:29.820 --> 01:27:36.780]   There used to be signs around cafes and stuff and we were just giggle.
[01:27:36.780 --> 01:27:37.780]   It was a joke.
[01:27:37.780 --> 01:27:44.060]   Yeah, in full wars itself tells you kind of the name of the site kind of tells you.
[01:27:44.060 --> 01:27:48.100]   It was always a little bit of a conspiracy theory kind of nutty site.
[01:27:48.100 --> 01:27:50.100]   I was trying to argue it was weekly world news.
[01:27:50.100 --> 01:27:52.100]   It was aliens coming down.
[01:27:52.100 --> 01:27:55.940]   And even in his divorce proceeding, Alex Jones said, "I play a character."
[01:27:55.940 --> 01:27:59.300]   I mean, it's pretty patently a character.
[01:27:59.300 --> 01:28:05.340]   However, some of the stuff he said has been so scurrilous and damaging in particular
[01:28:05.340 --> 01:28:12.340]   the horrific things he said about the parents of children murdered in Sandy Hook.
[01:28:12.340 --> 01:28:13.340]   Wait, wait, wait.
[01:28:13.340 --> 01:28:16.700]   Okay, I have to, I'm not even going to let you finish.
[01:28:16.700 --> 01:28:19.580]   I'm going to pull a Kanye.
[01:28:19.580 --> 01:28:28.300]   What's so damaging is that we have someone in power who either A doesn't actually recognize
[01:28:28.300 --> 01:28:33.500]   that this guy is just a cooke playing a part in his legitimized him.
[01:28:33.500 --> 01:28:36.300]   That's what's so freaking scary.
[01:28:36.300 --> 01:28:40.980]   Can I slightly see if you agree with this, slightly change the slant of that.
[01:28:40.980 --> 01:28:42.900]   It's the same roughly.
[01:28:42.900 --> 01:28:47.060]   But this comes from Corey Doctor who read a great piece something called about Mark Zuckerberg's
[01:28:47.060 --> 01:28:53.860]   oily rag fire in which he says something I thought was quite astute, which was that
[01:28:53.860 --> 01:29:00.460]   in 2016, what really happened was very targeted advertising, mostly on Facebook, some other
[01:29:00.460 --> 01:29:10.260]   places empowered a slimy underbelly of the American people to let their true feelings
[01:29:10.260 --> 01:29:14.500]   of racism and out.
[01:29:14.500 --> 01:29:20.980]   And in fact got them to vote, something that they hadn't done ever in years, if ever.
[01:29:20.980 --> 01:29:29.300]   And as a result galvanize this, what is it 30%, 20%, 10%, I don't know, but enough people,
[01:29:29.300 --> 01:29:35.660]   especially given the apathy and the lack of voting from everybody else that got the got
[01:29:35.660 --> 01:29:40.060]   somebody in power that supported this point of view.
[01:29:40.060 --> 01:29:46.340]   And if that hadn't happened, if this slimy underbelly hadn't been empowered, then what
[01:29:46.340 --> 01:29:50.340]   Alex Jones says and does would be weekly world news.
[01:29:50.340 --> 01:29:52.260]   It would be a side show.
[01:29:52.260 --> 01:29:57.780]   But the problem is not so much that Alex Jones exists, but that the people who believe Alex
[01:29:57.780 --> 01:30:04.940]   Jones and QAnon and all this bop, Bogosity now suddenly are active and feel empowered
[01:30:04.940 --> 01:30:06.340]   and are acting on it.
[01:30:06.340 --> 01:30:10.220]   You have Charlottesville and we're going to have on the anniversary of Charlottesville something
[01:30:10.220 --> 01:30:15.900]   possibly worse in DC soon that those people have been empowered by all this.
[01:30:15.900 --> 01:30:18.700]   And that's what's, I don't think it's the man in the White House.
[01:30:18.700 --> 01:30:23.820]   I think it's that these people that these, he's empowered by these people and these people
[01:30:23.820 --> 01:30:25.740]   have somehow been activated.
[01:30:25.740 --> 01:30:31.780]   Somebody added some water and dehydrated them and they voted and they're active and
[01:30:31.780 --> 01:30:35.500]   they're marching around with Nazi flags and Tiki torches.
[01:30:35.500 --> 01:30:38.660]   It's violence repulsive, but I don't think you blame Alex Jones for it.
[01:30:38.660 --> 01:30:42.580]   I think he's always been there.
[01:30:42.580 --> 01:30:48.300]   He's got a light on, there's no water they throw on it was gasoline and he's got a match.
[01:30:48.300 --> 01:30:50.300]   But he's always, that match has always been there.
[01:30:50.300 --> 01:30:51.300]   Yeah, that's true.
[01:30:51.300 --> 01:30:58.100]   And the other factor here is media is that we amplified, we were manipulated and amplified
[01:30:58.100 --> 01:30:59.100]   this.
[01:30:59.100 --> 01:31:05.100]   We were used, Facebook was used, Twitter is used and it's the weakness in democracy that
[01:31:05.100 --> 01:31:08.460]   we believe in openness and information and it's a weakness to play that the Russians
[01:31:08.460 --> 01:31:10.100]   played and the trolls played the same.
[01:31:10.100 --> 01:31:11.100]   Well, God bless it.
[01:31:11.100 --> 01:31:13.020]   I'm glad we live in an open country.
[01:31:13.020 --> 01:31:14.900]   I'm glad that there's the First Amendment.
[01:31:14.900 --> 01:31:17.380]   I'm glad that there's free speech.
[01:31:17.380 --> 01:31:27.780]   I think that the antidote to this gas fire, this dumpster fire is for the vast majority
[01:31:27.780 --> 01:31:34.260]   of right-minded, open-minded citizens to step forward and stop, get off their butts and
[01:31:34.260 --> 01:31:38.900]   start voting and start participating.
[01:31:38.900 --> 01:31:46.900]   Not, well, I mean, okay, I'd be wary of the desire to censor.
[01:31:46.900 --> 01:31:49.220]   The censorship is what government does.
[01:31:49.220 --> 01:31:56.020]   Editing and choosing is what both platforms and publishers and bar owners do.
[01:31:56.020 --> 01:31:57.020]   Get out of my bar.
[01:31:57.020 --> 01:31:58.020]   You're not welcome here.
[01:31:58.020 --> 01:31:59.780]   Well, what if it weren't Alex Jones?
[01:31:59.780 --> 01:32:02.500]   What was her 4chan?
[01:32:02.500 --> 01:32:04.340]   Because Alex Jones basically 4chan.
[01:32:04.340 --> 01:32:05.900]   QAnon is a 4chan.
[01:32:05.900 --> 01:32:06.900]   Is a 4chan law.
[01:32:06.900 --> 01:32:09.060]   4chan is an all-on Facebook.
[01:32:09.060 --> 01:32:10.060]   Right.
[01:32:10.060 --> 01:32:14.620]   But what if somebody came along and said, let's shut down 4chan.
[01:32:14.620 --> 01:32:16.420]   Well, no, no, no, that's different.
[01:32:16.420 --> 01:32:17.420]   That's different.
[01:32:17.420 --> 01:32:19.380]   The internet is open.
[01:32:19.380 --> 01:32:24.300]   There are dark corners of the internet where Alex Jones can find his cockroaches and convene.
[01:32:24.300 --> 01:32:25.860]   Nobody's shutting that down.
[01:32:25.860 --> 01:32:27.180]   Nobody's stopping his speech.
[01:32:27.180 --> 01:32:29.580]   Mark Zuckerberg is not responsible for free speech.
[01:32:29.580 --> 01:32:31.940]   He does not run the internet.
[01:32:31.940 --> 01:32:36.860]   He has a choice and a responsibility to decide proper behavior on his platform as does Jack
[01:32:36.860 --> 01:32:38.900]   Dorsey, which leads us to the real question.
[01:32:38.900 --> 01:32:40.540]   I'm curious, Stacy.
[01:32:40.540 --> 01:32:47.900]   What's your view is, did Facebook and Apple and Spotify and YouTube do the right thing
[01:32:47.900 --> 01:32:54.700]   in going ahead and killing eventually Alex Jones and the info wars sites?
[01:32:54.700 --> 01:32:57.220]   What do you think Jack Dorsey and Twitter should do?
[01:32:57.220 --> 01:33:01.140]   And Google, by the way, because Google+ still apparently carries so much tone on this content.
[01:33:01.140 --> 01:33:06.060]   So Twitter and Google+ are the two who have not yet done anything about that.
[01:33:06.060 --> 01:33:07.060]   So I think-
[01:33:07.060 --> 01:33:08.060]   So I think-
[01:33:08.060 --> 01:33:11.380]   I think pulling the podcast is fine.
[01:33:11.380 --> 01:33:16.580]   Alex Jones has his app, making it easier to find that sort of thing is fine.
[01:33:16.580 --> 01:33:21.020]   And they're apparently really excited and people download it and that's good.
[01:33:21.020 --> 01:33:23.660]   You can have a website.
[01:33:23.660 --> 01:33:30.340]   As for Twitter banning him, he does clearly violate or he has in the past violated their
[01:33:30.340 --> 01:33:32.140]   terms of service.
[01:33:32.140 --> 01:33:33.140]   So-
[01:33:33.140 --> 01:33:35.980]   They say he hasn't those days.
[01:33:35.980 --> 01:33:36.980]   This is the-
[01:33:36.980 --> 01:33:37.980]   I've got a hard-
[01:33:37.980 --> 01:33:42.580]   We need to go back and find tweets where he attacks somebody or he says he calls for
[01:33:42.580 --> 01:33:45.620]   violence or does some of the things that Twitter says are not okay.
[01:33:45.620 --> 01:33:49.620]   And if you can go back and find those, then you send those to Jack Dorsey and you say,
[01:33:49.620 --> 01:33:54.340]   "Look, let's say he didn't, but he's still doing billius and horrible things.
[01:33:54.340 --> 01:33:55.340]   Do you-
[01:33:55.340 --> 01:33:57.420]   He can be billius and horrible on Twitter.
[01:33:57.420 --> 01:33:58.420]   He can be.
[01:33:58.420 --> 01:33:59.420]   He can.
[01:33:59.420 --> 01:34:00.420]   He can.
[01:34:00.420 --> 01:34:01.420]   Everybody else says.
[01:34:01.420 --> 01:34:02.420]   Well, here's the different question.
[01:34:02.420 --> 01:34:06.140]   If Harvey Weinstein had a Twitter account, given everything he's done, none of which he
[01:34:06.140 --> 01:34:12.580]   did on a platform, is it within the rights of Facebook and Twitter to kill Harvey Weinstein's
[01:34:12.580 --> 01:34:14.660]   account because there won't be associated with it?"
[01:34:14.660 --> 01:34:15.660]   No.
[01:34:15.660 --> 01:34:16.660]   No.
[01:34:16.660 --> 01:34:17.660]   Okay.
[01:34:17.660 --> 01:34:19.460]   I don't think so.
[01:34:19.460 --> 01:34:27.620]   I think as a business putting info wars on Facebook, Facebook has the right to take it
[01:34:27.620 --> 01:34:28.820]   down if they want to.
[01:34:28.820 --> 01:34:30.580]   Twitter has the right to take it down if they want to.
[01:34:30.580 --> 01:34:34.940]   I think Facebook not taking it down or sorry, Facebook taking it down says something about
[01:34:34.940 --> 01:34:38.900]   Facebook that many people want it, you know, that are happy about.
[01:34:38.900 --> 01:34:39.900]   Same thing with Twitter.
[01:34:39.900 --> 01:34:42.940]   I don't, I think Apple deciding to say, "You know what?
[01:34:42.940 --> 01:34:46.820]   We're not going to act as a distribution platform for your podcast.
[01:34:46.820 --> 01:34:47.820]   Fine.
[01:34:47.820 --> 01:34:52.740]   As long as he's still got a space on the internet, a company should be able to say,
[01:34:52.740 --> 01:34:54.340]   "Yeah, get out of my bar."
[01:34:54.340 --> 01:34:55.340]   I agree.
[01:34:55.340 --> 01:34:59.100]   It would be wrong, however, for Google to censor search results.
[01:34:59.100 --> 01:35:00.100]   Yes.
[01:35:00.100 --> 01:35:01.100]   Of course.
[01:35:01.100 --> 01:35:02.660]   Well, they're forced to do it by the EU.
[01:35:02.660 --> 01:35:03.660]   Okay.
[01:35:03.660 --> 01:35:10.220]   This is interesting because remember when Matthew Prince of CloudFlare talked about-
[01:35:10.220 --> 01:35:11.980]   This is a challenging one.
[01:35:11.980 --> 01:35:12.980]   Yeah.
[01:35:12.980 --> 01:35:13.980]   Yeah.
[01:35:13.980 --> 01:35:14.980]   Yeah.
[01:35:14.980 --> 01:35:16.620]   He talked about removing who basically-
[01:35:16.620 --> 01:35:17.620]   So the Daily Stormer.
[01:35:17.620 --> 01:35:21.700]   So the Daily Stormer website was using CloudFlare for DDoS protection.
[01:35:21.700 --> 01:35:26.820]   Initially, Matthew Prince said, "We're not going to do anything about that.
[01:35:26.820 --> 01:35:29.820]   We're an open platform and we don't want to get in the business of deciding which
[01:35:29.820 --> 01:35:32.300]   content we should protect."
[01:35:32.300 --> 01:35:38.500]   They're considerable comment, including, by the way, to be perfectly blunt.
[01:35:38.500 --> 01:35:41.940]   They were an advertiser at the time and we decided to decline their advertising as a
[01:35:41.940 --> 01:35:49.300]   result, which I have really- It was a very difficult decision for me.
[01:35:49.300 --> 01:35:50.300]   Yeah.
[01:35:50.300 --> 01:35:54.940]   Short- The day we decided not to do that coincidentally, he said, "All right, we're
[01:35:54.940 --> 01:35:57.300]   going to block them."
[01:35:57.300 --> 01:36:01.500]   By the way, completely understood Matthew Prince's point of view and as I'm arguing
[01:36:01.500 --> 01:36:05.860]   here, did not disagree with it.
[01:36:05.860 --> 01:36:10.820]   But we decided not to do the advertising mostly because I felt like that would be counterproductive
[01:36:10.820 --> 01:36:11.820]   for everybody.
[01:36:11.820 --> 01:36:16.660]   It would be counterproductive for CloudFlare because it would just stimulate a big battle
[01:36:16.660 --> 01:36:18.740]   over this and it would be counterproductive for us.
[01:36:18.740 --> 01:36:21.420]   We'd be caught in the crossfire.
[01:36:21.420 --> 01:36:23.940]   Since, by the way, we brought them back.
[01:36:23.940 --> 01:36:26.700]   We said, "Yes, we'll be glad to take your advertising now."
[01:36:26.700 --> 01:36:32.100]   It was not, in both cases, it was neither a condemnation nor an endorsement of his decision.
[01:36:32.100 --> 01:36:37.340]   I understood his decision, both directions, but just not thinking that doing the advertising
[01:36:37.340 --> 01:36:41.980]   at that point would be not good for anybody.
[01:36:41.980 --> 01:36:44.780]   So I said, "No, we're not going to take your money here because you don't believe
[01:36:44.780 --> 01:36:45.780]   it.
[01:36:45.780 --> 01:36:49.300]   You don't want to run an ad now and I don't want to do it."
[01:36:49.300 --> 01:36:55.020]   So I should probably not even mention that, but in interest of clarity, I will.
[01:36:55.020 --> 01:36:56.980]   So Stacey, the author will agree.
[01:36:56.980 --> 01:36:57.980]   That's a challenging thing.
[01:36:57.980 --> 01:36:58.980]   I don't know what I would do.
[01:36:58.980 --> 01:37:00.460]   I will do every matching princess point of position.
[01:37:00.460 --> 01:37:01.980]   Let me throw another thing out here.
[01:37:01.980 --> 01:37:06.180]   So Jack said something about, "We don't want us to come outside pressure."
[01:37:06.180 --> 01:37:11.380]   And I wrote a piece the other day saying that, "No, what's really happening here I think
[01:37:11.380 --> 01:37:17.460]   is that society is negotiating its norms and the platforms would love us to do that with
[01:37:17.460 --> 01:37:18.460]   a rule set."
[01:37:18.460 --> 01:37:19.460]   Here's the rule to follow.
[01:37:19.460 --> 01:37:20.460]   No, we're going to do that anecdotally.
[01:37:20.460 --> 01:37:21.460]   We're going to do that anecdotally.
[01:37:21.460 --> 01:37:22.460]   We're going to pass it through that.
[01:37:22.460 --> 01:37:24.460]   We'll just do what you say.
[01:37:24.460 --> 01:37:25.460]   Right.
[01:37:25.460 --> 01:37:26.580]   So we're going to do that instead anecdotally.
[01:37:26.580 --> 01:37:30.620]   And what society is saying, what a large portion of society is saying is, if you have
[01:37:30.620 --> 01:37:34.500]   a rule set that leaves info wars in with all their abilities behavior, then it's a bad
[01:37:34.500 --> 01:37:35.500]   rule set.
[01:37:35.500 --> 01:37:37.380]   No, info wars is over the line.
[01:37:37.380 --> 01:37:39.940]   You figure out what the line is, people, but get rid of it.
[01:37:39.940 --> 01:37:43.340]   And so yes, there was outside pressure, but I think that it actually was the system beginning
[01:37:43.340 --> 01:37:44.340]   to work.
[01:37:44.340 --> 01:37:47.380]   It was society saying, "We're going to identify a line.
[01:37:47.380 --> 01:37:49.860]   We're going to identify info wars on the wrong side of it."
[01:37:49.860 --> 01:37:53.060]   Now we'll figure out the rest later, but we think it's a bad thing.
[01:37:53.060 --> 01:37:56.020]   We think you shouldn't stand up and distribute it.
[01:37:56.020 --> 01:38:00.580]   And so it was democracy, it was the market working in a way.
[01:38:00.580 --> 01:38:02.820]   So that happened with pornography.
[01:38:02.820 --> 01:38:08.460]   But still, there are purveyors of porn, much to many people chagrin at a certain point
[01:38:08.460 --> 01:38:09.460]   in time.
[01:38:09.460 --> 01:38:13.300]   So you could be saying that that line may have been drawn and Twitter may be like, "You
[01:38:13.300 --> 01:38:14.300]   know what?
[01:38:14.300 --> 01:38:15.300]   I'm okay distributing.
[01:38:15.300 --> 01:38:18.580]   It's the equivalent of being I'm okay with distributing porn."
[01:38:18.580 --> 01:38:23.020]   So I mean, again, I think it's a legitimate thing.
[01:38:23.020 --> 01:38:24.020]   But it stands to take.
[01:38:24.020 --> 01:38:30.140]   I may not like it, but it's their right and they can do it.
[01:38:30.140 --> 01:38:36.580]   There is an argument that you want to be careful about banning stuff because it's unpopular
[01:38:36.580 --> 01:38:38.660]   or because somebody doesn't like it.
[01:38:38.660 --> 01:38:39.660]   But that's fine.
[01:38:39.660 --> 01:38:40.660]   But this feels moral.
[01:38:40.660 --> 01:38:47.140]   So it's moral to you, but maybe to some, maybe to Alex Jones, it doesn't.
[01:38:47.140 --> 01:38:54.300]   I mean, I know I would, I don't want to be the sit on the high throne of moral judgment.
[01:38:54.300 --> 01:39:02.300]   I think inciting the harassment of the parents of murdered children, no matter how you cut
[01:39:02.300 --> 01:39:03.300]   it.
[01:39:03.300 --> 01:39:04.300]   It's pretty reprehensible.
[01:39:04.300 --> 01:39:05.300]   Yeah.
[01:39:05.300 --> 01:39:06.300]   Yeah.
[01:39:06.300 --> 01:39:09.060]   And B, and you are the company you keep.
[01:39:09.060 --> 01:39:14.020]   And at some level, as I say, the problem is Zuckerberg thought he was responsible for
[01:39:14.020 --> 01:39:15.300]   free speech.
[01:39:15.300 --> 01:39:18.100]   And that's only if he runs the whole internet, which maybe he wants to do in some countries
[01:39:18.100 --> 01:39:19.100]   and does.
[01:39:19.100 --> 01:39:20.540]   But that's not interesting.
[01:39:20.540 --> 01:39:25.740]   And even in the United States, in many cases, Facebook is what people do on the internet.
[01:39:25.740 --> 01:39:30.540]   I mean, he's rapidly getting that moral responsibility whether he will.
[01:39:30.540 --> 01:39:36.420]   But if we go there, the economists had a piece today that almost said, treat them as government,
[01:39:36.420 --> 01:39:41.780]   in that case, you could, you'd be requiring Facebook to distribute in for wars.
[01:39:41.780 --> 01:39:44.580]   That's not a world I want either.
[01:39:44.580 --> 01:39:45.980]   Very challenging.
[01:39:45.980 --> 01:39:49.380]   It's all that's the ultimate lesson here.
[01:39:49.380 --> 01:39:51.860]   I think that there is this kind of presumption that these are easy decisions.
[01:39:51.860 --> 01:39:53.380]   Why the hell did they do them before?
[01:39:53.380 --> 01:39:54.380]   These are hard decisions.
[01:39:54.380 --> 01:39:56.500]   They have many implications.
[01:39:56.500 --> 01:39:57.820]   There are hidden dangers here.
[01:39:57.820 --> 01:39:58.820]   Yeah.
[01:39:58.820 --> 01:40:04.060]   I think they're also a wide variety of opinions and users.
[01:40:04.060 --> 01:40:11.420]   And yeah, I don't think this is not a black and white thing.
[01:40:11.420 --> 01:40:14.540]   We love black and white computers love black and white.
[01:40:14.540 --> 01:40:18.980]   You know, computer purveyors and systems online love it because you can make it work.
[01:40:18.980 --> 01:40:23.020]   But really, this is stuff you should be having conversations about.
[01:40:23.020 --> 01:40:24.020]   Exactly.
[01:40:24.020 --> 01:40:28.700]   I thought I'd ask Stacy about this.
[01:40:28.700 --> 01:40:31.660]   So there's two FCC stories in the harbor.
[01:40:31.660 --> 01:40:42.180]   One, the FCC, Ajit Pai is blaming his Obama appointed CIO for his story that the FCC comments
[01:40:42.180 --> 01:40:44.180]   say it was hacked.
[01:40:44.180 --> 01:40:50.820]   But instead it was DDoSed as the investigative report is proven.
[01:40:50.820 --> 01:40:57.100]   DDoSed by a lot of Americans commenting that they wanted to preserve net neutrality.
[01:40:57.100 --> 01:41:01.180]   Ajit Pai said, "Hey, I said it was hacked, but that wasn't my fault.
[01:41:01.180 --> 01:41:04.380]   It was that Obama guy told me that."
[01:41:04.380 --> 01:41:05.380]   Okay.
[01:41:05.380 --> 01:41:06.460]   That's, okay.
[01:41:06.460 --> 01:41:08.460]   That's patently bogus.
[01:41:08.460 --> 01:41:09.460]   False.
[01:41:09.460 --> 01:41:10.460]   Ajit Pai.
[01:41:10.460 --> 01:41:11.460]   So.
[01:41:11.460 --> 01:41:13.860]   But here's the other story.
[01:41:13.860 --> 01:41:23.060]   The FCC has now sided with Google fiber over Comcast on one touch make ready, which you're
[01:41:23.060 --> 01:41:24.060]   going to have to explain.
[01:41:24.060 --> 01:41:30.540]   But it basically opens the polls right to a third party internet service providers,
[01:41:30.540 --> 01:41:32.660]   the utility polls.
[01:41:32.660 --> 01:41:34.380]   So that's good.
[01:41:34.380 --> 01:41:35.620]   So which is it?
[01:41:35.620 --> 01:41:36.620]   Yeah.
[01:41:36.620 --> 01:41:37.620]   And stopping Sinclair was good.
[01:41:37.620 --> 01:41:39.100]   Killing net neutrality was bad.
[01:41:39.100 --> 01:41:40.100]   Which is it?
[01:41:40.100 --> 01:41:41.100]   Yeah.
[01:41:41.100 --> 01:41:43.180]   I didn't see the R story.
[01:41:43.180 --> 01:41:44.180]   Hold on.
[01:41:44.180 --> 01:41:45.180]   I got Gosey.
[01:41:45.180 --> 01:41:50.020]   So one touch make ready is a rule that lets companies attach wires to utility polls without
[01:41:50.020 --> 01:41:53.620]   waiting for the other users of the poll to move their own wires.
[01:41:53.620 --> 01:41:58.060]   Google fiber says the utilities have been dragging their heels and that's what killed
[01:41:58.060 --> 01:42:00.740]   Google fiber because they couldn't get up on the polls.
[01:42:00.740 --> 01:42:04.220]   Comcast and AT&T wouldn't make their polls ready.
[01:42:04.220 --> 01:42:10.620]   One touch make ready says, "Hey, you can do the adjustments yourself, cop fiber."
[01:42:10.620 --> 01:42:12.420]   And I said, "Don't do it, man.
[01:42:12.420 --> 01:42:13.980]   The FCC stopped, man.
[01:42:13.980 --> 01:42:14.980]   That's terrible."
[01:42:14.980 --> 01:42:15.980]   So this this was something that--
[01:42:15.980 --> 01:42:20.740]   Ajit Pai rejected the argument saying that startups are unnecessarily delayed when they
[01:42:20.740 --> 01:42:24.900]   have to wait for incumbent ISPs before hanging wires.
[01:42:24.900 --> 01:42:29.940]   This is one of a couple of, I think, interesting pie decisions, pro competition.
[01:42:29.940 --> 01:42:30.940]   Yeah.
[01:42:30.940 --> 01:42:31.940]   Yeah.
[01:42:31.940 --> 01:42:34.820]   And this is something that Wheeler actually implemented or started.
[01:42:34.820 --> 01:42:35.820]   Right.
[01:42:35.820 --> 01:42:39.820]   They started this way back of the day and it was a legitimate issue in Austin, AT&T.
[01:42:39.820 --> 01:42:42.980]   It was just dragging their feet forever.
[01:42:42.980 --> 01:42:47.340]   Could have something to do with 5G, too, because 5G might require some of this deployment.
[01:42:47.340 --> 01:42:48.340]   So.
[01:42:48.340 --> 01:42:49.340]   Yeah.
[01:42:49.340 --> 01:42:54.300]   But it also will help because in this, this again takes some power.
[01:42:54.300 --> 01:42:58.020]   Not all polls are actually owned by utilities.
[01:42:58.020 --> 01:42:59.020]   Utilities.
[01:42:59.020 --> 01:43:00.020]   Yeah.
[01:43:00.020 --> 01:43:01.020]   Or--
[01:43:01.020 --> 01:43:02.020]   Well, interestingly--
[01:43:02.020 --> 01:43:04.500]   Some of them are owned by municipalities and this takes away some of the states ability
[01:43:04.500 --> 01:43:08.300]   to say to ISPs.
[01:43:08.300 --> 01:43:09.780]   They can put restrictions on things.
[01:43:09.780 --> 01:43:10.780]   So--
[01:43:10.780 --> 01:43:16.420]   Verizon supports this when touch make ready because that will help them implement 5G.
[01:43:16.420 --> 01:43:19.940]   I have a 5G, of course, right.
[01:43:19.940 --> 01:43:20.940]   So--
[01:43:20.940 --> 01:43:23.260]   What I'm looking for is a thread.
[01:43:23.260 --> 01:43:28.940]   I'm just looking for a consistent point of view from Ajit Pai.
[01:43:28.940 --> 01:43:31.700]   And maybe it's just I'll do whatever Verizon tells me to do.
[01:43:31.700 --> 01:43:33.340]   Maybe that's the consistent point of view.
[01:43:33.340 --> 01:43:35.300]   I don't know.
[01:43:35.300 --> 01:43:37.860]   It takes away power from the states.
[01:43:37.860 --> 01:43:39.180]   It does help.
[01:43:39.180 --> 01:43:46.140]   But it puts power in the hands of people who actually own that good.
[01:43:46.140 --> 01:43:50.060]   So yeah, I mean, it's overall a positive thing.
[01:43:50.060 --> 01:43:55.220]   And sometimes a stop clock can be right twice a day.
[01:43:55.220 --> 01:43:56.220]   And then--
[01:43:56.220 --> 01:43:57.220]   Yeah.
[01:43:57.220 --> 01:43:58.620]   And maybe Ajit Pai is in 100% evil.
[01:43:58.620 --> 01:43:59.620]   I don't know.
[01:43:59.620 --> 01:44:00.620]   I mean, it's--
[01:44:00.620 --> 01:44:01.620]   He's not.
[01:44:01.620 --> 01:44:02.620]   I mean, he's--
[01:44:02.620 --> 01:44:04.820]   He's a human.
[01:44:04.820 --> 01:44:05.820]   We think.
[01:44:05.820 --> 01:44:06.820]   We're not sure.
[01:44:06.820 --> 01:44:08.740]   He is human.
[01:44:08.740 --> 01:44:11.260]   And he is in a crappy spot.
[01:44:11.260 --> 01:44:14.780]   I mean, imagine having the entire internet or most of the internet
[01:44:14.780 --> 01:44:15.780]   hating you.
[01:44:15.780 --> 01:44:16.780]   Hate you.
[01:44:16.780 --> 01:44:20.420]   I mean, the lobbyists at Comcast and AT&T,
[01:44:20.420 --> 01:44:21.420]   they're used to that.
[01:44:21.420 --> 01:44:23.740]   They get paid really good money.
[01:44:23.740 --> 01:44:25.620]   I don't think Ajit Pai does.
[01:44:25.620 --> 01:44:27.020]   Not yet, anyway.
[01:44:27.020 --> 01:44:28.020]   Yeah, yeah.
[01:44:28.020 --> 01:44:31.180]   That's the right thing, Stacy.
[01:44:31.180 --> 01:44:36.140]   Amazon has launched grocery pickup at Whole Foods for prime members.
[01:44:36.140 --> 01:44:38.220]   Get on in there.
[01:44:38.220 --> 01:44:39.220]   Rose, what does that mean?
[01:44:39.220 --> 01:44:40.740]   Nidually pack it for you and you pick it up?
[01:44:40.740 --> 01:44:41.740]   Yeah.
[01:44:41.740 --> 01:44:42.900]   You order it and they pack it.
[01:44:42.900 --> 01:44:44.300]   It's actually a really handy service.
[01:44:44.300 --> 01:44:45.980]   Have you used it?
[01:44:45.980 --> 01:44:47.460]   I have not used the Amazon one.
[01:44:47.460 --> 01:44:51.500]   I've used HEB by Micro Suries.
[01:44:51.500 --> 01:44:53.260]   This is not a weird service.
[01:44:53.260 --> 01:44:54.860]   So this isn't delivery.
[01:44:54.860 --> 01:45:00.180]   This is-- you go-- you call them ahead or go online and you order.
[01:45:00.180 --> 01:45:02.300]   And then they have it ready for you and you just go get it.
[01:45:02.300 --> 01:45:03.300]   Yeah.
[01:45:03.300 --> 01:45:05.980]   You basically, like, if you can do your grocery shopping on your lunch hour
[01:45:05.980 --> 01:45:08.060]   at your computer and then pack it up and then we help.
[01:45:08.060 --> 01:45:09.060]   Yeah.
[01:45:09.060 --> 01:45:10.660]   Oh, OK.
[01:45:10.660 --> 01:45:15.940]   Yeah, I mean, it's actually quite convenient.
[01:45:15.940 --> 01:45:20.620]   And then the information says that they have information
[01:45:20.620 --> 01:45:25.860]   that people are not using their Amazon Echoes or other voice-enabled device
[01:45:25.860 --> 01:45:26.820]   to buy things.
[01:45:26.820 --> 01:45:32.780]   In fact, only 2% of people with devices that use Amazon Echo
[01:45:32.780 --> 01:45:35.460]   have made a purchase so far this year.
[01:45:35.460 --> 01:45:39.620]   This is according to two people briefed on the company's internal figures.
[01:45:39.620 --> 01:45:43.500]   Now, 2% of 50 million is still not a bad number.
[01:45:43.500 --> 01:45:44.620]   I buy stuff on it.
[01:45:44.620 --> 01:45:46.180]   I buy stuff with it all the time.
[01:45:46.180 --> 01:45:48.220]   I find it insanely convenient.
[01:45:48.220 --> 01:45:49.220]   But they make a point--
[01:45:49.220 --> 01:45:49.740]   You do?
[01:45:49.740 --> 01:45:50.260]   Yeah.
[01:45:50.260 --> 01:45:54.180]   They make a point that you're not going to buy a stereo system
[01:45:54.180 --> 01:45:57.380]   or you're only going to buy commodities or something you don't have to try.
[01:45:57.380 --> 01:46:00.620]   I can't even reorder my dog treats on that thing.
[01:46:00.620 --> 01:46:01.780]   It is so bad.
[01:46:01.780 --> 01:46:02.820]   I buy batteries that--
[01:46:02.820 --> 01:46:03.300]   It's a miracle.
[01:46:03.300 --> 01:46:05.340]   The reason I use it is because I'm in the bathroom.
[01:46:05.340 --> 01:46:06.100]   I'm out of toothpaste.
[01:46:06.100 --> 01:46:07.860]   I'll say Echo, buy some toothpaste.
[01:46:07.860 --> 01:46:10.420]   And I'll say, well, the last thing you bought was this.
[01:46:10.420 --> 01:46:11.460]   We want me to buy some more.
[01:46:11.460 --> 01:46:12.940]   And I say, yes, they say, what's your number?
[01:46:12.940 --> 01:46:13.620]   I say my number.
[01:46:13.620 --> 01:46:14.620]   And that's it.
[01:46:14.620 --> 01:46:16.340]   And how about Echo in the bathroom?
[01:46:16.340 --> 01:46:17.900]   You have an Echo in the bathroom?
[01:46:17.900 --> 01:46:18.940]   Of course I do.
[01:46:18.940 --> 01:46:21.820]   Actually, my real problem is the Echo in the bathroom
[01:46:21.820 --> 01:46:25.660]   is too close to the Echo in the closet and the Echo in the bedroom.
[01:46:25.660 --> 01:46:27.660]   So I have to give them different names.
[01:46:27.660 --> 01:46:33.260]   Because if I say Echo or the other word, they all go, what?
[01:46:33.260 --> 01:46:37.100]   And sometimes the wrong one picks it up.
[01:46:37.100 --> 01:46:39.020]   The ESP doesn't work for you?
[01:46:39.020 --> 01:46:40.220]   Not at all.
[01:46:40.220 --> 01:46:42.940]   It's supposed to know which one you're closest to.
[01:46:42.940 --> 01:46:44.820]   Yeah, it is.
[01:46:44.820 --> 01:46:47.780]   The worst thing that happens is I'll say--
[01:46:47.780 --> 01:46:48.620]   and it's happened today.
[01:46:48.620 --> 01:46:50.140]   And this is why I'm familiar with it.
[01:46:50.140 --> 01:46:55.940]   I say Echo, I say Echo, listen to First Up Podcast.
[01:46:55.940 --> 01:46:58.100]   Because I like the NPR First Up Podcast
[01:46:58.100 --> 01:46:58.900]   when I'm getting dressed.
[01:46:58.900 --> 01:47:00.340]   I listen to the news.
[01:47:00.340 --> 01:47:02.740]   And unfortunately, I'm in the bathroom.
[01:47:02.740 --> 01:47:04.980]   But the bedroom one starts playing First Up.
[01:47:04.980 --> 01:47:08.740]   So I say Echo Stop, the one in the bathroom stops.
[01:47:08.740 --> 01:47:15.180]   And then I say Echo, listen to the daily on the bathroom Sonos.
[01:47:15.180 --> 01:47:19.100]   And then I have two news shows going at the same time.
[01:47:19.100 --> 01:47:20.140]   Out of sync.
[01:47:20.140 --> 01:47:20.740]   Out of sync.
[01:47:20.740 --> 01:47:21.980]   No, it's two different shows.
[01:47:21.980 --> 01:47:22.700]   So yes, they're--
[01:47:22.700 --> 01:47:24.180]   Oh, two different shows, yes.
[01:47:24.180 --> 01:47:25.060]   Well, it's everyone's a while.
[01:47:25.060 --> 01:47:26.580]   They both talk about the same story.
[01:47:26.580 --> 01:47:30.620]   So I feel like the left ear and the right ear are at least--
[01:47:30.620 --> 01:47:31.820]   it's very bad.
[01:47:31.820 --> 01:47:34.380]   Is that what they call an ESP?
[01:47:34.380 --> 01:47:35.460]   I think they call it ESP.
[01:47:35.460 --> 01:47:38.340]   Echo sensing--
[01:47:38.340 --> 01:47:38.780]   Extra--
[01:47:38.780 --> 01:47:39.780]   --proximity.
[01:47:39.780 --> 01:47:40.780]   That's--
[01:47:40.780 --> 01:47:41.300]   what is it?
[01:47:41.300 --> 01:47:41.900]   Hold on.
[01:47:41.900 --> 01:47:42.620]   No, no, look at that.
[01:47:42.620 --> 01:47:43.060]   That's right.
[01:47:43.060 --> 01:47:44.020]   OK.
[01:47:44.020 --> 01:47:44.980]   Anyway--
[01:47:44.980 --> 01:47:46.820]   Extra stolen privacy.
[01:47:46.820 --> 01:47:48.860]   Yeah, extra stolen privacy.
[01:47:48.860 --> 01:47:50.380]   I like it.
[01:47:50.380 --> 01:47:52.140]   Echo spatial perception.
[01:47:52.140 --> 01:47:53.140]   Yeah.
[01:47:53.140 --> 01:47:54.380]   Ooh.
[01:47:54.380 --> 01:47:55.660]   So do you think this is a big deal?
[01:47:55.660 --> 01:47:58.860]   The information got a lot of press over this
[01:47:58.860 --> 01:48:02.220]   that so few people have bought things?
[01:48:02.220 --> 01:48:06.860]   You know, I don't know because there is consistent--
[01:48:06.860 --> 01:48:08.100]   like, when did the Echo came out?
[01:48:08.100 --> 01:48:12.140]   Everyone was like, oh, this is to help Amazon boost commerce.
[01:48:12.140 --> 01:48:14.060]   And people talked about people with echoes
[01:48:14.060 --> 01:48:17.340]   tending to buy more and spend more on Amazon.
[01:48:17.340 --> 01:48:20.540]   It didn't actually say that they did it over their echoes.
[01:48:20.540 --> 01:48:22.620]   And I think it's a very shallow way
[01:48:22.620 --> 01:48:24.940]   of looking at the platform.
[01:48:24.940 --> 01:48:25.420]   Yeah, I agree.
[01:48:25.420 --> 01:48:26.220]   It's just really--
[01:48:26.220 --> 01:48:29.100]   So it was-- that's just my bad expectations.
[01:48:29.100 --> 01:48:31.300]   You know, I mean, of course, Amazon would love it
[01:48:31.300 --> 01:48:32.820]   if you bought more stuff with your Echo,
[01:48:32.820 --> 01:48:35.140]   but it's just part of the whole ecosystem.
[01:48:35.140 --> 01:48:36.780]   And I am all in on prime.
[01:48:36.780 --> 01:48:37.980]   You are all in on prime.
[01:48:37.980 --> 01:48:39.540]   You are all in on prime.
[01:48:39.540 --> 01:48:40.740]   And you and you and you--
[01:48:40.740 --> 01:48:42.700]   I mean, clearly it's working.
[01:48:42.700 --> 01:48:44.220]   As long as you're buying it from Amazon,
[01:48:44.220 --> 01:48:45.900]   do they care how you ask for it?
[01:48:45.900 --> 01:48:47.060]   I don't think.
[01:48:47.060 --> 01:48:49.980]   What I thought was actually a way more interesting story
[01:48:49.980 --> 01:48:52.500]   was the one I think that came out today--
[01:48:52.500 --> 01:48:55.300]   or maybe it was yesterday about stolen GoPros--
[01:48:55.300 --> 01:48:59.940]   in how people fencing stolen merchandise lower the cost
[01:48:59.940 --> 01:49:01.900]   of that--
[01:49:01.900 --> 01:49:05.180]   Amazon's price matching algorithms lower their prices
[01:49:05.180 --> 01:49:07.620]   and other merchants lower their prices.
[01:49:07.620 --> 01:49:10.060]   And it really frustrates the manufacturers.
[01:49:10.060 --> 01:49:13.660]   So thieves go on Amazon selling stolen GoPros
[01:49:13.660 --> 01:49:16.620]   for a really low price because they stole them.
[01:49:16.620 --> 01:49:17.580]   It fell off a truck.
[01:49:17.580 --> 01:49:19.900]   And unfortunately, it hurts doubly
[01:49:19.900 --> 01:49:22.740]   because not only is the thief selling a stolen GoPro,
[01:49:22.740 --> 01:49:25.260]   but GoPro now gets lower prices because of Amazon
[01:49:25.260 --> 01:49:27.460]   pricing algorithms.
[01:49:27.460 --> 01:49:27.980]   Ooh.
[01:49:27.980 --> 01:49:29.540]   And that's kind of an interesting--
[01:49:29.540 --> 01:49:33.740]   that's one of those cases where the algorithm is behaving
[01:49:33.740 --> 01:49:36.300]   in a way that probably shouldn't.
[01:49:36.300 --> 01:49:38.940]   And does Amazon really have a care?
[01:49:38.940 --> 01:49:42.700]   It doesn't really-- it's like an externality for Amazon, right?
[01:49:42.700 --> 01:49:43.180]   So--
[01:49:43.180 --> 01:49:46.300]   I think the-- Amazon's a little too algorithmic sometimes
[01:49:46.300 --> 01:49:48.580]   on its pricing.
[01:49:48.580 --> 01:49:49.380]   We've seen--
[01:49:49.380 --> 01:49:50.540]   Yes, but when people--
[01:49:50.540 --> 01:49:51.860]   side effects.
[01:49:51.860 --> 01:49:55.220]   When people point things out where Amazon's algorithm--
[01:49:55.220 --> 01:49:57.940]   don't work so well, Amazon has reacted.
[01:49:57.940 --> 01:50:00.180]   Remember that Business Week story when they talked about,
[01:50:00.180 --> 01:50:04.060]   like, people not having access to prime, I think it was,
[01:50:04.060 --> 01:50:05.660]   in poorer areas of Boston?
[01:50:05.660 --> 01:50:06.180]   Oh, I know.
[01:50:06.180 --> 01:50:06.820]   Terrible.
[01:50:06.820 --> 01:50:08.260]   Yeah.
[01:50:08.260 --> 01:50:09.700]   So.
[01:50:09.700 --> 01:50:10.540]   OK.
[01:50:10.540 --> 01:50:12.740]   Nice.
[01:50:12.740 --> 01:50:13.300]   OK.
[01:50:13.300 --> 01:50:15.260]   Mm-hmm.
[01:50:15.260 --> 01:50:19.620]   I love the Samsung accidentally publishes
[01:50:19.620 --> 01:50:22.780]   the official Galaxy Note 9 video, which they accidentally
[01:50:22.780 --> 01:50:25.220]   have done right before the release of every phone
[01:50:25.220 --> 01:50:26.220]   for the last four years.
[01:50:26.220 --> 01:50:27.700]   Accidentally--
[01:50:27.700 --> 01:50:29.660]   That makes tech bloggers happy.
[01:50:29.660 --> 01:50:33.420]   [LAUGHTER]
[01:50:33.420 --> 01:50:35.860]   I'm not going to repeat that story.
[01:50:35.860 --> 01:50:36.300]   Let's see.
[01:50:36.300 --> 01:50:36.820]   There it is.
[01:50:36.820 --> 01:50:37.860]   But we're not going to repeat it.
[01:50:37.860 --> 01:50:39.140]   We're not going to repeat it.
[01:50:39.140 --> 01:50:44.500]   I think we could just take a break now and go to your picks,
[01:50:44.500 --> 01:50:44.860]   right?
[01:50:44.860 --> 01:50:45.460]   Is there anything--
[01:50:45.460 --> 01:50:46.540]   I'll give you guys a chance.
[01:50:46.540 --> 01:50:50.580]   There's no chance we'll be able to hear anything else.
[01:50:50.580 --> 01:50:54.380]   I would love to leave because I was planning on being
[01:50:54.380 --> 01:50:55.980]   done by 4 o'clock, but you're not.
[01:50:55.980 --> 01:50:56.900]   Here we go, quickly.
[01:50:56.900 --> 01:50:57.460]   Quickly.
[01:50:57.460 --> 01:50:58.460]   One add.
[01:50:58.460 --> 01:51:00.260]   And then you'll get your pick and you can go.
[01:51:00.260 --> 01:51:01.620]   I'm so sorry, Stacey.
[01:51:01.620 --> 01:51:02.420]   No, no, no.
[01:51:02.420 --> 01:51:02.940]   I just--
[01:51:02.940 --> 01:51:03.980]   You started late, and I apologize.
[01:51:03.980 --> 01:51:04.580]   We started late.
[01:51:04.580 --> 01:51:05.780]   Well, that's-- I'm like--
[01:51:05.780 --> 01:51:06.820]   That's on me.
[01:51:06.820 --> 01:51:08.060]   That's on me.
[01:51:08.060 --> 01:51:09.820]   I was watching TV.
[01:51:09.820 --> 01:51:12.100]   Our show today brought to you by Rocket Mortgage
[01:51:12.100 --> 01:51:14.020]   from Quick and Loans.
[01:51:14.020 --> 01:51:16.780]   Actually, this is good for people who like to go quick.
[01:51:16.780 --> 01:51:19.500]   Rocket Mortgage is the entirely online mortgage approval
[01:51:19.500 --> 01:51:23.140]   process that unlike my last experience buying house,
[01:51:23.140 --> 01:51:25.460]   doesn't take months to get a home loan.
[01:51:25.460 --> 01:51:26.740]   Takes minutes.
[01:51:26.740 --> 01:51:28.940]   I love Rocket Mortgage from Quick and Loans,
[01:51:28.940 --> 01:51:31.140]   a best lender in the country, number one in customer
[01:51:31.140 --> 01:51:34.060]   satisfaction, year after year, eight years in a row,
[01:51:34.060 --> 01:51:35.140]   according to JD Power.
[01:51:35.140 --> 01:51:37.700]   Number one, they're also number one in volume,
[01:51:37.700 --> 01:51:40.060]   and I think they go hand in hand, right?
[01:51:40.060 --> 01:51:43.140]   They took over at the end of last year from the Big Bank,
[01:51:43.140 --> 01:51:44.860]   who took months to get me my home loan,
[01:51:44.860 --> 01:51:47.220]   and you better believe it the next time I buy a house,
[01:51:47.220 --> 01:51:49.700]   Rocket Mortgage.com/Twig.
[01:51:49.700 --> 01:51:51.780]   They've also done something to reduce the anxiety
[01:51:51.780 --> 01:51:53.340]   of buying a house, the most expensive thing
[01:51:53.340 --> 01:51:54.580]   you're ever going to buy.
[01:51:54.580 --> 01:51:55.500]   It's a big deal, too.
[01:51:55.500 --> 01:51:56.700]   You want to buy the right house.
[01:51:56.700 --> 01:51:58.460]   You want to buy a house that you and your family will love
[01:51:58.460 --> 01:52:00.260]   for the years you're going to be living in it,
[01:52:00.260 --> 01:52:02.900]   so you don't want to be rushed or pressured.
[01:52:02.900 --> 01:52:05.580]   That's why Quick and Loans has created the power buying
[01:52:05.580 --> 01:52:06.420]   process.
[01:52:06.420 --> 01:52:09.740]   So it starts going to Rocket Mortgage.com/Twig.
[01:52:09.740 --> 01:52:11.460]   You don't have to fill out a long application.
[01:52:11.460 --> 01:52:12.660]   You answer a couple of questions.
[01:52:12.660 --> 01:52:15.340]   They can get information-- the information they need
[01:52:15.340 --> 01:52:17.220]   about income and assets and credit,
[01:52:17.220 --> 01:52:19.660]   just from the trusted financial institutions
[01:52:19.660 --> 01:52:22.140]   that they work with, as long as you give it your permission.
[01:52:22.140 --> 01:52:23.340]   Within a few minutes, they're going
[01:52:23.340 --> 01:52:26.420]   to give you what they call qualified approval.
[01:52:26.420 --> 01:52:29.420]   Within 24 hours, they'll give you verified approval.
[01:52:29.420 --> 01:52:31.180]   Now, the verified approval is really cool,
[01:52:31.180 --> 01:52:35.660]   because that basically makes you a cash buyer.
[01:52:35.660 --> 01:52:37.460]   With your verified approval letter,
[01:52:37.460 --> 01:52:39.860]   when you make an offer on a house, the seller says,
[01:52:39.860 --> 01:52:41.140]   oh, no contingency.
[01:52:41.140 --> 01:52:42.500]   You're good for the money.
[01:52:42.500 --> 01:52:44.660]   It's like you got cash.
[01:52:44.660 --> 01:52:47.100]   You go right to the head of the line.
[01:52:47.100 --> 01:52:48.060]   So that's very important.
[01:52:48.060 --> 01:52:49.540]   But once you're verified, you also
[01:52:49.540 --> 01:52:53.020]   qualify for their all new exclusive rate shield approval.
[01:52:53.020 --> 01:52:55.700]   This is really a nice way to reduce the anxiety.
[01:52:55.700 --> 01:52:57.140]   And this is a relatively new thing.
[01:52:57.140 --> 01:52:58.940]   For the last few years, interest rates have been flat.
[01:52:58.940 --> 01:53:03.100]   They're starting to go up and even a quarter of a percent more,
[01:53:03.100 --> 01:53:05.380]   and you're going to pay tens of thousands of dollars more
[01:53:05.380 --> 01:53:07.620]   over the life of the loan.
[01:53:07.620 --> 01:53:13.060]   So that's pressure to buy now before the rates go up some more.
[01:53:13.060 --> 01:53:14.180]   And we don't want that.
[01:53:14.180 --> 01:53:15.260]   We want to make it easy.
[01:53:15.260 --> 01:53:18.900]   We want you to have the time to look at their houses
[01:53:18.900 --> 01:53:20.740]   and find the right one for you, not just buy it,
[01:53:20.740 --> 01:53:22.340]   because you got it right now.
[01:53:22.340 --> 01:53:26.300]   They lock up your rate for up to 90 days, up to three months.
[01:53:26.300 --> 01:53:29.700]   So you can go house hunting and not worry about rates.
[01:53:29.700 --> 01:53:31.820]   They can't go up.
[01:53:31.820 --> 01:53:32.860]   They can't go up.
[01:53:32.860 --> 01:53:34.380]   If rates go up, it doesn't matter.
[01:53:34.380 --> 01:53:35.900]   Your rate stays the same.
[01:53:35.900 --> 01:53:38.620]   If rates go down, your rate will go down.
[01:53:38.620 --> 01:53:39.380]   But it can't go up.
[01:53:39.380 --> 01:53:40.700]   Either way you win.
[01:53:40.700 --> 01:53:42.820]   It's exactly what you'd expect from the best mortgage
[01:53:42.820 --> 01:53:46.540]   lender in the country, rocketmortgage.com/twig.
[01:53:46.540 --> 01:53:48.500]   Take the stress out of buying a house.
[01:53:48.500 --> 01:53:50.460]   Make it a pleasant experience.
[01:53:50.460 --> 01:53:52.180]   It's fun to look for your new home.
[01:53:52.180 --> 01:53:55.260]   It is, as long as you don't have that stress.
[01:53:55.260 --> 01:53:58.420]   And rocket mortgage just takes the stress out of the equation.
[01:53:58.420 --> 01:53:59.940]   Now here's some legales I got to read.
[01:53:59.940 --> 01:54:00.700]   Don't get stressed.
[01:54:00.700 --> 01:54:01.500]   Rate shield approvals.
[01:54:01.500 --> 01:54:04.260]   Only valid on certain 30-year purchase transactions.
[01:54:04.260 --> 01:54:05.740]   Additional conditions or exclusions
[01:54:05.740 --> 01:54:07.340]   may apply based on quick and loans data
[01:54:07.340 --> 01:54:09.100]   and comparison to public data records.
[01:54:09.100 --> 01:54:11.900]   Equal housing lender licensed in all 50 states
[01:54:11.900 --> 01:54:14.980]   and MLS consumer access.org number 30-30.
[01:54:14.980 --> 01:54:16.300]   But really all you have to worry about,
[01:54:16.300 --> 01:54:20.060]   all you have to remember, rocketmortgage.com/twig.
[01:54:20.060 --> 01:54:22.780]   Honestly, the way to buy your next house,
[01:54:22.780 --> 01:54:26.100]   rocketmortgage.com/twig, or they do refi's too.
[01:54:26.100 --> 01:54:29.220]   Thank you quick and loans for making Twig possible.
[01:54:29.220 --> 01:54:32.540]   Stacey, let's get your thing out of the way, the June oven.
[01:54:32.540 --> 01:54:36.020]   - Yes, this is the second generation June.
[01:54:36.020 --> 01:54:38.140]   I don't have it with me in Seattle to show you.
[01:54:38.140 --> 01:54:39.460]   - Did you buy it?
[01:54:39.460 --> 01:54:41.460]   - No, no, no, I have the first generation.
[01:54:41.460 --> 01:54:44.100]   So the pricing here is really worth talking about.
[01:54:44.100 --> 01:54:46.340]   So it is a very similar oven.
[01:54:46.340 --> 01:54:47.620]   We'll talk about what's different.
[01:54:47.620 --> 01:54:50.860]   It is right now, you can buy it for $100 off.
[01:54:50.860 --> 01:54:52.020]   So it's $4.99.
[01:54:52.020 --> 01:54:52.860]   - Whoa.
[01:54:52.860 --> 01:54:55.420]   - Or you can buy the quote unquote gourmet package,
[01:54:55.420 --> 01:54:56.700]   which is $6.99.
[01:54:56.700 --> 01:54:59.980]   - Did I blow it by buying the really expensive one?
[01:54:59.980 --> 01:55:01.700]   - I'm gonna tell you and you can decide.
[01:55:01.700 --> 01:55:02.540]   - Okay.
[01:55:02.540 --> 01:55:03.900]   (laughs)
[01:55:03.900 --> 01:55:05.220]   - 'Cause it's your fault.
[01:55:05.220 --> 01:55:07.860]   - Okay.
[01:55:07.860 --> 01:55:10.940]   - Comes with extra warranty and the recipes app
[01:55:10.940 --> 01:55:12.660]   and a bunch of trays that did on with our--
[01:55:12.660 --> 01:55:13.500]   - How much does that cost?
[01:55:13.500 --> 01:55:14.860]   How much does the or may one cost?
[01:55:14.860 --> 01:55:15.700]   - 100 bucks more.
[01:55:15.700 --> 01:55:17.860]   - 6.99, 200 bucks more.
[01:55:17.860 --> 01:55:18.700]   - 200.
[01:55:18.700 --> 01:55:19.540]   - 200.
[01:55:19.540 --> 01:55:21.260]   - Better be some nice trays.
[01:55:21.260 --> 01:55:22.940]   - There's a bunch of them.
[01:55:22.940 --> 01:55:24.860]   So what do we think?
[01:55:24.860 --> 01:55:25.980]   Did you blow it?
[01:55:25.980 --> 01:55:29.020]   Well, the new one is different.
[01:55:29.020 --> 01:55:31.740]   It doesn't have the same size.
[01:55:31.740 --> 01:55:33.580]   It doesn't have the scales and the feet.
[01:55:33.580 --> 01:55:34.900]   - Oh, I like the scales and the feet.
[01:55:34.900 --> 01:55:36.540]   'Cause then it knows how much you--
[01:55:36.540 --> 01:55:37.700]   - Doesn't actually do that.
[01:55:37.700 --> 01:55:38.540]   - Oh.
[01:55:38.540 --> 01:55:39.420]   - So this is what I learned.
[01:55:39.420 --> 01:55:42.660]   So it has in, they also did a way with the knob,
[01:55:42.660 --> 01:55:45.380]   which had some extra sensors and is extra super fancy
[01:55:45.380 --> 01:55:47.980]   because most people just touch it.
[01:55:47.980 --> 01:55:48.820]   So--
[01:55:48.820 --> 01:55:49.660]   - Yeah, nobody uses the knob.
[01:55:49.660 --> 01:55:50.500]   Yeah.
[01:55:50.500 --> 01:55:51.340]   - I use the knob.
[01:55:51.340 --> 01:55:53.260]   - I do too, but I can understand why you wouldn't need it.
[01:55:53.260 --> 01:55:54.260]   - Yes.
[01:55:54.260 --> 01:55:55.820]   - So that's one of the ways they cut it.
[01:55:55.820 --> 01:55:58.420]   They also have more volume.
[01:55:58.420 --> 01:56:00.180]   They also have more experience.
[01:56:00.180 --> 01:56:02.700]   So they've changed their manufacturing process.
[01:56:02.700 --> 01:56:05.620]   So I talked to Matt Van Horn and he'll be on the podcast
[01:56:05.620 --> 01:56:07.660]   tomorrow if you are a June aficionado.
[01:56:07.660 --> 01:56:08.580]   - As I am.
[01:56:08.580 --> 01:56:09.420]   - I love my--
[01:56:09.420 --> 01:56:10.260]   - That's one might be.
[01:56:10.260 --> 01:56:11.100]   - Yeah.
[01:56:11.100 --> 01:56:14.180]   - And I would say what they did, Leo, you and I
[01:56:14.180 --> 01:56:16.660]   helped to make this oven possible.
[01:56:16.660 --> 01:56:18.340]   Basically, they looked at all the data
[01:56:18.340 --> 01:56:20.660]   from the existing customers and they said,
[01:56:20.660 --> 01:56:21.860]   you know what?
[01:56:21.860 --> 01:56:22.740]   Here's what people need.
[01:56:22.740 --> 01:56:24.180]   Here's what they don't.
[01:56:24.180 --> 01:56:26.900]   And they kept the stuff like the fast heating.
[01:56:26.900 --> 01:56:29.580]   So the carbon fiber heating elements.
[01:56:29.580 --> 01:56:30.780]   They kept the camera.
[01:56:30.780 --> 01:56:32.740]   They kept all of that.
[01:56:32.740 --> 01:56:35.220]   They kept the local control.
[01:56:35.220 --> 01:56:39.420]   And I would buy this oven again in a heartbeat.
[01:56:39.420 --> 01:56:40.500]   - It kind of makes sense.
[01:56:40.500 --> 01:56:43.100]   This is an example of a feedback loop
[01:56:43.100 --> 01:56:45.380]   that modern technology allows.
[01:56:45.380 --> 01:56:48.500]   'Cause if you buy a normal toaster oven,
[01:56:48.500 --> 01:56:51.820]   Hamilton Beach knows nothing about how you use it.
[01:56:51.820 --> 01:56:54.420]   But June knows everything about how you use it.
[01:56:54.420 --> 01:56:56.140]   So they can improve it.
[01:56:56.140 --> 01:56:57.380]   That makes sense.
[01:56:57.380 --> 01:56:58.540]   - This does a lot of things.
[01:56:58.540 --> 01:57:00.220]   It does the air frying.
[01:57:00.220 --> 01:57:01.940]   You can use it as a great model.
[01:57:01.940 --> 01:57:04.180]   - I can use it as an air fryer.
[01:57:04.180 --> 01:57:06.220]   You can use yours as an air fryer.
[01:57:06.220 --> 01:57:07.660]   - I didn't know that. - It's just a software.
[01:57:07.660 --> 01:57:10.500]   Yeah, so you do have to buy a $50 air fryer tray.
[01:57:10.500 --> 01:57:11.380]   - Oh. - But yeah,
[01:57:11.380 --> 01:57:13.340]   I've used mine as an air fryer for chicken
[01:57:13.340 --> 01:57:15.460]   and for technology. - We're about to buy an air fryer.
[01:57:15.460 --> 01:57:16.380]   - Don't do that.
[01:57:16.380 --> 01:57:17.740]   Your June doesn't.
[01:57:17.740 --> 01:57:19.820]   - My June doesn't. - So.
[01:57:19.820 --> 01:57:21.580]   Yeah. - Thank you, Stacy.
[01:57:21.580 --> 01:57:23.260]   The osu-- Leo should say thank you, Stacy.
[01:57:23.260 --> 01:57:24.300]   - Thank you, Stacy.
[01:57:24.300 --> 01:57:25.300]   Look at all the baskets.
[01:57:25.300 --> 01:57:27.620]   I didn't know all this stuff.
[01:57:27.620 --> 01:57:28.460]   - Yeah.
[01:57:28.460 --> 01:57:31.540]   - Oh, I can get the June air baskets.
[01:57:31.540 --> 01:57:32.380]   - They're actually real.
[01:57:32.380 --> 01:57:33.740]   Like I have them, they're very heavy.
[01:57:33.740 --> 01:57:35.660]   - They bought a big fancy dehydrator.
[01:57:35.660 --> 01:57:37.180]   I-- - Oh, no.
[01:57:37.180 --> 01:57:38.860]   Yeah, you get rid of your dehydrator too.
[01:57:38.860 --> 01:57:39.700]   - No, I'm not.
[01:57:39.700 --> 01:57:40.540]   I just bought it.
[01:57:40.540 --> 01:57:41.380]   (laughs)
[01:57:41.380 --> 01:57:43.740]   - Oh, sell it on eBay.
[01:57:43.740 --> 01:57:45.380]   - Yeah, I like my dehydrator.
[01:57:45.380 --> 01:57:48.140]   I could do a lot more in that 'cause it's huge.
[01:57:48.140 --> 01:57:49.180]   - Oh, well, there you go.
[01:57:49.180 --> 01:57:50.260]   Keep your dehydrator.
[01:57:50.260 --> 01:57:52.620]   - And I don't need a new crumb tray
[01:57:52.620 --> 01:57:55.060]   or wire shelf for June pan.
[01:57:55.060 --> 01:57:57.620]   Thermometer's good.
[01:57:57.620 --> 01:58:00.140]   So all I really need is these--
[01:58:00.140 --> 01:58:01.820]   - So Stacy, two questions.
[01:58:01.820 --> 01:58:04.380]   Is there anything that this one has
[01:58:04.380 --> 01:58:06.620]   that your expensive one doesn't have?
[01:58:06.620 --> 01:58:08.420]   A, and then B, is there anything
[01:58:08.420 --> 01:58:09.620]   that if you had this one alone,
[01:58:09.620 --> 01:58:11.980]   you would miss that the expensive one has?
[01:58:11.980 --> 01:58:15.340]   - I would miss the knob on the expensive one,
[01:58:15.340 --> 01:58:18.340]   but I would totally be fine
[01:58:18.340 --> 01:58:21.060]   and I would totally pay less if I could.
[01:58:21.060 --> 01:58:23.860]   - Yeah, this is less than half the original June oven.
[01:58:23.860 --> 01:58:25.900]   - So I have a lot of my friends actually,
[01:58:25.900 --> 01:58:27.380]   they emailed me and they were like,
[01:58:27.380 --> 01:58:28.540]   is this real, is this the same?
[01:58:28.540 --> 01:58:29.980]   And I was like, yeah, it's basically,
[01:58:29.980 --> 01:58:32.140]   it's almost exactly the same with the exception
[01:58:32.140 --> 01:58:34.020]   of those two things mostly.
[01:58:34.020 --> 01:58:35.460]   And it doesn't have anything
[01:58:35.460 --> 01:58:37.940]   that would change the cooking experience.
[01:58:37.940 --> 01:58:40.740]   In fact, over time, when I bought it,
[01:58:40.740 --> 01:58:42.300]   they've added many new programs.
[01:58:42.300 --> 01:58:44.540]   So it's actually gotten better for me over time
[01:58:44.540 --> 01:58:47.300]   and this comes with all that automatically.
[01:58:47.300 --> 01:58:48.860]   So I'm like, it's a no-brainer guys.
[01:58:48.860 --> 01:58:51.180]   If this is now in your price point, go buy it.
[01:58:51.180 --> 01:58:53.140]   - Toaster ovens are really useful in the kitchen.
[01:58:53.140 --> 01:58:54.100]   This is a very smart,
[01:58:54.100 --> 01:58:55.500]   internet connected toaster oven.
[01:58:55.500 --> 01:59:00.500]   It has an app, has a camera, has a thermal probe
[01:59:00.500 --> 01:59:01.940]   and all of that stuff.
[01:59:01.940 --> 01:59:05.860]   - And it has a preset recipes, which I cannot over--
[01:59:05.860 --> 01:59:07.380]   - Do you use those a lot?
[01:59:07.380 --> 01:59:09.060]   - Oh my gosh, we always use them.
[01:59:09.060 --> 01:59:11.100]   I mean, we-- - What's your favorite?
[01:59:11.100 --> 01:59:14.340]   - The salmon turns out really nice each time
[01:59:14.340 --> 01:59:16.420]   and the chicken, actually, the chicken breasts
[01:59:16.420 --> 01:59:18.140]   turned out really nice. - Do you cook in the salmon
[01:59:18.140 --> 01:59:18.980]   in the oven?
[01:59:18.980 --> 01:59:20.180]   I should try it in the June.
[01:59:20.180 --> 01:59:21.940]   - Oh my gosh, yes. - Okay, I will.
[01:59:21.940 --> 01:59:24.060]   - What do you do to the chicken?
[01:59:25.060 --> 01:59:27.820]   - I can just put the chicken breasts in there.
[01:59:27.820 --> 01:59:29.340]   - It's a little bit of a seasonant.
[01:59:29.340 --> 01:59:31.660]   - Yeah, but if I just wanna have chicken breasts
[01:59:31.660 --> 01:59:33.980]   handy to throw in bowls or some weird thing
[01:59:33.980 --> 01:59:36.340]   later on in the week, I just spice them up
[01:59:36.340 --> 01:59:37.300]   and then pop them in.
[01:59:37.300 --> 01:59:39.700]   - And they use the probe, right, the thermometer.
[01:59:39.700 --> 01:59:41.220]   - Yeah, you just put it in it.
[01:59:41.220 --> 01:59:42.700]   - So that way they're cooked perfectly, they're juicy,
[01:59:42.700 --> 01:59:43.940]   but they're fully cooked all like that.
[01:59:43.940 --> 01:59:45.260]   That's nice. - Yeah.
[01:59:45.260 --> 01:59:47.140]   - Okay, you convinced me.
[01:59:47.140 --> 01:59:49.820]   - But you don't need to buy this one
[01:59:49.820 --> 01:59:50.900]   'cause you already have yours.
[01:59:50.900 --> 01:59:52.540]   - Well, mine is well.
[01:59:52.540 --> 01:59:55.540]   - No. - No, no.
[01:59:55.540 --> 01:59:57.540]   - I'm just teasing, I'm not gonna buy it.
[01:59:57.540 --> 01:59:58.940]   I like my-- - Leo, you have to buy
[01:59:58.940 --> 02:00:01.140]   a second house, not to live in,
[02:00:01.140 --> 02:00:02.740]   but just to have the more gadgets.
[02:00:02.740 --> 02:00:05.340]   - Yeah, that's why I use rocket mortgage.
[02:00:05.340 --> 02:00:08.700]   Thank you, Stacy, go, go, go.
[02:00:08.700 --> 02:00:09.860]   It's wonderful to have you.
[02:00:09.860 --> 02:00:12.220]   Stacy's the host of Stacy on IoT.
[02:00:12.220 --> 02:00:15.940]   Go to Stacyoniot.com and subscribe to our free newsletter.
[02:00:15.940 --> 02:00:18.540]   Keep on what's going on in the world of internet of things,
[02:00:18.540 --> 02:00:21.540]   all sorts of cool stuff at Gigastacy.
[02:00:21.540 --> 02:00:24.540]   And you are-- - Oh, we forgot.
[02:00:24.540 --> 02:00:26.660]   Okay, I shouldn't have talked about the June.
[02:00:26.660 --> 02:00:30.460]   I should have told you, just go check out the Anki Vector.
[02:00:30.460 --> 02:00:31.540]   That should be my other thing.
[02:00:31.540 --> 02:00:33.220]   - What, what? - Sorry.
[02:00:33.220 --> 02:00:36.740]   The Anki Vector, it just launched today.
[02:00:36.740 --> 02:00:38.940]   It is amazing.
[02:00:38.940 --> 02:00:42.020]   - A-N-K-I, I have the original Anki race track.
[02:00:42.020 --> 02:00:43.180]   Oh, it's a robot.
[02:00:43.180 --> 02:00:46.140]   Oh. - It's the Cosmo, but it's smarter.
[02:00:46.140 --> 02:00:48.220]   - Oh. - Yeah.
[02:00:48.220 --> 02:00:50.060]   - Yeah, they killed the-- - I have the Cosmo.
[02:00:50.060 --> 02:00:54.100]   - They killed the-- what was the other one, the Orbe?
[02:00:54.100 --> 02:00:55.140]   They killed that one.
[02:00:55.140 --> 02:00:56.100]   Oh, it's cute.
[02:00:56.100 --> 02:00:57.020]   It is a Cosmo.
[02:00:57.020 --> 02:00:59.020]   It's the same size as a Cosmo.
[02:00:59.020 --> 02:01:01.500]   - Yeah. - But does it do more stuff?
[02:01:01.500 --> 02:01:02.340]   - It does it.
[02:01:02.340 --> 02:01:03.180]   It does it locally.
[02:01:03.180 --> 02:01:05.340]   So the Cosmo borrow the processing power from your phone.
[02:01:05.340 --> 02:01:07.900]   This does more stuff and it does it on the robot.
[02:01:07.900 --> 02:01:10.740]   - But it's-- they didn't do the original Cosmo.
[02:01:10.740 --> 02:01:12.140]   - Yeah, they did. - Oh, they did.
[02:01:12.140 --> 02:01:12.980]   Oh, they did the Cosmo.
[02:01:12.980 --> 02:01:13.820]   Okay.
[02:01:13.820 --> 02:01:15.300]   So it's got those cute little eyes and stuff.
[02:01:15.300 --> 02:01:19.740]   And you can get one for $199 a Kickstarter.
[02:01:19.740 --> 02:01:21.580]   Did you get one? - You have it?
[02:01:21.580 --> 02:01:22.540]   - Kevin got that one.
[02:01:22.540 --> 02:01:24.460]   I still like the Cosmo.
[02:01:24.460 --> 02:01:26.300]   I don't-- - We have a Cosmo.
[02:01:26.300 --> 02:01:30.180]   - You're looking into the-- - Around the office
[02:01:30.180 --> 02:01:31.780]   'cause we reviewed it.
[02:01:31.780 --> 02:01:33.580]   Here's the cute little eyes.
[02:01:33.580 --> 02:01:35.020]   Yeah, I like the color better than white.
[02:01:35.020 --> 02:01:36.740]   I think it looks more utilitarian.
[02:01:36.740 --> 02:01:38.980]   - I think it looks mean. - Yes.
[02:01:38.980 --> 02:01:40.860]   - And Kevin says-- - I like it.
[02:01:40.860 --> 02:01:43.100]   - I don't think it's a cute robot.
[02:01:43.100 --> 02:01:44.380]   - Robots should look mean. - The robot.
[02:01:44.380 --> 02:01:46.380]   No. - They should look mean.
[02:01:46.380 --> 02:01:48.500]   Don't be fooled by the cute friendly.
[02:01:48.500 --> 02:01:49.340]   They're not.
[02:01:49.340 --> 02:01:51.980]   - Cosmo is cute.
[02:01:51.980 --> 02:01:52.820]   Okay. - Fortunately--
[02:01:52.820 --> 02:01:55.580]   - Off I go. - He's too small to be a real threat.
[02:01:55.580 --> 02:01:56.500]   - Thank you. - I don't know.
[02:01:56.500 --> 02:01:58.820]   He can whack you with that little bulldozer thing
[02:01:58.820 --> 02:02:01.220]   on the finger. - He's a little bulldozer on it.
[02:02:01.220 --> 02:02:02.500]   Can he move sand?
[02:02:02.500 --> 02:02:04.860]   - He moves those little cubes that come with it.
[02:02:04.860 --> 02:02:07.100]   - He doesn't do anything useful.
[02:02:07.100 --> 02:02:08.620]   - He can pick up a cube.
[02:02:08.620 --> 02:02:12.020]   Now he can actually, now he can answer questions.
[02:02:12.020 --> 02:02:13.100]   And I think he can actually,
[02:02:13.100 --> 02:02:14.780]   you can send him to go look out the window
[02:02:14.780 --> 02:02:16.980]   and he can recognize things.
[02:02:16.980 --> 02:02:19.300]   You can actually program him with Python.
[02:02:19.300 --> 02:02:21.620]   You can use TensorFlow. - You can torture a cat.
[02:02:21.620 --> 02:02:24.340]   - You can torture a cat.
[02:02:24.340 --> 02:02:27.460]   - You can fist bump it.
[02:02:27.460 --> 02:02:28.820]   - Yeah.
[02:02:28.820 --> 02:02:30.700]   - This guy is the tech director of AI.
[02:02:30.700 --> 02:02:32.780]   He looks like he's eight.
[02:02:32.780 --> 02:02:33.700]   - Okay, 12.
[02:02:33.700 --> 02:02:35.060]   (laughing)
[02:02:35.060 --> 02:02:38.780]   Brad Newman, he looks like he's just a kid.
[02:02:38.780 --> 02:02:41.340]   Look at him.
[02:02:41.340 --> 02:02:42.900]   Fresh-faced Brad Newman,
[02:02:42.900 --> 02:02:45.420]   director of artificial intelligence.
[02:02:46.300 --> 02:02:48.780]   And in fact, I think he's in his kindergarten classroom
[02:02:48.780 --> 02:02:49.660]   right now. - I should be worried
[02:02:49.660 --> 02:02:51.540]   not about being replaced by the robot, but by him.
[02:02:51.540 --> 02:02:52.780]   - I'm worried about Brad.
[02:02:52.780 --> 02:02:54.660]   Forget the robot.
[02:02:54.660 --> 02:02:55.500]   Thank you Stacey.
[02:02:55.500 --> 02:02:56.340]   Bye.
[02:02:56.340 --> 02:02:58.820]   Enjoy some queso when you get home.
[02:02:58.820 --> 02:03:00.020]   - Oh, I was like, what?
[02:03:00.020 --> 02:03:01.940]   - 'Cause there's no queso in Seattle.
[02:03:01.940 --> 02:03:03.580]   Bye. - Bye.
[02:03:03.580 --> 02:03:05.260]   - Bye, Higginbotham.
[02:03:05.260 --> 02:03:07.060]   You're not related to Daniel Higginbotham,
[02:03:07.060 --> 02:03:10.120]   author of "Closure for the Brave and True", are you?
[02:03:10.120 --> 02:03:12.540]   We'll never know.
[02:03:12.540 --> 02:03:14.180]   And now, ladies and gentlemen.
[02:03:14.180 --> 02:03:15.580]   (laughing)
[02:03:15.580 --> 02:03:17.780]   - Jeff Jarvis is second to get out of here.
[02:03:17.780 --> 02:03:19.620]   - Yeah, she wasted no time.
[02:03:19.620 --> 02:03:20.460]   - Our pick of the week.
[02:03:20.460 --> 02:03:21.560]   - Let's see which one should I do.
[02:03:21.560 --> 02:03:22.400]   - Number.
[02:03:22.400 --> 02:03:25.420]   - Well, so we have, number is one,
[02:03:25.420 --> 02:03:27.660]   because we have children now,
[02:03:27.660 --> 02:03:29.120]   a story from the Associated Press
[02:03:29.120 --> 02:03:31.920]   about how their first words are, what we get.
[02:03:31.920 --> 02:03:33.520]   - Oh my God. - No.
[02:03:33.520 --> 02:03:35.420]   - And, no. - No.
[02:03:35.420 --> 02:03:37.220]   Actually kind of a decent story talking about
[02:03:37.220 --> 02:03:39.860]   how kids are interacting with these, oh, oh, sorry.
[02:03:39.860 --> 02:03:41.820]   Oh, my, my, my, my, my, it's just went crazy.
[02:03:43.740 --> 02:03:46.020]   Three, four, it once responded to me.
[02:03:46.020 --> 02:03:50.940]   But how kids are interacting with these devices
[02:03:50.940 --> 02:03:52.300]   and what the impact of that is,
[02:03:52.300 --> 02:03:53.940]   and it's not a full, I was gonna scream
[02:03:53.940 --> 02:03:57.180]   about moral panic, but it's actually not a bad story.
[02:03:57.180 --> 02:03:58.780]   Saying that they can get answers to things
[02:03:58.780 --> 02:04:00.060]   and they can watch neat things
[02:04:00.060 --> 02:04:01.340]   and they can ask questions
[02:04:01.340 --> 02:04:04.220]   and that maybe it's not such an awful thing.
[02:04:04.220 --> 02:04:06.860]   - Wow.
[02:04:06.860 --> 02:04:09.460]   - But so, a parent tells a story that, of course,
[02:04:09.460 --> 02:04:10.780]   kids say, "Goo-goo."
[02:04:10.780 --> 02:04:12.580]   So when the mother said, the kid said,
[02:04:12.580 --> 02:04:13.500]   "Okay, Google," the father said,
[02:04:13.500 --> 02:04:15.340]   "No, no, kids say goo."
[02:04:15.340 --> 02:04:18.300]   And no, no, it was hearing us say all the time,
[02:04:18.300 --> 02:04:19.860]   "Okay, you know who."
[02:04:19.860 --> 02:04:20.860]   And it was mimicking us.
[02:04:20.860 --> 02:04:23.140]   - It was easy anyway, 'cause they do say goo.
[02:04:23.140 --> 02:04:24.060]   - They do say goo, right?
[02:04:24.060 --> 02:04:25.780]   So it's goo-goo, right?
[02:04:25.780 --> 02:04:27.300]   Okay, goo-goo.
[02:04:27.300 --> 02:04:28.860]   - I can't see work. - I can't see work.
[02:04:28.860 --> 02:04:29.700]   - It did?
[02:04:29.700 --> 02:04:31.380]   - Yeah, it did.
[02:04:31.380 --> 02:04:34.220]   - There's a whole bunch of stuff on Reddit
[02:04:34.220 --> 02:04:37.900]   about other words you can use to trigger your devices.
[02:04:37.900 --> 02:04:38.940]   - Right. - And what words
[02:04:38.940 --> 02:04:40.300]   people are using, 'cause it's fun
[02:04:40.300 --> 02:04:43.340]   to use something besides, you know, the usual.
[02:04:43.340 --> 02:04:44.380]   People complain about that.
[02:04:44.380 --> 02:04:47.020]   I see those with a plate that's a dumb trigger.
[02:04:47.020 --> 02:04:48.860]   - Oh, that's so bad.
[02:04:48.860 --> 02:04:50.900]   - I do wish you could change triggers.
[02:04:50.900 --> 02:04:52.620]   That will come, I guess.
[02:04:52.620 --> 02:04:53.740]   That's really interesting.
[02:04:53.740 --> 02:04:56.700]   So first words, okay, goo-goo.
[02:04:56.700 --> 02:05:00.900]   Well, I think we can wrap it.
[02:05:00.900 --> 02:05:03.140]   I don't want it to take any more of your time.
[02:05:03.140 --> 02:05:07.940]   We got two picks from Stacey, so that kind of feels like--
[02:05:07.940 --> 02:05:09.500]   - That is your weekend, dammit.
[02:05:09.500 --> 02:05:10.620]   - We've done our job.
[02:05:10.620 --> 02:05:12.500]   Well, I'm never in a hurry to get out of this show.
[02:05:12.500 --> 02:05:13.420]   I love doing it.
[02:05:13.420 --> 02:05:15.340]   It's a lot of fun.
[02:05:15.340 --> 02:05:19.220]   And besides, I gotta go buy a magically headset.
[02:05:19.220 --> 02:05:20.780]   I got stuck. - No, don't do it.
[02:05:20.780 --> 02:05:23.020]   Stop yourself. - No, stop.
[02:05:23.020 --> 02:05:25.300]   I wish I did have that ability to just say,
[02:05:25.300 --> 02:05:26.820]   "No, you're not gonna."
[02:05:26.820 --> 02:05:29.460]   But I, you know, what happens is I say it,
[02:05:29.460 --> 02:05:32.460]   and then I think about it for days.
[02:05:32.460 --> 02:05:33.500]   - So what's killing me is I don't,
[02:05:33.500 --> 02:05:35.980]   we're gonna have a new phone.
[02:05:35.980 --> 02:05:37.140]   - Yeah, it's gonna be expensive.
[02:05:37.140 --> 02:05:39.540]   - And we're gonna have maybe a new Pixelbook.
[02:05:39.540 --> 02:05:40.540]   - Yep, yep.
[02:05:40.540 --> 02:05:43.900]   - And maybe a Pixel brand watch.
[02:05:43.900 --> 02:05:45.300]   - You got nothing. - This is a bankrupt thing.
[02:05:45.300 --> 02:05:46.140]   - You got nothing.
[02:05:46.140 --> 02:05:46.980]   I have to buy everything.
[02:05:46.980 --> 02:05:49.420]   You just buy Google stuff.
[02:05:49.420 --> 02:05:51.860]   You got no reason to complain.
[02:05:51.860 --> 02:05:57.780]   By the way, this just in Mailchimp has now dumped Alex Jones.
[02:05:57.780 --> 02:05:58.620]   - Yes.
[02:05:58.620 --> 02:06:01.020]   (laughing)
[02:06:01.020 --> 02:06:03.220]   Next friend. - Wow.
[02:06:03.220 --> 02:06:04.620]   - He's off of Friend's Drew.
[02:06:04.620 --> 02:06:08.420]   - It's one thing to be thrown off of Facebook,
[02:06:08.420 --> 02:06:11.580]   but in Mailchimp says you can't use our service.
[02:06:11.580 --> 02:06:14.500]   Man, that's bad.
[02:06:14.500 --> 02:06:16.500]   (laughing)
[02:06:16.500 --> 02:06:17.540]   Thank you, Jeff Jarvis.
[02:06:17.540 --> 02:06:19.500]   You'll find him at the City University of New York.
[02:06:19.500 --> 02:06:21.260]   When's the semester begin soon?
[02:06:21.260 --> 02:06:22.580]   - Next week, I started brainwashed
[02:06:22.580 --> 02:06:23.900]   the new students all next week.
[02:06:23.900 --> 02:06:26.060]   - Gutenberg time. - Gutenberg time.
[02:06:26.060 --> 02:06:28.260]   Those are some damn lucky kids.
[02:06:28.260 --> 02:06:30.540]   Are a lot of them straight out of college
[02:06:30.540 --> 02:06:32.140]   or in the graduate program,
[02:06:32.140 --> 02:06:32.980]   or a lot of them re-entry?
[02:06:32.980 --> 02:06:34.140]   - It's just like 27.
[02:06:34.140 --> 02:06:35.780]   - Yeah, so most of them have had jobs,
[02:06:35.780 --> 02:06:36.620]   and now they're-- - There are a lot
[02:06:36.620 --> 02:06:38.980]   of jobs, career shifters, summer out of college.
[02:06:38.980 --> 02:06:39.860]   It's quite a great mix.
[02:06:39.860 --> 02:06:43.220]   We have a huge class, our enrollment's way up,
[02:06:43.220 --> 02:06:45.860]   and that's good.
[02:06:45.860 --> 02:06:48.900]   - That's fantastic. - At the Craig Newmark
[02:06:48.900 --> 02:06:49.980]   Graduate School of Journalism
[02:06:49.980 --> 02:06:51.460]   at the City University of New York.
[02:06:51.460 --> 02:06:52.380]   - Beautiful.
[02:06:52.380 --> 02:06:55.260]   It's a beautiful thing.
[02:06:55.260 --> 02:06:56.260]   - It is a beautiful thing.
[02:06:56.260 --> 02:06:57.100]   - Yeah, indeed.
[02:06:57.100 --> 02:06:59.540]   - And thank Craig for, I'm sure you have,
[02:06:59.540 --> 02:07:01.300]   for endowing that chair.
[02:07:01.300 --> 02:07:02.140]   It's a good thing.
[02:07:02.140 --> 02:07:05.260]   He's Craig of Craig's list.
[02:07:05.260 --> 02:07:07.900]   He's taking the money, he'll gotten gained
[02:07:07.900 --> 02:07:09.900]   from putting newspapers out of business
[02:07:09.900 --> 02:07:12.100]   and funded journalism. - Oh, oh, oh.
[02:07:12.100 --> 02:07:14.300]   - How confusing is that?
[02:07:14.300 --> 02:07:17.700]   - All that money he left in the pockets of consumers.
[02:07:17.700 --> 02:07:19.140]   - Yeah, you're right.
[02:07:19.140 --> 02:07:21.500]   We do this week in Google every Wednesday,
[02:07:21.500 --> 02:07:24.700]   130 Pacific, 430 Eastern, 2030 UTC.
[02:07:24.700 --> 02:07:26.020]   You could watch live if you wanted,
[02:07:26.020 --> 02:07:29.340]   twit.tv/live, we stream audio and video.
[02:07:29.340 --> 02:07:31.300]   There's four or five streams you can choose from
[02:07:31.300 --> 02:07:32.580]   and pick the one you like.
[02:07:32.580 --> 02:07:35.580]   And if you do watch it live, you should chat live.
[02:07:35.580 --> 02:07:38.820]   'Cause that's just a bunch of people just like you
[02:07:38.820 --> 02:07:42.740]   at IRC.twit.tv and we're all talking about the same thing.
[02:07:42.740 --> 02:07:44.700]   Never.
[02:07:44.700 --> 02:07:45.740]   (laughs)
[02:07:45.740 --> 02:07:46.580]   It's still fun.
[02:07:46.580 --> 02:07:49.780]   IRC.twit.tv.
[02:07:49.780 --> 02:07:52.500]   And if incidentally,
[02:07:52.500 --> 02:07:56.500]   you would like to download on demand versions of the show,
[02:07:56.500 --> 02:07:59.420]   you can also do that at twit.tv/twig
[02:07:59.420 --> 02:08:01.380]   or subscribe in your favorite podcatcher.
[02:08:01.380 --> 02:08:02.780]   Thanks for joining us.
[02:08:02.780 --> 02:08:04.540]   And we'll see you next Wednesday
[02:08:04.540 --> 02:08:05.380]   on this week in Google.
[02:08:05.380 --> 02:08:06.820]   Bye bye.
[02:08:06.820 --> 02:08:07.940]   - Bye.
[02:08:07.940 --> 02:08:08.780]   - Bye bye everybody.
[02:08:08.780 --> 02:08:09.620]   - Bye bye.
[02:08:09.620 --> 02:08:10.460]   - Bye bye.
[02:08:10.460 --> 02:08:11.300]   - Bye bye Google.
[02:08:11.300 --> 02:08:12.220]   - Bye bye.
[02:08:12.220 --> 02:08:13.300]   - Bye bye Google.
[02:08:13.300 --> 02:08:15.880]   (upbeat music)
[02:08:15.880 --> 02:08:18.460]   (upbeat music)
[02:08:18.460 --> 02:08:25.460]   Thanks for watching!

