;FFMETADATA1
title=A Machete, A Shotgun, and a Votive Candle!
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=256
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons Attribution Non-Commercial Share-Alike license. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2014
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:02.120]   It's time for Twig this week in Google,
[00:00:02.120 --> 00:00:04.820]   Leo's in Hawaii drinking a beverage with a tiny umbrella in it.
[00:00:04.820 --> 00:00:07.120]   My name's Mike Elgin and I'm filling in for Leo.
[00:00:07.120 --> 00:00:10.160]   Jeff and Gina are here and will be sifting through the aftermath
[00:00:10.160 --> 00:00:12.200]   of last week's Google I/O.
[00:00:12.200 --> 00:00:14.880]   Stick around. This week in Google is next.
[00:00:14.880 --> 00:00:18.200]   [music]
[00:00:18.200 --> 00:00:19.960]   Netcast you love.
[00:00:19.960 --> 00:00:21.840]   From people you trust.
[00:00:21.840 --> 00:00:25.360]   [music]
[00:00:25.360 --> 00:00:27.200]   This is Twig.
[00:00:27.200 --> 00:00:30.760]   Bandwidth for this week in Google is provided by
[00:00:30.760 --> 00:00:35.160]   Cashfly, C-A-C-H-E-F-L-Y.com.
[00:00:35.160 --> 00:00:39.000]   [music]
[00:00:39.000 --> 00:00:43.000]   This is Twig. This week in Google, episode 256,
[00:00:43.000 --> 00:00:46.000]   recorded July 2, 2014.
[00:00:46.000 --> 00:00:49.600]   A machete, a shotgun, and a votive candle.
[00:00:49.600 --> 00:00:53.760]   It's time for Twig this week in Google where we cover all things
[00:00:53.760 --> 00:00:55.600]   cloudy and googlycious.
[00:00:55.600 --> 00:00:58.120]   With us today is the usual cast of characters.
[00:00:58.120 --> 00:00:59.680]   I am not Leo LaPorte.
[00:00:59.680 --> 00:01:00.560]   That's the bad news.
[00:01:00.560 --> 00:01:02.840]   The good news, we have Jeff and Gina with us,
[00:01:02.840 --> 00:01:04.160]   starting with Jeff Jarvis,
[00:01:04.160 --> 00:01:07.200]   professor of journalism at City University of New York.
[00:01:07.200 --> 00:01:09.840]   I heard on this show that you've been recently
[00:01:09.840 --> 00:01:13.560]   anointed with total professorial powers.
[00:01:13.560 --> 00:01:15.160]   You cannot be touched.
[00:01:15.160 --> 00:01:16.480]   Yes, that's true.
[00:01:16.480 --> 00:01:17.680]   I have tenure too, so.
[00:01:17.680 --> 00:01:19.240]   No, that's a heck with you.
[00:01:19.240 --> 00:01:20.560]   That too, why not?
[00:01:20.560 --> 00:01:22.680]   Boy, we should have tenure here at Twig.
[00:01:22.680 --> 00:01:23.840]   That'd be great.
[00:01:23.840 --> 00:01:24.880]   [laughter]
[00:01:24.880 --> 00:01:26.720]   Author of Public Parts, what would Google do?
[00:01:26.720 --> 00:01:30.640]   And Gutenberg, the geek, also you blog at buzzmachine.com.
[00:01:30.640 --> 00:01:32.600]   I love your blog, always have.
[00:01:32.600 --> 00:01:35.720]   And I'm glad I'm here on this show.
[00:01:35.720 --> 00:01:37.280]   I always listen to this show and it's great to be here.
[00:01:37.280 --> 00:01:37.920]   I can finally--
[00:01:37.920 --> 00:01:38.440]   At the head?
[00:01:38.440 --> 00:01:38.920]   Here.
[00:01:38.920 --> 00:01:42.040]   Somebody will hear me when I talk it back at you guys.
[00:01:42.040 --> 00:01:44.880]   And Gina Trapani, creator of thinkup.com,
[00:01:44.880 --> 00:01:47.240]   host of Twits All About Android,
[00:01:47.240 --> 00:01:50.160]   and founding editor of Life Hacker.
[00:01:50.160 --> 00:01:50.640]   How you doing?
[00:01:50.640 --> 00:01:51.560]   Hello.
[00:01:51.560 --> 00:01:52.640]   Great to be here.
[00:01:52.640 --> 00:01:55.200]   How did I not see either one of you at Google I/O?
[00:01:55.200 --> 00:01:56.200]   I didn't see either one of you.
[00:01:56.200 --> 00:01:57.600]   Because you were busy working, Mike.
[00:01:57.600 --> 00:01:58.600]   You were working.
[00:01:58.600 --> 00:01:59.120]   You were working.
[00:01:59.120 --> 00:02:00.400]   Remember that.
[00:02:00.400 --> 00:02:02.160]   It was a busy couple of days.
[00:02:02.160 --> 00:02:02.520]   Yeah.
[00:02:02.520 --> 00:02:03.040]   It was.
[00:02:03.040 --> 00:02:03.480]   It was crazy.
[00:02:03.480 --> 00:02:05.160]   You know, the greatest thing--
[00:02:05.160 --> 00:02:06.520]   day two, I went to a session.
[00:02:06.520 --> 00:02:07.040]   I did this and that.
[00:02:07.040 --> 00:02:08.680]   But of course, most of them aren't meant for me.
[00:02:08.680 --> 00:02:11.000]   But I would just stand in the hall and honest to God,
[00:02:11.000 --> 00:02:13.400]   one after another after another of you
[00:02:13.400 --> 00:02:15.880]   magnificent Twig fans would come up and say, hey,
[00:02:15.880 --> 00:02:17.800]   Jeff Jarvis, I'm a fan of Twig.
[00:02:17.800 --> 00:02:18.720]   And we'd take pictures.
[00:02:18.720 --> 00:02:20.520]   And it was just-- I could have spent the whole day just
[00:02:20.520 --> 00:02:21.360]   talking to Twig fans.
[00:02:21.360 --> 00:02:23.000]   It was wonderful.
[00:02:23.000 --> 00:02:24.840]   Those are definitely our people, aren't they?
[00:02:24.840 --> 00:02:26.240]   At Google I/O.
[00:02:26.240 --> 00:02:26.880]   Yeah.
[00:02:26.880 --> 00:02:27.880]   It was pretty awesome.
[00:02:27.880 --> 00:02:28.680]   It's the one moment.
[00:02:28.680 --> 00:02:30.600]   There was one time they really feel like a celebrity.
[00:02:30.600 --> 00:02:32.440]   I had people stop and ask to take pictures with me too.
[00:02:32.440 --> 00:02:34.040]   And I was like, this is crazy.
[00:02:34.040 --> 00:02:34.920]   I was telling my mom.
[00:02:34.920 --> 00:02:36.280]   She was just like, what?
[00:02:36.280 --> 00:02:37.480]   I was like, yeah, mom.
[00:02:37.480 --> 00:02:37.980]   Yeah.
[00:02:37.980 --> 00:02:38.680]   For real.
[00:02:38.680 --> 00:02:39.480]   Same thing for me.
[00:02:39.480 --> 00:02:41.520]   You take one step out the door into the streets of San
[00:02:41.520 --> 00:02:43.560]   Francisco and you are nobody.
[00:02:43.560 --> 00:02:45.800]   So that was a lot of fun.
[00:02:45.800 --> 00:02:48.800]   So Google is buying or has bought
[00:02:48.800 --> 00:02:51.880]   songs, music play service that competes with the likes
[00:02:51.880 --> 00:02:53.840]   of all the music services.
[00:02:53.840 --> 00:02:55.400]   To me, in terms of functionality,
[00:02:55.400 --> 00:02:57.200]   in terms of its sense of curation,
[00:02:57.200 --> 00:02:59.600]   I think it competes very closely with Google,
[00:02:59.600 --> 00:03:03.680]   with Apple's Beats Music Service.
[00:03:03.680 --> 00:03:05.440]   Kind of sort of.
[00:03:05.440 --> 00:03:06.840]   Jeff and Gina, why did they buy this?
[00:03:06.840 --> 00:03:07.680]   Let's start with you, Jeff.
[00:03:07.680 --> 00:03:09.320]   Why did they buy this?
[00:03:09.320 --> 00:03:09.880]   Music service.
[00:03:09.880 --> 00:03:10.960]   Oh, Gina first?
[00:03:10.960 --> 00:03:12.080]   They need music.
[00:03:12.080 --> 00:03:13.080]   I think it's as simple as that.
[00:03:13.080 --> 00:03:16.920]   And I think they can go cheaper than Apple's gone with Beats.
[00:03:16.920 --> 00:03:19.760]   And these music services are going to get snapped up
[00:03:19.760 --> 00:03:21.280]   because they have an audience.
[00:03:21.280 --> 00:03:23.560]   But did Google need cheaper?
[00:03:23.560 --> 00:03:27.080]   I mean, it's like, they throw around billions of dollars
[00:03:27.080 --> 00:03:27.880]   like it's nothing.
[00:03:27.880 --> 00:03:30.680]   And here they probably spent more than $39 million.
[00:03:30.680 --> 00:03:32.240]   The evaluation was--
[00:03:32.240 --> 00:03:34.360]   somewhere around $15 million that there's apparently
[00:03:34.360 --> 00:03:35.520]   competition.
[00:03:35.520 --> 00:03:37.520]   That's Padre's chocolate budget.
[00:03:37.520 --> 00:03:38.200]   Yeah, right.
[00:03:38.200 --> 00:03:38.680]   Exactly.
[00:03:38.680 --> 00:03:40.240]   Well, yeah.
[00:03:40.240 --> 00:03:41.760]   Who can keep up with that?
[00:03:41.760 --> 00:03:42.440]   It's not much.
[00:03:42.440 --> 00:03:45.400]   And I think that the truth is that at times Google does know
[00:03:45.400 --> 00:03:47.520]   it's built or buy, and times Google knows
[00:03:47.520 --> 00:03:49.120]   that it should buy and not build.
[00:03:49.120 --> 00:03:53.880]   Well, so you obviously have an intimate familiarity with Google.
[00:03:53.880 --> 00:03:56.480]   The secret sauce of songs is human curation.
[00:03:56.480 --> 00:03:59.520]   That doesn't sound like a Google thing to me.
[00:03:59.520 --> 00:04:01.240]   Yeah, as we learned in the organization of Bio,
[00:04:01.240 --> 00:04:03.800]   a couple times last week, humans are not Google's specialty.
[00:04:03.800 --> 00:04:04.800]   Yeah.
[00:04:04.800 --> 00:04:05.400]   I'm joking.
[00:04:05.400 --> 00:04:05.880]   I'm joking.
[00:04:05.880 --> 00:04:06.840]   I was very happy to be there.
[00:04:06.840 --> 00:04:07.840]   I'm not complaining at all.
[00:04:07.840 --> 00:04:09.080]   It's big, big, big, big, big, little joke.
[00:04:09.080 --> 00:04:10.960]   Just a little joke, but the lines, it's all but it really
[00:04:10.960 --> 00:04:11.560]   was really good.
[00:04:11.560 --> 00:04:12.320]   It was really good.
[00:04:12.320 --> 00:04:14.000]   No, I think songs--
[00:04:14.000 --> 00:04:16.880]   I don't use it, so I don't know that much about it.
[00:04:16.880 --> 00:04:19.120]   So Gina, do you use it?
[00:04:19.120 --> 00:04:23.280]   I don't use songs, though, but I do use Google Play music a lot.
[00:04:23.280 --> 00:04:25.040]   And so it kind of makes sense to me
[00:04:25.040 --> 00:04:28.760]   that Google would look to snap up a company like this
[00:04:28.760 --> 00:04:31.960]   for a relatively small price and Google scale,
[00:04:31.960 --> 00:04:36.280]   financial anyway, that can help them improve their--
[00:04:36.280 --> 00:04:36.960]   I listen to it.
[00:04:36.960 --> 00:04:38.440]   I'm feeling lucky radio a lot.
[00:04:38.440 --> 00:04:40.280]   That's basically what I just do at this point.
[00:04:40.280 --> 00:04:41.760]   I just go into Google Play music.
[00:04:41.760 --> 00:04:42.720]   It has my music.
[00:04:42.720 --> 00:04:43.600]   It knows what I like.
[00:04:43.600 --> 00:04:45.080]   I press I'm feeling lucky.
[00:04:45.080 --> 00:04:48.000]   And it's pretty good some of the time.
[00:04:48.000 --> 00:04:50.560]   So if an acquisition like this makes that better,
[00:04:50.560 --> 00:04:53.320]   I think it makes a lot of sense.
[00:04:53.320 --> 00:04:55.840]   One of the crazy things about Songza
[00:04:55.840 --> 00:04:59.880]   is that it changes the playlist based on your context.
[00:04:59.880 --> 00:05:01.440]   And that is a very Googly thing.
[00:05:01.440 --> 00:05:03.000]   It's also advertiser-supported.
[00:05:03.000 --> 00:05:04.160]   That's a Googly thing.
[00:05:04.160 --> 00:05:07.720]   But the context even goes so far as a deal
[00:05:07.720 --> 00:05:09.880]   that they have with the weather channel that
[00:05:09.880 --> 00:05:13.640]   changes the songs based on the weather, based on your weather.
[00:05:13.640 --> 00:05:15.920]   Well, of course, Mike, if this were bought by Facebook,
[00:05:15.920 --> 00:05:18.640]   they would know when you're sad because they made you sad.
[00:05:18.640 --> 00:05:20.960]   So they play you sad music and then play you happy music
[00:05:20.960 --> 00:05:21.840]   to make you happier.
[00:05:21.840 --> 00:05:23.960]   So they manipulate your feelings constantly, right?
[00:05:23.960 --> 00:05:25.560]   I'm so glad you brought that up.
[00:05:25.560 --> 00:05:28.240]   Why don't we talk about that?
[00:05:28.240 --> 00:05:32.400]   This really chaps my hide here, this Facebook thing,
[00:05:32.400 --> 00:05:34.720]   because for a number of reasons, yesterday we
[00:05:34.720 --> 00:05:35.960]   talked on on techniques today.
[00:05:35.960 --> 00:05:39.520]   We were talking to the person, Cashmere Hill,
[00:05:39.520 --> 00:05:43.880]   that Forbes, who broke the story that, in fact, when they--
[00:05:43.880 --> 00:05:47.800]   in 2012 when they actually tested the feature to see
[00:05:47.800 --> 00:05:50.800]   if they can make people sad or happy based on what--
[00:05:50.800 --> 00:05:53.520]   they're tweaking their feeds, that they didn't actually
[00:05:53.520 --> 00:05:58.120]   have explicit language in the terms of service
[00:05:58.120 --> 00:06:02.040]   talking about research and the sorts of things
[00:06:02.040 --> 00:06:03.720]   that they, in fact, did.
[00:06:03.720 --> 00:06:05.400]   Facebook countered to that saying, oh, it's
[00:06:05.400 --> 00:06:06.520]   all about improving the service.
[00:06:06.520 --> 00:06:07.720]   That's what it was all about.
[00:06:07.720 --> 00:06:10.360]   That's always been in terms of service.
[00:06:10.360 --> 00:06:14.280]   So that's one problematic aspect to this.
[00:06:14.280 --> 00:06:19.640]   But to me, this is an example of Facebook's show--
[00:06:19.640 --> 00:06:22.240]   and probably Google, too, which is--
[00:06:22.240 --> 00:06:25.240]   they're so used to messing around and determining
[00:06:25.240 --> 00:06:27.040]   what we see and what we don't see,
[00:06:27.040 --> 00:06:30.640]   that the reasons for doing that are not as important to them
[00:06:30.640 --> 00:06:33.480]   as it probably is to the public.
[00:06:33.480 --> 00:06:38.400]   I mean, it's just like to actually affect people's moods.
[00:06:38.400 --> 00:06:40.320]   I mean, Gina, do you use Facebook?
[00:06:40.320 --> 00:06:42.360]   Do you know what you're doing?
[00:06:42.360 --> 00:06:43.920]   I do use Facebook.
[00:06:43.920 --> 00:06:45.160]   And I thought about this a lot.
[00:06:45.160 --> 00:06:48.600]   And my first gut reaction, I'm sad to admit,
[00:06:48.600 --> 00:06:50.520]   was very much the sort of--
[00:06:50.520 --> 00:06:52.600]   yeah, it made me sad.
[00:06:52.600 --> 00:06:54.800]   I kind of took this technologist view
[00:06:54.800 --> 00:06:57.240]   where I was like, well, companies, AB test things
[00:06:57.240 --> 00:06:58.600]   all the time, right?
[00:06:58.600 --> 00:07:02.160]   Like so many products are constantly tweaking.
[00:07:02.160 --> 00:07:02.840]   Google does this.
[00:07:02.840 --> 00:07:04.520]   I mean, everything is run on an algorithm.
[00:07:04.520 --> 00:07:07.240]   Everything is data-driven based on reactions and clicks.
[00:07:07.240 --> 00:07:08.920]   And everything is being adjusted.
[00:07:08.920 --> 00:07:11.640]   So it didn't surprise me at all that Facebook did this.
[00:07:11.640 --> 00:07:16.280]   I was a little surprised at the outcry about the ethics of it.
[00:07:16.280 --> 00:07:20.720]   I suppose the idea that users should have been informed
[00:07:20.720 --> 00:07:23.880]   in a more explicit way makes sense to me.
[00:07:23.880 --> 00:07:25.480]   But I was kind of--
[00:07:25.480 --> 00:07:29.520]   I mean, I think there was a lack of empathy
[00:07:29.520 --> 00:07:31.240]   about the communication about this, right?
[00:07:31.240 --> 00:07:32.640]   Like, the communication should have been clearer
[00:07:32.640 --> 00:07:34.880]   but the terms of service wasn't enough.
[00:07:34.880 --> 00:07:37.840]   These folks should have been able to let know.
[00:07:37.840 --> 00:07:39.360]   But at the same time, I kind of was like,
[00:07:39.360 --> 00:07:41.640]   this is constantly going on.
[00:07:41.640 --> 00:07:44.600]   How is this different than AB testing a headline
[00:07:44.600 --> 00:07:48.000]   or an email subject line, which goes on constantly?
[00:07:48.000 --> 00:07:48.520]   Exactly.
[00:07:48.520 --> 00:07:52.520]   And every marketer out there, every entertainment,
[00:07:52.520 --> 00:07:55.160]   every politician and political campaign
[00:07:55.160 --> 00:07:56.000]   does the same thing.
[00:07:56.000 --> 00:07:58.880]   But it's kind of a technopanic thing again, right?
[00:07:58.880 --> 00:08:00.600]   Facebook was tone-definite communication.
[00:08:00.600 --> 00:08:03.360]   You were absolutely right about that.
[00:08:03.360 --> 00:08:05.760]   They got caught rather than being open about this.
[00:08:05.760 --> 00:08:07.280]   And there have been experiments in the past.
[00:08:07.280 --> 00:08:12.880]   I remember that Yahoo had a great lab that was--
[00:08:12.880 --> 00:08:17.640]   test AB testing, behavioral impact on people.
[00:08:17.640 --> 00:08:21.840]   I'm not against that in theory.
[00:08:21.840 --> 00:08:23.960]   But when it hurts your business because of the way
[00:08:23.960 --> 00:08:26.000]   it's discovered, then that's just stupid.
[00:08:26.000 --> 00:08:27.960]   And I think Sheryl Sandberg has basically said that.
[00:08:27.960 --> 00:08:30.320]   They certainly had a communications problem on this.
[00:08:30.320 --> 00:08:32.400]   Well, I think this is slightly different
[00:08:32.400 --> 00:08:34.560]   than your average garden variety technopanic.
[00:08:34.560 --> 00:08:37.720]   And I'm always with you on the technopanic argument, Jeff,
[00:08:37.720 --> 00:08:38.200]   that you make.
[00:08:38.200 --> 00:08:42.440]   But in this case, actually making people sad on purpose.
[00:08:42.440 --> 00:08:43.440]   That's an exaggeration.
[00:08:43.440 --> 00:08:45.440]   They didn't make-- that many people that sad.
[00:08:45.440 --> 00:08:50.520]   No, but Mike, that's what every chick flick does.
[00:08:50.520 --> 00:08:51.640]   Yeah, but people know it.
[00:08:51.640 --> 00:08:54.120]   I think a big part of this story that's interesting
[00:08:54.120 --> 00:08:55.560]   is the degree to which people are not
[00:08:55.560 --> 00:09:00.320]   aware that algorithm noise filtering goes on.
[00:09:00.320 --> 00:09:03.440]   But let's do talk about the technopanic aspect of it.
[00:09:03.440 --> 00:09:05.680]   Let's say they discovered, which in fact they did,
[00:09:05.680 --> 00:09:08.000]   they came to the conclusion, one of the conclusions
[00:09:08.000 --> 00:09:10.080]   of the paper that was published around this,
[00:09:10.080 --> 00:09:13.120]   is that in fact, mood is contagious.
[00:09:13.120 --> 00:09:17.320]   If they can tweak your newsfeed to be happier or sadder,
[00:09:17.320 --> 00:09:20.560]   you tend to post things that are happier or sadder.
[00:09:20.560 --> 00:09:22.560]   There's some question about whether it's good science,
[00:09:22.560 --> 00:09:24.440]   whether that's a legitimate conclusion.
[00:09:24.440 --> 00:09:25.840]   But that was their conclusion.
[00:09:25.840 --> 00:09:27.120]   So let's say that's true.
[00:09:27.120 --> 00:09:30.400]   And let's say they did conclude that and that's the conclusion.
[00:09:30.400 --> 00:09:34.600]   So maybe Facebook wants to make your newsfeed a happy place.
[00:09:34.600 --> 00:09:36.960]   Maybe they decide that as a matter of policy,
[00:09:36.960 --> 00:09:39.680]   because nobody knows-- this is the part that bothers me.
[00:09:39.680 --> 00:09:41.080]   Nobody knows what their algorithms are.
[00:09:41.080 --> 00:09:42.480]   They even got rid of the name.
[00:09:42.480 --> 00:09:44.080]   It's sort of like in the Soviet Union,
[00:09:44.080 --> 00:09:46.120]   when they used to erase people from the photographs.
[00:09:46.120 --> 00:09:47.880]   People were-- too many people were throwing around
[00:09:47.880 --> 00:09:49.440]   the E word, ED rank.
[00:09:49.440 --> 00:09:52.000]   So they basically said, well, now it's not called ED rank
[00:09:52.000 --> 00:09:52.280]   anymore.
[00:09:52.280 --> 00:09:53.080]   It doesn't have a name.
[00:09:53.080 --> 00:09:55.680]   Now we can't really talk about it all that clearly.
[00:09:55.680 --> 00:09:57.160]   But they do have secret algorithms
[00:09:57.160 --> 00:09:58.600]   that nobody is aware of.
[00:09:58.600 --> 00:09:59.680]   They're changing constantly.
[00:09:59.680 --> 00:10:02.320]   They're testing them constantly.
[00:10:02.320 --> 00:10:04.720]   What if Facebook or some other social network
[00:10:04.720 --> 00:10:10.840]   decided to deliberately improve the service by making it
[00:10:10.840 --> 00:10:12.080]   everybody happy?
[00:10:12.080 --> 00:10:15.640]   Jeff, is that a technopanic reaction as well?
[00:10:15.640 --> 00:10:19.200]   Well, I'll be an old tabloid guy.
[00:10:19.200 --> 00:10:21.960]   I'll play into this and panic you more.
[00:10:21.960 --> 00:10:29.000]   There was a hedge fund that I wrote about this in public parts.
[00:10:29.000 --> 00:10:32.040]   A computer scientist at the University of Indiana
[00:10:32.040 --> 00:10:36.680]   tracked six moods and their opposites with various keywords
[00:10:36.680 --> 00:10:39.520]   and found that he could predict the daily ups and downs
[00:10:39.520 --> 00:10:42.120]   in the Dow Jones with more than 90% accuracy.
[00:10:42.120 --> 00:10:43.000]   So guess what happened?
[00:10:43.000 --> 00:10:45.480]   A hedge fund hired his butt, and they
[00:10:45.480 --> 00:10:47.280]   created a new hedge fund based on this.
[00:10:47.280 --> 00:10:48.760]   Now the next step-- I said at the time,
[00:10:48.760 --> 00:10:50.640]   the next step behind this is, of course,
[00:10:50.640 --> 00:10:53.160]   you'll try to manipulate the mood of the country
[00:10:53.160 --> 00:10:56.000]   because you're going to arbitrage that mood.
[00:10:56.000 --> 00:10:58.000]   And if you read the wonderful Michael Lewis book
[00:10:58.000 --> 00:11:01.640]   Flash Boys, which I do recommend, it's phenomenal,
[00:11:01.640 --> 00:11:04.160]   it's not beyond Wall Street and marketers
[00:11:04.160 --> 00:11:07.600]   to do exactly that and to profit from it,
[00:11:07.600 --> 00:11:10.720]   to affect the mood of the country for a reason or another.
[00:11:10.720 --> 00:11:12.960]   So yeah, that's possible to be there.
[00:11:12.960 --> 00:11:14.240]   But at some point, there are cash bear
[00:11:14.240 --> 00:11:14.920]   heels in the world.
[00:11:14.920 --> 00:11:17.400]   And at some point, the truth will out and we'll figure it out.
[00:11:17.400 --> 00:11:19.240]   This reminds me of going back to the early days
[00:11:19.240 --> 00:11:20.400]   of television advertising.
[00:11:20.400 --> 00:11:23.080]   And I'm old enough to have been around almost then.
[00:11:23.080 --> 00:11:25.440]   When the panic of the time was, there
[00:11:25.440 --> 00:11:28.960]   was some liminal advertising and that things were shot at us
[00:11:28.960 --> 00:11:30.880]   and the screen would convince us, you know,
[00:11:30.880 --> 00:11:32.760]   buy deodorant, buy deodorant.
[00:11:32.760 --> 00:11:34.480]   You stink, you stink.
[00:11:34.480 --> 00:11:36.560]   And you start to believe it.
[00:11:36.560 --> 00:11:38.480]   Well, it was never really true.
[00:11:38.480 --> 00:11:44.600]   If we really believe that we are as a people, such sheeples,
[00:11:44.600 --> 00:11:48.680]   that a Facebook newsfeed could affect truly our entire mood
[00:11:48.680 --> 00:11:52.520]   and thus the country, then we got bigger problems, I think.
[00:11:52.520 --> 00:11:54.600]   Gina?
[00:11:54.600 --> 00:11:56.680]   Yeah, I mean, it's hard.
[00:11:56.680 --> 00:11:58.160]   We'd like to-- like, a lot of my friends
[00:11:58.160 --> 00:12:00.240]   would be really upset about me saying this right now.
[00:12:00.240 --> 00:12:02.560]   But because a lot of my friends, particularly
[00:12:02.560 --> 00:12:04.360]   in community management, were really
[00:12:04.360 --> 00:12:07.360]   upset about the fact that Facebook did not communicate this
[00:12:07.360 --> 00:12:09.640]   and that they were overusing their power.
[00:12:09.640 --> 00:12:13.240]   This is a power relationship and manipulating emotions.
[00:12:13.240 --> 00:12:14.600]   It's unethical.
[00:12:14.600 --> 00:12:17.760]   But I mean, if Facebook tweaks their newsfeed
[00:12:17.760 --> 00:12:20.680]   to make people happier when they use Facebook,
[00:12:20.680 --> 00:12:23.680]   how is that different than anybody building any product
[00:12:23.680 --> 00:12:26.320]   who's trying to create a better user experience, right?
[00:12:26.320 --> 00:12:28.560]   I mean, think about any sort of experience
[00:12:28.560 --> 00:12:29.480]   you have with a product.
[00:12:29.480 --> 00:12:33.440]   Of course, the maker is trying to make people feel happy
[00:12:33.440 --> 00:12:36.600]   or compelled to do any advertising
[00:12:36.600 --> 00:12:38.640]   it manipulates our emotions.
[00:12:38.640 --> 00:12:40.640]   Music and movies manipulate our emotions.
[00:12:40.640 --> 00:12:44.640]   I mean, I think we know that.
[00:12:44.640 --> 00:12:48.560]   So it felt like-- and also this finding that emotions
[00:12:48.560 --> 00:12:49.680]   are contagious.
[00:12:49.680 --> 00:12:51.760]   I mean, it's news, really?
[00:12:51.760 --> 00:12:53.960]   I mean, we're empathetic beings.
[00:12:53.960 --> 00:12:56.840]   I mean, do we need study on Facebook to find out
[00:12:56.840 --> 00:12:59.720]   that if you guys are sad, I'm also going to feel sad.
[00:12:59.720 --> 00:13:01.840]   Or if you're joyous and happy enough beat,
[00:13:01.840 --> 00:13:03.320]   that's not going to be a look contagious.
[00:13:03.320 --> 00:13:07.840]   I mean, it just didn't seem like news to me.
[00:13:07.840 --> 00:13:08.640]   I don't know.
[00:13:08.640 --> 00:13:09.880]   I feel like-- I don't know.
[00:13:09.880 --> 00:13:10.880]   What do you think, Mike?
[00:13:10.880 --> 00:13:15.640]   A little more critical about this than I thought.
[00:13:15.640 --> 00:13:17.960]   The reason I'm critical-- I'm critical for two reasons.
[00:13:17.960 --> 00:13:20.280]   The first reason is they don't make a super easy way
[00:13:20.280 --> 00:13:22.080]   for you to just turn it off.
[00:13:22.080 --> 00:13:23.080]   Google doesn't either.
[00:13:23.080 --> 00:13:25.040]   With Google, you can do noise filtering.
[00:13:25.040 --> 00:13:27.240]   You can choose a little bit or a lot.
[00:13:27.240 --> 00:13:28.880]   But you can't say, give me everything.
[00:13:28.880 --> 00:13:32.120]   I want the ability to just throw a switch that's right there.
[00:13:32.120 --> 00:13:34.560]   And everybody knows about that switch, where I just say,
[00:13:34.560 --> 00:13:35.360]   give me the fire hose.
[00:13:35.360 --> 00:13:37.600]   And then maybe I can decide for myself, it's too much.
[00:13:37.600 --> 00:13:39.120]   I want some noise filtering.
[00:13:39.120 --> 00:13:40.600]   I want some help.
[00:13:40.600 --> 00:13:44.120]   Of course, Facebook does now allow you to granular control
[00:13:44.120 --> 00:13:45.800]   of, I want more of this, less of this.
[00:13:45.800 --> 00:13:47.440]   I don't want to hear from this person, whatever.
[00:13:47.440 --> 00:13:48.960]   That exists for power user.
[00:13:48.960 --> 00:13:52.520]   But for the most part, this whole algorithm thing--
[00:13:52.520 --> 00:13:55.560]   you mentioned that lots of things make us happy or sad.
[00:13:55.560 --> 00:13:56.960]   Stories make us happy or sad.
[00:13:56.960 --> 00:14:01.520]   I think we go to stories to feel happy or sad on purpose.
[00:14:01.520 --> 00:14:06.760]   Whereas noise filtering is based on an assumption
[00:14:06.760 --> 00:14:08.720]   of ignorance by the public.
[00:14:08.720 --> 00:14:13.200]   Facebook knows that we want to believe that everyone that
[00:14:13.200 --> 00:14:15.880]   follows us will see everything we post.
[00:14:15.880 --> 00:14:18.160]   And we want to believe that everything that comes to us
[00:14:18.160 --> 00:14:20.360]   in our news feed is everything that we post.
[00:14:20.360 --> 00:14:22.680]   That's a whole other business issue, where, of course,
[00:14:22.680 --> 00:14:24.600]   Facebook is charging for access.
[00:14:24.600 --> 00:14:27.280]   And you don't know what it's going to unless you pay them,
[00:14:27.280 --> 00:14:28.360]   which is a whole issue.
[00:14:28.360 --> 00:14:29.760]   But on the other hand, at Google+,
[00:14:29.760 --> 00:14:30.960]   they don't do the charging thing.
[00:14:30.960 --> 00:14:36.680]   But of course, no one of our of your millions of followers
[00:14:36.680 --> 00:14:38.600]   see everything that you write.
[00:14:38.600 --> 00:14:39.840]   That they have an algorithm that--
[00:14:39.840 --> 00:14:40.640]   And is trying to do that.
[00:14:40.640 --> 00:14:42.080]   --tries to improve the service.
[00:14:42.080 --> 00:14:42.640]   I know it is.
[00:14:42.640 --> 00:14:43.680]   Yes, they're robbed.
[00:14:43.680 --> 00:14:45.640]   Everyone on the robbed, I tell you.
[00:14:45.640 --> 00:14:46.680]   Yeah.
[00:14:46.680 --> 00:14:52.320]   And it's the same solution that I would give to half
[00:14:52.320 --> 00:14:54.800]   the problems that we talk about on these shows
[00:14:54.800 --> 00:14:56.200]   when we're complaining about companies.
[00:14:56.200 --> 00:14:57.720]   I want transparency and control.
[00:14:57.720 --> 00:14:58.720]   That's what I want.
[00:14:58.720 --> 00:15:01.120]   I don't want a complete absence of transparency,
[00:15:01.120 --> 00:15:03.320]   and I don't want the removal of control.
[00:15:03.320 --> 00:15:06.200]   And that's essentially, more or less, what we've got right now.
[00:15:06.200 --> 00:15:10.280]   And I think that it's one thing to do noise filtering
[00:15:10.280 --> 00:15:13.720]   and just, OK, we trust Facebook to determine what our relationships
[00:15:13.720 --> 00:15:14.240]   are.
[00:15:14.240 --> 00:15:15.320]   Essentially, that's what they're doing.
[00:15:15.320 --> 00:15:16.720]   They're basically saying, you know what?
[00:15:16.720 --> 00:15:19.640]   You never like anything on @mildrud's page.
[00:15:19.640 --> 00:15:20.600]   Never comment there.
[00:15:20.600 --> 00:15:23.600]   Therefore, you're not going to see anything from @mildr anymore.
[00:15:23.600 --> 00:15:25.440]   And we're severing that relationship.
[00:15:25.440 --> 00:15:27.600]   And you think that you still have that relationship
[00:15:27.600 --> 00:15:29.640]   and then just somebody's being quiet or they're
[00:15:29.640 --> 00:15:31.120]   out of sight out of mind or whatever.
[00:15:31.120 --> 00:15:33.600]   But they're determining your relationships.
[00:15:33.600 --> 00:15:34.520]   That's the difference between--
[00:15:34.520 --> 00:15:36.120]   But that's a different issue from the happier sad.
[00:15:36.120 --> 00:15:39.280]   That's there's an algorithm filtering at all.
[00:15:39.280 --> 00:15:42.040]   And you're objecting to that algorithm filtering at all,
[00:15:42.040 --> 00:15:45.800]   which means you object, I think, to both Facebook and Google
[00:15:45.800 --> 00:15:47.440]   Plus, in that sense.
[00:15:47.440 --> 00:15:50.640]   I'm objecting to the lack of transparency.
[00:15:50.640 --> 00:15:52.280]   They should be really clear about it,
[00:15:52.280 --> 00:15:54.400]   because I talk to noobs all the time.
[00:15:54.400 --> 00:15:56.480]   And everybody's on Facebook, right?
[00:15:56.480 --> 00:15:57.760]   Everybody is on Facebook.
[00:15:57.760 --> 00:16:00.560]   That's the social network for everybody.
[00:16:00.560 --> 00:16:03.520]   And the vast majority of people I talk to, they're like, really?
[00:16:03.520 --> 00:16:04.040]   They do that.
[00:16:04.040 --> 00:16:07.600]   They have no idea that there's noise filtering on Facebook.
[00:16:07.600 --> 00:16:08.520]   No idea.
[00:16:08.520 --> 00:16:09.000]   OK.
[00:16:09.000 --> 00:16:11.520]   So what I want is you go to Facebook and there are buttons.
[00:16:11.520 --> 00:16:12.960]   Facebook, make me happy.
[00:16:12.960 --> 00:16:13.480]   Yes, that's right.
[00:16:13.480 --> 00:16:14.640]   It's so big and thoughtful.
[00:16:14.640 --> 00:16:15.920]   It's just make me angry.
[00:16:15.920 --> 00:16:17.560]   Make me melancholy.
[00:16:17.560 --> 00:16:20.080]   Show me the thought, I'll get kittens or I'll get lots of--
[00:16:20.080 --> 00:16:22.920]   Gina, that's what BuzzFeed cats are made for exactly.
[00:16:22.920 --> 00:16:23.440]   Exactly.
[00:16:23.440 --> 00:16:23.960]   True.
[00:16:23.960 --> 00:16:25.720]   It's true.
[00:16:25.720 --> 00:16:29.520]   It'd be all up worthy when I want to feel hopeful and happy.
[00:16:29.520 --> 00:16:31.560]   And just be in great--
[00:16:31.560 --> 00:16:34.480]   I will believe how I'm going to feel after I hit this button
[00:16:34.480 --> 00:16:35.000]   button.
[00:16:35.000 --> 00:16:36.920]   [LAUGHTER]
[00:16:36.920 --> 00:16:37.600]   Wouldn't that be--
[00:16:37.600 --> 00:16:41.040]   It surprised me with an emotion, Facebook.
[00:16:41.040 --> 00:16:43.400]   Make me feel nothing, Facebook.
[00:16:43.400 --> 00:16:49.160]   OK, so let's talk about Android 1, the reference platform
[00:16:49.160 --> 00:16:51.480]   that Google announced at Google I/O. This is for the next billion.
[00:16:51.480 --> 00:16:52.880]   They said it was for the next 5 billion.
[00:16:52.880 --> 00:16:55.280]   I thought that was a bit of a reach.
[00:16:55.280 --> 00:16:56.840]   But for the next billion--
[00:16:56.840 --> 00:17:00.240]   and what this is talking about is there are low-cost phones
[00:17:00.240 --> 00:17:03.200]   or a necessity in many, many countries in the world
[00:17:03.200 --> 00:17:06.480]   and many places of even wealthy countries.
[00:17:06.480 --> 00:17:09.720]   And so is that a horrible experience
[00:17:09.720 --> 00:17:12.000]   or is that a pretty darn good experience?
[00:17:12.000 --> 00:17:14.440]   And Google says that they want to make it a really good
[00:17:14.440 --> 00:17:18.120]   experience, even if this phone costs between $100 and $200
[00:17:18.120 --> 00:17:18.920]   unlocked.
[00:17:18.920 --> 00:17:23.120]   And so Android 1 is their reference platform solution
[00:17:23.120 --> 00:17:23.480]   to this.
[00:17:23.480 --> 00:17:25.080]   They're starting out launching in India.
[00:17:25.080 --> 00:17:27.280]   And of course, this is going to be rolled out across the globe.
[00:17:27.280 --> 00:17:30.200]   They'll be competing with all kinds of other companies
[00:17:30.200 --> 00:17:31.680]   going after this space.
[00:17:31.680 --> 00:17:36.520]   And to me, I think that this part of the conversation
[00:17:36.520 --> 00:17:40.840]   is part of another story that we've got in the rundown here,
[00:17:40.840 --> 00:17:46.520]   which is the idea that Google is feeling really compelled
[00:17:46.520 --> 00:17:50.560]   these days to lock down the experience, to not allow skins.
[00:17:50.560 --> 00:17:55.840]   It's the same thing with Android TV, Android Auto, Android Wear,
[00:17:55.840 --> 00:17:57.120]   and Android 1.
[00:17:57.120 --> 00:17:59.960]   These are all theoretically versions of Android,
[00:17:59.960 --> 00:18:03.320]   and you're not allowed to put your own custom interface on it.
[00:18:03.320 --> 00:18:05.080]   Is this something that's going to come
[00:18:05.080 --> 00:18:07.560]   to the regular version of Android, do you guys think?
[00:18:07.560 --> 00:18:09.440]   What do you think, Gina?
[00:18:09.440 --> 00:18:11.560]   Well, to me, I would phrase it a little differently.
[00:18:11.560 --> 00:18:15.760]   I think that rather than lock in the Android experience,
[00:18:15.760 --> 00:18:21.040]   I think that Google is putting, planting a flag and saying,
[00:18:21.040 --> 00:18:23.080]   this is the reference experience.
[00:18:23.080 --> 00:18:25.840]   This is a good Android experience.
[00:18:25.840 --> 00:18:27.600]   We're trying to create a model.
[00:18:27.600 --> 00:18:29.920]   Google knows that Android's a mobile operating system that's
[00:18:29.920 --> 00:18:31.400]   going to go out to the next billion people.
[00:18:31.400 --> 00:18:33.320]   That's going to go out to the rest of the world.
[00:18:33.320 --> 00:18:35.600]   And they don't want to leave the decision of what that experience
[00:18:35.600 --> 00:18:40.000]   is like to other manufacturers who are going to load on AOSP
[00:18:40.000 --> 00:18:41.600]   with none of the Google add-ons.
[00:18:41.600 --> 00:18:44.280]   They want to be first with that experience.
[00:18:44.280 --> 00:18:45.960]   I think it's great.
[00:18:45.960 --> 00:18:48.200]   I think Android is a great thing.
[00:18:48.200 --> 00:18:50.080]   I mean, certainly I don't think being locked down
[00:18:50.080 --> 00:18:51.000]   is a good thing.
[00:18:51.000 --> 00:18:54.280]   And certainly, I'm pro Android being open source.
[00:18:54.280 --> 00:18:56.600]   And I'm pro other companies, even if it's big companies,
[00:18:56.600 --> 00:19:00.840]   like Amazon or Microsoft, building a layer on top of Android.
[00:19:00.840 --> 00:19:05.200]   But I really like that Google is taking the lead on defining
[00:19:05.200 --> 00:19:08.680]   what a good Android experience is for their next users.
[00:19:08.680 --> 00:19:12.720]   Do you think this will increase Gina or decrease Amazon
[00:19:12.720 --> 00:19:17.040]   like forks or the kind that you see in China, where you see
[00:19:17.040 --> 00:19:19.320]   huge numbers of Android users never use a Play Store,
[00:19:19.320 --> 00:19:22.600]   for example, they're not using the regular version of Google.
[00:19:22.600 --> 00:19:26.520]   Will this increase or decrease that?
[00:19:26.520 --> 00:19:27.800]   Do you see what I'm saying?
[00:19:27.800 --> 00:19:31.360]   Because on the one hand, it's like companies who make phones
[00:19:31.360 --> 00:19:34.120]   might be like, well, if I can't put on my own stuff,
[00:19:34.120 --> 00:19:35.520]   then I don't want to play.
[00:19:35.520 --> 00:19:38.000]   That would increase the forks.
[00:19:38.000 --> 00:19:40.040]   And on the other hand, if it's really compelling
[00:19:40.040 --> 00:19:41.800]   and they've really got all the specs locked down,
[00:19:41.800 --> 00:19:43.200]   it's easy and low costs to do.
[00:19:43.200 --> 00:19:45.960]   And you can make a lot of money, that would decrease it.
[00:19:45.960 --> 00:19:47.960]   So which way do you think you go?
[00:19:47.960 --> 00:19:50.440]   I think the more Android users there are, the more forks
[00:19:50.440 --> 00:19:52.320]   they're going to be and the more users they're going
[00:19:52.320 --> 00:19:53.400]   to be and the better it is for Google,
[00:19:53.400 --> 00:19:55.720]   the better it is for everybody.
[00:19:55.720 --> 00:19:58.040]   I think that this is-- Android will be the first experience
[00:19:58.040 --> 00:19:59.640]   of getting online for a lot of people.
[00:19:59.640 --> 00:20:01.320]   And I think that that opens up opportunities,
[00:20:01.320 --> 00:20:04.000]   even for other manufacturers.
[00:20:04.000 --> 00:20:04.800]   But you're right.
[00:20:04.800 --> 00:20:05.840]   It could go both ways.
[00:20:05.840 --> 00:20:07.640]   But I think it's actually a good thing for Android.
[00:20:07.640 --> 00:20:09.400]   I think it means more Android for everyone,
[00:20:09.400 --> 00:20:11.920]   not just more Google Android.
[00:20:11.920 --> 00:20:12.420]   Yeah.
[00:20:12.420 --> 00:20:12.920]   Yeah.
[00:20:12.920 --> 00:20:15.120]   I think they're trying to have the cake and eat it too.
[00:20:15.120 --> 00:20:17.040]   And they might just accomplish it the way Google--
[00:20:17.040 --> 00:20:19.720]   well, Google can-- is that they get a lot of crap
[00:20:19.720 --> 00:20:21.360]   for the fragmentation.
[00:20:21.360 --> 00:20:23.080]   So this is a way to deal with that.
[00:20:23.080 --> 00:20:24.880]   But yet the open horse is out of the barn.
[00:20:24.880 --> 00:20:26.160]   And there are going to be-- I was changing
[00:20:26.160 --> 00:20:27.520]   and just said a lot more versions of that.
[00:20:27.520 --> 00:20:29.160]   And you can kind of have a choice.
[00:20:29.160 --> 00:20:33.080]   I was at a Deutsche Vella conference in Bonn two days ago
[00:20:33.080 --> 00:20:36.500]   and was talking with the head of a gigantic Indian public
[00:20:36.500 --> 00:20:37.800]   broadcaster there.
[00:20:37.800 --> 00:20:40.240]   I was talking about Android 1, and in India,
[00:20:40.240 --> 00:20:41.800]   he got a shrug and he said, we already
[00:20:41.800 --> 00:20:43.960]   have Android phones for $50.
[00:20:43.960 --> 00:20:47.240]   And we're an inch away from having tablets for $100.
[00:20:47.240 --> 00:20:50.840]   And so yes, you'll have the--
[00:20:50.840 --> 00:20:51.960]   they're not knockoff Android.
[00:20:51.960 --> 00:20:54.240]   They're Android products at lower prices.
[00:20:54.240 --> 00:20:57.200]   Or you can say, I want the quality experience,
[00:20:57.200 --> 00:21:00.080]   and that's not going to cost me a lot more.
[00:21:00.080 --> 00:21:01.800]   But I have a choice.
[00:21:01.800 --> 00:21:03.880]   And by the way, I want one of these Android 1 phones.
[00:21:03.880 --> 00:21:06.080]   I just can't wait to play with it and see how good it is.
[00:21:06.080 --> 00:21:08.200]   Where would you get one in your neck of the woods?
[00:21:08.200 --> 00:21:09.840]   Will we be able to go in--
[00:21:09.840 --> 00:21:10.640]   I don't know that we will.
[00:21:10.640 --> 00:21:12.400]   I mean, next trip to India, I'm stopped.
[00:21:12.400 --> 00:21:14.240]   I'll buy a couple in the airport.
[00:21:14.240 --> 00:21:15.440]   Would you get me one, please?
[00:21:15.440 --> 00:21:17.120]   They're only $200.
[00:21:17.120 --> 00:21:19.640]   Yeah, I think that Google learned a lot
[00:21:19.640 --> 00:21:23.360]   from its experiences with the Moto G and also the Play--
[00:21:23.360 --> 00:21:26.960]   the Google Play editions of the Samsung phones,
[00:21:26.960 --> 00:21:28.520]   the high-end phones.
[00:21:28.520 --> 00:21:30.920]   And I think they've gotten a lot of confidence
[00:21:30.920 --> 00:21:33.720]   that they really know what they're doing oftentimes more
[00:21:33.720 --> 00:21:36.000]   than the OMs know.
[00:21:36.000 --> 00:21:39.360]   And so it's really an interesting initiative,
[00:21:39.360 --> 00:21:39.700]   I think.
[00:21:39.700 --> 00:21:42.120]   There's so many companies that are going after these markets.
[00:21:42.120 --> 00:21:44.000]   And I'm curious to see how low they'll go.
[00:21:44.000 --> 00:21:46.400]   Like you said, they're $50 phones.
[00:21:46.400 --> 00:21:47.400]   How low can it possibly go?
[00:21:47.400 --> 00:21:49.840]   $25 phones, $20 phones.
[00:21:49.840 --> 00:21:51.040]   Could be really crazy.
[00:21:51.040 --> 00:21:54.040]   Still, people struggle to pay the data rates
[00:21:54.040 --> 00:21:54.920]   in some of these countries.
[00:21:54.920 --> 00:21:56.360]   And that's an entirely different issue
[00:21:56.360 --> 00:21:58.640]   that Google, in fact, is potentially
[00:21:58.640 --> 00:22:01.520]   in a position to do something about as well.
[00:22:01.520 --> 00:22:03.440]   Well, let's talk about the right to be forgotten.
[00:22:03.440 --> 00:22:08.800]   I know, Jeff, that this is one of your many hot button issues.
[00:22:08.800 --> 00:22:10.200]   It's one of mine too.
[00:22:10.200 --> 00:22:11.960]   The reason we would talk about it again today
[00:22:11.960 --> 00:22:13.720]   is that this went into effect.
[00:22:13.720 --> 00:22:20.120]   Google is actually making stories and information forgotten,
[00:22:20.120 --> 00:22:23.320]   meaning that they're removing them from the Google search
[00:22:23.320 --> 00:22:24.160]   index.
[00:22:24.160 --> 00:22:27.400]   And the Guardian had a really great piece by James Ball,
[00:22:27.400 --> 00:22:30.880]   talking about specific articles that were de-indexed
[00:22:30.880 --> 00:22:32.360]   on the Guardian newspaper.
[00:22:32.360 --> 00:22:35.760]   So this is a case, very strong case, a very clear case,
[00:22:35.760 --> 00:22:39.640]   that really shows the reality of this ruling by the EU
[00:22:39.640 --> 00:22:44.120]   that here are articles on the Guardian's newspaper site, which
[00:22:44.120 --> 00:22:47.680]   cannot be found with the European version of Google search.
[00:22:47.680 --> 00:22:50.000]   Jeff, does this--
[00:22:50.000 --> 00:22:51.920]   I mean--
[00:22:51.920 --> 00:22:53.320]   This is exactly what I've been--
[00:22:53.320 --> 00:22:53.840]   This is horrible.
[00:22:53.840 --> 00:22:55.080]   What do you mean about this show?
[00:22:55.080 --> 00:22:56.880]   I know probably most of our audience,
[00:22:56.880 --> 00:22:57.800]   I imagine, is American.
[00:22:57.800 --> 00:22:59.880]   And I go off crazy about the Europeans and the Germans
[00:22:59.880 --> 00:23:00.440]   on these issues.
[00:23:00.440 --> 00:23:02.840]   And I don't mean to besmirch everybody with the same thing.
[00:23:02.840 --> 00:23:05.280]   But this was a god-awful decision.
[00:23:05.280 --> 00:23:06.760]   And it's now coming home to roost.
[00:23:06.760 --> 00:23:09.080]   Now, one might argue that Google is very cleverly,
[00:23:09.080 --> 00:23:13.600]   if not cynically, starting with de-indexing news stories
[00:23:13.600 --> 00:23:14.360]   for just this purpose.
[00:23:14.360 --> 00:23:16.520]   But fine, it proves the point.
[00:23:16.520 --> 00:23:19.160]   Both Guardian and now the BBC as well
[00:23:19.160 --> 00:23:21.600]   has had stories de-indexed for no good reason.
[00:23:21.600 --> 00:23:22.480]   There's nothing liable.
[00:23:22.480 --> 00:23:23.640]   There's nothing wrong about them.
[00:23:23.640 --> 00:23:24.640]   Somebody didn't like them.
[00:23:24.640 --> 00:23:26.280]   They didn't like what was said about them.
[00:23:26.280 --> 00:23:30.800]   And there is a whitewashing that is now enabled by the court.
[00:23:30.800 --> 00:23:34.560]   But more than that, it has an impact on free speech
[00:23:34.560 --> 00:23:35.920]   and freedom of the press.
[00:23:35.920 --> 00:23:39.760]   And my hope now is that not only Google,
[00:23:39.760 --> 00:23:41.720]   but also especially the Guardian and BBC,
[00:23:41.720 --> 00:23:44.760]   will go and sue at the European court
[00:23:44.760 --> 00:23:48.760]   to protect the freedom of press and the freedom of speech.
[00:23:48.760 --> 00:23:51.440]   Yes, those stories still exist on their sites,
[00:23:51.440 --> 00:23:53.720]   but people can't find them because Google was ordered
[00:23:53.720 --> 00:23:55.640]   by a government to take them down
[00:23:55.640 --> 00:23:58.040]   on behalf of people who didn't like what was said about them.
[00:23:58.040 --> 00:24:01.640]   Well, that affects the speech of those who said it.
[00:24:01.640 --> 00:24:04.640]   And that is the tool of tyrants.
[00:24:04.640 --> 00:24:07.600]   And it is shocking that this would come out of Europe
[00:24:07.600 --> 00:24:09.720]   of all places with its history.
[00:24:09.720 --> 00:24:14.160]   It just shows an absolute lack of understanding
[00:24:14.160 --> 00:24:18.320]   of how tyrants use the ability to change history.
[00:24:18.320 --> 00:24:19.720]   Absolutely, and I couldn't say it better.
[00:24:19.720 --> 00:24:21.280]   That's exactly how I feel about it.
[00:24:21.280 --> 00:24:23.240]   And there's another element to this as well
[00:24:23.240 --> 00:24:25.800]   that really is really upsetting,
[00:24:25.800 --> 00:24:28.680]   which is that a search index exists
[00:24:28.680 --> 00:24:31.200]   to reflect what is on the internet.
[00:24:31.200 --> 00:24:33.560]   It's a card catalog, it's a terrible metaphor,
[00:24:33.560 --> 00:24:36.360]   but it's a card catalog for the library of the internet.
[00:24:36.360 --> 00:24:39.280]   And essentially what they're doing is they're ordering Google
[00:24:39.280 --> 00:24:41.480]   to have a search engine that's increasingly,
[00:24:41.480 --> 00:24:42.680]   and remember, this is cumulative,
[00:24:42.680 --> 00:24:46.240]   as they're continuously erasing a search engine.
[00:24:46.240 --> 00:24:48.800]   10,000 requests a day, 10,000 a day.
[00:24:48.800 --> 00:24:53.240]   Exactly, the search engine that everybody uses
[00:24:53.240 --> 00:24:56.200]   will not reflect what is actually on the internet.
[00:24:56.200 --> 00:24:58.200]   I mean, we're trying to have a society here,
[00:24:58.200 --> 00:25:03.200]   and here we have a government mandated requirement
[00:25:03.680 --> 00:25:07.440]   that search engines not reflect what is on the internet.
[00:25:07.440 --> 00:25:08.880]   It's a horrible state of affairs.
[00:25:08.880 --> 00:25:10.840]   Now, if they want to go after the Guardian
[00:25:10.840 --> 00:25:13.960]   and try to censor the Guardian, fine, go for it.
[00:25:13.960 --> 00:25:16.720]   There are free speech protections in place
[00:25:16.720 --> 00:25:21.600]   in most countries that, you know, certainly in Europe,
[00:25:21.600 --> 00:25:22.880]   and certainly in the United States.
[00:25:22.880 --> 00:25:27.120]   So go try that, go try to erase pages.
[00:25:27.120 --> 00:25:29.800]   And when you actually are enough of a tyrant
[00:25:29.800 --> 00:25:33.960]   to ban actual articles that have been published
[00:25:33.960 --> 00:25:35.360]   by the Guardian newspaper,
[00:25:35.360 --> 00:25:36.960]   then Google can change its search engine
[00:25:36.960 --> 00:25:39.480]   to reflect the fact that those have been censored.
[00:25:39.480 --> 00:25:41.680]   But this idea to go to the search engine and say,
[00:25:41.680 --> 00:25:42.520]   "You know what?
[00:25:42.520 --> 00:25:44.840]   "We're just gonna make it so that people can't find it."
[00:25:44.840 --> 00:25:46.600]   This is really outrageous and really intense.
[00:25:46.600 --> 00:25:48.960]   I was delighted that Google apparently notified
[00:25:48.960 --> 00:25:51.000]   those whose articles were being taken down,
[00:25:51.000 --> 00:25:52.880]   though there is no appeal at this.
[00:25:52.880 --> 00:25:54.800]   Not from Google, this is an unappelable decision
[00:25:54.800 --> 00:25:56.200]   by the European court,
[00:25:56.200 --> 00:25:58.760]   nor from those whose articles are de-indexed.
[00:25:58.760 --> 00:26:00.600]   And so suddenly now your article is taken down
[00:26:00.600 --> 00:26:02.800]   because some subject of your article,
[00:26:02.800 --> 00:26:06.360]   or your blog post, or whatever has asked me taken down
[00:26:06.360 --> 00:26:08.000]   because they don't like it, they say it's irrelevant,
[00:26:08.000 --> 00:26:09.560]   they say it's no good,
[00:26:09.560 --> 00:26:11.040]   Google takes it down, Google notifies you,
[00:26:11.040 --> 00:26:15.520]   there's no appeal on behalf of the censored party here.
[00:26:15.520 --> 00:26:16.760]   And that's wrong too.
[00:26:16.760 --> 00:26:20.960]   This was such a num-nuts court decision.
[00:26:20.960 --> 00:26:22.440]   Dangerous as can be.
[00:26:22.440 --> 00:26:24.040]   When I was at the Google Big Ten event
[00:26:24.040 --> 00:26:25.960]   where full disclosure, Google paid for my way over,
[00:26:25.960 --> 00:26:29.120]   not for me, about three weeks ago,
[00:26:29.120 --> 00:26:30.920]   what shocked me was I sat in the room
[00:26:30.920 --> 00:26:34.080]   and I was a lone voice almost.
[00:26:34.080 --> 00:26:36.840]   Fighting against this decision,
[00:26:36.840 --> 00:26:38.800]   Google obviously wasn't crazy about it either,
[00:26:38.800 --> 00:26:41.200]   but politicians and people in the room,
[00:26:41.200 --> 00:26:42.800]   it just sounds cynically okay,
[00:26:42.800 --> 00:26:45.040]   oh what's wrong with being forgotten, it's okay.
[00:26:45.040 --> 00:26:46.600]   No, because it affects speech.
[00:26:46.600 --> 00:26:49.240]   Oh, I'll shut up now.
[00:26:49.240 --> 00:26:50.760]   - I agree with you guys,
[00:26:50.760 --> 00:26:53.400]   but that's not the advocate on the card catalog thing.
[00:26:53.400 --> 00:26:55.960]   Like I don't think that Google's index
[00:26:55.960 --> 00:26:58.360]   is actually a representation of everything
[00:26:58.360 --> 00:26:59.640]   that exists on the internet.
[00:26:59.640 --> 00:27:02.680]   Google's filters span, it filters pornography,
[00:27:02.680 --> 00:27:06.520]   it ranks based on its own internal factors,
[00:27:06.520 --> 00:27:08.200]   which is not transparent about,
[00:27:08.200 --> 00:27:10.400]   I mean, you know, like I said,
[00:27:10.400 --> 00:27:12.880]   I agree with you, but the right to be forgotten stuff,
[00:27:12.880 --> 00:27:16.000]   but Google makes a lot of other judgment calls
[00:27:16.000 --> 00:27:19.520]   about what content to show up in its results,
[00:27:19.520 --> 00:27:22.080]   particularly on the first page.
[00:27:22.080 --> 00:27:25.080]   So this isn't a new thing for them.
[00:27:25.080 --> 00:27:26.960]   You know, I saw the interview in the Times
[00:27:26.960 --> 00:27:27.960]   where I think it was,
[00:27:27.960 --> 00:27:28.960]   hey, it was complaining,
[00:27:28.960 --> 00:27:30.560]   oh, we're gonna have to make these decisions
[00:27:30.560 --> 00:27:31.960]   about whether or not there's judgment call,
[00:27:31.960 --> 00:27:34.480]   whether or not we should take this thing out of the index.
[00:27:34.480 --> 00:27:37.520]   Do us already doing that around,
[00:27:37.520 --> 00:27:40.120]   I mean, that's what Matt Cutt's team does, right?
[00:27:40.120 --> 00:27:41.280]   So again, I'm playing devil's advocate
[00:27:41.280 --> 00:27:42.280]   and I do agree with you guys.
[00:27:42.280 --> 00:27:43.280]   - Oh, that's an important point,
[00:27:43.280 --> 00:27:44.280]   that's an important point.
[00:27:44.280 --> 00:27:45.120]   - Yeah, it's an important point.
[00:27:45.120 --> 00:27:46.840]   - Right, so then we get to the question
[00:27:46.840 --> 00:27:49.960]   when I was at this Deutchevella event,
[00:27:49.960 --> 00:27:52.000]   my second trip to Germany in a few weeks,
[00:27:52.000 --> 00:27:54.240]   I was kind of debating that was frustrating
[00:27:54.240 --> 00:27:55.080]   we weren't allowed to,
[00:27:55.080 --> 00:27:56.680]   Matthias Dufthner who's the head of actual Springer,
[00:27:56.680 --> 00:27:59.440]   who's been a major Google foe,
[00:27:59.440 --> 00:28:01.040]   and arguing about this,
[00:28:01.040 --> 00:28:03.840]   and he brings up this argument of so-called search neutrality,
[00:28:03.840 --> 00:28:06.080]   which I've said on the show is an absurd concept,
[00:28:06.080 --> 00:28:07.960]   because that equals only noise.
[00:28:07.960 --> 00:28:08.880]   So you're right,
[00:28:08.880 --> 00:28:12.360]   Google does make decisions based on relevance,
[00:28:12.360 --> 00:28:16.560]   authority, freshness, page rank,
[00:28:16.560 --> 00:28:18.520]   certain criteria of what's taken down,
[00:28:18.520 --> 00:28:22.800]   like porn, those who ask for transparency to that,
[00:28:22.800 --> 00:28:24.360]   are also asking for them to be game,
[00:28:24.360 --> 00:28:26.120]   so there is not transparency of it,
[00:28:26.120 --> 00:28:28.320]   that's all the given in the case.
[00:28:28.320 --> 00:28:30.680]   What makes this case different, I think, Gina,
[00:28:30.680 --> 00:28:34.960]   is that you have Google ordered by a government
[00:28:34.960 --> 00:28:36.160]   to follow these orders,
[00:28:36.160 --> 00:28:38.080]   to take down these things from people
[00:28:38.080 --> 00:28:40.760]   who are the subjects of things,
[00:28:40.760 --> 00:28:43.200]   and then there's no appeal,
[00:28:43.200 --> 00:28:46.780]   there's no appeal from the person who's been taken down.
[00:28:48.120 --> 00:28:51.120]   I think it's qualitatively different
[00:28:51.120 --> 00:28:55.080]   from an algorithm that prioritizes things.
[00:28:55.080 --> 00:28:58.680]   - There's another dimension to it as well
[00:28:58.680 --> 00:29:00.960]   that's related to the one that you mentioned, Jeff,
[00:29:00.960 --> 00:29:03.840]   which is that when these things happen
[00:29:03.840 --> 00:29:07.760]   by the request or action of people in the public,
[00:29:07.760 --> 00:29:09.400]   what will inevitably happen,
[00:29:09.400 --> 00:29:11.200]   and this is a very un-European thing,
[00:29:11.200 --> 00:29:13.200]   generally speaking, democracy in Europe,
[00:29:13.200 --> 00:29:15.600]   the United States differs in its emphasis
[00:29:15.600 --> 00:29:19.760]   where the United States tends to emphasize freedom
[00:29:19.760 --> 00:29:23.800]   over equality, whereas in Europe, especially France,
[00:29:23.800 --> 00:29:26.360]   they tend to emphasize equality over freedom,
[00:29:26.360 --> 00:29:29.320]   and here's a case where they're de-emphasizing equality
[00:29:29.320 --> 00:29:32.680]   because who are the people who are going to request
[00:29:32.680 --> 00:29:34.120]   that information be taken down?
[00:29:34.120 --> 00:29:38.000]   It's gonna be politicians, billionaires, wealthy people,
[00:29:38.000 --> 00:29:41.360]   smitherers, get my bad reputation cleaned up,
[00:29:41.360 --> 00:29:43.440]   they're gonna have these reputation management companies
[00:29:43.440 --> 00:29:47.120]   that are very expensive, go and take this,
[00:29:47.120 --> 00:29:48.920]   get rid of whatever they can,
[00:29:48.920 --> 00:29:51.440]   whatever bad news or bad opinion,
[00:29:51.440 --> 00:29:54.360]   or whatever it is they don't like, they'll attempt it.
[00:29:54.360 --> 00:29:58.440]   And so over the years, if this is allowed to stand,
[00:29:58.440 --> 00:30:00.320]   what'll happen is there'll be an imbalance
[00:30:00.320 --> 00:30:04.520]   in terms of the reputations and the good and bad information
[00:30:04.520 --> 00:30:08.320]   based on class, wealth, and so on,
[00:30:08.320 --> 00:30:13.320]   and that is, to me, an extraordinarily un-European result.
[00:30:13.320 --> 00:30:14.320]   Really a good point.
[00:30:14.320 --> 00:30:15.160]   Yeah.
[00:30:15.160 --> 00:30:16.000]   Yeah, that is a good point.
[00:30:16.000 --> 00:30:16.840]   There's another one.
[00:30:16.840 --> 00:30:19.360]   There's already an access issue around class and the internet,
[00:30:19.360 --> 00:30:20.920]   right? I mean, people who don't have access to the internet
[00:30:20.920 --> 00:30:22.640]   don't have no reputation.
[00:30:22.640 --> 00:30:23.480]   Yeah.
[00:30:23.480 --> 00:30:25.680]   But I agree that this could worsen it.
[00:30:25.680 --> 00:30:28.160]   There was another case, and I'm not sure,
[00:30:28.160 --> 00:30:29.800]   you guys talked about it on this show,
[00:30:29.800 --> 00:30:33.960]   I don't recall hearing it, that happened in Canada
[00:30:33.960 --> 00:30:37.200]   where a judge in British Columbia ordered Google
[00:30:37.200 --> 00:30:41.360]   to block not only existing websites referencing a company,
[00:30:41.360 --> 00:30:44.840]   but all future references to that company.
[00:30:44.840 --> 00:30:48.800]   And not just in Canada, but around the world.
[00:30:48.800 --> 00:30:50.720]   That was the chilling part of it, wasn't it?
[00:30:50.720 --> 00:30:54.080]   Because once you have a precedent where,
[00:30:54.080 --> 00:30:58.600]   for any reason, a national government can essentially
[00:30:58.600 --> 00:31:00.000]   block something through the whole world
[00:31:00.000 --> 00:31:02.280]   or get out of the country, well, this is the greatest thing
[00:31:02.280 --> 00:31:07.320]   ever for China, for Iran, for any sort of authoritarian country
[00:31:07.320 --> 00:31:08.680]   you can imagine.
[00:31:08.680 --> 00:31:10.400]   And then, what do you do?
[00:31:10.400 --> 00:31:13.360]   I mean, ultimately, it's just going to get worse and worse.
[00:31:13.360 --> 00:31:16.240]   The other part of this decision that was pretty awful,
[00:31:16.240 --> 00:31:20.440]   the Canadian decision, was that it applied only to Google.
[00:31:20.440 --> 00:31:25.120]   No other search engines were required to adhere to this ruling.
[00:31:25.120 --> 00:31:27.200]   And by the way, that goes back to the right to be forgotten.
[00:31:27.200 --> 00:31:30.560]   We haven't heard yet, because that decision does apply
[00:31:30.560 --> 00:31:33.080]   to Bing and Yahoo at all.
[00:31:33.080 --> 00:31:35.000]   And it'll be interesting, I haven't heard
[00:31:35.000 --> 00:31:36.400]   what they're doing with this.
[00:31:36.400 --> 00:31:38.840]   And as I said, when we started this discussion,
[00:31:38.840 --> 00:31:39.880]   I don't know this.
[00:31:39.880 --> 00:31:43.360]   I would suspect that Google prioritized
[00:31:43.360 --> 00:31:47.480]   the order of its takedowns, knowing that taking down press
[00:31:47.480 --> 00:31:49.120]   stories would get attention from the press.
[00:31:49.120 --> 00:31:50.600]   We'd get their attention, and we need that.
[00:31:50.600 --> 00:31:51.760]   And I'm fine with that.
[00:31:51.760 --> 00:31:55.760]   I think it's-- if it's done for clever reasons, then cool.
[00:31:55.760 --> 00:31:57.920]   We are talking about it, because the Guardian and the BBC
[00:31:57.920 --> 00:31:59.560]   wrote about this.
[00:31:59.560 --> 00:32:03.040]   Now it's time to go and ask what Bing and Yahoo
[00:32:03.040 --> 00:32:04.480]   are going to do about this.
[00:32:04.480 --> 00:32:11.000]   And it's time to see whether there is any means of appeal
[00:32:11.000 --> 00:32:12.280]   to this.
[00:32:12.280 --> 00:32:14.240]   A, we're starting on the Google We'll give notice,
[00:32:14.240 --> 00:32:15.880]   but we'll notice be given by all parties
[00:32:15.880 --> 00:32:17.720]   to those who were taken down.
[00:32:17.720 --> 00:32:20.120]   There's no apparent means of appeal.
[00:32:20.120 --> 00:32:23.080]   And is there an opportunity for these censored parties
[00:32:23.080 --> 00:32:26.240]   to go and now sue for their own freedoms?
[00:32:26.240 --> 00:32:27.240]   We'll see.
[00:32:27.240 --> 00:32:30.800]   This was a dumb decision that's only going to get dumber.
[00:32:30.800 --> 00:32:32.360]   Absolutely horrible.
[00:32:32.360 --> 00:32:36.640]   Well, the big story, I think, that remains
[00:32:36.640 --> 00:32:40.200]   undiscussed on this show, because you guys both
[00:32:40.200 --> 00:32:44.040]   came rushing to the studio last week from Google I/O.
[00:32:44.040 --> 00:32:46.400]   And they didn't start handing out watches yet, right?
[00:32:46.400 --> 00:32:48.720]   So we haven't talked about Android Wear.
[00:32:48.720 --> 00:32:49.560]   We have not.
[00:32:49.560 --> 00:32:52.840]   So let's go around the horn and find out, Gina, what do you
[00:32:52.840 --> 00:32:55.040]   think of Android Wear?
[00:32:55.040 --> 00:32:55.920]   Oh, man.
[00:32:55.920 --> 00:32:57.360]   I just-- I love this thing.
[00:32:57.360 --> 00:32:59.120]   I've got the LG GW watch.
[00:32:59.120 --> 00:33:03.160]   And I'll tell you, my sweet link review
[00:33:03.160 --> 00:33:09.360]   is the hardware is flimsy and bad, and the software is amazing.
[00:33:09.360 --> 00:33:11.200]   And now, that's coming from someone who loves--
[00:33:11.200 --> 00:33:12.080]   I love Google Now.
[00:33:12.080 --> 00:33:13.000]   I live in Google Now.
[00:33:13.000 --> 00:33:14.680]   It's the first thing I look at in the morning,
[00:33:14.680 --> 00:33:16.200]   lasting a look at at night.
[00:33:16.200 --> 00:33:18.600]   The fact that I have Google Now and my notifications
[00:33:18.600 --> 00:33:21.040]   on my wrist, it means that I just don't look at my phone
[00:33:21.040 --> 00:33:22.000]   as much during the day.
[00:33:22.000 --> 00:33:23.640]   And that's something I like.
[00:33:23.640 --> 00:33:25.480]   I don't want to be the person who's got my face
[00:33:25.480 --> 00:33:27.280]   buried in my phone all day.
[00:33:27.280 --> 00:33:29.960]   It's very lightweight.
[00:33:29.960 --> 00:33:32.280]   The software is really delightful to you.
[00:33:32.280 --> 00:33:33.400]   It's a little rougher on the edges,
[00:33:33.400 --> 00:33:35.320]   and has to make some improvements.
[00:33:35.320 --> 00:33:38.160]   I don't use the voice control as much as I thought that I would.
[00:33:38.160 --> 00:33:41.240]   I really-- this is just a text messaging notification
[00:33:41.240 --> 00:33:43.320]   system for me, but I really, really love it.
[00:33:43.320 --> 00:33:46.480]   And I can't wait to get the 360, because I think that's
[00:33:46.480 --> 00:33:50.080]   when the hardware has a shot at catching up.
[00:33:50.080 --> 00:33:53.360]   And I won't feel quite like I'm wearing such a nerd watch.
[00:33:53.360 --> 00:33:54.480]   But I am wearing this watch.
[00:33:54.480 --> 00:33:56.960]   The software is good enough, but I'm actually wearing it.
[00:33:56.960 --> 00:33:59.480]   How is the hardware flimsy genome?
[00:33:59.480 --> 00:34:02.840]   I just think that I don't have the shape of the face,
[00:34:02.840 --> 00:34:04.560]   and it just feels kind of plastic-y.
[00:34:04.560 --> 00:34:05.560]   Oh, OK.
[00:34:05.560 --> 00:34:07.120]   It just feels like a nice watch.
[00:34:07.120 --> 00:34:10.360]   It feels like I'm wearing this plastic old Casio.
[00:34:10.360 --> 00:34:12.200]   It just kind of screams nerd watch.
[00:34:12.200 --> 00:34:14.240]   It's comfortable, though, right?
[00:34:14.240 --> 00:34:17.200]   It's comfortable, and it's fine.
[00:34:17.200 --> 00:34:20.360]   It looks like I've got this computer on my wrist, right?
[00:34:20.360 --> 00:34:23.920]   And I'd like for it to just look like I have a watch on a nice watch.
[00:34:23.920 --> 00:34:26.200]   So I'm excited about the 360.
[00:34:26.200 --> 00:34:28.960]   And an underappreciated fact of the 360
[00:34:28.960 --> 00:34:34.160]   is that even though, as you can agree, Gina, the LG G-Watch
[00:34:34.160 --> 00:34:38.080]   is very light, the 360 is significantly lighter.
[00:34:38.080 --> 00:34:38.600]   Really?
[00:34:38.600 --> 00:34:39.400]   Yes.
[00:34:39.400 --> 00:34:41.600]   I wouldn't have expected that with a stainless steel.
[00:34:41.600 --> 00:34:43.080]   It kind of looks pretty heavy.
[00:34:43.080 --> 00:34:44.920]   So, Jeff, what do you think of yours?
[00:34:44.920 --> 00:34:46.200]   I also got the LG.
[00:34:46.200 --> 00:34:47.440]   I'm also wearing it every day.
[00:34:47.440 --> 00:34:48.960]   I'm also loving it.
[00:34:48.960 --> 00:34:52.920]   And I'm coming to big conclusions about my world
[00:34:52.920 --> 00:34:54.880]   and our world of news with it.
[00:34:54.880 --> 00:34:57.680]   Because I think that the primary benefit to me so far
[00:34:57.680 --> 00:35:00.320]   has indeed been news updates, right?
[00:35:00.320 --> 00:35:02.760]   So I saw Supreme Court decisions, things like that come across.
[00:35:02.760 --> 00:35:05.440]   Now, generally, news companies are actually
[00:35:05.440 --> 00:35:07.000]   ironically awful at updates.
[00:35:07.000 --> 00:35:10.440]   They either do too many, or they don't do any at all.
[00:35:10.440 --> 00:35:15.120]   But so far, I'm getting guardian updates.
[00:35:15.120 --> 00:35:18.080]   I think New York Times updates and circa updates on this.
[00:35:18.080 --> 00:35:22.320]   And they're using them sparingly that it pretty much works.
[00:35:22.320 --> 00:35:23.880]   It's pretty much valuable.
[00:35:23.880 --> 00:35:26.560]   I'm finding the user interface still fairly clunky,
[00:35:26.560 --> 00:35:28.480]   trying to get around and do stuff.
[00:35:28.480 --> 00:35:30.360]   It constantly tells me I have zero steps when,
[00:35:30.360 --> 00:35:32.280]   by God, I've been walking.
[00:35:32.280 --> 00:35:36.240]   I'd have to go turn on fit.
[00:35:36.240 --> 00:35:38.080]   I wish there were some other things
[00:35:38.080 --> 00:35:40.040]   that I can have an update for me.
[00:35:40.040 --> 00:35:42.400]   The most fundamental weakness to me of this
[00:35:42.400 --> 00:35:48.080]   is that I use my shine still.
[00:35:48.080 --> 00:35:49.320]   I haven't updated in a few days.
[00:35:49.320 --> 00:35:52.760]   But I use it probably because it can tell my sleep.
[00:35:52.760 --> 00:35:53.920]   This doesn't do my sleep.
[00:35:53.920 --> 00:35:55.840]   But worse than that, I have to charge it every night.
[00:35:55.840 --> 00:35:57.920]   So I don't have a watch on knowing the time,
[00:35:57.920 --> 00:36:00.640]   and I'm blind without these.
[00:36:00.640 --> 00:36:03.200]   So when I was in a hotel room the last few nights,
[00:36:03.200 --> 00:36:04.520]   I needed to have a clock.
[00:36:04.520 --> 00:36:05.480]   I don't know what time it is.
[00:36:05.480 --> 00:36:08.160]   I'm waking up and I'm jet lagged.
[00:36:08.160 --> 00:36:11.240]   Not having this on at night to me is an issue.
[00:36:11.240 --> 00:36:12.640]   It's almost like you need to have two of them.
[00:36:12.640 --> 00:36:13.880]   A day version and a night version.
[00:36:13.880 --> 00:36:16.840]   I assume we will.
[00:36:16.840 --> 00:36:18.480]   But I agree with Gina.
[00:36:18.480 --> 00:36:21.160]   I'm looking at my phone less.
[00:36:21.160 --> 00:36:23.600]   I'm finding it comfortable to wear this all the time.
[00:36:23.600 --> 00:36:25.040]   I said on the show last week that I
[00:36:25.040 --> 00:36:27.080]   think that the computer is going to migrate from the phone
[00:36:27.080 --> 00:36:29.120]   into this device, and this becomes our identity,
[00:36:29.120 --> 00:36:30.840]   and this becomes our primary computer,
[00:36:30.840 --> 00:36:32.720]   and everything else is a slave of it.
[00:36:32.720 --> 00:36:35.680]   And we're seeing the transition to that in terms
[00:36:35.680 --> 00:36:37.880]   of how Android is now the master of all.
[00:36:37.880 --> 00:36:43.160]   I haven't used the voice either, and it's funny,
[00:36:43.160 --> 00:36:46.200]   because it just seems too stupid, Dick Tracy-ish.
[00:36:46.200 --> 00:36:49.880]   I was on the plane coming back, and I dictated a tweet
[00:36:49.880 --> 00:36:50.440]   on my phone.
[00:36:50.440 --> 00:36:52.640]   It didn't feel weird about that.
[00:36:52.640 --> 00:36:55.000]   But I feel weird about doing this,
[00:36:55.000 --> 00:36:57.720]   especially starting with, OK, Gogo.
[00:36:57.720 --> 00:37:00.120]   And it also isn't great at hearing me.
[00:37:00.120 --> 00:37:00.720]   I don't find.
[00:37:00.720 --> 00:37:05.360]   So now I'm trying to get it to go to that.
[00:37:05.360 --> 00:37:06.720]   And I can't get to go back to the home.
[00:37:06.720 --> 00:37:07.600]   OK, now.
[00:37:07.600 --> 00:37:09.520]   OK, Gogo.
[00:37:09.520 --> 00:37:11.640]   Oh, did it.
[00:37:11.640 --> 00:37:13.720]   Search for Gina Trappani.
[00:37:13.720 --> 00:37:14.880]   No, it gave me audit.
[00:37:14.880 --> 00:37:15.960]   We can see it.
[00:37:15.960 --> 00:37:16.960]   It's--
[00:37:16.960 --> 00:37:17.960]   [LAUGHTER]
[00:37:17.960 --> 00:37:20.240]   Do you think that that seems really awkward?
[00:37:20.240 --> 00:37:20.760]   Yeah.
[00:37:20.760 --> 00:37:22.640]   But what's interesting, I think to me,
[00:37:22.640 --> 00:37:23.920]   about the experience of wearing it,
[00:37:23.920 --> 00:37:27.440]   is that it immediately becomes clear that, yes, smartwatches,
[00:37:27.440 --> 00:37:28.920]   we're all going to be wearing them.
[00:37:28.920 --> 00:37:30.920]   It's such a great place for information,
[00:37:30.920 --> 00:37:33.520]   for contextual information, for notifications.
[00:37:33.520 --> 00:37:36.280]   It's a great place for Google Now.
[00:37:36.280 --> 00:37:38.120]   Google Now really never had a place before.
[00:37:38.120 --> 00:37:39.000]   You had to go find it.
[00:37:39.000 --> 00:37:42.280]   You had to seek it out and say, oh, I'm going to use Google Now
[00:37:42.280 --> 00:37:42.800]   at this point.
[00:37:42.800 --> 00:37:45.360]   And that's not how Google Now really needs to be used.
[00:37:45.360 --> 00:37:46.160]   It needs to be ambient.
[00:37:46.160 --> 00:37:47.800]   It needs to be just kind of there.
[00:37:47.800 --> 00:37:48.960]   And now it's just there.
[00:37:48.960 --> 00:37:50.040]   It's on the wrist.
[00:37:50.040 --> 00:37:51.040]   And that's fantastic.
[00:37:51.040 --> 00:37:52.200]   We don't try to experiment.
[00:37:52.200 --> 00:37:54.920]   OK, Jarvis.
[00:37:54.920 --> 00:37:57.000]   Oh, it didn't work.
[00:37:57.000 --> 00:37:58.720]   Oh, it didn't work.
[00:37:58.720 --> 00:37:59.840]   Oh, that's sad.
[00:37:59.840 --> 00:38:01.080]   It works for us, if we say it.
[00:38:01.080 --> 00:38:02.480]   You usually reply.
[00:38:02.480 --> 00:38:03.480]   What?
[00:38:03.480 --> 00:38:04.480]   What do you want?
[00:38:04.480 --> 00:38:07.840]   But what's amazing to me is that this is an app--
[00:38:07.840 --> 00:38:10.000]   and I've said this on a couple of other shows here at Twit--
[00:38:10.000 --> 00:38:13.040]   but it's the first platform with a killer app, which is
[00:38:13.040 --> 00:38:13.480]   Google Now.
[00:38:13.480 --> 00:38:15.640]   Right out of the box, it's already got its killer app.
[00:38:15.640 --> 00:38:16.560]   Don, killer app.
[00:38:16.560 --> 00:38:17.760]   Well said.
[00:38:17.760 --> 00:38:19.560]   And just wait till the apps come,
[00:38:19.560 --> 00:38:21.920]   which July 7th, they start coming out.
[00:38:21.920 --> 00:38:24.920]   And a year from now, how many apps are going to be out there?
[00:38:24.920 --> 00:38:27.000]   And what are they going to be able to do?
[00:38:27.000 --> 00:38:30.000]   It's really exciting that it's already so useful.
[00:38:30.000 --> 00:38:32.120]   It's already so comfortable to wear, especially if you're
[00:38:32.120 --> 00:38:34.320]   used to using Google Glass, where you have to kind of
[00:38:34.320 --> 00:38:36.400]   psych yourself up to go outside into public.
[00:38:36.400 --> 00:38:37.920]   You can just wear this thing around.
[00:38:37.920 --> 00:38:42.840]   You can relax and really use it in a sort of invisible way
[00:38:42.840 --> 00:38:44.400]   without making a big scene without like--
[00:38:44.400 --> 00:38:47.160]   Now, has anyone outside your two geek circles
[00:38:47.160 --> 00:38:49.520]   where it's too obvious or no, you just came back from my own?
[00:38:49.520 --> 00:38:51.960]   In any kind of setting with a waiter or a waitress
[00:38:51.960 --> 00:38:53.840]   or somebody on the street, has anybody come up to you
[00:38:53.840 --> 00:38:55.000]   and said, what's that?
[00:38:55.000 --> 00:38:55.520]   No.
[00:38:55.520 --> 00:38:56.800]   Nobody has.
[00:38:56.800 --> 00:38:57.300]   No.
[00:38:57.300 --> 00:38:59.440]   It's completely invisible.
[00:38:59.440 --> 00:39:00.440]   Which I--
[00:39:00.440 --> 00:39:01.960]   My daughter noticed it.
[00:39:01.960 --> 00:39:03.680]   I mean, because she saw me fiddling with it.
[00:39:03.680 --> 00:39:04.640]   She's won.
[00:39:04.640 --> 00:39:06.040]   So she touches it a lot.
[00:39:06.040 --> 00:39:07.480]   Because she sees me touching it.
[00:39:07.480 --> 00:39:08.480]   So that's kind of funny.
[00:39:08.480 --> 00:39:09.680]   And actually, her favorite thing to do is to
[00:39:09.680 --> 00:39:11.480]   comment, to turn it off.
[00:39:11.480 --> 00:39:13.200]   And Jason and I were talking about this last night.
[00:39:13.200 --> 00:39:15.360]   If you have kids, especially young kids, it's very sensitive
[00:39:15.360 --> 00:39:16.520]   to touch.
[00:39:16.520 --> 00:39:17.480]   So the baby touches it.
[00:39:17.480 --> 00:39:19.120]   If I pick it up and her clothes brush it,
[00:39:19.120 --> 00:39:20.120]   it comes on.
[00:39:20.120 --> 00:39:23.000]   I actually did just fall in bed last night with it on.
[00:39:23.000 --> 00:39:26.080]   And then it kind of hit the pillow and came on and lit up
[00:39:26.080 --> 00:39:27.000]   my wife's face.
[00:39:27.000 --> 00:39:28.360]   She was not happy about it.
[00:39:28.360 --> 00:39:31.640]   It's not a good sleeping thing.
[00:39:31.640 --> 00:39:34.240]   Like, especially in the dark on the screen that's really bright.
[00:39:34.240 --> 00:39:36.000]   She was like, get that thing off of you.
[00:39:36.000 --> 00:39:37.920]   I was like, whoops, sorry.
[00:39:37.920 --> 00:39:38.200]   This is--
[00:39:38.200 --> 00:39:39.880]   My wife thinks it's dumb that it comes
[00:39:39.880 --> 00:39:40.920]   that it's on all the time.
[00:39:40.920 --> 00:39:41.840]   She thinks it should be blank.
[00:39:41.840 --> 00:39:44.000]   But I said, no, my watch has time on it.
[00:39:44.000 --> 00:39:45.440]   But she just thinks it's dumb.
[00:39:45.440 --> 00:39:48.240]   The other problem is I crossed my arms like this.
[00:39:48.240 --> 00:39:49.960]   And it turns it on all the time.
[00:39:49.960 --> 00:39:50.480]   Yeah.
[00:39:50.480 --> 00:39:51.480]   Yeah, great.
[00:39:51.480 --> 00:39:52.480]   Thank you.
[00:39:52.480 --> 00:39:54.120]   And it goes--
[00:39:54.120 --> 00:39:55.600]   and it like buzzes.
[00:39:55.600 --> 00:39:56.520]   I do this all the time.
[00:39:56.520 --> 00:39:57.840]   I do this, and all of a sudden it's buzzing.
[00:39:57.840 --> 00:39:58.960]   And I'm like, is that a notification?
[00:39:58.960 --> 00:40:00.480]   Now, what about the Motorola seems
[00:40:00.480 --> 00:40:02.800]   to have in the STEM spot?
[00:40:02.800 --> 00:40:03.360]   Yeah.
[00:40:03.360 --> 00:40:05.280]   Is that a button or is that just a--
[00:40:05.280 --> 00:40:05.840]   It's a button.
[00:40:05.840 --> 00:40:06.880]   It turns it on and off.
[00:40:06.880 --> 00:40:09.440]   And you can sort of reset it and reboot it.
[00:40:09.440 --> 00:40:12.240]   It's unnecessary because you can do that, obviously.
[00:40:12.240 --> 00:40:15.840]   The LG GWatch has no buttons at all, no physical buttons.
[00:40:15.840 --> 00:40:17.640]   So yeah, it's a button to turn it on and off.
[00:40:17.640 --> 00:40:18.960]   I think they just like the look of it.
[00:40:18.960 --> 00:40:21.000]   They really wanted that mechanic.
[00:40:21.000 --> 00:40:22.480]   Did you also get the LG mic?
[00:40:22.480 --> 00:40:22.840]   I did.
[00:40:22.840 --> 00:40:24.000]   Yeah, I have the LG as well.
[00:40:24.000 --> 00:40:25.840]   Did anybody around you get the Samsung--
[00:40:25.840 --> 00:40:26.920]   There's already-- there are some
[00:40:26.920 --> 00:40:27.680]   to be getting the Samsung.
[00:40:27.680 --> 00:40:28.920]   What did Jason think of the Samsung?
[00:40:28.920 --> 00:40:29.720]   Have you compared?
[00:40:29.720 --> 00:40:30.160]   We have.
[00:40:30.160 --> 00:40:32.000]   We did it before you buy yesterday.
[00:40:32.000 --> 00:40:33.600]   And he likes it a lot.
[00:40:33.600 --> 00:40:34.880]   They're pros and cons.
[00:40:34.880 --> 00:40:37.040]   Generally, the Samsung's a little cheaper.
[00:40:37.040 --> 00:40:40.120]   It's just under $200, where this is $229.
[00:40:40.120 --> 00:40:41.920]   The Samsung has a brighter screen,
[00:40:41.920 --> 00:40:43.960]   a smaller battery, but longer battery life, which
[00:40:43.960 --> 00:40:46.720]   is impressive because it uses a screen that
[00:40:46.720 --> 00:40:48.920]   doesn't show-- it doesn't light up pixels.
[00:40:48.920 --> 00:40:52.080]   If it's not using those pixels, it
[00:40:52.080 --> 00:40:54.160]   doesn't use any energy on those pixels.
[00:40:54.160 --> 00:40:56.240]   And it's a great watch.
[00:40:56.240 --> 00:40:57.080]   He likes it a lot.
[00:40:57.080 --> 00:40:58.520]   It's a little bigger, bulkier.
[00:40:58.520 --> 00:41:00.640]   There's a little bit more chrome.
[00:41:00.640 --> 00:41:03.280]   I really think it's a little bit of a wash.
[00:41:03.280 --> 00:41:04.720]   Maybe the Samsung sort of--
[00:41:04.720 --> 00:41:07.080]   Are the watch faces the same on both?
[00:41:07.080 --> 00:41:08.280]   The choices of watch faces?
[00:41:08.280 --> 00:41:12.120]   Oh, oh, by the way, they're really mostly ugly as sin.
[00:41:12.120 --> 00:41:12.600]   Yeah.
[00:41:12.600 --> 00:41:13.520]   Which one are you guys using?
[00:41:13.520 --> 00:41:14.440]   I'm using this one.
[00:41:14.440 --> 00:41:17.840]   Yeah, that's the one I use, too.
[00:41:17.840 --> 00:41:18.400]   I like that one.
[00:41:18.400 --> 00:41:19.760]   It's nice and basic.
[00:41:19.760 --> 00:41:22.160]   But I wanted to really get a nice fool you.
[00:41:22.160 --> 00:41:23.120]   This is a real watch.
[00:41:23.120 --> 00:41:24.560]   And they're pretty ugly.
[00:41:24.560 --> 00:41:26.000]   Which one are you using, Gina?
[00:41:26.000 --> 00:41:29.360]   I'm using mini neon, which is a little hipster for my taste,
[00:41:29.360 --> 00:41:30.880]   but it was the closest I could find.
[00:41:30.880 --> 00:41:32.520]   It's a little designer-y and bright,
[00:41:32.520 --> 00:41:35.640]   but it was the closest I could find to something that I liked.
[00:41:35.640 --> 00:41:36.160]   You're right.
[00:41:36.160 --> 00:41:40.240]   I would like to see more watch faces.
[00:41:40.240 --> 00:41:41.440]   It's got the time.
[00:41:41.440 --> 00:41:42.200]   It's kind of hard to see.
[00:41:42.200 --> 00:41:43.200]   I'm like, it's called mini neon.
[00:41:43.200 --> 00:41:45.120]   Really ugly, like this one.
[00:41:45.120 --> 00:41:45.640]   Yeah.
[00:41:45.640 --> 00:41:46.760]   What's the deal with that?
[00:41:46.760 --> 00:41:48.200]   It's like Peter Maxx or something.
[00:41:48.200 --> 00:41:52.800]   I mean, it's like psychedelic 70s.
[00:41:52.800 --> 00:41:53.800]   I don't know what it is.
[00:41:53.800 --> 00:41:57.080]   It's like a children's show from the 70s or something like that.
[00:41:57.080 --> 00:41:58.920]   It's really quite horrible.
[00:41:58.920 --> 00:42:01.160]   And this is another example of--
[00:42:01.160 --> 00:42:02.400]   Yeah, that's the one I'm using.
[00:42:02.400 --> 00:42:04.320]   The one that looks like a children's show from the 70s
[00:42:04.320 --> 00:42:05.680]   with the number coming out.
[00:42:05.680 --> 00:42:09.800]   Yeah, it was the least bad one, I thought.
[00:42:09.800 --> 00:42:11.360]   But yeah, that's an opportunity.
[00:42:11.360 --> 00:42:12.960]   The watch faces is definitely an opportunity.
[00:42:12.960 --> 00:42:15.200]   This is another example of how the Moto 360 is probably
[00:42:15.200 --> 00:42:15.800]   going to dominate.
[00:42:15.800 --> 00:42:19.040]   They've already had a contest for people to crowdsource.
[00:42:19.040 --> 00:42:22.560]   Yeah, so there is going to be open source design.
[00:42:22.560 --> 00:42:24.280]   We can download watch faces we like, right?
[00:42:24.280 --> 00:42:25.920]   I'm almost certain that that is the case.
[00:42:25.920 --> 00:42:28.000]   And a year from now, there are going
[00:42:28.000 --> 00:42:31.440]   to be tens of thousands of watch faces to choose from.
[00:42:31.440 --> 00:42:33.720]   And so that's going to be kind of cool.
[00:42:33.720 --> 00:42:36.520]   But yeah, the ones out of the box for the LG GWatch
[00:42:36.520 --> 00:42:39.440]   are pretty slim pickens if you want a good looking watch,
[00:42:39.440 --> 00:42:40.760]   I thought.
[00:42:40.760 --> 00:42:42.840]   I can't wait for the Rolex knockoff.
[00:42:42.840 --> 00:42:45.040]   Yeah, watch face.
[00:42:45.040 --> 00:42:47.720]   Yeah, absolutely.
[00:42:47.720 --> 00:42:52.120]   Well, one other question that somebody wrote about this week
[00:42:52.120 --> 00:42:56.960]   is the question of whether or not Android Wear sort of invalidates
[00:42:56.960 --> 00:43:00.240]   or makes obsolete Google Glass.
[00:43:00.240 --> 00:43:02.560]   They have similar functions in terms
[00:43:02.560 --> 00:43:06.520]   of their app extensible notification oriented,
[00:43:06.520 --> 00:43:09.840]   Google now oriented wearable devices.
[00:43:09.840 --> 00:43:12.400]   The biggest difference, I think, besides the fact
[00:43:12.400 --> 00:43:15.560]   that Google Glass looks on your face is that Google Glass has
[00:43:15.560 --> 00:43:17.880]   a camera that you pointed everybody look at.
[00:43:17.880 --> 00:43:20.960]   And that's the biggest controversial point about Google Glass.
[00:43:20.960 --> 00:43:24.960]   But is this the end of Google Glass as a consumer product?
[00:43:24.960 --> 00:43:27.320]   And obviously, Google Glass might have a life
[00:43:27.320 --> 00:43:31.600]   as a sort of vertical integrated business device.
[00:43:31.600 --> 00:43:34.000]   But is it over for Google Glass because of Android Wear?
[00:43:34.000 --> 00:43:36.000]   What do you think, Jeff?
[00:43:36.000 --> 00:43:37.920]   That was my argument the show last week was just that.
[00:43:37.920 --> 00:43:41.840]   But it obsolete two thirds of the functions of Google Glass.
[00:43:41.840 --> 00:43:44.240]   Notifications and instructions for directions.
[00:43:44.240 --> 00:43:47.080]   And far more convenient, far better structure.
[00:43:47.080 --> 00:43:48.520]   I don't want that up here.
[00:43:48.520 --> 00:43:51.240]   And I think what Google Glass does show the power of having
[00:43:51.240 --> 00:43:54.080]   a camera so that as Gina has often pointed out,
[00:43:54.080 --> 00:43:58.520]   your baby sees you not some box in front of your eyes.
[00:43:58.520 --> 00:44:02.880]   And the images that you're taking are of what you actually see.
[00:44:02.880 --> 00:44:05.800]   I think that's proven to be valuable.
[00:44:05.800 --> 00:44:09.480]   But clearly, it's going to have to come with a red light
[00:44:09.480 --> 00:44:12.720]   and a siren that says, OK, OK, I'm making a picture now.
[00:44:12.720 --> 00:44:14.560]   OK, I'm OK with that, OK?
[00:44:14.560 --> 00:44:19.520]   And a way to notify people that it's there.
[00:44:19.520 --> 00:44:25.520]   And so I see Glass knows cameras of some sort coming,
[00:44:25.520 --> 00:44:28.680]   completely separate from the functionality of Google Glass,
[00:44:28.680 --> 00:44:30.560]   I mean, of Android Wear.
[00:44:30.560 --> 00:44:33.680]   And I wouldn't mind having that either.
[00:44:33.680 --> 00:44:35.280]   I think it has journalistic opportunities.
[00:44:35.280 --> 00:44:37.440]   But I don't think the other functionality works very well
[00:44:37.440 --> 00:44:38.280]   up here.
[00:44:38.280 --> 00:44:39.280]   Gina?
[00:44:39.280 --> 00:44:44.560]   Yeah, I mean, I do agree that Android Wear, the watch,
[00:44:44.560 --> 00:44:49.200]   is a much more appealing product for most consumers
[00:44:49.200 --> 00:44:52.640]   that gives you most of the functionality of Glass.
[00:44:52.640 --> 00:44:54.360]   I don't think that Glass is dead.
[00:44:54.360 --> 00:44:56.560]   I think it's just a niche market.
[00:44:56.560 --> 00:44:58.560]   You know, I imagine going to Coney Island
[00:44:58.560 --> 00:45:00.400]   that I'm about to get on the Ferris wheel.
[00:45:00.400 --> 00:45:02.760]   And they say, do you want to rent a pair of Glass
[00:45:02.760 --> 00:45:04.000]   to take video, right?
[00:45:04.000 --> 00:45:05.240]   Or I'm going to get on a zip line.
[00:45:05.240 --> 00:45:06.520]   It's an experienced thing.
[00:45:06.520 --> 00:45:10.600]   The heads up, the camera on your head thing.
[00:45:10.600 --> 00:45:13.840]   That's not something that you need on a daily basis.
[00:45:13.840 --> 00:45:15.960]   And even just being able to speak to your face computer
[00:45:15.960 --> 00:45:17.640]   isn't something that people really want.
[00:45:17.640 --> 00:45:20.440]   I think the watch is like people want a way
[00:45:20.440 --> 00:45:23.840]   to stay in touch without constantly being buried in their phone.
[00:45:23.840 --> 00:45:24.880]   I think that's a problem.
[00:45:24.880 --> 00:45:26.000]   I think it's an issue.
[00:45:26.000 --> 00:45:28.080]   I think Microsoft has done commercials around people
[00:45:28.080 --> 00:45:30.160]   falling in a mall fountain or whatever, just being,
[00:45:30.160 --> 00:45:32.680]   you know, staring at their phone all day.
[00:45:32.680 --> 00:45:34.840]   I think for people who are hyper connected,
[00:45:34.840 --> 00:45:39.200]   the watch, you know, is a much more appealing product,
[00:45:39.200 --> 00:45:41.160]   especially because people don't stop and ask you about it.
[00:45:41.160 --> 00:45:43.720]   It's not banded theaters and that kind of thing.
[00:45:43.720 --> 00:45:45.080]   So I don't think Glass is dead,
[00:45:45.080 --> 00:45:47.880]   but the watch is definitely a much more--
[00:45:47.880 --> 00:45:50.160]   - The big question is-- - A little bit better.
[00:45:50.160 --> 00:45:51.240]   - If we'd had Larry Page there,
[00:45:51.240 --> 00:45:56.240]   the big question is, is if this is emasculating, is this?
[00:45:56.240 --> 00:46:00.280]   (laughing)
[00:46:00.280 --> 00:46:02.560]   And for those on audio, I was saying that Larry,
[00:46:02.560 --> 00:46:06.080]   "Hold on, so looking at your phone all day was emasculating,
[00:46:06.080 --> 00:46:07.840]   somehow Google Glass was not."
[00:46:07.840 --> 00:46:09.760]   - Was that Sergey or where was the watch coming from?
[00:46:09.760 --> 00:46:10.600]   - Was it Sergey or was it the watch coming from?
[00:46:10.600 --> 00:46:12.040]   - I don't know which one it was, that's true.
[00:46:12.040 --> 00:46:13.160]   - I think I'm not-- - That room which one was it.
[00:46:13.160 --> 00:46:14.240]   - Might have been Sergey.
[00:46:14.240 --> 00:46:18.000]   - That was an educational moment for me
[00:46:18.000 --> 00:46:19.680]   because I didn't realize that emasculate
[00:46:19.680 --> 00:46:22.960]   could mean something other than something gender related.
[00:46:22.960 --> 00:46:25.440]   Like it actually means like weakening.
[00:46:25.440 --> 00:46:26.280]   (laughing)
[00:46:26.280 --> 00:46:28.080]   And I think what you're trying to say is it just,
[00:46:28.080 --> 00:46:31.200]   it breaks down, it limits you less present in the world.
[00:46:31.200 --> 00:46:33.560]   It was just a bad choice of words.
[00:46:33.560 --> 00:46:35.280]   Or maybe it was a good choice, we're still talking about it.
[00:46:35.280 --> 00:46:37.560]   That was like a year, it was a little while ago, wasn't it?
[00:46:37.560 --> 00:46:40.920]   - Yeah, but they're sure, I think we can all agree
[00:46:40.920 --> 00:46:43.560]   that the comfort level of using Android Wear
[00:46:43.560 --> 00:46:45.960]   is very high, surprisingly high,
[00:46:45.960 --> 00:46:50.280]   and that differentiates it massively from Google Glass,
[00:46:50.280 --> 00:46:51.880]   which is a little uncomfortable.
[00:46:51.880 --> 00:46:54.000]   Really cool, it was really cool at first,
[00:46:54.000 --> 00:46:55.840]   it's still cool, I kinda like Google Glass,
[00:46:55.840 --> 00:46:58.080]   it's great to be able to take pictures
[00:46:58.080 --> 00:46:59.880]   and you know, I wear it when I'm trail running
[00:46:59.880 --> 00:47:01.040]   and stuff like that, and I see a deer
[00:47:01.040 --> 00:47:03.080]   and I take a picture and then the picture comes out
[00:47:03.080 --> 00:47:04.880]   and it's a little tiny picture of a deer
[00:47:04.880 --> 00:47:07.120]   that nobody cares about, but it's really kinda cool
[00:47:07.120 --> 00:47:09.320]   to be able to do that if there's an alien invasion
[00:47:09.320 --> 00:47:12.440]   and I get abducted or whatever, I'm gonna have some good video.
[00:47:12.440 --> 00:47:15.000]   But for the most part, I'm really loving the Android Wear,
[00:47:15.000 --> 00:47:18.960]   I think we all do and I'm really looking forward to the apps.
[00:47:18.960 --> 00:47:20.960]   So again, that's coming next week.
[00:47:20.960 --> 00:47:23.240]   Well, speaking of new platforms,
[00:47:23.240 --> 00:47:25.120]   Gina, have you got a chance to play
[00:47:25.120 --> 00:47:28.280]   with Android L's developer preview?
[00:47:28.280 --> 00:47:31.440]   Oh man, I have not had a chance to play with it
[00:47:31.440 --> 00:47:34.400]   and it's because my Nexus 7 is a little too old
[00:47:34.400 --> 00:47:37.600]   and I don't have a Nexus 5, my wife does
[00:47:37.600 --> 00:47:39.200]   and I wanted to swap with her,
[00:47:39.200 --> 00:47:42.840]   I can just call the preview, but my co-hosts on all,
[00:47:42.840 --> 00:47:45.400]   but Android last night, we had Ron Amadeo
[00:47:45.400 --> 00:47:47.680]   from Ars Technica who's written extensively
[00:47:47.680 --> 00:47:50.400]   about the L preview, he said, you know,
[00:47:50.400 --> 00:47:52.640]   it's just not ready for, it can't be,
[00:47:52.640 --> 00:47:54.680]   it's not ready to be your daily driver, right?
[00:47:54.680 --> 00:47:55.760]   You know, I've got a kid in daycare,
[00:47:55.760 --> 00:47:57.000]   like my phone's gonna work, right?
[00:47:57.000 --> 00:47:59.720]   Like I can't, my phone can crash, I need to get phone calls.
[00:47:59.720 --> 00:48:01.720]   So I have not installed it 'cause I just don't have
[00:48:01.720 --> 00:48:03.880]   the hardware laying around to test it out.
[00:48:03.880 --> 00:48:07.000]   And it looks, so we did a nice long review
[00:48:07.000 --> 00:48:09.560]   kinda last night on all about Android added,
[00:48:09.560 --> 00:48:12.200]   it's beautiful, but it's still rough.
[00:48:12.200 --> 00:48:15.080]   It very much is a preview, like this is in a beta,
[00:48:15.080 --> 00:48:16.360]   this is a developer preview.
[00:48:16.360 --> 00:48:19.960]   So it's killing me because, man, does it look good?
[00:48:19.960 --> 00:48:23.520]   I'm just, I'm like, material design is amazing,
[00:48:23.520 --> 00:48:25.520]   but unfortunately I'm going to be developing
[00:48:25.520 --> 00:48:27.560]   in the simulator for now.
[00:48:27.560 --> 00:48:30.560]   I'm sure there are a couple of L's laying around
[00:48:30.560 --> 00:48:32.320]   in the Twit Studios, Mike.
[00:48:32.320 --> 00:48:35.560]   - Not that I've seen, I'll check,
[00:48:35.560 --> 00:48:36.960]   I'll check on Grace's chocolate.
[00:48:36.960 --> 00:48:39.320]   - Yeah, I think Jason's on it, yeah.
[00:48:39.320 --> 00:48:42.800]   - So, yeah, I haven't talked to anybody here
[00:48:42.800 --> 00:48:44.640]   who's looked at that, but you've obviously
[00:48:44.640 --> 00:48:47.000]   been reading about it and, you know,
[00:48:47.000 --> 00:48:48.200]   you've been talking a lot about it,
[00:48:48.200 --> 00:48:50.120]   but for those watching and listening
[00:48:50.120 --> 00:48:53.720]   who are not super familiar on the materials design,
[00:48:53.720 --> 00:48:56.280]   can you explain exactly what that is
[00:48:56.280 --> 00:48:57.840]   and why you're excited about it?
[00:48:57.840 --> 00:49:01.000]   - Well, I'm not quite, I'm not a designer,
[00:49:01.000 --> 00:49:04.400]   but the idea of material design is the idea that
[00:49:04.400 --> 00:49:09.200]   the design of Android is that this kind of
[00:49:09.200 --> 00:49:12.320]   card-based design, which we've already seen in Google now,
[00:49:12.320 --> 00:49:15.120]   but the idea is that the cards and the movement
[00:49:15.120 --> 00:49:18.520]   is very tactile, that the design of the interface,
[00:49:18.520 --> 00:49:21.480]   that the items of the interface behave
[00:49:21.480 --> 00:49:24.120]   as if they were objects in real space.
[00:49:24.120 --> 00:49:26.720]   So there's this idea of height and Z index
[00:49:26.720 --> 00:49:30.000]   where cards can be above the rest of the interface.
[00:49:30.000 --> 00:49:34.400]   The cards kind of scroll and bounce and list very naturally.
[00:49:34.400 --> 00:49:36.520]   Things don't just teleport from one side to the other,
[00:49:36.520 --> 00:49:38.600]   they slide and shift.
[00:49:38.600 --> 00:49:40.280]   You have this hero image that you just saw,
[00:49:40.280 --> 00:49:44.200]   top that then just kind of contracts as you scroll up.
[00:49:44.200 --> 00:49:47.240]   Everything is extremely smooth and fast
[00:49:47.240 --> 00:49:51.880]   and it behaves as if it's card stock.
[00:49:51.880 --> 00:49:54.000]   As if they were cards laid out on the table
[00:49:54.000 --> 00:49:54.920]   and you were moving them around,
[00:49:54.920 --> 00:49:56.520]   except that they can change shape obviously
[00:49:56.520 --> 00:49:57.800]   because it's digital.
[00:49:57.800 --> 00:50:01.880]   You have nice shadows and buttons that can kind of overlay.
[00:50:01.880 --> 00:50:06.560]   It's a complete overhaul of Android's default theme,
[00:50:06.560 --> 00:50:07.800]   which right now is hollow.
[00:50:07.800 --> 00:50:09.560]   So this is just a material design,
[00:50:09.560 --> 00:50:11.760]   is a successful hollow and it takes over
[00:50:11.760 --> 00:50:14.440]   the entire interface of Android and any apps
[00:50:14.440 --> 00:50:17.760]   that use the default theme will also get the material design
[00:50:17.760 --> 00:50:18.760]   upgrades.
[00:50:18.760 --> 00:50:22.440]   And as far as I can say, it's beautiful and it's fast.
[00:50:22.440 --> 00:50:24.640]   And it looks like this really beautiful evolution
[00:50:24.640 --> 00:50:28.080]   of kind of pheomorphism plus flat design.
[00:50:28.080 --> 00:50:29.720]   It's flat design but it's even better
[00:50:29.720 --> 00:50:32.560]   because it feels very natural.
[00:50:32.560 --> 00:50:35.720]   The idea that your brain thinks about objects in space,
[00:50:35.720 --> 00:50:38.600]   the way they actually act in physical space
[00:50:38.600 --> 00:50:40.880]   and to try to create that experience on the phone
[00:50:40.880 --> 00:50:42.000]   to make it more intuitive.
[00:50:42.000 --> 00:50:45.280]   And from what I've seen, just the previews and the videos
[00:50:45.280 --> 00:50:48.080]   and the screenshots, they've done a really, really nice job.
[00:50:48.080 --> 00:50:51.240]   And I'm really excited actually about converting my app
[00:50:51.240 --> 00:50:53.400]   over to material design, which means that Google
[00:50:53.400 --> 00:50:56.000]   did their job at I/O because that was the whole idea.
[00:50:56.000 --> 00:50:57.880]   It's convinced developers to get them excited
[00:50:57.880 --> 00:51:00.800]   about this new theme, this new design.
[00:51:00.800 --> 00:51:01.880]   It's really incredible.
[00:51:01.880 --> 00:51:02.760]   Go ahead, Jeff.
[00:51:02.760 --> 00:51:04.000]   Just a quick question to you on that.
[00:51:04.000 --> 00:51:05.560]   When you redesign your app for that,
[00:51:05.560 --> 00:51:07.320]   does that mean it's yet more fragmentation
[00:51:07.320 --> 00:51:09.960]   that all the earlier versions of Android won't be there?
[00:51:09.960 --> 00:51:13.000]   How much effort does that take and what's the payoff?
[00:51:13.000 --> 00:51:15.960]   It depends on how much customization that you do.
[00:51:15.960 --> 00:51:17.600]   So my app is a to-do list app.
[00:51:17.600 --> 00:51:19.080]   It's a very, very simple app.
[00:51:19.080 --> 00:51:23.640]   It uses standard Android UI elements, lists,
[00:51:23.640 --> 00:51:27.240]   and scrolling and the hamburger menu with the slideout menu.
[00:51:27.240 --> 00:51:31.680]   These are default UI widgets or objects that Android provides.
[00:51:31.680 --> 00:51:33.320]   And I didn't do a whole lot of customization.
[00:51:33.320 --> 00:51:36.320]   So for me, it's going to be very, very simple.
[00:51:36.320 --> 00:51:39.680]   For apps that have custom designs,
[00:51:39.680 --> 00:51:42.800]   that aren't your standard Android stuff,
[00:51:42.800 --> 00:51:45.200]   it's a little harder.
[00:51:45.200 --> 00:51:47.200]   Maybe you don't switch the material design at all
[00:51:47.200 --> 00:51:49.880]   if you've decided to design your app completely custom.
[00:51:49.880 --> 00:51:52.520]   But for the most part, all these improvements
[00:51:52.520 --> 00:51:55.000]   in material design, you get mostly for free.
[00:51:55.000 --> 00:51:58.800]   If you're already using default Android UI elements,
[00:51:58.800 --> 00:52:02.240]   you get these updates for free, which is really nice.
[00:52:02.240 --> 00:52:03.080]   That's very cool.
[00:52:03.080 --> 00:52:05.200]   When you said it was a phrase used a lot last week at I/O,
[00:52:05.200 --> 00:52:08.080]   you get them for free.
[00:52:08.080 --> 00:52:10.680]   It doesn't mean the obvious that otherwise you'd pay for them.
[00:52:10.680 --> 00:52:12.040]   What does it mean?
[00:52:12.040 --> 00:52:14.440]   It means that there's no extra effort on my part
[00:52:14.440 --> 00:52:14.960]   of the developer.
[00:52:14.960 --> 00:52:17.000]   I don't have to recompile my APK.
[00:52:17.000 --> 00:52:19.280]   I don't have to write new source code.
[00:52:19.280 --> 00:52:19.840]   It just runs.
[00:52:19.840 --> 00:52:20.840]   It just works.
[00:52:20.840 --> 00:52:23.360]   So that's why when they were saying with Android Wear,
[00:52:23.360 --> 00:52:26.160]   that if your app has notifications on Android,
[00:52:26.160 --> 00:52:28.560]   it works on Android Wear because Android Wear just detects
[00:52:28.560 --> 00:52:29.280]   those notifications.
[00:52:29.280 --> 00:52:31.600]   I don't have to recompile and re-upload for free, right?
[00:52:31.600 --> 00:52:33.920]   Meaning no more extra cost or investment
[00:52:33.920 --> 00:52:35.920]   on my part of the developer.
[00:52:35.920 --> 00:52:38.880]   It's really fascinating to see Google's rapid transition
[00:52:38.880 --> 00:52:41.680]   from essentially ignoring and almost having a contempt
[00:52:41.680 --> 00:52:45.160]   for anything that resembles design just a few years ago
[00:52:45.160 --> 00:52:47.400]   to being so good at design.
[00:52:47.400 --> 00:52:49.960]   Their apps have been beautiful for a while.
[00:52:49.960 --> 00:52:53.040]   Their iOS apps have been beautiful for a while.
[00:52:53.040 --> 00:52:55.600]   The design of Google Plus is very nice.
[00:52:55.600 --> 00:52:57.520]   And the cards interface is beautiful.
[00:52:57.520 --> 00:52:59.400]   And now this.
[00:52:59.400 --> 00:53:01.760]   They've just gone from the back of the class
[00:53:01.760 --> 00:53:03.440]   to the front of the class.
[00:53:03.440 --> 00:53:04.840]   And it's really great to see.
[00:53:04.840 --> 00:53:08.280]   They finally understand the design isn't about decoration.
[00:53:08.280 --> 00:53:12.360]   It's about usability and user happiness, really.
[00:53:12.360 --> 00:53:14.320]   I mean, we saw this on the web, too, right?
[00:53:14.320 --> 00:53:16.200]   Like Android's iteration evolution
[00:53:16.200 --> 00:53:19.240]   has been this sped up process that we saw on the web, right?
[00:53:19.240 --> 00:53:22.440]   I mean, back in the day, Google was--
[00:53:22.440 --> 00:53:23.840]   it was a list of blue links, right?
[00:53:23.840 --> 00:53:25.840]   It was like the default browser browser blue.
[00:53:25.840 --> 00:53:28.480]   And I don't know if it still is that, right?
[00:53:28.480 --> 00:53:30.200]   But we see a lot more design and things like,
[00:53:30.200 --> 00:53:32.440]   I look at the new modern apps like Google Keats.
[00:53:32.440 --> 00:53:36.520]   And I'm just like, this is gorgeous what they did here.
[00:53:36.520 --> 00:53:39.080]   When they launched forever ago, I think
[00:53:39.080 --> 00:53:42.080]   either Larry or Sergey were photoshopping the Google
[00:53:42.080 --> 00:53:43.800]   logo themselves.
[00:53:43.800 --> 00:53:44.760]   They've come a long way.
[00:53:44.760 --> 00:53:46.720]   And I feel like the Android evolution
[00:53:46.720 --> 00:53:48.320]   has been just an accelerated version of what
[00:53:48.320 --> 00:53:49.640]   we've seen on the web.
[00:53:49.640 --> 00:53:52.080]   And, Gina, speaking of things that you get for free,
[00:53:52.080 --> 00:53:54.320]   what is your current thinking about Project Volta?
[00:53:54.320 --> 00:53:56.720]   I mean, it sounds great right out of the bat.
[00:53:56.720 --> 00:53:59.040]   Project Volta is a huge initiative
[00:53:59.040 --> 00:54:04.960]   that will enable Android devices to really be careful
[00:54:04.960 --> 00:54:05.720]   with battery life.
[00:54:05.720 --> 00:54:06.840]   It'll extend battery life.
[00:54:06.840 --> 00:54:09.680]   Essentially, that'll be the end result for end users
[00:54:09.680 --> 00:54:13.320]   that with the same battery, with the same everything else,
[00:54:13.320 --> 00:54:16.280]   the phone will last a lot longer between charges.
[00:54:16.280 --> 00:54:17.320]   But there's a downside.
[00:54:17.320 --> 00:54:18.680]   There are downsides to it, of course,
[00:54:18.680 --> 00:54:20.200]   that it turns off services.
[00:54:20.200 --> 00:54:22.440]   It doesn't do anything super magical.
[00:54:22.440 --> 00:54:24.480]   It just manages the things that are running.
[00:54:24.480 --> 00:54:26.000]   For example, it won't launch something that
[00:54:26.000 --> 00:54:27.800]   requires an internet connection if there's
[00:54:27.800 --> 00:54:30.400]   no internet connection present, that sort of thing.
[00:54:30.400 --> 00:54:32.720]   But what you're thinking as a developer about Project Volta,
[00:54:32.720 --> 00:54:36.560]   is this something that's going to be transformative,
[00:54:36.560 --> 00:54:37.720]   or could this be problematic?
[00:54:37.720 --> 00:54:39.920]   What are you thinking about this?
[00:54:39.920 --> 00:54:42.800]   I mean, to me, it sounds like advantages
[00:54:42.800 --> 00:54:44.360]   that you also kind of get for free.
[00:54:44.360 --> 00:54:46.320]   I mean, when you're developing for a mobile app,
[00:54:46.320 --> 00:54:48.880]   you have to think about things like snow flow connections
[00:54:48.880 --> 00:54:51.960]   and intermittent connections and non-existent connections
[00:54:51.960 --> 00:54:54.480]   and small screens and low processing power.
[00:54:54.480 --> 00:54:57.800]   And as Android, the system can help me manage that better.
[00:54:57.800 --> 00:55:00.120]   If my app doesn't work, if there's no internet connection,
[00:55:00.120 --> 00:55:01.560]   it's a bad user experience.
[00:55:01.560 --> 00:55:05.440]   If the user launches the app and it just says, oops, sorry.
[00:55:05.440 --> 00:55:08.200]   So if Android handles that for me, that's great.
[00:55:08.200 --> 00:55:09.240]   Bring it on.
[00:55:09.240 --> 00:55:10.840]   Like, that's just less work that I have to do.
[00:55:10.840 --> 00:55:13.600]   I mean, there's certain problems that every mobile app
[00:55:13.600 --> 00:55:15.960]   has to deal with, particularly around intermittent connections
[00:55:15.960 --> 00:55:18.080]   and slow connections and bad connections.
[00:55:18.080 --> 00:55:20.680]   And so anything that the Android, the system, can handle,
[00:55:20.680 --> 00:55:22.280]   I'm like, bring it on.
[00:55:22.280 --> 00:55:23.160]   That's great.
[00:55:23.160 --> 00:55:26.520]   And if your app is so battery hungry
[00:55:26.520 --> 00:55:29.120]   that Volta is killing it on a regular basis,
[00:55:29.120 --> 00:55:31.160]   I mean, that's more motivation for me as a developer
[00:55:31.160 --> 00:55:34.440]   to optimize even more.
[00:55:34.440 --> 00:55:35.920]   That's a great point.
[00:55:35.920 --> 00:55:39.720]   Well, I think we should do the Google Change Log
[00:55:39.720 --> 00:55:44.120]   if we have the Timponies ready and the trumpets.
[00:55:44.120 --> 00:55:47.280]   So why don't we launch into that?
[00:55:47.280 --> 00:55:49.280]   The Google Change Log.
[00:55:49.280 --> 00:55:52.760]   [MUSIC PLAYING]
[00:55:52.760 --> 00:55:56.400]   [CLICKING]
[00:55:56.400 --> 00:55:59.000]   This is a relatively light change log post-IO,
[00:55:59.000 --> 00:56:00.880]   but we do have a couple of little things.
[00:56:00.880 --> 00:56:03.760]   First, this was spotted by Android Central.
[00:56:03.760 --> 00:56:08.120]   Google Voice for Android now has emoji support.
[00:56:08.120 --> 00:56:11.920]   So you can send all your happy faces that you want.
[00:56:11.920 --> 00:56:12.800]   I tried it out today.
[00:56:12.800 --> 00:56:15.200]   It works really great on Google Voice for Android.
[00:56:15.200 --> 00:56:17.440]   However, I got what I think--
[00:56:17.440 --> 00:56:18.880]   I think you pronounce it MojiBaki.
[00:56:18.880 --> 00:56:19.760]   Is that how it's called?
[00:56:19.760 --> 00:56:20.360]   What it's called?
[00:56:20.360 --> 00:56:21.360]   I have no idea.
[00:56:21.360 --> 00:56:22.880]   And it's what it messes up emoji.
[00:56:22.880 --> 00:56:25.840]   Yeah, on the web, Google Voice the web, I did not see my emoji.
[00:56:25.840 --> 00:56:30.920]   But it does work from Google Voice to regular SMS carrier
[00:56:30.920 --> 00:56:31.800]   and back.
[00:56:31.800 --> 00:56:34.440]   So that's a welcome addition for those of us who
[00:56:34.440 --> 00:56:36.560]   like our smiley faces.
[00:56:36.560 --> 00:56:37.240]   Let's see.
[00:56:37.240 --> 00:56:42.960]   Oh, video hangouts no longer require a plugin on the desktop.
[00:56:42.960 --> 00:56:45.040]   So Google is officially deprecated.
[00:56:45.040 --> 00:56:48.640]   The Hangouts plugin for Chrome on the developer and Canary
[00:56:48.640 --> 00:56:50.520]   channels on the Chrome browser.
[00:56:50.520 --> 00:56:52.400]   Meaning that Hangouts video functionality
[00:56:52.400 --> 00:56:55.560]   is now completely built into the browser.
[00:56:55.560 --> 00:56:58.240]   So this feature is going to roll out to all Chrome users
[00:56:58.240 --> 00:57:00.560]   in the next weeks, which really nice just
[00:57:00.560 --> 00:57:05.040]   means you don't have to install an extra extension.
[00:57:05.040 --> 00:57:07.480]   Sad news for orchid users.
[00:57:07.480 --> 00:57:09.000]   Remember orchid?
[00:57:09.000 --> 00:57:10.640]   It was pre-Google+.
[00:57:10.640 --> 00:57:12.400]   In other words, you're Brazilian viewers.
[00:57:12.400 --> 00:57:13.360]   You're Brazilian.
[00:57:13.360 --> 00:57:13.880]   Yes.
[00:57:13.880 --> 00:57:14.160]   Yes.
[00:57:14.160 --> 00:57:16.440]   Bad news to Brazilian users.
[00:57:16.440 --> 00:57:18.960]   Google is shutting down orchid.
[00:57:18.960 --> 00:57:23.680]   First social networking effort back in the day acquired.
[00:57:23.680 --> 00:57:27.600]   I guess they launched it in 2011.
[00:57:27.600 --> 00:57:29.400]   So sorry not 2011.
[00:57:29.400 --> 00:57:31.160]   That's Google+.
[00:57:31.160 --> 00:57:31.720]   Sorry about that.
[00:57:31.720 --> 00:57:32.480]   Actually, don't do that.
[00:57:32.480 --> 00:57:33.280]   2004, I believe.
[00:57:33.280 --> 00:57:34.520]   I think it's 10 years old.
[00:57:34.520 --> 00:57:36.280]   Long, 10 years old.
[00:57:36.280 --> 00:57:36.680]   Yes.
[00:57:36.680 --> 00:57:38.360]   So they're shutting it down to focus
[00:57:38.360 --> 00:57:40.760]   on other social networking businesses like YouTube
[00:57:40.760 --> 00:57:42.400]   Blogger and Google+.
[00:57:42.400 --> 00:57:42.920]   So--
[00:57:42.920 --> 00:57:45.480]   I do believe Kevin Marks worked on orchid for a while,
[00:57:45.480 --> 00:57:46.680]   as I remember.
[00:57:46.680 --> 00:57:47.240]   Oh, yeah.
[00:57:47.240 --> 00:57:48.280]   You know, you might be right.
[00:57:48.280 --> 00:57:50.040]   You might be right.
[00:57:50.040 --> 00:57:51.920]   It was a 20% time project.
[00:57:51.920 --> 00:57:54.160]   And I used it at the beginning.
[00:57:54.160 --> 00:57:56.520]   And then pretty soon, everything was in Portuguese.
[00:57:56.520 --> 00:57:57.520]   And then--
[00:57:57.520 --> 00:57:58.520]   Yes.
[00:57:58.520 --> 00:58:00.960]   [LAUGHTER]
[00:58:00.960 --> 00:58:02.840]   It was also big in India for a while.
[00:58:02.840 --> 00:58:03.400]   Yes.
[00:58:03.400 --> 00:58:03.920]   Yeah.
[00:58:03.920 --> 00:58:04.440]   Yeah.
[00:58:04.440 --> 00:58:05.960]   It still is, or was, I guess.
[00:58:05.960 --> 00:58:08.520]   They're shutting it down September 30th, I believe it is.
[00:58:08.520 --> 00:58:10.080]   So is there no trend-- there's nothing you can do
[00:58:10.080 --> 00:58:12.120]   to transport your friends anywhere else or anything?
[00:58:12.120 --> 00:58:12.880]   They're just--
[00:58:12.880 --> 00:58:13.680]   They're just--
[00:58:13.680 --> 00:58:16.400]   You can export your profile data and posts and photos
[00:58:16.400 --> 00:58:18.320]   using Google Takeout from orchids.
[00:58:18.320 --> 00:58:20.320]   And that'll be available until September 2016.
[00:58:20.320 --> 00:58:22.800]   So you've got some time if you got some orchid data.
[00:58:22.800 --> 00:58:24.280]   And I understand I'm getting rid of it.
[00:58:24.280 --> 00:58:26.280]   I have a problem with it in the long run.
[00:58:26.280 --> 00:58:28.560]   But there is-- I remember when I talked about this long ago,
[00:58:28.560 --> 00:58:33.560]   when my daughter was on the American Girl site.
[00:58:33.560 --> 00:58:35.160]   They'll be coming to you soon, Gina.
[00:58:35.160 --> 00:58:36.960]   [LAUGHTER]
[00:58:36.960 --> 00:58:40.320]   And I think Mattel owns the company and owned the site.
[00:58:40.320 --> 00:58:42.840]   And it was a safe place where she could have friends.
[00:58:42.840 --> 00:58:43.920]   And something they just killed it.
[00:58:43.920 --> 00:58:46.360]   And it was like destroying the town.
[00:58:46.360 --> 00:58:47.840]   Right?
[00:58:47.840 --> 00:58:51.360]   It's-- you have a bit of a social responsibility
[00:58:51.360 --> 00:58:53.160]   when you create the platform for a community.
[00:58:53.160 --> 00:58:54.520]   And then you kill the platform.
[00:58:54.520 --> 00:58:57.240]   And the community just goes, boom.
[00:58:57.240 --> 00:58:57.600]   Right.
[00:58:57.600 --> 00:58:59.360]   There's no space for them to go to anymore.
[00:58:59.360 --> 00:58:59.880]   Yeah.
[00:58:59.880 --> 00:59:00.480]   Yeah.
[00:59:00.480 --> 00:59:00.880]   It is.
[00:59:00.880 --> 00:59:04.360]   You really need someone to make an organize, move over.
[00:59:04.360 --> 00:59:06.520]   I feel like even beyond Google Takeout,
[00:59:06.520 --> 00:59:08.640]   Google could do something like create an orchid community
[00:59:08.640 --> 00:59:10.200]   on plus or create some sort of alternate space.
[00:59:10.200 --> 00:59:11.040]   Exactly.
[00:59:11.040 --> 00:59:11.880]   Well, I think--
[00:59:11.880 --> 00:59:12.720]   I think that they--
[00:59:12.720 --> 00:59:14.760]   I've heard that they are going to provide a tool.
[00:59:14.760 --> 00:59:17.320]   It's not available yet to actually automatically
[00:59:17.320 --> 00:59:22.880]   transition orchid profiles to Google+ profiles.
[00:59:22.880 --> 00:59:23.360]   Chatroom.
[00:59:23.360 --> 00:59:24.400]   Then you've got to transition all your--
[00:59:24.400 --> 00:59:25.560]   you're losing your friends, too.
[00:59:25.560 --> 00:59:27.080]   You're losing the thing that matters to you.
[00:59:27.080 --> 00:59:27.520]   Yeah.
[00:59:27.520 --> 00:59:28.040]   Exactly.
[00:59:28.040 --> 00:59:29.680]   And again, I understand why they're doing it.
[00:59:29.680 --> 00:59:31.320]   They kill things that aren't working.
[00:59:31.320 --> 00:59:33.800]   We've been making orchid jokes for years.
[00:59:33.800 --> 00:59:36.320]   But still, there's some responsibility
[00:59:36.320 --> 00:59:37.800]   to a community when you start it.
[00:59:37.800 --> 00:59:40.040]   And I think that's an issue going forward.
[00:59:40.040 --> 00:59:40.720]   Yeah.
[00:59:40.720 --> 00:59:42.120]   Hey, you said it was OK for Facebook
[00:59:42.120 --> 00:59:44.240]   to sever my relationship with that mildrin.
[00:59:44.240 --> 00:59:45.640]   What's the difference here?
[00:59:45.640 --> 00:59:46.000]   That's right.
[00:59:46.000 --> 00:59:47.680]   I don't know anybody in Brazil.
[00:59:47.680 --> 00:59:51.000]   So is that a--
[00:59:51.000 --> 00:59:53.080]   Gina, is that the change log?
[00:59:53.080 --> 00:59:54.360]   One last shutdown.
[00:59:54.360 --> 00:59:54.880]   One last shutdown.
[00:59:54.880 --> 00:59:57.760]   This is actually a feature that wasn't available here in the US.
[00:59:57.760 --> 01:00:03.440]   But Google had actually introduced SMS for Hangouts on the web.
[01:00:03.440 --> 01:00:06.400]   Of course, we know that it exists in Hangouts for Android.
[01:00:06.400 --> 01:00:07.480]   So they had offered that.
[01:00:07.480 --> 01:00:10.680]   And up until now, that feature was available in India, Pakistan.
[01:00:10.680 --> 01:00:13.480]   Israel, Turkey, Ukraine, Congo, and other countries in Africa,
[01:00:13.480 --> 01:00:16.520]   and Asia, they are currently-- they are shutting that down
[01:00:16.520 --> 01:00:17.640]   as well.
[01:00:17.640 --> 01:00:19.840]   They're saying that the service will be discontinued.
[01:00:19.840 --> 01:00:23.720]   And for other regions, it just says
[01:00:23.720 --> 01:00:25.120]   that the service isn't available.
[01:00:25.120 --> 01:00:26.760]   So not sure what's going on there.
[01:00:26.760 --> 01:00:28.920]   I think we saw quite a bit at Google I/O
[01:00:28.920 --> 01:00:33.240]   about getting text messages from Android onto Chrome OS.
[01:00:33.240 --> 01:00:35.680]   I would love to see that actually just in Chrome.
[01:00:35.680 --> 01:00:37.840]   So you don't have to be on a Chromebook to get that.
[01:00:37.840 --> 01:00:40.000]   But I wouldn't be surprised if we saw another iteration
[01:00:40.000 --> 01:00:43.000]   of getting SMS on the desktop for everyone soon.
[01:00:43.000 --> 01:00:45.240]   But for now, that experimental feature
[01:00:45.240 --> 01:00:47.400]   for those countries is no longer available.
[01:00:47.400 --> 01:00:50.080]   And there were stories related to this
[01:00:50.080 --> 01:00:55.360]   before we play the trumpets again that were talking about evidence
[01:00:55.360 --> 01:00:58.160]   that Google is going to be moving Google Voice people
[01:00:58.160 --> 01:01:00.640]   to Hangouts and building some of the Google Voice functionality
[01:01:00.640 --> 01:01:01.640]   in the Hangouts.
[01:01:01.640 --> 01:01:04.720]   And in there somewhere would be another way
[01:01:04.720 --> 01:01:08.320]   to integrate SMS with Hangouts.
[01:01:08.320 --> 01:01:10.560]   But I have to be honest, I read multiple articles.
[01:01:10.560 --> 01:01:12.960]   And none of them were all that clear.
[01:01:12.960 --> 01:01:17.000]   And I still am not certain about exactly what the evidence is
[01:01:17.000 --> 01:01:19.560]   and what the information is and what's going to happen.
[01:01:19.560 --> 01:01:21.440]   But I think that logically speaking,
[01:01:21.440 --> 01:01:24.000]   it makes a lot of sense that Google Voice
[01:01:24.000 --> 01:01:27.080]   be folded into and integrated with Hangouts
[01:01:27.080 --> 01:01:29.360]   that some of the Google Voice functionality-- hopefully
[01:01:29.360 --> 01:01:30.880]   all the Google Voice functionality.
[01:01:30.880 --> 01:01:31.640]   I'm a voice user.
[01:01:31.640 --> 01:01:33.560]   There are certain things in Google Voice
[01:01:33.560 --> 01:01:37.320]   that I really would rather not live without.
[01:01:37.320 --> 01:01:39.040]   And if they're going to move it to Hangouts,
[01:01:39.040 --> 01:01:40.640]   bring all that stuff.
[01:01:40.640 --> 01:01:43.400]   The only thing I have to say is that I, into this day,
[01:01:43.400 --> 01:01:46.560]   confused about SMS in Hangouts.
[01:01:46.560 --> 01:01:48.040]   Yeah.
[01:01:48.040 --> 01:01:52.400]   It's just-- and I end up sending a message to my son
[01:01:52.400 --> 01:01:55.320]   on his Google account instead of his phone.
[01:01:55.320 --> 01:01:56.320]   And I--
[01:01:56.320 --> 01:01:57.120]   Yeah.
[01:01:57.120 --> 01:01:57.520]   Yeah.
[01:01:57.520 --> 01:01:59.920]   And so it's all very, very confusing.
[01:01:59.920 --> 01:02:01.960]   There are many things about Hangouts that are confusing.
[01:02:01.960 --> 01:02:05.160]   For example, why can't they turn off people calling me
[01:02:05.160 --> 01:02:07.680]   from Pakistan in the middle of the night?
[01:02:07.680 --> 01:02:08.840]   Like, why can't they turn off?
[01:02:08.840 --> 01:02:09.340]   Really?
[01:02:09.340 --> 01:02:10.600]   Yeah, it happens in the middle.
[01:02:10.600 --> 01:02:12.080]   From all over the world, and I just
[01:02:12.080 --> 01:02:13.440]   can't figure out how to turn it off.
[01:02:13.440 --> 01:02:16.040]   But this whole SMS thing, when they first launched it,
[01:02:16.040 --> 01:02:17.600]   and I believe it's still the case,
[01:02:17.600 --> 01:02:21.760]   a person's SMS is treated like a different person
[01:02:21.760 --> 01:02:25.640]   from that person as you know them on Google+ Gmail and so on.
[01:02:25.640 --> 01:02:29.280]   And it's very easy to mix them up.
[01:02:29.280 --> 01:02:31.680]   But the other thing that the story that Gina's talking about,
[01:02:31.680 --> 01:02:33.880]   as I understand it, is not that.
[01:02:33.880 --> 01:02:36.040]   It's not that use of SMS via Hangouts.
[01:02:36.040 --> 01:02:42.160]   It's the transmission of Hangout messages via the SMS system.
[01:02:42.160 --> 01:02:44.040]   And so it's super complicated.
[01:02:44.040 --> 01:02:47.720]   Nobody knows what's going on with Hangouts in SMS.
[01:02:47.720 --> 01:02:50.920]   And it's terrible because Google needs to fix this.
[01:02:50.920 --> 01:02:54.480]   Hangouts is super central to what Google is trying to accomplish.
[01:02:54.480 --> 01:02:58.280]   And they need to make it clear and easy, and frankly,
[01:02:58.280 --> 01:03:01.320]   more FaceTime-like or more iMessage-like, I guess I should
[01:03:01.320 --> 01:03:05.240]   say, where you basically can just send someone a message.
[01:03:05.240 --> 01:03:09.000]   And the company takes care of how it gets there.
[01:03:09.000 --> 01:03:11.920]   And if everybody's using Hangouts, fine, it goes by Hangouts.
[01:03:11.920 --> 01:03:13.360]   If they're not, it goes by SMS, fine.
[01:03:13.360 --> 01:03:15.440]   But it's all sort of behind the scenes.
[01:03:15.440 --> 01:03:19.320]   I don't want to have to stress out about who I'm contacting,
[01:03:19.320 --> 01:03:20.640]   how I'm contacting them.
[01:03:20.640 --> 01:03:23.000]   And I don't want people calling me in the middle of the night.
[01:03:23.000 --> 01:03:24.200]   Yeah, I totally agree.
[01:03:24.200 --> 01:03:26.200]   I mean, we're still waiting for the unified messaging
[01:03:26.200 --> 01:03:28.560]   platform that Google promised.
[01:03:28.560 --> 01:03:30.840]   It was like two I/Os ago.
[01:03:30.840 --> 01:03:32.040]   And I don't know with Google Voice.
[01:03:32.040 --> 01:03:34.360]   I mean, I hope they build it into Hangouts.
[01:03:34.360 --> 01:03:36.480]   It feels like Google Voice is either on the edge of getting
[01:03:36.480 --> 01:03:40.000]   killed or this amazing roll-up upgrade into Hangouts
[01:03:40.000 --> 01:03:42.200]   where everything just works.
[01:03:42.200 --> 01:03:45.080]   I feel like if Google shuts down Voice,
[01:03:45.080 --> 01:03:47.560]   it will have a worse situation on its hands
[01:03:47.560 --> 01:03:49.480]   than it did when Google Reader closed.
[01:03:49.480 --> 01:03:54.640]   Because I think that there's a very strong and vocal user
[01:03:54.640 --> 01:03:57.240]   base, a power user who love Voice and have
[01:03:57.240 --> 01:03:58.640]   used it for a really long time.
[01:03:58.640 --> 01:04:00.200]   I think most people don't know what Voice is,
[01:04:00.200 --> 01:04:01.960]   but I think that the people who do know what Voice is
[01:04:01.960 --> 01:04:06.600]   are folks like us who switch phones and who are privileged
[01:04:06.600 --> 01:04:09.320]   in that way and that have a need for the one number
[01:04:09.320 --> 01:04:10.720]   to rule them all.
[01:04:10.720 --> 01:04:12.640]   So I hope that they don't shut it down, because I think it
[01:04:12.640 --> 01:04:14.960]   will be a serious PR issue if they do.
[01:04:14.960 --> 01:04:17.880]   And for those watching or listening who are not familiar
[01:04:17.880 --> 01:04:20.120]   with the feature set of Google Voice, essentially,
[01:04:20.120 --> 01:04:21.480]   there are many features.
[01:04:21.480 --> 01:04:23.920]   But the killer features are that you can add multiple phones.
[01:04:23.920 --> 01:04:27.160]   You can have landline phones, cell phones,
[01:04:27.160 --> 01:04:29.520]   and they're all attached to your single Google Voice number.
[01:04:29.520 --> 01:04:31.880]   So people call and then you can determine which phones ring,
[01:04:31.880 --> 01:04:33.680]   whether they all ring, whether none of them
[01:04:33.680 --> 01:04:34.920]   rings between certain hours.
[01:04:34.920 --> 01:04:36.800]   You can block callers.
[01:04:36.800 --> 01:04:40.400]   So if you're getting a telephone spam,
[01:04:40.400 --> 01:04:41.920]   you can block that number.
[01:04:41.920 --> 01:04:45.560]   And Google will lie for you and tell those callers,
[01:04:45.560 --> 01:04:47.400]   it'll play a fake.
[01:04:47.400 --> 01:04:52.240]   This number is no longer in service recording, which is crazy,
[01:04:52.240 --> 01:04:54.640]   really, that they would be willing to lie
[01:04:54.640 --> 01:04:58.160]   by copying the official telephone systems no longer
[01:04:58.160 --> 01:05:00.160]   in service message.
[01:05:00.160 --> 01:05:01.200]   And features like that.
[01:05:01.200 --> 01:05:02.240]   But that's really great.
[01:05:02.240 --> 01:05:03.840]   You can swap out other numbers, and you
[01:05:03.840 --> 01:05:05.160]   can have a lot of control over your numbers.
[01:05:05.160 --> 01:05:06.520]   That's how phones should work, really.
[01:05:06.520 --> 01:05:08.560]   That's how contacting people on a phone should work.
[01:05:08.560 --> 01:05:11.040]   So yeah, please keep all of those features
[01:05:11.040 --> 01:05:12.200]   if you're going to move it to Hangouts,
[01:05:12.200 --> 01:05:13.760]   because those are very, very powerful.
[01:05:13.760 --> 01:05:16.520]   And yeah, like you said, people are passionate about voice,
[01:05:16.520 --> 01:05:19.760]   because you start using it, and you just need it.
[01:05:19.760 --> 01:05:20.600]   You can't turn back.
[01:05:20.600 --> 01:05:21.280]   Yeah.
[01:05:21.280 --> 01:05:22.080]   Yeah.
[01:05:22.080 --> 01:05:22.880]   Absolutely.
[01:05:22.880 --> 01:05:24.760]   So we have a closer for the change log.
[01:05:24.760 --> 01:05:25.640]   Shouldn't we play that?
[01:05:25.640 --> 01:05:27.560]   [MUSIC PLAYING]
[01:05:27.560 --> 01:05:28.560]   There we go.
[01:05:28.560 --> 01:05:29.680]   Thank you, Chad.
[01:05:29.680 --> 01:05:31.440]   Yeah, awesome.
[01:05:31.440 --> 01:05:35.760]   Well, OK, so let's talk about the Supreme Court's refusal
[01:05:35.760 --> 01:05:38.440]   to hear Google's Street View appeal.
[01:05:38.440 --> 01:05:41.720]   Now, just to set up the story, some time ago,
[01:05:41.720 --> 01:05:43.600]   a few years ago, a couple of years ago,
[01:05:43.600 --> 01:05:48.600]   Google was caught harvesting data from people's home Wi-Fi,
[01:05:48.600 --> 01:05:51.920]   small business Wi-Fi, as their Street View cars roamed
[01:05:51.920 --> 01:05:55.280]   through the streets, and just sucking down data,
[01:05:55.280 --> 01:05:57.320]   taking, in some cases, passwords,
[01:05:57.320 --> 01:05:58.680]   anything it could.
[01:05:58.680 --> 01:06:01.120]   It turns out that Google officially
[01:06:01.120 --> 01:06:03.560]   threw a rogue engineer under the bus
[01:06:03.560 --> 01:06:05.680]   saying that this project was something
[01:06:05.680 --> 01:06:09.080]   done without official corporate authorization.
[01:06:09.080 --> 01:06:10.240]   They should have coped to the fact
[01:06:10.240 --> 01:06:13.520]   that it's possible for employees to do things like that
[01:06:13.520 --> 01:06:16.560]   without the company's knowledge or permission.
[01:06:16.560 --> 01:06:19.040]   But the Supreme Court basically said,
[01:06:19.040 --> 01:06:22.880]   and Google was sued, they lost the lawsuit.
[01:06:22.880 --> 01:06:24.760]   Google wanted the Supreme Court to look at it,
[01:06:24.760 --> 01:06:27.240]   and the Supreme Court said, no, and that's the end of it.
[01:06:27.240 --> 01:06:29.840]   So there's no higher court, the Supreme Court wants this.
[01:06:29.840 --> 01:06:31.200]   Well, but I think this was--
[01:06:31.200 --> 01:06:32.600]   and I didn't read the--
[01:06:32.600 --> 01:06:34.320]   I saw the stories quickly.
[01:06:34.320 --> 01:06:37.960]   But as I recall, Google was trying
[01:06:37.960 --> 01:06:39.320]   to stop the case from going on.
[01:06:39.320 --> 01:06:41.160]   This now allows the case to go on.
[01:06:41.160 --> 01:06:42.200]   So I don't think it's fully--
[01:06:42.200 --> 01:06:43.880]   OK, OK.
[01:06:43.880 --> 01:06:45.320]   Sadly, I can be wrong about that.
[01:06:45.320 --> 01:06:48.240]   Chatroom, correct me, as I know you will, if I'm wrong.
[01:06:48.240 --> 01:06:49.320]   Yeah, OK.
[01:06:49.320 --> 01:06:50.080]   That's a good point.
[01:06:50.080 --> 01:06:52.080]   But I do want to talk about the question.
[01:06:52.080 --> 01:06:55.800]   And the truth be told, I'm hoping, Jeff Jarvis,
[01:06:55.800 --> 01:06:58.600]   that you'll be one of the only people in the world
[01:06:58.600 --> 01:07:01.480]   to agree with my opinion on this.
[01:07:01.480 --> 01:07:03.560]   But my opinion is essentially this.
[01:07:03.560 --> 01:07:06.280]   The way this story has been characterized in the press
[01:07:06.280 --> 01:07:09.280]   since this was first uncovered is
[01:07:09.280 --> 01:07:12.440]   that Google Street Viewcars were driving around
[01:07:12.440 --> 01:07:15.320]   and reaching into people's homes and reaching
[01:07:15.320 --> 01:07:19.520]   into their Wi-Fi routers and grabbing information.
[01:07:19.520 --> 01:07:21.240]   When, in fact, the way that works
[01:07:21.240 --> 01:07:24.640]   is that the Wi-Fi information is under the control
[01:07:24.640 --> 01:07:27.320]   of the owner theoretically, whether it's encrypted
[01:07:27.320 --> 01:07:29.080]   or not encrypted, whether it's password protected,
[01:07:29.080 --> 01:07:30.400]   or not password protected.
[01:07:30.400 --> 01:07:32.600]   And those things are broadcast out into the street,
[01:07:32.600 --> 01:07:34.040]   out into the public street.
[01:07:34.040 --> 01:07:37.560]   And a car passing by, everything that passes by
[01:07:37.560 --> 01:07:40.720]   is going to be washed over by these wave--
[01:07:40.720 --> 01:07:44.760]   by these electromagnetic radiation, essentially.
[01:07:44.760 --> 01:07:48.840]   And so the idea that you would pay attention to it,
[01:07:48.840 --> 01:07:51.480]   that you would see it, that you would capture it,
[01:07:51.480 --> 01:07:54.320]   it's similar to when if you open up a Wi-Fi network
[01:07:54.320 --> 01:07:57.480]   in the restaurant next door, you can see their Wi-Fi password.
[01:07:57.480 --> 01:08:00.800]   You're actually connecting to their router, to a certain extent.
[01:08:00.800 --> 01:08:03.360]   That information is coming to you and you're seeing it.
[01:08:03.360 --> 01:08:07.680]   So to capture and record what is on a public street,
[01:08:07.680 --> 01:08:11.560]   essentially, it's not polite.
[01:08:11.560 --> 01:08:12.240]   It's not nice.
[01:08:12.240 --> 01:08:14.680]   They shouldn't have done it, as they've admitted.
[01:08:14.680 --> 01:08:19.200]   But it doesn't seem to me like a super wrong thing to do either.
[01:08:19.200 --> 01:08:22.800]   It's kind of as if it's literally like somebody
[01:08:22.800 --> 01:08:26.600]   put a big TV set in the window facing out toward the street
[01:08:26.600 --> 01:08:28.800]   with their personal password on it,
[01:08:28.800 --> 01:08:32.320]   and then having somebody walk by and go, huh, writing it down,
[01:08:32.320 --> 01:08:35.440]   and then them getting in trouble for writing it down.
[01:08:35.440 --> 01:08:37.680]   The person who was in control of that information
[01:08:37.680 --> 01:08:40.200]   broadcasted into the public sphere.
[01:08:40.200 --> 01:08:43.840]   And so it just doesn't seem as wrong as it sounds on its face.
[01:08:43.840 --> 01:08:45.200]   What do you think, Jeff?
[01:08:45.200 --> 01:08:46.560]   Well, I agree.
[01:08:46.560 --> 01:08:50.520]   And we've talked about this back when this case happened
[01:08:50.520 --> 01:08:51.840]   in the US and Europe.
[01:08:51.840 --> 01:08:57.000]   This is stuff that is broadcast on public and open airwaves.
[01:08:57.000 --> 01:08:57.440]   You're right.
[01:08:57.440 --> 01:09:01.480]   It was stupid and rude and unnecessary for Google to take it.
[01:09:01.480 --> 01:09:04.560]   But it's also been the case in technopanic land
[01:09:04.560 --> 01:09:07.360]   that people have argued that Google has some great conspiracy
[01:09:07.360 --> 01:09:07.760]   to do this.
[01:09:07.760 --> 01:09:12.560]   And just the absurdity of that, the odds
[01:09:12.560 --> 01:09:16.960]   that something of value is going to be caught on the day
[01:09:16.960 --> 01:09:19.720]   when the car happens to drive by in three minutes
[01:09:19.720 --> 01:09:20.920]   and catch us something.
[01:09:20.920 --> 01:09:23.680]   And the idea that Google had any business model for doing
[01:09:23.680 --> 01:09:26.240]   anything with this data is absurd.
[01:09:26.240 --> 01:09:28.040]   Also, people were ignorant about the fact
[01:09:28.040 --> 01:09:29.840]   that there are other companies besides Google
[01:09:29.840 --> 01:09:33.000]   that capture Wi-Fi router addresses
[01:09:33.000 --> 01:09:36.520]   so that they can be used in geolocation software
[01:09:36.520 --> 01:09:37.880]   that we all depend upon.
[01:09:37.880 --> 01:09:38.920]   And that's all OK.
[01:09:38.920 --> 01:09:40.200]   And nobody talks about that.
[01:09:40.200 --> 01:09:41.440]   And it's not a big deal.
[01:09:41.440 --> 01:09:43.760]   The problem here was that Google took too much data.
[01:09:43.760 --> 01:09:46.560]   That data was absolutely useless.
[01:09:46.560 --> 01:09:48.080]   They were stupid to take it.
[01:09:48.080 --> 01:09:51.200]   It caused them a huge PR hell and now legal hell.
[01:09:51.200 --> 01:09:56.720]   But there was no possibility of a business conspiracy behind it.
[01:09:56.720 --> 01:10:00.440]   And it's once again a case of an ignorant court
[01:10:00.440 --> 01:10:04.240]   or set of courts that don't know enough about the technology
[01:10:04.240 --> 01:10:06.400]   to understand how to rule to the principle.
[01:10:06.400 --> 01:10:10.520]   They've had an impact on the definition of public now.
[01:10:10.520 --> 01:10:13.480]   And just as the cases against Google Street View
[01:10:13.480 --> 01:10:15.480]   in some countries, especially in Europe,
[01:10:15.480 --> 01:10:18.400]   have an impact on the notion of what's public,
[01:10:18.400 --> 01:10:21.880]   that's going to have, I think, a precedent that
[01:10:21.880 --> 01:10:23.840]   could be harmful in other cases.
[01:10:23.840 --> 01:10:26.400]   Gina, do you have a view on this?
[01:10:26.400 --> 01:10:29.000]   Do you have an opinion one way or the other?
[01:10:29.000 --> 01:10:30.960]   I agree with you guys.
[01:10:30.960 --> 01:10:33.520]   I mean, Google, obviously, it was a bug in the software
[01:10:33.520 --> 01:10:38.640]   that prevented the software from discarding that data.
[01:10:38.640 --> 01:10:40.520]   I mean, they were just collecting the hot--
[01:10:40.520 --> 01:10:42.240]   that they were supposed to be just collecting the access
[01:10:42.240 --> 01:10:45.120]   point information, not the data that was
[01:10:45.120 --> 01:10:47.880]   passing to and from it.
[01:10:47.880 --> 01:10:50.280]   And look, it was a bug in the software
[01:10:50.280 --> 01:10:51.880]   that they collected the data.
[01:10:51.880 --> 01:10:54.040]   I think that they did it by mistake.
[01:10:54.040 --> 01:10:56.240]   That's what they said.
[01:10:56.240 --> 01:10:59.000]   And look, this is the reason why Google blurs out
[01:10:59.000 --> 01:11:00.840]   faces in Street View pictures, right?
[01:11:00.840 --> 01:11:04.560]   And why we were a DAC personal information from public documents.
[01:11:04.560 --> 01:11:06.200]   They should have discarded it.
[01:11:06.200 --> 01:11:06.640]   They didn't.
[01:11:06.640 --> 01:11:08.360]   They made a mistake.
[01:11:08.360 --> 01:11:10.280]   The law that they purportedly broke
[01:11:10.280 --> 01:11:13.640]   was the Federal Wiretap law, right?
[01:11:13.640 --> 01:11:15.120]   Yeah, which is absurd.
[01:11:15.120 --> 01:11:18.720]   Yeah, the Wiretap Act, which I think
[01:11:18.720 --> 01:11:22.280]   that indicates sort of a misunderstanding of technology
[01:11:22.280 --> 01:11:24.520]   as these cases as there is-- so often
[01:11:24.520 --> 01:11:25.960]   is in these kinds of cases.
[01:11:25.960 --> 01:11:30.000]   So I mean, look, this is the case
[01:11:30.000 --> 01:11:33.080]   that means that the FCC is going to be babysitting Google
[01:11:33.080 --> 01:11:34.440]   for the next 20 years, right?
[01:11:34.440 --> 01:11:37.280]   Aren't they doing privacy audits Google for the next 20
[01:11:37.280 --> 01:11:38.760]   years because of this?
[01:11:38.760 --> 01:11:42.880]   Look, I don't think that that's necessarily a bad thing.
[01:11:42.880 --> 01:11:45.120]   And I know, Jeff, I'm sorry.
[01:11:45.120 --> 01:11:50.520]   I think it's good that Google's aware that buggy software
[01:11:50.520 --> 01:11:53.080]   or something they're doing in interest of their business
[01:11:53.080 --> 01:11:57.400]   could have these kinds of effects.
[01:11:57.400 --> 01:11:59.720]   But yeah, this seems like a bummer ruling.
[01:11:59.720 --> 01:12:03.800]   And I think that they should have heard the appeal.
[01:12:03.800 --> 01:12:05.320]   Yeah, I agree.
[01:12:05.320 --> 01:12:09.600]   Well, why don't we do our picks and tips and number of the week?
[01:12:09.600 --> 01:12:11.080]   Who normally goes first on this show?
[01:12:11.080 --> 01:12:13.240]   Is it Leo or Gina, do you go first?
[01:12:13.240 --> 01:12:13.880]   Gina.
[01:12:13.880 --> 01:12:14.680]   All right, Gina.
[01:12:14.680 --> 01:12:15.680]   I usually go first.
[01:12:15.680 --> 01:12:18.920]   All these ladies first.
[01:12:18.920 --> 01:12:22.560]   So this tip comes from the Google operating system blog,
[01:12:22.560 --> 01:12:25.280]   great blog covering Google, particularly around products.
[01:12:25.280 --> 01:12:28.200]   And it's just a little tip.
[01:12:28.200 --> 01:12:32.120]   The new Google Maps came out quite some time ago.
[01:12:32.120 --> 01:12:34.960]   But if you haven't thought about the old Google Maps
[01:12:34.960 --> 01:12:36.240]   or if you missed the old Google Maps,
[01:12:36.240 --> 01:12:38.040]   there's a little short URL, a secret URL
[01:12:38.040 --> 01:12:40.880]   that can take you to the old classic Google Maps.
[01:12:40.880 --> 01:12:44.920]   And that is google.com/local.
[01:12:44.920 --> 01:12:46.640]   I got to tell you, I haven't looked at the old Google Maps
[01:12:46.640 --> 01:12:48.120]   in a really, really long time.
[01:12:48.120 --> 01:12:50.640]   It went to this URL today just to kind of check it out.
[01:12:50.640 --> 01:12:52.840]   And it felt like I was just seeing an old friend.
[01:12:52.840 --> 01:12:56.160]   I was like, oh, yes, this.
[01:12:56.160 --> 01:12:58.760]   I think there are a few things that the new Google Maps does.
[01:12:58.760 --> 01:13:00.960]   It tries to be a little too smart, a little too predictive
[01:13:00.960 --> 01:13:02.240]   for me.
[01:13:02.240 --> 01:13:04.400]   Sometimes I'm fumbling around, trying to figure out
[01:13:04.400 --> 01:13:06.080]   how to get to one view or the other.
[01:13:06.080 --> 01:13:08.160]   So it was kind of cool to see the old Google Maps.
[01:13:08.160 --> 01:13:10.040]   This URL might not work for very long.
[01:13:10.040 --> 01:13:12.000]   I'm sure they're going to phase out the old maps,
[01:13:12.000 --> 01:13:14.200]   the classic maps soon.
[01:13:14.200 --> 01:13:16.160]   But if you haven't looked at the old maps
[01:13:16.160 --> 01:13:17.560]   after using the new map for a while,
[01:13:17.560 --> 01:13:21.560]   go to google.com/local and you can enjoy a little bit
[01:13:21.560 --> 01:13:22.560]   of nostalgia.
[01:13:22.560 --> 01:13:25.120]   Gina, I am totally using this as my default view
[01:13:25.120 --> 01:13:26.520]   for Google Maps for as long as I can.
[01:13:26.520 --> 01:13:27.440]   And here's why.
[01:13:27.440 --> 01:13:32.120]   I hate the new maps because the card on the upper left-hand
[01:13:32.120 --> 01:13:33.520]   corner always covers.
[01:13:33.520 --> 01:13:34.560]   And I try to get rid of it.
[01:13:34.560 --> 01:13:35.680]   And I kind of lose control.
[01:13:35.680 --> 01:13:36.520]   And it's frustrating.
[01:13:36.520 --> 01:13:37.400]   I like the old ones.
[01:13:37.400 --> 01:13:38.520]   Same here.
[01:13:38.520 --> 01:13:39.280]   Yes.
[01:13:39.280 --> 01:13:40.720]   So thank you for that tip.
[01:13:40.720 --> 01:13:44.240]   I'm absolutely going to make this my default Google Maps
[01:13:44.240 --> 01:13:44.760]   view.
[01:13:44.760 --> 01:13:46.640]   So Jeff, what do you have number-wise?
[01:13:46.640 --> 01:13:47.520]   Let's mention two things.
[01:13:47.520 --> 01:13:48.880]   Well, one I want to mention this just quickly,
[01:13:48.880 --> 01:13:50.480]   that Google is offering free lessons
[01:13:50.480 --> 01:13:52.840]   encoding in 2000s of women and minorities.
[01:13:52.840 --> 01:13:55.480]   And it couldn't happen soon enough.
[01:13:55.480 --> 01:13:57.200]   Not only have Google and Facebook and other companies
[01:13:57.200 --> 01:14:01.160]   revealed their less than stellar diversity numbers,
[01:14:01.160 --> 01:14:05.800]   but also just culturally we're seeing just a rat-attatt
[01:14:05.800 --> 01:14:10.120]   of cases of women being treated badly in technology companies.
[01:14:10.120 --> 01:14:12.760]   And the only solution to that is to have more people doing it.
[01:14:12.760 --> 01:14:14.400]   I want to plug one of my students,
[01:14:14.400 --> 01:14:18.760]   Autuberneer, or my graduates, has a business called Skill Crush
[01:14:18.760 --> 01:14:20.400]   that is aimed at teaching women how to code.
[01:14:20.400 --> 01:14:22.320]   And the more we have, the better.
[01:14:22.320 --> 01:14:23.360]   Right, Gina?
[01:14:23.360 --> 01:14:23.920]   Absolutely.
[01:14:23.920 --> 01:14:25.560]   Love Skill Crush.
[01:14:25.560 --> 01:14:27.160]   But the number I wanted to do for this week
[01:14:27.160 --> 01:14:28.960]   was that Google--
[01:14:28.960 --> 01:14:32.280]   so far, the Google Cloud platform is eight for eight
[01:14:32.280 --> 01:14:33.800]   in World Cup predictions.
[01:14:33.800 --> 01:14:38.520]   So who needs to watch the World Cup when you have Google?
[01:14:38.520 --> 01:14:39.080]   Exactly.
[01:14:39.080 --> 01:14:42.520]   That's my point exactly.
[01:14:42.520 --> 01:14:46.160]   Oh, man, I've been trash-talking soccer in general
[01:14:46.160 --> 01:14:47.680]   for this whole period of time.
[01:14:47.680 --> 01:14:48.520]   Zero is zero.
[01:14:48.520 --> 01:14:49.520]   It's not a good idea.
[01:14:49.520 --> 01:14:50.520]   It's a low-income guy.
[01:14:50.520 --> 01:14:51.520]   Zero is zero.
[01:14:51.520 --> 01:14:52.320]   Oh, gosh.
[01:14:52.320 --> 01:14:54.960]   It's so funny when I was in Frankfurt the other night
[01:14:54.960 --> 01:14:55.680]   coming back here.
[01:14:55.680 --> 01:14:58.200]   And it was before the Germans were going on.
[01:14:58.200 --> 01:15:00.440]   And so people were out at restaurants on the streets,
[01:15:00.440 --> 01:15:02.200]   just like TV's were everywhere.
[01:15:02.200 --> 01:15:04.200]   The funny thing was to listen.
[01:15:04.200 --> 01:15:06.720]   Soccer sounds like such a painful sport,
[01:15:06.720 --> 01:15:08.760]   because it's constantly all you hear from the distances.
[01:15:08.760 --> 01:15:09.760]   Oh!
[01:15:09.760 --> 01:15:10.760]   Oh!
[01:15:10.760 --> 01:15:11.760]   Oh!
[01:15:11.760 --> 01:15:12.760]   Oh!
[01:15:12.760 --> 01:15:13.760]   Oh!
[01:15:13.760 --> 01:15:15.760]   For three hours and nothing happens.
[01:15:15.760 --> 01:15:16.760]   Yeah.
[01:15:16.760 --> 01:15:17.760]   Yeah.
[01:15:17.760 --> 01:15:19.720]   Jason and I yesterday were doing, before you
[01:15:19.720 --> 01:15:24.120]   buy during the Belgium USA game.
[01:15:24.120 --> 01:15:27.240]   And we hear there's enormous cheers coming out
[01:15:27.240 --> 01:15:28.360]   of the break room.
[01:15:28.360 --> 01:15:30.960]   And we thought, oh, the US must have scored.
[01:15:30.960 --> 01:15:34.440]   No, the US kind of sort of almost scored.
[01:15:34.440 --> 01:15:35.440]   [LAUGHTER]
[01:15:35.440 --> 01:15:38.000]   And that was like super exciting, apparently,
[01:15:38.000 --> 01:15:42.080]   that the ball got within the general proximity of the goal.
[01:15:42.080 --> 01:15:42.960]   Yeah, it's awful.
[01:15:42.960 --> 01:15:44.160]   I just can't do it.
[01:15:44.160 --> 01:15:45.960]   You know, I'm not a sports guy anyway.
[01:15:45.960 --> 01:15:47.680]   Oh, we got to get flamed.
[01:15:47.680 --> 01:15:49.320]   Yeah.
[01:15:49.320 --> 01:15:51.080]   And boy, I hear it on Google+.
[01:15:51.080 --> 01:15:53.120]   I have so many friends all over the world.
[01:15:53.120 --> 01:15:55.960]   And we have these big arguments about whether it's
[01:15:55.960 --> 01:15:57.200]   called football or soccer.
[01:15:57.200 --> 01:16:00.120]   And we had a big, pissing contest yesterday
[01:16:00.120 --> 01:16:03.800]   about how many English speakers, native English speakers,
[01:16:03.800 --> 01:16:06.600]   or people who speak English fluently as a second language,
[01:16:06.600 --> 01:16:08.480]   use soccer versus football.
[01:16:08.480 --> 01:16:11.800]   And it was very an interesting conversation,
[01:16:11.800 --> 01:16:13.000]   but it always comes up.
[01:16:13.000 --> 01:16:16.440]   And then these conversations about what's better,
[01:16:16.440 --> 01:16:19.160]   you know, American football or international football,
[01:16:19.160 --> 01:16:22.440]   always end what the Australian saying, yeah, you know what?
[01:16:22.440 --> 01:16:23.440]   Rugby.
[01:16:23.440 --> 01:16:25.880]   That's the best sport in the world.
[01:16:25.880 --> 01:16:26.880]   Always.
[01:16:26.880 --> 01:16:29.240]   Well, I got the important sports news of the day is Federer 1.
[01:16:29.240 --> 01:16:31.120]   Yeah, there you go.
[01:16:31.120 --> 01:16:33.960]   All right, so let's do my tool.
[01:16:33.960 --> 01:16:37.240]   There is a Kickstarter project that I would love for everyone
[01:16:37.240 --> 01:16:40.720]   to back so that I can buy it called PELTY.
[01:16:40.720 --> 01:16:45.920]   PELTY is a speaker that is powered not by plugging it in.
[01:16:45.920 --> 01:16:47.280]   It's not powered by batteries.
[01:16:47.280 --> 01:16:49.320]   It's powered by a single candle.
[01:16:49.320 --> 01:16:52.040]   And one candle will play in its Bluetooth,
[01:16:52.040 --> 01:16:52.760]   so it's wireless.
[01:16:52.760 --> 01:16:53.840]   There are no wires visible.
[01:16:53.840 --> 01:16:56.040]   There's no nothing visible.
[01:16:56.040 --> 01:16:58.720]   And it'll play for eight hours with one little votive
[01:16:58.720 --> 01:17:00.400]   like candle.
[01:17:00.400 --> 01:17:02.200]   This is great for the coming apocalypse,
[01:17:02.200 --> 01:17:04.440]   the end of the world where there's no electricity.
[01:17:04.440 --> 01:17:09.200]   And all you need is shotgun, a machete, and one of these.
[01:17:09.200 --> 01:17:12.960]   And you should be fine in the post-apocalyptic--
[01:17:12.960 --> 01:17:14.440]   Mike, has anyone told you really lately
[01:17:14.440 --> 01:17:16.400]   that you have too much disposable income?
[01:17:16.400 --> 01:17:19.760]   [LAUGHTER]
[01:17:19.760 --> 01:17:20.520]   Maybe.
[01:17:20.520 --> 01:17:22.920]   But this is kind of cool.
[01:17:22.920 --> 01:17:25.400]   Not only does it play nice music,
[01:17:25.400 --> 01:17:29.840]   but it also creates a kind of ambiance.
[01:17:29.840 --> 01:17:30.680]   Date night.
[01:17:30.680 --> 01:17:31.880]   Yeah, there you go.
[01:17:31.880 --> 01:17:33.280]   And look, there's the hook right there.
[01:17:33.280 --> 01:17:34.880]   That's an Android phone.
[01:17:34.880 --> 01:17:35.960]   Of course, you're going to get confused.
[01:17:35.960 --> 01:17:37.360]   You're going to start burning your phone
[01:17:37.360 --> 01:17:39.160]   by putting a candle underneath it.
[01:17:39.160 --> 01:17:39.640]   That's right.
[01:17:39.640 --> 01:17:40.520]   That's right.
[01:17:40.520 --> 01:17:42.880]   Well, you know, and if I do that,
[01:17:42.880 --> 01:17:44.960]   I'll have to get a new phone, which would be fine anyway.
[01:17:44.960 --> 01:17:48.320]   You know, like you said, too much disposable income.
[01:17:48.320 --> 01:17:52.240]   Well, that concludes this edition of This Week in Google.
[01:17:52.240 --> 01:17:53.600]   I want to thank you, Jeff and Gina.
[01:17:53.600 --> 01:17:56.040]   I want to thank all of you for tuning in today.
[01:17:56.040 --> 01:17:56.840]   Good job, Mike.
[01:17:56.840 --> 01:17:57.480]   Thank you so much.
[01:17:57.480 --> 01:17:58.440]   Yes, Mike.
[01:17:58.440 --> 01:18:00.640]   Boy, Leo makes this look easy.
[01:18:00.640 --> 01:18:01.640]   And it does not.
[01:18:01.640 --> 01:18:03.000]   Makes it look so easy.
[01:18:03.000 --> 01:18:03.480]   What?
[01:18:03.480 --> 01:18:04.840]   Are you saying we're difficult to deal with?
[01:18:04.840 --> 01:18:05.960]   Is that what you're saying here, Algab?
[01:18:05.960 --> 01:18:07.000]   Yes, I am.
[01:18:07.000 --> 01:18:07.560]   No, I'm not.
[01:18:07.560 --> 01:18:08.480]   You guys are wonderful.
[01:18:08.480 --> 01:18:09.400]   I love the show.
[01:18:09.400 --> 01:18:13.400]   I'm the biggest fan of the show and always have been for a long time.
[01:18:13.400 --> 01:18:15.320]   And I always love to either be on the show
[01:18:15.320 --> 01:18:18.120]   as I've done once or twice before and hosting it is absolutely
[01:18:18.120 --> 01:18:19.960]   fantastic because I get to talk back.
[01:18:19.960 --> 01:18:21.560]   I get to engage with you guys.
[01:18:21.560 --> 01:18:23.760]   But I never miss a single word of the show.
[01:18:23.760 --> 01:18:24.760]   I absolutely love it.
[01:18:24.760 --> 01:18:27.920]   Jeff Jarvis is Professor of Journalism, the University
[01:18:27.920 --> 01:18:30.280]   of New York and author of Public Parts.
[01:18:30.280 --> 01:18:30.920]   What will Google do?
[01:18:30.920 --> 01:18:35.000]   And Gutenberg, the geeky blogs at Buzzmachine.com.
[01:18:35.000 --> 01:18:36.720]   Thank you so much, Jeff Jarvis.
[01:18:36.720 --> 01:18:40.000]   And Gina Trappani is creator of ThinkUp.com,
[01:18:40.000 --> 01:18:43.640]   host of tweets all about Android with the lovely and talented
[01:18:43.640 --> 01:18:45.120]   Jason Howell as well.
[01:18:45.120 --> 01:18:46.760]   Founding editor of Life Hacker.
[01:18:46.760 --> 01:18:48.440]   Thank you so much, Gina.
[01:18:48.440 --> 01:18:49.440]   Trappani, we do this.
[01:18:49.440 --> 01:18:49.960]   Thank you.
[01:18:49.960 --> 01:18:52.760]   We do this week in Google every Wednesday at 1 PM Pacific,
[01:18:52.760 --> 01:18:53.560]   4 PM Eastern.
[01:18:53.560 --> 01:18:54.800]   That's 2,000 UTC.
[01:18:54.800 --> 01:18:58.560]   You can watch the show live at live.twit.tv.
[01:18:58.560 --> 01:19:02.520]   Or you can subscribe to the show at twit.tv/twig.
[01:19:02.520 --> 01:19:04.800]   There are many, many subscription options available.
[01:19:04.800 --> 01:19:05.840]   Thank you for joining us today.
[01:19:05.840 --> 01:19:08.800]   Leo and the gang will see you next time on Twig.
[01:19:08.800 --> 01:19:11.640]   [MUSIC PLAYING]
[01:19:11.640 --> 01:19:15.000]   [MUSIC PLAYING]
[01:19:15.000 --> 01:19:18.360]   [MUSIC PLAYING]
[01:19:18.360 --> 01:19:20.780]   (soft music)

