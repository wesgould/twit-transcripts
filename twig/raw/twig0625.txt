;FFMETADATA1
title=You Can't Handle the Waffle!
artist=Leo Laporte, Jeff Jarvis, Stacey Higginbotham, Ant Pruitt
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2021-08-19
track=625
language=English
genre=Podcast
comment=T-Mobile hack, robots write code, YikYak is back, Matter delayed
encoded_by=Uniblab 5.3
date=2021
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.160]   It's time for Twig this week at Google Jeff Stacey and they're all here
[00:00:04.160 --> 00:00:11.560]   We're gonna talk about the big team mobile hack and what you can do about it. We'll watch a robot write code
[00:00:11.560 --> 00:00:21.500]   And then we'll debate whether disinformation is the fault of social media or just a side effect plus the history of retail
[00:00:21.500 --> 00:00:26.000]   It's just changed dramatically. It's all coming up next on Twig
[00:00:29.080 --> 00:00:31.920]   Podcasts you love from people you trust
[00:00:31.920 --> 00:00:34.760]   This is twig
[00:00:34.760 --> 00:00:46.480]   This is twig this week in Google episode 625 recorded Wednesday August 18th
[00:00:46.480 --> 00:00:49.800]   2021 you can't handle the waffle
[00:00:49.800 --> 00:00:56.400]   This week in Google is brought to you by modern finance our NFTs here for the long haul
[00:00:56.520 --> 00:01:01.080]   Which cryptocurrency is a fad? How does decentralized finance work?
[00:01:01.080 --> 00:01:07.760]   Modern finance podcast hosted by Kevin Rose looks to answer these questions and many more about the investment marketplace
[00:01:07.760 --> 00:01:15.320]   Download and subscribe to modern finance wherever you listen to podcasts and get ahead of the future of finance
[00:01:15.320 --> 00:01:22.220]   It's time for Twig this week in Google the show where you cover the latest news from the Google verse
[00:01:22.220 --> 00:01:26.160]   Stacey Higginbotham is here Stacey on IOT.com
[00:01:26.800 --> 00:01:32.960]   And in the IOT podcast featuring Kevin Tofo. Oh, I love your infinity scarf. That's quite attractive
[00:01:32.960 --> 00:01:39.440]   It's an autumn. Thank you. Yes, it's cold. It was cold here today. It's less cold now. Yeah
[00:01:39.440 --> 00:01:43.480]   We were thinking a move in a hat island. It's right next door to you
[00:01:43.480 --> 00:01:47.240]   This big do you know?
[00:01:49.400 --> 00:01:56.240]   I do not know hat island. It's a little teeny tiny island just off the coast of Bainbridge called Hat Island
[00:01:56.240 --> 00:02:00.380]   Actually, it's really off the coast of would be it's in Puget Sound though
[00:02:00.380 --> 00:02:07.360]   Okay, yeah, are you gonna have a boat cuz I need a friend with a boat. Oh, yes, we would it's it's a tiny little island
[00:02:07.360 --> 00:02:13.960]   But I just you know you have to have a boat if you live there. I think that's the only way and get groceries
[00:02:15.960 --> 00:02:20.280]   Right before we leave Stacey, I think we have to say hello to cousin cousin Ray
[00:02:20.280 --> 00:02:24.320]   Cousin Ray, oh, okay. You all need to say hello to cousin
[00:02:24.320 --> 00:02:32.080]   We got one buddy Ray Boley a
[00:02:32.080 --> 00:02:41.080]   All right, that's Jeff Jarvis ladies gentlemen, he's the Leonard cousin Ray's best friend cousin Ray's best friend Leonard
[00:02:41.080 --> 00:02:43.360]   Tap professor for journalist at innovation at the
[00:02:43.360 --> 00:02:51.000]   Graduate School of Journalism at the City University
[00:02:51.000 --> 00:02:57.040]   I talked to Craig about coming on and joining us for the chorus. Oh, that would be great if he just popped in yeah
[00:02:57.040 --> 00:03:02.640]   We can even we can even make like a little Craig Newmark pop up that we just pop up
[00:03:02.640 --> 00:03:05.920]   My god that would be a tour of the hysterical. Yeah
[00:03:05.920 --> 00:03:10.920]   Oh and that that mellow mellif Lewis mellow base
[00:03:11.560 --> 00:03:14.280]   Baso prophono turtle turtle is aunt
[00:03:14.280 --> 00:03:18.640]   Pruitt of TVs hands on photography
[00:03:18.640 --> 00:03:23.480]   Hello, aunt hello, sir. That was some pretty awesome alliteration
[00:03:23.480 --> 00:03:28.360]   We we're really pleased to announce that aunt is now
[00:03:28.360 --> 00:03:32.520]   officially the community manager for the club he's
[00:03:32.520 --> 00:03:35.720]   Loved by our club twit members
[00:03:35.720 --> 00:03:42.440]   We thought it'd be great if we needed somebody to take point on this and it is kindly agreed to do so so
[00:03:42.440 --> 00:03:48.640]   Thank you is indeed beloved. Yes, thank you. That was my pleasure and I appreciate the opportunity. Oh, yeah
[00:03:48.640 --> 00:03:51.840]   We love we love both and club twit
[00:03:51.840 --> 00:03:57.680]   So you might want to talk about the offer and the opportunity that is the club right now. That's a good idea
[00:03:57.680 --> 00:04:00.240]   $7 Jeff's worried about his paycheck
[00:04:03.240 --> 00:04:08.000]   $1 a month gets you ad-free versions of all of our shows audio and video a
[00:04:08.000 --> 00:04:12.720]   Special feed just for you the twit plus feed which has things like that fun bit
[00:04:12.720 --> 00:04:17.720]   we did before the show that you didn't hear because well unless you were here by chance
[00:04:17.720 --> 00:04:23.280]   But it'll be in the twit plus feed and then of course there's that great discord and we love our our discord
[00:04:23.280 --> 00:04:27.720]   Fans and it's a great place to have conversations not just about the shows
[00:04:27.720 --> 00:04:30.480]   But right now
[00:04:30.960 --> 00:04:34.240]   Hedge 36 says oh ants management now
[00:04:34.240 --> 00:04:48.560]   Because if anyone's throwing a party you want to go to the parties that the cool people are throwing and is that person?
[00:04:48.560 --> 00:04:52.480]   Yeah, you won't let anybody get out of hand. Yeah, that's true. Yeah
[00:04:52.480 --> 00:05:00.040]   People might have collar. Yeah, no, so we're really thank you for agreeing to do that, and we really appreciate it
[00:05:00.040 --> 00:05:03.080]   It's gonna I think it's gonna be a lot more fun with that
[00:05:03.080 --> 00:05:06.320]   He's gonna you're gonna plan some events and we're gonna do some fun things and so forth
[00:05:06.320 --> 00:05:09.560]   Maybe we'll get credit and do a mark in there. Hope so yep
[00:05:09.560 --> 00:05:17.000]   So bad news for you team mobile folks. We we were hoping it was just a bad dream, but no team mobile now admits
[00:05:17.000 --> 00:05:21.560]   that the motherboards vice investigation was accurate and
[00:05:21.560 --> 00:05:26.520]   their data as their data has been hacked now
[00:05:27.360 --> 00:05:32.640]   Motherboard says it's a hundred million users team. Mobile's only admitted to 40 million so far
[00:05:32.640 --> 00:05:38.520]   This is information is upsetting that they got away with oh
[00:05:38.520 --> 00:05:41.240]   Yeah, you want to hear what they got?
[00:05:41.240 --> 00:05:42.680]   It's
[00:05:42.680 --> 00:05:45.280]   Essentially it sounds like it's the
[00:05:45.280 --> 00:05:50.400]   You know when you get a smartphone these days they do a credit check on you so you have to provide
[00:05:50.400 --> 00:05:54.240]   Information for the credit check including social data birth things like that
[00:05:54.680 --> 00:05:59.880]   It's that even if you didn't sign up for a T-Mobile account, but you got the credit check done
[00:05:59.880 --> 00:06:04.480]   It's in that database so even non T-Mobile customers
[00:06:04.480 --> 00:06:11.200]   You may be bit if you've ever tried to get a T-Mobile account social security numbers phone numbers names physical addresses
[00:06:11.200 --> 00:06:15.000]   Unique IMEI numbers for your phone drivers license information
[00:06:15.000 --> 00:06:22.400]   Motherboards has said they've seen samples of the data and they did in fact contain accurate information a hacker selling a
[00:06:23.520 --> 00:06:24.800]   small
[00:06:24.800 --> 00:06:30.240]   Tranche of this 30 million of these for six bitcoin two hundred seventy thousand dollars
[00:06:30.240 --> 00:06:37.280]   He says he has one hundred million from you know and this happens a lot a database left open T-Mobile
[00:06:37.280 --> 00:06:41.680]   Initially reacted last week saying we're investigating now. They say
[00:06:41.680 --> 00:06:43.520]   Yeah
[00:06:43.520 --> 00:06:49.760]   7.8 million current users had information stolen along with 40 million records from past or perspective
[00:06:50.080 --> 00:06:56.640]   Customers who'd applied for credit is it possible the T-Mobile didn't know this and motherboard revealed it
[00:06:56.640 --> 00:07:00.880]   Or the T-Mobile knew it and didn't say it and is thus filing I think some laws
[00:07:00.880 --> 00:07:07.480]   Yeah, certainly GDPR has a and I think California also has a breach of a loss that you have
[00:07:07.480 --> 00:07:12.200]   Day you have a certain amount of time. I don't know how long team is pretty quick. Okay. Yeah
[00:07:12.200 --> 00:07:15.640]   Yeah, well, we don't know we don't know
[00:07:15.640 --> 00:07:20.160]   You know how when did they know and how did when they know it and what do they know and all that but
[00:07:20.160 --> 00:07:27.080]   They say T-Mobile says the hack doesn't appear to have included credit card details of other financial information
[00:07:27.080 --> 00:07:30.480]   That is in contradiction of what vice says
[00:07:30.480 --> 00:07:34.680]   hackers
[00:07:34.680 --> 00:07:40.160]   Are selling it which means so T-Mobile Scott, but hey the good news is T-Mobile
[00:07:41.800 --> 00:07:45.880]   Offering all of you two years of identity protection surfaces
[00:07:45.880 --> 00:07:49.920]   And they're changing the pin numbers on your accounts
[00:07:49.920 --> 00:07:56.040]   So T-Mobile has started sending out text messages to customers. Sorry your house got burned down, but here's a bucket
[00:07:56.040 --> 00:07:59.400]   Yeah, here's a bucket in case you need it better bring the bucket
[00:07:59.400 --> 00:08:02.600]   That's just that's just awful
[00:08:02.600 --> 00:08:07.880]   But it's just continually happening, you know, you can almost assume it's gonna happen. Yeah
[00:08:07.880 --> 00:08:14.560]   I don't know if you want to talk about this, but this ties to it's not in here, but I did write something last week about
[00:08:14.560 --> 00:08:19.160]   Regulations I would like us to have for I called it the era of IOT
[00:08:19.160 --> 00:08:27.920]   But this particular story hits on at least three of the things that I think we need seven principles for regulation of the IOT in the IOT
[00:08:27.920 --> 00:08:32.040]   Era scroll down. You'll get there
[00:08:32.040 --> 00:08:35.280]   So one is for this one
[00:08:35.280 --> 00:08:38.360]   It would be in some of them we've talked about like number two we did a whole show on
[00:08:38.360 --> 00:08:47.640]   But if you scroll down, I think - number two is rethink the fourth amendment for the digital era somebody pointed out and I take this correction like
[00:08:47.640 --> 00:08:55.800]   You know that I was conflating the government the fourth amendment limits governments unreasonable search and seizure, but I have to say
[00:08:55.800 --> 00:09:02.520]   That's the presumption is government has that power and ability to do that if somebody else does it that's just against the law
[00:09:04.320 --> 00:09:10.320]   No non-government will no law enforcement agency has the right to search your house or your phone well in the
[00:09:10.320 --> 00:09:17.240]   The government is actually going through private entities to get access to this data. That's true. This very
[00:09:17.240 --> 00:09:24.280]   But the T mobile thing I was thinking fits with three which I think we need way
[00:09:24.280 --> 00:09:29.680]   Way more like way higher penalties for things like I even say this
[00:09:30.080 --> 00:09:36.920]   Leaving unencrypted personal data and unlock cloud instances. Yes, they're negligent and they should be paying a price for that. Yes
[00:09:36.920 --> 00:09:41.160]   And then yeah, and then also letting people
[00:09:41.160 --> 00:09:44.600]   Yeah, we'll go with that anyway
[00:09:44.600 --> 00:09:49.700]   I just wanted to put that out there because I really I'm getting very frustrated with this idea that most of us were like
[00:09:49.700 --> 00:09:56.760]   Ho hum it happened again. So now it's the seventh my seventh principle is rethink our current forms of identity and create different layers
[00:09:57.240 --> 00:10:01.280]   Important social security numbers a bad way to identify people
[00:10:01.280 --> 00:10:03.720]   It should be used that way
[00:10:03.720 --> 00:10:06.520]   So we need a layer we need a couple layers
[00:10:06.520 --> 00:10:10.560]   We need like my stupid New York Times password that who cares if it gets out, right?
[00:10:10.560 --> 00:10:15.040]   We need things like for pretty secure things that are tied to our financial data
[00:10:15.040 --> 00:10:21.480]   But could still be easily changed and then we need like an inviolate thing that no one sees except for maybe the government
[00:10:21.480 --> 00:10:23.080]   repair taxes
[00:10:23.080 --> 00:10:28.000]   Yeah, mr. Serbs. That's it a little bit today on floss weekly
[00:10:28.000 --> 00:10:30.880]   Maybe was at the end of floss weekly today
[00:10:30.880 --> 00:10:39.000]   Sovereign identity and the guest was was saying okay when we go to a bar and they want to make sure that we're
[00:10:39.000 --> 00:10:44.760]   You know of age to be able to drink alcohol people hand over the driver's license. It has to name
[00:10:44.760 --> 00:10:49.000]   Their street address their height sometimes their weight their date of birth
[00:10:49.520 --> 00:10:52.760]   When all they really need is a are you over 21 or not?
[00:10:52.760 --> 00:10:59.960]   Are you of ages? Yes? No, but we hand that information over and and Serbs was saying you know we need some type of sovereign
[00:10:59.960 --> 00:11:06.920]   Identity process that that will protect us as the consumer as well as you know
[00:11:06.920 --> 00:11:10.840]   Keep all this stuff out of the hands of big tech where breaches don't really matter
[00:11:10.840 --> 00:11:15.840]   Ironically, it's big tech that's proposing this kind of thing. They're all sorts of proposals use your phone
[00:11:16.880 --> 00:11:21.880]   Apple has something like this where they control the information when you use your Apple
[00:11:21.880 --> 00:11:27.000]   card that the merchant gets and they offer to use a
[00:11:27.000 --> 00:11:32.280]   Special email address so that you'll get email, but they won't know your email and I think you're right
[00:11:32.280 --> 00:11:33.720]   I think it should be I
[00:11:33.720 --> 00:11:38.800]   Don't know if you could tie it to the smartphone, but there should be this is what data years months ago
[00:11:38.800 --> 00:11:42.360]   Stacy was talking about your data blob. This is kind of like that
[00:11:42.360 --> 00:11:48.080]   This is the idea the phone could hold all this information and then there needs to be a system
[00:11:48.080 --> 00:11:53.200]   For saying in a trusted way. That's this is your birth date or you know
[00:11:53.200 --> 00:11:55.720]   Just the stuff they need and I think you could do that on the phone
[00:11:55.720 --> 00:12:04.000]   But the other piece of this that I've long wondered is if we presume that and amount of information is gonna get out
[00:12:04.000 --> 00:12:04.960]   No matter what
[00:12:04.960 --> 00:12:11.880]   Then what we need to do is is is also regulate the other end of this and that you can't do certain things with certain basics
[00:12:11.880 --> 00:12:13.880]   That's good information. Yeah
[00:12:13.880 --> 00:12:20.160]   And that there's more security required on that end so that if they know your mother's made name or if they know your address
[00:12:20.160 --> 00:12:24.960]   Or they know your social security number which they already do they are and nothing can be done with those things
[00:12:24.960 --> 00:12:29.280]   Well, there you know, there is a credit freeze
[00:12:29.280 --> 00:12:31.120]   and
[00:12:31.120 --> 00:12:36.560]   Thank goodness the Congress a couple of years ago passed a law saying companies cannot charge you
[00:12:37.160 --> 00:12:44.200]   for doing a credit freeze you can go to the big three credit reporting agencies trans union Equifax and
[00:12:44.200 --> 00:12:50.480]   I always forget the third one and
[00:12:50.480 --> 00:12:55.000]   Experian experience the one we don't like and
[00:12:55.000 --> 00:12:59.160]   10 points to answer team 10 points
[00:12:59.160 --> 00:13:05.320]   And there's credit freeze and credit lock you can investigate the two, but they shouldn't cost you any money
[00:13:06.080 --> 00:13:09.920]   It keeps people from using that information to get credit in your name
[00:13:09.920 --> 00:13:19.000]   It's a pain you know where it's a pain if you're younger and you're actively renting and buying houses and buying cars and getting credit
[00:13:19.000 --> 00:13:22.840]   But nowadays they don't they can't charge you to freeze and unfreeze so I
[00:13:22.840 --> 00:13:27.680]   Think a credit freeze is something worth looking at I honestly think you should probably freeze
[00:13:27.680 --> 00:13:33.520]   Your credit with all three reporting agencies. I we keep ours frozen all the time. Yeah
[00:13:34.080 --> 00:13:36.760]   It used to be you had to have a reason
[00:13:36.760 --> 00:13:42.280]   But now nowadays I don't you know just to write. Yes, it's a right
[00:13:42.280 --> 00:13:47.760]   Which we do to yeah, yeah, you do it you do it as well. I should probably do it
[00:13:47.760 --> 00:13:53.960]   Yeah, it's a good idea. It is that's the only thing is you have to unfreeze it if you want to apply for credit
[00:13:53.960 --> 00:13:55.960]   So if you're doing that a lot, it's not very convenient
[00:13:55.960 --> 00:14:02.240]   Yeah, well, we had to get our mortgage. It was kind of a pain. They all have these apps, but they're terrible and you're like
[00:14:02.640 --> 00:14:05.840]   Well, they don't want to make them bad at this. They don't want to make it easy
[00:14:05.840 --> 00:14:10.640]   No, I know but man, it just drives me bonkers. Yeah
[00:14:10.640 --> 00:14:19.880]   Remember Stacy before you apply for the mortgage. Did you remember you had to unfreeze it or did somebody call you from the bank and say
[00:14:19.880 --> 00:14:22.880]   Miss Higginbotham
[00:14:22.880 --> 00:14:24.880]   You have to do we're organized like that
[00:14:24.880 --> 00:14:30.560]   Oh
[00:14:30.560 --> 00:14:33.520]   Everything on lock but do you know
[00:14:33.520 --> 00:14:40.720]   Oh, no, I was gonna ask a question about the T-Mobile hack which is do we think this could be used for sim swapping attacks
[00:14:40.720 --> 00:14:44.160]   I was that where we think because I know that was a worry people. Oh, yeah
[00:14:44.160 --> 00:14:48.920]   Well T-Mobile is now going out proactively changing pins for everybody was affected
[00:14:48.920 --> 00:14:53.480]   That's exactly how if they got the pin apparently they did otherwise T-Mobile wouldn't be changing it
[00:14:53.480 --> 00:15:00.360]   You could pose I could pose a Stacy and they say okay. Hello. My name is Stacy Higginbotham
[00:15:00.360 --> 00:15:02.360]   And I need a new sim
[00:15:02.360 --> 00:15:05.960]   All right, you have hours of my voice you could do it better
[00:15:05.960 --> 00:15:09.720]   Stacy
[00:15:09.720 --> 00:15:12.680]   What's your pin and I go well and I know your pin
[00:15:12.680 --> 00:15:15.240]   Data-births. Yeah, I know that you know
[00:15:15.240 --> 00:15:18.720]   I mean last for the social I know that you know most cases
[00:15:18.720 --> 00:15:23.120]   That's enough of a hurdle to get to get that sim sent to a new address. So yes
[00:15:23.120 --> 00:15:29.840]   Yeah, it could absolutely but that you know also identity fraud of all kinds. So not good not good. Thank you T-Mobile
[00:15:30.840 --> 00:15:36.880]   Hey, you were mentioning carrying the phone as part of your identity, but what about the folks that are
[00:15:36.880 --> 00:15:40.000]   Well, that's the problem their phone
[00:15:40.000 --> 00:15:45.400]   That's that or don't want to have a smartphone which is still a significant percentage of the pop up
[00:15:45.400 --> 00:15:49.320]   They still have right to identification. Yeah, you know, then you need your blob
[00:15:49.320 --> 00:15:53.520]   You need to be given a lot. I feel like blockchain is it would be could be a solution for this
[00:15:53.520 --> 00:15:55.520]   But you need some sort of digital thing
[00:15:55.520 --> 00:16:03.160]   Maybe you carry a digital car. You could have like a key chain or like a little Bob. Yeah. Yeah, like key chain for the blockchain
[00:16:03.160 --> 00:16:10.240]   I mean wrapped in foil. You know, there's a portion of the population say under no circumstances
[00:16:10.240 --> 00:16:12.240]   I'm I gonna carry around any federal
[00:16:12.240 --> 00:16:19.320]   But that's the worst thing the federal government instead. We're just gonna inject it into your bloodstream with the vaccine
[00:16:19.320 --> 00:16:24.720]   Watch it now you're gonna get people fired up
[00:16:25.720 --> 00:16:27.720]   Oh those people stop listening
[00:16:27.720 --> 00:16:32.080]   Ants community manager voice did you hear that?
[00:16:32.080 --> 00:16:40.880]   Manager, you're absolutely right. Well, I suspect Ant has family back East maybe who feel that way, right?
[00:16:40.880 --> 00:16:48.160]   Yeah, I think we need a meme that Ant can put into discord. Wait a minute. You're gonna get people fired up
[00:16:48.160 --> 00:16:50.880]   meme, please
[00:16:50.880 --> 00:16:53.040]   Give them about 30 seconds. It'll be there. I know they will
[00:16:53.040 --> 00:17:02.320]   Okay, okay, so there you go. That's the T mobile. I'll let with that just because I gosh it seems like
[00:17:02.320 --> 00:17:09.680]   It's such a big deal not good news. It's not such such a bad. Do you want to let's run this open codecs
[00:17:09.680 --> 00:17:15.200]   Live demo. I put a time code in there. You can go into about 1340. Okay. Um
[00:17:15.200 --> 00:17:17.440]   so so
[00:17:17.440 --> 00:17:21.600]   You usually explain open codecs is good better than open AI codecs is better than I am
[00:17:21.600 --> 00:17:26.000]   But well, I'll just say so what this is is a demonstration of code writing code
[00:17:26.000 --> 00:17:28.880]   And you guys might look at this and say
[00:17:28.880 --> 00:17:34.720]   Stupid, but I looked at it and I was I was fairly amazed because it uses as a learning set
[00:17:34.720 --> 00:17:39.760]   One point in this all the api's out there and tons of code
[00:17:39.760 --> 00:17:44.400]   And so you tell it what you want it to do and then you watch it write the code to do that
[00:17:44.400 --> 00:17:46.960]   And I thought this reminds me a little bit of what github's doing
[00:17:46.960 --> 00:17:48.960]   Which is the github code code pilot?
[00:17:49.680 --> 00:17:54.800]   Program where you can ask it. Hey, I can't remember how to create a random number generator
[00:17:54.800 --> 00:17:59.760]   And it'll it'll paste the code in it's getting and it's actually been controversial because it's getting its code
[00:17:59.760 --> 00:18:04.800]   from some of those same places but also from public github projects and
[00:18:04.800 --> 00:18:08.800]   That's a little problematic reusing that stuff
[00:18:08.800 --> 00:18:12.960]   Uh, let's say a problem. This could also do things like somebody wrote that code
[00:18:12.960 --> 00:18:17.040]   Uh, it'll it'll write a seat public
[00:18:17.680 --> 00:18:19.680]   Public doesn't give up your rights to it
[00:18:19.680 --> 00:18:24.880]   Does it well as I was gonna say no public doesn't it doesn't necessarily mean open source, correct?
[00:18:24.880 --> 00:18:28.400]   No, it is open source, but it also does not give up your rights to it
[00:18:28.400 --> 00:18:31.920]   There's all sorts of ways you can license that and if you don't license it then you have
[00:18:31.920 --> 00:18:34.000]   Not give it up any rights to it
[00:18:34.000 --> 00:18:41.120]   So I can publish source code that I still own that you can't read you shouldn't you can't theoretically reuse you can't yeah cut and paste and
[00:18:41.120 --> 00:18:45.200]   Yeah, so that a lot of people were a little upset about co-pilot. There was also the issue
[00:18:45.680 --> 00:18:49.120]   Of it not being very good. Let's take a look. This is an artificial
[00:18:49.120 --> 00:18:54.480]   So the first demo that is a hello world that because you have to right and they and have a do more things
[00:18:54.480 --> 00:18:58.160]   But then the second demo which I give the time code for it's gonna it's gonna write a game
[00:18:58.160 --> 00:19:04.400]   So open AI was elan musk and a number of other companies founded this as a nonprofit
[00:19:04.400 --> 00:19:07.200]   But they've jacked so far
[00:19:07.200 --> 00:19:12.400]   It's interesting because some of the most scary and interesting developments in AI are coming from open AI
[00:19:12.480 --> 00:19:15.120]   I think they don't feel as constrained as a company would be
[00:19:15.120 --> 00:19:19.200]   Google might be a little slower to announce some of the stuff that open AI is just going
[00:19:19.200 --> 00:19:23.920]   Yeah, and what look what else we can do like like this all right. Well, let's give that a try
[00:19:23.920 --> 00:19:25.600]   um
[00:19:25.600 --> 00:19:28.080]   So first of all, I'm going to look up
[00:19:28.080 --> 00:19:30.400]   I a silhouette of a person
[00:19:30.400 --> 00:19:33.120]   They're gonna make a game of a boulder
[00:19:33.120 --> 00:19:37.840]   If you agree we should probably not use a real image of a person for this because they're going to get squashed by a boulder
[00:19:37.840 --> 00:19:41.600]   To give you a very wise choice and what you see here is something very similar to the previous
[00:19:41.600 --> 00:19:45.360]   The Greg is typing the instruction to the text box
[00:19:45.360 --> 00:19:51.280]   Then he presses playing so he he only did was he typed add this image of a person and then he put a link in
[00:19:51.280 --> 00:19:54.080]   Right and it is now
[00:19:54.080 --> 00:19:56.320]   Is now looks like in javascript been added
[00:19:56.320 --> 00:20:00.400]   To you know, it's been created a var named image
[00:20:00.400 --> 00:20:03.600]   Uh, and it's actually been created in code
[00:20:03.600 --> 00:20:09.520]   It's so interesting does its neural magic and produces code and now we get this oversized person on the page
[00:20:09.520 --> 00:20:15.920]   Yeah, and I want to point out so the the only difference here as far as the the output is concerned is this is outputting
[00:20:15.920 --> 00:20:18.400]   JavaScript as opposed to python
[00:20:18.400 --> 00:20:20.080]   It's actually the same model under the hood
[00:20:20.080 --> 00:20:22.400]   So the only piece of magic we're not showing you right now
[00:20:22.400 --> 00:20:25.760]   Is that we pride a little bit of context to the model in the case of python
[00:20:25.760 --> 00:20:30.080]   We have just one example of following an instruction in python in the case of javascript
[00:20:30.080 --> 00:20:31.920]   We have like two examples of doing it
[00:20:32.640 --> 00:20:36.400]   And from there the model latches on and just continues and continues
[00:20:36.400 --> 00:20:41.840]   Wait, I mean so I think they're training it with a set of two instructions are my they yes
[00:20:41.840 --> 00:20:47.200]   No, yes, okay. I like it was a good first. If it were that easy to learn a language
[00:20:47.200 --> 00:20:53.200]   Well, no, no, they're various instructions. They're they're they're training with various various. Yeah, I mean, yeah, okay
[00:20:53.200 --> 00:20:57.360]   Step but what I would really like is for the person to be a lot smaller
[00:20:57.360 --> 00:21:00.640]   And for it to be controllable with the left and right arrow keys
[00:21:00.640 --> 00:21:07.520]   Great, and we also just got a report that the emails have started rolling in so I think he's typing into him for a field
[00:21:07.520 --> 00:21:13.120]   The english language text. So let's see how big make the person 100 pixels. That's even about right
[00:21:13.120 --> 00:21:17.360]   Let's find out. All right, let's give that a try and actually what I'm gonna also do is I just want to show people
[00:21:17.360 --> 00:21:21.760]   The full prompt that's being sent so that you can really see what's going on without any magic
[00:21:21.760 --> 00:21:23.520]   So I just opened up the chrome inspector
[00:21:23.520 --> 00:21:26.080]   We have a completion zen point and you can actually just
[00:21:26.720 --> 00:21:30.880]   Scroll to this to the post message and you can look at the entire
[00:21:30.880 --> 00:21:34.000]   bit of the
[00:21:34.000 --> 00:21:36.400]   And
[00:21:36.400 --> 00:21:40.320]   What that looks like it's an background and to just to just explain what you're seeing here
[00:21:40.320 --> 00:21:44.960]   The way this neural network works is that it's a really really good
[00:21:44.960 --> 00:21:51.360]   Pattern completion system that happens to work on patterns in code. It's like the world's best
[00:21:51.920 --> 00:21:59.440]   Yes and improv actor whose domain happens to be code rather than improv well that really makes it crystal clear
[00:21:59.440 --> 00:22:06.960]   They're trying so hard. Yeah, I'm getting them plus this demo is really compelling so far
[00:22:06.960 --> 00:22:12.000]   Okay, yes, so we provided with this context of oh you're supposed to follow some instructions
[00:22:12.000 --> 00:22:16.720]   So you're typing in relaying english and writing the javascript code so far, okay
[00:22:16.720 --> 00:22:20.800]   It's not the two companies have been yeah so far. So we've got the person 100 pixels
[00:22:21.040 --> 00:22:24.000]   Look, I think so all right now what do you want?
[00:22:24.000 --> 00:22:27.920]   Image style that width equals I want it to be 100 px
[00:22:27.920 --> 00:22:31.840]   At a reasonable position at the bottom of the space of the screen and to be comfortable
[00:22:31.840 --> 00:22:34.400]   Impressive thing was it understood who this person was?
[00:22:34.400 --> 00:22:37.040]   Let's set its position to more of a new
[00:22:37.040 --> 00:22:41.520]   Its position right now. It says it's so it's understanding the context
[00:22:41.520 --> 00:22:47.920]   Yes from the left. Yeah, no, cedent seems reasonable as far as I can tell these these though are fairly
[00:22:47.920 --> 00:22:49.920]   I mean that's not hard to try. No, I know
[00:22:50.640 --> 00:22:55.520]   Controllable image that style that left equals 400 pixels start top equals 500 pixels now
[00:22:55.520 --> 00:23:00.160]   This is a pretty high level instruction. That's hard now. This is a hard one make it controllable
[00:23:00.160 --> 00:23:06.320]   Model really has to infer what's going on in here and it can't look at the screen
[00:23:06.320 --> 00:23:10.000]   The model only has access to all of this text over here
[00:23:10.000 --> 00:23:13.360]   And so from that alone it has to infer what to do, but let's see if it worked
[00:23:13.360 --> 00:23:15.920]   Let's see. I'm curious myself the code looks reasonable
[00:23:15.920 --> 00:23:17.760]   Okay
[00:23:17.760 --> 00:23:21.680]   It's quite good, but this looks like something I don't quite like
[00:23:21.680 --> 00:23:22.560]   Goes off the edge
[00:23:22.560 --> 00:23:24.640]   I don't want it to be able to get out of the screen like this
[00:23:24.640 --> 00:23:26.160]   Yeah, but you didn't tell it
[00:23:26.160 --> 00:23:27.520]   But it's a lot to do. You want to do that?
[00:23:27.520 --> 00:23:30.240]   Yeah, it's just an if statement
[00:23:30.240 --> 00:23:34.960]   Constantly check if the person looking for the key code off left arrow 37
[00:23:34.960 --> 00:23:36.320]   And put it in the
[00:23:36.320 --> 00:23:40.240]   Move that left 10 pixels it did make some though so again pretty high level
[00:23:40.240 --> 00:23:44.320]   Constantly check if the person is off screen and put it back on the screen so
[00:23:44.320 --> 00:23:45.280]   Okay, go ahead.
[00:23:45.280 --> 00:23:46.480]   Oh, that's that's that's okay.
[00:23:46.480 --> 00:23:48.320]   So that's pretty good to me.
[00:23:48.320 --> 00:23:48.720]   That's pretty good.
[00:23:48.720 --> 00:23:49.680]   That's pretty good.
[00:23:49.680 --> 00:23:50.800]   Let's see what's happening there.
[00:23:50.800 --> 00:23:52.000]   It should point out.
[00:23:52.000 --> 00:23:53.840]   I would have put it back in the middle.
[00:23:53.840 --> 00:23:54.400]   Yeah, well.
[00:23:54.400 --> 00:23:56.320]   Except that you see this flickering scroll
[00:23:56.320 --> 00:23:58.400]   Oh yeah, so they're going to do that and fix that.
[00:23:58.400 --> 00:24:00.720]   Fortunately, you can just say disable scroll bars.
[00:24:00.720 --> 00:24:03.440]   By the way, I actually don't know how to do this in JavaScript.
[00:24:03.440 --> 00:24:04.240]   Does the model now?
[00:24:04.240 --> 00:24:08.800]   Well, it's obviously document.body.style.overflow=
[00:24:08.800 --> 00:24:10.480]   Everyone knows that.
[00:24:12.080 --> 00:24:15.680]   There is a suggestion from twitch to see if we can make it move upward.
[00:24:15.680 --> 00:24:18.880]   This would be certainly would be helpful to do a
[00:24:18.880 --> 00:24:21.680]   You know preliminary run at something.
[00:24:21.680 --> 00:24:25.920]   Although anybody's ever written any kind of game code.
[00:24:25.920 --> 00:24:28.000]   This is boilerplate in the head.
[00:24:28.000 --> 00:24:32.320]   Yeah, well, so you don't have to think about if you're like doing your website
[00:24:32.320 --> 00:24:34.080]   or you want to build a table.
[00:24:34.080 --> 00:24:36.880]   I mean, like I can remember building tables and each table.
[00:24:36.880 --> 00:24:40.320]   Yeah, you know, this would be great for building HTML tables.
[00:24:40.320 --> 00:24:41.040]   Right.
[00:24:41.040 --> 00:24:45.040]   Well, there's a lot of things that I'm like, oh, this could be helpful.
[00:24:45.040 --> 00:24:52.080]   Imagine if I could use it to make API calls for my smart home gear.
[00:24:52.080 --> 00:24:57.840]   So I could be like, if I could like tie it into like the life X API and say,
[00:24:57.840 --> 00:25:02.320]   Hey, if you see that the weather is this, turn it blue.
[00:25:02.320 --> 00:25:04.800]   And I could just type that in just like I do with like if to anything.
[00:25:04.800 --> 00:25:08.640]   But if I could do that on my own and host it myself, how baller would that be?
[00:25:08.640 --> 00:25:10.640]   So here's a Google angle.
[00:25:10.640 --> 00:25:12.160]   What?
[00:25:12.160 --> 00:25:18.160]   What if this was in place when Chrome OS was needing to be updated and someone forgot a semicolon?
[00:25:18.160 --> 00:25:24.960]   There are programs to fix that they didn't use, obviously.
[00:25:24.960 --> 00:25:25.840]   So this is interesting.
[00:25:25.840 --> 00:25:26.240]   It's cool.
[00:25:26.240 --> 00:25:29.360]   And now they're adding a boulder and they're going to crush this guy with a boulder.
[00:25:29.360 --> 00:25:32.640]   You know, this is this is a
[00:25:34.800 --> 00:25:38.640]   example of a program that you would have in the first class of your computer science.
[00:25:38.640 --> 00:25:42.720]   You know, college computer science.
[00:25:42.720 --> 00:25:45.520]   Yeah, it's very interesting.
[00:25:45.520 --> 00:25:45.760]   Yeah.
[00:25:45.760 --> 00:25:47.200]   And you know what I love?
[00:25:47.200 --> 00:25:52.560]   The thing I like the best is taking the pros, the guy types in and makes it the comment,
[00:25:52.560 --> 00:25:55.520]   which in effect is self commenting code, which is really great.
[00:25:55.520 --> 00:26:01.840]   The next one also uses the Microsoft word API.
[00:26:01.840 --> 00:26:02.880]   Oh, that's interesting.
[00:26:02.880 --> 00:26:05.840]   See, for APIs, this would be great to write API code.
[00:26:05.840 --> 00:26:06.320]   Yeah.
[00:26:06.320 --> 00:26:07.680]   That would be so handy.
[00:26:07.680 --> 00:26:09.920]   I would use that every day all the time.
[00:26:09.920 --> 00:26:10.080]   Yeah.
[00:26:10.080 --> 00:26:13.440]   APIs are kind of everybody's got a slight difference.
[00:26:13.440 --> 00:26:23.120]   So the prior one did a thing of hello world, then they had to create a web page with hello world
[00:26:23.120 --> 00:26:24.080]   multiple times.
[00:26:24.080 --> 00:26:30.480]   Then they created the option of sending you getting an email of that plus bitcoin chart of price.
[00:26:31.760 --> 00:26:36.960]   And so it used the what's the email, the mail chimp API.
[00:26:36.960 --> 00:26:44.400]   So I'm really the thing I'm most curious about is when they ask it to write the code for collision
[00:26:44.400 --> 00:26:45.840]   between the boulder and the guy.
[00:26:45.840 --> 00:26:52.160]   That's something that is easy to understand and takes a lot of typing.
[00:26:52.160 --> 00:26:57.920]   So it would be really great if I could do that.
[00:26:57.920 --> 00:26:59.760]   It would just save me a lot of typing.
[00:27:00.320 --> 00:27:04.480]   Well, can't you do that with like, I mean, that's part of sometimes what game engines have.
[00:27:04.480 --> 00:27:06.640]   You know, they write all the physics behind there.
[00:27:06.640 --> 00:27:06.640]   Absolutely.
[00:27:06.640 --> 00:27:07.200]   Yeah.
[00:27:07.200 --> 00:27:09.600]   Hey, you all want a quick update?
[00:27:09.600 --> 00:27:09.920]   Yes.
[00:27:09.920 --> 00:27:15.440]   My dad just texted me and said, I don't know what you said, but Ray said to tell you, thanks for the shout out.
[00:27:15.440 --> 00:27:17.440]   Cousin Ray is really happy right now.
[00:27:17.440 --> 00:27:21.600]   Cousin Ray, we're going to drop a boulder on you.
[00:27:21.600 --> 00:27:22.000]   Come here.
[00:27:26.080 --> 00:27:31.920]   So this is cool. Open AI codecs, a live demo of an AI writing code,
[00:27:31.920 --> 00:27:33.760]   which has been the Holy Grail in computers.
[00:27:33.760 --> 00:27:40.240]   It's just a small demo, but it starts to, when you realize that what the learning set can be,
[00:27:40.240 --> 00:27:43.680]   and then how you can speak to it, that starts to get your brain.
[00:27:43.680 --> 00:27:44.080]   Yeah. Yeah.
[00:27:44.080 --> 00:27:46.000]   I'm starting to think a lot of things like AI.
[00:27:46.000 --> 00:27:48.880]   I'm going to call Kevin and tell him his master's is going to be useless.
[00:27:51.120 --> 00:27:57.440]   I know how to do all this in Python. I will say that no code, there's been so much venture
[00:27:57.440 --> 00:28:03.360]   capital going into the no code, you know, startups. And the reason is because we're turning
[00:28:03.360 --> 00:28:10.400]   everything we have into software, addressable devices and things. And we all have to be it's like,
[00:28:10.400 --> 00:28:14.080]   I know people said everyone would learn to code because that's like literacy.
[00:28:14.080 --> 00:28:18.880]   I don't actually know if that's the case. I think not everyone will learn to write,
[00:28:19.760 --> 00:28:23.600]   but everyone will know how to read. And I think these no code platforms are kind of like the
[00:28:23.600 --> 00:28:27.520]   basic literacy and maybe actual coding is like someone being a writer.
[00:28:27.520 --> 00:28:28.640]   Yeah.
[00:28:28.640 --> 00:28:28.640]   Yeah.
[00:28:28.640 --> 00:28:29.840]   And see writer.
[00:28:29.840 --> 00:28:30.800]   We've got some signs of life.
[00:28:30.800 --> 00:28:32.800]   We're going back and yes, there we go.
[00:28:32.800 --> 00:28:35.040]   All right. Very nice. This is very nice.
[00:28:35.040 --> 00:28:37.120]   It's right in boulders.
[00:28:37.120 --> 00:28:45.040]   Cool. Thank you for that link. We actually have a little more challenging link from Jeff that
[00:28:45.040 --> 00:28:49.200]   we're going to talk about in just a little bit from Harper's Magazine who says it's
[00:28:49.200 --> 00:28:55.280]   not a democracy. Who said we need an ad before we do that because I have to finish reading it.
[00:28:55.280 --> 00:28:56.000]   Yeah. Go ahead.
[00:28:56.000 --> 00:29:00.640]   You now have two minutes to finish reading it and get a waffle. Yes.
[00:29:00.640 --> 00:29:05.200]   I read it at breakfast. You'll be glad to know in the breakfast table.
[00:29:05.200 --> 00:29:08.080]   So thank you for the link. I'm glad you sent it a little bit ahead.
[00:29:08.080 --> 00:29:12.080]   And your wife pulled you up out of the plate of potatoes.
[00:29:12.080 --> 00:29:14.000]   No, I actually had a lot of thoughts about it.
[00:29:14.560 --> 00:29:15.280]   So we'll talk.
[00:29:15.280 --> 00:29:16.800]   I have to consider it's a very interesting piece.
[00:29:16.800 --> 00:29:19.840]   It's provocative. It's from Harper's Magazine,
[00:29:19.840 --> 00:29:21.520]   a guy who for years was at BuzzFeed.
[00:29:21.520 --> 00:29:27.120]   And it's about news, bad fake news and disinformation.
[00:29:27.120 --> 00:29:34.400]   Our show today though, brought to you by my buddy Kevin Rose and his brand new podcast,
[00:29:34.400 --> 00:29:40.400]   Modern Finance. I know a lot of times, in fact practically every time we talk about
[00:29:40.400 --> 00:29:46.480]   cryptocurrencies, NFTs, we get all twisted around trying to explain and understand what these things
[00:29:46.480 --> 00:29:52.080]   are. Robo investors, FinCEN, the investment world is changing rapidly.
[00:29:52.080 --> 00:29:56.800]   And you know, I think it makes sense. If you're an informed person, you need to understand it.
[00:29:56.800 --> 00:30:00.400]   Fortunately, there's an easy, entertaining, fun way to learn.
[00:30:00.400 --> 00:30:07.440]   Kevin's new podcast. Modern Finance. Modern Finance helps to demystify crypto,
[00:30:07.440 --> 00:30:12.960]   decentralized finance and more. Of course, Kevin Rose knows Kevin, of course, with us
[00:30:12.960 --> 00:30:17.360]   for a long time at the screen savers on tech TV. He was a host later in the attack of the show.
[00:30:17.360 --> 00:30:23.600]   He is also a very successful investor. In fact, Bloomberg called him one of the top 25
[00:30:23.600 --> 00:30:27.200]   angel investors in the country, one of the top 25 most influential people on the web,
[00:30:27.200 --> 00:30:32.560]   according to Time Magazine. He is a venture capitalist of true ventures. He really understands
[00:30:32.560 --> 00:30:38.480]   how this stuff works and has made it his business to really be able to communicate about it. Modern
[00:30:38.480 --> 00:30:44.560]   Finance is a show, a crypto show for the novice and expert alike. Their mission is to demystify crypto
[00:30:44.560 --> 00:30:49.600]   in the world of NFTs without dumbing it down. When I needed to know what an NFT wasn't understand it,
[00:30:49.600 --> 00:30:54.720]   that's where I went. It was actually the very first episode of MoFi, Modern Finance. And it was,
[00:30:54.720 --> 00:31:01.360]   I felt like after I listened to it, I got it. I got it. There's two, there's actually two shows on
[00:31:01.360 --> 00:31:07.200]   one feed. One is the weekly consensus episode. Once a week it explores the latest news distills
[00:31:07.200 --> 00:31:12.640]   it into digestible information, a great way to keep up. The other Kevin interviews top tech
[00:31:12.640 --> 00:31:20.160]   experts and entrepreneurs, individual crypto founders, NFT artists, talks about modern finance
[00:31:20.160 --> 00:31:27.760]   tools, helps you understand cryptos, NFTs. There's Amy Wu talking about gaming NFTs and D5 versus C5.
[00:31:27.760 --> 00:31:31.920]   I don't know what that is. I'm going to have to listen to that episode. I missed that one episode.
[00:31:31.920 --> 00:31:37.920]   It proceeds from light speed. Fascinating stuff. You could, don't let that crypto guy be the life
[00:31:37.920 --> 00:31:42.400]   of the party. You could be the life of the party by listening to modern finance. You'll feel well
[00:31:42.400 --> 00:31:48.560]   equipped to discuss, maybe more importantly, understand the crypto and NFT landscape. Kevin Rose,
[00:31:48.560 --> 00:31:54.800]   modern finance every week. 10 years ago, people called cryptocurrency a scam five years ago,
[00:31:54.800 --> 00:32:00.560]   people thought it was a fad. Now my daughter is celebrating the fact that she bought Dogecoin.
[00:32:00.560 --> 00:32:05.600]   It's over a trillion dollar market and growing. The modern finance podcast,
[00:32:05.600 --> 00:32:10.640]   let's you make sense, helps you make sense of all of the coins and FTS and chaos.
[00:32:10.640 --> 00:32:16.080]   And it does it in a good, humid, interesting and very informative way. Kevin's great. The
[00:32:16.080 --> 00:32:20.400]   financial landscape is harder than ever to navigate. You don't have to do it alone. Download and
[00:32:20.400 --> 00:32:25.200]   subscribe to modern finance. Wherever you listen to podcasts, that's modern finance,
[00:32:25.200 --> 00:32:32.320]   wherever you listen to podcasts or go to mofi, m-o-f-i dot net. That's the website. Don't be the
[00:32:32.320 --> 00:32:38.720]   last person on the next train out. Listen to modern finance and get ahead of the future of
[00:32:38.720 --> 00:32:45.920]   finance. Really happy to support Kevin's latest venture. It's kind of a wonderful full circle
[00:32:47.120 --> 00:32:53.120]   of the podcast world to come back around to Kevin advertising podcast on your podcast.
[00:32:53.120 --> 00:33:00.080]   Is that funny? Yeah. Kevin's great. I am a huge fan and really glad to be able to support
[00:33:00.080 --> 00:33:05.600]   him a little bit about it. I'm always remember the time you did. You surfed, your body surfed
[00:33:05.600 --> 00:33:11.840]   the crowd. Oh yeah. It's not by Southwest. Yeah. You saw that?
[00:33:12.720 --> 00:33:18.720]   Yeah. And you still were willing to be on the show? Yeah. Okay. I think I saw your butt crack go by.
[00:33:18.720 --> 00:33:24.080]   You might have. It wasn't my fault, man. I was being manhandled at the time.
[00:33:24.080 --> 00:33:31.360]   I have to confess something. I was watching all about Android last night and Ron convinced me to
[00:33:31.360 --> 00:33:40.080]   buy a Samsung flip phone three. Oh, well. Oh, the little, the little one. Yeah. I already had the
[00:33:40.080 --> 00:33:44.960]   Galaxy Fold last year and I thought, I don't want that. And then Ron pointed out that I could take
[00:33:44.960 --> 00:33:53.360]   that old one and get a pretty good money back for it. I think like six or seven hundred bucks back.
[00:33:53.360 --> 00:33:56.240]   This is the cool thing. Oh, okay. Well, yeah, I didn't do it. Yeah.
[00:33:56.240 --> 00:34:03.600]   Yeah. Why can't wait to see that? 99, right? Yes. 999. I got it for 349. Oh, yes.
[00:34:03.600 --> 00:34:09.200]   After after trading. Yeah. And you get a, if you order it now, you get $150 an extra crap.
[00:34:09.920 --> 00:34:13.840]   In fact, it was a little hard to Samsung. Your buds or the watch, but I unfortunately already,
[00:34:13.840 --> 00:34:17.040]   yes, Samsung credits already ordered the watch. So, but I want to try that.
[00:34:17.040 --> 00:34:23.360]   You know, after all the iPhone stuff, I'm thinking, maybe I should go back to Android. So I'm going
[00:34:23.360 --> 00:34:28.720]   to try that and the Pixel 6 will come out in October. And I'll try that too. But yeah, the watch looks
[00:34:28.720 --> 00:34:34.160]   pretty cool. Well, anyway, I'll give you a report. Jason also reviewed the Pixel 5A last night
[00:34:34.160 --> 00:34:37.840]   on all about it. He's a really good review. He's fine. Also, music.
[00:34:37.840 --> 00:34:46.720]   You mean, 5A, 5, 4A, 4, ABC? It's really hard. So, yeah, I mean,
[00:34:46.720 --> 00:34:53.440]   so what they've been doing is introducing the flagship phone in the fall. And then six months
[00:34:53.440 --> 00:34:59.840]   later introducing a reduced cost, reduced feature version of that phone. And that's what this 5A is.
[00:34:59.840 --> 00:35:06.080]   It's kind of a reduced cost feature of the 5. Not so much different, but about half the price.
[00:35:06.640 --> 00:35:11.680]   Yeah, I think he liked it quite a bit. But actually, everybody does. All the reviews are very positive.
[00:35:11.680 --> 00:35:18.400]   It's just, you know, you got the 6 coming out in two months. It's all about a time.
[00:35:18.400 --> 00:35:24.400]   Maybe when I see the 6, I'll be like, oh, too much money or is it not good enough?
[00:35:24.400 --> 00:35:26.800]   Right. Yeah, that's a thought. That's a thought, Stacey.
[00:35:26.800 --> 00:35:33.200]   But maybe he's going to talk about this on has on tech when it drops later today. But did
[00:35:33.920 --> 00:35:40.000]   you all see the subscription options for this device? Or was it 15 hours a month on Google 5?
[00:35:40.000 --> 00:35:44.000]   What do you do to the device for two years? Oh, in addition to your 5 fee.
[00:35:44.000 --> 00:35:47.600]   Oh, so.
[00:35:47.600 --> 00:35:54.480]   I was truly trying to figure out a way to get that in there somehow.
[00:35:54.480 --> 00:36:03.280]   They also reviewed the Z Flip 3 and they took a look at Android 12 beta. So, a good episode
[00:36:03.280 --> 00:36:06.720]   last night on all about Android. And they convinced me I should.
[00:36:06.720 --> 00:36:11.360]   I've done the full, I don't like the big folding phone, but maybe the little one because it's so cute.
[00:36:11.360 --> 00:36:15.360]   You just go right in there. It looks cute. It's got that screen on the other side. I thought,
[00:36:15.360 --> 00:36:19.840]   maybe I'm maybe. Stacey was convincing me last week that there was a there was a there was a
[00:36:19.840 --> 00:36:28.480]   useful market for that. Yeah. I mean, it opens up to be a normal size phone, but it will fit in
[00:36:28.480 --> 00:36:36.560]   Stacey's pockets. Right? And in my hand, I mean, I'm sorry, but like, yeah, I have normal sized
[00:36:36.560 --> 00:36:42.480]   hands, but I'm a bigger woman than other people. I've been going down this road of bigger and
[00:36:42.480 --> 00:36:47.920]   bigger phones with all everybody else. And now I'm thinking, yeah, maybe a smaller phone isn't
[00:36:47.920 --> 00:36:55.360]   such a bad idea. And for a size, I didn't mind just decides that the 4A being a little bit shorter.
[00:36:55.360 --> 00:37:03.120]   Yes, smaller. Yeah. Yeah. So. Plus, when you're mad, can you snap it shut with emphasis? I would
[00:37:03.120 --> 00:37:11.040]   be careful with that. And we're done. And so's the phone.
[00:37:11.040 --> 00:37:18.400]   I don't know. The only thing I don't like is this kind of it looks like a clothespin
[00:37:18.400 --> 00:37:24.320]   when you look at why that bugs you so much. Yeah. Well, stuff gets in that crap.
[00:37:24.320 --> 00:37:27.520]   Okay, it'll be okay. Well, it'll be okay. It's not a navel. It'll be
[00:37:27.520 --> 00:37:33.440]   Thank you. Oh, no.
[00:37:33.440 --> 00:37:44.720]   I'm excited. I can't wait to see it. Please bring it on the show. I will. I'll get it. August 27th. So
[00:37:44.720 --> 00:37:50.960]   eight or nine dice. Yeah. I settled for Phantom Black, because that's the only one I could get,
[00:37:50.960 --> 00:37:56.720]   like, on the 27th. I have to wait longer for the other pretty colors. But I don't care about colors.
[00:37:56.720 --> 00:38:05.760]   Yeah. What color would you get? Lavender, green, gold. I didn't see the Samsung colors.
[00:38:05.760 --> 00:38:10.880]   The colors aren't that good. They don't look that good. I like orange and blue. Yeah.
[00:38:10.880 --> 00:38:16.080]   Talking. Yeah. I agree with you. Something a little that pops. You want something that pops?
[00:38:16.080 --> 00:38:18.080]   Yeah. I would even do bright red. Yeah.
[00:38:19.200 --> 00:38:24.400]   Like this whole Google loves pastel kind of thing. All of their home gear, all of the, you know,
[00:38:24.400 --> 00:38:30.160]   the even the new pixel colors look kind of muted and pastel. Yeah. Let's get some pizzazz.
[00:38:30.160 --> 00:38:36.560]   Yeah. Yeah. Jewel tones, baby. Jewel tones. You know, you won't get with a pixel six or I don't
[00:38:36.560 --> 00:38:42.720]   think that with a flip three either is a charger. Everybody's doing what Apple did and leaving the
[00:38:42.720 --> 00:38:50.560]   charger out. I just, I don't change the charger. That'd be okay. Right. It'll always be type C now
[00:38:50.560 --> 00:38:57.040]   going forward. And, you know, part of the reason people say this is, you know, there's a huge waste.
[00:38:57.040 --> 00:39:02.000]   Everybody's by now got a type C charger. You can buy one if you don't. But considering that
[00:39:02.000 --> 00:39:07.760]   probably most people do, it's just a waste. Let's not add more plastic waste. I'm kind of behind that.
[00:39:08.800 --> 00:39:15.520]   And it also saves money. Yeah. And we go to wireless power. Well, in the chip shortage,
[00:39:15.520 --> 00:39:20.320]   some of the power components are an issue there. True. So true. True debt. True debt.
[00:39:20.320 --> 00:39:29.520]   There is, we reported that Amy Klobuchar and Dick Blumenthal and Marsha Blackburn had united
[00:39:29.520 --> 00:39:36.720]   to create an unholy alliance in the Senate to propose the open market markets app last week.
[00:39:36.720 --> 00:39:44.160]   There is now a similar act in the house. Be interesting. It would force both Apple and Google,
[00:39:44.160 --> 00:39:48.640]   although I think it's a little less onerous for Google, mostly if this is aimed at Apple
[00:39:48.640 --> 00:39:54.400]   to allow third party app stores and third party payment platforms on their phone. Google already
[00:39:54.400 --> 00:40:00.800]   allows third party app stores. Samsung has one. So I'm not sure this would change how Google does
[00:40:00.800 --> 00:40:06.240]   business. They mentioned Google though. They say Dick Blumenthal said the legislation would
[00:40:06.240 --> 00:40:10.720]   break the competitive hold that Apple and Google have over the app market while providing mobile
[00:40:10.720 --> 00:40:15.280]   users with more control over their devices. Apple says, oh yeah, great.
[00:40:15.280 --> 00:40:25.200]   How much of a security issue is this? I think it's quite a bit. I think it's quite a bit. The
[00:40:25.200 --> 00:40:29.200]   thing I think about is, you know, Google's always had this setting and they warn you when you check
[00:40:29.200 --> 00:40:34.640]   it that you could download a sideload apps or get downloaded from another store. And Epic,
[00:40:34.640 --> 00:40:38.800]   who didn't want to pay Google, they're 30% on Fortnite, just like they didn't want to pay Apple,
[00:40:38.800 --> 00:40:44.160]   when they released a new version of Fortnite on Android, put it, you know, sideloaded it and
[00:40:44.160 --> 00:40:48.240]   said, well, you have to check this box and go out and get it and download it that way.
[00:40:48.240 --> 00:40:51.040]   Your phone vulnerable. And almost instantly within a day,
[00:40:51.040 --> 00:40:58.880]   some bad guy was putting a malware laced version of Fortnite up and a number of people got that
[00:40:58.880 --> 00:41:06.160]   instead of the real Fortnite. So there is a risk. I mean, there's clearly a risk. I think Apple
[00:41:06.160 --> 00:41:09.840]   could find a way to make this. What Apple will do is probably what Google does, which is put
[00:41:09.840 --> 00:41:15.360]   up a bunch of warnings saying, you really don't want to check this box is going to cause all sorts
[00:41:15.360 --> 00:41:21.680]   of problems. And I think most people won't won't do it. I don't do it on Android that much, right?
[00:41:21.680 --> 00:41:25.840]   Do you? I mean, I have. Yeah, I mean, sideloading is kind of a pain. I mean, I have done it on occasion.
[00:41:27.280 --> 00:41:30.720]   Yeah. But just as it's available in the days of rootin and ramen.
[00:41:30.720 --> 00:41:36.320]   Yeah, I liked rootin and ramen. Yeah. Yeah. In fact, if I get a Pixel 6, I'm thinking of
[00:41:36.320 --> 00:41:41.520]   rootin it and putting a privacy forward OS on it like Calix OS just to try it.
[00:41:41.520 --> 00:41:47.040]   Like what this atofo did. Yeah. The toful do it? Oh, he's a smart boy.
[00:41:47.040 --> 00:41:51.200]   He's been doing stuff like that. Yeah. I don't know if he's, no, he's using the iPhone right now.
[00:41:51.840 --> 00:41:57.280]   You can't rootin, ramen the iPhone. Nope. No, you cannot. It's not an option.
[00:41:57.280 --> 00:42:05.760]   All right. We could talk about it, Jeff. You put this article in our email that to us all gave
[00:42:05.760 --> 00:42:08.720]   us homework. Yeah. Because I thought it was so interesting. I think I really get a few.
[00:42:08.720 --> 00:42:15.360]   It's momentarily, but that's okay. Joseph Bernstein, who was at BuzzFeed writing in Harper's Magazine.
[00:42:15.360 --> 00:42:22.240]   What do you think of Harper's these days? Yeah. I used to love it.
[00:42:22.240 --> 00:42:26.000]   He tries a little too hard to be weird. Yeah. I used to love it. I'm not sure I like the
[00:42:26.000 --> 00:42:29.360]   new Harper's that much, but this is an article about, thanks to the cover story,
[00:42:29.360 --> 00:42:37.120]   disinformed, how we get fake news wrong. And in it Bernstein,
[00:42:37.120 --> 00:42:43.520]   Distinfo was he calls it fake disinfo, big disinfo, big disinfo. So it's kind of an industry
[00:42:43.520 --> 00:42:50.400]   unto itself. Yeah. Yeah. That's, that's one of his points, which I have to say is absolutely true.
[00:42:50.400 --> 00:42:56.960]   He says, only five years ago, Mark Zuckerberg said it was a pretty crazy idea. That's a quote
[00:42:56.960 --> 00:43:02.160]   that bad content on his website had persuaded enough voters to swing the 2016 election of Donald
[00:43:02.160 --> 00:43:08.560]   Trump. Voters make decisions based on their lived experience, he said, quote, there's a profound
[00:43:08.560 --> 00:43:12.240]   lack of empathy in asserting that the only reason someone would have voted the way they did is
[00:43:12.240 --> 00:43:17.360]   because they saw fake news. A year, which by the way, I think Jeff, you agree with, right?
[00:43:17.360 --> 00:43:22.000]   I think it's too simplistic to argue that someone was perfectly normal walking down the street,
[00:43:22.000 --> 00:43:26.720]   and then they saw Facebook posted. Suddenly, he said something in him nuts. A year later,
[00:43:26.720 --> 00:43:32.640]   suddenly, Jason Zuckerberg apologized for being so glib and pledged to do his part to thwart those
[00:43:32.640 --> 00:43:44.320]   who spread misinformation. He also says that this, the kind of denial that we didn't influence anybody
[00:43:44.320 --> 00:43:49.520]   is frankly not consonant with their business. Facebook's basic business pitch made denial
[00:43:49.520 --> 00:43:54.400]   impossible. Zuckerberg's company profits by convincing advertisers, it can standardize this
[00:43:54.400 --> 00:43:58.560]   audience for commercial persuasion, right? This is the key to the piece, right?
[00:43:58.560 --> 00:44:02.960]   How could it simultaneously claim that people aren't persuaded by its content,
[00:44:02.960 --> 00:44:08.080]   but they are persuaded by the ads? Right. That's what's fascinating about this.
[00:44:08.080 --> 00:44:15.360]   It shows an unholy alliance, he says, among journalists and researchers of technology,
[00:44:15.360 --> 00:44:22.640]   and all of them. But that's the primary argument is that if you say that advertising doesn't have
[00:44:22.640 --> 00:44:26.800]   impact, then you have to say the propaganda doesn't have impact, and Facebook can't do that.
[00:44:26.800 --> 00:44:32.640]   Right. They kind of allow, it's almost good for, if people argue that this info is good for Facebook
[00:44:32.640 --> 00:44:37.040]   business, but I think it's crap because it's a bad experience. But in this sense, Bernstein
[00:44:37.040 --> 00:44:42.560]   has it right, I think, because they're saying that if you deny, as Leo just said, that this info
[00:44:42.560 --> 00:44:46.720]   is influential, then you deny that advertising is influential, and that's bad for your business.
[00:44:46.720 --> 00:44:51.280]   He also points out that since time immemorial, or at least the turn of the last century,
[00:44:52.720 --> 00:44:59.920]   it's been kind of hip to talk. I mean, it's not this is not new to talk about how propaganda can
[00:44:59.920 --> 00:45:07.840]   change people's minds and so forth going back even to Vance Packard and the hidden persuaders.
[00:45:07.840 --> 00:45:12.560]   And he says, in almost every case, this was overstated, but advertisers heated up,
[00:45:12.560 --> 00:45:19.120]   advertisers love it. And I know this from our own experience at TWIT, advertisers really,
[00:45:21.440 --> 00:45:26.640]   it goes along with the fact that advertisers want to know all this information about the audience,
[00:45:26.640 --> 00:45:32.080]   that they want to do targeting. They really want to believe that this stuff is persuasive.
[00:45:32.080 --> 00:45:35.760]   We love to be clear, the podcast advertising is absolutely influential, and a million people
[00:45:35.760 --> 00:45:40.800]   40 signs up for cameras is podcast. No doubt, it's all the other stuff that isn't, just to be clear here.
[00:45:40.800 --> 00:45:50.880]   What if it's not persuasive, but what I felt this was missing was, what if it's not persuasive,
[00:45:50.880 --> 00:45:54.000]   but what if it's not like a lie? It's not like a lie. It's not like a lie.
[00:45:54.000 --> 00:46:00.960]   Yeah, because I do think the challenge here isn't that I will suddenly see one anti-vaxxer post and
[00:46:00.960 --> 00:46:06.800]   be like, "Oh my gosh, they're right. I should never get a vaccine again." What it does is it makes me
[00:46:06.800 --> 00:46:11.920]   start thinking about something and I would be had journalism professors, people come in and they'll
[00:46:11.920 --> 00:46:18.160]   tell you something demonstrably untrue, but then you'll start thinking about it and you'll be like,
[00:46:18.160 --> 00:46:22.320]   "Well, could that be true? I don't actually know." It calls into question like what you believe.
[00:46:22.320 --> 00:46:29.360]   And I do think there's something to the fact that you're normalizing by bringing people of a
[00:46:29.360 --> 00:46:36.720]   like mind together in normalizing the things they say to each other. It does make it easier to go out
[00:46:36.720 --> 00:46:42.480]   and have a belief that I'll call it an antisocial or an anti-society kind of belief,
[00:46:43.120 --> 00:46:48.480]   whereas prior to this, a lot of our goals were about fitting in. Does that make sense? And we had...
[00:46:48.480 --> 00:46:55.200]   Yeah, but also Stacey, I think, but it also ties into the media piece here, right? That once it's
[00:46:55.200 --> 00:47:00.240]   out there in the conversation sphere, then it can go lots of places, right?
[00:47:00.240 --> 00:47:08.000]   Yes, and it not only can it go lots of places, but it will influence people who thought, "Oh,
[00:47:08.000 --> 00:47:11.840]   do I want to believe that? I guess these people believe." Okay, I guess that's not crazy to believe
[00:47:11.840 --> 00:47:13.680]   that. Sure, toothpaste causes cancer.
[00:47:13.680 --> 00:47:21.040]   Honestly, we have plenty of an admittedly anecdotal, but plenty of, in our own lives,
[00:47:21.040 --> 00:47:26.320]   I'm sure you do, too, Jeff, examples of people who have gone down a rabbit hole,
[00:47:26.320 --> 00:47:34.080]   whether it's on YouTube or Facebook, followed that rabbit to the craziest of conclusions.
[00:47:34.080 --> 00:47:39.600]   Maybe they would have done that anyway, or maybe, but it certainly facilitated it, right?
[00:47:40.560 --> 00:47:44.880]   That's why QNOS does do the research. Where do you think that research is happening?
[00:47:44.880 --> 00:47:51.520]   All of this information. And you search their terms like incel, and you go down the rabbit hole.
[00:47:51.520 --> 00:47:56.720]   Yeah, that's their desire. But what impact does that actually have? We don't have enough research.
[00:47:56.720 --> 00:48:03.520]   We don't know. Don't you... On the face of it, doesn't it seem obvious that it does? No, no, no.
[00:48:04.080 --> 00:48:11.040]   I think it does. I think it changes enough people's minds and brings them to places that they
[00:48:11.040 --> 00:48:17.200]   otherwise never would have considered. Think about the idea of sheeple. The whole goal there is like,
[00:48:17.200 --> 00:48:21.920]   "Hey, you're going to think for yourself by adopting this whacked out worldview that you
[00:48:21.920 --> 00:48:25.920]   always... That you never questioned before." And the reason you never questioned it was because,
[00:48:25.920 --> 00:48:31.280]   "Yeah, we know the Earth is round," right? But sheeple, now, they think the Earth is round,
[00:48:31.280 --> 00:48:37.280]   but really, if you do the research, it's flat. So what you just sent Stacy a minute ago, though,
[00:48:37.280 --> 00:48:43.360]   is that it's a permission system for a belief you already have. It doesn't suddenly make you believe...
[00:48:43.360 --> 00:48:50.160]   The... Nobody in their mind. A lot of people have that, and they found in a
[00:48:50.160 --> 00:48:56.160]   moderate mission system from the top down. But think about QNOS. Nobody in their mind just
[00:48:56.160 --> 00:49:01.040]   independently comes up with... I think the Democrats have a better,
[00:49:01.040 --> 00:49:05.360]   better-assity ring, and they're sucking the blood of children to stay on. I think that's what's
[00:49:05.360 --> 00:49:10.720]   happening. Let me check. That comes from an external input. You cannot say that that's internal.
[00:49:10.720 --> 00:49:22.080]   But that's not the driving belief. That's the device. That's the McGuffin. It's meaningless.
[00:49:22.080 --> 00:49:27.760]   You don't think QNOS and people believe that? No, I actually... I know QNOS and people who believe
[00:49:27.760 --> 00:49:31.920]   it. Well, they want you to believe they believe it, and they've succeeded.
[00:49:31.920 --> 00:49:36.560]   I think there's a mix of people that probably fit into both of those camps.
[00:49:36.560 --> 00:49:42.800]   In less so QNOS, but think about things that have an actual impact, like vaccines. Let's take
[00:49:42.800 --> 00:49:47.840]   out the lizard people, and let's just talk about vaccine misinformation, which I think we all have
[00:49:47.840 --> 00:49:52.640]   a vested interest in getting the right information to the right people. It's not black and white. It's
[00:49:52.640 --> 00:49:58.960]   not as if somebody is persuaded to change their views 180 degrees. I agree with in most cases,
[00:49:58.960 --> 00:50:05.680]   it's not. But I also don't think they're not influenced by it. This is third-person effect.
[00:50:05.680 --> 00:50:12.000]   How am I immune when everybody else is a mess? And the quote from the piece is,
[00:50:12.000 --> 00:50:16.160]   "The question is, why do disinformation workers think they're the only ones who've noticed that
[00:50:16.160 --> 00:50:21.200]   Facebook stinks? Why should we suppose that the rest of the world has been hypnotized by it?
[00:50:21.200 --> 00:50:25.920]   Why have we been so eager to accept that? Because it has three and a half billion
[00:50:25.920 --> 00:50:32.960]   activities. I bet that that line is how easy we are to manipulate. That line to me was bull
[00:50:32.960 --> 00:50:39.520]   because three and a half billion active users, somebody likes Facebook. You think they all hate it?
[00:50:39.520 --> 00:50:45.040]   No, it's not that. It's just that we think that Facebook has manipulated them and changed
[00:50:45.040 --> 00:50:50.640]   them and it's miserable. And somehow they're not there for that. In fact, we'll have another story
[00:50:50.640 --> 00:50:57.600]   up soon about Facebook's new numbers about what people see. And we're doing this without data
[00:50:57.600 --> 00:51:02.160]   to know both what do people actually see because there's presumption that because it's on Facebook,
[00:51:02.160 --> 00:51:06.880]   everyone has seen it as an old media presumption. And then what impact that has? And what impact
[00:51:06.880 --> 00:51:11.760]   it has separate from the other ecosystem. Last week's story we did about the study about YouTube
[00:51:11.760 --> 00:51:17.840]   videos not radicalizing the way it's thought but it fits into a radical larger ecosystem.
[00:51:17.840 --> 00:51:26.400]   I do agree with you and him where he says that the establishment needs the theater of social media
[00:51:26.400 --> 00:51:33.200]   persuasion because the current political world doesn't make sense to them. They need to explain
[00:51:33.200 --> 00:51:38.320]   Brexit and Trump and the loss of faith in the decaying institutions of the West because of
[00:51:38.320 --> 00:51:45.760]   otherwise they'd have to look deeper at a deeper cause for all that. It's a lot easier just to say,
[00:51:45.760 --> 00:51:50.400]   well, it's they're being, you know, these otherwise normal people are being persuaded
[00:51:50.400 --> 00:51:59.840]   by disinformation in the media. But it's not an either or. I think that's true, but it's not an
[00:51:59.840 --> 00:52:07.040]   either or. And I feel like you and he are unwilling to recognize the inf, certainly the role that
[00:52:08.000 --> 00:52:12.960]   the disinformation has if we can get the data to get the research. Well, you don't, I don't think
[00:52:12.960 --> 00:52:17.760]   see how you say it doesn't have a role. It's patent. I don't see how you can say it does because
[00:52:17.760 --> 00:52:22.080]   I don't think you there's this presumption that goes on. And I repeat again, Axel runs his book,
[00:52:22.080 --> 00:52:24.880]   our filter bubbles real. We all presume filter bubbles were there. We had to create
[00:52:24.880 --> 00:52:29.840]   interventions because filter bubbles are awful. And the research says not so much.
[00:52:29.840 --> 00:52:33.120]   YouTube is radicalizing everybody. The research last week said maybe not.
[00:52:34.320 --> 00:52:38.160]   We went and by the way, what holds this up on this research? The fact that the platforms aren't
[00:52:38.160 --> 00:52:42.640]   giving us data. I feel like it's you're saying, what are you going to believe the research or
[00:52:42.640 --> 00:52:48.080]   your lion eyes? We're surrounded in a world by people who are influenced by this. And you say,
[00:52:48.080 --> 00:52:53.200]   Oh, what the research says, they're not. But they obviously are. I don't maybe Jeff. I don't,
[00:52:53.200 --> 00:52:59.280]   maybe you don't know these people. I know these people. And I know they they were already effed up.
[00:52:59.840 --> 00:53:06.240]   Here I am. And this becomes a way to. Sorry. Here I am. I'm going to step in and oversimplify this.
[00:53:06.240 --> 00:53:13.120]   Those people are out there. How many times have I walked outside and heard someone say,
[00:53:13.120 --> 00:53:18.320]   I saw on Facebook, I saw on Facebook that blah, blah, blah, blah, blah, blah. And I just shake
[00:53:18.320 --> 00:53:23.680]   my head thinking, Oh my gosh, this this people are believing anything. It's everywhere you go.
[00:53:23.680 --> 00:53:30.160]   And 3 billion users out there. That's a large percentage of people in that 3 billion that just
[00:53:30.160 --> 00:53:36.400]   believe whatever the hell is put on that service. I give people more respect than that. I think
[00:53:36.400 --> 00:53:40.560]   they have more. Hold on. I think they have more history than that. I don't think that they can
[00:53:40.560 --> 00:53:44.720]   be influenced that quickly by that. And this is what the story says that that fits into the
[00:53:44.720 --> 00:53:49.760]   advanced Packard view that advertising can hypnotize them and get them to change their world. That's
[00:53:49.760 --> 00:53:54.960]   a myth. I think the greater extent and it's a myth. We know advertising works. People buy
[00:53:54.960 --> 00:54:00.880]   tied because they've seen a lot of tide ads. They're not objectively deciding that Pepsi is
[00:54:00.880 --> 00:54:05.920]   better than Coke or Coke is better than Pepsi. Those ads are very effective. We know that.
[00:54:05.920 --> 00:54:12.000]   Let alone someone sitting in a big chair that buys from Instagram at least. Yeah, they ads.
[00:54:12.000 --> 00:54:18.240]   Those ads work. That's really true. I know it from my own experience. Those ads work.
[00:54:18.240 --> 00:54:25.120]   What if we look at it not just as ads, but what if we add the nuance here that politics has become
[00:54:25.120 --> 00:54:31.680]   for a lot of people not actually a way to govern, but kind of a form of entertainment?
[00:54:31.680 --> 00:54:37.840]   And if you think about us arguing about politics, you can embrace Jeff's vision of the person who's
[00:54:37.840 --> 00:54:43.440]   kind of trolling us with their belief in QAnon. Although I don't think everyone does that. But
[00:54:43.440 --> 00:54:49.840]   in the arguments there, then become more akin to a sports rivalry. I see this actually in some
[00:54:49.840 --> 00:54:55.360]   of my own family members who are like, "Stick it to the libs." But when you meet them as people,
[00:54:55.360 --> 00:55:02.320]   they are compassionate people. It's like they have a blind spot where their politics
[00:55:02.320 --> 00:55:11.200]   actually impact people that they're compassionate to and about. So there's... Obviously, I'm always
[00:55:11.200 --> 00:55:16.080]   going to argue for more nuance. But I think that's something to think about here is our understanding
[00:55:16.080 --> 00:55:21.840]   of... Sorry. I thought you stopped. No, just our understanding of politics has become divorced from
[00:55:21.840 --> 00:55:27.760]   what politics... for policies, I guess, maybe. Absolutely. Stacy, isn't it just not entertainment,
[00:55:27.760 --> 00:55:33.120]   but also identity. Yeah. It's a way to signal. I agree. It's a way to say I'm with this person.
[00:55:33.120 --> 00:55:37.840]   I also... I don't care what they say. I also... I'll say yeah. I agree. But it's not...
[00:55:37.840 --> 00:55:42.560]   It's not performative for everybody. I've seen marriages, several of them break up over this.
[00:55:42.560 --> 00:55:50.800]   It's not performative for everybody. And by the way, I take Bernstein's point absolutely and will
[00:55:50.800 --> 00:56:01.440]   agree to it. It's in big tech's interest. It's in big media's interest to buy into this narrative.
[00:56:03.760 --> 00:56:09.920]   My takeaway from this is you should take with a grain of salt any account from big tech or big
[00:56:09.920 --> 00:56:15.200]   media that all these problems are called by social media. I wouldn't say that at all. But I think
[00:56:15.200 --> 00:56:20.080]   you at this... On the same time, you cannot deny the impact of social media on this.
[00:56:20.080 --> 00:56:24.320]   Yeah. We just don't know what we don't know. Justice Fox News has an impact. MSNBC has an
[00:56:24.320 --> 00:56:29.360]   impact. Yes. Yes. All that. There is for sure an impact. I don't think there is one culprit.
[00:56:30.720 --> 00:56:34.400]   And I think that he makes a good... It's worth reading it because the point that he makes...
[00:56:34.400 --> 00:56:43.120]   He says in a way, this world is a kind of comfort. Easy to explain, easy to tweak,
[00:56:43.120 --> 00:56:48.480]   easy to sell. It's a worthy successor to the unified vision of American life produced by
[00:56:48.480 --> 00:56:54.800]   20th century television. We all want to oversimplify. That's a natural human tendency.
[00:56:54.800 --> 00:56:57.760]   It's hard to understand complexities. It's hard to understand gray areas.
[00:56:58.960 --> 00:57:02.720]   But I think this is another way of oversimplifying. He's going in the other direction of...
[00:57:02.720 --> 00:57:06.640]   Well, he's trying to counterbalance. But what I thought was great about this
[00:57:06.640 --> 00:57:09.600]   good answer to it, the oversimplifying. Yeah. That's what is there for. That's what...
[00:57:09.600 --> 00:57:14.240]   It's just... As Facey would say, we need discussion and this sparks discussion in interesting ways.
[00:57:14.240 --> 00:57:18.240]   And as I said, when I sent it to all of you in the morning, it has something for everybody
[00:57:18.240 --> 00:57:23.360]   because he's critical of Facebook and of Facebook's critics. Yeah. And then puts them
[00:57:23.360 --> 00:57:28.400]   together in an interesting way to say, what are they really believing in saying? Now, I know somebody
[00:57:28.640 --> 00:57:34.800]   who does his disinful work got insulted by this. And I don't think that was the point.
[00:57:34.800 --> 00:57:38.560]   I don't think there's a lot of good disinful work that goes on. But there's also a lot of
[00:57:38.560 --> 00:57:44.080]   stupid, well, entrepreneurship. Well, Bernstein kind of implies that it's all with a hidden agenda.
[00:57:44.080 --> 00:57:51.840]   He was in a box that disinfo people quite a bit in this piece. Yeah. But I think in a way,
[00:57:51.840 --> 00:57:58.000]   it was part of his effort to show a different end of the prism. So I don't take that terribly
[00:57:58.000 --> 00:58:05.120]   seriously. Yeah. Don't take it personally. It is a cover story on Harper's. I think it is perhaps
[00:58:05.120 --> 00:58:08.640]   a little one-sided, but it's a good hand to go to the...
[00:58:08.640 --> 00:58:12.000]   As you said, well, Harper's is like these days. Yeah. Yeah. It's provocative.
[00:58:12.000 --> 00:58:18.880]   He mocks the Aspen Institute's... He says, "Exquisitely nonpartisan commission on information
[00:58:18.880 --> 00:58:26.560]   disorder, co-chaired by Katie Couric featuring Yasmin Green from Google's Jigsaw, Gary Kasparov,
[00:58:26.560 --> 00:58:31.600]   the chess champion and Kremlin critic Alex Stamos." I mean, this is a pretty...
[00:58:31.600 --> 00:58:36.320]   Don't forget the royalty. Yeah. Glittering. Yes.
[00:58:36.320 --> 00:58:43.200]   Prince Harry. Alex Stamos from Facebook and Catherine Murdock, Rupert Murdock's estranged
[00:58:43.200 --> 00:58:49.360]   daughter, and Law important to put that word is strange in there. I could see if I were somebody
[00:58:49.360 --> 00:58:54.160]   on this commission. I might be insulted by how he's mocking it. I wasn't too happy about it.
[00:58:54.880 --> 00:59:01.920]   But I don't think that should be taken too seriously. I think it's a way to counterbalance at its
[00:59:01.920 --> 00:59:05.920]   rhetorical. I think you went a little over there. That's fine.
[00:59:05.920 --> 00:59:09.840]   Among the commission's goals to determine, quote, "How government, private industry,
[00:59:09.840 --> 00:59:16.400]   and civil society can work together to engage disaffected populations who have lost faith
[00:59:16.400 --> 00:59:22.080]   in evidence-based reality." Seems like a law for a reasonable goal. Which is a reasonable goal.
[00:59:22.080 --> 00:59:27.920]   And I hope we'll spark the kind of research that I want. And so I'm dandy with that.
[00:59:27.920 --> 00:59:31.120]   Yeah. Yeah. That's important as long as it comes out of evidence.
[00:59:31.120 --> 00:59:36.400]   He says, "This commission is the latest and most creepily named addition to a new field of
[00:59:36.400 --> 00:59:39.600]   knowledge production." That was a little funny. I can say.
[00:59:39.600 --> 00:59:42.160]   "Called big dis info." Yeah, it's funny. Yeah.
[00:59:42.160 --> 00:59:48.000]   A bunch of bucks a lot. I would like a coffee cup that says, "member of the big dis info."
[00:59:48.000 --> 00:59:56.080]   Big dis info. That's us. I just think it's so obvious that this stuff has an impact.
[00:59:56.080 --> 01:00:02.080]   But I don't think it's the villain in the play. It's just one of many.
[01:00:02.080 --> 01:00:08.000]   Well, but if we're going to one's policy to use Stacey's proper word and interventions to use mine
[01:00:08.000 --> 01:00:13.040]   around presumptions rather than around research, it's a problem. Because it may be the wrong ones,
[01:00:13.040 --> 01:00:17.280]   right? The one I've used on the show a million times is the kids are all right. They're not
[01:00:17.280 --> 01:00:21.680]   spreading that disinformation. It's Grandpa who's messing up the world. But we've invented all these
[01:00:21.680 --> 01:00:25.600]   media literacy interventions for the kids who are actually much more savvy than we get them credit
[01:00:25.600 --> 01:00:32.640]   for. Grandpa is one of Facebook. I think Grandpa has been that people have been trying to get to
[01:00:32.640 --> 01:00:36.640]   Grandpa in a while. I feel like we can see a lot of studies. A lot of studies have come out recently
[01:00:36.640 --> 01:00:44.320]   showing the correlation between people's lack of trust in government and all of that with the
[01:00:44.320 --> 01:00:51.600]   prevalence of Fox News. So I think there's a growing awareness. The challenge with research,
[01:00:51.600 --> 01:00:58.800]   though, Jeff, is when you're looking for data, especially with social sciences, you can find it.
[01:00:58.800 --> 01:01:03.760]   Yeah. Oh, yeah. You can make these correlations. That's great. You also can't find some of them,
[01:01:03.760 --> 01:01:06.560]   Stacey, because the platforms are the ones who have it and they won't give it to you.
[01:01:06.560 --> 01:01:10.960]   Yeah, we talked about that as well. That's key. Yeah.
[01:01:11.680 --> 01:01:13.680]   No, I'm with you, Stacey. I have a little bit of...
[01:01:13.680 --> 01:01:19.440]   Interesting. I don't have a lot of faith in, quote, research as being the definitive
[01:01:19.440 --> 01:01:23.920]   answer to any of these questions. Evidence, then. Call it evidence.
[01:01:23.920 --> 01:01:31.840]   I also think that, I mean, let's just get on the soapbox about America. I feel like if people were
[01:01:31.840 --> 01:01:37.280]   a little bit more secure in their livelihoods, I feel like if people were a bit more secure in
[01:01:37.280 --> 01:01:42.240]   their neighborliness, I feel like we could be better. But that's just not happening right now.
[01:01:42.240 --> 01:01:47.520]   I think the latest census is the basis of so much of it. That for the first time,
[01:01:47.520 --> 01:01:54.000]   white population in this country went down, relatively, and that is scaring some people who
[01:01:54.000 --> 01:02:00.960]   are losing the hegemony they enjoyed for four centuries. And I think we can't not
[01:02:00.960 --> 01:02:06.800]   look at deeper roots like that in this discussion and to think that it's some new thing that came
[01:02:06.800 --> 01:02:11.040]   along that made us worse as a country. I mean, I'm the first one to yell about Fox News, and I
[01:02:11.040 --> 01:02:16.960]   think it's done terrible things. But it started before Fox News. It started before talk radio.
[01:02:16.960 --> 01:02:20.320]   There's also many causes there. You and I will agree. There's many causes.
[01:02:20.320 --> 01:02:25.840]   It's complicated. And I also would point out that, yes, that might be a white terror over changing
[01:02:25.840 --> 01:02:31.120]   demographics might be part of it. But let's not forget how unpredictable Hispanic vote was and is.
[01:02:32.800 --> 01:02:38.000]   It is not necessarily the case that Hispanics or people of color vote is a block either.
[01:02:38.000 --> 01:02:42.960]   So I don't, you know, I don't, I think it's, I think what's going on is a little more complicated.
[01:02:42.960 --> 01:02:46.800]   I think it's very complicated. I don't think we really can understand it. And I certainly
[01:02:46.800 --> 01:02:51.920]   agree that we shouldn't blame big tech or social media for our woes, whether, you know,
[01:02:51.920 --> 01:02:58.400]   contributory or not, they're not to blame for our woes. If they're successful, those ads are
[01:02:58.400 --> 01:03:04.000]   not necessarily the roots because they fall on fertile ground, right? John, John, can you can you
[01:03:04.000 --> 01:03:09.760]   take that as a snippet that I can, I can refer to back. I've always thought that this is nothing new.
[01:03:09.760 --> 01:03:14.320]   What is it? Jesus said you cast your seeds upon the ground.
[01:03:14.320 --> 01:03:19.280]   Sometimes it lands in fertile ground, sometimes not on good ground. Yep.
[01:03:19.280 --> 01:03:23.200]   Unfortunately, in this case, the good ground is bad ground.
[01:03:24.960 --> 01:03:31.600]   That's the really interesting thing because what happens is the bad guys use our own beliefs
[01:03:31.600 --> 01:03:36.000]   against us, right? We believe in open information. Well, that's very easy to manipulate.
[01:03:36.000 --> 01:03:39.680]   And so that's what's happening is, is a lot of the
[01:03:39.680 --> 01:03:48.080]   virtues we saw in an open media ecosystem are now being used badly. And we don't know what to do
[01:03:48.080 --> 01:03:53.120]   about it. That's part of his point, I think. But thank you. That was enough. I don't mean to take over.
[01:03:53.120 --> 01:03:57.120]   It's a good topic. It's a block of the piece. I felt there was a little
[01:03:57.120 --> 01:04:03.520]   facile, personally, but yeah, a little blip. Yeah. But not but but point well taken.
[01:04:03.520 --> 01:04:11.360]   Let's see here. What else would Jeff like to talk about? Oh, it's time we hear from another
[01:04:11.360 --> 01:04:18.560]   quarter. CES 2022 is on baby. Just bring your COVID card. He's going.
[01:04:20.320 --> 01:04:24.880]   I got your on. Could you could edit it? You put some crickets in there right there at that point.
[01:04:24.880 --> 01:04:34.160]   I have my vaccination card that wants to go. You really want you. I don't want to go. You had such a
[01:04:34.160 --> 01:04:40.000]   good time at CES when we went January 2020. The last conference, I feel like.
[01:04:42.480 --> 01:04:52.400]   I really I'm fascinated by what COVID has done in this country and then the return of COVID is done
[01:04:52.400 --> 01:04:57.440]   and how quickly people were willing to go pull back. Some people and other people said no, no,
[01:04:57.440 --> 01:05:03.360]   forward. I'm fascinated by this. And I'm mostly fascinated by the drastic changes
[01:05:03.360 --> 01:05:08.560]   that are going to occur in our society. People not coming to work because they can work from home.
[01:05:08.560 --> 01:05:15.040]   And I have a feeling that conferences just like malls are going to be one of the casualties of
[01:05:15.040 --> 01:05:23.440]   yes, COVID. Yes, yes. Well, WPPI is still happening. That's the photography. I think these are
[01:05:23.440 --> 01:05:31.840]   vestigial spasms of a corpse that is already dead. CD is still happening. Yeah, CD. Adobe Max
[01:05:32.720 --> 01:05:38.800]   they announced their dates for October, but I believe it's all virtual and it's 100% free again.
[01:05:38.800 --> 01:05:47.600]   So that's after after CES 2020 when you guys went come March 1st, did you look back and say,
[01:05:47.600 --> 01:05:52.880]   what were we thinking going somewhere? We all did. In fact, everybody's very nervous.
[01:05:52.880 --> 01:05:55.040]   I was nervous. Yeah. Yeah. Larry Maggid.
[01:05:55.040 --> 01:06:02.000]   So Larry put up a post on Facebook, I think, or somewhere. I saw it somehow.
[01:06:02.880 --> 01:06:09.680]   Saying I, there was somebody at CES with COVID. I met with them and I met with all of you who are
[01:06:09.680 --> 01:06:16.160]   getting this message. Did anybody get sick? I think none of us got sick, but that wasn't the Delta
[01:06:16.160 --> 01:06:22.880]   variant. Yeah. Yeah. He looked bad that day when we saw him. He looked bad. Yeah. Yeah. He was,
[01:06:22.880 --> 01:06:29.120]   he got really sick. Lisa got really sick, but she did. Lisa did not get COVID as far as I know.
[01:06:29.120 --> 01:06:34.720]   We did the antibody test and it said it was negative. We had a pretty terrible faculty meeting today
[01:06:34.720 --> 01:06:40.320]   to speak out of school where the students are supposedly required to be vaccinated,
[01:06:40.320 --> 01:06:43.760]   but now it turns out they're not vaccinated. Faculty and staff are not required to be vaccinated.
[01:06:43.760 --> 01:06:49.040]   A lot of my colleagues have kids at home who can't be vaccinated. Yeah. And recently,
[01:06:49.040 --> 01:06:55.920]   a lot of anger and nerves about this, including from yours truly. Yeah, but what do you do? That's
[01:06:55.920 --> 01:07:01.440]   the thing. I understand absolutely the anxiety. This is provoking. And I don't know what you do. So,
[01:07:01.440 --> 01:07:06.880]   mandate vaccinations for one thing and you take care of your own people. Well, this is one thing
[01:07:06.880 --> 01:07:10.880]   that see the Consumer Technology Association is doing. They're going to not good for them.
[01:07:10.880 --> 01:07:17.360]   Require vaccination vaccination. It's not one of those. Not vaccination test. Masks
[01:07:17.360 --> 01:07:25.200]   will probably be required in all the public indoor spaces. The organization said it's assessing
[01:07:25.200 --> 01:07:29.760]   whether to accept proof of a positive antibody test as an alternative requirement.
[01:07:29.760 --> 01:07:35.760]   But they're going to defer that until closer to the date. That's part of the problem is we're
[01:07:35.760 --> 01:07:40.960]   in Terra incognito. No one knows what's going to happen next month. There's a lambda variant.
[01:07:40.960 --> 01:07:48.320]   No one knows. Yeah. Yeah. I'm supposed to fly to Michigan to give a speech at the end of October
[01:07:48.320 --> 01:07:53.680]   that was canceled from April of 2020. Wow.
[01:07:53.680 --> 01:07:57.440]   And I don't know if they're going to cancel. I was like, look, y'all can have your money back.
[01:07:57.440 --> 01:08:03.360]   I'm happy to do something virtually for you. I just don't know. They don't know. No one knows.
[01:08:03.360 --> 01:08:09.120]   That's the problem. That's the problem. And the people who are saying we have to get back to normal,
[01:08:09.120 --> 01:08:15.600]   I totally agree that I don't think I don't want to live like this. I would hate from my daughter
[01:08:15.600 --> 01:08:22.720]   to grow up in a world that has this kind of object fear about being in public with people.
[01:08:22.720 --> 01:08:31.920]   But we can't do it unless we have, I don't know, vaccines, more people vaccinated.
[01:08:31.920 --> 01:08:39.120]   I feel like we were briefly seduced by the notion that vaccines could fix this.
[01:08:39.120 --> 01:08:46.240]   And now we're getting disabused of that notion. I think vaccines could have done a lot more to
[01:08:46.240 --> 01:08:51.920]   help if we had got. I mean, but we always knew that you had to get to a certain level with them.
[01:08:51.920 --> 01:08:55.040]   We always knew that if half the people were vaccinated, it wasn't going to work.
[01:08:55.040 --> 01:09:00.240]   We also underestimated the strength of breakthrough of Delta and breakthrough infections.
[01:09:00.240 --> 01:09:03.680]   Maybe normal people did. I felt like we were.
[01:09:03.680 --> 01:09:06.880]   We knew Delta looks. We knew that was going to happen.
[01:09:06.880 --> 01:09:11.680]   I don't know. I think people are willing to now pull back a little bit more than they were.
[01:09:11.680 --> 01:09:15.280]   I think there's a lot of trepidation. Kids are going back to school today.
[01:09:15.280 --> 01:09:18.640]   In California. Kids are already back in school.
[01:09:18.640 --> 01:09:22.960]   And I started yesterday. There's a lot of trepidation.
[01:09:22.960 --> 01:09:26.800]   I just feel like nobody knows what's going to happen.
[01:09:26.800 --> 01:09:32.240]   If I had a kid under the age of 12 who couldn't be vaccinated, I mean, I look at this and I'm like,
[01:09:32.240 --> 01:09:40.400]   man, what do you do? This is where I feel like we're entering into this level.
[01:09:40.400 --> 01:09:44.640]   We talk about distrust in the government. I think what we're seeing right here is
[01:09:45.840 --> 01:09:51.360]   visceral reaction to a failure of public policy that has been hurt us for a long time.
[01:09:51.360 --> 01:09:56.640]   And not just in the QAnon way, but in an actual way that affects real people.
[01:09:56.640 --> 01:10:03.120]   Some of this was misguided. Just as it was misguided trust in the New York Times and CVS,
[01:10:03.120 --> 01:10:06.960]   misguided trust in public health officials that were now learning.
[01:10:06.960 --> 01:10:11.120]   That's unfair because I think it was the science was changing.
[01:10:11.120 --> 01:10:13.520]   The knowledge was changing. That's what I'm saying.
[01:10:13.520 --> 01:10:19.040]   We've all learned that it isn't as certain as they might have pretended in past.
[01:10:19.040 --> 01:10:23.440]   We've seen the sausage being made.
[01:10:23.440 --> 01:10:28.240]   I think once you've seen the sausage being made, you never enjoy those bangs.
[01:10:28.240 --> 01:10:29.760]   It's a pretty random process of sausage.
[01:10:29.760 --> 01:10:30.880]   That's very impressive.
[01:10:30.880 --> 01:10:32.640]   Jeff, what the heck are you tweeting?
[01:10:32.640 --> 01:10:34.560]   What did he tweet now?
[01:10:34.560 --> 01:10:35.760]   Who?
[01:10:35.760 --> 01:10:36.080]   You.
[01:10:36.080 --> 01:10:40.400]   Jeff, how are you talking about this and tweeting about snakes in the spice aisle?
[01:10:41.600 --> 01:10:45.440]   It was a simple. I saw you. I could have brought it up on the show and I spared you.
[01:10:45.440 --> 01:10:50.560]   I'm looking over on Twitter just to check.
[01:10:50.560 --> 01:10:52.080]   I'm like, oh my god.
[01:10:52.080 --> 01:10:56.720]   I don't understand. You did this 49 seconds ago.
[01:10:56.720 --> 01:10:57.920]   Yeah.
[01:10:57.920 --> 01:11:00.240]   While he was arguing with us about other things.
[01:11:00.240 --> 01:11:00.960]   Why, boys?
[01:11:00.960 --> 01:11:02.880]   Are you ADHD a little or?
[01:11:02.880 --> 01:11:05.120]   No, I'm just on line, man.
[01:11:05.120 --> 01:11:07.440]   Wow.
[01:11:07.440 --> 01:11:08.640]   That's impressive.
[01:11:08.640 --> 01:11:10.080]   I am internet man.
[01:11:11.040 --> 01:11:14.560]   I will say the snake in the spice aisle is very compelling in the fact that it was
[01:11:14.560 --> 01:11:14.960]   not bad.
[01:11:14.960 --> 01:11:15.680]   I'm actually on the show.
[01:11:15.680 --> 01:11:16.160]   I didn't know.
[01:11:16.160 --> 01:11:17.840]   I could have done it for a closer.
[01:11:17.840 --> 01:11:18.800]   Yeah, but it's Australia.
[01:11:18.800 --> 01:11:19.760]   That's what always amuses me.
[01:11:19.760 --> 01:11:20.480]   Australia.
[01:11:20.480 --> 01:11:21.280]   You don't want to go there.
[01:11:21.280 --> 01:11:22.240]   Things will kill you.
[01:11:22.240 --> 01:11:23.600]   It will kill you in the spice aisle.
[01:11:23.600 --> 01:11:27.360]   A nine foot python in the F in spice aisle.
[01:11:27.360 --> 01:11:31.840]   Python, it's going to take a while if it's going to kill you because it's got a
[01:11:31.840 --> 01:11:32.240]   squeeze.
[01:11:32.240 --> 01:11:32.960]   It's a little stress.
[01:11:32.960 --> 01:11:34.800]   I don't move very fast anymore, Stacey.
[01:11:34.800 --> 01:11:36.000]   So it can happen.
[01:11:36.000 --> 01:11:39.760]   Actually, we've just saw some statistics about
[01:11:40.880 --> 01:11:42.640]   death by reptiles in Australia.
[01:11:42.640 --> 01:11:44.080]   It's actually much better than you think.
[01:11:44.080 --> 01:11:47.520]   Not bad.
[01:11:47.520 --> 01:11:48.880]   You just need the data.
[01:11:48.880 --> 01:11:49.840]   Just need the data.
[01:11:49.840 --> 01:11:49.840]   That's all the data.
[01:11:49.840 --> 01:11:49.840]   That's the data.
[01:11:49.840 --> 01:11:50.800]   That's the data.
[01:11:50.800 --> 01:11:51.280]   That's the data.
[01:11:51.280 --> 01:11:51.440]   Right.
[01:11:51.440 --> 01:11:58.960]   We all live with these biases, spiders and snakes as bad as they are.
[01:11:58.960 --> 01:12:00.880]   Don't seem to kill very many people in Australia.
[01:12:00.880 --> 01:12:01.840]   Maybe they just know better.
[01:12:01.840 --> 01:12:02.560]   I don't know.
[01:12:02.560 --> 01:12:03.440]   Hey, good news.
[01:12:03.440 --> 01:12:05.840]   Spence we're talking about vaccines.
[01:12:06.400 --> 01:12:11.040]   Modana is about to begin trials for an mRNA vaccine for HIV.
[01:12:11.040 --> 01:12:13.840]   This is incredibly good.
[01:12:13.840 --> 01:12:14.480]   It's awesome.
[01:12:14.480 --> 01:12:17.840]   Based on how many friends you lost.
[01:12:17.840 --> 01:12:22.480]   Yeah, it gets that idea of the M-H-R-N-A.
[01:12:22.480 --> 01:12:26.800]   M-R-N-A vaccines being like software.
[01:12:26.800 --> 01:12:27.120]   Yeah.
[01:12:27.120 --> 01:12:28.960]   I love it.
[01:12:28.960 --> 01:12:29.440]   I love it.
[01:12:29.440 --> 01:12:36.000]   They were such success in sequencing the COVID-19 genome and then creating literally,
[01:12:36.000 --> 01:12:39.920]   it only took them a weekend to sequence it and create a vaccine within a week.
[01:12:39.920 --> 01:12:47.360]   All the time was wasted and not wasted spent in trials to make sure it wasn't going to kill
[01:12:47.360 --> 01:12:50.640]   anybody, but they had a vaccine last spring.
[01:12:50.640 --> 01:12:58.560]   And so the same technology now is being used on something a virus has been intractable for 40 years.
[01:12:58.560 --> 01:13:05.040]   All of a sudden, they're also reportedly working on an influenza vaccine based on mRNA.
[01:13:06.000 --> 01:13:07.040]   That makes sense.
[01:13:07.040 --> 01:13:07.520]   Yeah.
[01:13:07.520 --> 01:13:08.960]   Science.
[01:13:08.960 --> 01:13:14.960]   We kind of knew this would happen actually was I was talking with Andy Weir, the author of
[01:13:14.960 --> 01:13:19.680]   "The Martian" interviewing him at his new book and he was saying,
[01:13:19.680 --> 01:13:25.040]   "I don't think we understand what a massive breakthrough mRNA vaccines are."
[01:13:25.040 --> 01:13:25.040]   Oh.
[01:13:25.040 --> 01:13:28.160]   He said, "This is the last pandemic.
[01:13:28.160 --> 01:13:30.240]   This is the last pandemic."
[01:13:30.240 --> 01:13:32.000]   Well, knock some wood please, Andy.
[01:13:32.000 --> 01:13:32.320]   Yeah.
[01:13:32.320 --> 01:13:32.960]   Knock wood.
[01:13:32.960 --> 01:13:34.800]   Question.
[01:13:34.800 --> 01:13:36.800]   Well, go ahead, Stacy.
[01:13:36.800 --> 01:13:39.120]   No, I was going to ask his, "Am I?"
[01:13:39.120 --> 01:13:42.400]   God, I can't message our RNA vaccines.
[01:13:42.400 --> 01:13:46.160]   Are they only good against viruses?
[01:13:46.160 --> 01:13:48.000]   Would they also work against bacteria?
[01:13:48.000 --> 01:13:53.760]   I think they're particularly tuned to viruses because of the way viruses work,
[01:13:53.760 --> 01:13:55.040]   which is to invade the cell.
[01:13:55.040 --> 01:13:56.080]   Right.
[01:13:56.080 --> 01:14:02.320]   That's a good question because, of course, you're just creating any,
[01:14:02.320 --> 01:14:05.520]   ultimately you're creating T-cells in antibodies to fight the virus.
[01:14:05.520 --> 01:14:08.880]   I suppose you could do that with...
[01:14:08.880 --> 01:14:10.480]   I'm just thinking about malaria.
[01:14:10.480 --> 01:14:12.720]   No, that's a parasite disease that you've got.
[01:14:12.720 --> 01:14:14.720]   There's no vaccine for that.
[01:14:14.720 --> 01:14:15.600]   Bacterial disease.
[01:14:15.600 --> 01:14:17.600]   I have to say that like the big diseases.
[01:14:17.600 --> 01:14:19.040]   Well, the virus is...
[01:14:19.040 --> 01:14:25.840]   I think that the real frontier is to do this kind of work around cancer.
[01:14:25.840 --> 01:14:26.160]   Yeah.
[01:14:26.160 --> 01:14:28.480]   Very, very interesting.
[01:14:28.480 --> 01:14:29.520]   Very, very interesting.
[01:14:29.520 --> 01:14:33.040]   Curiosity question because I think this will be a debate that comes up.
[01:14:33.040 --> 01:14:39.760]   So I would be due in eight months in late October for a booster under the CDAA,
[01:14:39.760 --> 01:14:43.360]   the government's HIS rules today.
[01:14:43.360 --> 01:14:49.520]   So the debate is, do you get the booster?
[01:14:49.520 --> 01:14:51.120]   Do I get the third Moderna?
[01:14:51.120 --> 01:14:56.080]   Or do you wait a little longer hoping that there's a version of Moderna that's specific
[01:14:56.080 --> 01:14:57.360]   to the Delta or the Lambda?
[01:14:58.240 --> 01:14:59.600]   Ask your doctor, Jeff.
[01:14:59.600 --> 01:15:00.960]   Yes, I'm going to.
[01:15:00.960 --> 01:15:01.760]   You're my doctor.
[01:15:01.760 --> 01:15:03.440]   We're not the people who know.
[01:15:03.440 --> 01:15:03.600]   Who know?
[01:15:03.600 --> 01:15:08.160]   This is like going on Facebook and asking your friends these questions.
[01:15:08.160 --> 01:15:08.720]   Lisa and I...
[01:15:08.720 --> 01:15:11.200]   I was curious if I have this conversation all the time.
[01:15:11.200 --> 01:15:11.680]   I'm sure they say...
[01:15:11.680 --> 01:15:13.280]   Lisa, I have this conversation all the time.
[01:15:13.280 --> 01:15:14.240]   She said, "What can I get the booster?
[01:15:14.240 --> 01:15:14.960]   I'm getting the booster."
[01:15:14.960 --> 01:15:17.840]   I said, I'm just saying, "Wait, your doctor will tell you."
[01:15:17.840 --> 01:15:20.160]   Your doctor will let you know.
[01:15:20.160 --> 01:15:21.040]   You have a good doctor.
[01:15:21.040 --> 01:15:22.720]   What I'm curious about is the emotions of it.
[01:15:22.720 --> 01:15:24.000]   What's the...
[01:15:26.640 --> 01:15:31.680]   I'm going up a wrong tree here, but I'm curious how people will be asking about this and reacting
[01:15:31.680 --> 01:15:34.480]   to it and playing the odds of the science.
[01:15:34.480 --> 01:15:35.840]   Let's just find it interesting.
[01:15:35.840 --> 01:15:36.240]   That's all.
[01:15:36.240 --> 01:15:38.560]   That's my doctor.
[01:15:38.560 --> 01:15:40.800]   Yeah, that's a good question.
[01:15:40.800 --> 01:15:44.320]   I guess now the latest is...
[01:15:44.320 --> 01:15:50.000]   The CDC is expected to announce that boosters will be suggested after eight months after you get
[01:15:50.000 --> 01:15:50.560]   the initial one.
[01:15:50.560 --> 01:15:51.520]   Biden said it this afternoon.
[01:15:51.520 --> 01:15:52.240]   He said it today?
[01:15:52.240 --> 01:15:52.720]   Okay, good.
[01:15:52.720 --> 01:15:54.800]   So that was the speculation now.
[01:15:54.800 --> 01:15:55.840]   It's confirmed.
[01:15:55.840 --> 01:15:58.080]   Which is fine with me, and it's the same one.
[01:15:58.080 --> 01:15:59.440]   It's just another one of the same one.
[01:15:59.440 --> 01:16:00.400]   And that really...
[01:16:00.400 --> 01:16:04.240]   What I saw was a significant improvement in effectiveness,
[01:16:04.240 --> 01:16:05.360]   like on the order of 200%.
[01:16:05.360 --> 01:16:06.720]   Yeah.
[01:16:06.720 --> 01:16:07.440]   Nice.
[01:16:07.440 --> 01:16:09.600]   So it sounds like it's worth doing.
[01:16:09.600 --> 01:16:12.560]   Let's see.
[01:16:12.560 --> 01:16:16.880]   Congratulations to Amazon now officially.
[01:16:16.880 --> 01:16:21.440]   The world's biggest e-commerce company outside of China.
[01:16:21.440 --> 01:16:23.680]   This is a lot.
[01:16:23.680 --> 01:16:28.080]   This article in The Times was fascinating because it goes back in time.
[01:16:28.080 --> 01:16:35.040]   In the 1940s, the number one retailer in America was...
[01:16:35.040 --> 01:16:36.160]   What guesses?
[01:16:36.160 --> 01:16:36.640]   Anybody?
[01:16:36.640 --> 01:16:37.600]   Sears Robot.
[01:16:37.600 --> 01:16:38.880]   Sears Robot and Co.
[01:16:38.880 --> 01:16:39.760]   Before Sears.
[01:16:39.760 --> 01:16:41.200]   It was A&P.
[01:16:41.200 --> 01:16:42.480]   A&P?
[01:16:42.480 --> 01:16:43.680]   A&P was so big...
[01:16:43.680 --> 01:16:44.400]   That makes sense.
[01:16:44.400 --> 01:16:49.040]   That the government was considering antitrust regulations against it in the '40s.
[01:16:49.040 --> 01:16:50.640]   Unbelievable.
[01:16:50.640 --> 01:16:50.960]   Wow.
[01:16:52.000 --> 01:16:54.400]   You know, and this kind of maybe is informing...
[01:16:54.400 --> 01:16:56.880]   Maybe you don't need to do these antitrust regulations because
[01:16:56.880 --> 01:16:59.840]   Times change in companies are on top now.
[01:16:59.840 --> 01:17:02.480]   So A&P gave point.
[01:17:02.480 --> 01:17:04.400]   There's a book that I've got to mention here.
[01:17:04.400 --> 01:17:09.360]   I think I've mentioned the show before, but if you're interested in this, I highly recommend it.
[01:17:09.360 --> 01:17:14.160]   The great A&P and the struggle for small business in America.
[01:17:14.160 --> 01:17:16.560]   Oh, you mentioned this last year's in Europe.
[01:17:16.560 --> 01:17:17.040]   Yeah.
[01:17:17.040 --> 01:17:18.800]   Really good by Mark Loeberson.
[01:17:19.360 --> 01:17:24.000]   And I recommend it because what it shows is the parallelogram here to...
[01:17:24.000 --> 01:17:31.120]   A&P chain stores came in and ruined the Mon-Paw neighborhood store.
[01:17:31.120 --> 01:17:32.480]   Right? A preview of Walmart.
[01:17:32.480 --> 01:17:35.680]   But the A&P was the first villain in this.
[01:17:35.680 --> 01:17:37.760]   They were seen as the Amazon of the day and they were seen as awful.
[01:17:37.760 --> 01:17:40.160]   There was tons of protective legislation against them.
[01:17:40.160 --> 01:17:41.600]   They were seen as terrible.
[01:17:41.600 --> 01:17:42.400]   It was awful.
[01:17:42.400 --> 01:17:45.600]   The fact that they lowered prices was unfair.
[01:17:45.600 --> 01:17:49.360]   And there was laws passed to them, make them raise the prices on consumers.
[01:17:49.360 --> 01:17:56.560]   And it's just amazing how similar this is because it's once mass media was made possible to advertise
[01:17:56.560 --> 01:18:00.240]   something like the A&P and made it possible with that in transportation.
[01:18:00.240 --> 01:18:03.280]   And it created the exact same kind of structure we see in the transition today.
[01:18:03.280 --> 01:18:04.880]   It's a wonderful parallel.
[01:18:04.880 --> 01:18:11.040]   So it wasn't until the '60s that A&P was superseded by Sears.
[01:18:11.040 --> 01:18:15.520]   Sears overtook A&P as the largest retail in the early 1960s.
[01:18:15.520 --> 01:18:19.840]   By targeting middle-class shoppers in the suburbs and expanding the department store model.
[01:18:19.840 --> 01:18:26.240]   Then the Five and Dime, the Walton Five and Dime in Bentonville, Arkansas.
[01:18:26.240 --> 01:18:29.040]   That's the original one.
[01:18:29.040 --> 01:18:32.640]   Turned into a behemoth.
[01:18:32.640 --> 01:18:37.680]   This was founded in 1962, right when Sears kind of took over from A&P.
[01:18:37.680 --> 01:18:45.040]   By the '90s, Walmart had surpassed Sears, opening thousands of stores, buying up competitors.
[01:18:46.000 --> 01:18:50.240]   And this seems to be kind of where they overlap.
[01:18:50.240 --> 01:18:56.160]   Just as Walmart beat Sears, this guy named Jeff Bezos, his hedge fund manager,
[01:18:56.160 --> 01:18:59.680]   drives out to Seattle with his wife and starts Amazon.
[01:18:59.680 --> 01:19:07.600]   And the reason this is all coming up is because today Amazon became bigger than Walmart.
[01:19:07.600 --> 01:19:16.960]   Over the last 12 months, Amazon's revenue was 610, retail only, 610 billion dollars beating
[01:19:16.960 --> 01:19:22.800]   Walmart's sales posted yesterday of $566 billion.
[01:19:22.800 --> 01:19:24.960]   So Amazon, except for China.
[01:19:24.960 --> 01:19:28.320]   You know who's bigger than Amazon?
[01:19:28.320 --> 01:19:29.440]   Of course, Alibaba.
[01:19:29.440 --> 01:19:30.720]   Alibaba, right?
[01:19:30.720 --> 01:19:31.440]   In China.
[01:19:31.440 --> 01:19:31.840]   Yeah.
[01:19:31.840 --> 01:19:33.680]   They sell it to a lot more people.
[01:19:33.680 --> 01:19:34.960]   Yeah.
[01:19:35.680 --> 01:19:37.680]   They got a billion and a half customers.
[01:19:37.680 --> 01:19:38.880]   And they have some advantages.
[01:19:38.880 --> 01:19:40.800]   Yeah.
[01:19:40.800 --> 01:19:43.600]   Well, they might say disadvantages now.
[01:19:43.600 --> 01:19:44.400]   I don't know.
[01:19:44.400 --> 01:19:45.680]   Well, that's interesting.
[01:19:45.680 --> 01:19:46.720]   Jack, may not be.
[01:19:46.720 --> 01:19:47.200]   Very interesting.
[01:19:47.200 --> 01:19:47.520]   Yeah.
[01:19:47.520 --> 01:19:50.800]   So Amazon, huge.
[01:19:50.800 --> 01:19:57.120]   And but I think it's really important to understand how these companies without any
[01:19:57.120 --> 01:20:03.680]   governmental intervention have superseded each other every few decades as technology changes, right?
[01:20:04.560 --> 01:20:10.240]   I think it's interesting to see how technology is making it possible for Amazon because I can
[01:20:10.240 --> 01:20:17.040]   just think back to a decade or two ago being in small town, North Kaculaki, and having a
[01:20:17.040 --> 01:20:24.480]   discussion with people wanting to buy products and refusing to figure out Amazon.com, they'd
[01:20:24.480 --> 01:20:26.320]   rather just go to the Walmart.
[01:20:26.320 --> 01:20:26.640]   Right.
[01:20:26.640 --> 01:20:29.760]   Well, obviously that demographic's shifting.
[01:20:29.760 --> 01:20:31.840]   But that's why Sears became so big, right?
[01:20:31.840 --> 01:20:33.360]   Because the catalog.
[01:20:33.360 --> 01:20:34.160]   But that's Sears.
[01:20:34.160 --> 01:20:34.800]   Yeah.
[01:20:34.800 --> 01:20:37.360]   The mail order was kind of Sears's big thing.
[01:20:37.360 --> 01:20:37.360]   Right.
[01:20:37.360 --> 01:20:38.960]   But that was the internet of...
[01:20:38.960 --> 01:20:40.320]   That was the tech.
[01:20:40.320 --> 01:20:41.920]   That was the tech of that time, right?
[01:20:41.920 --> 01:20:43.200]   That was the internet of that time.
[01:20:43.200 --> 01:20:48.160]   Well, also the creation of the department store was a phenomenon.
[01:20:48.160 --> 01:20:48.880]   Exactly.
[01:20:48.880 --> 01:20:49.440]   Another one.
[01:20:49.440 --> 01:20:52.560]   And what you had was you didn't have the consolidation of federated.
[01:20:52.560 --> 01:20:56.640]   You had every city had its own family-owned department stores,
[01:20:56.640 --> 01:20:58.640]   and they were huge newspaper advertisers.
[01:20:59.600 --> 01:21:02.160]   But they too agglomerated.
[01:21:02.160 --> 01:21:05.040]   Mrs. Jones's dress store?
[01:21:05.040 --> 01:21:05.680]   Dead.
[01:21:05.680 --> 01:21:07.520]   Mr. Smith's tie store?
[01:21:07.520 --> 01:21:07.840]   Dead.
[01:21:07.840 --> 01:21:12.640]   So all these bigger things kept eating up to the smaller things that came before.
[01:21:12.640 --> 01:21:17.040]   Surprising how many years it took for Home Depot to kill the neighborhood hardware store?
[01:21:17.040 --> 01:21:20.720]   It's actually shocking that A&P was the number one retail in America
[01:21:20.720 --> 01:21:22.720]   until 1965 when it was beat by Sears.
[01:21:22.720 --> 01:21:26.160]   I mean, I would have thought that happened a long time sooner earlier than that.
[01:21:26.160 --> 01:21:29.040]   Well, people didn't buy as much stuff back then.
[01:21:29.040 --> 01:21:29.680]   No, that's true.
[01:21:29.680 --> 01:21:30.640]   So groceries?
[01:21:30.640 --> 01:21:30.800]   Yeah.
[01:21:30.800 --> 01:21:35.280]   Probably in food costs have gone down so much compared to what a family of four
[01:21:35.280 --> 01:21:38.400]   used to spend on percentage of their income spent on food back then.
[01:21:38.400 --> 01:21:38.720]   Right.
[01:21:38.720 --> 01:21:40.160]   Right.
[01:21:40.160 --> 01:21:42.560]   The great Atlantic and Pacific Tea Company.
[01:21:42.560 --> 01:21:44.800]   I like it.
[01:21:44.800 --> 01:21:45.200]   Isn't that?
[01:21:45.200 --> 01:21:46.080]   I wish they kept that.
[01:21:46.080 --> 01:21:47.600]   They make sodas, don't they?
[01:21:47.600 --> 01:21:48.160]   A&P?
[01:21:48.160 --> 01:21:49.760]   No.
[01:21:49.760 --> 01:21:50.320]   No.
[01:21:50.320 --> 01:21:50.960]   A&W.
[01:21:50.960 --> 01:21:56.560]   A little later in the alphabet stays.
[01:21:56.560 --> 01:21:57.520]   Aces America.
[01:21:57.520 --> 01:21:58.080]   I'm getting there.
[01:21:58.080 --> 01:22:00.640]   All right.
[01:22:00.640 --> 01:22:03.040]   We'll have more with our esteemed panel.
[01:22:03.040 --> 01:22:05.760]   Aunt Pruitt, community manager at our club,
[01:22:05.760 --> 01:22:10.320]   Twit, as well as host of Hands-off Photography and regular host here on Twiggood to have you.
[01:22:10.320 --> 01:22:15.120]   Sad to say, A&P, had to go back in the home office because of COVID.
[01:22:15.120 --> 01:22:17.440]   We're back on restriction.
[01:22:17.440 --> 01:22:19.280]   I'm all alone in the studio again.
[01:22:19.280 --> 01:22:20.480]   Yeah.
[01:22:20.480 --> 01:22:22.320]   Only see his lighting looks so much better.
[01:22:22.320 --> 01:22:22.640]   I know.
[01:22:22.640 --> 01:22:23.760]   It really looks a lot better.
[01:22:23.760 --> 01:22:26.240]   But I don't look as small.
[01:22:26.240 --> 01:22:27.600]   I'm not trying to insult your studio people.
[01:22:27.600 --> 01:22:28.560]   I'm sitting next to me.
[01:22:28.560 --> 01:22:33.040]   Jeff Jarvis, Buzzmachine.com.
[01:22:33.040 --> 01:22:33.680]   Good to have you.
[01:22:33.680 --> 01:22:37.920]   Of course, Stacey, you can buy some Stacey on IOT.com.
[01:22:37.920 --> 01:22:43.040]   Remember, Yik Yak is back, baby.
[01:22:43.040 --> 01:22:44.320]   I think you need to forget it.
[01:22:44.320 --> 01:22:44.560]   All right.
[01:22:44.560 --> 01:22:48.960]   We talked about Yik Yak when it was all the rage and then a scandal
[01:22:48.960 --> 01:22:50.560]   that what is it?
[01:22:50.560 --> 01:22:52.320]   2017, it went out of business?
[01:22:52.320 --> 01:22:55.920]   2013 through 2017.
[01:22:55.920 --> 01:23:00.560]   The whole premise was to anonymous, that's the bad word,
[01:23:00.560 --> 01:23:03.840]   social network for people within five miles of you.
[01:23:03.840 --> 01:23:08.880]   And it was actually ended up being very big in colleges and high schools.
[01:23:08.880 --> 01:23:13.680]   But because it was anonymous, it also became very popular with bullies,
[01:23:13.680 --> 01:23:14.960]   trolls, and gossips.
[01:23:14.960 --> 01:23:22.160]   In fact, it became a haven for bullying and harassment threats and eventually shut down.
[01:23:22.160 --> 01:23:24.480]   Somebody must have bought it.
[01:23:24.480 --> 01:23:26.800]   It was once valued at $400 million.
[01:23:26.800 --> 01:23:29.040]   That's so funny.
[01:23:29.040 --> 01:23:31.680]   It's what a bubble, right?
[01:23:31.680 --> 01:23:36.320]   And then it shut down in 2017.
[01:23:36.320 --> 01:23:38.640]   Square bought a lot of the original team.
[01:23:38.640 --> 01:23:44.720]   Mashable has the story that they're back on the app store,
[01:23:44.720 --> 01:23:47.200]   but they say it's unclear who's behind the app now.
[01:23:47.200 --> 01:23:51.440]   No one really knows who Yik Yak is or how it came back.
[01:23:53.920 --> 01:23:57.520]   It showed up on Monday on the Apple App Store as
[01:23:57.520 --> 01:23:59.840]   kept pretty much unchanged.
[01:23:59.840 --> 01:24:08.000]   But wasn't there a mention about their culture changed far as doing something for
[01:24:08.000 --> 01:24:12.880]   mental health awareness and telling people don't be jerks on this?
[01:24:12.880 --> 01:24:13.440]   That'll work.
[01:24:13.440 --> 01:24:14.080]   Even though it's...
[01:24:14.080 --> 01:24:15.680]   Hey, don't be jerks, okay?
[01:24:15.680 --> 01:24:18.240]   Even though it's anonymous, don't be a jerk.
[01:24:18.240 --> 01:24:19.120]   Don't be jerks.
[01:24:19.920 --> 01:24:24.400]   I think they got Kevin Malone from the office to do an ad.
[01:24:24.400 --> 01:24:28.240]   Brian Bomb got here.
[01:24:28.240 --> 01:24:28.560]   Yeah.
[01:24:28.560 --> 01:24:31.760]   Let me see if I can.
[01:24:31.760 --> 01:24:33.040]   I'd never heard of this app.
[01:24:33.040 --> 01:24:34.480]   I never heard of it in its...
[01:24:34.480 --> 01:24:39.040]   We heard about it because we talked about it at the time.
[01:24:39.040 --> 01:24:42.720]   I don't even remember what phone I had back then.
[01:24:42.720 --> 01:24:46.560]   And I was probably on a black bear or something and couldn't get it.
[01:24:46.560 --> 01:24:47.040]   Who knows?
[01:24:48.000 --> 01:24:51.520]   We've been doing Twig for how long?
[01:24:51.520 --> 01:24:52.400]   So here's...
[01:24:52.400 --> 01:24:54.080]   Here, ladies and gentlemen, I give you...
[01:24:54.080 --> 01:24:57.360]   Kevin, the dumb guy from the office.
[01:24:57.360 --> 01:24:58.720]   Is back.
[01:24:58.720 --> 01:24:59.440]   Oh, wait, wait, let me.
[01:24:59.440 --> 01:25:02.800]   The Yak is back.
[01:25:02.800 --> 01:25:05.920]   It's back, baby.
[01:25:05.920 --> 01:25:10.640]   Hi, it's Brian Bombarder here and I am so excited.
[01:25:10.640 --> 01:25:12.000]   He has no idea what he's talking about.
[01:25:12.000 --> 01:25:12.560]   You all...
[01:25:12.560 --> 01:25:13.040]   Right.
[01:25:13.040 --> 01:25:13.360]   That...
[01:25:13.360 --> 01:25:14.880]   Did they just buy a cameo from him?
[01:25:14.880 --> 01:25:15.360]   I think he's a cameo.
[01:25:15.360 --> 01:25:17.680]   He's apparently one of the most popular people.
[01:25:17.680 --> 01:25:21.440]   I'm a giant pot of chili.
[01:25:21.440 --> 01:25:25.840]   Go to the App Store and download it for iPhone.
[01:25:25.840 --> 01:25:27.840]   I'm not joking.
[01:25:27.840 --> 01:25:32.000]   It is back and it is better than ever.
[01:25:32.000 --> 01:25:34.080]   I want you to get paid for that.
[01:25:34.080 --> 01:25:34.640]   Two hundred bucks.
[01:25:34.640 --> 01:25:35.440]   Amardette chick.
[01:25:35.440 --> 01:25:41.760]   Can you go to cameo and get these guys to do ads?
[01:25:41.760 --> 01:25:43.840]   For their regular fee?
[01:25:43.840 --> 01:25:44.720]   Maybe they don't realize they're doing it.
[01:25:44.720 --> 01:25:45.600]   Or a small fee.
[01:25:46.240 --> 01:25:50.240]   Let me just see what Kevin...
[01:25:50.240 --> 01:25:51.520]   I mean, what was his name?
[01:25:51.520 --> 01:25:52.000]   Bill Bob?
[01:25:52.000 --> 01:25:52.480]   Brian Bombarder.
[01:25:52.480 --> 01:25:52.960]   Brian Bombarder.
[01:25:52.960 --> 01:25:54.880]   Brian Bombarder.
[01:25:54.880 --> 01:25:59.360]   I want to just see what he would charge me if I went to cameo.
[01:25:59.360 --> 01:26:00.560]   This is curious.
[01:26:00.560 --> 01:26:02.240]   Uh, 195 bucks.
[01:26:02.240 --> 01:26:06.080]   It does look pretty much like the same as a cameo.
[01:26:06.080 --> 01:26:08.800]   In fact, I think he's in the same spot.
[01:26:08.800 --> 01:26:09.280]   Same spot.
[01:26:09.280 --> 01:26:09.440]   Yeah.
[01:26:09.440 --> 01:26:11.440]   It looks like a cameo.
[01:26:11.440 --> 01:26:12.240]   It's a cameo.
[01:26:12.240 --> 01:26:14.400]   195 bucks.
[01:26:15.120 --> 01:26:15.760]   That a boy.
[01:26:15.760 --> 01:26:16.160]   You know what?
[01:26:16.160 --> 01:26:18.000]   Way to hack that advertising.
[01:26:18.000 --> 01:26:19.040]   That's pretty awesome.
[01:26:19.040 --> 01:26:20.480]   Break it in.
[01:26:20.480 --> 01:26:22.800]   Oh.
[01:26:22.800 --> 01:26:23.680]   He's...
[01:26:23.680 --> 01:26:24.160]   I guess he's...
[01:26:24.160 --> 01:26:24.560]   I don't know.
[01:26:24.560 --> 01:26:25.440]   Let me play something here.
[01:26:25.440 --> 01:26:26.080]   What is he doing?
[01:26:26.080 --> 01:26:28.640]   Here.
[01:26:28.640 --> 01:26:30.800]   Is he swearing?
[01:26:30.800 --> 01:26:32.960]   Well, hello, you beautiful cameo people.
[01:26:32.960 --> 01:26:35.680]   It's Brian Bombarder here and I am.
[01:26:35.680 --> 01:26:38.560]   See, he can't say Kevin Malone or the office.
[01:26:38.560 --> 01:26:40.880]   So, but everybody knows who it is.
[01:26:40.880 --> 01:26:41.920]   Of course.
[01:26:41.920 --> 01:26:43.360]   Yeah.
[01:26:43.360 --> 01:26:44.160]   Well, all the young people are...
[01:26:44.160 --> 01:26:46.000]   The next one looks like it was the same, right?
[01:26:46.000 --> 01:26:49.120]   Yeah, it's the same background and everything.
[01:26:49.120 --> 01:26:49.520]   Well, so...
[01:26:49.520 --> 01:26:50.320]   So, go back one.
[01:26:50.320 --> 01:26:51.120]   Go back.
[01:26:51.120 --> 01:26:51.600]   Go left.
[01:26:51.600 --> 01:26:52.880]   It's that.
[01:26:52.880 --> 01:26:53.520]   That one.
[01:26:53.520 --> 01:26:54.080]   That's the same.
[01:26:54.080 --> 01:26:54.960]   You should play that one.
[01:26:54.960 --> 01:26:55.680]   Play that one.
[01:26:55.680 --> 01:26:56.320]   Think it's that...
[01:26:56.320 --> 01:26:56.800]   He'll be a...
[01:26:56.800 --> 01:26:57.360]   It'll be a...
[01:26:57.360 --> 01:26:59.600]   Hello, Michael Scott.
[01:26:59.600 --> 01:27:00.640]   Nevermind.
[01:27:00.640 --> 01:27:01.120]   Oh.
[01:27:01.120 --> 01:27:01.600]   Oh.
[01:27:01.600 --> 01:27:03.040]   And Liz.
[01:27:03.040 --> 01:27:04.160]   Well...
[01:27:04.160 --> 01:27:05.920]   He didn't even bother to shave for this one.
[01:27:05.920 --> 01:27:06.560]   You're a family.
[01:27:06.560 --> 01:27:07.520]   M.S.
[01:27:07.520 --> 01:27:08.320]   Uh, read out.
[01:27:08.320 --> 01:27:09.440]   He's just $200 he's made.
[01:27:09.440 --> 01:27:10.080]   And totally...
[01:27:10.080 --> 01:27:13.600]   Well, two loves eternal glory.
[01:27:13.600 --> 01:27:15.040]   I value myself too much.
[01:27:15.040 --> 01:27:16.160]   I wouldn't do this for $200.
[01:27:16.160 --> 01:27:19.600]   Although he probably should crank that.
[01:27:19.600 --> 01:27:20.160]   How many...
[01:27:20.160 --> 01:27:20.880]   Yeah, well, that's different.
[01:27:20.880 --> 01:27:21.760]   That was for charity.
[01:27:21.760 --> 01:27:22.560]   How many...
[01:27:22.560 --> 01:27:23.440]   Could you do...
[01:27:23.440 --> 01:27:24.080]   There's...
[01:27:24.080 --> 01:27:26.320]   You could probably do several hundred a day.
[01:27:26.320 --> 01:27:27.680]   Times 200 bucks.
[01:27:27.680 --> 01:27:28.160]   Yeah, I guess it's boring.
[01:27:28.160 --> 01:27:29.120]   Well, let's just say you're like...
[01:27:29.120 --> 01:27:30.160]   It's good money.
[01:27:30.160 --> 01:27:32.800]   I would say I would dedicate like an hour of my data
[01:27:32.800 --> 01:27:33.520]   doing these.
[01:27:33.520 --> 01:27:36.320]   So, I can't imagine anyone wanting to pay $200 for me.
[01:27:36.320 --> 01:27:37.760]   But like 50 bucks,
[01:27:37.760 --> 01:27:40.800]   if I know I'm going to get 50 bucks to do five or six of us.
[01:27:40.800 --> 01:27:41.520]   Can I be your agent?
[01:27:42.960 --> 01:27:44.480]   No, Andrew's your agent.
[01:27:44.480 --> 01:27:44.960]   Too late.
[01:27:44.960 --> 01:27:46.000]   Oh yeah, half one.
[01:27:46.000 --> 01:27:46.960]   Too late.
[01:27:46.960 --> 01:27:48.720]   Gotta keep it in the family.
[01:27:48.720 --> 01:27:49.920]   What's the name of the A&P?
[01:27:49.920 --> 01:27:52.400]   Can we do Twitox?
[01:27:52.400 --> 01:27:53.360]   Twitox.
[01:27:53.360 --> 01:27:54.080]   Twitox.
[01:27:54.080 --> 01:27:55.360]   For the sake of the show.
[01:27:55.360 --> 01:27:57.680]   It's a new revenue stream, Lisa.
[01:27:57.680 --> 01:28:01.360]   I'll do them if it goes to the show.
[01:28:01.360 --> 01:28:04.400]   I think I just heard her run into the studio.
[01:28:04.400 --> 01:28:05.440]   Hey, community manager.
[01:28:05.440 --> 01:28:08.640]   So, I searched...
[01:28:08.640 --> 01:28:09.600]   What's the name of that A&P,
[01:28:09.600 --> 01:28:12.960]   because I searched for A&P on Audible.
[01:28:12.960 --> 01:28:15.600]   And I got the call of Suthulu by HP Lovecraft.
[01:28:15.600 --> 01:28:16.960]   I don't think that's the same.
[01:28:16.960 --> 01:28:21.280]   Look, the great A&P in the 12th of first ball business in America by Mark Levinson.
[01:28:21.280 --> 01:28:22.800]   It is on audio.
[01:28:22.800 --> 01:28:23.440]   The great...
[01:28:23.440 --> 01:28:26.720]   Yes, that business, Kuthulu,
[01:28:26.720 --> 01:28:27.440]   Cross-over-crowd.
[01:28:27.440 --> 01:28:27.840]   Yeah, yeah, yeah.
[01:28:27.840 --> 01:28:34.000]   So, it was the love crafty and horror that came from the F&C.
[01:28:34.000 --> 01:28:34.560]   There it is.
[01:28:34.560 --> 01:28:35.200]   I got it.
[01:28:35.200 --> 01:28:36.000]   Okay, I just wanted to...
[01:28:36.000 --> 01:28:39.200]   Why don't we know that name Mark Levinson?
[01:28:39.200 --> 01:28:40.800]   He also did the book about...
[01:28:40.800 --> 01:28:44.720]   Shipping container is the box.
[01:28:44.720 --> 01:28:47.200]   Which I wish were an Audible.
[01:28:47.200 --> 01:28:47.600]   It's not.
[01:28:47.600 --> 01:28:48.080]   It's killing me.
[01:28:48.080 --> 01:28:51.200]   It's just exactly the kind of book I don't need to watch.
[01:28:51.200 --> 01:28:51.200]   It is.
[01:28:51.200 --> 01:28:52.960]   It's the word of interest.
[01:28:52.960 --> 01:28:53.760]   It is an Audible.
[01:28:53.760 --> 01:28:54.560]   The boxes?
[01:28:54.560 --> 01:28:55.200]   Yeah.
[01:28:55.200 --> 01:28:58.240]   How the shipping container made the world smaller and the world economy bigger.
[01:28:58.240 --> 01:29:00.080]   Oh, heck, I'm boring it right now.
[01:29:00.080 --> 01:29:03.520]   Yes, everybody.
[01:29:03.520 --> 01:29:04.240]   You were here.
[01:29:04.240 --> 01:29:05.760]   The day Leo convinced...
[01:29:06.880 --> 01:29:09.680]   Jeff Jarvis to buy a book about a shipping container.
[01:29:09.680 --> 01:29:10.080]   Of something.
[01:29:10.080 --> 01:29:15.120]   Y'all.
[01:29:15.120 --> 01:29:16.000]   Y'all.
[01:29:16.000 --> 01:29:18.160]   Should I start talking about the...
[01:29:18.160 --> 01:29:21.760]   I'm very proud that I got a whole font of letters.
[01:29:21.760 --> 01:29:23.600]   I can start talking about Gutenberg stuff you want.
[01:29:23.600 --> 01:29:24.640]   Oh my.
[01:29:24.640 --> 01:29:25.920]   Where did you order that?
[01:29:25.920 --> 01:29:26.640]   Is that led to...
[01:29:26.640 --> 01:29:28.320]   No, I went to the museum of printing.
[01:29:28.320 --> 01:29:29.760]   Oh, I went to the museum of printing.
[01:29:29.760 --> 01:29:30.400]   And this is...
[01:29:30.400 --> 01:29:31.600]   They hand them out at the door.
[01:29:31.600 --> 01:29:32.320]   I thought it was made.
[01:29:32.320 --> 01:29:33.440]   No, no, no, no, I bought them.
[01:29:33.440 --> 01:29:34.080]   They were not cheap.
[01:29:34.080 --> 01:29:34.560]   Okay.
[01:29:34.560 --> 01:29:36.240]   This is a 10-point type.
[01:29:36.240 --> 01:29:37.840]   Now imagine it's reasonable.
[01:29:37.840 --> 01:29:38.640]   That's tiny.
[01:29:38.640 --> 01:29:39.920]   You got a set type.
[01:29:39.920 --> 01:29:40.560]   That's tiny.
[01:29:40.560 --> 01:29:42.800]   Word after word after word after word with these little tiny things.
[01:29:42.800 --> 01:29:46.080]   That letter after letter.
[01:29:46.080 --> 01:29:46.400]   What are we looking at?
[01:29:46.400 --> 01:29:47.360]   Yeah, it's one letter.
[01:29:47.360 --> 01:29:48.160]   Yeah.
[01:29:48.160 --> 01:29:49.040]   That was one letter.
[01:29:49.040 --> 01:29:54.800]   And would they ever have like the ready maids, so you just pop it in?
[01:29:54.800 --> 01:29:58.240]   There was, there wasn't an effort to do that to have all kinds of...
[01:29:58.240 --> 01:30:00.000]   Funny you should ask me Leo.
[01:30:00.000 --> 01:30:01.120]   Since you asked, I'll tell you.
[01:30:01.120 --> 01:30:03.200]   I think we have a new TikTok channel.
[01:30:03.200 --> 01:30:04.640]   Jeff, I'm a line-out site.
[01:30:04.640 --> 01:30:08.720]   Of the stereotype also, and the iron press also worked on this.
[01:30:08.720 --> 01:30:13.440]   And the problem was the typesetter said that the type case was just too huge.
[01:30:13.440 --> 01:30:15.280]   I know where to find the T and the H and E.
[01:30:15.280 --> 01:30:16.880]   But the time I got to remember where the "the" is.
[01:30:16.880 --> 01:30:17.280]   Oh, yeah.
[01:30:17.280 --> 01:30:17.760]   It's a great sport.
[01:30:17.760 --> 01:30:18.320]   Good point.
[01:30:18.320 --> 01:30:19.840]   But you might also be interested.
[01:30:19.840 --> 01:30:20.080]   Yes.
[01:30:20.080 --> 01:30:22.240]   There was late in the 1800s.
[01:30:22.240 --> 01:30:24.560]   He was going late in the 1800s.
[01:30:24.560 --> 01:30:25.840]   There was a competitive...
[01:30:25.840 --> 01:30:26.640]   I swear this is true.
[01:30:26.640 --> 01:30:29.280]   A competitive sport of typesetting.
[01:30:29.280 --> 01:30:29.920]   Oh, yeah.
[01:30:29.920 --> 01:30:31.840]   The "swifts" would do this.
[01:30:32.800 --> 01:30:36.240]   And they would do it in dime museums.
[01:30:36.240 --> 01:30:41.360]   And there would be cheering crowds of people watching them set type for big prizes.
[01:30:41.360 --> 01:30:45.280]   Until the International Democratic Union ordered them to stop,
[01:30:45.280 --> 01:30:48.240]   because they knew that they would lose against the line of type.
[01:30:48.240 --> 01:30:51.440]   A charming story of technology.
[01:30:51.440 --> 01:30:52.080]   It's amazing.
[01:30:52.080 --> 01:30:53.920]   It's a beautiful, it's a beautiful thing.
[01:30:53.920 --> 01:30:55.680]   You're going to add up that all.
[01:30:55.680 --> 01:30:56.160]   I know.
[01:30:56.160 --> 01:30:56.480]   I know.
[01:30:56.480 --> 01:30:56.800]   Go ahead.
[01:30:56.800 --> 01:30:59.280]   Hipto currency platform, Poly Network.
[01:30:59.280 --> 01:31:00.720]   I didn't actually tell this story.
[01:31:01.280 --> 01:31:04.160]   Last week, I should have because it has a happy ending.
[01:31:04.160 --> 01:31:06.000]   Hipt with a major attack.
[01:31:06.000 --> 01:31:11.120]   Hackers made off with more than $600 million worth of cryptocurrency.
[01:31:11.120 --> 01:31:14.720]   Then in a bizarre twist, the hacker returned
[01:31:14.720 --> 01:31:21.760]   $400 million, is withholding $200 million until, quote, "Everyone is ready."
[01:31:21.760 --> 01:31:26.400]   I don't know.
[01:31:26.400 --> 01:31:34.560]   And then, Poly Network promised him a half million dollar bounty for restoration of user funds
[01:31:34.560 --> 01:31:39.200]   and invited him to become its chief security officer.
[01:31:39.200 --> 01:31:42.640]   After he finishes his jail term?
[01:31:42.640 --> 01:31:45.440]   Mr. Whitehat is his name.
[01:31:45.440 --> 01:31:47.760]   That's how you apply for a job, right?
[01:31:47.760 --> 01:31:49.280]   Yeah.
[01:31:49.280 --> 01:31:54.160]   They offered him a half million dollar bug bounty.
[01:31:55.440 --> 01:32:01.520]   He turned down the bounty offer, however, in a message embedded in a digital currency
[01:32:01.520 --> 01:32:05.360]   transaction on Monday, which is, of course, the best way to put out a press release.
[01:32:05.360 --> 01:32:08.480]   The hacker said, "I'm considering taking the bounty as a bonus
[01:32:08.480 --> 01:32:12.320]   for public hackers if they can hack the Poly Network."
[01:32:12.320 --> 01:32:16.000]   There goes your job offer, buddy.
[01:32:16.000 --> 01:32:24.720]   Chief security advisor to extend our thanks and encourage Mr. Whitehat to continue
[01:32:24.720 --> 01:32:29.280]   contributing to security advancement in the blockchain world together with Poly Network.
[01:32:29.280 --> 01:32:34.160]   We cordially invite Mr. Whitehat to be the chief security advisor of Poly Network.
[01:32:34.160 --> 01:32:39.520]   If he would just surrender, I mean, come on down to the office,
[01:32:39.520 --> 01:32:44.800]   we'll be glad to provide him with some golden handcuffs.
[01:32:44.800 --> 01:32:49.520]   And not Diamond Hands?
[01:32:49.520 --> 01:32:50.560]   No, Diamond Hands.
[01:32:50.560 --> 01:32:52.960]   Maybe, maybe, maybe.
[01:32:52.960 --> 01:32:56.000]   Should we do a, I don't know, we should do some Google stories.
[01:32:56.000 --> 01:32:58.240]   We did.
[01:32:58.240 --> 01:32:59.120]   These are all boring.
[01:32:59.120 --> 01:32:59.440]   Good.
[01:32:59.440 --> 01:33:01.520]   We talked about Pixel 5A.
[01:33:01.520 --> 01:33:08.960]   How about the delightful Google ad imagining the Perseverance rover using Google photos?
[01:33:08.960 --> 01:33:10.560]   I don't know why this is delightful.
[01:33:10.560 --> 01:33:14.320]   I guess it has a robot that's on Mars.
[01:33:14.320 --> 01:33:15.680]   Everyone loves Perseverance.
[01:33:18.880 --> 01:33:20.640]   Oh, it's a musical.
[01:33:20.640 --> 01:33:22.800]   It's from Wally.
[01:33:22.800 --> 01:33:24.640]   That's the beginning song in Wally.
[01:33:24.640 --> 01:33:26.400]   Just for you, Aunt.
[01:33:26.400 --> 01:33:29.680]   It's Mars Perseverance rover, the musical.
[01:33:29.680 --> 01:33:32.800]   This doesn't sound like this is from Wally.
[01:33:32.800 --> 01:33:37.200]   No, it's the, it's, they used it in Wally.
[01:33:37.200 --> 01:33:39.840]   It's a song from like a 1930s movie.
[01:33:39.840 --> 01:33:41.920]   Yeah, it's like, it is Hello, Dolly, I think.
[01:33:41.920 --> 01:33:42.400]   It is Hello, Dolly.
[01:33:42.400 --> 01:33:43.760]   But they played it in Wally.
[01:33:43.760 --> 01:33:45.600]   It was his favorite.
[01:33:45.600 --> 01:33:46.720]   He plays it over and over.
[01:33:46.720 --> 01:33:47.360]   That's right.
[01:33:47.360 --> 01:33:47.920]   Yeah, yeah, yeah.
[01:33:47.920 --> 01:33:48.400]   Yes.
[01:33:48.400 --> 01:33:48.880]   Yes, yeah.
[01:33:48.880 --> 01:33:51.680]   Sorry, I know it's not from Wally, but that's where I was.
[01:33:51.680 --> 01:33:52.560]   It's Hello, Wally.
[01:33:52.560 --> 01:33:54.320]   Thank God, Esso.
[01:33:54.320 --> 01:33:54.720]   There we go.
[01:33:54.720 --> 01:34:00.240]   You would love Hello, Dolly.
[01:34:00.240 --> 01:34:05.200]   It's the, it's the charming story of a matchmaker from Yonkers.
[01:34:05.200 --> 01:34:08.640]   That weren't.
[01:34:08.640 --> 01:34:10.160]   That weren't.
[01:34:10.160 --> 01:34:11.120]   Don't be dead.
[01:34:11.120 --> 01:34:18.080]   My hope is there's going to be a whole subsection of the society on the Twit Club of musical fans.
[01:34:18.080 --> 01:34:21.680]   Oh, I'm starting, I'm starting to chat right now.
[01:34:21.680 --> 01:34:24.240]   Lovers of the musical.
[01:34:24.240 --> 01:34:25.040]   Hello, T.M.
[01:34:25.040 --> 01:34:25.760]   Yeah.
[01:34:25.760 --> 01:34:27.520]   Musical memes, Fran.
[01:34:27.520 --> 01:34:28.000]   Yeah.
[01:34:28.000 --> 01:34:30.080]   Notes self mute that channel.
[01:34:30.080 --> 01:34:33.440]   I'm the boss now.
[01:34:33.440 --> 01:34:40.400]   I guess we should mention this.
[01:34:40.400 --> 01:34:43.680]   I'm not that bullish about the prospects.
[01:34:43.680 --> 01:34:47.120]   Remember Twitter had this notion of creating it kind of an open,
[01:34:47.120 --> 01:34:50.160]   federated Twitter called Project Blue Sky.
[01:34:50.160 --> 01:34:55.200]   They have hired what many people considered to be a very good choice crypto developer,
[01:34:55.200 --> 01:35:00.560]   Jay Greber, to helm the initiative, particularly Mike Maslin, who did,
[01:35:00.560 --> 01:35:02.800]   it was part of the interview process for this job.
[01:35:02.800 --> 01:35:05.600]   He said Jay is an excellent choice.
[01:35:05.600 --> 01:35:07.280]   He was one of my first choices.
[01:35:07.280 --> 01:35:09.120]   He was one of the first one of the.
[01:35:09.120 --> 01:35:09.280]   Yeah.
[01:35:09.280 --> 01:35:09.680]   She.
[01:35:09.680 --> 01:35:10.720]   Pardon me?
[01:35:10.720 --> 01:35:12.240]   She, Jay is she.
[01:35:12.240 --> 01:35:12.880]   Oh, you're right.
[01:35:12.880 --> 01:35:14.000]   She absolutely.
[01:35:14.000 --> 01:35:14.880]   Yes, not he.
[01:35:16.720 --> 01:35:18.240]   Um, I see.
[01:35:18.240 --> 01:35:21.920]   I think that Blue Sky, we've talked about it before, but I think theoretically it could
[01:35:21.920 --> 01:35:23.040]   be really quite amazing.
[01:35:23.040 --> 01:35:23.600]   Oh, wonderful.
[01:35:23.600 --> 01:35:24.480]   And give me a little more.
[01:35:24.480 --> 01:35:24.960]   I would love it.
[01:35:24.960 --> 01:35:25.280]   Yes.
[01:35:25.280 --> 01:35:25.840]   Hope that it.
[01:35:25.840 --> 01:35:26.240]   Let's hope.
[01:35:26.240 --> 01:35:27.280]   This is a good sign.
[01:35:27.280 --> 01:35:28.000]   Yeah.
[01:35:28.000 --> 01:35:28.160]   Yeah.
[01:35:28.160 --> 01:35:30.080]   I was going to ask, why are you so against Blue Sky?
[01:35:30.080 --> 01:35:30.880]   I'm not against it.
[01:35:30.880 --> 01:35:31.680]   I'm pro at this.
[01:35:31.680 --> 01:35:32.240]   Growly.
[01:35:32.240 --> 01:35:34.240]   I just don't think that Twitter is going to do it.
[01:35:34.240 --> 01:35:36.160]   I think this is lip service.
[01:35:36.160 --> 01:35:37.600]   Right.
[01:35:37.600 --> 01:35:44.880]   But maybe, maybe if they could find a way to monetize it, but then that kind of.
[01:35:44.880 --> 01:35:48.240]   It's about an value added layer on top of the commodity.
[01:35:48.240 --> 01:35:50.560]   The speaking becomes a commodity.
[01:35:50.560 --> 01:35:54.480]   The finding, the recommending becomes the value.
[01:35:54.480 --> 01:35:57.440]   That's my, that's my view of what this means.
[01:35:57.440 --> 01:35:58.480]   But that's like Jack.
[01:35:58.480 --> 01:35:58.880]   Great.
[01:35:58.880 --> 01:36:00.960]   Graybird told Tech Crunch from January.
[01:36:00.960 --> 01:36:04.800]   She saw a major opportunity in Twitter entering the decentralized social space.
[01:36:04.800 --> 01:36:08.560]   Due to the hefty user base on the Twitter platform,
[01:36:08.560 --> 01:36:11.200]   which will eventually itself migrate to the protocol.
[01:36:11.200 --> 01:36:12.320]   The company has said.
[01:36:14.160 --> 01:36:17.040]   Well, I mean, if they do it, that just seems kind of utopian.
[01:36:17.040 --> 01:36:18.640]   If they do it, I'd be very happy.
[01:36:18.640 --> 01:36:19.360]   Yeah.
[01:36:19.360 --> 01:36:20.400]   So try to be happy.
[01:36:20.400 --> 01:36:21.440]   Try to be unexcited.
[01:36:21.440 --> 01:36:22.480]   Well, good choice, Jack.
[01:36:22.480 --> 01:36:23.600]   Good choice.
[01:36:23.600 --> 01:36:25.200]   Good choice.
[01:36:25.200 --> 01:36:27.040]   That's better.
[01:36:27.040 --> 01:36:30.720]   The video didn't sound so convincing.
[01:36:30.720 --> 01:36:31.120]   Good choice.
[01:36:31.120 --> 01:36:34.000]   Twitter.
[01:36:34.000 --> 01:36:40.960]   I didn't realize this, but back in April, according to the information,
[01:36:41.760 --> 01:36:49.120]   the Chinese government took a seat and a stake in ByteDance, the TikTok company.
[01:36:49.120 --> 01:36:51.520]   A subsidiary thereof.
[01:36:51.520 --> 01:36:53.600]   A subsidiary thereof.
[01:36:53.600 --> 01:36:56.000]   TikTok is a subsidiary of ByteDance.
[01:36:56.000 --> 01:36:58.560]   Are you just mocking, Jeff?
[01:36:58.560 --> 01:37:00.880]   Excuse me.
[01:37:00.880 --> 01:37:02.960]   But then it's subsidiary.
[01:37:02.960 --> 01:37:04.320]   What is happening here?
[01:37:04.320 --> 01:37:04.800]   What is happening here?
[01:37:04.800 --> 01:37:08.960]   If you really pay attention, just try to make it accurate.
[01:37:08.960 --> 01:37:11.760]   Particles of incorporation you would know,
[01:37:11.760 --> 01:37:16.080]   that ByteDance in TikTok is a subsidiary thereof.
[01:37:16.080 --> 01:37:19.360]   I appreciate your dedication to accuracy.
[01:37:19.360 --> 01:37:20.560]   Thank you.
[01:37:20.560 --> 01:37:21.200]   Stacey.
[01:37:21.200 --> 01:37:25.040]   Mr. Rydal did the evidence.
[01:37:25.040 --> 01:37:25.680]   I don't need any of that.
[01:37:25.680 --> 01:37:27.280]   I don't need no stinking evidence.
[01:37:27.280 --> 01:37:27.920]   I got this.
[01:37:27.920 --> 01:37:29.200]   I believe my lion eyes.
[01:37:29.200 --> 01:37:33.920]   Chinese government, apparently, it also acquired a stake in a board seat in
[01:37:33.920 --> 01:37:36.560]   why Beibot, the big social network in China.
[01:37:36.560 --> 01:37:38.880]   That's so interesting.
[01:37:38.880 --> 01:37:40.800]   Is it Ted Cruz?
[01:37:40.800 --> 01:37:45.360]   Who is it who's trying to say that ByteDance should now turn off TikTok because of this?
[01:37:45.360 --> 01:37:46.240]   Oh, really?
[01:37:46.240 --> 01:37:47.040]   Oh, yes.
[01:37:47.040 --> 01:37:50.160]   Well, what of the...
[01:37:50.160 --> 01:37:51.840]   Well, well.
[01:37:51.840 --> 01:37:54.480]   Hey, Blackberry.
[01:37:54.480 --> 01:37:58.640]   I don't know about this.
[01:37:58.640 --> 01:38:03.120]   Blackberry, apparently, talking about reporting and obligation to report,
[01:38:03.120 --> 01:38:07.520]   knew about a flaw in its Q and X operating system.
[01:38:08.640 --> 01:38:12.160]   That had been around for some time.
[01:38:12.160 --> 01:38:12.720]   Ever.
[01:38:12.720 --> 01:38:18.720]   And though the reason they have been marketing Q and X to people as the most secure,
[01:38:18.720 --> 01:38:23.440]   for IoT, they put it in cars, they put it in medical devices,
[01:38:23.440 --> 01:38:26.720]   and the idea was that Blackberry was securing the heck out of it.
[01:38:26.720 --> 01:38:30.240]   And then to find out that they couldn't even do the bare minimum,
[01:38:30.240 --> 01:38:34.080]   which is when someone reports a vulnerability, instead of saying,
[01:38:34.080 --> 01:38:34.960]   "Oh, thank you.
[01:38:34.960 --> 01:38:35.920]   We should fix that."
[01:38:35.920 --> 01:38:38.000]   They said, "Shh, don't tell anybody."
[01:38:38.480 --> 01:38:39.600]   And then refused to fix it.
[01:38:39.600 --> 01:38:42.400]   Microsoft security research is announced in April.
[01:38:42.400 --> 01:38:48.640]   They discovered the bad alec vulnerability, which affected a lot of different software,
[01:38:48.640 --> 01:38:51.680]   founded in a number of companies operating systems and software.
[01:38:51.680 --> 01:38:56.080]   In May, those companies, many of them, worked with the Department of Homeland Security,
[01:38:56.080 --> 01:39:01.440]   Cybersecurity, and Infrastructure Security Agency to publicly reveal the flaws and
[01:39:01.440 --> 01:39:03.520]   urge users to patch their devices.
[01:39:03.520 --> 01:39:05.280]   Blackberry was not among them.
[01:39:06.800 --> 01:39:10.720]   Blackberry thought, "Oh, bad alec doesn't impact us."
[01:39:10.720 --> 01:39:14.560]   Even though Sissa had concluded that it did,
[01:39:14.560 --> 01:39:23.040]   more than 200 million cars, which are among the many things that use Q and X,
[01:39:23.040 --> 01:39:27.040]   a real-time operating system, along with critical hospital and factory equipment,
[01:39:27.040 --> 01:39:32.480]   was therefore vulnerable to hackers, the company opted to keep it secret for months.
[01:39:32.480 --> 01:39:32.800]   Oops.
[01:39:36.320 --> 01:39:37.280]   Not good.
[01:39:37.280 --> 01:39:37.840]   Not good.
[01:39:37.840 --> 01:39:38.880]   Not good.
[01:39:38.880 --> 01:39:41.440]   A lot of cars have Q and X.
[01:39:41.440 --> 01:39:44.880]   My old Audi had Q and X, I think, as it's on.
[01:39:44.880 --> 01:39:45.200]   Yeah.
[01:39:45.200 --> 01:39:46.640]   It was a big deal.
[01:39:46.640 --> 01:39:50.400]   Hey, did some of the luxury cars have it too?
[01:39:50.400 --> 01:39:50.640]   Yeah.
[01:39:50.640 --> 01:39:51.760]   Yeah.
[01:39:51.760 --> 01:39:53.520]   Tons of cars too.
[01:39:53.520 --> 01:39:57.120]   It was kind of like free yard toss for people who...
[01:39:57.120 --> 01:39:57.280]   Right.
[01:39:57.280 --> 01:40:01.520]   195 million vehicles.
[01:40:01.520 --> 01:40:06.720]   Blackberry called it in June the key to the future of the automotive industry because
[01:40:06.720 --> 01:40:11.920]   it provided a safe, reliable, and secure foundation for autonomous vehicles.
[01:40:11.920 --> 01:40:13.120]   Secure, did you say?
[01:40:13.120 --> 01:40:13.440]   Yeah.
[01:40:13.440 --> 01:40:13.840]   Ooops.
[01:40:13.840 --> 01:40:18.880]   They said that tongue is shame.
[01:40:18.880 --> 01:40:20.240]   Shame.
[01:40:20.240 --> 01:40:21.840]   Shame.
[01:40:21.840 --> 01:40:26.000]   We should make Blackberry walk naked down the streets of Ottawa.
[01:40:26.000 --> 01:40:30.800]   I think it's interesting to talk about if you don't mind.
[01:40:30.800 --> 01:40:31.120]   Yeah.
[01:40:31.120 --> 01:40:35.280]   Facebook widely viewed content report.
[01:40:35.280 --> 01:40:37.120]   Okay.
[01:40:37.120 --> 01:40:38.720]   Here it is.
[01:40:38.720 --> 01:40:41.280]   This is from transparency.fb.com.
[01:40:41.280 --> 01:40:44.640]   Widely viewed content report.
[01:40:44.640 --> 01:40:45.600]   What people see.
[01:40:45.600 --> 01:40:50.480]   This is out of some controversy here because Facebook had a tool called...
[01:40:50.480 --> 01:40:55.360]   has a tool called CrowdTangle and Kevin Ruse of the New York Times used it to say,
[01:40:55.360 --> 01:40:59.600]   "Well, here's the top things that CrowdTangle Facebook's own tool that they bought."
[01:40:59.600 --> 01:40:59.920]   Right.
[01:40:59.920 --> 01:41:05.440]   It says, "Are the most popular, most seen things on Facebook?"
[01:41:05.440 --> 01:41:11.680]   And there were others, I think Masnek might be one of them who maybe wasn't Masnek.
[01:41:11.680 --> 01:41:15.840]   Some other smart people said, "Well, we really don't know how big is big,
[01:41:15.840 --> 01:41:17.120]   and this doesn't make a lot of sense."
[01:41:17.120 --> 01:41:19.760]   And CrowdTangle kept going, and it was useful for journalists,
[01:41:19.760 --> 01:41:22.320]   and they kind of made Kevin Ruse in this.
[01:41:22.320 --> 01:41:27.520]   And then there was an internal debate in Facebook about this that this is not making us look good,
[01:41:27.520 --> 01:41:29.120]   and we shouldn't be doing this.
[01:41:29.120 --> 01:41:33.840]   And they pulled apart the team, and then Facebook now came out with another report,
[01:41:33.840 --> 01:41:37.360]   which as usual gives you part of the story, not the whole story, which is the issue here.
[01:41:37.360 --> 01:41:43.840]   But it says the thing that I've said all along is, because no two people see the same Facebook,
[01:41:43.840 --> 01:41:45.120]   how...
[01:41:45.120 --> 01:41:47.760]   If you say something, it's number one in Facebook, how big is that?
[01:41:47.760 --> 01:41:49.280]   It's not very big.
[01:41:49.280 --> 01:41:52.160]   It's 0.1% of all content views.
[01:41:53.440 --> 01:41:56.880]   They say that's because given the customized nature of newsfeed,
[01:41:56.880 --> 01:42:00.320]   most of what people see on Facebook is personalized for them specifically.
[01:42:00.320 --> 01:42:04.800]   So this does go back to the earlier discussion too about, well,
[01:42:04.800 --> 01:42:06.960]   this turned out in Facebook, it influenced the whole world.
[01:42:06.960 --> 01:42:10.000]   Well, part of the data I want, pardon me for wanting it,
[01:42:10.000 --> 01:42:12.640]   is to say, well, how many people actually saw it?
[01:42:12.640 --> 01:42:14.960]   It could have been number one, but it could have been number one among
[01:42:14.960 --> 01:42:19.760]   25 billion things, and it's the long tail of long tails of long tails.
[01:42:19.760 --> 01:42:25.120]   And so it's important to have data like this, though I'd rather have it done independently,
[01:42:25.120 --> 01:42:28.880]   so that we can say how big is big, how influential is influential.
[01:42:28.880 --> 01:42:29.760]   This is important.
[01:42:29.760 --> 01:42:32.560]   The vast majority, this is from Facebook's Transparency Report,
[01:42:32.560 --> 01:42:37.280]   the vast majority of content viewed in newsfeed during the second quarter of this year,
[01:42:37.280 --> 01:42:43.120]   87.1% did not include a link to a source outside of Facebook.
[01:42:46.160 --> 01:42:49.920]   Most of these links are in posts shared by pages that people follow.
[01:42:49.920 --> 01:42:54.160]   This means a majority of newsfeed content views in the US were on posts
[01:42:54.160 --> 01:42:58.800]   without links and were from content viewers, friends or from groups they were connected to,
[01:42:58.800 --> 01:43:03.440]   content that did not come from friends, pages people followed or groups
[01:43:03.440 --> 01:43:07.920]   that they were part of also referred to as unconnected posts made up a relatively minor
[01:43:07.920 --> 01:43:09.280]   percentage of content views.
[01:43:09.280 --> 01:43:12.080]   I don't know if that's meaningful though, because there's a lot of people who follow
[01:43:12.800 --> 01:43:18.640]   anti-vex groups.
[01:43:18.640 --> 01:43:23.760]   I think it's a lot of people who follow the link to the link to the link to the link.
[01:43:23.760 --> 01:43:30.160]   I think it's a lot of people who follow the link to the link to the link to the link.
[01:43:30.160 --> 01:43:36.160]   I think it's a lot of people who follow the link to the link to the link.
[01:43:36.160 --> 01:43:42.160]   And I think it's a lot of people who follow the link to the link to the link to the link.
[01:43:42.160 --> 01:43:45.120]   And I think it's a lot of people who follow the link to the link to the link.
[01:43:45.120 --> 01:43:48.960]   I went into Facebook the other day and I just if you search for vaccination last time I did it,
[01:43:48.960 --> 01:43:52.800]   it's all news because I think Facebook's trying to do that now.
[01:43:52.800 --> 01:43:57.520]   I am just very happy not being on Facebook. That's all I can say.
[01:43:57.520 --> 01:43:58.240]   I just don't miss it.
[01:43:58.240 --> 01:43:58.800]   I have a story.
[01:43:58.800 --> 01:43:59.920]   It was what your list of yourselves.
[01:43:59.920 --> 01:44:00.800]   And it has Google in it.
[01:44:00.800 --> 01:44:02.240]   Good.
[01:44:02.240 --> 01:44:04.480]   You want a Google story?
[01:44:04.480 --> 01:44:04.880]   Yeah.
[01:44:04.880 --> 01:44:07.200]   Y'all matter.
[01:44:07.200 --> 01:44:10.880]   Google affiliated smart home protocol interoperability.
[01:44:10.880 --> 01:44:15.600]   Woo-woo. Google Amazon Facebook not Facebook.
[01:44:15.600 --> 01:44:20.720]   Sorry. Google Amazon Apple and Samsung all got together and were like,
[01:44:20.720 --> 01:44:23.040]   Hey, let's make your smart home stuff interoperable.
[01:44:23.040 --> 01:44:24.640]   They called a project chip for a while.
[01:44:24.640 --> 01:44:27.360]   Now it became matter or it became matter earlier this year.
[01:44:27.360 --> 01:44:31.680]   And it was supposed to be out this fall, but they're going to delay it until the first half of
[01:44:31.680 --> 01:44:32.560]   next year.
[01:44:32.560 --> 01:44:34.240]   And while I am sad.
[01:44:34.240 --> 01:44:35.440]   Sorry Stacey.
[01:44:35.440 --> 01:44:36.240]   I'm sorry.
[01:44:36.240 --> 01:44:36.560]   I know.
[01:44:36.560 --> 01:44:38.160]   It's very sad.
[01:44:38.160 --> 01:44:39.200]   It was disappointing.
[01:44:39.200 --> 01:44:41.040]   It was contributing to the delay.
[01:44:41.040 --> 01:44:43.280]   Couple things.
[01:44:43.280 --> 01:44:46.320]   One, I think they're doing this a little differently.
[01:44:46.320 --> 01:44:49.360]   They are releasing a full software development kit.
[01:44:49.360 --> 01:44:52.800]   So the full SDK is going to come out and they realize that, oh,
[01:44:52.800 --> 01:44:55.600]   I think they took a look at their code and they were like,
[01:44:55.600 --> 01:44:58.000]   we should work on this a little bit longer.
[01:44:58.000 --> 01:45:03.600]   I think the COVID coming back, the Delta variant has kind of pushed them
[01:45:03.600 --> 01:45:05.040]   tests back a little bit.
[01:45:05.040 --> 01:45:07.120]   So they're testing events.
[01:45:07.760 --> 01:45:10.720]   But also, I mean, I'm really sad.
[01:45:10.720 --> 01:45:14.960]   They say also that more companies join, but I think that's just a BS kind of just,
[01:45:14.960 --> 01:45:19.040]   you know, if you can't handle 20 more companies joining your standards
[01:45:19.040 --> 01:45:21.760]   organizations at the last minute, that's a problem.
[01:45:21.760 --> 01:45:23.680]   So I'm going to hope that's not the real issue.
[01:45:23.680 --> 01:45:29.520]   But I think it's actually okay because I'd rather have a good standard coming out.
[01:45:29.520 --> 01:45:33.920]   It's really disappointing for people like me who are waiting to buy new smart home stuff that's
[01:45:33.920 --> 01:45:40.160]   matter certified. We should still see people releasing their plans at CES or in that time frame.
[01:45:40.160 --> 01:45:42.720]   But it is kind of a left out.
[01:45:42.720 --> 01:45:46.000]   Is it still worth waiting for a matter certified device?
[01:45:46.000 --> 01:45:46.560]   You think so?
[01:45:46.560 --> 01:45:51.840]   Yes, I'm getting a lot of people who are a little unsure about what matter is going to do.
[01:45:51.840 --> 01:45:53.840]   So people are like, oh, I need a new doorbell.
[01:45:53.840 --> 01:45:55.280]   I'm going to wait and buy a matter one.
[01:45:55.280 --> 01:45:59.280]   I was like, don't do that because doorbells aren't part of the certification.
[01:45:59.280 --> 01:46:03.040]   If you're waiting to buy new locks, new light bulbs, maybe a new HVAC,
[01:46:03.040 --> 01:46:05.200]   those kind of things, then yes, sure, wait.
[01:46:05.200 --> 01:46:13.120]   I would also say, realistically, the soonest you're going to buy a matter certified device
[01:46:13.120 --> 01:46:15.360]   is going to be the latter half of next year.
[01:46:15.360 --> 01:46:16.800]   Ooh, so you're right.
[01:46:16.800 --> 01:46:21.520]   So I mean, you can buy things that are likely to be upgraded.
[01:46:21.520 --> 01:46:23.760]   Like, Phillips says, hey, we're going to upgrade everything.
[01:46:23.760 --> 01:46:25.840]   So if you want to invest in new Phillips light bulbs, great.
[01:46:25.840 --> 01:46:31.440]   The Nanoleaf bulbs, things, some of these things people already, if people have come out,
[01:46:31.440 --> 01:46:32.320]   go ahead and buy it.
[01:46:32.320 --> 01:46:36.160]   But I would not buy door locks right now because none of the lockmakers are like,
[01:46:36.160 --> 01:46:37.040]   this is what we're doing.
[01:46:37.040 --> 01:46:43.280]   Actually, you say in your article that it's going to be first half of next year for the SDK
[01:46:43.280 --> 01:46:47.840]   and the start of a certification program, which means probably it's going to be the following
[01:46:47.840 --> 01:46:50.080]   later that you'll actually be able to get devices.
[01:46:50.080 --> 01:46:54.240]   It'll be towards the holiday season of next year, I think.
[01:46:54.240 --> 01:46:54.640]   Yes.
[01:46:54.640 --> 01:46:59.040]   I mean, there's some like Google and Amazon, they're going to have their stuff ready.
[01:46:59.040 --> 01:47:03.440]   And a lot of the companies who are participating, they're already working with this stuff.
[01:47:03.440 --> 01:47:04.240]   Yeah.
[01:47:04.240 --> 01:47:04.480]   Yeah.
[01:47:04.480 --> 01:47:05.440]   So it will be pretty.
[01:47:05.440 --> 01:47:07.360]   They're working on the SDK and development.
[01:47:07.360 --> 01:47:12.080]   So but if you are part of the membership and you don't have access to any of this,
[01:47:12.080 --> 01:47:14.000]   then yeah, it's going to be a little bit longer for you.
[01:47:14.000 --> 01:47:18.160]   So I'm going to, I'm going to not home automate until next year.
[01:47:18.160 --> 01:47:19.360]   Yes.
[01:47:19.360 --> 01:47:20.960]   Yeah, that's fine.
[01:47:20.960 --> 01:47:21.280]   Okay.
[01:47:21.280 --> 01:47:23.520]   I haven't missed it so far.
[01:47:23.520 --> 01:47:26.880]   I do actually know I have few lights.
[01:47:27.440 --> 01:47:30.880]   And I know you have home automation stuff.
[01:47:30.880 --> 01:47:35.040]   Home automation, I have doorbells, I have, you know, voice assistants.
[01:47:35.040 --> 01:47:37.760]   But I can say, you know, turn off the lights, turn on the lights.
[01:47:37.760 --> 01:47:40.720]   And there's lights in the living room and lights in my office.
[01:47:40.720 --> 01:47:45.360]   How is it possible that these lights can be upgraded?
[01:47:45.360 --> 01:47:47.840]   I would assume there's some hardware limitations.
[01:47:47.840 --> 01:47:53.680]   So a lot of the lights that will be upgraded, so Phillips has two brands.
[01:47:53.680 --> 01:47:57.120]   They have their fancy Hue ones and they have their cheaper Wiz ones.
[01:47:58.080 --> 01:48:01.280]   The cheaper Wiz ones will not be upgraded.
[01:48:01.280 --> 01:48:03.600]   The Hue's will be because they're running through a hub.
[01:48:03.600 --> 01:48:06.400]   So the hub will get a software update to talk about lights.
[01:48:06.400 --> 01:48:06.880]   Okay, that makes sense.
[01:48:06.880 --> 01:48:08.880]   That makes a lot of sense.
[01:48:08.880 --> 01:48:12.320]   Some lights that run things, well, no.
[01:48:12.320 --> 01:48:14.720]   Yeah, no, we'll just go with no.
[01:48:14.720 --> 01:48:18.240]   Some of the lights like Nano Leaf put out light bulbs with thread enabled
[01:48:18.240 --> 01:48:23.120]   and they did that to make it eventually compatible with matter.
[01:48:24.880 --> 01:48:29.040]   Let's play the drums and do a Google change log.
[01:48:29.040 --> 01:48:32.720]   The Google change log.
[01:48:32.720 --> 01:48:36.400]   Now that sounded normal.
[01:48:36.400 --> 01:48:41.680]   That's it's it's exactly the same as last.
[01:48:41.680 --> 01:48:43.360]   No, that sounded normal.
[01:48:43.360 --> 01:48:47.520]   John, is there any last week was weird.
[01:48:47.520 --> 01:48:49.360]   Yeah, yeah, it was.
[01:48:49.360 --> 01:48:51.520]   We don't know.
[01:48:51.520 --> 01:48:53.200]   We can't understand it.
[01:48:54.080 --> 01:48:58.320]   It sounds exactly the same to me, but anyway.
[01:48:58.320 --> 01:49:01.200]   Google fuchsia Google fuchsia.
[01:49:01.200 --> 01:49:05.680]   The update is rolling out widely to first generation nest hubs.
[01:49:05.680 --> 01:49:09.440]   If you have one of these nest devices, they used to run on kind of Chromecast,
[01:49:09.440 --> 01:49:10.400]   crack cast to us.
[01:49:10.400 --> 01:49:16.320]   Now kind of seamlessly behind the scenes, they're going to all be fuchsia.
[01:49:16.320 --> 01:49:19.200]   So there you go.
[01:49:19.200 --> 01:49:22.640]   But finally a fuchsia has a life fuchsia is alive.
[01:49:23.040 --> 01:49:23.920]   It's alive.
[01:49:23.920 --> 01:49:27.360]   Google Maps just added a bunch of new features,
[01:49:27.360 --> 01:49:30.080]   including just for Jeff Jarvis, a dark mode.
[01:49:30.080 --> 01:49:37.920]   Which is where it's dark mode or musicals?
[01:49:37.920 --> 01:49:39.360]   Musicals.
[01:49:39.360 --> 01:49:40.720]   Dark mode.
[01:49:40.720 --> 01:49:42.640]   I love them both.
[01:49:42.640 --> 01:49:45.920]   No, which is worse dark mode or moral panics?
[01:49:45.920 --> 01:49:48.560]   Oh, that's another minor entirely.
[01:49:48.560 --> 01:49:50.240]   So dark mode.
[01:49:50.240 --> 01:49:50.880]   That's hard Stacy.
[01:49:50.880 --> 01:49:51.600]   That's hard.
[01:49:51.600 --> 01:49:53.840]   I didn't know this in the past.
[01:49:53.840 --> 01:49:59.600]   You could not share your location from Google Maps to iMessage,
[01:49:59.600 --> 01:50:04.080]   but now you can and you can it's a live sharing.
[01:50:04.080 --> 01:50:06.560]   So it'll be automatically updating.
[01:50:06.560 --> 01:50:07.280]   I've used that.
[01:50:07.280 --> 01:50:11.520]   I guess I must have used it in either on an Android device or on an iPhone,
[01:50:11.520 --> 01:50:15.040]   but it's a great feature live traffic updates, best restaurants,
[01:50:15.040 --> 01:50:19.040]   dark mode and dark mode.
[01:50:19.040 --> 01:50:23.680]   All new features in the new dark mode, Google Maps.
[01:50:23.680 --> 01:50:28.400]   Google Calendar will soon let you share where you're working from.
[01:50:28.400 --> 01:50:34.560]   This is a sign of the time starting in August and of August into this month.
[01:50:34.560 --> 01:50:38.960]   You'll be able to indicate where you're working from directly on your calendar.
[01:50:38.960 --> 01:50:40.720]   You can add weekly working location,
[01:50:40.720 --> 01:50:44.000]   routine and update your location as plans change.
[01:50:44.000 --> 01:50:45.040]   I'm at home right now.
[01:50:45.040 --> 01:50:46.800]   I'm in my car.
[01:50:46.800 --> 01:50:48.000]   I'm at work.
[01:50:48.960 --> 01:50:50.240]   Nice.
[01:50:50.240 --> 01:50:56.800]   I do love being able to see where the kids are on the apps.
[01:50:56.800 --> 01:50:57.120]   Yeah.
[01:50:57.120 --> 01:50:58.000]   That's so...
[01:50:58.000 --> 01:51:01.440]   Because I want them to be independent, but at the same time,
[01:51:01.440 --> 01:51:03.520]   it's just a little bit of piece of money.
[01:51:03.520 --> 01:51:04.080]   That seems fair.
[01:51:04.080 --> 01:51:04.560]   Yeah.
[01:51:04.560 --> 01:51:06.800]   At what age do you turn that off?
[01:51:06.800 --> 01:51:09.440]   At what age do I what?
[01:51:09.440 --> 01:51:10.000]   Turn it off.
[01:51:10.000 --> 01:51:10.640]   Turn it off.
[01:51:10.640 --> 01:51:12.800]   When do you stop spying on your children?
[01:51:12.800 --> 01:51:14.480]   When you're out of the house.
[01:51:14.480 --> 01:51:14.880]   College?
[01:51:14.880 --> 01:51:15.440]   Yeah.
[01:51:15.440 --> 01:51:17.200]   When they're out of the house.
[01:51:17.200 --> 01:51:18.960]   Yeah, you're not responsible for them anymore.
[01:51:18.960 --> 01:51:21.360]   But secretly 46.
[01:51:21.360 --> 01:51:21.920]   Stays again.
[01:51:21.920 --> 01:51:25.200]   Do you know where Jake is right now?
[01:51:25.200 --> 01:51:25.520]   Jake?
[01:51:25.520 --> 01:51:27.520]   No.
[01:51:27.520 --> 01:51:27.760]   No.
[01:51:27.760 --> 01:51:33.680]   I think both my kids have find my turned on on their phones
[01:51:33.680 --> 01:51:35.760]   because they want to...
[01:51:35.760 --> 01:51:38.400]   If they lose it, they want to be able to find it.
[01:51:38.400 --> 01:51:41.120]   And they're we're all in the family,
[01:51:41.120 --> 01:51:43.280]   so I think I could see their location.
[01:51:43.280 --> 01:51:45.600]   You know, turned off her location is Lisa.
[01:51:45.600 --> 01:51:46.880]   She doesn't want to mean to know where she is.
[01:51:47.760 --> 01:51:49.200]   I don't have my location.
[01:51:49.200 --> 01:51:49.920]   Yeah.
[01:51:49.920 --> 01:51:51.760]   Yeah.
[01:51:51.760 --> 01:51:52.800]   Should I be suspicious?
[01:51:52.800 --> 01:51:53.360]   I don't have mine on.
[01:51:53.360 --> 01:51:54.480]   Yeah, I just saw it.
[01:51:54.480 --> 01:51:56.800]   I hate to come over your sight.
[01:51:56.800 --> 01:51:57.840]   Should I be worried?
[01:51:57.840 --> 01:52:00.480]   No, I know where she is at all times.
[01:52:00.480 --> 01:52:01.600]   She's right there down the hall.
[01:52:01.600 --> 01:52:06.160]   YouTube on iOS and Android tests instant comment
[01:52:06.160 --> 01:52:08.320]   translations for premium subscribers.
[01:52:08.320 --> 01:52:10.160]   Good news.
[01:52:10.160 --> 01:52:12.640]   We won't be testing instant comments any time soon.
[01:52:12.640 --> 01:52:14.400]   I consider nobody turns on comments.
[01:52:14.400 --> 01:52:19.280]   Uh, that's what we have the forums and discord for.
[01:52:19.280 --> 01:52:20.640]   We can at least moderate those.
[01:52:20.640 --> 01:52:21.680]   An ant.
[01:52:21.680 --> 01:52:22.160]   An ant.
[01:52:22.160 --> 01:52:26.960]   Android's newest accessibility feature
[01:52:26.960 --> 01:52:30.560]   lets you control your phone with facial expressions.
[01:52:30.560 --> 01:52:30.960]   Wow.
[01:52:30.960 --> 01:52:33.920]   That's an effort.
[01:52:33.920 --> 01:52:38.880]   This is part of the switch access, which is in accessibility.
[01:52:38.880 --> 01:52:43.440]   So it's really for people who have mobility issues and so forth.
[01:52:43.440 --> 01:52:48.160]   You can open mouth, then back to resting face is one of the gestures.
[01:52:48.160 --> 01:52:52.000]   Smile, then back to resting face is another gesture.
[01:52:52.000 --> 01:52:54.000]   That's kind of neat.
[01:52:54.000 --> 01:52:54.560]   And then you can.
[01:52:54.560 --> 01:52:55.280]   It's pretty neat.
[01:52:55.280 --> 01:52:56.400]   Yeah, that's really cool.
[01:52:56.400 --> 01:52:59.120]   Raising your eyebrows.
[01:52:59.120 --> 01:53:01.520]   I hate dark mode and then back to resting face.
[01:53:01.520 --> 01:53:02.160]   Yep.
[01:53:02.160 --> 01:53:03.040]   Looking left.
[01:53:03.040 --> 01:53:03.920]   Looking right.
[01:53:03.920 --> 01:53:04.560]   Looking up.
[01:53:04.560 --> 01:53:09.680]   The feature will by default ask for the user to set expressions for next.
[01:53:09.680 --> 01:53:13.280]   Select and pause, which stops the phone from recognizing other gestures.
[01:53:13.680 --> 01:53:14.480]   Temporarily.
[01:53:14.480 --> 01:53:17.840]   So you could have look left, go to the next page.
[01:53:17.840 --> 01:53:19.280]   That's great.
[01:53:19.280 --> 01:53:22.560]   I think it's mostly for people with mobility issues, but still.
[01:53:22.560 --> 01:53:23.120]   Yeah.
[01:53:23.120 --> 01:53:23.760]   You can use it.
[01:53:23.760 --> 01:53:26.640]   Kind of trying to think if that would be good on the Kindle.
[01:53:26.640 --> 01:53:27.680]   I know it doesn't have a camera.
[01:53:27.680 --> 01:53:28.800]   Oh, so as you're reading.
[01:53:28.800 --> 01:53:29.280]   Like when you're.
[01:53:29.280 --> 01:53:29.440]   Yeah.
[01:53:29.440 --> 01:53:32.240]   I could see Anderson.
[01:53:32.240 --> 01:53:32.960]   Do you have a tick?
[01:53:32.960 --> 01:53:35.600]   Something going on over there?
[01:53:35.600 --> 01:53:37.600]   What tell me about?
[01:53:38.960 --> 01:53:45.440]   And remember, we talked about Google being sued for $5 billion because the incognito tab
[01:53:45.440 --> 01:53:49.520]   doesn't hide what you're doing from Google.
[01:53:49.520 --> 01:53:52.640]   Well, that's being redesigned.
[01:53:52.640 --> 01:53:58.000]   Maybe in response, if you have the Canary version, the early developer version of Chrome,
[01:53:58.000 --> 01:53:59.920]   on Android, you'll be able to see it.
[01:53:59.920 --> 01:54:08.480]   Here's the on the left, the old version on the right, the new version.
[01:54:08.640 --> 01:54:12.000]   Maybe too much text on the left, right?
[01:54:12.000 --> 01:54:17.200]   And now it's just what incognito does after closing all incognito tabs,
[01:54:17.200 --> 01:54:21.520]   Chrome clears your browsing activity from this device, your search history from this device.
[01:54:21.520 --> 01:54:25.200]   Information editor informs what incognito doesn't do.
[01:54:25.200 --> 01:54:29.360]   Incognito does not make you invisible online.
[01:54:29.360 --> 01:54:34.080]   Sites know when you visit them, employers or schools contract browsing activity.
[01:54:34.080 --> 01:54:36.480]   Internet service providers may monitor web traffic.
[01:54:36.480 --> 01:54:38.080]   That's a lot clearer.
[01:54:38.080 --> 01:54:38.960]   That's much better.
[01:54:38.960 --> 01:54:44.400]   And stands a chance for people to read it, considering it's not terrible.
[01:54:44.400 --> 01:54:45.280]   It's a lot shorter.
[01:54:45.280 --> 01:54:50.000]   It's roughly the same information, but I think it's just in a clearer format.
[01:54:50.000 --> 01:54:54.160]   And I believe that's the Google change law.
[01:54:54.160 --> 01:54:56.560]   Yeah.
[01:54:56.560 --> 01:55:05.760]   I think that is all she...
[01:55:05.760 --> 01:55:07.280]   Have you done it again, Leo?
[01:55:07.280 --> 01:55:09.680]   Have you found everything possible interesting we could talk about?
[01:55:09.680 --> 01:55:10.640]   Well, I don't know.
[01:55:10.640 --> 01:55:12.080]   If you see something you want me to...
[01:55:12.080 --> 01:55:13.200]   The talent is a wonder.
[01:55:13.200 --> 01:55:14.640]   If you see something...
[01:55:14.640 --> 01:55:15.520]   If you see something...
[01:55:15.520 --> 01:55:16.160]   Say something...
[01:55:16.160 --> 01:55:17.520]   Say something...
[01:55:17.520 --> 01:55:19.120]   You know me, I will.
[01:55:19.120 --> 01:55:20.480]   The state of Hamburg...
[01:55:20.480 --> 01:55:22.240]   It's August, you guys.
[01:55:22.240 --> 01:55:23.280]   There's not a lot of...
[01:55:23.280 --> 01:55:26.320]   Well, we've been gassing for an hour and 54 minutes.
[01:55:26.320 --> 01:55:26.880]   That's plenty.
[01:55:26.880 --> 01:55:30.240]   You don't want to overdo your overstay are welcome.
[01:55:30.240 --> 01:55:31.520]   I have a quick question.
[01:55:31.520 --> 01:55:31.760]   Yes.
[01:55:31.760 --> 01:55:33.200]   Would you like or hate chirp?
[01:55:33.200 --> 01:55:36.240]   Chirp?
[01:55:36.240 --> 01:55:37.600]   He's not on Twitter.
[01:55:37.600 --> 01:55:38.480]   He has no idea.
[01:55:38.480 --> 01:55:39.200]   Oh, that's right.
[01:55:39.200 --> 01:55:40.880]   That was the other Twitter that does it.
[01:55:40.880 --> 01:55:42.160]   What you talk about, Willis?
[01:55:42.160 --> 01:55:43.120]   It's the new Twitter font.
[01:55:43.120 --> 01:55:44.480]   That's the new Twitter font.
[01:55:44.480 --> 01:55:46.080]   Oh, I thought that was a no Twitter.
[01:55:46.080 --> 01:55:48.000]   If I go there now, will I have it?
[01:55:48.000 --> 01:55:48.880]   Oh, I don't like it.
[01:55:48.880 --> 01:55:49.360]   Yes.
[01:55:49.360 --> 01:55:49.920]   I hate it.
[01:55:49.920 --> 01:55:51.760]   Ooh, change.
[01:55:51.760 --> 01:55:52.480]   Ah-ha!
[01:55:52.480 --> 01:55:52.800]   Ow.
[01:55:52.800 --> 01:55:55.200]   No, it's an ugly ass font.
[01:55:55.200 --> 01:55:57.920]   Oh, chirp.
[01:55:57.920 --> 01:55:58.400]   Okay.
[01:55:58.400 --> 01:55:58.880]   Well, it's just...
[01:55:58.880 --> 01:56:00.240]   Well, I'm not alone because aren't they...
[01:56:01.200 --> 01:56:02.240]   Doesn't everybody hate it?
[01:56:02.240 --> 01:56:03.920]   Not everybody.
[01:56:03.920 --> 01:56:05.280]   Oh, it says it's change in Twitter.
[01:56:05.280 --> 01:56:06.880]   Of course, some people were screaming murder.
[01:56:06.880 --> 01:56:08.000]   It's just an ugly font.
[01:56:08.000 --> 01:56:09.040]   I don't like the kerning.
[01:56:09.040 --> 01:56:11.600]   It's ugly.
[01:56:11.600 --> 01:56:12.480]   What was it before?
[01:56:12.480 --> 01:56:14.480]   Just not much better.
[01:56:14.480 --> 01:56:15.600]   Older.
[01:56:15.600 --> 01:56:16.640]   Just do Helvetica.
[01:56:16.640 --> 01:56:18.480]   This is not a...
[01:56:18.480 --> 01:56:20.320]   Helvetica people.
[01:56:20.320 --> 01:56:21.600]   This is not a good font.
[01:56:21.600 --> 01:56:22.880]   Uh, it's weird.
[01:56:22.880 --> 01:56:25.600]   It's just new.
[01:56:25.600 --> 01:56:26.080]   Give it a...
[01:56:26.080 --> 01:56:26.880]   Give it like...
[01:56:26.880 --> 01:56:27.360]   Exactly.
[01:56:27.360 --> 01:56:31.040]   Oh, people say that who don't really appreciate fonts.
[01:56:32.000 --> 01:56:33.040]   But there is a...
[01:56:33.040 --> 01:56:33.520]   Oh, my.
[01:56:33.520 --> 01:56:33.920]   There is.
[01:56:33.920 --> 01:56:34.480]   Oh, my.
[01:56:34.480 --> 01:56:35.520]   The font says something.
[01:56:35.520 --> 01:56:37.360]   Did I just get font-shamed?
[01:56:37.360 --> 01:56:38.720]   I think I just got font-shamed.
[01:56:38.720 --> 01:56:39.840]   Yes, you did.
[01:56:39.840 --> 01:56:42.000]   Anybody who says, "Oh, it's just a little bigger,
[01:56:42.000 --> 01:56:43.760]   or a little bolder, a little less bold."
[01:56:43.760 --> 01:56:44.640]   That's not it at all.
[01:56:44.640 --> 01:56:45.600]   There's all sorts of things that you want.
[01:56:45.600 --> 01:56:46.320]   Let me tell you about that.
[01:56:46.320 --> 01:56:46.400]   Tell you about that.
[01:56:46.400 --> 01:56:46.880]   Let me tell you about that.
[01:56:46.880 --> 01:56:47.360]   Let me tell you about that.
[01:56:47.360 --> 01:56:48.240]   Oh, God, no.
[01:56:48.240 --> 01:56:50.000]   I agree with you.
[01:56:50.000 --> 01:56:52.480]   I took an entire class on fonts.
[01:56:52.480 --> 01:56:53.760]   Okay, okay, okay.
[01:56:53.760 --> 01:56:55.680]   It's a...
[01:56:55.680 --> 01:56:57.440]   Experts says it's not accessible.
[01:56:57.440 --> 01:56:58.960]   Well, I don't think it's inaccessible.
[01:56:58.960 --> 01:57:00.080]   But it's hurting my eyes.
[01:57:00.080 --> 01:57:01.360]   I'll tell you that.
[01:57:01.360 --> 01:57:02.480]   Well, this is a dark mode.
[01:57:02.480 --> 01:57:04.000]   No.
[01:57:04.000 --> 01:57:07.200]   You know, on my website,
[01:57:07.200 --> 01:57:11.360]   I have a button that you can make it dark mode,
[01:57:11.360 --> 01:57:13.520]   or you can make it light mode.
[01:57:13.520 --> 01:57:14.480]   You can make it dark mode.
[01:57:14.480 --> 01:57:14.880]   Is it dark mode?
[01:57:14.880 --> 01:57:15.440]   Is that?
[01:57:15.440 --> 01:57:16.080]   Or you can make...
[01:57:16.080 --> 01:57:17.760]   That's one of my many websites.
[01:57:17.760 --> 01:57:20.160]   Leo.fm.
[01:57:20.160 --> 01:57:20.800]   It's a button.
[01:57:20.800 --> 01:57:21.840]   I put that there for...
[01:57:21.840 --> 01:57:23.200]   Call it the Jeff button.
[01:57:23.200 --> 01:57:26.560]   What are Jeff's never hitting it?
[01:57:26.560 --> 01:57:28.320]   What do you think of this font?
[01:57:28.320 --> 01:57:31.280]   It's so you can push Jeff's buttons, basically.
[01:57:31.280 --> 01:57:32.560]   I think it's a mass font.
[01:57:32.560 --> 01:57:34.080]   Well, no, it's ugly.
[01:57:34.080 --> 01:57:36.960]   Okay.
[01:57:36.960 --> 01:57:37.440]   Okay.
[01:57:37.440 --> 01:57:40.240]   Really?
[01:57:40.240 --> 01:57:40.640]   Yeah.
[01:57:40.640 --> 01:57:45.920]   There's something about your font shaming as an honor.
[01:57:45.920 --> 01:57:48.000]   This is something about this font bothers me.
[01:57:48.000 --> 01:57:49.280]   I can't tell you what it is,
[01:57:49.280 --> 01:57:50.560]   but it's hurting my eyes.
[01:57:50.560 --> 01:57:51.440]   The chirp font.
[01:57:51.440 --> 01:57:53.760]   Seriously, go to light mode
[01:57:53.760 --> 01:57:54.720]   just to see if you can save the book.
[01:57:54.720 --> 01:57:55.360]   I'm just curious.
[01:57:57.600 --> 01:57:59.040]   How do you do that, Jeff?
[01:57:59.040 --> 01:58:00.080]   I don't know.
[01:58:00.080 --> 01:58:01.840]   I have no idea because I never do it, Leo.
[01:58:01.840 --> 01:58:06.080]   Display, accessible display, font size, background.
[01:58:06.080 --> 01:58:06.560]   You don't chirp, actually.
[01:58:06.560 --> 01:58:09.120]   It looks a lot like the Discord font, doesn't it?
[01:58:09.120 --> 01:58:10.240]   Let me just...
[01:58:10.240 --> 01:58:10.480]   Oh, yeah.
[01:58:10.480 --> 01:58:11.920]   I like it better in light mode.
[01:58:11.920 --> 01:58:12.320]   You're right.
[01:58:12.320 --> 01:58:13.200]   Yeah.
[01:58:13.200 --> 01:58:15.520]   It's still a little...
[01:58:15.520 --> 01:58:17.600]   Laji's a little weird that there's...
[01:58:17.600 --> 01:58:18.160]   Something a little...
[01:58:18.160 --> 01:58:21.840]   Kind of playful a little bit with this font.
[01:58:21.840 --> 01:58:22.640]   Like the R...
[01:58:22.640 --> 01:58:24.560]   That's their goal, probably.
[01:58:24.560 --> 01:58:26.720]   The G is funky in chirp.
[01:58:26.720 --> 01:58:27.200]   Yeah.
[01:58:27.200 --> 01:58:28.000]   It's a...
[01:58:28.000 --> 01:58:28.720]   I don't like it.
[01:58:28.720 --> 01:58:30.080]   I notice that because I'm a gigastacy.
[01:58:30.080 --> 01:58:31.120]   Yeah, it's kind of a...
[01:58:31.120 --> 01:58:32.480]   It changes a lot.
[01:58:32.480 --> 01:58:33.680]   It's trying to be jonty.
[01:58:33.680 --> 01:58:36.800]   It's a jonty font and I don't like it.
[01:58:36.800 --> 01:58:38.160]   It's called chirp.
[01:58:38.160 --> 01:58:40.400]   Yes, yes, chirp sounds jonty, doesn't it?
[01:58:40.400 --> 01:58:42.400]   It's a bit jonty.
[01:58:42.400 --> 01:58:43.840]   It looks kind of jonty.
[01:58:43.840 --> 01:58:45.040]   It's a jonty font.
[01:58:45.040 --> 01:58:46.560]   Jonty fonty.
[01:58:46.560 --> 01:58:49.120]   Yeah.
[01:58:49.120 --> 01:58:51.520]   Oh, y'all.
[01:58:51.520 --> 01:58:56.400]   They killed the fast past at Disney World,
[01:58:56.400 --> 01:58:59.760]   in Disneyland and introduced a new fee for...
[01:58:59.760 --> 01:59:02.000]   It's the Gini Plus.
[01:59:02.000 --> 01:59:05.040]   It's a skip online benefit for a daily fee.
[01:59:05.040 --> 01:59:07.680]   That's greedy.
[01:59:07.680 --> 01:59:08.240]   That's Disney.
[01:59:08.240 --> 01:59:09.280]   Otherwise known as Disney.
[01:59:09.280 --> 01:59:12.320]   No, but then you have to pay for the fast past before.
[01:59:12.320 --> 01:59:14.320]   They always do that.
[01:59:14.320 --> 01:59:15.840]   No, you just had to go sign...
[01:59:15.840 --> 01:59:19.600]   You could sign up for the fast past and pay...
[01:59:19.600 --> 01:59:20.480]   Did you pay extra?
[01:59:20.480 --> 01:59:21.760]   Did you just show up at the...
[01:59:21.760 --> 01:59:24.000]   No, you paid your shoulder on the machine.
[01:59:24.000 --> 01:59:24.400]   You showed up on the machine.
[01:59:25.840 --> 01:59:27.040]   You paid for fast past before.
[01:59:27.040 --> 01:59:28.800]   I think you got to choose like three times.
[01:59:28.800 --> 01:59:29.760]   Oh, yeah.
[01:59:29.760 --> 01:59:30.960]   There were certain...
[01:59:30.960 --> 01:59:31.600]   Yes, you're right.
[01:59:31.600 --> 01:59:34.560]   You got three rides or something that you could do that to.
[01:59:34.560 --> 01:59:36.000]   That's right for free.
[01:59:36.000 --> 01:59:39.040]   But obviously, that's just a come on for the...
[01:59:39.040 --> 01:59:41.440]   You know, super duper fast past.
[01:59:41.440 --> 01:59:49.760]   I think we could, very reasonably,
[01:59:49.760 --> 01:59:51.520]   at this point in the show,
[01:59:51.520 --> 01:59:53.360]   do our back of the book,
[01:59:53.360 --> 01:59:54.160]   our picks of the week.
[01:59:54.160 --> 01:59:57.420]   Would you all be interested in that?
[01:59:57.420 --> 02:00:00.300]   It just feels like we're one step closer to Waffles,
[02:00:00.300 --> 02:00:05.140]   I'm just saying it Waffles or pie.
[02:00:05.140 --> 02:00:07.080]   I need pie, I'm out of butter.
[02:00:07.080 --> 02:00:09.040]   - Pie, y'all. - Pie.
[02:00:09.040 --> 02:00:13.320]   - Western, no, Eastern Washington, just driving through,
[02:00:13.320 --> 02:00:15.040]   no one told me this existed,
[02:00:15.040 --> 02:00:16.700]   but you could just drive through all these small towns
[02:00:16.700 --> 02:00:18.980]   and they all have a shop that will sell ya pie paid
[02:00:18.980 --> 02:00:20.740]   with like fruit from next door.
[02:00:22.420 --> 02:00:25.620]   - Pie. - Okay, cake or pie, Stacy?
[02:00:25.620 --> 02:00:29.060]   - They serve very different needs.
[02:00:29.060 --> 02:00:32.700]   - No, you gotta answer. - Pie is a breakfast food.
[02:00:32.700 --> 02:00:34.200]   - Gotta answer. - Pie is a breakfast food.
[02:00:34.200 --> 02:00:37.500]   I'm liking your thinking here.
[02:00:37.500 --> 02:00:39.260]   You wouldn't need to dessert for breakfast,
[02:00:39.260 --> 02:00:41.980]   but you might eat a pie for breakfast, you're right.
[02:00:41.980 --> 02:00:46.980]   - I think I might be more pie just because it's more useful.
[02:00:46.980 --> 02:00:49.380]   You could have pie in more circumstances
[02:00:49.380 --> 02:00:51.060]   than you can really legitimately have cake.
[02:00:51.060 --> 02:00:53.460]   - Fair, fair, there you go. - Plus fruit in dough.
[02:00:53.460 --> 02:00:56.380]   - Is your vote what I think it's gonna be?
[02:00:56.380 --> 02:00:57.780]   - Pie is always good. - Pie is always good.
[02:00:57.780 --> 02:00:59.180]   - Cake. - Oh, of course.
[02:00:59.180 --> 02:01:00.540]   - And Jeff, you agree, I think.
[02:01:00.540 --> 02:01:01.860]   Anybody who eats kachoey pie.
[02:01:01.860 --> 02:01:06.140]   - Kachoey pie. - Kachoey pie.
[02:01:06.140 --> 02:01:10.500]   - Yes. - Here is a entire article
[02:01:10.500 --> 02:01:12.980]   about pie shops in Washington state.
[02:01:12.980 --> 02:01:18.740]   Of course, it's from a site called Washington, the state.
[02:01:18.740 --> 02:01:21.060]   (laughing)
[02:01:21.060 --> 02:01:22.740]   Marion Berry's gotta be on that list.
[02:01:22.740 --> 02:01:24.500]   - Oh, love Marion Berry. - Oh, Mary Berry's,
[02:01:24.500 --> 02:01:26.180]   there isn't. - Yeah.
[02:01:26.180 --> 02:01:30.340]   - Okay, you gotta go to Skagit Valley in Ferndale
[02:01:30.340 --> 02:01:32.980]   and buy a slice from Barb's pies and pastries
[02:01:32.980 --> 02:01:34.940]   in the Carnation Building there.
[02:01:34.940 --> 02:01:37.140]   Should we take a look at Barb's pies and pastries?
[02:01:37.140 --> 02:01:39.300]   - You had me at Barb's. - Barb's.
[02:01:39.300 --> 02:01:41.420]   Anybody named Barb's gotta make good pies.
[02:01:41.420 --> 02:01:44.860]   Look at that, we brought it to ad block detected.
[02:01:44.860 --> 02:01:46.420]   There's a pay wall.
[02:01:46.420 --> 02:01:50.980]   - There's a pay wall blocking us from Barb's pies.
[02:01:50.980 --> 02:01:52.700]   - The pie's the fourth day creator.
[02:01:52.700 --> 02:01:54.100]   - What the hell?
[02:01:54.100 --> 02:01:55.540]   He's the pie Nazi.
[02:01:55.540 --> 02:02:02.300]   I've never heard of a pie shop blocking for her.
[02:02:02.300 --> 02:02:04.300]   What kind of ads can she advertise?
[02:02:04.300 --> 02:02:05.620]   - Yeah. - Yeah, what does she advertise?
[02:02:05.620 --> 02:02:08.060]   - How about, let's go to the Farms Reach Cafe.
[02:02:08.060 --> 02:02:09.340]   Let's see if they have an ad block.
[02:02:09.340 --> 02:02:11.220]   - Barb, you lost. - It's a Facebook.
[02:02:11.220 --> 02:02:14.100]   You definitely lost me.
[02:02:14.100 --> 02:02:15.660]   - Yep, farms reach. - Oh yeah, all these,
[02:02:15.660 --> 02:02:18.620]   no, you basically just drive around, didn't you?
[02:02:18.620 --> 02:02:20.140]   - Yeah, you don't need to stop it.
[02:02:20.140 --> 02:02:23.940]   - Use the web. - Oh, Barb's pies is not work.
[02:02:23.940 --> 02:02:27.020]   Barb's pies is not, it's no longer Barb's.
[02:02:27.020 --> 02:02:30.300]   - Oh, that's why the ad blocker, yeah.
[02:02:30.300 --> 02:02:36.900]   Oh look, I'm being delivered via extensible.
[02:02:36.900 --> 02:02:40.540]   - I love that. - Oh, it's Waffle Time.
[02:02:40.540 --> 02:02:41.540]   (laughing)
[02:02:41.540 --> 02:02:44.220]   Waffle Time. - Oh, this is, mm.
[02:02:44.220 --> 02:02:45.140]   - Well done.
[02:02:45.140 --> 02:02:48.500]   - Where did you get this waffle? - Yeah, it's a kind of a toasty waffle.
[02:02:48.500 --> 02:03:11.220]   - Oh, listen, it's an
[02:03:11.220 --> 02:03:14.980]   it, what is your pick of the week, Stacy?
[02:03:14.980 --> 02:03:16.300]   - All right, my pick of the week,
[02:03:16.300 --> 02:03:19.260]   I wanted to do this last week and I keep screwing up the name.
[02:03:19.260 --> 02:03:22.580]   So I'm gonna do it, I'm looking at it right now.
[02:03:22.580 --> 02:03:25.940]   Okay, this is how they tell me the world ends,
[02:03:25.940 --> 02:03:30.260]   the cyber weapons arm rates by Nicole Perloff.
[02:03:30.260 --> 02:03:34.100]   And I'm a little late to this because I didn't want to read it
[02:03:34.100 --> 02:03:36.660]   because I was like, dude, I know all about our crappy
[02:03:36.660 --> 02:03:39.700]   cybersecurity practices, right?
[02:03:39.700 --> 02:03:44.860]   Just stop what you're doing, go get it because you do not know.
[02:03:44.860 --> 02:03:47.780]   And this is a wonderful book for two reasons.
[02:03:47.780 --> 02:03:52.140]   One, it lays out a lot of risk factors in common people's
[02:03:52.140 --> 02:03:55.460]   language but is respectful of the tech side.
[02:03:55.460 --> 02:04:02.460]   Two, as a journalist, it was awesome because Nicole talks a lot
[02:04:02.460 --> 02:04:04.620]   about her reporting on this issue.
[02:04:04.620 --> 02:04:07.180]   So as a journalist, it was really interesting to read
[02:04:07.180 --> 02:04:09.020]   how she was like trying to find,
[02:04:09.020 --> 02:04:13.500]   like this is a hard community to crack and write about.
[02:04:13.500 --> 02:04:15.540]   And so that was kind of cool.
[02:04:15.540 --> 02:04:19.820]   And at the end, she offers some really good takeaways
[02:04:19.820 --> 02:04:23.260]   and advice and also includes kind of some bits of hope
[02:04:23.260 --> 02:04:27.340]   that I wish I would love to see her write more about.
[02:04:27.340 --> 02:04:31.380]   She talks about like Japan and Norway having kind of solved
[02:04:31.380 --> 02:04:36.380]   a lot of the cybersecurity problems because they've implemented
[02:04:37.820 --> 02:04:39.300]   practices, but I don't know what they were.
[02:04:39.300 --> 02:04:40.900]   So, but that would be another whole book.
[02:04:40.900 --> 02:04:43.700]   Anyway, the point is that book is great.
[02:04:43.700 --> 02:04:45.980]   And even if you think you know that we're screwed,
[02:04:45.980 --> 02:04:46.820]   you should really read it.
[02:04:46.820 --> 02:04:47.660]   - She's good.
[02:04:47.660 --> 02:04:49.900]   I think she's an airtime cybersecurity reporter.
[02:04:49.900 --> 02:04:50.860]   She's very good.
[02:04:50.860 --> 02:04:54.420]   This is how they tell me the world ends.
[02:04:54.420 --> 02:04:55.580]   Nicole Perreault.
[02:04:55.580 --> 02:04:56.420]   - Yes.
[02:04:56.420 --> 02:04:57.420]   - Oh, yes.
[02:04:57.420 --> 02:04:58.260]   - I am another.
[02:04:58.260 --> 02:05:00.420]   - Oh, yeah, she talks about Russian interference
[02:05:00.420 --> 02:05:02.660]   in the election and it almost made me cry.
[02:05:06.300 --> 02:05:08.220]   How dare she make you cry.
[02:05:08.220 --> 02:05:09.060]   - How dare she?
[02:05:09.060 --> 02:05:10.940]   - I'm gonna add this to my audible.
[02:05:10.940 --> 02:05:13.340]   Thank you.
[02:05:13.340 --> 02:05:15.380]   I've got that in the A&P.
[02:05:15.380 --> 02:05:16.820]   So, I'm, this is--
[02:05:16.820 --> 02:05:18.700]   - And the box, did you add the box book?
[02:05:18.700 --> 02:05:21.460]   Plus he has a new book out after the box.
[02:05:21.460 --> 02:05:23.180]   - What's the box?
[02:05:23.180 --> 02:05:24.020]   - That's the box.
[02:05:24.020 --> 02:05:26.540]   - The box, you just showed me the book I could buy,
[02:05:26.540 --> 02:05:27.540]   the container ships.
[02:05:27.540 --> 02:05:28.580]   - Oh, the container ships.
[02:05:28.580 --> 02:05:29.420]   - Mark Levinson.
[02:05:29.420 --> 02:05:30.780]   - Yes.
[02:05:30.780 --> 02:05:31.620]   Oh man.
[02:05:31.620 --> 02:05:32.460]   - What happens after the box?
[02:05:32.460 --> 02:05:33.700]   - You've grown.
[02:05:33.700 --> 02:05:35.940]   Well, that's about how globalization is not what you think.
[02:05:35.940 --> 02:05:37.460]   I just saw it in the listing there.
[02:05:37.460 --> 02:05:38.940]   Thanks to Leo.
[02:05:38.940 --> 02:05:39.940]   - And outside the box.
[02:05:39.940 --> 02:05:42.660]   - Now the shipping container made the world
[02:05:42.660 --> 02:05:44.380]   smaller in the world economy bigger.
[02:05:44.380 --> 02:05:47.220]   And then outside the box, another Mark Levinson.
[02:05:47.220 --> 02:05:50.060]   He apparently only writes books with box in the title.
[02:05:50.060 --> 02:05:55.060]   How globalization, how globalization changed
[02:05:55.060 --> 02:05:57.820]   from moving stuff to--
[02:05:57.820 --> 02:05:59.460]   - Like one another whiskey box.
[02:05:59.460 --> 02:06:01.460]   - Yeah, I was like, what's in that box man?
[02:06:01.460 --> 02:06:03.820]   - I'm a fucking pig.
[02:06:03.820 --> 02:06:05.420]   - It's a bourbon syrup here.
[02:06:05.420 --> 02:06:07.780]   - Think of bad data.
[02:06:07.780 --> 02:06:09.300]   - Give off waffles.
[02:06:09.300 --> 02:06:10.140]   How global?
[02:06:10.140 --> 02:06:11.980]   (laughing)
[02:06:11.980 --> 02:06:13.860]   Yeah, that book.
[02:06:13.860 --> 02:06:15.700]   Okay, thank you Stacey.
[02:06:15.700 --> 02:06:17.780]   That's a good recommendation, I like that.
[02:06:17.780 --> 02:06:21.220]   - Mr. A&P.
[02:06:21.220 --> 02:06:24.620]   - Not Mr. A&T.
[02:06:24.620 --> 02:06:25.460]   - A&T.
[02:06:25.460 --> 02:06:27.780]   - No, Mr. A&P, Mr.
[02:06:27.780 --> 02:06:28.620]   - A&P.
[02:06:28.620 --> 02:06:29.780]   - Mr. - So, some more related.
[02:06:29.780 --> 02:06:32.020]   I don't know why I'm fascinated by these things,
[02:06:32.020 --> 02:06:34.060]   but I'm fascinated by ghost kitchens.
[02:06:34.060 --> 02:06:34.900]   - Me too.
[02:06:34.900 --> 02:06:35.740]   - Me too.
[02:06:35.740 --> 02:06:36.580]   - Me too.
[02:06:36.580 --> 02:06:38.500]   - COVID, and I never know when they order
[02:06:38.500 --> 02:06:40.100]   any more ghost kitchen,
[02:06:40.100 --> 02:06:42.980]   but the business just fast, we can hear you chewing, Leo.
[02:06:42.980 --> 02:06:45.240]   (laughing)
[02:06:45.240 --> 02:06:48.420]   - I at least mute when I eat my waffles.
[02:06:48.420 --> 02:06:49.940]   - It's thick and fluffy.
[02:06:49.940 --> 02:06:52.180]   (laughing)
[02:06:52.180 --> 02:06:54.180]   - Yep.
[02:06:54.180 --> 02:06:55.260]   - We don't hear fluffy.
[02:06:55.260 --> 02:06:56.740]   (laughing)
[02:06:56.740 --> 02:06:59.580]   - Wendy's is to open 700 ghost kitchens
[02:06:59.580 --> 02:07:01.380]   with reef technology.
[02:07:01.380 --> 02:07:02.220]   (crunching)
[02:07:02.220 --> 02:07:03.060]   What?
[02:07:03.060 --> 02:07:03.900]   (laughing)
[02:07:03.900 --> 02:07:05.740]   - I'm making Leo hungry, talking about Wendy's.
[02:07:05.740 --> 02:07:07.020]   He's gonna go get a double.
[02:07:07.020 --> 02:07:09.780]   So, what fascinates me about this
[02:07:09.780 --> 02:07:13.140]   is that the fast food business,
[02:07:13.140 --> 02:07:15.060]   like the department store business,
[02:07:15.060 --> 02:07:17.500]   used to be in great measure, a real estate business, right?
[02:07:17.500 --> 02:07:19.180]   McDonald's was being all about--
[02:07:19.180 --> 02:07:20.020]   - Right, they owned the--
[02:07:20.020 --> 02:07:20.860]   - About the land.
[02:07:20.860 --> 02:07:21.700]   - Real estate.
[02:07:21.700 --> 02:07:22.860]   - Right, you franchised the restaurant,
[02:07:22.860 --> 02:07:24.620]   but it kept the land.
[02:07:24.620 --> 02:07:27.220]   - And they knew the science of where to put it.
[02:07:27.220 --> 02:07:28.660]   And so on and so on and so on.
[02:07:28.660 --> 02:07:31.580]   So, it just strikes me that the ghost kitchen thing,
[02:07:31.580 --> 02:07:33.260]   which is that they think that they're gonna make
[02:07:33.260 --> 02:07:36.540]   between 500,000 and one million per unit.
[02:07:36.540 --> 02:07:37.380]   - Wow.
[02:07:37.380 --> 02:07:38.220]   - I've seen all of that.
[02:07:38.220 --> 02:07:39.260]   - It's just a little truck.
[02:07:39.260 --> 02:07:40.100]   So what is the--
[02:07:40.100 --> 02:07:41.940]   - It's the warehouse.
[02:07:41.940 --> 02:07:43.260]   - Oh, it's a where?
[02:07:43.260 --> 02:07:44.420]   - You know, it can be anywhere.
[02:07:44.420 --> 02:07:46.620]   Because there's no need to be public,
[02:07:46.620 --> 02:07:48.740]   you just need people to drive the food somewhere.
[02:07:48.740 --> 02:07:51.180]   - The Uber guy comes and gets it, yeah.
[02:07:51.180 --> 02:07:55.740]   - And so, the value of real estate in this business
[02:07:55.740 --> 02:07:56.620]   just kinda went nowhere.
[02:07:56.620 --> 02:07:59.460]   It's like the opposite of we work or something like that.
[02:07:59.460 --> 02:08:01.540]   I just find it interesting, that's all.
[02:08:01.540 --> 02:08:04.020]   I wanted to spend enough time here
[02:08:04.020 --> 02:08:06.380]   so Leo could get his whole waffle down.
[02:08:06.380 --> 02:08:07.580]   - Huh?
[02:08:07.580 --> 02:08:09.820]   So, that's interesting.
[02:08:09.820 --> 02:08:12.060]   It's so they can expand in areas
[02:08:12.060 --> 02:08:14.260]   where they don't have stores, I guess.
[02:08:14.260 --> 02:08:15.100]   Yeah.
[02:08:15.100 --> 02:08:17.180]   - Well, it's also to deliver, like if people,
[02:08:17.180 --> 02:08:19.220]   they're making a bet that people have changed
[02:08:19.220 --> 02:08:21.140]   the way they're going to get in each food.
[02:08:21.140 --> 02:08:22.300]   - Oh, good point.
[02:08:22.300 --> 02:08:23.140]   Yeah. - Right.
[02:08:23.140 --> 02:08:24.180]   - They want it delivered.
[02:08:24.180 --> 02:08:25.020]   - I like that.
[02:08:25.020 --> 02:08:26.500]   - This is exactly what I was talking about earlier.
[02:08:26.500 --> 02:08:28.500]   I just find it's fascinating how the pandemic
[02:08:28.500 --> 02:08:31.420]   has changed culture in the kind of somewhat
[02:08:31.420 --> 02:08:34.060]   permanent way, I'm sorry, Stacy, go ahead.
[02:08:34.060 --> 02:08:36.060]   - No, no, I was just gonna jump on the fact
[02:08:36.060 --> 02:08:38.540]   that Jeff's comment about real estate is really,
[02:08:38.540 --> 02:08:40.740]   that's very smart.
[02:08:40.740 --> 02:08:41.580]   - Oh, yes.
[02:08:41.580 --> 02:08:43.900]   - And I wonder, like if you think about McDonald's
[02:08:43.900 --> 02:08:46.340]   being optimized for highways,
[02:08:46.340 --> 02:08:51.340]   how would you optimize delivery for delivery drivers?
[02:08:51.340 --> 02:08:52.180]   - Right, right.
[02:08:52.180 --> 02:08:53.500]   - 'Cause you see some neighborhoods
[02:08:53.500 --> 02:08:55.860]   are actually fighting back against like,
[02:08:55.860 --> 02:08:58.420]   highly localized Amazon warehouses
[02:08:58.420 --> 02:08:59.620]   because they don't want the traffic
[02:08:59.620 --> 02:09:01.140]   running through their streets.
[02:09:01.140 --> 02:09:03.260]   So, huh.
[02:09:03.260 --> 02:09:05.180]   - If you haven't seen "The Founder" yet,
[02:09:05.180 --> 02:09:07.860]   which is a biopic about Ray Crock,
[02:09:07.860 --> 02:09:10.060]   the founder of McDonald's, in that movie,
[02:09:10.060 --> 02:09:14.460]   he has the insight, oh, I'm not selling hamburgers.
[02:09:14.460 --> 02:09:16.860]   It's a real estate business.
[02:09:16.860 --> 02:09:18.700]   And they dramatize it very effectively.
[02:09:18.700 --> 02:09:19.540]   They show and--
[02:09:19.540 --> 02:09:22.700]   - Did you know that Ray Crock also sent me a heat letter?
[02:09:22.700 --> 02:09:23.900]   - No.
[02:09:23.900 --> 02:09:24.740]   - Oh, God. - He called me
[02:09:24.740 --> 02:09:26.140]   a nickel millionaire.
[02:09:26.140 --> 02:09:27.260]   (laughing)
[02:09:27.260 --> 02:09:28.580]   - Wow.
[02:09:28.580 --> 02:09:29.420]   - What was he--
[02:09:29.420 --> 02:09:30.900]   - Ray Sinatra called him a bum
[02:09:30.900 --> 02:09:33.860]   and the founder of McDonald's called him a nickel millionaire.
[02:09:33.860 --> 02:09:35.900]   - Does that mean you have a million nickels?
[02:09:35.900 --> 02:09:38.820]   Well, that means you're kind of with heirs.
[02:09:38.820 --> 02:09:41.140]   So, there was a new McDonald's on Van S
[02:09:41.140 --> 02:09:43.700]   in San Francisco, a very fancy one in the day.
[02:09:43.700 --> 02:09:44.540]   - I remember that one.
[02:09:44.540 --> 02:09:45.660]   - I reviewed it for my column.
[02:09:45.660 --> 02:09:46.500]   - Yeah.
[02:09:46.500 --> 02:09:47.340]   - And I was disappointed.
[02:09:47.340 --> 02:09:48.500]   There was a picture of me in the paper
[02:09:48.500 --> 02:09:49.460]   and looking very sad,
[02:09:49.460 --> 02:09:51.260]   a little bit of a burger pounder.
[02:09:51.260 --> 02:09:53.860]   And in a coat and tie,
[02:09:53.860 --> 02:09:56.340]   trying to look like I was respectable doing this.
[02:09:56.340 --> 02:09:57.780]   And he was enraged.
[02:09:57.780 --> 02:09:59.460]   And he sent a letter to the paper,
[02:09:59.460 --> 02:10:01.780]   enraged that I dared do this.
[02:10:01.780 --> 02:10:02.620]   And I called him.
[02:10:02.620 --> 02:10:03.460]   - That's hysterical.
[02:10:03.460 --> 02:10:04.300]   - That's hysterical.
[02:10:04.300 --> 02:10:06.260]   - And I said, "Mr. Crock, you don't understand.
[02:10:06.260 --> 02:10:09.420]   "I sometimes eat at McDonald's five times a week,
[02:10:09.420 --> 02:10:11.020]   "which was sad and true."
[02:10:11.020 --> 02:10:12.180]   And I said, "I love McDonald's.
[02:10:12.180 --> 02:10:13.940]   "I believe in quality control, sir."
[02:10:13.940 --> 02:10:16.380]   And this store was not up to your standards
[02:10:16.380 --> 02:10:17.220]   in quality control.
[02:10:17.220 --> 02:10:19.140]   We hit it off brilliantly then.
[02:10:19.140 --> 02:10:21.180]   And everything was wonderful.
[02:10:21.180 --> 02:10:23.780]   - That Van S McDonald's has been closed.
[02:10:23.780 --> 02:10:24.620]   - No.
[02:10:24.620 --> 02:10:25.980]   - Oh, yeah, long ago. - No.
[02:10:25.980 --> 02:10:26.820]   - Yeah.
[02:10:26.820 --> 02:10:29.460]   - It was from the across from the opera house, right?
[02:10:29.460 --> 02:10:31.060]   - Yeah, which is where you wanna go after the opera
[02:10:31.060 --> 02:10:31.900]   is to go to big levels.
[02:10:31.900 --> 02:10:33.940]   - You shut it in 2015.
[02:10:33.940 --> 02:10:35.060]   They shut it down six years ago.
[02:10:35.060 --> 02:10:36.220]   Remember them? - Oh, that's so sad.
[02:10:36.220 --> 02:10:39.260]   - They used to go there before the opera.
[02:10:39.260 --> 02:10:41.020]   'Cause I'm a nickel million era also.
[02:10:41.020 --> 02:10:43.260]   (laughing)
[02:10:43.260 --> 02:10:46.220]   Wow.
[02:10:46.220 --> 02:10:50.540]   - Mr. Ant Pruitt, your pick of the week.
[02:10:50.540 --> 02:10:53.980]   - I wanna shout out a show on Netflix.
[02:10:53.980 --> 02:10:55.220]   This is a pop.
[02:10:55.220 --> 02:10:56.740]   I've only watched two episodes,
[02:10:56.740 --> 02:10:59.060]   but these two have been so well done.
[02:10:59.060 --> 02:11:02.420]   The first one spoke about the R&B group,
[02:11:02.420 --> 02:11:05.060]   Boys to Men and how they pretty much changed
[02:11:05.060 --> 02:11:09.620]   the R&B and pop industry back in the days
[02:11:09.620 --> 02:11:13.140]   in the early '90s and how everybody right after them
[02:11:13.140 --> 02:11:16.420]   decided to emulate them and it pretty much put them
[02:11:16.420 --> 02:11:19.260]   out of music because you get the likes of NSYNC
[02:11:19.260 --> 02:11:22.620]   and Backstreet Boys and so on and so forth.
[02:11:22.620 --> 02:11:24.500]   And then T-Pain and Episode Two
[02:11:24.500 --> 02:11:26.260]   were to talk about. - Oh, the King of Auto-Tune.
[02:11:26.260 --> 02:11:27.260]   - Yeah.
[02:11:27.260 --> 02:11:30.780]   - And that one was really, really good
[02:11:30.780 --> 02:11:34.580]   because T-Pain is ridiculously talented
[02:11:34.580 --> 02:11:36.700]   with music composition.
[02:11:36.700 --> 02:11:40.660]   It's added in care for the auto-tune sound,
[02:11:40.660 --> 02:11:43.060]   but his arrangement, so I've always thought
[02:11:43.060 --> 02:11:44.460]   his arrangements were quite nice.
[02:11:44.460 --> 02:11:45.460]   - Oh, it took over the world.
[02:11:45.460 --> 02:11:49.340]   I see that the Stockholm group is the third episode.
[02:11:49.340 --> 02:11:51.260]   Oh, I am gonna definitely watch this.
[02:11:51.260 --> 02:11:54.180]   This is great. - It is really, really well done.
[02:11:54.180 --> 02:11:55.620]   Netflix has just been crushing it
[02:11:55.620 --> 02:11:58.500]   with their own content here recently.
[02:11:58.500 --> 02:12:03.500]   And then my second pick is, I've been putting more art up there
[02:12:03.500 --> 02:12:07.180]   and I figured out Twitter folks might like this one,
[02:12:07.180 --> 02:12:08.940]   just my little play on words.
[02:12:08.940 --> 02:12:11.900]   It's called "Error Fire Not Found."
[02:12:11.900 --> 02:12:13.940]   - I loved your cat one.
[02:12:13.940 --> 02:12:15.860]   Somebody bought it right out from under me though,
[02:12:15.860 --> 02:12:16.700]   I gotta say.
[02:12:16.700 --> 02:12:18.460]   (laughing)
[02:12:18.460 --> 02:12:21.340]   - But this one I called it "Error Fire Not Found"
[02:12:21.340 --> 02:12:23.060]   because it was a 404.
[02:12:23.060 --> 02:12:24.180]   (laughing)
[02:12:24.180 --> 02:12:26.580]   But there's an actual story behind it.
[02:12:26.580 --> 02:12:31.580]   I snapped that at about three or four in the morning
[02:12:31.580 --> 02:12:34.900]   while I was out traveling one night for work.
[02:12:34.900 --> 02:12:37.140]   And the fire alarm went off in the hotel
[02:12:37.140 --> 02:12:39.780]   and there was no fire and while I was outside,
[02:12:39.780 --> 02:12:41.980]   while I got up, I decided to take my camera with me
[02:12:41.980 --> 02:12:44.780]   just because I'm weird enough like that.
[02:12:44.780 --> 02:12:47.860]   And I noticed, huh, 404 on the back of this truck
[02:12:47.860 --> 02:12:49.300]   and there's no fire here.
[02:12:49.300 --> 02:12:51.220]   This would be a cool image.
[02:12:51.220 --> 02:12:53.100]   That really literally was not found.
[02:12:53.100 --> 02:12:57.900]   And I like your price, which is 1, 404 Ethereum.
[02:12:57.900 --> 02:12:59.220]   - Oh, you noticed that too.
[02:12:59.220 --> 02:13:00.540]   - Yes.
[02:13:00.540 --> 02:13:01.900]   - Like it.
[02:13:01.900 --> 02:13:04.980]   You didn't want to make it 404.404 Ethereum
[02:13:04.980 --> 02:13:05.820]   that'd be too expensive.
[02:13:05.820 --> 02:13:06.660]   - No, no, no, no.
[02:13:06.660 --> 02:13:07.500]   - Yeah, one more.
[02:13:07.500 --> 02:13:09.100]   That's great.
[02:13:09.100 --> 02:13:11.140]   One more thing to plug 'cause it's coming up soon
[02:13:11.140 --> 02:13:14.940]   and I want everybody to register for ANSI Photo Workshop
[02:13:14.940 --> 02:13:16.340]   in New Orleans.
[02:13:16.340 --> 02:13:18.660]   - That's right, the Wanderers Photo Excurs.
[02:13:18.660 --> 02:13:21.580]   And then New Orleans with myself, Mr. Steve Brazo,
[02:13:21.580 --> 02:13:24.940]   Mr. Frady Clark and Mr. Andrews Gravini.
[02:13:24.940 --> 02:13:28.100]   Gonna talk about food photography,
[02:13:28.100 --> 02:13:30.380]   gonna talk about beverage photography,
[02:13:30.380 --> 02:13:32.380]   gonna talk about street photography.
[02:13:32.380 --> 02:13:34.100]   - New Orleans is such a great place.
[02:13:34.100 --> 02:13:35.420]   - Concerts.
[02:13:35.420 --> 02:13:38.660]   And so far it is still on.
[02:13:38.660 --> 02:13:41.980]   There have been some events canceling in New Orleans
[02:13:41.980 --> 02:13:44.620]   at the same time that we're there,
[02:13:44.620 --> 02:13:46.460]   but not everything is canceled.
[02:13:46.460 --> 02:13:48.300]   So, so far everything is still on for us.
[02:13:48.300 --> 02:13:51.460]   So, go ahead and register and we'll see you there.
[02:13:51.460 --> 02:13:52.300]   - I love it.
[02:13:52.300 --> 02:13:54.620]   There's ANSI, shining picture.
[02:13:54.620 --> 02:13:57.300]   And Pruitt.
[02:13:57.300 --> 02:13:58.820]   - My resting face.
[02:13:58.820 --> 02:13:59.780]   - Yeah, just your resting face.
[02:13:59.780 --> 02:14:01.020]   - Did you use the chirp font?
[02:14:01.020 --> 02:14:03.220]   And this, this looks like the chirp font.
[02:14:03.220 --> 02:14:04.700]   (laughs)
[02:14:04.700 --> 02:14:05.620]   Maybe they did.
[02:14:05.620 --> 02:14:07.380]   That's Mr. Frady's site.
[02:14:07.380 --> 02:14:08.380]   (laughs)
[02:14:08.380 --> 02:14:10.300]   - It looks like the chirp font.
[02:14:10.300 --> 02:14:13.780]   - We're gonna see it everywhere now, Leo.
[02:14:13.780 --> 02:14:17.300]   - Oh, I much prefer a Babis.
[02:14:17.300 --> 02:14:19.020]   - I think we've thought about that before.
[02:14:19.020 --> 02:14:19.860]   - Babis?
[02:14:19.860 --> 02:14:22.700]   I don't know that one.
[02:14:22.700 --> 02:14:26.380]   - B-E-B-A-S-N-E-A-U-E.
[02:14:26.380 --> 02:14:27.900]   Babis, new places.
[02:14:27.900 --> 02:14:30.940]   - I guess I am, I have to apologize
[02:14:30.940 --> 02:14:33.820]   because I am amongst font connoisseurs.
[02:14:33.820 --> 02:14:34.660]   I had no idea.
[02:14:34.660 --> 02:14:35.500]   - I knew it.
[02:14:35.500 --> 02:14:36.340]   - I do not.
[02:14:36.340 --> 02:14:37.180]   - I do not.
[02:14:37.180 --> 02:14:38.460]   - You're only amongst a few.
[02:14:38.460 --> 02:14:41.260]   I just wanna be clear that Waffles better than fonts.
[02:14:41.260 --> 02:14:42.940]   - Waffles better than fonts.
[02:14:42.940 --> 02:14:44.340]   - I will not argue that.
[02:14:44.340 --> 02:14:45.180]   - Yep.
[02:14:45.180 --> 02:14:47.980]   - Amazing stories about how the font,
[02:14:47.980 --> 02:14:50.140]   Janssen, which was the first Roman font,
[02:14:50.140 --> 02:14:52.420]   drove later designers insane,
[02:14:52.420 --> 02:14:55.100]   but I'll spare you and do that another time.
[02:14:55.100 --> 02:14:57.460]   - My pick of the week from Netflix,
[02:14:57.460 --> 02:15:00.100]   it's a little something called Waffles and Mochi.
[02:15:00.100 --> 02:15:03.580]   Two of my favorites.
[02:15:03.580 --> 02:15:05.020]   - I'll begin.
[02:15:05.020 --> 02:15:08.500]   - All together in one exciting little cartoon.
[02:15:08.500 --> 02:15:10.220]   We can't show this 'cause I'll be
[02:15:10.220 --> 02:15:11.620]   taken down by Netflix.
[02:15:11.620 --> 02:15:14.020]   - Is that Michelle Obama's thing?
[02:15:14.020 --> 02:15:15.380]   - No, it's a cartoon.
[02:15:15.380 --> 02:15:16.940]   I just searched for Waffles and Netflix.
[02:15:16.940 --> 02:15:18.580]   I just, I was making a joke.
[02:15:18.580 --> 02:15:19.420]   I apologize.
[02:15:19.420 --> 02:15:21.020]   - Oh no, I think that's her.
[02:15:21.020 --> 02:15:22.140]   Didn't she do the Waffles?
[02:15:22.140 --> 02:15:23.420]   Isn't she affiliated with that?
[02:15:23.420 --> 02:15:25.660]   - Oh, well, a little did I know.
[02:15:25.660 --> 02:15:26.700]   Maybe she is.
[02:15:26.700 --> 02:15:28.460]   - Yeah, that's Michelle Obama's.
[02:15:28.460 --> 02:15:30.500]   She's exactly what I was saying.
[02:15:30.500 --> 02:15:31.740]   - I knew I liked her.
[02:15:31.740 --> 02:15:33.660]   Waffles and Mochi.
[02:15:33.660 --> 02:15:35.700]   I knew I liked her.
[02:15:35.700 --> 02:15:36.860]   That's awesome.
[02:15:36.860 --> 02:15:39.580]   - I thought this was a sincere pick.
[02:15:39.580 --> 02:15:40.860]   Man, I am just...
[02:15:40.860 --> 02:15:42.900]   (laughing)
[02:15:42.900 --> 02:15:45.300]   - Well, here's my pick of the week.
[02:15:45.300 --> 02:15:48.460]   Eggo, thick and fluffy Waffles.
[02:15:48.460 --> 02:15:49.460]   Belgian style.
[02:15:49.460 --> 02:15:50.300]   - Oh no.
[02:15:50.300 --> 02:15:52.660]   - Mm, brown sugar.
[02:15:52.660 --> 02:15:53.940]   - I don't like it to John.
[02:15:53.940 --> 02:15:56.780]   Cut up the box so that I can hold this up apparently.
[02:15:56.780 --> 02:15:58.700]   (laughing)
[02:15:58.700 --> 02:16:00.540]   - There's only like six in a box,
[02:16:00.540 --> 02:16:03.300]   so you really don't get a lot.
[02:16:03.300 --> 02:16:04.700]   - John, where do the other five go?
[02:16:04.700 --> 02:16:06.260]   - Well, there's other options.
[02:16:06.260 --> 02:16:08.100]   Oh, original.
[02:16:08.100 --> 02:16:08.940]   - Is this a ready pack?
[02:16:08.940 --> 02:16:12.220]   - Blueberry, brown sugar, cinnamon, and double chocolatey.
[02:16:13.220 --> 02:16:15.460]   - I find my favorite is the normal
[02:16:15.460 --> 02:16:16.740]   because the brown sugar, cinnamon,
[02:16:16.740 --> 02:16:17.860]   and even are a little too sweet.
[02:16:17.860 --> 02:16:21.460]   And the chocolatey and blueberry, definitely too sweet.
[02:16:21.460 --> 02:16:24.140]   - I make my own sourdough waffles,
[02:16:24.140 --> 02:16:28.140]   and sometime we'll just invite you over for Waffle Fest.
[02:16:28.140 --> 02:16:28.980]   It'll be fun.
[02:16:28.980 --> 02:16:29.900]   - We make ricotta waffles.
[02:16:29.900 --> 02:16:31.580]   - Ooh, I've done that.
[02:16:31.580 --> 02:16:33.260]   - That is really good.
[02:16:33.260 --> 02:16:34.980]   That is really good.
[02:16:34.980 --> 02:16:36.340]   - You step my game up.
[02:16:36.340 --> 02:16:37.660]   (laughing)
[02:16:37.660 --> 02:16:38.660]   - There are no Eggo.
[02:16:38.660 --> 02:16:40.500]   - And we'll just visit Waffle.
[02:16:40.500 --> 02:16:43.020]   - We're ricotta waffles, that's for sure.
[02:16:43.020 --> 02:16:45.060]   Hey, thank you everybody for putting up with us
[02:16:45.060 --> 02:16:47.460]   for the last couple of hours.
[02:16:47.460 --> 02:16:49.260]   Ant-Pruit, hands-on photography.
[02:16:49.260 --> 02:16:50.660]   Who's on the hop this week?
[02:16:50.660 --> 02:16:55.100]   - Actually, this week is a guestless week.
[02:16:55.100 --> 02:16:57.860]   I'm gonna talk about some alternatives
[02:16:57.860 --> 02:17:00.540]   to the world of Photoshop because, yeah,
[02:17:00.540 --> 02:17:02.580]   there are some options beyond Photoshop
[02:17:02.580 --> 02:17:05.300]   to do photo manipulation and post-processing.
[02:17:05.300 --> 02:17:06.340]   - We were talking about that.
[02:17:06.340 --> 02:17:09.740]   Yes, I'm excited to hear all about that.
[02:17:09.740 --> 02:17:10.740]   - It's gonna be fun.
[02:17:10.740 --> 02:17:13.180]   - We have our different choices.
[02:17:13.180 --> 02:17:15.500]   Thank you, Ant.
[02:17:15.500 --> 02:17:17.780]   It's always fun to have you on.
[02:17:17.780 --> 02:17:21.260]   Mr. Jeff Jarvis, now we've got another thing to say.
[02:17:21.260 --> 02:17:25.540]   - Our very own nickel millionaire.
[02:17:25.540 --> 02:17:28.140]   Jeff Jarvis, he's also the Leonard Tao,
[02:17:28.140 --> 02:17:29.500]   I'm sorry, the director of,
[02:17:29.500 --> 02:17:30.540]   let's give him the full title,
[02:17:30.540 --> 02:17:32.500]   the director of the Town Knight Center
[02:17:32.500 --> 02:17:35.420]   for Entrepreneurial Journalism at the...
[02:17:35.420 --> 02:17:36.260]   - Granny.
[02:17:36.260 --> 02:17:37.100]   - Granny.
[02:17:37.100 --> 02:17:38.180]   - New mark.
[02:17:39.260 --> 02:17:41.140]   - Graduate School of Journalism
[02:17:41.140 --> 02:17:45.540]   at the City University of New York.
[02:17:45.540 --> 02:17:47.100]   Thank you, Jeff, great to have you.
[02:17:47.100 --> 02:17:47.940]   Buzz machine.
[02:17:47.940 --> 02:17:48.780]   - Thank you.
[02:17:48.780 --> 02:17:49.620]   - Buzz machine.
[02:17:49.620 --> 02:17:51.020]   - And of course, Stacey Higginbotham.
[02:17:51.020 --> 02:17:53.700]   Stacey on IOT.com's our website.
[02:17:53.700 --> 02:17:57.020]   Subscribe to the newsletter, check out the events.
[02:17:57.020 --> 02:17:59.460]   Listen to the podcast with Kevin Tofel
[02:17:59.460 --> 02:18:01.460]   @Gigastacey on the Twitter.
[02:18:01.460 --> 02:18:03.100]   Thank you all.
[02:18:03.100 --> 02:18:04.460]   Have a great week.
[02:18:04.460 --> 02:18:07.580]   We do Twig every Wednesday,
[02:18:07.580 --> 02:18:11.540]   about 2 p.m. Pacific, 5 p.m. Eastern, 2,100 UTC.
[02:18:11.540 --> 02:18:14.780]   You can watch a stream at live at twit.tv/live.
[02:18:14.780 --> 02:18:16.340]   There's audio or video there.
[02:18:16.340 --> 02:18:18.700]   People who watch live often like to chat live
[02:18:18.700 --> 02:18:23.140]   in our IRC chat room, open to all@irc.twit.tv.
[02:18:23.140 --> 02:18:25.820]   Club Twit members also have their chat room
[02:18:25.820 --> 02:18:30.820]   in our Discord server for more information on that club twit.com/club twit.
[02:18:30.820 --> 02:18:36.180]   On demand versions of the show available at twit.tv/twig.
[02:18:36.180 --> 02:18:38.620]   There's a This Week in Google Amazon channel.
[02:18:38.620 --> 02:18:39.460]   Of course, the best thing to do,
[02:18:39.460 --> 02:18:40.660]   be subscribing here.
[02:18:40.660 --> 02:18:42.020]   - Amazon? - As I say, Amazon,
[02:18:42.020 --> 02:18:43.660]   we don't have an Amazon channel.
[02:18:43.660 --> 02:18:46.300]   Although, that's not a bad idea.
[02:18:46.300 --> 02:18:48.460]   There is a twit.tv.
[02:18:48.460 --> 02:18:53.460]   There is a, I think I'm in a kind of a waffle coma right about it.
[02:18:53.460 --> 02:18:56.060]   (laughing)
[02:18:56.060 --> 02:18:57.260]   There's a YouTube channel.
[02:18:57.260 --> 02:18:59.220]   - I don't think you're ready for waffles.
[02:18:59.220 --> 02:19:00.700]   - I know, I'm maybe not.
[02:19:00.700 --> 02:19:01.780]   - That's a good cake.
[02:19:01.780 --> 02:19:04.540]   - Should I work my way up with start with silver dollar pancakes,
[02:19:04.540 --> 02:19:07.020]   Swedish pancakes, and slowly incrementing
[02:19:07.020 --> 02:19:09.300]   crease the amount of sugar intake?
[02:19:09.300 --> 02:19:10.900]   - The sugar is getting in.
[02:19:10.900 --> 02:19:11.740]   - Ah.
[02:19:11.740 --> 02:19:13.020]   (laughing)
[02:19:13.020 --> 02:19:16.860]   - Oh yeah, just next time, you know, half a waffle.
[02:19:16.860 --> 02:19:19.100]   (laughing)
[02:19:19.100 --> 02:19:22.780]   There is a YouTube channel dedicated this week in Google.
[02:19:22.780 --> 02:19:24.700]   And of course, if you have a podcast client,
[02:19:24.700 --> 02:19:25.540]   you could search for us.
[02:19:25.540 --> 02:19:27.060]   In fact, that's probably the easiest way
[02:19:27.060 --> 02:19:29.420]   to make sure you get it every week.
[02:19:29.420 --> 02:19:32.580]   And if there is a place where you can leave reviews
[02:19:32.580 --> 02:19:34.520]   on that podcast client, please give us
[02:19:34.520 --> 02:19:35.360]   a five star review.
[02:19:35.360 --> 02:19:39.300]   Tell the world of your love for waffle mania.
[02:19:39.300 --> 02:19:41.340]   Thanks everybody, we'll see you next week
[02:19:41.340 --> 02:19:42.660]   on This Week in Google.
[02:19:42.660 --> 02:19:43.500]   Bye bye.
[02:19:43.500 --> 02:19:47.200]   - You know what's fun, Android.
[02:19:47.200 --> 02:19:48.720]   You know what's even more fun though?
[02:19:48.720 --> 02:19:51.080]   All about Android, that's my show, Jason Howell,
[02:19:51.080 --> 02:19:53.960]   along with my co-host Ron Richards, Florence Ion.
[02:19:53.960 --> 02:19:56.280]   And we welcome guests on each and every week
[02:19:56.280 --> 02:19:59.000]   from throughout the Android ecosystem,
[02:19:59.000 --> 02:20:01.420]   developers, Googlers, journalists,
[02:20:01.420 --> 02:20:04.720]   people who are all geeked out about the Android operating
[02:20:04.720 --> 02:20:05.560]   system.
[02:20:05.560 --> 02:20:06.460]   We tell you everything you need to know,
[02:20:06.460 --> 02:20:09.880]   twit.tv/aa every Tuesday.
[02:20:09.880 --> 02:20:10.720]   We'll see you there.
[02:20:10.720 --> 02:20:13.300]   (upbeat music)
[02:20:13.300 --> 02:20:15.880]   (upbeat music)
[02:20:15.880 --> 02:20:18.460]   (upbeat music)
[02:20:18.460 --> 02:20:20.460]   [guitar music]

