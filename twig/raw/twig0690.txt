;FFMETADATA1
title=Search For Hardcore
artist=Leo Laporte, Jeff Jarvis, Ant Pruitt, Mike Elgan
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2022-11-17
track=690
language=English
genre=Podcast
comment=FTX celebrity fallout, Musk's Twitter purge, goodbye Protocol, palette.fm
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.840]   It's time for Twig! This week in Google Mike Elgin fills in for Stacey Higginbotham and
[00:00:05.840 --> 00:00:11.440]   Pruitt's in the house. Jeff Jarvis in his house. Lots to talk about what the heck is going on with
[00:00:11.440 --> 00:00:18.560]   Twitter. There are so many stories just from today. We'll talk about a few of them. Jeff Bezos
[00:00:18.560 --> 00:00:25.280]   gives Dolly Parton a hundred million dollars. Why? And we're going to the moon. Some beautiful
[00:00:25.280 --> 00:00:29.440]   shots from Artemis. All that and a whole lot more coming up next on Twig.
[00:00:29.440 --> 00:00:37.920]   Podcasts you love from people you trust. This is Twig.
[00:00:37.920 --> 00:00:51.360]   This is Twig. Episode 690 recorded Wednesday November 16, 2022. Search for hardcore.
[00:00:52.960 --> 00:00:57.600]   This episode of this week at Google is brought to you by Rocket Money, formerly known as True
[00:00:57.600 --> 00:01:03.680]   Bill. Are you wasting money on subscriptions? Cancel your unnecessary subscriptions right now
[00:01:03.680 --> 00:01:12.720]   at rocketmoney.com/twig. Seriously, it could save you hundreds per year. And by ITProTV. If
[00:01:12.720 --> 00:01:18.800]   you're looking to break into the world of IT or if your IT team needs to level up, get the introduction
[00:01:18.800 --> 00:01:26.960]   you need with ITProTV. Check out an ITProTV business plan by visiting itpro.tv/twig today.
[00:01:26.960 --> 00:01:35.520]   And by OnLogic. OnLogic is helping innovators around the world solve their most complex technology
[00:01:35.520 --> 00:01:41.520]   challenges using OnLogic industrial computers, which are engineered for reliability, even in
[00:01:41.520 --> 00:01:47.360]   environments that would challenge or destroy traditional computer hardware. Learn more and find
[00:01:47.360 --> 00:01:53.920]   out about OnLogic's 30-day risk-free hardware trial by visiting onlogic.com/twig.
[00:01:53.920 --> 00:01:59.680]   It's time for Twig. This week in Google, the show we have with the ladies and ladies from
[00:01:59.680 --> 00:02:07.920]   Google, the Facebook, the Twitterverse, and now with crypto. That's it for it. Hands-off
[00:02:07.920 --> 00:02:16.480]   photography in studio. Good to see you. Twit.tv/com. He's also community manager at our club
[00:02:16.480 --> 00:02:21.760]   Twit. And I saw three new events. I'm excited we'll talk about those a little later on. Also joining
[00:02:21.760 --> 00:02:29.760]   us, the Leonard Taap professor for journalistic innovation at the Craig Newmark. Graduate School
[00:02:29.760 --> 00:02:35.200]   of Journalism at the City University of North Mr. Jeff Jarvis, now on Mastodol. I want to tell
[00:02:35.200 --> 00:02:41.520]   you what I've done for you, boss. You notice how now that is nighttime here and I have my machine
[00:02:41.520 --> 00:02:48.800]   open and I'm getting the clear, right? Yes. So what did I do just for you? Not dark mode. I did it.
[00:02:48.800 --> 00:02:56.560]   Only for the hour or five that were on the show. This is like an old Henry novel because you know
[00:02:56.560 --> 00:03:06.560]   what I did for you? Light mode. Wow. So it's straight out of Henry, man. And I can confirm this is
[00:03:06.560 --> 00:03:11.760]   light mode on this panel here. Everybody. Everybody. I mentioned this to when it comes to Mastod and
[00:03:11.760 --> 00:03:15.760]   says, Oh my God, you're right. Oh my Lord. Oh, you're not you're not on the advanced
[00:03:15.760 --> 00:03:21.760]   view? Yeah, you can go to the advanced view. I thought for for Twitter users that the
[00:03:21.760 --> 00:03:29.680]   standard does be more noir-y, right? Yeah, it does. It does. I wish I could go back and forth easily.
[00:03:29.680 --> 00:03:36.320]   Yeah. Yeah. Unfortunately, it remembers it. It's a it's account specific, not browser-specific.
[00:03:36.320 --> 00:03:43.280]   So it remembers exactly exactly. And Kevin Tofel instructed me to off what he wrote about this
[00:03:43.280 --> 00:03:51.280]   to install the PWA, which I did, but it was really laggy. So I on iOS, I like
[00:03:51.280 --> 00:03:57.040]   meta text. I mentioned this before. I don't know if there's a great Android one. Tuskegee's
[00:03:57.040 --> 00:04:01.120]   another best for Mastodont. Tuskegee's what I've been hearing about. I've not tried it yet,
[00:04:01.120 --> 00:04:04.800]   but that's the one I've been hearing about. Yeah. Yeah. For mobile, it's very good. Hey,
[00:04:04.800 --> 00:04:09.840]   let's not be able to hit. Yep. You did. You know, we started. We didn't say hello to Mike
[00:04:09.840 --> 00:04:14.080]   Algin, who's also with us. I love somebody else. Daisy has the week off again. Again,
[00:04:14.080 --> 00:04:18.880]   I think I started to take it personally. But hey, good news from Mexico City, ladies and gentlemen,
[00:04:18.880 --> 00:04:27.760]   Mike Algin, who has been on Mastodont for some time? Yes. Yes. Yes. And yeah, I've been on for a
[00:04:27.760 --> 00:04:34.480]   long time, and I've been using it a lot for a week and a half. So, which by the way, makes you
[00:04:34.480 --> 00:04:40.080]   an old time. Right. That's right. Exactly. That's right. My question, by the way, I think is
[00:04:40.080 --> 00:04:47.040]   Android only. Yeah. That's the Android solution. Metatxt for iOS. But you can use a PWA. But, you
[00:04:47.040 --> 00:04:51.040]   know, I think the apps are a little bit better. I just used to browse her on my mobile device,
[00:04:51.040 --> 00:04:55.680]   and it's been totally fine. So, you could save that to your home screen as a PWA.
[00:04:55.680 --> 00:04:57.440]   I could. Yeah. But yeah, it's fine.
[00:04:58.800 --> 00:05:06.000]   Like, I got a question for you first. Yeah. Would you ever lunch today? I had a, let me see,
[00:05:06.000 --> 00:05:14.320]   it was a tostada. No, it was a taco with avocado, wahackin' cheese, and spicy jalapeno peppers.
[00:05:14.320 --> 00:05:19.680]   Pretty damn. He's like the worst person to follow on Instagram and on
[00:05:19.680 --> 00:05:27.360]   just he's like the worst to follow. We all want to be biked. Do not recommend.
[00:05:28.400 --> 00:05:32.000]   Yeah. And then as soon as we're done here, I'm going to go to this really cool place.
[00:05:32.000 --> 00:05:37.360]   It's just opened and it's like amazing. Oh, yeah. It's a Mexico City is a quite
[00:05:37.360 --> 00:05:42.480]   amazing food city for people who don't know. Mike lives in a Chipotle. Yes.
[00:05:42.480 --> 00:05:48.640]   He vacations a Taco Bell. Actually, you shouldn't follow Mike. You all get
[00:05:48.640 --> 00:05:53.920]   you have two pictures on Instagram. Follow, follow Gastronomat. Gastronomat. That's the one.
[00:05:53.920 --> 00:05:59.600]   I'm not really on Instagram, but Gastronomat is there and the Gastronomat experience is the one.
[00:05:59.600 --> 00:06:05.520]   And that's where my audience on there too. So she's cheap with a lot of stuff there too.
[00:06:05.520 --> 00:06:12.480]   Yeah, but it's just ridiculous. So you see that picture of the opera house with the orange dome?
[00:06:12.480 --> 00:06:16.640]   Yeah. I was taken right out this window. Oh, man, that's beautiful.
[00:06:16.640 --> 00:06:21.440]   Wow. We have the greatest view here. That's unbelievable. That's hard living there,
[00:06:21.440 --> 00:06:27.680]   Mr. Elgin Hard, Hard-Leh-Goodle. I'm telling you, best Chipotle in the whole world. It's great.
[00:06:27.680 --> 00:06:32.720]   I didn't even know what Chipotle is here. No, they would just laugh at you.
[00:06:32.720 --> 00:06:36.160]   Say Chipotle, we have this. Oh my God.
[00:06:36.160 --> 00:06:41.200]   Oh, actually, this is Italy, I think. Where is this? Me, Morocco?
[00:06:41.200 --> 00:06:46.560]   That is Silicon Valley. That's a big name. Oh, you're kidding me. No, no, no. In Los
[00:06:46.560 --> 00:06:51.760]   Carlos. He eats this well all the time, kids. This is ridiculous. We had the most wonderful.
[00:06:51.760 --> 00:06:55.440]   This is actually from Oaxaca. That's right. There you are. There you are.
[00:06:55.440 --> 00:07:03.760]   We had the most wonderful visit. It's been a year. It was a day of the day last year.
[00:07:03.760 --> 00:07:08.880]   Yeah. So much fun. Anyway, that's not what we're here to talk about. We're here to talk about
[00:07:08.880 --> 00:07:15.120]   Twitter. And actually, before we get to Twitter, I think it might be interesting to talk about
[00:07:15.120 --> 00:07:19.680]   the collapse of crypto. There's so many angles on this.
[00:07:19.680 --> 00:07:26.560]   But, sir, you were so far the crypto world. I mean, you just said nothing but glowing things.
[00:07:26.560 --> 00:07:28.240]   Oh, he's winking at me. Thank God.
[00:07:28.240 --> 00:07:33.840]   Because I don't want to be named in this lawsuit.
[00:07:33.840 --> 00:07:41.040]   FTX, which is the crypto exchange that has become insolvent, Samuel Bankman Freed's
[00:07:41.920 --> 00:07:47.600]   crypto exchange. Perhaps a little weird, but you might have seen ads for it.
[00:07:47.600 --> 00:07:54.480]   Larry David on the Super Bowl saying the wheel, no, no, you can't eat a bagel. You can't eat the
[00:07:54.480 --> 00:07:58.880]   wheel. And then he's talking about how he eats forks and toilets. And finally, they asked about
[00:07:58.880 --> 00:08:06.640]   cryptos. No, no. And then the tagline is don't be Larry. Invest in crypto.
[00:08:06.640 --> 00:08:12.720]   Strangers, Super Bowl commercial, ever. Much like Matt Damon for crypto.com saying courage
[00:08:12.720 --> 00:08:19.680]   favors the bold, which it doesn't as it turns out. Because if you'd bought Bitcoin after seeing
[00:08:19.680 --> 00:08:28.480]   that ad with Matt Damon at $60,000, you would be very scared now to see Bitcoin down to $16,000.
[00:08:28.480 --> 00:08:35.760]   So there is a class action suit against not only Larry David, but remember, Tom Brady and his wife,
[00:08:35.760 --> 00:08:39.920]   Ex-wife, Giselle Bunchen, did an ad also on football games.
[00:08:39.920 --> 00:08:44.080]   Does it, Larry David have a defense? Yeah, Larry said he didn't like it. So that'll be interesting.
[00:08:44.080 --> 00:08:49.680]   Yeah, he'll be fascinating. Other celebs, all of whom, whoops, endorsed
[00:08:49.680 --> 00:08:57.680]   crypto. I mean, FTX Shaquille on Neil. They've been named in a class action lawsuit accusing FTX
[00:08:57.680 --> 00:09:03.120]   and its quote brand ambassadors of deceptively encouraging customers to invest in the company.
[00:09:03.120 --> 00:09:09.440]   When Bitcoin and other cryptocurrencies crashed, a lot of the exchanges started to suffer.
[00:09:09.440 --> 00:09:15.840]   First, kind of the outliers, Robinhood, FTX jumped in and gave Robinhood the money to keep going.
[00:09:15.840 --> 00:09:19.840]   Then BlockFi FTX jumped in and gave them the money. But then all of a sudden,
[00:09:19.840 --> 00:09:25.280]   probably I'm thinking there's a little shenanigans going on with their competitor,
[00:09:26.480 --> 00:09:36.080]   which is Binance. Binance, I think maybe stuck the knife in and implied I think that maybe FTX
[00:09:36.080 --> 00:09:40.720]   wasn't solvent. Binance said they were going to come and buy the recipe. And then they said,
[00:09:40.720 --> 00:09:45.200]   "Well, we looked at the books and we don't want to hear that on us." He turned that knife.
[00:09:45.200 --> 00:09:52.080]   So there was a run on FTX for $6 billion. FTX said, "Well, we don't have reserves
[00:09:52.800 --> 00:09:57.120]   to cover that. A normal bank has to have with I think 2% or something like that,
[00:09:57.120 --> 00:10:02.720]   reserves in case of a run in the bank. There's no regulation of FTX there in the Bahamas anyway."
[00:10:02.720 --> 00:10:09.520]   They basically declared chapter 11 bankruptcy. There were some shenanigans because it turns out
[00:10:09.520 --> 00:10:14.720]   at the same time as he was running FTX, he also owned and his girlfriend, his 28-year-old girlfriend,
[00:10:14.720 --> 00:10:21.760]   was running Alameda Research, which was a crypto trading firm. And FTX was giving crypto
[00:10:21.760 --> 00:10:28.080]   its own crypto token, FT2 Alameda Research, which they had promised they wouldn't do. They were in
[00:10:28.080 --> 00:10:35.120]   effect taking your deposits and putting him in Alameda Research for Alameda Research to trade,
[00:10:35.120 --> 00:10:40.880]   and they were doing very risky trades. And the problem is that was with your money, not with Sam's.
[00:10:40.880 --> 00:10:48.480]   Anyway, he's got $0. Unclear what's going to happen to him. New York Times acted as if it wasn't his
[00:10:48.480 --> 00:10:54.400]   fault. They had a whole profile of SPF just a couple of days ago. He's still doing PR.
[00:10:54.400 --> 00:10:56.880]   He's an I put an interview with him up just a few minutes before the show.
[00:10:56.880 --> 00:11:03.920]   Two interviews? But what will be interesting, Michael Lewis was in the process of writing a book.
[00:11:03.920 --> 00:11:07.760]   Had gone to the Bahamas many times interviewed him, he's going to have the best ending to any book.
[00:11:07.760 --> 00:11:14.800]   So opposed to Walt Rieseckson, who was writing the Musk book, it's going to have never, it's never
[00:11:14.800 --> 00:11:19.120]   going to end. Yeah, that's an ongoing, you just have a blog.
[00:11:19.120 --> 00:11:26.640]   But can we talk about the lawsuit because this is the Thomas Lost that I've ever heard. What is
[00:11:26.640 --> 00:11:31.120]   Tom Brady supposed to do? Like launch an investigation before he does a commercial?
[00:11:31.120 --> 00:11:36.880]   Well, I don't endorse anything that I don't believe in, but let's look at the four.
[00:11:36.880 --> 00:11:40.880]   That's really rare. But if they're going to take money away from the people who are
[00:11:40.880 --> 00:11:45.120]   promoting these things, they should take that money and give it to you and me Leo, because we've
[00:11:45.120 --> 00:11:50.320]   been telling people that's crypto generally. So we should get the money. You know what I mean?
[00:11:50.320 --> 00:11:56.240]   It's like, I'll take my, I'll take my check from from that lawsuit, but it's a frivolous lawsuit.
[00:11:56.240 --> 00:12:00.560]   Golden State Warriors are named because they had a they had FTX on the company's logo. You might
[00:12:00.560 --> 00:12:06.880]   have seen in the World Series, the umpires had FTX on their uniforms. Again, very smart ad buy,
[00:12:06.880 --> 00:12:13.760]   not the players, the umpires. I mean, when you making financial decisions, are you off the hook
[00:12:13.760 --> 00:12:19.680]   because an umpire had a sticker on his uniform? I mean, the defendant's name of the suit,
[00:12:19.680 --> 00:12:24.720]   according to the suit, either controlled, promoted, assisted in, or actively participated in FTX's
[00:12:24.720 --> 00:12:31.520]   business. Now, there is some precedent. Jeff Jarvis has been doing. Yes, there is. There's a few here
[00:12:31.520 --> 00:12:39.200]   and fun video to go along with it. Oh, so Pat Boone in 1981 endorsed an acne cream,
[00:12:39.200 --> 00:12:45.280]   saying it was going to get rid of your zits. It didn't work so well as no acne cream does.
[00:12:45.280 --> 00:12:55.440]   And so he was brought up by the FTC in the matter and eventually had to apologize and paid some
[00:12:55.440 --> 00:13:00.800]   reparations. Oh, right. You want to pay a little bit of Pat Boone there just to give people these
[00:13:00.800 --> 00:13:03.760]   kids here a sense of who Pat Boone was? Tell me again, what?
[00:13:03.760 --> 00:13:07.440]   Oh, I'm looking at the wrong show. That would be why I can't find it.
[00:13:07.440 --> 00:13:14.640]   Thank you. His life is so confusing. What's the name of the hell there about line 90?
[00:13:14.640 --> 00:13:19.120]   line 90. Okay. We're going to get to an even better case. I thought it was weird that all the
[00:13:19.120 --> 00:13:26.800]   stories are about Apple. So, okay. Pat Boone, which one do you want to play? The 90 is the
[00:13:26.800 --> 00:13:30.960]   apology? No, that's no, that's the story. Here's here's a
[00:13:30.960 --> 00:13:34.640]   for the kids. Those of you who could get a sense of this is
[00:13:34.640 --> 00:13:42.000]   he was a trust Pat Boone. He was looking at the clean the clean gene of singers.
[00:13:42.000 --> 00:13:46.560]   Oh, boy. He took African American music, black music, and
[00:13:46.560 --> 00:13:52.880]   wandered it, whitewashed it so that the the kids of America would not be
[00:13:52.880 --> 00:13:57.920]   Elvis did, right? Yeah, Elvis did. That's a perfect way of putting it. In fact,
[00:13:57.920 --> 00:14:02.400]   he sang some well, no, that's Elvis left it more black than he did. He made it completely
[00:14:02.400 --> 00:14:06.560]   wonderbrut. Did you ever you ever seen his version of 2D fruity?
[00:14:06.560 --> 00:14:11.760]   But later later in his career, he went like heavy metal. Say it ain't so, please. Yeah,
[00:14:11.760 --> 00:14:15.280]   he did. He did. He did a healthy metal album, didn't he? But he still said,
[00:14:16.240 --> 00:14:22.640]   I remember an SC TV fake Pat Boone commercial where they said he makes you want to just stand
[00:14:22.640 --> 00:14:29.360]   up and stretch. There you go. A little, I'm sure we're going to take it, get taken down for this,
[00:14:29.360 --> 00:14:40.560]   but Pat Boone doing the classic little Richard. No, 2D fruity. Oh, no. I wonder if he goes,
[00:14:42.240 --> 00:14:47.520]   this is legit. This is really. It was a bigger. All right, you really want something terrible?
[00:14:47.520 --> 00:14:52.640]   It was a bigger hit. Oh my God. Richard's version. Oh my God. A little Richard received his freaky
[00:14:52.640 --> 00:14:59.280]   because he was black man. Yeah, black man dancing like crazy. Yeah. Is his Apollo? So Pat Boone
[00:14:59.280 --> 00:15:06.400]   advertised that this acting medication had helped his four daughters and turned them blemish free.
[00:15:07.280 --> 00:15:12.960]   And then he admitted that that that this was wrong. He was chasing by the FTC and accepted personal
[00:15:12.960 --> 00:15:18.880]   responsibility and paid rep restitution. But of course not the best way before I get a little
[00:15:18.880 --> 00:15:25.040]   side note before, but wait because of the screen because on the screen savers, one of our hosts
[00:15:25.040 --> 00:15:31.440]   was Pat Boone's granddaughter. Really? Did you get it? She did she had beautiful skin. She was a redhead.
[00:15:32.960 --> 00:15:40.480]   Can't remember her name. I'm trying to remember her name. But yeah, she and she, Grandpa Pat
[00:15:40.480 --> 00:15:50.000]   talks about them all the time. Anyway, so, okay, so they held him libel, which is the FTC.
[00:15:50.000 --> 00:15:54.720]   That's what's what's what's I was looking for the show because I do things like looking
[00:15:54.720 --> 00:15:59.280]   Twitter and Google and stuff for the good of the show. Sure. Sure. Sure. And I find I fear
[00:15:59.280 --> 00:16:06.800]   because I won't. I won't do it. So Lloyd Bridges was also in trouble. And Jeff
[00:16:06.800 --> 00:16:16.000]   Bridget is playing who he is in a minute. He in this is 1990. Yeah, he had advertised
[00:16:16.000 --> 00:16:21.040]   four companies that went bankrupt having built investors out of millions of dollars. That's bad.
[00:16:22.080 --> 00:16:29.520]   The Diamond Mortgage Company not only did bridges do this, but also who was it here? Art
[00:16:29.520 --> 00:16:34.880]   letter said that he would now be careful about doing endorsements. This is back in 1990.
[00:16:34.880 --> 00:16:40.400]   Nothing. 1990. So we might want to want to ask who's Lloyd Bridges? Well, I put up video for that
[00:16:40.400 --> 00:16:45.040]   too. That's all right. We don't show that far down. Come on. I'm already googled it. I'm
[00:16:45.040 --> 00:16:50.720]   already googled it on my lap. It's a good life. You want to show the sound video from his
[00:16:51.600 --> 00:17:01.200]   classic show. You could play the sea hunt. See hunt. He was a Navy seal turned commercial diver.
[00:17:01.200 --> 00:17:07.200]   And the thing I loved about Lloyd Bridges on sea hunt is he was such a man because he always
[00:17:07.200 --> 00:17:14.080]   dived off the boat backwards, which I've which I've learned by the way, because I did it the first
[00:17:14.080 --> 00:17:21.280]   time I scuba dive and say, what are you doing? Stop it. That's dangerous. So I'm sea hunting.
[00:17:21.280 --> 00:17:27.440]   So I saw Lloyd Bridges do it. I thought that was okay. Anyway, his sons became well known Hollywood
[00:17:27.440 --> 00:17:32.960]   actors, Bob Bridges and Jeff Bridges. Yeah, I recognize them now at Google do I never knew their names,
[00:17:32.960 --> 00:17:38.480]   but I recognize the faces. So George Hamilton also made commercials for Diamond Mortgage
[00:17:38.480 --> 00:17:42.080]   and was sued by investors and reached an out of court settlement. And you know what George
[00:17:42.080 --> 00:17:45.840]   Hamilton's famous for? Young men? What's that tanning his tan?
[00:17:48.240 --> 00:17:52.960]   He was the most tander than you. I love how Mr. Benito cuts to me.
[00:17:52.960 --> 00:18:05.760]   I think he literally was darker than Anne. Wow. Look at that. All right. Now we got. Okay. Now we
[00:18:05.760 --> 00:18:11.520]   got looked at that up. There he is. Oh, I remember him. Yeah. Yeah. I remember. He was a Zorro in that
[00:18:11.520 --> 00:18:19.360]   funny Zorro parody. Oh, man. And then he did love it for spite. He was a vampire. Yeah. So he
[00:18:19.360 --> 00:18:24.640]   he would make fun of himself. Wow. So to answer your question, Mike, yes, there's liability
[00:18:24.640 --> 00:18:29.120]   because you are endorsing something. And if you don't take duty of care here,
[00:18:29.120 --> 00:18:35.760]   you could be up as is Greek. But I don't understand this because I'm thinking about
[00:18:35.760 --> 00:18:42.240]   though Ford Pinto and whomever decided to to endorse that back in the days. Nobody
[00:18:42.240 --> 00:18:48.400]   knows. I was going to blow up back then. But I'm sure Ford had some sort of a spokesperson to try
[00:18:48.400 --> 00:18:54.880]   to help promote it and market it. But how are they going to know this is a bad car? What's
[00:18:54.880 --> 00:18:58.960]   going on? What about what I think? I think in this case, it's a question of whether or not
[00:18:58.960 --> 00:19:04.320]   you're making an endorsement. If you said specifically, this car will never explode.
[00:19:05.200 --> 00:19:08.240]   The FPC is going to say, well, how did you know that? I don't know what basis did you
[00:19:08.240 --> 00:19:11.440]   promise that to people and you shouldn't have because you shouldn't know better. Now,
[00:19:11.440 --> 00:19:15.680]   all you said was, I think it's a cute little car. But isn't that what most of those
[00:19:15.680 --> 00:19:20.640]   commercials were saying? Well, let me show you a little bit. I want to get a little
[00:19:20.640 --> 00:19:24.960]   thing. Yeah. Let me set his daughter's that clear skin that you look like Peppero
[00:19:24.960 --> 00:19:30.160]   Capitas. This is Tom Brady, Giselle Bunchinette. I'm just going to play a little bit of the
[00:19:30.160 --> 00:19:33.840]   beginning. Okay. And you tell me if this is an endorsement of FTX.
[00:19:34.640 --> 00:19:36.400]   So they're not showing. They're just.
[00:19:36.400 --> 00:19:40.880]   I'm in. Let's call everyone. Hang on a minute.
[00:19:40.880 --> 00:19:43.840]   So he's telling all of his friends.
[00:19:43.840 --> 00:19:49.520]   Okay. I'm in. Whatever. Wow. That was my own.
[00:19:49.520 --> 00:19:51.600]   They're all getting in on.
[00:19:51.600 --> 00:19:55.520]   Chris Tom Brady says. He's not making an agreement.
[00:19:55.520 --> 00:19:59.600]   Well, you think it was kind of clever how they didn't say what you're in on.
[00:19:59.600 --> 00:20:03.200]   Yeah, they just said you're in. I mean, and they're not making any claims. They're
[00:20:03.200 --> 00:20:07.760]   not saying that it's going to work or anything. You just say, sounds good. I'm going to do it.
[00:20:07.760 --> 00:20:14.880]   Wow. That's interesting. It's which to me sounds like Tom Brady or more likely his people said,
[00:20:14.880 --> 00:20:18.560]   Tom, whatever you do, don't say you're going to make money. Right. Right.
[00:20:18.560 --> 00:20:24.640]   But we actually when we do ads for financial services, actually, there is a long list and
[00:20:24.640 --> 00:20:28.960]   it doesn't come from us. It comes from the companies of things you cannot say, including,
[00:20:29.680 --> 00:20:36.000]   I'm doing this. I tell you, I'm encouraging you to do it. All of that is is verbote and by the
[00:20:36.000 --> 00:20:41.760]   FTC and these companies tell us, look, we want you to do an ad. Right. Implicitly saying,
[00:20:41.760 --> 00:20:48.240]   this company is a good company. Actually, it's frustrating to me because I'm not allowed to
[00:20:48.240 --> 00:20:54.880]   have an account with those companies as the the ad guy. And even though my kids do have an account
[00:20:54.880 --> 00:21:00.640]   with these companies, I can't say that they do. All right. So did you just do that?
[00:21:00.640 --> 00:21:07.360]   I didn't say what company. No, no comments. Okay. Yeah. It's not a current. In this case,
[00:21:07.360 --> 00:21:13.920]   it's not a current advertiser. Well, I'm in. So, right. I've been, but there are very clear rules,
[00:21:13.920 --> 00:21:19.200]   especially with financial services, and I would guess, I mean, based on just watching that.
[00:21:19.200 --> 00:21:23.600]   So this is the interesting. I came away with the memory of that ad of him saying,
[00:21:23.600 --> 00:21:30.000]   yeah, I'm going to buy some crypto at FTX. Very cleverly done that he never said that.
[00:21:30.000 --> 00:21:33.600]   So does this hold any water in court? We'll see in court. I don't know.
[00:21:33.600 --> 00:21:40.640]   And remember, it's a class action, not an FTC action. Okay. So the FTC has to start to go to
[00:21:40.640 --> 00:21:44.400]   court, right? They can't just. Oh, no, no, the FTC can follow. No, no, no. They can
[00:21:44.400 --> 00:21:49.760]   find it without hello, hello, Elon Musk. Okay. The FTC can find you the FTC. This was,
[00:21:50.240 --> 00:21:55.040]   it's actually a model, I think, for internet regulation. Well, the FTC says is we don't care how you make
[00:21:55.040 --> 00:22:00.480]   your sparkly water. If you, if you promise this sparkly water is going to clear up your acne,
[00:22:00.480 --> 00:22:07.600]   then, and it doesn't, then what we get you for is the false promise, not because we told you how
[00:22:07.600 --> 00:22:13.440]   to make sparkling water. So here's a question for you, just to get really freaky and Google,
[00:22:13.440 --> 00:22:22.240]   you know, googly about it. Let's say, let's say, you know, somebody, some celebrity
[00:22:22.240 --> 00:22:27.040]   loans their image to a synthetic media company that uses deep fake technology.
[00:22:27.040 --> 00:22:33.280]   And they're not involved in saying the thing, but it's their, the fact that the public
[00:22:33.280 --> 00:22:38.480]   loves them and trust them that causes everybody to go and buy this product. And it turns out to be
[00:22:38.480 --> 00:22:45.200]   a fraudulent or whatever, are they, are they liable in that case? And if they, if they aren't,
[00:22:45.200 --> 00:22:49.280]   then what's the difference? I mean, they're just reading a script that was given to them,
[00:22:49.280 --> 00:22:54.880]   in the one hand, by the company, and they're just letting the company type the script into the
[00:22:54.880 --> 00:22:58.800]   synthetic media generator on the other. What's the difference? Yikes.
[00:22:58.800 --> 00:23:07.280]   Wow. I didn't think about that. Bruce Willis very famously did an ad, a deep fake ad,
[00:23:08.080 --> 00:23:14.160]   for a, was a Russian telecom company, which he probably has rights at this point.
[00:23:14.160 --> 00:23:20.480]   But he since has started to loan his likeness for other things, movies and so on, because he's got a,
[00:23:20.480 --> 00:23:28.560]   he's got a, he physically can. But this is, this is really, this is really the future. There's one,
[00:23:28.560 --> 00:23:35.680]   one person who's predicted that within like a few years, the vast majority, more than 90% of
[00:23:35.680 --> 00:23:39.040]   the media posted online would be synthetic media of one kind or another.
[00:23:39.040 --> 00:23:41.600]   Well, so we've been doing that on Twitch for years.
[00:23:41.600 --> 00:23:45.120]   Oh, I forgot that I didn't tell anybody. No comment.
[00:23:45.120 --> 00:23:48.080]   Sorry. You retired five years ago. I have a figure of that.
[00:23:48.080 --> 00:23:50.560]   I have a figure of real, incredible simulation.
[00:23:50.560 --> 00:23:59.280]   All right. So there you have it. That's the, that's the FTX story. I really think this is an
[00:23:59.280 --> 00:24:07.680]   interesting story. And I, it doesn't, so crypto.com is still around. There's another company that's
[00:24:07.680 --> 00:24:12.000]   been doing that still around. Coinbase, finance is still around.
[00:24:12.000 --> 00:24:19.840]   I wonder though, how long they can continue. There's, there's no evidence that they've been
[00:24:19.840 --> 00:24:24.160]   fraudulent in any way, but I wonder how long they can continue. Are these, is going to turn
[00:24:24.160 --> 00:24:29.920]   people against crypto? Maybe probably not. I don't think so. They just maybe be more
[00:24:29.920 --> 00:24:33.520]   careful about where they put the money. I think, yeah, you just don't put it in these kind of places.
[00:24:33.520 --> 00:24:40.400]   Yeah. I think there's still the, the, the normals out there in the world that are still holding on
[00:24:40.400 --> 00:24:46.960]   to the, the hopes of, of crypto being big and, and a get rich, quick kind of thing for them,
[00:24:46.960 --> 00:24:53.520]   regardless if they understand the technology behind blockchain or any of that. But I, I'm pretty
[00:24:53.520 --> 00:24:58.880]   sure people are still just sort of squirling away for stuff like Sheba. Is it Sheba token? Is that
[00:24:58.880 --> 00:25:04.000]   the one? Sheba Enu. Sheba Enu. It's a mean token. Yeah. I'm sure people are still just,
[00:25:04.000 --> 00:25:07.840]   just squirling away. Why not? Ten dollars there. Because they're like, well, who knows? I might get
[00:25:07.840 --> 00:25:13.600]   lucky five years from now in the same way those people that got into Bitcoin five, six years ago.
[00:25:13.600 --> 00:25:18.160]   I wish to hell have found that password because that wall at was worth at one point, almost half
[00:25:18.160 --> 00:25:24.480]   a million dollars. Now it's yeah. A lot less. It's a lot less, but I'm sure it's still fine. Yeah. Yeah.
[00:25:24.480 --> 00:25:29.040]   Yeah. That's what is it? Sixteen thousand? I got like six, almost eight coins? That's pretty good.
[00:25:29.040 --> 00:25:33.920]   That's not a twenty eight buck thousand bucks. That's not bad. Yeah. I could buy me to the oven race
[00:25:33.920 --> 00:25:41.120]   next year. Oh, yeah. Or, or to Taylor Swift con concert. Did you see this? You got a ticket?
[00:25:41.120 --> 00:25:46.960]   Well, that, so that was the first story was the ticket master had completely screwed her.
[00:25:47.520 --> 00:25:52.880]   Or maybe they didn't expect so many. Oh, no. It's their ticket master.
[00:25:52.880 --> 00:26:02.240]   But it melted down. And people trying to buy Taylor Swift tickets. Fans were outraged yesterday.
[00:26:02.240 --> 00:26:08.080]   Broke these lawmakers said we should break up live nation and ticket master. That's their
[00:26:08.080 --> 00:26:13.760]   subsidiary because they basically own all the ticketing and when that's been the case for how
[00:26:13.760 --> 00:26:22.160]   many decades now. Yep. Shouldn't have ever gone together. But then I saw. If you wanted to see
[00:26:22.160 --> 00:26:28.960]   Taylor Swift in in LA, I think it was I saw tickets as much as ninety five thousand dollars
[00:26:28.960 --> 00:26:36.960]   on the resale market. That's some spoiled kids. You got to see that show. I don't know. Yeah.
[00:26:36.960 --> 00:26:42.640]   Yeah. Daddy. What do you want for your birthday daughter? I just want, I just want tickets to
[00:26:42.640 --> 00:26:48.640]   see Tannish Swift or I won't love you. I won't love you. This is on stub hub.
[00:26:48.640 --> 00:26:56.080]   That's crazy. Floor seats for the opening night in Glendale, Arizona, 17,000 dollars. Atlanta,
[00:26:56.080 --> 00:27:06.240]   35,000 dollars. If you want to see, see her in LA, I think I saw on stub hub as much as 95.
[00:27:06.240 --> 00:27:10.400]   And those are the resale. That's right. That's right. That's somebody was lucky enough to get tickets
[00:27:10.400 --> 00:27:15.360]   before. Take it master melted down, which I guess. At those prices, I would expect her to do my
[00:27:15.360 --> 00:27:20.160]   birthday party. Yeah. But the thing is, that's a million bucks a million dollars. Their resale
[00:27:20.160 --> 00:27:24.720]   are charging that because they could probably get it. Well, they're, yeah, they must think
[00:27:24.720 --> 00:27:28.480]   they're going to get it. Who knows though, they might not prices may go down as you get closer to
[00:27:28.480 --> 00:27:34.320]   the closer. Yeah, it'd be a different story. If you want to see, if you wanted to see the Super Bowl
[00:27:34.960 --> 00:27:41.840]   last year, take its average $10,000. So it's more expensive to see Taylor.
[00:27:41.840 --> 00:27:48.960]   Did you ever take your daughter to a Taylor Swift concert? My daughter? I did. Did you? Was it fun?
[00:27:48.960 --> 00:27:54.960]   Yeah, actually it was. Yeah. It was. You surrounded as long as it's like going to VidCon.
[00:27:54.960 --> 00:27:58.640]   You're surrounded by a whole bunch of screaming little people. Yeah. It's like going to a
[00:27:58.640 --> 00:28:06.080]   Beatles concert back in the day, back in the day, screaming little people. Speaking of which,
[00:28:06.080 --> 00:28:11.040]   did you? Are you going? At least it bought tickets for everybody. I think to go see.
[00:28:11.040 --> 00:28:17.840]   I don't even want to say the name of it. The midget wrestling at the mystic.
[00:28:17.840 --> 00:28:24.560]   Why are little people? That's what that's what they call it. I didn't know nothing about this.
[00:28:24.560 --> 00:28:31.600]   Like that's that's wrong. It can't be that can't be right. Microw mania midget wrestling.
[00:28:31.600 --> 00:28:37.120]   Oh my. Yeah, no, I don't think we use the M word anymore. I know we don't know.
[00:28:37.120 --> 00:28:43.120]   Oh, my mayday. It's like the N word. It's okay. If you're one. Oh gosh. That's crazy. No.
[00:28:43.120 --> 00:28:48.800]   Well, what are they rappers? I mean, oh no. No, no, it's wrestling. Oh gosh. Using the M word.
[00:28:48.800 --> 00:28:55.520]   Oh, that's bad. So bad. I'd never I never saw this in the news. I think it's appalling that my
[00:28:55.520 --> 00:28:59.680]   wife is going I said, I am not going to that. But apparently the whole sales department's going,
[00:28:59.680 --> 00:29:08.800]   which tells you something. Oh geez. And then for my birthday, she's going to girls night out.
[00:29:08.800 --> 00:29:13.280]   This I'll tell you the mystic theater is when you changed a little bit since you lived here.
[00:29:14.160 --> 00:29:23.840]   Like it's a it's upgraded or well, it's changed. Oh, it's changed. All right, let me do an ad.
[00:29:23.840 --> 00:29:28.320]   When we come back, I have no I have I can't figure how to get this into the show.
[00:29:28.320 --> 00:29:40.080]   But did you love the New York posts page 26 coverage of the 45th well on their page one play for it.
[00:29:40.080 --> 00:29:44.560]   Yeah, on page one, it said what below the fold, it said Florida man, Florida,
[00:29:44.560 --> 00:29:51.920]   makes an announcement page 26. You know what though? You know that this is Rupert, right?
[00:29:51.920 --> 00:29:58.240]   An effort, but you know, exactly. Oh, you know, the Rupert. Yeah. Last night on Fox. Yeah.
[00:29:58.240 --> 00:30:03.280]   And it was so boring and so often even Fox cut away embarrassing. Yeah. No, well, Fox cut away,
[00:30:03.280 --> 00:30:07.680]   but they cut away to do what to have Mike Huckabee there saying it's the best speech he's ever given.
[00:30:07.680 --> 00:30:11.920]   This is brilliant. He will show you. Yes. Yes. He was looking for a cabinet post.
[00:30:11.920 --> 00:30:16.720]   Did you see the national reviews headline, which the national reviews headline was no.
[00:30:16.720 --> 00:30:30.160]   Nope. All right. That's it. There's no way I can get that into the show. So I won't but, you know,
[00:30:30.160 --> 00:30:33.680]   right. We won't even mention it. We won't. We shouldn't. We shouldn't even we shouldn't even
[00:30:33.680 --> 00:30:38.720]   bring up. This is the magic. You won't tell what page it's on. Nothing.
[00:30:38.720 --> 00:30:47.600]   I'll tell you what I should do though is tell you about our fine sponsor. How about that?
[00:30:47.600 --> 00:30:52.080]   Our show today brought to you by, I was just talking about this with the
[00:30:52.080 --> 00:31:01.280]   Poulter out rocket money. I, like many of you, have subscribed to many things over time, right?
[00:31:01.280 --> 00:31:06.320]   And I found an app a couple of years ago that I love called true bill, put it on my phone. Well,
[00:31:06.320 --> 00:31:11.680]   just the other day, true bill turned into rocket money. Turns out the rocket folks bought true bill.
[00:31:11.680 --> 00:31:18.640]   It's even better than ever. Look, I think 80% of you have subscriptions that you've just
[00:31:18.640 --> 00:31:24.160]   plumb forgotten about, right? Maybe it's an unused Amazon prime account or a Hulu account.
[00:31:24.160 --> 00:31:30.880]   And you never watch Hulu, right? This app tracks all my expenses, which by the way,
[00:31:30.880 --> 00:31:34.880]   helps me with budgeting and all sorts of things. But it also will say, Hey, here's a recurring
[00:31:34.880 --> 00:31:42.800]   expenditure. Do you know that you're paying every month, $50 for subscription to mad magazine? What?
[00:31:42.800 --> 00:31:49.440]   I, I love this and it saves me money because I clicked the button that says cancel the subscription
[00:31:49.440 --> 00:31:55.760]   and I'm done. They canceled it for you. This is rocket money. Formerly true bill. Most Americans
[00:31:55.760 --> 00:32:00.960]   think they spend about 80 bucks a month on subscriptions. They did a survey. I said,
[00:32:00.960 --> 00:32:07.040]   how much do you think you said on subscriptions? Okay, now check the actual total closer to $200 or
[00:32:07.040 --> 00:32:12.880]   more. People are wasting and you know, this is true, wasting hundreds of dollars every month in
[00:32:12.880 --> 00:32:17.040]   subscriptions. They've forgotten about they never, they don't remember, or maybe you're getting
[00:32:17.040 --> 00:32:22.720]   double billed. It'll find those two shows all your subscriptions in one place and it'll cancel
[00:32:22.720 --> 00:32:28.320]   them for you. Just press the cancel button and it does it. Rocket money is awesome.
[00:32:28.320 --> 00:32:32.240]   I found subscriptions you don't know about. You didn't even know you were paying or you've been
[00:32:32.240 --> 00:32:36.400]   double billed for it. It'll find everything. All you have to do is press cancel. Rocket money
[00:32:36.400 --> 00:32:44.240]   takes care of the rest. I found a political contribution I made in the last cycle in 20.
[00:32:44.240 --> 00:32:51.840]   What is that? 2022? 2020? Two years ago, I made a contribution and there's a little box they never
[00:32:51.840 --> 00:32:55.600]   tell you. There's a little box that says make this a recurring one and it was just pre-checked.
[00:32:55.600 --> 00:33:01.120]   I didn't, I forgot or I didn't know and they've been billing me ever since and I just wasn't paying
[00:33:01.120 --> 00:33:06.960]   attention. Rocket money found it. I cancel it. It saved me thousands of dollars. It is huge.
[00:33:06.960 --> 00:33:12.560]   I love Rocket money. I love true bill and I like Rocket money even more. They've added some
[00:33:12.560 --> 00:33:17.280]   great new features. It really is fantastic. Get rid of those useless subscriptions right now.
[00:33:17.280 --> 00:33:24.000]   Go to rocketmoney.com/twig. It seriously could save you hundreds of dollars a year. Rocket money
[00:33:24.000 --> 00:33:30.720]   .com/twig. They've got iOS and they've got Android. You should do this, Anne. It's, you probably
[00:33:30.720 --> 00:33:35.760]   already have. Cancel your own that. It's just, in fact, I bet you have the people who I'm talking
[00:33:35.760 --> 00:33:39.920]   to. I say, "Oh yeah, Leo, I know about that." Cancel your unnecessary subscriptions right now. If
[00:33:39.920 --> 00:33:46.880]   you don't, this is a huge thing. Rocketmoney.com/twig. We thank you so much for supporting this. We
[00:33:46.880 --> 00:33:51.200]   can Google and you support us. It's very important. You got to go to that address because otherwise,
[00:33:51.200 --> 00:33:55.840]   you could, I know you're smart. You just go to iOS and download it or Android and download it.
[00:33:55.840 --> 00:34:01.680]   Please don't. Just do me a favor. Go to the website rocketmoney.com/twig. Then click the
[00:34:01.680 --> 00:34:06.240]   link then download it. Just do that for us so that they know you saw it here. Rocket money.
[00:34:06.240 --> 00:34:11.920]   Major's, I should look into this. You haven't done it? I should look into this. I have
[00:34:11.920 --> 00:34:17.920]   teenagers. I know. Hey, Dan, can we order such a month? Yeah, I should probably look at that.
[00:34:17.920 --> 00:34:20.800]   I don't know where I put my phone. I think I left it in the office. I would show you. I mean,
[00:34:20.800 --> 00:34:25.120]   there's dozens of subscriptions. Sorry, John. It's all right. The ad's open now.
[00:34:25.120 --> 00:34:33.040]   I would feel so naked with my phone. I couldn't talk. It's like not wearing glasses.
[00:34:33.040 --> 00:34:38.640]   That's not good to have. Not good. You are hooked. I bet that number one app on your front page is
[00:34:38.640 --> 00:34:48.160]   Twitter, isn't it? We haven't talked to you, Mike, since this all went down. I know you were
[00:34:48.160 --> 00:34:57.920]   famous for being a Google+ fan when Google+ shut down. Infamous. Infamous is more accurate.
[00:34:57.920 --> 00:35:01.680]   You were one of the first people to do a newsletter that I know about. You always
[00:35:01.680 --> 00:35:06.720]   been on top of this and you use Twitter to publicize it. Twitter was a very effective go-to for you.
[00:35:08.160 --> 00:35:15.920]   I'm with Stephen King who pointed out that he's invested massive numbers of hours and probably
[00:35:15.920 --> 00:35:21.280]   Elon Musk owes him a million dollars or something. He only owes me about $10,000.
[00:35:21.280 --> 00:35:26.720]   Yeah, invested countless hours on Twitter. I mean, the greater fool us, right?
[00:35:26.720 --> 00:35:35.200]   Because we would say it out loud. I am giving away all this content to a company that is
[00:35:35.200 --> 00:35:41.120]   monetizing or attempting to. Right. And of course, there has been a lot of value. The thing that I
[00:35:41.120 --> 00:35:49.920]   have to say about it, though, basically is that people keep referring to it as paid verification,
[00:35:49.920 --> 00:35:55.840]   which is not what it is. What Elon Musk is going to do is he's going to end verification.
[00:35:55.840 --> 00:36:01.520]   And then he's going to add a totally unrelated feature, which is basically paid prioritization.
[00:36:01.520 --> 00:36:07.280]   The main benefit of Twitter Blue at $8 a month is that you get priority. In fact, Elon Musk has
[00:36:07.280 --> 00:36:12.320]   even said that if you don't pay, it's like everything you post will essentially go into the spam.
[00:36:12.320 --> 00:36:19.760]   Shadow mind. Exactly. So basically, it's paid prioritization that they're calling verification
[00:36:19.760 --> 00:36:24.480]   and they're using the verification symbol. But there's no relationship at all between verification
[00:36:25.280 --> 00:36:31.600]   and the Twitter Blue so-called verification. They're unrelated completely. And this is the
[00:36:31.600 --> 00:36:38.160]   problem that people don't realize there's going to be no benefit to verification. It's going to
[00:36:38.160 --> 00:36:42.880]   be part of the many things that Elon Musk is apparently going to do to destroy Twitter,
[00:36:42.880 --> 00:36:48.640]   drive people off, drive people to mass it on and elsewhere. And it's just a real shame.
[00:36:48.640 --> 00:36:54.560]   And I personally am fed up with narcissistic people ruining everything for the rest of us.
[00:36:54.560 --> 00:36:57.680]   That's the hysterical thing is everybody knows that.
[00:36:57.680 --> 00:37:05.840]   Except Elon, apparently. And immediately, as soon as he turned it on, everybody demonstrated the
[00:37:05.840 --> 00:37:12.560]   problem by impersonating really and flipping public beta tests and right there. And Eli Lilly
[00:37:12.560 --> 00:37:18.320]   cost him billions in stock value. I mean, it was a train wreck. They stopped it. Elon has now said
[00:37:18.320 --> 00:37:23.360]   he's tweeted that November 29th, it's going to be turned on. He says, but I want to do it until
[00:37:23.360 --> 00:37:26.560]   it's rock solid. I don't know what he could do that would make it rock solid.
[00:37:26.560 --> 00:37:30.320]   What does that rock solid? Eliminate the check, right? Here's the story from the Verge.
[00:37:30.320 --> 00:37:34.320]   Actually, it's Casey Newton's a platformer. I guess the Verge and the platformer are doing a deal
[00:37:34.320 --> 00:37:39.280]   because I ended up paying a hundred bucks. Jeff, you'll be glad to know for platformer because this
[00:37:39.280 --> 00:37:44.080]   is the best Twitter coverage is all coming from. Absolutely. He's knocking it out of the park.
[00:37:44.080 --> 00:37:51.840]   He's the big winner out of all this. So, he was warned. He was warned
[00:37:52.720 --> 00:37:53.840]   that this would fail.
[00:37:53.840 --> 00:37:59.680]   But days before the launch of the blue check, the company's trust and safety team.
[00:37:59.680 --> 00:38:05.840]   This is from Casey via the Verge prepared a seven page list of recommendations intended to help
[00:38:05.840 --> 00:38:11.440]   Musk avoid the most obvious and damaging consequences of his plans for blue. The document was obtained
[00:38:11.440 --> 00:38:18.560]   by the platformer predicts with eerie accuracy some of the events that follow. This is a quote
[00:38:19.840 --> 00:38:25.360]   "motivated scammers and bad actors could be willing to pay to leverage increased amplification to
[00:38:25.360 --> 00:38:32.160]   achieve their ends where their upside exceeds the cost. In personation of world leaders,
[00:38:32.160 --> 00:38:37.600]   advertisers, brand partners, election officials and other high profile individuals.
[00:38:37.600 --> 00:38:44.400]   Emergency authorities. Check, check, check. Initially, he was considering a $99 a year annual
[00:38:44.400 --> 00:38:48.480]   subscription, which by the way probably wouldn't have had the same effect because I know somebody's
[00:38:48.480 --> 00:38:52.960]   willing to pay $8 to flip you off. But $99 maybe not.
[00:38:52.960 --> 00:39:00.320]   And Casey says it was because of the discussion with Stephen King who said, "I'm not paying $99."
[00:39:00.320 --> 00:39:04.080]   No, that's an item, believe that. I think Elon was always thinking eight.
[00:39:04.080 --> 00:39:07.040]   Right. He already rumors it was going to be eight.
[00:39:07.040 --> 00:39:11.840]   Right. So, I don't know. I think if he re-releases it, it's going to have to be without
[00:39:11.840 --> 00:39:15.680]   verification of any kind because obviously that's... He started saying $20 a month, remember.
[00:39:15.680 --> 00:39:17.340]   Yeah. He said, "Tw
[00:39:17.340 --> 00:39:19.520]   eight alls a month on Stephen King, he said, "What?" And he said, "How about eight?"
[00:39:19.520 --> 00:39:25.440]   Yeah. Yeah. But if we don't ever have verification, won't the brand start to get upset and...
[00:39:25.440 --> 00:39:33.520]   Oh, wait a minute. That ship has sailed. That ship has totally sailed. I mean, Eli Lilly used to spend
[00:39:33.520 --> 00:39:37.440]   $10 million a year on Twitter. Are they ever going to spend penny one with Elon Musk?
[00:39:37.440 --> 00:39:43.760]   Ever again? Of course not. Yeah, of course not. If he really wants to save it, if he wants my
[00:39:43.760 --> 00:39:47.200]   advice, Elon, if you're listening, which are probably not your work and job.
[00:39:47.200 --> 00:39:49.520]   No, but I can send your advice to Jason Calicanis.
[00:39:49.520 --> 00:39:58.800]   Our great hand of God. Connected tissue to Elon Musk. No, the way to save this is you charge and
[00:39:58.800 --> 00:40:04.960]   you verify. So basically, you do the old verification process, but then charge people to do it. And
[00:40:04.960 --> 00:40:10.400]   you let anybody get verification if they can verify that that's really them.
[00:40:11.600 --> 00:40:17.200]   So have a solid verification procedure. Charge eight bucks. I mean, many of us won't pay it.
[00:40:17.200 --> 00:40:23.280]   Many of us will. But at least don't cancel verification. That's the problem.
[00:40:23.280 --> 00:40:31.200]   Why can't the current verification verified people be grandfather then?
[00:40:31.200 --> 00:40:36.400]   They went through a procedure. What does it matter? You're next to Schmoe.
[00:40:37.920 --> 00:40:42.480]   What? He's checking that they're that they're God. Well, he did try that for five minutes.
[00:40:42.480 --> 00:40:47.120]   No, I'm sorry. I'm still thinking about verification actually verifying who I am.
[00:40:47.120 --> 00:40:52.800]   The main purpose of verification wasn't to say, okay, this person's really important.
[00:40:52.800 --> 00:40:57.840]   It's that this is the real person. The real person. The other 25 Jeff Jarvis is on Twitter
[00:40:57.840 --> 00:41:02.000]   and not the real Jeff Jarvis is only this one is. Right. Right. Let's see. It's a real names thing.
[00:41:02.000 --> 00:41:07.120]   And that that's something that everybody might want. It's a good thing. Everybody could get.
[00:41:07.120 --> 00:41:11.440]   Yes, exactly. This is one of the reasons we talked about this last week. I'm sorry. I yelled at you,
[00:41:11.440 --> 00:41:16.320]   Jeff. Is your blood pressure back to normal? You should be out at the real Jeff. You didn't
[00:41:16.320 --> 00:41:21.920]   yell. You just you just. People were talking about they were talking about it online. The reason
[00:41:21.920 --> 00:41:28.640]   whoa, man, a self verification that works quite well. And you can be the judge. I want you to look
[00:41:28.640 --> 00:41:33.120]   at my profile, please. Did you figure it out? Well, with Jake's help. Yeah, I was.
[00:41:35.760 --> 00:41:40.400]   Hey, you further proved my point that I was trying to make last week. You're right. And
[00:41:40.400 --> 00:41:48.080]   what was your point that you get your kid to do? No, the fact that everybody doesn't necessarily
[00:41:48.080 --> 00:41:54.880]   have that skill set to go in and think about a real tag. So Jeff there, he's unmasked on that social.
[00:41:54.880 --> 00:41:59.920]   You put the rail tag, which is even Twitter. I mean, as a mess, no, tells you how to do it.
[00:41:59.920 --> 00:42:06.080]   They say use this as your link to master. No, that's fine for Twitter. But again, everybody
[00:42:06.080 --> 00:42:10.000]   doesn't have access to their own domain. You could do it, Jeff. You could still do it on your
[00:42:10.000 --> 00:42:14.160]   Twitter account too, by the way, you know, you just make that link on Twitter. I can't do it with
[00:42:14.160 --> 00:42:20.480]   medium and I can't do it with my school. Yeah, maybe not. But all you need is this one thing,
[00:42:20.480 --> 00:42:23.360]   Buzz machine, which is verifiably you to link back to your
[00:42:23.360 --> 00:42:28.160]   Mastodon and people say, Oh, this must be the real Jeff Jarvis because a fake one couldn't do that.
[00:42:28.160 --> 00:42:32.800]   Correct. The other thing is, if I can jump in, if I can jump in because I listened to that conversation
[00:42:32.800 --> 00:42:38.560]   and you made a self-disparaging remark, Jeff, about Buzz machine saying,
[00:42:38.560 --> 00:42:43.840]   well, nobody knows what Buzz machine is. And I first of all disagree with that. It's a fantastic
[00:42:43.840 --> 00:42:49.120]   blog and everybody should read it. Fantastic. And the other thing is that if somebody goes to
[00:42:49.120 --> 00:42:54.720]   your Mastodon handle, sees that you're verified through Buzz machine, then goes to Buzz machine.
[00:42:54.720 --> 00:42:59.120]   Any intelligent person can scan what's written there and see that you're really legit.
[00:42:59.120 --> 00:43:04.800]   Well, but I can say, as somebody who had a humorless imposter after me,
[00:43:04.800 --> 00:43:12.720]   they could go also go to Buzz machine with three Z's. Yeah, sure can. And so it doesn't really mean
[00:43:12.720 --> 00:43:16.480]   much. So my point, we're going to get legal going again. I don't got to get a good idea.
[00:43:17.120 --> 00:43:24.560]   My point is, oh, he yelled at me. He was just me. My point is that, I'm not sure what I'm
[00:43:24.560 --> 00:43:30.960]   now because he's hiding his head in shame, right? Right, Jeremy. You went ballistic.
[00:43:30.960 --> 00:43:37.280]   Yes. The point is, let me make my point first before you go ballistic again.
[00:43:37.280 --> 00:43:43.360]   You probably need multiple means. If it's Nick Christoff of the New York Times,
[00:43:45.600 --> 00:43:48.960]   you want, and Nick has a, who just joined Mastodon, by the way,
[00:43:48.960 --> 00:43:55.040]   he's got the New York Times to verify him in that way. Well, New York Times can have his own
[00:43:55.040 --> 00:43:58.720]   server and say, anybody who's on here is really New York Times. They don't need to have their
[00:43:58.720 --> 00:44:04.560]   another method. You don't understand. All Nick has to do is get his New York Times to do the,
[00:44:04.560 --> 00:44:08.720]   to the, I'm saying that sometimes you want multiple, like, I've been trained as a journalist. You try
[00:44:08.720 --> 00:44:12.480]   to, you know, you ask twice, you get three answers. You try to ask more than once.
[00:44:12.480 --> 00:44:15.440]   Multiple methods are not a bad thing. Well, by the way, what do you think you were
[00:44:15.440 --> 00:44:20.240]   yelling about last week, which I'm funding now, by the way, I'm funding journadot host.
[00:44:20.240 --> 00:44:23.120]   All right. So I believe in it even more of the school,
[00:44:23.120 --> 00:44:28.000]   is that it all say, wasn't just about verification. It's also, let's just like to put
[00:44:28.000 --> 00:44:31.680]   dot social. It's providing a service for a community of people. Yeah, I'm not against
[00:44:31.680 --> 00:44:36.960]   them being journadot host. I'm against their notion that they should be the arbiters of who's
[00:44:37.520 --> 00:44:43.360]   officially, no, but here's the thing, Leo. They decided that for that community, you had to be
[00:44:43.360 --> 00:44:47.440]   a journalist to be in there. That's fine. So they were for their own purposes of their own
[00:44:47.440 --> 00:44:50.720]   country. I don't have a problem with that. They were verifying that people were journalists.
[00:44:50.720 --> 00:44:55.920]   Yeah. But I don't want the, the oppression that, well, if you're a journalist, you must be on
[00:44:55.920 --> 00:45:00.880]   journadot host. Otherwise, no, it's because you could, so, so Matthew Ingram wrote a, wrote a,
[00:45:00.880 --> 00:45:05.600]   wrote a column about this academic guy and his host, who because they led in one conservative
[00:45:05.600 --> 00:45:11.040]   journalist, journaled a host, he just put ballistic, even worse to Leo and said, you're
[00:45:11.040 --> 00:45:14.880]   on blocking the whole server. Yeah. That's a problem. Like, we can block one person.
[00:45:14.880 --> 00:45:20.560]   Yeah. You know, it's stupid. But no, there's, there's multiple places where you can do this.
[00:45:20.560 --> 00:45:25.600]   Part of the idea that I'm hoping we get to is places like Lion, which, which is an organization
[00:45:25.600 --> 00:45:32.000]   that serves small, local, hyper local news sites could start its own instances for their communities.
[00:45:32.720 --> 00:45:38.720]   Or INN, the, the, the group of non-profit news sites could do. It's just become services for
[00:45:38.720 --> 00:45:43.120]   places and you could be, I could see that you're on INN and I know you're a journalist. I could see
[00:45:43.120 --> 00:45:45.920]   you're on journal host and they went to the airport. I know you're a journalist. I could see you work
[00:45:45.920 --> 00:45:49.360]   with the Washington Post. Oh, that's where I see you're a freelancer. That's where I disagree. I
[00:45:49.360 --> 00:45:54.560]   don't think journadot host should be in the job that responsible for saying whether you're a journalist
[00:45:54.560 --> 00:45:59.360]   or not. There are one signal, Leo. That's all they are is a signal. That's not what verification is.
[00:45:59.360 --> 00:46:03.040]   Verification isn't saying I'm a journalist. Verification is saying I'm Jeff Jarvis.
[00:46:03.040 --> 00:46:10.080]   Right. Yes. And that should be done by you. If you're, if you're, if you're a columnist for the
[00:46:10.080 --> 00:46:15.440]   New York Times, it would behoove the New York Times on the online version of your column to have a link
[00:46:15.440 --> 00:46:19.920]   so that they shouldn't, you can hide that link. It doesn't have to be hard. Let's try to get the
[00:46:19.920 --> 00:46:23.520]   New York Times. That's going to keep you here. No, no, they would absolutely do that because it
[00:46:23.520 --> 00:46:28.080]   verifies that you are who you say you are. They have it. Not a single news organization is done.
[00:46:28.080 --> 00:46:32.480]   Well, not a single one. Then then do your blog or you could do it with your, by the way,
[00:46:32.480 --> 00:46:36.960]   you could do it with your Twitter account. It's, it shouldn't be like, it shouldn't be like healthcare
[00:46:36.960 --> 00:46:43.280]   in America where it's, it's a link to the player. So they're, we're in the early days of the new
[00:46:43.280 --> 00:46:48.560]   Macedon, right? So there are going to be a hundred solutions coming out. And you could easily imagine
[00:46:48.560 --> 00:46:52.080]   something that will cost less than eight bucks a month where you go and you show them your
[00:46:52.080 --> 00:46:56.640]   passport and your driver's license and they say, yep. And then they have a reputation as a company
[00:46:56.640 --> 00:47:01.600]   that they're verifying people are who they say they are. And this would actually enable
[00:47:01.600 --> 00:47:06.960]   pseudonymity, right? So you, you prove to them that you really are who you are. And then you go online
[00:47:06.960 --> 00:47:12.880]   with the, with the verification badge that they certify as being legitimate because they checked
[00:47:12.880 --> 00:47:17.360]   your D's. And then, and then you can have a fake name. We don't need to belabor this because we did
[00:47:17.360 --> 00:47:20.560]   it last. We did it for the year. Let me last week. No, we different hour.
[00:47:21.600 --> 00:47:26.720]   Our positions differ a little bit. I don't, I think the whole point of mass and desentralization. So
[00:47:26.720 --> 00:47:31.760]   any centralization is a bad idea. But you know what? This is a little teeny, weeny part of the
[00:47:31.760 --> 00:47:36.800]   whole thing that isn't all that important. So we can, we can disagree on that. It's not that.
[00:47:36.800 --> 00:47:41.600]   I'll just say this. It's like there's a, there's a club called the Society of Professional Journalists.
[00:47:41.600 --> 00:47:46.720]   I think they're full of crap. I don't belong to them. But some choose to. And they have a membership
[00:47:46.720 --> 00:47:50.560]   policy as to who they led in this, this real club. And you can use that as a single and say,
[00:47:50.560 --> 00:47:54.480]   look, I'm a journalist. I'm a freelancer, but I'm a journalist or not. And you can judge that.
[00:47:54.480 --> 00:48:00.480]   And then that claims to have certified, you're genius. But I don't think that's a really good.
[00:48:00.480 --> 00:48:04.800]   Yeah, exactly. Exactly. So, so I wouldn't stop them. I'm just saying the real
[00:48:04.800 --> 00:48:09.680]   advantage of what Massadon offers is it isn't centralized, but it is a way to do that and
[00:48:09.680 --> 00:48:14.560]   verify yourself. I think in a perfectly adequate way. But we don't need to talk about that. Let's
[00:48:14.560 --> 00:48:20.320]   continue to talk about it. Well, two exciting things here. I did one is that George De K is
[00:48:20.320 --> 00:48:23.440]   on Massadon. Yes. Let's all go follow, follow George De K.
[00:48:23.440 --> 00:48:31.440]   And then, um, oh, my gosh, go just, just put up, put up a two, just all he said was exciting times
[00:48:31.440 --> 00:48:37.520]   exclamation point. Imagine how busy he is these days. Who? Yeah. Boy, you're gene.
[00:48:37.520 --> 00:48:42.080]   Oh, he says, you know, I, by the way, people talk a lot about him. It's an open source project
[00:48:42.080 --> 00:48:47.680]   with hundreds of contributors. Absolutely. So good for, good for you, if any, or whatever his
[00:48:47.680 --> 00:48:52.320]   name is. But if you look at the source code, if you look at the, more importantly, if you look at
[00:48:52.320 --> 00:48:57.360]   the documentation, it's clear this is a big team effort. No, absolutely. And they've done a very
[00:48:57.360 --> 00:49:06.480]   good job. 4.0 just came out. They have changed the word to to publish. I had a poll on my site
[00:49:06.480 --> 00:49:12.240]   about whether we should change it back to to and the publishers has it by about four votes.
[00:49:12.240 --> 00:49:17.920]   It was as close as how many 10 I am so disappointed in Twitter social community.
[00:49:17.920 --> 00:49:25.280]   Can you get Scott Galloway off your screen? I can't, I can't take it. So there about 435 votes,
[00:49:25.280 --> 00:49:30.080]   although, uh, one of the things that, well, no, but half of them were, were for two. You like
[00:49:30.080 --> 00:49:35.600]   to or you don't like to I like to I like to I like to. What I like about it is that, is that
[00:49:35.600 --> 00:49:41.520]   Rajco didn't his English wasn't good enough. He didn't get the joke. Right. That's pretty fun.
[00:49:41.520 --> 00:49:47.440]   Yeah, but it is funny. Yeah. So we have about 3000 users right now on a mass 3000 active
[00:49:47.440 --> 00:49:53.280]   users are mastered on a Twitter social, which is I think I've come to the conclusion that's
[00:49:53.280 --> 00:49:59.760]   exactly the right amount. Somewhere between two and five thousand for an individual server.
[00:49:59.760 --> 00:50:03.520]   A lot of brands are start Vivaldi just announced they're doing Vivaldi.social.
[00:50:03.520 --> 00:50:08.880]   I wanted to ask y'all about brands, but what you because I saw this story with Nike jumping
[00:50:08.880 --> 00:50:14.480]   on the web three bandwagon the other day, what's stopping the likes of Nike and other brands from
[00:50:14.480 --> 00:50:20.560]   doing and master done instance. And that's I think a good idea. You know, there's some,
[00:50:20.560 --> 00:50:24.960]   there's some, you know, some people are nervous about that. The beauty of master done is you don't
[00:50:24.960 --> 00:50:29.440]   have to you can block an instance. You don't have to follow them. If Nike says they, we have a big
[00:50:29.440 --> 00:50:33.200]   fan base and we want to engage with them just as we have, we're a brand. That's a brand. Yep.
[00:50:33.200 --> 00:50:42.080]   We engage with our fan base through a variety of means forums, a club club to it and that's
[00:50:42.080 --> 00:50:47.120]   that's pretty much why I joined to it that socials because of our that's who you want to be with
[00:50:47.120 --> 00:50:52.720]   community folks. And that's a local on account back in I guess it was 2018 or so,
[00:50:52.720 --> 00:50:58.880]   which I never used, but I did have since merged it into to it that social because of the whole
[00:50:58.880 --> 00:51:04.640]   community aspect and I can limit it. Now, Jeff, you're on mass done that social, which is one of the
[00:51:04.640 --> 00:51:08.880]   two. It's probably the biggest server, the Mastodon on the line of the best. It's the newbie server.
[00:51:08.880 --> 00:51:13.600]   It's where everybody goes thinking that there is a central mastodon. Right. And it's probably
[00:51:13.600 --> 00:51:18.880]   the federated line is probably very fast. It scrolls by really quick. It is because that's all
[00:51:18.880 --> 00:51:25.360]   people who are the local, but the local. Yeah. But the big ones, the big Mastodon run ones are
[00:51:25.360 --> 00:51:32.320]   closed like they're maxed out. And I'll tell you why the minute a Barack Obama,
[00:51:32.320 --> 00:51:38.880]   Michelle Obama, or Elon Musk joins any server, George, I wonder. I don't know where George is,
[00:51:38.880 --> 00:51:44.000]   but crash. George is on. Well, if you look at the top of your own service right now, he's on your
[00:51:44.000 --> 00:51:50.000]   federated feed. Yeah, he's universe done. So they are probably getting hit pretty hard.
[00:51:50.720 --> 00:51:57.840]   Because you remember in the old days of Twitter, who was it? Justin Bieber had his own server.
[00:51:57.840 --> 00:52:04.560]   Oh, yeah. That's right. Twitter is distributed like any big web service over many, many, many
[00:52:04.560 --> 00:52:09.840]   servers. Got a half a proper load balance. And they actually gave Bieber his own server at the
[00:52:09.840 --> 00:52:16.400]   time he was the easily the biggest person ever on Twitter. So, you know, I, the problem with George
[00:52:16.400 --> 00:52:22.320]   Decay is that there are a few George Decay bots out there. So I, you said he's on universe.
[00:52:22.320 --> 00:52:27.840]   Universe. So done. Oh, there it is. Okay. So I'm already following. I'm going to hope that's
[00:52:27.840 --> 00:52:31.680]   really him. Yeah. I hope he gets off Facebook. That's what I wanted to do. Well, and this would be
[00:52:31.680 --> 00:52:36.960]   a great opportunity for George or somebody who knows George to show him how you get rid of the
[00:52:36.960 --> 00:52:44.080]   link tree, George. And you wanted to use, you know, your link to George needs help to prove.
[00:52:44.080 --> 00:52:48.320]   Well, I understand that. I think some of that is because we have Twitter brains and we expect
[00:52:48.320 --> 00:52:52.640]   somebody central to verify us. You know how many people complain that they could never get a
[00:52:52.640 --> 00:53:00.240]   blue check on Twitter? Yeah. Lots, right? Yeah. Yeah. I like a system where you verify yourself
[00:53:00.240 --> 00:53:05.600]   in a way that is pretty darn good that works. Right. Yeah. Can I ask you a question, Leo? Because
[00:53:05.600 --> 00:53:12.400]   this seemed to change with with four dot O. Before, if I went to twitter.social/explore,
[00:53:12.400 --> 00:53:19.280]   I would see who was on the server. I no longer see that. I now see what appears to be the local feed.
[00:53:19.280 --> 00:53:26.160]   So that's up to the server. So if I go to, I can't go to a server that's not yours. Go to
[00:53:26.160 --> 00:53:35.680]   journal. Okay. Journal.host/explore. That used to give me big boxes of who was on the server.
[00:53:35.680 --> 00:53:41.040]   Now, instead everywhere I go, I get something like this. Oh, maybe that is. Let's let me go to
[00:53:41.040 --> 00:53:44.640]   mine and just see because maybe that is something because I didn't change anything.
[00:53:44.640 --> 00:53:52.080]   It used to be kind of here a feature to count. Type O. Explore. Explore is not a word.
[00:53:52.080 --> 00:53:56.800]   That's that's if you don't have acne anymore. You are export. Oh, yeah. Because I'm logged in.
[00:53:56.800 --> 00:54:00.480]   That's giving me. It's not going to work for me. That's what I'd say. You have to go to a
[00:54:00.480 --> 00:54:04.160]   yeah. Well, maybe they did change that. The other thing they changed, which you might like,
[00:54:04.160 --> 00:54:09.280]   there's an edit button. You can edit your toots. I'm sorry. There always has been published.
[00:54:09.280 --> 00:54:14.400]   No, you're published. No, there hasn't. That's it. Oh, you see, I think I got four before
[00:54:14.400 --> 00:54:17.360]   everybody else. You might have. Wait, wait, wait, wait, we stopped there. What is, what does that
[00:54:17.360 --> 00:54:21.600]   jerk do we don't see it? And then what's it about? I can't stand it. He hates Galloway.
[00:54:21.600 --> 00:54:25.760]   So this is hysterical because he doesn't like him. He wanted me to get it off. But now he's
[00:54:25.760 --> 00:54:29.040]   wanting me to play, which I'm not. No, I just want to know what the hell he's talking about.
[00:54:29.040 --> 00:54:34.240]   I just, you know what? I just left the advisory board of a company because he was going to be on
[00:54:34.240 --> 00:54:40.160]   it. I said, no, I'm not coming here. He's a quick thing. By the way, in the week crashed
[00:54:40.160 --> 00:54:47.680]   mockumentary about we work interviewing Adam Nomen. It's pretty funny. They've got somebody
[00:54:47.680 --> 00:54:53.200]   who looks just like Scott Galloway, which isn't that hard. Go ahead. Go ahead, Mike.
[00:54:53.200 --> 00:54:57.200]   Yeah, just a couple of things. First of all, you just said, you know, you referred to toots
[00:54:57.200 --> 00:55:03.360]   right as a noun. What do we call things that go through the publish? Like when you publish
[00:55:03.360 --> 00:55:07.680]   is it a publish? I'm going to still call them toots. You can call them posts.
[00:55:07.680 --> 00:55:12.320]   They're still going to be. The other thing I wanted to mention is I just wrote a sub-stack
[00:55:12.320 --> 00:55:19.360]   for content creators, especially writers. We writers and journalists have always had this
[00:55:19.360 --> 00:55:24.320]   fraught relationship with Twitter, which is that it's such a, it's Twitter has always been such a
[00:55:24.320 --> 00:55:30.720]   infinity pool of content and political bickering. And it's always distracting. When you're on Twitter
[00:55:30.720 --> 00:55:35.200]   and you're a writer, using Twitter feels like you're working, right? You're doing, you're sort of
[00:55:35.200 --> 00:55:40.560]   looking things up. You're arguing over topics and so on. And it's always been kind of a problem for
[00:55:40.560 --> 00:55:46.640]   writers. And so I just wrote a, but also a resource. Yeah. I just wrote a piece about making the
[00:55:46.640 --> 00:55:51.360]   case that for most people, of course, if you're going to leave Twitter, mass it on its place to go.
[00:55:51.360 --> 00:55:57.280]   But for writers, you might want to also have a sub-stack, get into the sub-stack stuff because
[00:55:57.280 --> 00:56:01.200]   they've recently announced a whole bunch of really cool stuff. So if you're not familiar
[00:56:01.200 --> 00:56:05.680]   sub-stack, it's a writer platform for sending newsletters, but it's also a blogging platform.
[00:56:05.680 --> 00:56:10.720]   It's a podcast platform, very minimalist. It's a video platform. You can upload video or take
[00:56:10.720 --> 00:56:16.320]   video and publish that. It has an RSS reader of all things. So you can put in all your RSS
[00:56:16.320 --> 00:56:21.760]   feeds and just be in the sub-stack inbox and see all the RSS feeds go by, along with the
[00:56:21.760 --> 00:56:26.560]   publications that you subscribe to on sub-stack. But they've also had some social things, which
[00:56:26.560 --> 00:56:32.080]   is really interesting. They've added chat. They've added mentions. So you can mention
[00:56:32.080 --> 00:56:40.560]   sub-stack writers. You can repost other writers' articles and then comment on them, essentially a
[00:56:40.560 --> 00:56:49.920]   quoted retweet. That sort of thing. Yes, yes, exactly. But the case I'm making is that when you're
[00:56:49.920 --> 00:56:55.280]   writing, when you're working, when you're doing research and it's hard and you feel like you
[00:56:55.280 --> 00:56:59.760]   want to escape to the Twitter world where you can be thrilled with all kinds of information and
[00:56:59.760 --> 00:57:05.040]   argument and all that kind of stuff, sub-stacks actually a pretty good substitute if you use all
[00:57:05.040 --> 00:57:09.600]   these features while you're working. It brings you into your work. It brings you into your audience
[00:57:09.600 --> 00:57:16.560]   because that's your basic following on sub-stack is the people who subscribe to you. Those are your
[00:57:16.560 --> 00:57:24.720]   people there. It's not just random people. And so personally, I'm using Massadon as a social network
[00:57:24.720 --> 00:57:32.640]   and sub-stack is a kind of like substitute social network while I'm working. And I think this is a
[00:57:32.640 --> 00:57:36.800]   great idea for writers. I don't know if anybody else, a couple of people said that it's a great
[00:57:36.800 --> 00:57:41.360]   idea. They're doing it now. But it's just something to consider. Sub-stack is an social network,
[00:57:41.360 --> 00:57:46.240]   but it's enough of a social network and enough of a newsfeed to sort of scratch that.
[00:57:46.240 --> 00:57:51.280]   Nice. What are you working? Mike, isn't sub-stack just another Twitter? Why don't you have a blog in
[00:57:51.280 --> 00:57:56.240]   the step? Well, I do have a blog as well. I know, but I'm just saying. Well, that's my
[00:57:56.240 --> 00:58:01.200]   complaint about sub-stack. You saw what happened. I started reading your posts and then it said,
[00:58:01.200 --> 00:58:07.280]   "Well, you can't read this. You got to buy it." And it let, I can read one and then it'll make me buy
[00:58:07.280 --> 00:58:12.480]   it. I didn't comp you in it. I'm going to consult you. Well, it doesn't. No, but that's still my
[00:58:12.480 --> 00:58:18.560]   problem with it. It's not the point, right? Yeah. I mean, I kind of like the idea of a blog that
[00:58:18.560 --> 00:58:24.000]   isn't a painting, but you have to make a living. Right. So I'm not going to complain about that.
[00:58:24.000 --> 00:58:28.880]   You deserve every penny you get because your stuff's worth it. I make a living in other ways.
[00:58:28.880 --> 00:58:37.120]   So, and I hate to write. Well, you know, the thing is, we're in a moment right now where
[00:58:37.120 --> 00:58:41.920]   something like sub-stack is pretty welcome. And of course, you can monetize a blog entirely
[00:58:41.920 --> 00:58:46.400]   independently. Not as well. Sub-stack is much better. Not as well. But like with protocol going
[00:58:46.400 --> 00:58:50.000]   out of business, for example, I was writing freelance for protocol. Like I was writing
[00:58:50.000 --> 00:58:54.000]   articles for protocol and now they're gone. So it's like, you know, let's talk about that,
[00:58:54.000 --> 00:58:58.720]   actually. That's a bit of it. It's like nice to have sub-stack the source of revenue where
[00:58:58.720 --> 00:59:02.320]   nobody can cancel it. You know what I mean? It's kind of nice. Can I do one more thing about
[00:59:02.320 --> 00:59:07.600]   the best done before we leave it? Yeah. Well, no, it's not a democracy, Mike. It's not for you.
[00:59:07.600 --> 00:59:12.560]   It's a career. Oh, no, it's not to me. It's like the Jeff, please. Go right ahead.
[00:59:14.800 --> 00:59:19.840]   So we also talked last week about Black Twitter. And there's been a fascinating discussion
[00:59:19.840 --> 00:59:26.240]   on Master Don. Well, Lovey's unmested on now. So follow Lovey. And you know, that's how I got
[00:59:26.240 --> 00:59:36.960]   into Black Twitter. So Jonathan Flowers, Dr. Jonathan Flowers, Shengo Kai, Zirk.us had a fascinating
[00:59:36.960 --> 00:59:44.400]   thread this morning, or yesterday morning, about the affordance of the quote tweet and the importance
[00:59:44.400 --> 00:59:46.960]   of it. There's much to argument about, right? Because because Eugene,
[00:59:46.960 --> 00:59:50.960]   you, Eigen said, I don't want quote tweets because they're performative. They're not conversational.
[00:59:50.960 --> 00:59:56.480]   It leads to bad behavior. But the belief is, and I've talked to other experts in Black Twitter
[00:59:56.480 --> 01:00:01.680]   about this in the last week, that the quote tweet is critical for call and response
[01:00:01.680 --> 01:00:10.960]   as a cultural element of Black Twitter. And without that affordance, it just doesn't work as well.
[01:00:10.960 --> 01:00:15.600]   So there's tons and tons of discussion about this then about quote tweets. And then I saw,
[01:00:15.600 --> 01:00:21.760]   it's on the rundown somewhere down there, where the great thing about being unmasked on now is
[01:00:21.760 --> 01:00:27.520]   some, okay, somebody, put your money where your mouth is. And online 74 at GitHub is somebody
[01:00:27.520 --> 01:00:34.080]   proposing a method for maybe a better quote tweet. And maybe the powers that be, and there are
[01:00:34.080 --> 01:00:38.960]   powers in an open source world, which is to say, Rajko will say, oh, this looks better, or maybe
[01:00:38.960 --> 01:00:43.280]   not. But that's where the discussions should occur. That's, that's what's so beautiful about this,
[01:00:43.280 --> 01:00:48.400]   is you're not waiting for say, well, will you fix this? Will Jack fix this? Now there's a way that
[01:00:48.400 --> 01:00:51.760]   you can make suggestions to the corpus. And that's what the beautiful part of it.
[01:00:51.760 --> 01:00:55.200]   Or even do it yourself, if you have the skills, that's the beauty of open source.
[01:00:55.200 --> 01:01:00.160]   Sorry. There are a lot of, I mean, mastodon, I've said this before, I'll say it again, because
[01:01:00.160 --> 01:01:06.640]   important is just one of many entrance, entrance points to activity pub. That's what really is
[01:01:06.640 --> 01:01:12.560]   going on. That's the Fediverse. There's also a whole bunch of, we talked about pixel fed,
[01:01:12.560 --> 01:01:18.240]   which you've joined, which is an Instagram, there is finally, you to clone. There's other
[01:01:18.240 --> 01:01:24.000]   mastodon Twitter like things like Pleroma, there's almost an infinitude. It's open. In fact,
[01:01:24.000 --> 01:01:32.400]   that's true social is based on the mass mass. It doesn't federate because they know nobody would
[01:01:32.400 --> 01:01:37.840]   would federate with it. But it's, they basically use mastodon and cupcake to make their own thing.
[01:01:37.840 --> 01:01:41.440]   It's open source. That's what you just described as the beauty of open source in general.
[01:01:41.440 --> 01:01:45.200]   Exactly. Exactly. Gargron played out that that's going on right now.
[01:01:45.200 --> 01:01:51.360]   Gargron is Eugene Rochko, the author, original author of Mastodon. Gargron, that's his handle,
[01:01:51.360 --> 01:01:56.720]   has said he doesn't like quote tweets because he thinks that that's part of the problem on Twitter.
[01:01:56.720 --> 01:02:01.920]   There's, I've seen evidence that it isn't in fact used for harassment more than it's used for
[01:02:01.920 --> 01:02:05.680]   other things. And you write, Jeff, there are some benefits, a call and response kind of thing.
[01:02:05.680 --> 01:02:11.840]   So I think that eventually something like the quote tweet will come to Mastodon, but Gargron's
[01:02:11.840 --> 01:02:17.040]   resisted it. And I think I don't disagree with him. We have the boost, which is just a retweet.
[01:02:17.040 --> 01:02:23.200]   And you could quote tweet as you used to do on Twitter by hand, if you wanted to.
[01:02:23.200 --> 01:02:28.480]   So I kind of agree with that. Well, I don't want to make it too easy because,
[01:02:28.480 --> 01:02:31.760]   well, is it considered, is it considered bad form to do it by hand? No.
[01:02:31.760 --> 01:02:38.480]   Well, it's not. It just you just made an effort. Clearly. Yeah. You could get a link to somebody's
[01:02:38.480 --> 01:02:43.120]   to right, write a comment. I've done it a few times and paste the link in and that would be
[01:02:43.120 --> 01:02:46.320]   completely appropriate. And I think that's a good thing. That is appropriate. And that's enough of a
[01:02:46.320 --> 01:02:52.080]   speed bump to prevent the whole the real problem with. I was afraid that that was considered rude.
[01:02:52.080 --> 01:02:57.200]   Yeah, I know a lot of people coming to Mastodon are very worried about the. Oh, yeah.
[01:02:57.200 --> 01:03:02.400]   Scolded. Yeah, because you will get scolded, but it's changing already. You know, content warnings,
[01:03:02.400 --> 01:03:09.040]   which really were de rigor when Mastodon was a refuge for transgender people and other people who
[01:03:09.040 --> 01:03:15.040]   didn't feel safe on Twitter. So we have a, there were a lot of, you know, kind of standards to
[01:03:15.040 --> 01:03:20.640]   protect people. And those are, I noticed completely disappear. But that's what happens.
[01:03:20.640 --> 01:03:24.880]   That's what happened to Twitter. It's, it's kind of an amazing thing. These things change as people
[01:03:25.440 --> 01:03:30.000]   and use them. So here's what I will just tell you real quickly that is very useful. Everybody
[01:03:30.000 --> 01:03:36.000]   should know you can follow hashtags just like you know, a person. So if you made it better,
[01:03:36.000 --> 01:03:40.880]   it's even better. So if you search for, let's say you want to search for black Mastodon
[01:03:40.880 --> 01:03:46.640]   and you find that hashtag, you can, and this is the advanced web interface, but you could do it on
[01:03:46.640 --> 01:03:51.840]   any version of it, you can create a column on the advanced web interface that you pin.
[01:03:52.800 --> 01:03:59.360]   And now this is a column called black Mastodon that has many of the people who will ultimately
[01:03:59.360 --> 01:04:04.320]   create black Mastodon. And including by the way, the, I think the one guy that I followed that
[01:04:04.320 --> 01:04:12.560]   started this all off for me was black Aziz Anansi in exile. And, but love is here now and some of
[01:04:12.560 --> 01:04:19.760]   the other stalwarts of black Twitter. So I suspect, I'm hoping that all of these subcultures,
[01:04:19.760 --> 01:04:23.600]   look, I mean Mastodon was created really as a, as a refuge for subcultures.
[01:04:23.600 --> 01:04:29.520]   And I suspect that all of them will be well represented in the long run. And that's the beauty
[01:04:29.520 --> 01:04:34.880]   of having your own instance, the subculture called Twit listeners has its own instance, right?
[01:04:34.880 --> 01:04:40.960]   Yeah. And I realized the other day, I don't need to follow anybody on Twit social, because I just
[01:04:40.960 --> 01:04:44.960]   look at the local timeline and everybody's. So they're all hurt. You don't follow them.
[01:04:44.960 --> 01:04:48.960]   Yeah. I just unfollowed everybody. There is a negative to that. So I have to figure this out.
[01:04:49.600 --> 01:04:53.520]   If you follow them in the, if I follow you, Jeff, and you're on Twit social,
[01:04:53.520 --> 01:04:58.720]   I will see your posts in the local timeline, but your boosts will not go into home because I'm not
[01:04:58.720 --> 01:05:02.160]   following. So it does affect the boost. So I'm going to have to figure out how to,
[01:05:02.160 --> 01:05:05.920]   have you been doing the call out social? Yeah, that's awesome. That's X Twitter,
[01:05:05.920 --> 01:05:10.400]   X Twitter employees and current Twitter employees have probably got fired for being there.
[01:05:10.400 --> 01:05:19.200]   Let's talk about that. No, this is so, this is really shameful, I think.
[01:05:19.840 --> 01:05:28.080]   Apparently Twitter for a long time had a culture that it was okay in their slack to say,
[01:05:28.080 --> 01:05:34.160]   hey, Jack, I don't like this or you're doing it wrong. And so, and apparently,
[01:05:34.160 --> 01:05:40.160]   those rules haven't been changed explicitly, but they've absolutely been implicitly changed now.
[01:05:40.160 --> 01:05:42.640]   Oh, no. Elon foolishly.
[01:05:44.640 --> 01:05:49.200]   You know, I think Elon likes to pretend he's a coder like he did a VIM joke the other day.
[01:05:49.200 --> 01:05:57.440]   He's not a coder. We likes to pretend. So he tweeted something like, oh, I see why Twitter
[01:05:57.440 --> 01:06:04.720]   slow in overseas. We have more than 10,000 remote procedure calls and it's slowing it down to which
[01:06:04.720 --> 01:06:11.680]   one of his engineers, the guy working on this particular problem on Android, said, no, no,
[01:06:11.680 --> 01:06:19.040]   that's, that's not the problem. All remote procedure calls happen inside the network over fiber.
[01:06:19.040 --> 01:06:23.520]   You could have 20,000, you could have a million. It wouldn't matter. They're very fast fiber.
[01:06:23.520 --> 01:06:29.440]   There's other issues that are causing the slowdown overseas. I know I work on this at Twitter to
[01:06:29.440 --> 01:06:36.240]   which Elon's response is you're fired. Yeah, that's going to be a problem in the long run.
[01:06:37.280 --> 01:06:42.160]   This is a man. He came up with a chain about environment. Yeah, this is what I'm saying about
[01:06:42.160 --> 01:06:47.680]   narcissists. Elon Musk has a personality trait similar to Trump, which is just, you know, toxic
[01:06:47.680 --> 01:06:54.240]   narcissism. And one of the features of toxic narcissists who are very smart as Elon Musk clearly
[01:06:54.240 --> 01:06:59.040]   is. And this answer is something that somebody was asking about in the club, Twitter discord a
[01:06:59.040 --> 01:07:02.960]   little while ago, you know, why he's so smart? Why would he be making all these dumb moves? And
[01:07:02.960 --> 01:07:08.960]   I think the reason is that people who are really good at really hard things and they're also
[01:07:08.960 --> 01:07:13.680]   narcissistic tend to believe that because they're good at really hard things, they're really good
[01:07:13.680 --> 01:07:18.320]   at all the hard things. And I've worked with a lot of, I've been, I've been an editor for decades,
[01:07:18.320 --> 01:07:24.320]   working with technical people who are brilliant developers. And because they know they're brilliant
[01:07:24.320 --> 01:07:28.320]   developers, they think, well, I'm also a brilliant writer. I'm also a brilliant speaker. I'm also a
[01:07:28.320 --> 01:07:33.760]   brilliant this brilliant that. And it's just it's just a something that goes along with a lot of
[01:07:33.760 --> 01:07:39.760]   competent competence in one area, plus narcissism, who makes you think he literally thinks he knows
[01:07:39.760 --> 01:07:43.360]   better than the 10,000 people who have been working on these problems.
[01:07:43.360 --> 01:07:50.160]   Listen to anybody. There's a name for this is called the Dunning Kruger Effect, a cognitive bias in
[01:07:50.160 --> 01:07:56.880]   which people wrongly overestimate their knowledge or ability in a specific area. This is from psychology
[01:07:56.880 --> 01:08:01.200]   today. This tends to occur because a lack of self awareness prevents them from accurately
[01:08:01.200 --> 01:08:06.080]   assessing their own skills. And you're kind of expanding on it by saying, well, because they're
[01:08:06.080 --> 01:08:12.640]   smart in other areas. But honestly, they don't have to be. Yeah, Dunning Kruger is a very
[01:08:12.640 --> 01:08:17.440]   so here's a little difference. Dunning Kruger would apply to something like George W. Bush,
[01:08:17.440 --> 01:08:22.160]   who just didn't know he was ignorant because he was ignorant, right? Right. Right. Whereas
[01:08:22.160 --> 01:08:25.760]   this is a different kind of thing. And I think it's related in narcissistic personality disorder,
[01:08:25.760 --> 01:08:31.600]   but I'm not a psycho. I'm not convinced there's evidence that Elon is a genius in any other
[01:08:31.600 --> 01:08:37.680]   field either. I'm not honest with you, but I'll stipulate that because it doesn't matter. We don't
[01:08:37.680 --> 01:08:42.960]   need to argue about it. He's clearly not a genius Twitter. Here's the tweet. BDW says,
[01:08:42.960 --> 01:08:47.360]   "Elon, I'd like to apologize for Twitter being super slow in many countries. App is doing more
[01:08:47.360 --> 01:08:52.320]   than a thousand poorly-batched RPCs just to render a timeline to which Eric Fraunhofer,
[01:08:52.320 --> 01:08:57.040]   who's responsible for this on Android said, "I've spent six years working on Twitter for
[01:08:57.040 --> 01:09:01.680]   Android. I could say this is wrong." Now, here's a mistake Eric made. You don't tweet that.
[01:09:01.680 --> 01:09:06.320]   Don't retweet it. There's plenty of there's many a boss that would fire you for that, right?
[01:09:06.320 --> 01:09:12.320]   You know better than that. I will say this. I like this idea.
[01:09:12.320 --> 01:09:19.120]   And I can't say, "Yes, sir. I do." Well, I wouldn't. No, you know what? I wouldn't. But
[01:09:19.840 --> 01:09:28.400]   I will say this. I totally cosigned the idea or the premise that they had previously where they
[01:09:28.400 --> 01:09:34.080]   could say in their Slack channel, "Hey, Jack, no, I don't agree with this. This is probably a better
[01:09:34.080 --> 01:09:38.800]   route to go." That's great. The problem I have is yes, go in public with it. He didn't
[01:09:38.800 --> 01:09:42.640]   put up this. That's not cool. No, I shouldn't have that stuff in the four walls.
[01:09:42.640 --> 01:09:48.000]   Two points in his defense. Elon Musk shouldn't have gone public with what he's like. Good point.
[01:09:48.000 --> 01:09:52.160]   I agree with that too, sir. And there's no way that if we put that in the Twitter
[01:09:52.160 --> 01:09:56.560]   Slack channel that Elon Musk would have seen it. He's running three companies
[01:09:56.560 --> 01:10:00.720]   and he's spending all his time on Twitter. So how do you reach it? He never seen it.
[01:10:00.720 --> 01:10:05.760]   He never saw it, right? He was crapping all over the engineers at Twitter.
[01:10:05.760 --> 01:10:09.520]   They have a right to defend themselves, I think. There's evidence that he has fired
[01:10:09.520 --> 01:10:14.960]   20 people overnight a couple of nights ago for stuff they posted privately in company slides.
[01:10:14.960 --> 01:10:21.280]   Probably on Slack. So he's an equal opportunity. And now he is requiring
[01:10:21.280 --> 01:10:26.960]   something new for employment. You have that story, right? OMG, I don't even know. Can you do this?
[01:10:26.960 --> 01:10:32.160]   I don't even know if this is legal. Elon has, Twitter sent out, was it last night?
[01:10:32.160 --> 01:10:36.480]   What? They sent an email to all employees.
[01:10:36.480 --> 01:10:41.920]   And I got a question for you first. Can't tell me true. Are you hardcore Twitch?
[01:10:42.640 --> 01:10:46.720]   I am hardcore Twitch. There you go. Well, good. Because I'm going to send you an email
[01:10:46.720 --> 01:10:52.800]   saying the form Twitter is shifting to an engineer-driven operation, one that will
[01:10:52.800 --> 01:10:59.680]   quote need to be extremely hardcore going forward. The Washington Post got this email.
[01:10:59.680 --> 01:11:06.240]   This will mean quote long hours at high intensity. Only exceptional performance will
[01:11:06.240 --> 01:11:11.200]   constitute a passing grade. Okay. I'm going to make you work an 80 hour week with no extra
[01:11:11.200 --> 01:11:17.920]   compensation. And you better be exceptional or you're out of here. And then, and then
[01:11:17.920 --> 01:11:26.720]   at the bottom it says, agree to this or take your severance. Wow. You have a checkbox
[01:11:26.720 --> 01:11:32.960]   that says commit to the new hardcore Twitter or leave the company with severance pay. That
[01:11:32.960 --> 01:11:37.120]   was this morning that went out. Wow. And by the way, if you're looking for more information
[01:11:37.120 --> 01:11:42.960]   there's just a better way to do it. And search for the word hardcore. Just pro tip.
[01:11:42.960 --> 01:11:49.200]   No, don't do that. Don't. Don't. Don't. No, I got to do it now. No, please don't.
[01:11:49.200 --> 01:11:52.000]   I got to do it now. I need to do not show the screen.
[01:11:52.000 --> 01:12:02.080]   I'll show it a screen. Something about a few. This is from run DMG. Something about a guy in his
[01:12:02.080 --> 01:12:08.320]   50s using hardcore unironically in a business email feels like a crime. Oh boy. There's a lot
[01:12:08.320 --> 01:12:16.720]   of porn fans who are very mad right now. So that seems to me like a very mean.
[01:12:16.720 --> 01:12:23.600]   Oh, that's what it is. I mean, that's so big. I get the premise of it. Again, I think it's just
[01:12:23.600 --> 01:12:28.320]   going about this the wrong way. I have no problem with leadership coming and saying,
[01:12:29.120 --> 01:12:34.320]   hey, let's get it done. Y'all come on. We're going to do this. Right. You know, but that's a good
[01:12:34.320 --> 01:12:37.920]   coach would do. Right. But he's just going to go out of the room and say to his team,
[01:12:37.920 --> 01:12:46.000]   I expect 110% out of you. They are. Or get off my team. They all do. Right. So, I have to say,
[01:12:46.000 --> 01:12:50.800]   if it's good, he's just going about it. If I'm a software engineer, presumably accomplished.
[01:12:50.800 --> 01:12:54.560]   I've been working at Twitter, let's say eight or nine years. I really love the company because
[01:12:54.560 --> 01:12:59.920]   the people who worked at Twitter did apparently really love the company. This guy comes in,
[01:12:59.920 --> 01:13:04.400]   is telling me I got to work. I got to double my intensity, got to create exceptional code.
[01:13:04.400 --> 01:13:08.880]   Okay. I like that. I don't mind that or quit. And oh, by the way, here's three months severance.
[01:13:08.880 --> 01:13:13.520]   If you quit, what are you going to do? I'm going to take the three months because you don't
[01:13:13.520 --> 01:13:17.280]   know if he's going to fire you tomorrow. Right. Because you said something in the elevator.
[01:13:17.280 --> 01:13:22.000]   Right. I don't understand why if you're going to forge it unless you're an H1B.
[01:13:22.560 --> 01:13:26.800]   Okay. So, who's going to stay? People who will have to leave the country
[01:13:26.800 --> 01:13:32.080]   will get deported because they don't have a job. They're going to stay. Nice job,
[01:13:32.080 --> 01:13:35.600]   Elon. People while there's a layoff school and all we're all crazy.
[01:13:35.600 --> 01:13:38.480]   Yeah. With three months. A lot of time.
[01:13:38.480 --> 01:13:41.120]   A lot of time. Thirty thousand people have laid off in a week.
[01:13:41.120 --> 01:13:46.400]   Yeah. But, okay. Amazon laid off a bunch of people this week. But if you are a good coder,
[01:13:46.400 --> 01:13:49.200]   you could find another job in three months. Somewhere. Don't you think?
[01:13:50.160 --> 01:13:54.480]   I would think so. There's still people hiring. Okay. Well, I was going to say if you're a PR
[01:13:54.480 --> 01:13:58.000]   person, we fired all the people already. Yeah. There are literally other jobs there too.
[01:13:58.000 --> 01:13:59.280]   In the communications department.
[01:13:59.280 --> 01:14:04.240]   So, I understand, Elon, saying that you're right. It's like a coach. And I think that's probably
[01:14:04.240 --> 01:14:08.720]   what Elon was thinking. Well, why is he telling it to us? You know, this is the problem. He's
[01:14:08.720 --> 01:14:13.120]   basically, yeah, you're right. Showing the world that he's like pushing these guys around.
[01:14:13.120 --> 01:14:15.760]   It's like it's one thing to be pushed around. It's another thing to
[01:14:17.120 --> 01:14:21.920]   have it be done publicly. It's just it's just it's just wrong. It's clearly wrong. We all
[01:14:21.920 --> 01:14:25.120]   can tell that it's wrong. And it's just another failure.
[01:14:25.120 --> 01:14:28.960]   He goes after US senators too. He goes, that's part of his pride.
[01:14:28.960 --> 01:14:33.200]   So, I'm going to go after Ron Wyden and he are now in a feud and Elon loves it.
[01:14:33.200 --> 01:14:36.080]   So, here's the, I actually found on Twitter,
[01:14:36.080 --> 01:14:39.600]   bye. Thank you, Mike, searching for hardcore. Here is
[01:14:39.600 --> 01:14:46.400]   according to CNN. According to a CNN, and they're great. He's got a
[01:14:46.960 --> 01:14:51.840]   he's got to put that that hashtag in his hashtag hardcore.
[01:14:51.840 --> 01:15:00.640]   I love what's his last name? Donnie on CNN, the Irish guy who's their social guy. He's so great.
[01:15:00.640 --> 01:15:07.920]   I just love him. Donnie O'Sullivan. He's great guy. Anyway, he says, here's the email,
[01:15:07.920 --> 01:15:13.120]   a FARC in the road going forward to build a breakthrough Twitter at 2.0 and succeed.
[01:15:13.120 --> 01:15:16.880]   This Elon set this this morning and succeed in an increasingly competitive world.
[01:15:16.880 --> 01:15:19.200]   We will need to be extremely hardcore.
[01:15:19.200 --> 01:15:23.040]   Now, you tell me if a coach would say anything different from this. Okay.
[01:15:23.040 --> 01:15:28.000]   This will mean working long hours at high intensity. Only exceptional performance will
[01:15:28.000 --> 01:15:30.800]   constitute a passing grade. Sounds like every coach I've ever had.
[01:15:30.800 --> 01:15:35.840]   Twitter will also be much more engineering driven. Design and product management will
[01:15:35.840 --> 01:15:40.720]   still be very important and report to me. But those writing great code will constitute the
[01:15:40.720 --> 01:15:45.280]   majority of our team and have the greatest sway. Coder's got to love that.
[01:15:45.280 --> 01:15:49.440]   It's hard. Twitter is a software and servers company. By the way, Mike Masnick said,
[01:15:49.440 --> 01:15:51.680]   you do not understand the business if you think that's true.
[01:15:51.680 --> 01:15:57.280]   So I think this makes sense. If you are sure that you want to be part of the new Twitter,
[01:15:57.280 --> 01:16:03.120]   please click yes in the link below. It's to a forms. You actually have to actually click yes.
[01:16:03.120 --> 01:16:08.960]   Anyone who's not done so by 5 p.m. Eastern tomorrow, Thursday, will receive three months of
[01:16:08.960 --> 01:16:13.440]   severance. That's where it falls apart. Whatever decision you make. That's where it falls apart.
[01:16:13.440 --> 01:16:17.120]   Thank you for your efforts to make Twitter successful, Elon. Everything above that,
[01:16:17.120 --> 01:16:22.640]   I have no problem with this. It's motivational speaking ish. That's good. Good point. Yeah.
[01:16:22.640 --> 01:16:28.400]   Mike Masnick says, if he thinks at its heart, Twitter is a software and servers company. It
[01:16:28.400 --> 01:16:34.240]   doesn't matter how many engineers self-certify that their hardcore, the whole thing is going to
[01:16:34.240 --> 01:16:40.640]   collapse. Twitter is not about servers and software and never has been. What is Twitter about, Mike?
[01:16:40.640 --> 01:16:45.440]   I wonder, we have to get him on an ask. I swear every time I see Mr. Mas and his tweets,
[01:16:45.440 --> 01:16:51.840]   I can visualize as him rolling his eyes. He's a big guy rolling. A guy roller.
[01:16:51.840 --> 01:16:59.120]   I love his feet. I put up a headline of his today. He did a great headline today.
[01:17:00.800 --> 01:17:07.040]   What was it? He waits every day and is like, he's the editor, chief of Panama, but anytime.
[01:17:07.040 --> 01:17:08.480]   Tech Dirt. Tech Dirt. Here's one.
[01:17:08.480 --> 01:17:14.640]   Here's one. If you thought the FTC was going to F over Elon, just wait until he learns about the EU.
[01:17:14.640 --> 01:17:24.720]   Did I tell you what Elon said in the lawsuit that he's facing over his Tesla compensation?
[01:17:24.720 --> 01:17:30.320]   Oh, no. Oh, this is another good one. Elon has been, he's better than Trump for his days.
[01:17:30.960 --> 01:17:33.360]   He is our Donald Trump, isn't it? Right now, you.
[01:17:33.360 --> 01:17:40.800]   Yes. Yes. Yes. Do we always need to have a feeling that we can make fun of, Mike?
[01:17:40.800 --> 01:17:47.360]   Is that the? Absolutely. We're living in an age of extreme narcissists. Look at Netflix.
[01:17:47.360 --> 01:17:56.320]   We crashed, becoming Anna. The Theranos series, Trump, Fire Island,
[01:17:58.240 --> 01:18:07.040]   and so on. Bezos, it's like these outer control, promise the moon, delusional narcissists,
[01:18:07.040 --> 01:18:11.520]   or this is what characterizes our era, it seems like.
[01:18:11.520 --> 01:18:16.320]   So, Elon's being sued currently
[01:18:16.320 --> 01:18:26.000]   by shareholders. My shareholders. Yeah. To defend his $56 billion compensation pay package,
[01:18:26.000 --> 01:18:31.840]   that's a year. It's the largest ever to be paid out to an individual from a publicly traded company.
[01:18:31.840 --> 01:18:39.040]   He testified today. And inadvertently, this is from WeGotThisCovered.com.
[01:18:39.040 --> 01:18:42.960]   Inadvertently, let us slip how Littlely understands about Twitter and its dealings
[01:18:42.960 --> 01:18:47.040]   with the Federal Trade Commission. You will remember, of course, the FTC
[01:18:49.440 --> 01:18:58.800]   reached a consent decree with Twitter in May saying, "You have to do a report on every feature
[01:18:58.800 --> 01:19:03.840]   you add to Twitter about its security because your security has been so terrible.
[01:19:03.840 --> 01:19:11.440]   And we need to see that report and you need to make it public so that everybody is assured
[01:19:11.440 --> 01:19:16.400]   that you have thought about security in every feature, including I might add blue checks going
[01:19:16.400 --> 01:19:24.240]   forward." By the way, these programs have to be audited by a third party.
[01:19:24.240 --> 01:19:32.480]   Thank you. Okay. And are responsible for it. Yeah. Even unto fine and jail. In his testimony,
[01:19:32.480 --> 01:19:39.200]   when the attorney questioning must seem to unconvinced by that argument, "Oh, well,
[01:19:39.200 --> 01:19:44.240]   okay, as reported by the chanceary daily, must apparently told the court he was no longer bound
[01:19:44.240 --> 01:19:50.720]   to this FTC consent decree because, quote, "An agreement made under duress is not valid."
[01:19:50.720 --> 01:19:57.920]   Tell that to everybody who ever did a plea bargain. What? Wait a minute. What?
[01:19:57.920 --> 01:20:03.440]   I'd agree with it. So when the attorney questioning must seem, quote, "unconvinced by that argument,"
[01:20:03.440 --> 01:20:07.680]   the billionaire asked whether he was trained as a lawyer to which he responded, "I have some
[01:20:07.680 --> 01:20:11.040]   familiarity with the legal system. If you were in enough lawsuits, you pick up a few."
[01:20:11.040 --> 01:20:16.320]   The line is a yes, no question, sir. That ain't crueger effect. "The consent decree was made
[01:20:16.320 --> 01:20:23.120]   under duress. An agreement made under duress is not valid as a foundation of law," says Elon Musk.
[01:20:23.120 --> 01:20:28.480]   "Are you a lawyer, sir?" Oh, yeah. Well, if you're in enough lawsuits, you pick up a few things
[01:20:28.480 --> 01:20:31.440]   along the way. But I did sleep it at holiday and it's press last night.
[01:20:31.440 --> 01:20:40.160]   So I hate to keep bringing up the N word, but narcissism is remember when Trump said that he
[01:20:40.160 --> 01:20:45.440]   declassified documents with his mind. If somebody on narcissism, they think their mental state
[01:20:45.440 --> 01:20:52.720]   affects the legal status of what they're doing. So is that is there any legal? I wish we had
[01:20:52.720 --> 01:20:56.560]   a lawyer here. Maybe he asked any cell who is also on Twitter. That's social.
[01:20:56.560 --> 01:21:03.520]   We should ask her, "Is an agreement made under duress not legal, not binding?"
[01:21:03.520 --> 01:21:07.680]   I'll let you ask her. They're all made under duress. I'll let you ask her that.
[01:21:07.680 --> 01:21:14.640]   I think every single consent decree is under duress. That's the notion, nature of a consentor.
[01:21:14.640 --> 01:21:20.000]   When Microsoft agreed with the Department of Justice to have an ombudsman paying attention
[01:21:20.000 --> 01:21:25.440]   to how they were doing their job, they didn't do it because they wanted to. They were under duress.
[01:21:25.440 --> 01:21:31.920]   It's only legally binding if you're getting a Shatsu massage or receiving music and you're
[01:21:31.920 --> 01:21:38.320]   a piece of the universe. Then it's legal. Unbelievable. I'm not a lawyer, sir, but I've been sued plenty
[01:21:38.320 --> 01:21:45.600]   of times. I think I think you're wrong, Elon. Anyway, let's take a break. I'm telling you,
[01:21:45.600 --> 01:21:53.200]   he's going to be the gift that keeps on giving. Clearly. Good grief. We haven't even touched this.
[01:21:53.200 --> 01:21:56.400]   We haven't scratched the surfaces. There's just stuff that happened this morning.
[01:21:57.040 --> 01:22:04.720]   This is just stuff that happened this morning. Like I said, I paid Casey Newton 100 bucks
[01:22:04.720 --> 01:22:09.840]   because the platformers got it all. You know what, Mike? I'm going to pay for your sub-stack.
[01:22:09.840 --> 01:22:18.080]   You're the best, dude. The only problem I have is that I have to make up a new password and
[01:22:18.080 --> 01:22:24.160]   email for every platformer or every sub-stack. I haven't figured out a way to do this because
[01:22:24.160 --> 01:22:29.200]   you can't just, like medium, you pay five bucks and you get medium. But sub-stacks, everybody's
[01:22:29.200 --> 01:22:36.800]   individual. Yes, but it's not a portal. Your single username can get you multiple scripts.
[01:22:36.800 --> 01:22:44.960]   All of them, I just pay for more. The problem is my username for Casey's newsletter is platformer@loport.com.
[01:22:44.960 --> 01:22:47.600]   Yes, that's, yes. You do that. I blew it.
[01:22:47.600 --> 01:22:53.440]   At sensible measure, you make sure people aren't using it. Right, selling my hand. I do that too.
[01:22:53.440 --> 01:23:01.680]   Now I'm screwed. That's the problem. I didn't even mention that they fired 4,400 of their 5,500
[01:23:01.680 --> 01:23:08.560]   contract employers' employees last week. That Elon said, "I'm turning off 80% of all those
[01:23:08.560 --> 01:23:20.160]   microservices, including apparently SSMS, right?" Whoops. I've been sued plenty at times. I don't
[01:23:20.160 --> 01:23:25.360]   need a lawyer. Well, did you see that I think it was TechDirt said that they're going to stop
[01:23:25.360 --> 01:23:30.720]   allowing embedded tweets in their articles because they just don't know what's going to happen.
[01:23:30.720 --> 01:23:32.880]   Trust them. Yeah, it was Mike Bastic said so, yeah.
[01:23:33.920 --> 01:23:39.920]   That's a very reasonable thing. Ed Bot wrote a great article on what to do now if you're on
[01:23:39.920 --> 01:23:44.960]   still on Twitter. I will reiterate the two most important things, one of which is,
[01:23:44.960 --> 01:23:49.840]   over the years, many of us have turned on a lot of third-party services using
[01:23:49.840 --> 01:23:56.640]   login with Twitter or an in-of-story line or whatever. I went through all of my third-party
[01:23:56.640 --> 01:24:00.000]   services and I canceled them all. Yep, thanks to you. I did too.
[01:24:00.000 --> 01:24:06.160]   Only because if something goes wrong, that could be a passageway into something else.
[01:24:06.160 --> 01:24:10.720]   I just don't want to give that access. The other thing he suggested, which might now be
[01:24:10.720 --> 01:24:15.280]   kind of hard to do, is turn on two-factor authentication. I had that covered.
[01:24:15.280 --> 01:24:18.960]   Thank goodness. Fortunately, I had turned it on. One of the things you recently were able to do
[01:24:18.960 --> 01:24:23.600]   like in the last few years is you have to first have SMS authentication turned on,
[01:24:23.600 --> 01:24:29.200]   but then I used my Yuba key and then I was going to be able to uncheck SMS because SMS is not secure
[01:24:29.200 --> 01:24:33.760]   anyway. I have it with a Yuba key and with an authenticator app.
[01:24:33.760 --> 01:24:37.120]   Yeah, you use this. I'll just say. I'll just please explain as you did to me on
[01:24:37.120 --> 01:24:43.760]   Mastodon, the story that then came out that Mosk had worked on two-factor.
[01:24:43.760 --> 01:24:49.360]   Well, it seems to be that one of the 80% of microservices he turned off was the ability to send a text
[01:24:49.360 --> 01:24:58.880]   message to verify your two-factor. If you only had SMS two-factor, text me a six-digit code and
[01:24:58.880 --> 01:25:03.040]   I'll log in with that, that's no longer working. Apparently, at least some have reported I haven't
[01:25:03.040 --> 01:25:07.360]   tried it because I never used it because it was not reliable. I'm not secure. So,
[01:25:07.360 --> 01:25:14.720]   is that how you authenticate with Twitter? I'm afraid to look. I'm afraid I'm going to...
[01:25:14.720 --> 01:25:19.200]   Oh, wait, another thing. I don't remember. I'm not signing into Twitter because I'm afraid that
[01:25:19.200 --> 01:25:23.200]   I'm going to start rolling down the hill as the last I'll ever see at Twitter. You have a verified
[01:25:23.200 --> 01:25:32.000]   check, right? You can't change your name anymore. No. Nor can I. So, if you're verified on Twitter,
[01:25:32.000 --> 01:25:38.320]   I think this is because of Kathy Griffin's solution because she changed her verified name
[01:25:38.320 --> 01:25:43.200]   to Elon Musk. She's a trailblazer. Which got her band.
[01:25:43.200 --> 01:25:48.240]   So, if I go... If you change your mother's Twitter handle to Elon Musk and get going,
[01:25:49.920 --> 01:25:55.920]   that's one solution. So, I guess I still have the check, which I guess I'll lose at some point
[01:25:55.920 --> 01:25:59.680]   because I'm not... Wait, wait, wait. Is it only white because you're in dark mode?
[01:25:59.680 --> 01:26:03.360]   Oh, really? Yours is not white? Stop blue. Or is that one of those...
[01:26:03.360 --> 01:26:09.120]   Official ones? No. Are you official? No. It could be anything.
[01:26:09.120 --> 01:26:14.800]   Only the shadow knows. Let me go to Settings. Mine's white. And yours is white too.
[01:26:15.840 --> 01:26:20.080]   Where do you change? Is that display here? What if we're dark mode?
[01:26:20.080 --> 01:26:26.160]   Let's go into default. Oh, my eyes. Oh, that's so much better. Oh, my eyes.
[01:26:26.160 --> 01:26:31.600]   How can you do this? What a relief. Yeah, it's blue in its way. So, if I edit profile
[01:26:31.600 --> 01:26:37.360]   and I say, "No, I don't want to be Leo Laport. I want to be... Or I want to be Leo Laport
[01:26:37.360 --> 01:26:45.360]   as it used to be Chief Twit." And I hit Save. It says, "Deny." That's nice. That's nice.
[01:26:46.000 --> 01:26:52.080]   Nice coding there, right? Let's try that again. It's a little blue pop-up off. It actually goes
[01:26:52.080 --> 01:26:58.080]   on. It's not even in front of what frame, right? It says, "Deny." What the hell does that mean?
[01:26:58.080 --> 01:27:02.560]   Elon Musk did that himself. Yeah, I think he coded that. That's the coder. Code monkey.
[01:27:02.560 --> 01:27:08.400]   Code monkey. So, I can't change my name. I guess that's what deny means.
[01:27:08.400 --> 01:27:14.400]   Not denied. Should be denied, right? I can't inform you. Yes. Let's see. Deny.
[01:27:15.360 --> 01:27:21.840]   I deny you. What is the name? I deny you. Yes, I like to deny it. Yes. Deny it.
[01:27:21.840 --> 01:27:26.560]   I never even attempted to change it. I never met the woman. Deny.
[01:27:26.560 --> 01:27:33.120]   Lance, go ahead. Are you checked? Are you okay? I'm checked, but I think I'm in the wrong screen.
[01:27:33.120 --> 01:27:39.200]   It's so fun. Edit profile. Profile. And then edit profile. See if you can change it,
[01:27:39.200 --> 01:27:45.920]   because it just says, "Amprew it right now." Take off. Yeah, just "Amp." Be "Amp." "Amp."
[01:27:45.920 --> 01:27:53.680]   I love you, "Amp." Okay, now click save. Deny. Deny. Deny.
[01:27:53.680 --> 01:28:02.400]   That's a new show. Deny. Don't log out, because, yeah, somebody's saying,
[01:28:02.400 --> 01:28:07.680]   Knox says, "Two-factor was completely broken." You couldn't log back in, if you wanted to.
[01:28:07.680 --> 01:28:12.160]   So don't log out. We don't want to test it. Is there anybody in the chat room who wants to test it?
[01:28:12.160 --> 01:28:20.400]   I'm plugged to it. You don't want to go back to Twitter. Crash test. A crash test dummy.
[01:28:20.400 --> 01:28:26.240]   Just log out. Okay, Anthony's going to check. Anthony's going to do a log out.
[01:28:26.240 --> 01:28:29.520]   Log in at the house. Anthony Nielsen. Try that, but let me see.
[01:28:29.520 --> 01:28:34.160]   It does take a few days to download your data, but I don't know. Jeff, have you downloaded your
[01:28:34.160 --> 01:28:39.760]   tweets? Yes. Right before Elon actually took over, it took a two and a half days, but they came.
[01:28:39.760 --> 01:28:46.560]   And why? Yeah, I was going to ask why. I don't know. Wait, wait, wait. Look at my office.
[01:28:46.560 --> 01:28:54.080]   Everything. It's just another pile. Right. So, yeah, so I have more crap.
[01:28:54.080 --> 01:28:55.200]   Order. Order.
[01:28:55.200 --> 01:28:56.000]   Order.
[01:28:56.000 --> 01:28:56.640]   Today on hoarders.
[01:28:56.640 --> 01:29:02.160]   So, FTLFTR says it worked this morning with the Authenticator app. So, at least the Authenticator
[01:29:02.160 --> 01:29:07.440]   app does work, which is good. That's good news. Please, folks, don't log out of your Twitter account
[01:29:07.440 --> 01:29:11.760]   on my behalf. Our show today brought to you, by the way, Love Having Your Mike Yelligan.
[01:29:11.760 --> 01:29:17.040]   It's great to see you in beautiful Mexico City. It's starting. Oh, look, it's now so pretty.
[01:29:17.040 --> 01:29:21.280]   The sun's cut. It's the opera house right there. So beautiful.
[01:29:21.280 --> 01:29:23.840]   Where is it? Oh, wow. Yeah, there it is.
[01:29:23.840 --> 01:29:27.920]   You know who loves living there is Paul Therat, his second home is that? Yeah.
[01:29:27.920 --> 01:29:32.000]   Yeah. Great city. Great city. His second home, and he tells me all his USB-C cables.
[01:29:32.000 --> 01:29:37.600]   He forgot and he brought them all down. I didn't have any homes.
[01:29:37.600 --> 01:29:45.120]   I said, you know, I it's always been the problem when you have several homes. That dude is a home.
[01:29:45.120 --> 01:29:46.000]   No one's there.
[01:29:46.000 --> 01:29:52.240]   Well, sometimes my stuffs at Bedminster. Sometimes it's more long ago. I don't know.
[01:29:52.240 --> 01:29:54.480]   Does Paul speak Spanish?
[01:29:55.520 --> 01:30:00.240]   Yeah, he's learning it. His wife's actually apparently learning it faster than he is. But yeah,
[01:30:00.240 --> 01:30:04.480]   yeah, he loves it. It's he loves the food, right? Yes.
[01:30:04.480 --> 01:30:05.680]   Who's amazing. Yeah.
[01:30:05.680 --> 01:30:08.640]   Incredible. We might get one question for you. Yeah.
[01:30:08.640 --> 01:30:12.640]   Because I have a tender, a tender stomach. Yes.
[01:30:12.640 --> 01:30:17.680]   Walking by some of that street food in Mexico City, I'm dying for it, but I'm afraid I might die
[01:30:17.680 --> 01:30:22.880]   with it. It's it's it's it's popular with the locals.
[01:30:23.520 --> 01:30:29.440]   It's unlikely to make you sick, but the almost all the street food is not high quality food.
[01:30:29.440 --> 01:30:36.400]   Of course, you love Taco Bell, so maybe that's not a problem. Yeah. Hey, man, it's. Hey, hey, hey, hey, hey.
[01:30:36.400 --> 01:30:43.840]   Taco Valley down here, but they they they cook the ever loving hell out of everything for the street vendors.
[01:30:43.840 --> 01:30:47.840]   There's some high quality street vendors, to be sure, and and we love them.
[01:30:47.840 --> 01:30:53.760]   But the thing that's amazing about Mexico City is a super high quality food that you get at some
[01:30:53.760 --> 01:30:59.840]   of the restaurants. And we got we we have we have a ton of friends here who are chefs and that sort
[01:30:59.840 --> 01:31:05.760]   of thing who just are doing such amazing, innovative work that it's really kind of mind-blowing.
[01:31:05.760 --> 01:31:11.120]   Yeah. You know, Steve, Paul says so attractive, but it's it's really.
[01:31:11.120 --> 01:31:16.480]   Oh, yes. Paul says they live a couple of blocks from the best sushi place ever.
[01:31:16.480 --> 01:31:21.120]   Sushi in Mexico City. I mean, Mexico City is crazy for sushi. It's awesome.
[01:31:21.120 --> 01:31:26.080]   And there are there are probably hundreds of sushi restaurants in Mexico City,
[01:31:26.080 --> 01:31:30.800]   some of which are so fancy that I walked into one and I felt like I felt like a hobo, man,
[01:31:30.800 --> 01:31:34.240]   because it was like everybody was like Argentina. Everybody was like sweet and
[01:31:34.240 --> 01:31:38.880]   Thai. It's really amazing. But yeah, Mexico. Mexico City loves sushi. Where was it?
[01:31:38.880 --> 01:31:43.920]   To be awake. That's right. There you go. Yeah, that's right. Where was it that we went
[01:31:43.920 --> 01:31:49.840]   when we were with the Gastronoment Adventures last year. It was in the big market. And we had the
[01:31:49.840 --> 01:31:56.080]   street tacos that were made famous. They were incredible. Yeah, that's that's not street food.
[01:31:56.080 --> 01:32:00.960]   That's she's just she's doing making really high quality food. Oh my gosh. And and it's very,
[01:32:00.960 --> 01:32:04.640]   you know, they have running water for one thing that's this is a problem with street vendors.
[01:32:04.640 --> 01:32:09.200]   They bring their own water with a bucket like wash things with, you know, it's not a great
[01:32:09.200 --> 01:32:13.120]   scenario. That was actually, you know, they had plumbing a whole bit and that's
[01:32:13.120 --> 01:32:19.440]   really good. So what is it? Donia? What is their name? Yeah, Donia. Donia Valle. Oh,
[01:32:19.440 --> 01:32:25.200]   Valle. Oh my gosh. She's legendary. And that is some really, really delicious food and high quality.
[01:32:25.200 --> 01:32:31.680]   Oh, yeah. It was really high quality. It was so you notice we had a blue tortillas.
[01:32:31.680 --> 01:32:35.920]   A lot of the street vendors in Mexico City and elsewhere in Mexico, they actually die regular
[01:32:35.920 --> 01:32:42.000]   colored tortillas. There's a lot of that kind of stuff going on because really what Mexico is
[01:32:42.000 --> 01:32:49.520]   very good at is very inexpensive food for everyday people. Yeah. And so part of the low cost comes
[01:32:49.520 --> 01:32:54.400]   with some low quality as well. So you've got to be careful with street vendors in Mexico City. But
[01:32:54.400 --> 01:33:00.240]   again, there are some really high quality ones. There is there's Donia Valle's hands making amazing
[01:33:00.800 --> 01:33:08.400]   tacos with the Oaxaca cheese, which is the best cheese ever. Oaxaca. So it was so she was featured
[01:33:08.400 --> 01:33:15.200]   in a Netflix TV show. So she was famous. She's famous. Yeah. Well, Oaxaca, I mean, Oaxaca is
[01:33:15.200 --> 01:33:21.600]   like Mexico's Mexico. You know, it's like Mexicans go to Oaxaca to like really experienced old school
[01:33:21.600 --> 01:33:28.800]   authentic Mexican culture in general and Oaxaca culture in particular. And so the really,
[01:33:28.800 --> 01:33:34.480]   really great food vendors in Oaxaca are really famous throughout Mexico, at least, and some of them,
[01:33:34.480 --> 01:33:39.680]   you know, around the world. So it's pretty, pretty amazing. So just to clarify something
[01:33:39.680 --> 01:33:47.040]   about Mexico City in the top 10 restaurants, I forgot the the the rancor offhand, but in the top 10
[01:33:47.040 --> 01:33:53.360]   restaurants in the world, two of them are in Mexico City, zero of them in the United States,
[01:33:53.360 --> 01:33:59.520]   zero of them are in France. Isn't that interesting? Or in Mexico City, and both of those restaurants
[01:33:59.520 --> 01:34:07.200]   are using primarily Oaxaca ingredients. It's it's Oaxaca theme things, including Puyo, of course,
[01:34:07.200 --> 01:34:10.480]   which is considered the number five restaurant in the world.
[01:34:10.480 --> 01:34:18.800]   This is Donia Valle's she cooks on this crazy thing. This is a small. Yeah. Oh my goodness. And
[01:34:18.800 --> 01:34:25.440]   this is a YouTube video, a YouTuber that they went to this is where we went. It was so good. There it is.
[01:34:25.440 --> 01:34:32.640]   Of course, we were with chef Alex Reese and like all those groupies were like, oh yeah. Yeah,
[01:34:32.640 --> 01:34:38.320]   so we were going in the market. And and of course, Amir won't tell you anything about where you're
[01:34:38.320 --> 01:34:42.560]   going. We just get in the van, we show up, I said, oh, we're going on market. And this guy comes up
[01:34:42.560 --> 01:34:47.680]   and says, Hi, everybody. And he says, I'm chef Alex, and we're going to go shopping and then
[01:34:47.680 --> 01:34:52.880]   we're going to cook. And so we said, Oh, this is great. And we found little did we know everybody.
[01:34:52.880 --> 01:35:00.800]   Yeah, says chef Alex. He's he's a star. He's a legend. Yeah. And then we went to his beautiful
[01:35:00.800 --> 01:35:05.360]   place out of town. And we took all the food that we'd made and cooked it. And it was the best
[01:35:05.360 --> 01:35:11.680]   experience ever. Anyway, hard hits, make your own grasshoppers too. Yeah, we picked our own grasshoppers,
[01:35:11.680 --> 01:35:18.240]   roasted them. I remember those pictures. My hard-hitting college, his girlfriend,
[01:35:18.240 --> 01:35:28.480]   her family is from Oaxaca. Oh, the best food. So I love when his parents like to cook and
[01:35:28.480 --> 01:35:34.800]   send me food. It's quite quite great. You can get Oaxaca cheese here, but I forgot where,
[01:35:34.800 --> 01:35:38.800]   but there's a Oaxaca in March, downtown. There is. Yeah, I think it's on the boulevard.
[01:35:39.440 --> 01:35:41.680]   Anyway, I have to do an ad. Oh, yeah. Yeah. Yeah.
[01:35:41.680 --> 01:35:45.600]   By 15 minutes ago, or he'll never eat again.
[01:35:45.600 --> 01:35:48.160]   They're on their own ever no more Donia.
[01:35:48.160 --> 01:35:53.840]   Our show today brought to you by good friends. Actually, we had a great trip, Lisa and I.
[01:35:53.840 --> 01:36:00.080]   Right before COVID, we went out to Gainesville, Florida to visit it pro TV. They had opened their
[01:36:00.080 --> 01:36:06.080]   brand new studio in Gainesville. I was a little bit jealous because they started in 2013. They
[01:36:06.080 --> 01:36:12.000]   went to an NAB panel that I did. Adam Corolla was on the panel, a bunch of other video streaming
[01:36:12.000 --> 01:36:20.160]   podcasters. It was Don Pazette and Tim Broome. They were already IT trainers in the classroom
[01:36:20.160 --> 01:36:26.320]   setting. They said, "We should do this training on the internet, and IT Pro TV was born. That's
[01:36:26.320 --> 01:36:32.080]   back in 2013. Fast forward like six years later, Lisa and I are at this. They have seven studios.
[01:36:32.080 --> 01:36:36.960]   The most beautiful facility you've ever seen. They're using all seven studios all day,
[01:36:36.960 --> 01:36:43.120]   Monday through Friday because they're always creating new content. They have a dozen of the best
[01:36:43.120 --> 01:36:48.640]   IT professionals in the world. I mean, really talented people working IT professionals,
[01:36:48.640 --> 01:36:53.440]   but they all share one thing, all these trainers. They all have a passion for what they do.
[01:36:53.440 --> 01:36:58.720]   That makes them really good at teaching IT because that passion communicates.
[01:36:58.720 --> 01:37:03.840]   So if you're looking to get into IT, if you're already in IT and you want to get new skills,
[01:37:03.840 --> 01:37:09.440]   and maybe even more importantly, if you have a company with an IT team and you want them
[01:37:09.440 --> 01:37:17.440]   to keep up and they need to, just keep your company safe, IT Pro TV is the place. They'll help
[01:37:17.440 --> 01:37:23.360]   you ensure your success. The good thing about this, sometimes if you're a business owner and you
[01:37:23.360 --> 01:37:27.920]   get training for your staff and you wonder, "Are they going to use it? Are they going to like it?"
[01:37:27.920 --> 01:37:32.720]   Let me tell you, 80% of users who start an IT Pro TV video finish the whole thing.
[01:37:32.720 --> 01:37:38.160]   They're that good. They're that engaging. Your team will be so thrilled when you say, "Okay, guys,
[01:37:38.160 --> 01:37:43.440]   we're getting you IT Pro TV. You're going to get these new skills. You're going to get the,
[01:37:43.440 --> 01:37:50.720]   you know, recertify. You're going to learn about the stuff that we need to make our business thrive.
[01:37:52.160 --> 01:37:58.960]   You'll be thrilled to results. Partly because IT Pro TV is always up to date. They've got training
[01:37:58.960 --> 01:38:02.560]   for everything, all the training, all the search for your team in one place,
[01:38:02.560 --> 01:38:08.800]   every vendor, every skill, Microsoft, course IT training, Cisco training, Linux, Apple,
[01:38:08.800 --> 01:38:15.520]   security, cloud, more than 5,800 hours of on-demand training, plus the stuff they're doing live every
[01:38:15.520 --> 01:38:20.000]   day, ranging from technical skills to compliance to soft skills. A lot of stuff is nice because
[01:38:20.000 --> 01:38:25.120]   like what we do here, you can be in the chatroom, you can watch live. I should say this, IT Pro TV is
[01:38:25.120 --> 01:38:32.800]   a community. Almost a quarter of a million IT Pro TV students are in their forums, in their community,
[01:38:32.800 --> 01:38:38.880]   in their chat rooms. And so you're in a wonderful community of IT professionals and people learning
[01:38:38.880 --> 01:38:43.360]   about IT. You'll love the business plan because you can track your team's results, you get advanced
[01:38:43.360 --> 01:38:49.600]   reporting with very visual reports. So it's great for justifying the spend to your, you know,
[01:38:49.600 --> 01:38:56.080]   management. You'll be able to assign team members, you can manage all your seats, you can access
[01:38:56.080 --> 01:39:01.360]   monthly usage reports, you'll get all the metrics, logins, viewing time tracks completed. You can
[01:39:01.360 --> 01:39:06.960]   even assign subsets of groups, you can assign them to just one class. By the way, all the lessons
[01:39:06.960 --> 01:39:13.760]   are about 20 to 30 minutes, easy to watch during a lunch break at home. You can watch it on Apple
[01:39:13.760 --> 01:39:20.000]   TV, on Roku, on your computer, on your tablet. So it's very convenient. You'll know who's watched
[01:39:20.000 --> 01:39:24.960]   what you can even, they have transcripts of every single episode. So you can say, okay, I want you
[01:39:24.960 --> 01:39:30.880]   to learn this thing. This one thing here, that's episode six in the course on Cisco, and then
[01:39:30.880 --> 01:39:36.880]   see if they watched it. And you'll know, I think IT Pro TV is the best way to learn for an individual,
[01:39:36.880 --> 01:39:41.600]   for somebody already in IT, for somebody who wants to get into IT and of course for your business.
[01:39:41.600 --> 01:39:46.240]   Give your team the IT development platform they need to level up their skills while enjoying the
[01:39:46.240 --> 01:39:57.360]   journey. Itpro.tv/twit, go there today, itpro.tv/twit, we thank you so much for the support of this week.
[01:39:57.360 --> 01:40:02.240]   In Google, and by the way, you support us if you go to that address, that's important.
[01:40:02.240 --> 01:40:09.120]   It's not Twig, it's Twit, itpro.tv/twit, okay, but they'll know, they'll know that you saw it on
[01:40:09.120 --> 01:40:17.440]   this week in Google. Thank you, IT Pro TV. All right, we've done enough of Elon, yes, or should we,
[01:40:17.440 --> 01:40:22.800]   should we do more? It's so well, it's a lot. Before we do one more thing, let me show you
[01:40:22.800 --> 01:40:29.680]   something, Leo, a little Mexico City thing. Can you can you show up? Can you hear that?
[01:40:29.680 --> 01:40:34.960]   What? I don't know if you pick it up the, it's an endless party here at some point.
[01:40:35.680 --> 01:40:42.480]   They're partying out the window? Oh, 24/7. Your microphone, unfortunately, is too good.
[01:40:42.480 --> 01:40:50.160]   Yeah, we can't hear it. There are something like every block, there's an amazing band,
[01:40:50.160 --> 01:40:55.680]   live band that play hour after hour. It's mostly like 60s and 70s American rock in English,
[01:40:55.680 --> 01:41:00.240]   they're Mexican brands, or it's American jazz, which tend to be super brilliant.
[01:41:00.240 --> 01:41:06.560]   Any sleep? I use white noise machines and all kinds of stuff, but they're going to like two,
[01:41:06.560 --> 01:41:13.360]   three in the morning. It's just, I have a slightly off topic question for you, Mr. Elgin. Are you
[01:41:13.360 --> 01:41:18.720]   standing right now for the show? No, I'm sitting. Oh, okay. I'm not going to stand for this. I saw
[01:41:18.720 --> 01:41:25.360]   you, I believe I saw you stand one episode and I tried a handful episodes exhausting. I showed
[01:41:25.360 --> 01:41:30.000]   it, Dan near killed me when I did it. I was like, oh my gosh, how did it mistake? I'll get into this.
[01:41:30.000 --> 01:41:35.040]   I did it once and that's probably the last time I do that. A couple of quick ones, quick ones.
[01:41:35.040 --> 01:41:42.080]   We mentioned protocol. Yeah. Very sad story. Protocol, which I thought was really cool. And we know,
[01:41:42.080 --> 01:41:47.680]   you know, Megan Moroni went to work for them. Oh, and Thomas works for them. They were spun off
[01:41:47.680 --> 01:41:55.440]   from Politico. But I didn't realize his Politico still owned them. Right, Jeff? Yes. Yeah. And then
[01:41:55.440 --> 01:42:01.200]   that in turn was sold to Axel Springer, old friend of mine, a goalie, shekla Islam, he is the CEO,
[01:42:01.200 --> 01:42:06.800]   and she did the deed. So could they just not get advertising? What happened? Because it was a
[01:42:06.800 --> 01:42:10.720]   great, I thought it was great. I was always part of the guest. Well, here's, here's my other
[01:42:10.720 --> 01:42:15.280]   worry, Leo, is that, is that I think that they, they said, Oh, tack. Oh, yeah, it's kind of going
[01:42:15.280 --> 01:42:19.120]   away. Because we see that happen, right? The New York Times had a tech section and these media
[01:42:19.120 --> 01:42:23.040]   companies that aren't in the business like you think that it's more cyclical than it is.
[01:42:23.040 --> 01:42:27.920]   So this is a response to the tech downturn. I think a little bit, I think it's going to
[01:42:27.920 --> 01:42:31.120]   excuse like, I think that it's like, I think Springer wanted it. They want a political for the
[01:42:31.120 --> 01:42:36.640]   political stuff. And I think the tech stuff was just kind of, yeah. Plus, don't forget,
[01:42:36.640 --> 01:42:44.880]   Springer runs campaigns in, in, uh, legislatures against Silicon Valley. Right.
[01:42:44.880 --> 01:42:50.000]   Well, you know, Matt might have concerned me, except I knew the people working there, and I knew
[01:42:50.000 --> 01:42:55.280]   that they would never stand for any influence, uh, pedaling. So these guys, no, no, I, I just
[01:42:55.280 --> 01:43:00.320]   need to work to be the same company that hates Silicon Valley while you're trying to cover and
[01:43:00.320 --> 01:43:04.720]   get money from a, that just didn't kind of fit with their ethos. That is a little scary. So they're
[01:43:04.720 --> 01:43:08.800]   thinking that the tech downturn is permanent. I don't know. That's one speculation.
[01:43:08.800 --> 01:43:13.200]   Interesting. Or no, I don't even, not even permanent. Just like, oh, we got too much going on, too much
[01:43:13.200 --> 01:43:19.120]   risk right now. They, I understand they didn't monetize. They had very few ads and, you know,
[01:43:19.120 --> 01:43:22.720]   they did a lot of newsletters, which were free. I really wasn't sure how they were.
[01:43:22.720 --> 01:43:27.520]   And they were well capitalized. And I can say as a freelancer, they paid well,
[01:43:27.520 --> 01:43:32.880]   and, uh, you know, they had a lot of employees and so on. And, and so, you know, it's, I think they
[01:43:32.880 --> 01:43:37.520]   were, I think they were hoping, you know, when you go into a launch, a new publication, you figure
[01:43:37.520 --> 01:43:40.560]   you're going to lose money for five years. And then eventually you're going to make some money,
[01:43:40.560 --> 01:43:46.160]   something like that. That's what they used to say. But I think they, I, advertising is probably
[01:43:46.160 --> 01:43:51.600]   a drying up out of fears of recession and that sort of thing. So they probably figured, okay,
[01:43:51.600 --> 01:43:56.240]   this is, this is just not worth it. I feel, I feel bad for a Yanko Redkers who,
[01:43:56.240 --> 01:44:02.560]   was it giga home? Good friend of Stacey's. He then left giga home, wrote for Variety for quite a while.
[01:44:03.440 --> 01:44:08.480]   Uh, first technology reported for Variety and then moved over to Protocol a few months ago. And
[01:44:08.480 --> 01:44:14.880]   now he's out of work too. Yeah. So many good people, so many good people. He's, he's a really good
[01:44:14.880 --> 01:44:21.200]   reporter. Um, do you, I hope there's a place for all these people and then I hope it's not
[01:44:21.200 --> 01:44:29.360]   masted on. I hope so too. Yeah. Or PR companies. Yeah. Isn't that what happens? They go to the
[01:44:29.360 --> 01:44:34.960]   dark side. Yeah. You're smart as a freelancer, Mike. If somewhere, if one of your people goes
[01:44:34.960 --> 01:44:38.880]   under, you still have computer world. You have still other people. I, I try, but it's, it's an
[01:44:38.880 --> 01:44:46.160]   endless game of lack of, but he still has to replace that extra slot. Right? Yeah. Right. You
[01:44:46.160 --> 01:44:53.600]   know, yeah. Yeah. Uh, layoffs at Amazon, 10,000 layoffs coming. They announced this week. Meanwhile,
[01:44:53.600 --> 01:45:01.680]   Jeff Bezos pledges his fortune to charity. Um, I thought he'd already signed up on the, uh,
[01:45:01.680 --> 01:45:07.520]   whatever they call them, Bill Gates pledge that they were doing, but, uh, he's in fact, you know,
[01:45:07.520 --> 01:45:15.440]   then I saw that the number two philanthropist in the country in the world, I believe, is his ex.
[01:45:15.440 --> 01:45:17.280]   Yep. Yep.
[01:45:18.080 --> 01:45:24.160]   Mackenzie's doing amazing work. Yeah. Amazing work. So good for her. Yeah. Um,
[01:45:24.160 --> 01:45:29.760]   she just gave, I think just gave two, uh, billion dollars. Another two billion dollars
[01:45:29.760 --> 01:45:36.560]   in donations. So between her and Jeff, they've split his fortune, but obviously it was so huge.
[01:45:36.560 --> 01:45:42.960]   There was plenty, uh, to give away. She's given away 14.4 billion dollars since her divorce in the
[01:45:42.960 --> 01:45:50.800]   last three years. And, uh, her most recent donation is 1.9 billion dollars, 300 organizations.
[01:45:50.800 --> 01:45:57.040]   That's in the last seven months. That's impressive. Oh, Jeff Bezos did not sign the giving pledge.
[01:45:57.040 --> 01:46:01.920]   Now, you just made a claim on the, to the media. He just said, I'm going to give most of it away.
[01:46:01.920 --> 01:46:06.080]   Yeah. He did give a hundred million dollars to Dolly Parton. God bless him.
[01:46:06.080 --> 01:46:11.840]   Some people do whatever she wants with. Some people were, give it away to whatever she wants.
[01:46:11.840 --> 01:46:14.480]   And really put a dent in his lifestyle, I'm sure.
[01:46:14.480 --> 01:46:20.320]   Some people were critical of that. Actually, Dolly has given more than 170 million dollars in
[01:46:20.320 --> 01:46:26.400]   free books to, uh, you know, poor communities and libraries and so forth. So I, that's awesome.
[01:46:26.400 --> 01:46:32.640]   Jose Andres, the previous winner of the hundred million dollar grant, uh, fan Jones of CNN.
[01:46:32.640 --> 01:46:40.720]   Um, so I think that's, uh, that's fine. I, uh, I don't, uh, I don't have, remember Dolly gave,
[01:46:41.600 --> 01:46:48.960]   um, a million dollars to fund the more, more modern vaccine. Yes. God bless her. She's amazing.
[01:46:48.960 --> 01:46:57.600]   That is really great. And her imagination library, uh, book gifting program, uh, has given away
[01:46:57.600 --> 01:47:02.240]   so many books, more than a million dollars with the book. So I'm sure that's where a lot of this,
[01:47:02.240 --> 01:47:08.640]   uh, money will go. I better backstage at the Oakland Coliseum many, many, many, many years ago,
[01:47:08.640 --> 01:47:12.640]   when she was performing with Linda Ronstadt. Oh, how cool. And you know, you think backstage,
[01:47:12.640 --> 01:47:17.120]   you're going to see somebody just being a little grumpier. She's just, she's just amazing. She is,
[01:47:17.120 --> 01:47:23.280]   who she is all the time. Um, phenomenal human being. Really great. Say hello, Dolly.
[01:47:23.280 --> 01:47:30.480]   Did you say that? Oh, she would never have heard that before. I'm saying, no. Pretty
[01:47:30.480 --> 01:47:35.200]   show. I was sick when I was going through to run down. I came across this, this story, and I was
[01:47:35.200 --> 01:47:40.160]   sitting in the host office with Mr. Howell. And I was, I told him straight up, I was like, man,
[01:47:40.160 --> 01:47:46.960]   I'm just jaded because this story does absolutely nothing for me. It would probably,
[01:47:46.960 --> 01:47:53.760]   I would feel better or actually feel anything if that had been Mr. Jammer B saying I'm going to
[01:47:53.760 --> 01:47:58.720]   donate X amount of more. Well, that would be more impressive if Jammer B gives 100 million dollars
[01:47:58.720 --> 01:48:03.840]   to anybody that would, you know, I mean, it just, it just, I don't know. It's Bezos. It's like,
[01:48:03.840 --> 01:48:09.600]   it's like his cigarette money is what you're saying. Yeah. But it's not, it just seems like a PR
[01:48:09.600 --> 01:48:14.880]   move. Of course it is. You know, but if you said it, Miss LePort or Jammer B, it just,
[01:48:14.880 --> 01:48:21.200]   here's the thing. And I believe this, uh, we don't publicize our charitable giving because I,
[01:48:21.200 --> 01:48:25.200]   and that's fine. I, but I agree with you. I think if you put out a press release,
[01:48:25.200 --> 01:48:29.920]   yeah, there's a little, you know, it's a little self-serving. No, we don't, we don't tell people
[01:48:29.920 --> 01:48:34.560]   what we do. Right. Yeah. I mean, I know Y'all's heart. It's good. You know, but we're buying
[01:48:34.560 --> 01:48:38.480]   tickets to a SpongeBob SquarePants, the musical. That's charity.
[01:48:38.480 --> 01:48:46.640]   Queen Pruitt is playing Sandy Daikum Cheeks.
[01:48:46.640 --> 01:48:55.280]   And there's the only night Friday, Friday, November 18th is open and night.
[01:48:55.280 --> 01:49:01.040]   And have you memorized her songs too? Oh, man, I can't get these songs on the songs, the lines.
[01:49:01.040 --> 01:49:07.040]   I'm like, I haven't been reading a script. Why do I know all of this stuff? You were so funny. We were,
[01:49:07.040 --> 01:49:11.440]   I don't remember, maybe I think it was on the, uh, on the call yesterday or at a thrill. Oh, yeah.
[01:49:11.440 --> 01:49:16.160]   We're in our meeting and I'm trying to go through my points in the meeting and then all of a sudden,
[01:49:16.160 --> 01:49:23.280]   I hear you said there were hersing. Yep, they're rehearsing again. And then sorry happens now is the
[01:49:23.280 --> 01:49:30.480]   dogs chime in. No, no, this gets starts to sing. It's it's oh boy. Everybody's learning all of
[01:49:30.480 --> 01:49:38.480]   these lines and his dad got music. Oh, I just I just I just love that the man who hates music
[01:49:38.480 --> 01:49:47.120]   is more than anything. Oh, I know you do. I know you. I love. I just love it. I would fly out to go
[01:49:47.120 --> 01:49:52.560]   see it just for just for the joy of watching us. But you're proud of the Queen. I'll take pictures.
[01:49:52.560 --> 01:49:57.440]   I am quite proud. I am quite. Oh boy. I never cost him if you seen her costume.
[01:49:57.440 --> 01:50:03.360]   I've seen the costumes. They are quite nice. That whole set is it's quite nice. We've seen shows
[01:50:03.360 --> 01:50:10.240]   there before. They do a good job. They really do a good job. It's quite nice. Um, weird talking
[01:50:10.240 --> 01:50:19.360]   about transitions. Evernote. Oh man. Evernote, which I loved when it first came out. Phil Libben,
[01:50:19.360 --> 01:50:24.480]   who was one of the was the CEO and really responsible. I think we're putting Evernote in the map.
[01:50:24.480 --> 01:50:34.640]   He many years ago, he there's a great article about the history of Evernote on nira.com.
[01:50:34.640 --> 01:50:41.840]   They talk about Stepan Pajikov, who wrote it. A Russian who had, you know, was training computer
[01:50:41.840 --> 01:50:48.000]   science in the Soviet Union and felt like there was a memory hole in communist Russia.
[01:50:48.800 --> 01:50:54.960]   And wanted to write a program once he got out that would help him remember stuff. So he wrote
[01:50:54.960 --> 01:51:01.120]   the first version of Evernote. Matt, Phil Libben, who was also a refugee from the Soviet Union,
[01:51:01.120 --> 01:51:07.200]   spoke Russian. And Phil had been working on something similar called the ribbon. They combined forces
[01:51:07.200 --> 01:51:12.320]   and Evernote, as we know it was born. And I remember first using it, Microsoft had just come out with
[01:51:12.320 --> 01:51:18.560]   one note. And I had this ribbon idea that it was just a continuous ribbon of notes. And I loved it.
[01:51:18.560 --> 01:51:25.200]   And I was a major fan of Evernote for many, many years. I still used a free version.
[01:51:25.200 --> 01:51:30.800]   After Phil left, and by the way, I've asked Jason because Phil likes to be on
[01:51:30.800 --> 01:51:34.160]   Twitter. He's been on Twitter. He said, it's the last time I talked to him, he said,
[01:51:34.160 --> 01:51:37.200]   get me on Twitter again. So we'll get Phil on to talk about this. But
[01:51:37.200 --> 01:51:44.400]   after he left, Evernote went through some tough times. They cut off the free one. They went to
[01:51:44.400 --> 01:51:49.360]   a subscription model. I think nobody wanted to buy there. It was I think really struggling.
[01:51:49.360 --> 01:51:55.440]   Mike, were you an Evernote user? I was and and Reagan in the chat room just said that Phil
[01:51:55.440 --> 01:51:58.880]   is confirmed for Sunday. I don't know if that's true or not. Oh, fantastic. Yeah,
[01:51:58.880 --> 01:52:03.920]   Reagan is Jason Howell. That's our producer. So good. He'll be on Sunday. I've written a lot about
[01:52:03.920 --> 01:52:12.240]   what I don't know. Is he verified? I personally verify him. It's good. That's not your job to do.
[01:52:12.240 --> 01:52:15.600]   No, he is actually verified. Scooter X has verified him. Yes.
[01:52:15.600 --> 01:52:23.520]   But I have used Evernote and I've used a bunch of different services trying to do life logging
[01:52:23.520 --> 01:52:30.320]   because I've always been that spelling idea. Evernote was kind of an odd thing. Everything
[01:52:30.320 --> 01:52:36.160]   about it was theoretically perfect. I loved that they had this paper notes and you
[01:52:36.160 --> 01:52:41.280]   if there was integrated with this stuff and put anything in there. I just never really liked it
[01:52:41.280 --> 01:52:46.320]   very much. I don't really know why. Something about the interface. I don't know what it was.
[01:52:46.320 --> 01:52:51.920]   But but I did use it for a few years. Oh, I was fanatic. In fact, I had my whole life.
[01:52:51.920 --> 01:52:57.360]   Everything was in Evernote. I still use it every every week. And I'm looking back now.
[01:52:57.360 --> 01:53:02.080]   I still have some old notes from previous employers, like some couple scripts that
[01:53:02.080 --> 01:53:07.040]   I stopped to run. It's the archive career in me with a little they had raised a hundred
[01:53:07.040 --> 01:53:13.680]   million dollars in venture capital. But honestly, I think that they were kind of
[01:53:13.680 --> 01:53:18.400]   mismanaged in the last five years. Anyway, the reason we're talking about Evernote,
[01:53:18.400 --> 01:53:24.080]   it has been sold to a company called Bending Spoons. This can't be good.
[01:53:24.080 --> 01:53:34.080]   Bending Spoons is makes the make apps apps that I'm not sure I'm first of all,
[01:53:34.080 --> 01:53:39.760]   their website is really slow. So it's pretty. Apps that I'm not sure I'm familiar with. Maybe you are
[01:53:39.760 --> 01:53:45.840]   splice. What does that sound video editor for iOS and Android? The thing is it's not the spoon
[01:53:45.840 --> 01:53:52.480]   that bends, but you. Yeah. Automatic captions. They just have a lot of print. I mean, obviously,
[01:53:52.480 --> 01:53:58.320]   the design is very good. Speed effects do. But it's all video, nothing like Evernote.
[01:53:58.880 --> 01:54:07.360]   So I'm just thinking this is a fire sale problem. Yeah. Yeah. To live and do. Yeah. He's
[01:54:07.360 --> 01:54:18.080]   that's the name I used it seriously in 2018. Yeah, that's about right for me. Yeah. Yeah.
[01:54:18.080 --> 01:54:26.160]   Or really 2015 actually. Oh, it was just you. Yeah. I'm a. Can I export this stuff or is it like?
[01:54:26.160 --> 01:54:30.240]   Yeah, totally. In fact, I have exported it to many different places.
[01:54:30.240 --> 01:54:38.080]   Tell us how do you do that? There's an export command. And then I moved it. What did I move it to?
[01:54:38.080 --> 01:54:43.040]   I've moved it. I've tried every note taking app in the world. Just move it to drive.
[01:54:43.040 --> 01:54:47.440]   Joplin was one of them. An open source note taker. I think I might have moved it to Joplin.
[01:54:47.440 --> 01:54:52.160]   I think there was a program that read Evernote files. So I think it was a very easy transition
[01:54:52.160 --> 01:54:57.280]   to something. And then I use Notion for a while. Notions in the news. Now they haven't. Well,
[01:54:57.280 --> 01:55:01.680]   we'll talk about that in a second. We'll talk about that. And then Obsidian,
[01:55:01.680 --> 01:55:08.480]   which is what I currently use. I like Obsidian a lot. It's really everything Evernote kind of was.
[01:55:08.480 --> 01:55:14.160]   But a lot of community support and community plugins and stuff. I have a random note here.
[01:55:14.160 --> 01:55:20.880]   Apparently, I'm so weird. Here's my note that says Plains A321, seat 11, window slightly back.
[01:55:20.880 --> 01:55:29.040]   Seat 12, no window. There you go. There you go. There you go. There's simple notes like that.
[01:55:29.040 --> 01:55:33.360]   Ah, bending spoons. Scooter X is telling me. That's why it's not familiar.
[01:55:33.360 --> 01:55:39.520]   Filmic. I didn't even know Filmic was sold. Filmic is an amazing idea. It was about two months ago.
[01:55:39.520 --> 01:55:44.080]   They went subscription. And they made it subscription. Yeah. That's why it sounded.
[01:55:44.080 --> 01:55:47.120]   Yeah, September. Okay. Thank you, Scooter X.
[01:55:48.080 --> 01:55:54.400]   So that's the one app they make that I've heard of. I'm a big fan. I do all the note-taking apps.
[01:55:54.400 --> 01:56:00.320]   I use EMAX org mode. I use day one, which is a journaling program. I've yet to find the perfect
[01:56:00.320 --> 01:56:08.720]   one. Notion is pretty good. Paul Therat uses Notion, which is a kind of web-based block
[01:56:09.600 --> 01:56:15.200]   style note-taking app with some really good features. They've just added AI.
[01:56:15.200 --> 01:56:25.520]   Today we're introducing Notion AI. So the idea is you start something. This is a Notion page.
[01:56:25.520 --> 01:56:31.520]   And you can press the button that says generate posts. So they've written a prompt,
[01:56:31.520 --> 01:56:38.080]   write a blog post introducing Notion's to AI feature. And then it generates a post. I don't
[01:56:38.080 --> 01:56:44.880]   know if it's GPT-3. Then you can keep it, try again or discard it. But look at this one.
[01:56:44.880 --> 01:56:52.480]   Slash brainstorm, brainstorm ideas. And then brainstorm five ways to promote Notion AI, generate.
[01:56:52.480 --> 01:57:00.160]   And then it's going to do that. Now, I have to say co-pilot on GitHub does a very good job in a
[01:57:00.160 --> 01:57:04.160]   constrained, you know, if you it's easier for artificial intelligence to work if you have a
[01:57:04.160 --> 01:57:11.280]   limited environment. So maybe I don't know, I've you have to sign up. I signed up on 32,000
[01:57:11.280 --> 01:57:16.560]   on the list. So I won't get it right away. Look, there's a translate question for you.
[01:57:16.560 --> 01:57:23.840]   You just named off about four different services here on this week in Google. We haven't even
[01:57:23.840 --> 01:57:29.840]   mentioned Google Keep. Why not keep is a great one. Keep is good. I like keep. I love Keep. In fact,
[01:57:30.320 --> 01:57:35.040]   on on Tuesday, Alex Lindsay's pick of the week was Apple's notes also very
[01:57:35.040 --> 01:57:41.360]   Apple notes is great. I use Apple notes. Leo, I hope you don't mind if I crap all over the this
[01:57:41.360 --> 01:57:46.800]   feature where it's like, oh boy, I wrote a piece on this and I'm curious what Jeff thinks about this
[01:57:46.800 --> 01:57:53.920]   idea. But I really think that AI that writes for us should be opposed with every fiber of our being
[01:57:53.920 --> 01:58:02.480]   because writing, writing is not writing. Writing is thinking. Reading writing and thinking are
[01:58:02.480 --> 01:58:08.400]   literacy. And those muscles have to be exercised in words, not just for us to write, but to think
[01:58:08.400 --> 01:58:14.480]   clearly and to know what we think it basically reflects our thoughts back to us so can consider
[01:58:14.480 --> 01:58:20.800]   them remotely so we can go in and change them and tweak them and get to the point where what is on
[01:58:20.800 --> 01:58:26.960]   the page is what we really think and what we really want to communicate. And it's one thing that we
[01:58:26.960 --> 01:58:31.280]   nobody can do right curse of anymore. We've lost all kinds of skills and I'm totally in favor of
[01:58:31.280 --> 01:58:39.200]   losing obsolete skills. But once the AI is writing for us, once the AI is thinking for us and the
[01:58:39.200 --> 01:58:47.200]   ability to think and write and read and all that stuff gets atrophied, it's it's not what you think
[01:58:47.200 --> 01:58:54.560]   people are thinking now in 2022. Well, some people are I think I think that you know, just writing
[01:58:54.560 --> 01:58:59.440]   company emails and and laboring over an email makes you think about what you're saying and what your
[01:58:59.440 --> 01:59:06.960]   position is. And I can slow so Mike, since yes, more authentic. No, no, no, no, see the other one
[01:59:06.960 --> 01:59:13.520]   here, Mike, you're gonna start with Gutenberg. Okay, and we're gonna advance a century and a half.
[01:59:14.160 --> 01:59:18.960]   Where is there a book that I should know, Montaigne? Montaigne, I'm just gonna
[01:59:18.960 --> 01:59:26.720]   the essay tip toe. Yeah. And with the essay, he changed the nature of public conversation and made
[01:59:26.720 --> 01:59:33.760]   writing a prerequisite to be included in it. Show me the need. What? What are you doing? What are you
[01:59:33.760 --> 01:59:47.200]   leaving? I'm not Steve. I taught me this to towing away. Delphily, ensuring the camera.
[01:59:47.200 --> 01:59:54.160]   So when Montaigne invented the essay, yes, writing became a prerequisite to be part of the public
[01:59:54.160 --> 02:00:00.000]   conversation and it stayed that way through time. Yes. But now we have new definitions of literacy.
[02:00:00.000 --> 02:00:05.600]   Right? We have the audio book. Yeah. And when audio came out, the belief was it was going to
[02:00:05.600 --> 02:00:11.680]   obsolete the printed book because suddenly why would you bother reading? Because now you could
[02:00:11.680 --> 02:00:16.560]   it could maybe you could read with your eyes closed. Right? Yeah. And but yet people mocked this.
[02:00:16.560 --> 02:00:23.200]   That's not really reading. You're not reading. I disagree with that. Well, okay, but there's other
[02:00:23.200 --> 02:00:28.080]   definitions of literacy. And so I think that when you go to places, you know, when you have a world of
[02:00:28.560 --> 02:00:36.240]   of emoji and memes and video, these are also ways people express themselves. Video is harder
[02:00:36.240 --> 02:00:40.640]   to do writing in a lot of ways. Right. Simple. Right. Here, which is not this is a lot easier.
[02:00:40.640 --> 02:00:45.920]   But you know, making maybe even a TikTok video has more effort into it and more thought into it,
[02:00:45.920 --> 02:00:50.880]   I could argue. So I think we have to value many forms of literacy. The other last thing I'll say
[02:00:50.880 --> 02:01:00.000]   waiting for the year to come back from the piss war is that languages were not the notion of
[02:01:00.000 --> 02:01:06.320]   literacy, the notion of a formal language of language being a proper dot come to print.
[02:01:06.320 --> 02:01:12.880]   Because before that, you had lots of, okay, now he's not. Is that a slice of pizza?
[02:01:12.880 --> 02:01:15.520]   Gutenberg, you say?
[02:01:18.400 --> 02:01:21.200]   Every time you say Gutenberg, you're supposed to drink not bite.
[02:01:21.200 --> 02:01:29.520]   All right, we can move on.
[02:01:29.520 --> 02:01:38.320]   That was mean, but I do get a nice slice of pizza.
[02:01:38.320 --> 02:01:44.560]   I'll just, I'll just make one point about, about audiobooks.
[02:01:44.560 --> 02:01:49.680]   Audiobooks is storytelling and that's far more ancient form of literacy than writing. And it
[02:01:49.680 --> 02:01:54.640]   goes back to before we were even human, I'm sure. As long as we've had languages, we've had
[02:01:54.640 --> 02:01:59.520]   storytelling, which has been an oral medium. But I'll bet you that nobody listening to this
[02:01:59.520 --> 02:02:07.680]   who took the time to listen to an audiobook that wasn't a pored over by the author and
[02:02:07.680 --> 02:02:10.080]   every sentence considered. Good point. Yes.
[02:02:10.080 --> 02:02:14.000]   And consuming something that's, well, but podcasts are you.
[02:02:14.000 --> 02:02:16.160]   That's a completely different story.
[02:02:16.160 --> 02:02:21.920]   Can you explain that? I didn't quite get that, Mr. Elgin. Say that one more time.
[02:02:21.920 --> 02:02:27.200]   What I'm saying is that the audiobooks are listening to are the result of literate people
[02:02:27.200 --> 02:02:32.720]   who who who labored over every sentence and really thought and considered every point they made.
[02:02:32.720 --> 02:02:37.600]   Otherwise, it wouldn't be worth listening to. And I just think that of all the of all the
[02:02:37.600 --> 02:02:43.760]   obsolete skills that we give up and let AI do it. I've been actually working on a piece for a
[02:02:43.760 --> 02:02:49.200]   long time. I haven't quite finished it yet. But all the things that we're doing because of AI,
[02:02:49.200 --> 02:02:55.440]   if AI was like a malicious actor and was plotting to overtake humanity,
[02:02:55.440 --> 02:03:00.240]   this would be, it's not. It's a ridiculous notion. But if it was, this would be a great
[02:03:00.240 --> 02:03:04.800]   part of the plot, right? You're drinking scotch out of the bottle.
[02:03:04.800 --> 02:03:11.280]   You gave me the worst scotch in the whole cupboard.
[02:03:11.280 --> 02:03:16.000]   This is the, no wonder it's the only one we have. This is the synthetic scotch that is.
[02:03:16.000 --> 02:03:17.040]   Oh, yeah. That one was.
[02:03:17.040 --> 02:03:22.080]   Amy, that does like synthetic writing, Leo. That's, that's what has the AI one.
[02:03:22.080 --> 02:03:26.720]   That was what it has. This is this scotch tastes like synthetic
[02:03:26.720 --> 02:03:30.320]   racism. It was so bad. Oh gosh. It was so bad.
[02:03:30.880 --> 02:03:36.720]   Glyph is either smell bad. It did. It's, it's, so the idea was if you came up with all the right
[02:03:36.720 --> 02:03:44.000]   esters and, and overtones and components of an aged whiskey by analyzing it chemically,
[02:03:44.000 --> 02:03:49.440]   you could make a instant aged whiskey. So this is like that made but never aged.
[02:03:49.440 --> 02:03:55.840]   And it's exactly like GP. Is she embarrassing it, Amy? No, she thinking it was good? No, I don't
[02:03:55.840 --> 02:04:03.280]   think so. I don't know. I'm, I'm a big fan of reality. Yeah. No, you make a really, really good
[02:04:03.280 --> 02:04:08.240]   point. You lose that capability if you don't exercise it. And the most important part is not
[02:04:08.240 --> 02:04:12.640]   putting words on the page. The most important part is thinking. Yeah. Exactly. The point is not
[02:04:12.640 --> 02:04:17.840]   to put some words out there. The point is to express your real thoughts. And I think we shouldn't
[02:04:17.840 --> 02:04:22.080]   hand that over to you. I love you. I think that's exactly what about, what about, what about
[02:04:22.080 --> 02:04:25.520]   illustration? I can't draw worth it. Same thing. But now there are AI.
[02:04:25.520 --> 02:04:36.880]   It's an interesting point. And I've lately been obsessing about synthetic media and all its forms.
[02:04:36.880 --> 02:04:40.800]   And it's a really, really interesting question. All this, all this text driven AI stuff,
[02:04:40.800 --> 02:04:45.360]   Google now has a video version of that. It's coming and it's, we're going to really have to
[02:04:45.360 --> 02:04:49.760]   grapple with it. And I'm not sure what I think about it yet. Jeff, I sure love playing with it.
[02:04:49.760 --> 02:04:52.160]   It's almost an addiction to play with somebody. It's so much fun.
[02:04:52.160 --> 02:04:58.000]   Yeah. Oh, I put a story in the rundown. Oh, yeah. So look at this. This is Casey Newton's
[02:04:58.000 --> 02:05:02.240]   platformer now. That's all he does for a illustration. That's what I do too. Yeah.
[02:05:02.240 --> 02:05:07.600]   It's it's it's great. It looks good. It's like you had a rundown about
[02:05:07.600 --> 02:05:11.680]   foreign art about copyright and this stuff and how it's just kind of, it's just confusing the
[02:05:11.680 --> 02:05:17.200]   heck out of everybody. Nobody knows exactly what to say because this stuff wouldn't look like it
[02:05:17.200 --> 02:05:25.040]   as if they hadn't scanned in derivatives. Real art from real people who's now who are now
[02:05:25.040 --> 02:05:29.840]   disenfranchised by the fact that this machine can make something like it. Not as the way the way
[02:05:29.840 --> 02:05:35.440]   plagiarism works in language is not the content. Of course, it's the it's the expression. It's the
[02:05:35.440 --> 02:05:40.960]   way you craft the language that can be stolen illegally. And that's essentially what they're
[02:05:40.960 --> 02:05:46.960]   doing. They're basically applying an artist's style to whatever. And that's kind of the equivalent
[02:05:46.960 --> 02:05:52.080]   of the expression part, right? As opposed to the content part. It's not about a picture of Elon Musk.
[02:05:52.080 --> 02:05:55.920]   It's about in the style of so-and-so artist. Yeah. So it's a really interesting question.
[02:05:55.920 --> 02:06:03.920]   Hey, this is this is a tweet from Matthew Garrett who says you can now, if you can figure out what
[02:06:03.920 --> 02:06:10.640]   somebody's phone number is, turn off their two-factor authentication by sending a text message saying
[02:06:10.640 --> 02:06:18.400]   stop from that number. And it will turn off two FA. So that's good or bad? Bad. That's bad.
[02:06:18.400 --> 02:06:24.560]   That's really bad. It's really bad, especially with all of these Simjack and stuff that used to
[02:06:24.560 --> 02:06:32.640]   happen. Now you can just spoof the phone number, send a stop command. And then if, you know,
[02:06:32.640 --> 02:06:37.360]   because so many Twitter passwords are terrible and it's easy to brute force those. Now you really,
[02:06:37.360 --> 02:06:42.480]   oh man. Really got a problem. Distincts. I got that by the way from a wonderful
[02:06:42.480 --> 02:06:50.320]   version of Molly White's Web3 is going just great. She's the timeline thing that she's created,
[02:06:50.320 --> 02:06:55.120]   can be used by anybody. It's open source. So somebody's done. Twitter is going great,
[02:06:55.120 --> 02:07:02.640]   which is now collecting all the Twitter stories. So it's just if you want to keep track,
[02:07:02.640 --> 02:07:09.520]   Web3 is going just as great as good. And then Twitter is going great.com.
[02:07:09.520 --> 02:07:10.400]   I love it.
[02:07:10.400 --> 02:07:18.240]   Based on, and he even credits at the bottom. He credits Molly White's static timeline generator,
[02:07:18.240 --> 02:07:23.840]   which is this is a great example of open source. It's an open source project anybody can clone
[02:07:23.840 --> 02:07:31.040]   and install for anything. Very cool. Even cats. Jeff, so you want to talk about this copyright
[02:07:31.040 --> 02:07:37.440]   story? No, no, I think it's just interesting that it's both input and output, right? Who owns the
[02:07:37.440 --> 02:07:44.160]   output? Who has the rights to things? Does the AI do you give away? But also the input side of
[02:07:44.160 --> 02:07:51.840]   sharing by looking at all those images. There's no way to track back as to what inspired the AI.
[02:07:51.840 --> 02:07:56.320]   You're not going to know. You're never going to know what it pulled out and what inspired it.
[02:07:56.320 --> 02:08:00.560]   So you're not going to share revenue or anything. Copyright is just outmoded for the same.
[02:08:00.560 --> 02:08:07.680]   Yep. A couple of real quick stories. Birds are changing their song due to urbanization.
[02:08:07.680 --> 02:08:13.440]   This is a research that comes. Did you get that story from about 1843?
[02:08:13.440 --> 02:08:23.520]   Cities are you here on top of it? Birds sing. No, this is research coming out of Costa Rica
[02:08:25.360 --> 02:08:36.000]   that they took recorded a lot of songs from house rins. Actually,
[02:08:36.000 --> 02:08:43.600]   first it was Blackbirds. I'm sorry, Blackbirds scientific name, unfortunately, is Turdis Marola.
[02:08:43.600 --> 02:08:51.680]   Which would be used as little boys. Yeah. Then, well, you like that. Then you'll love the great
[02:08:51.680 --> 02:08:58.720]   tits, Paris major, and Rufus collared sparrows. I'm not going to bother. They all sing at higher
[02:08:58.720 --> 02:09:03.280]   pitches with higher minimum frequencies in urban environments. And they have to go to the urban
[02:09:03.280 --> 02:09:07.120]   environments because their food supply tends to be close to populations. That's exactly right.
[02:09:07.120 --> 02:09:14.720]   Yep. This is similar to Jeff's point about what year is this. But, you know, famous case with
[02:09:14.720 --> 02:09:21.440]   Darwin in London when they had all the coal fires in the 20th century, the moths, which were normally
[02:09:21.440 --> 02:09:27.440]   white to camouflage on white trees. They turn black. They turn black from camouflage on
[02:09:27.440 --> 02:09:34.400]   black trees that were blackened by the coal fires. And so, this is a history.
[02:09:34.400 --> 02:09:40.320]   Well, here's the future. We're going to the moon, kids. Oh, wait a minute. That's history.
[02:09:40.320 --> 02:09:49.760]   Artemis launched successfully last night, 2 AM Eastern time. Did you, John, you were up to
[02:09:49.760 --> 02:09:57.280]   watch the launch, I'm sure. Yeah. I turned it on about, I think it was about 945 Pacific.
[02:09:57.280 --> 02:10:01.680]   And right when I turned it on, they started talking about a delay. I turned it off.
[02:10:01.680 --> 02:10:05.120]   Yeah. I think this thing was never going to happen again. Yeah. In fact,
[02:10:05.120 --> 02:10:10.080]   we're starting to, they put a lot of cameras on this. And we're starting to get the first
[02:10:10.080 --> 02:10:18.320]   pictures back, including the first time since 1972 or 6, I want to say, a picture of the big blue
[02:10:18.880 --> 02:10:26.800]   marble that we live on Earthrise. We haven't seen a picture of Earthrise from a manned vehicle
[02:10:26.800 --> 02:10:34.080]   since the 70s. And if you're, where is Artemis now on its way to the moon?
[02:10:34.080 --> 02:10:37.280]   That's on the waist with with allis crandam.
[02:10:37.280 --> 02:10:44.720]   To the moon with amazing high res cameras. That's awesome. And that's one of the things
[02:10:44.720 --> 02:10:49.600]   is different. 16 cameras. It also has a satellite on it that has a camera.
[02:10:49.600 --> 02:10:56.560]   To show me one of the, yeah. Go ahead. I'm sorry. One of the cool things is it's the most
[02:10:56.560 --> 02:11:04.800]   powerful rocket in history, which is kind of cool. Yeah. Elon. Yeah. Well, yeah, this one,
[02:11:04.800 --> 02:11:10.080]   it was not Elon. It was a, I think, Boeing and the NASA doing this one. And actually,
[02:11:10.080 --> 02:11:14.960]   I was some concern. I would never get off the ground because it was one of those things
[02:11:14.960 --> 02:11:20.480]   where Congress mandated that every piece had to be from a different state. And it was kind of not,
[02:11:20.480 --> 02:11:26.240]   you make things move along. Yeah, it went into Congress, but they, but they got off the ground.
[02:11:26.240 --> 02:11:31.920]   And apparently a beautiful night launch. If you're lucky enough to see mannequins aboard.
[02:11:31.920 --> 02:11:35.680]   Yeah, there's no, it's not manned, but it is a precursor to a manned mission.
[02:11:35.680 --> 02:11:39.920]   Was chamor be up to watch? He's not in the room anymore. Oh, he's not even stepped out.
[02:11:39.920 --> 02:11:44.560]   He stepped out. He's been a bit of a running joke on our podcast at Ayers every Friday,
[02:11:44.560 --> 02:11:49.120]   ain't this week in space hosted by Mr. Rod? They got bets over with. Right. You know, like,
[02:11:49.120 --> 02:11:54.240]   well, is this thing going to launch at some point? So they've been betting over Mr. Tart Mallet's
[02:11:54.240 --> 02:12:00.640]   chair. And I guess now we're going to go up there. I think up to the Transluder injection burn,
[02:12:00.640 --> 02:12:09.520]   which he stayed in 1230. Wow. Yeah. Wow. Just some beautiful pictures. Unfortunately,
[02:12:10.080 --> 02:12:18.240]   they're on Twitter, but really, I mean, this is not science fiction. This is actual video.
[02:12:18.240 --> 02:12:24.240]   Is that really NASA? You know, you never know. Oh, you're not verified. If Mario flips us off
[02:12:24.240 --> 02:12:31.920]   in a minute, well, no, this is the moon, the Earthrise. Incredible, cool, beautiful images.
[02:12:31.920 --> 02:12:34.560]   As it goes to the moon, we'll have beautiful images of the moon as well. Right.
[02:12:34.560 --> 02:12:39.920]   Stable. That's stable diffusion. Come on. That's not real. That's really what happens.
[02:12:39.920 --> 02:12:48.880]   Anything. Anything. Let's do a quick Google change. Like we're getting, we're running long,
[02:12:48.880 --> 02:12:53.440]   and I want to get everything in here. We're running long. What a shock.
[02:12:53.440 --> 02:12:59.600]   It's a quick law. It's a quick law. There's nothing in it.
[02:13:00.560 --> 02:13:06.960]   Google Wallet is finally on your Fitbit Smartwatch, which is a big deal. It hasn't been there yet.
[02:13:06.960 --> 02:13:13.920]   Fitbit Sense and Versa4. It's also expanding to more countries. So that's good. Google
[02:13:13.920 --> 02:13:18.640]   Bot Fitbit, you may remember a few years ago, and now they're adding features that were only on
[02:13:18.640 --> 02:13:24.720]   the Android devices. They're adding those. I think this is worth, and I'd be very curious if
[02:13:24.720 --> 02:13:33.280]   anybody in our audience has signed up for this yet. Android Auto, now with a new beta program that
[02:13:33.280 --> 02:13:38.320]   looks fantastic. I've seen images from people you've got split screen. You have a lot of new
[02:13:38.320 --> 02:13:45.680]   features. It's a beta, so you have to sign up for it. But apparently Google has opened a few more
[02:13:45.680 --> 02:13:52.080]   slots for the beta program. This might be one where you run over to the Android Auto Beta testing
[02:13:52.080 --> 02:14:02.800]   page and push the box. It says become a tester. I don't know. No? I don't know. It's not driving
[02:14:02.800 --> 02:14:09.760]   your car, sir. It's just the software. It's the music and the maps and stuff. My car is really...
[02:14:09.760 --> 02:14:15.760]   I forgot my Mazda. I had to have it put in after the fact.
[02:14:16.800 --> 02:14:21.760]   Oh, I thought that was a thing you were looking for. That's what I was, and I finally gave up,
[02:14:21.760 --> 02:14:24.880]   and then I got managed to get it in. So it's in the car, but boy is it wonky.
[02:14:24.880 --> 02:14:31.520]   I just went to the App Store, and unfortunately it says, "Thanks for your interest."
[02:14:31.520 --> 02:14:35.760]   But we've reached the maximum number of testers. So it was open this morning, but...
[02:14:35.760 --> 02:14:37.440]   Thanks for your interest, but we've Googled it.
[02:14:37.440 --> 02:14:42.400]   We're not going to end it out. We've already killed it all. No, no, no.
[02:14:43.840 --> 02:14:47.920]   Actually, I think that's a big part of Google's going forward. Google's strategy is to get in the
[02:14:47.920 --> 02:14:51.920]   car. They're already making Android for automakers. Many of them are using it.
[02:14:51.920 --> 02:14:56.320]   Well, I'm reading right now to my mind, absolutely dreadful. I'm screaming about it.
[02:14:56.320 --> 02:15:02.400]   Oh, Shoshana Zuboff's the age. Everything is capitalist.
[02:15:02.400 --> 02:15:06.640]   Spiracy and everything is also... This is all part of Google's plan to know where you are every
[02:15:06.640 --> 02:15:16.320]   minute and extract the smoke of your exhaust. Google Fi gives you a year of YouTube premium.
[02:15:16.320 --> 02:15:22.240]   That's cool. Yeah. If you sign up for their unlimited plus plan...
[02:15:22.240 --> 02:15:25.200]   What was that cost these days? Wow.
[02:15:25.200 --> 02:15:32.320]   Let's see. $65 a month for one person, $40 a month for families per long.
[02:15:32.320 --> 02:15:38.160]   It's pretty expensive. It's like a real insult. Real phone, yeah.
[02:15:38.160 --> 02:15:41.840]   I still pay, I think, the 20 bucks for voice and text plus...
[02:15:41.840 --> 02:15:47.120]   Was it 10 bucks a gigabyte? I can't remember. And then it's capped after 6 gigabytes. It
[02:15:47.120 --> 02:15:54.080]   probably ends up being the same. And Google has rolled out a VPN for Mac and Windows,
[02:15:54.080 --> 02:15:58.400]   Google One, if you're a Google One subscriber, although it's both a run through.
[02:15:58.960 --> 02:16:04.160]   To point it out, the picture of Google One running on Windows is from 2015.
[02:16:04.160 --> 02:16:11.200]   So obviously they just superimposed this on a screenshot they had lying around.
[02:16:11.200 --> 02:16:16.160]   Wow. But if you're already paying for Google One, I think a lot of us are. I am.
[02:16:16.160 --> 02:16:21.600]   I meant to use their stir gifts in an email. This is the bizarre thing about Google and VPN.
[02:16:21.600 --> 02:16:27.520]   So Google does all this work to optimize the performance of its browser,
[02:16:27.520 --> 02:16:34.800]   of search itself, of all these things. It has devices that optimize performance.
[02:16:34.800 --> 02:16:40.960]   And then it pushes VPNs, sells VPNs, it builds VPNs into its phones. It's super pro VPN.
[02:16:40.960 --> 02:16:46.800]   But then if you actually use Google Search with a VPN, it stops you in your tracks,
[02:16:46.800 --> 02:16:51.680]   makes you say, am I'm human, you have to identify all the traffic lights on it, identify all the
[02:16:51.680 --> 02:16:56.240]   bicycles and you have to go in. And there's four or five or six different things you have to identify.
[02:16:56.240 --> 02:17:01.120]   What's the point of optimizing performance of all these things that they're going to stop you
[02:17:01.120 --> 02:17:05.920]   in their tracks and you have to donate a minute of your time in the middle of your day to Google's
[02:17:05.920 --> 02:17:12.400]   of image recognition system through CAPTCHA. It makes no sense. It's like they punish you for
[02:17:12.400 --> 02:17:20.880]   using a VPN. You want us to use VPNs or not? Someone else's VPN. Maybe if it's theirs,
[02:17:20.880 --> 02:17:25.200]   you won't have to do it. What do you think? I don't know. Because I mean,
[02:17:25.200 --> 02:17:33.680]   I use Express VPN and five times a day like, oh, are you really human? There's unusual activity.
[02:17:33.680 --> 02:17:38.640]   Yeah. And it really bothers me. I'd be very curious to see if Google, I'll turn on Google one and see.
[02:17:39.440 --> 02:17:43.040]   Yeah, because I bet it doesn't. And then you've got any competitive market.
[02:17:43.040 --> 02:17:49.040]   If you watch Europe, when you need them, watch the EU jump. Yeah. Yeah.
[02:17:49.040 --> 02:17:50.720]   Let's see.
[02:17:50.720 --> 02:18:00.640]   And that's Google change. No, and that's it. That's it. That's you're right. Thank you,
[02:18:00.640 --> 02:18:03.360]   Ann. I'm going to finish the old man sentences.
[02:18:05.840 --> 02:18:10.480]   Where am I? He's in a pizza coma right now. Facebook, is this a tempest in a teapot? Facebook
[02:18:10.480 --> 02:18:17.840]   apparently has a rule that they don't fact check politicians. Now that Trump is running for office
[02:18:17.840 --> 02:18:25.600]   in 2024, two years from now, they're no longer fact checking check. Now, Trump is not on Facebook,
[02:18:25.600 --> 02:18:32.560]   but anything that he says that is in, I presume, I don't know what is this. If he's not on Facebook,
[02:18:32.560 --> 02:18:38.400]   does it matter? Well, Trump is there. Plus, if I quote him there, they won't they will fact check
[02:18:38.400 --> 02:18:43.920]   him. Oh, interesting. I'm getting a little fed up about the special treatment the politicians get
[02:18:43.920 --> 02:18:49.360]   on all things, especially criminal justice system. If an unnamed politician has broken a
[02:18:49.360 --> 02:18:54.160]   bunch of laws, the Department of Justice should not be sitting there going, well, we can't indict
[02:18:54.160 --> 02:18:58.240]   them now because they're running for office or Facebook says we can't fact check them because
[02:18:58.240 --> 02:19:02.480]   they're running for, who cares if they're running for office in a democracy, the people who
[02:19:02.480 --> 02:19:07.200]   are running for office are supposed to be everyday citizens, just like the rest of us. And I'm getting
[02:19:07.200 --> 02:19:12.080]   fed up with a special treatment. I don't understand why they should be the first factor to set the
[02:19:12.080 --> 02:19:14.400]   rules exactly. Good point.
[02:19:14.400 --> 02:19:20.720]   Met also plans on considering allowing Trump back on the platform as soon as January,
[02:19:20.720 --> 02:19:25.440]   because that'll be two years from his initial ban January 6th, the course.
[02:19:26.640 --> 02:19:32.160]   So he may be back anyway in more than more ways than one. Did they specify like why they're
[02:19:32.160 --> 02:19:36.320]   considering it? Yeah, because that was because the oversight board oversight board sits. Yeah,
[02:19:36.320 --> 02:19:40.480]   they said you can't do a permanent ban. In definition. Although they said you couldn't do
[02:19:40.480 --> 02:19:45.440]   it in definite. Right. So you have to say, I'm sure he's learned his lesson. Yeah, it's clear
[02:19:45.440 --> 02:19:51.520]   after watching him last night. So the senator from Maine. I mean, actually, actually, it was
[02:19:51.520 --> 02:19:56.880]   better than usual. He only told 20 lives according to CNN. I don't know. They cut away before he
[02:19:56.880 --> 02:20:01.040]   started to really get going. Even Fox cut away before he really started going. That's because it
[02:20:01.040 --> 02:20:08.000]   was boring. That could be false. Out of sync in the RSC says, isn't it journalist jobs to fact check
[02:20:08.000 --> 02:20:13.360]   them? And I get where you're coming from. But also I say a journalist does that on one of these
[02:20:13.360 --> 02:20:19.520]   platforms. And I've seen where the platform comes after the journalist is like, wait a minute,
[02:20:19.520 --> 02:20:27.520]   this is this is misinformation. Yeah, I mean, if most people get their news from social networks,
[02:20:27.520 --> 02:20:30.320]   and the social networks refuse to do the job journalists do,
[02:20:30.320 --> 02:20:37.680]   you got a problem. My only point is not, you know, whether whether we decide to fact check or not
[02:20:37.680 --> 02:20:41.760]   fact check on social medians and all that stuff, that's a separate conversation. But whatever the
[02:20:41.760 --> 02:20:46.320]   rules should apply to everyone. Yeah, politician, not a politician, journalist, not a journalist.
[02:20:47.280 --> 02:20:51.760]   The rules should be the rules. And I don't think politicians of all people should get special
[02:20:51.760 --> 02:20:57.120]   treatment. That's all. Yeah. All right, I'm going to do a final ad and get your picks of the week.
[02:20:57.120 --> 02:21:03.600]   And we'll get you out of here. So great to have you visiting us from Mexico City. Mr. Mike Elgin.
[02:21:03.600 --> 02:21:07.920]   So how are you going to be there for a while? What's the what's the current
[02:21:07.920 --> 02:21:13.040]   gastron? I think we're here about a month or so. And then we're going to go to California for a
[02:21:13.040 --> 02:21:19.840]   few days and then back to Mexico. So back to Oaxaca, we're going to do a December Oaxaca experience.
[02:21:19.840 --> 02:21:27.520]   And yeah, it's, yeah, Oaxaca is sold out. Mexico City is sold out for April. The next,
[02:21:27.520 --> 02:21:31.200]   wow, we're doing in Mexico is in November of next year, actually.
[02:21:31.200 --> 02:21:36.880]   Wow. So you want to jump on that if you want to do a Mexico thing. But yeah, we're spending,
[02:21:36.880 --> 02:21:43.200]   you know, it's great now that COVID is more or less over. It's great to be spending a lot of
[02:21:43.200 --> 02:21:47.840]   more time in Mexico. One of the great things about these and one of the reasons you sell out so fast
[02:21:47.840 --> 02:21:55.760]   is it's a small group. It's Mike and Amira, his wife who knows everybody in these towns in these,
[02:21:55.760 --> 02:22:01.520]   she's like the local expert knows every chef knows every vittener knows every men's cowmaker in the
[02:22:01.520 --> 02:22:06.640]   area. And so they take you around. But it's a small group. Our group was what about 10 people,
[02:22:06.640 --> 02:22:13.680]   something like that? Yeah, yeah, typically the size. Well, that one, that one went out of way
[02:22:13.680 --> 02:22:18.000]   out of proportion because people that we really love like you and Lisa said, Hey, I like to do
[02:22:18.000 --> 02:22:24.080]   it. And we're like, okay, six or so and it's a kept adding. But but yeah, they're typically,
[02:22:24.080 --> 02:22:31.360]   you know, small, intimate groups of very cool people always. And Amira knows everybody. And so
[02:22:31.440 --> 02:22:37.840]   we're doing another Wahawk experience in December. We're doing Mexico City in April, like I said.
[02:22:37.840 --> 02:22:44.000]   And these are going to be completely different from the ones that you did, because there's so much
[02:22:44.000 --> 02:22:49.680]   change. There's so many new things to explore. So it's really a lot of fun. But we have the next
[02:22:49.680 --> 02:22:56.160]   one that's available is in the Proseco Hills, Veneto, Venice and Proseco Hills in Italy. And that's in
[02:22:56.160 --> 02:23:02.240]   May, and of course, Provence. But these are filling up pretty fast too nowadays. People are traveling
[02:23:02.240 --> 02:23:08.320]   with a vengeance. Do you get a lot of return? I guess you do. Return people like who come back.
[02:23:08.320 --> 02:23:13.920]   We were having returned people like there's several people who've done all of them. But now
[02:23:13.920 --> 02:23:18.880]   we're having people repeat the same place. Oh, interesting. Lots of people. So for example,
[02:23:18.880 --> 02:23:24.320]   in in in both Wahawk and Mexico City, we're having people who've done Wahaka and Mexico City
[02:23:24.320 --> 02:23:31.360]   before and all the places. And so it's funny because Amira does when there is a person who's
[02:23:31.360 --> 02:23:36.400]   repeating the place, she kind of shocks them with like the whole thing is different.
[02:23:36.400 --> 02:23:41.600]   It's totally different. Yeah. New wineries, new shafts of meat, like all these different things.
[02:23:41.600 --> 02:23:46.560]   And so it's really fun. But it's so cool. I really invite everybody to join us.
[02:23:46.560 --> 02:23:51.520]   Aunt Pruitt hands on photography. And I see you planned a lot of good stuff for our club members.
[02:23:51.520 --> 02:23:57.200]   Yeah, we've got some good tomorrow coming up. Mr. Jonathan Bennett has an AMA. You may know
[02:23:57.200 --> 02:24:04.160]   him from our show Floss Weekly on Wednesdays. And he also hosts the untitled Linux show,
[02:24:04.160 --> 02:24:11.120]   which has the best name of any show on our network. I love that guy. He is so smart.
[02:24:11.120 --> 02:24:15.920]   He had his hair out of control on the last loss. That was pretty funny. He fixed it this week.
[02:24:15.920 --> 02:24:19.920]   Did he? All right. I put in air quotes. I hope he doesn't fix it for tomorrow.
[02:24:19.920 --> 02:24:23.520]   9am tomorrow. Glen Fleischman will be on Thursday, December 15th.
[02:24:23.520 --> 02:24:27.520]   Oh, you're welcome. You're welcome. You're welcome. Yeah, we'll have a fireside.
[02:24:27.520 --> 02:24:35.760]   He's a great. Yep. And Stacy's book club is next month. And no, it's January.
[02:24:35.760 --> 02:24:40.800]   That's to give you time to read. Although I've already read it. Project Hail Mary.
[02:24:40.800 --> 02:24:45.520]   Will you join us for this? I will. I love Andy. We're totally hated the last book.
[02:24:45.520 --> 02:24:47.680]   Yeah, I refuse to join about the last one.
[02:24:48.320 --> 02:24:52.240]   I shouldn't really. You shouldn't not go if you don't like the book.
[02:24:52.240 --> 02:24:54.640]   That was all more of the reason you should have been.
[02:24:54.640 --> 02:24:57.440]   I didn't even want to read it though. That's a problem. I didn't want to finish it.
[02:24:57.440 --> 02:25:02.480]   I did finish Project Hail Mary. We, of course, interviewed Andy Weir on triangulation.
[02:25:02.480 --> 02:25:06.320]   I can't wait. That'll be fun. Maybe we get Andy's show up.
[02:25:06.320 --> 02:25:11.200]   I'll put out put in a call. He just he and his wife had a baby a couple of months ago.
[02:25:11.200 --> 02:25:16.000]   We were actually asking to be on and he couldn't. But I think by now
[02:25:16.000 --> 02:25:21.600]   the way to get on. It's like, please save me.
[02:25:21.600 --> 02:25:25.920]   And of course, Jeff Jarvis, buzzmachine.com's the blog,
[02:25:25.920 --> 02:25:30.880]   Mastodon.socialsass/Jeff Jarvis. Are you feeling a little better on Mastodon now?
[02:25:30.880 --> 02:25:34.560]   Like you like feeling good. You like the people you like the conversation?
[02:25:34.560 --> 02:25:37.200]   I am. I am. And the conversations are substantive.
[02:25:37.200 --> 02:25:41.440]   Oh, they're still about Mastodon a lot. That's going to get a little fade away.
[02:25:41.440 --> 02:25:45.520]   But no, I'm really enjoying it. And I think it's reached a critical mass for me.
[02:25:46.320 --> 02:25:48.880]   I especially now that Don Trump is on.
[02:25:48.880 --> 02:25:52.640]   Do you think that's a parody account? It's not verified.
[02:25:52.640 --> 02:25:55.600]   Well, does he know, well, don't me?
[02:25:55.600 --> 02:26:01.600]   Too shay. Oh, he's ready to his diary. That's what it is.
[02:26:01.600 --> 02:26:06.800]   Donnie's diary. Well, George Tk is also also on.
[02:26:06.800 --> 02:26:07.680]   I hope it's real.
[02:26:07.680 --> 02:26:10.400]   We should work, but it's not. I don't think it is.
[02:26:10.400 --> 02:26:12.960]   You don't pick something? No, sad to say.
[02:26:14.080 --> 02:26:21.360]   Yeah, we love the Mastodon. Somebody's been asking me for a special icon for club
[02:26:21.360 --> 02:26:25.040]   Twit members. And I'll do that tonight. Maybe I'll have a discord shaped icon with the
[02:26:25.040 --> 02:26:27.440]   Twitter and something like that. I'll figure out something.
[02:26:27.440 --> 02:26:32.080]   So if you're a club Twit member and you're in our Mastodon instance, you can say, you
[02:26:32.080 --> 02:26:34.480]   know, you could show your colors. So that's really cool.
[02:26:34.480 --> 02:26:38.480]   Yeah, we do have a couple of custom little badge custom icons, including a
[02:26:38.480 --> 02:26:44.080]   street gauge. Yeah, yeah. Join join the gang. Twit.s. That social is free to join. I do
[02:26:44.080 --> 02:26:48.160]   approve everybody who joins just to make sure we keep it nice and family friendly.
[02:26:48.160 --> 02:26:54.960]   I'm pretty aggressive about banning instances that are have hate speech or racism.
[02:26:54.960 --> 02:27:00.960]   You know, the usual bad stuff fitted blocks. I do not block journalists, however, Jeff,
[02:27:00.960 --> 02:27:04.880]   you'll be glad to know those are. Those are safe. Those are allowed. Even if I disagree
[02:27:04.880 --> 02:27:08.480]   with their point of view, just the ones with the last name Jarvis in the first name.
[02:27:08.480 --> 02:27:14.240]   Oh, yeah. I was watching that guy. Yeah. Yeah. Yeah. I wonder if hashtag Gutenberg is trending.
[02:27:14.240 --> 02:27:17.760]   I'll be in the minute now.
[02:27:17.760 --> 02:27:24.960]   Our show today is brought to you by those great folks and on logic. I got a couple of these
[02:27:24.960 --> 02:27:30.400]   really sweet on logic computers. And you know, I put my pizza slice on it,
[02:27:30.400 --> 02:27:34.720]   but you know, I don't think that's a problem. These things are made for difficult environments.
[02:27:34.720 --> 02:27:40.880]   And, you know, a little grease. No big deal on logic. You know, this is what's interesting.
[02:27:40.880 --> 02:27:45.120]   This is the transformation that's really happened. When I first started talking about technology,
[02:27:45.120 --> 02:27:50.720]   it was really a big computer on your desk. We didn't even have phones. Now computing is moving
[02:27:50.720 --> 02:27:55.840]   to the edge. Computers are everywhere. And often in hostile environments that, you know,
[02:27:55.840 --> 02:28:01.920]   your normal desktop PC doesn't belong in. There is an entire hidden world of computing
[02:28:01.920 --> 02:28:08.000]   all around us, bringing smart cities to life, driving, driving sustainable agriculture,
[02:28:08.000 --> 02:28:12.720]   revolutionizing the way virtually everything is made in factories. And that's where you're
[02:28:12.720 --> 02:28:19.120]   going to find these on logic, distinctive orange industrial and embedded computers.
[02:28:19.120 --> 02:28:22.960]   On logic is the first choice of industrial computing for innovators around the world who need
[02:28:22.960 --> 02:28:28.080]   computing power that could survive and thrive where traditional hardware might fail.
[02:28:28.080 --> 02:28:35.760]   They design on logic. I mean, these are solid, beautifully made computers. You know,
[02:28:35.760 --> 02:28:39.920]   they're custom made to the environment they're going to be in. This one, for instance, has no
[02:28:39.920 --> 02:28:47.120]   fans, no ports, because no dust. It's perfect for agriculture on, you know, on an area where
[02:28:47.120 --> 02:28:53.680]   you've got lots of dust in the air, maybe an industrial factory, that kind of thing.
[02:28:53.680 --> 02:28:58.080]   But they have high end processors. You can get, I mean, you really customize it out the way you want.
[02:28:58.080 --> 02:29:02.640]   On logic designs and creates computing solutions that fit in the palm of your hand while powering
[02:29:02.640 --> 02:29:08.960]   everything from advanced robotics and AI to manufacturing automation and digital media solutions,
[02:29:08.960 --> 02:29:14.880]   smart agriculture technologies. On logic computers are passively cooled and ventless,
[02:29:15.680 --> 02:29:19.360]   protecting internal components from dust and other airborne contaminants.
[02:29:19.360 --> 02:29:24.800]   And because they're completely solid state, no moving parts, they protect against shock and
[02:29:24.800 --> 02:29:32.480]   vibration. Other designs feature systems that are protected from extreme temperatures or radio
[02:29:32.480 --> 02:29:39.440]   interference. There's designs for every hostile environment, including Leo's desk and a little
[02:29:39.440 --> 02:29:44.880]   bit of coffee and pizza. The team, the team in on logic truly cares about creating right fit
[02:29:44.880 --> 02:29:50.560]   solutions tailored specifically to solve unique technology challenges on logic partners with
[02:29:50.560 --> 02:29:58.000]   leading software companies. I'll give you an example. AWS has approved a line of AWS IoT Greengrass
[02:29:58.000 --> 02:30:03.440]   compatible computers. So they've been vetted by AWS. So you know now that it's going to work
[02:30:03.440 --> 02:30:08.800]   right out of the box. If you're doing Greengrass, this is a great solution for rapid evaluation
[02:30:08.800 --> 02:30:13.040]   and deployment of edge computing. If you need a computing solution that can easily be configured
[02:30:13.040 --> 02:30:19.040]   to your particular needs, supported by industry experts who really want you to succeed, you know,
[02:30:19.040 --> 02:30:24.160]   they're just a phone call website chat or email away. And don't worry about supply chain. They
[02:30:24.160 --> 02:30:30.400]   can get these to you fast. The team at on logic is there to help. If you'd rather do it yourself,
[02:30:30.400 --> 02:30:34.480]   you could do it on the website on logic is easy to use website gives you everything you need to
[02:30:34.480 --> 02:30:39.520]   configure and order your next industrial computing device quickly and easily right online. I know
[02:30:39.520 --> 02:30:44.080]   some people want to get on the phone and talk it out. Some people want to do it online. All in
[02:30:44.080 --> 02:30:49.920]   stock online orders are custom built though. After you push the send button, they build it then,
[02:30:49.920 --> 02:30:54.240]   they test them thoroughly and they still get them out to you in as little as five days.
[02:30:54.240 --> 02:31:00.880]   When you need a custom configured industrial computer edge server panel PC delivered quickly,
[02:31:00.880 --> 02:31:08.560]   first place to go on logic.com/twit to get started to learn more about on logic's 30 day risk free
[02:31:08.560 --> 02:31:15.920]   hardware trial. Connect with their experts or visit on logic.com/twit. O-N-L-O-G-I-C on logic.
[02:31:15.920 --> 02:31:26.080]   Dot com slash twit industrial computers engineered to last on logic. Thank you on logic for
[02:31:26.080 --> 02:31:32.320]   support and twig. Everybody use that address now on logic.com/twit. So you know you saw it here.
[02:31:32.320 --> 02:31:36.640]   I'm just going to put it right next to my pizza put the slice of pizza right on top of there.
[02:31:37.680 --> 02:31:43.600]   Perfect. That's exactly how it's supposed to be. The fanless one will keep that slice nice and
[02:31:43.600 --> 02:31:47.680]   warm. Yeah, that's a good idea. Those the fans really are great for keeping the pizza warm.
[02:31:47.680 --> 02:31:51.760]   Mike, did you have a pizza? The new pizza slide pizza pizza. Pizza
[02:31:51.760 --> 02:31:58.560]   warmer places the pizza box computer. There you go. That's right. That's right. I do. I do. I don't
[02:31:58.560 --> 02:32:05.200]   know if you've mentioned De-Bertify on this show. Not yet. De-Bertify, which has a fantastic name,
[02:32:05.200 --> 02:32:10.800]   is a tool for bringing people from Twitter over to Massadon. Basically how it works,
[02:32:10.800 --> 02:32:16.640]   it has an interface from the 1990s, but basically you just log in to Twitter and then you click the
[02:32:16.640 --> 02:32:21.360]   authorize with Twitter button. It goes and checks your Twitter and finds anything that looks like
[02:32:21.360 --> 02:32:28.400]   a Fediverse address among the people that follow you or that you follow. And then you download a
[02:32:28.400 --> 02:32:34.240]   CVS file and then those of us, those of you who are into Massadon know that within your profile
[02:32:34.240 --> 02:32:43.360]   settings in Massadon, there's an import feature. Just import that CVS file and you are now following.
[02:32:43.360 --> 02:32:47.200]   Excuse me. You're now following. Or you go to the drug store where you can't figure it out and buy
[02:32:47.200 --> 02:32:54.240]   some of that. That's right. This is actually one of the best features of Massadon because unlike
[02:32:54.240 --> 02:32:59.600]   the current site where they're trying to keep you from moving in or out, it's completely open. So
[02:32:59.600 --> 02:33:05.280]   you can also export your list. You can import blocking, following, muting, domain blocking,
[02:33:05.280 --> 02:33:11.600]   and bookmarks too. So yeah, get a following list. This was what Birdify will do is generate that.
[02:33:11.600 --> 02:33:17.280]   You import it in. You can either have it merge with your existing records so you can refollow,
[02:33:17.280 --> 02:33:24.720]   won't hurt anything, or you can overwrite it. And I used this when Twitter first started to go down,
[02:33:24.720 --> 02:33:27.840]   but I think you want to keep using it, right, Mike? Because people are...
[02:33:27.840 --> 02:33:32.160]   Yeah, because more people add their addresses to their Twitter handles and so you'll pick up
[02:33:32.160 --> 02:33:37.440]   some more and basically it doesn't merge. It doesn't hurt. It doesn't merge. So if it's a redundant
[02:33:37.440 --> 02:33:45.520]   address, it just ignores it and moves on. So highly recommended, you can get that at provisto.org/dbirdify.
[02:33:45.520 --> 02:33:55.360]   And it works. It works great. And I think I picked up something like six or seven hundred
[02:33:56.240 --> 02:33:59.440]   people that I now subscribe to on Mastlon that I got through there.
[02:33:59.440 --> 02:34:03.840]   Boy, that's changed a lot because I only got a handful when I was two weeks ago.
[02:34:03.840 --> 02:34:07.360]   So I'm going to... You've all been adding their addresses there coming on every day.
[02:34:07.360 --> 02:34:12.240]   And I have one really quick one that everybody should try. It's called pallet.fm,
[02:34:12.240 --> 02:34:19.680]   P-A-L-E-T-T-E dot FM. And this is a simple, free site where you upload black and white photos
[02:34:19.680 --> 02:34:25.280]   and it will colorize them instantly. What? And it does such a good job. Look at AI at work.
[02:34:26.000 --> 02:34:32.720]   Oh, it's fantastic. It picks the colors of the thing. It knows my brother was a redhead somehow.
[02:34:32.720 --> 02:34:39.280]   Uploaded all these pictures from our youth. Wow. It's really fantastic. It takes literally about
[02:34:39.280 --> 02:34:44.960]   five, maybe 10 seconds to process. It gives you a bunch of different options for different styles,
[02:34:44.960 --> 02:34:52.400]   essentially filters. But I've been having a blast with this and there's no charge and it's really fun.
[02:34:52.960 --> 02:35:01.120]   pallet, P-A-L-E-T-T-E dot FM. Let me go find a black and white photo and try it.
[02:35:01.120 --> 02:35:09.920]   No, I'll do... Before I do it, I'll do a Jeff with your pick or number of weeks.
[02:35:09.920 --> 02:35:12.880]   Something. All right. So I'll do this in honor of Mike being here.
[02:35:12.880 --> 02:35:21.920]   The portable off-grid hotels designed by former SpaceX and Tesla engineers who were smart enough
[02:35:21.920 --> 02:35:26.000]   to get out and go find a box somewhere they could live in to get their sanity back.
[02:35:26.000 --> 02:35:33.280]   $30,000. Tiny home hotels. I can see Mike living in one of these.
[02:35:33.280 --> 02:35:38.240]   That clearly does look like some... They could be flat packed, driven across the country.
[02:35:38.240 --> 02:35:41.200]   No mad adventure. So you buy this and you put it somewhere.
[02:35:41.200 --> 02:35:45.840]   Or somebody puts it somewhere and then rents it out. Oh, and then you could clamp.
[02:35:46.800 --> 02:35:54.000]   Yeah. They got solar. They got a tent. Do they have a toilet?
[02:35:54.000 --> 02:35:57.920]   The world is your toilet. No.
[02:35:57.920 --> 02:36:01.600]   That's the slogan of the company.
[02:36:01.600 --> 02:36:08.560]   Laminate wood aluminum superstructure weather resistant canvas.
[02:36:08.560 --> 02:36:15.040]   Okay. 10-year lifespan. Although you will have to replace the canvas more frequently,
[02:36:15.040 --> 02:36:20.240]   it says these they call these JUPS. 111 square foot. Wow.
[02:36:20.240 --> 02:36:24.000]   Oh, because they have solar, they have plugs and lights.
[02:36:24.000 --> 02:36:28.400]   Nice. That's pretty cool though. Air-conditioner heater can be drilled using an app.
[02:36:28.400 --> 02:36:32.800]   Company wants to integrate Starlink in so you could get internet.
[02:36:32.800 --> 02:36:37.680]   Huh. There it is on a truck.
[02:36:37.680 --> 02:36:39.920]   The one truck? Yeah. A bunch of them.
[02:36:39.920 --> 02:36:43.120]   Wow. Okay. I'd take one.
[02:36:43.120 --> 02:36:48.800]   JUPS. Very cool. JUPS. All right. Thank you, JJ.
[02:36:48.800 --> 02:36:59.840]   Eddow. At Pruitt. My pick is a very, very inexpensive piece of kit for product, photo, or product
[02:36:59.840 --> 02:37:03.840]   video. And it is, dang, my phone just go off. I am so sorry.
[02:37:03.840 --> 02:37:07.600]   That's all right. That's all right. We know rehearsals are ongoing,
[02:37:08.320 --> 02:37:15.600]   but it's a lazy Susan. And this one I've gotten in on Amazon, it's a whole 20 bucks or so.
[02:37:15.600 --> 02:37:21.200]   And it's automated, so you can just literally hit the button on it to have it rotate however,
[02:37:21.200 --> 02:37:25.600]   whichever direction you want it to rotate, as well as change the speed on it.
[02:37:25.600 --> 02:37:30.320]   And a lot of those things, you get them and they're too small and the motors aren't very strong,
[02:37:30.320 --> 02:37:36.480]   so putting certain objects on them tends to break them. But in this case, this one has a very,
[02:37:36.480 --> 02:37:41.200]   very strong motor on it. I've put probably about four pounds worth of stuff on it,
[02:37:41.200 --> 02:37:44.960]   and it just rotates it without a problem. Can you choose the speed?
[02:37:44.960 --> 02:37:48.880]   Yeah. I think the button on the right. It's like a throw.
[02:37:48.880 --> 02:37:54.240]   It goes too fast, in my opinion. I have to use the slowest setting.
[02:37:54.240 --> 02:38:00.400]   But it works really well and it's so cheap. It's something like 20, yeah, 20 dollars on Amazon.
[02:38:00.400 --> 02:38:05.520]   So I had to recommend now. This should be great for anybody who sells on eBay or something.
[02:38:05.520 --> 02:38:10.160]   You can put your product on there and get a great shot. Get the black one if you're going to do that.
[02:38:10.160 --> 02:38:15.760]   Yeah, get the black one. Mix it a lot easier for you. A lot easier for you.
[02:38:15.760 --> 02:38:22.160]   Cool. We'll put a link in the show notes. It's on Amazon J-A-Y-E-G-T, which is, I have no idea how to
[02:38:22.160 --> 02:38:26.400]   change it. It's tempting to do something in English. But it works.
[02:38:26.400 --> 02:38:33.520]   Next up, I'm going to give a shout out because I had a bit of an embarrassing moment where
[02:38:34.320 --> 02:38:38.320]   I thought my boy had five touchdowns last week in game.
[02:38:38.320 --> 02:38:39.040]   Ooh, nice.
[02:38:39.040 --> 02:38:41.280]   I'm going to find out he didn't. I was wrong.
[02:38:41.280 --> 02:38:43.040]   He had seven touchdowns.
[02:38:43.040 --> 02:38:44.480]   Whoa!
[02:38:44.480 --> 02:38:44.960]   Oh!
[02:38:44.960 --> 02:38:45.680]   The game.
[02:38:45.680 --> 02:38:46.240]   Last one.
[02:38:46.240 --> 02:38:47.360]   That is a lot easier.
[02:38:47.360 --> 02:38:48.640]   In one game?
[02:38:48.640 --> 02:38:54.720]   Yes, sir. We started the first round of the playoffs last week. And I live-tweet the games because
[02:38:54.720 --> 02:38:58.480]   I have people back east that follow along want to know what's going on.
[02:38:58.480 --> 02:39:02.480]   And apparently Mr. Jammer B watches it too and I really appreciate that.
[02:39:03.280 --> 02:39:07.280]   But yeah, we had a first round of the playoffs and he tied the school record
[02:39:07.280 --> 02:39:10.160]   for playoff touchdowns and he set the record.
[02:39:10.160 --> 02:39:11.760]   Is that Mike Asargent interviewing?
[02:39:11.760 --> 02:39:13.520]   Yeah, I don't understand.
[02:39:13.520 --> 02:39:16.000]   He does a little like Mike Asargent.
[02:39:16.000 --> 02:39:16.240]   Yeah.
[02:39:16.240 --> 02:39:21.120]   But yeah, I thought he had five and then the press Democrat was like,
[02:39:21.120 --> 02:39:22.560]   "Oh no, he had seven touchdowns."
[02:39:22.560 --> 02:39:23.680]   Seven in one game?
[02:39:23.680 --> 02:39:24.640]   Seven touchdowns.
[02:39:24.640 --> 02:39:25.760]   He threw four.
[02:39:25.760 --> 02:39:28.800]   They only won 49 to 14.
[02:39:28.800 --> 02:39:30.160]   That means he had all the touchdowns.
[02:39:30.160 --> 02:39:35.200]   He had all of them. He threw several touchdowns and then he ran several touchdowns.
[02:39:35.200 --> 02:39:36.160]   You saw the game, John?
[02:39:36.160 --> 02:39:38.320]   He just saw my live-tweets.
[02:39:38.320 --> 02:39:41.120]   He had all the touchdowns.
[02:39:41.120 --> 02:39:41.920]   He had all of them.
[02:39:41.920 --> 02:39:42.400]   It was-
[02:39:42.400 --> 02:39:44.640]   All the points were scored by one person.
[02:39:44.640 --> 02:39:45.920]   It's quite impressive.
[02:39:45.920 --> 02:39:46.800]   It's quite impressive.
[02:39:46.800 --> 02:39:49.680]   It's been fun watching and we're hoping for-
[02:39:49.680 --> 02:39:50.080]   You keep the-
[02:39:50.080 --> 02:39:51.760]   The colleges are going to be coming.
[02:39:51.760 --> 02:39:52.640]   I hope so.
[02:39:52.640 --> 02:39:54.080]   Come on, colleges, because it proved-
[02:39:54.080 --> 02:39:56.080]   We can't afford college tuition.
[02:39:56.080 --> 02:39:58.640]   So was he the quarterback?
[02:39:58.640 --> 02:39:59.360]   He's the quarterback.
[02:39:59.360 --> 02:40:01.520]   So he was 13 for 16 on passing.
[02:40:01.520 --> 02:40:02.080]   Yes, sir.
[02:40:02.080 --> 02:40:04.320]   204 yards, four TDs, wrong.
[02:40:04.320 --> 02:40:06.720]   Seven TDs, 80.
[02:40:06.720 --> 02:40:08.640]   No, no, no, what, four TDs passing.
[02:40:08.640 --> 02:40:10.320]   Oh, those are the passing TDs.
[02:40:10.320 --> 02:40:10.720]   Right.
[02:40:10.720 --> 02:40:12.480]   And he had three rushing TDs.
[02:40:12.480 --> 02:40:14.560]   Right, 415 yards rushing.
[02:40:14.560 --> 02:40:17.120]   This guy is a one man-
[02:40:17.120 --> 02:40:17.520]   He's-
[02:40:17.520 --> 02:40:17.680]   He's-
[02:40:17.680 --> 02:40:17.960]   He's-
[02:40:17.960 --> 02:40:18.400]   Rec and crew.
[02:40:18.400 --> 02:40:18.960]   He's-
[02:40:18.960 --> 02:40:20.640]   Colleges, colleges everywhere.
[02:40:20.640 --> 02:40:21.120]   Hello.
[02:40:21.120 --> 02:40:21.360]   He's-
[02:40:21.360 --> 02:40:21.840]   Hello.
[02:40:21.840 --> 02:40:21.840]   He's-
[02:40:21.840 --> 02:40:22.320]   Hello.
[02:40:22.320 --> 02:40:22.800]   Holy-
[02:40:22.800 --> 02:40:23.600]   Come on, we-
[02:40:23.600 --> 02:40:24.880]   By the way, this is not your tweet.
[02:40:24.880 --> 02:40:25.920]   This is some other guys-
[02:40:25.920 --> 02:40:27.360]   That's from the newspaper.
[02:40:27.360 --> 02:40:28.640]   That's from the press Democrat.
[02:40:28.640 --> 02:40:29.280]   Right.
[02:40:29.280 --> 02:40:30.320]   Very nice.
[02:40:30.320 --> 02:40:30.720]   Thank you for-
[02:40:30.720 --> 02:40:32.080]   This is why it's got the blue check.
[02:40:32.080 --> 02:40:32.720]   Fossil.
[02:40:32.720 --> 02:40:34.240]   Fossil for hard help.
[02:40:34.240 --> 02:40:36.400]   He tied for the
[02:40:36.400 --> 02:40:38.720]   Rancher-Katati single game school record.
[02:40:38.720 --> 02:40:39.200]   Mm-hmm.
[02:40:39.200 --> 02:40:41.280]   Oh, my, my, my.
[02:40:41.280 --> 02:40:42.000]   Yeah, we sat-
[02:40:42.000 --> 02:40:43.520]   We sat him out in the fourth quarter.
[02:40:43.520 --> 02:40:44.640]   What?
[02:40:44.640 --> 02:40:46.000]   That was in three quarters?
[02:40:46.000 --> 02:40:47.760]   [Laughter]
[02:40:47.760 --> 02:40:48.080]   What?
[02:40:48.080 --> 02:40:51.040]   What?
[02:40:51.040 --> 02:40:52.320]   He sat out in the fourth quarter.
[02:40:52.320 --> 02:40:54.560]   He did that in three quarters?
[02:40:54.560 --> 02:40:56.880]   Yeah, it was like two and a half.
[02:40:56.880 --> 02:40:58.080]   It was almost three quarters.
[02:40:58.080 --> 02:40:58.720]   Okay, you want to-
[02:40:58.720 --> 02:40:59.680]   What is he?
[02:40:59.680 --> 02:41:00.640]   He's a junior.
[02:41:00.640 --> 02:41:01.280]   Oh, man.
[02:41:01.280 --> 02:41:01.920]   He's-
[02:41:01.920 --> 02:41:03.280]   He's a talented boy.
[02:41:03.280 --> 02:41:03.840]   Yeah.
[02:41:03.840 --> 02:41:04.800]   Holy cow.
[02:41:04.800 --> 02:41:06.240]   We're quite proud of him.
[02:41:06.240 --> 02:41:06.880]   Quite proud.
[02:41:06.880 --> 02:41:08.240]   I found a black and white picture,
[02:41:08.240 --> 02:41:10.160]   Mr. Elgin,
[02:41:10.160 --> 02:41:12.320]   that I took some time ago,
[02:41:12.320 --> 02:41:15.600]   and I submitted this to Palette.
[02:41:15.600 --> 02:41:17.200]   Look at that.
[02:41:17.200 --> 02:41:19.120]   And let me see if I can find the-
[02:41:19.120 --> 02:41:19.760]   That looks good.
[02:41:19.760 --> 02:41:20.880]   Look at this.
[02:41:20.880 --> 02:41:21.760]   Mm.
[02:41:21.760 --> 02:41:23.840]   It's a real color.
[02:41:23.840 --> 02:41:24.560]   Here.
[02:41:24.560 --> 02:41:26.640]   That's probably what the picture looked like.
[02:41:26.640 --> 02:41:27.280]   It looks good.
[02:41:27.280 --> 02:41:30.080]   I could do a lavender dust version of that.
[02:41:30.080 --> 02:41:32.080]   I could do colorful memories.
[02:41:32.080 --> 02:41:33.680]   Now, how do I-
[02:41:33.680 --> 02:41:34.880]   Oh, is it not-
[02:41:34.880 --> 02:41:35.440]   Why is it not?
[02:41:35.440 --> 02:41:37.680]   It's a lot of images.
[02:41:37.680 --> 02:41:39.680]   It's a lot of images.
[02:41:39.680 --> 02:41:40.640]   It's a lot of pixels,
[02:41:40.640 --> 02:41:41.200]   so I guess-
[02:41:41.200 --> 02:41:42.000]   I get it slowly.
[02:41:42.000 --> 02:41:42.240]   Hey, hey, hey.
[02:41:42.240 --> 02:41:42.720]   Hey, hey.
[02:41:42.720 --> 02:41:44.160]   Holy cow.
[02:41:44.160 --> 02:41:46.240]   A slide of branch,
[02:41:46.240 --> 02:41:46.880]   lane, and oak,
[02:41:46.880 --> 02:41:48.480]   small contrasting details
[02:41:48.480 --> 02:41:50.080]   in natural covert colors.
[02:41:50.080 --> 02:41:52.560]   It actually provided a text description of it.
[02:41:52.560 --> 02:41:54.240]   Holy cow.
[02:41:54.240 --> 02:41:54.800]   That's really-
[02:41:54.800 --> 02:41:55.840]   It's really amazing.
[02:41:55.840 --> 02:41:57.920]   And a lot of us have black and white photos
[02:41:57.920 --> 02:42:00.240]   of our families that we've seen forever.
[02:42:00.240 --> 02:42:01.360]   Once you apply color,
[02:42:01.360 --> 02:42:03.040]   it really brings them to life.
[02:42:03.040 --> 02:42:04.720]   And you can really imagine what it was-
[02:42:04.720 --> 02:42:06.000]   So this is the original.
[02:42:06.000 --> 02:42:06.880]   I didn't give it a,
[02:42:06.880 --> 02:42:09.040]   you know, anything but a JPEG.
[02:42:09.040 --> 02:42:10.800]   I'm going to try it now with mine.
[02:42:10.800 --> 02:42:11.760]   Wow.
[02:42:11.760 --> 02:42:13.760]   Isn't that amazing?
[02:42:13.760 --> 02:42:14.160]   It's-
[02:42:14.160 --> 02:42:15.840]   Um, yeah.
[02:42:15.840 --> 02:42:16.720]   Because that's exactly-
[02:42:16.720 --> 02:42:17.840]   Because this is-
[02:42:17.840 --> 02:42:17.920]   Yeah.
[02:42:17.920 --> 02:42:18.800]   This is our road,
[02:42:18.800 --> 02:42:20.400]   and that's exactly what it looks like.
[02:42:20.400 --> 02:42:22.320]   I don't know how-
[02:42:22.320 --> 02:42:22.880]   That's-
[02:42:22.880 --> 02:42:24.720]   And you can make the trees green if you want.
[02:42:25.360 --> 02:42:26.320]   Or you can make them-
[02:42:26.320 --> 02:42:26.960]   You're in California.
[02:42:26.960 --> 02:42:27.760]   It's not that green.
[02:42:27.760 --> 02:42:28.560]   It's not that green.
[02:42:28.560 --> 02:42:29.440]   Yeah, maybe it's a little green.
[02:42:29.440 --> 02:42:31.280]   Well, maybe it's a little green.
[02:42:31.280 --> 02:42:32.240]   We're going to have a little laugh at her.
[02:42:32.240 --> 02:42:33.440]   Warm glow.
[02:42:33.440 --> 02:42:34.320]   This is really-
[02:42:34.320 --> 02:42:36.960]   That's AI, man.
[02:42:36.960 --> 02:42:37.520]   Wow.
[02:42:37.520 --> 02:42:39.600]   I want to see how it does with mine.
[02:42:39.600 --> 02:42:40.880]   I have a black and white picture
[02:42:40.880 --> 02:42:42.560]   that I use for hands-on photography.
[02:42:42.560 --> 02:42:43.280]   A couple of weeks ago,
[02:42:43.280 --> 02:42:43.920]   as we talked about-
[02:42:43.920 --> 02:42:45.120]   And you hand color.
[02:42:45.120 --> 02:42:46.720]   And I had to hand color it.
[02:42:46.720 --> 02:42:48.160]   Because I knew what it looked like.
[02:42:48.160 --> 02:42:48.880]   I don't know.
[02:42:48.880 --> 02:42:50.080]   I'm in the picture.
[02:42:50.080 --> 02:42:51.200]   Oh, this is remarkable.
[02:42:51.200 --> 02:42:52.640]   So I'm curious to see if it figures out-
[02:42:52.640 --> 02:42:53.600]   Most of my shots-
[02:42:53.600 --> 02:42:56.320]   I take color and then I reduce it to black and white.
[02:42:56.320 --> 02:42:57.040]   Or I shoot.
[02:42:57.040 --> 02:42:58.240]   So, you know,
[02:42:58.240 --> 02:43:01.200]   this was originally a color photo.
[02:43:01.200 --> 02:43:05.120]   But I don't think there's any information in the JPEG about the color.
[02:43:05.120 --> 02:43:06.080]   That's incredible.
[02:43:06.080 --> 02:43:07.600]   Yeah, this ain't bad.
[02:43:07.600 --> 02:43:10.720]   I'm trying this color from memories one.
[02:43:10.720 --> 02:43:11.040]   Wow.
[02:43:11.040 --> 02:43:14.160]   Like I said, my brother's a redhead.
[02:43:14.160 --> 02:43:17.200]   And I uploaded these black and white photos
[02:43:17.200 --> 02:43:19.360]   from when we were kids and it made him a redhead.
[02:43:19.360 --> 02:43:20.000]   I was shocked.
[02:43:20.000 --> 02:43:21.040]   My mother's blonde,
[02:43:21.040 --> 02:43:21.680]   made her blonde.
[02:43:21.680 --> 02:43:23.760]   It was like shocking.
[02:43:23.760 --> 02:43:24.080]   Wow.
[02:43:24.080 --> 02:43:25.840]   Yeah, this is pretty good.
[02:43:25.840 --> 02:43:27.680]   That's my skin.
[02:43:27.680 --> 02:43:28.640]   That's good.
[02:43:28.640 --> 02:43:30.480]   I mean, the helmet is not right.
[02:43:30.480 --> 02:43:33.200]   The helmet's blue for whatever reason.
[02:43:33.200 --> 02:43:33.760]   I made it.
[02:43:33.760 --> 02:43:34.320]   Yeah.
[02:43:34.320 --> 02:43:36.080]   But the jersey is right.
[02:43:36.080 --> 02:43:37.440]   My skin is right.
[02:43:37.440 --> 02:43:38.320]   The white pants.
[02:43:38.320 --> 02:43:38.720]   That's-
[02:43:38.720 --> 02:43:39.360]   Is that you?
[02:43:39.360 --> 02:43:40.240]   Yeah, that's me.
[02:43:40.240 --> 02:43:41.920]   Oh, I didn't know that.
[02:43:41.920 --> 02:43:43.040]   I saw the episode.
[02:43:43.040 --> 02:43:44.000]   I missed that part.
[02:43:44.000 --> 02:43:46.720]   Oh, the one of the pictures kind of old and-
[02:43:46.720 --> 02:43:49.440]   Yeah, there's an old beat up black and white photo.
[02:43:49.440 --> 02:43:49.840]   This is-
[02:43:49.840 --> 02:43:50.960]   Does it look like you at all?
[02:43:50.960 --> 02:43:52.320]   This is pretty good.
[02:43:52.320 --> 02:43:54.640]   That's before you started doing a lot of lifting.
[02:43:54.640 --> 02:43:55.040]   Yeah.
[02:43:55.040 --> 02:43:57.520]   I was skinny then.
[02:43:57.520 --> 02:43:58.080]   What was it?
[02:43:58.080 --> 02:43:59.840]   I was only 200 pounds then.
[02:43:59.840 --> 02:44:02.400]   I did a decent job now.
[02:44:02.400 --> 02:44:02.880]   Yeah, this did work.
[02:44:02.880 --> 02:44:04.240]   You know what it was supposed to look like.
[02:44:04.240 --> 02:44:04.560]   Right.
[02:44:04.560 --> 02:44:05.760]   That's why I wanted to upload it.
[02:44:05.760 --> 02:44:06.000]   Yeah.
[02:44:06.000 --> 02:44:07.920]   That's not bad at all.
[02:44:07.920 --> 02:44:08.720]   Really good-
[02:44:08.720 --> 02:44:09.600]   Palette.fm.
[02:44:09.600 --> 02:44:10.480]   Palette.fm.
[02:44:10.480 --> 02:44:11.360]   Very fun to play with.
[02:44:11.360 --> 02:44:13.920]   Thank you, Mike Elgin.
[02:44:13.920 --> 02:44:18.240]   By the way, I also searched using
[02:44:19.360 --> 02:44:22.240]   Provistu's DeBertify and found
[02:44:22.240 --> 02:44:24.720]   241 accounts.
[02:44:24.720 --> 02:44:25.680]   Wow.
[02:44:25.680 --> 02:44:26.240]   Fantastic.
[02:44:26.240 --> 02:44:29.600]   With 248 FEDiverse IDs spread over 77 instances.
[02:44:29.600 --> 02:44:31.360]   So it did a good job.
[02:44:31.360 --> 02:44:33.040]   Wow.
[02:44:33.040 --> 02:44:34.800]   Did a good job finding stuff that I,
[02:44:34.800 --> 02:44:35.920]   you know,
[02:44:35.920 --> 02:44:37.360]   I mean, some of those I may have,
[02:44:37.360 --> 02:44:38.560]   but this is nice.
[02:44:38.560 --> 02:44:40.640]   Now don't forget to go and revoke that excess.
[02:44:40.640 --> 02:44:41.760]   Yeah.
[02:44:41.760 --> 02:44:44.080]   Absolutely.
[02:44:44.080 --> 02:44:45.520]   Absolutely.
[02:44:45.520 --> 02:44:46.880]   The Lute on Musk cars.
[02:44:49.200 --> 02:44:50.240]   Really cool.
[02:44:50.240 --> 02:44:51.440]   What a fun show this has been.
[02:44:51.440 --> 02:44:52.960]   Thank you so much for being here.
[02:44:52.960 --> 02:44:55.040]   It is now pitch black in Mexico City.
[02:44:55.040 --> 02:44:56.080]   Is the band still playing?
[02:44:56.080 --> 02:44:58.320]   They're on a break right now.
[02:44:58.320 --> 02:44:58.720]   Okay.
[02:44:58.720 --> 02:45:02.560]   Gastronomad.net.
[02:45:02.560 --> 02:45:03.360]   We told you that.
[02:45:03.360 --> 02:45:05.200]   Subscribe to Mike's Substack.
[02:45:05.200 --> 02:45:07.840]   Mike Elgin.substack.com.
[02:45:07.840 --> 02:45:09.760]   Follow him on Twitter at Mike Elgin.
[02:45:09.760 --> 02:45:13.680]   He's also on Mastodon.social@micelgin.
[02:45:13.680 --> 02:45:14.080]   Yeah.
[02:45:14.080 --> 02:45:15.440]   It's great to see you.
[02:45:15.440 --> 02:45:16.160]   I want to give him-
[02:45:16.160 --> 02:45:16.560]   I want to give him-
[02:45:16.560 --> 02:45:17.840]   Kevin's doing great.
[02:45:17.840 --> 02:45:18.240]   I'm sure,
[02:45:18.240 --> 02:45:21.440]   but let's give a little plug for his project.
[02:45:21.440 --> 02:45:22.000]   Thank you.
[02:45:22.000 --> 02:45:22.400]   Thank you.
[02:45:22.400 --> 02:45:23.360]   It's Chatterbox.
[02:45:23.360 --> 02:45:24.720]   Hello Chatterbox.com.
[02:45:24.720 --> 02:45:25.600]   And he is-
[02:45:25.600 --> 02:45:26.080]   Mm-hmm.
[02:45:26.080 --> 02:45:28.160]   He makes a smart speaker out of cardboard
[02:45:28.160 --> 02:45:29.360]   that kids build themselves,
[02:45:29.360 --> 02:45:30.960]   and they teach it how to talk,
[02:45:30.960 --> 02:45:33.920]   and it teaches them how AI works.
[02:45:33.920 --> 02:45:36.720]   teaches them to get used to privacy
[02:45:36.720 --> 02:45:40.080]   instead of being listened to all the time
[02:45:40.080 --> 02:45:41.200]   from a smart speaker.
[02:45:41.200 --> 02:45:41.760]   Nice.
[02:45:41.760 --> 02:45:42.880]   And kids are going nuts with this.
[02:45:42.880 --> 02:45:43.920]   They're learning so much.
[02:45:43.920 --> 02:45:44.400]   It's great.
[02:45:44.400 --> 02:45:44.960]   Teachers love it too.
[02:45:44.960 --> 02:45:47.840]   Because they don't have to be a computer
[02:45:47.840 --> 02:45:48.880]   scientist to teach it.
[02:45:48.880 --> 02:45:51.280]   It's easy to teach because it comes with curriculum
[02:45:51.280 --> 02:45:52.000]   and all this kind of stuff.
[02:45:52.000 --> 02:45:53.760]   So there are educators out there
[02:45:53.760 --> 02:45:55.360]   that really want to teach kids
[02:45:55.360 --> 02:45:57.520]   and prepare them for the actual future
[02:45:57.520 --> 02:45:58.640]   that they're going to be encountering,
[02:45:58.640 --> 02:46:00.720]   which is going to be AI and voice interfaces.
[02:46:00.720 --> 02:46:02.720]   Chatterbox is amazing.
[02:46:02.720 --> 02:46:04.560]   So highly recommended.
[02:46:04.560 --> 02:46:05.680]   Hello Chatterbox.com.
[02:46:05.680 --> 02:46:07.200]   That's Mike Sunkeven who does that.
[02:46:07.200 --> 02:46:08.720]   And it's really cool.
[02:46:08.720 --> 02:46:09.440]   Hello Chatterbox.
[02:46:09.440 --> 02:46:10.080]   We're very proud of him.
[02:46:10.080 --> 02:46:11.680]   He's very successful.
[02:46:11.680 --> 02:46:16.160]   And he did it all without VC or anything on purpose.
[02:46:16.160 --> 02:46:17.760]   So it's a good concept.
[02:46:17.760 --> 02:46:18.320]   It's a great, great, great.
[02:46:18.320 --> 02:46:18.800]   Love it.
[02:46:18.800 --> 02:46:18.880]   Yeah.
[02:46:18.880 --> 02:46:21.440]   No pressure to reveal all that information
[02:46:21.440 --> 02:46:22.800]   or anything like that.
[02:46:22.800 --> 02:46:25.360]   Hands-off, photography twit.tv/hop.
[02:46:25.360 --> 02:46:27.680]   Tomorrow, watch Jonathan Bennett's going to get
[02:46:27.680 --> 02:46:29.280]   the Ant-Pruit AMA.
[02:46:29.280 --> 02:46:30.880]   Look, what is that T-shirt?
[02:46:30.880 --> 02:46:33.120]   This is a shout-out again to Queen Pruitt.
[02:46:33.120 --> 02:46:35.040]   This is open a week as previously mentioned.
[02:46:35.040 --> 02:46:36.240]   Oh, I could move to Mike.
[02:46:36.240 --> 02:46:39.120]   But Sandy Cheeks in the house.
[02:46:39.120 --> 02:46:43.120]   Did she look like that in the show?
[02:46:43.120 --> 02:46:44.080]   She does not.
[02:46:44.080 --> 02:46:48.160]   She wears a astronaut suit or something, I believe.
[02:46:48.160 --> 02:46:48.960]   Oh, cool.
[02:46:48.960 --> 02:46:50.720]   Scientists over there.
[02:46:50.720 --> 02:46:52.640]   I won't be attending open at night
[02:46:52.640 --> 02:46:54.800]   because she knows that I'm supposed
[02:46:54.800 --> 02:46:56.080]   to be at the playoff game.
[02:46:56.080 --> 02:46:57.600]   Oh, OK.
[02:46:57.600 --> 02:47:00.400]   Plus, all the other grad seekers would be focused on you
[02:47:00.400 --> 02:47:01.120]   instead of her.
[02:47:01.120 --> 02:47:01.680]   Yeah.
[02:47:01.680 --> 02:47:04.000]   So I think it's appropriate to give her her space.
[02:47:04.000 --> 02:47:04.480]   Yeah.
[02:47:04.480 --> 02:47:05.040]   Right.
[02:47:05.040 --> 02:47:05.840]   That's what it is.
[02:47:05.840 --> 02:47:06.640]   That's it.
[02:47:06.640 --> 02:47:07.280]   Good call, sir.
[02:47:07.280 --> 02:47:08.720]   You got to go with your entourage.
[02:47:08.720 --> 02:47:10.720]   There's all the paparazzi show up.
[02:47:10.720 --> 02:47:14.000]   It can really take away from her.
[02:47:14.000 --> 02:47:15.280]   Oh, you're my cathartian?
[02:47:15.280 --> 02:47:16.800]   Yeah, I get that in mind.
[02:47:16.800 --> 02:47:17.760]   No.
[02:47:17.760 --> 02:47:19.600]   No, you do not.
[02:47:19.600 --> 02:47:21.120]   I know you don't get that.
[02:47:21.120 --> 02:47:24.880]   Mr. Jeff Jarvis, folks, he's the director.
[02:47:24.880 --> 02:47:28.720]   Not just the actor, the director of the Townite Center
[02:47:28.720 --> 02:47:30.720]   for Entrepreneurial Journalism at the--
[02:47:30.720 --> 02:47:34.080]   [MUSIC - "RAIN DRY"]
[02:47:34.080 --> 02:47:35.920]   Craig Neumard, graduate school of journalism
[02:47:35.920 --> 02:47:37.440]   at the City University in New York.
[02:47:37.440 --> 02:47:38.240]   He's on Massonon.
[02:47:38.240 --> 02:47:39.280]   He's on Twitter.
[02:47:39.280 --> 02:47:40.640]   And he's at buzzmachine.com.
[02:47:40.640 --> 02:47:44.160]   By the way, Craig is on Massonon as well, Craig Neumard.
[02:47:44.160 --> 02:47:44.680]   He is.
[02:47:44.680 --> 02:47:45.180]   Yeah.
[02:47:45.180 --> 02:47:46.080]   That's pretty active, too.
[02:47:46.080 --> 02:47:47.080]   That's good.
[02:47:47.080 --> 02:47:48.280]   That's good.
[02:47:48.280 --> 02:47:50.280]   Thank you, everybody, for joining us.
[02:47:50.280 --> 02:47:51.440]   We do this week in Google.
[02:47:51.440 --> 02:47:55.520]   Usually, if we weren't taking the company photo,
[02:47:55.520 --> 02:47:56.680]   we would have started to--
[02:47:56.680 --> 02:47:57.800]   but we were a little late today.
[02:47:57.800 --> 02:47:58.720]   I apologize.
[02:47:58.720 --> 02:48:02.760]   2PM Pacific, 5PM Eastern, 2200 UTC.
[02:48:02.760 --> 02:48:05.640]   You can watch us do at live at live.twit.tv.
[02:48:05.640 --> 02:48:07.960]   Chat with us live at IRC.twit.tv.
[02:48:07.960 --> 02:48:11.800]   Club members get to join us in the club-twit discord.
[02:48:11.800 --> 02:48:13.120]   That's always a lot of fun.
[02:48:13.120 --> 02:48:13.880]   Ants in there.
[02:48:13.880 --> 02:48:16.080]   And all of us and so much.
[02:48:16.080 --> 02:48:18.280]   And it's less expensive than Twitter blue.
[02:48:18.280 --> 02:48:19.600]   It is.
[02:48:19.600 --> 02:48:22.160]   It is.
[02:48:22.160 --> 02:48:24.160]   And there's cats.
[02:48:24.160 --> 02:48:27.400]   [LAUGHTER]
[02:48:27.400 --> 02:48:29.320]   That's how I feel right about now.
[02:48:29.320 --> 02:48:31.280]   That's me and Jeff having fun.
[02:48:31.280 --> 02:48:32.440]   All right.
[02:48:32.440 --> 02:48:36.320]   Photo number three in Slack.
[02:48:36.320 --> 02:48:38.400]   OK, I have to go to Slack and do that.
[02:48:38.400 --> 02:48:41.480]   I've got to tell you, the company photo today,
[02:48:41.480 --> 02:48:44.360]   this had to be the most adventurous company photo
[02:48:44.360 --> 02:48:45.680]   I've ever been a part of.
[02:48:45.680 --> 02:48:46.320]   Oh, dear.
[02:48:46.320 --> 02:48:47.920]   What in the world?
[02:48:47.920 --> 02:48:48.880]   Is it in general?
[02:48:48.880 --> 02:48:50.040]   Where is it?
[02:48:50.040 --> 02:48:51.040]   General?
[02:48:51.040 --> 02:48:51.400]   OK.
[02:48:51.400 --> 02:48:54.160]   We're watching the whole thing over the stream.
[02:48:54.160 --> 02:48:57.000]   It was quite-- there were drones and--
[02:48:57.000 --> 02:48:58.400]   Chaos.
[02:48:58.400 --> 02:48:59.360]   Chaos.
[02:48:59.360 --> 02:48:59.840]   That's the word.
[02:48:59.840 --> 02:49:00.360]   Chaos.
[02:49:00.360 --> 02:49:02.040]   Yeah, that's the word I was looking for.
[02:49:02.040 --> 02:49:02.520]   Chaos.
[02:49:02.520 --> 02:49:04.080]   I think we could colorize this.
[02:49:04.080 --> 02:49:07.920]   And we might have us a Christmas picture.
[02:49:07.920 --> 02:49:08.840]   How do I get this?
[02:49:08.840 --> 02:49:10.880]   Look at Lisa.
[02:49:10.880 --> 02:49:12.360]   [LAUGHTER]
[02:49:12.360 --> 02:49:16.840]   OK, this is-- why am I having a double picture here?
[02:49:16.840 --> 02:49:18.560]   I don't understand how this works.
[02:49:18.560 --> 02:49:20.080]   How does computers work?
[02:49:20.080 --> 02:49:20.680]   Linux.
[02:49:20.680 --> 02:49:21.600]   Is it-- is it--
[02:49:21.600 --> 02:49:22.360]   Linux?
[02:49:22.360 --> 02:49:23.240]   It's a Linux problem.
[02:49:23.240 --> 02:49:24.560]   It's just Linux.
[02:49:24.560 --> 02:49:25.560]   There it is.
[02:49:25.560 --> 02:49:27.320]   Are we off now?
[02:49:27.320 --> 02:49:28.640]   No, we're not off.
[02:49:28.640 --> 02:49:29.080]   Oh.
[02:49:29.080 --> 02:49:29.760]   Don't wait a minute.
[02:49:29.760 --> 02:49:30.640]   Don't say anything yet.
[02:49:30.640 --> 02:49:32.080]   Ladies and gentlemen, thanks for joining us.
[02:49:32.080 --> 02:49:33.560]   We'll see you next time.
[02:49:33.560 --> 02:49:36.920]   On this week at Google, I need a waffle.
[02:49:36.920 --> 02:49:37.760]   [LAUGHTER]
[02:49:37.760 --> 02:49:38.600]   Oh, shut up.
[02:49:38.600 --> 02:49:39.440]   Here's some pizza.
[02:49:39.440 --> 02:49:45.960]   Don't miss all about Android every week.
[02:49:45.960 --> 02:49:48.920]   We talk about the latest news, hardware, apps,
[02:49:48.920 --> 02:49:51.080]   and now all the developer-y goodness
[02:49:51.080 --> 02:49:53.440]   happening in the Android ecosystem.
[02:49:53.440 --> 02:49:56.240]   I'm Jason Howell, also joined by Ron Richards, Florence
[02:49:56.240 --> 02:49:58.880]   Ion, and our newest co-host on the panel,
[02:49:58.880 --> 02:50:01.880]   When Toow Who Brings Her Developer Chops.
[02:50:01.880 --> 02:50:02.840]   Really great stuff.
[02:50:02.840 --> 02:50:05.920]   We also invite people from all over the Android ecosystem
[02:50:05.920 --> 02:50:09.240]   to talk about this mobile platform we love so much.
[02:50:09.240 --> 02:50:12.680]   Join us every Tuesday, all about Android, on twit.tv.
[02:50:12.680 --> 02:50:15.680]   [MUSIC PLAYING]
[02:50:15.680 --> 02:50:19.040]   [MUSIC PLAYING]
[02:50:19.040 --> 02:50:22.400]   [MUSIC PLAYING]
[02:50:22.400 --> 02:50:25.740]   [MUSIC PLAYING]

