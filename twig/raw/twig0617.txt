;FFMETADATA1
title=That's A Moray 
artist=Leo Laporte, Jeff Jarvis, Stacey Higginbotham, Matt Cutts
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2021-06-24
track=617
language=English
genre=Podcast
comment=John McAfee, Peloton, Bitcoin
encoded_by=Uniblab 5.2
date=2021
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.880]   It's time for Twink this week in Google. Stacey's here, Jeff's here, and a very special visit
[00:00:04.880 --> 00:00:10.720]   from the former administrator of the United States Digital Service. Matt Cutz is in the house.
[00:00:10.720 --> 00:00:16.800]   Is Sundar Pichai a terrible CEO? Or is the New York Times just putting out link bait? We'll talk
[00:00:16.800 --> 00:00:21.840]   about that. Congress going after big tech. What does Matt Cutz think of that? And
[00:00:21.840 --> 00:00:28.800]   Peloton owners are just a little bit miffed because they can't use their treadmills unless
[00:00:28.800 --> 00:00:33.760]   they pay a subscription, details to come with the entire show next on Twig.
[00:00:33.760 --> 00:00:42.160]   Podcasts you love from people you trust. This is Twig.
[00:00:42.160 --> 00:00:52.480]   This is Twig this week in Google, episode 617, recorded Wednesday, June 23rd, 2021.
[00:00:53.120 --> 00:00:59.280]   That's Amore. This episode of This Week in Google is brought to you by Noreva. Getting your audio
[00:00:59.280 --> 00:01:05.280]   ready for meetings back in the office. Noreva audio is designed for distancing. It automatically
[00:01:05.280 --> 00:01:10.960]   adapts to new room configurations. So you're ready for the new normal and whatever comes next.
[00:01:10.960 --> 00:01:21.040]   Learn more at noreva.com/twits. And by AT&T active armor. We rely so much on our phones these days
[00:01:21.040 --> 00:01:26.240]   and are always on them. Whether it's live streaming content catching up with family on weekly video
[00:01:26.240 --> 00:01:32.400]   calls or watching your favorite podcast, there's no room for fraud calls. Thankfully, AT&T makes
[00:01:32.400 --> 00:01:40.320]   customer security a priority helping block those pesky calls. It's not complicated. AT&T active armor
[00:01:40.320 --> 00:01:47.600]   24/7 proactive network security and fraud call blocking to help stop threats. And no extra charge.
[00:01:47.600 --> 00:01:53.360]   compatible device and service required visit att.com/active armor for details.
[00:01:53.360 --> 00:02:00.000]   And by untucket. Summer is right around the corner and now is the perfect time to try out
[00:02:00.000 --> 00:02:06.240]   an untucket shirt that's just right for you. Use the code TWIT for 20% off your first purchase
[00:02:06.240 --> 00:02:14.240]   at untucket.com. It's time for Twig this week in Google. We might even talk about Google today.
[00:02:14.240 --> 00:02:18.400]   I don't know. I just have a feeling Stacy Higginbotham is back. It's great to have you Stacy.
[00:02:18.400 --> 00:02:21.200]   We missed you. Yeah. It's great to be back.
[00:02:21.200 --> 00:02:21.720]   It's great to be back.
[00:02:21.720 --> 00:02:26.640]   com. You went to Texas. Did you have fun?
[00:02:26.640 --> 00:02:31.040]   I spent 10 days in Texas and my gosh, it was warm.
[00:02:31.040 --> 00:02:38.000]   Yeah. You're having a heat wave. Yeah. Well, it's good to see you. Welcome back. Also with us
[00:02:38.000 --> 00:02:43.280]   Jeff Jarvis who's back home from his trip to real microphone. Mark Twain's birthplace.
[00:02:43.840 --> 00:02:48.000]   Yes. I'm positively giddy about the next person you're going to announce.
[00:02:48.000 --> 00:02:53.440]   We are very thrilled. So I asked Ant Pruitt to take a step back. He's actually producing today.
[00:02:53.440 --> 00:02:58.240]   Jason had to take the day off. So worked out fine to make some room for an old friend.
[00:02:58.240 --> 00:03:05.440]   Mr. Matt Cuts is with us. Yeah. It's so good to be back on Twitter.
[00:03:06.880 --> 00:03:17.520]   So Matt has a rather checkered past. Storyed is good. Good word. Writer. Very good word.
[00:03:17.520 --> 00:03:24.080]   Storyed past. Early employee at Google, he did all those great webmaster videos. He was in charge
[00:03:24.080 --> 00:03:30.320]   of the fighting spammy. He saved us all from spam. Saved us all from link farms.
[00:03:30.320 --> 00:03:36.720]   And then got the call to go into government in the last six months of the Obama administration.
[00:03:36.720 --> 00:03:40.800]   He went to the United States digital service. And you've been on since then to talk about
[00:03:40.800 --> 00:03:48.800]   USDS and to invite programmers and other technical people to join to help make our
[00:03:48.800 --> 00:03:54.000]   federal government's technology work better. With veterans affairs has used USDS. There
[00:03:54.000 --> 00:03:57.760]   been some amazing success stories. It was originally started because the
[00:03:57.760 --> 00:04:04.080]   Obamacare websites, the National Obamacare website was so poorly done. And did you didn't go then?
[00:04:04.080 --> 00:04:10.320]   Did you or? No, I was sort of in that second wave, but got to overlap with people who worked
[00:04:10.320 --> 00:04:15.200]   on the original healthcare.gov team. And some of those folks have now come back. So it is the
[00:04:15.200 --> 00:04:21.600]   perfect time to come and do a tour of government service if you're interested. USDS.gov/join.
[00:04:21.600 --> 00:04:31.280]   And for your term, you've done four and a half, but promoted to acting administrator and eventually
[00:04:32.000 --> 00:04:40.400]   full administrator of the USDS, which is great. He is a colonel in the US military call and
[00:04:40.400 --> 00:04:45.200]   call and call and cut. And it was funny when you were all we're doing that and I couldn't respond.
[00:04:45.200 --> 00:04:52.400]   So yeah, it was the pay grade, not the title. Did you get a title though? I mean, you get like
[00:04:52.400 --> 00:04:58.160]   the grade? Not really. Everybody at the US digital service is just a digital service expert.
[00:04:58.160 --> 00:05:06.160]   Okay, good enough. Anyway, since you've retired from the digital service and are now just kind of
[00:05:06.160 --> 00:05:11.680]   living the life up there on DuPont Circle with all the lobbyists, you're not going to be a
[00:05:11.680 --> 00:05:19.040]   lobbyist though, are you? No, oh, no, absolutely not. I wish you would. So you stop the government
[00:05:19.040 --> 00:05:24.080]   from doing horrible, stupid, damaging internet regulation. Not all lobbyists are bad, actually.
[00:05:24.960 --> 00:05:29.040]   Yeah, I wouldn't I wouldn't do it for money. I just, you know, trying to help make
[00:05:29.040 --> 00:05:34.000]   bad things not happen. Sneak into the Congressman's office. Just change some language in this.
[00:05:34.000 --> 00:05:37.920]   Yeah, let's just do this a little bit. You don't want to do that representative. You don't want
[00:05:37.920 --> 00:05:42.480]   to do that. As long as we're doing an old home week, I should mention that Gina Trapani, who is also
[00:05:42.480 --> 00:05:47.520]   a longtime host on the show, has now been promoted to CEO of her company Postlight.
[00:05:48.160 --> 00:05:55.120]   So congratulations, Gina. She left us in 2016 or 2017 to go to work there in New York City
[00:05:55.120 --> 00:06:01.280]   and to have a child. And you know, she was she was pretty busy. And she's risen through the ranks
[00:06:01.280 --> 00:06:07.600]   is now CEO of her design from Postlight. So congratulations, Gina. It's really great.
[00:06:07.600 --> 00:06:12.720]   That's fantastic. It'd be nice to get her back sometimes. How old is how old is her kid now?
[00:06:12.720 --> 00:06:18.320]   Oh, yeah, I probably head of the college. So I know it goes so fast. It really does.
[00:06:18.320 --> 00:06:24.560]   So Matt, is there anything you want to share with us about your experience working in government?
[00:06:24.560 --> 00:06:31.200]   Was it a good overall? Was it a positive thing? Oh, I absolutely. Yes. I mean, working under
[00:06:31.200 --> 00:06:37.360]   Obama, the Trump administration now Biden, the thing that unites all of that is people really care
[00:06:37.360 --> 00:06:42.240]   about making government work. This is the people at the US digital service. And it is such a
[00:06:42.240 --> 00:06:47.120]   fantastic time right now. If you were a, you know, a technologist, a software engineer, a designer,
[00:06:47.120 --> 00:06:52.800]   a product manager, like they desperately need those skills and US digital service got like a
[00:06:52.800 --> 00:06:59.200]   $200 million infusion because of a build that passed. And so that's good news. Yeah, what they
[00:06:59.200 --> 00:07:04.880]   really need, they have amazing projects. They helped along with, you know, Boston Children's
[00:07:04.880 --> 00:07:09.680]   Hospital on vaccines.gov. So they've been doing phenomenal work helping veterans.
[00:07:09.680 --> 00:07:13.600]   Now what they need is some more people who are willing to go and help out in government.
[00:07:13.600 --> 00:07:18.960]   And you don't even have to come to DC right now because of the, oh, yeah, because of, so,
[00:07:18.960 --> 00:07:22.320]   and it's a paying job. It's not a volunteer job, right? I mean, it's actually work.
[00:07:22.320 --> 00:07:28.320]   And that's absolutely right. So if you're what's called a GS 1510 general schedule,
[00:07:28.320 --> 00:07:34.000]   you can earn like 170,000 dollars a year. I'll be there. I'm on my way.
[00:07:35.200 --> 00:07:42.320]   Just podcast. Very long. Yeah. They do. We do need content strategist. So if there's, you know,
[00:07:42.320 --> 00:07:46.800]   there's a lot of different checkup website, uss.gov. There's a lot of really good stuff to do.
[00:07:46.800 --> 00:07:52.880]   What you really need right now is cobalt programmers. The Medicare payment system is
[00:07:52.880 --> 00:08:00.080]   eight million lines of cobalt code, 2.5 million lines of assembly running on 15 mainframes.
[00:08:00.080 --> 00:08:06.240]   It powers four and a half percent of the entire American economy. 53 million people depend on
[00:08:06.240 --> 00:08:12.800]   including me in about six months. And it's really, it needs to be updated a little bit.
[00:08:12.800 --> 00:08:18.080]   Are you having trouble finding cobalt? Somebody actually called the radio show and said,
[00:08:18.080 --> 00:08:22.160]   who's looking for cobalt programmers? I said, Matt cuts his. But now it's.
[00:08:22.160 --> 00:08:28.240]   It's 100% true. Yeah. We have had people who learned how to program cobalt for fun because they're
[00:08:28.240 --> 00:08:33.520]   like, oh, this would be an interesting way to get go deeper in the job. We also had a USGS
[00:08:33.520 --> 00:08:39.040]   former engineer write a book talking about her experiences modernizing things and including
[00:08:39.040 --> 00:08:43.200]   some cobalt stuff. I think the book is called like, Kill It With Fire or something like that.
[00:08:43.200 --> 00:08:53.440]   Wow. This is really, you know, I think especially at Geeks, we're a little cynical about government.
[00:08:53.440 --> 00:08:59.120]   I think years of Ronald Reagan, you know, badmouthing big government really kind of
[00:08:59.120 --> 00:09:02.960]   turned a whole generation against it. But it's really about public service.
[00:09:02.960 --> 00:09:08.080]   And it's about making a difference. And yeah, government is big and unwieldy and it's running
[00:09:08.080 --> 00:09:14.480]   on a lot of lines of cobalt code. But here's a chance to make it work for people. And it's
[00:09:14.480 --> 00:09:19.520]   really important. It is a very important part of our economy and the work.
[00:09:19.520 --> 00:09:25.680]   It's hugely matters. And you can make stuff work for one tenth, you know, either the price or,
[00:09:25.680 --> 00:09:30.560]   or, you know, the complexity. And you can bring in user center design so that it's actually a
[00:09:30.560 --> 00:09:36.240]   good system to use. You know, Rick Cloud just became the chief technology and innovation officer
[00:09:36.240 --> 00:09:42.960]   for the state of California. And that team has rolled out, you know, a vaccine passport for the
[00:09:42.960 --> 00:09:48.000]   state of California and its open source. So, you know, it can be state level, it can be federal
[00:09:48.000 --> 00:09:53.280]   level. There's so many great places to slot in to help out with with really important projects
[00:09:53.280 --> 00:09:58.400]   right now. Let me just check and see if I got my passport yet. Nope, still waiting. But
[00:09:58.400 --> 00:10:06.960]   Rick, Rick, Rick created Feedburner, which was a great way, especially in early days of podcasting
[00:10:06.960 --> 00:10:12.240]   to make a RSS feed. I used it was a big fan of Feedburner. Google bought it. He was a Google
[00:10:12.240 --> 00:10:16.240]   for some time, eventually Google ventures and is now CTO of the state of California.
[00:10:16.240 --> 00:10:24.240]   And a really nice guy. A really great guy. Yeah. Well, good. A usds.gov. If you want to know more
[00:10:24.240 --> 00:10:32.080]   or you want to tell your friends about it, I think this is a, this is just, I love this picture,
[00:10:32.080 --> 00:10:37.280]   by the way, this hero's picture on the site is the best isn't picture ever. It is full of all,
[00:10:37.280 --> 00:10:43.520]   there's a little Drupal icon. It's full of so many fascinating little things. I just adore it.
[00:10:43.520 --> 00:10:48.080]   Yeah. You might be able to notice if you look on the hearth, there's actually
[00:10:48.080 --> 00:10:54.160]   Pez dispensers from like former presidents. Oh, right. There they are right here. Oh, wow. Look
[00:10:54.160 --> 00:10:59.840]   at that right there. And the world's tiniest whiteboards. Yeah, then you really need a bigger
[00:10:59.840 --> 00:11:04.320]   whiteboard. I think we can afford this $200 million. You can now afford a bigger whiteboard.
[00:11:04.320 --> 00:11:09.280]   We can get a bigger one. That's actually, it was a nicely done whiteboard though, I must say.
[00:11:10.160 --> 00:11:15.200]   Anyway, thank you so much for joining us. We won't, we won't pester you too much about what it was like
[00:11:15.200 --> 00:11:21.760]   working in DC for the last four years, but. Let me just ask one general question if I can.
[00:11:21.760 --> 00:11:29.280]   Going from a private company to government. And I have a small taste of it working in a state
[00:11:29.280 --> 00:11:39.600]   university. What were there any kind of bureaucratic cultural moments? Yes, absolutely. I mean,
[00:11:39.600 --> 00:11:45.920]   there's different pockets in government that are great, USAID or even the Department of Defense
[00:11:45.920 --> 00:11:50.560]   has some really high functioning technology. And then you go to some places that are a little,
[00:11:50.560 --> 00:11:56.400]   that you think might be really high flute and great tech. And I felt like I had a 40% productivity
[00:11:56.400 --> 00:12:01.280]   hit. You couldn't use any of the common cloud software that you're used to or your Chromebooks.
[00:12:01.280 --> 00:12:07.840]   For security reasons. Yeah, well, and there's a lot of people who are still afraid of the cloud.
[00:12:07.840 --> 00:12:12.240]   Like they think either it's illegal or they're worried is somebody going to subpoena this and I
[00:12:12.240 --> 00:12:17.040]   won't have a chance to weigh in on it, which is why I'll try to bring this around to Google.
[00:12:17.040 --> 00:12:22.320]   Whenever Google just announced they're going to allow client side encryption and people keep their
[00:12:22.320 --> 00:12:27.920]   own keys like that was really big news. We, we, it took us four years to get access to Slack.
[00:12:27.920 --> 00:12:32.480]   And the breakthrough was primarily because you know, you can encrypt it such that nobody could
[00:12:32.480 --> 00:12:37.120]   send a subpoena to the executive office, the president. And so the idea that you can now use
[00:12:37.120 --> 00:12:42.640]   cloud software and maybe Google workspace and not have to actually, you know, worry about a subpoena
[00:12:42.640 --> 00:12:46.240]   because you've got all that stuff encrypted in the cloud. Like those are the kinds of things
[00:12:46.240 --> 00:12:50.880]   that will unlock a lot of enterprise tools within government. I think where you, you probably weren't
[00:12:50.880 --> 00:12:56.960]   involved, but were you maybe peripherally in the Jedi contract and the battle between Amazon,
[00:12:56.960 --> 00:13:04.240]   Microsoft and Oracle and others to get that big Pentagon contract for a new Pentagon cloud.
[00:13:05.440 --> 00:13:10.160]   So I was, I was off on the side, you know, the US digital services in one part of the government,
[00:13:10.160 --> 00:13:14.240]   but there was a different group, the defense digital service, which we were working closely
[00:13:14.240 --> 00:13:19.600]   with at the time that started the Jedi initiative. So actually, I actually had to sell all of my
[00:13:19.600 --> 00:13:24.000]   Google shares because I wanted to avoid even the appearance of the parties. Well, it turned out
[00:13:24.000 --> 00:13:30.880]   to be a costly share. But that's okay. Like you, it's important that government be fair and that
[00:13:30.880 --> 00:13:35.040]   you, you know, make sure that you're in good shape. So I think that definitely turned into a more
[00:13:35.040 --> 00:13:41.120]   complicated procurement than probably a lot of people would have liked to have seen. But it's
[00:13:41.120 --> 00:13:45.440]   nice to see, you know, government starting to embrace technology and thinking, how are they going to
[00:13:45.440 --> 00:13:49.600]   move to the cloud? You know, should it be seamless with one provider or should it be many providers?
[00:13:49.600 --> 00:13:54.640]   And in fact, that was one of the big, the big specs of Jedi was that it being encrypted
[00:13:54.640 --> 00:13:59.920]   cloud that was safe for the DoD to use. Yeah, cross service. So the irony is that government
[00:13:59.920 --> 00:14:03.280]   wants encryption for itself, but wants a backdoor for all of us.
[00:14:03.280 --> 00:14:06.880]   Different branches of government, Jeff.
[00:14:06.880 --> 00:14:13.440]   Even with this, just like us, Jeff, we want everything to be cheap, but we also
[00:14:13.440 --> 00:14:16.480]   wanted to be high quality. People suck it when it comes to trade offs.
[00:14:16.480 --> 00:14:21.920]   We're not good at that. Yes, we know. But even within the NSA, there's, there's part of the NSA
[00:14:21.920 --> 00:14:26.560]   is about breaking our crypto. And part of it saying, no, no, we need really strong good
[00:14:26.560 --> 00:14:31.040]   crypto. It's so funny. So even within a single agency, there's a debate over this.
[00:14:31.040 --> 00:14:35.680]   You know, I was thinking about culture. I thought that's what your question kind of was about, Jeff,
[00:14:35.680 --> 00:14:39.840]   was the corporate culture versus the Google culture. We're going to get into the Google
[00:14:39.840 --> 00:14:48.000]   culture in a little bit. But I read a really good blog post from a guy who, a former senior developer
[00:14:48.000 --> 00:14:54.960]   advocate at Amazon Web Services talking about Amazon's document culture. And I really, I found
[00:14:54.960 --> 00:14:59.680]   it really inspiring. This is Justin Garrison.com. That's his blog.
[00:14:59.680 --> 00:15:04.000]   You know, we've talked about kind of what Amazon does before. For instance,
[00:15:04.000 --> 00:15:09.600]   you don't start a meeting without a document and the meeting begins with reading time,
[00:15:09.600 --> 00:15:15.200]   where everybody reads the document so that you're all on the same ground, it's fresh in your mind.
[00:15:15.200 --> 00:15:19.840]   I think there's just little things that Amazon does that are really kind of smart.
[00:15:20.880 --> 00:15:26.000]   This is a good piece. But I'm wondering how much of that kind of thinking is making its way into
[00:15:26.000 --> 00:15:31.760]   government or is government so high bound, Matt, that it's hard to change the corporate culture?
[00:15:31.760 --> 00:15:37.280]   You know, there was this video clip I remember of Eric Schmidt who said,
[00:15:37.280 --> 00:15:41.920]   "The tech industry and startups move three times faster than regular companies and
[00:15:41.920 --> 00:15:47.280]   regular companies move three times faster than the government." So it's tricky because the
[00:15:47.280 --> 00:15:51.360]   government, you know, there's a lot of risk aversion and people are worried about getting
[00:15:51.360 --> 00:15:58.160]   called up in front of Congress. At the same time, you know, if you can do a mortgage on your phone,
[00:15:58.160 --> 00:16:02.080]   it's very hard to figure out, "Okay, why do I have to sign a piece of paper over here? Why can't I
[00:16:02.080 --> 00:16:06.640]   do the equivalent of a Hello Sign, DocuSign, whatever?" And so like those things are making
[00:16:06.640 --> 00:16:14.240]   their way into government. And the wild thing is that it feels like now we have a lot of proven
[00:16:14.240 --> 00:16:19.040]   great examples. Like I love this, you know, right the right the the meeting begins with reading time
[00:16:19.040 --> 00:16:23.600]   and you've written the document in advance. We've gotten proven examples and it's just they haven't
[00:16:23.600 --> 00:16:27.840]   made it over to government yet. And so you can like literally bring in like, "I know the user
[00:16:27.840 --> 00:16:31.680]   center design is going to create a much better experience." And people think it looks risky and
[00:16:31.680 --> 00:16:35.360]   it's not really risky. It's going to make great design. It's listening to constituents.
[00:16:35.360 --> 00:16:39.440]   Exactly. Yeah, we'll see the citizens serving. And at the same time, I don't want government to
[00:16:39.440 --> 00:16:45.280]   move too fast. Our government is designed kind of not to be too fast, right? That's
[00:16:45.280 --> 00:16:50.240]   it's all the checks and balances because you don't want to be too efficient.
[00:16:50.240 --> 00:16:56.160]   Well, I was going to say in government has to serve everyone. Like when you're a company,
[00:16:56.160 --> 00:17:00.160]   you can alienate a quarter of your users or a quarter of the population because you don't care,
[00:17:00.160 --> 00:17:04.640]   but government can't really do that or shouldn't rather. Although the good news is
[00:17:04.640 --> 00:17:08.480]   corporations now do have to worry about being brought in front of Congress.
[00:17:08.480 --> 00:17:14.160]   So there is a certain parody now. Oh, that's yeah. That's real terrifying for sure.
[00:17:14.160 --> 00:17:19.280]   All right. I want to take a little break. We actually have a lot of news. Matt,
[00:17:19.280 --> 00:17:24.720]   we love having you here. It's great to have you. I didn't want to make this the Quiz Matt cuts
[00:17:24.720 --> 00:17:29.920]   show. So I appreciate you're putting up with a few questions. But as you know,
[00:17:29.920 --> 00:17:34.320]   we're here to talk about what's going on in the world of Google and tech. And we will get to that
[00:17:34.320 --> 00:17:37.280]   in just a little bit. There's actually a big breaking story we're going to get to.
[00:17:37.280 --> 00:17:42.800]   But first a word from our sponsor, Nareva. People are heading back to the office.
[00:17:42.800 --> 00:17:48.800]   The way we meet is going to change distancing and have big implications for meeting room
[00:17:48.800 --> 00:17:53.600]   audio. You're probably going to have to change your room configurations. You still want good
[00:17:53.600 --> 00:17:58.800]   mic coverage. You still want good audio. But people now have to be distanced. They may be facing
[00:17:58.800 --> 00:18:03.040]   in different directions. What you need is Nareva. Nareva makes it possible. Now,
[00:18:03.040 --> 00:18:08.880]   it's not a beam forming system. Those need adjustments often by an expensive technician.
[00:18:08.880 --> 00:18:13.600]   And it's not a tabletop system because you're going to add mics and then you have to sanitize
[00:18:13.600 --> 00:18:19.520]   mics between meetings. And in both cases, your participants are going to have to be sitting.
[00:18:19.520 --> 00:18:24.480]   You have to have marks on the table. This is where you sit, predetermined spots. This is the
[00:18:24.480 --> 00:18:28.720]   direction you face because that's where the microphone is. Wouldn't it be nice if there
[00:18:28.720 --> 00:18:32.960]   are a better way to get clear, reliable audio? But your team could still act naturally,
[00:18:32.960 --> 00:18:37.840]   still sit the way they want, still socially distanced appropriately so they feel safe.
[00:18:37.840 --> 00:18:45.920]   One analyst called Nareva, N-U-R-E-V-A Nareva Audio, the first socially distanced mic system. It's
[00:18:45.920 --> 00:18:52.960]   designed for these kinds of distanced meeting rooms. It's actually, I have to think they designed
[00:18:52.960 --> 00:18:58.080]   this before COVID-19. So it's kind of a happy coincidence. It was really just designed to make
[00:18:58.080 --> 00:19:03.200]   meeting room audio better. They use a, they actually have four patents on this technology. They call
[00:19:03.200 --> 00:19:11.120]   it microphone mist that uses digital technology to place microphones everywhere in the room and to
[00:19:11.120 --> 00:19:17.520]   automatically adjust whoever's speaking. So people can sit where they want, can face in any direction
[00:19:17.520 --> 00:19:22.960]   and still be clearly heard. Their HDL 300 system, that's the big system, has become the first microphone
[00:19:22.960 --> 00:19:29.680]   and speaker bar to be certified for large meeting spaces. That's as big as 15 by 28 feet. It fills
[00:19:29.680 --> 00:19:34.560]   a room with thousands of virtual microphones. The audio adapts automatically, no technician
[00:19:34.560 --> 00:19:40.080]   necessary. In fact, you can set it up. It's very easy to install each microphone and speaker bar.
[00:19:40.080 --> 00:19:44.320]   It's just put it up on the wall and it's there. But you'll get full room coverage. People can be
[00:19:44.320 --> 00:19:48.560]   heard from anywhere in the room no matter how they sit, how they face, how they're distanced.
[00:19:48.560 --> 00:19:54.480]   And once you get the Noreva system set in, set up, you get the device management in your hands because
[00:19:54.480 --> 00:20:00.480]   the Noreva console is web based. You can adjust settings, install firmware updates, check device
[00:20:00.480 --> 00:20:05.920]   status and more, all from a secure cloud based platform. That console comes by the way with every
[00:20:05.920 --> 00:20:10.000]   Noreva audio system. In fact, when you enroll your system, you'll even get an extra year of warranty,
[00:20:10.000 --> 00:20:17.200]   absolutely free. Noreva audio products have won numerous awards. Top new technology at ISE 2020.
[00:20:17.200 --> 00:20:21.920]   That's for the middle size system, the Noreva HDL 200. But no matter what size you're in,
[00:20:21.920 --> 00:20:27.280]   as they have systems for small, medium, large spaces, actually, they use the big one, the HDL 300
[00:20:27.280 --> 00:20:33.280]   at HubSpot, Jimi Yan, their principal collaboration engineer said, quote, "We were so impressed
[00:20:33.280 --> 00:20:40.080]   with the sound quality, the ease of install, and the ease of use of the HDL 300 was a no brainer
[00:20:40.080 --> 00:20:45.440]   for us to adopt it." To learn more about how Noreva audio is the simple cost effective way to let
[00:20:45.440 --> 00:20:51.360]   your team's distance and meetings and still act and converse naturally, go to Noreva.com/twit
[00:20:51.360 --> 00:21:00.320]   T-W-I-T. And you are eva-noreva.com/twit. We thank you so much for supporting this week.
[00:21:00.320 --> 00:21:03.920]   And Google, thank you for supporting us by going to that address if you're interested.
[00:21:03.920 --> 00:21:13.680]   Noreva.com/twit. Just before we went on the air, breaking news, John McAfee, a pioneer
[00:21:14.640 --> 00:21:22.480]   in software found dead in a Spanish prison cell, reportedly died just hours after a Spanish
[00:21:22.480 --> 00:21:27.440]   court approved his extradition to the United States. McAfee had been arrested in October
[00:21:27.440 --> 00:21:37.600]   in Barcelona. And it was being held for extradition. He was being investigated by the SEC for an IRS
[00:21:37.600 --> 00:21:43.280]   for tax evasion, failing to pay taxes on millions of dollars he earned for, among other things,
[00:21:43.280 --> 00:21:49.600]   promoting cryptocurrencies, consulting work, selling the rights to his life story. The authority said he owed
[00:21:49.600 --> 00:21:58.080]   $23 million, had he been convicted, he was facing as much as 30 years in jail, the 75-year-old John
[00:21:58.080 --> 00:22:08.080]   McAfee. Dead at the age of 75 in Barcelona, he was already on the run from the Belizean authorities.
[00:22:08.720 --> 00:22:17.520]   He was wanted for questioning concerning the murder of his neighbor. He ran for president in 2016
[00:22:17.520 --> 00:22:25.360]   in 2020, tried to get the nomination of a libertarian party. He says the tax charges were retaliation for
[00:22:25.360 --> 00:22:40.720]   that. He had a fall of 2019 launched a cryptocurrency called WAC-D or WACT. Anyway, McAfee best known,
[00:22:40.720 --> 00:22:49.600]   of course, because he was working at Lockheed in 1980 when he got a copy of an early virus called
[00:22:49.600 --> 00:22:59.680]   Brain and decided to write an antivirus program, founded the company with his name. McAfee antivirus
[00:22:59.680 --> 00:23:05.600]   was a very well-known antivirus, one of the big two for years and years and years purchased by Intel in
[00:23:05.600 --> 00:23:15.520]   2010. John McAfee dead apparently by suicide, but it's unknown at this point until an investigation.
[00:23:15.520 --> 00:23:22.720]   He was alone in that jail cell, I think. That's all there is to say about that, I guess. He was
[00:23:22.720 --> 00:23:27.040]   quite a character, is the most generous thing you could say about him.
[00:23:27.040 --> 00:23:37.600]   Where do you go after that? I'm like, "Oh, this was a tough story to talk about."
[00:23:37.600 --> 00:23:43.760]   Yeah, there's nothing really no analysis necessary, but let us also say that anyone out there,
[00:23:43.760 --> 00:23:50.240]   whenever talk of suicide exists, it can have an impact on some people. So if you have any feelings
[00:23:50.240 --> 00:23:55.040]   of depression, any desire for help, there are tons of resources out there. Suicide hotlines,
[00:23:55.040 --> 00:23:59.600]   galore, plus family and friends and doctors, and please make sure you reach out.
[00:23:59.600 --> 00:24:05.840]   National Suicide Prevention Life 9800273 talk, there's some good people there. We'll be glad to talk to
[00:24:05.840 --> 00:24:11.280]   you. I'm glad you mentioned that. Suicide is a permanent solution to a temporary problem,
[00:24:11.280 --> 00:24:20.560]   and it's never necessary. There's also a text line. You could text talk to 741741.
[00:24:20.560 --> 00:24:27.120]   I know people who work on that. I think Dana Boyd works on that, and it's amazing what they
[00:24:27.120 --> 00:24:34.560]   share with you. It's actually part of the rules now, the best practices for journalists.
[00:24:34.560 --> 00:24:37.680]   If you're reporting on a story about this, you're supposed to include the number.
[00:24:38.080 --> 00:24:42.880]   Good. I'm actually reading from the Daily Beast story, and that's exactly what they did.
[00:24:42.880 --> 00:24:51.360]   Thank you for saying that. From now on, mention that when that comes up, because it can be
[00:24:51.360 --> 00:24:58.080]   triggering, I know, to people. We don't want to lose anybody. This has been a very tough year,
[00:24:58.080 --> 00:25:06.240]   thanks to COVID for teens. It's been isolated and difficult, and a lot of teens have been struggling.
[00:25:06.880 --> 00:25:12.480]   I'm going to take that seriously. All right, Matt, now you're back in the hot seat, because
[00:25:12.480 --> 00:25:23.840]   the New York Times says Sundar Pichai sucks. Can a nice guy be an effective leader is the question
[00:25:23.840 --> 00:25:34.080]   that Times asks? Diasuki Waka Biyashi talking to restive Google executives, all anonymous, of course,
[00:25:34.640 --> 00:25:42.640]   who say that Sundar takes too long to make a decision. We have seen some blog posts.
[00:25:42.640 --> 00:25:49.040]   The guy who founded Wei's Noam Bardeen, when he left, wrote a blog post kind of
[00:25:49.040 --> 00:25:54.240]   excoriating the Google culture, saying it had turned into a big, slow-moving company.
[00:25:54.240 --> 00:25:59.120]   Do you stay in touch with people at Google, Matt, or have you?
[00:25:59.120 --> 00:26:06.960]   Oh, yeah. Absolutely. It's interesting, because even in the later days when I was at Google,
[00:26:06.960 --> 00:26:13.440]   you could definitely feel like getting a change launched was more difficult, of course,
[00:26:13.440 --> 00:26:19.840]   than the early days. But also just like, "Okay, how does it affect international markets,
[00:26:19.840 --> 00:26:25.440]   the search quality and other languages?" That sort of stuff. Some people are like, "Oh, you have to
[00:26:25.440 --> 00:26:31.920]   get all of these approvals." But also, it's a natural thing that when you are a really big company
[00:26:31.920 --> 00:26:38.160]   with a really big footprint and impact, you're going to have more scrutiny. It's hard to try to
[00:26:38.160 --> 00:26:42.240]   figure out how can you move quickly while still being big. I don't think anybody's found the
[00:26:42.240 --> 00:26:49.520]   perfect solution to that at all. Every time I wrangled or interacted with Sundar, he was always
[00:26:49.520 --> 00:26:55.120]   doing a really good job. I've only talked to him when he was running the Chrome OS division.
[00:26:55.600 --> 00:27:02.400]   But I was very impressed by his genial and nature, his intelligence, his candor. I thought he was a
[00:27:02.400 --> 00:27:09.120]   really great guy. But that does not necessarily make a great CEO. In fact, it might be the contrary
[00:27:09.120 --> 00:27:14.880]   abilities. I have to say, at the time, Barry's about eight paragraphs in. The Google executives
[00:27:14.880 --> 00:27:20.560]   complaining about Mr. Pichai's leadership acknowledge that and say he is a thoughtful and caring leader.
[00:27:20.560 --> 00:27:24.960]   They say Google is more disciplined and organized these days, a bigger and more professionally run
[00:27:24.960 --> 00:27:30.720]   company than one Mr. Pichai inherited six years ago. Is he going to say that whole pipe in?
[00:27:30.720 --> 00:27:34.720]   Well, I was just going to say what they're doing is building a story based on an archaeotype.
[00:27:34.720 --> 00:27:41.360]   Zuckerberg archetype, which is, I don't care about other people. I never apologize. I never
[00:27:41.360 --> 00:27:46.720]   about think about things. I'm just in it for, I don't know what he's in it for. Anyway, the money,
[00:27:46.720 --> 00:27:53.280]   the data, the whatever. Then you've got this sort of thing, which is, oh, he's too slow moving,
[00:27:53.280 --> 00:27:57.440]   you know, and very thoughtful and blah, blah, blah, Google's separate problems and it's slow
[00:27:57.440 --> 00:28:03.600]   moving. It is a much bigger company. It's trying to do a lot more things. But
[00:28:03.600 --> 00:28:09.920]   there's two things happening here. One is conflating the person at the top with
[00:28:09.920 --> 00:28:16.560]   the fate of the company. I know that leadership matters. You look at Intel,
[00:28:16.560 --> 00:28:23.840]   and you can just watch how leadership has just sucked a company, just down the toilet. But I also know
[00:28:23.840 --> 00:28:33.280]   that there are many people under him. Google is a company that from the outside really looks
[00:28:33.280 --> 00:28:39.840]   pretty disorganized, just in general. I don't know if I feel like the executives there
[00:28:39.840 --> 00:28:45.920]   complaining about Pichai really means much. Does that make sense? I think the New York Times is
[00:28:45.920 --> 00:28:52.000]   kind of making a story to fit a mold that it needs. Jeff was a little pissed off actually,
[00:28:52.000 --> 00:28:56.080]   as I remember. Surprise! Well, no, journalist,
[00:28:56.080 --> 00:29:00.400]   journalistically, I just came here, Kafka and I, from Rico, just went back and forth with each
[00:29:00.400 --> 00:29:04.960]   other on Twitter. I don't know if I could do well in your journalism class. I said, well,
[00:29:04.960 --> 00:29:09.520]   maybe not. I think this is based on anonymous reporting. You can write this story about any
[00:29:09.520 --> 00:29:12.160]   boss out there. Well, some people like them, some people don't. They don't like how they make
[00:29:12.160 --> 00:29:21.280]   decisions. Any boss there is. And in my tweet, I said, can you roll a scroll up?
[00:29:21.280 --> 00:29:25.920]   Yes. The more I think about this New York Times, one man trend story about Cinder Pichai,
[00:29:25.920 --> 00:29:32.240]   the more ridiculous it is, Jeff Jarvis wrote. It could be written about any boss in any organization.
[00:29:32.240 --> 00:29:37.920]   Some agree, some disagree, some like, some don't like. Go up to the prior tweet.
[00:29:37.920 --> 00:29:44.720]   And the initial tweet is, go ahead. Media, move faster, break things as Silicon Valley evil.
[00:29:44.720 --> 00:29:50.240]   Google, our CEO is thoughtful and patient. New York Times, let's do a trend story about Google
[00:29:50.240 --> 00:29:55.120]   cracking because it's not moving faster, breaking things. There is a little contradiction there.
[00:29:55.120 --> 00:30:00.720]   Mike Masnick replied to you. He said, I mean, how much do you want to bet that if Google had
[00:30:00.720 --> 00:30:05.040]   acquired Shopify, we'd be seeing New York Times story about how weak any trust is that it was
[00:30:05.040 --> 00:30:12.720]   allowed to happen. So that's another point is that the Times has a little bit of a dog in this hunt.
[00:30:12.720 --> 00:30:18.880]   But we have said on this show, Mike Elgin said at first, we said it several times that Cinder Pichai
[00:30:18.880 --> 00:30:27.600]   may not be the right man for the job. Google is making a lot of money. They've doubled their
[00:30:27.600 --> 00:30:33.600]   staff. They tripled their revenues since he took over. But it's making money the way it's always
[00:30:33.600 --> 00:30:38.960]   made money in search and advertising. Well, you can't abruptly switch. I mean,
[00:30:38.960 --> 00:30:44.800]   Google is clearly trying other things to make money. I don't think anyone who's wondering around
[00:30:44.800 --> 00:30:53.520]   going, ah, you know, not aware that search one day is going to erode. But I think they're struggling
[00:30:53.520 --> 00:30:59.040]   with how to build up that much money again. And part of that's just because they got in early.
[00:30:59.040 --> 00:31:04.000]   I mean, it's like you got in early on the web. That gives you untold advantages. And actually,
[00:31:04.000 --> 00:31:09.920]   that's why the FTC is in the Congress are looking at antitrust things now is the companies that
[00:31:09.920 --> 00:31:15.840]   got in early in these kind of newly forming networks are raking in the dough.
[00:31:15.840 --> 00:31:20.720]   And well, if they did it well, there's also, I mean, of course, Al Jazeera and Yahoo are untouchable.
[00:31:20.720 --> 00:31:23.920]   Yes. I mean, yes. I mean,
[00:31:23.920 --> 00:31:30.400]   Google to its credit did really well. Yes. Same as Amazon, same as Facebook. Apple's a little
[00:31:30.400 --> 00:31:38.640]   of an outlier there. But you know, it's interesting to me that I feel like a Larry Page Sergey,
[00:31:38.640 --> 00:31:43.920]   like they hired a lot of really great slash smart people in the early days. And then sometimes if
[00:31:43.920 --> 00:31:49.200]   Larry or Sergey or even Eric were like, we're going to go down this route. They had enough people
[00:31:49.200 --> 00:31:55.600]   who were like, maybe and it wasn't mutiny. But it was like, you know, we'll just have our backup
[00:31:55.600 --> 00:31:59.440]   plan in our pocket where if this thing doesn't work out, we're ready for the next thing. Like,
[00:31:59.440 --> 00:32:05.120]   you had a really high caliber of people. And I think they've been able to maintain that much
[00:32:05.120 --> 00:32:10.560]   better than a lot of big companies that I know of. The one thing I would just add is Google is,
[00:32:10.560 --> 00:32:16.240]   it's kind of entering, well, the whole tech industry is entering the lawyer season. Like,
[00:32:16.800 --> 00:32:21.920]   you know, the ability to talk well in front of Congress makes a difference and will for the next
[00:32:21.920 --> 00:32:27.120]   few years at least just because of the spotlight that's coming on on big tech in general. And if
[00:32:27.120 --> 00:32:33.040]   you comparing a trust or think about Sundar, you know, testifying to Congress versus Larry Page,
[00:32:33.040 --> 00:32:39.120]   you know, Larry is brilliant. He's fantastic. He has all kinds of amazing ideas, but he wouldn't be
[00:32:39.120 --> 00:32:44.960]   my first book pick to go sit down in front of, you know, the Federal Trade Commission or Congress.
[00:32:44.960 --> 00:32:50.400]   And it feels like Sundar is pretty well suited for that. You know, certainly there's areas where he,
[00:32:50.400 --> 00:32:55.920]   you know, you might say, okay, well, where's the maniacal vision or something like that? But
[00:32:55.920 --> 00:33:00.320]   Sundar does a good job of listening to, you know, the feedback that he's hearing from what I
[00:33:00.320 --> 00:33:05.520]   understand. So I think, though, from the outside, there are some clear problems at Google. One,
[00:33:05.520 --> 00:33:11.360]   of course, the firing of Tim Nick Gebru and the difficulty they're going through over in general,
[00:33:12.560 --> 00:33:18.640]   their diversity programs, their inclusiveness programs, employees seem to be a little bit upset,
[00:33:18.640 --> 00:33:24.000]   a round of variety of things, whether it's government contracts or this, or this problem with the AI
[00:33:24.000 --> 00:33:30.320]   ethics committee. And then there are a lot of people who have lost faith in Google because they
[00:33:30.320 --> 00:33:35.120]   seem to announce products, then kill them so rapidly that people are very reluctant to go all
[00:33:35.120 --> 00:33:42.400]   in on those products. You know, I'm sure there's justifications for that. But it doesn't
[00:33:42.400 --> 00:33:50.000]   look like a company on the move. And I have to say in 2020, it really felt somnolent. The Pixel 5 was
[00:33:50.000 --> 00:33:58.480]   just like a, well, we can do this. They have a new Pixel book or a new Chromebook. It really felt
[00:33:58.480 --> 00:34:02.880]   like the company and maybe because of COVID, I don't know, but it really felt like the company
[00:34:02.880 --> 00:34:08.080]   was not on the march. And I have to point out the companies, other companies like Apple took
[00:34:08.080 --> 00:34:13.840]   advantage of 2020 to really do some interesting stuff. But not
[00:34:13.840 --> 00:34:17.920]   you thinking about devices or you think I mean, like Google announced some interesting research
[00:34:17.920 --> 00:34:21.680]   around AI's interesting results around team mind that
[00:34:21.680 --> 00:34:22.700]   they announced a lot of
[00:34:22.700 --> 00:34:30.160]   Yeah. Okay. That's that's what Google I/O's keynote was, which was a lot of stuff in the labs.
[00:34:30.160 --> 00:34:35.120]   That's not a product. You know, Google's always done that from verily trying to figure out a way
[00:34:35.120 --> 00:34:43.680]   to use contact lenses to measure blood glucose failed. The project loon now shuttered. Google's
[00:34:43.680 --> 00:34:50.720]   always had a lot of interest research products that projects that doesn't mean anything as to
[00:34:50.720 --> 00:34:56.800]   to the outside world. It's just, you know, interesting. Well, Google's, I mean, Google's core value
[00:34:56.800 --> 00:35:01.840]   isn't in devices. And so when I hear you, the examples are throwing out our devices. So I'm
[00:35:01.840 --> 00:35:06.400]   trying to think what's something exciting that Google's done in the last year, something new
[00:35:06.400 --> 00:35:14.000]   and different. They're coasting. I got to say, they're much better job. That's improved immensely
[00:35:14.000 --> 00:35:19.360]   though. And it was in there in their AI. And this is this is actually a really interesting
[00:35:19.360 --> 00:35:24.080]   question. And I'm not I'm not challenging you just to be sticky. I'm thinking about, I don't know what
[00:35:24.080 --> 00:35:31.040]   that means. I'm thinking about things like where we where is the value in tech going to be? Is it
[00:35:31.040 --> 00:35:36.160]   going to be in like, I am producing devices, Allah, Apple and thinking about things like,
[00:35:36.160 --> 00:35:42.960]   Oh, what is my heads up display coming? Or is it going to be in services, Allah, Amazon? Or is it
[00:35:42.960 --> 00:35:48.960]   better services delivered through AI? And Google just hasn't figured out our monetit. Like, I truly
[00:35:48.960 --> 00:35:53.360]   am like, well, just as a reporter, tell me what they've done that's interest nest.
[00:35:53.360 --> 00:35:58.640]   Hasn't done anything in a year more than a year. I feel like they've done some interesting
[00:35:58.640 --> 00:36:03.120]   things on the cloud side. I feel like they've done some interesting works on the back end related
[00:36:03.120 --> 00:36:07.840]   to security. But a lot of these are nerdy and I don't cover them as much. And you know, when I
[00:36:07.840 --> 00:36:14.000]   look at their their TPU designs and their embedded ML efforts, I'm like, there's cool stuff there,
[00:36:14.000 --> 00:36:18.240]   but I don't know how realistic it will ever come. Chrome has had seven zero days this year.
[00:36:18.240 --> 00:36:24.400]   They just had another one this week. I mean, I mean, there's all sorts of issues. And I don't see
[00:36:24.400 --> 00:36:29.200]   amaze. I don't see anything interesting coming out of Google in the last couple of years. I really
[00:36:29.200 --> 00:36:36.240]   don't even this documents feature that they've added to workspace feels like a reheated wave.
[00:36:36.240 --> 00:36:43.840]   Maybe something that Microsoft's been doing. It doesn't seem inspired by anything. When's the last
[00:36:43.840 --> 00:36:51.120]   time they came up with a Gmail, for instance, that's that's a fair point. It was interesting in
[00:36:51.120 --> 00:36:57.920]   the chat somebody said, what about Fuchsia OS? Like, if if Google's created a whole operating
[00:36:57.920 --> 00:37:02.240]   system from scratch that most people haven't even noticed that's built from the ground up to,
[00:37:02.240 --> 00:37:06.560]   you know, provide security or something that, you know, current operating systems don't do a good
[00:37:06.560 --> 00:37:12.320]   job at. And I think Stacy makes some really good points about you don't notice all the places where
[00:37:12.320 --> 00:37:16.480]   AI is like the search team is never going to talk about all the ways that artificial intelligence
[00:37:16.480 --> 00:37:22.240]   or machine learning has improved their search. But, you know, it creates a much more defensible
[00:37:22.240 --> 00:37:26.080]   position where it's harder for, you know, other companies to try to compete in search.
[00:37:26.080 --> 00:37:31.200]   But I think you're also fair to say, look, you know, if you're thinking about outfitting your
[00:37:31.200 --> 00:37:36.000]   smart home, you know, do you think of Google first? Like, where's that? Where's that Google
[00:37:36.000 --> 00:37:42.480]   Chromebook laptop? I need that to that. Yeah, I think, I think, Leo, you everything you list,
[00:37:43.360 --> 00:37:48.080]   Google killing, well, like services, the I will be an unimpressive, the messaging mess, which
[00:37:48.080 --> 00:37:56.160]   we'll get to later, the AI ethics and equity problems, all stipulated your honor. But, but I
[00:37:56.160 --> 00:38:01.360]   think Matt's point is really important too, about the age they are in right now is, is I think two
[00:38:01.360 --> 00:38:07.200]   fold it's a lawyer run age. It's a lobbying congressional run age, where if they started doing too
[00:38:07.200 --> 00:38:12.560]   much that was too exciting and big, they would get hammered for it for overusing their power
[00:38:12.560 --> 00:38:17.200]   and going crazy. And second, it's a huge company. Now, Eric Schmidt always said that the biggest
[00:38:17.200 --> 00:38:22.000]   problem Google was going to have was what grows too big. And so it's also a Ruth Porat age,
[00:38:22.000 --> 00:38:28.240]   which is going to be about economic efficiencies. And, and, and, and so that's not exciting,
[00:38:28.240 --> 00:38:32.480]   just like Microsoft for a lot of years was not at all for, I would say it's whole damn life,
[00:38:32.480 --> 00:38:37.760]   but we'll, we'll, we'll leave that all the day was not exciting, but it became a well run company.
[00:38:38.560 --> 00:38:43.600]   And I think that's the kind of phase that Google's in. So maybe we shouldn't have a show about Google.
[00:38:43.600 --> 00:38:49.920]   I don't want to go too far down this path, but I think that it's, it's a different time for the
[00:38:49.920 --> 00:38:53.760]   company too. Well, yeah, one of the reasons we started this show, something like 12 years ago,
[00:38:53.760 --> 00:39:00.480]   was this was Google all by itself was a single company doing all sorts of interesting things,
[00:39:00.480 --> 00:39:08.000]   changing the world around us. I look, I'm, I'm a fan. I want Google to be the Google of old. I
[00:39:08.000 --> 00:39:15.280]   want it to be innovative and exciting and groundbreaking. Maybe is maybe this is just part of the life
[00:39:15.280 --> 00:39:18.640]   cycle of a, of any corporation. Well, it cites me as who's going to compete with Google,
[00:39:18.640 --> 00:39:21.600]   who's going to come up with the next new thing outside Google. I think that's where we should be
[00:39:21.600 --> 00:39:27.200]   looking. I'm going to talk about brave search in a little bit. I think that's pretty interesting,
[00:39:27.200 --> 00:39:35.280]   but I, I don't know. I don't know. I mean, you know, Chrome is the number one browser in the world by a
[00:39:35.280 --> 00:39:42.400]   huge margin. And, and in fact, what's happening is that other companies are nibbling away at Chrome
[00:39:42.400 --> 00:39:49.040]   just by duplicating it, including Microsoft, you know, using the Chromium engine and making
[00:39:49.040 --> 00:39:53.600]   their own version of Chrome. So don't just blame Google blame the entire world of mobile phones.
[00:39:53.600 --> 00:39:57.840]   Nobody's exciting us. It's all pretty much just morbid right now. Blame the entire world of browsers.
[00:39:57.840 --> 00:40:02.480]   It's arrived. It does what it's supposed to do. What do you expect? Right. So, so rather than
[00:40:02.480 --> 00:40:07.200]   looking at what's there, then we got to look at something new. Well, if any of these companies that
[00:40:07.200 --> 00:40:11.520]   are in regulatory trouble and political trouble try to do something majorly new to go into a new
[00:40:11.520 --> 00:40:16.560]   area, they're going to get body parts chopped off. Well, they're being quiet about it. But if you
[00:40:16.560 --> 00:40:22.480]   look at things like, I mean, we can talk about this, but we are about to enter into a new era of
[00:40:22.480 --> 00:40:27.360]   computing. It's going to be highly distributed. There's going to be lots of processing happening
[00:40:27.360 --> 00:40:33.120]   at each node. It's going to be both not just the processing power being distributed, but like the
[00:40:33.120 --> 00:40:40.880]   databases and networking is always distributed. All of that is going to require a different model.
[00:40:40.880 --> 00:40:45.920]   And Google's already built a lot of this at the macro level for its data centers and for the cloud
[00:40:45.920 --> 00:40:50.720]   stuff. So, you know, and they have those engineers. And then if you look at what they're doing in
[00:40:50.720 --> 00:40:56.480]   containers to run software at all these different levels, I think what we're kind of in this just
[00:40:56.480 --> 00:41:03.040]   really super boring era where people like, whatever I talk about, like machine learning at the edge,
[00:41:03.040 --> 00:41:07.200]   people are like super bored because they don't understand why it's going to be a big deal. And
[00:41:07.200 --> 00:41:11.520]   they don't understand the computer problems yet. But rest assured, the people at Google do.
[00:41:11.520 --> 00:41:15.520]   I mean, the people at Apple do as well. I mean, nobody's going to be caught flat-footed if they're
[00:41:15.520 --> 00:41:20.080]   in this world. But I agree, Google should be ascended in artificial intelligence. They might
[00:41:20.080 --> 00:41:24.800]   be. We just haven't gotten there yet. I mean, if you look at like TPU Lite, you look at their
[00:41:24.800 --> 00:41:30.080]   work with Kubernetes, you look at the partnership deals they're doing on like the industrial IoT
[00:41:30.080 --> 00:41:34.080]   side to kind of bring in some of this stuff. They're making a lot of the right moves, but no one
[00:41:34.080 --> 00:41:39.600]   gives a poop about them because they're not gadgets and they're not sexy. But you know what,
[00:41:39.600 --> 00:41:45.200]   Stacy, I think the learn products. Well, but that's okay. The other, the other
[00:41:45.200 --> 00:41:49.520]   have to be gadgets, but there's no products either. I mean, at some point, they have to.
[00:41:49.520 --> 00:41:53.840]   You can't build products until the base of the infrastructure has to be there. You can't build
[00:41:53.840 --> 00:41:58.080]   McDonald's until the freeways are there. You can't build the freeways until we figure out the best
[00:41:58.080 --> 00:42:04.000]   type of concrete to use. I mean, that's right now we're at the concrete laying state of this next
[00:42:04.000 --> 00:42:10.480]   era of computing. I really believe that. I agree Stacy. I agree. Right. Right. That's true too.
[00:42:10.480 --> 00:42:15.200]   The other thing is, and I'm not the first to say this Clay Shurkey said it, others have said it,
[00:42:15.200 --> 00:42:21.120]   it gets interesting when the technology gets boring. Watch out, watch out, Leo. I'm going to go back
[00:42:21.120 --> 00:42:28.160]   a few hundred years here. It took 150 years after Gutenberg there, have a drink, everybody,
[00:42:28.160 --> 00:42:34.560]   before we got the newspaper, the modern novel, the essay, and the market for plays because the
[00:42:34.560 --> 00:42:39.120]   technology was boring. We knew what it was. Everybody knew how to do it. It was no big deal.
[00:42:39.120 --> 00:42:45.120]   And then people started to say, oh, I can do this with it. And that's when the world around it
[00:42:45.120 --> 00:42:49.360]   gets interesting. So I think you're looking at the wrong place. What Google has done with
[00:42:49.360 --> 00:42:54.960]   translation is going to enable really interesting things to happen around the world.
[00:42:54.960 --> 00:42:59.760]   It's going to be really interesting what happens to be able to read information and literature
[00:42:59.760 --> 00:43:08.240]   because it's advanced leap years for where it was. And it's boring, fine. Others will make good use
[00:43:08.240 --> 00:43:12.880]   out of it. And that's where the excitement is. Matt, does it pain you when I attack Google like
[00:43:12.880 --> 00:43:18.240]   this? Is it like family? Do you feel like? No, no, I've got a little bit of distance. And I also
[00:43:18.240 --> 00:43:27.040]   know sometimes you stir the pot for fun. No, no, never. But I think it's interesting because Stacey's
[00:43:27.040 --> 00:43:33.360]   point about highways and concrete. If you think about it, Google is only just now, I think, presenting
[00:43:33.360 --> 00:43:39.120]   some of the stuff where they've done software-defined networking. So the joke at Google used to be,
[00:43:39.120 --> 00:43:45.680]   we didn't just build our own car. We vulcanized the rubber on the tires. And so in some areas,
[00:43:45.680 --> 00:43:50.160]   Google is only just now revealing some of the ways that they've gotten far ahead in some ways.
[00:43:50.160 --> 00:43:54.240]   And maybe they're being independently recreated at Amazon and all these other things.
[00:43:54.240 --> 00:44:00.320]   But you see that. I do think thinking about machine learning, voice recognition and
[00:44:00.320 --> 00:44:04.000]   transcription has gotten so much better even the last few years. And there was this article that
[00:44:04.000 --> 00:44:11.280]   was talking about, you can almost have a coach that teaches you to speak another language just
[00:44:11.280 --> 00:44:17.520]   using AI now. So if Google rolled out a way where I could practice my Spanish and not have awkward
[00:44:17.520 --> 00:44:22.320]   interactions with humans until I feel like I can speak better than a four-year-old,
[00:44:22.320 --> 00:44:26.800]   that would be really great for me and probably a lot of other people and lead to a lot better
[00:44:26.800 --> 00:44:30.960]   understanding around the world. And so it feels like some of this stuff, the infrastructure is
[00:44:30.960 --> 00:44:35.680]   there and you won't quite know it until people pounce. And then they're like, oh, we call everybody
[00:44:35.680 --> 00:44:40.000]   in the United States, all the businesses, once per month with AI that's indistinguishable from a
[00:44:40.000 --> 00:44:43.840]   human voice just to make sure we've got the COVID hours right or something like that where you don't
[00:44:43.840 --> 00:44:50.560]   even know it until it's done. I think Google has a problem, which is they're too successful.
[00:44:50.560 --> 00:44:55.680]   This is historically, as always, a problem in any business, especially in technology.
[00:44:55.680 --> 00:45:03.360]   They basically mint money with their advertising and search. And there isn't a huge amount of
[00:45:03.360 --> 00:45:10.800]   incentive. Everything else is at a loss. So there's literally everything else is at a loss. It's all
[00:45:10.800 --> 00:45:16.720]   other bets. But they make so much money in search that they can just kind of... Well, it's not
[00:45:16.720 --> 00:45:21.280]   search though to make the money. It's advertising. It's advertising. That's advertising. That's
[00:45:21.280 --> 00:45:25.840]   a way, yes. Well, advertising otherwise too. Yeah. Double click. But what if they're building,
[00:45:25.840 --> 00:45:30.080]   think about this, what if they're building and everyone seems to be trying to build this, a
[00:45:30.800 --> 00:45:35.520]   scalable digital assistance so everybody has a little digital voice in their ear that helps them?
[00:45:35.520 --> 00:45:38.720]   I would love that, but I see no progress in that direction. Hold on, hold on. Hold on.
[00:45:38.720 --> 00:45:40.800]   Is the assistant better than it was five years ago?
[00:45:40.800 --> 00:45:49.440]   Okay. A good, like a good assistant, you take them almost completely for granted.
[00:45:49.440 --> 00:45:53.840]   They learn what you need and they deliver it when you need it and you may never realize until you
[00:45:53.840 --> 00:45:58.160]   have a crappy assistant, how great your one was. Okay, but you're, you're writing science fiction
[00:45:58.160 --> 00:46:02.880]   at this point. Okay, fine. No, I'm not. If I look at like Matt just talked about, you know,
[00:46:02.880 --> 00:46:08.080]   things like duplex, so or calling things up to make sure the app is a good example.
[00:46:08.080 --> 00:46:15.120]   They showed that how many years ago? Two, three? Okay. I can't wait to try it.
[00:46:15.120 --> 00:46:22.480]   The point is some of the stuff they're building isn't in the methods they're building. They're
[00:46:22.480 --> 00:46:29.360]   building it so they can create ways to get information to you the way you want. And because we are
[00:46:29.360 --> 00:46:34.400]   human, they, that means they've got to figure out how to deliver something via the web, which
[00:46:34.400 --> 00:46:39.040]   they're pretty good at. They have to figure out how to deliver it in a format for Google voice type
[00:46:39.040 --> 00:46:44.880]   displays. They have to figure out how to like build routines into your smart home that makes sense
[00:46:44.880 --> 00:46:49.360]   and deliver exactly what you need. And they're working on that, but those things get announced
[00:46:49.360 --> 00:46:54.400]   as silly little features that we talk about in the change log. And if you don't bring it back to
[00:46:54.400 --> 00:46:59.920]   five years ago, so I think we're going to have to stop measuring technology based on like cool
[00:46:59.920 --> 00:47:05.280]   devices and start measuring it based on five years ago. What did my experience look like
[00:47:05.280 --> 00:47:10.400]   and today how much smoother is it? And it's going to be super incremental and we're not going to be
[00:47:10.400 --> 00:47:18.400]   odd by it. Think of the pandemic without the internet or just without Google, right? Think of
[00:47:18.400 --> 00:47:24.560]   what it would have been like without that. And it's, and again, when it gets boring,
[00:47:24.560 --> 00:47:28.000]   that means that it's useful as part of our lives. It's just integrated in.
[00:47:28.000 --> 00:47:32.000]   And if you get super bored, let's see how they ruin Fitbit.
[00:47:32.000 --> 00:47:36.800]   Well, there's a good example. They acquired Fitbit. I don't know what's happening with it.
[00:47:36.800 --> 00:47:41.200]   Android Wear is a great example of a product that never, that just like,
[00:47:41.200 --> 00:47:45.280]   Oh God, Andrew, where was terrible? I was going to tell you about Fitbit. So this is a new Google
[00:47:45.280 --> 00:47:51.760]   product that's actually, I'm using it my life today. Is it life changing? No, but okay. Here we go.
[00:47:51.760 --> 00:47:55.440]   I got a new mouth guard because I grip my teeth like a crazy person at night.
[00:47:55.440 --> 00:48:01.120]   It's not fitted well. So I started snoring and my husband was like, Stacy, you are terrible.
[00:48:01.120 --> 00:48:06.000]   And I was like, Oh no. So then I started implementing different storing solutions. And I used my
[00:48:06.000 --> 00:48:13.280]   Google display that now tracks snoring. So the second gen nest, whatever I talked about on the
[00:48:13.280 --> 00:48:19.200]   show. So I set that up. And then I was able to set up controls between like things that I was
[00:48:19.200 --> 00:48:25.520]   trying, including taping my mouth shut. Thank you, Leo, to see how I could do this. I did. It
[00:48:25.520 --> 00:48:32.000]   worked for two days. And then I figured out how to snore around it. Yeah, my life says my snoring
[00:48:32.000 --> 00:48:34.320]   with my mouth tape shut is comical.
[00:48:34.320 --> 00:48:42.880]   I'm like, it's basically, it's not effective. And when my alarm goes off in the morning,
[00:48:42.880 --> 00:48:45.120]   I can no longer say, you know, stop.
[00:48:45.120 --> 00:48:55.120]   Okay. So the point is, I was like, this was like a tiny personal problem, but I figured out
[00:48:55.120 --> 00:49:00.640]   Google offered me a tool that was really easy to use to start solving it. And
[00:49:00.640 --> 00:49:03.120]   So they're recording your snoring.
[00:49:03.120 --> 00:49:10.400]   They're they're recording it process to get on the device, analyzing it on the device,
[00:49:10.400 --> 00:49:15.840]   dumping that data and only sending you stored for nine to 12 minutes versus 30.
[00:49:15.840 --> 00:49:19.520]   So they're telling how long you snored that's interesting, I guess. Yes.
[00:49:19.520 --> 00:49:24.880]   But it's kind of sad when you have a multi trillion company.
[00:49:24.880 --> 00:49:30.480]   Telling me how much I'm sorry. And that's the thing you point to is like, look what they're doing.
[00:49:30.480 --> 00:49:36.560]   But no, what they're doing is they figured out how to do the A somewhere they figured out
[00:49:36.560 --> 00:49:40.480]   algorithms that actually in this case, it's not that hard, but they figured out
[00:49:40.480 --> 00:49:44.560]   how to break out snoring from coughing and any other nighttime noises.
[00:49:44.560 --> 00:49:48.640]   They figured out how to take that data, process it on the device, which again,
[00:49:48.640 --> 00:49:52.560]   this is not a huge difficult problem. I don't think to solve algorithmically.
[00:49:52.560 --> 00:49:57.600]   And then they've made it accessible to me through lots of other places.
[00:49:57.600 --> 00:50:02.240]   They are now bringing that technology to the wristband. So again,
[00:50:03.920 --> 00:50:09.440]   they're solving tiny problems, but unusually for they're trying to solve them well in lots of
[00:50:09.440 --> 00:50:11.760]   places. And they're going to have to solve problems to solve it.
[00:50:11.760 --> 00:50:18.880]   It's probably a good thing. Just like a university does a lot of research, kind of pro bono research
[00:50:18.880 --> 00:50:24.800]   is probably a good thing that Google's sinking a lot of money into R&D. And there's a lot of PhDs
[00:50:24.800 --> 00:50:30.640]   working hard at Google getting supported in their research. I mean, I guess it's kind of like a
[00:50:30.640 --> 00:50:35.920]   university in that respect. So imagine, you know, we did this week in AT&T.
[00:50:35.920 --> 00:50:38.720]   They haven't come out with anything since the princess phone.
[00:50:38.720 --> 00:50:43.280]   Well, I would never do this week in AT&T, but what about this week in Amazon? Amazon at their
[00:50:43.280 --> 00:50:46.800]   Amazon announced they do about 150 new products every announcement.
[00:50:46.800 --> 00:50:49.920]   AT&T had well, AT&T have bell labs. Yes.
[00:50:49.920 --> 00:50:54.960]   Yeah. So AT&T did those since I'm talking about way back in the day when it was a monopoly.
[00:50:54.960 --> 00:50:59.520]   Is it is that on a product level, you'd be bored with it, but behind the scenes,
[00:50:59.520 --> 00:51:01.600]   they were doing amazing things like the semiconductor.
[00:51:01.600 --> 00:51:07.600]   Well, hopefully AT&T or sorry, hopefully Google does not become AT&T, which is just
[00:51:07.600 --> 00:51:12.800]   regular to capture. Well, in a way, that's the question is,
[00:51:12.800 --> 00:51:18.640]   is this a normal state in the lifecycle of a big company? I mean,
[00:51:18.640 --> 00:51:22.720]   It's a different evolution. I mean, I don't think Google is going for regulatory capture because
[00:51:22.720 --> 00:51:27.040]   they're like, they don't need to. They've got, you know, all this data. I mean,
[00:51:27.040 --> 00:51:31.040]   is data monopoly? Is that a thing that we should be thinking about? I've been thinking about this a
[00:51:31.040 --> 00:51:34.800]   lot. I'm trying to write something coherent, but it's taking time.
[00:51:34.800 --> 00:51:40.480]   In a way, this is my defensive Google that says, Congress, you don't have to worry about Google.
[00:51:40.480 --> 00:51:44.000]   We're about those other guys.
[00:51:44.000 --> 00:51:49.840]   It's interesting, though, to also jump up a level and think about the tech industry.
[00:51:49.840 --> 00:51:56.720]   Because for a while, like 20, like if you said in 2020, what are the big things that happened in
[00:51:56.720 --> 00:52:01.600]   tech? A lot of it for a while was social networks, which the more we look backwards at social
[00:52:01.600 --> 00:52:06.320]   networks, well, maybe we're not getting all the benefits that we want to get. And lately,
[00:52:06.320 --> 00:52:11.200]   it seems like some of our best and brightest minds in technology are chasing, you know,
[00:52:11.200 --> 00:52:18.480]   cryptocurrency stuff. And I remain a person who feels like if you think you need to decouple money
[00:52:18.480 --> 00:52:22.080]   from government in order to fix money, maybe you should actually fix government first.
[00:52:22.640 --> 00:52:28.800]   Because guess what? Government can still come in and take care of your freedom money and do
[00:52:28.800 --> 00:52:34.320]   all kinds of interesting things to it. So, you know, the tech industry sometimes feels like it's
[00:52:34.320 --> 00:52:41.840]   taking a little bit of a weird turn. Think about semiconductors and chips and personal
[00:52:41.840 --> 00:52:47.120]   computers and desktop publishing and how the internet, all of that, huge productivity gains.
[00:52:47.120 --> 00:52:53.680]   And then in the last 10 years, has it all necessarily been good? You know, how good is your quality
[00:52:53.680 --> 00:52:57.040]   of life compared to 10 years ago because of the technology industry?
[00:52:57.040 --> 00:53:03.440]   Yeah. And again, what excites me, so I'm working on a project that I'm not ready to talk about yet,
[00:53:03.440 --> 00:53:08.160]   but I've talked about a little bit is what interests me now is internet studies, more than
[00:53:08.160 --> 00:53:15.840]   media or journalism, and the opportunity to design our future. And I think that what excites me is
[00:53:15.840 --> 00:53:20.640]   what we start to do with this outside of these companies. Now, the question is, then, do they
[00:53:20.640 --> 00:53:25.120]   make it possible? Do they make things transparent? Do they make things portable? Those are all issues.
[00:53:25.120 --> 00:53:31.920]   But even using the technologies that they patent and use eventually get used in other ways and
[00:53:31.920 --> 00:53:38.080]   inspire other things. And that's what interests me. And so I want to encourage students to think
[00:53:38.080 --> 00:53:44.080]   about designing that future, design companies and functions and features and regulatory regimes
[00:53:44.080 --> 00:53:51.120]   and ethical regimes and think about what is it we want to build. And also, when we're stuck
[00:53:51.120 --> 00:53:56.320]   in as Matt brought up the social media and our disappointment, shall we say, lightly in that.
[00:53:56.320 --> 00:54:03.920]   And all the talk is around disinformation and getting rid of bad stuff. That limits the conversation
[00:54:03.920 --> 00:54:10.400]   to can we incrementally fix what we already have? And it also entrenches the incumbents in power,
[00:54:10.400 --> 00:54:12.640]   because we're not imagining new competitors.
[00:54:12.640 --> 00:54:21.760]   Well, I think we've we've concluded this exhaust to this area. Exhausted this area.
[00:54:21.760 --> 00:54:25.520]   It was like, I just want a good Chromebook. I just want a Chromebook. I just want
[00:54:25.520 --> 00:54:30.480]   I want Stadia to work. I just they're just a few things. I'd love to see a pixel.
[00:54:30.480 --> 00:54:31.920]   You know, actually,
[00:54:31.920 --> 00:54:36.240]   You want a better pixel phone. Mine is about to die. Yeah, mine is two Stacy.
[00:54:36.240 --> 00:54:43.440]   My my 4 XL has exceeded its its battery has exceeded the width of the case is now is blossomed.
[00:54:43.440 --> 00:54:48.880]   And it's too bad because I was using Android 12, which I like quite a bit. I can't wait to
[00:54:48.880 --> 00:54:53.120]   the Pixel 6. And you know what? We this, you know, we may be saying in a couple of months,
[00:54:53.120 --> 00:54:56.080]   Wow, look what Google did with the Pixel 6. It's just mind-bogg.
[00:54:56.080 --> 00:55:01.520]   Google strapped a phone to my face. Maybe it was my wrist or maybe it's implanted in my skull.
[00:55:03.120 --> 00:55:07.040]   It really may be that, you know, I don't I don't I don't think you're something like me.
[00:55:07.040 --> 00:55:14.480]   I don't think I'm not blaming Cinder Pichai for this. That's kind of the point here. Yeah,
[00:55:14.480 --> 00:55:19.280]   coming off the New York Times story. As I said back to Kafka, there's plenty of things to complain
[00:55:19.280 --> 00:55:22.640]   about with Google right now and things to be disappointed and fine. There's stories there.
[00:55:22.640 --> 00:55:28.320]   I do think though, maybe if they had a more dynamic, it's, you know, it's too big a company.
[00:55:28.320 --> 00:55:33.120]   You can't there would be it's too late to have the dynamic CEO in place there.
[00:55:33.120 --> 00:55:34.800]   I don't think that's going to be a target on our back.
[00:55:34.800 --> 00:55:40.560]   Even mean. I what I'm sick of dynamism. Well, such a Nutella is a dynamic.
[00:55:40.560 --> 00:55:44.880]   Sacha Nutella's got his company to be his true.
[00:55:44.880 --> 00:55:50.400]   He's not dynamic. He's dynamic in terms of what he's done in Microsoft. He sure as all is.
[00:55:50.400 --> 00:55:55.120]   I don't mean. Okay, I recognize. Okay. Yeah. Well, that's what you're you're kind of
[00:55:55.120 --> 00:56:00.080]   completing the two and I know I'm not. You are. I'm I think Sacha Nutella is dynamic.
[00:56:00.080 --> 00:56:05.920]   Not personally. I'm not. I can't. It's not. He's not a dynamic in any way personally,
[00:56:05.920 --> 00:56:12.000]   but he's what he's done with the company is very dynamic. So Microsoft sounds Microsoft's
[00:56:12.000 --> 00:56:17.200]   turnabout is dynamic and you're excited about that. But Google, you're not. But you are directly
[00:56:17.200 --> 00:56:24.880]   completing Sacha and Sundar. I'm saying that it may be that having a good CEO is the difference.
[00:56:25.840 --> 00:56:31.920]   I don't think Sundar is a bad CEO. I do. Oh, okay. Well, there you are.
[00:56:31.920 --> 00:56:36.800]   There. I think he's the problem. No, I think he's the problem. I think they need somebody who
[00:56:36.800 --> 00:56:41.280]   can take do some leadership in that company. Right now, there's our show title. Sundar is the
[00:56:41.280 --> 00:56:46.400]   problem. Well, I know that I don't think the problem is that he's too thoughtful or moves
[00:56:46.400 --> 00:56:51.760]   too slowly. I don't think he's dynamic. I don't think he has the vision. He's a he's more like
[00:56:51.760 --> 00:56:56.720]   those Intel CEOs that you were talking about, Stacy, you know, the Intel CEO is a problem.
[00:56:56.720 --> 00:57:02.880]   Brian Cresnich was a terrible CEO in the sense that he could not handle people telling him
[00:57:02.880 --> 00:57:08.720]   things that he didn't want to hear. He was a bad leader. I don't think Sundar is a bad leader.
[00:57:08.720 --> 00:57:14.080]   He might be a quieter leader. And I don't know if he's ever rallied the troops with some grand
[00:57:14.080 --> 00:57:18.000]   vision for Google. And that may be an issue. Although,
[00:57:18.000 --> 00:57:23.600]   depends what you mean by a good leader. I don't think Steve Jobs was anybody who could listen to
[00:57:23.600 --> 00:57:30.000]   criticism. But I think he actually did a lot of good for the company. So I don't think that
[00:57:30.000 --> 00:57:36.640]   somebody who's nice is necessarily what you want to be honest with you. I don't think Elon Musk is
[00:57:36.640 --> 00:57:43.440]   a nice guy. But Elon Musk is his stock prices up because people are loyal to him. I mean,
[00:57:43.440 --> 00:57:47.120]   this gets back to our old conversation. Remember about financial engineering.
[00:57:47.120 --> 00:57:53.520]   No, no, no, Musk innovates. Look at how Tesla sells. Look at how Spate West SpaceX has done.
[00:57:53.520 --> 00:57:57.440]   There is no question that Musk's companies. How old is this company versus Google?
[00:57:57.440 --> 00:58:02.720]   There's a life cycle. Yeah, maybe that's what it is. TikTok. TikTok. Although,
[00:58:02.720 --> 00:58:06.240]   Microsoft's older than Google. Apple is older than Google.
[00:58:06.240 --> 00:58:10.880]   Well, in Microsoft, Microsoft was a rescue leader. That's different.
[00:58:10.880 --> 00:58:15.680]   Yeah. I don't think Google's ready for a rescue. Who is, how is it rescued by bringing in?
[00:58:15.680 --> 00:58:18.800]   Microsoft? Yes, by bringing in the right guy to run.
[00:58:18.800 --> 00:58:22.240]   You also looked good because the act he followed was knocking fucks.
[00:58:22.240 --> 00:58:31.280]   So Jeff, what you're saying that Microsoft was closely tied to windows and such a pivoted to a
[00:58:31.280 --> 00:58:36.880]   more open framework, which then, you know, naturally got him kudos and good wills and maybe helped
[00:58:36.880 --> 00:58:41.600]   pivot the company. It sounds like that's- He came from Azure. He understood the cloud.
[00:58:41.600 --> 00:58:45.440]   He understood that Microsoft's mission was not selling software and boxes,
[00:58:45.440 --> 00:58:50.080]   but was a very different mission. Pivoted the company and it's done very, very well with it.
[00:58:50.080 --> 00:58:54.080]   You're all good with your Leo. So Microsoft was very static. Now,
[00:58:54.080 --> 00:58:58.000]   bomber, bomber had the, you know, you could point to bomber and say the same thing that you could
[00:58:58.000 --> 00:59:02.480]   say about Sundar, which is, look at the revenue that the company's up. The, you know, I mean,
[00:59:02.480 --> 00:59:07.040]   the company's growing. All of those things happened under bomber, but it wasn't a company on the
[00:59:07.040 --> 00:59:14.480]   march. Okay. So let me play you for a second here and go dystopian on Google.
[00:59:14.480 --> 00:59:20.160]   I think where Google's week, of course, is not just that even though it's diversified a lot,
[00:59:20.160 --> 00:59:24.960]   advertising is still the lion's share of the revenue. I think that advertising as an industry
[00:59:24.960 --> 00:59:29.920]   is going to be in trouble soon. And that's why I'm not worried about regulation the long
[00:59:29.920 --> 00:59:33.200]   so I don't think Google's going to be king forever because it's an advertising company.
[00:59:33.760 --> 00:59:38.320]   But, but then it would be a move to them to get a little innovation under their belt.
[00:59:38.320 --> 00:59:45.360]   But then the problem becomes then they get accused of big footing, some new sector.
[00:59:45.360 --> 00:59:51.200]   Right. Right. And so what would you do if you're so real fine? You are the CEO of Google.
[00:59:51.200 --> 00:59:55.360]   Bing. What do you, what do you think Google should be doing?
[00:59:55.360 --> 01:00:03.040]   Do you think Google, I think the moon shots were too moony. I think Google should be looking
[01:00:03.600 --> 01:00:09.280]   for what its next, what its next business is. Just like Apple does, just like Microsoft does,
[01:00:09.280 --> 01:00:15.120]   a well run company. Intel is the Polaroid of tech. I mean, Intel is a poorly run company
[01:00:15.120 --> 01:00:20.320]   with a product line that did not innovate and is going down the tubes. I don't want to see
[01:00:20.320 --> 01:00:24.400]   that happen to Google. I really don't. I think you might be right about advertising. That's a
[01:00:24.400 --> 01:00:30.480]   pretty big prediction. It's going to be interesting. But I think for at least the next 10 years,
[01:00:30.480 --> 01:00:36.400]   Google can absolutely continue to be a revenue juggernaut. I don't think that's going to be a
[01:00:36.400 --> 01:00:40.000]   problem. But that was the time to figure out what the next thing is. I think.
[01:00:40.000 --> 01:00:44.400]   I agree with that. It's interesting to think about Google because they break down into very
[01:00:44.400 --> 01:00:48.720]   functional units. And so if you think of them in terms of silos, I started to make a list, right?
[01:00:48.720 --> 01:00:53.440]   You've got search, you've got ads, you've got Chrome, you've got YouTube, Android, cloud, Google
[01:00:53.440 --> 01:01:03.360]   apps or workplace or whatever they want to call it this year. But if you think about it, each one
[01:01:03.360 --> 01:01:09.840]   of those is run pretty well individually. It's hard to. It's a great success story. Absolutely.
[01:01:09.840 --> 01:01:15.520]   Yeah. And so if you distinguish between manager versus leader, I think all of those
[01:01:15.520 --> 01:01:19.440]   individual silos are managed really well. And Leo, it sounds like one of your things is,
[01:01:19.440 --> 01:01:24.400]   OK, don't just go for the moonshots with Waymo because it turns out that was harder than anybody
[01:01:24.400 --> 01:01:30.320]   thought. Where are the roof shots that are in the middle of it where you could grow to
[01:01:30.320 --> 01:01:35.760]   those kinds of juggernauts that they do have in the existing silos?
[01:01:35.760 --> 01:01:40.400]   That's an excellent point, Matt. And so if they, in a way, that's what alphabet should have been
[01:01:40.400 --> 01:01:45.280]   seen as is it's now a holding company of a bunch of good companies.
[01:01:45.280 --> 01:01:50.560]   It's a holding company. Yeah. Yeah. And then we should be calling it alphabet because that's
[01:01:50.560 --> 01:01:54.400]   really what we're talking about. And then I think Matt's analysis, of course, the problem with that
[01:01:54.400 --> 01:01:57.840]   is, OK, fine, let's break it up into five wonderful little companies, which by the way,
[01:01:57.840 --> 01:02:03.920]   might increase the hell out of shareholder value. I think it's a mistake to get too worried about
[01:02:03.920 --> 01:02:08.720]   what's going to happen in Washington, D.C. I understand that that's a legitimate fear,
[01:02:08.720 --> 01:02:12.320]   but I think that can freeze you. And that could be bad too. Yes.
[01:02:13.600 --> 01:02:19.840]   I think but also ignoring it can be really bad. Microsoft was cocky Google and Facebook were
[01:02:19.840 --> 01:02:26.560]   cocky. Most of these guys are doing it was a lot easier with the other guy in office because it was
[01:02:26.560 --> 01:02:33.040]   easier to kind of pet him. But I think most of these companies are doing the what they can to appear
[01:02:33.040 --> 01:02:39.760]   to care while they still have full speed with all the things that the antitrust regulators don't
[01:02:39.760 --> 01:02:46.240]   like. You know, you got to say the say the right words, make everybody feel good. But honestly,
[01:02:46.240 --> 01:02:50.880]   as if you're running a company at this point, you still got to want to win and play as hard as
[01:02:50.880 --> 01:02:57.040]   you can. You can't stay with it. Look, Microsoft, although, I'll argue against myself, a number of
[01:02:57.040 --> 01:03:04.240]   people pointed out that the DOJ are indictment of Microsoft helped them be a better company
[01:03:04.800 --> 01:03:10.240]   because it taught them a little fear. And it slowed them down a little bit and it gave them
[01:03:10.240 --> 01:03:15.280]   the space to pivot and to change in ways instead of just saying, let's just eat the world.
[01:03:15.280 --> 01:03:20.240]   Or you could argue that only because they were so huge and were, I'm going to argue against myself,
[01:03:20.240 --> 01:03:26.960]   monopolistic, they had the they had the room to shift. Yeah. Yeah. I mean,
[01:03:26.960 --> 01:03:32.720]   versus Intel versus other companies. I think what's happening in Washington is pretty shameful,
[01:03:32.720 --> 01:03:37.280]   to be honest with you. I'm and you're going to be surprised to hear me say this, Jeff, because
[01:03:37.280 --> 01:03:42.320]   you've been defending big tech and I've been attacking it. I'm defending the internet. I'm
[01:03:42.320 --> 01:03:46.960]   not defending big tech. I'm fearful of what doing things to the big tech will do. I think these
[01:03:46.960 --> 01:03:52.800]   bills, these five bills that we're looking at are really risky. Tim Cook called the Nancy Pelosi
[01:03:52.800 --> 01:03:56.800]   a couple of days ago saying, you know, you could put us out of business. This is,
[01:03:56.800 --> 01:04:01.120]   this is very risky what you're proposing. And it's going to really hurt consumers.
[01:04:02.240 --> 01:04:05.200]   Now, I know, obviously he's lobbying, but
[01:04:05.200 --> 01:04:12.400]   Did I put that? I put the letter that the various industry trade groups sent to Congress. Yeah.
[01:04:12.400 --> 01:04:16.960]   Well, there's the Times article here, which is tech giants, fearful of proposals to curb them.
[01:04:16.960 --> 01:04:22.800]   Bid blitz Washington with lobbying. Of course, I think there's a little slant in in this,
[01:04:22.800 --> 01:04:24.320]   but from the Times,
[01:04:24.320 --> 01:04:31.760]   he, Tim Cook told Pelosi that antitrust bills were rushed. They will crimp innovation,
[01:04:31.760 --> 01:04:36.240]   and they'll hurt consumers by disrupting the services that power Apples lucrative iPhone.
[01:04:36.240 --> 01:04:40.480]   And this is according to five people with the launch of the conversations. Wow.
[01:04:40.480 --> 01:04:45.760]   Leo, line 118, the various trade groups and their trade groups, their company groups.
[01:04:45.760 --> 01:04:50.640]   At the time when voters are looking, this is a letter to the House Judiciary Committee and
[01:04:50.640 --> 01:04:54.720]   Sicily. At the time when voters are looking to Congress to address the country's most pressing
[01:04:54.720 --> 01:04:59.120]   challenges, it seems hard to believe that Congress is instead on the verge of banning Amazon Prime
[01:04:59.120 --> 01:05:03.440]   and Amazon basics, banning the pre installation of iMessage and FaceTime on iPhones,
[01:05:03.440 --> 01:05:06.320]   and banning Google from including Google Maps and its search results.
[01:05:06.320 --> 01:05:11.760]   That starts to get to a really what consumers are you protecting here? Yes.
[01:05:11.760 --> 01:05:18.000]   Wait, hold on. Hold on. Okay. Let's in. No, this is important because I sat through the net news.
[01:05:18.000 --> 01:05:24.240]   I spent over a decade covering net neutrality and you can read these. You can read these.
[01:05:24.240 --> 01:05:31.360]   You cannot determine what a law will or will not do based on these sorts of letters. You have to
[01:05:31.360 --> 01:05:36.400]   actually read the legislation. You have to actually talk to people on, I hate to say it,
[01:05:36.400 --> 01:05:40.960]   literally both sides to figure out and you have to understand the underlying issues in a way
[01:05:40.960 --> 01:05:46.640]   that's really hard. Do I trust Cecilia Kang to do that? I do. And yet she is at the New York Times.
[01:05:46.640 --> 01:05:52.800]   But this is an area where I would read these letters, but I knew what they were going to say
[01:05:52.800 --> 01:05:59.360]   before I was reading them because I had done the legwork. And this is where news organizations
[01:05:59.360 --> 01:06:06.480]   and reporting expertise is so essential. And I'm sorry, I've been on vacation for the last 10 days.
[01:06:06.480 --> 01:06:12.320]   So I have not started doing this. But I know G.G. Zone, for example, I'm going to give her a call
[01:06:12.320 --> 01:06:16.400]   and I'm going to be like, hey, let's talk about this. And then I'll call the people who are working
[01:06:16.400 --> 01:06:23.840]   it the other. But yeah, Jeff, just no, no, I'm just what I'm saying, Stacy is I that's why I
[01:06:23.840 --> 01:06:29.040]   emphasize five times it's from trade groups from the companies. So it's pure lobbying PR.
[01:06:29.040 --> 01:06:34.880]   Well, what I am trying to say is just that it's going to be a political it's a political fight now.
[01:06:34.880 --> 01:06:39.920]   It's not a it's not right now. It's purely politics. And so there's a there's a political
[01:06:39.920 --> 01:06:44.480]   view that says at some point, if you start attacking the apps we'd like, maybe there's a political
[01:06:44.480 --> 01:06:50.400]   blowback on them. Well, it's totally political. Jayapal's bill, which basically says, you can't
[01:06:50.400 --> 01:06:55.360]   self deal. So you got to, you know, you got to stop all those things that you were just talking
[01:06:55.360 --> 01:07:01.360]   about, you know, using promoting Google maps on Google and things like that. And it's really,
[01:07:01.360 --> 01:07:06.960]   it's as if there's no antitrust law. And so you're going to write a new one.
[01:07:07.840 --> 01:07:15.120]   It is and it's not because she says and the Clayton act has to be has to be enforced.
[01:07:15.120 --> 01:07:21.600]   There is antitrust law. This is it's bizarre. I think this is very, this is very much about
[01:07:21.600 --> 01:07:27.600]   posturing, say making the right sounds. We have antitrust laws, which are not enforced in this
[01:07:27.600 --> 01:07:32.640]   country. It's a little late to tell Facebook, you got to get rid of Instagram and and WhatsApp.
[01:07:33.360 --> 01:07:40.320]   Facebook's right to point out your mechanism. Our mechanism for antitrust does not reflect
[01:07:40.320 --> 01:07:48.560]   the market advantages of the tech companies because our mechanism for antitrust results
[01:07:48.560 --> 01:07:54.560]   looks only at the prices a consumer pays or looks primarily at the price of. Well, then rewrite
[01:07:54.560 --> 01:07:59.440]   the antitrust laws, but that's not what this is. Okay. Well, okay. Have you do you remember the
[01:07:59.440 --> 01:08:05.120]   last time we wrote a big piece of legislation? It was in 1996, the Telecommunications Act. And
[01:08:05.120 --> 01:08:10.160]   we've been attacking that thing since like 2002 thinking, Hey, we should go back to this.
[01:08:10.160 --> 01:08:14.800]   And what have we done? Nothing. So well, coming at it with the new law,
[01:08:14.800 --> 01:08:19.520]   maybe it doesn't make sense, but government isn't about making sense. I mean,
[01:08:19.520 --> 01:08:24.960]   Well, and the other problem, just to build on something you were saying earlier, Stacey,
[01:08:24.960 --> 01:08:28.880]   you were talking about, Hey, to really understand the implications of these laws,
[01:08:28.880 --> 01:08:33.520]   you need reporters who have tech expertise who think about this stuff deeply, who talked to both
[01:08:33.520 --> 01:08:40.000]   sides. And I 100% agree with that. The other side is you need legislators with tech expertise,
[01:08:40.000 --> 01:08:45.600]   because otherwise you get all kinds of unintended consequences when heaven of heavens, a law actually
[01:08:45.600 --> 01:08:50.720]   does get passed. People don't always foresee how it's going to play out. Like certainly being in DC,
[01:08:50.720 --> 01:08:55.120]   I saw a lot of laws where it's like this software practice will be implemented on, you know,
[01:08:55.120 --> 01:09:02.160]   February 14th of such and such a date. And the idea of like doing beta testing or like a stage
[01:09:02.160 --> 01:09:06.960]   rollout or any of that stuff just never even occurred to people. So for example, there's a
[01:09:06.960 --> 01:09:13.440]   group called Tech Congress that puts technologists working with Congress people. And so like, if
[01:09:13.440 --> 01:09:17.920]   you're a technologist and you want to see some better laws, like the FTC is looking for technical
[01:09:17.920 --> 01:09:23.040]   people, Congress needs, you know, some of these kinds of fellows to go and help make sure that
[01:09:23.040 --> 01:09:27.440]   when laws do get passed or regulations do get passed that they're sensible and not like,
[01:09:27.440 --> 01:09:32.320]   you know, as Jeff, you've mentioned many times, like don't don't say here's what you can and can't do,
[01:09:32.320 --> 01:09:37.360]   you know, on the specific mechanism, you know, instead do it in the more general way and don't
[01:09:37.360 --> 01:09:41.680]   hard code technology into a bill necessary. Well, and I should also forward that.
[01:09:41.680 --> 01:09:48.480]   beta lawmaking or sandboxing in certain like you think about like how municipalities will
[01:09:49.200 --> 01:09:53.920]   you can look at various state or municipal governments for new ways to kind of create
[01:09:53.920 --> 01:09:58.800]   some legislation or implement different programs. It would be very interesting to
[01:09:58.800 --> 01:10:04.160]   and it might be utterly impractical because the France kind of did that. France did that.
[01:10:04.160 --> 01:10:13.520]   But I'll tell you the end of this story isn't so great. But but one of the members of the of the
[01:10:13.520 --> 01:10:16.960]   Susan Ness task force that I was part of the transatlantic high level working group on content
[01:10:16.960 --> 01:10:23.040]   moderation freedom of expression was a guy named a brilliant regulator and listen to those words
[01:10:23.040 --> 01:10:30.240]   come out of my mouth, a brilliant regulator named Benoit Lutrell who embedded inside Facebook for
[01:10:30.240 --> 01:10:36.720]   six months to imagine what it would be like to regulate Facebook and Facebook went along with
[01:10:36.720 --> 01:10:40.880]   this. And you know, the weird thing was there was nothing to regulate against. There was no law to
[01:10:40.880 --> 01:10:46.000]   do. But but he saw where it worked. And he came out with, I think, a brilliant scheme, which became
[01:10:46.000 --> 01:10:50.480]   the basis of a lot of what we recommended saying that what you you don't want government to tell
[01:10:50.480 --> 01:10:54.080]   the platforms exactly what to do because new stuff's going to happen and they're not going to know
[01:10:54.080 --> 01:10:59.680]   and they're behind. You want to have something to hold companies accountable to you want the data
[01:10:59.680 --> 01:11:04.080]   to be able to do that you want the research to be able to do that. That all came from his experience
[01:11:04.080 --> 01:11:09.280]   inside Facebook. Now then what happened, of course, in France was the legislators take it over and
[01:11:09.280 --> 01:11:14.320]   it gets kind of messed up. Same time in Britain, I was just part of a session that Susan Ness led
[01:11:14.320 --> 01:11:23.040]   today about the Digital Services Act in the EU and about the online harms thing in the UK. And in
[01:11:23.040 --> 01:11:28.240]   the UK, they're still going for you must take down legal but harmful content. And I said, well,
[01:11:28.240 --> 01:11:32.800]   what's harmful? Harmful is now defined as anything that would cause psychological or physical damage
[01:11:32.800 --> 01:11:37.360]   to people. So you're going to have courts trying to judge what psychological damage is. It's
[01:11:37.360 --> 01:11:41.280]   the mind gets blown, right? So it's not just our dumb laws. It's dumb laws. There's this, we got
[01:11:41.280 --> 01:11:47.360]   to do something thing going on. And Benoit was brilliant at saying, no, let's stand back and
[01:11:47.360 --> 01:11:53.280]   say, what's the proper role of a regulator is to hold people to account. And his argument in the end
[01:11:53.280 --> 01:11:59.120]   was nobody trusts either the tech companies or government. And then what we the real job here was
[01:11:59.120 --> 01:12:03.440]   to increase trust and the way to increase trust was to get data and research. So we knew what the
[01:12:03.440 --> 01:12:09.760]   impact was. So we made wiser decisions. This is a path that I endorse, right? I keep on worrying
[01:12:09.760 --> 01:12:14.240]   about internet regulation because I worry about the kind of stupid regulation Leo was talking about.
[01:12:14.240 --> 01:12:20.160]   Smart regulation, I agree, is a good thing. But as Matt also said, it shouldn't be down at the
[01:12:20.160 --> 01:12:25.280]   nitty gritty level. It should be up at a level of principle so that it can last for decades.
[01:12:25.280 --> 01:12:32.960]   Well, and we should point out, AT&T wasn't broken up by Congress. AT&T was broken up by the courts
[01:12:32.960 --> 01:12:39.200]   based on a law that was passed 30 years earlier. And I would say principles make really crappy
[01:12:39.200 --> 01:12:44.080]   loss. I mean, the point of a law, I mean, I'm serious. You know, makes really crappy loss.
[01:12:44.080 --> 01:12:51.280]   The Congress of the United States of America. Well, I mean, this is hard. This is this is why
[01:12:51.280 --> 01:12:57.520]   this is so tough. Amy Klobuchar is now complaining about what matter because she says, you know,
[01:12:57.520 --> 01:13:02.640]   echo is 50% of the speaker smart market. Nest is 30%. You guys are too dominant.
[01:13:02.640 --> 01:13:08.080]   I want to know what period of time you commit to support interoperability and who at your
[01:13:08.080 --> 01:13:12.560]   companies is responsible for determining whether to extend the length of your commitment to matter.
[01:13:12.560 --> 01:13:19.600]   I mean, it's so scattershot what's going on that it's ultimately going to scare the
[01:13:19.600 --> 01:13:25.600]   hell out of any company that is positioned as posturing. Right. And all of this is because
[01:13:25.600 --> 01:13:33.360]   Sonos decided to testify that, Oh, if you put theory on smart stuff, that is that.
[01:13:34.800 --> 01:13:43.360]   So does the legitimate consumer issue. No, no, the lack of interoperability between these devices,
[01:13:43.360 --> 01:13:49.360]   the amount of data they hold, the fact that the consumer has no rights when a hardware device
[01:13:49.360 --> 01:13:55.920]   becomes a software based service is something that is inherently worth looking at from a governmental
[01:13:55.920 --> 01:14:02.800]   perspective, because none of these companies pushing this have any incentive to behave well,
[01:14:02.800 --> 01:14:08.880]   absent some sort of government regulation. Why? Because consumers are scattershot and the
[01:14:08.880 --> 01:14:16.080]   the companies finally figured it out 10 years after these devices were making their way into
[01:14:16.080 --> 01:14:20.720]   people's homes, because enough people were like, Oh, crap, this is confusing and I don't want to
[01:14:20.720 --> 01:14:26.400]   invest in it. But they only decided to deal with the interoperability level, which is the matter
[01:14:26.400 --> 01:14:31.040]   stuff. We still don't have any answers or basic rights when we start talking about a device that
[01:14:31.040 --> 01:14:35.120]   is actually a service. And this is something this is exactly what government is supposed to do with
[01:14:35.120 --> 01:14:39.040]   tech. I think it's what the market is supposed to do with tech. And I think the market is currently
[01:14:39.040 --> 01:14:43.680]   no weighing in on this stuff. Look at all the people who say, I will never have an Amazon
[01:14:43.680 --> 01:14:49.680]   device in my house. I'm turning off sidewalk. I don't want to have any services and doctors and
[01:14:49.680 --> 01:14:55.920]   insurance companies and essential ingredients for living your life are going to be mediated
[01:14:55.920 --> 01:15:00.640]   through these things. This is the same issue we heard from 20 years ago when people were like,
[01:15:00.640 --> 01:15:06.960]   I don't want the internet in my home. Those people are now in their, they're gone. They have nothing
[01:15:06.960 --> 01:15:10.720]   they can't their kids can't go to school. They can't find jobs. This is
[01:15:10.720 --> 01:15:16.000]   do you really think that not having an Amazon Echo or a Google voice assistant in your home
[01:15:16.000 --> 01:15:21.440]   is going to disadvantage you in the years to come? Yes. In the years to come, not having a credible
[01:15:21.440 --> 01:15:28.080]   digital assistant will disadvantage you in your job. It will, I don't know how much it'll disadvantage
[01:15:28.080 --> 01:15:33.840]   you at home. Although with the advances in like medicine, like maybe cough to see if you have the
[01:15:33.840 --> 01:15:41.440]   flu or COVID, those sorts of things will roll out to those devices. Yes, I 100% do. And I don't
[01:15:41.440 --> 01:15:47.200]   think it's a smart speaker. I think it's access to a digital assistant. And you can tell I'm passionate
[01:15:47.200 --> 01:15:53.200]   because I never yell about these things and I threw my Bobby pin down. I got on moral panicky.
[01:15:54.400 --> 01:15:58.960]   This is this is a universal basic basic access to an assistant. Yeah, that's it.
[01:15:58.960 --> 01:16:06.480]   Well, Marissa Meyer going way back when I remember we talked about this in the show so many years
[01:16:06.480 --> 01:16:11.120]   ago. Oh, I'm doing it again. I'm going back in the years. I just can't help it. You know, I'm a
[01:16:11.120 --> 01:16:17.280]   grandpa. That's what I do. When I talked about hyper local, she she said, no, no, no, Jeff,
[01:16:17.280 --> 01:16:21.840]   the hyper personal digital assistant. She said that vision for years and years and years, but
[01:16:21.840 --> 01:16:25.120]   that also requires that the company knows enough about you to be a good assistant.
[01:16:25.120 --> 01:16:30.960]   You're right. But Stacy, I think Leo's a boy about Klomuchar is that the irony here is
[01:16:30.960 --> 01:16:37.440]   don't build a walled gardens, uh, interoperate. Okay. So that companies here, we are
[01:16:37.440 --> 01:16:41.040]   interoperating. Well, I'm worried about your interoperation. You know, it's just it's it's
[01:16:41.040 --> 01:16:45.920]   can't win. Well, she that's your job as a parent. You don't trust that your kids with her. Oh, we're
[01:16:45.920 --> 01:16:50.800]   playing just fine. You pop your head in the door and you say, really? And that's what she's doing.
[01:16:50.800 --> 01:16:56.080]   She's saying, I'm watching you. Okay. That's all this letter is. That's fair enough.
[01:16:56.080 --> 01:17:00.320]   Let's take a little break. It's great to have you here. Matt cuts formerly, uh,
[01:17:00.320 --> 01:17:04.800]   administrator of the United States digital service. He is now gainfully unemployed and
[01:17:04.800 --> 01:17:10.160]   having a good time professional vagabond. But you see, could you see yourself as being a CEO?
[01:17:10.160 --> 01:17:18.320]   Would you like to be a CEO? Hmm. I mean, it's next for you, isn't it? No, no, I will.
[01:17:18.320 --> 01:17:23.360]   That's what comes after Colonel. So it comes after Colonel. Going back into the tech industry.
[01:17:23.360 --> 01:17:28.720]   I think all the stuff we're talking about is a, there's a lot of interesting problems to
[01:17:28.720 --> 01:17:34.080]   solve in the world that aren't strictly, strictly technology. So I like that. That's true.
[01:17:34.080 --> 01:17:39.280]   We focus so much on technology, but it isn't to be on and all by any means. Absolutely.
[01:17:39.280 --> 01:17:43.120]   What kind of what at a high level, what kind of problems fascinate you these days?
[01:17:44.400 --> 01:17:47.120]   Leo is just trying to get to the break. He's just a,
[01:17:47.120 --> 01:17:52.080]   Jeff does this to me all the time. Don't worry about it, Matt.
[01:17:52.080 --> 01:18:00.080]   Oh man. Okay. So if you, if you, if you say the political system is messed up, uh, you know,
[01:18:00.080 --> 01:18:05.600]   and, and you don't have good, good legislators who know about how technology works, like all of
[01:18:05.600 --> 01:18:10.000]   these things, all of these, you know, two sides shouting at each other very loudly.
[01:18:10.000 --> 01:18:14.160]   How do you break through that? You know, it's things like money in politics. It's things like
[01:18:14.160 --> 01:18:19.520]   gerrymandering. It's things like, you know, voting. You know, all of this stuff is government is
[01:18:19.520 --> 01:18:23.120]   the people who show up and the people who show up need to represent America and they need to do
[01:18:23.120 --> 01:18:28.000]   it well. And it feels like everybody is tuning out of all the things that are happening in DC.
[01:18:28.000 --> 01:18:31.760]   They're not participating there when they could really make things work a lot better in a lot of
[01:18:31.760 --> 01:18:36.880]   cases and maybe even lighter touch and maybe a lot more efficient. And it's part of some
[01:18:36.880 --> 01:18:42.720]   folk strategy to make people want to tune out. And that's crazy. That's true. You're absolutely right.
[01:18:42.720 --> 01:18:48.000]   That put people on the moon. Like, there's no excuse for us to tune out. We need to figure out how
[01:18:48.000 --> 01:18:53.040]   to fix some of these problems. And it feels like technology could help in some ways. And there's
[01:18:53.040 --> 01:18:56.880]   just so many good, hearted people that have had the privilege of working with and the honor of
[01:18:56.880 --> 01:19:03.120]   working with. And so those kinds of things, how do you know, what's the aim is people cheating on
[01:19:03.120 --> 01:19:07.120]   Google and in the web search results, right? That's a hairball of evil. Where are the other
[01:19:07.120 --> 01:19:11.040]   hairballs of evil? There's all kinds of people who need help. Sounds like public service might be
[01:19:11.040 --> 01:19:17.120]   in your future. Continuing public service. Congress, Matt, I'll follow you.
[01:19:17.120 --> 01:19:23.520]   No, going, he'll be our representative from Ottawa. It'll be great. I can't always
[01:19:23.520 --> 01:19:30.080]   are represented from the internet from Elle. You know, should there be a internet representative
[01:19:30.080 --> 01:19:34.560]   in Congress? I think that's not a bad idea. I think statehood for Washington and statehood
[01:19:34.560 --> 01:19:37.360]   for the internet. Yeah. Yeah. Now we're talking later eyes.
[01:19:38.960 --> 01:19:47.200]   Internet does not want to be part of Congress. John Perry, but no, memes going all anyway. Okay.
[01:19:47.200 --> 01:19:54.320]   Jeff Jarvis is also here. Leonard Taub professor for journalistic innovation at the Craig Newmark
[01:19:54.320 --> 01:19:59.680]   Graduate School of Journalism at CUNY. Great to have you. And of course, Stacy Higginbotham,
[01:19:59.680 --> 01:20:05.280]   I didn't give you guys your due. So let me give you your plugs. Stacy Higginbotham from Stacy
[01:20:05.280 --> 01:20:13.440]   on IOT.com, where everything matters at Gigastacey on the Twitter. And don't forget to subscribe to
[01:20:13.440 --> 01:20:19.680]   our newsletter. And more matters and more. And listen to her great podcast with Kevin Tofill,
[01:20:19.680 --> 01:20:25.040]   who has refused to be on this show. And now I think I know why. So because he's pursuing a graduate
[01:20:25.040 --> 01:20:30.320]   degree in theater science. Oh, is that it? Oh, yeah, sure. And Matt and I need Kevin's advice for
[01:20:30.320 --> 01:20:37.840]   Chromebooks. Yeah. You have time for your blog. No, no, we asked, we've asked, and he said,
[01:20:37.840 --> 01:20:42.320]   no, I'm just, he said, literally, I'm too busy with my master's. So I understand that he's going
[01:20:42.320 --> 01:20:49.280]   to be a teacher. Is that his goal? He's getting a credential? Well, he wants to teach at his local
[01:20:49.280 --> 01:20:53.680]   community college because he's done enough classes there and he helps work with the kids there.
[01:20:54.640 --> 01:21:00.480]   So great. He calls him his young links. It's really nice. And they're getting great jobs. And he just
[01:21:00.480 --> 01:21:08.400]   wants to like, just to like help people succeed. I love him so much. He's so good. He's like a good
[01:21:08.400 --> 01:21:17.840]   person. He's kind of the Mac cuts of. Yes. Python. Yeah. He's attacking smaller hairballs. Yeah,
[01:21:17.840 --> 01:21:24.560]   little hairballs, little bitty hairball. Every hairball matters. Every hairball is made up of a lot
[01:21:24.560 --> 01:21:28.400]   of a lot of little hairballs, little hairballs all the way down.
[01:21:28.400 --> 01:21:37.120]   Our show today brought to you by AT&T active armor. We rely so much on our phones these days.
[01:21:37.120 --> 01:21:42.000]   And we're always on them, whether it's live streaming content catching up with family on
[01:21:42.000 --> 01:21:48.720]   weekly video calls, watching your favorite show. There's no room for fraud calls. Nothing worse,
[01:21:48.720 --> 01:21:53.680]   right? You know what? The guys, the fraud guys, this time I got a message saying, okay,
[01:21:53.680 --> 01:22:01.600]   you're warned. He's not really expiring. But we'd like you to extend it. It's like, I know that's a
[01:22:01.600 --> 01:22:08.080]   fraudulent call. Thankfully, that's not on my AT&T phone. AT&T makes customer security a priority,
[01:22:08.080 --> 01:22:16.720]   helping block those pesky calls. It's not complicated. AT&T active armor 24/7 proactive network security
[01:22:16.720 --> 01:22:21.680]   and fraud call blocking to help stop threats and no extra charge.
[01:22:21.680 --> 01:22:28.160]   Capitable device and service required, visit att.com/active-armour for details.
[01:22:28.160 --> 01:22:34.960]   And we thank active armor and AT&T for sponsoring this week in Google on a lighter note.
[01:22:34.960 --> 01:22:42.640]   What was the greatest headline of all time, Jeff Jarvis? I had those body and topless bar.
[01:22:42.640 --> 01:22:48.240]   That was the New York Post. New York Post, yes. I think this is a rival from the New York Times.
[01:22:48.800 --> 01:22:54.720]   When an eel climbs a ramp to eat squid from a clamp, that's a moray.
[01:22:54.720 --> 01:23:03.680]   I really did appreciate that person. Isn't that a great headline? Let me give credit to,
[01:23:03.680 --> 01:23:10.960]   is it, you think it's a copy editor or the writer? Oh, copy editor. Oh, yeah. Yeah, the writers
[01:23:10.960 --> 01:23:16.080]   like, had a real publication, professionals, right? You can suggest it.
[01:23:16.080 --> 01:23:22.400]   Not Sabrina Emler. Sabrina Emler has a story about, this is it, an eel
[01:23:22.400 --> 01:23:32.560]   that is eating in public. When an eel wants a squid that's on land, God forbid, that's a moray.
[01:23:32.560 --> 01:23:37.840]   It's a moray eel. And actually, scientists are very excited about this video because
[01:23:37.840 --> 01:23:45.200]   they were able to get the moray to emerge, to eat this food so that they can see its second set of
[01:23:45.200 --> 01:23:53.600]   jaws, slurping it down after the first set of jaws gets it. It's a snowflake moray eel named
[01:23:53.600 --> 01:24:00.960]   Chani. It bites a squid. Godly a name for a moray eel. Sorry, no, I'm not.
[01:24:00.960 --> 01:24:10.240]   It's the secret set of jaws that evolutionary biologists at UCSC were trying to film and they
[01:24:10.240 --> 01:24:19.040]   succeeded. Congratulations to Dr. Rita S. Meta, the pharyngeal jaw, no longer a mystery.
[01:24:19.040 --> 01:24:23.760]   I just wanted to read that headline out loud. That's a great story.
[01:24:23.760 --> 01:24:29.280]   I just want to appreciate their people in this world who are dedicated to finding this stuff out.
[01:24:29.280 --> 01:24:35.200]   I love that the world has people like this. Yeah. So this is her life work, Dr. Meta.
[01:24:35.200 --> 01:24:43.520]   In 2007, she was the first to describe the pharyngeal jaws, but she's been trying to get
[01:24:43.520 --> 01:24:52.720]   video of it. And they finally figured out if you make it come up a ramp, this is a whole thing.
[01:24:52.720 --> 01:24:55.440]   I think it should be on TikTok myself.
[01:24:55.440 --> 01:25:01.680]   You know, I've been after this because I'm trying to prove Sasquatch exists.
[01:25:01.680 --> 01:25:05.600]   Oh, really? All of my research efforts. Nothing has come of that.
[01:25:05.600 --> 01:25:07.840]   I mean, that's secretly why I moved up to Seattle.
[01:25:07.840 --> 01:25:13.760]   The truth comes out. Are you sincere? Because I have a friend, we call him Squatch.
[01:25:13.760 --> 01:25:23.120]   He used to be one of the hosts on tech TV, Scott Harriet, who has he retired from television
[01:25:23.120 --> 01:25:28.800]   to pursue his life's goal of proving Sasquatch's existence sincerely.
[01:25:29.920 --> 01:25:34.000]   Okay, this is not one of my sense here, but I like that there are people out there who are
[01:25:34.000 --> 01:25:38.080]   working on this. We actually didn't. I'm just trying to think of something we don't know about
[01:25:38.080 --> 01:25:42.640]   that we haven't filmed yet. Santa Claus was the first thing and I was like, eh? Yeah.
[01:25:42.640 --> 01:25:50.880]   If you want to know more, go to his website, Squatchfilms.com. I am not kidding.
[01:25:50.880 --> 01:25:58.160]   The thing is, you know, Squatch is living his best life. Squatch is probably not worried about
[01:25:58.160 --> 01:26:04.000]   regulatory regimes. No, it's not. It's internet. Now, now Squatch is just he's loving life.
[01:26:04.000 --> 01:26:09.760]   I think you'll be interested in Scott's kind of magnum opus, which is called a Squatch-elips now.
[01:26:09.760 --> 01:26:21.280]   I love it. Available for rental. There's also a DVD and a Blu-ray. If you want,
[01:26:21.280 --> 01:26:26.240]   there's Scott in the middle there doing push-ups. Looking quite happy. Yeah, that's right.
[01:26:26.240 --> 01:26:33.200]   He's actually, was it? Does Squatch, does Squatch wear Crocs? That would make sense.
[01:26:33.200 --> 01:26:37.920]   I don't know what the Croc deal is. They're using them so that they can do their push-ups, I guess.
[01:26:37.920 --> 01:26:46.880]   I, you know, it's, what can I say? What can I say?
[01:26:46.880 --> 01:26:54.640]   How did we get onto this? Oh, yeah. Amore. Amore. Moving on. Let's see. Chromebooks. You
[01:26:54.640 --> 01:27:01.440]   wanted to talk about Chromebooks. It happened today. Samsung has slipped out a new Chromebook,
[01:27:01.440 --> 01:27:08.560]   the Galaxy Chromebook Go with a 14-inch display and Intel Celeron quietly launched.
[01:27:08.560 --> 01:27:14.960]   It is, yes, I'm sorry to say Jeff. Jeff doesn't want an affordable Chromebook.
[01:27:14.960 --> 01:27:19.120]   No, no, I want to rip off Chromebooks. I absolutely want to rip off. He doesn't want to save money.
[01:27:19.120 --> 01:27:26.080]   No, no, no, no. Yeah. Some sacrifices have been made in this Chromebook, although you can't get
[01:27:26.080 --> 01:27:34.800]   8 gigs of RAM, but it is, yes, it's a lower cost Chromebook. Sorry. Sorry. I think,
[01:27:34.800 --> 01:27:41.600]   I think that the man has the best Chromebook out there, the Acer spin. Is it the 715? Is that what
[01:27:41.600 --> 01:27:46.960]   it is? 713. I think 713. Yeah. 713. How's the keyboard, man? I wasn't this crazy about that
[01:27:46.960 --> 01:27:52.320]   when I went to Best Buy and the father of the board. It's okay. You know. It's no Chromebook.
[01:27:52.320 --> 01:27:58.400]   It's okay. It's what we have to do the best you can with what you have, where you are, right?
[01:27:58.400 --> 01:28:03.760]   So what about the Google? It's innovation together. Were you tempted by the Google Go at all?
[01:28:03.760 --> 01:28:06.640]   I tried it and gave it to my mom, I think.
[01:28:06.640 --> 01:28:12.320]   That's the laptop. Not the, what am I talking about? Wait a minute. Wait a minute.
[01:28:12.320 --> 01:28:16.800]   Wait a minute. You tried it, didn't like it. And so you gave it to your mother?
[01:28:16.800 --> 01:28:25.920]   That seems, I did. I'm going to own it. I'm going to own it. So there was an incident.
[01:28:25.920 --> 01:28:31.520]   There was a caller who said that, hey, your computer has a virus. So you clearly need to go to
[01:28:31.520 --> 01:28:38.880]   this website. And so that Windows computer was radioactive, or at least that's what I said.
[01:28:38.880 --> 01:28:43.360]   Please don't pass this on to my mom. And I'm like, well, we're done with Windows. I guess we got
[01:28:43.360 --> 01:28:48.480]   a switch to Chromebook. And so the timing just happened to work out where I was like, I'll try
[01:28:48.480 --> 01:28:53.840]   it. And if I like it, great. And if I don't, then it's yours since mom, you know, the trickle down
[01:28:53.840 --> 01:28:58.320]   effect, we all do it. Oh no. All my laptops go to us already else. That's right. Yeah.
[01:28:58.320 --> 01:29:00.160]   Usually not within a few minutes.
[01:29:03.440 --> 01:29:10.000]   Guilty. Usually I get to use it for a while. Actually, Windows 11 comes out tomorrow.
[01:29:10.000 --> 01:29:16.880]   We're going to be doing a special tomorrow morning, 8am Pacific, 11am. Get it? 11 Eastern.
[01:29:16.880 --> 01:29:21.520]   Panos, Penne, and the Microsoft team are going to announce the next version of Windows. We'll be
[01:29:21.520 --> 01:29:26.240]   covering it. Paul, throughout Mary Jo Foley will join me for that live coverage. And then we'll do
[01:29:26.240 --> 01:29:32.720]   a special Windows weekly shortly after talking about the brand new version of Windows.
[01:29:33.440 --> 01:29:41.360]   Here's a good, good business. The CCTV, a closed circuit TV company is paying remote workers in
[01:29:41.360 --> 01:29:50.000]   India to yell at armed robbers. I should maybe we should play this video. Oh, you have to contact
[01:29:50.000 --> 01:29:55.360]   them for demos. Shoot. I think there was too much. My favorite part about. Go ahead. Oh, sorry.
[01:29:55.360 --> 01:29:59.840]   I was going to say my favorite part about this story is it drives home the fact that right now,
[01:29:59.840 --> 01:30:03.680]   a lot of what we think of is like super advanced AI and robotics.
[01:30:03.680 --> 01:30:11.920]   So like, dude in India is shouting at people who are robbing stores. There's a laundry folding
[01:30:11.920 --> 01:30:17.440]   robot that's really just a person that controls the robot arms. That's not that's not going to ever.
[01:30:17.440 --> 01:30:20.640]   There's somebody who calls the restaurant for you when you think the machine is doing it. Yeah,
[01:30:20.640 --> 01:30:27.920]   that's exactly. That's a duplex. So in a short closed circuit TV video, a clerk at a small convenience
[01:30:27.920 --> 01:30:33.280]   store can be seen. I wish we could play these, but they I guess too many people were downloading them.
[01:30:33.280 --> 01:30:39.120]   This is from motherboards vice. Vice's motherboard, I should say, can be seen taking a bottle of coffee
[01:30:39.120 --> 01:30:44.560]   from a cooler and drinking it when he returns to the cash register. An unseen person's voice
[01:30:44.560 --> 01:30:49.680]   emits from a speaker on the ceiling and asks him, did you scan and pay for that item?
[01:30:49.680 --> 01:30:54.640]   In another video, a cashier standing behind the counter talking to someone just out of frame.
[01:30:54.640 --> 01:30:59.840]   There's a ding sound and the voice from above questions the cashier about who is that guy?
[01:30:59.840 --> 01:31:04.160]   He's there to give the cashier right at the end of his shift and orders the man to stand on the
[01:31:04.160 --> 01:31:11.840]   other side of the counter. Washington based live eye surveillance, $399 $399 a month.
[01:31:11.840 --> 01:31:19.440]   Some poor guy in carnal India watches the feed from your business 24/7 and then
[01:31:20.000 --> 01:31:25.280]   compress a button and say, hey, maybe there's audio in this. Let's see here. Let's see.
[01:31:25.280 --> 01:31:37.600]   Oh, it's a robbery in progress. Well, what's a guy in India going to do about that? Hey, stop it.
[01:31:37.600 --> 01:31:44.720]   Knock it off. I'm coming here from India to get you. No, okay. That was just a little bit of an
[01:31:44.720 --> 01:31:49.760]   accent. Just a small accent. There would be so much more funny if I did it in this.
[01:31:49.760 --> 01:31:56.960]   Oh my God, these are terrible. What are these videos? I don't want to see these. This is awful.
[01:31:56.960 --> 01:31:58.960]   Yeah, I'm not sure this is going to be helpful. No.
[01:31:58.960 --> 01:32:08.160]   The live eye system dings and a voice informs the robbers the police have been called and they
[01:32:08.160 --> 01:32:14.160]   run out of the store. What wimps? Here it is.
[01:32:14.160 --> 01:32:18.560]   Let him do the accent.
[01:32:18.560 --> 01:32:29.440]   And they run out. They leave. They go, what? Oh, okay. Never mind.
[01:32:31.600 --> 01:32:38.320]   Please call 911 and just check outside if they have come by car. Please try to take their
[01:32:38.320 --> 01:32:47.360]   registration number as well. I wonder how much he makes per hour for do. Nothing.
[01:32:47.360 --> 01:32:57.200]   Let's see. Hyundai has bought Boston Robotics. That's really interesting.
[01:32:57.200 --> 01:33:03.760]   $880 million. The Korean auto manufacturer is bottom. They bought a controlling stake,
[01:33:03.760 --> 01:33:09.040]   but didn't they already have a stake too? Oh, let's see. Hyundai Motors, Hyundai
[01:33:09.040 --> 01:33:15.200]   Mobas, Hyundai Glovis, and Hyundai Motor Group, chairman will have 30%, 20%, 10%, and 20%
[01:33:15.200 --> 01:33:22.640]   respectively. 30, 50, 60, 80% total. Carry the one. Carry the one.
[01:33:23.840 --> 01:33:28.880]   So 800 million out of their $1.1 billion valuation. I don't know who has the remaining 30%.
[01:33:28.880 --> 01:33:34.320]   I like this story. I think we're walking to Pyongyang.
[01:33:34.320 --> 01:33:38.240]   Yeah, I don't know what's going to happen. That's interesting. I like this story. This is really an
[01:33:38.240 --> 01:33:47.600]   interesting unintended consequence story. In Argentina in the mid 2010s, the government was
[01:33:47.600 --> 01:33:59.040]   giving netbooks to kids in the slums to wire them up. As a result, these kids started making music,
[01:33:59.040 --> 01:34:06.240]   and some of these kids are now massive stars in Argentina thanks to these inexpensive,
[01:34:06.240 --> 01:34:11.040]   basic computers that they were given when they were young.
[01:34:14.640 --> 01:34:21.120]   I think that's a really great story. By the way, SoftBank owns the remaining 20%
[01:34:21.120 --> 01:34:25.600]   of Austin. SoftBank. Okay, thank you very much. And the deal was announced in December and
[01:34:25.600 --> 01:34:31.600]   just closed. I'm done. Oh, oh, oh, oh, oh, I'm just behind. I'm just behind. I'm just behind.
[01:34:31.600 --> 01:34:37.760]   That's all she Googled it. Yeah. When he first opened his Connector Iguale d'Ad
[01:34:37.760 --> 01:34:44.880]   netbook in 2014, the 10 inch black screen reflected Matteo Palacios Corazina's face back at him,
[01:34:44.880 --> 01:34:50.800]   a 12 year old boy from La Boca, one of Buenos Aires historic slums about to turn on his first
[01:34:50.800 --> 01:34:55.600]   computer. What he neither he nor those who had handed out the device knew was that a new era of
[01:34:55.600 --> 01:35:01.200]   Argentine music was about to be launched. But that six about that one gig ram machine,
[01:35:01.760 --> 01:35:09.840]   Matteo became a star using his netbook as a makeshift computer. He is now known as Truno or Trueno,
[01:35:09.840 --> 01:35:14.640]   one of the fastest. It makes you have computer. It's a real computer, makes you have studio.
[01:35:14.640 --> 01:35:18.880]   Yeah, makes you have studio. It's a well, the net book is not exactly a real computer. Let me tell
[01:35:18.880 --> 01:35:25.360]   you. But you know what? That's the point, right? The cheap computer, but it did the job.
[01:35:25.360 --> 01:35:29.440]   Yeah, it's what I can do. Yep. He's one of the fastest rising stars in Latin American rap.
[01:35:30.800 --> 01:35:37.440]   Pretty good story. This is from restoftheworld.org, reporting global tech stories.
[01:35:37.440 --> 01:35:45.200]   I didn't know. I feel like we've interviewed somebody who is involved with this, but I can't
[01:35:45.200 --> 01:35:53.840]   remember. The program or rest of the world? Rest of the world. Somebody from this has been on our
[01:35:54.720 --> 01:36:00.720]   shows or something like that. Oh, it's so much. It's OK. It's also from Sophie Schmidt.
[01:36:00.720 --> 01:36:09.200]   Yeah, Sophie Schmidt. Yeah. So yeah, yeah, Michael Donahoe. Yeah. So a lot of the people that we know,
[01:36:09.200 --> 01:36:16.080]   this was, yeah, this was started to say, to give a voice to some of these really interesting
[01:36:16.080 --> 01:36:21.680]   stories that just don't get covered in mainstream press in the US. Restoftheworld.org.
[01:36:22.800 --> 01:36:28.880]   Give them a little plug. Let's see what else here that we have. What else?
[01:36:28.880 --> 01:36:38.320]   Peloton. Did you see this? Wow. So Peloton, which is the bicycle company, they do a spin bike.
[01:36:38.320 --> 01:36:43.760]   Actually, a full disclaimer, have a Peloton bike for which I pay $40 a month for spin classes I
[01:36:43.760 --> 01:36:50.640]   never take. But I think that's a fair deal. They also made a treadmill somewhat later.
[01:36:51.680 --> 01:36:56.800]   And the treadmill had, I mean, on my Peloton spin bike, I could do a spin class. In fact,
[01:36:56.800 --> 01:37:03.360]   I could sit on the bike, spin, and use somebody else's spin classes on my TV, like Apple's fitness
[01:37:03.360 --> 01:37:10.960]   classes. The Peloton treadmill had a just run feature. But unfortunately, following the tragic
[01:37:10.960 --> 01:37:18.000]   death of a six-year-old and 72 injuries, including broken bones, cuts, and graces, Peloton had to
[01:37:18.000 --> 01:37:21.840]   recall the treadmill. And as part of the recall, they said, we're going to introduce new features
[01:37:21.840 --> 01:37:28.560]   to improve the safety. One of the features is treadlock, which locks the treadmill behind a
[01:37:28.560 --> 01:37:36.560]   passcode when idle. So kids can't come in and use it. However, it's only available to Peloton
[01:37:36.560 --> 01:37:42.720]   subscribers. So you can no longer just run on this treadmill. You have to pay a $40 subscription fee.
[01:37:42.720 --> 01:37:46.080]   You want to go after an evil company, or try this one. If you want to lock it, correct?
[01:37:46.080 --> 01:37:53.840]   No, if you want to use it, if you want to use it, you can no longer use the treadmill unless you're
[01:37:53.840 --> 01:37:59.440]   a subscriber. It's just a dead song. Remember how I said our hardware devices are becoming software
[01:37:59.440 --> 01:38:03.920]   services. And we need to talk about how to regulate that from a consumer point of view.
[01:38:03.920 --> 01:38:11.360]   Yeah, people are very upset. Brianna Wu tweeted, wow, the Peloton tread will no longer allow you to
[01:38:11.360 --> 01:38:16.800]   use your $3,000 treadmill without a $40 a month subscription. The pretext is their design issues
[01:38:16.800 --> 01:38:22.720]   led to a child's death. Somebody responded to her, the ransomware business model is quite lucrative.
[01:38:22.720 --> 01:38:31.440]   Peloton understands this is a public relations problem. They are giving three months free
[01:38:31.440 --> 01:38:38.880]   to tread plus owners. But I'm curious how many people
[01:38:40.400 --> 01:38:46.720]   the bike you were charged for the bike on a monthly basis. Yes, for the class. No,
[01:38:46.720 --> 01:38:53.680]   no, so you buy the treadmill, the hardware for $3,000. The classes are an additional $40 a month.
[01:38:53.680 --> 01:38:58.320]   That's the treadmill. But on the bike, can you just read the bike without the classes? Yes,
[01:38:58.320 --> 01:39:02.560]   but is the bike? But no child has been injured by the bike, I guess. I don't.
[01:39:02.560 --> 01:39:06.400]   Right. No, I'm just trying to figure out like what percentage of Peloton owners,
[01:39:07.200 --> 01:39:13.520]   the bike owners don't pay for a subscription. Oh, I bet you a lot of them. You know how it is,
[01:39:13.520 --> 01:39:17.600]   you buy exercise equipment, you spend the money on it for a while, then you just, you know, I'm
[01:39:17.600 --> 01:39:22.000]   not using it that much. I stopped the subscription, but I still have a spin bike, which I can use as
[01:39:22.000 --> 01:39:27.600]   a spin bike with some other input or just to ride it. But not the case with this treadmill.
[01:39:27.600 --> 01:39:34.800]   Peloton did say that they have a voluntary recall where you can return your tread plus for a full
[01:39:34.800 --> 01:39:39.120]   refund by contacting member support. So you can get your money back.
[01:39:39.120 --> 01:39:42.560]   Oh, well, then that's fine. Then basically what they're doing is they're changing the terms
[01:39:42.560 --> 01:39:46.240]   upon which you would buy this device. That's right. And as long as they're saying you can give it
[01:39:46.240 --> 01:39:50.880]   that. I mean, of course, I would require them to pay shipping back to them because that is not
[01:39:50.880 --> 01:39:57.280]   cheap. It's expensive. We had to have a Peloton person come and install it. There's a whole thing.
[01:39:57.280 --> 01:40:02.800]   It's expensive to ship. It's an installation process. Don't piss off Bradley.
[01:40:03.360 --> 01:40:10.160]   This is a great story. I it's such a good story. I'm a fan of the Atari because my first personal
[01:40:10.160 --> 01:40:16.320]   computer was an Atari 400 back in the late 70s. And then an Atari 800. It kind of got me into the
[01:40:16.320 --> 01:40:23.280]   thing. If there is a guy who has bought up all of the new remaining parts, he has a warehouse in San
[01:40:23.280 --> 01:40:29.280]   Jose, the world's largest remaining collection of factory original replacement Atari parts.
[01:40:30.480 --> 01:40:38.240]   It's called best electronics. But apparently he's the soup, Nancy of Atari parts. You have to be nice.
[01:40:38.240 --> 01:40:47.600]   Because most of Coda's customers adore him, writes vice. He's a skilled service technician with an
[01:40:47.600 --> 01:40:53.440]   encyclopedic knowledge of Atari systems. He helps customers put the joy back in their joysticks
[01:40:53.440 --> 01:40:58.480]   with fresh replacement circuit boards. He's been known to diagnose complex Atari ailments over the
[01:40:58.480 --> 01:41:03.920]   phone. He even occasionally produces his own fresh runs of crucial replacement parts when his
[01:41:03.920 --> 01:41:09.680]   vintage stock runs dry. But even those who love buying from Coda admit they experience a slight
[01:41:09.680 --> 01:41:18.160]   tingling of animal fear every time they order from best electronics. If I if you call him too
[01:41:18.160 --> 01:41:22.560]   many times a month, he gets annoyed with you. If you try to order too many things, he gets annoyed
[01:41:22.560 --> 01:41:28.240]   with you. It just comes down to having to adapt the way he does business. But once you're on his
[01:41:28.240 --> 01:41:35.120]   list, it's really hard to get off. He's famous for ignoring and blacklisting badly behaved
[01:41:35.120 --> 01:41:42.480]   customers as he is for selling Atari parts. Learn the rules or accept your fate. This is
[01:41:42.480 --> 01:41:50.160]   what I love about technology, right? These guys who've been keeping this for decades,
[01:41:50.160 --> 01:41:56.640]   he's been keeping this alive. He will not accept PayPal orders under $50. That's it. Just won't.
[01:41:57.440 --> 01:42:03.200]   Do not buy more than a few items at a time. He will not handle large orders. Repeated attempts
[01:42:03.200 --> 01:42:06.800]   to convince him to make an exception will cause your future emails to be ignored.
[01:42:06.800 --> 01:42:13.520]   Well, and the reporter reached out to him and was like, can I do an interview and the guy
[01:42:13.520 --> 01:42:20.000]   blacklisted a reporter? We're all blacklisted now by the way. I hope you don't have an Atari
[01:42:20.000 --> 01:42:31.680]   computer you want. I love this guy. I will Bradley, you're on our show anytime you want to come on.
[01:42:31.680 --> 01:42:37.360]   I admire you for doing that. I really loved my Atari computer, although I don't have one. Maybe
[01:42:37.360 --> 01:42:46.800]   I wonder if he sells whole computers. He sold out now. Samsung, we did mention,
[01:42:46.800 --> 01:42:50.400]   I should have mentioned this when I mentioned the new Chromebook. Samsung is having an event.
[01:42:50.400 --> 01:42:55.280]   I don't know if Jason decided we want to cover this or not. I think what we're not going to cover
[01:42:55.280 --> 01:43:01.920]   it, but we'll do a tech break right after June 28th. This is their mobile world congress event
[01:43:01.920 --> 01:43:10.160]   announcing their new Android Wear-ish watches. Remember, Samsung was using Tizen as its watch
[01:43:10.960 --> 01:43:15.680]   operating system. The problem was they didn't have access to the Google Play Store. Google at IO
[01:43:15.680 --> 01:43:21.520]   announced, and I don't really understand what they mean. They're going to merge Wear OS and Tizen
[01:43:21.520 --> 01:43:29.360]   together so that the new Galaxy watches will run apps from the Wear store, which makes me think
[01:43:29.360 --> 01:43:36.320]   that it's just Galaxy Wear. I'm confused because I thought they were merging with the
[01:43:36.320 --> 01:43:41.280]   other ones. They used the word merge. We were confused when this was launched and announced,
[01:43:41.280 --> 01:43:47.760]   and Leo had thought that basically Tizen goes away. We're just waiting to see what it acts.
[01:43:47.760 --> 01:43:52.880]   Wear goes away. One of them goes away. It won't be Wear going away. Wear should go away.
[01:43:52.880 --> 01:43:58.560]   But the Wear has the Play Store, and that was the thing Galaxy watches were suffering from as you
[01:43:58.560 --> 01:44:04.560]   couldn't add other apps. You had very limited apps. I don't know. Do you wear an Android Wear-watch?
[01:44:04.560 --> 01:44:07.040]   Anybody? Anybody? Android Wear? Anybody?
[01:44:07.040 --> 01:44:09.040]   >> Herman. >> Bitbit.
[01:44:09.040 --> 01:44:12.160]   >> Nobody. >> Yeah, Garmin. Oh, you're a runner, Matt.
[01:44:12.160 --> 01:44:16.080]   That's the sign that you're a runner. >> Slow runner.
[01:44:16.080 --> 01:44:19.040]   >> Slow runner. >> I get vaccine donuts, everyone.
[01:44:19.040 --> 01:44:24.000]   >> When you were a tech. Oh, that's right. Yeah, yeah. Are you training for a marathon, you said?
[01:44:24.000 --> 01:44:29.200]   >> So they haven't been doing marathons for a year, and they just have started to ramp back up.
[01:44:29.200 --> 01:44:33.680]   So I've got friends in California, one who wants to run a marathon in every state.
[01:44:33.680 --> 01:44:38.400]   And she said, you know, Vermont in September, and I'm like, that gives me some time to train,
[01:44:38.400 --> 01:44:42.400]   and Vermont's pretty close to Canada, which is-- >> You could just run up to Canada.
[01:44:42.400 --> 01:44:47.440]   That would be like a four-day run. >> Yeah, you could do that.
[01:44:47.440 --> 01:44:49.440]   >> Yeah. >> You could do a 30-day challenge.
[01:44:49.440 --> 01:44:54.160]   You could do that. >> Long run. But yes, hopefully going to do another marathon soon and
[01:44:54.160 --> 01:44:58.800]   get back into it. >> Are you at the Krispy Kreme by the DuPont Circle subway stop?
[01:44:58.800 --> 01:45:04.960]   >> Yes. >> I love that Krispy Kreme. >> It's such a good one, and they know you now.
[01:45:04.960 --> 01:45:09.200]   Like, I walk in, and I just start to reach for my wallet, and they're like, vaccine donut.
[01:45:09.200 --> 01:45:12.960]   I'm like, yeah, I don't even have to bring out the photocopying vaccine.
[01:45:12.960 --> 01:45:15.440]   >> Vaccine donut? >> Yeah. Yeah.
[01:45:15.440 --> 01:45:20.240]   >> They have a pile. They have a pile with bags. They're just like, here's your vaccine.
[01:45:20.240 --> 01:45:23.680]   >> Here's your vaccine donut. Enjoy it. >> That's great.
[01:45:23.680 --> 01:45:30.480]   You know, the idea was you'd come and buy 13 of them. All right. How do you know that Krispy Kreme
[01:45:30.480 --> 01:45:37.360]   Stacy, did you spend time on DuPont Circle? >> I, A, every now and then I visited Washington,
[01:45:37.360 --> 01:45:44.960]   DC for my job and stayed around there. But B, we did our baby moon, and we stayed right by there,
[01:45:44.960 --> 01:45:51.040]   and every day, every trip we took, we went by it and walked in and bought it.
[01:45:51.040 --> 01:45:57.680]   >> Aww. Donuts make everything better. >> I was pregnant. So the fact that I gained
[01:45:57.680 --> 01:46:01.280]   like 10 pounds on that trip for beating Krispy Kreme's, that was fine.
[01:46:01.280 --> 01:46:08.080]   >> Let me just, let me just see. According to Google Maps, it's going to take me 43 hours to
[01:46:08.080 --> 01:46:14.160]   drive there via I-80. But I could be there in four days, Matt.
[01:46:14.160 --> 01:46:18.320]   >> I'll just see Krispy Kreme donut. >> I'll get my free donut.
[01:46:18.320 --> 01:46:21.520]   >> No, they're no good, Matt. You got to get them fresh.
[01:46:21.520 --> 01:46:27.360]   >> No, no, no, no. If you put them in the microwave for eight seconds, they're fine.
[01:46:27.360 --> 01:46:31.760]   >> You're kidding. >> Depends on your microwave, between seven and nine seconds,
[01:46:31.760 --> 01:46:33.360]   depending on how many watts your microwave is.
[01:46:33.360 --> 01:46:36.960]   >> And Stacy has a controlled hot sign and the window starts flashing.
[01:46:36.960 --> 01:46:44.080]   >> Wow. So Stacy, speaking of hot, you were in Austin, and it was pretty warm. They're having
[01:46:44.080 --> 01:46:48.960]   a heat wave, right? >> Yeah, so I didn't notice it was any warmer than it.
[01:46:48.960 --> 01:46:53.200]   >> It's always warm. >> It was just like, "Oh, it's summer in Austin." But it was hot,
[01:46:53.200 --> 01:46:58.960]   and apparently the grid was having some issues. So two things came out of this.
[01:46:58.960 --> 01:47:04.640]   One, I talked to a lot of my former neighbors and friends about the Texas utility grid,
[01:47:04.640 --> 01:47:09.840]   because they had their thing in February. But two, I started seeing these stories about
[01:47:09.840 --> 01:47:13.760]   everyone's smart thermostats taken over their house and turned into the heater.
[01:47:13.760 --> 01:47:16.960]   >> Yeah, turned it up the AC. >> Yeah, turn it up.
[01:47:16.960 --> 01:47:22.320]   >> Yeah, yeah, yeah. >> And my friends didn't have this problem. So I was really confused
[01:47:22.320 --> 01:47:26.720]   when I started seeing all these pissed off stories. And I was like, "What is happening?"
[01:47:26.720 --> 01:47:32.320]   And here's the deal. People were like, "I can't believe I signed up for a smart thermostat.
[01:47:32.320 --> 01:47:35.680]   This is not the smart thermostats fault." >> It's energy hub's fault.
[01:47:35.680 --> 01:47:40.720]   >> It's energy hub's fault. So I participated in a demand response program.
[01:47:40.720 --> 01:47:45.360]   I participated actually in one of Austin Energy's first ones, like before--
[01:47:45.360 --> 01:47:52.080]   >> Is this Urkat? >> Urkat is the energy-- they manage the energy grid in Texas.
[01:47:52.080 --> 01:47:54.560]   >> Okay. Because we-- they were in the news, of course,
[01:47:54.560 --> 01:47:59.600]   but when it got really cold in Texas a couple of months ago.
[01:47:59.600 --> 01:48:06.880]   >> That's because Urkat is the managing-- that's because the Texas grid does not
[01:48:06.880 --> 01:48:11.920]   attach to many other grids. And Urkat is the entity that runs it. And the reason why we had such--
[01:48:11.920 --> 01:48:17.680]   sorry, Texas had such issues during the freeze is because they couldn't borrow power from any
[01:48:17.680 --> 01:48:24.560]   else. It's not the only reason. Anyway, okay. So this issue-- it's not your smart thermostat.
[01:48:25.280 --> 01:48:31.600]   It's how your energy company implements a program. And in Austin, you got an $80 rebate if you
[01:48:31.600 --> 01:48:34.960]   signed up for this program. >> So they agreed for $80 bucks.
[01:48:34.960 --> 01:48:38.800]   >> Hold on. Hold on. This is-- you want to go back to my favorite thing on Eagle?
[01:48:38.800 --> 01:48:41.040]   I know I talk too much. Just hold on. Go to the family.
[01:48:41.040 --> 01:48:43.680]   >> No, no, no. I'm the one who talks too much. You don't talk too much.
[01:48:43.680 --> 01:48:49.840]   >> I paid-- or I bought my thermostat. They gave me an $80 discount for every one of these,
[01:48:49.840 --> 01:48:54.160]   and they said, "This is how it's going to work." When they started a demand response
[01:48:54.160 --> 01:48:57.840]   incident, so every afternoon they were like, "Oh crap, we've got a shed load."
[01:48:57.840 --> 01:49:04.080]   I would get an email and my nest or my ecobee would show me via a notification on the device
[01:49:04.080 --> 01:49:08.560]   and via a notification on my phone saying, "Hey, we're going to change your thermostat."
[01:49:08.560 --> 01:49:15.200]   At that point in time, you could opt out or you could do something like turn your thermostat down
[01:49:15.200 --> 01:49:19.200]   a little bit because they would only move it up by four degrees. So if you wanted it to stay
[01:49:19.200 --> 01:49:22.880]   78 but you still wanted to feel like you were helping, you could do whatever.
[01:49:22.880 --> 01:49:27.200]   >> So wait a minute. So you could override what they did so they turn it up and you could
[01:49:27.200 --> 01:49:28.640]   just go over there and say, "Oh shit, oh shit."
[01:49:28.640 --> 01:49:33.600]   >> You could only override it if you caught it in time.
[01:49:33.600 --> 01:49:34.080]   >> Ah.
[01:49:34.080 --> 01:49:38.080]   >> Once the demand response started, you were just like host.
[01:49:38.080 --> 01:49:38.640]   >> Oh.
[01:49:38.640 --> 01:49:39.360]   >> Okay.
[01:49:39.360 --> 01:49:39.920]   >> Oh.
[01:49:39.920 --> 01:49:40.400]   >> So--
[01:49:40.400 --> 01:49:43.280]   >> But you got any books to do this. You agreed to do it, right?
[01:49:43.280 --> 01:49:48.160]   >> Yes. And you agreed. Now, Austin Energy is a municipally owned energy
[01:49:48.720 --> 01:49:54.320]   company and they have, I would say, an incentive to not piss off their rate payers and the taxpayers.
[01:49:54.320 --> 01:50:01.280]   In Texas, much of the energy market is deregulated and you have power companies
[01:50:01.280 --> 01:50:04.640]   and then you have third party providers like Energy Hub, which--
[01:50:04.640 --> 01:50:08.400]   >> They're not the power company. They're just the management company.
[01:50:08.400 --> 01:50:11.920]   >> They're just a management company that manages their demand response.
[01:50:11.920 --> 01:50:19.120]   And they signed up people by offering them the chance to enter a $5,000 sweepstakes.
[01:50:19.120 --> 01:50:19.600]   >> Oh.
[01:50:19.600 --> 01:50:24.800]   >> And they said, "Hey, do you want to win $5,000? Because if you do,
[01:50:24.800 --> 01:50:28.320]   you should totally participate in demand response. It's going to be amazing. You could use your
[01:50:28.320 --> 01:50:30.240]   smart thermostat and blah, blah, blah."
[01:50:30.240 --> 01:50:35.120]   >> What was the-- besides the economic incentives, was there some sort of pitch that like why this
[01:50:35.120 --> 01:50:39.760]   would be good for you? It's good for-- obviously, it's good for the neighborhood.
[01:50:39.760 --> 01:50:42.960]   So this gets into one of my big things.
[01:50:42.960 --> 01:50:52.240]   So I think these programs should be very transparent. I think if you're going to have an
[01:50:52.240 --> 01:50:56.960]   unregulated industry, tricking people using everybody's favorite dark patterns, that's a
[01:50:56.960 --> 01:50:59.520]   bad sign and people are going to be pissed and you're going to--
[01:50:59.520 --> 01:51:01.440]   And this is ultimately-- and here comes my thing--
[01:51:01.440 --> 01:51:07.040]   bad for all of us because as Texas so recently discovered,
[01:51:08.400 --> 01:51:12.080]   you need-- when you've got a shed load, it's like public health.
[01:51:12.080 --> 01:51:16.000]   Everyone has to shed load. You all have to behave well.
[01:51:16.000 --> 01:51:20.000]   >> Here in California, they just turn off your electricity.
[01:51:20.000 --> 01:51:24.160]   >> Well, but that's a slightly-- that's a wild higher issue.
[01:51:24.160 --> 01:51:30.480]   >> Yeah. But literally, we sit around here during the summer months and wait to see if the
[01:51:30.480 --> 01:51:36.560]   power is going to get turned off. They call it a public safety power shut off or paps or pssps.
[01:51:36.560 --> 01:51:42.240]   And you know what, Texas could go that way because of these stupidly implemented programs,
[01:51:42.240 --> 01:51:45.280]   because at a certain point in time, it is a health issue to say,
[01:51:45.280 --> 01:51:49.280]   it's going to be 100 degrees outside and we're not going to have power.
[01:51:49.280 --> 01:51:55.760]   This whole story in the way it was covered is just so appalling because we did nothing to--
[01:51:55.760 --> 01:52:00.320]   we just outrage, outrage. We did nothing to educate people. We did nothing to point--
[01:52:00.320 --> 01:52:03.840]   I'm not assigning blame, like, they suck.
[01:52:03.840 --> 01:52:06.480]   I'm assigning blame like you would for an engineering issue.
[01:52:06.480 --> 01:52:08.720]   >> It wasn't-- it wasn't properly solved.
[01:52:08.720 --> 01:52:10.080]   No, I think I agree with you.
[01:52:10.080 --> 01:52:10.080]   >> Yeah.
[01:52:10.080 --> 01:52:10.880]   >> Yeah, yeah, yeah.
[01:52:10.880 --> 01:52:15.440]   >> It was a miscommunication.
[01:52:15.440 --> 01:52:18.320]   But it was duplicitous.
[01:52:18.320 --> 01:52:21.280]   >> Because they used dark patterns.
[01:52:21.280 --> 01:52:26.160]   >> Yes. I mean, the way my utility did it, everyone I talked to in Austin,
[01:52:26.160 --> 01:52:31.280]   I mean, I was hanging out with friends. They're like, oh, we got to go out tonight to--
[01:52:31.280 --> 01:52:34.400]   we can't stay at the house because it's a demand response event.
[01:52:34.400 --> 01:52:34.880]   We got to go.
[01:52:34.880 --> 01:52:35.200]   >> Oh, wow.
[01:52:35.200 --> 01:52:36.320]   >> I was like, oh, yeah, we got to go.
[01:52:36.320 --> 01:52:39.040]   >> Oh, wow, everybody knew. They knew.
[01:52:39.040 --> 01:52:40.480]   >> Wow.
[01:52:40.480 --> 01:52:43.040]   >> Because they were told and they signed up and they knew about it
[01:52:43.040 --> 01:52:45.760]   and they acted like responsible people because of it.
[01:52:45.760 --> 01:52:46.240]   >> Right, right.
[01:52:46.240 --> 01:52:48.160]   >> Okay, sorry.
[01:52:48.160 --> 01:52:52.320]   >> It was a very bad week for Bitcoin this week.
[01:52:52.320 --> 01:52:57.040]   In a number of interesting ways.
[01:52:58.320 --> 01:53:01.920]   So the price obviously went down, but that's not really the main thing.
[01:53:01.920 --> 01:53:07.600]   China is shutting down over 90% of its Bitcoin mining capacity.
[01:53:07.600 --> 01:53:13.200]   China just kind of woke up to the fact that most Bitcoin miners are in China,
[01:53:13.200 --> 01:53:18.240]   and many of them in Sichuan province, and they were closed on Sunday,
[01:53:18.240 --> 01:53:23.040]   an intensified nationwide crackdown against cryptocurrency
[01:53:23.680 --> 01:53:31.360]   mining. That's a lot of capacity, so much so that the hash rate, the rate at which transactions
[01:53:31.360 --> 01:53:35.200]   and new Bitcoin are mined has dropped by 50%.
[01:53:35.200 --> 01:53:37.520]   Whoops, that's an ad.
[01:53:37.520 --> 01:53:39.120]   Not-- there we go. There's that.
[01:53:39.120 --> 01:53:41.040]   >> Wait, wait, wait, wait.
[01:53:41.040 --> 01:53:43.360]   I'm dumb Jeff moment here.
[01:53:43.360 --> 01:53:49.680]   I would think that when the supply is down, the price would go up.
[01:53:49.680 --> 01:53:51.440]   >> No, it doesn't work that way.
[01:53:52.560 --> 01:53:53.680]   Oh, isn't that cute?
[01:53:53.680 --> 01:54:00.480]   No, the price for Bitcoin has nothing to do with anything, including how much Bitcoin there is.
[01:54:00.480 --> 01:54:05.920]   However, I have to say, it feels like this could be a risky thing for Bitcoin, because
[01:54:05.920 --> 01:54:10.960]   it is true that if you make less money, you don't-- you're just less instead of to be a miner.
[01:54:10.960 --> 01:54:14.480]   Only right now, the reason there were so many in Sichuan provinces,
[01:54:14.480 --> 01:54:15.840]   because energy was very cheap.
[01:54:18.560 --> 01:54:23.840]   And so it is the case that if the price of Bitcoin goes down, your incentive to mine goes down,
[01:54:23.840 --> 01:54:29.200]   which means you may have fewer miners, which at that point means the hash rate slows down,
[01:54:29.200 --> 01:54:32.720]   which means transactions slow down. Bitcoin becomes more of a hassle.
[01:54:32.720 --> 01:54:40.480]   It is kind of a bad negative spiral, a negative circle.
[01:54:40.480 --> 01:54:44.160]   Then there's-- and then there's just bad news in general.
[01:54:45.600 --> 01:54:53.520]   In South Africa, there were two brothers who were creating a Bitcoin investment fund.
[01:54:53.520 --> 01:55:00.320]   They had raised 69,000 Bitcoins worth about almost $4 billion.
[01:55:00.320 --> 01:55:04.800]   They've disappeared now with the Bitcoin.
[01:55:04.800 --> 01:55:06.080]   >> There was Sasquatch.
[01:55:06.080 --> 01:55:11.600]   >> They're living with BD Cooper and Sasquatch up in the Pacific North.
[01:55:11.600 --> 01:55:14.720]   >> They went to the World On Lab and they got some viruses.
[01:55:14.720 --> 01:55:17.520]   >> Yeah. >> And then they went to Sasquatch.
[01:55:17.520 --> 01:55:21.040]   >> So this is another bad thing that happens sometimes.
[01:55:21.040 --> 01:55:26.720]   I think it shakes confidence in it. So all of this together might not be--
[01:55:26.720 --> 01:55:29.600]   I wouldn't be buying a lot of Bitcoin right now.
[01:55:29.600 --> 01:55:35.760]   >> So I put up just a little gif of the falls on a tweet that I just said,
[01:55:35.760 --> 01:55:40.560]   and all the boy, the cyber boys are so sensitive.
[01:55:40.560 --> 01:55:44.640]   >> Well, yeah, because you're hitting them where it hurts and the breadbasket there.
[01:55:44.640 --> 01:55:48.080]   >> Well, I lost two.
[01:55:48.080 --> 01:55:49.040]   >> You have Bitcoin?
[01:55:49.040 --> 01:55:54.880]   >> My $500 became like $12,000 is now down to $4,000, but fine.
[01:55:54.880 --> 01:56:00.800]   >> That's part of the problem with a cryptocurrency is the unlike stocks where the
[01:56:00.800 --> 01:56:04.960]   movement sort of tied to the performance of a company unless you're game stopper, ANSI.
[01:56:04.960 --> 01:56:05.920]   >> Wait, wait, wait.
[01:56:05.920 --> 01:56:09.680]   We had this argument late a month ago.
[01:56:09.680 --> 01:56:10.720]   >> You're not proven to me.
[01:56:10.720 --> 01:56:11.280]   >> Nothing.
[01:56:11.280 --> 01:56:13.520]   >> You didn't prove it to me.
[01:56:13.520 --> 01:56:17.520]   But anyway, it's kind of sort of tied to it.
[01:56:17.520 --> 01:56:20.400]   But Bitcoin, what is the price?
[01:56:20.400 --> 01:56:26.640]   It's whatever people pay, I guess, which is volatile.
[01:56:26.640 --> 01:56:27.280]   Let's put it that.
[01:56:27.280 --> 01:56:29.200]   >> That is capitalism at its finest.
[01:56:29.200 --> 01:56:30.240]   >> It's pure--
[01:56:30.240 --> 01:56:31.200]   >> People pay for health care.
[01:56:31.200 --> 01:56:31.600]   >> Capitalism.
[01:56:31.600 --> 01:56:32.640]   >> Let's see.
[01:56:32.640 --> 01:56:33.520]   >> Yeah.
[01:56:33.520 --> 01:56:34.080]   How much?
[01:56:34.080 --> 01:56:34.960]   How high can we go?
[01:56:34.960 --> 01:56:37.200]   All right, let's do a change log.
[01:56:37.200 --> 01:56:37.760]   What do you say?
[01:56:37.760 --> 01:56:38.960]   And then we can wrap this thing up.
[01:56:38.960 --> 01:56:40.800]   But you want to play that music there, Burke?
[01:56:40.800 --> 01:56:42.160]   I don't have a long change log.
[01:56:42.160 --> 01:56:46.000]   >> That's because you were lazy putting it together.
[01:56:46.000 --> 01:56:46.480]   >> I did.
[01:56:46.480 --> 01:56:47.600]   >> Google change log.
[01:56:47.600 --> 01:56:53.040]   >> No, because I have the strongly held, if not factually based position,
[01:56:53.040 --> 01:56:54.400]   that Google's not doing nothing.
[01:56:54.400 --> 01:56:57.840]   [laughter]
[01:56:57.840 --> 01:57:00.640]   So why are we even doing a change log?
[01:57:00.640 --> 01:57:01.600]   No, they do some things.
[01:57:01.600 --> 01:57:02.240]   For instance--
[01:57:02.240 --> 01:57:04.720]   >> I'll tell you, the next thing that's going to come is Stacey's, we're getting canceled.
[01:57:06.400 --> 01:57:07.200]   >> I mean--
[01:57:07.200 --> 01:57:08.720]   >> Wait a minute, this one I did last week.
[01:57:08.720 --> 01:57:11.040]   I can't-- I need newer stuff.
[01:57:11.040 --> 01:57:11.840]   That's an old one.
[01:57:11.840 --> 01:57:13.040]   Here--
[01:57:13.040 --> 01:57:13.840]   >> We'll put this together.
[01:57:13.840 --> 01:57:15.040]   >> You're right, this is terrible.
[01:57:15.040 --> 01:57:20.560]   Chrome Books getting a new update for the hybrid classroom,
[01:57:20.560 --> 01:57:22.720]   some new features in Chromebooks.
[01:57:22.720 --> 01:57:26.400]   Automatic updates for eight years on devices.
[01:57:26.400 --> 01:57:28.160]   I think that's very, very good.
[01:57:28.160 --> 01:57:30.320]   They're going to roll out in August,
[01:57:30.320 --> 01:57:34.320]   pin logins for education users as part of the device setup.
[01:57:34.320 --> 01:57:35.040]   That'll make it easy.
[01:57:35.040 --> 01:57:38.080]   You don't have to-- you know, I always do a little bit of a problem with a Chromebook,
[01:57:38.080 --> 01:57:40.080]   is you had to enter your Google password.
[01:57:40.080 --> 01:57:44.080]   Or if you had an Android phone, you could pair it to it and that worked.
[01:57:44.080 --> 01:57:48.000]   But now you can just type in a simple six-digit pin.
[01:57:48.000 --> 01:57:53.920]   So when students set up their Chromebook, they'll be prompted to set up their pin.
[01:57:53.920 --> 01:57:55.120]   I think that's a good thing.
[01:57:55.120 --> 01:58:00.240]   Chromebooks will have the live caption feature now.
[01:58:00.240 --> 01:58:02.400]   That's-- we've heard that, I think, at Google I/O.
[01:58:03.840 --> 01:58:07.600]   For students who need alternate input into their Chromebook, they're switch access.
[01:58:07.600 --> 01:58:11.520]   There's a full screen magnifier to help users better understand
[01:58:11.520 --> 01:58:14.560]   the screen reader ChromeVox.
[01:58:14.560 --> 01:58:16.800]   They've released new tutorials.
[01:58:16.800 --> 01:58:21.200]   So all of this-- it's time to think about back to school already.
[01:58:21.200 --> 01:58:21.920]   Sorry, kids.
[01:58:21.920 --> 01:58:25.920]   And Chromebooks are getting some new updates for the high-year launch.
[01:58:25.920 --> 01:58:26.960]   >> The Snow Day is over.
[01:58:26.960 --> 01:58:27.920]   >> Yeah.
[01:58:27.920 --> 01:58:33.280]   And two days ago, Monday was-- I didn't know this-- world music day.
[01:58:34.000 --> 01:58:41.200]   Also known as FET de la Musique, an annual celebration of music, Google Arts and Culture,
[01:58:41.200 --> 01:58:49.040]   created a FET de la Musique, a music party, two new experiments, paint with music and assisted
[01:58:49.040 --> 01:58:50.400]   melody. You want to try?
[01:58:50.400 --> 01:58:52.560]   Some of these, let's do paint with music.
[01:58:52.560 --> 01:58:54.400]   All right, we're loading right now.
[01:58:54.400 --> 01:58:55.680]   Turn on my sound, Burke.
[01:58:55.680 --> 01:59:01.600]   This is one of those Google experiments at artsandculture.google.com.
[01:59:01.600 --> 01:59:04.160]   What do you want?
[01:59:04.160 --> 01:59:06.560]   In the sky, underwater, on the street, or on paper?
[01:59:06.560 --> 01:59:07.440]   >> Underwater.
[01:59:07.440 --> 01:59:09.760]   >> Underwater reminds me of more eels.
[01:59:09.760 --> 01:59:11.920]   >> Yes. That's some of it.
[01:59:11.920 --> 01:59:15.760]   So now, you can choose your instrument down here.
[01:59:15.760 --> 01:59:18.480]   Flute saxophone trumpet, violin--
[01:59:18.480 --> 01:59:19.840]   >> I want blobs.
[01:59:19.840 --> 01:59:20.480]   >> Or whale.
[01:59:20.480 --> 01:59:20.960]   >> I want blobs.
[01:59:20.960 --> 01:59:23.920]   There's-- that's a whale.
[01:59:23.920 --> 01:59:29.600]   That's a violin.
[01:59:30.240 --> 01:59:31.680]   Sounds just like the whale.
[01:59:31.680 --> 01:59:32.320]   Oh, there it is.
[01:59:32.320 --> 01:59:33.360]   >> I said that sounded like a whale.
[01:59:33.360 --> 01:59:35.200]   >> Oh, that's cool.
[01:59:35.200 --> 01:59:38.480]   So I'm drawing and then it plays later.
[01:59:38.480 --> 01:59:41.600]   This is really boring.
[01:59:41.600 --> 01:59:48.320]   I didn't piss on your Gutenberg story.
[01:59:48.320 --> 01:59:53.040]   I mean, all right.
[01:59:53.040 --> 01:59:54.960]   >> I mean, it ain't no--
[01:59:54.960 --> 01:59:55.440]   you're right.
[01:59:55.440 --> 01:59:57.040]   It ain't no blob orchestra.
[01:59:57.040 --> 01:59:58.080]   I'll grant you that.
[01:59:58.080 --> 01:59:59.680]   I'll grant you that.
[01:59:59.680 --> 02:00:00.400]   By the way, yeah.
[02:00:00.400 --> 02:00:03.040]   I mean, blob is worth at least one bad eye out.
[02:00:03.040 --> 02:00:04.960]   >> No, that's true.
[02:00:04.960 --> 02:00:07.360]   >> How about assisted melody?
[02:00:07.360 --> 02:00:08.640]   This was actually launched a year ago,
[02:00:08.640 --> 02:00:11.760]   but for World Music Day, there's a new version.
[02:00:11.760 --> 02:00:14.880]   So let's try this and see how boring this will be.
[02:00:14.880 --> 02:00:18.400]   You can-- we played with this, I think, when it came out.
[02:00:18.400 --> 02:00:20.800]   So you want to compose on box organ?
[02:00:20.800 --> 02:00:22.640]   That sounds painful.
[02:00:22.640 --> 02:00:25.920]   >> Can't help yourself, can you?
[02:00:25.920 --> 02:00:28.160]   >> No, not with the word organ.
[02:00:28.160 --> 02:00:29.200]   Now, let's harmonize.
[02:00:29.840 --> 02:00:31.280]   >> I used to play the organ.
[02:00:31.280 --> 02:00:32.000]   >> Did you?
[02:00:32.000 --> 02:00:33.120]   Well, get on over here.
[02:00:33.120 --> 02:00:35.040]   Training.
[02:00:35.040 --> 02:00:36.400]   So this has been--
[02:00:36.400 --> 02:00:39.600]   Look at that.
[02:00:39.600 --> 02:00:41.120]   I wrote that.
[02:00:41.120 --> 02:00:46.160]   That was bocchish.
[02:00:46.160 --> 02:00:47.360]   >> You're looking down the aisle to get married.
[02:00:47.360 --> 02:00:48.800]   >> Do you want to try Mozart?
[02:00:48.800 --> 02:00:52.640]   Okay, let's play Mozart's harpsichord.
[02:00:52.640 --> 02:00:58.000]   All right.
[02:00:58.000 --> 02:01:01.040]   Now we're going to harmonize and see what happens.
[02:01:01.040 --> 02:01:05.200]   It's-- the computer is working, harmonizing, harmonizing.
[02:01:05.200 --> 02:01:07.200]   >> It's a lot of work to harmonize that one.
[02:01:07.200 --> 02:01:07.760]   >> Harmonizing?
[02:01:07.760 --> 02:01:09.040]   Show the computer.
[02:01:09.040 --> 02:01:09.760]   Harmonizing?
[02:01:09.760 --> 02:01:12.400]   They apparently didn't give it the best.
[02:01:12.400 --> 02:01:12.880]   Here we go.
[02:01:12.880 --> 02:01:13.920]   Here we go.
[02:01:13.920 --> 02:01:21.120]   See, if I actually could play the piano, this might be good.
[02:01:21.120 --> 02:01:22.800]   It is--
[02:01:22.800 --> 02:01:25.840]   >> That was on a discord note there.
[02:01:25.840 --> 02:01:26.560]   >> Yeah, well--
[02:01:26.560 --> 02:01:27.680]   >> I was trying to avoid that,
[02:01:27.680 --> 02:01:28.320]   but--
[02:01:28.320 --> 02:01:29.920]   >> That's why I didn't think so long.
[02:01:29.920 --> 02:01:33.200]   You want to try new harmony with the help of Beethoven?
[02:01:33.200 --> 02:01:33.920]   Sure, why not?
[02:01:33.920 --> 02:01:34.640]   Let's harmonize.
[02:01:34.640 --> 02:01:37.520]   Beethoven.
[02:01:37.520 --> 02:01:38.880]   Now, ladies and gentlemen,
[02:01:38.880 --> 02:01:41.840]   I give you arts and culture experiment,
[02:01:41.840 --> 02:01:43.600]   assisted melody.
[02:01:43.600 --> 02:01:46.640]   I will now play in the style of Ludwig von.
[02:01:46.640 --> 02:01:57.120]   That was pretty good.
[02:01:57.920 --> 02:01:58.400]   >> Huh.
[02:01:58.400 --> 02:02:02.000]   >> That's a medal of marriage.
[02:02:02.000 --> 02:02:02.960]   >> Well, that changed.
[02:02:02.960 --> 02:02:04.320]   >> Got two us.
[02:02:04.320 --> 02:02:04.880]   >> Huh.
[02:02:04.880 --> 02:02:05.440]   >> Huh.
[02:02:05.440 --> 02:02:05.760]   >> Huh.
[02:02:05.760 --> 02:02:06.400]   >> Huh.
[02:02:06.400 --> 02:02:06.880]   >> Huh.
[02:02:06.880 --> 02:02:07.360]   >> Huh.
[02:02:07.360 --> 02:02:12.560]   I'll bet a young kid could probably play with that for three hours, though.
[02:02:12.560 --> 02:02:14.400]   Like, I'm making--
[02:02:14.400 --> 02:02:16.720]   >> Oh, my daughter still plays with a blob opera.
[02:02:16.720 --> 02:02:16.960]   >> Yeah.
[02:02:16.960 --> 02:02:17.440]   >> Yeah.
[02:02:17.440 --> 02:02:18.800]   She-- this sort of stuff.
[02:02:18.800 --> 02:02:19.840]   >> That's all I got.
[02:02:19.840 --> 02:02:21.280]   That's the Google change log.
[02:02:21.280 --> 02:02:24.480]   >> That's the most pathetic Google change log.
[02:02:24.480 --> 02:02:27.360]   >> I told you, it's Sundar Pachai's fault.
[02:02:27.360 --> 02:02:28.400]   Blame Sundar.
[02:02:28.400 --> 02:02:30.080]   It's his fault.
[02:02:30.080 --> 02:02:32.960]   No, no, no, it started over.
[02:02:32.960 --> 02:02:33.600]   That was enough.
[02:02:33.600 --> 02:02:38.720]   Warren Buffett is resigning from the Gates Foundation
[02:02:38.720 --> 02:02:39.520]   and has donated--
[02:02:39.520 --> 02:02:40.560]   >> Get me out of here.
[02:02:40.560 --> 02:02:44.000]   >> 4.1 billion with a B.
[02:02:44.000 --> 02:02:45.600]   Dollars.
[02:02:45.600 --> 02:02:48.960]   He has been inactive, he said in a statement for some time.
[02:02:48.960 --> 02:02:51.840]   His decision is stepped down,
[02:02:51.840 --> 02:02:54.240]   comes at an uncertain time for the Foundation.
[02:02:54.240 --> 02:02:55.680]   Of course, the Gates are divorcing.
[02:02:55.680 --> 02:02:58.800]   For years, says Warren, I've been a trustee,
[02:02:58.800 --> 02:03:02.240]   an inactive trustee at that of only one recipient of my funds,
[02:03:02.240 --> 02:03:04.160]   the Bill and Melinda Gates Foundation.
[02:03:04.160 --> 02:03:06.240]   I'm now resigning from that post as I--
[02:03:06.240 --> 02:03:08.720]   just as I have done it all corporate boards other than Berkshires.
[02:03:08.720 --> 02:03:11.360]   But he's 90 years old.
[02:03:11.360 --> 02:03:12.320]   I don't blame him.
[02:03:12.320 --> 02:03:15.120]   I mean, I'm amazed that he's this energetic.
[02:03:15.120 --> 02:03:20.880]   He's given away 4.1 billion dollars of Berkshires Hathaway shares.
[02:03:20.880 --> 02:03:23.760]   His goal, of course, as part of the Giving Pledge,
[02:03:23.760 --> 02:03:26.880]   is to give away 99% of his fortune.
[02:03:26.880 --> 02:03:29.520]   He says he's about halfway there.
[02:03:29.520 --> 02:03:32.560]   >> I loved the quote at the end of that article, though,
[02:03:32.560 --> 02:03:33.600]   because he said something like,
[02:03:33.600 --> 02:03:35.200]   "No matter how you slice it,
[02:03:35.200 --> 02:03:38.800]   I'm past the fourth quarter and into bonus time or overtime."
[02:03:38.800 --> 02:03:39.360]   [laughter]
[02:03:39.360 --> 02:03:40.480]   It's 15 years old.
[02:03:40.480 --> 02:03:42.160]   >> I'm really impressed.
[02:03:42.160 --> 02:03:42.640]   >> I've worked on this.
[02:03:42.640 --> 02:03:43.920]   >> Especially since he has--
[02:03:43.920 --> 02:03:46.560]   apparently he has an egg McMuffin for breakfast every day.
[02:03:46.560 --> 02:03:47.680]   I don't know how he's doing it.
[02:03:47.680 --> 02:03:50.000]   >> Well, he's--
[02:03:51.120 --> 02:03:54.160]   he loves his McDonalds.
[02:03:54.160 --> 02:03:56.400]   I guess he owns some portion of it.
[02:03:56.400 --> 02:03:56.800]   I don't know.
[02:03:56.800 --> 02:03:58.720]   >> Has a coke with it.
[02:03:58.720 --> 02:04:00.880]   Leo, have you ever gone to Berkshire Hathaway days?
[02:04:00.880 --> 02:04:01.680]   >> No. Have you?
[02:04:01.680 --> 02:04:03.280]   >> Yeah.
[02:04:03.280 --> 02:04:04.880]   I spent some time in Nebraska.
[02:04:04.880 --> 02:04:06.320]   >> Oh, how fun.
[02:04:06.320 --> 02:04:08.000]   >> That was the highlight of the year.
[02:04:08.000 --> 02:04:08.320]   >> Yeah.
[02:04:08.320 --> 02:04:09.760]   >> They've got like C's, candy,
[02:04:09.760 --> 02:04:12.640]   all the different companies at Berkshire Hathaway invest in.
[02:04:12.640 --> 02:04:15.760]   They have booths from all the different companies.
[02:04:15.760 --> 02:04:16.720]   Wow.
[02:04:16.720 --> 02:04:18.080]   How fun.
[02:04:18.080 --> 02:04:18.560]   >> Yeah.
[02:04:19.120 --> 02:04:19.840]   It was fun.
[02:04:19.840 --> 02:04:24.560]   Bill Gates would come and they would have a newspaper throwing contest in the--
[02:04:24.560 --> 02:04:25.120]   >> Oh, shit.
[02:04:25.120 --> 02:04:25.920]   >> --emention center.
[02:04:25.920 --> 02:04:27.920]   It was actually a lot of fun stuff.
[02:04:27.920 --> 02:04:28.240]   >> It's very--
[02:04:28.240 --> 02:04:28.560]   >> A lot of fun stuff.
[02:04:28.560 --> 02:04:29.280]   >> It's very folksy.
[02:04:29.280 --> 02:04:30.000]   Very down home.
[02:04:30.000 --> 02:04:30.480]   >> Yeah.
[02:04:30.480 --> 02:04:31.040]   >> Yeah.
[02:04:31.040 --> 02:04:31.120]   >> Mm-hmm.
[02:04:31.120 --> 02:04:31.680]   >> That's nice.
[02:04:31.680 --> 02:04:33.280]   That's really cool.
[02:04:33.280 --> 02:04:34.320]   That's really cute.
[02:04:34.320 --> 02:04:34.560]   All right.
[02:04:34.560 --> 02:04:35.920]   Let's take a little break and then--
[02:04:35.920 --> 02:04:37.120]   I can't believe it.
[02:04:37.120 --> 02:04:38.800]   This has been so much fun having you here, man.
[02:04:38.800 --> 02:04:40.560]   I can't believe we're at the end of the show.
[02:04:40.560 --> 02:04:43.680]   But we will give you a final chance to make a pick or a suggestion
[02:04:43.680 --> 02:04:47.680]   or tell people to go to usds.org, whatever that may be.
[02:04:48.640 --> 02:04:50.160]   Our picks of the week coming up in just a bit.
[02:04:50.160 --> 02:04:52.640]   But I want to show you my pick.
[02:04:52.640 --> 02:04:53.520]   I'm getting ready.
[02:04:53.520 --> 02:04:57.520]   You know, we're going to Hawaii in a few weeks, July 12th.
[02:04:57.520 --> 02:05:00.160]   And I'm getting the sport clothing together.
[02:05:00.160 --> 02:05:04.880]   Some people I know are getting ready for going back to work,
[02:05:04.880 --> 02:05:06.960]   maybe getting some dressier shirts.
[02:05:06.960 --> 02:05:09.600]   Can I recommend untucket?
[02:05:09.600 --> 02:05:13.360]   Untucket shirts are exactly what you need to transition back to the things
[02:05:13.360 --> 02:05:15.840]   we've been missing, whether it's dinner with friends,
[02:05:15.840 --> 02:05:19.040]   reuniting with family, and especially vacations.
[02:05:19.040 --> 02:05:24.880]   A tucket made its name, designing shirts that are worn to be untucked.
[02:05:24.880 --> 02:05:27.680]   Because the untucked shirt is a tough style to get right.
[02:05:27.680 --> 02:05:30.320]   My son hates it when I tuck in my shirt.
[02:05:30.320 --> 02:05:32.080]   And so he said, "Get that.
[02:05:32.080 --> 02:05:33.200]   Get untucket."
[02:05:33.200 --> 02:05:36.480]   It has that just right length fits all shapes and sizes,
[02:05:36.480 --> 02:05:40.640]   helps you look sharp, but also relaxed and you're at your most casual.
[02:05:40.640 --> 02:05:42.080]   Now I'm wearing a performance shirt.
[02:05:42.080 --> 02:05:42.880]   They wick sweat.
[02:05:42.880 --> 02:05:44.640]   They're very cool when it's really hot.
[02:05:44.640 --> 02:05:49.280]   They also have short sleeve button downs and polos that are made to beat the heat.
[02:05:49.280 --> 02:05:53.040]   I just recently discovered, I have a number, a lot of untucket shirts,
[02:05:53.040 --> 02:05:56.080]   but I recently discovered they have linen shirts.
[02:05:56.080 --> 02:05:59.040]   And I have bought half dozen linen shirts for the trip to Hawaii
[02:05:59.040 --> 02:06:00.000]   because they're so cool.
[02:06:00.000 --> 02:06:02.480]   They look great, but they breathe.
[02:06:02.480 --> 02:06:03.440]   I love linen.
[02:06:03.440 --> 02:06:08.880]   They have all sizes and shapes all the way up to triple XL.
[02:06:08.880 --> 02:06:10.640]   They have slim, relaxed, and tall fits.
[02:06:10.640 --> 02:06:13.840]   So it's really easy to get something that works just right for you,
[02:06:13.840 --> 02:06:18.000]   whether you're like a snug fit or you want something a little looser and relaxed.
[02:06:18.000 --> 02:06:19.440]   And let's see, what else can I tell you?
[02:06:19.440 --> 02:06:23.840]   They are kind of obsessive about the quality.
[02:06:23.840 --> 02:06:25.600]   And you can really tell when you get these shirts,
[02:06:25.600 --> 02:06:27.040]   they really are well made.
[02:06:27.040 --> 02:06:33.840]   Untucket tests every batch of fabric to ensure the best possible quality and consistency.
[02:06:33.840 --> 02:06:38.000]   All of their button downs, polos, teas, handlies, and more have that just right length.
[02:06:38.000 --> 02:06:39.600]   They fit perfectly.
[02:06:39.600 --> 02:06:42.400]   The material is fantastic.
[02:06:42.400 --> 02:06:46.160]   They have the highest quality control in the industry.
[02:06:46.160 --> 02:06:50.640]   Every aspect of the shirts checked five times to ensure they retain shape,
[02:06:50.640 --> 02:06:51.600]   color, and strength.
[02:06:51.600 --> 02:06:54.400]   And they have outstanding customer service.
[02:06:54.400 --> 02:06:58.400]   So if you ever have a problem, it's so easy to get it made right.
[02:06:58.400 --> 02:07:00.800]   If you're looking for shirts to return to the office,
[02:07:00.800 --> 02:07:03.760]   I really love Untucket's wrinkle-free collection.
[02:07:03.760 --> 02:07:07.440]   I take advantage of that because nobody ain't nobody got time to iron shirts.
[02:07:07.440 --> 02:07:10.560]   Whether you prefer short or long sleeves, you're ready to get back to work.
[02:07:10.560 --> 02:07:11.680]   There are untucket stores.
[02:07:11.680 --> 02:07:12.560]   They're all over the place.
[02:07:12.560 --> 02:07:14.400]   85 of them nationwide.
[02:07:14.400 --> 02:07:18.080]   But you can also go online at untucket.com.
[02:07:18.080 --> 02:07:20.800]   Free returns and exchanges.
[02:07:20.800 --> 02:07:21.760]   No risk at all.
[02:07:21.760 --> 02:07:28.000]   Great time now as we get ready to go back into the real world to try out an untucket shirt.
[02:07:28.000 --> 02:07:29.120]   That's just right for you.
[02:07:29.120 --> 02:07:30.720]   And we've got a great deal too.
[02:07:30.720 --> 02:07:37.280]   Our offer code TWIT gets you 20% off your first purchase at untucket.com.
[02:07:37.280 --> 02:07:38.560]   I am such a fan.
[02:07:39.200 --> 02:07:40.320]   untucket.com.
[02:07:40.320 --> 02:07:41.520]   Use the code TWIT.
[02:07:41.520 --> 02:07:44.080]   Everything I wear and why it's going to be untucket.
[02:07:44.080 --> 02:07:48.160]   Untucket shirts designed to be worn, untucked.
[02:07:48.160 --> 02:07:50.160]   And they are well made and they look good too.
[02:07:50.160 --> 02:07:51.520]   I'm a big fan.
[02:07:51.520 --> 02:07:58.320]   It is time to wrap things up with Stacy's thing.
[02:07:58.320 --> 02:08:00.240]   What do you got for us?
[02:08:00.240 --> 02:08:02.240]   This week's thing is not a thing.
[02:08:02.240 --> 02:08:09.040]   This week thing, this week's thing is only for Android people.
[02:08:09.040 --> 02:08:09.920]   And Google people.
[02:08:09.920 --> 02:08:11.360]   But I figured this was the place for it.
[02:08:11.360 --> 02:08:15.280]   I tried out Google launched something called paste walking.
[02:08:15.280 --> 02:08:19.600]   It's a metronome for walking.
[02:08:19.600 --> 02:08:22.160]   You can listen to your podcast.
[02:08:22.160 --> 02:08:23.280]   You could do whatever else you want.
[02:08:23.280 --> 02:08:24.960]   But it's like to help you set a pace.
[02:08:24.960 --> 02:08:28.800]   Yeah, it's a little less of a truth.
[02:08:28.800 --> 02:08:32.240]   And it's in the Google Fit app,
[02:08:32.240 --> 02:08:35.040]   which I actually had to go and re-download because I never used Google.
[02:08:35.040 --> 02:08:36.080]   Oh, I use Google Fit.
[02:08:36.080 --> 02:08:37.520]   Yeah, I love Google Fit.
[02:08:37.520 --> 02:08:38.960]   So if you use it, great.
[02:08:38.960 --> 02:08:42.400]   It's just a little card in the screen.
[02:08:42.400 --> 02:08:43.760]   I don't know what you call these anymore.
[02:08:43.760 --> 02:08:45.440]   So does it make you walk fast?
[02:08:45.440 --> 02:08:46.880]   Because I'm a stroller.
[02:08:46.880 --> 02:08:47.760]   Lisa doesn't like it.
[02:08:47.760 --> 02:08:48.560]   Well, I'm not.
[02:08:48.560 --> 02:08:49.840]   I don't walk real fast.
[02:08:49.840 --> 02:08:53.120]   What you do is you set a pace.
[02:08:53.120 --> 02:08:55.200]   So it gives you the option to try pace walking.
[02:08:55.200 --> 02:08:58.480]   And it says for you can go, I don't know how low you can go,
[02:08:58.480 --> 02:09:00.080]   but the base is 100.
[02:09:00.080 --> 02:09:00.480]   And that's a...
[02:09:00.480 --> 02:09:03.680]   100 steps a minute.
[02:09:03.680 --> 02:09:04.320]   Okay.
[02:09:04.320 --> 02:09:06.080]   Yeah, 100 steps a minute.
[02:09:06.080 --> 02:09:10.720]   I walk, I naturally walk about 110 steps a minute, 120 even.
[02:09:10.720 --> 02:09:13.200]   So I set mine a little higher.
[02:09:13.200 --> 02:09:14.080]   And you can figure this.
[02:09:14.080 --> 02:09:15.120]   I mean, just play with it.
[02:09:15.120 --> 02:09:15.840]   It's free.
[02:09:15.840 --> 02:09:18.720]   But I walk a lot.
[02:09:18.720 --> 02:09:22.160]   And I walk not necessarily for fitness,
[02:09:22.160 --> 02:09:24.160]   but I walk because I get stressed and anxious.
[02:09:24.160 --> 02:09:26.800]   And this is a really nice way to like...
[02:09:26.800 --> 02:09:28.880]   Do you have to wear headphones?
[02:09:28.880 --> 02:09:29.760]   I guess you do, right?
[02:09:29.760 --> 02:09:32.400]   Yes, but you, like I said,
[02:09:32.400 --> 02:09:35.280]   you can still listen to whatever you want in addition to this.
[02:09:35.280 --> 02:09:35.760]   Nice.
[02:09:35.760 --> 02:09:36.960]   So, you know...
[02:09:36.960 --> 02:09:40.400]   And you try to take a step for every tick or whatever.
[02:09:40.400 --> 02:09:42.160]   Yeah, for every tick here, your foot...
[02:09:42.160 --> 02:09:42.800]   Is it a beep?
[02:09:42.800 --> 02:09:45.040]   No, no, no, it's a tick.
[02:09:45.040 --> 02:09:47.280]   Here, let's see.
[02:09:47.280 --> 02:09:49.120]   I don't know if I can play it over...
[02:09:49.120 --> 02:09:49.760]   Probably not.
[02:09:49.760 --> 02:09:54.320]   Here, three, two, one.
[02:09:54.320 --> 02:09:59.600]   Oh no, it's going over my...
[02:09:59.600 --> 02:10:00.160]   Yeah.
[02:10:00.160 --> 02:10:03.600]   I'm A, not walking and B, I'm not...
[02:10:03.600 --> 02:10:08.080]   You have to actually leave us to demonstrate this, so please don't.
[02:10:08.080 --> 02:10:10.320]   There are no say's.
[02:10:10.320 --> 02:10:11.200]   He buys things.
[02:10:11.200 --> 02:10:11.920]   Don't go.
[02:10:11.920 --> 02:10:12.400]   Don't go.
[02:10:12.400 --> 02:10:16.960]   So anyway, but like, I mean, again, this is...
[02:10:16.960 --> 02:10:18.480]   This is not for everyone, but try it.
[02:10:18.480 --> 02:10:19.520]   I mean, it's there.
[02:10:19.520 --> 02:10:20.160]   Try it out.
[02:10:20.160 --> 02:10:22.000]   If it works for you, I found it to be like,
[02:10:22.000 --> 02:10:28.320]   I listen to podcasts and walk and it's helpful to keep my pace up and kind of feel...
[02:10:30.160 --> 02:10:33.680]   I can't be convinced that walking is actually exercise.
[02:10:33.680 --> 02:10:34.160]   It is.
[02:10:34.160 --> 02:10:34.880]   I know it is.
[02:10:34.880 --> 02:10:35.360]   It is.
[02:10:35.360 --> 02:10:36.720]   It goes in and over a certain way.
[02:10:36.720 --> 02:10:39.040]   Yes, for me, it's strenuous.
[02:10:39.040 --> 02:10:41.440]   So yeah, try it out.
[02:10:41.440 --> 02:10:42.080]   I mean, it's...
[02:10:42.080 --> 02:10:42.560]   They say...
[02:10:42.560 --> 02:10:43.360]   I tried it out.
[02:10:43.360 --> 02:10:43.360]   I tried it out.
[02:10:43.360 --> 02:10:43.840]   I tried it out.
[02:10:43.840 --> 02:10:47.120]   50 minutes a week of walking or similar exercise like that,
[02:10:47.120 --> 02:10:48.320]   according to the American Heart Association.
[02:10:48.320 --> 02:10:49.120]   Oh, I walk like...
[02:10:49.120 --> 02:10:50.320]   More than that.
[02:10:50.320 --> 02:10:55.720]   At least it tastes like 10,000 steps just like going around the house. I don't know how she does it
[02:10:55.720 --> 02:11:01.100]   I'm not I like to walk, but I know I get a thousand steps. I feel good
[02:11:01.100 --> 02:11:06.780]   Wednesday's are not my walking step days. I'm stuck here with us
[02:11:06.780 --> 02:11:14.720]   My pick this week is something we've talked about brave is a browser before it's based on chromium, but it's privacy focused
[02:11:14.720 --> 02:11:19.360]   I'm actually a big fan of the brave browser. If you need a chromium browser. There are a lot of choices
[02:11:19.880 --> 02:11:22.960]   These days, but I like brave, but they did something interesting
[02:11:22.960 --> 02:11:28.040]   You know most browsers still use Google or Bing as your search engine or you can use duck duck go
[02:11:28.040 --> 02:11:30.960]   Which kind of still uses Google or Bing brave?
[02:11:30.960 --> 02:11:35.920]   a year or so ago bought clicks which was a third-party
[02:11:35.920 --> 02:11:42.160]   Search engine and they have just released the beta of the brave browser search.brave.com
[02:11:45.360 --> 02:11:52.040]   Private search they I think at some point they might want to charge for it. I think that they're trying to figure out a way to
[02:11:52.040 --> 02:11:53.880]   monetize without
[02:11:53.880 --> 02:11:56.880]   Tracking and ads which I commend them for
[02:11:56.880 --> 02:12:03.400]   Let me search for something. I know intimately my name Leo Laport. I think it does a very good job
[02:12:03.400 --> 02:12:05.400]   It comes up with
[02:12:05.400 --> 02:12:07.400]   And by the way, it also tells you
[02:12:07.400 --> 02:12:12.260]   At the bottom of the search how much of this it got with an anonymized
[02:12:12.960 --> 02:12:18.760]   API call to Google and how much of it it generated on its own and actually does a very good job
[02:12:18.760 --> 02:12:22.600]   There's even a button that says find elsewhere on Google Bing or Mojik
[02:12:22.600 --> 02:12:28.200]   So if you didn't get the results that you wanted you can do more notice YouTube videos are there
[02:12:28.200 --> 02:12:33.300]   There is a kind of a Wikipedia knowledge cards Google style knowledge card
[02:12:33.300 --> 02:12:37.640]   I it has a lot of the features, you know safe search
[02:12:38.400 --> 02:12:45.280]   You've got time frames a lot of the features image news and video search as well, and then you can also get
[02:12:45.280 --> 02:12:48.120]   info about your search and
[02:12:48.120 --> 02:12:53.360]   And I think that's kind of interesting too. I think this does a pretty good job. You want to give me a Leo look
[02:12:53.360 --> 02:12:56.600]   Chris be crazy. I miss felt your name. Yeah, and then look
[02:12:56.600 --> 02:13:02.720]   And knew it right there. It knew it could tell Leo Lapapa party was actually that Leo Laport
[02:13:02.720 --> 02:13:07.220]   All right, look up crispy cream. I want to see what it gives. All right. Let's see what we get for crispy
[02:13:08.220 --> 02:13:12.960]   Cream it does, you know, it's not Google yet. I mean got it be amazing if we're even close
[02:13:12.960 --> 02:13:19.900]   So it gets a map it gets it gets a local eye you can choose whether or not to give it location information
[02:13:19.900 --> 02:13:27.060]   And it can be very general location information. So that is a local map and yeah, I think it's a pretty good result actually
[02:13:27.060 --> 02:13:29.460]   Gives me Yelp reviews
[02:13:29.460 --> 02:13:33.260]   Wikipedia entries
[02:13:34.540 --> 02:13:40.540]   So is that's that you know, I was actually press given how hard it is to create a new search engine
[02:13:40.540 --> 02:13:42.540]   This has done a pretty good job. I
[02:13:42.540 --> 02:13:47.420]   Have I'm sure there's a way to make it the default in other browsers, but I'm just using brave
[02:13:47.420 --> 02:13:56.100]   And it's easier just to do that. Here's the information on your results independence privately calculated in a browser not tracked 89%
[02:13:56.100 --> 02:14:04.480]   Global results independence anonymous tally from all users not tracked 87% so you can really see you can get some sense
[02:14:04.480 --> 02:14:08.700]   Of the privacy of how much was used Google was used and so forth
[02:14:08.700 --> 02:14:15.600]   This is really good. I think this is a really interesting attempt to offer search in a private form
[02:14:15.600 --> 02:14:19.120]   And I think you should give it a try. I've been using it all through the show
[02:14:19.120 --> 02:14:27.540]   Search.Google. I'm sorry search.Brave.com. You can Google it and just say brave search. I bet you'd find it right away
[02:14:27.540 --> 02:14:33.740]   So I'm sorry Matt, but you I know you've done many good things with the Google search over the years
[02:14:33.740 --> 02:14:37.880]   But all good it's good to have competition. Yeah, yes, absolutely
[02:14:37.880 --> 02:14:40.680]   Jeff a number
[02:14:40.680 --> 02:14:45.800]   So I follow as you know Benedict Evans because I often get numbers from his newsletter
[02:14:45.800 --> 02:14:52.000]   But this time was his Twitter feed he put up something from the epic case that is amazing here
[02:14:52.000 --> 02:14:58.400]   Last year he said Apple took in about 15 billion in commissions from in-app payments on iOS
[02:14:58.400 --> 02:15:02.060]   On these numbers from 2017
[02:15:02.520 --> 02:15:07.300]   Disclosed in the case half half of that number came from
[02:15:07.300 --> 02:15:10.860]   half a percent of the accounts
[02:15:10.860 --> 02:15:17.980]   Spending more than a hundred fifty dollars a month. These are the whales the Apple store the whales
[02:15:17.980 --> 02:15:21.720]   Somebody said in response to Ben that plus does a lot of work
[02:15:21.720 --> 02:15:24.700]   Well, that's really interesting
[02:15:24.700 --> 02:15:32.220]   There are a lot of scam apps which Apple has had a hard time getting rid of that charge you like thirty dollars a week and things
[02:15:32.220 --> 02:15:38.220]   So I wonder if how much of that comes from scam apps half the revenue. That's a lot of the revenue. I
[02:15:38.220 --> 02:15:40.220]   You know I
[02:15:40.220 --> 02:15:44.840]   Fairly notoriously spent a lot of money on donuts in Simpsons donuts. They weren't as good as
[02:15:44.840 --> 02:15:48.020]   Krispy Kreme's
[02:15:48.020 --> 02:15:55.200]   This was the Simpsons tapped out game. I had a problem. I might have been one of those four hundred fifty dollar months people at that time
[02:15:55.200 --> 02:16:01.200]   Nothing wrong with being a whale you're you're I'm a whale. Oh, I'm a whale
[02:16:01.200 --> 02:16:05.000]   I don't get free drinks or stays in the Apple hotel. However, so
[02:16:05.000 --> 02:16:12.360]   Gallery free donuts that's got a gallery free they have no flavor whatsoever
[02:16:12.360 --> 02:16:17.520]   Matt would you like to share something with us?
[02:16:17.520 --> 02:16:20.680]   Sure, would you prefer okay?
[02:16:20.680 --> 02:16:26.720]   So I have to say if you're a technologist who wants to make the world a better place instead of working at a tech company
[02:16:26.720 --> 02:16:31.380]   Consider doing a tour of public service possibly at the US digital service usps.gov
[02:16:31.380 --> 02:16:35.360]   I have to say that they need people to do really important projects right now
[02:16:35.360 --> 02:16:43.160]   But I can do another thing would you rather have a book or a game whatever you got a game that sounds interesting you got a good game
[02:16:43.160 --> 02:16:45.000]   Yeah
[02:16:45.000 --> 02:16:47.560]   So there's this game called you think you know me
[02:16:47.560 --> 02:16:55.400]   And it's really it's not a competitive game. You're not gonna like slam down the cards and be like boo
[02:16:55.400 --> 02:16:57.400]   Yeah, I win
[02:16:57.400 --> 02:17:05.360]   It's more of a cooperative game where you you try to know more about people so for example like I
[02:17:05.360 --> 02:17:12.160]   If I know if you became the president today the first thing you'd work on is blank or I like that
[02:17:12.160 --> 02:17:16.600]   I know you think one of the greatest things ever invented is blank
[02:17:16.600 --> 02:17:22.120]   And if you get it right then you get to get rid of that card and the goal is to get rid of the cards
[02:17:22.120 --> 02:17:26.460]   But really the goal is just a it's like a way to do small talk you can do it with
[02:17:26.460 --> 02:17:31.560]   Oh, I love this idea all kinds of people or people that you know really well and get to know them a lot better
[02:17:31.560 --> 02:17:37.440]   So it's called you think you know me and it's it's just a delight. It's kind of like the newlywed game in reverse
[02:17:37.440 --> 02:17:41.040]   Sort of yeah, I like this
[02:17:41.040 --> 02:17:43.720]   Couple of dinner table
[02:17:43.720 --> 02:17:51.440]   We we actually do sometimes take them in baggies for dates. So like if we're like oh, yeah, we don't have much to talk about
[02:17:51.440 --> 02:17:56.200]   Oh, why don't we just work a few cards and try a little bit. I'm gonna order this right now
[02:17:56.200 --> 02:17:59.080]   This was a Kickstarter
[02:17:59.080 --> 02:18:02.440]   You think you know me dot cards
[02:18:02.440 --> 02:18:10.760]   Mm-hmm. That's really Amy Bayo who you might know because of Andy Bayo or I know just because she's awesome
[02:18:10.760 --> 02:18:17.440]   Is she related to Andy Bayo? I think they are partners. Oh, that's really cool. I love Andy Bayo
[02:18:18.320 --> 02:18:23.020]   Nice you think you know me dot cards. Well see that's really cool
[02:18:23.020 --> 02:18:31.600]   And Pruitt wanted to put a little plug in ants listening. He's on he'll be back next week. Hello, Ant
[02:18:31.600 --> 02:18:34.040]   Thank you for letting
[02:18:34.040 --> 02:18:36.440]   us bring in
[02:18:36.440 --> 02:18:39.160]   Matt in your place just for this week only
[02:18:39.160 --> 02:18:42.400]   But I did want to ants gonna do yeah
[02:18:42.400 --> 02:18:46.760]   Yeah, it's a sweetheart. Thanks for producing and he did produce
[02:18:47.400 --> 02:18:49.400]   At the last minute jumped in
[02:18:49.400 --> 02:18:54.320]   But Ant wanted to remind everybody that he's gonna be
[02:18:54.320 --> 02:18:58.480]   Speaking and all nalens at the wanderers photographic
[02:18:58.480 --> 02:19:05.920]   Cultural experiences. He's one of the instructors like they're there there. Mm-hmm. I think he is going to New Orleans
[02:19:05.920 --> 02:19:10.000]   Are you going to know? Yes, he's going to New Orleans. So that's pretty cool
[02:19:10.000 --> 02:19:12.640]   if you want to know more wanderers photo
[02:19:13.560 --> 02:19:15.560]   dot com and
[02:19:15.560 --> 02:19:20.760]   You can find out about this event in I mean it's a walking
[02:19:20.760 --> 02:19:26.640]   Oh, it's like a oh that's so cool October 10th through the 14th
[02:19:26.640 --> 02:19:33.520]   Of this year a five-day workshop set against the backdrop. You know what New Orleans is made for photography
[02:19:33.520 --> 02:19:40.880]   What a great time that'll be look at oh, you know, I want to do this this looks great
[02:19:42.480 --> 02:19:44.480]   wanderers photo dot com
[02:19:44.480 --> 02:19:50.720]   Join ant and many other photographers in a one-of-a-kind photo experience
[02:19:50.720 --> 02:19:53.680]   Matt cuts usds.gov
[02:19:53.680 --> 02:19:58.000]   Join I know you're not there anymore, but your heart's still there
[02:19:58.000 --> 02:20:04.760]   I'm so glad to hear how well you're doing and it was so great to get you back on. Thank you so much for being here
[02:20:04.760 --> 02:20:07.840]   We really appreciate thank you for having me on it. So good to see you
[02:20:09.480 --> 02:20:14.960]   Looking forward to post COVID times when we can like say hello in person next time. You're in the Bay Area
[02:20:14.960 --> 02:20:18.120]   You let me know we'll take care of you here
[02:20:18.120 --> 02:20:25.200]   Thank you for being here. Thank you to Jeff Jarvis director of the townite Center for entrepreneurial journalism at the great
[02:20:25.200 --> 02:20:36.600]   Graduate School of Journalism at the City University of New York buzz machine calm at Jeff Jarvis former TV guide critic Frank Sinatra once called him
[02:20:36.600 --> 02:20:38.700]   I'm figuring your a towner Matt
[02:20:39.540 --> 02:20:40.980]   or
[02:20:40.980 --> 02:20:42.980]   Barakol. I'm I'm just awful
[02:20:42.980 --> 02:20:47.420]   Any register like
[02:20:47.420 --> 02:20:55.660]   You hear on the Craig we usually make we make ants sing but I guess we
[02:20:55.660 --> 02:21:01.380]   Matt you can follow the Stacy rules. You don't have to say. Yeah, she she abstains
[02:21:01.380 --> 02:21:04.020]   That's the screen would just crack if I
[02:21:06.580 --> 02:21:13.780]   Yeah, Stacy Iga bottoms at Stacy on IOT.com subscribe your free newsletter check out our events and of course the great
[02:21:13.780 --> 02:21:17.060]   IOT podcast with Kevin Tofel. Thank you Stacy
[02:21:17.060 --> 02:21:20.700]   Thank you all of you. I really appreciate
[02:21:20.700 --> 02:21:24.220]   You're visiting and
[02:21:24.220 --> 02:21:29.780]   Listening to the show. There's a couple of things I want to tell you about we now have a twit club
[02:21:30.460 --> 02:21:36.900]   At to TV slash club to it. It's chance for you to support what we do here if you like our stuff
[02:21:36.900 --> 02:21:42.460]   And there are some benefits to you to add free versions of all our show and shows and you know what that means
[02:21:42.460 --> 02:21:46.580]   Ad free means tracker free as well. So it's a good privacy option
[02:21:46.580 --> 02:21:53.300]   You also get access to our wonderful discord server and it has been a lot of fun in the discord server
[02:21:53.300 --> 02:21:56.900]   You get to listen in you get to post animated gifts
[02:21:56.940 --> 02:22:01.780]   There's a of course every show has a thread in the discord server, but there are also
[02:22:01.780 --> 02:22:08.540]   Conversations about everything from books to comics to Linux to IOT to travel
[02:22:08.540 --> 02:22:14.940]   Check it out and of course a special feed for the two plus members of stuff that didn't make it into the shows
[02:22:14.940 --> 02:22:20.660]   A lot of pre-show badder things like that come join us says Patrick Della
[02:22:23.660 --> 02:22:26.380]   Shall the animal in a gift if you want to join
[02:22:26.380 --> 02:22:34.460]   A fun place to be
[02:22:34.460 --> 02:22:41.140]   Club Twit we're also going on a cruise next year to Alaska join me and join Lisa and me
[02:22:41.140 --> 02:22:49.460]   Oh, I didn't tell you about this. No, well, it's easy. Even from Seattle. We're going from Stacy's home area
[02:22:49.460 --> 02:22:55.820]   In fact, maybe we get a little little Stacy action pre-cruise something like that cruise dot TV
[02:22:55.820 --> 02:23:00.220]   It's a Holland America cruise to Alaska. It's gonna be a lot of fun in July
[02:23:00.220 --> 02:23:02.780]   2023
[02:23:02.780 --> 02:23:07.660]   We have already 30 people signed up, which is great if we can get to 30 cabins
[02:23:07.660 --> 02:23:11.720]   It's 2022 right - thank you for correcting that July
[02:23:11.720 --> 02:23:18.280]   23rd 2022, you know, I just signed up to go on a Mississippi River cruise in 2024
[02:23:19.060 --> 02:23:23.460]   So we did you have to supply the head you have to plan these ahead honestly
[02:23:23.460 --> 02:23:28.740]   So save the date and get on in there and sign up if you're interested
[02:23:28.740 --> 02:23:34.080]   I think it's gonna be a lot of fun. We're gonna have some events cocktail parties photo walks things like that
[02:23:34.080 --> 02:23:39.220]   cruise dot twit TV for more information we do how many people
[02:23:39.220 --> 02:23:44.940]   The boat holds thousands, but I don't think we're gonna get that many
[02:23:46.100 --> 02:23:50.820]   We have 30 so far I if we get to 60 we can add another host
[02:23:50.820 --> 02:23:53.860]   you could start lobbying now Jeff and
[02:23:53.860 --> 02:24:00.460]   So I do watch building Alaska every chance I get on it last is beautiful
[02:24:00.460 --> 02:24:03.420]   I've been on an Alaska cruise before and it's really a nice trip
[02:24:03.420 --> 02:24:09.100]   It's really funny and they do it in the summertime because otherwise it'd be chilly, but it's it's very pleasant in July
[02:24:09.100 --> 02:24:15.580]   We do this week in Google every Wednesday round about 2 p.m. Pacific 5 p.m. Eastern
[02:24:15.580 --> 02:24:21.980]   2100 UTC you can watch us do it live at twit.tv/live if you're watching live chat with us live
[02:24:21.980 --> 02:24:29.580]   IRC dot twit dot TV on-demand versions of the show available afterwards at our website twit.tv/twig
[02:24:29.580 --> 02:24:33.660]   You can also join us on the YouTube channel with all the videos
[02:24:33.660 --> 02:24:38.700]   Actually the best thing to do is we get a podcast client right and subscribe if you do that
[02:24:38.700 --> 02:24:45.500]   You'll get it automatically the minutes available if that client should happen to offer a chance to review the show a five-star
[02:24:45.500 --> 02:24:47.500]   Review would be much appreciated
[02:24:47.500 --> 02:24:53.260]   Thank you all for being here. Thank you Stacey. Thank you Jeff. Thanks to Matt cuts Colonel cuts
[02:24:53.260 --> 02:24:58.500]   We'll see y'all next time on this week in Google. Bye. Bye. Hey, what's going on everybody?
[02:24:58.500 --> 02:25:06.240]   I am Ant Pruitt and I want to tell you about my show hands on photography here on Twit TV each and every week
[02:25:06.240 --> 02:25:10.960]   Thursday that is I like to sit down and share with you the best tips and tricks
[02:25:10.960 --> 02:25:15.640]   They're gonna help make you a better photographer and it's not always about Photoshop
[02:25:15.640 --> 02:25:20.320]   It's not always about just having the biggest and baddest and bestest camera
[02:25:20.320 --> 02:25:26.240]   It can be the simplest of things like leave your eye open when you're looking through the viewfinder
[02:25:26.240 --> 02:25:30.180]   All of these simple tips can really help step your photography game up
[02:25:30.180 --> 02:25:35.800]   So subscribe to the show today as twit.tv/hop and I look forward to talking to you soon
[02:25:35.800 --> 02:25:37.800]   You
[02:25:37.800 --> 02:25:40.380]   (upbeat music)
[02:25:40.380 --> 02:25:42.960]   (upbeat music)
[02:25:42.960 --> 02:25:45.540]   (upbeat music)
[02:25:45.540 --> 02:25:46.540]   [Music]

