;FFMETADATA1
title=Best of 2017
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=437
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.760]   It's time for Twig this week in Google and a very special Twig. It's year end of course
[00:00:05.760 --> 00:00:11.400]   and in between Christmas and New Year we like to give everybody the week off, the staff,
[00:00:11.400 --> 00:00:16.880]   our hosts. But I thought you don't get a week off. You get a special episode. How about
[00:00:16.880 --> 00:00:20.040]   that? And I hope you get the chance to listen to it. This is our best step. Some of the
[00:00:20.040 --> 00:00:25.680]   best moments from 2017 with Jeff, Stacy and more. Stay tuned.
[00:00:25.680 --> 00:00:40.520]   NetCasts you love. From people you trust. This is Twig. Bandwidth for this week in Google
[00:00:40.520 --> 00:00:52.740]   is provided by cash fly. This is Twig this week in Google, episode
[00:00:52.740 --> 00:01:02.780]   437 for Wednesday, December 27th, 2017. Our best of. This week in Google is brought to
[00:01:02.780 --> 00:01:09.660]   you by GoToWebinar, a trusted webinar platform with over 55,000 customers who have hosted over
[00:01:09.660 --> 00:01:19.780]   2.7 million interactive web events to connect with their audiences. For more, visit GoToWebinar.com/podcast.
[00:01:19.780 --> 00:01:26.500]   Happy Holidays everybody. It's this week in Google, our special in between Christmas
[00:01:26.500 --> 00:01:30.140]   and New Year's edition and we said everybody home for the week. So we're going to do a
[00:01:30.140 --> 00:01:35.500]   best of although I'm very pleased to see Jeff Jarvis of the City University of New York
[00:01:35.500 --> 00:01:41.220]   wearing his traditional Christmas black is here and it's hoodie. Actually this is a little
[00:01:41.220 --> 00:01:45.620]   brown. Is it brown? Brown hoodie. It's black. It's a very neat pack show which is different
[00:01:45.620 --> 00:01:50.740]   as a new to the cover designer. Oh, I like it. It's like a plastic. Oh yeah. Interesting.
[00:01:50.740 --> 00:01:54.740]   It's a rain proof hoodie. Yeah. Yeah. Yeah. I have a sport club and the same stuff. It's
[00:01:54.740 --> 00:02:02.620]   very strange. And Stacy Higginbotham of Stacy on IOT. I would have worn my hand at us. For
[00:02:02.620 --> 00:02:08.620]   some reason I feel I feel like Stacy really loves Christmas. I do. I thought you might.
[00:02:08.620 --> 00:02:14.020]   It's a special especially when you have a young child as you do. It's really fun. For
[00:02:14.020 --> 00:02:23.380]   Jeff and me it's really just a bunch of bitter memories. Yeah. It's true. It's never as good.
[00:02:23.380 --> 00:02:28.380]   The first Christmas you're conscious of it. Yeah. It's downhill from there. Don't tell
[00:02:28.380 --> 00:02:36.060]   stuff to your damn life. No. No. I refuse Jeff. Christmas is always magical. It is always
[00:02:36.060 --> 00:02:41.780]   fun even when I had no children. Nice. I was. You guys have plans for New Year's Eve? It's
[00:02:41.780 --> 00:02:49.820]   a couple of days hence. No. Stay at home. I like to go to bed early. We're a excited
[00:02:49.820 --> 00:02:55.060]   bunch for holidays. Yeah. Anyway, I'm glad you're here for our holiday special. We thanks
[00:02:55.060 --> 00:03:01.940]   to our audience who helped us collate about I think about maybe 10, 12 clips from this
[00:03:01.940 --> 00:03:05.340]   week in Google show over the year. Of course it's been a great year because we had Stacy
[00:03:05.340 --> 00:03:09.660]   join us. Actually, you join us a year ago, more than a year ago. But this year was your
[00:03:09.660 --> 00:03:13.780]   first full year I think. Am I right? Stacy, I believe. It was. And I may even come back
[00:03:13.780 --> 00:03:21.540]   for next year. You're darn well better crossing my fingers. You're invited. Actually, we started
[00:03:21.540 --> 00:03:27.380]   with this. This is a story we were talking about on January 11th of last year, more than
[00:03:27.380 --> 00:03:34.500]   you know, almost exactly a year ago. And it has gotten no better. Google's messaging mess.
[00:03:34.500 --> 00:03:39.140]   Very sad news, I guess. And this is another one of those Google things that you know,
[00:03:39.140 --> 00:03:44.100]   they're all hot and excited about it. And then they lose interest over a couple of years.
[00:03:44.100 --> 00:03:48.380]   You remember that Google Hangouts had all these wild, crazy things you could do in the
[00:03:48.380 --> 00:03:54.980]   Google Hangouts video calls, conference calls, everything for put a mustache on to play ping
[00:03:54.980 --> 00:04:01.700]   pong. Google has announced that they're going to shut down the Hangouts API, which will prevent
[00:04:01.700 --> 00:04:12.380]   new apps from being built and turn off all existing apps on April 25th. So bye bye.
[00:04:12.380 --> 00:04:17.540]   I read something interesting that makes a lot of sense to me because we've complained
[00:04:17.540 --> 00:04:25.260]   bitterly about Google's very confused messaging over messages. It's as SMS apps. You know,
[00:04:25.260 --> 00:04:32.900]   Aloe isn't can't be an SMS app, but Facebook's messenger can on Android devices. All Android
[00:04:32.900 --> 00:04:40.060]   phones come you typically come with Google's SMS app messages and an SSMS, SMS map called
[00:04:40.060 --> 00:04:47.460]   messages from the manufacturer like Samsung or LG. So I have like four or five candidates
[00:04:47.460 --> 00:04:52.980]   for SMS messaging, including Hangouts. So what is Aloe? What is Hangouts? What is their
[00:04:52.980 --> 00:04:58.140]   intent? What are they? Which of these should I use? It's very messed up. And what I read
[00:04:58.140 --> 00:05:02.740]   and I think it was probably on a Reddit thread talking about this Hangouts API is it's probably
[00:05:02.740 --> 00:05:08.460]   for antitrust reasons. Google's reluctant. That which makes sense, right? That if they
[00:05:08.460 --> 00:05:12.060]   were to say, no, no, this is the messaging app. Everybody uses Android should use this
[00:05:12.060 --> 00:05:18.740]   messaging app that that would be an antitrust problem. Don't know, but that that fine.
[00:05:18.740 --> 00:05:24.660]   Other you would it has to be some external force. Surely Google knows what a hash they've
[00:05:24.660 --> 00:05:31.100]   done of this. Apple has their own messaging thing. They control their physical hardware
[00:05:31.100 --> 00:05:36.140]   to a greater extent than Google. That's a very good point. Apple does have one messaging
[00:05:36.140 --> 00:05:43.900]   app. It does SMS and data messaging. It's not cross platform. You have to use well, you
[00:05:43.900 --> 00:05:48.220]   it's cross platform to the extent that it interoperates with the SMS network. Right. But
[00:05:48.220 --> 00:05:53.580]   you can't get Apple messages on Android. So you're right. So maybe I'll never mind because
[00:05:53.580 --> 00:05:58.300]   Apple's not being sued. But Apple doesn't isn't like the king of search and all kinds
[00:05:58.300 --> 00:06:05.940]   of crazy productivity apps either. So I don't. Right. Antitrust is going to be hard to determine
[00:06:05.940 --> 00:06:12.620]   as we can go forward. We don't know. Yeah. We are in such it's really I've been talking
[00:06:12.620 --> 00:06:19.140]   about this a lot with friends and family off the air. It's just unknown what's going to
[00:06:19.140 --> 00:06:24.700]   happen in 10 days. What the world's going to be in cognitive. I said this morning in
[00:06:24.700 --> 00:06:30.020]   the chat room, I said, I really wonder what a year from now what our top news stories
[00:06:30.020 --> 00:06:39.820]   will be. You know, what we'll be talking about on January 10th or January 11th, 2018.
[00:06:39.820 --> 00:06:46.620]   You just be like this. Probably there'll be some Google technology that they're deprecating.
[00:06:46.620 --> 00:06:52.260]   I like there's deadly silence as well. Like we can't even imagine it. We can't. And some
[00:06:52.260 --> 00:06:58.020]   of us don't want to imagine. Well, I don't want to go. I'm only to be good. I don't know.
[00:06:58.020 --> 00:07:04.180]   I'm just waiting to see what happens. I guess the most common passwords of 2016 from
[00:07:04.180 --> 00:07:10.940]   down here. Yeah. Aaron Guccione who is at Campkeeper, which is one of the one of the
[00:07:10.940 --> 00:07:16.740]   well known password very good password vault keeper security. They went through 10 million
[00:07:16.740 --> 00:07:23.460]   passwords that became public through data breaches in 2016 and came up with a list.
[00:07:23.460 --> 00:07:29.780]   Are you ready? The 25 most common passwords of 2016. They haven't really changed much.
[00:07:29.780 --> 00:07:42.180]   Number one, 123456. Number two 123456 789. It's it's three bets. Number three, quarter.
[00:07:42.180 --> 00:07:54.700]   Number four 12345678. Number five 111111. I had a chief engineer who used that as a password
[00:07:54.700 --> 00:07:59.740]   as I remember. In fact, I think a tech TV that was the default password was 111111.
[00:07:59.740 --> 00:08:03.780]   Number six, really what you want to do? One, two, three, four, five, six, seven, eight, nine,
[00:08:03.780 --> 00:08:08.580]   zero, one number seven, one, two, three, four, five, six, seven, number eight password.
[00:08:08.580 --> 00:08:15.940]   I feel like that's sinking. It's going down. People are learning to be like number one.
[00:08:15.940 --> 00:08:20.100]   It was number one. No, I think one, two, three, four, five, six has always been number nine,
[00:08:20.100 --> 00:08:26.140]   one, two, three, one, two, three, old clever. And number 10 obfuscated by doing it backwards,
[00:08:26.140 --> 00:08:33.740]   nine, eight, seven, six, five, four, three, two, one. Why is my noob a password? Number 12
[00:08:33.740 --> 00:08:46.380]   on the list. Hmm. Number 21 Google. What's your Google password? Google? Wow. Anyway,
[00:08:46.380 --> 00:08:50.900]   Oh, I'm trying to I was trying to figure out the one Q2, W3, and then I'm like, Oh, look
[00:08:50.900 --> 00:08:57.380]   at your keyboard, right? Yeah, I'm like, so what's 18? ATC, SK, what's that? Oh, that's
[00:08:57.380 --> 00:09:03.780]   it. Number 15 is eight. This is a good. This would be a great test. Right for people to
[00:09:03.780 --> 00:09:12.580]   like, okay, you have five seconds to figure out why number 15, what is one eight ATC, SKD
[00:09:12.580 --> 00:09:23.980]   two W. T C. Teen a doesn't seem like it's related to the keyboard layout, does it? No,
[00:09:23.980 --> 00:09:29.180]   I was typing it in. I'm like, I don't see it. What is what? But if this is, I mean, apparently
[00:09:29.180 --> 00:09:34.540]   this is multiple people. A lot of people doing it. A lot of people doing it. What does it
[00:09:34.540 --> 00:09:45.260]   mean? Come on, chatroom. It's stuck right between 6, 6, 6, 6, 6, 6, and 7, 7, 7, 7, 7, 7,
[00:09:45.260 --> 00:09:54.620]   7. So it's got to be pretty obvious. What could it be? This is the only one you're right,
[00:09:54.620 --> 00:09:58.460]   Stacy. This is the only one that's not immediately. I feel like once we know it's going to be
[00:09:58.460 --> 00:10:08.300]   though. Got three smart people here. Three RJ. Yes. No, some of these are weird. Like,
[00:10:08.300 --> 00:10:16.660]   look at the look at 20. That's I'm sure they all have some meaning somewhere. Number 20
[00:10:16.660 --> 00:10:28.300]   is three RJ s one L a seven Q E. Is it backwards? Is it anything? I would be a terrible hacker.
[00:10:28.300 --> 00:10:32.700]   I'm looking at here for like, I feel like I'm reading license plates. You know, where
[00:10:32.700 --> 00:10:36.780]   you're trying to figure out what are they trying to? These are obviously used at on
[00:10:36.780 --> 00:10:45.860]   sites where it requires a letter and a number, right? Yeah. Is shift is shift helpful? No,
[00:10:45.860 --> 00:10:53.060]   what? No one. Oh, asky. No. No. Okay. So. Oh, wait a minute. Here's a link to the in
[00:10:53.060 --> 00:10:59.180]   the track. It's a hard coded password for bots. Oh, this is.
[00:10:59.180 --> 00:11:05.980]   Spambot. Yes. It's spam bots. It's spam bots. Use it. So it's not. It's my though.
[00:11:05.980 --> 00:11:19.460]   This is Graham Cluely, aptly named writing a tripwire.com. The reason is bots. Huh?
[00:11:19.460 --> 00:11:28.500]   Huh. People are not choosing those passwords. Same with three RJ s one L a seven Q E. Oh,
[00:11:28.500 --> 00:11:37.580]   I spotted the bot passwords. You are an anti bot. I'm a human. You're a human. Wow,
[00:11:37.580 --> 00:11:43.460]   that's really interesting. It must be hard coded in some malware or something, right?
[00:11:43.460 --> 00:11:49.340]   Yeah, that's that's pretty cool. Yeah. Well, there we go. We've all learned something
[00:11:49.340 --> 00:11:55.620]   here today. History solved. Thanks, Internet. So do you want to talk about vault seven?
[00:11:55.620 --> 00:12:00.340]   Yeah, what do you have to say about this? Ian Thompson did the work. So we didn't have
[00:12:00.340 --> 00:12:09.220]   to. He actually went through all eight thousand documents. 8,761 CAA documents published yesterday
[00:12:09.220 --> 00:12:16.940]   on WikiLeaks. WikiLeaks again, while it's, you know, there's, it's hard to tell the provenance
[00:12:16.940 --> 00:12:22.300]   of these. It seems highly unlikely that WikiLeaks could have generated this much content spreously,
[00:12:22.300 --> 00:12:27.820]   so it's probably real or something like it. They were, they were good enough not to include
[00:12:27.820 --> 00:12:34.780]   the exploits, the actual code, just the descriptions thereof. Most of this, like the Snowden revelations,
[00:12:34.780 --> 00:12:40.620]   is several years old. Some of it was misreported initially. For instance, you might have seen
[00:12:40.620 --> 00:12:48.620]   that the CIA can break signal WhatsApp and telegram encrypted messaging, not so. As Ian
[00:12:48.620 --> 00:12:54.860]   points out, what it actually says is that the CIA, if they can compromise the device, the
[00:12:54.860 --> 00:13:00.700]   computer, the phone that's using signal or WhatsApp or telegram, they can get it before
[00:13:00.700 --> 00:13:05.980]   it's encrypted that does not say that they can decrypt it in transit. That's fairly important.
[00:13:05.980 --> 00:13:14.940]   So one of the things, of course, is that your Samsung TV, one particular model could be
[00:13:14.940 --> 00:13:21.340]   used to listen to you. They've got the code to hack it and turn on a full-time speaker and
[00:13:21.340 --> 00:13:26.540]   microphone, which is funny because there was a big brew, ha ha, Samsung in its terms of service
[00:13:26.540 --> 00:13:31.660]   last year, you know, let slip in there. Oh, and third parties could possibly be monitoring you,
[00:13:31.660 --> 00:13:36.860]   serving everybody. And we said, oh, that's just boilerplate. That's not possible. Well,
[00:13:42.860 --> 00:13:46.940]   so Edward Snowden tweeted yesterday still working through the publication, but what
[00:13:46.940 --> 00:13:52.860]   WikiLeaks has here is genuinely a big deal looks authentic. I guess Edward would probably be a
[00:13:52.860 --> 00:13:59.500]   pretty good expert on that. With regards to particular operating systems,
[00:13:59.500 --> 00:14:05.820]   CIA has a modest collection of attack tools for systems powered by Microsoft's Windows,
[00:14:06.620 --> 00:14:13.740]   keystroke loggers, sandbox, escape ropes, anti-virus avoidance mechanisms, CIA analysts found flaws
[00:14:13.740 --> 00:14:20.540]   in control panel, the ability to add data streams to NTFS without detection. So you could put data
[00:14:20.540 --> 00:14:30.140]   onto storage drives. DLL files, a popular attack vector. There's a program called Ricky Bobby,
[00:14:31.580 --> 00:14:38.060]   which is Will Ferrell's character in the movie, Talladega Nights. It uses Windows PowerShell and
[00:14:38.060 --> 00:14:43.580]   several dot net DLLs to put a listening post on a target PC. You know, all of this, you kind of
[00:14:43.580 --> 00:14:51.420]   expect they have. The one big takeaway was how much more humor in the code names the CIA's stuff
[00:14:51.420 --> 00:15:00.940]   had than the NSA stuff like names like Swamp Monkey Eggs Mayhem, Ricky Bobby, weeping angels.
[00:15:00.940 --> 00:15:05.740]   Yeah, weeping angel. We liked that one. That's of course a doctor who reference. I didn't know
[00:15:05.740 --> 00:15:14.380]   that, but I was informed. Lots of pages of hacking tools for OS 10, including at the time, what was
[00:15:14.380 --> 00:15:19.900]   the most recent version of OS 10 of Kepi 10? Of course, this is an old dump. So presumably they've
[00:15:19.900 --> 00:15:26.860]   updated those. There's a project called Harpy Eagle that analyzes the Apple's Airport extreme firmware
[00:15:26.860 --> 00:15:32.860]   for private keys and then cracks it also time capsule systems. There's a project called Quark
[00:15:32.860 --> 00:15:40.540]   Matter that puts persistent spyware on an OS 10 system using an EFI driver stored on the system,
[00:15:40.540 --> 00:15:44.700]   EFI system partition. In other words, something that wouldn't be wiped by formatting the drive.
[00:15:44.700 --> 00:15:53.260]   Snowy Owl uses open SSH to pull off remote monitoring. I mean, it goes on and on and on.
[00:15:53.260 --> 00:16:01.900]   This is a very rich set of stuff. Now, Android, lots of exploits, Chronos, Criton,
[00:16:01.900 --> 00:16:14.300]   Starmy, Snubble, Bowtie, Sucker Punch, and Royde Rage, SMS Stealing, Chrome-based attacks for
[00:16:14.300 --> 00:16:20.540]   Android. There's a huge number of exploits. Escalation of privileges, allowing malicious apps,
[00:16:21.420 --> 00:16:27.900]   Baron Samdi, which is a voodoo named Doug Trio and Salazar allow for remote access.
[00:16:27.900 --> 00:16:32.860]   They're fixed or mitigated by later versions of Android, but remember a lot of people
[00:16:32.860 --> 00:16:35.820]   have older versions of Android. And of course, this list is three years old.
[00:16:35.820 --> 00:16:42.620]   The CIA stash contains, this is all for me and Thompson on the register.co.uk. The CIA stash
[00:16:42.620 --> 00:16:46.220]   contains rundowns on most of the popular antivirus systems and how to defeat them.
[00:16:47.340 --> 00:16:50.780]   Much of the information has been redacted, but there are a few snippets left.
[00:16:50.780 --> 00:16:58.620]   That's interesting that they're working to defeat antivirus software.
[00:16:58.620 --> 00:17:01.660]   Because it's a pathality, right? Yeah. Virus.
[00:17:01.660 --> 00:17:03.340]   Yeah. What about Chrome?
[00:17:03.340 --> 00:17:03.980]   What the...
[00:17:03.980 --> 00:17:06.220]   Sorry, go on.
[00:17:06.220 --> 00:17:11.900]   Smart TV. I haven't got to Chrome yet. Smart TVs. We mentioned Weeping Angel, which
[00:17:11.900 --> 00:17:16.940]   takes a Samsung TV and turns it into a fake off mode, which makes it look like it's powered down,
[00:17:16.940 --> 00:17:22.540]   but it's still on and can be used as a bugging device. That's really handy, actually.
[00:17:22.540 --> 00:17:28.220]   But the TV has to be compromised by a USB stick inserted into the device.
[00:17:28.220 --> 00:17:31.340]   That one was in a stressful one. Yeah.
[00:17:31.340 --> 00:17:35.180]   Although, if they're going to come into your hotel room or whatever to put a bug in there,
[00:17:35.180 --> 00:17:38.940]   I've been watching the Americans. They could stick the USB.
[00:17:38.940 --> 00:17:44.780]   Uh-huh, exactly. How easy is that to... You don't have to drill holes or anything.
[00:17:45.580 --> 00:17:48.620]   Apparently, they're looking actively at the United States. Now, three years ago,
[00:17:48.620 --> 00:17:51.660]   IoT was not such a big story, but it is now, right?
[00:17:51.660 --> 00:17:55.980]   I feel like it's almost exactly in the same place, to be totally honest.
[00:17:55.980 --> 00:17:56.460]   Yeah. Yeah.
[00:17:56.460 --> 00:18:03.420]   Three years of IoT excitement and basically, the most advanced devices I have are my Nest and
[00:18:03.420 --> 00:18:05.020]   my Echo. Yeah. So...
[00:18:05.020 --> 00:18:06.620]   And you're living in Brigadoon.
[00:18:06.620 --> 00:18:13.500]   One analyst included his favorite ASCII characters for conversing online with Japanese people,
[00:18:13.500 --> 00:18:16.700]   along with games he likes to play and some music suggestions.
[00:18:16.700 --> 00:18:21.740]   Because they had a kind of a jaunty way about them, the CIA operatives.
[00:18:21.740 --> 00:18:27.660]   Nougat is already being eclipsed. The next version of Android is coming into beta.
[00:18:27.660 --> 00:18:30.860]   Android O takes all the suspense out of it.
[00:18:30.860 --> 00:18:32.860]   Wait, do we know what it's called?
[00:18:32.860 --> 00:18:35.260]   O-M-G, we do not.
[00:18:36.220 --> 00:18:41.420]   Oh. Oreo jokes have been made. Oreo would make sense.
[00:18:41.420 --> 00:18:53.180]   Oh, I don't know. Better battery life? What's new in O? Here's what's new in O.
[00:18:53.180 --> 00:18:55.740]   Background limits. Building on the work we began in Nougat.
[00:18:55.740 --> 00:19:00.700]   Android O puts a big priority in improving battery life. That is actually the biggest thing
[00:19:00.700 --> 00:19:04.540]   that I would say Android needs to work on compared to iOS.
[00:19:05.820 --> 00:19:09.980]   Because iOS is very good about, very aggressive about killing background
[00:19:09.980 --> 00:19:15.020]   tasks. And as a result, gets very, very good battery life on much less battery.
[00:19:15.020 --> 00:19:20.220]   The way, if you're an Android device, you handle this just by putting in big old batteries.
[00:19:20.220 --> 00:19:25.020]   So there are automatic limits in O and what apps can do in the background.
[00:19:25.020 --> 00:19:29.980]   In three main areas, implicit broadcast, background services and location updates.
[00:19:29.980 --> 00:19:34.540]   This will make it easier, says Google, to create apps that have minimal
[00:19:34.540 --> 00:19:36.140]   impact on the user's battery.
[00:19:36.140 --> 00:19:44.780]   Notification channels. These are new app-defined categories for notification content. Channels
[00:19:44.780 --> 00:19:51.100]   let developers give users fine grain control over different kinds of notifications. So
[00:19:51.100 --> 00:19:54.540]   in the past, all you've been able to do is say, I don't want a notification from you. Now you'll
[00:19:54.540 --> 00:20:02.860]   be able to say, I want this kind, but not that kind. That's good, right? New visuals and grouping
[00:20:02.860 --> 00:20:08.140]   to notifications and make it easier for users to see what's going on. Auto-fill APIs.
[00:20:08.140 --> 00:20:16.300]   So I use LastPass for Auto-fill, which is awesome. But this will make a standard operating system
[00:20:16.300 --> 00:20:23.980]   wide. Auto-fill API available to apps. So they won't have to kind of do it. LastPass,
[00:20:23.980 --> 00:20:28.620]   you have to turn on stuff and things. They have to kind of do a accessibility work around and stuff.
[00:20:29.180 --> 00:20:34.940]   So this is welcome news. That means your password manager will be better at auto-filling in passwords.
[00:20:34.940 --> 00:20:42.140]   Picture in picture. So we already have that with YouTube, right? When you're watching a YouTube
[00:20:42.140 --> 00:20:48.620]   video, it can go down into a little thumbnail as you do other applications. There's a new
[00:20:48.620 --> 00:20:52.940]   app overlay window for apps to use instead of a system alert window and a multi-display support.
[00:20:52.940 --> 00:20:55.500]   Actually, I think this is going to be interesting.
[00:20:55.500 --> 00:21:02.300]   From the split screen. Yeah. Oh, that's good for tab. Oh, wait. No, it's handsets. Okay.
[00:21:02.300 --> 00:21:05.580]   Multi-display support is interesting because in your seeing this already,
[00:21:05.580 --> 00:21:13.580]   Windows phone has it. It's called, what's it called? Because of the C, I can't remember. But
[00:21:13.580 --> 00:21:20.940]   the idea is that your phone is going to be your computer. And if you can plug it into a display
[00:21:20.940 --> 00:21:24.860]   and keyboard, suddenly it's a full-size computer. And these phones are so powerful now. I think
[00:21:24.860 --> 00:21:29.500]   this is going to be a big category in the years to come. So you don't have more than one computer.
[00:21:29.500 --> 00:21:33.660]   You have one device that can be a desktop, a laptop. Earlier in the earlier conversation,
[00:21:33.660 --> 00:21:40.140]   you go abroad and you rent a screen and a keyboard and this is your computer.
[00:21:40.140 --> 00:21:46.860]   Right. I'm guessing, but that sounds like multi-display support for launching an activity on a remote
[00:21:46.860 --> 00:21:50.300]   display. That sounds maybe more. This is more like Chromecast. I don't know.
[00:21:51.580 --> 00:21:57.660]   Font resources and XML. Adaptive icons to help you integrate better with the device UI.
[00:21:57.660 --> 00:22:04.140]   This is for developers. Wide color, wide gamut color for apps.
[00:22:04.140 --> 00:22:12.300]   Newer. Oh, this is good. New Bluetooth audio codecs like LDAC. I'm not familiar with LDAC.
[00:22:12.300 --> 00:22:18.220]   New Wi-Fi features like Wi-Fi aware, previously known as neighbor awareness networking or NAN.
[00:22:21.100 --> 00:22:23.340]   With the appropriate hardware apps and nearby devices,
[00:22:23.340 --> 00:22:28.860]   can discover and communicate over Wi-Fi without an internet access point.
[00:22:28.860 --> 00:22:37.260]   Interesting sort of ad hoc. Oh, ad hoc networking. Yeah. Oh, I like that.
[00:22:37.260 --> 00:22:42.220]   Time I used to run Serval so we could do ad hoc networking, but no one else ran it.
[00:22:42.220 --> 00:22:46.300]   So yeah, this sounds like it'll be built in and built into Android O.
[00:22:46.300 --> 00:22:49.580]   That is so nerdy. Awesome. Nerdy. Awesome.
[00:22:50.540 --> 00:22:54.220]   I think that, I mean, yeah, think about that for like protests, but also think about what you
[00:22:54.220 --> 00:23:02.220]   could do from a community standpoint or just even conferences. Oh, so fun. Okay. Nice.
[00:23:02.220 --> 00:23:06.460]   Like it. Keyboard navigation.
[00:23:06.460 --> 00:23:15.020]   Arrow and tab navigation. A audio API for pro audio. This is something that's really
[00:23:15.020 --> 00:23:18.780]   been a problem in the past on Android. Actually, glad to see they're addressing this.
[00:23:18.780 --> 00:23:22.060]   And it wasn't really Android's fault. It was because of the kernel they were using,
[00:23:22.060 --> 00:23:26.060]   but latency on Android was too high for really professional music apps.
[00:23:26.060 --> 00:23:35.100]   So there is a new audio API that will have a high performance, low latency audio streams.
[00:23:35.100 --> 00:23:40.540]   That's very interesting for musicians. You know, that's why there's not a lot of great music apps
[00:23:40.540 --> 00:23:51.900]   on Android. Web view enhancements, Java 8, partner platform. This is a big, big, big, big changes,
[00:23:51.900 --> 00:23:58.620]   but not so much UI changes as a kind of API change. And I think isn't that kind of,
[00:23:58.620 --> 00:24:05.100]   feel like that's what Google said is that they're going to do a TikTok thing where they update the
[00:24:05.100 --> 00:24:09.340]   interface and then they update under the hood and they update the interface in the next one.
[00:24:09.340 --> 00:24:12.780]   Maybe I'm mistaken that was somebody else, but that would make sense.
[00:24:12.780 --> 00:24:20.860]   I really should talk to all these IoT companies about how they plan to implement and update their
[00:24:20.860 --> 00:24:24.940]   Android on the back end for all of their devices that are running versions of Android.
[00:24:24.940 --> 00:24:28.380]   Because a lot of them don't spend a lot of time on that.
[00:24:28.380 --> 00:24:35.100]   Right. Well, they do. Do they do iOS? Is that why is it like that's the platform of choice?
[00:24:35.740 --> 00:24:41.020]   No, they build their stuff on Android. Oh, on Android. Oh, I was going to have June Oven.
[00:24:41.020 --> 00:24:45.580]   You're June Oven. That's right. June is Android. That's right. There's other things.
[00:24:45.580 --> 00:24:49.740]   I think the Nucleus conference call conference system thing is built on Android.
[00:24:49.740 --> 00:24:55.500]   Interesting. It's out there. It's open. Yeah, it's free. It's free.
[00:24:55.500 --> 00:25:02.220]   Yeah. So YouTube TV, YouTube TV was announced about a month ago. Nobody knew when it was going
[00:25:02.220 --> 00:25:08.700]   to launch or wear. And it has launched today in five American cities. I think that everybody
[00:25:08.700 --> 00:25:14.860]   in the nation in the US can sign up, but you only get local programming from the area of one of
[00:25:14.860 --> 00:25:19.980]   those cities. New York Los Angeles, San Francisco Bay Area, Chicago, and Philadelphia.
[00:25:19.980 --> 00:25:24.780]   And see is going to be on the network. It's kind of right now. It's kind of the sports
[00:25:24.780 --> 00:25:29.100]   and locals network with a little news thrown in. It's got all the news networks as well.
[00:25:29.100 --> 00:25:35.980]   Yes. But I believe that this is really, really, really bad news for the cable TV industry and a
[00:25:35.980 --> 00:25:39.900]   really, really big deal, much bigger than people realize. And I'm going to tell you exactly why.
[00:25:39.900 --> 00:25:48.140]   Now, just a quick roundup of what it is. It's 40 channels for the basic. 35 bucks package,
[00:25:48.140 --> 00:25:53.420]   35 bucks. And that's five accounts, each of which has unlimited DVR. You can watch three of them
[00:25:53.420 --> 00:25:58.060]   simultaneously. You can watch that on a phone, on a tablet, on a TV with Chromecast
[00:25:58.860 --> 00:26:06.540]   etc. It has ABC, CBS, NBC, Fox, the CW, ESPN, USA, Bravo, etc. It's a Disney channel on and on.
[00:26:06.540 --> 00:26:10.860]   It does not have a TV. No, it has Oprah.
[00:26:10.860 --> 00:26:20.460]   What else you need? It does not have HBO, Amazon, MTV, it has. Yeah, you get this housewives.
[00:26:20.460 --> 00:26:27.580]   Yeah. And some cooking shows. It also has super hot. It also has a DVR functionality.
[00:26:28.060 --> 00:26:33.420]   Unlimited storage for the DVR. And this is how easy the accounts can have its own DVR. So
[00:26:33.420 --> 00:26:37.820]   your each of your kids can have their own unlimited DVR. So let's say I am an Archer fan,
[00:26:37.820 --> 00:26:43.740]   which I am and I want to record Archer. I could just click it to boom, I press the plus button.
[00:26:43.740 --> 00:26:48.380]   It will now record every Archer episode and I will have that available to me to watch time
[00:26:48.380 --> 00:26:55.100]   shifted. Oh, this is for you Stacey. Total Divas. You like that? Let's add. I don't know,
[00:26:55.100 --> 00:26:58.300]   but I think you're going to want to watch it. Add total divas to my DVR,
[00:26:58.300 --> 00:27:03.660]   the NCAA championships, Modern Fin. So this and it's got live locals, right?
[00:27:03.660 --> 00:27:10.300]   Does it have live locals for sports? Like, yes, yes. Because an MLB live,
[00:27:10.300 --> 00:27:15.100]   you know, your baseball games are locked out if you're just a. I don't know. I, you know,
[00:27:15.100 --> 00:27:18.860]   that's a good question. If because that is a little bit of a problem. That's annoying.
[00:27:18.860 --> 00:27:24.140]   Sometimes they promise that they've got major league baseball, but then you get blacked out.
[00:27:24.140 --> 00:27:29.340]   Well, this is they're probably going to be some of that, but probably less than on other services.
[00:27:29.340 --> 00:27:35.580]   It's the sports coverage is really good. It's sports. ESPN, ESPN to ESPN and you,
[00:27:35.580 --> 00:27:40.060]   the big 10 networks, SEC network. There's much better college coverage and and
[00:27:40.060 --> 00:27:45.340]   coverage. One and two and and B.C. sports here in the Bay Area. We've got the Bay Area
[00:27:45.340 --> 00:27:51.740]   networks so we can watch Giants baseball, Warriors basketball, CBS sports network. It's even got golf.
[00:27:52.380 --> 00:28:00.860]   It's got a, you know, the kids stuff sprouts Disney. It's got. Finneas and fur. Baby.
[00:28:00.860 --> 00:28:08.300]   So that's a thing that the thing that I think that that movies and TV shows are becoming more
[00:28:08.300 --> 00:28:14.620]   and more available on multiple places, you name it, Hulu, etc. But what's becoming more
[00:28:14.620 --> 00:28:18.700]   rare and valuable is event television, including sports. So the Oscars, the Olympics, the
[00:28:19.580 --> 00:28:23.980]   missing piece from any court that's missing. Again, that place you get that. Yeah.
[00:28:23.980 --> 00:28:29.980]   This provides and by the way, almost all of it. I, you know, and I can compare this to PlayStation
[00:28:29.980 --> 00:28:37.180]   view, AT&T's direct TV. There's three or four of these services now, but this is Google. The UI
[00:28:37.180 --> 00:28:42.700]   is spectacular. So here I am. This is, this is my, this is my cable guide. These are the live
[00:28:42.700 --> 00:28:48.060]   channels I can see. And you said Finneas and Furbs. So I hover over it and now I'm watching it.
[00:28:48.060 --> 00:28:54.700]   It's actually playing as a preview. I get a great, it says 17 minutes left. I get a great description
[00:28:54.700 --> 00:29:00.140]   of it. I could see if I want to watch it. I see what's next. I can DVR it from here. I can go full
[00:29:00.140 --> 00:29:05.980]   screen. This is, this is, this is how, you know, when, when Steve Jobs said I've looked TV, it's,
[00:29:05.980 --> 00:29:09.100]   you know, this is what I would have imagined Apple would have done in Apple. This is what he
[00:29:09.100 --> 00:29:14.300]   would have looked. This is Apple has not been able to put this together. You know, the, the
[00:29:14.300 --> 00:29:18.700]   thing that's powerful about this is that people under the age of 30 are obsessed with YouTube.
[00:29:18.700 --> 00:29:22.460]   But as they, as they get older and start families and go to college and all that kind of stuff,
[00:29:22.460 --> 00:29:26.140]   they're going to want to watch more mainstream TV, but they love YouTube already. And so they're
[00:29:26.140 --> 00:29:33.180]   going to start watching their live TV and their cable TV on YouTube. This is very devastating to
[00:29:33.180 --> 00:29:39.900]   the cable providers. I think one of the things it's going to do is finally turn phones into a
[00:29:39.900 --> 00:29:44.700]   legitimate and widespread medium for live TV. Cause this will work on my mobile device
[00:29:44.700 --> 00:29:51.340]   might even sell some iPads, right? It might. It'll work on all these mobile devices. The other
[00:29:51.340 --> 00:29:55.260]   thing that's really devastating to cable, and I think it's really underappreciated and underreported
[00:29:55.260 --> 00:30:00.860]   by all those fake news people is, is the fact that their advertising
[00:30:00.860 --> 00:30:07.660]   abilities are through the roof. The advertising industry has been champing it a bit for years to
[00:30:07.660 --> 00:30:13.900]   get for, for, for Google and YouTube to, to launch exactly this because their data on the users is
[00:30:13.900 --> 00:30:19.420]   amazing. And they'll be able to very tightly target advertising and YouTube would be able to
[00:30:19.420 --> 00:30:25.420]   charge a fortune for advertising because it'd be so, so tightly and, and, and accurately targeted
[00:30:25.420 --> 00:30:30.140]   at the demographics of the, of the viewers. They don't, the premium channels a little bit lacking,
[00:30:30.140 --> 00:30:34.620]   they have showtime, they do not have HBO. You'd have to buy HBO now. I mean,
[00:30:36.060 --> 00:30:41.420]   at 35 bucks, this is the least expensive offering. This beats PlayStation's lowest offering at 39.
[00:30:41.420 --> 00:30:48.620]   Yeah. What? So for NFL fans, you'll fall under blackouts on mobiles because Verizon has this.
[00:30:48.620 --> 00:30:52.460]   Right. I'm still trying to figure out the blackout situation. It, well, good luck.
[00:30:52.460 --> 00:30:57.340]   Cause it's, it's terrible. So look at this though. Here's sports on now, and I'm actually getting live
[00:30:57.340 --> 00:31:05.820]   mini feeds of the Giants game, the, the, uh, uh, athletics game, the NCAA championship. Here's ESPN,
[00:31:05.820 --> 00:31:11.740]   soccer, and total divas is apparently a sports show. I don't, I don't know that's the case,
[00:31:11.740 --> 00:31:14.940]   but it's in there, right? And these are all like that show. Yeah.
[00:31:14.940 --> 00:31:20.300]   These are all what they call soccer. Yeah. Total divas. Oh, that's right. It's the, the drop and flop.
[00:31:21.420 --> 00:31:28.380]   This is, this is the UI that you're, you're, you nailed it, by the way, uh, that,
[00:31:28.380 --> 00:31:34.620]   Oh my God. Total divas is a sports show. I had to look it up. Sorry. It is a docu series following
[00:31:34.620 --> 00:31:40.060]   the top female WWE superstars. Oh, but it's wrestling. So it's kind of got a little bit of both.
[00:31:40.060 --> 00:31:45.580]   Yeah. This, it's like reality TV on reality TV. Yeah. This is, this would not interest me.
[00:31:45.580 --> 00:31:52.620]   The title of this episode, season six, episode seven, a win wine situation. So you be the judge.
[00:31:52.620 --> 00:31:57.420]   Now I have to say for the YouTube generation, YouTube's mixed right in, including the YouTube
[00:31:57.420 --> 00:32:06.460]   originals, right? Shows on YouTube, YouTube videos. Uh, this, I could see my son, my 22 year old son,
[00:32:06.460 --> 00:32:10.940]   who does not watch TV, he watches YouTube. This is what he can, this is what he wants.
[00:32:10.940 --> 00:32:15.420]   And the beauty of it is that that family plan, the kids are going to be nagging the
[00:32:15.420 --> 00:32:21.020]   parents to get the family plan. The $35 a month covers five people. So all each of the kids gets
[00:32:21.020 --> 00:32:26.700]   their own separate, like account, their own DVR. This is, this is big news. This is going to be
[00:32:26.700 --> 00:32:33.180]   really popular. I think now what is that? So here's the big issue I see is this is a lean forward
[00:32:33.180 --> 00:32:38.940]   experience on mobile and even on computer. What is the lean back experience? Do I watch it on
[00:32:38.940 --> 00:32:44.940]   Chromecast and red TV? I guess, yes, right TV, right? Yes. And Chromecast and Google said that they,
[00:32:44.940 --> 00:32:49.660]   they're going to be making announcements this year of additional TVs. So I have a shield in a moment.
[00:32:49.660 --> 00:32:52.860]   This would, this will probably be now on my shield because I have YouTube on there.
[00:32:52.860 --> 00:32:59.580]   Uh, wow. But I do think, I do think that the subtle play here is a behavior one. And I do think
[00:32:59.580 --> 00:33:05.900]   it's going to turn live TV and event TV into a lean back experience. Getting the live locals is a big
[00:33:05.900 --> 00:33:12.380]   deal. Now I'm in the San Francisco area of dominant influence, but we are 50 miles north of San Francisco.
[00:33:12.380 --> 00:33:18.940]   We can't over the air get any San Francisco stations. So, you know, I hear up here in Petaluma,
[00:33:18.940 --> 00:33:23.900]   but I am getting the locals. I'm in the San Francisco Bay area. So that's really interesting.
[00:33:23.900 --> 00:33:28.220]   That's awesome. This, this could replace cable for me. This is, this is fantastic.
[00:33:28.220 --> 00:33:34.140]   The Bay area coverage seems to be much broader than the other. Yeah, they call it Bay area. Yeah.
[00:33:34.140 --> 00:33:40.860]   Yeah. Yeah. Wow. This is, uh, just in the nick of time, for baseball season to start.
[00:33:42.220 --> 00:33:43.340]   You don't have MLB live.
[00:33:43.340 --> 00:33:52.620]   Not anymore. Not anymore. It's $149 for the season. This is $35 a month. I guess it's the same,
[00:33:52.620 --> 00:33:55.980]   but it was, but I get a lot of other stuff. It sounds cheaper though.
[00:33:55.980 --> 00:33:59.340]   Even how long baseball season is. Sounds, sounds, sounds on cheaper though.
[00:33:59.340 --> 00:34:03.980]   They should have a weekly rate. That'd be really cheap. Um, wow. I, and I have to say,
[00:34:03.980 --> 00:34:09.420]   this is, I've played, I played with, for iOS today, we did a review. I did a review of the,
[00:34:09.420 --> 00:34:15.420]   all of the streaming packages, PlayStation View, which I think is the, was until now the best
[00:34:15.420 --> 00:34:19.340]   AT&T Direct TV, which did not work very well. And a lot of people have continued to complain
[00:34:19.340 --> 00:34:24.620]   that it's not working very well, that it's not playing their bugs. Uh, who else, uh,
[00:34:24.620 --> 00:34:31.420]   sling box, sling TV. Um, what are some of the other, I think that's the big three right there,
[00:34:31.420 --> 00:34:38.780]   sling TV, view and, uh, AT&T. This one beats them up, down in sideways. It's, it's in every
[00:34:38.780 --> 00:34:45.100]   respect. Plus it's cheaper. Yeah. Here's another, uh, subtle benefit. You can pause it. So if you're
[00:34:45.100 --> 00:34:50.060]   going to be out of the country for a month or two, you can not pay during those months. And if you
[00:34:50.060 --> 00:34:55.420]   don't, if nobody in your, on your family account logs in for three months, they automatically
[00:34:55.420 --> 00:35:01.820]   pause it. Well, that's, that's nice. That is very anti-cable company. Yeah. Yeah. Well,
[00:35:01.820 --> 00:35:06.860]   that's, is where competition really, we really benefit from that. Yeah. Uh, and so here's some
[00:35:06.860 --> 00:35:10.860]   movies. Let's say I did want to see the matrix. They know their geek audience. I click on it.
[00:35:10.860 --> 00:35:15.980]   It's going to be on sci-fi. I just press the plus button and now it's DVR. That's it. It's simple as
[00:35:15.980 --> 00:35:22.380]   that. Uh, wow. Is right. Can I, now I'd be interested if I'll be able to skip commercials.
[00:35:22.380 --> 00:35:29.260]   Then they also have, yeah, related on YouTube and here's all the YouTube content. So this is a
[00:35:29.260 --> 00:35:34.940]   great cross promotion for YouTube. And then there's more information about the cast. This is,
[00:35:34.940 --> 00:35:41.260]   this is exactly what the online consuming TV audience is now kind of expecting, right?
[00:35:41.260 --> 00:35:47.580]   Now, Leo imagine, right, but it doesn't imagine if they bought Twitter and integrated Twitter
[00:35:47.580 --> 00:35:52.620]   into that experience. How great that would be. Oh, that's what's missing from this is a kind of
[00:35:52.620 --> 00:36:00.700]   real time interactivity and outrage. How dare they put Lauren, like, how dare they put Lauren
[00:36:00.700 --> 00:36:08.620]   likes paternity court on at 4 30. Oh, time doesn't matter. I still remember my daughter
[00:36:08.620 --> 00:36:14.140]   saying to me, probably like when she was like six or seven, she's like, I really, I, I fit,
[00:36:14.140 --> 00:36:18.860]   because we've been court cutters forever. I feel really sorry for my friends who have to watch
[00:36:18.860 --> 00:36:25.980]   television shows when they're on. I was like, what are you talking about? Also, wow.
[00:36:27.180 --> 00:36:31.820]   So you get a first month's free. So I'm on the free trial. By the way, most of these other
[00:36:31.820 --> 00:36:36.220]   services, in fact, all the other services have one week free trial. So in every respect,
[00:36:36.220 --> 00:36:40.540]   YouTube has clearly paid attention to what's going on out there. Apple really wanted to launch
[00:36:40.540 --> 00:36:46.140]   this, by the way. But even if Apple does launch exactly the same service, it'll be limited to Apple
[00:36:46.140 --> 00:36:51.660]   TV. They don't have YouTube and they don't have YouTube. I could do this instead of Hulu. Sorry,
[00:36:51.660 --> 00:36:55.500]   my brain just clicked on, although it's kind of more expensive compared because I use Hulu as my
[00:36:55.500 --> 00:37:00.540]   network TV. But I get so irritated because they, you know, they window things that if you
[00:37:00.540 --> 00:37:07.420]   don't catch it. I don't know, see, it's not in Austin yet. So New York, LA, San Francisco, Chicago,
[00:37:07.420 --> 00:37:11.820]   and Philadelphia. We don't get that or Google five. They're going to have AMC, which is,
[00:37:11.820 --> 00:37:16.780]   that's the, that's the Walking Dead crowd. But again, Stacy, I'm pretty sure you can just get
[00:37:16.780 --> 00:37:21.500]   the Chicago one. Really? Is that the case? Pretty sure. You don't have to be in that area. Why don't
[00:37:21.500 --> 00:37:24.940]   you try them right now, Stacy? TV.YouTube.com.
[00:37:24.940 --> 00:37:28.540]   TV.YouTube.com.
[00:37:28.540 --> 00:37:34.860]   And Hulu is working on its own. These are called skinny bundles.
[00:37:34.860 --> 00:37:41.420]   Terrible name. Try one month free. Oh my God. But I've got to pick one of my eight Google accounts.
[00:37:41.420 --> 00:37:47.580]   I guess my personal one. It's one month free. Just remember to cancel it in a month. That's
[00:37:47.580 --> 00:37:52.140]   what I did is I set reminders to cancel all of those other services because I did not want to
[00:37:52.140 --> 00:37:56.700]   have it. Oh wait, hold on. Now I've picked my account. It's asking me about my location. Okay.
[00:37:56.700 --> 00:38:04.460]   They guessed my location wrong, but it is not available in my area. Yeah. So they're not
[00:38:04.460 --> 00:38:08.060]   letting you do it. So what if you have to be in those bedrooms? Chicago.
[00:38:08.060 --> 00:38:11.100]   Give me a zip code for Chicago.
[00:38:12.140 --> 00:38:18.620]   What is the Spiegel catalog, right? 60601? 606. I'm not even speaking.
[00:38:18.620 --> 00:38:19.420]   I'm not even going to go. I'm not even going to go. I'm not even going to go. I'm not even going to go.
[00:38:19.420 --> 00:38:26.460]   Oh no. I 6061. Oh Chicago area. YouTube TV is available in my area, but unfortunately,
[00:38:26.460 --> 00:38:28.460]   you're going to have to wait until you're home to sign up.
[00:38:28.460 --> 00:38:36.540]   But what if you use VPN? Yes, I could.
[00:38:36.540 --> 00:38:40.540]   VPN, but that's not, you know, that's not going to be satisfactory. The question really is how soon do
[00:38:40.540 --> 00:38:45.820]   they roll this out nationwide? Will they? I suspect that they have to make these negotiations with
[00:38:45.820 --> 00:38:52.860]   the locals in each market, right? Or no. You can't go to CBS and say, hey, can we run KPIX,
[00:38:52.860 --> 00:39:00.140]   our local CBS station? Let's see what the quality is. It's starting off not great. And remember,
[00:39:00.140 --> 00:39:08.140]   we have it. Oh, but I can, the auto 360, I can go up to 480p. I don't see HD. That might be another
[00:39:08.140 --> 00:39:10.860]   issue. So Judge Judy doesn't look as good as she ought to.
[00:39:10.860 --> 00:39:17.100]   Is that Judge Judy? No, I don't know who it is. You're asking the wrong guy.
[00:39:17.100 --> 00:39:21.660]   Judy said she's got she's older and has shorter. Who is that? That's the people's court. This is
[00:39:21.660 --> 00:39:29.580]   the Wopner replacement. Time for a Wopner. Judge Judy's coming up. Oh, okay. Yeah, that's
[00:39:29.580 --> 00:39:37.980]   Judge Judy. I got fooled. What do you think? Close captioning? When you're already in on,
[00:39:37.980 --> 00:39:44.460]   you're over your head in just audio track primary. I guess I can do, let's see if that
[00:39:44.460 --> 00:39:51.820]   sounds in Spanish. So then subtitles. He called me. He said he was unhappy. He wanted to come back.
[00:39:51.820 --> 00:39:55.420]   Oh, watch. This is the way to watch it. I can watch it at double speed.
[00:39:58.380 --> 00:40:03.100]   Oh my god. That would be awesome for all those reality shows that we play everything a million
[00:40:03.100 --> 00:40:05.820]   times. So I'll come back. I wish they'd make the voices twice as high.
[00:40:05.820 --> 00:40:10.300]   And his behavior just became a Reddit path. He was eyes closed. He would start talking, you know,
[00:40:10.300 --> 00:40:15.500]   rambling. At one point, he took a pack of frozen meat. That's why you're acting like this.
[00:40:15.500 --> 00:40:21.660]   Why are you acting like this? Why are you doing this to me? That's really interesting. YouTube TV.
[00:40:21.660 --> 00:40:25.980]   Wow. I think this might be a kill. And I have to say, I've seen Google do some stupid things,
[00:40:25.980 --> 00:40:31.980]   but this is a killer product. I still like YouTube TV. Here we are, what, seven,
[00:40:31.980 --> 00:40:36.220]   eight months later. And I still, I didn't cancel my subscription. I subscribed just to try it.
[00:40:36.220 --> 00:40:42.620]   But I really still think it's a, it's actually a great deal for TV. I haven't, on the other hand,
[00:40:42.620 --> 00:40:48.940]   canceled my cable either. You never cancel anything. I don't just pay more. I'll up more monthly fee
[00:40:48.940 --> 00:40:57.740]   or content. What was your, I'm a such a sucker. What was, I'm just curious,
[00:40:57.740 --> 00:41:03.180]   your favorite deaf used to be a TV critic. So I'll start with you, your favorite TV show of the
[00:41:03.180 --> 00:41:07.580]   year was there one that just really enjoyed. Well, I just finished binge watching. I'm going to be,
[00:41:07.580 --> 00:41:13.020]   I'm going to be a cliche, but I strange things was a lot of fun. It really wasn't. And Susan too was
[00:41:13.020 --> 00:41:16.300]   arguably even better than season one. Yes. I think so. I think really,
[00:41:16.940 --> 00:41:21.900]   several times during the show, I actually exclaimed out loud, Lisa, can vouch for this.
[00:41:21.900 --> 00:41:28.540]   This is the best show I've ever seen. I wouldn't go to that far. It's good though. It's good.
[00:41:28.540 --> 00:41:31.980]   It's good. It's good. It's really enjoyed. How about, how about you, Stacey? Yeah.
[00:41:31.980 --> 00:41:36.700]   Was there a show or a movie or something you watched that you really thought was great this year?
[00:41:36.700 --> 00:41:45.340]   I have four. Four is good. So host Trump in office. I was kind of feeling bummed. So I
[00:41:45.340 --> 00:41:48.460]   re-watched Parks and Rec. What a great show. And you know what,
[00:41:48.460 --> 00:41:54.060]   worth it, we re-watched that show. That show wears well, I think. I never got into it.
[00:41:54.060 --> 00:41:59.020]   Oh, really? You know what I'm trying to do? I'll tell you this show. Let me just sneak it.
[00:41:59.020 --> 00:42:04.220]   Oh, that was a great show. But now you have a kid that's the perfect age for Lemony. Yeah.
[00:42:04.220 --> 00:42:10.780]   Yes. And there's such a shortage of good quality TV for like real family watching. So
[00:42:10.780 --> 00:42:13.020]   that was amazing. And I can't wait for the next ones.
[00:42:14.300 --> 00:42:19.820]   Oh, they're going to do more? Neil Patrick Harris is perfect in it. He's so good in it.
[00:42:19.820 --> 00:42:25.020]   And it's even better because they made a movie of this a couple of years ago that was awful.
[00:42:25.020 --> 00:42:28.860]   It was. It was terrible. It was terrible. But they got Lemony.
[00:42:28.860 --> 00:42:32.300]   Snicket involved in the production of this one. And it's much truer to the books and really
[00:42:32.300 --> 00:42:37.980]   wonderful and creepy at the same time. And the only... But not... Yeah, but not too creepy.
[00:42:37.980 --> 00:42:42.860]   And the only show I've ever seen that begs you not to watch it every time in the beginning.
[00:42:44.060 --> 00:42:50.460]   Go away. What else? That's two. The good place.
[00:42:50.460 --> 00:42:55.020]   You know, I started watching that because of you and I enjoy it. I do enjoy it. It's very good.
[00:42:55.020 --> 00:42:58.460]   But I love her. I do too. And Ted dance. Good. Yeah.
[00:42:58.460 --> 00:43:04.300]   I'd say stranger things because it was also awesome. Wasn't it awesome? Yeah. I have one.
[00:43:04.300 --> 00:43:09.340]   It's a late entry, but I've been binging it and I love it. Is the Marvelous Mrs. Maisel on...
[00:43:10.140 --> 00:43:13.660]   Oh, I'm sorry. I'm sorry. Good. You know what I like it? I'm in it.
[00:43:13.660 --> 00:43:18.860]   Not really. In it? Well, not really. But it takes place in 1958
[00:43:18.860 --> 00:43:24.780]   in the Upper West Side of New York, which is where I was born in 1956. There's a two-year-old boy who
[00:43:24.780 --> 00:43:31.820]   looks just like me in it. I think it's me. And it could be my mom. So, except for the circumstance,
[00:43:31.820 --> 00:43:35.660]   it's a little bit different. But it's a wonderful period piece in a very interesting time in New
[00:43:35.660 --> 00:43:43.900]   York's history. It's one of the whole crop of new strong women leads. She's going to be a superstar,
[00:43:43.900 --> 00:43:47.260]   I think, out of it. I can't remember her name, but she's very good. And I think you'll just enjoy it.
[00:43:47.260 --> 00:43:52.860]   The music's great in it. One thing I like about Amazon, I feel like Amazon does...
[00:43:52.860 --> 00:43:59.020]   they don't have rights problems with the music. So, sometimes you'll see a show. There was a show
[00:43:59.020 --> 00:44:03.660]   on HBO about rock and roll. They didn't want to play the real songs. They didn't want to pay for it.
[00:44:03.660 --> 00:44:09.980]   So, they had kind of fakie sounding. I can't remember which one of the many shows on HBO,
[00:44:09.980 --> 00:44:16.380]   maybe it was vinyl, but they had fakie songs. And it really annoyed me. They've got all the real
[00:44:16.380 --> 00:44:22.060]   songs, lots of Streisand and Sinatra and stuff. And it really sets the tone. It's beautifully,
[00:44:22.060 --> 00:44:28.140]   beautifully done. Oh, and that another period piece with a strong female lead, The Crown.
[00:44:28.140 --> 00:44:35.020]   Love The Crown, the most expensive television show ever made. I'm just thinking that she's dull.
[00:44:35.020 --> 00:44:39.500]   Well, she is dull. That's kind of the point. She's the queen. You can't.
[00:44:39.500 --> 00:44:45.900]   You're the one exciting queen. How can you tell over a show about adulthood? Have you seen the
[00:44:45.900 --> 00:44:51.900]   second season yet? I was in any of Victoria. Victoria was very cool. I felt like him. Yes.
[00:44:51.900 --> 00:44:55.740]   First season was a little duller than the second season. I'm finding there more dynamics in the
[00:44:55.740 --> 00:45:01.660]   second season of The Crown. I'm really enjoying it. So as a woman who is expected to behave a
[00:45:01.660 --> 00:45:10.300]   certain way, when I saw that, I saw her internalizing and then working her way around things that I've
[00:45:10.300 --> 00:45:17.900]   always had to, I don't necessarily obey it, but be aware of it. So it probably does speak to a lot
[00:45:17.900 --> 00:45:22.140]   of women. And it's also, by the way, the same period. It starts in 1956, the second season.
[00:45:23.340 --> 00:45:27.500]   I just started watching Dark. Now tip on Dark. And I know you're doing this.
[00:45:27.500 --> 00:45:33.580]   If you just watch it in Netflix in default, it's got the worst English dubbing I have ever seen in
[00:45:33.580 --> 00:45:37.820]   my life. Yeah, I had the the Germans subscribe. It's horrific. But I didn't read. Yeah, you can go
[00:45:37.820 --> 00:45:42.940]   right in the Netflix settings and it turned on English subtitles. But it really is the darker
[00:45:42.940 --> 00:45:47.980]   dark stranger thing. It's really strange. It's just rocket strange. Yeah, it's rocket strangers.
[00:45:47.980 --> 00:45:56.540]   Yeah. Now is the time when we kill. No, I like it. And it's much better than German. The original
[00:45:56.540 --> 00:46:03.260]   German is perfect. It's worse for the suits. So well. I felt like with the dubbed version,
[00:46:03.260 --> 00:46:06.940]   I was watching Woody Allen, What's Up Tiger the Lady. It was just like, it was almost comedic,
[00:46:06.940 --> 00:46:11.660]   right? Oh, it's terrible. All right, let's move on. That was that's actually a good way to end the
[00:46:11.660 --> 00:46:16.060]   year's talk about our favorite broadcasting of the year. But we also talk a lot on the show about
[00:46:16.060 --> 00:46:21.260]   Google, of course, and Facebook. You were at Facebook's developers conference F8.
[00:46:21.260 --> 00:46:28.300]   And we talked a little bit about it back in April. Let's first get a report from F8. We covered the
[00:46:28.300 --> 00:46:36.140]   keynote yesterday. And a lot of attention paid to a couple of things. Mark Zuckerberg and company
[00:46:36.140 --> 00:46:42.300]   announced a new platform in the Facebook app for V for a augmented reality using the camera
[00:46:43.500 --> 00:46:47.820]   platform in the sense that developers will have a way to access the camera and information and add
[00:46:47.820 --> 00:46:51.980]   filters and things to it. Some people said it was, you know, really a catch up to snap chats,
[00:46:51.980 --> 00:47:00.300]   filters and world filters, which Snapchat announced the day before. They also announced the VR spaces,
[00:47:00.300 --> 00:47:05.900]   which is a beta version of an Oculus Rift program that allows you to finally be in the same space
[00:47:05.900 --> 00:47:11.100]   as somebody else wearing Oculus Rift and interact with them. So what do you think, Jeff?
[00:47:12.220 --> 00:47:17.260]   So I think Farhad Manchu in the Times this morning had the best piece that I've read and
[00:47:17.260 --> 00:47:21.260]   probably the best thing I think he's ever written about Facebook today. And he starts off, I'm
[00:47:21.260 --> 00:47:25.580]   never going to like it very much, we start off saying, yeah, okay, so Mark's a thief. So they took
[00:47:25.580 --> 00:47:28.860]   this stuff from Snapchat and they took other stuff from other places. They bought other companies.
[00:47:28.860 --> 00:47:36.700]   But then by the end, he says, and so what? Steve Jobs stole, Bill Gates stole. This is where it is.
[00:47:37.580 --> 00:47:42.780]   The power of Facebook is the network. And I think he was really right. Chris Cox showed a good slide
[00:47:42.780 --> 00:47:48.780]   yesterday and the keynote notes where he showed one axis was how they go from one-on-one relationships
[00:47:48.780 --> 00:47:54.780]   to your community up through your geography, to government, to immediate the government.
[00:47:54.780 --> 00:47:59.100]   And on the other axis was all the tools they have from text to photos all the way to AR/VR.
[00:47:59.100 --> 00:48:03.180]   But what really struck me is they missed a third axis. And a third axis is what Facebook
[00:48:03.180 --> 00:48:07.340]   really is, which is that it connects people to people. And that's what Farhad is really talking
[00:48:07.340 --> 00:48:11.260]   about. That's the power of Facebook. That's the, that allows them to do anything they want. So,
[00:48:11.260 --> 00:48:18.620]   yeah, they took, they took features from Snapchat. Top, it's kind of the world. And maybe they weren't
[00:48:18.620 --> 00:48:21.580]   the most innovative in the world. Maybe they're following, but they have the network that is
[00:48:21.580 --> 00:48:26.300]   phenomenal. And so yes, they have the power to bring rainbow puke to the world.
[00:48:26.300 --> 00:48:33.740]   Right. Well, you know, reminds me of Matthew is Microsoft in the 1990s. They embraced it.
[00:48:33.740 --> 00:48:40.300]   Embrace them. Yeah, exactly. That's exactly what I thought of too. And, you know, to be fair,
[00:48:40.300 --> 00:48:45.740]   I think they, they did copy stories, right? They copied it whole, it's boeless. They've
[00:48:45.740 --> 00:48:51.500]   copied lots of other things. But what they are talking about with augmented reality, they didn't
[00:48:51.500 --> 00:48:57.500]   just develop that stuff a week ago, because they saw that Snapchat was working on it. This is,
[00:48:57.500 --> 00:49:01.900]   these are things that Facebook and just about everyone, I think, has been thinking about
[00:49:01.900 --> 00:49:07.100]   for quite some time. So it does look as though, you know, they're duplicating things that
[00:49:07.100 --> 00:49:11.900]   Snapchat is doing. I think they both seem to be moving along the same track, which is to use the
[00:49:11.900 --> 00:49:19.820]   camera as the easiest sort of interface to a virtual world. That just makes sense. They've also,
[00:49:19.820 --> 00:49:26.380]   their vision, I think, goes significantly farther than Snapchat's has or at least has so far. So,
[00:49:26.380 --> 00:49:30.060]   are they duplicating each other? Yes. But I don't think it's just
[00:49:30.700 --> 00:49:34.220]   Facebook is out of ideas. And so they're copying whatever Snapchat does.
[00:49:34.220 --> 00:49:41.020]   Farhad Manju quotes Miranda Carr, Evan Spiegel's fiance, in an interview with The Times of London,
[00:49:41.020 --> 00:49:45.660]   she said, "She couldn't stand Facebook's behavior. Can they not innovate? Do they have to steal all
[00:49:45.660 --> 00:49:49.980]   of my partner's ideas?" she asked. "When you directly copy someone, that's not innovation,
[00:49:49.980 --> 00:49:55.100]   to which I say writes Farhad." Meh, there are lots of different kinds of innovation in the tech
[00:49:55.100 --> 00:50:00.220]   industry. Coming up with something first is not the only kind. One of the reasons Microsoft got
[00:50:00.220 --> 00:50:08.460]   dung-dinged for this, or is it dung-d for this? Dung-d is because it looked like they were being a bully.
[00:50:08.460 --> 00:50:15.100]   They used their market share to invest, to approach companies. They would like to see more of that
[00:50:15.100 --> 00:50:20.380]   and then steal it. Or they'd buy companies that were competitive and engulf them.
[00:50:20.380 --> 00:50:25.100]   And to some degree, Facebook's done this. But I don't think Facebook's being a bully here.
[00:50:25.100 --> 00:50:29.820]   And I think you're right, Jeff, that they had to have been working on this all along. It wasn't
[00:50:29.820 --> 00:50:33.020]   like, "Oh, we like this worldviews. Can we do that tomorrow?"
[00:50:33.020 --> 00:50:38.460]   Right. And the best use of innovation they showed today in the keynote, where they talked about
[00:50:38.460 --> 00:50:43.820]   direct connections to your brain and AR glasses in our lifetime that are comfortable and really
[00:50:43.820 --> 00:50:51.100]   work. And another thing is that they are truly innovating in gigantic ways. And Snapchat,
[00:50:51.100 --> 00:50:55.820]   bless their soul, came up with a mechanism that young people like to communicate with each other.
[00:50:55.820 --> 00:50:59.580]   They did a brilliant job of it. But in a competitive world, you see the best ideas and
[00:50:59.580 --> 00:51:04.060]   you use them. How innovative is Facebook? We'll see over the next 20 years. It's only just
[00:51:04.060 --> 00:51:09.340]   how does bar mitzvah. For the first time ever, an advertisement has intentionally triggered
[00:51:09.340 --> 00:51:15.020]   a voice assistant intentionally. We do it by accident all the time. Now, if you've got a Google
[00:51:15.020 --> 00:51:20.380]   home, go ahead, Jeff. Put your Google home up next to the speaker. What's funny is this burger
[00:51:20.380 --> 00:51:26.460]   king ad doesn't do what it was trying to do. So maybe they didn't expect it to work. They just
[00:51:26.460 --> 00:51:31.420]   thought to be make everybody laugh. You're watching a 15 second burger king at,
[00:51:31.420 --> 00:51:34.780]   which is unfortunately not enough time to explain all the fresh ingredients in the
[00:51:34.780 --> 00:51:41.980]   Whopper sandwich. But I got an idea. Oh, what is the Whopper burger?
[00:51:41.980 --> 00:51:49.500]   Wow. Wikipedia. The Whopper is a hamburger consisting of a flame-rilled quarter pound beef
[00:51:49.500 --> 00:51:55.100]   patty, sesame seed bun, mayonnaise, lettuce, tomato, pickles, ketchup, and sliced onions.
[00:51:55.100 --> 00:52:02.620]   Oh, it did work. It did work. Now, I've got Google had. Okay. So here's what I hear this story
[00:52:02.620 --> 00:52:09.340]   like evolving. And I feel like so played by con glomerates here. But they said Wikipedia was
[00:52:09.340 --> 00:52:14.940]   edited to change the top section of it. Oh, my God. For a while. And they were like,
[00:52:14.940 --> 00:52:19.260]   did Burger King do it? Did someone else do it? Okay. So was that Prankster or Burger King?
[00:52:19.260 --> 00:52:24.140]   The other thing then was that I had seen that Google had stopped that from working. But clearly,
[00:52:24.140 --> 00:52:32.860]   Jeff, yours just weren't. Yeah. So it looks like Burger King is behind the Wikipedia edit because
[00:52:32.860 --> 00:52:41.660]   the line was added by somebody with a username, Fairmachado 123 Burger King's marketing chief
[00:52:41.660 --> 00:52:48.940]   is Fernando Machado and he uses firma chado 123 on Instagram and a very similar name on Twitter.
[00:52:51.100 --> 00:52:56.300]   So don't feel like I'm being played. You are being played, but not by Google by Burger King.
[00:52:56.300 --> 00:53:05.660]   This is like, okay, so this is why voice authentication needs to come sooner rather than later.
[00:53:05.660 --> 00:53:13.100]   And by the way, the Verge modified the Wikipedia entry and the Google home said the new entry.
[00:53:13.100 --> 00:53:19.340]   So, you know, if I were Burger King, I'd be very nervous at this point. We should check.
[00:53:19.340 --> 00:53:23.100]   Read the other story. Yeah, read the other story. Oh, yeah, I don't got far worse.
[00:53:23.100 --> 00:53:26.540]   The one right there on the rundown. Oh, okay. So, so this is the
[00:53:26.540 --> 00:53:31.900]   total flipping. The Whopper is made of toenail flipping. Oh, my God.
[00:53:31.900 --> 00:53:39.020]   Yeah, because the Wikipedia was adapted and voice comes from Wikipedia. Now they fixed it.
[00:53:39.020 --> 00:53:42.380]   And I would guess Wikipedia is locked it down. Although oddly, they've locked it
[00:53:42.380 --> 00:53:46.540]   with the promotional copy. Well, of course they did.
[00:53:47.500 --> 00:53:52.380]   Well, but Wikipedia doesn't take ads. That's very interesting.
[00:53:52.380 --> 00:53:55.180]   It's not inaccurate. I mean, the Whopper and I mean,
[00:53:55.180 --> 00:54:01.340]   not made of nail clippings. That's inaccurate. And so I, yes, like if it's said, it's a delicious
[00:54:01.340 --> 00:54:05.660]   burger with lightly toasted sesame seeds. That's true. It is just mere facts. Yeah.
[00:54:05.660 --> 00:54:12.780]   But by the way, Burger King got what it really wanted, which is all this social media play.
[00:54:12.780 --> 00:54:16.940]   You're welcome, Burger King. Here we are. I'm going to be better than
[00:54:16.940 --> 00:54:20.620]   Chipotle Burger King. You can buy an ad on this very show. We'll play your ad.
[00:54:20.620 --> 00:54:23.340]   Well, I'll eat burgers if you want during the show.
[00:54:23.340 --> 00:54:26.940]   Not if it's the wrong three days. Yeah.
[00:54:26.940 --> 00:54:27.260]   Right.
[00:54:27.260 --> 00:54:33.500]   But isn't that interesting? And I wonder if we'll see more of that.
[00:54:33.500 --> 00:54:33.740]   Right.
[00:54:33.740 --> 00:54:36.380]   That'd be a better commercial Leo. You're on your fast day and we start,
[00:54:36.380 --> 00:54:40.620]   they start, of course, and runs the Whopper under your nose to torture. Shaking.
[00:54:44.540 --> 00:54:47.980]   Isn't that funny? Isn't that funny? It's like,
[00:54:47.980 --> 00:54:53.420]   but it feels like we're going to be like people were saying, apparently,
[00:54:53.420 --> 00:54:58.380]   when I did my little birthday thing, they were like, oh, you triggered my echo.
[00:54:58.380 --> 00:55:03.820]   You know, and I'm like, oops. It's a dick move to trigger someone's voice activated speaker.
[00:55:03.820 --> 00:55:04.860]   Intentionally it is.
[00:55:04.860 --> 00:55:07.340]   Intentionally. It's easy enough to do accidentally.
[00:55:07.340 --> 00:55:07.900]   Yes.
[00:55:07.900 --> 00:55:13.180]   In fact, it goes back to Aaron Paul, where there was an Xbox ad where the actor from Breaking Bad
[00:55:13.740 --> 00:55:21.340]   issued some Xbox commands and quite famously, because many people, not many, but probably many
[00:55:21.340 --> 00:55:27.020]   relatively, I did had their Xbox hooked up to their television set. And so,
[00:55:27.020 --> 00:55:31.420]   when he issued the command in the Xbox ad, it took over the TV.
[00:55:31.420 --> 00:55:36.300]   And you no longer were watching the ad. That was an unintended consequence.
[00:55:36.300 --> 00:55:38.460]   Like ad advertising.
[00:55:38.460 --> 00:55:43.740]   I think this is quite clever. I wonder what Google will do to keep it from happening.
[00:55:43.740 --> 00:55:48.380]   Again, I guess there's nothing they can do. You're right. The one solution, Stacy, is voice
[00:55:48.380 --> 00:55:53.740]   authentication training. Or you could do like, well, didn't we have a whole, I feel it in my
[00:55:53.740 --> 00:55:57.740]   hallucinating this conversation, but we had a whole thing about frequencies that you could play
[00:55:57.740 --> 00:56:02.140]   underneath the. Yeah, no, we talked about it. And I know everybody by playing a five kilohertz tone.
[00:56:02.140 --> 00:56:03.260]   Oh, right. Oh, yeah.
[00:56:03.260 --> 00:56:04.940]   Show and everybody was getting very upset.
[00:56:04.940 --> 00:56:08.060]   You really pissed off everybody below a certain age.
[00:56:08.060 --> 00:56:14.860]   This week in Google brought to you on our special year ender by a great company, a company
[00:56:14.860 --> 00:56:19.660]   with a product I've used many, many times go to webinar. We've used it to host,
[00:56:19.660 --> 00:56:24.620]   I gave a go to webinar on how to keep your kids, your teenagers safe, for instance.
[00:56:24.620 --> 00:56:29.420]   We've used it to promote Twit. We've used it to promote other products is really a great tool.
[00:56:29.420 --> 00:56:37.100]   They have 2.7 million interactive web events every year, 60 million viewers every year.
[00:56:37.100 --> 00:56:43.100]   It's designed to have you or as many as six presenters talk to almost an unlimited number of
[00:56:43.100 --> 00:56:49.660]   viewers. And by the way, you can not only talk to them, they can see you face to face, but they can
[00:56:49.660 --> 00:56:54.700]   also see your desktop or your application. You can show them a PowerPoint presentation.
[00:56:54.700 --> 00:56:59.900]   Go to webinar is awesome starts with you creating the webinar makes it very simple to make custom
[00:56:59.900 --> 00:57:04.940]   email invitations and confirmations and reminders. They have automated email templates. It makes
[00:57:04.940 --> 00:57:09.260]   it even easier. Of course, your company logo and images on it. It's great for marketing.
[00:57:09.260 --> 00:57:12.300]   You can create and schedule prerecorded webinars,
[00:57:12.300 --> 00:57:17.900]   do them and then have people watch them anytime on demand and they'll be just as interactive,
[00:57:17.900 --> 00:57:23.740]   just as much fun. And that's great. It means you give one seminar, but it continues to
[00:57:23.740 --> 00:57:29.100]   broadcast your message for a long time. Mobile friendly to of course, both for you as a presenter,
[00:57:29.100 --> 00:57:33.820]   you could schedule a webinar, edit the session, track performance on your iOS or Android device.
[00:57:33.820 --> 00:57:38.940]   You people can view you on their iOS or Android device. I really like the poll feature, which
[00:57:38.940 --> 00:57:43.900]   makes it interactive. If you're giving a webinar, you want to know are people paying attention?
[00:57:43.900 --> 00:57:48.540]   Do they understand you can do on the fly Q&A? You can also prepare polls in advanced,
[00:57:48.540 --> 00:57:53.980]   very valuable for marketing. It makes a webinar very much more interactive. It's not just them
[00:57:53.980 --> 00:57:58.380]   passively consuming it. It's better than TV for that reason. It's really interactive, but it looks
[00:57:58.380 --> 00:58:04.460]   as good as TV. Go to webinar. Also, we'll let you know how your webinar is doing with amazing
[00:58:04.460 --> 00:58:10.140]   reporting and analytics. Just a click away. You'll get qualified leads. You can get metrics.
[00:58:10.140 --> 00:58:14.460]   The information you need to make your webinars more compelling, more interesting too.
[00:58:14.460 --> 00:58:20.060]   Of course, it's secure 128-bit AES encryption end-to-end. Number one in customer satisfaction,
[00:58:20.060 --> 00:58:27.660]   I want you to try it right now. Turn your next presentation into a conversation with go to webinar.
[00:58:27.660 --> 00:58:35.500]   For more information, visit the website, go to webinar.com/podcast. Go to webinar.com/podcast.
[00:58:35.500 --> 00:58:39.820]   We thank them for their support of our year-end this week in Google.
[00:58:40.620 --> 00:58:45.100]   Hey, let's talk about them. Let's talk about why I just got a Google Pixel and it won't let me
[00:58:45.100 --> 00:58:53.180]   choose Hangouts as my default messaging app. Why can't you use Hangouts? I don't know because it's
[00:58:53.180 --> 00:58:58.940]   a Google phyphone and Google phy. Text messages come in as Hangouts, but they apparently don't want
[00:58:58.940 --> 00:59:05.500]   me to use it to send out as a message. I have to use Android Messenger or Facebook. There was a bug
[00:59:05.500 --> 00:59:10.460]   with that. I don't think it's a bug. I think this is the new thing. Are you a Google voice user?
[00:59:10.460 --> 00:59:19.100]   Yes. I've got a Google phyphone. This is a phyphone. I've got a Google phyphone and I'm always
[00:59:19.100 --> 00:59:24.300]   hanging out on it just fine. No, I'm just saying. Go into apps, choose your default apps,
[00:59:24.300 --> 00:59:28.860]   and it's where it says SMS app. What are your choices? Well, in my case, Facebook Messenger
[00:59:28.860 --> 00:59:33.900]   messages, which is Android messages, and Signal because those are the three messaging apps I
[00:59:33.900 --> 00:59:38.540]   have installed, not Hangouts. But what does Binget the default do for you anyway?
[00:59:38.540 --> 00:59:42.620]   It means that if you send an SMS, it goes through Android messages.
[00:59:42.620 --> 00:59:47.900]   Why wouldn't you send an SMS from Hangouts? I can, but it's not the default.
[00:59:47.900 --> 00:59:53.020]   Yes, you can. Just use Hangouts. If you send from-- If you send--
[00:59:53.020 --> 00:59:56.860]   No, no. On my dock, the Hangouts is the messaging app on my dock.
[00:59:56.860 --> 01:00:01.020]   So when you send from Hangouts, you're sending from Hangouts. So the problem is when you receive,
[01:00:01.020 --> 01:00:07.580]   but if you've clicked on Google Voice, redirect anything from Google Voice to Hangouts,
[01:00:07.580 --> 01:00:12.940]   then it'll come into Hangouts. It's a phyphone phone. Hum.
[01:00:12.940 --> 01:00:19.820]   It doesn't matter that it's a phyphone. That's just a SIM card. Right?
[01:00:19.820 --> 01:00:23.500]   Well, I'm using Google Voice. No, I'm telling you that's the whole fix it.
[01:00:23.500 --> 01:00:26.220]   That's how I fix it. Switch from Hangouts to a new text messaging app.
[01:00:26.220 --> 01:00:29.260]   But you don't need to switch. You're happy with what you're doing.
[01:00:29.260 --> 01:00:34.060]   I know, Google. Just use that. I don't have the little thing in front of me to show you,
[01:00:34.060 --> 01:00:36.460]   but just go into Hangouts and make sure you've ticked--
[01:00:36.460 --> 01:00:39.500]   No, I know what you're talking about. No, I know what you're talking about.
[01:00:39.500 --> 01:00:45.100]   And I am. And I still am. And text messages now come to both Android Messenger and Hangouts.
[01:00:45.100 --> 01:00:50.620]   I haven't had this problem. Well, go ahead and try it. Maybe you haven't updated the latest
[01:00:50.620 --> 01:00:55.180]   version of Android 7.1.2. Connect Hangouts in Google Voice, right?
[01:00:55.180 --> 01:00:59.900]   Yeah, no, no, no. Look in your phone. Look in your Pixel phone. You can no longer make Hangouts
[01:00:59.900 --> 01:01:05.340]   your default SMS app. But I guess I never used it as my default. I never set it in the first place.
[01:01:05.340 --> 01:01:09.500]   All right. So you get your SMS messages in two places.
[01:01:09.500 --> 01:01:15.900]   Well, I don't think so. I don't. It's confusing. I have to go look.
[01:01:15.900 --> 01:01:21.100]   Google's dropping SMS support from Hangouts. I can't go look right now. I'm on the phone.
[01:01:21.100 --> 01:01:25.900]   But-- No, that wasn't the same thing. But that was for Google Voice people. And that's not for
[01:01:25.900 --> 01:01:31.260]   Google Voice people. No, five people were exempted. I understand. I'm not a Google Voice person because
[01:01:31.260 --> 01:01:38.140]   I lost my stand. I am and I'm not. If I go to watch-- You know this. If you go to voice.google.com,
[01:01:38.140 --> 01:01:43.500]   watch. Go ahead, watch. You have to log out of Google Voice. It brings you to Project Fi.
[01:01:43.500 --> 01:01:51.900]   Right. If you have Google Voice on one account and you have Google Fi or Fi as I like to call it--
[01:01:51.900 --> 01:01:58.700]   Why? --like GIF on another account, you can never be logged in. You got to totally log out of that
[01:01:58.700 --> 01:02:04.940]   Google Fi account. But I don't want to log out. I'm using Google Fi. What do you care on Google Fi
[01:02:04.940 --> 01:02:11.420]   on the web? This is how I see my billing and my thing. But just open it up in an incognito tab.
[01:02:12.780 --> 01:02:16.380]   Or why are you going to Google Voice anyway on the web? You only need to do it once.
[01:02:16.380 --> 01:02:19.580]   OK. I have Google Hangouts on my desktop.
[01:02:19.580 --> 01:02:24.300]   You sound like you're-- I think you-- Have you ever heard of Stockholm syndrome?
[01:02:24.300 --> 01:02:32.460]   No, I-- No. Oh, do not get me going on Google. And the nightmare that it is with Google Voice.
[01:02:32.460 --> 01:02:38.300]   And just even when they rolled out the new app, it was a piece of crap. Because it looks cleaner,
[01:02:38.300 --> 01:02:43.020]   but do you want to send animated GIFs with Google Gboard? No, you don't get to do that with Google.
[01:02:43.020 --> 01:02:49.260]   So I'm like back on Google Hangouts. And I would abandon Google Voice and Google Hangouts
[01:02:49.260 --> 01:02:53.580]   and all the mess that they've got out there. No one knows what they're doing. And like you say,
[01:02:53.580 --> 01:02:56.620]   you try to Google, Google Fi. And I'm like, oh, I'm sorry, you're going to Google Voice,
[01:02:56.620 --> 01:03:00.540]   but you were Google Fi on another account. You can never ever go and you're like, oh my god,
[01:03:00.540 --> 01:03:06.780]   what is wrong with you? Oh, and why? And this point, can't I have a Google Fi account with a Google
[01:03:06.780 --> 01:03:13.100]   account that is like a Google Docs work, whatever Gboard, whatever they're calling the new stuff.
[01:03:13.100 --> 01:03:19.020]   Oh, G Suite. Got a G Suite account? No Google Fi for you. Why? I don't know where Google. We can't
[01:03:19.020 --> 01:03:24.380]   handle the fact that people who pay us money to have services can't actually get to use all the
[01:03:24.380 --> 01:03:29.900]   services we'll give everybody else for free. So yeah, I got some issues with Google and their big
[01:03:29.900 --> 01:03:35.020]   messed up thing. But I've worked around in the best way I can. Because, you know, when I was in
[01:03:35.020 --> 01:03:40.700]   Japan, I turned on my Google Fi phone. I had internet and it worked. And I had Google Voice,
[01:03:40.700 --> 01:03:45.100]   so I could still get phone calls from the US and I could send out messages. And that was very
[01:03:45.100 --> 01:03:50.460]   convenient. So I live with it. I endure it just for those occasional overseas trips.
[01:03:50.460 --> 01:03:55.980]   But it could be better. Wow, Danny, that felt really cathartic.
[01:03:55.980 --> 01:04:01.820]   Because he just let it out. Let it all out. I mean, I kind of want like a t-shirt of you doing this.
[01:04:02.620 --> 01:04:09.100]   Oh, it is embarrassing though, because Google Voice is such a great service, has potential to be
[01:04:09.100 --> 01:04:14.780]   such a great service. And they've just shoved it off into nowhere land. And you're just like,
[01:04:14.780 --> 01:04:18.300]   what is wrong? And my only guess is because they just don't think they can make any money off of it.
[01:04:18.300 --> 01:04:23.820]   So back we go with some of the big stories of 2017. I think there's no bigger story. And I'm
[01:04:23.820 --> 01:04:33.260]   sure you'd agree with me than Susan J Fowler's memo about mistreatment at Uber that really brought
[01:04:33.260 --> 01:04:40.300]   down the CEO of Uber, Travis Kalanek. And among other events, I would say created this new Me Too
[01:04:40.300 --> 01:04:45.260]   environment to the point where Time Magazine's person of the year were people who were speaking
[01:04:45.260 --> 01:04:52.220]   out. We talked at the time, and this goes back to July. Susan Fowler's memo was in spring, but this
[01:04:52.220 --> 01:04:58.140]   is in July about harassment in Silicon Valley. And I think Stacy, you have some really good points.
[01:04:58.140 --> 01:05:07.260]   So we spent a lot of time on Sunday on Twitch on this week in tech. I kind of rejiggered the
[01:05:07.260 --> 01:05:11.020]   panel because I want to make sure we had at least one woman we called and got Katie Benner, who wrote
[01:05:11.020 --> 01:05:16.620]   the New York Times article about harassment in Silicon Valley really blew the lid off it. It all
[01:05:16.620 --> 01:05:21.340]   started and credit to Reed Albergotti over at the information who broke the story of Justin
[01:05:21.340 --> 01:05:30.220]   Kalbek. And Kalbek, of course, a venture capitalist who was accused by at least six women of using his
[01:05:30.220 --> 01:05:38.860]   position of power to harass, sexually harass women who were women entrepreneurs who were trying to
[01:05:38.860 --> 01:05:43.820]   get funding. I mean, that is as bad as bad as you can get. And then Katie Benner and her article
[01:05:43.820 --> 01:05:51.740]   for the New York Times further further the story by talking about Chris Saka, another very well-known
[01:05:51.740 --> 01:05:57.260]   venture capitalist, Dave McClure of another very famous and Mark Cantor, a very famous entrepreneur,
[01:05:57.260 --> 01:06:03.340]   all three of whom apparently did something similar. In fact, Dave McClure in Medium,
[01:06:03.340 --> 01:06:12.620]   shortly after the New York Times article wrote a maya culpa, a confessional piece in which he said,
[01:06:12.620 --> 01:06:24.060]   I'm a jerk. You got me and it stepped down from his position. Chris Saka has, I'm a creep. I'm sorry,
[01:06:24.060 --> 01:06:29.900]   it was the name of that story. Chris Saka has continued to kind of deny the allegations
[01:06:29.900 --> 01:06:36.620]   as has Mark Cantor. But nevertheless, these are well-known people in Silicon Valley, not so much
[01:06:36.620 --> 01:06:47.260]   Justin, but these two very much worse. He said that, well, I could like a jerk to get rid of her.
[01:06:47.260 --> 01:06:52.540]   Yeah, he really does. That was really awful. Yeah.
[01:06:52.540 --> 01:07:00.220]   So, I mean, it's clear that at least some of these allegations are found in a fact. I mean,
[01:07:01.020 --> 01:07:08.060]   both Callbeck and McClure have left their positions. And in fact, the Callbeck's fund has been dissolved.
[01:07:08.060 --> 01:07:10.300]   Oh, really? Yeah.
[01:07:10.300 --> 01:07:17.180]   McClure apparently had decided to quit earlier, but as it turns out, now there's still a lot of
[01:07:17.180 --> 01:07:23.820]   conversation about all this in Silicon Valley and elsewhere. He apparently, they knew about this
[01:07:23.820 --> 01:07:28.060]   and they didn't maybe act on it as quickly as they should. Christine Sy, who's his partner,
[01:07:28.060 --> 01:07:35.580]   and now runs the fund 500 startups, says I didn't know, but he said he was going to step down
[01:07:35.580 --> 01:07:40.300]   earlier this year anyway. And anyway, there's a lot more to this story. And I don't need to
[01:07:40.300 --> 01:07:45.180]   go into the deets of these specific story as I'm much more interested. And I know Stacy,
[01:07:45.180 --> 01:07:51.340]   you wanted to talk about this in the culture. I have to say though, the conversation is really
[01:07:51.340 --> 01:07:55.820]   important. And I have to say that as we've started talking about this, I've heard from everybody,
[01:07:55.820 --> 01:08:01.020]   I know, oh, yeah, I've been harassed. And not just in the tech business, but every woman has been
[01:08:01.020 --> 01:08:06.140]   harassed, at least once, if not many times, how much worse is the tech business?
[01:08:06.140 --> 01:08:09.580]   That's a good question. Yeah, that's that's I don't think it is.
[01:08:09.580 --> 01:08:18.860]   OK, well, whoa, whoa. OK, I would say I've worked in finance. So I worked when I was very young. My
[01:08:18.860 --> 01:08:24.540]   first job was bond traders and working at the bonfire. That's a bunch of pros. It's a bunch of
[01:08:24.540 --> 01:08:31.980]   pros. It's a very big, sweet, you know, what's yeah, I'm like, yeah, there's there's harassment
[01:08:31.980 --> 01:08:37.980]   there. Then I worked actually here in Austin, where I dealt with a lot of the real estate guys.
[01:08:37.980 --> 01:08:43.340]   And they were at the time, I guess you could get porn on your smartphones. And I vividly remember
[01:08:43.340 --> 01:08:48.540]   sitting at a table like at a gala with some real estate guys that they were like showing me
[01:08:48.540 --> 01:08:54.060]   the porn on their smartphone. And I'm a 23 year old kid. Isn't that sweet? I'm like, oh, my wife
[01:08:54.060 --> 01:08:59.500]   worked in the construction industry. Similar. Oh, yeah. Similar. Very few women and very macho
[01:08:59.500 --> 01:09:08.780]   culture. And then yeah, tech guys are also bad. So honestly, I think,
[01:09:08.780 --> 01:09:15.500]   let us let us say, oh, hey, I think the issue here is that the tech industry is not as enlightened
[01:09:15.500 --> 01:09:21.340]   as they maybe thought they were and not as diverse as it needs to be. Well, we've known that forever.
[01:09:21.340 --> 01:09:25.980]   I mean, I was kind of getting to that from an economic diversity when I was asking about
[01:09:25.980 --> 01:09:30.780]   internships and journalism being paid, for example, that's a different kind of diversity.
[01:09:30.780 --> 01:09:36.700]   We're not talking about that here, but I mean, these are conversations everyone should be having
[01:09:36.700 --> 01:09:46.540]   across the board, both economic, racial, gender, all of that needs to be if we want to fix where we
[01:09:46.540 --> 01:09:51.580]   are. So those are the big macro kind of questions. Boys will be boys.
[01:09:51.580 --> 01:09:57.660]   Wrong. If there aren't enough women around to say, not the heck out and let's top it.
[01:09:57.660 --> 01:10:03.420]   So that's the I mean, and most women aren't going to do it because boys still have the power.
[01:10:03.420 --> 01:10:06.860]   Right. You don't want to be. So it's right. So you'll be able to say. So you'll be able to say,
[01:10:06.860 --> 01:10:11.180]   equals in power, I would submit that's going to be a problem.
[01:10:13.260 --> 01:10:19.260]   You should not say the word boys will be boys. You as a person Leo should say, hey, there's not
[01:10:19.260 --> 01:10:26.140]   enough women in power. I'm going to say, hey, stop it. Don't do that. And I have worked for
[01:10:26.140 --> 01:10:30.780]   some real jerks and I've worked for people who are amazing. And I'm going to I'll call
[01:10:30.780 --> 01:10:37.900]   home for being really amazing because he said great culture. He did. And you know, I remember
[01:10:37.900 --> 01:10:43.740]   someone writing on the bottom of a blog post. It was a picture from one of our structure events.
[01:10:43.740 --> 01:10:48.220]   And it was a picture of me sitting talking to some person at a cloud computing event.
[01:10:48.220 --> 01:10:54.380]   And the person wrote great legs. And I saw this and I was like, oh my God, that's so embarrassing.
[01:10:54.380 --> 01:11:00.380]   And oh, just without without even thinking about it, just deleted it. And was like,
[01:11:00.380 --> 01:11:05.900]   send a note to the person was like, screw you. We don't want your kind here on our site in.
[01:11:06.940 --> 01:11:13.580]   Good for home. I love that. I don't say boys will be boys to to to in any way condone it or even
[01:11:13.580 --> 01:11:18.540]   say it's okay. But just that this is what happens when you get a bunch of men together. You go you
[01:11:18.540 --> 01:11:22.460]   go in a locker room or just have to happen. I get a lot of it. But it does. I'm I agree. It
[01:11:22.460 --> 01:11:27.180]   shouldn't happen. But it does. And it somebody in the chat room saying I worked in construction.
[01:11:27.180 --> 01:11:32.460]   There's not a single construction office in the country doesn't have a adult calendar on the wall.
[01:11:32.460 --> 01:11:38.460]   Now, if there were women executives, that would stop immediately. It might not. Some women internalize
[01:11:38.460 --> 01:11:43.740]   a lot of this. I guess I'm looking at Google's diversity report, which just came out. This is
[01:11:43.740 --> 01:11:52.540]   overall 69% men, 39, 31% women in in general. If I go to tech, which is what we really care about,
[01:11:52.540 --> 01:12:00.300]   it goes down to 20% women. The thing I see also very shameful, 1% black, 3% Hispanic.
[01:12:01.580 --> 01:12:09.420]   53% white. The next largest ethnicity is Asian, 39%. So this is Google who's trying apparently
[01:12:09.420 --> 01:12:13.660]   trying very hard to create diversity. But if you are an environment like this,
[01:12:13.660 --> 01:12:19.340]   I think I think that's very hard on the 20 on the one and five women.
[01:12:19.340 --> 01:12:26.540]   Yes, I think that's true. The the watch brightness more is that when one
[01:12:27.500 --> 01:12:32.380]   for whatever reason, one person has the courage to come out and expose this, the number who then
[01:12:32.380 --> 01:12:37.900]   follow. Yeah, look what's happened. BC or whether it's Bill Cosby or any of these cases. So,
[01:12:37.900 --> 01:12:43.340]   it's not a numbers game. It's I think Stacy's quite right. It's a power game no matter what.
[01:12:43.340 --> 01:12:50.700]   And even if the numbers are 50/50, there's intimidation that goes beyond even that.
[01:12:50.700 --> 01:12:55.100]   Oh, absolutely. And you know, aggressions of all kinds. And we should, I agree with you Stacy,
[01:12:55.100 --> 01:12:59.420]   we should all be more like home. And even if there aren't women in the workplace,
[01:12:59.420 --> 01:13:01.580]   there should be men in the workplace who say knock it off.
[01:13:01.580 --> 01:13:07.180]   Exactly. And I would say, so here's here's my advice to guys in the workplace.
[01:13:07.180 --> 01:13:13.020]   It's just basic rules that I can't believe someone they don't know, but
[01:13:13.020 --> 01:13:17.740]   their mothers didn't or their fathers. I mean,
[01:13:17.740 --> 01:13:23.260]   Yes, sorry. Sorry. I'm like, we are not putting this all on the women. Sorry, Jeff.
[01:13:23.260 --> 01:13:29.180]   No, no, no, no, but the real problem is that man.
[01:13:29.180 --> 01:13:36.940]   Wait, Leo, please give you my rule. Okay, rule is, I should never know if you want to
[01:13:36.940 --> 01:13:41.260]   sleep with me in a work environment. If you're dealing with a woman,
[01:13:41.260 --> 01:13:45.260]   that's a good rule. I like that. Any woman you're working with should never know if you want to
[01:13:45.260 --> 01:13:49.740]   sleep with her or not, because it's completely irrelevant to your professional relationship.
[01:13:49.740 --> 01:13:53.180]   Yes. Period. And if you follow that rule, you're great.
[01:13:53.180 --> 01:13:56.300]   That doesn't mean just not saying I want to sleep with you.
[01:13:56.300 --> 01:14:02.300]   No, it means all of the flirty, weird things that people do.
[01:14:02.300 --> 01:14:10.940]   But I think that's a very good rule. And the thing I would say is that most men want to
[01:14:10.940 --> 01:14:17.660]   sleep with most women. So the difficulty and the reason men kind of glosses over is,
[01:14:17.660 --> 01:14:24.860]   well, we're all thinking this anyway. So it really is, it's got to be at a behavioral level.
[01:14:24.860 --> 01:14:28.300]   You can't, you can't, I don't think you can teach men not to think that.
[01:14:28.300 --> 01:14:32.620]   Right. I don't care what they think. I just should never know.
[01:14:32.620 --> 01:14:41.100]   I love that rule. I mean, I've, I work with so many men and I work really closely with lots of men.
[01:14:41.100 --> 01:14:47.340]   And I honestly, I don't give it much thought. But when I was thinking about this rule,
[01:14:47.340 --> 01:14:49.980]   I was like, God, did any of them want to sleep with me? And I have no idea.
[01:14:49.980 --> 01:14:52.540]   Good. Zero. That's good. I like that a lot.
[01:14:52.540 --> 01:14:56.380]   So. And you can tell I don't want to sleep with you, right?
[01:14:56.380 --> 01:15:03.500]   I don't even think about it. No, it shouldn't come up. It shouldn't even be. No, that's a,
[01:15:03.500 --> 01:15:07.420]   that's such a great rule. I've never heard it articulated like that. And I think that that's,
[01:15:07.420 --> 01:15:11.900]   if it comes down to it, that's it. But, and, and, but you really got to say,
[01:15:11.900 --> 01:15:16.380]   that doesn't just mean you say something. It means showing you porn at a dinner.
[01:15:16.380 --> 01:15:18.620]   It means having a sexy calendar even in your office.
[01:15:18.620 --> 01:15:19.180]   In your office.
[01:15:19.180 --> 01:15:20.300]   With respect. Yeah.
[01:15:20.300 --> 01:15:21.660]   Treating with respect. Yeah.
[01:15:21.660 --> 01:15:27.100]   You all probably, if you follow Tech News, know that last week,
[01:15:27.100 --> 01:15:35.580]   a, a Googler at the time unnamed Googler posted on the, on an internal board,
[01:15:35.580 --> 01:15:42.620]   a memo about why he felt goog, now I'm going to try to phrase this in a neutral way.
[01:15:42.620 --> 01:15:49.260]   Why he felt that Google was barking down the wrong path was diversity initiatives and was
[01:15:49.260 --> 01:15:55.500]   perhaps too politically correct about it to do a good job. He wasn't anti diversity,
[01:15:55.500 --> 01:15:59.980]   said right up front, I'm not against diversity. I'm not against an attempt to make the workplace
[01:15:59.980 --> 01:16:04.700]   more diverse. But we have to understand the difference between men and women. And
[01:16:04.700 --> 01:16:10.780]   I think a lot of people read it and took it as women are not suited for tech jobs.
[01:16:11.340 --> 01:16:14.060]   That of course got an immediate response.
[01:16:14.060 --> 01:16:20.220]   Loud vociferous response, Gizmodo somehow got the actual memo and published it.
[01:16:20.220 --> 01:16:24.780]   Janatan Zungar, former senior engineer. I'll former recently former.
[01:16:24.780 --> 01:16:27.180]   Yeah. We didn't even know he wasn't there until he wrote this piece.
[01:16:27.180 --> 01:16:30.540]   That's a brilliant guy. I could talk now because I'm not there anymore. So I can,
[01:16:30.540 --> 01:16:36.620]   I can talk in a way I wouldn't completely dismissed a, the factual material in the memo and b,
[01:16:36.620 --> 01:16:44.940]   said the guy should be fired because this is destructive to Google. The VP diversity at Google
[01:16:44.940 --> 01:16:50.380]   put out initially a memo saying, you know, this is unacceptable. And Sundar Pichai apparently,
[01:16:50.380 --> 01:16:55.660]   the CEO of Google came back from a family holiday to address the issue and they ended up firing
[01:16:55.660 --> 01:17:05.020]   the person who wrote the memo. It's a 10 page screed at which point Julian Assange immediately
[01:17:05.020 --> 01:17:06.020]   offered a majority of it.
[01:17:06.020 --> 01:17:11.340]   He makes saying he was a victim of the political correct, political correct culture of the United
[01:17:11.340 --> 01:17:18.300]   States. Have I summarized that? I think that's pretty much where we stand today.
[01:17:18.300 --> 01:17:24.860]   There have been articles since both in his favor and against him. I'm not going to describe this
[01:17:24.860 --> 01:17:34.780]   as neutral is like, you cannot describe what he did is neutral in a neutral fashion because what
[01:17:34.780 --> 01:17:41.580]   he did was basically take a position, which fine, let's talk about Google's diversity efforts.
[01:17:41.580 --> 01:17:48.380]   But the way he decided to do the conversation was by saying it was the equivalent of me walking
[01:17:48.380 --> 01:17:55.420]   into a place and saying, hey, let's talk about crime statistics and then saying something terrible
[01:17:55.420 --> 01:18:01.100]   about black people and accusing all of them of being a problem or not up to white people crime
[01:18:01.100 --> 01:18:07.100]   standards or something equally horrifying. So to even describe this in neutral terms,
[01:18:07.100 --> 01:18:15.420]   I think does it gives it way more credit than it should even get. This is a terrible piece of
[01:18:15.420 --> 01:18:22.220]   writing in terms of just spewing hate in points that are directly from men's rights activists.
[01:18:23.260 --> 01:18:31.740]   But two, doing it in such a way that if any reasonable person had decided to take issue with
[01:18:31.740 --> 01:18:39.020]   the company's policy by saying, by doing it like this, they should be fired. This is not
[01:18:39.020 --> 01:18:44.380]   not a reasonable thing to do because anyone reading that memo is going to be like,
[01:18:44.380 --> 01:18:51.260]   holy cow, I work with a guy who's a total kind of misogynistic jerk. I would say bigger worst words,
[01:18:51.260 --> 01:18:57.020]   but I won't. >> And so I get the people who are like,
[01:18:57.020 --> 01:19:02.780]   let's argue the science. I'm like screw the science. He is wrong. He doesn't address all of the issues
[01:19:02.780 --> 01:19:10.860]   behind the science. And B, the way he did this was like dropping a bomb in his workplace.
[01:19:10.860 --> 01:19:17.180]   >> Well, I'm not sure. >> I'm not sure what I don't know,
[01:19:17.180 --> 01:19:25.020]   maybe you do, but I don't know. He posted it, we're told on a meme board, an internal board,
[01:19:25.020 --> 01:19:31.660]   and then an internal equivalent of Google+, I don't know if this was sent to every single person
[01:19:31.660 --> 01:19:36.300]   at the company or was posted in a discussion group for this. Yeah, everybody could see it,
[01:19:36.300 --> 01:19:40.540]   I gather, but I don't know even. >> Is he sent it to 10 people?
[01:19:40.540 --> 01:19:47.180]   If he sent it to 10 people, then one of them is a woman, then there's a hostile workplace,
[01:19:47.180 --> 01:19:51.420]   and if they're all men and they're connected to the spiriters, it doesn't matter how many in Google.
[01:19:51.420 --> 01:19:55.740]   >> Okay. >> And think about when Facebook posted their
[01:19:55.740 --> 01:20:00.780]   wall where they had their wall where employees could write stuff, and then suddenly when Zuck had
[01:20:00.780 --> 01:20:06.700]   to come down and say, hey guys, you cannot, I think was it white lives also matter, or someone
[01:20:06.700 --> 01:20:09.980]   took a stance and wrote that on the wall. >> Oh, I forgot that, yeah.
[01:20:09.980 --> 01:20:15.980]   >> He is a CEO, he had a responsibility to come in and say, guys, that is not our culture, that is
[01:20:15.980 --> 01:20:20.780]   not okay. >> Right, well, and that's kind of what Google did, and of course we should stipulate
[01:20:20.780 --> 01:20:25.980]   immediately that Google as a private company has the right to fire the person, or the right to
[01:20:25.980 --> 01:20:29.900]   discipline the person, has the right to react anyway, it chooses, there's no free speech in the
[01:20:29.900 --> 01:20:36.300]   workplace in that sense. >> Right. >> So he's not, what he wrote was not protected because he
[01:20:36.300 --> 01:20:45.500]   published it on a company board. So, and I don't think anybody would dispute that much of what he
[01:20:45.500 --> 01:20:51.980]   said was hurtful and inaccurate about women, saying things like women have a higher tendency
[01:20:51.980 --> 01:20:57.740]   to anxiety. So if you're going to have an attack job, you should have them in a place where it's
[01:20:57.740 --> 01:21:04.060]   less anxious. Women are extroverted, men are introverted, that's, you know, blatant, obviously not,
[01:21:05.100 --> 01:21:11.820]   generally is it true. Neuroticism, higher anxiety, lower stress tolerance, this may
[01:21:11.820 --> 01:21:15.980]   contribute to the higher levels of anxiety, I don't want to get Stacy upset, so. >> Has he seen a
[01:21:15.980 --> 01:21:20.540]   Woody Allen movie? >> I know. >> Has that man's entire? >> Well, okay, so a couple of things,
[01:21:20.540 --> 01:21:26.300]   first of all, and he even says this, these are, these are generalities, but you're generalizing
[01:21:26.300 --> 01:21:32.060]   about a gender, just like generalizing about a race is offensive to people. >> But Stacy's,
[01:21:32.060 --> 01:21:36.220]   Stacy's on to something else here, which is really important, you know, which is, is, and I could
[01:21:36.220 --> 01:21:38.940]   barely get through the damn thing because it was so badly written. >> Yeah, I didn't
[01:21:38.940 --> 01:21:43.100]   button read the whole thing either, I tried. >> So that's part of the case going on here.
[01:21:43.100 --> 01:21:48.540]   Is, is, whether it's political or technology, the, the, the, the Venn diagram we're getting
[01:21:48.540 --> 01:21:54.060]   here of the so-called men's rights movement, which is, I, as a man, I will say is BS. We've had
[01:21:54.060 --> 01:21:59.020]   plenty of rights for plenty of time, and, and, and it's a reaction to feminism, it's a reaction to,
[01:21:59.660 --> 01:22:05.980]   to a perceived loss of power, it's a reaction to all kinds of things, like nationalism, like racism,
[01:22:05.980 --> 01:22:11.100]   you know, misogyny fits in there. And so there's, there's a set of dog whistles, there's a set of
[01:22:11.100 --> 01:22:15.980]   ways to talk. And, you know, when I criticized it, then boom, I got it on Twitter like that, right?
[01:22:15.980 --> 01:22:22.860]   And, and so what's, what's disturbing to me is, I mean, so, so, so that exists, and that has a
[01:22:22.860 --> 01:22:27.500]   voice now because social enables it, enables lots of things good and bad. I don't know, okay,
[01:22:27.500 --> 01:22:33.660]   with that. I think we could clearly say there's a tenor in this country right now to tolerate
[01:22:33.660 --> 01:22:38.620]   speech that we would not have tolerated 10 years ago. Well, then it goes, well, that's, that
[01:22:38.620 --> 01:22:42.220]   itself is an argument, right? Because if you go to NRO, National Review and others, they're,
[01:22:42.220 --> 01:22:46.940]   they're decrying his firing as a lack of free speech and as political correctness, but the point
[01:22:46.940 --> 01:22:51.100]   I'm trying to make here for the show that's relevant. So, so don't send me your emails. I'm
[01:22:51.100 --> 01:22:57.100]   being relevant. Oh, send them emails anyway. Uh, is, that's going to stop them. What disturbs
[01:22:57.100 --> 01:23:03.740]   me is the connection of the technology industry because it's not gender diverse and the so-called
[01:23:03.740 --> 01:23:08.380]   men's rights movement and the misogyny that is inherent in that and how they come together.
[01:23:08.380 --> 01:23:14.220]   And the whole gamer-gater world around technology and men and, and technology not being open to
[01:23:14.220 --> 01:23:20.700]   respectful of women. Uh, that's a huge cultural problem, not just for the individual companies.
[01:23:20.700 --> 01:23:24.860]   I don't think you can take this one guy as the Atlantic did and said, well, this shows the
[01:23:24.860 --> 01:23:29.340]   horrible core of Google and the horrible core of technology. I'm gonna, I'm gonna propose,
[01:23:29.340 --> 01:23:35.740]   I want to propose something. Um, I was gonna go, because I, first of all, if you, if you just go
[01:23:35.740 --> 01:23:42.620]   to the end of his memo and look at his suggestions, I think we can clearly throw out the bogus sociological
[01:23:42.620 --> 01:23:48.620]   crap he's throwing in there. Although people are people with some expertise are defending him.
[01:23:48.620 --> 01:23:53.420]   No, no, no, no, there are people with expertise defending him. There are also people with expertise
[01:23:53.420 --> 01:23:56.860]   saying he's full of crap. So that's why we're throwing that out. There's some debate about it,
[01:23:56.860 --> 01:24:01.660]   but we're just gonna throw that out. Um, would you agree with, he says, my larger point is we have
[01:24:01.660 --> 01:24:05.900]   an intolerance for ideas and evidence that don't fit a certain ideology. Would you agree with that?
[01:24:05.900 --> 01:24:11.740]   No, because he's wrapping it. He's using my ideas and freedom of expression to espouse
[01:24:11.740 --> 01:24:17.660]   stereotypes, bigoted thinking. Yeah. Well, then says, I'm not saying we should restrict people
[01:24:17.660 --> 01:24:22.380]   to certain gender roles. I'm advocating for quite the opposite tree and I don't, I couldn't disagree
[01:24:22.380 --> 01:24:28.060]   with this line. Tree people as individuals, not as just another member of their group, tribalism.
[01:24:28.060 --> 01:24:34.300]   That's fine. But he in this memo lumped women under an entire group who's bad at engineering.
[01:24:34.300 --> 01:24:38.300]   So I love the fact that he's like, Oh yeah, that's all the individuals. That's not
[01:24:38.300 --> 01:24:42.060]   doing it. That's not doing it. Right. Extraverted neurotic. So here's what I'm going to propose.
[01:24:42.060 --> 01:24:49.420]   Maybe, maybe we'll defuse this a little bit. Um, technology, uh, and, and frankly, business
[01:24:50.060 --> 01:24:55.260]   in general, but technology particularly has been a male playing field for so long that we have a
[01:24:55.260 --> 01:25:04.140]   certain picture of it. And, uh, and people who've grown up in the industry have have a picture of how
[01:25:04.140 --> 01:25:10.300]   it looks, how the workplace looks, how the product that we create looks. Uh, I on Windows weekly, I
[01:25:10.300 --> 01:25:16.220]   said it's like we for years have been operating with a black screen in white text. You know,
[01:25:16.220 --> 01:25:22.940]   it's in the black and white. And it's, and then all of a sudden, uh, people are saying, no, but we
[01:25:22.940 --> 01:25:28.300]   want to make it a rainbow. We want to include everybody. We want technology to reflect all the
[01:25:28.300 --> 01:25:33.980]   people in the world, not just this white, you know, short sleeve pocket protector, skinny, black tie,
[01:25:33.980 --> 01:25:40.300]   nerd glasses, uh, speaking of story, but, but, well, but you know, that's the IBM.
[01:25:41.260 --> 01:25:46.620]   Yeah, thing, you know, and, uh, and I think what we're saying is it should be in rainbows. And
[01:25:46.620 --> 01:25:51.420]   it's upsetting to people who say, but no, but tech is this way. And that's the, this is what this guy
[01:25:51.420 --> 01:25:58.620]   really at bottom is saying on this. I'm just going to, but I feel like what he's saying is
[01:25:58.620 --> 01:26:03.660]   he doesn't know it, but what he's saying is this is how it looks. This is how it should look. This
[01:26:03.660 --> 01:26:07.340]   is how it's always looked. This is how it feels good and right to me.
[01:26:07.340 --> 01:26:11.580]   Because then we don't want to change. And what we're saying, what we're saying to him is
[01:26:11.580 --> 01:26:17.980]   I understand what I would say is I understand why you'd feel that way, but the, but there is,
[01:26:17.980 --> 01:26:23.340]   it could be so much more and there's so much more opportunity with diversity,
[01:26:23.340 --> 01:26:29.260]   not just gender diversity, racial diversity, national origin, that that the melting pot is a
[01:26:29.260 --> 01:26:34.860]   melting pot of many colors. It could be so much more interesting. Yes, it doesn't look like what
[01:26:34.860 --> 01:26:41.900]   it used to look like. That's upsetting to people. But the opportunity is so much better that it's
[01:26:41.900 --> 01:26:46.860]   worth opening up your mind to that idea. Let's, let's just jump over to Amazon. We keep talking
[01:26:46.860 --> 01:26:51.420]   about it. This way we don't have to dance around it anymore. I feel like, I feel like this was a
[01:26:51.420 --> 01:26:57.020]   very surprise announcement on Amazon's part. I had no idea that there was an event. Maybe I was
[01:26:57.020 --> 01:27:02.140]   just out of the loop, but then suddenly boom, boom, boom. It was like five million products were being
[01:27:02.140 --> 01:27:06.380]   announced. And we've got them all here while we don't have them in studio, but we've got them to
[01:27:06.380 --> 01:27:14.060]   talk about. Amazon showed off first a new smaller Echo device. It's wrapped in cloth. It's not quite
[01:27:14.060 --> 01:27:20.780]   half the size, but it's probably like, I don't know, it probably cuts off a third of the size of the
[01:27:20.780 --> 01:27:25.740]   original Echo. It's wrapped in cloth. So maybe it fits into your home a little bit better.
[01:27:26.700 --> 01:27:33.900]   $99, you could get a three pack. If you like buying in packs for $250, you just add three to the cart
[01:27:33.900 --> 01:27:39.980]   and then you get a $50 discount applied there. And apparently this, well, with a three pack,
[01:27:39.980 --> 01:27:45.420]   obviously it offers the Echo's new multi-room functionality. So you can get these between rooms
[01:27:45.420 --> 01:27:52.940]   like we were just talking about. Matt will not do that. Many others will. And then you can also
[01:27:52.940 --> 01:27:58.140]   make free calls in the US, Canada, and Mexico, as well as 911 calls. I'm assuming this because
[01:27:58.140 --> 01:28:01.900]   you can plug the phone into this, which that's what you can do with another device they announced,
[01:28:01.900 --> 01:28:08.540]   which we'll talk about in a second. But smaller Echo, $99, so lowering the entry point for
[01:28:08.540 --> 01:28:16.140]   kind of what used to be premium Echo functionality, which thanks, Stacey. I know you are an Echo
[01:28:16.140 --> 01:28:21.980]   user. What do you think about this? Man, I'm super excited. Now, so I looked at this and I was
[01:28:22.780 --> 01:28:29.420]   kind of bummed that I do not have like the wood-grained Echo. I'm like, oh, that's kind of neat.
[01:28:29.420 --> 01:28:38.140]   I have, see, in my house, I've got two dots and two normal-sized echoes. And so I really,
[01:28:38.140 --> 01:28:44.300]   I'm running out of rooms. I could buy one more and put it in. I've got one more room I could use it in.
[01:28:44.300 --> 01:28:51.500]   So I probably would buy it, but I may actually go for there's two other products that I'm really
[01:28:51.500 --> 01:29:03.820]   excited about. So the plus is the more premium of the devices that they showed off today.
[01:29:03.820 --> 01:29:09.660]   Although it's still cheaper than the current Echo, like the original Echo. It's $149,
[01:29:09.660 --> 01:29:15.660]   which is $30 cheaper than the original Echo. But the Echo Plus retains the bigger form factor
[01:29:15.660 --> 01:29:19.500]   of the original. They've kind of redesigned a little bit of the material and everything to make it
[01:29:19.500 --> 01:29:26.940]   look a little sleeker and everything a little bit more refined. It has a built-in smart home hub
[01:29:26.940 --> 01:29:34.140]   for smart home control. It also includes higher-end sound and components for those who play their
[01:29:34.140 --> 01:29:40.140]   music through an Echo and not on their phone. It ships with, sorry, bad. I can't help it.
[01:29:40.140 --> 01:29:45.980]   It's all good. It's all good. Ships with... I'm proud. Yes. Wear it like a badge of honor.
[01:29:47.180 --> 01:29:52.940]   It ships with a Hue light bulb in the box, which I think is there to kind of prove that this is
[01:29:52.940 --> 01:29:59.900]   meant to control to be a hub for your smart home. Stacy, do you know what is the standard that's
[01:29:59.900 --> 01:30:04.620]   built into here? Because I mean, I have Hue at home and it requires a Hue light bulb hub.
[01:30:04.620 --> 01:30:12.300]   The Hue uses Zigbee, but it uses I think Zigbee HA. So Zigbee is kind of a pain because there were
[01:30:12.300 --> 01:30:17.980]   many variations on this standard software profile so things could get kind of wacky between things.
[01:30:17.980 --> 01:30:24.780]   But the fact that there is no hub, they're basically saying that, hey, the Hue guys are like,
[01:30:24.780 --> 01:30:28.620]   yeah, this thing talks Zigbee and we're going to just talk to it and you don't need a hub.
[01:30:28.620 --> 01:30:35.660]   As someone who has, I kid you not, 10 different hubs, I can see if I bought one of these, I could
[01:30:35.660 --> 01:30:42.460]   get rid of like six of them, which totally worthwhile because my little server closet is, it's the hub
[01:30:42.460 --> 01:30:49.340]   home. And I would love this. And everybody who listens to my show would be excited too because I
[01:30:49.340 --> 01:30:52.700]   give away my hubs when I'm done with them. So they'd be like, yeah, I get a wing hub, I get a
[01:30:52.700 --> 01:30:58.460]   smart things, you get a Phillips Hue. So basically this hub is going to replace multiple other hubs
[01:30:58.460 --> 01:31:05.020]   that you have serving different purposes. That would be my hope. I would lose the software
[01:31:05.020 --> 01:31:12.140]   functionality. So like, in this, this is something to think about. Like if I had this and I had the
[01:31:12.140 --> 01:31:18.620]   Phillips Hue bulb, would I use the Phillips Hue app or would I just run it through the Amazon Echo?
[01:31:18.620 --> 01:31:22.780]   Right. And that's a real question for people who are partnering too because Phillips Hue
[01:31:22.780 --> 01:31:26.620]   wants my email address, it wants all this data and information for itself. But if it's going
[01:31:26.620 --> 01:31:32.620]   through the Amazon Echo, how does it feel about that? I don't know. And same thing.
[01:31:32.620 --> 01:31:35.100]   I did a Hue bulb in the package. So they're
[01:31:35.100 --> 01:31:40.940]   Yeah. So are they? I mean, did Amazon actually, because you know, Amazon doesn't always
[01:31:40.940 --> 01:31:46.060]   ask about this stuff. It's like, hey, we had some Hue bulbs and inventory list toss these in.
[01:31:46.060 --> 01:31:49.420]   That's true. That's true. Sweet in the deal.
[01:31:49.420 --> 01:31:53.740]   I assume that's not what happened. But you know, I would not put it past Jeff Bezos.
[01:31:53.740 --> 01:32:00.860]   Yeah. What do you think, Matt? You have Google Home, I'm assuming throughout your home. But
[01:32:01.420 --> 01:32:06.060]   what do you think? I do have a Google Home. I also have the Amazon equivalent.
[01:32:06.060 --> 01:32:14.940]   I am breaking new pioneering waves in dumb home technology. So, you know, just the amount of work
[01:32:14.940 --> 01:32:19.660]   to try to control a lot of this stuff. I'm like, you know what? I'll just get up and turn off the
[01:32:19.660 --> 01:32:26.860]   light switch myself. You know, so I'm like adding a skill to this and then you got a reboot. So
[01:32:28.060 --> 01:32:33.580]   I'm playing around with going super, super dumb and just, you know, trying to use those cycles for
[01:32:33.580 --> 01:32:37.420]   other things these days. So we'll see whether that works out. I'll report back on the experiment.
[01:32:37.420 --> 01:32:43.900]   But I got to say, like, there's so many devices that Amazon announced today, it's like they've
[01:32:43.900 --> 01:32:50.380]   just decided to make Echo its own like consumer brand, you know, like the Echo buttons sound
[01:32:50.380 --> 01:32:53.260]   pretty cool, but it doesn't sound like they have anything to do with sound.
[01:32:53.260 --> 01:32:59.580]   So the Echo buttons, this is kind of a strange one. If you were ever hoping to turn your Echo into
[01:32:59.580 --> 01:33:08.700]   a game show, we've all been there. Now you can. These buttons are for interacting with Echo devices
[01:33:08.700 --> 01:33:13.900]   for family, well, not just family games, but for games. Trivia was one example that they used.
[01:33:13.900 --> 01:33:21.260]   So basically you get a two pack for $20 and that'll be released timed with the holidays.
[01:33:21.260 --> 01:33:27.100]   But it's kind of like that. What was it? Staples had their big like easy button or whatever.
[01:33:27.100 --> 01:33:33.020]   It's kind of like that, but it works with the Echo devices so that you can kind of ring in and
[01:33:33.020 --> 01:33:38.060]   has a little LED light that lights it up. I don't know. That one came out of nowhere,
[01:33:38.060 --> 01:33:41.740]   but I mean, I can understand like that would probably actually be very fun.
[01:33:41.740 --> 01:33:48.060]   It's the first in Amazon's Alexa gadgets lineup. So there will be more in this gadgets category.
[01:33:49.260 --> 01:33:52.540]   I think this is awesome and I'll tell you why. I'll tell you why.
[01:33:52.540 --> 01:33:53.500]   Yeah, tell us why.
[01:33:53.500 --> 01:33:59.180]   I love gameplay. My daughter and I actually we did the Jeopardy skill. We also do
[01:33:59.180 --> 01:34:03.180]   would you rather because she's a tween girl and that's like the best game for tween girls.
[01:34:03.180 --> 01:34:10.460]   So I can see us having a total fun. It's like totally a stocking stuffer kind of idea, right?
[01:34:10.460 --> 01:34:14.140]   It's $20 for a two pack or is it? No, $20 for two.
[01:34:15.340 --> 01:34:20.140]   That's that's nothing. The other thing is if you're a clever developer, you could start building
[01:34:20.140 --> 01:34:26.620]   this into skills. So Amazon's got their IOT button, but that's 20 bucks and you have to be pretty
[01:34:26.620 --> 01:34:36.460]   adept to code like a skill for your IOT button. But like I spent forever doing a skill for
[01:34:36.460 --> 01:34:41.340]   did I feed the dog? So in our house, you know, who knows who feeds the dog? You know, we just
[01:34:41.900 --> 01:34:49.740]   just a common question. So we actually put a motion sensor on the dog food container. So when
[01:34:49.740 --> 01:34:56.060]   we lifted it, you know, it would send a text to everybody, but I wanted to do an echo skill for
[01:34:56.060 --> 01:35:01.260]   the longest time to be like this. No, did we feed the dog? And she would tell you yes or no.
[01:35:01.260 --> 01:35:05.980]   With this button, I could stick it right next to the dog food. Whoever opens and feeds the dog,
[01:35:05.980 --> 01:35:12.540]   they just hit the button. And then when we ask that question to the echo, not each other,
[01:35:12.540 --> 01:35:18.220]   we'll get an answer. So I feel like there's a lot of really cool opportunities for being able to
[01:35:18.220 --> 01:35:23.580]   press a button to indicate to your personal assistant that lives in your house that something's happened,
[01:35:23.580 --> 01:35:30.460]   right? Absolutely. And then, I mean, technically, you know, even this button has an LED and it may
[01:35:30.460 --> 01:35:34.460]   be a changes to a different color when you do that. And that way, if you don't ask, but you just
[01:35:34.460 --> 01:35:39.180]   have to be standing there, you see there's a blue, you go, okay, already done. I know. See,
[01:35:39.180 --> 01:35:46.620]   even even smarter. Look at you. Well, you know, I am a developer. Not at all. Are the dishes
[01:35:46.620 --> 01:35:54.540]   dirty or are they clean? Yes, right. Just yeah. Okay. So then, but that that turns this, like,
[01:35:54.540 --> 01:36:00.460]   Amazon really build this as being for games. But I mean, really, maybe the game part is just an
[01:36:00.460 --> 01:36:05.420]   example of some of the unique ways that you can use this and let developers run wild with it and
[01:36:05.420 --> 01:36:12.140]   see what they come up with. I like that. Let's see here. What else do we have? We have the Echo
[01:36:12.140 --> 01:36:19.740]   Spot, which is an alarm clock with Amazon's voice assistant baked in as all of these things have a
[01:36:19.740 --> 01:36:28.300]   2.5 inch circular screen device. It has the ability, you know, so it's got a full screen there. You
[01:36:28.300 --> 01:36:35.260]   can view cameras, hold video calls, of course, watch video news. I'm sure you can watch videos on there
[01:36:35.260 --> 01:36:39.980]   if you really wanted to, although the circular screen might make that weird. But it has the ability
[01:36:39.980 --> 01:36:45.660]   to control your smart home, Bluetooth capability, 3.5 millimeter stereo cable. If you want to take
[01:36:45.660 --> 01:36:51.820]   your audio out into your whole, you know, into your bedroom, let's say have speakers and set up
[01:36:51.820 --> 01:36:57.580]   there so that you wake up to nice pleasing music, maybe Katy Perry or someone who I don't know.
[01:36:57.580 --> 01:37:04.700]   $129 ships in December pre-order now. Was this the other device that you were really excited about?
[01:37:04.700 --> 01:37:11.740]   Stacey. So I was excited about this and then I learned about the camera feature. And then I was
[01:37:11.740 --> 01:37:16.300]   like, oh, if I could do a video call on this, that means there's a camera and that means I don't
[01:37:16.300 --> 01:37:21.260]   want to put it next to my bed. I mean, I do actually trust Amazon quite a bit, but I don't trust
[01:37:21.260 --> 01:37:27.180]   anybody that much unless there's like a hard shutter for it. But it's so cute.
[01:37:27.180 --> 01:37:33.180]   Yeah. I mean, it is cool. I mean, yeah, maybe you get that and you throw a little of the tape
[01:37:33.180 --> 01:37:36.140]   over the camera and then, you know, if you really need to use it.
[01:37:36.140 --> 01:37:38.780]   But then you eliminate the cool, cute design. I mean, it's...
[01:37:38.780 --> 01:37:40.700]   That's true. You keep it quiet.
[01:37:40.700 --> 01:37:48.140]   Someone called it Chubby for... it's Amazon's Chubby. And it is. It's exactly that. So I'm like,
[01:37:48.140 --> 01:37:53.420]   welcome back Chubby. We missed you. We missed you. It's like you were never gone.
[01:37:53.420 --> 01:37:57.820]   The button is my favorite thing, the little LED game buttons.
[01:37:57.820 --> 01:38:02.780]   Okay. Awesome. And not to mention inexpensive so you can get a ton of those.
[01:38:02.780 --> 01:38:09.340]   Yeah. And everything that I read about the spot is that it's considered like a discounted Amazon
[01:38:09.340 --> 01:38:15.100]   show. So if you had reservations about Amazon show with the camera and everything, I mean,
[01:38:15.100 --> 01:38:19.660]   coupled with the alarm clock, that means it's almost destined to end up in your bedroom.
[01:38:19.660 --> 01:38:23.100]   So, you know, ask yourself whether you're okay with the fact that there's an internet
[01:38:23.100 --> 01:38:27.500]   connected camera hanging out in your bedroom. And if you're okay with that, they great go for it.
[01:38:27.500 --> 01:38:32.860]   If not, you know, maybe, maybe think twice. So Google last week announced a week ago,
[01:38:32.860 --> 01:38:37.580]   exactly. A number of new devices, including a new Google home to Google Home. So Google Home,
[01:38:37.580 --> 01:38:44.860]   many in the Google Home Maxi or Max. It's just Max. They gave everybody at the event. I did not
[01:38:44.860 --> 01:38:48.300]   go to the event. Now I'm glad they gave everybody the event a home mini,
[01:38:48.300 --> 01:38:59.820]   including from Android police, Artem Rusekovsky, Rusekovsky, Artem set his ring mini up.
[01:38:59.820 --> 01:39:10.380]   And then noticed it seemed to be responding a lot to kind of random noises. So he went online,
[01:39:10.380 --> 01:39:19.340]   you know, the, not ring, the home, Google Home has an online interface. You can see all the triggers.
[01:39:19.340 --> 01:39:25.900]   So he went to his Google My Activity Portal, opened it up and he says, my jaw dropped.
[01:39:25.900 --> 01:39:34.380]   I saw thousands of items, each with a play button and a timestamp, all attributed to this device
[01:39:34.380 --> 01:39:42.220]   called the mushroom. So he, so he was a little nervous. He thought maybe your mushroom is the
[01:39:42.220 --> 01:39:46.940]   mini because he knew that the code name for the Google Home was pineapple. So he listened to the
[01:39:46.940 --> 01:39:53.180]   audio clips and it was like sounds coming from his living room. Oh, I'm sorry, not his living
[01:39:53.180 --> 01:40:03.660]   room worse. He put it in his bathroom. So he sent a note to Google thinking, well, hi, please
[01:40:03.660 --> 01:40:07.260]   forward this to Google Home Team for response. I'm working on a story I'm going to publish in
[01:40:07.260 --> 01:40:11.900]   the next day or so I discovered this issue. Would you please confirm the mini's code name is mushroom?
[01:40:11.900 --> 01:40:18.380]   And here's, you know, my activity page. He says, here's the kicker based on Google My Activity,
[01:40:18.380 --> 01:40:22.460]   the onslaught of thousands of transmitted and saved assistant related audio queries
[01:40:22.460 --> 01:40:28.380]   started the day the home mini was set up. Needless to say, if a listening device records
[01:40:28.380 --> 01:40:33.260]   almost every minute of every day and stores it remotely, we're talking about a huge privacy
[01:40:33.260 --> 01:40:40.220]   violation. Does Google have a comment about this? This is this is it. What does he say? 422 PM.
[01:40:40.220 --> 01:40:48.380]   He heard from them 10 minutes later. And by 7 PM Google was on its way to his house
[01:40:48.380 --> 01:40:56.300]   to take the mini. An engineer drove up to Oakland to examine it that very night. The next day,
[01:40:56.300 --> 01:41:00.620]   they say we've learned of an issue impacting a small number of Google Home minis like all the
[01:41:00.620 --> 01:41:07.660]   ones we handed out at the press event. Now, that causes the touch mechanism to behave
[01:41:07.660 --> 01:41:12.380]   incorrectly. See, apparently there if you just like your Google Home, if you touch the top of it,
[01:41:12.380 --> 01:41:17.420]   instead of saying, Okay, Google, you touch the top of it, it'll trigger it. Apparently,
[01:41:17.420 --> 01:41:22.140]   they had something wrong with a switch in it was just it was registering phantom touch events. So
[01:41:22.140 --> 01:41:26.620]   the fix, which they pushed out pretty quickly simply disabled that capability.
[01:41:27.660 --> 01:41:32.700]   And it says, he says the company let me know they're in the process of building a long term fix.
[01:41:32.700 --> 01:41:38.220]   But if you're one of those journalists, no, but actually you wouldn't have to do anything because
[01:41:38.220 --> 01:41:44.860]   they pushed the fix to all of them. But how embarrassing is that? Wow. I don't think that was
[01:41:44.860 --> 01:41:50.940]   malicious or intentional. They certainly responded very quickly. But it's but but if they hadn't
[01:41:50.940 --> 01:41:56.380]   discovered it for like two weeks, a bit of a black see, what was the drive by Wi-Fi thing that
[01:41:56.380 --> 01:42:03.100]   Oh, yeah, maybe a lawsuit. Yeah. But but there'd be much in Google's actually in Google's defense,
[01:42:03.100 --> 01:42:07.580]   it was discovered because Google so transparent about what about all the audio recording. That's
[01:42:07.580 --> 01:42:13.100]   a good point. Anybody can go see it. And that's what they did. That's a very good point. Google AI,
[01:42:13.100 --> 01:42:18.620]   this is the one Stacy really wanted to do. Can create better machine learning code than humans.
[01:42:21.340 --> 01:42:26.220]   That coding class you're taking. Forget it. Never mind. Stop. Don't do it.
[01:42:26.220 --> 01:42:34.140]   Yeah, this is a little misleading. Google has a system called auto ML.
[01:42:34.140 --> 01:42:39.500]   Oh, so this wasn't the story. Oh, oh, it's not the one you're talking about. Oh,
[01:42:39.500 --> 01:42:46.060]   it's not the story. I was talking about, but that is that is that is auto learning to code. So
[01:42:46.060 --> 01:42:52.300]   that is also related, but I was talking about the AlphaGo Zero research paper that came out today.
[01:42:52.300 --> 01:42:55.100]   Oh, I think it's in there. Did I put it in there? I didn't see it there. No.
[01:42:55.100 --> 01:43:01.100]   Oh, no. What if they didn't? AlphaGo Zero learns on its own. It's under alphabet.
[01:43:01.100 --> 01:43:07.580]   It's the last item. Well, same idea, right? The same idea is not writing software, but
[01:43:07.580 --> 01:43:13.740]   it's able to create knowledge about itself. But isn't that what? Wait a minute. Isn't that
[01:43:13.740 --> 01:43:17.340]   the learning system is doing neural networks? That's the whole idea of a neural network.
[01:43:17.340 --> 01:43:23.900]   No. So if you're doing, depending on the type of learning that it's doing,
[01:43:23.900 --> 01:43:34.060]   a person, a data scientist actually helps train the model. So it's saying it's nudging it. It's
[01:43:34.060 --> 01:43:40.780]   like, oh, you know, this is your, you're more right here. And then it's like it adapts.
[01:43:40.780 --> 01:43:47.020]   This is doing it without any human intervention whatsoever. So this is like what mine did with
[01:43:47.020 --> 01:43:52.300]   learning how to play video games. You basically give it a goal. You say, here's what we want you
[01:43:52.300 --> 01:43:57.580]   to get to figure out how to do it. So here's the, here's the example that the Guardian says,
[01:43:57.580 --> 01:44:03.180]   previous versions of AlphaGo learned their moves by training on thousands of games by strong players,
[01:44:03.180 --> 01:44:09.180]   which, you know, as you say, we're fed to it. AlphaGo Zero had no such help. Instead,
[01:44:09.180 --> 01:44:13.660]   it learned purely by playing itself with a logic millions of times over.
[01:44:13.660 --> 01:44:22.380]   So it just played Go at random and the goal was to win by taking over territory,
[01:44:22.380 --> 01:44:26.460]   but swiftly improved as a discovered winning strategy. The interesting thing about that is
[01:44:26.460 --> 01:44:31.340]   it might learn to play better because humans might have a style of play that's influenced by each
[01:44:31.340 --> 01:44:36.140]   other, but it's not necessarily the right style. And so it might be learning from humans that are
[01:44:36.140 --> 01:44:41.180]   imperfect. Instead, it's learning by actual experience. It takes a lot longer.
[01:44:41.180 --> 01:44:45.980]   And what was kind of fun is that it figured out some really difficult things very quickly,
[01:44:45.980 --> 01:44:50.540]   and then some very simple things. It took a while. So it's learning in a different way than
[01:44:50.540 --> 01:44:56.140]   we learned, which I guess makes sense because it's a computer and we're people, but still kind of cool.
[01:44:56.140 --> 01:44:59.900]   Yeah. And I'm not sure that the replicated human brain is the goal.
[01:45:00.620 --> 01:45:07.580]   So they use a rating system, the ELO rating system. They use it in chess. I guess they use it in Go
[01:45:07.580 --> 01:45:13.740]   as well. This is a video of how AlphaGo, make a little higher, how AlphaGo learned. It started
[01:45:13.740 --> 01:45:19.980]   at zero, like it knew nothing, no knowledge of the game. But look how fast and it's not a straight
[01:45:19.980 --> 01:45:25.420]   up. It's up and down, up and down. But in the long run, it got to a very strong three days.
[01:45:25.420 --> 01:45:31.420]   It got to a stronger than the original AlphaGo. Now it starts to taper off, of course, because
[01:45:31.420 --> 01:45:37.500]   it can't grow as fast in three weeks. It reached the level that defeated the 60 top professionals
[01:45:37.500 --> 01:45:41.980]   online and the world champion three out of three games last year. And now it's better.
[01:45:41.980 --> 01:45:47.740]   It's on the charts. In 40 days, it's better than all of their versions of AlphaGo.
[01:45:47.740 --> 01:45:52.620]   Many times to play to get there. Oh, that's a great question. It must have been hundreds of
[01:45:52.620 --> 01:45:57.980]   millions of games, right? Because it can play a lot faster. If it doesn't actually have to put
[01:45:57.980 --> 01:46:07.340]   those 10,000 hours ideas, just straight to hell. Now Go is a very rigorous and rigid structure.
[01:46:07.340 --> 01:46:13.340]   For instance, I had for years, and my kids love this as a screen saver, something called
[01:46:13.340 --> 01:46:21.180]   Breathe Walker, which is a very popular artificial intelligence thing. It was a four-legged creature
[01:46:22.220 --> 01:46:28.460]   here. I'll show you a video of it at work. It's a four-legged creature that teaches itself to walk.
[01:46:28.460 --> 01:46:36.780]   But it first doesn't do a very good job. But over many iterations, it gets better and better and
[01:46:36.780 --> 01:46:43.820]   better and eventually walks. But it might take months or even years because you start with nothing.
[01:46:43.820 --> 01:46:50.300]   I love that it's the best screensaver ever. How does it define what is not all about the goal?
[01:46:50.300 --> 01:46:53.020]   The goal is distance. What defines good walking? Oh, distance.
[01:46:53.020 --> 01:47:00.940]   So it tries different strategies at random with its four articulated legs. Some of them are like
[01:47:00.940 --> 01:47:05.660]   this, and they don't move anywhere. And then till it gets somewhere. And it's really interesting to
[01:47:05.660 --> 01:47:10.060]   see it. But it's not nearly as, of course, we can't do as many iterations as fast. So
[01:47:10.060 --> 01:47:14.940]   it didn't take 40 days to become the best Go player in the world. I think Go is so much more
[01:47:14.940 --> 01:47:20.540]   structured. It might be a little bit easier. I don't know. It's pretty impressive. So that's
[01:47:20.540 --> 01:47:27.100]   very different than a computer that writes its own code. But it's related in this sense. And this
[01:47:27.100 --> 01:47:32.780]   is the thing that scares humans. And this to me is what the real singularity is. You know, often
[01:47:32.780 --> 01:47:37.900]   they talk about the singularity being when a computer mind is indistinguishable from a human
[01:47:37.900 --> 01:47:45.420]   mind. It's as good as, or at least can't, you can't tell the difference. My singularity is when
[01:47:45.420 --> 01:47:52.060]   computers or artificial intelligences can start designing themselves. Because that's the hockey
[01:47:52.060 --> 01:47:58.620]   stick. Because we're slow. So as long as we have to write the code or teach the computer to play
[01:47:58.620 --> 01:48:03.260]   Go, it's going to take longer. The minute the computer can just say, let me take it from here
[01:48:03.260 --> 01:48:10.140]   and do a million moves a second or write its own code. The acceleration of learning just
[01:48:10.140 --> 01:48:15.740]   takes off. You've got the exponential elbow in the hockey stick. That to me is the real singularity.
[01:48:15.740 --> 01:48:21.020]   And it sounds like we might be getting there. Auto ML.
[01:48:21.020 --> 01:48:28.780]   I think that'll go ahead. So that will be important for times to come because we cannot, as people,
[01:48:29.580 --> 01:48:35.900]   generate the code we're going to need in a flawless manner as we have to. So, you know,
[01:48:35.900 --> 01:48:41.740]   I know this is scary in some ways. And we should be talking about how to audit things and,
[01:48:41.740 --> 01:48:52.140]   you know, how to look at outcomes and test stuff. But we don't do things by hand anymore. There's
[01:48:52.140 --> 01:48:57.420]   so many like we don't, we don't hand stitch our clothing anymore. It's ridiculous that we should
[01:48:57.420 --> 01:49:05.420]   have to hand write our code when we're putting so much of our lives in tech. That was kind of not
[01:49:05.420 --> 01:49:08.460]   as eloquent as I wanted it to be. But you get where I'm going with this.
[01:49:08.460 --> 01:49:11.420]   Yeah. And I don't think that
[01:49:11.420 --> 01:49:17.500]   I think that there's the two
[01:49:17.500 --> 01:49:25.020]   issues are orthogonal. So I think there's the one issue that the computer writing its own code
[01:49:25.020 --> 01:49:31.340]   that's separate from the what you don't want a computer to do is optimize for its success.
[01:49:31.340 --> 01:49:38.940]   That's the famous paperclip example, right? If you build a paperclip machine that is trained
[01:49:38.940 --> 01:49:44.540]   to optimize for building paperclips, that's all it does. And success is only the number of paper
[01:49:44.540 --> 01:49:50.140]   clips generates. Eventually, it eats the whole world because everything is about making paper clips.
[01:49:51.980 --> 01:49:55.820]   That's different in, if my opinion, that's orthogonal from the goal of having computers
[01:49:55.820 --> 01:50:01.660]   right there on software. That's two different problems, I hope. You know that example, the paperclip
[01:50:01.660 --> 01:50:07.740]   Yes. Machine. Isn't, isn't writing your own software just an extension of a learning system?
[01:50:07.740 --> 01:50:14.300]   A learning network? Yeah. Sort of. Right. That's, it's all used.
[01:50:14.300 --> 01:50:18.780]   If you think about it, AlphaGo is writing its own software because it's saying how do I,
[01:50:18.780 --> 01:50:26.620]   how do I win at, at Go? Yeah, you're right. And yeah, because we heard this said at I/O where,
[01:50:26.620 --> 01:50:31.340]   where you have a system that says, here's the goal to, I think, I think in the example,
[01:50:31.340 --> 01:50:38.140]   it's to correctly identify photos. And we'll create them, but, but, but they said the software
[01:50:38.140 --> 01:50:43.900]   could create its own tests, basically its own software to do that more efficiently and effectively
[01:50:44.540 --> 01:50:50.940]   that would be the itself. It's called the paperclip maximizer. It's the canonical thought experiment.
[01:50:50.940 --> 01:50:56.700]   I'm reading from the less wrong wiki, which I like the name of showing how an artificial
[01:50:56.700 --> 01:51:02.860]   general intelligence, even one designed competently and without malice, could ultimately destroy humanity.
[01:51:04.620 --> 01:51:14.300]   This was Nick Bostrom proposed this in 2003. It, it, the goal is to maximize the number of paper
[01:51:14.300 --> 01:51:18.300]   clips in its collection. If it has been constructed with roughly human level of general intelligence,
[01:51:18.300 --> 01:51:23.180]   the AGI might collect paper clips or earn money to buy paper clips or begin to manufacture paper
[01:51:23.180 --> 01:51:29.580]   clips. More importantly, however, it would undergo an intelligence explosion, the hockey stick.
[01:51:29.580 --> 01:51:33.740]   It would work to improve its own intelligence where intelligence is understood in the optimization
[01:51:33.740 --> 01:51:39.180]   power, the ability to maximize a reward utility function, in this case, the number of paper clips.
[01:51:39.180 --> 01:51:45.180]   So the AGI would quickly realize, oh, collecting paper clips is not the goal, is not really how
[01:51:45.180 --> 01:51:52.380]   I achieve my goal. I need to improve my intelligence to help it, to help accumulate more paper clips.
[01:51:52.380 --> 01:51:58.060]   And it would continue to improve and enhance. And eventually, it would consume the entire
[01:51:58.060 --> 01:52:02.220]   world making paper clips. And then it will go on to make a fake first lady.
[01:52:02.700 --> 01:52:04.700]   [Laughter]
[01:52:04.700 --> 01:52:10.620]   Which is why audit and understanding how these, looking at outcomes of AI is actually really
[01:52:10.620 --> 01:52:16.460]   important. Because we don't understand necessarily how computers are making the decisions or get
[01:52:16.460 --> 01:52:20.780]   to their decision. But eventually, we're not going to be black boxes, right?
[01:52:20.780 --> 01:52:26.620]   That's what I'm saying. That's why audit and outcomes are important. And that, we tend to look
[01:52:26.620 --> 01:52:37.820]   a lot at intent. So that'll be kind of an interesting way to think about legal issues and regulations
[01:52:37.820 --> 01:52:39.340]   and fun stuff like that.
[01:52:39.340 --> 01:52:44.860]   You know what we did talk about a lot this year? And I don't see it a lot in this rundown
[01:52:44.860 --> 01:52:46.540]   case. So we have to talk more about...
[01:52:46.540 --> 01:52:48.540]   [Laughter]
[01:52:48.540 --> 01:52:53.420]   Because it was a major cultural moment.
[01:52:53.420 --> 01:53:01.340]   You started. And I am a great fan of Stacey Hagan-Motham. But my foundation crumbled.
[01:53:01.340 --> 01:53:10.460]   She's so tolerated that she could even, even for a moment consider what Chipotle passes off
[01:53:10.460 --> 01:53:14.220]   as queso. She's just too nice, Stacey.
[01:53:14.220 --> 01:53:15.180]   You just...
[01:53:15.180 --> 01:53:19.740]   No, it just didn't offend me. It was not the worst queso I've ever had.
[01:53:19.740 --> 01:53:21.420]   Oh, I thought it was quite good too.
[01:53:21.420 --> 01:53:24.460]   Oh, I didn't think it was quite good. Don't put those words in the mouth.
[01:53:24.460 --> 01:53:24.620]   Okay.
[01:53:24.620 --> 01:53:29.180]   Hey, you know what? Up here in Northern California, any queso is good queso.
[01:53:29.180 --> 01:53:33.980]   We don't kick queso like you do. Not in Chipotle. It's not.
[01:53:33.980 --> 01:53:35.260]   Yeah. Anyway...
[01:53:35.260 --> 01:53:36.380]   They did change the recipe.
[01:53:36.380 --> 01:53:37.180]   They fixed the recipe.
[01:53:37.180 --> 01:53:37.900]   They didn't blame it all on you, Jim.
[01:53:37.900 --> 01:53:39.260]   I think it's Jeff Jarvis is doing it.
[01:53:39.260 --> 01:53:39.900]   They did?
[01:53:39.900 --> 01:53:40.140]   Yeah.
[01:53:40.140 --> 01:53:41.180]   Oh, yeah.
[01:53:41.180 --> 01:53:41.980]   They said they did.
[01:53:41.980 --> 01:53:44.940]   They wanted to make it smoother. You would complain about it being grainy.
[01:53:44.940 --> 01:53:47.100]   Mine wasn't grainy when I had it.
[01:53:47.100 --> 01:53:49.500]   Yeah, I didn't experience that either. You had it here, by the way.
[01:53:49.500 --> 01:53:49.980]   I did.
[01:53:49.980 --> 01:53:51.020]   Yeah, she was.
[01:53:51.020 --> 01:53:54.060]   That was the highlight of my year. Stacey Higabotham coming to our studio.
[01:53:54.060 --> 01:53:56.540]   Unexpectedly too. I was thrilled.
[01:53:56.540 --> 01:53:57.180]   I was thrilled.
[01:53:57.180 --> 01:54:01.340]   And you know, is that any way to treat an honored guest to give her the worst queso owners?
[01:54:01.340 --> 01:54:03.340]   She's legal.
[01:54:03.340 --> 01:54:05.180]   Can I tell you?
[01:54:05.180 --> 01:54:06.460]   I never called that a hospitality.
[01:54:06.460 --> 01:54:07.500]   That'd tell you a secret.
[01:54:07.500 --> 01:54:08.620]   Luba hospitality.
[01:54:08.620 --> 01:54:09.740]   We also got it for free.
[01:54:09.740 --> 01:54:11.980]   I did know that.
[01:54:11.980 --> 01:54:17.820]   Somebody from works at Chipotle had come by and given us a bunch of Chipotle gift cards.
[01:54:17.820 --> 01:54:20.220]   And so we took it for instance.
[01:54:20.220 --> 01:54:21.340]   All right.
[01:54:21.340 --> 01:54:25.020]   This was a big year for Google's hardware announcements.
[01:54:25.020 --> 01:54:27.660]   Some pro, some not so good.
[01:54:27.660 --> 01:54:29.180]   I'm a fan of the Pixel 2 XL.
[01:54:29.180 --> 01:54:31.340]   Jeff, you still are using it, right? You like it.
[01:54:31.340 --> 01:54:32.700]   I have the Pixel 2 XL.
[01:54:32.700 --> 01:54:35.660]   I have it right in front of me, the Pixel book.
[01:54:35.660 --> 01:54:36.780]   Yep.
[01:54:36.780 --> 01:54:37.580]   Love the Pixel book.
[01:54:37.580 --> 01:54:39.580]   Although Jason Hall had to send his back.
[01:54:39.580 --> 01:54:40.220]   There was something wrong.
[01:54:40.220 --> 01:54:41.340]   Yeah, it was scary.
[01:54:41.340 --> 01:54:41.980]   I saw that.
[01:54:41.980 --> 01:54:45.340]   Mine went black yesterday and I thought,
[01:54:45.340 --> 01:54:47.260]   oh, I've been Jason'd.
[01:54:47.260 --> 01:54:47.900]   But it's fine.
[01:54:47.900 --> 01:54:48.460]   I think they're OK.
[01:54:48.460 --> 01:54:49.420]   I think it's OK.
[01:54:49.420 --> 01:54:52.300]   But the one product I think everybody agreed that Google came out with
[01:54:52.300 --> 01:54:55.100]   that really was a bust and disappointing.
[01:54:55.100 --> 01:54:57.420]   It's kind of, you know, in the hardware line,
[01:54:57.420 --> 01:54:58.300]   it's kind of the case.
[01:54:58.300 --> 01:54:59.020]   So of hardware.
[01:54:59.020 --> 01:55:01.500]   The Pixel Buds.
[01:55:01.500 --> 01:55:02.700]   Like case A, case.
[01:55:02.700 --> 01:55:03.900]   So of the case.
[01:55:03.900 --> 01:55:03.900]   The case.
[01:55:03.900 --> 01:55:04.700]   So much.
[01:55:04.700 --> 01:55:06.140]   Case.
[01:55:06.140 --> 01:55:06.540]   So much.
[01:55:06.540 --> 01:55:10.060]   Hey, have neither of you bought the Pixel Buds yet, right?
[01:55:10.060 --> 01:55:11.660]   Oh, I said my back.
[01:55:11.660 --> 01:55:12.300]   I just canceled them.
[01:55:12.300 --> 01:55:14.220]   Oh, I canceled them.
[01:55:14.220 --> 01:55:16.700]   I have to return mine.
[01:55:16.700 --> 01:55:18.780]   Mine stopped working.
[01:55:18.780 --> 01:55:20.140]   Why'd you send yours back?
[01:55:20.140 --> 01:55:20.620]   As Stacy.
[01:55:20.620 --> 01:55:23.660]   Because they were the most uncomfortable things ever.
[01:55:23.660 --> 01:55:27.100]   God, it felt like spiders clawing at my ears.
[01:55:27.100 --> 01:55:29.500]   You know, the sound quality was good.
[01:55:29.500 --> 01:55:32.380]   Although Sam Askovich had a pretty good piece in ours,
[01:55:32.380 --> 01:55:36.300]   Technica, in which he said he has a broader musical taste,
[01:55:36.300 --> 01:55:37.020]   I guess, than I do.
[01:55:37.020 --> 01:55:38.220]   But he listens to older music.
[01:55:38.220 --> 01:55:39.100]   It doesn't sound as good.
[01:55:39.100 --> 01:55:41.340]   It's tuned for modern pop music.
[01:55:42.540 --> 01:55:46.140]   I didn't know, but there's a lot of sound shaping going on in the Pixel Buds.
[01:55:46.140 --> 01:55:47.420]   But I thought they sounded very good.
[01:55:47.420 --> 01:55:49.020]   The music I was listening to.
[01:55:49.020 --> 01:55:51.260]   I kind of like the idea of it being in your ear.
[01:55:51.260 --> 01:55:54.300]   But then it just basically they stopped working and I can't repair them.
[01:55:54.300 --> 01:55:55.340]   I can't pair them to anything.
[01:55:55.340 --> 01:55:57.660]   So now I have to call them and get an ear.
[01:55:57.660 --> 01:55:58.780]   Did you un-pair them?
[01:55:58.780 --> 01:56:00.700]   Well, yeah, because it wasn't-
[01:56:00.700 --> 01:56:01.580]   You could un-pair them first.
[01:56:01.580 --> 01:56:04.540]   It wasn't working, so I forgot them on my Pixel phone.
[01:56:04.540 --> 01:56:07.820]   And then I never could repair them.
[01:56:07.820 --> 01:56:09.180]   So the whole thing is, I mean,
[01:56:10.380 --> 01:56:12.540]   they've had such trouble with the Pixel phone.
[01:56:12.540 --> 01:56:13.660]   I think it's okay now.
[01:56:13.660 --> 01:56:17.500]   They put out an update that let me saturate the color more.
[01:56:17.500 --> 01:56:18.700]   And there's no burn in on mine.
[01:56:18.700 --> 01:56:20.540]   But still, what's going on, Google?
[01:56:20.540 --> 01:56:22.940]   Can we talk about that momentarily?
[01:56:22.940 --> 01:56:25.980]   Because I have my own issue, which is-
[01:56:25.980 --> 01:56:27.420]   You have the smaller pixel.
[01:56:27.420 --> 01:56:27.900]   You have the little one.
[01:56:27.900 --> 01:56:29.660]   I have the little pixel.
[01:56:29.660 --> 01:56:31.180]   The pixel mini.
[01:56:31.180 --> 01:56:31.900]   The Wii Pixel.
[01:56:31.900 --> 01:56:34.380]   The Wii Pixel.
[01:56:34.380 --> 01:56:38.940]   So I called them because I was kind of sick of having my NFC radio turned off.
[01:56:38.940 --> 01:56:42.220]   So I was like, "Hey, can my phone is clicking?
[01:56:42.220 --> 01:56:45.180]   Can we- is there something you guys could do?"
[01:56:45.180 --> 01:56:47.180]   And they're like, "Well, we have an update that addresses that."
[01:56:47.180 --> 01:56:48.220]   But it's not out yet.
[01:56:48.220 --> 01:56:50.460]   Okay, so he tells me it's out.
[01:56:50.460 --> 01:56:51.500]   We've started pushing it.
[01:56:51.500 --> 01:56:52.460]   And I was like, "Great.
[01:56:52.460 --> 01:56:54.860]   Could you push it down to me super fast?"
[01:56:54.860 --> 01:56:56.220]   Now?
[01:56:56.220 --> 01:56:56.540]   Could you-
[01:56:56.540 --> 01:56:57.660]   Now?
[01:56:57.660 --> 01:56:58.860]   Yes, because I didn't have it.
[01:56:58.860 --> 01:57:01.820]   And he's like, "Well, it'll be out to you in a few weeks."
[01:57:01.820 --> 01:57:04.620]   And I was like, "I am not on a carrier.
[01:57:04.620 --> 01:57:07.900]   They are not Apple having to stagger their release times."
[01:57:08.540 --> 01:57:11.980]   You know, like, it's not like he's got 50 million of these out in the wild.
[01:57:11.980 --> 01:57:12.940]   You're on Google Fi?
[01:57:12.940 --> 01:57:17.020]   No, I'm on Verizon, but it's an unlocked phone.
[01:57:17.020 --> 01:57:18.060]   So my carrier doesn't-
[01:57:18.060 --> 01:57:19.420]   Push anything.
[01:57:19.420 --> 01:57:20.460]   Right.
[01:57:20.460 --> 01:57:20.780]   Right.
[01:57:20.780 --> 01:57:27.260]   So what this tells me is Google can't do an update.
[01:57:27.260 --> 01:57:28.460]   An over the update to us.
[01:57:28.460 --> 01:57:30.300]   What this tells me is Google can't do hardware.
[01:57:30.300 --> 01:57:32.300]   God, it tells us shit.
[01:57:32.300 --> 01:57:33.340]   It's very disappointing.
[01:57:33.340 --> 01:57:33.980]   I mean, here they are.
[01:57:33.980 --> 01:57:36.700]   They're really kind of making a push to compete with Apple.
[01:57:36.700 --> 01:57:38.060]   And in some respects, they do.
[01:57:38.060 --> 01:57:38.860]   The camera's great.
[01:57:38.860 --> 01:57:39.420]   Right, Stacey?
[01:57:39.420 --> 01:57:40.140]   You love your camera.
[01:57:40.140 --> 01:57:40.620]   The camera's-
[01:57:40.620 --> 01:57:41.260]   Yeah, it's great.
[01:57:41.260 --> 01:57:44.540]   But in other respects, they just-
[01:57:44.540 --> 01:57:46.540]   I mean, this is not as good a screen.
[01:57:46.540 --> 01:57:51.900]   And as either the Samsung notes or S8s or the Apple iPhone 10,
[01:57:51.900 --> 01:57:53.420]   it's just not a very good screen.
[01:57:53.420 --> 01:57:56.460]   And then it's got buzzing and clicking on the Pixel 2.
[01:57:56.460 --> 01:57:59.180]   It's got a burden issue on the XL.
[01:57:59.180 --> 01:58:01.660]   And the Pixel Buds-
[01:58:01.660 --> 01:58:04.140]   Why did you return yours, Jeff?
[01:58:04.140 --> 01:58:04.460]   Just-
[01:58:04.460 --> 01:58:05.180]   You didn't return them.
[01:58:05.180 --> 01:58:06.140]   You just cancel them.
[01:58:06.140 --> 01:58:07.340]   I just canceled them just today.
[01:58:07.340 --> 01:58:08.540]   I remember the show coming up.
[01:58:08.540 --> 01:58:09.900]   Oh, better canceled before it's too late.
[01:58:09.900 --> 01:58:12.140]   I just read the reviews too often.
[01:58:12.140 --> 01:58:13.340]   The pairing is what killed it for me.
[01:58:13.340 --> 01:58:14.460]   Yeah, well, it's broken.
[01:58:14.460 --> 01:58:16.620]   I want to be able to operate among the three devices
[01:58:16.620 --> 01:58:18.700]   seamlessly, and you've got to un-pair and repair.
[01:58:18.700 --> 01:58:20.300]   And you've got to put them back in the case to do so.
[01:58:20.300 --> 01:58:21.740]   Oh, forget it.
[01:58:21.740 --> 01:58:21.740]   Plus-
[01:58:21.740 --> 01:58:22.780]   Plus-
[01:58:22.780 --> 01:58:22.860]   Plus-
[01:58:22.860 --> 01:58:24.620]   The translation is dopey.
[01:58:24.620 --> 01:58:27.660]   It works much better just using it as always on the phone.
[01:58:27.660 --> 01:58:28.220]   Because-
[01:58:28.220 --> 01:58:28.620]   Yeah.
[01:58:28.620 --> 01:58:32.220]   The real problem is the translation that's being made is
[01:58:32.220 --> 01:58:32.940]   you don't-
[01:58:32.940 --> 01:58:35.740]   You hear it, but the person who talked to you and the-
[01:58:35.740 --> 01:58:37.580]   the other language doesn't hear it.
[01:58:37.580 --> 01:58:39.100]   So can't correct it.
[01:58:39.100 --> 01:58:40.700]   And since it does make mistakes,
[01:58:40.700 --> 01:58:41.820]   it's really better to do it on the phone
[01:58:41.820 --> 01:58:44.300]   where both sides can hear the translation and say,
[01:58:44.300 --> 01:58:45.580]   "No, no, no, that's a mistake.
[01:58:45.580 --> 01:58:47.260]   What I meant to say was-
[01:58:47.260 --> 01:58:48.380]   We need to be able to choose that.
[01:58:48.380 --> 01:58:50.300]   It's a gimmicky thing.
[01:58:50.300 --> 01:58:52.380]   Because they said, "Okay, we can put a system on the-
[01:58:52.380 --> 01:58:52.940]   on the buds.
[01:58:52.940 --> 01:58:53.820]   Oh, what can we do with it?
[01:58:53.820 --> 01:58:54.380]   Oh, I don't know-
[01:58:54.380 --> 01:58:54.940]   It's gimmicky.
[01:58:54.940 --> 01:58:54.940]   - I don't know-
[01:58:54.940 --> 01:58:55.500]   - Translate.
[01:58:55.500 --> 01:58:55.900]   - Yeah, it's gimmicky.
[01:58:55.900 --> 01:58:57.340]   Yeah, it'll translate.
[01:58:57.340 --> 01:58:57.740]   Yeah, it'll translate.
[01:58:57.740 --> 01:58:58.140]   You know-
[01:58:58.140 --> 01:59:04.220]   So, actually, I think one of our chatters has it right.
[01:59:05.100 --> 01:59:07.660]   Which is where is it?
[01:59:07.660 --> 01:59:09.740]   I want to give you a quote.
[01:59:09.740 --> 01:59:12.540]   Basically, Google's not a hardware manufacturer.
[01:59:12.540 --> 01:59:14.300]   - Well, Leo, it's an information company.
[01:59:14.300 --> 01:59:15.580]   - It's an information company.
[01:59:15.580 --> 01:59:16.140]   That's the quote.
[01:59:16.140 --> 01:59:18.460]   - Or what you just said, Google is in fact like Apple,
[01:59:18.460 --> 01:59:21.100]   in the sense that it's no longer wowing us.
[01:59:21.100 --> 01:59:23.100]   - Well, didn't they-
[01:59:23.100 --> 01:59:26.380]   - Yeah, but Apple has wowed us with the iPhone X.
[01:59:26.380 --> 01:59:28.940]   Apple is not 100% consistent,
[01:59:28.940 --> 01:59:31.500]   but they know how to manufacture.
[01:59:34.140 --> 01:59:37.340]   And the AirPods do exactly what the Pixel Buds don't.
[01:59:37.340 --> 01:59:39.580]   And it would behoove you if you take the
[01:59:39.580 --> 01:59:41.180]   headphone jack out of a phone
[01:59:41.180 --> 01:59:44.380]   to provide a wireless alternative,
[01:59:44.380 --> 01:59:47.100]   or you've really just screwed your users.
[01:59:47.100 --> 01:59:49.420]   - And if you want wired ones,
[01:59:49.420 --> 01:59:54.140]   there are very few good USB-C wired headphones.
[01:59:54.140 --> 01:59:54.300]   - Right.
[01:59:54.300 --> 01:59:54.940]   - Oh, are there any-
[01:59:54.940 --> 01:59:54.940]   - Really?
[01:59:54.940 --> 01:59:57.740]   - There are like five.
[01:59:57.740 --> 01:59:59.180]   - But they give you an adapter,
[01:59:59.180 --> 02:00:00.220]   so you could use any headphones.
[02:00:00.220 --> 02:00:01.500]   - Oh, my adapter stopped working,
[02:00:01.500 --> 02:00:02.540]   so I'm getting a new doggo.
[02:00:02.540 --> 02:00:04.540]   - I'm getting a new doggo, how awful.
[02:00:04.540 --> 02:00:07.420]   - And how quickly you're going to lose the adapter.
[02:00:07.420 --> 02:00:08.220]   It's just-
[02:00:08.220 --> 02:00:09.020]   - Well, I have-
[02:00:09.020 --> 02:00:10.380]   - Or you could buy five of them or-
[02:00:10.380 --> 02:00:15.020]   - But yeah, it is really frustrating
[02:00:15.020 --> 02:00:16.300]   to take something out that worked.
[02:00:16.300 --> 02:00:18.460]   - You know what?
[02:00:18.460 --> 02:00:18.780]   - You know what?
[02:00:18.780 --> 02:00:19.580]   - You're using the size of this phone.
[02:00:19.580 --> 02:00:20.700]   Why, I'm sorry, I just need to see.
[02:00:20.700 --> 02:00:22.300]   - No, I was going to say,
[02:00:22.300 --> 02:00:24.220]   and it's my fault for buying, you know,
[02:00:24.220 --> 02:00:25.020]   the Pixel phone,
[02:00:25.020 --> 02:00:26.940]   but I really like being on stock, Android.
[02:00:26.940 --> 02:00:27.340]   - Yep.
[02:00:27.340 --> 02:00:27.340]   - And-
[02:00:27.340 --> 02:00:27.900]   - Yep.
[02:00:27.900 --> 02:00:29.500]   - Google, my God,
[02:00:29.500 --> 02:00:31.340]   I'm your most loyal customer here.
[02:00:31.340 --> 02:00:32.860]   I mean, these are the people who are like,
[02:00:32.860 --> 02:00:34.540]   "We love you, Google, we love Android."
[02:00:34.540 --> 02:00:36.620]   Why must you screw us up here?
[02:00:36.620 --> 02:00:39.420]   - Probably the most important news of the week,
[02:00:39.420 --> 02:00:43.020]   no doubt people are very excited about the fact
[02:00:43.020 --> 02:00:46.780]   that the hamburger emoji is now correct.
[02:00:46.780 --> 02:00:47.340]   - The right way around.
[02:00:47.340 --> 02:00:48.140]   - The right way around,
[02:00:48.140 --> 02:00:49.900]   the cheese is no longer on the bun,
[02:00:49.900 --> 02:00:51.180]   it's now on the burger,
[02:00:51.180 --> 02:00:52.620]   we can all sleep at night.
[02:00:52.620 --> 02:00:54.620]   - Let's not deny,
[02:00:54.620 --> 02:00:55.660]   this is a crucial,
[02:00:55.660 --> 02:00:58.060]   even global issue.
[02:00:58.060 --> 02:00:59.740]   Like, I, for one,
[02:00:59.740 --> 02:01:02.220]   I'm glad that this has been dealt with,
[02:01:02.220 --> 02:01:03.740]   because it's been hanging over us for
[02:01:03.740 --> 02:01:05.740]   low these many days.
[02:01:05.740 --> 02:01:08.860]   - How many hamburger emojis have you been putting out there?
[02:01:08.860 --> 02:01:09.420]   They've been,
[02:01:09.420 --> 02:01:11.660]   or is it just that they've been being sent to you?
[02:01:11.660 --> 02:01:14.300]   Because I don't know if I've ever used a hamburger emoji.
[02:01:14.300 --> 02:01:15.980]   - I actually hadn't either.
[02:01:15.980 --> 02:01:16.940]   I like to eat them,
[02:01:16.940 --> 02:01:18.060]   but the emoji,
[02:01:18.060 --> 02:01:19.820]   I don't feel that strongly about.
[02:01:19.820 --> 02:01:21.100]   But I have to admit,
[02:01:21.100 --> 02:01:23.260]   I got into the discussion over,
[02:01:23.260 --> 02:01:27.820]   what is the appropriate order for the lettuce,
[02:01:27.820 --> 02:01:30.060]   the tomato, the cheese, etc.
[02:01:30.060 --> 02:01:32.220]   People feel very passionately about this topic.
[02:01:32.220 --> 02:01:33.660]   - They really do.
[02:01:33.660 --> 02:01:35.580]   I don't know.
[02:01:35.580 --> 02:01:36.780]   I mean, it looks fine either way.
[02:01:36.780 --> 02:01:40.220]   No, wow, that was a loud drone.
[02:01:40.220 --> 02:01:41.100]   - No, no, no, no, no, no, no, no, no, no, no, no, no, no, no.
[02:01:41.100 --> 02:01:42.700]   - From off the microphone.
[02:01:42.700 --> 02:01:46.460]   I mean, it's still cheese in a hamburger, right?
[02:01:46.460 --> 02:01:48.620]   - Are we rehashing this dish?
[02:01:48.620 --> 02:01:49.820]   - No, we don't need every hash.
[02:01:49.820 --> 02:01:51.340]   - Are we going there?
[02:01:51.340 --> 02:01:52.620]   - No, no, we don't really need to.
[02:01:52.620 --> 02:01:55.100]   Sorry, I didn't mean to take it there.
[02:01:55.100 --> 02:01:57.100]   Although, I do want to point out,
[02:01:57.100 --> 02:01:58.940]   another part of this emoji gate,
[02:01:58.940 --> 02:02:01.180]   if it does qualify as a gate,
[02:02:01.180 --> 02:02:02.620]   is this whole beer thing,
[02:02:02.620 --> 02:02:04.780]   which I hadn't noticed.
[02:02:04.780 --> 02:02:08.460]   But once I noticed the correction that they made to the beer emoji,
[02:02:08.460 --> 02:02:10.860]   I realized like, what were they thinking?
[02:02:10.860 --> 02:02:13.820]   How do you have foam on the top of a beer stein,
[02:02:13.820 --> 02:02:16.860]   a beer mug, with no beer up to the top of the...
[02:02:16.860 --> 02:02:17.660]   - Beer point.
[02:02:17.660 --> 02:02:19.100]   - I mean, how do you do that?
[02:02:19.100 --> 02:02:21.100]   It looks like a hat, like a, like a,
[02:02:21.100 --> 02:02:24.140]   I don't know, a raccoon hat or something.
[02:02:24.140 --> 02:02:26.460]   - Really, what this says to me is that Google,
[02:02:27.180 --> 02:02:29.500]   maybe it doesn't invest a lot in its emojis.
[02:02:29.500 --> 02:02:31.660]   - Yeah, like maybe they've got better things to do.
[02:02:31.660 --> 02:02:35.020]   - Maybe of their mini messaging platforms,
[02:02:35.020 --> 02:02:36.460]   they still are kind of like, yeah,
[02:02:36.460 --> 02:02:37.580]   let's work on those instead.
[02:02:37.580 --> 02:02:40.620]   - Let's fix things that are broken,
[02:02:40.620 --> 02:02:43.580]   instead of fix little pictures that were drawn by somebody.
[02:02:43.580 --> 02:02:46.540]   Although, if I remember correctly,
[02:02:46.540 --> 02:02:50.220]   Sundar Pichai did say when all this was kind of hit in the fan,
[02:02:50.220 --> 02:02:51.660]   that this was going to be high priority,
[02:02:51.660 --> 02:02:52.860]   that he was going to make a change.
[02:02:52.860 --> 02:02:53.740]   - Any help to it.
[02:02:53.740 --> 02:02:54.860]   - They were going to get on it.
[02:02:54.860 --> 02:02:55.420]   - Yeah.
[02:02:55.420 --> 02:02:55.820]   - Yeah.
[02:02:55.820 --> 02:02:56.220]   - So.
[02:02:56.220 --> 02:02:59.100]   - Well, just imagine if it was beer and burgers,
[02:02:59.100 --> 02:03:00.780]   imagine all the other emojis that,
[02:03:00.780 --> 02:03:04.300]   I seem to be frozen for some reason.
[02:03:04.300 --> 02:03:08.380]   I am actually moving my lips, but the beer and,
[02:03:08.380 --> 02:03:11.340]   what other emojis are they ignoring?
[02:03:11.340 --> 02:03:12.540]   - That's true.
[02:03:12.540 --> 02:03:14.780]   - You know, what have we not discovered yet?
[02:03:14.780 --> 02:03:17.260]   - And their gift emojis are on point.
[02:03:17.260 --> 02:03:18.300]   - Okay.
[02:03:18.300 --> 02:03:19.740]   - So I'm pro those.
[02:03:19.740 --> 02:03:21.740]   You know, I have never used an eggplant emoji,
[02:03:21.740 --> 02:03:23.420]   but that seems to be a popular one.
[02:03:23.420 --> 02:03:25.100]   - What about the dumpling emoji?
[02:03:25.100 --> 02:03:26.700]   Has anybody looked at the dumpling emoji?
[02:03:26.700 --> 02:03:27.660]   - The dumpling emoji.
[02:03:27.660 --> 02:03:28.300]   - So that's brand new.
[02:03:28.300 --> 02:03:32.780]   So Jenny Lee, who's a friend who used to work at the New York Times,
[02:03:32.780 --> 02:03:37.020]   wrote about emojis and actually pursued a personal quest
[02:03:37.020 --> 02:03:42.540]   to get the International Emoji Federation or whatever it is to add the dumpling
[02:03:42.540 --> 02:03:44.380]   and succeeded.
[02:03:44.380 --> 02:03:45.900]   So good for her.
[02:03:45.900 --> 02:03:50.380]   - Man, Apple's dumpling emoji looks just like a photograph or something that they have.
[02:03:50.380 --> 02:03:50.940]   - Yeah.
[02:03:50.940 --> 02:03:52.620]   - Microsoft is terrible, of course.
[02:03:53.420 --> 02:03:54.460]   Wow, that's a lot of...
[02:03:54.460 --> 02:03:57.900]   I didn't realize there was so much variation in how you could do a dumpling,
[02:03:57.900 --> 02:04:00.140]   but then I also didn't realize the same about a hamburger.
[02:04:00.140 --> 02:04:02.860]   - Were you not aware that there was a dumpling emoji?
[02:04:02.860 --> 02:04:03.660]   'Cause I wasn't.
[02:04:03.660 --> 02:04:04.380]   - I wasn't.
[02:04:04.380 --> 02:04:07.500]   No, you know, honestly, I'm super clueless about emoji.
[02:04:07.500 --> 02:04:11.900]   I rarely ever use it unless it's like placed in front of me and super obvious.
[02:04:11.900 --> 02:04:13.020]   Like I never go hunting.
[02:04:13.020 --> 02:04:19.100]   Like I see people's emoji language, you know, filled posts on Twitter or whatever.
[02:04:19.100 --> 02:04:22.220]   And I'm kind of amazed that they took the time to do that.
[02:04:22.220 --> 02:04:23.580]   I just want to like go out and go.
[02:04:23.580 --> 02:04:25.260]   - I know it's...
[02:04:25.260 --> 02:04:27.580]   You go ahead, Steve.
[02:04:27.580 --> 02:04:32.540]   - Oh, I was going to say Google will auto suggest things as emojis when you're typing.
[02:04:32.540 --> 02:04:35.020]   So I get a lot of emoji exposure that way.
[02:04:35.020 --> 02:04:40.220]   - Maybe it's just because I have teenagers and 20-somethings, but
[02:04:40.220 --> 02:04:48.700]   I mean, emojis are funny, but there are people I know and I'm related to who
[02:04:49.340 --> 02:04:51.980]   they conduct entire conversations in emojis.
[02:04:51.980 --> 02:04:55.100]   Sort of the emojis are a significant part of the conversation.
[02:04:55.100 --> 02:04:55.660]   - Yeah.
[02:04:55.660 --> 02:05:00.460]   - And it's interesting to me as a sort of student of language,
[02:05:00.460 --> 02:05:07.340]   how much you can convey with teeny, tiny, little cartoon figures.
[02:05:07.340 --> 02:05:12.300]   And I know when we used to use Slack, Stacy, and I way back in the gig home days,
[02:05:12.300 --> 02:05:13.740]   which I think was 100 years ago.
[02:05:13.740 --> 02:05:17.260]   It was amazing how much you could convey.
[02:05:17.260 --> 02:05:20.620]   It was just a single emoji where it would take you,
[02:05:20.620 --> 02:05:23.340]   you know, sentences to kind of get across what you were.
[02:05:23.340 --> 02:05:27.420]   It's just interesting to me that they're very emotionally
[02:05:27.420 --> 02:05:31.500]   laden, but so simple.
[02:05:31.500 --> 02:05:34.780]   And obviously dumplings don't actually mean that much.
[02:05:34.780 --> 02:05:36.380]   They just mean dumplings.
[02:05:36.380 --> 02:05:38.540]   But you know, you can get across.
[02:05:38.540 --> 02:05:43.740]   If you ever looked at shares, tweets, sometimes I have to spend like 20 minutes
[02:05:43.740 --> 02:05:46.940]   trying to understand what she's saying, because it's literally all emoji.
[02:05:46.940 --> 02:05:49.740]   - I don't know if it's only emojis.
[02:05:49.740 --> 02:05:52.140]   I mean, shares live a hard life.
[02:05:52.140 --> 02:05:53.900]   - True.
[02:05:53.900 --> 02:05:56.140]   And she conveys emotion in lots of ways, obviously.
[02:05:56.140 --> 02:05:59.100]   But I just find it fascinating that I thought they were dumb,
[02:05:59.100 --> 02:06:03.740]   and I wish I thought they were a sign of the dumbing down of society in general,
[02:06:03.740 --> 02:06:05.100]   and my kids in particular.
[02:06:05.100 --> 02:06:09.660]   But I think they actually do convey things that are hard to convey in words.
[02:06:09.660 --> 02:06:10.700]   - Yeah.
[02:06:10.700 --> 02:06:12.380]   They also soften things.
[02:06:13.420 --> 02:06:18.300]   I use emojis a lot of times as a, to add emotion.
[02:06:18.300 --> 02:06:21.740]   And I think, you know, people mock it as being a preteen girl thing,
[02:06:21.740 --> 02:06:25.740]   and I have a preteen girl, and she definitely uses emojis and stickers.
[02:06:25.740 --> 02:06:26.860]   Oh my God, the stickers.
[02:06:26.860 --> 02:06:27.420]   - Yes.
[02:06:27.420 --> 02:06:32.540]   - But I actually think it's useful and fun.
[02:06:32.540 --> 02:06:35.980]   And so, and who doesn't like getting like the little sparkly champagne
[02:06:35.980 --> 02:06:38.860]   plus the fireworks, plus everything when they're like, "I get something."
[02:06:38.860 --> 02:06:42.220]   That's way better than like, yay.
[02:06:42.220 --> 02:06:42.860]   Good job.
[02:06:42.860 --> 02:06:46.700]   - You know, the burger fixing the burger is great,
[02:06:46.700 --> 02:06:52.780]   but what I wish as an old person, someone would do is figure out a way to incorporate
[02:06:52.780 --> 02:06:57.420]   a magnifying glass to figure out, because sometimes I will see emojis,
[02:06:57.420 --> 02:06:59.020]   and I literally have no idea what they are.
[02:06:59.020 --> 02:07:02.380]   Like, so there's so much going on in the emoji.
[02:07:02.380 --> 02:07:04.620]   Like a burger I can figure out, obviously.
[02:07:04.620 --> 02:07:07.740]   But some of them, I'm squinting at them.
[02:07:07.740 --> 02:07:09.580]   I don't know what it is.
[02:07:09.580 --> 02:07:11.420]   Am I supposed to be happy about it?
[02:07:11.420 --> 02:07:12.380]   - I'm not gonna be the fun.
[02:07:12.380 --> 02:07:14.620]   It's like you're creating this whole language with different,
[02:07:14.620 --> 02:07:17.660]   like with some of my emojis mean something,
[02:07:17.660 --> 02:07:20.300]   and with other people, my emojis mean totally different thing.
[02:07:20.300 --> 02:07:23.420]   So it's kind of like, whoa, as a student.
[02:07:23.420 --> 02:07:24.060]   - You need a translate.
[02:07:24.060 --> 02:07:27.580]   - It's like you need a two times magnification button.
[02:07:27.580 --> 02:07:29.180]   - Exactly, two times.
[02:07:29.180 --> 02:07:29.740]   - Yeah.
[02:07:29.740 --> 02:07:31.340]   - And then you need a click to translate.
[02:07:31.340 --> 02:07:32.380]   - Oh, yeah.
[02:07:32.380 --> 02:07:32.860]   - To Google.
[02:07:32.860 --> 02:07:33.420]   - Well, you know.
[02:07:33.420 --> 02:07:34.940]   - That shouldn't be that hard, right?
[02:07:34.940 --> 02:07:36.060]   Google should be able to do that.
[02:07:36.060 --> 02:07:37.420]   - That should be really easy, actually.
[02:07:37.420 --> 02:07:41.820]   Doesn't each emoji, like, I know I've seen texts where they strip out the emoji,
[02:07:41.820 --> 02:07:44.460]   but they replace it with a description of what the emoji actually is.
[02:07:44.460 --> 02:07:47.980]   - So all you know is that they can translate Welsh,
[02:07:47.980 --> 02:07:50.700]   you know, they can probably translate emojis.
[02:07:50.700 --> 02:07:56.460]   - Well, I would say no, because not everything correlates exactly to what it is.
[02:07:56.460 --> 02:07:57.740]   - True, true.
[02:07:57.740 --> 02:07:58.460]   - Yeah.
[02:07:58.460 --> 02:08:02.140]   But in a couple of hundred years when emoji is an official language,
[02:08:02.140 --> 02:08:06.460]   that people live and exist there, you know, in their lives,
[02:08:07.020 --> 02:08:10.940]   100% of the time, this is going to be, you know, do the research now.
[02:08:10.940 --> 02:08:14.060]   We need to figure this out now, because it's important for the future generations.
[02:08:14.060 --> 02:08:15.980]   - It's important for our culture, for society.
[02:08:15.980 --> 02:08:16.940]   - Absolutely.
[02:08:16.940 --> 02:08:19.740]   These are not, you know, petty topics here.
[02:08:19.740 --> 02:08:24.220]   Like, I'm so old school, I still do the emoticons.
[02:08:24.220 --> 02:08:25.260]   - Me too.
[02:08:25.260 --> 02:08:26.380]   - It's like, it's habit.
[02:08:26.380 --> 02:08:26.780]   - Me too.
[02:08:26.780 --> 02:08:28.540]   - It's total habit to do the colon--
[02:08:28.540 --> 02:08:29.420]   - Okay, question.
[02:08:29.420 --> 02:08:30.700]   - Perenthesis.
[02:08:30.700 --> 02:08:33.420]   - Question, the smiley face.
[02:08:33.420 --> 02:08:34.060]   - Yeah.
[02:08:34.060 --> 02:08:38.300]   Do you do a colon and then a period and then the bracket?
[02:08:38.300 --> 02:08:39.900]   Or just a colon and the bracket?
[02:08:39.900 --> 02:08:43.420]   - Well, I thought you were going to ask, do you do the bracket and then the colon,
[02:08:43.420 --> 02:08:44.940]   which is the like opposite way.
[02:08:44.940 --> 02:08:47.660]   But no, I do the colon and then the bracket.
[02:08:47.660 --> 02:08:48.620]   I don't do the put of periods.
[02:08:48.620 --> 02:08:49.660]   - So it doesn't have a nose.
[02:08:49.660 --> 02:08:50.220]   - It's just so really good.
[02:08:50.220 --> 02:08:51.260]   - It doesn't have a nose.
[02:08:51.260 --> 02:08:55.500]   As my daughter told me that I'm, she made fun of me,
[02:08:55.500 --> 02:08:58.220]   because I make the smiley face with a nose.
[02:08:58.220 --> 02:08:59.740]   So there's the colon and the period.
[02:08:59.740 --> 02:09:00.700]   - Oh, I only think it's you.
[02:09:00.700 --> 02:09:00.860]   - Yeah.
[02:09:00.860 --> 02:09:01.180]   - Really?
[02:09:01.180 --> 02:09:05.660]   - She said that's like, it's like I'm from the 16th century or something.
[02:09:05.660 --> 02:09:08.300]   - It's like you use the Oxford comma in a text.
[02:09:08.300 --> 02:09:09.420]   - Yeah, yeah, exactly.
[02:09:09.420 --> 02:09:10.140]   - Yeah.
[02:09:10.140 --> 02:09:10.700]   - I probably do too.
[02:09:10.700 --> 02:09:12.300]   - So now I just use it to bugger.
[02:09:12.300 --> 02:09:13.900]   - I probably do that too, actually.
[02:09:13.900 --> 02:09:14.380]   Dang it.
[02:09:14.380 --> 02:09:15.660]   Dang it.
[02:09:15.660 --> 02:09:17.500]   I need to get with the times.
[02:09:17.500 --> 02:09:18.700]   - Keep it up.
[02:09:18.700 --> 02:09:21.580]   - You know, I haven't talked a whole lot about net neutrality.
[02:09:21.580 --> 02:09:24.380]   I've seen protests on the net Reddit when you go to Reddit has a big thing and
[02:09:24.380 --> 02:09:30.780]   a few other sites put up a, don't forget to call your Congress Critter and all that.
[02:09:30.780 --> 02:09:33.500]   I feel like it's over because there's no way, no matter what we do,
[02:09:33.500 --> 02:09:37.500]   we already got a more than a million comments in favor of net neutrality.
[02:09:37.500 --> 02:09:38.860]   The FCC just goes, yeah, right.
[02:09:38.860 --> 02:09:39.500]   Never mind.
[02:09:39.500 --> 02:09:40.460]   Who cares what you think?
[02:09:40.460 --> 02:09:41.500]   Why?
[02:09:41.500 --> 02:09:45.980]   - Not only do we have all these comments in favor of keeping net neutrality,
[02:09:45.980 --> 02:09:49.340]   we also have evidence of fraud that they're like,
[02:09:49.340 --> 02:09:51.980]   we don't care.
[02:09:51.980 --> 02:09:52.540]   - We don't care.
[02:09:52.540 --> 02:09:54.300]   They literally don't care.
[02:09:54.300 --> 02:09:59.020]   And incidentally, just to add insult to injury,
[02:09:59.020 --> 02:10:04.780]   because remember one of the things the FCC will do probably tomorrow is hand over all
[02:10:04.780 --> 02:10:06.460]   enforcement of net neutrality.
[02:10:06.460 --> 02:10:12.140]   A job, it really should be its job, Federal Communications Commission to the Federal Trade
[02:10:12.140 --> 02:10:12.540]   Commission.
[02:10:12.540 --> 02:10:17.500]   - And then the FTC says what?
[02:10:17.500 --> 02:10:17.820]   - Yeah.
[02:10:17.820 --> 02:10:23.420]   - Federal Trade Commissioner, Terrell McSweeney has repeatedly warned that her organization
[02:10:23.420 --> 02:10:28.700]   is not able to do the job. She actually wrote an article and says,
[02:10:28.700 --> 02:10:32.940]   quote, "The FTC does not have specialized expertise in telecommunications.
[02:10:32.940 --> 02:10:37.020]   We'll duh. We don't have engineers that technical experience in data network
[02:10:37.020 --> 02:10:41.660]   management practices. We don't even have jurisdiction over common carriers."
[02:10:41.660 --> 02:10:45.580]   These are very real and significant limits to the effectiveness of our tools,
[02:10:45.580 --> 02:10:49.260]   ensuring that networks are open and free of harmful discrimination."
[02:10:51.420 --> 02:10:55.580]   Which would explain to me exactly why AgiPi wants to give it to the FTC.
[02:10:55.580 --> 02:10:57.100]   There will be no enforcement.
[02:10:57.100 --> 02:10:58.060]   - Right.
[02:10:58.060 --> 02:11:02.300]   - You know, the thing about this is that go ahead, go ahead, Stacy.
[02:11:02.300 --> 02:11:04.860]   - I was going to say it'll be purely deceptive trade,
[02:11:04.860 --> 02:11:09.420]   the practices, anti-competitive.
[02:11:09.420 --> 02:11:12.700]   And those things are hard to prove.
[02:11:12.700 --> 02:11:18.940]   And even under net neutrality, there was a method for people to call that in and fight
[02:11:19.900 --> 02:11:22.700]   that and it takes a long time. This is just...
[02:11:22.700 --> 02:11:29.020]   - That's frustrating. Canada has gotten into the act.
[02:11:29.020 --> 02:11:34.140]   Apparently, a Canadian government official said that net neutrality has become an issue in the
[02:11:34.140 --> 02:11:39.340]   NAFTA negotiations, or it isn't really the NAFTA negotiations, but the negotiations over the
[02:11:39.340 --> 02:11:42.620]   replacement for the North America trade negotiations.
[02:11:42.620 --> 02:11:43.660]   The Trump negotiations.
[02:11:43.660 --> 02:11:49.100]   Canada's lead NAFTA negotiator, Steve Verhol, said to a parliamentary committee this week,
[02:11:49.100 --> 02:11:55.100]   "We're including provisions like online consumer protection to ensure that it's provided for,
[02:11:55.100 --> 02:11:58.460]   and that we also have provisions to provide personal information protection, which we feel
[02:11:58.460 --> 02:12:03.180]   is essential in this kind of trade, along with our position that we want to protect net neutrality
[02:12:03.180 --> 02:12:05.260]   when it comes to digital trade."
[02:12:05.260 --> 02:12:11.580]   He says the US negotiating team is focused on trying to get Canada to accept our version of
[02:12:11.580 --> 02:12:16.860]   intermediary protections online where ISPs and third parties like Facebook cannot be held
[02:12:16.860 --> 02:12:20.220]   legally responsible for the behavior of their customers.
[02:12:20.220 --> 02:12:25.180]   But Canadians prefer to leave the issue of the courts and out of a trade agreement.
[02:12:25.180 --> 02:12:31.580]   He says, Verhol says, "US negotiate team has not reacted positively to the Canadian pushback
[02:12:31.580 --> 02:12:32.380]   on net neutrality."
[02:12:32.380 --> 02:12:34.620]   - All right, let me say a couple of things if I may name.
[02:12:34.620 --> 02:12:35.100]   - Yes, man.
[02:12:35.100 --> 02:12:40.620]   - One, University of Maryland poll out, I think yesterday, said that 83% of Americans
[02:12:40.620 --> 02:12:42.540]   are in favor of keeping net neutrality.
[02:12:42.540 --> 02:12:47.180]   So this is by no means a political decision, just like the tax bill, I would argue, but
[02:12:47.180 --> 02:12:52.060]   especially here, the people don't want the 79% of Republicans want to keep net neutrality.
[02:12:52.060 --> 02:12:56.540]   This is an oligopoly. This is big companies ruling the country.
[02:12:56.540 --> 02:13:01.420]   And I'm sounding like I'm Bernie. I'm not. I'm a middle of the road guy in so many ways.
[02:13:01.420 --> 02:13:08.140]   But this is an indication of undemocratic governance, 0.1, 0.2.
[02:13:09.260 --> 02:13:13.180]   Ajit Pai is saying he has absolutely zero.
[02:13:13.180 --> 02:13:21.980]   He's not consistent in any way in his philosophy. He doesn't have any philosophy.
[02:13:21.980 --> 02:13:27.420]   So just like on the one hand, he's saying, the government is saying, no,
[02:13:27.420 --> 02:13:33.260]   CNN merger, but go ahead, Tribune by Trump.
[02:13:33.260 --> 02:13:38.540]   In this case, Ajit Pai is saying the phone companies in the ISP should be able to do whatever they want,
[02:13:38.540 --> 02:13:42.940]   whatever the heck they want. That's fine. However, then he turns around the next breath and he told
[02:13:42.940 --> 02:13:53.020]   Tucker Carlson last night that there ought to be a law investigation or something stopping Facebook
[02:13:53.020 --> 02:14:01.420]   and Google from disadvantaging conservative content. Well, free speech is about includes the right
[02:14:01.420 --> 02:14:05.260]   to edit includes the right to say what's hate speech and not to have that on your platform.
[02:14:05.980 --> 02:14:10.860]   But that's the that's the meme that's being put out there. And there's no consistency in any way
[02:14:10.860 --> 02:14:16.460]   between those two things. You say a guy named Jeff Jarvis on MSNBC said it all. He said,
[02:14:16.460 --> 02:14:23.580]   this is all about enabling the oligopoly of cable and the telephone to control the neti.
[02:14:23.580 --> 02:14:28.460]   Yeah. For those of you listening, I have a time he's wearing a black suit and tie.
[02:14:28.460 --> 02:14:35.900]   You look much nicer. Hey, hey, well, you dress up for Stephanie rule. You say,
[02:14:35.980 --> 02:14:40.700]   yeah, yeah, Stephanie. Yeah. By the way, she calls you one of her favorites.
[02:14:40.700 --> 02:14:44.380]   They gave one of our faves.
[02:14:44.380 --> 02:14:48.940]   You know, I almost don't want to bring this up because it's
[02:14:48.940 --> 02:14:53.980]   I don't think we can influence the vote at this point. I don't think there's much we can do.
[02:14:53.980 --> 02:15:00.700]   You still could call your Congress critter and should and you should because just who there
[02:15:00.700 --> 02:15:05.420]   was a Republican congressman who came out against it. So there's a couple things after this vote
[02:15:05.420 --> 02:15:14.700]   repeals it. There's then the process will happen again. We could have a lawsuit. We could find
[02:15:14.700 --> 02:15:23.100]   another case. You can also expect. I mean, it's possible that even it's a shame no one
[02:15:23.100 --> 02:15:29.180]   got Trump upset over this. And so Trump could tweet, you know, ah, I want the net to stay free
[02:15:29.180 --> 02:15:34.700]   because then you know, I just I would have to go around. Here's a there's not a lot to do.
[02:15:34.700 --> 02:15:39.260]   No, but you can do what the internet pioneers did. They wrote a a letter.
[02:15:39.260 --> 02:15:46.780]   Scaving letter. Scaving letter to members of the house and the Senate. We are writing to respectfully
[02:15:46.780 --> 02:15:54.060]   urge you to call on FCC chairman Ajapai to cancel the December 14th vote. We are the pioneers of
[02:15:54.060 --> 02:15:59.660]   technologies who created and now operate the internet, including Vince surf Steve Wozniak,
[02:16:01.740 --> 02:16:09.020]   Paul Vixie, Stephen Wolf, Ron Rivest. I mean, these are names you all know Ted Nelson, Susan Landab,
[02:16:09.020 --> 02:16:16.860]   Brewster, Kale. These are the Whitfield, Diffy Vernon, Vincent surf. The father of the internet,
[02:16:16.860 --> 02:16:21.740]   Tim Berners Lee, the creator of the worldwide web. Steve Bellivin who tweeted yesterday that
[02:16:21.740 --> 02:16:27.580]   that that neutrality is what enabled him to invent the web. He needed a permissionless
[02:16:27.580 --> 02:16:32.860]   thank you very much. Thank you. So people who say, Oh, you guys are out of touch.
[02:16:32.860 --> 02:16:38.460]   You know, we don't need net neutrality. We don't want more government regulation.
[02:16:38.460 --> 02:16:43.900]   Okay, don't believe us. But do you believe the people who invented and run the today's internet?
[02:16:43.900 --> 02:16:47.020]   Do you believe them? Because they seem unanimous.
[02:16:47.020 --> 02:16:52.460]   This is it, but this is a list of who's who. Boy is it.
[02:16:53.580 --> 02:17:00.300]   Unanimous in their contempt for what is happening tomorrow. Well, what a year it has been some good,
[02:17:00.300 --> 02:17:06.540]   some not so good. But I think we always have fun here on this weekend Google. And I do think
[02:17:06.540 --> 02:17:12.620]   that the conversations thanks to you to Jeff Jarvis, Stacy Higambotham are always fascinating,
[02:17:12.620 --> 02:17:17.420]   challenging, stimulating. So I want to just thank you. I'm very grateful to both of you.
[02:17:17.420 --> 02:17:22.780]   We I know I speak for Stacy, but she'll speak for herself for a second to say thank you. It's always
[02:17:22.780 --> 02:17:27.500]   a pleasure. Yeah, so we're a whole bunch of love doing the show every Wednesday 130 Pacific
[02:17:27.500 --> 02:17:35.580]   430 Eastern 21 30 UTC. Stacy, I hope you have a wonderful new year. I hope you guys do too as
[02:17:35.580 --> 02:17:43.740]   well. Yeah, and be safe, y'all be safe, drive safe. And of course we want you Stacy and everybody
[02:17:43.740 --> 02:17:50.060]   to come back for our all new episode first episode of the new year seven days from now.
[02:17:50.780 --> 02:17:56.060]   Thanks everybody. Thank you, Stacy. Thank you, Jeff. Happy new year, everybody. We'll see you next time.
[02:17:56.060 --> 02:17:56.700]   On this weekend.
[02:17:56.700 --> 02:18:07.020]   [Music]

