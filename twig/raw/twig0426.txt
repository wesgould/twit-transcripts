;FFMETADATA1
title=Vulnerable to Journalism
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=426
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.000]   It's time for Twig this week in Google. Wow, we have an international panel this week.
[00:00:04.000 --> 00:00:08.960]   Evan Marks from the UK, Jeff Jarvis. He's in Berlin and all the way from
[00:00:08.960 --> 00:00:14.480]   Tbilisi, Georgia. Mike Elgin talks with us about all the biggest news, the debate
[00:00:14.480 --> 00:00:20.640]   over Kaspersky anti-virus. Is it dangerous? Should you worry? Are they at fault?
[00:00:20.640 --> 00:00:24.800]   We'll talk about the relative IQs of all the voices since you won't believe
[00:00:24.800 --> 00:00:31.120]   who's the smartest and how dumb it turns out to be and why you should probably not
[00:00:31.120 --> 00:00:36.960]   Google how to rob a bank. That's all coming up next on Twig.
[00:00:36.960 --> 00:00:43.840]   Netcast you love from people you trust.
[00:00:43.840 --> 00:00:52.160]   This is Twig. Bandwidth for this week in Google is provided by CashFly,
[00:00:52.160 --> 00:00:55.360]   C-A-C-H-E-F-L-Y dot com.
[00:00:55.360 --> 00:01:07.680]   This is Twig. This week in Google, episode 426 recorded Wednesday, October 11th, 2017.
[00:01:07.680 --> 00:01:13.520]   Vulnerable to journalism. This week at Google is brought to you by the Ring Video Doorbell with Ring.
[00:01:13.520 --> 00:01:18.400]   You can see and talk to anyone at your door from anywhere in the world using
[00:01:18.400 --> 00:01:25.120]   your smartphone. It's like caller ID for your home. Go to Ring.com/Twig and get up to $150 off
[00:01:25.120 --> 00:01:31.120]   a Ring of Security Kit. And by Rocket Mortgage. From Quick and Loans, home plays a big role in
[00:01:31.120 --> 00:01:35.680]   your life. That's why Quick and Loans created Rocket Mortgage. It lets you apply simply and
[00:01:35.680 --> 00:01:40.080]   understand the entire mortgage process fully so you can be confident. You're getting the right
[00:01:40.080 --> 00:01:44.800]   mortgage for you. Get started at rocketmortgage.com/Twig.
[00:01:46.320 --> 00:01:49.600]   It's time for Twig. This week in Google is showing where we cover the latest news from the Google
[00:01:49.600 --> 00:01:54.480]   universe. Kevin Marks is going to join us in a few minutes. But right now, this is going to be a
[00:01:54.480 --> 00:02:01.280]   truly international show. Joining us from Berlin, Jeff Jarvis, he's there. What are you there for, Jeff?
[00:02:01.280 --> 00:02:06.080]   Good not it. The one effort which is the World Association of Newspapers, a conference. I'm just
[00:02:06.080 --> 00:02:09.440]   yummering at them. You love going to Germany though. This is like your favorite place to go.
[00:02:09.440 --> 00:02:13.600]   I actually like it. Yeah. Berlin, I like quite a bit. I feel very comfortable here oddly.
[00:02:13.600 --> 00:02:17.600]   And you were saying you had a little free time this afternoon. So you went to the Stazzy Museum.
[00:02:17.600 --> 00:02:24.480]   The East German Secret movies. Yeah. And all this talk we have that is at the advertising world
[00:02:24.480 --> 00:02:28.960]   as a surveillance state that just so trivializes what a real survey they want.
[00:02:28.960 --> 00:02:34.800]   Yeah. When you really get into it, what was the movie? There was a very good movie about the Stazzy.
[00:02:34.800 --> 00:02:40.480]   The lives of others. Lives of others. Very good movie. Shilling.
[00:02:41.440 --> 00:02:47.520]   Yeah. Also joining us, Mike Elgin. And you know, it's always a fun game to play with Mike Elgin.
[00:02:47.520 --> 00:02:52.160]   Where the hell is he? But this one, I only reason I know where you are, Mike, is because I follow
[00:02:52.160 --> 00:03:02.000]   you so closely on Instagram. He's in Georgia. He's also muted. The country. Yeah. Say that again.
[00:03:02.000 --> 00:03:07.200]   We muted you. The country of Georgia. Yeah. The country of Georgia. It's a fantastic country.
[00:03:07.200 --> 00:03:12.320]   And I've been out of the United States for quite a while. We just missed each other in France.
[00:03:12.320 --> 00:03:19.600]   I saw you fly by on the highway there near the coat de rose. And then we came out to Georgia.
[00:03:19.600 --> 00:03:25.200]   We've been living in Georgia for the last two weeks or so. You're in Tbilisi. Tbilisi, Georgia.
[00:03:25.200 --> 00:03:30.160]   Yeah. It's a fantastic place. We're next. It's a former Soviet Union.
[00:03:30.720 --> 00:03:34.560]   country. Oh, you going back to Italy? Oh, good. Going back to Italy, we're putting together both the,
[00:03:34.560 --> 00:03:40.560]   you know about the Barcelona experience, putting together the Prosecco experience and then the
[00:03:40.560 --> 00:03:44.880]   Provence experience. We're doing two in a row this summer. And it's going to be amazing. But
[00:03:44.880 --> 00:03:50.480]   we're going back to Italy to work on the Prosecco experience coming up. Gastronomad.net. If you
[00:03:50.480 --> 00:03:54.640]   want to find out what Mike and Amira do, you had you've already had your first in Barcelona,
[00:03:54.640 --> 00:03:58.080]   which looked from the pitch. You got the pictures and the photos. Yeah. That's it. It looked really
[00:03:58.080 --> 00:04:03.520]   great. Yeah. Yeah. All right. That was fantastic. All right. Prosecco coming up. Mike, make a quick
[00:04:03.520 --> 00:04:09.120]   question. Quick question for all that trouble. Do you ever get Oda Kumbat in the stomach because
[00:04:09.120 --> 00:04:15.360]   of the travel? Are you so well? Funny you should mention that. I had it a couple of days ago. We
[00:04:15.360 --> 00:04:22.320]   went to there was a big street festival in Tbilisi here in Tbilisi, where basically what the festival
[00:04:22.320 --> 00:04:27.360]   is is people come from all the different regions of the country into the city. They set up booths,
[00:04:27.360 --> 00:04:32.240]   they barbecue pork and all this other stuff. And then they have just outdoor eating all day for
[00:04:32.240 --> 00:04:38.880]   two days. And I felt a little bit, but it was totally worth it. I would do it again. If I had
[00:04:38.880 --> 00:04:45.280]   a chance. Yes. I think it's important to eat street food. So you build up a resistance to all of them.
[00:04:45.280 --> 00:04:49.280]   Normal street food. If you go to Mexico City or something and have street food,
[00:04:49.280 --> 00:04:53.920]   it's probably going to be at least as safe as the restaurants because when the street vendors
[00:04:53.920 --> 00:04:57.840]   are there all the time and they've been doing it for years and years, and it's usually good.
[00:04:57.840 --> 00:05:02.480]   Whenever it's a carnival type thing, people set up just once a year or something like that.
[00:05:02.480 --> 00:05:08.560]   You don't know how they're transporting things. Stay with the professionals. That's a good point.
[00:05:08.560 --> 00:05:12.400]   Right. All right. We've learned something today, I think.
[00:05:12.400 --> 00:05:18.560]   So last week we talked on and on about all the things Google had announced. And gosh knows,
[00:05:18.560 --> 00:05:22.400]   there was plenty to talk about. I don't even think we got through it all. So we have a big kind of
[00:05:22.400 --> 00:05:26.480]   Google News dump of a bunch of stuff that's been going on with Google. I'll start with Puerto Rico.
[00:05:26.480 --> 00:05:32.320]   As you know, tragedy going on in Puerto Rico right now in the aftermath of Hurricane Irma,
[00:05:32.320 --> 00:05:37.440]   three weeks later. And there's still no power in 85% of the country.
[00:05:37.440 --> 00:05:44.720]   Cell service is down in those areas. Hospitals are suffering. People are dying.
[00:05:45.280 --> 00:05:54.000]   But Google was given permission by the FCC this week to deploy those big project loon balloons
[00:05:54.000 --> 00:06:00.800]   for emergency connectivity in the wake of Hurricane Irma. And now I guess Maria too.
[00:06:00.800 --> 00:06:05.840]   Emergency LTE coverage to the island. That's kind of amazing.
[00:06:05.840 --> 00:06:12.960]   Yeah. The thing is a lot of people are talking about it. This is if it's a done deal. Unfortunately,
[00:06:12.960 --> 00:06:18.320]   it isn't. They have permission from the FCC. Now they have to establish partnerships with the
[00:06:18.320 --> 00:06:28.240]   carriers in Puerto Rico. They are carriers. And when they do get some sort of connectivity
[00:06:28.240 --> 00:06:33.920]   online with the carriers, then people have to actually install an update for their phones.
[00:06:33.920 --> 00:06:40.000]   So we're a ways away from this actually happening. The good news is they have plenty of paper towels
[00:06:40.000 --> 00:06:46.880]   and that's about it. In Puerto Rico. Yeah, I'm going to be in San Juan in a couple of months.
[00:06:46.880 --> 00:06:51.840]   And I just I don't know what I'm going to see there. And our heart goes out to people.
[00:06:51.840 --> 00:06:55.920]   Yeah. I was supposed to go there for a conference in November and they moved it to Miami. And I
[00:06:55.920 --> 00:06:59.520]   just feel bad that the island is losing business. Well, that's why I still want to go there. We,
[00:06:59.520 --> 00:07:04.480]   you know, we were I was thinking of canceling. We were going on a taking my son on a sailing trip
[00:07:04.480 --> 00:07:11.040]   in the Virgin Islands, which also needs support. And we start we fly to San Juan. We go to Tortola.
[00:07:11.040 --> 00:07:15.360]   And then he wanted to spend a week in San Juan afterwards. And at first, I was going to say,
[00:07:15.360 --> 00:07:19.040]   well, I don't think there'll be any infrastructure. But as long as they'll let us, we'll go if we
[00:07:19.040 --> 00:07:23.920]   need to build things, whatever it is. So I think that's really cool. I'll yeah, forward to that.
[00:07:23.920 --> 00:07:30.320]   So what about the electric infrastructure with Elon? And that was the other thing. And I now
[00:07:30.320 --> 00:07:35.200]   this one may be real pie in this guy, but isn't it funny how Puerto Rico's suffering with this,
[00:07:35.200 --> 00:07:40.320]   but the science fiction future is is ready to come in. Elon Musk says, you know, if you're going
[00:07:40.320 --> 00:07:45.120]   to rebuild the electric infrastructure, which apparently they have to do, you really ought to do
[00:07:45.120 --> 00:07:53.760]   it with solar and giant batteries. And he's talked to the governor. And there's apparently some
[00:07:53.760 --> 00:07:59.520]   interest. I don't know how far along it is or whether I doubt Tesla has the money to do this on their
[00:07:59.520 --> 00:08:02.080]   own. But it will be
[00:08:02.080 --> 00:08:07.440]   And Puerto Rico has no money. Yeah. Well, they got but they have 77 million, I think, to rebuild the
[00:08:07.440 --> 00:08:12.080]   power infrastructure, at least this is seed seed money from the from the federal government. So
[00:08:12.080 --> 00:08:18.400]   remember, Puerto Rico is is America. Just remind everybody. It is
[00:08:18.400 --> 00:08:21.920]   It's official status. It's a territory. It's a territory. Yeah.
[00:08:21.920 --> 00:08:22.640]   Territory. Yeah.
[00:08:23.760 --> 00:08:31.120]   Yeah. So but it's America. So just as the American Virgin Islands are in America. So one would hope
[00:08:31.120 --> 00:08:36.080]   that the federal resources will go in there and they can and they can get it rebuilt. But right now
[00:08:36.080 --> 00:08:42.000]   it's just in crisis. I can't imagine. I mean, no power and and still don't worry water. We
[00:08:42.000 --> 00:08:46.000]   know no fresh water rather in these places. How do you survive? How did that Jesus? I don't know.
[00:08:46.000 --> 00:08:51.200]   I don't know. They need to get more people over there. Meanwhile, we have had a kind of close call
[00:08:51.200 --> 00:08:56.560]   up here in Northern California to and I can't I think a little bit of a better understanding of how
[00:08:56.560 --> 00:09:03.040]   you could talk about federal aid, but ultimately you're kind of alone when this stuff happens. And
[00:09:03.040 --> 00:09:08.720]   technology is not a savior. So we have these big fires about 10 miles away in the wine country.
[00:09:08.720 --> 00:09:12.880]   I know Mike's very familiar with the areas that are burning some of our favorite wineries too.
[00:09:12.880 --> 00:09:19.200]   But a couple of things. First of all, during the first few days of the crisis,
[00:09:19.200 --> 00:09:23.280]   it was very hard to get any information at all. You just really didn't know what was going on
[00:09:23.280 --> 00:09:27.360]   or where the fires were. In fact, one of the reasons I think so many people died and I think many
[00:09:27.360 --> 00:09:34.320]   more are going to be discovered dead is because it happened so quickly and there was very little
[00:09:34.320 --> 00:09:39.920]   communication infrastructure. We've started to rely on cell phones for emergency alerts and they
[00:09:39.920 --> 00:09:44.960]   weren't working. They went out right away. There's no there used to be when when you were a kid,
[00:09:44.960 --> 00:09:52.320]   did you have a whistle, an air raid siren? Yeah, the noon whistle. We never knew we have we
[00:09:52.320 --> 00:09:56.240]   would I wouldn't have known what you're supposed to do. You heard it at midnight. You might want
[00:09:56.240 --> 00:10:00.560]   at least get up and go what's going on. Well, that's the point is we've let this kind of old
[00:10:00.560 --> 00:10:05.920]   fashion infrastructure die relying on technical infrastructure that died without immediately.
[00:10:05.920 --> 00:10:12.960]   And they actually have some of that infrastructure still around. I'm not sure if it's connected. I
[00:10:12.960 --> 00:10:18.480]   noticed I was in Los Angeles about about eight months ago and I saw this tower with a weird
[00:10:18.480 --> 00:10:21.840]   thing. I'm like, what is that? I kind of looked it up and it was an air raid sign.
[00:10:21.840 --> 00:10:26.800]   Right in the middle of like, you know, a posh area of LA and there there was just this.
[00:10:26.800 --> 00:10:31.680]   They didn't use that again now. Well, they are a ring the church bells or something because
[00:10:31.680 --> 00:10:37.200]   what happened was it had sprung up at midnight. People didn't know some people Denver woke up.
[00:10:37.200 --> 00:10:42.560]   Some people got out the skin of their teeth because they were and they ran. I mean,
[00:10:42.560 --> 00:10:48.960]   they literally had to run to get away and moves very fast. It isn't over here because tonight,
[00:10:48.960 --> 00:10:54.000]   we're expecting high winds again and read what they call red flag conditions, which are very
[00:10:54.000 --> 00:10:59.680]   high fire danger conditions all in this snowman, Napa and Menasino and Sassoon County. So it's
[00:10:59.680 --> 00:11:06.240]   it may not be. I saw a CBS report here from the BBC and it was this downtown Santa Rosa. I mean,
[00:11:06.240 --> 00:11:12.080]   it's just just devastating downtown, but very nearby. There's a there's an area a little north
[00:11:12.080 --> 00:11:16.320]   of Santa Rosa where the interestingly, the county courthouse, the county seat is the county jail
[00:11:16.320 --> 00:11:22.320]   and a bunch of beautiful homes, the Kaiser Hospital. Many of the beautiful homes up in the
[00:11:22.320 --> 00:11:28.240]   Fatemgrove area burned golf course, Silverado golf course, the homes around that, but also
[00:11:28.240 --> 00:11:33.040]   many trailer parks and just it's just it's devastation. If you look at it, I've never seen
[00:11:33.040 --> 00:11:38.400]   anything like it. It's a moonscape. This was such a fast moving hot fires that everything just
[00:11:38.400 --> 00:11:44.720]   was flattened. And of course, we have employees who have been who are up there waiting to hear
[00:11:44.720 --> 00:11:50.000]   if they're evacuated. We have many friends who have been evacuated, some have lost their houses.
[00:11:50.000 --> 00:11:55.360]   There are shelters all around Petalomo that are set up and for the most part full at this point.
[00:11:55.360 --> 00:12:00.160]   And Airbnb opened up the volunteer rooms for free. I think that was great. There's a
[00:12:00.160 --> 00:12:05.360]   there. You know, it is what is great is you don't see, I don't know where the firefighters are
[00:12:05.360 --> 00:12:09.040]   obviously very busy. Right now they're trying to save lives, not properties. So the fires are
[00:12:09.040 --> 00:12:16.160]   burning uncontained. But you don't see I don't see a lot of tanker planes. I think the big 747
[00:12:16.160 --> 00:12:21.520]   tanker plane is supposedly here. But what you do see is people is the community.
[00:12:21.520 --> 00:12:28.000]   And another reminder that we think, oh, the government will come and save us. It's the people
[00:12:28.000 --> 00:12:32.560]   on the ground. We went we went over the other day yesterday with blankets and pillows. They
[00:12:32.560 --> 00:12:36.240]   needed them at the shelter. And they were just a constant stream of people going in
[00:12:36.240 --> 00:12:41.600]   bringing stuff to the point where they said, OK, no more. We have a friend. We got too much.
[00:12:41.600 --> 00:12:48.640]   Well, you know, a friend of mine, Leo, has a newish cafe called the pharmacy in Santa Rosa.
[00:12:48.640 --> 00:12:55.360]   And it's an exquisite place. The food is amazing. But she's just giving away food and coffee. And
[00:12:55.360 --> 00:12:59.840]   she's announced on Instagram. She's given it away until it's gone. A lot of the rest of
[00:12:59.840 --> 00:13:04.880]   the rest around here doing that. Yep. It's so neat. That's where, you know, so,
[00:13:04.880 --> 00:13:09.280]   you know, you can talk about FEMA. You can talk about the National Guard. You can talk about,
[00:13:09.280 --> 00:13:15.280]   you know, all of this. But ultimately, the community steps up. And thank goodness, it's not
[00:13:15.280 --> 00:13:20.560]   unlike Puerto Rico, which was the devastation was universal. Here, it's just a small pockets.
[00:13:20.560 --> 00:13:26.480]   We're safe, by the way, if case anybody cares, the studio and the pedaloma area are currently
[00:13:26.480 --> 00:13:31.200]   not under threat. One of the strange things about this that I haven't heard mentioned,
[00:13:31.200 --> 00:13:38.080]   of course, obviously, the safety and the loss of life is and property is the biggest thing.
[00:13:38.080 --> 00:13:43.600]   But this is the wine country. It's affecting the three major counties for wine production,
[00:13:43.600 --> 00:13:52.160]   Napa, Sonoma, and Mendocino. And this is going to affect wine for years. The wine will actually retain
[00:13:52.160 --> 00:14:01.840]   tastes and stuff from the fire for several years. Oh, no. And yeah, and in California, of course,
[00:14:01.840 --> 00:14:06.720]   a huge exporter of wine. So this is, you know, California wine is going to be different for a while.
[00:14:08.080 --> 00:14:14.800]   Well, it's good news for Tbilisi. Yeah. The Georgians are happy. I didn't realize this,
[00:14:14.800 --> 00:14:20.560]   but you said this is where wine was invented. You go downtown in downtown Tbilisi, Leo, there's
[00:14:20.560 --> 00:14:27.040]   literally at least one wine store on every block. And there's one, there's one block where there
[00:14:27.040 --> 00:14:32.560]   are four wine stores next to each other in a row. There's wine stores everywhere. It's amazing.
[00:14:32.560 --> 00:14:38.000]   Wow. Wow. Google has acquired a company. I liked a lot and used to listen to a lot
[00:14:38.000 --> 00:14:45.760]   we Liz Gaines was one of the people there. We've had her on the show. She worked for 60 DB. It was a
[00:14:45.760 --> 00:14:52.640]   company founded a couple of years ago to rethink how radio works. And it was a great way to listen to
[00:14:52.640 --> 00:14:57.520]   some people. I mean, that's coming is calling a podcast app. I'm not sure that's that's fair to
[00:14:57.520 --> 00:15:01.840]   it. It was much more than that. But Google bought the company and will be shutting down
[00:15:02.960 --> 00:15:08.400]   the service next month was founded by a radio reporter Steve Han to Netflix veterans,
[00:15:08.400 --> 00:15:13.120]   John C. and Cootie and Steve McLennan. All of them will be going to Google,
[00:15:13.120 --> 00:15:22.560]   is we going to Google, but not the service anymore. And fast company says Google's purchase of 60 DB
[00:15:22.560 --> 00:15:26.160]   seems to imply they're taking the whole podcasting thing a bit more seriously now,
[00:15:26.160 --> 00:15:32.080]   which is great. Yeah, I this was a surprise from the New York Times. I don't know if this is true.
[00:15:32.080 --> 00:15:38.560]   It's not true for us, but it's according to New York Times, 65. I'm sorry, what was it not 65 85?
[00:15:38.560 --> 00:15:45.680]   No, 65% of podcasts go through Apple's built in iPhone app. That is not true for us. I think
[00:15:45.680 --> 00:15:52.720]   iTunes and iPhone podcast app are below 50%. But it's still a big chunk of it. And so I make
[00:15:52.720 --> 00:15:57.520]   sense that Google might try to muscle in on some of that business. And it's kind of good that
[00:15:57.520 --> 00:16:03.360]   I hate to dance on the grave. It's not really a grave that being acquired. But this was an
[00:16:03.360 --> 00:16:08.160]   alternative to podcasting in a way it was. Yeah, you could listen to podcasts through it, but
[00:16:08.160 --> 00:16:12.000]   you're right. It was more like you would listen to this instead of podcasts, right? Right. And we
[00:16:12.000 --> 00:16:16.880]   don't need podcasting forking into these different platforms. I love to see everything being poured
[00:16:16.880 --> 00:16:22.240]   into the standards for podcasting so that you can get a pod catcher and you can listen to the
[00:16:22.240 --> 00:16:27.280]   podcast you want and keep it that way. So I think it's kind of a good thing. And I hope
[00:16:27.280 --> 00:16:31.200]   that Google getting serious about podcasting and it'll also light a fire under Apple because I
[00:16:31.200 --> 00:16:35.760]   think they don't take podcasting and seriously as they do music and other things. So hopefully
[00:16:35.760 --> 00:16:43.440]   we'll see a lot more effort being put into podcast promoting podcasts. I personally think
[00:16:43.440 --> 00:16:50.080]   that radio and TV should just go away and it should all be replaced by podcasts. I think the
[00:16:50.080 --> 00:16:54.240]   world would be. I like that. Although then as somebody pointed out in the chat room, one of the
[00:16:54.240 --> 00:16:59.600]   reasons these environmental crises are problems because nobody has TV anymore. They're not and
[00:16:59.600 --> 00:17:05.600]   radio anymore. They're not getting the emergency action. What do they call EAS notifications anymore?
[00:17:05.600 --> 00:17:12.960]   Again, all of these systems that we used to have remember, do you remember? I guess this is really
[00:17:12.960 --> 00:17:20.800]   betrays my age, but AM radios used to have a civil defense symbol on the on the band on the dial
[00:17:20.800 --> 00:17:25.040]   in the AM radio. Am I imagining this? And that would be I think that sounds right. Yeah, it's where
[00:17:25.040 --> 00:17:31.280]   you'd go. If there were an atomic attack, a nuclear attack on the country, you'd dial to the civil
[00:17:31.280 --> 00:17:40.800]   defense frequency. And all the radios had these. Mike, you listen to radio radio.
[00:17:42.080 --> 00:17:48.640]   Well, remember, I do a radio show. I know that. Besides your own show,
[00:17:48.640 --> 00:17:53.920]   in terms of saying the car.
[00:17:53.920 --> 00:18:01.760]   You know what? I'll tell you when I listen to radio. Now that you ask, I don't, you're right,
[00:18:01.760 --> 00:18:06.320]   I don't listen to a lot of radio. But I did during the fires, we tune in the local news radio station.
[00:18:06.320 --> 00:18:11.840]   It was the only source of information. So there you go. That's one of the reasons you've got to
[00:18:11.840 --> 00:18:16.400]   keep this stuff around. I hope there's local reports on the other.
[00:18:16.400 --> 00:18:21.040]   It's funny because we also have here, uh,
[00:18:21.040 --> 00:18:26.960]   cron channel four, which used to be an NBC affiliate, lost its NBC affiliation about 10 years ago.
[00:18:26.960 --> 00:18:32.240]   And so they've been really feisty trying to do local news. And they were the station to go to
[00:18:32.240 --> 00:18:37.280]   because they were they had reporters all over the area. And many of them were either very young.
[00:18:37.280 --> 00:18:41.760]   It was one reporter. I swear I got you was 16. But but they did a really good
[00:18:41.760 --> 00:18:45.520]   job. And it just showed you there. You know, there are a lot of people, you know,
[00:18:45.520 --> 00:18:48.560]   you teach these kids all the time. There are a lot of people want to be journalists.
[00:18:48.560 --> 00:18:52.000]   And I just, I will hope there's still places for them to go.
[00:18:52.000 --> 00:18:57.600]   Connell Rad. That's what it was called. Here's a Connell Rad. Here's a car radio.
[00:18:57.600 --> 00:19:04.160]   So my God, I think it's from Mad Max's car there. But there's this.
[00:19:04.160 --> 00:19:05.360]   So you dig this out of a ditch.
[00:19:08.240 --> 00:19:13.280]   So a little rusty. It is a relic, but God, it's in my memory.
[00:19:13.280 --> 00:19:19.040]   See those red triangles there. Those that's those are the Connell Rad frequencies that you go to
[00:19:19.040 --> 00:19:24.240]   in case we get attacked. We might want to bring that back.
[00:19:24.240 --> 00:19:27.040]   Oh, Jesus.
[00:19:27.040 --> 00:19:37.680]   Si. Let's see. What else is oh, Google says us too. I love this. So Facebook and Twitter both
[00:19:37.680 --> 00:19:43.040]   came forward and congressional inquiry. Yes, the Russian spot ads. Here's the ads. Google.
[00:19:43.040 --> 00:19:49.600]   Amazing has discovered that Russian operatives spent tens of thousands of dollars on YouTube,
[00:19:49.600 --> 00:19:55.360]   Gmail and Google search ads in an attempt to affect the 2016 election.
[00:19:55.360 --> 00:19:59.680]   Google actually, I'm sorry, Russia actually, I'm sorry, go ahead, Jeff.
[00:19:59.680 --> 00:20:01.520]   No, go ahead, Mike.
[00:20:01.520 --> 00:20:05.920]   Yeah, we got the here's the problem here, folks. Both of these guys are about 10 seconds behind.
[00:20:05.920 --> 00:20:09.520]   So Mike, then Jeff, Mike and Jeff.
[00:20:09.520 --> 00:20:18.800]   So the Russians actually hired people, YouTube personalities to, I guess, spread its propaganda.
[00:20:18.800 --> 00:20:19.840]   Those were the worst.
[00:20:19.840 --> 00:20:26.560]   Yeah. I mean, and it was all about sewing divisions, the social divisions within the United States.
[00:20:26.560 --> 00:20:30.640]   It wasn't about electing one candidate or another. In this case, it was about
[00:20:31.920 --> 00:20:35.840]   exacerbating existing racial tension within the US.
[00:20:35.840 --> 00:20:41.040]   I would love to play with for you some of this, these black divists is one of the accounts.
[00:20:41.040 --> 00:20:44.240]   They had people pretending to be
[00:20:44.240 --> 00:20:53.920]   African Americans in the United States. They were clearly not. They're laying, I don't think,
[00:20:53.920 --> 00:20:59.280]   I think they've all been pulled down since saying, I hate Hillary Clinton. She's a bad person.
[00:21:00.000 --> 00:21:06.080]   I am more than Trump. And it was so blatant. I don't think, in fact, most of them had very few views.
[00:21:06.080 --> 00:21:13.280]   But there were a number of these accounts purchased by the Russians.
[00:21:13.280 --> 00:21:16.720]   The fun. Now, go ahead, Jeff, because I think I know what you're going to say about the funniest
[00:21:16.720 --> 00:21:21.360]   thing about this story. Go ahead. That Facebook found the accounts.
[00:21:21.360 --> 00:21:25.040]   Twitter didn't really do any work and gotten trouble with Congress because they just went to the
[00:21:25.040 --> 00:21:31.360]   accounts that Facebook found. And then Google didn't fully do it. They used Twitter to figure
[00:21:31.360 --> 00:21:35.520]   out where the accounts were. Oh, that's hysterical. And my favorite, this is the one I was going to
[00:21:35.520 --> 00:21:40.640]   say is the fun one. And then Microsoft said, oh, we better check to see if they bought anything
[00:21:40.640 --> 00:21:43.600]   on Bing. So far now.
[00:21:43.600 --> 00:21:52.400]   Oh, poor Microsoft. Poor Microsoft. They can't even get the Russian, the Russian dollars.
[00:21:53.600 --> 00:21:59.600]   My other favorite story. I can't find it right now. I got him the silly get off who's speaking here.
[00:21:59.600 --> 00:22:04.960]   He was an expert in Russian stuff because he's Russian. Had this great story that there was fake
[00:22:04.960 --> 00:22:11.440]   news in Russia of a Putin cheeseburger that supposedly a New York restaurant named Lucy's
[00:22:11.440 --> 00:22:16.640]   right near Penn Station, which I've eaten at, had an honor of Putin. And some reason had this gigantic
[00:22:16.640 --> 00:22:22.080]   cheeseburger for Putin. And they called the restaurant and somebody who supposedly worked there said,
[00:22:22.080 --> 00:22:26.720]   Oh, yes, we are on a read Putin with his cheeseburger. Lord. And they, you know, what great lengths to
[00:22:26.720 --> 00:22:30.720]   do it until finally a reporter of nowhere called and said, Do you have a Putin cheeseburger?
[00:22:30.720 --> 00:22:37.760]   They said, what? What are you talking about? Is Lucy's where you and Lisa and I and Gina
[00:22:37.760 --> 00:22:41.760]   Trapani went and we had delicious burgers? I think that was Lucy's. No, no, that's.
[00:22:41.760 --> 00:22:47.440]   No, it was around the corner. Oh, okay. Not so delicious. Okay. Why did you take me to the not
[00:22:47.440 --> 00:22:53.200]   so delicious place? No, no, no, Lucy's is not so delicious. I'd hate you to go live the best.
[00:22:53.200 --> 00:22:57.040]   Thank you. It was a fine burger. I do remember it very well.
[00:22:57.040 --> 00:23:09.840]   Little word of warning if you can't really trust what you see on the Chrome store. I think Google
[00:23:09.840 --> 00:23:19.200]   has fixed this, but about 37,000 Chrome users downloaded a fake ad blossom ad block plus extension.
[00:23:19.200 --> 00:23:28.080]   Google has taken it down. Swift on security tweeted about it. The fabulous Taylor Swift account.
[00:23:28.080 --> 00:23:34.400]   But the fake according to Swift on security, the fake extension was created by a fraudulent
[00:23:34.400 --> 00:23:40.560]   developer who clones popular names and spams keywords, you know, ad block plus very popular
[00:23:40.560 --> 00:23:46.720]   ad blocking extension. And I guess since the name was ad block plus, I wouldn't be surprised
[00:23:46.720 --> 00:23:52.560]   that people were fooled. According to one of the reviewers of the fake Chrome extension,
[00:23:52.560 --> 00:23:56.880]   he started getting invasive ads that opened lots of tabs after he installed it exactly the
[00:23:56.880 --> 00:24:02.960]   opposite of why you install ad block plus, of course. Google has removed it. But the point is,
[00:24:02.960 --> 00:24:08.560]   I don't think I don't know how good their verification process is. If something like that could
[00:24:08.560 --> 00:24:16.240]   sneak through. So care, you know, my new rule. I've been saying it a lot. Don't install anything.
[00:24:16.240 --> 00:24:21.680]   You don't absolutely want need and be careful when you do. It's when you install stuff on your
[00:24:21.680 --> 00:24:27.200]   system that you get in trouble. And that leads us to the Kaspersky story.
[00:24:29.200 --> 00:24:34.800]   Do we have is Kevin still out there? Or is he is not responding? All right, we may we may just
[00:24:34.800 --> 00:24:42.400]   forget Kevin. I mean, we have enough countries. We've got Georgia. We've got Germany. Do we really
[00:24:42.400 --> 00:24:49.200]   need England? It would be kind of fun. So the good always be there, the good, the always be in
[00:24:49.200 --> 00:24:58.320]   England. No, I think it's always the always be a Paris. The the sad story gets stranger and
[00:24:58.320 --> 00:25:05.120]   stranger. It started with a Wall Street Journal report last week that an NSA contractor had taken
[00:25:05.120 --> 00:25:13.600]   work home. By the way, that's a really big red flag taken his work home and put it on his home
[00:25:13.600 --> 00:25:22.720]   computer. He was running according to the journal, the Kaspersky anti virus program and Kaspersky
[00:25:24.240 --> 00:25:31.440]   intentionally or not, it's not clear. Notified Russia that there were NSA secrets on this computer
[00:25:31.440 --> 00:25:38.560]   and the Russians were able to then exfiltrate those NSA secrets. The question that remains is
[00:25:38.560 --> 00:25:46.240]   what was Kaspersky's involvement in this? And you may remember that the Department of Homeland
[00:25:46.240 --> 00:25:50.560]   Security a few months ago said that no government agencies should be running Kaspersky.
[00:25:52.080 --> 00:25:56.800]   Kaspersky, you know Eugene Kaspersky. Jeff, you've been on a panel with him. He's a very like about
[00:25:56.800 --> 00:26:00.960]   follow-up. I've met him. I've run a panel with a very, very affable fellow and apparently
[00:26:00.960 --> 00:26:10.160]   one would believe very frank about security. Yeah. The journal says that there's evidence that
[00:26:10.160 --> 00:26:17.840]   in fact Kaspersky was involved, but not concrete evidence. So among others.
[00:26:17.840 --> 00:26:22.240]   They're saying that it's saying could only have been made with the company's knowledge.
[00:26:22.240 --> 00:26:28.560]   This is one person quoted by. Unnamed official with knowledge of the information.
[00:26:28.560 --> 00:26:33.360]   Yeah. Right. But that phrase doesn't make any sense. Companies don't have knowledge.
[00:26:33.360 --> 00:26:38.400]   Individual employees have knowledge and you don't know whether
[00:26:38.400 --> 00:26:43.760]   could this have been done with one insider, a few insiders. Could they have been bribed?
[00:26:43.760 --> 00:26:48.560]   Were they were they moles? Did Russia have them be hired? Was it a long term thing? Short term thing?
[00:26:48.560 --> 00:26:55.600]   Was it? Did they were they hacked? Like they just because it requires somebody on the inside
[00:26:55.600 --> 00:27:01.840]   doesn't mean that Kaspersky is a company or that their CEO and founder had any knowledge.
[00:27:01.840 --> 00:27:08.160]   It also is possible that they did. So I just at this point, we there are so many unknowns that
[00:27:08.160 --> 00:27:15.200]   it's impossible to to really understand to what extent Kaspersky is a spy agents, you know, wing of
[00:27:15.200 --> 00:27:20.720]   the. Well, we do know a few things. We know that Kaspersky has written software for the FSB,
[00:27:20.720 --> 00:27:26.960]   the Russian secret police, that they have done contract work for the Russian government. Eugene
[00:27:26.960 --> 00:27:32.640]   Kaspersky says, yeah, that's but that's not. We also know that Putin is exerts a lot of influence
[00:27:32.640 --> 00:27:40.240]   over Russian companies. We also know that antivirus software just by its very nature kind of opens
[00:27:40.240 --> 00:27:45.440]   vulnerabilities in a way in your system. You have to really trust your antivirus software because
[00:27:45.440 --> 00:27:50.960]   because of the nature of the way it works and how deeply into the system it goes, it puts its hooks.
[00:27:50.960 --> 00:27:58.160]   It could it had and we've seen this happen. It could be if it's poorly written a venue for exploits
[00:27:58.160 --> 00:28:02.320]   to get into your system. And antivirus can actually make your system less secure. In fact, I don't
[00:28:02.320 --> 00:28:07.360]   recommend people use antiviruses. But at this point, I would very much not recommend anybody use Kaspersky,
[00:28:07.360 --> 00:28:15.280]   whether it's Kaspersky's fault or not. Interestingly, the German federal cyber agency BSI says there's
[00:28:15.280 --> 00:28:21.600]   no evidence that Kaspersky was used by Russian hackers. There are no plans to warn against the
[00:28:21.600 --> 00:28:26.800]   use of Kaspersky products in Germany since the BSI has no evidence for misconduct by the company
[00:28:26.800 --> 00:28:33.440]   or weaknesses in its software. That seems like a dangerous thing to say. The Israelis say,
[00:28:33.440 --> 00:28:40.480]   "Well, no, wait a minute. We hacked Kaspersky months ago and we warned the US that Kaspersky was
[00:28:40.480 --> 00:28:46.000]   responsible for exfiltrating this data. This is crazy."
[00:28:46.000 --> 00:28:55.760]   Adding to the craziness is the is the and again, we don't know anything about where this came from.
[00:28:55.760 --> 00:29:00.160]   Here's just, I don't believe this is true. I have no evidence. I haven't even heard this or read this,
[00:29:00.160 --> 00:29:08.160]   but just as a point of devil's advocacy, it's possible. Imagine if the NSA or another agency
[00:29:08.160 --> 00:29:14.640]   or Israel or somebody were able to infiltrate an American antivirus program that you wanted to be
[00:29:14.640 --> 00:29:21.280]   used in Russia. One way to get that to be used would be to compromise the Russian antivirus so that
[00:29:21.280 --> 00:29:26.880]   people... Kaspersky is probably the leading antivirus globally, isn't it?
[00:29:26.880 --> 00:29:32.080]   I think that I read that there's... What was the number? It was a very large number of installed
[00:29:32.080 --> 00:29:37.360]   users. What was the brand of old? McAfee?
[00:29:37.360 --> 00:29:44.160]   If you are going to hack McAfee, don't hack Kaspersky. Don't hack the Russian company.
[00:29:44.160 --> 00:29:49.520]   It was what I was not exactly as normal as Mr. Kaspersky.
[00:29:50.720 --> 00:29:55.440]   I, for some reason, I want to say 400 million users. That can't possibly be right, but it is
[00:29:55.440 --> 00:29:59.040]   certainly very popular. It's one Devorak recommended for a decade.
[00:29:59.040 --> 00:30:02.320]   400 million is the number. It is 400 million. That's astounding.
[00:30:02.320 --> 00:30:05.120]   I have one recommendation, people, and you know what it is.
[00:30:05.120 --> 00:30:06.800]   What? Chrome.
[00:30:06.800 --> 00:30:09.040]   Chrome. Oh, Chromebook.
[00:30:09.040 --> 00:30:10.080]   Chromebook.
[00:30:10.080 --> 00:30:11.200]   You don't need an antivirus.
[00:30:11.200 --> 00:30:14.480]   Well, I would submit you don't need an antivirus on any system anyway.
[00:30:14.480 --> 00:30:19.760]   This just goes back to me saying don't install anything you don't absolutely have to have.
[00:30:19.760 --> 00:30:23.120]   There's no evidence that any virus makes you more secure and there's a lot of evidence that
[00:30:23.120 --> 00:30:27.920]   makes you less secure. Whatever the name. But certainly at this point, if I were using Kaspersky,
[00:30:27.920 --> 00:30:34.800]   I would uninstall it. The company says, Kaspersky says, "Kaspersky Lab, should I do it in a Russian
[00:30:34.800 --> 00:30:40.160]   accent?" No, I won't do that. That would be mean. Kaspersky Lab was not involved in it,
[00:30:40.160 --> 00:30:45.360]   does not possess any knowledge of the situation in question. The company reiterates its willingness
[00:30:45.360 --> 00:30:50.000]   to work alongside US authorities to address any concerns they may have about its products as well
[00:30:50.000 --> 00:30:59.440]   as its systems. On the other hand, the government of Israel said they alerted in 2014 the US that
[00:30:59.440 --> 00:31:05.520]   Kaspersky software was being used to find American intelligence information. This Israeli's owns
[00:31:05.520 --> 00:31:13.040]   computer hackers penetrated Kaspersky Labs networks in 2014. So they were the Israelis were
[00:31:13.040 --> 00:31:19.200]   spying on the Kaspersky and the Kaspersky's were spying on us. Once inside the Israelis discovered
[00:31:19.200 --> 00:31:24.880]   how the software is being used and how Russia had obtained classified information from the NSA
[00:31:24.880 --> 00:31:31.440]   after the Israelis passed along what they knew to the US officials at the NSA began an
[00:31:31.440 --> 00:31:35.680]   investigation that led to the contractor who would install Kaspersky software on his personal
[00:31:35.680 --> 00:31:39.840]   computer at home. People familiar with that. This is the Wall Street Journal. People with
[00:31:39.840 --> 00:31:44.240]   familiar with that investigation say he appeared to have no ill intent, but of course he knew that
[00:31:44.240 --> 00:31:50.320]   removing classified material from Fort Meade was a violation of agency rules and possibly a crime.
[00:31:50.320 --> 00:31:56.240]   So now we at least know why the DHS banned federal government agencies from using Kaspersky
[00:31:56.240 --> 00:32:01.200]   last month. That's the other that's the information that they were working on.
[00:32:01.200 --> 00:32:07.680]   22 government agencies were authorized to use Kaspersky. It's also of course widely used
[00:32:08.240 --> 00:32:17.520]   by consumers. Yeah, we may we may never know whether Kaspersky was knowing or that's what's not clear
[00:32:17.520 --> 00:32:24.480]   whether they were willing knowing pawn or an unwitting pawn of the Russian government. But we do,
[00:32:24.480 --> 00:32:32.000]   I think from this, it seems pretty clear that it was an avenue for getting into somebody's system.
[00:32:32.880 --> 00:32:38.880]   How does Kaspersky recover from something like this? I mean, this is just you can't have this kind
[00:32:38.880 --> 00:32:43.360]   of reputation in this business. Well, especially since there are many competitors who are just
[00:32:43.360 --> 00:32:47.280]   as good and there's no compelling reason to go with Kaspersky if you want an antivirus.
[00:32:47.280 --> 00:32:55.760]   You know, there's nothing requiring you to use Kaspersky. I would not use an antivirus, but.
[00:32:55.760 --> 00:33:02.560]   Yeah. So this is Dan Gooden writing in ours. Technica, this is also a recent
[00:33:02.560 --> 00:33:10.880]   new report Kaspersky reportedly modified its AV to help Russia steal NSA secrets. But I'm with you,
[00:33:10.880 --> 00:33:19.680]   Mike, we don't know for sure. But I also think it'd be foolish to use Kaspersky.
[00:33:19.680 --> 00:33:28.080]   If we take this at face value, if the Putin government is using this to hack the NSA and in
[00:33:28.080 --> 00:33:33.600]   the wake of revelations of all the ads and meddling with the Mark sales, is this got to be generally
[00:33:33.600 --> 00:33:40.160]   backfiring for brand Russia? Isn't it? I mean, wouldn't Russia prefer to be a trusted partner
[00:33:40.160 --> 00:33:44.720]   to be, you know, I mean, this is like Russia is in like every story these days.
[00:33:44.720 --> 00:33:47.840]   What do you think? What do you think? That's a good question, Jeff. What do you think?
[00:33:47.840 --> 00:33:53.920]   Some say that Putin loves all his attention because the truth is Russia's economy is smaller
[00:33:53.920 --> 00:34:00.800]   than Italy's. It isn't really a big nation, big power. It's not one of the top powers anymore.
[00:34:00.800 --> 00:34:06.800]   It does have nuclear weapons, but that Putin likes the fact that people fear and respect Russia,
[00:34:06.800 --> 00:34:10.400]   that this is a good thing for Russia. What do you think? So I read a
[00:34:10.400 --> 00:34:16.320]   read an interview with this guy, Vasili Khatov, who I'm speaking after tomorrow here in Berlin.
[00:34:16.320 --> 00:34:22.320]   I had coffee with him this afternoon. A fascinating guy, former media executive in Russia,
[00:34:22.320 --> 00:34:29.520]   now a USC fellow. And the analysis he gave, I think was critical, which was that Russia's been
[00:34:29.520 --> 00:34:36.880]   invaded often, never defeated, except the notion that it lost the Cold War.
[00:34:36.880 --> 00:34:44.480]   And that's what greats. That's what they can't stand. And that's why you have this authoritarian
[00:34:44.480 --> 00:34:50.480]   and Putin trying to beat his breast to have victories. And an authoritarian government,
[00:34:50.480 --> 00:34:52.960]   it's not Brad Russia's brand Putin.
[00:34:52.960 --> 00:34:59.600]   Well, we're the other. Yeah, they want to be seen as a strong player as a power. And here you are,
[00:34:59.600 --> 00:35:05.280]   Mike, in a country Russia invaded not so very long ago, because it'd been invaded by everybody
[00:35:05.280 --> 00:35:12.160]   and their brother over the last 10 centuries. But Georgia was a Soviet republic. It's where
[00:35:12.160 --> 00:35:20.400]   Stalin came from. Yeah, it was annexed. And there's no question that
[00:35:21.200 --> 00:35:28.000]   Putin yearns for the glory days of the Soviet Union and the reach that they had a global superpower
[00:35:28.000 --> 00:35:34.240]   and at the center of things in terms of international affairs. And that's part of his allure that the
[00:35:34.240 --> 00:35:40.720]   idea that he's going to bring them back to that glory days. If they bring about the bread lines
[00:35:40.720 --> 00:35:45.520]   and the poverty and the famine and all that stuff as well, which people don't remember quite as well
[00:35:46.320 --> 00:35:52.320]   as the international heft, then maybe that idea wouldn't be so popular. But to a certain extent,
[00:35:52.320 --> 00:35:57.600]   the other, not this hack, but the other meddling in democracy with the ads and all that kind of
[00:35:57.600 --> 00:36:01.600]   stuff, that's a win-win, I think, for Russia. Because on the one hand, yeah, maybe they'll
[00:36:01.600 --> 00:36:08.560]   screw with our democracy. Yes, maybe they'll, but even in being, in that case, even when they're
[00:36:08.560 --> 00:36:12.080]   caught red-handed with their hands in the cookie jar, they could say, look, all these tech companies
[00:36:12.080 --> 00:36:16.240]   Silicon Valley, they're not so great. We hacked them, we'd messed with them, we did all this stuff.
[00:36:16.240 --> 00:36:23.040]   And it's part of it is tarnishing the Western brand, if you will, the things that are alluring
[00:36:23.040 --> 00:36:29.360]   about the United States and Europe, those take a big hit when Russia successfully is caught
[00:36:29.360 --> 00:36:33.360]   meddling with our culture, with our democracy and all that kind of stuff.
[00:36:33.360 --> 00:36:39.840]   Well, let's extend it beyond Russia. North Korea, too, has a very active hacking
[00:36:39.840 --> 00:36:47.280]   cadre, a very effective hacking cadre. It's an easy way for a country that's small and doesn't
[00:36:47.280 --> 00:36:53.360]   have a lot of resources and can't foot a million-man army or to-
[00:36:53.360 --> 00:36:55.520]   North Korea literally has a million-man army, but yeah,
[00:36:55.520 --> 00:37:02.000]   well, and probably Russia does, too, and both may have nukes. But cyber warfare,
[00:37:02.000 --> 00:37:06.880]   20 good hackers are selling you need. Yeah, exactly. And you're a player.
[00:37:06.880 --> 00:37:12.720]   It's a lot cheaper. It's a hell of a lot cheaper. And I've plugged this on the show before, but
[00:37:12.720 --> 00:37:21.280]   the NATO handbook on Russian information warfare is spectacular. And it makes clear that the goal
[00:37:21.280 --> 00:37:26.160]   is to get the country to turn on itself. Yeah. Yeah.
[00:37:26.160 --> 00:37:30.080]   Realization. Yeah, I mean, I think it's simplistic to say they just wanted Trump to get elected.
[00:37:30.080 --> 00:37:34.240]   I think it's a much more, it's a longer game they're playing than that, although there is evidence
[00:37:34.240 --> 00:37:40.560]   that there was not a lot of love lost between Putin and Clinton. Yeah, the word that is making
[00:37:40.560 --> 00:37:46.400]   its way into the English language is des informatsia. Yeah. And there's actually a book on that topic
[00:37:46.400 --> 00:37:51.120]   and lots of really great articles I've mentioned in a couple of my columns. But this is the
[00:37:51.120 --> 00:37:59.600]   idea behind des informatsia is to ultimate the ultimate goal is to erode trust in information
[00:37:59.600 --> 00:38:06.480]   itself to the point where people don't know what to believe. And everything is equivalent.
[00:38:06.480 --> 00:38:11.920]   Legitimate claims, false claims are all the same. You know who might win from all of this China?
[00:38:13.520 --> 00:38:22.000]   Uh-huh. Yeah. I think it's already happening. Yeah. As the West declines into chaos and Russia
[00:38:22.000 --> 00:38:32.080]   acts like a mean teenager, China can stand above it all and say, well, go ahead, you guys fight it
[00:38:32.080 --> 00:38:35.840]   out. We're gonna take a break. I want to talk about actually, if you're worried about spying,
[00:38:35.840 --> 00:38:38.960]   it turns out maybe the worst thing you could put in your house is a Google Home Mini.
[00:38:40.160 --> 00:38:46.400]   Oh, that was a mistake. It was a mistake. But they fixed it. We'll talk about that in a second.
[00:38:46.400 --> 00:38:49.520]   Jeff Jarvis is here. He's in Berlin. It's great to have him from the city,
[00:38:49.520 --> 00:38:53.840]   University of New York, buzzmachine.com. It's funny because Paul and Mary Jo did their show
[00:38:53.840 --> 00:38:58.880]   from CUNY today. I said, oh, yeah, they got the sort that didn't work. Okay. Works great. I said,
[00:38:58.880 --> 00:39:05.680]   say hi to Jeff. Is it he's not here. But thank you for helping us get that going. That's great.
[00:39:05.680 --> 00:39:11.280]   Pleasure. And from all the way from the state of Georgia on the Black Sea, can you see the Black
[00:39:11.280 --> 00:39:21.200]   Sea from your, I can see from my nose. Absolutely. Nice. No. He's in Tbilisi, Mike Elgin of Gastronomad.net.
[00:39:21.200 --> 00:39:27.680]   He and Amira are planning, yes, another gastronomatic adventure next in Italy,
[00:39:27.680 --> 00:39:33.600]   then in France. And who knows? Maybe I wouldn't, I'd go to Georgia to taste some of that wine that
[00:39:33.600 --> 00:39:38.720]   you've been singing the praises of. We're considering it. I'll bring you a bottle, Leo,
[00:39:38.720 --> 00:39:43.200]   and but we're considering doing an event here as well. So you never know.
[00:39:43.200 --> 00:39:49.760]   Boy, well, yeah, that would be really, I just so much fun. Our show today brought to you by the
[00:39:49.760 --> 00:39:56.320]   Ring Video Doorbell. Actually, it's by all the Ring things. Ring's mission is to make
[00:39:56.320 --> 00:40:00.000]   neighborhoods safer. We've talked about the doorbell before I have it. Everybody in the
[00:40:00.000 --> 00:40:05.280]   bit, everybody at Twitter has it. It affects funny because yeah, when, when, when, when
[00:40:05.280 --> 00:40:09.440]   somebody comes to anybody's door in the house, the one thing ring, please make us make it possible
[00:40:09.440 --> 00:40:14.080]   to have differing ringtones. Because all of our phones go ding, ding, ding, ding. And then we all
[00:40:14.080 --> 00:40:19.360]   say, Oh, there's somebody at my door. It's a little confusing. We're all in on ring. We love our ring
[00:40:19.360 --> 00:40:24.720]   video doorbell. It's a great way to see what's going on at your front door wherever you are in
[00:40:24.720 --> 00:40:28.560]   the world. You put the camera up. As you mentioned, Mike, last time you were here,
[00:40:28.560 --> 00:40:33.680]   great for an Airbnb. If you want to see when your visitors come and go, somebody rings your
[00:40:33.680 --> 00:40:38.000]   doorbell, you can talk to them. They can talk to you. You can say, leave the package there.
[00:40:38.000 --> 00:40:43.600]   And now we've got this. This is so cool. This is the ring floodlight cam and the idea behind the
[00:40:43.600 --> 00:40:48.320]   floodlight cam is well, you've all seen the motion activated floodlights people have on their garages.
[00:40:48.320 --> 00:40:54.800]   But the floodlight cam adds that special ring goodness, the camera with the speaker
[00:40:54.800 --> 00:40:59.840]   and the microphone and the motion detector. Somebody comes in your backyard, they're brightly lit.
[00:40:59.840 --> 00:41:06.960]   You're notified on your phone, even if you're far, far away. And you could see who's there and say,
[00:41:06.960 --> 00:41:11.920]   Hey, raccoon, get out of my yard and listen to see what the raccoon says. And if the raccoon
[00:41:11.920 --> 00:41:17.840]   doesn't respond, you can even push a button that triggers a 110 decibel alarm. And that'll scare the
[00:41:17.840 --> 00:41:25.440]   little fellas right out of your backyard. Rings stuff is great. It's well made, it's smart. It
[00:41:25.440 --> 00:41:31.920]   works with your Amazon, echoes and other devices. It's a great way to hear, see and speak to visitors
[00:41:31.920 --> 00:41:36.480]   at your door or anywhere around your house. When things go bump in the night, you will know
[00:41:36.480 --> 00:41:43.840]   what it is. And you know, it's for situations like this fire here, the ability to go check your
[00:41:43.840 --> 00:41:48.240]   backyard and see if there's anything going on. If the fire is getting close, that is really
[00:41:48.240 --> 00:41:55.440]   valuable too. Here's what you do. Go to ring.com/twig and take a look at the ring of security kits
[00:41:55.440 --> 00:42:00.240]   they've put together. Choose either the original ring doorbell or the new Ring Pro doorbell and one,
[00:42:00.240 --> 00:42:06.560]   two or three of these floodlight cams, easy to install, connect them with your favorite locks,
[00:42:06.560 --> 00:42:12.720]   your smart locks, your hubs for added convenience, monitoring and security and save up to $150
[00:42:13.440 --> 00:42:23.920]   at ring.com/twig of the Wall Street Journal's best of CES 2017. Ring.com/twig. We thank them for
[00:42:23.920 --> 00:42:32.960]   keeping us safe and supporting our show. So Google last week announced a week ago, exactly,
[00:42:32.960 --> 00:42:36.960]   a number of new devices including a new Google home, two new Google homes, the Google Home Mini
[00:42:36.960 --> 00:42:44.160]   and the Google Home Maxi or Max. It's just Max. They gave everybody at the event. I did not go to
[00:42:44.160 --> 00:42:52.240]   the event. Now I'm glad they gave everybody the event a home Mini including from Android Police
[00:42:52.240 --> 00:43:02.640]   Artem Rousa Kofsky. Rousa Kofsky. Artem set his ring Mini up and then noticed it seemed to be
[00:43:02.640 --> 00:43:11.520]   responding a lot to kind of random noises. So he went online, you know, the, not ring, the
[00:43:11.520 --> 00:43:18.400]   home, Google Home has an online interface. You can see all the triggers.
[00:43:18.400 --> 00:43:25.040]   So he went to his Google My Activity Portal, opened it up and he says, "My jaw dropped."
[00:43:26.240 --> 00:43:33.440]   I saw thousands of items, each with a play button and a timestamp all attributed to this device
[00:43:33.440 --> 00:43:42.080]   called the mushroom. So he was a little nervous. He thought maybe your mushroom is the Mini because
[00:43:42.080 --> 00:43:46.800]   he knew that the code name for the Google Home was pineapple. So he listened to the audio clips
[00:43:46.800 --> 00:43:53.200]   and it was like sounds coming from his living room. Oh, I'm sorry, not his living room worse.
[00:43:53.200 --> 00:44:02.160]   He put it in his bathroom. So he sent a note to Google thinking, "Well,
[00:44:02.160 --> 00:44:05.920]   hi, please forward this to Google Home Team for response. I'm working on a story I'm going to
[00:44:05.920 --> 00:44:10.000]   publish in the next day or so. I discovered this issue. Would you please confirm the Mini's code
[00:44:10.000 --> 00:44:16.240]   name is mushroom? And here's, you know, my activity page. He says, "Here's the kicker,
[00:44:16.240 --> 00:44:20.160]   based on Google My Activity, the onslaught of thousands of transmitted and saved assistant
[00:44:20.160 --> 00:44:26.800]   related audio queries started the day the Home Mini was set up." Needless to say, if a listening
[00:44:26.800 --> 00:44:31.440]   device records almost every minute of every day and stores it remotely, we're talking about a
[00:44:31.440 --> 00:44:37.760]   huge privacy violation. Does Google have a comment about this? This is, this is it. What does he say?
[00:44:37.760 --> 00:44:47.520]   422 PM. He heard from them 10 minutes later. And by 7 PM, Google was on its way to his house
[00:44:48.160 --> 00:44:55.440]   to take the Mini. An engineer drove up to Oakland to examine it that very night. The next day,
[00:44:55.440 --> 00:44:59.600]   they say, "We've learned of an issue impacting a small number of Google Home Mini's, like all
[00:44:59.600 --> 00:45:06.720]   the ones we handed out at the press event." Now, that causes the touch mechanism to behave
[00:45:06.720 --> 00:45:11.520]   incorrectly. See, apparently there, if you, just like your Google Home, if you touch the top of it,
[00:45:11.520 --> 00:45:16.560]   instead of saying, "Okay, Google, you touch the top of it, it'll trigger it." Apparently,
[00:45:16.560 --> 00:45:20.720]   they had something wrong with the switch and it was just, it was registering phantom touch events.
[00:45:20.720 --> 00:45:25.760]   So, the fix, which they pushed out pretty quickly, simply disabled that capability.
[00:45:25.760 --> 00:45:31.760]   And it says, he says, "The company let me know they're in the process of building a long-term fix."
[00:45:31.760 --> 00:45:37.200]   But if you're one of those journalists, no, but actually, you wouldn't have to do anything
[00:45:37.200 --> 00:45:40.720]   because they pushed the fix to all of them. But how embarrassing is that?
[00:45:42.560 --> 00:45:48.480]   Wow. I don't think that was malicious or unintentional. They certainly responded very quickly.
[00:45:48.480 --> 00:45:51.280]   But if they hadn't discovered it for like two weeks,
[00:45:51.280 --> 00:45:55.440]   it would have been like, "What was the drive-by-wifi thing that happened?"
[00:45:55.440 --> 00:45:57.760]   Oh, yeah. Maybe in lawsuits.
[00:45:57.760 --> 00:46:04.240]   But there'd be much in Google's defense. It was discovered because Google's so transparent
[00:46:04.240 --> 00:46:07.600]   about what, about all the audio recording. They put it all on. That's a good point.
[00:46:07.600 --> 00:46:10.960]   Anybody can go see it and that's what they did. That's a very good point.
[00:46:10.960 --> 00:46:11.840]   He was able to go.
[00:46:11.840 --> 00:46:16.880]   Hey, look who just joined us. Kevin Marks is here adding to the
[00:46:16.880 --> 00:46:24.240]   trio of countries we're visiting this week. Kevin is Poodle or in Yorkshire. Kevin Marks is in
[00:46:24.240 --> 00:46:29.520]   Yorkshire. Jeff Jarvis is in Berlin. Mike Algin is in Tbilisi, Georgia. Wow.
[00:46:29.520 --> 00:46:36.320]   And people say we're American-centric, not true, not true.
[00:46:36.320 --> 00:46:39.920]   Leo's been over the place recently too, haven't you?
[00:46:39.920 --> 00:46:41.200]   I'm just going to have a laugh.
[00:46:41.200 --> 00:46:46.400]   I'm unfortunately kind of stuck here to do the shows because I have to anchor it at the home base.
[00:46:46.400 --> 00:46:49.600]   But anyway, thank you for joining us, Kevin. It's great to have you.
[00:46:49.600 --> 00:46:55.200]   You missed all the fun stuff though, because Spirsty and the pixel, I mean the
[00:46:55.200 --> 00:47:00.800]   mini. We didn't get a chance to talk to you after the Google event. Are you excited about
[00:47:00.800 --> 00:47:05.840]   the Pixel 2 and the Chromebook Pixel and Pixel Book?
[00:47:05.840 --> 00:47:11.760]   Well, they seem like nice incremental improvements. The Chromebook looks very nice,
[00:47:11.760 --> 00:47:17.120]   because I've still used the Chromebook Pixel I got four years ago. So them doing another one of those.
[00:47:17.120 --> 00:47:22.240]   Jason Howell is also, and he said, "Can I please replace my original Chromebook Pixel with a
[00:47:22.240 --> 00:47:25.600]   Pixel Book?" And I said, "Yes, of course." Jeff though, you'll be interested to know,
[00:47:25.600 --> 00:47:30.880]   I did cancel my order for the 256 gig one, and I'm ordering the 128 gig one.
[00:47:30.880 --> 00:47:34.800]   Yes, what? You inspired me to do the exact same thing.
[00:47:34.800 --> 00:47:36.480]   Yeah. I don't think you need more.
[00:47:36.480 --> 00:47:38.560]   I'm not so I waited another week. I think you're right.
[00:47:38.560 --> 00:47:42.480]   You don't get more RAM. You don't get a faster processor. You don't get, if you want,
[00:47:42.480 --> 00:47:48.640]   for instance, the fastest drive storage, you have to go all the way up to the $1,650 version
[00:47:48.640 --> 00:47:52.320]   with the i7 and the NVMe drive. I'm not willing to spend that much.
[00:47:52.320 --> 00:48:00.640]   No, I'm not either. And I think that because the keyboard is exposed, we use it as a tablet,
[00:48:01.520 --> 00:48:05.520]   I can't see just pulling it out of the path of training and watching a show
[00:48:05.520 --> 00:48:11.040]   and risking the keyboard and it being bigger. So it's going to be a
[00:48:11.040 --> 00:48:18.240]   leave it at the desk machine, I think. And I'll keep using the tablet, which I'm using right now
[00:48:18.240 --> 00:48:24.960]   for reasons I'll explain. And thus, when I travel, I want all my shows and movies and things on the
[00:48:24.960 --> 00:48:29.760]   tablet so I can watch that. That's why you'd want extra memory on the device.
[00:48:30.560 --> 00:48:33.040]   And if I don't travel with it, I don't need that much stuff.
[00:48:33.040 --> 00:48:40.400]   We're so spoiled, though, because really 128 gigabytes. That's a lot of movies, a lot of music,
[00:48:40.400 --> 00:48:43.760]   a lot of... Sure, yeah. I'm not sure I really need all that.
[00:48:43.760 --> 00:48:49.600]   I just... You know, the thing is that I never feel like I need it, but if I think about what
[00:48:49.600 --> 00:48:54.160]   frustrates me about my one or two-year-old devices, it's always that they don't have enough storage.
[00:48:56.000 --> 00:49:01.920]   I just ordered the new Amazon Kindle, the first waterproof Kindle.
[00:49:01.920 --> 00:49:08.160]   What? You're taking the tub now. You could take in the tub now. It's weird that the waterproof
[00:49:08.160 --> 00:49:14.320]   Kindle is named Oasis. It has 32 gigs, but remember, but that's a ton for books.
[00:49:14.320 --> 00:49:19.120]   Yeah, there's a lot of books. You know, on the other hand,
[00:49:20.720 --> 00:49:27.120]   they do now read audio-audible books. You can play from the Oasis to a Bluetooth speaker. It
[00:49:27.120 --> 00:49:30.960]   doesn't have speakers built in, but... Is there any advantage to that, though, as opposed to your
[00:49:30.960 --> 00:49:40.400]   phone? Yes, I'll tell you why. Because if you buy the print book, the Kindle book and the audible,
[00:49:40.400 --> 00:49:45.680]   you could do both. So you could switch back and forth. And when you listen to the audible,
[00:49:45.680 --> 00:49:49.840]   it'll show the text highlighted as the reader reads. And every once in a while,
[00:49:49.840 --> 00:49:54.400]   there's a book that I wish I could read at the same time as I'm listening. Most of the time,
[00:49:54.400 --> 00:49:58.640]   it doesn't matter. Or go back and forth, easily. Yeah. But sometimes you want... Game of Thrones is
[00:49:58.640 --> 00:50:05.040]   a good example. The way they spell those names, you never know. And it's not unusual that I'm
[00:50:05.040 --> 00:50:10.720]   listening to a book that if you're reading it, and he mentions somebody's name at the top of the
[00:50:10.720 --> 00:50:14.320]   page, by the bottom of the page, if you're listening, you may have forgotten who are we talking about
[00:50:14.320 --> 00:50:18.240]   again? So it's easy enough. If you're looking at a page, you just go, "Oh, yeah, yeah." But if
[00:50:18.240 --> 00:50:21.760]   you're listening, that's a big rewind. So it's nice to have... Especially if you're in the top.
[00:50:21.760 --> 00:50:27.440]   And now I can do it in the tub. In the hot tub, you're in your mind. By the way, audible books.
[00:50:27.440 --> 00:50:32.640]   Sorry. Mike and I get... I apologize to the audience. Mike and I are each on delay,
[00:50:32.640 --> 00:50:37.760]   so we don't know when we're interrupting each other. Go ahead, Mike. No, no, I go ahead. I'm
[00:50:37.760 --> 00:50:45.760]   pretty much done making my crack. Brought by me. So I listened to the John LeCarr.
[00:50:46.640 --> 00:50:53.120]   And the dramatization of it was spectacular and not over the top, not obnoxious, but just using
[00:50:53.120 --> 00:50:59.520]   the voices, one reader, but really doing... They've gotten so much better at this. It's just amazing.
[00:50:59.520 --> 00:51:04.160]   I agree. By the way, have you... Have we talked about the butterfly effect on Audible?
[00:51:04.160 --> 00:51:09.040]   John Ronson. Ron Johnson? Yes, we have. You mentioned it. Yeah, you really like that.
[00:51:09.040 --> 00:51:12.960]   Yeah. That was very good. There is a new LeCarr novel. Is it good?
[00:51:14.080 --> 00:51:18.160]   It's very good, I think. Yes. Because it goes back to the spinal cord from the cold
[00:51:18.160 --> 00:51:22.720]   and digs into it. Is this a legacy of spies?
[00:51:22.720 --> 00:51:28.480]   Yeah, it's very good. Okay. Because I'm a huge fan, but I just thought, "Wow, I didn't even know
[00:51:28.480 --> 00:51:36.000]   he was still alive. I hate to see that." I know. It's presumably valedictory in the sense that it
[00:51:36.000 --> 00:51:40.720]   wraps up some things. If you like this, I am going to recommend also an Audible, and I wish
[00:51:40.720 --> 00:51:48.480]   Audible had an ad today. They have taken the complete BBC Radio 4 dramatizations of all the
[00:51:48.480 --> 00:51:56.080]   smiley books and put it on one Audible thing, and it's really, really well done. It's 18 hours
[00:51:56.080 --> 00:52:00.560]   and 59 minutes. Call for the dead murder of quality. Spiocame Anthony McCold, looking glass,
[00:52:00.560 --> 00:52:05.040]   wart tinker, tailor soldiers, by honorable school boy. Smileys, people's in the secret program.
[00:52:06.320 --> 00:52:10.720]   In one all dramatized. It's fully, fully dramatized with lots of actors.
[00:52:10.720 --> 00:52:16.640]   They stay at... They listen to that before you listen to the new novel, because it'll...
[00:52:16.640 --> 00:52:22.560]   It sets you up. It makes that easier. Yeah, reminds you who smiley is and all that stuff, but I love
[00:52:22.560 --> 00:52:28.800]   all that stuff. When the last veil was removed, George blinked and blushed and understood.
[00:52:28.800 --> 00:52:34.560]   He'd imagined, so he said, fellowships under life devoted to the literary obscurities of 17th
[00:52:34.560 --> 00:52:38.560]   century Germany. And here he was, being offered a job in the British Secret Service.
[00:52:38.560 --> 00:52:44.960]   I love it! You know what I think? I think that the new book is better. It doesn't have a bunch
[00:52:44.960 --> 00:52:49.280]   of actors. It has only one guy. I'm gonna get it. I think it's better. I have two credits.
[00:52:49.280 --> 00:52:56.880]   The production. It's just added it to my cart. Thank you for the recommendation.
[00:52:56.880 --> 00:52:59.680]   And all of this without an Audible ad. Well, that's a lot of the BBC ones.
[00:53:00.480 --> 00:53:08.160]   I like the BBC. Did I show you the BBC adaptation of Asimov's Foundation? No!
[00:53:08.160 --> 00:53:11.520]   It's mid-70s. I'll dig that out for you. I'll put that. That's my...
[00:53:11.520 --> 00:53:17.200]   Oh, make that your pick. Of course, the BBC is very famous. People think the Hitchhiker's
[00:53:17.200 --> 00:53:21.520]   Guide to the Galaxy was a novel or some confused people might think it was a movie,
[00:53:21.520 --> 00:53:27.200]   but it was a BBC radio play first. In fact, Douglas Adams was scribbling the lines like
[00:53:27.200 --> 00:53:32.080]   minutes before they went on the air and handing it to the actors. And if you can get a copy of the
[00:53:32.080 --> 00:53:37.680]   original original BBC Hitchhiker's Guide to the Galaxy, wow, is that good. So, but I can't wait
[00:53:37.680 --> 00:53:42.480]   to hear the foundation. That would be great. I was about to get the book just to reread it.
[00:53:42.480 --> 00:53:46.640]   It's been so long. We were talking about that. It was on this show. It wasn't a joke. We were
[00:53:46.640 --> 00:53:51.120]   talking about it a couple of weeks ago how we're headed quickly towards corporate world
[00:53:51.760 --> 00:53:59.120]   domination. And you know what? I'll take it. I keep saying it. At this point, that's what
[00:53:59.120 --> 00:54:04.080]   Google wants you to do. Maybe this isn't a Russian plot. This is a Google plot all along.
[00:54:04.080 --> 00:54:10.080]   So, while we're on book, I just want to mention I want to give a plug. John Green of Hank and John
[00:54:10.080 --> 00:54:14.560]   Green, his new novel is just, I guess, we got a spectacular review of the New York Times.
[00:54:14.560 --> 00:54:18.400]   I just bought it. I mean, he has books from African-agers, but this is he has a character
[00:54:18.400 --> 00:54:25.760]   who's deep into a deep episode of OCD. John himself is now talking about his own OCD and how
[00:54:25.760 --> 00:54:33.840]   this book was basically inspired by a crippling episode of it in 2015. And the interview and
[00:54:33.840 --> 00:54:39.040]   the review of the Times were stellar. So, we like the Green brothers.
[00:54:39.040 --> 00:54:44.320]   I will read that too, even though I try to stay away from young adult fiction.
[00:54:46.560 --> 00:54:52.400]   I would normally, too, if people say that, and especially his sad, I'm told, but this one sounds
[00:54:52.400 --> 00:55:01.120]   like it's an excellent window onto OCD. Did anybody see Mark Zuckerberg's VR tour for the week?
[00:55:01.120 --> 00:55:07.840]   Thank God, no. Yeah, and I don't actually think that Mark was,
[00:55:07.840 --> 00:55:15.520]   I think he made the point that it's very different when you're in the VR.
[00:55:16.160 --> 00:55:21.200]   Let's see if can we find it now? I don't have it here. Oh, yeah, here he is.
[00:55:21.200 --> 00:55:28.240]   So he was kind of, they were walking around Puerto Rico. He was walking around with a Facebook
[00:55:28.240 --> 00:55:35.360]   executive and looking at all the devastation. But remember that Mark is a cartoon character
[00:55:35.360 --> 00:55:42.240]   in this. This is using Facebook's Spaces VR app. And he see himself. No.
[00:55:42.240 --> 00:55:46.560]   No. Or does he only see the background? He would have seen her. She would have seen him.
[00:55:46.560 --> 00:55:53.200]   But that was the point that Zuckerberg's people may. At one point, he says,
[00:55:53.200 --> 00:56:00.000]   "Do you want to teleport somewhere else?" Yeah, maybe back to California, says another executive.
[00:56:00.000 --> 00:56:05.760]   Zuckerberg responded in a comment to all the negative comments. One of the most powerful
[00:56:05.760 --> 00:56:11.920]   VR features of VR is empathy. My goal here was to show how VR can raise awareness and
[00:56:11.920 --> 00:56:15.440]   help see what's happening in different parts of the world. I also wanted to share the news of our
[00:56:15.440 --> 00:56:20.240]   partnership with Red Cross to help with the recovery, reading some of the comments I realized
[00:56:20.240 --> 00:56:26.240]   this wasn't clear. And I'm sorry to anyone this offended. He came back and actually added some more.
[00:56:26.240 --> 00:56:32.080]   He said, "When you're in VR yourself, the surroundings feel quite real. But that sense of empathy
[00:56:32.080 --> 00:56:38.000]   doesn't extend well to people watching you as a virtual character on a 2D screen. That's something
[00:56:38.000 --> 00:56:46.160]   we'll need to work on over time." So I don't know. What do you think?
[00:56:46.160 --> 00:56:59.840]   I think that Facebook and Zuckerberg apologize for a lot of things. And they all have a similar
[00:57:00.400 --> 00:57:07.520]   theme, which is that there's a lack of understanding about what the public, how they
[00:57:07.520 --> 00:57:12.800]   perceive things by Facebook and Zuckerberg. I think this is one of the reasons why he went
[00:57:12.800 --> 00:57:19.840]   on his grand tour of the United States. He doesn't understand people. He doesn't understand why they
[00:57:19.840 --> 00:57:23.840]   respond the way they do. He doesn't understand why people do what they do and how they think.
[00:57:23.840 --> 00:57:29.440]   And so this is yet another example. And I think that hopefully what he's learned and what all
[00:57:29.440 --> 00:57:35.200]   such companies should learn is that when there is a crisis and people are hurting and suffering,
[00:57:35.200 --> 00:57:41.200]   that's not the time to promote anything. Yes. Thank you. Yes. Well said. Good rule.
[00:57:41.200 --> 00:57:47.360]   There is in general in Silicon Valley, though, a kind of a bro-related insensitivities. Why we
[00:57:47.360 --> 00:57:51.200]   always say, "Oh, they ought to have some people of color, some diversity on their boards." They
[00:57:51.200 --> 00:57:55.440]   need to understand a little bit better how the rest of the world thinks. They are a little bit in a
[00:57:55.440 --> 00:58:03.760]   bubble. Yes. All right. We won't beat him up. He apologized. And Facebook's very good,
[00:58:03.760 --> 00:58:13.200]   has gotten very good at apologizing. I actually have a Google alert that searches for Facebook
[00:58:13.200 --> 00:58:19.920]   apologized, Zuckerberg apologized. Wow. That's probably the best way to find out what they've done
[00:58:19.920 --> 00:58:26.560]   wrong lately. I wrote a post last week. We didn't talk about Google, but we mentioned it quickly
[00:58:26.560 --> 00:58:34.160]   about the need for the technology companies to establish and learn moral authority.
[00:58:34.160 --> 00:58:39.200]   That's not good enough to say, "Don't be evil." It's not good enough to say we follow the laws.
[00:58:39.200 --> 00:58:45.040]   It's not good enough to apologize. They have such tremendous power now. The internet,
[00:58:45.040 --> 00:58:49.280]   and thus the futures in their hands, they have to go beyond what they thought they had to do.
[00:58:49.280 --> 00:58:56.000]   They're being expected. I don't want to make them overly cautious, but they just have to have a
[00:58:56.000 --> 00:59:02.560]   North Star in front of them at all times and understand that if they do gain moral authority,
[00:59:02.560 --> 00:59:09.200]   that is the platform. We in media thought that our platform was technology, and we found out too
[00:59:09.200 --> 00:59:14.720]   late that we'd lost our moral authority. These guys haven't gained their moral authority,
[00:59:14.720 --> 00:59:20.400]   and they have to do so. You mean, such as when Walter Cronkite said, "You know what,
[00:59:20.400 --> 00:59:25.680]   we shouldn't be in Vietnam." That was the weight of America's most trusted voice saying
[00:59:25.680 --> 00:59:30.320]   Vietnam is a mistake. That carried huge weight in those days. That kind of moral authority.
[00:59:30.320 --> 00:59:34.880]   Yeah. I think that an example of the Russian ads,
[00:59:37.520 --> 00:59:41.120]   I don't know when they knew they had Russian ads. I don't presume that they were too much.
[00:59:41.120 --> 00:59:46.160]   They did a long, long time though. Whenever they, A, they should have searched like hell,
[00:59:46.160 --> 00:59:52.240]   and B, if they had come out first and said we were manipulated by the Russians,
[00:59:52.240 --> 00:59:55.360]   then the story would have been the Russians. Instead, the story is Facebook.
[00:59:55.360 --> 01:00:01.760]   I want to see them go even further now, where I think they should make all the ads public immediately.
[01:00:01.760 --> 01:00:04.960]   Zuckerberg has said that in the future, when you see a political ad in your feed,
[01:00:04.960 --> 01:00:08.960]   you can go and see who bought it. That's good. But I think we should all be able to see all
[01:00:08.960 --> 01:00:16.880]   political ads. I also think very adamantly that they should reveal targeting data for these ads,
[01:00:16.880 --> 01:00:23.840]   so that we know who's being targeted. My point here is that Facebook and Google
[01:00:23.840 --> 01:00:28.480]   could go far beyond where television is. Certainly, where direct mail is,
[01:00:28.480 --> 01:00:32.960]   where there's no transparency, they could see that they have the opportunity to set a new moral
[01:00:32.960 --> 01:00:37.360]   standard here, rather than merely saying what they say today, which is, we follow the laws of the
[01:00:37.360 --> 01:00:43.600]   country we're in, not good enough. Google seems to have tried to go so far. Go ahead. Go ahead,
[01:00:43.600 --> 01:00:48.880]   Mike. To be suspicious of ads that don't advertise a product or service.
[01:00:48.880 --> 01:00:51.760]   I mean, political ads, a lot of the things that Facebook apparently,
[01:00:51.760 --> 01:00:56.560]   or the Russians apparently bought, Facebook and elsewhere, they weren't political ads.
[01:00:56.560 --> 01:01:00.400]   They weren't political at all. They were just people ranting about this that or the other thing,
[01:01:00.400 --> 01:01:07.440]   or they were supposedly some sort of nonprofit group that was concerned about some identity
[01:01:07.440 --> 01:01:12.480]   politics or something like that. All of that stuff, I think, is potentially suspicious in the
[01:01:12.480 --> 01:01:18.320]   wake of all these revelations. I think it'd be great to see companies that do especially
[01:01:18.320 --> 01:01:23.520]   mobile advertising and social networking advertising to demand that advertisers are selling something,
[01:01:23.520 --> 01:01:27.520]   either a product or a service or something identifiable.
[01:01:28.560 --> 01:01:35.200]   You do remember, though, that Facebook, since 2011, has told the Federal Elections Commission
[01:01:35.200 --> 01:01:42.400]   that they should not be held responsible in the way that other media is for ad disclosure.
[01:01:42.400 --> 01:01:50.240]   They did not want to be held accountable. Since 2011, they've asked the Federal Election
[01:01:50.240 --> 01:01:56.240]   Communication, I'm sorry, commission for blanket exemptions for political advertising disclosure
[01:01:56.240 --> 01:02:03.200]   rules. That tells me that they kind of knew. Why would they want to be exempt from that?
[01:02:03.200 --> 01:02:07.920]   Well, okay. Here's why, I think we know. I'm not justifying, but
[01:02:07.920 --> 01:02:16.160]   we never had advertising to the scale before. When blogs came along, suddenly,
[01:02:16.160 --> 01:02:21.920]   anybody could publish, it opened up tremendously. It also opened it up to spam and manipulation
[01:02:21.920 --> 01:02:26.480]   and worse and trolling and worse. Now, advertising has similar been democratized,
[01:02:26.480 --> 01:02:32.160]   where any, you know, Aunt Mary can advertise her jam to the world around, or a mere elegant
[01:02:32.160 --> 01:02:38.560]   God knows what she can make and sell the world around. And that opens it up, and that creates
[01:02:38.560 --> 01:02:43.760]   whole new businesses and whole new opportunities, but the scale is so difficult to deal with.
[01:02:43.760 --> 01:02:47.840]   It's not like you're a TV station with a very finite number of ads or a newspaper with a finite
[01:02:47.840 --> 01:02:53.040]   number of ads. This is a virtually infinite number of ads. And so it's not just scale.
[01:02:53.040 --> 01:02:53.760]   Bring it cost.
[01:02:53.760 --> 01:03:01.040]   Yeah, it's not just scale. These are dark ads. So let's say I find one new person in the world
[01:03:01.040 --> 01:03:06.880]   who's terrified of leprechauns, I can serve up ads about how this political candidate or that is
[01:03:06.880 --> 01:03:12.560]   going to unleash the leprechauns. And nobody will ever know that that was the ad. They're dark ads,
[01:03:12.560 --> 01:03:24.000]   nobody can see them. The irony is the FEC. The irony is the FEC
[01:03:24.000 --> 01:03:30.880]   did not give Facebook an exemption. So they were required to disclose, but they
[01:03:30.880 --> 01:03:35.680]   decided, well, it's the ad buyer's issue, and we're not going to do it.
[01:03:36.640 --> 01:03:42.800]   So you can apologize. You could say we should say we did better, but they have not been on the
[01:03:42.800 --> 01:03:48.560]   right side of this for some time. There's a lot of money to be made in these ads.
[01:03:48.560 --> 01:03:56.640]   It also has to be said that it's understood in the advertising industry. I read the ad age and
[01:03:56.640 --> 01:04:02.560]   some of the other advertising publications that Facebook is the gold standard for targeting.
[01:04:02.560 --> 01:04:07.280]   You can target people better on Facebook than anywhere else, and it's global.
[01:04:07.280 --> 01:04:11.520]   It's a lot of power. Where do those ads affect if somebody in the chatroom,
[01:04:11.520 --> 01:04:15.840]   who I think has an extra grind, says, oh, we know they weren't very effective.
[01:04:15.840 --> 01:04:20.480]   It's interesting, though, that they were highly targeted at states where there was a very slim
[01:04:20.480 --> 01:04:24.800]   margin. And Trump did, in fact, win via very, very slim margin, 17,000 votes.
[01:04:24.800 --> 01:04:28.000]   You're never going to prove the
[01:04:28.000 --> 01:04:34.880]   effectiveness, but boy, if they're putting the ads in those states, and those are the states that
[01:04:34.880 --> 01:04:41.440]   they turn it, that seems to me that those ads can't prove it was effective, but there's evidence
[01:04:41.440 --> 01:04:47.600]   maybe they were. The grand opportunity for Facebook is that they claim that this is their business
[01:04:47.600 --> 01:04:52.400]   model. We are really effective for advertising. Yeah, and you want to target Wisconsin
[01:04:53.760 --> 01:04:57.920]   and Michigan, you can do it. Let them come lovers in those areas.
[01:04:57.920 --> 01:05:07.120]   In fact, this is all amazing ad for Facebook, $100,000, and you too can become president.
[01:05:07.120 --> 01:05:14.240]   Facebook did not help their case, their moral authority this weekend when Alex Stamos,
[01:05:14.240 --> 01:05:21.920]   their chief of security, ranted on Twitter about how nobody understands how hard it is
[01:05:21.920 --> 01:05:28.480]   to stop fake news. And I wish the journalists would just ask us, and we could tell them how
[01:05:28.480 --> 01:05:32.960]   hard it is. Lots of journalists have celebrated academics who made wild claims about,
[01:05:32.960 --> 01:05:36.320]   I think you're probably one of those celebrated academics, by the way, Jeff.
[01:05:36.320 --> 01:05:41.600]   Wild claims about how easy it is to spot fake news and propaganda. Was he thinking about you,
[01:05:41.600 --> 01:05:48.000]   Jeff Jarvis? I doubt it. Does he know you? I'm not saying it easy. I'm not saying it easy.
[01:05:49.120 --> 01:05:52.400]   I don't think we've ever said it. We know how hard it is. We've had that discussion.
[01:05:52.400 --> 01:05:57.520]   Well, the closure here is I got, I just, whenever this comes up, you should say I started the
[01:05:57.520 --> 01:06:01.040]   Pus integrity initiative, and I got a substantial amount of money from Facebook,
[01:06:01.040 --> 01:06:04.560]   Greek, Newmark, Ford Foundation, and others to deal with this. And by the way, one of the
[01:06:04.560 --> 01:06:09.120]   grants we just gave was to PRI, Public Radio International, where they're doing a really neat
[01:06:09.120 --> 01:06:15.520]   project to basically use the same techniques the bad guys use, the bad guys, the Cambridge
[01:06:15.520 --> 01:06:19.360]   Analytica's, to find people who are vulnerable not to propaganda, but to journalism.
[01:06:19.360 --> 01:06:24.400]   Vulnerable to journalism. Let's find those people.
[01:06:24.400 --> 01:06:33.920]   What is that? That sounds really nefarious. One of my favorite things about Alex Stamos'
[01:06:33.920 --> 01:06:42.400]   rant is that he says that he encourages reporters to talk to engineers. They can really
[01:06:42.400 --> 01:06:46.640]   say, "I'd like to talk to some of your engineers about that."
[01:06:46.640 --> 01:06:53.040]   And next I want to call Coca-Cola and talk about their secret recipe. I'd like to know,
[01:06:53.040 --> 01:07:00.480]   how do they do that? Hey, good news for our friend, Danny Sullivan, who was on the show
[01:07:00.480 --> 01:07:05.920]   not so long ago. He has retired, as you know, from Search Engine Land and Marketing Engine Land.
[01:07:05.920 --> 01:07:14.480]   He now has a job at Google. Danny Sullivan, I think he's taken the basically the Mac Cuts position.
[01:07:14.480 --> 01:07:26.880]   Yeah, Google needs somebody who can talk and be human to explain a search. And that's his new
[01:07:26.880 --> 01:07:31.840]   job to explain Search and help bridge the gap, he says. And there was a picture of him.
[01:07:31.840 --> 01:07:38.960]   Yes, that's credibility. You know he's not going to spew BS. He'll do it in a way that people can
[01:07:38.960 --> 01:07:44.080]   understand. Brilliant, brilliant move. We're reaching out, seeing if Google will let him talk to us.
[01:07:44.080 --> 01:07:50.880]   He can bridge the gap right here. He's probably busy going through the... So, all those things
[01:07:50.880 --> 01:07:55.680]   I've speculated about for 10 years. Which ones are those? We're actually true. Most of these are good.
[01:07:56.960 --> 01:08:06.640]   He posted a picture of him in front of the nuclear statue, which is the nuclear statue. Tell me,
[01:08:06.640 --> 01:08:10.320]   you've stood in front of this too, I think Kevin Marks, where you stand if you're new to Google,
[01:08:10.320 --> 01:08:16.720]   or as a statue to the new ones at Google. I don't remember the statue. This may be newer than me.
[01:08:16.720 --> 01:08:21.920]   He says, "First day at Google, in front of the nuclear statue, see the beanie with the propeller,
[01:08:22.560 --> 01:08:28.320]   learned all I know about orientation from the internship. It is slightly different."
[01:08:28.320 --> 01:08:36.000]   Slightly different, he says. I love that. Good for you, Danny. Well done, good luck.
[01:08:36.000 --> 01:08:43.200]   He was in San Diego, right? I wonder if he's going to move up to Mountain View?
[01:08:43.200 --> 01:08:48.720]   Oh, that's a good question. Yeah, I don't know. Might have to. I'd move to Mountain View.
[01:08:48.720 --> 01:08:55.520]   Google Office in San Diego. Yeah. By the way, if you're going to, if you want to rob a bank,
[01:08:55.520 --> 01:09:01.440]   probably not the best idea to Google how to do it.
[01:09:01.440 --> 01:09:08.880]   Now, he robbed the bank, by the way. That may be how they caught him.
[01:09:08.880 --> 01:09:14.160]   But he later told police he searched how to rob a bank on Google to help carry out the robbery.
[01:09:17.520 --> 01:09:21.360]   YouTube probably would have been better. Yeah. I imagine that will come up at the trial.
[01:09:21.360 --> 01:09:26.480]   Then you get baby driver and he'd be picking the right tune to the bank too.
[01:09:26.480 --> 01:09:33.360]   It's a really interesting question. What do you find if you search Google for how do you rob a bank?
[01:09:33.360 --> 01:09:40.720]   To rob a bank. I am not. By the way, I can't rob a bank because this will be used in the trial
[01:09:40.720 --> 01:09:46.960]   against me. You're searching YouTube. Wow. Look at this. There's actually a lot of
[01:09:46.960 --> 01:09:51.040]   YouTube videos. Here's one. The following information is for educational purposes only.
[01:09:51.040 --> 01:09:59.840]   Robbing a bank. An amateur's guide. You will need to gather specialists who know their craft.
[01:09:59.840 --> 01:10:04.320]   The mastermind, the driver, the lookout. More than half a million views.
[01:10:04.320 --> 01:10:09.040]   It is important. You choose your team members wisely.
[01:10:09.040 --> 01:10:15.440]   Supplies and tactical gear. You will need gloves. Really irritating. Well, I think it was smart
[01:10:15.440 --> 01:10:24.320]   of him. Is it the robotic voice that bugs you? Yeah. Yeah. Oh, there's all sorts of technologies
[01:10:24.320 --> 01:10:33.120]   involved. Crazy. I think this is more how to write a bank heist movie than anything else.
[01:10:33.120 --> 01:10:41.440]   Anyway, I doubt that he did all of this. Wow, though. You really, truly can't learn anything on Google.
[01:10:43.840 --> 01:10:49.040]   Now that means, right? I'm going to get from now on along with the bikini clad women in my Google
[01:10:49.040 --> 01:10:55.200]   autoplay. I'm going to start having bank robbery videos, right? Right. Yeah. They did bought their
[01:10:55.200 --> 01:11:00.240]   work. That's not a Germany. I got it German. Did you? There are. There were quite a few
[01:11:00.240 --> 01:11:08.240]   bump stock videos and so forth on YouTube. And after the Las Vegas shooting, they have banned
[01:11:08.880 --> 01:11:14.560]   many of those modding tutorials from YouTube, but they were there. They were there.
[01:11:14.560 --> 01:11:21.760]   An example to an authority question is, is that you can't, it is hard and it's expensive and I get it.
[01:11:21.760 --> 01:11:25.520]   But you can't just set a standard that says when the disaster happens, we'll then backtrack.
[01:11:25.520 --> 01:11:29.120]   Now, we don't want them to be in a position to censor the world. We don't want them to be
[01:11:29.120 --> 01:11:32.400]   the judges of the world. We don't want them to say what's true and false, but they have to set
[01:11:32.400 --> 01:11:38.400]   standards above. Childport is bad. Well, now this is an interesting question. What about,
[01:11:38.400 --> 01:11:49.360]   where do you stand on Twitter banning or tell me what they did? There's a candidate for Congress in
[01:11:49.360 --> 01:11:54.880]   Florida, Georgia, Alabama. I forgotten. So we're down there, right? Who
[01:11:54.880 --> 01:12:04.400]   had a video including something about if I if elected, I will stop the sale of baby parts.
[01:12:05.520 --> 01:12:09.760]   And initially, Twitter decided Marsha Blackburn, Marsha Blackburn.
[01:12:09.760 --> 01:12:16.720]   Initially, Twitter shut down that video, right? It's back.
[01:12:16.720 --> 01:12:24.640]   Well, I think they you could still they reversed the decision. They shut down the ad. I think it
[01:12:24.640 --> 01:12:31.520]   was. No, they were they. So Twitter is reversing a decision to block. Oh, she's already a member
[01:12:31.520 --> 01:12:35.840]   of Congress. Marsha Blackburn of Tennessee for promoting her Senate campaign launch video on
[01:12:35.840 --> 01:12:42.080]   the social network. The company said Monday that a line in her in a video referencing baby body
[01:12:42.080 --> 01:12:50.080]   parts was inflammatory, violated its kind lines. I guess they pulled down the tweet referring to it,
[01:12:50.080 --> 01:13:00.080]   but then they reinstated. And and Blackburn says this is a victory for conservatives in America.
[01:13:00.080 --> 01:13:04.880]   It was pleased with the reversal. I think the reversal was a good idea. And I think the banning
[01:13:04.880 --> 01:13:10.400]   was a bad idea. This is this is I can't believe you know, I don't like, but it's like it's not,
[01:13:10.400 --> 01:13:15.440]   you know, she's trying to she's using inflammatory speech to make a political point. And that should
[01:13:15.440 --> 01:13:24.000]   be protected. So the Blackburn campaign said that it was pleased with the reversal. The Congress
[01:13:24.000 --> 01:13:27.840]   will and raised money off the decision on Monday saying that Silicon Valley elites
[01:13:28.400 --> 01:13:33.920]   were trying to impose their values. That's not my problem with it. My problem with it is
[01:13:33.920 --> 01:13:40.800]   if somebody has an opinion like that opinion, whether you disagree or agree, you need to know that.
[01:13:40.800 --> 01:13:47.120]   What if it's what if it is I agree, I agree, just to play it out a little bit more here playing the
[01:13:47.120 --> 01:13:53.120]   little role. What if it is, if I hit the phrase fake news, what if this is a debunked thing that
[01:13:53.120 --> 01:14:00.160]   that it was which it is, which was. So at some point, the rule was after them to go after fake
[01:14:00.160 --> 01:14:04.000]   now. This is this is by the way, this is Twitter, which doesn't go after horrible, horrible,
[01:14:04.000 --> 01:14:09.520]   stalking and and and harassment of people. And just as oh, we'll just turn it off so you don't
[01:14:09.520 --> 01:14:16.400]   hear it. So I did a standard. But but if the world is telling the platforms, get rid of fake news,
[01:14:16.400 --> 01:14:21.120]   this is fake news. What are we expecting to do? It's a really interesting challenge, right?
[01:14:21.680 --> 01:14:27.120]   It is. It is. But we're calling on Facebook and Twitter to do is stop fake news.
[01:14:27.120 --> 01:14:36.240]   So it's it's it's inflammatory speech. It's it's based on false information. And in this case,
[01:14:36.240 --> 01:14:41.680]   I mean, she is in Congress that I think the I think the clear remedy is more speech. People
[01:14:41.680 --> 01:14:48.720]   calling her out. She you know, basically going after her with more speech. I don't think, you know,
[01:14:48.720 --> 01:14:54.320]   silent of all the things to censor and silence. This is just this is a bad example of of
[01:14:54.320 --> 01:14:58.800]   this isn't fake. She's not a fake news organization per se. She's okay.
[01:14:58.800 --> 01:15:03.120]   Mike. So what is what is just to play with it? Just to keep going. Let's say she's not running
[01:15:03.120 --> 01:15:11.440]   for Congress. It's not a politician. Let's say it is a edgy news site. Yeah, right. It's but
[01:15:11.440 --> 01:15:17.840]   then what do you say? Well, I mean, in in the case of something like Sputnik or RT,
[01:15:18.480 --> 01:15:24.240]   which are which themselves, they have a lot of legitimate information mixed in with the BS.
[01:15:24.240 --> 01:15:33.360]   It's it's the you have to go, you know, consider the purpose of the site. You know, in which case,
[01:15:33.360 --> 01:15:39.600]   you know, Sputnik is clearly pro Russian propaganda. And and and and I wouldn't call for banning that.
[01:15:39.600 --> 01:15:43.360]   There are some other publications that would call for banning some of the Macedonian ones that
[01:15:43.360 --> 01:15:49.920]   exist purely to spread fake, fake news and and and that sort of thing. But in this case, you have
[01:15:49.920 --> 01:15:58.240]   you have lots of politicians saying lots. I mean, the president wouldn't last an hour if the rule,
[01:15:58.240 --> 01:16:02.800]   you know, against politics, you know, if there was a rule against politicians saying things that
[01:16:02.800 --> 01:16:09.440]   were untrue. And so, you know, you have to to a certain extent, allow occasional now if this
[01:16:09.440 --> 01:16:13.760]   politician, I don't know her that well. But if she's, you know, if every day she's coming out with more
[01:16:13.760 --> 01:16:18.640]   stuff that's patently false and so on, then that's another issue. But I doubt that that's the case here.
[01:16:18.640 --> 01:16:26.800]   It's a really it's a challenging and this is by the way, Alex Stamos is right. This is a hard
[01:16:26.800 --> 01:16:32.640]   thing to do. And I don't think we've ever denied that. Facebook is now added and I and I button
[01:16:32.640 --> 01:16:38.560]   to its news feed for more information. This is a test. So not everybody will see it for links to
[01:16:38.560 --> 01:16:43.440]   articles shared in the news feed. We're testing a button people can tap to access additional
[01:16:43.440 --> 01:16:48.240]   information without needing to go elsewhere contextual information pulled from across Facebook
[01:16:48.240 --> 01:16:53.680]   and other sources like the publishers, Wikipedia entry, a button to follow their page of training
[01:16:53.680 --> 01:16:58.720]   articles or related articles about the subject. The idea is to combat fake news by giving people
[01:16:58.720 --> 01:17:05.840]   an an unbutton they can press. Let's see if what the eye button looks like. A button they can press
[01:17:05.840 --> 01:17:13.520]   to say, well, who is this from? We talked about this a little bit on Sunday and the consensus
[01:17:13.520 --> 01:17:18.240]   seemed to be, well, that's an easy thing to do that nobody will ever click. Look at that. That's
[01:17:18.240 --> 01:17:22.880]   the eye button. Yeah, you're going to click that button. Nobody's going to. And certainly nobody
[01:17:22.880 --> 01:17:29.360]   who agrees with the story. Only people who already disagree with it are going to click that button.
[01:17:29.360 --> 01:17:34.400]   Right? I mean, it's nice. I mean, it's nice. Let me ask Jeff, because Jeff, you really, this is
[01:17:34.400 --> 01:17:38.560]   you're on the forefront of this and ways to solve this. This is one of the things you suggested
[01:17:38.560 --> 01:17:44.160]   more contextual information. Is this what you were talking about? I think a button is
[01:17:44.160 --> 01:17:48.560]   difficult, but I do think that what Facebook has done that's from the beginning, we talked about
[01:17:48.560 --> 01:17:53.360]   this long ago before all this came up, is that when they have the related links, that's the more
[01:17:53.360 --> 01:17:59.920]   powerful mechanism. And the related link could be who's the source. I do think that that sourcing
[01:17:59.920 --> 01:18:05.360]   in all kinds of ways is important, positive and negative. But you're right. Readers are not going
[01:18:05.360 --> 01:18:12.160]   to nor should they be expected really to go do homework on every on every link. But before you
[01:18:12.160 --> 01:18:17.440]   share it, before you know, people don't even read the article before they share it. We know they
[01:18:17.440 --> 01:18:24.080]   share it based on the headline. Can we change? Can we change the norms? We're really into this system.
[01:18:24.640 --> 01:18:29.760]   You know, if it's the same as I've argued about trolling, if you if the troll needs their meds
[01:18:29.760 --> 01:18:36.800]   and they got problems, but the person who who gives attention to the troll is the person we have
[01:18:36.800 --> 01:18:42.320]   to reach out to. Similarly, yeah, people share crap. But at some point, should you be embarrassed
[01:18:42.320 --> 01:18:46.400]   that you did? It was wrong and you did it. Not if you're a master grind.
[01:18:46.400 --> 01:18:52.320]   Then that's different. Right. But at least we can get rid of some of this by saying, you know,
[01:18:52.320 --> 01:18:56.400]   did you know that came from like, it's the same. You know, I see people embarrassed all the
[01:18:56.400 --> 01:18:59.760]   times when they when they spread something and somebody says, Oh, they know, they died five years
[01:18:59.760 --> 01:19:05.360]   ago. What are you doing doing that again? Or that's on Snopes. And here it is. People of sense
[01:19:05.360 --> 01:19:13.200]   get embarrassed by this. I don't know if Neil deGrasse Tyson ever said this. But if he didn't,
[01:19:13.200 --> 01:19:18.160]   he ought to. The internet landed in our laps without creating a curriculum that empowers you
[01:19:18.160 --> 01:19:25.200]   to know when someone online is full of shit. I don't know if he said that, but boy, that's a good
[01:19:25.200 --> 01:19:31.920]   stick. Yeah, that's a good point. We don't really have what we don't we haven't been taught
[01:19:31.920 --> 01:19:37.200]   how to do this. I mean, having an eye buttons great, but that doesn't teach people to push it.
[01:19:37.200 --> 01:19:44.080]   Yeah, I also argue that. Go ahead. Let let let let let let let my go talk for a second.
[01:19:44.080 --> 01:19:50.720]   Yeah, just you know, the companies like Google and Facebook, their proposition to us all is that
[01:19:50.720 --> 01:19:55.440]   their algorithms are amazing that they do that they're able to do all these wonderful things.
[01:19:55.440 --> 01:20:00.880]   And there's got to be a way that a combination of downvoting things as you see on Reddit and
[01:20:00.880 --> 01:20:06.480]   that's true. Upvoting sources like, you know, if you, you know, if lots and lots of people are
[01:20:06.480 --> 01:20:10.480]   constantly saying, you know, this is this is a legitimate thing, you know, there's got to be a
[01:20:10.480 --> 01:20:19.120]   way to understand to link the behavior of the individual to their to their activity. And
[01:20:19.120 --> 01:20:24.000]   we're not talking about whether something can be posted. We're talking about whether something
[01:20:24.000 --> 01:20:30.480]   can be made viral, given the given the jet engine of a viral distribution that Facebook is capable
[01:20:30.480 --> 01:20:34.800]   of giving different types of news stories. If somebody posts it and two or three people see it or
[01:20:34.800 --> 01:20:40.400]   whatever, nobody cares about that. It's like, they should be very careful about which news stories
[01:20:40.400 --> 01:20:46.480]   which videos and so on go wildly viral on the site. That's that's really the key thing. And they're
[01:20:46.480 --> 01:20:52.000]   not really addressing the positive side of it. You know, what if they said, okay, look, if it's a
[01:20:52.000 --> 01:20:56.880]   story, a news related story, if it's current events or something like that, we're going to be super,
[01:20:56.880 --> 01:21:02.320]   super careful. Most of the stuff we're not going to allow to go crazy viral. But we're going to
[01:21:02.320 --> 01:21:09.200]   cherry pick sources. We're going to use the community behavior and our algorithms to identify the
[01:21:09.200 --> 01:21:14.000]   really good sources of information. We're going to let only those go crazy viral. Nobody's talking
[01:21:14.000 --> 01:21:19.280]   about that. They're just talking about whack-a-mole with the fake news. But why does everything with
[01:21:19.280 --> 01:21:22.720]   the get a lot gets a lot of likes automatically have to go crazy viral?
[01:21:22.720 --> 01:21:33.440]   You know, that's the definition of viral. I mean, the point is that is the feedback loop that
[01:21:34.400 --> 01:21:40.480]   works. In some ways, Twitter has tried to do the opposite thing and say, yes, there are these
[01:21:40.480 --> 01:21:46.400]   verified people and you can trust them. And that misses the point that a lot of the things that
[01:21:46.400 --> 01:21:52.160]   take off are started by someone who you wouldn't think had any influence, but somehow they've
[01:21:52.160 --> 01:21:56.720]   expressed something in a way that's pithy enough that other people retweet it and it was spread and
[01:21:56.720 --> 01:22:03.200]   jump from just them to their friends, them talking to the world in hours.
[01:22:03.920 --> 01:22:10.240]   And that is the challenge of this because those things can be great. They can also be false.
[01:22:10.240 --> 01:22:16.080]   They're often funny. But also, they can be devastating to the person who started them because suddenly
[01:22:16.080 --> 01:22:21.680]   there are 100,000 people trying to argue with them about it or take them on and they don't have the
[01:22:21.680 --> 01:22:23.680]   facilities to deal with that.
[01:22:23.680 --> 01:22:33.040]   Getting Amazon to buy you may not be a bad idea, but I don't think going on Twitter to beg is the
[01:22:33.040 --> 01:22:39.920]   best way to go about it. Carl's Jr. I wonder, maybe this is just a marketing campaign. Carl's
[01:22:39.920 --> 01:22:48.000]   Jr. is now begging using the hashtag Amazon buy us. Hey, Amazon for the next 24 hours, we're
[01:22:48.000 --> 01:22:56.080]   sharing one of our big ideas every hour on the hour trying to get a no joke. You like shipping
[01:22:56.080 --> 01:23:02.720]   boxes where we like filling them with food. Our logo smiles. Your logo smiles. Perfect fit. Hey,
[01:23:02.720 --> 01:23:08.560]   Amazon, this is from the official blue check marked Carl's Jr. Twitter feed. Amazon buy us.
[01:23:08.560 --> 01:23:12.880]   Seriously, for real, let's do this. Let's change the future of eating hashtag Amazon bias.
[01:23:12.880 --> 01:23:19.040]   They actually admitted Jeff Jenkins, the chief marketing officer, Carl's and its sister,
[01:23:19.040 --> 01:23:23.680]   Hardys told USA Today, the tweets are obviously a start to try and see where the dialogue goes.
[01:23:24.640 --> 01:23:31.920]   If I'm Jeff Bezos, you never get here as loud as you're never, you never go out with a girl that
[01:23:31.920 --> 01:23:39.120]   begs you. No, that's just not, it's just not a good way to get Amazon's attention.
[01:23:39.120 --> 01:23:46.640]   On the other hand, if you're a teenager, you may now be able to buy things on Amazon with your own
[01:23:46.640 --> 01:23:51.440]   account, as long as your parents say, okay, Amazon, which I didn't know this had apparently
[01:23:51.440 --> 01:23:58.480]   blocked a kids 13 to 17 from buying things on Amazon. They'll now be able to use an Amazon
[01:23:58.480 --> 01:24:02.720]   household account to shop the marketplace. Parents will be notified of each purchase via
[01:24:02.720 --> 01:24:07.200]   text or email. They will by default have the chance to approve or deny it and they can set
[01:24:07.200 --> 01:24:14.480]   spending limits. But speaking of begging, as they make the purchase, teens will be able to include a
[01:24:14.480 --> 01:24:22.640]   note that explains or begs why they need the particular item. Apparently, they say why or
[01:24:22.640 --> 01:24:27.440]   and this already goes on in our house, but it usually is a terrible position.
[01:24:27.440 --> 01:24:34.720]   We've got a shared prime account as well, but mostly what that means is when someone
[01:24:34.720 --> 01:24:38.800]   anyone buys anything, it just shows up in each other's target ads.
[01:24:38.800 --> 01:24:43.600]   Oh, that's really bad. Yeah, that's a good argument for getting a separate account.
[01:24:43.600 --> 01:24:48.960]   It's a nice time to buy a video game. It shows up in my time.
[01:24:48.960 --> 01:24:56.160]   Another problem, that's just Amazon's poor recommendation engine, by the way.
[01:24:56.160 --> 01:25:10.320]   Let's see, what else? Oculus, the Oculus event was today and Oculus connects fourth annual
[01:25:10.320 --> 01:25:19.200]   get together in San Jose. They announced a standalone $199 VR headset called the Oculus Go.
[01:25:19.200 --> 01:25:23.680]   It's really a lot like the Google Daydream or the Gear VR. It doesn't need a PC,
[01:25:23.680 --> 01:25:27.920]   but it doesn't need a phone either. It doesn't need wires. I can't imagine how this would even
[01:25:27.920 --> 01:25:34.560]   work. You ordered one yet? No, I'm not going to. You know what? I'm over VR.
[01:25:35.680 --> 01:25:43.680]   Really? Isn't it funny, Leo, that Oculus was
[01:25:43.680 --> 01:25:51.120]   a second now? We're all still waiting for the real VR.
[01:25:51.120 --> 01:25:59.520]   Oh, you're dropping every third word now, Michael. I can't really understand. Try one more time.
[01:26:00.400 --> 01:26:06.640]   I'm just going to say that I remember a couple years ago when Oculus was the future. VR was the
[01:26:06.640 --> 01:26:13.600]   future. The whole thing was about to just break into the world, change everything. But since then,
[01:26:13.600 --> 01:26:20.080]   augmented reality, mixed reality, et cetera, 360 video is clearly going to be such a so much
[01:26:20.080 --> 01:26:26.320]   bigger impact and wider use. I do, absolutely. Is this just the next?
[01:26:27.200 --> 01:26:30.560]   Another one that we're saying. The next big thing that won't go anywhere.
[01:26:30.560 --> 01:26:36.000]   This is another confirming story. Nokia made, remember, a $30,000 camera? We actually
[01:26:36.000 --> 01:26:40.640]   taped an episode of one of our shows with this, the Ozo. Was it Twig or Twit?
[01:26:40.640 --> 01:26:47.280]   The virtual reality camera? They're killing it. And 310 people are losing their jobs due to
[01:26:47.280 --> 01:26:51.840]   slower than expected development of the VR market. And the fact that it cost $30,000?
[01:26:54.480 --> 01:27:01.040]   Then I'm sorry, did I say $30,000? $60,000? Although they did reduce the price to $45,000.
[01:27:01.040 --> 01:27:04.320]   So Alex Lindsay, I think bought several of these.
[01:27:04.320 --> 01:27:12.480]   Wow. You got to be careful in this business. You can easily get sucked in by something that
[01:27:12.480 --> 01:27:17.440]   seems really, you know, you're right. augmented reality has a lot of promise. But remember,
[01:27:17.440 --> 01:27:22.080]   it wasn't the Apple event going to be the big thing, Mike, that was scoble told me it's going to be
[01:27:22.080 --> 01:27:27.200]   the breakthrough for AR. It's going to, oh my God. And notice how AR is just taken off
[01:27:27.200 --> 01:27:33.360]   every since Apple's iPhone 8? Not. Well, I think what's going to happen is it's kind of like
[01:27:33.360 --> 01:27:39.600]   the when the app store first hit for the iPhone, you know, the first few months was like, you know,
[01:27:39.600 --> 01:27:43.040]   this is kind of cool. There's this, that and the other thing. But I think over the next couple of
[01:27:43.040 --> 01:27:48.800]   years, we're going to see more and more phone apps and tablet apps have augmented reality that's
[01:27:48.800 --> 01:27:54.720]   practical. Things like you can measure you use a measuring tape to measure a cabinet using your
[01:27:54.720 --> 01:28:01.280]   phone. Well, that's kind of amazing. And you know, it'll be sort of step wise. I do believe that,
[01:28:01.280 --> 01:28:06.480]   you know, I think, you may never know what he believes.
[01:28:06.480 --> 01:28:14.400]   Well, I mean, I don't think it's coming soon. Hold on a second. Let me get Mike to say whatever
[01:28:14.400 --> 01:28:21.200]   it is he believes. One more time we can edit out the gap. Yeah, I do think that Augment reality is
[01:28:21.200 --> 01:28:26.720]   going to make a huge impact. Not this year, not next year. It's coming by the time we're, you know,
[01:28:26.720 --> 01:28:32.080]   completely think it's mundane. It'll definitely be here changing the world.
[01:28:32.080 --> 01:28:35.920]   Kevin, you've been through this, you know, technology that we're going to change the world and didn't
[01:28:35.920 --> 01:28:43.040]   and some that did. What do you think? I think it's coming in via photography. I mean, Snapchat is
[01:28:43.040 --> 01:28:47.680]   actually the biggest AR company because they do all this weird face modification stuff that people
[01:28:47.680 --> 01:28:53.600]   create in post. And that's that's true. What reality if you think about doing that. And if you
[01:28:53.600 --> 01:28:58.960]   look at the way that it's moving into the cameras with both the app, the Apple's face scanner and
[01:28:58.960 --> 01:29:05.840]   Google's applying AI to to do photo processing things like that, we're starting to see that
[01:29:05.840 --> 01:29:11.200]   see it happen in that space. So that's that's where I think it will end up being showing up in
[01:29:11.200 --> 01:29:17.040]   those practical spaces first rather than requiring us to strap things to our faces again, which is
[01:29:17.040 --> 01:29:22.240]   is a big ask. That's the piece that's been difficult about this. And Zuckerberg turned himself into
[01:29:22.240 --> 01:29:27.680]   a cartoon and going up to his waist in in virtual water where real water but virtual him is not
[01:29:27.680 --> 01:29:35.360]   helping any of this. Really water but virtual him. This is actually an interesting here's the first
[01:29:35.360 --> 01:29:39.840]   AR app on the iPhone. By the way, it's also available on Android that I actually kind of liked. And
[01:29:39.840 --> 01:29:44.400]   Megan Maroney showed me this yesterday on iOS today. It's from a company called View Fory. It's
[01:29:44.400 --> 01:29:49.520]   called chalk and you have the app on your phone, you could be on your Android phone and you pointed
[01:29:49.520 --> 01:29:54.800]   at something. Let's say you're at an Airbnb, Mike and you're and you and they've got a remote control.
[01:29:54.800 --> 01:30:00.720]   You don't know how to get the TV working. So you you call them up. They have the chalk app. You
[01:30:00.720 --> 01:30:06.400]   have the chalk app and you say, let me show you this remote control. What buttons should I push?
[01:30:07.280 --> 01:30:14.000]   And then they can actually use their finger or pen. Let's see if it shows it here on this video.
[01:30:14.000 --> 01:30:20.640]   To circle the buttons to point to the buttons, you're pointing your camera at the thing they need to do.
[01:30:20.640 --> 01:30:25.920]   The thing you want to understand and they're drawing on it to show you how to use it.
[01:30:25.920 --> 01:30:32.320]   Then I think is really interesting. That's kind of cute. Yeah. It's kind of a crowd show for
[01:30:32.320 --> 01:30:36.400]   grandparents. If you could teach the grandparents how to use chalk, you need the chalk to teach them
[01:30:36.400 --> 01:30:41.120]   to use chalk. It's the funny that you should say that because that was on our episode of
[01:30:41.120 --> 01:30:45.120]   apps for your parents, for your elders, how to show them how to do stuff.
[01:30:45.120 --> 01:30:54.880]   I think it's kind of interesting. It's on chalk.viewforia.vuforia.com and it's Android or iOS.
[01:30:54.880 --> 01:31:00.400]   That was after I've tried all the apps on iPhone 8. That's the first one I've seen that I thought,
[01:31:00.400 --> 01:31:06.320]   oh, that might be useful, not wildly useful, but it might be that might have some value.
[01:31:07.200 --> 01:31:11.840]   I think the best thing you could say about AR is it doesn't make you nauseous.
[01:31:11.840 --> 01:31:21.920]   Well, that's nauseous. If it's got lag, it makes you pretty nauseous because you're trying to
[01:31:21.920 --> 01:31:28.720]   see the real world. It's not quite all good AR. Let's see.
[01:31:28.720 --> 01:31:34.320]   If Williams is back reinventing journalism, let's try this one more time.
[01:31:34.320 --> 01:31:43.680]   He says, "Anybody who writes on Medium now will be able to put their articles behind a pay wall."
[01:31:43.680 --> 01:31:47.360]   Jeff Jarvis, you've, I think, I don't know. You like Medium, but I think you've
[01:31:47.360 --> 01:31:54.080]   had mixed feelings about this new-- I'm on Medium to get more social coverage,
[01:31:54.640 --> 01:31:59.120]   not less. I know I'm not going to make any money with my Blatherings, and I'm frustrated that I
[01:31:59.120 --> 01:32:06.240]   can't read some of the stuff that I want to read. I love you. I think the world of them,
[01:32:06.240 --> 01:32:09.920]   and he's changed the world twice, and I'm never going to bet against them, but I don't think we're
[01:32:09.920 --> 01:32:16.800]   there yet. So far, since the company expanded its partner program to the end of August, 83% of
[01:32:16.800 --> 01:32:23.680]   the publishers of participants who published at least one member's only story earned money,
[01:32:23.680 --> 01:32:31.760]   83%. The average amount earned $93.65. It doesn't sound like riches, but it's better than nothing.
[01:32:31.760 --> 01:32:33.600]   The most--
[01:32:33.600 --> 01:32:40.960]   Most any single author received in September was $2,279.12. Now that's decent money.
[01:32:44.320 --> 01:32:46.880]   It's not much for a professional journalist, is it?
[01:32:46.880 --> 01:32:53.120]   No. Right. What they don't tell you is what percentage of the world's population
[01:32:53.120 --> 01:32:59.680]   they hid that article from, because no people in certain countries or certain economies are
[01:32:59.680 --> 01:33:06.320]   not going to spend money on your-- That's, of course, Jeff's point, which is he'd rather get
[01:33:06.320 --> 01:33:10.880]   people seeing it than paying for it. And that's what we do here. We give this away.
[01:33:12.960 --> 01:33:17.200]   Let's support advertising and figure out how to make advertising work. Let's not figure out how
[01:33:17.200 --> 01:33:22.080]   to make these little elite bubbles even worse. Yeah. Well, I'm going to fight a different direction
[01:33:22.080 --> 01:33:26.000]   with that. I'd say find a way to get people to pay for things that doesn't require putting
[01:33:26.000 --> 01:33:30.720]   behind a paywall behind a wall. That's the piece that's-- The payment bar is interesting,
[01:33:30.720 --> 01:33:36.560]   but the wall part is boring. And I can't touch you. My dog has just put my headphones out.
[01:33:36.560 --> 01:33:42.240]   Oh, poodles. What are you going to do? What can you do with a poodle? Let's take a break while
[01:33:42.240 --> 01:33:45.760]   Kevin Marks puts his headphones back in. We're going to get your picks of the week, gentlemen.
[01:33:45.760 --> 01:33:49.920]   When we come back or your number or whatever it is, whatever, final thoughts you have our
[01:33:49.920 --> 01:33:55.760]   show today brought to you by rocket mortgage from quick and loans. You know, if you are buying a
[01:33:55.760 --> 01:34:00.320]   new home or you're refinancing your home, you're about to enter into the Twilight Zone submitted
[01:34:00.320 --> 01:34:09.440]   for your approval. A normal couple trying to buy a new home trapped by the bank for months.
[01:34:10.160 --> 01:34:16.000]   That was me and Lisa four years ago when we tried to buy our house. The house we're living in now,
[01:34:16.000 --> 01:34:22.240]   we went to the big bank, the number one lender in the country. You know the bank. And we figured
[01:34:22.240 --> 01:34:27.040]   we're going to vacation in a couple of-- I think it was four weeks. This will be over by then.
[01:34:27.040 --> 01:34:32.960]   No. No. They wanted more materials, more materials. We had to fax them stuff. We had to fax them
[01:34:32.960 --> 01:34:38.720]   stuff from the vacation. Lisa had to call her sister, said, "Debbie, can you please fax them
[01:34:38.720 --> 01:34:43.760]   some stuff they need more?" It took more than a month to get a home loan. That was my friend's
[01:34:43.760 --> 01:34:51.280]   2013. Today in 2017, we have a better way. We have rocket mortgage from quick and loans. First of
[01:34:51.280 --> 01:34:55.520]   all, the S, the number two lender in the country. All right. I'm in it number two in size, but number
[01:34:55.520 --> 01:34:59.760]   one in your heart's number one in the JD Power Customer Satisfaction Award year after year after year
[01:34:59.760 --> 01:35:04.800]   after year for seven consecutive years. And I'll get it again this year. I guarantee you both for
[01:35:04.800 --> 01:35:11.200]   primary mortgage origination and mortgage servicing. Rocket mortgage is a creation of
[01:35:11.200 --> 01:35:15.440]   quick and loans. They said, "We got to make this-- we got to bring this loan process into the 21st
[01:35:15.440 --> 01:35:20.560]   century. What if you could do it all online? What if you could do it not in months or weeks or days
[01:35:20.560 --> 01:35:27.200]   or even hours but in minutes without going into the attic to find your pay stubs or your bank statements?
[01:35:27.200 --> 01:35:32.160]   This is Rocket Mortgage. You go online, you do it on your phone, you do it on your tablet,
[01:35:32.160 --> 01:35:37.840]   your computer. You could do it at an open house because it's so fast. You're feeling a few simple
[01:35:37.840 --> 01:35:43.200]   questions because of their trusted partnerships with all the financial institutions. Rocket
[01:35:43.200 --> 01:35:49.040]   mortgage can get the information they need to crunch the numbers with your permission. Once they
[01:35:49.040 --> 01:35:52.800]   do that based on your income assets and credit, literally in minutes, they will analyze all the
[01:35:52.800 --> 01:35:56.800]   home loan options for which you qualify and make you an offer. Find the one that's just right for you.
[01:35:56.800 --> 01:36:02.560]   You choose the term, you choose the rate, you choose the down payment, you get the loan minutes
[01:36:02.560 --> 01:36:07.680]   later. Rocket mortgage from quick and loans, whether you're refinancing and now's a very good
[01:36:07.680 --> 01:36:14.160]   time to do it, by the way, or buying a new home, apply simply, understand fully and mortgage
[01:36:14.160 --> 01:36:18.560]   confidently with Rocket Mortgage from Quick and Loans. Rocket Mortgage.com/twig, you're probably
[01:36:18.560 --> 01:36:22.560]   not buying a home this very, very minute but if you're thinking about it or maybe you're shopping
[01:36:22.560 --> 01:36:29.120]   around, please bookmark that URL so you can use it when the time comes. Rocket Mortgage.com/twig.
[01:36:29.120 --> 01:36:34.480]   The number one tip I would give anybody who's looking to buy a house is get a pre-approved for
[01:36:34.480 --> 01:36:40.480]   a loan. It puts you in front of the line. It's a competitive thing these days by in the house.
[01:36:40.480 --> 01:36:45.520]   Get in front of the line. Rocket Mortgage.com/twig, equal housing, lender, license, and all 50 states
[01:36:45.520 --> 01:36:52.640]   and MLS consumer access.org number 3030. Book market. Rocket Mortgage.com/twig and we thank
[01:36:52.640 --> 01:36:57.600]   them so much for their support. Kevin Marks, I feel bad. We hardly had much from you today.
[01:36:57.600 --> 01:37:04.320]   Got to you late, but I'm glad you always welcome and I know it's like the middle of the night.
[01:37:04.320 --> 01:37:09.040]   So thank you for staying up late with your poodle. Well, the poodles of Waynes be fat as well.
[01:37:09.040 --> 01:37:17.280]   Oh dear. Thanks to Grumpy with me at the moment. Oh dear. Well, you have anything to plug with
[01:37:17.280 --> 01:37:23.120]   the open web? Anything you'd like to let us know about? Well, the usual thing is to go to
[01:37:23.120 --> 01:37:30.640]   indyweb.org and see what the upcoming indie webcams and home website clubs are. There's a few of
[01:37:30.640 --> 01:37:35.200]   those there. We'd like to promote that. I owe a big favor of the open web. Big fan.
[01:37:36.160 --> 01:37:41.520]   Well, people are starting to think about this again. It's interesting to see
[01:37:41.520 --> 01:37:46.000]   people start to say, "What if there's something that wasn't Facebook?" So you're like, "Yep,
[01:37:46.000 --> 01:37:51.120]   we're here waiting for you when you want to think about that." When you're ready for an open web.
[01:37:51.120 --> 01:37:55.840]   But you said you were going to give us that foundation pick and I do want that.
[01:37:55.840 --> 01:38:02.720]   So the foundation link, the best place to get it is on the Internet Archive. If you search that
[01:38:02.720 --> 01:38:11.120]   for BBC Foundation or I made a short link, J.MP/capital BBC found, and it's an eight-part
[01:38:11.120 --> 01:38:16.240]   adaptation of the whole trilogy. So it's a little bit compressed, each eight-hour long episodes.
[01:38:16.240 --> 01:38:24.160]   And this was made in 1973. So it's a reasonably faithful adaptation. It gets most of the original
[01:38:24.160 --> 01:38:28.080]   stuff, so they cut a few bits here and there. But it's also got a great classic radiophonic
[01:38:28.080 --> 01:38:36.080]   workshop soundtrack from the D.V.E.E.E.E.E. area. So it has that sort of futuristic
[01:38:36.080 --> 01:38:44.240]   thing that you get from 1970s to BBC. So I listened to it sometime last year and it's a fun listen.
[01:38:44.240 --> 01:38:50.240]   The BBC does an amazing amount of drama. There's actually a BBC drama for the week podcast
[01:38:50.240 --> 01:38:55.120]   that I recommend that's worth subscribing to because it'll give you something to listen to
[01:38:57.520 --> 01:39:05.440]   regular intervals as well. And they produce probably something, some radio play every day,
[01:39:05.440 --> 01:39:13.280]   something there. They've also done great adaptations recently of a couple of Neil
[01:39:13.280 --> 01:39:20.640]   Gaming novels that are up there. So there's a bunch of really good stuff in the BBC's archives
[01:39:20.640 --> 01:39:25.680]   and they sort of get in the hang of the podcasting there. So my broader recommendation is
[01:39:26.720 --> 01:39:30.480]   go to the BBC and look for podcasts there because you'll find something good.
[01:39:30.480 --> 01:39:38.320]   You know, it's just reminded me as long as you're talking about this. RTE, which is, I guess,
[01:39:38.320 --> 01:39:43.040]   it's the Irish radio? Yes, it's the Irish BBC effectively. Irish BBC.
[01:39:43.040 --> 01:39:50.400]   The TV, Telethys Aeren. Yeah. Has a phenomenal reading of James Joyce Ulysses that has widely
[01:39:50.400 --> 01:39:58.400]   agreed. I was looking for... Now calm down. It's okay. How long does that go?
[01:39:58.400 --> 01:40:06.480]   Oh, it's pretty long. I was looking for a good version of Ulysses and Audible literally has four
[01:40:06.480 --> 01:40:12.720]   or five various readings and so forth. But I searched around and widely agreed that the RTE's
[01:40:12.720 --> 01:40:20.240]   version is the best and there happens to be a copy of it on Internet Archive as you...
[01:40:20.240 --> 01:40:25.760]   That's what reminded me of this. And actually there's two versions you're going to want to get the
[01:40:25.760 --> 01:40:34.560]   the little bit higher resolution VBR MP3 version of it. But it's dramatized. It's quite good. I have
[01:40:34.560 --> 01:40:39.680]   to say and I've been listening to it. It's not, you know, it is a hard book but in some ways it's
[01:40:39.680 --> 01:40:45.120]   easier to listen to it especially if it's acted out. It kind of comes alive and who better to act
[01:40:45.120 --> 01:40:50.960]   it out than RTE? So as long as you're in the Internet Archive and you're looking and you can
[01:40:50.960 --> 01:40:58.400]   also buy this on the CDs directly from RTE. It was recorded in 1982 to celebrate the
[01:40:58.400 --> 01:41:03.920]   centenary of James Joyce and it's a full dramatized production. I think it's unabridged. I think it's
[01:41:03.920 --> 01:41:11.040]   everything. It's very long. So basically they read the text but then they had actors do all the
[01:41:11.040 --> 01:41:20.240]   voices and so forth. Pretty, pretty good. Pretty good. You don't want you but watch it. Yes.
[01:41:20.240 --> 01:41:25.760]   What do you think of it by the way? I'm not sure I like it. I always like it. Yeah, he's great.
[01:41:25.760 --> 01:41:33.680]   We're talking about Kirby enthusiasm. Yeah. So Archive.org has the 1973 BBC Foundation
[01:41:34.400 --> 01:41:40.320]   trilogy but you can also go to BBC.co.uk/podcast and subscribe to the drama of the week.
[01:41:40.320 --> 01:41:44.480]   Is that what which BBC channel is that on?
[01:41:44.480 --> 01:41:52.800]   That's Channel 4. Channel 4? Okay. There's a study of BBC Radio 4. There's also separate Radio 3
[01:41:52.800 --> 01:41:57.840]   dramas as well which tends to be slightly more classical. BBC Radio 3 is the classical stuff
[01:41:57.840 --> 01:42:02.640]   so they will do adaptations whereas the BBC Drive the week is due to the original drama.
[01:42:02.640 --> 01:42:07.680]   Okay. I'm all in this one, two, three, four. I'm all confused which is which. Some are music,
[01:42:07.680 --> 01:42:11.440]   some are spoken word. BBC 4 is the one that has all the all this.
[01:42:11.440 --> 01:42:19.520]   Radio 4 is spoken word. Radio 3 is mostly classical music and one and two are two is easy listening
[01:42:19.520 --> 01:42:25.840]   and one is pop. Yeah. I don't listen to that. What's nice though? This is through the iPlayer
[01:42:25.840 --> 01:42:30.320]   and what's nice is even though I'm in the US I am able to listen to it so they don't have the
[01:42:31.120 --> 01:42:34.400]   geographic restrictions that they do on the video stuff on the iPlayer.
[01:42:34.400 --> 01:42:40.400]   There's a mixture there. There is a BBC Radio iPlayer app that has quite a lot of stuff.
[01:42:40.400 --> 01:42:48.400]   The challenges a lot of the iPlayer rules are available for one week only so you actually
[01:42:48.400 --> 01:42:52.800]   have to listen to it that week whereas some of the podcasts have deeper archives.
[01:42:54.160 --> 01:43:01.840]   One of the best is BBC in our time which they basically do live a 45 minute seminar on something
[01:43:01.840 --> 01:43:08.160]   every week and there's about 400 of those up that you've been listening to. So if you want to learn
[01:43:08.160 --> 01:43:14.400]   all about James Joyce or something that they've covered, something historical, it's like history,
[01:43:14.400 --> 01:43:20.640]   science, art, culture. You basically get a 45 minute seminar led by a Melvin Bragg with three
[01:43:20.640 --> 01:43:25.440]   academics explaining it and they've spent a week getting it down a full-time minutes. They do it
[01:43:25.440 --> 01:43:31.680]   live and they put the podcast up. Nice. And that's another one of these things that it's nice to
[01:43:31.680 --> 01:43:37.040]   have in your podcast because once a week you get a brain dump on something and it's usually
[01:43:37.040 --> 01:43:42.240]   interesting and it's usually very well produced. It's not the complete foundation trilogy.
[01:43:42.240 --> 01:43:50.080]   Oh wow. They do it in eight hours which is quite tight for the trilogy. I think the audio book is
[01:43:50.080 --> 01:43:55.920]   quite a bit longer. Oh yeah. Oh yeah. So it's abridged. It's a little abridged.
[01:43:55.920 --> 01:44:03.040]   And by the way, archive.org has so much great stuff on there. What a great site. I mean,
[01:44:03.040 --> 01:44:08.800]   you can use HyperCard on a Macintosh. It's incredible.
[01:44:08.800 --> 01:44:15.840]   Another archive that I've talked about this week is they've just found that it's legal to
[01:44:15.840 --> 01:44:21.680]   post books that were out of print in the US that are out of print. Sorry that were published between
[01:44:21.680 --> 01:44:28.400]   1923 and 1941 if you're a library which they claim they are. So they're busy digitizing every
[01:44:28.400 --> 01:44:34.320]   book published in the US between 1923 and 1941 that is not in print anymore. Wow. That's this
[01:44:34.320 --> 01:44:40.480]   week's time. Which is going to be a fascinating slice of time. And I just noticed this ad on
[01:44:40.480 --> 01:44:47.120]   Facebook. They also have a very large collection of Russian audio books just in case you would like
[01:44:47.120 --> 01:44:53.360]   to rush rush up your rush. You might useful useful in case you don't get enough Russian
[01:44:53.360 --> 01:45:01.120]   content on Facebook. Jeff Jarvis, your number of the week. So I like this one. I got a look over
[01:45:01.120 --> 01:45:11.360]   here. So Google, so two, a couple of researchers, Feng Li, Yong Xi and Ying Liu, according to Boin
[01:45:11.360 --> 01:45:19.600]   Boing, tested the IQs of the various AI systems. Google came out on top with an IQ of 47.28
[01:45:19.600 --> 01:45:26.640]   doubling Siri. Take that fanboys, which had the 23-point-9-4.
[01:45:26.640 --> 01:45:33.440]   Jeff, 47 is not very bright either. I mean, it's an actual moron. It's an actual moron.
[01:45:33.440 --> 01:45:41.360]   Okay. But it's the best of the bunch. Yeah, that is. Bing is only 31.98. How do you test an
[01:45:41.360 --> 01:45:46.080]   IQ of an artificial intelligence? I didn't have a chance to look at the whole paper and figure out
[01:45:46.080 --> 01:45:54.640]   the methodology. What an interesting idea. What an interesting idea. So Google's AI, Google
[01:45:54.640 --> 01:46:01.280]   Assistant has a 47 and a quarter IQ. You obviously pick the IQ test you could program it to,
[01:46:01.280 --> 01:46:07.040]   as Donald Trump evidently said, get 100. But no, he didn't say get 100, did he?
[01:46:07.040 --> 01:46:10.960]   He said I had a perfect score. I had a perfect score on my IQ test.
[01:46:10.960 --> 01:46:23.200]   Mike Elgin, pick of the week. Yes. So I, unlike a lot of my fellow tech journalists,
[01:46:23.200 --> 01:46:26.080]   was not particularly impressed by Google Pixel Buds.
[01:46:26.080 --> 01:46:30.000]   Really? See, I would think in Georgia, they'd be so useful.
[01:46:30.000 --> 01:46:35.760]   Well, you know, I'm not impressed by the translation feature in particular. People are saying,
[01:46:35.760 --> 01:46:42.400]   oh, with the Pixel Buds, it translates languages. No, it doesn't. Google translates languages,
[01:46:42.400 --> 01:46:47.040]   and it's brilliant. I recommend that everybody use Google Translate. What the Pixel Buds actually
[01:46:47.040 --> 01:46:54.720]   do if you have a Pixel is they'll take the sound of the translation that's incoming to you and put
[01:46:54.720 --> 01:46:59.200]   it in earbuds. So they're not doing any work, I understand. Yeah, it's not that impressive.
[01:46:59.200 --> 01:47:04.320]   Let's face it, folks, you're not going to use that feature. I'm not going to use that feature.
[01:47:04.320 --> 01:47:09.760]   And I'm always living in countries where people speak a foreign language. As earbuds,
[01:47:10.400 --> 01:47:18.080]   they're dramatically inferior to earbuds, Apple's AirPods, which I think are one of the best Apple
[01:47:18.080 --> 01:47:23.920]   products since the iPad, they're phenomenal. I love them. And you can use them with an Android
[01:47:23.920 --> 01:47:30.080]   phone. But here's the problem. The way they work on an iPhone when you use AirPods is you double
[01:47:30.080 --> 01:47:35.120]   tap and you get Siri. Okay, Siri is obviously, as we just learned, super dumb. You don't want to
[01:47:35.120 --> 01:47:43.040]   use Siri. You want to use Google Assistant, right? So there is an application, there's an app for
[01:47:43.040 --> 01:47:51.280]   Android on the Play Store called AirPods4GA. Oh, and it's a free app. You download it. And once
[01:47:51.280 --> 01:47:56.160]   you have this and you're using AirPods with an Android phone, you double tap on the AirPods and
[01:47:56.160 --> 01:48:03.360]   you get Google Assistant. Oh, so that's interesting. Because remember, Neelai Patel was saying that
[01:48:03.360 --> 01:48:10.640]   really the pixel buds in the AirPods and the lack of a headphone jack is really about creating
[01:48:10.640 --> 01:48:16.960]   kind of walls between these different platforms. So that you... That's still true. Yeah. That's
[01:48:16.960 --> 01:48:22.720]   true in terms of the optimization. So AirPods are not optimized for Android. You can use them. They're
[01:48:22.720 --> 01:48:29.280]   great. The AirPods as a hardware product are super slick. The batteries and all that stuff is
[01:48:29.280 --> 01:48:35.120]   fantastic. They're not optimized. You can use them. It's not quite as good of an experience as on
[01:48:35.120 --> 01:48:40.000]   the iPhone, but it's probably better than Google Pixel Buds, I'm guessing, in general.
[01:48:40.000 --> 01:48:44.880]   And again, double tapping for the Google Assistant is a pretty key feature, I think.
[01:48:44.880 --> 01:48:50.880]   All right. Nice picks. I'm going to tell you a couple of things coming up
[01:48:50.880 --> 01:48:56.000]   because I don't want you to miss them Friday on triangulation. Triangulation has moved to a
[01:48:56.000 --> 01:49:02.640]   new time, 3 p.m. Fridays, 3 p.m. Pacific, 6 p.m. Eastern, 2200 UTC. And I know many of you are
[01:49:02.640 --> 01:49:08.560]   fans of the Expanse series on SciFi and the SciFi network. Daniel Abraham will be joining us.
[01:49:08.560 --> 01:49:15.120]   Is that right? Carson, this Friday with Father Robert Ballisare, he'll be interviewing
[01:49:15.120 --> 01:49:24.000]   Daniel Abraham, the author of The Expanse on Friday. That's a big one. That is one you do not
[01:49:24.000 --> 01:49:30.240]   want to miss, but we have some really exciting triangulations coming up. The following week,
[01:49:30.240 --> 01:49:36.000]   on October 20th, I'll be interviewing Philippe Kahn, who is absolutely legendary in this business.
[01:49:36.000 --> 01:49:41.120]   I know Mike Elgin, you probably know Philippe not only for his great saxophone work. He's a
[01:49:41.120 --> 01:49:47.760]   sailor, but he started a little thing called Borland, which transformed the computer industry
[01:49:47.760 --> 01:49:52.960]   back in the '90s. And I don't know if people know this widely, but without Philippe Kahn,
[01:49:52.960 --> 01:49:58.000]   I don't know if we would have camera phones. He originated the technology, patented it,
[01:49:58.000 --> 01:50:03.600]   and I think still reaps the rewards of inventing technology that was vital to the camera phone.
[01:50:03.600 --> 01:50:08.240]   So that'll be very exciting. The following week, we're going to talk about
[01:50:08.240 --> 01:50:15.680]   a new technology, gallium nitride technology, that's going to make a massive difference
[01:50:15.680 --> 01:50:20.640]   in technology and computing and processors. But right now, in amplifiers and FinFets,
[01:50:22.160 --> 01:50:25.680]   and then Scott Galloway, we've been talking about Scott Galloway's article.
[01:50:25.680 --> 01:50:31.760]   He has a new book called The Four, The Hidden DNA of Amazon, Apple, Facebook, and Google.
[01:50:31.760 --> 01:50:36.880]   He wrote the article that said that you talked a lot about, Mike actually, you wrote about it,
[01:50:36.880 --> 01:50:43.760]   that said that Silicon Valley is losing the faith and it's basically losing its reputation
[01:50:43.760 --> 01:50:48.240]   in the rest of the world. And he was the guy who said it's just a matter of time before
[01:50:48.240 --> 01:50:52.320]   governments really start cracking down on Google and Amazon. He'll be Jason Howell
[01:50:52.320 --> 01:50:56.800]   interviewing him on November 3rd. So we have some really big...
[01:50:56.800 --> 01:50:57.520]   Good bunch.
[01:50:57.520 --> 01:51:01.520]   Yeah, well, and let's not forget Andy Weir coming up November 17th, the author of The Martian.
[01:51:01.520 --> 01:51:05.760]   He's got a brand new book. We'll talk about that. So make sure you tune in triangulation
[01:51:05.760 --> 01:51:11.280]   at its new time almost every week in the next few weeks is just huge. 3PM Pacific's
[01:51:11.280 --> 01:51:17.520]   6PM Eastern, 2200 UTC on its new time Fridays. I don't want to give it a bit of a plug.
[01:51:18.480 --> 01:51:22.480]   And I want to thank you all for being here. Kevin Marks, staying up late in Yorkshire.
[01:51:22.480 --> 01:51:28.720]   Thank you, sir. indieweb.org. Always a pleasure. Nice to have you here today.
[01:51:28.720 --> 01:51:29.840]   From Berlin.
[01:51:29.840 --> 01:51:30.400]   Great to be here again.
[01:51:30.400 --> 01:51:31.360]   It's so sweet.
[01:51:31.360 --> 01:51:35.040]   No, no, no, that's fine. I'm just sorry we didn't have more for you to talk about today.
[01:51:35.040 --> 01:51:39.120]   Jeff Jarvis joining us all the way from Berlin where it's equally late.
[01:51:39.120 --> 01:51:43.840]   We're going to let him... Are you staying in an Airbnb? That's not a hotel, is it?
[01:51:44.480 --> 01:51:49.520]   It is a hotel that's pretty tacky behind me. I now see yes, but that won't pay for it.
[01:51:49.520 --> 01:51:54.720]   It's at the hotel is actually nice. The conference and the Wi-Fi is good. The conference
[01:51:54.720 --> 01:51:59.280]   forgot to make my hotel reservation. So I used hotels tonight and got something fast.
[01:51:59.280 --> 01:52:03.200]   It's very good. Very good Mutlekite or something. I don't know what it is.
[01:52:03.200 --> 01:52:08.000]   Yeah, it's a little tacky. I like it. No, I like it. I'm like...
[01:52:08.960 --> 01:52:14.080]   And then all the way from Tbilisi, Georgia on the Black Sea. Amazing. Mike Elgin, we had a
[01:52:14.080 --> 01:52:22.160]   great international family today. Mike is of course planning his next food assault at gastronomad.net.
[01:52:22.160 --> 01:52:26.720]   They had a great success in Barcelona. Next it's the south of France. I'm sorry, Italy,
[01:52:26.720 --> 01:52:31.200]   then the south of France. And who knows? Where's next? It's great to see you again.
[01:52:31.200 --> 01:52:32.160]   That's right.
[01:52:32.160 --> 01:52:37.200]   Oh, I just... We just found out that the best restaurant in the world is just around the
[01:52:37.200 --> 01:52:40.560]   corner from us here according to...
[01:52:40.560 --> 01:52:42.480]   That's not the official trip advisor.
[01:52:42.480 --> 01:52:45.440]   Oh, trip advisor. What is the best restaurant in the world?
[01:52:45.440 --> 01:52:47.200]   What is the best restaurant in the world?
[01:52:47.200 --> 01:52:49.600]   It is the Black Swan at Oldfield.
[01:52:49.600 --> 01:52:55.680]   No, wait a minute. That sounds like there's some shenanigans going on.
[01:52:55.680 --> 01:52:57.200]   Yeah. What's going to look now?
[01:52:57.200 --> 01:53:00.640]   Is it that good?
[01:53:00.640 --> 01:53:05.040]   No, it's basically... I've not actually been there.
[01:53:06.320 --> 01:53:14.160]   But it's run by this nice, unassuming guy who does very good local food and has won a place on
[01:53:14.160 --> 01:53:20.240]   like top chef competitions in the UK, like a real one, not one of the fake ones.
[01:53:20.240 --> 01:53:26.240]   And so I imagine this is the kind of place you go to think this is actually really amazing
[01:53:26.240 --> 01:53:28.960]   because it is in the middle of nowhere and you don't expect it there.
[01:53:28.960 --> 01:53:33.440]   But it's basically got the top ranked one on a trip advisor worldwide.
[01:53:33.440 --> 01:53:35.360]   Wow.
[01:53:35.360 --> 01:53:36.320]   So it's all right.
[01:53:36.320 --> 01:53:38.160]   All right. Old stead. Yeah.
[01:53:38.160 --> 01:53:39.040]   Old stead, yes.
[01:53:39.040 --> 01:53:41.280]   Okay, I'm on my way.
[01:53:41.280 --> 01:53:43.840]   And you get to go see...
[01:53:43.840 --> 01:53:48.640]   Look at that. That's even nicer than your hotel room.
[01:53:48.640 --> 01:53:52.960]   Okay, you can say the night too.
[01:53:52.960 --> 01:53:55.520]   Thank you everybody.
[01:53:55.520 --> 01:53:57.200]   It's kind of a book now.
[01:53:57.200 --> 01:53:57.520]   Yeah.
[01:53:57.520 --> 01:54:00.400]   Yeah, I bet it is. Best restaurant in the world.
[01:54:00.400 --> 01:54:03.440]   Thank you all for joining us.
[01:54:03.440 --> 01:54:07.760]   We do this week in Google every Wednesday, 130 Pacific, 430 Eastern, 2030 UTC.
[01:54:07.760 --> 01:54:09.520]   I hope you'll stop by and say hi, do it live.
[01:54:09.520 --> 01:54:12.080]   That way you can go to the chatroom@irc.twit.tv.
[01:54:12.080 --> 01:54:16.400]   But if you got things to do and I understand, you can always get it on demand.
[01:54:16.400 --> 01:54:21.600]   Just go to the T-W-I-T-V, twit.tv/twig.
[01:54:21.600 --> 01:54:23.840]   And you can download episodes.
[01:54:23.840 --> 01:54:29.200]   You can subscribe there to listen every week in your favorite podcatcher like pocket casts or
[01:54:29.200 --> 01:54:32.240]   overcast or iTunes, whatever you like to listen to.
[01:54:32.240 --> 01:54:33.920]   We don't want to miss you.
[01:54:33.920 --> 01:54:36.560]   So please come by each and every week, subscribe.
[01:54:36.560 --> 01:54:37.520]   Thanks for joining us.
[01:54:37.520 --> 01:54:44.480]   And we'll see you next time, whether it be Tbilisi or Oldstead on this week in Google.
[01:54:44.480 --> 01:54:54.960]   Bye.

