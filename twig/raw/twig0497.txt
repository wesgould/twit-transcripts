;FFMETADATA1
title=Hermione Said So
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=497
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.520]   It's time for Twig this week at Google. Jeff Jarvis is out of the country, but we are
[00:00:05.520 --> 00:00:09.800]   fortunate to have Aunt Pruitt join us along with Stacey Higginbotham. We'll talk about
[00:00:09.800 --> 00:00:16.520]   folding phones. We'll talk about 5G. Stacey will explain all to us about 5G. We need a
[00:00:16.520 --> 00:00:23.280]   little help. And worry about how you pronounce Amicus Curia. It's all coming and why you
[00:00:23.280 --> 00:00:26.560]   might want to pronounce it. It's all coming up next on Twig.
[00:00:26.560 --> 00:00:32.560]   Netcast you love.
[00:00:32.560 --> 00:00:37.560]   From people you trust.
[00:00:37.560 --> 00:00:42.560]   This is Twig.
[00:00:42.560 --> 00:00:52.560]   This is Twig, Episode 497, recorded Wednesday, February 27, 2019. Hermione said so.
[00:00:52.560 --> 00:00:58.760]   This week in Google is brought to you by Thousand Eyes. Companies that run in the cloud
[00:00:58.760 --> 00:01:04.760]   rely on Thousand Eyes. It's the place they go first to see, understand, and improve the
[00:01:04.760 --> 00:01:10.080]   digital experience of their cloud-based applications and services. Do the cloud write and improve
[00:01:10.080 --> 00:01:17.280]   services for your customers and employees today. Visit ThousandEyes.com/Twig. And by
[00:01:17.280 --> 00:01:23.160]   the way, CapTera. Find the right software for your business with over 750,000 reviews of
[00:01:23.160 --> 00:01:28.840]   products from real software users. Check out CapTera's free website to find the right tools
[00:01:28.840 --> 00:01:35.840]   to make 2019 the year for your business at capterra.com/twig.
[00:01:35.840 --> 00:01:39.840]   It's time for Twig. This week in Google, the show we talk about the latest news in the
[00:01:39.840 --> 00:01:44.160]   Google verse, which really doesn't mean just Google, but Facebook, Twitter, the Internet
[00:01:44.160 --> 00:01:50.560]   as a whole. We also talk a lot about journalism and media. Jeff Jarvis, our journalism guru,
[00:01:50.560 --> 00:01:54.520]   is taking the week off because he's in Oxford, England. And he says, "I don't have good enough
[00:01:54.520 --> 00:02:02.320]   internet to do the show." But Stacey Higginbotham is here. And she apparently has taken over Jeff's
[00:02:02.320 --> 00:02:13.000]   wood-lined panel study. So from Stacey and IOT and at Gigas Stacey on the Twitters, she
[00:02:13.000 --> 00:02:19.760]   has a great podcast on the Internet of Things with about Chromebooks, Kevin Tofel. There
[00:02:19.760 --> 00:02:27.200]   I got two plugs in one. That was nice. And that other long-tall drink of water there,
[00:02:27.200 --> 00:02:31.360]   that's Ant Proit. He has contributed to tech republic and always a welcome visitor to our
[00:02:31.360 --> 00:02:38.280]   shores. Hi, Ant. Hey, Mr. LaPorte. Great to see you. Likewise. Thanks for having me.
[00:02:38.280 --> 00:02:44.400]   Neither, none of us were in Barcelona over the weekend, much as I would have loved to.
[00:02:44.400 --> 00:02:48.840]   But that's what happened with Mobile World Congress. Microsoft announced its new HoloLens
[00:02:48.840 --> 00:02:53.920]   2. And finally, just gave up on the idea of making it a consumer product and said, "No,
[00:02:53.920 --> 00:02:59.520]   it's all about business." And I had an insight earlier today on Windows Weekly that I think
[00:02:59.520 --> 00:03:08.920]   I'm just thick. But I was, as a tech guy, I kind of think about the gadgets, the products,
[00:03:08.920 --> 00:03:16.400]   the shiny stuff, and less about the backbone. And what I realized is this HoloLens 2 announcement
[00:03:16.400 --> 00:03:21.520]   was really put it in high relief for me, is Microsoft makes these things not because they
[00:03:21.520 --> 00:03:27.960]   want to sell these things, Surface, HoloLens, even Xbox. It's not so much about those products.
[00:03:27.960 --> 00:03:32.160]   But yeah, sure, they make some money on them. But really, what Microsoft is, and they've
[00:03:32.160 --> 00:03:36.960]   never changed since day one was a platform company. The platform used to be Windows.
[00:03:36.960 --> 00:03:40.400]   When Sacha Nadella, their new CEO, came along five years ago, he said, "You know, this
[00:03:40.400 --> 00:03:45.240]   Windows desktop operating systems don't have that much of a future. You know what has a
[00:03:45.240 --> 00:03:51.920]   future? The cloud." And he said, "Our new platform is the cloud, is Azure. And now,
[00:03:51.920 --> 00:03:56.360]   if I contextualize it there, HoloLens makes a lot of sense because all throughout the
[00:03:56.360 --> 00:04:01.720]   demo, they're talking about the enterprise uses of it, which require Azure and Dynamics
[00:04:01.720 --> 00:04:07.200]   365, their enterprise business platform. And then suddenly, "Oh, it all kind of makes
[00:04:07.200 --> 00:04:12.880]   sense to me." That's really what HoloLens is all about. In fact, they really established
[00:04:12.880 --> 00:04:17.840]   how open it is because they showed one person wearing the HoloLens visor. It's an augmented
[00:04:17.840 --> 00:04:24.520]   reality visor. He's working on an engine. And somebody else is using an iPad to see the
[00:04:24.520 --> 00:04:29.680]   same thing, which that Microsoft would never have said that in the past. But it's really
[00:04:29.680 --> 00:04:36.480]   a platform for them. So I think that's really an interesting, to me, that's an important
[00:04:36.480 --> 00:04:40.200]   insight because it tells us why Microsoft does what they do.
[00:04:40.200 --> 00:04:47.960]   Well, and it's in addition to being a platform for an AR platform. It's not just a platform
[00:04:47.960 --> 00:04:50.360]   for heads up displays, right?
[00:04:50.360 --> 00:04:54.960]   So if you think about it across a number of devices, they're just trying to figure out
[00:04:54.960 --> 00:04:59.280]   what do people want to do with it? What kind of software designs do we need to think about
[00:04:59.280 --> 00:05:00.760]   how will people interact with it?
[00:05:00.760 --> 00:05:06.200]   Oh, absolutely. But they realize that ultimately, whatever the design is, however people use
[00:05:06.200 --> 00:05:11.460]   it, it will all hook up to their platform, which is Azure, right? And they showed a
[00:05:11.460 --> 00:05:20.320]   conferencing thing that uses Azure. They showed remote telemedicine. I mean, it's all Azure.
[00:05:20.320 --> 00:05:26.200]   Base is all in the cloud. And that's really what they're selling.
[00:05:26.200 --> 00:05:30.600]   That's the difference between a company like Microsoft and the other ones. It's not about
[00:05:30.600 --> 00:05:36.120]   viral. It's about legacy. It's about, you know, who's going to be here, you know, 10
[00:05:36.120 --> 00:05:41.120]   years from now, 20 years from now. And that's the type of thinking you got to have and not
[00:05:41.120 --> 00:05:43.880]   worry about the big hit right now.
[00:05:43.880 --> 00:05:45.360]   Well, and stick around.
[00:05:45.360 --> 00:05:50.520]   Because we know platform is kind of a nice play. Microsoft got really big by creating
[00:05:50.520 --> 00:05:55.680]   a platform that they other people used. And somebody once asked Bill Gates, well, you
[00:05:55.680 --> 00:06:00.560]   didn't really get all the, extract the maximum profit you could have out of Windows. A lot
[00:06:00.560 --> 00:06:04.880]   of other people made money on Windows. He said, actually, that's the measure of a platform
[00:06:04.880 --> 00:06:09.200]   that the partners make more money than the platform creator. But the good, but the good
[00:06:09.200 --> 00:06:12.360]   news is the platform creator gets a chunk of all of that.
[00:06:12.360 --> 00:06:17.080]   Yeah. And the reason I've been thinking about it is because Apple, which was a device maker
[00:06:17.080 --> 00:06:24.480]   and made all its money on devices is faced with this issue going forward that their sales
[00:06:24.480 --> 00:06:30.080]   are slowing down and they don't have the next big thing. And they're doing the same thing.
[00:06:30.080 --> 00:06:35.320]   They're suddenly pivoting to the cloud. They're saying the future don't pay attention to device
[00:06:35.320 --> 00:06:41.640]   sales anymore. The future is revenue per customer based on their use of our services and services
[00:06:41.640 --> 00:06:48.320]   is really just another word for cloud. And that kind of all makes sense to me.
[00:06:48.320 --> 00:06:52.520]   With regards to Apple, I think it's more along the lines of they're saying, you know what,
[00:06:52.520 --> 00:06:56.680]   we made our phones a little too expensive and people are going to buy them every other
[00:06:56.680 --> 00:07:04.640]   year, right, right, you know, every four years or so at the most. So let's find a way to
[00:07:04.640 --> 00:07:10.600]   keep the shareholders from panicking and saying, Hey, we're focusing more on the ecosystem,
[00:07:10.600 --> 00:07:17.880]   yeah. Well, they Microsoft must have enjoyed the Samsung event a week ago and other announcements
[00:07:17.880 --> 00:07:22.000]   at Mobile World Congress because suddenly the iPhone is no longer the most expensive
[00:07:22.000 --> 00:07:30.480]   phone by any means. Samsung's Galaxy Fold will start at almost $2,000. And this is the
[00:07:30.480 --> 00:07:38.920]   Huawei Mate X and it's going to start closer to $3,000. And so I think that's good news
[00:07:38.920 --> 00:07:45.200]   for Apple. It establishes a new kind of price point way out there. So Apple might not look
[00:07:45.200 --> 00:07:48.880]   like the most expensive player. What do you think of these foldable phones? Stacy, do you
[00:07:48.880 --> 00:07:54.400]   want one? I do. I won't went so badly, but I can't just apply the price. Yeah. Initially,
[00:07:54.400 --> 00:07:58.920]   it'll be one of those products where people will buy it either because they have more
[00:07:58.920 --> 00:08:03.680]   disposable income than anybody or because they want to show everybody that they have
[00:08:03.680 --> 00:08:07.120]   more disposable income because it'd be very obvious if you took out a Mate X from your
[00:08:07.120 --> 00:08:12.840]   pocket and unfolded it. Oh, that guy's loaded. Right. That's a status symbol. How about you
[00:08:12.840 --> 00:08:17.000]   say about the iPhone? Right. It is. But it's no longer is it a status symbol to have an
[00:08:17.000 --> 00:08:21.720]   iPhone? Because everybody's not anybody has an iPhone. So what do you think? And are you
[00:08:21.720 --> 00:08:27.240]   a as a photographer? You must be no, no, no, he's shaking his head. No, no, no, no, no,
[00:08:27.240 --> 00:08:34.800]   you lost me. Yeah, you lost me. It's been too grand. I can go out and get a Sony a7R2
[00:08:34.800 --> 00:08:40.720]   right now. That's a camera. Very nice camera, by the way. Right. That's not even the newest
[00:08:40.720 --> 00:08:46.200]   model. Right. Yeah. But on the other hand, if you think of this as instead of just an
[00:08:46.200 --> 00:08:52.240]   accessory, your phone as as one of your primary, if not your primary computers, then is it
[00:08:52.240 --> 00:08:58.840]   too much? I just bought a MacBook Pro, which is a fancy expensive computer for like 1800.
[00:08:58.840 --> 00:09:05.800]   Oh, so no, no, yeah, but you can't that's bold your MacBook Pro up and put it in your
[00:09:05.800 --> 00:09:12.120]   pocket. But I also can't run Premiere Pro on that thing either. Yeah. That's going to
[00:09:12.120 --> 00:09:14.920]   be an interesting thing. In fact, that's one of the things we talked about on Mac break
[00:09:14.920 --> 00:09:22.200]   weekly yesterday. Apple, the rumor mill says Apple's moving first to arm chips in the next
[00:09:22.200 --> 00:09:28.680]   couple of years and then second to a unified operating system iOS and Mac OS. And at that
[00:09:28.680 --> 00:09:35.320]   point, Adobe will develop for all three, I would guess. So you would be cool. Yeah,
[00:09:35.320 --> 00:09:42.120]   that would be cool. But I look at this is my opinion when it comes to these OEMs and these
[00:09:42.120 --> 00:09:48.680]   high price phones. You put in all of these specs in there as if the mass market is a
[00:09:48.680 --> 00:09:54.280]   bunch of power users. Right. And I can't assume that the mass market is power users.
[00:09:54.280 --> 00:10:00.440]   Everybody is out there just taking selfies and sending Facebook messages and WhatsApp and all
[00:10:00.440 --> 00:10:05.560]   of that. They don't really need that much horsepower. They don't really need all of the
[00:10:05.560 --> 00:10:11.640]   extra pixels on the screen. Now, if you want to be a content creator or what have you,
[00:10:11.640 --> 00:10:16.280]   I get that. But at the same time, it's still a dad gum phone and it shouldn't cost me more
[00:10:16.280 --> 00:10:21.640]   than $1,000. Well, but don't these companies, I mean, in order to move forward,
[00:10:22.520 --> 00:10:28.040]   they're going to develop phones that are very expensive initially and the price would come down.
[00:10:28.040 --> 00:10:32.520]   If they said anything new we do has to be affordable for the masses,
[00:10:32.520 --> 00:10:35.400]   we wouldn't see a lot of new developments, would we?
[00:10:35.400 --> 00:10:42.120]   Let's look at what makes a full, I mean, what are the components of a foldable screen?
[00:10:42.120 --> 00:10:48.280]   Because that's what we've got to assess. Are there economies of scale that can be derived from
[00:10:48.280 --> 00:10:53.640]   that type of manufacturing process? Yeah, I'm sure. Any screen gets cheaper as you make more of
[00:10:53.640 --> 00:10:59.960]   them and as you refine the process. I mean, remember the first LCD screens, the problem was
[00:10:59.960 --> 00:11:04.120]   dead pixels and they got better and better at making them and the price went down because
[00:11:04.120 --> 00:11:11.160]   more and more of the screens came out without defect. They didn't have to reject as many.
[00:11:11.160 --> 00:11:16.520]   But that wasn't just a defect thing. It was a semiconductor or a way for a kind of
[00:11:16.520 --> 00:11:21.800]   yeah, it's a process problem. Yeah. So, but are foldable screens that same?
[00:11:21.800 --> 00:11:25.560]   God knows. I don't know how they make them. They're polymer. We know that. They're plastic.
[00:11:25.560 --> 00:11:31.640]   They've got to be probably somewhat like OLED screens. I think these OLED screens,
[00:11:31.640 --> 00:11:37.000]   this is a Samsung Galaxy Note 9 and they have a little bit of a curve, don't they? On the edge
[00:11:37.000 --> 00:11:43.960]   as they come down here. So I'd be my guess that this OLED material is somewhat like the material
[00:11:43.960 --> 00:11:53.400]   that'll be used in these folding phones. I do wonder what the fold's going to handle all those
[00:11:53.400 --> 00:11:58.920]   bins. You don't have to ask. There's only three of us.
[00:11:58.920 --> 00:12:05.560]   Well, she said she would get one of those phones, but she couldn't justify the price.
[00:12:05.560 --> 00:12:09.720]   My question is why? What do you like about it? Yeah.
[00:12:10.760 --> 00:12:14.680]   I like having a big screen, but I hate something that doesn't fit in my pocket.
[00:12:14.680 --> 00:12:18.680]   So this solves, well, theoretically this solves this problem.
[00:12:18.680 --> 00:12:23.800]   And I also like playing with new interfaces. I like because that's like
[00:12:23.800 --> 00:12:31.400]   when you can see the future is when you see something that you use it and you're like,
[00:12:31.400 --> 00:12:36.360]   oh my gosh, this totally changes how I look at this type of device or maybe this workflow.
[00:12:37.240 --> 00:12:45.160]   I have a feeling, I could be wrong, that this type of foldable phone thing could actually do
[00:12:45.160 --> 00:12:51.480]   that for me. So that's why I would want one. Do you think it doesn't feel to me that this came
[00:12:51.480 --> 00:12:57.480]   out of a lot of focus grouping and testing and research? It feels like they just said,
[00:12:57.480 --> 00:13:02.440]   what can we do next? I know foldable. No, phones have had a very real constraint.
[00:13:02.440 --> 00:13:06.920]   Like as they got bigger and bigger, people started complaining more about them not fitting in
[00:13:06.920 --> 00:13:10.520]   their pockets and all of these other things, but people still bought the big screens because they
[00:13:10.520 --> 00:13:17.480]   like the big screens. So, I mean, there is an actual, I don't know if it's really a problem,
[00:13:17.480 --> 00:13:21.000]   per se, but there is an actual need for something that does this.
[00:13:21.000 --> 00:13:29.400]   I do appreciate the innovation because I was getting smartphone fatigue because everything
[00:13:29.400 --> 00:13:33.960]   pretty much looks the same for the last six, seven years. You go to a store and say,
[00:13:33.960 --> 00:13:38.840]   "Show me your flagship phone." It's going to look like the one that's right next to it is not a
[00:13:38.840 --> 00:13:45.480]   flagship. One glass slab is much like the other. Yeah. So, I mean, I appreciate the innovation,
[00:13:45.480 --> 00:13:53.320]   but I just don't see the need for the fold. And we might be in this area of kind of wacky
[00:13:53.320 --> 00:13:58.280]   interfaces, wacky new designs. I can't think of the name of the phone that's a watch.
[00:13:58.280 --> 00:14:03.640]   Oh, yeah. There were a couple of, I think of them, slap bracelets.
[00:14:04.040 --> 00:14:12.840]   There are a couple of phones that you wear around your wrist. Here's one from TCL. This is a concept,
[00:14:12.840 --> 00:14:19.960]   so not available yet. In fact, this was the year of goofy, weird designs. And again,
[00:14:19.960 --> 00:14:23.720]   I don't feel like these were in response to demand. These are more like, let's throw
[00:14:23.720 --> 00:14:28.680]   spaghetti against the wall and see what sticks. Well, yeah, but no one demanded the,
[00:14:29.800 --> 00:14:37.080]   no one demanded the Amazon Echo, for example. And I feel like right now, and especially
[00:14:37.080 --> 00:14:42.520]   when we think about 5G and not super hyped 5G, but think about where we are with, we have
[00:14:42.520 --> 00:14:48.360]   really ubiquitous fast broadband connections pretty much everywhere, either mobile or fixed.
[00:14:48.360 --> 00:14:55.320]   We've got computing that is incredibly powerful, power efficient, both in the cloud and on the
[00:14:55.320 --> 00:15:01.240]   device. And so if you start, and now we're pulling all this contextual data from applications and
[00:15:01.240 --> 00:15:08.280]   sensors around us and doing things with it, it feels like we're ripe for some sort of new
[00:15:08.280 --> 00:15:13.880]   innovation in like a paradigm shift in computing. And I hate that phrase paradigm shift, but I
[00:15:13.880 --> 00:15:19.160]   think it could happen. Would you wear this? Look at this. This is Nubia's alpha watch.
[00:15:20.600 --> 00:15:28.760]   It's a phone. It's a watch. It's, it looks actually almost steampunk and it's design.
[00:15:28.760 --> 00:15:37.640]   I would not. Yeah, I think it's kind of bizarre. I would wear something like that if there was
[00:15:37.640 --> 00:15:44.280]   a hearing component, like an ear. Look at this. This is the
[00:15:46.760 --> 00:15:51.720]   now. Now, now it really does look like something steampunk-y. Wow.
[00:15:51.720 --> 00:15:58.120]   Yeah, I maybe the wrist isn't the right place to put this display. I'm just I'm just saying.
[00:15:58.120 --> 00:16:05.640]   I and it's it's tough. And what about why do you need? I'm trying. You can put a display anywhere
[00:16:05.640 --> 00:16:12.200]   and what becomes really exciting is when you have, I think, the interface mostly in your ear
[00:16:12.200 --> 00:16:17.320]   and a display anywhere you need one is personally what I'm excited about. What about a heads up
[00:16:17.320 --> 00:16:20.680]   display? I mean, the hollow lens right now is ridiculous. You're not going to walk around
[00:16:20.680 --> 00:16:25.480]   wearing that. But this is early days. What if they got it down to the size of something like
[00:16:25.480 --> 00:16:33.000]   maybe some the North glasses? Yeah. I always refer back to Daniel Suarez. Yes, exactly.
[00:16:33.000 --> 00:16:38.680]   And demon and freedom. That's exactly right. Yeah. I would take that any day because the way
[00:16:38.680 --> 00:16:45.080]   it's described in the book is those those glasses look like just regular high-end stylish glasses,
[00:16:45.080 --> 00:16:49.960]   you know, but I don't think anybody's been able to do that just yet. It's early days.
[00:16:49.960 --> 00:17:00.280]   Hollow lens at least is fully, you know, encapsulated. There's no tether. There's three-hour battery
[00:17:00.280 --> 00:17:05.400]   life. Okay, that's low, but the full computer and everything's in the band. It is heavy. I have
[00:17:05.400 --> 00:17:11.160]   worn hollow lens. The new one's three times more comfortable. Stacey. That's three times.
[00:17:11.160 --> 00:17:16.920]   That's what Microsoft says. Yeah, three times more comfortable. It's more like a hat now with all.
[00:17:16.920 --> 00:17:21.560]   You remember when you put on the original Hollands, yo, it was a lot of knob twiddling and fiddling.
[00:17:21.560 --> 00:17:25.560]   Yeah, like this like Frankenstein. They don't do that anymore. It goes on.
[00:17:25.560 --> 00:17:30.200]   It's much more comfortable, apparently. And it's more balanced. I think it's probably not much
[00:17:30.200 --> 00:17:34.280]   lighter, but it's balanced. And that's kind of true. There was a lot of weight. I mean,
[00:17:34.280 --> 00:17:41.240]   you don't want to pull on you forward. Yeah. But I, you know, I, I see because I go to these
[00:17:41.240 --> 00:17:45.480]   industrial user group conferences, I actually see people using the HoloLens,
[00:17:45.480 --> 00:17:52.360]   get demos of that. And I've changed out weird chats and like swapped out things using HoloLens
[00:17:52.360 --> 00:18:00.360]   demos where they're like, and it's very effective and it is super cool. And I can see why Microsoft
[00:18:00.360 --> 00:18:05.320]   is investing here. And there is demand for that sort of thing, especially on the industrial side.
[00:18:05.320 --> 00:18:09.880]   Yeah. And we know Google Glass still sells in industrial applications. It's a little
[00:18:09.880 --> 00:18:14.040]   lot. It's not a heads up display as much as like a monitor over your eye.
[00:18:14.040 --> 00:18:20.120]   Brouh. Yeah. I remember going to Mobile World Congress. It was the only time I went, I think it was 2016.
[00:18:20.120 --> 00:18:26.920]   And there was a big company, I think it was Fujitsu that showed off just having some type of little
[00:18:26.920 --> 00:18:34.440]   Google Glass looking device on. And you're basically a line worker at a, at a factory.
[00:18:34.440 --> 00:18:38.520]   And you're able to do your inventory and inspect the parts and things like that just from looking
[00:18:38.520 --> 00:18:44.120]   at it. And I thought it was pretty outstanding tech and could be used everywhere with these big
[00:18:44.120 --> 00:18:49.480]   manufacturing companies. But I don't know who's all buying into it. And now it seems like that
[00:18:49.480 --> 00:18:56.520]   would be perfect for HoloLens stuff. That's what they use it for. So like Emerson, who else is
[00:18:57.400 --> 00:19:03.000]   like Emerson Honeywell. Trying to think as not Xerox.
[00:19:03.000 --> 00:19:08.840]   Tetrapack actually, you know, the people who make the aseptic milk containers.
[00:19:08.840 --> 00:19:16.840]   Tetrapack actually uses HoloLens in their factories for a lot of times it's used for
[00:19:16.840 --> 00:19:24.040]   training or repair of machines. So understanding what's happening inside of machine, it's all part
[00:19:24.040 --> 00:19:27.720]   of like Microsoft's digital twin product. I don't know if you guys are familiar with that,
[00:19:27.720 --> 00:19:31.800]   where they've got a replica of a really big expensive machine and all the sensor data comes
[00:19:31.800 --> 00:19:35.800]   into that. Yeah, that's what they showed people repairing, learning how to repair.
[00:19:35.800 --> 00:19:40.360]   They showed surgeons learning how to do hard surgery in the operating room, just reviewing
[00:19:40.360 --> 00:19:45.560]   the procedure and then doing it. I think there's a lot of, I mean, there's huge amount of use for
[00:19:45.560 --> 00:19:50.280]   this. But I'll tell you where I feel like we are. We're in the, in the maybe the 90s or even the 80s.
[00:19:50.920 --> 00:19:56.360]   When we saw a lot of technologies like the Newton and the Palm and internet technologies and
[00:19:56.360 --> 00:20:05.080]   converging and it took 10 years, but by 2007 they converged onto the iPhone and Blackberry and
[00:20:05.080 --> 00:20:12.040]   and they convert and now I mean that 10 years later it's completely changed computing, how we use
[00:20:12.040 --> 00:20:17.720]   computing, how we think of computing. It's a huge shift. I think we're at that. Those early stages
[00:20:17.720 --> 00:20:24.680]   where you're starting to see the convergence of new technologies coming in when you have voice
[00:20:24.680 --> 00:20:29.720]   activated technologies, that's going to be critical for user interface because user interface on any
[00:20:29.720 --> 00:20:36.680]   of these is very difficult. You see voice activated coming in. You see screens in a heads up display
[00:20:36.680 --> 00:20:41.880]   or a variety of places, experimentation with where a screen would be because you do need to read
[00:20:41.880 --> 00:20:47.400]   out of some kind. My money's on a heads up display and you do see a lot of those. You see
[00:20:47.400 --> 00:20:54.360]   artificial intelligence too and that's I think going to be very important because any wearable
[00:20:54.360 --> 00:20:59.000]   has to know a lot about in the environment, just like a self-driving car, I know where it's going.
[00:20:59.000 --> 00:21:03.640]   The wearable and I think all the demos right now are in very constrained environments,
[00:21:03.640 --> 00:21:07.880]   just as all the speech demos are very unconstrained vocabulars. But once you
[00:21:08.920 --> 00:21:15.640]   evolve these things, imagine having the same kind of heads up display you have now in a factory floor
[00:21:15.640 --> 00:21:23.000]   in the arbitrary real world. That's where AI and things like time of flight sensors,
[00:21:23.000 --> 00:21:29.320]   which those are the 3D sensors that are on the HoloLens and are very similar to the LiDAR used on
[00:21:29.320 --> 00:21:34.040]   automobiles, self-driving cars. I think all of that is starting to come together. It's got to get
[00:21:34.040 --> 00:21:39.400]   miniaturized. It's got to get more effective. But I ultimately see the future of computing and
[00:21:39.400 --> 00:21:45.560]   maybe it's 10, maybe it's 20 years out as something like that, something that maybe they're not going
[00:21:45.560 --> 00:21:51.720]   to look like they don't have to look like stylish glasses, spectacles. They can look a little clunky,
[00:21:51.720 --> 00:21:55.000]   not super, not like HoloLens clunky, but they could be a little clunky here because we'll get
[00:21:55.000 --> 00:22:00.280]   used to it. But I see people wearing those and using that as their primary computing platform
[00:22:00.840 --> 00:22:11.000]   and using speech, AI, cameras, heads up displays that can turn into screens.
[00:22:11.000 --> 00:22:17.800]   I'm going to argue with you a little bit. I think you're close. I think what is actually
[00:22:17.800 --> 00:22:24.200]   like, I think the computing, there will be computing on your body some sort of computer that is a
[00:22:24.200 --> 00:22:28.600]   smartphone or maybe we get to the point where it could be a headset. We're not there for a while.
[00:22:29.160 --> 00:22:36.360]   But I think what happens with displays is actually anything around you will be a display. We'll get
[00:22:36.360 --> 00:22:42.680]   a standard that has it interact with you so you can pull up your display in front of you on any
[00:22:42.680 --> 00:22:47.800]   screen. So many surfaces will become screens either projected interface with them.
[00:22:47.800 --> 00:22:50.360]   That's right. And by your proximity, you'll make it yours.
[00:22:50.360 --> 00:22:52.920]   Right. I completely agree.
[00:22:52.920 --> 00:23:01.320]   That's my hunch because I think the HoloLens and those kind of heads up displays are good in
[00:23:01.320 --> 00:23:07.080]   industrial. They're very expensive. You do need a lot of computing power to do that.
[00:23:07.080 --> 00:23:13.320]   And they solve a really real problem, but it's not a real problem that we all have every day,
[00:23:13.320 --> 00:23:14.200]   I don't think today.
[00:23:17.160 --> 00:23:25.160]   Well, it's not that it's solving a problem. It's ubiquitous computing, right? We're moving in that
[00:23:25.160 --> 00:23:28.680]   direction. Yes, that's why I was talking about that whole paradigm shift.
[00:23:28.680 --> 00:23:34.520]   Yeah, that's ubiquitous computing. To me, though, there is a data point with these foldable screens,
[00:23:34.520 --> 00:23:39.160]   which is we do want better screens wherever we are. I think you're right that maybe that whatever
[00:23:39.160 --> 00:23:44.360]   screen is near you is the one that you use. And if screens are everywhere, then it won't matter if
[00:23:44.360 --> 00:23:48.760]   you carry one with you, but you will carry a personal computing device of some kind that
[00:23:48.760 --> 00:23:54.040]   knows your preference. Maybe not. Maybe it'll be that'll be a mesh that's everywhere. And
[00:23:54.040 --> 00:24:00.440]   when I get no no privacy, right? You want to keep it to yourself. Privacy lack of standards
[00:24:00.440 --> 00:24:04.920]   that we're not going to get there. Lack of standards would be a real hardship because you
[00:24:04.920 --> 00:24:08.600]   and that might even be the hardship with the screen thing. That is the hardship with the screens.
[00:24:08.600 --> 00:24:13.880]   But that is one of the. We know computing is moving to the edges. We know ubiquitous
[00:24:13.880 --> 00:24:20.360]   computing is the trend. And I think looking at new interfaces is really what's going on right now.
[00:24:20.360 --> 00:24:27.960]   And I think wearable glasses makes a lot of sense. Your pieces, certainly it's the stuff of
[00:24:27.960 --> 00:24:31.800]   science fiction. You see this in science fiction all the time. Just as you saw the iPad in 2001,
[00:24:31.800 --> 00:24:38.040]   not the year, the movie, the movie, the year was 1977 or something like that. Yeah.
[00:24:39.000 --> 00:24:47.080]   All right. I just that was our speculative section. That was Leo goes off on a speculative tangent.
[00:24:47.080 --> 00:24:55.160]   There are also camera phones now. Ants a photographer like the Nokia Pure View,
[00:24:55.160 --> 00:25:02.840]   which is I'm calling it the spider phone because the cameras look like a spider's eye. There are
[00:25:03.880 --> 00:25:10.600]   it looks like there's seven cameras. There's only five, but there's a flash and there's some
[00:25:10.600 --> 00:25:17.880]   other sensor in it. But it's really, I mean, it's kind of creepy looking the Nokia nine. And I
[00:25:17.880 --> 00:25:23.000]   presume because Nokia's Pure View, that was the one that was 41 megapixels in the windows phone,
[00:25:23.000 --> 00:25:27.880]   right? That was their brand for that. That's correct. That they're they're probably each of these
[00:25:28.840 --> 00:25:35.320]   five cameras is a 12 megapixel sensor, two of the five shooting color, the other three are monochrome.
[00:25:35.320 --> 00:25:46.440]   And the idea is you can then merge these shots into one ultra detailed shot. What do you think?
[00:25:46.440 --> 00:25:53.960]   I love the idea. I wonder how efficient it is because essentially that's what Apple and Google
[00:25:53.960 --> 00:26:01.320]   are already doing right now with their camera technology. So I'm guessing having that additional
[00:26:01.320 --> 00:26:07.480]   hardware supposedly makes it easier to do that stuff. But I don't know, I'd like to see it in
[00:26:07.480 --> 00:26:12.680]   action. I hope it doesn't go by the wayside the way that Lumia did years ago. I want it.
[00:26:12.680 --> 00:26:19.320]   Yeah, that's right. Did you ever have a one man? I do one person that had it. I tried it for
[00:26:20.360 --> 00:26:25.160]   Windows time to switch phones. And I remember playing around with it in the store. But Windows
[00:26:25.160 --> 00:26:29.080]   phone just didn't do anything for me. So look at these images. Now, of course, you're looking at
[00:26:29.080 --> 00:26:35.880]   them over a Skype connection. And this is a web view of it. This is the Verge. I thought what's
[00:26:35.880 --> 00:26:40.680]   interesting about these is the color is very neutral. It's probably super accurate.
[00:26:40.680 --> 00:26:49.000]   The details. When it comes to processing images, you want that that leeway, right?
[00:26:49.960 --> 00:26:53.720]   That the colors on most camera phones today, Samsung is a particular
[00:26:53.720 --> 00:27:00.200]   violator. This is our ultra bright popped over sharpened. Yeah, because it makes people happy.
[00:27:00.200 --> 00:27:08.200]   Right. Yeah. The Samsung knows who it's who it's marketing to. They're going after the people that
[00:27:08.200 --> 00:27:13.880]   lights all the bubbly stuff, right? gimmicky stuff. This is really interesting.
[00:27:13.880 --> 00:27:17.160]   Well, it's not just bubbly and gimmicky. It's just it looks good, even if you're a sake
[00:27:17.160 --> 00:27:22.120]   photographer, which that's the key. That's that's Instagram right there in a nutshell.
[00:27:22.120 --> 00:27:28.360]   Well, you said it not me. I'm like, as a person who is not a great photographer, I'm like,
[00:27:28.360 --> 00:27:32.920]   yeah, you know, I like being able to take photos that look good. Like neat. I have to say,
[00:27:32.920 --> 00:27:40.520]   this was a good mobile world Congress. If you like different, if you like innovation slash crazy,
[00:27:40.520 --> 00:27:45.560]   I know I should have done this instead of CES, which was a snooze bill. Yeah. Well, a lot of tech
[00:27:45.560 --> 00:27:50.040]   conferences have been snoozed, Villa, over the last few years because we're chated and old.
[00:27:50.040 --> 00:27:55.240]   We're at peak night. We're kind of a peak phone, peak computer. Here's Oppo's version of the
[00:27:55.240 --> 00:28:02.280]   folder before and they've gone the Huawei direction of having the screen on the outside, not the inside.
[00:28:02.280 --> 00:28:10.920]   Oppo, I just think these are so neat. Yeah. Yeah. Thickness is what I questioned, though,
[00:28:10.920 --> 00:28:14.760]   because I can remember at one time when everybody wanted a thinner device. Right.
[00:28:14.760 --> 00:28:20.440]   Oh, well, yeah. No, and they are thick, but again, they're thick and they fit in your pocket. So,
[00:28:20.440 --> 00:28:25.400]   yeah, what's more important to you, big screen or thinness? To me, it's pocket.
[00:28:25.400 --> 00:28:32.760]   I know what you don't want is this phone. This is from Energizer. It has an 1800 milliamp hour
[00:28:32.760 --> 00:28:37.240]   battery. Man, I got a press release about that thing.
[00:28:38.040 --> 00:28:39.240]   So hard.
[00:28:39.240 --> 00:28:45.080]   And I'm thinking, who in the right mind wants that? That's, oh my goodness.
[00:28:45.080 --> 00:28:48.040]   This is Vlad Zavov from the Verde. That's my trade show phone.
[00:28:48.040 --> 00:28:52.360]   Yeah. Well, it's a phone if you had to go to the Antarctic or something and we're unsure about
[00:28:52.360 --> 00:28:55.240]   where you'd be able to charge next. You know, it's so weird, though, when you look at this
[00:28:55.240 --> 00:29:02.200]   picture, is it looks like they've kind of just glued a regular smartphone on top of a big battery
[00:29:02.200 --> 00:29:05.720]   charger. Big battery, yeah. And I bet you that's what it is. You can even use this as a battery
[00:29:05.720 --> 00:29:12.760]   charger. Isn't that so weird looking? Energizer has surprised me because at CES, they were showing
[00:29:12.760 --> 00:29:18.680]   off, oh, it's the company that does monster cables. They have the licensing deal for Energizer
[00:29:18.680 --> 00:29:22.520]   for smart home products. So they were showing off, you know, connected outlets, connected doorbell
[00:29:22.520 --> 00:29:29.240]   cams, connected light strips for like very cheap. And I was just like, Energizer, what are you doing?
[00:29:29.240 --> 00:29:33.160]   Yeah. Maybe they're currently all in on this. Yeah. Well,
[00:29:33.160 --> 00:29:38.040]   or they license their name to be all sure who's because they're not making any of this. No.
[00:29:38.040 --> 00:29:42.600]   So maybe they're just licensing their name. Then there's companies like LG, which really didn't
[00:29:42.600 --> 00:29:46.440]   do anything new or different. And they're not just don't get the coverage, right? It's got,
[00:29:46.440 --> 00:29:51.960]   you know, this has the this has a time of flights uncertain, the ThinQ, which
[00:29:51.960 --> 00:29:58.040]   is that required for face for true good face ID? I think so maybe. Yes, because it gives you depth.
[00:29:58.040 --> 00:30:03.080]   Right. So it can't be fooled by like a flat photo of the person. And I have to say,
[00:30:03.080 --> 00:30:07.000]   you know, as I said, I ordered the Samsung Galaxy S10 plus and I'd be very interested
[00:30:07.000 --> 00:30:11.160]   that you're using an ultrasonic fingerprint reader as opposed to an optical fingerprint
[00:30:11.160 --> 00:30:15.320]   reader. And they do it through the screen. And everybody who tried it said it really works as
[00:30:15.320 --> 00:30:20.600]   fast. And you don't have it's not super picky about where you put your finger. I think that's great.
[00:30:20.600 --> 00:30:25.240]   Yeah, able to get your grooves. Get your grooves on through the ultrasound.
[00:30:25.240 --> 00:30:31.240]   And ultrasonic sensors are cheap. Oh, are they? Interest? Well, I don't know about theirs.
[00:30:31.240 --> 00:30:34.920]   There's in particular, but in general, they've been around for a long time and they're pretty cheap.
[00:30:34.920 --> 00:30:40.280]   Let's take a break. Because I think the real story at Mobile World Congress is all about 5G.
[00:30:40.280 --> 00:30:46.520]   And Stacy Higginbotham is our 5G guru. At least she knows more than I do, which is not saying that
[00:30:46.520 --> 00:30:54.360]   much, but in me. There's a lot of announcements, including some steps back. We'll talk about that
[00:30:54.360 --> 00:31:01.000]   in just a second as we continue this week in Google, the Jarvis list version. It's a whole
[00:31:01.000 --> 00:31:04.520]   different show when Jeff's not here. There is no media discussion.
[00:31:04.520 --> 00:31:07.560]   And I don't say that in a bad way. I just it's just a different show.
[00:31:07.560 --> 00:31:15.320]   But he'll be bad. No article 13 and 12 or 11. I checked. I checked just to see. And this is the
[00:31:15.320 --> 00:31:20.600]   the new European Copyright Act, which is really going to be devastating. If it goes through to
[00:31:20.600 --> 00:31:27.800]   content creators, people even like us, because article 13 will require a license. There won't be
[00:31:27.800 --> 00:31:32.520]   any fair use or license to use any copyrighted material and anything you do, including news and
[00:31:32.520 --> 00:31:38.600]   commentary. And no more memes. No more. We'd have to shut off our feed to Europe.
[00:31:38.600 --> 00:31:47.080]   That it's the good news is that there is a mounting drum beat against it. Some people are
[00:31:47.080 --> 00:31:51.960]   already starting to because there's an election coming up for members of the EU Parliament.
[00:31:51.960 --> 00:31:55.800]   There are people saying, hey, this is going to be a litmus test. If you vote for
[00:31:56.840 --> 00:32:01.560]   article 11 and 13, then we're not going to vote for you. That's the kind of pressure we need to
[00:32:01.560 --> 00:32:07.880]   exert because it would be disastrous. But so far, last I checked and I just visited Julia Rayda's
[00:32:07.880 --> 00:32:15.240]   blog, Nothing More Since Last Week. Our show today brought to you by a thousand eyes.
[00:32:15.240 --> 00:32:19.880]   I love thousand eyes. I had never heard of them. That's just because I'm ignorant.
[00:32:19.880 --> 00:32:25.960]   But I went to an event of theirs where they talked about how their sensors, which are all over the
[00:32:25.960 --> 00:32:32.440]   internet, were able to learn all sorts of interesting things about cloud providers and
[00:32:32.440 --> 00:32:39.320]   pros and cons to consider when you choose a cloud provider. But thousand eyes can provide that same
[00:32:39.320 --> 00:32:45.880]   kind of immediate and unmatched view of all the networks, all the dependencies that impact you
[00:32:45.880 --> 00:32:50.920]   and your users' digital experience. That is amazing. They shouldn't really call it a thousand
[00:32:50.920 --> 00:32:56.440]   eyes because it's more like a million eyes. There are sensors everywhere from the internet all the
[00:32:56.440 --> 00:33:03.800]   way out to the edge. Look, we know many of you are going to the cloud. You do gain agility,
[00:33:03.800 --> 00:33:10.840]   but you increase risk and this is scary for a lot of IT teams and companies. You lose a little bit
[00:33:10.840 --> 00:33:17.160]   of control. Your stuff is sitting out there. It's hard when a cloud app or a service goes down.
[00:33:17.880 --> 00:33:25.560]   How do you know what went wrong? I liken this to you're trying to peer through a dirty window,
[00:33:25.560 --> 00:33:30.280]   trying to figure out what's going on out there. Meanwhile, you're losing revenue,
[00:33:30.280 --> 00:33:35.080]   employee productivity is shot. You're damaging your brand in some cases.
[00:33:35.080 --> 00:33:38.680]   And that's why they have it as a puffy little cloud, right? Because who knows what's going on in
[00:33:38.680 --> 00:33:44.360]   there? Thousand eyes knows. It's like taking a squeegee to that dirty window. And suddenly,
[00:33:44.360 --> 00:33:51.880]   you can see instant visibility into the entire service delivery path from the cloud to your end
[00:33:51.880 --> 00:33:57.080]   user. And that's not your. These aren't your little sensors. These are thousand eyes. So it
[00:33:57.080 --> 00:34:02.200]   includes portions you need their own or control. Look at these are the kinds of things thousand eyes
[00:34:02.200 --> 00:34:08.440]   sees. It's not like anything you've ever seen before. The story of Thousand Eyes is great. This was
[00:34:08.440 --> 00:34:17.320]   originally a research project at UCLA, the founder of Thousand Eyes realized that they could find
[00:34:17.320 --> 00:34:21.880]   this great information, this valuable information to any company that's operating in the cloud.
[00:34:21.880 --> 00:34:27.240]   And they created Thousand Eyes. Mohete was great, by the way. I met him at the
[00:34:27.240 --> 00:34:32.360]   survey. They launched at the Gigahome Structure event. Did they? Yes, they were one of my favorite
[00:34:32.360 --> 00:34:37.320]   companies ever. And it was so cool. See, you're smart. So you got it. When they came up on stage,
[00:34:37.320 --> 00:34:41.800]   you understood what they were doing. Yes. Even before, that's why I put them on stage.
[00:34:41.800 --> 00:34:47.640]   Yeah. Oh, you put them on stage. Yeah. Nice. Oh, these guys are, I mean, these guys are legit.
[00:34:47.640 --> 00:34:51.720]   Oh, I completely agree. Well, thank you for that unsolicited testimonial. Mohete
[00:34:51.720 --> 00:34:57.080]   lad and Ricardo Oliveira, they were at the UCLA Internet Research Lab. They were working on
[00:34:57.080 --> 00:35:03.320]   technologies to visualize autonomous system topologies. They got a half million dollar National Science
[00:35:03.320 --> 00:35:09.480]   Foundation grant because at NSF knew that we needed to understand DNS infrastructure issues.
[00:35:09.480 --> 00:35:18.840]   They decided to start Thousand Eyes in 2013. And man, in that time, they have really done well.
[00:35:18.840 --> 00:35:22.680]   And I'm very proud to have a partnership with them right now. I'm just so impressed.
[00:35:22.680 --> 00:35:27.880]   Old school IT monitoring does not work. As you probably know, it's passive. It's siloed, right?
[00:35:27.880 --> 00:35:33.320]   It's in your silo. You can, you know, or you use somebody's that can only see the data center.
[00:35:33.320 --> 00:35:39.960]   That's no use in the cloud. Thousand Eyes is cloud-based software built to help organizations
[00:35:39.960 --> 00:35:45.960]   do the cloud right, a massive array of vantage points spanning the entire global internet cloud
[00:35:45.960 --> 00:35:53.000]   providers right down to the Wi-Fi in your local coffee shop. Thousand Eyes, unique path visualization
[00:35:53.000 --> 00:35:58.280]   technology, extends beyond any boundaries, allowing you to see, understand, and improve the experience
[00:35:58.280 --> 00:36:03.160]   for all your app services and websites. It took me a while to really get what they're doing,
[00:36:03.160 --> 00:36:07.320]   but now that I do, I don't know how you could operate in a cloud environment without Thousand
[00:36:07.320 --> 00:36:12.200]   Eyes. Join the top banks, the enterprises, the SaaS companies, the world's largest and fastest
[00:36:12.200 --> 00:36:18.280]   growing brands that rely on Thousand Eyes to do the cloud and do it right. You want to find out
[00:36:18.280 --> 00:36:27.480]   more, go to Thousand Eyes, all spelled out, T-H-O-U-S-A-N-D-E-Y-E-S.com/twit, and find out what you've
[00:36:27.480 --> 00:36:32.760]   been missing. They do have a great e-book. This would be good to give to the boss. Five cloud
[00:36:32.760 --> 00:36:37.720]   migration challenges you shouldn't ignore. Great stuff in there, but also browse around the site
[00:36:37.720 --> 00:36:43.400]   because there's some really good information there. Thousandeyes.com/twit, and I'm very pleased to
[00:36:43.400 --> 00:36:48.600]   say you should be too Stacey since you saw it at the very beginning. They're doing great. They're
[00:36:48.600 --> 00:36:56.280]   really great. Thrive in a connected world with Thousand Eyes. Thousandeyes.com/twit.
[00:36:56.280 --> 00:37:02.440]   I had no idea you had that relationship with them. That's awesome. Yeah. Sorry, I always forget
[00:37:02.440 --> 00:37:07.160]   that you're doing ads and I try to interrupt. I'm sorry. No, no. As long as when you interrupt,
[00:37:07.160 --> 00:37:13.160]   you interrupt that way. You interrupt all you want. This does a... I'm not in a sound...
[00:37:13.160 --> 00:37:17.560]   I'm not in the bubble. I'm lower the count, cone of silence. You're always allowed to speak.
[00:37:17.560 --> 00:37:23.240]   Especially if it's something positive like that. That's always interesting. Yeah. I had no idea.
[00:37:23.240 --> 00:37:30.840]   I'm A-old. B- That was seven years ago. Formerly a deep cloud computing person.
[00:37:30.840 --> 00:37:39.480]   Yeah. Cool. Okay. Stacey is one of those nerds who really... We used to call them walks.
[00:37:40.920 --> 00:37:45.240]   Really loves the nuts and bolts, gets into the details, reads the white papers and stuff like that.
[00:37:45.240 --> 00:37:50.520]   We're very grateful to her because that way I can ask her questions. Jeff and I will say,
[00:37:50.520 --> 00:37:56.040]   "What is that? Stacey?" She'll say, "Well, let me explain it to you." You're actually, you're her
[00:37:56.040 --> 00:38:03.160]   Miami. Isn't she? She's her Miami. Jeff's Harry and I'm that Weasley kid.
[00:38:04.680 --> 00:38:13.080]   I was wondering who is gonna be Harry. She's her Miami. She's just like, "Wow." You go, "Okay, yes,
[00:38:13.080 --> 00:38:21.960]   ma'am." Now we're going to 5G. 5G was probably the big banner topic at Mobile World Congress.
[00:38:21.960 --> 00:38:25.240]   When you see things like HoloLens and you see Microsoft talking about cloud,
[00:38:25.240 --> 00:38:31.960]   clearly everybody's kind of... Correct me if I'm wrong, Stacey. Thinking about 5G,
[00:38:31.960 --> 00:38:37.720]   like planning for the future. Yes. The future though, the road to the future is always bumpy.
[00:38:37.720 --> 00:38:45.320]   For instance, T-Mobile has announced that they're going to delay the launch of their 5G technology
[00:38:45.320 --> 00:38:51.800]   till later this year, not because their networks aren't ready. There's a glowering John Leger,
[00:38:51.800 --> 00:38:59.000]   but because the phones aren't out there. Right. That makes sense. I mean, they're doing a millimeter
[00:38:59.000 --> 00:39:07.560]   wave network and... That's the real thing, right? Well, no. Yes. No. So 5G, when we talk about like
[00:39:07.560 --> 00:39:13.880]   the FCC, when they talk about 5G, they're talking about millimeter wave. When a carrier is talking
[00:39:13.880 --> 00:39:17.800]   about 5G, they might be talking about millimeter wave, but they might also be talking about the
[00:39:17.800 --> 00:39:23.240]   3GPP standard for 5G. That's the difference between a technology and a marketing term.
[00:39:24.840 --> 00:39:31.640]   Yeah. I mean, is the FCC using a marketing term? No, they're just allocating spectrum.
[00:39:31.640 --> 00:39:36.920]   Right. That's what they're in. And the 3GPP standard, in the 3GPP is the organization that
[00:39:36.920 --> 00:39:42.040]   governs all of your cellular standards. So that's technology too. I mean, that's a real spec, right?
[00:39:42.040 --> 00:39:48.440]   It's a... I mean, it's their radio spec. Right. So the problem is people like AT&T and Verizon,
[00:39:48.440 --> 00:39:56.840]   who call things 5G that aren't millimeter wave 5G, they're 4G enhanced or... AT&T is
[00:39:56.840 --> 00:40:03.320]   messing this up. Verizon is actually deploying over the millimeter wave spectrum. They're deploying
[00:40:03.320 --> 00:40:09.000]   fixed broadband or fixed... For business. Fixed mobile broadband. But it's not the same. It's
[00:40:09.000 --> 00:40:14.840]   not the 3GPP standard though, right? Right, because it's not cellular. And that's why...
[00:40:14.840 --> 00:40:18.840]   But are they using millimeter wave spectrum? Yes. Okay.
[00:40:18.840 --> 00:40:24.760]   And so that's why... And you'll get people... The Qualcomm... Every time I talk about this,
[00:40:24.760 --> 00:40:30.680]   the Qualcomm guys call me and they're like, "Stay safe. There is a standard and it's the 3GPP standard."
[00:40:30.680 --> 00:40:37.000]   Well, that's because they're making the chips for it, right? Right. And that is a standard.
[00:40:37.000 --> 00:40:42.280]   So with T-Mobile, they're talking about both things. They're talking about using a millimeter wave.
[00:40:42.280 --> 00:40:47.720]   They're also talking about phones that use the true cellular 5G radios.
[00:40:47.720 --> 00:40:54.680]   So T-Mobile had initially said that they would have 30 cities with 5G by the end of last year.
[00:40:54.680 --> 00:41:00.520]   That didn't happen. Phones they thought would launch early this year, like now.
[00:41:00.520 --> 00:41:07.960]   There are phones. Still can't buy them. I wouldn't say there are. There's... The Galaxy Fold,
[00:41:07.960 --> 00:41:14.120]   which will be available for April 26th, is 5G. Samsung also has a 5G S10. They have an
[00:41:14.120 --> 00:41:19.240]   announced availability for that. You could buy a Moto X that has the promise of a 5G back,
[00:41:19.240 --> 00:41:23.640]   but there's no 5G back yet. And some of these phones announced in Mobile World Congress,
[00:41:23.640 --> 00:41:31.480]   I guess, will be 5G. Are you saying that we don't... Is the technology... The technology is settled,
[00:41:31.480 --> 00:41:35.320]   right? It's not that they're not... Do they lack the chips? Is that the problem?
[00:41:35.320 --> 00:41:42.120]   No, no. The technology is settled. They're deploying the networks. You have to get the networks out
[00:41:42.120 --> 00:41:45.960]   there. It's a chicken and egg. I understand. You need a phone and you need a network.
[00:41:45.960 --> 00:41:50.680]   You also need a business case. And for a while, the carriers were kind of like,
[00:41:50.680 --> 00:41:57.640]   "We're going to do this, but nobody really wanted it. No one wanted to upgrade. Look at the upgrade
[00:41:57.640 --> 00:42:01.560]   cycles on handsets now are like at three years." That's slowed it down, hasn't it? Yeah.
[00:42:01.560 --> 00:42:05.400]   So, yes, although you could make the case that that's one thing that will get people back in,
[00:42:05.400 --> 00:42:12.440]   if you're suddenly, if you have a phone that can go five times faster, but it's unclear how
[00:42:12.440 --> 00:42:17.400]   much this is going to affect your overall performance. Because we don't have a huge use case. Like,
[00:42:17.400 --> 00:42:22.840]   remember when we went to LTE, that was in the midst of the iPhone sucking up everybody's data.
[00:42:22.840 --> 00:42:24.280]   Right. And it was like, "Ah!"
[00:42:24.840 --> 00:42:33.640]   So, when the FCC or the 3GPP talk about nominal speeds for 5G, that's if no one else is competing
[00:42:33.640 --> 00:42:39.480]   for that bandwidth at the head end. Well, okay, it depends on a couple things.
[00:42:39.480 --> 00:42:46.040]   If you're talking about millimeter wave band, you can. There's a lot of capacity available.
[00:42:46.040 --> 00:42:53.240]   So, because these bands are really fat, you're looking at like 100 megahertz of spectrum all in
[00:42:53.240 --> 00:42:59.640]   one chunk that you could use to like just gig up bits of data, right? So, that's one thing.
[00:42:59.640 --> 00:43:08.200]   The 3GPP radio spec talks about using those bands, but it also works in other bands.
[00:43:08.200 --> 00:43:14.120]   And you're going to see like AT&T deploy over nonmillimeter wave bands. You're going to see Verizon
[00:43:14.120 --> 00:43:19.960]   actually do that too, because millimeter wave bands perform horribly when going through buildings
[00:43:19.960 --> 00:43:22.600]   and that sort of thing. So, you're going to need to have that. There's so high frequency they get
[00:43:22.600 --> 00:43:29.240]   stopped by anything, and they don't propagate very far either. Yeah, so what you're going to see is
[00:43:29.240 --> 00:43:35.240]   kind of a blend of all of these technologies, and they're going to be organized and optimized on
[00:43:35.240 --> 00:43:43.240]   the carrier side, but they are going to be, you're only going to have what you need when you need it,
[00:43:43.240 --> 00:43:46.760]   if that makes sense. It's not going to, not everyone's going to have this massive gigabit
[00:43:46.760 --> 00:43:54.840]   connection. So, that explains, so the Verge is quoting Sprint's CTO John Saw, who was talking
[00:43:54.840 --> 00:44:00.200]   about this at Mobile World Congress. He said, in one demo video they ran, somebody was shown
[00:44:00.200 --> 00:44:06.360]   getting 430 megabits per second, which is nice, right? 430 megabits. But Saw said,
[00:44:06.360 --> 00:44:11.240]   "We don't really want to focus too much on speeds, but the experience."
[00:44:14.040 --> 00:44:19.400]   I don't know what that means. How is the experience of 5G different if you're not talking about it's
[00:44:19.400 --> 00:44:27.400]   faster? That's what I wanted to ask. I'm thinking about just enough lanes on the highway, if you will.
[00:44:27.400 --> 00:44:35.320]   If I'm out at a football game or what have you, and this is a LTE area, and there's 200,000 people
[00:44:35.320 --> 00:44:41.720]   within a five-mile radius, my phone is just going to struggle when it comes to getting data.
[00:44:41.720 --> 00:44:46.600]   Is this the benefit of having 5G? Is this a bigger highway or what?
[00:44:46.600 --> 00:44:52.280]   So, if you stick with the highway analogy, capacity, which is what we're talking about when we talk
[00:44:52.280 --> 00:44:58.600]   about things like 438 megabits per second down, so that's capacity. So, that means everybody can,
[00:44:58.600 --> 00:45:04.520]   you've got that much data can flow through that particular imaginary pipe because it's wireless.
[00:45:04.520 --> 00:45:10.360]   So, if you have lots of people, it's a fat highway, lots of cars can still have a whole megabit to
[00:45:10.360 --> 00:45:17.560]   themselves. Now, 5G, where it really excels in where we're seeing a lot of emphasis from the carriers,
[00:45:17.560 --> 00:45:23.560]   is on latency. So, not only is the highway bigger, but I guess your car can speed faster,
[00:45:23.560 --> 00:45:28.520]   is maybe the way to think about that, but it's lower latency, which will give you a better experience
[00:45:28.520 --> 00:45:37.560]   in some things. So, data calls, database calls, your car getting back and forth to the cloud.
[00:45:37.560 --> 00:45:40.920]   You need low latency if you're using the cloud during your self-driving.
[00:45:40.920 --> 00:45:46.040]   Even speech recognition that's looking at me in my phone, this is my phone hand.
[00:45:46.040 --> 00:45:51.080]   I did this with a small child, like a 4-year-old, and I'm like, "Hey, bring me, bring me."
[00:45:51.080 --> 00:45:55.160]   And she is looking at me and I'm like, "It's a phone." And she's like, "Hello?"
[00:45:55.160 --> 00:46:00.600]   That's really interesting. This is no longer, she's doing, for those of you just listening,
[00:46:00.600 --> 00:46:07.320]   the hang loose bra Hawaiian thing with the pinky and the thumb. It's the universal gesture.
[00:46:07.320 --> 00:46:11.240]   I'm holding it to my thumbs by my ear, pinkies by my hand.
[00:46:11.240 --> 00:46:14.280]   What you're pointing out is that no kid would recognize that as a phone call,
[00:46:14.280 --> 00:46:17.160]   because that doesn't look like anything they've got.
[00:46:17.160 --> 00:46:25.240]   So, yes, now we're going to be going, "Call me with hands folding. Call me."
[00:46:26.280 --> 00:46:32.360]   Okay, sorry, that was a total digression for latency. But, and think about it, we always talk about
[00:46:32.360 --> 00:46:39.480]   it in gaming, but your ADAS systems, also things like industrial IoT, they're looking at that.
[00:46:39.480 --> 00:46:44.520]   They're one of the things that Mobile World Congress was Qualcomm and Bosch got together,
[00:46:44.520 --> 00:46:51.000]   and they're like, "We're going to do research on not this generation of 5G, but 5G NR for the
[00:46:51.000 --> 00:46:59.320]   industrial IoT." And that is super focused on low latency and uses something called deterministic
[00:46:59.320 --> 00:47:05.880]   networking. So, there's a lot of flavors here with 5G. And one of the reasons is because so many
[00:47:05.880 --> 00:47:11.000]   industries need better broadband. So, you're going to have 5G for industrial, you're going to have 5G
[00:47:11.000 --> 00:47:14.360]   for cars. You're going to have Yeah. And I think there are a lot of
[00:47:14.360 --> 00:47:17.720]   So, many of our chatrooms said, a lot of people looking at it and saying, "Hmm, maybe I can
[00:47:17.720 --> 00:47:22.280]   replace my internet service, my landline-based internet service with 5G if it's fast."
[00:47:22.280 --> 00:47:24.200]   And that's what Yeah, Verizon's doing.
[00:47:24.200 --> 00:47:31.240]   Right. Sprint says they will launch their 5G network this May, just took a few months off,
[00:47:31.240 --> 00:47:36.600]   in Atlanta, Chicago, Dallas, and Kansas City. Now, when this happens, right, it's not the whole
[00:47:36.600 --> 00:47:39.960]   It's not all of Dallas, it's parts of It's whatever You have to be in the right area.
[00:47:39.960 --> 00:47:40.920]   Dallas is a huge area.
[00:47:40.920 --> 00:47:46.280]   You know this, Stacy, because you were promised a lot in Austin and got none of it.
[00:47:46.280 --> 00:47:48.600]   Google Fiber didn't reach your curb.
[00:47:48.600 --> 00:47:52.120]   Still sad about that.
[00:47:52.120 --> 00:47:58.280]   It's 5G will come to Houston, L.A., New York, Phoenix, and Washington by the first half of the year.
[00:47:58.280 --> 00:48:00.120]   Here, here, where? Charlotte?
[00:48:00.120 --> 00:48:05.960]   Yeah, well, not 5G, but the Google Fiber discussion. They were supposed to be here in
[00:48:05.960 --> 00:48:10.040]   Charlotte and yeah, that hasn't been working out so well. They got a lot of red tape.
[00:48:10.040 --> 00:48:12.760]   You don't have it now. You ain't getting it. I got bad news for you.
[00:48:12.760 --> 00:48:19.480]   Right. Google's pretty much giving up on that. So, Sprint will have 5G this year in a lot of
[00:48:19.480 --> 00:48:24.520]   markets. Again, you'll have to have a phone. You'll have to find a phone that works with 5G.
[00:48:24.520 --> 00:48:28.760]   Here's the good news, at least for me as a Google Fi subscriber and maybe some of you are,
[00:48:28.760 --> 00:48:31.640]   Sprint said its 5G network will be part of Google Fi.
[00:48:31.640 --> 00:48:39.400]   So, you'd need a Fi phone that's 5G compatible and not clear if that's going to happen.
[00:48:40.120 --> 00:48:44.440]   Sprint's marketing chief also said early Sprint 5G phones. This might be a reason not to rush to
[00:48:44.440 --> 00:48:49.000]   get a 5G phone. Early Sprint 5G phones may not be compatible across networks.
[00:48:49.000 --> 00:48:55.560]   That's because there's not like a unified, like we're not sure what like TMO is doing,
[00:48:55.560 --> 00:49:03.400]   I think 600 megahertz and something else spectrum for their 5G network. AT&T, everybody is doing
[00:49:03.400 --> 00:49:07.720]   different. Sprint doesn't have the spectrum. Doesn't have that super high frequency spectrum.
[00:49:08.440 --> 00:49:13.000]   They don't need it. They can deploy it over. They're going to put it on the mid band spectrum.
[00:49:13.000 --> 00:49:17.000]   Is that CDMA stuff still out there in the wild?
[00:49:17.000 --> 00:49:23.160]   Yes, CDMA is still out in the wild. My Verizon phone still will fail over to CDMA.
[00:49:23.160 --> 00:49:28.600]   Really? I think so. Sometimes like Verizon did, but I wasn't 100% sure.
[00:49:28.600 --> 00:49:33.080]   Sprint and Verizon were CDMA networks, but it's kind of like when you get in a bad area and you
[00:49:33.080 --> 00:49:40.360]   go down to 3G, you go down to LTE to 3G to 2G to no G.
[00:49:40.360 --> 00:49:45.000]   Is there 2G? I don't know, maybe not. But they slowly start, there is this kind of lagging tale
[00:49:45.000 --> 00:49:49.080]   that they slowly get rid of over time. Yeah, I know that a couple carriers have gotten rid of
[00:49:49.080 --> 00:49:55.160]   their 2G or have announced on sets for it. But yeah. Sprint says they will launch on this
[00:49:55.160 --> 00:50:01.080]   mid band spectrum, which is faster than LTE waves. Doesn't travel as far, which by the way,
[00:50:02.200 --> 00:50:07.720]   it's slower than millimeter wave, but travels farther. And Sprint also says it'll rely on
[00:50:07.720 --> 00:50:31.980]   massive MIMO to improve its network capacity. Multi-in-
[00:50:31.980 --> 00:50:38.620]   I don't see a lot of devices, especially handsets, getting like 16 by 16.
[00:50:38.620 --> 00:50:43.100]   There's not a lot of room for that. You've seen these massively MIMO, the Moom MIMO
[00:50:43.100 --> 00:50:48.860]   Wi-Fi routers, they look like spiders. Yeah, they're crazy big. And I mean, it's cool for
[00:50:48.860 --> 00:50:53.660]   a gateway, for example, if you want to stick something out in the middle of a field or,
[00:50:53.660 --> 00:51:00.940]   you know, maybe on top of a car or ambulance. But not, I mean, this is like satellite all over again.
[00:51:00.940 --> 00:51:05.180]   Sprint says it will launch the 5G hotspot. So you're going to see, I think everybody do that.
[00:51:05.180 --> 00:51:11.340]   That's what Verizon is doing right now. And that's for home and office, not for mobile.
[00:51:11.340 --> 00:51:19.820]   So really, this is a mess. It's not a mess. It's just, we're using the phrase 5G to mean like
[00:51:19.820 --> 00:51:25.820]   three different things. Right. Right. It's confusing to consumers, that's for sure.
[00:51:26.620 --> 00:51:33.180]   It is, but consumers. We're not all Hermione. Well, no, when consumers, you know,
[00:51:33.180 --> 00:51:42.860]   I wouldn't buy. So here's my take for your consumer take. I wouldn't buy a 5G phone expecting
[00:51:42.860 --> 00:51:50.300]   anything awesome, nor would you need it. Anytime this year, it probably well into next. At the end
[00:51:50.300 --> 00:51:56.140]   of 2020, if you wanted to upgrade, you're going to get something out of it. But I don't think this
[00:51:56.140 --> 00:51:59.260]   year you're going to get a lot out of having a quote unquote 5G phone.
[00:51:59.260 --> 00:52:03.740]   And see, I was thinking earlier with my whole power user
[00:52:03.740 --> 00:52:11.740]   discussion, it was, it seems like the 5G talk is still marketing, speak and marketing towards
[00:52:11.740 --> 00:52:17.900]   people being able to quote unquote do more, you know, as if they're using phones, do everything.
[00:52:18.940 --> 00:52:26.700]   No, I think if you were buying 5G for fixed wireless, I think that's something you could buy today.
[00:52:26.700 --> 00:52:32.460]   And within the next year, like if you hate your cable provider, it's going to provide another
[00:52:32.460 --> 00:52:38.940]   option for cable, basically. Okay. But it'll be from someone like Verizon. So you're like,
[00:52:38.940 --> 00:52:40.620]   still be somebody you hate, but it just.
[00:52:40.620 --> 00:52:43.180]   Different someone you hate. It's different.
[00:52:43.180 --> 00:52:48.380]   Some of you hate. All right. So there's the 5G explainer. It was a, you know, it was all over
[00:52:48.380 --> 00:52:53.580]   Mobile World Congress. But again, this is, you know, it's up in the air as to how this is going
[00:52:53.580 --> 00:52:59.020]   to come out and how I think you miss Stacy. Yes. Thank you. You kind of stop calling me Miss Stacy.
[00:52:59.020 --> 00:53:01.980]   Hermione hitting a bottom. Throwin' me out there, man.
[00:53:01.980 --> 00:53:09.340]   Mine married to Miss Stacy. Miss. Miss. Miss. Miss. Miss Stacy.
[00:53:11.580 --> 00:53:17.260]   Every new flagship will have a 5G variant of the phones showed at Mobile World Congress.
[00:53:17.260 --> 00:53:24.540]   Like the Galaxy S10 5G, the V50, the LG V55G, the Xiaomi Mi Mix 35G.
[00:53:24.540 --> 00:53:31.340]   Whoa. So, but don't try, your advice, I think, is right. Unless you're,
[00:53:31.340 --> 00:53:36.940]   unless you're, you know, planning to keep this phone for five years, you probably shouldn't buy it now.
[00:53:38.220 --> 00:53:41.420]   I mean, it's not worth the call. Two years from now, baby. It calls premium
[00:53:41.420 --> 00:53:45.420]   hubs from 5G. Right. Then just say, buy a folding phone instead.
[00:53:45.420 --> 00:53:53.180]   And then, and this is from Tom's guide where they had a great article on 5G,
[00:53:53.180 --> 00:53:58.220]   Stuff. Caitlin McGarry and Adam is male of 5G takeaways of Mobile World Congress.
[00:53:58.220 --> 00:54:02.620]   And one of them was expect weird and wonderful devices.
[00:54:03.820 --> 00:54:10.220]   I liked that one. Yeah. This is the HTC hub. This is the one that I think
[00:54:10.220 --> 00:54:15.500]   Sprint said it would be offering later this year. It's a hotspot, but it's got a big five-inch
[00:54:15.500 --> 00:54:20.220]   display on it. So it can stand on its own. It's got Android Pi, it can stream media,
[00:54:20.220 --> 00:54:25.660]   play games, even run apps. There's an ethernet cable you can plug into other devices if
[00:54:25.660 --> 00:54:30.940]   you want to get even faster speed, Bluetooth connectivity for controllers.
[00:54:31.740 --> 00:54:36.460]   I'm glad HTC has found something to do. I wonder if there's a microphone on it.
[00:54:36.460 --> 00:54:44.940]   Oh, there's definitely. I'm like, oh, no. It's a Snapdragon 855. It's a hotspot with heart.
[00:54:44.940 --> 00:54:51.420]   That's what I'm going to call it. A hotspot with heart. Oh, yeah. Google's getting in trouble
[00:54:51.420 --> 00:54:57.660]   with a microphone thing. Stacy just added a little article to our rundown. I guess Congress,
[00:54:58.780 --> 00:55:02.940]   we talked about this last week. People found out that the Google home was what was it?
[00:55:02.940 --> 00:55:08.300]   It's the microphone on the Nest Guard box. It's part of the Nest security system.
[00:55:08.300 --> 00:55:14.780]   The Nest, it's like the base unit, right? Of the Nest. And now Congress is calling.
[00:55:14.780 --> 00:55:23.660]   There's a letter. The United States Senate, Congress is calling on Google to explain to me,
[00:55:23.660 --> 00:55:30.300]   Google, what else you got microphones on. We gave them a pass last week as you may run.
[00:55:30.300 --> 00:55:36.140]   Oh, but this is actually a good point. If you should like to do it, you should go to the
[00:55:36.140 --> 00:55:40.620]   state, San IOT because I did a consumer bill of rights for connected devices.
[00:55:40.620 --> 00:55:43.980]   And one of the things we talked about, I think we may have talked about this last week,
[00:55:43.980 --> 00:55:46.940]   was that you should disclose that you have a microphone on there. And there's some other
[00:55:46.940 --> 00:55:54.300]   things that you should do. But that's what the this is the Commerce Committee of the US Senate
[00:55:54.300 --> 00:56:01.820]   is asking them, hey, have you always had this? Right. What happened? How did you not list it?
[00:56:01.820 --> 00:56:03.900]   Right. What changed? Yeah.
[00:56:03.900 --> 00:56:09.420]   These are and my favorite is, is Google aware of similar omissions of the technical specs for
[00:56:09.420 --> 00:56:17.660]   other Google products. Wow. Wow. What else has got a mic Google and has Google been aware of any
[00:56:17.660 --> 00:56:22.460]   third party using the Nest secure microphone for any unauthorized purchase or purpose not purchase.
[00:56:22.460 --> 00:56:28.940]   The senators have asked a Googler respond by March 12th. And they are asking for an in-person
[00:56:28.940 --> 00:56:35.820]   briefing to committee staff. Must be so often to be a Congress person and say I would love to just
[00:56:35.820 --> 00:56:41.420]   be able to be like Sundar. Come here. Get over here. Sundar. I have some questions for you.
[00:56:41.420 --> 00:56:50.540]   You're in trouble. You're in trouble, buddy. Get over here. Sundar. Most of the time they don't
[00:56:50.540 --> 00:56:54.620]   know an iPhone from a pixel. So I don't know if I want to be a Congress. I think Congress is getting
[00:56:54.620 --> 00:57:00.940]   a little smarter. This is the Commerce Committee and the subcommittee on communications, technology
[00:57:00.940 --> 00:57:05.500]   innovation, the unit, John Thune, Roger Wicker, Jerry Moran. Yeah, they're getting better. I
[00:57:05.500 --> 00:57:12.540]   think they're not as dumb as they used to be. Could this be a situation where Google just
[00:57:12.540 --> 00:57:17.580]   please please the Fifth Amendment? Yeah, no, I don't think you're loud. You don't have to do that.
[00:57:17.580 --> 00:57:28.220]   Maybe. I don't know. I'm not a lawyer. So yeah, interesting. Google is also facing the Supremes.
[00:57:29.580 --> 00:57:37.020]   You remember that Google lost in an Oracle Google lawsuit? Oracle, there was this one went on for
[00:57:37.020 --> 00:57:47.660]   on forever forever. Yeah, basically, the question boiled down to something really off target,
[00:57:47.660 --> 00:57:56.860]   but this was the best that Oracle could do, which was, is it a copyright violation to use
[00:57:56.860 --> 00:58:03.820]   a published API? And of course, if the thanks to the ruling, which said, yeah, it is, that
[00:58:03.820 --> 00:58:09.420]   violates copyright, you can copyright an API that kind of breaks the notion of APIs, because
[00:58:09.420 --> 00:58:15.260]   APIs, like we have a public API for our podcasts, we want people to write software that uses the
[00:58:15.260 --> 00:58:21.340]   public API. That's the purpose of an API. But Oracle is saying, because they couldn't get Google
[00:58:21.340 --> 00:58:26.620]   just on copying Java, that didn't work out. They lost on that. So they said, well, okay,
[00:58:26.620 --> 00:58:33.100]   but Java's API is copyright and Google emulated it writing a completely compatible
[00:58:33.100 --> 00:58:40.700]   language that uses the Java API and the courts upheld Oracle's rights there. So now it's in front
[00:58:40.700 --> 00:58:47.740]   of the Supreme Court. And dozens of briefs are coming in from the tech community in Google's
[00:58:47.740 --> 00:58:55.740]   favor, Mozilla, Microsoft, Python, Red Hat, Electronic Frontier Foundation, 65 intellectual
[00:58:55.740 --> 00:59:04.460]   property scholars, among others, because everybody understands that APIs and the use of APIs is
[00:59:04.460 --> 00:59:08.620]   kind of critical to the entire way the software and destroyers. The lingua franca of the internet.
[00:59:08.620 --> 00:59:14.620]   Perfect. Perfect. Damages. We don't know what the damages are. One point Oracle was asking for
[00:59:14.620 --> 00:59:21.100]   $8.8 billion. The lower court has not yet ruled on damages. But I don't think it's the money from
[00:59:21.100 --> 00:59:28.060]   at this point for Google. Oracle General Counsel said, despite Google and it's Amici's, those are
[00:59:28.060 --> 00:59:33.660]   the people the Amici's curiai briefs that are coming in in its favor despite how you say that?
[00:59:33.660 --> 00:59:40.540]   Well, Amici's curiai. Yes. Okay. I don't know if it's Amici or Amici.
[00:59:40.540 --> 00:59:46.620]   When I was learning Latin, so church and church Latin, it would be Amici, a soft C.
[00:59:47.260 --> 00:59:51.260]   But when I was learning Latin, the whole new thing, and this was like 100 years ago, but the whole
[00:59:51.260 --> 00:59:59.660]   new thing was, oh no, C's are hard. So it's not Cicero. It's kick-a-row, which nobody liked.
[00:59:59.660 --> 01:00:06.380]   Amici, unless something's changed, and if you're a Latin scholar, please contact me.
[01:00:06.380 --> 01:00:12.540]   I had no idea how to say the words. I only know how to spell them. So I'm like, oh, amici is friend,
[01:00:12.540 --> 01:00:18.860]   curiai is of the court. I love the fact that Latin has a gift, gift, discussion happening.
[01:00:18.860 --> 01:00:22.540]   Oh, oh, yeah. Oh, yeah. Okay. So instead of Caesar, it's Kaiser.
[01:00:22.540 --> 01:00:28.620]   Kaiser. Oh, okay. Like the roll. Like the Kaiser roll. I don't think that's.
[01:00:28.620 --> 01:00:36.060]   Anyway, I said Amici because that's the Italian or the church Latin pronunciation,
[01:00:36.060 --> 01:00:41.100]   but I think actually it's probably Amici. Anyway, this, I will read it again. I don't even know if
[01:00:41.100 --> 01:00:45.820]   Oracle's general counsel knows how to pronounce it. Despite Google and it's Amici's overheated
[01:00:45.820 --> 01:00:51.420]   rhetoric predicting the end of the software industry, it has continued to thrive. Well,
[01:00:51.420 --> 01:00:55.900]   that's true. With increased R&D spending, higher investment in innovation and hiring demand
[01:00:55.900 --> 01:01:01.020]   outpacing supply. In other words, he says, there's no issue. The arguments are without merit,
[01:01:01.020 --> 01:01:05.020]   and we want our billions. The court will decide. Now, there's an example
[01:01:06.700 --> 01:01:13.660]   of a Supreme Court that I think is woefully inadequate to decide this one. But we'll find out.
[01:01:13.660 --> 01:01:18.700]   They're pretty smart. They're smart. Oh, I'm not saying they're smart,
[01:01:18.700 --> 01:01:23.340]   but do they know from an API? I hope they have. Someone in the chat room said, you know,
[01:01:23.340 --> 01:01:29.340]   we're talking about APIs like web services. And this is about web APIs as just,
[01:01:29.340 --> 01:01:35.100]   I don't remember what they said. Well, you know, I didn't know there was a difference.
[01:01:35.100 --> 01:01:39.020]   So I'm sitting here thinking about this. I'm like, oh, like just the language of the API.
[01:01:39.020 --> 01:01:43.500]   Yeah. As you know, Android was originally Java. And what Google when Google got in,
[01:01:43.500 --> 01:01:50.780]   you know, Oracle said, yeah, we let Java's license for free and you can use it for free.
[01:01:50.780 --> 01:01:54.860]   But we don't intend for you to make this massively successful commercial product.
[01:01:54.860 --> 01:02:02.140]   And so we want some they lost and that then they said, well, okay, but and then Google in the
[01:02:02.140 --> 01:02:10.780]   meantime, started to rewrite it in a created Java like it was it Dalvik? A Java like language that
[01:02:10.780 --> 01:02:15.020]   stuff could be written in that would have compatible APIs, because otherwise everything breaks.
[01:02:15.020 --> 01:02:20.460]   And then Oracle said, no, you can't use even if you're not using Java anymore.
[01:02:20.460 --> 01:02:27.580]   We still got you because you're using our copyrighted API in your new Java clone.
[01:02:28.540 --> 01:02:36.380]   So I mean, on the one hand, I kind of understand. Yeah, I mean, what is an API? It merely says,
[01:02:36.380 --> 01:02:42.380]   when you when a program sends you this message, you respond with this message. That's really
[01:02:42.380 --> 01:02:48.460]   fundamentally all it is. Should that be? Could you copyright? How you respond to a message and
[01:02:48.460 --> 01:02:52.460]   what the message how the message is formed? The how the query and answer a form? Can you
[01:02:52.460 --> 01:03:02.380]   copyright that? Seems to me not. I don't know. It's complicated. So the reporter checked in with
[01:03:02.380 --> 01:03:06.220]   Professor William McCarthy of the Greek and Latin Department of Catholic University.
[01:03:06.220 --> 01:03:11.900]   He never asked a Catholic. The professor said Amicus. So that's how I thought it was.
[01:03:11.900 --> 01:03:17.980]   I'm a key. So the K is the C is hard, but the emphasis is on the first syllable.
[01:03:21.020 --> 01:03:27.820]   So I don't I don't think anybody from that Roman era is here to tell us how they pronounced it.
[01:03:27.820 --> 01:03:35.420]   So presumably they've got clerks who know what's going on. And some of these guys may
[01:03:35.420 --> 01:03:39.900]   understand it. You're right. I mean, it can be explained to them in a way that they understand
[01:03:39.900 --> 01:03:44.380]   it and then they can they can rule on it. So maybe maybe they are. Oh, holy cow, someone in
[01:03:44.380 --> 01:03:50.300]   the chat room just threw up a William Sapphire column all about this from 1997. It's called
[01:03:50.300 --> 01:03:57.900]   when a justice needs a friend. You got a friend? Wow. There are two kinds of legal kibbetsers.
[01:03:57.900 --> 01:04:04.300]   Those who pronounce amicus amicus and nobody pronounces amicus, which is how I initially.
[01:04:04.300 --> 01:04:08.380]   And those who pronounce it amicus. Each submits a brief as an outsider,
[01:04:08.380 --> 01:04:13.340]   ostensibly not with an interest in the outcome of the case, but as a friend of the court in Latin,
[01:04:13.340 --> 01:04:17.340]   amicus curii. You know, this is why I miss William Sapphire.
[01:04:17.580 --> 01:04:25.820]   Um, Justice Breyer had his own pronunciation. He said amicus.
[01:04:25.820 --> 01:04:30.940]   Okay, we'll see. Now I don't feel bad. I feel much because I always said amicus.
[01:04:30.940 --> 01:04:37.740]   Apparently William McCarthy is. Oh, this is the one who agreed. Breyer pronunciation was non-standard
[01:04:37.740 --> 01:04:49.820]   in the professor for amicus amicus. I'm sorry. This is totally derailleur. No, no, this is exactly
[01:04:49.820 --> 01:04:55.980]   what twig is all about. Brian Garner, editor of the dictionary of modern legal usage and editor
[01:04:55.980 --> 01:05:08.220]   of the seventh edition of blacks law dictionary says it sounds like a micus.
[01:05:08.220 --> 01:05:22.460]   What? Oh, Lord. Justice Breyer adopted an Anglo-Latin pronunciation. It will make any Latin teacher
[01:05:22.460 --> 01:05:27.580]   apoplectic, but it has English and American history behind it. And in the end, that matters more than
[01:05:27.580 --> 01:05:37.180]   how Cicero or kick a row might have mouhed the phrase. So glad I have no use for this word in my
[01:05:37.180 --> 01:05:44.140]   camera. This thing goes on. There's a lot more. I don't know if he really comes to a conclusion.
[01:05:44.140 --> 01:05:50.860]   I used to love those articles about things like that as you words. I love words. You love words.
[01:05:50.860 --> 01:05:55.420]   You're a writer. You got to love words. I'm a reporter. I never call myself a writer.
[01:05:55.420 --> 01:05:59.500]   Really? Never. And why is that? You don't want your right.
[01:05:59.500 --> 01:06:05.340]   So you like to report though. I do. I love learning. Yeah. I'm a wonk man.
[01:06:05.340 --> 01:06:12.940]   Her mind. I've never heard that phrase until today. Really? Yeah. No, she's a wonk. It's a good
[01:06:12.940 --> 01:06:19.100]   thing. Being a wonk in my mind is right out there with being a geek. Oh, standing. Yeah.
[01:06:19.100 --> 01:06:24.220]   What if I'm a wonk who plays D and D? What does that make me? Then you're a wonk. Oh, geek. Or a geeky
[01:06:24.220 --> 01:06:31.260]   one. Okay. Okay. I was just curious. No, you can be both a geek in my opinion is anybody who has
[01:06:31.260 --> 01:06:37.820]   an outsized enthusiasm for a narrow slice of stuff, usually technology, but it could be comic books.
[01:06:37.820 --> 01:06:45.100]   5G 5G. You're anything. Yeah. And a wonk, in my opinion, if William Sapphire were here,
[01:06:45.100 --> 01:06:50.620]   we'd ask him. But in my opinion, a wonk is somebody who really loves the nitty gritty details of everything
[01:06:50.620 --> 01:06:58.860]   and studies it and will be glad to tell you. So you're a geeky wonk. Excellent.
[01:06:58.860 --> 01:07:04.140]   So what should we talk about next? Have we killed? I mean, do we want to talk about the Huawei thing
[01:07:04.140 --> 01:07:10.620]   that was overshadowing or mobile? Yeah. I mean, I've gotten people writing to me saying shame on
[01:07:10.620 --> 01:07:16.460]   you, Leo, for falling for, you know, the US government's propaganda against Huawei. But I think it's hard
[01:07:16.460 --> 01:07:23.980]   to turn your back on numerous convictions or arrests anyway now on spying and accusations of
[01:07:23.980 --> 01:07:27.580]   spying. And I think there's a lot of evidence that Huawei isn't maybe the
[01:07:27.580 --> 01:07:35.020]   upstanding global citizen, one would hope, but is much more likely than the thrall of the Chinese
[01:07:35.020 --> 01:07:42.220]   government. I still don't know if the calls to, you know, abandon Huawei 5G gear is a political
[01:07:42.220 --> 01:07:47.900]   move. I tell you how we'll know though, where it looks like the president has now indicated he wants
[01:07:47.900 --> 01:07:54.940]   to sign a trade agreement with China is backing down considerably. And if he does, and all of a
[01:07:54.940 --> 01:08:00.540]   sudden the calls to get rid of Huawei disappear, well, then you'll know. Yes. Or if Huawei just
[01:08:00.540 --> 01:08:06.300]   tells him he had they have six G then, you know, yeah, he's anxious to get six G. He can have it.
[01:08:06.300 --> 01:08:14.300]   Wi-Fi baby. New name. New name just to screw everything up. And Huawei says there's no evidence
[01:08:14.300 --> 01:08:20.620]   of the claims against us. Somebody in the chat room says, just because it's propaganda doesn't
[01:08:20.620 --> 01:08:25.900]   mean it's not true. All of that is true. And the problem is it's just very hard to know.
[01:08:28.060 --> 01:08:33.740]   Yeah. The Chinese government had funded Huawei. There are close ties.
[01:08:33.740 --> 01:08:41.740]   Yes. In China is not a transparent country. And it does have a pretty good stranglehold on its
[01:08:41.740 --> 01:08:47.660]   corporate leaders. So it's really hard to assess these claims. And I think you could safely say
[01:08:47.660 --> 01:08:53.420]   that even if today Huawei is not spying, that the nature of being a Chinese company with
[01:08:53.980 --> 01:08:59.180]   investment from the Chinese government is if they were asked to spy down the road,
[01:08:59.180 --> 01:09:03.820]   they wouldn't really even be able to say no. Although AT&T did the same thing. So
[01:09:03.820 --> 01:09:08.940]   Spied on us. Right. Spied on us. That the NSA into the AT&T wire closet.
[01:09:08.940 --> 01:09:15.820]   Right. So I mean, yes, it's different, but it's also not unprecedented that a government would
[01:09:15.820 --> 01:09:22.620]   that's true to its companies and be like, hello. So speaking at Mobile World Congress,
[01:09:22.620 --> 01:09:33.420]   Guoping, who I guess is the chairman of Huawei said, we don't do bad things. I think that was
[01:09:33.420 --> 01:09:41.100]   Google's motto for some time. He's the rotating. He's the road. Yeah. According to the CNBC,
[01:09:41.100 --> 01:09:47.820]   he's the rotating chairman. I can do that too. I have a rotating chair, but he's the rotating
[01:09:47.820 --> 01:09:52.460]   chairman of the world's largest provider of telecommunications equipment, Huawei, where most
[01:09:52.460 --> 01:09:58.620]   5G equipment comes from, although the US has been pressuring allies not to use Huawei's technology
[01:09:58.620 --> 01:10:05.420]   and its 5G networks. Guoping said, to build a system that we can all trust, we need aligned
[01:10:05.420 --> 01:10:10.700]   responsibility, unified standards and clear regulations. We could proudly say 5G is safer
[01:10:10.700 --> 01:10:16.300]   than 4G. And as a vendor, we don't operate carriers networks and we don't own carrier data.
[01:10:16.300 --> 01:10:21.820]   In a way, he's pointing to the fact that at least one carrier in the US was handing over your
[01:10:21.820 --> 01:10:27.740]   information, not to the Chinese government, but to our government. Well, in there are like,
[01:10:27.740 --> 01:10:32.540]   Ericsson, for example, does deals with carriers where they will operate their network for them.
[01:10:32.540 --> 01:10:40.300]   So there is there. Yeah, there is a distinction to be made between AT&T, which owns and operates,
[01:10:40.300 --> 01:10:44.220]   its network and buys the gear from them and somebody who doesn't.
[01:10:44.220 --> 01:10:49.740]   There is a precedent for Huawei executives getting hot under the collar. I remember at CES last
[01:10:49.740 --> 01:10:53.900]   year, not this most recent one, but... Okay, well, that was legit, man. They like just suddenly
[01:10:53.900 --> 01:11:00.540]   pulled his big announcement. Yeah, he was about to go on stage and say the Huawei P20 phone,
[01:11:00.540 --> 01:11:04.140]   which is a great phone, which I have Paul Theriot uses. I didn't realize that.
[01:11:04.140 --> 01:11:10.060]   Was about to announce that they were going to have a carrier deal in the US with Verizon and AT&T.
[01:11:10.060 --> 01:11:15.100]   Under pressure from the administration, Verizon and AT&T pulled out and Huawei's
[01:11:15.100 --> 01:11:21.500]   chairman got up on stage furious, livid, because instead of making a great announcement, he had to
[01:11:21.500 --> 01:11:24.700]   say, "You're not going to be able to get this phone in the US. You're not going to be able to get
[01:11:24.700 --> 01:11:29.020]   the Huawei fold in phone either because they don't sell phones in the US because of that."
[01:11:29.020 --> 01:11:33.740]   They say, "Without a carrier, there's no point in us trying to market a phone in the US.
[01:11:33.740 --> 01:11:38.620]   We need a carrier partnership." And that's true. I mean, remember, there was a smartphone before
[01:11:38.620 --> 01:11:43.180]   the iPhone. It was the Nokia phones and nobody in the US had them because the carriers wouldn't
[01:11:43.180 --> 01:11:46.460]   subsidize them. And this was back in that day. So it makes sense.
[01:11:46.460 --> 01:11:52.220]   Here's, by the way, your consumer rights bill of rights. And do you have on there,
[01:11:52.220 --> 01:11:56.220]   probably should have on there something about it and it won't let the Chinese government spy on you.
[01:11:56.220 --> 01:11:59.900]   I didn't do that because this was a little bit more generic.
[01:11:59.900 --> 01:12:05.180]   But it is things to look for. You should know. There should be disclosure.
[01:12:05.180 --> 01:12:08.620]   What sensors are in there, especially if, "Oh, hi, Stacey!"
[01:12:08.620 --> 01:12:13.100]   Especially, no, no. Every site does that. Every site does that.
[01:12:13.100 --> 01:12:16.780]   They'll pop up saying, "Sign up for my newsletter, even though I'm already signed up."
[01:12:16.780 --> 01:12:22.780]   So the ones that, like, yes, disclose all of your sensors, but things like an expiration date
[01:12:22.780 --> 01:12:25.820]   for devices. So when are you going to stop hatching them? That's really good.
[01:12:25.820 --> 01:12:30.060]   Okay. More than an expiration date, a commitment to continue to patch them to that point.
[01:12:30.620 --> 01:12:35.260]   You know, a commitment. That's what I want. I want to know when you're going to stop supporting it,
[01:12:35.260 --> 01:12:38.700]   but I want your commitment that you will support it right up to that day, the bitter end.
[01:12:38.700 --> 01:12:41.100]   And Microsoft does that with their operating systems.
[01:12:41.100 --> 01:12:43.180]   You know. It seems like it all works. Yeah.
[01:12:43.180 --> 01:12:48.540]   Yeah. Well, the IoT devices are like, they're coming in and they do it for enterprise. So
[01:12:48.540 --> 01:12:53.420]   Microsoft and Google and even Qualcomm will support enterprise chips for seven to 10 years.
[01:12:53.420 --> 01:12:57.740]   But they don't do it for consumer devices, which I feel is...
[01:12:58.460 --> 01:13:04.540]   So we had a really good sponsor. I really liked them. Lighthouse. It had time of flight sensor in it.
[01:13:04.540 --> 01:13:10.140]   It had camera in it. It had night vision. It had a lot of AI in it. I used it. And they just
[01:13:10.140 --> 01:13:14.940]   went out of business. I'm sad to say they did the right thing, though. They refunded every owner.
[01:13:14.940 --> 01:13:19.100]   I had the CEO on my podcast. We talked about time of light sensors.
[01:13:19.100 --> 01:13:25.820]   Yeah. It's... That's an example of a company with all the right
[01:13:27.340 --> 01:13:32.860]   ideas with a great product. And what he said was, I think it was too expensive because it was like
[01:13:32.860 --> 01:13:38.460]   over 300 bucks. And I think it was competing against... I mean, crying out loud, you're competing
[01:13:38.460 --> 01:13:43.500]   now against the WISE cam for $20. And people just couldn't see their way of spending that
[01:13:43.500 --> 01:13:49.500]   much money and then subscribing to a service as well. All right. But if you were a lighthouse,
[01:13:49.500 --> 01:13:55.180]   if you did buy a lighthouse, especially if you bought it because I said how good it was, which it was,
[01:13:56.540 --> 01:14:03.660]   Alex has written a post at LIGHT.House. And they did commit to refunding everybody some money.
[01:14:03.660 --> 01:14:08.460]   So I presume that I hope they've contacted you and said something about it. Now I have this
[01:14:08.460 --> 01:14:15.100]   great lighthouse which I'm going to put in my museum of dead technology. I wish there were some
[01:14:15.100 --> 01:14:19.740]   way to keep it working. But without the back end service, there's nothing.
[01:14:19.740 --> 01:14:20.540]   Yeah.
[01:14:22.620 --> 01:14:26.540]   So I would say the other thing I put in there that I want to make a plug for is two-factor
[01:14:26.540 --> 01:14:31.420]   authentication for connected devices. Absolutely. Wish they would do that.
[01:14:31.420 --> 01:14:37.820]   Nest, does it? Chamberlain for the MyQ does it? I'm looking for other devices that do it. So we'll
[01:14:37.820 --> 01:14:42.620]   see if that's... What you're saying when you're saying do it, it means when you log into your Nest,
[01:14:42.620 --> 01:14:50.220]   my Nest Home website, you need a password and a second factor which is through an authenticator.
[01:14:51.340 --> 01:14:57.500]   Yes. And you link your devices to an account. And this actually, there was a rash of stories
[01:14:57.500 --> 01:15:01.580]   recently about Nest cameras getting hacked, but they weren't hacked. It's just that someone's
[01:15:01.580 --> 01:15:06.620]   password on the Nest camera, they used it in multiple places and someone then got into it.
[01:15:06.620 --> 01:15:07.100]   Exactly.
[01:15:07.100 --> 01:15:08.140]   Is that hacking?
[01:15:08.140 --> 01:15:11.580]   No. And had they had two-factor, wouldn't even have mattered.
[01:15:11.580 --> 01:15:15.180]   So you get different password all the time and use two-factor. You know,
[01:15:16.460 --> 01:15:22.220]   I can't think of a single router manufacturer that is two-factor. And there are a lot of routers.
[01:15:22.220 --> 01:15:26.140]   I should tell it, you're like, "Hey, Nick Weaver, get on that."
[01:15:26.140 --> 01:15:30.060]   Well, I think probably you should write a letter to Jeff Bezos now that he owns a company.
[01:15:30.060 --> 01:15:35.020]   Is it deal close yet? It was announced.
[01:15:35.020 --> 01:15:36.700]   Probably not. It takes a while. These things take a while.
[01:15:36.700 --> 01:15:42.220]   Yeah, that's a perfect example. You wrote should because you're rose managed over the network.
[01:15:42.940 --> 01:15:46.540]   So that's really important that you have that kind of security.
[01:15:46.540 --> 01:15:51.100]   And I can do things with Eero such as block devices on my network.
[01:15:51.100 --> 01:15:51.340]   Right.
[01:15:51.340 --> 01:15:52.860]   I can see all kinds of-
[01:15:52.860 --> 01:15:55.660]   There are a lot of routers that don't have that or don't-
[01:15:55.660 --> 01:16:00.780]   You turn off that remote administration, the WAN administration.
[01:16:00.780 --> 01:16:05.340]   But Eero kind of requires it. And many mesh routers do require it. Plung does that.
[01:16:05.340 --> 01:16:10.620]   Warby does not do that. Warby's more like a traditional router.
[01:16:11.260 --> 01:16:12.460]   They're not a real mesh.
[01:16:12.460 --> 01:16:13.260]   No, they're-
[01:16:13.260 --> 01:16:13.900]   Well, they are.
[01:16:13.900 --> 01:16:16.300]   Wow.
[01:16:16.300 --> 01:16:17.500]   You have a dog there too?
[01:16:17.500 --> 01:16:20.140]   That's my dog.
[01:16:20.140 --> 01:16:21.740]   The dog is the fan of warby.
[01:16:21.740 --> 01:16:22.860]   It travels with me.
[01:16:22.860 --> 01:16:24.620]   He loves those. He loves his Orbeez.
[01:16:24.620 --> 01:16:32.140]   Yeah, but I do think routers, at least if they require wide area network administration,
[01:16:32.140 --> 01:16:35.020]   should have two factor.
[01:16:35.020 --> 01:16:36.940]   I agree with you 100% on that, Stacey.
[01:16:37.820 --> 01:16:42.380]   They also, if they have data, who gets access to the data and how long it's kept?
[01:16:42.380 --> 01:16:43.500]   Very, very important.
[01:16:43.500 --> 01:16:45.580]   That should be in the privacy policy, obviously.
[01:16:45.580 --> 01:16:47.980]   I love the expiration date.
[01:16:47.980 --> 01:16:49.260]   I think that's really good.
[01:16:49.260 --> 01:16:53.820]   Do you anticipate that as time goes by, you'll add new clauses to this agreement?
[01:16:53.820 --> 01:16:55.020]   I hope so.
[01:16:55.020 --> 01:16:58.140]   I think there are lots of things that I'm hoping people will say,
[01:16:58.140 --> 01:16:59.500]   "Hey, we should totally have this too."
[01:16:59.500 --> 01:16:59.820]   Yes.
[01:16:59.820 --> 01:17:01.020]   So.
[01:17:01.020 --> 01:17:01.260]   Yes.
[01:17:01.260 --> 01:17:02.940]   Demand of them.
[01:17:02.940 --> 01:17:05.260]   Hermione says so-
[01:17:05.260 --> 01:17:06.140]   I'm really sorry, guys.
[01:17:06.140 --> 01:17:06.620]   Hold on.
[01:17:06.620 --> 01:17:07.900]   I'm a barking dog.
[01:17:07.900 --> 01:17:09.740]   Well, I'll tell you what.
[01:17:09.740 --> 01:17:13.980]   While Stacey feeds the visitors to the dog,
[01:17:13.980 --> 01:17:18.060]   I'll tell you a little bit about our sponsor for today.
[01:17:18.060 --> 01:17:19.020]   Kaptera.
[01:17:19.020 --> 01:17:22.780]   This week in Google, brought to you by Kaptera.
[01:17:22.780 --> 01:17:27.660]   Kaptera is a great company if you are looking for software for your business.
[01:17:27.660 --> 01:17:30.220]   So this is an issue.
[01:17:30.220 --> 01:17:31.660]   You can consume your software.
[01:17:31.660 --> 01:17:35.580]   There's plenty of places to go to read reviews and find the software and ask friends and stuff.
[01:17:35.580 --> 01:17:38.060]   But business software, it's a bigger expense.
[01:17:38.060 --> 01:17:40.060]   You're going to run your business on it.
[01:17:40.060 --> 01:17:42.860]   And it's hard to figure out what the best business software is.
[01:17:42.860 --> 01:17:47.180]   Sometimes people Google it, but that just gives you a kind of a dump of all kinds of
[01:17:47.180 --> 01:17:48.780]   things that aren't necessarily related.
[01:17:48.780 --> 01:17:52.140]   If you're, let's say you have a, I don't know, a veterinary office
[01:17:52.140 --> 01:17:56.140]   and on our Stacey's dog and you want software to run it,
[01:17:56.140 --> 01:18:00.780]   what would be the best way to find veterinary office management software?
[01:18:00.780 --> 01:18:01.420]   Kaptera.
[01:18:01.420 --> 01:18:02.860]   Kaptera.com.
[01:18:02.860 --> 01:18:04.060]   It's a free service.
[01:18:04.060 --> 01:18:09.900]   It has over 700 specific categories of software, everything from project management
[01:18:09.900 --> 01:18:14.300]   to email marketing to yoga studio management software.
[01:18:14.300 --> 01:18:17.420]   But the thing I love best, there are a few things I really like about Kaptera.
[01:18:17.420 --> 01:18:18.700]   It's the fact that it's free.
[01:18:18.700 --> 01:18:22.780]   There are more than three quarters of a million reviews from actual users.
[01:18:22.780 --> 01:18:24.300]   And they're really good with those reviews.
[01:18:24.300 --> 01:18:25.020]   They're really venom.
[01:18:25.020 --> 01:18:26.940]   So those are reviews you can trust.
[01:18:26.940 --> 01:18:31.580]   Plus they have a really easy way to find the software you want,
[01:18:31.580 --> 01:18:37.020]   find the various versions, narrow it down with check boxes to say,
[01:18:37.020 --> 01:18:40.300]   "Well, no, it has to be online or no, it has to be on premises," or,
[01:18:40.300 --> 01:18:43.020]   "It has to be able to do email as well.
[01:18:43.020 --> 01:18:45.900]   It has to be able to make appointments," whatever it is you're looking for.
[01:18:45.900 --> 01:18:48.540]   Narrow it down and then compare them head to head.
[01:18:48.540 --> 01:18:50.460]   It couldn't be easier.
[01:18:50.460 --> 01:18:52.140]   This will really simplify your search.
[01:18:52.140 --> 01:18:56.380]   If you're looking for business software, join the millions of people who use Kaptera
[01:18:56.380 --> 01:19:01.260]   every month to find the right tools for your business, no matter what it is you need.
[01:19:02.220 --> 01:19:04.700]   It's the leading free online resource.
[01:19:04.700 --> 01:19:09.580]   And you can check it out right now at captera.com.
[01:19:09.580 --> 01:19:11.580]   There really is no business software that's not on there.
[01:19:11.580 --> 01:19:12.300]   It's amazing.
[01:19:12.300 --> 01:19:16.300]   captera.com/twig.
[01:19:16.300 --> 01:19:18.780]   Go there just so they know you heard it on twig.
[01:19:18.780 --> 01:19:20.380]   Kaptera.com/twig.
[01:19:20.380 --> 01:19:23.420]   And make this the year you get the right software.
[01:19:23.420 --> 01:19:28.460]   Stop suffering with old line of business software when you get something modern new
[01:19:28.460 --> 01:19:29.900]   that works great.
[01:19:29.900 --> 01:19:34.860]   Kaptera, even if you're in a weird line of business or you have weird needs, they'll have it.
[01:19:34.860 --> 01:19:38.380]   captera.com/twig.
[01:19:38.380 --> 01:19:41.500]   Stacey has calmed the beast.
[01:19:41.500 --> 01:19:44.060]   I'm not sure about that, but we'll see.
[01:19:44.060 --> 01:19:46.620]   The beast has been tamed.
[01:19:46.620 --> 01:19:49.340]   I shut the doors against the beast.
[01:19:49.340 --> 01:19:53.580]   So, YouTube's been going through a weird thing.
[01:19:53.580 --> 01:19:57.180]   For a long time on YouTube, I think we were somehow whitelisted.
[01:19:57.180 --> 01:19:59.660]   They thought we were a news organization and we are.
[01:19:59.660 --> 01:20:00.140]   I think.
[01:20:00.140 --> 01:20:03.980]   We didn't get context strikes against us.
[01:20:03.980 --> 01:20:07.900]   And then something changed in the content ID system last week.
[01:20:07.900 --> 01:20:09.420]   And it wasn't just us.
[01:20:09.420 --> 01:20:11.580]   There are a lot of weird content strikes.
[01:20:11.580 --> 01:20:16.300]   We got Macbreak Weekly got pulled down because we showed and talked about an apple
[01:20:16.300 --> 01:20:17.420]   ad in the middle of the show.
[01:20:17.420 --> 01:20:26.060]   But then Linus on text podcast took down his own podcast for content ID.
[01:20:26.060 --> 01:20:27.740]   I don't even know how that works.
[01:20:28.860 --> 01:20:30.620]   So, I think there's something weird going on.
[01:20:30.620 --> 01:20:34.620]   If you are at YouTube, can you whitelist us so that we don't?
[01:20:34.620 --> 01:20:35.660]   Because we got another one.
[01:20:35.660 --> 01:20:38.380]   We got another ding that didn't even make sense.
[01:20:38.380 --> 01:20:39.420]   It was completely out of nowhere.
[01:20:39.420 --> 01:20:40.940]   And I feel like the content ID system.
[01:20:40.940 --> 01:20:44.700]   Probably because YouTube has been going under such heat.
[01:20:44.700 --> 01:20:47.340]   Here's a new one.
[01:20:47.340 --> 01:20:53.020]   This is from The Washington Post, a pediatrician, a Florida doctor
[01:20:53.020 --> 01:20:56.140]   who's got the great name Free Hess.
[01:20:56.140 --> 01:21:07.180]   A found instructions for suicide in videos on YouTube kids.
[01:21:07.180 --> 01:21:11.180]   Holy crap.
[01:21:11.180 --> 01:21:15.340]   She says minutes into the clip from a children's video game, a man appeared on the screen
[01:21:15.340 --> 01:21:19.020]   offering instructions on how to kill yourself.
[01:21:19.020 --> 01:21:19.740]   I was shocked.
[01:21:19.740 --> 01:21:24.860]   Has said noting that since then the scene's been spliced, that scene has been spliced
[01:21:24.860 --> 01:21:31.100]   into several more videos from the popular Nintendo game Splatoon on YouTube and YouTube kids.
[01:21:31.100 --> 01:21:34.380]   YouTube kids specifically aimed at children supposedly safe for children.
[01:21:34.380 --> 01:21:39.020]   Yeah, that's not great.
[01:21:39.020 --> 01:21:43.740]   I don't want to trigger anybody, so I won't talk about what the clip has,
[01:21:43.740 --> 01:21:47.420]   but it's extremely detailed and totally inappropriate.
[01:21:47.420 --> 01:21:51.900]   She says, "I think it's extremely dangerous for our kids."
[01:21:51.900 --> 01:21:56.780]   Yeah. And I'm telling The Washington Post, I think our kids are facing a whole new world
[01:21:56.780 --> 01:22:00.860]   with social media and internet access. It's changing the way they're growing
[01:22:00.860 --> 01:22:02.380]   and it's changing the way they're developing.
[01:22:02.380 --> 01:22:05.180]   And I think videos like this put them at risk.
[01:22:05.180 --> 01:22:12.060]   It's not clear why this YouTube personality, Filthy Frank, is his name,
[01:22:12.060 --> 01:22:17.180]   did this, but his fans have been known to put him in memes and other videos.
[01:22:17.180 --> 01:22:21.260]   It could just be just for the lols, you know?
[01:22:21.260 --> 01:22:22.140]   It is probably.
[01:22:22.140 --> 01:22:24.940]   There's six people out there.
[01:22:24.940 --> 01:22:32.060]   I've got my daughter, she downloaded some, I can't think of the name of it right now.
[01:22:32.060 --> 01:22:39.340]   It's a character building app and that is fine. There's censored chat that we talked about,
[01:22:39.340 --> 01:22:44.780]   but the YouTube videos, which when she plays any game, she's constantly on the YouTube videos
[01:22:44.780 --> 01:22:49.660]   for that game are crazy disturbing. It's like someone was like, "Oh kids love this.
[01:22:49.660 --> 01:22:55.820]   Let's use it to really screw with their heads." So we did a deal where she does not watch those
[01:22:55.820 --> 01:22:58.220]   YouTube videos and she can have the app.
[01:22:58.220 --> 01:23:05.500]   And you know, as we gave YouTube a pass last week, because...
[01:23:05.500 --> 01:23:08.380]   No, no, we didn't on the pedophiles.
[01:23:08.380 --> 01:23:14.300]   Well, it's not that it's just that it's hard. Well, we gave them a half a pass.
[01:23:15.020 --> 01:23:19.420]   I think they... Look, it's hard to police YouTube. It's just so massive.
[01:23:19.420 --> 01:23:25.900]   I mean, clearly we want them to do a better job and they want to do a better job. I mean,
[01:23:25.900 --> 01:23:29.900]   they don't want this stuff showing up in YouTube kids anymore than they want the pedophile comments
[01:23:29.900 --> 01:23:34.700]   to show up on innocent videos of children. That's not something... I mean, you can't accuse them
[01:23:34.700 --> 01:23:39.580]   of wanting that. Maybe they need to work harder on stopping it.
[01:23:40.860 --> 01:23:44.460]   Hire some more people to train these algorithms that are doing.
[01:23:44.460 --> 01:23:47.900]   Well, but you saw the... You know, this is the problem. We call for that.
[01:23:47.900 --> 01:23:55.660]   And then you saw the article from... Oh my God, Casey Newton writing in the Verge on the horrific
[01:23:55.660 --> 01:24:03.260]   lives led by these Facebook moderators. The trauma floor, the secret lives of Facebook
[01:24:03.260 --> 01:24:11.660]   moderators in America, just horrific. It's a job nobody wants. Nobody should have to do.
[01:24:11.660 --> 01:24:18.620]   There are a thousand people doing this for Facebook and Phoenix, 15,000 around the world.
[01:24:18.620 --> 01:24:25.260]   And they see the worst. I mean, it's worse than being a cop. They see the worst.
[01:24:25.260 --> 01:24:29.580]   You feel for those people because they end up... I mean, they could potentially end up being
[01:24:29.580 --> 01:24:38.060]   desensitized too. Well, and Casey starts with talking about a specific worker who was having
[01:24:38.060 --> 01:24:43.260]   panic attacks because of what she saw. I don't want to... Again, it's too graphic. I don't want to
[01:24:43.260 --> 01:24:52.780]   talk about it. But the stuff she saw made her nuts. Made her just... I mean, people being murdered.
[01:24:54.780 --> 01:25:03.260]   People are awful. But again, that team of a thousand people are needed. They are...
[01:25:03.260 --> 01:25:09.580]   Desperated. Well, but think about how many hours of content... It's like 36 hours for every hour
[01:25:09.580 --> 01:25:15.900]   of content is uploaded or 36 hours of content is uploaded to YouTube. Like, for every... Every hour.
[01:25:15.900 --> 01:25:20.140]   Every hour, every minute. I don't remember that. I think every minute. It keeps going up,
[01:25:20.140 --> 01:25:27.420]   obviously. People can't keep up with that. So how do we figure this out? Because it is a problem,
[01:25:27.420 --> 01:25:34.780]   and it's running away from us. And we can figure this out. We just... Maybe it results in more
[01:25:34.780 --> 01:25:41.180]   legit takedowns. I don't know. Casey also points out that moderators make... At least the Phoenix
[01:25:41.180 --> 01:25:48.940]   moderators make $28,800 a year while the average Facebook employee has a total compensation of
[01:25:48.940 --> 01:25:57.340]   240,000. You've got to be kidding me. Yeah. And I think there's a high level of PTSD,
[01:25:57.340 --> 01:26:04.060]   as you might imagine. And once they leave the company, there's no support for that from anybody.
[01:26:04.060 --> 01:26:10.940]   There is a counselor on duty, but only for part of the day.
[01:26:10.940 --> 01:26:18.620]   It doesn't sound like a good job. Well, that's on Facebook, in my opinion.
[01:26:18.620 --> 01:26:23.340]   That's on Facebook. Maybe you just share. Yeah, you're making a lot of money. You can pay them
[01:26:23.340 --> 01:26:31.180]   better. You can help them. You can support them. You know, I think I was on this week in Google.
[01:26:31.180 --> 01:26:38.460]   I discussed talking about Apple and how the executives that make a gazillion dollars,
[01:26:38.460 --> 01:26:43.420]   you have the sales team that makes a gazillion dollars far as trying to sell services and what
[01:26:43.420 --> 01:26:48.540]   not. But then you go to the Apple store and those folks are not making a lot of money.
[01:26:48.540 --> 01:26:53.100]   Well, look at Amazon where it's even there's an even greater Gulf.
[01:26:53.100 --> 01:26:59.740]   Right. But all of those people at the bottom of that food chain, they have some serious value there,
[01:26:59.740 --> 01:27:04.700]   and they should be compensated for it. Now you guess, this is America. This is how it works.
[01:27:04.700 --> 01:27:10.860]   I understand people have college degrees and experience and education and all of that can
[01:27:11.660 --> 01:27:18.540]   warrant having extra wages. I get that. So I went to college, but at the same time,
[01:27:18.540 --> 01:27:26.060]   it shouldn't be such a huge gap when you got people staring at a screen of just disgusting content
[01:27:26.060 --> 01:27:31.980]   and trying to protect the eyeballs of my hard-headed kids from seeing it out there accidentally.
[01:27:31.980 --> 01:27:36.780]   You know, those people should should, leadership should look at that and fix that from a
[01:27:36.780 --> 01:27:45.100]   compensation standpoint. It seems unfair, but this is life in a capitalist society.
[01:27:45.100 --> 01:27:50.540]   On the other hand, I would submit to Facebook that it's important to do a better job of this
[01:27:50.540 --> 01:27:56.860]   because the upshot of this and YouTube too is that you will lose customers because people
[01:27:56.860 --> 01:28:00.460]   won't let their kids look at Facebook. They don't want to, I'm not on Facebook. I don't want to
[01:28:00.460 --> 01:28:06.300]   near Facebook. I very rarely go to YouTube. Whatever I do, I never read YouTube comments.
[01:28:06.300 --> 01:28:15.340]   So this hurts your business. If you can't get to them out of humanity, and I'm a business owner,
[01:28:15.340 --> 01:28:24.540]   I pay my employees terribly, but that's business. What I do is I don't know anything about what
[01:28:24.540 --> 01:28:31.260]   they get paid. My CEO, my business partner, my wife does that, and she doesn't tell me.
[01:28:31.260 --> 01:28:37.260]   So I can say, when I'm brought up in court or for the Congress, I can say, "Well, I don't know.
[01:28:37.260 --> 01:28:41.660]   You'll have to ask." You'll have to ask. I don't have to watch anything quite as bad as I do.
[01:28:41.660 --> 01:28:46.860]   It's almost as bad. Close. And you may have PTSD. I mean, you have to have us arguing over
[01:28:46.860 --> 01:28:52.380]   Latin pronunciations of what I mean. He's a Harvard man. He loves that kind of stuff I've heard.
[01:28:53.100 --> 01:28:58.700]   He's like, "No, I'll tell you, because I spent my whole life until very recently,
[01:28:58.700 --> 01:29:04.380]   until I started my own business as an employee. I think I am trying to be a better employer.
[01:29:04.380 --> 01:29:09.500]   I want to be the employer that I wanted when I was an employee. But honestly, it's America.
[01:29:09.500 --> 01:29:14.220]   You got to pay minimum wage, but that's about it.
[01:29:14.220 --> 01:29:21.420]   So I think the way to appeal to Facebook and YouTube and other companies and Twitter,
[01:29:21.420 --> 01:29:25.260]   I would guess you throw them in there too, is just appeal to their greed,
[01:29:25.260 --> 01:29:29.660]   appeal to their bottom line and say, "Look, this is going to hurt you. It is going to hurt them,
[01:29:29.660 --> 01:29:37.260]   isn't it?" See, this is why we need metrics above and beyond profits to measure how corporations are.
[01:29:37.260 --> 01:29:41.820]   We have to measure the externalities and the costs of social-- Well, you're just a socialist.
[01:29:41.820 --> 01:29:44.300]   What? That's not a socialist one.
[01:29:44.300 --> 01:29:49.020]   It doesn't have to be socialism for me to call you a socialist. You understand that, right?
[01:29:49.020 --> 01:29:54.620]   Right. Can I call you a Nazi? Yeah, absolutely. You know how it works.
[01:29:54.620 --> 01:30:00.300]   Is that the next level? Socialist, Nazi. Yeah, there you go. Perfect.
[01:30:00.300 --> 01:30:03.260]   Perfect. Fascist, socialist, socialist. Perfect.
[01:30:03.260 --> 01:30:09.180]   What do we live in a terrible world? I wish we could fix this. I do. I really do.
[01:30:09.180 --> 01:30:15.100]   Most people are good, aren't they? Yes, they are, Aunt. I know you know that, Aunt.
[01:30:15.660 --> 01:30:21.820]   I know you believe. I'm not going to say most. Oh, really? You don't think it's more than 51%?
[01:30:21.820 --> 01:30:28.220]   I can't say that. I see a whole lot of stuff, brother.
[01:30:28.220 --> 01:30:35.500]   I'm just fortunate that I deal with more than 51%.
[01:30:35.500 --> 01:30:37.660]   Yes, try to stick around the people. Stick with the good ones.
[01:30:37.660 --> 01:30:44.220]   Well, that's even more depressing. Yeah, let's take some cheery news.
[01:30:44.220 --> 01:30:45.900]   I can. I like to believe that.
[01:30:45.900 --> 01:30:50.780]   Well, how about this Wall Street Journal article that talks about an app called
[01:30:50.780 --> 01:30:58.460]   Flow that women use to monitor their menstrual cycles in order to get pregnant and things like
[01:30:58.460 --> 01:31:04.940]   that. Turns out Flow has code in it from Facebook that even if you're not a Facebook subscriber,
[01:31:04.940 --> 01:31:10.540]   even if you don't have the Facebook app, even if you're not logged in, it tells
[01:31:10.540 --> 01:31:15.980]   Facebook when you're menstruating, among other things. So Bloomberg did the story like two or
[01:31:15.980 --> 01:31:23.340]   three weeks ago, but yes. Oh, well, let's get credit to Bloomberg then. Bloomberg had a period
[01:31:23.340 --> 01:31:27.900]   tracking apps or fertility tracking apps share more data than you think. And the times has been
[01:31:27.900 --> 01:31:34.140]   doing articles like that as well. Yep. So, yeah, this is this is part of that. Hey,
[01:31:35.020 --> 01:31:42.300]   before you, you know, having a clear and easy way to share what data goes out to what people is,
[01:31:42.300 --> 01:31:45.820]   I mean, really, that's that should be a minimal standard.
[01:31:45.820 --> 01:31:50.460]   The journal hired somebody to test this they found, for instance, instant heart rate,
[01:31:50.460 --> 01:31:55.660]   which is the most popular heart rate app on iOS, sends it a user's heart rate to Facebook
[01:31:55.660 --> 01:32:06.780]   immediately after it's recorded. Realtor.com, which is a real estate app, which by the way is owned
[01:32:06.780 --> 01:32:12.700]   by a subsidiary of the Wall Street Journal, or actually the parent Corp News Corp, sends the
[01:32:12.700 --> 01:32:17.260]   location of price of listings that you view noting which ones were marked as favorites to Facebook.
[01:32:17.260 --> 01:32:23.900]   Facebook's got a lot of data down there. And the thing is, there's no way to stop that because if
[01:32:23.900 --> 01:32:29.820]   you're using it doesn't say it explicitly, it's just you can't you won't even know.
[01:32:29.820 --> 01:32:38.860]   That's crazy. I read a Yula the other day from a product that was sent to me to review.
[01:32:38.860 --> 01:32:44.460]   And I'm glad I read the Yula first because it confused me. So I've just put the product down.
[01:32:44.460 --> 01:32:47.820]   Yeah. Do you mind if I read two lines? Yeah, let's hear it.
[01:32:48.700 --> 01:32:55.100]   All right. So it says, and I changed a company's name in there. It says, you own personally
[01:32:55.100 --> 01:33:01.340]   identifiable user generated data. ABC company can't use it without your consent. Oh, that's good.
[01:33:01.340 --> 01:33:09.100]   Yeah. Then it says, you grant ABC company a revocable, non-exclusive, worldwide, royalty-free
[01:33:09.100 --> 01:33:14.460]   license to reproduce, distribute, transmit, publicly perform, publicly display, digitally
[01:33:14.460 --> 01:33:19.900]   perform, modify, create, derivative works of, and otherwise use personally identifiable
[01:33:19.900 --> 01:33:24.620]   user generated data. Oh, that's hysterical. So they start by saying, you know, without your
[01:33:24.620 --> 01:33:29.100]   consent, we can't do anything. Can we have your consent? The next sentence. The next sentence.
[01:33:29.100 --> 01:33:34.940]   They don't know. At least it's right there. Yeah. Well, they know nobody reads it. Yeah,
[01:33:34.940 --> 01:33:39.260]   at least it's right there. But why even bother to say we can't without your consent? And then
[01:33:39.260 --> 01:33:47.580]   so why aren't you telling us what the product name is? I guess I could, but no, this is just
[01:33:47.580 --> 01:33:53.020]   not my style. Yeah. But you know, Instagram gotten a lot of heat because Instagram wanted some
[01:33:53.020 --> 01:33:59.340]   similar rights to your photos, right? Mm hmm. I mean, this is an uncommon. And I think, you know,
[01:33:59.340 --> 01:34:05.020]   in defense of this lawyers, write these because you always, when you write a contract,
[01:34:06.300 --> 01:34:12.380]   take the broadest rights you can because you never know. You know, maybe we'll make a billboard ad
[01:34:12.380 --> 01:34:16.380]   out of your photo. And then, you know, we don't want any problem with that afterwards.
[01:34:16.380 --> 01:34:21.580]   We wouldn't want to have to ask your permission. Yeah. We got your permission. Don't you remember?
[01:34:21.580 --> 01:34:29.660]   You clicked OK. Otherwise, it's not scalable. Facebook did kill that O'Nava app that we were
[01:34:29.660 --> 01:34:35.340]   talking about the Android VPN app. It was a VPN, right? Yeah, they killed that. That was, but you
[01:34:35.340 --> 01:34:40.700]   know, honestly, and maybe this is cynical of me, but my reaction to this is, oh, yes, as soon as
[01:34:40.700 --> 01:34:44.460]   they get caught, they kill it. But that doesn't stop them from doing something different. In fact,
[01:34:44.460 --> 01:34:48.940]   that's exactly what happened with O'Nava when Apple said, you can't do that. They made a new app,
[01:34:48.940 --> 01:34:53.820]   just put the Enovo code into that and sell that on the iPhone or gave that away on the iPhone.
[01:34:53.820 --> 01:35:00.940]   So it doesn't, it doesn't encourage me when companies say, Oh, gosh, oh, I'm so sorry. We won't, we'll
[01:35:00.940 --> 01:35:08.780]   never do that again because. And again, I'm not one that's going to just totally bulk at
[01:35:08.780 --> 01:35:14.860]   some of these companies having my data because I love what Google does for me and my day-to-day
[01:35:14.860 --> 01:35:21.260]   life for me squared away, knowing my habits and things of that nature. And, you know, hey,
[01:35:21.260 --> 01:35:26.540]   you got an appointment to go go to here in a little while, you need to leave now, go pick up your
[01:35:26.540 --> 01:35:31.980]   son because he's got to be there on time. And you know, just, I love that stuff. It really does help
[01:35:31.980 --> 01:35:38.860]   me out when they can feed in and pull useful information like that. The whole ad standpoint,
[01:35:38.860 --> 01:35:44.540]   the people at these tech companies claimed that they're doing it for, I never really see it.
[01:35:44.540 --> 01:35:50.620]   And I never see targeted ads or anything like that. Nine times out of 10, I guess,
[01:35:50.620 --> 01:35:55.900]   it's because of my VPN. But when it comes to some of the other stuff, far as, you know, Google
[01:35:55.900 --> 01:36:03.100]   reading my email that knows that, you know, my monthly bill for whatever services do on such
[01:36:03.100 --> 01:36:07.500]   as such day, make sure your bank account is ready for that automatic draft, you know,
[01:36:07.500 --> 01:36:15.180]   I dig that to an extent. Yeah, I mean, it's not, it's not all bad.
[01:36:15.180 --> 01:36:19.260]   It's, it's not over. Yeah, it's not.
[01:36:19.260 --> 01:36:25.980]   We just have to keep an eye on it and call them, call them out like you just did. And that's good.
[01:36:25.980 --> 01:36:29.500]   Yeah, but he didn't call them out. He did not know as who it was.
[01:36:29.500 --> 01:36:35.100]   I didn't call them out publicly, but I did email them back with the screenshot of the
[01:36:35.100 --> 01:36:41.100]   Yula because it is, it was for a device that's going to be measuring things medically.
[01:36:41.100 --> 01:36:47.500]   Oh, wow. Oh, wow. Yeah. And so of course, I wanted to read it a little closer. And I took a screenshot
[01:36:47.500 --> 01:36:51.980]   of it and I sent it to them and I said, Hey, so what's the deal with this, this, this, you,
[01:36:51.980 --> 01:36:55.180]   what are you for reading it? I mean, most people, they know most people don't read them.
[01:36:55.180 --> 01:37:04.220]   Where was that? That was, that's little Jack, somebody downstairs,
[01:37:04.220 --> 01:37:09.340]   rung the doorbell. So the biggest quote unquote, my smallest dog is deciding to bark.
[01:37:09.340 --> 01:37:14.540]   He's not that small, I bet. No, he's small. Oh, he's a teacup Chihuahua.
[01:37:14.540 --> 01:37:18.540]   Oh, it's small. That is a big dog as a bark unless he needs to.
[01:37:18.540 --> 01:37:24.620]   It's always that way, isn't it? Big dogs never bark. Big, big dogs don't need to bark.
[01:37:24.620 --> 01:37:30.860]   It's true for humans too, I think. True. Here's an IOT story. Ray Aussie, you know that name.
[01:37:30.860 --> 01:37:37.180]   He helped create Lotus Notes, worked at Microsoft. Oh, yeah, this story. Yeah, he is creating a new
[01:37:37.180 --> 01:37:45.820]   company called Blues. What is it? Blues Wireless. The idea is that you might have an IOT device,
[01:37:45.820 --> 01:37:53.340]   but it does not have to connect to your Wi-Fi. It has its own connectivity built in on 3G or 4G.
[01:37:53.340 --> 01:38:01.020]   And so you could add the Blues Wireless module to your IOT device. And it would be more secure
[01:38:01.020 --> 01:38:06.940]   because everything's encrypted, secure credential stored on the device itself. It's set up to
[01:38:06.940 --> 01:38:14.620]   connect wirelessly at the factory, so it's easier for users. I have a scale. I'm on this
[01:38:14.620 --> 01:38:20.380]   medically supervised diet, you know, program, weight loss program. And they sent me a scale.
[01:38:20.380 --> 01:38:26.220]   And it just, and I said, "Well, do I have to pair this to my phone or set it up on the
[01:38:26.220 --> 01:38:30.940]   Internet?" And he says, "No, no, it just sends it to us. Whenever I weigh myself, it just boom,
[01:38:30.940 --> 01:38:38.300]   they get it." And I guess it's using. It's got to be using, you know, cell connectivity somehow.
[01:38:38.300 --> 01:38:43.820]   It has a number, I guess, a serial number, and they just connect that to my accountant.
[01:38:43.820 --> 01:38:48.060]   It says, "I weigh myself. It shows up in the app." It's like, "Oh, that was weird." So that's what
[01:38:48.060 --> 01:38:58.140]   this would do. Like a Kindle, right? Kindle has whisper sync. They plan to sell the modules at
[01:38:58.140 --> 01:39:02.860]   enough of a profit to cover the cost of the device and the wireless data. IoT devices,
[01:39:02.860 --> 01:39:06.380]   unless their cameras don't use a lot of data, right? That scale is not using a lot of data
[01:39:06.380 --> 01:39:09.980]   sending. No, usually it's like a kilobyte, less than a kilobyte a day.
[01:39:09.980 --> 01:39:16.620]   It wouldn't be for cameras, obviously. That would not, that would not, that would be cost prohibitive.
[01:39:16.620 --> 01:39:23.900]   Let's do the thing with the trums and trumpet. What do you say?
[01:39:25.740 --> 01:39:34.140]   The Google change log. New stuff from Google.
[01:39:34.140 --> 01:39:40.860]   Ant hasn't been here since we started doing that. Oh, no, my favorite segment. I love this.
[01:39:40.860 --> 01:39:43.420]   Oh, you love the change log. Apparently Stacy does not.
[01:39:43.420 --> 01:39:46.860]   Either that she's wearing her invisibility cloak.
[01:39:46.860 --> 01:39:50.940]   Building the Google Assistant on phones for everyone,
[01:39:51.740 --> 01:39:56.620]   everywhere Google Assistant is now coming to the Android Messages app.
[01:39:56.620 --> 01:40:05.020]   It will do the kinds of things that Alo, I guess, did. Assistant is in maps. You might have
[01:40:05.020 --> 01:40:09.340]   noticed that. Assistant everywhere. I think this makes a lot of sense. And of course,
[01:40:09.340 --> 01:40:12.940]   it makes it easier for Google to collect information, but we won't mention that.
[01:40:12.940 --> 01:40:19.580]   If you're chatting with your friends in the Android Messages app and you need to quickly
[01:40:19.580 --> 01:40:23.500]   look something up, your assistant will help at any point. Just press the home button,
[01:40:23.500 --> 01:40:28.300]   long press the home button, and it will pop up. And it can even see what you're saying, I gather,
[01:40:28.300 --> 01:40:31.820]   and show you stuff then. That's how Alo worked. That was really cool.
[01:40:31.820 --> 01:40:37.260]   You would say, "Hey, let's go to dinner. What restaurant are you going to go to?" I don't know
[01:40:37.260 --> 01:40:42.060]   how about tellies. And then it would just pop up. You can make a reservation right in the messenger.
[01:40:42.060 --> 01:40:45.740]   That's good. Now that they've killed Alo, it's good to have.
[01:40:45.740 --> 01:40:47.900]   Convenient. Yeah. Really convenient.
[01:40:47.900 --> 01:40:51.980]   I wish they'd fixed their messaging platform because I'm a Google Fi user. I want to have a
[01:40:51.980 --> 01:40:58.380]   cross-platform messaging that I can use on my iOS and Mac, as well as Android. And Android
[01:40:58.380 --> 01:41:04.940]   Messages does not do that, but Hangouts does. But that's really something. I used Hangouts. I
[01:41:04.940 --> 01:41:10.140]   said, "What? That's still there. It's still around." Yeah. It's just barely hanging on by a thread.
[01:41:10.140 --> 01:41:10.940]   Yeah. Hangouts.
[01:41:10.940 --> 01:41:17.740]   Google Voice Person. Yeah. Same problem. It's fairly convenient being able to access it
[01:41:17.740 --> 01:41:23.900]   over to web or whatever like that. But it still has its quirks from a messages standpoint.
[01:41:23.900 --> 01:41:29.500]   Now, thanks to Google Play Services, Android devices running version 7 or later,
[01:41:29.500 --> 01:41:36.620]   we'll use FIDO2 to let you use a fingerprint or pin to log into various services. I think
[01:41:36.620 --> 01:41:41.820]   that's a great thing because, of course, on many phones now, you are doing biometric logins.
[01:41:41.820 --> 01:41:47.420]   And it would be really nice if those logins would extend to apps, websites, and other places.
[01:41:47.420 --> 01:41:53.180]   And apparently FIDO2, that standard does have that. And that may be soon. You'll be able just to do
[01:41:53.180 --> 01:42:04.060]   that everywhere you go. FIDO2 supports a variety of authentication methods. And it's also supported
[01:42:04.060 --> 01:42:11.260]   in Chrome, Edge, and Firefox. Developers do have to adopt the FIDO API to support the feature.
[01:42:13.820 --> 01:42:20.300]   Let's see. What else? Google says Android 1. That's the inexpensive version of Android.
[01:42:20.300 --> 01:42:30.220]   Android 1 activations grew very popular. 250% year over year. So people like--
[01:42:30.220 --> 01:42:30.780]   That's awesome.
[01:42:30.780 --> 01:42:34.940]   Isn't that good? Yeah. I mean, everybody can't afford a $1,000 phone.
[01:42:34.940 --> 01:42:41.180]   50% of the new entry-level Android devices are Android Go. Digital well-being tools also
[01:42:41.180 --> 01:42:49.900]   coming to more phones. Google Docs AI-powered grammar checker is coming to everyone on G Suite.
[01:42:49.900 --> 01:42:56.860]   G Suite is the paid business version. Grammarly it ain't. Grammarly is our advertiser,
[01:42:56.860 --> 01:43:02.300]   but it's also the case. Grammarly it ain't. But it does have some nice features.
[01:43:02.300 --> 01:43:10.940]   So for instance, if you write something is more likely not to do something, they'll suggest
[01:43:10.940 --> 01:43:13.420]   maybe you should say more likely to not.
[01:43:13.420 --> 01:43:20.380]   I would ask Stacy about it, but she's not a writer. She's a reporter.
[01:43:20.380 --> 01:43:27.100]   That's right. I have an editor for those end questions. I pay her lots of money. So she handles
[01:43:27.100 --> 01:43:34.540]   those kind of things. Did you watch the Oscars? Did you see the new Google Assistant commercials?
[01:43:34.540 --> 01:43:36.860]   Let's play them.
[01:43:36.860 --> 01:43:40.540]   Okay. Wait, is this going to get you probably some YouTube?
[01:43:40.540 --> 01:43:44.860]   Unfortunately, some nice YouTube employees going to make sure that we are whitelisted as a news
[01:43:44.860 --> 01:43:49.260]   organization. Because three strikes is their policy there is really brutal.
[01:43:49.260 --> 01:43:55.420]   No, you don't want to blow it. Here is, you don't mind if I play a commercial of yours. Google,
[01:43:55.420 --> 01:44:01.100]   do you really? Hey, let's go to the movies. Open the pod bay doors, Hal.
[01:44:01.100 --> 01:44:07.340]   What loves that? Hello, how do you read me? Hey, open the pod bay doors.
[01:44:07.340 --> 01:44:14.700]   Oh, I wish. Okay. If you know, 2001 is space on us, you'll get that showing your photos.
[01:44:14.700 --> 01:44:21.260]   You should just go to city college. Oh, these are all movies. I get it.
[01:44:21.260 --> 01:44:27.900]   This is my, I saw this part. This is hysterical. So you remember Lady Bird, right? Was that the
[01:44:27.900 --> 01:44:33.980]   name of it? Oh, it's great. The opening scene, mom's talking to her daughter and driving her nuts.
[01:44:33.980 --> 01:44:38.780]   Eventually, her daughter hurls herself out of the moving car. She's going so crazy. But in this
[01:44:38.780 --> 01:44:43.100]   version, she instead asked Google Assistant to book her a lift ride.
[01:44:43.100 --> 01:44:47.260]   To the city college, learn to pull yourself off your lift has arrived. Everybody to do everything.
[01:44:47.260 --> 01:44:54.380]   Are you ready? What do you do? How do you do?
[01:44:54.380 --> 01:45:00.860]   Or a police run away? Oh, it just doesn't work. What was that scream?
[01:45:00.860 --> 01:45:08.060]   Just doesn't work if you've got a nest camera, right? Here's a Jerry Maguire.
[01:45:08.060 --> 01:45:14.460]   Remember that great scene? Show me the money. Cuba Gooding Jr. Show me the money.
[01:45:14.460 --> 01:45:20.780]   Here you go. By the way, I tried that immediately after that commercial.
[01:45:20.780 --> 01:45:24.380]   And it works. You can tell your assistant, show me the money. I'll show you the Dow Jones
[01:45:24.380 --> 01:45:30.380]   Industrial Average. Of course it does. Of course it does. So the theme of this is make Google do it.
[01:45:30.380 --> 01:45:37.420]   No! With Home Hub, Home Mini, and Pixel 3M. I'm glad the remote.
[01:45:37.420 --> 01:45:41.980]   Hey, what's on my calendar today? At 5.30 p.m. You have appear in Google commercial.
[01:45:41.980 --> 01:45:48.940]   That's never going to happen. Tell them Deadpool, Deadpool humor. That is a good ad.
[01:45:49.500 --> 01:45:55.180]   Yeah, that was. That's clever. It was. And it's nice to do an ad that ties in with the movies when
[01:45:55.180 --> 01:46:05.660]   you're doing an ad on the Oscars. And just for the record, Spike Lee was robbed. As was Alfonso
[01:46:05.660 --> 01:46:09.420]   Cuarn. I really thought, and I think we talked about it last week, I really thought,
[01:46:09.420 --> 01:46:14.460]   Roma would win Best Picture and it would have been a big deal for the technology world because it
[01:46:14.460 --> 01:46:22.060]   would be a Netflix movie winning an Academy Award, a streaming first movie. And I actually think
[01:46:22.060 --> 01:46:30.060]   that might be why it didn't win. Because there's no way the Academy is going to allow that to happen.
[01:46:30.060 --> 01:46:30.540]   Yes.
[01:46:30.540 --> 01:46:34.300]   Right. But Black Panther could have won, Black Clansman could have won.
[01:46:34.300 --> 01:46:38.140]   Green Book is a, it's driving Miss Daisy for the 21st century.
[01:46:38.140 --> 01:46:42.780]   It was so treacle-y. Treacle-y is a good word. Treacle-y is a good word.
[01:46:42.780 --> 01:46:49.100]   I enjoyed it. That's saying I didn't enjoy it. But it was a little treacle-y. Kind of glossed over
[01:46:49.100 --> 01:46:55.020]   maybe some significant race issues in the 60s in the South. Maybe, I don't know.
[01:46:55.020 --> 01:47:06.620]   Maybe. Maybe just a little bit. Living the multi-dream by blending coding with a rap career.
[01:47:08.380 --> 01:47:14.540]   What? Brandon Torrey is a Googler. He works in the LA office on artificial intelligence,
[01:47:14.540 --> 01:47:19.900]   training computer models to better understand how humans use language, why we use certain words,
[01:47:19.900 --> 01:47:27.660]   or describe things in a certain way. But once he leaves the office, by day, Google employee,
[01:47:27.660 --> 01:47:35.820]   by night, let me just play a little another, we're going to get another ding for this, are we?
[01:47:36.700 --> 01:47:44.140]   This is a little, oh yes. A little Brandon Torrey. Brandon Torrey is living the multi-dream,
[01:47:44.140 --> 01:47:50.780]   spreading the word in the next generation. Oh, there it is. There it is, a multi-dream.
[01:47:50.780 --> 01:47:52.780]   So.
[01:47:52.780 --> 01:48:02.060]   I like him. I like him.
[01:48:02.060 --> 01:48:09.500]   I'm sure my family would dig it. I don't know if it's a hit.
[01:48:09.500 --> 01:48:13.420]   I'm sure my family would dig it. He says he got into technology after seeing Good Will
[01:48:13.420 --> 01:48:21.500]   hunting the Matrix and hackers when he was 13. He was a homeless teenager in Brockton,
[01:48:21.500 --> 01:48:26.060]   Massachusetts. Got support from his church, went dumpster diving for parts to build his first
[01:48:26.060 --> 01:48:30.540]   computer. He spray-painted it black. He recalls spending 12 to 14 hours a day during his teenage
[01:48:30.540 --> 01:48:38.620]   years in online forums, learning sea, assembly, and Python. That's the good stuff.
[01:48:38.620 --> 01:48:50.380]   Got an E.E. degree in college. But, and he loved the music and he liked hip hop, but he decided
[01:48:50.380 --> 01:48:54.940]   once he got his E.E. degree, I'm packing it up, I'm moving to Atlanta. I'm going to try to break
[01:48:54.940 --> 01:48:58.860]   into the music industry. I want to be a star. So he bought a $1,200 van move to Atlanta after
[01:48:58.860 --> 01:49:03.740]   years of striving, moved to Los Angeles, won a national songwriting competition,
[01:49:03.740 --> 01:49:10.300]   got to work with Timbaland. Or as I pronounce it, amicus and started housing.
[01:49:10.300 --> 01:49:16.300]   I'm really bad at rap names. I keep calling him 50 cents. I think it was you, Anne, who corrected
[01:49:16.300 --> 01:49:23.100]   me on that one. But, you never got a hit. So he said, well, maybe that software engineering
[01:49:23.100 --> 01:49:28.140]   thing will work. It's actually really cool. That's awesome. He's still working on an album.
[01:49:28.780 --> 01:49:42.620]   And he's kind of, he says, I'm a cross between Jay Z and Maroon 5. Oh boy. Oh boy. Oh, and by the way,
[01:49:42.620 --> 01:49:48.860]   he's got an iPhone, but it, but it does look googly, right? And he wears Calvin's.
[01:49:48.860 --> 01:49:55.580]   I was going to say he wears Calvin's. Yes, yes, we go in. He's not coming. Oh no. Oh no.
[01:49:55.580 --> 01:49:59.500]   What's going on? He's got a good cinematographer. Yeah, no kidding. I'm not going to go on because
[01:49:59.500 --> 01:50:04.460]   he just dropped the Calvin. So we'll stop right there and say, that's the end of the Google change
[01:50:04.460 --> 01:50:13.500]   log. There's not many, not many Google programmers who could drop their Calvin's on camera.
[01:50:13.500 --> 01:50:21.420]   Wow. I don't know. Any other stories that we missed before we wrap this guy up?
[01:50:21.980 --> 01:50:28.460]   The FedEx delivery robots. Are we thinking those are cute? These are repurposed. Aren't they like
[01:50:28.460 --> 01:50:35.500]   repurposed segue wheelchairs? Oh, are they? I think so. They're based. Yeah, I think they're
[01:50:35.500 --> 01:50:40.940]   based on the I bot, which is a mobility device designed to climb stairs and stuff.
[01:50:40.940 --> 01:50:50.140]   Oh, cool. Yeah. So it is a scary look and beast there. Wow. It's got lighter and a bunch of
[01:50:50.140 --> 01:50:55.980]   chicken. Yeah, this is expensive. It's a FedEx same day bot. It's an innovation design to change the
[01:50:55.980 --> 01:51:00.700]   face of local delivery and help retailers efficiently address their customers rising expectations.
[01:51:00.700 --> 01:51:08.460]   So AutoZone, Lowe's, Pizza Hut, Target, Walgreens and Walmart. And they hope to test the bot in
[01:51:08.460 --> 01:51:17.980]   this summer and markets like, notice summer, not winter or not winter or during rain in markets
[01:51:17.980 --> 01:51:22.540]   like Memphis. Mayor of Memphis says, I think it's a good idea.
[01:51:22.540 --> 01:51:31.660]   I don't know. Here is a, here's, of course, they had to get on national television.
[01:51:31.660 --> 01:51:35.500]   Here is a same day bot delivering a pizza to Jimmy Fallon.
[01:51:35.500 --> 01:51:37.260]   The Tempest and his mini flyers.
[01:51:37.260 --> 01:51:45.900]   No, no, no, no. This is, I guess we got to jump ahead to find the, to find the,
[01:51:47.260 --> 01:51:54.220]   two things are dominating MWC. Who's that? Shut up. Okay. Okay. Is this the bot?
[01:51:54.220 --> 01:52:00.700]   This is this, this is Jimmy's tech segment. He's got a lot of weird stuff. She looks like she
[01:52:00.700 --> 01:52:03.100]   works for Google. Doesn't she? Let's try it. Let's turn up the sound.
[01:52:03.100 --> 01:52:08.620]   And we've got a package for you coming now, actually. It's coming down the hall. Where is,
[01:52:08.620 --> 01:52:13.020]   where is the robot? Absolutely. It's on its way now. Look at this thing. This is the future.
[01:52:13.020 --> 01:52:21.260]   Jimmy Fallon said so. This reminds me if you saw the Americans, the CIA mail bot or the FBI mail
[01:52:21.260 --> 01:52:25.340]   bot. What can it deliver? I did not see that. Is it wandering the halls of the FBI with your mail?
[01:52:25.340 --> 01:52:30.220]   It does and someone has to. I know you're a parent. So if you're a family of a sick child,
[01:52:30.220 --> 01:52:33.260]   it was a plot point on the Americans. It can bring the medicine to you.
[01:52:33.260 --> 01:52:39.340]   So you notice that they have taped off with caution tape, the entire studio to make sure the
[01:52:39.340 --> 01:52:45.180]   bot doesn't accidentally wander. Oh, if you go over sand. Rocks.
[01:52:45.180 --> 01:52:51.340]   We're the water. Come on, get up to the top, buddy. Up some steps.
[01:52:51.340 --> 01:52:53.260]   Can he do it? Can he do it? Can he do it?
[01:52:53.260 --> 01:52:59.020]   It's so sad. It's your foot.
[01:52:59.020 --> 01:53:05.020]   This is cooler than an iPhone. You think so?
[01:53:06.220 --> 01:53:11.180]   Oh, look, here comes. We have our national unveiling. We're going to talk about all the
[01:53:11.180 --> 01:53:16.060]   national retailers that we've been partnering with to design this device and again to bring things.
[01:53:16.060 --> 01:53:22.060]   I'll stop it now, but you saw it. You saw it at work. That's cute. That's the FedEx.
[01:53:22.060 --> 01:53:27.660]   I'll never see it. No. People beat it up before it gets anywhere.
[01:53:27.660 --> 01:53:30.700]   That's the thing. I mean, it's only going to work in certain areas, obviously.
[01:53:34.140 --> 01:53:41.100]   Elon Musk is a little bit of trouble. I heard he was, but I didn't hear what he did or I didn't
[01:53:41.100 --> 01:53:46.540]   really get a chance to go and look and see what he did or said. He said the information he tweeted
[01:53:46.540 --> 01:53:54.540]   was already part of their earnings, but the SEC was like, "We told you not to tweet anything
[01:53:54.540 --> 01:53:58.140]   about financials anymore. You're being held in contempt." He tweeted that.
[01:53:58.140 --> 01:54:03.260]   Oh, 24 million people. See, this is it. I've been telling Elon to get off Twitter for years.
[01:54:04.140 --> 01:54:12.460]   Yeah. Now, the SEC is asking a judge to hold Elon Musk in contempt because he violated the
[01:54:12.460 --> 01:54:16.380]   deal. He has till a March 11 to explain why he should not be held in contempt.
[01:54:16.380 --> 01:54:20.460]   Does that mean jail time? Does it mean a fine? I don't know. I don't know.
[01:54:20.460 --> 01:54:27.420]   So you all think it was okay for him to tweet? What he tweeted? When he tweeted it?
[01:54:27.420 --> 01:54:32.220]   He didn't tweet anything. His contention is he tweeted something that had already been said in
[01:54:32.220 --> 01:54:38.220]   a prior earnings call. Now, the SEC is saying that they told him not to tweet about earnings,
[01:54:38.220 --> 01:54:41.820]   period. So this is kind of like when you're four-year-olds, you're like,
[01:54:41.820 --> 01:54:45.660]   "Don't come out of your room." And they throw something out. Like, "I told you not to come out
[01:54:45.660 --> 01:54:48.780]   of your room." They're like, "I didn't come out." My dolly did.
[01:54:48.780 --> 01:54:56.460]   Well, that was a very binary list of instructions. Hey, you can't talk about this. So I guess,
[01:54:56.460 --> 01:55:05.900]   I guess they got a leg to stand on. I think I'm guessing that tweets are starting to assume a
[01:55:05.900 --> 01:55:12.460]   lower standard of communication than an actual press release. I'm just thinking,
[01:55:12.460 --> 01:55:18.780]   it should then a press release, a presidential proclamation. It's kind of,
[01:55:20.220 --> 01:55:26.620]   it should. I would say, because it's just rap. But Jeff Bezos did his announcement.
[01:55:26.620 --> 01:55:29.500]   His divorce. He announced his divorce via a tweet.
[01:55:29.500 --> 01:55:33.820]   And then he announced his Medium post where he pointed out his
[01:55:33.820 --> 01:55:37.740]   extortion thing in a tweet and then the follow-up Medium post.
[01:55:37.740 --> 01:55:41.260]   Well, I'm thinking of Matt Gates, the representative yesterday who
[01:55:41.260 --> 01:55:47.820]   basically said to Michael Cohen, "It would be a shame if anything were to happen to your family
[01:55:47.820 --> 01:55:53.260]   after you testify of a Congress," which many thought that sounds a little bit like witness tampering.
[01:55:53.260 --> 01:55:58.300]   But I think legal experts that I saw said, "Well, it was a tweet."
[01:55:58.300 --> 01:56:06.300]   The argument that Trump is, whenever Trump tweets about things, you're like, "Oh, is that,
[01:56:06.300 --> 01:56:10.940]   is he inciting violence? I don't know." Is it a presidential proclamation? Is it
[01:56:10.940 --> 01:56:16.860]   the weight of an actual presidential proclamation? Or is it just blowing off a little steam?
[01:56:17.420 --> 01:56:22.140]   Well, I mean, this is the message, the Medium or whatever, blah, blah, blah.
[01:56:22.140 --> 01:56:25.260]   I think you got to consider where it is. But maybe not.
[01:56:25.260 --> 01:56:27.820]   You have to consider who's saying it. I mean, if this is a direct,
[01:56:27.820 --> 01:56:35.420]   Twitter is not a private forum. So if Elon talks about something with his buddies.
[01:56:35.420 --> 01:56:37.180]   It's in public. You're right.
[01:56:37.180 --> 01:56:41.820]   Versus, I mean, that's kind of like TV. He wouldn't say that on television,
[01:56:41.820 --> 01:56:46.460]   just because it's a limited number of characters and most people use it to talk about breakfast
[01:56:46.460 --> 01:56:47.820]   cereals. That doesn't mean that.
[01:56:47.820 --> 01:56:51.260]   If you said something on Jimmy Fallon, would that...
[01:56:51.260 --> 01:56:52.700]   It would count.
[01:56:52.700 --> 01:56:53.980]   That would count as much as Twitter.
[01:56:53.980 --> 01:56:58.460]   That means just as much of a joke as Twitter. So, yes.
[01:56:58.460 --> 01:57:02.860]   Well, there goes your chance to get on Jimmy Fallon.
[01:57:02.860 --> 01:57:07.340]   Oh, and your dog is not happy.
[01:57:07.340 --> 01:57:12.700]   All right. Let's wrap this up so Stacy can discipline her dog.
[01:57:13.820 --> 01:57:18.060]   I think he's in violation of SEC regulations and she'll go back to his...
[01:57:18.060 --> 01:57:19.660]   He is holding me in contempt.
[01:57:19.660 --> 01:57:20.060]   Yes.
[01:57:20.060 --> 01:57:27.740]   Yes, he is. Stacy Hagenbotham, we call her Hermione Hengabotham because she is so smart.
[01:57:27.740 --> 01:57:33.900]   Straight A student, she's at StacyOnIOT.com. Sign up for the free newsletter. It's awesome.
[01:57:33.900 --> 01:57:39.980]   Oh, we didn't do our things yet. I'm so sorry. Stacy, what was your...
[01:57:39.980 --> 01:57:43.260]   Well, you do ants thing first because then I can shut my dog up.
[01:57:43.260 --> 01:57:47.420]   Okay. Ant has a few things. We're going to let you do all of them.
[01:57:47.420 --> 01:57:52.300]   We love ants. By the way, Ant Pruitt, we love you. You're the greatest. He's so calm.
[01:57:52.300 --> 01:57:55.340]   He's so collected. He's so sensible.
[01:57:55.340 --> 01:57:57.260]   I try to be in a...
[01:57:57.260 --> 01:57:58.780]   In a world gone mad.
[01:57:58.780 --> 01:58:02.140]   Ant Pruitt is a man you can listen to.
[01:58:02.140 --> 01:58:03.900]   I appreciate that.
[01:58:03.900 --> 01:58:04.060]   Yeah.
[01:58:04.060 --> 01:58:05.340]   What's your...
[01:58:05.340 --> 01:58:05.900]   What's your thing?
[01:58:05.900 --> 01:58:06.380]   My thing.
[01:58:06.380 --> 01:58:06.700]   Yes.
[01:58:06.700 --> 01:58:10.780]   First off, in honor of Black History Month,
[01:58:11.740 --> 01:58:12.940]   I want to just shut it up.
[01:58:12.940 --> 01:58:14.700]   I just wanted to hear to our friend,
[01:58:14.700 --> 01:58:19.260]   Barry Turntay Thurston, in his book, How to Be Black.
[01:58:19.260 --> 01:58:22.300]   If you haven't read that book, go get it.
[01:58:22.300 --> 01:58:22.940]   It's awesome.
[01:58:22.940 --> 01:58:29.020]   It's hilarious. It's thought-provoking. It is all Baratunde.
[01:58:29.020 --> 01:58:31.820]   I mean, it's... I really, really enjoyed that book.
[01:58:31.820 --> 01:58:33.020]   Yes, the greatest.
[01:58:33.020 --> 01:58:37.260]   But yeah, go check that out. I don't get anything for it, but it's worth sharing.
[01:58:38.140 --> 01:58:41.580]   It absolutely, absolutely is. I have an autographed copy.
[01:58:41.580 --> 01:58:45.500]   I think he said to something like the whitest man I know, but I don't know.
[01:58:45.500 --> 01:58:49.660]   Is that an insult? I don't know.
[01:58:49.660 --> 01:58:53.500]   I think Barry Turntay...
[01:58:53.500 --> 01:58:55.820]   I think he...
[01:58:55.820 --> 01:58:58.460]   Is he getting... I think he might have gotten engaged.
[01:58:58.460 --> 01:58:59.260]   He got engaged.
[01:58:59.260 --> 01:58:59.820]   He did.
[01:58:59.820 --> 01:59:00.300]   I think he did.
[01:59:00.300 --> 01:59:00.700]   I don't know.
[01:59:00.700 --> 01:59:02.540]   Is that... I don't know if...
[01:59:02.540 --> 01:59:03.820]   Well, it's public now.
[01:59:03.820 --> 01:59:06.140]   I'm sorry, Barry Turntay, if that was the secret.
[01:59:06.140 --> 01:59:07.100]   Oh, no. He didn't hide.
[01:59:07.100 --> 01:59:07.900]   It was public.
[01:59:07.900 --> 01:59:10.620]   I think he tweeted it or whatever.
[01:59:10.620 --> 01:59:12.620]   Yeah, he put it out there in social.
[01:59:12.620 --> 01:59:13.260]   So it's probably...
[01:59:13.260 --> 01:59:14.220]   Yeah, we love Baratunde.
[01:59:14.220 --> 01:59:15.660]   Congratulations, Baratunde.
[01:59:15.660 --> 01:59:16.220]   It's great.
[01:59:16.220 --> 01:59:16.700]   Definitely.
[01:59:16.700 --> 01:59:17.180]   What else?
[01:59:17.180 --> 01:59:19.660]   The second thing is...
[01:59:19.660 --> 01:59:23.180]   The Mrs. and I started a podcast and...
[01:59:23.180 --> 01:59:24.460]   Oh, look at that.
[01:59:24.460 --> 01:59:30.300]   I wanted to be able to spend some more time with her, because I spent a lot of my time at this desk
[01:59:30.300 --> 01:59:34.140]   trying to create content and handle SQL and stuff like that.
[01:59:35.100 --> 01:59:39.020]   And I thought it would be fun for her and I to sit down and just talk about
[01:59:39.020 --> 01:59:41.340]   everyday people doing everyday.
[01:59:41.340 --> 01:59:43.580]   I didn't want to curse.
[01:59:43.580 --> 01:59:45.740]   Nice.
[01:59:45.740 --> 01:59:51.820]   It's short form at the most 30 minutes long.
[01:59:51.820 --> 01:59:53.100]   And it's just...
[01:59:53.100 --> 01:59:58.060]   Any type of conversation that we're going to have here in the house,
[01:59:58.060 --> 02:00:00.860]   the only exception is there's mics in front of us.
[02:00:00.860 --> 02:00:02.700]   There's not plan.
[02:00:02.700 --> 02:00:06.780]   It's just everyday people and trying to take it away from
[02:00:06.780 --> 02:00:13.420]   all of the bad news that you hear in podcasts and all of the hate and
[02:00:13.420 --> 02:00:17.740]   just people trying to show boat and things like that.
[02:00:17.740 --> 02:00:23.740]   No, I'm just trying to bring it back to real world stuff that people can relate to.
[02:00:23.740 --> 02:00:24.140]   Love it.
[02:00:24.140 --> 02:00:26.060]   What's your wife's name?
[02:00:26.060 --> 02:00:27.340]   Phoebe.
[02:00:27.340 --> 02:00:28.700]   That looks...
[02:00:28.700 --> 02:00:29.820]   I can't wait to hear that.
[02:00:30.380 --> 02:00:33.020]   Phoebe and Ant, every day people.
[02:00:33.020 --> 02:00:35.820]   Every day people do want every day.
[02:00:35.820 --> 02:00:36.940]   Ants and Phoebe.
[02:00:36.940 --> 02:00:37.260]   Nice.
[02:00:37.260 --> 02:00:37.820]   Ants and Phoebe.
[02:00:37.820 --> 02:00:39.900]   We're having a good time with that.
[02:00:39.900 --> 02:00:43.740]   We haven't recorded this week's episode, but we'll get to that soon.
[02:00:43.740 --> 02:00:44.220]   How do you plan it?
[02:00:44.220 --> 02:00:47.180]   I thought it always had to be fun to do a podcast with Lisa.
[02:00:47.180 --> 02:00:49.100]   You just go in and sit down or...
[02:00:49.100 --> 02:00:50.780]   Dead serious.
[02:00:50.780 --> 02:00:52.220]   I say, "Hey, we recording tonight?"
[02:00:52.220 --> 02:00:53.980]   And it's a yes or a no.
[02:00:53.980 --> 02:00:57.340]   And if it's a yes, I turn around and she sits back there in that chair
[02:00:57.340 --> 02:00:58.780]   and I give her a mic.
[02:00:58.780 --> 02:01:00.620]   I sit here and turn around and face her,
[02:01:00.620 --> 02:01:02.940]   hit record and go and...
[02:01:02.940 --> 02:01:05.980]   It would be nice if the dogs were shut up.
[02:01:05.980 --> 02:01:09.420]   You could talk about that tonight.
[02:01:09.420 --> 02:01:10.940]   Yes.
[02:01:10.940 --> 02:01:12.060]   But that's all it is.
[02:01:12.060 --> 02:01:13.420]   It's just real casual.
[02:01:13.420 --> 02:01:15.020]   For real.
[02:01:15.020 --> 02:01:17.100]   It's our everyday conversations.
[02:01:17.100 --> 02:01:17.900]   That's all it is.
[02:01:17.900 --> 02:01:20.220]   And you have a YouTube channel.
[02:01:20.220 --> 02:01:21.260]   We should not forget.
[02:01:21.260 --> 02:01:22.620]   You used to do Friday night stuff.
[02:01:22.620 --> 02:01:23.500]   Do you still do that or...?
[02:01:24.860 --> 02:01:28.780]   I haven't done that in a while because football season took it away.
[02:01:28.780 --> 02:01:33.580]   But now I've been trying to focus on building some playlists upon request.
[02:01:33.580 --> 02:01:38.060]   My recent playlist is for Premiere Pro people.
[02:01:38.060 --> 02:01:39.020]   Just getting started.
[02:01:39.020 --> 02:01:40.460]   I've done two videos.
[02:01:40.460 --> 02:01:42.300]   I have the third one coming up next week.
[02:01:42.300 --> 02:01:46.940]   And it's just to get people started and get them comfortable with the interface
[02:01:46.940 --> 02:01:49.740]   and get out there creating some awesome content.
[02:01:49.740 --> 02:01:52.700]   So go out there and subscribe and watch them.
[02:01:52.700 --> 02:01:58.380]   If you ever want to have us pay you to do some reviews for our hands-on tech show,
[02:01:58.380 --> 02:02:00.300]   for our reviews show, I see you do a lot of reviews.
[02:02:00.300 --> 02:02:01.100]   We'd love to have you.
[02:02:01.100 --> 02:02:02.220]   Sure.
[02:02:02.220 --> 02:02:04.220]   Anytime you got something you want to review, let us know.
[02:02:04.220 --> 02:02:05.340]   Sure.
[02:02:05.340 --> 02:02:07.420]   You can show it on your channel and our channel.
[02:02:07.420 --> 02:02:08.700]   We'll share.
[02:02:08.700 --> 02:02:09.420]   I'll do that.
[02:02:09.420 --> 02:02:09.660]   Yeah.
[02:02:09.660 --> 02:02:13.340]   We'll actually give you actual money.
[02:02:13.340 --> 02:02:17.740]   That would be awesome.
[02:02:17.740 --> 02:02:18.620]   A buck for you.
[02:02:18.620 --> 02:02:18.860]   Yeah.
[02:02:20.060 --> 02:02:20.380]   Good.
[02:02:20.380 --> 02:02:20.700]   Cool.
[02:02:20.700 --> 02:02:21.340]   Thank you, Anne.
[02:02:21.340 --> 02:02:22.540]   It's always great to have Anne on.
[02:02:22.540 --> 02:02:25.340]   You can find out about his podcast, his YouTube channel.
[02:02:25.340 --> 02:02:28.380]   Everything else he's doing it is a website, antproot.com.
[02:02:28.380 --> 02:02:30.540]   Antepr-u-i-t-t-p-r-t.
[02:02:30.540 --> 02:02:32.060]   Proot.
[02:02:32.060 --> 02:02:32.380]   Gruet.
[02:02:32.380 --> 02:02:32.940]   That's it.
[02:02:32.940 --> 02:02:35.340]   Antproot.com.
[02:02:35.340 --> 02:02:36.140]   Thank you, Anne.
[02:02:36.140 --> 02:02:39.180]   Stacey, you can buy them as a podcast too.
[02:02:39.180 --> 02:02:41.340]   But we'll plug that in a moment.
[02:02:41.340 --> 02:02:44.220]   But first, a world without clouds.
[02:02:44.220 --> 02:02:47.260]   So I don't know if you guys saw this.
[02:02:47.260 --> 02:02:49.740]   It was in Quanta, which is like my favorite magazine,
[02:02:49.740 --> 02:02:50.780]   because I'm a nerd.
[02:02:50.780 --> 02:02:55.900]   It was a supercomputer simulation that looked at climate change,
[02:02:55.900 --> 02:02:58.140]   and it talked about as the earth warms,
[02:02:58.140 --> 02:03:02.620]   clouds basically might, in one simulation, disappear,
[02:03:02.620 --> 02:03:06.460]   setting off another precipitous rise in temperature.
[02:03:06.460 --> 02:03:08.540]   And eight degree rise in temperatures.
[02:03:08.540 --> 02:03:10.380]   But I just-
[02:03:10.380 --> 02:03:10.780]   Yikes.
[02:03:10.780 --> 02:03:13.900]   I was fascinated, I mean,
[02:03:13.900 --> 02:03:15.660]   because I read a lot about climate change,
[02:03:15.660 --> 02:03:16.540]   and I think about this.
[02:03:16.540 --> 02:03:20.460]   But in all of my imaginings of a world,
[02:03:20.460 --> 02:03:23.180]   and I'll tell you guys, I write random fiction,
[02:03:23.180 --> 02:03:26.620]   sometimes about climate change and what happens next.
[02:03:26.620 --> 02:03:29.500]   I never thought about this,
[02:03:29.500 --> 02:03:31.100]   and I'm kind of upset that I hadn't.
[02:03:31.100 --> 02:03:32.220]   And now I'm like, oh.
[02:03:32.220 --> 02:03:35.660]   Clouds covered two surfaces of the earth's surface.
[02:03:35.660 --> 02:03:39.420]   Without them would be sitting ducks.
[02:03:39.420 --> 02:03:40.540]   Yeah.
[02:03:40.540 --> 02:03:42.300]   So I-
[02:03:42.300 --> 02:03:42.780]   I just-
[02:03:42.780 --> 02:03:42.780]   I think-
[02:03:42.780 --> 02:03:43.980]   I think it's political, right?
[02:03:43.980 --> 02:03:45.100]   Well-
[02:03:45.100 --> 02:03:45.420]   It is.
[02:03:46.380 --> 02:03:46.860]   There's a-
[02:03:46.860 --> 02:03:47.500]   Oh.
[02:03:47.500 --> 02:03:50.140]   I once did a recommendation-
[02:03:50.140 --> 02:03:50.700]   It has been a show.
[02:03:50.700 --> 02:03:51.500]   ... of a book.
[02:03:51.500 --> 02:03:52.140]   Yeah.
[02:03:52.140 --> 02:03:55.020]   A recommendation of a book,
[02:03:55.020 --> 02:03:56.700]   it was called The End of the World,
[02:03:56.700 --> 02:04:01.580]   and it was by a geophysicist that talks about how,
[02:04:01.580 --> 02:04:04.540]   you know, the seven great cataclysms of earth-
[02:04:04.540 --> 02:04:05.020]   Right.
[02:04:05.020 --> 02:04:06.460]   ... is, I think, was last year.
[02:04:06.460 --> 02:04:08.540]   I mean, this kind of reminded me of that.
[02:04:08.540 --> 02:04:09.660]   So, you know, you guys,
[02:04:09.660 --> 02:04:11.900]   obviously, I'm really a cheerful person,
[02:04:11.900 --> 02:04:15.180]   deep down inside as I think about the end of the world.
[02:04:15.500 --> 02:04:15.820]   So-
[02:04:15.820 --> 02:04:16.940]   Cool.
[02:04:16.940 --> 02:04:17.340]   That's it.
[02:04:17.340 --> 02:04:19.820]   And this was a big supercomputer simulation that they did,
[02:04:19.820 --> 02:04:20.460]   and they got us-
[02:04:20.460 --> 02:04:21.900]   They got a result they didn't expect.
[02:04:21.900 --> 02:04:23.180]   That's what's kind of interesting.
[02:04:23.180 --> 02:04:23.660]   Yes.
[02:04:23.660 --> 02:04:26.300]   I'm always like excited about simulated-
[02:04:26.300 --> 02:04:27.820]   simulated training for AI,
[02:04:27.820 --> 02:04:30.540]   simulated, you know, methodologies for science.
[02:04:30.540 --> 02:04:31.020]   Yay.
[02:04:31.020 --> 02:04:34.940]   Quanta q-u-a-n-t-a magazine.org.
[02:04:34.940 --> 02:04:36.140]   Yes.
[02:04:36.140 --> 02:04:36.700]   I wrote science.
[02:04:36.700 --> 02:04:38.700]   Physics, mathematics, biology, computer science.
[02:04:38.700 --> 02:04:40.620]   That sounds like a pretty good magazine to read.
[02:04:40.620 --> 02:04:42.780]   Oh, it's awesome.
[02:04:42.780 --> 02:04:43.340]   It's awesome.
[02:04:44.300 --> 02:04:45.500]   I mean, it's awesome.
[02:04:45.500 --> 02:04:46.380]   It's for me.
[02:04:46.380 --> 02:04:49.260]   And so are you awesome Stacy Higginbotham?
[02:04:49.260 --> 02:04:52.780]   Her IoT podcast pod is with Kevin Tofel.
[02:04:52.780 --> 02:04:56.140]   It goes out every Wednesday, I think, right?
[02:04:56.140 --> 02:04:57.660]   You do it Wednesday.
[02:04:57.660 --> 02:04:58.300]   We do it Wednesday.
[02:04:58.300 --> 02:04:59.260]   It goes out Thursday morning.
[02:04:59.260 --> 02:04:59.820]   Thursday morning.
[02:04:59.820 --> 02:05:00.060]   Yeah.
[02:05:00.060 --> 02:05:01.820]   I don't say I thought I get it Thursdays.
[02:05:01.820 --> 02:05:02.940]   I love their theme music.
[02:05:02.940 --> 02:05:04.940]   Yes.
[02:05:04.940 --> 02:05:06.220]   It's gotta be better than our theme music.
[02:05:06.220 --> 02:05:09.100]   It's gotta be better than our theme music.
[02:05:09.100 --> 02:05:09.820]   That's for sure.
[02:05:09.820 --> 02:05:13.340]   Oh, well, I'm stuck with it now.
[02:05:13.340 --> 02:05:14.140]   Thank you, Stacy.
[02:05:14.140 --> 02:05:17.580]   You can also read her stuff at our website, stacy@iot.com.
[02:05:17.580 --> 02:05:20.060]   And make sure you subscribe to our newsletter too.
[02:05:20.060 --> 02:05:23.420]   Aunt Stacy, you guys are great.
[02:05:23.420 --> 02:05:24.220]   Come back soon.
[02:05:24.220 --> 02:05:26.300]   Well, Stacy, I'll see you next week.
[02:05:26.300 --> 02:05:26.780]   I hope.
[02:05:26.780 --> 02:05:27.420]   I was good to say.
[02:05:27.420 --> 02:05:28.940]   I'll be here next week, I think.
[02:05:28.940 --> 02:05:29.900]   Aunt, you come back soon.
[02:05:29.900 --> 02:05:32.300]   Unless you don't invite me, no, you're always invited.
[02:05:32.300 --> 02:05:34.220]   Anytime, sir.
[02:05:34.220 --> 02:05:34.940]   Anytime.
[02:05:34.940 --> 02:05:35.340]   Thank you.
[02:05:35.340 --> 02:05:37.500]   We do this show.
[02:05:37.500 --> 02:05:38.780]   This is this week in Google.
[02:05:38.780 --> 02:05:41.820]   And we do it every Wednesday, around 130 Pacific.
[02:05:43.020 --> 02:05:45.660]   430 Eastern, 2130 UTC.
[02:05:45.660 --> 02:05:49.100]   You can watch or listen live at twit.tv/live.
[02:05:49.100 --> 02:05:51.420]   We've audio and video streams there.
[02:05:51.420 --> 02:05:54.540]   If you do that, join us in the chatroom at irc.twit.tv.
[02:05:54.540 --> 02:05:58.940]   A fun place to hang out our community run chatroom.
[02:05:58.940 --> 02:06:01.580]   Our community mods do a great job of it.
[02:06:01.580 --> 02:06:03.820]   And I keep my hands off.
[02:06:03.820 --> 02:06:04.300]   Hands off.
[02:06:04.300 --> 02:06:05.580]   I don't have anything to do with it.
[02:06:05.580 --> 02:06:09.420]   We also have downloadable versions of everything we do.
[02:06:09.420 --> 02:06:12.060]   On demand video and audio at our website.
[02:06:12.060 --> 02:06:13.980]   In this case, twit.tv/twig.
[02:06:13.980 --> 02:06:16.060]   And we are now on.
[02:06:16.060 --> 02:06:18.460]   I'm happy to say Pandora, which is great.
[02:06:18.460 --> 02:06:20.620]   They've added podcasts and this is one of them.
[02:06:20.620 --> 02:06:23.820]   So if you're a Pandora subscriber, you can get it there.
[02:06:23.820 --> 02:06:25.420]   You can get it on Spotify, stick them.
[02:06:25.420 --> 02:06:26.300]   Stick them.
[02:06:26.300 --> 02:06:27.820]   Stitcher.
[02:06:27.820 --> 02:06:29.660]   Stick them to long gone.
[02:06:29.660 --> 02:06:31.500]   Our first video stream.
[02:06:31.500 --> 02:06:37.100]   On Stitcher, on Slacker, Overcast, Pocket Casts, iTunes, Google,
[02:06:37.100 --> 02:06:40.700]   wherever you get your podcasts, make sure you subscribe to this week in Google
[02:06:40.700 --> 02:06:43.100]   so you get every episode the minute it's ready.
[02:06:43.100 --> 02:06:43.980]   Thanks for listening.
[02:06:43.980 --> 02:06:44.780]   Thanks for watching.
[02:06:44.780 --> 02:06:45.820]   We'll see you next time.
[02:06:45.820 --> 02:06:46.860]   On twig.
[02:06:46.860 --> 02:06:47.660]   Bye-bye.
[02:06:47.660 --> 02:06:57.900]   [Music]

