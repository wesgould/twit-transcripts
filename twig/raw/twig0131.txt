;FFMETADATA1
album=This Week In Google
artist=Leo Laporte, Jeff Jarvis and Gina Trapani
iTunPGAP=0
comment=http://twit.tv/twig131
encoded_by=iTunes v7.0
genre=Tech News
TGID=http://www.podtrac.com/pts/redirect.mp3/twit.cachefly.net/twig0115.mp3
TDES=Hosts: Leo Laporte, Jeff Jarvis, and Gina Trapani\
\
Apple's iPhone 4S keynote, what is PhoneGap, \# on Google +, Google won't screw up Android, and more cloud news.\
\
Download or subscribe to this show at twit.tv/twig.\
\
We invite you to read, add to, and amend our show notes.\
\
Friendfeed links for this episode.\
\
Thanks to Cachefly for the bandwidth for this show.\
\
Running time: 1:29:14
track=131
title=This Week In Google 131: BE AFRAID... or not
date=2012
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:10.000]   [MUSIC]
[00:00:10.000 --> 00:00:12.000]   This is Twit.
[00:00:12.000 --> 00:00:14.000]   [MUSIC]
[00:00:14.000 --> 00:00:17.000]   Bandwidth for this week in Google is provided by
[00:00:17.000 --> 00:00:21.000]   cachefly, C-A-C-H-E-F-L-Y.com.
[00:00:21.000 --> 00:00:23.000]   [MUSIC]
[00:00:23.000 --> 00:00:27.000]   This is Twit. This week in Google, Episode 131,
[00:00:27.000 --> 00:00:30.000]   recorded January 25th, 2012.
[00:00:30.000 --> 00:00:32.000]   Be afraid.
[00:00:32.000 --> 00:00:33.000]   Or not.
[00:00:33.000 --> 00:00:36.000]   This week in Google is brought to you by Ford,
[00:00:36.000 --> 00:00:39.000]   featuring voice-activated sync app link.
[00:00:39.000 --> 00:00:42.000]   Now you can control your select smartphone apps with your voice
[00:00:42.000 --> 00:00:45.000]   so you keep your hands on the wheel and your eyes on the road.
[00:00:45.000 --> 00:00:52.000]   Check it out in the 2012 Ford Fiesta and at Ford.com/technology.
[00:00:52.000 --> 00:00:56.000]   It's time for Twit this week in Google and a good day to talk
[00:00:56.000 --> 00:00:59.000]   about Google and we have four great panelists.
[00:00:59.000 --> 00:01:02.000]   To do so, I'll start to my left with Matthew Ingram.
[00:01:02.000 --> 00:01:06.000]   He says, "I'm the Emanence Grease and senior writer at
[00:01:06.000 --> 00:01:07.000]   gigahome.com."
[00:01:07.000 --> 00:01:09.000]   Hi, Matthew. Welcome.
[00:01:09.000 --> 00:01:10.000]   Thanks for having me.
[00:01:10.000 --> 00:01:12.000]   I think this is your first time on Twig.
[00:01:12.000 --> 00:01:13.000]   Is it not?
[00:01:13.000 --> 00:01:14.000]   I believe it is.
[00:01:14.000 --> 00:01:15.000]   Welcome.
[00:01:15.000 --> 00:01:16.000]   Good to have you.
[00:01:16.000 --> 00:01:18.000]   And I see that he has brought his boxing gloves,
[00:01:18.000 --> 00:01:20.000]   so watch out, everybody.
[00:01:20.000 --> 00:01:25.000]   Also joining us, Gina Trippani from SmarterWare.org.
[00:01:25.000 --> 00:01:28.000]   And a former founder of Life Hacker.
[00:01:28.000 --> 00:01:31.000]   She's, of course, the creator of ThinkUp app.
[00:01:31.000 --> 00:01:35.000]   And I forgot to ask you last week, did you meet the Prez when you were at the White House?
[00:01:35.000 --> 00:01:39.000]   I didn't. I didn't meet the President, but I met CTO in the United States
[00:01:39.000 --> 00:01:41.000]   and I met the First Lady's Chief of Staff.
[00:01:41.000 --> 00:01:43.000]   No bow sightings either. I didn't see the dog.
[00:01:43.000 --> 00:01:44.000]   No bow the dog.
[00:01:44.000 --> 00:01:48.000]   But I did get to step into the West Wing momentarily, which was exciting.
[00:01:48.000 --> 00:01:50.000]   Yeah, you don't normally get to go there.
[00:01:50.000 --> 00:01:51.000]   Yeah, no, you don't.
[00:01:51.000 --> 00:01:54.000]   The President was definitely hard at work because the Secret Service guy looked like
[00:01:54.000 --> 00:01:55.000]   a rat to tackle me.
[00:01:55.000 --> 00:01:56.000]   I said, I had to write that.
[00:01:56.000 --> 00:01:59.000]   So you don't look right, whoever you are.
[00:01:59.000 --> 00:02:01.000]   Yeah, because I look really intimidating.
[00:02:01.000 --> 00:02:02.000]   Yes.
[00:02:02.000 --> 00:02:03.000]   He looked very intimidating.
[00:02:03.000 --> 00:02:07.000]   So I stepped carefully.
[00:02:07.000 --> 00:02:08.000]   Tread softly.
[00:02:08.000 --> 00:02:09.000]   Yes.
[00:02:09.000 --> 00:02:14.000]   To my right, Mr. Jeff Jarvis, who is calling from Switzerland, from Davos,
[00:02:14.000 --> 00:02:20.000]   where he is hanging with the big Mucky Mucks at the World Economic Forum.
[00:02:20.000 --> 00:02:22.000]   It's cold here. I've got to have a hat on.
[00:02:22.000 --> 00:02:23.000]   That's a good hat.
[00:02:23.000 --> 00:02:25.000]   That has the built in earpiece ear muffs.
[00:02:25.000 --> 00:02:26.000]   Yeah, cool.
[00:02:26.000 --> 00:02:27.000]   I'm getting on it.
[00:02:27.000 --> 00:02:30.000]   I was with Matthew Ingram in Victoria, BC.
[00:02:30.000 --> 00:02:31.000]   Wow.
[00:02:31.000 --> 00:02:32.000]   Small world.
[00:02:32.000 --> 00:02:34.000]   It wasn't that cold.
[00:02:34.000 --> 00:02:36.000]   No, but I'm sure it is what you said six feet.
[00:02:36.000 --> 00:02:37.000]   Oh, it's a good hat for here.
[00:02:37.000 --> 00:02:38.000]   Six feet of snow.
[00:02:38.000 --> 00:02:40.000]   Six feet in the last two weeks.
[00:02:40.000 --> 00:02:41.000]   Yeah.
[00:02:41.000 --> 00:02:42.000]   Wow.
[00:02:42.000 --> 00:02:47.000]   And by the way, Gene, I was invited to a meeting with the CTO today in Washington.
[00:02:47.000 --> 00:02:50.000]   And I was already committed to come here and about killed me.
[00:02:50.000 --> 00:02:51.000]   I came here instead.
[00:02:51.000 --> 00:02:54.000]   You know, is it an election year or something?
[00:02:54.000 --> 00:02:57.000]   You think?
[00:02:57.000 --> 00:03:00.000]   All these bloggers here at the White House.
[00:03:00.000 --> 00:03:04.000]   For every four years, bloggers get to go to the White House.
[00:03:04.000 --> 00:03:07.000]   Well, I think after soap, we'll get to go a lot more often.
[00:03:07.000 --> 00:03:08.000]   Maybe.
[00:03:08.000 --> 00:03:10.000]   A little, the power of the blog.
[00:03:10.000 --> 00:03:15.000]   Also here, and it looks like he's at Macworld Expo because I see the jukebox
[00:03:15.000 --> 00:03:16.000]   Marriott behind him.
[00:03:16.000 --> 00:03:20.000]   Mr. Kevin Marks of salesforce.com and Tumblevision TV.
[00:03:20.000 --> 00:03:21.000]   Hello, Kevin.
[00:03:21.000 --> 00:03:22.000]   Hi there.
[00:03:22.000 --> 00:03:26.000]   I'm on top of the, I mean, the year of Wayne of Gardens.
[00:03:26.000 --> 00:03:27.000]   Yes.
[00:03:27.000 --> 00:03:29.000]   And are you there for Macworld or something else?
[00:03:29.000 --> 00:03:33.000]   No, no, I was, I just picked this place as a nice place to sit and chat because I couldn't,
[00:03:33.000 --> 00:03:35.000]   I found that the offices were booked.
[00:03:35.000 --> 00:03:36.000]   Perfect.
[00:03:36.000 --> 00:03:37.000]   We need to watch the books and salesforce.
[00:03:37.000 --> 00:03:38.000]   Perfect.
[00:03:38.000 --> 00:03:40.000]   It's next to the metrian.
[00:03:40.000 --> 00:03:41.000]   It is.
[00:03:41.000 --> 00:03:43.000]   You go see an IMAX film.
[00:03:43.000 --> 00:03:47.000]   So, those are the sort of really weird view down here of like, doesn't the White San Francisco?
[00:03:47.000 --> 00:03:49.000]   It's full of churches and things.
[00:03:49.000 --> 00:03:50.000]   Yeah.
[00:03:50.000 --> 00:03:54.000]   You're in the Erbobuina Center, which was really quite a great redevelopment project.
[00:03:54.000 --> 00:03:59.000]   And they put the Moscone Center is underneath this garden on top.
[00:03:59.000 --> 00:04:00.000]   And it's nice.
[00:04:00.000 --> 00:04:01.000]   Pretty.
[00:04:01.000 --> 00:04:02.000]   The Museum of Modern Art is over there.
[00:04:02.000 --> 00:04:05.000]   And of course, as you can see, the reason why they call it the jukebox Marriott.
[00:04:05.000 --> 00:04:07.000]   It looks like a jukebox.
[00:04:07.000 --> 00:04:08.000]   Yes.
[00:04:08.000 --> 00:04:09.000]   Yeah.
[00:04:09.000 --> 00:04:11.000]   Anyway, welcome all.
[00:04:11.000 --> 00:04:12.000]   The big story.
[00:04:12.000 --> 00:04:14.000]   I don't think there's any question about it this week.
[00:04:14.000 --> 00:04:19.000]   And it's all started with the Washington Post a couple of days ago.
[00:04:19.000 --> 00:04:21.000]   Washington Post published an article.
[00:04:21.000 --> 00:04:22.000]   I thought it was a little sensationalistic.
[00:04:22.000 --> 00:04:27.000]   I'd love to get your take on it saying, Oh, my God.
[00:04:27.000 --> 00:04:33.000]   Google is going to update their privacy policies.
[00:04:33.000 --> 00:04:41.000]   And somehow they left the conclusion that because of this, the changes were going to make that
[00:04:41.000 --> 00:04:44.680]   all of a sudden they were going to aggregate everything they know about you and you couldn't
[00:04:44.680 --> 00:04:48.760]   opt out of it.
[00:04:48.760 --> 00:04:52.920]   Now I just scanned them because they just they have published them now on the official Google
[00:04:52.920 --> 00:04:53.920]   blog.
[00:04:53.920 --> 00:04:54.920]   And I just scanned them.
[00:04:54.920 --> 00:05:00.320]   And it doesn't seem like that Washington Post article was justified.
[00:05:00.320 --> 00:05:01.320]   Anybody dissent disagree?
[00:05:01.320 --> 00:05:05.040]   Matthew, I actually very held it a very good story on that just saying that they didn't
[00:05:05.040 --> 00:05:06.040]   really change their policy.
[00:05:06.040 --> 00:05:08.880]   They changed some execution of them, but they've always said that they were going to combine
[00:05:08.880 --> 00:05:09.880]   stuff.
[00:05:09.880 --> 00:05:10.880]   And it only makes sense that they would.
[00:05:10.880 --> 00:05:11.880]   That's the point of Google.
[00:05:11.880 --> 00:05:12.880]   What are you going to do?
[00:05:12.880 --> 00:05:14.960]   Build a firewall between your stuff?
[00:05:14.960 --> 00:05:20.240]   This is this is the insanity of the privacy insanity.
[00:05:20.240 --> 00:05:21.240]   And it makes sense.
[00:05:21.240 --> 00:05:24.240]   In fact, I think it's an improvement to have a unified privacy policy.
[00:05:24.240 --> 00:05:25.480]   That's what's unified now, right?
[00:05:25.480 --> 00:05:27.280]   We have one privacy policy.
[00:05:27.280 --> 00:05:28.280]   Right.
[00:05:28.280 --> 00:05:29.280]   Across all the products.
[00:05:29.280 --> 00:05:32.280]   That's the thing they inherited some from the companies they bought that were different.
[00:05:32.280 --> 00:05:34.440]   I think YouTube had a different one.
[00:05:34.440 --> 00:05:35.440]   It's a point.
[00:05:35.440 --> 00:05:36.440]   Right.
[00:05:36.440 --> 00:05:38.920]   So each product, some of the products had different ones.
[00:05:38.920 --> 00:05:43.160]   I fell into the headline trap about this yesterday, where I was like, "This is terrible.
[00:05:43.160 --> 00:05:46.520]   Google's being aggressive at making this horrible change that you can't opt out of.
[00:05:46.520 --> 00:05:51.000]   This is totally against their entire ethos about user control and openness.
[00:05:51.000 --> 00:05:52.000]   This is terrible.
[00:05:52.000 --> 00:05:53.160]   It's so Facebook-like."
[00:05:53.160 --> 00:05:55.160]   And then I actually read about it.
[00:05:55.160 --> 00:05:59.040]   I think Peter Kefka did a good piece where it was like Google maintains an archive of
[00:05:59.040 --> 00:06:01.760]   all their privacy policies over time.
[00:06:01.760 --> 00:06:09.200]   And they've always said that they may use data from other services, usage, behavioral
[00:06:09.200 --> 00:06:13.000]   data from other services, that we obviously know they can.
[00:06:13.000 --> 00:06:14.440]   It's all one company.
[00:06:14.440 --> 00:06:15.760]   And now they're saying they may.
[00:06:15.760 --> 00:06:18.200]   And this consolidation just makes that very clear.
[00:06:18.200 --> 00:06:19.200]   Right.
[00:06:19.200 --> 00:06:22.600]   So that may not have been laid out very clearly in different product privacy policies.
[00:06:22.600 --> 00:06:25.680]   But now there's one privacy policy, and it makes it really clear.
[00:06:25.680 --> 00:06:27.520]   So nothing has really changed.
[00:06:27.520 --> 00:06:32.320]   I was thinking a few days ago before this story broke, if someone had asked me, "Does Google
[00:06:32.320 --> 00:06:36.320]   take the things that you do on YouTube and use it to inform the ads it shows you in Google
[00:06:36.320 --> 00:06:37.320]   search?"
[00:06:37.320 --> 00:06:38.960]   I would have said, "Well, of course."
[00:06:38.960 --> 00:06:40.320]   Well, certainly they can.
[00:06:40.320 --> 00:06:41.640]   And I don't see why they wouldn't.
[00:06:41.640 --> 00:06:42.840]   It's all one company.
[00:06:42.840 --> 00:06:44.960]   I mean, you know, it's all one company's product.
[00:06:44.960 --> 00:06:46.760]   So what's the big deal?
[00:06:46.760 --> 00:06:50.240]   But then they announced this change, which is them being upfront and saying, "Hey, this
[00:06:50.240 --> 00:06:53.840]   change is going to happen in a month or two.
[00:06:53.840 --> 00:06:55.280]   It's going to be the same for everywhere.
[00:06:55.280 --> 00:06:58.080]   And we're just being really clear and consolidating 60 documents."
[00:06:58.080 --> 00:06:59.720]   They're being transparent, right?
[00:06:59.720 --> 00:07:00.720]   Yeah, they're being transparent.
[00:07:00.720 --> 00:07:04.280]   And they're saying, "You can just close your account if you don't like it."
[00:07:04.280 --> 00:07:05.920]   Which they didn't quite say that.
[00:07:05.920 --> 00:07:09.840]   But that was what the non-opt-out piece of that sensationalist headline came from.
[00:07:09.840 --> 00:07:13.040]   In the end, I was like, "This really isn't that big a deal."
[00:07:13.040 --> 00:07:16.080]   It's just the timing was bad after Search Plus Your World.
[00:07:16.080 --> 00:07:17.320]   See, that's what I think.
[00:07:17.320 --> 00:07:20.640]   I think what's interesting is how people's perceptions have changed.
[00:07:20.640 --> 00:07:23.880]   And I think it's partly because of Google Search Plus Your World.
[00:07:23.880 --> 00:07:29.480]   I think some people at least are a lot more sensitive about, is Google doing this stuff
[00:07:29.480 --> 00:07:32.560]   for me or is it doing it for its own purposes?
[00:07:32.560 --> 00:07:36.160]   So before they might have thought, "Oh, Google just shows me the results that are really
[00:07:36.160 --> 00:07:37.160]   relevant to me."
[00:07:37.160 --> 00:07:41.360]   Except now they're thinking, "Oh, no, Google's showing me Google+ results because that's
[00:07:41.360 --> 00:07:42.360]   what they want."
[00:07:42.360 --> 00:07:46.240]   So now they're distorting things in a way to their own benefit.
[00:07:46.240 --> 00:07:52.640]   So whereas before someone might have said, "Oh, I think Google is pretty fair with my
[00:07:52.640 --> 00:07:53.640]   privacy.
[00:07:53.640 --> 00:07:55.400]   Now they're a little bit more suspicious.
[00:07:55.400 --> 00:07:58.240]   Is there going to show you all the information?"
[00:07:58.240 --> 00:07:59.240]   Sorry.
[00:07:59.240 --> 00:08:00.240]   Go ahead.
[00:08:00.240 --> 00:08:03.400]   I visited the Munich offices of Google this week.
[00:08:03.400 --> 00:08:04.480]   And those are the guys.
[00:08:04.480 --> 00:08:07.160]   It's almost all privacy because they're on the front line of privacy.
[00:08:07.160 --> 00:08:08.160]   They're in Germany.
[00:08:08.160 --> 00:08:09.160]   In Blermany, yeah.
[00:08:09.160 --> 00:08:10.160]   Exactly.
[00:08:10.160 --> 00:08:14.040]   And interestingly, as I was talking to them part about the need to not just talk about
[00:08:14.040 --> 00:08:18.000]   transparency and talk about benefits, but also to create more products that have benefits.
[00:08:18.000 --> 00:08:22.840]   And they said interestingly, "For all the fewer over the fair, Pixel Ohms rekt of Street
[00:08:22.840 --> 00:08:27.640]   View and Wave and all that, Google priority inbox.
[00:08:27.640 --> 00:08:29.000]   German's love it.
[00:08:29.000 --> 00:08:31.040]   Nary a complaint."
[00:08:31.040 --> 00:08:33.920]   And Google's reading your email.
[00:08:33.920 --> 00:08:35.960]   No, what they're doing.
[00:08:35.960 --> 00:08:38.520]   But the value is so high, nobody bitches.
[00:08:38.520 --> 00:08:41.880]   Well, I've talked to some Germans, including Chris Markwart, who's a regular contributor
[00:08:41.880 --> 00:08:42.880]   here, lives in Tubingen.
[00:08:42.880 --> 00:08:46.480]   He said, "I don't think the German public share this fear that the German government
[00:08:46.480 --> 00:08:47.480]   has.
[00:08:47.480 --> 00:08:49.480]   The German public loves Google and loves to use it.
[00:08:49.480 --> 00:08:50.480]   Exactly.
[00:08:50.480 --> 00:08:56.000]   And it's a very hard article that raised people's ire, including yours, Gina, on The Washington
[00:08:56.000 --> 00:08:57.800]   Post yesterday.
[00:08:57.800 --> 00:09:01.600]   Google announces, "Privacy changes across products.
[00:09:01.600 --> 00:09:03.000]   Users can't opt out."
[00:09:03.000 --> 00:09:04.000]   That's the headline.
[00:09:04.000 --> 00:09:05.840]   "Sasudia Kang writing."
[00:09:05.840 --> 00:09:08.840]   She says, "The web giant announced Tuesday.
[00:09:08.840 --> 00:09:14.600]   It plans to follow the activities of users across nearly all of its ubiquitous sites,
[00:09:14.600 --> 00:09:17.200]   including YouTube, Gmail, and its leading search engine.
[00:09:17.200 --> 00:09:20.960]   Google has already been collecting some of this information, but for the first time,
[00:09:20.960 --> 00:09:26.840]   is combining data across its websites to stitch together a fuller portrait of users.
[00:09:26.840 --> 00:09:32.480]   It says, "Consumers who are logged into Google services won't be able to opt out of the changes,
[00:09:32.480 --> 00:09:34.320]   which take a first effect March 1."
[00:09:34.320 --> 00:09:35.960]   Is any of that wrong?
[00:09:35.960 --> 00:09:36.960]   That's not factually in error.
[00:09:36.960 --> 00:09:40.560]   I don't think it's the first time they've shared information.
[00:09:40.560 --> 00:09:44.000]   Well, and I, you know, we've, look, I don't want to be an apologist for Google by any
[00:09:44.000 --> 00:09:45.000]   means.
[00:09:45.000 --> 00:09:48.240]   I've shared this Google dashboard many times, Google.com/dashboard.
[00:09:48.240 --> 00:09:53.680]   When you log into your account, Google has been more transparent than almost, look, this
[00:09:53.680 --> 00:09:56.120]   is my, my general response to people when they come to me.
[00:09:56.120 --> 00:09:59.320]   In fact, somebody, a friend of mine, a doctor said today, came to me, said, "What should
[00:09:59.320 --> 00:10:00.320]   I do?"
[00:10:00.320 --> 00:10:03.200]   And I said, "You know, who knows more about you than Google?
[00:10:03.200 --> 00:10:04.680]   Oh, you're internet service provider.
[00:10:04.680 --> 00:10:05.760]   What's their privacy policy?"
[00:10:05.760 --> 00:10:06.760]   Right.
[00:10:06.760 --> 00:10:08.720]   Do they have one?
[00:10:08.720 --> 00:10:10.040]   They know more than what you do.
[00:10:10.040 --> 00:10:12.080]   This is only stuff you visit on Google.
[00:10:12.080 --> 00:10:17.840]   When Google is very, I think, upfront about exposing what they know in this dashboard,
[00:10:17.840 --> 00:10:24.080]   is there any contention that this dashboard is not full, complete, and accurate?
[00:10:24.080 --> 00:10:26.200]   I think it's a bad word.
[00:10:26.200 --> 00:10:27.200]   Right.
[00:10:27.200 --> 00:10:28.200]   Kevin, what's your thought on?
[00:10:28.200 --> 00:10:29.200]   You actually worked for the evil.
[00:10:29.200 --> 00:10:30.200]   I mean, Google.
[00:10:30.200 --> 00:10:40.040]   No, I think, you know, historically, they weren't, the product teams were fairly independent
[00:10:40.040 --> 00:10:43.360]   and there wasn't as much coordination as they could have been.
[00:10:43.360 --> 00:10:47.400]   And one of the things that has changed this Larry Page to go there is that they are trying
[00:10:47.400 --> 00:10:48.960]   to focus this stuff more.
[00:10:48.960 --> 00:10:54.960]   You know, the way the black bar staff, the logins, and the Google+ everywhere is part
[00:10:54.960 --> 00:10:55.960]   of that.
[00:10:55.960 --> 00:10:57.760]   And I think this privacy policy is another aspect of that.
[00:10:57.760 --> 00:11:02.200]   They're going to start actually coupling all the products together much more consistently
[00:11:02.200 --> 00:11:04.440]   than converging that makes sense, too.
[00:11:04.440 --> 00:11:07.440]   And I think, you know, historically, there were a bunch of different product teams that
[00:11:07.440 --> 00:11:11.280]   had come from acquisitions and things and had some variations in privacy policy and in
[00:11:11.280 --> 00:11:12.920]   profiles as well.
[00:11:12.920 --> 00:11:17.000]   Google still has several different profiles, but there's profiles on Blogger, profiles
[00:11:17.000 --> 00:11:20.080]   on YouTube, and the sort of core profiles that are on the other services, and they're
[00:11:20.080 --> 00:11:21.520]   trying to converge those as well.
[00:11:21.520 --> 00:11:28.040]   So I suspect this is sort of reflecting that general management effort to make Google more
[00:11:28.040 --> 00:11:30.040]   coherent and more one Google.
[00:11:30.040 --> 00:11:31.040]   You're exactly right, Matthew.
[00:11:31.040 --> 00:11:32.040]   I mean, Kevin.
[00:11:32.040 --> 00:11:37.880]   Yeah, when I went from a book talk at Google HQ, they were in the middle of privacy week
[00:11:37.880 --> 00:11:39.400]   and they have these principles of privacy.
[00:11:39.400 --> 00:11:42.800]   When I went to the Munich headquarters, they're up all on the walls.
[00:11:42.800 --> 00:11:44.080]   They're really working very hard.
[00:11:44.080 --> 00:11:47.520]   And, you know, we can criticize Google for other things.
[00:11:47.520 --> 00:11:51.960]   But I think compared to Facebook, compared to Twitter, compared to your ISP, Google's
[00:11:51.960 --> 00:11:57.040]   been doing better work, but it's just this reflexive Google hatred that takes over.
[00:11:57.040 --> 00:12:00.040]   I think it's, I mean, I think it is a perception.
[00:12:00.040 --> 00:12:01.040]   Sorry.
[00:12:01.040 --> 00:12:02.840]   Go ahead, Matthew.
[00:12:02.840 --> 00:12:04.680]   I think the perception is changing.
[00:12:04.680 --> 00:12:08.360]   And I think things like Google Search Plus, your world are doing that.
[00:12:08.360 --> 00:12:10.520]   I think people are questioning.
[00:12:10.520 --> 00:12:15.160]   So they're losing a little bit of trust, maybe, that Google is doing this for their benefit
[00:12:15.160 --> 00:12:17.440]   or being as open and transparent as possible.
[00:12:17.440 --> 00:12:20.400]   I think that's a real problem for them.
[00:12:20.400 --> 00:12:21.760]   It is, Matthew.
[00:12:21.760 --> 00:12:25.360]   But then again, you know, Facebook is using everything you tell them.
[00:12:25.360 --> 00:12:30.400]   Yeah, Facebook doesn't have to say, oh, we're going to combine information from your
[00:12:30.400 --> 00:12:32.480]   profile and your fan page.
[00:12:32.480 --> 00:12:33.480]   Of course they are.
[00:12:33.480 --> 00:12:35.960]   But Google is always different.
[00:12:35.960 --> 00:12:41.120]   I think people always assume Google was better, you know, more objective, more in it for you.
[00:12:41.120 --> 00:12:43.320]   Like, kind of for them.
[00:12:43.320 --> 00:12:45.240]   But they are in it for, because that's the point, Matthew.
[00:12:45.240 --> 00:12:46.240]   They are in it for us.
[00:12:46.240 --> 00:12:47.840]   Why are they doing this stuff?
[00:12:47.840 --> 00:12:51.160]   Not just for advertising, but they're going to focus and give us a better service.
[00:12:51.160 --> 00:12:54.200]   I mean, I don't, again, I'm sounding like a Google fanboy, even though I am one, but
[00:12:54.200 --> 00:12:57.000]   they're going to use this information to give us more relevant results.
[00:12:57.000 --> 00:12:58.000]   Well, okay.
[00:12:58.000 --> 00:12:59.960]   M.G. Seagler said an interesting thing.
[00:12:59.960 --> 00:13:05.360]   He said, and this is relevant to the conversation we had last week, which was about Search Plus
[00:13:05.360 --> 00:13:06.360]   Your World.
[00:13:06.360 --> 00:13:12.520]   And we talked a lot about last week on Twitter and on this show in negative terms.
[00:13:12.520 --> 00:13:14.680]   He said, look, it's Google's a private enterprise.
[00:13:14.680 --> 00:13:19.520]   They have the right to, you know, do what they can to maximize profits.
[00:13:19.520 --> 00:13:24.040]   My only issue, and I think this is, I would agree with him, is it makes the search results
[00:13:24.040 --> 00:13:25.040]   less good.
[00:13:25.040 --> 00:13:29.440]   And I think that when you search for Mark Zuckerberg, instead of some sites that might legitimately
[00:13:29.440 --> 00:13:34.040]   tell you about Mark Zuckerberg, what you get is Mark Zuckerberg's Google Plus account,
[00:13:34.040 --> 00:13:35.960]   where he has never posted anything.
[00:13:35.960 --> 00:13:42.480]   So clearly that's not as good a search result in, and Google's doing that in order to promote
[00:13:42.480 --> 00:13:43.480]   their own product.
[00:13:43.480 --> 00:13:47.080]   So they're, they're trading promotion for quality.
[00:13:47.080 --> 00:13:49.000]   And that's what M.G. said, and I agree with him.
[00:13:49.000 --> 00:13:52.000]   Yeah, there was a sense of betrayal there for sure.
[00:13:52.000 --> 00:13:53.000]   Yeah.
[00:13:53.000 --> 00:13:54.480]   But it's the right to do it.
[00:13:54.480 --> 00:13:57.360]   It's their right to do it.
[00:13:57.360 --> 00:14:02.640]   I think that they're to be commended for being clear about what they're collecting and give
[00:14:02.640 --> 00:14:04.640]   you a privacy policy.
[00:14:04.640 --> 00:14:08.200]   What's unfortunate is there isn't any really credible competition for Google.
[00:14:08.200 --> 00:14:10.040]   Certainly no competition that's not doing the same thing.
[00:14:10.040 --> 00:14:11.840]   Bing's doing the same thing.
[00:14:11.840 --> 00:14:12.840]   Right.
[00:14:12.840 --> 00:14:16.880]   And I think if you look at, I don't want to get too much into the Google search plus
[00:14:16.880 --> 00:14:17.880]   your world again.
[00:14:17.880 --> 00:14:22.680]   But if you look at what they've said, what they've said about why or how they don't favor
[00:14:22.680 --> 00:14:23.760]   Google Plus.
[00:14:23.760 --> 00:14:30.040]   Some of that is, if not outright lying, then clearly just, you know, twisting the truth.
[00:14:30.040 --> 00:14:32.000]   We should have had you here last week, Matthew Ingev.
[00:14:32.000 --> 00:14:33.080]   We had Matt cuts on.
[00:14:33.080 --> 00:14:36.440]   Now he admittedly, this isn't his division and he wasn't speaking for Google in this
[00:14:36.440 --> 00:14:37.440]   case.
[00:14:37.440 --> 00:14:40.040]   But he did make the argument, which I found somewhat credible.
[00:14:40.040 --> 00:14:43.560]   We don't want to base social results on something we can't control.
[00:14:43.560 --> 00:14:48.160]   And we learned that from Twitter experience with Twitter, we can't control that data.
[00:14:48.160 --> 00:14:49.800]   We can't control the Facebook data.
[00:14:49.800 --> 00:14:51.720]   So we have to use our own social graph.
[00:14:51.720 --> 00:14:52.720]   At least we control that.
[00:14:52.720 --> 00:14:55.400]   Is that not a, you believe that's disingenuous?
[00:14:55.400 --> 00:14:57.400]   I think that's disingenuous.
[00:14:57.400 --> 00:14:59.800]   They can't control the web and they base their index on the web.
[00:14:59.800 --> 00:15:02.200]   So that's, there's noise there.
[00:15:02.200 --> 00:15:04.040]   That's ridiculous.
[00:15:04.040 --> 00:15:11.560]   The focus on the user.org thing, the thing that Facebook and Twitter and Co. put up to
[00:15:11.560 --> 00:15:13.080]   point this out is really interesting.
[00:15:13.080 --> 00:15:14.880]   I don't know if you've played with that.
[00:15:14.880 --> 00:15:16.360]   It is.
[00:15:16.360 --> 00:15:18.880]   Because what they did, you can read the JavaScript.
[00:15:18.880 --> 00:15:22.160]   What they do is they do the Google Plus with your world search.
[00:15:22.160 --> 00:15:26.360]   And then they, if you click their bookmarklet, they go into a plain Google search from the
[00:15:26.360 --> 00:15:31.960]   API and they replace the Google Plus results with things that rank higher for that person
[00:15:31.960 --> 00:15:33.800]   that come from social networking sites.
[00:15:33.800 --> 00:15:35.360]   And the results get better.
[00:15:35.360 --> 00:15:36.680]   It fixes the Zuckerberg problem.
[00:15:36.680 --> 00:15:38.320]   It fixes a bunch of these other things.
[00:15:38.320 --> 00:15:41.520]   It stops pointing to Google Plus affirmatively.
[00:15:41.520 --> 00:15:47.040]   Now, that is making it clear that Google's not that fun one that scales for Google Plus.
[00:15:47.040 --> 00:15:48.040]   But we knew that.
[00:15:48.040 --> 00:15:50.480]   And I think Matt was being a bit disingenuous about that.
[00:15:50.480 --> 00:15:56.160]   But the other half of this is that Twitter and Facebook do make it hard to call them now.
[00:15:56.160 --> 00:15:57.160]   Yes.
[00:15:57.160 --> 00:16:05.360]   They, if you actually try and pull Facebook down with with curl, it says this is your
[00:16:05.360 --> 00:16:06.360]   browser is not supported.
[00:16:06.360 --> 00:16:11.000]   You know, they explicitly send you a not supported page unless you lie about what browser you
[00:16:11.000 --> 00:16:12.000]   are.
[00:16:12.000 --> 00:16:13.000]   Google's new search features.
[00:16:13.000 --> 00:16:14.560]   You can cut the audio on this, John.
[00:16:14.560 --> 00:16:19.840]   I'm just showing the video from this is a focus on the user.org if you want to know more.
[00:16:19.840 --> 00:16:25.000]   And they give an example, as you were saying, and you can do your own searches of if you
[00:16:25.000 --> 00:16:30.760]   search for Hugh Jackman on Google Plus versus Hugh Jackman, which is in an actual search
[00:16:30.760 --> 00:16:32.920]   result, the results are somewhat different.
[00:16:32.920 --> 00:16:33.920]   Go ahead.
[00:16:33.920 --> 00:16:34.920]   I'm sorry.
[00:16:34.920 --> 00:16:36.920]   I didn't mean to interrupt you.
[00:16:36.920 --> 00:16:41.960]   So San Francisco Fire Department on the ahead.
[00:16:41.960 --> 00:16:43.960]   They may indeed choose to interrupt.
[00:16:43.960 --> 00:16:44.960]   Next thing, go past.
[00:16:44.960 --> 00:16:45.960]   Okay.
[00:16:45.960 --> 00:16:55.280]   So the thing is that Twitter puts no follow on all outbound links.
[00:16:55.280 --> 00:16:57.760]   And it also routes them all through T dot CO now.
[00:16:57.760 --> 00:17:01.440]   So that's basically saying to Google's index, so do not follow this link.
[00:17:01.440 --> 00:17:04.240]   You're saying Twitter, not Google, Twitter.
[00:17:04.240 --> 00:17:06.080]   Twitter puts no follow.
[00:17:06.080 --> 00:17:09.240]   Does no follow and uses their own shortening.
[00:17:09.240 --> 00:17:11.040]   And cut off the fire hose.
[00:17:11.040 --> 00:17:12.040]   All three, right.
[00:17:12.040 --> 00:17:13.040]   Yeah.
[00:17:13.040 --> 00:17:16.280]   So the cut off the fire hose is a, you know, there's the, he said she said the thing about
[00:17:16.280 --> 00:17:17.280]   that, but it's.
[00:17:17.280 --> 00:17:18.280]   Yeah.
[00:17:18.280 --> 00:17:19.280]   Yeah.
[00:17:19.280 --> 00:17:22.480]   Basically, Twitter backed up the price and Google bought to the price, but who knows
[00:17:22.480 --> 00:17:28.040]   what was doing, you know, the sort of who was deciding what there, but it is a massive
[00:17:28.040 --> 00:17:31.320]   shame losing that real time search is a big hole in Google's results.
[00:17:31.320 --> 00:17:32.320]   And Matt's right about that.
[00:17:32.320 --> 00:17:35.160]   That was a beautiful feature that they had to take away because the Twitter pulled the
[00:17:35.160 --> 00:17:39.680]   plug on the contract or Google refused to pay it or whichever way around it is.
[00:17:39.680 --> 00:17:41.600]   But they were able to crawl.
[00:17:41.600 --> 00:17:42.600]   They are able to crawl to Twitter.
[00:17:42.600 --> 00:17:45.240]   I said, you've crawled 150 million pages off.
[00:17:45.240 --> 00:17:46.880]   But last week, what are you complaining about?
[00:17:46.880 --> 00:17:53.000]   The answer is they're complaining that they cannot get links out from Twitter because Twitter
[00:17:53.000 --> 00:17:59.160]   is, is no following them all, which is I had a bit of a back and forth with sample error
[00:17:59.160 --> 00:18:00.520]   at Twitter on this.
[00:18:00.520 --> 00:18:05.520]   Because the no follow thing was originally designed for third party content.
[00:18:05.520 --> 00:18:10.480]   So the idea of if you've got a blog post that has comments on it, the no follow was designed
[00:18:10.480 --> 00:18:13.880]   to go on links that are in your comments that weren't posted by you, but not on links
[00:18:13.880 --> 00:18:17.680]   that are posted with you so that you're not accidentally giving page rank to spammers
[00:18:17.680 --> 00:18:18.680]   through that.
[00:18:18.680 --> 00:18:21.920]   And this was an extension that Google created and promoted.
[00:18:21.920 --> 00:18:22.920]   Yes.
[00:18:22.920 --> 00:18:28.640]   In a way to keep people from artificially boosting Google juice by posting on other people's
[00:18:28.640 --> 00:18:29.640]   blogs.
[00:18:29.640 --> 00:18:34.400]   And now Twitter is using this in a way that wasn't intended.
[00:18:34.400 --> 00:18:38.000]   But the point is that Google wants them to.
[00:18:38.000 --> 00:18:43.440]   Yeah, Twitter is, Twitter is awkward because it doesn't have that second party third party
[00:18:43.440 --> 00:18:47.640]   distinction because there isn't a distinction between a comment and a post.
[00:18:47.640 --> 00:18:54.640]   So a tweet from me is from me, but a response from you to it is to a tweet from you.
[00:18:54.640 --> 00:18:56.360]   And there's two things going on here.
[00:18:56.360 --> 00:19:01.280]   One is that Google assigns page rank for the whole domain.
[00:19:01.280 --> 00:19:06.000]   And they can't distinguish between Twitter.com/KevinMarks, Twitter.com/Jeff.
[00:19:06.000 --> 00:19:08.720]   So that's what they say.
[00:19:08.720 --> 00:19:10.280]   That's what Max says about this.
[00:19:10.280 --> 00:19:12.040]   But here's the question.
[00:19:12.040 --> 00:19:16.440]   Let's say, let's say Twitter reversed their policy and Facebook reversed their policy.
[00:19:16.440 --> 00:19:18.760]   Would Google really even want this?
[00:19:18.760 --> 00:19:19.760]   Isn't they?
[00:19:19.760 --> 00:19:20.760]   They say they do.
[00:19:20.760 --> 00:19:21.760]   Yes.
[00:19:21.760 --> 00:19:22.760]   Don't they really prefer it?
[00:19:22.760 --> 00:19:24.960]   Well, but don't they really prefer the search?
[00:19:24.960 --> 00:19:26.960]   Go ahead, Max.
[00:19:26.960 --> 00:19:27.960]   Google, right?
[00:19:27.960 --> 00:19:34.920]   I mean, these engineers fix these search results with one like JavaScript file.
[00:19:34.920 --> 00:19:39.080]   This focus on the user weekend project is a bookmark list.
[00:19:39.080 --> 00:19:40.080]   It's so fun.
[00:19:40.080 --> 00:19:41.080]   Yeah.
[00:19:41.080 --> 00:19:42.080]   How hard could it be?
[00:19:42.080 --> 00:19:43.080]   A lot.
[00:19:43.080 --> 00:19:46.720]   I mean, it really was a very, very good.
[00:19:46.720 --> 00:19:50.880]   It was a really, really good project that made a really good point, which was like if
[00:19:50.880 --> 00:19:55.560]   a bookmark could configure out that this famous chef updates his Twitter profile, a lot more
[00:19:55.560 --> 00:19:57.320]   than he does is Google+ profile.
[00:19:57.320 --> 00:20:02.280]   And that if you search for him, his Twitter profiles would show up first, then Google certainly
[00:20:02.280 --> 00:20:03.280]   can.
[00:20:03.280 --> 00:20:05.520]   It's even better than that.
[00:20:05.520 --> 00:20:07.240]   They're actually using Google students to do that.
[00:20:07.240 --> 00:20:12.120]   They're using Google's raw search ranking to decide which one to replace it with.
[00:20:12.120 --> 00:20:15.680]   So I'll give you an example here.
[00:20:15.680 --> 00:20:21.680]   This is a search, John, if you pull up my page on music as revealed by Search Plus Your
[00:20:21.680 --> 00:20:22.680]   World.
[00:20:22.680 --> 00:20:26.240]   You see on the right people on pages on Google+ Britney Spears.
[00:20:26.240 --> 00:20:29.960]   I don't even know who David Guetta is and Lil Wayne.
[00:20:29.960 --> 00:20:33.760]   The Gaga noticed she wasn't on this list, so she suddenly joined Google+.
[00:20:33.760 --> 00:20:40.840]   Now I click the Don't Be Evil link and these are massaged by focus on the user.
[00:20:40.840 --> 00:20:42.960]   And now we actually get something completely different.
[00:20:42.960 --> 00:20:45.000]   We get some songs.
[00:20:45.000 --> 00:20:47.040]   I'm not sure how this is improved.
[00:20:47.040 --> 00:20:48.040]   This is MySpace.
[00:20:48.040 --> 00:20:49.040]   How is it?
[00:20:49.040 --> 00:20:50.040]   Two of them.
[00:20:50.040 --> 00:20:51.640]   Britney's MySpace and David Guetta.
[00:20:51.640 --> 00:20:54.720]   So what they did is they replaced Google+ with MySpace.
[00:20:54.720 --> 00:20:55.720]   That's interesting.
[00:20:55.720 --> 00:20:58.080]   Well, for music, but not for our orders.
[00:20:58.080 --> 00:21:00.080]   What are first?
[00:21:00.080 --> 00:21:02.480]   Well, it shows us what else the most page rank is.
[00:21:02.480 --> 00:21:05.920]   Well, let me look at Obama.
[00:21:05.920 --> 00:21:08.640]   That would be presumably not going to give me MySpace.
[00:21:08.640 --> 00:21:10.440]   I don't get any Google+ results here.
[00:21:10.440 --> 00:21:12.960]   So maybe they aren't evil when you search on the president.
[00:21:12.960 --> 00:21:13.960]   I don't know.
[00:21:13.960 --> 00:21:14.960]   Oh, we'll do something.
[00:21:14.960 --> 00:21:15.960]   If you search for a cooking.
[00:21:15.960 --> 00:21:16.960]   Cooking?
[00:21:16.960 --> 00:21:17.960]   All right, let's try that.
[00:21:17.960 --> 00:21:19.320]   Like cooking.
[00:21:19.320 --> 00:21:22.160]   And now I'm getting Jamie Oliver Alton, Brown and Lee Alice.
[00:21:22.160 --> 00:21:23.600]   Oh, by the way, I'm getting ads.
[00:21:23.600 --> 00:21:24.600]   It's OK.
[00:21:24.600 --> 00:21:25.600]   Lee Allison.
[00:21:25.600 --> 00:21:27.680]   From Google+, let's de-evilize it.
[00:21:27.680 --> 00:21:30.000]   I love that bookmark.
[00:21:30.000 --> 00:21:33.400]   And now we're getting Facebook, Twitter+, MySpace.
[00:21:33.400 --> 00:21:34.840]   We're getting Twitter tweets.
[00:21:34.840 --> 00:21:35.360]   Yeah.
[00:21:35.360 --> 00:21:35.880]   LinkedIn.
[00:21:35.880 --> 00:21:37.000]   Much better.
[00:21:37.000 --> 00:21:38.800]   And that's funny because Google has that information.
[00:21:38.800 --> 00:21:40.160]   That's the point.
[00:21:40.160 --> 00:21:40.800]   Right.
[00:21:40.800 --> 00:21:41.320]   Yeah.
[00:21:41.320 --> 00:21:43.560]   So that just answered the question.
[00:21:43.560 --> 00:21:45.440]   If Google had the information, would they want to use it?
[00:21:45.440 --> 00:21:47.040]   No.
[00:21:47.040 --> 00:21:49.000]   They want to promote Google+.
[00:21:49.000 --> 00:21:50.560]   Well, that was the argument Matt made,
[00:21:50.560 --> 00:21:52.680]   was that if they can't reliably have it--
[00:21:52.680 --> 00:21:54.200]   I'm not justifying it.
[00:21:54.200 --> 00:21:55.200]   But he was saying that they're not
[00:21:55.200 --> 00:21:57.040]   going to include it as a feature unless they
[00:21:57.040 --> 00:21:59.920]   know that the feature is secure.
[00:21:59.920 --> 00:22:02.560]   I'm not judging because I don't think that.
[00:22:02.560 --> 00:22:04.280]   One of the other things they did last week
[00:22:04.280 --> 00:22:06.040]   was deprecate the Social Graph API.
[00:22:06.040 --> 00:22:07.520]   That was buried in their list of things
[00:22:07.520 --> 00:22:09.080]   they were getting rid of.
[00:22:09.080 --> 00:22:12.040]   And that really worries me because the Social Graph API
[00:22:12.040 --> 00:22:14.400]   was the thing that Bradford's Patrick wrote
[00:22:14.400 --> 00:22:18.920]   that crawls the realm me and realm friend links on the web
[00:22:18.920 --> 00:22:21.480]   to construct a Social Graph in the public web.
[00:22:21.480 --> 00:22:22.480]   It's kind of useful.
[00:22:22.480 --> 00:22:25.320]   You put your URL in there and it tells you
[00:22:25.320 --> 00:22:27.120]   what other URLs are yours that connect to you by realm
[00:22:27.120 --> 00:22:28.160]   me links.
[00:22:28.160 --> 00:22:32.600]   And you can see who you link to, but my friend links.
[00:22:32.600 --> 00:22:34.240]   But what happens-- and that was what
[00:22:34.240 --> 00:22:35.640]   was used for the previous Social Search.
[00:22:35.640 --> 00:22:40.440]   If you actually go back to the old S2 Social Search thing,
[00:22:40.440 --> 00:22:41.840]   it will still show you that graph.
[00:22:41.840 --> 00:22:43.760]   But they basically said we're taking this API away.
[00:22:43.760 --> 00:22:47.440]   I know because I added all those links.
[00:22:47.440 --> 00:22:51.840]   They're all the realm me links to my sites some time ago.
[00:22:51.840 --> 00:22:53.160]   And that's the point.
[00:22:53.160 --> 00:22:55.280]   This is how you do distributed social.
[00:22:55.280 --> 00:22:57.480]   That was the point of that spec from--
[00:22:57.480 --> 00:22:59.320]   that's exactly-- 2003 spec.
[00:22:59.320 --> 00:23:01.200]   So why did they deprecate it, did they say?
[00:23:01.200 --> 00:23:04.720]   Usage.
[00:23:04.720 --> 00:23:05.920]   Now, part of the reason they deprecate it
[00:23:05.920 --> 00:23:09.680]   is that when Twitter went to new new Twitter,
[00:23:09.680 --> 00:23:12.400]   all the realm-- sorry, not all the realm me.
[00:23:12.400 --> 00:23:16.160]   But the realm me links is still there.
[00:23:16.160 --> 00:23:19.160]   But the realm friend links all went away.
[00:23:19.160 --> 00:23:22.240]   And Twitter's connection graph is no longer crawlable.
[00:23:22.240 --> 00:23:25.400]   If you actually look at their robots.txt,
[00:23:25.400 --> 00:23:29.480]   the following pages are behind a login wall.
[00:23:29.480 --> 00:23:30.960]   And they don't want you crawling that.
[00:23:30.960 --> 00:23:33.600]   So basically, you cannot crawl the link graph
[00:23:33.600 --> 00:23:36.480]   of Twitter anymore, which means that this is not no longer
[00:23:36.480 --> 00:23:38.440]   driving link graphs from Twitter.
[00:23:38.440 --> 00:23:40.520]   And I think possibly having problems with Facebook
[00:23:40.520 --> 00:23:42.200]   is what Facebook does show that.
[00:23:42.200 --> 00:23:44.640]   But they never showed you all the friends.
[00:23:44.640 --> 00:23:46.120]   They would only show you five of them
[00:23:46.120 --> 00:23:47.560]   on the page that was crawlable.
[00:23:47.560 --> 00:23:49.600]   And so it had to statistically accumulate them
[00:23:49.600 --> 00:23:50.680]   over time or something.
[00:23:50.680 --> 00:23:55.120]   So the link graphs are now a no longer part of the public web
[00:23:55.120 --> 00:23:56.440]   from either of those companies.
[00:23:56.440 --> 00:23:59.440]   Their excuse is the API isn't experiencing the kind
[00:23:59.440 --> 00:24:01.560]   of adoption we'd like.
[00:24:01.560 --> 00:24:02.320]   Which is true.
[00:24:02.320 --> 00:24:03.920]   I doubt very many people did what I did.
[00:24:03.920 --> 00:24:05.440]   But it's not quite something to keep it running.
[00:24:05.440 --> 00:24:06.960]   That's the thing.
[00:24:06.960 --> 00:24:09.360]   The thing is, it's a very useful--
[00:24:09.360 --> 00:24:12.560]   I wrote those some apps there, so I'm probably biased here.
[00:24:12.560 --> 00:24:17.360]   But it is useful because it's actually quite hard and expensive
[00:24:17.360 --> 00:24:18.320]   to crawl the web.
[00:24:18.320 --> 00:24:21.560]   And so to follow all those links with your own crawler,
[00:24:21.560 --> 00:24:23.520]   to say, OK, I've got Leela Port's page.
[00:24:23.520 --> 00:24:26.040]   And the rest of his pages, that would involve me visiting
[00:24:26.040 --> 00:24:27.600]   all those web pages and following all the meetings
[00:24:27.600 --> 00:24:28.640]   and deriving it.
[00:24:28.640 --> 00:24:30.400]   Google already does that.
[00:24:30.400 --> 00:24:32.280]   They crawl the entire web all the time.
[00:24:32.280 --> 00:24:35.960]   So caching that for other people is a really useful service.
[00:24:35.960 --> 00:24:38.520]   It's basically taking Google's crawl and giving something back.
[00:24:38.520 --> 00:24:42.200]   So dropping that, I think, is a shame.
[00:24:42.200 --> 00:24:45.040]   I can sort of see why because the other companies haven't
[00:24:45.040 --> 00:24:46.000]   necessarily kept this up.
[00:24:46.000 --> 00:24:51.040]   But it's still a step away from the openware.
[00:24:51.040 --> 00:24:53.880]   The other link thing, the no-follow piece,
[00:24:53.880 --> 00:24:58.400]   is Twitter is not passing through page rank
[00:24:58.400 --> 00:25:01.360]   to anything that's posted on Twitter.
[00:25:01.360 --> 00:25:04.960]   When Google had the firehose, they were using those links.
[00:25:04.960 --> 00:25:07.200]   But they're now strictly obeying the no-follows
[00:25:07.200 --> 00:25:10.360]   that Twitter puts on, which means there's no page rank
[00:25:10.360 --> 00:25:12.240]   thrown from Twitter to 4-square or Instagram,
[00:25:12.240 --> 00:25:13.520]   or anything like that.
[00:25:13.520 --> 00:25:19.120]   And this conversation with Dennis Crowley of 4-square yesterday,
[00:25:19.120 --> 00:25:22.960]   that they get a lot of traction from links being posted on Twitter,
[00:25:22.960 --> 00:25:25.120]   but they're not sharing a lot of research because of it.
[00:25:25.120 --> 00:25:28.600]   Because that link is not counted by Google.
[00:25:28.600 --> 00:25:32.520]   But Kevin, wasn't the no-follow?
[00:25:32.520 --> 00:25:35.120]   Isn't that something that Google requires
[00:25:35.120 --> 00:25:37.840]   so that you don't flow page rank to things?
[00:25:37.840 --> 00:25:40.800]   Doesn't it penalize you if you flow page rank to things
[00:25:40.800 --> 00:25:42.800]   that go to spam and so on?
[00:25:42.800 --> 00:25:44.760]   It needs updating.
[00:25:44.760 --> 00:25:49.600]   It will be good to get Matt Cuts in a room with the people at Twitter
[00:25:49.600 --> 00:25:51.560]   who were responding in that sense.
[00:25:51.560 --> 00:25:57.080]   But yeah, the issue is that what Google really needs
[00:25:57.080 --> 00:25:59.400]   to make sense of Twitter in its terms
[00:25:59.400 --> 00:26:03.080]   is to understand the links between the different Twitter profiles
[00:26:03.080 --> 00:26:05.640]   and the links that are tweets and retweets
[00:26:05.640 --> 00:26:12.120]   so that it can build a page rank trust for the Twitter set of pages.
[00:26:12.120 --> 00:26:14.360]   And without those follow links,
[00:26:14.360 --> 00:26:17.920]   it cannot get the who's more interesting
[00:26:17.920 --> 00:26:21.200]   because they've got more followers-type information out of it.
[00:26:21.200 --> 00:26:25.520]   And because they're not allowed to flow page rank
[00:26:25.520 --> 00:26:27.760]   from the tweets to the links in the tweets,
[00:26:27.760 --> 00:26:32.920]   they can't use the sort of trending links there as a signal anymore.
[00:26:32.920 --> 00:26:34.840]   Which means that posting a link on Twitter
[00:26:34.840 --> 00:26:37.840]   is not helping people find it on Google.
[00:26:37.840 --> 00:26:39.840]   And that's a problem.
[00:26:39.840 --> 00:26:43.640]   And I think that I wrote something recently.
[00:26:43.640 --> 00:26:46.040]   We're losing signal, right?
[00:26:46.040 --> 00:26:49.360]   And I think both Google and Twitter and all their users
[00:26:49.360 --> 00:26:50.920]   are the ones who suffer.
[00:26:50.920 --> 00:26:54.560]   I mean, I wrote a whole blog post about the relationship
[00:26:54.560 --> 00:26:58.040]   between these two companies feeling like a couple that has broken up
[00:26:58.040 --> 00:27:00.680]   or a couple that's divorcing.
[00:27:00.680 --> 00:27:03.240]   You've got Google saying it's your fault and Twitter saying,
[00:27:03.240 --> 00:27:04.240]   "No, no, it's your fault."
[00:27:04.240 --> 00:27:06.720]   And Google's saying, "Well, you left first."
[00:27:06.720 --> 00:27:09.720]   And Twitter's like, "Well, you didn't, you know, finally..."
[00:27:09.720 --> 00:27:12.520]   You was seeing others' social networks.
[00:27:12.520 --> 00:27:13.520]   But you know what?
[00:27:13.520 --> 00:27:14.520]   I don't think we're being tough enough.
[00:27:14.520 --> 00:27:16.520]   But to be the bad group on Twitter's...
[00:27:16.520 --> 00:27:17.520]   Go ahead, Matt.
[00:27:17.520 --> 00:27:20.320]   ...with users of the ones who suffer.
[00:27:20.320 --> 00:27:23.120]   Twitter has virtually no useful search.
[00:27:23.120 --> 00:27:24.120]   Let's face it.
[00:27:24.120 --> 00:27:25.720]   Their search doesn't show up things.
[00:27:25.720 --> 00:27:28.120]   It only lasts for like five days, I think, now.
[00:27:28.120 --> 00:27:29.720]   It's basically useless.
[00:27:29.720 --> 00:27:33.120]   So then you have to go to Topsy, which is OK, but it's not great.
[00:27:33.120 --> 00:27:36.320]   If Google had that fire hose, it would be fantastic.
[00:27:36.320 --> 00:27:37.920]   It would be great for Google users.
[00:27:37.920 --> 00:27:39.720]   It would be great for Twitter users.
[00:27:39.720 --> 00:27:43.520]   But here we are watching mom and dad fight over the kids.
[00:27:43.520 --> 00:27:44.520]   Go ahead, Jeff.
[00:27:44.520 --> 00:27:46.720]   We've got to ask a question about Twitter here.
[00:27:46.720 --> 00:27:48.320]   And I'm not trying to attack Twitter.
[00:27:48.320 --> 00:27:52.320]   I'm just saying that Google always gets under the laser light.
[00:27:52.320 --> 00:27:53.720]   And then Facebook is under the laser light.
[00:27:53.720 --> 00:27:55.120]   Twitter generally doesn't.
[00:27:55.120 --> 00:27:57.120]   And I still go back and, Gina, you've defended Twitter.
[00:27:57.120 --> 00:28:02.320]   But I still think that Twitter's behavior toward its developers is pretty schmucky.
[00:28:02.320 --> 00:28:02.920]   Yes.
[00:28:02.920 --> 00:28:07.520]   And the Twitter doing things like being passive aggressive and assisting in its own clients
[00:28:07.520 --> 00:28:10.920]   to not do retweet the way the whole world wants to retweet done.
[00:28:10.920 --> 00:28:14.320]   And stuff-- and then, you know, yeah, there's a back and forth between mom and dad.
[00:28:14.320 --> 00:28:16.720]   You're right, Matthew, in terms of the fire hose.
[00:28:16.720 --> 00:28:19.120]   But Twitter should want to say you should be able to find tweets.
[00:28:19.120 --> 00:28:19.720]   Our tweets.
[00:28:19.720 --> 00:28:21.920]   They're our tweets anywhere.
[00:28:21.920 --> 00:28:22.920]   They're not Twitter's tweets.
[00:28:22.920 --> 00:28:23.720]   Damn it.
[00:28:23.720 --> 00:28:28.720]   And so I just think we need to put a little more attention on Twitter and ask whether
[00:28:28.720 --> 00:28:30.220]   they're being good or evil.
[00:28:30.220 --> 00:28:31.520]   And I'm not answering the question.
[00:28:31.520 --> 00:28:32.520]   But I want to ask it more often.
[00:28:32.520 --> 00:28:34.920]   Jeff, we posed this question two or three years ago.
[00:28:34.920 --> 00:28:37.120]   Remember, Bear Hug Camp with Steve Gilmore?
[00:28:37.120 --> 00:28:37.720]   We went there.
[00:28:37.720 --> 00:28:38.920]   We covered it live.
[00:28:38.920 --> 00:28:44.320]   I've been saying this all along that we should do another Bear Hug Camp.
[00:28:44.320 --> 00:28:49.520]   I mean, at that time, Steve was upset about the loss of track.
[00:28:49.520 --> 00:28:53.920]   But really, the issue is that Twitter guard is silos this information.
[00:28:53.920 --> 00:28:54.520]   Yeah.
[00:28:54.520 --> 00:28:59.120]   A very interesting article on Tech Crunch from Devon Coldway who says that Google going
[00:28:59.120 --> 00:29:02.920]   evil has become the Godwin's law of tech commentary.
[00:29:02.920 --> 00:29:03.720]   I love that.
[00:29:03.720 --> 00:29:04.520]   It's so true.
[00:29:04.520 --> 00:29:07.120]   He says that basically what's happened is there's bias.
[00:29:07.120 --> 00:29:13.420]   People want so badly for Google to do something truly evil evil that they're they're actually
[00:29:13.420 --> 00:29:14.320]   expecting it.
[00:29:14.320 --> 00:29:17.720]   And so that's why you get things like, Oh my God, they did it.
[00:29:17.720 --> 00:29:19.420]   It's really bad in Europe, but you're right.
[00:29:19.420 --> 00:29:21.120]   The Washington Post is we did it this week.
[00:29:21.120 --> 00:29:23.120]   Yeah, I'd expect more from this wall.
[00:29:23.120 --> 00:29:23.620]   Yeah.
[00:29:23.620 --> 00:29:24.320]   Godwin's law.
[00:29:24.320 --> 00:29:25.120]   It's so true.
[00:29:25.120 --> 00:29:28.920]   I was saying on Twitter yesterday that like at Google's values, like I prefer.
[00:29:28.920 --> 00:29:34.120]   This is a very general statement, but I prefer Google's values over their products and Apple's
[00:29:34.120 --> 00:29:35.920]   products over their values.
[00:29:35.920 --> 00:29:41.320]   So whenever I feel like Google's values are compromised, I freak out because it because
[00:29:41.320 --> 00:29:44.920]   I feel like, you know, Google is sort of the conscience of the industry where's where
[00:29:44.920 --> 00:29:47.720]   as Apple is kind of the forefront of design.
[00:29:47.720 --> 00:29:51.920]   So, you know, I would be just as quick to point out if Apple made a crappy product.
[00:29:51.920 --> 00:29:53.320]   I'm still waiting for that to happen.
[00:29:53.320 --> 00:29:55.520]   Well, I mean, that's a good point.
[00:29:55.520 --> 00:29:56.520]   That's a good point.
[00:29:56.520 --> 00:29:59.020]   We expect Apple to be evil, right?
[00:29:59.020 --> 00:30:04.920]   We expect Apple to do things that are only in its interest, but we always expected Google.
[00:30:04.920 --> 00:30:06.920]   We've sort of held it to a higher standard.
[00:30:06.920 --> 00:30:07.920]   We have.
[00:30:07.920 --> 00:30:09.920]   And so when I'm just below that, I think people.
[00:30:09.920 --> 00:30:14.720]   Yeah, I'm going to see Schmidt and company here at Davos on Friday.
[00:30:14.720 --> 00:30:17.120]   Is there any question that you want to deputize me to ask?
[00:30:17.120 --> 00:30:19.220]   Well, this is a good one to start with.
[00:30:19.220 --> 00:30:24.760]   This is Sarah Lacey writing in the new Pando Daily, which has issues which talk about at
[00:30:24.760 --> 00:30:25.760]   some point.
[00:30:25.760 --> 00:30:28.560]   She does point out.
[00:30:28.560 --> 00:30:29.560]   She does.
[00:30:29.560 --> 00:30:33.880]   I mean, I guess what you should say is considered the source, but she does point out that Chris
[00:30:33.880 --> 00:30:38.280]   Saka, who's probably an investor in Pando Daily, has says that three Googlers.
[00:30:38.280 --> 00:30:39.800]   Is everybody an investor?
[00:30:39.800 --> 00:30:40.800]   Everybody is.
[00:30:40.800 --> 00:30:42.360]   If you're on page, what is it?
[00:30:42.360 --> 00:30:44.560]   Page Mill Road.
[00:30:44.560 --> 00:30:46.360]   You're an investor.
[00:30:46.360 --> 00:30:49.640]   Apparently, Larry Page to Googlers is the headline.
[00:30:49.640 --> 00:30:54.720]   If you don't get search plus your world, work somewhere else.
[00:30:54.720 --> 00:31:00.320]   Actually at a Friday staff event after the launch, he said, and this is a quote, but
[00:31:00.320 --> 00:31:03.040]   again, kind of unsourced.
[00:31:03.040 --> 00:31:08.700]   This is the path we're heading down a single unified, beautiful product across everything.
[00:31:08.700 --> 00:31:12.920]   If you don't get that, you should probably work somewhere else.
[00:31:12.920 --> 00:31:14.840]   Well, this is Apple's value.
[00:31:14.840 --> 00:31:15.840]   I think it's right.
[00:31:15.840 --> 00:31:16.840]   I think it's right.
[00:31:16.840 --> 00:31:17.840]   Seeping into Google, right?
[00:31:17.840 --> 00:31:18.840]   Like this is how I read that.
[00:31:18.840 --> 00:31:19.840]   That worried me.
[00:31:19.840 --> 00:31:21.320]   I was like, oh, these are Apple's value, sleeping into Google.
[00:31:21.320 --> 00:31:24.200]   And that's something that I've actually, I think Google has a lot to learn from Apple
[00:31:24.200 --> 00:31:26.080]   as I think Apple has a lot to learn from Google.
[00:31:26.080 --> 00:31:29.880]   But aren't they saying this to not just their employees, but users as well?
[00:31:29.880 --> 00:31:31.640]   And this is the thing that bugs me a little bit.
[00:31:31.640 --> 00:31:33.840]   Hey, you can opt out.
[00:31:33.840 --> 00:31:34.840]   Stop using Google.
[00:31:34.840 --> 00:31:37.720]   No, we see Leo, your head law there.
[00:31:37.720 --> 00:31:39.040]   You're a little bit far.
[00:31:39.040 --> 00:31:42.600]   What they're saying to employees is that we've been saying that Google doesn't have a strong
[00:31:42.600 --> 00:31:43.600]   enough strategy.
[00:31:43.600 --> 00:31:44.600]   There was all over the map.
[00:31:44.600 --> 00:31:47.680]   So now they're on the map and you're saying, oh, we don't like this map.
[00:31:47.680 --> 00:31:48.680]   It's their map.
[00:31:48.680 --> 00:31:52.920]   Nick Husharwar was at the VLD conference in Munich a couple of days ago, and I heard him
[00:31:52.920 --> 00:31:53.920]   talk.
[00:31:53.920 --> 00:31:54.920]   He's given the company line.
[00:31:54.920 --> 00:31:58.560]   And the company line is that we're moving as a whole here, not just Google, but as a whole
[00:31:58.560 --> 00:32:01.840]   from the information age back to people.
[00:32:01.840 --> 00:32:03.040]   And that's where Google is.
[00:32:03.040 --> 00:32:04.520]   And that's where the strategic view is.
[00:32:04.520 --> 00:32:06.600]   We like or dislike it.
[00:32:06.600 --> 00:32:10.440]   But it's a corporate strategy that they're saying this is going.
[00:32:10.440 --> 00:32:11.440]   And that is a good goal.
[00:32:11.440 --> 00:32:16.440]   I mean, what he's describing, Search Plus Your World is actually a great idea, I think,
[00:32:16.440 --> 00:32:20.160]   having social search results in your search results.
[00:32:20.160 --> 00:32:23.560]   But they're not doing what they claim to be doing.
[00:32:23.560 --> 00:32:25.560]   They're not executing well.
[00:32:25.560 --> 00:32:28.680]   But broad enough search and they're not ranking as the way they do other things.
[00:32:28.680 --> 00:32:29.680]   And that's what they're doing.
[00:32:29.680 --> 00:32:30.680]   I agree with that.
[00:32:30.680 --> 00:32:31.680]   That's a huge issue.
[00:32:31.680 --> 00:32:32.680]   They're doing what they're saying.
[00:32:32.680 --> 00:32:33.680]   They're doing.
[00:32:33.680 --> 00:32:36.240]   But you can't reduce the number of choices, right?
[00:32:36.240 --> 00:32:37.240]   Like you can't offer something.
[00:32:37.240 --> 00:32:40.160]   Like if you were selling a product, you can't offer product for free and then make it cost
[00:32:40.160 --> 00:32:41.160]   money.
[00:32:41.160 --> 00:32:43.480]   Like the psychological impact of that is people get upset.
[00:32:43.480 --> 00:32:47.000]   You know, Google's has always been about choice and control and openness.
[00:32:47.000 --> 00:32:52.000]   And I think that the no opt out part of the privacy policy headline, the sensationalist
[00:32:52.000 --> 00:32:53.520]   headline, is a thing that got me.
[00:32:53.520 --> 00:32:57.560]   Because I thought, hey, Google's all about choice and control and now they're not, right?
[00:32:57.560 --> 00:32:59.120]   Apple's never about choice and control.
[00:32:59.120 --> 00:33:01.520]   Apple starts out with CRM and then they remove it.
[00:33:01.520 --> 00:33:02.520]   It's about how you don't have it.
[00:33:02.520 --> 00:33:06.040]   Because going the other way, you know, lots of choices and now they're reducing choices.
[00:33:06.040 --> 00:33:10.760]   So the feeling, I agree that it's the right path, but it's why people are freaking out.
[00:33:10.760 --> 00:33:14.160]   Because you don't want to raise prices.
[00:33:14.160 --> 00:33:21.240]   So it's just a different, it's a, if you're going to suffer through these kinds of PR problems
[00:33:21.240 --> 00:33:25.240]   regularly, if it keeps going this way, this reduction.
[00:33:25.240 --> 00:33:29.440]   Yeah, and I think saying you can stop using all Google's products, that's great.
[00:33:29.440 --> 00:33:32.800]   So I can't use any Google service if I don't want to have my information shared.
[00:33:32.800 --> 00:33:34.040]   Well, can you opt out?
[00:33:34.040 --> 00:33:35.040]   Can I opt out?
[00:33:35.040 --> 00:33:37.000]   If I log out, do I not opt out?
[00:33:37.000 --> 00:33:39.040]   Yeah, you can log out, right?
[00:33:39.040 --> 00:33:40.040]   You log out, right.
[00:33:40.040 --> 00:33:41.640]   None of this kicks in.
[00:33:41.640 --> 00:33:46.560]   And also something important to note, double click cookie tracking and Google Analytics
[00:33:46.560 --> 00:33:50.040]   tracking is not covered underneath this new privacy policy change.
[00:33:50.040 --> 00:33:53.520]   Like that's totally separate things.
[00:33:53.520 --> 00:33:55.200]   So it doesn't sound too truthfully.
[00:33:55.200 --> 00:34:02.200]   What really happened here is that Google kind of made some technical changes that will,
[00:34:02.200 --> 00:34:04.080]   this is completely separate from Search Plus Your World.
[00:34:04.080 --> 00:34:07.720]   I realize we've got two conversations going on here, but it made some technical changes
[00:34:07.720 --> 00:34:10.080]   that allowed them to unify all this data.
[00:34:10.080 --> 00:34:13.560]   And as a result, they've given us a unified privacy policy.
[00:34:13.560 --> 00:34:17.040]   And under normal circumstances, people would say, that's great.
[00:34:17.040 --> 00:34:18.640]   Now we want a simple normal.
[00:34:18.640 --> 00:34:20.640]   This is what you ask of Facebook, isn't it?
[00:34:20.640 --> 00:34:24.400]   Give us a policy that's universal and clear.
[00:34:24.400 --> 00:34:25.800]   So we understand it.
[00:34:25.800 --> 00:34:28.400]   Google's policy isn't changing, by the way.
[00:34:28.400 --> 00:34:31.240]   Some of it, I've lost the article now, but somebody did a search back to 2005.
[00:34:31.240 --> 00:34:33.760]   It's been doing the same basic policy all along.
[00:34:33.760 --> 00:34:34.760]   It's just now--
[00:34:34.760 --> 00:34:35.760]   Yeah, so--
[00:34:35.760 --> 00:34:44.400]   So I think it shows, that shows the response I think shows that Google has lost some trust.
[00:34:44.400 --> 00:34:45.400]   That's a risk.
[00:34:45.400 --> 00:34:48.200]   What, but the math, you, well, yeah, no, I think--
[00:34:48.200 --> 00:34:50.480]   You're right and wrong.
[00:34:50.480 --> 00:34:55.280]   In terms of the recent Search Plus stuff, in our circles, I don't think that's really
[00:34:55.280 --> 00:34:58.840]   in the world yet, in our circles, yeah, we're kind of a little suspicious.
[00:34:58.840 --> 00:35:03.640]   But in general, there's just this general Godwin's law when it comes to Google, that
[00:35:03.640 --> 00:35:06.080]   they're big and big is bad.
[00:35:06.080 --> 00:35:10.280]   And almost anti-capitalist at some point over here in Europe.
[00:35:10.280 --> 00:35:11.440]   And I see it all the time.
[00:35:11.440 --> 00:35:13.000]   And I don't think that's because of anything they've done.
[00:35:13.000 --> 00:35:14.960]   I think that's just because they're big and successful.
[00:35:14.960 --> 00:35:16.960]   And it was Microsoft before them.
[00:35:16.960 --> 00:35:24.440]   Although, you know, I have to say, my 18-year-old daughter said to me, what's going on with
[00:35:24.440 --> 00:35:25.440]   Google?
[00:35:25.440 --> 00:35:29.120]   Why are they fooling all my information and not letting me opt out?
[00:35:29.120 --> 00:35:30.120]   But that's the fact.
[00:35:30.120 --> 00:35:31.760]   That's like my doctor saying it.
[00:35:31.760 --> 00:35:32.760]   That's like my doctor saying it.
[00:35:32.760 --> 00:35:34.240]   He's not a techy.
[00:35:34.240 --> 00:35:35.240]   But he says, I'm a doctor.
[00:35:35.240 --> 00:35:37.920]   I have to be very careful about what's online with me.
[00:35:37.920 --> 00:35:40.360]   Now, should I worry, should I stop using Google?
[00:35:40.360 --> 00:35:43.320]   This is the universal response to this.
[00:35:43.320 --> 00:35:44.320]   But you're right.
[00:35:44.320 --> 00:35:45.320]   It's the press.
[00:35:45.320 --> 00:35:46.800]   It's Washington Post specifically.
[00:35:46.800 --> 00:35:47.800]   And it's government too.
[00:35:47.800 --> 00:35:49.640]   Again, I'm seeing that Europe will get to it in a few minutes.
[00:35:49.640 --> 00:35:53.680]   But over here in Europe, there's just awful, soap-asquared stuff happening with this.
[00:35:53.680 --> 00:35:57.640]   And it's going to affect not just Google, but the whole entire internet is getting
[00:35:57.640 --> 00:35:58.640]   foodies.
[00:35:58.640 --> 00:36:04.760]   And it will be interesting to see how Google's new cool all your information and do whatever
[00:36:04.760 --> 00:36:08.240]   we want with it is going to fly with European regulators.
[00:36:08.240 --> 00:36:14.560]   And let's be honest, as you point out, Matthew, in your article on Gigahome, this Don't
[00:36:14.560 --> 00:36:18.280]   Be Evil plugin was written by one of the developers works for Facebook.
[00:36:18.280 --> 00:36:20.640]   So it's also Facebook.
[00:36:20.640 --> 00:36:21.920]   It's also Compound Editors.
[00:36:21.920 --> 00:36:26.320]   It's Twitter and Facebook saying, Google's being evil.
[00:36:26.320 --> 00:36:29.680]   And I think that's really what we're seeing, by the way.
[00:36:29.680 --> 00:36:31.600]   I mean, let's really be honest.
[00:36:31.600 --> 00:36:38.440]   Is intense competition among Facebook, Google, Twitter.
[00:36:38.440 --> 00:36:41.360]   You can include some other companies in on that.
[00:36:41.360 --> 00:36:48.480]   And Microsoft, and as the competition ramps up, companies start acting more in their own
[00:36:48.480 --> 00:36:49.480]   interest.
[00:36:49.480 --> 00:36:51.480]   They're fighting it out.
[00:36:51.480 --> 00:36:55.320]   And that's what- And it's been across against cable industry and telephone industry.
[00:36:55.320 --> 00:36:58.080]   It's going to get stronger, of course.
[00:36:58.080 --> 00:36:59.080]   Yeah.
[00:36:59.080 --> 00:37:03.520]   And let's face it, that's why Google added-that's why Google+ was created in the first place.
[00:37:03.520 --> 00:37:04.520]   Right.
[00:37:04.520 --> 00:37:07.960]   It's not because Google suddenly felt that it had to let you share photos of your cat
[00:37:07.960 --> 00:37:12.600]   with everyone, was because they wanted to get those social signals that they could use
[00:37:12.600 --> 00:37:15.080]   to improve search, improve targeting, and so on.
[00:37:15.080 --> 00:37:16.080]   That's the Holy Grail.
[00:37:16.080 --> 00:37:18.680]   This is something that happened, and I don't know what happened, but something happened,
[00:37:18.680 --> 00:37:20.360]   maybe because the stakes are so high all of a sudden.
[00:37:20.360 --> 00:37:22.640]   But a couple of years ago, we all observed this.
[00:37:22.640 --> 00:37:24.640]   There was suddenly this kind of animosity.
[00:37:24.640 --> 00:37:25.640]   Apple hates Google.
[00:37:25.640 --> 00:37:27.560]   I mean, really hates Google.
[00:37:27.560 --> 00:37:29.720]   Facebook really hates Twitter.
[00:37:29.720 --> 00:37:32.880]   I mean, there was this battle all of a sudden among these companies.
[00:37:32.880 --> 00:37:37.880]   We're in the past, there might have been some sort of sense of kind of we're all in it together.
[00:37:37.880 --> 00:37:41.480]   Is there any hope that SOPA brings us back together for a group of us?
[00:37:41.480 --> 00:37:43.000]   I just want to say one thing.
[00:37:43.000 --> 00:37:45.000]   Isn't that what we all say we want?
[00:37:45.000 --> 00:37:46.720]   We want competition.
[00:37:46.720 --> 00:37:50.480]   Isn't that what we're all talking?
[00:37:50.480 --> 00:37:51.480]   We don't want monopoly.
[00:37:51.480 --> 00:37:52.480]   We want competition.
[00:37:52.480 --> 00:37:56.800]   So a stronger Google and a stronger Facebook is good for the users, isn't it?
[00:37:56.800 --> 00:37:57.800]   Good point.
[00:37:57.800 --> 00:38:00.840]   But that's why Google putting its thumb on the scale is so important.
[00:38:00.840 --> 00:38:03.160]   They're tipping the balance.
[00:38:03.160 --> 00:38:04.960]   Facebook puts the thumb on the scale.
[00:38:04.960 --> 00:38:07.960]   Are you using their search?
[00:38:07.960 --> 00:38:09.960]   They're both doing it.
[00:38:09.960 --> 00:38:11.960]   It's all fist on the scale.
[00:38:11.960 --> 00:38:12.960]   But we put it on the scale.
[00:38:12.960 --> 00:38:13.960]   It minimally doesn't.
[00:38:13.960 --> 00:38:16.520]   They don't control 60% of the search.
[00:38:16.520 --> 00:38:18.240]   Kevin Marks, go ahead.
[00:38:18.240 --> 00:38:20.000]   So yes, Jeff, they do.
[00:38:20.000 --> 00:38:21.000]   But people do it too.
[00:38:21.000 --> 00:38:22.000]   Doesn't make it better.
[00:38:22.000 --> 00:38:24.520]   It makes it worse.
[00:38:24.520 --> 00:38:29.680]   Maybe Google is in somewhat poking at Facebook to say make yourself more crawlable, please,
[00:38:29.680 --> 00:38:31.960]   so that we can crawl you better.
[00:38:31.960 --> 00:38:36.360]   That's clearly part of what Matt was saying last week, that they don't have specialized
[00:38:36.360 --> 00:38:37.360]   access.
[00:38:37.360 --> 00:38:41.720]   They have to crawl them, but they're calling them in the constraints of what they publish.
[00:38:41.720 --> 00:38:43.280]   So there is definitely that.
[00:38:43.280 --> 00:38:47.400]   And as you said previously, Facebook has briefed against them and said, oh, Google is pulling
[00:38:47.400 --> 00:38:50.800]   your private Facebook data out when it was actually the stuff that was public.
[00:38:50.800 --> 00:38:52.920]   So there is, yes, there's animosity there.
[00:38:52.920 --> 00:38:58.760]   But the kind of competition you want is not sort of attacking competition.
[00:38:58.760 --> 00:39:02.160]   You want competition where they're competing to serve as better, not where they need to
[00:39:02.160 --> 00:39:04.840]   catch the route of the picture.
[00:39:04.840 --> 00:39:08.680]   The difference is the difference between the old browser wars where it was used in our
[00:39:08.680 --> 00:39:12.840]   browser because we've got these special features the other guy that don't have.
[00:39:12.840 --> 00:39:15.840]   And the new browser wars, which is use our browser because we're implementing the open
[00:39:15.840 --> 00:39:18.080]   standards of the web better than the other guys.
[00:39:18.080 --> 00:39:19.240]   And it's more responsive.
[00:39:19.240 --> 00:39:24.000]   And we want to move to that kind of competition as opposed to the competition of we're doing
[00:39:24.000 --> 00:39:25.560]   this thing just to spite each other.
[00:39:25.560 --> 00:39:29.920]   So there's a way of doing competing in a sort of positive some way as opposed to a negative
[00:39:29.920 --> 00:39:30.920]   some way.
[00:39:30.920 --> 00:39:35.320]   And that's the piece that's probably, no, the thing that makes me most sad about this is
[00:39:35.320 --> 00:39:40.240]   that we're losing a lot of the open web of this stuff.
[00:39:40.240 --> 00:39:41.800]   There is this competition for quality.
[00:39:41.800 --> 00:39:43.840]   It's only social inside silos.
[00:39:43.840 --> 00:39:44.840]   Yeah.
[00:39:44.840 --> 00:39:50.880]   We had this sort of very distributed graph of information that was the blogosphere that
[00:39:50.880 --> 00:39:54.600]   was the equivalent of what we use Twitter for now.
[00:39:54.600 --> 00:39:57.880]   And I was able to write a search engine at technology that could crawl that because it
[00:39:57.880 --> 00:40:02.040]   was all in public and it was on multiple people's servers and it, you know, no one company
[00:40:02.040 --> 00:40:03.040]   controlled all of it.
[00:40:03.040 --> 00:40:06.640]   There are a few companies that were fairly big that you had to deal with specially, but
[00:40:06.640 --> 00:40:07.640]   we could do that.
[00:40:07.640 --> 00:40:11.760]   Now, that stuff is not crawlable in the same way.
[00:40:11.760 --> 00:40:16.400]   And the other thing is we had a convention for pinging to say something is new, something
[00:40:16.400 --> 00:40:19.640]   has changed, come and crawl this now, which meant that technology didn't have to crawl
[00:40:19.640 --> 00:40:24.920]   the entire web, we were told by the blog software when something had changed.
[00:40:24.920 --> 00:40:31.440]   That piece is a big chunk of what people got from the fire hose was a notation that these
[00:40:31.440 --> 00:40:32.680]   things have changed now.
[00:40:32.680 --> 00:40:36.200]   If they do it with standard crawl, they've got to basically keep hitting pages and guessing
[00:40:36.200 --> 00:40:37.960]   when they've changed.
[00:40:37.960 --> 00:40:40.560]   They don't get that feed of updates.
[00:40:40.560 --> 00:40:43.280]   And we don't have, well, that's not quite true.
[00:40:43.280 --> 00:40:48.320]   We do have a standard for how to do this with Pub/Sub/ Pub/Sub, but that is designed for
[00:40:48.320 --> 00:40:52.160]   a distributed world, not for the essentialised world, where you really do need a feed for
[00:40:52.160 --> 00:40:54.440]   one company to make it useful.
[00:40:54.440 --> 00:41:00.520]   And the other part of this is that Google Plus itself doesn't have a good API for this,
[00:41:00.520 --> 00:41:06.120]   or rather, the Google Plus API has a 5,000 calls a day limit, which means you can't get
[00:41:06.120 --> 00:41:08.160]   fire hose access to Google Plus.
[00:41:08.160 --> 00:41:09.160]   True.
[00:41:09.160 --> 00:41:10.760]   And it was responses, well, crawl us like we crawl the web.
[00:41:10.760 --> 00:41:14.320]   It's like, well, yeah, but we don't actually have the infrastructure to do that.
[00:41:14.320 --> 00:41:18.120]   It would be nice if you set things up by making your API available too.
[00:41:18.120 --> 00:41:19.120]   That's a great point.
[00:41:19.120 --> 00:41:24.040]   Okay, let me wrap up this conversation by asking each of you.
[00:41:24.040 --> 00:41:25.880]   Has Google changed?
[00:41:25.880 --> 00:41:27.800]   What has changed?
[00:41:27.800 --> 00:41:32.920]   Is this a suddenly evil Google, Kevin Marks?
[00:41:32.920 --> 00:41:34.280]   I don't think it's a suddenly evil Google.
[00:41:34.280 --> 00:41:39.400]   I think it's a suddenly more insular Google, or more obviously insular Google.
[00:41:39.400 --> 00:41:42.480]   They're starting to say, oh, right, we'll do this ourselves because you won't cooperate
[00:41:42.480 --> 00:41:43.480]   with this.
[00:41:43.480 --> 00:41:45.200]   And I get, you know, I sensed that frustration.
[00:41:45.200 --> 00:41:49.440]   And I was there when we were having versions of these battles with Facebook where Facebook
[00:41:49.440 --> 00:41:51.640]   would say, no, you can't call a API.
[00:41:51.640 --> 00:41:52.640]   Stop it.
[00:41:52.640 --> 00:41:57.120]   And so, you know, eventually, and then it was like, okay, you say we're violent in terms
[00:41:57.120 --> 00:41:58.120]   of service.
[00:41:58.120 --> 00:41:59.440]   What could we change to not violate them?
[00:41:59.440 --> 00:42:00.760]   We're not telling you.
[00:42:00.760 --> 00:42:05.080]   So those kinds of sort of bad, bad, bad conversations have happened.
[00:42:05.080 --> 00:42:11.440]   And the way forward for me is to make this part of the open web, to make this stuff out
[00:42:11.440 --> 00:42:13.800]   there in public that people can make sense of.
[00:42:13.800 --> 00:42:17.240]   And that's the bit that's being lost in these battles.
[00:42:17.240 --> 00:42:20.760]   People are sort of cutting off access to each other's stuff.
[00:42:20.760 --> 00:42:24.920]   And that's the piece that Google is being more aggressive in those terms.
[00:42:24.920 --> 00:42:26.840]   And that's the piece that this--
[00:42:26.840 --> 00:42:30.320]   [INAUDIBLE]
[00:42:30.320 --> 00:42:34.040]   Has Google changed, Jeff Jarvis?
[00:42:34.040 --> 00:42:36.600]   I think Google has not learned grace.
[00:42:36.600 --> 00:42:38.440]   I think the problem is--
[00:42:38.440 --> 00:42:40.240]   Nerds are not graceful.
[00:42:40.240 --> 00:42:41.240]   Let's face it.
[00:42:41.240 --> 00:42:45.840]   And they're creating a new feature, which I think we would intellectually agree is the
[00:42:45.840 --> 00:42:49.560]   right direction for them and the right direction for the internet is headed.
[00:42:49.560 --> 00:42:53.200]   We've been saying this all year that they have to have social.
[00:42:53.200 --> 00:42:54.360]   But they're doing two things wrong.
[00:42:54.360 --> 00:42:56.560]   One, they're doing it clumsily.
[00:42:56.560 --> 00:42:59.040]   And I think that, you know, again, I'll defend the beta view.
[00:42:59.040 --> 00:43:00.520]   I can defend that part.
[00:43:00.520 --> 00:43:03.360]   But what I think they got to learn is--
[00:43:03.360 --> 00:43:05.880]   And I'm just a few months from this.
[00:43:05.880 --> 00:43:10.960]   They've got to learn how to be more graceful in terms of how they speak with the public.
[00:43:10.960 --> 00:43:12.600]   And they haven't learned that.
[00:43:12.600 --> 00:43:13.680]   Now, part of that--
[00:43:13.680 --> 00:43:17.560]   The bad part of that is if they become pure PR speak, I don't want them to become fake
[00:43:17.560 --> 00:43:18.560]   about it.
[00:43:18.560 --> 00:43:21.400]   But I want them to be more human and realize.
[00:43:21.400 --> 00:43:23.000]   Nikesh Rurur was at DLD.
[00:43:23.000 --> 00:43:24.160]   And he was very, very good.
[00:43:24.160 --> 00:43:24.920]   He killed with a line.
[00:43:24.920 --> 00:43:27.720]   I thought, oh, there's an Eric line where he said, well, you're not going to have a
[00:43:27.720 --> 00:43:30.280]   good experience on the web if you're anonymous.
[00:43:30.280 --> 00:43:30.960]   He said it worse.
[00:43:30.960 --> 00:43:32.640]   He said, you can't be--
[00:43:32.640 --> 00:43:34.120]   You're going to have to--
[00:43:34.120 --> 00:43:35.400]   Being anonymous on the web won't work.
[00:43:35.400 --> 00:43:36.760]   And I thought, oh boy, where does it go?
[00:43:36.760 --> 00:43:37.760]   But I knew what he was saying.
[00:43:37.760 --> 00:43:40.360]   He was saying, you're not going to have a less good experience.
[00:43:40.360 --> 00:43:45.320]   But they've got to think this through first and realize how they're seen and become graceful
[00:43:45.320 --> 00:43:46.320]   out of that.
[00:43:46.320 --> 00:43:47.320]   And they're not.
[00:43:47.320 --> 00:43:50.520]   So I think that the changes they're making are not evil.
[00:43:50.520 --> 00:43:54.600]   They're clumsy, but clumsy and potentially a very damaging way.
[00:43:54.600 --> 00:43:55.600]   Gina?
[00:43:55.600 --> 00:43:57.240]   Google has changed.
[00:43:57.240 --> 00:43:59.040]   It has not become more evil.
[00:43:59.040 --> 00:44:00.760]   It has become more focused.
[00:44:00.760 --> 00:44:06.040]   The problem is it has to work twice as hard to prove that focus does not equal evil.
[00:44:06.040 --> 00:44:11.320]   And like what Jeff just said, the clumsiness is an issue.
[00:44:11.320 --> 00:44:15.560]   So they need to take things like focus on the user and iterate based on them.
[00:44:15.560 --> 00:44:19.480]   They need to be open about that kind of feedback and show they need to respond to things like
[00:44:19.480 --> 00:44:23.360]   the Nimwors more quickly, which they did finally respond to that.
[00:44:23.360 --> 00:44:25.800]   Student names are allowed, and we'll talk about that in a bit.
[00:44:25.800 --> 00:44:29.320]   But they need to be more responsive and more iterative more quickly, and they need to be
[00:44:29.320 --> 00:44:34.560]   more elegant and better about communicating, just like what Jeff said, the less clumsy.
[00:44:34.560 --> 00:44:38.800]   So they're more focused, but they need to work harder to communicate that that doesn't
[00:44:38.800 --> 00:44:41.040]   mean necessarily more evil.
[00:44:41.040 --> 00:44:43.280]   Is there someone at Google besides Matt cuts?
[00:44:43.280 --> 00:44:44.880]   Should Larry just be Larry?
[00:44:44.880 --> 00:44:46.680]   Who should do this?
[00:44:46.680 --> 00:44:47.680]   Who's capable of doing this?
[00:44:47.680 --> 00:44:48.680]   That's a good question.
[00:44:48.680 --> 00:44:51.640]   Who's the Larry's better learn Larry better friggin learn.
[00:44:51.640 --> 00:44:53.640]   I think it's got to be Larry.
[00:44:53.640 --> 00:44:55.400]   His vision has to be on.
[00:44:55.400 --> 00:44:56.560]   I agree.
[00:44:56.560 --> 00:44:58.080]   And this focus is his obsession.
[00:44:58.080 --> 00:45:02.080]   I mean, this is, you know, you know, some people might say this is about him, you know,
[00:45:02.080 --> 00:45:03.080]   his meeting with jobs, right?
[00:45:03.080 --> 00:45:04.440]   I mean, this was Steve Jobs.
[00:45:04.440 --> 00:45:06.320]   It was to him was to become more focused.
[00:45:06.320 --> 00:45:09.160]   And the problem is that Steve Jobs never talked to the public.
[00:45:09.160 --> 00:45:11.320]   No, he wasn't very good at that.
[00:45:11.320 --> 00:45:13.000]   Although, well, he did those emails.
[00:45:13.000 --> 00:45:16.200]   And in some ways, those emails were a very clever PR strategy.
[00:45:16.200 --> 00:45:17.200]   But he was never great.
[00:45:17.200 --> 00:45:18.760]   God knows he was not graceful.
[00:45:18.760 --> 00:45:19.760]   No, right.
[00:45:19.760 --> 00:45:23.560]   Well, he was, but he was straightforward and honest.
[00:45:23.560 --> 00:45:29.680]   And I think he understood better than anyone, the value of good public relations.
[00:45:29.680 --> 00:45:30.680]   It didn't seem that way.
[00:45:30.680 --> 00:45:31.680]   I know sometimes.
[00:45:31.680 --> 00:45:35.000]   He actually knew he was pretty clever about me.
[00:45:35.000 --> 00:45:38.280]   He cared more about public relations about media relations.
[00:45:38.280 --> 00:45:39.280]   That's one way of putting it.
[00:45:39.280 --> 00:45:42.960]   Well, I disagree because he knew who to suck up to in the media to.
[00:45:42.960 --> 00:45:46.120]   Let me tell you, he knew very well who was powerful.
[00:45:46.120 --> 00:45:50.480]   And when Walt Bosberg, you know, comes to his house and spends three hours with him,
[00:45:50.480 --> 00:45:55.080]   that's not because he likes Walt so very, very much.
[00:45:55.080 --> 00:46:00.200]   By the way, Larry doesn't have that Larry's missing that.
[00:46:00.200 --> 00:46:04.160]   And you know, but it shows you don't have to be a nice, wonderful, friendly charismatic.
[00:46:04.160 --> 00:46:09.320]   Well, I guess he was charismatic, but you don't have to be a lovable person to do that.
[00:46:09.320 --> 00:46:10.960]   But you have to have some focus and vision.
[00:46:10.960 --> 00:46:15.000]   And unfortunately, I'm just pulling up this story on Fox News.
[00:46:15.000 --> 00:46:17.440]   This just crossed the wire.
[00:46:17.440 --> 00:46:18.440]   Be afraid.
[00:46:18.440 --> 00:46:20.680]   Google spying on you.
[00:46:20.680 --> 00:46:23.480]   New policy rolls out March 1st.
[00:46:23.480 --> 00:46:24.480]   Oh, God.
[00:46:24.480 --> 00:46:26.200]   F-E-N-U-S corp.
[00:46:26.200 --> 00:46:27.520]   And guess where it comes from?
[00:46:27.520 --> 00:46:29.240]   The Wall Street Journal.
[00:46:29.240 --> 00:46:31.240]   Oh, don't get me started.
[00:46:31.240 --> 00:46:33.240]   Well, you will get me started momentarily.
[00:46:33.240 --> 00:46:35.600]   Can we compare the Wall Street Journal's primacy policy?
[00:46:35.600 --> 00:46:38.760]   Because they insist you log in and track you with cookies.
[00:46:38.760 --> 00:46:40.760]   Yeah, this is not only that.
[00:46:40.760 --> 00:46:42.080]   They know your PII.
[00:46:42.080 --> 00:46:44.920]   They know your name and address and credit card number.
[00:46:44.920 --> 00:46:47.320]   They do not allow you to opt out.
[00:46:47.320 --> 00:46:50.160]   They require you to be cookie.
[00:46:50.160 --> 00:46:53.360]   They sell your data to third parties.
[00:46:53.360 --> 00:46:58.000]   They finally had to admit all that stuff after doing their what you they know, spooky,
[00:46:58.000 --> 00:46:59.800]   uh, series.
[00:46:59.800 --> 00:47:00.800]   Don't get me started.
[00:47:00.800 --> 00:47:02.240]   By the way, it's Julia Angwin again.
[00:47:02.240 --> 00:47:06.480]   Although I got to say the Wall Street Journal headline as opposed to the Fox News headline
[00:47:06.480 --> 00:47:08.240]   is much less sensational.
[00:47:08.240 --> 00:47:10.800]   It's merely Google widens its tracks.
[00:47:10.800 --> 00:47:14.600]   Privacy changes to combine data on users making an anonymity harder to keep.
[00:47:14.600 --> 00:47:19.840]   Much more judicious and accurate than the Fox News article, which links right back to
[00:47:19.840 --> 00:47:21.560]   the Wall Street Journal article.
[00:47:21.560 --> 00:47:24.520]   Be afraid.
[00:47:24.520 --> 00:47:26.520]   So this is, so I agree with you, Gina.
[00:47:26.520 --> 00:47:28.720]   This is a communications issue.
[00:47:28.720 --> 00:47:29.720]   Very much so.
[00:47:29.720 --> 00:47:31.880]   Matthew, we lost you for a little bit.
[00:47:31.880 --> 00:47:35.840]   I don't know if you heard how much of this conversation you heard, but the question is,
[00:47:35.840 --> 00:47:37.720]   has Google changed?
[00:47:37.720 --> 00:47:41.560]   Is this a different Google and what do they need to do?
[00:47:41.560 --> 00:47:42.640]   I think it has changed.
[00:47:42.640 --> 00:47:45.480]   I don't, you know, I'm not going to say they've become evil and so on.
[00:47:45.480 --> 00:47:50.520]   I think I'm sure they wish that phrase had never entered the lexicon.
[00:47:50.520 --> 00:47:51.520]   Yeah.
[00:47:51.520 --> 00:47:56.480]   They've gotten evil or not, I don't want to say, but I do think if you look at what Google
[00:47:56.480 --> 00:48:00.960]   promised when it went public, it was going to provide objective results.
[00:48:00.960 --> 00:48:06.280]   It was not going to influence those results based on who paid money or whatever.
[00:48:06.280 --> 00:48:11.120]   But now it sure looks like Google is influencing those results based on what it wants to do,
[00:48:11.120 --> 00:48:12.960]   which is to promote its own network.
[00:48:12.960 --> 00:48:19.680]   And I think that fundamentally changes the nature of what Google is selling or pitching.
[00:48:19.680 --> 00:48:22.520]   And so that's, you know, to me, that's a risk.
[00:48:22.520 --> 00:48:28.200]   And I think, as Kevin was saying, the biggest risk is that it's just going to change the
[00:48:28.200 --> 00:48:33.680]   sort of openness and we came to rely on Google for that.
[00:48:33.680 --> 00:48:38.560]   So now if it's just going to do what everybody else does and sort of pimp its own stuff,
[00:48:38.560 --> 00:48:40.440]   that's going to change things fundamentally.
[00:48:40.440 --> 00:48:41.760]   And that's a problem.
[00:48:41.760 --> 00:48:45.000]   Although you've got to feel for Google a little bit because that is a subtle and I think
[00:48:45.000 --> 00:48:51.520]   you're exactly right, distinction between the old and the new, but Fox is not going to
[00:48:51.520 --> 00:48:52.520]   make that distinction.
[00:48:52.520 --> 00:48:54.560]   And Google did not handle it well.
[00:48:54.560 --> 00:48:57.880]   And Google has to consider real people, not us.
[00:48:57.880 --> 00:49:01.320]   They have to consider, you know, we can understand the nuance.
[00:49:01.320 --> 00:49:04.160]   We could say, they're hurting their search results.
[00:49:04.160 --> 00:49:07.880]   That's not what the guy on the street is thinking about.
[00:49:07.880 --> 00:49:11.560]   They're thinking about, is Google following me everywhere I go?
[00:49:11.560 --> 00:49:13.400]   And what are they doing with what they know?
[00:49:13.400 --> 00:49:16.240]   Right, especially given the stuff that's going on with the FTC.
[00:49:16.240 --> 00:49:20.920]   And again, I keep on presaging this, but here in Europe, they've got to be hypersensitive
[00:49:20.920 --> 00:49:22.360]   and this was not hypersensitive.
[00:49:22.360 --> 00:49:25.880]   I'm tempted just to say, hey, Google, I'll do it for you.
[00:49:25.880 --> 00:49:27.880]   Give me, you know, I'll take a month leave.
[00:49:27.880 --> 00:49:28.880]   Let me just go.
[00:49:28.880 --> 00:49:30.080]   I can explain it to people really.
[00:49:30.080 --> 00:49:34.320]   It's just, yeah, because it's just they don't, they are not communicating, I think, well,
[00:49:34.320 --> 00:49:35.320]   at all.
[00:49:35.320 --> 00:49:36.320]   Let's take the story.
[00:49:36.320 --> 00:49:37.880]   The story really should have been they clarified their language.
[00:49:37.880 --> 00:49:38.880]   Yes.
[00:49:38.880 --> 00:49:39.880]   Made a change.
[00:49:39.880 --> 00:49:41.680]   This was less about a change and more about clarifying their language.
[00:49:41.680 --> 00:49:44.720]   It's a good unified privacy policy.
[00:49:44.720 --> 00:49:45.720]   This is good.
[00:49:45.720 --> 00:49:46.720]   This is clarity.
[00:49:46.720 --> 00:49:48.880]   This is what we always want Facebook to do.
[00:49:48.880 --> 00:49:53.920]   This is not, oh, we're trying to hide something or, oh, we're not going to let you opt out
[00:49:53.920 --> 00:49:54.920]   anymore.
[00:49:54.920 --> 00:49:57.120]   There isn't a change in the way they deal with your data.
[00:49:57.120 --> 00:49:58.120]   Right.
[00:49:58.120 --> 00:49:59.120]   Right.
[00:49:59.120 --> 00:50:00.120]   They're just letting you know now, clearly.
[00:50:00.120 --> 00:50:01.120]   Yeah.
[00:50:01.120 --> 00:50:02.120]   There could be a change.
[00:50:02.120 --> 00:50:03.120]   We don't know.
[00:50:03.120 --> 00:50:04.640]   Well, I'm looking.
[00:50:04.640 --> 00:50:08.080]   We kind of know because they've now published it.
[00:50:08.080 --> 00:50:10.880]   So we, I mean, it doesn't look like it's a change.
[00:50:10.880 --> 00:50:11.880]   But how are they going to share it?
[00:50:11.880 --> 00:50:12.880]   Are they going to share more?
[00:50:12.880 --> 00:50:14.880]   They're going to share more between everything.
[00:50:14.880 --> 00:50:17.280]   No, it's exactly the same.
[00:50:17.280 --> 00:50:18.360]   No, same.
[00:50:18.360 --> 00:50:20.200]   They're just unifying it.
[00:50:20.200 --> 00:50:21.880]   They're doing exactly what they've said they've done.
[00:50:21.880 --> 00:50:22.880]   They haven't changed anything.
[00:50:22.880 --> 00:50:24.520]   Let's go to a break.
[00:50:24.520 --> 00:50:25.520]   Yeah.
[00:50:25.520 --> 00:50:29.920]   And but that's the problem is that that does not generate page views to say that.
[00:50:29.920 --> 00:50:32.520]   What generates page views is be afraid.
[00:50:32.520 --> 00:50:33.520]   Yeah.
[00:50:33.520 --> 00:50:36.040]   I'm going to make you afraid in a minute.
[00:50:36.040 --> 00:50:37.040]   We come back for a break.
[00:50:37.040 --> 00:50:39.200]   I want to make you very afraid.
[00:50:39.200 --> 00:50:41.600]   Film at 11.
[00:50:41.600 --> 00:50:45.000]   Are people rampaging in the streets about to kill you?
[00:50:45.000 --> 00:50:46.000]   Film at 11.
[00:50:46.000 --> 00:50:47.080]   Stay tuned.
[00:50:47.080 --> 00:50:50.240]   But first, by the way, the answer no, but first.
[00:50:50.240 --> 00:50:53.720]   Oh, we're from Ford.
[00:50:53.720 --> 00:50:56.720]   You know, that's what I love about engineers.
[00:50:56.720 --> 00:50:58.760]   And so I love about doing a technology network.
[00:50:58.760 --> 00:51:04.080]   And it's so different from mainstream media is we assume the intelligence of our audience.
[00:51:04.080 --> 00:51:07.280]   And like engineers, things are tend to be black and white.
[00:51:07.280 --> 00:51:10.280]   So we're so we're looking for truth.
[00:51:10.280 --> 00:51:13.480]   And maybe things are nuanced in all sorts of interesting ways.
[00:51:13.480 --> 00:51:16.680]   But ultimately, I think engineers always say, well, it works or it doesn't work.
[00:51:16.680 --> 00:51:18.160]   It is or it isn't.
[00:51:18.160 --> 00:51:24.360]   And that's why I love working in this field because it isn't so.
[00:51:24.360 --> 00:51:29.240]   It's not like nailing jello to a tree, despite what they say.
[00:51:29.240 --> 00:51:31.320]   We're going to talk a little bit about Ford right now.
[00:51:31.320 --> 00:51:37.240]   And I have to say, I love talking about Ford because this is an example of a company
[00:51:37.240 --> 00:51:42.240]   that I love when we went to Detroit last was it last year or two years ago.
[00:51:42.240 --> 00:51:46.360]   And we went there was a last year we went out on the assembly line of their of their
[00:51:46.360 --> 00:51:52.440]   original plant, the one that Henry Ford built in the 20s because he knew there was Henry
[00:51:52.440 --> 00:51:59.520]   Ford's goal was at the time when he started Ford, only very rich people could drive.
[00:51:59.520 --> 00:52:03.400]   And his goal was to make a car that everyone in the United, he said, I want to put everyone
[00:52:03.400 --> 00:52:04.400]   in the United States on the road.
[00:52:04.400 --> 00:52:05.400]   I want to make a car anyone can drive.
[00:52:05.400 --> 00:52:08.080]   I want to make it accessible to all.
[00:52:08.080 --> 00:52:14.040]   And to that end, he built this plant that took, you know, box cars of lumber and iron
[00:52:14.040 --> 00:52:19.920]   or coke and one end and cars came out the other end.
[00:52:19.920 --> 00:52:23.560]   It's amazing, massive plant.
[00:52:23.560 --> 00:52:24.560]   And it's still there.
[00:52:24.560 --> 00:52:25.560]   It's still operating.
[00:52:25.560 --> 00:52:26.560]   It's green.
[00:52:26.560 --> 00:52:32.400]   Now they've got a greenery on the roof that captures CO2 and generates oxygen.
[00:52:32.400 --> 00:52:34.120]   They've got light everywhere.
[00:52:34.120 --> 00:52:37.640]   You know, I went down on the actually rode the assembly line, which is a treat.
[00:52:37.640 --> 00:52:41.440]   It's not quite going to the West Wing, but it was close.
[00:52:41.440 --> 00:52:45.480]   And to talk to the workers and their experiences changed so much.
[00:52:45.480 --> 00:52:46.960]   This is a modern company.
[00:52:46.960 --> 00:52:51.240]   And I just love how they've gone into the 21st century with that vision, though, of,
[00:52:51.240 --> 00:52:57.080]   you know, this is this is the original technology of industrial era technology turning into information
[00:52:57.080 --> 00:52:58.240]   era technology.
[00:52:58.240 --> 00:53:01.400]   And by and to do that, of course, they're wiring the cabin.
[00:53:01.400 --> 00:53:04.760]   Now they have a challenge, which is distracted driving.
[00:53:04.760 --> 00:53:05.760]   They don't.
[00:53:05.760 --> 00:53:08.920]   And I think a lot of car companies are not paying much attention.
[00:53:08.920 --> 00:53:14.600]   I won't say the name big luxury car company on CES's show floor showed how you could
[00:53:14.600 --> 00:53:20.360]   update your status on Facebook in their car as you're driving by looking down at the screen,
[00:53:20.360 --> 00:53:23.840]   turning a knob to the right status and pressing go.
[00:53:23.840 --> 00:53:27.480]   And it's like, no, don't please don't do no.
[00:53:27.480 --> 00:53:33.040]   I don't want to be dodging Mercedes in the street coming in the next few years.
[00:53:33.040 --> 00:53:37.320]   Ford's idea is, look, we understand consumers want technology in their car.
[00:53:37.320 --> 00:53:38.480]   How do we incorporate it?
[00:53:38.480 --> 00:53:40.000]   How we solve this problem?
[00:53:40.000 --> 00:53:44.280]   And after a lot of research, they said, and Alan Malawi told me this is if you keep your
[00:53:44.280 --> 00:53:47.800]   hands on the wheel and the eyes on the road, if you're focused on what you're doing and
[00:53:47.800 --> 00:53:52.080]   you're not like looking down and you're not twiddling knobs, you have enough cocks, humans
[00:53:52.080 --> 00:53:57.920]   have enough cognitive free space to also make a have a phone conversation or to listen to
[00:53:57.920 --> 00:54:00.680]   stuff or to direct with the car using voice.
[00:54:00.680 --> 00:54:03.120]   So that's why they focused on this voice technologies.
[00:54:03.120 --> 00:54:07.120]   And that's where sync comes from and now sync in my Ford touch.
[00:54:07.120 --> 00:54:10.960]   And he told me this last year, the car's iterate.
[00:54:10.960 --> 00:54:15.800]   They've got the car iteration down about three years, which is amazing from the conception
[00:54:15.800 --> 00:54:17.360]   to shipping.
[00:54:17.360 --> 00:54:20.960]   But it's still, of course, much slower than your Android phone, which seems to update
[00:54:20.960 --> 00:54:22.600]   every three weeks.
[00:54:22.600 --> 00:54:27.760]   So what they've decided to do is they created an API for sync that allows app developers
[00:54:27.760 --> 00:54:29.040]   to interface with the car.
[00:54:29.040 --> 00:54:33.200]   So now you can talk to your smartphone and into the apps on the smartphone.
[00:54:33.200 --> 00:54:37.000]   So the iteration happens in the phone and you have that full access.
[00:54:37.000 --> 00:54:38.600]   So they started with Pandora.
[00:54:38.600 --> 00:54:42.040]   You can literally press a button in your steering wheel, your drive and your paying attention
[00:54:42.040 --> 00:54:43.040]   what you're doing.
[00:54:43.040 --> 00:54:44.600]   And you say, play my classic rock station.
[00:54:44.600 --> 00:54:49.560]   It plays, by the way, this has to terrify radio broadcast radios just going, huh?
[00:54:49.560 --> 00:54:51.040]   You've got Stitcher now and Slacker.
[00:54:51.040 --> 00:54:52.200]   So you can actually listen to this show.
[00:54:52.200 --> 00:54:54.000]   You don't even have to download it ahead of time.
[00:54:54.000 --> 00:54:57.040]   Just say, play, play Twig and it'll play.
[00:54:57.040 --> 00:54:58.960]   You can thumbs up and thumbs down songs.
[00:54:58.960 --> 00:55:02.160]   You can do all the things you could do with Pandora with your voice.
[00:55:02.160 --> 00:55:03.760]   You can get horoscopes, maps.
[00:55:03.760 --> 00:55:05.280]   You can call people.
[00:55:05.280 --> 00:55:07.320]   You can play music.
[00:55:07.320 --> 00:55:09.640]   You're connected, but you're not distracted.
[00:55:09.640 --> 00:55:11.960]   And I think that's really the key to all of this.
[00:55:11.960 --> 00:55:15.220]   You can find out more at Ford.com/technology@ceas.
[00:55:15.220 --> 00:55:19.080]   They announced five or six new apps that use this app link API.
[00:55:19.080 --> 00:55:21.680]   There's many more to come.
[00:55:21.680 --> 00:55:23.480]   Ford.com/technology.
[00:55:23.480 --> 00:55:26.560]   And of course, try it today.
[00:55:26.560 --> 00:55:31.920]   The app link is available in the 2012 Ford Fiesta, which you can test drive at a Ford
[00:55:31.920 --> 00:55:32.920]   dealer near you.
[00:55:32.920 --> 00:55:34.920]   It's actually going to be in all the cars, of course.
[00:55:34.920 --> 00:55:39.400]   Ford.com/technology or drive of Fiesta at a Ford dealer near you.
[00:55:39.400 --> 00:55:40.640]   Thank them for their support.
[00:55:40.640 --> 00:55:43.880]   I love that story.
[00:55:43.880 --> 00:55:47.280]   It's just such an interesting thing to watch.
[00:55:47.280 --> 00:55:49.880]   You will look at Kodak, which filed chapter 11.
[00:55:49.880 --> 00:55:51.880]   It's so hard to pivot.
[00:55:51.880 --> 00:55:55.800]   And to watch this industrial era company go into the 21st century and watch.
[00:55:55.800 --> 00:55:57.760]   And we know what it is.
[00:55:57.760 --> 00:55:59.160]   It's intelligent people.
[00:55:59.160 --> 00:56:03.640]   It's, you know, Allen's an engineer from Lockheed, or not Lockheed Boeing.
[00:56:03.640 --> 00:56:08.360]   He says, I was involved in every Boeing cockpit for the last 20 years.
[00:56:08.360 --> 00:56:09.360]   He knows all about this.
[00:56:09.360 --> 00:56:10.360]   And he's a brilliant engineer.
[00:56:10.360 --> 00:56:12.720]   And he engineered the future.
[00:56:12.720 --> 00:56:13.720]   Very smart.
[00:56:13.720 --> 00:56:14.720]   Let's see.
[00:56:14.720 --> 00:56:15.720]   Let's see.
[00:56:15.720 --> 00:56:17.920]   Let's talk about, yes, go ahead.
[00:56:17.920 --> 00:56:18.920]   Are you losing my battery?
[00:56:18.920 --> 00:56:20.760]   I jack a show is before I better goes out.
[00:56:20.760 --> 00:56:21.760]   Yes.
[00:56:21.760 --> 00:56:22.760]   And do end of the European soap.
[00:56:22.760 --> 00:56:24.840]   I think it's going to be boring, but I think it's important.
[00:56:24.840 --> 00:56:25.840]   No, no, no, no.
[00:56:25.840 --> 00:56:26.840]   It's a huge topic.
[00:56:26.840 --> 00:56:27.840]   So, ACTA.
[00:56:27.840 --> 00:56:28.840]   Here's the deal.
[00:56:28.840 --> 00:56:30.760]   Oh, no, not ACTA this time.
[00:56:30.760 --> 00:56:34.000]   This is today Vivian Redding, who's the vice president of the European Commission, came
[00:56:34.000 --> 00:56:39.360]   out with a whole new list of privacy regulations and laws that she plans to implement.
[00:56:39.360 --> 00:56:40.360]   And she has four pillars.
[00:56:40.360 --> 00:56:41.960]   I'm going to go through this real quickly.
[00:56:41.960 --> 00:56:44.000]   But here's, there's a lot of dangers.
[00:56:44.000 --> 00:56:46.800]   Bill Reiger with his transparency and portability of data.
[00:56:46.800 --> 00:56:47.800]   Yay, yay, yay, yay.
[00:56:47.800 --> 00:56:49.280]   Two is privacy by default.
[00:56:49.280 --> 00:56:54.800]   Well, if you make privacy the default by law of services, we'd never have a flicker.
[00:56:54.800 --> 00:57:01.000]   Three is that your data must be held by European standards, the world around or else you can
[00:57:01.000 --> 00:57:07.560]   find a service up to 2% of their worldwide global take home.
[00:57:07.560 --> 00:57:11.640]   And so what that means is Europe just is trying to take over the friggin' internet.
[00:57:11.640 --> 00:57:15.400]   It also means we end up with a high watermark of regulation and a low watermark of freedom.
[00:57:15.400 --> 00:57:18.560]   And if we grant that power to EU, we'll grant it to China.
[00:57:18.560 --> 00:57:24.120]   Fourth pillar is the right to be forgotten, which again sounds cool, but it says that
[00:57:24.120 --> 00:57:31.440]   you have the right to demand that any personal information about you would be deleted.
[00:57:31.440 --> 00:57:35.880]   And she has to carve out history and carve out journalism, which acknowledges the impact
[00:57:35.880 --> 00:57:37.320]   on freedom of speech.
[00:57:37.320 --> 00:57:39.880]   But she's defined personal information.
[00:57:39.880 --> 00:57:46.200]   Is there anything about you including your private, public, and business and public life,
[00:57:46.200 --> 00:57:47.960]   including an IP address?
[00:57:47.960 --> 00:57:52.400]   So that means that people can go back and years later come to ULEO if you cookie and
[00:57:52.400 --> 00:57:57.360]   demand that you have to get rid of their IP address, not even knowing who that person
[00:57:57.360 --> 00:58:02.320]   is and photos and posts about you in the public.
[00:58:02.320 --> 00:58:04.280]   This is extremely dangerous.
[00:58:04.280 --> 00:58:09.840]   It is a huge grab to regulate the internet, the whole internet from Europe across 26 years
[00:58:09.840 --> 00:58:10.840]   to 27 countries.
[00:58:10.840 --> 00:58:12.240]   It is truly dangerous.
[00:58:12.240 --> 00:58:17.520]   If we got our dander up and we got our action together about SOPA, this is, as Henry Blodgett
[00:58:17.520 --> 00:58:21.640]   said in the night, in the snow of Davos, this is SOPA squared.
[00:58:21.640 --> 00:58:23.760]   This is a big deal.
[00:58:23.760 --> 00:58:25.280]   And we've got to get mad about this.
[00:58:25.280 --> 00:58:28.440]   We've got to get scared about this because it doesn't just affect Europe.
[00:58:28.440 --> 00:58:30.280]   Europe will affect all of us.
[00:58:30.280 --> 00:58:34.760]   That's the end of my spiel here, but I'm telling you folks, watch out for this news.
[00:58:34.760 --> 00:58:35.760]   It's dangerous stuff.
[00:58:35.760 --> 00:58:39.800]   And it's going to affect media too, lost in media because it's going to demand that
[00:58:39.800 --> 00:58:45.120]   you have to give the right to opt in even to cooking, which means you wouldn't be able
[00:58:45.120 --> 00:58:49.320]   to use the New York Times or Leo, when your people comes to your site from Europe, you're
[00:58:49.320 --> 00:58:51.040]   going to have to say, I'm just going to block it.
[00:58:51.040 --> 00:58:52.040]   I'm just going to cook you.
[00:58:52.040 --> 00:58:53.040]   Right.
[00:58:53.040 --> 00:58:55.080]   But most companies are going to do that.
[00:58:55.080 --> 00:58:56.600]   And so that's where we end up.
[00:58:56.600 --> 00:58:57.800]   It's extremely dangerous.
[00:58:57.800 --> 00:59:00.240]   It's a move of a government trying to regulate the internet.
[00:59:00.240 --> 00:59:04.800]   It's just as dangerous as Sarkozy does it, or if the American Congress does it with SOPA,
[00:59:04.800 --> 00:59:06.320]   or if China does it.
[00:59:06.320 --> 00:59:10.960]   And we, the internet, have to fight to keep our tool of publicness free.
[00:59:10.960 --> 00:59:11.960]   Thank you.
[00:59:11.960 --> 00:59:12.960]   And so far.
[00:59:12.960 --> 00:59:17.720]   This is a proposal for Directive 9546, which does this have to be?
[00:59:17.720 --> 00:59:18.720]   How does this get approved?
[00:59:18.720 --> 00:59:20.920]   Is this approved by the European Commission?
[00:59:20.920 --> 00:59:23.320]   It goes through your period of commission.
[00:59:23.320 --> 00:59:25.120]   Is it going to all 27 countries?
[00:59:25.120 --> 00:59:29.240]   It goes in some measure of some parts that have to be passed by the 27 countries.
[00:59:29.240 --> 00:59:30.240]   They'll have two years.
[00:59:30.240 --> 00:59:34.120]   Once it's passed by the EU, then the EU dictates the 27 countries must do this.
[00:59:34.120 --> 00:59:36.160]   They'll have two years to implement it.
[00:59:36.160 --> 00:59:39.360]   And we're going through this right now with cookie directors as we stand today.
[00:59:39.360 --> 00:59:44.880]   So the question, rightly so, in the chat is, well, but this protects me as an individual.
[00:59:44.880 --> 00:59:47.080]   How does this hurt me as an individual?
[00:59:47.080 --> 00:59:48.080]   Doesn't this protect me?
[00:59:48.080 --> 00:59:49.880]   No, but from what?
[00:59:49.880 --> 00:59:52.200]   That's the first question of what's the real harm here?
[00:59:52.200 --> 00:59:53.520]   Yeah, I'll give you an example.
[00:59:53.520 --> 00:59:54.520]   So you watched it.
[00:59:54.520 --> 00:59:56.880]   I'm not interested in any personal information about you.
[00:59:56.880 --> 00:59:59.840]   But as with all web servers, we have a log.
[00:59:59.840 --> 01:00:01.640]   And the log has who watched when.
[01:00:01.640 --> 01:00:07.000]   And we actually do use that to count how many viewers so we can charge our advertisers.
[01:00:07.000 --> 01:00:10.000]   That would, that log now.
[01:00:10.000 --> 01:00:11.000]   So you did it.
[01:00:11.000 --> 01:00:14.200]   So the same thing, the same argument would be that American Express should delete all
[01:00:14.200 --> 01:00:17.600]   of your financial records after six months because it says what you did.
[01:00:17.600 --> 01:00:21.000]   The library should delete all the records of after a certain time that you should be
[01:00:21.000 --> 01:00:22.880]   able to erase yourself from the whole net.
[01:00:22.880 --> 01:00:27.960]   And this applies to anybody, including us, processing data of any EU citizen.
[01:00:27.960 --> 01:00:28.960]   Exactly.
[01:00:28.960 --> 01:00:31.480]   And you can ask anywhere you're responsible for doing this.
[01:00:31.480 --> 01:00:32.640]   And what are the penalties?
[01:00:32.640 --> 01:00:35.840]   Let's say Twitch says, yeah, go ahead, European Union.
[01:00:35.840 --> 01:00:40.520]   The penalties go up to 2% of your entire, not just EU, but you're in higher.
[01:00:40.520 --> 01:00:42.240]   How are they going to get that?
[01:00:42.240 --> 01:00:47.040]   Well, because if you, well, you perhaps not, but, but obviously there's a lot of international
[01:00:47.040 --> 01:00:48.040]   companies.
[01:00:48.040 --> 01:00:49.040]   Right.
[01:00:49.040 --> 01:00:51.040]   And so, and you believe instance would be vulnerable.
[01:00:51.040 --> 01:00:54.240]   Well, you bet that because Google's always been some money's in Ireland.
[01:00:54.240 --> 01:00:55.240]   Right.
[01:00:55.240 --> 01:00:56.240]   Right.
[01:00:56.240 --> 01:00:57.240]   Yeah.
[01:00:57.240 --> 01:00:58.960]   So, you're a data protection officer.
[01:00:58.960 --> 01:00:59.960]   Oh, yeah.
[01:00:59.960 --> 01:01:05.600]   If you have 250 employees, you have to add a full-time staff for data protection.
[01:01:05.600 --> 01:01:10.680]   Now, you know, the advantage she argues is there are now 27 different regulations in
[01:01:10.680 --> 01:01:12.200]   27 countries in Europe.
[01:01:12.200 --> 01:01:13.200]   And so, let's put it together.
[01:01:13.200 --> 01:01:16.640]   But this is also, you know, it's kind of the one-world government of the Internet comes
[01:01:16.640 --> 01:01:17.640]   along.
[01:01:17.640 --> 01:01:18.640]   So, who does that?
[01:01:18.640 --> 01:01:19.640]   Is it the US?
[01:01:19.640 --> 01:01:20.640]   Is it China?
[01:01:20.640 --> 01:01:21.640]   Is it Sarkozy?
[01:01:21.640 --> 01:01:22.640]   Is it Reading?
[01:01:22.640 --> 01:01:24.040]   Is it Germany?
[01:01:24.040 --> 01:01:27.200]   This is what's happening, my friends, is that, and I see this in Davos right now.
[01:01:27.200 --> 01:01:29.480]   Davos is scared shitless.
[01:01:29.480 --> 01:01:34.560]   The institutions that are here of us who, through soap bro, through occupied Davos and
[01:01:34.560 --> 01:01:38.280]   occupied Wall Street and the Arab Spring and the ended dottos of Spain.
[01:01:38.280 --> 01:01:39.920]   These are all movements that scare them.
[01:01:39.920 --> 01:01:44.120]   So you're really at the one, this is a meeting of the 1% is that what the WEF is?
[01:01:44.120 --> 01:01:45.720]   Oh, the point, the point one.
[01:01:45.720 --> 01:01:46.720]   Yeah.
[01:01:46.720 --> 01:01:48.520]   It's the people who are in charge of the 1%.
[01:01:48.520 --> 01:01:49.520]   Oh, wow.
[01:01:49.520 --> 01:01:50.520]   Okay.
[01:01:50.520 --> 01:01:52.120]   So, they're threatened by all of this.
[01:01:52.120 --> 01:01:54.960]   Very threatened, very threatened and fluid denial.
[01:01:54.960 --> 01:01:58.600]   And this is about a fight about disruption of institutions.
[01:01:58.600 --> 01:01:59.600]   And what?
[01:01:59.600 --> 01:02:04.320]   So, how, actually, I'm very curious, how where are they of what's going on?
[01:02:04.320 --> 01:02:09.080]   And how real is, I mean, I clearly Rupert Murdoch's grasp of what's going on is hazy
[01:02:09.080 --> 01:02:10.240]   at best.
[01:02:10.240 --> 01:02:14.280]   These guys at WEF, these guys, you're hanging in Davos, do they get it?
[01:02:14.280 --> 01:02:15.520]   Do they know what's going on?
[01:02:15.520 --> 01:02:21.240]   No, what they got was that soap, the reaction to soap was scary, that it was people rising
[01:02:21.240 --> 01:02:22.240]   up.
[01:02:22.240 --> 01:02:24.080]   What they get is that I won't street a few.
[01:02:24.080 --> 01:02:27.400]   If you're in the 1%, you don't want to hear from the 99.
[01:02:27.400 --> 01:02:28.400]   No, no.
[01:02:28.400 --> 01:02:30.680]   Just do your job and stay cool.
[01:02:30.680 --> 01:02:34.560]   If you're ready, you know, said, we'll never have a blocking bill out of Europe.
[01:02:34.560 --> 01:02:35.560]   Well, yeah, not now.
[01:02:35.560 --> 01:02:37.600]   You're not going to.
[01:02:37.600 --> 01:02:38.600]   So they're aware of that.
[01:02:38.600 --> 01:02:41.560]   I was at a time debate on the future of capitalism.
[01:02:41.560 --> 01:02:44.280]   It's kind of absurd topics this morning.
[01:02:44.280 --> 01:02:52.320]   And there was a corporation and an equity firm and labor unions and bankers and universities.
[01:02:52.320 --> 01:02:55.760]   And I just got fed up at one point and I said, none of you are succeeding responsibility
[01:02:55.760 --> 01:02:57.160]   for the mess we're in.
[01:02:57.160 --> 01:02:58.160]   You are the disrupted.
[01:02:58.160 --> 01:02:59.960]   I want to hear from the disruptors.
[01:02:59.960 --> 01:03:02.720]   And they're here too, some of them, but not many.
[01:03:02.720 --> 01:03:04.400]   This is the disrupted.
[01:03:04.400 --> 01:03:09.840]   And what I'm trying to say is that what we're really seeing at a high level is that the
[01:03:09.840 --> 01:03:11.760]   Internet threatens institutions.
[01:03:11.760 --> 01:03:15.440]   And so the institutions are now fighting back to use the power they have to regulate the
[01:03:15.440 --> 01:03:19.200]   Internet and we've got to keep fighting.
[01:03:19.200 --> 01:03:22.280]   Kevin Marks, you have a funny accent.
[01:03:22.280 --> 01:03:26.320]   These are your people.
[01:03:26.320 --> 01:03:33.960]   Actually Britain is kind of only a reluctant participant in the EU.
[01:03:33.960 --> 01:03:37.440]   Chate Chateram is saying that Jeff is biased against Europeans and doesn't understand how
[01:03:37.440 --> 01:03:38.440]   it works.
[01:03:38.440 --> 01:03:41.640]   Oh, I, Jeff's muted the right read the red.
[01:03:41.640 --> 01:03:43.600]   Yeah, read them and I'll put a link in the show.
[01:03:43.600 --> 01:03:44.600]   But Jeff's muted.
[01:03:44.600 --> 01:03:47.840]   I mean, Kevin, Kevin, you're muted.
[01:03:47.840 --> 01:03:49.400]   We can't hear a word you're saying.
[01:03:49.400 --> 01:03:51.160]   Maybe it's that funny accent.
[01:03:51.160 --> 01:03:52.160]   There it is.
[01:03:52.160 --> 01:03:53.160]   There we go.
[01:03:53.160 --> 01:03:54.160]   There we go.
[01:03:54.160 --> 01:03:55.160]   So another fire engine went past.
[01:03:55.160 --> 01:03:56.160]   So I told you myself.
[01:03:56.160 --> 01:03:57.160]   Thank you for doing that.
[01:03:57.160 --> 01:03:58.160]   We could do that here too.
[01:03:58.160 --> 01:03:59.160]   Okay.
[01:03:59.160 --> 01:04:02.800]   So what about, I think Jeff is overstating this, to some extent, some of the European
[01:04:02.800 --> 01:04:04.840]   data protection stuff is useful.
[01:04:04.840 --> 01:04:09.240]   The stuff that they have in the UK says that you can demand information from a company
[01:04:09.240 --> 01:04:12.840]   that they're holding on you and they have to send it to you.
[01:04:12.840 --> 01:04:13.840]   That's a useful right.
[01:04:13.840 --> 01:04:15.840]   And I'm sure that transparency for it.
[01:04:15.840 --> 01:04:16.840]   Right.
[01:04:16.840 --> 01:04:19.320]   There are chunks of this to make sense.
[01:04:19.320 --> 01:04:22.800]   There are also ways when they're trying to extend these that don't make sense.
[01:04:22.800 --> 01:04:24.760]   And I think this is the first part of this.
[01:04:24.760 --> 01:04:27.520]   And yes, we need to engage with it and make sure that it starts making sense.
[01:04:27.520 --> 01:04:29.120]   That's very true.
[01:04:29.120 --> 01:04:34.880]   And the similarity with SOPA is that these proposals tend to get written by one side
[01:04:34.880 --> 01:04:39.000]   of the argument, as you say, by these sort of professional privacy lobbyists.
[01:04:39.000 --> 01:04:42.480]   And then we need to look at them and say, well, do you understand the implications of
[01:04:42.480 --> 01:04:44.200]   what you're saying and fix them?
[01:04:44.200 --> 01:04:46.840]   And with SOPA stuff, there wasn't much to actually fix there.
[01:04:46.840 --> 01:04:49.080]   I think with these, there probably is some useful stuff there.
[01:04:49.080 --> 01:04:53.480]   I'm fairly sure that my colleagues at the Open Rights Group and the others who are involved
[01:04:53.480 --> 01:04:57.400]   in the policy stuff in Europe will be paying close actually as I'm saying, this bit is
[01:04:57.400 --> 01:04:59.040]   a good, these bits are bad.
[01:04:59.040 --> 01:05:06.440]   There was a great article in Computer World by Alex Muppet, which I've got a link to somewhere,
[01:05:06.440 --> 01:05:12.960]   talking about, I think you'll like, Jeff, talking about the problems of trying to regulate
[01:05:12.960 --> 01:05:13.960]   this stuff.
[01:05:13.960 --> 01:05:23.760]   You need to be careful not to tell people how to do things, but you need to give them frameworks
[01:05:23.760 --> 01:05:25.160]   to say what you want to achieve.
[01:05:25.160 --> 01:05:26.960]   And that's the difference with right.
[01:05:26.960 --> 01:05:28.960]   Well, Kevin, you're right.
[01:05:28.960 --> 01:05:31.200]   It's nice to regulate the behavior, not the technology.
[01:05:31.200 --> 01:05:34.560]   What's happening here is that whether there's child porn or whatever this stuff, we see
[01:05:34.560 --> 01:05:38.520]   the government trying to regulate the technology, because the technology, the fuddles and frightens
[01:05:38.520 --> 01:05:39.520]   them.
[01:05:39.520 --> 01:05:45.160]   We already have the laws to regulate the legal behavior, witness the taking down of mega
[01:05:45.160 --> 01:05:46.160]   upload.
[01:05:46.160 --> 01:05:47.720]   They didn't make something.
[01:05:47.720 --> 01:05:51.520]   But mega upload, this is an interesting story because mega upload servers were in the US,
[01:05:51.520 --> 01:05:54.240]   so they could take them down and everything about SOPA.
[01:05:54.240 --> 01:05:57.240]   But they've been addressed for international service.
[01:05:57.240 --> 01:06:00.640]   Yeah, but they were able to arrest the guys.
[01:06:00.640 --> 01:06:07.440]   But if the servers had been in China, they wouldn't have been able to do anything.
[01:06:07.440 --> 01:06:11.080]   So I mean, I'm not, believe me, I'm not an apologist for SOPA.
[01:06:11.080 --> 01:06:13.600]   But I have to, I don't think this is irrelevant.
[01:06:13.600 --> 01:06:16.520]   Mega upload is not a relevant issue.
[01:06:16.520 --> 01:06:21.680]   Well, Vivian Reddyin said was nothing new when she spoke of DLD this week, but I was
[01:06:21.680 --> 01:06:25.520]   with executives of a certain very large technology company and a certain part of the advertising
[01:06:25.520 --> 01:06:28.920]   industry who were scared to death.
[01:06:28.920 --> 01:06:31.280]   Well, it scares me.
[01:06:31.280 --> 01:06:33.360]   I don't know if I should be scared.
[01:06:33.360 --> 01:06:39.760]   I know in England anyway, Kevin, it's been a very active and effective, as you said,
[01:06:39.760 --> 01:06:44.600]   the open rights movement, political action against this stuff.
[01:06:44.600 --> 01:06:45.600]   Yeah.
[01:06:45.600 --> 01:06:51.280]   Well, that was, I mean, that was founded like seven years ago to try and provide a voice
[01:06:51.280 --> 01:06:52.280]   for this.
[01:06:52.280 --> 01:06:57.440]   One of the things that worried me about the sort of post-soap of thing was the anti-tame
[01:06:57.440 --> 01:06:59.440]   industry should sit down with the technology industry.
[01:06:59.440 --> 01:07:02.000]   It's like, no, that doesn't necessarily give you the right answer.
[01:07:02.000 --> 01:07:03.560]   You also need these.
[01:07:03.560 --> 01:07:07.720]   You need some of these people who are representing the broader public interest as well, like the
[01:07:07.720 --> 01:07:11.440]   EFF and the open rights group who are there saying, well, can we look at both sides of
[01:07:11.440 --> 01:07:12.440]   this?
[01:07:12.440 --> 01:07:15.840]   And yeah, there is a danger that you also get people who are, you know, axe grinders
[01:07:15.840 --> 01:07:21.200]   who are there with a particular agenda, but there are organizations who actually focus
[01:07:21.200 --> 01:07:25.640]   on thinking this stuff through carefully from the technology angle and from the policy
[01:07:25.640 --> 01:07:27.040]   angle.
[01:07:27.040 --> 01:07:32.360]   There are a lot of people, activists, in fact, who believe in privacy, Jeff, and who say,
[01:07:32.360 --> 01:07:33.360]   well, we need stronger protection.
[01:07:33.360 --> 01:07:34.360]   I do too.
[01:07:34.360 --> 01:07:35.360]   I believe in privacy.
[01:07:35.360 --> 01:07:36.360]   I'm not against privacy.
[01:07:36.360 --> 01:07:37.720]   I mean, you read the book.
[01:07:37.720 --> 01:07:38.720]   I'm not against privacy at all.
[01:07:38.720 --> 01:07:43.240]   I think I'm for privacy, but I'm for protecting the tools of publicness and I'm against regulation
[01:07:43.240 --> 01:07:44.240]   of the Internet.
[01:07:44.240 --> 01:07:45.240]   They just been around for decades.
[01:07:45.240 --> 01:07:46.440]   Why is it suddenly getting regulated?
[01:07:46.440 --> 01:07:49.160]   Why is everybody suddenly seeing danger, danger in the Internet?
[01:07:49.160 --> 01:07:50.160]   Because the Internet is coming together.
[01:07:50.160 --> 01:07:52.120]   Because it's coming in our homes.
[01:07:52.120 --> 01:07:54.360]   It's becoming economic and also political.
[01:07:54.360 --> 01:07:56.720]   It's becoming a force for political change.
[01:07:56.720 --> 01:07:59.560]   It hasn't changed, folks.
[01:07:59.560 --> 01:08:01.600]   The circumstances around it and society have changed.
[01:08:01.600 --> 01:08:04.000]   It's having an impact and that's why they're reacting.
[01:08:04.000 --> 01:08:06.720]   And if we reacted to SOPA, I'm all in favor of privacy.
[01:08:06.720 --> 01:08:09.160]   I have a private life, privacy needs protection.
[01:08:09.160 --> 01:08:10.760]   I'm in favor of privacy regulations.
[01:08:10.760 --> 01:08:12.080]   Make that clear.
[01:08:12.080 --> 01:08:17.880]   But I'm also saying here that the Internet means to remain free and the Internet is the
[01:08:17.880 --> 01:08:20.200]   tool of disruption and that's why it's threatened.
[01:08:20.200 --> 01:08:21.200]   It's freedom is threatened.
[01:08:21.200 --> 01:08:24.200]   I'm about out of battery juice, so you'll be lucky to know about that.
[01:08:24.200 --> 01:08:27.280]   I'm Jeff Satter, but I do want to before we wrap.
[01:08:27.280 --> 01:08:29.080]   Go ahead, Matthew.
[01:08:29.080 --> 01:08:32.960]   I was just going to say that I think one of the things Jeff, one of the points he raised
[01:08:32.960 --> 01:08:38.080]   is a good one that even if you accept that the goals of say the right to be forgotten
[01:08:38.080 --> 01:08:45.400]   are good ones, the duty that that would impose on companies and the expense and the time
[01:08:45.400 --> 01:08:48.920]   and the effort required to do that might be punitive.
[01:08:48.920 --> 01:08:51.160]   It just might not be even be possible.
[01:08:51.160 --> 01:08:52.160]   Right.
[01:08:52.160 --> 01:08:54.440]   I think that's exactly what he's saying.
[01:08:54.440 --> 01:09:01.080]   That's this issue with SOPA too, is that maybe the goal is appropriate, but you've got to
[01:09:01.080 --> 01:09:05.240]   be careful about how you achieve these goals without doing things.
[01:09:05.240 --> 01:09:09.760]   And I think you're right, Jeff, that the scapegoat is often technology because it's scary.
[01:09:09.760 --> 01:09:14.800]   Whether it's political, economic, or just we're Luddites, it's scary.
[01:09:14.800 --> 01:09:16.320]   I didn't mean to hijack so much.
[01:09:16.320 --> 01:09:17.320]   I apologize.
[01:09:17.320 --> 01:09:18.320]   No, that's good.
[01:09:18.320 --> 01:09:19.320]   I got it.
[01:09:19.320 --> 01:09:21.080]   Well, it's scary because people are using it.
[01:09:21.080 --> 01:09:22.080]   Right.
[01:09:22.080 --> 01:09:23.080]   And that's what we want.
[01:09:23.080 --> 01:09:24.080]   Right.
[01:09:24.080 --> 01:09:25.080]   Yeah.
[01:09:25.080 --> 01:09:26.080]   Yes.
[01:09:26.080 --> 01:09:27.080]   Suit on Imms.
[01:09:27.080 --> 01:09:31.080]   Google has Google Plus says, yeah, you can use a NIMM.
[01:09:31.080 --> 01:09:35.880]   Good article Monday from you, Kevin Marks.
[01:09:35.880 --> 01:09:40.360]   Google admits they want fake names, but you have to be famous.
[01:09:40.360 --> 01:09:42.360]   What is the deal?
[01:09:42.360 --> 01:09:48.040]   Well, it's kind of the same thing they've been saying all along, but they've been direct
[01:09:48.040 --> 01:09:49.040]   about it.
[01:09:49.040 --> 01:09:52.920]   But, you know, Bradley wrote a sort of PRE thing, oh, we've done this stuff.
[01:09:52.920 --> 01:09:56.160]   And then you're not saying Zungra in the comments said what was actually going on, which is
[01:09:56.160 --> 01:10:00.960]   they have decided that people don't like the look of handles.
[01:10:00.960 --> 01:10:05.360]   And so they have an algorithm that tries to decide if your name looks real or not.
[01:10:05.360 --> 01:10:06.800]   They don't care if it is real or not.
[01:10:06.800 --> 01:10:08.600]   They want them to look like names.
[01:10:08.600 --> 01:10:12.160]   So it's this, the thing it reminds me of is--
[01:10:12.160 --> 01:10:13.160]   It's broken.
[01:10:13.160 --> 01:10:16.400]   People working in call centers have written.
[01:10:16.400 --> 01:10:17.400]   That's so Google.
[01:10:17.400 --> 01:10:18.400]   They're American.
[01:10:18.400 --> 01:10:19.400]   They're asking things.
[01:10:19.400 --> 01:10:22.040]   It's like you have to look normal because you're scared.
[01:10:22.040 --> 01:10:23.040]   You're scared.
[01:10:23.040 --> 01:10:25.040]   So the mainstream Americans or whatever.
[01:10:25.040 --> 01:10:31.720]   And so what they've explicitly said is your name has to be named like enough to our algorithm.
[01:10:31.720 --> 01:10:34.920]   Now their algorithm lets through a whole bunch of crap.
[01:10:34.920 --> 01:10:39.200]   You know, I checked 30 of mine and I got-- let me look for the line.
[01:10:39.200 --> 01:10:46.520]   I got the Phoenix Rising panel heater, Tulay Meidumont, and there's one called Mayor Decent,
[01:10:46.520 --> 01:10:52.680]   which is actually obviously a fake account using a Pakistani actress's photo.
[01:10:52.680 --> 01:10:56.680]   And that was out of the 30 people, the last 30 people who followed me at that point.
[01:10:56.680 --> 01:11:01.720]   So their algorithm is failing in its goal of creating things that look like real names.
[01:11:01.720 --> 01:11:04.520]   And they are attacking people who use names that they want to use.
[01:11:04.520 --> 01:11:07.720]   Now they've said, oh, if you can show us you've been using this name on the internet for
[01:11:07.720 --> 01:11:10.520]   a while, you can go through the appeals process.
[01:11:10.520 --> 01:11:13.840]   Well, Clea Hamlin went through the appeals process and it is ridiculous.
[01:11:13.840 --> 01:11:18.840]   And clearly it's designed to mess you around and make you back off.
[01:11:18.840 --> 01:11:24.040]   So it's really annoying.
[01:11:24.040 --> 01:11:26.040]   [LAUGHTER]
[01:11:26.040 --> 01:11:28.040]   They still have a fix up, right?
[01:11:28.040 --> 01:11:30.280]   As he's annoyed too, my dog's annoyed too.
[01:11:30.280 --> 01:11:31.440]   Gina, what are your thoughts?
[01:11:31.440 --> 01:11:36.240]   Were you cheered by this change or does it seem like it's meaningless?
[01:11:36.240 --> 01:11:41.440]   I was cheered that there was a change, still kind of annoying.
[01:11:41.440 --> 01:11:46.960]   I mean, I sort of agree with Google that a community of real names has a different vibe
[01:11:46.960 --> 01:11:50.720]   to it than a community of handles that can be anything.
[01:11:50.720 --> 01:11:54.640]   But I'm still not convinced they're quite handling this right yet.
[01:11:54.640 --> 01:11:59.280]   I'm still also really suspicious that most of my people who have put me in their circles
[01:11:59.280 --> 01:12:01.520]   on Google+ are spammers.
[01:12:01.520 --> 01:12:03.200]   So there's also that.
[01:12:03.200 --> 01:12:07.440]   My phone numbers are insane and it just seems-- and I just get a lot of them.
[01:12:07.440 --> 01:12:11.600]   So yeah, I'm not sure how I feel about this yet.
[01:12:11.600 --> 01:12:15.760]   Although I do have friends who have handles, who use them on Twitter and other social networks
[01:12:15.760 --> 01:12:19.520]   and have had them for years, who are now finally getting their Google profiles restored
[01:12:19.520 --> 01:12:21.080]   and that makes me happy.
[01:12:21.080 --> 01:12:25.320]   It does seem like there's an awful lot of spam on Google+.
[01:12:25.320 --> 01:12:26.960]   More than there is on Facebook.
[01:12:26.960 --> 01:12:30.800]   So clearly this didn't-- whatever they did didn't quite work.
[01:12:30.800 --> 01:12:32.000]   Does it help?
[01:12:32.000 --> 01:12:33.320]   Yeah.
[01:12:33.320 --> 01:12:36.320]   You know, I think in a way we've got the worst of both worlds.
[01:12:36.320 --> 01:12:41.680]   We've got Google pretending that they're having real names.
[01:12:41.680 --> 01:12:46.880]   But they're not because it's as long as it's what I call the real looking names policy.
[01:12:46.880 --> 01:12:48.480]   Well, what purpose does that serve?
[01:12:48.480 --> 01:12:50.880]   Why not let people use whatever name they want?
[01:12:50.880 --> 01:12:55.680]   And the thing that I like about Twitter is that you can use whatever handle you want.
[01:12:55.680 --> 01:12:57.920]   And most people attach their real name to it.
[01:12:57.920 --> 01:12:58.960]   Some people don't.
[01:12:58.960 --> 01:13:01.120]   But then it's about the quality of the content.
[01:13:01.120 --> 01:13:05.600]   And then you can start, you know, forming your community around that instead of what someone's name is.
[01:13:06.240 --> 01:13:09.760]   But Twitter, there's your handle and then there's your full name.
[01:13:09.760 --> 01:13:12.160]   You know, you kind of have both really.
[01:13:12.160 --> 01:13:14.800]   And I think Google's trying to do that.
[01:13:14.800 --> 01:13:19.120]   So they're saying there's this other field and you can have your handle in there.
[01:13:19.120 --> 01:13:23.280]   And but we still need your real name or your real looking name, which, you know,
[01:13:23.280 --> 01:13:26.480]   it just it feels like the worst of both worlds instead of the best.
[01:13:26.480 --> 01:13:34.080]   Let us get to our tool tip and number of the week before Jeff's battery
[01:13:34.880 --> 01:13:35.440]   dies.
[01:13:35.440 --> 01:13:41.360]   Why don't you do the number first as the air escapes from Jeff's balloon head?
[01:13:41.360 --> 01:13:42.640]   Why not?
[01:13:42.640 --> 01:13:45.680]   I will confess that I cheated and teacher gave me a number.
[01:13:45.680 --> 01:13:46.640]   I gave you a number.
[01:13:46.640 --> 01:13:47.440]   But it's a good number.
[01:13:47.440 --> 01:13:48.560]   It's a good number.
[01:13:48.560 --> 01:13:49.920]   9.68 million.
[01:13:49.920 --> 01:13:54.000]   That's how much Google spending on lobbying, which I would just say simply is still a lot enough.
[01:13:54.000 --> 01:13:54.800]   Not even close.
[01:13:54.800 --> 01:13:55.840]   No.
[01:13:55.840 --> 01:13:58.720]   Although all the members of Congress are cheaper than they used to be.
[01:13:58.720 --> 01:14:00.800]   A few thousand gets you a vote.
[01:14:00.800 --> 01:14:01.040]   So.
[01:14:01.600 --> 01:14:06.240]   But if Google saw it's if Google, I think this is where the discussion earlier in the show was
[01:14:06.240 --> 01:14:11.440]   right. If Google truly were aligned with our interests, if it truly were for able to do that
[01:14:11.440 --> 01:14:15.040]   and did that well, then they wouldn't need a lobbyist because we proved the soap of that
[01:14:15.040 --> 01:14:16.000]   we are the lobby.
[01:14:16.000 --> 01:14:17.520]   Right. Let us be the lobby Google.
[01:14:17.520 --> 01:14:21.600]   By the way, that number is twice what they spent last year, 2010.
[01:14:21.600 --> 01:14:22.720]   That's the 2011 number.
[01:14:22.720 --> 01:14:25.360]   So they are is going up going up.
[01:14:25.360 --> 01:14:25.600]   Yeah.
[01:14:25.600 --> 01:14:27.440]   Half of it is.
[01:14:27.440 --> 01:14:30.560]   And that will continue to go up by that half of its carfare for Eric Schmidt.
[01:14:31.280 --> 01:14:34.560]   And I'm going to apologize rather than just fade away.
[01:14:34.560 --> 01:14:39.680]   I'm going to say hello to the 1.1 the 0.1 percent.
[01:14:39.680 --> 01:14:43.680]   Bono's not there this year.
[01:14:43.680 --> 01:14:44.560]   Mick Jagger might be.
[01:14:44.560 --> 01:14:45.280]   We're not sure.
[01:14:45.280 --> 01:14:47.200]   I'll try to dance with him.
[01:14:47.200 --> 01:14:47.760]   Fine, Mick.
[01:14:47.760 --> 01:14:48.960]   See you, Jeff.
[01:14:48.960 --> 01:14:49.280]   Thank you.
[01:14:49.280 --> 01:14:51.920]   Jeff Jarvis, Buzz Machine.com, his new book, Public Parts.
[01:14:51.920 --> 01:14:54.560]   Available at better bookstores everywhere.
[01:14:54.560 --> 01:14:55.920]   He'll be back next week, I'm sure.
[01:14:55.920 --> 01:14:56.800]   Enjoy Davos.
[01:14:56.800 --> 01:14:58.800]   Enjoy the six feet of snow.
[01:14:59.840 --> 01:15:01.040]   Gina, you have a tip for us?
[01:15:01.040 --> 01:15:02.240]   Yes, I do.
[01:15:02.240 --> 01:15:03.360]   Twelve feet?
[01:15:03.360 --> 01:15:06.480]   Go ahead.
[01:15:06.480 --> 01:15:09.680]   Google Maps now highlights an area.
[01:15:09.680 --> 01:15:14.400]   So if you search for Petaluma or if you search for a zip code or if you search for a county,
[01:15:14.400 --> 01:15:18.560]   the Google Maps, if you're in, not in satellite view, but in just regular map view,
[01:15:18.560 --> 01:15:20.000]   it'll highlight the area in pink.
[01:15:20.000 --> 01:15:23.760]   You can actually see the boundaries of a zip or a city.
[01:15:23.760 --> 01:15:27.920]   So if you search for Brooklyn, New York, you can see how big my hometown really is
[01:15:27.920 --> 01:15:29.120]   or my home borough really is.
[01:15:29.120 --> 01:15:32.400]   It's just a neat feature if you want to get a sense of different areas and neighborhoods.
[01:15:32.400 --> 01:15:34.640]   It might even work for just neighborhoods as well.
[01:15:34.640 --> 01:15:35.600]   That's cool.
[01:15:35.600 --> 01:15:38.800]   And they've added a bunch more 3D renderings as well.
[01:15:38.800 --> 01:15:40.800]   Like they said, 42 plus more locations.
[01:15:40.800 --> 01:15:41.600]   Let me just see.
[01:15:41.600 --> 01:15:44.800]   Brooklyn, New York, New York.
[01:15:44.800 --> 01:15:46.080]   Let's zoom in on that here.
[01:15:46.080 --> 01:15:48.160]   And you have to be in map mode.
[01:15:48.160 --> 01:15:49.440]   You're in satellite mode right now.
[01:15:49.440 --> 01:15:49.920]   Oh, yes.
[01:15:49.920 --> 01:15:50.800]   Let's go to map mode.
[01:15:50.800 --> 01:15:54.400]   I don't even know how to do it.
[01:15:54.400 --> 01:15:54.800]   Wait a minute.
[01:15:54.800 --> 01:15:55.360]   What happened?
[01:15:55.360 --> 01:15:55.600]   There.
[01:15:55.600 --> 01:15:56.080]   Click that.
[01:15:56.080 --> 01:15:56.560]   There we go.
[01:15:56.560 --> 01:15:57.440]   Oh, yeah.
[01:15:57.440 --> 01:15:58.160]   Look, they're pink.
[01:15:58.160 --> 01:15:58.560]   Yeah.
[01:15:58.560 --> 01:16:02.320]   So yes, if you zoom out, you can kind of see the highlighted area.
[01:16:02.320 --> 01:16:03.200]   That's where it is.
[01:16:03.200 --> 01:16:06.240]   That's where we're going for zip codes as well.
[01:16:06.240 --> 01:16:07.680]   If you want to get a sense.
[01:16:07.680 --> 01:16:08.160]   That's cool.
[01:16:08.160 --> 01:16:08.480]   Let's see.
[01:16:08.480 --> 01:16:10.640]   Let's look at our zip code 94952.
[01:16:10.640 --> 01:16:15.440]   Oh, now that's what we should do.
[01:16:15.440 --> 01:16:17.120]   Let's see the 11th congressional district.
[01:16:17.120 --> 01:16:17.920]   That's what we need.
[01:16:17.920 --> 01:16:18.960]   Oh, interesting.
[01:16:18.960 --> 01:16:19.920]   I'm not sure if that's going to work.
[01:16:19.920 --> 01:16:23.280]   Wouldn't that surprise you?
[01:16:27.840 --> 01:16:28.400]   I'm sorry.
[01:16:28.400 --> 01:16:29.200]   I just have to try this.
[01:16:29.200 --> 01:16:32.160]   Oh, I don't know what state there it is.
[01:16:32.160 --> 01:16:34.400]   California's 11th congressional district.
[01:16:34.400 --> 01:16:36.080]   No.
[01:16:36.080 --> 01:16:37.200]   Well, you know what?
[01:16:37.200 --> 01:16:38.160]   It gave me a dot though.
[01:16:38.160 --> 01:16:39.280]   It showed me where it is.
[01:16:39.280 --> 01:16:39.920]   Right.
[01:16:39.920 --> 01:16:40.960]   But I think there's not a band.
[01:16:40.960 --> 01:16:42.480]   Yeah, I need an outline.
[01:16:42.480 --> 01:16:43.360]   Wouldn't that be nice?
[01:16:43.360 --> 01:16:45.280]   Hey, at least it's on the map.
[01:16:45.280 --> 01:16:47.520]   Because they do the word of voting.
[01:16:47.520 --> 01:16:49.120]   So they have that in the Google politics.
[01:16:49.120 --> 01:16:49.440]   They vote.
[01:16:49.440 --> 01:16:49.920]   Ah, OK.
[01:16:49.920 --> 01:16:51.360]   We're just going to have to put it up here.
[01:16:51.360 --> 01:16:52.000]   I get it.
[01:16:52.000 --> 01:16:52.560]   That's cool.
[01:16:52.560 --> 01:16:56.800]   I was going to make my tool
[01:16:56.800 --> 01:16:59.680]   be something that apparently Google doesn't want you to use.
[01:16:59.680 --> 01:17:02.000]   So I was going to do this last week.
[01:17:02.000 --> 01:17:03.040]   I should have.
[01:17:03.040 --> 01:17:03.920]   It was so cool.
[01:17:03.920 --> 01:17:05.920]   It was called Google's Sesame.
[01:17:05.920 --> 01:17:07.920]   It would give you a QR code.
[01:17:07.920 --> 01:17:10.240]   Did I do that wrong?
[01:17:10.240 --> 01:17:11.760]   Give you a QR code
[01:17:11.760 --> 01:17:16.400]   that you could use to log in from mobile phones and so forth.
[01:17:16.400 --> 01:17:19.760]   So a QR code for your account.
[01:17:19.760 --> 01:17:21.440]   Making it so easy.
[01:17:21.440 --> 01:17:25.600]   And it turns out it wasn't a public service at all.
[01:17:25.600 --> 01:17:29.600]   It was an experiment that never was intended to be exposed.
[01:17:29.600 --> 01:17:32.000]   And the guy who, I got to find this.
[01:17:32.000 --> 01:17:36.640]   Because they have a thank you for your interest.
[01:17:36.640 --> 01:17:37.120]   Goodbye.
[01:17:37.120 --> 01:17:42.880]   We'll find out something.
[01:17:42.880 --> 01:17:44.880]   We'll do something better next time, but that's not it.
[01:17:44.880 --> 01:17:47.600]   Thank you so much, all of you for being here.
[01:17:47.600 --> 01:17:49.040]   There was so much more to talk about.
[01:17:49.040 --> 01:17:52.320]   I just, this is such a good subject in general
[01:17:52.320 --> 01:17:54.720]   for everything that we do.
[01:17:55.360 --> 01:17:58.240]   Matthew Ingram is the Emanol Screeze.
[01:17:58.240 --> 01:18:01.200]   I love that, Matthew.
[01:18:01.200 --> 01:18:01.840]   As your new title.
[01:18:01.840 --> 01:18:02.960]   I think that's on your card.
[01:18:02.960 --> 01:18:05.360]   It's Latin for old.
[01:18:05.360 --> 01:18:07.840]   Oldman@giggaom.com.
[01:18:07.840 --> 01:18:10.240]   And you can catch us writing there.
[01:18:10.240 --> 01:18:12.160]   He's also on Twitter at Matthewye.
[01:18:12.160 --> 01:18:13.920]   Thank you, Matthew, for being here.
[01:18:13.920 --> 01:18:14.480]   Thanks.
[01:18:14.480 --> 01:18:18.560]   Kevin Marks is at Urban Buena Gardens enjoying the beautiful weather.
[01:18:18.560 --> 01:18:20.160]   I think tomorrow it's going to be in the 70s.
[01:18:20.160 --> 01:18:22.560]   So if you're coming for Macworld Expo,
[01:18:22.560 --> 01:18:23.440]   you're going to be in good shape.
[01:18:23.440 --> 01:18:24.720]   You can catch his show.
[01:18:24.720 --> 01:18:29.040]   Tumble Vision, he does it with Heather and Deborah and Deb Schultz.
[01:18:29.040 --> 01:18:30.240]   And it's just a great show.
[01:18:30.240 --> 01:18:33.600]   Tumblevision.tv to see more at Kevin Marks.
[01:18:33.600 --> 01:18:34.640]   Tomorrow night at six.
[01:18:34.640 --> 01:18:35.600]   Tomorrow night at six.
[01:18:35.600 --> 01:18:36.240]   Thank you, Kevin.
[01:18:36.240 --> 01:18:40.160]   Always a pleasure to get an intelligent person on here.
[01:18:40.160 --> 01:18:42.800]   Speaking of intense, I'm watching this.
[01:18:42.800 --> 01:18:43.280]   Hey.
[01:18:43.280 --> 01:18:44.480]   Well, he's got a British accent.
[01:18:44.480 --> 01:18:45.920]   That makes him sound smarter.
[01:18:45.920 --> 01:18:46.960]   It's a good party.
[01:18:46.960 --> 01:18:47.760]   Hey.
[01:18:47.760 --> 01:18:50.400]   I think Jim here in everybody's mind too.
[01:18:50.400 --> 01:18:52.560]   Oh, I don't know.
[01:18:52.560 --> 01:18:53.680]   I don't know.
[01:18:53.680 --> 01:18:55.360]   Gina's pretty darn smart.
[01:18:55.360 --> 01:18:56.000]   You bet.
[01:18:56.000 --> 01:18:58.000]   Gina Trippani, smarterware.org.
[01:18:58.000 --> 01:18:59.920]   Even her website says so.
[01:18:59.920 --> 01:19:00.800]   She's brilliant.
[01:19:00.800 --> 01:19:02.000]   Of course she is.
[01:19:02.000 --> 01:19:03.200]   It's a great conversation today.
[01:19:03.200 --> 01:19:04.240]   Really interesting.
[01:19:04.240 --> 01:19:04.640]   Loved it.
[01:19:04.640 --> 01:19:05.040]   Yeah.
[01:19:05.040 --> 01:19:05.600]   Thank you, Matthew.
[01:19:05.600 --> 01:19:06.800]   And Kevin, for joining us.
[01:19:06.800 --> 01:19:09.360]   This is just such a great show to do.
[01:19:09.360 --> 01:19:09.840]   Here it is.
[01:19:09.840 --> 01:19:12.800]   Here's the accounts.google.com/sesame.
[01:19:12.800 --> 01:19:15.920]   This is this is this sounds like something Douglas Adams would have written.
[01:19:15.920 --> 01:19:17.680]   Hello, there.
[01:19:17.680 --> 01:19:21.360]   Thank you for your interest in our phone-based login experiment.
[01:19:21.360 --> 01:19:23.360]   We have concluded this particular experiment.
[01:19:23.360 --> 01:19:26.160]   Stay tuned for something even better.
[01:19:26.160 --> 01:19:27.280]   Bye-bye.
[01:19:27.280 --> 01:19:28.720]   Thank you all for being here.
[01:19:28.720 --> 01:19:31.440]   We do this show every Wednesday afternoon,
[01:19:31.440 --> 01:19:33.760]   about 1 p.m. Pacific, 4 p.m. Eastern.
[01:19:33.760 --> 01:19:35.440]   At Twit TV, you can watch us live.
[01:19:35.440 --> 01:19:36.480]   But if you don't, don't worry.
[01:19:36.480 --> 01:19:39.840]   We make an audio and video available for download from this site,
[01:19:39.840 --> 01:19:42.080]   but also from iTunes and everywhere.
[01:19:42.080 --> 01:19:44.000]   Better podcasts are stored.
[01:19:44.000 --> 01:19:46.400]   Please tune in again next week.
[01:19:46.400 --> 01:19:49.520]   And stay tuned to Tech News Today is coming up next with Tom,
[01:19:49.520 --> 01:19:53.040]   I as Sarah and the latest technology news.
[01:19:53.040 --> 01:19:54.080]   Have a great week.
[01:19:54.080 --> 01:19:55.600]   Thanks for joining us on this week.
[01:19:55.600 --> 01:20:07.520]   [MUSIC]
[01:20:07.520 --> 01:20:08.960]   And my battery just went to zero.
[01:20:08.960 --> 01:20:10.160]   Yay!
[01:20:10.160 --> 01:20:11.440]   We got it all the way down.
[01:20:11.440 --> 01:20:13.120]   Thank you, Kevin.
[01:20:13.120 --> 01:20:14.400]   Really nice.
[01:20:14.400 --> 01:20:16.000]   You got the choice.
[01:20:16.000 --> 01:20:19.040]   I guess one of the QR code things is that they did experiment and found they were
[01:20:19.040 --> 01:20:20.080]   absolutely for logging in.
[01:20:20.080 --> 01:20:20.720]   It didn't work.
[01:20:20.720 --> 01:20:21.600]   [LAUGHTER]
[01:20:21.600 --> 01:20:23.120]   It probably didn't work.
[01:20:23.120 --> 01:20:25.840]   There was a museum that started trying to use QR codes,
[01:20:25.840 --> 01:20:31.280]   and they found that the uptake was 80% down compared to having a texting that people would put in.
[01:20:31.280 --> 01:20:31.760]   Yeah.
[01:20:31.760 --> 01:20:32.240]   Yeah.
[01:20:32.240 --> 01:20:34.720]   Basically QR codes work if you have a dedicated scanner,
[01:20:34.720 --> 01:20:36.640]   but they're completely useless with most phones.

