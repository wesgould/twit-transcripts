;FFMETADATA1
album=This Week In Google
artist=Leo Laporte, Jeff Jarvis and Gina Trapani
iTunPGAP=0
comment=http://twit.tv/twig141
encoded_by=iTunes v7.0
genre=Tech News
TGID=http://www.podtrac.com/pts/redirect.mp3/twit.cachefly.net/twig0115.mp3
TDES=Hosts: Leo Laporte, Jeff Jarvis, and Gina Trapani\
\
Apple's iPhone 4S keynote, what is PhoneGap, \# on Google +, Google won't screw up Android, and more cloud news.\
\
Download or subscribe to this show at twit.tv/twig.\
\
We invite you to read, add to, and amend our show notes.\
\
Friendfeed links for this episode.\
\
Thanks to Cachefly for the bandwidth for this show.\
\
Running time: 1:29:14
track=141
title=This Week In Google 141: A Carrot-Shaped Stick
date=2012
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:03.000]   It's time for Twig this week at Google.
[00:00:03.000 --> 00:00:06.000]   The Google glasses are here and they're real.
[00:00:06.000 --> 00:00:08.000]   We'll take a look at what that might be.
[00:00:08.000 --> 00:00:13.000]   Larry Page after he celebrates his first year as CEO of Google.
[00:00:13.000 --> 00:00:15.000]   We'll give him a report card.
[00:00:15.000 --> 00:00:17.000]   And yes, we'll talk about the jobs, Bill.
[00:00:17.000 --> 00:00:19.000]   It's all coming up next on Twig.
[00:00:19.000 --> 00:00:24.000]   Netcast you love.
[00:00:24.000 --> 00:00:26.000]   From people you trust.
[00:00:29.000 --> 00:00:31.000]   This is Twig.
[00:00:32.000 --> 00:00:39.000]   Bandwidth for this week in Google is provided by CashFly, C-A-C-H-E-F-L-Y.com.
[00:00:40.000 --> 00:00:41.000]   This is Twig.
[00:00:41.000 --> 00:00:47.000]   This week in Google, Episode 141, recorded April 4, 2012.
[00:00:47.000 --> 00:00:49.000]   A carrot shaped stick.
[00:00:49.000 --> 00:00:52.000]   This week in Google is brought to you by Stamps.com.
[00:00:52.000 --> 00:00:54.000]   Your time is valuable.
[00:00:54.000 --> 00:00:57.000]   Don't waste another minute waiting in line at the post office.
[00:00:57.000 --> 00:01:01.000]   Use Stamps.com to buy and print real US postage, the instant you need it.
[00:01:01.000 --> 00:01:03.000]   Using your own computer and printer.
[00:01:03.000 --> 00:01:05.000]   To get my special offer, go to Stamps.com now.
[00:01:05.000 --> 00:01:08.000]   Click on the radio microphone and enter Twig.
[00:01:08.000 --> 00:01:11.000]   Stamps.com offer code Twig.
[00:01:11.000 --> 00:01:15.000]   And buy Ford, featuring voice activated sync app link.
[00:01:15.000 --> 00:01:18.000]   Now you can control select smartphone apps with your voice.
[00:01:18.000 --> 00:01:20.000]   Helping keep your hands on the wheel and your eyes on the road.
[00:01:20.000 --> 00:01:27.000]   Learn more about the technologies Ford is bringing to its vehicles at Ford.com/technology.
[00:01:27.000 --> 00:01:31.000]   It's time for this weekend.
[00:01:31.000 --> 00:01:32.000]   Google!
[00:01:32.000 --> 00:01:35.000]   To show that covers anything we damn well want to cover.
[00:01:35.000 --> 00:01:37.000]   How about that?
[00:01:37.000 --> 00:01:38.000]   Right?
[00:01:38.000 --> 00:01:44.000]   Just because it says Google in the name doesn't mean there isn't, there's something besides Google inside.
[00:01:44.000 --> 00:01:50.000]   Ladies and gentlemen, I give you Gina Trippani, founding editor of Life Hacker, author of ThinkUp,
[00:01:50.000 --> 00:01:53.000]   blogger at smarterware.org and all around.
[00:01:53.000 --> 00:01:55.000]   Gee, you're a good person and Brooklynite.
[00:01:55.000 --> 00:01:56.000]   Hello Gina.
[00:01:56.000 --> 00:01:57.000]   Hello.
[00:01:57.000 --> 00:01:58.000]   Welcome.
[00:01:58.000 --> 00:02:00.000]   I'm excited to talk about glasses.
[00:02:00.000 --> 00:02:01.000]   Glasses.
[00:02:01.000 --> 00:02:02.000]   Let's get to be intro first.
[00:02:02.000 --> 00:02:03.000]   They're half full.
[00:02:03.000 --> 00:02:04.000]   They are half full.
[00:02:04.000 --> 00:02:07.000]   Today they're half full.
[00:02:07.000 --> 00:02:15.000]   Mr. Jeff Jarvis, my friends of the City University of New York where he teaches the new journalism to young children.
[00:02:15.000 --> 00:02:21.000]   He's also a blogger, buzz machine to come and author of many great books like what Google do in his latest public parts.
[00:02:21.000 --> 00:02:23.000]   Thank you for the plug as always.
[00:02:23.000 --> 00:02:26.000]   Today wearing leather so he won't mwahre.
[00:02:26.000 --> 00:02:29.000]   I learned that term on glee.
[00:02:29.000 --> 00:02:31.000]   And that leather, I mean.
[00:02:31.000 --> 00:02:34.000]   And then we got all the way over to the right.
[00:02:34.000 --> 00:02:39.000]   We got Mr. Matthew Ingram of gigaohm, gigaohm.com.
[00:02:39.000 --> 00:02:44.000]   And no one knows why his Twitter handle is Matthew I, I guess it's his name.
[00:02:44.000 --> 00:02:47.000]   For a while I thought it was Matt Huey.
[00:02:47.000 --> 00:02:50.000]   Hey Matthew, frozen solid.
[00:02:50.000 --> 00:02:52.000]   He's turned to stone.
[00:02:52.000 --> 00:02:56.000]   Stop looking at your wife and keep going forward.
[00:02:56.000 --> 00:02:58.000]   He's a biller of salt.
[00:02:58.000 --> 00:03:01.000]   All right, let's, what is.
[00:03:01.000 --> 00:03:03.000]   We're in a fighting mood today.
[00:03:03.000 --> 00:03:04.000]   I'm feisty today.
[00:03:04.000 --> 00:03:09.000]   I've been fighting with that's because I've been fighting with my galaxy.
[00:03:09.000 --> 00:03:10.000]   Tablet that I haven't turned.
[00:03:10.000 --> 00:03:11.000]   It's my fault.
[00:03:11.000 --> 00:03:14.000]   I haven't turned it on in a year and it's feeling left out.
[00:03:14.000 --> 00:03:22.000]   But I wanted to show you something hot and new that requires honeycomer later on a tablet.
[00:03:22.000 --> 00:03:26.000]   So I'm going to, you know what, I'm going to defer to you Gina because you were excited
[00:03:26.000 --> 00:03:31.000]   about talking about the glasses that we're all going to get at Google I/O.
[00:03:31.000 --> 00:03:33.000]   Oh, you're from your lips.
[00:03:33.000 --> 00:03:34.000]   You're from Google I/O.
[00:03:34.000 --> 00:03:35.000]   You are.
[00:03:35.000 --> 00:03:38.000]   We'll all be stumbling around.
[00:03:38.000 --> 00:03:40.000]   Not getting to see anything.
[00:03:40.000 --> 00:03:44.000]   Yes, Google I/O is going to be such a train wreck because everybody's going to be looking
[00:03:44.000 --> 00:03:46.000]   like this or looking like this.
[00:03:46.000 --> 00:03:53.000]   What are, so Google, this ice, I swear to God I thought this was a hoax when we first heard
[00:03:53.000 --> 00:03:54.000]   about it.
[00:03:54.000 --> 00:04:00.000]   But now no less authority than Nick Bilton in the freaking New York Times says Google is
[00:04:00.000 --> 00:04:02.000]   testing these glasses.
[00:04:02.000 --> 00:04:04.000]   I think it's the one who broke the story initially.
[00:04:04.000 --> 00:04:05.000]   Yeah.
[00:04:05.000 --> 00:04:07.000]   Now these photos come from Google.
[00:04:07.000 --> 00:04:08.000]   So this is it.
[00:04:08.000 --> 00:04:09.000]   This is the real.
[00:04:09.000 --> 00:04:11.000]   We have a plenty video or we have bands over.
[00:04:11.000 --> 00:04:12.000]   Yeah, let's play it.
[00:04:12.000 --> 00:04:13.000]   I've got it here.
[00:04:13.000 --> 00:04:14.000]   We go and we should mention this.
[00:04:14.000 --> 00:04:15.000]   We should mention this.
[00:04:15.000 --> 00:04:23.200]   That last week we aired what I thought was a great promotional video, promotional video
[00:04:23.200 --> 00:04:26.000]   for Google and it's self-driving cars.
[00:04:26.000 --> 00:04:27.000]   It was a great--
[00:04:27.000 --> 00:04:28.000]   I think it needs any promotion.
[00:04:28.000 --> 00:04:31.000]   It was a great video and it came from Google as promotional.
[00:04:31.000 --> 00:04:34.000]   They yanked us off YouTube immediately.
[00:04:34.000 --> 00:04:37.000]   Content removed at request of Google.
[00:04:37.000 --> 00:04:38.000]   The robots did.
[00:04:38.000 --> 00:04:41.000]   Well, I think it was the robots because we immediately appeared.
[00:04:41.000 --> 00:04:43.000]   Well, it is the robot Gina.
[00:04:43.000 --> 00:04:44.000]   Well, it's true.
[00:04:44.000 --> 00:04:45.000]   [LAUGHTER]
[00:04:45.000 --> 00:04:46.000]   It's the same thing.
[00:04:46.000 --> 00:04:48.000]   Python told us--
[00:04:48.000 --> 00:04:50.000]   Hey, welcome back, Matthew.
[00:04:50.000 --> 00:04:52.000]   So we appealed it.
[00:04:52.000 --> 00:04:54.000]   So here's how it works just for those who don't know.
[00:04:54.000 --> 00:05:00.280]   So there is an automated content filter which, by the way, is totally being game because
[00:05:00.280 --> 00:05:05.800]   we have shows that I get flagged all the time for violating content from Brazilian TV companies
[00:05:05.800 --> 00:05:08.000]   that we've never aired any content from.
[00:05:08.000 --> 00:05:12.880]   So I think these companies are gaming the content filter saying, yes, I will own anything
[00:05:12.880 --> 00:05:16.320]   that has anything in it that says zuby, zuby, zuby, zuby.
[00:05:16.320 --> 00:05:19.720]   And then what happens is, but don't worry, don't pull it down.
[00:05:19.720 --> 00:05:21.120]   Just put our ads in it.
[00:05:21.120 --> 00:05:26.880]   It's a way of third parties getting ads into our content by gaming Google's content filter.
[00:05:26.880 --> 00:05:27.880]   This is my thesis.
[00:05:27.880 --> 00:05:28.880]   Wow.
[00:05:28.880 --> 00:05:32.320]   Because I'm telling you, I get these notices all the time.
[00:05:32.320 --> 00:05:33.880]   Well, don't worry.
[00:05:33.880 --> 00:05:35.400]   Your content is not going to be pulled down.
[00:05:35.400 --> 00:05:36.720]   We're just going to put ads on it.
[00:05:36.720 --> 00:05:39.160]   We might put ads on it.
[00:05:39.160 --> 00:05:41.720]   So that's a YouTube thing that is already bugging me.
[00:05:41.720 --> 00:05:42.960]   So this time they pulled it down.
[00:05:42.960 --> 00:05:45.240]   Now the way it works, it's automated to take you.
[00:05:45.240 --> 00:05:50.880]   So if you're a content creator, you tell Google, here's, I guess the thumbprint, right?
[00:05:50.880 --> 00:05:54.000]   The fingerprint of our content somehow.
[00:05:54.000 --> 00:05:58.320]   And if you see this, do something and you're given a number of choices.
[00:05:58.320 --> 00:06:00.440]   You can say, yank it.
[00:06:00.440 --> 00:06:05.840]   You can say, put our ads on it or something like buy, you can say, put ads on it or buy
[00:06:05.840 --> 00:06:07.520]   this product by this song.
[00:06:07.520 --> 00:06:09.800]   So you have a choice.
[00:06:09.800 --> 00:06:12.280]   Google in this case, yanked it.
[00:06:12.280 --> 00:06:17.480]   Now the next step is for the cost, the us, the people who put the video up in the first
[00:06:17.480 --> 00:06:19.280]   place to appeal.
[00:06:19.280 --> 00:06:22.720]   So there's a form, you fill out a form saying, no, no, and there's a couple of things.
[00:06:22.720 --> 00:06:25.320]   We own this content that's wrong.
[00:06:25.320 --> 00:06:26.560]   Is there a fair use exemption?
[00:06:26.560 --> 00:06:30.400]   Is there actually a checkbox that says, no, we say that we have the right to do this?
[00:06:30.400 --> 00:06:35.080]   I don't think there is, but that's our assertion is we're a news organization.
[00:06:35.080 --> 00:06:36.080]   There is.
[00:06:36.080 --> 00:06:37.080]   Okay.
[00:06:37.080 --> 00:06:38.440]   Tom, who does this pretty much all the time?
[00:06:38.440 --> 00:06:43.960]   No, anyway, Alex, couple and our staff filled this out and they immediately put it back.
[00:06:43.960 --> 00:06:47.280]   Now it's not been taken down again.
[00:06:47.280 --> 00:06:49.680]   What happens is a human then reviews it.
[00:06:49.680 --> 00:06:52.040]   And at that point the human says, no, that's a violation.
[00:06:52.040 --> 00:06:53.200]   It'll get pulled down again.
[00:06:53.200 --> 00:06:58.720]   Now there's a long 10 day appeal process that is much more complicated.
[00:06:58.720 --> 00:07:03.760]   What content does Google have that it possibly wants to protect under copyright?
[00:07:03.760 --> 00:07:06.520]   Everything Google puts online is promotional.
[00:07:06.520 --> 00:07:10.680]   Well, that's why, well, there's a couple of things.
[00:07:10.680 --> 00:07:11.840]   First of all, and I'll pass this along.
[00:07:11.840 --> 00:07:14.280]   Anybody does a podcast.
[00:07:14.280 --> 00:07:16.720]   The fingerprinting tool doesn't work very well.
[00:07:16.720 --> 00:07:21.400]   So if you don't make the video full screen, if you just show it in context on the YouTube
[00:07:21.400 --> 00:07:25.240]   screen, apparently it just doesn't even know.
[00:07:25.240 --> 00:07:26.880]   So that was one mistake I made.
[00:07:26.880 --> 00:07:29.080]   I wanted to go full screen on that great video.
[00:07:29.080 --> 00:07:32.600]   So I did it and I figured, well, how could I look at the license, but how could Google
[00:07:32.600 --> 00:07:36.400]   complain that we're playing a promotional video on a show about Google?
[00:07:36.400 --> 00:07:39.800]   So just to Mystery Science Theater 3000 and you can show anything.
[00:07:39.800 --> 00:07:43.960]   Well, but that's the other side of it is now there's this is kind of a fair use provision,
[00:07:43.960 --> 00:07:46.800]   which means it's never it's not, you know, you have to test it in court.
[00:07:46.800 --> 00:07:47.800]   It's a defense.
[00:07:47.800 --> 00:07:49.560]   It's not proactive.
[00:07:49.560 --> 00:07:53.280]   So it doesn't protect you until somebody says no, and then you have to go to court.
[00:07:53.280 --> 00:07:56.520]   As Larry Lessick says, it's it's the right to hire a lawyer.
[00:07:56.520 --> 00:07:57.600]   Oh, thank you.
[00:07:57.600 --> 00:07:59.760]   Thanks, Congress.
[00:07:59.760 --> 00:08:04.360]   But that's our assertion is that we're a news organization and we are protected in
[00:08:04.360 --> 00:08:07.920]   not to use it as a production value, but in the in the coverage of this news to show
[00:08:07.920 --> 00:08:09.800]   clips, you see it all the time on television, right?
[00:08:09.800 --> 00:08:12.000]   That's normal.
[00:08:12.000 --> 00:08:14.400]   But we're not nobody knows who the hell twig is.
[00:08:14.400 --> 00:08:16.400]   And so we get pulled all the time.
[00:08:16.400 --> 00:08:19.000]   Anyway, so let's so having said all this.
[00:08:19.000 --> 00:08:20.000]   Here's a little test.
[00:08:20.000 --> 00:08:21.480]   Now we're going to do it again.
[00:08:21.480 --> 00:08:22.480]   Let's do it again.
[00:08:22.480 --> 00:08:23.480]   And let's go full screen.
[00:08:23.480 --> 00:08:24.480]   Well, we don't have to.
[00:08:24.480 --> 00:08:25.480]   Really?
[00:08:25.480 --> 00:08:26.480]   Okay.
[00:08:26.480 --> 00:08:30.440]   Well, I why the problem is if they pull it down, it costs us money because that's a days
[00:08:30.440 --> 00:08:33.680]   worth of impressions, even if we react right away that we lose.
[00:08:33.680 --> 00:08:35.560]   So yeah, make it make it be in the window.
[00:08:35.560 --> 00:08:36.560]   Okay, here we go.
[00:08:36.560 --> 00:08:37.560]   Yeah, then then your audience.
[00:08:37.560 --> 00:08:41.320]   Then we can talk about this project last one day.
[00:08:41.320 --> 00:08:45.160]   We believe technology should work for you to be there when you need it.
[00:08:45.160 --> 00:08:47.560]   So I'm going to narrate because there's people listening on a audio.
[00:08:47.560 --> 00:08:52.440]   There's a guy in flip flops just got up looking at his desk, making some coffee.
[00:08:52.440 --> 00:08:57.160]   And now he's looking through glasses that tell him what he has to do today.
[00:08:57.160 --> 00:08:58.760]   What he's looking out the window.
[00:08:58.760 --> 00:09:01.280]   It says 58 degrees with a chance of rain.
[00:09:01.280 --> 00:09:06.560]   He's eating a sandwich and his friend, Ev Williams, says want to meet up today.
[00:09:06.560 --> 00:09:09.440]   And he talks back to him, says meet his strand books.
[00:09:09.440 --> 00:09:11.720]   And it says sent and then goes back to his sandwich.
[00:09:11.720 --> 00:09:13.360]   All of this through his eyes.
[00:09:13.360 --> 00:09:17.880]   You're seeing out his, these are the glasses.
[00:09:17.880 --> 00:09:19.360]   It's augmented reality.
[00:09:19.360 --> 00:09:22.840]   Subway service suspended before he even goes down the stairs.
[00:09:22.840 --> 00:09:25.280]   So it gives him a walking route.
[00:09:25.280 --> 00:09:29.040]   And he's going to take that route from Google Maps.
[00:09:29.040 --> 00:09:31.600]   And he's going to walk right into the middle of the street.
[00:09:31.600 --> 00:09:32.600]   There's some puppies.
[00:09:32.600 --> 00:09:35.280]   It's probably didn't tell him to breed a dog.
[00:09:35.280 --> 00:09:36.280]   That dog.
[00:09:36.280 --> 00:09:43.280]   Now, oh, now this is really looking at a poster for a Mr. Gano concert.
[00:09:43.280 --> 00:09:45.000]   Is that a real person?
[00:09:45.000 --> 00:09:49.280]   And he's going to any book tickets just like that.
[00:09:49.280 --> 00:09:52.000]   He's in a bookstore and it's showing him where to go.
[00:09:52.000 --> 00:09:53.000]   Oh, yes.
[00:09:53.000 --> 00:09:54.000]   This is it.
[00:09:54.000 --> 00:09:56.000]   Now he's learning to play the ukulele.
[00:09:56.000 --> 00:09:57.000]   It's all here yet?
[00:09:57.000 --> 00:09:58.000]   He's talking to himself.
[00:09:58.000 --> 00:09:59.000]   He would have gotten the book out.
[00:09:59.000 --> 00:10:00.000]   He would have seen the barcode.
[00:10:00.000 --> 00:10:02.000]   He would have found the cheaper price at another point.
[00:10:02.000 --> 00:10:04.160]   All four and a two feet away.
[00:10:04.160 --> 00:10:05.160]   There's Paul.
[00:10:05.160 --> 00:10:06.320]   I'm going to play on that new play.
[00:10:06.320 --> 00:10:07.320]   No facial recognition.
[00:10:07.320 --> 00:10:08.320]   No, this is Paul.
[00:10:08.320 --> 00:10:09.320]   Yeah.
[00:10:09.320 --> 00:10:10.320]   It's a jerk.
[00:10:10.320 --> 00:10:11.320]   None of that.
[00:10:11.320 --> 00:10:15.160]   He's loading the taco truck to see if it's okay.
[00:10:15.160 --> 00:10:16.160]   He's checking in on you.
[00:10:16.160 --> 00:10:18.640]   This is your, what is mud?
[00:10:18.640 --> 00:10:19.640]   Coffee?
[00:10:19.640 --> 00:10:20.640]   Coffee.
[00:10:20.640 --> 00:10:21.640]   Is he getting coffee?
[00:10:21.640 --> 00:10:22.640]   What do you call it?
[00:10:22.640 --> 00:10:23.640]   Coffee light?
[00:10:23.640 --> 00:10:24.640]   Well, light and sweet.
[00:10:24.640 --> 00:10:25.640]   Light and sweet.
[00:10:25.640 --> 00:10:26.640]   Take a photo with us.
[00:10:26.640 --> 00:10:28.640]   He's going to take a photo with his glasses.
[00:10:28.640 --> 00:10:33.240]   Sharing it to his circles because he's the last person still using Google+.
[00:10:33.240 --> 00:10:35.280]   Oh, I'm really late.
[00:10:35.280 --> 00:10:37.280]   Oh, music.
[00:10:37.280 --> 00:10:38.640]   That'll get your pulled off.
[00:10:38.640 --> 00:10:39.640]   You do.
[00:10:39.640 --> 00:10:41.160]   Wait a minute.
[00:10:41.160 --> 00:10:42.920]   Jessica wants to talk.
[00:10:42.920 --> 00:10:43.920]   Hi.
[00:10:43.920 --> 00:10:44.920]   What's up?
[00:10:44.920 --> 00:10:45.920]   Hey.
[00:10:45.920 --> 00:10:49.600]   He's actually seeing video of Jessica while he apparently he's kind of playing suicide.
[00:10:49.600 --> 00:10:51.480]   But Jessica is going to, is he going to jump?
[00:10:51.480 --> 00:10:55.440]   Oh, he's learning the ukulele and jumping.
[00:10:55.440 --> 00:10:58.800]   And he's playing the Google theme on his ukulele.
[00:10:58.800 --> 00:11:01.000]   He's a fast learner.
[00:11:01.000 --> 00:11:03.200]   And she's, she thinks it's adorable.
[00:11:03.200 --> 00:11:06.200]   G.CO/ProjectGlass.
[00:11:06.200 --> 00:11:10.040]   There, I give him even a promotional plug.
[00:11:10.040 --> 00:11:12.400]   So this is what we want.
[00:11:12.400 --> 00:11:15.040]   In that video, they never show the glasses.
[00:11:15.040 --> 00:11:18.120]   But this is what the picture in the times is of the glasses.
[00:11:18.120 --> 00:11:21.400]   These don't look like the Oakleys that we thought they were.
[00:11:21.400 --> 00:11:24.720]   In fact, they look particularly dorky.
[00:11:24.720 --> 00:11:26.720]   She looks like seven of nine.
[00:11:26.720 --> 00:11:30.400]   It's like a half of Jordy LaForge's visor, you know, kind of on one side of your face.
[00:11:30.400 --> 00:11:32.160]   It's very Borgish.
[00:11:32.160 --> 00:11:36.920]   What the hell?
[00:11:36.920 --> 00:11:39.520]   So anyway, this is, go ahead.
[00:11:39.520 --> 00:11:41.640]   They're, they're not as bad as I thought.
[00:11:41.640 --> 00:11:43.400]   They're not as bad as they could have been.
[00:11:43.400 --> 00:11:44.400]   Style-wise.
[00:11:44.400 --> 00:11:48.600]   I don't, I don't like that the, that there's only one side that has the camera, you know,
[00:11:48.600 --> 00:11:52.440]   the bit, the bit of hardware that's required to have the camera and all that.
[00:11:52.440 --> 00:11:56.280]   I want our audience to imagine that we're all, all of us on the show now are wearing
[00:11:56.280 --> 00:11:57.280]   them now.
[00:11:57.280 --> 00:11:58.280]   We're all wearing them.
[00:11:58.280 --> 00:11:59.280]   We soon will be.
[00:11:59.280 --> 00:12:02.800]   So, and by the way, doesn't work with an iPhone, I presume.
[00:12:02.800 --> 00:12:04.840]   You have to have an Android phone.
[00:12:04.840 --> 00:12:08.280]   That's where all this, all of this power is coming from.
[00:12:08.280 --> 00:12:12.840]   The glass is, can stream information of the lenses and allow the wearer to send and receive
[00:12:12.840 --> 00:12:14.520]   messages through voice command.
[00:12:14.520 --> 00:12:19.400]   There's a built in camera to record video and take pictures.
[00:12:19.400 --> 00:12:21.480]   And there you go.
[00:12:21.480 --> 00:12:26.680]   I want project glass.
[00:12:26.680 --> 00:12:31.920]   They also say it could hypothetically become project contact lens.
[00:12:31.920 --> 00:12:34.720]   People are rebuilding, not Google, but Nick does.
[00:12:34.720 --> 00:12:41.080]   He quotes a professor at the University of Washington who specializes in, well, you know
[00:12:41.080 --> 00:12:44.440]   why, bio-nano technology.
[00:12:44.440 --> 00:12:49.680]   Thanks to the miracles of bio-nano technology, which is the fusion of tiny technologies.
[00:12:49.680 --> 00:12:50.680]   Get the lens.
[00:12:50.680 --> 00:12:51.680]   It's hard wire straight in.
[00:12:51.680 --> 00:12:52.680]   Where's the USB port?
[00:12:52.680 --> 00:12:53.680]   I'm here.
[00:12:53.680 --> 00:12:54.680]   I missed it somewhere.
[00:12:54.680 --> 00:12:56.560]   Here's Professor Párez's lens.
[00:12:56.560 --> 00:13:00.040]   It's, you put that in your eye and shove it.
[00:13:00.040 --> 00:13:03.680]   Smoke it, whatever it is.
[00:13:03.680 --> 00:13:05.680]   So these are, you know, they're interesting.
[00:13:05.680 --> 00:13:06.680]   These are cool.
[00:13:06.680 --> 00:13:09.280]   I mean, the chat room said, come on.
[00:13:09.280 --> 00:13:12.560]   The reality is I'm dying to try this out.
[00:13:12.560 --> 00:13:13.560]   Dying to myself.
[00:13:13.560 --> 00:13:15.480]   I would buy these in a second if I could.
[00:13:15.480 --> 00:13:17.680]   And I really hope that they are going to be at Google I/O.
[00:13:17.680 --> 00:13:18.680]   Wouldn't that be awesome.
[00:13:18.680 --> 00:13:22.920]   If not, the giveaway, then at least a couple of prototypes that people can try out, you
[00:13:22.920 --> 00:13:23.920]   know, on the floor.
[00:13:23.920 --> 00:13:26.360]   What would you page, you know?
[00:13:26.360 --> 00:13:27.840]   Hmm.
[00:13:27.840 --> 00:13:30.080]   At least as much as you paid for your phone, right?
[00:13:30.080 --> 00:13:31.760]   Yeah, I mean, I would think so.
[00:13:31.760 --> 00:13:34.480]   So, Leo, you're saying that it connects to your phone.
[00:13:34.480 --> 00:13:35.640]   So it's like Bluetooth connection to your phone.
[00:13:35.640 --> 00:13:37.040]   That's my understanding, yeah.
[00:13:37.040 --> 00:13:38.040]   Yeah, yeah, yeah.
[00:13:38.040 --> 00:13:39.040]   It makes sense.
[00:13:39.040 --> 00:13:40.040]   You're not going to put all the CPU in there.
[00:13:40.040 --> 00:13:43.680]   And by the way, you might want to sell some Android phones while you're at it.
[00:13:43.680 --> 00:13:44.680]   Well, right.
[00:13:44.680 --> 00:13:45.680]   Yeah, that makes sense.
[00:13:45.680 --> 00:13:48.800]   I would probably pay as much as my phone, although I'm a little crazy.
[00:13:48.800 --> 00:13:50.360]   I don't know if a regular consumer would.
[00:13:50.360 --> 00:13:52.080]   I pay a thousand dollars for these.
[00:13:52.080 --> 00:13:53.080]   Are you kidding?
[00:13:53.080 --> 00:13:54.080]   Yeah, that's what I'm saying.
[00:13:54.080 --> 00:13:55.080]   I'd pay a thousand dollars.
[00:13:55.080 --> 00:13:56.080]   The issue is not the cost.
[00:13:56.080 --> 00:13:58.080]   Well, I'm made of money, Matthew.
[00:13:58.080 --> 00:14:00.920]   But, Gina, would you wear them all the time?
[00:14:00.920 --> 00:14:03.680]   Or would you just try them out now and then?
[00:14:03.680 --> 00:14:05.200]   Well, I don't know.
[00:14:05.200 --> 00:14:06.200]   I don't know.
[00:14:06.200 --> 00:14:08.640]   I really would have to try them to see how they really work in real life.
[00:14:08.640 --> 00:14:11.760]   I mean, you know, there's, you have to think about kind of remember the Google TV demo
[00:14:11.760 --> 00:14:12.760]   problem.
[00:14:12.760 --> 00:14:14.760]   I mean, like, you know, it's like in theory, this looks really great.
[00:14:14.760 --> 00:14:15.760]   Exactly.
[00:14:15.760 --> 00:14:16.760]   It was going to be my phone.
[00:14:16.760 --> 00:14:18.680]   These glasses, that demo video is amazing.
[00:14:18.680 --> 00:14:20.680]   But are they really going to work that way?
[00:14:20.680 --> 00:14:22.000]   Yeah, absolutely not.
[00:14:22.000 --> 00:14:23.000]   Of course not.
[00:14:23.000 --> 00:14:24.240]   Well, you know.
[00:14:24.240 --> 00:14:25.320]   And that's totally the issue.
[00:14:25.320 --> 00:14:26.320]   It's not the price.
[00:14:26.320 --> 00:14:27.320]   Right.
[00:14:27.320 --> 00:14:28.320]   It's doesn't work.
[00:14:28.320 --> 00:14:33.280]   I mean, so you go to the subway entrance, you know, and there's just a spinning colored
[00:14:33.280 --> 00:14:34.280]   ball or something.
[00:14:34.280 --> 00:14:37.480]   You're waiting for it to tell you, should I get on the subway or not?
[00:14:37.480 --> 00:14:38.480]   Right.
[00:14:38.480 --> 00:14:41.560]   This is going to change the way we build cities.
[00:14:41.560 --> 00:14:46.520]   Yeah, I mean, you know, a lot of it has to do with your data connection, whether or
[00:14:46.520 --> 00:14:49.440]   not you're in a city where it's going to recognize the subway that you're getting on
[00:14:49.440 --> 00:14:53.160]   or if you even take the subway, if all your friends actually do share their location on
[00:14:53.160 --> 00:14:55.160]   Google Latitude down to the foot.
[00:14:55.160 --> 00:14:56.840]   So I can say, where is my friend?
[00:14:56.840 --> 00:15:01.120]   I found it wonderfully sort of charming and ironic that the demo video was of this guy
[00:15:01.120 --> 00:15:06.360]   going to a bookstore to buy a book on how to play the Yuke.
[00:15:06.360 --> 00:15:10.440]   And it wasn't just like, hey, download a book to my Android phone from the Google Play
[00:15:10.440 --> 00:15:12.320]   market on how to play a Yuke.
[00:15:12.320 --> 00:15:13.320]   Clearly.
[00:15:13.320 --> 00:15:17.480]   But, you know, I'm really interested in what the experience is for my eyeballs to focus
[00:15:17.480 --> 00:15:21.760]   in on the heads of display versus what I'm trying to look at.
[00:15:21.760 --> 00:15:25.400]   And a lot of people brought up the awkwardness of just speaking into a device, you know,
[00:15:25.400 --> 00:15:27.160]   like talking, but we've done that.
[00:15:27.160 --> 00:15:28.160]   Wait a minute.
[00:15:28.160 --> 00:15:29.160]   So I thought it was crazy.
[00:15:29.160 --> 00:15:32.720]   Everybody's wearing these little Bluetooth things and you see crazy people walking and
[00:15:32.720 --> 00:15:34.400]   we got pretty used to it, didn't we?
[00:15:34.400 --> 00:15:35.400]   Yeah, we got used to.
[00:15:35.400 --> 00:15:37.400]   But come on, everybody might make fun of those people.
[00:15:37.400 --> 00:15:40.640]   Well, yeah, but if you're a Bluetooth guy, you don't care.
[00:15:40.640 --> 00:15:41.640]   Right.
[00:15:41.640 --> 00:15:44.360]   You're busy driving your cab.
[00:15:44.360 --> 00:15:47.720]   Hawaii Dave in our chat room said something I think that's kind of telling.
[00:15:47.720 --> 00:15:50.440]   I'd buy it if it came from Apple.
[00:15:50.440 --> 00:15:51.440]   Right.
[00:15:51.440 --> 00:15:52.440]   Right.
[00:15:52.440 --> 00:15:53.440]   Isn't that the case?
[00:15:53.440 --> 00:15:54.440]   Good point.
[00:15:54.440 --> 00:15:58.560]   Is that because Google has a reputation for putting out half fake products that break
[00:15:58.560 --> 00:16:05.840]   them getting to boot loops later?
[00:16:05.840 --> 00:16:09.520]   I'd buy it if it came from, you know, if it came from Apple would, you know, then it
[00:16:09.520 --> 00:16:11.280]   would be at least to be kind of work.
[00:16:11.280 --> 00:16:14.880]   Well, and the other part of it is that, especially when these first get released, people are
[00:16:14.880 --> 00:16:15.880]   going to notice them.
[00:16:15.880 --> 00:16:16.880]   They look different.
[00:16:16.880 --> 00:16:17.880]   They look a little weird.
[00:16:17.880 --> 00:16:21.520]   They're you're going to spend more most of your time explaining what's on your face,
[00:16:21.520 --> 00:16:23.640]   you know, maybe then actually getting value out of them.
[00:16:23.640 --> 00:16:27.440]   So, but do I love to fantasize about a world where everybody has one of these and it's
[00:16:27.440 --> 00:16:29.520]   just kind of a normal way of interacting?
[00:16:29.520 --> 00:16:30.520]   Absolutely.
[00:16:30.520 --> 00:16:33.680]   I think if somebody asks you, you say they're my Google, Google, Google glasses, like,
[00:16:33.680 --> 00:16:36.640]   yeah, they're my Google goggles and then leave it at that.
[00:16:36.640 --> 00:16:37.640]   And that'll take you.
[00:16:37.640 --> 00:16:39.960]   Now, my question is, I'm trying to understand this.
[00:16:39.960 --> 00:16:42.760]   I see the guy's eye.
[00:16:42.760 --> 00:16:43.960]   Do you how does this work?
[00:16:43.960 --> 00:16:46.080]   Are you looking up through the?
[00:16:46.080 --> 00:16:47.080]   I don't know.
[00:16:47.080 --> 00:16:48.640]   No, I think you look at the look of the video.
[00:16:48.640 --> 00:16:50.920]   It was just it was just it's projected on.
[00:16:50.920 --> 00:16:53.240]   So is it projecting this into my retina?
[00:16:53.240 --> 00:16:56.600]   Yeah, in your eye.
[00:16:56.600 --> 00:16:58.080]   And then so I'm looking straight.
[00:16:58.080 --> 00:16:59.800]   It's a heads up display.
[00:16:59.800 --> 00:17:00.800]   Right.
[00:17:00.800 --> 00:17:03.200]   Is it projecting your eye or is it?
[00:17:03.200 --> 00:17:04.960]   Is it reflective on the glasses?
[00:17:04.960 --> 00:17:07.160]   So he's looking at stuff.
[00:17:07.160 --> 00:17:08.160]   This is bogus.
[00:17:08.160 --> 00:17:10.360]   I was not going to look for this.
[00:17:10.360 --> 00:17:12.280]   But that looks like that.
[00:17:12.280 --> 00:17:17.320]   I mean, that's an overlay over his, you know, but if you look at these glasses, we're not
[00:17:17.320 --> 00:17:20.120]   they're not looking through the glasses at me.
[00:17:20.120 --> 00:17:21.120]   They're looking at me.
[00:17:21.120 --> 00:17:23.280]   I think they're looking at a little, I don't know.
[00:17:23.280 --> 00:17:26.160]   The old ones, you had a literally a little screen up here.
[00:17:26.160 --> 00:17:27.160]   Right.
[00:17:27.160 --> 00:17:28.160]   These in neither case.
[00:17:28.160 --> 00:17:30.640]   Look at that little thing that's over her eye.
[00:17:30.640 --> 00:17:33.080]   I don't know that you're not looking at a little screen up there.
[00:17:33.080 --> 00:17:34.400]   So you would look up to see it.
[00:17:34.400 --> 00:17:35.400]   Yeah, it looks like.
[00:17:35.400 --> 00:17:39.320]   The New York Times New York Times article makes it sound like it's projecting information
[00:17:39.320 --> 00:17:40.320]   on a screen.
[00:17:40.320 --> 00:17:42.280]   Yeah, I think it's a little screen.
[00:17:42.280 --> 00:17:45.320]   You can't really set it into your eye.
[00:17:45.320 --> 00:17:49.000]   You can actually, but I'll bet you $10 if you describe that to somebody, they wouldn't
[00:17:49.000 --> 00:17:52.240]   be, you know, optimistic about trying it out.
[00:17:52.240 --> 00:17:54.560]   It beams it right into your retina.
[00:17:54.560 --> 00:17:55.560]   All right.
[00:17:55.560 --> 00:17:58.200]   Well, as long as it's not doing it with a laser.
[00:17:58.200 --> 00:18:02.560]   I mean, you notice that things go kind of blurry in the background when in this video,
[00:18:02.560 --> 00:18:04.640]   I realize that this demo video is just a demo.
[00:18:04.640 --> 00:18:06.840]   It looks as if you have to focus on the screen.
[00:18:06.840 --> 00:18:07.840]   It's a focus.
[00:18:07.840 --> 00:18:08.840]   Focus on the screen.
[00:18:08.840 --> 00:18:11.360]   That's exactly what the Times article says.
[00:18:11.360 --> 00:18:12.360]   It's not.
[00:18:12.360 --> 00:18:16.880]   They're saying it's a well designed pair of wraparound glasses with a clear display that
[00:18:16.880 --> 00:18:19.640]   sits above the eye.
[00:18:19.640 --> 00:18:22.800]   The glasses can stream information to the lenses.
[00:18:22.800 --> 00:18:24.560]   I don't see any lenses.
[00:18:24.560 --> 00:18:26.520]   There's only one lens.
[00:18:26.520 --> 00:18:28.480]   Maybe there's maybe, yeah.
[00:18:28.480 --> 00:18:29.480]   Yeah.
[00:18:29.480 --> 00:18:30.480]   Yeah.
[00:18:30.480 --> 00:18:32.400]   That's what's really weird looking.
[00:18:32.400 --> 00:18:35.080]   Is your wearing glasses that actually don't have a lens?
[00:18:35.080 --> 00:18:37.080]   They have a Borg piece.
[00:18:37.080 --> 00:18:38.080]   Wow.
[00:18:38.080 --> 00:18:39.080]   A Borg piece.
[00:18:39.080 --> 00:18:40.720]   A Borg piece is really good.
[00:18:40.720 --> 00:18:43.120]   I am Borg.
[00:18:43.120 --> 00:18:45.600]   I am part human, part machine.
[00:18:45.600 --> 00:18:48.040]   Which part would you like to speak to today?
[00:18:48.040 --> 00:18:51.080]   You know the part I like the best was where you could just take a picture.
[00:18:51.080 --> 00:18:52.080]   Yeah.
[00:18:52.080 --> 00:18:55.200]   Because I know I see lots of things I want to take a picture of and then I have to get
[00:18:55.200 --> 00:18:58.480]   my phone out and then I have to, you know, be nice to just be able to look at something
[00:18:58.480 --> 00:18:59.480]   and say, take a picture.
[00:18:59.480 --> 00:19:00.480]   By voice command.
[00:19:00.480 --> 00:19:01.480]   Yeah.
[00:19:01.480 --> 00:19:03.200]   I wonder how good that camera is.
[00:19:03.200 --> 00:19:05.520]   Well, it's no bigger than the camera anywhere.
[00:19:05.520 --> 00:19:07.400]   I mean, it could be a very good camera.
[00:19:07.400 --> 00:19:08.400]   It could be.
[00:19:08.400 --> 00:19:09.400]   Could be.
[00:19:09.400 --> 00:19:11.000]   So the camera is record.
[00:19:11.000 --> 00:19:12.240]   No, okay.
[00:19:12.240 --> 00:19:15.000]   You have a combination of geo data and camera data, right?
[00:19:15.000 --> 00:19:17.880]   It's like your own self-driving car except you have feet still.
[00:19:17.880 --> 00:19:18.880]   Right?
[00:19:18.880 --> 00:19:21.000]   So it's combining the two.
[00:19:21.000 --> 00:19:25.720]   The question is, do you want to be 1.0 of nine?
[00:19:25.720 --> 00:19:29.160]   Do you or .01 of nine?
[00:19:29.160 --> 00:19:32.560]   I'll wait till it's seven.
[00:19:32.560 --> 00:19:33.560]   Eight.
[00:19:33.560 --> 00:19:37.000]   Then once it's seven, it'll be safe.
[00:19:37.000 --> 00:19:38.000]   That's seven.
[00:19:38.000 --> 00:19:44.040]   For my 1.0 of any version 1.0 of nine.
[00:19:44.040 --> 00:19:45.040]   You know what?
[00:19:45.040 --> 00:19:47.240]   We should get Jerry Ryan on the show.
[00:19:47.240 --> 00:19:48.880]   Ask her what she would do.
[00:19:48.880 --> 00:19:53.720]   Have you ever heard of Steve Mann, the University of Toronto professor in the cyborg?
[00:19:53.720 --> 00:19:54.720]   Yeah.
[00:19:54.720 --> 00:19:55.720]   He was at MIT, right?
[00:19:55.720 --> 00:19:57.200]   He was a guy who walked around all the time.
[00:19:57.200 --> 00:19:58.200]   Now he's a Toronto.
[00:19:58.200 --> 00:20:02.680]   When he first started, he had this huge headset and a giant backpack and it weighed about
[00:20:02.680 --> 00:20:04.320]   100 pounds.
[00:20:04.320 --> 00:20:08.120]   And then eventually it was just basically glasses like that.
[00:20:08.120 --> 00:20:09.120]   Wow.
[00:20:09.120 --> 00:20:12.520]   Matthew Ingram is here from Gig Aome.
[00:20:12.520 --> 00:20:14.280]   We love Gig Aome.
[00:20:14.280 --> 00:20:16.400]   Gig Aome.com.
[00:20:16.400 --> 00:20:17.800]   What's your beat, Matthew?
[00:20:17.800 --> 00:20:20.360]   Did you get to cover anything you feel like?
[00:20:20.360 --> 00:20:22.560]   My beat is the internet.
[00:20:22.560 --> 00:20:23.760]   The internet.
[00:20:23.760 --> 00:20:25.760]   I'm in charge of the internet, says Matthew.
[00:20:25.760 --> 00:20:28.160]   I guess, you know, media is my thing.
[00:20:28.160 --> 00:20:29.160]   Oh, come on.
[00:20:29.160 --> 00:20:30.720]   But everything's media, right?
[00:20:30.720 --> 00:20:31.720]   Anything.
[00:20:31.720 --> 00:20:32.720]   You cover everything.
[00:20:32.720 --> 00:20:33.720]   Everything and nothing.
[00:20:33.720 --> 00:20:34.720]   There's no media.
[00:20:34.720 --> 00:20:35.920]   There is no media.
[00:20:35.920 --> 00:20:39.480]   If it doesn't drop when you break it, it's part of my view.
[00:20:39.480 --> 00:20:43.120]   It doesn't break when you drop it.
[00:20:43.120 --> 00:20:44.720]   I like drop when you break it.
[00:20:44.720 --> 00:20:46.800]   Yeah, I like that too.
[00:20:46.800 --> 00:20:47.800]   So is Jeff Jarvis?
[00:20:47.800 --> 00:20:48.800]   So is Gina Trapani?
[00:20:48.800 --> 00:20:52.760]   We're going to talk about Larry Page and his one-year anniversary as CEO.
[00:20:52.760 --> 00:20:54.280]   What's the report card that's next?
[00:20:54.280 --> 00:20:58.320]   But first, let's tell you how you never have to go to the post office again.
[00:20:58.320 --> 00:21:00.960]   I'm not talking forever, Stamps.
[00:21:00.960 --> 00:21:06.480]   I'm talking, bringing the post office to your desk so that all everything you need to do,
[00:21:06.480 --> 00:21:08.840]   you can do right here with your computer and your printer.
[00:21:08.840 --> 00:21:09.840]   It's Stamps.com.
[00:21:09.840 --> 00:21:11.440]   Mac or PC.
[00:21:11.440 --> 00:21:18.800]   It lets you print real US postage for a letter, a package, anything, a post card.
[00:21:18.800 --> 00:21:22.200]   You've got a USB scale that goes right into the computer so you drop the thing on the
[00:21:22.200 --> 00:21:23.200]   scale.
[00:21:23.200 --> 00:21:25.080]   That means exactly right if you're mailing internationally.
[00:21:25.080 --> 00:21:27.200]   You know what a hassle that is.
[00:21:27.200 --> 00:21:30.000]   If you want to mail something to England, you have to go to the post office.
[00:21:30.000 --> 00:21:31.560]   They get the international postage.
[00:21:31.560 --> 00:21:32.880]   You've got to fill out forms.
[00:21:32.880 --> 00:21:34.120]   Stamps.com does it for you.
[00:21:34.120 --> 00:21:35.440]   You don't have to go to the post office.
[00:21:35.440 --> 00:21:37.560]   In fact, there's nothing you can do at the post office.
[00:21:37.560 --> 00:21:40.160]   You can't do at your desk with Stamps.com.
[00:21:40.160 --> 00:21:43.480]   Even post 9/11, I tried this.
[00:21:43.480 --> 00:21:47.280]   You can't mail a package more than 13 ounces in a mailbox because they're worried about
[00:21:47.280 --> 00:21:48.880]   whatever.
[00:21:48.880 --> 00:21:50.520]   You can with Stamps.com.
[00:21:50.520 --> 00:21:57.160]   In fact, because it's got an indicia on it so there's not any information so they're comfortable.
[00:21:57.160 --> 00:21:58.360]   It's got a barcode on.
[00:21:58.360 --> 00:21:59.360]   They're comfortable with that.
[00:21:59.360 --> 00:22:01.440]   In fact, the mail carrier comes to you and takes anything you want.
[00:22:01.440 --> 00:22:02.440]   A 100 pound packet.
[00:22:02.440 --> 00:22:03.440]   No problem.
[00:22:03.440 --> 00:22:04.440]   We trust you.
[00:22:04.440 --> 00:22:05.480]   You're using Stamps.com.
[00:22:05.480 --> 00:22:06.640]   You also get discounts.
[00:22:06.640 --> 00:22:09.000]   You cannot get anywhere else.
[00:22:09.000 --> 00:22:12.800]   The post office will not give you up to 21% on Express mail.
[00:22:12.800 --> 00:22:15.160]   Up to 15% off on priority mail.
[00:22:15.160 --> 00:22:16.160]   No, but Stamps.com.
[00:22:16.160 --> 00:22:17.640]   Well, all right.
[00:22:17.640 --> 00:22:19.200]   So look, this is cool.
[00:22:19.200 --> 00:22:20.200]   You don't need special ink.
[00:22:20.200 --> 00:22:21.200]   You get postage meter.
[00:22:21.200 --> 00:22:22.880]   Get rid of the postage meter.
[00:22:22.880 --> 00:22:25.720]   You just need Stamps.com, a computer and a printer.
[00:22:25.720 --> 00:22:26.720]   You get the scale.
[00:22:26.720 --> 00:22:27.720]   I get a deal.
[00:22:27.720 --> 00:22:29.840]   Now see right there on the page at Stamps.com since $80.
[00:22:29.840 --> 00:22:30.980]   Forget that.
[00:22:30.980 --> 00:22:32.840]   Click the microphone up at the top there.
[00:22:32.840 --> 00:22:36.240]   Don't do the $80 deal and put twig to your IG.
[00:22:36.240 --> 00:22:37.200]   Eileen's going to do it right now.
[00:22:37.200 --> 00:22:38.680]   I've convinced her.
[00:22:38.680 --> 00:22:39.680]   And then look what you get.
[00:22:39.680 --> 00:22:41.840]   First of all, a lovely picture of me.
[00:22:41.840 --> 00:22:42.840]   No.
[00:22:42.840 --> 00:22:44.480]   Aw.
[00:22:44.480 --> 00:22:46.680]   Used to get a picture of me.
[00:22:46.680 --> 00:22:53.760]   Now all you get is $110 bonus offer, including $55 free postage and the scale.
[00:22:53.760 --> 00:22:55.480]   All you have to do is pay for your shipping and handling.
[00:22:55.480 --> 00:22:58.680]   It's you have a couple of bucks and a month of Stamps.com.
[00:22:58.680 --> 00:22:59.680]   This is a great deal.
[00:22:59.680 --> 00:23:01.600]   $55 in free postage.
[00:23:01.600 --> 00:23:03.600]   Come on.
[00:23:03.600 --> 00:23:07.240]   That's going to get you a couple of months of postage right there.
[00:23:07.240 --> 00:23:09.640]   If you're an eBay seller, this is great at Amazon.
[00:23:09.640 --> 00:23:10.800]   That's great.
[00:23:10.800 --> 00:23:12.320]   Stamps.com.
[00:23:12.320 --> 00:23:15.480]   Click the funny looking microphone in the upper right hand corner.
[00:23:15.480 --> 00:23:17.920]   Use the offer code twig for $110.
[00:23:17.920 --> 00:23:23.240]   No risk trial, including the scale and $55 free postage.
[00:23:23.240 --> 00:23:24.240]   Stamps.com.
[00:23:24.240 --> 00:23:27.000]   Don't put it off.
[00:23:27.000 --> 00:23:29.360]   I cannot promise you how long this is going to last.
[00:23:29.360 --> 00:23:30.360]   You've got to do it.
[00:23:30.360 --> 00:23:31.360]   Do not delay.
[00:23:31.360 --> 00:23:33.440]   And I'm telling you, you'll thank me.
[00:23:33.440 --> 00:23:37.480]   Because I think they're changing the price and the stamps soon and they're closing posts.
[00:23:37.480 --> 00:23:41.720]   Two out of the three post offices in Petaluma are slated for closing.
[00:23:41.720 --> 00:23:45.440]   In June, Iran, if everybody's interested in this, I helped organize a conference.
[00:23:45.440 --> 00:23:47.440]   I'm Washington called Postal Vision 2020.
[00:23:47.440 --> 00:23:48.440]   You're kidding.
[00:23:48.440 --> 00:23:49.440]   No.
[00:23:49.440 --> 00:23:54.360]   Because some guy named John Callan read what we will do and said, you know, he was at
[00:23:54.360 --> 00:23:59.040]   a conference where somebody asked the head of the regulatory commission in the US, what
[00:23:59.040 --> 00:24:00.440]   would Google do if they own post office?
[00:24:00.440 --> 00:24:01.440]   Oh, how interesting.
[00:24:01.440 --> 00:24:05.280]   Well, they'd give everybody a computer and a printer.
[00:24:05.280 --> 00:24:06.360]   And he thought they read the book.
[00:24:06.360 --> 00:24:07.360]   They hadn't.
[00:24:07.360 --> 00:24:08.360]   So he gave them a copy.
[00:24:08.360 --> 00:24:10.360]   And I find it so fascinating.
[00:24:10.360 --> 00:24:12.640]   It's such a disrupted industry on the one hand.
[00:24:12.640 --> 00:24:16.680]   On the other hand, it's disrupting retail on the parcel end.
[00:24:16.680 --> 00:24:20.760]   And so if anybody's fascinated with this, as I am, there's huge, I think disruptive
[00:24:20.760 --> 00:24:24.080]   entrepreneurial opportunities in this area, Postal Vision 2020.
[00:24:24.080 --> 00:24:27.040]   I'm not making any money off of it, but I just find it to be a fascinating topic.
[00:24:27.040 --> 00:24:28.040]   This June.
[00:24:28.040 --> 00:24:29.040]   This June.
[00:24:29.040 --> 00:24:30.040]   Cool.
[00:24:30.040 --> 00:24:32.560]   I think actually it is a very interesting area.
[00:24:32.560 --> 00:24:34.120]   It really actually is.
[00:24:34.120 --> 00:24:40.200]   Because when you realize how much of the Postal Service is subsidized by first class, by
[00:24:40.200 --> 00:24:43.760]   the notion of number one, a letter, what's that?
[00:24:43.760 --> 00:24:45.640]   And then number two, bills.
[00:24:45.640 --> 00:24:46.640]   Right.
[00:24:46.640 --> 00:24:47.640]   You have to get--
[00:24:47.640 --> 00:24:48.640]   Right.
[00:24:48.640 --> 00:24:49.640]   Right.
[00:24:49.640 --> 00:24:50.640]   Take that high--
[00:24:50.640 --> 00:24:52.400]   All I get now is junk mail.
[00:24:52.400 --> 00:24:53.840]   It's the only thing I get in the mail.
[00:24:53.840 --> 00:24:54.840]   Right.
[00:24:54.840 --> 00:24:57.920]   And so that's essentially been subsidized by first class.
[00:24:57.920 --> 00:24:58.920]   And I don't want to--
[00:24:58.920 --> 00:25:00.520]   And there's no first class anymore.
[00:25:00.520 --> 00:25:01.520]   Right.
[00:25:01.520 --> 00:25:05.480]   So the economics of the Postal Department, all of that infrastructure that they have
[00:25:05.480 --> 00:25:07.400]   that they don't really need anymore.
[00:25:07.400 --> 00:25:08.400]   So what do you do?
[00:25:08.400 --> 00:25:10.560]   You put post offices in Walgreens.
[00:25:10.560 --> 00:25:12.880]   Put it on your desk.
[00:25:12.880 --> 00:25:13.880]   You just set it.
[00:25:13.880 --> 00:25:14.880]   Computer prayer.
[00:25:14.880 --> 00:25:15.880]   Bingo.
[00:25:15.880 --> 00:25:16.880]   Bingo.
[00:25:16.880 --> 00:25:17.880]   You don't need to put it anywhere.
[00:25:17.880 --> 00:25:22.120]   And so literally if the Postal Department gave you a constant discount to use stamps.com,
[00:25:22.120 --> 00:25:24.960]   not to plug the sponsor to use them.
[00:25:24.960 --> 00:25:25.960]   They do, by the way.
[00:25:25.960 --> 00:25:26.960]   Right.
[00:25:26.960 --> 00:25:29.760]   I mean, so the constant discount, at some point you're going to change the economics
[00:25:29.760 --> 00:25:32.160]   so that why would you go to the post office?
[00:25:32.160 --> 00:25:35.320]   The value of the post offices, you've got a bunch of people running around in little
[00:25:35.320 --> 00:25:40.280]   trucks, they could figure out how to capitalize on that, get rid of everything else.
[00:25:40.280 --> 00:25:43.840]   But they could be delivering ice cream.
[00:25:43.840 --> 00:25:47.600]   Think about that.
[00:25:47.600 --> 00:25:51.600]   Or you get the Schwann guy to start delivering mail, either way, one or the other.
[00:25:51.600 --> 00:25:54.680]   Milkman, bring back the milkman to get the occasional letter.
[00:25:54.680 --> 00:25:55.680]   Oh man.
[00:25:55.680 --> 00:25:58.880]   But you knew the milkman was in trouble when they started adding products, like they started
[00:25:58.880 --> 00:26:01.200]   doing milk shampoo.
[00:26:01.200 --> 00:26:06.920]   That was when you knew there must be a problem in the fundamental economics of getting up
[00:26:06.920 --> 00:26:09.440]   in the morning and delivering milk to people.
[00:26:09.440 --> 00:26:11.840]   I think the post office is mandated by the Constitution.
[00:26:11.840 --> 00:26:12.840]   You're right.
[00:26:12.840 --> 00:26:14.360]   We need a constitutional amendment to get rid of it.
[00:26:14.360 --> 00:26:16.440]   But they can cut it back.
[00:26:16.440 --> 00:26:18.320]   You can have universal service other ways.
[00:26:18.320 --> 00:26:22.360]   You could subsidize UPS.
[00:26:22.360 --> 00:26:23.920]   Right.
[00:26:23.920 --> 00:26:27.200]   Not to go off this week and go in postal.
[00:26:27.200 --> 00:26:28.200]   Right.
[00:26:28.200 --> 00:26:29.720]   Hey, I like it.
[00:26:29.720 --> 00:26:30.720]   That's a good title.
[00:26:30.720 --> 00:26:31.720]   Yeah.
[00:26:31.720 --> 00:26:32.720]   Twig.
[00:26:32.720 --> 00:26:38.520]   So Larry Page, what was the actual date that he became?
[00:26:38.520 --> 00:26:39.800]   He's one year now, right?
[00:26:39.800 --> 00:26:40.960]   April 4th, right?
[00:26:40.960 --> 00:26:44.240]   So this is today is the anniversary.
[00:26:44.240 --> 00:26:47.480]   I'll have to give him a cake or something.
[00:26:47.480 --> 00:26:51.680]   He replaced, hard to believe it's been a year that he replaced Eric Schmidt as CEO of
[00:26:51.680 --> 00:26:52.960]   Google.
[00:26:52.960 --> 00:26:54.440]   What kind of year has it been?
[00:26:54.440 --> 00:27:00.680]   Matthew, what grade would we give Larry Page and his first year as the CEO?
[00:27:00.680 --> 00:27:02.400]   That's a good one.
[00:27:02.400 --> 00:27:08.040]   I'd have to say probably in the B+ range.
[00:27:08.040 --> 00:27:10.320]   Not perfect, huh?
[00:27:10.320 --> 00:27:11.320]   No.
[00:27:11.320 --> 00:27:16.440]   And I think there's some things he's done that I think some people would give high marks
[00:27:16.440 --> 00:27:23.240]   to, like say streamlining things, shutting down lots of products, lots of experiments,
[00:27:23.240 --> 00:27:25.000]   the labs and so on that.
[00:27:25.000 --> 00:27:26.360]   I kind of go back and forth on that.
[00:27:26.360 --> 00:27:28.040]   Is that a good thing or is it a bad thing?
[00:27:28.040 --> 00:27:32.760]   I actually think you could argue it's good that he streamlined the company and focused
[00:27:32.760 --> 00:27:33.760]   it and so on.
[00:27:33.760 --> 00:27:38.400]   But at the same time, I think a lot of those things were part of what made Google special.
[00:27:38.400 --> 00:27:44.240]   You know, like Google classes or the Google art project.
[00:27:44.240 --> 00:27:49.360]   I agree that -- and Stephen Levy's got a good article in the Wired about this.
[00:27:49.360 --> 00:27:54.280]   The pull quote is, "When I asked Larry last September what he thought was Google's threat,
[00:27:54.280 --> 00:27:57.680]   the answer was out of his mouth before I even finished the query."
[00:27:57.680 --> 00:27:59.800]   "Google," he said.
[00:27:59.800 --> 00:28:02.640]   The biggest threat to Google is Google.
[00:28:02.640 --> 00:28:03.640]   You agree, Jeff?
[00:28:03.640 --> 00:28:07.720]   Yeah, in fact, Eric Smith gave the same answer when I asked them that.
[00:28:07.720 --> 00:28:08.960]   So it's one area where they were.
[00:28:08.960 --> 00:28:09.960]   They were well alignment.
[00:28:09.960 --> 00:28:13.200]   And I think that's why they had the management change.
[00:28:13.200 --> 00:28:14.440]   Is it the management structure?
[00:28:14.440 --> 00:28:15.880]   And they said this at the time.
[00:28:15.880 --> 00:28:20.400]   It fulfilled its purpose for a while, but they were standing in the way of progress and
[00:28:20.400 --> 00:28:21.960]   focus and so on.
[00:28:21.960 --> 00:28:24.280]   So clearly, they knew they had to focus.
[00:28:24.280 --> 00:28:28.240]   That's why Larry has been so perhaps maniacal about focus.
[00:28:28.240 --> 00:28:34.880]   The hard part I have in judging his reign so far is separating out those things that came
[00:28:34.880 --> 00:28:35.880]   before it.
[00:28:35.880 --> 00:28:36.880]   All right?
[00:28:36.880 --> 00:28:41.800]   So buzz and the buzz screw up, I think, was a screw up before or certainly started before
[00:28:41.800 --> 00:28:43.800]   he was solely in charge.
[00:28:43.800 --> 00:28:48.040]   You know, we can get it back into the argument about whether they released credit privacy
[00:28:48.040 --> 00:28:49.040]   or not.
[00:28:49.040 --> 00:28:50.760]   I don't think they have.
[00:28:50.760 --> 00:28:54.040]   But I agree with Matthew.
[00:28:54.040 --> 00:28:58.240]   I'd say it's B plus because we're not even at the midterm yet.
[00:28:58.240 --> 00:29:02.600]   We're just barely into the first marking period.
[00:29:02.600 --> 00:29:04.600]   It's a thank you, Professor.
[00:29:04.600 --> 00:29:06.720]   I'll finish this homework.
[00:29:06.720 --> 00:29:09.760]   It's a mixed bag because on the one hand, I think you could say that he's done some
[00:29:09.760 --> 00:29:12.240]   good stuff focusing the company.
[00:29:12.240 --> 00:29:16.840]   But this has been the year that Google has suffered its biggest black marks of all, right,
[00:29:16.840 --> 00:29:17.840]   Gina?
[00:29:17.840 --> 00:29:18.840]   It is.
[00:29:18.840 --> 00:29:19.840]   And a lot of people would say that they're...
[00:29:19.840 --> 00:29:24.080]   I mean, what's the biggest product launch that Google's had in the past year?
[00:29:24.080 --> 00:29:25.280]   I mean, Google plus.
[00:29:25.280 --> 00:29:26.280]   Plus.
[00:29:26.280 --> 00:29:27.280]   Plus.
[00:29:27.280 --> 00:29:28.280]   And there's a lot that that's a mixed bag.
[00:29:28.280 --> 00:29:33.000]   So you could argue that that's the Google plus is the long term play and that the classification
[00:29:33.000 --> 00:29:38.120]   of everything is Google, you know, moving the shifting the entire company toward being
[00:29:38.120 --> 00:29:42.080]   more social and that, you know, even though people don't love it right at the moment,
[00:29:42.080 --> 00:29:43.240]   they will in the long term.
[00:29:43.240 --> 00:29:44.240]   So he's making the right decisions.
[00:29:44.240 --> 00:29:49.040]   At the same time, you can make the argument that Google plus was not a spectacular product
[00:29:49.040 --> 00:29:51.320]   that changed lives right away.
[00:29:51.320 --> 00:29:54.480]   You know, that that answer to that question, you know, what's Google's biggest challenge?
[00:29:54.480 --> 00:29:55.480]   Google.
[00:29:55.480 --> 00:29:59.120]   It's a good answer, but it also seems a little insular to me.
[00:29:59.120 --> 00:30:03.200]   I think maybe an honest answer would have included things like Facebook and Twitter.
[00:30:03.200 --> 00:30:05.400]   I mean, I think that that feeling is certainly...
[00:30:05.400 --> 00:30:06.800]   So that's a good point.
[00:30:06.800 --> 00:30:07.800]   Within the company?
[00:30:07.800 --> 00:30:08.800]   Yeah.
[00:30:08.800 --> 00:30:09.800]   That there...
[00:30:09.800 --> 00:30:14.800]   I mean, obviously Google plus was a response to feeling like Facebook was dominating an
[00:30:14.800 --> 00:30:18.320]   area that Google couldn't or didn't.
[00:30:18.320 --> 00:30:19.320]   So, so while...
[00:30:19.320 --> 00:30:24.120]   So I would say that I think a B plus is fair, is a fair mark for him.
[00:30:24.120 --> 00:30:28.240]   I think the focus on particular products, trimming the fat, all good things, at the
[00:30:28.240 --> 00:30:31.760]   same time, I mean, you know, somebody said, I forget, I mean, maybe it was Adam from LifeHacker
[00:30:31.760 --> 00:30:35.920]   said on Twitter that the April Fool's gags that Google did this past weekend, I mean,
[00:30:35.920 --> 00:30:39.920]   we're some of the best product announcements they've had in a really long time.
[00:30:39.920 --> 00:30:43.440]   And, you know, that says something.
[00:30:43.440 --> 00:30:50.080]   It was kind of stunning that we ran down all the Google April Fool's jokes on Twitter.
[00:30:50.080 --> 00:30:51.600]   It made me feel like, what are they doing?
[00:30:51.600 --> 00:30:54.840]   This seems like more energy was put into those April Fool's jokes and they put in everything
[00:30:54.840 --> 00:30:56.640]   else they've done all year.
[00:30:56.640 --> 00:30:57.640]   Yeah.
[00:30:57.640 --> 00:30:58.640]   Yeah.
[00:30:58.640 --> 00:30:59.640]   Yes.
[00:30:59.640 --> 00:31:00.640]   I'm really looking forward to IO.
[00:31:00.640 --> 00:31:02.200]   I think that Google Glasses is really cool.
[00:31:02.200 --> 00:31:06.800]   I'm interested to see things like Google Drive finally kind of come to fruition.
[00:31:06.800 --> 00:31:08.320]   And I'm not anti-Google plus.
[00:31:08.320 --> 00:31:13.480]   I just don't think that Google Plus was the big blockbuster that things like GML and
[00:31:13.480 --> 00:31:14.960]   Maps were kind of back in the day.
[00:31:14.960 --> 00:31:16.760]   It's starting to look like a spot.
[00:31:16.760 --> 00:31:17.760]   I think it's a spot.
[00:31:17.760 --> 00:31:18.760]   Yeah.
[00:31:18.760 --> 00:31:19.760]   And it is.
[00:31:19.760 --> 00:31:20.760]   It depends on where you look at it.
[00:31:20.760 --> 00:31:21.760]   It's not clear though, you know?
[00:31:21.760 --> 00:31:22.760]   No, it's not.
[00:31:22.760 --> 00:31:23.760]   It's not.
[00:31:23.760 --> 00:31:25.760]   You know, I think it's...
[00:31:25.760 --> 00:31:27.640]   Listen, they're clumsy with design.
[00:31:27.640 --> 00:31:29.280]   They're clumsy with announcements.
[00:31:29.280 --> 00:31:33.800]   And, you know, I'm hesitant to say that we need a Slicker Google, but we do.
[00:31:33.800 --> 00:31:34.800]   You just said that, right?
[00:31:34.800 --> 00:31:38.280]   All of the product announcements done for April Fool's were much Slicker.
[00:31:38.280 --> 00:31:39.960]   And Google does, but only does things.
[00:31:39.960 --> 00:31:41.760]   Google could get too slick.
[00:31:41.760 --> 00:31:44.320]   Part of what we like about it is that it's not fully slick.
[00:31:44.320 --> 00:31:49.680]   But let's just say that, yes, it needs to be Slicker.
[00:31:49.680 --> 00:31:51.400]   And that's true in all of these areas.
[00:31:51.400 --> 00:31:56.480]   You know, Google Plus, I still think has the essence of something.
[00:31:56.480 --> 00:31:59.720]   And I don't think that it is the anti-Facebook.
[00:31:59.720 --> 00:32:03.560]   My art, I've made this argument a hundred times in the show, but it's a single generation.
[00:32:03.560 --> 00:32:09.760]   And I say that Google Plus and Android are about, in terms of their product value, in
[00:32:09.760 --> 00:32:13.680]   terms of separate from monetary value, product value, are about bringing new data, new signals
[00:32:13.680 --> 00:32:19.160]   about people and content to Google.
[00:32:19.160 --> 00:32:23.120]   And that Google can measure the success or failure of Google Plus differently.
[00:32:23.120 --> 00:32:24.120]   Is it the new Facebook?
[00:32:24.120 --> 00:32:25.440]   No, it's never going to be that.
[00:32:25.440 --> 00:32:28.120]   I'll fully concede that, no problem.
[00:32:28.120 --> 00:32:30.440]   But does Google learn a lot from Google Plus?
[00:32:30.440 --> 00:32:34.520]   Does it bring new services, which they, again, to search, they make, you know, clumsily
[00:32:34.520 --> 00:32:38.200]   designed, badly designed, badly announced, badly let out?
[00:32:38.200 --> 00:32:39.200]   But is there potential there?
[00:32:39.200 --> 00:32:42.080]   I think it's way too soon to call it a flop.
[00:32:42.080 --> 00:32:47.680]   But you know, Jeff, it feels to me, like even your description sort of feels to me like,
[00:32:47.680 --> 00:32:51.000]   I know, and I've said this before, I know what Google is getting out of Google Plus.
[00:32:51.000 --> 00:32:52.880]   I know they're getting lots of my data.
[00:32:52.880 --> 00:32:59.120]   I know they're probably triangulating all sorts of things about me and my demographic
[00:32:59.120 --> 00:33:00.120]   or whatever.
[00:33:00.120 --> 00:33:03.160]   I don't actually sort of see what they're getting in terms of pulling in information.
[00:33:03.160 --> 00:33:06.040]   I don't actually see what I get out of it yet.
[00:33:06.040 --> 00:33:12.160]   What I get, and there's people who are denizens of it and like it, what I'm getting very simply
[00:33:12.160 --> 00:33:13.240]   is quality conversation.
[00:33:13.240 --> 00:33:16.600]   I get a better conversation on Google Plus than I get in my blog, which is mainly people
[00:33:16.600 --> 00:33:20.720]   who don't like me, and Twitter, which is, "Hey, look, there's a fight over there," which
[00:33:20.720 --> 00:33:24.120]   I'm really sick of.
[00:33:24.120 --> 00:33:33.040]   And there's other places where Hacker News or...
[00:33:33.040 --> 00:33:34.040]   Slash.
[00:33:34.040 --> 00:33:35.040]   Slash.
[00:33:35.040 --> 00:33:37.680]   Or Reddit, where you might have conversations you like.
[00:33:37.680 --> 00:33:39.280]   And now, but here's the huge caveat.
[00:33:39.280 --> 00:33:43.440]   Yes, I'm on the recommended list, and I just look just now.
[00:33:43.440 --> 00:33:44.920]   This should be my number of the day.
[00:33:44.920 --> 00:33:47.920]   No, go ahead, use it.
[00:33:47.920 --> 00:33:49.040]   We'll get another number for you.
[00:33:49.040 --> 00:33:50.040]   I got one.
[00:33:50.040 --> 00:33:56.120]   Because I just saw it just now, I just passed a million alleged followers on Google Plus.
[00:33:56.120 --> 00:33:57.120]   Now...
[00:33:57.120 --> 00:34:03.680]   I think you can make the case, though, that suggested user list is a sign of a problem,
[00:34:03.680 --> 00:34:07.000]   because I'm not on the suggested user list, and I'm totally stalled out at 287.
[00:34:07.000 --> 00:34:08.520]   Yes, I agree with that.
[00:34:08.520 --> 00:34:10.880]   And the thing about it is that it's also rather meaningless.
[00:34:10.880 --> 00:34:14.440]   I'm not in conversations with people who basically don't know.
[00:34:14.440 --> 00:34:17.800]   I'm in conversations with people who really do truly follow.
[00:34:17.800 --> 00:34:21.080]   And so I don't know how the algorithm is working and how much I'm really shown to people.
[00:34:21.080 --> 00:34:22.080]   I don't think it's much.
[00:34:22.080 --> 00:34:26.720]   So, yeah, I think that kind of absurdity of the list and that number is ridiculous.
[00:34:26.720 --> 00:34:32.840]   But I just go back to the bottom line for me, Matthew, I get good quality conversations
[00:34:32.840 --> 00:34:34.400]   out of Google Plus.
[00:34:34.400 --> 00:34:36.600]   And it depends on who you follow.
[00:34:36.600 --> 00:34:38.600]   Yeah, I think...
[00:34:38.600 --> 00:34:39.600]   Sorry.
[00:34:39.600 --> 00:34:40.600]   Sorry, go ahead, Jim.
[00:34:40.600 --> 00:34:43.200]   I was going to say, I think that the...
[00:34:43.200 --> 00:34:47.380]   We're defining participating on Google Plus, participating in the network the same way we
[00:34:47.380 --> 00:34:50.440]   define participating on Facebook or Twitter.
[00:34:50.440 --> 00:34:53.040]   And I think that it's actually a lot more than that.
[00:34:53.040 --> 00:34:57.160]   I think that just clicking, plus one on a link in your search results or checking in
[00:34:57.160 --> 00:35:03.660]   on Google Attitude on Android or, I don't know, clicking on somebody's circle information
[00:35:03.660 --> 00:35:04.660]   in your contacts.
[00:35:04.660 --> 00:35:09.600]   I think because Google Plus, like little bits of Google Plus are going to be part of every
[00:35:09.600 --> 00:35:13.360]   signal Google product, that in a lot of ways you're giving them signals and you're using
[00:35:13.360 --> 00:35:18.020]   the network without going to google, you know, plus.google.com and writing a post, right?
[00:35:18.020 --> 00:35:21.020]   Like that's a very active way to participate, but there are going to be very passive ways
[00:35:21.020 --> 00:35:23.820]   to participate, especially when you have, sorry, Jeff, this is your number.
[00:35:23.820 --> 00:35:27.300]   When you have more than 50% of smartphones or Android phones, what you're signed in your
[00:35:27.300 --> 00:35:30.180]   Google account already, you're signed into your Plus account.
[00:35:30.180 --> 00:35:32.420]   Your Google account is your Plus account, basically.
[00:35:32.420 --> 00:35:35.980]   So, you know, saying, "Hey, I'm at this great taco truck.
[00:35:35.980 --> 00:35:40.220]   Check me in," is a way to sort of participate, plus, especially with the privacy policy
[00:35:40.220 --> 00:35:41.220]   consolidation.
[00:35:41.220 --> 00:35:44.680]   Like, I get it, like, if I don't go to Google, yeah, I don't go to Google Plus, I don't
[00:35:44.680 --> 00:35:45.920]   write a whole lot of Google Plus.
[00:35:45.920 --> 00:35:49.760]   Really, I talk about Google because I know that that's my highest chances for Google
[00:35:49.760 --> 00:35:50.760]   employees.
[00:35:50.760 --> 00:35:53.200]   See what I have to say about Google is there on Plus.
[00:35:53.200 --> 00:35:57.080]   I'm still participating in the network in a lot of ways just by using all the different
[00:35:57.080 --> 00:35:59.200]   products because Google Plus is Google.
[00:35:59.200 --> 00:36:00.200]   Right.
[00:36:00.200 --> 00:36:04.080]   I totally use myself as a measure and that's the only way I can ever do anything.
[00:36:04.080 --> 00:36:07.960]   And I just notice, I just don't really feel the urge to go to Google.
[00:36:07.960 --> 00:36:11.340]   I used to check it every day with my homepage, still as my homepage, but I just don't feel
[00:36:11.340 --> 00:36:12.780]   the urge to check that much.
[00:36:12.780 --> 00:36:15.020]   I don't know about some gene, what Gene just said.
[00:36:15.020 --> 00:36:23.300]   I think it's now tie-in, Gene, what you just said to the demo video we watched of the classes.
[00:36:23.300 --> 00:36:25.900]   Yeah, I mean, that was all Google Plus going on there.
[00:36:25.900 --> 00:36:26.900]   Exactly.
[00:36:26.900 --> 00:36:32.000]   And there's no web page, there's no tech stuff, there's no search, there's results of all
[00:36:32.000 --> 00:36:33.000]   that.
[00:36:33.000 --> 00:36:34.000]   Right.
[00:36:34.000 --> 00:36:38.160]   And I think it's a layer of the world and technology connected.
[00:36:38.160 --> 00:36:41.540]   And let's give Google credit for this.
[00:36:41.540 --> 00:36:46.480]   Let's assume they think, they and Mark Zuckerberg think highly strategically and that they're
[00:36:46.480 --> 00:36:50.680]   not worried about indeed this quarter, even in Google Plus.
[00:36:50.680 --> 00:36:54.640]   They've got to look at it and say, what's the world going to look like in two, three
[00:36:54.640 --> 00:36:56.160]   years even?
[00:36:56.160 --> 00:37:02.440]   And what competencies, expertise, services, data, are we going to have to survive when
[00:37:02.440 --> 00:37:03.440]   we get there?
[00:37:03.440 --> 00:37:06.280]   And I think that's the context of what you have to judge Google Plus.
[00:37:06.280 --> 00:37:11.560]   Now, that's another that is to say that Google Plus is perfect, brilliant, couldn't screw
[00:37:11.560 --> 00:37:12.680]   up, couldn't die.
[00:37:12.680 --> 00:37:13.680]   All that's true.
[00:37:13.680 --> 00:37:14.680]   All that's absolutely true.
[00:37:14.680 --> 00:37:20.360]   But I think it's a big mistake to think of it just in terms of going on to it to Facebook.
[00:37:20.360 --> 00:37:22.360]   I think Gene is way right about this.
[00:37:22.360 --> 00:37:26.760]   Yeah, I mean, I listen to Spotify and I'm sharing what songs I'm playing to Facebook
[00:37:26.760 --> 00:37:27.760]   automatically, right?
[00:37:27.760 --> 00:37:29.680]   That whole frictionless sharing thing.
[00:37:29.680 --> 00:37:32.280]   That's what Google Plus is doing.
[00:37:32.280 --> 00:37:33.960]   And I think we're just going to see a lot more of that.
[00:37:33.960 --> 00:37:35.160]   I mean, that was a hangout.
[00:37:35.160 --> 00:37:37.840]   The chat with his girlfriend in the video was a hangout.
[00:37:37.840 --> 00:37:40.640]   The check-ins, the checking his friends location.
[00:37:40.640 --> 00:37:44.600]   So I think for all the people that say, oh, Google Plus is a failure because I don't go
[00:37:44.600 --> 00:37:49.880]   to plus.google.com and interact with my friends there aren't taking all that other activity
[00:37:49.880 --> 00:37:50.880]   into account.
[00:37:50.880 --> 00:37:51.880]   Yeah.
[00:37:51.880 --> 00:37:55.720]   And I think that's part of the problem with everybody wants to measure the numbers.
[00:37:55.720 --> 00:38:00.160]   Part of the problem is a lot of people are engaging through Google Plus or with Google
[00:38:00.160 --> 00:38:03.240]   Plus by doing those other things that you mentioned.
[00:38:03.240 --> 00:38:07.760]   They're never actually going there, but there's still, you know, content is flowing in and
[00:38:07.760 --> 00:38:08.760]   out.
[00:38:08.760 --> 00:38:09.760]   Right.
[00:38:09.760 --> 00:38:14.000]   Which means it's not a successful social network in that it's foreground.
[00:38:14.000 --> 00:38:18.080]   But as you said, Matthew, it's very successful for Google in collecting signals.
[00:38:18.080 --> 00:38:20.360]   It's an background social network.
[00:38:20.360 --> 00:38:22.040]   Kevin Marks and I were talking about this.
[00:38:22.040 --> 00:38:26.720]   Why doesn't Google have more API access to Google Plus?
[00:38:26.720 --> 00:38:29.160]   I mean, it would be a big difference.
[00:38:29.160 --> 00:38:31.360]   I would contribute a huge amount to that network.
[00:38:31.360 --> 00:38:32.360]   Yes.
[00:38:32.360 --> 00:38:34.960]   Other tools that I'm using already like Tweet Tech or whatever.
[00:38:34.960 --> 00:38:35.960]   What do you do?
[00:38:35.960 --> 00:38:41.880]   You know, they don't get my photos because I use Instagram or path and it goes to Facebook.
[00:38:41.880 --> 00:38:42.880]   They get all my photos.
[00:38:42.880 --> 00:38:43.880]   Right.
[00:38:43.880 --> 00:38:45.880]   Go goes to Flickr.
[00:38:45.880 --> 00:38:47.680]   I mean, they're the only argument company.
[00:38:47.680 --> 00:38:49.160]   Why don't they have a right API?
[00:38:49.160 --> 00:38:50.160]   Gina, that's crazy.
[00:38:50.160 --> 00:38:51.160]   Oh, go ahead.
[00:38:51.160 --> 00:38:52.160]   I don't know.
[00:38:52.160 --> 00:38:53.160]   It's been a long time.
[00:38:53.160 --> 00:38:54.960]   I'm hoping that that's going to be announced at I/O.
[00:38:54.960 --> 00:38:55.960]   That's crazy.
[00:38:55.960 --> 00:38:56.960]   I'm not sure why it's taken so long.
[00:38:56.960 --> 00:39:01.080]   Like Vikas said, Vikas said it is his fault and the reason it's his fault, the argument
[00:39:01.080 --> 00:39:07.480]   that he gives is very simply that he doesn't want and Facebook hates it that people put
[00:39:07.480 --> 00:39:09.040]   their Twitter feed on to Facebook.
[00:39:09.040 --> 00:39:10.040]   They shouldn't.
[00:39:10.040 --> 00:39:11.680]   But they do.
[00:39:11.680 --> 00:39:16.520]   And you know, why do they hate it because they're not going to see ads and say so.
[00:39:16.520 --> 00:39:18.560]   You're not going to Facebook.
[00:39:18.560 --> 00:39:19.560]   You're putting in noise.
[00:39:19.560 --> 00:39:20.560]   You're not really part of it.
[00:39:20.560 --> 00:39:22.280]   You're reaching the content.
[00:39:22.280 --> 00:39:23.280]   It's like.
[00:39:23.280 --> 00:39:26.280]   But if Google wants signals from people, that's the thing they need API.
[00:39:26.280 --> 00:39:27.800]   I agree with that, Matthew.
[00:39:27.800 --> 00:39:29.560]   But I think the two things.
[00:39:29.560 --> 00:39:32.600]   One, remember Buzz when people like you.
[00:39:32.600 --> 00:39:33.600]   Well, Buzz got bad.
[00:39:33.600 --> 00:39:34.600]   Yeah, yeah.
[00:39:34.600 --> 00:39:36.880]   Well, we just put our Twitter in there because we weren't into it.
[00:39:36.880 --> 00:39:37.880]   That's all it becomes.
[00:39:37.880 --> 00:39:42.200]   And don't forget, Google's at a precious moment now when people like you are saying, "Eh,
[00:39:42.200 --> 00:39:43.200]   Deva."
[00:39:43.200 --> 00:39:46.920]   So if people just make it a repository for a whole bunch of automated feeds, that will
[00:39:46.920 --> 00:39:48.920]   kill it, right?
[00:39:48.920 --> 00:39:49.920]   And yes.
[00:39:49.920 --> 00:39:51.840]   I go back to Facebook all the time.
[00:39:51.840 --> 00:39:54.560]   I post pictures there through Path and Instagram.
[00:39:54.560 --> 00:39:57.440]   And I go back to check the comments and look at the engagement.
[00:39:57.440 --> 00:40:02.120]   So Facebook becomes, in a way, the Path and Instagram aren't a form of interaction around
[00:40:02.120 --> 00:40:03.120]   the stuff that I post.
[00:40:03.120 --> 00:40:04.560]   They're in a better position to do that.
[00:40:04.560 --> 00:40:07.720]   And I actually go to Facebook a lot less than I go to Google Plus.
[00:40:07.720 --> 00:40:08.720]   Okay.
[00:40:08.720 --> 00:40:09.720]   So it's just me then.
[00:40:09.720 --> 00:40:12.160]   No, no, no, it's just, I'm the viewer over here.
[00:40:12.160 --> 00:40:16.560]   Larry Page gave an interview to Business Week yesterday and they asked him.
[00:40:16.560 --> 00:40:22.080]   And he said, "He's very happy with the success of Android, Chrome, YouTube.
[00:40:22.080 --> 00:40:23.080]   Long-term bets we've made.
[00:40:23.080 --> 00:40:24.880]   They've been very successful.
[00:40:24.880 --> 00:40:26.840]   All of those things have continued to grow like crazy.
[00:40:26.840 --> 00:40:29.880]   We've made a more recent one, which is Google Plus.
[00:40:29.880 --> 00:40:31.280]   And that's a long-term bet as well.
[00:40:31.280 --> 00:40:32.880]   We're not even a year into that.
[00:40:32.880 --> 00:40:35.960]   And it's going very well, much better than I expected.
[00:40:35.960 --> 00:40:38.520]   There are various worries that people have and we'll address those.
[00:40:38.520 --> 00:40:40.120]   But we have a really good start.
[00:40:40.120 --> 00:40:43.920]   I have over two million followers now on Google Plus," says Larry Page.
[00:40:43.920 --> 00:40:47.560]   "A number of other people are even ahead of me and that's with real engagement."
[00:40:47.560 --> 00:40:48.560]   So I'm very happy.
[00:40:48.560 --> 00:40:50.920]   That's the last time was Larry posted.
[00:40:50.920 --> 00:40:51.920]   He doesn't get engagement.
[00:40:51.920 --> 00:40:52.920]   Yeah.
[00:40:52.920 --> 00:40:53.920]   That's a little disingenuous.
[00:40:53.920 --> 00:40:54.920]   That's totally disingenuous.
[00:40:54.920 --> 00:40:55.920]   He doesn't post.
[00:40:55.920 --> 00:40:56.920]   Yeah.
[00:40:56.920 --> 00:40:57.920]   There's no engagement.
[00:40:57.920 --> 00:41:02.000]   So I'm very happy with the growth of the core Google Plus network.
[00:41:02.000 --> 00:41:06.400]   It's interesting that phrase, core Google Plus network.
[00:41:06.400 --> 00:41:08.800]   What does that mean?
[00:41:08.800 --> 00:41:11.120]   That means when you go to Google Plus, right?
[00:41:11.120 --> 00:41:12.120]   The site.
[00:41:12.120 --> 00:41:13.920]   The site.
[00:41:13.920 --> 00:41:17.040]   It doesn't mean tomorrow it's going to be bigger than any other social network out there.
[00:41:17.040 --> 00:41:20.160]   That's not realistic, but it's growing faster I think than other services have and I'm very
[00:41:20.160 --> 00:41:21.360]   happy with that.
[00:41:21.360 --> 00:41:26.800]   So he's making the distinction between the core, which is the page, and all the other
[00:41:26.800 --> 00:41:28.200]   stuff which is clearly working.
[00:41:28.200 --> 00:41:32.720]   Every time I go somewhere, latitude automatically checks me in and feeds that to Google Plus
[00:41:32.720 --> 00:41:36.240]   and as a result to Google.
[00:41:36.240 --> 00:41:39.720]   So all those other services I think are working.
[00:41:39.720 --> 00:41:41.800]   And plus one button is everywhere.
[00:41:41.800 --> 00:41:42.800]   Plus one's everywhere.
[00:41:42.800 --> 00:41:43.800]   Yeah.
[00:41:43.800 --> 00:41:46.680]   When they launch third party comments, just think about this.
[00:41:46.680 --> 00:41:50.720]   How fast will you integrate Google Plus comments on your blog?
[00:41:50.720 --> 00:41:54.960]   If you know that those comments will affect your search rank, come the same thing as the
[00:41:54.960 --> 00:41:55.960]   authorship.
[00:41:55.960 --> 00:41:59.320]   No, no, no one disagrees that they have the big stick.
[00:41:59.320 --> 00:42:00.320]   They do.
[00:42:00.320 --> 00:42:01.320]   Absolutely.
[00:42:01.320 --> 00:42:02.320]   It's a carrot actually.
[00:42:02.320 --> 00:42:04.120]   Yeah, they get close.
[00:42:04.120 --> 00:42:07.320]   It's a stick shaped carrot.
[00:42:07.320 --> 00:42:12.960]   They have that's what's going to they're basically force feeding people Google Plus.
[00:42:12.960 --> 00:42:13.960]   They're encouraging.
[00:42:13.960 --> 00:42:15.960]   No, no, no, no.
[00:42:15.960 --> 00:42:20.480]   Yeah, I don't know if it's force feeding.
[00:42:20.480 --> 00:42:24.720]   I mean, I happily claim my authorship on my websites now.
[00:42:24.720 --> 00:42:27.840]   I mean, I know it's going to show up in the, you know, and plus one things.
[00:42:27.840 --> 00:42:30.400]   Okay, so you're happy to be force fed.
[00:42:30.400 --> 00:42:34.200]   I mean, you want to show up better on Google.
[00:42:34.200 --> 00:42:38.600]   I'm saying they're using their cloud and search to encourage you.
[00:42:38.600 --> 00:42:39.840]   Well, that's the carrot.
[00:42:39.840 --> 00:42:40.840]   They're force feeding you carrots.
[00:42:40.840 --> 00:42:41.840]   That's fine.
[00:42:41.840 --> 00:42:42.840]   That's fine.
[00:42:42.840 --> 00:42:43.840]   Yes, it's part of an SEO checklist, basically.
[00:42:43.840 --> 00:42:44.840]   I think it's a little like.
[00:42:44.840 --> 00:42:48.080]   Like if I want my site to do well, this is a bullet point now on the list of things that
[00:42:48.080 --> 00:42:50.080]   you should do for your site to do well.
[00:42:50.080 --> 00:42:52.440]   And there's, you know, you have a really nice blog there.
[00:42:52.440 --> 00:42:54.320]   It'd be a shame if anything happened.
[00:42:54.320 --> 00:42:57.120]   It's a stick shaped carrot.
[00:42:57.120 --> 00:42:58.120]   I'm telling you.
[00:42:58.120 --> 00:43:02.480]   If you've ever been hit by a carrot, it can hurt.
[00:43:02.480 --> 00:43:04.320]   It's really big carrot.
[00:43:04.320 --> 00:43:06.120]   It's really big carrot.
[00:43:06.120 --> 00:43:07.120]   You know what's interesting though?
[00:43:07.120 --> 00:43:12.520]   He says just below what you were quoting Leo, he says, our mission's organizing the
[00:43:12.520 --> 00:43:14.520]   world's information and making it accessible.
[00:43:14.520 --> 00:43:19.440]   And I think we probably missed more of people part of that than we should have.
[00:43:19.440 --> 00:43:22.600]   So when I'd missed him, they're basically playing catch up.
[00:43:22.600 --> 00:43:24.320]   You also haven't gotten it either.
[00:43:24.320 --> 00:43:29.480]   I think what we're hearing from especially Leo is, you know, you haven't engaged me.
[00:43:29.480 --> 00:43:30.880]   You haven't engaged my heart.
[00:43:30.880 --> 00:43:31.880]   No.
[00:43:31.880 --> 00:43:33.880]   And I think that's where people love it or hate it.
[00:43:33.880 --> 00:43:38.600]   But you've got to give Zuckerberg, you know, irony of Zuckerberg not being exactly what
[00:43:38.600 --> 00:43:42.360]   seemed the Oprah of the world.
[00:43:42.360 --> 00:43:49.400]   But he does know how to pluck emotional strings with technology in a way that Google is incapable
[00:43:49.400 --> 00:43:50.400]   of doing.
[00:43:50.400 --> 00:43:53.480]   And so timeline, you know, yeah, every time you change, it'll be controversial.
[00:43:53.480 --> 00:43:54.480]   It's creepy.
[00:43:54.480 --> 00:43:55.480]   It's this and that.
[00:43:55.480 --> 00:43:56.480]   But you know, now it's virtually everywhere.
[00:43:56.480 --> 00:43:58.720]   I've got to remind you, but it's virtually everywhere.
[00:43:58.720 --> 00:44:00.240]   And it does engage you more.
[00:44:00.240 --> 00:44:01.240]   It is more human.
[00:44:01.240 --> 00:44:02.680]   Facebook is a human company.
[00:44:02.680 --> 00:44:06.400]   And that's been Zuckerberg's argument.
[00:44:06.400 --> 00:44:09.640]   And Google still is not a human company.
[00:44:09.640 --> 00:44:11.320]   You get a little insight in this interview.
[00:44:11.320 --> 00:44:13.720]   Bad Stone does the interview, by the way, took a good job at Businessweek.
[00:44:13.720 --> 00:44:19.360]   But you get a little insight into why Google Plus is important to Larry with the little
[00:44:19.360 --> 00:44:21.240]   Ben Smith analogy he gives.
[00:44:21.240 --> 00:44:23.280]   He says, I have a friend named Ben Smith.
[00:44:23.280 --> 00:44:24.680]   That's a very common name.
[00:44:24.680 --> 00:44:29.920]   For the first time, we're able to say this Ben Smith because we attach a picture to it
[00:44:29.920 --> 00:44:31.320]   and content to it.
[00:44:31.320 --> 00:44:36.920]   And now you see really what Google Plus is, I think really all about to Google is that
[00:44:36.920 --> 00:44:41.920]   kind of, what do they call it on Wikipedia, disambiguation.
[00:44:41.920 --> 00:44:42.920]   Yes.
[00:44:42.920 --> 00:44:46.640]   And the irony is when I go into Facebook and I search for someone who has a name like
[00:44:46.640 --> 00:44:47.640]   Ben Smith.
[00:44:47.640 --> 00:44:52.160]   Unless I've never found this, there's no way to search for other data points to get the
[00:44:52.160 --> 00:44:53.520]   right Ben Smith.
[00:44:53.520 --> 00:44:54.520]   You might get a picture.
[00:44:54.520 --> 00:44:55.520]   You'll get a picture of Ben Smith.
[00:44:55.520 --> 00:44:59.080]   But if there's 100 Ben Smiths, there's no help to be at all.
[00:44:59.080 --> 00:45:02.160]   There's no way to do an advanced search, right?
[00:45:02.160 --> 00:45:04.240]   Is the chat room going to tell me what I'm going to know?
[00:45:04.240 --> 00:45:05.240]   No, you're right.
[00:45:05.240 --> 00:45:06.240]   It's true.
[00:45:06.240 --> 00:45:07.240]   It's a real flaw.
[00:45:07.240 --> 00:45:08.240]   It's very hard to find people to find.
[00:45:08.240 --> 00:45:09.240]   It's interesting though.
[00:45:09.240 --> 00:45:10.240]   That's a search engine problem.
[00:45:10.240 --> 00:45:11.240]   And I guess it's a problem that people have.
[00:45:11.240 --> 00:45:15.360]   I mean, going back to what Jeff said earlier about Zuckerberg, you know, Zuck really does
[00:45:15.360 --> 00:45:17.040]   know what people want.
[00:45:17.040 --> 00:45:19.880]   I mean, if you go back to the early stuff he did in college, like what he did like a
[00:45:19.880 --> 00:45:25.240]   hot or not thing where you compare like sorority, infertunity, guys and girls to one another.
[00:45:25.240 --> 00:45:28.080]   And he had done like a P2P file sharing thing.
[00:45:28.080 --> 00:45:32.800]   I mean, he has a good insight, even though he's a little bit maybe robotic, his personality
[00:45:32.800 --> 00:45:36.560]   himself, he has good insight into what people really want to do online.
[00:45:36.560 --> 00:45:38.960]   And that shows that's part of why Facebook has been so popular.
[00:45:38.960 --> 00:45:42.040]   Also, Facebook has been at this for how many years now?
[00:45:42.040 --> 00:45:43.040]   Has it been 10 years?
[00:45:43.040 --> 00:45:44.040]   I'm not even sure how many years.
[00:45:44.040 --> 00:45:45.040]   No, no, it's not.
[00:45:45.040 --> 00:45:46.040]   Six or so.
[00:45:46.040 --> 00:45:47.040]   Yes.
[00:45:47.040 --> 00:45:48.040]   Six or seven.
[00:45:48.040 --> 00:45:49.040]   Okay.
[00:45:49.040 --> 00:45:50.040]   All right.
[00:45:50.040 --> 00:45:52.040]   Well, still that's a long time in internet, in internet time.
[00:45:52.040 --> 00:45:59.760]   When I interviewed Zuck for public parts plug, you know, he really sees Facebook as an ex-step
[00:45:59.760 --> 00:46:03.320]   on an evolutionary scale after the Googles.
[00:46:03.320 --> 00:46:06.680]   And he says that, you know, where all the real value comes is in the stuff that's in
[00:46:06.680 --> 00:46:07.680]   your head.
[00:46:07.680 --> 00:46:11.160]   And the only way to get the stuff out of your head, willy-lay, is by creating things that
[00:46:11.160 --> 00:46:15.640]   are going to make you want to do that, have a reason to do that, want to share.
[00:46:15.640 --> 00:46:19.200]   And so he really believes that he's enabling that.
[00:46:19.200 --> 00:46:22.280]   And so he sees the value of that humanity.
[00:46:22.280 --> 00:46:28.280]   And Google to this day, you know, how do you hire, how do you add humanity to the culture?
[00:46:28.280 --> 00:46:29.440]   And I love Google, right?
[00:46:29.440 --> 00:46:30.440]   I'm amazing Google.
[00:46:30.440 --> 00:46:32.840]   I think it's a wonderful place, very smart, brilliant.
[00:46:32.840 --> 00:46:33.840]   But it is, workish.
[00:46:33.840 --> 00:46:35.640]   Well, not throw.
[00:46:35.640 --> 00:46:36.640]   And there was a...
[00:46:36.640 --> 00:46:38.280]   It is, it is, what's the right word?
[00:46:38.280 --> 00:46:39.280]   It's robotic.
[00:46:39.280 --> 00:46:40.280]   It's a Python script.
[00:46:40.280 --> 00:46:47.880]   There was a Google engineer who left and talked about Google's rationale, and particularly,
[00:46:47.880 --> 00:46:49.720]   I think he was talking about plus.
[00:46:49.720 --> 00:46:53.880]   And he said, you know, they don't care about you or as a person and what you want to do.
[00:46:53.880 --> 00:46:54.880]   They just want that data.
[00:46:54.880 --> 00:46:56.920]   In some ways, that should reassure people.
[00:46:56.920 --> 00:47:00.040]   I mean, if they cared about me, I'd be a little nervous.
[00:47:00.040 --> 00:47:02.120]   They wanted to know about me specifically.
[00:47:02.120 --> 00:47:05.280]   Isn't that what people are really afraid of when they say you were being tracked?
[00:47:05.280 --> 00:47:09.720]   You have to have insight in what people want in order to make products that are so compelling
[00:47:09.720 --> 00:47:10.720]   and instinct.
[00:47:10.720 --> 00:47:11.720]   You can't keep taking your hands off of them, right?
[00:47:11.720 --> 00:47:12.720]   They don't have the instinct.
[00:47:12.720 --> 00:47:13.720]   They don't have the instinct.
[00:47:13.720 --> 00:47:14.720]   They don't have the instinct.
[00:47:14.720 --> 00:47:16.720]   It's a bunch of kicks.
[00:47:16.720 --> 00:47:18.720]   It's a bunch of people work.
[00:47:18.720 --> 00:47:19.720]   Right.
[00:47:19.720 --> 00:47:22.120]   I mean, is that why Kevin Rose is there?
[00:47:22.120 --> 00:47:23.120]   Maybe.
[00:47:23.120 --> 00:47:24.120]   Maybe.
[00:47:24.120 --> 00:47:25.720]   I still can't figure that out.
[00:47:25.720 --> 00:47:26.720]   No.
[00:47:26.720 --> 00:47:28.520]   I mean, I understand why Kevin did it.
[00:47:28.520 --> 00:47:30.320]   I don't understand why Google did it.
[00:47:30.320 --> 00:47:31.520]   I love this idea.
[00:47:31.520 --> 00:47:35.480]   I can see a huge whiteboard with a gigantic orchard chart, and there's one box that just
[00:47:35.480 --> 00:47:37.520]   says, "Insert human here."
[00:47:37.520 --> 00:47:38.520]   Yeah.
[00:47:38.520 --> 00:47:40.120]   Kevin, congratulations.
[00:47:40.120 --> 00:47:41.120]   You're our token human.
[00:47:41.120 --> 00:47:44.720]   You need a ton of paper presentation.
[00:47:44.720 --> 00:47:45.920]   Everybody wants to be loved.
[00:47:45.920 --> 00:47:47.640]   Go back to a place where you're loved.
[00:47:47.640 --> 00:47:50.440]   How do these products make you feel loved?
[00:47:50.440 --> 00:47:53.320]   Let's not say that Google hasn't made-- Google's made some incredible products.
[00:47:53.320 --> 00:47:56.040]   Maps and Gmail in particular.
[00:47:56.040 --> 00:48:02.120]   Gmail never makes email awesome, and Maps also still blows my mind to this day.
[00:48:02.120 --> 00:48:06.360]   We shouldn't say blanket cart blocks that they're unable to make really compelling products.
[00:48:06.360 --> 00:48:08.360]   Just lately, it hasn't felt that way.
[00:48:08.360 --> 00:48:12.800]   And Google+, the people who make those things are gone.
[00:48:12.800 --> 00:48:13.800]   Chased out in effect.
[00:48:13.800 --> 00:48:17.280]   The rest of us is effectively chased out to Facebook.
[00:48:17.280 --> 00:48:18.280]   Facebook.
[00:48:18.280 --> 00:48:21.080]   And that's the one you want to say, right?
[00:48:21.080 --> 00:48:22.080]   Paul Booth, I think.
[00:48:22.080 --> 00:48:25.960]   Facebook is-- Facebook is working on search.
[00:48:25.960 --> 00:48:27.800]   You know, they've got a guy from Google.
[00:48:27.800 --> 00:48:30.760]   They're going to pour a bunch of resources into search.
[00:48:30.760 --> 00:48:35.640]   What is that to-- they're adding search to something that's already a social network.
[00:48:35.640 --> 00:48:39.280]   Google's trying to add social to a giant search engine.
[00:48:39.280 --> 00:48:44.280]   Yeah, but Matthew, I'm going to disagree with you there that I think that only and so far
[00:48:44.280 --> 00:48:49.160]   as I think it's dangerous to define the fight in that way.
[00:48:49.160 --> 00:48:56.040]   I think when you go to a world where the real aim is-- the way I used to put it is for Google
[00:48:56.040 --> 00:48:59.720]   to-- for either of them to intuit your intent.
[00:48:59.720 --> 00:49:02.000]   And it's by signals shtick.
[00:49:02.000 --> 00:49:06.160]   But it's saying that they want to know what you want before you want it so they can serve
[00:49:06.160 --> 00:49:08.520]   you, hyper-serve you.
[00:49:08.520 --> 00:49:12.960]   And with both content and advertising and commerce.
[00:49:12.960 --> 00:49:18.400]   And so I think it goes beyond-- search and social are merely tools toward that higher
[00:49:18.400 --> 00:49:19.400]   end.
[00:49:19.400 --> 00:49:20.400]   I go back to the video.
[00:49:20.400 --> 00:49:21.400]   I agree.
[00:49:21.400 --> 00:49:22.400]   No, I totally agree.
[00:49:22.400 --> 00:49:30.040]   But if Facebook has, you know, make billions of social signals already, it's got years of
[00:49:30.040 --> 00:49:31.800]   sort of building up that expertise.
[00:49:31.800 --> 00:49:32.800]   Right.
[00:49:32.800 --> 00:49:36.560]   Now it has to apply that better to search.
[00:49:36.560 --> 00:49:40.480]   Google's got expertise in search, but they're missing a lot of that social stuff.
[00:49:40.480 --> 00:49:46.760]   Well, in your right, it's not just the signals about you as an individual, right?
[00:49:46.760 --> 00:49:50.800]   Go back to Zuck's favorite phrase, social graph.
[00:49:50.800 --> 00:49:54.720]   It's about the relationships, the relationships are what are telling.
[00:49:54.720 --> 00:49:58.400]   And that's what Facebook understands in a way that Google has not nearly enough.
[00:49:58.400 --> 00:50:02.120]   You know, Android will give you-- Google will give Google tons more signals about you as
[00:50:02.120 --> 00:50:03.320]   an individual.
[00:50:03.320 --> 00:50:05.240]   Very valuable signals.
[00:50:05.240 --> 00:50:07.960]   Very valuable when it comes to new kinds of advertising and product sales and all kinds
[00:50:07.960 --> 00:50:08.960]   of stuff.
[00:50:08.960 --> 00:50:12.400]   But it doesn't have really the graph.
[00:50:12.400 --> 00:50:15.840]   And I'm assuming Facebook, you know, they've got engineers that have been working on that
[00:50:15.840 --> 00:50:20.400]   social graph and how it works and how it's all connected and how you can infer certain
[00:50:20.400 --> 00:50:22.600]   things from it for years now.
[00:50:22.600 --> 00:50:26.360]   I mean, Google's got, you know, they've got a lot of smart guys, but that's a totally
[00:50:26.360 --> 00:50:27.360]   different game.
[00:50:27.360 --> 00:50:34.080]   Yeah, Twitter, I think, has-- you know, if you look at the Twitter edge fund, it has
[00:50:34.080 --> 00:50:37.320]   the finger on the pulse of society more broadly, right?
[00:50:37.320 --> 00:50:38.600]   What are we talking about?
[00:50:38.600 --> 00:50:39.600]   What's our mood?
[00:50:39.600 --> 00:50:40.600]   What's going up?
[00:50:40.600 --> 00:50:42.440]   What's going down?
[00:50:42.440 --> 00:50:46.000]   Also who we're connected to and who's seen as authoritative over topics and it's like,
[00:50:46.000 --> 00:50:47.560]   "Twitter has value here, too."
[00:50:47.560 --> 00:50:49.880]   And I wouldn't count them out of this race.
[00:50:49.880 --> 00:50:55.080]   They're not going to win any part of this race, but they have their own unique value.
[00:50:55.080 --> 00:51:01.120]   The most interesting part in this interview in Business Week is when Brad Stone asks Larry
[00:51:01.120 --> 00:51:03.320]   Page about the Steve Jobs biography.
[00:51:03.320 --> 00:51:07.800]   He says, "According to the biography, when you became CEO, you went to Jobs for advice.
[00:51:07.800 --> 00:51:10.400]   I know you had your differences at the end around Android, but what did you take from
[00:51:10.400 --> 00:51:12.080]   him as a mentor and friend?"
[00:51:12.080 --> 00:51:13.560]   And then Larry says something quite stunning.
[00:51:13.560 --> 00:51:19.960]   I think the Android differences were actually for show.
[00:51:19.960 --> 00:51:22.640]   And Brad says, "Wait, what?"
[00:51:22.640 --> 00:51:26.200]   The fury around Android was for show.
[00:51:26.200 --> 00:51:29.320]   Larry Page says, "I think that served their interests for a lot of companies.
[00:51:29.320 --> 00:51:33.000]   It's useful for them to feel like they have an obvious competitor and a rally around
[00:51:33.000 --> 00:51:34.000]   that."
[00:51:34.000 --> 00:51:37.360]   This is actually exactly the kind of thing Steve Jobs would do.
[00:51:37.360 --> 00:51:39.160]   I personally believe it's better to shoot higher.
[00:51:39.160 --> 00:51:40.400]   You don't want to be looking at your competitors.
[00:51:40.400 --> 00:51:43.760]   You want to be looking at what's possible and how to wake the world better.
[00:51:43.760 --> 00:51:45.240]   So it's a little...
[00:51:45.240 --> 00:51:46.160]   Wow.
[00:51:46.160 --> 00:51:47.640]   That's so funny.
[00:51:47.640 --> 00:51:51.880]   So he's saying, "I don't care what Facebook's doing.
[00:51:51.880 --> 00:51:53.960]   I don't care what Twitter's doing.
[00:51:53.960 --> 00:51:56.480]   He's worried about what they're going to do."
[00:51:56.480 --> 00:51:59.400]   He says, "I personally believe it's better to shoot higher.
[00:51:59.400 --> 00:52:01.000]   You don't want to be looking at your competitors.
[00:52:01.000 --> 00:52:03.680]   You want to be looking at what's possible and how to make the world better.
[00:52:03.680 --> 00:52:05.600]   And for that, we have glasses."
[00:52:05.600 --> 00:52:06.600]   [Laughter]
[00:52:06.600 --> 00:52:09.600]   "Cermoduclear Show."
[00:52:09.600 --> 00:52:10.600]   Yeah.
[00:52:10.600 --> 00:52:15.160]   I think it's hysterical that he says that I had a great conversation.
[00:52:15.160 --> 00:52:16.160]   Steve was dying.
[00:52:16.160 --> 00:52:18.040]   He called me and said, "Come over."
[00:52:18.040 --> 00:52:19.040]   We talked.
[00:52:19.040 --> 00:52:20.040]   He says it was for show.
[00:52:20.040 --> 00:52:24.160]   And I could totally see Steve Jobs exactly thinking in the back of his head, "Yeah, how
[00:52:24.160 --> 00:52:26.640]   am I going to get those people to get angry?"
[00:52:26.640 --> 00:52:28.360]   Ah, go get him.
[00:52:28.360 --> 00:52:34.360]   He did say that he used every one of Apple's resources in order to fight that fight, which
[00:52:34.360 --> 00:52:38.440]   does seem ridiculous when framed, the way that Larry framed it.
[00:52:38.440 --> 00:52:43.240]   I have to say that quote alone just ratchered out my respect for him a few notches.
[00:52:43.240 --> 00:52:44.240]   Yeah.
[00:52:44.240 --> 00:52:45.240]   Well, that's the right thing to say.
[00:52:45.240 --> 00:52:46.240]   Let's hope it's not just lip service.
[00:52:46.240 --> 00:52:47.240]   That's the right thing to say.
[00:52:47.240 --> 00:52:48.920]   That is very, very sad thing to say.
[00:52:48.920 --> 00:52:49.920]   And let's not forget.
[00:52:49.920 --> 00:52:55.680]   Google, when you think what products does Google search is unequivocally the best thing
[00:52:55.680 --> 00:52:58.320]   out there still, despite all of its flaws.
[00:52:58.320 --> 00:53:01.240]   And I don't like search plus your world, et cetera, et cetera.
[00:53:01.240 --> 00:53:02.880]   "Crum" is a great browser.
[00:53:02.880 --> 00:53:04.280]   Crum is a great product.
[00:53:04.280 --> 00:53:05.280]   It's a great product.
[00:53:05.280 --> 00:53:06.280]   Crum is a great product.
[00:53:06.280 --> 00:53:07.400]   My Android phone is my favorite phone.
[00:53:07.400 --> 00:53:08.560]   I love Android.
[00:53:08.560 --> 00:53:12.560]   Now, there have been people who say Google's not got to get control of this brand.
[00:53:12.560 --> 00:53:13.560]   It's going to add a control.
[00:53:13.560 --> 00:53:15.280]   It's not even their brand anymore.
[00:53:15.280 --> 00:53:16.280]   And that may be true.
[00:53:16.280 --> 00:53:21.200]   And you see Google take this play thing and make it be the play phone and the play tablet.
[00:53:21.200 --> 00:53:22.200]   Who knows?
[00:53:22.200 --> 00:53:23.600]   The play store.
[00:53:23.600 --> 00:53:26.040]   But it's still a great success.
[00:53:26.040 --> 00:53:30.200]   If you think about it, it's now half of the smartphones.
[00:53:30.200 --> 00:53:31.200]   Yep.
[00:53:31.200 --> 00:53:32.200]   Yep.
[00:53:32.200 --> 00:53:33.200]   At a nowhere.
[00:53:33.200 --> 00:53:34.360]   And you're listening over yet.
[00:53:34.360 --> 00:53:36.280]   Who does email better?
[00:53:36.280 --> 00:53:37.280]   Email, Gmail's.
[00:53:37.280 --> 00:53:38.920]   Well, I will argue with you on that.
[00:53:38.920 --> 00:53:40.240]   I know you guys love Gmail.
[00:53:40.240 --> 00:53:44.160]   I do not think Gmail Webmail is the best Webmail experience out there.
[00:53:44.160 --> 00:53:47.240]   It's got the ads are annoying.
[00:53:47.240 --> 00:53:48.840]   It's kind of quirky.
[00:53:48.840 --> 00:53:52.160]   Maybe you guys have gotten used to the fact that it's not folders, it's lists.
[00:53:52.160 --> 00:53:53.160]   All right.
[00:53:53.160 --> 00:53:54.160]   It's awesome.
[00:53:54.160 --> 00:53:55.160]   And it's iMap.
[00:53:55.160 --> 00:53:56.560]   I mean, it offers iMap access.
[00:53:56.560 --> 00:53:58.080]   Well, I have an iMap use.
[00:53:58.080 --> 00:54:00.440]   I mean, yeah, I love iMap.
[00:54:00.440 --> 00:54:02.880]   But I mean, there's lots of iMap services out there.
[00:54:02.880 --> 00:54:03.880]   Absolutely.
[00:54:03.880 --> 00:54:04.880]   I would be dead without priority inbox.
[00:54:04.880 --> 00:54:05.880]   Really?
[00:54:05.880 --> 00:54:07.040]   Google is providing this free service.
[00:54:07.040 --> 00:54:11.120]   I mean, for someone who just doesn't want to set up email, I mean, you can use Gmail
[00:54:11.120 --> 00:54:12.120]   with any client.
[00:54:12.120 --> 00:54:13.120]   I'm not going to sell Gmail.
[00:54:13.120 --> 00:54:17.000]   I do happen to love the web interface and labels and party inbox.
[00:54:17.000 --> 00:54:20.280]   I know I'm alone on this one because a lot of people love Gmail.
[00:54:20.280 --> 00:54:23.360]   And I think Docs is actually kind of brilliant.
[00:54:23.360 --> 00:54:24.360]   It is.
[00:54:24.360 --> 00:54:25.680]   And you haven't even listed maps yet.
[00:54:25.680 --> 00:54:26.680]   Map.
[00:54:26.680 --> 00:54:27.680]   Yeah.
[00:54:27.680 --> 00:54:30.000]   Well, and then building on to what Gina already said about maps.
[00:54:30.000 --> 00:54:31.000]   Right.
[00:54:31.000 --> 00:54:32.000]   Okay.
[00:54:32.000 --> 00:54:37.240]   So now they have plenty of products that are first in class, best in class, right?
[00:54:37.240 --> 00:54:38.240]   There's no question.
[00:54:38.240 --> 00:54:39.800]   Yeah.
[00:54:39.800 --> 00:54:42.560]   So it's not like they're struggling.
[00:54:42.560 --> 00:54:48.320]   It's just that there's, and I have to say, if you're going to grade Larry on his year,
[00:54:48.320 --> 00:54:50.920]   this was the worst year for the creepy factor.
[00:54:50.920 --> 00:54:52.480]   It wasn't under Eric Schmidt.
[00:54:52.480 --> 00:54:54.720]   It was under Larry Page, right?
[00:54:54.720 --> 00:54:55.720]   Right.
[00:54:55.720 --> 00:55:00.240]   With the iOS hack, search plus my world, the privacy.
[00:55:00.240 --> 00:55:02.600]   I mean, one could argue, one could argue.
[00:55:02.600 --> 00:55:06.000]   I'm not trying to throw Erica to the bus here either.
[00:55:06.000 --> 00:55:10.200]   One could argue that those were cultural issues that were probably already brewing.
[00:55:10.200 --> 00:55:11.200]   Maybe.
[00:55:11.200 --> 00:55:12.200]   That we're not there.
[00:55:12.200 --> 00:55:13.200]   But I get there too.
[00:55:13.200 --> 00:55:14.840]   He said, I think it's a PR problem.
[00:55:14.840 --> 00:55:17.080]   And I know that's not, I'm going to get in trouble for saying that.
[00:55:17.080 --> 00:55:18.080]   No, it's no or Jarvis.
[00:55:18.080 --> 00:55:19.080]   It's more than a PR problem.
[00:55:19.080 --> 00:55:20.080]   But I really think so.
[00:55:20.080 --> 00:55:26.080]   There's, I put up a piece on the, on the list from Gigah Olm, in fact, from your colleague,
[00:55:26.080 --> 00:55:28.760]   Derek, right?
[00:55:28.760 --> 00:55:33.840]   Wrote a defense of Google on, on the privacy things and just said, you know, come on, let's
[00:55:33.840 --> 00:55:36.000]   get back down to earth, let's get back down to reality.
[00:55:36.000 --> 00:55:39.720]   It's not, you know, these are, this has been way overblown.
[00:55:39.720 --> 00:55:41.560]   And I don't want to get any other discussion five times before.
[00:55:41.560 --> 00:55:42.560]   I don't want to.
[00:55:42.560 --> 00:55:44.280]   Yeah, I've been saying this for months.
[00:55:44.280 --> 00:55:45.280]   Right.
[00:55:45.280 --> 00:55:51.120]   My point here is that what got bungled in this was not the policy, but the execution
[00:55:51.120 --> 00:55:55.320]   of the PR strategy, the public strategy about it.
[00:55:55.320 --> 00:55:59.240]   They couldn't turn around and really worked this hard and said, you know, we think it's
[00:55:59.240 --> 00:56:01.880]   ridiculous that you have 20 things.
[00:56:01.880 --> 00:56:03.120]   We're going to put this out there.
[00:56:03.120 --> 00:56:04.600]   We're going to have a time for comment.
[00:56:04.600 --> 00:56:05.600]   We're going to do this.
[00:56:05.600 --> 00:56:10.040]   We're going to, they could have made this such a plus and it turned into a negative because
[00:56:10.040 --> 00:56:11.040]   they don't understand.
[00:56:11.040 --> 00:56:14.400]   It's the problem with Google and people again, not that Facebook is any better at those kinds
[00:56:14.400 --> 00:56:15.400]   of things.
[00:56:15.400 --> 00:56:17.520]   They are in some ways worse.
[00:56:17.520 --> 00:56:22.800]   And I, and I don't want to see the purification of the world and everything gets slicked up.
[00:56:22.800 --> 00:56:25.960]   There's a different kind of relationship than messaging that, that relationship should be
[00:56:25.960 --> 00:56:30.840]   collaborative and it should be open and beta and they, they, they forget their own lessons
[00:56:30.840 --> 00:56:31.840]   when it comes to this.
[00:56:31.840 --> 00:56:34.080]   And so I think the problem privacy was not creepiness.
[00:56:34.080 --> 00:56:36.120]   The problem was oddly spanking.
[00:56:36.120 --> 00:56:37.120]   Yeah.
[00:56:37.120 --> 00:56:38.120]   Yeah.
[00:56:38.120 --> 00:56:42.600]   But to use, but to use an alternate example, I would argue that Google search plus your
[00:56:42.600 --> 00:56:46.240]   world was all PR, like it's all spin.
[00:56:46.240 --> 00:56:50.160]   I mean, they're, they're even the name, right?
[00:56:50.160 --> 00:56:51.680]   You know, search plus your world.
[00:56:51.680 --> 00:56:53.080]   It's not your world.
[00:56:53.080 --> 00:56:56.480]   It's search plus the parts of your world that intersect with our plus plus.
[00:56:56.480 --> 00:56:57.480]   Yeah.
[00:56:57.480 --> 00:56:59.800]   And I'll buy that Matthew, even though I, I will some defend the thing.
[00:56:59.800 --> 00:57:04.400]   And I, I buy that because it, it did not certainly live up to the company's hype.
[00:57:04.400 --> 00:57:05.400]   Right.
[00:57:05.400 --> 00:57:07.160]   But it's a contrary, it disappointed.
[00:57:07.160 --> 00:57:13.240]   Whereas they didn't try to get the expectations up for privacy and deal with that properly.
[00:57:13.240 --> 00:57:17.440]   I mean, Gina, you, you were more obviously negative on that policy than I am.
[00:57:17.440 --> 00:57:19.440]   What do you think?
[00:57:19.440 --> 00:57:24.680]   On the, the privacy, the privacy policy consolidate substance versus presentation.
[00:57:24.680 --> 00:57:25.680]   Mm.
[00:57:25.680 --> 00:57:28.440]   I actually thought the substance was excellent.
[00:57:28.440 --> 00:57:29.440]   Yeah.
[00:57:29.440 --> 00:57:34.440]   And I kept trying to tell people, even on the radio show, this is good.
[00:57:34.440 --> 00:57:36.080]   This is a good thing.
[00:57:36.080 --> 00:57:37.080]   Yeah.
[00:57:37.080 --> 00:57:38.080]   Yeah.
[00:57:38.080 --> 00:57:40.920]   I, I agree that it was a PR problem the way that they presented it.
[00:57:40.920 --> 00:57:42.760]   Well, they may not have been in control of this.
[00:57:42.760 --> 00:57:49.000]   I mean, it's kind of hard when the entire world and Fox News decide that you're evil
[00:57:49.000 --> 00:57:51.160]   to say, no, no, no, we're not evil.
[00:57:51.160 --> 00:57:52.160]   Really?
[00:57:52.160 --> 00:57:53.640]   And we're not evil.
[00:57:53.640 --> 00:57:57.520]   This is, this is showing, show me another company that has as many services as this
[00:57:57.520 --> 00:58:02.360]   that has a unified privacy policy that's in English that you can understand, gives you
[00:58:02.360 --> 00:58:05.120]   an opt out, gives you a way to take your data out of it.
[00:58:05.120 --> 00:58:09.600]   But when have you heard people say that in Google, I put up a thing in today, somebody
[00:58:09.600 --> 00:58:12.680]   in USA Today from Google actually kind of wrote that.
[00:58:12.680 --> 00:58:15.480]   And, and, and, and that's the test of raising something simply.
[00:58:15.480 --> 00:58:16.480]   It's in USA Today.
[00:58:16.480 --> 00:58:17.480]   Right.
[00:58:17.480 --> 00:58:19.800]   But that's the way they need to talk to.
[00:58:19.800 --> 00:58:20.800]   That's what they have out today.
[00:58:20.800 --> 00:58:21.800]   It's on the list under Google.
[00:58:21.800 --> 00:58:22.800]   Yeah, I see it.
[00:58:22.800 --> 00:58:25.800]   And we protect your data.
[00:58:25.800 --> 00:58:29.080]   Magic, you know, they should have been saying that months ago.
[00:58:29.080 --> 00:58:32.120]   And now the problem is it's probably too late to make this point.
[00:58:32.120 --> 00:58:36.520]   A search for Google privacy tools points you to a dozen ways to control your information.
[00:58:36.520 --> 00:58:38.360]   Yeah, this is good.
[00:58:38.360 --> 00:58:39.480]   This is what should have been written.
[00:58:39.480 --> 00:58:44.360]   This is from Alma Whitten, Google's director of privacy for product and engineering.
[00:58:44.360 --> 00:58:48.160]   If you go to the link below that, it's Derek Harris's piece in Gigalm.
[00:58:48.160 --> 00:58:49.480]   Yes, yes, yes.
[00:58:49.480 --> 00:58:50.800]   This is very good.
[00:58:50.800 --> 00:58:51.800]   Yeah.
[00:58:51.800 --> 00:58:56.320]   And just says, let's, let's cut the crap here.
[00:58:56.320 --> 00:58:59.040]   But I've been saying, I hate to say it, but I'm saying this.
[00:58:59.040 --> 00:59:00.040]   I don't know.
[00:59:00.040 --> 00:59:04.840]   And I've kind of get, I kind of gave up because people, it's, this is where it's a problem.
[00:59:04.840 --> 00:59:07.320]   I, I said it and people get upset at me.
[00:59:07.320 --> 00:59:09.200]   Oh, you're a Google fan boy.
[00:59:09.200 --> 00:59:12.000]   How dare you, you know, defend them.
[00:59:12.000 --> 00:59:13.480]   Everybody knows Google's evil.
[00:59:13.480 --> 00:59:15.400]   So go back to that org chart.
[00:59:15.400 --> 00:59:16.640]   Not that Google probably has any.
[00:59:16.640 --> 00:59:18.760]   They probably have it in 3D and moving.
[00:59:18.760 --> 00:59:20.760]   It's a Python script.
[00:59:20.760 --> 00:59:23.040]   Imagine there's a 2D org chart, right?
[00:59:23.040 --> 00:59:24.040]   Where do they need help?
[00:59:24.040 --> 00:59:27.800]   They need help in, um, get the word out.
[00:59:27.800 --> 00:59:31.360]   It's true public relations, relations with the public.
[00:59:31.360 --> 00:59:34.840]   And I think that's why you see Larry Page, who doesn't give interviews, finally giving
[00:59:34.840 --> 00:59:36.600]   an interview a business week.
[00:59:36.600 --> 00:59:37.600]   Way overdue.
[00:59:37.600 --> 00:59:39.240]   I think that's part of the responsible he should have.
[00:59:39.240 --> 00:59:41.400]   He is, he has to be the human to do it.
[00:59:41.400 --> 00:59:44.360]   Now there's a great interview also in business week.
[00:59:44.360 --> 00:59:47.680]   Actually it's from the 92nd Street, why were Marissa Meyer and we're some great little
[00:59:47.680 --> 00:59:48.680]   juicy tidbits.
[00:59:48.680 --> 00:59:51.880]   Nothing, nothing very shattering, but I'm going to share five things you didn't know
[00:59:51.880 --> 00:59:54.600]   about Google from that interview in just a second.
[00:59:54.600 --> 00:59:58.040]   We're talking about Google, the internet, the internet, the, actually we're talking
[00:59:58.040 --> 01:00:03.960]   about Google, the universe and everything on this episode of this week in Google with
[01:00:03.960 --> 01:00:07.680]   Gina Trappani, Matthew Ingram from giga ohm and Jeff Jarvis more in a bit.
[01:00:07.680 --> 01:00:12.200]   But first let's talk about Ford and sink.
[01:00:12.200 --> 01:00:13.200]   You know, I love sink.
[01:00:13.200 --> 01:00:15.440]   I have a Mustang, 2010 Mustang, which I love anyway.
[01:00:15.440 --> 01:00:16.440]   Who wouldn't love it?
[01:00:16.440 --> 01:00:18.760]   You turn it on, it goes boom boom boom boom.
[01:00:18.760 --> 01:00:23.520]   But it's kind of cool to have a muscle car that looks like it came straight out of, you
[01:00:23.520 --> 01:00:25.240]   know, bullet 1965.
[01:00:25.240 --> 01:00:29.440]   I feel like I'm Steve McQueen driving this thing and it's got Ford sink.
[01:00:29.440 --> 01:00:31.880]   It's got like the latest 21st century stuff in it.
[01:00:31.880 --> 01:00:32.880]   So here's the deal.
[01:00:32.880 --> 01:00:38.040]   Ford did a lot of studies, a lot of research, distracted driving, big issue, right?
[01:00:38.040 --> 01:00:39.360]   But people want to be connected.
[01:00:39.360 --> 01:00:43.800]   So on the one hand, there's consumers saying no, no, we want to be connected to the world
[01:00:43.800 --> 01:00:47.560]   and then there's all this research and government saying, yeah, but distracted driving is very,
[01:00:47.560 --> 01:00:49.400]   very, very dangerous.
[01:00:49.400 --> 01:00:53.520]   So Ford did the research and this is what they found is long as your eyes are on the
[01:00:53.520 --> 01:00:59.560]   road and your hands are on the wheel, you have sufficient cognitive resources to listen
[01:00:59.560 --> 01:01:04.800]   to talk, but the key is nothing can pull your attention over down to the console.
[01:01:04.800 --> 01:01:09.720]   You can't be fiddling with knobs, hands on the wheel, eyes on the road.
[01:01:09.720 --> 01:01:13.000]   That's why they came up with sink, which means you tell your car everything, you talk
[01:01:13.000 --> 01:01:17.160]   to it and it's safer because your hands don't leave the wheel.
[01:01:17.160 --> 01:01:19.040]   You don't have to look down at a screen.
[01:01:19.040 --> 01:01:20.440]   Everything is spoken to.
[01:01:20.440 --> 01:01:23.760]   You can even say, what's my horoscope and the sink will tell you.
[01:01:23.760 --> 01:01:26.720]   And now they've added this, which I love, it's app link.
[01:01:26.720 --> 01:01:29.880]   So what they told me, yeah, here it is, Ford.com/technology.
[01:01:29.880 --> 01:01:30.880]   You can look at it.
[01:01:30.880 --> 01:01:33.880]   What they told me is, well, we understand that we're never going to iterate our technology
[01:01:33.880 --> 01:01:39.680]   as fast as app developers are iterating their technology on the Android and the iPhone.
[01:01:39.680 --> 01:01:45.160]   So what we're going to do is give developers a mobile application developer network will
[01:01:45.160 --> 01:01:47.920]   work with them to get their apps on Ford Sync.
[01:01:47.920 --> 01:01:51.320]   We'll give you a full API.
[01:01:51.320 --> 01:01:52.680]   And that's what app link is.
[01:01:52.680 --> 01:01:57.280]   It's an API platform that allows Ford and app developers to bring in vehicle voice control,
[01:01:57.280 --> 01:02:00.840]   that Ford Sync to apps on your phone.
[01:02:00.840 --> 01:02:03.560]   You don't have to update the software and the vehicle.
[01:02:03.560 --> 01:02:04.880]   You just connect to the phone.
[01:02:04.880 --> 01:02:09.240]   Now it started with Pandora and you had all the Pandora controls in voice, thumbs up, thumbs
[01:02:09.240 --> 01:02:12.800]   down, next station, play my Rolling Stone station, that kind of thing.
[01:02:12.800 --> 01:02:13.800]   Then there was OpenBeak.
[01:02:13.800 --> 01:02:14.960]   You could read tweets.
[01:02:14.960 --> 01:02:18.360]   There was slacker radio for podcast, Stitcher for podcast.
[01:02:18.360 --> 01:02:22.640]   Now they've got iHeartRadio and it supports their ThumPlay service.
[01:02:22.640 --> 01:02:23.640]   So you're listening.
[01:02:23.640 --> 01:02:26.680]   You say, I want to hear KFI, you're saved stations.
[01:02:26.680 --> 01:02:28.320]   You just pull them up by name.
[01:02:28.320 --> 01:02:31.520]   We can skip to the next song when you're listening to their radio, their music, their
[01:02:31.520 --> 01:02:32.520]   Pandora thing.
[01:02:32.520 --> 01:02:33.920]   You can give a song, a thumbs up.
[01:02:33.920 --> 01:02:36.200]   NPR has breaking news now.
[01:02:36.200 --> 01:02:38.280]   You say, I want to hear all things considered.
[01:02:38.280 --> 01:02:40.040]   I want to hear this American life.
[01:02:40.040 --> 01:02:41.040]   Boom, boom.
[01:02:41.040 --> 01:02:44.800]   Actually, I don't know if this American life's on it.
[01:02:44.800 --> 01:02:47.520]   That's another public radio system.
[01:02:47.520 --> 01:02:50.560]   They got to get this together.
[01:02:50.560 --> 01:02:55.000]   They have this destinations thing, sync destinations, which is an app on your phone.
[01:02:55.000 --> 01:02:59.200]   You could take the phone's navigation and bring it to the car.
[01:02:59.200 --> 01:03:01.720]   It's simple.
[01:03:01.720 --> 01:03:07.600]   It's obvious once I say it, make an API so the car's computer can talk to the phone apps
[01:03:07.600 --> 01:03:11.120]   and then your hands stay on the wheel, your eyes are on the road and yet you have the
[01:03:11.120 --> 01:03:13.840]   world at your fingertips and it's updated.
[01:03:13.840 --> 01:03:15.080]   This is so slick.
[01:03:15.080 --> 01:03:16.080]   Try it.
[01:03:16.080 --> 01:03:17.080]   Go to a Ford dealer.
[01:03:17.080 --> 01:03:18.080]   Drive one today.
[01:03:18.080 --> 01:03:22.840]   There's almost, mine unfortunately does not have AppLink, but all the new Ford's do.
[01:03:22.840 --> 01:03:25.480]   Tell the Ford dealer you want to take a look at AppLink.
[01:03:25.480 --> 01:03:28.400]   They'll give you a demo or visit for.com/technology.
[01:03:28.400 --> 01:03:31.080]   They've got the videos on there and more.
[01:03:31.080 --> 01:03:32.080]   Pretty cool stuff.
[01:03:32.080 --> 01:03:38.240]   Well, wasn't there a car once that like the Google Glass's projected info on the device?
[01:03:38.240 --> 01:03:39.240]   There still are.
[01:03:39.240 --> 01:03:40.240]   There are a number of cars.
[01:03:40.240 --> 01:03:41.240]   Audi does that.
[01:03:41.240 --> 01:03:43.080]   I think Mercedes has a heads up display.
[01:03:43.080 --> 01:03:44.080]   Yeah.
[01:03:44.080 --> 01:03:46.960]   Audi has something that is really wild.
[01:03:46.960 --> 01:03:50.240]   They have night vision and they'll project pedestrians.
[01:03:50.240 --> 01:03:53.240]   I think I've told this that project pedestrians on the screen.
[01:03:53.240 --> 01:03:57.560]   They had it, yes, they were there and they had a simulator with hydraulics.
[01:03:57.560 --> 01:04:00.760]   So you'd think you were in the car and you'd be driving around and they showed if you
[01:04:00.760 --> 01:04:01.920]   drift out of a lane.
[01:04:01.920 --> 01:04:06.000]   It's kind of the car stuff is very interesting, but I have to say, not all these manufacturers
[01:04:06.000 --> 01:04:08.600]   have the same focus on distracted driving.
[01:04:08.600 --> 01:04:12.560]   I was stunned because Mercedes said, "Whoa, we're putting Facebook and Mercedes.
[01:04:12.560 --> 01:04:17.120]   All you have to do is turn a knob and pick the message you want to send your status message
[01:04:17.120 --> 01:04:18.120]   and push the button."
[01:04:18.120 --> 01:04:20.760]   Oh, that's a good idea.
[01:04:20.760 --> 01:04:24.160]   Is it that important?
[01:04:24.160 --> 01:04:27.320]   Well, it would make an episode of Glee.
[01:04:27.320 --> 01:04:28.320]   Cheese.
[01:04:28.320 --> 01:04:33.200]   Oh, a car crash was hanger, exactly.
[01:04:33.200 --> 01:04:35.120]   Smart.
[01:04:35.120 --> 01:04:36.160]   So it really is important.
[01:04:36.160 --> 01:04:40.560]   And I think Alan Malallion and his team are really doing a lot and this is not the for
[01:04:40.560 --> 01:04:45.440]   dad anymore, but I think they're really thinking responsibility.
[01:04:45.440 --> 01:04:49.440]   There's a huge responsibility and one of the things they're terrified about, they don't
[01:04:49.440 --> 01:04:53.840]   want the government to suddenly say, "Oh, by the way, you can't talk on the phone anymore
[01:04:53.840 --> 01:04:54.840]   in your car."
[01:04:54.840 --> 01:04:59.520]   There is that risk that if they do not take, this is always true, if they don't take it
[01:04:59.520 --> 01:05:04.400]   in hand and really be responsive that they'll be forced to and then maybe in a way that consumers
[01:05:04.400 --> 01:05:05.840]   don't like and the companies don't like.
[01:05:05.840 --> 01:05:08.280]   And you know the new proposed standards?
[01:05:08.280 --> 01:05:11.200]   Yes, the NTSB does not want you talking on the phone.
[01:05:11.200 --> 01:05:15.200]   Right, so there's new standards that cut down all kinds of things.
[01:05:15.200 --> 01:05:16.200]   Yeah.
[01:05:16.200 --> 01:05:20.400]   Oh, damn, I can't find them right now, but a whole new set of standards that would cut
[01:05:20.400 --> 01:05:22.200]   down what you're allowed to do in the car.
[01:05:22.200 --> 01:05:24.520]   What car manufacturers can give you.
[01:05:24.520 --> 01:05:27.560]   It's scary because just as they get more sophisticated, they'll get dumbed down.
[01:05:27.560 --> 01:05:28.560]   Right.
[01:05:28.560 --> 01:05:33.400]   And it's interesting, you know, we were looking at the Google classes and how to some extent
[01:05:33.400 --> 01:05:37.800]   a heads up display makes a lot of sense, especially if you're trying to follow directions or
[01:05:37.800 --> 01:05:42.920]   you're trying to get information without looking down so you walk into things.
[01:05:42.920 --> 01:05:44.480]   That's even more the case when you're driving.
[01:05:44.480 --> 01:05:48.280]   The more information you can get that's overlaid on the road while you're driving, the less
[01:05:48.280 --> 01:05:49.280]   you have to look away.
[01:05:49.280 --> 01:05:50.280]   Yeah, heads up is cool.
[01:05:50.280 --> 01:05:53.720]   Of course, I predict that I predict within two years it will be illegal to wear your Google
[01:05:53.720 --> 01:05:54.720]   class.
[01:05:54.720 --> 01:05:57.160]   Oh, yeah, nobody's going to be wearing Google class.
[01:05:57.160 --> 01:06:02.760]   But I think within five years, there'll be calls to outlaw while walking.
[01:06:02.760 --> 01:06:08.680]   Then the absurdity of that would be made clear to the staff that proposes it.
[01:06:08.680 --> 01:06:09.680]   Yeah.
[01:06:09.680 --> 01:06:12.200]   It will create a little bit of an isolating experience though.
[01:06:12.200 --> 01:06:15.400]   You know, like when headphones, you know, we go on any college campus, campus, everyone's
[01:06:15.400 --> 01:06:18.640]   walking across campus with headphones in and people don't read one another and talk as
[01:06:18.640 --> 01:06:19.640]   much.
[01:06:19.640 --> 01:06:22.280]   If everyone's kind of stuck into their heads up display, it also, you know, creates this
[01:06:22.280 --> 01:06:24.200]   other layer of isolating.
[01:06:24.200 --> 01:06:27.680]   I'm telling you, there is a risk.
[01:06:27.680 --> 01:06:29.920]   This is the problem is that we as geeks, we want this.
[01:06:29.920 --> 01:06:31.920]   We don't want it to see people.
[01:06:31.920 --> 01:06:32.920]   Right.
[01:06:32.920 --> 01:06:36.040]   I want to see virtual people.
[01:06:36.040 --> 01:06:39.040]   Work conforming the world to our own introverted notions.
[01:06:39.040 --> 01:06:41.880]   It is sure as not called this week in people.
[01:06:41.880 --> 01:06:44.960]   Get the people out of here.
[01:06:44.960 --> 01:06:45.960]   So five things.
[01:06:45.960 --> 01:06:46.960]   Go ahead.
[01:06:46.960 --> 01:06:52.640]   I don't know if you had sonar.me or highlight or something like that integrated into your
[01:06:52.640 --> 01:06:53.640]   glasses.
[01:06:53.640 --> 01:06:58.000]   I could tell you when someone was nearby that you might want to talk to do not or or
[01:06:58.000 --> 01:06:59.600]   or girls around me.
[01:06:59.600 --> 01:07:00.600]   Yeah.
[01:07:00.600 --> 01:07:01.600]   Girls around me.
[01:07:01.600 --> 01:07:02.600]   What did you think about that?
[01:07:02.600 --> 01:07:03.600]   Huh?
[01:07:03.600 --> 01:07:04.600]   Oh, yeah.
[01:07:04.600 --> 01:07:05.600]   Yeah.
[01:07:05.600 --> 01:07:06.600]   Exactly.
[01:07:06.600 --> 01:07:07.600]   You first.
[01:07:07.600 --> 01:07:08.600]   You tweeted brilliantly on it.
[01:07:08.600 --> 01:07:10.200]   So, I mean, the whole point of four square and location services that you can find other
[01:07:10.200 --> 01:07:11.200]   people.
[01:07:11.200 --> 01:07:12.200]   I accept that.
[01:07:12.200 --> 01:07:16.000]   But girls around me was an iPhone app, which I don't think exists anymore or at least
[01:07:16.000 --> 01:07:17.000]   four square.
[01:07:17.000 --> 01:07:18.000]   Apple killed it.
[01:07:18.000 --> 01:07:20.680]   Four squared pulled the API and then Apple killed the app.
[01:07:20.680 --> 01:07:22.440]   And then Apple killed the app.
[01:07:22.440 --> 01:07:26.960]   Girls around me would launch and you'd see this lovely radar screen with the silhouette
[01:07:26.960 --> 01:07:32.200]   of naked women kind of dancing on the radar and would let you in which would show you
[01:07:32.200 --> 01:07:36.560]   people who registered on Facebook as female and their photos and all their history.
[01:07:36.560 --> 01:07:41.840]   So it was a way to find women girls quote unquote around you.
[01:07:41.840 --> 01:07:46.560]   And I had a serious problem not with the premise of the app, which is finding people near you.
[01:07:46.560 --> 01:07:48.440]   That's a premise to four square and I use that.
[01:07:48.440 --> 01:07:50.760]   Or look at the highlight, which does exactly the same.
[01:07:50.760 --> 01:07:51.760]   Or highlight.
[01:07:51.760 --> 01:07:53.280]   Same thing, but it was the design.
[01:07:53.280 --> 01:07:54.280]   It was a weapon.
[01:07:54.280 --> 01:07:55.280]   It was clearly weaponized design.
[01:07:55.280 --> 01:07:56.280]   I don't like that.
[01:07:56.280 --> 01:07:58.640]   I mean, it's like, it's like, Stalker's here.
[01:07:58.640 --> 01:08:01.000]   You know, Stalker's come down low this app here.
[01:08:01.000 --> 01:08:03.160]   So that was the problem that I had because a lot of people said, hey, you know, this
[01:08:03.160 --> 01:08:05.560]   is the whole point about four squares of finding people nearby.
[01:08:05.560 --> 01:08:07.400]   I don't think there's a problem with that.
[01:08:07.400 --> 01:08:13.200]   It was the fact that this app was designed shamelessly and clearly designed for people
[01:08:13.200 --> 01:08:16.680]   who were, you know, their chicks checking in near you.
[01:08:16.680 --> 01:08:18.640]   I mean, this was like the actual app copy.
[01:08:18.640 --> 01:08:22.120]   But that was that was really what it was is that they were tone deaf designers.
[01:08:22.120 --> 01:08:26.440]   You know, I mean, that, look, Mark Zuckerberg, yeah, I mean, yeah, and that's this is something
[01:08:26.440 --> 01:08:27.920]   that Zuck may have built when he was in college.
[01:08:27.920 --> 01:08:28.920]   Let me tell you something.
[01:08:28.920 --> 01:08:32.920]   Mark Zuckerberg made Facebook to get laid and people use Facebook.
[01:08:32.920 --> 01:08:37.200]   That's the primary reason people use Facebook is they want to meet people of the other, you
[01:08:37.200 --> 01:08:41.680]   know, that they're, I won't say opposite sex of the people that they're interested in.
[01:08:41.680 --> 01:08:43.920]   That's the primary purpose of it still.
[01:08:43.920 --> 01:08:52.080]   But Zuck had the good sense to obfuscate that to make it right, to make it right.
[01:08:52.080 --> 01:08:54.360]   And it is a problem.
[01:08:54.360 --> 01:08:56.240]   It only takes one bows or a ruin it, right?
[01:08:56.240 --> 01:09:01.480]   This is a classic case that the piece that I put on this is from O'Reilly by Mike, if
[01:09:01.480 --> 01:09:05.080]   I get this right, look at it is new.
[01:09:05.080 --> 01:09:09.720]   It's a good, a good and recent piece about it saying that, yeah, you might want to find
[01:09:09.720 --> 01:09:13.120]   car repair people around you or geeks around you or hackers around you or other people around
[01:09:13.120 --> 01:09:14.120]   you.
[01:09:14.120 --> 01:09:15.120]   The functionality works.
[01:09:15.120 --> 01:09:18.800]   The problem is one person does this and then someone's going to come along and try to outlaw
[01:09:18.800 --> 01:09:21.960]   every possible use of the same technology because one person.
[01:09:21.960 --> 01:09:22.960]   Right.
[01:09:22.960 --> 01:09:23.960]   Do something bad.
[01:09:23.960 --> 01:09:25.960]   And that's the world that we're in right now.
[01:09:25.960 --> 01:09:29.760]   I just search for the app and one of the latest news.
[01:09:29.760 --> 01:09:32.120]   If you just read the headline right here.
[01:09:32.120 --> 01:09:33.320]   Our app's not for stalking them.
[01:09:33.320 --> 01:09:34.920]   It's for avoiding the ugly one.
[01:09:34.920 --> 01:09:36.160]   See it tone deaf.
[01:09:36.160 --> 01:09:37.600]   See tone deaf.
[01:09:37.600 --> 01:09:38.720]   That was exactly it.
[01:09:38.720 --> 01:09:39.720]   It was tone deaf.
[01:09:39.720 --> 01:09:40.720]   They didn't get it.
[01:09:40.720 --> 01:09:41.720]   They didn't.
[01:09:41.720 --> 01:09:42.720]   I mean, it was beyond tone deaf.
[01:09:42.720 --> 01:09:43.720]   It was on the sogenetic.
[01:09:43.720 --> 01:09:45.840]   I mean, it's the title girls.
[01:09:45.840 --> 01:09:49.720]   I mean, they were talking about women because an app that actually showed you girls like
[01:09:49.720 --> 01:09:53.160]   girls like and I define a girl as an menstruated yet.
[01:09:53.160 --> 01:09:54.160]   That would be illegal.
[01:09:54.160 --> 01:09:55.160]   Okay.
[01:09:55.160 --> 01:09:59.080]   So the whole thing, sorry, I didn't mean to go into a girls around me rant.
[01:09:59.080 --> 01:10:00.080]   Wow.
[01:10:00.080 --> 01:10:01.760]   The whole thing was just these guys are idiots.
[01:10:01.760 --> 01:10:02.760]   I mean, they're.
[01:10:02.760 --> 01:10:06.560]   There's that larger point, which is it's not doing something that these apps weren't intended
[01:10:06.560 --> 01:10:07.560]   to do.
[01:10:07.560 --> 01:10:08.560]   No, right.
[01:10:08.560 --> 01:10:10.680]   But it just was blatant about it.
[01:10:10.680 --> 01:10:13.600]   It was lean about it was bad intentioned.
[01:10:13.600 --> 01:10:15.640]   It was just like I disagree.
[01:10:15.640 --> 01:10:16.640]   I would disagree.
[01:10:16.640 --> 01:10:18.880]   The intention is always the same intention.
[01:10:18.880 --> 01:10:21.680]   Well, it's an old for like almost a year.
[01:10:21.680 --> 01:10:23.640]   I mean, this has been around for a long time.
[01:10:23.640 --> 01:10:24.640]   It's been around a long time.
[01:10:24.640 --> 01:10:25.640]   Do you remember Docker Stalker?
[01:10:25.640 --> 01:10:28.040]   Do you know, were you were you like Docker with Docker Stalker?
[01:10:28.040 --> 01:10:29.040]   Yes, I do.
[01:10:29.040 --> 01:10:30.040]   I do.
[01:10:30.040 --> 01:10:32.720]   Gina, do you have a problem with grinder?
[01:10:32.720 --> 01:10:33.720]   No, I don't.
[01:10:33.720 --> 01:10:35.840]   It's exactly the same purpose.
[01:10:35.840 --> 01:10:38.320]   But grinder, you are signing in for that purpose.
[01:10:38.320 --> 01:10:39.320]   You are using it.
[01:10:39.320 --> 01:10:40.320]   Exactly.
[01:10:40.320 --> 01:10:41.320]   Only for the.
[01:10:41.320 --> 01:10:42.320]   Ah, you're right.
[01:10:42.320 --> 01:10:43.320]   Okay.
[01:10:43.320 --> 01:10:44.320]   You're right.
[01:10:44.320 --> 01:10:45.320]   You're opting into being grinded.
[01:10:45.320 --> 01:10:48.440]   You're telling your buddies where you are and this place is using it for purpose.
[01:10:48.440 --> 01:10:50.720]   And that's the argument in the O'Reilly piece.
[01:10:50.720 --> 01:10:55.200]   Helen Nissenbaum, who's who's being very influential right now in privacy talks about
[01:10:55.200 --> 01:10:56.200]   context.
[01:10:56.200 --> 01:11:01.880]   And it's a good concept, but I find it almost impossible to imagine an execution in all
[01:11:01.880 --> 01:11:02.880]   these cases.
[01:11:02.880 --> 01:11:06.360]   So, but the argument in this case was if you're using grinder, the context is very clear.
[01:11:06.360 --> 01:11:09.360]   You are getting laid because that's the whole point.
[01:11:09.360 --> 01:11:10.360]   Right.
[01:11:10.360 --> 01:11:14.320]   Whereas you're using your giving Facebook data to tell your buddies and your family where
[01:11:14.320 --> 01:11:15.320]   you are.
[01:11:15.320 --> 01:11:18.480]   And then it's being used in this terrible way and it violates the context.
[01:11:18.480 --> 01:11:22.840]   So their real mistake was just not making a heterosexual grinder.
[01:11:22.840 --> 01:11:24.640]   I had a student who.
[01:11:24.640 --> 01:11:26.200]   That's a couple of them out there already.
[01:11:26.200 --> 01:11:27.200]   Oh, really?
[01:11:27.200 --> 01:11:28.200]   Yeah.
[01:11:28.200 --> 01:11:34.040]   And who taught me about grinder who found his straight friends were amazed at this.
[01:11:34.040 --> 01:11:37.840]   And so his business for my classes, Too Bet He Didn't Do It, was going to do that way
[01:11:37.840 --> 01:11:38.840]   early on.
[01:11:38.840 --> 01:11:39.840]   Straight grinder.
[01:11:39.840 --> 01:11:40.840]   Yeah.
[01:11:40.840 --> 01:11:41.840]   Yeah.
[01:11:41.840 --> 01:11:42.840]   There's one called Tingle.
[01:11:42.840 --> 01:11:43.840]   I think it is.
[01:11:43.840 --> 01:11:44.840]   Ooh, I like that.
[01:11:44.840 --> 01:11:45.840]   Ooh, it's going to be a tingle.
[01:11:45.840 --> 01:11:46.840]   Yeah.
[01:11:46.840 --> 01:11:47.840]   I mean, any dating site, right, where you say, you know, come by.
[01:11:47.840 --> 01:11:49.240]   I mean, grinder works particularly well.
[01:11:49.240 --> 01:11:51.760]   The target demo is game man, right?
[01:11:51.760 --> 01:11:52.760]   There is.
[01:11:52.760 --> 01:11:53.760]   Yes, right.
[01:11:53.760 --> 01:11:54.760]   Right.
[01:11:54.760 --> 01:11:56.480]   So, I mean, that's a really good demographic.
[01:11:56.480 --> 01:11:57.480]   We're opting into fun.
[01:11:57.480 --> 01:11:59.480]   You know, it's pretty safe to say.
[01:11:59.480 --> 01:12:02.960]   I won't go into queer politics here or whatever.
[01:12:02.960 --> 01:12:04.960]   Those guys are pigs.
[01:12:04.960 --> 01:12:07.400]   I like to hook up.
[01:12:07.400 --> 01:12:12.360]   No, no, stop, stop, stop, stop, stop.
[01:12:12.360 --> 01:12:15.160]   I think we've made the point.
[01:12:15.160 --> 01:12:16.600]   Let's move on.
[01:12:16.600 --> 01:12:18.760]   I really want to go ahead, Matt.
[01:12:18.760 --> 01:12:19.760]   Go ahead.
[01:12:19.760 --> 01:12:20.760]   Sorry.
[01:12:20.760 --> 01:12:21.760]   Just one thing.
[01:12:21.760 --> 01:12:24.360]   I thought Jeff, you know, Helen, this and Bob makes a really good point about context.
[01:12:24.360 --> 01:12:26.360]   How we do it is a lot more complicated.
[01:12:26.360 --> 01:12:33.640]   But I think the point is, when I wrote a public parts plug, I struggled with that because
[01:12:33.640 --> 01:12:34.960]   a lot of people admire Helen.
[01:12:34.960 --> 01:12:35.960]   I admire her too.
[01:12:35.960 --> 01:12:36.960]   She's very smart.
[01:12:36.960 --> 01:12:37.960]   She's an annoying you.
[01:12:37.960 --> 01:12:42.240]   I read her book and every argument makes sense, but then I cannot imagine the execution
[01:12:42.240 --> 01:12:43.240]   of it.
[01:12:43.240 --> 01:12:45.680]   I mean, you can, but that's what actually taught me.
[01:12:45.680 --> 01:12:50.360]   So I turned it around using data void who, and this is the point that Tim O'Reilly makes
[01:12:50.360 --> 01:12:54.760]   in the piece on O'Reilly is that it's about the use, not the gathering of the data.
[01:12:54.760 --> 01:12:57.040]   It's about the behavior, not the technology.
[01:12:57.040 --> 01:13:02.040]   And so the way I learned from it was to turn it around and say that you can't probably
[01:13:02.040 --> 01:13:06.440]   make a law or regulations that can anticipate context, so they can't anticipate it.
[01:13:06.440 --> 01:13:12.440]   But you can have an ethical standard that says to these guys, come on, you know this
[01:13:12.440 --> 01:13:14.400]   is evil, this is wrong, it's misusing.
[01:13:14.400 --> 01:13:16.800]   Well, and I think that's exactly what happened.
[01:13:16.800 --> 01:13:17.800]   Exactly.
[01:13:17.800 --> 01:13:18.800]   They got some math.
[01:13:18.800 --> 01:13:19.800]   So it worked in this case.
[01:13:19.800 --> 01:13:20.800]   It didn't work from regulation.
[01:13:20.800 --> 01:13:21.800]   It didn't work from legislation.
[01:13:21.800 --> 01:13:22.800]   Right.
[01:13:22.800 --> 01:13:23.800]   It worked from the norms.
[01:13:23.800 --> 01:13:27.920]   You just saw a new line and you're a mile over, Paul's oh, get back.
[01:13:27.920 --> 01:13:31.320]   And the chatroom's suggesting, and I think this is going to be my next app, Bacon Around
[01:13:31.320 --> 01:13:32.320]   Me.
[01:13:32.320 --> 01:13:40.400]   Now that I'd spend money for.
[01:13:40.400 --> 01:13:41.560]   I just want to go home now.
[01:13:41.560 --> 01:13:43.240]   Let's all just go home and take a shower.
[01:13:43.240 --> 01:13:44.240]   All right.
[01:13:44.240 --> 01:13:45.240]   Time to eat.
[01:13:45.240 --> 01:13:47.080]   It's time to eat bacon, bacon.
[01:13:47.080 --> 01:13:51.200]   Five things you didn't know about Google M1, and then we'll get your picks and tips and
[01:13:51.200 --> 01:13:52.200]   so forth.
[01:13:52.200 --> 01:13:53.680]   I wish I'd seen this.
[01:13:53.680 --> 01:13:58.760]   92nd Street Y is great where people really go and they talk and she spent 90 minutes
[01:13:58.760 --> 01:14:04.520]   talking with Josh Tyrangel of Business Week.
[01:14:04.520 --> 01:14:05.520]   Tyrangel.
[01:14:05.520 --> 01:14:06.520]   Google.
[01:14:06.520 --> 01:14:08.520]   I don't know.
[01:14:08.520 --> 01:14:12.600]   He and Michael Kydes can just get together and figure out how to say their names.
[01:14:12.600 --> 01:14:16.280]   Google basics, white homepage wasn't an old diminimalism.
[01:14:16.280 --> 01:14:18.920]   It was pure necessity, said Marissa Meyer.
[01:14:18.920 --> 01:14:22.400]   We don't have a webmaster and I don't do HTML.
[01:14:22.400 --> 01:14:25.880]   Sergey Brin is famous for saying.
[01:14:25.880 --> 01:14:28.840]   It's simple because I can't do anything fancier.
[01:14:28.840 --> 01:14:34.280]   Marissa Meyer almost killed the idea of targeting ads against users email because she thought
[01:14:34.280 --> 01:14:36.280]   it was creepy.
[01:14:36.280 --> 01:14:38.480]   A colleague.
[01:14:38.480 --> 01:14:39.480]   Yeah.
[01:14:39.480 --> 01:14:40.480]   She knew.
[01:14:40.480 --> 01:14:43.840]   She actually, I was embarrassed that she even thought that.
[01:14:43.840 --> 01:14:45.000]   She was right.
[01:14:45.000 --> 01:14:51.080]   A colleague working on an all-nighter ignored her and of course created AdSense.
[01:14:51.080 --> 01:14:59.600]   Google has calculated that an ad on its homepage would cost at least $10 million but it's
[01:14:59.600 --> 01:15:02.000]   not for sale.
[01:15:02.000 --> 01:15:04.000]   This is one that just shocked me.
[01:15:04.000 --> 01:15:08.720]   Most Google pages sport a small copyright notice at the bottom.
[01:15:08.720 --> 01:15:10.000]   Why?
[01:15:10.000 --> 01:15:12.520]   Not because it's necessary.
[01:15:12.520 --> 01:15:17.800]   But it turned out when they tested it that users would just stare at the homepage, waiting
[01:15:17.800 --> 01:15:19.960]   for the rest of it to load.
[01:15:19.960 --> 01:15:23.240]   And we're so conditioned that once the copyright loads, oh, it's all done.
[01:15:23.240 --> 01:15:25.040]   So they put a copyright.
[01:15:25.040 --> 01:15:26.960]   Is that my favorite?
[01:15:26.960 --> 01:15:27.960]   Brilliant.
[01:15:27.960 --> 01:15:28.800]   It's done.
[01:15:28.800 --> 01:15:30.720]   You can now click.
[01:15:30.720 --> 01:15:32.040]   And that came from user testing.
[01:15:32.040 --> 01:15:36.080]   That came from showing the pages again and again and again to people.
[01:15:36.080 --> 01:15:37.640]   Just love that.
[01:15:37.640 --> 01:15:38.640]   All right.
[01:15:38.640 --> 01:15:39.640]   Time, my friends.
[01:15:39.640 --> 01:15:46.400]   There's lots more Facebook threatening to sue it, comment or untick, crunch.
[01:15:46.400 --> 01:15:47.400]   But let's move on.
[01:15:47.400 --> 01:15:48.400]   I think.
[01:15:48.400 --> 01:15:49.400]   Yeah, I mentioned just one thing.
[01:15:49.400 --> 01:15:54.400]   There's a really good piece and believe it or not, the current issue of Vanity Fair about
[01:15:54.400 --> 01:15:55.400]   the war with the dynamic.
[01:15:55.400 --> 01:15:56.400]   We're talking about a next week.
[01:15:56.400 --> 01:15:57.400]   I love Vanity Fair.
[01:15:57.400 --> 01:15:58.400]   What do you mean, believe it or not?
[01:15:58.400 --> 01:16:01.640]   Well, it's not exactly doing, well, you know, compete with Wired.
[01:16:01.640 --> 01:16:03.160]   It's good piece.
[01:16:03.160 --> 01:16:04.160]   That's all I mean.
[01:16:04.160 --> 01:16:07.320]   It's a very good piece that goes on about the war with a net that's coming the dangers
[01:16:07.320 --> 01:16:08.320]   to the net.
[01:16:08.320 --> 01:16:09.320]   Cool.
[01:16:09.320 --> 01:16:11.400]   What expresses it very well, I think.
[01:16:11.400 --> 01:16:13.680]   Is it a Tim Wu kind of a thing or?
[01:16:13.680 --> 01:16:15.840]   No, it's more about the UN.
[01:16:15.840 --> 01:16:16.840]   The white boat.
[01:16:16.840 --> 01:16:19.080]   They won't take control over.
[01:16:19.080 --> 01:16:22.480]   Yeah, just efforts to control the net.
[01:16:22.480 --> 01:16:25.920]   And so I just recommended for reading.
[01:16:25.920 --> 01:16:29.680]   It's for discussion next week.
[01:16:29.680 --> 01:16:35.400]   And also we should mention this, that Starbucks right now you get a Google offer deal $5 for
[01:16:35.400 --> 01:16:36.400]   $10 at Starbucks.
[01:16:36.400 --> 01:16:40.640]   Yeah, but $3 goes to creating jobs, apparently.
[01:16:40.640 --> 01:16:42.480]   Oh, I was just thinking about the money.
[01:16:42.480 --> 01:16:43.480]   Okay.
[01:16:43.480 --> 01:16:46.480]   So it's good for job stuff.
[01:16:46.480 --> 01:16:47.960]   It's good for the economy.
[01:16:47.960 --> 01:16:48.960]   Go to Starbucks.
[01:16:48.960 --> 01:16:49.960]   Not too.
[01:16:49.960 --> 01:16:50.960]   Starbucks gift cards.
[01:16:50.960 --> 01:16:53.080]   You know, I have a Starbucks card.
[01:16:53.080 --> 01:16:57.880]   I wonder if I could like just add more, use this to add more dollars to it.
[01:16:57.880 --> 01:16:59.360]   Yeah, I guess so probably.
[01:16:59.360 --> 01:17:00.560]   Hey, Paul, you got a gift card.
[01:17:00.560 --> 01:17:01.560]   Yeah.
[01:17:01.560 --> 01:17:02.560]   Yeah.
[01:17:02.560 --> 01:17:04.720]   $5 for $10 gift card.
[01:17:04.720 --> 01:17:07.720]   And $3 goes to jobs.
[01:17:07.720 --> 01:17:08.720]   Nothing wrong with jobs.
[01:17:08.720 --> 01:17:09.720]   Steve.
[01:17:09.720 --> 01:17:10.720]   Not Steve.
[01:17:10.720 --> 01:17:11.720]   Some other jobs.
[01:17:11.720 --> 01:17:12.720]   Jobs for USA.
[01:17:12.720 --> 01:17:14.720]   Jobs in the US.
[01:17:14.720 --> 01:17:15.720]   Jobs in the US.
[01:17:15.720 --> 01:17:18.080]   Leo, have you been talking on Twitter?
[01:17:18.080 --> 01:17:21.080]   I missed this week's episode about the jobs bill.
[01:17:21.080 --> 01:17:23.000]   You know, we didn't and we should.
[01:17:23.000 --> 01:17:24.000]   It's very close to passing.
[01:17:24.000 --> 01:17:28.000]   It's passed both houses and of the Congress and now it just waits.
[01:17:28.000 --> 01:17:30.000]   Oh, wait, President Obama's signature, right?
[01:17:30.000 --> 01:17:31.000]   Yeah.
[01:17:31.000 --> 01:17:32.000]   So tomorrow I think.
[01:17:32.000 --> 01:17:36.600]   Jobs does not stand for jobs actually, oddly enough.
[01:17:36.600 --> 01:17:38.240]   What does it stand for?
[01:17:38.240 --> 01:17:41.400]   Oh, let me, I'll look it up.
[01:17:41.400 --> 01:17:42.400]   I hate these acronyms.
[01:17:42.400 --> 01:17:43.400]   They're so funny.
[01:17:43.400 --> 01:17:46.080]   Jumpstart, our business startups act.
[01:17:46.080 --> 01:17:52.000]   Now, here's the thing that it's overturning what I thought were quite reasonable restrictions
[01:17:52.000 --> 01:17:59.600]   that were designed to keep suckers from being taken by con men getting them to invest in
[01:17:59.600 --> 01:18:00.600]   stuff.
[01:18:00.600 --> 01:18:03.640]   Well, that's what Andrew Ross Sorkin tried to say in the times.
[01:18:03.640 --> 01:18:07.000]   And I think he's right to an extent that there are controls that are necessary.
[01:18:07.000 --> 01:18:09.000]   Those are safety net.
[01:18:09.000 --> 01:18:10.000]   Yeah, but there's two things.
[01:18:10.000 --> 01:18:11.000]   There's an example.
[01:18:11.000 --> 01:18:12.200]   They wouldn't even be covered.
[01:18:12.200 --> 01:18:13.200]   Right.
[01:18:13.200 --> 01:18:16.640]   But as Henry Blodgett said, you know, it's not the SEC's job.
[01:18:16.640 --> 01:18:20.160]   I mean, listen, any idiot could know the group on was a bad investment.
[01:18:20.160 --> 01:18:22.400]   And now, unfortunately, there were a lot of people who were idiots and invested in it.
[01:18:22.400 --> 01:18:24.440]   I was screaming and others were screaming at it.
[01:18:24.440 --> 01:18:26.400]   It was a bad investment.
[01:18:26.400 --> 01:18:30.320]   And you can't stop people from investing in bad companies.
[01:18:30.320 --> 01:18:35.840]   Now, the separate issue is, you know, if you have a fraudulent company, if you're in penny
[01:18:35.840 --> 01:18:40.360]   stock land and it's just plain old crap, that comes broadly, that's an issue.
[01:18:40.360 --> 01:18:46.440]   But we have a big problem with capital in the country and startups to be able to enable
[01:18:46.440 --> 01:18:52.880]   one early liquidity and two to enable a Kickstarter of equity, which is what the low end of this
[01:18:52.880 --> 01:18:53.880]   bill does.
[01:18:53.880 --> 01:18:55.160]   I didn't mean to get the whole discussion.
[01:18:55.160 --> 01:19:00.320]   But I think it's an important thing for where we go in the entrepreneurial investment in
[01:19:00.320 --> 01:19:01.320]   the country.
[01:19:01.320 --> 01:19:04.960]   And it's going to be important to what we cover on Twig and such.
[01:19:04.960 --> 01:19:05.960]   But we're --
[01:19:05.960 --> 01:19:10.680]   No, I'm glad you brought it up because in fact, we hadn't really had this conversation.
[01:19:10.680 --> 01:19:12.560]   This would be the best place to do it.
[01:19:12.560 --> 01:19:18.080]   And it actually sounds to me as though there's -- it's sort of two bills in one in a way,
[01:19:18.080 --> 01:19:20.160]   or there's a good part and a bad part.
[01:19:20.160 --> 01:19:24.640]   And the good part, or what most people agree is the good part, is that it encourages crowd
[01:19:24.640 --> 01:19:29.200]   funding, it allows you to raise smaller amounts of money from more people, and that's all
[01:19:29.200 --> 01:19:30.200]   good.
[01:19:30.200 --> 01:19:35.040]   And then there's another part of the bill that kind of scales back some of the regulatory
[01:19:35.040 --> 01:19:40.200]   stuff that companies would have to face, you know, filings and proving that they're
[01:19:40.200 --> 01:19:41.200]   not scams.
[01:19:41.200 --> 01:19:44.320]   And so a lot of people like the one part, but not the other part, but they're airing
[01:19:44.320 --> 01:19:45.320]   together in one bill.
[01:19:45.320 --> 01:19:49.120]   Yeah, disclosure rules like Cyrebane's Oxley are loosened a little bit for small companies.
[01:19:49.120 --> 01:19:50.120]   We're certain companies.
[01:19:50.120 --> 01:19:51.120]   Companies under a billion.
[01:19:51.120 --> 01:19:52.120]   Right.
[01:19:52.120 --> 01:19:54.320]   And who is over so actually wouldn't be part of this.
[01:19:54.320 --> 01:19:58.400]   It also is kind of for Facebook, because Facebook remember had to once it had, I think it was
[01:19:58.400 --> 01:20:01.680]   200, 500 investors.
[01:20:01.680 --> 01:20:03.280]   It had to file for public.
[01:20:03.280 --> 01:20:05.280]   Now it can go, what is it, 1,000?
[01:20:05.280 --> 01:20:06.280]   2,000.
[01:20:06.280 --> 01:20:07.280]   Two thousand.
[01:20:07.280 --> 01:20:08.280]   Two thousand.
[01:20:08.280 --> 01:20:09.280]   So you know, these things were modernizing.
[01:20:09.280 --> 01:20:10.280]   We're merely modernizing.
[01:20:10.280 --> 01:20:15.280]   And Steve Case, who was the guy who put this through, really, the former founder of AOL,
[01:20:15.280 --> 01:20:18.400]   made the point that, look, you can be an idiot and go to a casino and lose unlimited
[01:20:18.400 --> 01:20:19.480]   amounts of money.
[01:20:19.480 --> 01:20:21.120]   We don't protect people from casinos.
[01:20:21.120 --> 01:20:25.480]   Why are we protecting people from investing in startups and things like Kickstarter?
[01:20:25.480 --> 01:20:29.560]   Look, I got taken on Kickstarter and I keep getting taken on Kickstarter, but you know,
[01:20:29.560 --> 01:20:35.280]   it's a small amount of money and it's huge for jump-starting the economy.
[01:20:35.280 --> 01:20:38.840]   And it is restricted to $10,000 or no more than $10,000.
[01:20:38.840 --> 01:20:41.000]   Yeah, your library is limited.
[01:20:41.000 --> 01:20:46.120]   In the UK, this is encouraged to think that there's even tax breaks around this kind of
[01:20:46.120 --> 01:20:53.120]   crowd-sourced-- Scraste.
[01:20:53.120 --> 01:20:55.920]   --a company called Escape the City.
[01:20:55.920 --> 01:21:00.120]   Mikey Howe is one of the founders and he was nice enough to send an email saying they were
[01:21:00.120 --> 01:21:02.320]   probably inspired by what would Google do, plug.
[01:21:02.320 --> 01:21:07.320]   But they just put it out there because they couldn't in the UK and they--I just got an
[01:21:07.320 --> 01:21:13.520]   update from him today and he said that 2,200 members have pledged and they won't actually
[01:21:13.520 --> 01:21:16.080]   raise all this, but they've pledged $15 million in investment in the company.
[01:21:16.080 --> 01:21:20.120]   And now, God bless you, a capitalist and part of a for-profit venture.
[01:21:20.120 --> 01:21:21.120]   Yes.
[01:21:21.120 --> 01:21:26.160]   Would you see--how would you look at investment from crowd-sourcing and members and a whole
[01:21:26.160 --> 01:21:31.640]   bunch of small people like, you know, kind of Obama fundraising versus angels, friends
[01:21:31.640 --> 01:21:33.320]   and family and venture funds?
[01:21:33.320 --> 01:21:34.320]   Yeah, certainly.
[01:21:34.320 --> 01:21:36.840]   It would certainly be a possibility for us.
[01:21:36.840 --> 01:21:38.920]   I think the Kickstarter model is amazing.
[01:21:38.920 --> 01:21:43.440]   I also have had projects not send me anything in the end, but also seen some great projects
[01:21:43.440 --> 01:21:44.440]   come through.
[01:21:44.440 --> 01:21:47.440]   It's definitely something that we would consider.
[01:21:47.440 --> 01:21:52.120]   I don't want to speak for a meal, but we're trying to raise funding kind of in a smart
[01:21:52.120 --> 01:21:55.600]   way, get good money, like the night application, for example.
[01:21:55.600 --> 01:21:58.200]   So that's something I would love.
[01:21:58.200 --> 01:22:02.440]   It would be--what could be beneficial to us and I think in a lot of different startups.
[01:22:02.440 --> 01:22:10.040]   And it seems funny to me that you can raise money for a new iPod doc or iPad stand or
[01:22:10.040 --> 01:22:15.400]   someone can raise $2 million for back issues of comic books or something, but you can't
[01:22:15.400 --> 01:22:18.240]   use the same model for a startup technology company.
[01:22:18.240 --> 01:22:19.640]   It just doesn't make any sense.
[01:22:19.640 --> 01:22:21.560]   So our consensus is, this is a good thing.
[01:22:21.560 --> 01:22:22.640]   Be careful.
[01:22:22.640 --> 01:22:24.880]   But it's basically a good idea.
[01:22:24.880 --> 01:22:25.880]   Be careful out there.
[01:22:25.880 --> 01:22:27.680]   Good, because it's going to be a law tomorrow.
[01:22:27.680 --> 01:22:30.520]   By the way, today's the day and I don't know if we've heard yet the Yahoo's laying off
[01:22:30.520 --> 01:22:31.520]   a million people.
[01:22:31.520 --> 01:22:32.520]   2000.
[01:22:32.520 --> 01:22:33.520]   2000.
[01:22:33.520 --> 01:22:34.520]   2000.
[01:22:34.520 --> 01:22:35.520]   The letters out.
[01:22:35.520 --> 01:22:37.520]   Just to start.
[01:22:37.520 --> 01:22:40.040]   Let's see more where they came from.
[01:22:40.040 --> 01:22:41.040]   Let's see more where they came from.
[01:22:41.040 --> 01:22:44.880]   And there's a really great stupid game on the front page of the New York Times.
[01:22:44.880 --> 01:22:46.800]   I can't stop playing it.
[01:22:46.800 --> 01:22:47.800]   It doesn't do anything.
[01:22:47.800 --> 01:22:49.760]   It's the story about stupid games, but I couldn't read the story.
[01:22:49.760 --> 01:22:51.760]   I never got to the story.
[01:22:51.760 --> 01:22:53.800]   It's D.F.D.R. too much fun.
[01:22:53.800 --> 01:22:54.800]   Don't read.
[01:22:54.800 --> 01:22:58.040]   Is this the first time there's been a game on the New York Times web page?
[01:22:58.040 --> 01:23:01.920]   Remember way back when the original pong add on wired.
[01:23:01.920 --> 01:23:02.920]   Whoa!
[01:23:02.920 --> 01:23:04.560]   As an ad.
[01:23:04.560 --> 01:23:06.200]   You can blow up ads.
[01:23:06.200 --> 01:23:08.200]   Oh, this is great.
[01:23:08.200 --> 01:23:11.000]   I wish the text exactly disappeared.
[01:23:11.000 --> 01:23:17.760]   The best joke I saw on Twitter was, "Can you use it to blow through the paywall?"
[01:23:17.760 --> 01:23:20.360]   Let's find out.
[01:23:20.360 --> 01:23:22.800]   You can see the NYT on it.
[01:23:22.800 --> 01:23:24.680]   This Twitter account.
[01:23:24.680 --> 01:23:26.640]   I love it.
[01:23:26.640 --> 01:23:28.440]   It's NYT on it.
[01:23:28.440 --> 01:23:29.440]   NYT on it.
[01:23:29.440 --> 01:23:31.240]   The tweet on it.
[01:23:31.240 --> 01:23:35.480]   The tweet on this story was, "Guys, Angry Birds is very addictive and the Times is on
[01:23:35.480 --> 01:23:36.480]   it."
[01:23:36.480 --> 01:23:39.960]   So everything has to end with, "The Times is on it."
[01:23:39.960 --> 01:23:42.560]   Yeah, everything where they find a fake trend story.
[01:23:42.560 --> 01:23:43.560]   They read a trend.
[01:23:43.560 --> 01:23:44.560]   They read it very late.
[01:23:44.560 --> 01:23:45.560]   I'll do it.
[01:23:45.560 --> 01:23:47.120]   Guys, apparently clothing really does make the man.
[01:23:47.120 --> 01:23:49.320]   The New York Times is on it.
[01:23:49.320 --> 01:23:51.120]   These are actual stories.
[01:23:51.120 --> 01:23:53.280]   The actual stories go on one of the iPhone cases.
[01:23:53.280 --> 01:23:54.280]   The iPhone cases.
[01:23:54.280 --> 01:23:57.720]   Yeah, people like to put colorful iPhone cases on their iPhones.
[01:23:57.720 --> 01:23:59.040]   The New York Times is on it.
[01:23:59.040 --> 01:24:00.840]   Oh, this is so funny.
[01:24:00.840 --> 01:24:05.280]   Guys, New York City Apartments don't always have dishwashers at that time.
[01:24:05.280 --> 01:24:08.520]   Oh my God, this is hysterical.
[01:24:08.520 --> 01:24:10.440]   Very funny.
[01:24:10.440 --> 01:24:11.440]   Recommend.
[01:24:11.440 --> 01:24:14.720]   Guys, sports fans cheer for the home team and mock the visitors.
[01:24:14.720 --> 01:24:17.360]   The Times is on it.
[01:24:17.360 --> 01:24:21.080]   Guys, puppies are now an acceptable part of any wedding party.
[01:24:21.080 --> 01:24:23.040]   And The Times is on it.
[01:24:23.040 --> 01:24:24.440]   Wow, this is very funny.
[01:24:24.440 --> 01:24:26.240]   They have so much to choose from.
[01:24:26.240 --> 01:24:28.240]   It's kind of natural.
[01:24:28.240 --> 01:24:29.240]   Write yourself.
[01:24:29.240 --> 01:24:30.240]   Follow.
[01:24:30.240 --> 01:24:31.240]   Follow.
[01:24:31.240 --> 01:24:39.200]   I promise I follow so many great things like that that I saw at my Twitter feed is useless.
[01:24:39.200 --> 01:24:40.200]   But fun.
[01:24:40.200 --> 01:24:41.200]   Plus.
[01:24:41.200 --> 01:24:46.080]   All right, so I think we've now covered everything that I can't get out of this stupid game,
[01:24:46.080 --> 01:24:47.080]   unfortunately.
[01:24:47.080 --> 01:24:48.080]   I can't close this window.
[01:24:48.080 --> 01:24:49.440]   All right, there we go.
[01:24:49.440 --> 01:24:51.400]   Stupid game done.
[01:24:51.400 --> 01:24:52.400]   Google surveys?
[01:24:52.400 --> 01:24:55.400]   Do we want to talk about the consumer surveys?
[01:24:55.400 --> 01:24:56.400]   It's pretty cool.
[01:24:56.400 --> 01:24:58.440]   Yes, Nate, I should have made this my tool.
[01:24:58.440 --> 01:24:59.440]   Interesting idea.
[01:24:59.440 --> 01:25:00.440]   Yeah.
[01:25:00.440 --> 01:25:04.840]   I don't think the data coming through that is going to be that useful.
[01:25:04.840 --> 01:25:05.840]   But maybe that's just me.
[01:25:05.840 --> 01:25:10.520]   I mean, I think I just was in an airport and I filled out a survey so I could get free
[01:25:10.520 --> 01:25:11.520]   Wi-Fi.
[01:25:11.520 --> 01:25:15.600]   I just clicked things randomly until it said, OK, you can have Wi-Fi now.
[01:25:15.600 --> 01:25:17.320]   I'm going to make a survey.
[01:25:17.320 --> 01:25:22.880]   Is the New York Times on it?
[01:25:22.880 --> 01:25:28.160]   Anyway, so you can see this is just Google Google surveys.
[01:25:28.160 --> 01:25:34.040]   If that's not a recursive search that will get you in a loop and there you go.
[01:25:34.040 --> 01:25:35.880]   Oh, and there's a visualization.
[01:25:35.880 --> 01:25:36.880]   Yeah.
[01:25:36.880 --> 01:25:37.880]   That's fantastic.
[01:25:37.880 --> 01:25:38.880]   It's funny.
[01:25:38.880 --> 01:25:48.680]   One hour per second dot com, a visualization of how many videos are being uploaded to YouTube
[01:25:48.680 --> 01:25:49.680]   every second.
[01:25:49.680 --> 01:25:54.280]   You just got me hungry talking about bacon, so I'm ready for lunch.
[01:25:54.280 --> 01:25:55.280]   Sorry.
[01:25:55.280 --> 01:25:58.200]   OK, just go to one hour per second dot com.
[01:25:58.200 --> 01:25:59.200]   It's kind of fun.
[01:25:59.200 --> 01:26:00.200]   One hour per second dot com.
[01:26:00.200 --> 01:26:02.560]   Yeah, if you click there, it kind of translates what that means.
[01:26:02.560 --> 01:26:03.560]   Yeah.
[01:26:03.560 --> 01:26:04.560]   Let's visualize that.
[01:26:04.560 --> 01:26:08.160]   Again, somebody's 20% time going to a complete waste of time.
[01:26:08.160 --> 01:26:10.160]   Now we're going to get bumped off YouTube.
[01:26:10.160 --> 01:26:11.160]   No, I didn't play it.
[01:26:11.160 --> 01:26:12.160]   I didn't play it.
[01:26:12.160 --> 01:26:13.160]   I didn't do it.
[01:26:13.160 --> 01:26:14.160]   I didn't do it.
[01:26:14.160 --> 01:26:15.160]   All right.
[01:26:15.160 --> 01:26:17.360]   Gina's tip of the week.
[01:26:17.360 --> 01:26:21.560]   So people who watched it probably heard about this this weekend, but I just absolutely couldn't
[01:26:21.560 --> 01:26:23.840]   resist because it was so cool.
[01:26:23.840 --> 01:26:25.680]   It was an April Fool's gag.
[01:26:25.680 --> 01:26:29.120]   It's 8-bit Google Maps, which is still up.
[01:26:29.120 --> 01:26:30.120]   You could still get to it.
[01:26:30.120 --> 01:26:36.240]   I think it's maps.google.com, and you have to give it a parameter like UTM campaign 8-bit.
[01:26:36.240 --> 01:26:37.240]   But it's really neat.
[01:26:37.240 --> 01:26:38.720]   You can zoom in pan around the world.
[01:26:38.720 --> 01:26:39.720]   It's all 8-bit.
[01:26:39.720 --> 01:26:43.080]   And there's a ton of Easter eggs in there.
[01:26:43.080 --> 01:26:48.080]   There's a UFO abducting a cow in Area 51.
[01:26:48.080 --> 01:26:50.360]   There's the Loch Ness Monster.
[01:26:50.360 --> 01:26:53.360]   There's a big foot.
[01:26:53.360 --> 01:26:55.800]   And I included a link to some of the Easter eggs throughout.
[01:26:55.800 --> 01:26:58.600]   If you didn't see it this weekend, if it was a Sunday, you're spending it with your
[01:26:58.600 --> 01:27:03.720]   family instead of looking at all the online April Fool's gags, this one should not be
[01:27:03.720 --> 01:27:04.720]   messed.
[01:27:04.720 --> 01:27:07.040]   It was pretty amazing that they did this street view in 8-bit.
[01:27:07.040 --> 01:27:08.440]   I mean, that's awesome.
[01:27:08.440 --> 01:27:09.440]   Amazing.
[01:27:09.440 --> 01:27:10.440]   Yeah.
[01:27:10.440 --> 01:27:11.440]   Yeah.
[01:27:11.440 --> 01:27:12.440]   Very cool.
[01:27:12.440 --> 01:27:13.440]   Jeff, your number of the week.
[01:27:13.440 --> 01:27:18.480]   Well, just relevant to what we talked about earlier with the glasses we all want.
[01:27:18.480 --> 01:27:27.840]   Google Maps now covers 75% of global population, which, again, it gives context as to why are
[01:27:27.840 --> 01:27:28.840]   they doing some of this stuff?
[01:27:28.840 --> 01:27:31.680]   Why is Maps so important to them besides the fact that it's a good service?
[01:27:31.680 --> 01:27:38.460]   If you want to be able to walk people around by the nose, then having good maps around
[01:27:38.460 --> 01:27:39.460]   the world is important.
[01:27:39.460 --> 01:27:40.460]   And it has value.
[01:27:40.460 --> 01:27:43.480]   If you want to have self-driving cars, having great maps is important.
[01:27:43.480 --> 01:27:45.920]   So Maps just keeps growing and growing and growing.
[01:27:45.920 --> 01:27:46.920]   That's amazing, isn't it?
[01:27:46.920 --> 01:27:51.840]   They need to attach cameras to postal trucks.
[01:27:51.840 --> 01:27:52.840]   As long as we have that.
[01:27:52.840 --> 01:27:53.840]   There you go.
[01:27:53.840 --> 01:27:56.200]   We've been looking for something like that.
[01:27:56.200 --> 01:27:57.200]   Sorry, Matt.
[01:27:57.200 --> 01:27:59.240]   Self-driving postal trucks.
[01:27:59.240 --> 01:28:04.400]   I was just going to say I noticed over the last little while a bunch of startups not using
[01:28:04.400 --> 01:28:08.400]   Google Maps anymore and using OpenStreetMap or stuff like that.
[01:28:08.400 --> 01:28:10.800]   Even Apple using OSM data.
[01:28:10.800 --> 01:28:13.000]   I like OSM.
[01:28:13.000 --> 01:28:15.120]   OpenStreetMaps.
[01:28:15.120 --> 01:28:17.280]   This was going to be, is that your number or are you done?
[01:28:17.280 --> 01:28:18.280]   I'm done.
[01:28:18.280 --> 01:28:19.440]   Are we done with the number?
[01:28:19.440 --> 01:28:22.640]   This was my tool is something that no one can use.
[01:28:22.640 --> 01:28:24.800]   But it's something we've been waiting for.
[01:28:24.800 --> 01:28:31.840]   We had heard that Hearst Time and Conde Nast would do some sort of Netflix for magazines.
[01:28:31.840 --> 01:28:35.680]   It's now out, but you have to have a honeycomb or better tablet.
[01:28:35.680 --> 01:28:41.320]   So all 12 of you watching who have that can down.
[01:28:41.320 --> 01:28:48.480]   I've actually already paid for this is 15 bucks a month, but you get a bunch of titles.
[01:28:48.480 --> 01:28:55.440]   Essence, fitness, Esquire, entertainment, glamour, in style, money.
[01:28:55.440 --> 01:28:56.680]   So you can read New Yorker.
[01:28:56.680 --> 01:28:58.840]   You can read at Vanity Fair time.
[01:28:58.840 --> 01:29:00.040]   You can read any of these.
[01:29:00.040 --> 01:29:01.040]   Unlimited.
[01:29:01.040 --> 01:29:03.080]   I want to hear back from you in two months.
[01:29:03.080 --> 01:29:04.280]   How many articles you actually read?
[01:29:04.280 --> 01:29:05.280]   Well, that's the thing.
[01:29:05.280 --> 01:29:10.120]   For $15 a month, most of these magazines are $10 or $15 a year.
[01:29:10.120 --> 01:29:12.360]   So you could get a 10 magazines.
[01:29:12.360 --> 01:29:13.360]   So pick the 10 you like.
[01:29:13.360 --> 01:29:14.360]   How long do you read magazines now?
[01:29:14.360 --> 01:29:15.360]   No, I don't read magazines.
[01:29:15.360 --> 01:29:17.640]   I get the New Yorker on my iPad and I don't know.
[01:29:17.640 --> 01:29:18.640]   Oh, OK.
[01:29:18.640 --> 01:29:19.640]   You read it.
[01:29:19.640 --> 01:29:20.640]   Never.
[01:29:20.640 --> 01:29:21.640]   Occasionally, there'll be something good.
[01:29:21.640 --> 01:29:22.640]   Never.
[01:29:22.640 --> 01:29:28.280]   This is their last attempt at saving magazines.
[01:29:28.280 --> 01:29:30.280]   They have unlimited basic.
[01:29:30.280 --> 01:29:34.480]   Get unlimited access to dozens of the top magazines for just $9.99 a month.
[01:29:34.480 --> 01:29:36.440]   Great for the whole family.
[01:29:36.440 --> 01:29:40.920]   You can get everything in the unlimited basic plan plus unlimited access to weeklies, including
[01:29:40.920 --> 01:29:44.480]   New Yorker people sports illustrated more for just $14.99 a month.
[01:29:44.480 --> 01:29:47.400]   So I guess I got the weekly plan, but it's free for the first month.
[01:29:47.400 --> 01:29:48.400]   So you're right.
[01:29:48.400 --> 01:29:49.400]   I'll keep it for a month.
[01:29:49.400 --> 01:29:50.800]   And let's report back.
[01:29:50.800 --> 01:29:52.800]   And I'll report back on whether I do this.
[01:29:52.800 --> 01:29:56.440]   And I only have it's only for tablets with a resolution of 10, 24 by 600.
[01:29:56.440 --> 01:30:01.720]   Not greater than, not less than exactly.
[01:30:01.720 --> 01:30:04.080]   And that's the New Yorker, by the way, is the only one.
[01:30:04.080 --> 01:30:05.920]   That's bizarre.
[01:30:05.920 --> 01:30:08.600]   It's not even on the on the iPad is not even that.
[01:30:08.600 --> 01:30:10.400]   So I don't know what they're talking about.
[01:30:10.400 --> 01:30:13.040]   It's basically broken.
[01:30:13.040 --> 01:30:15.200]   I'm sure Jeff would have something.
[01:30:15.200 --> 01:30:19.200]   Pithy to say about the end of print.
[01:30:19.200 --> 01:30:20.200]   Hmm.
[01:30:20.200 --> 01:30:24.640]   That's all there is to say about print.
[01:30:24.640 --> 01:30:25.920]   Matthew, great to have you.
[01:30:25.920 --> 01:30:29.200]   Matthew Ingram editor at gig Oum.com.
[01:30:29.200 --> 01:30:30.200]   Great to have you.
[01:30:30.200 --> 01:30:31.920]   Please see frozen.
[01:30:31.920 --> 01:30:32.920]   Come back.
[01:30:32.920 --> 01:30:33.920]   Well, he's thinking.
[01:30:33.920 --> 01:30:34.920]   He's got books.
[01:30:34.920 --> 01:30:36.920]   I'll call him the pugnacious.
[01:30:36.920 --> 01:30:37.920]   Sphinx-like.
[01:30:37.920 --> 01:30:38.920]   Sphinx-like.
[01:30:38.920 --> 01:30:41.080]   He's still in this.
[01:30:41.080 --> 01:30:42.080]   He's contemplative.
[01:30:42.080 --> 01:30:43.080]   He's meditating.
[01:30:43.080 --> 01:30:44.840]   That's very Canadian of them.
[01:30:44.840 --> 01:30:45.840]   Mmm.
[01:30:45.840 --> 01:30:46.840]   That's what they call it, Giggah.
[01:30:46.840 --> 01:30:48.840]   Oh, that's right.
[01:30:48.840 --> 01:30:49.840]   Hit the tongue.
[01:30:49.840 --> 01:30:50.840]   Oh.
[01:30:50.840 --> 01:30:51.840]   Jeff.
[01:30:51.840 --> 01:30:54.760]   Jeff Jarrassee is a journalism professor at the University of New York.
[01:30:54.760 --> 01:31:00.520]   Those lucky kids also, the blogger at buzzmachine.com and the author of a book you must read, called
[01:31:00.520 --> 01:31:03.120]   Public Parts If You Wanna Understand What's Happening.
[01:31:03.120 --> 01:31:05.120]   And a future.
[01:31:05.120 --> 01:31:07.440]   Gina Trapani at smartawear.org.
[01:31:07.440 --> 01:31:10.120]   Think up app.com.
[01:31:10.120 --> 01:31:13.360]   And just a wonderful person.
[01:31:13.360 --> 01:31:14.360]   Thank you.
[01:31:14.360 --> 01:31:15.360]   Live long and prosper, Leo.
[01:31:15.360 --> 01:31:16.360]   Live long and prosper.
[01:31:16.360 --> 01:31:20.800]   Jeff Clavier is joining us on triangulation this afternoon, 4 p.m. Pacific, 7 p.m. Eastern
[01:31:20.800 --> 01:31:23.800]   time, 2300 UTC.
[01:31:23.800 --> 01:31:28.720]   Jeff is a very interesting angel capitalist who has some very interesting ideas about
[01:31:28.720 --> 01:31:29.720]   the startup economy.
[01:31:29.720 --> 01:31:31.520]   And of course, we'll ask him about jobs.
[01:31:31.520 --> 01:31:34.800]   I'm sure he'll have something to say about that as well.
[01:31:34.800 --> 01:31:41.760]   We do this show every Wednesday, 1 p.m. Pacific, 4 p.m. Eastern, 2000 UTC at twit.tv, watch
[01:31:41.760 --> 01:31:46.480]   live, or we make audio and video available after the fact you don't always download it.
[01:31:46.480 --> 01:31:50.920]   Just subscribe though so that you make sure you get every episode on iTunes and all the
[01:31:50.920 --> 01:31:54.240]   better subscription places.
[01:31:54.240 --> 01:31:55.240]   That's about it.
[01:31:55.240 --> 01:31:56.240]   Thanks to Eileen.
[01:31:56.240 --> 01:31:57.240]   Rivera, our producer.
[01:31:57.240 --> 01:31:58.640]   Thanks to you for joining us.
[01:31:58.640 --> 01:31:59.640]   Yes.
[01:31:59.640 --> 01:32:03.280]   And as a young guy, he's a very nice actor for performing background duties and keeping his
[01:32:03.280 --> 01:32:04.280]   glasses clean.
[01:32:04.280 --> 01:32:05.280]   Thanks, I.
[01:32:05.280 --> 01:32:08.280]   Thanks, you guys.
[01:32:08.280 --> 01:32:09.520]   It was a little weird the other day.
[01:32:09.520 --> 01:32:10.520]   He wasn't there.
[01:32:10.520 --> 01:32:11.520]   It was like, what the hell?
[01:32:11.520 --> 01:32:12.520]   I know.
[01:32:12.520 --> 01:32:13.520]   Oh, Sunday.
[01:32:13.520 --> 01:32:14.520]   It was Sunday.
[01:32:14.520 --> 01:32:15.520]   Does it come in on Sunday?
[01:32:15.520 --> 01:32:16.520]   What the hell?
[01:32:16.520 --> 01:32:17.520]   Missing.
[01:32:17.520 --> 01:32:18.520]   Yeah, what's missing?
[01:32:18.520 --> 01:32:22.600]   And thanks to Betty Francis for making me look thin.
[01:32:22.600 --> 01:32:23.880]   Little madman reference in there.
[01:32:23.880 --> 01:32:25.440]   We'll see you next time on this week in Goog.
[01:32:25.440 --> 01:32:25.960]   Go bye-bye.
[01:32:25.960 --> 01:32:27.960]   [MUSIC PLAYING]
[01:32:27.960 --> 01:32:34.960]   [MUSIC PLAYING]
[01:32:34.960 --> 01:32:37.540]   (upbeat music)

