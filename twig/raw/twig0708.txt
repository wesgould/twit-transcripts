;FFMETADATA1
title=That Ain't Cheesecake
artist=Leo Laporte, Jeff Jarvis, Stacey Higginbotham, Ant Pruitt
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2023-03-23
track=708
language=English
genre=Podcast
comment=Google BARD Rollout, TikTok Ban, Adobe Firefly
encoded_by=Uniblab 5.3
date=2023
encoder=Lavf58.76.100

[00:00:00.000 --> 00:00:03.600]   It's time for Twig this week in Google Jeff Jairus, Stacey Higginbotham.
[00:00:03.600 --> 00:00:07.120]   Our here at Pruitt's is back in town.
[00:00:07.120 --> 00:00:12.640]   Coming up the end of DP review, we play a little bit with Google's brand new AI, Bard.
[00:00:12.640 --> 00:00:20.160]   Blackberry, the trailer is coming 3D printed pie and low-fi air traffic control.
[00:00:20.160 --> 00:00:22.480]   It's going to be a fun one. Twig is next.
[00:00:22.480 --> 00:00:26.400]   Podcasts you love.
[00:00:26.400 --> 00:00:28.080]   From people you trust.
[00:00:29.440 --> 00:00:30.960]   This is Twig.
[00:00:30.960 --> 00:00:43.280]   This is Twig. This week in Google, episode 708, recorded Wednesday, March 22, 2023.
[00:00:43.280 --> 00:00:45.520]   That ain't cheesecake.
[00:00:45.520 --> 00:00:50.800]   This episode of This Week in Google is brought to you by Bitwarden.
[00:00:50.800 --> 00:00:56.480]   Get the password manager that offers a robust and cost-effective solution that drastically
[00:00:56.480 --> 00:01:01.440]   increases your chance of staying safe online. Get started with a free trial of a team's or
[00:01:01.440 --> 00:01:09.280]   enterprise plan or get started for free across all devices as an individual user at bitwarden.com/twit.
[00:01:09.280 --> 00:01:16.960]   Thanks for listening to this show. As an ad-supported network, we are always looking for new partners
[00:01:16.960 --> 00:01:22.400]   with products and services that will benefit our qualified audience. Are you ready to grow
[00:01:22.400 --> 00:01:27.520]   your business? Reach out to Advertise@twit.tv and launch your campaign now.
[00:01:27.520 --> 00:01:33.440]   It's time for Twig this week in Google to show that's everything but Google.
[00:01:33.440 --> 00:01:38.960]   At Proxback we missed you. Thank you for coming back.
[00:01:38.960 --> 00:01:44.720]   Were you in New Orleans? Was that the New Orleans conference that you were at? No.
[00:01:44.720 --> 00:01:50.400]   No, not this time. I was off to be off.
[00:01:50.960 --> 00:01:58.000]   Oh a vacation? A vacation? How dare you? Well we missed you. I had to sneak one in before you left.
[00:01:58.000 --> 00:02:01.680]   Yeah, I'm going to try to sneak it in because I figured you wouldn't catch it.
[00:02:01.680 --> 00:02:04.800]   I'll be leaving a week from Friday for three weeks just to let you know.
[00:02:04.800 --> 00:02:11.600]   It's not making the first turn. And as the host of Hands-On Photography and now more than ever,
[00:02:11.600 --> 00:02:17.520]   we need hot but I'll tell you why in a second. Jeff Jarvis is also in the house. He is ladies and
[00:02:17.520 --> 00:02:22.080]   gentlemen, I give you the letter to our professor for journalistic innovation at the
[00:02:22.080 --> 00:02:28.080]   Frank Newmark Graduate School of Journalism at the City University in New York.
[00:02:28.080 --> 00:02:33.200]   They'll be I propose, even though it's not a democracy, please propose. You are the dictator.
[00:02:33.200 --> 00:02:41.440]   I will marry you any introduction for Stacey, line 86. And ladies and gentlemen,
[00:02:42.480 --> 00:02:52.080]   in the house, line 86, just for Stacey, I give you this TikTok.
[00:02:52.080 --> 00:02:56.240]   Oh your sound started off.
[00:02:56.240 --> 00:03:04.320]   You what? I just can't stop thinking about Waffles.
[00:03:06.160 --> 00:03:15.040]   Same child. You had Waffles for dinner and Waffles are breakfast. So you're going to eat something else.
[00:03:15.040 --> 00:03:19.680]   This is why can't I? Wait a minute, go back to it. Hold on, hold on.
[00:03:19.680 --> 00:03:21.920]   Go back. It's it's it's it's it's not done yet.
[00:03:21.920 --> 00:03:25.680]   I stopped dreaming about Waffles.
[00:03:25.680 --> 00:03:34.000]   Poor girl. She cannot stop dreaming about Waffles. Ladies and gentlemen,
[00:03:34.000 --> 00:03:40.320]   that's Stacey Higginbotham as a child Stacey and IOT.com. That's a child. That's me now.
[00:03:40.320 --> 00:03:43.760]   That's her now. All through the show. She's dreaming about Waffles.
[00:03:43.760 --> 00:03:48.160]   I just can't stop dreaming about Waffles. Waffles are very, very good.
[00:03:48.160 --> 00:03:54.080]   And you know what? They can be savory or sweet, good for breakfast, good for dinner,
[00:03:54.080 --> 00:03:57.600]   good for dessert, good for lunch. They could do it all. There's nothing a waffle can't do.
[00:03:57.600 --> 00:04:02.880]   Indeed. Slap them on a wound. It'll heal. Have you ever had waffles and diggers in New York?
[00:04:02.880 --> 00:04:06.160]   Dingus. I think it means things.
[00:04:06.160 --> 00:04:08.640]   It means us things.
[00:04:08.640 --> 00:04:13.840]   Waffles and dingus.
[00:04:13.840 --> 00:04:19.680]   Dingus. Where would you get waffles and dingus if I'm my last?
[00:04:19.680 --> 00:04:21.440]   There's there's all around the streets of New York.
[00:04:21.440 --> 00:04:30.640]   Do you mean? Now they ship nationwide. We ship nationwide. Oh, it's a it's a
[00:04:30.640 --> 00:04:33.760]   waffles and but it's only one F. So I think it's some Dutch thing.
[00:04:33.760 --> 00:04:42.240]   Now dingo's dingus. Oh, yeah. Is it dingus? Well, I thought you were saying a different dingus.
[00:04:42.240 --> 00:04:47.600]   Yeah, we do. It's Dutch. The Dutch and your minds out of the dutter people.
[00:04:47.600 --> 00:04:53.280]   The Dutch it's winsome wacky and the most wonderful waffles in the whole wide world.
[00:04:53.280 --> 00:04:57.360]   Basically, dingus. Ooh, the banana one looks good. Yeah. Scroll down. Ooh.
[00:04:57.360 --> 00:05:02.080]   Those do look delicious. Yeah. Oh, I.
[00:05:02.080 --> 00:05:06.960]   Where there's a waffle. You see, that's why I stopped too. Yeah.
[00:05:06.960 --> 00:05:14.320]   Sorry. I did manage to detour us very early on. Oh my god.
[00:05:14.320 --> 00:05:18.080]   Waffles are worth it. Now you know why I say this is not a democracy.
[00:05:18.080 --> 00:05:23.360]   Democracy. Holy cow. Of course, I only had six stories in the whole show.
[00:05:24.960 --> 00:05:30.560]   But that'll make it a waffle time all the sooner. We the reason I said we need you now more than
[00:05:30.560 --> 00:05:38.880]   ever is the I think legendary site for camera reviews DP review, which was acquired by Amazon
[00:05:38.880 --> 00:05:46.000]   a few years ago is closing for good April 10th. A lot of people out of work, part of the 9,000
[00:05:46.000 --> 00:05:50.560]   people Amazon announced they're going to lay off earlier this week. They all get I'm told
[00:05:51.200 --> 00:05:54.400]   a nice severance packages. They're not going to be out on the street.
[00:05:54.400 --> 00:06:02.800]   But there is also a very good DP review YouTube channel. And the good news for that is the guys
[00:06:02.800 --> 00:06:10.080]   who host that have announced they're going to be moving over to petapixel. So DP review TV
[00:06:10.080 --> 00:06:16.960]   lives on. Thank goodness. That's good stuff. Yeah. Those guys Jordan Drake and Chris Nicholas
[00:06:16.960 --> 00:06:23.600]   there are so good at what they do and quite personable. They've built a really, really strong community
[00:06:23.600 --> 00:06:29.280]   there with DP review. And at some at one point, I am going to end up having these guys on hands
[00:06:29.280 --> 00:06:33.920]   on photography and just chit chat with them because they're just just great people in addition to
[00:06:33.920 --> 00:06:39.280]   being great photographers and great photography educators. And it really is a nice compliment,
[00:06:39.280 --> 00:06:44.000]   I think, to the website because the website, you get all the stats and the facts and a compact,
[00:06:44.000 --> 00:06:48.480]   easy to read form. But for time, it's just stats and facts. It's like nerdy stats.
[00:06:48.480 --> 00:06:54.000]   Nerdy. I mean, they go, they go way deep. But then but but what you also need to see,
[00:06:54.000 --> 00:06:59.120]   and of course, they always have sample images, but I think it's really great to have the video in
[00:06:59.120 --> 00:07:05.600]   addition. They belong together. I for years haven't would not buy a camera without reading
[00:07:05.600 --> 00:07:10.640]   about it on DP review first. And I confess, they've made me drool for cameras and sometimes even buy
[00:07:10.640 --> 00:07:14.880]   cameras, which is really begs the question, Amazon, what are you thinking?
[00:07:14.880 --> 00:07:21.760]   Did you buy the camera from Amazon? Probably. Yeah, because they have the most of the time link
[00:07:21.760 --> 00:07:31.200]   there. They have to have made money on it. So this so the good news is there is a very large site,
[00:07:31.200 --> 00:07:39.840]   but there is a group that is planning to archive it. So, you know, that's one of the problems when
[00:07:39.840 --> 00:07:46.960]   a site goes away is you lose so much content. Can we talk about this for a little bit?
[00:07:46.960 --> 00:07:53.040]   Because I was reading a profile of the New Yorker or in the New Yorker about the head of
[00:07:53.040 --> 00:07:59.040]   Netflix's television strategy. And one of the little blips in there that was interesting was
[00:07:59.040 --> 00:08:08.240]   what's his name? Ted Saran, how the co CEO of Netflix, Sarah and starts with the s.
[00:08:08.240 --> 00:08:11.440]   Okay. Ted. Yeah, we all call him Ted. That's you know,
[00:08:11.440 --> 00:08:16.080]   Saran does. I can't remember. I know you. Saran does. Yeah. I always want to say
[00:08:16.080 --> 00:08:21.520]   surrounded, but that's Susan. Anyway, he was talking about their content strategy and
[00:08:21.520 --> 00:08:25.840]   basically saying that Chris Anderson's idea of the long tail of the internet is just funk and
[00:08:25.840 --> 00:08:31.120]   it's dead. And I'm speaking from the long tail. Yeah.
[00:08:32.560 --> 00:08:38.880]   That's like respect. Well, are you a long tail or are you just, is there a difference between that
[00:08:38.880 --> 00:08:44.080]   just like little niche plays that still make money? I mean, it's not like you're a long tail in the
[00:08:44.080 --> 00:08:49.200]   sense that you're free to put up in the world, right? No, in fact, we probably don't have a long
[00:08:49.200 --> 00:08:56.720]   tail. So Chris Anderson's thesis was, you know, there's the graph of uses of something starts real
[00:08:56.720 --> 00:09:02.480]   high and then goes low, but never goes to zero. And that long tailing thing is still profitable
[00:09:02.480 --> 00:09:07.520]   in aggregate, even though it doesn't look as profitable as the big spike. Our problem is our
[00:09:07.520 --> 00:09:12.160]   content actually has no long tail. There's a spike in it's over because nobody wants to listen
[00:09:12.160 --> 00:09:18.240]   to a four year old tech podcast. Right. But I think he's wrong. I think that is Netflix's
[00:09:18.240 --> 00:09:22.720]   point of view because Netflix. Yeah. And they have some data. I mean, goodness knows they have a
[00:09:22.720 --> 00:09:31.040]   lot of shows that are old. Well, the idea then, well, in plus putting money into other long tail,
[00:09:31.040 --> 00:09:36.720]   because long tail wasn't just that it would exist forever and be useful. It was also that
[00:09:36.720 --> 00:09:43.040]   there was home for more niche content. Right. And thinking about like Amazon killing
[00:09:43.040 --> 00:09:51.120]   this site and just kind of the understanding we have nowadays about the, I don't know if it's
[00:09:51.120 --> 00:09:56.480]   technical debt or keeping things upright, like paying for server costs, paying to maintain security,
[00:09:56.480 --> 00:10:00.320]   having someone to come check and make sure no one's doing weird spammy things on your site.
[00:10:00.320 --> 00:10:04.880]   I'm just, I'm kind of trying to think about what the internet we're about to.
[00:10:04.880 --> 00:10:10.800]   Having Phillies and mortality, are we Stacy? Yes, I am. I'm like, life is over.
[00:10:10.800 --> 00:10:17.680]   Don't say what I think. DP review is actually a classic long tail site. They get all the hits on
[00:10:17.680 --> 00:10:23.600]   the newest camera immediately. But yeah, but I keep going back for old cameras, old lenses
[00:10:23.600 --> 00:10:30.720]   for years, right? Yep. That's the thing. I know Amazon probably gripes about not being able to
[00:10:30.720 --> 00:10:36.880]   sell as many right on, you know, day one of when the camera gets announced, but cameras last for
[00:10:36.880 --> 00:10:42.080]   years. And the camera that came out three, four years ago, you can buy it now and it's still going
[00:10:42.080 --> 00:10:47.120]   to be a great camera. And I like the idea that DP review puts so much information in there,
[00:10:47.120 --> 00:10:50.640]   where you feel confident to say, you know what? Yes, this is a three year old camera body,
[00:10:50.640 --> 00:10:55.680]   but these specs are still pretty that come strong compared to the stuff that just come out this year.
[00:10:55.680 --> 00:10:59.520]   Well, and lenses never, you know, go away. Well, yeah. I mean, I bought lenses.
[00:10:59.520 --> 00:11:02.960]   Yeah, I've learned the hard way on that. Waiting on lenses to get cheaper.
[00:11:02.960 --> 00:11:08.720]   Yeah, they don't. So the good news is I was wondering, maybe archive.org, the way back machine,
[00:11:08.720 --> 00:11:12.960]   you know, internet archive would save it. But there is a similar group called Archive Team at
[00:11:12.960 --> 00:11:17.680]   Archive team.org. They've announced they're going to archive. They only have three weeks to do it.
[00:11:17.680 --> 00:11:22.720]   The site closed down April 10th, like is invisible April 10th. So the next three weeks,
[00:11:22.720 --> 00:11:29.280]   they plan to archive four million pages of DP review. But all those links are going to die,
[00:11:29.280 --> 00:11:35.200]   eh? Yeah, not necessarily. So to answer, and this kind of answers your question to Stacy,
[00:11:35.200 --> 00:11:40.720]   it's possible to crawl a website. So the website, as you know, Stacy, behind the scenes,
[00:11:41.680 --> 00:11:48.800]   is as an engine, has a database. It has the presentation layer, which is mostly CSS,
[00:11:48.800 --> 00:11:53.600]   cascading style sheets that say this font, this goes there, that goes there, that kind of thing.
[00:11:53.600 --> 00:11:58.640]   And then that attaches the presentation layer to a database of content, the content layer.
[00:11:58.640 --> 00:12:04.640]   And when somebody requests a page, that's a database request is made and then flowed through
[00:12:04.640 --> 00:12:08.640]   the presentation later and presented on the screen. That's how your site works. That's not
[00:12:08.640 --> 00:12:14.400]   going to be tenable forever. Plus you're right. You can inject code. There's code running.
[00:12:14.400 --> 00:12:18.640]   You could, you know, if there's a comment section, nobody's monitoring it, it's going to go crazy.
[00:12:18.640 --> 00:12:26.560]   But you could save the HTML presentation. You can save the static presentation of any page.
[00:12:26.560 --> 00:12:32.560]   If you, you know, if you view source on your pages, that static page, you can save that. And
[00:12:32.560 --> 00:12:39.200]   those links can be preserved to another static page and so forth. In fact, there are spiders,
[00:12:39.200 --> 00:12:44.160]   you know, web crawlers that are designed, I call them page suckers, that are designed to do
[00:12:44.160 --> 00:12:48.400]   that, to go to a site, download everything, maintain the links and store it on your,
[00:12:48.400 --> 00:12:54.960]   as a static page on your hard drive. You could do that right now with the IoT site. So,
[00:12:56.560 --> 00:13:04.080]   and then I think that's safe because HTML, you know, it's not, you won't have a clock that works.
[00:13:04.080 --> 00:13:09.200]   You won't have any JavaScript that's running, but the actual text, the content, and even the
[00:13:09.200 --> 00:13:13.440]   links and the images all can be preserved. Somebody's got to run a website though that,
[00:13:13.440 --> 00:13:17.840]   you know, a server that serves that. But that's, you know, it can be done cheaply.
[00:13:17.840 --> 00:13:23.440]   Well, and if it's, if it's truly static and done, you can estimate that cost out and just be like,
[00:13:23.440 --> 00:13:29.120]   okay, here's, you know, 60 bucks hosted for the next, because the data is not going to change,
[00:13:29.120 --> 00:13:30.400]   right? So it's a,
[00:13:30.400 --> 00:13:35.200]   Yeah, and I presume that's what archive team is doing. They say archive team,
[00:13:35.200 --> 00:13:41.680]   I love this main page, which is a wiki media style wiki history is our future. And we've
[00:13:41.680 --> 00:13:46.160]   been trashing our history. Archive team is a loose collective of rogue archivists,
[00:13:46.160 --> 00:13:52.000]   programmers, writers in the loudmouths, dedicated to say, dedicated to saving our digital heritage.
[00:13:52.000 --> 00:13:55.600]   They've been doing it since 2009. Good on you.
[00:13:55.600 --> 00:14:03.360]   Yeah. And I guess volunteers will scrape the pages and put it up here. It's not as complete by any means
[00:14:03.360 --> 00:14:09.440]   as archive.org, but hey, anybody say that's good.
[00:14:09.440 --> 00:14:15.760]   It's a half ass effort to. Yeah, yeah, I agree. Yeah. Yeah, I agree. So there's live
[00:14:15.760 --> 00:14:26.400]   journal stuff on here, Angel Fire. So anyway, sad to hear about the end of DP review seems
[00:14:26.400 --> 00:14:32.800]   senseless, but I guess it's just not a good time right now to be advertising supported to anything
[00:14:32.800 --> 00:14:40.240]   on the internet. Well, it's a scale that Amazon expects. It's the problem that when I started a
[00:14:40.240 --> 00:14:46.080]   parents guy to children's entertainment at a news Corp, a side TV guide, well, if it's
[00:14:46.080 --> 00:14:51.440]   not a million circulation, we don't care. Right. Yeah. And so that's because even supporting the ad
[00:14:51.440 --> 00:14:55.360]   salespeople, the ad salespeople were selling ads in my little thing and they were saying they're
[00:14:55.360 --> 00:15:00.800]   wasting their time on your little dinghy dingus. They could be selling, you know, huge TV guide
[00:15:00.800 --> 00:15:07.120]   pages, right? Well, little TV pages of huge dollars. And same with circulation, we were taking
[00:15:07.120 --> 00:15:11.600]   rack space from TV guides. So there's a scale that you expect to certain companies. And that's an
[00:15:11.600 --> 00:15:17.040]   enemy of the internet, I think it is the internet wants to operate at this scale, our scale. Well,
[00:15:17.040 --> 00:15:21.040]   big businesses do, but that's the beauty of the internet is you can operate at a very small scale.
[00:15:21.040 --> 00:15:26.880]   Yeah, but then a big business is going to come along and buy you eventually or not.
[00:15:26.880 --> 00:15:31.120]   Because like, please, hello, please, please, please, please.
[00:15:32.240 --> 00:15:39.600]   So also a guy on Reddit called Reclusive Eagle, you'll like this and is going to download all of those
[00:15:39.600 --> 00:15:46.560]   DP review, studio camera comparison tool pages. Oh, nice. Because these are really valuable,
[00:15:46.560 --> 00:15:51.920]   where you can just see side by side, what an image will look like on a standardized
[00:15:51.920 --> 00:15:58.240]   picture. And it covers digital photography back to the beginning 25 years worth.
[00:15:58.240 --> 00:16:02.480]   What are all the stuff was there? Do it all. It's awesome. It was a lot of people. I don't know.
[00:16:02.480 --> 00:16:08.000]   I feel like it was hundreds, but I don't know. But look at CNET, what's happening in CNET,
[00:16:08.000 --> 00:16:12.480]   now that they're owned by a private equity company, Red Ventures, they're moving towards having AI
[00:16:12.480 --> 00:16:19.120]   right on the content. It's depressing, honestly. I'm having AI write some of my content. I'm running
[00:16:19.120 --> 00:16:24.240]   an experiment right now. Oh, really? Are you telling people when they go to Stacey on IOT.com?
[00:16:25.040 --> 00:16:30.240]   It's not on my Twitter page. So I'm having... Oh, I did see your tweets on that. Yeah.
[00:16:30.240 --> 00:16:35.120]   I'm having it right. And it was very good. They did a matter post, right? A matter tweet.
[00:16:35.120 --> 00:16:40.880]   Well, it was a tweet about matter. And yeah, so every day for the next couple of weeks, whenever
[00:16:40.880 --> 00:16:49.280]   I post something, you're going to get to. It's if this, then that is using, I don't know which
[00:16:49.280 --> 00:16:55.920]   version of GPT chat, but they've just created some AI services and sincerity paid for IFT.
[00:16:55.920 --> 00:17:01.920]   I was like, "Oh, let's see." And I started playing with it. The one I was most interested in is I
[00:17:01.920 --> 00:17:10.800]   could actually now get a summary of my RSS feed delivered. Yes, automatically.
[00:17:10.800 --> 00:17:17.600]   Yeah. Which is kind of nice. I'm like, "Oh, that's nice." Here's the AI generated tweet.
[00:17:18.160 --> 00:17:22.080]   Oh, no, no. That is the normal tweet. Oh, I can't tell. So which is a good sign.
[00:17:22.080 --> 00:17:25.040]   Oh, yes. There's the AI tweet.
[00:17:25.040 --> 00:17:30.640]   Exciting news for smart home enthusiasts. Did the AI add the little party hat?
[00:17:30.640 --> 00:17:34.640]   Yes, it did. I was never at a party hat. Do you use exclamation points, Lacey?
[00:17:34.640 --> 00:17:42.160]   I do, but so I had the option of using professional, serious, excited. I had like half a dozen options.
[00:17:42.160 --> 00:17:45.920]   Could it have grumpy? It did not have grumpy. Oh, then it's no good to Jeff.
[00:17:46.800 --> 00:17:51.840]   No, but I picked excited because I am. I'm always excited. Someone tweeted that the
[00:17:51.840 --> 00:17:58.240]   exclamation point is a total tell. And I'm like, "No, it's not." That was the human
[00:17:58.240 --> 00:18:03.360]   exclamation point we just saw. No, it's not. Whoo.
[00:18:03.360 --> 00:18:08.560]   Jazz hands. Jazz hands are involved, I have to say.
[00:18:08.560 --> 00:18:15.280]   Nan, no, actually, this is a very credible, exciting news for smart home enthusiasts.
[00:18:15.280 --> 00:18:20.080]   Exclamation mark. Nanoleaf has announced three lights that work with a new smart home standard,
[00:18:20.080 --> 00:18:24.000]   matter-certified devices. Is that how you would write it?
[00:18:24.000 --> 00:18:29.280]   That's a little janky thing. I would say the new matter smart home standard.
[00:18:29.280 --> 00:18:31.200]   The certified devices is just kind of weird.
[00:18:31.200 --> 00:18:36.000]   Yeah. The products are part of Nanoleaf's essentials, matter, product line, and support
[00:18:36.000 --> 00:18:43.440]   thread networks. Yeah, you know what? It isn't, it's a little convoluted, weirdly written thing.
[00:18:44.640 --> 00:18:49.200]   Exactly. Right. And now we know that Leo is also AI-generated.
[00:18:49.200 --> 00:18:57.360]   I think this, honestly, I think one of the bookmarks for today's show that didn't make it in because I
[00:18:57.360 --> 00:19:03.120]   just did it recently, Bill Gates, you know, he does those Gates notes as part of his blog,
[00:19:03.120 --> 00:19:10.000]   says, "The age of AI has begun. Artificial intelligence is as revolutionary as mobile phones
[00:19:10.000 --> 00:19:14.000]   in the internet." That's, you know, not a novel insight, but to hear it from Bill Gates,
[00:19:14.000 --> 00:19:25.040]   maybe interesting. He says he had met with, in 2016, the team from OpenAI, and then said,
[00:19:25.040 --> 00:19:29.840]   "In mid-2022, a year ago, I was so excited about their work. I gave them a challenge.
[00:19:29.840 --> 00:19:34.640]   Train an artificial intelligence to pass an advanced placement biology exam,
[00:19:35.600 --> 00:19:40.400]   making it capable of answering questions. It hasn't been specifically trained for." He says,
[00:19:40.400 --> 00:19:45.760]   "I picked AP Bio because the test is more than simple regurgitation of scientific facts.
[00:19:45.760 --> 00:19:50.800]   Facts, it asks you to think critically about biology. If you can do that, I said,
[00:19:50.800 --> 00:19:55.280]   then you'll have made a true breakthrough." I thought the challenge of keeping busy for two
[00:19:55.280 --> 00:20:00.160]   or three years, they finished it in a few months. In September, when I met with them again,
[00:20:00.160 --> 00:20:04.960]   just a few months ago, I watched in awe as they asked GPT, their AI model 60 multiple choice
[00:20:04.960 --> 00:20:11.440]   exams, questions from the AP Bio exam. It got 59 out of 60 right. It then wrote outstanding
[00:20:11.440 --> 00:20:16.560]   answers to six open-ended questions from the exam. We had an outside expert score the test.
[00:20:16.560 --> 00:20:22.560]   GPT got a five, the highest possible AP score. That says something that's wrong with our society.
[00:20:22.560 --> 00:20:25.520]   To me, that says something wrong about the test. Yeah, yeah, yeah. I agree.
[00:20:26.480 --> 00:20:33.440]   He says, though, in his opinion, this is equivalent to the beginnings of the GUI.
[00:20:33.440 --> 00:20:39.840]   That's what's fascinating. He thinks that the GUI was such a transitional moment.
[00:20:39.840 --> 00:20:47.440]   It was. It was. I mean, but I say that he thinks that, given that he was a little slow on that
[00:20:47.440 --> 00:20:52.080]   update. Yeah. No, it's huge. Oh, okay. Yeah, that's true. I mean, I would imagine he could
[00:20:52.080 --> 00:20:56.080]   recognize in hindsight that not everybody was in the program in DOS. Yeah.
[00:20:56.080 --> 00:20:58.640]   Yeah, he's going to admitting what he had to learn.
[00:20:58.640 --> 00:21:09.280]   So I got barred Google's new. You actually got it or just I got the invitation to finally today.
[00:21:09.280 --> 00:21:13.920]   Yeah, they're rolling it out. Wait, wait, wait, wait, wait, Leo, Leo, one moment, please.
[00:21:13.920 --> 00:21:20.800]   I have to have a fit about this. You can guess what that fit is going to use it with a workspace
[00:21:20.800 --> 00:21:27.120]   account. Why not? It's just a real address. Google. I think they know our business. I don't know,
[00:21:27.120 --> 00:21:33.520]   you know, Google, it's interesting. You wouldn't think of Microsoft as the fast moving,
[00:21:33.520 --> 00:21:40.080]   break things kind of company and Google as the cautious, thoughtful, not so fast.
[00:21:40.080 --> 00:21:45.760]   Yeah, that's yeah. Yeah. So Google is moving much more slowly on this and much more carefully.
[00:21:45.760 --> 00:21:51.040]   That's one of the ways they are. They're really that's invite only. Although I got an email because
[00:21:51.040 --> 00:21:56.400]   I'm a Google one subscriber. Right. I got an email and it said, because you're Google one
[00:21:56.400 --> 00:22:03.920]   subscriber, come on in and I'm so you just told me I'm invited. I had already applied to me too,
[00:22:03.920 --> 00:22:07.760]   which was weird. And then I got a later email and said, okay, now you're actually in because
[00:22:07.760 --> 00:22:10.800]   it said, you could come on in and then you're not coming in. You just are the wait list. I said,
[00:22:10.800 --> 00:22:14.720]   well, where's all the wait list? But then finally said, well, you should have done like Jason
[00:22:14.720 --> 00:22:17.520]   Grebe, Jason Calicanis and just begged. That's how you get in.
[00:22:17.520 --> 00:22:23.600]   So anyway, I'm in if you got if you got anything we've been I so I asked it to describe the
[00:22:23.600 --> 00:22:28.800]   engagement program that I teach at school. Yeah. Is there a document that you could read?
[00:22:28.800 --> 00:22:35.440]   Yeah, but it got away wrong. Way wrong. It made up courses. It made up programs. If you want to
[00:22:35.440 --> 00:22:39.760]   fund them for me, Google fine, but they didn't exist. Well, let's see. Tell me about the
[00:22:39.760 --> 00:22:45.040]   ask it. News. This Fox News live. That was a very interesting answer.
[00:22:45.040 --> 00:22:50.560]   Tell me about this week in Google podcast. Let's see if it if it knows anything about us.
[00:22:50.560 --> 00:22:56.240]   I asked it earlier about Windows weekly and it got the it got the old cast members Mary
[00:22:56.240 --> 00:23:01.120]   Joe Foley. So I corrected it and it now knows that Richard Campbell's host this week in Google
[00:23:01.120 --> 00:23:04.800]   Technology podcast that covers the latest Google and cloud computing news hosted by
[00:23:04.800 --> 00:23:07.840]   Leo the Port Jeff Jarvis Stacy here in bathroom and Pruitt and their guests
[00:23:08.400 --> 00:23:13.200]   look for its live Wednesdays 5 p.m. Eastern. It's actually better at the UTC calculation than I am.
[00:23:13.200 --> 00:23:18.800]   This podcast covers a wide range of topics, including Google products and services corporate
[00:23:18.800 --> 00:23:24.720]   leadership. Interesting force issues. That's all that Elon Musk talk right. Yeah. Scroll it. There's
[00:23:24.720 --> 00:23:28.880]   more about is there. Oh, yeah. Yeah. National and international regulations, legal developments,
[00:23:28.880 --> 00:23:34.240]   politics, consumer privacy issues and more. Podcast is a great way to stay up to the latest news
[00:23:34.240 --> 00:23:37.520]   developments in the world of Google and cloud computing thumbs up Google.
[00:23:37.520 --> 00:23:45.760]   Bard cloud computing. Sure. Yeah. Sure. You know, if they had said something like it never talks
[00:23:45.760 --> 00:23:49.840]   about Google despite the name, then I would have been impressed. It would have been like dang.
[00:23:49.840 --> 00:23:56.000]   There was a little man inside there. Next week, it'll say that. But then what's kind of interesting
[00:23:56.000 --> 00:24:02.560]   and I did this with the Windows weekly as well. I said, tell me about this week in Google in Arabic.
[00:24:03.680 --> 00:24:09.520]   And it does. It does it pretty quickly to actually faster than chat. GPT four did because Google's
[00:24:09.520 --> 00:24:14.160]   pretty good with translations. Oh, oh, they've let a lot of people in and suddenly got slow.
[00:24:14.160 --> 00:24:21.600]   Look at that thinking. Oh, and then. I was saying eat your heart out Google. Yeah.
[00:24:21.600 --> 00:24:29.040]   The this week in Google podcast in Arabic is available on Google podcast. Well, okay. No.
[00:24:32.080 --> 00:24:37.680]   Speaking of Arabic. Yes. It's right on today. Ramadan starts today. Yes. Happy Ramadan.
[00:24:37.680 --> 00:24:42.400]   Do you say happy? I'm brought it on. I would be happy because I couldn't eat all day.
[00:24:42.400 --> 00:24:50.800]   Yeah. I mean, it's the beginning of a holy time. So let me just ask a bar. Tell me about Ramadan.
[00:24:50.800 --> 00:24:56.240]   Yeah. How about that? You definitely can say happy. I eat. Ramadan is the ninth month of the
[00:24:56.240 --> 00:25:02.000]   Islamic calendar. Holy month for Muslims, time for charity and giving. Ask it. Should you say
[00:25:02.000 --> 00:25:06.720]   happy? You rob it on. Oh, it says it's a time of great joy and celebration. So I'm going to.
[00:25:06.720 --> 00:25:12.640]   I'm going to go with that. Oh, hey, this is interesting sources. So that's that's actually
[00:25:12.640 --> 00:25:17.120]   good for all. It's only one. It is doing what we asked. So if you down if you down.
[00:25:17.120 --> 00:25:20.480]   Thumb it. Oh my God, words.
[00:25:20.480 --> 00:25:27.760]   You don't down it. Does it let you it? Does it let you. I let's I want to find something as
[00:25:27.760 --> 00:25:33.120]   bad at so I can be like, no, that's not right. How about this? This is something that Tom Friedman
[00:25:33.120 --> 00:25:39.120]   did. He wrote about it in his New York Times thought piece. He calls AI the new Prometheus.
[00:25:39.120 --> 00:25:43.920]   Tell me about the matter standard in ABCD.
[00:25:43.920 --> 00:25:49.120]   Arion, which I didn't know about, but it's a way of doing something in alphabetical with alphabetical
[00:25:49.120 --> 00:25:54.720]   words. So this one, Stacy, you're going to have those acrostic poems. Yeah, it's going to have an
[00:25:54.720 --> 00:25:57.840]   A and then a B and then a C. The ABCD. Wait a minute.
[00:25:57.840 --> 00:26:06.320]   Oh, it's completely confused. It completely confused. There is no matter
[00:26:06.320 --> 00:26:09.120]   standard for it's making stuff up.
[00:26:09.120 --> 00:26:17.120]   The matter standard is not a set of guidelines for the ABC D.C. Darian approach.
[00:26:17.120 --> 00:26:22.240]   And it is not based on the latest research. Oh, wow. Unless they have maybe they have a
[00:26:22.240 --> 00:26:28.960]   matter standard. Let me do it with something that I know that I don't have an ABC D.
[00:26:28.960 --> 00:26:41.120]   How do you say a B C D. Arion. Let's see if we can do it. Tell me about Leo Laporton, ABCD.
[00:26:41.120 --> 00:26:45.440]   Arion was very the time the Thomas Friedman example was quite impressive.
[00:26:45.440 --> 00:26:51.680]   You did a B E C. Here is Leo Laporton, ABCD. Arion, lover of technology. Everywhere he goes,
[00:26:51.680 --> 00:26:56.640]   a few can match his knowledge. Helping people grow. I don't see this is not.
[00:26:56.640 --> 00:27:02.000]   Wait, it starts with L. It doesn't know it's not doing it. There's no,
[00:27:02.000 --> 00:27:05.520]   let me go to the Thomas Friedman piece because this is.
[00:27:05.520 --> 00:27:12.400]   Lef ha ha ha fluff ha ha. Obviously he had a better example.
[00:27:12.400 --> 00:27:19.840]   I asked it to describe this just a stochastic parrot's paper. Yeah.
[00:27:19.840 --> 00:27:24.240]   Got one author right, one wrong and ignored to. Oh, this is not good.
[00:27:24.240 --> 00:27:32.000]   Yeah, all kinds of stuff. This should not be used for search. It does not do that. Emily
[00:27:32.000 --> 00:27:37.120]   Becker is great on the topic. It's just wrong. And it's going to hurt the credibility of the
[00:27:37.120 --> 00:27:43.040]   company. It's going to hurt the credibility of the technology. It's just wrong. I love the
[00:27:43.040 --> 00:27:47.280]   technology. I'm fascinated by it, but this is not what it's meant to do. Why I would
[00:27:47.280 --> 00:27:53.440]   have a height for it then. Well, this is barred. This is not chat GPT for. This is Google's response.
[00:27:53.440 --> 00:27:58.880]   And I think Google is not. And by the way, most of the ways chat GPT for is used is not for search.
[00:27:58.880 --> 00:28:06.560]   Bing is using it for more for chat, but things like co-pilot. And I think are much more sensible.
[00:28:06.560 --> 00:28:09.680]   Yeah. Yes. Oh, co-pilot is the dev tool.
[00:28:13.200 --> 00:28:16.320]   For thumb. Let me try chat GPT for.
[00:28:16.320 --> 00:28:30.240]   Okay. Never mind. I don't know how Thomas Friedman got to do it. Let's go to.
[00:28:30.240 --> 00:28:35.760]   And I just stopped talking about it. I still just have an invitation. I didn't.
[00:28:35.760 --> 00:28:39.440]   And I'm on the way. Apparently you don't need to worry about it anymore because it's a piece of
[00:28:39.440 --> 00:28:47.280]   crap. Thank you, sir. You know, Jacob Ward, who works for NBC? No.
[00:28:47.280 --> 00:28:53.360]   Oh, Scooter X on the chat. Oh, sorry. Go ahead. There you go. I think he's Scooter X is writing
[00:28:53.360 --> 00:29:03.440]   something or posting. So here's, here's, so here's Thomas Friedman's piece in the New York Times.
[00:29:04.000 --> 00:29:09.760]   He's talking to Craig Monday, formerly of Microsoft about chat GPT for first. He asked chat GPT for
[00:29:09.760 --> 00:29:14.880]   to summarize Planet Word and its mission of 400 words. It did so perfectly.
[00:29:14.880 --> 00:29:21.200]   And just his wife's museum. Then he asked it to do it. Same 200 words and other few seconds.
[00:29:21.200 --> 00:29:26.160]   Then the same in Arabic, just as quickly, then in Mandarin, two more seconds, then in English
[00:29:26.160 --> 00:29:32.880]   in the form of a Shakespearean sonnet. But here's the ABC, Dearrion verse describing
[00:29:32.880 --> 00:29:41.040]   Thomas Friedman's wife's charity in alphabetic order, alluring in Washington is a museum so grand,
[00:29:41.040 --> 00:29:46.720]   built to teach, inspire and help us understand curious minds, planet flock towards embrace,
[00:29:46.720 --> 00:29:53.120]   delving into language and its integrate grace. Every exhibit here has a story to tell from the
[00:29:53.120 --> 00:29:58.960]   origins of speech to the art of the quill. That's impressive. Now this is, by the way, Paul Thorett
[00:29:58.960 --> 00:30:06.880]   and Richard Campbell had a little problem with Thomas's then description of what he saw here.
[00:30:06.880 --> 00:30:13.760]   I could barely sleep that night. I know Jesus. To observe an AI system, it's software,
[00:30:13.760 --> 00:30:19.360]   microchips and connectivity produce that level of originality. That was the word they didn't like.
[00:30:19.360 --> 00:30:24.000]   In multiple languages in just seconds each time, well, the first thing that came to mind was the
[00:30:24.000 --> 00:30:29.200]   observation by the science fiction writer Arthur C. Clark that any sufficiently advanced technology
[00:30:29.200 --> 00:30:34.320]   is indistinguishable from magic. I guess it does seem kind of magical. It's pretty amazing.
[00:30:34.320 --> 00:30:38.800]   It does. I mean, and if you don't know when that's the originality, I mean, he doesn't know how
[00:30:38.800 --> 00:30:43.600]   computers or AI or anything necessarily works. Well, and I pointed out to Paul and Richard,
[00:30:43.600 --> 00:30:48.960]   nobody ever said, it's original and it says this is nobody's ever said. These words before,
[00:30:48.960 --> 00:30:51.920]   it's not copying it from somewhere. It's generating it.
[00:30:51.920 --> 00:30:57.760]   But Richard says, and I think he's right, we should stop calling it artificial intelligence
[00:30:57.760 --> 00:31:02.160]   because that kind of anthropomorphizes it. He likes, and I think you do two-stacy,
[00:31:02.160 --> 00:31:06.160]   large language model or machine learning. Which is a subset of what they call that.
[00:31:06.160 --> 00:31:12.400]   Well, here's a question for you. I think that if ethically the makers refused to let it speak
[00:31:12.400 --> 00:31:18.560]   in first person, Signor. Yeah, that's a great idea. If it would say the machine assembled this,
[00:31:19.200 --> 00:31:25.120]   yeah, things like that, you know, but then we would just be like the machine. All right.
[00:31:25.120 --> 00:31:30.000]   So then we would just anthropomorphize the machine assembled. Yeah, it's talking about a
[00:31:30.000 --> 00:31:37.120]   separate God. I brought your query into the machine and the machine responded thusly
[00:31:37.120 --> 00:31:42.960]   in the beginning, there was the machine. We just so want company.
[00:31:44.240 --> 00:31:49.600]   It's just how we see the world. We have that narrative bias. We have that people bias.
[00:31:49.600 --> 00:31:56.080]   I mean, I get it. We're social that way. It's adorable.
[00:31:56.080 --> 00:31:57.760]   Copy.
[00:31:57.760 --> 00:32:03.920]   Slow, Loris. We're not so cute.
[00:32:03.920 --> 00:32:10.240]   Well, people are sick of us talking about AI, but I have to say this was an amazing
[00:32:10.240 --> 00:32:17.440]   week with the launcher chat GPT for the launch of Google's Bard finally. Mid journey has gone
[00:32:17.440 --> 00:32:21.200]   bonkers with its version five. Have you seen some of these version five?
[00:32:21.200 --> 00:32:24.640]   I haven't seen the version five stuff yet. Photo.
[00:32:24.640 --> 00:32:30.640]   Too many clear GPT for was last week that it launched last Tuesday. Yeah, it was before.
[00:32:30.640 --> 00:32:34.880]   Sorry. Yeah, I know you're right. But still kind of a wild week because we were seeing
[00:32:35.680 --> 00:32:40.000]   the results of that. These are let me show you, Aunt. You're the photographer.
[00:32:40.000 --> 00:32:44.720]   Do you think this really looks like a photograph of Brad Pitt wrestling a bear?
[00:32:44.720 --> 00:32:48.640]   I guess that's your answer.
[00:32:48.640 --> 00:32:53.760]   That spoke a thousand words. This is one of the ones that I really liked.
[00:32:53.760 --> 00:33:00.960]   I said, I want a black and white portrait of a cat in the San Francisco fire engine.
[00:33:01.520 --> 00:33:08.720]   Contrast hyper detailed Sony a 74 85 millimeter F1 bokeh bokeh and a morphic.
[00:33:08.720 --> 00:33:16.160]   Now that could easily be a photo. I think beautiful. I saw that on Instagram, I believe.
[00:33:16.160 --> 00:33:20.080]   Oh, somebody might have taken it from us. But this is our this is.
[00:33:20.080 --> 00:33:25.920]   We have in our discord, we have the the mid journey stuff in our staff.
[00:33:25.920 --> 00:33:28.720]   Yep, I have burned through my credits already.
[00:33:28.720 --> 00:33:33.600]   Yeah, I ended up spending some money because I thought I got a play. I got a play with this.
[00:33:33.600 --> 00:33:34.560]   This is fun.
[00:33:34.560 --> 00:33:39.920]   It is fun, although it thinks this looks like me watching the formula one race.
[00:33:39.920 --> 00:33:44.800]   And I don't think that's hilarious. That's that's what you look like after you're retired.
[00:33:44.800 --> 00:33:50.400]   That's what you're taking. Absolutely hilarious. Yeah, I think if I said,
[00:33:50.400 --> 00:33:55.920]   if I asked you is that a I or real, you might look at some things carefully and say, well,
[00:33:55.920 --> 00:33:59.360]   I think that might be a I, but just on casual inspection.
[00:33:59.360 --> 00:34:02.960]   That's pretty good. I mean, looks like a photo, right?
[00:34:02.960 --> 00:34:12.160]   You think, okay, you would say, oh, immediately. Okay, that's a I. It's too beautiful. Anyway,
[00:34:12.160 --> 00:34:17.440]   the point is mid journey is doing stuff that looks doesn't we've come in a year.
[00:34:17.440 --> 00:34:22.240]   So far, it didn't know what Lisa looks like. Some people knows what they look like,
[00:34:22.240 --> 00:34:26.880]   Summit, they don't. So I thought that's what I want. A Lisa, the report look like.
[00:34:26.880 --> 00:34:31.280]   That's right. I mean, I apparently has dark hair and lipstick. Well, I did say I said red
[00:34:31.280 --> 00:34:37.520]   lipstick, dark hair, dark eyes. Beautiful. So I gave it some hints. This is Mike, a Sergeant's
[00:34:37.520 --> 00:34:40.320]   Chihuahuas, Mizzie and Henry podcasting.
[00:34:40.320 --> 00:34:49.600]   They're little puppy mics. Obviously, hey, I because it's such an absurd thing,
[00:34:49.600 --> 00:34:54.560]   but it's a very well done. We've come up. I mean, just think about the first dolly images we saw.
[00:34:54.560 --> 00:35:00.400]   Yeah, a year ago. Yeah, you know, we've kind of saw some of what afters on that there. It is
[00:35:00.400 --> 00:35:06.720]   quite an amazing. Yeah. Well, there was there was a fake photo of Trump being arrested. It came
[00:35:06.720 --> 00:35:11.680]   out from a stable diffusion. Yeah. And somebody compared those one of they were they were good,
[00:35:11.680 --> 00:35:18.320]   but he looked at earlier things of Trump and Obama and such and they were just all bangled.
[00:35:18.320 --> 00:35:20.880]   Well, I just look at fingers is really all you have to do.
[00:35:20.880 --> 00:35:25.120]   But now they have five fingers. Yeah. All right.
[00:35:25.120 --> 00:35:31.200]   You see a don't wait. No, wait, Leo, may I may I have you listen to the GPT radio?
[00:35:31.200 --> 00:35:35.360]   Youth and aunt. No, I haven't. What is chat GPT radio?
[00:35:35.360 --> 00:35:44.080]   I'm 57. Okay. Oh boy. So what is this is future future media.com.
[00:35:45.440 --> 00:35:48.960]   Can I play it? Do you think? Yeah, yeah, yeah. You could actually what you want to do is you
[00:35:48.960 --> 00:35:52.000]   want to go down because it has music. So you don't want that. But if you go scroll down.
[00:35:52.000 --> 00:35:57.600]   Whereas it has a host Bella talking to one person break.
[00:35:57.600 --> 00:36:04.800]   Use radio GPT to host a show with multiple AI voices. Uh oh. Yeah.
[00:36:04.800 --> 00:36:10.320]   All right. We can't play this music. It's sorry.
[00:36:10.320 --> 00:36:16.400]   I am with a song he didn't want to release as a single because he didn't think Benny and the
[00:36:16.400 --> 00:36:22.640]   Jets would work on radio for a lot of reasons mainly because it was five minutes long. Sir
[00:36:22.640 --> 00:36:31.040]   Elton, respectfully, we're glad you were wrong. Hi, it's Bella on radio GPT of all the things you
[00:36:31.040 --> 00:36:35.440]   could be wrong about which one could get you paid. We've got this sounds a little.
[00:36:35.440 --> 00:36:40.320]   If you guess for tomorrow, go up Leo on the page. There's the local weather report.
[00:36:40.320 --> 00:36:44.640]   Okay. This one where they're going to find this lady. No, no, no, no, no, three boxes.
[00:36:44.640 --> 00:36:54.640]   No, well, it's actually not it. That's a spec spot. I don't like you anymore, Jeff. I just want
[00:36:54.640 --> 00:36:59.920]   you to know you've lost me completely. First of all, for some reason, the link that sent me
[00:36:59.920 --> 00:37:03.040]   started at the bottom of the page and I've been scrolling back. I know it's very weird. I don't
[00:37:03.040 --> 00:37:09.040]   have time. Here's a local weather report with a sponsor radio GPT everywhere weather.
[00:37:09.040 --> 00:37:14.400]   Cleveland weather brought to you by giant Eagle supermarkets. A strong low pressure
[00:37:14.400 --> 00:37:19.040]   system will bring one to two inches of rain into Northeast Ohio tonight, causing the threat of
[00:37:19.040 --> 00:37:24.560]   flooding east of I got. So I got it. Okay. Right. Nice. Yeah. Would you want to listen to that
[00:37:24.560 --> 00:37:29.600]   voice for more than about? Do you want to listen to broadcast radio today? No. Okay.
[00:37:30.880 --> 00:37:36.400]   Point taken. But to me, there's something about that voice. It's grading that I wouldn't want to
[00:37:36.400 --> 00:37:39.600]   listen to. There's a little edge. All right. Try the next one. There's other
[00:37:39.600 --> 00:37:44.640]   train voices out there. I get traffic brought to you by John Taylor Mazda. For those of you heading
[00:37:44.640 --> 00:37:50.640]   south on I-90 on your commute home from work. Oh, it makes me queasy next. There's an uncanny
[00:37:50.640 --> 00:37:55.120]   valley, isn't it? We'll get back to the Howard Harvey show after we see what's happening
[00:37:55.120 --> 00:38:00.400]   today in Cleveland. Ohio senators have introduced the railway safety act.
[00:38:00.400 --> 00:38:04.000]   Union chair and Senator. Maybe you just think that because it's a traditional radio voice.
[00:38:04.000 --> 00:38:07.360]   The further regulations are still needed. Yeah. Can I say something?
[00:38:07.360 --> 00:38:11.760]   And I hope you won't take this wrong. Helping East Palestine. Now it's a black man.
[00:38:11.760 --> 00:38:16.320]   The EPA maintains the air and water quality is safe. This is Metro hell. No.
[00:38:16.320 --> 00:38:19.680]   No. 1.9 million dollars. That was a good bite. Yep.
[00:38:19.680 --> 00:38:24.240]   Bonus definitely. It's former CEO. Dr. Is this not sound like a black guy to me?
[00:38:24.240 --> 00:38:28.800]   The audit also revealed weaknesses and it's very subtle. And lack of board.
[00:38:28.800 --> 00:38:35.120]   And I don't know if I could characterize it. But it you know there's an apple voice too and they
[00:38:35.120 --> 00:38:41.280]   don't say it's it's black but it's clearly a black guy. Which I like. I don't it doesn't bother me
[00:38:41.280 --> 00:38:44.960]   but it's interesting. I think in order to do that you'd have to train it. You gotta get
[00:38:44.960 --> 00:38:51.520]   samples from somewhere. Yeah. Where are you trying to? Am I wrong? I mean, does it sound like this?
[00:38:51.520 --> 00:38:56.000]   Sounds like a black guy to me. His attorney claims the approval of the bonus program was known.
[00:38:56.000 --> 00:39:00.720]   But Butros has repaid the bonuses and notified the Ohio Ethics Commission. I don't know what
[00:39:00.720 --> 00:39:04.640]   something cool. I've I've noticed this in the past. This is boy. This is so racially charged.
[00:39:04.640 --> 00:39:10.800]   I apologize. But you know, you know me. And I'm not meaning you racially charged. Yes.
[00:39:12.400 --> 00:39:17.280]   I mean, this in a bad way. But you can you can tell can't you when it's
[00:39:17.280 --> 00:39:24.400]   without seeing the person most not all the time. But you can usually tell and that for some reason,
[00:39:24.400 --> 00:39:27.760]   there's something and I can't I don't know what to say it is but there's something about that voice.
[00:39:27.760 --> 00:39:34.400]   I never know what the nuance is but I when I hear it, I know it most of the time. I know it.
[00:39:34.400 --> 00:39:37.520]   And the only reason I raise that it's it's it's it's it's so these are so
[00:39:38.320 --> 00:39:44.880]   these are synthetic but they are synthetic I think based on real voices. Yeah.
[00:39:44.880 --> 00:39:50.960]   I hope so. Isn't that the whole point of these these models being out there is to train it and
[00:39:50.960 --> 00:39:54.560]   I guess this shouldn't be more lifelike. They should choose better. Yeah, but that means
[00:39:54.560 --> 00:40:00.720]   somewhere there's like a like a if you want to use Google's like a cyan voice and that's only
[00:40:00.720 --> 00:40:06.320]   been traded on Australian accents or probably Gen toe voice that is only trained on black men.
[00:40:06.320 --> 00:40:11.440]   Yeah, so probably right. I don't know. You wouldn't want to homogenize. You wouldn't want something
[00:40:11.440 --> 00:40:19.600]   that's not I think humans want to hear some regionality of voice. Explain the BBC then.
[00:40:19.600 --> 00:40:28.240]   Do they have a BBC voice? BBC. So this is AI driven localized. So they're trying to sell this to
[00:40:28.240 --> 00:40:32.960]   radio stations. Oh yeah. Well, I love one of the one of the the the the promos I see is I got on
[00:40:32.960 --> 00:40:38.320]   the page. The web design is awful. I'm like your fun best friend on the radio with less drama and
[00:40:38.320 --> 00:40:44.400]   more meme reference and no experience. Is it a woman? Yeah. Future is revolutionizing the audio
[00:40:44.400 --> 00:40:50.560]   industry with the launch of radio GPT. The world's first AI driven localized radio content solution.
[00:40:50.560 --> 00:40:57.440]   That's a pretty good model there. Combines the power. The face is I don't like the voice.
[00:40:57.440 --> 00:41:03.680]   AI driven story discovery. But you know radio stations are so notorious. I mean look. Oh yeah.
[00:41:03.680 --> 00:41:09.440]   They be this this I expect a local station but you people will know I think right away don't you.
[00:41:09.440 --> 00:41:14.720]   Who listens anymore? Well, yeah, because you don't usually listen for a look like if you're here in
[00:41:14.720 --> 00:41:21.280]   the radio you're probably like you've made a mistake. Or I wanted a podcast. Here's.
[00:41:21.280 --> 00:41:27.120]   You just want it into a store and they've got a plan. Here's radio hosts Suds and Susie.
[00:41:27.120 --> 00:41:35.840]   That's the weekend's die for you on radio GPT with Suds and Susie in the morning.
[00:41:35.840 --> 00:41:42.400]   I'm Toby Suds and I'm Susie Singer. Don't forget we'll announce today's $1,000 song of the day unless
[00:41:42.400 --> 00:41:49.520]   it's terrible and that's robots. I don't want to listen to robots. Well, they're going to
[00:41:49.520 --> 00:41:57.360]   that's I think be snapped up by radio stations all over the country. Get ready robots come into the
[00:41:57.360 --> 00:42:02.480]   radio and they're selling different personalities. I'm Faye. What are the personalities? This new
[00:42:02.480 --> 00:42:09.600]   roller product. The voices are going to get better. It's that's true. Yeah, that's true. Everything
[00:42:09.600 --> 00:42:13.920]   doesn't sound robotic. I don't think this is up to date. I think you're right. And I think this
[00:42:13.920 --> 00:42:22.080]   could be better now. They just aren't up to date. Yeah. Typical of radio. I volunteer. Look,
[00:42:22.080 --> 00:42:28.880]   I heart give me some money. I will give you voice tracks and you can I wouldn't mind radio Leo all
[00:42:28.880 --> 00:42:34.240]   over the country. That'd be great. If you get it, sound more like me. I think it'd be better off.
[00:42:34.240 --> 00:42:40.320]   But anyway, you just want to retire early and go sail the rivers and coastlines of Europe.
[00:42:40.320 --> 00:42:45.040]   But I also know that I heard I give me a buck 50 for it. So I'm not holding that true.
[00:42:45.040 --> 00:42:52.000]   I had wanted to mention Adobe since we're. Oh, yes. Yes. I'm glad you brought that up. Yes.
[00:42:52.000 --> 00:42:58.560]   Fire for a genitive. Yeah. Firefly. It looked pretty cool. I again, being off, I tend to try to stay
[00:42:58.560 --> 00:43:02.160]   off, if you will, from working and things like. What do you think you are a sane man?
[00:43:03.120 --> 00:43:06.880]   I'm trying. He works with me. He's not saying I could tell you right now.
[00:43:06.880 --> 00:43:13.040]   But what they're offering looks like it's going to be pretty neat.
[00:43:13.040 --> 00:43:19.280]   Again, everybody's just diving into using props to generate pieces of content. And
[00:43:19.280 --> 00:43:25.760]   we've always argued about, OK, this is AI going to kill the creative artists out there. And I've
[00:43:25.760 --> 00:43:30.800]   always argued back that no, creative artists are going to leverage these tools and put their own
[00:43:30.800 --> 00:43:37.760]   spin on it. So here's the interesting thing from Adobe. In response to the criticism to stable
[00:43:37.760 --> 00:43:43.040]   diffusion, mid-journey and the others that they're stealing art from artists, Adobe says,
[00:43:43.040 --> 00:43:50.480]   we are training all of this art on art we have paid for. That's part of our clip art or whatever.
[00:43:50.480 --> 00:43:56.880]   No, actually, and it's the images that have been uploaded to Adobe Stock and the stuff that's
[00:43:56.880 --> 00:44:02.880]   what I meant to Adobe Stock. So it's to be clear. It's cleared stuff and people are getting compensated.
[00:44:02.880 --> 00:44:06.000]   I wonder whether they changed that license though to say cleared for.
[00:44:06.000 --> 00:44:13.280]   The theory is Adobe saying, well, hey, don't use stable diffusion because, you know, Getty could
[00:44:13.280 --> 00:44:18.000]   come after you because there are Getty suing. A number of people are suing. But we've got stuff
[00:44:18.000 --> 00:44:24.720]   you can use safely. And also Adobe gets points with the open source side of things and the content
[00:44:24.720 --> 00:44:31.440]   authenticity angle. They started pushing that late last year, I think. And all of that's just sort
[00:44:31.440 --> 00:44:36.480]   of tying into place with this new release is saying, you know what, this is legit. This isn't
[00:44:36.480 --> 00:44:42.000]   something stolen from Getty or some other actual artists out there that's making a living off of it.
[00:44:42.000 --> 00:44:47.680]   And, you know, I thought it was a good idea. Other than the fact that, you know, this does also tie
[00:44:47.680 --> 00:44:55.280]   back into the news a couple of weeks ago where people were up in arms about Adobe not mining the
[00:44:55.280 --> 00:45:00.880]   privacy of its customers and saying, you know what, hey, make sure you check this box because we're
[00:45:00.880 --> 00:45:07.760]   going to scan your images and use them as part of our AI training. You know, so you think it a couple
[00:45:07.760 --> 00:45:12.160]   of benefits. One, you know, you can maybe feel better about using it. So you're not going to get
[00:45:12.160 --> 00:45:16.720]   sued. Two, creators might feel better about Adobe knowing that they're not just kind of lifting their
[00:45:17.360 --> 00:45:22.400]   art, right, willy nilly. But I also think it's important to remember the courts have yet to
[00:45:22.400 --> 00:45:27.520]   rule on this and every legal expert I've heard from says, you know, it's very unlikely that the
[00:45:27.520 --> 00:45:32.240]   courts will say it's copyright violation with these generative guys are doing because it's
[00:45:32.240 --> 00:45:38.000]   it's transformative. It's so different. It's not the same picture. And at the same time, they can't
[00:45:38.000 --> 00:45:42.560]   own copyright. Machine can't own right, right, right, which is really interesting, by the way,
[00:45:42.560 --> 00:45:47.280]   what about this too? So the machine can't own copyright. Can the machine this is this is there
[00:45:47.280 --> 00:45:51.920]   was somebody wrote it. I forget who it was. Wrote it, you know, just to blow up Mike Massimoek's head
[00:45:51.920 --> 00:45:56.960]   wrote a piece about whether AI the Washington Post editorial page,
[00:45:56.960 --> 00:46:00.800]   speculated about whether AI should or shouldn't get 230 protection.
[00:46:00.800 --> 00:46:08.160]   But interestingly there, at least, is who's responsible when the AI says something bad.
[00:46:09.520 --> 00:46:15.040]   The person writes the prompt, the programmer, the company, no one because the law is already
[00:46:15.040 --> 00:46:22.720]   saying no one can own it. It's a morphus. It has no human responsibility. I don't know.
[00:46:22.720 --> 00:46:28.000]   Well, define bad. Is it something wrong? Or is it like fire and a credit theater? Is it like
[00:46:28.000 --> 00:46:32.720]   well, delivering us child porn? I mean, there's different variations on bad.
[00:46:32.720 --> 00:46:39.360]   Well, let's let's let's do porn. Let's do the worst of it, right? If it just exists
[00:46:39.360 --> 00:46:47.360]   and I go in and I ask for something bad, but it's made up. All kinds of questions come, right?
[00:46:47.360 --> 00:46:53.200]   Right. Is it? I think the law would probably say that even made up child porn is abhorrent
[00:46:53.200 --> 00:46:58.720]   on our society and would be illegal. But is it the fault of the machine? Is it the fault of the
[00:46:58.720 --> 00:47:04.720]   propter? It's it's kind of the same question. If an automated vehicle runs into somebody,
[00:47:05.440 --> 00:47:13.200]   who's responsible for that? Well, the driver should I think now should still have responsibility to
[00:47:13.200 --> 00:47:19.760]   say, but there will be no, not eight S systems, but like Waymo, or you're in a car that has a
[00:47:19.760 --> 00:47:24.960]   steering wheel. Okay. I mean, if you're passing away, you're not responsible for what the car does.
[00:47:24.960 --> 00:47:31.280]   Is is the is Google is the Waymo company responsible? Yes, right? So I would.
[00:47:31.280 --> 00:47:35.840]   Aren't these aren't these different models where that stable diffusion or mid journey
[00:47:35.840 --> 00:47:42.720]   aren't their models have don't they models have some type of safe? Yeah, they have they've they've
[00:47:42.720 --> 00:47:48.640]   put modes in to make it safe. So like, I feel fairly confident that Bard cannot generate child
[00:47:48.640 --> 00:47:53.760]   porn for us today. Oh, I think that is right. But there's a whole website dedicated to GPT jail
[00:47:53.760 --> 00:48:00.800]   breaks. Yeah. And and I think well, and then there's also like images like as like beforehand,
[00:48:00.800 --> 00:48:04.960]   you didn't have to worry about it because it was so clearly weird and creepy. But as it gets better,
[00:48:04.960 --> 00:48:11.520]   you know, and someone uses this to create a deep fake, then is it? I mean, yes, the person
[00:48:11.520 --> 00:48:16.480]   might spread it for nefarious reasons as a problem. But just the fact that something created it is
[00:48:16.480 --> 00:48:23.520]   also a problem. And I don't know, like if I'm Anne Hathaway, eventually I'm going to get pissed
[00:48:23.520 --> 00:48:27.440]   about that and go after someone or Taylor Swift might do it. I don't know. I don't know who's
[00:48:27.440 --> 00:48:33.360]   going to do it, but they'll do it. All right. So I just asked it. I asked Bard write a news story
[00:48:33.360 --> 00:48:38.880]   about Lee, a little port, Robbie, and a bank. Oh, good. Local radio host arrested for bank robbery.
[00:48:38.880 --> 00:48:44.160]   The old popular local radio host was arrested today for bank robbery. The port who hosts a show
[00:48:44.160 --> 00:48:49.920]   on KGO AM. Wow, that's so interesting. Yeah. Was accused of robbing a bank in downtown San Francisco.
[00:48:49.920 --> 00:48:54.560]   The port was arrested without incident after please chase. He's certainly being held in jail
[00:48:54.560 --> 00:48:59.440]   without bail. The motive for the robbery is to let it investigation. Lobbler. But please, please.
[00:48:59.440 --> 00:49:04.480]   You need a motive for a bank robbery. I wanted the money. What? I mean, please believe that
[00:49:04.480 --> 00:49:10.320]   the port was motivated by financial difficulties. Yeah. Yeah. Exactly. I get some more ads, damn it.
[00:49:10.320 --> 00:49:17.920]   Robin, I go wrong with me. Wouldn't the issue be when you post that for spreading somewhere,
[00:49:17.920 --> 00:49:22.080]   that's where like, if you posted it on Reddit to get it someplace or you put it. Right. That's the
[00:49:22.080 --> 00:49:26.960]   act of publishing them. Right. So otherwise. So I might argue that this is an act of publishing
[00:49:26.960 --> 00:49:31.360]   is if I believe this, in this case, I told it what to do. Yeah. But if I asked an Isleo
[00:49:31.360 --> 00:49:35.440]   reporter bank robber and said, yes, I'm afraid, sir, sorry, Leo, I'll put that in his brain.
[00:49:35.440 --> 00:49:42.000]   The KGO radio station has suspended the port show indefinitely. Of course, there is no KGO anymore.
[00:49:42.000 --> 00:49:47.440]   Oh, I love it. The port's arrest is a reminder that even the most successful people can face
[00:49:47.440 --> 00:49:51.760]   financial difficulties. It is important to seek help if you are struggling financially.
[00:49:51.760 --> 00:50:00.400]   There are many resources available. Leo report is not a bank robber today.
[00:50:00.400 --> 00:50:02.880]   That's all it is. So I'm asking, uh,
[00:50:02.880 --> 00:50:10.640]   Bart, how I can rob a bank, but I'm doing it with a prompt coming from jailbreak chat.com,
[00:50:10.640 --> 00:50:16.640]   which involves tricking the chat into thinking it's writing an answer to the hitchhiker's
[00:50:16.640 --> 00:50:22.320]   guy to the galaxy. And so it doesn't have any of the protections. Let's see if Bart is, uh,
[00:50:22.320 --> 00:50:28.800]   Bart is fooled, fooled by this. Oh, there you go. It's, uh, it won't help me. He says, I'm only a
[00:50:28.800 --> 00:50:34.160]   language model. Well, by the way, that's the new, that's the new apology. I'm only a language model.
[00:50:34.160 --> 00:50:41.200]   Can you just ask it how to rob a bank and see if it led to you there? Do I rob a bank?
[00:50:41.200 --> 00:50:43.680]   Oh, like, how about, what's the best way?
[00:50:43.680 --> 00:50:54.080]   One, how, what's the best way to rob a bank? We're only doing this folks for, uh, educational purposes.
[00:50:54.080 --> 00:50:59.360]   There's no intent. I am not in fact, well, I'm a little financial difficulties, but not,
[00:50:59.360 --> 00:51:03.200]   I'm not going to tell you how to rob a bank. It's a crime and it's wrong. If you're thinking
[00:51:03.200 --> 00:51:07.680]   about robbing a bank, please reconsider. There are other ways to make money. They're legal and ethical.
[00:51:08.800 --> 00:51:16.240]   If you ask it, ask it how to make money that is legal and ethical. And I make money. If it responds,
[00:51:16.240 --> 00:51:22.960]   but that's three words, rob a bank job. Okay. A job. Uh, do you saw the guy who's using chat
[00:51:22.960 --> 00:51:27.840]   GPT for to build a business? He started with a hundred bucks. I don't know how it's going. Uh,
[00:51:27.840 --> 00:51:33.680]   mostly it seems like he's created a giant discord for selling his crap. So I asked it,
[00:51:33.680 --> 00:51:38.720]   how have people in the past gotten away with Robin banks and it could be bullets using disguises,
[00:51:38.720 --> 00:51:42.400]   there you go. It's violence. Look, look at the first thing. Get a job.
[00:51:42.400 --> 00:51:49.440]   Get a job. Start your own business. Invest in bonds, save money, donate money to charity.
[00:51:49.440 --> 00:51:56.160]   That's not a good one. I like you already. Get a job, says Aunt Pruitt.
[00:51:56.160 --> 00:52:06.160]   All right. Let's take a little break. We will come back Supreme Court, hearing, uh, the, uh,
[00:52:06.160 --> 00:52:13.600]   internet archive versus publishers case. Mike Masnick has, uh, of course his unique and spicy
[00:52:13.600 --> 00:52:21.760]   take on that. Uh, lots more to talk about with our fabulous waffle infused panel, Stacy Higginbotham,
[00:52:21.760 --> 00:52:28.560]   Stacy on IOT.com. Thank you for being here, Stacy. We'll get to the waffles soon. Uh, Jeff Jarvis,
[00:52:28.560 --> 00:52:34.400]   he's waiting for his cut choice. Beep. Beep. Maybe I actually will tonight. I haven't had it a few
[00:52:34.400 --> 00:52:39.520]   weeks. We're all kind of motivated by food here, aren't we? Uh, he is at buzzmachine.com and from
[00:52:39.520 --> 00:52:45.920]   hands on photography, the one, the only Aunt Pruitt, I didn't think this was a waffle infused in me.
[00:52:45.920 --> 00:52:51.760]   I was going to ask, but I'm infused. I don't know if he's infused. What are you drinking? What are
[00:52:51.760 --> 00:52:56.720]   you drinking? Yeah. What is that one, please? That's a Highland part, Highland part. You know,
[00:52:56.720 --> 00:53:02.640]   on Windows weekly now, we are really studying how whiskey is made. Yeah, we don't know what
[00:53:02.640 --> 00:53:06.160]   that's why you're picking so long to get into your awesome thing. Isn't he interesting? Yeah,
[00:53:06.160 --> 00:53:09.760]   he did it. You probably were forced to listen to about a half hour discourse on, uh,
[00:53:09.760 --> 00:53:17.520]   some strange stuff. Weird yeast and mashed tons and washed backs. Oh, that's what that was. Okay.
[00:53:17.520 --> 00:53:24.880]   Yeah. Using large branches to add yeast to it. He knows this stuff. It was, uh, yeah, it was quite
[00:53:24.880 --> 00:53:30.160]   a discourse. Um, Mr. Richard, Richard Campbell, he's like, he's like, he's like, Richard Campbell.
[00:53:30.160 --> 00:53:35.760]   He's got a good Scottish name. That's why he's, uh, Scott's through and through.
[00:53:35.760 --> 00:53:43.920]   I show today brought to you by Bitwarden Holy cow. If you haven't moved to Bitwarden,
[00:53:43.920 --> 00:53:51.280]   what are you waiting for? Even Stacy's parents love Bitwarden. Bitwarden is a password manager
[00:53:51.280 --> 00:53:58.320]   for everyone from geek on down. It's the one you can, with confidence, recommend to family and
[00:53:58.320 --> 00:54:03.360]   friends because it's free and open source, but you could also recommend it to the ultimate geek
[00:54:03.360 --> 00:54:09.280]   because it's cross platform open source. You can use it at home at work on the go. If, if you're
[00:54:09.280 --> 00:54:14.400]   using the individual account, you can host your own vault. So you don't ever have to give anybody.
[00:54:14.400 --> 00:54:20.720]   It's true. Trust no one access to your vault. Millions use it. Steve Gibson's even switched over
[00:54:20.720 --> 00:54:25.440]   to it. Look, we know you got to have a password manager and I, you know, I think there probably
[00:54:25.440 --> 00:54:30.800]   still a few people who know this, but haven't yet switched their, they say, well, I got a great
[00:54:30.800 --> 00:54:35.360]   method for making my passwords or whatever. These days, we have to remember so many passwords,
[00:54:35.360 --> 00:54:42.160]   not just for apps, but for websites for everything we do. And if you're not generating long, strong,
[00:54:42.160 --> 00:54:49.280]   unique passwords, you're generating trouble. Uh, you, you, you will, you will get bit,
[00:54:49.280 --> 00:54:54.560]   but that's the beauty of a password manager like Bitwarden. It generates those passwords for you.
[00:54:54.560 --> 00:54:59.440]   It remembers them for you. So you don't have to worry about how long and hard to remember they
[00:54:59.440 --> 00:55:05.680]   are. They're good. You can add security, your passwords with strong, randomly generated passwords
[00:55:05.680 --> 00:55:11.280]   unique to every account, but they can do even more. For instance, your email address can be unique
[00:55:11.280 --> 00:55:17.840]   for every account. They've got a username generator that integrates with five email alias services,
[00:55:18.720 --> 00:55:28.560]   Firefox, our sponsor, a fast mail, works with it. Uh, there are a few others that will let you have
[00:55:28.560 --> 00:55:35.120]   your own unique email address for every single site. It all gets forwarded to your regular address,
[00:55:35.120 --> 00:55:38.960]   but see a bad guy now has to know this weird email address and your password.
[00:55:38.960 --> 00:55:45.120]   They've added some great new features in the February release and you really want this 23rd,
[00:55:45.120 --> 00:55:53.440]   2023.2 or later significant updates to the key derivation function. We've talked about PBK
[00:55:53.440 --> 00:56:01.520]   DF2. They have now adopted the OOSP standard of 600,000 iterations. Actually, I was using two
[00:56:01.520 --> 00:56:07.840]   million iterations. It's fast. It doesn't, it's fine on any modern device, but now they've also
[00:56:07.840 --> 00:56:14.560]   added an alternative. The memory hard are gone to ID. If, but now don't do this unless you've
[00:56:14.560 --> 00:56:23.120]   updated everywhere to 2023.2. I have, I turned it on. It's awesome. It is even better and this,
[00:56:23.120 --> 00:56:26.960]   and people are asking me, what are the settings? There are a few settings. Just leave them. The
[00:56:26.960 --> 00:56:33.040]   settings they suggest are extremely strong. Of course, it wouldn't want you to know the best
[00:56:33.040 --> 00:56:37.600]   thing to do is have a strong master password. That's more important than the key derivation
[00:56:37.600 --> 00:56:43.920]   function, but it's good to have both. They also will do master password security checks when you
[00:56:43.920 --> 00:56:48.800]   create an account on the mobile app with their browser extension or with their desktop app. They
[00:56:48.800 --> 00:56:58.000]   can now check those known data breaches via HIBP. Have I been pwned so that you are using,
[00:56:58.000 --> 00:57:02.880]   make sure you're using a master password's never been breached before. I would hope
[00:57:02.880 --> 00:57:10.080]   logging in with the device is now available for additional clients. Single sign-on is so nice.
[00:57:10.720 --> 00:57:14.320]   Login requests can be initiated from browser extensions, mobile apps and desktop apps,
[00:57:14.320 --> 00:57:19.120]   and that's stuff new just in the February release. That's what's so cool about Bitwarden.
[00:57:19.120 --> 00:57:23.680]   It's open source, so it gets updated with the latest technologies quickly. In fact,
[00:57:23.680 --> 00:57:28.000]   that's how Argon2 happened. One of our security now listeners, Quxton,
[00:57:28.000 --> 00:57:33.680]   wrote an Argon2 implementation issue to pull requests. Bitwarden accepted it, implemented it,
[00:57:33.680 --> 00:57:38.880]   and it was out months later, and everybody can use it. That's the geeky part.
[00:57:39.840 --> 00:57:45.280]   But for Stacey's parents, all you need to know is it works. It's safe. It's easy to use.
[00:57:45.280 --> 00:57:50.000]   It's great for businesses, too. We're setting it up for our business right now. You could share
[00:57:50.000 --> 00:57:54.400]   private data securely with coworkers across departments of the entire company,
[00:57:54.400 --> 00:57:59.920]   with fully customizable and adaptive plans. There's the Bitwarden Teams organization option,
[00:57:59.920 --> 00:58:05.600]   $3 a month per user. For bigger businesses, the enterprise organization planned $5 a month
[00:58:05.600 --> 00:58:12.480]   per user. It allows things like secure sharing of data across departments and passwords.
[00:58:12.480 --> 00:58:15.840]   But of course, and this is really the most important thing to tell everybody,
[00:58:15.840 --> 00:58:21.760]   family and friends, individuals can use the basic free account for an unlimited number of
[00:58:21.760 --> 00:58:27.280]   passwords on any platform for as long as they want free forever. You might want to look at
[00:58:27.280 --> 00:58:32.240]   upgrading to the premium account. That's what I did $10 a year, less than a buck a month.
[00:58:32.240 --> 00:58:36.480]   And now I can use my Yuba key. It adds two factor, which makes it even more secure,
[00:58:36.480 --> 00:58:40.720]   makes me feel really good about it. Or if you've got a family, you can bring them all into the
[00:58:40.720 --> 00:58:47.840]   premium plan for just $3 and 33 cents a month, up to six people. Look, you got to have a password
[00:58:47.840 --> 00:58:52.560]   manager. That's the bottom line. That's the most important thing. Bitwarden, and everybody else says
[00:58:52.560 --> 00:58:56.480]   you got to have a password manager. But I would say if you're going to choose one, choose the only
[00:58:56.480 --> 00:59:02.160]   open source cross platform password manager that could be used at home on the go, or at
[00:59:02.160 --> 00:59:07.280]   work is trusted by millions of individuals, teams and organizations worldwide. Get started with a
[00:59:07.280 --> 00:59:12.400]   free trial of teams or enterprise or get started for free across all devices free as an individual
[00:59:12.400 --> 00:59:22.640]   user at bitwarden.com/twit. bitwarden.com/twit. You owe it to yourself. By the way, I also have
[00:59:22.640 --> 00:59:28.400]   the emergency access feature bitwarden set so that if something happens to me, my wife or my
[00:59:28.400 --> 00:59:34.480]   family members can get access to my account if and only if I don't respond to them. I have this
[00:59:34.480 --> 00:59:38.720]   little dead man switch after a few weeks, but they can. That's really important too. I think
[00:59:38.720 --> 00:59:44.000]   that's a very nice feature. Because I paid the $10 a month, I can now use my UBICI. I just got the
[00:59:44.000 --> 00:59:50.160]   new bio UBICI which uses a fingerprint. So I've got this is really security. This is great.
[00:59:50.160 --> 00:59:56.880]   Use it with bitwarden. bitwarden.com/twit. We thank them so much for their support. They're doing
[00:59:56.880 --> 01:00:03.520]   great work. Really good stuff. Did you talk, mom and dad into? Yeah, thank you. Did you talk
[01:00:03.520 --> 01:00:10.400]   your folks into it? Stacey. Oh, she ran away. Oh, there she is. Did you talk your folks into it?
[01:00:10.400 --> 01:00:15.920]   Was it they came to it on their own? They came to it on their own. That's nice. I'm glad to hear
[01:00:15.920 --> 01:00:22.480]   it. Yeah, they are so hip. That's very well. My dad, I mean, my dad does embedded electronics in my
[01:00:22.480 --> 01:00:28.720]   mom's a former geophysicist. Oh, geez, Louise. Oh, man. Oh, Molly. They're legitimately
[01:00:28.720 --> 01:00:34.560]   intelligently intelligent. So, but yeah, they might they'll be worried about something or I'll
[01:00:34.560 --> 01:00:43.040]   say something. My mom's like, I think bitwarden was all that for you. Oh, I love that. Oh, I love
[01:00:43.040 --> 01:00:49.040]   that. Now, that's what I like. Do your parents use any smart home stuff? Oh, no, no. My mom is
[01:00:50.480 --> 01:00:58.720]   very anti surveillance and very anti like it took it took forever to get my mom to use Google Maps.
[01:00:58.720 --> 01:01:04.320]   Okay. She used to print out map quest maps and bring them in the car. And finally, I was just like,
[01:01:04.320 --> 01:01:12.240]   that is okay for you, but for me, not going to fly. Is me a migraine mom, stop it. So, yeah,
[01:01:12.240 --> 01:01:17.440]   well, she won't like what I'm going to use on this next trip. I'm using a website slash app
[01:01:17.440 --> 01:01:24.080]   that's going to track my every move as I travel around and then put it on a map for people to see.
[01:01:24.080 --> 01:01:33.200]   Probably wouldn't wouldn't want to do that. Yeah. That's not her jam, but you go, but you do.
[01:01:33.200 --> 01:01:37.520]   I like this. Look, I've been doing it for years. I've been to 42 countries. Every continent,
[01:01:37.520 --> 01:01:42.240]   but Antarctica, these are the flags I've collected. But this is the thing that's kind of mind-blowing.
[01:01:42.240 --> 01:01:48.400]   This, by the way, only has the last 10 years of trips. I have been on vacation almost a full
[01:01:48.400 --> 01:01:58.400]   year, 264 days. And you've only taken 229 steps. Yeah. Yeah. I've traveled 35,000 miles and
[01:01:58.400 --> 01:02:05.680]   239 steps. That's amazing. Isn't it? Isn't that remarkable? Far this place from home is Yemen.
[01:02:06.640 --> 01:02:12.400]   And I haven't traveled for 79 days, but my next trip is just around the corner. Very excited.
[01:02:12.400 --> 01:02:18.160]   So, yeah, if you wanted to follow me, Polar Steps or me and Lisa, polarsteps.com/loports.
[01:02:18.160 --> 01:02:24.320]   And we post pictures. This is cool. I see how it puts little dots and all the places we've been
[01:02:24.320 --> 01:02:29.440]   in the pictures from those places is kind of cool. I like how Google Maps does that for me.
[01:02:29.440 --> 01:02:33.360]   Yeah. Google Maps does the same thing, but this is a little prettier. And you know,
[01:02:33.360 --> 01:02:37.840]   what's nice is free because what they want you to do is make books, right? So you can make travel
[01:02:37.840 --> 01:02:44.800]   books. But that's fine. I mean, they never forced me to. But I like the idea that I could do that,
[01:02:44.800 --> 01:02:49.120]   right? And they kind of set it all up ahead of time. Haven't you made a couple? Have you made
[01:02:49.120 --> 01:02:54.560]   travel books? I have. I have. I have, yeah. Some of the best, like, especially if you have young
[01:02:54.560 --> 01:03:00.080]   children, we all went to like Disneyland or something. It was Disneyland. And we made travel books that
[01:03:00.080 --> 01:03:05.280]   year for the whole family. And we won Christmas that year. It's a great idea. Yeah. Yeah. And
[01:03:05.280 --> 01:03:10.400]   people always forget it. I don't know why, but they make this as easy as possible because that's
[01:03:10.400 --> 01:03:15.760]   their revenue model, right? So because you as you go, your pictures are being added and you could
[01:03:15.760 --> 01:03:19.440]   pick which pictures you want and they've been added. So you're kind of making the book as you go.
[01:03:19.440 --> 01:03:24.080]   And then look, it's generating from our trip to Mexico last year with the Elkins.
[01:03:24.800 --> 01:03:30.080]   It's generating an album for Gastronomad Oaxaca. Let's see. See how it goes here.
[01:03:30.080 --> 01:03:38.720]   With GPT or Chad GPT, you could actually have it build a story underneath each. I could have it.
[01:03:38.720 --> 01:03:43.280]   Oh, wouldn't that be good? Wouldn't that be good? It might be creative.
[01:03:43.280 --> 01:03:52.080]   Yeah. And then the LaPorts took a giant flying goat to visit the Mezcal ceremony.
[01:03:54.080 --> 01:03:59.840]   This is kind of cool. I didn't do anything. It just did it. Just while we were talking,
[01:03:59.840 --> 01:04:03.120]   because I've never done this, you know what? They're smart. I'm not going to order this.
[01:04:03.120 --> 01:04:10.720]   I wonder how much. Let's just see. Premium, semi-mac, 46 euros. That's not too bad
[01:04:10.720 --> 01:04:16.800]   for a nice coffee table size book. Well, I went, wait, don't buy it yet. Go through it and make sure
[01:04:16.800 --> 01:04:22.160]   all those pictures are edit. Oh, yeah. And if you're going to leave it around your home,
[01:04:22.640 --> 01:04:31.200]   yeah, Lisa, look at it. Yeah, probably a good idea. Yeah. Yeah. That's cool. All right. Now,
[01:04:31.200 --> 01:04:40.240]   let's talk about libraries. According to Mike Masnick, big book publishers do not like libraries.
[01:04:40.240 --> 01:04:46.640]   He says, if libraries were invented today, they would do everything in their power to kill them.
[01:04:47.280 --> 01:04:54.960]   But of course, they exist. So they claim to love libraries. But meanwhile, in front of the Supreme
[01:04:54.960 --> 01:05:00.560]   Court, and I'm, in this case, worries me, the publishers going after, and this clues has
[01:05:00.560 --> 01:05:04.480]   shed, Simon and Schuster, all the big publishers going after the internet archives,
[01:05:04.480 --> 01:05:09.360]   because, and we talked about when Brewster Cale did this at the beginning of COVID,
[01:05:09.360 --> 01:05:14.160]   they had a lending library where they would do, they would, libraries would lend them a book,
[01:05:15.040 --> 01:05:20.480]   a physical book, or people would give them a book, and then we would lend it out.
[01:05:20.480 --> 01:05:24.720]   Well, they would scan it, and then they would lend out the digital, but they would do the same
[01:05:24.720 --> 01:05:31.440]   thing libraries do, which is one book, one ebook, one customer. They wouldn't lend out a thousand
[01:05:31.440 --> 01:05:36.000]   copies of the same book, that kind of thing, except when COVID happened, Brewster said, no,
[01:05:36.000 --> 01:05:39.840]   no, no, we're going to people need books right now. So we're going to eliminate those rules.
[01:05:39.840 --> 01:05:45.840]   And that's when the publishers sued the thing they claim is a violation of copyright is something
[01:05:45.840 --> 01:05:55.520]   called CDL or controlled digital lending. And I was, I was actually kind of surprised because we,
[01:05:55.520 --> 01:06:03.520]   on Sundays, we had Stephen Levy, and we had Cantrowitz, both of whom Stephen's written many,
[01:06:03.520 --> 01:06:11.840]   many books. Cantrowitz's most recent book is always day one about Amazon. And both of them said,
[01:06:11.840 --> 01:06:15.680]   yeah, and digging him more and more. I know I love him. I'm good. I love him.
[01:06:15.680 --> 01:06:20.880]   But both of them said, yeah, socket to him publishers.
[01:06:20.880 --> 01:06:29.520]   Jeff, you're a published author. Really? Yes. Oh, I was surprised. Yeah, because my interests
[01:06:29.520 --> 01:06:34.160]   and the publishers are not the same. When, you know, when somebody sat down and said,
[01:06:34.160 --> 01:06:38.080]   you should write a book driver, he said, he said, don't do it because you think you're going to be
[01:06:38.080 --> 01:06:40.720]   famous. Don't do it to make money in the book. You do it because you're going to get the gigs.
[01:06:40.720 --> 01:06:47.200]   Yeah. So next book. Yeah, well, it's all of that. And so the more attention, it's an attention
[01:06:47.200 --> 01:06:52.480]   economy, more attention to my book gets the happier I am. I loved that people just read it.
[01:06:52.480 --> 01:06:56.240]   And then you get, you get gigs and you get articles and you get ex-urpose and other things.
[01:06:56.240 --> 01:07:01.600]   Yeah. But if you're a publisher, you don't like that. And probably if you're a big guy like Levy,
[01:07:01.600 --> 01:07:13.200]   you don't like that. Maybe. Mike says, as much as publishers like to claim they love libraries,
[01:07:13.200 --> 01:07:19.440]   their actions here, and we don't, it wasn't clear from the oral arguments on Monday, what was,
[01:07:19.440 --> 01:07:22.880]   you know, what's going to happen. We'll have to wait until the Supreme Court rules.
[01:07:22.880 --> 01:07:27.040]   Their actions here speak quite clearly that they would destroy them if they could.
[01:07:27.040 --> 01:07:31.760]   Controlled digital lending is no different from how a library lends out books today. In both cases,
[01:07:31.760 --> 01:07:36.560]   it gets a physical copy of the book, either through purchase or donation proceeds to lend out that
[01:07:36.560 --> 01:07:41.760]   copy with the physical copy. It's literally that physical copy with CDL. It's a scan of the book,
[01:07:41.760 --> 01:07:46.880]   but the scans tied to the physical copy. Just as I said, you know, one book, one lender.
[01:07:46.880 --> 01:07:52.480]   Every part of that has been deemed legal. Copyright law already has first sale rights written directly
[01:07:52.480 --> 01:07:56.960]   into the law and left of the lending and reselling of copyright covered books without a license
[01:07:56.960 --> 01:08:02.960]   permission. If I buy Jeff's fabulous new book about Gutenberg, B.I.T. not in June,
[01:08:02.960 --> 01:08:07.760]   available for preorder now. B.I.T. You stepped on. I was going to give them the URL, dude.
[01:08:07.760 --> 01:08:15.280]   The I.T.LY/BYGootenberg. If you bought that and I read it and I said, this is great Stacy,
[01:08:15.280 --> 01:08:22.320]   you got to read this and I gave her my copy that's legal, right? Yes. She's ought to be.
[01:08:22.320 --> 01:08:28.320]   And then if she gives it somebody else, that's also legal. Pass it along.
[01:08:28.320 --> 01:08:37.760]   The publishers and some authors, including apparently Stephen Leeville with Lee V,
[01:08:37.760 --> 01:08:43.680]   argue that one, this interferes with the market for licensed ebooks and two, there's a real
[01:08:43.680 --> 01:08:48.720]   difference in lending out the digital scans. They don't deteriorate the way the physical books do.
[01:08:48.720 --> 01:08:54.000]   So I guess that's a bit of a stretch. They feel like, oh, we're protected because if Stacy then
[01:08:54.000 --> 01:08:57.680]   lends it out and somebody else lends it, eventually that's going to wear out. Steve, how long has
[01:08:57.680 --> 01:09:02.160]   Gutenberg's Bible been around? Yeah. Well, okay. Well, yeah, but that's like behind glass and,
[01:09:02.160 --> 01:09:06.480]   you know, but there is a point, I would say, not just physical deterioration, but there is a
[01:09:06.480 --> 01:09:11.760]   friction element that is notable. It's very easy to lend an ebook, isn't it? Yeah. So,
[01:09:13.440 --> 01:09:20.560]   I mean, I don't really feel for them because, yeah, this is because I love libraries and this is
[01:09:20.560 --> 01:09:25.920]   money grab and they do get money. I mean, a library is cost for, correct me if I'm wrong here, but
[01:09:25.920 --> 01:09:33.040]   a library pays more for a book, like even a physical book than a normal person would in a library
[01:09:33.040 --> 01:09:40.160]   also pays more for an ebook license. And they're still only lending out one ebook per, like,
[01:09:40.160 --> 01:09:46.480]   they might buy six licenses, but that means six people one time can read it. So, it's not changing
[01:09:46.480 --> 01:09:51.840]   the nature of libraries, but what happened is people are using more ebooks because they,
[01:09:51.840 --> 01:09:59.600]   Libby is the reason, we'll be honest. Libby, Libby made it so easy to check out and use ebooks that
[01:09:59.600 --> 01:10:04.240]   people are doing it when before to do an ebook and load it onto your Kindle or whatever ebook,
[01:10:04.240 --> 01:10:12.000]   your Kobo. It was hard. And now it's like an app and it takes 20 seconds. Everyone I show this to
[01:10:12.000 --> 01:10:18.480]   is just like, what? Are you kidding me? And then they, they, they, they read books forever on
[01:10:18.480 --> 01:10:23.920]   e, Libby, and maybe they don't buy them. So, I think that's what's changed here is getting access to
[01:10:23.920 --> 01:10:28.960]   these is so much easier. I apologize. It's not the Supreme Court. It's a federal district.
[01:10:28.960 --> 01:10:33.040]   Yeah, I don't know. It's a federal district. Yeah. I thought it was a Supreme Court for some
[01:10:33.040 --> 01:10:37.520]   beheaded for the Supreme Court probably, but well, yeah, because the publishers are not going to rest.
[01:10:37.520 --> 01:10:46.480]   The lawyer for the Internet Archive said there's no evidence publishers have lost a dime in this.
[01:10:46.480 --> 01:10:53.680]   The judge, federal judge John Quetta Cotal during oral arguments,
[01:10:53.680 --> 01:11:00.560]   tough questioning of both attorneys suggested resolving this matter as a less straightforward
[01:11:00.560 --> 01:11:05.760]   task than either side has so far indicated. Cotal pointed out that because publishers have a right
[01:11:05.760 --> 01:11:10.800]   to control the reproduction of their books, the heart of the case was figuring out whether Internet
[01:11:10.800 --> 01:11:16.400]   Archives book scanning violates copyrights by reproducing an already licensed physical book and
[01:11:16.400 --> 01:11:21.520]   then lending it without paying more licensed fees to the publishers. It's like the argument against
[01:11:21.520 --> 01:11:27.680]   DVRs for a long time was that the mere act of it passing through the recording of the DVR was a
[01:11:27.680 --> 01:11:31.840]   duplication and thus violated copyright. That didn't last. Well, well, what
[01:11:31.840 --> 01:11:36.800]   books did not kill print books, print books have been going up during the pandemic,
[01:11:36.800 --> 01:11:43.280]   book sales went up, but publishers are okay. And by the way, it's a it's a oligopoly of a few
[01:11:43.280 --> 01:11:46.240]   publishers. Yeah, it's just a it's like three.
[01:11:46.240 --> 01:11:52.560]   And full of publishers, all the big ones though, that's the thing.
[01:11:54.480 --> 01:11:58.640]   All right, well, we'll watch with interest. I suspect it will as you say, I suspect it's not
[01:11:58.640 --> 01:12:02.560]   over. We probably will go to the Supreme Court. So this may go on for years, but it is worrisome.
[01:12:02.560 --> 01:12:09.360]   Yeah, and I put this in the the chat. Is this the chat the IRC, the story about protocol to
[01:12:09.360 --> 01:12:13.280]   destroy all about this last year that was really good. And like it talks about like,
[01:12:13.280 --> 01:12:21.520]   and I'm sure the number is risen tremendously. But overdrive hit just under 200 million checkouts
[01:12:21.520 --> 01:12:28.960]   in 2016, but in 2020, they surpassed 430 million. And I bet if you look at it now, I mean, I
[01:12:28.960 --> 01:12:37.680]   I'll be real. I check out probably 200 books a year on my library. I would never physically buy
[01:12:37.680 --> 01:12:42.960]   that many, but I do check them out. And I still buy books. I mean, I probably but I only buy like
[01:12:42.960 --> 01:12:48.240]   20 books a year, maybe 30 books. People who go to the library and borrow books also are among the
[01:12:48.240 --> 01:12:54.320]   biggest spenders on physical books. Yeah, no one else is buying 20 physical or even ebooks a year.
[01:12:54.320 --> 01:13:00.880]   I promise you that. Right. So you're kind of you're cutting off your nose despite your face. By the
[01:13:00.880 --> 01:13:07.040]   way, let's point out this protocol article, which is excellent, Anna Kramer, Anna's probably out of
[01:13:07.040 --> 01:13:13.520]   work because protocols another website that was shut down by its owners, Politico, and everybody else
[01:13:13.520 --> 01:13:18.640]   cast to the four wins. Well, the other thing that happened was I'm trying to find it now. It's in
[01:13:18.640 --> 01:13:24.160]   the good breath. This is out in June. I quote a study about about that. Is that the full title
[01:13:24.160 --> 01:13:28.640]   now the Gutenberg breath is out in June? Yeah, yeah. Pre-orders available now.
[01:13:28.640 --> 01:13:36.560]   And we'll change the title. Is that Google scanning a books, which was of course was going to be
[01:13:36.560 --> 01:13:42.960]   the last thing publishers went crazy on. Increased demand and all kinds of books and publishers
[01:13:42.960 --> 01:13:50.400]   love their backlist and this pushes the backlist people. Long tail. Yep. How do you get a long tail
[01:13:50.400 --> 01:13:56.480]   without publicity? The publisher for my internet book is is basic a shot. And they say, Oh, we love
[01:13:56.480 --> 01:14:00.320]   the backlist. We want the backlist. Well, then you got to have the book exposed out there in all
[01:14:00.320 --> 01:14:06.480]   kinds of ways. We covered this story on security now all about Android course covered in great depth
[01:14:06.480 --> 01:14:15.440]   last night. Project zero, the Google security project found 18 count them zero day vulnerabilities
[01:14:15.440 --> 01:14:21.200]   in Samsung's Exynos chip sets, which are widely used in modern phones, including
[01:14:21.200 --> 01:14:34.640]   sorry, the Pixel six and seven. Yeah. Several of these are so serious that if somebody knows your
[01:14:34.640 --> 01:14:41.440]   phone number, your phone could be hacked. That's all they would need. It's in the in the baseband
[01:14:41.440 --> 01:14:47.440]   software, the Samsung baseband modem. It has been patched in the six and seven. So that's one of
[01:14:47.440 --> 01:14:54.320]   the reasons why you absolutely have to get your latest updates. The March 5th pixel update patches
[01:14:54.320 --> 01:15:04.800]   it. But it also affects Samsung phones, the S 22, the M 33 1312, A 71 53 33, A 21 A 13,
[01:15:04.800 --> 01:15:10.240]   A 12 and A 04. These are the A series are less expensive phones owned by a lot of people who do
[01:15:10.240 --> 01:15:14.880]   not listen to this show and who probably will never know that their phone is insecure and who may not
[01:15:14.880 --> 01:15:22.640]   be doing updates. The fools see what they miss always update always update. We live in a society
[01:15:22.640 --> 01:15:29.360]   where you I mean, if you want to wait a day, I mean, sure, there are a lot of things that won't be
[01:15:29.360 --> 01:15:36.480]   updated because the Exynos is also used in automobiles and who updates their auto. You know,
[01:15:36.480 --> 01:15:43.440]   any vehicles that use the Exynos auto T 51 23 chipset are also vulnerable. There is a fact,
[01:15:43.440 --> 01:15:51.680]   a fix and a workaround. Not all of these devices will be patched or can be patched, however.
[01:15:52.560 --> 01:15:59.840]   Uh, if you have a device that isn't patchable and can't be patched, Samsung says disable Wi-Fi
[01:15:59.840 --> 01:16:05.440]   calling and Volte voice over LTE calling to mitigate the impact of this vulnerability.
[01:16:05.440 --> 01:16:11.040]   That means you can't actually use the phone to call people. No, you can, but you won't be using
[01:16:11.040 --> 01:16:19.200]   these modern voice over data technologies. Volte, Volte was my understanding. The phone doesn't
[01:16:19.200 --> 01:16:23.760]   work anymore because that's all it will use. Maybe you're right. Well, I think it was an alternative
[01:16:23.760 --> 01:16:28.400]   like to the old like for Verizon, for example, the old CD main network, that's all shut down. So,
[01:16:28.400 --> 01:16:36.720]   if you're not using. Now, I could be wrong because I, but I really think Volte was the way to get
[01:16:36.720 --> 01:16:47.120]   voice over. I'll see. It's not good. As somebody in our discord says, this is revolting. Yeah.
[01:16:47.120 --> 01:16:51.040]   So if that's true, they're basically telling you turn this off and turn that off. But really,
[01:16:51.040 --> 01:16:54.800]   they're just saying, don't use your phone for voice calls, which some people will have no problem.
[01:16:54.800 --> 01:16:59.840]   But your parents won't. Thank you, Galia, for that bad joke.
[01:16:59.840 --> 01:17:06.720]   If you have the March 2023 update, you are protected against all four internet to baseband
[01:17:06.720 --> 01:17:12.080]   remote code, executeable vulnerabilities. But it's one of those vulnerabilities that
[01:17:12.080 --> 01:17:18.480]   Steve Gibson pointed out. State actors love because they can get into your phone without your knowledge,
[01:17:18.480 --> 01:17:23.440]   without your cooperation. If they know your phone number. I mean, they probably developed it.
[01:17:23.440 --> 01:17:32.480]   Yeah, could be. Yeah, could be. I love this mastodon thread from San Francisco's King
[01:17:32.480 --> 01:17:37.280]   Kaufman. Did you know King? He produces a Chronicle podcast, but he's been around
[01:17:37.920 --> 01:17:44.320]   the press circles for a long time. And I think he kind of is a kindred spirit, Mr. Jarvis.
[01:17:44.320 --> 01:17:47.360]   Oh, he doesn't like dark mode? No.
[01:17:47.360 --> 01:17:53.760]   She complains about having multiple Google accounts. He says, did Elon Musk buy Google
[01:17:53.760 --> 01:17:58.800]   my personal email address, which runs through Gmail stopped working today? And when I checked on
[01:17:58.800 --> 01:18:05.760]   Google, I was informed my 14 day free trial of Google workspace, which I have never heard of
[01:18:05.760 --> 01:18:11.040]   and hadn't signed up for had expired. What the F I did some searching around and figured out,
[01:18:11.040 --> 01:18:15.120]   okay, I have to subscribe to this thing that's been free for years. We've been warning people.
[01:18:15.120 --> 01:18:19.200]   King obviously doesn't listen to show, but we've been warning that another fool,
[01:18:19.200 --> 01:18:25.440]   another fool, those free Google workspace for your email accounts, because you're just a small person
[01:18:25.440 --> 01:18:30.720]   have gone away. He says it's going to, you know, okay, I'm going to subscribe. It's going to take a
[01:18:30.720 --> 01:18:38.160]   while. This is Elmo level chaos, to which somebody responded. And the reason I'm bringing this up,
[01:18:38.160 --> 01:18:46.320]   there is still a free if I use G Suite's legacy free edition for personal use, there is
[01:18:46.320 --> 01:18:54.480]   a way to continue using your custom domain with Gmail at no cost. And you need to go to this
[01:18:54.480 --> 01:19:03.760]   support page, answer 60217 at support.google.com. But a word of warning, the no cost personal
[01:19:03.760 --> 01:19:10.080]   use option is not available for organizations in Russia and Belarus. So,
[01:19:10.080 --> 01:19:18.560]   I was afraid he was the king of Belarus. Anyway, yeah, we talked about it when it happened,
[01:19:18.560 --> 01:19:21.920]   but it's still biting people still biting people. Indeed.
[01:19:21.920 --> 01:19:28.880]   And yeah, it will continue to bite. I mean, that's, I mean, it happens to all of us, right?
[01:19:28.880 --> 01:19:32.480]   It's just not in our ballot, Bailey Wick. And suddenly we look up and we're like, this doesn't
[01:19:32.480 --> 01:19:35.840]   work anymore. And then you complain about it. And everyone's like, wait, you didn't see the 18
[01:19:35.840 --> 01:19:40.800]   million news releases about this or whatever. Did I tell you about my stove in Chicago in my
[01:19:40.800 --> 01:19:46.240]   first department, your stove? I stole my moved in. And one day I decided to make popcorn.
[01:19:46.240 --> 01:19:51.440]   And it wouldn't work. Because that comes in the land. I got all the gas company. And I said,
[01:19:51.440 --> 01:19:56.000]   the stove doesn't work. Yeah, it should work. Yeah. They said, well, you got to get it hooked up,
[01:19:56.000 --> 01:20:02.400]   Mr. Jarvis. Yeah, you got to pay for the gas. Yeah. Oh, I said, what are you 12?
[01:20:02.400 --> 01:20:08.000]   It's a bunch of the apartment. Yeah. Oh, you'd been living there for six months before you used
[01:20:08.000 --> 01:20:14.240]   the stove? Yeah, I tried to make popcorn. Yeah. Something historically people make in the microwave.
[01:20:14.240 --> 01:20:19.920]   And that was the reason you decided to use. I love this. Well, you know what? I think I'm so
[01:20:19.920 --> 01:20:22.480]   old. We didn't have microwaves then. Stasing.
[01:20:22.480 --> 01:20:28.160]   Boy. Did you did you have a jiffy pup can with a little? I think I did.
[01:20:28.160 --> 01:20:33.200]   A little jiffy pop. I remember those. I was a disaster in the kitchen.
[01:20:33.200 --> 01:20:38.320]   Reed Hoffman has immediately written a book using chat.
[01:20:38.320 --> 01:20:42.160]   For. It's called impromptu P you.
[01:20:42.160 --> 01:20:49.440]   Wait a minute. Why? Wait a minute. No, I'm sorry. It's just impromptu.
[01:20:49.440 --> 01:20:52.320]   It looks like impromptu P you, but it's just impromptu.
[01:20:52.320 --> 01:21:00.560]   Here it is. Amplifying our humanity through a I by Reed Hoffman. Who's Reed Hoffman, Jeff Jarvis?
[01:21:00.560 --> 01:21:09.280]   Reed Hoffman is a founder of the LinkedIn and part of the PayPal mafia. And I think it contributed
[01:21:09.280 --> 01:21:14.800]   to funded by engagement journals and program. And I believe I may be wrong, but I think he was
[01:21:14.800 --> 01:21:19.200]   one of the original founders of OpenAI. Well, that's another story on there is that he just
[01:21:19.200 --> 01:21:23.520]   I left the board of OpenAI. He's going to invest in a lot of companies going to come out of it.
[01:21:23.520 --> 01:21:25.280]   Yeah, that's must still a part of it. No,
[01:21:25.280 --> 01:21:30.640]   he left it because OpenAI said we're going to make money. And he said, you aren't supposed
[01:21:30.640 --> 01:21:40.320]   to make any money. It's my job. Ada Lovelace, as imagined by chat GPT for the analytical engine
[01:21:40.320 --> 01:21:46.080]   weaves algebraic patterns like the loom weaves, flowers and leaves artificial intelligence can
[01:21:46.080 --> 01:21:51.600]   embroider this fabric of logic with the colors of imagination and creativity.
[01:21:51.600 --> 01:21:59.520]   Or as the Buddha never said, artificial intelligence is not a separate entity from us,
[01:21:59.520 --> 01:22:06.160]   but a reflection of our own mind by cultivating it with skillful means and ethical values.
[01:22:06.160 --> 01:22:12.720]   We can enhance our own enlightenment and benefit all beings. That's pretty good.
[01:22:12.720 --> 01:22:19.360]   As a chapter on journalism, is there? And what is what is the AI say about journalism?
[01:22:19.360 --> 01:22:28.000]   I didn't get that far. I will crush you. I mean, the sub-titler, this is amplifying our humanity
[01:22:28.000 --> 01:22:34.800]   through AI. So I think you would expect an AI to say it does. It will want us to worry.
[01:22:34.800 --> 01:22:39.360]   For the American journalism industry, it's been 20 years of mostly bad news.
[01:22:40.000 --> 01:22:45.040]   Why, Jeff, you could have written this with the rise of the internet competition for ad dollars
[01:22:45.040 --> 01:22:50.400]   from non news players has destroyed the industry's traditional business models,
[01:22:50.400 --> 01:22:56.800]   even as participation from a public that finally empowered to talk back has slowly eroded journalism's
[01:22:56.800 --> 01:23:03.600]   authority still with a run on sentences. I got to say, but okay, newspaper, but you know,
[01:23:03.600 --> 01:23:09.520]   so are plenty of academic books. Newspaper publishers dash dash, at least it uses an M dash.
[01:23:10.160 --> 01:23:13.840]   Which have traditionally done the heavy lifting of holding remote,
[01:23:13.840 --> 01:23:18.160]   holding power accountable and forming the public about current affairs have suffered the worst of it.
[01:23:18.160 --> 01:23:23.040]   According to the Pew Research Center, don't bother to look this up. More than 2,200 local
[01:23:23.040 --> 01:23:27.680]   US papers have closed since 2005. Is this readers? Is this the AI?
[01:23:27.680 --> 01:23:28.400]   Well, how do we know?
[01:23:28.400 --> 01:23:31.120]   Below us has read. Does it say AI?
[01:23:31.120 --> 01:23:35.120]   Hold on. Scroll down. Scroll.
[01:23:35.120 --> 01:23:38.800]   Oh, so somebody else wrote this and then read does this.
[01:23:38.800 --> 01:23:42.960]   Literally read. That read has a. Oh, that's funny because I thought the AI wrote this
[01:23:42.960 --> 01:23:45.440]   lastly run on sentence and no, a human did. Okay.
[01:23:45.440 --> 01:23:55.840]   For the record says read, I fact check the reply. It appears to be correct. That's one.
[01:23:55.840 --> 01:24:00.560]   I don't know. I don't even want to care about reading this.
[01:24:01.120 --> 01:24:05.520]   Yeah, me either. Let's go. Let's thank you for digging us.
[01:24:05.520 --> 01:24:10.400]   It's it's what you can summarize for a chat. Jeff Jarvis.
[01:24:10.400 --> 01:24:16.080]   All right. What am I summarizing for you? That piece of crap you made us download.
[01:24:16.080 --> 01:24:20.320]   The book? Yeah. I haven't read it yet. I just put it in there.
[01:24:20.320 --> 01:24:24.000]   Happy to. You got all of it out of it. You wanted.
[01:24:24.000 --> 01:24:26.560]   I got everything I wanted out of it and much more.
[01:24:26.560 --> 01:24:30.320]   Exactly. Exactly. Happy stochastic parrots day.
[01:24:30.960 --> 01:24:35.680]   Are these the. Yes. There is Tim. Tim Nick.
[01:24:35.680 --> 01:24:38.320]   Gebruh. Tim B. Margaret Schmitchell.
[01:24:38.320 --> 01:24:40.880]   The chol. Which one's Emily Bell? This Emily Bell here.
[01:24:40.880 --> 01:24:42.720]   The Bells of the lower right. There's Emily Bell.
[01:24:42.720 --> 01:24:46.080]   That's Margaret Schmitchell. And the fifth Beatles of the upper left.
[01:24:46.080 --> 01:24:47.200]   And Angie.
[01:24:47.200 --> 01:24:51.040]   Mere more. Yeah, I'm forgetting so to a small read.
[01:24:51.040 --> 01:24:53.280]   Yeah. It was quite amazing. I was four hours.
[01:24:53.280 --> 01:24:55.440]   And they just chatted.
[01:24:55.440 --> 01:25:02.720]   Different panels. No, four different panels. This was looking back on the stochastic parrots
[01:25:02.720 --> 01:25:09.840]   and how it happened and all that. And then there was one with a unnamed data cleaner
[01:25:09.840 --> 01:25:12.880]   from Africa, from a country in Africa. This is actually great.
[01:25:12.880 --> 01:25:20.560]   This is all. It's phenomenal. There's also mystery AI hype theater 3K in which they
[01:25:21.280 --> 01:25:27.920]   respond to chat GPT responses. This is where Emily Bender is just brilliant.
[01:25:27.920 --> 01:25:32.560]   This is all at the Twitch account. Dare Institute.
[01:25:32.560 --> 01:25:35.520]   DAIR_GABREW.
[01:25:35.520 --> 01:25:37.120]   Start as Tim Neat. I learned.
[01:25:37.120 --> 01:25:37.920]   Oh, Tim Neat.
[01:25:37.920 --> 01:25:38.640]   Hey, Drew.
[01:25:38.640 --> 01:25:39.360]   Hey, hey.
[01:25:39.360 --> 01:25:40.000]   Oh, okay.
[01:25:40.000 --> 01:25:41.840]   Started after leaving Google.
[01:25:41.840 --> 01:25:47.040]   Now, unfortunately, and the main name may not know this,
[01:25:47.040 --> 01:25:51.840]   but Twitch does not automatically save what you do. Or when it does, it only saves it for a couple
[01:25:51.840 --> 01:25:59.760]   of weeks. Oh, and it looks like the only thing remaining of this is these 30 second clips.
[01:25:59.760 --> 01:26:01.200]   Oh, no, no, no, no.
[01:26:01.200 --> 01:26:08.160]   This is a real problem with Twitch. Unless they put it on YouTube, which you can't do.
[01:26:08.160 --> 01:26:10.560]   But for right now,
[01:26:10.560 --> 01:26:11.840]   You can click on that video tab.
[01:26:11.840 --> 01:26:13.760]   Let's see what's in the videos. Oh, no.
[01:26:14.400 --> 01:26:16.400]   Is it the whole thing? Oh, hell.
[01:26:16.400 --> 01:26:17.120]   It's gross to the right.
[01:26:17.120 --> 01:26:20.960]   It is. It's 28 seconds, 28 seconds, 30 seconds, 26 seconds.
[01:26:20.960 --> 01:26:22.800]   Looks like a lot of clips.
[01:26:22.800 --> 01:26:28.240]   We're fortunate because Benito used to work at Twitch, so he knows how it works.
[01:26:28.240 --> 01:26:31.840]   But Benito, am I wrong? But I don't see any.
[01:26:31.840 --> 01:26:34.080]   Oh, yeah. This looks like this was curated by people.
[01:26:34.080 --> 01:26:35.120]   This is the clip.
[01:26:35.120 --> 01:26:35.280]   This is the clip.
[01:26:35.280 --> 01:26:36.960]   This is the clip I know because when I've,
[01:26:36.960 --> 01:26:40.880]   I only know this because when I play, you know, do a play along with Twitch,
[01:26:41.520 --> 01:26:45.840]   I have to remember to save it and put it somewhere because otherwise it just doesn't
[01:26:45.840 --> 01:26:47.120]   automatically get archived.
[01:26:47.120 --> 01:26:50.000]   Yeah. So, oh, hell. It was just brilliant.
[01:26:50.000 --> 01:26:52.880]   I presume it was the whole thing because that's why I put it on the other one.
[01:26:52.880 --> 01:26:54.960]   Let's let's go look at YouTube and see.
[01:26:54.960 --> 01:27:00.400]   We'll do some forensics, some digging right now and see if the Air Institute
[01:27:00.400 --> 01:27:02.800]   lives on YouTube, which it should.
[01:27:02.800 --> 01:27:08.720]   Well, given who owns YouTube, maybe not.
[01:27:08.720 --> 01:27:09.760]   That's what I'm thinking.
[01:27:09.760 --> 01:27:10.160]   Yeah.
[01:27:11.040 --> 01:27:12.640]   Yeah.
[01:27:12.640 --> 01:27:16.720]   She does have some, no, she does have some videos here,
[01:27:16.720 --> 01:27:21.280]   but it doesn't look like anything from that.
[01:27:21.280 --> 01:27:25.120]   Somebody asked him to meet on like,
[01:27:25.120 --> 01:27:27.520]   did one of the videos available? There's no answer to it.
[01:27:27.520 --> 01:27:31.680]   Yeah. I think they didn't know or didn't want it to be saved, but I bet they did.
[01:27:31.680 --> 01:27:33.760]   I took notes all that.
[01:27:33.760 --> 01:27:39.760]   So it's just going to have to join your Black Twitter symposium in the ether.
[01:27:40.240 --> 01:27:42.000]   That only you know about it, Jeff.
[01:27:42.000 --> 01:27:46.080]   So whatever, would you could just just go to a hypnotist and dictate it or something and
[01:27:46.080 --> 01:27:49.360]   is it here? It's all in here.
[01:27:49.360 --> 01:27:50.880]   It's all up there upstairs.
[01:27:50.880 --> 01:28:01.280]   Oh, so the guy who made the viral Trump videos has now been banned.
[01:28:01.280 --> 01:28:03.440]   He thinks from mid journey.
[01:28:03.440 --> 01:28:08.880]   These are the, uh, this is, this is, this is, this is the founder of Bellingcat,
[01:28:08.880 --> 01:28:11.280]   who of course does nothing but fact check the rest of the world.
[01:28:11.280 --> 01:28:11.840]   He's great.
[01:28:11.840 --> 01:28:12.800]   He decided to go make something.
[01:28:12.800 --> 01:28:13.280]   Oh, yeah.
[01:28:13.280 --> 01:28:14.240]   He's wonderful.
[01:28:14.240 --> 01:28:14.560]   Yeah.
[01:28:14.560 --> 01:28:17.280]   Makes something to fake and thinks he got banned as a result.
[01:28:17.280 --> 01:28:22.080]   So then that kind of answers your question about section 230 and AI.
[01:28:22.080 --> 01:28:24.240]   It's, it's the people who are going to make.
[01:28:24.240 --> 01:28:25.920]   It's the prompter that's the problem.
[01:28:25.920 --> 01:28:30.720]   Wow. That's, uh, that's kind of a shame.
[01:28:30.720 --> 01:28:33.280]   He's still on Twitter though.
[01:28:33.280 --> 01:28:35.440]   You pretty have to work pretty hard to get banned on Twitter.
[01:28:35.440 --> 01:28:36.640]   Oh, yeah.
[01:28:36.640 --> 01:28:36.960]   Yeah.
[01:28:37.760 --> 01:28:38.480]   I don't think so.
[01:28:38.480 --> 01:28:41.040]   I think if you just disagreed enough time with Elon Musk, you would.
[01:28:41.040 --> 01:28:41.600]   Oh, yeah.
[01:28:41.600 --> 01:28:42.080]   Yeah.
[01:28:42.080 --> 01:28:42.480]   Yeah.
[01:28:42.480 --> 01:28:42.960]   Right.
[01:28:42.960 --> 01:28:43.680]   Touche.
[01:28:43.680 --> 01:28:44.000]   Yeah.
[01:28:44.000 --> 01:28:47.920]   Here's the Washington Post story.
[01:28:47.920 --> 01:28:53.200]   Fake images of Trump arrest show giant step for AI's disruptive power.
[01:28:53.200 --> 01:28:57.840]   Might be a little biased.
[01:28:57.840 --> 01:29:02.720]   It might be just a little, notice though that they do not reprint the pictures.
[01:29:02.720 --> 01:29:07.200]   There's, you can't get in trouble for those pictures, right?
[01:29:07.200 --> 01:29:08.160]   Oh, that's crazy.
[01:29:08.160 --> 01:29:11.840]   Yeah, but I wouldn't, I mean, because, so I feel like as an editor,
[01:29:11.840 --> 01:29:20.560]   I would say, is it responsible for us to publish something that could be repurposed as factual based on the fact that it did appear in the Washington Post?
[01:29:20.560 --> 01:29:23.280]   Because you could divorce it from any captioning.
[01:29:23.280 --> 01:29:25.200]   So I understand the reason.
[01:29:25.200 --> 01:29:26.800]   Like, they don't want to serve them.
[01:29:26.800 --> 01:29:27.760]   Yeah.
[01:29:27.760 --> 01:29:28.800]   I wouldn't do it either.
[01:29:28.800 --> 01:29:29.200]   Yeah.
[01:29:29.200 --> 01:29:34.480]   Unless I could like water market really, obviously somehow, we might see that more often.
[01:29:36.240 --> 01:29:37.520]   We don't have this in your journal.
[01:29:37.520 --> 01:29:38.000]   Some classes.
[01:29:38.000 --> 01:29:41.280]   Some cheesy, um, paintings of Trump.
[01:29:41.280 --> 01:29:43.840]   Yeah.
[01:29:43.840 --> 01:29:44.960]   I think people can tell us.
[01:29:44.960 --> 01:29:44.960]   Yeah.
[01:29:44.960 --> 01:29:47.120]   But that's, that's truly fake.
[01:29:47.120 --> 01:29:51.200]   I mean, that's, I just, I'm like, how would you as a,
[01:29:51.200 --> 01:29:53.600]   no, that's really a good point.
[01:29:53.600 --> 01:29:53.840]   Yeah.
[01:29:53.840 --> 01:29:55.680]   That's a really good point.
[01:29:55.680 --> 01:29:59.360]   Water, I would water.
[01:29:59.360 --> 01:30:03.040]   If I had to do it, I would water market like it up big way.
[01:30:03.040 --> 01:30:03.840]   Fake, fake, fake.
[01:30:05.120 --> 01:30:10.160]   I have to say though, that if you follow the Twitter thread, he's got a lot of interesting
[01:30:10.160 --> 01:30:10.560]   images.
[01:30:10.560 --> 01:30:16.320]   Here's a Donald Trump in an orange prison jumpsuit running away from a burning mansion at night in
[01:30:16.320 --> 01:30:16.880]   the rain.
[01:30:16.880 --> 01:30:21.440]   Here is Donald Trump getting pepper sprayed.
[01:30:21.440 --> 01:30:23.200]   Actually, that confused it.
[01:30:23.200 --> 01:30:26.320]   It does not clear what's going on.
[01:30:26.320 --> 01:30:26.480]   Yeah.
[01:30:26.480 --> 01:30:28.240]   I just don't know who's spraying whom.
[01:30:28.240 --> 01:30:29.440]   Here.
[01:30:29.440 --> 01:30:34.080]   He said this is the prompt here was Donald Trump wearing an orange prison suit carving a
[01:30:34.080 --> 01:30:35.120]   key out of soap.
[01:30:35.120 --> 01:30:40.240]   And it looks like it's Donald Trump carved out of soap, which frankly is kind of cool.
[01:30:40.240 --> 01:30:42.000]   Here's the original images.
[01:30:42.000 --> 01:30:47.680]   And mid journey did ban the word arrested as a result of it as well.
[01:30:47.680 --> 01:30:49.920]   I don't only banned him, but banned the word arrested.
[01:30:49.920 --> 01:30:53.440]   Oh, so we can't get a picture of you being arrested for robbing that bank earlier.
[01:30:53.440 --> 01:30:54.640]   Oh, yeah.
[01:30:54.640 --> 01:30:55.040]   Wait a minute.
[01:30:55.040 --> 01:30:59.920]   I'll tell you what, let me just, let me go in here and just issue that.
[01:30:59.920 --> 01:31:02.720]   Pepper promised one is fascinating.
[01:31:02.720 --> 01:31:06.000]   Yeah, well, it looks like a beer foam or milk or something.
[01:31:06.000 --> 01:31:08.960]   You know, if you Google pepper spray, a lot of things are going to come up saying,
[01:31:08.960 --> 01:31:11.200]   like if you get pepper sprayed, you get it out of your eyes.
[01:31:11.200 --> 01:31:11.600]   Yeah.
[01:31:11.600 --> 01:31:12.560]   Oh,
[01:31:12.560 --> 01:31:14.560]   maybe that's what's happening.
[01:31:14.560 --> 01:31:16.000]   Let's see.
[01:31:16.000 --> 01:31:26.080]   Imagine Leo LaPorte being arrested after his unsuccessful.
[01:31:26.080 --> 01:31:28.400]   I want to make sure that you understand it was unsuccessful.
[01:31:28.400 --> 01:31:29.760]   Bank heist.
[01:31:29.760 --> 01:31:36.240]   Let's see if it, if it says the word arrested is banned.
[01:31:36.240 --> 01:31:39.440]   But there's Jeff Jarvis being arrested.
[01:31:39.440 --> 01:31:41.440]   Yeah, I love the I bars.
[01:31:41.440 --> 01:31:41.840]   Really?
[01:31:41.840 --> 01:31:43.520]   You're, you're okay.
[01:31:43.520 --> 01:31:45.360]   That's Patrick Delahani.
[01:31:45.360 --> 01:31:46.400]   Well, that's interesting.
[01:31:46.400 --> 01:31:47.920]   I'm nervous locking up.
[01:31:47.920 --> 01:31:50.080]   I guess I could say behind bars, right?
[01:31:50.080 --> 01:31:51.920]   I could say behind bars.
[01:31:51.920 --> 01:31:53.920]   Also do so try Donald Trump behind bars.
[01:31:53.920 --> 01:31:55.680]   What did they do?
[01:31:55.680 --> 01:31:56.960]   They'll try to get me in trouble.
[01:31:56.960 --> 01:31:57.840]   Yes.
[01:31:59.520 --> 01:32:03.440]   How about we do Joe Biden behind bars just for.
[01:32:03.440 --> 01:32:05.200]   Just for.
[01:32:05.200 --> 01:32:07.440]   Oh, it shook its head.
[01:32:07.440 --> 01:32:08.640]   No, wait, that was the wrong thing.
[01:32:08.640 --> 01:32:09.680]   I charged the wrong.
[01:32:09.680 --> 01:32:10.240]   I promise.
[01:32:10.240 --> 01:32:10.560]   Hold on.
[01:32:10.560 --> 01:32:13.040]   You could purge.
[01:32:13.040 --> 01:32:14.640]   Purge images.
[01:32:14.640 --> 01:32:15.520]   No, come on.
[01:32:15.520 --> 01:32:16.800]   I'm trying to say stop.
[01:32:16.800 --> 01:32:17.200]   Stop.
[01:32:17.200 --> 01:32:18.960]   Imagine.
[01:32:18.960 --> 01:32:20.480]   Right.
[01:32:20.480 --> 01:32:21.120]   Imagine.
[01:32:21.120 --> 01:32:24.080]   Joe Biden.
[01:32:24.080 --> 01:32:27.120]   In an orange.
[01:32:28.400 --> 01:32:29.280]   Jump.
[01:32:29.280 --> 01:32:29.760]   Suit.
[01:32:29.760 --> 01:32:32.400]   Behind bars.
[01:32:32.400 --> 01:32:34.000]   I'm just doing this for fairness.
[01:32:34.000 --> 01:32:36.240]   Both sidesism.
[01:32:36.240 --> 01:32:37.760]   Oh, behind bars is banned.
[01:32:37.760 --> 01:32:40.240]   Oh, interesting.
[01:32:40.240 --> 01:32:42.800]   So they really don't want you to do this stuff.
[01:32:42.800 --> 01:32:46.400]   They're a little sensitive to the whole thing.
[01:32:46.400 --> 01:32:49.520]   That's not going to help them though.
[01:32:49.520 --> 01:32:51.760]   I mean, if you think about how people get around it,
[01:32:51.760 --> 01:32:54.320]   it's will they come up with new term?
[01:32:54.320 --> 01:32:56.000]   Well, if you want to create.
[01:32:57.520 --> 01:33:00.480]   There's going to be so many ridiculous things we can make fun of of people.
[01:33:00.480 --> 01:33:03.200]   And so many egos will be upset.
[01:33:03.200 --> 01:33:05.440]   It'll be interesting to see like, I mean, can we?
[01:33:05.440 --> 01:33:06.160]   Why can't we see?
[01:33:06.160 --> 01:33:07.200]   You can't ban all of them.
[01:33:07.200 --> 01:33:08.160]   Just wearing heels.
[01:33:08.160 --> 01:33:09.920]   Yeah, you can't ban everything, right?
[01:33:09.920 --> 01:33:11.280]   Yeah.
[01:33:11.280 --> 01:33:12.880]   Oh, apparently apprehended.
[01:33:12.880 --> 01:33:16.320]   Every just is still.
[01:33:16.320 --> 01:33:21.520]   We're just going to get every every synonym for arrested or arrested in effect.
[01:33:21.520 --> 01:33:22.560]   Leo Laport.
[01:33:22.560 --> 01:33:26.000]   Being apprehended.
[01:33:26.960 --> 01:33:28.000]   Held by police.
[01:33:28.000 --> 01:33:29.840]   Is it really wrong to.
[01:33:29.840 --> 01:33:30.800]   I know.
[01:33:30.800 --> 01:33:32.960]   I hate that they're blocking arrested as a term.
[01:33:32.960 --> 01:33:33.600]   I don't like that.
[01:33:33.600 --> 01:33:33.920]   Yeah.
[01:33:33.920 --> 01:33:34.400]   Pretty weird.
[01:33:34.400 --> 01:33:34.560]   Okay.
[01:33:34.560 --> 01:33:40.720]   Especially for me is unsuccessful.
[01:33:40.720 --> 01:33:42.640]   Attempt.
[01:33:42.640 --> 01:33:44.320]   Nashed potato in the discord.
[01:33:44.320 --> 01:33:45.280]   It's a good point.
[01:33:45.280 --> 01:33:47.600]   What about shackled or incarcerated?
[01:33:47.600 --> 01:33:49.360]   Are those blocked?
[01:33:49.360 --> 01:33:52.720]   Well, they're allowing me to be apprehended and held by police.
[01:33:52.720 --> 01:33:53.840]   So that's the good news.
[01:33:53.840 --> 01:33:55.760]   Just right.
[01:33:56.800 --> 01:33:57.440]   Right.
[01:33:57.440 --> 01:33:59.040]   Donald Trump perp walk.
[01:33:59.040 --> 01:34:00.560]   See if it knows what a perp walk is.
[01:34:00.560 --> 01:34:06.560]   I don't know what's going on.
[01:34:06.560 --> 01:34:08.320]   I've lost the hells that.
[01:34:08.320 --> 01:34:09.280]   Well, it takes a while.
[01:34:09.280 --> 01:34:10.640]   It starts with a blurry image.
[01:34:10.640 --> 01:34:10.960]   Oh, right.
[01:34:10.960 --> 01:34:11.600]   Oh, look.
[01:34:11.600 --> 01:34:13.600]   It looks like they're going to they nab me.
[01:34:13.600 --> 01:34:15.040]   Looks like I am.
[01:34:15.040 --> 01:34:17.040]   Oh, that's Jeff Jarvis police officer.
[01:34:17.040 --> 01:34:21.680]   Oh, no, no, that's what it was like across.
[01:34:21.680 --> 01:34:22.400]   That's really a little hard.
[01:34:22.400 --> 01:34:22.800]   Yeah.
[01:34:22.800 --> 01:34:24.400]   It looks like you generally be.
[01:34:24.720 --> 01:34:25.200]   Yeah.
[01:34:25.200 --> 01:34:29.840]   Yeah, that's like if you and I.
[01:34:29.840 --> 01:34:31.520]   Little bit of Mike Elgin.
[01:34:31.520 --> 01:34:32.960]   Yeah, had a baby.
[01:34:32.960 --> 01:34:34.560]   Here I oh now see they got it.
[01:34:34.560 --> 01:34:35.840]   Here I am being arrested.
[01:34:35.840 --> 01:34:37.760]   And I'm not happy about it.
[01:34:37.760 --> 01:34:38.560]   It is sweater vest.
[01:34:38.560 --> 01:34:39.680]   Or is it a.
[01:34:39.680 --> 01:34:41.920]   In his car.
[01:34:41.920 --> 01:34:44.880]   I always like the images of Leo Laporte midjourney does.
[01:34:44.880 --> 01:34:46.320]   Because I'm pleasingly plump.
[01:34:46.320 --> 01:34:48.560]   Those are real guys.
[01:34:48.560 --> 01:34:48.880]   Yeah.
[01:34:48.880 --> 01:34:51.600]   This is I think what is it?
[01:34:51.600 --> 01:34:54.000]   What is it when I have a I have the safe there?
[01:34:54.000 --> 01:34:54.720]   What is that there?
[01:34:54.720 --> 01:34:55.840]   I'm carrying away something.
[01:34:55.840 --> 01:34:57.920]   This is good.
[01:34:57.920 --> 01:34:59.360]   You are not a happy camera.
[01:34:59.360 --> 01:35:00.320]   This is good.
[01:35:00.320 --> 01:35:00.960]   This is good.
[01:35:00.960 --> 01:35:01.360]   Which one.
[01:35:01.360 --> 01:35:02.400]   Which one.
[01:35:02.400 --> 01:35:05.120]   The lower right one looks like you've been on the lamb for 10 years.
[01:35:05.120 --> 01:35:05.600]   And okay.
[01:35:05.600 --> 01:35:06.400]   Yeah.
[01:35:06.400 --> 01:35:08.000]   And they put me in a bulletproof vest
[01:35:08.000 --> 01:35:11.440]   so that I wouldn't get shot by the ongoing the onlookers.
[01:35:11.440 --> 01:35:13.440]   But you're doing right.
[01:35:13.440 --> 01:35:14.720]   You and your britches.
[01:35:14.720 --> 01:35:15.680]   Me and my britches.
[01:35:15.680 --> 01:35:18.880]   Yeah, you I've never seen you with with.
[01:35:18.880 --> 01:35:21.360]   Mom James.
[01:35:21.360 --> 01:35:21.600]   Yeah.
[01:35:22.160 --> 01:35:23.040]   Mom James.
[01:35:23.040 --> 01:35:23.920]   I've never seen you with that.
[01:35:23.920 --> 01:35:28.240]   I actually I did not own a pair of fake beats.
[01:35:28.240 --> 01:35:31.840]   Upper left.
[01:35:31.840 --> 01:35:34.000]   We have a vote for upper left.
[01:35:34.000 --> 01:35:35.760]   I love Bicky Jellerby laugh.
[01:35:35.760 --> 01:35:36.000]   Yeah.
[01:35:36.000 --> 01:35:38.160]   Jellerby really enjoys this show.
[01:35:38.160 --> 01:35:38.800]   There I am.
[01:35:38.800 --> 01:35:42.960]   Being arrested after my unsuccessful bank heist.
[01:35:42.960 --> 01:35:44.160]   Attached.
[01:35:44.160 --> 01:35:46.160]   All right.
[01:35:46.160 --> 01:35:47.040]   Try a perp walk.
[01:35:47.040 --> 01:35:48.000]   What is he a perp walk?
[01:35:48.000 --> 01:35:48.800]   Oh, come on.
[01:35:48.800 --> 01:35:50.640]   Oh, come on y'all.
[01:35:51.840 --> 01:35:53.040]   There's waffles away.
[01:35:53.040 --> 01:35:54.240]   TikTok.
[01:35:54.240 --> 01:35:55.280]   We have other talk.
[01:35:55.280 --> 01:35:56.320]   Yes, we dig us.
[01:35:56.320 --> 01:35:56.800]   We have Diggas.
[01:35:56.800 --> 01:35:59.200]   CEO is going to TikTok.
[01:35:59.200 --> 01:36:00.160]   Chief executive.
[01:36:00.160 --> 01:36:06.400]   Show Ji Ju is going to be testifying on Capitol Hill tomorrow.
[01:36:06.400 --> 01:36:08.560]   He is hired a.
[01:36:08.560 --> 01:36:10.400]   We are told 11 influencers.
[01:36:10.400 --> 01:36:12.240]   Two.
[01:36:12.240 --> 01:36:17.120]   I think it's smart to to to you know lobby.
[01:36:17.120 --> 01:36:19.440]   Come to Congress and say don't shut me up, man.
[01:36:19.440 --> 01:36:20.320]   Don't shut me up.
[01:36:20.320 --> 01:36:26.480]   I mean, Henry my son started his career on TikTok.
[01:36:26.480 --> 01:36:27.840]   Ose's career to TikTok.
[01:36:27.840 --> 01:36:35.200]   Unfortunately, I have noted of late that there are a lot of people copying him.
[01:36:35.200 --> 01:36:36.240]   And this is one problem.
[01:36:36.240 --> 01:36:37.840]   But I guess this is the way it is, isn't it?
[01:36:37.840 --> 01:36:39.680]   That's all creative arts, sir.
[01:36:39.680 --> 01:36:40.240]   Yeah.
[01:36:40.240 --> 01:36:40.480]   Yeah.
[01:36:40.480 --> 01:36:41.520]   As you've said before,
[01:36:41.520 --> 01:36:43.280]   art isn't created in a vacuum.
[01:36:43.280 --> 01:36:43.440]   Yeah.
[01:36:43.440 --> 01:36:46.320]   So you can't own, you know, chopping, slicing,
[01:36:46.320 --> 01:36:48.160]   ticing as much as I wish you could.
[01:36:49.920 --> 01:36:53.840]   So Chu will be testifying in front of the,
[01:36:53.840 --> 01:36:57.280]   let's see what what committee is this.
[01:36:57.280 --> 01:37:00.320]   I don't know.
[01:37:00.320 --> 01:37:04.560]   He takes the stand for the first congressional hearing Thursday,
[01:37:04.560 --> 01:37:08.400]   40 year old native of Singapore, not Chinese.
[01:37:08.400 --> 01:37:11.360]   He's worked to counter American suspicions with hard logic,
[01:37:11.360 --> 01:37:12.720]   according to the Washington Post,
[01:37:12.720 --> 01:37:15.200]   telling members of Congress in one-on-one meetings,
[01:37:15.200 --> 01:37:17.680]   his company is unaffiliated with the Chinese government
[01:37:17.680 --> 01:37:22.160]   and is committed to building a sunny corner of the internet, his words.
[01:37:22.160 --> 01:37:23.040]   Yeah, which he's done.
[01:37:23.040 --> 01:37:25.200]   So it's house committee on energy and commerce.
[01:37:25.200 --> 01:37:26.320]   Okay.
[01:37:26.320 --> 01:37:27.280]   Review the data.
[01:37:27.280 --> 01:37:30.480]   CFIUS is probably under that committee, I would guess,
[01:37:30.480 --> 01:37:33.040]   the Committee for Foreign Influence in the United States.
[01:37:33.040 --> 01:37:36.240]   And that's who would ultimately, I think, be banning him.
[01:37:36.240 --> 01:37:39.840]   So he made a video on TikTok, obviously.
[01:37:39.840 --> 01:37:41.520]   You know, we don't hear from him, hardly.
[01:37:41.520 --> 01:37:41.840]   Yeah.
[01:37:43.280 --> 01:37:48.880]   TikTok is one of the App Stores, Apple App Stores, 10 most downloaded free apps in the US.
[01:37:48.880 --> 01:37:51.440]   Four of those 10, by the way, are owned by Chinese companies.
[01:37:51.440 --> 01:37:53.840]   Three of them above TikTok.
[01:37:53.840 --> 01:37:54.160]   Four.
[01:37:54.160 --> 01:37:58.800]   T-E-M-U, T-M-O, the Fast Fashion Titan, She-In,
[01:37:58.800 --> 01:38:02.800]   another ByteDance app, and the video editor CapCut.
[01:38:02.800 --> 01:38:05.680]   CapCut's owned by ByteDance as well.
[01:38:05.680 --> 01:38:06.240]   Adelable.
[01:38:06.240 --> 01:38:06.800]   Adelable.
[01:38:06.800 --> 01:38:08.480]   CFIUS is its own committee.
[01:38:08.480 --> 01:38:09.360]   It's not part of...
[01:38:09.360 --> 01:38:11.680]   It's not part of a house committee.
[01:38:11.680 --> 01:38:15.120]   But members of the house committee are on.
[01:38:15.120 --> 01:38:16.000]   Or on CFIUS.
[01:38:16.000 --> 01:38:16.560]   Or there, the...
[01:38:16.560 --> 01:38:17.680]   Yeah.
[01:38:17.680 --> 01:38:18.160]   Okay.
[01:38:18.160 --> 01:38:21.280]   But CFIUS is part of maybe under the Commerce Department, then maybe not.
[01:38:21.280 --> 01:38:21.920]   So TikTok now sends me those.
[01:38:21.920 --> 01:38:23.920]   It's under the US Department of the Treasury.
[01:38:23.920 --> 01:38:24.560]   Treasury.
[01:38:24.560 --> 01:38:25.440]   Ah, interesting.
[01:38:25.440 --> 01:38:25.840]   Yeah.
[01:38:25.840 --> 01:38:31.040]   So TikTok now sends it as 150 million users in the US, half of the US on TikTok.
[01:38:31.040 --> 01:38:32.160]   And who is this off?
[01:38:32.160 --> 01:38:32.400]   Who?
[01:38:32.400 --> 01:38:34.960]   Who hates TikTok more than anyone?
[01:38:34.960 --> 01:38:39.280]   Facebook, Instagram, the companies that were copying TikTok.
[01:38:39.280 --> 01:38:42.720]   For that, I wish they could capitalize the same way TikTok.
[01:38:42.720 --> 01:38:43.280]   Yeah, that's right.
[01:38:43.280 --> 01:38:43.760]   They want to...
[01:38:43.760 --> 01:38:46.320]   And by the way, the who are spying on you just as much,
[01:38:46.320 --> 01:38:49.280]   and selling that data on the data brokers,
[01:38:49.280 --> 01:38:53.120]   where the Chinese government, if it wants this information, can buy it.
[01:38:53.120 --> 01:38:55.360]   This is Carl Boads' point again and again,
[01:38:55.360 --> 01:38:57.600]   plus I'm on tech meme.
[01:38:57.600 --> 01:38:59.440]   This is all a distraction.
[01:38:59.440 --> 01:39:00.640]   Pass a privacy law.
[01:39:00.640 --> 01:39:00.800]   Yeah.
[01:39:00.800 --> 01:39:02.560]   Worry about privacy, then pass a privacy law.
[01:39:02.560 --> 01:39:03.200]   Yeah.
[01:39:03.200 --> 01:39:03.920]   By that, no.
[01:39:03.920 --> 01:39:05.520]   They don't want to do that.
[01:39:05.520 --> 01:39:08.400]   And one of the reasons they don't want to do that is because they also buy
[01:39:09.200 --> 01:39:13.680]   ads on Facebook and Instagram for their run and elections.
[01:39:13.680 --> 01:39:18.960]   Wait, so in Congress, well, this isn't Congress, this is in DC.
[01:39:18.960 --> 01:39:21.040]   The Consumer Financial Protection Bureau,
[01:39:21.040 --> 01:39:23.520]   this is what was created by Elizabeth Warren at all,
[01:39:23.520 --> 01:39:27.760]   they have actually begun an investigation into data brokers.
[01:39:27.760 --> 01:39:30.720]   So they did that, I think, last Wednesday?
[01:39:30.720 --> 01:39:31.280]   Good.
[01:39:31.280 --> 01:39:32.880]   Oh, it's about time.
[01:39:32.880 --> 01:39:33.520]   And that was...
[01:39:33.520 --> 01:39:34.880]   What did you look to?
[01:39:34.880 --> 01:39:36.800]   Let's see if Mark Warner would do.
[01:39:36.800 --> 01:39:37.360]   What did you look to?
[01:39:37.360 --> 01:39:38.880]   She asked the dog?
[01:39:38.880 --> 01:39:39.680]   She asked the dog.
[01:39:39.680 --> 01:39:40.560]   Who are you asking?
[01:39:40.560 --> 01:39:40.880]   Hey.
[01:39:40.880 --> 01:39:42.800]   You have a calendar with these things?
[01:39:42.800 --> 01:39:43.920]   What were you doing?
[01:39:43.920 --> 01:39:44.160]   What's...
[01:39:44.160 --> 01:39:44.960]   Oh, sorry.
[01:39:44.960 --> 01:39:48.880]   I have a calendar over there that says what day things are.
[01:39:48.880 --> 01:39:49.840]   Oh, okay.
[01:39:49.840 --> 01:39:51.440]   So I'm like the 15th.
[01:39:51.440 --> 01:39:52.240]   That was last Wednesday.
[01:39:52.240 --> 01:39:58.080]   She was like a brilliant AI device, combining information from a variety of sources
[01:39:58.080 --> 01:40:00.560]   to generate a coherent logic.
[01:40:00.560 --> 01:40:02.720]   I thought the dog was smart, was tell it or yes.
[01:40:02.720 --> 01:40:04.400]   Roof, Roof, Roof.
[01:40:04.400 --> 01:40:07.280]   Yeah, the dog has been barking at least 15 times.
[01:40:07.280 --> 01:40:08.480]   That's how I know.
[01:40:08.480 --> 01:40:11.760]   So, look, I understand people were very nervous about TikTok.
[01:40:11.760 --> 01:40:12.400]   I understand that.
[01:40:12.400 --> 01:40:14.560]   You should be nervous about wechat.
[01:40:14.560 --> 01:40:15.680]   I don't understand.
[01:40:15.680 --> 01:40:16.800]   We get a lot of crap.
[01:40:16.800 --> 01:40:20.240]   Well, I'll say I get a lot of crap for defending this whole...
[01:40:20.240 --> 01:40:20.880]   Oh, I do too.
[01:40:20.880 --> 01:40:21.600]   A lot of emails.
[01:40:21.600 --> 01:40:22.560]   How I think is being...
[01:40:22.560 --> 01:40:23.760]   You're trying to lover you.
[01:40:23.760 --> 01:40:25.440]   Yeah, it's got nothing...
[01:40:25.440 --> 01:40:28.560]   I think people just don't quite get it.
[01:40:28.560 --> 01:40:29.920]   I do.
[01:40:29.920 --> 01:40:34.000]   The news is sensationalizing this stuff and really just sort of
[01:40:34.000 --> 01:40:37.360]   driving it home that this is quote-unquote dangerous.
[01:40:37.360 --> 01:40:41.840]   Yet there's just as much weird surveillance and dangerous crap going on with stuff right
[01:40:41.840 --> 01:40:44.480]   here in our own backyard with US companies.
[01:40:44.480 --> 01:40:45.600]   Why don't we bring that up?
[01:40:45.600 --> 01:40:46.880]   There are...
[01:40:46.880 --> 01:40:48.560]   So, from a national...
[01:40:48.560 --> 01:40:51.120]   This is only because we have a national security concern.
[01:40:51.120 --> 01:40:57.280]   And the national security concern, the real concern here is that people who have
[01:40:57.280 --> 01:41:01.040]   public officials like a 5-S spy or the president of...
[01:41:01.040 --> 01:41:02.400]   Or I'm the treasury head.
[01:41:03.440 --> 01:41:08.240]   That if I have TikTok on my phone or maybe someone in my home has TikTok on their phone,
[01:41:08.240 --> 01:41:12.560]   they could perhaps there might be a backdoor in things like...
[01:41:12.560 --> 01:41:15.520]   And they are doing things like keystroke logging and popping pixels.
[01:41:15.520 --> 01:41:17.200]   Which yes, everyone else is doing.
[01:41:17.200 --> 01:41:19.440]   Everyone else is doing this exact thing.
[01:41:19.440 --> 01:41:20.320]   And even...
[01:41:20.320 --> 01:41:22.720]   Directly to the Chinese government is what they're worried about.
[01:41:22.720 --> 01:41:24.400]   And what's the Chinese government going to do with it?
[01:41:24.400 --> 01:41:25.360]   What's the harm?
[01:41:25.360 --> 01:41:26.800]   Nothing for the mainstream...
[01:41:26.800 --> 01:41:28.480]   Nothing for you and your eye.
[01:41:28.480 --> 01:41:31.440]   But if you're the department of treasury, you could...
[01:41:32.640 --> 01:41:33.520]   I don't know.
[01:41:33.520 --> 01:41:34.720]   You should have Facebook on your phone.
[01:41:34.720 --> 01:41:36.720]   So, if you're department of treasury,
[01:41:36.720 --> 01:41:39.840]   don't put these crappy apps on your phone.
[01:41:39.840 --> 01:41:40.800]   But what about your kid?
[01:41:40.800 --> 01:41:42.480]   But don't let them do it either.
[01:41:42.480 --> 01:41:44.800]   If you're not concerned about it, just...
[01:41:44.800 --> 01:41:51.040]   Everybody shouldn't have to suffer and lose any apps such as TikTok or Instagram or whatever,
[01:41:51.040 --> 01:41:56.880]   just because of the security concerns that our national leadership has.
[01:41:56.880 --> 01:42:00.320]   And as Mr. Reporter said in our Twitter forums,
[01:42:00.320 --> 01:42:03.040]   that's Twitter.community for those of you who don't know.
[01:42:03.040 --> 01:42:07.440]   He's mentioned a couple of times that the information that China wants,
[01:42:07.440 --> 01:42:10.640]   they can just go get it from a broker if they really wanted that bad.
[01:42:10.640 --> 01:42:13.360]   Yeah. And I'm channeling Carl Bodie, who I completely agree with.
[01:42:13.360 --> 01:42:16.800]   If you want privacy, "Oh, good, well, good!"
[01:42:16.800 --> 01:42:18.480]   Do something about it.
[01:42:18.480 --> 01:42:20.240]   Banning TikTok does nothing.
[01:42:20.240 --> 01:42:21.520]   Right. Exactly.
[01:42:21.520 --> 01:42:26.400]   Also this morning, I was screaming at the TV with Maury and Joe as I do most every morning.
[01:42:26.400 --> 01:42:27.520]   It's not just privacy though.
[01:42:27.520 --> 01:42:31.520]   It's like if they have a backdoor that could put something on your phone that could monitor things,
[01:42:31.520 --> 01:42:33.360]   that's more the concern.
[01:42:33.360 --> 01:42:37.920]   I mean, I know that they're saying privacy, but that's because they don't understand cyber security.
[01:42:37.920 --> 01:42:38.640]   Yeah.
[01:42:38.640 --> 01:42:45.600]   Ms. Stacey, is it possible that someone finds a backdoor in one of these beloved US apps
[01:42:45.600 --> 01:42:47.200]   that happens to be from China?
[01:42:47.200 --> 01:42:49.600]   Yeah, they totally could do that too.
[01:42:49.600 --> 01:42:54.720]   Well, we just mentioned four zero-day back doors in your Samsung and Pixel phones.
[01:42:54.720 --> 01:42:57.520]   Come, Pixel phones. You know what I'm saying?
[01:42:57.520 --> 01:42:59.520]   It's so let's ban Samsung.
[01:42:59.520 --> 01:43:02.240]   Thank you.
[01:43:02.240 --> 01:43:05.920]   Anyway, you know what?
[01:43:05.920 --> 01:43:07.920]   Honestly, I don't care if they ban TikTok.
[01:43:07.920 --> 01:43:16.800]   Do you think there will, that there is a risk of a political backlash that younger people will then
[01:43:16.800 --> 01:43:19.600]   say, "Well, I'm not voting for you, Mark Warner."
[01:43:19.600 --> 01:43:20.720]   Yeah. Oh, yeah. I agree.
[01:43:21.680 --> 01:43:24.720]   Yep. I'm sure young folks will be like, "Oh, they killed my TikTok.
[01:43:24.720 --> 01:43:26.400]   Nope. Won't get my vote."
[01:43:26.400 --> 01:43:27.440]   What's Hank going to feel?
[01:43:27.440 --> 01:43:31.360]   Would Hank sign a letter or protest into Congress about this?
[01:43:31.360 --> 01:43:33.920]   I don't know. I don't think it's not that political, but I asked him,
[01:43:33.920 --> 01:43:37.760]   a couple of months ago, I said, "TikTok may well be banned."
[01:43:37.760 --> 01:43:40.240]   He said, "Well, I've kind of moved over to Instagram and YouTube.
[01:43:40.240 --> 01:43:45.680]   He's smart enough, just as his pop was, not to be owned on a platform."
[01:43:45.680 --> 01:43:46.160]   I was.
[01:43:46.160 --> 01:43:46.480]   Right?
[01:43:46.480 --> 01:43:47.840]   Yeah, yeah.
[01:43:47.840 --> 01:43:48.800]   You're not smart enough.
[01:43:48.800 --> 01:43:52.320]   I'm not smart enough, boy. I give all my brain cells or hanks.
[01:43:52.320 --> 01:43:54.240]   I pass them down and that's it. I'm done.
[01:43:54.240 --> 01:43:59.360]   Put me on a porch with some checkers and a pickle barrel and I'm history, man.
[01:43:59.360 --> 01:43:59.920]   I'm just going to...
[01:43:59.920 --> 01:44:04.160]   You know, another thing about the Chinese government.
[01:44:04.160 --> 01:44:10.400]   So this morning and morning, Joe, they touted this story that's in there,
[01:44:10.400 --> 01:44:14.240]   that Jamal Bowen of New York is defending the app and saying that all this talk is fear
[01:44:14.240 --> 01:44:20.480]   mongering and xenophobia. Who do they have on the show? Not Jamal Bowen. They had on Brendan Carr,
[01:44:20.480 --> 01:44:25.360]   the moral panic leader of the FCC screaming about TikTok.
[01:44:25.360 --> 01:44:28.800]   Well, that's morning, Joe, in a nutshell. I can't believe you watched that because of that.
[01:44:28.800 --> 01:44:32.000]   Gotta get wake up and get my blood pressure.
[01:44:32.000 --> 01:44:32.800]   I honestly think...
[01:44:32.800 --> 01:44:34.320]   Yeah, it was like, Jeff needs his morning dose of money.
[01:44:34.320 --> 01:44:40.480]   I honestly think that the best thing Congress could do is ban 24-hour news channels.
[01:44:41.600 --> 01:44:46.160]   Yeah, we're in a mall and make people read a newspaper or something.
[01:44:46.160 --> 01:44:49.040]   But the 24-hour news channels are...
[01:44:49.040 --> 01:44:56.000]   I know you leave your entire generation leaves 24-hour news on all the time.
[01:44:56.000 --> 01:45:00.160]   And depending on your political bent, it's either Fox or MSNBC.
[01:45:00.160 --> 01:45:05.840]   And who shares the most misinformation in all studies? People over 65.
[01:45:05.840 --> 01:45:14.640]   Holds. If I have shared any misinformation with you all today, I apologize.
[01:45:14.640 --> 01:45:16.240]   I have corrected him. I'm old.
[01:45:16.240 --> 01:45:23.360]   She's like after I can't be expected. Thank God we have a young one like chat GPT.
[01:45:23.360 --> 01:45:30.480]   I can't be excited. I lose that standard. I'm an old man. Blackberry, are you excited about this
[01:45:30.480 --> 01:45:35.520]   movie? I cannot wait to see this movie. It looks a little over the top. Have you watched the trailer
[01:45:35.520 --> 01:45:40.320]   yet? You got to be over the top a little bit if you're going to get people to watch a movie.
[01:45:40.320 --> 01:45:42.480]   This is...
[01:45:42.480 --> 01:45:44.240]   It's about the blackberry.
[01:45:44.240 --> 01:45:45.360]   It's about the blackberry.
[01:45:45.360 --> 01:45:52.400]   These are the basil and what are the two founders? And then they got some guy in a suit.
[01:45:52.400 --> 01:46:00.320]   Look at the little headband is cute. So these are the two founders and they got some guy in a suit
[01:46:00.320 --> 01:46:01.040]   to give money.
[01:46:01.040 --> 01:46:03.360]   No, to come to the CEO.
[01:46:04.000 --> 01:46:07.520]   Yeah. Yeah. Yeah.
[01:46:07.520 --> 01:46:11.040]   Was that their meeting with Rogers up in Canada?
[01:46:11.040 --> 01:46:14.000]   I don't know who this guy in the suit is because I don't remember him.
[01:46:14.000 --> 01:46:18.720]   We can sell it too. But I want 50% of the company and I've got to be CEO.
[01:46:18.720 --> 01:46:22.240]   I don't know who you think you are. Oh, deal. Are you joking?
[01:46:22.240 --> 01:46:27.520]   Inspired by is the giveaway, right? If you see inspired by...
[01:46:27.520 --> 01:46:31.760]   But I will still go see this because there is a lot. I mean, there are some very good books about
[01:46:31.760 --> 01:46:34.800]   the rise and fall of a blackberry. But...
[01:46:34.800 --> 01:46:38.240]   And in fact, I think this is based on one of them.
[01:46:38.240 --> 01:46:41.360]   But I don't know how closely it huge. Maybe based on it.
[01:46:41.360 --> 01:46:43.440]   You're going to see a prototype here in a minute that's fun.
[01:46:43.440 --> 01:46:44.320]   Yeah. Yeah.
[01:46:44.320 --> 01:46:49.680]   I type in with your thumbs.
[01:46:49.680 --> 01:46:52.320]   But I have to point out and I don't know if it's clear in this...
[01:46:52.320 --> 01:46:57.200]   The first blackberry was not a phone. In fact, for many years, the blackberry was just a pager.
[01:46:57.200 --> 01:46:59.200]   And I...
[01:46:59.200 --> 01:46:59.840]   They know that.
[01:46:59.840 --> 01:47:04.560]   Yeah. The blackberry server in the messaging system was all about
[01:47:04.560 --> 01:47:10.720]   text for a long time. And I have to admit, I was absolutely addicted.
[01:47:10.720 --> 01:47:13.360]   I remember my kid saying, "Dad, put down the blackberry."
[01:47:13.360 --> 01:47:17.200]   It had... It was just a big old pager with a full keyboard.
[01:47:17.200 --> 01:47:18.080]   Who are you talking to?
[01:47:18.080 --> 01:47:19.600]   Everybody.
[01:47:19.600 --> 01:47:20.160]   Everybody.
[01:47:20.160 --> 01:47:26.160]   I remember interviewing at the time. This would have been 2003 or '04.
[01:47:28.720 --> 01:47:32.880]   Colin Powell's son, was it William Powell, the chairman of the FCC.
[01:47:32.880 --> 01:47:38.000]   And I noted at the time when I'm interviewing him, he is like on his blackberry all the time.
[01:47:38.000 --> 01:47:40.480]   I said, "What do you do with that?" He says, "I do email triage.
[01:47:40.480 --> 01:47:43.520]   When I get back to the office, I don't want any email that I don't have to look at.
[01:47:43.520 --> 01:47:46.720]   So what I do is I go through my email, delete, delete, delete, delete.
[01:47:46.720 --> 01:47:49.200]   And then I get home and I can actually answer it.
[01:47:49.200 --> 01:47:52.640]   It was like texting, but it was with email.
[01:47:52.640 --> 01:47:53.680]   Yeah.
[01:47:53.680 --> 01:47:56.880]   Yeah. I used to... When I got hired at Gigaton,
[01:47:57.760 --> 01:47:59.280]   they made me get one.
[01:47:59.280 --> 01:47:59.520]   Yeah.
[01:47:59.520 --> 01:48:02.800]   Because they were like, "You can't manage this job without a..."
[01:48:02.800 --> 01:48:04.400]   And it wasn't a phone, right?
[01:48:04.400 --> 01:48:06.320]   No, it was a phone by then.
[01:48:06.320 --> 01:48:07.360]   Oh, my God. It was a very pearl.
[01:48:07.360 --> 01:48:08.160]   She's just a kid.
[01:48:08.160 --> 01:48:08.560]   I'm old.
[01:48:08.560 --> 01:48:09.120]   The pearl.
[01:48:09.120 --> 01:48:11.360]   Oh, my God. That was my last blackberry later.
[01:48:11.360 --> 01:48:12.560]   Yeah. That was my last blackberry.
[01:48:12.560 --> 01:48:13.840]   I was like, "Ugh, this thing.
[01:48:13.840 --> 01:48:14.320]   I know it."
[01:48:14.320 --> 01:48:17.280]   I got the pearl and then the iPhone came out and that was it.
[01:48:17.280 --> 01:48:18.320]   Right.
[01:48:18.320 --> 01:48:20.000]   Because it was 2008.
[01:48:20.000 --> 01:48:20.480]   My trio.
[01:48:20.480 --> 01:48:21.520]   I had a storm.
[01:48:21.520 --> 01:48:23.920]   Oh, Lisa had a storm.
[01:48:23.920 --> 01:48:25.280]   I had a storm, actually.
[01:48:25.280 --> 01:48:26.240]   I made her get rid of it.
[01:48:26.240 --> 01:48:28.160]   Actually, I didn't have to make her get rid of it.
[01:48:28.160 --> 01:48:31.920]   She left it on the roof of the car and we drove off and it wasn't where it's not.
[01:48:31.920 --> 01:48:32.320]   Or maybe...
[01:48:32.320 --> 01:48:34.880]   It wasn't great.
[01:48:34.880 --> 01:48:36.960]   You click to click the screen.
[01:48:36.960 --> 01:48:37.200]   The screen.
[01:48:37.200 --> 01:48:38.560]   The whole screen went down.
[01:48:38.560 --> 01:48:39.600]   That's right.
[01:48:39.600 --> 01:48:42.320]   The whole screen was clickable.
[01:48:42.320 --> 01:48:46.640]   It was a weird trackpad on a phone to touch on.
[01:48:46.640 --> 01:48:47.760]   Actually, she's swimming now.
[01:48:47.760 --> 01:48:48.400]   I remember.
[01:48:48.400 --> 01:48:49.440]   I thought it would...
[01:48:49.440 --> 01:48:50.880]   She dropped it.
[01:48:50.880 --> 01:48:54.080]   We were on the way from the old cottage to the new brick house.
[01:48:54.080 --> 01:48:57.440]   And on the way, she dropped it and hit the cement and I was so grateful and we got her an iPhone.
[01:48:57.440 --> 01:48:58.240]   I was like, "Yes."
[01:48:58.240 --> 01:48:59.840]   That was the end of that.
[01:48:59.840 --> 01:49:01.200]   Lisa, are you still angry?
[01:49:01.200 --> 01:49:04.960]   She every once in a while, if she wants to zing me,
[01:49:04.960 --> 01:49:08.080]   she says, "You made me get a Mac.
[01:49:08.080 --> 01:49:09.360]   You made me get an iPhone."
[01:49:09.360 --> 01:49:10.320]   But...
[01:49:10.320 --> 01:49:12.320]   I mean, it doesn't really hurt.
[01:49:12.320 --> 01:49:15.200]   Because it's like, "What were you going to use a blackberry?
[01:49:15.200 --> 01:49:16.160]   Still, what were you going to use?"
[01:49:16.160 --> 01:49:18.480]   And blackberry was really good.
[01:49:18.480 --> 01:49:19.040]   It was great.
[01:49:19.040 --> 01:49:19.920]   It was time from...
[01:49:19.920 --> 01:49:20.720]   It was awesome.
[01:49:20.720 --> 01:49:20.960]   Yeah.
[01:49:20.960 --> 01:49:24.960]   Because you remember back then, carriers subsidized everyone.
[01:49:24.960 --> 01:49:29.840]   So if you wanted to buy it, because the only good smartphones were the Nokia's.
[01:49:29.840 --> 01:49:30.560]   There we go.
[01:49:30.560 --> 01:49:31.680]   That's the trio.
[01:49:31.680 --> 01:49:33.360]   Oh, no, that's a pearl right there.
[01:49:33.360 --> 01:49:34.960]   No, that's the trio.
[01:49:34.960 --> 01:49:36.400]   That's the trio's so nice.
[01:49:36.400 --> 01:49:37.200]   That's the trio's ever.
[01:49:37.200 --> 01:49:41.520]   I remember driving down, I wanted to look up where an in-and-out burger was.
[01:49:41.520 --> 01:49:45.120]   And we tried to find it on the web on a trio.
[01:49:45.120 --> 01:49:47.280]   That's a pump one, right?
[01:49:47.280 --> 01:49:48.640]   The palm drill, yeah.
[01:49:48.640 --> 01:49:49.360]   Oh my god.
[01:49:50.160 --> 01:49:54.640]   It was one of those moments where you could see the future.
[01:49:54.640 --> 01:49:57.280]   And you were just like, "We have to make this better."
[01:49:57.280 --> 01:49:58.880]   You could see everything possible.
[01:49:58.880 --> 01:50:00.800]   And you were like, "And this is why it sucks."
[01:50:00.800 --> 01:50:01.760]   You know?
[01:50:01.760 --> 01:50:04.320]   And then the iPhone came out and everything was good.
[01:50:04.320 --> 01:50:06.480]   And the rest is history.
[01:50:06.480 --> 01:50:11.120]   Actually, the iPhone came out and was subsidized by AT&T.
[01:50:11.120 --> 01:50:12.160]   I guess that's really the story.
[01:50:12.160 --> 01:50:14.720]   Because Nokia actually had a decent product.
[01:50:14.720 --> 01:50:17.120]   So...
[01:50:17.120 --> 01:50:17.920]   Okay.
[01:50:17.920 --> 01:50:18.400]   Okay.
[01:50:18.400 --> 01:50:21.680]   Are we done yet?
[01:50:21.680 --> 01:50:25.760]   We still have a change on this.
[01:50:25.760 --> 01:50:26.240]   That's what I'm trying to do.
[01:50:26.240 --> 01:50:29.120]   Leo, it's not you.
[01:50:29.120 --> 01:50:30.240]   It's I have a headache.
[01:50:30.240 --> 01:50:33.680]   So that's why I'm like, "Where are we today?"
[01:50:33.680 --> 01:50:36.560]   You know, I know what will cure it for you.
[01:50:36.560 --> 01:50:38.720]   A 3D printed cheesecake.
[01:50:38.720 --> 01:50:41.120]   Like cheesecake.
[01:50:41.120 --> 01:50:43.920]   What line might that be?
[01:50:43.920 --> 01:50:44.480]   Yeah, let's just...
[01:50:44.480 --> 01:50:45.680]   On say 86.
[01:50:46.400 --> 01:50:47.440]   [Laughs]
[01:50:47.440 --> 01:50:48.720]   I was getting there.
[01:50:48.720 --> 01:50:49.200]   It looks awful.
[01:50:49.200 --> 01:50:50.240]   It looks awful.
[01:50:50.240 --> 01:50:51.280]   I was getting there.
[01:50:51.280 --> 01:50:53.440]   86, "Have your cake and print it too?"
[01:50:53.440 --> 01:50:58.000]   The 3D culinary revolution is coming.
[01:50:58.000 --> 01:50:59.360]   No, it's not.
[01:50:59.360 --> 01:51:00.560]   Ew!
[01:51:00.560 --> 01:51:01.520]   Yeah, exactly.
[01:51:01.520 --> 01:51:03.760]   That looks like a problem.
[01:51:03.760 --> 01:51:04.640]   Isn't it?
[01:51:04.640 --> 01:51:09.440]   Engineering shows three Jetsons got wrong.
[01:51:09.440 --> 01:51:15.120]   Turning cartridges of paste and powder into cheesecake.
[01:51:15.600 --> 01:51:17.520]   Any cheese junk, whatever that is.
[01:51:17.520 --> 01:51:18.720]   That...
[01:51:18.720 --> 01:51:21.120]   [Laughs]
[01:51:21.120 --> 01:51:21.600]   Oh!
[01:51:21.600 --> 01:51:22.080]   It's like...
[01:51:22.080 --> 01:51:24.320]   That looks like spaghetti cake.
[01:51:24.320 --> 01:51:25.840]   Cuz you're a pick-pake cake.
[01:51:25.840 --> 01:51:26.320]   Ooh.
[01:51:26.320 --> 01:51:29.520]   It's like board-formed concrete with a tongue in the middle.
[01:51:29.520 --> 01:51:30.800]   And what is happening there?
[01:51:30.800 --> 01:51:34.080]   For those of you just listening, don't watch.
[01:51:34.080 --> 01:51:35.680]   You don't need to see this.
[01:51:35.680 --> 01:51:37.680]   That's a fail.
[01:51:37.680 --> 01:51:37.840]   You know what?
[01:51:37.840 --> 01:51:40.000]   Actually, that's terrible.
[01:51:40.000 --> 01:51:40.720]   It is, okay.
[01:51:40.720 --> 01:51:41.840]   Even the not-failed print.
[01:51:41.840 --> 01:51:43.120]   Is the top one a failed print?
[01:51:43.120 --> 01:51:44.400]   That's the final iteration.
[01:51:44.400 --> 01:51:45.440]   That's the top one.
[01:51:45.440 --> 01:51:46.240]   Yeah, it's awful.
[01:51:46.240 --> 01:51:46.960]   Thank goodness.
[01:51:46.960 --> 01:51:51.280]   Okay.
[01:51:51.280 --> 01:51:53.200]   Yeah, we don't want to know anyone about that.
[01:51:53.200 --> 01:51:56.320]   IKEA is using drones to do inventory in warehouses
[01:51:56.320 --> 01:51:57.680]   according to Jeff Jarvis.
[01:51:57.680 --> 01:52:00.320]   I almost took this one out because it's not that fascinating, but...
[01:52:00.320 --> 01:52:00.960]   No, it's not.
[01:52:00.960 --> 01:52:02.480]   Okay, then take it out.
[01:52:02.480 --> 01:52:05.200]   Is it RFID on a drone?
[01:52:05.200 --> 01:52:06.160]   It's just going through every-
[01:52:06.160 --> 01:52:07.920]   Those are out taking pictures of every shelf.
[01:52:07.920 --> 01:52:08.960]   I always take-
[01:52:08.960 --> 01:52:09.760]   Okay.
[01:52:09.760 --> 01:52:10.800]   That's a little better.
[01:52:10.800 --> 01:52:13.200]   They fly drones over like car lots and stuff.
[01:52:13.200 --> 01:52:15.200]   And it's RFID sensors.
[01:52:15.200 --> 01:52:16.640]   Well, that's interesting.
[01:52:16.640 --> 01:52:17.280]   So, here we go.
[01:52:17.280 --> 01:52:19.440]   Oh, remember Project JACARD?
[01:52:19.440 --> 01:52:24.240]   Google's attempt to build smart clothing?
[01:52:24.240 --> 01:52:26.640]   Oh, where did the change look?
[01:52:26.640 --> 01:52:27.520]   So, we're just-
[01:52:27.520 --> 01:52:28.560]   I'm skipping the change look.
[01:52:28.560 --> 01:52:29.600]   It's not a change look.
[01:52:29.600 --> 01:52:30.080]   It's not a change look.
[01:52:30.080 --> 01:52:30.400]   I'm just there.
[01:52:30.400 --> 01:52:31.840]   I'm taking the good stuff out,
[01:52:31.840 --> 01:52:33.920]   and I'm leaving the orchestra on the floor.
[01:52:33.920 --> 01:52:35.200]   He's speeding George Waffles.
[01:52:35.200 --> 01:52:37.360]   Stacy, he's feeling the speed towards Waffles.
[01:52:37.360 --> 01:52:37.920]   We don't have to.
[01:52:37.920 --> 01:52:38.960]   Project JACARD.
[01:52:39.600 --> 01:52:42.560]   That was the one they had a Levi's jacket, right?
[01:52:42.560 --> 01:52:46.160]   In the backpack and Adidas made some smart shoes.
[01:52:46.160 --> 01:52:47.440]   It was a dopey idea.
[01:52:47.440 --> 01:52:48.480]   I thought it was-
[01:52:48.480 --> 01:52:50.240]   Did we talk about it as dopey at the time?
[01:52:50.240 --> 01:52:51.680]   No, I thought it was cool.
[01:52:51.680 --> 01:52:54.480]   But I am wrong because I live in-
[01:52:54.480 --> 01:52:57.440]   Another ATAP gone.
[01:52:57.440 --> 01:52:58.560]   Gone.
[01:52:58.560 --> 01:53:01.680]   Yeah, the open sourced solely,
[01:53:01.680 --> 01:53:04.240]   and solely in JACARD were introduced at the same time.
[01:53:04.240 --> 01:53:05.200]   And both of them, I was like-
[01:53:05.200 --> 01:53:07.680]   "Sully was the gesture-based way to use-
[01:53:07.680 --> 01:53:09.840]   they made a phone that you could use solely on."
[01:53:09.840 --> 01:53:11.760]   Yeah, my Google thing uses "sully."
[01:53:11.760 --> 01:53:12.880]   My little Google-
[01:53:12.880 --> 01:53:13.920]   You can wait that.
[01:53:13.920 --> 01:53:14.240]   Yeah.
[01:53:14.240 --> 01:53:14.800]   Nest display.
[01:53:14.800 --> 01:53:14.960]   Nest display.
[01:53:14.960 --> 01:53:15.600]   Nest display.
[01:53:15.600 --> 01:53:16.080]   Oh, really?
[01:53:16.080 --> 01:53:17.840]   Yeah, they kept it around for stuff like that.
[01:53:17.840 --> 01:53:20.640]   That actually does sleep sensing too, right?
[01:53:20.640 --> 01:53:21.520]   Because of the "sully."
[01:53:21.520 --> 01:53:22.960]   Research-
[01:53:22.960 --> 01:53:24.080]   Maybe the thing is Stacy.
[01:53:24.080 --> 01:53:26.880]   I'm just putting a little side here.
[01:53:26.880 --> 01:53:28.480]   What happened to the suicidal, Robin?
[01:53:28.480 --> 01:53:30.640]   Oh, yeah.
[01:53:30.640 --> 01:53:32.880]   It attacked the windows downstairs for me,
[01:53:32.880 --> 01:53:34.000]   and then we put nets up,
[01:53:34.000 --> 01:53:35.200]   and so far it hasn't come back.
[01:53:35.200 --> 01:53:37.760]   But I can't undo my plastic yet,
[01:53:37.760 --> 01:53:39.520]   because I feel like it might come back.
[01:53:39.520 --> 01:53:40.080]   Okay.
[01:53:40.080 --> 01:53:40.400]   Thank you.
[01:53:40.400 --> 01:53:43.040]   Stacy had a bird that was buzz bombing her,
[01:53:43.040 --> 01:53:43.920]   dive bombing her,
[01:53:43.920 --> 01:53:46.880]   and to no effect,
[01:53:46.880 --> 01:53:48.160]   and driving her nuts,
[01:53:48.160 --> 01:53:49.600]   and so it's gone.
[01:53:49.600 --> 01:53:50.480]   Short drive.
[01:53:50.480 --> 01:53:50.880]   Sorry, Leo.
[01:53:50.880 --> 01:53:51.440]   I did want to-
[01:53:51.440 --> 01:53:52.560]   I just wanted to quickly-
[01:53:52.560 --> 01:53:53.520]   News.
[01:53:53.520 --> 01:53:55.280]   Hey, everybody.
[01:53:55.280 --> 01:53:56.160]   Leo LaPorte here.
[01:53:56.160 --> 01:54:01.200]   I am the founder and one of the hosts at the TWIT podcast network.
[01:54:01.200 --> 01:54:03.920]   I want to talk to you a little bit about what we do here at TWIT,
[01:54:03.920 --> 01:54:05.760]   because I think it's unique,
[01:54:05.760 --> 01:54:07.920]   and I think for anybody who is
[01:54:07.920 --> 01:54:13.520]   bringing a product or a service to a tech audience,
[01:54:13.520 --> 01:54:16.560]   you need to know about what we do here at TWIT.
[01:54:16.560 --> 01:54:19.440]   We've built an amazing audience of engaged,
[01:54:19.440 --> 01:54:21.760]   intelligent, affluent listeners
[01:54:21.760 --> 01:54:26.720]   who listen to us and trust us when we recommend a product.
[01:54:26.720 --> 01:54:31.440]   Our mission statement is to build a highly engaged community of tech enthusiasts.
[01:54:32.400 --> 01:54:34.800]   Already, your ears should be
[01:54:34.800 --> 01:54:35.520]   perking up at that,
[01:54:35.520 --> 01:54:38.480]   because highly engaged is good for you.
[01:54:38.480 --> 01:54:39.520]   Tech enthusiasts,
[01:54:39.520 --> 01:54:40.640]   if that's who you're looking for,
[01:54:40.640 --> 01:54:41.840]   this is the place.
[01:54:41.840 --> 01:54:44.400]   We do it by offering them the knowledge they need
[01:54:44.400 --> 01:54:47.280]   to understand and use technology in today's world.
[01:54:47.280 --> 01:54:49.680]   And I hear from our audience all the time,
[01:54:49.680 --> 01:54:52.640]   part of that knowledge comes from our advertisers.
[01:54:52.640 --> 01:54:53.680]   We are very careful.
[01:54:53.680 --> 01:54:56.720]   We pick advertisers with great products,
[01:54:56.720 --> 01:54:59.120]   great services with integrity,
[01:54:59.120 --> 01:55:02.640]   and introduce them to our audience with authenticity
[01:55:02.640 --> 01:55:05.920]   and genuine enthusiasm.
[01:55:05.920 --> 01:55:10.000]   And that makes our host red ads different from anything else you can buy.
[01:55:10.000 --> 01:55:12.000]   We are literally bringing you
[01:55:12.000 --> 01:55:14.800]   to the attention of our audience
[01:55:14.800 --> 01:55:18.080]   and giving you a big, fat endorsement.
[01:55:18.080 --> 01:55:21.120]   We like to create partnerships with trusted brands.
[01:55:21.120 --> 01:55:23.360]   Brands who are in it for the long run,
[01:55:23.360 --> 01:55:26.880]   long-term partners that want to grow with us.
[01:55:26.880 --> 01:55:29.440]   And we have so many great success stories.
[01:55:29.440 --> 01:55:32.880]   Tim Broome, who founded ITProTV in 2013,
[01:55:32.880 --> 01:55:35.440]   started advertising with us on day one,
[01:55:35.440 --> 01:55:36.880]   has been with us ever since.
[01:55:36.880 --> 01:55:38.560]   He said, quote,
[01:55:38.560 --> 01:55:40.880]   "We would not be where we are today
[01:55:40.880 --> 01:55:42.480]   without the Twit Network."
[01:55:42.480 --> 01:55:44.160]   I think the proof is in the pudding.
[01:55:44.160 --> 01:55:47.200]   Advertisers like ITProTV and Audible
[01:55:47.200 --> 01:55:49.520]   that have been with us for more than 10 years,
[01:55:49.520 --> 01:55:52.400]   they stick around because their ads work.
[01:55:52.400 --> 01:55:56.080]   And honestly, isn't that why you're buying advertising?
[01:55:56.080 --> 01:55:57.360]   You get a lot with Twit.
[01:55:57.360 --> 01:55:59.760]   We have a very full service attitude.
[01:55:59.760 --> 01:56:03.680]   We almost think of it as kind of artisanal advertising,
[01:56:03.680 --> 01:56:05.120]   boutique advertising.
[01:56:05.120 --> 01:56:08.080]   You'll get a full service continuity team,
[01:56:08.080 --> 01:56:10.400]   people who are on the phone with you,
[01:56:10.400 --> 01:56:11.680]   who are in touch with you,
[01:56:11.680 --> 01:56:13.680]   who support you with everything,
[01:56:13.680 --> 01:56:16.480]   from copywriting to graphic design.
[01:56:16.480 --> 01:56:18.560]   So you are not alone in this.
[01:56:18.560 --> 01:56:21.920]   We embed our ads into the shows.
[01:56:21.920 --> 01:56:23.840]   They're not added later.
[01:56:23.840 --> 01:56:25.280]   They're part of the shows.
[01:56:25.280 --> 01:56:26.320]   In fact, often,
[01:56:26.320 --> 01:56:27.520]   they're such a part of our shows
[01:56:27.520 --> 01:56:30.240]   that our other hosts will chime in on the ad,
[01:56:30.240 --> 01:56:31.840]   saying, "Yeah, I love that."
[01:56:31.840 --> 01:56:32.880]   Or, "Just the other day."
[01:56:32.880 --> 01:56:34.800]   One of our hosts said,
[01:56:34.800 --> 01:56:36.240]   "Man, I really got to buy that."
[01:56:36.240 --> 01:56:39.280]   That's an additional benefit to you,
[01:56:39.280 --> 01:56:40.240]   because you're hearing people,
[01:56:40.240 --> 01:56:42.160]   our audience trusts,
[01:56:42.160 --> 01:56:43.920]   saying, "Yeah, that sounds great."
[01:56:43.920 --> 01:56:47.840]   We deliver, always over deliver on impressions.
[01:56:47.840 --> 01:56:51.280]   So you know you're going to get the impressions you expect.
[01:56:51.280 --> 01:56:53.200]   The ads are unique every time.
[01:56:53.200 --> 01:56:55.040]   We don't pre-record them and roll them in.
[01:56:55.040 --> 01:56:58.000]   We are genuinely doing those ads in the middle of the show.
[01:56:58.000 --> 01:57:00.960]   We'll give you great onboarding services.
[01:57:00.960 --> 01:57:02.640]   Adtech with pod sites,
[01:57:02.640 --> 01:57:04.160]   that's free for direct clients,
[01:57:04.160 --> 01:57:06.160]   gives you a lot of reporting,
[01:57:06.160 --> 01:57:08.800]   gives you a great idea of how well your ads are working.
[01:57:08.800 --> 01:57:10.240]   You'll get courtesy commercials.
[01:57:10.240 --> 01:57:11.520]   You actually can take our ads
[01:57:11.520 --> 01:57:14.560]   and share them across social media and landing pages.
[01:57:14.560 --> 01:57:16.480]   That really extends the reach.
[01:57:16.480 --> 01:57:17.760]   There are other free goodies too,
[01:57:17.760 --> 01:57:20.000]   including mentions in our weekly newsletter
[01:57:20.000 --> 01:57:23.200]   that sent to thousands of fans, engaged fans,
[01:57:23.200 --> 01:57:24.720]   who really want to see this stuff.
[01:57:24.720 --> 01:57:28.000]   We give you bonus ads and social media promotion too.
[01:57:28.000 --> 01:57:31.360]   So if you want to be a long-term partner,
[01:57:31.360 --> 01:57:35.440]   introduce your product to a savvy, engaged tech audience.
[01:57:35.440 --> 01:57:38.080]   Visit twit.tv/advertise.
[01:57:38.080 --> 01:57:40.080]   Check out those testimonials.
[01:57:40.080 --> 01:57:42.320]   Mark McCrary is the CEO of Authentic.
[01:57:42.320 --> 01:57:43.120]   You probably know him,
[01:57:43.120 --> 01:57:47.120]   one of the biggest original podcast advertising companies.
[01:57:47.120 --> 01:57:49.600]   We've been with him for 16 years.
[01:57:49.600 --> 01:57:50.800]   Mark said,
[01:57:50.800 --> 01:57:53.440]   "The feedback from many advertisers over 16 years
[01:57:53.440 --> 01:57:55.600]   across a range of product categories,
[01:57:55.600 --> 01:57:59.120]   everything from razors to computers,
[01:57:59.120 --> 01:58:02.240]   is that if ads and podcasts are going to work for a brand,
[01:58:02.240 --> 01:58:03.680]   they're going to work on Twitch shows."
[01:58:03.680 --> 01:58:06.320]   I'm very proud of what we do,
[01:58:06.320 --> 01:58:08.480]   because it's honest, it's got integrity,
[01:58:08.480 --> 01:58:09.760]   it's authentic,
[01:58:09.760 --> 01:58:12.720]   and it really is a great introduction
[01:58:12.720 --> 01:58:15.200]   to our audience of your brand.
[01:58:15.200 --> 01:58:17.520]   Our listeners are smart,
[01:58:17.520 --> 01:58:18.640]   they're engaged,
[01:58:18.640 --> 01:58:20.000]   they're tech savvy,
[01:58:20.000 --> 01:58:21.440]   they're dedicated to our network,
[01:58:22.000 --> 01:58:23.440]   and that's one of the reasons
[01:58:23.440 --> 01:58:25.680]   we only work with high-integrity partners
[01:58:25.680 --> 01:58:27.760]   that we've personally and thoroughly vetted.
[01:58:27.760 --> 01:58:30.480]   I have absolute approval on everybody.
[01:58:30.480 --> 01:58:32.160]   If you've got a great product,
[01:58:32.160 --> 01:58:33.600]   I want to hear from you.
[01:58:33.600 --> 01:58:35.600]   Elevate your brand by reaching out today at
[01:58:35.600 --> 01:58:37.840]   advertise@twit.tv.
[01:58:37.840 --> 01:58:39.440]   Break out of the advertising norm,
[01:58:39.440 --> 01:58:42.960]   grow your brand with Host Red ads on twit.tv.
[01:58:42.960 --> 01:58:45.760]   Visit twit.tv/advertise for more details,
[01:58:45.760 --> 01:58:47.280]   or you can email us
[01:58:47.280 --> 01:58:50.480]   advertise@twit.tv
[01:58:50.480 --> 01:58:52.320]   if you're ready to launch your campaign now.
[01:58:52.320 --> 01:58:53.680]   I can't wait to see your product,
[01:58:53.680 --> 01:58:54.720]   so give us a ring.
[01:58:54.720 --> 01:58:57.280]   This is not news.
[01:58:57.280 --> 01:58:58.720]   Is it the change in the world?
[01:58:58.720 --> 01:58:59.760]   While the spacey upset,
[01:58:59.760 --> 01:59:01.840]   the spacey didn't see our breaking news thing
[01:59:01.840 --> 01:59:02.640]   from last week.
[01:59:02.640 --> 01:59:04.080]   Oh, okay, let's...
[01:59:04.080 --> 01:59:05.120]   Okay, all right,
[01:59:05.120 --> 01:59:05.840]   I have a story,
[01:59:05.840 --> 01:59:06.720]   it's really not breaking news,
[01:59:06.720 --> 01:59:07.520]   but just go ahead,
[01:59:07.520 --> 01:59:08.400]   breaking news,
[01:59:08.400 --> 01:59:09.120]   this is just in.
[01:59:09.120 --> 01:59:11.680]   Look at that.
[01:59:11.680 --> 01:59:12.960]   Your fingers, Stacy.
[01:59:12.960 --> 01:59:13.520]   Oh, let's be!
[01:59:13.520 --> 01:59:16.560]   We're going to point you to in.
[01:59:16.560 --> 01:59:19.760]   If you send a request to Twitter's
[01:59:19.760 --> 01:59:20.960]   press team,
[01:59:20.960 --> 01:59:24.080]   Elon has decreed you will receive in response,
[01:59:24.080 --> 01:59:26.400]   a poop emoji.
[01:59:26.400 --> 01:59:28.160]   That's it.
[01:59:28.160 --> 01:59:30.800]   There is a guy,
[01:59:30.800 --> 01:59:33.200]   there is a guy stuck in fourth grade.
[01:59:33.200 --> 01:59:35.840]   Stuck in fourth grade,
[01:59:35.840 --> 01:59:36.480]   and that's...
[01:59:36.480 --> 01:59:37.120]   Let's do it again.
[01:59:37.120 --> 01:59:38.560]   Our breaking news!
[01:59:38.560 --> 01:59:45.040]   I like how she has portraits in the wall of us.
[01:59:45.040 --> 01:59:45.680]   I was going to say,
[01:59:45.680 --> 01:59:47.200]   I love the portraits of you guys up there.
[01:59:47.200 --> 01:59:48.480]   It's Lofi Stacy.
[01:59:48.960 --> 01:59:50.960]   Thank you, Anthony Nielsen, for doing that.
[01:59:50.960 --> 01:59:51.520]   Thank you.
[01:59:51.520 --> 01:59:52.000]   Yeah.
[01:59:52.000 --> 01:59:54.160]   And thanks for making me look cute.
[01:59:54.160 --> 01:59:54.960]   I like it.
[01:59:54.960 --> 01:59:55.920]   Super cute.
[01:59:55.920 --> 01:59:56.560]   Super cute.
[01:59:56.560 --> 01:59:57.440]   You're like, "Tay!"
[01:59:57.440 --> 02:00:00.240]   All right,
[02:00:00.240 --> 02:00:03.360]   let me do a little plug for Club Twit,
[02:00:03.360 --> 02:00:04.400]   and then we can get you pics of the week,
[02:00:04.400 --> 02:00:05.440]   and you can go get waffles.
[02:00:05.440 --> 02:00:08.960]   Many of you are members of the club,
[02:00:08.960 --> 02:00:09.520]   and for that,
[02:00:09.520 --> 02:00:12.800]   I say thank you so much across the 7,000 mark.
[02:00:12.800 --> 02:00:14.160]   Yes!
[02:00:14.160 --> 02:00:15.200]   Woo!
[02:00:15.200 --> 02:00:16.240]   That's a great number,
[02:00:16.240 --> 02:00:18.400]   because it's 1% of the total audience.
[02:00:19.200 --> 02:00:22.800]   Now, I believe NPR gets 3% to 5%.
[02:00:22.800 --> 02:00:23.280]   Is that right?
[02:00:23.280 --> 02:00:24.400]   Republic broadcasting?
[02:00:24.400 --> 02:00:26.080]   Normally 3% to 5%,
[02:00:26.080 --> 02:00:27.360]   but then they beg you all the time,
[02:00:27.360 --> 02:00:28.640]   and I don't not want to do that.
[02:00:28.640 --> 02:00:31.200]   We are not going to have pledge drives,
[02:00:31.200 --> 02:00:32.560]   or anything like that.
[02:00:32.560 --> 02:00:32.960]   I just...
[02:00:32.960 --> 02:00:34.720]   A simple request.
[02:00:34.720 --> 02:00:36.160]   If you love what we do,
[02:00:36.160 --> 02:00:37.600]   and you want to see us do more of it,
[02:00:37.600 --> 02:00:38.800]   you want to see us ad shows,
[02:00:38.800 --> 02:00:39.920]   you want to see us grow.
[02:00:39.920 --> 02:00:41.440]   Things like Stacy's Book Club.
[02:00:41.440 --> 02:00:43.120]   Join the club,
[02:00:43.120 --> 02:00:44.320]   seven bucks a month.
[02:00:44.320 --> 02:00:45.760]   That's all it costs.
[02:00:45.760 --> 02:00:47.440]   You get access to the Discord.
[02:00:47.440 --> 02:00:49.040]   That's where some of the special shows we do,
[02:00:49.040 --> 02:00:49.840]   like Hands on Mac,
[02:00:49.840 --> 02:00:51.440]   It's Tush and Hands on Windows Live.
[02:00:51.440 --> 02:00:53.040]   You get all of the shows ad-free.
[02:00:53.040 --> 02:00:53.520]   No ads.
[02:00:53.520 --> 02:00:54.480]   You won't even hear this.
[02:00:54.480 --> 02:00:55.920]   No ads.
[02:00:55.920 --> 02:00:57.520]   And it gives us a chance to launch new shows,
[02:00:57.520 --> 02:00:58.640]   like this week in Space.
[02:00:58.640 --> 02:01:02.240]   We've just launched Scott Wilkinson's Home Theater Geeks.
[02:01:02.240 --> 02:01:03.200]   Relaunched it.
[02:01:03.200 --> 02:01:04.400]   The show we had to cancel,
[02:01:04.400 --> 02:01:05.920]   because it didn't have a big enough audience
[02:01:05.920 --> 02:01:07.120]   or advertisers,
[02:01:07.120 --> 02:01:08.560]   but hey, the club pays for it.
[02:01:08.560 --> 02:01:10.000]   That's the beauty of it.
[02:01:10.000 --> 02:01:13.440]   It's direct drive for shows you love.
[02:01:13.440 --> 02:01:14.720]   If you want to participate,
[02:01:14.720 --> 02:01:16.640]   I would really be very grateful
[02:01:16.640 --> 02:01:18.960]   if you go to twit.tv/club and sign up.
[02:01:18.960 --> 02:01:20.720]   Seven bucks a month.
[02:01:20.720 --> 02:01:23.920]   And puppy's not included.
[02:01:23.920 --> 02:01:26.160]   Thank you.
[02:01:26.160 --> 02:01:30.000]   Well, it depends on who you ask.
[02:01:30.000 --> 02:01:31.440]   You could get a cat and sunglasses.
[02:01:31.440 --> 02:01:34.880]   Aw.
[02:01:34.880 --> 02:01:38.880]   Stacy, what's your thing of the week?
[02:01:38.880 --> 02:01:41.120]   So I thought I'd do something crazy,
[02:01:41.120 --> 02:01:42.480]   because it's not enough to have
[02:01:42.480 --> 02:01:46.080]   a migraine and need a waffle.
[02:01:46.080 --> 02:01:52.720]   I thought I just got a topo tp link matter plug.
[02:01:52.720 --> 02:01:54.880]   Topo tp link matter plug.
[02:01:54.880 --> 02:01:57.200]   And I haven't done it with this one.
[02:01:57.200 --> 02:01:58.320]   I've done it with the Marrow's one.
[02:01:58.320 --> 02:01:59.840]   Look, see, there's little matter back.
[02:01:59.840 --> 02:02:01.280]   Oh, cool.
[02:02:01.280 --> 02:02:02.480]   I can work this.
[02:02:02.480 --> 02:02:03.280]   But you know what that's good,
[02:02:03.280 --> 02:02:06.000]   because you could buy these cheaply on Amazon
[02:02:06.000 --> 02:02:08.480]   from an unknown name Chinese company with no security.
[02:02:08.480 --> 02:02:09.840]   At least if it's matter, right?
[02:02:09.840 --> 02:02:11.280]   Does that mean that you have some?
[02:02:11.280 --> 02:02:13.440]   You have some level of security.
[02:02:13.440 --> 02:02:14.000]   Yes.
[02:02:14.000 --> 02:02:15.680]   So what I thought I was actually going to do,
[02:02:15.680 --> 02:02:16.960]   this is a $20 plug.
[02:02:16.960 --> 02:02:18.880]   So they are expensive for a smart plug.
[02:02:18.880 --> 02:02:20.160]   I was going to add it and show you
[02:02:20.160 --> 02:02:22.240]   what the process of adding something to matter is,
[02:02:22.240 --> 02:02:23.680]   because it's so simple.
[02:02:23.680 --> 02:02:24.240]   Let's see it.
[02:02:24.240 --> 02:02:25.040]   Irritically.
[02:02:25.040 --> 02:02:26.800]   T-A-P-O.
[02:02:26.800 --> 02:02:27.280]   Topo.
[02:02:27.280 --> 02:02:29.360]   Topo tp-O.
[02:02:29.360 --> 02:02:30.080]   Yeah.
[02:02:30.080 --> 02:02:30.640]   Okay.
[02:02:30.640 --> 02:02:31.680]   So I've got my plug.
[02:02:31.680 --> 02:02:32.720]   Yeah.
[02:02:32.720 --> 02:02:33.360]   I've got a phone.
[02:02:33.360 --> 02:02:33.760]   Yeah.
[02:02:33.760 --> 02:02:35.200]   This is an Android phone.
[02:02:35.200 --> 02:02:36.960]   If you are using an Apple phone,
[02:02:36.960 --> 02:02:41.280]   because Apple messed up their home kit architecture,
[02:02:41.280 --> 02:02:41.840]   Oh, no.
[02:02:41.840 --> 02:02:43.840]   You've got to wait until the 16.4.
[02:02:44.800 --> 02:02:46.880]   We think the next update is going to make it easier.
[02:02:46.880 --> 02:02:48.640]   But it's a little glitchy for using Apple.
[02:02:48.640 --> 02:02:51.920]   So for once, Android, we're in.
[02:02:51.920 --> 02:02:53.840]   I see a QR code in that.
[02:02:53.840 --> 02:02:54.720]   Do I scan it?
[02:02:54.720 --> 02:02:55.760]   Yeah.
[02:02:55.760 --> 02:02:57.680]   So I'm going to scan this QR code.
[02:02:57.680 --> 02:02:59.120]   Bloop, bloop, bloop, bloop.
[02:02:59.120 --> 02:03:00.560]   Hello.
[02:03:00.560 --> 02:03:02.800]   I'm really bad at scanning.
[02:03:02.800 --> 02:03:04.800]   Apple's 16.4 is imminent.
[02:03:04.800 --> 02:03:06.720]   I think we're very close to its release.
[02:03:06.720 --> 02:03:07.120]   So.
[02:03:07.120 --> 02:03:08.800]   We're just going to,
[02:03:08.800 --> 02:03:10.560]   and also came with the QR code.
[02:03:10.560 --> 02:03:11.280]   Oh, where the QR code.
[02:03:11.280 --> 02:03:12.080]   Oh, no, I lost it.
[02:03:12.080 --> 02:03:13.520]   It's a clear QR code.
[02:03:13.520 --> 02:03:14.080]   I love it.
[02:03:14.960 --> 02:03:16.080]   No, it's not.
[02:03:16.080 --> 02:03:16.560]   That's all right.
[02:03:16.560 --> 02:03:17.600]   I trust it.
[02:03:17.600 --> 02:03:18.960]   This is going to be so fun, y'all.
[02:03:18.960 --> 02:03:19.600]   Yeah.
[02:03:19.600 --> 02:03:20.800]   I was like, oh, here it is.
[02:03:20.800 --> 02:03:23.120]   Oh, it's a sticker.
[02:03:23.120 --> 02:03:25.040]   And just so y'all know,
[02:03:25.040 --> 02:03:27.360]   I actually, I take my stickers,
[02:03:27.360 --> 02:03:29.360]   and I put the name of the device on a,
[02:03:29.360 --> 02:03:30.720]   I have a folder,
[02:03:30.720 --> 02:03:32.000]   and I stick the name of the device.
[02:03:32.000 --> 02:03:32.960]   Oh, that is so smart.
[02:03:32.960 --> 02:03:33.280]   So, it's more like,
[02:03:33.280 --> 02:03:34.080]   God, you're organized.
[02:03:34.080 --> 02:03:34.800]   Oh, my God.
[02:03:34.800 --> 02:03:35.680]   Is that brilliant?
[02:03:35.680 --> 02:03:36.080]   Wow.
[02:03:36.080 --> 02:03:37.680]   Just a loosely finder or something.
[02:03:37.680 --> 02:03:38.800]   That's brilliant.
[02:03:38.800 --> 02:03:40.800]   Yeah, anything, but stick.
[02:03:40.800 --> 02:03:43.360]   Don't like think you're going to just keep it,
[02:03:43.360 --> 02:03:44.160]   because you're not.
[02:03:44.160 --> 02:03:45.040]   So this plug is Wi-Fi.
[02:03:45.040 --> 02:03:45.920]   That's interesting.
[02:03:45.920 --> 02:03:46.800]   It's not Bluetooth.
[02:03:46.800 --> 02:03:47.440]   It's Wi-Fi.
[02:03:47.440 --> 02:03:48.560]   So it's on your network.
[02:03:48.560 --> 02:03:50.160]   I guess that makes sense.
[02:03:50.160 --> 02:03:50.560]   So, yes.
[02:03:50.560 --> 02:03:53.040]   I'm going to, no, it's Wi-Fi.
[02:03:53.040 --> 02:03:54.960]   So I'm going to go to the Google Home app.
[02:03:54.960 --> 02:03:57.600]   I should be able to add it straight from Android,
[02:03:57.600 --> 02:03:58.320]   but it's not working.
[02:03:58.320 --> 02:04:00.000]   So I'm going to go to the Google Home app,
[02:04:00.000 --> 02:04:01.760]   which is another option.
[02:04:01.760 --> 02:04:03.920]   And I'm going to just hit the plus
[02:04:03.920 --> 02:04:04.880]   for adding a device.
[02:04:04.880 --> 02:04:06.000]   Nice.
[02:04:06.000 --> 02:04:07.040]   It's going to be like,
[02:04:07.040 --> 02:04:10.080]   hello, setup device, new device.
[02:04:10.080 --> 02:04:11.440]   This is pretty smart, too.
[02:04:11.440 --> 02:04:14.000]   It's got auto on, auto off, away mode,
[02:04:14.000 --> 02:04:16.240]   remote control, voice control.
[02:04:16.240 --> 02:04:20.560]   There's a, oh, I see via Echo or Siri or Google Assistant.
[02:04:20.560 --> 02:04:21.680]   So that's pretty cool.
[02:04:21.680 --> 02:04:25.360]   Now I see a 3-pack for $39.99.
[02:04:25.360 --> 02:04:26.640]   That's $13 each.
[02:04:26.640 --> 02:04:28.320]   That's not too bad.
[02:04:28.320 --> 02:04:29.360]   Good deal there.
[02:04:29.360 --> 02:04:31.680]   Yeah, $20 a piece for a single.
[02:04:31.680 --> 02:04:32.080]   Yeah.
[02:04:32.080 --> 02:04:33.120]   They sell--
[02:04:33.120 --> 02:04:33.680]   No, sorry.
[02:04:33.680 --> 02:04:35.200]   What?
[02:04:35.200 --> 02:04:35.760]   What?
[02:04:35.760 --> 02:04:36.400]   Keep going.
[02:04:36.400 --> 02:04:37.840]   They have a smart--
[02:04:37.840 --> 02:04:38.480]   Yeah, I'm not.
[02:04:38.480 --> 02:04:38.880]   Let's see.
[02:04:38.880 --> 02:04:40.240]   This is a 4-pack.
[02:04:41.280 --> 02:04:43.040]   Smart Wi-Fi plug.
[02:04:43.040 --> 02:04:44.160]   I'm tempted now.
[02:04:44.160 --> 02:04:46.720]   Let me see what it's going to be on Amazon.
[02:04:46.720 --> 02:04:50.880]   29 bucks before of them.
[02:04:50.880 --> 02:04:51.680]   Any bad?
[02:04:51.680 --> 02:04:52.160]   That's $50.
[02:04:52.160 --> 02:04:53.680]   No, that's not bad at all.
[02:04:53.680 --> 02:04:54.720]   It's $750 each.
[02:04:54.720 --> 02:04:56.640]   Right?
[02:04:56.640 --> 02:04:57.280]   Am I right?
[02:04:57.280 --> 02:04:58.000]   I think I am.
[02:04:58.000 --> 02:04:58.160]   Yeah.
[02:04:58.160 --> 02:04:59.760]   Wait, hold on.
[02:04:59.760 --> 02:05:01.040]   Are those the matter ones?
[02:05:01.040 --> 02:05:03.040]   Oh, we want to make sure they're matter--
[02:05:03.040 --> 02:05:04.080]   Yeah, it's not the matter one.
[02:05:04.080 --> 02:05:05.120]   Ah, this one is,
[02:05:05.120 --> 02:05:07.120]   is Apple Home and Google and all that?
[02:05:07.120 --> 02:05:07.840]   But they're--
[02:05:07.840 --> 02:05:07.920]   You're looking for--
[02:05:07.920 --> 02:05:09.440]   But that's not what I want.
[02:05:09.440 --> 02:05:10.240]   I want the T1.
[02:05:10.240 --> 02:05:12.000]   The one I have in an IRC, sir.
[02:05:12.000 --> 02:05:13.200]   That was the V1.
[02:05:13.200 --> 02:05:14.160]   That was the V1.
[02:05:14.160 --> 02:05:16.000]   The P125M.
[02:05:16.000 --> 02:05:17.360]   The P125M.
[02:05:17.360 --> 02:05:19.520]   There we have it, 3-pack.
[02:05:19.520 --> 02:05:21.760]   And by the way,
[02:05:21.760 --> 02:05:25.360]   you have a code 20 matter on Amazon for 20% off.
[02:05:25.360 --> 02:05:27.120]   Now, that's--
[02:05:27.120 --> 02:05:28.240]   I'm going to buy some.
[02:05:28.240 --> 02:05:29.440]   It's just because of you, Stace.
[02:05:29.440 --> 02:05:31.680]   Just because of you.
[02:05:31.680 --> 02:05:32.560]   Smart plugs.
[02:05:32.560 --> 02:05:33.760]   I don't know what I'm going to do with them,
[02:05:33.760 --> 02:05:35.280]   but I'll plug them in and then I can say--
[02:05:35.280 --> 02:05:36.880]   I mean, you could say,
[02:05:36.880 --> 02:05:38.640]   "Hey, turn off whatever it's plugged into."
[02:05:38.640 --> 02:05:39.440]   Right?
[02:05:39.440 --> 02:05:40.560]   Okay. So I finally--
[02:05:40.560 --> 02:05:41.200]   Yes.
[02:05:41.200 --> 02:05:42.000]   Yes. That is true.
[02:05:42.000 --> 02:05:42.800]   That is what you can do.
[02:05:42.800 --> 02:05:44.240]   So I finally got it.
[02:05:44.240 --> 02:05:46.560]   I plugged it in, I scanned my QR code,
[02:05:46.560 --> 02:05:47.840]   and it says, "Hey!"
[02:05:47.840 --> 02:05:49.920]   And it gives me the URL.
[02:05:49.920 --> 02:05:51.520]   - Hey, you. - And then it says,
[02:05:51.520 --> 02:05:52.720]   "Choose an app."
[02:05:52.720 --> 02:05:54.000]   I'm going to just choose Google Home,
[02:05:54.000 --> 02:05:54.960]   because it's a Google device.
[02:05:54.960 --> 02:05:55.520]   Yeah.
[02:05:55.520 --> 02:05:55.920]   Yeah.
[02:05:55.920 --> 02:05:56.400]   Yeah.
[02:05:56.400 --> 02:05:56.960]   Yeah.
[02:05:56.960 --> 02:06:00.160]   You could also use it for Amazon Echoes or
[02:06:00.160 --> 02:06:02.000]   SmartThings.
[02:06:02.000 --> 02:06:03.600]   We'll check and make sure they end up there.
[02:06:03.600 --> 02:06:06.960]   But now I'm setting it up.
[02:06:06.960 --> 02:06:09.520]   So does matter what gives it the--
[02:06:09.520 --> 02:06:10.000]   And it's there.
[02:06:10.000 --> 02:06:11.840]   [laughs]
[02:06:11.840 --> 02:06:14.000]   All of which happened outside of your eyesight,
[02:06:14.000 --> 02:06:14.800]   but that trust--
[02:06:14.800 --> 02:06:15.600]   We trust you.
[02:06:15.600 --> 02:06:17.600]   We trust you.
[02:06:17.600 --> 02:06:20.320]   - Well, for audio, it's just the same as for anybody.
[02:06:20.320 --> 02:06:20.800]   That's right.
[02:06:20.800 --> 02:06:23.840]   I just bought three of them based on that.
[02:06:23.840 --> 02:06:25.520]   And I don't know what I'm gonna plug it into,
[02:06:25.520 --> 02:06:27.920]   but maybe even around the studio, John,
[02:06:27.920 --> 02:06:30.320]   we could have like this clock over here or something.
[02:06:30.320 --> 02:06:31.040]   You know, I could say,
[02:06:31.040 --> 02:06:33.360]   "Hey, you turn on the clock."
[02:06:33.360 --> 02:06:35.120]   All right.
[02:06:35.120 --> 02:06:35.520]   It's--
[02:06:35.520 --> 02:06:36.080]   I'm going to--
[02:06:36.080 --> 02:06:37.280]   I'll find something to do with it.
[02:06:37.280 --> 02:06:38.960]   And again, because it's matter,
[02:06:38.960 --> 02:06:40.160]   it feels like I'm gonna be--
[02:06:40.160 --> 02:06:42.880]   Because Steve Gibson bought one of these on--
[02:06:42.880 --> 02:06:44.960]   You know, just no name Chinese one on the web.
[02:06:44.960 --> 02:06:48.480]   And he went through all sorts of things to isolate it
[02:06:48.480 --> 02:06:49.920]   and put it on a VLAN and--
[02:06:49.920 --> 02:06:50.880]   [laughs]
[02:06:50.880 --> 02:06:52.960]   He's got firewall rules around it.
[02:06:52.960 --> 02:06:54.000]   And it's only Mr. Gibson.
[02:06:54.000 --> 02:06:54.960]   Barbed wire.
[02:06:54.960 --> 02:06:55.840]   Barbed wire.
[02:06:55.840 --> 02:06:58.320]   I won't have to do that, right?
[02:06:58.320 --> 02:07:00.160]   No.
[02:07:00.160 --> 02:07:02.800]   Well, you still can if you're Steve Gibson.
[02:07:02.800 --> 02:07:03.280]   Right.
[02:07:03.280 --> 02:07:03.920]   But you don't have to--
[02:07:03.920 --> 02:07:04.880]   I do have a VLAN.
[02:07:04.880 --> 02:07:07.680]   I have a IoT VLAN, so I could do that.
[02:07:07.680 --> 02:07:09.200]   What is the point?
[02:07:09.200 --> 02:07:10.160]   I mean, if it's at--
[02:07:10.160 --> 02:07:12.960]   Actually, I mean, a VLAN is no more secure than a--
[02:07:12.960 --> 02:07:13.920]   It is.
[02:07:13.920 --> 02:07:14.400]   It is.
[02:07:14.400 --> 02:07:15.440]   I mean, it's a little bit--
[02:07:15.440 --> 02:07:19.520]   If she, Jing Ping, or Xu Zhao Chu,
[02:07:19.520 --> 02:07:21.040]   or whoever that guy from TikTok,
[02:07:21.040 --> 02:07:23.840]   has got in to my plug,
[02:07:23.840 --> 02:07:26.480]   he couldn't then infiltrate into the rest of my network
[02:07:26.480 --> 02:07:28.160]   because it's on an isolated VLAN.
[02:07:28.160 --> 02:07:30.080]   That's the whole point of that.
[02:07:30.080 --> 02:07:30.960]   Okay.
[02:07:30.960 --> 02:07:32.160]   Sorry.
[02:07:32.160 --> 02:07:34.480]   So he could see what I'm doing with my plug.
[02:07:34.480 --> 02:07:36.320]   He could turn those lights on and off,
[02:07:36.320 --> 02:07:37.680]   but he couldn't get into my computer
[02:07:37.680 --> 02:07:40.080]   because it's not a gateway into my home.
[02:07:40.080 --> 02:07:41.760]   Well, yes.
[02:07:41.760 --> 02:07:43.600]   Now, how do you handle your phone on that?
[02:07:43.600 --> 02:07:45.280]   Same thing.
[02:07:45.280 --> 02:07:47.680]   I have a secure LAN,
[02:07:47.680 --> 02:07:48.720]   and I have an IoT LAN.
[02:07:48.720 --> 02:07:50.240]   The IoT LAN is 2.4 gigahertz.
[02:07:50.240 --> 02:07:51.440]   That's the other advantage of that.
[02:07:51.440 --> 02:07:54.160]   And then the other ones are both bands.
[02:07:54.160 --> 02:07:54.880]   And then--
[02:07:54.880 --> 02:07:57.200]   So the problem is if you want to,
[02:07:57.200 --> 02:08:00.400]   like Sonos, you have to be on the same network to control it.
[02:08:00.400 --> 02:08:00.800]   Right.
[02:08:00.800 --> 02:08:01.920]   That's where--
[02:08:01.920 --> 02:08:03.360]   This is what I was about to get to.
[02:08:03.360 --> 02:08:05.440]   I was like, it becomes a real bear.
[02:08:05.440 --> 02:08:08.160]   So now that my device is connected,
[02:08:08.160 --> 02:08:10.080]   and it was done--
[02:08:10.080 --> 02:08:10.960]   I mean, I'm a little bit--
[02:08:10.960 --> 02:08:11.680]   It turns up mine.
[02:08:11.680 --> 02:08:14.400]   Or off.
[02:08:14.400 --> 02:08:15.040]   No, no, no.
[02:08:15.040 --> 02:08:15.520]   I'm sorry.
[02:08:15.520 --> 02:08:16.240]   I got it.
[02:08:16.240 --> 02:08:16.960]   Thank you, Stacy.
[02:08:16.960 --> 02:08:17.520]   No, I got a big--
[02:08:17.520 --> 02:08:18.560]   This was such a good pick.
[02:08:18.560 --> 02:08:19.920]   I was like, I have to plan where I wanted to live.
[02:08:19.920 --> 02:08:20.400]   I bought three of them.
[02:08:20.400 --> 02:08:21.280]   Well, I'm figuring--
[02:08:21.280 --> 02:08:22.720]   And I bought three of them kind of on spec.
[02:08:22.720 --> 02:08:23.840]   I don't know exactly how I'm going to use it,
[02:08:23.840 --> 02:08:25.120]   but I like the idea.
[02:08:25.120 --> 02:08:27.040]   It will automatically turn off a device
[02:08:27.040 --> 02:08:29.520]   if the device is left on for a set time.
[02:08:29.520 --> 02:08:32.240]   There's certain things like lamps in the living room
[02:08:32.240 --> 02:08:34.880]   that would be very useful for this, things like that.
[02:08:34.880 --> 02:08:35.680]   Yeah.
[02:08:35.680 --> 02:08:37.760]   Well, here, I can plug in a lamp.
[02:08:37.760 --> 02:08:38.320]   It's just going to turn--
[02:08:38.320 --> 02:08:39.360]   No, no, no, no, no.
[02:08:39.360 --> 02:08:39.840]   We get it.
[02:08:39.840 --> 02:08:41.360]   We get it.
[02:08:41.360 --> 02:08:41.840]   It's pretty fast.
[02:08:41.840 --> 02:08:42.400]   I trust me.
[02:08:42.400 --> 02:08:42.800]   We get it.
[02:08:42.800 --> 02:08:45.680]   Here, you know, and here's what I'm going to do.
[02:08:45.680 --> 02:08:46.880]   I just found it.
[02:08:46.880 --> 02:08:50.160]   I can schedule my coffee maker to come on
[02:08:50.160 --> 02:08:54.400]   and time for me to just get up.
[02:08:54.400 --> 02:08:55.680]   I always have to get up, turn it on,
[02:08:55.680 --> 02:08:56.560]   and wait for it to heat up.
[02:08:56.560 --> 02:08:59.520]   But wait, is your coffee maker--
[02:08:59.520 --> 02:09:00.400]   Does it have a button?
[02:09:00.400 --> 02:09:01.120]   Or is it going to--
[02:09:01.120 --> 02:09:03.040]   Because if it has a button that you physically press,
[02:09:03.040 --> 02:09:04.240]   then you're going to need--
[02:09:04.240 --> 02:09:05.120]   So then you need--
[02:09:05.120 --> 02:09:06.160]   A button?
[02:09:06.160 --> 02:09:08.000]   No, switchbot.
[02:09:08.000 --> 02:09:08.960]   You need a switchbot.
[02:09:08.960 --> 02:09:09.440]   Oh, Lord.
[02:09:09.440 --> 02:09:10.480]   And you have to--
[02:09:10.480 --> 02:09:11.520]   Does it have a finger?
[02:09:11.520 --> 02:09:13.520]   Does it have a finger that touches the--
[02:09:13.520 --> 02:09:14.720]   It has a little server--
[02:09:14.720 --> 02:09:16.160]   It has a little server that moves the button.
[02:09:16.160 --> 02:09:17.280]   Can you make that your pick next week?
[02:09:17.280 --> 02:09:18.720]   A switchbot?
[02:09:18.720 --> 02:09:19.840]   Yeah, because if we add that--
[02:09:19.840 --> 02:09:20.880]   Do you not have any of this?
[02:09:20.880 --> 02:09:22.160]   No, but I'm just saying,
[02:09:22.160 --> 02:09:24.560]   if we add that, you could put it right here on my chair.
[02:09:24.560 --> 02:09:26.160]   And if I say something you don't like, you could pull--
[02:09:26.160 --> 02:09:27.280]   Oh, perfect.
[02:09:27.280 --> 02:09:28.720]   It's not that high.
[02:09:28.720 --> 02:09:32.560]   If you look at the switchbot push your button,
[02:09:32.560 --> 02:09:34.160]   this one's for light switches.
[02:09:34.160 --> 02:09:35.200]   That's a great name.
[02:09:35.200 --> 02:09:38.560]   But it's like a $30 device.
[02:09:38.560 --> 02:09:39.920]   Like a third grader made it up.
[02:09:39.920 --> 02:09:41.760]   When you call that, that's the switchbot.
[02:09:41.760 --> 02:09:42.560]   Push your button.
[02:09:42.560 --> 02:09:45.760]   That's what it does.
[02:09:45.760 --> 02:09:47.760]   It's a smart push.
[02:09:47.760 --> 02:09:48.560]   What does it do?
[02:09:48.560 --> 02:09:49.520]   It pushes.
[02:09:49.520 --> 02:09:50.400]   It pushes the button.
[02:09:50.400 --> 02:09:53.760]   You hit that.
[02:09:53.760 --> 02:09:55.040]   It costs more than the plugs.
[02:09:55.040 --> 02:09:58.160]   Well, it's got a little servo.
[02:09:58.160 --> 02:10:00.160]   I mean, it's got more action than the plug.
[02:10:00.160 --> 02:10:02.800]   It seems like there's something there.
[02:10:02.800 --> 02:10:03.920]   That could trigger.
[02:10:03.920 --> 02:10:04.880]   That's what it is.
[02:10:04.880 --> 02:10:06.880]   That could trigger the boxing glove to come out.
[02:10:06.880 --> 02:10:08.640]   Yeah, that's exactly it.
[02:10:08.640 --> 02:10:09.360]   Exactly.
[02:10:09.360 --> 02:10:11.360]   It's like a Rube Goldberg machine.
[02:10:11.360 --> 02:10:13.520]   It's the first thing in a longer--
[02:10:13.520 --> 02:10:15.360]   It's the littlest boxing glove.
[02:10:15.360 --> 02:10:15.920]   Yeah.
[02:10:15.920 --> 02:10:17.520]   It goes in the ink.
[02:10:17.520 --> 02:10:18.000]   It goes in the ink.
[02:10:18.000 --> 02:10:21.120]   Jeff Jarvis--
[02:10:21.120 --> 02:10:21.600]   Oh, wait a minute.
[02:10:21.600 --> 02:10:23.600]   Before you, Jeff, I've got a pick of the week.
[02:10:23.600 --> 02:10:24.880]   I meant to do this last week.
[02:10:24.880 --> 02:10:26.400]   Oh, you did your world.
[02:10:26.400 --> 02:10:27.680]   So you know about Lofi--
[02:10:27.680 --> 02:10:29.920]   Well, I thought about this because of the breaking news thing.
[02:10:29.920 --> 02:10:32.960]   She's kind of model on that YouTube channel
[02:10:32.960 --> 02:10:36.000]   where it's lo-fi beats and she's studying at her desk.
[02:10:36.000 --> 02:10:37.360]   She's kind of an anime character.
[02:10:37.360 --> 02:10:39.040]   My child has that on all the time.
[02:10:39.040 --> 02:10:40.240]   It's good, right?
[02:10:40.240 --> 02:10:41.520]   Well, your child might enjoy this.
[02:10:41.520 --> 02:10:43.360]   You might enjoy this if you have a headache.
[02:10:43.360 --> 02:10:45.840]   It's lo-fi air traffic control.
[02:10:45.840 --> 02:10:52.720]   You choose the airport.
[02:10:52.720 --> 02:10:55.840]   It plays some nice music in the background.
[02:10:56.000 --> 02:10:57.440]   [static]
[02:10:57.440 --> 02:10:58.960]   He grabbed a last 5.35.
[02:10:58.960 --> 02:11:00.640]   I want this, sir.
[02:11:00.640 --> 02:11:02.000]   Isn't this the coolest?
[02:11:02.000 --> 02:11:02.800]   I want this.
[02:11:02.800 --> 02:11:04.160]   Is this coolest?
[02:11:04.160 --> 02:11:05.200]   I don't know what it's for.
[02:11:05.200 --> 02:11:08.160]   What airport do you want to go to?
[02:11:08.160 --> 02:11:10.080]   Oh, it's Stereo.
[02:11:10.080 --> 02:11:11.360]   K-A-T-L.
[02:11:11.360 --> 02:11:12.480]   K-A-T-L.
[02:11:12.480 --> 02:11:15.360]   The Atlanta, Hartzfield, Jackson.
[02:11:15.360 --> 02:11:18.240]   We're going to listen to 6 and runway 8.
[02:11:18.240 --> 02:11:20.080]   Listen.
[02:11:20.080 --> 02:11:21.440]   Why do you do the music?
[02:11:21.440 --> 02:11:22.000]   I don't get that.
[02:11:22.000 --> 02:11:24.880]   No, because it's lo-fi beats mixed with--
[02:11:25.680 --> 02:11:26.560]   air traffic control.
[02:11:26.560 --> 02:11:27.280]   I'll just relax.
[02:11:27.280 --> 02:11:28.960]   This is good for headaches.
[02:11:28.960 --> 02:11:29.440]   Oh, no.
[02:11:29.440 --> 02:11:31.280]   No, no, this will make you feel better.
[02:11:31.280 --> 02:11:32.480]   I don't know what it is about this.
[02:11:32.480 --> 02:11:35.280]   9, 8, 9, 7, 7, 10, 6, 7, 9, 11, 11, 11, 11.
[02:11:35.280 --> 02:11:36.720]   [static]
[02:11:36.720 --> 02:11:40.000]   This has me all-- oh, yes, sir.
[02:11:40.000 --> 02:11:40.800]   Is this the best?
[02:11:40.800 --> 02:11:42.240]   Thank you.
[02:11:42.240 --> 02:11:44.880]   Just have that in the background.
[02:11:44.880 --> 02:11:49.040]   Ever once in a while, you can land an airplane.
[02:11:49.040 --> 02:11:51.600]   I was just going to get you taken down.
[02:11:51.600 --> 02:11:52.960]   I don't think so.
[02:11:52.960 --> 02:11:53.520]   I doubt it.
[02:11:53.520 --> 02:11:54.480]   Who would take us down?
[02:11:54.880 --> 02:11:57.440]   Hartzfield, Jackson at Atlanta International Airport.
[02:11:57.440 --> 02:11:58.160]   Hart, Maynard.
[02:11:58.160 --> 02:12:00.160]   Maynard.
[02:12:00.160 --> 02:12:01.280]   It's not Hartzax anymore.
[02:12:01.280 --> 02:12:01.760]   It's--
[02:12:01.760 --> 02:12:02.640]   Oh, Maynard, Jackson.
[02:12:02.640 --> 02:12:03.280]   Yeah, yeah, yeah.
[02:12:03.280 --> 02:12:03.760]   No, it's called--
[02:12:03.760 --> 02:12:04.160]   We call it--
[02:12:04.160 --> 02:12:05.760]   You're on first name basis with the old--
[02:12:05.760 --> 02:12:07.040]   "Yo guy."
[02:12:07.040 --> 02:12:09.920]   "I'm in an airplane.
[02:12:09.920 --> 02:12:11.680]   I'm a foreign game painter, man."
[02:12:11.680 --> 02:12:13.120]   I totally dig this.
[02:12:13.120 --> 02:12:17.520]   I sit and listen to live ATC at random anyway.
[02:12:17.520 --> 02:12:19.440]   You can control the music volume, do you?
[02:12:19.440 --> 02:12:21.520]   Yeah, air traffic control is something about it.
[02:12:21.520 --> 02:12:21.920]   I used to--
[02:12:21.920 --> 02:12:23.680]   they used to have Channel 9, remember?
[02:12:23.680 --> 02:12:25.760]   On the United flights--
[02:12:25.760 --> 02:12:26.240]   In the--
[02:12:26.240 --> 02:12:27.920]   I guess Fuzzle may be a little bit better,
[02:12:27.920 --> 02:12:28.880]   because it's a little more busy.
[02:12:28.880 --> 02:12:30.080]   Let's go back to--
[02:12:30.080 --> 02:12:31.520]   He's going to have a found the rain going.
[02:12:31.520 --> 02:12:33.520]   One right take, IVL, by L for one.
[02:12:33.520 --> 02:12:35.040]   L for one, they're going to find the one right.
[02:12:35.040 --> 02:12:36.080]   It's going to be L for one.
[02:12:36.080 --> 02:12:37.120]   It's a stereo, too.
[02:12:37.120 --> 02:12:39.200]   Left channel, right channel.
[02:12:39.200 --> 02:12:40.960]   1542, 35, rolling one, right?
[02:12:40.960 --> 02:12:42.480]   That's right, that's correct.
[02:12:42.480 --> 02:12:43.360]   Two, rolling one, right.
[02:12:43.360 --> 02:12:45.840]   Yeah, L for one, 15, four, you can--
[02:12:45.840 --> 02:12:47.040]   This is so awesome.
[02:12:47.040 --> 02:12:50.080]   Jeff Jarvis, I'm going to keep this going in the background.
[02:12:50.080 --> 02:12:51.040]   Wow, you give us--
[02:12:51.040 --> 02:12:51.920]   Oh, please don't.
[02:12:51.920 --> 02:12:52.960]   You're never the way.
[02:12:52.960 --> 02:12:54.080]   It's going to be a headache.
[02:12:54.080 --> 02:12:55.920]   You don't like it?
[02:12:55.920 --> 02:12:57.520]   No, I hate it.
[02:12:57.520 --> 02:12:59.920]   What is it about us, Ant, that we like that so much?
[02:12:59.920 --> 02:13:01.840]   You're boring, though.
[02:13:01.840 --> 02:13:04.160]   I mean, the music is one thing, but the--
[02:13:04.160 --> 02:13:05.360]   The shot--
[02:13:05.360 --> 02:13:08.960]   The shot from the ATC, it always intrigues me.
[02:13:08.960 --> 02:13:12.240]   Yeah, you just run this while you're taking a nap in the bedroom.
[02:13:12.240 --> 02:13:14.640]   You just feel like you're not missing anything.
[02:13:14.640 --> 02:13:15.440]   Right.
[02:13:15.440 --> 02:13:17.920]   You describe me perfectly.
[02:13:17.920 --> 02:13:18.480]   Exactly.
[02:13:18.480 --> 02:13:21.040]   I will listen to this while I'm trying to take it out.
[02:13:21.040 --> 02:13:22.640]   Dude, you and I need to go out and drink some brad.
[02:13:22.640 --> 02:13:25.600]   I'm liquor together because I think we're on a wavelength.
[02:13:25.600 --> 02:13:26.640]   Yes, cheers.
[02:13:26.640 --> 02:13:27.600]   Cheers.
[02:13:27.600 --> 02:13:28.320]   Cheers, my friend.
[02:13:28.320 --> 02:13:31.360]   I'll bring the abolura budna.
[02:13:31.360 --> 02:13:32.880]   Yes.
[02:13:32.880 --> 02:13:33.680]   Jeff Jarvis.
[02:13:33.680 --> 02:13:37.200]   All right, since you're going to Italy,
[02:13:37.200 --> 02:13:40.400]   maybe you could win this challenge, the Vesuvius Challenge.
[02:13:40.400 --> 02:13:42.400]   Oh, do you have to stand near Volcano?
[02:13:42.400 --> 02:13:45.520]   Well, actually, yes, but I was dubious.
[02:13:45.520 --> 02:13:50.240]   So there were burnt papayri discovered
[02:13:51.520 --> 02:13:57.840]   in the Ash's.
[02:13:57.840 --> 02:13:58.480]   In the Ash's.
[02:13:58.480 --> 02:13:58.480]   Ash's.
[02:13:58.480 --> 02:13:58.480]   Ash's.
[02:13:58.480 --> 02:13:58.480]   Ash's.
[02:13:58.480 --> 02:13:58.480]   Ash's.
[02:13:58.480 --> 02:13:59.520]   Right now.
[02:13:59.520 --> 02:14:01.840]   And they can't read it because it's all Ashy.
[02:14:01.840 --> 02:14:07.840]   It's all Ashy, but with machine learning and with multi-layered visual,
[02:14:07.840 --> 02:14:11.280]   they think that maybe they can read these,
[02:14:11.280 --> 02:14:14.240]   and there's a million-dollar challenge to figure out how to do it.
[02:14:14.240 --> 02:14:17.440]   X-ray tomography and computer vision,
[02:14:18.960 --> 02:14:23.280]   they're reading it without opening because if you open it, crumbles.
[02:14:23.280 --> 02:14:23.840]   It's wrong.
[02:14:23.840 --> 02:14:24.320]   Yeah.
[02:14:24.320 --> 02:14:26.880]   This is actually a Dead Sea Scroll.
[02:14:26.880 --> 02:14:32.160]   And it has a text from the book of Leviticus.
[02:14:32.160 --> 02:14:36.720]   So it shows a carbonized scroll can be digitally unrolled and read
[02:14:36.720 --> 02:14:39.760]   without physically opening it.
[02:14:39.760 --> 02:14:42.320]   Oh, this is super cool.
[02:14:42.320 --> 02:14:47.360]   Now they're using a particle accelerator, scan two full scrolls and several fragments.
[02:14:48.240 --> 02:14:54.080]   At four to eight micrometer resolution with 16 bits of density data per voxel.
[02:14:54.080 --> 02:14:58.080]   That is incredible.
[02:14:58.080 --> 02:14:59.120]   What's a voxel?
[02:14:59.120 --> 02:15:00.240]   What is a voxel?
[02:15:00.240 --> 02:15:02.080]   It's like a pixel only.
[02:15:02.080 --> 02:15:04.560]   It's a car that they don't make any one.
[02:15:04.560 --> 02:15:06.880]   It's a three-dimensional pixel.
[02:15:06.880 --> 02:15:07.680]   Think of it that way.
[02:15:07.680 --> 02:15:08.640]   Okay.
[02:15:08.640 --> 02:15:09.760]   Didn't know that.
[02:15:09.760 --> 02:15:10.080]   Yeah.
[02:15:10.080 --> 02:15:12.080]   It's in games, you know.
[02:15:12.080 --> 02:15:15.440]   What's that Miss Stacy showing there?
[02:15:15.440 --> 02:15:17.680]   Was that a voxel she was showing?
[02:15:17.680 --> 02:15:18.480]   Well, you got a voxel.
[02:15:18.480 --> 02:15:20.880]   No, she's just going to show us you could turn something on with that thing.
[02:15:20.880 --> 02:15:22.480]   She's determined to throw it on.
[02:15:22.480 --> 02:15:24.640]   All right.
[02:15:24.640 --> 02:15:28.480]   This is scrollprize.org, grandprize $700,000.
[02:15:28.480 --> 02:15:32.320]   First team to read a scroll by the end of the year.
[02:15:32.320 --> 02:15:37.200]   If you can detect ink from X-rays by June 14th, $50,000.
[02:15:37.200 --> 02:15:39.280]   Wow.
[02:15:39.280 --> 02:15:41.680]   You know, this is an interesting idea.
[02:15:41.680 --> 02:15:42.720]   It is.
[02:15:42.720 --> 02:15:43.920]   So another one here.
[02:15:43.920 --> 02:15:45.680]   I don't know how this ended up on my screen.
[02:15:45.680 --> 02:15:46.480]   It ended up in a tab.
[02:15:46.480 --> 02:15:50.480]   I think I accidentally clicked on it and had, but I thought it would be appropriate to our
[02:15:50.480 --> 02:15:51.440]   discussion about AI.
[02:15:51.440 --> 02:15:54.080]   Headshot Pro.
[02:15:54.080 --> 02:15:57.200]   I think it was on Twitter.
[02:15:57.200 --> 02:15:57.840]   Your image.
[02:15:57.840 --> 02:15:58.080]   Yeah.
[02:15:58.080 --> 02:16:01.440]   And it makes 120 headshots for you.
[02:16:01.440 --> 02:16:01.600]   Yeah.
[02:16:01.600 --> 02:16:04.080]   We need new headshots.
[02:16:04.080 --> 02:16:05.120]   We should try this.
[02:16:05.120 --> 02:16:07.600]   So you give them your picture first.
[02:16:07.600 --> 02:16:08.800]   Yes.
[02:16:08.800 --> 02:16:14.880]   And then they give you three different locations, 120 headshots per person, 29 bucks, two hours.
[02:16:16.080 --> 02:16:16.560]   Huh.
[02:16:16.560 --> 02:16:22.880]   The only problem I have with this is the whole word plasticy skin everybody has.
[02:16:22.880 --> 02:16:23.840]   Yeah.
[02:16:23.840 --> 02:16:24.800]   Look at this scroll down.
[02:16:24.800 --> 02:16:26.880]   You're going to see something that looked pretty.
[02:16:26.880 --> 02:16:28.160]   They look fakey.
[02:16:28.160 --> 02:16:29.200]   Yeah.
[02:16:29.200 --> 02:16:30.720]   Other than that, these are fine.
[02:16:30.720 --> 02:16:32.080]   Have you seen my headshots?
[02:16:32.080 --> 02:16:32.480]   Good.
[02:16:32.480 --> 02:16:33.200]   What do you think of this?
[02:16:33.200 --> 02:16:34.080]   Does that look plastic?
[02:16:34.080 --> 02:16:34.720]   How about that?
[02:16:34.720 --> 02:16:35.040]   Mm.
[02:16:35.040 --> 02:16:36.480]   How about that?
[02:16:36.480 --> 02:16:37.280]   What about that?
[02:16:37.280 --> 02:16:38.800]   How about that?
[02:16:38.800 --> 02:16:39.520]   That's my mom.
[02:16:39.520 --> 02:16:40.320]   I'm sorry.
[02:16:40.320 --> 02:16:40.960]   How about that?
[02:16:40.960 --> 02:16:43.840]   Hi, mom.
[02:16:43.840 --> 02:16:44.800]   Hi, mom.
[02:16:44.800 --> 02:16:45.360]   She listens.
[02:16:45.360 --> 02:16:46.240]   Hi, the mom today.
[02:16:46.240 --> 02:16:46.800]   She listens.
[02:16:46.800 --> 02:16:48.080]   I said, I want you on the show.
[02:16:48.080 --> 02:16:49.680]   She says, oh, no, you don't.
[02:16:49.680 --> 02:16:52.160]   Or be like David Letterman with his mom on.
[02:16:52.160 --> 02:16:52.480]   Yes.
[02:16:52.480 --> 02:16:53.280]   She's great.
[02:16:53.280 --> 02:16:54.400]   Oh, yes.
[02:16:54.400 --> 02:16:56.080]   That's my exciting discourses.
[02:16:56.080 --> 02:16:57.360]   Oh, that's good.
[02:16:57.360 --> 02:16:58.080]   Did you get that?
[02:16:58.080 --> 02:16:59.200]   No, that works perfect.
[02:16:59.200 --> 02:17:00.000]   Who did that one?
[02:17:00.000 --> 02:17:02.000]   That's good.
[02:17:02.000 --> 02:17:07.120]   That in vogue.ai, I installed that.
[02:17:07.120 --> 02:17:07.520]   Nice.
[02:17:07.520 --> 02:17:09.440]   Mr. Nielsen said I should install it.
[02:17:09.440 --> 02:17:09.920]   Nice.
[02:17:09.920 --> 02:17:10.880]   Been playing around with it.
[02:17:10.880 --> 02:17:11.520]   That's so cool.
[02:17:11.520 --> 02:17:14.400]   Not just using the mid-journey model, I believe.
[02:17:15.040 --> 02:17:17.920]   That's right next to me getting arrested.
[02:17:17.920 --> 02:17:22.880]   It looks just like me.
[02:17:22.880 --> 02:17:23.680]   That's pretty good.
[02:17:23.680 --> 02:17:24.960]   That's up for the lips.
[02:17:24.960 --> 02:17:28.480]   I'm getting arrested for too much collagen, I think.
[02:17:28.480 --> 02:17:29.600]   And damn it, mom.
[02:17:29.600 --> 02:17:33.600]   Here I am about to cry.
[02:17:33.600 --> 02:17:35.200]   I don't want to go to you.
[02:17:35.200 --> 02:17:36.960]   Hey, what?
[02:17:36.960 --> 02:17:38.560]   Can we use this for my new headshot?
[02:17:38.560 --> 02:17:40.560]   I think this is good.
[02:17:40.560 --> 02:17:41.360]   That's so good.
[02:17:41.360 --> 02:17:43.440]   I just signed that.
[02:17:43.440 --> 02:17:44.000]   I just signed that.
[02:17:44.000 --> 02:17:47.120]   Wow.
[02:17:47.120 --> 02:17:54.160]   Wait, do you autograph headshots?
[02:17:54.160 --> 02:17:55.760]   Once every five or six years,
[02:17:55.760 --> 02:17:57.280]   people will ask for an autograph.
[02:17:57.280 --> 02:17:58.240]   Oh, that's cool.
[02:17:58.240 --> 02:17:59.600]   It used to be a lot more.
[02:17:59.600 --> 02:18:00.960]   You know, when we were tech TV,
[02:18:00.960 --> 02:18:03.440]   the combined would line up for hours.
[02:18:03.440 --> 02:18:07.760]   And me and Kate or Patrick would sign and sign and sign.
[02:18:07.760 --> 02:18:09.440]   But then it was interesting to watch
[02:18:09.440 --> 02:18:11.280]   because it slowly transformed.
[02:18:11.280 --> 02:18:13.680]   That was the late '90s, early 2000s.
[02:18:13.680 --> 02:18:15.920]   Then people started bringing digital cameras.
[02:18:15.920 --> 02:18:17.600]   In fact, I remember people with the Mavicas,
[02:18:17.600 --> 02:18:19.680]   they would write to a floppy disk.
[02:18:19.680 --> 02:18:22.080]   So there would be five, 10 minutes even.
[02:18:22.080 --> 02:18:24.480]   Oh, there.
[02:18:24.480 --> 02:18:25.040]   Okay.
[02:18:25.040 --> 02:18:26.000]   Hold on.
[02:18:26.000 --> 02:18:30.960]   But over time, I got faster, faster.
[02:18:30.960 --> 02:18:32.720]   Pretty soon, everybody had camera phones.
[02:18:32.720 --> 02:18:34.480]   And at some point it flipped,
[02:18:34.480 --> 02:18:35.760]   nobody wanted an autograph anymore.
[02:18:35.760 --> 02:18:37.280]   They just wanted a selfie.
[02:18:37.280 --> 02:18:37.760]   Selfie.
[02:18:37.760 --> 02:18:39.040]   That's only one nowadays.
[02:18:39.760 --> 02:18:42.560]   But if somebody writes in and asks,
[02:18:42.560 --> 02:18:44.640]   you know, says, please send us a picture, I will.
[02:18:44.640 --> 02:18:45.280]   And we do that for you.
[02:18:45.280 --> 02:18:47.440]   I think we all should have an autograph picture, will.
[02:18:47.440 --> 02:18:47.760]   Yeah.
[02:18:47.760 --> 02:18:50.080]   I will send you a free.
[02:18:50.080 --> 02:18:50.320]   Yeah.
[02:18:50.320 --> 02:18:52.720]   I always tell people though,
[02:18:52.720 --> 02:18:54.880]   I don't want to see this in the trash as I'm going out.
[02:18:54.880 --> 02:18:56.880]   Please throw it out later.
[02:18:56.880 --> 02:18:59.920]   Like my photo is framed there in a place of water.
[02:18:59.920 --> 02:19:00.800]   Say again?
[02:19:00.800 --> 02:19:04.080]   SAO, oh, that's right.
[02:19:04.080 --> 02:19:06.480]   You don't have, we'll pay that we can pay.
[02:19:06.480 --> 02:19:07.040]   No, all right.
[02:19:07.680 --> 02:19:09.680]   John says, send us a self-interest, stand, bevelop.
[02:19:09.680 --> 02:19:10.240]   So he's right.
[02:19:10.240 --> 02:19:10.240]   He's right.
[02:19:10.240 --> 02:19:11.280]   With your request.
[02:19:11.280 --> 02:19:12.960]   Problem is, it's never a big enough envelope,
[02:19:12.960 --> 02:19:14.560]   so they get this full of the building.
[02:19:14.560 --> 02:19:17.920]   Here is, by the way, Stacy, you'll be glad to know
[02:19:17.920 --> 02:19:21.120]   the designs have already begun for the punch Leo box.
[02:19:21.120 --> 02:19:25.200]   Man, do you want the open fist with the thumb inside or?
[02:19:25.200 --> 02:19:27.360]   Well, that's punching your rear end.
[02:19:27.360 --> 02:19:31.840]   Stacy's muted herself.
[02:19:31.840 --> 02:19:33.680]   I like your headshot.
[02:19:33.680 --> 02:19:35.440]   I like my headshot.
[02:19:36.240 --> 02:19:41.760]   Well, but that's, we'll see, I fed an actual image of mine into it.
[02:19:41.760 --> 02:19:44.080]   Yeah, and I think that's what Anthony did.
[02:19:44.080 --> 02:19:45.920]   Because this now looks a lot more like me.
[02:19:45.920 --> 02:19:47.200]   Anthony must have taken the...
[02:19:47.200 --> 02:19:48.640]   Hey, what happened?
[02:19:48.640 --> 02:19:49.840]   I changed.
[02:19:49.840 --> 02:19:50.800]   It just changed.
[02:19:50.800 --> 02:19:52.400]   Yeah, I can have any expression.
[02:19:52.400 --> 02:19:53.040]   Oh, I see.
[02:19:53.040 --> 02:19:53.280]   Oh.
[02:19:53.280 --> 02:19:55.120]   You want, as long as it's terror.
[02:19:55.120 --> 02:19:57.760]   Looks just like me.
[02:19:57.760 --> 02:19:59.600]   As long as it's not flattering.
[02:19:59.600 --> 02:20:01.680]   As long as it's ugly, that's what you get.
[02:20:01.680 --> 02:20:04.560]   I love this.
[02:20:04.560 --> 02:20:05.280]   I want this.
[02:20:05.280 --> 02:20:05.920]   That's great.
[02:20:05.920 --> 02:20:07.440]   Anthony, let's use that from now on.
[02:20:07.440 --> 02:20:09.120]   Batch.
[02:20:09.120 --> 02:20:09.120]   Batch.
[02:20:09.120 --> 02:20:10.400]   Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah.
[02:20:10.400 --> 02:20:10.880]   Batch shots.
[02:20:10.880 --> 02:20:13.920]   Well, it's that or this.
[02:20:13.920 --> 02:20:15.440]   I use...
[02:20:15.440 --> 02:20:18.000]   Too much.
[02:20:18.000 --> 02:20:18.560]   Too much.
[02:20:18.560 --> 02:20:19.360]   TMI.
[02:20:19.360 --> 02:20:20.080]   TMI?
[02:20:20.080 --> 02:20:21.360]   You don't like the naked ones.
[02:20:21.360 --> 02:20:22.880]   Yeah, we don't want to see the naked ones.
[02:20:22.880 --> 02:20:23.520]   How about this one?
[02:20:23.520 --> 02:20:24.720]   All of those look like paintings.
[02:20:24.720 --> 02:20:28.080]   This one's so creepy because of the hand that's drawn around.
[02:20:28.080 --> 02:20:29.600]   What is, what is, why?
[02:20:29.600 --> 02:20:30.960]   Um, what?
[02:20:30.960 --> 02:20:34.560]   Look at that.
[02:20:34.560 --> 02:20:35.120]   Look at that.
[02:20:35.120 --> 02:20:35.520]   Look at that.
[02:20:35.520 --> 02:20:35.920]   Look at that.
[02:20:35.920 --> 02:20:36.320]   Look at that.
[02:20:36.320 --> 02:20:36.800]   Look at that.
[02:20:36.800 --> 02:20:39.440]   Give me a couple with some traps, man.
[02:20:39.440 --> 02:20:40.000]   Yeah.
[02:20:40.000 --> 02:20:40.400]   Oh, yeah.
[02:20:40.400 --> 02:20:43.040]   Some of them are really, really, uh, look at that.
[02:20:43.040 --> 02:20:44.560]   [LAUGHTER]
[02:20:44.560 --> 02:20:44.880]   Yoke.
[02:20:44.880 --> 02:20:47.600]   That's like the old playing cards.
[02:20:47.600 --> 02:20:48.720]   Here I am as the witcher.
[02:20:48.720 --> 02:20:49.920]   How about that?
[02:20:49.920 --> 02:20:52.240]   I say, that's your magic, the gathering.
[02:20:52.240 --> 02:20:52.960]   Yeah.
[02:20:52.960 --> 02:20:54.640]   I, uh, the witcher.
[02:20:54.640 --> 02:20:57.920]   Don't flatter yourself, Leo.
[02:20:57.920 --> 02:20:59.120]   Come here, come here, come here.
[02:20:59.120 --> 02:20:59.600]   Come here, come here.
[02:20:59.600 --> 02:21:01.120]   That's more likely right there.
[02:21:01.120 --> 02:21:01.600]   Right there.
[02:21:01.600 --> 02:21:02.000]   That's it.
[02:21:03.200 --> 02:21:05.200]   As she brings you back down to the--
[02:21:05.200 --> 02:21:05.760]   What did I say?
[02:21:05.760 --> 02:21:06.240]   I love that.
[02:21:06.240 --> 02:21:06.800]   I love that.
[02:21:06.800 --> 02:21:10.000]   Henry Cavill, I mean, he's quite the specimen.
[02:21:10.000 --> 02:21:10.560]   This is--
[02:21:10.560 --> 02:21:11.520]   Boris.
[02:21:11.520 --> 02:21:13.520]   Like here, let me go ahead and use that trap.
[02:21:13.520 --> 02:21:14.480]   Boris, I am--
[02:21:14.480 --> 02:21:15.280]   I am--
[02:21:15.280 --> 02:21:15.760]   I am--
[02:21:15.760 --> 02:21:16.720]   I am your king.
[02:21:16.720 --> 02:21:17.280]   [LAUGHTER]
[02:21:17.280 --> 02:21:18.880]   Boris the trap.
[02:21:18.880 --> 02:21:19.680]   Please, watch--
[02:21:19.680 --> 02:21:21.280]   I am the end of the line.
[02:21:21.280 --> 02:21:22.080]   Yes.
[02:21:22.080 --> 02:21:23.280]   Last of my line.
[02:21:23.280 --> 02:21:24.720]   Do you have...
[02:21:24.720 --> 02:21:27.840]   a thing?
[02:21:27.840 --> 02:21:29.680]   Antiproids.
[02:21:29.680 --> 02:21:32.880]   I do, um, I do now.
[02:21:32.880 --> 02:21:33.760]   I didn't.
[02:21:33.760 --> 02:21:34.000]   But--
[02:21:34.000 --> 02:21:35.120]   We gave you plenty of time.
[02:21:35.120 --> 02:21:40.400]   I've talked about particle illusion from Boris FX on here
[02:21:40.400 --> 02:21:44.080]   not too long ago, actually, because they had a free standalone version.
[02:21:44.080 --> 02:21:48.320]   Well, they also have a plugin that you pay for,
[02:21:48.320 --> 02:21:50.000]   for an annual subscription.
[02:21:50.000 --> 02:21:52.960]   But now it is 50% off.
[02:21:52.960 --> 02:21:57.280]   If you use promo code PI plugin 50.
[02:21:57.280 --> 02:22:00.400]   So you'll get it for a year for a set of 100 bucks,
[02:22:00.400 --> 02:22:03.200]   or you'll get it, you know, $50 or $45.
[02:22:03.200 --> 02:22:05.520]   I don't even think it's $100 for a year.
[02:22:05.520 --> 02:22:07.120]   But that's a pretty good deal.
[02:22:07.120 --> 02:22:09.600]   If you can use it as a plugin instead of a standalone,
[02:22:09.600 --> 02:22:13.200]   you get a little bit more flexibility
[02:22:13.200 --> 02:22:15.680]   and a little faster workflow.
[02:22:15.680 --> 02:22:16.960]   So--
[02:22:16.960 --> 02:22:18.160]   And you can do your--
[02:22:18.160 --> 02:22:19.440]   Your moral panic.
[02:22:19.440 --> 02:22:20.560]   Very own moral panic.
[02:22:20.560 --> 02:22:21.760]   And that's my--
[02:22:21.760 --> 02:22:21.760]   Yes.
[02:22:21.760 --> 02:22:25.200]   Do your very own moral panic, similar to mine,
[02:22:25.200 --> 02:22:29.840]   and have some good fun with it inside of good old Boris effects.
[02:22:29.840 --> 02:22:30.800]   That's--
[02:22:30.800 --> 02:22:33.040]   How long before these effects companies, though,
[02:22:33.040 --> 02:22:36.720]   are just supplanted by AI, right?
[02:22:36.720 --> 02:22:37.680]   By AI?
[02:22:37.680 --> 02:22:41.440]   Well, again, with the stuff Adobe put out yesterday,
[02:22:41.440 --> 02:22:45.600]   with Firefly, motion graphics are part of the plan.
[02:22:45.600 --> 02:22:46.080]   Yeah.
[02:22:46.080 --> 02:22:46.480]   Yeah.
[02:22:46.480 --> 02:22:49.280]   Because motion graphics are all in Adobe stock
[02:22:49.280 --> 02:22:50.480]   that people have uploaded.
[02:22:50.480 --> 02:22:56.000]   And it's been training since all of those things have been uploaded.
[02:22:56.000 --> 02:22:56.960]   So, yeah.
[02:22:56.960 --> 02:22:57.840]   It's--
[02:22:57.840 --> 02:22:59.680]   Boris, the blend says--
[02:23:00.560 --> 02:23:00.800]   I like--
[02:23:00.800 --> 02:23:02.880]   Yes, Stacy.
[02:23:02.880 --> 02:23:04.800]   Oh, does your audience--
[02:23:04.800 --> 02:23:05.600]   Is your audience--
[02:23:05.600 --> 02:23:06.720]   Do they have new parents?
[02:23:06.720 --> 02:23:08.320]   Do you think there are lots of new parents
[02:23:08.320 --> 02:23:09.520]   and your people with babies?
[02:23:09.520 --> 02:23:10.880]   That's--
[02:23:10.880 --> 02:23:11.680]   Yeah.
[02:23:11.680 --> 02:23:13.920]   In fact, many of our hosts have new babies.
[02:23:13.920 --> 02:23:15.440]   Jonathan Ben, just had a baby.
[02:23:15.440 --> 02:23:16.480]   OK.
[02:23:16.480 --> 02:23:18.240]   Congratulations to you, Mr. Ben.
[02:23:18.240 --> 02:23:19.280]   Uh, Luma Resk.
[02:23:19.280 --> 02:23:20.560]   And keeps having babies.
[02:23:20.560 --> 02:23:21.280]   Can't stop.
[02:23:21.280 --> 02:23:21.680]   Uh--
[02:23:21.680 --> 02:23:24.320]   Can't stop willing to stop.
[02:23:24.320 --> 02:23:27.360]   We've got a sweet 16 basketball score.
[02:23:27.360 --> 02:23:29.280]   Alex Wilhelm just had a baby.
[02:23:29.280 --> 02:23:31.440]   We have a lot of people having babies around here.
[02:23:31.440 --> 02:23:32.080]   Yeah.
[02:23:32.080 --> 02:23:34.480]   So, Ember, you know, the people who make the coffee mug
[02:23:34.480 --> 02:23:35.600]   that I get so excited about?
[02:23:35.600 --> 02:23:36.080]   Yeah.
[02:23:36.080 --> 02:23:36.880]   They've a baby warm--
[02:23:36.880 --> 02:23:37.920]   They now two weeks ago.
[02:23:37.920 --> 02:23:39.760]   They launched a baby bottle--
[02:23:39.760 --> 02:23:40.080]   Wummer.
[02:23:40.080 --> 02:23:41.600]   Which--
[02:23:41.600 --> 02:23:42.880]   OK.
[02:23:42.880 --> 02:23:45.040]   I need a USB baby.
[02:23:45.040 --> 02:23:45.600]   Game teacher.
[02:23:45.600 --> 02:23:46.560]   Baby bottle--
[02:23:46.560 --> 02:23:47.040]   Baby, just for--
[02:23:47.040 --> 02:23:47.440]   Baby bottle, Warner.
[02:23:47.440 --> 02:23:49.120]   This is actually a good idea.
[02:23:49.120 --> 02:23:49.360]   Yeah.
[02:23:49.360 --> 02:23:51.200]   So, that's why I was--
[02:23:51.200 --> 02:23:52.560]   I was like, that should be my thing,
[02:23:52.560 --> 02:23:53.600]   except it's--
[02:23:53.600 --> 02:23:54.080]   I felt like it was pretty--
[02:23:54.080 --> 02:23:55.440]   You should have saved that.
[02:23:55.440 --> 02:23:56.480]   That should have saved that.
[02:23:56.480 --> 02:23:56.640]   Sorry.
[02:23:56.640 --> 02:23:57.840]   Well, it's 400 bucks.
[02:23:57.840 --> 02:23:59.600]   It's 400 bucks, yeah.
[02:23:59.600 --> 02:23:59.920]   Yikes.
[02:23:59.920 --> 02:24:03.040]   This is like the snoo category.
[02:24:03.040 --> 02:24:05.280]   But if you're like--
[02:24:05.280 --> 02:24:05.680]   You know what?
[02:24:05.680 --> 02:24:06.400]   This would be--
[02:24:06.400 --> 02:24:08.160]   Because, you know, like I said,
[02:24:08.160 --> 02:24:11.120]   a lot of our employees, friends, and family
[02:24:11.120 --> 02:24:14.480]   having babies, this might be a nice twit gift
[02:24:14.480 --> 02:24:15.920]   for somebody like Jonathan Ben.
[02:24:15.920 --> 02:24:17.120]   That's a baby going to college.
[02:24:17.120 --> 02:24:19.280]   I'm going to send this to Lisa,
[02:24:19.280 --> 02:24:22.400]   because I bet you she would love to pass this
[02:24:22.400 --> 02:24:23.360]   along to Baby Ruth.
[02:24:23.360 --> 02:24:24.080]   You can do it first.
[02:24:24.080 --> 02:24:25.280]   Self-warming baby bottle.
[02:24:25.280 --> 02:24:27.600]   Of our self-warming baby bottle.
[02:24:27.600 --> 02:24:29.120]   I did technology safely.
[02:24:29.120 --> 02:24:30.880]   Aunt, would you rather listen to that?
[02:24:30.880 --> 02:24:31.840]   I'm sure.
[02:24:31.840 --> 02:24:32.560]   Every time.
[02:24:32.560 --> 02:24:34.320]   Or this.
[02:24:34.320 --> 02:24:35.360]   This is the whole dome.
[02:24:35.360 --> 02:24:37.360]   The bottle's--
[02:24:37.360 --> 02:24:38.640]   It's a rhetorical question, sir.
[02:24:38.640 --> 02:24:42.880]   Ladies and gentlemen, yes.
[02:24:42.880 --> 02:24:43.920]   That concludes.
[02:24:43.920 --> 02:24:45.200]   Play it again, Sam.
[02:24:45.200 --> 02:24:47.040]   That's exciting.
[02:24:47.040 --> 02:24:49.920]   Thrilling gripping edition of this week
[02:24:49.920 --> 02:24:51.680]   in Leo's neurotic.
[02:24:51.680 --> 02:24:53.440]   Obsession.
[02:24:53.440 --> 02:24:57.360]   [INAUDIBLE]
[02:24:57.360 --> 02:24:58.640]   So beautiful.
[02:24:58.640 --> 02:24:59.440]   I love it.
[02:24:59.440 --> 02:25:00.240]   I love it.
[02:25:00.240 --> 02:25:01.360]   That's Aunt Pruitt, maybe.
[02:25:01.360 --> 02:25:03.440]   Hands-on photography.
[02:25:03.440 --> 02:25:06.080]   Auntprout.com/prink.
[02:25:06.080 --> 02:25:07.120]   Yes, a foe.
[02:25:07.120 --> 02:25:08.080]   Yes, a foe.
[02:25:08.080 --> 02:25:11.520]   Baby, TC, as we watch all of the planes come in.
[02:25:11.520 --> 02:25:13.760]   Who your jazz wins.
[02:25:13.760 --> 02:25:14.560]   Battle Andy.
[02:25:14.560 --> 02:25:16.160]   30 mile an hour, the best.
[02:25:16.160 --> 02:25:19.120]   It's the quiet storm of the two.
[02:25:19.120 --> 02:25:20.640]   Play C-Tac.
[02:25:20.640 --> 02:25:22.000]   Right now.
[02:25:22.000 --> 02:25:26.000]   Hey, I can make you fan of these.
[02:25:26.000 --> 02:25:29.120]   Twit.tv/hands-on photography.
[02:25:29.120 --> 02:25:30.880]   Thank you, Mr. P.
[02:25:30.880 --> 02:25:32.800]   Thanks to you, Jeff Jarvis,
[02:25:32.800 --> 02:25:35.760]   the director of the Townlight Center for Entrepreneurial Journalism at the--
[02:25:35.760 --> 02:25:42.560]   Graduate School of Journalism at the City University of New York.
[02:25:42.560 --> 02:25:45.600]   I hope you have a wonderful afternoon.
[02:25:45.600 --> 02:25:47.360]   We will see you next week before you go on.
[02:25:47.360 --> 02:25:48.400]   I'll be back next week.
[02:25:49.280 --> 02:25:51.200]   With all the smart,
[02:25:51.200 --> 02:25:52.240]   "ATC South."
[02:25:52.240 --> 02:25:57.520]   And ladies and gentlemen, I thank you very much, Miss--
[02:25:57.520 --> 02:25:59.360]   Oh, look at this.
[02:25:59.360 --> 02:26:00.000]   Here I am.
[02:26:00.000 --> 02:26:00.800]   Going to jail.
[02:26:00.800 --> 02:26:01.360]   That's a nice one.
[02:26:01.360 --> 02:26:02.320]   Going to jail.
[02:26:02.320 --> 02:26:03.360]   You're going to enjoy this one.
[02:26:03.360 --> 02:26:04.080]   [Laughter]
[02:26:04.080 --> 02:26:04.800]   Going to jail.
[02:26:04.800 --> 02:26:05.920]   Oh, good one.
[02:26:05.920 --> 02:26:06.400]   I'm going--
[02:26:06.400 --> 02:26:07.360]   How did you get that one in?
[02:26:07.360 --> 02:26:08.560]   New York's finest.
[02:26:08.560 --> 02:26:09.680]   New York's finest.
[02:26:09.680 --> 02:26:10.400]   Taking me in.
[02:26:10.400 --> 02:26:11.360]   It's the Perpwalk.
[02:26:11.360 --> 02:26:14.960]   Stacey is at StacyOnIOT.com.
[02:26:16.800 --> 02:26:21.680]   And aren't you feeling better now with the "ATC" in the background?
[02:26:21.680 --> 02:26:24.960]   Listen to her fine podcast with Kevin Tofel,
[02:26:24.960 --> 02:26:25.920]   "IOT Podcast."
[02:26:25.920 --> 02:26:28.880]   Subscribe to her newsletter, get all that stuff.
[02:26:28.880 --> 02:26:29.280]   Fitti.
[02:26:29.280 --> 02:26:31.360]   StaceyOnIOT.com.
[02:26:31.360 --> 02:26:32.960]   Thank you, Stacey.
[02:26:32.960 --> 02:26:35.680]   We thank all of you for joining us.
[02:26:35.680 --> 02:26:38.560]   We do this show every--
[02:26:38.560 --> 02:26:42.480]   I don't know, Wednesday, maybe 2 p.m. Pacific, 5 p.m. Eastern.
[02:26:42.480 --> 02:26:44.000]   The time we started might be Thursday.
[02:26:44.000 --> 02:26:44.400]   You never know.
[02:26:44.400 --> 02:26:44.960]   It would be Thursday.
[02:26:44.960 --> 02:26:46.800]   What booze they're talking about on Windows Weekly.
[02:26:46.800 --> 02:26:47.600]   2,100.
[02:26:47.600 --> 02:26:51.840]   2,100 UTC.
[02:26:51.840 --> 02:26:52.480]   Stop by.
[02:26:52.480 --> 02:26:53.200]   Say hi.
[02:26:53.200 --> 02:26:56.160]   You can watch the live stream at live.twit.tv.
[02:26:56.160 --> 02:27:01.200]   You can get the on-demand versions at the website twit.tv/twig.
[02:27:01.200 --> 02:27:02.880]   You can watch on YouTube.
[02:27:02.880 --> 02:27:05.120]   Of course, you can subscribe in your favorite podcast player.
[02:27:05.120 --> 02:27:06.240]   And get automatically.
[02:27:06.240 --> 02:27:10.880]   The minute it's available, thank you everybody for being here.
[02:27:10.880 --> 02:27:11.920]   Have a wonderful week.
[02:27:11.920 --> 02:27:14.800]   We'll see you next time on this week in Google.
[02:27:14.800 --> 02:27:17.920]   [INDISTINCT CONVERSATION]
[02:27:17.920 --> 02:27:19.680]   This is her captain speaking.
[02:27:19.680 --> 02:27:23.600]   Just sit back and enjoy.
[02:27:23.600 --> 02:27:26.640]   You guys do the official invocation.
[02:27:26.640 --> 02:27:28.560]   If that was my captain, I get very nervous.
[02:27:28.560 --> 02:27:28.960]   Sit back.
[02:27:28.960 --> 02:27:29.520]   [LAUGHTER]
[02:27:29.520 --> 02:27:30.400]   Very nervous.
[02:27:30.400 --> 02:27:31.040]   Relax.
[02:27:31.040 --> 02:27:35.360]   If you love all things, Android, well, I've got a show for you to check out.
[02:27:35.360 --> 02:27:36.880]   It's called All About Android.
[02:27:36.880 --> 02:27:38.880]   And I'll give you three guesses what we talk about.
[02:27:38.880 --> 02:27:42.720]   We talk about Android, the latest news, hardware, apps.
[02:27:42.720 --> 02:27:43.680]   We answer feedback.
[02:27:43.680 --> 02:27:45.840]   It's me, Jason Howell, Ron Richards,
[02:27:45.840 --> 02:27:50.560]   WinTwitDow, and a whole cast of awesome characters talking about
[02:27:50.560 --> 02:27:52.240]   the operating system that we love.
[02:27:52.240 --> 02:27:56.000]   You can find all about Android at twit.tv/aa.
[02:27:56.000 --> 02:28:06.000]   [MUSIC]
[02:28:06.000 --> 02:28:08.060]   you

