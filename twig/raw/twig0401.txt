;FFMETADATA1
title=A New Interface Paradigm for Your Friends
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=401
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.840]   It's time for Twig this week at Google. Jeff Jarvis joins us from the show floor at Facebook's
[00:00:05.840 --> 00:00:11.680]   Developers Conference. F8, we will talk about all the announcements Facebook made today and yesterday
[00:00:11.680 --> 00:00:18.240]   with of course, Jeff, Matthew Ingram from Fortune.com and Stacey Higginbotham Twig is next.
[00:00:18.240 --> 00:00:39.040]   Netcast you love. Ban with for this week in Google is provided by CashFly, C-A-C-H-E-F-L-Y.com.
[00:00:43.280 --> 00:00:50.560]   This is Twig this week in Google. Episode 401 recorded Wednesday April 19th 2017.
[00:00:50.560 --> 00:00:57.440]   A new interface paradigm for your friends. This week in Google is brought to you by LegalZoom.
[00:00:57.440 --> 00:01:01.760]   LegalZoom has helped more than a million people with their DBAs, LLCs,
[00:01:01.760 --> 00:01:07.520]   incorporation and more. Visit LegalZoom.com and enter Twig at checkout for special savings.
[00:01:07.520 --> 00:01:12.960]   And by Rocket Mortgage from Quick and Loans. When it comes to the big decision of choosing
[00:01:12.960 --> 00:01:17.760]   a mortgage lender, work with one that has your best interest in mind. Use Rocket Mortgage for
[00:01:17.760 --> 00:01:23.840]   a transparent, trustworthy home loan process that's completely online at quickandlones.com/twig.
[00:01:23.840 --> 00:01:31.600]   And by nature box, delicious snacks made from high quality ingredients. Eat well and feel better.
[00:01:31.600 --> 00:01:35.840]   Visit naturebox.com/twit to save 50% on your first order.
[00:01:35.840 --> 00:01:42.560]   It's time for Twig this week in Google. Which will be probably a lot of this week in Facebook.
[00:01:42.560 --> 00:01:49.360]   This week. Joining us from Google's, I'm sorry, Facebook's F8 developers conference. Jeff Jarvis,
[00:01:49.360 --> 00:01:53.680]   he's in the lobby right now. Sounds like he's coming to us via Gemini 8. Somebody in the
[00:01:53.680 --> 00:01:59.440]   charm said, but that's good enough. We'll take it. Thank you. Thank you. For being here. He's
[00:01:59.440 --> 00:02:02.160]   stepped away from the media stage. You were presenting a moments ago.
[00:02:02.160 --> 00:02:05.520]   About the news integrity initiative we talked about last week.
[00:02:05.520 --> 00:02:11.840]   But there's a lot of interest in that. I hope so, yeah. Facebook's a partner in that, of course.
[00:02:12.800 --> 00:02:20.800]   Also with us, of course, Stacey Higginbotham, StaceyOnIOT.com and IOTPodcast.com from Austin, Texas.
[00:02:20.800 --> 00:02:27.200]   Which is where Jeff's going to be tomorrow, I guess. So you're going to invite you in Jeff
[00:02:27.200 --> 00:02:32.400]   over and have a barbecue. Breakfast tacos. Breakfast tacos. That sounds good.
[00:02:32.400 --> 00:02:41.200]   And from fortune.com, Matthew Ingram is also here from the Northern regions of
[00:02:41.840 --> 00:02:48.240]   Canada. And we're all here to talk about, of course, many, many things. But let's first get a
[00:02:48.240 --> 00:02:55.840]   report from F8. We covered the keynote yesterday and a lot of attention paid to a couple of things.
[00:02:55.840 --> 00:03:02.160]   Mark Zuckerberg and company announced a new platform in the Facebook app for
[00:03:02.160 --> 00:03:08.480]   A. Augmented Reality using the camera platform in the sense that developers will have a way to
[00:03:08.480 --> 00:03:12.800]   access the camera and information and add filters and things to it. Some people said it was really
[00:03:12.800 --> 00:03:18.480]   a catch up to Snapchats, filters and world filters. Snapchat announced the day before.
[00:03:18.480 --> 00:03:25.440]   They also announced the VR Spaces, which is a beta version of an Oculus Rift program that allows
[00:03:25.440 --> 00:03:31.280]   you to finally be in the same space as somebody else wearing Oculus Rift and interact with them.
[00:03:31.280 --> 00:03:33.520]   So what do you think, Jeff?
[00:03:34.560 --> 00:03:39.680]   So I think Farhad Monashu in the Times this morning had the best piece that I've read and
[00:03:39.680 --> 00:03:43.600]   probably the best thing I think he's ever written about Facebook today. And he starts off, I'm
[00:03:43.600 --> 00:03:47.760]   never going to like it very much. We start on saying, yeah, okay, so Mark's a thief. So they
[00:03:47.760 --> 00:03:51.280]   took this stuff from Snapchat and they took other stuff from other places. They bought other companies.
[00:03:51.280 --> 00:03:59.120]   But then by the end, he says, and so what? Steve Jobs stole, Bill Gates stole. This is where it is.
[00:04:00.000 --> 00:04:05.200]   The power of Facebook is the network. And I think he was really right. Chris Cox showed a good slide
[00:04:05.200 --> 00:04:11.200]   yesterday and the keynote notes where he showed one axis was how they go from one-on-one relationships
[00:04:11.200 --> 00:04:18.240]   to your community up through your geography to the media to the government. And on the other
[00:04:18.240 --> 00:04:22.400]   axis was all the tools they have from text to photos all the way to AR/VR. But what really
[00:04:22.400 --> 00:04:26.480]   struck me is they missed a third axis. And a third axis is what Facebook really is,
[00:04:26.480 --> 00:04:30.000]   which is that it connects people to people. And that's what Farhod is really talking about.
[00:04:30.000 --> 00:04:34.960]   That's the power of Facebook. That allows them to do anything they want. So yeah, they took
[00:04:34.960 --> 00:04:41.760]   features from Snapchat. Top, it's a better world. And maybe they weren't the most innovative in
[00:04:41.760 --> 00:04:46.000]   the world. Maybe they're following, but they have the network that is phenomenal. And so yes,
[00:04:46.000 --> 00:04:48.720]   they have the power to bring Rainbow Puke to the world.
[00:04:48.720 --> 00:04:55.120]   Right. Well, you know, our minds may have, Matthew, is Microsoft in his heyday in the 90s.
[00:04:55.120 --> 00:04:59.520]   Yeah, they embraced it. Embrace the next 10. Yeah, exactly. Yeah, that's exactly what I thought
[00:04:59.520 --> 00:05:06.720]   up to. And, you know, to be fair, I think they did copy stories, right? They copied it whole,
[00:05:06.720 --> 00:05:12.560]   it's bolus. They've copied lots of other things. But what they are talking about with
[00:05:12.560 --> 00:05:18.160]   augmented reality, they didn't just develop that stuff a week ago because they saw that
[00:05:18.160 --> 00:05:22.880]   Snapchat was working on it. These are things that Facebook and just about everyone I think
[00:05:22.880 --> 00:05:29.040]   has been thinking about for quite some time. So it does look as though, you know, they're duplicating
[00:05:29.040 --> 00:05:33.760]   things that Snapchat is doing. I think they both seem to be moving along the same track, which is
[00:05:33.760 --> 00:05:40.480]   to use the camera as the easiest sort of interface to a virtual world. That just makes sense.
[00:05:40.480 --> 00:05:48.640]   They've also their vision, I think, goes significantly farther than Snapchat's has or at least has so far.
[00:05:48.640 --> 00:05:54.400]   So are they duplicating each other? Yes. But I don't think it's just Facebook is out of ideas.
[00:05:54.400 --> 00:05:59.840]   And so they're copying whatever Snapchat does. Farhad Manju quotes Miranda Carr, Evan Spiegles,
[00:05:59.840 --> 00:06:05.520]   a fiance in an interview with The Times of London. She said she couldn't stand Facebook's behavior.
[00:06:05.520 --> 00:06:10.000]   Can they not innovate? Do they have to steal all of my partner's ideas? She asked,
[00:06:10.000 --> 00:06:14.720]   when you directly copy someone, that's not innovation, to which I say writes farhad.
[00:06:14.720 --> 00:06:18.320]   Man, there are lots of different kinds of innovation in the tech industry.
[00:06:18.320 --> 00:06:23.520]   Coming up with something first is not the only kind. One of the reasons Microsoft got dinged for
[00:06:23.520 --> 00:06:30.880]   this or is it dunged for this? Dunged is because it didn't, it looked like they were being a bully,
[00:06:30.880 --> 00:06:36.080]   right? They used their market share to invest, you know, to approach companies.
[00:06:36.080 --> 00:06:40.720]   Say we'd like to see more of that and then and then steal it. Or they'd buy companies that
[00:06:40.720 --> 00:06:45.760]   were competitive and engulf them. And I to some degree, Facebook's done this.
[00:06:45.760 --> 00:06:50.400]   But I don't think Facebook's being a bully here. And I think you're right, Jeff, that they had to
[00:06:50.400 --> 00:06:55.440]   have been working on this all along. It wasn't like, oh, we like this worldviews. Can we do that tomorrow?
[00:06:55.440 --> 00:07:00.880]   Right. The innovation they showed today in the keynote, when they talked about
[00:07:00.880 --> 00:07:06.000]   direct connections to your brain and AR glasses in our lifetime, that they're comfortable and
[00:07:06.000 --> 00:07:12.720]   really work. And and another thing is that show that they are truly innovating in gigantic ways.
[00:07:12.720 --> 00:07:17.760]   And Snapchat, unless their soul came up with a mechanism that young people like to communicate
[00:07:17.760 --> 00:07:21.280]   with each other, they did a brilliant job of it. But in a competitive world, you see the best
[00:07:21.280 --> 00:07:26.480]   ideas and you use them. How innovative is Facebook? We'll see over the next 20 years. It's only just
[00:07:26.480 --> 00:07:32.880]   how does bar mitzvah. Well, you mentioned that today's speech that the CTO of Facebook was there
[00:07:32.880 --> 00:07:38.000]   and did a good job of mapping out the future. But there also was towards the end. And this is a
[00:07:38.000 --> 00:07:44.320]   little bit of flying car stuff, right? But we have a clip of I'm not sure who it is, but I'm sure
[00:07:44.320 --> 00:07:49.200]   she'll be identified in the clip talking about typing with your mind and listening with your
[00:07:49.200 --> 00:07:55.520]   skin. Let's take a look. The head of building eight, who's the Wowie left Regina done Regina done.
[00:07:55.520 --> 00:08:04.720]   Yeah, she cannot move or speak. But she is typing with her mind, not with eye blanks with her mind.
[00:08:04.720 --> 00:08:14.160]   An array of electrodes, the size of a P has been implanted where her brain would normally control
[00:08:14.160 --> 00:08:22.960]   her motor functions. The electrodes record her neurons firing when she imagines moving the cursor.
[00:08:22.960 --> 00:08:31.120]   Then the computer learns to move it for her. Using this system, she can type eight words per minute.
[00:08:31.120 --> 00:08:41.200]   She is typing at eight words per minute directly with her brain. That is pretty impressive.
[00:08:41.200 --> 00:08:49.280]   Now this Regina Dugan, she also talked a little bit about listening with your skin. This is not,
[00:08:50.720 --> 00:08:58.160]   by the way, she was at the ATAP group at Google. And the director of DARPA, she only joined Facebook
[00:08:58.160 --> 00:09:01.040]   recently, right? I think fairly recently, maybe a year ago.
[00:09:01.040 --> 00:09:07.440]   So I did mention that I'm not sure people typing with their mind exactly what they're thinking on
[00:09:07.440 --> 00:09:12.400]   Facebook is going to be a great development for humanity. It's a little too close to that already.
[00:09:13.200 --> 00:09:23.760]   Yeah. Nothing in the no inhibition whatsoever. You Jeff were talking today about the TOW
[00:09:23.760 --> 00:09:32.240]   initiative that you're doing along with Craig, Newmark and Facebook, and a few other partners to
[00:09:32.240 --> 00:09:38.000]   improve integrity in the news. What's the reaction to your talk today?
[00:09:38.000 --> 00:09:42.080]   I don't know because I ran out of the room to come here. So it looks like suspiciously escaping.
[00:09:42.080 --> 00:09:49.680]   He's dressed in black and he ran out. Yeah. I hope they knew that I was not escaping the
[00:09:49.680 --> 00:09:55.280]   wrath of the media. There were shakes of head and other things. And Facebook to its credit is
[00:09:55.280 --> 00:10:00.480]   trying to be more open about its roadmap with publishers. The session I was just in is off
[00:10:00.480 --> 00:10:05.040]   the record, so I can't say anything. But I know that we publishers have been asking for. They
[00:10:05.040 --> 00:10:09.360]   just said they're going to do and they're listening to publishers more. There's a long way to go still,
[00:10:09.360 --> 00:10:16.720]   but I think we see progress. I give Google credit to first starting this path and setting the way.
[00:10:16.720 --> 00:10:20.480]   I think both platforms are trying very hard to make friends in media and
[00:10:20.480 --> 00:10:25.120]   proofs of the point and we'll see. But it's also up to us to collaborate with them.
[00:10:25.120 --> 00:10:30.640]   Yeah. I mean, some of the so we have a broad mix of stuff from today's keynote. You said today
[00:10:30.640 --> 00:10:35.680]   we go and we unfortunately we chose to cover the first day keynote. Maybe not unfortunately,
[00:10:35.680 --> 00:10:39.760]   because that was the announcement of some big new Facebook technologies that you can use right now.
[00:10:39.760 --> 00:10:47.600]   I love Facebook's forward looking stuff. They really do a good job investing much like Google.
[00:10:47.600 --> 00:10:51.440]   Remember back in the day, we were like Google's infrastructure is really
[00:10:51.440 --> 00:10:56.400]   competitive advantage. I know. Google Island.
[00:10:57.600 --> 00:11:04.080]   Yeah. But let's face it. Facebook has a lot of failures under its belt too. Far more failures
[00:11:04.080 --> 00:11:10.400]   than successes. Yeah. I think they deserve credit for that. They try for a big company.
[00:11:10.400 --> 00:11:16.400]   Yeah. They try and fail at stuff all the time. Right. And they invest so much money in the hardware
[00:11:16.400 --> 00:11:23.840]   infrastructure to get it right and to think about not just their platform and the software side.
[00:11:23.840 --> 00:11:27.280]   They invest in the infrastructure and they're going even further down with their broadband
[00:11:27.280 --> 00:11:32.800]   efforts and not all of that's going to work. But the way they look at the world, they see that
[00:11:32.800 --> 00:11:39.520]   we're moving to this massively distributed computing architecture or infrastructure.
[00:11:39.520 --> 00:11:45.280]   And they're like, okay, how can we make it even extended further and make it more resilient?
[00:11:45.280 --> 00:11:49.040]   And if you look at it in cheaper, I should say in cheaper. Those are kind of the three things.
[00:11:49.760 --> 00:11:55.520]   So Facebook handed out 4,360 degree cameras. Did you get yours, Jeff?
[00:11:55.520 --> 00:11:59.520]   I'm not sure. There's a bag that gave me a thing yesterday that was back in the
[00:11:59.520 --> 00:12:05.680]   hotel. I don't even look at your bag. It's the Joroptic. There's one of two kind of very popular
[00:12:05.680 --> 00:12:12.960]   360 degree cameras. This one attaches to your phone. It came out in December, $250.
[00:12:13.520 --> 00:12:20.880]   1920 by 960. Anyway, get ready for an onslaught of 360. They also showed a new 24 camera and a
[00:12:20.880 --> 00:12:29.520]   six camera rigs for VR for 360, where the 24 camera is high overlap of pixels, which enables them
[00:12:29.520 --> 00:12:35.680]   to basically, they did a lot of work on this with AI and even 2D photos of being able to navigate
[00:12:35.680 --> 00:12:41.760]   around the photo and understand that. They've sort of showed a lot of AI stuff, understanding
[00:12:41.760 --> 00:12:45.360]   people and their actions in a room. Pretty impressive.
[00:12:45.360 --> 00:12:51.760]   This today was obviously a little more VR than yesterday. Yesterday really was about AR.
[00:12:51.760 --> 00:12:55.760]   It almost felt like a somewhat of a pivot. Of course, they acquired three years ago,
[00:12:55.760 --> 00:13:03.120]   they acquired Oculus Rift. Nominally, a VR company, but as many have pointed out, VR is just a subset
[00:13:03.120 --> 00:13:09.040]   of what AR can do. And they really talked a lot about AR yesterday.
[00:13:10.080 --> 00:13:16.000]   And more than just Snapchat style filters, although I imagine the first things we'll see will be
[00:13:16.000 --> 00:13:21.840]   mostly that. I actually think if Facebook got anything from Snapchat,
[00:13:21.840 --> 00:13:26.800]   it was my sense is, I don't have any inside of information on this, but my sense is that what
[00:13:26.800 --> 00:13:33.760]   they got was in the short term, particularly for augmented reality, we should just stick to the
[00:13:33.760 --> 00:13:41.600]   camera. Everybody's got one. It's relatively easy to do. So instead of leaping forward to headsets
[00:13:41.600 --> 00:13:47.120]   and eyeglasses and so on, even Zuckerberg said, "We decided some interesting stuff is happening
[00:13:47.120 --> 00:13:51.840]   with the camera." It's right here in your hand. Let's see what we can do with that.
[00:13:51.840 --> 00:13:58.400]   He even said the camera box is more important than the text box at input. And that's certainly
[00:13:58.400 --> 00:14:03.840]   a another Snapchat view, but you're right, the camera is the mechanism to augment the world.
[00:14:03.840 --> 00:14:12.640]   It's something in everybody's hand right now. I suspect this is Apple's plan to this fall with
[00:14:12.640 --> 00:14:21.040]   the next iPhone. So this is, I mean, it's clearly kind of entry level tech, just as Oculus Rift,
[00:14:21.040 --> 00:14:23.840]   frankly, is entry level VR tech. But everybody has it.
[00:14:25.840 --> 00:14:32.560]   So I don't plan to be puking Rainbow soon or putting headsets on. Stacy, what do you think
[00:14:32.560 --> 00:14:36.640]   your daughter is going to think of this AR stuff on Facebook? Is it old hat? Is it new?
[00:14:36.640 --> 00:14:43.760]   Well, so my daughter won't be on Facebook is my guess. It'll be like her equivalent of LinkedIn
[00:14:43.760 --> 00:14:48.240]   or something. I don't know. You know, I thought that too. We had a bunch of high school kids from
[00:14:48.240 --> 00:14:54.720]   Perth, Australia, and yesterday. And Megan thought, as I did, probably most of them are using Snapchat.
[00:14:54.720 --> 00:14:59.200]   Maybe they're using Instagram, but they're unlikely to be using their parents' social network.
[00:14:59.200 --> 00:15:04.080]   Every one of them is on Facebook. And this is, I think, to Farhan Manju's point, which is
[00:15:04.080 --> 00:15:10.400]   the size and scope of the Facebook network is such that even if you don't like embrace it,
[00:15:10.400 --> 00:15:13.840]   because your parents are there also, you can't not be on there.
[00:15:13.840 --> 00:15:23.840]   Our teenage daughter quit, quit, deleted her account. She was, I think, 17. And within a
[00:15:23.840 --> 00:15:27.840]   matter of months, she had started her account again. Everybody hates Facebook.
[00:15:27.840 --> 00:15:33.440]   She didn't want to be there, but she felt like she had to be. So it's like email is for us.
[00:15:33.440 --> 00:15:38.240]   You have to do it. Yeah. So I suspect, and I don't, you know, this is the very interesting
[00:15:38.240 --> 00:15:44.240]   question. You're supposing Stacy that in 10 years, while your daughter is what, seven, so in six years.
[00:15:44.240 --> 00:15:44.800]   She's 10.
[00:15:44.800 --> 00:15:50.800]   10. Oh, well, sooner than you think. There'll be something else just as Facebook replaced my
[00:15:50.800 --> 00:15:54.800]   space. But I think you do get to a point with the network effect where when you have two,
[00:15:54.800 --> 00:15:58.640]   nearly two billion monthly active users, it's pretty hard for somebody else to come along and
[00:15:58.640 --> 00:16:04.720]   steal them away. I think I think what will happen is we'll graduate beyond these fake social networks
[00:16:04.720 --> 00:16:10.240]   that are like Facebook. So what will happen isn't that there'll be another Facebook. There's going to
[00:16:10.240 --> 00:16:18.880]   be just something that's a better evolution. And maybe it's like, and I think Facebook's right to
[00:16:18.880 --> 00:16:25.280]   focus on the camera, if only because there are plenty of times when, think about how voice
[00:16:25.280 --> 00:16:30.480]   evolved you started out just asking for, I remember trying speech to text kind of commands
[00:16:30.480 --> 00:16:38.000]   back in like 2008. And they were clunky and lame. And you just say something and it would happen.
[00:16:38.000 --> 00:16:40.960]   I think you're going to get to these points where, yeah, you see something and you're like,
[00:16:40.960 --> 00:16:43.760]   if you hold your camera up in front of it, you're going to be like, oh, look, there's something
[00:16:43.760 --> 00:16:50.320]   there and it's more information. And then it'll gradually envelop more and more things. And then
[00:16:50.320 --> 00:16:56.640]   it'll become instinctive to at some point to look up and be like, oh, hey, look, it felt cool.
[00:16:56.640 --> 00:17:03.200]   And that's when we're going to see the glasses. Yeah. Yeah. I mean, I think if that, if they shipped
[00:17:03.200 --> 00:17:09.840]   those today, wouldn't they sell like hotcakes? I would buy some glasses. Well, wouldn't. I would.
[00:17:09.840 --> 00:17:17.040]   Yeah. So people outside the tech world, like, I mean, think about the Snapchat's glasses and
[00:17:17.040 --> 00:17:22.960]   it sounds really cool. And you and I, and we would all buy them and be like, nifty, but real people
[00:17:22.960 --> 00:17:27.680]   have limited income and they may not want to spend it on what feels like a gimmicky device.
[00:17:27.680 --> 00:17:30.480]   What if when you're buying sunglasses, which you're going to wear anyway,
[00:17:30.480 --> 00:17:36.880]   it happens to have that capability that you can see Yelp reviews or other kinds of information.
[00:17:36.880 --> 00:17:40.960]   I thought that's going to be that's going to be a few years down the road.
[00:17:40.960 --> 00:17:44.080]   Yes, that's exactly how it's going to play out. I think that's what people mean.
[00:17:44.080 --> 00:17:49.760]   Mark Zuckerberg mentioned one of my use cases, which is you're in Italy. You know, you've read
[00:17:49.760 --> 00:17:55.840]   about the Coliseum, but you know zero about it. And you look at it and information pops up about it.
[00:17:55.840 --> 00:18:01.520]   That would be hugely useful. Do you need to buy it? Maybe not. Maybe rent it, but it's still
[00:18:01.520 --> 00:18:08.400]   be hugely useful. Well, you're right. Sorry. I was going to say that gets to this idea of
[00:18:08.400 --> 00:18:15.280]   innovation, who's copying whom, because this is not a new concept. And the key is figuring out
[00:18:15.280 --> 00:18:20.000]   the right time to launch something in the right form factor that people that will get people
[00:18:20.000 --> 00:18:26.640]   adopted. Right. And Facebook has a lot of those advantages. Right. And I think there's one argument.
[00:18:27.600 --> 00:18:32.400]   Now go ahead, Joe. No, Jeff, you're our guest of honor because you're leaving.
[00:18:32.400 --> 00:18:35.360]   No, no, no, no. I apologize. I apologize to everybody for being
[00:18:35.360 --> 00:18:40.640]   workers. Because I can't. There's latency. So I'm trying to call a picture of the things
[00:18:40.640 --> 00:18:45.840]   that are needed for AR glasses to really work. And let me call it this picture because it was a
[00:18:45.840 --> 00:18:54.400]   really interesting line. Well, it's one thing is that today, the pixel density that we can get
[00:18:55.680 --> 00:19:04.560]   is 15 pixels per degree. In the near future will be 120. Field of view is about 90 degrees.
[00:19:04.560 --> 00:19:10.320]   A future will go to 220 to 330. The depth of focus is fixed at two meters in the future.
[00:19:10.320 --> 00:19:18.000]   It'll be variable from 45 centimeters to. Uh oh, we're losing. Whoops. Who lost his signal.
[00:19:18.000 --> 00:19:22.080]   That's all right. We'll continue on. And we'll get him back. Yeah, I mean, it's clear that you
[00:19:22.080 --> 00:19:25.200]   need better batteries because obviously this is good enough to be detached. You need
[00:19:25.200 --> 00:19:29.840]   high speed connectivity everywhere. The one of the things that bothered me a little bit when
[00:19:29.840 --> 00:19:35.600]   in Mark's presentation yesterday is the notion that you could leave little messages and notes
[00:19:35.600 --> 00:19:41.040]   around as you're going around, which is going to really open. I mean, if we think we have problems
[00:19:41.040 --> 00:19:45.600]   with trolling with Twitter right now, at least it's constrained to Twitter. Imagine, uh, you're
[00:19:45.600 --> 00:19:51.680]   want. I mean, it's going to be like digital graffiti everywhere. Right. We have to solve that issue.
[00:19:53.600 --> 00:19:59.920]   And yeah, I'm not sure that that's a that's a great thing is to is to be able to graffiti
[00:19:59.920 --> 00:20:05.440]   the world in augmented reality, no matter, you know, and actually Matt Hohnen. I think it was,
[00:20:05.440 --> 00:20:10.080]   was writing about how Facebook, you know, paints these beautiful pictures about, oh, you could
[00:20:10.080 --> 00:20:15.520]   leave public art in public spaces. You could also paint a swastika, you know, on a famous painting.
[00:20:15.520 --> 00:20:20.880]   I mean, this is going to happen. That's one of the lessons. Let's face it. There'll be penises
[00:20:20.880 --> 00:20:26.560]   everywhere. Yep. Right. Yeah. I mean, this is just one of just kind of one of the lessons I think of
[00:20:26.560 --> 00:20:33.520]   the Facebook killing, if you want to call it, that is, Facebook continually sort of releases these
[00:20:33.520 --> 00:20:39.760]   G with technologies and then has to catch up. Oh my God. Human beings are doing horrible things
[00:20:39.760 --> 00:20:44.880]   with our service. Well, this is the kind of the blind spot. All technologists and I am one of them
[00:20:44.880 --> 00:20:49.920]   have is we get excited. We look at the potential for these new technologies and then we forget that
[00:20:49.920 --> 00:20:55.280]   there are many bad humans that will inevitably find a way to twist this and make it unusable.
[00:20:55.280 --> 00:21:05.360]   And so maybe augmented reality is only great in our dreams. I mean, I guess we now have to be
[00:21:05.360 --> 00:21:10.400]   worried about this. I think you have to think about, you know, you have to be prepared not to get
[00:21:10.400 --> 00:21:14.880]   depressed and think, well, we shouldn't do this because people might do bad things. But you have
[00:21:14.880 --> 00:21:21.440]   to think it through, at least consider what could be some of the bad things and what could you do
[00:21:21.440 --> 00:21:27.120]   to prevent that. And I wonder if maybe Facebook doesn't do that second part as well.
[00:21:27.120 --> 00:21:33.520]   Well, maybe, I mean, it feels like, I know we want this maximum internet like freedom to do what we
[00:21:33.520 --> 00:21:40.320]   want and leave our messages. But what's more likely is that, especially initially, we'll have
[00:21:40.960 --> 00:21:46.240]   maybe it's software platforms or packages that you buy. So if you're going to Italy, maybe you buy
[00:21:46.240 --> 00:21:51.760]   the lonely planets, Italy, AR software. Yeah, they're yeah. Yeah.
[00:21:51.760 --> 00:22:00.160]   I'm not so stressed about that because I don't see, I don't see something like leaving messages
[00:22:00.160 --> 00:22:05.600]   for people actually getting implemented anytime soon. Maybe that's what Facebook offers though. I mean,
[00:22:05.600 --> 00:22:11.520]   Facebook does. So naturally, that's what they're going to show. You know what that reminded me
[00:22:11.520 --> 00:22:16.080]   of was Microsoft Bob. Do you remember you could actually leave little virtual notes?
[00:22:16.080 --> 00:22:22.960]   Well, post it on people's documents. See, that was the reality opportunity missed.
[00:22:22.960 --> 00:22:28.960]   You know, I think it's really interesting that the timing of this is poor from Facebook's point
[00:22:28.960 --> 00:22:34.000]   of view, but it does bring, you know, this Facebook murderer brings home exactly this issue,
[00:22:34.000 --> 00:22:39.440]   which is you can create live video, you can create postable video. But when you have that many users,
[00:22:39.440 --> 00:22:45.920]   it's very difficult to create the safeguards that prevent it from being, you know, a Paul.
[00:22:45.920 --> 00:22:49.760]   And if you go back, you look at what Mark Zuckerberg said when Facebook Live launched,
[00:22:49.760 --> 00:22:55.840]   someone had a quote. He said, this allows you to be unfiltered and to create experiences that are
[00:22:55.840 --> 00:23:00.880]   raw and visceral. Well, that sure is true. Like that sure is what people are doing.
[00:23:00.880 --> 00:23:06.240]   He feels like he's learned his lesson or if he's. I don't know. I doubt it. I mean,
[00:23:06.240 --> 00:23:11.920]   it's I still think he's fundamentally optimistic about these technologies and that's good.
[00:23:11.920 --> 00:23:19.360]   I just don't know like, how do you stop someone from uploading those types of videos? Yeah,
[00:23:19.360 --> 00:23:22.480]   Jeff, are people talking about that Facebook murderer at all there?
[00:23:22.480 --> 00:23:27.440]   I mean, they are. The interesting thing is, is that I think there's a big difference in
[00:23:27.440 --> 00:23:33.280]   expectation. I think that that frankly, some people thought that they actually did a good job
[00:23:33.280 --> 00:23:37.600]   getting that video down in moderately short order. Half about half an hour.
[00:23:37.600 --> 00:23:43.120]   Other people thought, of course, that. Yeah. Some people said that wasn't a good.
[00:23:43.120 --> 00:23:49.440]   Oh, okay. I heard people say that maybe they'd be all video should go to a small group. But
[00:23:49.440 --> 00:23:53.520]   but then the chances of someone reporting something bad are far lessened.
[00:23:56.560 --> 00:24:01.360]   You know, I think those who criticize Facebook on this, yes, they need they
[00:24:01.360 --> 00:24:05.200]   they just as off. You wrote a very good post that went through the TikTok. It was exactly what
[00:24:05.200 --> 00:24:09.680]   happened when I think they're honest about saying they need to get better and that's fine. But
[00:24:09.680 --> 00:24:16.080]   but the extension of the complaints is nobody should have live because one horrible person came
[00:24:16.080 --> 00:24:20.400]   along and did this. I think we wouldn't agree with that. So we live in an imperfect world and
[00:24:20.400 --> 00:24:24.800]   the features that reflect this world will be imperfect along with it. I thought it was interesting.
[00:24:25.360 --> 00:24:32.000]   Like sorry, go ahead, Stace. It correct me if I'm wrong, but there have been one or two cases of
[00:24:32.000 --> 00:24:37.360]   people like attacking news anchors while they were doing live reports. Yes. Oh, yeah. Yeah. So
[00:24:37.360 --> 00:24:44.320]   not just YouTube has had this kind of stuff for like how long now it's true. It's not just Facebook.
[00:24:44.320 --> 00:24:48.160]   That's true. But the difference is Facebook live, although YouTube now has YouTube live.
[00:24:48.160 --> 00:24:53.600]   There's Paris. But this wasn't even live. Right. No, it wasn't. It was reported first. Yeah. He did
[00:24:53.600 --> 00:25:00.080]   go on live later talking about it. The thing I thought was interesting was that video of the
[00:25:00.080 --> 00:25:06.240]   killing was up for an hour before anybody reported it. That's very sweet. Time is not.
[00:25:06.240 --> 00:25:12.320]   Yeah. And the issue there is the public is who does he know? What are their norms? How does this
[00:25:12.320 --> 00:25:18.640]   operate? Facebook, I think as soon as they're alerted will act to re alert them. Does it
[00:25:18.640 --> 00:25:23.360]   the guy? Do you see what I don't see with data on is how many people saw it more than the time
[00:25:23.360 --> 00:25:30.480]   is what was the actual exposure of the thing? So the first video reported the first video went
[00:25:30.480 --> 00:25:36.560]   up at 11.09 a.m. with the intent to murder not reported to Facebook. Second video of the shooting
[00:25:36.560 --> 00:25:43.760]   went up at 11.11 two minutes later. 11.22 the live stream where he confesses to the murder.
[00:25:44.320 --> 00:25:49.840]   11.27 the live stream ends and the live video is first reported shortly after. So there wasn't
[00:25:49.840 --> 00:25:56.640]   a half an hour. It's 16 minutes after the shooting video. The first reporting of the shooting video
[00:25:56.640 --> 00:26:03.200]   was more than an hour later. Was it 1 p.m. It was posted 11.11. It wasn't reported to 1 p.m.
[00:26:03.200 --> 00:26:10.480]   And it took them after it was reported 23 minutes from Facebook to disable the account.
[00:26:10.480 --> 00:26:17.440]   Pretty good. Okay. Is that a pretty good or is that a long time? I guess.
[00:26:17.440 --> 00:26:22.320]   Well, they do it. I assume. Yeah. But how long does it take to review it? I guess there's a
[00:26:22.320 --> 00:26:27.200]   queue of things they have to review. We now know it's a 23 minute queue. I presume because
[00:26:27.200 --> 00:26:32.480]   as soon as you reviewed it, you'd take it down. I mean, could they do better? Obviously. And
[00:26:32.480 --> 00:26:37.360]   I think there's a big debate. Certainly journalists would like there to be
[00:26:38.320 --> 00:26:43.840]   a group of editors who view everything and then say what should go up and what shouldn't. But
[00:26:43.840 --> 00:26:48.240]   the fact is Facebook is never going to do that in a million years. That's ridiculous. That's
[00:26:48.240 --> 00:26:53.520]   not scale. Human beings don't scale. Right. So and AI is never going to really be good at this because
[00:26:53.520 --> 00:26:59.120]   so it goes from 23 minutes to two minutes. That's right. What's the real difference?
[00:26:59.120 --> 00:27:06.160]   You know, we this is the world we we live in. Yeah, a lot of people saw it. A lot of people saw
[00:27:06.160 --> 00:27:12.480]   it tweeted. I mean, I know people who who Twitter autoplay video turned on and were horrified.
[00:27:12.480 --> 00:27:17.200]   Yep. Because it was tweeted. It was on YouTube as well. Yeah. But who would do that?
[00:27:17.200 --> 00:27:21.280]   Well, and it actually took YouTube longer to take it down than it did Facebook.
[00:27:21.280 --> 00:27:26.800]   Who would do that? This is the point. It really is. I won't. People. It's the problem.
[00:27:26.800 --> 00:27:32.560]   And there's been demand on the internet and availability on the internet of, I guess,
[00:27:32.560 --> 00:27:38.080]   snuff films or things. Sure. But this is what happened. We knew this would happen with the
[00:27:38.080 --> 00:27:43.760]   internet. Everything that was hidden under a rock in the hard to get to places is now easily
[00:27:43.760 --> 00:27:47.280]   available. And that's the good, the bad and the ugly. And that's just right. And we know.
[00:27:47.280 --> 00:27:54.560]   And we know that every feature like Facebook Live is going to enable some incredibly wonderful
[00:27:54.560 --> 00:27:59.040]   things. And it's also going to enable some horrible offensive disgusting things.
[00:27:59.600 --> 00:28:04.640]   Because it's a tool. It doesn't have any particular. So here's the other thing today.
[00:28:04.640 --> 00:28:09.440]   I was really surprised. I imagine there are German lawmakers writing laws right now,
[00:28:09.440 --> 00:28:13.520]   because Facebook went over the line that Google has tickled and not gone over.
[00:28:13.520 --> 00:28:19.360]   In today's keynote, they showed AR glasses. They said, and really put up a picture,
[00:28:19.360 --> 00:28:27.520]   you see a face and puts the name next to it. So you say, no, no, no. Well, everybody next to me,
[00:28:27.520 --> 00:28:30.480]   every real person next to me said, yeah, I can't wait. I can't remember names.
[00:28:30.480 --> 00:28:33.120]   Yeah, me too. No, no, but I can't remember names.
[00:28:33.120 --> 00:28:34.000]   I can't remember names. People didn't do that.
[00:28:34.000 --> 00:28:39.440]   I don't want people to be able to have computer aided access to who I am.
[00:28:39.440 --> 00:28:44.800]   Sorry. In their defense, Facebook does have your social graph. And so it would be trivial for
[00:28:44.800 --> 00:28:48.960]   Facebook to say you will only identify people you are friends. Right. Right. That's true.
[00:28:48.960 --> 00:28:51.440]   If you could ask them that way, they should.
[00:28:51.440 --> 00:28:54.560]   They should Google had the tech to do that what two years ago, right? And they
[00:28:55.680 --> 00:29:01.120]   explicitly said, we're not going to turn it on. I mean, sad to say the FBI also has that tech and
[00:29:01.120 --> 00:29:07.040]   whether you turn it on. They sure do. Yeah. So also today, they showed Akila. In fact,
[00:29:07.040 --> 00:29:14.000]   they showed a couple of ways to get internet to people who don't have it. They showed helicopter
[00:29:14.000 --> 00:29:19.680]   emergency internet access. And apparently, Tequila, I'm sorry, not Tequila.
[00:29:20.560 --> 00:29:26.400]   Akila. That's a way better name. I think Tequila would be great. The drone has really
[00:29:26.400 --> 00:29:31.760]   improved using a millimeter wave technology has really improved the bandwidth. They now are 80
[00:29:31.760 --> 00:29:38.880]   gigabits per second. Wow. And it's also been able to establish the 16 gigabit link between a ground
[00:29:38.880 --> 00:29:44.720]   station and a small plane circling five miles away. Watch a few hundred kilometers of
[00:29:45.840 --> 00:29:52.800]   the atmosphere and try to connect that way. So fiber connects to a microwave dish,
[00:29:52.800 --> 00:29:56.960]   a millimeter wave dish, provides connectivity to the first plane. And then other millimeter
[00:29:56.960 --> 00:30:03.760]   wave systems where lasers can interconnect and form a network in the sky. So it's a cool idea.
[00:30:03.760 --> 00:30:09.200]   Sky net. Yeah. Parts of it. Literally. We've actually started to do. So this is our Akila system.
[00:30:09.200 --> 00:30:14.720]   This is a flight from last year. And to me, this was one of the most incredible moments in my life,
[00:30:14.720 --> 00:30:21.200]   where I got to see an aircraft roughly the wingspan of a Boeing 737, the mass one third of a Toyota
[00:30:21.200 --> 00:30:29.360]   Prius running on the power of three blow dryers flying in the air. They use blow dryers. But this
[00:30:29.360 --> 00:30:36.160]   is not a communications network yet. It needs connectivity. It needs a millimeter wave system.
[00:30:36.160 --> 00:30:41.520]   And so we've scoured the earth and tried to find is there a technology that can go in this
[00:30:41.520 --> 00:30:47.760]   aircraft today? And there wasn't. So we had to make a system that was 10 times faster and roughly
[00:30:47.760 --> 00:30:54.720]   10 to 100 times less in terms of mass and power. So I'm really excited that last year,
[00:30:54.720 --> 00:31:04.320]   we announced that we achieved over a 13 kilometer link, a 20 gigabits per second millimeter wave
[00:31:04.320 --> 00:31:11.200]   link. It was a pretty awesome achievement by our team. Okay. That's not as impressive as it sounds.
[00:31:11.200 --> 00:31:16.800]   Old stuff. This is the future. And I'm really pleased to announce that using that same link,
[00:31:16.800 --> 00:31:23.440]   the team almost doubled that rate and achieved 36 gigabits per second over that link. So we beat
[00:31:23.440 --> 00:31:28.560]   our own world record. Is it half duplex? Is that why it's not impressive? So it's not impressive.
[00:31:28.560 --> 00:31:34.800]   We then flew it in a set on the path to getting it into an Achela in which you've 16 gigabits
[00:31:34.800 --> 00:31:41.120]   per second in that system. And then I mentioned optical links that may exist between aircraft
[00:31:41.120 --> 00:31:46.800]   and we actually have built an optical link also on the same 13 kilometer path. And we achieved 80
[00:31:46.800 --> 00:31:52.720]   gigabits per second. All right, pause this for a second. So why should we be less than joy over
[00:31:52.720 --> 00:31:59.760]   joy? It's great. But the technology they're using with the millimeter wave, that is a wavelength
[00:31:59.760 --> 00:32:06.320]   that is affected tremendously by things like rain and clouds and plants. So most of the people in
[00:32:06.320 --> 00:32:10.560]   the satellite world that I've talked to who've looked at these plans are like, this is awesome,
[00:32:10.560 --> 00:32:16.640]   where you don't have cloud cover. And we have a lot of cloud cover. So that's your moment of,
[00:32:16.640 --> 00:32:18.880]   that's my Debbie Downer moment. Reality.
[00:32:18.880 --> 00:32:25.040]   And it is still cool. I'm just like, there's some constraints and like, what's
[00:32:25.040 --> 00:32:32.000]   like, I talked to Jay Perique at Facebook about like how they're doing this and that
[00:32:32.000 --> 00:32:35.600]   the technical accuracy they have to get with these lasers is freaking awesome.
[00:32:35.600 --> 00:32:39.120]   They have to be pretty accurate, right? Because you're aiming for one plane to another. They're
[00:32:39.120 --> 00:32:45.360]   moving around. He said it's like hitting a dime from a, you know, with a, with a gun from miles away.
[00:32:45.360 --> 00:32:52.800]   They also are talking about a small helicopter, almost a drone that can be deployed in emergencies
[00:32:52.800 --> 00:33:00.560]   to provide internet access. They call it Tether Tenna, instant infrastructure in time of crisis.
[00:33:00.560 --> 00:33:05.040]   I'm glad I think it's wonderful. Facebook's working on this. And it is, it's kind of amazing.
[00:33:05.680 --> 00:33:10.480]   You know, Google has scaled back a lot of the similar types of projects, like Project Loon.
[00:33:10.480 --> 00:33:16.960]   And I mean, it's, I think it's great to see Facebook continuing these kinds of things. I imagine.
[00:33:16.960 --> 00:33:23.440]   They scaled it back? Loon? Yeah. Yeah. Yeah. They scaled it back.
[00:33:23.440 --> 00:33:28.720]   Oh, it's another, another casualty of Ruth Porat. Yeah. Shane saw Ruth Porat, we're calling it.
[00:33:28.720 --> 00:33:30.000]   Budget cuts. Yeah.
[00:33:32.000 --> 00:33:36.640]   What else, Jeff, did you think? I mean, you're there. What else are you seeing that you think is
[00:33:36.640 --> 00:33:47.280]   interesting? I think we've hit most of the high points. I think the VR stuff kind of fast
[00:33:47.280 --> 00:33:51.600]   dates me because there's still hot on it, obviously. Oculus is here, but it just didn't, I think you
[00:33:51.600 --> 00:33:56.400]   said it right earlier that VR is just a subset of AR and they're now considering an AR that we
[00:33:56.400 --> 00:34:04.880]   have recognized the difficulty of the equipment problem. So I wonder about the uptake of VR,
[00:34:04.880 --> 00:34:09.280]   just because of a slightly less enthusiastic world for it. We're going to set up, we have
[00:34:09.280 --> 00:34:15.280]   two Oculus Rift systems. And in the next couple of weeks, Nate, all of us, Giles and I are going
[00:34:15.280 --> 00:34:23.120]   to set up spaces and meet each other in this virtual reality space. I know my initial reaction
[00:34:23.120 --> 00:34:27.200]   to this is just pathetic. But yeah, I can't get my head around the valley.
[00:34:27.200 --> 00:34:31.200]   That's what you can do to a Skype call. Yeah, there's so many other ways. Of course,
[00:34:31.200 --> 00:34:34.560]   it doesn't make any sense if you're anywhere near another person, we make
[00:34:34.560 --> 00:34:41.120]   but I guess if Matthew's in Canada and I'm here and we wanted to kind of play ping pong,
[00:34:41.120 --> 00:34:46.480]   we could. We'll see. We'll see. It's an interesting...
[00:34:46.480 --> 00:34:50.160]   I continue. Every time I see these technologies, the first thing I think of is
[00:34:51.040 --> 00:34:57.680]   people who are hospitalized or bedridden or shut-ins. You can't move.
[00:34:57.680 --> 00:35:02.400]   I can see this type of thing being a fantastic experience. Yeah, just incredible.
[00:35:02.400 --> 00:35:07.920]   But for people who can walk around and leave the building, I'm not sure why would you do that?
[00:35:07.920 --> 00:35:16.240]   Here's what I worry about. I already see this with younger kids, our 14-year-old.
[00:35:17.360 --> 00:35:23.280]   He'll play with his friends, but they're at home playing a game or in our Minecraft server or
[00:35:23.280 --> 00:35:28.320]   whatever. They're all in separate places talking to each other. And it makes me a little bit sad.
[00:35:28.320 --> 00:35:33.040]   Well, that's us. That's us old friends. Maybe it's just because I have this preconceived notion.
[00:35:33.040 --> 00:35:39.760]   Those damn kids should go outside. Yeah, they're socializing. They're thrilled.
[00:35:39.760 --> 00:35:44.960]   Yeah. And we'll even... We have a neighbor. One of his best friends is literally
[00:35:45.680 --> 00:35:50.800]   Nextdoor Neighbor. And he'll come over to play and say, "Okay, I'm going to go home and we'll see you online."
[00:35:50.800 --> 00:35:59.440]   Leo, here's my bigger conclusion of coming to this and the lately, the HUHA,
[00:35:59.440 --> 00:36:06.560]   or Fake News, and Hate, and divisiveness in America and the world. I don't know if I said this in the
[00:36:06.560 --> 00:36:12.560]   show before or not, but I think that Facebook may be losing a little bit of a site of its real value,
[00:36:12.560 --> 00:36:16.880]   which I said earlier, is that third axis, it's the connecting people with each other. And
[00:36:16.880 --> 00:36:22.080]   Facebook's been accused of creating filler bubbles, and the argument is made that they should expose
[00:36:22.080 --> 00:36:26.480]   us to new ideas. But if Facebook is not an ideas platform, nor is it an information platform,
[00:36:26.480 --> 00:36:31.520]   to be clear, it is a people platform. And what I want Facebook to do is introduce me to strangers
[00:36:31.520 --> 00:36:36.800]   and make them less strange. The power that Facebook has is to bring other people's lives
[00:36:36.800 --> 00:36:41.760]   together, to bring communities into connection together. There was a great project by a company
[00:36:41.760 --> 00:36:49.200]   called Spaceship Media at AL.com in Alabama where they bought 20 Trump voters from Alabama and 20
[00:36:49.200 --> 00:36:53.120]   Clinton voters from San Francisco and brought them together. And the journalists convened
[00:36:53.120 --> 00:36:56.480]   their discussion. Yes, they got into arguments, but then they went and asked the journalists for
[00:36:56.480 --> 00:37:00.240]   information. They tried to find as close as they could get. They understood each other's arguments.
[00:37:00.240 --> 00:37:06.640]   They didn't agree, but that's democracy. That's what Facebook can do. It can convene people,
[00:37:06.640 --> 00:37:12.400]   it can make strangers less strange. It can show us other lives. It can allow us to show our own
[00:37:12.400 --> 00:37:18.720]   lives. Should it be that though, if people don't want to do that? I mean, people want that. Do we?
[00:37:18.720 --> 00:37:25.440]   Yeah, we always say that's the next human. We love other people's experiences. If it's packaged
[00:37:25.440 --> 00:37:32.960]   the right way. Think about how well profiles do of people in how... And reality TV.
[00:37:34.320 --> 00:37:40.560]   So it could facilitate this in a way that we would appeal to us. I think the natural
[00:37:40.560 --> 00:37:44.400]   tendency is just to hang out with people you know. And that's the prop. That's the filter bubble
[00:37:44.400 --> 00:37:50.640]   itself. That's the perfect trouble. That is the argument. Mark Zuckerberg talks about community,
[00:37:50.640 --> 00:37:55.120]   and he talks about it religiously now. And he made a joke yesterday of his about his huge essay
[00:37:55.120 --> 00:37:59.600]   in many pages. Community isn't just about replicating the communities we're already in.
[00:37:59.600 --> 00:38:03.920]   Community is about... And that enables us to find new people. And indeed, that's what happens.
[00:38:03.920 --> 00:38:10.400]   So I was talking about this recently with Dave Liner in Perusion, where I said, "Dave, what happened
[00:38:10.400 --> 00:38:15.760]   to blogging?" In the early days of blogging, it was so wonderful. I met people from Iran and Iraq.
[00:38:15.760 --> 00:38:19.680]   I talked to conservatives for whom I now turn off the TV if I see them on there. We were able
[00:38:19.680 --> 00:38:23.920]   to have civil conversations. What was it? And Dave said, "Everything's nice in the beginning, Jeff."
[00:38:23.920 --> 00:38:29.360]   It's really the bottom line. Everything's nice in the beginning. Period. We doomed
[00:38:30.560 --> 00:38:37.120]   or is Facebook just a small, nascent beginning of what it could be in a truly social platform,
[00:38:37.120 --> 00:38:42.720]   where it does enable us to create new communities and even new societies? Do you think that big? I
[00:38:42.720 --> 00:38:50.320]   mean, to me, that's bigger thinking than drones and AR is rethinking the human connections.
[00:38:50.320 --> 00:38:54.320]   And I think that's what Facebook may be losing a little bit. And that's what its real focus should be.
[00:38:54.320 --> 00:39:00.080]   Well, I think Mark Zuckerberg talked about that in the keynote, right? That's what
[00:39:00.080 --> 00:39:04.000]   that's one of the things he said they are trying to do. Yeah, that's his new manifesto, right?
[00:39:04.000 --> 00:39:07.840]   That's the community part of that. Representative together, breakdown walls.
[00:39:07.840 --> 00:39:12.960]   Stacy, you were starting to get a break in. No, I was just going to say, doesn't Twitter
[00:39:12.960 --> 00:39:17.120]   perform that function for lots of people? I mean, I know I meet lots of people in different
[00:39:17.120 --> 00:39:22.240]   communities I've created on Twitter. Yeah, you too. Yeah, I always think Twitter is also kind of a
[00:39:22.240 --> 00:39:27.520]   cesspool. Yeah, well, can you say you really have an interaction at 140 characters per? I mean,
[00:39:27.520 --> 00:39:33.440]   yes, yes, I have. I think you can. Yeah, lots of the people that I communicate with on Twitter and
[00:39:33.440 --> 00:39:39.120]   I was definitely friends and knew them first. I do actually, I do actually remember
[00:39:39.120 --> 00:39:44.320]   in the early days of Twitter meeting people and thinking of them as their Twitter handle, you know,
[00:39:44.320 --> 00:39:47.760]   another name I knew their Twitter handle. I still do that.
[00:39:47.760 --> 00:39:50.880]   Stay with the early day blogs. Here's the problem. I think Facebook could be following
[00:39:50.880 --> 00:39:55.280]   following into a media trap where what they see themselves doing is constantly creating new ways
[00:39:55.280 --> 00:40:01.120]   for people to create content. They're not content. They're people connecting with each other
[00:40:01.120 --> 00:40:06.480]   in communities. And if you truly imagine what that looks like, then you rethink the nature of
[00:40:06.480 --> 00:40:13.680]   communities and connections. So, you can get together. No, you can't because that's highly
[00:40:13.680 --> 00:40:21.280]   engaged. It's just you think content is just a tool, not the end. I think Facebook can,
[00:40:21.280 --> 00:40:27.840]   that's soul knows that. Yeah, I wonder whether I mean, I think Mark Zuckerberg is sincere.
[00:40:27.840 --> 00:40:28.880]   You're laughing, Nancy.
[00:40:28.880 --> 00:40:33.840]   About what he wants to do. But I think it's going to be a whole lot harder than he thinks it is.
[00:40:33.840 --> 00:40:36.160]   To actually.
[00:40:36.160 --> 00:40:36.720]   She's going to be laughing.
[00:40:36.720 --> 00:40:43.280]   I was just laughing at your belief, your optimism here in this.
[00:40:43.280 --> 00:40:44.640]   [laughter]
[00:40:44.640 --> 00:40:50.320]   Oh, oh, Jeff. Oh, Jeff, you're so, you're so naive.
[00:40:50.320 --> 00:40:51.120]   Yeah.
[00:40:51.120 --> 00:40:51.840]   I'm a pleasure.
[00:40:51.840 --> 00:40:54.000]   Stacy says, "Paw to your optimism."
[00:40:54.000 --> 00:40:54.160]   Hah.
[00:40:54.160 --> 00:40:55.040]   Kids nowadays.
[00:40:55.040 --> 00:41:00.240]   I tell you. Jeff Jarvis is with us from, as you probably could tell, from the sound quality,
[00:41:00.240 --> 00:41:07.040]   from the floor of F8 in San Jose. No, we're thrilled to have you. We can survive.
[00:41:07.040 --> 00:41:13.440]   Also with us Matthew Ingram, who is visiting from Canada. He's at fortune.com.
[00:41:13.440 --> 00:41:19.760]   And Stacy Higginbotham from Austin, Texas, from the IOT podcast.com.
[00:41:19.760 --> 00:41:20.480]   I'm more in a minute.
[00:41:20.480 --> 00:41:23.760]   Obviously, as long as we've got Jeff here, we should keep talking about
[00:41:23.760 --> 00:41:28.400]   Facebook and F8. But we've got lots of other Google stuff to talk about too.
[00:41:28.400 --> 00:41:34.720]   Our show today brought to you by LegalZoom. LegalZoom is awesome. LegalZoom is how we started
[00:41:34.720 --> 00:41:38.320]   to it. 12 years, you know, Monday was our 12th anniversary. I don't think I--
[00:41:38.320 --> 00:41:38.960]   Puzzle.
[00:41:38.960 --> 00:41:40.720]   Yeah. Isn't that great? 12 years?
[00:41:40.720 --> 00:41:43.600]   I think we're here younger than Facebook.
[00:41:43.600 --> 00:41:45.280]   Wow. We're almost a teenager.
[00:41:45.280 --> 00:41:48.000]   I know. Pretty soon I'm going to break it up.
[00:41:48.000 --> 00:41:49.040]   So you'll be a man.
[00:41:49.040 --> 00:41:51.920]   Soon I shall be a man and responsible for this thing.
[00:41:51.920 --> 00:41:55.600]   But it wasn't right away. I think it was within the first year or two.
[00:41:55.600 --> 00:41:59.920]   I decided to create an LLC. I asked my friend Kevin Rose, who'd started many a company.
[00:41:59.920 --> 00:42:03.760]   He said, "Oh yeah, go to LegalZoom and they could do it all. It's cheap online. You don't
[00:42:03.760 --> 00:42:08.640]   need a lawyer." And we did. You know, more than a million people have trusted LegalZoom to start
[00:42:08.640 --> 00:42:15.680]   their businesses. Incorporation, LLCs, nonprofits, DBAs and more. You can use LegalZoom to get
[00:42:15.680 --> 00:42:21.760]   started right away. One of the five things business owners could count on from LegalZoom. Reliability,
[00:42:21.760 --> 00:42:27.120]   experience. They've been doing this for 15 years. Plenty of experiencing helping people with their
[00:42:27.120 --> 00:42:32.640]   legal needs. Great support. The right people standing by ready for your questions, all based in the US.
[00:42:32.640 --> 00:42:39.120]   And by the way, even though LegalZoom is not a law firm, you can get legal advice from LegalZoom
[00:42:39.120 --> 00:42:43.440]   because they have a network of independent attorneys who could do things like review contracts,
[00:42:43.440 --> 00:42:47.680]   help with employment law, advise you on those hurdles that come up when you run a business.
[00:42:47.680 --> 00:42:53.680]   Finally, no surprises. LegalZoom provides complete transparency. You know, upfront when it's going
[00:42:53.680 --> 00:42:59.360]   to cost. You can see customer reviews right there on the site. There is a satisfaction guarantee.
[00:42:59.360 --> 00:43:06.480]   So for the paperwork you need, for the advice you need, for the support you need, LegalZoom is
[00:43:06.480 --> 00:43:12.480]   there to help you start your business, make your will, or do a whole variety of legal tasks.
[00:43:12.480 --> 00:43:16.880]   Check out LegalZoom today to see how they can make life better for you and your business.
[00:43:16.880 --> 00:43:22.080]   And don't forget to enter Twig when you check out to save. That's LegalZoom.com,
[00:43:22.080 --> 00:43:28.080]   the offer code TWIG that lets them know you heard it here. We thank LegalZoom for many years.
[00:43:28.080 --> 00:43:35.200]   A sponsor and pleased to say they've helped us. We trademarked through LegalZoom. We did the LLC
[00:43:35.200 --> 00:43:41.760]   through LegalZoom. They really are great. LegalZoom.com, offer code TWIG. Jeff Jarvis,
[00:43:41.760 --> 00:43:47.760]   is it a break? Where are you going next? Back to the media track. They have a separate date.
[00:43:47.760 --> 00:43:54.320]   So this year, last year, they had a room with about 120 seats, was for just media people,
[00:43:54.320 --> 00:43:58.640]   but all the non-technical people who come to FA kind of went there. So they couldn't even get
[00:43:58.640 --> 00:44:04.160]   the media people. I can understand this. I understand the VR, but I understand the news.
[00:44:04.160 --> 00:44:09.360]   So this year they had a room that I don't know, it was a thousand people and that filled.
[00:44:09.360 --> 00:44:13.760]   Wow. And now there's a private track for media executives and such. They're really
[00:44:13.760 --> 00:44:20.880]   putting a big emphasis on news and media here. Are they attempting to solve the instant articles
[00:44:20.880 --> 00:44:28.480]   problem, the Exodus from Instant Articles? Yes. They emphasized that in the beginning of every talk.
[00:44:28.480 --> 00:44:32.320]   They emphasized how they're trying to increase modernization and instant articles. Number one,
[00:44:32.320 --> 00:44:36.640]   new ad opportunity, more ads in it. We'll see what works. New kind of ad units. We'll see what
[00:44:36.640 --> 00:44:43.440]   that goes. Second, they also recognized that a lot of publishers who have paywalls and paymeters
[00:44:43.440 --> 00:44:48.480]   really want to convert and that they're working on that. The problem for some, like the New York
[00:44:48.480 --> 00:44:55.360]   Times, instant articles does not work well with a paymaker. Either it's available on Facebook or
[00:44:55.360 --> 00:44:59.920]   it's not. So they know they've got to work on that. They're working on that and trying to figure
[00:44:59.920 --> 00:45:06.080]   out a mechanism. AMP has worked on that separately. And I think that yes, they're taking it seriously.
[00:45:06.080 --> 00:45:10.800]   There's some skepticism to be true. And here's the problem. I have instant articles. The thing
[00:45:10.800 --> 00:45:15.520]   what I say about it is that the fundamental problem with instant articles is it plays to our
[00:45:15.520 --> 00:45:22.240]   worst egotistical notions that everything is an article and it stops us from innovating in news
[00:45:22.240 --> 00:45:27.040]   in other ways and stops Facebook from helping us monetize by using Facebook properly to bring
[00:45:27.040 --> 00:45:32.960]   journalism to the conversation. And so instant articles is great as far as it goes, but it's not
[00:45:32.960 --> 00:45:36.800]   to be all an end all. And I fear that media are going to expect it to be that.
[00:45:36.800 --> 00:45:44.240]   I actually don't think maybe I'm wrong and Jeff, correct me if I'm wrong, but I feel like instant
[00:45:44.240 --> 00:45:50.960]   articles was something Facebook kind of cared about a year or two ago. I mean, so much has happened
[00:45:50.960 --> 00:45:58.400]   since then. Video is now the big deal. Facebook has its eye on lots of other balls. It doesn't
[00:45:58.400 --> 00:46:06.400]   feel like helping newspaper articles load faster on mobile. Why does that matter to Facebook?
[00:46:06.400 --> 00:46:11.120]   Well, they're investing in it matters to Facebook because they think it's a path to helping
[00:46:11.120 --> 00:46:18.800]   publishers monetize and sustain. And so they think they've got to make it monetize equal to the web,
[00:46:18.800 --> 00:46:23.760]   basically is what they say. And I think that's fine. I got no objection to that whatsoever.
[00:46:23.760 --> 00:46:28.160]   But again, I think that it's not the only path. And we in media tend to often to think there's a
[00:46:28.160 --> 00:46:34.400]   false messiah. Pavlets will save us. Meters will save us. Native advertising will save us.
[00:46:34.400 --> 00:46:38.880]   Instant articles and Apple save us. None of those will save us. They'll be a bit better, but we have
[00:46:38.880 --> 00:46:42.960]   to rethink journalism fundamentally. And that's what I really want journalists Google and Facebook
[00:46:42.960 --> 00:46:48.000]   to do. And that's what I hope that the thing I'm working on, the news integrity initiative,
[00:46:48.000 --> 00:46:52.960]   can inspire some collaboration on those lines. Facebook is also caring about local. They recognize
[00:46:52.960 --> 00:46:58.640]   instant articles does not serve local terribly well. It's more for national media. They don't
[00:46:58.640 --> 00:47:03.520]   have a plan for local yet. They're quick to say that. But they are thinking about how to
[00:47:03.520 --> 00:47:07.600]   start to think about that. So no, I don't think this is an article by any means in their view
[00:47:07.600 --> 00:47:15.520]   getting dust on the shelf. But what I hope is that they learn to create more new things.
[00:47:18.160 --> 00:47:26.320]   Ben Thompson writing today in Stratecary says quite an indictment. This is kind of
[00:47:26.320 --> 00:47:33.360]   harkening back to our earlier conversation that Facebook can steal from Snapchat and win because
[00:47:33.360 --> 00:47:39.840]   of their monopoly. He does like it as we did to Microsoft. And he says they should be worried
[00:47:39.840 --> 00:47:48.080]   because remember Microsoft faced anti-trust, very vigorous anti-trust action.
[00:47:48.080 --> 00:47:52.400]   And I think Facebook is in Europe as well, maybe not in the US, but Europe is definitely
[00:47:52.400 --> 00:47:56.400]   thinking about it. And just from a point of view of a consumer in a monopoly situation,
[00:47:56.400 --> 00:48:00.960]   he writes, there's no competition. The monopoly provider makes decisions based on profit
[00:48:00.960 --> 00:48:07.120]   macroization. So they don't have to worry about the demand curve. They just consider the marginal
[00:48:07.120 --> 00:48:12.080]   revenue is gained from selling additional items. They basically win by winning.
[00:48:12.080 --> 00:48:19.280]   But look at the graph that he has for Facebook because the marginal cost, that's the curve.
[00:48:19.280 --> 00:48:21.440]   The marginal cost is effectively zero.
[00:48:21.440 --> 00:48:25.600]   Is zero, right? So all they have to care about is demand.
[00:48:25.600 --> 00:48:33.680]   The hard part and the only thing I would say to Ben is,
[00:48:35.360 --> 00:48:42.080]   what does Facebook have a monopoly on? So does it have a large chunk of the ad market? Yes.
[00:48:42.080 --> 00:48:48.400]   Does it have a huge number of users? Yes. But if you were to go after it sort of from a legal
[00:48:48.400 --> 00:48:55.600]   point of view, what is the monopoly that Facebook has? What is it on? What is the market graph?
[00:48:55.600 --> 00:49:03.360]   No, no, no, this is it has a monopoly on access to data that is going to improve the way
[00:49:04.160 --> 00:49:08.960]   everything that we have is being delivered to us. So this is actually a really interesting,
[00:49:08.960 --> 00:49:15.920]   okay. So I read random papers because academic papers. And I read one that talked about how
[00:49:15.920 --> 00:49:21.760]   we're going to look at monopolies in a digital world. And it's really smart. I'm looking for
[00:49:21.760 --> 00:49:27.040]   it right now. So I can tell you it's from Chet and Sharma. I don't know if you remember him,
[00:49:27.040 --> 00:49:32.640]   Matthew. Yeah, I certainly do. So he has an entire paper called competition rethinking the
[00:49:32.640 --> 00:49:38.880]   regulatory framework. And the whole idea he looks at how we have failed.
[00:49:38.880 --> 00:49:46.560]   Yeah, to look at how connectivity like our ownership of different levels of connectivity.
[00:49:46.560 --> 00:49:50.160]   And then how the influx of data that companies are gathering about people
[00:49:50.160 --> 00:49:58.560]   change the question of monopolies because with AI. I think he's right. I mean, that definitely is
[00:49:58.560 --> 00:50:02.000]   the problem is you're going to have to rewrite competition. Yes, policy.
[00:50:02.000 --> 00:50:07.440]   Is that going to happen? Yes, maybe. I know, but I mean, okay, when you're trying.
[00:50:07.440 --> 00:50:13.520]   Yeah, no, they are. And I agree that that's the market that we should be looking at. It's not
[00:50:13.520 --> 00:50:18.880]   the market for likes or clicks or it's the underlying data about us as individuals in our
[00:50:18.880 --> 00:50:24.960]   social graph. But how you define that in such a way that you can apply competition policy
[00:50:26.160 --> 00:50:31.200]   is a really big. That's just a really big question. And we say this all the time, though, in tech.
[00:50:31.200 --> 00:50:36.800]   And I get very frustrated with us because we're like, wow, that's a big problem. And there's a
[00:50:36.800 --> 00:50:42.320]   lot of innovation coming out. Let's just step back for a while. And I don't, I think we need to start
[00:50:42.320 --> 00:50:47.680]   really talking about it because tech is only going to become more essential and more.
[00:50:47.680 --> 00:50:53.520]   I agree. Yeah, I agree. And why not our lives? And we can't afford to step back anymore.
[00:50:54.160 --> 00:51:00.240]   And if Facebook continues to do all the things that they're describing, that monopoly, if they
[00:51:00.240 --> 00:51:06.160]   have one over those things is going to become even more powerful. I mean, all you have to do is look
[00:51:06.160 --> 00:51:12.080]   at them providing internet access to underdeveloped countries that effectively puts them in a position
[00:51:12.080 --> 00:51:17.760]   that, you know, that no other company has has been in, I don't think. So how do you
[00:51:17.760 --> 00:51:26.160]   interesting? So the interesting thing is with our data, we don't actually have it's not a monopoly
[00:51:26.160 --> 00:51:30.160]   in the sense that I can grant my access to my data to Facebook, to Google, to all of these other
[00:51:30.160 --> 00:51:35.280]   companies. So there are some kind of crazy, fun, legal things to think about. There should be
[00:51:35.280 --> 00:51:39.520]   user controls. I mean, you should be able to extract your data and export it wherever you want.
[00:51:39.520 --> 00:51:45.680]   So seriously, it's between for just that. We've talked a long time about the vault and having your
[00:51:45.680 --> 00:51:50.080]   own data stored locally and you get permission to it. So Sir Tim is thinking about,
[00:51:50.080 --> 00:51:52.080]   you talked about on the show, Leo? Yeah.
[00:51:52.080 --> 00:52:00.640]   Tim's efforts to rethink the web around just what you guys are talking about is you have control
[00:52:00.640 --> 00:52:05.040]   your data. Now, it's hard to imagine separating the data from the experience, separating the data
[00:52:05.040 --> 00:52:11.760]   from the transaction, separating the data from other people. Nonetheless, I do see if Sir Tim's
[00:52:11.760 --> 00:52:15.920]   working on it. I'm hoping that people will pay attention. We can start experimenting with us.
[00:52:15.920 --> 00:52:21.760]   Tomorrow, I have a guest on my show that actually is doing,
[00:52:21.760 --> 00:52:26.560]   don't hate me, you guys. I'm going to say the magic D word. He's doing a blockchain-based
[00:52:26.560 --> 00:52:32.560]   way to track this. I don't know if his solution is the right one, but this is a way to deliver
[00:52:32.560 --> 00:52:38.240]   that stuff around that. Yeah. As a way of tracking, it's certainly a sort of low.
[00:52:41.680 --> 00:52:45.040]   I think it would be an efficient way of tracking things, whether it's information.
[00:52:45.040 --> 00:52:52.160]   Incidentally, to get back to the instant articles, Ben also points out that instant
[00:52:52.160 --> 00:52:57.760]   articles problem is because Facebook's monopoly, he said, yeah, they monetize, but they weren't
[00:52:57.760 --> 00:53:01.840]   in Senate in any way to really share it with the publishers. They kept... They kept...
[00:53:01.840 --> 00:53:06.560]   Oh, come on. They give publishers 100% of the revenue that the publishers sell, 70% of the
[00:53:06.560 --> 00:53:10.240]   revenue that Facebook sells. Well, apparently it's not enough for the publishers, right?
[00:53:10.240 --> 00:53:15.840]   Well, okay, but hello. The job here is not to replace what the publishers used to have when
[00:53:15.840 --> 00:53:20.240]   they had monopolies. Well, and Ben's point is it doesn't matter whether the publishers are
[00:53:20.240 --> 00:53:25.840]   happy or unhappy because the Facebook has a monopoly. This Facebook doesn't care.
[00:53:25.840 --> 00:53:30.800]   Facebook is so dominant, he writes, when it comes to attention, it doesn't have to do anything for
[00:53:30.800 --> 00:53:36.160]   publishers at all. And if said publishers leave instant articles, well, they'll still place links
[00:53:36.160 --> 00:53:39.040]   and the users aren't going anywhere regardless. But they aren't...
[00:53:39.040 --> 00:53:45.600]   And I have to say, I don't want to say anything. I know, Jeff, the news integrity project is a
[00:53:45.600 --> 00:53:51.680]   great idea. I hope Facebook is working on all kinds of things to help journalism and so on.
[00:53:51.680 --> 00:53:58.960]   But I wonder if for all the things they say about it, media, journalism, whatever you want to call
[00:53:58.960 --> 00:54:04.960]   it, is a tiny fraction of what happens on the platform. It's never going to be the thing that
[00:54:04.960 --> 00:54:10.480]   they care about the most because it doesn't generate a lot of revenue. And it just isn't a huge part
[00:54:10.480 --> 00:54:15.200]   of what people do. They come in contact with news accidentally while they're doing other things.
[00:54:15.200 --> 00:54:23.120]   It's not core to what Facebook really is. And that's fine. It's not nobody says that it should be.
[00:54:23.120 --> 00:54:26.320]   There are number one job is to connect you with your friends and family. Now they add to this
[00:54:26.320 --> 00:54:31.040]   Zuckerberg as this is what we're going to move past that to also connect you to your communities
[00:54:31.040 --> 00:54:36.640]   and larger communities. That's job number one. Job number... They don't put it this much,
[00:54:36.640 --> 00:54:41.440]   but I will, is to entertain you, to amuse you, to engage you. Job number three, almost
[00:54:41.440 --> 00:54:45.280]   coincidentally, is to inform you. Because that's what it does do. They recognize that they didn't
[00:54:45.280 --> 00:54:49.440]   build it for that. It does that job fine. And they'll improve how it does that job. But
[00:54:49.440 --> 00:54:53.120]   no one in Facebook, whatever say that's job one, no one.
[00:54:53.120 --> 00:54:59.520]   Ben concludes that the real problem with monopolies basically just don't innovate. It's hard to think
[00:54:59.520 --> 00:55:03.440]   he writes of any example where establishment of plays produce technology that wouldn't have been
[00:55:03.440 --> 00:55:09.440]   produced by the free market. That's why Facebook's theft of not just Snapchat's features, but its
[00:55:09.440 --> 00:55:14.880]   entire vision bums me out, even if it makes good business sense. Which is a point...
[00:55:14.880 --> 00:55:22.080]   I'm a little more optimistic about Snapchat's potential to survive than I think Ben is in that
[00:55:22.080 --> 00:55:28.000]   piece. I wonder what... I don't think Snapchat actually is competing against Facebook in any
[00:55:28.000 --> 00:55:31.440]   kind of fundamental way. Snapchat is doing something completely different.
[00:55:31.440 --> 00:55:37.760]   Snapchat is all about private communication. Facebook is all about public. They're two very
[00:55:37.760 --> 00:55:43.360]   different things. Everyone I know who uses Snapchat has no interest in sharing things publicly,
[00:55:43.360 --> 00:55:48.880]   no interest in how many followers or likes they have, no interest in... It's all about one to one
[00:55:48.880 --> 00:55:53.040]   or one to a small group. Yeah, it's funny too because when I use Snapchat because of I have a
[00:55:53.040 --> 00:55:58.000]   different bent, I'm not young. I almost think, you know, how can I get this great picture out
[00:55:58.000 --> 00:56:02.400]   and put it on Instagram? Me too. Me too. But that's not what Snapchat uses.
[00:56:02.400 --> 00:56:08.000]   No, my 22 year old doesn't use it that way. Exactly. It's only the older people, the adults
[00:56:08.000 --> 00:56:11.440]   that you see their Snapchat filters. You don't see any pictures. And they're the ones moving to
[00:56:11.440 --> 00:56:15.760]   Instagram, right? They're the ones saying Instagram is better because I can see how many people read
[00:56:15.760 --> 00:56:20.400]   it or saw it or watched it. Snapchat too. So if you're having a
[00:56:20.400 --> 00:56:24.080]   Spiegel... That is not what Snapchat's about. If you're having Spiegel at Snapchat, do you just
[00:56:24.080 --> 00:56:28.160]   sit back and place it and say, "Well, let Facebook have these old farts. I've got the future. I've
[00:56:28.160 --> 00:56:34.720]   got the kids." This is what I was talking about. It's a new way to use a network. And it's not...
[00:56:34.720 --> 00:56:38.640]   Exactly. It's how Facebook gets replaced. There was a good piece. Mashable had a great
[00:56:38.640 --> 00:56:43.680]   piece. I forget who wrote it now, but looking at the old Facebook's going to kill Snapchat,
[00:56:43.680 --> 00:56:49.360]   or Instagram is going to kill Snapchat because it's copied everything. The two are fundamentally
[00:56:49.360 --> 00:56:55.760]   different. And so I don't see people who are hardcore Snapchat users suddenly deciding,
[00:56:55.760 --> 00:56:59.920]   "Oh, I guess I'll just use Instagram instead." They operate in fundamentally different ways.
[00:56:59.920 --> 00:57:04.160]   No, I asked those kids, these Australian teenagers, they're all still on Snapchat. They
[00:57:04.160 --> 00:57:08.960]   hadn't moved to Instagram. So Stacy, you think for your daughter and her generation,
[00:57:08.960 --> 00:57:14.880]   Facebook isn't going to be the monopoly it is today. Snapchat will... Or somebody like it will
[00:57:14.880 --> 00:57:18.880]   supersede them? You'll just have a different interface paradigm with your friends.
[00:57:19.440 --> 00:57:21.680]   Okay, I cannot believe I just said that. Those words just like...
[00:57:21.680 --> 00:57:26.640]   This is how those words happen. They just come out.
[00:57:26.640 --> 00:57:30.000]   No, but that makes sense. In fact...
[00:57:30.000 --> 00:57:33.840]   ...for your friends. Let's just swallow that from...
[00:57:33.840 --> 00:57:35.840]   That's the new timeline.
[00:57:35.840 --> 00:57:41.680]   Excuse me. You're my new friend, but I still have yet to decide on our interface paradigm.
[00:57:41.680 --> 00:57:45.440]   Maybe we'll do a VR thing for just to try.
[00:57:46.880 --> 00:57:50.720]   No, I think you're right. But I think what it is is they'll... She'll use both, though, right?
[00:57:50.720 --> 00:57:52.800]   She'll have a public... Maybe. Maybe. Maybe.
[00:57:52.800 --> 00:57:53.840]   Maybe not.
[00:57:53.840 --> 00:57:56.800]   To be honest, I think Mark Zuckerberg is terrified.
[00:57:56.800 --> 00:57:58.160]   Like I know that he...
[00:57:58.160 --> 00:58:00.000]   If you steal from somebody...
[00:58:00.000 --> 00:58:01.120]   Right.
[00:58:01.120 --> 00:58:02.480]   ...as they did with Instagram...
[00:58:02.480 --> 00:58:05.280]   ...and they're doing that with Facebook, it's because you see them as a threat.
[00:58:05.280 --> 00:58:08.480]   And very famously, he tried very hard to buy Snapchat.
[00:58:08.480 --> 00:58:14.160]   He was able to buy WhatsApp and Instagram previous threats to Facebook's dominance.
[00:58:14.160 --> 00:58:15.360]   He was not able to buy Snapchat.
[00:58:15.360 --> 00:58:20.800]   And I think when he lies awake at night, he is afraid of what Snapchat represents.
[00:58:20.800 --> 00:58:25.040]   Maybe not Snapchat specifically, but the change that Stacey's talking about,
[00:58:25.040 --> 00:58:27.920]   those changes in the way people behave and the way they interact,
[00:58:27.920 --> 00:58:31.040]   and whether Facebook is going to miss the boat.
[00:58:31.040 --> 00:58:33.200]   Well, they can't really change their...
[00:58:33.200 --> 00:58:36.160]   I mean, public is kind of fundamental to Facebook, right?
[00:58:36.160 --> 00:58:37.200]   You can't really...
[00:58:37.200 --> 00:58:38.240]   Exactly.
[00:58:38.240 --> 00:58:39.520]   So, and I wonder whether...
[00:58:39.520 --> 00:58:43.520]   Like, if you look at Instagram or WhatsApp or...
[00:58:44.400 --> 00:58:51.120]   Everything Facebook tries in a way is a way of kind of reinventing Facebook itself,
[00:58:51.120 --> 00:58:53.040]   while still keeping the original Facebook.
[00:58:53.040 --> 00:58:54.480]   But that was...
[00:58:54.480 --> 00:58:55.760]   Which was far-hods point.
[00:58:55.760 --> 00:58:57.120]   The power of the...
[00:58:57.120 --> 00:58:58.320]   It sounds like a future...
[00:58:58.320 --> 00:58:59.680]   What is the future?
[00:58:59.680 --> 00:59:03.760]   But doesn't the power of the network ultimately depend on keeping those people?
[00:59:03.760 --> 00:59:09.200]   And haven't we seen in the past how the power of the network can just...
[00:59:09.200 --> 00:59:10.160]   Definitely.
[00:59:10.160 --> 00:59:11.760]   ...if we evaporate like mists?
[00:59:11.760 --> 00:59:15.520]   It can, but they also said yesterday that they are...
[00:59:15.520 --> 00:59:19.280]   I'm sorry, there's a stairwell here that goes nowhere.
[00:59:19.280 --> 00:59:20.080]   I see people going to...
[00:59:20.080 --> 00:59:22.080]   [laughter]
[00:59:22.080 --> 00:59:22.880]   They should put a sign...
[00:59:22.880 --> 00:59:23.440]   That's a metaphor.
[00:59:23.440 --> 00:59:24.000]   There's a metaphor.
[00:59:24.000 --> 00:59:24.640]   Yeah.
[00:59:24.640 --> 00:59:26.720]   Maybe that's the Facebook stairwell.
[00:59:26.720 --> 00:59:28.640]   Oh, and we lost him.
[00:59:28.640 --> 00:59:29.120]   We lost him.
[00:59:29.120 --> 00:59:29.680]   Oh, man.
[00:59:29.680 --> 00:59:31.280]   Let's take a break while we try to get him back.
[00:59:31.280 --> 00:59:34.960]   I think we're almost done with our conversation about F8.
[00:59:34.960 --> 00:59:38.560]   I'll give you all three of your chance to save some final words in them.
[00:59:38.560 --> 00:59:42.800]   We'll talk about some other news of the week on this week in Google.
[00:59:42.800 --> 00:59:46.000]   I showed today brought to you by Rocket Mortgage from Quick and Loans.
[00:59:46.000 --> 00:59:49.840]   Quick and Loans, one of the best, most innovative, most interesting companies,
[00:59:49.840 --> 00:59:53.360]   home mortgage lenders in the nation.
[00:59:53.360 --> 00:59:57.200]   I mean, just not only are they, I think, number two in the business,
[00:59:57.200 --> 00:59:59.360]   they're doing some of the most interesting things.
[00:59:59.360 --> 01:00:01.680]   They're very trustworthy.
[01:00:01.680 --> 01:00:02.800]   They're beloved.
[01:00:02.800 --> 01:00:07.440]   If you look at the website, you'll see all those JD Power Customer Satisfaction Awards.
[01:00:07.440 --> 01:00:14.000]   Number one year after year for financial services for mortgage origination and for
[01:00:14.000 --> 01:00:14.880]   mortgage servicing.
[01:00:14.880 --> 01:00:23.360]   And they know that there are people like us who want to apply for our home loan or our refinance
[01:00:23.360 --> 01:00:24.320]   entirely online.
[01:00:24.320 --> 01:00:29.120]   So they created a product just for us called Rocket Mortgage.
[01:00:29.120 --> 01:00:33.760]   It lifts the burden of getting a home loan.
[01:00:33.760 --> 01:00:35.040]   You got to work with someone you trust.
[01:00:35.040 --> 01:00:36.400]   Someone's got your best interest in mind.
[01:00:36.400 --> 01:00:40.000]   But if you're going to do that, do it with Quick and Loans and make it easy on yourself
[01:00:40.000 --> 01:00:40.800]   with Rocket Mortgage.
[01:00:40.800 --> 01:00:45.120]   Rocket Mortgage is a mortgage approval process you could do from your phone, your tablet.
[01:00:45.120 --> 01:00:46.240]   You could do it anywhere you are.
[01:00:46.240 --> 01:00:47.200]   You could do it in an open house.
[01:00:47.200 --> 01:00:49.120]   You could see a house and say, "I like this house.
[01:00:49.120 --> 01:00:50.000]   Let's buy this house.
[01:00:50.000 --> 01:00:50.960]   Let's apply for the loan."
[01:00:50.960 --> 01:00:55.840]   You have, because it's all online, you submit everything online, including whatever paperwork
[01:00:55.840 --> 01:00:58.480]   they need, pay stubs and bank statements typically.
[01:00:58.480 --> 01:01:04.400]   They allow you to play with a slider to see what your payments would be,
[01:01:04.400 --> 01:01:07.600]   depending on the rate and the term of the loan.
[01:01:07.600 --> 01:01:10.240]   Get it just right and then push the button and apply.
[01:01:10.240 --> 01:01:14.960]   Now, I think back to the last time we bought a house, it took me more than a month.
[01:01:14.960 --> 01:01:17.360]   At least tonight, it took a month to get our home loan.
[01:01:17.360 --> 01:01:19.840]   And they kept coming back to us for more stuff.
[01:01:19.840 --> 01:01:21.920]   With Rocket Mortgage, it's minutes, not months.
[01:01:21.920 --> 01:01:23.760]   Minutes to approval.
[01:01:23.760 --> 01:01:26.960]   You could literally do it, as I said, at the open house and show the realtor.
[01:01:26.960 --> 01:01:28.640]   It says, "Look, it says we're approved.
[01:01:28.640 --> 01:01:29.680]   We'd like to buy this house."
[01:01:29.680 --> 01:01:34.160]   Whether you're looking to buy or refi, lift the burden of getting a home loan
[01:01:34.160 --> 01:01:37.920]   with Rocket Mortgage, skip the bank, skip the waiting, go completely online.
[01:01:37.920 --> 01:01:40.640]   QuickandLones.com/twig.
[01:01:40.640 --> 01:01:44.480]   QuickandLones.com/twig.
[01:01:44.480 --> 01:01:45.760]   Let me see if I can do the legalese.
[01:01:45.760 --> 01:01:48.160]   Normally, I would do it really fast.
[01:01:48.160 --> 01:01:49.840]   That's what they do on radio.
[01:01:49.840 --> 01:01:50.320]   Equal housing.
[01:01:50.320 --> 01:01:51.200]   Let me license all 50 states.
[01:01:51.200 --> 01:01:52.640]   I was like, "But you can't hear it."
[01:01:52.640 --> 01:01:54.080]   Equal housing lender.
[01:01:54.080 --> 01:01:59.200]   License in all 50 states and MLS consumer access.org number 3030.
[01:01:59.200 --> 01:02:00.160]   That's Rocket Mortgage.
[01:02:01.040 --> 01:02:05.920]   Go to quickandlones.com/twig.
[01:02:05.920 --> 01:02:08.880]   Stacey, we've all decided that the name of the show will be
[01:02:08.880 --> 01:02:10.880]   a new interface paradigm for your friends.
[01:02:10.880 --> 01:02:11.200]   Oh.
[01:02:11.200 --> 01:02:14.480]   Stacey.
[01:02:14.480 --> 01:02:17.200]   This is why I'm better in writing, because I can look at things like that and go,
[01:02:17.200 --> 01:02:18.560]   "Oh, God, what was I thinking?"
[01:02:18.560 --> 01:02:21.840]   Oh, man, I would look at it and go, "Yeah, good sentence, Leo."
[01:02:21.840 --> 01:02:24.400]   Stacey Higginbotham's here.
[01:02:24.400 --> 01:02:26.320]   Jeff Jarvis is here.
[01:02:26.320 --> 01:02:27.280]   Matthew Ingram's here.
[01:02:27.280 --> 01:02:28.720]   I'm surrounded by journalists.
[01:02:29.920 --> 01:02:30.960]   I feel out of place.
[01:02:30.960 --> 01:02:33.200]   Jeff is so horrified.
[01:02:33.200 --> 01:02:36.080]   I'm terrified that you'll catch me out.
[01:02:36.080 --> 01:02:36.640]   I'm from Mexico.
[01:02:36.640 --> 01:02:37.600]   Are you going to take off?
[01:02:37.600 --> 01:02:39.520]   I'm going to take off the band with us, Baba.
[01:02:39.520 --> 01:02:41.760]   Thank you for suffering my sound and everything else.
[01:02:41.760 --> 01:02:42.240]   No problem.
[01:02:42.240 --> 01:02:45.600]   Any final thoughts as you go back to F8?
[01:02:45.600 --> 01:02:46.560]   Anything you want to say?
[01:02:46.560 --> 01:02:49.760]   No, the bar opens at two hours.
[01:02:49.760 --> 01:02:50.800]   That's all I need to know.
[01:02:50.800 --> 01:02:52.320]   Thank you, Jeff Jarvis.
[01:02:52.320 --> 01:02:53.680]   Buzzmachine.com.
[01:02:53.680 --> 01:02:56.320]   He's going back to the media room where they're talking about...
[01:02:56.320 --> 01:02:57.360]   Say hi to Mark.
[01:02:57.360 --> 01:02:58.560]   Yes, say hi to Mark.
[01:02:59.120 --> 01:03:00.880]   Talking about news.
[01:03:00.880 --> 01:03:04.240]   So how's that Matthew doing?
[01:03:04.240 --> 01:03:05.280]   Matthew with one tea.
[01:03:05.280 --> 01:03:07.200]   I always liked that guy.
[01:03:07.200 --> 01:03:08.240]   I always liked that guy.
[01:03:08.240 --> 01:03:08.800]   See, Jeff?
[01:03:08.800 --> 01:03:09.680]   He's chipped.
[01:03:09.680 --> 01:03:15.120]   Actually, I don't know if there's a coincidence or if it's real, but
[01:03:15.120 --> 01:03:18.480]   Google had a social network called Spaces,
[01:03:18.480 --> 01:03:20.880]   which they announced in February that they were going to kill,
[01:03:20.880 --> 01:03:23.920]   and they killed it on Friday.
[01:03:23.920 --> 01:03:27.520]   And then on Monday, or Tuesday,
[01:03:27.520 --> 01:03:28.000]   Spaceship.
[01:03:28.000 --> 01:03:29.600]   Facebook announces its own Spaces.
[01:03:29.600 --> 01:03:30.560]   Do you think they had a deal?
[01:03:30.560 --> 01:03:32.160]   And it's Easter.
[01:03:32.160 --> 01:03:33.200]   Is there a coincidence?
[01:03:33.200 --> 01:03:36.640]   Ah, maybe Facebook Plus is coming.
[01:03:36.640 --> 01:03:40.000]   If Tom announces my Spaces, then we'll know.
[01:03:40.000 --> 01:03:43.040]   Facebook Plus, that would be funny.
[01:03:43.040 --> 01:03:43.760]   All right, I'll see you guys.
[01:03:43.760 --> 01:03:44.080]   Thank you.
[01:03:44.080 --> 01:03:44.560]   Take care.
[01:03:44.560 --> 01:03:50.320]   Actually, it's said that Facebook responded to Google Plus
[01:03:50.320 --> 01:03:54.320]   with a baton down the hatches, all hands on deck,
[01:03:54.320 --> 01:03:55.680]   kind of close.
[01:03:55.680 --> 01:03:56.400]   Lock the doors.
[01:03:56.400 --> 01:03:57.760]   We're going to sponsor them.
[01:03:57.760 --> 01:03:58.480]   They did, yeah.
[01:03:58.480 --> 01:04:03.360]   It said they did the same exact thing with Snapchat.
[01:04:03.360 --> 01:04:07.360]   And how are we going to respond to this?
[01:04:07.360 --> 01:04:11.120]   Yeah, it was like a three months, 24 hour lockdown.
[01:04:11.120 --> 01:04:11.440]   Yeah.
[01:04:11.440 --> 01:04:18.000]   As it turned out, Google Plus was not nothing to worry about.
[01:04:18.000 --> 01:04:19.120]   Big competitor.
[01:04:19.120 --> 01:04:22.160]   Yeah, I think those people were locked in there for three months
[01:04:22.160 --> 01:04:23.360]   felt when they found that out.
[01:04:23.360 --> 01:04:23.840]   Yeah.
[01:04:23.840 --> 01:04:24.960]   Maybe they declared victory.
[01:04:24.960 --> 01:04:26.400]   They said, see what we did worked.
[01:04:26.400 --> 01:04:29.280]   I was going to say, maybe they only stayed there for, you know,
[01:04:29.280 --> 01:04:30.160]   one and a half months.
[01:04:30.160 --> 01:04:33.280]   Oh, you know what, guys?
[01:04:33.280 --> 01:04:34.160]   Y'all can come out now.
[01:04:34.160 --> 01:04:34.720]   This isn't--
[01:04:34.720 --> 01:04:37.040]   Yeah, yeah, not a big deal.
[01:04:37.040 --> 01:04:37.680]   No big deal.
[01:04:37.680 --> 01:04:41.680]   All right, let's see.
[01:04:41.680 --> 01:04:43.600]   I'm trying to-- but there's so much Facebook material.
[01:04:43.600 --> 01:04:46.560]   I think we covered a good set of it.
[01:04:46.560 --> 01:04:48.320]   I feel like we got a lot.
[01:04:48.320 --> 01:04:51.120]   Matthew, you have-- because Matthew's the Facebook guy, so--
[01:04:51.120 --> 01:04:54.640]   Yeah, I did say I'd let you guys--
[01:04:54.640 --> 01:04:55.440]   That was much as--
[01:04:55.440 --> 01:05:00.320]   Offer a final coda on what we saw in the last two days.
[01:05:00.320 --> 01:05:06.640]   I have my new interface paradigm apparently.
[01:05:06.640 --> 01:05:07.520]   That was my one.
[01:05:07.520 --> 01:05:09.200]   That was my addition to the job, though.
[01:05:09.200 --> 01:05:14.800]   I have to say, I think I always enjoy seeing what a company
[01:05:14.800 --> 01:05:17.120]   operating at this kind of scale.
[01:05:17.120 --> 01:05:23.520]   It can do in a way of being nimble.
[01:05:24.160 --> 01:05:26.800]   And yeah, you could say they copied, but I agree with Farhad.
[01:05:26.800 --> 01:05:31.760]   Every great artist's steal, as Steve Jobs famously said,
[01:05:31.760 --> 01:05:34.640]   that everybody stands on everybody else's shoulders.
[01:05:34.640 --> 01:05:38.880]   And I like seeing the kinds of innovations that Facebook's doing.
[01:05:38.880 --> 01:05:43.120]   I think this is encouraging for monopoly.
[01:05:43.120 --> 01:05:45.520]   On the other hand, I do feel like
[01:05:45.520 --> 01:05:51.280]   their dominance is threatening.
[01:05:51.280 --> 01:05:53.360]   It's threatening to the internet, to the open web,
[01:05:53.360 --> 01:05:57.440]   that we know, to media consumption,
[01:05:57.440 --> 01:05:58.880]   because whether they admit it or not,
[01:05:58.880 --> 01:06:00.320]   they're clearly a media company.
[01:06:00.320 --> 01:06:03.280]   And that's always a worry.
[01:06:03.280 --> 01:06:04.800]   That's definitely my--
[01:06:04.800 --> 01:06:07.520]   I enjoy the GWAS stuff,
[01:06:07.520 --> 01:06:11.920]   and I enjoy the sort of thinking about the future of interface paradigms and whatnot.
[01:06:11.920 --> 01:06:15.360]   But I mean, I'm fundamentally a media guy,
[01:06:15.360 --> 01:06:20.240]   and I've been arguing bang in the drum for years
[01:06:20.240 --> 01:06:21.920]   that Facebook is a media company,
[01:06:21.920 --> 01:06:25.840]   the biggest and most powerful media company that has ever existed in human history.
[01:06:25.840 --> 01:06:27.600]   You still do not admit that, do they?
[01:06:27.600 --> 01:06:28.160]   I mean, I just--
[01:06:28.160 --> 01:06:31.680]   Well, I mean, Mark Zuckerberg's kind of tiptoeed around,
[01:06:31.680 --> 01:06:35.600]   we're not really a media company, but we're kind of involved in it.
[01:06:35.600 --> 01:06:36.480]   So at least he's--
[01:06:36.480 --> 01:06:40.400]   they were there in Peruja at the Journalism Festival,
[01:06:40.400 --> 01:06:41.920]   which they had not been--
[01:06:41.920 --> 01:06:43.760]   they threw a party.
[01:06:43.760 --> 01:06:46.560]   They talked about the news integrity initiative.
[01:06:46.560 --> 01:06:49.360]   They're setting up things like the journalism project.
[01:06:49.360 --> 01:06:51.920]   So at least they're trying to do things,
[01:06:51.920 --> 01:06:58.320]   but I'm still concerned about the fundamentals of the kind of control that they have over the
[01:06:58.320 --> 01:06:59.840]   information that people consume.
[01:06:59.840 --> 01:07:06.080]   And that power is really frightening in a lot of ways.
[01:07:06.080 --> 01:07:09.040]   If you look at the fake news issue,
[01:07:09.040 --> 01:07:15.360]   they came out with some tips about how to make sure that the news you're consuming is not fake.
[01:07:15.360 --> 01:07:18.960]   And one of the things they mentioned was you should look at the URL.
[01:07:18.960 --> 01:07:22.880]   Which is the first thing I thought of was Facebook has spent years--
[01:07:22.880 --> 01:07:23.440]   They're scaring it.
[01:07:23.440 --> 01:07:27.200]   --basically hiding and obscuring the URL as much as possible,
[01:07:27.200 --> 01:07:31.440]   so that you will not click on it, because that would take you outside of the network.
[01:07:31.440 --> 01:07:35.120]   So they're fundamentally trying to suck and blow at the same time.
[01:07:35.120 --> 01:07:42.080]   You know, you can't say, check the URL, but we're going to move it around and you won't be able to find it.
[01:07:42.080 --> 01:07:48.240]   So fundamentally, some of the things they've done to keep people in the platform
[01:07:48.240 --> 01:07:53.280]   into boost engagement are the same things that they're now saying they're going to fight.
[01:07:53.280 --> 01:07:55.360]   So I wonder about that.
[01:07:55.360 --> 01:07:58.560]   Yeah, Mike Caulfield wrote a very good piece on Medium.
[01:07:58.560 --> 01:08:03.280]   He is actually part of a web literacy program at WSU Vancouver.
[01:08:03.280 --> 01:08:04.720]   Yeah, it was a great piece.
[01:08:04.720 --> 01:08:08.880]   Facebook's news literacy advice is harmful to news literacy.
[01:08:08.880 --> 01:08:12.640]   He says, "We've been working in this space for a long time.
[01:08:12.640 --> 01:08:13.600]   We know what works and doesn't."
[01:08:13.600 --> 01:08:17.760]   He says, "Most of what Facebook's media literacy campaign contained
[01:08:17.760 --> 01:08:19.040]   was bad advice."
[01:08:19.040 --> 01:08:22.880]   He lists the various things and says exactly what you said, which is,
[01:08:22.880 --> 01:08:26.720]   A, there's no evidence that any of this works.
[01:08:26.720 --> 01:08:33.440]   And B, they actually make it harder to do.
[01:08:33.440 --> 01:08:41.360]   He says, this process is fine to recommend it, but nobody's going to do it because it takes too long.
[01:08:42.640 --> 01:08:50.720]   What they suggested was basically what they did was effectively the least possible thing they could
[01:08:50.720 --> 01:08:51.280]   do.
[01:08:51.280 --> 01:08:51.760]   It was almost trite.
[01:08:51.760 --> 01:08:53.440]   It was almost like the obvious.
[01:08:53.440 --> 01:08:54.880]   Not almost.
[01:08:54.880 --> 01:08:58.160]   It was the kind of thing I've been saying for years.
[01:08:58.160 --> 01:09:00.960]   We need a critical thinking and you've got to check the URL.
[01:09:00.960 --> 01:09:01.840]   Think more critically.
[01:09:01.840 --> 01:09:04.480]   So problem solved.
[01:09:04.480 --> 01:09:10.560]   I mean, the reality is, if you remember, there was an interview with a
[01:09:10.560 --> 01:09:15.200]   Facebook newsfeed staffer, former Facebook newsfeed staffer who said,
[01:09:15.200 --> 01:09:18.400]   "All Facebook cares about is engagement."
[01:09:18.400 --> 01:09:19.760]   And you know what's really engaging?
[01:09:19.760 --> 01:09:21.120]   Bullshit.
[01:09:21.120 --> 01:09:21.360]   Right.
[01:09:21.360 --> 01:09:24.880]   So fake news works for Facebook's business.
[01:09:24.880 --> 01:09:25.680]   Exactly.
[01:09:25.680 --> 01:09:33.360]   The structure of that machine depends on things that make you engaged, not on things that are true.
[01:09:33.360 --> 01:09:37.360]   And that's really why they had this problem because their algorithm favored it.
[01:09:37.360 --> 01:09:39.120]   Right.
[01:09:39.120 --> 01:09:40.320]   Because people engage with it.
[01:09:40.320 --> 01:09:41.280]   Yeah.
[01:09:41.280 --> 01:09:43.600]   The faker it is, the more people engage with it.
[01:09:43.600 --> 01:09:44.080]   Right.
[01:09:44.080 --> 01:09:47.120]   And I think that's why Mark, I'm glad to hear he's coming around a little bit,
[01:09:47.120 --> 01:09:50.320]   but it was reluctant to say they're a media company because really,
[01:09:50.320 --> 01:09:56.640]   their business model is at odds with being a responsible media company.
[01:09:56.640 --> 01:09:57.120]   Right.
[01:09:57.120 --> 01:10:04.320]   And unfortunately, his manifesto, if he wants to follow through on lots of the things that he said in there,
[01:10:05.200 --> 01:10:13.840]   it's going to run headlong into the things that Facebook is already doing because of its business.
[01:10:13.840 --> 01:10:14.560]   You know, you can't...
[01:10:14.560 --> 01:10:21.520]   So some of that is either going to have to change or he won't be able to follow through on the type
[01:10:21.520 --> 01:10:26.000]   of stuff that he's talking about, about bringing people together and helping people with their
[01:10:26.000 --> 01:10:29.360]   community information needs and stuff like that.
[01:10:29.360 --> 01:10:32.560]   That's just not the kind of machine that he has built.
[01:10:32.560 --> 01:10:35.840]   What does, what does Churnet say about digital monopoly?
[01:10:35.840 --> 01:10:40.160]   Because it does strike me that, yeah, Microsoft was a monopoly.
[01:10:40.160 --> 01:10:46.480]   And perhaps the Department of Justice brought it down or the EU actions brought it down,
[01:10:46.480 --> 01:10:53.040]   but more likely just the nature of the world, the nature of the digital economy brought it down,
[01:10:53.040 --> 01:10:53.600]   the business cycle.
[01:10:53.600 --> 01:10:54.720]   Time moving on.
[01:10:54.720 --> 01:10:56.000]   Time moved on.
[01:10:56.000 --> 01:10:56.000]   Right.
[01:10:56.000 --> 01:10:56.560]   Right.
[01:10:56.560 --> 01:11:02.160]   So the most persuasive theory I've heard from someone who followed the anti-trust case was that
[01:11:02.560 --> 01:11:04.480]   the case slowed Microsoft down.
[01:11:04.480 --> 01:11:10.080]   So it didn't really fundamentally change much, but it sort of slowed it down.
[01:11:10.080 --> 01:11:15.600]   And that made it easier for other things to come along and disrupt Microsoft.
[01:11:15.600 --> 01:11:20.000]   Oh, it's like the Germans having to fight Russia and you're at the same time.
[01:11:20.000 --> 01:11:20.800]   Yeah, the two front were...
[01:11:20.800 --> 01:11:21.680]   Just slows you down.
[01:11:21.680 --> 01:11:30.560]   So, but there's no question in my mind that innovation and new developments would inevitably
[01:11:30.560 --> 01:11:32.160]   have done the same thing.
[01:11:32.160 --> 01:11:35.600]   So maybe the case just kind of sped that process up.
[01:11:35.600 --> 01:11:37.840]   Well, and the reason I bring it up is maybe we don't have to worry.
[01:11:37.840 --> 01:11:41.840]   I still think we need to worry.
[01:11:41.840 --> 01:11:46.000]   As a government, you can't say, oh, this will solve itself over time.
[01:11:46.000 --> 01:11:48.800]   Well, I don't know what the government is going to do.
[01:11:48.800 --> 01:11:51.120]   Well, I've got to say, if you're a regulator looking at this,
[01:11:51.120 --> 01:11:52.160]   we're making it as a perspective.
[01:11:52.160 --> 01:11:52.800]   Well, and they're not going to do anything.
[01:11:52.800 --> 01:11:53.040]   Yeah.
[01:11:53.040 --> 01:11:53.200]   Right.
[01:11:53.200 --> 01:11:54.560]   Certainly not the current government.
[01:11:54.560 --> 01:11:55.040]   Help me.
[01:11:55.040 --> 01:11:59.920]   Is not going to wade into Facebook and it's monopoly on the, that's just never going to happen.
[01:12:00.480 --> 01:12:05.600]   I still think we need to worry and I still think we need to point these kinds of things out
[01:12:05.600 --> 01:12:08.080]   and put some pressure on.
[01:12:08.080 --> 01:12:14.400]   It feels to me like Mark Zuckerberg is genuinely concerned about some of this stuff,
[01:12:14.400 --> 01:12:18.000]   or at least he does a good job of pretending to be concerned.
[01:12:18.000 --> 01:12:20.720]   So maybe we should build on that if we can.
[01:12:20.720 --> 01:12:22.880]   I don't think he's a bad person.
[01:12:22.880 --> 01:12:29.680]   It's not doing wrong things deliberately because he wants to kill the media or
[01:12:30.320 --> 01:12:33.520]   make people share fake news articles.
[01:12:33.520 --> 01:12:36.560]   It's just a function of how Facebook operates.
[01:12:36.560 --> 01:12:40.960]   What is your, that paper you read, what was it, Churnette?
[01:12:40.960 --> 01:12:42.640]   Oh, Churnette Sharma.
[01:12:42.640 --> 01:12:43.520]   Yeah, Churnette Sharma.
[01:12:43.520 --> 01:12:44.800]   What is Churn Sharma?
[01:12:44.800 --> 01:12:46.480]   What does Churn Sharma say about this?
[01:12:46.480 --> 01:12:49.200]   Oh, I knew you were going to ask me.
[01:12:49.200 --> 01:12:51.600]   No, I didn't think you were going to ask me.
[01:12:51.600 --> 01:12:53.280]   I went away from it and did it again.
[01:12:53.280 --> 01:12:53.520]   Yeah.
[01:12:53.520 --> 01:12:56.480]   Well, we have his website, but I also have an article I think he wrote
[01:12:57.520 --> 01:13:03.120]   in the Economist a few years ago, Trust Busting in the digital age.
[01:13:03.120 --> 01:13:08.240]   And he says, "There are good reasons why governments should regulate
[01:13:08.240 --> 01:13:11.600]   monopoly's less energetic than offline ones.
[01:13:11.600 --> 01:13:16.400]   The barriers to entry are lower in the digital realms, so there's more competition."
[01:13:16.400 --> 01:13:22.720]   But he also, and I think this is him, says, "Finally, the lesson of recent decades is
[01:13:22.720 --> 01:13:26.960]   technology monopolists may be dominant for a while, but they are eventually toppled
[01:13:27.600 --> 01:13:31.520]   when they fail to move within times or when new technology is expanding the market in
[01:13:31.520 --> 01:13:32.080]   unexpected ways."
[01:13:32.080 --> 01:13:33.360]   And definitely research shows that.
[01:13:33.360 --> 01:13:33.680]   Yeah.
[01:13:33.680 --> 01:13:40.720]   I mean, all the research I've read shows that innovation and certainly internet-powered
[01:13:40.720 --> 01:13:43.360]   digital innovation happens much faster.
[01:13:43.360 --> 01:13:48.400]   By the time the government takes action, it's too late anyway, usually.
[01:13:48.400 --> 01:13:54.560]   Yeah, I mean, you look at the DOJ case, which began in 1998 and concluded some four years later.
[01:13:55.360 --> 01:14:00.640]   And I think by the time it concluded, the whole issue was including the browser and the operating
[01:14:00.640 --> 01:14:03.440]   system. The whole question was moot.
[01:14:03.440 --> 01:14:04.320]   Yeah.
[01:14:04.320 --> 01:14:13.680]   The risk is, and I know Tim Wu has talked about this and written about this, the network effects
[01:14:13.680 --> 01:14:20.240]   of the kind that Facebook has, particularly over information and connections, the social
[01:14:20.240 --> 01:14:26.320]   graph or whatever, is something unlike anything we've seen. So Microsoft's control over your
[01:14:26.320 --> 01:14:32.640]   operating system wasn't anything like what we're talking about. And it's a monopoly that
[01:14:32.640 --> 01:14:39.840]   feeds on itself in a way that requires no effort on Facebook's part, because we do it.
[01:14:39.840 --> 01:14:48.640]   Users do it. And that creates such a huge barrier. And yet it's a barrier that is almost
[01:14:48.640 --> 01:14:53.600]   impossible to dismantle because Facebook didn't create it. Users created it.
[01:14:53.600 --> 01:15:00.960]   You may remember changing the subject a little bit. Three years ago, the Wall Street Journal
[01:15:00.960 --> 01:15:08.000]   reported the FBI was considering loosening its restrictions on marijuana. James Comey
[01:15:08.000 --> 01:15:11.200]   implying he was having a hard time finding hackers who hadn't smoked weed.
[01:15:15.040 --> 01:15:21.120]   Well, motherboard reports this week, the FBI says it can finally find hackers who don't smoke weed.
[01:15:21.120 --> 01:15:27.120]   So it still has a ban on hiring anyone who's used marijuana.
[01:15:27.120 --> 01:15:28.480]   How did they do that? I wonder.
[01:15:28.480 --> 01:15:30.720]   Yeah, I don't know. And how good are these hackers? You know?
[01:15:30.720 --> 01:15:34.720]   I was wondering about what kind of lame drug tests are they using now?
[01:15:34.720 --> 01:15:37.520]   Or maybe they're not smoking weed. They're using other drugs. I don't know.
[01:15:37.520 --> 01:15:40.720]   Maybe they're, is it okay if I microdose LSD?
[01:15:40.720 --> 01:15:43.600]   Oh, that's right. Yeah. That's totally fine.
[01:15:43.600 --> 01:15:48.080]   That's totally fine. Yeah. Since they don't have a test for that anyway,
[01:15:48.080 --> 01:15:50.160]   yeah, that's fine. But weed is right out.
[01:15:50.160 --> 01:15:58.720]   I loved the Jim Sensenbrenner, who is a Republican member of Congress from, I think it was Ohio.
[01:15:58.720 --> 01:16:06.400]   Remember talking about this net neutrality, or I'm sorry, internet, I'm sorry, he's from Wisconsin.
[01:16:07.200 --> 01:16:16.080]   The internet privacy rules. He was talking at a, at a meeting of his town hall meeting of his
[01:16:16.080 --> 01:16:21.040]   constituents. And they pointed out, they were upset that he voted to roll back FCC privacy.
[01:16:21.040 --> 01:16:24.480]   And they pointed out, you know, he said, well, it's like Google or Facebook. Yeah, we want a
[01:16:24.480 --> 01:16:28.640]   levying level playing field, which is what the Republican response has been, you know,
[01:16:28.640 --> 01:16:29.840]   You don't have to use the internet.
[01:16:29.840 --> 01:16:31.520]   That was his answer. Yeah.
[01:16:31.520 --> 01:16:35.040]   One of his constituents said, well, you don't have to use Google or Facebook.
[01:16:35.760 --> 01:16:38.560]   And Sensenbrenner says, yeah, well, you don't have to use the internet.
[01:16:38.560 --> 01:16:43.440]   Fair enough. Fair enough. He says, if you start regulating the internet like a utility,
[01:16:43.440 --> 01:16:47.920]   if you did that right at the beginning, we would have no internet. I don't know if that's true.
[01:16:47.920 --> 01:16:52.160]   I don't think it's my job to tell you you cannot get advertising for your information being sold.
[01:16:52.160 --> 01:16:56.960]   My job is to tell you that you have the opportunity to do it. And then you take it upon yourself to
[01:16:56.960 --> 01:17:02.240]   make the choice that government should give you. Facebook, a woman said, is not comparable to an
[01:17:02.240 --> 01:17:06.640]   ISP. I do not have to go on Facebook. I do have one provider. I live two miles from here.
[01:17:06.640 --> 01:17:11.120]   I have one choice. I don't have to go on Google, but my internet service is different.
[01:17:11.120 --> 01:17:17.200]   That's what his whole argument that in fact, the whole conservative argument about about
[01:17:17.200 --> 01:17:23.760]   it's just that it fails because they're comparing Google and Facebook, you know, using your
[01:17:23.760 --> 01:17:25.840]   completely different information for ads. Yeah.
[01:17:25.840 --> 01:17:28.640]   And by the way, you have one choice.
[01:17:28.640 --> 01:17:32.320]   Well, really, this was you're right. This was the line the ISPs fed them.
[01:17:32.320 --> 01:17:38.080]   This was all the briefings. But really, can we raise the bar, not lower the bar? I don't
[01:17:38.080 --> 01:17:44.240]   mind a level playing field. Let's raise the bar. Not only that. They're not similar. My choice
[01:17:44.240 --> 01:17:51.280]   to use Google or Facebook is not the same as my choice to use the single ISP, you know, that I can
[01:17:51.280 --> 01:17:59.120]   get access from. That's not comparable. Android's head of security says,
[01:17:59.120 --> 01:18:06.080]   Oh, wait, I had a, oh, Google related story, a Google related story that I didn't see on the
[01:18:06.080 --> 01:18:13.200]   rundown. Bring it up. Okay. Google yesterday made their cloud speech API available. And you
[01:18:13.200 --> 01:18:18.960]   guys may be like, well, but this is basically Google's version of Amazon Echo's voice services.
[01:18:18.960 --> 01:18:23.200]   Yeah. Yeah. So this is actually a big deal. Because when I talk to developers,
[01:18:23.200 --> 01:18:28.240]   probably eight or nine months ago, they're like, Google has great stuff, but you have to like
[01:18:28.240 --> 01:18:33.280]   beat them over the head and beg them to get access to it. It's completely opposite of the way
[01:18:33.280 --> 01:18:39.920]   Amazon treated AVS. So there you go, competition. There you go. It's a good thing.
[01:18:39.920 --> 01:18:46.640]   Good point. So you can, and by the way, this is a business for them. They're not giving this away.
[01:18:46.640 --> 01:18:52.160]   Oh, yes. You know, but so great, you know, you so you so speech recognition,
[01:18:52.160 --> 01:18:56.960]   convert audio to text by applying, applying their neural network models,
[01:18:56.960 --> 01:19:05.280]   and easy to use API that recognizes 80 languages. Wow. Wow. I like the inappropriate content
[01:19:05.280 --> 01:19:12.320]   filtering in text results for some languages. I thought I don't know if the echo or AVS has that.
[01:19:12.320 --> 01:19:16.880]   Wait, wait, let me. So it has a button on here. Start now. What happens?
[01:19:16.880 --> 01:19:25.280]   Hello. My name is Leo and I am a technology show host. I don't think it's hearing me.
[01:19:25.280 --> 01:19:33.360]   Anyway, you can, you can, you can do this for yourself and return text results in real time.
[01:19:33.360 --> 01:19:38.320]   So it's basically okay, you know, who, but that anybody can use. I like that.
[01:19:39.200 --> 01:19:43.920]   It's the backend for Google Assistant. I believe it handles noisy audio from any environments.
[01:19:43.920 --> 01:19:49.360]   So it does the recognition, but it doesn't do the artificial intelligence understanding part.
[01:19:49.360 --> 01:19:55.120]   It just sends you back text. Right. It's speech recognition. And then it,
[01:19:55.120 --> 01:20:00.880]   doesn't it tie back? Okay. Yeah. Oh, yeah. So it is. So, yeah, I don't know why they put this on a
[01:20:00.880 --> 01:20:06.560]   page because you could do this on your phone. It's exactly the same thing as doing the recognition
[01:20:06.560 --> 01:20:10.960]   in real time as I'm talking and it isn't doing a very good job.
[01:20:10.960 --> 01:20:15.360]   It's my fact. I love it. I'm not just going, Matthew.
[01:20:15.360 --> 01:20:22.560]   I'm super excited about the sort of future of, you know, universal translation. Like, I don't
[01:20:22.560 --> 01:20:29.200]   care if it's that's what you say. I guess. Yeah. I mean, I'm having just been a bunch of time in
[01:20:29.200 --> 01:20:35.840]   in Italy. Yeah. I'm looking forward to being able to say something and have, you know, it instantly
[01:20:35.840 --> 01:20:40.240]   translated into something that's what you're on. Another feature of your augmented reality glasses.
[01:20:40.240 --> 01:20:45.760]   Don't you think? Oh, Michael, look at your phone and talk into it and then it talks.
[01:20:45.760 --> 01:20:50.160]   I really think that augmented reality earpieces will go along with those glasses.
[01:20:50.160 --> 01:20:55.520]   Or Apple's AirPod type. You'll have some sort of thing in your ear.
[01:20:55.520 --> 01:21:03.120]   I be able. I forget who wrote it, but somebody wrote a fascinating kind of near future potential
[01:21:03.920 --> 01:21:11.440]   for the wireless headphones like the AirPods as a control mechanism for all sorts of things,
[01:21:11.440 --> 01:21:14.720]   you know, just as something you keep in your ear and it understands you.
[01:21:14.720 --> 01:21:17.600]   I wrote that once upon a time. It probably wasn't my version.
[01:21:17.600 --> 01:21:21.520]   It was you. No, a lot of people have written this, but I know I have to.
[01:21:21.520 --> 01:21:27.600]   But I think that's a really compelling, you know, if speech becomes one of the primary ways that
[01:21:27.600 --> 01:21:30.720]   you interact, you're going to have to have something like that. You're not going to want to hold your
[01:21:30.720 --> 01:21:38.800]   phone in front of you all the time. So yes, and I will say for all the people who are sad,
[01:21:38.800 --> 01:21:43.760]   because universal translation means that your languages, you've learned are rendered useless
[01:21:43.760 --> 01:21:48.320]   because that's my daughter. My daughter is in a school right now that is teaching her two
[01:21:48.320 --> 01:21:51.920]   languages. So I'm like, whoa, I'm paying a lot for that. I hope it works.
[01:21:51.920 --> 01:21:54.960]   And Mandarin. Wow.
[01:21:54.960 --> 01:22:00.320]   I'm a type A. Is she not getting confused by learning two different languages at the same time?
[01:22:01.200 --> 01:22:05.280]   She actually dreams in Spanish. So she's been learning Spanish. It's an immersion school
[01:22:05.280 --> 01:22:10.320]   since kindergarten. Okay. So she's like, so she's now really bilingual. And research shows
[01:22:10.320 --> 01:22:16.800]   that kids are their brains are a lot more flexible than old people. Like they're capable of learning
[01:22:16.800 --> 01:22:22.320]   multiple things. And the more languages you learn, the easier it gets. Yeah, but simultaneous. It's
[01:22:22.320 --> 01:22:26.560]   tough. Yeah. I think I mean, I see me. Especially Mandarin. Yeah. Mandarin's one of the hardest
[01:22:26.560 --> 01:22:32.080]   languages I was ever in. That was my major in college. It is. Wow. It's actually, well,
[01:22:32.080 --> 01:22:37.680]   it's actually surprisingly easy to learn the spoken Mandarin. If you can handle the tone structure,
[01:22:37.680 --> 01:22:42.640]   tonal shift, the pronunciation is hard. But the language itself is one of the simplest languages,
[01:22:42.640 --> 01:22:47.600]   because it's old, the older the language, the less you don't have declinations, conjugations,
[01:22:47.600 --> 01:22:52.000]   you don't even have past and future. That's true. But the thing that's hard for people to
[01:22:52.000 --> 01:22:56.080]   learn is the tonal shift. Yeah, but that's like singing. And I bet your daughter is good at it.
[01:22:56.080 --> 01:23:01.600]   It's just, it's, you know, it's just, you know, it's not, it's, you just learn each, you know,
[01:23:01.600 --> 01:23:06.960]   up and down. You know, there's wall, wall, wall. There's just different tones. Once you learn that,
[01:23:06.960 --> 01:23:12.160]   it's not that complicated. I'm hard. I have a hard time. We need to go for them some sometimes.
[01:23:12.160 --> 01:23:16.720]   The hard thing is the written language, which is, yeah, yes, she is.
[01:23:16.720 --> 01:23:23.440]   She is, that is, it is beautiful and complicated. And I feel sad. It's calligraphy. It's something
[01:23:23.440 --> 01:23:28.960]   completely different. And now you can't, you know, when you're writing a, drawing a character, for
[01:23:28.960 --> 01:23:34.960]   instance, there's an order to each stroke, you can't make up, you can't say, well, I'll do this later.
[01:23:34.960 --> 01:23:38.240]   You got to do it in exactly right or right. And they can tell if you don't do it right.
[01:23:38.240 --> 01:23:41.360]   And those Chinese teachers are mean.
[01:23:41.360 --> 01:23:46.880]   They, yes, they, they put the fear of God into my job.
[01:23:46.880 --> 01:23:47.280]   She is.
[01:23:47.280 --> 01:23:51.680]   They take it seriously. You need, you need to teach her a heptopod.
[01:23:52.720 --> 01:23:53.200]   What's that?
[01:23:53.200 --> 01:23:56.400]   From the movie Arrival.
[01:23:56.400 --> 01:23:57.840]   Yes.
[01:23:57.840 --> 01:23:58.400]   Did you see?
[01:23:58.400 --> 01:24:00.640]   That was an interesting language because it looked like very shock.
[01:24:00.640 --> 01:24:01.760]   Very shock.
[01:24:01.760 --> 01:24:07.600]   My daughter took linguistics and she was fascinated by the way they constructed that language.
[01:24:07.600 --> 01:24:09.840]   Because it's real, right? I mean, they attempt, it's not a real language,
[01:24:09.840 --> 01:24:12.080]   but they attempted to follow linguistic rules and grammar.
[01:24:12.080 --> 01:24:12.480]   Right.
[01:24:12.480 --> 01:24:16.240]   They thought, they thought it through, how would you have a language where
[01:24:17.360 --> 01:24:24.560]   the whole thing is a sentence. It's not structured in parts in the same way that our languages are.
[01:24:24.560 --> 01:24:24.960]   Yeah.
[01:24:24.960 --> 01:24:26.480]   It's like German times, million.
[01:24:26.480 --> 01:24:26.960]   And forwards.
[01:24:26.960 --> 01:24:33.120]   Well, Chinese is like that where one character is, is, you know, many is a thought.
[01:24:33.120 --> 01:24:36.560]   Is a thought and this is a heptopod is.
[01:24:36.560 --> 01:24:40.240]   Yeah, it was fascinating. They did a really good job.
[01:24:40.240 --> 01:24:43.360]   I don't think it's a spoiler anymore, right? We can talk about it.
[01:24:43.360 --> 01:24:43.760]   I hope.
[01:24:43.760 --> 01:24:44.080]   I hope.
[01:24:44.080 --> 01:24:44.720]   I've never seen it.
[01:24:44.720 --> 01:24:46.160]   Oh, go see.
[01:24:46.160 --> 01:24:46.800]   I'm okay.
[01:24:46.800 --> 01:24:48.640]   I'm okay. I'm not going to hold you to it.
[01:24:48.640 --> 01:24:50.240]   I'm just like, I'm sorry.
[01:24:50.240 --> 01:24:53.040]   It's not really a sci-fi. It's not really a sci-fi movie.
[01:24:53.040 --> 01:24:56.480]   I mean, if there's aliens, but it's much more.
[01:24:56.480 --> 01:24:57.040]   It's really well done.
[01:24:57.040 --> 01:24:57.520]   Yeah.
[01:24:57.520 --> 01:24:58.640]   I thought it was very good.
[01:24:58.640 --> 01:24:59.200]   I will.
[01:24:59.200 --> 01:25:00.720]   I will check it. I just haven't gotten it.
[01:25:00.720 --> 01:25:03.040]   It reminds me is more like inception in that sense.
[01:25:03.040 --> 01:25:03.600]   It's more like.
[01:25:03.600 --> 01:25:04.800]   Oh, no, I hate that.
[01:25:04.800 --> 01:25:05.040]   Yeah.
[01:25:05.040 --> 01:25:05.680]   I hate that.
[01:25:05.680 --> 01:25:06.560]   No, no, it's not.
[01:25:06.560 --> 01:25:09.600]   I hate movies who are like, I'm going to mess with you.
[01:25:09.600 --> 01:25:10.000]   Yes.
[01:25:10.000 --> 01:25:10.480]   It's a little.
[01:25:10.480 --> 01:25:10.800]   Okay.
[01:25:10.800 --> 01:25:11.680]   Well, there's a little bit.
[01:25:11.680 --> 01:25:12.640]   There is a little bit.
[01:25:12.640 --> 01:25:13.360]   Yes, there is.
[01:25:13.360 --> 01:25:14.960]   But the language is very well done.
[01:25:14.960 --> 01:25:15.760]   I think, you know what?
[01:25:15.760 --> 01:25:17.600]   I'm going to predict you will like it, Stacy.
[01:25:17.600 --> 01:25:18.800]   Okay.
[01:25:18.800 --> 01:25:20.240]   I am. I'm going to predict you will like it.
[01:25:20.240 --> 01:25:20.720]   That's your case.
[01:25:20.720 --> 01:25:22.080]   I will endeavor to watch it.
[01:25:22.080 --> 01:25:23.280]   Now, Matthew knows you much better.
[01:25:23.280 --> 01:25:25.040]   What's the star as a nerd lady?
[01:25:25.040 --> 01:25:26.160]   Yeah, it's nerdy.
[01:25:26.160 --> 01:25:28.480]   And it's intellectually interesting.
[01:25:28.480 --> 01:25:29.440]   And I think it will take--
[01:25:29.440 --> 01:25:30.720]   Yeah, it's really well done.
[01:25:30.720 --> 01:25:30.880]   Yeah.
[01:25:30.880 --> 01:25:32.960]   Heptopod.
[01:25:32.960 --> 01:25:38.000]   If a jit pie moves too fast,
[01:25:40.240 --> 01:25:44.160]   this is a really interesting article in the Wall Street Journal.
[01:25:44.160 --> 01:25:47.440]   If the chairman moves too fast,
[01:25:47.440 --> 01:25:51.920]   he risks a court fight and attempted to kill things like that neutrality.
[01:25:51.920 --> 01:25:53.440]   But if he goes too slow,
[01:25:53.440 --> 01:25:57.760]   it gives the opponent's time to organize a soap-alike protest.
[01:25:57.760 --> 01:25:58.880]   And you know how that ended.
[01:25:58.880 --> 01:26:02.160]   So kind of a challenge, apparently,
[01:26:02.160 --> 01:26:06.160]   politically to kill that neutrality.
[01:26:08.800 --> 01:26:10.000]   I'm glad to hear it anyway.
[01:26:10.000 --> 01:26:12.960]   You want the death of neutrality?
[01:26:12.960 --> 01:26:14.480]   No, no, I'm glad to hear it's a challenge.
[01:26:14.480 --> 01:26:17.200]   The whole thing is just a minefield.
[01:26:17.200 --> 01:26:17.760]   Like the whole thing is--
[01:26:17.760 --> 01:26:20.720]   That's exactly their words.
[01:26:20.720 --> 01:26:22.240]   Whatever path Mr. Pie chooses,
[01:26:22.240 --> 01:26:25.440]   his road has studded with possible landmines,
[01:26:25.440 --> 01:26:27.040]   including vacancies on his commission,
[01:26:27.040 --> 01:26:29.120]   a continuing court fight over current rules,
[01:26:29.120 --> 01:26:31.040]   a new Supreme Court justice,
[01:26:31.040 --> 01:26:32.880]   the coming 2018 midterm elections,
[01:26:32.880 --> 01:26:35.680]   and the potential for the kind of widespread protest
[01:26:35.680 --> 01:26:37.680]   only internet activists can organize.
[01:26:37.680 --> 01:26:42.080]   I do believe that Congress is a little bit as opposed to SOPA.
[01:26:42.080 --> 01:26:48.000]   And of course, the net neutrality laws or regulations
[01:26:48.000 --> 01:26:52.160]   were instituted after an extensive comment period
[01:26:52.160 --> 01:26:53.600]   where they received more comments
[01:26:53.600 --> 01:26:56.240]   than they'd ever received on anything since Janet Jackson.
[01:26:56.240 --> 01:27:00.320]   Net neutrality has been going on since--
[01:27:00.320 --> 01:27:03.760]   Since the internet was invented.
[01:27:03.760 --> 01:27:04.240]   Since 2000--
[01:27:04.240 --> 01:27:07.120]   So 2005 is when we first started fighting over it.
[01:27:07.120 --> 01:27:07.760]   But--
[01:27:07.760 --> 01:27:10.320]   And remember, I think we convinced Tom Wheeler
[01:27:10.320 --> 01:27:13.920]   to change a kind of change his tune.
[01:27:13.920 --> 01:27:15.760]   And it was the millions of comments.
[01:27:15.760 --> 01:27:18.080]   He was not going to do title two.
[01:27:18.080 --> 01:27:21.280]   That was like the third rail of this policy.
[01:27:21.280 --> 01:27:24.000]   And then he was like, "Okay, I guess this is how we're doing it."
[01:27:24.000 --> 01:27:24.480]   Because we have to.
[01:27:24.480 --> 01:27:27.440]   Well, he didn't really have any other way to do it.
[01:27:27.440 --> 01:27:29.120]   He had to do it.
[01:27:29.120 --> 01:27:31.200]   The court told him he had to go with title two.
[01:27:31.200 --> 01:27:32.880]   In order to achieve what he wanted to achieve,
[01:27:32.880 --> 01:27:33.840]   he had to do that.
[01:27:33.840 --> 01:27:35.760]   And this actually is a larger--
[01:27:35.760 --> 01:27:38.560]   And really, I'm going to be fair,
[01:27:38.560 --> 01:27:40.560]   a much more complex discussion,
[01:27:40.560 --> 01:27:45.680]   which is that the FCC can only do what the Congress mandates it to do.
[01:27:45.680 --> 01:27:47.600]   And there are those in Congress who feel like,
[01:27:47.600 --> 01:27:50.720]   whatever Jim Sensenbrenner says,
[01:27:50.720 --> 01:27:53.440]   that choosing to regulate internet service providers
[01:27:53.440 --> 01:27:55.440]   like normal utilities--
[01:27:55.440 --> 01:27:58.080]   In other words, invoking title two of the Telecommunications Act--
[01:27:58.080 --> 01:28:00.880]   wasn't Congress's intent.
[01:28:00.880 --> 01:28:04.720]   So that while it was available as an option,
[01:28:04.720 --> 01:28:06.320]   many in Congress thought,
[01:28:06.320 --> 01:28:09.520]   "This is not what we met when we wrote the Telecommunications Act."
[01:28:09.520 --> 01:28:10.800]   And this is a misinterpret--
[01:28:10.800 --> 01:28:13.760]   A willful misinterpretation of this to get a certain--
[01:28:13.760 --> 01:28:15.680]   And what really should happen.
[01:28:15.680 --> 01:28:17.360]   I may have--
[01:28:17.360 --> 01:28:18.800]   So you're right at the telecommunications act?
[01:28:18.800 --> 01:28:19.280]   Exactly.
[01:28:19.280 --> 01:28:20.960]   I may have to give Adjut Pai credit.
[01:28:20.960 --> 01:28:23.280]   He may be saying--
[01:28:23.280 --> 01:28:28.640]   I think he is saying this title two really wasn't what the people who wrote the law and envisioned.
[01:28:28.640 --> 01:28:30.080]   We should get--
[01:28:30.080 --> 01:28:32.960]   We should go back to Congress and have a comprehensive
[01:28:32.960 --> 01:28:35.280]   telecommunications act that addresses all of this.
[01:28:35.280 --> 01:28:36.880]   And if we do that, that's fine.
[01:28:36.880 --> 01:28:38.240]   But just leave what we have.
[01:28:38.240 --> 01:28:43.680]   Don't go back and take the vase that was smashed on the floor.
[01:28:43.680 --> 01:28:45.040]   And we tried to tape it all together,
[01:28:45.040 --> 01:28:46.880]   and then it got smashed again, and we taped it again.
[01:28:46.880 --> 01:28:47.760]   Don't go back to that.
[01:28:47.760 --> 01:28:50.320]   Say, "Okay, let's go out and make a new vase."
[01:28:50.320 --> 01:28:52.960]   And that's a terrible metaphor.
[01:28:52.960 --> 01:28:54.160]   There is some evidence--
[01:28:54.160 --> 01:28:56.320]   There is some evidence, as the journal points out,
[01:28:56.320 --> 01:29:02.480]   that the new Justice Neil Gorsuch is really a strong believer
[01:29:02.480 --> 01:29:06.240]   that federal agencies should have much more constrained rulemaking capabilities,
[01:29:06.240 --> 01:29:09.120]   that Congress is ultimately responsible for this,
[01:29:09.120 --> 01:29:12.480]   and that Congress should tell the agencies what the rules are,
[01:29:12.480 --> 01:29:14.400]   not that the agencies should make up the rules.
[01:29:14.400 --> 01:29:15.520]   And I think if there's a--
[01:29:15.520 --> 01:29:19.680]   If they're one of the strongest parts of Adjut Pai's argument, is that.
[01:29:19.680 --> 01:29:21.360]   But the risk--
[01:29:21.360 --> 01:29:22.400]   And this is part of the risk--
[01:29:22.400 --> 01:29:25.200]   Is we've got midterm elections coming up not so far off.
[01:29:25.200 --> 01:29:27.840]   The complexion of Congress could change.
[01:29:27.840 --> 01:29:29.760]   If you could get it to Congress now,
[01:29:32.080 --> 01:29:33.520]   before the midterm elections,
[01:29:33.520 --> 01:29:39.280]   well, you'd be assured that you're going to get some rules that are favor big business.
[01:29:39.280 --> 01:29:40.640]   You're not going to--
[01:29:40.640 --> 01:29:41.520]   Well, Adjut Pai is--
[01:29:41.520 --> 01:29:45.840]   You're not going to be able to rewrite the Telecommunications Act.
[01:29:45.840 --> 01:29:47.600]   In a year or two.
[01:29:47.600 --> 01:29:49.200]   That's not going to happen.
[01:29:49.200 --> 01:29:51.840]   And if what Adjut Pai is saying is,
[01:29:51.840 --> 01:29:55.600]   "Well, let's just turn it back to the FTC and we'll just let them handle it."
[01:29:55.600 --> 01:29:57.280]   That's not really a solution.
[01:29:57.280 --> 01:29:57.840]   I disagree.
[01:29:57.840 --> 01:29:59.520]   Yeah, and he has said that as well.
[01:29:59.520 --> 01:30:02.000]   This is not the something the FCC should be involved in.
[01:30:02.000 --> 01:30:04.560]   The Federal Trade Community Commission should be involved in this.
[01:30:04.560 --> 01:30:08.560]   But that may be a disingenuous point of view because the FTC,
[01:30:08.560 --> 01:30:11.680]   even though the FCC doesn't have an enforcement arm, the FTC does,
[01:30:11.680 --> 01:30:17.360]   they also have a lot more cases, including whether diapers give babies rashes and all sorts of things.
[01:30:17.360 --> 01:30:18.960]   The FCC has an enforcement arm.
[01:30:18.960 --> 01:30:20.880]   They have an enforcement bureau.
[01:30:20.880 --> 01:30:22.880]   They march down and find people all the time.
[01:30:22.880 --> 01:30:24.400]   Yeah, well, okay.
[01:30:24.400 --> 01:30:27.360]   Did you not see that Christian slavery?
[01:30:27.360 --> 01:30:29.680]   There's like four vans in the whole country.
[01:30:30.960 --> 01:30:33.120]   And I don't think there's an FCC police.
[01:30:33.120 --> 01:30:34.880]   There's one guy in each face.
[01:30:34.880 --> 01:30:37.120]   It's the FCC bureau of enforcement.
[01:30:37.120 --> 01:30:37.920]   I understand.
[01:30:37.920 --> 01:30:39.520]   I understand.
[01:30:39.520 --> 01:30:44.640]   But I don't think it's really more about making sure radio stations don't exceed this.
[01:30:44.640 --> 01:30:45.600]   No, no, no.
[01:30:45.600 --> 01:30:46.640]   They find people.
[01:30:46.640 --> 01:30:47.920]   They find AT&T.
[01:30:47.920 --> 01:30:49.360]   They find people for programming.
[01:30:49.360 --> 01:30:50.960]   They do a lot.
[01:30:50.960 --> 01:30:55.360]   And they also come down hard on the people who run cell phone jammers in the movie.
[01:30:55.360 --> 01:30:56.080]   No, I agree with you.
[01:30:56.080 --> 01:30:58.960]   I think they would do a better job on this than the FTC,
[01:30:58.960 --> 01:31:00.880]   which has way too much on its plate.
[01:31:00.880 --> 01:31:06.560]   And well, if this is hard and say what we will about Tom Wheeler,
[01:31:06.560 --> 01:31:13.440]   he listened very closely and had a deep technical understanding of what he was doing.
[01:31:13.440 --> 01:31:13.760]   Yeah.
[01:31:13.760 --> 01:31:20.800]   Ajit Pai, I swear to God, is like he parrots the most...
[01:31:20.800 --> 01:31:26.080]   He parrots the ISP line in a way that makes regulatory capture look too...
[01:31:26.080 --> 01:31:28.240]   It's too nice of a word.
[01:31:30.800 --> 01:31:36.080]   Well, I think we as Geeks agree that the internet...
[01:31:36.080 --> 01:31:40.160]   Well, we don't agree on is what the government's role in the internet should be,
[01:31:40.160 --> 01:31:44.400]   but that we would like an internet that is free and open to all.
[01:31:44.400 --> 01:31:47.600]   And certainly I made my living competing...
[01:31:47.600 --> 01:31:50.560]   ISPs are not the internet.
[01:31:50.560 --> 01:31:54.480]   So we should talk about regulating ISPs as a monopoly player.
[01:31:54.480 --> 01:31:56.400]   And this is you're falling into the trap that...
[01:31:56.400 --> 01:31:57.040]   Sorry, Leo.
[01:31:57.040 --> 01:31:58.560]   I could so passionate about this.
[01:31:58.560 --> 01:31:58.560]   Good.
[01:32:00.480 --> 01:32:04.400]   But ISPs want you to think that they are the internet.
[01:32:04.400 --> 01:32:05.920]   They are your access to the internet,
[01:32:05.920 --> 01:32:08.320]   which is why they should be under common carrier,
[01:32:08.320 --> 01:32:11.680]   with forbearance, which is what the FCC tried to do.
[01:32:11.680 --> 01:32:14.960]   And that is all... That is it.
[01:32:14.960 --> 01:32:16.560]   Yeah.
[01:32:16.560 --> 01:32:16.880]   It's our...
[01:32:16.880 --> 01:32:18.880]   No, and I don't disagree with you.
[01:32:18.880 --> 01:32:21.200]   And then we did win that but fight briefly.
[01:32:21.200 --> 01:32:26.800]   But I think that it's not completely unreasonable to say,
[01:32:26.800 --> 01:32:31.680]   "Well, we need to go back to Congress and get a real authorization for this if that's what we're going to do."
[01:32:31.680 --> 01:32:32.880]   That would be the best.
[01:32:32.880 --> 01:32:33.840]   Yes.
[01:32:33.840 --> 01:32:35.200]   Well, you know what would be the best?
[01:32:35.200 --> 01:32:37.440]   Would be no government interference,
[01:32:37.440 --> 01:32:39.440]   but just a really good competitive market
[01:32:39.440 --> 01:32:44.640]   where you could choose as a user, you'd have more than one or two choices.
[01:32:44.640 --> 01:32:45.440]   Right.
[01:32:45.440 --> 01:32:46.560]   Which we don't have.
[01:32:46.560 --> 01:32:47.600]   You don't have it in Canada?
[01:32:47.600 --> 01:32:48.640]   We don't have it in the US.
[01:32:48.640 --> 01:32:49.440]   Right.
[01:32:49.440 --> 01:32:52.000]   And there's no sign of it coming any time soon.
[01:32:52.000 --> 01:32:53.600]   Well, no, it's quite the opposite, isn't it?
[01:32:53.600 --> 01:32:55.520]   Right. Google gave up.
[01:32:55.520 --> 01:32:56.240]   It's getting worse.
[01:32:56.240 --> 01:32:58.400]   Like Amsterdam has such a...
[01:32:58.400 --> 01:33:03.680]   I wish we hadn't hunted on 21st century infrastructure.
[01:33:03.680 --> 01:33:06.640]   Because if you look at Amsterdam, what they've done is they put...
[01:33:06.640 --> 01:33:09.280]   They laid conduit and they said everyone has access to this conduit.
[01:33:09.280 --> 01:33:09.760]   Right.
[01:33:09.760 --> 01:33:10.720]   Just run your pipes through it.
[01:33:10.720 --> 01:33:18.000]   But also Amsterdam is the size of downtown Brooklyn.
[01:33:18.000 --> 01:33:19.280]   It's clearly the right way to...
[01:33:19.280 --> 01:33:20.240]   I mean, not clearly, but it's not...
[01:33:20.240 --> 01:33:20.720]   Sure.
[01:33:20.720 --> 01:33:21.120]   I agree with you.
[01:33:21.120 --> 01:33:22.000]   It is my opinion.
[01:33:22.000 --> 01:33:26.400]   The right way to do this is to have the governments...
[01:33:26.400 --> 01:33:26.720]   Open us.
[01:33:26.720 --> 01:33:31.280]   Which have the right of way and have put in the infrastructure and then let us know.
[01:33:31.280 --> 01:33:35.120]   But even Google didn't want to do open access when they talked about it initially.
[01:33:35.120 --> 01:33:35.680]   And then they were like...
[01:33:35.680 --> 01:33:37.120]   This is such an outlay to put this in.
[01:33:37.120 --> 01:33:38.160]   That's why it has to be public.
[01:33:38.160 --> 01:33:38.720]   Right.
[01:33:38.720 --> 01:33:39.120]   Right.
[01:33:39.120 --> 01:33:39.120]   Right.
[01:33:39.120 --> 01:33:39.120]   Right.
[01:33:39.120 --> 01:33:40.640]   This is what government does.
[01:33:40.640 --> 01:33:40.800]   Yeah.
[01:33:40.800 --> 01:33:44.160]   Because I mean, the economic benefits of having fast internet access...
[01:33:44.160 --> 01:33:48.400]   Remember, we have an administration that wants the highway system to be privatized.
[01:33:48.400 --> 01:33:49.760]   Right.
[01:33:51.840 --> 01:33:52.480]   Okay.
[01:33:52.480 --> 01:33:53.920]   I can't...
[01:33:53.920 --> 01:33:55.120]   I get...
[01:33:55.120 --> 01:33:55.520]   I just...
[01:33:55.520 --> 01:33:58.480]   There is a role for government.
[01:33:58.480 --> 01:34:00.080]   And I can't say frustrating.
[01:34:00.080 --> 01:34:00.560]   I completely agree.
[01:34:00.560 --> 01:34:01.600]   And even...
[01:34:01.600 --> 01:34:03.760]   I think even a conservative...
[01:34:03.760 --> 01:34:05.680]   And in some respects, I'm a conservative.
[01:34:05.680 --> 01:34:09.360]   Understands that the government represents society's interests.
[01:34:09.360 --> 01:34:12.000]   And sometimes, society's interests are encountered
[01:34:12.000 --> 01:34:13.280]   that the interests of businesses.
[01:34:13.280 --> 01:34:16.000]   And that's in cases of monopoly.
[01:34:16.000 --> 01:34:16.800]   For instance, it's all...
[01:34:16.800 --> 01:34:18.000]   Monopolies are great for business.
[01:34:18.000 --> 01:34:19.360]   Not so good for society.
[01:34:19.360 --> 01:34:22.160]   And that's an appropriate place for government to weigh in.
[01:34:22.160 --> 01:34:25.600]   And I think that it's appropriate for government to build infrastructure.
[01:34:25.600 --> 01:34:27.040]   That includes roads.
[01:34:27.040 --> 01:34:28.560]   And I think you could argue.
[01:34:28.560 --> 01:34:29.040]   Water.
[01:34:29.040 --> 01:34:29.440]   Understandably...
[01:34:29.440 --> 01:34:29.520]   Water.
[01:34:29.520 --> 01:34:30.480]   Electricity.
[01:34:30.480 --> 01:34:33.040]   And I think you could argue reasonably internet access.
[01:34:33.040 --> 01:34:37.120]   And what's great is there's a way to make this viable for government and for private
[01:34:37.120 --> 01:34:37.840]   industry.
[01:34:37.840 --> 01:34:41.760]   Have the government build the lines and then lease it to private industry.
[01:34:41.760 --> 01:34:47.840]   Thereby, defraying the cost so the taxpayers don't have to pay for it in the long run.
[01:34:47.840 --> 01:34:52.160]   And giving... having some real competition on top of those lines.
[01:34:52.160 --> 01:34:57.200]   And yet even when municipalities and regions have tried to do that,
[01:34:57.200 --> 01:35:02.000]   they can fought by ISPs and carriers.
[01:35:02.000 --> 01:35:02.400]   Mostly...
[01:35:02.400 --> 01:35:04.480]   Now I'm going to get political here.
[01:35:04.480 --> 01:35:06.800]   In my opinion, that's because we have the best Congress money can buy.
[01:35:06.800 --> 01:35:08.400]   And...
[01:35:08.400 --> 01:35:09.680]   That's not political.
[01:35:09.680 --> 01:35:13.120]   That's just a statement of facts.
[01:35:13.120 --> 01:35:20.480]   And so money wins and they're paying more money for your member of Congress's campaign than you are.
[01:35:20.480 --> 01:35:22.800]   And so they get to do what they want.
[01:35:22.800 --> 01:35:24.000]   And that's just really a shame.
[01:35:24.000 --> 01:35:24.960]   It all comes down to Larry.
[01:35:24.960 --> 01:35:26.240]   Listen, he's always said this.
[01:35:26.240 --> 01:35:28.000]   It all comes down to campaign finance reform.
[01:35:28.000 --> 01:35:34.800]   Until you get big money out of politics, people are never going to win.
[01:35:34.800 --> 01:35:40.480]   Unfortunately, I think Larry just exchanged one unsolvable problem for even larger,
[01:35:40.480 --> 01:35:41.920]   unsolvable problem.
[01:35:41.920 --> 01:35:42.960]   Well, but he was right though.
[01:35:42.960 --> 01:35:43.680]   That's the root...
[01:35:43.680 --> 01:35:44.480]   Oh, he's right.
[01:35:44.480 --> 01:35:45.040]   He's totally...
[01:35:45.040 --> 01:35:50.880]   If you don't solve that, you can do anything you want about DRM and IP and all of that,
[01:35:50.880 --> 01:35:52.640]   because it doesn't matter because...
[01:35:52.640 --> 01:35:56.320]   And all we have to do to change it is to fundamentally change human nature.
[01:35:56.320 --> 01:35:56.560]   Yeah.
[01:35:56.560 --> 01:35:59.040]   I'm on it.
[01:35:59.040 --> 01:36:00.240]   Can you work on that?
[01:36:00.240 --> 01:36:02.640]   I think we need a new paradigm for human...
[01:36:02.640 --> 01:36:04.880]   New interface paradigm for human nature.
[01:36:04.880 --> 01:36:05.440]   Human interface.
[01:36:05.440 --> 01:36:06.880]   Get on that, Stacey.
[01:36:06.880 --> 01:36:08.160]   Your action.
[01:36:08.160 --> 01:36:08.400]   Done.
[01:36:10.080 --> 01:36:12.960]   The Galaxy S8 is emerging.
[01:36:12.960 --> 01:36:13.600]   This is...
[01:36:13.600 --> 01:36:15.520]   In my opinion, it's going to come out this week.
[01:36:15.520 --> 01:36:18.000]   We're already seeing reviews from all the big tech blogs.
[01:36:18.000 --> 01:36:19.440]   We've had it for a couple of weeks in Bargo.
[01:36:19.440 --> 01:36:24.960]   In my opinion, this is going to change what we expect a smartphone to look like.
[01:36:24.960 --> 01:36:27.840]   Basil Liss is the future.
[01:36:27.840 --> 01:36:29.840]   And I'm sad to say...
[01:36:29.840 --> 01:36:30.960]   Yeah, I think it is.
[01:36:30.960 --> 01:36:31.280]   Yeah.
[01:36:31.280 --> 01:36:32.800]   Basil Liss Olens.
[01:36:32.800 --> 01:36:34.080]   And Apple's going to do it,
[01:36:34.080 --> 01:36:35.040]   Samsel's going to do it.
[01:36:35.040 --> 01:36:36.480]   And while I love this pixel,
[01:36:37.120 --> 01:36:40.480]   it's going to start looking like a 1950 Ford Fairlane.
[01:36:40.480 --> 01:36:41.440]   Because...
[01:36:41.440 --> 01:36:42.400]   It's a classic car, man.
[01:36:42.400 --> 01:36:43.760]   It's a classic car.
[01:36:43.760 --> 01:36:45.360]   Come on, those things are worth a lot of money.
[01:36:45.360 --> 01:36:46.640]   It's a classic, but...
[01:36:46.640 --> 01:36:48.720]   Yeah, you know what?
[01:36:48.720 --> 01:36:49.760]   But Basil Liss...
[01:36:49.760 --> 01:36:51.680]   Maybe it's going to look more like a 1980s.
[01:36:51.680 --> 01:36:52.320]   It's all about...
[01:36:52.320 --> 01:36:52.960]   No, you don't.
[01:36:52.960 --> 01:36:54.560]   This has all been solved.
[01:36:54.560 --> 01:36:56.160]   Yeah, it's all been solved.
[01:36:56.160 --> 01:36:59.760]   And what you really want is just a big-ass screen with controls on the screen.
[01:36:59.760 --> 01:37:01.360]   I had to come around.
[01:37:01.360 --> 01:37:04.320]   I did not like it when Android started using on-screen buttons
[01:37:04.320 --> 01:37:05.440]   to set up physical buttons.
[01:37:05.440 --> 01:37:06.880]   But this is Samsel's...
[01:37:06.880 --> 01:37:08.320]   No, I'm fine with that screen button.
[01:37:08.320 --> 01:37:10.960]   It's supposedly Apple's abandoning it.
[01:37:10.960 --> 01:37:12.800]   They're going OLED,
[01:37:12.800 --> 01:37:15.120]   curved displays,
[01:37:15.120 --> 01:37:17.520]   infinity displays with the smallest possible basil.
[01:37:17.520 --> 01:37:20.720]   And people are raving about this phone.
[01:37:20.720 --> 01:37:21.200]   Although...
[01:37:21.200 --> 01:37:23.040]   Oh, I thought...
[01:37:23.040 --> 01:37:24.080]   Yeah, I thought I heard that...
[01:37:24.080 --> 01:37:25.840]   Although the camera is terrible, isn't it?
[01:37:25.840 --> 01:37:28.240]   No, no, the camera's the same as last year, which was superb.
[01:37:28.240 --> 01:37:29.760]   Oh, okay.
[01:37:29.760 --> 01:37:30.160]   Sorry.
[01:37:30.160 --> 01:37:31.440]   I thought it wasn't that good.
[01:37:31.440 --> 01:37:33.200]   Well, what I've seen,
[01:37:33.200 --> 01:37:34.720]   I'm getting mine on Friday, I'll make you know.
[01:37:34.720 --> 01:37:36.320]   But as far as I can tell,
[01:37:36.320 --> 01:37:39.680]   it's a new Sony sensor,
[01:37:39.680 --> 01:37:43.120]   but very similar to last year's sensor,
[01:37:43.120 --> 01:37:43.520]   which was...
[01:37:43.520 --> 01:37:45.120]   The S7 was very, very good.
[01:37:45.120 --> 01:37:48.000]   A Ford exploded?
[01:37:48.000 --> 01:37:50.080]   And this one, no, it's seven.
[01:37:50.080 --> 01:37:51.280]   You see the problem.
[01:37:51.280 --> 01:37:53.280]   See the problem.
[01:37:53.280 --> 01:37:53.680]   Your right.
[01:37:53.680 --> 01:37:55.040]   This phone is not going to explode, right?
[01:37:55.040 --> 01:37:56.720]   This phone, well,
[01:37:56.720 --> 01:38:00.640]   I think you can make the argument that this is the phone least likely to explode.
[01:38:00.640 --> 01:38:00.960]   Okay.
[01:38:00.960 --> 01:38:05.040]   Right. After Samsung spent more than $3 billion on the Note 7's back.
[01:38:05.040 --> 01:38:05.600]   You would think.
[01:38:05.600 --> 01:38:05.920]   You would think.
[01:38:05.920 --> 01:38:08.480]   They announced, you know, we're going to x-ray every phone,
[01:38:08.480 --> 01:38:09.840]   we've got all these new technologies.
[01:38:09.840 --> 01:38:12.160]   They're putting smaller batteries in these things.
[01:38:12.160 --> 01:38:14.800]   I think that they're probably going...
[01:38:14.800 --> 01:38:17.680]   I would guess going to bend over backwards to make sure this phone...
[01:38:17.680 --> 01:38:18.240]   I would think.
[01:38:18.240 --> 01:38:18.640]   That's not...
[01:38:18.640 --> 01:38:19.120]   That was quick.
[01:38:19.120 --> 01:38:20.960]   So smaller batteries.
[01:38:20.960 --> 01:38:22.240]   Is that going to be bad?
[01:38:22.240 --> 01:38:24.640]   3,000 milliamp hours in the 8,
[01:38:24.640 --> 01:38:27.520]   3,500 milliamp hours in the S plus...
[01:38:28.560 --> 01:38:32.480]   Android's doing a lot these days to make these phones last longer.
[01:38:32.480 --> 01:38:33.520]   I'm very curious.
[01:38:33.520 --> 01:38:36.240]   So far, battery tests look pretty good.
[01:38:36.240 --> 01:38:39.760]   It's up at the top, which isn't saying much,
[01:38:39.760 --> 01:38:42.560]   because almost all phones batteries are not enough.
[01:38:42.560 --> 01:38:46.320]   The biggest problem Samsung's going to have is Bixby.
[01:38:46.320 --> 01:38:50.000]   The highly-towned voice assistant that for some reason,
[01:38:50.000 --> 01:38:52.000]   Samsung felt like, oh, it needs another one.
[01:38:52.000 --> 01:38:56.400]   Unfortunately, when it ships, it is not shipping with Bixby.
[01:38:56.400 --> 01:38:57.840]   It's not ready for prime time.
[01:38:58.320 --> 01:39:00.400]   There is a physical Bixby button.
[01:39:00.400 --> 01:39:04.880]   And one would hope that you could map that to Google Assistant.
[01:39:04.880 --> 01:39:07.120]   In fact, early reports were that you could map it
[01:39:07.120 --> 01:39:11.280]   using software that lets you change keystroke actions.
[01:39:11.280 --> 01:39:15.840]   But we're now hearing stories that you can't.
[01:39:15.840 --> 01:39:19.600]   I again will let you know this is something I'm going to want to do,
[01:39:19.600 --> 01:39:22.320]   because if you've got a dedicated voice button, it's nice, right?
[01:39:22.320 --> 01:39:23.200]   That's a nice idea.
[01:39:23.200 --> 01:39:23.280]   Yeah.
[01:39:23.280 --> 01:39:25.200]   It's like the tap.
[01:39:26.160 --> 01:39:29.360]   But if Samsung prevents you from doing it,
[01:39:29.360 --> 01:39:33.440]   even though Bixby is not ready, that would be really, really annoying.
[01:39:33.440 --> 01:39:34.480]   That seems mean.
[01:39:34.480 --> 01:39:36.160]   That would really be annoying.
[01:39:36.160 --> 01:39:38.560]   According to a posted XDA developers,
[01:39:38.560 --> 01:39:41.120]   the new Galaxy S8 firmware update that you'll get
[01:39:41.120 --> 01:39:44.960]   when you get your new phone shuts down the ability to remap the Bixby button.
[01:39:44.960 --> 01:39:51.680]   It was a, the trick was that accessibility could intercept it.
[01:39:51.680 --> 01:39:53.600]   You could map it and you could have it do something else,
[01:39:53.600 --> 01:39:58.960]   like maybe launch the camera, the calendar, or Google Assistant.
[01:39:58.960 --> 01:40:03.840]   Why have soft buttons if you can't program them?
[01:40:03.840 --> 01:40:04.880]   Yeah, I agree.
[01:40:04.880 --> 01:40:06.480]   I agree.
[01:40:06.480 --> 01:40:08.880]   See, I think they're afraid that no one will change it back.
[01:40:08.880 --> 01:40:10.080]   That's exactly right.
[01:40:10.080 --> 01:40:11.120]   Well, yes.
[01:40:11.120 --> 01:40:12.160]   That's exactly right.
[01:40:12.160 --> 01:40:15.280]   Once you don't use Bixby, you'll never use Bixby, right?
[01:40:15.280 --> 01:40:17.120]   And that, that makes sense.
[01:40:17.120 --> 01:40:19.760]   That's why you got to launch these things with the features intact.
[01:40:19.760 --> 01:40:20.000]   Yeah.
[01:40:20.000 --> 01:40:20.800]   Yeah.
[01:40:20.800 --> 01:40:23.200]   Well, if only it was that simple.
[01:40:23.200 --> 01:40:24.240]   Yeah, exactly.
[01:40:24.240 --> 01:40:24.720]   I know.
[01:40:24.720 --> 01:40:25.600]   Everybody wants to.
[01:40:25.600 --> 01:40:26.800]   I'm sure they didn't think of it.
[01:40:26.800 --> 01:40:28.080]   Hey, this is really good news.
[01:40:28.080 --> 01:40:31.440]   Amazon has announced that they're going to,
[01:40:31.440 --> 01:40:36.320]   you know, the Amazon Echo has a very sophisticated seven mic array.
[01:40:36.320 --> 01:40:37.680]   Oh, yeah.
[01:40:37.680 --> 01:40:39.600]   We talked about this on the podcast this morning.
[01:40:39.600 --> 01:40:42.560]   They're now making that available to third party device makers.
[01:40:42.560 --> 01:40:43.440]   Yep.
[01:40:43.440 --> 01:40:47.280]   So this leads to the big obvious question,
[01:40:47.280 --> 01:40:50.400]   which is, okay, everyone can build their own Amazon Echo.
[01:40:50.400 --> 01:40:50.640]   Right.
[01:40:50.640 --> 01:40:56.240]   This is great because this, if voice is the next UI, Amazon is going to be,
[01:40:56.240 --> 01:41:03.120]   that they have built the vocabulary that right now is positioned to be everywhere.
[01:41:03.120 --> 01:41:05.520]   So it's the pinch to zoom for voice, right?
[01:41:05.520 --> 01:41:09.680]   They've built that and you can put it anywhere and everyone can have it.
[01:41:09.680 --> 01:41:16.240]   But how many devices do you want to talk to individually versus having one device be the
[01:41:16.240 --> 01:41:17.680]   butler for all of your devices?
[01:41:17.680 --> 01:41:18.640]   And that's the big question.
[01:41:18.640 --> 01:41:18.800]   Right.
[01:41:18.800 --> 01:41:19.520]   I think.
[01:41:19.520 --> 01:41:28.720]   Yeah, to me, it almost says that Samsung, I mean, Amazon isn't too tied to making hardware
[01:41:28.720 --> 01:41:33.200]   that they make more money from the voice services and they would love everybody
[01:41:33.200 --> 01:41:34.560]   to use it.
[01:41:34.560 --> 01:41:36.240]   And that's, that's pretty exciting.
[01:41:36.240 --> 01:41:42.240]   Well, if you think about Google's slow reluctance to let other people use a system, right?
[01:41:42.240 --> 01:41:44.400]   But think about how Amazon makes money.
[01:41:44.400 --> 01:41:47.360]   They're, they've never made money from hardware.
[01:41:47.360 --> 01:41:50.640]   Hardware is just a way to get you into the Amazon ecosystem.
[01:41:50.640 --> 01:41:51.280]   That's where they make it.
[01:41:51.280 --> 01:41:52.880]   So that you will pay for prime, right?
[01:41:52.880 --> 01:41:59.200]   Well, and I believe homes, homes with the Echo, I'm trying to find the data.
[01:41:59.200 --> 01:42:03.760]   They, those people spend a significant percentage more.
[01:42:03.760 --> 01:42:04.240]   Yeah.
[01:42:04.240 --> 01:42:04.720]   Yeah.
[01:42:04.720 --> 01:42:04.880]   Yeah.
[01:42:04.880 --> 01:42:04.880]   Yeah.
[01:42:04.880 --> 01:42:04.880]   Yeah.
[01:42:04.880 --> 01:42:04.880]   Yeah.
[01:42:04.880 --> 01:42:06.000]   I believe that.
[01:42:06.000 --> 01:42:06.720]   I know I do.
[01:42:06.720 --> 01:42:08.800]   I order stuff all the time.
[01:42:08.800 --> 01:42:13.040]   It's got to the point where I'm in the bathroom and I've run out of something,
[01:42:13.040 --> 01:42:15.440]   you know, shaving cream or whatever.
[01:42:15.440 --> 01:42:18.400]   And I'll, I'll just tell Echo to order it.
[01:42:18.400 --> 01:42:20.400]   It's just easy.
[01:42:20.400 --> 01:42:23.760]   Does anybody use the dash buttons?
[01:42:23.760 --> 01:42:24.800]   I had the dash button.
[01:42:24.800 --> 01:42:26.240]   And then...
[01:42:26.240 --> 01:42:27.360]   Or was that an interim...
[01:42:27.360 --> 01:42:27.840]   My 14 year old...
[01:42:27.840 --> 01:42:29.120]   No, no, no, they're still big.
[01:42:29.120 --> 01:42:29.920]   They're all in on the dash.
[01:42:29.920 --> 01:42:30.320]   Okay.
[01:42:30.320 --> 01:42:30.960]   Oh, yeah, yeah.
[01:42:30.960 --> 01:42:34.640]   But my 14 year old found our dash button and we got a lot of toilet paper
[01:42:34.640 --> 01:42:36.240]   at a very brief period of time.
[01:42:36.240 --> 01:42:37.360]   And so I had to hide it.
[01:42:37.360 --> 01:42:39.840]   And I forgot where I hid it.
[01:42:39.840 --> 01:42:41.200]   It's somewhere in the pantry.
[01:42:41.200 --> 01:42:44.800]   But there actually, no, in fact, there are appliance
[01:42:44.800 --> 01:42:49.440]   manufacturers making dishwashers and washing machines with the built-in dash button.
[01:42:49.440 --> 01:42:53.600]   Yeah, well, the dash button was never the exciting thing.
[01:42:53.600 --> 01:42:56.560]   The dash button is just the front end for the service,
[01:42:56.560 --> 01:42:58.720]   which is the automatic fulfillment.
[01:42:58.720 --> 01:43:01.520]   DVS is something...
[01:43:01.520 --> 01:43:01.920]   That's interesting.
[01:43:01.920 --> 01:43:02.400]   That's interesting.
[01:43:02.400 --> 01:43:03.360]   That's interesting.
[01:43:03.360 --> 01:43:04.880]   So there, oh, that's interesting.
[01:43:04.880 --> 01:43:08.080]   So there is a whole technology beyond the hardware.
[01:43:08.080 --> 01:43:11.040]   This isn't just like sending an order to Amazon.
[01:43:11.040 --> 01:43:13.440]   It's a fulfillment service.
[01:43:13.440 --> 01:43:17.120]   I think it is the dash of automated warehouses and drones and whatnot.
[01:43:17.120 --> 01:43:18.080]   Oh, man.
[01:43:18.080 --> 01:43:23.440]   So if you are a manufacturer, you can actually build that into your product
[01:43:23.440 --> 01:43:26.000]   without ever having the dash, which is the...
[01:43:26.000 --> 01:43:26.240]   Yes.
[01:43:26.240 --> 01:43:29.520]   Look here, dash replacement, DRS.
[01:43:29.520 --> 01:43:29.840]   There it is.
[01:43:29.840 --> 01:43:31.120]   Connected devices.
[01:43:31.120 --> 01:43:33.760]   And that's an extension of Amazon's warehousing.
[01:43:33.760 --> 01:43:37.360]   They handle all of your fulfillment and logistics.
[01:43:37.360 --> 01:43:38.320]   It's running out.
[01:43:38.320 --> 01:43:40.640]   It's an extension of everything Amazon does.
[01:43:40.640 --> 01:43:41.600]   Consumers.
[01:43:41.600 --> 01:43:42.400]   If you have something...
[01:43:42.400 --> 01:43:44.400]   So these are the companies like Whirlpool...
[01:43:44.400 --> 01:43:46.720]   ...that are building this thing in.
[01:43:46.720 --> 01:43:50.000]   Britta, there's pet food companies.
[01:43:50.000 --> 01:43:50.320]   Wow.
[01:43:50.320 --> 01:43:52.960]   And Peter, this is...
[01:43:52.960 --> 01:43:59.760]   Amazon has within it to be the massive IoT company.
[01:43:59.760 --> 01:44:04.800]   If you imagine IoT as cloud data in touching the physical world,
[01:44:04.800 --> 01:44:10.560]   Amazon has that chain down pretty much packed.
[01:44:10.800 --> 01:44:12.400]   And they're automating it quickly.
[01:44:12.400 --> 01:44:16.880]   So if you want to see what the future looks like in terms of socially,
[01:44:16.880 --> 01:44:22.320]   what AI and automation means for the economy, look at what's happening there.
[01:44:22.320 --> 01:44:23.120]   Yeah.
[01:44:23.120 --> 01:44:27.600]   But the good news is it's not going to impact jobs because all of you grocery clerks,
[01:44:27.600 --> 01:44:32.080]   all you truck drivers, you're going to be going to the Amazon warehouse and pulling...
[01:44:32.080 --> 01:44:32.800]   Drone repair.
[01:44:32.800 --> 01:44:34.080]   ...draming right.
[01:44:34.080 --> 01:44:34.800]   What else?
[01:44:34.800 --> 01:44:35.760]   Robot repair.
[01:44:35.760 --> 01:44:38.400]   Because in fact, the robots will be doing the picking anyway.
[01:44:40.240 --> 01:44:40.720]   But yeah.
[01:44:40.720 --> 01:44:44.000]   So at some point, and I don't think it's more than a year or two off,
[01:44:44.000 --> 01:44:46.960]   no human will intervene at all in this process.
[01:44:46.960 --> 01:44:49.360]   So maybe the UPS guy who gives you the package.
[01:44:49.360 --> 01:44:53.040]   Yeah, because the drones may not be launching from their truck just yet.
[01:44:53.040 --> 01:44:54.880]   Soon though.
[01:44:54.880 --> 01:44:56.000]   Yeah.
[01:44:56.000 --> 01:44:59.520]   We're going to actually have at the point where a drone goes to the shelf,
[01:44:59.520 --> 01:45:01.440]   gets the object and brings it to you.
[01:45:01.440 --> 01:45:03.760]   So there literally is no human involvement at all.
[01:45:03.760 --> 01:45:08.320]   You will always have to have, I shouldn't say always, because that's like never.
[01:45:08.320 --> 01:45:13.040]   But for a significant period of time, there will be odd shaped things,
[01:45:13.040 --> 01:45:14.960]   there will be weird wackadoo situations.
[01:45:14.960 --> 01:45:15.280]   Oh yeah.
[01:45:15.280 --> 01:45:18.080]   But the dash button is not for everything, right?
[01:45:18.080 --> 01:45:20.640]   It's for those not so odd shaped things that are easily...
[01:45:20.640 --> 01:45:21.600]   Right.
[01:45:21.600 --> 01:45:24.880]   Wow.
[01:45:24.880 --> 01:45:26.160]   What a world we live in.
[01:45:26.160 --> 01:45:29.920]   I'm just glad that I can't be replaced by a robot.
[01:45:29.920 --> 01:45:33.520]   But you could.
[01:45:33.520 --> 01:45:34.240]   The condition is getting better.
[01:45:36.560 --> 01:45:37.600]   No, not a robot.
[01:45:37.600 --> 01:45:42.480]   I was going to say your competition is just a more enthusiastic young person.
[01:45:42.480 --> 01:45:44.720]   A young person who's on Snapchat.
[01:45:44.720 --> 01:45:47.040]   Well, we always can get replaced by a young person.
[01:45:47.040 --> 01:45:49.280]   That's always been the way of the world.
[01:45:49.280 --> 01:45:50.160]   That's the way of the world.
[01:45:50.160 --> 01:45:50.400]   Yeah.
[01:45:50.400 --> 01:45:51.360]   That's how it works.
[01:45:51.360 --> 01:45:52.240]   That's how it works.
[01:45:52.240 --> 01:45:55.040]   So you're going to get replaced sooner or later anyway.
[01:45:55.040 --> 01:45:58.880]   Any other IoT news?
[01:45:58.880 --> 01:46:01.440]   I don't see any IoT news here, but Stacey, this is your beat.
[01:46:01.440 --> 01:46:03.920]   Any other IoT news we should be aware of?
[01:46:04.640 --> 01:46:05.040]   Let's see.
[01:46:05.040 --> 01:46:08.720]   It's all pretty small this week.
[01:46:08.720 --> 01:46:09.360]   I'm trying to...
[01:46:09.360 --> 01:46:10.720]   I'm like...
[01:46:10.720 --> 01:46:11.280]   We really...
[01:46:11.280 --> 01:46:15.520]   I mean, we got to take advantage of your IoT expert.
[01:46:15.520 --> 01:46:16.640]   No, I want to.
[01:46:16.640 --> 01:46:19.520]   I talk about it a lot on my own show and I know I like overlap.
[01:46:19.520 --> 01:46:23.360]   Well, yeah, and we don't want to steal people from your show at all.
[01:46:23.360 --> 01:46:28.800]   But I think as a kind of a high level look at what's going on in IoT,
[01:46:28.800 --> 01:46:31.680]   and then if people want the deep dive, they can go to your show.
[01:46:31.680 --> 01:46:31.920]   Yeah.
[01:46:31.920 --> 01:46:32.800]   You want to go crazy?
[01:46:32.800 --> 01:46:36.000]   I'm trying to think if there's anything new that I've seen.
[01:46:36.000 --> 01:46:43.440]   Last week, I talked to people about the Google Home versus the Amazon Echo,
[01:46:43.440 --> 01:46:48.400]   because I did an experiment where I swapped mine out for a full week to see if that Google Home was ready.
[01:46:48.400 --> 01:46:48.560]   Which is your life?
[01:46:48.560 --> 01:46:49.680]   Yes, which did you?
[01:46:49.680 --> 01:46:51.360]   It's still the Echo.
[01:46:51.360 --> 01:46:52.960]   Google Home still has some issues.
[01:46:52.960 --> 01:46:58.240]   So that was a little bit of a bummer because Google Home is so much better.
[01:46:59.440 --> 01:47:04.880]   So for home control, its grouping is weird.
[01:47:04.880 --> 01:47:10.160]   So it groups things based on, it puts things in a room.
[01:47:10.160 --> 01:47:12.160]   So you have the name of your particular device.
[01:47:12.160 --> 01:47:18.800]   So living room left table lamp would be one of my devices of the four lights in my living room.
[01:47:18.800 --> 01:47:22.720]   And then I put that in the living room group.
[01:47:22.720 --> 01:47:25.360]   In the Echo, I have those two classifications.
[01:47:25.360 --> 01:47:31.200]   But then I have a further one called downstairs that encompasses every light downstairs.
[01:47:31.200 --> 01:47:32.720]   Google doesn't give you that next level.
[01:47:32.720 --> 01:47:39.680]   So it was kind of irritating because I'd be like, Google Turnoff, living room, Google Turnoff,
[01:47:39.680 --> 01:47:44.240]   dining room, Google Turnoff, kitchen, as opposed to all that.
[01:47:44.240 --> 01:47:45.040]   So that was my--
[01:47:45.040 --> 01:47:50.400]   That's a question and answer vocabulary in the way it handles and remembers the thing you just
[01:47:50.400 --> 01:47:51.200]   asked is better than that.
[01:47:51.200 --> 01:47:51.600]   Yes.
[01:47:51.600 --> 01:47:53.200]   That is so much better.
[01:47:53.200 --> 01:47:58.800]   And it has great things like being able to tie directly into a Chromecast.
[01:47:58.800 --> 01:48:01.440]   But I can't tie it into my Amazon Prime account.
[01:48:01.440 --> 01:48:03.120]   Right.
[01:48:03.120 --> 01:48:03.360]   Right.
[01:48:03.360 --> 01:48:03.920]   Yeah.
[01:48:03.920 --> 01:48:05.520]   So there's just like--
[01:48:05.520 --> 01:48:06.400]   Silos.
[01:48:06.400 --> 01:48:10.640]   I think Amazon is a two-year lead and I think we'll probably maintain lead for some time.
[01:48:10.640 --> 01:48:15.360]   Here, thanks to Acio Braun, our chatroom is--
[01:48:15.360 --> 01:48:17.760]   You know, the future's happening already in China.
[01:48:17.760 --> 01:48:20.880]   This is a Chinese factory where robots sort packages--
[01:48:20.880 --> 01:48:21.360]   Yeah.
[01:48:21.360 --> 01:48:22.480]   I watched that yesterday.
[01:48:22.480 --> 01:48:23.360]   Automatically.
[01:48:23.360 --> 01:48:28.400]   And the only thing humans do is put the thing on the machine.
[01:48:28.400 --> 01:48:31.120]   Well, their only job is to put it on top of a filling job.
[01:48:31.120 --> 01:48:32.400]   Isn't that great?
[01:48:32.400 --> 01:48:34.480]   Well, they have to do it just right.
[01:48:34.480 --> 01:48:36.080]   They have to put it in a straight way.
[01:48:36.080 --> 01:48:38.400]   Oh my god.
[01:48:38.400 --> 01:48:39.280]   You know, what happened?
[01:48:39.280 --> 01:48:41.840]   We were moving away from the Henry Ford assembly line.
[01:48:41.840 --> 01:48:45.120]   And now we're going right back to it.
[01:48:45.120 --> 01:48:50.160]   Humans, apparently, only real skill is our ability to, you know,
[01:48:50.160 --> 01:48:54.080]   spatial and physical recognition of odd-shaped packages.
[01:48:54.080 --> 01:48:56.240]   And that feels like a bone they toss to the--
[01:48:56.240 --> 01:49:01.520]   You couldn't get a claw or something to just pick the thing up and put it on top of the machine.
[01:49:01.520 --> 01:49:02.080]   Come on.
[01:49:02.080 --> 01:49:03.200]   They could get a claw.
[01:49:03.200 --> 01:49:05.040]   But how do we--
[01:49:05.040 --> 01:49:06.480]   Oh, let me survive where--
[01:49:06.480 --> 01:49:07.040]   You know, I mean--
[01:49:07.040 --> 01:49:08.480]   We just--
[01:49:08.480 --> 01:49:09.760]   And they sell free charge too.
[01:49:09.760 --> 01:49:11.760]   Oh my god.
[01:49:11.760 --> 01:49:13.440]   200,000 packages a day.
[01:49:13.440 --> 01:49:19.200]   And eventually they'll be manufactured in automated plants
[01:49:19.200 --> 01:49:20.240]   covered only by--
[01:49:20.240 --> 01:49:26.080]   Wait till we start injecting everything with self-replicating nanobites.
[01:49:26.080 --> 01:49:26.640]   Then we're done.
[01:49:26.640 --> 01:49:30.240]   I read about that.
[01:49:30.240 --> 01:49:33.600]   Just two words.
[01:49:33.600 --> 01:49:34.640]   Gray goo.
[01:49:34.640 --> 01:49:36.960]   Gray goo.
[01:49:36.960 --> 01:49:38.400]   It's not going to work out.
[01:49:38.400 --> 01:49:39.600]   I read science fiction.
[01:49:39.600 --> 01:49:43.600]   What are you reading these days, Stacey?
[01:49:43.600 --> 01:49:45.040]   What's your favorite fiction?
[01:49:45.040 --> 01:49:46.480]   What are you reading fictionally?
[01:49:47.280 --> 01:49:48.080]   Fictionally.
[01:49:48.080 --> 01:49:48.880]   Oh.
[01:49:48.880 --> 01:49:49.600]   Oh, hold on.
[01:49:49.600 --> 01:49:50.640]   I got my Kindle right here.
[01:49:50.640 --> 01:49:51.360]   I'm like--
[01:49:51.360 --> 01:49:53.840]   My daughter and I are reading the Hunger Games allowed to each other.
[01:49:53.840 --> 01:49:54.960]   Oh, perfect.
[01:49:54.960 --> 01:49:57.040]   She's at a perfect age for that, isn't she?
[01:49:57.040 --> 01:49:57.440]   Yeah.
[01:49:57.440 --> 01:49:58.880]   So goo dystopia.
[01:49:58.880 --> 01:49:59.440]   Yeah.
[01:49:59.440 --> 01:50:03.040]   I did read lab girl, but that's nonfiction.
[01:50:03.040 --> 01:50:03.280]   So--
[01:50:03.280 --> 01:50:04.000]   What's that about?
[01:50:04.000 --> 01:50:06.080]   Oh, it's a great book.
[01:50:06.080 --> 01:50:09.040]   It's a female biologist who wrote about--
[01:50:09.040 --> 01:50:10.400]   Just--
[01:50:10.400 --> 01:50:12.560]   It's a memoir of her time in science.
[01:50:12.560 --> 01:50:13.040]   Nice.
[01:50:13.040 --> 01:50:15.760]   It was great because I learned a lot about trees,
[01:50:15.760 --> 01:50:16.480]   which I did--
[01:50:16.480 --> 01:50:19.200]   I'm going to give this to my daughter who wants to be a lab girl.
[01:50:19.200 --> 01:50:20.160]   Oh, yeah.
[01:50:20.160 --> 01:50:20.560]   You should.
[01:50:20.560 --> 01:50:22.320]   It actually doesn't--
[01:50:22.320 --> 01:50:25.600]   Her experience is very--
[01:50:25.600 --> 01:50:28.320]   It's a woman's experience, which you don't hear a lot about,
[01:50:28.320 --> 01:50:31.280]   but she never actually talks about it for like--
[01:50:31.280 --> 01:50:32.560]   That should be any different, right?
[01:50:32.560 --> 01:50:38.080]   And every chapter begins with this great piece of knowledge
[01:50:38.080 --> 01:50:39.840]   about how plants grow.
[01:50:39.840 --> 01:50:42.240]   So you learn a lot.
[01:50:42.240 --> 01:50:42.720]   It's cool.
[01:50:42.720 --> 01:50:43.440]   It was well written.
[01:50:43.440 --> 01:50:46.000]   I'm just trying to think of--
[01:50:46.000 --> 01:50:47.200]   I started reading the North Runner.
[01:50:47.200 --> 01:50:49.840]   Someone in the chat just said, Stacy is an awesome mom.
[01:50:49.840 --> 01:50:51.440]   Yeah, no kidding.
[01:50:51.440 --> 01:50:52.880]   Thanks.
[01:50:52.880 --> 01:50:53.760]   They get to an age though.
[01:50:53.760 --> 01:50:54.800]   I was reading--
[01:50:54.800 --> 01:50:56.320]   My kids are, of course, older,
[01:50:56.320 --> 01:50:58.480]   and so I was reading the Harry Potter books to them.
[01:50:58.480 --> 01:50:59.760]   And we got to about book five,
[01:50:59.760 --> 01:51:01.440]   and Abby, who was about, I think 12,
[01:51:01.440 --> 01:51:02.480]   said, "You're reading it,
[01:51:02.480 --> 01:51:03.440]   so just give it to me."
[01:51:03.440 --> 01:51:06.640]   Well, we make deals with each other
[01:51:06.640 --> 01:51:08.480]   that we're not going to read ahead.
[01:51:08.480 --> 01:51:10.000]   Yeah, she just read a belly--
[01:51:10.000 --> 01:51:11.040]   Yeah, that's a good deal.
[01:51:11.040 --> 01:51:12.000]   That's a good deal.
[01:51:12.000 --> 01:51:12.240]   Yeah.
[01:51:12.240 --> 01:51:12.880]   Yeah.
[01:51:12.880 --> 01:51:13.360]   Yeah.
[01:51:13.360 --> 01:51:15.680]   Every time we stop, she gets--
[01:51:15.680 --> 01:51:17.840]   she's like, "Ah, no."
[01:51:17.840 --> 01:51:18.960]   And I'm like, "Sorry."
[01:51:18.960 --> 01:51:21.920]   Mommy's voice is giving out.
[01:51:21.920 --> 01:51:24.320]   Yeah, so--
[01:51:24.320 --> 01:51:25.920]   Oh, but I am reading the North Water,
[01:51:25.920 --> 01:51:27.360]   which if you're a guy, you might like,
[01:51:27.360 --> 01:51:30.160]   but I was having a real hard time with it.
[01:51:30.160 --> 01:51:31.280]   I'm finally getting around--
[01:51:31.280 --> 01:51:32.240]   Speaking of guy books,
[01:51:32.240 --> 01:51:33.760]   I'm finally getting around to
[01:51:33.760 --> 01:51:36.000]   reading Blood Meridian,
[01:51:36.000 --> 01:51:38.800]   Carmack McCarthy's amazing book.
[01:51:38.800 --> 01:51:40.880]   Yeah, you'll really like North Water then.
[01:51:40.880 --> 01:51:41.440]   That's a guy.
[01:51:41.440 --> 01:51:42.720]   Well, that's what reminded me of it.
[01:51:42.720 --> 01:51:43.760]   I thought, "Man, that sounds--"
[01:51:43.760 --> 01:51:43.920]   Yeah.
[01:51:45.200 --> 01:51:46.560]   Ooh, "The Sympathizer."
[01:51:46.560 --> 01:51:47.440]   That's a good book.
[01:51:47.440 --> 01:51:48.160]   I just read that.
[01:51:48.160 --> 01:51:48.880]   What's that about?
[01:51:48.880 --> 01:51:53.760]   It's about Vietnam,
[01:51:53.760 --> 01:51:57.520]   from the perspective of Vietnamese soldier.
[01:51:57.520 --> 01:51:58.960]   Oh, there's one, the Pulitzer Prize.
[01:51:58.960 --> 01:51:59.120]   Yeah.
[01:51:59.120 --> 01:52:00.880]   It won a Pulitzer.
[01:52:00.880 --> 01:52:01.360]   It's a good book.
[01:52:01.360 --> 01:52:02.080]   Oh, okay.
[01:52:02.080 --> 01:52:02.720]   That's good enough.
[01:52:02.720 --> 01:52:04.400]   It's good enough.
[01:52:04.400 --> 01:52:06.400]   But it was a really good book.
[01:52:06.400 --> 01:52:07.920]   What you reading, Matthew?
[01:52:07.920 --> 01:52:10.480]   I'm reading Seven Eaves.
[01:52:10.480 --> 01:52:11.920]   Love that.
[01:52:11.920 --> 01:52:12.880]   I was just thinking about that.
[01:52:12.880 --> 01:52:13.680]   Neil Stevenson, yeah.
[01:52:13.680 --> 01:52:14.240]   Yeah.
[01:52:14.240 --> 01:52:15.280]   Matthew, is that your daughter?
[01:52:15.280 --> 01:52:16.560]   It was, yeah.
[01:52:16.560 --> 01:52:18.640]   Megan, wave to the camera.
[01:52:18.640 --> 01:52:20.880]   Hi, Megan.
[01:52:20.880 --> 01:52:21.200]   Hi, Jason.
[01:52:21.200 --> 01:52:22.560]   Stacy says hi.
[01:52:22.560 --> 01:52:23.200]   Take care of the cat.
[01:52:23.200 --> 01:52:25.760]   I don't know why I'm saying that
[01:52:25.760 --> 01:52:27.840]   because she can't hear me any better than she can hear you.
[01:52:27.840 --> 01:52:28.240]   I know.
[01:52:28.240 --> 01:52:29.600]   I'm just so excited.
[01:52:29.600 --> 01:52:32.320]   I'm like, I know Matthew for so long.
[01:52:32.320 --> 01:52:34.000]   She was a little girl, I bet, when you--
[01:52:34.000 --> 01:52:35.360]   For sure.
[01:52:35.360 --> 01:52:36.640]   Oh, yeah.
[01:52:36.640 --> 01:52:37.200]   Little Lear.
[01:52:37.200 --> 01:52:38.640]   Little Lear.
[01:52:38.640 --> 01:52:42.480]   Neil Stevenson's Seven Eaves is a very good--
[01:52:42.480 --> 01:52:43.600]   Fast-necking book.
[01:52:43.600 --> 01:52:44.320]   Really well done.
[01:52:44.320 --> 01:52:46.880]   The premise is, and it's not spoiling anything to say,
[01:52:46.880 --> 01:52:51.280]   it begins with the movement, the event,
[01:52:51.280 --> 01:52:53.600]   the moon breaking up into pieces
[01:52:53.600 --> 01:52:57.200]   and the consequences on Earth.
[01:52:57.200 --> 01:52:59.680]   And you don't really know what the name of the movie
[01:52:59.680 --> 01:53:02.640]   of the book is means until really almost the end.
[01:53:02.640 --> 01:53:03.920]   Until the end, yeah.
[01:53:03.920 --> 01:53:05.600]   And then it's like, wow.
[01:53:05.600 --> 01:53:07.440]   Highly recommend it.
[01:53:07.440 --> 01:53:08.240]   Very good book.
[01:53:08.240 --> 01:53:10.720]   Yeah, I thought it was fascinating in the beginning when
[01:53:10.720 --> 01:53:11.920]   the moon explodes.
[01:53:12.320 --> 01:53:14.320]   And everyone thinks, wow, that's really cool.
[01:53:14.320 --> 01:53:15.920]   Look at all the little pieces of the moon.
[01:53:15.920 --> 01:53:19.280]   And even the guy who's like the chief scientist of the US.
[01:53:19.280 --> 01:53:21.520]   There's a Neil de Grasse Tyson character in it.
[01:53:21.520 --> 01:53:22.160]   Yeah, exactly.
[01:53:22.160 --> 01:53:23.920]   And he's thinking, wow, that's pretty amazing.
[01:53:23.920 --> 01:53:26.400]   And he's going on talk shows and he's talking about it.
[01:53:26.400 --> 01:53:30.480]   And then he has this horrible realization
[01:53:30.480 --> 01:53:34.320]   that eventually all of those pieces are going to come falling down.
[01:53:34.320 --> 01:53:36.640]   And it's going to be very, very, very, very bad.
[01:53:36.640 --> 01:53:38.800]   And that's all we need to say.
[01:53:38.800 --> 01:53:42.640]   It's audible has it. I listened on audiobooks, but boy,
[01:53:42.640 --> 01:53:43.760]   I love Neil Stevenson.
[01:53:43.760 --> 01:53:45.040]   He's had some pieces.
[01:53:45.040 --> 01:53:46.320]   Reem D was not great.
[01:53:46.320 --> 01:53:48.400]   He's had a couple of near misses lately.
[01:53:48.400 --> 01:53:50.240]   I went back and read Snow Crash actually.
[01:53:50.240 --> 01:53:52.560]   I think it was last year.
[01:53:52.560 --> 01:53:52.560]   Great.
[01:53:52.560 --> 01:53:57.520]   And it's funny how William Gibson, who knows a thing or two about
[01:53:57.520 --> 01:54:02.080]   science fiction and the future, had a tweet the other day.
[01:54:02.080 --> 01:54:07.760]   Do you remember a guy sent an animated GIF to a Newsweek writer
[01:54:07.760 --> 01:54:09.520]   and triggered his epilepsy?
[01:54:09.520 --> 01:54:09.920]   Yes.
[01:54:09.920 --> 01:54:14.640]   And this William Gibson said that was the first thing he thought of was Snow Crash.
[01:54:14.640 --> 01:54:19.600]   Because that was the closest that he could think of to a sort of virus
[01:54:19.600 --> 01:54:22.880]   that is replicated and distributed basically on the net.
[01:54:22.880 --> 01:54:24.640]   So I thought it was interesting.
[01:54:24.640 --> 01:54:27.600]   So William Gibson is great dismal on Twitter.
[01:54:27.600 --> 01:54:29.120]   He has one of the best Twitter handles ever.
[01:54:29.120 --> 01:54:29.840]   Must follow.
[01:54:29.840 --> 01:54:30.160]   Yeah.
[01:54:30.160 --> 01:54:31.840]   Yeah, it's a good one.
[01:54:31.840 --> 01:54:34.560]   Yeah, we're big fans of his stuff.
[01:54:34.560 --> 01:54:36.000]   Are you Canadian?
[01:54:37.280 --> 01:54:38.000]   Yeah.
[01:54:38.000 --> 01:54:39.280]   Oh, sorry.
[01:54:39.280 --> 01:54:42.000]   You guys are producing all kinds of great detail.
[01:54:42.000 --> 01:54:42.640]   He's in Vancouver.
[01:54:42.640 --> 01:54:43.280]   No, no.
[01:54:43.280 --> 01:54:44.000]   In fact...
[01:54:44.000 --> 01:54:46.320]   Pretty sure he's Canadian.
[01:54:46.320 --> 01:54:46.800]   Yeah, he is.
[01:54:46.800 --> 01:54:53.280]   At Paul Allen's Experience Music Project, they have a...
[01:54:53.280 --> 01:54:54.720]   I can't remember which novel it is.
[01:54:54.720 --> 01:54:55.840]   And maybe it's not...
[01:54:55.840 --> 01:54:57.680]   Maybe it's Neil Stevens and Scripta Nomicon.
[01:54:57.680 --> 01:55:00.240]   Another great one.
[01:55:00.240 --> 01:55:00.800]   But it's...
[01:55:00.800 --> 01:55:04.560]   Is it Gibson or Gibson types it?
[01:55:04.560 --> 01:55:05.440]   Neil writes it.
[01:55:06.000 --> 01:55:07.440]   Hand writes his novels.
[01:55:07.440 --> 01:55:08.640]   And so they have...
[01:55:08.640 --> 01:55:10.320]   So it must have been Neil Stevenson.
[01:55:10.320 --> 01:55:14.000]   And it has a pile, like five foot high pile manuscript
[01:55:14.000 --> 01:55:15.760]   of the handwritten manuscript.
[01:55:15.760 --> 01:55:18.800]   And then all the pens, the pilot pens...
[01:55:18.800 --> 01:55:19.120]   Wow.
[01:55:19.120 --> 01:55:20.320]   ...he went through.
[01:55:20.320 --> 01:55:21.760]   It's the best display ever saw.
[01:55:21.760 --> 01:55:22.320]   It's awesome.
[01:55:22.320 --> 01:55:22.720]   Amazing.
[01:55:22.720 --> 01:55:25.360]   I don't know.
[01:55:25.360 --> 01:55:25.920]   I just...
[01:55:25.920 --> 01:55:26.560]   You know what?
[01:55:26.560 --> 01:55:28.320]   You were two of the smartest people I know.
[01:55:28.320 --> 01:55:29.840]   I thought, I wonder what they're reading.
[01:55:29.840 --> 01:55:33.120]   It's not a normal feature of this show,
[01:55:33.120 --> 01:55:34.080]   but I just thought what the...
[01:55:34.080 --> 01:55:35.360]   No, it's a great feature.
[01:55:35.360 --> 01:55:37.280]   I'm going to go look for those books.
[01:55:37.280 --> 01:55:38.240]   Yeah, right.
[01:55:38.240 --> 01:55:38.880]   Exactly.
[01:55:38.880 --> 01:55:40.240]   I will recommend a great book.
[01:55:40.240 --> 01:55:41.840]   I don't know if our audience will...
[01:55:41.840 --> 01:55:44.320]   Why could or not?
[01:55:44.320 --> 01:55:46.240]   It's kind of a fantasy.
[01:55:46.240 --> 01:55:50.960]   It's by a guy who's very famous for his short stories,
[01:55:50.960 --> 01:55:55.600]   but he's 57 years old and he had never written a novel.
[01:55:55.600 --> 01:55:58.400]   And his first novel just came out.
[01:55:58.400 --> 01:55:59.920]   His name is George Sanders,
[01:55:59.920 --> 01:56:01.840]   and the novel is Lincoln and the Bartow.
[01:56:01.840 --> 01:56:04.960]   Oh, you and the New Yorker.
[01:56:05.200 --> 01:56:06.160]   Good Lord.
[01:56:06.160 --> 01:56:09.280]   This is an amazing novel.
[01:56:09.280 --> 01:56:11.360]   All of the intelligentsia is like,
[01:56:11.360 --> 01:56:12.640]   "This is an amazing novel.
[01:56:12.640 --> 01:56:14.000]   I have it on my list."
[01:56:14.000 --> 01:56:17.520]   This novel is so different and weird and brilliant.
[01:56:17.520 --> 01:56:20.080]   And this is actually a good one to listen on audio,
[01:56:20.080 --> 01:56:25.200]   because they recorded it with 186 different voice actors,
[01:56:25.200 --> 01:56:27.680]   including Nick Offerman,
[01:56:27.680 --> 01:56:29.200]   who has a large part in it.
[01:56:29.200 --> 01:56:31.280]   Of course, Ron Swanson from Parks and Rec.
[01:56:31.280 --> 01:56:32.160]   David Sedaris,
[01:56:32.160 --> 01:56:33.680]   Kerry Brownstein.
[01:56:33.680 --> 01:56:34.800]   There are just...
[01:56:34.800 --> 01:56:36.960]   It's Lena Dunham's in it.
[01:56:36.960 --> 01:56:40.320]   The cast is 186 characters,
[01:56:40.320 --> 01:56:42.960]   because there are a lot of people and there's a lot of dialogue in it.
[01:56:42.960 --> 01:56:44.800]   It's a...
[01:56:44.800 --> 01:56:46.720]   I don't want to say a word about what it's about,
[01:56:46.720 --> 01:56:48.400]   and don't read any of the synopsis,
[01:56:48.400 --> 01:56:52.000]   because it's much more interesting just to not know what you're reading,
[01:56:52.000 --> 01:56:54.080]   and then figure it out as you're listening.
[01:56:54.080 --> 01:56:56.880]   Highly recommend that as an honorable book.
[01:56:56.880 --> 01:57:00.000]   And of course, there's the whole Bill O'Reilly collection.
[01:57:02.640 --> 01:57:03.360]   Yeah.
[01:57:03.360 --> 01:57:06.000]   Available now at ReminderBins Everywhere.
[01:57:06.000 --> 01:57:09.600]   Actually, Bill will come to your house and read it to you.
[01:57:09.600 --> 01:57:14.320]   He's done with his day job.
[01:57:14.320 --> 01:57:15.760]   He'll have a lot of time on his hands.
[01:57:15.760 --> 01:57:16.000]   Yeah.
[01:57:16.000 --> 01:57:20.400]   I had to share that video clip,
[01:57:20.400 --> 01:57:22.000]   which you probably don't want to play,
[01:57:22.000 --> 01:57:22.720]   because they're swearing.
[01:57:22.720 --> 01:57:23.280]   Let's...
[01:57:23.280 --> 01:57:24.240]   I'll do it live.
[01:57:24.240 --> 01:57:25.680]   Yeah.
[01:57:25.680 --> 01:57:26.080]   Yeah.
[01:57:26.080 --> 01:57:26.880]   We'll do it live.
[01:57:26.880 --> 01:57:27.280]   Yeah.
[01:57:27.280 --> 01:57:28.800]   I kill myself laughing.
[01:57:28.800 --> 01:57:30.160]   It's very funny.
[01:57:30.160 --> 01:57:30.560]   It's...
[01:57:30.560 --> 01:57:32.000]   I've seen it a million times.
[01:57:32.000 --> 01:57:32.880]   It is so funny.
[01:57:32.880 --> 01:57:34.240]   But anybody who's worked in my business,
[01:57:34.240 --> 01:58:01.720]   -
[01:58:01.720 --> 01:58:03.080]   - what? - What?
[01:58:03.080 --> 01:58:04.440]   - We get some time. - That's...
[01:58:04.440 --> 01:58:05.320]   It's snack time and then we can...
[01:58:05.320 --> 01:58:06.520]   Virtual time right after.
[01:58:06.520 --> 01:58:09.880]   Yeah, I'm sorry, I can't really thrust these down the wire to you,
[01:58:09.880 --> 01:58:12.280]   but it's time for nature box.
[01:58:12.280 --> 01:58:14.280]   These snacks arrive at your door.
[01:58:14.280 --> 01:58:16.200]   You used to be monthly, but now you can...
[01:58:16.200 --> 01:58:18.040]   You know, and it was a fixed number of snacks.
[01:58:18.040 --> 01:58:20.680]   Now you can order as much as you want, as often as you want.
[01:58:20.680 --> 01:58:21.880]   There's no minimum purchase.
[01:58:21.880 --> 01:58:23.080]   You can cancel anytime.
[01:58:23.080 --> 01:58:24.360]   And these are the best snacks ever.
[01:58:24.360 --> 01:58:25.160]   This one's already opened.
[01:58:25.160 --> 01:58:26.760]   The blueberry almond quinoa bites.
[01:58:26.760 --> 01:58:27.960]   And one of the things I like about this one...
[01:58:27.960 --> 01:58:28.760]   - Oh!
[01:58:28.760 --> 01:58:28.920]   - Yeah.
[01:58:28.920 --> 01:58:30.360]   - They're really good.
[01:58:30.920 --> 01:58:33.960]   If you have a desire for a salty crunchy snack,
[01:58:33.960 --> 01:58:35.960]   but you don't want to eat like Cheetos.
[01:58:35.960 --> 01:58:37.400]   - I try to do. - Yeah.
[01:58:37.400 --> 01:58:37.880]   - I don't.
[01:58:37.880 --> 01:58:39.480]   - This is healthy for you.
[01:58:39.480 --> 01:58:42.360]   Roasted cashews, crispy rice, pumpkin seeds,
[01:58:42.360 --> 01:58:44.280]   roasted almonds, dried blueberries,
[01:58:44.280 --> 01:58:46.520]   rice syrup, cane sugar, quinoa, palm oil,
[01:58:46.520 --> 01:58:49.400]   sesame seeds, natural blueberry flavor, and sea salt.
[01:58:49.400 --> 01:58:51.400]   And you're incredible.
[01:58:51.400 --> 01:58:54.760]   And they satisfy, you know, they check off all the boxes.
[01:58:54.760 --> 01:58:55.720]   - You're killing me. - But...
[01:58:55.720 --> 01:58:58.680]   But one of the things you can do is they all have...
[01:58:58.680 --> 01:59:00.680]   They all have resealable bags.
[01:59:00.680 --> 01:59:02.360]   So you don't have to overeat, right?
[01:59:02.360 --> 01:59:02.840]   And they're nice.
[01:59:02.840 --> 01:59:04.600]   They're usually very healthy-sized.
[01:59:04.600 --> 01:59:05.960]   These are not like the, you know,
[01:59:05.960 --> 01:59:08.680]   the eight chip bags you buy in the grocery store.
[01:59:08.680 --> 01:59:10.280]   Naked trail mix, nuts, raisin,
[01:59:10.280 --> 01:59:11.160]   seasoned dried fruit.
[01:59:11.160 --> 01:59:13.480]   And when I say nuts, raisin, seasoned...
[01:59:13.480 --> 01:59:15.000]   Listen, listen, what's in it?
[01:59:15.000 --> 01:59:17.560]   Peanuts, raisins, almonds, roasted pumpkin seeds,
[01:59:17.560 --> 01:59:19.640]   dried apples, cashews, peanut oil, salt.
[01:59:19.640 --> 01:59:20.120]   That's it.
[01:59:20.120 --> 01:59:21.880]   That's all there is.
[01:59:21.880 --> 01:59:24.040]   And that's what I love about nature at box.
[01:59:24.040 --> 01:59:25.160]   They are making...
[01:59:25.160 --> 01:59:27.160]   There's over 100 snacks to choose from.
[01:59:27.160 --> 01:59:29.640]   Sweet, savory, spicy.
[01:59:29.640 --> 01:59:31.640]   You pick the snacks you want.
[01:59:31.640 --> 01:59:34.120]   They'll deliver them right to your door.
[01:59:34.120 --> 01:59:36.200]   If ever you get a snack you don't like,
[01:59:36.200 --> 01:59:38.200]   they'll replace it for free in your next box.
[01:59:38.200 --> 01:59:40.280]   It is awesome.
[01:59:40.280 --> 01:59:41.320]   High quality ingredients.
[01:59:41.320 --> 01:59:43.000]   Suracha.
[01:59:43.000 --> 01:59:46.120]   Oh, they do a lot of sriracha stuff that's so good.
[01:59:46.120 --> 01:59:48.040]   Highly recommend it.
[01:59:48.040 --> 01:59:50.760]   Actually, one of the favorites,
[01:59:50.760 --> 01:59:52.280]   and I was listening to another podcast,
[01:59:52.280 --> 01:59:53.480]   I think it was Joe Rogans or something
[01:59:53.480 --> 01:59:54.520]   he was talking about.
[01:59:54.520 --> 01:59:56.520]   Nature Box, he said his favorite was
[01:59:56.520 --> 01:59:57.720]   the Big Island pineapple,
[01:59:57.720 --> 01:59:59.000]   and that's my favorite too.
[01:59:59.000 --> 02:00:01.560]   It's the best dried pineapple you ever had.
[02:00:01.560 --> 02:00:03.160]   That's all that's in this.
[02:00:03.160 --> 02:00:04.200]   No sulfites, nothing.
[02:00:04.200 --> 02:00:07.480]   In fact, all of nature box snacks are free from artificial
[02:00:07.480 --> 02:00:09.400]   colors, flavors, or sweeteners,
[02:00:09.400 --> 02:00:11.160]   so you can feel great about snacking.
[02:00:11.160 --> 02:00:13.160]   Your daughter would love these.
[02:00:13.160 --> 02:00:17.640]   And you know, snacks are an important part of growing up,
[02:00:17.640 --> 02:00:20.440]   but let's not go to the vending machine and
[02:00:20.440 --> 02:00:24.600]   stack up on things that aren't going to be...
[02:00:25.720 --> 02:00:27.480]   How about this nutty power clusters,
[02:00:27.480 --> 02:00:29.560]   nut squares with walnuts, almonds, and cashews?
[02:00:29.560 --> 02:00:30.680]   Of course, if you have a nut allergy,
[02:00:30.680 --> 02:00:31.640]   you don't have...
[02:00:31.640 --> 02:00:32.840]   They don't all have nuts in them.
[02:00:32.840 --> 02:00:35.160]   Just great stuff.
[02:00:35.160 --> 02:00:35.960]   Nature Box.
[02:00:35.960 --> 02:00:36.600]   Here's the deal.
[02:00:36.600 --> 02:00:39.960]   Right now, you're going to save 50% on your first order.
[02:00:39.960 --> 02:00:42.120]   So there's no reason not to.
[02:00:42.120 --> 02:00:44.760]   When you go to naturebox.com/twit.
[02:00:44.760 --> 02:00:47.000]   Naturebox.com/twit.
[02:00:47.000 --> 02:00:49.560]   50% off your first order nature box.
[02:00:49.560 --> 02:00:51.880]   It's my favorite part of the day.
[02:00:51.880 --> 02:00:52.920]   Nature Box snack time.
[02:00:52.920 --> 02:00:54.200]   Now everybody get out your mats,
[02:00:54.920 --> 02:00:55.880]   and we're going to take a nap.
[02:00:55.880 --> 02:00:58.200]   No, we're not going to take a nap.
[02:00:58.200 --> 02:01:01.080]   We're going to get your pics of the week.
[02:01:01.080 --> 02:01:05.880]   Did we do the Google Draw thing?
[02:01:05.880 --> 02:01:07.080]   We did it last week.
[02:01:07.080 --> 02:01:07.880]   We did do it.
[02:01:07.880 --> 02:01:08.440]   Okay.
[02:01:08.440 --> 02:01:09.000]   Yes.
[02:01:09.000 --> 02:01:11.080]   I want to make sure that we did not miss that,
[02:01:11.080 --> 02:01:12.120]   because that is so much fun.
[02:01:12.120 --> 02:01:15.000]   Well, I'll let you guys have another Google,
[02:01:15.000 --> 02:01:17.160]   new thing from Google, but I'll let you guys go first.
[02:01:17.160 --> 02:01:18.120]   First state.
[02:01:18.120 --> 02:01:19.880]   Yes, is that yours?
[02:01:19.880 --> 02:01:20.680]   Oh, sorry.
[02:01:20.680 --> 02:01:22.040]   Damn, that was going to be my name.
[02:01:22.040 --> 02:01:22.760]   No, that could be yours.
[02:01:22.760 --> 02:01:23.640]   That's fine.
[02:01:23.640 --> 02:01:24.120]   Okay.
[02:01:24.120 --> 02:01:25.000]   Let's do it right now.
[02:01:25.000 --> 02:01:26.200]   Okay.
[02:01:26.200 --> 02:01:26.360]   Yeah.
[02:01:26.360 --> 02:01:28.520]   Then we'll get Stacey's pick of the week.
[02:01:28.520 --> 02:01:29.960]   So Google Earth rolled out.
[02:01:29.960 --> 02:01:31.320]   Brand new, tell us about it, Matt.
[02:01:31.320 --> 02:01:33.000]   It's amazing.
[02:01:33.000 --> 02:01:36.520]   I saw somebody tweeted a link,
[02:01:36.520 --> 02:01:38.520]   and they said, "Oh, there's a new Google Earth."
[02:01:38.520 --> 02:01:39.800]   And I thought, big deal.
[02:01:39.800 --> 02:01:41.400]   Like, we've seen Google Earth.
[02:01:41.400 --> 02:01:43.240]   What's, you know, so what?
[02:01:43.240 --> 02:01:45.320]   I think it's great and everything, but it was,
[02:01:45.320 --> 02:01:47.640]   it stepped it up.
[02:01:47.640 --> 02:01:49.000]   Like, there's much more.
[02:01:49.000 --> 02:01:51.960]   I had just been in Italy,
[02:01:51.960 --> 02:01:53.560]   and I went to a bunch of places that
[02:01:54.120 --> 02:01:57.000]   I had been and zoomed in and pan around,
[02:01:57.000 --> 02:01:59.560]   and looked at the, it's phenomenal.
[02:01:59.560 --> 02:02:03.800]   Like, it's significantly more.
[02:02:03.800 --> 02:02:05.960]   Well, let's go to Perugia right now.
[02:02:05.960 --> 02:02:07.160]   Zooming in.
[02:02:07.160 --> 02:02:09.480]   So what, so you got your knowledge cards.
[02:02:09.480 --> 02:02:10.840]   Yeah.
[02:02:10.840 --> 02:02:12.600]   What else is different here?
[02:02:12.600 --> 02:02:16.360]   There's, I found the motion,
[02:02:16.360 --> 02:02:18.920]   and this, I don't know of this part as new,
[02:02:18.920 --> 02:02:20.840]   but it was much more seamless.
[02:02:20.840 --> 02:02:23.080]   Yeah, it's really, really nicely done.
[02:02:23.080 --> 02:02:26.600]   Yeah, the panning and zooming, the kind of,
[02:02:26.600 --> 02:02:30.120]   not scrolling, but however you call it,
[02:02:30.120 --> 02:02:32.520]   in a sort of 3D station.
[02:02:32.520 --> 02:02:34.760]   Stacy and I, by the way, are extremely jealous.
[02:02:34.760 --> 02:02:35.880]   Oh, yeah.
[02:02:35.880 --> 02:02:39.320]   We want to go to Perugia, yeah.
[02:02:39.320 --> 02:02:40.280]   You should.
[02:02:40.280 --> 02:02:41.320]   It's so fascinating.
[02:02:41.320 --> 02:02:47.080]   I had no idea, like, it was the capital of the,
[02:02:47.080 --> 02:02:48.920]   the Truscan Empire.
[02:02:48.920 --> 02:02:49.880]   I mean, it was a big deal.
[02:02:49.880 --> 02:02:50.920]   Oh, it's so midi.
[02:02:50.920 --> 02:02:51.880]   Back in the day.
[02:02:51.880 --> 02:02:52.680]   It's in India.
[02:02:52.680 --> 02:02:53.160]   Yeah.
[02:02:53.160 --> 02:02:53.720]   Yeah.
[02:02:53.720 --> 02:02:56.440]   And it was a, at war at one point with Assisi.
[02:02:56.440 --> 02:02:58.840]   In fact, if I remember correctly,
[02:02:58.840 --> 02:03:01.160]   St. Francis was in the war,
[02:03:01.160 --> 02:03:03.640]   and then he got injured,
[02:03:03.640 --> 02:03:06.920]   and that's when he went back to Assisi and became a monk.
[02:03:06.920 --> 02:03:09.000]   I've always loved Google Earth.
[02:03:09.000 --> 02:03:10.760]   It's amazing.
[02:03:10.760 --> 02:03:11.080]   Yeah.
[02:03:11.080 --> 02:03:14.440]   Like I, it was like I saw it for the first time again.
[02:03:14.440 --> 02:03:15.160]   Yeah.
[02:03:15.160 --> 02:03:17.000]   And I was amazed all over it yet.
[02:03:17.000 --> 02:03:19.640]   Yeah, this is like looking down from an airplane.
[02:03:19.640 --> 02:03:20.280]   I mean, it's-
[02:03:20.280 --> 02:03:21.320]   It's really great.
[02:03:22.040 --> 02:03:23.400]   And it's fast.
[02:03:23.400 --> 02:03:24.840]   Now, have you seen Lion yet?
[02:03:24.840 --> 02:03:26.520]   Yes.
[02:03:26.520 --> 02:03:32.040]   That's a great movie, the story of an Indian orphan who gets lost
[02:03:32.040 --> 02:03:35.720]   when he's only, I think, five years old or very young.
[02:03:35.720 --> 02:03:39.960]   Gets on a train, loses his brother,
[02:03:39.960 --> 02:03:43.160]   ends up thousands of miles away from home, completely lost,
[02:03:43.160 --> 02:03:44.600]   becomes a street urchin,
[02:03:44.600 --> 02:03:46.760]   is adopted by an Australian family,
[02:03:46.760 --> 02:03:50.840]   but still can never get over the idea that he lost his mother
[02:03:50.840 --> 02:03:52.600]   and his brother and his sister.
[02:03:52.600 --> 02:03:55.080]   And then Google Earth comes along at just the right moment,
[02:03:55.080 --> 02:03:56.680]   and someone tells him about it.
[02:03:56.680 --> 02:03:58.360]   And I remember that news story.
[02:03:58.360 --> 02:03:58.840]   Yeah.
[02:03:58.840 --> 02:04:00.600]   I remember reading about it.
[02:04:00.600 --> 02:04:00.840]   You do.
[02:04:00.840 --> 02:04:02.120]   Thinking that's incredible,
[02:04:02.120 --> 02:04:05.000]   because it was such a powerful story,
[02:04:05.000 --> 02:04:06.200]   and it's an amazing movie.
[02:04:06.200 --> 02:04:08.360]   So he uses Google Earth because he can only remember,
[02:04:08.360 --> 02:04:09.320]   you know, he remembers some-
[02:04:09.320 --> 02:04:11.560]   he's got the name wrong of the town.
[02:04:11.560 --> 02:04:11.560]   Yeah.
[02:04:11.560 --> 02:04:12.120]   He can't really-
[02:04:12.120 --> 02:04:12.920]   Yeah.
[02:04:12.920 --> 02:04:13.880]   He can't figure it out,
[02:04:13.880 --> 02:04:16.600]   so he just figures out what the radius would be of his-
[02:04:16.600 --> 02:04:18.200]   you know, how far the train went.
[02:04:18.200 --> 02:04:20.040]   It took him months, years, I think.
[02:04:20.840 --> 02:04:22.200]   Really a neat story,
[02:04:22.200 --> 02:04:25.480]   in a beautiful movie that was nominated.
[02:04:25.480 --> 02:04:25.880]   It was so-
[02:04:25.880 --> 02:04:28.200]   It was so incredible.
[02:04:28.200 --> 02:04:30.920]   I remember thinking that can't possibly be true.
[02:04:30.920 --> 02:04:31.160]   Right.
[02:04:31.160 --> 02:04:32.120]   Like it's so-
[02:04:32.120 --> 02:04:33.800]   it seems almost fictional, you know.
[02:04:33.800 --> 02:04:34.280]   Yeah.
[02:04:34.280 --> 02:04:35.000]   It's amazing.
[02:04:35.000 --> 02:04:36.120]   That actually happened.
[02:04:36.120 --> 02:04:36.440]   Yeah.
[02:04:36.440 --> 02:04:39.880]   Ooh, we just zoomed in on the 12 Apostles' Visitors Center
[02:04:39.880 --> 02:04:44.280]   off Port Campbell National Park in Victoria, Australia.
[02:04:44.280 --> 02:04:46.680]   This is really remarkable.
[02:04:46.680 --> 02:04:47.640]   You really feel-
[02:04:47.640 --> 02:04:49.960]   So this is the dice of where in the left there's a die.
[02:04:49.960 --> 02:04:52.200]   And you click it and you get a random spot.
[02:04:52.200 --> 02:04:53.560]   That's fun too, if you-
[02:04:53.560 --> 02:04:54.360]   I think for a kid-
[02:04:54.360 --> 02:04:55.400]   And there's some guides,
[02:04:55.400 --> 02:04:57.960]   there's like, oh yeah, as a kid, this would be incredible.
[02:04:57.960 --> 02:05:02.120]   My daughter, when she was young, she loved Google Earth.
[02:05:02.120 --> 02:05:05.560]   Like she would spend hours just playing with it on a tablet.
[02:05:05.560 --> 02:05:07.960]   And we showed her this and she's just like, wow.
[02:05:07.960 --> 02:05:08.520]   Wait a minute.
[02:05:08.520 --> 02:05:08.920]   She would-
[02:05:08.920 --> 02:05:09.800]   Maybe she would like this.
[02:05:09.800 --> 02:05:11.400]   Girl Muppets around the world.
[02:05:11.400 --> 02:05:11.720]   What?
[02:05:11.720 --> 02:05:13.240]   Okay.
[02:05:13.240 --> 02:05:15.400]   Oh, I get it.
[02:05:15.400 --> 02:05:16.520]   So here's an Afghanistan-
[02:05:16.520 --> 02:05:18.120]   Oh, they're different nationalities.
[02:05:18.120 --> 02:05:18.760]   You had different-
[02:05:18.760 --> 02:05:20.360]   Different up at nationalities.
[02:05:20.360 --> 02:05:22.200]   It's just so seamless.
[02:05:22.200 --> 02:05:26.760]   Like before, you know, it was laggy or blocky or-
[02:05:26.760 --> 02:05:28.120]   And you would kind of lose the-
[02:05:28.120 --> 02:05:32.680]   The illusion in a way.
[02:05:32.680 --> 02:05:33.000]   Right.
[02:05:33.000 --> 02:05:34.280]   It's just so seamless.
[02:05:34.280 --> 02:05:35.240]   Oh, this is-
[02:05:35.240 --> 02:05:35.720]   This is-
[02:05:35.720 --> 02:05:36.120]   This is-
[02:05:36.120 --> 02:05:37.640]   Keep it zooming to that level.
[02:05:37.640 --> 02:05:38.040]   Yeah.
[02:05:38.040 --> 02:05:38.520]   This is-
[02:05:38.520 --> 02:05:39.800]   This is technology that just-
[02:05:39.800 --> 02:05:42.840]   And I remember Google Earth, the original,
[02:05:42.840 --> 02:05:43.800]   when it was Keyhole.
[02:05:43.800 --> 02:05:46.280]   I remember seeing a demo.
[02:05:47.000 --> 02:05:48.440]   And it was one of those things where-
[02:05:48.440 --> 02:05:52.200]   Actually told somebody from Google this in Peruja.
[02:05:52.200 --> 02:05:56.040]   It was one of those moments where I felt like I was living in the future.
[02:05:56.040 --> 02:05:58.440]   Like where all of a sudden, you know,
[02:05:58.440 --> 02:06:00.440]   faster than light travel appears or something.
[02:06:00.440 --> 02:06:05.640]   Like it just felt so different and so futuristic.
[02:06:05.640 --> 02:06:06.920]   And yet there it was.
[02:06:06.920 --> 02:06:07.720]   And it was free.
[02:06:07.720 --> 02:06:10.840]   It's pretty incredible when you think about it.
[02:06:10.840 --> 02:06:12.680]   It's just remarkable.
[02:06:12.680 --> 02:06:13.880]   You want to explore Paris?
[02:06:13.880 --> 02:06:15.000]   Well, we'd all like this-
[02:06:15.000 --> 02:06:17.880]   Dude, lost civilizations from above.
[02:06:17.880 --> 02:06:18.680]   Oh, wait a minute.
[02:06:18.680 --> 02:06:20.920]   We're going to Machu Picchu in a couple of months.
[02:06:20.920 --> 02:06:22.680]   I wonder if that's a lost civilization.
[02:06:22.680 --> 02:06:25.240]   I was like, Paris is cool, but lost civilizations.
[02:06:25.240 --> 02:06:26.600]   How about Nevada Playa?
[02:06:26.600 --> 02:06:30.040]   Between 7,000 and 6,500 BCE,
[02:06:30.040 --> 02:06:32.680]   an urban community arose and what is currently the Egyptian-
[02:06:32.680 --> 02:06:35.000]   Now what do I do to see more of it?
[02:06:35.000 --> 02:06:35.720]   Do I click this?
[02:06:35.720 --> 02:06:37.400]   I don't know.
[02:06:37.400 --> 02:06:41.000]   Just click indiscriminately.
[02:06:41.000 --> 02:06:41.560]   Zoom in.
[02:06:41.560 --> 02:06:41.960]   There's-
[02:06:41.960 --> 02:06:42.840]   That's all you get.
[02:06:42.840 --> 02:06:43.400]   That's it.
[02:06:43.400 --> 02:06:43.800]   That's it?
[02:06:43.800 --> 02:06:44.520]   Well, it's points up.
[02:06:44.520 --> 02:06:45.400]   That's a fascinating-
[02:06:45.400 --> 02:06:46.120]   Don't skip it.
[02:06:46.120 --> 02:06:46.600]   I don't know.
[02:06:46.600 --> 02:06:47.000]   You might.
[02:06:47.000 --> 02:06:47.640]   Let's double click.
[02:06:47.640 --> 02:06:49.240]   Kind of looks like an abstract painting.
[02:06:49.240 --> 02:06:50.040]   Yeah, it's pretty.
[02:06:50.040 --> 02:06:52.680]   You can, in parts-
[02:06:52.680 --> 02:06:54.920]   I mean, there are some amazing things like camels
[02:06:54.920 --> 02:06:58.200]   and their shadows trekking across the desert that you can see.
[02:06:58.200 --> 02:07:00.280]   More lost civilizations.
[02:07:00.280 --> 02:07:00.840]   Let's do another one.
[02:07:00.840 --> 02:07:06.600]   I remember we used to look for the glitches or the hidden things
[02:07:06.600 --> 02:07:09.880]   or there was a woman sunbathing or something.
[02:07:09.880 --> 02:07:12.520]   Everybody in the newsroom just like,
[02:07:12.520 --> 02:07:17.080]   work stopped while everybody looked for all the little Easter eggs.
[02:07:17.080 --> 02:07:17.640]   Google Earth.
[02:07:17.640 --> 02:07:21.560]   There was one where cars looked like they were levitating
[02:07:21.560 --> 02:07:23.880]   in a parking lot because of the way the shadows.
[02:07:23.880 --> 02:07:26.200]   This is really-
[02:07:26.200 --> 02:07:27.720]   My dad is on Google Earth.
[02:07:27.720 --> 02:07:28.440]   Your dad is?
[02:07:28.440 --> 02:07:29.400]   What's he doing there?
[02:07:29.400 --> 02:07:29.400]   Yeah.
[02:07:29.400 --> 02:07:30.760]   Is his-
[02:07:30.760 --> 02:07:31.560]   No, I'm sorry.
[02:07:31.560 --> 02:07:32.680]   He's on Google Street View.
[02:07:32.680 --> 02:07:34.680]   Oh, he's standing outside the house?
[02:07:34.680 --> 02:07:35.880]   No, he's just-
[02:07:35.880 --> 02:07:36.840]   He's trying to start.
[02:07:36.840 --> 02:07:37.320]   He's trying to start.
[02:07:37.320 --> 02:07:37.800]   He's another great one too.
[02:07:37.800 --> 02:07:38.440]   Yeah.
[02:07:38.440 --> 02:07:40.280]   Street View actually, when it came out,
[02:07:41.480 --> 02:07:45.240]   someone I won't name who I worked with was shocked and horrified
[02:07:45.240 --> 02:07:47.000]   and screamed, bloody murder.
[02:07:47.000 --> 02:07:48.040]   And I said, "What is the matter?"
[02:07:48.040 --> 02:07:49.720]   And she said, "If you go to my house,
[02:07:49.720 --> 02:07:55.720]   the car was driving by just as she bent over into her car to get the groceries out."
[02:07:55.720 --> 02:07:57.160]   She's hanging out of a car with you.
[02:07:57.160 --> 02:07:59.160]   Literally, all you see is her butt.
[02:07:59.160 --> 02:07:59.800]   That's her butt.
[02:07:59.800 --> 02:08:03.800]   And she said, "It's going to take like a year for them to go back and re-index."
[02:08:03.800 --> 02:08:09.720]   So I said, "You could send an email and beg them to come down your street again."
[02:08:10.280 --> 02:08:12.360]   This you're actually seeing too loom.
[02:08:12.360 --> 02:08:13.000]   See, look at that.
[02:08:13.000 --> 02:08:13.800]   Yeah.
[02:08:13.800 --> 02:08:14.760]   This is the Street View.
[02:08:14.760 --> 02:08:16.600]   So it's the next step, right?
[02:08:16.600 --> 02:08:17.400]   Yeah.
[02:08:17.400 --> 02:08:19.080]   Wow.
[02:08:19.080 --> 02:08:22.920]   And you know, with all these 360 degree cameras and stuff out there,
[02:08:22.920 --> 02:08:24.440]   at some point, this is just-
[02:08:24.440 --> 02:08:27.320]   You're going to be able to go anywhere and see anything.
[02:08:27.320 --> 02:08:29.160]   And you already can.
[02:08:29.160 --> 02:08:31.080]   I mean, there's not even just streets,
[02:08:31.080 --> 02:08:35.640]   but they've got guys carrying them on their backs and people on scooters and like,
[02:08:35.640 --> 02:08:37.000]   unicycles.
[02:08:37.000 --> 02:08:38.040]   The animals.
[02:08:38.040 --> 02:08:39.960]   You can get street view almost anywhere.
[02:08:39.960 --> 02:08:40.520]   Right.
[02:08:40.520 --> 02:08:41.160]   And so it's something-
[02:08:41.160 --> 02:08:41.640]   Is it an-
[02:08:41.640 --> 02:08:44.840]   A Scottish island that has them on sheep or something?
[02:08:44.840 --> 02:08:45.160]   Is that-
[02:08:45.160 --> 02:08:47.000]   They have-
[02:08:47.000 --> 02:08:47.000]   They have-
[02:08:47.000 --> 02:08:48.200]   They have street view-
[02:08:48.200 --> 02:08:49.800]   They have way more sheep than they do people.
[02:08:49.800 --> 02:08:50.360]   That's for sure.
[02:08:50.360 --> 02:08:50.760]   Wow.
[02:08:50.760 --> 02:08:50.760]   Yeah.
[02:08:50.760 --> 02:08:53.560]   It was like street view cameras on sheep, I want to say.
[02:08:53.560 --> 02:08:54.840]   So it's sheep view.
[02:08:54.840 --> 02:08:56.120]   Sheep view.
[02:08:56.120 --> 02:08:58.040]   Cameras on sheep.
[02:08:58.040 --> 02:08:59.880]   Someone helped me out here because-
[02:08:59.880 --> 02:09:02.520]   The Pharaoh Islands.
[02:09:02.520 --> 02:09:04.280]   Okay.
[02:09:04.280 --> 02:09:05.480]   There's nobody there.
[02:09:05.480 --> 02:09:06.600]   Yeah, they have to use sheep.
[02:09:06.600 --> 02:09:08.360]   There's like four people in a motion sheet.
[02:09:09.640 --> 02:09:10.440]   This is neat.
[02:09:10.440 --> 02:09:14.440]   One of the most mysterious human structures ever built.
[02:09:14.440 --> 02:09:16.760]   Sheep view.
[02:09:16.760 --> 02:09:17.880]   So it wasn't Google.
[02:09:17.880 --> 02:09:18.520]   Oh, there's a sheep.
[02:09:18.520 --> 02:09:18.680]   It wasn't Google.
[02:09:18.680 --> 02:09:19.560]   Oh, there's a sheep.
[02:09:19.560 --> 02:09:20.440]   Yeah.
[02:09:20.440 --> 02:09:21.560]   That's funny.
[02:09:21.560 --> 02:09:21.800]   Ah.
[02:09:21.800 --> 02:09:25.720]   That's funny.
[02:09:25.720 --> 02:09:26.360]   That's cheap view.
[02:09:26.360 --> 02:09:28.280]   All right, Stacy.
[02:09:28.280 --> 02:09:29.160]   IoT.
[02:09:29.160 --> 02:09:31.320]   So this was both Matthew and my pick.
[02:09:31.320 --> 02:09:32.360]   What's your pick of the week?
[02:09:32.360 --> 02:09:37.000]   So you know how we have this punch Leo button that we've been joking about?
[02:09:37.000 --> 02:09:37.880]   Yeah, we really want to make.
[02:09:37.880 --> 02:09:38.360]   Yeah.
[02:09:38.360 --> 02:09:39.240]   Yeah, the virtual year.
[02:09:39.240 --> 02:09:40.040]   Yeah.
[02:09:40.040 --> 02:09:42.520]   Here is now this is not,
[02:09:42.520 --> 02:09:44.040]   this can't be done over Wi-Fi yet,
[02:09:44.040 --> 02:09:47.560]   but it would be simple to add a Wi-Fi shield and program it.
[02:09:47.560 --> 02:09:47.960]   Yeah.
[02:09:47.960 --> 02:09:53.640]   So this is a HACSTER IO project to create a fist bumping robot.
[02:09:53.640 --> 02:09:56.600]   And Leo, I don't think you want the punch to actually be that hard.
[02:09:56.600 --> 02:10:02.120]   So we just have to make the fist bump instead of the punch is more like a fist bump.
[02:10:02.120 --> 02:10:05.640]   Or we could put a stronger servo and make that work.
[02:10:05.640 --> 02:10:06.680]   Well, wait a minute though.
[02:10:06.680 --> 02:10:12.840]   Here on Instructables are the instructions for building a desktop fist bumper.
[02:10:12.840 --> 02:10:16.280]   I think this actually would do the job.
[02:10:16.280 --> 02:10:17.400]   There you go.
[02:10:17.400 --> 02:10:17.880]   I would work.
[02:10:17.880 --> 02:10:19.800]   The idea being,
[02:10:19.800 --> 02:10:22.920]   I mean, it needs to come out faster.
[02:10:22.920 --> 02:10:24.040]   Yeah.
[02:10:24.040 --> 02:10:26.040]   We could probably, we could probably step it up.
[02:10:26.040 --> 02:10:27.400]   Spring loaded.
[02:10:27.400 --> 02:10:28.360]   It's an Arduino.
[02:10:28.360 --> 02:10:28.840]   Look at that.
[02:10:28.840 --> 02:10:33.880]   Well, actually, if you spring loaded it, you wouldn't need the servo.
[02:10:33.880 --> 02:10:34.520]   Oh, you're right.
[02:10:35.080 --> 02:10:38.200]   You just got something to release the, release the fist.
[02:10:38.200 --> 02:10:39.960]   And then it would just.
[02:10:39.960 --> 02:10:41.800]   All right.
[02:10:41.800 --> 02:10:43.720]   So I'm going to let you different instructional things.
[02:10:43.720 --> 02:10:46.520]   You'd have to rely on my staff to.
[02:10:46.520 --> 02:10:47.880]   Shove it back in.
[02:10:47.880 --> 02:10:48.600]   Shove it back.
[02:10:48.600 --> 02:10:49.400]   You're not to replace it.
[02:10:49.400 --> 02:10:50.680]   Yeah.
[02:10:50.680 --> 02:10:53.720]   And to not replace the spring with something really, really powerful.
[02:10:53.720 --> 02:10:54.040]   Yeah.
[02:10:54.040 --> 02:10:55.240]   This is.
[02:10:55.240 --> 02:10:56.920]   I wouldn't actually have to rely on your stuff.
[02:10:56.920 --> 02:10:57.400]   You would.
[02:10:57.400 --> 02:10:58.840]   This is 3D printable.
[02:10:58.840 --> 02:10:59.560]   You can print this.
[02:10:59.560 --> 02:11:02.200]   And then of course there's a.
[02:11:02.200 --> 02:11:04.920]   There's a lot of, you know what?
[02:11:04.920 --> 02:11:08.200]   If you, I search for fist bumper, but there's a lot of this stuff.
[02:11:08.200 --> 02:11:10.920]   Aren't you?
[02:11:10.920 --> 02:11:14.520]   We know it's a powerful human need to either bump or.
[02:11:14.520 --> 02:11:15.320]   Bump fist.
[02:11:15.320 --> 02:11:19.800]   Ladies and gentlemen, thank you so much for being here.
[02:11:19.800 --> 02:11:24.200]   We thank, of course, Jeff Jarvis who had to leave to go on to other things at F8,
[02:11:24.200 --> 02:11:28.040]   but he took some time out from his very busy schedule there to join us.
[02:11:28.040 --> 02:11:33.080]   Also to Stacy Higginbotham, who also took time out from our very busy schedule to join us.
[02:11:33.880 --> 02:11:36.440]   You can find more Stacy at Stacy on IOT.com.
[02:11:36.440 --> 02:11:40.840]   And her podcast, the IOT podcast at IOT podcast.com.
[02:11:40.840 --> 02:11:43.640]   Matthew Ingram writes for fortune.
[02:11:43.640 --> 02:11:44.760]   He is.
[02:11:44.760 --> 02:11:46.520]   Are you going to the lake soon?
[02:11:46.520 --> 02:11:48.280]   It's getting to be lake weather soon.
[02:11:48.280 --> 02:11:48.280]   Soon.
[02:11:48.280 --> 02:11:49.480]   Very soon.
[02:11:49.480 --> 02:11:53.320]   We're all talking about you and your lake pictures.
[02:11:53.320 --> 02:11:54.520]   How jealous we are that.
[02:11:54.520 --> 02:11:56.200]   You got to have.
[02:11:56.200 --> 02:11:56.920]   I can't talk now.
[02:11:56.920 --> 02:11:58.280]   I'm in a canoe on the lake.
[02:11:58.280 --> 02:11:59.960]   There's lots of room.
[02:11:59.960 --> 02:12:02.360]   It's a big lake.
[02:12:02.360 --> 02:12:03.000]   I'll come up.
[02:12:03.000 --> 02:12:04.120]   We'll come up and visit.
[02:12:04.120 --> 02:12:05.320]   We can do this show from the lake.
[02:12:05.320 --> 02:12:06.120]   What's the name of the lake?
[02:12:06.120 --> 02:12:06.280]   Yeah.
[02:12:06.280 --> 02:12:08.680]   It's called Golden Lake.
[02:12:08.680 --> 02:12:09.640]   Oh no.
[02:12:09.640 --> 02:12:15.640]   Stacy, can you go the loans, Leo, the loans.
[02:12:15.640 --> 02:12:17.800]   Oh.
[02:12:17.800 --> 02:12:18.760]   On gold.
[02:12:18.760 --> 02:12:19.720]   Yes.
[02:12:19.720 --> 02:12:20.280]   You will.
[02:12:20.280 --> 02:12:20.840]   You will.
[02:12:20.840 --> 02:12:21.320]   Oh, man.
[02:12:21.320 --> 02:12:22.360]   You'll hold hope.
[02:12:22.360 --> 02:12:29.160]   We do this show every Wednesday about 130 Pacific 430 Eastern 2030 UTC.
[02:12:29.160 --> 02:12:30.760]   If you want to join us, please do.
[02:12:30.760 --> 02:12:32.040]   You can watch live.
[02:12:32.040 --> 02:12:35.400]   Or even email tickets at twitter.tv and join us in studio.
[02:12:35.400 --> 02:12:37.640]   Of course, our chat room is always open at IRC.
[02:12:37.640 --> 02:12:40.520]   Twit.tv on demand video and audio always available after the fact.
[02:12:40.520 --> 02:12:44.840]   On our website, twitter.tv/twig and wherever you get your podcasts.
[02:12:44.840 --> 02:12:48.040]   Last day to vote tomorrow, I guess, is the last day to vote for the webbies.
[02:12:48.040 --> 02:12:50.760]   I don't know what it when is the deadline is it midnight tonight or midnight tomorrow.
[02:12:50.760 --> 02:12:52.840]   We would really appreciate it.
[02:12:52.840 --> 02:12:54.360]   It's this it's neck and neck.
[02:12:54.360 --> 02:13:00.760]   We are fighting tooth and nail against marketplace for the people's choice.
[02:13:01.880 --> 02:13:04.280]   Technology podcast and the Webby Awards.
[02:13:04.280 --> 02:13:06.280]   Man, I want to win this one.
[02:13:06.280 --> 02:13:11.720]   But these marketplace people, they're using the power, the mighty power of American public
[02:13:11.720 --> 02:13:13.080]   radio to solicit votes.
[02:13:13.080 --> 02:13:15.400]   All I got is this here podcast.
[02:13:15.400 --> 02:13:17.240]   So tell a friend.
[02:13:17.240 --> 02:13:19.880]   We actually have a short URL.
[02:13:19.880 --> 02:13:25.800]   You can use twit.to/webbies2017 and your votes are appreciated.
[02:13:25.800 --> 02:13:29.160]   It's like we're literally a couple of percentage points between us.
[02:13:29.160 --> 02:13:31.800]   This is worse than the Georgia 6th.
[02:13:31.800 --> 02:13:32.680]   This is close.
[02:13:32.680 --> 02:13:36.120]   Actually, it's a lot worse than Georgia 6th, which wasn't close at all.
[02:13:36.120 --> 02:13:39.480]   You could vote more than once if you have more than one email address,
[02:13:39.480 --> 02:13:42.600]   but I would personally never tell you to do that.
[02:13:42.600 --> 02:13:47.000]   Thanks for joining us.
[02:13:47.000 --> 02:13:48.840]   Should I tell them, Leo?
[02:13:48.840 --> 02:13:51.080]   I have no dog.
[02:13:51.080 --> 02:13:51.960]   Yeah, tell them.
[02:13:51.960 --> 02:13:56.760]   You can use your Twitter account, your Facebook account, and an email address or two.
[02:13:58.680 --> 02:14:01.560]   Thanks for joining us and we'll see you next time on this week at Google.
[02:14:01.560 --> 02:14:09.000]   Bye bye.
[02:14:09.000 --> 02:14:11.580]   (upbeat music)
[02:14:11.580 --> 02:14:13.820]   [MUSIC PLAYING]

