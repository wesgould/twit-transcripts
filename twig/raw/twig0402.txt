;FFMETADATA1
title=Garanimal House
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=402
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.560]   It's time for Twig this week in Google Jeff and Stacy are here with a great show. We're gonna talk about
[00:00:06.560 --> 00:00:11.280]   the decision by the FCC to eliminate
[00:00:11.280 --> 00:00:20.360]   Net neutrality good bad indifferent will also talk about Google revising its search results to prevent fake news and the ultimate juicer
[00:00:20.360 --> 00:00:23.680]   Only $400. It's all coming up next on Twig
[00:00:23.680 --> 00:00:29.360]   Netcasts you love
[00:00:29.360 --> 00:00:31.360]   From people you trust
[00:00:31.360 --> 00:00:43.200]   This is Twig bandwidth for this week in Google is provided by cash fly C A C H E F L Y
[00:00:43.200 --> 00:00:45.760]   .com
[00:00:45.760 --> 00:00:55.360]   This is Twig this week in Google episode 402 recorded Wednesday April 26 2017
[00:00:55.920 --> 00:01:02.640]   The Random House this week in Google is brought to you by box.com bringing people and ideas together
[00:01:02.640 --> 00:01:04.640]   So businesses can work as one
[00:01:04.640 --> 00:01:09.920]   71,000 companies including the majority of the fortune 500 are already on box
[00:01:09.920 --> 00:01:13.960]   Why aren't you for a free two-week trial and to find out more visit box
[00:01:13.960 --> 00:01:16.920]   B O X calm
[00:01:16.920 --> 00:01:21.760]   It's time for twig this week in Google. Oh, I'm excited
[00:01:21.760 --> 00:01:25.760]   We got a great big show planned for you and we're gonna stick with the core group
[00:01:25.760 --> 00:01:30.440]   Because we got this tight. We got this thing going on Jeff Jarvis
[00:01:30.440 --> 00:01:37.960]   He's at the City University of Newark where he teaches journalism at the grad school there. He's also a blogger buzz machine.com
[00:01:37.960 --> 00:01:40.720]   Long time
[00:01:40.720 --> 00:01:42.480]   journalist writer
[00:01:42.480 --> 00:01:46.920]   Book author it's so great to have you Jeff and we were just observing that we started the show
[00:01:46.920 --> 00:01:51.080]   August 2009 so our eighth anniversary is coming up this summer
[00:01:51.880 --> 00:01:54.760]   Together long trip down the marillion. Yeah
[00:01:54.760 --> 00:02:01.920]   And we welcome the newest member, but most welcome to the show Stacey Higginbotham from
[00:02:01.920 --> 00:02:06.760]   Formerly of giga home for many years. Who was at fortune for a minute?
[00:02:06.760 --> 00:02:11.640]   Cup of coffee as they say and then started her own IOT podcast and IOT
[00:02:11.640 --> 00:02:17.280]   Site high Stacey you're in where are you? I'm in New York nice for
[00:02:17.280 --> 00:02:19.880]   Finding out about IOT stuff
[00:02:20.280 --> 00:02:25.240]   Yes, I was doing an event for teaching people in the media how to review connected gadgets
[00:02:25.240 --> 00:02:30.240]   Oh, that's telling them about smart homes. That's the kind of boy. I didn't know people in the media were interested in learning anything
[00:02:30.240 --> 00:02:33.480]   Hey
[00:02:33.480 --> 00:02:37.440]   Yeah, I say that as a person in the media I know
[00:02:37.440 --> 00:02:43.320]   Maybe I'm a reformed media person, but that's good to know that they want they want to do a better job of covering it
[00:02:43.320 --> 00:02:45.320]   Yeah, I presume mainstream media
[00:02:45.320 --> 00:02:49.000]   Yes, I talked to people at Martha Stewart magazine Oprah magazine
[00:02:49.720 --> 00:02:57.120]   Crazy other places it was it was really neat. I learned a lot and we and we owe a debt of gratitude to because I guess you didn't have much
[00:02:57.120 --> 00:03:02.400]   Connectivity there. Where are you so we can give them a plug sure? I am at we communications
[00:03:02.400 --> 00:03:09.280]   You guys may be familiar with them as Microsoft's PR agency. Oh used to be wag yet or Wagner. That's true. Yes
[00:03:09.280 --> 00:03:11.720]   Yes, now she's we what a good idea
[00:03:11.720 --> 00:03:19.120]   So they're they're being super kind in let me tell you we are accruing all kinds of technical debt with them good lord
[00:03:19.640 --> 00:03:21.640]   Yeah, thank you
[00:03:21.640 --> 00:03:27.160]   Yeah, we started by Pam Edstrom who was a Microsoft employee then spun off into a agency of her own
[00:03:27.160 --> 00:03:35.600]   Didn't one of the founders just die recently? Yes celebrating the life of Pam Edstrom. She did a message from Lissa Wagner Zorkin who was the Wagner in wag it
[00:03:35.600 --> 00:03:43.080]   Yeah, but really a venerable agency years. Yeah. Yeah. Oh, yeah, anybody covered tech new wag ed
[00:03:43.080 --> 00:03:45.800]   Tech PR was its own
[00:03:45.800 --> 00:03:48.000]   unique world in PR
[00:03:48.320 --> 00:03:52.200]   Made its own kind of PR stars. It's kind of interesting. I mean
[00:03:52.200 --> 00:03:57.640]   They were so tightly associated with Microsoft for so many years
[00:03:57.640 --> 00:04:01.320]   I'm glad they're still
[00:04:01.320 --> 00:04:06.280]   Doing what they're doing. That's great. Thank you. I think they have more than just Microsoft now. Oh, yeah
[00:04:06.280 --> 00:04:09.880]   Lots of clients. Well, I think the rebranding to we was smart. I like that
[00:04:09.880 --> 00:04:16.720]   Anyway, we have lots to talk about so I'm not gonna I'm not gonna drag it out here. I don't know where to start though
[00:04:18.000 --> 00:04:24.440]   Google has said they may be doing an ad blocker in Chrome or no, they haven't sent anything but
[00:04:24.440 --> 00:04:27.520]   Apparently, that's the Bloomberg story
[00:04:27.520 --> 00:04:34.160]   There is a post from Google search had been goams that they're gonna change
[00:04:34.160 --> 00:04:42.480]   How search works because of the fake news problem and the snippets problem and they're gonna use humans us
[00:04:43.120 --> 00:04:49.600]   But they've always used humans, but we're gonna make it easier for us to get involved. Yeah, but they've changed they changed the
[00:04:49.600 --> 00:04:57.480]   Criteria and what struck me about this? Well, I think it's very important is that Ben Gomes who's the genius in search at Google?
[00:04:57.480 --> 00:05:06.520]   Talks about favoring quality talks about reliable sources talks about giving people authority. I think that's a really big deal
[00:05:06.520 --> 00:05:10.800]   It's not Google's not saying we're favoring truth. We're favoring reliability
[00:05:11.440 --> 00:05:13.440]   quality and authority
[00:05:13.440 --> 00:05:22.320]   That matters in a few ways that's that's Google deciding to bias in favor of the good stuff and decide what the good stuff is
[00:05:22.320 --> 00:05:27.800]   You know not that Google didn't do it. Extend. They always wanted a good experience. They always wanted relevance
[00:05:27.800 --> 00:05:37.680]   But now to say out loud they want quality. I think is good for Google and good for those of us who fancy that we make quality
[00:05:38.200 --> 00:05:43.960]   it's a kind of timely because Robert Percy passed away this week the author of
[00:05:43.960 --> 00:05:50.160]   Zen in the art of motorcycle maintenance and it the much of the book is really about
[00:05:50.160 --> 00:05:56.240]   quality right he talks a lot about quality what is what is quality and
[00:05:56.240 --> 00:05:59.720]   It's funny because
[00:05:59.720 --> 00:06:05.760]   Gosh, you think that from day one the quality of their search results was the most important
[00:06:06.120 --> 00:06:08.560]   That's what they offer right there's per se well
[00:06:08.560 --> 00:06:13.040]   People learned how to game the system. I mean that if we think about
[00:06:13.040 --> 00:06:17.000]   Googles in the constant race and they use you know
[00:06:17.000 --> 00:06:24.880]   The original was like people linking back a sort of authoritative linking back people started gaming that and then they started using different metrics
[00:06:24.880 --> 00:06:29.320]   And so this is not like a huge change. I think Google has always wanted to
[00:06:29.320 --> 00:06:33.880]   Surface the best and brightest and now that we're in such an automated age. I
[00:06:34.880 --> 00:06:37.720]   Think it comes back to people so I don't know
[00:06:37.720 --> 00:06:40.040]   quality thing about it quality is
[00:06:40.040 --> 00:06:42.640]   It's one of those things you know when you see it
[00:06:42.640 --> 00:06:49.400]   But it's pretty hard to pin down and everybody's idea of what a quality search result is might would vary wouldn't it?
[00:06:49.400 --> 00:06:54.480]   It depends on what you search for. I mean if you're really searching
[00:06:54.480 --> 00:07:01.000]   You know when you search for how to make a peanut butter and jelly sandwich when you get a like that's actually a terrible example
[00:07:01.000 --> 00:07:04.280]   That's a because that's a good example because that's obvious
[00:07:04.840 --> 00:07:13.480]   Right well how to pick a smartphone so if you if you look that is harder, but hopefully you know there's all those crappy like
[00:07:13.480 --> 00:07:15.480]   the smartphone
[00:07:15.480 --> 00:07:17.520]   Dada results that are just link
[00:07:17.520 --> 00:07:20.640]   They're just amalgamations of links and then there's
[00:07:20.640 --> 00:07:23.400]   authoritative reviews and I think
[00:07:23.400 --> 00:07:26.120]   the opinions may be different there, but
[00:07:26.120 --> 00:07:31.960]   Deciding who's done the work I guess is probably a little bit easier. I don't know
[00:07:32.600 --> 00:07:37.240]   It's funny because when people talk about fake news. This is related in a way to fake news, right?
[00:07:37.240 --> 00:07:41.880]   Yeah, when people talk about fake news. It's in the eye of the holder to you and I we all we could all agree
[00:07:41.880 --> 00:07:43.960]   What's a fake story?
[00:07:43.960 --> 00:07:49.120]   But I would say that part of the problem with fake news is a lot of people would embrace that story and
[00:07:49.120 --> 00:07:51.960]   I it doesn't make it true
[00:07:51.960 --> 00:07:58.640]   Yeah, and then there but yeah, right there's there's not there's stuff. That's not factually true
[00:07:58.760 --> 00:08:02.360]   That that would qualify easily as fake news. That's like peanut butter and jelly sandwich
[00:08:02.360 --> 00:08:08.240]   Then there's stuff that can't be measured and then there's stuff that's true in spirit if not true in fact
[00:08:08.240 --> 00:08:11.800]   And that's the big one. That's the problematic one, right?
[00:08:11.800 --> 00:08:18.960]   Yeah, there's there's there's the schema as they say you may have you know the Breitbart article might have
[00:08:18.960 --> 00:08:22.680]   Facts right, but how it chooses to interpret that or what it what it does
[00:08:22.680 --> 00:08:27.280]   You know the recent example was there was a but you can't call it fake news even as the facts right can you?
[00:08:27.280 --> 00:08:29.280]   um
[00:08:29.280 --> 00:08:35.960]   Give me an example of a fake news story. That's factually true. Well, so there was a recent case
[00:08:35.960 --> 00:08:39.320]   that
[00:08:39.320 --> 00:08:47.520]   Of the ledge rape of a I think a high school student by the son of an illegal of an undocumented immigrant right and
[00:08:47.520 --> 00:08:51.120]   It got no play on
[00:08:51.120 --> 00:08:56.680]   CNN MSNBC ABC CBS NBC, but it was non stop on Fox
[00:08:56.680 --> 00:09:03.560]   It's the argument there that that's the the schema. That's the worldview you choose right and you say it's not factually
[00:09:03.560 --> 00:09:10.840]   I'm true taking the world. What's factually? What's untrue or maybe a misrepresentation is the conclusion you draw from it
[00:09:10.840 --> 00:09:15.440]   Right right in the prioritization you give it and so it's an interpretation of the world
[00:09:15.440 --> 00:09:22.360]   Which is the world is open for interpretation right and it doesn't every every this I mean there's editorial judgment in every news source. Yes
[00:09:22.360 --> 00:09:24.160]   absolutely
[00:09:24.160 --> 00:09:27.520]   And a worldview and ultimately it's defined by a worldview right?
[00:09:27.520 --> 00:09:30.280]   Yes, yes
[00:09:30.280 --> 00:09:36.320]   Belt on show so what I think some people would say is this whole thing about fake news is my world for view versus your worldview
[00:09:36.320 --> 00:09:41.440]   Well, that's fine as long as you're it's fake if it doesn't match my worldview
[00:09:41.440 --> 00:09:49.080]   Well, no, that's that's Donald Trump's interpretation of fake news. I'm serious. That is but it's also some lefties
[00:09:49.080 --> 00:09:51.680]   interpretation, isn't it?
[00:09:51.680 --> 00:09:58.000]   I don't hear a lot of lefties as you call them shouting fake as you're a lefty
[00:09:58.000 --> 00:10:01.040]   You're seeing it through the prism of a lefty. Yes
[00:10:01.040 --> 00:10:04.000]   My that would be what I would submit right?
[00:10:04.000 --> 00:10:12.080]   It doesn't I'm not because we're looking through a certain filter. It looks true to us
[00:10:12.080 --> 00:10:14.840]   I
[00:10:14.840 --> 00:10:20.480]   Wouldn't look at Fox's story that they chose to run and call that fake news if it indeed
[00:10:20.480 --> 00:10:24.040]   I mean if it happened is it happened and you know
[00:10:24.040 --> 00:10:28.560]   The only reason I'm raising this is I do think this is difficulty rampage
[00:10:28.560 --> 00:10:35.440]   Go ahead go ahead. No your turn. I'm sorry. It's the the the the the lag driving a crazy boy
[00:10:35.440 --> 00:10:41.520]   If but if they say there is a rampage of immigrants on a
[00:10:41.520 --> 00:10:49.280]   Crime wave, I'll give you an example rapes across America. I'll give you an example and that's fake the word wilding
[00:10:49.600 --> 00:10:51.600]   Yeah
[00:10:51.600 --> 00:10:54.320]   Yeah
[00:10:54.320 --> 00:10:59.080]   Which is so this is remember that that they're in central Park
[00:10:59.080 --> 00:11:01.920]   the right the story of
[00:11:01.920 --> 00:11:08.440]   Supposedly young black men who attacked a jogger the men went to jail
[00:11:08.440 --> 00:11:12.400]   But that story was
[00:11:12.400 --> 00:11:17.520]   Became a story of young black men wilding
[00:11:18.000 --> 00:11:22.800]   you know, this is a trend furthermore the men were eventually acquitted and and
[00:11:22.800 --> 00:11:26.640]   Donald Trump and I would presume his political
[00:11:26.640 --> 00:11:30.680]   allies said continued to say that they were guilty and
[00:11:30.680 --> 00:11:36.440]   We're wilding so there's an example of there are there's some fact in there
[00:11:36.440 --> 00:11:40.320]   And there's also some interpretation in there and there's some actual lies in there
[00:11:40.320 --> 00:11:45.600]   And how do you know how to what how would you call what would you do with that story?
[00:11:47.440 --> 00:11:54.280]   Well, if you've reported on them being a quit. I mean they were acquitted you just say that Donald Trump is wrong
[00:11:54.280 --> 00:11:59.160]   Yeah, okay. Yeah, I mean if you've been acquitted you're no longer guilty. That's
[00:11:59.160 --> 00:12:07.000]   You never were here's the last night. Here's the headline from the daily news
[00:12:07.000 --> 00:12:14.920]   You know, this was a story 19 when it was it was a long time ago 89 something like that
[00:12:16.840 --> 00:12:24.760]   brutally raping and nearly killing a jogger during a crime spree a three dozen youths wilding randomly attacking anyone they found and it turned out this I
[00:12:24.760 --> 00:12:29.040]   Mean this probably was fake news. It was certainly misinterpreted
[00:12:29.040 --> 00:12:33.560]   And it ended up having you know
[00:12:33.560 --> 00:12:41.520]   Five kids spending their years in jail including Rockers Island because this is this is something innocent
[00:12:42.920 --> 00:12:51.800]   Remember welfare queens. Yeah, the he's threat of welfare queens that really weren't I mean, that's both an interpretation and we're still actually getting
[00:12:51.800 --> 00:12:56.160]   We get a hint of that today with like the debate over health care
[00:12:56.160 --> 00:13:04.560]   I was it Shae Fitz who said, you know, people could have health care or or an iPhone or I cannot remember his
[00:13:04.560 --> 00:13:08.880]   Same the buy an iPhone why shouldn't they pay for their health care?
[00:13:09.280 --> 00:13:16.000]   By the by the way, it was just just to finish this wilding story. It was a 28 year old investment banker who confessed
[00:13:16.000 --> 00:13:20.280]   years later that did it a white guy so
[00:13:20.280 --> 00:13:29.040]   But I bet you anything in most people and certainly in the president's mind. This is still those seven kids those seven black kids
[00:13:29.040 --> 00:13:31.640]   So how do you as Google?
[00:13:31.640 --> 00:13:38.640]   The the only reason we bring this up I bring this up is how do you is Google to try how how do you weigh this stuff?
[00:13:38.640 --> 00:13:44.680]   I know I think it's very difficult to put yourself in that they don't want to they haven't wanted to but now that I
[00:13:44.680 --> 00:13:48.120]   Understand why it's a slippery slope. They have to you know
[00:13:48.120 --> 00:13:50.120]   It's the example that I gave on the show a couple weeks ago
[00:13:50.120 --> 00:13:55.320]   Search for climate change you get one set of results search for the no longer the case
[00:13:55.320 --> 00:13:59.720]   but search for this for me search for his climate change reel you got different results and
[00:13:59.720 --> 00:14:07.720]   So at some point Google said no no actually we should give the same thing we try right now climate
[00:14:08.720 --> 00:14:09.720]   change
[00:14:09.720 --> 00:14:11.720]   so climate change
[00:14:11.720 --> 00:14:15.080]   There's a really good example because
[00:14:15.080 --> 00:14:21.360]   There is no there's no agreement. I mean there's a lot of scientific consensus
[00:14:21.360 --> 00:14:24.760]   but there's no agreement among people about this and
[00:14:24.760 --> 00:14:31.360]   I mean Google I in Google might say oh yeah, no, it's true. It's real, but there are plenty of people who say it's not
[00:14:31.360 --> 00:14:33.480]   What should Google do with that?
[00:14:33.480 --> 00:14:37.680]   Well, this is the authoritative sources agree. Oh, no
[00:14:38.520 --> 00:14:42.440]   Boy, that's really problematic. So so so so sir. So climate change reel
[00:14:42.440 --> 00:14:46.160]   Okay, so they fixed this problem
[00:14:46.160 --> 00:14:51.440]   Is yeah now now if you search for climate number three is how to talk to a climate skeptic?
[00:14:51.440 --> 00:14:58.080]   Number seven is the 97 percent consensus on global warming some people are gonna really say that this is slanted
[00:14:58.080 --> 00:15:00.560]   well
[00:15:00.560 --> 00:15:03.360]   But but toward what towards science
[00:15:04.080 --> 00:15:12.000]   What's wrong with that? Yeah, I'm like towards something that's provable and in thought wait a minute. Well, I'm not provable
[00:15:12.000 --> 00:15:14.400]   There's scientific census
[00:15:14.400 --> 00:15:19.200]   There's scientific consensus. They can prove that things are changing. I mean there's
[00:15:19.200 --> 00:15:23.000]   in you know the nice thing is if
[00:15:23.000 --> 00:15:30.320]   Scientific consensus goes another way and they're like, oh our bad look what's happening something totally different has changed in the
[00:15:30.320 --> 00:15:32.960]   climate modeling and
[00:15:33.400 --> 00:15:40.640]   Global or climate change isn't happening and we got a bunch of scientists who agreed that that was the case and there was a set consensus
[00:15:40.640 --> 00:15:44.800]   Google would change the results and the rest of us who are like
[00:15:44.800 --> 00:15:47.960]   Climate change is a big deal suddenly. We'd be like, oh
[00:15:47.960 --> 00:15:53.800]   Here's all this proof that it's not okay, and we change our worldview and Google would change it too to reflect that
[00:15:53.800 --> 00:15:55.320]   Well, and maybe okay
[00:15:55.320 --> 00:16:00.640]   So this is so this actually is climate change real is a really interesting search and I should probably do this in an in-cob needle mode
[00:16:01.680 --> 00:16:06.520]   Because I'm because that's another thing. There's this filter bubble your results vary depending on whether you're logged in
[00:16:06.520 --> 00:16:11.000]   To go to that too, but look at so you're right the first three results climate change
[00:16:11.000 --> 00:16:16.320]   How do we know climate change vital signs of the planet how to talk to climate skeptic and then top stories?
[00:16:16.320 --> 00:16:19.880]   two of which are
[00:16:19.880 --> 00:16:25.320]   Climate change believers, but the third of which is a is a guy who says that's it's all wrong. It's crazy
[00:16:25.320 --> 00:16:29.120]   It's weather that's in the top stories. So there aren't banning
[00:16:29.920 --> 00:16:31.920]   Appinions no
[00:16:31.920 --> 00:16:34.800]   I don't know
[00:16:34.800 --> 00:16:40.960]   So I mean this is challenging for Google I think and I think problematic, but it is
[00:16:40.960 --> 00:16:46.200]   So last night I interviewed David Kenny who's the in charge of IBM Watson
[00:16:46.200 --> 00:16:54.480]   Fascinating our with him at on a stage of cutie and he talked a lot about ground truth and
[00:16:55.920 --> 00:17:02.240]   That a fact is a fact. I think there's ranges here right there are facts and then there are interpretations of the facts and then there are lies
[00:17:02.240 --> 00:17:08.000]   In facts he said on climate change climate change has been quite you know
[00:17:08.000 --> 00:17:12.080]   He used to head the weather channel or weather company. It's it's quite the issue for him
[00:17:12.080 --> 00:17:16.840]   He said that the data we do not have is data from the bottom of the ocean
[00:17:16.840 --> 00:17:24.960]   That if we spent a trillion dollars on on sensors at the bottom of the ocean we would know a hell of a lot more and be able to
[00:17:25.160 --> 00:17:30.600]   from that model better once actually happy with climate
[00:17:30.600 --> 00:17:38.400]   We don't have that but we have a scientific consensus based on a hell of a lot of facts and a lot of facts that are verified
[00:17:38.400 --> 00:17:44.480]   So this is the fact there's the interpretation and then there's the stretch and the lie
[00:17:44.480 --> 00:17:49.360]   So in the earliest days of Google
[00:17:50.400 --> 00:17:54.960]   The goal was merely to reflect the internet right or was it right?
[00:17:54.960 --> 00:17:59.680]   Was it yes, and yes, and well we said that media
[00:17:59.680 --> 00:18:06.280]   Google says that Facebook says that we reflect and the argument I've been making lately is that Google's mirror may well indeed be straight and true
[00:18:06.280 --> 00:18:08.280]   But the world is cracked
[00:18:08.280 --> 00:18:14.880]   It's cracked. Yeah, but so that's not Google's job to say oh, let me adjust this view. Yes, it is
[00:18:16.520 --> 00:18:20.800]   No, it's the same with spam if so you have this article over here that has has
[00:18:20.800 --> 00:18:23.960]   10,000 people talking about it. This is climate change is BS
[00:18:23.960 --> 00:18:29.440]   You have a scientific paper over there that's annotated and factual and has two people reading it
[00:18:29.440 --> 00:18:35.000]   If you use the wrong judgment, you will you will give too much weight to the discussion
[00:18:35.000 --> 00:18:40.660]   And the fake controversy being formed over here and even worse because it can be gamed
[00:18:41.480 --> 00:18:45.880]   Like I'd be so I agree with you what Google that's not an indication of truth
[00:18:45.880 --> 00:18:50.360]   What Google should do is do everything it can to prevent gaming?
[00:18:50.360 --> 00:18:55.480]   What Google should not do the creation of fake controversy?
[00:18:55.480 --> 00:19:04.300]   Yeah, gaming is not gaming if a lot of people gravitate towards a really inflammatory headline that may or may not be true
[00:19:04.300 --> 00:19:06.880]   it's
[00:19:06.880 --> 00:19:11.120]   That's just well, I'm sorry, but I think Google should reflect
[00:19:11.800 --> 00:19:15.200]   Google should have a pure algorithm and that when Google
[00:19:15.200 --> 00:19:19.200]   Thing is a pure algorithm. I
[00:19:19.200 --> 00:19:22.320]   Would argue
[00:19:22.320 --> 00:19:27.360]   No, I would argue that page rank is a pure algorithm out no your algorithms are totally
[00:19:27.360 --> 00:19:31.240]   They're told your biases are reflected in how you design your algorithm
[00:19:31.240 --> 00:19:38.120]   So if you design your algorithm to wait what you might be saying is I want the algorithm to value the mass
[00:19:38.840 --> 00:19:45.960]   You know the mass attention which would be the 10,000 people viewing one article versus the two viewing the scientific paper
[00:19:45.960 --> 00:19:49.360]   Well, so let's talk about how page rank worked doesn't work this way anymore
[00:19:49.360 --> 00:19:54.280]   You it would rank highest the highest the the articles that were
[00:19:54.280 --> 00:19:58.600]   linked linked not read linked by
[00:19:58.600 --> 00:20:01.600]   High ranking sites
[00:20:01.600 --> 00:20:08.680]   So it it that was in a nut shell what page rank did that would I would argue the only by
[00:20:08.680 --> 00:20:17.080]   As there is well the the search results should return the result that is linked to by the most high rank in sites
[00:20:17.080 --> 00:20:21.960]   Which to me yes, no, you could say it's a bias, but
[00:20:21.960 --> 00:20:26.680]   That's that's as pure a such thing as you could do I would say
[00:20:26.680 --> 00:20:28.240]   But what is it?
[00:20:28.240 --> 00:20:31.840]   Gaming which you have to kind of maybe do something about spam and gaming
[00:20:31.840 --> 00:20:38.560]   But what's wrong with that you also have fake controversy you have you have you have you have controversies that are ginned up
[00:20:38.960 --> 00:20:46.000]   But don't you understand the risk the huge risk that's involved if you do anything else because now you're gonna say okay
[00:20:46.000 --> 00:20:52.200]   Well, it's not giving us the results. We approve of in whatever context we're living that risk right now
[00:20:52.200 --> 00:20:54.200]   We're living the opposite risk right now
[00:20:54.200 --> 00:21:00.720]   This was my problem with fake news all along was that it's it says it doesn't agree with what I agree with
[00:21:00.720 --> 00:21:02.720]   But that's could be used by anybody
[00:21:02.720 --> 00:21:06.720]   I don't want to search engine that's gonna have bias built in whether it's bias for things
[00:21:06.720 --> 00:21:09.720]   I believe in or bias against things the world has bias built in and
[00:21:09.720 --> 00:21:16.000]   Choice search engine reflects what's out on the internet if a lot of people are writing about one thing
[00:21:16.000 --> 00:21:18.720]   It should reflect that whether you agree with it or not
[00:21:18.720 --> 00:21:25.680]   No, because they're well Leo, but they're not really people that's made up stuff. It's it's it's it's it's it's it's PR
[00:21:25.680 --> 00:21:32.160]   It's Bernays right the world has been warped media warped the world. Well, we don't know if we're gonna
[00:21:32.160 --> 00:21:38.840]   I don't think Google could fix that it has to make some attempt and that's why I think the Gomes letter is so so important
[00:21:38.840 --> 00:21:42.400]   Is it's them saying we're gonna make an attempt and Facebook is saying the same thing?
[00:21:42.400 --> 00:21:46.680]   They have to worry about quality comparing contrast with Twitter, which doesn't do Jack
[00:21:46.680 --> 00:21:52.360]   Because they argue oh no no we go as free we go anybody on and we see the result there
[00:21:52.360 --> 00:21:57.920]   So I think that yeah, you're right. This is this is this is a this is a rocky path fraught with peril
[00:21:57.920 --> 00:22:05.920]   It's fraught, but but the but not doing anything we have just learned is more fraught and and I not know in 20 years
[00:22:05.920 --> 00:22:09.280]   When we're sitting here saying god
[00:22:09.280 --> 00:22:14.760]   We should never have let silicon valley determine how what our values and future was because look what we got
[00:22:14.760 --> 00:22:18.520]   Are we gonna come back and say you know boy? I guess that was a bad idea
[00:22:18.520 --> 00:22:25.760]   So what's about say about about about New York media? We should we should never have let
[00:22:26.440 --> 00:22:32.000]   Hollywood in New York determine our values and so they're looking at just that so so that's a good point
[00:22:32.000 --> 00:22:35.160]   Hollywood has for several generations now
[00:22:35.160 --> 00:22:38.520]   Projected a worldview out there, right?
[00:22:38.520 --> 00:22:42.760]   Yeah, it's not uniform. It's not uniform. There's also Mel Gibson movies
[00:22:42.760 --> 00:22:48.960]   But but take those out and there's a relatively uniform worldview for coming from Hollywood
[00:22:48.960 --> 00:22:52.980]   What would you do? What would you do then in response to that would you say? Oh?
[00:22:53.160 --> 00:22:58.480]   We got a decide we got a sensor. Let's see. What about the Catholic anti defamation leave?
[00:22:58.480 --> 00:23:05.340]   Why don't we say let's come up with a rating system and say you know Catholic could see that movie because that's a worldview. We start here
[00:23:05.340 --> 00:23:09.580]   Start here in the case of climate change
[00:23:09.580 --> 00:23:13.160]   Google is now
[00:23:13.160 --> 00:23:16.400]   favoring the institution of science
[00:23:17.040 --> 00:23:22.600]   Is there anything wrong in a company that wants to bring us to knowledge with favoring?
[00:23:22.600 --> 00:23:25.800]   the academe and science and
[00:23:25.800 --> 00:23:33.680]   Expertise and authority, okay, but I think it would be those are the institutions that the others want to tear down
[00:23:33.680 --> 00:23:36.800]   It was why it's controversial right now. It would be it would be on its face
[00:23:36.800 --> 00:23:43.520]   The favor science science it would be a mistake to fetishize science though
[00:23:43.520 --> 00:23:46.400]   because what you call science is
[00:23:47.160 --> 00:23:53.600]   Just today's scientific worldview and no in no scientific innovation ever ever thus
[00:23:53.600 --> 00:24:00.360]   It always flies in the face of the current scientific worldview. That's called scientific method
[00:24:00.360 --> 00:24:06.920]   Well, so yeah the scientific method is always allowing for you to question that and then prove that it's wrong
[00:24:06.920 --> 00:24:10.360]   And that's that's very different than saying I don't like it. It's wrong
[00:24:10.360 --> 00:24:14.360]   Science says I don't like this. I think it works a different way
[00:24:14.360 --> 00:24:21.280]   Let me show you why I think that and let me prove it to you and that's that's a very different value in
[00:24:21.280 --> 00:24:25.200]   In terms of quality. It's it's much preferred
[00:24:25.200 --> 00:24:31.600]   So otherwise you're just living inside someone's head. Okay, so when it was accepted
[00:24:31.600 --> 00:24:34.440]   scientific fact that the
[00:24:34.440 --> 00:24:37.560]   Sun revolved around the earth if you were
[00:24:37.560 --> 00:24:40.320]   Google in in the 16th century
[00:24:41.200 --> 00:24:47.760]   Would you eliminate search results that said it was otherwise that Copernicus guy got a down rank him?
[00:24:47.760 --> 00:24:53.840]   They probably would have downranked Copernicus for a while until they had but they really
[00:24:53.840 --> 00:24:56.320]   They would have gotten their event
[00:24:56.320 --> 00:25:00.800]   I mean in probably faster than unless you got burned at the stake in which case well, we'd be out of luck
[00:25:00.800 --> 00:25:08.640]   We still got there and we'd probably get there faster with more people having that kind of input a larger crowdsource system
[00:25:09.080 --> 00:25:12.280]   And gets gets you to the right answer faster
[00:25:12.280 --> 00:25:15.880]   Get you to me by by your logic
[00:25:15.880 --> 00:25:21.160]   By your logic then schools then then you're in favor of teaching creationism because hey
[00:25:21.160 --> 00:25:25.920]   There are some people out there who believe in creationism and who are we to say what's right and wrong?
[00:25:25.920 --> 00:25:29.920]   Well, I would be a mistake for school not to ignore creationism. I
[00:25:29.920 --> 00:25:38.240]   Wouldn't teach it as scientific same as Google Google does not kill off links to Holocaust deniers
[00:25:38.240 --> 00:25:42.720]   If you search for Holocaust deniers you can find them because you might want them for research and find out what they're saying
[00:25:42.720 --> 00:25:48.560]   That's what googled up. Okay, but if you ask is the Holocaust real if you ask is climate change real it favors
[00:25:48.560 --> 00:25:51.800]   Here's my here's my fear. It's Google's going to start
[00:25:51.800 --> 00:25:57.360]   So so part of the problem is that the web
[00:25:57.360 --> 00:26:05.800]   Is not it does not exist in a vacuum that the what we really see is the web is the result of Google searches, right?
[00:26:05.800 --> 00:26:08.040]   You can't you you only see what Google surfaces
[00:26:08.040 --> 00:26:14.960]   So I've that's the huge and in my opinion dangerous power the Google wheels and
[00:26:14.960 --> 00:26:17.800]   The good news is there are other search engines
[00:26:17.800 --> 00:26:22.200]   So it's foolish to treat them as a monopoly and that may that may be enough to fix this
[00:26:22.200 --> 00:26:26.400]   But I'd be very worried if Google used some worldview
[00:26:26.400 --> 00:26:34.120]   I don't you know, maybe I agree with it or disagree with it, but use some worldview to rank the web to shape the web
[00:26:35.400 --> 00:26:38.440]   There's a heat don't you think there's a risk in that that?
[00:26:38.440 --> 00:26:47.360]   Well conventional wisdom says the Sun revolves around the earth so Leo schools do it universities do a lot of history does it
[00:26:47.360 --> 00:26:51.560]   I mean history history is the you know, this story told by the winners, but
[00:26:51.560 --> 00:26:57.280]   Where I was hoping is that the web would be a better do a better job
[00:26:57.280 --> 00:27:03.200]   Because people make it I mean the web is just a reflection of us and who are values
[00:27:03.200 --> 00:27:06.720]   The web is not if it's a reflection of us is not a fine if it's a reflection of Google or
[00:27:06.720 --> 00:27:10.920]   It's how it's a reflection of how we manipulate it. It's a reflection of how we all explained it
[00:27:10.920 --> 00:27:16.360]   Do you see what I'm saying that it's it's if it would be one thing of a reflection of us guided or misguided?
[00:27:16.360 --> 00:27:21.520]   It's another thing entirely if it's a reflection of Silicon Valley's worldview. That's dangerous
[00:27:21.520 --> 00:27:25.160]   But
[00:27:25.160 --> 00:27:26.160]   It
[00:27:26.160 --> 00:27:30.160]   I know I think you're I think you're you're there's gonna be a word for this, you know
[00:27:30.680 --> 00:27:33.240]   reverse anthem or morphizing or something you
[00:27:33.240 --> 00:27:36.080]   For Google
[00:27:36.080 --> 00:27:40.640]   To decide I mean it's no different from the fight for textbooks in Kansas, right?
[00:27:40.640 --> 00:27:45.840]   Google decides to favor science or Texas exactly look better yet. Yes, right
[00:27:45.840 --> 00:27:48.480]   Science or a teacher
[00:27:48.480 --> 00:27:55.120]   Librarian decides to favor science in Texas. It is no different. That's why I don't want it. It's exactly the same. I
[00:27:55.760 --> 00:28:02.120]   Do want it good Lord. I don't want people walking around saying well if enough people say it then I'm gonna treat this as fact
[00:28:02.120 --> 00:28:07.000]   That is fake news. No, but I'm gonna show my surface if everybody in the world agrees on something
[00:28:07.000 --> 00:28:14.120]   Your search results reflect that if if there's dissent is rich reflect that whether it fits your role
[00:28:14.120 --> 00:28:17.600]   Okay, all right. Hold on. No, hold on two things there two things one
[00:28:17.600 --> 00:28:24.320]   Just because people talk about it doesn't mean that it's a survey if you're trying to say we determine fact by survey
[00:28:24.600 --> 00:28:27.000]   I'm saying there's a huge risk in
[00:28:27.000 --> 00:28:30.380]   censoring or limiting the
[00:28:30.380 --> 00:28:35.760]   visibility of parts of the web because it doesn't fit
[00:28:35.760 --> 00:28:40.040]   Your worldview which everybody in your bubble agrees is true
[00:28:40.040 --> 00:28:43.240]   Okay, science is the web that Google's giving you
[00:28:43.240 --> 00:28:47.040]   True and Google's giving you not true. I beg to differ
[00:28:47.040 --> 00:28:51.480]   Science is true. No, and it is a science changes
[00:28:52.480 --> 00:28:54.560]   Changes so something that's true shouldn't change
[00:28:54.560 --> 00:29:01.440]   It's not true science is not true science is a result of a scientific method which aims towards truth
[00:29:01.440 --> 00:29:09.120]   Science is not true. That's a big mistake as soon as you say better. Well, I'm not saying I believe in the scientific method look
[00:29:09.120 --> 00:29:14.240]   Say Google favors the scientific method
[00:29:14.240 --> 00:29:20.640]   Is it is that what you're saying is we're gonna favor the scientific method? That's not what they're saying
[00:29:21.000 --> 00:29:23.600]   If you look at the results on climate change, they're
[00:29:23.600 --> 00:29:28.940]   That's loaded so that's that's not used quote climate change, but in general
[00:29:28.940 --> 00:29:33.720]   Google is not saying we favor scientific method. They say we favor our worldview
[00:29:33.720 --> 00:29:42.280]   No, they're saying their favor authority and quality and as defined by well, and that's it so so maybe your institution
[00:29:42.280 --> 00:29:48.200]   So you you know time the Texas school is an institution
[00:29:49.320 --> 00:29:51.320]   For enough, okay, you got me
[00:29:51.320 --> 00:29:54.120]   Who chooses the institution
[00:29:54.120 --> 00:30:00.080]   So and it's really important to understand that it's it
[00:30:00.080 --> 00:30:03.640]   I don't want to put that's giving too much power to Google
[00:30:03.640 --> 00:30:06.680]   By the way, it's giving to me
[00:30:06.680 --> 00:30:09.520]   There's this is not in this I've been we've been doing the shows for eight years
[00:30:09.520 --> 00:30:16.000]   And if there's a threat in this show, it's me saying Google has too much power or Google has to be respond has to
[00:30:16.000 --> 00:30:18.520]   responsibly uses power and
[00:30:18.720 --> 00:30:23.440]   It's the problem is I you know look I understand why they're trying to do this and my Facebook's trying to do this
[00:30:23.440 --> 00:30:27.880]   In fact, I think that I would say in both cases. They're doing it out of
[00:30:27.880 --> 00:30:33.880]   Absolutely benign and in fact positive motives. I just don't think we should ignore the risk
[00:30:33.880 --> 00:30:35.880]   They're also doing it to not lose ads
[00:30:35.880 --> 00:30:40.880]   I mean the other story of the rundown is is is is Google expanding the definition of hate speech?
[00:30:40.880 --> 00:30:46.800]   Because they've got a real problem around YouTube when havas and the guardian and Verizon all drop YouTube
[00:30:47.360 --> 00:30:53.020]   Oh, no, this is this is an economic decision to though. There's a line from hate speech to fake news
[00:30:53.020 --> 00:30:57.360]   That makes it even worse right now the institutions influenced by revenue
[00:30:57.360 --> 00:31:00.160]   Well, we knew that was the case to begin with
[00:31:00.160 --> 00:31:04.600]   There's a quality that's why I like age run the advertisers
[00:31:04.600 --> 00:31:10.120]   That was too simplistic, you know, obviously the problem is humans
[00:31:10.120 --> 00:31:14.540]   and they want to yeah the game stuff so but
[00:31:15.680 --> 00:31:22.000]   You know I honored Matt cuts attempts to de-get to to eliminate the effect of gaming on Google
[00:31:22.000 --> 00:31:26.960]   That was what Matt cuts job was and then I have no problem now the whole world does it now
[00:31:26.960 --> 00:31:33.320]   You have entire campaigns that are run on nothing but this now you have eight Chen and four Chen and company
[00:31:33.320 --> 00:31:35.520]   trying to tear down institutions
[00:31:35.520 --> 00:31:39.520]   I know and and and and and and
[00:31:39.520 --> 00:31:42.560]   How many people is it it could be a hundred people?
[00:31:43.320 --> 00:31:46.320]   Right. Yeah, and they're very clever about it. They're very good about it
[00:31:46.320 --> 00:31:51.360]   And and it's just an extension of a PR company in the old days or an ad agency, right?
[00:31:51.360 --> 00:31:55.880]   No, I guess to take it to take it to your full conclusion is
[00:31:55.880 --> 00:32:01.440]   If you if you don't want those hundred people to determine what you see on the web either
[00:32:01.440 --> 00:32:07.500]   Right. Thank you. Yes, and so you've got to find a balance. You've got to adjust for them
[00:32:07.500 --> 00:32:10.600]   You've got to make some and so you're forced to go. Here's what I'm saying
[00:32:11.400 --> 00:32:15.000]   Google didn't want to be this position. They were forced into this position
[00:32:15.000 --> 00:32:18.640]   Yeah, they wanted to deliver knowledge and a quality experience to us
[00:32:18.640 --> 00:32:26.760]   They have to acknowledge my own my point to them has been that they've got to be more transparent about the efforts to manipulate them and thus us and
[00:32:26.760 --> 00:32:33.860]   And that they have to adjust for those efforts to manipulate and we have to be here's the sense that
[00:32:33.860 --> 00:32:36.880]   Worries me and and this is once again from
[00:32:36.880 --> 00:32:41.080]   The Ben Gomes who's the VP of engineering at Google ahead of search at Google?
[00:32:41.720 --> 00:32:46.040]   The bro we combine hundreds of signals. This is this is really it in a nutshell
[00:32:46.040 --> 00:32:54.080]   We combine the whole key is ranking is the key we combine hundreds of signals to determine which results we show for a given query from the
[00:32:54.080 --> 00:32:58.240]   freshness of the content to the number of times your search queries appear on the page
[00:32:58.240 --> 00:33:05.080]   We've adjust then this is the sentence that that I worry about we've adjusted our signals to help service more authoritative
[00:33:06.040 --> 00:33:12.600]   Pages and to demote low quality content so that issues similar to the Holocaust and I'll result
[00:33:12.600 --> 00:33:15.840]   So we saw back in December less likely to appear and I just want to know
[00:33:15.840 --> 00:33:21.440]   This is good, but what is it's already cool. What is authoritative and what is low quality?
[00:33:21.440 --> 00:33:26.960]   Now he says an issue part of this comes from direct feedback tools, right? He says we're gonna give
[00:33:26.960 --> 00:33:31.320]   Users a chance to help us with authority and quality
[00:33:31.920 --> 00:33:37.080]   If that's more that's more on the feature, which is autocomplete, which is really a different thing. Okay
[00:33:37.080 --> 00:33:42.160]   That's not gonna work with that's not gonna change ranking ranking is holy and so ranking
[00:33:42.160 --> 00:33:49.480]   They've got to make universal decisions that they can stick with it's gonna yield so and where is he where's that conversation about?
[00:33:49.480 --> 00:33:53.520]   What is authoritative and what is low quality? Where's that so I'm involved in this decision?
[00:33:53.520 --> 00:33:57.520]   There's gonna be an announcement next week is something I'm involved in that I won't say yet
[00:33:57.520 --> 00:34:00.040]   but
[00:34:00.040 --> 00:34:07.400]   We have to be more transparent about the signals that various parties use to make decisions on their own and for their own reasons
[00:34:07.400 --> 00:34:13.960]   So if you're if you're an ad network if you're an ad agency if you're an advertiser if you're a media company if you're a platform
[00:34:13.960 --> 00:34:16.440]   You and if you're a reader
[00:34:16.440 --> 00:34:18.600]   You need more signals
[00:34:18.600 --> 00:34:27.240]   That you can use to judge things so so for example and give you a simple example right age of sight if this site is only been up for
[00:34:27.240 --> 00:34:31.960]   For two weeks Procter and Gamble. Do you really want to put your diapers on it?
[00:34:31.960 --> 00:34:37.120]   You know, I don't know now the New York Times was two weeks old once two weeks doesn't mean it's bad
[00:34:37.120 --> 00:34:40.560]   But it's a signal that tells you you might want to be cautious
[00:34:40.560 --> 00:34:43.400]   There's a really good example because doesn't that favor incumbents?
[00:34:43.400 --> 00:34:49.760]   It does it less and so what I bought what I'm arguing what I'm gonna argue with next week is that?
[00:34:49.760 --> 00:34:55.280]   Absolutely, and so there needs to be so like how would you think that you know it signals become
[00:34:56.520 --> 00:35:01.200]   If you just well twits brand new and you got a trust
[00:35:01.200 --> 00:35:04.040]   I'm gonna answer your question. I'm gonna answer your question
[00:35:04.040 --> 00:35:10.240]   So so you have sets of signals and you have interpretation of them and they're both bad signals and good signals
[00:35:10.240 --> 00:35:12.280]   Vice and virtue
[00:35:12.280 --> 00:35:18.400]   You need a few things then you also have people signing up to pledges of doing this and that and this and that so you need
[00:35:18.400 --> 00:35:23.200]   I think an agency to to or agencies to worry about three things to audit compliance
[00:35:23.200 --> 00:35:28.920]   I made this pledge do I hold true to it and that pledge is just me saying to those who care?
[00:35:28.920 --> 00:35:32.920]   That I fact check or I do whatever second is
[00:35:32.920 --> 00:35:38.960]   Not game. Yeah, okay, so I screwed up. I screwed up once now. You need human beings
[00:35:38.960 --> 00:35:40.960]   You need human beings there's an appeal process
[00:35:40.960 --> 00:35:47.800]   I've long said I have long said that Google needs a jury of advertising peers to make these decisions because Google is the voice of God
[00:35:47.800 --> 00:35:52.560]   So you need appeal and you need review of a new site. Oh, this thing is only two weeks old
[00:35:52.560 --> 00:35:55.760]   But hell it's Nick Kristoff starting a new media brand. Yeah, let him in
[00:35:55.760 --> 00:36:00.240]   Now the second part is which favors these incumbents
[00:36:00.240 --> 00:36:06.400]   It does to some extent if Edward our mario starts a podcast network. He's gonna be damn fine
[00:36:06.400 --> 00:36:12.480]   There needs to be a door open for new ones. Yeah, well, yeah, and and Leo, but this is where we're stuck
[00:36:12.480 --> 00:36:17.400]   I understand the problem and I understand the difficult. Here's a here's an example with snippets
[00:36:17.400 --> 00:36:25.000]   So who or search completion who painted the Mona Lisa and then which predictions were inappropriate and then but see notice the
[00:36:25.000 --> 00:36:30.200]   Categories that they give you for and I wish I could pause this gift the predictions
[00:36:30.200 --> 00:36:33.880]   And this is why I don't like them are hateful sexually explicit violet or other
[00:36:33.880 --> 00:36:39.240]   The three cat hatefully hateful sexually explicit violent
[00:36:39.240 --> 00:36:47.120]   That that's an interesting choice those three because that reflects a current cultural point of view
[00:36:47.600 --> 00:36:52.720]   but exactly true in France nudity is not nearly as
[00:36:52.720 --> 00:36:54.680]   problematic
[00:36:54.680 --> 00:37:02.120]   But they hate violence, but they hate violence that's still there we currently will rate a movie are for sex
[00:37:02.120 --> 00:37:04.960]   But not for violence
[00:37:04.960 --> 00:37:07.840]   so these kinds of systems are
[00:37:07.840 --> 00:37:12.200]   I think culturally problematic they perpetuate the
[00:37:13.760 --> 00:37:17.480]   establishment the the the culture in charge and
[00:37:17.480 --> 00:37:27.400]   I think the risk here is the culture in charges the silicon valley culture, which is I think one could argue a very bizarre and non
[00:37:27.400 --> 00:37:30.480]   standard culture
[00:37:30.480 --> 00:37:34.720]   What's said about Hollywood? That's what said about New York. Just like Holly was in the government. Yeah
[00:37:34.720 --> 00:37:38.680]   Yeah, and I would say and I would say and I'd be and it's only a deal
[00:37:38.680 --> 00:37:47.480]   It's a big it's a deal because Hollywood movies are one thing the the the the company that essentially controls visibility on the internet
[00:37:47.480 --> 00:37:49.920]   And the tired and it's a whole nother thing
[00:37:49.920 --> 00:37:54.040]   They have them even a higher responsibility much higher responsibility than Hollywood does
[00:37:54.040 --> 00:38:01.080]   You know people used to make that argument about Hollywood though that they are the influencer and arbiter of culture not just here
[00:38:01.080 --> 00:38:03.080]   But abroad and I mean
[00:38:03.080 --> 00:38:06.960]   relevant is problematic was much more problematic now
[00:38:07.880 --> 00:38:12.600]   With Google it's much more problematic because it's not just Hollywood. It's not just the movie you went to see
[00:38:12.600 --> 00:38:18.240]   It's your everything you do when I mean the web is now the internet is everything
[00:38:18.240 --> 00:38:23.440]   It's where you get your information period, but you don't have to get it through Google and
[00:38:23.440 --> 00:38:28.320]   Okay, so that's so I did mention that there are other there are other search engines
[00:38:28.320 --> 00:38:31.680]   And they're yeah
[00:38:31.680 --> 00:38:34.480]   Oh, no about
[00:38:34.480 --> 00:38:36.240]   Going away
[00:38:36.240 --> 00:38:38.240]   Didn't know it was still around
[00:38:38.240 --> 00:38:41.800]   But it was full of gaming right it's all I consulted there for a year
[00:38:41.800 --> 00:38:48.560]   And the Times bought it. I don't I don't I don't I just worry that Google has so much power
[00:38:48.560 --> 00:38:56.800]   But you but but and Jeff I do trust people like you to kind of speak truth to them and and so I just I think it's important that we make
[00:38:56.800 --> 00:39:03.240]   Sure that there's room for points of view scientific theories ideas that don't fit
[00:39:03.960 --> 00:39:10.120]   The dominant culture that's that's where humanity I agree. They're also testing different perspectives
[00:39:10.120 --> 00:39:15.200]   They're they're testing other things as well, and I think they're they're very conscious of this
[00:39:15.200 --> 00:39:18.880]   But but but the Leo all the points you raise are of course good points
[00:39:18.880 --> 00:39:25.680]   And you're doing it for the sake of showing all the yeah, cuz I'm a liberal and I want I don't I I firmly believe in climate change
[00:39:25.680 --> 00:39:30.360]   I but for the sake of argument and and the problem is
[00:39:32.200 --> 00:39:35.560]   If we're if you're not the dominant culture, it sure doesn't feel good
[00:39:35.560 --> 00:39:42.920]   You know when the dominant culture uses these very powerful tools to suppress your points of view
[00:39:42.920 --> 00:39:46.440]   Unless those points of view are
[00:39:46.440 --> 00:39:50.280]   wrong guys, we're no no no no no no
[00:39:50.280 --> 00:39:53.720]   We're we're not gonna solve this now, but we've been talking about it for a while
[00:39:53.720 --> 00:39:56.720]   And we keep I feel like we've gone around and around a couple times
[00:39:56.720 --> 00:40:02.200]   You're right we have not but I am gonna give you a chance to talk about the new Amazon echo
[00:40:02.200 --> 00:40:06.000]   This was not just for my own selfish reasons
[00:40:06.000 --> 00:40:12.320]   I want to get you a devil's advocate hat you can put it on when you're like if you know the worst thing
[00:40:12.320 --> 00:40:17.920]   But but I think Google needs to be devil's out here the reason the the worst thing is for is for a
[00:40:17.920 --> 00:40:25.400]   bunch of people who have this who have come from white privilege or whatever point of view it is all sitting around agreeing
[00:40:26.400 --> 00:40:33.280]   I agree and so it's important. I played it's not merely the devil's advocate. I think it's really I'm sincere in my
[00:40:33.280 --> 00:40:38.640]   Concerned that the dominant culture not dominate the internet
[00:40:38.640 --> 00:40:48.880]   We can get a revisit of clippy would you like an alternative opinion on this? Yeah, there's gotta be a there's gotta be a way to do you fool you
[00:40:48.880 --> 00:40:51.720]   yeah, meanwhile
[00:40:51.720 --> 00:40:56.320]   In more important news now. There's an Amazon echo that will look at your style choices. I
[00:40:56.320 --> 00:41:03.560]   Thought this was an April Fool's joke when I saw it. I was like no that was my exact tweet not an April Fool's joke
[00:41:03.560 --> 00:41:11.120]   But it's actually telling I don't think Amazon look they've made mistakes the Amazon Fire Phone is
[00:41:11.120 --> 00:41:19.240]   Obviously one but I think Amazon is Jeff Bezos is careful about strategic moves this there's a super smart
[00:41:19.240 --> 00:41:23.880]   I love like there's a reason for this. Yes. So what is it? Tell us what this thing does?
[00:41:23.880 --> 00:41:31.440]   Okay, so for $200 and right now it's invite only it's an Amazon echo that has all the features of Madam a
[00:41:31.440 --> 00:41:35.640]   with a camera and the camera in this case
[00:41:35.640 --> 00:41:39.840]   takes a picture or a video of your outfit and it uses
[00:41:39.840 --> 00:41:42.900]   machine learning and recommendation algorithms to
[00:41:42.900 --> 00:41:48.400]   Which ones better see up blurs the background intentionally so that chair doesn't distract
[00:41:49.400 --> 00:41:51.320]   And what is style check?
[00:41:51.320 --> 00:41:58.480]   How does that work style check is looking to say this the computer 64% confident that this is a better choice this
[00:41:58.480 --> 00:42:01.040]   Oh, God
[00:42:01.040 --> 00:42:03.440]   Talk about dominant culture
[00:42:03.440 --> 00:42:09.800]   Fortunately don't flannel for you America fashion is a completely trivial
[00:42:09.800 --> 00:42:14.880]   Thing so I don't mind so much but I have to agree the shoes are much better on the left than the right
[00:42:15.480 --> 00:42:22.360]   So this is great for Amazon because here are a couple things that that I think is smart here
[00:42:22.360 --> 00:42:28.200]   Okay, I don't I called this the closet the closet echo even though I would not want this in my closet
[00:42:28.200 --> 00:42:31.520]   I actually have a camera in my closet. I have a dot. I have a dot in my closet
[00:42:31.520 --> 00:42:36.280]   Yes, but so I can listen to news while I'm changing this would this would take its place effect
[00:42:36.280 --> 00:42:39.320]   I got on the list immediately me too, but it's a camera
[00:42:39.320 --> 00:42:41.320]   So I don't think I would want the camera while I'm changing
[00:42:41.840 --> 00:42:48.360]   To be honest, but so what this does is it gives Amazon a chance to understand what you're wearing
[00:42:48.360 --> 00:42:55.640]   Which will give it the ability to make some amazing recommendations for what you should buy next fashion's a big spot for Amazon
[00:42:55.640 --> 00:43:00.040]   You know clothing is still something that most people don't buy from Amazon
[00:43:00.040 --> 00:43:07.600]   So that's one in two once it has this intelligence think about the kinds of value added services that can add
[00:43:08.040 --> 00:43:12.160]   Such as once it knows what's in my wardrobe. It can suggest alphas for me
[00:43:12.160 --> 00:43:17.000]   It could even look at the weather and say hey, it's gonna be cold cold here
[00:43:17.000 --> 00:43:22.360]   What about this or look at my calendar? You've got? I mean these are the sort of it's not doing this, but
[00:43:22.360 --> 00:43:26.840]   these are the sort like the things you can do when you have
[00:43:26.840 --> 00:43:33.240]   Information about people we're just we're just uncovering this and it's gonna be amazing in
[00:43:34.200 --> 00:43:38.040]   Amazon's getting a leg up with understanding what the heck's in my wardrobe
[00:43:38.040 --> 00:43:47.480]   I'm gonna predict this is this is the we're gonna we're gonna look back a flop. It's gonna be the Museum of dead technology another fire phone
[00:43:47.480 --> 00:43:56.040]   Yeah, it might be yeah, I don't limited to use this is huge to there is no one standard opinion and taste Jeff
[00:43:56.040 --> 00:44:01.720]   Just go to YouTube and look up. What are they call those videos Stacy this the
[00:44:02.240 --> 00:44:04.600]   style, you know the shop
[00:44:04.600 --> 00:44:08.760]   Social
[00:44:08.760 --> 00:44:16.600]   It's not swag bag. It's um, it's the shopping videos. Oh, Hall Hall video. Oh, that's it
[00:44:16.600 --> 00:44:19.880]   So you've been on poly board
[00:44:19.880 --> 00:44:26.760]   Poly board is works for social it doesn't work for for for Amazon telling me what to do
[00:44:26.760 --> 00:44:31.760]   Trust me trust me if Amazon's good at this it will be
[00:44:32.600 --> 00:44:39.680]   Amazing and there is so much interest among the non-tech nerati about style and your outfits and
[00:44:39.680 --> 00:44:45.120]   Here's a hall video. I'm gonna show I'll turn off the audio. This is a Zoella
[00:44:45.120 --> 00:44:50.760]   She's she's been shopping Zoella's been shopping and she's gonna actually Jeff
[00:44:50.760 --> 00:44:53.880]   This is your worst nightmare and every every husband's worst nightmare
[00:44:53.880 --> 00:44:58.560]   She is going to now force us to sit in the chair and look at her
[00:44:59.080 --> 00:45:03.760]   Show everything she bought at her shopping hall Jeff
[00:45:03.760 --> 00:45:06.040]   How many views you think on this video where you can see it?
[00:45:06.040 --> 00:45:13.120]   This is social this is in the computer telling you what to wear with one view
[00:45:13.120 --> 00:45:19.400]   I think this is exactly what Amazon wants to do with this
[00:45:19.400 --> 00:45:25.120]   This is trained. It's a machine learning algorithm. They're training it against these videos. They're trained
[00:45:25.120 --> 00:45:27.160]   I actually I don't know what they're training it against well
[00:45:27.160 --> 00:45:31.720]   They're clearly collecting information right in much the same way Google photos is collected
[00:45:31.720 --> 00:45:35.440]   I mean, you know Amazon's not stupid that your machine learning it needs
[00:45:35.440 --> 00:45:38.280]   It eats data. I
[00:45:38.280 --> 00:45:43.760]   Think this is huge. I think they'll sell they'll sell a million of these in the first year
[00:45:43.760 --> 00:45:49.800]   What if you sell a million to do that's 200 million dollars Jeff
[00:45:49.800 --> 00:45:53.600]   Well, but it's not
[00:45:53.600 --> 00:45:56.640]   The only the only thing go ahead again
[00:45:56.640 --> 00:46:01.880]   I send I take pictures and I send of my outfits like before I go on stage or something
[00:46:01.880 --> 00:46:05.960]   Like if I'm picking my wardrobe, I send pictures to my friends there
[00:46:05.960 --> 00:46:11.200]   Where you can no, but there are dozens of apps where you can send it to strangers
[00:46:11.200 --> 00:46:14.120]   I can't think of the apps name right now, but there's if I don't have a friend
[00:46:14.120 --> 00:46:17.560]   I want to bother yes, I can send it to yes still people
[00:46:17.560 --> 00:46:22.760]   Well, there could be people that I mean I wouldn't be surprised at all if they tie this into stylists
[00:46:22.760 --> 00:46:28.160]   In fact, they say style check combines machine learning algorithms with advice all by fashion specialists
[00:46:28.160 --> 00:46:34.160]   The only to me the only threat to this is the price which is 200 bucks. I think if this is also an echo
[00:46:34.160 --> 00:46:39.640]   Yeah, it does everything the echo does well. Does it have speakers? Oh, that's a good question
[00:46:39.640 --> 00:46:41.800]   I think it's more like a dot with a camera
[00:46:41.800 --> 00:46:46.720]   I mean, I it probably needs to be that expensive because it's got a camera is expensive. Yeah
[00:46:46.720 --> 00:46:51.520]   And it's got LED lighting and it's got now algorithms in it to blur
[00:46:52.360 --> 00:46:59.200]   Let's go play my getting ready playlist. Yeah, Jeff. You just got a lot of people really mad
[00:46:59.200 --> 00:47:05.800]   But also imagine saying hey echo Google no say hey echo after your year of using this
[00:47:05.800 --> 00:47:11.480]   What should I wear today and echo said checks the weather checks your calendar and says ah?
[00:47:11.480 --> 00:47:17.160]   I've got just something right for you go to a solution looking for a problem. That's why that's why we have windows
[00:47:18.160 --> 00:47:24.280]   Jeff Jeff I cannot tell you the brain power. I spend thinking about what to wear
[00:47:24.280 --> 00:47:27.400]   I'm not kidding. This is why uniforms are so big in schools
[00:47:27.400 --> 00:47:32.160]   This is why I mean think about think about how many productivity it had hacks involved
[00:47:32.160 --> 00:47:35.160]   Granimals Jeff
[00:47:35.160 --> 00:47:39.600]   Randomly
[00:47:39.600 --> 00:47:43.440]   Ger animals it's that's a gift. Jiffy. I think it's ger animals not girl
[00:47:43.440 --> 00:47:47.640]   149 employees an annual revenue of 11.9 million dollars
[00:47:47.920 --> 00:47:52.320]   For clothes that have a tag that's this bottom where this top
[00:47:52.320 --> 00:47:58.440]   So I am giggling imagining this thing in Mark Zuckerberg's closet. I
[00:47:58.440 --> 00:48:02.000]   Think only has this great hoodies, right?
[00:48:02.000 --> 00:48:05.280]   Great t-shirts. Yeah
[00:48:05.280 --> 00:48:11.080]   All right, well, we'll do I see the you want to see the president of Ger animals
[00:48:11.080 --> 00:48:16.880]   4.75 million dollar Florida home that's now available in Sarasota for
[00:48:17.240 --> 00:48:20.360]   This is the house that Ger animals built no I
[00:48:20.360 --> 00:48:23.600]   Randomals all right is it sure go
[00:48:23.600 --> 00:48:26.800]   It's what I
[00:48:26.800 --> 00:48:33.600]   Think I think Carson. I post by the way. I've you league educated say that it's go
[00:48:33.600 --> 00:48:38.160]   Randomels look at this house. Okay. How's your animals built? How do you pronounce?
[00:48:38.160 --> 00:48:41.080]   Ger animals
[00:48:41.080 --> 00:48:46.000]   Renounced or animal okay Google. How do you pronounce ger animals?
[00:48:46.000 --> 00:48:52.400]   Randomly that's Google for you right there. We'll take a position
[00:48:52.400 --> 00:48:57.600]   Whatever you say Jeff is absolutely neutral. I
[00:48:57.600 --> 00:49:04.080]   Want to buy this house that Ger animals built, but I I'm afraid I haven't figured out a way to get people matching their clothing
[00:49:04.080 --> 00:49:07.680]   Wow
[00:49:07.680 --> 00:49:13.040]   Okay, I don't know. I'm excited about this. I can't wait to try it. I am - I am - not because I
[00:49:13.040 --> 00:49:16.400]   Need fashion help as you can see I'm
[00:49:16.400 --> 00:49:22.320]   Very fashionable, but because I think it's cool. I think it's an interesting idea if I get one
[00:49:22.320 --> 00:49:24.960]   I will pair last season's shoes
[00:49:24.960 --> 00:49:30.640]   With like four seasons ago's clothing and I'll be like what do you think and if it likes it?
[00:49:30.640 --> 00:49:32.600]   I'm gonna be like you're wrong. You're so wrong
[00:49:33.600 --> 00:49:39.600]   As wave was to Gina oh, maybe to you maybe the echo look available
[00:49:39.600 --> 00:49:43.480]   Well only by invitation, but both Stacy and I have applied
[00:49:43.480 --> 00:49:52.000]   Fingers crossed if selected you receive an email with an invitation to purchase what is that how the echo was yes?
[00:49:52.000 --> 00:49:54.000]   Is it Amazon brilliant?
[00:49:54.000 --> 00:50:00.760]   Yes, I am begging for the right to give them $200. I know exactly please you understand in lines
[00:50:02.040 --> 00:50:06.000]   Brilliant let's take a break when we come back. There's more to talk about
[00:50:06.000 --> 00:50:09.280]   I'm sure we can find more controversial and uncontroversial
[00:50:09.280 --> 00:50:15.000]   Topics I like that fake news story and I just I'm sorry that I
[00:50:15.000 --> 00:50:18.520]   I'm such a curmudgeon on that one, but I worry
[00:50:18.520 --> 00:50:25.080]   I worry about the future I worry about the discussion think of the children. That's all I say you want to know something
[00:50:25.080 --> 00:50:27.880]   You know what I learned two other fascinating things from David Kenny
[00:50:28.600 --> 00:50:32.080]   One they had Watson right headlines for the weather channel
[00:50:32.080 --> 00:50:38.400]   Yeah, and guess what it was the absolute worst at clickbait because the reward system right traffic
[00:50:38.400 --> 00:50:43.640]   It we used every trick there wasn't the book you won't believe what's gonna happen when you click on this -
[00:50:43.640 --> 00:50:48.880]   You'll never believe who has an artificial intelligence department staff with scientists
[00:50:48.880 --> 00:50:56.560]   We'll find out the Vatican. Oh wow well you saw the the the Pope spoke it Ted
[00:50:57.600 --> 00:51:05.280]   Yeah, which is wild. He didn't come he didn't dane do go to Vancouver for it, but he spoke via Skype
[00:51:05.280 --> 00:51:10.160]   Did it make him stand on a red dot the Vatican's very hip. Oh
[00:51:10.160 --> 00:51:13.320]   Yeah, mm-hmm
[00:51:13.320 --> 00:51:21.680]   The Google home can turn you into a sous chef I like that or yes, yes stay tuned
[00:51:21.680 --> 00:51:24.840]   Stay tuned
[00:51:25.360 --> 00:51:31.040]   I know I'm excited too. Thank you and I actually drive a drive to help your own girls. Yeah
[00:51:31.040 --> 00:51:34.480]   Why is it so hard to get a Google pixel?
[00:51:34.480 --> 00:51:38.320]   and
[00:51:38.320 --> 00:51:41.720]   Facebook another tragedy
[00:51:41.720 --> 00:51:49.200]   Is it Facebook's fault and Twitter is it the Trump bump
[00:51:51.880 --> 00:51:58.000]   Stay tuned our show today brought to you by a great company making a big difference. I
[00:51:58.000 --> 00:52:01.720]   You know, I'd use box everybody's use box right box calm
[00:52:01.720 --> 00:52:07.480]   But I hadn't used it in a while and when I went back and tried I went wow. This is not your father's box
[00:52:07.480 --> 00:52:15.680]   Doesn't sound quite right, but what it is is the best way to bring people and ideas together
[00:52:15.680 --> 00:52:20.480]   So businesses can work as one centralize your files keep your team on track with box
[00:52:20.680 --> 00:52:23.440]   It provides a single place to edit. Yes edit
[00:52:23.440 --> 00:52:27.760]   The the box plug an ecosystem is amazing
[00:52:27.760 --> 00:52:34.440]   To comment to share to approve files. This is great for a law office that wants to
[00:52:34.440 --> 00:52:40.720]   share documents securely for a doctor that wants to share patient records securely because
[00:52:40.720 --> 00:52:47.400]   Box meets your organization's content governance and compliance standards. It's HIPAA compliant
[00:52:47.400 --> 00:52:50.440]   It's FINRA compliant FIPS and FedRAMP compliant
[00:52:50.880 --> 00:52:57.000]   You can solve data resins. He requirements because they will offer storage all over the world and you could pick the place
[00:52:57.000 --> 00:53:02.280]   You've got complete permissions on the files you share you could set expiration dates
[00:53:02.280 --> 00:53:07.560]   You can secure files you can get this if you can employ using box
[00:53:07.560 --> 00:53:11.920]   You can room and they get and you fire them you can remotely log them out and delete the box data
[00:53:11.920 --> 00:53:13.480]   You'll lose a device
[00:53:13.480 --> 00:53:19.200]   You can log it out delete your data. You have total control. No more email attachments. This is a big one for me
[00:53:19.720 --> 00:53:27.240]   If you can get the people in your company stop opening email attachments, you will save yourself a lot of heartache from things like ransomware
[00:53:27.240 --> 00:53:30.200]   Instead securely share large files
[00:53:30.200 --> 00:53:33.720]   Using a link or a custom URL with box.com
[00:53:33.720 --> 00:53:43.160]   Box always you know you're always gonna have the latest version on hand you can preview a hundred twenty different file types huge number of file types
[00:53:43.720 --> 00:53:50.000]   Of course PDF, but also for instance Photoshop PSD without downloading the file. It just shows you a preview
[00:53:50.000 --> 00:53:55.160]   Real-time notifications if you want when edits are made box will save earlier versions
[00:53:55.160 --> 00:54:00.360]   Look at the integrations box has a great API, but also integrates with everything else
[00:54:00.360 --> 00:54:08.720]   More than 41 million users 59,000 businesses I got the box religion. I started playing with it. I said wow
[00:54:08.720 --> 00:54:10.720]   I've had a box account forever
[00:54:11.360 --> 00:54:16.880]   But man this thing this box is so incredible
[00:54:16.880 --> 00:54:25.960]   Work is one with box.com. I got a free two-week trial so you too can see the new box. This ain't your daddy's box box.com
[00:54:25.960 --> 00:54:30.880]   Work is one is a great motto. It is awesome. I
[00:54:30.880 --> 00:54:35.760]   Have I now have box synchronizing to every
[00:54:35.760 --> 00:54:39.560]   Workstation I have just fantastic
[00:54:40.960 --> 00:54:45.400]   We're talking about Google Facebook news
[00:54:45.400 --> 00:54:49.760]   Amazon fashion and fashion
[00:54:49.760 --> 00:54:55.880]   We don't don't put a sneer in your voice in your tone there. I did not I did
[00:54:55.880 --> 00:54:58.680]   Jesus I did not
[00:54:58.680 --> 00:55:06.000]   Stacy Stacy I worked for 12 years at Conde Nast. Oh, he knows fashion. Yeah, but which part of Conde
[00:55:06.000 --> 00:55:09.320]   Well, I'm not I didn't learn anything you got the geek part of Conde Nast
[00:55:10.080 --> 00:55:14.680]   No, I had to when I when I worked there. I called my boss suits protective coloration
[00:55:14.680 --> 00:55:18.400]   Where they all blew surge
[00:55:18.400 --> 00:55:26.680]   Well now you did you pick you guys pick I don't want to I don't want to dominate here. I picked the last story Jeff
[00:55:26.680 --> 00:55:30.040]   What is it
[00:55:30.040 --> 00:55:39.040]   What last story I pick the Google or the oh, it's Jeff's turn I say I see oh I see thank you
[00:55:39.040 --> 00:55:41.640]   Well, I've been a little bit self-serving. Yeah
[00:55:41.640 --> 00:55:47.400]   Jimmy Wales announced I'm excited. Are you involved with this? I?
[00:55:47.400 --> 00:55:49.800]   I'm an advisor
[00:55:49.800 --> 00:55:51.360]   I'm I
[00:55:51.360 --> 00:55:57.840]   Jumped for joy because Wikipedia Jimmy. Oh, of course created Wikipedia. He's now creating wiki Tribune
[00:55:57.840 --> 00:56:01.280]   What's the point?
[00:56:01.280 --> 00:56:04.640]   So the point is a few things one is
[00:56:05.600 --> 00:56:10.760]   That and it's gonna be a changeable beast. So I'm probably projecting my wishes on it more than reality
[00:56:10.760 --> 00:56:16.480]   What I want most one out of this is that we have this constant flow of news updates breaking news everything else
[00:56:16.480 --> 00:56:20.680]   And I want a place where I can go and say what do we know about blank an updated repository?
[00:56:20.680 --> 00:56:23.480]   Jimmy also wants this to be a
[00:56:23.480 --> 00:56:27.520]   he wants to bring over some of the culture this is gonna be hard from wiki
[00:56:27.520 --> 00:56:29.960]   media of
[00:56:30.320 --> 00:56:36.480]   collaboration number one and also of N.Pob of nuclear point of view of the effect based and and things that have
[00:56:36.480 --> 00:56:43.080]   The show their work and they're transparent and you know what changes are made and why by whom?
[00:56:43.080 --> 00:56:47.040]   See I is gonna have professional journey along side
[00:56:47.040 --> 00:56:52.000]   volunteer contrast this to my point of view on the Google's attempt to you know get
[00:56:52.000 --> 00:56:58.680]   Search-fixed this is exactly the response. I'd love to see first of all. It's one site
[00:56:58.680 --> 00:57:05.880]   It's not dominating than that, but it gives people place they can go. It's community supported. It's a news platform, but
[00:57:05.880 --> 00:57:12.800]   Fact focused fact oriented evidence based journalism is the tagline they're using and
[00:57:12.800 --> 00:57:19.120]   Because it's like Wikipedia. It's people. It's made it people are involved and
[00:57:19.120 --> 00:57:23.120]   and somebody I think it might have been you Jeff said the reason that
[00:57:23.120 --> 00:57:27.000]   Journalists say this is because community and journalists are equals
[00:57:28.360 --> 00:57:32.560]   That kind of might I didn't somebody there, but yes, that's true. They said that yeah
[00:57:32.560 --> 00:57:38.280]   I visited I visited Jimmy when he was not to do a weekend test where he hired journalists and
[00:57:38.280 --> 00:57:42.760]   Volunteers hired people play the roles and covered news for a weekend
[00:57:42.760 --> 00:57:49.520]   He thinks wiki software is not easy enough to use and and there were different functionality
[00:57:49.520 --> 00:57:52.760]   So he's building on top of of existing platforms
[00:57:52.760 --> 00:57:58.420]   But building an easier to use platform to do this and I'm enthused. It's a for-profit company
[00:57:58.420 --> 00:58:02.960]   He's trying to get as much patronage as possible to use as little advertising as possible
[00:58:02.960 --> 00:58:05.680]   That's not closing the door on advertising
[00:58:05.680 --> 00:58:12.800]   I think I think so may be necessary, but but if you don't totally depend upon advertising then the reward structures are not
[00:58:12.800 --> 00:58:17.400]   Clickbait, so are they gonna monetize with subscriptions?
[00:58:17.400 --> 00:58:22.480]   Yes, so it's a patronage. It's all gonna be free in access. It's gonna be like a book media in the US
[00:58:22.480 --> 00:58:26.400]   But I can become a supporter and have it yeah, I want to definitely become a supporter of various levels
[00:58:26.400 --> 00:58:33.160]   I'm a supporter of wicked. He loved me. I give Wikipedia a monthly contribution, but I this is just as good a idea. I think
[00:58:33.160 --> 00:58:36.880]   So
[00:58:36.880 --> 00:58:38.880]   So he's hired
[00:58:38.880 --> 00:58:43.000]   He's hired three out of the ten that they want to hire according to the web page
[00:58:43.000 --> 00:58:49.920]   What do you think Stacy? I mean you're you're a journalist. What do you think? I think it's a good idea as a journalist
[00:58:50.000 --> 00:58:56.680]   Okay, this is just gonna come out wrong. So I'm just a say it. I think in some ways I am a
[00:58:56.680 --> 00:59:04.920]   Common like a general community member isn't necessarily as knowledgeable as I am about some things not everything
[00:59:04.920 --> 00:59:10.380]   But so well, that's why they're journalists - I mean there it's right it doesn't work
[00:59:10.380 --> 00:59:15.400]   Wikipedia is created in time in fact, it's it's interesting because Wikipedia doesn't have a lot of
[00:59:17.360 --> 00:59:22.020]   Experts I think but but I don't know actually I shouldn't say that well
[00:59:22.020 --> 00:59:28.480]   Volunteers whoever says I want to write an article and it somehow manages to it's not
[00:59:28.480 --> 00:59:34.240]   The sole version of truth, but work towards truth it does in a beautiful way
[00:59:34.240 --> 00:59:35.240]   I
[00:59:35.240 --> 00:59:41.840]   Would love them to I want to see this and actually something like net neutrality, which hey, it's back
[00:59:41.840 --> 00:59:45.480]   I think that would be like a real I want to see them cover something
[00:59:46.080 --> 00:59:51.800]   Like that as opposed to like there was a shooting and X number of people were killed which feels
[00:59:51.800 --> 00:59:54.040]   so
[00:59:54.040 --> 00:59:56.920]   He's a great idea. I just want to see latest on Trump and Russia
[00:59:56.920 --> 01:00:02.280]   Yeah, give give me the give me what we know and don't know about Trump and Russia
[01:00:02.280 --> 01:00:06.720]   And don't force me to go through 87 articles to figure out. Where the hell are we?
[01:00:06.720 --> 01:00:10.120]   Because I mean finding
[01:00:10.120 --> 01:00:14.560]   Making meaning out of what's happening in the world is tough
[01:00:14.800 --> 01:00:16.800]   and especially right now and there's
[01:00:16.800 --> 01:00:23.960]   It's so complicated and the more meaning you try to put in a story the more context you put into a story
[01:00:23.960 --> 01:00:28.520]   the more dangerous and I won't say the further from the truth, but
[01:00:28.520 --> 01:00:34.440]   The more risky run of people saying what no, that's not my meaning and it's because people
[01:00:34.440 --> 01:00:37.560]   tell their own stories and make their own stories and I
[01:00:37.560 --> 01:00:41.040]   Don't know we'll see well. I mean so
[01:00:41.840 --> 01:00:44.840]   It's funny because this could trash us with our earlier conversation
[01:00:44.840 --> 01:00:48.080]   This this is but the because it's just one source
[01:00:48.080 --> 01:00:52.280]   You can still go read the New York Times of Washington Post the bright part whatever you want to read
[01:00:52.280 --> 01:00:57.120]   This is one source. I've I think this is a very interesting experiment and maybe it'll be a flop
[01:00:57.120 --> 01:01:04.200]   I mean if you if before Wikipedia if you had said we're gonna make an encyclopedia of all the world's knowledge edited by volunteers
[01:01:04.200 --> 01:01:08.720]   Who have free access from anywhere in the internet would you have said what a that'll work?
[01:01:10.360 --> 01:01:12.360]   I mean remember a conference at
[01:01:12.360 --> 01:01:17.120]   Harvard where Jimmy Wales faced Jalee Brims said it was then a number two editor at the Times
[01:01:17.120 --> 01:01:22.600]   And she said you don't understand how much cost I'm a banked up your own and Jimmy said I don't care
[01:01:22.600 --> 01:01:27.280]   The world doesn't care the market doesn't care who would have thought that volunteers could replace the psychopaedic
[01:01:27.280 --> 01:01:33.320]   Now on the other hand the cautionary tale. Do you remember the wiki toriel in the LA Times? No
[01:01:34.520 --> 01:01:41.680]   So they they they not too wisely decided to do a an editorial and - hey this is a crowd thing
[01:01:41.680 --> 01:01:43.040]   Let's make it into a wiki
[01:01:43.040 --> 01:01:49.600]   So they took an editorial about the Iraq war and then opened it up and it took no time at all for of course
[01:01:49.600 --> 01:01:54.960]   It was of course in war zone and I blogged at the time. This is going back many years now
[01:01:54.960 --> 01:02:01.520]   I blogged at the time and I said no no no no you should have had one from column A one from column B two perspectives
[01:02:01.520 --> 01:02:05.920]   And each one should do its best job to argue this is an editorial so it's not fact-based
[01:02:05.920 --> 01:02:11.720]   It's opinion based and show me the two perspectives argue to their best and Jimmy Wales happened to see that at the time
[01:02:11.720 --> 01:02:16.120]   He said you're right up to come and they should fork it and he tried to get to the LA Times to say no
[01:02:16.120 --> 01:02:19.120]   No guys fork this thing, but it was too late. It was such a disaster
[01:02:19.120 --> 01:02:25.800]   They also didn't I mean look at I think the key to Wikipedia is the talk page and the fact that you can see all edits made
[01:02:25.800 --> 01:02:30.040]   And you can see the debate over the talk the editors the volunteers
[01:02:30.040 --> 01:02:35.400]   Is a small percentage of people who really spend a lot of time on it, but for whatever reason in fact
[01:02:35.400 --> 01:02:41.040]   Really, I mean if you want to know about net neutrality wouldn't isn't the first place you'd go Wikipedia
[01:02:41.040 --> 01:02:47.260]   I don't I think it's you know, it's it does of any effect when that's overwhelming when there's breaking
[01:02:47.260 --> 01:02:51.480]   Yes, when there's breaking news I go to Wikipedia. Do you stay used?
[01:02:51.480 --> 01:02:53.840]   What a feature for research. I bet you do I
[01:02:53.840 --> 01:02:57.120]   like especially the technical topics like
[01:02:58.000 --> 01:03:04.320]   semiconductor design discussions and like if I encounter some weird spectrum thing I'm like, oh, what's this? I'll go there
[01:03:04.320 --> 01:03:06.960]   It's better there. I don't I
[01:03:06.960 --> 01:03:14.680]   Don't go for things like net neutrality even though they can do a really good job of covering like the historical I
[01:03:14.680 --> 01:03:20.280]   Think this actually is really good this net neutrality the conversation
[01:03:20.280 --> 01:03:25.520]   And the other thing I like is there you can see all the references of you know article after so if
[01:03:25.640 --> 01:03:30.560]   This is a starting point it really bugs me when I see school say you and you may not use Wikipedia
[01:03:30.560 --> 01:03:33.640]   Because it's better than the encyclopedia Britannica
[01:03:33.640 --> 01:03:38.240]   So my daughter school says she can use Wikipedia and they even say it is a source
[01:03:38.240 --> 01:03:41.520]   But they actually talk about where to go to see
[01:03:41.520 --> 01:03:44.600]   controversial things and how to recognize
[01:03:44.600 --> 01:03:47.120]   gained pages course you need that too
[01:03:47.120 --> 01:03:54.000]   Although Wikipedia is surprisingly not game given how open it is it's always amazing me
[01:03:54.560 --> 01:03:59.320]   People I mean it's gained for a few moments and then it's ungame. It's not game a long term usually
[01:03:59.320 --> 01:04:02.320]   Like if I go to Hillary Clinton, I wonder
[01:04:02.320 --> 01:04:09.280]   There's gonna be a lot of factual stuff and of course at some point somebody will put something bad in but that there are people watch over it
[01:04:09.280 --> 01:04:12.880]   I think this these are these are really kind of amazing
[01:04:12.880 --> 01:04:18.600]   I'll tell you it's not a day goes by that I don't refer to Wikipedia and so yeah, yeah
[01:04:18.600 --> 01:04:21.520]   If you go back to our Google discussion
[01:04:22.520 --> 01:04:26.400]   One of the arguments that I've made is that is that you need to look at the things where there's fake
[01:04:26.400 --> 01:04:32.200]   Controversy created there's there's there's a right so it's not how many coats of shellac do you put on wood?
[01:04:32.200 --> 01:04:36.000]   It's is climate change real and and to me the the
[01:04:36.000 --> 01:04:42.520]   Data to use for that the easiest day is to look at those pages on Wikipedia which have to be shut down
[01:04:42.520 --> 01:04:49.920]   Yeah, you know, I would guess the climate change pages locked down or vaccines. Oh boy. Oh
[01:04:50.880 --> 01:04:52.160]   yeah
[01:04:52.160 --> 01:04:58.000]   but see they have they have a vaccine page, but then they also have a page called vaccine controversy and
[01:04:58.000 --> 01:05:02.840]   That's where the college the controversy is fine. Yeah, that's where the debate goes
[01:05:02.840 --> 01:05:04.280]   and
[01:05:04.280 --> 01:05:10.400]   Then if you go to adverse effects, which is where you would expect anti vaccine advocates to get involved this looks I
[01:05:10.400 --> 01:05:13.400]   mean like
[01:05:13.400 --> 01:05:16.040]   Pretty accurate. It looks like the CDC stuff. Yeah
[01:05:17.840 --> 01:05:24.640]   So and yet if you go to vaccine controversy you will then see all the stuff and that's exactly how it should be handled
[01:05:24.640 --> 01:05:26.120]   Don't you think?
[01:05:26.120 --> 01:05:33.640]   This is I mean, I'm anyway, I'm I only say this to say Jimmy seems to understand and Jimmy and his team
[01:05:33.640 --> 01:05:37.200]   I'm sure Jimmy doesn't that involve I don't know how involved he is in Wikipedia these days
[01:05:37.200 --> 01:05:42.360]   Oh Jimmy's gonna be very involved. He's gonna be the I think he's gonna be the editor good good cuz he think he gets it
[01:05:42.360 --> 01:05:45.240]   and this could I
[01:05:45.560 --> 01:05:47.920]   I expect to check wiki Tribune for news
[01:05:47.920 --> 01:05:54.280]   Maybe my first stop in the same way that Wikipedia is my first up for factual information
[01:05:54.280 --> 01:05:58.480]   But I very much agree with my esteemed fellow panelists
[01:05:58.480 --> 01:06:04.600]   That covering a fire or shooting or that kind of stuff is not what we will have plenty of that
[01:06:04.600 --> 01:06:07.120]   There's breaking news everywhere taking these
[01:06:07.120 --> 01:06:10.320]   Ongoing complex stories, but I wish it would start with a test
[01:06:10.320 --> 01:06:11.800]   I told him this he's not gonna do this
[01:06:11.800 --> 01:06:16.680]   I would just like to start with a test of this that's just the latest on Trump what we know about Trump
[01:06:16.680 --> 01:06:19.200]   What his policies are what he said
[01:06:19.200 --> 01:06:27.360]   connections to Russia and so on that would be a test of this thing if you can pull that off without the world tearing you apart
[01:06:27.360 --> 01:06:33.000]   If you can be a useful resource that people can look up and see what's going on you've passed an acid test
[01:06:33.000 --> 01:06:34.240]   Yeah
[01:06:34.240 --> 01:06:39.680]   So the idea is you'll have reporters and then you'll have the community by the way look at the bottom of the page
[01:06:39.680 --> 01:06:45.440]   There's a picture of somebody we know guys advisors include guy a Kawasaki Jeff Jarvis and Lily Cole
[01:06:45.440 --> 01:06:49.880]   Who's Lily Cole? I don't know who Lily Cole is. I don't know. Yeah, they have without a committee meeting
[01:06:49.880 --> 01:06:52.560]   I
[01:06:52.560 --> 01:06:57.160]   Think this is good for Jimmy. I mean this is this is a very Jimmy way to address
[01:06:57.160 --> 01:07:00.160]   this fake news controversy
[01:07:00.160 --> 01:07:09.160]   The interesting is an English model actress and entrepreneur great watch Jimmy Jimmy Jimmy's a strange fellow in some respects
[01:07:09.160 --> 01:07:16.860]   Okay, you know, I don't know what the story is there, but I
[01:07:16.860 --> 01:07:21.840]   I became a supporter the question is will she have the Amazon look in her closet?
[01:07:21.840 --> 01:07:24.520]   She's a model she oughta
[01:07:24.520 --> 01:07:30.880]   No, they go there on environmental. Okay. Here's why environmental campaigning and business activities, right?
[01:07:30.880 --> 01:07:37.600]   Right and you know what you just advise her we can once or already is great already in her wiki
[01:07:38.600 --> 01:07:44.840]   Profile is that she's a loser wiki tribute. That's the other thing that's amazing about wiki PDA. I love how fast Wikipedia is
[01:07:44.840 --> 01:07:47.520]   I see somebody may have died and like Wikipedia tell me
[01:07:47.520 --> 01:07:53.640]   And who would have guessed that I know who would have guessed that was the use to the actor which would you put?
[01:07:53.640 --> 01:08:00.200]   Well, but who would have guessed it would work and we continue to work after all these years and not turn into 4channer Reddit or something
[01:08:01.720 --> 01:08:08.880]   So so this is very so so she started a an ultra room based altruism based social network called impossible.com
[01:08:08.880 --> 01:08:13.640]   Which invites people to give their services. I know it's awesome to help others. Yeah. Yeah, so that's great
[01:08:13.640 --> 01:08:18.960]   So she's neat so so the note the notion of altruism and helping out in volunteering is core to this smart smart
[01:08:18.960 --> 01:08:21.440]   Smart get as I would expect
[01:08:21.440 --> 01:08:26.680]   But they are hiring actual journalists and the ideas they just take the new stories of the day and report them
[01:08:26.800 --> 01:08:32.720]   Okay, and then I don't think that's what it is at least all the stories of the day. I don't think they're gonna be comprehensive
[01:08:32.720 --> 01:08:39.280]   But but then there are obviously push here and and then copy and copy edit it by the way
[01:08:39.280 --> 01:08:45.400]   Because there's a rule. There's a role for grammar grammar whizzes grammar whizzes. I love that
[01:08:45.400 --> 01:08:47.720]   I can't wait to see the Oxford and serial comment debates
[01:08:47.720 --> 01:08:50.720]   And you know your gay man
[01:08:50.720 --> 01:08:56.120]   Oxford forever and you know you're gonna find plenty of unemployed copy frustrated copy editors out there
[01:08:56.120 --> 01:09:01.320]   They'll volunteer like yeah, oh I hear from them all the time in a way. It's rolling
[01:09:01.320 --> 01:09:08.760]   It's rolling the comments into the story in a way, right? That's right now. Yeah some authority writes the story and then
[01:09:08.760 --> 01:09:13.880]   You know the comments supplement it, but if you could in a responsible
[01:09:13.880 --> 01:09:18.720]   Well done way add that content back in that might be very interesting
[01:09:20.200 --> 01:09:26.640]   All right, well we anyway that watch for it wiki Tribune comm he says if he doesn't get enough support
[01:09:26.640 --> 01:09:30.000]   He doesn't get ten journalists. He's a third of the way there
[01:09:30.000 --> 01:09:35.080]   He he'll refund everybody's money 28 days to go. So it's kind of crowd sourced
[01:09:35.080 --> 01:09:38.600]   6306 supporters. He doesn't say how much he's raised at this point
[01:09:38.600 --> 01:09:41.400]   Just that he's got three out of ten journalists hired
[01:09:41.400 --> 01:09:46.200]   Yeah, for the way some of the so it got what swamp at first and the contribution thing didn't work at first
[01:09:46.200 --> 01:09:53.000]   So if you did try to contribute go and you couldn't go back and let's all make a pledge to contribute after it starts with content
[01:09:53.000 --> 01:09:55.320]   like help out
[01:09:55.320 --> 01:09:58.000]   Because these things are better if we all help out
[01:09:58.000 --> 01:10:01.640]   So Google's doing virtual reality field trips
[01:10:01.640 --> 01:10:05.960]   Wait, go ahead. Haven't they done this before?
[01:10:05.960 --> 01:10:12.760]   My daughter that's hard like she knew what Google cardboard was way at the beginning because she went on virtual field trips
[01:10:12.760 --> 01:10:14.760]   Oh, but now it's available to everyone
[01:10:15.880 --> 01:10:19.760]   Okay, so you can install expeditions on your phone and
[01:10:19.760 --> 01:10:23.960]   Participate and one of them the reason has caught my eye is Hamilton
[01:10:23.960 --> 01:10:27.760]   So my favorite thing in the world
[01:10:27.760 --> 01:10:32.000]   Is there really so one of my favorite things I was like
[01:10:32.000 --> 01:10:35.080]   Yeah, no, I also like spaghetti with meatballs
[01:10:35.080 --> 01:10:39.200]   But no Hamilton. I took we just saw it in San Francisco
[01:10:39.200 --> 01:10:44.520]   That's what's on my mind because I'd seen it in New York. You saw it again. I yeah at least that we almost saw it again like
[01:10:45.400 --> 01:10:47.400]   tomorrow
[01:10:47.400 --> 01:10:53.200]   How much how much were the tickets in San Francisco? I think you know, I said I subscribed to the series
[01:10:53.200 --> 01:10:58.680]   So I think was I think there are a hundred bucks. I don't know if one day it'll come Boston. There's active scalping
[01:10:58.680 --> 01:11:00.720]   Yeah, this is a tour. So it is yeah
[01:11:00.720 --> 01:11:07.360]   How was the quality of the production? Well, it's not New York, but it was very good the the Hamilton was
[01:11:07.360 --> 01:11:13.760]   Had performed in New York. He was an understudy and for Hamilton in New York the Angela same thing
[01:11:14.680 --> 01:11:19.920]   They're very talented cast. There's just something about Broadway that is just you know, it's just it's hard to describe
[01:11:19.920 --> 01:11:21.920]   It's just a little bit better
[01:11:21.920 --> 01:11:28.040]   But it was it's such a you know, it's a brilliant show and I just seeing it is always great to see it
[01:11:28.040 --> 01:11:33.660]   It's just amazing. I also saw I walked by a theater the other day in 1984 as a play. Yes. Yes
[01:11:33.660 --> 01:11:36.920]   1984 really has had a resurgence in the last year. I don't know why yeah
[01:11:36.920 --> 01:11:41.520]   You know else who's had a resurgence this last year Twitter
[01:11:42.280 --> 01:11:47.920]   In fact the stock market thought Twitter would make one cent earning per share
[01:11:47.920 --> 01:11:51.120]   That was the analyst consensus it made 11
[01:11:51.120 --> 01:11:56.800]   Better than expected earnings after several quarters of disappointing results
[01:11:56.800 --> 01:11:58.960]   revenue
[01:11:58.960 --> 01:12:03.840]   Better than expected still declining five hundred forty eight million monthly active users
[01:12:03.840 --> 01:12:08.000]   seven million more than expected three hundred twenty eight million
[01:12:09.920 --> 01:12:16.080]   So gross, but it's got to be I mean I think the consensus is it's because our president uses it
[01:12:16.080 --> 01:12:22.240]   So I was talking to a brand manager at a large fortune 500 company and she was taught
[01:12:22.240 --> 01:12:27.280]   We were talking about different social media stuff and she's like yeah, we everyone's like get your brand off Twitter
[01:12:27.280 --> 01:12:33.000]   It's nothing nothing's there snapchat Instagram, but now the word is we all got to go back to Twitter
[01:12:33.000 --> 01:12:35.760]   Wow
[01:12:35.760 --> 01:12:39.000]   So now they're they're back to back on Twitter
[01:12:40.000 --> 01:12:41.000]   Oh Lord
[01:12:41.000 --> 01:12:45.560]   How long how long for how long that's a good question. That's a love-hate thing
[01:12:45.560 --> 01:12:49.880]   Yeah, I mean
[01:12:49.880 --> 01:12:53.400]   I just I'm just observing
[01:12:53.400 --> 01:12:56.920]   Weird freak out
[01:12:56.920 --> 01:13:02.120]   And I Google's peripherally related to this there was a New York Times article
[01:13:02.120 --> 01:13:07.640]   About uber on Sunday actually it wasn't about over it was a profile of Travis Kalanik
[01:13:08.200 --> 01:13:12.720]   Such a good Mike Isaacs did such a great job with that profile. Yeah
[01:13:12.720 --> 01:13:19.880]   But for the geeks reading between the lines there were two very interesting tidbits in here. I
[01:13:19.880 --> 01:13:24.960]   Do recommend it. It's it's really a profile of Kalanik, but it starts off
[01:13:24.960 --> 01:13:30.240]   With a little anecdote about Kalanik apparently he had pulled a fast one on Apple
[01:13:30.240 --> 01:13:36.200]   By telling his employees to help camouflage uber's app from Apple's engineers
[01:13:36.800 --> 01:13:39.880]   because uber had been violating Apple rules secretly
[01:13:39.880 --> 01:13:42.880]   tagging iPhones
[01:13:42.880 --> 01:13:48.640]   To keep track of them even after the app was deleted that is a strict violation of Apple's privacy guidelines
[01:13:48.640 --> 01:13:54.760]   Apple caught on what the way they prevented it was with it with I think with that tool grayball that they were using to keep
[01:13:54.760 --> 01:13:57.640]   authorities from using uber they
[01:13:57.640 --> 01:14:02.920]   Geofenced Cupertino so that the feature of the app that
[01:14:02.920 --> 01:14:06.120]   extracted the phone serial number
[01:14:06.920 --> 01:14:11.720]   Wouldn't work in Cupertino, but what they didn't realize is that Apple has employees all over the place
[01:14:11.720 --> 01:14:16.120]   they thought all of the apps were viewed in Cupertino Tim Cook called him in and
[01:14:16.120 --> 01:14:23.400]   Said so I heard you've been breaking some of our rules
[01:14:23.400 --> 01:14:29.660]   Miss to cook then demanded stop the trickery. Oh, we'll kick you out of the app stall
[01:14:31.200 --> 01:14:38.200]   Of course Apple didn't know Apple with anybody else would have kicked them out of the app store and never let them back in
[01:14:38.200 --> 01:14:43.700]   But it's uber so they didn't a little now you knock it off you bad boy you and
[01:14:43.700 --> 01:14:46.480]   Of course uber says they knocked it off
[01:14:46.480 --> 01:14:51.900]   What they were doing is is keep and actually they did it for legitimate business reason not to spy on us
[01:14:51.900 --> 01:14:57.560]   But because uber drivers particularly in India I understand were buying extra phones
[01:14:57.560 --> 01:15:01.560]   They were getting rewarded for the number of rides they accepted just period accepted
[01:15:01.560 --> 01:15:08.440]   So they were buying a hundred old iPhones putting the app on them and accepting rides to to bonus themselves
[01:15:08.440 --> 01:15:11.360]   And so the whole idea was well
[01:15:11.360 --> 01:15:17.320]   We'll now know because we've seen this phone before we'll know from this idea that this is bogus that this is a resold phone
[01:15:17.320 --> 01:15:19.320]   And it's not you know or something
[01:15:19.320 --> 01:15:27.160]   So that was revelation number one interesting to Apple fans was that Apple has kind of a double standard when it comes to uber
[01:15:27.880 --> 01:15:30.960]   and also interested because Apple has never said and
[01:15:30.960 --> 01:15:35.160]   Probably should have oh, you know that uber app that was spying on you
[01:15:35.160 --> 01:15:41.800]   I didn't mention that but then the other thing we learned way down at the bottom of the story Mike Isaac
[01:15:41.800 --> 01:15:50.240]   Why you this was well researched was that uber had been buying information about competitors?
[01:15:50.240 --> 01:15:56.480]   Of course every company not every but many companies have to competitive research big companies do
[01:15:57.200 --> 01:15:59.920]   But what's interesting is where they were getting this information
[01:15:59.920 --> 01:16:06.720]   So we I've used and I even have recommended a service called unroll me unroll me
[01:16:06.720 --> 01:16:09.600]   Which is great you use it?
[01:16:09.600 --> 01:16:14.720]   Well, it was great until I found out what they were doing you use it to get
[01:16:14.720 --> 01:16:17.920]   In fact, I think I recommend it on this show to sign off of
[01:16:17.920 --> 01:16:25.400]   newsletters and mailing lists that you don't want to be on does it automatically look created digest of the stuff the leader from your
[01:16:25.400 --> 01:16:27.080]   inbox if you want
[01:16:27.080 --> 01:16:29.720]   But it turns out unroll me which was a free service
[01:16:29.720 --> 01:16:32.880]   We maybe should have asked a little bit more about how they monetized
[01:16:32.880 --> 01:16:39.800]   They said in the early days. Oh, we'll put an ad in the digest. We send you but no in fact they were collecting all your Gmail
[01:16:39.800 --> 01:16:48.080]   Going through it looking for things like oh, I don't know lift receipts and then selling that information anonymized
[01:16:48.080 --> 01:16:51.520]   They say to uber I
[01:16:53.600 --> 01:16:57.160]   Think a lot of people unrolled unroll me when they heard this
[01:16:57.160 --> 01:17:01.760]   But I guess we should have known
[01:17:01.760 --> 01:17:07.680]   Unroll me yeah wrote a blog post that was found of unroll me saying he was heartbroken
[01:17:07.680 --> 01:17:13.440]   Heartbroken we can do better. I'm heartbroken that you found out
[01:17:13.440 --> 01:17:16.240]   What we were forward
[01:17:16.240 --> 01:17:20.880]   So this is one of those things where again
[01:17:21.520 --> 01:17:25.360]   when you sign up for free service you are the product and I
[01:17:25.360 --> 01:17:34.760]   Saw this and I was like people are gonna have a fit about this and I was kind of but I was a little shruggy about it too
[01:17:34.760 --> 01:17:36.880]   but
[01:17:36.880 --> 01:17:39.240]   One of my people I follow on Twitter
[01:17:39.240 --> 01:17:41.400]   She said you know a lot of people
[01:17:41.400 --> 01:17:46.880]   Don't think about the trials and tribulations that come with being a free base service
[01:17:46.880 --> 01:17:54.120]   And she was wondering how many entrepreneurs would start a company based on a free service knowing now what they know
[01:17:54.120 --> 01:18:00.080]   Or know what they know now some dude. There's a lot of insulin Valley. We're gonna scale it and figure out how to monetize it later
[01:18:00.080 --> 01:18:02.080]   I mean Twitter is famous for that right
[01:18:02.080 --> 01:18:04.600]   They're doing a great job actually better
[01:18:04.600 --> 01:18:10.360]   Here's the thing Gmail does the same thing everybody knows Gmail Google looks at your mail
[01:18:10.360 --> 01:18:15.040]   Right, but what they do with it what they look at is they they don't sell it to a third party
[01:18:15.040 --> 01:18:20.400]   they use keywords to put advertising in your feed targeted advertising and
[01:18:20.400 --> 01:18:25.820]   People I think know most people know that that's what goes on and as long as you're not selling to a third party
[01:18:25.820 --> 01:18:30.180]   I don't think that you know most people are bothered by that those who are don't use Gmail
[01:18:30.180 --> 01:18:32.680]   Your Fitbit data sold to a third party
[01:18:32.680 --> 01:18:39.720]   But see that's kind of the thing is I think people yes, we now we need to really think harder if it's sold to a third party
[01:18:39.720 --> 01:18:41.840]   like
[01:18:41.840 --> 01:18:47.440]   Well the lifter seats, but what else is being sold with her what other email tidbits are being sold to a third party
[01:18:47.440 --> 01:18:49.720]   And the other thing we know is that anonymizing doesn't work
[01:18:49.720 --> 01:18:54.320]   We've seen time and time again so called anonymized data de anonymized easily
[01:18:54.320 --> 01:18:56.440]   right
[01:18:56.440 --> 01:19:00.960]   this is this is a huge thing that I have been talking about for years and
[01:19:00.960 --> 01:19:07.440]   People like free there's different. I mean Gmail is okay, right? I mean, it's okay with me anyway
[01:19:08.760 --> 01:19:11.800]   Gmail is fine by me because I am
[01:19:11.800 --> 01:19:14.760]   It's not just because they don't sell it
[01:19:14.760 --> 01:19:18.120]   They're also building like products on it that I think are interesting
[01:19:18.120 --> 01:19:24.320]   But I didn't put my photos in Google photos for a long time because that was a step too far for me
[01:19:24.320 --> 01:19:26.560]   So I mean everybody has
[01:19:26.560 --> 01:19:30.920]   It was accidental stupid phone
[01:19:30.920 --> 01:19:36.640]   Well, there's so much value I get out of Google photos and again
[01:19:36.640 --> 01:19:40.240]   You know Google does give you control of this and I think I know they're honest
[01:19:40.240 --> 01:19:42.320]   And I think they're explicit and what they do with it
[01:19:42.320 --> 01:19:47.080]   It doesn't sound like they're scanning your photos looking for stuff. They can sell to a third party
[01:19:47.080 --> 01:19:50.360]   No, but they do now have a image of my daughter
[01:19:50.360 --> 01:19:54.600]   Like and all of my friends and they know who hang out with and where I hang out with them
[01:19:54.600 --> 01:20:01.240]   Yeah, and that's maybe you don't want that because I understand that's really personal. Yeah, but you don't mind them seeing your fashion
[01:20:01.240 --> 01:20:03.240]   Amazon seeing your fashion choices
[01:20:03.240 --> 01:20:06.160]   No
[01:20:06.160 --> 01:20:08.160]   We all have
[01:20:08.160 --> 01:20:16.240]   Bar right there's a line beyond which we will like a slice which owns unroll me in fact bought unroll me apparently for this information
[01:20:16.240 --> 01:20:21.960]   I was using the slice app. I wasn't using unroll me. Well, actually I think I was but I not recently but slice
[01:20:21.960 --> 01:20:28.400]   is a great service because it gets all your receipts and tells you when something's on its way and so forth
[01:20:28.400 --> 01:20:34.360]   But now I realize I immediately deleted my slice account because I realized oh, they're selling it to other people
[01:20:34.360 --> 01:20:39.120]   People including uber. They also tell you like how much you spend on like uber in a year and that sort of thing
[01:20:39.120 --> 01:20:44.640]   Right, it's really useful if they kept it to themselves and have no problem with it. I trust slice
[01:20:44.640 --> 01:20:46.640]   but the problem is you're that
[01:20:46.640 --> 01:20:50.640]   Why do you care that uber can buy how many I mean?
[01:20:50.640 --> 01:20:56.880]   They're not marketing to you. They're just getting competitive. I mean is this really a huge issue
[01:20:56.880 --> 01:21:02.000]   I mean get past the icky factor like you're like what that's happening the problem is of course uber
[01:21:02.520 --> 01:21:05.240]   Because I don't trust uber as far as I can throw them
[01:21:05.240 --> 01:21:09.440]   So I mean it doesn't take a lot of imagination to come up with
[01:21:09.440 --> 01:21:11.160]   ugly uber
[01:21:11.160 --> 01:21:15.520]   Scenarios we know they have a god mode for instance that they could tell you where you you know
[01:21:15.520 --> 01:21:21.040]   They could say look there's where Leo is they could track you around with that well now if they also know my lift account
[01:21:21.040 --> 01:21:25.280]   I mean how many things are they is is did was sold to uber?
[01:21:25.280 --> 01:21:29.760]   Do they know everything I'm is uber tracking my every move are they gonna start?
[01:21:30.160 --> 01:21:34.280]   You know sending me solicitations say hey you we see you're going to the prom tomorrow
[01:21:34.280 --> 01:21:39.600]   Let's let's get an uber for you. How long before they start showing up the noobber driver starts showing up with a card
[01:21:39.600 --> 01:21:42.840]   That says Leo report at the airport because they know I'm arriving
[01:21:42.840 --> 01:21:46.240]   You know I could just see all sorts of scenarios that would not be savory
[01:21:46.240 --> 01:21:48.680]   so this is really like I
[01:21:48.680 --> 01:21:54.720]   Think uber is for whatever reasons and any company that's not thinking about
[01:21:55.640 --> 01:22:01.480]   User trust is being super short-sighted because we're moving into this era where they're gonna have a more information
[01:22:01.480 --> 01:22:09.760]   But be we're going to have automated transactions and relationships with them. So like if you sign up for Amazon -
[01:22:09.760 --> 01:22:15.160]   fulfillment on a product right you're trusting that it's measuring accurately is not trying to like
[01:22:15.160 --> 01:22:21.120]   Cheat you out of a few extra, you know filters for your Brita right or something like that, right?
[01:22:21.120 --> 01:22:29.680]   I would never expect Google to treat me not Google. I would never expect uber to treat me fairly if it had automatic access to my credit card and was
[01:22:29.680 --> 01:22:31.800]   in charge of saying
[01:22:31.800 --> 01:22:33.160]   like I
[01:22:33.160 --> 01:22:38.640]   Don't know when my ride should actually a good example is I always feel like it's telling me I've gotten my ride a little too early
[01:22:38.640 --> 01:22:41.560]   Even though the car isn't there yet, and I'm not actually in the car
[01:22:41.560 --> 01:22:47.840]   But that aside we're moving to this era where you're the trust your brand has it's gonna be really
[01:22:48.440 --> 01:22:54.200]   Important and essential like I trust Amazon with my data because Amazon doesn't sell it. They're gonna recommend products to me
[01:22:54.200 --> 01:23:01.680]   But that's about it and they're gonna protect it from authorities who come seeking it. So I don't know just going forward
[01:23:01.680 --> 01:23:03.680]   That's kind of how I've been thinking
[01:23:03.680 --> 01:23:13.560]   Jeff Google doesn't sell my information to a third party do you think no it ends up
[01:23:14.120 --> 01:23:19.000]   You know you others benefit so what when I had this conversation and the digital news initiative
[01:23:19.000 --> 01:23:25.080]   Where the beginning of the conversation about giving data to media? They're very cautious about
[01:23:25.080 --> 01:23:31.960]   Google executive said to the room media people the best way to make use of Google's media Google's data is to use
[01:23:31.960 --> 01:23:34.960]   Google's advertising services. Yeah
[01:23:34.960 --> 01:23:40.280]   And so you do get the benefit of it, but you don't get the data on your own
[01:23:40.760 --> 01:23:48.960]   To do something well, and there are ways to pass data on and cohorts that make it anonymized and make it right and allow others to give people valuable services
[01:23:48.960 --> 01:23:50.960]   Well, I think what we need to do
[01:23:50.960 --> 01:23:55.880]   The information needs to be given us clearly and then we each individual needs to decide what's okay. What's not okay?
[01:23:55.880 --> 01:24:01.480]   I'm okay with Google collecting information for internal use only. I'm not crazy about fit bit sending my
[01:24:01.480 --> 01:24:09.720]   Service this is exactly what the terms of service are it's just nobody reads them right? I mean fit it
[01:24:10.120 --> 01:24:12.240]   Well, but they're also not ready to be clear
[01:24:12.240 --> 01:24:16.520]   I mean I really think for instance on a wall me needs to say when you sign up and by the way
[01:24:16.520 --> 01:24:22.280]   This is what's gonna happen to the other things we see in your Gmail the reason they don't is they know that people would say oh, that's it
[01:24:22.280 --> 01:24:24.280]   I'm not signing up
[01:24:24.280 --> 01:24:30.560]   They like it that is obscure written in legal ease and I you know if you read the terms
[01:24:30.560 --> 01:24:36.760]   They're not immediately clear what they're gonna do what they need to do is is sayings and I wish we could say to the FTC
[01:24:37.160 --> 01:24:41.760]   Hey, you guys got to regulate this and you got to make sure that there's some rules about disclosure
[01:24:41.760 --> 01:24:47.480]   So that it's easily understood by a normal person what you planning to do
[01:24:47.480 --> 01:24:50.280]   so the FTC in
[01:24:50.280 --> 01:24:56.680]   2015 put out a report I think it was November 2015 that talked about what people should do with data and
[01:24:56.680 --> 01:25:04.840]   DC read the report and FTC called on Congress to make rules about this because the FTC currently doesn't have
[01:25:06.000 --> 01:25:12.400]   Interesting work on so if you look at the recommendations in that report you will just be dismayed by the fact that
[01:25:12.400 --> 01:25:15.280]   Even the FTC is like guys
[01:25:15.280 --> 01:25:19.420]   we should really look at this and do better here and we're not and Congress is like
[01:25:19.420 --> 01:25:23.860]   Plunt no election season and I guarantee we're not gonna deal with it now
[01:25:23.860 --> 01:25:26.560]   speaking of which
[01:25:26.560 --> 01:25:32.040]   Ajit Pai the new chairman the FCC spoke at the National Association of Broadcasters Convention today and announced
[01:25:32.040 --> 01:25:34.480]   We're gonna roll back net neutrality
[01:25:35.120 --> 01:25:37.400]   May 18th is to let you know
[01:25:37.400 --> 01:25:40.320]   the the Ed issue course
[01:25:40.320 --> 01:25:46.640]   What was the didn't you have didn't you have a devil's advocate the session which I know you do on the show to have discussion
[01:25:46.640 --> 01:25:50.640]   Didn't you have a devil's advocate session? No, I didn't but what I did is I explained
[01:25:50.640 --> 01:25:52.560]   the
[01:25:52.560 --> 01:25:54.560]   conservative point of view
[01:25:54.560 --> 01:25:56.080]   here
[01:25:56.080 --> 01:25:57.880]   Don't agree with it
[01:25:57.880 --> 01:26:04.760]   What they're gonna do is they're gonna roll back or they're gonna try to roll back the reclassification of internet service providers as common carriers
[01:26:04.760 --> 01:26:06.760]   under title two
[01:26:06.760 --> 01:26:15.760]   That provided the FCC with the regulatory cover that they needed to prohibit ISPs from blocking or throttling traffic
[01:26:15.760 --> 01:26:22.400]   FCC said we're not gonna we're not gonna use some of the other you know title two also allows them for instance to do to set rates
[01:26:22.400 --> 01:26:24.400]   We're not gonna do any of that other stuff
[01:26:24.400 --> 01:26:27.040]   but we are gonna do that and
[01:26:27.040 --> 01:26:33.400]   And that was because they were told by a court. That's the only way you can do this legally and so the
[01:26:33.920 --> 01:26:38.960]   One of the points I made is the FCC can only do what Congress explicitly allows them to do that?
[01:26:38.960 --> 01:26:46.240]   One could make the case that title two is kind of bending the telecommunications act to do what you want to do
[01:26:46.240 --> 01:26:49.680]   And I would prefer and I think most would prefer more
[01:26:49.680 --> 01:26:56.440]   Specific guidance from Congress. I think that's what pies point is well. We you know what we want is
[01:26:56.440 --> 01:26:59.120]   Congress to really say how
[01:26:59.680 --> 01:27:09.000]   ISP should be regulated now. I do believe that ISPs are you know utilities in a way that Google and Facebook are not and that your privacy
[01:27:09.000 --> 01:27:14.400]   Does need to be regulated and protected by the government. That's the only way it's gonna happen
[01:27:14.400 --> 01:27:18.000]   Wait net neutrality is in about privacy. So you sorry not privacy
[01:27:18.000 --> 01:27:23.720]   Your I was like wait. Thank you for the correction although this is kind of intermingled with the privacy rules
[01:27:23.720 --> 01:27:29.640]   But but I was like don't you jumped. Yeah, yeah, I apologize. Yes, obviously we're talking not about this
[01:27:29.640 --> 01:27:31.160]   But about
[01:27:31.160 --> 01:27:39.980]   prioritizing traffic on the Internet. Yes, and and things like zero rating and and and this is that picking incumbents thing where you know a company would say
[01:27:39.980 --> 01:27:43.720]   Well, we don't like you Netflix, but we happen to love Comcast's service
[01:27:43.720 --> 01:27:48.840]   And so we're gonna make sure everybody can get streamcast and not at no bandwidth cost to them
[01:27:48.840 --> 01:27:53.520]   But Comcast you're gonna have to pay so the FCC has scheduled a vote
[01:27:53.520 --> 01:27:58.320]   notice of proposed rulemaking for May 18th, which seeks comment and
[01:27:59.240 --> 01:28:03.640]   Would lead to a final vote. So this is the same situation that happened with the previous
[01:28:03.640 --> 01:28:07.080]   Vote remember Tom Wheeler kind of got
[01:28:07.080 --> 01:28:12.720]   Decided so this actually started this started back in
[01:28:12.720 --> 01:28:17.360]   2008 I think it was with Julius Genikowski
[01:28:17.360 --> 01:28:23.600]   His NPRM that started the ball of rowing on net neutrality regulation
[01:28:24.320 --> 01:28:31.600]   From the get-go and then Wheeler came back because Genikowski stuff was refused by the court, right and that took
[01:28:31.600 --> 01:28:38.320]   years, right and then Wheeler asked for comment millions of comments from people like you and me
[01:28:38.320 --> 01:28:43.840]   Convinced him in net neutrality and title two was the right way to go. He was really on the fence
[01:28:43.840 --> 01:28:51.680]   When he put out the the request but all of those comments convinced him that the right thing to do was title two he went title two
[01:28:53.400 --> 01:28:56.320]   So now I think once this May 18th vote happens
[01:28:56.320 --> 01:29:01.160]   It's gonna be incumbent on all of us to once again go back to the FCC and comment
[01:29:01.160 --> 01:29:09.960]   Jen pie is going to conservative groups saying look there's gonna be a grassroots movement against this you guys need to activate in favor of it
[01:29:09.960 --> 01:29:12.600]   So we'll see that
[01:29:12.600 --> 01:29:18.040]   And this everybody this is a long this is a long process. So an NPRM
[01:29:18.040 --> 01:29:21.840]   They put that out then you've got the comment period. That's usually like 90 days
[01:29:22.440 --> 01:29:26.640]   And then they will usually come back with revised rules and that sort of thing
[01:29:26.640 --> 01:29:31.200]   then it goes to a vote and then there's another response to the comment period and
[01:29:31.200 --> 01:29:37.640]   This this this is long and the thing I saw a tweet today that really I
[01:29:37.640 --> 01:29:44.480]   Took to heart because it's corrected a way. I've just used to describe this. This is not government regulation of the internet
[01:29:44.480 --> 01:29:46.600]   this is government regulation of
[01:29:46.600 --> 01:29:49.840]   private companies called ISPs and
[01:29:50.320 --> 01:29:57.280]   They should be regulated the internet does not need to be regulated. ISPs need to be prevented from breaking the internet
[01:29:57.280 --> 01:29:59.320]   Well, I like that. Well, that's good way to express is not good
[01:29:59.320 --> 01:30:00.840]   I can say I
[01:30:00.840 --> 01:30:05.520]   Mistakenly and others have done this to describe it as regulating the internet is not
[01:30:05.520 --> 01:30:14.600]   This is never described it is regulating the internet. No, it's regulating ISPs. You're smart and I'm dumb and I now stand corrected
[01:30:14.600 --> 01:30:18.200]   So do you think that that Silicon Valley?
[01:30:18.680 --> 01:30:23.040]   If they're not too busy affecting the morals and cultural worldview of
[01:30:23.040 --> 01:30:26.200]   Will they
[01:30:26.200 --> 01:30:29.600]   Step up and fight this again. Yes, so no
[01:30:29.600 --> 01:30:35.320]   So in Washington, I've talked to people who care about this fairly desperately
[01:30:35.320 --> 01:30:37.840]   both public interest groups and people who
[01:30:37.840 --> 01:30:45.400]   Historically have worked for some of the big firms that cared about this the last time around and most of them have bigger fish to fry
[01:30:45.400 --> 01:30:50.440]   Yeah, and it's not going to be a regulatory priority for them. Yeah
[01:30:50.440 --> 01:30:53.240]   So there's the bad news
[01:30:53.240 --> 01:31:00.320]   So the Internet Association Lexus Ohini and we're putting up the bat signal. Yeah. Yeah, Alex about to have what a new baby
[01:31:00.320 --> 01:31:02.640]   Yeah, but he was very involved last time remember
[01:31:02.640 --> 01:31:08.960]   The Internet Association, which is the lobbying group for Amazon Facebook Google Microsoft Netflix
[01:31:11.520 --> 01:31:16.140]   are apparently are you know concerned I hope that they will
[01:31:16.140 --> 01:31:22.820]   Step up Ed Markey from Massachusetts Richard Blumenthal from Connecticut Ron wide in of Oregon
[01:31:22.820 --> 01:31:26.600]   Mark is already. Yeah, he's already making issuing very
[01:31:26.600 --> 01:31:34.000]   Strong statements very those are three great senators who need our support. You should write your member of Congress
[01:31:34.000 --> 01:31:39.800]   Because Congress does have something to say about this ultimately electronic
[01:31:40.600 --> 01:31:43.800]   market at marquee on TV really discussed earlier
[01:31:43.800 --> 01:31:47.900]   Because he was supporting the V chip and I fear
[01:31:47.900 --> 01:31:52.140]   It was gonna result in what you fear Google's
[01:31:52.140 --> 01:31:54.840]   path to quality
[01:31:54.840 --> 01:32:00.720]   Will result in and there is right now only one Democratic Commissioner on the FCC that will be righted
[01:32:00.720 --> 01:32:04.520]   As soon as all those other things get up other people get appointed
[01:32:06.840 --> 01:32:12.640]   There's a bit of a backlog I guess but minion Clyburn who is the remaining Democratic Commissioner is
[01:32:12.640 --> 01:32:16.160]   Very active in this she's gonna have a press conference
[01:32:16.160 --> 01:32:21.720]   Just probably having it right now to discuss her support for these rules. So battle lines are being drawn
[01:32:21.720 --> 01:32:28.440]   Ajapai at an AB has said yep, we're gonna do it. We're gonna start May 18th. So pay attention and
[01:32:28.440 --> 01:32:31.720]   again again, you know what I
[01:32:31.720 --> 01:32:34.840]   We can do this as many times as we need to
[01:32:35.560 --> 01:32:38.200]   This is it. This is a word. I have to we're gonna have to
[01:32:38.200 --> 01:32:41.240]   It's it feels never mind
[01:32:41.240 --> 01:32:44.080]   I'm not ready for this
[01:32:44.080 --> 01:32:46.520]   All ready for this
[01:32:46.520 --> 01:32:52.280]   Did you get your false 5g network in Austin set up? Oh
[01:32:52.280 --> 01:32:56.540]   No, I did not I'm like oh AT&T
[01:32:56.540 --> 01:33:03.360]   Hey, you know what they've been they've been marketing the heck out of five G has been this amorphous marketing term forever
[01:33:04.720 --> 01:33:09.260]   So I have a galaxy S8 I should come down and and see you sometime
[01:33:09.260 --> 01:33:12.280]   gadget called a faux
[01:33:12.280 --> 01:33:14.280]   5g network or pre-standard
[01:33:14.280 --> 01:33:20.260]   If you have a galaxy S8 you can get speeds that should leave LTE in the dust downloads twice as fast on average
[01:33:20.260 --> 01:33:23.200]   According to AT&T Indianapolis next
[01:33:23.200 --> 01:33:28.160]   Atlanta Boston Chicago LA National Villain San Francisco slated for this year
[01:33:28.160 --> 01:33:33.040]   It's weird that you have to use a Samsung device. Is that a technical issue must be?
[01:33:33.440 --> 01:33:35.440]   It's the free you have to
[01:33:35.440 --> 01:33:39.720]   I was about to say it's your frequencies and if you're it depends on how they're doing their speeds
[01:33:39.720 --> 01:33:43.040]   And I I didn't have time to look at what AT&T is doing here
[01:33:43.040 --> 01:33:49.920]   But some of the things they use to make faster speeds you need it on the handset device side and on the tower side, right?
[01:33:49.920 --> 01:33:53.680]   Well good. I'm glad I have an essay although
[01:33:53.680 --> 01:33:57.080]   After a week with it. I'm going back to the pixel
[01:33:58.160 --> 01:34:02.240]   You're the pixels still the best Android phone out there. Oh, okay
[01:34:02.240 --> 01:34:07.920]   Yeah, I heard you saying before before at the end of the last show that you're thinking about but by another one by the larger one
[01:34:07.920 --> 01:34:11.840]   Yeah, you know cuz I do miss I like the screen real estate
[01:34:11.840 --> 01:34:17.480]   I have the small the right you know the small pixel and I like the screen real estate you use the XL right Jeff or no
[01:34:17.480 --> 01:34:22.800]   Yeah, yeah, I love it. Yeah, it's clunky looking. What's functional?
[01:34:22.800 --> 01:34:25.920]   so my pixel C
[01:34:26.800 --> 01:34:31.440]   Which I love your tab your crumb look almost died last night. Oh, no
[01:34:31.440 --> 01:34:33.760]   So
[01:34:33.760 --> 01:34:39.320]   And I found out this is this is a known issue since for almost a year. They haven't fixed it. That's very irritating
[01:34:39.320 --> 01:34:41.520]   So I had a finger
[01:34:41.520 --> 01:34:48.640]   Unlock right yeah and to boot it worked fine and then when you would then went in on the security level to get in wrong pattern
[01:34:48.640 --> 01:34:54.000]   I just use the same pattern pattern works. I did it again and again. I rebooted up. No nothing nothing
[01:34:54.480 --> 01:35:03.920]   Look it up known issue with the pixel C and fear of this or some isolated rumors of cases happening on this on the pixel phone
[01:35:03.920 --> 01:35:12.360]   And it's been unfixed so I had no choice but to wipe the tablet and then it's okay now. I'm now using a number instead
[01:35:12.360 --> 01:35:16.960]   Yeah, well, you always have a backup number right can't cool. You could have used that
[01:35:16.960 --> 01:35:21.400]   No, no wouldn't take the pattern. So there was no way to get in oh
[01:35:21.400 --> 01:35:24.160]   No, they must have been
[01:35:24.160 --> 01:35:27.120]   Something no rest no way to get in try another method. No
[01:35:27.120 --> 01:35:36.080]   Oh, that sucks. I did yeah, Stacy are you gonna get the first Wi-Fi connected juicer?
[01:35:36.080 --> 01:35:41.520]   Or are you gonna use your hands?
[01:35:41.520 --> 01:35:44.240]   Okay, okay y'all
[01:35:44.240 --> 01:35:47.880]   $400 juicer was originally down from $700
[01:35:47.880 --> 01:35:54.120]   June juicer the jr. It's the juicero. Well, that's why I thought maybe Stacy would like one of these
[01:35:54.160 --> 01:36:01.000]   Really well-made I've tested it. I've I've actually okay, so oh really? Yes. Yes, it's connected
[01:36:01.000 --> 01:36:08.280]   Here here's this is this is sad and you guys are gonna make fun of me
[01:36:08.280 --> 01:36:11.800]   But I know Doug Evans the CE the former CEO and the founder of juicero
[01:36:11.800 --> 01:36:17.720]   And everyone's making fun of this and I'm not I'm not saying they shouldn't make fun of the fact that there's a $400 juicer
[01:36:17.720 --> 01:36:24.040]   That squeezes these things but Doug Evans goal and the reason it raised so much money was not because of the juicer
[01:36:24.040 --> 01:36:26.040]   at the press the reason is because
[01:36:26.040 --> 01:36:36.840]   Doug Evans big goal in this company was to rethink how people got their food and got their vegetables and they wanted to he wanted to create an accountable supply chain
[01:36:36.840 --> 01:36:38.320]   for
[01:36:38.320 --> 01:36:41.480]   Fresh greens and fresh juice and make it easy for people to consume
[01:36:41.480 --> 01:36:48.920]   So the hardware was secondary to his vision. It was crucial to it, but it was it's not what the company is about
[01:36:48.920 --> 01:36:51.160]   And I think what happened is he ended up
[01:36:52.800 --> 01:36:58.400]   He over featured it. He got it's too much right and it became really expensive and we were in this
[01:36:58.400 --> 01:37:04.720]   It it does. I mean like it takes a very disciplined product management manager person to say
[01:37:04.720 --> 01:37:10.400]   Wait a second. This is not a good idea. We don't need the strength of two Teslas. So
[01:37:10.400 --> 01:37:13.160]   while everyone's mocking
[01:37:13.160 --> 01:37:17.360]   Everyone involved for giving $120 to a connected juicer
[01:37:17.880 --> 01:37:24.560]   Company that doesn't even require the juicer. That's actually not what this company's about. You know who agrees 100% with you
[01:37:24.560 --> 01:37:30.200]   The CEO of the juicing company of Anka Trump. She loves the idea of daily
[01:37:30.200 --> 01:37:36.240]   We can make it home. Yes, please she even
[01:37:42.960 --> 01:37:50.360]   I think we also use the same makeup believe it or not. We are we have what's on preference and one. I think it's our
[01:37:50.360 --> 01:37:53.040]   What's it called?
[01:37:53.040 --> 01:38:01.240]   It's you say Laura? We will touch magic magic magic eyeball touch it. Yeah, it's it's a it's a yeah
[01:38:01.240 --> 01:38:05.960]   I don't I'm not a makeup person. Your contouring is excellent. Don't give me that
[01:38:05.960 --> 01:38:11.200]   Like I do not I do not know I also the Queen of Contour. She's watched all the videos
[01:38:11.200 --> 01:38:14.480]   I have been Einstein's fabulous
[01:38:14.480 --> 01:38:21.680]   Bolt article about the juicero and how over engineered it is and by the way not in a bad way
[01:38:21.680 --> 01:38:28.800]   I mean he said of course if this were our investment we might have slowed them down a little bit, but they did stuff
[01:38:28.800 --> 01:38:34.400]   This is like the if you were gonna pick a squeezing device that is made
[01:38:34.400 --> 01:38:38.760]   To perfection. This is it. This is exactly
[01:38:39.040 --> 01:38:45.360]   This is the best squeezing device ever and it's just too bad that people might go out and get those juicero
[01:38:45.360 --> 01:38:48.040]   pouches of already juiced
[01:38:48.040 --> 01:38:51.600]   vegetables, let's say that they're already juiced and
[01:38:51.600 --> 01:38:54.240]   squeeze them by hand
[01:38:54.240 --> 01:39:00.600]   They're already juiced that the inside is is like it's the consistency of frozen chopped spinach
[01:39:00.600 --> 01:39:07.560]   So you're saying that you Sarah is doing more than just extruding this from the bag. It's actually processing it's it's not processing
[01:39:07.560 --> 01:39:11.880]   It's just it's the raw vegetables that are and you just kind of squeeze it
[01:39:11.880 --> 01:39:14.080]   So you've seen raw frozen spinach
[01:39:14.080 --> 01:39:20.080]   Yeah, so is it any did the stuff you get any different from the juicero that you get from squeezing it with your hand? Oh, no
[01:39:20.080 --> 01:39:22.240]   No, no, it's the same stuff. Okay, just checking
[01:39:22.240 --> 01:39:29.960]   But in you Sarah's been open at the demos they show think they will cut open a bag and they will show you the stuff inside and they're
[01:39:29.960 --> 01:39:34.720]   So they should really just give away the juicer and charge 39 bucks a month for the bags
[01:39:35.400 --> 01:39:38.400]   The bags are very expensive. They're like six to eight bucks
[01:39:38.400 --> 01:39:42.640]   But they could just do that the thing they're most concerned with like the accountability
[01:39:42.640 --> 01:39:45.260]   I think they probably could have done with like a QR code or a
[01:39:45.260 --> 01:39:51.800]   That's what he said. No, they're using either Wi-Fi as it checks the date. It makes sure it's you know, it's good
[01:39:51.800 --> 01:39:58.560]   It I don't know. I don't know. Maybe they're selling my juice preferences back to boobers
[01:39:58.560 --> 01:40:03.800]   They are they're communicating things back to the farmers there. I mean, oh again. Is this
[01:40:04.920 --> 01:40:14.720]   This is not world solving world hunger. This is just to get people to eat locally organic vegetables 120 million dollars adventure capital
[01:40:14.720 --> 01:40:19.400]   But his goal was to disrupt the food supply chain. I mean
[01:40:19.400 --> 01:40:21.760]   by
[01:40:21.760 --> 01:40:27.640]   By letting people by making a billion dollars sending afforded selling a four dollar juicer
[01:40:27.640 --> 01:40:34.160]   Giving people the confidence so selling it in an easy way giving people the confidence that it's you know
[01:40:34.440 --> 01:40:38.720]   Whatever not expired, which is a big problem actually with juice there the
[01:40:38.720 --> 01:40:44.840]   Unpassure juice you could get a real juicer and buy fresh fruit and then you really don't do that
[01:40:44.840 --> 01:40:46.840]   I mean think about sales of I mean
[01:40:46.840 --> 01:40:49.560]   sales of like microwave dinner
[01:40:49.560 --> 01:40:54.600]   It's hard to clean afterwards. It's easy to juice, but hard to clean I
[01:40:54.600 --> 01:40:56.400]   Don't know. I mean well
[01:40:56.400 --> 01:41:02.360]   There'd be a big market in you Sarah o bags or can you not get a subscription without buying the juicer?
[01:41:02.560 --> 01:41:09.200]   You have to have the juicer to get the bags. I believe or you could just eat the creative gray market in them. Yeah
[01:41:09.200 --> 01:41:15.080]   Again, I'm not saying this is great. I just well he's that I'm sure out of business
[01:41:15.080 --> 01:41:18.360]   Don't you think?
[01:41:18.360 --> 01:41:23.540]   Probably maybe I don't know. Yeah, you never know Silicon Valley. I mean some of these in the me
[01:41:23.540 --> 01:41:26.880]   Go ahead. Oh
[01:41:26.880 --> 01:41:31.880]   I was gonna say this isn't like you cat. I don't think no or is it Jesus. Oh, that was
[01:41:31.880 --> 01:41:34.880]   I sat in on the demonstrations of those guys
[01:41:34.880 --> 01:41:41.200]   There was a QR code reader the idea was you'd be reading a magazine and you'd want something in the magazine and
[01:41:41.200 --> 01:41:46.920]   You'd have this thing it looked like I have one actually and you'd scan the barcode in the magazine
[01:41:46.920 --> 01:41:51.240]   And then it would go to your computer because you didn't have a computer is connected by this cereal board
[01:41:51.240 --> 01:41:56.960]   And would go to the computer and launch the web page for that thing because because this because no one's ever gonna
[01:41:56.960 --> 01:42:00.240]   Do this thing called a you are type out the URL never
[01:42:01.320 --> 01:42:06.440]   No, never gonna happen. All right now. We're getting image search for things on our phones and getting out
[01:42:06.440 --> 01:42:08.320]   So actually that's what it's just a matter of time
[01:42:08.320 --> 01:42:11.920]   It's just be does do unless you're a Verizon customer which I want to kind of like turn it off
[01:42:11.920 --> 01:42:16.680]   Bixby on this S8 you take a picture of something. Here's my cue cat look
[01:42:16.680 --> 01:42:19.920]   Yeah, it exists. It's a little kitty
[01:42:19.920 --> 01:42:22.680]   Oh, yeah, these came out of Austin. I think
[01:42:22.680 --> 01:42:26.880]   Yeah, I think so the guy who did it had these huge gold
[01:42:27.920 --> 01:42:31.360]   Cuff links I'll never focused on this with a cue cat logo on them
[01:42:31.360 --> 01:42:37.760]   Was you know an aftershave you could smell from a radio check soul and it was just so slick. Yeah?
[01:42:37.760 --> 01:42:40.720]   I wonder if I go to see
[01:42:40.720 --> 01:42:42.800]   Go ahead
[01:42:42.800 --> 01:42:44.800]   No, go if you go to get cat
[01:42:44.800 --> 01:42:52.200]   And he's still on what I thought it was was Leo's point that you have an idea about how to change something and you
[01:42:52.200 --> 01:42:57.080]   As I do find this fascinating that he wants to change the supply chain here
[01:42:57.880 --> 01:42:59.560]   but
[01:42:59.560 --> 01:43:04.440]   Figuring out what the real value is of what you sell and what it's perceived as is
[01:43:04.440 --> 01:43:10.720]   Everything so people perceived the value was the juicer and it was not it was the juice right?
[01:43:10.720 --> 01:43:17.960]   And I have something so how you price it affected that perception 700 bucks. I mean I
[01:43:17.960 --> 01:43:21.600]   Yes, totally. I mean and I think that's of
[01:43:22.400 --> 01:43:27.600]   When we take away when we're doing our business case studies about this, that's probably closer to the lesson
[01:43:27.600 --> 01:43:30.960]   You would take away that you should take not not that this is absolutely
[01:43:30.960 --> 01:43:34.680]   Don't let your engineers over engineer your product
[01:43:34.680 --> 01:43:41.600]   Probably you know keep it up keep a lid on costs. That's you know what I honor him. What's his name?
[01:43:41.600 --> 01:43:50.480]   Doug Evans Doug Evans. He's he's such a hippie. He's a he's very he's not like he's a polar opposite of 90% of the entrepreneurs
[01:43:50.480 --> 01:43:56.080]   I mean except that he's got the same passion right but he sandalware and dude kind of chill
[01:43:56.080 --> 01:44:00.640]   He'll be back. I did he be back failure is not a stigma in Silicon Valley
[01:44:00.640 --> 01:44:03.440]   It's a badge of honor
[01:44:03.440 --> 01:44:10.000]   I don't think he's really a Silicon Valley dude to be honest in Austin. No, no, I mean he's he lives there, but he's
[01:44:10.000 --> 01:44:12.880]   He's not like that
[01:44:12.880 --> 01:44:17.640]   Serial entrepreneur. He just solved a problem a way to solve a problem that he thought
[01:44:18.600 --> 01:44:20.600]   Existed and you know, I
[01:44:20.600 --> 01:44:28.000]   Let's do our big seat exists the top of the hour and Jeff Jarvis your top 10 bands you've seen with one band that you haven't seen
[01:44:28.000 --> 01:44:34.120]   Facebook
[01:44:34.120 --> 01:44:39.640]   Nuts before that it was the he was that list of did you have you do you have how many states have you visited?
[01:44:39.640 --> 01:44:41.480]   How many tests do you have now? It's this?
[01:44:41.480 --> 01:44:48.000]   It's really creating posts that no one will read. It's just I don't care about your damn
[01:44:48.480 --> 01:44:54.240]   People no one's reading that here you spend hours making this thing up makes you feel good
[01:44:54.240 --> 01:44:59.320]   And it's just a lotion here's Jeff's post. I
[01:44:59.320 --> 01:45:02.720]   Don't know. Did you how did you make that tech so big?
[01:45:02.720 --> 01:45:07.760]   He's typing really hard I
[01:45:07.760 --> 01:45:13.840]   Debated for three minutes whether you use the F word or not. Oh, yeah. Oh, yeah
[01:45:15.600 --> 01:45:21.240]   Let's it's time for our picks. Why don't you start Stacey Higginbotham? Oh, man? I do you're gonna ask?
[01:45:21.240 --> 01:45:24.860]   Okay, why don't you start Jeff Jarvis? Yeah, thank you. She was gonna start shit
[01:45:24.860 --> 01:45:27.480]   What's he was gonna do the juicer and now she's gonna find something? Oh, no
[01:45:27.480 --> 01:45:34.880]   No, I love my June oven. I just want to say I love it. So glad we bought it. Love it. I
[01:45:34.880 --> 01:45:39.040]   In fact, I love it so much. I finally broke down the box. It came in
[01:45:39.040 --> 01:45:41.600]   Wow
[01:45:43.120 --> 01:45:46.740]   That's like that's like unpacking at the girlfriend's house. Yeah. Oh, yeah
[01:45:46.740 --> 01:45:48.960]   day two
[01:45:48.960 --> 01:45:50.380]   So very
[01:45:50.380 --> 01:45:58.000]   Verily the spin-off of Google worked on health has just announced project baseline looking for 10,000 volunteers
[01:45:58.000 --> 01:46:04.160]   To share tons and tons and tons of their medical data and I I signed up to volunteer and I'm gonna bet you will too Leo
[01:46:04.160 --> 01:46:06.680]   um and
[01:46:06.680 --> 01:46:10.400]   They asked some questions about some basic questions and then and then you're gonna go in
[01:46:10.760 --> 01:46:14.080]   Like two full days a year. You got a devote to this plus a couple of visits
[01:46:14.080 --> 01:46:17.800]   You're gonna give all kinds of precious bodily fluids what what I said
[01:46:17.800 --> 01:46:22.520]   I'm gonna give history and test for the good of society. This is like giving your DNA
[01:46:22.520 --> 01:46:29.440]   Okay, this is this is giving giving data so that they can get a baseline of data across many people not gonna sell it to over a day
[01:46:29.440 --> 01:46:37.040]   Well, yeah, they know if you're if you're limping you need a ride. Yeah, they'll charge you more
[01:46:37.040 --> 01:46:43.520]   But this is the same Verily that was doing the diabetic lens right the contact lens
[01:46:43.520 --> 01:46:49.840]   Mm-hmm. I think it was no it is it's on there. It's also will you will get a Verily study watch
[01:46:49.840 --> 01:46:54.400]   Which tracks your movement heart rate rhythm changes skins Luxe conductance?
[01:46:54.400 --> 01:46:59.720]   They'll pay you a little if you're in the study they'll pay you a little bit for your trouble
[01:46:59.720 --> 01:47:06.280]   This is this is the first large scale population health study since the or one of the few
[01:47:06.880 --> 01:47:13.560]   There's all this is not the first of course. Yeah, they're framing have had that's where all your BP data comes from actually
[01:47:13.560 --> 01:47:14.920]   I have written about it
[01:47:14.920 --> 01:47:20.120]   So wait this but this is Verily frame the framing ham heart study was done by hospitals
[01:47:20.120 --> 01:47:26.400]   I really wish yeah that they would have funded a neutral party because this is again a space where I'm like
[01:47:26.400 --> 01:47:29.400]   But they're doing it with you can stand for does that make it better?
[01:47:29.400 --> 01:47:31.320]   No, because
[01:47:31.320 --> 01:47:37.840]   Google's gonna have Google's doing the money and yes, it makes it slightly better, but you know do they have to abide by some of the
[01:47:37.840 --> 01:47:42.800]   The codes of ethics. What is it? Ira be review boards and things like that. I don't know
[01:47:42.800 --> 01:47:48.880]   So I would be very cautious and careful about this data
[01:47:48.880 --> 01:47:52.040]   Just because I move out to the wind and signed up
[01:47:52.040 --> 01:47:58.120]   Jeff, you know, okay, so I'm so you have to apply everybody knows about my prostate. So what now?
[01:47:58.840 --> 01:48:05.560]   Yeah, I think this is good. I mean, you know, these these only way to do this is with these big large longitudinal studies
[01:48:05.560 --> 01:48:09.200]   Well, yes, I just don't think they have to be done by companies
[01:48:09.200 --> 01:48:11.840]   This is a thing
[01:48:11.840 --> 01:48:17.880]   Well, good. I mean it's good to volunteer medical data. Yes, it starts because you have to find a site near you
[01:48:17.880 --> 01:48:21.440]   So oh, yeah, I could go down to pal. No, no, what no you then it says
[01:48:21.440 --> 01:48:26.920]   Then it then it goes ahead and says we're gonna be adding them all over some keep going in the thing takes about 10 minutes
[01:48:26.920 --> 01:48:28.920]   I did it while we were on
[01:48:28.920 --> 01:48:33.720]   Before the show started here's a quick. Oh, there you say what we're debating fake news. Here's a quick overview of
[01:48:33.720 --> 01:48:37.000]   the next steps step one log in
[01:48:37.000 --> 01:48:42.420]   Step two informed consent step three profile. Let's go
[01:48:42.420 --> 01:48:49.960]   Okay, so you sign in and and then but eventually I'll have to go down to Stanford. I guess because that's the nearest
[01:48:49.960 --> 01:48:56.560]   Or they'll have lots of others no, but I think this is altruistic to sign up for this and you you and I Jeff
[01:48:56.720 --> 01:49:01.480]   Have no privacy. So we're perfect. No, it's not right figure. Yeah
[01:49:01.480 --> 01:49:08.500]   Well, when you start getting the medical data though, you do like with 23 and me you're also screw my kids. I don't care
[01:49:08.500 --> 01:49:11.040]   Okay
[01:49:11.040 --> 01:49:13.040]   Fair enough
[01:49:13.040 --> 01:49:18.000]   That's what you were gonna say, right? You're giving away your genotype for your children
[01:49:18.000 --> 01:49:20.480]   Well that and
[01:49:20.480 --> 01:49:23.080]   You know the government's interested in looking at that data
[01:49:23.080 --> 01:49:27.600]   So like you start thinking about this what we don't have safeguards in place for this stuff yet
[01:49:27.600 --> 01:49:29.600]   and we're just giving it all away and
[01:49:29.600 --> 01:49:34.880]   Well, until they start putting type two diabetics and concentration camps. I think I'll be okay
[01:49:34.880 --> 01:49:40.560]   What if they make you charge they charge you well, they do charge higher insurance rates, but think about there anyway
[01:49:40.560 --> 01:49:43.560]   Yeah, I can't yeah, I know in fact insurance company
[01:49:43.560 --> 01:49:46.040]   Praise you'll lie to them
[01:49:46.040 --> 01:49:51.720]   Because that way they can deny you insurance when you ask for coverage they say no no you didn't tell us
[01:49:52.720 --> 01:49:56.040]   They don't want to know they would rather you lied to them
[01:49:56.040 --> 01:49:59.000]   find out later
[01:49:59.000 --> 01:50:06.740]   Okay, I don't know all right. I'm like I'm like I'm not I'm gonna I'm gonna hold off and read more
[01:50:06.740 --> 01:50:12.540]   I'm what could do it during the show. I don't know Stacy. You're giving your entire June diet to the to a company, you know, I mean
[01:50:12.540 --> 01:50:18.880]   I'm giving my family's entire June diet. Yeah, yeah
[01:50:19.960 --> 01:50:27.440]   You're exploiting your child's real Jesus uber now has videos of this salmon that you're eating tonight. It's like my love of broccoli
[01:50:27.440 --> 01:50:33.280]   But like I mean maybe if I only baked cookies in the June oven
[01:50:33.280 --> 01:50:38.360]   24/7 and had them every day for dinner. Maybe I wouldn't want to share that
[01:50:38.360 --> 01:50:42.200]   Yeah, I mean the only reason I'm comfortable sharing my diet is it's good
[01:50:42.200 --> 01:50:46.000]   You have a very healthy diet. Well, you think it's good
[01:50:46.680 --> 01:50:49.540]   We don't know what uber hospitals gonna think or the
[01:50:49.540 --> 01:50:52.280]   uber health plan
[01:50:52.280 --> 01:50:54.280]   What is your pick of the week Stacy?
[01:50:54.280 --> 01:50:56.640]   okay, so I
[01:50:56.640 --> 01:51:03.200]   My pick of the week was going to be talking about the the Google Home recipe stuff because we didn't do it
[01:51:03.200 --> 01:51:07.480]   We didn't mention it exactly. Um, so Google Home
[01:51:07.480 --> 01:51:10.440]   It's gonna be rolling out the next week and I haven't tried it because I'm not at my home
[01:51:10.440 --> 01:51:11.960]   So I don't have my Google home
[01:51:11.960 --> 01:51:16.840]   You're going to be able to find a recipe on the web or on your phone and send it to home
[01:51:16.840 --> 01:51:20.920]   And then you're gonna be able to go through the recipe with your Google home
[01:51:20.920 --> 01:51:25.600]   You can start stop it ask it to repeat steps. I wanted this on the echo forever and
[01:51:25.600 --> 01:51:33.880]   I'm really excited about it. So there you go. So it'll walk you through it. Mm-hmm. Can you say pause?
[01:51:33.880 --> 01:51:36.760]   You can and you can say go back
[01:51:36.920 --> 01:51:42.600]   So they've had recipes both Amazon's echo and Google and we've had recipes before but they can go through it real quick
[01:51:42.600 --> 01:51:43.600]   So this is nice
[01:51:43.600 --> 01:51:49.240]   So I will I mean I guess you could look at the app and then see the recipe but I would love it if they would say okay now Leo
[01:51:49.240 --> 01:51:53.320]   you're going to layer your raspberries in the jar and
[01:51:53.320 --> 01:51:58.740]   I'm gonna say Leo. She's kickfilling and then put some crushed
[01:51:58.740 --> 01:52:00.600]   Leo
[01:52:00.600 --> 01:52:06.120]   Stop eating the crushed graham crackers. You won't have an Leo. Stacy. This was cruel
[01:52:06.600 --> 01:52:08.600]   Showing this
[01:52:08.600 --> 01:52:16.840]   I'm immune I'm immune. Oh, I'm sorry. No, no, this is the beauty of fasting is I'm immune
[01:52:16.840 --> 01:52:22.600]   And in the Google Pro so other Google home tip for you. Yes, I just discovered this
[01:52:22.600 --> 01:52:25.960]   Yes headspace is on there you can enable headspace the headspace
[01:52:25.960 --> 01:52:31.240]   Oh, I gotta tell you because I bought her a year subscription to headspace as a gift
[01:52:31.240 --> 01:52:36.080]   She's been doing a little home. She has my Google home. So what do you do you ask?
[01:52:36.720 --> 01:52:43.240]   You say hold on. I was looking up the key first. Don't say the first stuff. It's the second stock to headspace great
[01:52:43.240 --> 01:52:47.360]   There you go. I'm messaging her right now
[01:52:47.360 --> 01:52:55.160]   And you do you have to activate it. So you have to go into services on your Google app. Oh, I
[01:52:55.160 --> 01:53:03.840]   Don't know if you do have to add it. Oh, I think it just works Andy putty. Home is sitting right now in my Google home
[01:53:03.840 --> 01:53:05.840]   I
[01:53:05.840 --> 01:53:10.320]   Love it. I just texted Abby to try it. So there you go. She has my Google home
[01:53:10.320 --> 01:53:16.000]   So I don't but yeah, she would at some point have to give it her login to headspace
[01:53:16.000 --> 01:53:21.280]   I guess I don't know if it didn't make me log in headspace is a guided meditation app
[01:53:21.280 --> 01:53:27.360]   Which we really was a form was a sponsor. We love them and it's a really good one. It's really really good. Oh cool
[01:53:27.360 --> 01:53:29.360]   Yeah, she loves them. Yeah
[01:53:29.360 --> 01:53:31.280]   Ladies and gentlemen
[01:53:31.280 --> 01:53:35.640]   Ladies and gentlemen the time has come to say goodbye to all our family
[01:53:35.640 --> 01:53:38.640]   But I hope you're hundred two times
[01:53:38.640 --> 01:53:42.800]   Yeah, 400 we have done women. I have it right here
[01:53:42.800 --> 01:53:49.540]   I have the list because Patrick Del Haney has a script it's written down here
[01:53:49.540 --> 01:53:57.240]   This we have done to date 28 days 18 hours 15 minutes and 53 seconds of this week in Google
[01:53:57.240 --> 01:54:04.120]   So I'm gonna add to that one hour 52 minutes and 39 seconds. So we have now done 28 days 19
[01:54:04.120 --> 01:54:10.440]   I'm sorry 20 hours 10 minutes and 50 60 78 seconds
[01:54:10.440 --> 01:54:15.560]   Of this one Google and if you've listened to all of it you get a prize
[01:54:15.560 --> 01:54:19.240]   This fine qcat
[01:54:19.240 --> 01:54:22.840]   Unlike say here. Oh, what's the price?
[01:54:24.120 --> 01:54:27.240]   But you but be warned you have to have a ps2 port to use it
[01:54:27.240 --> 01:54:35.880]   Jeff Jarvis is a professor of journalism at the city University of New York where there are some very lucky graduate school students in journalism
[01:54:35.880 --> 01:54:39.560]   He also blogs at buzz machine.com. He's at Jeff Jarvis. Are you traveling soon?
[01:54:39.560 --> 01:54:43.000]   London next week
[01:54:43.000 --> 01:54:45.000]   Will we have you from London?
[01:54:45.000 --> 01:54:49.720]   Uh, well, it's been something we want to do the hotel thing. I've got a dinner. So I don't know if we'll be out in all right
[01:54:49.720 --> 01:54:52.760]   We'll find others a Warren karston. Yeah, we'll figure it out
[01:54:53.640 --> 01:54:57.720]   It's not as good without you, but we'll we there's people we'll we'll sit in
[01:54:57.720 --> 01:55:02.840]   I'm just listening stacey higgin botham. Thanks once again to Wagner edstrom. I'm sorry we
[01:55:02.840 --> 01:55:10.200]   For letting you use their offices. Yeah, of course catch stacey on her iot podcast at iot podcast.com
[01:55:10.200 --> 01:55:14.360]   Does that with the wonderful kevin toful? She's at gigas stacey on the twitter
[01:55:14.360 --> 01:55:19.400]   Thank you everybody. We do this week in google every wednesday
[01:55:19.960 --> 01:55:25.480]   130 pm pacific 430 eastern 2030 utc if you want to watch live you could join us the live stream
[01:55:25.480 --> 01:55:30.120]   There's live streams everywhere twit.tv slash live youtube.com/twit
[01:55:30.120 --> 01:55:32.840]   uh twitch.tv slash twit
[01:55:32.840 --> 01:55:35.400]   You stream.com slash twit
[01:55:35.400 --> 01:55:38.040]   Or you and join us in the chamom, which is live ish
[01:55:38.040 --> 01:55:41.560]   I rc that twit.tv, but if you can't be here live
[01:55:41.560 --> 01:55:46.600]   Don't worry on demand audio and video is always available at our website twit.tv slash twig
[01:55:47.400 --> 01:55:50.280]   And wherever you subscribe to your finer podcast. We did not win
[01:55:50.280 --> 01:55:54.280]   the people's choice award in the webbies we came this close marketplace
[01:55:54.280 --> 01:55:58.200]   stepped it up at the last minute we didn't disclose
[01:55:58.200 --> 01:56:01.320]   At least it was a good show. I mean like you weren't
[01:56:01.320 --> 01:56:07.240]   Oh, yeah, we were close it was one or two percent, but we did win the webby for in the judging
[01:56:07.240 --> 01:56:08.520]   Hey
[01:56:08.520 --> 01:56:11.640]   So it worked out so you come in to new york no you know why
[01:56:11.640 --> 01:56:16.520]   Your wife said you were well, I thought we weren't till we found out the requirements
[01:56:16.520 --> 01:56:18.040]   You don't they don't you don't necessarily get on stage
[01:56:18.040 --> 01:56:19.800]   You have to show up the day before on sunday
[01:56:19.800 --> 01:56:25.400]   Give your five or accept a speech then they decide which of the ones they liked to put you on stage the next day
[01:56:25.400 --> 01:56:27.800]   And oh by the way, it'll be six thousand dollars for a table
[01:56:27.800 --> 01:56:32.760]   So we're gonna stay home. I'm going to google. I out with you. That's what i'm gonna do instead
[01:56:32.760 --> 01:56:33.960]   Yeah
[01:56:33.960 --> 01:56:35.160]   Yeah
[01:56:35.160 --> 01:56:39.080]   Same it's the same way better i'm gonna stay home go to google.io. We'll have live
[01:56:39.080 --> 01:56:41.480]   margaritas. Yeah, it'll be
[01:56:41.480 --> 01:56:45.160]   I still get the trophy
[01:56:45.160 --> 01:56:47.160]   Uh, it's in tune
[01:56:47.160 --> 01:56:48.760]   Okay
[01:56:48.760 --> 01:56:50.920]   I don't know why can you come out too?
[01:56:50.920 --> 01:56:54.040]   I don't know please
[01:56:54.040 --> 01:56:55.800]   May 16th
[01:56:55.800 --> 01:56:57.160]   It's soon. Oh
[01:56:57.160 --> 01:56:59.880]   Oh, yeah, that's soon. Um, I feel like i'm somewhere else
[01:56:59.880 --> 01:57:04.360]   Yes, I do too. I often feel that way, but maybe it's because I haven't eaten in two days
[01:57:04.360 --> 01:57:07.880]   Uh, ladies and gentlemen, thank you for joining us. We'll see you next time
[01:57:07.880 --> 01:57:11.000]   This weekend
[01:57:11.000 --> 01:57:13.000]   You
[01:57:13.000 --> 01:57:15.000]   You
[01:57:15.000 --> 01:57:17.000]   You
[01:57:17.000 --> 01:57:19.580]   (upbeat music)

