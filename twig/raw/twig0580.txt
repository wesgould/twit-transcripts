;FFMETADATA1
title=Non-Flying and Gregarious
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=580
genre=Podcast
comment=https://twit.tv/twig
copyright=These podcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2020
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:02.720]   It's time for Twig this week in Google.
[00:00:02.720 --> 00:00:06.160]   It's Stacy, Jeff, and Aunt are here,
[00:00:06.160 --> 00:00:09.760]   lots to talk about, including the Congressional Report
[00:00:09.760 --> 00:00:13.720]   Preliminary on their anti-trust case against Big Tech.
[00:00:13.720 --> 00:00:15.160]   We'll break it down.
[00:00:15.160 --> 00:00:18.600]   We'll talk about a new speaker company designed to bring live music
[00:00:18.600 --> 00:00:19.400]   into your home.
[00:00:19.400 --> 00:00:23.440]   It's founded by the guy who started Reddit, Pixel 5, No
[00:00:23.440 --> 00:00:24.240]   Neural Core.
[00:00:24.240 --> 00:00:26.200]   We'll explain why not.
[00:00:26.200 --> 00:00:28.840]   And then it's Google versus Oracle.
[00:00:28.840 --> 00:00:31.440]   Oracle arguments with this morning at the Supreme Court.
[00:00:31.440 --> 00:00:33.800]   We'll talk about how it's going.
[00:00:33.800 --> 00:00:35.680]   A lot relies on this one.
[00:00:35.680 --> 00:00:36.960]   It's all ahead.
[00:00:36.960 --> 00:00:39.240]   This week in Google is next.
[00:00:39.240 --> 00:00:43.240]   This week in Google comes to you from Twig's LastPass studios.
[00:00:43.240 --> 00:00:45.240]   Securing every access point in your company
[00:00:45.240 --> 00:00:46.840]   doesn't have to be a challenge.
[00:00:46.840 --> 00:00:49.840]   LastPass unifies access and authentication
[00:00:49.840 --> 00:00:53.360]   to make securing your employees simple and secure.
[00:00:53.360 --> 00:00:55.080]   Even when they're working remotely,
[00:00:55.080 --> 00:00:58.960]   check out lastpass.com/twit to learn more.
[00:00:58.960 --> 00:01:06.120]   Podcasts you love from people you trust.
[00:01:06.120 --> 00:01:07.400]   This is Twig.
[00:01:07.400 --> 00:01:14.160]   This is Twig this week in Google.
[00:01:14.160 --> 00:01:19.480]   Episode 580 recorded Wednesday, October 7, 2020.
[00:01:19.480 --> 00:01:23.480]   Non-flying and precarious.
[00:01:23.480 --> 00:01:25.160]   This episode of This Week in Google
[00:01:25.160 --> 00:01:27.600]   is brought to you by LastPass.
[00:01:27.600 --> 00:01:30.080]   LastPass can help you manage identities
[00:01:30.080 --> 00:01:32.560]   and promote good security behavior.
[00:01:32.560 --> 00:01:36.960]   While your employees are remote, visit lastpass.com/twit
[00:01:36.960 --> 00:01:39.400]   to find out how they can help you.
[00:01:39.400 --> 00:01:42.520]   And by Melissa, like expired milk,
[00:01:42.520 --> 00:01:46.440]   30% of your customers' data goes bad every year.
[00:01:46.440 --> 00:01:48.320]   That's money down the drain.
[00:01:48.320 --> 00:01:50.800]   Visit Melissa's developer portal for free access
[00:01:50.800 --> 00:01:54.720]   to data quality APIs, demos, and code samples.
[00:01:54.720 --> 00:01:57.240]   Fresh it up, your sour data today,
[00:01:57.240 --> 00:02:02.240]   with 1,000 records clean, for free, at Melissa.com/twit.
[00:02:02.240 --> 00:02:07.480]   And by Twilio, strengthen your customer relationships
[00:02:07.480 --> 00:02:11.040]   by uniting communications across your entire business.
[00:02:11.040 --> 00:02:13.680]   Get everything you need to build and deliver
[00:02:13.680 --> 00:02:16.840]   a new customer experience with Twilio.
[00:02:16.840 --> 00:02:19.680]   Go to Twilio.com to learn more.
[00:02:19.680 --> 00:02:21.640]   It's time for Twig this week in Google
[00:02:21.640 --> 00:02:25.840]   to show we cover the latest news from the Googleverse.
[00:02:25.840 --> 00:02:27.600]   Stacey Higginbotham is here.
[00:02:27.600 --> 00:02:30.880]   Stacey on IoT, the podcast on the website.
[00:02:30.880 --> 00:02:32.760]   Hello, Stace.
[00:02:32.760 --> 00:02:33.720]   Hello, y'all.
[00:02:33.720 --> 00:02:35.200]   Hello.
[00:02:35.200 --> 00:02:37.000]   Hello.
[00:02:37.000 --> 00:02:40.080]   Also, Aunt Pruitt is here from Hands-On Photography
[00:02:40.080 --> 00:02:41.680]   and Hands-On Wellness.
[00:02:41.680 --> 00:02:42.920]   Hello.
[00:02:42.920 --> 00:02:43.760]   How are you, Aunt Tru?
[00:02:43.760 --> 00:02:44.760]   Thanks, Port.
[00:02:44.760 --> 00:02:48.920]   And also with us the profile of Jeff Jarvis.
[00:02:48.920 --> 00:02:50.680]   It's just like outside, I forget.
[00:02:50.680 --> 00:02:53.080]   Yeah, no, there's definitely a good side.
[00:02:53.080 --> 00:02:55.080]   buzzmachine.com.
[00:02:55.080 --> 00:02:56.080]   And...
[00:02:56.080 --> 00:02:57.680]   (laughs)
[00:02:57.680 --> 00:03:00.120]   He's already got a whiteboard that says "Moral Panic."
[00:03:00.120 --> 00:03:01.880]   He's ready for our first story of the day.
[00:03:01.880 --> 00:03:03.160]   Oh, nice. He's ready for the show.
[00:03:03.160 --> 00:03:05.000]   He's also the director of the Townite Center
[00:03:05.000 --> 00:03:07.320]   for Entrepreneurial Journalism at the Craig Numer.
[00:03:07.320 --> 00:03:10.000]   It fixes the damn white balance.
[00:03:10.000 --> 00:03:10.840]   It does.
[00:03:10.840 --> 00:03:13.280]   You should just use this and now you're not pink.
[00:03:13.280 --> 00:03:14.440]   It's his moral path.
[00:03:14.440 --> 00:03:16.760]   It's his moral panic white balance.
[00:03:16.760 --> 00:03:18.800]   At the Craig Numert Graduate School of Journalism
[00:03:18.800 --> 00:03:21.160]   of the City University of New York,
[00:03:21.160 --> 00:03:26.160]   I think the moral panic is prepared for the testimony,
[00:03:26.160 --> 00:03:28.920]   or not testimony, the report.
[00:03:28.920 --> 00:03:32.920]   Remember when we had testimony from Sundar Pachai
[00:03:32.920 --> 00:03:34.680]   of Google and Mark Zuckerberg,
[00:03:34.680 --> 00:03:37.880]   Jeff Bezos, Tim Apple,
[00:03:37.880 --> 00:03:41.920]   before the House Judiciary Antitrust Subcommittee.
[00:03:41.920 --> 00:03:44.080]   The report is out.
[00:03:44.080 --> 00:03:46.520]   And...
[00:03:46.520 --> 00:03:47.520]   Only one side of it.
[00:03:47.520 --> 00:03:48.360]   Because they didn't do anything.
[00:03:48.360 --> 00:03:49.200]   The Democratic side.
[00:03:49.200 --> 00:03:50.040]   No, the Democratic side.
[00:03:50.040 --> 00:03:51.120]   They can't do anything.
[00:03:51.120 --> 00:03:53.280]   They thought they had a bipartisan thing going,
[00:03:53.280 --> 00:03:54.280]   and they don't.
[00:03:54.280 --> 00:03:55.800]   I noticed that the headlines changed.
[00:03:55.800 --> 00:03:58.120]   Initially it said the bipartisan, and then it, oops, no.
[00:03:58.120 --> 00:03:59.520]   Ah.
[00:03:59.520 --> 00:04:01.000]   Nope, it's not bipartisan.
[00:04:01.000 --> 00:04:04.600]   And the reason is, well, Washington.
[00:04:04.600 --> 00:04:05.440]   (laughs)
[00:04:05.440 --> 00:04:07.160]   It's all you need to know.
[00:04:07.160 --> 00:04:09.680]   There's a little dispute over what exactly should happen.
[00:04:09.680 --> 00:04:12.800]   The Republicans do not think that the big tech company
[00:04:12.800 --> 00:04:14.720]   should be broken up.
[00:04:14.720 --> 00:04:15.720]   The Democrats do.
[00:04:15.720 --> 00:04:20.000]   The Republicans are more concerned about anti-conservative bias.
[00:04:20.000 --> 00:04:21.600]   That's what happens when you give a report
[00:04:21.600 --> 00:04:24.000]   to Jim Jordan to review.
[00:04:24.000 --> 00:04:27.080]   It's a 450 page report.
[00:04:27.080 --> 00:04:30.840]   The House Judiciary Committee's Democratic leadership
[00:04:30.840 --> 00:04:32.880]   said the four big companies,
[00:04:32.880 --> 00:04:34.920]   Amazon, Apple, Facebook, and Google,
[00:04:34.920 --> 00:04:38.680]   had turned from scrappy startups into,
[00:04:38.680 --> 00:04:42.440]   "The kinds of monopolies we saw
[00:04:42.440 --> 00:04:46.200]   "in the era of oil barons and railroad tycoons."
[00:04:46.200 --> 00:04:47.520]   Oh, geez.
[00:04:47.520 --> 00:04:49.360]   The law--
[00:04:49.360 --> 00:04:50.960]   Oh, geez.
[00:04:50.960 --> 00:04:53.240]   No comments from the peanut gallery here.
[00:04:53.240 --> 00:04:54.080]   Oh, geez.
[00:04:54.080 --> 00:04:55.320]   (laughs)
[00:04:55.320 --> 00:04:57.040]   The law, he's got a big sign.
[00:04:57.040 --> 00:04:58.280]   This is moral panic.
[00:04:58.280 --> 00:05:00.280]   The law makers said the companies had abused
[00:05:00.280 --> 00:05:01.280]   their dominant positions,
[00:05:01.280 --> 00:05:04.480]   setting and often dictating prices and rules for commerce,
[00:05:04.480 --> 00:05:08.800]   search advertising, social networking, and publishing.
[00:05:10.160 --> 00:05:13.720]   They also, to amend these inequities,
[00:05:13.720 --> 00:05:16.520]   and I'm reading from the New York Times summary,
[00:05:16.520 --> 00:05:18.960]   law makers recommended restoring competition
[00:05:18.960 --> 00:05:20.480]   by breaking up the companies.
[00:05:20.480 --> 00:05:22.960]   This is the Democratic side of it.
[00:05:22.960 --> 00:05:26.400]   Emboldening the agencies of police market concentration
[00:05:26.400 --> 00:05:29.040]   and throwing up hurdles for the companies to acquire startups.
[00:05:29.040 --> 00:05:30.800]   I would agree with the last one.
[00:05:30.800 --> 00:05:33.040]   We've been a little lax in letting, for instance,
[00:05:33.040 --> 00:05:37.000]   Facebook acquire Instagram and WhatsApp.
[00:05:37.000 --> 00:05:38.160]   Hold on, hold on right there.
[00:05:38.160 --> 00:05:39.160]   Hold on.
[00:05:39.160 --> 00:05:41.920]   When they bought Instagram, people thought they were nuts.
[00:05:41.920 --> 00:05:42.760]   Instagram has those--
[00:05:42.760 --> 00:05:43.600]   That's true.
[00:05:43.600 --> 00:05:46.400]   They paid a fortune for it, and there's another argument
[00:05:46.400 --> 00:05:48.120]   that says, well, they made Instagram Instagram.
[00:05:48.120 --> 00:05:48.960]   They made it work.
[00:05:48.960 --> 00:05:51.080]   They could have died like other things.
[00:05:51.080 --> 00:05:53.880]   When they bought Instagram, no one thought they were nuts
[00:05:53.880 --> 00:05:55.000]   for buying Instagram.
[00:05:55.000 --> 00:05:57.360]   They thought they were nuts for paying so much.
[00:05:57.360 --> 00:05:58.200]   It is.
[00:05:58.200 --> 00:05:59.040]   It is.
[00:05:59.040 --> 00:06:01.320]   In fact, there is email, Mark Zuckerberg saying,
[00:06:01.320 --> 00:06:02.560]   "We've got to buy Instagram.
[00:06:02.560 --> 00:06:03.680]   "They're our biggest threat."
[00:06:03.680 --> 00:06:06.240]   So, and I think even then we knew
[00:06:06.240 --> 00:06:07.440]   that's why they were buying it.
[00:06:07.440 --> 00:06:09.280]   I don't think that that's a surprise.
[00:06:09.280 --> 00:06:09.800]   Yeah.
[00:06:09.800 --> 00:06:10.640]   I don't disagree.
[00:06:10.640 --> 00:06:14.400]   So, I spent a lot of time last night partially
[00:06:14.400 --> 00:06:18.320]   reading the documents because that's me.
[00:06:18.320 --> 00:06:21.040]   Jeff is like, nope, not going to read it.
[00:06:21.040 --> 00:06:24.600]   I did not read all 450 pages, but I will say
[00:06:24.600 --> 00:06:26.200]   that I spent a lot of time last night
[00:06:26.200 --> 00:06:29.680]   trying to think of the appropriate metaphors for this
[00:06:29.680 --> 00:06:33.240]   because there's a lot of issues here.
[00:06:33.240 --> 00:06:38.240]   And I would say, I think Google is in kind of the worst position
[00:06:38.240 --> 00:06:42.280]   because the core of their underlying economic value
[00:06:42.280 --> 00:06:44.880]   is ad business and the ad market said,
[00:06:44.880 --> 00:06:47.200]   this does threaten that very directly.
[00:06:47.200 --> 00:06:51.520]   Facebook is having problems with this
[00:06:51.520 --> 00:06:54.080]   or will have problems with this report as well
[00:06:54.080 --> 00:06:57.400]   because it does talk about breaking up
[00:06:57.400 --> 00:07:00.200]   and splitting apart Instagram and their businesses.
[00:07:00.200 --> 00:07:03.200]   But I think Google has the bigger threat, I'll be honest.
[00:07:03.200 --> 00:07:08.200]   But with this, I sat there and I was like, me?
[00:07:08.200 --> 00:07:13.760]   Is the everyone's favorite example about Facebook,
[00:07:13.760 --> 00:07:16.960]   the memo that Mark Zuckerberg sent saying,
[00:07:16.960 --> 00:07:19.240]   we're talking about, I don't know if Mark Zuckerberg sent it,
[00:07:19.240 --> 00:07:22.000]   the memo that talked about Instagram
[00:07:22.000 --> 00:07:23.680]   not going into some businesses
[00:07:23.680 --> 00:07:25.880]   so it didn't compete with Facebook
[00:07:25.880 --> 00:07:28.800]   and that particular employee was quoted as saying
[00:07:28.800 --> 00:07:32.680]   it was like a monopoly self-dealing inside of a company.
[00:07:32.680 --> 00:07:36.560]   And I was like, is it like a transportation company
[00:07:36.560 --> 00:07:40.480]   owning trains and airplanes and saying,
[00:07:40.480 --> 00:07:43.480]   we're only gonna fly our airplanes to these cities
[00:07:43.480 --> 00:07:46.680]   and we'll send our trains to only these cities
[00:07:46.680 --> 00:07:48.160]   and that kind of limits competition.
[00:07:48.160 --> 00:07:49.920]   Is it more like broadband in the US
[00:07:49.920 --> 00:07:52.840]   where you have a really crappy one alternative
[00:07:52.840 --> 00:07:55.480]   and then a really good one in most places?
[00:07:55.480 --> 00:07:57.080]   So, and I really struggled with this
[00:07:57.080 --> 00:07:59.480]   because this is not physical infrastructure.
[00:07:59.480 --> 00:08:02.080]   And the bottom line is I stayed up a lot thinking about this
[00:08:02.080 --> 00:08:03.240]   and I got nowhere.
[00:08:03.240 --> 00:08:06.600]   So, as a result, as a result, by the way,
[00:08:06.600 --> 00:08:07.880]   before the show began, she said,
[00:08:07.880 --> 00:08:11.320]   I haven't gotten much sleep and now I know why.
[00:08:11.320 --> 00:08:14.440]   This is a big mistake to try to understand this.
[00:08:14.440 --> 00:08:15.720]   Stacy, I wanna agree with you.
[00:08:15.720 --> 00:08:16.720]   - Well, I'm not trying to understand.
[00:08:16.720 --> 00:08:19.240]   - I'm trying to come to conclude.
[00:08:19.240 --> 00:08:20.560]   - Yeah, to think of what we could do
[00:08:20.560 --> 00:08:22.880]   that's appropriate, I understand, go ahead, Jeff.
[00:08:22.880 --> 00:08:27.120]   - So, I've long said that where Google is vulnerable
[00:08:27.120 --> 00:08:29.480]   is advertising, right?
[00:08:29.480 --> 00:08:31.840]   It's not search, that's absurd.
[00:08:31.840 --> 00:08:34.400]   It's not anything else, but advertising,
[00:08:34.400 --> 00:08:35.800]   but they're not a monopoly,
[00:08:35.800 --> 00:08:37.960]   but nonetheless, they have tremendous power.
[00:08:37.960 --> 00:08:39.080]   And the problem is long-
[00:08:39.080 --> 00:08:40.360]   - They are self-dealing.
[00:08:40.360 --> 00:08:42.320]   - That, well, well, let me say-
[00:08:42.320 --> 00:08:44.320]   - And I've always complained about that, for instance.
[00:08:44.320 --> 00:08:45.720]   - Let me tell you, there are YouTube results
[00:08:45.720 --> 00:08:47.320]   showing up at the top of search.
[00:08:47.320 --> 00:08:49.840]   - Well, hold on, hold on, let me cut it up to places.
[00:08:49.840 --> 00:08:54.360]   Sorry, for an independent company,
[00:08:54.360 --> 00:08:57.040]   Google has the power of God to say,
[00:08:57.040 --> 00:09:00.760]   you're just a click farm or you're a real company.
[00:09:00.760 --> 00:09:04.280]   And I long ago said they should have had a jury,
[00:09:04.280 --> 00:09:06.680]   a peers of advertisers, who's interested in this
[00:09:06.680 --> 00:09:09.960]   to have a good advertising marketplace on Google,
[00:09:09.960 --> 00:09:11.520]   to deal with that and Google should have made
[00:09:11.520 --> 00:09:12.640]   all those decisions themselves.
[00:09:12.640 --> 00:09:15.600]   That's point one, I think they screw that up long since.
[00:09:15.600 --> 00:09:17.440]   To your second point, I'm sorry,
[00:09:17.440 --> 00:09:20.640]   but I'm going to disagree here for the 87th time,
[00:09:20.640 --> 00:09:25.640]   that every single company on Earth promotes its own properties.
[00:09:25.640 --> 00:09:27.280]   And-
[00:09:27.280 --> 00:09:28.280]   - Yeah, that's business.
[00:09:28.280 --> 00:09:30.080]   - Google does it too, yeah.
[00:09:30.080 --> 00:09:33.120]   The New York Times does not promote the Washington Post.
[00:09:33.120 --> 00:09:35.560]   ABC does not promote CBS.
[00:09:35.560 --> 00:09:36.400]   - No, but that's the thing-
[00:09:36.400 --> 00:09:37.280]   - But that's the same.
[00:09:37.280 --> 00:09:38.480]   - So that's the important thing,
[00:09:38.480 --> 00:09:42.080]   and I think you kind of right there, you crystallized it.
[00:09:42.080 --> 00:09:43.800]   And I don't know what the answer is,
[00:09:43.800 --> 00:09:46.000]   but search is such an important part.
[00:09:46.000 --> 00:09:48.840]   Without, if you don't show up in a Google search,
[00:09:48.840 --> 00:09:51.200]   you practically don't exist.
[00:09:51.200 --> 00:09:52.680]   Hence the right to be forgotten.
[00:09:52.680 --> 00:09:54.360]   It doesn't attack the websites
[00:09:54.360 --> 00:09:58.000]   that carry the material you don't want to be remembered.
[00:09:58.000 --> 00:10:00.440]   It just says Google take down the search result.
[00:10:00.440 --> 00:10:02.760]   That's evidence, prima facie evidence,
[00:10:02.760 --> 00:10:05.840]   that if it's not on Google, it doesn't exist.
[00:10:05.840 --> 00:10:06.680]   That as you say-
[00:10:06.680 --> 00:10:08.120]   - Well, that's almost a bad law, but we'll leave it on.
[00:10:08.120 --> 00:10:10.040]   - I understand, I shouldn't have brought it into it,
[00:10:10.040 --> 00:10:13.160]   but I just, I think that it's widely agreed.
[00:10:13.160 --> 00:10:15.680]   I think that that's on the face of it obvious.
[00:10:15.680 --> 00:10:19.080]   And for that reason, as you say,
[00:10:19.080 --> 00:10:20.760]   Google has the power of God.
[00:10:20.760 --> 00:10:24.760]   And I don't think that that power of God should be resided,
[00:10:24.760 --> 00:10:27.080]   unfortunately, in a commercial entity
[00:10:27.080 --> 00:10:30.960]   that is then incented to promote its own business interests.
[00:10:30.960 --> 00:10:32.760]   You're right, that's what happens.
[00:10:32.760 --> 00:10:35.920]   That's a normal thing, but I don't, that's the problem,
[00:10:35.920 --> 00:10:39.640]   is that this is so important, this ecumenical search,
[00:10:39.640 --> 00:10:42.760]   this unbiased search, that it shouldn't be held
[00:10:42.760 --> 00:10:47.320]   by a private company because they're going to be polluting
[00:10:47.320 --> 00:10:49.000]   the results with their own self-interests.
[00:10:49.000 --> 00:10:51.960]   - I think that's not where they're in antitrust danger.
[00:10:51.960 --> 00:10:54.200]   I think Stacy's right, where they're in antitrust danger
[00:10:54.200 --> 00:10:56.200]   is in the ad business.
[00:10:56.200 --> 00:10:59.240]   It's not on search, search is only one way we get to stuff.
[00:10:59.240 --> 00:11:01.040]   There's lots of ways we get to stuff.
[00:11:01.040 --> 00:11:05.240]   But in terms of how an advertiser reaches the audience
[00:11:05.240 --> 00:11:09.360]   through programmatic now, Google has incredible power there.
[00:11:09.360 --> 00:11:13.920]   And by the way, by the way.
[00:11:13.920 --> 00:11:15.680]   - And the report talks about that.
[00:11:15.680 --> 00:11:17.840]   Or is it a report in my eyes?
[00:11:17.840 --> 00:11:21.040]   - It's a sort of report because we thought
[00:11:21.040 --> 00:11:22.800]   it was going to be a bipartisan report
[00:11:22.800 --> 00:11:24.360]   and then the Republicans disagreed.
[00:11:24.360 --> 00:11:29.040]   - There's a couple hundred page alternative report
[00:11:29.040 --> 00:11:31.440]   out there, you're aware of that, right?
[00:11:31.440 --> 00:11:33.320]   - From the right.
[00:11:33.320 --> 00:11:34.880]   - From the right. - From the right.
[00:11:34.880 --> 00:11:37.240]   - Yeah, from-- - Which also goes into,
[00:11:37.240 --> 00:11:38.520]   oh, you're-- - Ken, but--
[00:11:38.520 --> 00:11:39.920]   - We tell you to take down hate speech
[00:11:39.920 --> 00:11:41.480]   plus our speech speech you take down.
[00:11:41.480 --> 00:11:42.640]   - Right.
[00:11:42.640 --> 00:11:43.960]   - Right.
[00:11:43.960 --> 00:11:47.640]   - Yeah, so this, I will just say, sorry, Leo.
[00:11:47.640 --> 00:11:51.680]   Just one thing here, I was so excited reading some of this
[00:11:51.680 --> 00:11:54.960]   because it felt like a back to politics as usual
[00:11:54.960 --> 00:11:58.400]   in some ways, like, hey, because there are a lot
[00:11:58.400 --> 00:11:59.960]   of points of agreement here, right?
[00:11:59.960 --> 00:12:02.760]   That the big tech companies have too much power, right?
[00:12:02.760 --> 00:12:05.680]   We were figuring, there's so many points of agreement.
[00:12:05.680 --> 00:12:08.320]   And then they're like, okay, let's figure out
[00:12:08.320 --> 00:12:10.720]   how to solve this in, of course, the Republicans are like,
[00:12:10.720 --> 00:12:12.160]   we should not actively break up
[00:12:12.160 --> 00:12:13.880]   existing companies, we're conservatives.
[00:12:13.880 --> 00:12:16.120]   We don't like to do that, right?
[00:12:16.120 --> 00:12:18.200]   But then they went off and took their crazy pills again
[00:12:18.200 --> 00:12:22.240]   and were like, plus the real issue is bias against,
[00:12:22.240 --> 00:12:23.440]   you know, people on the right.
[00:12:23.440 --> 00:12:24.280]   - Right. - Is it kind of off?
[00:12:24.280 --> 00:12:25.280]   - For a second there, I thought we were gonna have
[00:12:25.280 --> 00:12:27.200]   a really, like, normal--
[00:12:27.200 --> 00:12:30.280]   - But Buck, Buck did say in his, and this was a draft
[00:12:30.280 --> 00:12:32.800]   that was, anyway, the writers got ahold of it.
[00:12:32.800 --> 00:12:34.640]   Buck did say in this draft, quote,
[00:12:34.640 --> 00:12:37.960]   the report offers a chilling look into how Apple,
[00:12:37.960 --> 00:12:40.920]   Amazon, Google and Facebook have used their power
[00:12:40.920 --> 00:12:44.320]   to control how we see and understand the world.
[00:12:44.320 --> 00:12:47.920]   Now maybe he's going to the conservative voices.
[00:12:47.920 --> 00:12:51.200]   But I don't think anybody disagrees with that.
[00:12:51.200 --> 00:12:54.960]   - I do. - You don't think Google has--
[00:12:54.960 --> 00:12:57.160]   - They have opened up, they have opened up
[00:12:57.160 --> 00:13:00.040]   far more ways to see the world than old mass media
[00:13:00.040 --> 00:13:01.120]   to be more controlled by them.
[00:13:01.120 --> 00:13:02.600]   - Yeah, that's fine. - There are far more places
[00:13:02.600 --> 00:13:04.680]   far more places we can hear. - That's up to now.
[00:13:04.680 --> 00:13:06.000]   - Here's the world.
[00:13:06.000 --> 00:13:09.160]   - That's up to now, but the fact remains,
[00:13:09.160 --> 00:13:10.760]   that decision is made-- - It broke open.
[00:13:10.760 --> 00:13:12.360]   - That's the only idea of media.
[00:13:12.360 --> 00:13:15.480]   - No, the fact remains, that decision is made
[00:13:15.480 --> 00:13:17.640]   by a group of people in Silicon Valley
[00:13:17.640 --> 00:13:21.520]   who have absolutely no responsibility to anybody.
[00:13:21.520 --> 00:13:24.000]   It's Google's-- - I heard it media.
[00:13:24.000 --> 00:13:27.120]   - Well, media was an oligopoly. - But wait a minute, Jeff.
[00:13:27.120 --> 00:13:28.760]   - A few players of old media, Jeff.
[00:13:28.760 --> 00:13:31.120]   - Wait a minute, Jeff. - But there's one company
[00:13:31.120 --> 00:13:33.560]   that determines whether you exist on the internet or not,
[00:13:33.560 --> 00:13:35.440]   and it's a privately held company.
[00:13:35.440 --> 00:13:37.280]   You think that's a good thing?
[00:13:37.280 --> 00:13:40.880]   - I think it's better than what we had before,
[00:13:40.880 --> 00:13:44.360]   because that company has enabled far more voices to occur.
[00:13:44.360 --> 00:13:45.720]   And let's throw in some-- - Wait a minute.
[00:13:45.720 --> 00:13:46.880]   Wait a minute. - What about this?
[00:13:46.880 --> 00:13:49.560]   - It's enabled more, but they have a whole lot of buttons
[00:13:49.560 --> 00:13:51.200]   that they can put. - Exactly.
[00:13:51.200 --> 00:13:54.400]   That's so far. - But can't versus does,
[00:13:54.400 --> 00:13:55.280]   it's a big difference.
[00:13:55.280 --> 00:13:56.600]   Can versus does.
[00:13:56.600 --> 00:13:58.280]   Show me the evidence that they've done something
[00:13:58.280 --> 00:13:59.840]   and actually roll. - No, they haven't.
[00:13:59.840 --> 00:14:02.360]   But that doesn't matter. - Well, you still don't give
[00:14:02.360 --> 00:14:04.400]   the nuclear button to some guy,
[00:14:04.400 --> 00:14:06.480]   sitting in a tower in Germany and say,
[00:14:06.480 --> 00:14:09.400]   "Well, he hasn't blown up the world yet, so it's okay."
[00:14:09.400 --> 00:14:13.380]   It doesn't make any sense to give that much power to Google.
[00:14:15.040 --> 00:14:16.880]   Just 'cause they haven't blown up the world,
[00:14:16.880 --> 00:14:19.440]   doesn't mean it's okay. - It's done the wrong way, right?
[00:14:19.440 --> 00:14:22.400]   - They broke up the power that existed already
[00:14:22.400 --> 00:14:23.560]   in these institutions.
[00:14:23.560 --> 00:14:25.520]   And the old institutions hate it,
[00:14:25.520 --> 00:14:26.960]   and that's why they're fighting it.
[00:14:26.960 --> 00:14:28.360]   That's why media fights it.
[00:14:28.360 --> 00:14:30.200]   That's why politics fights it.
[00:14:30.200 --> 00:14:32.960]   That's because-- - Jeff, I don't think you paying attention
[00:14:32.960 --> 00:14:34.480]   to Google-- - I don't think you're paying attention
[00:14:34.480 --> 00:14:35.880]   to the real criticism here.
[00:14:35.880 --> 00:14:37.640]   I get what you're saying.
[00:14:37.640 --> 00:14:39.800]   And there's definitely benefits.
[00:14:39.800 --> 00:14:43.120]   But, and also, I would submit that there is no obvious
[00:14:43.120 --> 00:14:46.240]   solution to the fact that Google dominates search,
[00:14:46.240 --> 00:14:48.360]   because I don't understand how you could fix that.
[00:14:48.360 --> 00:14:50.840]   You take it away from Google.
[00:14:50.840 --> 00:14:52.400]   There's just no way to do that.
[00:14:52.400 --> 00:14:55.920]   But, I do think it's a big problem that Google has is,
[00:14:55.920 --> 00:14:57.400]   and by the way, Facebook too.
[00:14:57.400 --> 00:14:59.960]   If somebody inside Facebook or somebody inside Google
[00:14:59.960 --> 00:15:03.520]   decided they, for instance, wanted to elect one person
[00:15:03.520 --> 00:15:04.840]   at the present of the United States,
[00:15:04.840 --> 00:15:07.800]   they would have an immense amount of power to do that.
[00:15:07.800 --> 00:15:10.640]   - Lots of tools. - This kind of good
[00:15:10.640 --> 00:15:14.080]   is really bad policy, a legal talk.
[00:15:14.080 --> 00:15:16.240]   A lot of things could happen.
[00:15:16.240 --> 00:15:18.000]   But, and you're gonna get indicted,
[00:15:18.000 --> 00:15:20.320]   and you're gonna get tried on the basis of what you could,
[00:15:20.320 --> 00:15:21.560]   but never did. - No, no, no.
[00:15:21.560 --> 00:15:23.360]   I'm not, there's no criminal.
[00:15:23.360 --> 00:15:24.840]   This is not a criminal trial.
[00:15:24.840 --> 00:15:26.880]   - Well, you're gonna suffer consequences
[00:15:26.880 --> 00:15:29.360]   for things you didn't do, but you could have done.
[00:15:29.360 --> 00:15:31.360]   - Well, you're gonna, okay.
[00:15:31.360 --> 00:15:32.960]   Actually, no.
[00:15:32.960 --> 00:15:35.040]   - Yeah, you'd be smart to stay away from this if I were--
[00:15:35.040 --> 00:15:37.480]   - Yeah, like, I'm gonna pull an inch right now.
[00:15:37.480 --> 00:15:38.520]   (laughing)
[00:15:38.520 --> 00:15:39.960]   - Otherwise, can I take a moment?
[00:15:39.960 --> 00:15:42.760]   So, this is completely off topic.
[00:15:42.760 --> 00:15:44.560]   But hey, do we ever do that?
[00:15:44.560 --> 00:15:48.440]   So, I got Zoom ear.
[00:15:48.440 --> 00:15:51.920]   I messed up my ears with these things,
[00:15:51.920 --> 00:15:54.480]   and so that's why I'm not wearing my usual thing today.
[00:15:54.480 --> 00:15:58.680]   I'm wearing this, but I can't hear anything 'cause of this.
[00:15:58.680 --> 00:15:59.520]   - Oh, no, no, no, no.
[00:15:59.520 --> 00:16:02.280]   - So I feel like I'm shouting more than I actually am.
[00:16:02.280 --> 00:16:03.120]   - Do you wanna do anything?
[00:16:03.120 --> 00:16:04.280]   Do you wanna do anything?
[00:16:04.280 --> 00:16:05.120]   - Yeah, yeah, yeah.
[00:16:05.120 --> 00:16:06.200]   - Wait, is that natural diagnosis?
[00:16:06.200 --> 00:16:07.440]   Zoom ear? - Zoom ear.
[00:16:07.440 --> 00:16:08.280]   It's a new thing. - It's a new thing.
[00:16:08.280 --> 00:16:09.120]   - I'm so, do diagnosis.
[00:16:09.120 --> 00:16:11.800]   - So I just can't hear what's going on for a month.
[00:16:11.800 --> 00:16:16.800]   I'm gonna change my headsets and risk pain again.
[00:16:16.800 --> 00:16:18.880]   - No, no, no, don't do that.
[00:16:18.880 --> 00:16:20.240]   You can hear well, if it's fine.
[00:16:20.240 --> 00:16:22.000]   - I can't hear what's going on.
[00:16:22.000 --> 00:16:25.360]   - Let's got Zoom ear.
[00:16:25.360 --> 00:16:28.600]   So now Zoom is on a time.
[00:16:28.600 --> 00:16:30.120]   - I don't know what the answer is
[00:16:30.120 --> 00:16:35.120]   if you accept the fact that Facebook and Google both
[00:16:35.120 --> 00:16:38.720]   have huge power,
[00:16:38.720 --> 00:16:41.280]   and no accountability,
[00:16:41.280 --> 00:16:43.680]   and I don't know what the answer is to that situation.
[00:16:43.680 --> 00:16:46.320]   I'm not assuming or saying they've done anything
[00:16:46.320 --> 00:16:49.840]   wrong up to now, but it's not unreasonable to say,
[00:16:49.840 --> 00:16:54.280]   well, just 'cause they haven't blown up the world yet,
[00:16:54.280 --> 00:16:55.120]   the fact that they have the-- - It's got tons
[00:16:55.120 --> 00:16:57.200]   of accountability, half the world is going after them.
[00:16:57.200 --> 00:16:58.600]   Every media outlet is going after them,
[00:16:58.600 --> 00:16:59.880]   every politician is going after them.
[00:16:59.880 --> 00:17:01.120]   I call that accountability.
[00:17:01.120 --> 00:17:03.720]   - They don't always listen.
[00:17:03.720 --> 00:17:06.520]   - I mean, you have to drag Facebook into every,
[00:17:06.520 --> 00:17:09.960]   I mean, Facebook will apologize for running over your mom,
[00:17:09.960 --> 00:17:12.240]   but that won't stop them from driving with his eyes closed.
[00:17:12.240 --> 00:17:14.080]   (laughing)
[00:17:14.080 --> 00:17:18.280]   So I think we do like accountability after the fact
[00:17:18.280 --> 00:17:21.320]   in social media is not very helpful.
[00:17:21.320 --> 00:17:24.600]   I think we need to acknowledge that and think,
[00:17:24.600 --> 00:17:26.640]   I mean, and I also think,
[00:17:26.640 --> 00:17:30.480]   do I think we should break these up?
[00:17:30.480 --> 00:17:32.720]   I really, like part of me is,
[00:17:32.720 --> 00:17:35.960]   this is what kept me up all night,
[00:17:35.960 --> 00:17:37.160]   never mind, keep going.
[00:17:37.160 --> 00:17:38.160]   - I know what you can say.
[00:17:38.160 --> 00:17:40.440]   - I don't think breaking them up would matter.
[00:17:40.440 --> 00:17:41.440]   - Oh, it'll matter.
[00:17:41.440 --> 00:17:44.640]   - People are way too smart and will still figure out a way
[00:17:44.640 --> 00:17:47.640]   to continue their dominance into space.
[00:17:47.640 --> 00:17:49.160]   - Oh, you could break them up.
[00:17:49.160 --> 00:17:50.920]   You could break them up, but I just think
[00:17:50.920 --> 00:17:55.400]   that the Congress's weapons and understanding
[00:17:55.400 --> 00:17:59.120]   or the courts is insufficient to do the job properly.
[00:17:59.120 --> 00:18:03.000]   So it'd be-- - I think a better understanding.
[00:18:03.000 --> 00:18:03.840]   I really do.
[00:18:03.840 --> 00:18:06.320]   - I think we've seen this as a problem
[00:18:06.320 --> 00:18:07.960]   and we've actually been talking about it.
[00:18:07.960 --> 00:18:09.000]   Let's see, it's 2020 now.
[00:18:09.000 --> 00:18:11.360]   We've been talking about this for six or seven years
[00:18:11.360 --> 00:18:13.000]   and we've actually gotten some really good
[00:18:13.000 --> 00:18:14.920]   academic research on it.
[00:18:14.920 --> 00:18:19.200]   So I think that we could actually do something.
[00:18:19.200 --> 00:18:20.960]   The question again is what do we do?
[00:18:20.960 --> 00:18:24.960]   And-- - All right, that's as hard, isn't it?
[00:18:24.960 --> 00:18:29.440]   - Yeah, and I think breaking up something like Facebook
[00:18:29.440 --> 00:18:33.160]   and pulling, the other thing to think about is
[00:18:33.160 --> 00:18:36.920]   when you break up, like when they broke up AT&T,
[00:18:36.920 --> 00:18:41.640]   they had to put in all of these rules in place
[00:18:41.640 --> 00:18:44.880]   to like, because there was actual physical infrastructure,
[00:18:44.880 --> 00:18:48.760]   right, that AT&T still had to deal with,
[00:18:48.760 --> 00:18:51.200]   like all the T1 lines or what it is.
[00:18:51.200 --> 00:18:54.480]   They weren't even, they were like T1s, OC48s,
[00:18:54.480 --> 00:18:55.800]   all that way back in the day.
[00:18:55.800 --> 00:18:57.120]   They had to have-- - And all this stuff
[00:18:57.120 --> 00:19:00.800]   still confuses me. - They had rules
[00:19:00.800 --> 00:19:04.280]   saying, "Hey, when your new competitor
[00:19:04.280 --> 00:19:07.120]   "who is actually using what was your equipment calls
[00:19:07.120 --> 00:19:09.080]   "and needs help, you have to serve them
[00:19:09.080 --> 00:19:11.160]   "within X number of hours."
[00:19:11.160 --> 00:19:14.200]   And AT&T was like, "Yeah, yeah, sure.
[00:19:14.200 --> 00:19:17.280]   "We'll get right on that, prove it."
[00:19:17.280 --> 00:19:20.800]   So I think we did those breakups
[00:19:20.800 --> 00:19:22.800]   and that was really hard.
[00:19:22.800 --> 00:19:24.560]   This in some ways would be easier
[00:19:24.560 --> 00:19:26.480]   because there's less physical infrastructure.
[00:19:26.480 --> 00:19:28.160]   I know there are servers.
[00:19:28.160 --> 00:19:30.320]   There's going to be a heavy lift to separate
[00:19:30.320 --> 00:19:33.560]   the computing infrastructure.
[00:19:33.560 --> 00:19:35.520]   But I actually don't know,
[00:19:35.520 --> 00:19:38.520]   I don't think it's as hard as it would be made out to be.
[00:19:38.520 --> 00:19:41.000]   - Was it a problem? - And I do think it's,
[00:19:41.000 --> 00:19:43.320]   it puts a bump in the road and lets--
[00:19:43.320 --> 00:19:45.640]   - Let me read this. - Other companies didn't know.
[00:19:45.640 --> 00:19:47.960]   - This is part one of the findings,
[00:19:47.960 --> 00:19:50.000]   real quickly, just a couple of paragraphs,
[00:19:50.000 --> 00:19:52.080]   which show that they understand the value
[00:19:52.080 --> 00:19:54.760]   of these companies, but also understand the peril.
[00:19:54.760 --> 00:19:57.200]   The open internet has delivered significant benefits
[00:19:57.200 --> 00:19:59.680]   to Americans and the US economy.
[00:19:59.680 --> 00:20:00.920]   Over the past few decades,
[00:20:00.920 --> 00:20:03.040]   it's created a surge of economic opportunity,
[00:20:03.040 --> 00:20:06.080]   capital investment and pathways for education.
[00:20:06.080 --> 00:20:09.040]   The COVID-19 pandemic has underscored
[00:20:09.040 --> 00:20:10.520]   the importance of internet access.
[00:20:10.520 --> 00:20:11.500]   That is affordable, competitive and wide-
[00:20:11.500 --> 00:20:13.400]   - That's great. - available.
[00:20:13.400 --> 00:20:14.320]   - Yep.
[00:20:14.320 --> 00:20:17.600]   So they acknowledge what you're saying completely,
[00:20:17.600 --> 00:20:20.640]   but they also say the online-- - A free speech.
[00:20:20.640 --> 00:20:22.120]   - They say the online platforms
[00:20:22.120 --> 00:20:23.720]   investigated by the subcommittee,
[00:20:23.720 --> 00:20:25.320]   Amazon, Apple, Facebook and Google,
[00:20:25.320 --> 00:20:28.280]   also play an important role in our economy and society
[00:20:28.280 --> 00:20:30.800]   as the underlying infrastructure
[00:20:30.800 --> 00:20:32.640]   for the exchange of communications,
[00:20:32.640 --> 00:20:35.600]   information, goods and services.
[00:20:35.600 --> 00:20:37.880]   They talk about the size and so forth,
[00:20:37.880 --> 00:20:40.000]   but, and this is the, I think this is the peril,
[00:20:40.000 --> 00:20:41.760]   and I don't know if you would even disagree with this,
[00:20:41.760 --> 00:20:43.560]   Jeff, but maybe you will, I'll give you a chance.
[00:20:43.560 --> 00:20:44.640]   Over the past decade,
[00:20:44.640 --> 00:20:48.440]   the digital economy has been highly concentrated
[00:20:48.440 --> 00:20:50.760]   and prone to monopolization.
[00:20:50.760 --> 00:20:53.920]   Several markets investigate by the subcommittee,
[00:20:53.920 --> 00:20:56.560]   such as social networking, general online search
[00:20:56.560 --> 00:20:58.520]   and online advertising are dominated
[00:20:58.520 --> 00:21:01.920]   by just one or two firms.
[00:21:01.920 --> 00:21:05.880]   And I think you would agree there is a peril to that,
[00:21:05.880 --> 00:21:07.640]   or maybe you wouldn't, would you disagree with it?
[00:21:07.640 --> 00:21:10.680]   - No, I wish I had my Marshall McLuhan moment,
[00:21:10.680 --> 00:21:12.800]   I wish I had Benedict Evans next to me,
[00:21:12.800 --> 00:21:15.640]   so he could explain it with a British accent better than I can.
[00:21:15.640 --> 00:21:18.600]   Two points on this, one is,
[00:21:18.600 --> 00:21:21.240]   it depends on how, well, three, I'll be at four or five.
[00:21:22.440 --> 00:21:24.800]   One is an antitrust in this country,
[00:21:24.800 --> 00:21:27.800]   we care about consumer harm, different in Europe,
[00:21:27.800 --> 00:21:28.960]   but here it's about consumer harm.
[00:21:28.960 --> 00:21:30.840]   I said there's no, but no consumer harm.
[00:21:30.840 --> 00:21:35.400]   Two is that Benedict argues very well better than I can,
[00:21:35.400 --> 00:21:36.920]   how breaking him up is gonna do nothing,
[00:21:36.920 --> 00:21:38.120]   it doesn't accomplish anything.
[00:21:38.120 --> 00:21:40.240]   It's just an effort to make you feel good punitively.
[00:21:40.240 --> 00:21:43.160]   So three, I was part of a transatlantic high level
[00:21:43.160 --> 00:21:44.400]   working group on content moderation
[00:21:44.400 --> 00:21:45.760]   and freedom of expression,
[00:21:45.760 --> 00:21:47.560]   which addressed only content moderation,
[00:21:47.560 --> 00:21:49.600]   which came up with a framework that even I,
[00:21:49.600 --> 00:21:51.760]   who seemed like sounds like a libertarian at these moments,
[00:21:51.760 --> 00:21:54.760]   so I'll have my Biden, Harris, mask on tonight,
[00:21:54.760 --> 00:21:58.040]   even I, endorsed.
[00:21:58.040 --> 00:22:01.080]   And what it says is rather than going at this punitively,
[00:22:01.080 --> 00:22:02.720]   acknowledge we're in a changing world,
[00:22:02.720 --> 00:22:04.240]   which is part of Stacey's argument,
[00:22:04.240 --> 00:22:05.600]   well, let's have discussions.
[00:22:05.600 --> 00:22:07.200]   Well, all right, more than discussions, fine.
[00:22:07.200 --> 00:22:08.880]   So then what this argues is,
[00:22:08.880 --> 00:22:13.880]   one, that hold the platforms to making warrants
[00:22:13.880 --> 00:22:17.320]   to the public, then hold them accountable for that
[00:22:17.320 --> 00:22:20.080]   as the FTC does and demand data
[00:22:20.080 --> 00:22:21.960]   so that you can hold them accountable for that.
[00:22:21.960 --> 00:22:24.080]   I endorse that view.
[00:22:24.080 --> 00:22:27.280]   And so, the FTC doesn't say to a peanut butter company,
[00:22:27.280 --> 00:22:29.480]   this is what you must promise or not promise.
[00:22:29.480 --> 00:22:31.680]   However, if you promise the peanut butter
[00:22:31.680 --> 00:22:33.240]   is going to make you rich
[00:22:33.240 --> 00:22:36.560]   and it doesn't make you rich, stupid idea, I know,
[00:22:36.560 --> 00:22:37.920]   then the FTC is gonna sue you
[00:22:37.920 --> 00:22:40.560]   for what you failed to deliver.
[00:22:40.560 --> 00:22:42.480]   So if you've got problems with the platforms,
[00:22:42.480 --> 00:22:44.960]   what we have now happening is a whole emotional thing.
[00:22:44.960 --> 00:22:46.680]   They're too damn big, break 'em up.
[00:22:46.680 --> 00:22:48.400]   It's an emotional response that a compliment.
[00:22:48.400 --> 00:22:51.600]   I don't know, I think you're exactly wrong on this report.
[00:22:51.600 --> 00:22:53.440]   This is the antithesis of emotional.
[00:22:53.440 --> 00:22:54.480]   This is well thought out.
[00:22:54.480 --> 00:22:56.080]   They took 18 months to research it.
[00:22:56.080 --> 00:22:59.280]   They collected huge amount of documentary evidence.
[00:22:59.280 --> 00:23:01.760]   I think this is as thoughtful and careful
[00:23:01.760 --> 00:23:03.200]   and they have tons of evidence,
[00:23:03.200 --> 00:23:05.960]   including smoking gun emails from Zuckerberg and others.
[00:23:05.960 --> 00:23:08.440]   But I think this is at the epitome
[00:23:08.440 --> 00:23:12.400]   of a carefully thought out proposal.
[00:23:12.400 --> 00:23:13.920]   Where does Apple say to all of this?
[00:23:13.920 --> 00:23:15.280]   In just a, oh.
[00:23:16.840 --> 00:23:19.600]   Well, Apple says we don't have them enoughly
[00:23:19.600 --> 00:23:21.440]   in any of the markets we compete in,
[00:23:21.440 --> 00:23:23.560]   which is that they've always said.
[00:23:23.560 --> 00:23:26.920]   I mean, you know, Apple, the issue is that
[00:23:26.920 --> 00:23:29.320]   in Facebook and Google because of all the data
[00:23:29.320 --> 00:23:30.920]   that they manage every single second of the day.
[00:23:30.920 --> 00:23:32.360]   Well, that's part of the problem.
[00:23:32.360 --> 00:23:36.520]   'Cause this, you're right, they're very different problems.
[00:23:36.520 --> 00:23:40.640]   And I don't know if Apple belongs in this basket, frankly.
[00:23:40.640 --> 00:23:41.480]   All right.
[00:23:41.480 --> 00:23:43.080]   I think it's none of these so-
[00:23:43.080 --> 00:23:45.240]   We're doing this research and we still have Apple
[00:23:45.240 --> 00:23:46.240]   in this conversation.
[00:23:46.240 --> 00:23:48.800]   Well, but they have, they talk about the problems.
[00:23:48.800 --> 00:23:49.640]   They have issues.
[00:23:49.640 --> 00:23:52.600]   So they should have issued a report on everybody.
[00:23:52.600 --> 00:23:54.400]   Individually, they should have said, hey,
[00:23:54.400 --> 00:23:55.240]   you're so cool.
[00:23:55.240 --> 00:23:57.000]   Or maybe Facebook and Google.
[00:23:57.000 --> 00:23:59.520]   'Cause those two are related.
[00:23:59.520 --> 00:24:04.520]   Well, no, 'cause they're related in some of the ad stuff.
[00:24:04.520 --> 00:24:06.520]   But they're in, yeah.
[00:24:06.520 --> 00:24:10.280]   So I would say each individually,
[00:24:10.280 --> 00:24:13.240]   and there are similar, like when they talk about
[00:24:13.240 --> 00:24:15.560]   the Google Play Store and revenue models,
[00:24:15.560 --> 00:24:18.120]   they also bring up the Apple.
[00:24:18.120 --> 00:24:20.400]   So there are places where it makes sense.
[00:24:20.400 --> 00:24:22.320]   But I think fundamentally,
[00:24:22.320 --> 00:24:24.600]   it's not like you're gonna apply one solution
[00:24:24.600 --> 00:24:26.160]   to all of these companies.
[00:24:26.160 --> 00:24:28.080]   So they do have recommendations.
[00:24:28.080 --> 00:24:29.600]   I'll jump ahead.
[00:24:29.600 --> 00:24:32.120]   There are several categories.
[00:24:32.120 --> 00:24:34.000]   One, restoring competition.
[00:24:34.000 --> 00:24:37.840]   They talk about structural separation,
[00:24:37.840 --> 00:24:40.000]   prohibitions of certain dominant platforms
[00:24:40.000 --> 00:24:42.720]   from operating in adjacent lines of business.
[00:24:42.720 --> 00:24:45.240]   That's an awful big bucket.
[00:24:45.240 --> 00:24:46.440]   Non-discrimination report.
[00:24:46.440 --> 00:24:48.400]   But we do that already in,
[00:24:48.400 --> 00:24:50.400]   like the FCC puts requirements
[00:24:50.400 --> 00:24:51.720]   for a certain number of years.
[00:24:51.720 --> 00:24:53.880]   And I did actually think about like some settings.
[00:24:53.880 --> 00:24:55.320]   I don't know what's on the same.
[00:24:55.320 --> 00:24:57.880]   It could be, I don't know what's gonna be underneath that.
[00:24:57.880 --> 00:24:59.720]   Non-discrimination.
[00:24:59.720 --> 00:25:02.600]   But that whole 'nother fight that we would have
[00:25:02.600 --> 00:25:03.600]   will last another second.
[00:25:03.600 --> 00:25:05.480]   I think actually this is fairly intelligent,
[00:25:05.480 --> 00:25:06.680]   but okay, I'll keep going.
[00:25:06.680 --> 00:25:09.600]   Non-discrimination requirements prohibiting dominant platforms
[00:25:09.600 --> 00:25:11.960]   from engaging in self-preferencing
[00:25:11.960 --> 00:25:14.000]   and requiring them to offer equal terms
[00:25:14.000 --> 00:25:15.240]   for equal products and service.
[00:25:15.240 --> 00:25:17.320]   Well, if we do, we're gonna take a four hour show
[00:25:17.320 --> 00:25:20.640]   'cause there's quite a few recommendations here.
[00:25:20.640 --> 00:25:24.960]   So let me just whizz through them here.
[00:25:24.960 --> 00:25:26.800]   So far, these make sense.
[00:25:26.800 --> 00:25:29.400]   Admittedly, it's not obvious how you do this,
[00:25:29.400 --> 00:25:31.880]   but I think this is, that's important.
[00:25:31.880 --> 00:25:33.560]   I think a reasonable person might say,
[00:25:33.560 --> 00:25:35.120]   yeah, that seems like a good idea.
[00:25:35.120 --> 00:25:37.560]   Interoperability, data portability.
[00:25:37.560 --> 00:25:42.080]   To make services compatible with networks.
[00:25:42.080 --> 00:25:45.280]   To make content information easily portable between them.
[00:25:45.280 --> 00:25:47.960]   A presumptive prohibition, this is tricky,
[00:25:47.960 --> 00:25:49.960]   against future mergers and acquisitions
[00:25:49.960 --> 00:25:51.960]   by the dominant platforms.
[00:25:51.960 --> 00:25:53.720]   Safe harbor for news publishers
[00:25:53.720 --> 00:25:55.960]   to safeguard a free and diverse press.
[00:25:55.960 --> 00:25:58.920]   This, this is library paying off.
[00:25:58.920 --> 00:26:00.440]   This is BS.
[00:26:00.440 --> 00:26:04.600]   This is my industry engaging in antitrust.
[00:26:04.600 --> 00:26:07.000]   It's BS, but keep going.
[00:26:07.000 --> 00:26:08.360]   Pro-abitions on a business.
[00:26:08.360 --> 00:26:09.800]   But the data, the data.
[00:26:09.800 --> 00:26:10.960]   Data portability.
[00:26:10.960 --> 00:26:11.800]   Good.
[00:26:11.800 --> 00:26:12.640]   Really good.
[00:26:12.640 --> 00:26:13.480]   I like that.
[00:26:13.480 --> 00:26:15.840]   How do you export a Facebook photo to TikTok?
[00:26:15.840 --> 00:26:18.920]   You know, there's a lot of definition to be done there.
[00:26:18.920 --> 00:26:20.080]   Well, you, so the idea of--
[00:26:20.080 --> 00:26:21.880]   By the way, this is not a list.
[00:26:21.880 --> 00:26:24.000]   This is not a list of prescription
[00:26:24.000 --> 00:26:25.760]   of what the committee wants to do.
[00:26:25.760 --> 00:26:30.760]   These are a set of reforms proposed for further examination.
[00:26:30.760 --> 00:26:35.360]   So for purposes of crafting legislative responses.
[00:26:35.360 --> 00:26:38.920]   So they're basically saying, we think now,
[00:26:38.920 --> 00:26:41.360]   the subcommittee needs to dig down on each of these
[00:26:41.360 --> 00:26:43.160]   and see what we can do about it
[00:26:43.160 --> 00:26:46.400]   and what kind of legislation we can talk about.
[00:26:46.400 --> 00:26:49.120]   We intend these recommendations to serve as a compliment
[00:26:49.120 --> 00:26:51.840]   to vigorous antitrust enforcement.
[00:26:51.840 --> 00:26:54.400]   So this is not the antitrust abortion.
[00:26:54.400 --> 00:26:55.560]   This is a set of reform.
[00:26:55.560 --> 00:26:56.400]   So in other words, this is a set of reform.
[00:26:56.400 --> 00:26:57.160]   What's you doing, Google?
[00:26:57.160 --> 00:26:59.560]   Well, there's also antitrust in here.
[00:26:59.560 --> 00:27:01.080]   That's later.
[00:27:01.080 --> 00:27:03.760]   Pro-abitions and abuses of superior bargaining power.
[00:27:03.760 --> 00:27:05.760]   These are all antitrust concepts, right?
[00:27:05.760 --> 00:27:07.600]   That's, that's, those law existing for that.
[00:27:07.600 --> 00:27:08.440]   Right.
[00:27:09.280 --> 00:27:11.440]   Then in strengthening the antitrust laws,
[00:27:11.440 --> 00:27:15.120]   'cause they did say the antitrust laws need some reworking.
[00:27:15.120 --> 00:27:17.480]   They wanna reassert the anti-monopoly goals
[00:27:17.480 --> 00:27:19.640]   of the antitrust laws and their centrality
[00:27:19.640 --> 00:27:23.160]   to ensuring a healthy and vibrant democracy.
[00:27:23.160 --> 00:27:24.000]   Strengthening--
[00:27:24.000 --> 00:27:25.280]   I think it's in the first amendment, but keep going.
[00:27:25.280 --> 00:27:26.280]   I understand, it's tricky.
[00:27:26.280 --> 00:27:27.480]   And I don't think that they imply
[00:27:27.480 --> 00:27:30.120]   that these are easily solved.
[00:27:30.120 --> 00:27:32.320]   They just say, this is something we ought to think about.
[00:27:32.320 --> 00:27:35.320]   Strengthening section seven of the Clayton Act,
[00:27:35.320 --> 00:27:38.960]   including through restoring presumptions of,
[00:27:38.960 --> 00:27:40.920]   I don't know what the Clayton Act is,
[00:27:40.920 --> 00:27:43.120]   so I'm just gonna stop right there.
[00:27:43.120 --> 00:27:44.760]   The Clayton antitrust act?
[00:27:44.760 --> 00:27:47.080]   Is that the fundamental, that Sherman--
[00:27:47.080 --> 00:27:49.320]   Clayton is, no, it's Sherman.
[00:27:49.320 --> 00:27:52.520]   Yeah, it was prior to the Sherman Act.
[00:27:52.520 --> 00:27:53.360]   Okay.
[00:27:53.360 --> 00:27:54.600]   Oh man, y'all are gonna--
[00:27:54.600 --> 00:27:55.620]   Recording with regard--
[00:27:55.620 --> 00:27:56.460]   No.
[00:27:56.460 --> 00:27:57.600]   Restoring the EPCP&C standard--
[00:27:57.600 --> 00:28:00.680]   19, 14, the Clayton antitrust act.
[00:28:00.680 --> 00:28:02.720]   Strengthening law of vertical mergers.
[00:28:02.720 --> 00:28:03.840]   Okay.
[00:28:03.840 --> 00:28:05.520]   They do suggest strengthening section two
[00:28:05.520 --> 00:28:09.360]   of the Sherman Act by introducing a prohibition
[00:28:09.360 --> 00:28:11.320]   of use of dominance.
[00:28:11.320 --> 00:28:13.840]   Y'all, this may come up.
[00:28:13.840 --> 00:28:17.040]   The Sherman Act declared monopolies illegal,
[00:28:17.040 --> 00:28:20.520]   but the Clayton Act defines prisoners' practices
[00:28:20.520 --> 00:28:23.640]   that are conducive to the formation of monopolies
[00:28:23.640 --> 00:28:25.920]   or the monopolies that result for them as illegal.
[00:28:25.920 --> 00:28:29.680]   They call that the restoring the EPCP&C standard
[00:28:29.680 --> 00:28:31.920]   and protecting nascent competitors.
[00:28:31.920 --> 00:28:32.760]   That's Clayton.
[00:28:32.760 --> 00:28:34.360]   We've seen a lot of that Clayton talk
[00:28:34.360 --> 00:28:36.520]   with all of these proposed bills,
[00:28:36.520 --> 00:28:39.680]   not bills, propositions for state of California.
[00:28:39.680 --> 00:28:41.720]   Oh yeah, that's in there.
[00:28:41.720 --> 00:28:43.720]   Great, gotta start studying.
[00:28:43.720 --> 00:28:47.360]   I like to add that Clayton talk.
[00:28:47.360 --> 00:28:49.360]   That Clayton talk is in here too.
[00:28:49.360 --> 00:28:51.280]   There's a lot of Clayton going on.
[00:28:51.280 --> 00:28:56.360]   Take, I don't like this one, taking additional measures
[00:28:56.360 --> 00:28:57.960]   to strengthen overall enforcement,
[00:28:57.960 --> 00:29:01.840]   including through overriding problematic precedents
[00:29:01.840 --> 00:29:02.920]   and the case law.
[00:29:02.920 --> 00:29:06.040]   I don't know about that.
[00:29:06.040 --> 00:29:07.560]   Reviving, in this section C,
[00:29:07.560 --> 00:29:09.960]   is reviving antitrust enforcement,
[00:29:09.960 --> 00:29:12.120]   which we probably do need to do.
[00:29:12.120 --> 00:29:14.400]   Restoring robust congressional oversight
[00:29:14.400 --> 00:29:16.920]   of the antitrust laws in their enforcement,
[00:29:16.920 --> 00:29:20.800]   restoring federal antitrust agencies to full strength
[00:29:20.800 --> 00:29:22.800]   and strengthening private enforcement.
[00:29:22.800 --> 00:29:23.640]   Yes, yes, yes, where that happened.
[00:29:23.640 --> 00:29:24.480]   Yeah.
[00:29:24.480 --> 00:29:29.120]   Yeah, I think this section has to do
[00:29:29.120 --> 00:29:31.360]   with kind of the erosion.
[00:29:31.360 --> 00:29:34.200]   And the abrogation, congressional abrogation
[00:29:34.200 --> 00:29:37.720]   of their duties and rights as Congress.
[00:29:37.720 --> 00:29:38.840]   Yeah.
[00:29:38.840 --> 00:29:39.840]   Yeah.
[00:29:39.840 --> 00:29:41.880]   And cutting out all regulation possible
[00:29:41.880 --> 00:29:42.800]   in the last three years.
[00:29:42.800 --> 00:29:43.560]   Yeah.
[00:29:43.560 --> 00:29:45.240]   Strengthening private enforcement,
[00:29:45.240 --> 00:29:46.560]   I don't even know what private enforcement is,
[00:29:46.560 --> 00:29:47.760]   through eliminating obstacles
[00:29:47.760 --> 00:29:50.560]   such as forced arbitration clauses.
[00:29:50.560 --> 00:29:53.600]   Those are those self-governing regulatory bodies
[00:29:53.600 --> 00:29:55.280]   that companies like to set up.
[00:29:55.280 --> 00:29:57.920]   Oh, like arbitration, okay.
[00:29:57.920 --> 00:29:59.880]   Limits on class and action formation.
[00:29:59.880 --> 00:30:02.960]   Oh, this is it, this one doesn't,
[00:30:02.960 --> 00:30:05.440]   one of these things is not like the other.
[00:30:05.440 --> 00:30:07.960]   Strengthening private enforcement,
[00:30:07.960 --> 00:30:09.520]   through eliminating obstacles,
[00:30:09.520 --> 00:30:13.600]   such as forced arbitration clauses,
[00:30:13.600 --> 00:30:17.400]   which by the way, we have forced arbitration clauses
[00:30:17.400 --> 00:30:22.160]   in our contracts, limits on class action formation.
[00:30:22.160 --> 00:30:23.880]   Juditionally creates standards,
[00:30:23.880 --> 00:30:27.080]   constraining what constitutes an antitrust injury
[00:30:27.080 --> 00:30:28.160]   and a duly high plead.
[00:30:28.160 --> 00:30:31.400]   This is lawyer talk on duly high pleading standards.
[00:30:31.400 --> 00:30:32.960]   Don't know about any of that stuff.
[00:30:32.960 --> 00:30:34.720]   That's right versus left about lawyers.
[00:30:34.720 --> 00:30:35.560]   Yeah, yeah.
[00:30:35.560 --> 00:30:36.400]   That's right.
[00:30:36.400 --> 00:30:37.760]   Yeah, that's any lawyer.
[00:30:37.760 --> 00:30:38.600]   Okay.
[00:30:38.600 --> 00:30:44.600]   I don't, I think this is as well-fied out as you could expect.
[00:30:44.600 --> 00:30:46.400]   Frankly, I think it's pretty good.
[00:30:46.400 --> 00:30:48.880]   I think A, it's not gonna happen
[00:30:48.880 --> 00:30:51.880]   because the Republicans have already pulled out.
[00:30:51.880 --> 00:30:53.880]   So we're just seeing a draft proposal,
[00:30:53.880 --> 00:30:54.720]   which is never gonna be.
[00:30:54.720 --> 00:30:56.880]   Well, if the Democrats end up in charge of everything,
[00:30:56.880 --> 00:30:59.640]   and this has become a blueprint for where it goes,
[00:30:59.640 --> 00:31:03.080]   but maybe that's the biggest takeaway from this.
[00:31:03.080 --> 00:31:05.760]   Here's a warning, if Democrats are elected,
[00:31:05.760 --> 00:31:07.440]   this is what's gonna happen.
[00:31:07.440 --> 00:31:08.760]   It's that one.
[00:31:08.760 --> 00:31:10.600]   Yeah, well, I think that's the case.
[00:31:10.600 --> 00:31:13.680]   And my, and this, I was part of a group
[00:31:13.680 --> 00:31:16.320]   that recommends a regulatory framework.
[00:31:16.320 --> 00:31:18.120]   My argument is that-
[00:31:18.120 --> 00:31:19.680]   Yeah, so you're not against that.
[00:31:19.680 --> 00:31:21.360]   You're not gonna rule by moral panic.
[00:31:21.360 --> 00:31:22.200]   Right.
[00:31:22.200 --> 00:31:23.040]   We'll get us in trouble.
[00:31:23.040 --> 00:31:23.880]   No, I agree.
[00:31:23.880 --> 00:31:26.280]   Because it will, that white balance is so different.
[00:31:26.280 --> 00:31:27.120]   Look at Ant.
[00:31:27.120 --> 00:31:30.040]   Ant's got a great, just permanent, like,
[00:31:30.040 --> 00:31:32.300]   (laughing)
[00:31:32.300 --> 00:31:35.480]   Oh, Ant in it.
[00:31:35.480 --> 00:31:37.680]   I thought not to do Ant's doing it.
[00:31:37.680 --> 00:31:38.520]   Yeah, yeah.
[00:31:38.520 --> 00:31:43.360]   Just blink it off and on, Ant, whenever he says it.
[00:31:43.360 --> 00:31:45.000]   (laughing)
[00:31:45.000 --> 00:31:45.840]   He's got a-
[00:31:45.840 --> 00:31:46.760]   Breaking game.
[00:31:46.760 --> 00:31:48.960]   So obviously, and this, you know this,
[00:31:48.960 --> 00:31:49.800]   and I don't-
[00:31:49.800 --> 00:31:52.480]   So you're not against, you're not against regulation.
[00:31:52.480 --> 00:31:53.320]   The internet.
[00:31:53.320 --> 00:31:55.400]   I'm not against a framework of sensible regulation.
[00:31:55.400 --> 00:31:56.240]   Yeah.
[00:31:56.240 --> 00:32:01.080]   My fear is that in the anger, emotional response,
[00:32:01.080 --> 00:32:02.520]   otherwise known as moral panic,
[00:32:02.520 --> 00:32:04.480]   and that's going on here,
[00:32:04.480 --> 00:32:08.720]   is that there's gonna be a lot of ancillary damage
[00:32:08.720 --> 00:32:10.400]   to freedom of expression.
[00:32:10.400 --> 00:32:12.080]   And the things that-
[00:32:12.080 --> 00:32:14.040]   Yes, they have to be done carefully.
[00:32:14.040 --> 00:32:15.040]   This is brain surgery.
[00:32:15.040 --> 00:32:16.280]   And I don't trust.
[00:32:16.280 --> 00:32:19.680]   And it'll be done poorly in some cases,
[00:32:19.680 --> 00:32:23.360]   and we will have to fix it through either further legislation
[00:32:23.360 --> 00:32:26.200]   or empowering a regulatory agency to make,
[00:32:26.200 --> 00:32:30.520]   you know, to dispense the rules in the right way
[00:32:30.520 --> 00:32:33.360]   or through lawsuits.
[00:32:33.360 --> 00:32:35.120]   Now I'm only on page 26.
[00:32:35.120 --> 00:32:36.840]   If you guys are gonna keep interrupting me,
[00:32:36.840 --> 00:32:39.400]   this is gonna take a long time.
[00:32:39.400 --> 00:32:40.240]   No, I'm just kidding.
[00:32:40.240 --> 00:32:41.320]   I'm just teasing.
[00:32:41.320 --> 00:32:42.160]   I think we've done that.
[00:32:42.160 --> 00:32:44.560]   We also look at the regulation to date in Europe,
[00:32:44.560 --> 00:32:45.960]   and I don't wanna get into all that,
[00:32:45.960 --> 00:32:49.000]   but I think I have a spiel, which I give as talks,
[00:32:49.000 --> 00:32:51.000]   where I go down everything that's happened so far,
[00:32:51.000 --> 00:32:53.600]   and what's wrong with it, and the unintended consequences,
[00:32:53.600 --> 00:32:57.080]   which include giving more power to the platforms,
[00:32:57.080 --> 00:32:59.760]   regulatory capture on behalf of the platforms,
[00:32:59.760 --> 00:33:03.280]   harming newcomers and smaller players
[00:33:03.280 --> 00:33:05.720]   because of the difficulty that the regulation creates.
[00:33:05.720 --> 00:33:08.040]   This is what's happened in Europe with this kind of regulation.
[00:33:08.040 --> 00:33:09.960]   And so be careful what you wish for,
[00:33:09.960 --> 00:33:11.920]   because what you might find is what's happened in Europe
[00:33:11.920 --> 00:33:13.960]   is that the platforms have become only more powerful.
[00:33:13.960 --> 00:33:16.480]   - I understand, but we also should not be knee-jerk
[00:33:16.480 --> 00:33:19.440]   in our rejection of thinking about this
[00:33:19.440 --> 00:33:21.120]   just because it can't jump off.
[00:33:21.120 --> 00:33:22.040]   - I've been two years on a commission
[00:33:22.040 --> 00:33:22.960]   coming up with an alternative.
[00:33:22.960 --> 00:33:24.560]   I'm not neat. - Right, good.
[00:33:24.560 --> 00:33:26.200]   All right, it just sounds like it.
[00:33:26.200 --> 00:33:29.120]   - I will have this always at the ready.
[00:33:29.120 --> 00:33:31.360]   (laughing)
[00:33:31.360 --> 00:33:34.400]   It's here, I'm warden yet, it's always gonna be here.
[00:33:34.400 --> 00:33:36.360]   - I like it.
[00:33:36.360 --> 00:33:38.720]   I kinda feel like we should get like a light bright version
[00:33:38.720 --> 00:33:40.040]   of the time for you.
[00:33:40.040 --> 00:33:42.040]   - Like OLD. - Ooh, I like that.
[00:33:42.040 --> 00:33:44.880]   - Oh, I have a grand final next week.
[00:33:44.880 --> 00:33:47.240]   Would you please, and it's gonna work on that.
[00:33:47.240 --> 00:33:48.360]   - Yeah.
[00:33:48.360 --> 00:33:51.840]   - Yeah, I mean, I completely concede all the issues
[00:33:51.840 --> 00:33:54.720]   with having this go through government, you know,
[00:33:54.720 --> 00:33:56.200]   and so forth, but what?
[00:33:56.200 --> 00:33:58.360]   - And I also concede all the issues that these companies,
[00:33:58.360 --> 00:33:59.840]   I think they're different.
[00:33:59.840 --> 00:34:03.640]   I think Facebook has been screwing up over and over and over again.
[00:34:03.640 --> 00:34:07.440]   Google has been screwing up less, but has a lot of hubris.
[00:34:07.440 --> 00:34:10.040]   Twitter is trying, but it's a small beast.
[00:34:10.040 --> 00:34:12.440]   I think Apple has incredible hubris.
[00:34:12.440 --> 00:34:14.560]   Amazon has incredible hubris.
[00:34:14.560 --> 00:34:16.360]   None of them is helping themselves.
[00:34:16.360 --> 00:34:17.520]   - I do think there's a difference.
[00:34:17.520 --> 00:34:22.200]   The damage Apple can do is limited to people who want iPhones.
[00:34:22.200 --> 00:34:23.040]   It's like--
[00:34:23.040 --> 00:34:25.240]   - Well, in Apple, there's a marketplace there.
[00:34:25.240 --> 00:34:26.760]   - It's not secret.
[00:34:26.760 --> 00:34:29.600]   But Apple's also very upfront.
[00:34:29.600 --> 00:34:31.720]   It is getting a little overbearing
[00:34:31.720 --> 00:34:33.240]   and how it enforces the rules,
[00:34:33.240 --> 00:34:35.160]   but Apple's been very upfront about,
[00:34:35.160 --> 00:34:37.520]   yes, we have made a beautiful walled garden.
[00:34:37.520 --> 00:34:40.320]   You will come inside, and if you leave it, you will be sad.
[00:34:40.320 --> 00:34:44.440]   - And you can leave it because there's another garden.
[00:34:44.440 --> 00:34:45.280]   Right.
[00:34:45.280 --> 00:34:46.120]   - Yeah, but we may--
[00:34:46.120 --> 00:34:47.240]   - But we may have a house there as an anti-dross,
[00:34:47.240 --> 00:34:48.080]   because there's a choice.
[00:34:48.080 --> 00:34:51.320]   - But to say that, for instance, you can leave Google
[00:34:51.320 --> 00:34:54.480]   because, well, there's always Bing or DuckDuckGo,
[00:34:54.480 --> 00:34:58.920]   which is Bing, by the way, isn't really--
[00:34:58.920 --> 00:34:59.920]   - You'll just worry about it, you gotta run.
[00:34:59.920 --> 00:35:01.960]   - For a searcher, you can.
[00:35:01.960 --> 00:35:03.200]   You'll get the same results.
[00:35:03.200 --> 00:35:05.520]   For an advertiser, that's different.
[00:35:05.520 --> 00:35:06.840]   So I think you're looking at the wrong end.
[00:35:06.840 --> 00:35:09.880]   - Have you used DuckDuckGo for any length of time or Bing?
[00:35:09.880 --> 00:35:11.440]   - I have.
[00:35:11.440 --> 00:35:12.280]   - Well--
[00:35:12.280 --> 00:35:13.120]   - I have this DuckDuckGo.
[00:35:13.120 --> 00:35:14.720]   It's not as good.
[00:35:14.720 --> 00:35:16.280]   So I don't think the search issue--
[00:35:16.280 --> 00:35:18.640]   - So I think people can use search.
[00:35:18.640 --> 00:35:22.000]   I do think it's very difficult, though,
[00:35:22.000 --> 00:35:23.680]   if you're not an Apple user,
[00:35:23.680 --> 00:35:25.920]   you're gonna be on Google's ecosystem.
[00:35:25.920 --> 00:35:28.520]   And I would also say if you are--
[00:35:28.520 --> 00:35:29.960]   - So it's really a two-wobly.
[00:35:29.960 --> 00:35:30.800]   - Or business.
[00:35:30.800 --> 00:35:31.640]   - Is what you're saying.
[00:35:31.640 --> 00:35:32.680]   - Yeah, and if you are a business,
[00:35:32.680 --> 00:35:36.080]   you are going to have to advertise with Google.
[00:35:36.080 --> 00:35:38.160]   No ifs, ands, or buts about it.
[00:35:38.160 --> 00:35:39.680]   - Google and/or Facebook.
[00:35:39.680 --> 00:35:43.080]   But that means there is competition.
[00:35:43.080 --> 00:35:44.760]   It's a two-wobly, but there is competition.
[00:35:44.760 --> 00:35:47.840]   - And as you're in programmatic--
[00:35:47.840 --> 00:35:48.680]   - Hold on, hold on.
[00:35:48.680 --> 00:35:50.560]   - Go ahead, Stacy.
[00:35:50.560 --> 00:35:51.400]   - Yeah.
[00:35:51.400 --> 00:35:53.200]   No, if you're programmatic advertising,
[00:35:53.200 --> 00:35:55.120]   you've only got Google.
[00:35:55.120 --> 00:35:56.520]   - Is that true? You can't.
[00:35:56.520 --> 00:35:57.360]   - There's no--
[00:35:57.360 --> 00:35:58.360]   - Well, no, you've got AppNexus,
[00:35:58.360 --> 00:35:59.360]   you've got others, but Stacy,
[00:35:59.360 --> 00:36:01.080]   the difference I would say there,
[00:36:01.080 --> 00:36:02.880]   there's advertising on Google,
[00:36:02.880 --> 00:36:04.800]   with Google, to Google Properties.
[00:36:04.800 --> 00:36:06.280]   That's one, right?
[00:36:06.280 --> 00:36:08.440]   Then there's advertising across the whole web
[00:36:08.440 --> 00:36:09.920]   through programmatic.
[00:36:09.920 --> 00:36:11.360]   A lot of that goes through Google,
[00:36:11.360 --> 00:36:12.280]   not everything does.
[00:36:12.280 --> 00:36:13.360]   You don't have to go through Google,
[00:36:13.360 --> 00:36:14.800]   you can be on AppNexus,
[00:36:14.800 --> 00:36:18.840]   and you still compete with others in that field.
[00:36:18.840 --> 00:36:20.480]   Having said all that,
[00:36:20.480 --> 00:36:22.320]   yes, in advertising, Leo,
[00:36:22.320 --> 00:36:24.160]   this is where we would actually agree here.
[00:36:24.160 --> 00:36:27.440]   In advertising, there is an antitrust issue with Google.
[00:36:27.440 --> 00:36:30.320]   It's not in search, it's in advertising.
[00:36:30.320 --> 00:36:32.160]   Where they have, but it's not,
[00:36:32.160 --> 00:36:33.640]   I don't know that it's legally a monopoly.
[00:36:33.640 --> 00:36:35.360]   This is where, hello, my friend Benedict Evans
[00:36:35.360 --> 00:36:38.000]   is gonna come in and explain this for you.
[00:36:38.000 --> 00:36:40.520]   But the advertising piece that Stacy's concentrating on
[00:36:40.520 --> 00:36:41.600]   is the right place to--
[00:36:41.600 --> 00:36:43.400]   Let's not be pedantic.
[00:36:43.400 --> 00:36:45.840]   Okay, it's not, doesn't say perhaps,
[00:36:45.840 --> 00:36:50.280]   perhaps match the standard of Clayton or Sherman.
[00:36:50.280 --> 00:36:52.280]   But I understand.
[00:36:52.280 --> 00:36:53.120]   That's all.
[00:36:53.120 --> 00:36:54.800]   But I understand.
[00:36:54.800 --> 00:36:55.640]   But there is a,
[00:36:55.640 --> 00:36:58.920]   do you not agree that there is a concentration of power
[00:36:58.920 --> 00:37:01.200]   and as a result, a problem?
[00:37:01.200 --> 00:37:03.760]   I think that there does need to be,
[00:37:03.760 --> 00:37:06.000]   especially in advertising,
[00:37:06.000 --> 00:37:10.840]   a structure of, at least to start off with accountability
[00:37:10.840 --> 00:37:12.680]   and oversight.
[00:37:12.680 --> 00:37:16.240]   All right, I don't, I think it is far too soon to say,
[00:37:16.240 --> 00:37:19.400]   break 'em up 'cause it's not an accomplished damn thing.
[00:37:19.400 --> 00:37:21.360]   But I do think that we need,
[00:37:21.360 --> 00:37:22.880]   this is the argument of the,
[00:37:22.880 --> 00:37:24.920]   again, my commission that I was on
[00:37:24.920 --> 00:37:26.360]   was only about content moderation,
[00:37:26.360 --> 00:37:28.760]   but it cuts across other areas too.
[00:37:28.760 --> 00:37:31.040]   Is there need to be regulations?
[00:37:31.040 --> 00:37:33.320]   There needs to be promises that companies make
[00:37:33.320 --> 00:37:34.760]   and they need to be held accountable to that
[00:37:34.760 --> 00:37:36.680]   and to do that, they have to give data
[00:37:36.680 --> 00:37:37.800]   to government and researchers
[00:37:37.800 --> 00:37:40.800]   so that we can see what the actual thing is.
[00:37:40.800 --> 00:37:42.400]   I mean, there was a lot of presumption in this country
[00:37:42.400 --> 00:37:45.240]   that, oh my God, filter bubbles are ruining us.
[00:37:45.240 --> 00:37:47.480]   It's miserable, it's horrible.
[00:37:47.480 --> 00:37:51.560]   From 2001 on through 2011,
[00:37:51.560 --> 00:37:53.200]   filter bubbles, filter bubbles, filter bubbles, right?
[00:37:53.200 --> 00:37:55.040]   Well, I recommend to you the book
[00:37:55.040 --> 00:37:57.280]   by Axel Brun's Academic Art Filter Bubbles,
[00:37:57.280 --> 00:37:58.840]   real in which he has all the research saying,
[00:37:58.840 --> 00:38:01.680]   actually they're not 'cause there was a presumption there.
[00:38:01.680 --> 00:38:03.040]   We need data.
[00:38:03.040 --> 00:38:04.720]   We don't have data from the companies.
[00:38:04.720 --> 00:38:07.320]   I do want oversight with data from the companies
[00:38:07.320 --> 00:38:10.600]   and then out of that comes sensible regulation
[00:38:10.600 --> 00:38:11.440]   and legislation.
[00:38:11.440 --> 00:38:14.800]   Right now it's being made on an emotional basis.
[00:38:14.800 --> 00:38:15.960]   They could do something bad.
[00:38:15.960 --> 00:38:18.000]   - I don't agree 100%. - I disagree 100%.
[00:38:18.000 --> 00:38:20.920]   This report is very, very precise.
[00:38:20.920 --> 00:38:23.400]   You gotta read the report, Jeff, before you say that.
[00:38:23.400 --> 00:38:27.040]   This report is very precise and very detailed
[00:38:27.040 --> 00:38:30.920]   and goes into a lot of, I think, very strong evidence.
[00:38:30.920 --> 00:38:34.320]   - And I also wanna bring up that idea
[00:38:34.320 --> 00:38:36.800]   'cause the report actually does a lot with this
[00:38:36.800 --> 00:38:39.760]   is the idea of how network effects,
[00:38:39.760 --> 00:38:42.640]   which are a viable and real proven thing
[00:38:42.640 --> 00:38:45.320]   in social networks and the way we,
[00:38:45.320 --> 00:38:48.280]   it's not just social networks,
[00:38:48.280 --> 00:38:50.240]   but it's, well, it is social in the sense
[00:38:50.240 --> 00:38:51.960]   if you think of texting and things like that
[00:38:51.960 --> 00:38:53.280]   as social networks too.
[00:38:53.280 --> 00:38:55.960]   And this report does a pretty good job
[00:38:55.960 --> 00:38:59.960]   of talking about the, like, using network effects
[00:38:59.960 --> 00:39:04.160]   as they say, a flywheel to get more users
[00:39:04.160 --> 00:39:09.160]   and thus broaden your power in the advertising market.
[00:39:09.640 --> 00:39:14.360]   So I actually, I think, Jeff, it would be really interesting
[00:39:14.360 --> 00:39:16.800]   to, like, read up a little bit more on that
[00:39:16.800 --> 00:39:17.880]   and get your thoughts on that
[00:39:17.880 --> 00:39:19.240]   because I know we talk about--
[00:39:19.240 --> 00:39:22.120]   - I started, I just had Zoom calls last night.
[00:39:22.120 --> 00:39:23.960]   - Yeah, no, I'm just thinking about,
[00:39:23.960 --> 00:39:26.200]   we don't actually talk about that a lot
[00:39:26.200 --> 00:39:27.560]   when we talk about Monopoly
[00:39:27.560 --> 00:39:29.960]   'cause I know you're an ardent supporter
[00:39:29.960 --> 00:39:33.520]   of first amendment rights and press freedom,
[00:39:33.520 --> 00:39:36.200]   but I do think there is a there there
[00:39:36.200 --> 00:39:40.400]   in terms of how we take advantage of network effects
[00:39:40.400 --> 00:39:43.080]   and then going forward, I think what's gonna be really
[00:39:43.080 --> 00:39:45.520]   interesting is how we use and aggregate data
[00:39:45.520 --> 00:39:48.920]   within our walled gardens to build services
[00:39:48.920 --> 00:39:53.080]   that further lock people, not lock people,
[00:39:53.080 --> 00:39:56.040]   they just make it much more enticing not to leave,
[00:39:56.040 --> 00:39:58.920]   but competitors can't build those services.
[00:39:58.920 --> 00:40:02.560]   In the question, then, we can't actually measure harm
[00:40:02.560 --> 00:40:04.960]   to a consumer because when we talk about harm
[00:40:04.960 --> 00:40:06.760]   to a consumer in antitrust,
[00:40:06.760 --> 00:40:08.560]   we usually talk about pricing,
[00:40:08.560 --> 00:40:13.080]   but right now, nobody in this market charges consumers.
[00:40:13.080 --> 00:40:16.640]   Okay, not nobody, but that's kind of a thing
[00:40:16.640 --> 00:40:18.400]   that we don't really talk a lot about,
[00:40:18.400 --> 00:40:23.360]   but changing how we think about antitrust
[00:40:23.360 --> 00:40:25.960]   is not a crazy thing to do here,
[00:40:25.960 --> 00:40:28.560]   especially because we're moving more towards
[00:40:28.560 --> 00:40:32.920]   a data exchange economy in some of these areas.
[00:40:32.920 --> 00:40:34.760]   But here's not a consequence, Stacy.
[00:40:34.760 --> 00:40:37.560]   Right, and I think that's a good analysis,
[00:40:37.560 --> 00:40:39.320]   but to look at it at the consequences,
[00:40:39.320 --> 00:40:41.400]   and this is part of the discussion I had on Twitter today,
[00:40:41.400 --> 00:40:46.400]   is in demonizing the cookie and getting rid
[00:40:46.400 --> 00:40:48.680]   of third party cookies because they were misused,
[00:40:48.680 --> 00:40:49.720]   they were spaced, screwed it up,
[00:40:49.720 --> 00:40:52.120]   I'm not arguing that, but in getting rid of that,
[00:40:52.120 --> 00:40:53.760]   what you're gonna see more and more and more and more
[00:40:53.760 --> 00:40:56.280]   is journalism and media will go behind pay walls.
[00:40:56.280 --> 00:41:00.280]   And that means that it's redlined for the privileged.
[00:41:00.280 --> 00:41:02.320]   And as much as advertising,
[00:41:02.320 --> 00:41:04.320]   I have problems with the way it operates, right?
[00:41:04.320 --> 00:41:07.720]   So there's gonna be unintended consequences that require,
[00:41:07.720 --> 00:41:10.960]   and same as as happened with regulation in Europe.
[00:41:10.960 --> 00:41:14.520]   So that's my concern is that we're gonna find ourselves
[00:41:14.520 --> 00:41:17.320]   where, look at the Australian law,
[00:41:17.320 --> 00:41:19.640]   where Merck just suddenly is not the one done.
[00:41:19.640 --> 00:41:21.720]   Merck suddenly has changed it too, not only.
[00:41:21.720 --> 00:41:24.320]   Text fine, 'cause text pay in me.
[00:41:24.320 --> 00:41:26.560]   So all the things that he had a principled stand on
[00:41:26.560 --> 00:41:28.960]   as tech is awful, he was bing, he was bribing him.
[00:41:28.960 --> 00:41:31.440]   He was using his political clout to get all the storm going.
[00:41:31.440 --> 00:41:34.440]   It worked, he's getting paid, he's gonna shut up now.
[00:41:34.440 --> 00:41:37.840]   And the cynicism that's behind that is an issue,
[00:41:37.840 --> 00:41:39.160]   'cause it's gonna have unintended consequences
[00:41:39.160 --> 00:41:40.720]   and it's gonna have regulatory capture
[00:41:40.720 --> 00:41:42.000]   to enable people like Rupert Murdoch
[00:41:42.000 --> 00:41:43.720]   to get more powerful than even they are today.
[00:41:43.720 --> 00:41:48.480]   - Well, it's a legit fear, but there is always,
[00:41:48.480 --> 00:41:52.480]   having covered politics in policy rather, not politics,
[00:41:52.480 --> 00:41:54.600]   policy for 20 years now,
[00:41:54.600 --> 00:41:57.880]   there are always unintended consequences.
[00:41:57.880 --> 00:42:00.560]   There is always going to be an adjustment period
[00:42:00.560 --> 00:42:03.080]   where, and then we move to regulatory capture.
[00:42:03.080 --> 00:42:08.080]   We are there, like, we are there post the bells
[00:42:08.080 --> 00:42:11.160]   in the bells right now, or sorry, with AT&T
[00:42:11.160 --> 00:42:14.080]   in the telcos right now.
[00:42:14.080 --> 00:42:16.080]   (laughs)
[00:42:16.080 --> 00:42:18.560]   I did, I mean, everyone knows, you know,
[00:42:18.560 --> 00:42:20.360]   - That's the classic case. - Pretty clear how old I am.
[00:42:20.360 --> 00:42:24.640]   - Yeah. - But, so I think,
[00:42:26.000 --> 00:42:29.160]   to say we have to keep things going the way,
[00:42:29.160 --> 00:42:32.240]   and we said this before, to say we go this way
[00:42:32.240 --> 00:42:35.920]   because we're afraid of unintended consequences is stupid.
[00:42:35.920 --> 00:42:39.200]   We know that there are, we know that there are-
[00:42:39.200 --> 00:42:40.520]   - I think you didn't wanna use that one,
[00:42:40.520 --> 00:42:42.640]   - What I just said, did you?
[00:42:42.640 --> 00:42:43.760]   - What?
[00:42:43.760 --> 00:42:45.880]   - You really wanna call what I said stupid?
[00:42:45.880 --> 00:42:49.960]   Wait.
[00:42:49.960 --> 00:42:51.120]   - How about reductions? - To say,
[00:42:51.120 --> 00:42:52.560]   to use that as our basis for-
[00:42:52.560 --> 00:42:53.400]   - How about reductions?
[00:42:53.400 --> 00:42:54.760]   (laughs)
[00:42:54.760 --> 00:42:58.200]   - Just to use that as the basis for not doing anything.
[00:42:58.200 --> 00:43:00.640]   We know you will always be unintended.
[00:43:00.640 --> 00:43:02.880]   - On page 399.
[00:43:02.880 --> 00:43:04.720]   (laughs)
[00:43:04.720 --> 00:43:05.880]   - You got a hit, really.
[00:43:05.880 --> 00:43:07.880]   - Good, we're almost there.
[00:43:07.880 --> 00:43:09.840]   We're almost there.
[00:43:09.840 --> 00:43:12.240]   - Well, a lot of what goes on in this report,
[00:43:12.240 --> 00:43:13.520]   I think it's quite interesting,
[00:43:13.520 --> 00:43:17.160]   the staff is saying to Congress and to the subcommittee,
[00:43:17.160 --> 00:43:20.080]   we need to make some adjustments.
[00:43:20.080 --> 00:43:23.400]   The courts have significantly undermined antitrust law
[00:43:23.400 --> 00:43:24.640]   and its original intent.
[00:43:24.640 --> 00:43:29.640]   And so we propose that you make laws to overcome
[00:43:29.640 --> 00:43:33.960]   what we consider mistaken court rulings.
[00:43:33.960 --> 00:43:35.920]   They also, I love this line in here,
[00:43:35.920 --> 00:43:38.000]   and it kind of goes to what you guys are saying,
[00:43:38.000 --> 00:43:40.720]   clarifying that false positives,
[00:43:40.720 --> 00:43:43.400]   in other words, erroneous enforcement,
[00:43:43.400 --> 00:43:46.760]   erroneous enforcement is not more costly
[00:43:46.760 --> 00:43:51.560]   than false negatives, erroneous non-enforcement.
[00:43:51.560 --> 00:43:52.400]   - Yes.
[00:43:52.400 --> 00:43:55.920]   - And when relating to conduct or mergers
[00:43:55.920 --> 00:43:57.920]   involving dominant firms,
[00:43:57.920 --> 00:44:02.520]   in fact, non-enforcement is costlier.
[00:44:02.520 --> 00:44:06.040]   So they are very much aware of the arguments
[00:44:06.040 --> 00:44:08.160]   that we are having here.
[00:44:08.160 --> 00:44:09.600]   And I think-- - Well, on that, Leo.
[00:44:09.600 --> 00:44:10.520]   - Yeah.
[00:44:10.520 --> 00:44:14.280]   - The only thing I would say is then treat that generically.
[00:44:14.280 --> 00:44:16.200]   Say if we've got a problem in antitrust in this company,
[00:44:16.200 --> 00:44:18.240]   then deal with it in antitrust at a large level.
[00:44:18.240 --> 00:44:20.440]   To say we're gonna deal with this only in the context
[00:44:20.440 --> 00:44:22.720]   of four companies is also--
[00:44:22.720 --> 00:44:23.560]   - I agree.
[00:44:23.560 --> 00:44:24.400]   - Reductionists.
[00:44:24.400 --> 00:44:25.240]   - I agree.
[00:44:25.240 --> 00:44:27.120]   I think these, and especially since the cases
[00:44:27.120 --> 00:44:28.120]   are different in each company.
[00:44:28.120 --> 00:44:29.440]   - My new word for stupid.
[00:44:29.440 --> 00:44:31.080]   (laughing)
[00:44:31.080 --> 00:44:32.160]   - I'm sorry.
[00:44:32.160 --> 00:44:33.160]   - It's a good word.
[00:44:33.160 --> 00:44:34.000]   - I could not use stupid.
[00:44:34.000 --> 00:44:34.840]   - No, no, no, no, no.
[00:44:34.840 --> 00:44:35.680]   - Reductionist.
[00:44:35.680 --> 00:44:39.400]   It's a subtle, it's kind of, it throws a little shade,
[00:44:39.400 --> 00:44:40.960]   but it's kind of like sub-tweeting.
[00:44:40.960 --> 00:44:42.160]   It's like a subtle--
[00:44:42.160 --> 00:44:44.000]   - I was, I was just--
[00:44:44.000 --> 00:44:45.640]   (laughing)
[00:44:45.640 --> 00:44:47.000]   - Really tired, but also--
[00:44:47.000 --> 00:44:47.840]   - I think I understand that.
[00:44:47.840 --> 00:44:49.240]   - Well, think you're stupid, chef.
[00:44:49.240 --> 00:44:51.400]   - No, obviously, Jeff's not stupid,
[00:44:51.400 --> 00:44:54.040]   although he's a little bit of a broken record
[00:44:54.040 --> 00:44:55.040]   on this subject.
[00:44:55.040 --> 00:44:57.280]   - Because you are, I've got to meet your broken record
[00:44:57.280 --> 00:44:58.200]   with my broken record.
[00:44:58.200 --> 00:45:00.080]   (laughing)
[00:45:00.080 --> 00:45:03.840]   - I do think, I have to say, having gone through this,
[00:45:03.840 --> 00:45:06.640]   it's an impressive document that addresses
[00:45:06.640 --> 00:45:08.480]   a lot of the things we're talking about,
[00:45:08.480 --> 00:45:11.080]   does not assume, all right, it's time,
[00:45:11.080 --> 00:45:12.760]   you bring down the hammer,
[00:45:12.760 --> 00:45:15.080]   but says in a very thoughtful way,
[00:45:15.080 --> 00:45:16.960]   there are some issues that we should think about.
[00:45:16.960 --> 00:45:21.960]   One of which is that the courts have effectively undermined
[00:45:21.960 --> 00:45:27.160]   the original intent of antitrust legislation.
[00:45:27.160 --> 00:45:29.080]   - Yeah, that's a huge issue,
[00:45:29.080 --> 00:45:30.800]   but that's apart from these companies.
[00:45:30.800 --> 00:45:32.720]   - Well, maybe it's apart from these companies,
[00:45:32.720 --> 00:45:36.280]   but it is restore the anti-monopoly goals
[00:45:36.280 --> 00:45:37.120]   of antitrust laws.
[00:45:37.120 --> 00:45:40.120]   I take you to page 391, section one.
[00:45:40.120 --> 00:45:41.320]   (laughing)
[00:45:41.320 --> 00:45:44.600]   Section one, the antitrust laws that Congress enacted
[00:45:44.600 --> 00:45:49.120]   in 1890 and 1914, that's Sherman Clayton and the FTC Act,
[00:45:49.120 --> 00:45:52.960]   reflected a recognition that unchecked monopoly power
[00:45:52.960 --> 00:45:54.600]   poses a threat to our economy,
[00:45:54.600 --> 00:45:56.880]   as well as to our democracy.
[00:45:56.880 --> 00:45:58.960]   And then Congress reasserted this vision
[00:45:58.960 --> 00:46:01.320]   through subsequent antitrust laws
[00:46:01.320 --> 00:46:02.920]   like the Hart Scott Rodino Act
[00:46:02.920 --> 00:46:04.440]   and the Robinson-Patman Act
[00:46:04.440 --> 00:46:06.960]   and the seller keyfauver act anyway,
[00:46:06.960 --> 00:46:08.880]   I can go on and on with the acts.
[00:46:08.880 --> 00:46:11.040]   In the decades since, Congress enacted
[00:46:11.040 --> 00:46:12.920]   these foundational statutes,
[00:46:12.920 --> 00:46:15.960]   the courts have significantly weakened these laws
[00:46:15.960 --> 00:46:18.080]   and made it increasingly difficult
[00:46:18.080 --> 00:46:19.880]   for federal antitrust enforcers
[00:46:19.880 --> 00:46:22.360]   and private plaintiffs to successfully challenge
[00:46:22.360 --> 00:46:24.400]   any competitive conduct and mergers.
[00:46:24.400 --> 00:46:29.120]   So what in a way they're saying is a much larger proposition
[00:46:29.120 --> 00:46:32.680]   that before we even address Facebook, Google, Apple
[00:46:32.680 --> 00:46:35.520]   and Amazon, what we really need to address
[00:46:35.520 --> 00:46:37.320]   is the tenor in this country,
[00:46:37.320 --> 00:46:41.160]   especially fostered by the courts,
[00:46:41.160 --> 00:46:44.400]   but I think also by the executive branch
[00:46:44.400 --> 00:46:48.280]   that we shouldn't leave that alone, let it go, let it be.
[00:46:48.280 --> 00:46:50.400]   Now of course that's why this is a democratic report
[00:46:50.400 --> 00:46:52.400]   and I guarantee you it's that paragraph right there
[00:46:52.400 --> 00:46:54.340]   that stopped the Republicans cold,
[00:46:54.340 --> 00:46:56.960]   but that's what Congress does.
[00:46:56.960 --> 00:47:00.280]   Congress can say that's the one branch of the government
[00:47:00.280 --> 00:47:02.640]   that can say, you know what, the courts made a mistake here.
[00:47:02.640 --> 00:47:04.920]   And even though there's a judicial precedent,
[00:47:04.920 --> 00:47:06.080]   that's not our intent.
[00:47:06.080 --> 00:47:08.240]   So we're going to be more specific
[00:47:08.240 --> 00:47:12.440]   because our intent was to prevent this concentration,
[00:47:12.440 --> 00:47:15.000]   this unchecked concentration of power.
[00:47:15.000 --> 00:47:16.520]   And I think that that's appropriate.
[00:47:16.520 --> 00:47:17.360]   I don't think that's inappropriate.
[00:47:17.360 --> 00:47:19.140]   And the courts are going to work in over the long
[00:47:19.140 --> 00:47:20.200]   generations.
[00:47:20.200 --> 00:47:21.640]   They can do that, but it's harder.
[00:47:21.640 --> 00:47:22.480]   That's the cycle we're on.
[00:47:22.480 --> 00:47:23.840]   That's the cycle, yeah.
[00:47:23.840 --> 00:47:24.680]   That's, yeah.
[00:47:24.680 --> 00:47:28.440]   'Cause like 120 years ago, we had the type of income
[00:47:28.440 --> 00:47:29.840]   inequality we had now.
[00:47:29.840 --> 00:47:32.080]   That's kind of what led to these was the robber
[00:47:32.080 --> 00:47:35.040]   variants of the late 1800s.
[00:47:35.040 --> 00:47:40.040]   And so we have some of these similar things happening.
[00:47:40.040 --> 00:47:44.760]   So maybe this is that backlash that leads to that.
[00:47:44.760 --> 00:47:45.600]   And boom.
[00:47:45.600 --> 00:47:46.600]   I think in a way, that's what they're saying.
[00:47:46.600 --> 00:47:49.160]   The pendulum has swung in the wrong direction.
[00:47:49.160 --> 00:47:50.560]   We want to bring it back.
[00:47:50.560 --> 00:47:53.400]   Because, and I, now here's the question.
[00:47:53.400 --> 00:47:56.080]   I don't think you would disagree with this, Jeff.
[00:47:56.080 --> 00:47:58.880]   It is possible for companies to have too much power.
[00:47:58.880 --> 00:48:02.640]   Not necessarily a monopoly in the sense that we--
[00:48:02.640 --> 00:48:04.200]   Define it for me in the statutes,
[00:48:04.200 --> 00:48:05.400]   what I'm asking for.
[00:48:05.400 --> 00:48:07.720]   Rather than an emotional view of their too big,
[00:48:07.720 --> 00:48:08.960]   which is much power, that's meaningless.
[00:48:08.960 --> 00:48:11.440]   Define for me and for them.
[00:48:11.440 --> 00:48:13.200]   But that's where we get our laws from,
[00:48:13.200 --> 00:48:15.240]   is these emotional things.
[00:48:15.240 --> 00:48:16.920]   And then we've billed statues.
[00:48:16.920 --> 00:48:20.040]   And I think what Leo's trying to say here is that maybe
[00:48:20.040 --> 00:48:22.760]   it's time and part of this report might be bringing up
[00:48:22.760 --> 00:48:25.840]   is it's time to reevaluate antitrust for the era
[00:48:25.840 --> 00:48:26.680]   that we're currently living in.
[00:48:26.680 --> 00:48:27.520]   I'm not working with that,
[00:48:27.520 --> 00:48:30.320]   but I would not do it against four companies alone.
[00:48:30.320 --> 00:48:31.520]   No, and that's perhaps--
[00:48:31.520 --> 00:48:34.800]   They just have two different reports.
[00:48:34.800 --> 00:48:38.560]   If they do a law, they're using this as an example.
[00:48:38.560 --> 00:48:40.080]   In any time you billed these,
[00:48:40.080 --> 00:48:43.480]   any time Congress writes laws, I guarantee you,
[00:48:43.480 --> 00:48:46.520]   there are companies, the hullabaloo
[00:48:46.520 --> 00:48:48.120]   and the comment periods here are going to be,
[00:48:48.120 --> 00:48:49.440]   there are going to be parts of the law
[00:48:49.440 --> 00:48:52.520]   that are going to be written only for like two companies.
[00:48:52.520 --> 00:48:55.440]   Because that's the way we do things in the US.
[00:48:55.440 --> 00:48:58.640]   But, it won't be just for these.
[00:48:58.640 --> 00:49:01.160]   It will be for, especially if they do things
[00:49:01.160 --> 00:49:05.760]   like data portability and they address the effects
[00:49:05.760 --> 00:49:07.720]   that are trying to mitigate network effects.
[00:49:07.720 --> 00:49:12.800]   I mean, all of these things, yeah, we need to do something there.
[00:49:12.800 --> 00:49:17.360]   But said, I agree with the chairman that Big Tech has
[00:49:17.360 --> 00:49:20.760]   acted anti-competitively, but with a problem
[00:49:20.760 --> 00:49:25.160]   is significant, there are a variety of legislative options.
[00:49:25.160 --> 00:49:26.680]   And I think ultimately you're not going
[00:49:26.680 --> 00:49:28.760]   to get Republican sign off on this.
[00:49:28.760 --> 00:49:32.560]   And so, I think the Department of Justice
[00:49:32.560 --> 00:49:34.760]   has been kind of waiting for this report.
[00:49:34.760 --> 00:49:38.520]   They keep saying, any day now we're going to come after Google,
[00:49:38.520 --> 00:49:40.600]   remember they've been saying that for three weeks,
[00:49:40.600 --> 00:49:42.120]   it's going to be this week, it's going to be this week.
[00:49:42.120 --> 00:49:43.920]   I think they were waiting for their support.
[00:49:43.920 --> 00:49:46.360]   And now, unfortunately, they're frozen in aspect
[00:49:46.360 --> 00:49:49.840]   because there's even within this committee,
[00:49:49.840 --> 00:49:52.520]   there's a market disagreement.
[00:49:52.520 --> 00:49:55.720]   So, and some of it's from Jim Jordan,
[00:49:55.720 --> 00:50:00.360]   who's the tip top Republican on the committee.
[00:50:00.360 --> 00:50:05.240]   You remember how he almost derailed the testimony of the--
[00:50:05.240 --> 00:50:07.640]   Yeah, I think I just heard him trying to cut you off right now.
[00:50:07.640 --> 00:50:08.640]   Yeah.
[00:50:08.640 --> 00:50:09.640]   [LAUGHTER]
[00:50:09.640 --> 00:50:13.480]   But you're jacking on, put your mask on.
[00:50:13.480 --> 00:50:20.440]   So, Jordan says he's not going to sign out of the report.
[00:50:20.440 --> 00:50:25.160]   Bucks shared that third way draft.
[00:50:25.160 --> 00:50:28.200]   But Jordan said, we don't have anything to do with the third way.
[00:50:28.200 --> 00:50:28.960]   And that's--
[00:50:28.960 --> 00:50:31.560]   They're going to go right now, especially before the election,
[00:50:31.560 --> 00:50:34.480]   is going to go full bore victimhood.
[00:50:34.480 --> 00:50:37.400]   Well, nothing's going to happen before the election at all.
[00:50:37.400 --> 00:50:39.360]   Oh, kind of, in terms of the rhetoric we're hearing.
[00:50:39.360 --> 00:50:40.040]   Right.
[00:50:40.040 --> 00:50:41.920]   It's all about rhetoric.
[00:50:41.920 --> 00:50:44.560]   And I think anybody, reasonable is going to say, well,
[00:50:44.560 --> 00:50:48.040]   we're going to have a new Congress in a month or two.
[00:50:48.040 --> 00:50:50.560]   Probably we should just put this off.
[00:50:50.560 --> 00:50:54.440]   They're all going to ride down the street on skateboards
[00:50:54.440 --> 00:50:57.000]   with cranberry sauce.
[00:50:57.000 --> 00:50:58.320]   And so it's going to be a happy place.
[00:50:58.320 --> 00:50:59.040]   I got some drinks.
[00:50:59.040 --> 00:51:00.280]   It's not cranberry sauce.
[00:51:00.280 --> 00:51:01.280]   Cranberry sauce.
[00:51:01.280 --> 00:51:03.320]   Cranberry sauce.
[00:51:03.320 --> 00:51:04.760]   But wait, I have a question for you,
[00:51:04.760 --> 00:51:06.520]   because this is one of those consumer harms things
[00:51:06.520 --> 00:51:10.280]   that I thought about last night when I was not sleeping.
[00:51:10.280 --> 00:51:15.040]   Remember when we used to be able to call someone on the phone.
[00:51:15.040 --> 00:51:16.320]   And you would reach them.
[00:51:16.320 --> 00:51:17.320]   You'd get yourself again.
[00:51:17.320 --> 00:51:19.280]   Now, I know, it's weird.
[00:51:19.280 --> 00:51:20.680]   But now we're sitting here.
[00:51:20.680 --> 00:51:22.320]   At least she's dating somebody she likes.
[00:51:22.320 --> 00:51:24.880]   [LAUGHTER]
[00:51:24.880 --> 00:51:25.880]   I'm going to--
[00:51:25.880 --> 00:51:26.400]   No sense.
[00:51:26.400 --> 00:51:28.400]   --you know, you want to zoom, you want to Skype,
[00:51:28.400 --> 00:51:30.880]   do you want to messenger?
[00:51:30.880 --> 00:51:32.000]   Where do I find you?
[00:51:32.000 --> 00:51:33.760]   Should I duo you?
[00:51:33.760 --> 00:51:36.400]   All of this does create consumer harm.
[00:51:36.400 --> 00:51:40.320]   I was just thinking, I'm like, ooh, I got my mom on duo,
[00:51:40.320 --> 00:51:43.560]   but my in-laws are on Amazon's Echo platform.
[00:51:43.560 --> 00:51:45.200]   And I want to be able to video call them.
[00:51:45.200 --> 00:51:46.560]   Gah.
[00:51:46.560 --> 00:51:49.240]   So just think about that, because that is a legit consumer
[00:51:49.240 --> 00:51:50.640]   harm that--
[00:51:50.640 --> 00:51:52.000]   is it catastrophic?
[00:51:52.000 --> 00:51:53.600]   No, but it's irritating.
[00:51:53.600 --> 00:51:56.200]   And we don't really have a way to address that,
[00:51:56.200 --> 00:51:59.720]   because, again, pricing is one of the primary metrics
[00:51:59.720 --> 00:52:00.720]   we use there.
[00:52:00.720 --> 00:52:01.560]   So just go on that--
[00:52:01.560 --> 00:52:02.000]   What are you saying?
[00:52:02.000 --> 00:52:03.960]   Are you saying there's too much choice in calling?
[00:52:03.960 --> 00:52:04.960]   Isn't that a good thing?
[00:52:04.960 --> 00:52:07.200]   No, I'm saying.
[00:52:07.200 --> 00:52:12.360]   I'm saying that we have all of these competitors in calling.
[00:52:12.360 --> 00:52:15.040]   And the network effects make it hard.
[00:52:15.040 --> 00:52:17.760]   They're trying to lock you into one place or another.
[00:52:17.760 --> 00:52:20.000]   So things like data interoperability become really
[00:52:20.000 --> 00:52:21.400]   important, which is why I think we
[00:52:21.400 --> 00:52:26.480]   need to have a rubric that looks at any competitive behavior
[00:52:26.480 --> 00:52:30.240]   for the modern era and tries to say, hey,
[00:52:30.240 --> 00:52:32.800]   it's really important.
[00:52:32.800 --> 00:52:34.800]   When they broke up the bells, they
[00:52:34.800 --> 00:52:37.120]   talked about the physical underlying infrastructure
[00:52:37.120 --> 00:52:38.560]   making that available.
[00:52:38.560 --> 00:52:42.680]   I think doing something like that with technology
[00:52:42.680 --> 00:52:44.680]   to a certain level, obviously.
[00:52:44.680 --> 00:52:46.560]   You can't go all the way up the stack.
[00:52:46.560 --> 00:52:50.520]   But those kind of things will make life easier for consumers
[00:52:50.520 --> 00:52:55.440]   and will cut down a little bit on the monopoly power
[00:52:55.440 --> 00:52:57.000]   that these companies have.
[00:52:57.000 --> 00:52:59.520]   And that's just at a consumer level
[00:52:59.520 --> 00:53:02.600]   that you and I would understand as opposed to breaking up
[00:53:02.600 --> 00:53:04.160]   the ad business of Google.
[00:53:04.160 --> 00:53:05.320]   Does that make sense?
[00:53:05.320 --> 00:53:06.800]   That's where I was going with that.
[00:53:06.800 --> 00:53:10.040]   I am going to call an adjournment on this session.
[00:53:10.040 --> 00:53:11.040]   Yeah.
[00:53:11.040 --> 00:53:12.040]   That's fine.
[00:53:12.040 --> 00:53:13.040]   Yeah.
[00:53:13.040 --> 00:53:15.600]   I can erase my whiteboard now.
[00:53:15.600 --> 00:53:16.480]   By the way--
[00:53:16.480 --> 00:53:17.160]   I don't know, Jeff.
[00:53:17.160 --> 00:53:18.200]   What else do we have to talk about?
[00:53:18.200 --> 00:53:24.560]   By the way, Nathan Apodaca has had car trouble.
[00:53:24.560 --> 00:53:27.560]   Thank you on his screen.
[00:53:27.560 --> 00:53:30.800]   God bless you, Mr. Apodaca.
[00:53:30.800 --> 00:53:35.160]   Nathan Apodaca's AKA Dogface 208 was having trouble.
[00:53:35.160 --> 00:53:36.760]   Those of you not able to hear that,
[00:53:36.760 --> 00:53:38.760]   to see that, and put up a screen and said thank you.
[00:53:38.760 --> 00:53:39.520]   Told them that.
[00:53:39.520 --> 00:53:40.600]   I said that already.
[00:53:40.600 --> 00:53:41.320]   Oh, I didn't hear that.
[00:53:41.320 --> 00:53:42.320]   I narrated--
[00:53:42.320 --> 00:53:43.720]   I got all the old men.
[00:53:43.720 --> 00:53:45.480]   Come on, stop.
[00:53:45.480 --> 00:53:48.160]   I told them that, Jeff.
[00:53:48.160 --> 00:53:54.280]   You're paying attention, you reductionist fool.
[00:53:54.280 --> 00:53:58.840]   Nathan Apodaca Dogface 208 was having car trouble
[00:53:58.840 --> 00:54:02.440]   on his way to his job at the Potato Warehouse.
[00:54:02.440 --> 00:54:04.440]   It's a true story.
[00:54:04.440 --> 00:54:07.480]   Car broke down, so Nathan popped the trunk
[00:54:07.480 --> 00:54:09.320]   and jumped on the longboard.
[00:54:09.320 --> 00:54:12.720]   He always kept in the trunk as an emergency,
[00:54:12.720 --> 00:54:14.720]   so he could get to work.
[00:54:14.720 --> 00:54:21.360]   He happened to have with him a 20-ounce ball of ocean spray
[00:54:21.360 --> 00:54:25.800]   crannapal juice recorded a TikTok video
[00:54:25.800 --> 00:54:32.960]   to Fleetwood Max Dreams, which has now received 28 million views.
[00:54:32.960 --> 00:54:36.400]   The sales of Fleetwood Max Dreams has tripled.
[00:54:36.400 --> 00:54:39.280]   The streams have doubled this video.
[00:54:39.280 --> 00:54:44.600]   We talked about this last week, this song that came out in 1977.
[00:54:44.600 --> 00:54:48.080]   Mick Fleetwood himself recreated the video.
[00:54:48.080 --> 00:54:49.800]   He joined TikTok to do so.
[00:54:49.800 --> 00:54:51.760]   Yeah, on the longboard.
[00:54:51.760 --> 00:54:54.960]   And as the bottom line, because poor Nathan
[00:54:54.960 --> 00:54:57.600]   has to get to his job at the Potato Warehouse,
[00:54:57.600 --> 00:55:03.000]   ocean spray gave him a cranberry red pickup truck.
[00:55:03.000 --> 00:55:05.400]   And who says the internet's a bad thing?
[00:55:05.400 --> 00:55:06.760]   Oh, I said the internet's a bad thing.
[00:55:06.760 --> 00:55:09.240]   It was filled with crannapal juice.
[00:55:09.240 --> 00:55:10.120]   Of course.
[00:55:10.120 --> 00:55:12.800]   So who says the internet's a bad thing?
[00:55:12.800 --> 00:55:15.200]   See, it's a wonderful thing, people.
[00:55:15.200 --> 00:55:16.360]   Just go with the flow.
[00:55:16.360 --> 00:55:18.960]   Ride your skin for it and drink your crannapal juice.
[00:55:18.960 --> 00:55:20.320]   And everything can be OK.
[00:55:20.320 --> 00:55:22.120]   Isn't that a great story?
[00:55:22.120 --> 00:55:22.840]   Isn't it great?
[00:55:22.840 --> 00:55:23.440]   I love it.
[00:55:23.440 --> 00:55:24.240]   I just loved it.
[00:55:24.240 --> 00:55:28.560]   And the fact that this guy has 28 million views, which
[00:55:28.560 --> 00:55:32.880]   is like more than last night's Tonight Show,
[00:55:32.880 --> 00:55:37.600]   him on his longboard singing dreams with his crannapal juice,
[00:55:37.600 --> 00:55:40.200]   lip-syncing.
[00:55:40.200 --> 00:55:42.040]   Wow.
[00:55:42.040 --> 00:55:46.880]   And you say, there's so many other people doing exactly what
[00:55:46.880 --> 00:55:50.920]   he did that just doesn't come off as good.
[00:55:50.920 --> 00:55:52.640]   And people won't gravitate towards it.
[00:55:52.640 --> 00:55:53.760]   I don't know how it works.
[00:55:53.760 --> 00:55:55.160]   It's worse than I get.
[00:55:55.160 --> 00:55:56.560]   I mean, honestly, not the first time
[00:55:56.560 --> 00:55:58.040]   that's had a figure of fate.
[00:55:58.040 --> 00:56:00.960]   It's a fickle figure fader, or maybe bike
[00:56:00.960 --> 00:56:03.160]   dances artificial intelligence algorithms.
[00:56:03.160 --> 00:56:05.160]   Oh, no, it's an algorithm.
[00:56:05.160 --> 00:56:07.240]   Oh, no, it changed the world.
[00:56:07.240 --> 00:56:09.800]   It really likes it really likes Stephen Hicks.
[00:56:09.800 --> 00:56:12.000]   Big fan of Stephen Hicks.
[00:56:12.000 --> 00:56:13.360]   It's kind of--
[00:56:13.360 --> 00:56:14.400]   [LAUGHTER]
[00:56:14.400 --> 00:56:14.920]   You're right.
[00:56:14.920 --> 00:56:17.280]   He didn't fully erase it, did you?
[00:56:17.280 --> 00:56:18.120]   No.
[00:56:18.120 --> 00:56:19.120]   He couldn't have let go.
[00:56:19.120 --> 00:56:19.720]   He was better than that.
[00:56:19.720 --> 00:56:22.160]   He's going to pull the moral panic button a lot.
[00:56:22.160 --> 00:56:23.560]   I think-- no, I like Stacey.
[00:56:23.560 --> 00:56:24.360]   I love your idea.
[00:56:24.360 --> 00:56:26.480]   I think we need some neon.
[00:56:26.480 --> 00:56:29.480]   I think we need a neon, moral panic sign.
[00:56:29.480 --> 00:56:30.480]   That's what I want.
[00:56:30.480 --> 00:56:34.240]   Chef, we need a card so you can play the moral panic card.
[00:56:34.240 --> 00:56:36.200]   And you just throw it down.
[00:56:36.200 --> 00:56:37.200]   Yes.
[00:56:37.200 --> 00:56:39.200]   Yes.
[00:56:39.200 --> 00:56:41.880]   And we're going to give you a reductionist card, Stacey.
[00:56:41.880 --> 00:56:43.120]   I think we can have--
[00:56:43.120 --> 00:56:44.440]   if we work on this a little bit, we
[00:56:44.440 --> 00:56:46.920]   can have Twig the board game pretty soon.
[00:56:46.920 --> 00:56:48.160]   I was going to say this really--
[00:56:48.160 --> 00:56:49.160]   Oh, yeah.
[00:56:49.160 --> 00:56:51.880]   Twig the gathering.
[00:56:51.880 --> 00:56:54.760]   Twig the gatherings.
[00:56:54.760 --> 00:56:56.480]   All right, I think we probably--
[00:56:56.480 --> 00:56:58.320]   So by the way, while we're on this, while we're on this--
[00:56:58.320 --> 00:56:59.400]   Yes, yes.
[00:56:59.400 --> 00:57:04.040]   So fears of monopolies, fears of everything going
[00:57:04.040 --> 00:57:05.200]   wrong in the world.
[00:57:05.200 --> 00:57:08.160]   TikTok has passed Instagram to become number two in the hard--
[00:57:08.160 --> 00:57:10.360]   I was-- that was one of our stories today, yeah.
[00:57:10.360 --> 00:57:10.960]   TikTok.
[00:57:10.960 --> 00:57:11.460]   Yes.
[00:57:11.460 --> 00:57:14.320]   So number two, by the way, with the teenagers,
[00:57:14.320 --> 00:57:15.360]   with the kids, with the youngs.
[00:57:15.360 --> 00:57:16.120]   That's who matters.
[00:57:16.120 --> 00:57:17.500]   Who matters on TikTok?
[00:57:17.500 --> 00:57:19.140]   There's five of us old people who are on it,
[00:57:19.140 --> 00:57:20.100]   and you're there by force.
[00:57:20.100 --> 00:57:26.580]   I have an account, but I don't do--
[00:57:26.580 --> 00:57:28.100]   Have you made a TikTok?
[00:57:28.100 --> 00:57:29.460]   Oh, yeah.
[00:57:29.460 --> 00:57:30.300]   Way back when--
[00:57:30.300 --> 00:57:31.900]   Did you all do it together?
[00:57:31.900 --> 00:57:33.660]   Didn't you all make a TikTok?
[00:57:33.660 --> 00:57:34.940]   Maybe there was something like that.
[00:57:34.940 --> 00:57:36.820]   Oh, no, those were Snapchat classes.
[00:57:36.820 --> 00:57:37.700]   Never mind.
[00:57:37.700 --> 00:57:39.980]   I think Jeff and I should do a--
[00:57:39.980 --> 00:57:41.980]   I have an account that says, "How could you do it?"
[00:57:41.980 --> 00:57:43.340]   --all the fat learn wall door on TikTok.
[00:57:43.340 --> 00:57:45.900]   I'm worried you throw something at it, Jeff.
[00:57:45.900 --> 00:57:46.740]   It'll be fun.
[00:57:46.740 --> 00:57:47.020]   That's right.
[00:57:47.020 --> 00:57:48.100]   We throw it-- yeah, that's right.
[00:57:48.100 --> 00:57:49.940]   That's right, yeah.
[00:57:49.940 --> 00:57:51.500]   It's a great story.
[00:57:51.500 --> 00:57:56.420]   Yeah, TikTok passed Instagram in the hearts of teens.
[00:57:56.420 --> 00:58:00.220]   This is according to a report published yesterday,
[00:58:00.220 --> 00:58:02.060]   a survey, if you will.
[00:58:02.060 --> 00:58:03.780]   By the way, neither is number one.
[00:58:03.780 --> 00:58:04.300]   What's number one?
[00:58:04.300 --> 00:58:07.740]   34% of the teens list Snapchat.
[00:58:07.740 --> 00:58:09.780]   29% TikTok.
[00:58:09.780 --> 00:58:13.340]   25% Instagram.
[00:58:13.340 --> 00:58:17.540]   However, there is an engagement thing.
[00:58:17.540 --> 00:58:18.740]   I don't know how they measure it.
[00:58:18.740 --> 00:58:23.220]   But Tik Instagram still is easily tops an engagement
[00:58:23.220 --> 00:58:29.020]   with 84% Snapchat, 80% TikTok, 69% up from 62%.
[00:58:29.020 --> 00:58:34.420]   This is a report from Piper Sandler.
[00:58:34.420 --> 00:58:35.700]   That's a legit.
[00:58:35.700 --> 00:58:36.260]   Is it?
[00:58:36.260 --> 00:58:36.900]   Org?
[00:58:36.900 --> 00:58:37.540]   Yeah.
[00:58:37.540 --> 00:58:38.380]   Yeah, they--
[00:58:38.380 --> 00:58:38.980]   Yeah, what is that?
[00:58:38.980 --> 00:58:39.940]   Is it a bangs?
[00:58:39.940 --> 00:58:41.420]   No, no, it's a research.
[00:58:41.420 --> 00:58:41.940]   No, it's a research.
[00:58:41.940 --> 00:58:43.340]   Yeah.
[00:58:43.340 --> 00:58:43.860]   Got it.
[00:58:43.860 --> 00:58:45.380]   All right, pause.
[00:58:45.380 --> 00:58:48.060]   Let's have a pause that refreshes.
[00:58:48.060 --> 00:58:49.900]   Drink your crayon apple juice.
[00:58:49.900 --> 00:58:51.460]   I think you need--
[00:58:51.460 --> 00:58:53.980]   Ant also needs a cue card that just says,
[00:58:53.980 --> 00:58:55.500]   go to a commercial break, please.
[00:58:55.500 --> 00:58:58.220]   [LAUGHTER]
[00:58:58.220 --> 00:58:58.780]   Carsten.
[00:58:58.780 --> 00:58:59.460]   Oh, OK.
[00:58:59.460 --> 00:59:00.100]   We're about to get it.
[00:59:00.100 --> 00:59:00.660]   We're about to get it.
[00:59:00.660 --> 00:59:01.180]   Yeah, OK, hold on.
[00:59:01.180 --> 00:59:03.060]   I think that's bad.
[00:59:03.060 --> 00:59:04.460]   Frank, Frank, I showed it.
[00:59:04.460 --> 00:59:07.100]   They brought to you by LastPass.
[00:59:07.100 --> 00:59:09.900]   As we know, a very important part of this operation.
[00:59:09.900 --> 00:59:12.980]   We're in the LastPass studios.
[00:59:12.980 --> 00:59:15.180]   LastPass has been around committed
[00:59:15.180 --> 00:59:17.580]   to protecting its users for 12 years.
[00:59:17.580 --> 00:59:19.980]   I started using them 12 years ago, right when they first
[00:59:19.980 --> 00:59:21.380]   started.
[00:59:21.380 --> 00:59:24.380]   In fact, we've been using LastPass Enterprise here
[00:59:24.380 --> 00:59:27.060]   at Twit for about five or six years.
[00:59:27.060 --> 00:59:30.500]   25 million users now, LastPass has.
[00:59:30.500 --> 00:59:32.340]   And 70,000 businesses.
[00:59:32.340 --> 00:59:33.260]   It's no surprise.
[00:59:33.260 --> 00:59:35.820]   They're the award-winning number-one password manager.
[00:59:35.820 --> 00:59:39.100]   And why are more businesses using LastPass right now?
[00:59:39.100 --> 00:59:41.340]   Well, because of work from home.
[00:59:41.340 --> 00:59:44.140]   When you're sending employees home with the passwords
[00:59:44.140 --> 00:59:46.380]   to the most valuable parts of your business,
[00:59:46.380 --> 00:59:50.260]   you're checking account, your business line of credit,
[00:59:50.260 --> 00:59:53.380]   your website, your customer lists, your supplier lists,
[00:59:53.380 --> 00:59:57.180]   you want to make sure you've got your identity and access
[00:59:57.180 --> 00:59:58.940]   management nailed down.
[00:59:58.940 --> 01:00:01.260]   That's what LastPass does.
[01:00:01.260 --> 01:00:03.060]   Adjusting to an online workforce isn't just
[01:00:03.060 --> 01:00:04.500]   a logistical problem.
[01:00:04.500 --> 01:00:06.340]   It's a security issue.
[01:00:06.340 --> 01:00:08.540]   LastPass has been a saving grace.
[01:00:08.540 --> 01:00:11.500]   So many companies, including ours.
[01:00:11.500 --> 01:00:14.780]   One company leveraged LastPass to enable the team to set up,
[01:00:14.780 --> 01:00:17.860]   utilize and share strong passwords for their accounts
[01:00:17.860 --> 01:00:19.260]   and programs.
[01:00:19.260 --> 01:00:24.460]   A crucial, progressive step towards improved data security.
[01:00:24.460 --> 01:00:27.220]   But-- and I love this about LastPass.
[01:00:27.220 --> 01:00:28.620]   It also makes life easier.
[01:00:28.620 --> 01:00:31.740]   It eases the burden of moving from the office
[01:00:31.740 --> 01:00:33.420]   to home full time.
[01:00:33.420 --> 01:00:34.340]   How does it make it easier?
[01:00:34.340 --> 01:00:36.580]   Well, auto fill passwords is great.
[01:00:36.580 --> 01:00:39.260]   When you create a new password for a site, it remembers it.
[01:00:39.260 --> 01:00:40.220]   It fills it in.
[01:00:40.220 --> 01:00:42.140]   You don't have to share passwords with colleagues
[01:00:42.140 --> 01:00:43.900]   by sending them a text or an email.
[01:00:43.900 --> 01:00:44.940]   That wouldn't be safe.
[01:00:44.940 --> 01:00:48.020]   LastPass has built-in password sharing.
[01:00:48.020 --> 01:00:52.660]   They have single sign-on, 1,300 plus single sign-on apps.
[01:00:52.660 --> 01:00:53.780]   Employees love that.
[01:00:53.780 --> 01:00:57.460]   I love it because you don't have to have a password.
[01:00:57.460 --> 01:00:59.620]   You just approve it on your phone and you're in.
[01:00:59.620 --> 01:01:01.740]   And IT loves it because they always
[01:01:01.740 --> 01:01:06.500]   know who has access to what and from where.
[01:01:06.500 --> 01:01:08.380]   The Enterprise Password Management
[01:01:08.380 --> 01:01:11.860]   ensures oversight of shadow IT and enforceable policies
[01:01:11.860 --> 01:01:14.860]   across all your password protective accounts.
[01:01:14.860 --> 01:01:18.260]   LastPass implements multi-factor in their enterprise product,
[01:01:18.260 --> 01:01:21.220]   not just fingerprint and face recognition,
[01:01:21.220 --> 01:01:25.620]   but contextual cues like IP address and geolocation.
[01:01:25.620 --> 01:01:29.420]   That makes it easier for employees and more secure for you.
[01:01:29.420 --> 01:01:31.340]   The model is zero knowledge.
[01:01:31.340 --> 01:01:32.340]   That's what they call it.
[01:01:32.340 --> 01:01:36.220]   The zero knowledge security model assumes that everything,
[01:01:36.220 --> 01:01:39.420]   whether it's inside the network or out, is a threat,
[01:01:39.420 --> 01:01:43.020]   and it protects everyone in the enterprise,
[01:01:43.020 --> 01:01:46.340]   from the individual user to the biggest organizations.
[01:01:46.340 --> 01:01:49.940]   Security is LastPass's number one priority.
[01:01:49.940 --> 01:01:54.420]   And because you can go passwordless, you can enjoy your work.
[01:01:54.420 --> 01:01:56.180]   It makes it just a little bit easier.
[01:01:56.180 --> 01:01:58.260]   And I enjoy it because I know, you know,
[01:01:58.260 --> 01:02:00.500]   we've been careful about assessing LastPass.
[01:02:00.500 --> 01:02:03.860]   Steve Gibson went through all the code with Joe Seagrest,
[01:02:03.860 --> 01:02:09.300]   its creator, gave it their thumbs up, AES-256-bit encryption,
[01:02:09.300 --> 01:02:13.740]   salted hashes, SHA-256, so your data is secure in the cloud.
[01:02:13.740 --> 01:02:17.660]   In fact, your data is never decrypted anywhere, but on device.
[01:02:17.660 --> 01:02:20.860]   And your passwords never transmitted the LastPass.
[01:02:20.860 --> 01:02:22.660]   That's how you keep your vault secret from everyone,
[01:02:22.660 --> 01:02:24.340]   including LastPass.
[01:02:24.340 --> 01:02:27.020]   LastPass has won eight awards so far this year.
[01:02:27.020 --> 01:02:28.740]   The PC Magazine's editor's choice,
[01:02:28.740 --> 01:02:31.020]   the Fortress Cyber Security Award,
[01:02:31.020 --> 01:02:34.820]   their business insider's best overall password manager.
[01:02:34.820 --> 01:02:35.980]   You don't have to take our word for it.
[01:02:35.980 --> 01:02:37.740]   LastPass speaks for itself.
[01:02:37.740 --> 01:02:40.380]   Speaking of speaking tomorrow, we're going to have so much fun.
[01:02:40.380 --> 01:02:42.500]   We're doing another LastPass event.
[01:02:42.500 --> 01:02:46.420]   It's Security Month, October is online security month.
[01:02:46.420 --> 01:02:47.940]   So we're going to have a special panel.
[01:02:47.940 --> 01:02:51.420]   This is going to be so much fun.
[01:02:51.420 --> 01:02:52.780]   It's called Attack and Defense.
[01:02:52.780 --> 01:02:55.740]   We're going to have two teams, our Red Team, our attackers,
[01:02:55.740 --> 01:03:00.140]   headed by Father Robert Ballisare, the digital Jesuit,
[01:03:00.140 --> 01:03:04.100]   and his buddy from Twiatt, Chee Bird, Brian Chi.
[01:03:04.100 --> 01:03:07.900]   These guys have been on both sides of the security equation.
[01:03:07.900 --> 01:03:10.940]   They know they're going to come up with some devious attacks.
[01:03:10.940 --> 01:03:15.460]   But don't worry, because we have some really good defenders.
[01:03:15.460 --> 01:03:19.380]   Jerry Bootkelt from LastPass, he's actually the CISO
[01:03:19.380 --> 01:03:21.340]   of their parent company, LogMeIn,
[01:03:21.340 --> 01:03:25.020]   certainly knows his way around a security perimeter.
[01:03:25.020 --> 01:03:29.660]   And the very well-known, one of my heroes, Bruce Schneier,
[01:03:29.660 --> 01:03:31.580]   will be on the defense team.
[01:03:31.580 --> 01:03:33.940]   I will be your white team, your moderator,
[01:03:33.940 --> 01:03:38.300]   between the red and the blue, trying to keep things on an even keel.
[01:03:38.300 --> 01:03:40.180]   It's going to be a lot of fun.
[01:03:40.180 --> 01:03:43.300]   It's not going to be a real competition.
[01:03:43.300 --> 01:03:44.620]   There is such a thing.
[01:03:44.620 --> 01:03:46.820]   They do these competitions, red and blue, white.
[01:03:46.820 --> 01:03:49.420]   But I am not going to--
[01:03:49.420 --> 01:03:51.460]   I think we'll be a little loosey, goosey,
[01:03:51.460 --> 01:03:53.220]   because we've got such great people.
[01:03:53.220 --> 01:03:56.820]   But we will talk about how people attack, how they defend,
[01:03:56.820 --> 01:03:59.140]   how you mitigate, how you plan.
[01:03:59.140 --> 01:04:02.140]   It is going to be a great presentation.
[01:04:02.140 --> 01:04:06.100]   That is tomorrow, October 8th, it's a Thursday,
[01:04:06.100 --> 01:04:09.020]   1 p.m. Pacific, 4 p.m. Eastern time.
[01:04:09.020 --> 01:04:12.220]   You can watch it live on the stream at twit.tv/live.
[01:04:12.220 --> 01:04:13.620]   And of course, it's a Twitter event,
[01:04:13.620 --> 01:04:16.780]   so we'll put it out on our Twitter events feed.
[01:04:16.780 --> 01:04:17.940]   That's a brand new feed.
[01:04:17.940 --> 01:04:19.260]   This will only be the ninth event on it.
[01:04:19.260 --> 01:04:21.660]   So if you're not a subscriber, go to twit.tv.
[01:04:21.660 --> 01:04:24.300]   Is John, is it twit.tv/events?
[01:04:24.300 --> 01:04:27.020]   Yeah, twit.tv/events.
[01:04:27.020 --> 01:04:28.420]   You'll see the previous events.
[01:04:28.420 --> 01:04:31.820]   We did one last week with ITProTV.
[01:04:31.820 --> 01:04:35.260]   And if you subscribe to that in your favorite app,
[01:04:35.260 --> 01:04:37.220]   you'll get it the minute it's available.
[01:04:37.220 --> 01:04:38.500]   So that's always the best policy.
[01:04:38.500 --> 01:04:39.940]   Subscribe to our events.
[01:04:39.940 --> 01:04:42.620]   And all of our feeds, twit.tv/events.
[01:04:42.620 --> 01:04:44.820]   There's no better time to get LastPass.
[01:04:44.820 --> 01:04:47.580]   Ease the burden for yourself and your remote workforce
[01:04:47.580 --> 01:04:49.460]   with a cyber security protection you need.
[01:04:49.460 --> 01:04:54.460]   Go to lastpass.com/twit.
[01:04:54.460 --> 01:04:56.700]   Can you imagine?
[01:04:56.700 --> 01:05:00.460]   Bruce Schneier versus the digital Jesuit in a cage.
[01:05:00.460 --> 01:05:02.140]   Man, I'll show it right.
[01:05:02.140 --> 01:05:04.060]   They're both saints to me.
[01:05:04.060 --> 01:05:05.740]   They're both saints.
[01:05:05.740 --> 01:05:06.700]   They really are.
[01:05:06.700 --> 01:05:08.380]   They're both saints to me.
[01:05:08.380 --> 01:05:09.900]   So can I take you to a weird story
[01:05:09.900 --> 01:05:10.860]   that I think is fascinating?
[01:05:10.860 --> 01:05:12.500]   Yeah.
[01:05:12.500 --> 01:05:14.260]   Line 136.
[01:05:14.260 --> 01:05:15.460]   I spotted this.
[01:05:15.460 --> 01:05:18.620]   I follow Alexis Ohanian, who I've known over the years.
[01:05:18.620 --> 01:05:19.660]   Not that he's found her.
[01:05:19.660 --> 01:05:21.500]   Founder of Reddit.
[01:05:21.500 --> 01:05:23.420]   But more importantly, the husband of--
[01:05:23.420 --> 01:05:24.900]   Husband of Serena.
[01:05:24.900 --> 01:05:26.860]   Serena Williams, the greatest world
[01:05:26.860 --> 01:05:29.540]   greatest champion tennis player in the world.
[01:05:29.540 --> 01:05:32.180]   And father of the cutest baby, cutest toddler.
[01:05:32.180 --> 01:05:34.060]   And so--
[01:05:34.060 --> 01:05:34.900]   And?
[01:05:34.900 --> 01:05:36.780]   He's founded.
[01:05:36.780 --> 01:05:39.060]   Well, he's not the founder of it.
[01:05:39.060 --> 01:05:39.900]   But he's tweeted it.
[01:05:39.900 --> 01:05:41.700]   He's, I guess, he's investing in helping out.
[01:05:41.700 --> 01:05:42.900]   He's working for a year.
[01:05:42.900 --> 01:05:43.740]   Oda.
[01:05:43.740 --> 01:05:46.740]   You're going to hear you guys.
[01:05:46.740 --> 01:05:47.780]   Have you seen it yet?
[01:05:47.780 --> 01:05:48.740]   I'm looking at it right now.
[01:05:48.740 --> 01:05:52.460]   Live performances in your home.
[01:05:52.460 --> 01:05:54.220]   So you buy the speakers.
[01:05:54.220 --> 01:05:56.220]   Oh, you have to buy speakers.
[01:05:56.220 --> 01:05:56.900]   Well, you don't have to.
[01:05:56.900 --> 01:05:57.540]   I don't think.
[01:05:57.540 --> 01:05:59.100]   I'm not sure what I don't think.
[01:05:59.100 --> 01:06:04.020]   And then you buy separately a $79 subscription.
[01:06:04.020 --> 01:06:09.860]   And then they fill them with live programming
[01:06:09.860 --> 01:06:11.140]   a lot of the time.
[01:06:11.140 --> 01:06:11.620]   You see.
[01:06:11.620 --> 01:06:13.060]   And so it's a weird company.
[01:06:13.060 --> 01:06:14.980]   So it's not a concert.
[01:06:14.980 --> 01:06:17.020]   You know, it's a company.
[01:06:17.020 --> 01:06:18.740]   It's a content company.
[01:06:18.740 --> 01:06:20.620]   It's a live performance company.
[01:06:20.620 --> 01:06:22.260]   It's a subscription company.
[01:06:22.260 --> 01:06:23.100]   Look at these speakers.
[01:06:23.100 --> 01:06:23.620]   And I said all this--
[01:06:23.620 --> 01:06:24.620]   They said all this looks like--
[01:06:24.620 --> 01:06:26.180]   Wooden frames.
[01:06:26.180 --> 01:06:27.340]   They're strange.
[01:06:27.340 --> 01:06:30.060]   So Google actually was talking about this last week
[01:06:30.060 --> 01:06:32.220]   at their event.
[01:06:32.220 --> 01:06:33.620]   Not this particular thing.
[01:06:33.620 --> 01:06:36.860]   But they had a whole section on recording artists
[01:06:36.860 --> 01:06:41.620]   in their home and optimizing the way their speakers sound
[01:06:41.620 --> 01:06:43.700]   for that particular performance.
[01:06:43.700 --> 01:06:44.900]   Oh, that's interesting.
[01:06:44.900 --> 01:06:47.700]   But that's what these guys are actually doing right here.
[01:06:47.700 --> 01:06:48.260]   Doing.
[01:06:48.260 --> 01:06:49.980]   And so they have a--
[01:06:49.980 --> 01:06:52.660]   they're producing a network of entertainment
[01:06:52.660 --> 01:06:54.140]   on a subscription basis.
[01:06:54.140 --> 01:06:56.060]   They say, well, take no data and never sell you data.
[01:06:56.060 --> 01:06:57.780]   Anybody, no advertising support.
[01:06:57.780 --> 01:06:59.540]   But the speakers and the subscriptions
[01:06:59.540 --> 01:07:02.540]   kind of support each other to support the artists.
[01:07:02.540 --> 01:07:05.020]   Mainly music, but also some speaking stuff.
[01:07:05.020 --> 01:07:06.740]   I wonder if there's an opportunity for journalists
[01:07:06.740 --> 01:07:07.740]   and things.
[01:07:07.740 --> 01:07:09.220]   I just found this--
[01:07:09.220 --> 01:07:11.020]   I can't get my head around it fully yet.
[01:07:11.020 --> 01:07:11.780]   I found it really--
[01:07:11.780 --> 01:07:12.860]   Yeah, I love it.
[01:07:12.860 --> 01:07:14.740]   Or is it--
[01:07:14.740 --> 01:07:15.700]   I think it's smart.
[01:07:15.700 --> 01:07:17.140]   But it's going to be clouded.
[01:07:17.140 --> 01:07:18.220]   Or is it reductionist?
[01:07:18.220 --> 01:07:18.780]   I don't know.
[01:07:18.780 --> 01:07:22.860]   So they've already sold out their first batch.
[01:07:22.860 --> 01:07:24.020]   Before anybody even knew about it.
[01:07:24.020 --> 01:07:25.460]   Presumably that was $199.
[01:07:25.460 --> 01:07:31.100]   The second batch is $299, two speakers plus a subscription.
[01:07:31.100 --> 01:07:33.620]   That delivers in January.
[01:07:33.620 --> 01:07:35.580]   And then the third batch is $399.
[01:07:35.580 --> 01:07:36.620]   So the price is going up.
[01:07:36.620 --> 01:07:37.060]   Wait a minute.
[01:07:37.060 --> 01:07:39.220]   The price does not include the membership.
[01:07:39.220 --> 01:07:40.660]   So that's just the speakers.
[01:07:40.660 --> 01:07:41.420]   So you have to also--
[01:07:41.420 --> 01:07:42.380]   I tweeted about this.
[01:07:42.380 --> 01:07:44.740]   They said, can you come to this special jazz performance
[01:07:44.740 --> 01:07:46.340]   we have tomorrow at sundown?
[01:07:46.340 --> 01:07:47.180]   And I does today.
[01:07:47.180 --> 01:07:50.820]   And I said, sorry, I'm on my podcast at sundown.
[01:07:50.820 --> 01:07:53.060]   What a bizarre--
[01:07:53.060 --> 01:07:53.580]   Conscience.
[01:07:53.580 --> 01:07:53.940]   --constraints.
[01:07:53.940 --> 01:07:54.780]   --combination.
[01:07:54.780 --> 01:07:56.780]   Yeah.
[01:07:56.780 --> 01:07:57.780]   So I kind of like it.
[01:07:57.780 --> 01:08:00.940]   It's hard to do this idea of--
[01:08:00.940 --> 01:08:03.620]   So there's this old school idea of craftsmanship
[01:08:03.620 --> 01:08:05.500]   tied to the physical object.
[01:08:05.500 --> 01:08:08.220]   So there's some veneration of the physical object.
[01:08:08.220 --> 01:08:11.260]   There is the serendipity of having a subscription
[01:08:11.260 --> 01:08:13.620]   where you could--
[01:08:13.620 --> 01:08:16.260]   if you subscribe to this, you have a random concert
[01:08:16.260 --> 01:08:20.300]   you could tune into that is also bounded in time, which
[01:08:20.300 --> 01:08:23.900]   people are really high on right now.
[01:08:23.900 --> 01:08:26.060]   Yeah, Jeff, this is really interesting.
[01:08:26.060 --> 01:08:27.660]   I don't--
[01:08:27.660 --> 01:08:28.820]   Oh, go on.
[01:08:28.820 --> 01:08:30.020]   Those guys, Jim R. B.
[01:08:30.020 --> 01:08:31.740]   Since Jim R. B is the music fan.
[01:08:31.740 --> 01:08:35.860]   Yes, we were listening to his speakers earlier.
[01:08:35.860 --> 01:08:37.300]   He has some beautiful--
[01:08:37.300 --> 01:08:39.340]   what is it?
[01:08:39.340 --> 01:08:43.740]   --dine audio speakers, really beautiful speakers.
[01:08:43.740 --> 01:08:45.420]   He brought them in so I could hear them.
[01:08:45.420 --> 01:08:49.740]   And we were listening to the Firebird Suite by Stravinsky.
[01:08:49.740 --> 01:08:53.820]   It was beautiful, really beautiful.
[01:08:53.820 --> 01:08:55.220]   You never be-- is this something you would ever
[01:08:55.220 --> 01:08:56.020]   subscribe to?
[01:08:56.020 --> 01:08:57.340]   Would you do it, Jim?
[01:08:57.340 --> 01:08:57.700]   No.
[01:08:57.700 --> 01:08:58.220]   But--
[01:08:58.220 --> 01:09:00.500]   It's not his kind of music, maybe.
[01:09:00.500 --> 01:09:01.220]   Is that why?
[01:09:01.220 --> 01:09:02.740]   Or because you already have these speakers.
[01:09:02.740 --> 01:09:03.260]   Right.
[01:09:03.260 --> 01:09:05.620]   And I have plenty of music to listen to.
[01:09:05.620 --> 01:09:07.460]   Yeah, he says he has plenty of music.
[01:09:07.460 --> 01:09:09.860]   Can they hear you or only me?
[01:09:09.860 --> 01:09:10.780]   No, we can hear.
[01:09:10.780 --> 01:09:11.740]   Oh, you can hear him here.
[01:09:11.740 --> 01:09:12.660]   Sometimes--
[01:09:12.660 --> 01:09:15.140]   Sometimes, Bob speaks to me in my own head.
[01:09:15.140 --> 01:09:18.020]   No, I'm using the big Mac today.
[01:09:18.020 --> 01:09:20.580]   Sometimes he speaks in my ear and I'm like, what's happening?
[01:09:20.580 --> 01:09:22.220]   He can do that, too.
[01:09:22.220 --> 01:09:24.460]   He's kind of amazing.
[01:09:24.460 --> 01:09:25.460]   So anyway, that was--
[01:09:25.460 --> 01:09:26.060]   That was--
[01:09:26.060 --> 01:09:27.860]   That was that.
[01:09:27.860 --> 01:09:29.820]   I kind of want to do this.
[01:09:29.820 --> 01:09:30.740]   It's very targeted.
[01:09:30.740 --> 01:09:32.700]   But if you want me to buy something,
[01:09:32.700 --> 01:09:34.340]   tell Jeff about it.
[01:09:34.340 --> 01:09:36.860]   His programmatic advertising.
[01:09:36.860 --> 01:09:39.340]   So Mr. Darby Stu is an espresso machine.
[01:09:39.340 --> 01:09:40.340]   I'm looking at--
[01:09:40.340 --> 01:09:42.460]   [LAUGHTER]
[01:09:42.460 --> 01:09:43.820]   Already bought that.
[01:09:43.820 --> 01:09:45.420]   Problem is, it's not in your house.
[01:09:45.420 --> 01:09:47.420]   [LAUGHTER]
[01:09:47.420 --> 01:09:49.140]   And I don't want Stacy once.
[01:09:49.140 --> 01:09:50.020]   What is Stacy once?
[01:09:50.020 --> 01:09:51.780]   Oh, she wants my thermomix.
[01:09:51.780 --> 01:09:52.940]   Yeah, exactly.
[01:09:52.940 --> 01:09:54.580]   Yes, I'm--
[01:09:54.580 --> 01:09:56.100]   That's what I'm after.
[01:09:56.100 --> 01:09:58.140]   You know, just--
[01:09:58.140 --> 01:10:00.060]   it's too bad you don't work in our studio
[01:10:00.060 --> 01:10:04.860]   because I do have periodic garage sales where I put--
[01:10:04.860 --> 01:10:07.300]   I take old stuff out of my house,
[01:10:07.300 --> 01:10:10.020]   bring it to the conference room, put a sign on it.
[01:10:10.020 --> 01:10:11.780]   We're at minus two months, right?
[01:10:11.780 --> 01:10:14.380]   Yeah, it's-- we're due pretty soon.
[01:10:14.380 --> 01:10:16.620]   Oh, what's the rule set about how that works?
[01:10:16.620 --> 01:10:18.900]   Well, I should make some because--
[01:10:18.900 --> 01:10:20.260]   Is it an auction or is it a crash?
[01:10:20.260 --> 01:10:24.460]   No, no, you just go in and whoever gets it gets it.
[01:10:24.460 --> 01:10:28.420]   It's a little tricky right now because--
[01:10:28.420 --> 01:10:29.540]   Jammer beak--
[01:10:29.540 --> 01:10:30.780]   Jammer beak basically gets everything.
[01:10:30.780 --> 01:10:32.220]   Jammer beak basically gets everything.
[01:10:32.220 --> 01:10:34.140]   [LAUGHTER]
[01:10:34.140 --> 01:10:36.500]   Well, maybe Jammer be and I need to team up.
[01:10:36.500 --> 01:10:40.220]   But like, do you really-- do you need a thermomix?
[01:10:40.220 --> 01:10:41.220]   Are you interested in--
[01:10:41.220 --> 01:10:43.660]   I don't think thermomix is going to go there.
[01:10:43.660 --> 01:10:44.660]   Dang it.
[01:10:44.660 --> 01:10:46.780]   [LAUGHTER]
[01:10:46.780 --> 01:10:48.660]   Oh, OK.
[01:10:48.660 --> 01:10:50.260]   Don't distract me.
[01:10:50.260 --> 01:10:51.460]   I'm trying to buy this right now.
[01:10:51.460 --> 01:10:52.460]   Hold on.
[01:10:52.460 --> 01:10:53.460]   Oh.
[01:10:53.460 --> 01:10:55.860]   All right, Stacy, find a dirty federal story for us.
[01:10:55.860 --> 01:10:57.780]   Well, no, I was going to see--
[01:10:57.780 --> 01:10:59.340]   I was thinking about this and I'm like, you know,
[01:10:59.340 --> 01:11:01.060]   this is a cool thing.
[01:11:01.060 --> 01:11:03.500]   And if they succeed in selling lots of speakers,
[01:11:03.500 --> 01:11:06.660]   then maybe they'll just provide the service over time.
[01:11:06.660 --> 01:11:07.180]   Right.
[01:11:07.180 --> 01:11:10.780]   And they'll deal with like a sonos or--
[01:11:10.780 --> 01:11:12.060]   anyway.
[01:11:12.060 --> 01:11:12.900]   OK, find a new--
[01:11:12.900 --> 01:11:14.460]   A new federal story.
[01:11:14.460 --> 01:11:19.340]   Hey, this is so terrible because it's promoting me,
[01:11:19.340 --> 01:11:20.940]   but I think it's such a really important topic.
[01:11:20.940 --> 01:11:26.860]   So I wrote about consent in our kind of building out
[01:11:26.860 --> 01:11:28.220]   the smart home.
[01:11:28.220 --> 01:11:33.060]   And I wanted to call-- this is actually a Google story, too.
[01:11:33.060 --> 01:11:40.780]   So I wrote about it tied to basically the idea being,
[01:11:40.780 --> 01:11:42.580]   we have all of this stuff in our homes,
[01:11:42.580 --> 01:11:46.140]   and it's not clear to everybody who lives in the home how
[01:11:46.140 --> 01:11:48.540]   these things can be used to surveil you.
[01:11:48.540 --> 01:11:50.980]   And I'm not talking about the companies.
[01:11:50.980 --> 01:11:54.620]   I'm talking about just people in the home.
[01:11:54.620 --> 01:11:59.220]   And so I put forth these nine ideas associated with this.
[01:11:59.220 --> 01:12:00.260]   And this isn't just the home.
[01:12:00.260 --> 01:12:02.020]   This can actually be in the enterprise anywhere.
[01:12:02.020 --> 01:12:02.940]   There's sensors.
[01:12:02.940 --> 01:12:05.300]   There's-- we're gathering a lot of data about people.
[01:12:05.300 --> 01:12:08.540]   And the two things that I focused most on in this story
[01:12:08.540 --> 01:12:10.980]   was, one, we're gathering data about people.
[01:12:10.980 --> 01:12:14.220]   And when I agree to share my data with the company,
[01:12:14.220 --> 01:12:17.340]   there's no conversation right now about sharing that data
[01:12:17.340 --> 01:12:20.820]   over time and through different AI or use cases.
[01:12:20.820 --> 01:12:25.820]   So I might share my Fitbit data right now for COVID-19 tracking.
[01:12:25.820 --> 01:12:29.060]   But if they look at that data and sometime later
[01:12:29.060 --> 01:12:31.260]   come up with an algorithm that says, hey, we can actually
[01:12:31.260 --> 01:12:33.900]   tell if you're about to get Parkinson's now.
[01:12:33.900 --> 01:12:35.820]   I may not actually want that.
[01:12:35.820 --> 01:12:37.300]   I may not want my data used for that.
[01:12:37.300 --> 01:12:40.940]   I may not want that associated with me.
[01:12:40.940 --> 01:12:42.780]   And we don't really-- we don't talk about that.
[01:12:42.780 --> 01:12:44.900]   So there's the consent.
[01:12:44.900 --> 01:12:46.820]   We don't know how our data is going to be used over time.
[01:12:46.820 --> 01:12:49.260]   And then there's just straight up consent.
[01:12:49.260 --> 01:12:50.660]   You put stuff in your house.
[01:12:50.660 --> 01:12:55.380]   And sometimes people don't understand what you can see.
[01:12:55.380 --> 01:12:57.740]   And I talk about tracking my husband on the Tesla
[01:12:57.740 --> 01:12:59.500]   all the time through the app.
[01:12:59.500 --> 01:13:02.900]   And during the holiday season, I am shameless.
[01:13:02.900 --> 01:13:05.660]   I will see if what stores he has parked in front of.
[01:13:05.660 --> 01:13:06.700]   So I can tell when I'm getting worse.
[01:13:06.700 --> 01:13:07.700]   Oh, you are terrible.
[01:13:07.700 --> 01:13:09.420]   Oh, that is awful.
[01:13:09.420 --> 01:13:10.180]   Isn't that terrible?
[01:13:10.180 --> 01:13:11.660]   Don't you want surprises?
[01:13:11.660 --> 01:13:12.700]   That is terrible.
[01:13:12.700 --> 01:13:14.420]   So yeah.
[01:13:14.420 --> 01:13:15.620]   And then the other--
[01:13:15.620 --> 01:13:16.820]   In fact, that you know--
[01:13:16.820 --> 01:13:17.780]   It's still a surprise.
[01:13:17.780 --> 01:13:19.980]   It's just where it came from.
[01:13:19.980 --> 01:13:23.020]   Like jewelry this year.
[01:13:23.020 --> 01:13:26.540]   Now, dear, I just bought you the velvet stand there on.
[01:13:26.540 --> 01:13:27.820]   Yeah, I got you a box.
[01:13:27.820 --> 01:13:28.820]   You need more.
[01:13:28.820 --> 01:13:31.620]   You need more jewelry stands.
[01:13:31.620 --> 01:13:35.300]   But the other thing is talking to the people who
[01:13:35.300 --> 01:13:38.540]   live in your home about the stuff you're putting into your home
[01:13:38.540 --> 01:13:41.580]   and what you can see is really important.
[01:13:41.580 --> 01:13:44.540]   And so Google actually did a good job.
[01:13:44.540 --> 01:13:46.940]   I got a review unit at the Nest Audio,
[01:13:46.940 --> 01:13:48.460]   and I'll show you all that later if you want.
[01:13:48.460 --> 01:13:49.860]   Oh, oh, oh, oh.
[01:13:49.860 --> 01:13:50.380]   Yeah.
[01:13:50.380 --> 01:13:51.020]   OK.
[01:13:51.020 --> 01:13:52.100]   It was my thing.
[01:13:52.100 --> 01:13:53.500]   So we're going to talk about it later.
[01:13:53.500 --> 01:13:55.060]   We're going to talk about it later.
[01:13:55.060 --> 01:13:58.060]   But when I signed up for it and added it,
[01:13:58.060 --> 01:14:02.020]   I got a little note on my screen saying, hey, by the way,
[01:14:02.020 --> 01:14:04.700]   if you have other people in your house using this,
[01:14:04.700 --> 01:14:06.900]   if they don't link their commands--
[01:14:06.900 --> 01:14:09.620]   if they don't link this device to their Google account,
[01:14:09.620 --> 01:14:12.620]   their commands are going to show up in my account.
[01:14:12.620 --> 01:14:14.060]   So let's say it's like--
[01:14:14.060 --> 01:14:14.900]   Oh.
[01:14:14.900 --> 01:14:16.660]   It's asking-- and it just let me know.
[01:14:16.660 --> 01:14:17.500]   So it was like--
[01:14:17.500 --> 01:14:18.300]   Well, the guest account.
[01:14:18.300 --> 01:14:20.020]   Yeah, that's just going to be in the change log.
[01:14:20.020 --> 01:14:21.340]   But go ahead.
[01:14:21.340 --> 01:14:21.580]   Yeah.
[01:14:21.580 --> 01:14:22.780]   So they're like, let people know.
[01:14:22.780 --> 01:14:23.140]   I like that.
[01:14:23.140 --> 01:14:25.420]   Which I was like, I tell companies
[01:14:25.420 --> 01:14:26.660]   they should let people know.
[01:14:26.660 --> 01:14:27.380]   Because--
[01:14:27.380 --> 01:14:28.740]   It's not well publicized.
[01:14:28.740 --> 01:14:32.660]   You have to say, turn on guest mode for it to work.
[01:14:32.660 --> 01:14:35.140]   So yeah, anyway, I just wanted to talk about that.
[01:14:35.140 --> 01:14:36.260]   Because I think it's really--
[01:14:36.260 --> 01:14:37.260]   So talk about your list.
[01:14:37.260 --> 01:14:39.740]   I like your list in your post a lot, Stacy.
[01:14:39.740 --> 01:14:40.420]   Oh, good.
[01:14:40.420 --> 01:14:40.900]   OK.
[01:14:40.900 --> 01:14:42.020]   Let's find that list.
[01:14:42.020 --> 01:14:43.500]   This is Stacy on IT.
[01:14:43.500 --> 01:14:45.860]   And then after we do that, I want to take a break.
[01:14:45.860 --> 01:14:46.860]   But we--
[01:14:46.860 --> 01:14:49.780]   because we had to take a little breather
[01:14:49.780 --> 01:14:51.500]   after the beginning of this show.
[01:14:51.500 --> 01:14:52.500]   Yeah, we did.
[01:14:52.500 --> 01:14:54.260]   Because my blood pressure was a little high.
[01:14:54.260 --> 01:14:59.140]   But now we're going to go back because the Supreme Court today
[01:14:59.140 --> 01:15:01.620]   is hearing Google versus Oracle.
[01:15:01.620 --> 01:15:02.260]   Oh, it is OK.
[01:15:02.260 --> 01:15:03.620]   So that's another one to talk.
[01:15:03.620 --> 01:15:05.140]   The story that never ends.
[01:15:05.140 --> 01:15:07.220]   Ooh, it's a never ending story.
[01:15:07.220 --> 01:15:08.260]   So we'll get to that.
[01:15:08.260 --> 01:15:10.100]   But they're nine.
[01:15:10.100 --> 01:15:12.900]   We should talk about consent in IoT.
[01:15:12.900 --> 01:15:14.540]   This is the story.
[01:15:14.540 --> 01:15:15.020]   Yeah.
[01:15:15.020 --> 01:15:16.380]   OK.
[01:15:16.380 --> 01:15:18.940]   First one, so most of these are really no brainers.
[01:15:18.940 --> 01:15:19.780]   And we've talked about them.
[01:15:19.780 --> 01:15:22.460]   Provide transparency about your data collection practices.
[01:15:22.460 --> 01:15:24.100]   Provide transparency about the sensors
[01:15:24.100 --> 01:15:24.940]   inside the device.
[01:15:24.940 --> 01:15:26.060]   So is there a microphone?
[01:15:26.060 --> 01:15:26.820]   Is there a camera?
[01:15:26.820 --> 01:15:27.780]   Blah, blah, blah.
[01:15:27.780 --> 01:15:29.780]   Protect the user's data through encryption
[01:15:29.780 --> 01:15:30.820]   at rest and emotion.
[01:15:30.820 --> 01:15:32.620]   So be good with data.
[01:15:32.620 --> 01:15:34.820]   Promote safe data practices with partners.
[01:15:34.820 --> 01:15:40.220]   That's-- make sure your partners aren't leaving their stuff
[01:15:40.220 --> 01:15:44.660]   on an unprotected S3 server, right?
[01:15:44.660 --> 01:15:47.140]   Develop a clear practice around the use of data
[01:15:47.140 --> 01:15:49.140]   after a merger and acquisition.
[01:15:49.140 --> 01:15:52.660]   And I know that you can't do this exactly.
[01:15:52.660 --> 01:15:54.220]   But we should be talking about it,
[01:15:54.220 --> 01:15:58.060]   because I think the data is going to become only more valuable.
[01:15:58.060 --> 01:16:00.900]   And explain your data deletion process or policy
[01:16:00.900 --> 01:16:03.140]   and give consumers a chance to delete their data.
[01:16:03.140 --> 01:16:06.980]   I think, actually, if Google buys Fitbit,
[01:16:06.980 --> 01:16:08.420]   that deal goes through, I actually
[01:16:08.420 --> 01:16:10.820]   think maybe Google should give me a chance to say--
[01:16:10.820 --> 01:16:12.180]   I agree.
[01:16:12.180 --> 01:16:13.260]   --get rid of my data.
[01:16:13.260 --> 01:16:15.180]   I don't want you to have that.
[01:16:15.180 --> 01:16:17.420]   Promise users the device will work for x number years.
[01:16:17.420 --> 01:16:19.340]   I talk about that the expiration date.
[01:16:19.340 --> 01:16:21.020]   Patch devices.
[01:16:21.020 --> 01:16:23.620]   And the final one is what I've been talking about,
[01:16:23.620 --> 01:16:25.900]   is push users to ask for consent from others
[01:16:25.900 --> 01:16:27.220]   in their environment.
[01:16:27.220 --> 01:16:31.820]   And that's telling users when they put something in what people
[01:16:31.820 --> 01:16:33.620]   can see and then reminding them.
[01:16:33.620 --> 01:16:35.860]   So this could be a sticker that says, hey,
[01:16:35.860 --> 01:16:39.180]   you're on my doorbell camera that goes up to the cloud.
[01:16:39.180 --> 01:16:44.300]   It might be things like, hey, if my smart oven, which--
[01:16:44.300 --> 01:16:47.060]   if you download the app, you see what people are cooking,
[01:16:47.060 --> 01:16:49.500]   remind the people in the house, like, hey,
[01:16:49.500 --> 01:16:52.140]   tell your family that you can see if they're baking cookies
[01:16:52.140 --> 01:16:54.660]   or they're baking roasting broccoli.
[01:16:54.660 --> 01:16:55.660]   That's something that they can--
[01:16:55.660 --> 01:16:58.340]   It should be like when you're on an airplane in the exit row.
[01:16:58.340 --> 01:17:00.420]   And the flight attendant comes to you and says,
[01:17:00.420 --> 01:17:06.820]   I need you to say yes to agree to this exit row policy.
[01:17:06.820 --> 01:17:08.220]   But how would you enforce that?
[01:17:08.220 --> 01:17:09.060]   Would Google say--
[01:17:09.060 --> 01:17:09.580]   But you don't--
[01:17:09.580 --> 01:17:10.580]   --it's just this isn't a wonderful device.
[01:17:10.580 --> 01:17:11.500]   --it's just this isn't a wonderful device.
[01:17:11.500 --> 01:17:16.100]   --because I'm going to ask you if you agree.
[01:17:16.100 --> 01:17:19.340]   It's a reminder to the people buying this device
[01:17:19.340 --> 01:17:22.300]   that the device affects everyone in the household.
[01:17:22.300 --> 01:17:23.300]   It's a norm.
[01:17:23.300 --> 01:17:24.220]   It's not a law.
[01:17:24.220 --> 01:17:24.820]   It's a norm.
[01:17:24.820 --> 01:17:26.060]   Today, or that you put out.
[01:17:26.060 --> 01:17:29.140]   Today, I go in to use the Pilates reformer.
[01:17:29.140 --> 01:17:32.460]   A 17 soon to be 18-year-old son uses it every day.
[01:17:32.460 --> 01:17:35.260]   And the Google nest is face down,
[01:17:35.260 --> 01:17:36.700]   even though there's no camera on it.
[01:17:36.700 --> 01:17:38.140]   I don't think he's figured that out.
[01:17:38.140 --> 01:17:39.660]   But it's face down.
[01:17:39.660 --> 01:17:43.780]   And I understand he doesn't know where that video would go.
[01:17:43.780 --> 01:17:45.900]   And he doesn't want it--
[01:17:45.900 --> 01:17:47.740]   he prefers a privacy.
[01:17:47.740 --> 01:17:48.340]   So--
[01:17:48.340 --> 01:17:49.140]   --the thing is--
[01:17:49.140 --> 01:17:49.740]   --the only question--
[01:17:49.740 --> 01:17:51.540]   --to get people to take this stuff seriously
[01:17:51.540 --> 01:17:53.340]   from a consumer standpoint.
[01:17:53.340 --> 01:17:56.260]   You can tell them about all this stuff till you blew in the face.
[01:17:56.260 --> 01:17:57.660]   And they're going to go ahead and just click--
[01:17:57.660 --> 01:17:58.060]   Yeah, I--
[01:17:58.060 --> 01:17:58.340]   --see 10 minutes.
[01:17:58.340 --> 01:18:00.540]   --if you went around to the hard heads and said, hey,
[01:18:00.540 --> 01:18:03.980]   dudes, just so you know everything you say can be heard
[01:18:03.980 --> 01:18:07.500]   by that Amazon Echo device or that Google Voice device,
[01:18:07.500 --> 01:18:09.540]   what would that reaction be?
[01:18:09.540 --> 01:18:10.740]   I've had that discussion.
[01:18:10.740 --> 01:18:11.640]   Good.
[01:18:11.640 --> 01:18:14.180]   They all give me that look of, oh, wow.
[01:18:14.180 --> 01:18:14.860]   Yeah, just kidding.
[01:18:14.860 --> 01:18:16.020]   They don't know.
[01:18:16.020 --> 01:18:17.220]   And that's OK.
[01:18:17.220 --> 01:18:19.180]   But the point is that you're doing it.
[01:18:19.180 --> 01:18:21.700]   You're giving people a real choice.
[01:18:21.700 --> 01:18:26.220]   So when people come into my house now, I'm like, hey, by the way,
[01:18:26.220 --> 01:18:28.300]   I have smart speakers everywhere.
[01:18:28.300 --> 01:18:30.140]   And their mics are on.
[01:18:30.140 --> 01:18:32.060]   And is it a weird thing to say?
[01:18:32.060 --> 01:18:33.140]   Yes.
[01:18:33.140 --> 01:18:35.620]   But do I feel better for having said it?
[01:18:35.620 --> 01:18:37.100]   Yes.
[01:18:37.100 --> 01:18:39.620]   And honestly, we should be doing it for phones,
[01:18:39.620 --> 01:18:43.300]   because phones are just as potentially problematic
[01:18:43.300 --> 01:18:44.420]   as some of these devices.
[01:18:44.420 --> 01:18:44.980]   But--
[01:18:44.980 --> 01:18:45.620]   Well, we do.
[01:18:45.620 --> 01:18:46.460]   We do the school.
[01:18:46.460 --> 01:18:47.220]   This is a model.
[01:18:47.220 --> 01:18:49.180]   So the school, I had a little effect,
[01:18:49.180 --> 01:18:51.060]   because every time we had an event,
[01:18:51.060 --> 01:18:51.980]   somebody had to go around.
[01:18:51.980 --> 01:18:53.940]   And they were having people sign releases,
[01:18:53.940 --> 01:18:56.140]   because we were going to put it on YouTube.
[01:18:56.140 --> 01:18:58.220]   And I said, what the hell are we doing here?
[01:18:58.220 --> 01:19:01.740]   Let's put up a sign that says, you're in this space.
[01:19:01.740 --> 01:19:03.740]   We are going to record things here.
[01:19:03.740 --> 01:19:06.700]   And it's big and visible and known.
[01:19:06.700 --> 01:19:08.060]   And anybody there could never say
[01:19:08.060 --> 01:19:09.540]   that they don't know that they can be recorded.
[01:19:09.540 --> 01:19:10.820]   If they don't want to be recorded,
[01:19:10.820 --> 01:19:12.860]   they can go sit in a place where they're not recorded.
[01:19:12.860 --> 01:19:14.060]   They can leave the event.
[01:19:14.060 --> 01:19:14.900]   There's lots of options.
[01:19:14.900 --> 01:19:17.220]   But we're running the event.
[01:19:17.220 --> 01:19:17.780]   It's our money.
[01:19:17.780 --> 01:19:19.460]   So we say, this is what we're doing.
[01:19:19.460 --> 01:19:19.980]   That's a rule.
[01:19:19.980 --> 01:19:20.700]   That's interesting.
[01:19:20.700 --> 01:19:21.260]   It is--
[01:19:21.260 --> 01:19:24.420]   It's prepared litigation litigation litigation, though.
[01:19:24.420 --> 01:19:24.860]   That's all that is.
[01:19:24.860 --> 01:19:26.900]   Yeah, the school is an interesting space,
[01:19:26.900 --> 01:19:28.460]   because the school--
[01:19:28.460 --> 01:19:31.620]   we sign-- actually, I don't sign the releases
[01:19:31.620 --> 01:19:33.260]   for my daughter's school, right?
[01:19:33.260 --> 01:19:36.860]   So they have to blackout her image and everything.
[01:19:36.860 --> 01:19:39.340]   But they do that because she's underage.
[01:19:39.340 --> 01:19:42.540]   So I don't know if your school does it, because--
[01:19:42.540 --> 01:19:44.380]   Or we're graduate school.
[01:19:44.380 --> 01:19:46.940]   OK, so then no, because--
[01:19:46.940 --> 01:19:48.740]   and also because she doesn't have a choice.
[01:19:48.740 --> 01:19:51.620]   I mean, I know that if you're doing an event,
[01:19:51.620 --> 01:19:52.700]   it's a little bit different.
[01:19:52.700 --> 01:19:54.020]   But she's got to be in school.
[01:19:54.020 --> 01:19:55.180]   It's not for classes.
[01:19:55.180 --> 01:19:56.420]   In fact, we are going to go with--
[01:19:56.420 --> 01:19:58.420]   We're going to go with the hard heads in North Carolina.
[01:19:58.420 --> 01:20:00.340]   And this school would send out the notifications
[01:20:00.340 --> 01:20:02.580]   about the privacy and things like that.
[01:20:02.580 --> 01:20:05.460]   And I've saw on both sides of the coin
[01:20:05.460 --> 01:20:07.580]   where people were really, really upset
[01:20:07.580 --> 01:20:10.260]   that this was being sent down because they never really
[01:20:10.260 --> 01:20:12.580]   considered the privacy implications.
[01:20:12.580 --> 01:20:14.260]   And then you had the other set that's like, wow,
[01:20:14.260 --> 01:20:14.820]   this is good.
[01:20:14.820 --> 01:20:16.140]   They're thinking about it and trying
[01:20:16.140 --> 01:20:20.380]   to protect our children, so on and so forth.
[01:20:20.380 --> 01:20:24.380]   Me, I didn't even worry about it because my kids are athletes,
[01:20:24.380 --> 01:20:26.860]   which means newspapers are going to come around to talk
[01:20:26.860 --> 01:20:29.540]   about said athletes and their names and pictures
[01:20:29.540 --> 01:20:30.700]   going to be all over the paper.
[01:20:30.700 --> 01:20:32.740]   So I'm like, yeah, that's part of territory.
[01:20:32.740 --> 01:20:33.100]   So--
[01:20:33.100 --> 01:20:34.780]   But you're going to buy the papers because the result--
[01:20:34.780 --> 01:20:36.260]   and that's the economic summit, right?
[01:20:36.260 --> 01:20:37.380]   We always said more names.
[01:20:37.380 --> 01:20:39.380]   You put the paper, the more papers you sell.
[01:20:39.380 --> 01:20:41.260]   That's it.
[01:20:41.260 --> 01:20:43.100]   So Stacy, the one thing I think requires
[01:20:43.100 --> 01:20:46.500]   to put it in your normal nature, more discussion,
[01:20:46.500 --> 01:20:50.460]   is the concept of my data, right?
[01:20:50.460 --> 01:20:53.500]   Because in transactions, there's always two sides to it.
[01:20:53.500 --> 01:20:56.420]   And the other party says, well, it's mine too.
[01:20:56.420 --> 01:21:02.500]   And so there needs to be some ability
[01:21:02.500 --> 01:21:06.980]   to come to understandings about that that recognizes
[01:21:06.980 --> 01:21:11.020]   that multiple parties to data each have a right
[01:21:11.020 --> 01:21:16.420]   and that there isn't a singular right in all cases to all data.
[01:21:16.420 --> 01:21:18.940]   And once we start talking about that,
[01:21:18.940 --> 01:21:21.220]   we also probably will come to the conclusion
[01:21:21.220 --> 01:21:23.540]   that some data is different than others, right?
[01:21:23.540 --> 01:21:26.300]   Knowing that my house has a kitchen
[01:21:26.300 --> 01:21:28.420]   is very different than knowing that last night I only
[01:21:28.420 --> 01:21:30.100]   slept for four hours, right?
[01:21:30.100 --> 01:21:35.380]   So I think we get stuck on regulatory things
[01:21:35.380 --> 01:21:38.420]   because we don't really dig into that.
[01:21:38.420 --> 01:21:39.780]   Anyway, we're back to regulation.
[01:21:39.780 --> 01:21:40.620]   What else is happening?
[01:21:40.620 --> 01:21:42.060]   Yeah, so let's keep going here.
[01:21:42.060 --> 01:21:42.900]   Yeah, let's keep going.
[01:21:42.900 --> 01:21:44.820]   All right, well, let's take a break and then--
[01:21:44.820 --> 01:21:46.660]   We were buying time for you, Leo, is what we're doing.
[01:21:46.660 --> 01:21:47.420]   I bought him.
[01:21:47.420 --> 01:21:48.580]   Yeah, were you doing something?
[01:21:48.580 --> 01:21:49.180]   I bought him.
[01:21:49.180 --> 01:21:50.900]   Oh, yeah, you bought a thing.
[01:21:50.900 --> 01:21:51.940]   Oh, you bought the Otis.
[01:21:51.940 --> 01:21:52.500]   Otis, Otis.
[01:21:52.500 --> 01:21:53.100]   Yeah, Otis.
[01:21:53.100 --> 01:21:54.980]   Did you all subscribe?
[01:21:54.980 --> 01:21:57.140]   I think they bill you later.
[01:21:57.140 --> 01:22:00.700]   But the problem is they say on the weekends.
[01:22:00.700 --> 01:22:03.100]   So I'm going to be here working.
[01:22:03.100 --> 01:22:04.460]   And all of a sudden, those speakers
[01:22:04.460 --> 01:22:06.940]   are going to leap into life.
[01:22:06.940 --> 01:22:07.580]   They also--
[01:22:07.580 --> 01:22:08.060]   There's a hell on you.
[01:22:08.060 --> 01:22:11.380]   I didn't recognize any of those artists unless--
[01:22:11.380 --> 01:22:13.580]   I think Lana-- what's her name?
[01:22:13.580 --> 01:22:14.500]   Lana Del-- not Del.
[01:22:14.500 --> 01:22:15.540]   I don't like Lana Del.
[01:22:15.540 --> 01:22:15.980]   I don't like Lana Del.
[01:22:15.980 --> 01:22:17.740]   I hope it's not Lana Del.
[01:22:17.740 --> 01:22:21.460]   I'm going to assume it's more like folky acoustic.
[01:22:21.460 --> 01:22:23.700]   Well, tonight, the one tonight was--
[01:22:23.700 --> 01:22:25.180]   I should have said yes, so we could have
[01:22:25.180 --> 01:22:26.380]   also do it together maybe--
[01:22:26.380 --> 01:22:29.980]   is a jazz piece for Sunset in New York.
[01:22:29.980 --> 01:22:33.260]   Something acoustic, so it'll play well on these speakers.
[01:22:33.260 --> 01:22:35.740]   It looked like they're tuned for a performance.
[01:22:35.740 --> 01:22:40.580]   They did say Terrence Riley, but that can't be Terry Riley,
[01:22:40.580 --> 01:22:41.860]   the synthesizer guy.
[01:22:41.860 --> 01:22:42.860]   That must be somebody else.
[01:22:42.860 --> 01:22:45.860]   So I didn't recognize anybody else on there.
[01:22:45.860 --> 01:22:47.580]   Our show-- we're going to take a break, come back,
[01:22:47.580 --> 01:22:50.540]   Supreme Court time.
[01:22:50.540 --> 01:22:52.660]   And you're going to put on your ropes and wig.
[01:22:52.660 --> 01:22:54.380]   What a thrilling--
[01:22:54.380 --> 01:22:54.980]   That's a tease.
[01:22:54.980 --> 01:22:55.740]   Ticular that is.
[01:22:55.740 --> 01:22:56.740]   Look at that.
[01:22:56.740 --> 01:22:59.980]   It's going to be in charge of our graphics from now.
[01:22:59.980 --> 01:23:01.700]   Can you say, already, put up a sign that says,
[01:23:01.700 --> 01:23:04.300]   Google versus Oracle.
[01:23:04.300 --> 01:23:06.940]   Study up, because that's the topic when we come back.
[01:23:06.940 --> 01:23:10.780]   Our show today brought to you by Melissa.
[01:23:10.780 --> 01:23:15.780]   If you ever forgot to check the best buy
[01:23:15.780 --> 01:23:17.460]   date on a carton of milk, you probably
[01:23:17.460 --> 01:23:20.420]   know what I'm talking about here when I say,
[01:23:20.420 --> 01:23:24.260]   there's nothing worse when your customer data goes bad.
[01:23:24.260 --> 01:23:27.180]   They can really put a crimp in your Rice Krispies.
[01:23:27.180 --> 01:23:32.740]   30% of customer data goes bad every year.
[01:23:32.740 --> 01:23:33.980]   Email addresses change.
[01:23:33.980 --> 01:23:34.860]   People move.
[01:23:34.860 --> 01:23:36.460]   Phone numbers change.
[01:23:36.460 --> 01:23:38.780]   Melissa has one job--
[01:23:38.780 --> 01:23:41.740]   to make sure your data is accurate and current.
[01:23:41.740 --> 01:23:44.100]   So you don't pester the wrong customers.
[01:23:44.100 --> 01:23:46.060]   You get to the right customers.
[01:23:46.060 --> 01:23:48.700]   You don't send multiple copies of your catalog
[01:23:48.700 --> 01:23:49.940]   or your brochure.
[01:23:49.940 --> 01:23:52.700]   Melissa got into this business 35 years ago.
[01:23:52.700 --> 01:23:54.980]   At the time, they were verifying zip codes.
[01:23:54.980 --> 01:23:57.100]   But as times have changed, there's
[01:23:57.100 --> 01:23:59.340]   a lot more customer data.
[01:23:59.340 --> 01:24:03.100]   And Melissa can verify it for you automatically.
[01:24:03.100 --> 01:24:04.660]   They have so many ways to do this.
[01:24:04.660 --> 01:24:06.340]   Even they have an API, so you could
[01:24:06.340 --> 01:24:07.860]   build this into your own software.
[01:24:07.860 --> 01:24:11.860]   Verify addresses, emails, phone numbers, and names
[01:24:11.860 --> 01:24:12.820]   in real time.
[01:24:12.820 --> 01:24:14.380]   Bad data happens.
[01:24:14.380 --> 01:24:17.580]   It's pretty darn easy.
[01:24:17.580 --> 01:24:21.420]   Fumble-fingered customer service reps or customers.
[01:24:21.420 --> 01:24:24.540]   Just accidentally putting in a wrong number or a digit.
[01:24:24.540 --> 01:24:25.660]   You don't want that to happen.
[01:24:25.660 --> 01:24:27.860]   When somebody's there ordering your beautiful speakers,
[01:24:27.860 --> 01:24:29.700]   you want to make sure they get to you.
[01:24:29.700 --> 01:24:31.780]   And you get to them, right?
[01:24:31.780 --> 01:24:34.420]   Melissa can also match and consolidate your records.
[01:24:34.420 --> 01:24:36.260]   They're matching in deduplication tools
[01:24:36.260 --> 01:24:39.020]   to help you uncover, merge, and purge.
[01:24:39.020 --> 01:24:40.660]   Hard to find duplicate records.
[01:24:40.660 --> 01:24:42.580]   Anybody's ever synced to their contact list.
[01:24:42.580 --> 01:24:45.620]   Knows how easy that is to get duplicates in there.
[01:24:45.620 --> 01:24:48.580]   You want an accurate view of your customers.
[01:24:48.580 --> 01:24:49.900]   And they are so flexible.
[01:24:49.900 --> 01:24:52.140]   Melissa can work on premises.
[01:24:52.140 --> 01:24:53.940]   They can work as a web service.
[01:24:53.940 --> 01:24:56.700]   They offer secure FTP upload and download.
[01:24:56.700 --> 01:24:58.380]   So you can just upload them a customer list
[01:24:58.380 --> 01:25:00.340]   and download the corrected version.
[01:25:00.340 --> 01:25:02.820]   It's also software as a service.
[01:25:02.820 --> 01:25:04.300]   And they've got a complete API.
[01:25:04.300 --> 01:25:07.420]   I mean, you can do this however works for you.
[01:25:07.420 --> 01:25:11.100]   And don't ever worry that your data isn't safe at Melissa.
[01:25:11.100 --> 01:25:14.340]   They continually undergo independent security audits
[01:25:14.340 --> 01:25:17.980]   to reinforce their commitment to data security, privacy,
[01:25:17.980 --> 01:25:19.620]   and compliance requirements.
[01:25:19.620 --> 01:25:21.900]   They've got an absolute dedication
[01:25:21.900 --> 01:25:23.860]   to the safety and security of your data.
[01:25:23.860 --> 01:25:27.860]   Strong controls and safeguards at every step of the way.
[01:25:27.860 --> 01:25:30.300]   No wonder over 10,000 businesses trust
[01:25:30.300 --> 01:25:32.020]   the address experts.
[01:25:32.020 --> 01:25:34.540]   You could trust Melissa to be your foundation
[01:25:34.540 --> 01:25:36.660]   for data-driven success.
[01:25:36.660 --> 01:25:40.580]   Melissa can even help you supplement that data.
[01:25:40.580 --> 01:25:43.460]   You can add public information, demographic information
[01:25:43.460 --> 01:25:45.340]   to your records like property and mortgage data,
[01:25:45.340 --> 01:25:47.820]   marital status, social media handles.
[01:25:47.820 --> 01:25:49.900]   Melissa will fill in the gaps by adding emails
[01:25:49.900 --> 01:25:51.260]   and phone numbers.
[01:25:51.260 --> 01:25:54.060]   And you can identify current customers,
[01:25:54.060 --> 01:25:56.700]   which will then let you find new prospective customers
[01:25:56.700 --> 01:26:00.020]   because Melissa maintains a prospect database as well.
[01:26:00.020 --> 01:26:01.260]   Look, they've got it all.
[01:26:01.260 --> 01:26:05.700]   And just to kind of reach out to people who are essential workers
[01:26:05.700 --> 01:26:09.620]   and nonprofits during the crisis, the COVID-19 crisis,
[01:26:09.620 --> 01:26:11.620]   they are offering six months of free service
[01:26:11.620 --> 01:26:13.140]   to qualifying organizations.
[01:26:13.140 --> 01:26:15.620]   So visit the website, apply online.
[01:26:15.620 --> 01:26:16.460]   They're nice people.
[01:26:16.460 --> 01:26:19.420]   Don't put up with sour customer contact data.
[01:26:19.420 --> 01:26:22.180]   Trimalist is APIs right there in the developer portal.
[01:26:22.180 --> 01:26:25.540]   It's easy to log on, sign up, and start playing
[01:26:25.540 --> 01:26:28.060]   in the sandbox 24/7.
[01:26:28.060 --> 01:26:32.820]   And just as a little hello, 1,000 records clean for free
[01:26:32.820 --> 01:26:35.580]   when you go right now to melissa.com/twit.
[01:26:35.580 --> 01:26:40.580]   M-E-L-I-S-S-A, melissa.com/twit.
[01:26:40.580 --> 01:26:46.900]   We thank you, Melissa, for supporting this week in Google.
[01:26:46.900 --> 01:26:55.140]   Oracle versus Google, the case that just never ends.
[01:26:55.140 --> 01:26:57.820]   How long has this been going on?
[01:26:57.820 --> 01:26:59.940]   It feels like-- What was it show?
[01:26:59.940 --> 01:27:00.940]   How long's Android?
[01:27:00.940 --> 01:27:02.180]   Was it just streamline?
[01:27:02.180 --> 01:27:04.260]   It's been forever.
[01:27:04.260 --> 01:27:06.820]   This will be the last time.
[01:27:06.820 --> 01:27:09.060]   This will be the last time.
[01:27:09.060 --> 01:27:14.140]   This will be the-- 10 years ago, Oracle first sued Google.
[01:27:14.140 --> 01:27:18.100]   The issue was Oracle owns Java.
[01:27:18.100 --> 01:27:20.420]   Android is built on Java.
[01:27:20.420 --> 01:27:25.300]   Oracle says, we never licensed Java to you.
[01:27:25.300 --> 01:27:30.100]   In the 10 years, there have been three trials, two appeals.
[01:27:30.100 --> 01:27:34.100]   Millions spent on a parade of-- I'm reading for the Verge--
[01:27:34.100 --> 01:27:37.860]   seasoned litigators, expert witnesses, and bizarre trial
[01:27:37.860 --> 01:27:40.580]   exhibits intended to explain programming
[01:27:40.580 --> 01:27:43.140]   to not technical juries.
[01:27:43.140 --> 01:27:46.220]   It may all have ended this morning.
[01:27:46.220 --> 01:27:48.780]   Of course, they no longer-- it's a teleconference.
[01:27:48.780 --> 01:27:50.740]   They don't go in person at the Supreme Court.
[01:27:50.740 --> 01:27:52.860]   But the oral arguments were today.
[01:27:52.860 --> 01:27:54.660]   Decisions usually take a few months,
[01:27:54.660 --> 01:27:57.980]   so it's not going to be decided today.
[01:27:57.980 --> 01:28:01.580]   But it's really interesting to know what this is all about.
[01:28:01.580 --> 01:28:10.820]   That issue is not the fact that Google used Java.
[01:28:10.820 --> 01:28:12.220]   They didn't.
[01:28:12.220 --> 01:28:14.860]   They used the Java API.
[01:28:14.860 --> 01:28:20.700]   In fact, 37 specific APIs that are at issue in the lawsuit.
[01:28:20.700 --> 01:28:25.660]   Oracle says, we own a piece of Android, billions of dollars
[01:28:25.660 --> 01:28:31.140]   worth of Android, because you used not Java, but our API.
[01:28:31.140 --> 01:28:34.460]   The issue is, can an API be copyrighted?
[01:28:34.460 --> 01:28:39.340]   Low courts have ruled that, yes, an API can be copyrighted.
[01:28:39.340 --> 01:28:46.700]   There are issues, because after all, Oracle, among other things,
[01:28:46.700 --> 01:28:49.860]   copies Amazons API.
[01:28:49.860 --> 01:28:55.820]   They're S3 API for Oracle's own database offerings online.
[01:28:55.820 --> 01:28:58.100]   Oracle says, oh, no, that's different.
[01:28:58.100 --> 01:29:05.300]   Let me get Mike Masnick's article, because he talks about this.
[01:29:05.300 --> 01:29:09.540]   Mike has so many good stories.
[01:29:09.540 --> 01:29:13.020]   We could just make this the Mike Masnick Tech Dirt show,
[01:29:13.020 --> 01:29:14.620]   honestly.
[01:29:14.620 --> 01:29:16.100]   Let me see if I can find this story.
[01:29:16.100 --> 01:29:21.100]   It's buried now, because he's talking about so much other stuff.
[01:29:21.100 --> 01:29:24.420]   Oh, God Lord.
[01:29:24.420 --> 01:29:27.340]   I might have to go back to Google and search for it.
[01:29:27.340 --> 01:29:28.660]   I think I do.
[01:29:28.660 --> 01:29:29.180]   Let's see.
[01:29:29.180 --> 01:29:30.620]   Can we get Mike back on the show?
[01:29:30.620 --> 01:29:31.780]   Will Stacy at the same time?
[01:29:31.780 --> 01:29:32.300]   Yes.
[01:29:32.300 --> 01:29:32.300]   Great.
[01:29:32.300 --> 01:29:32.700]   He's just great.
[01:29:32.700 --> 01:29:35.020]   Oh, he's never been here with Stacy.
[01:29:35.020 --> 01:29:35.460]   Right.
[01:29:35.460 --> 01:29:37.020]   Oh, yeah.
[01:29:37.020 --> 01:29:37.540]   He's so sorry.
[01:29:37.540 --> 01:29:39.500]   Did he sub for you?
[01:29:39.500 --> 01:29:41.220]   I think he subbed for me a lot.
[01:29:41.220 --> 01:29:42.260]   Yeah.
[01:29:42.260 --> 01:29:44.620]   I mean, I've met Mike, and we've--
[01:29:44.620 --> 01:29:45.260]   Where was he?
[01:29:45.260 --> 01:29:46.900]   He had this like, I love your work.
[01:29:46.900 --> 01:29:47.740]   I love your work.
[01:29:47.740 --> 01:29:49.500]   Oh, that's nice.
[01:29:49.500 --> 01:29:50.660]   Oh, that's nice.
[01:29:50.660 --> 01:29:51.820]   No, you're so smart.
[01:29:51.820 --> 01:29:53.300]   It was mostly me just telling you he's smart.
[01:29:53.300 --> 01:29:55.380]   But he was gracious and did say he thought I was smart,
[01:29:55.380 --> 01:29:55.940]   which was nice.
[01:29:55.940 --> 01:29:56.980]   Well, you're both smart.
[01:29:56.980 --> 01:29:58.340]   So there.
[01:29:58.340 --> 01:30:00.580]   I'm like, he's very smart about things I am not smart about.
[01:30:00.580 --> 01:30:01.260]   Of course, I didn't--
[01:30:01.260 --> 01:30:02.660]   And I don't really want to be smart.
[01:30:02.660 --> 01:30:05.220]   I, however, am reductions to whatever's smart.
[01:30:05.220 --> 01:30:06.060]   Oh, my gosh.
[01:30:06.060 --> 01:30:07.300]   I'm never going to live it down.
[01:30:07.300 --> 01:30:09.980]   Oh, yeah.
[01:30:09.980 --> 01:30:12.140]   That was careless use of the English language.
[01:30:12.180 --> 01:30:15.500]   [LAUGHTER]
[01:30:15.500 --> 01:30:16.820]   It was a third grade moment.
[01:30:16.820 --> 01:30:18.580]   It's scolding for that, yes.
[01:30:18.580 --> 01:30:20.060]   Oh, come on.
[01:30:20.060 --> 01:30:21.060]   So you said--
[01:30:21.060 --> 01:30:22.620]   I was like a third grade.
[01:30:22.620 --> 01:30:23.740]   This was from October 1st.
[01:30:23.740 --> 01:30:24.980]   We're trying to vamp for you, Leo.
[01:30:24.980 --> 01:30:25.700]   Do you find the thing?
[01:30:25.700 --> 01:30:27.980]   Oracle is wrong about having permission
[01:30:27.980 --> 01:30:31.540]   to re-implement Amazon's API, but they should need it.
[01:30:31.540 --> 01:30:35.620]   [LAUGHTER]
[01:30:35.620 --> 01:30:39.300]   Apparently-- oh, it has to do with bacon.
[01:30:39.300 --> 01:30:40.860]   And it's like too complicated.
[01:30:40.860 --> 01:30:42.340]   OK, a lot.
[01:30:42.340 --> 01:30:43.740]   Well, an API is--
[01:30:43.740 --> 01:30:46.580]   I mean, if Oracle was really pissed,
[01:30:46.580 --> 01:30:49.020]   they could change the APIs and break it.
[01:30:49.020 --> 01:30:50.780]   But no, it doesn't break it for everybody.
[01:30:50.780 --> 01:30:51.780]   Yeah.
[01:30:51.780 --> 01:30:53.740]   [LAUGHTER]
[01:30:53.740 --> 01:30:57.900]   Is Google still using it, or do they long ago get rid of it?
[01:30:57.900 --> 01:30:58.860]   That's a good question.
[01:30:58.860 --> 01:31:04.180]   I think they probably have proactively moved on.
[01:31:04.180 --> 01:31:05.860]   Maybe that was the point of Dalvik.
[01:31:05.860 --> 01:31:10.900]   [SIGHS]
[01:31:10.900 --> 01:31:12.220]   Google says--
[01:31:12.220 --> 01:31:13.740]   Dalvik, how long ago was that?
[01:31:13.740 --> 01:31:14.220]   Yeah.
[01:31:14.220 --> 01:31:18.860]   Google says that there's 11,500 codes
[01:31:18.860 --> 01:31:21.660]   encompassing these 37 Java APIs.
[01:31:21.660 --> 01:31:24.020]   Google says they were written in a clean room, which
[01:31:24.020 --> 01:31:25.380]   is how you do it, right?
[01:31:25.380 --> 01:31:29.860]   You say, we need this code to be given this input
[01:31:29.860 --> 01:31:31.340]   and to come out with this output,
[01:31:31.340 --> 01:31:34.780]   but you figure out how to do it.
[01:31:34.780 --> 01:31:36.380]   It's called reverse engineering.
[01:31:36.380 --> 01:31:36.860]   It's happened.
[01:31:36.860 --> 01:31:39.620]   That's how the PC marketplace started.
[01:31:39.620 --> 01:31:43.220]   Reverse engineering, the original PC BIOS with the Compaq.
[01:31:43.220 --> 01:31:47.620]   Ta, a lot of tech is done today.
[01:31:47.620 --> 01:31:48.580]   A lot of tech.
[01:31:48.580 --> 01:31:49.620]   Yeah.
[01:31:49.620 --> 01:31:52.980]   By the way, Google and Sun, which owned Java at the time,
[01:31:52.980 --> 01:31:54.020]   were in negotiations.
[01:31:54.020 --> 01:31:55.700]   Those negotiations failed.
[01:31:55.700 --> 01:31:57.940]   Oracle bought Sun in 2010.
[01:31:57.940 --> 01:31:59.940]   And I remember talking to Jonathan Schwartz, who
[01:31:59.940 --> 01:32:02.100]   was the CEO of Sun at the time.
[01:32:02.100 --> 01:32:03.460]   He was on a triangulation.
[01:32:03.460 --> 01:32:06.500]   He said, the Oracle lawyers showed up
[01:32:06.500 --> 01:32:08.580]   and were completely uninterested in us
[01:32:08.580 --> 01:32:12.460]   until we mentioned the patents on Java.
[01:32:12.460 --> 01:32:16.900]   And then he said they started rubbing their hands with Glee.
[01:32:16.900 --> 01:32:18.180]   You could make the argument.
[01:32:18.180 --> 01:32:19.940]   I think Jonathan was making the argument.
[01:32:19.940 --> 01:32:22.580]   The only reason Oracle bought Sun
[01:32:22.580 --> 01:32:26.580]   is so that they could go after Google and other companies.
[01:32:26.580 --> 01:32:33.420]   So let's see.
[01:32:33.420 --> 01:32:37.060]   Oracle is not asserting that the APIs are the same.
[01:32:37.060 --> 01:32:40.140]   They are saying that they violate copyright
[01:32:40.140 --> 01:32:44.340]   because they have the same function.
[01:32:44.340 --> 01:32:49.580]   And in fact, if you write code for the Java standard edition,
[01:32:49.580 --> 01:32:54.220]   it won't necessarily run on Android, but this helps.
[01:32:54.220 --> 01:32:58.820]   So the first run at the lawsuit resulted in a bifurcated trial
[01:32:58.820 --> 01:33:02.220]   in 2012, a trial for the patent claims,
[01:33:02.220 --> 01:33:04.460]   and a trial for the patent claims.
[01:33:04.460 --> 01:33:08.460]   The patent trial, the jury, ruled in Google's favor.
[01:33:08.460 --> 01:33:15.180]   In the copyright trial over APIs, the judge ruled.
[01:33:15.180 --> 01:33:19.900]   And the question that Google came down to was,
[01:33:19.900 --> 01:33:22.860]   is it fair use to use the API?
[01:33:22.860 --> 01:33:25.660]   So really fair use is on trial.
[01:33:25.660 --> 01:33:30.540]   That jury hung-- remember, this is the judge who
[01:33:30.540 --> 01:33:34.580]   wrote a Java route to-- like taught himself Java
[01:33:34.580 --> 01:33:39.380]   so that he could be the judge of this trial.
[01:33:39.380 --> 01:33:45.220]   He ruled that the code was not covered by copyright.
[01:33:45.220 --> 01:33:50.860]   However, the federal court in 2014 overturned that.
[01:33:50.860 --> 01:33:53.460]   Another jury trial was convened two years later.
[01:33:53.460 --> 01:33:56.580]   The jury once again ruled for Google.
[01:33:56.580 --> 01:34:00.420]   Two years later, in 2018, the federal circuit court
[01:34:00.420 --> 01:34:03.540]   ruled that the jury verdict had to be set inside in favor
[01:34:03.540 --> 01:34:07.260]   of Oracle because the evidence clearly indicated
[01:34:07.260 --> 01:34:09.780]   no fair use determination could be reached.
[01:34:09.780 --> 01:34:19.820]   Then it went to the Supreme Court, which I think
[01:34:19.820 --> 01:34:21.580]   sent it back down to the lower court.
[01:34:21.580 --> 01:34:23.940]   I was track at this point.
[01:34:23.940 --> 01:34:28.140]   But here's-- this is a big deal because it could really
[01:34:28.140 --> 01:34:32.820]   affect the software industry in general.
[01:34:32.820 --> 01:34:38.180]   The question of whether Java APIs could be covered by copyright
[01:34:38.180 --> 01:34:44.100]   really affects all APIs and whether they are copyrighted
[01:34:44.100 --> 01:34:45.020]   and copyrightable.
[01:34:45.020 --> 01:34:48.580]   And there are so many examples of APIs being duplicated.
[01:34:48.580 --> 01:34:52.220]   As I said, Oracle's even doing that right now with Amazon's S3.
[01:34:52.220 --> 01:34:55.020]   They say, because it's open source, we can do that.
[01:34:55.020 --> 01:35:00.220]   We'll see.
[01:35:00.220 --> 01:35:00.900]   We'll see.
[01:35:00.900 --> 01:35:01.540]   Blue poll.
[01:35:01.540 --> 01:35:03.140]   So it's just a little low poll.
[01:35:03.140 --> 01:35:06.780]   This is the verge writing.
[01:35:06.780 --> 01:35:09.060]   Let me see who wrote this because it's well written.
[01:35:09.060 --> 01:35:13.020]   I'll give the author credit.
[01:35:13.020 --> 01:35:13.780]   It's Sarah John.
[01:35:13.780 --> 01:35:15.340]   She's very good.
[01:35:15.340 --> 01:35:16.580]   She's very good.
[01:35:16.580 --> 01:35:17.080]   Yes.
[01:35:17.080 --> 01:35:22.880]   She says, the decade-long grudge between Grudge
[01:35:22.880 --> 01:35:27.120]   Match between Google and Oracle is not entirely rational.
[01:35:27.120 --> 01:35:29.680]   Google's re-implementation of the Java APIs
[01:35:29.680 --> 01:35:32.800]   is part of a long tradition of iteration that was mostly
[01:35:32.800 --> 01:35:36.320]   taken for granted now, like now, until now.
[01:35:36.320 --> 01:35:42.080]   Products like Oracle's own MySQL were created as an iteration,
[01:35:42.080 --> 01:35:46.760]   aka homage to IBM's SQL.
[01:35:46.760 --> 01:35:51.040]   So to put things roughly, coding is the process
[01:35:51.040 --> 01:35:52.240]   of speaking to the machine.
[01:35:52.240 --> 01:35:54.920]   Very few people who develop software in this day and age
[01:35:54.920 --> 01:35:56.880]   actually speak directly to the machine.
[01:35:56.880 --> 01:35:59.400]   Software exists in layers upon layers,
[01:35:59.400 --> 01:36:01.880]   a game of whispers that eventually reaches the bare metal
[01:36:01.880 --> 01:36:02.600]   of the computer.
[01:36:02.600 --> 01:36:05.240]   New languages derive from old, new libraries
[01:36:05.240 --> 01:36:08.160]   built on existing ones, dependencies stacked
[01:36:08.160 --> 01:36:10.480]   on top of one another like a game of Genka that
[01:36:10.480 --> 01:36:12.800]   is about to end at any moment.
[01:36:12.800 --> 01:36:15.760]   And Google versus Oracle is a case that is happening
[01:36:15.760 --> 01:36:20.720]   at one of the lowest levels of an ongoing game of Genka.
[01:36:20.720 --> 01:36:24.680]   And you know what happens when you pull out
[01:36:24.680 --> 01:36:31.000]   a little piece of wood at the lowest level of a game of Genka.
[01:36:31.000 --> 01:36:32.720]   How much money is at stake in this?
[01:36:32.720 --> 01:36:33.760]   Do we have any idea?
[01:36:33.760 --> 01:36:35.000]   Billions.
[01:36:35.000 --> 01:36:37.080]   Because they want to stake in Android.
[01:36:37.080 --> 01:36:40.400]   They claim, Oracle claims, no, we
[01:36:40.400 --> 01:36:43.640]   should get a piece of Android for eternity.
[01:36:43.640 --> 01:36:46.040]   It's a billions.
[01:36:46.040 --> 01:36:53.200]   And Oracle bought Sleepycat to get the MySQL stuff.
[01:36:53.200 --> 01:36:56.800]   And the reason they bought it was so they could actually
[01:36:56.800 --> 01:36:59.400]   hobble open source and take some--
[01:36:59.400 --> 01:37:00.520]   That's a good point.
[01:37:00.520 --> 01:37:02.680]   It's very similar to what Jonathan Schwartz was saying.
[01:37:02.680 --> 01:37:06.080]   What a regulate that behavior.
[01:37:06.080 --> 01:37:10.320]   And Oracle's-- they own TikTok now.
[01:37:10.320 --> 01:37:12.920]   Donald Trump gave it to a man, right?
[01:37:12.920 --> 01:37:16.240]   A lot of people are concerned in the open source community.
[01:37:16.240 --> 01:37:20.160]   Because that's one of the things you do in open source.
[01:37:20.160 --> 01:37:23.800]   Something like wine, which allows Windows software
[01:37:23.800 --> 01:37:26.400]   to run on Linux, is essentially--
[01:37:26.400 --> 01:37:27.440]   it's not an emulator.
[01:37:27.440 --> 01:37:28.200]   That's what it stands for.
[01:37:28.200 --> 01:37:30.400]   Wine is not an emulator.
[01:37:30.400 --> 01:37:32.600]   It basically copies the API.
[01:37:32.600 --> 01:37:35.360]   And so when you make an API call that you think
[01:37:35.360 --> 01:37:37.560]   it's to Microsoft Windows, the Linux box
[01:37:37.560 --> 01:37:40.800]   handles it properly because it has the API.
[01:37:40.800 --> 01:37:44.480]   Independently developed compatible API.
[01:37:44.480 --> 01:37:45.560]   And so I can go--
[01:37:45.560 --> 01:37:49.240]   I could give you example after example in the open source
[01:37:49.240 --> 01:37:50.360]   and in close--
[01:37:50.360 --> 01:37:52.640]   Does wine run worth a dang these days?
[01:37:52.640 --> 01:37:53.280]   Yeah.
[01:37:53.280 --> 01:37:53.280]   Right.
[01:37:53.280 --> 01:37:54.440]   It's pretty good.
[01:37:54.440 --> 01:37:55.760]   It gets better all the time.
[01:37:55.760 --> 01:37:55.960]   Because--
[01:37:55.960 --> 01:37:57.520]   What do you mean that years ago?
[01:37:57.520 --> 01:37:57.920]   Yeah, no.
[01:37:57.920 --> 01:38:00.600]   I think it's a lot better than it used to be.
[01:38:00.600 --> 01:38:02.920]   Although I think it-- maybe it's time
[01:38:02.920 --> 01:38:07.480]   has come and gone since there's so much good software.
[01:38:07.480 --> 01:38:10.080]   You don't really need to use Microsoft Office
[01:38:10.080 --> 01:38:11.120]   on Linux anymore.
[01:38:11.120 --> 01:38:12.240]   Yeah, not anymore.
[01:38:12.240 --> 01:38:18.960]   Court observers listening this morning
[01:38:18.960 --> 01:38:20.800]   found that while the justices seemed
[01:38:20.800 --> 01:38:24.320]   to side with Oracle on the copyright arguments,
[01:38:24.320 --> 01:38:25.880]   they were deferentially arguments
[01:38:25.880 --> 01:38:28.760]   presented by Microsoft who had taken Google's side in this case
[01:38:28.760 --> 01:38:30.760]   because they're in a similar situation.
[01:38:30.760 --> 01:38:33.720]   There was a good story about how Google and Oracle both
[01:38:33.720 --> 01:38:37.320]   have generated huge numbers of amicus briefs.
[01:38:37.320 --> 01:38:39.880]   This is how you lobby the Supreme Court.
[01:38:39.880 --> 01:38:43.960]   In theory, these briefs are not associated with the plaintiffs.
[01:38:43.960 --> 01:38:46.560]   They're just by people who are experts,
[01:38:46.560 --> 01:38:48.240]   but it turns out many of these experts
[01:38:48.240 --> 01:38:52.240]   work for either Oracle or Google in one way or the other.
[01:38:52.240 --> 01:38:54.680]   Microsoft argued in an amicus brief
[01:38:54.680 --> 01:38:57.560]   that ruling in Oracle's favor could upend the software.
[01:38:57.560 --> 01:39:00.200]   Industry, I'd agree with that.
[01:39:00.200 --> 01:39:06.200]   Judge Justice Gorsuch was also seen to focus heavily
[01:39:06.200 --> 01:39:09.440]   on the Seventh Amendment arguments
[01:39:09.440 --> 01:39:13.800]   and whether the federal district's ruling--
[01:39:13.800 --> 01:39:16.560]   oh boy, this is a--
[01:39:16.560 --> 01:39:20.240]   This is a compliment.
[01:39:20.240 --> 01:39:21.240]   I'm sorry, I put you to sleep.
[01:39:21.240 --> 01:39:22.680]   It doesn't look like it's going to happen anytime soon though.
[01:39:22.680 --> 01:39:25.360]   Well, it will in a couple of months.
[01:39:25.360 --> 01:39:26.760]   This is it, right?
[01:39:26.760 --> 01:39:27.600]   Unless--
[01:39:27.600 --> 01:39:28.600]   There's nowhere to go after the president.
[01:39:28.600 --> 01:39:29.440]   There's nowhere to go.
[01:39:29.440 --> 01:39:30.280]   Unless it's--
[01:39:30.280 --> 01:39:31.120]   You got Congress.
[01:39:31.120 --> 01:39:32.640]   They send it back, right?
[01:39:32.640 --> 01:39:33.960]   They can do that, right?
[01:39:33.960 --> 01:39:35.600]   They could.
[01:39:35.600 --> 01:39:36.440]   I got a hug.
[01:39:36.440 --> 01:39:37.280]   They've done that once before.
[01:39:37.280 --> 01:39:38.120]   They're going to keep going.
[01:39:38.120 --> 01:39:40.280]   Nope, I think it's done.
[01:39:40.280 --> 01:39:41.120]   But--
[01:39:41.120 --> 01:39:42.080]   My God.
[01:39:42.080 --> 01:39:46.520]   It could be done in a way that we're not too happy about.
[01:39:46.520 --> 01:39:48.080]   Those lawyers still want to get paid.
[01:39:48.080 --> 01:39:50.800]   They've been hurting during the pandemic,
[01:39:50.800 --> 01:39:52.240]   so stretch it out.
[01:39:52.240 --> 01:39:56.080]   CNBC's Tucker Higgins, things got technical
[01:39:56.080 --> 01:39:58.320]   at the Supreme Court as the justices
[01:39:58.320 --> 01:40:01.640]   heard arguments this morning in a blockbuster copyright
[01:40:01.640 --> 01:40:04.560]   dispute at the end of the hour and a half arguments,
[01:40:04.560 --> 01:40:08.200]   Justice Stephen Breyer, who at one point read aloud
[01:40:08.200 --> 01:40:10.600]   some Java code--
[01:40:10.600 --> 01:40:12.200]   Oh, gosh.
[01:40:12.200 --> 01:40:14.320]   --appeared to be the only sure vote for Google,
[01:40:14.320 --> 01:40:18.040]   several other of the justices, including Chief Justice Roberts,
[01:40:18.040 --> 01:40:21.880]   said they were sympathetic to Oracle's copyright claim,
[01:40:21.880 --> 01:40:25.280]   even as they appeared to rule, reluctant to rule in its favor.
[01:40:25.280 --> 01:40:28.280]   So it's unknown.
[01:40:28.280 --> 01:40:30.840]   It's unknown.
[01:40:30.840 --> 01:40:34.520]   Brett Kavanaugh and Samuel Alita noted that Google's allies
[01:40:34.520 --> 01:40:38.480]   had warned the sky will fall off Oracle 1.
[01:40:38.480 --> 01:40:40.720]   Roberts said, we're told if we agree with Oracle,
[01:40:40.720 --> 01:40:43.120]   we will ruin the tech industry in the United States.
[01:40:43.120 --> 01:40:49.200]   Brett Kavanaugh said, I'm not aware the sky has fallen
[01:40:49.200 --> 01:40:52.960]   in the last five or six years, despite Google losing its first
[01:40:52.960 --> 01:40:54.320]   battle in 2014.
[01:40:54.320 --> 01:40:59.800]   We need Jim Jordan to come in here and start yelling about you.
[01:40:59.800 --> 01:41:03.920]   That would set this off.
[01:41:03.920 --> 01:41:06.960]   So sometimes you try to read the T. Lee's ways.
[01:41:06.960 --> 01:41:08.800]   The questions that Justice has asked,
[01:41:08.800 --> 01:41:11.880]   but it sounds like, as is often the case,
[01:41:11.880 --> 01:41:13.880]   it's impossible to tell.
[01:41:13.880 --> 01:41:15.440]   This is one of those things.
[01:41:15.440 --> 01:41:18.240]   I'm like, God, just let it be over.
[01:41:18.240 --> 01:41:21.440]   Well, but I honestly think it would be a disaster
[01:41:21.440 --> 01:41:22.440]   if they ruled Oracle's favor.
[01:41:22.440 --> 01:41:23.040]   It would be a disaster.
[01:41:23.040 --> 01:41:24.920]   It would be really bad for Oracle.
[01:41:24.920 --> 01:41:26.920]   It would be terrible.
[01:41:26.920 --> 01:41:30.800]   But dang.
[01:41:30.800 --> 01:41:32.800]   Dang.
[01:41:32.800 --> 01:41:34.960]   Can I pay me enough to care about this?
[01:41:34.960 --> 01:41:35.280]   Cool.
[01:41:35.280 --> 01:41:35.840]   Good firms.
[01:41:35.840 --> 01:41:39.800]   The Pixel 5 does not have the Pixel neural core.
[01:41:39.800 --> 01:41:43.080]   The core is no more.
[01:41:43.080 --> 01:41:44.840]   Aw.
[01:41:44.840 --> 01:41:45.840]   What happened to it?
[01:41:45.840 --> 01:41:46.760]   Was it no you?
[01:41:46.760 --> 01:41:47.680]   No good?
[01:41:47.680 --> 01:41:52.320]   The hardware apparently was always on listening.
[01:41:52.320 --> 01:41:53.000]   It would help with that.
[01:41:53.000 --> 01:41:55.120]   It would help with learning.
[01:41:55.120 --> 01:41:58.640]   I think that they tried to get the price down on the Pixel 5.
[01:41:58.640 --> 01:42:01.280]   And as a result, they dumped a lot of features.
[01:42:01.280 --> 01:42:03.240]   Ironically-- and this is probably
[01:42:03.240 --> 01:42:05.640]   because they had a deal with Verizon--
[01:42:05.640 --> 01:42:09.880]   they did put in millimeter wave 5G, which no one has.
[01:42:09.880 --> 01:42:10.560]   No one needs.
[01:42:10.560 --> 01:42:14.040]   And probably only a handful people will ever use.
[01:42:14.040 --> 01:42:16.720]   At a cost of, it's estimated another $100.
[01:42:16.720 --> 01:42:20.080]   So that 699 phone probably could have been 599
[01:42:20.080 --> 01:42:22.840]   if they hadn't had a bout of Verizon
[01:42:22.840 --> 01:42:24.360]   and put millimeter wave in.
[01:42:24.360 --> 01:42:28.160]   Such a racket.
[01:42:28.160 --> 01:42:29.880]   Another reason they didn't need the neural core.
[01:42:29.880 --> 01:42:33.040]   They got rid of the Face ID.
[01:42:33.040 --> 01:42:33.880]   Soli's gone.
[01:42:33.880 --> 01:42:36.040]   The Face ID's gone.
[01:42:36.040 --> 01:42:38.080]   They use a fingerprint reader.
[01:42:38.080 --> 01:42:39.440]   Good.
[01:42:39.440 --> 01:42:41.040]   Seems like I saw a report that they
[01:42:41.040 --> 01:42:42.920]   weren't totally done with Soli.
[01:42:42.920 --> 01:42:43.480]   Google.
[01:42:43.480 --> 01:42:44.000]   That is.
[01:42:44.000 --> 01:42:45.520]   Yeah, Google's--
[01:42:45.520 --> 01:42:50.320]   Rick Osterlow said, it'll be Soli some other time.
[01:42:50.320 --> 01:42:51.960]   Well, I think your theory on this one
[01:42:51.960 --> 01:42:53.800]   was they needed a cheaper phone for this kind of crisis.
[01:42:53.800 --> 01:42:55.000]   That's what they were able to do.
[01:42:55.000 --> 01:42:56.320]   They had to do is the--
[01:42:56.320 --> 01:42:57.840]   And the rumor is that they're going
[01:42:57.840 --> 01:43:02.560]   to stick Soli in thermostat because they found an MDC.
[01:43:02.560 --> 01:43:03.560]   Yeah.
[01:43:03.560 --> 01:43:05.280]   Filing a while back on that.
[01:43:05.280 --> 01:43:08.680]   So Soli was the kind of the 3D radar that allowed you to--
[01:43:08.680 --> 01:43:10.280]   and it never worked for me.
[01:43:10.280 --> 01:43:11.360]   I'll try it again.
[01:43:11.360 --> 01:43:14.120]   Wave at your Pixel 4.
[01:43:14.120 --> 01:43:14.920]   Oh, for music?
[01:43:14.920 --> 01:43:15.760]   Yeah, music.
[01:43:15.760 --> 01:43:16.440]   And for dang.
[01:43:16.440 --> 01:43:18.040]   Yeah, it didn't work with the dang.
[01:43:18.040 --> 01:43:21.160]   As in the words of Ant Proit.
[01:43:21.160 --> 01:43:22.800]   Doesn't work with a dang.
[01:43:22.800 --> 01:43:23.480]   I love that.
[01:43:23.480 --> 01:43:25.720]   Well, it reminds me of the Newton.
[01:43:25.720 --> 01:43:28.440]   It's kind of mid-air Newton.
[01:43:28.440 --> 01:43:29.920]   Yeah, it was dumb.
[01:43:29.920 --> 01:43:32.760]   It would recognize that my hand was there.
[01:43:32.760 --> 01:43:36.000]   I'd see the little highlight at the top of the bezel.
[01:43:36.000 --> 01:43:38.600]   But after that, it was just dead.
[01:43:38.600 --> 01:43:42.720]   It would never consistently work in such a flop.
[01:43:42.720 --> 01:43:44.640]   So one of the things I was excited about
[01:43:44.640 --> 01:43:47.120]   is it has a metal back, the Pixel 5.
[01:43:47.120 --> 01:43:48.480]   And I was excited because even though it
[01:43:48.480 --> 01:43:51.320]   has a metal back, which is right and good and proper,
[01:43:51.320 --> 01:43:53.640]   it still can do wireless charging, which we thought
[01:43:53.640 --> 01:43:54.680]   was impossible.
[01:43:54.680 --> 01:43:55.520]   It is impossible.
[01:43:55.520 --> 01:43:56.840]   You can't do it through a metal back.
[01:43:56.840 --> 01:43:59.760]   So there's basically a hole in the aluminum, which
[01:43:59.760 --> 01:44:03.800]   is filled in with plastic bio resin, according to Google.
[01:44:03.800 --> 01:44:06.640]   And that's where the coil lives.
[01:44:06.640 --> 01:44:08.120]   But that's not glass, though.
[01:44:08.120 --> 01:44:08.920]   It's not glass.
[01:44:08.920 --> 01:44:09.880]   No, plastic's fine.
[01:44:09.880 --> 01:44:12.560]   And it feels like metal because everything around it's metal.
[01:44:12.560 --> 01:44:14.120]   So that's how they do it.
[01:44:14.120 --> 01:44:14.880]   Smart.
[01:44:14.880 --> 01:44:17.480]   Clever.
[01:44:17.480 --> 01:44:20.720]   Just a matter of time before Jerry Riggs, everything,
[01:44:20.720 --> 01:44:24.360]   punches a hole in the plastic, though.
[01:44:24.360 --> 01:44:27.720]   Did we talk about the plan to pay publishers a billion dollars
[01:44:27.720 --> 01:44:28.400]   last week, Jeff?
[01:44:28.400 --> 01:44:29.320]   I can't remember.
[01:44:29.320 --> 01:44:30.720]   I don't think we did.
[01:44:30.720 --> 01:44:31.960]   That's that new.
[01:44:31.960 --> 01:44:32.640]   That's that new.
[01:44:32.640 --> 01:44:34.840]   It's that new.
[01:44:34.840 --> 01:44:37.280]   And I wrote about similar things before.
[01:44:37.280 --> 01:44:39.560]   I actually think it's a mistake because I think
[01:44:39.560 --> 01:44:40.280]   it sets a precedent.
[01:44:40.280 --> 01:44:42.480]   Is this the victory you were referring to with Rupert
[01:44:42.480 --> 01:44:43.360]   Merne-Rigler earlier?
[01:44:43.360 --> 01:44:43.680]   OK.
[01:44:43.680 --> 01:44:45.280]   Yeah, there's another story in the rundown
[01:44:45.280 --> 01:44:47.200]   about that specifically from Maxios.
[01:44:47.200 --> 01:44:48.600]   So it's not immediately.
[01:44:48.600 --> 01:44:50.160]   It's over the next three years.
[01:44:50.160 --> 01:44:50.440]   Three years.
[01:44:50.440 --> 01:44:54.000]   It's to curate high quality journalism.
[01:44:54.000 --> 01:44:57.200]   And this is how companies like Google do this.
[01:44:57.200 --> 01:44:59.200]   They don't want to set a precedent by saying,
[01:44:59.200 --> 01:45:01.080]   by giving in in Australia and saying, OK,
[01:45:01.080 --> 01:45:02.760]   here's some money for those snippets.
[01:45:02.760 --> 01:45:04.760]   So they create a new product.
[01:45:04.760 --> 01:45:05.240]   Right.
[01:45:05.240 --> 01:45:06.160]   They call it Google News.
[01:45:06.160 --> 01:45:07.240]   They do Facebook, Facebook, Google News.
[01:45:07.240 --> 01:45:08.120]   Not the same thing.
[01:45:08.120 --> 01:45:09.880]   Google News Showcase.
[01:45:09.880 --> 01:45:11.840]   We're going to give you money.
[01:45:11.840 --> 01:45:15.200]   And when we use your news in the Google News Showcase--
[01:45:15.200 --> 01:45:17.080]   We get a whole article, not just a snippet.
[01:45:17.080 --> 01:45:17.360]   Yeah.
[01:45:17.360 --> 01:45:18.360]   Rupert gets his money.
[01:45:18.360 --> 01:45:20.160]   Rupert, you're syndicating the content.
[01:45:20.160 --> 01:45:21.800]   He goes away.
[01:45:21.800 --> 01:45:22.840]   Happy.
[01:45:22.840 --> 01:45:25.520]   And shuts up about the whole thing.
[01:45:25.520 --> 01:45:26.520]   And so Murdoch--
[01:45:26.520 --> 01:45:28.240]   And this is OK?
[01:45:28.240 --> 01:45:28.720]   Yeah.
[01:45:28.720 --> 01:45:30.520]   It's OK with Murdochs.
[01:45:30.520 --> 01:45:31.240]   Look at Murdoch.
[01:45:31.240 --> 01:45:32.760]   I think it sets a precedent.
[01:45:32.760 --> 01:45:39.120]   Because news is a tiny part, tiny, tiny part of search results.
[01:45:39.120 --> 01:45:41.280]   And I can imagine others coming along and trying to say,
[01:45:41.280 --> 01:45:42.960]   well, I got value too.
[01:45:42.960 --> 01:45:44.360]   Why don't you pay me?
[01:45:44.360 --> 01:45:49.880]   And it means that if we don't have a search of everything
[01:45:49.880 --> 01:45:52.320]   that's available, it's another case
[01:45:52.320 --> 01:45:58.000]   where we end up with paywalls that prevent the free exchange
[01:45:58.000 --> 01:45:59.560]   of knowledge, and that's what scares us.
[01:45:59.560 --> 01:46:02.040]   What do you think of the product that showcased itself?
[01:46:02.040 --> 01:46:04.320]   It hasn't launched here to Lost First in New Zealand.
[01:46:04.320 --> 01:46:05.840]   So I don't know if I haven't seen it yet.
[01:46:05.840 --> 01:46:08.520]   But the problem with all of these things
[01:46:08.520 --> 01:46:13.160]   is they're going to naturally favor the big old guys.
[01:46:13.160 --> 01:46:18.160]   And so all of this stuff prevents new upstart comers
[01:46:18.160 --> 01:46:18.720]   from the law.
[01:46:18.720 --> 01:46:20.960]   This is antitrust on the media part.
[01:46:20.960 --> 01:46:23.840]   This is the media place using all of their clout.
[01:46:23.840 --> 01:46:28.640]   You want to talk about the use of clout to get what you want?
[01:46:28.640 --> 01:46:29.920]   Media's been doing that.
[01:46:29.920 --> 01:46:32.560]   Full bore, getting laws passed throughout Europe,
[01:46:32.560 --> 01:46:35.480]   threatening things in the US, pushing the antitrust
[01:46:35.480 --> 01:46:39.320]   in Europe especially, pushing it here, pushing it in Australia.
[01:46:39.320 --> 01:46:44.120]   And so media have engaged in huge antitrust behavior
[01:46:44.120 --> 01:46:45.600]   and conflict of interest.
[01:46:45.600 --> 01:46:47.840]   And every time they cover a story about the giants,
[01:46:47.840 --> 01:46:49.160]   don't trust them, folks.
[01:46:49.160 --> 01:46:51.520]   Because they're in a conflict of interest.
[01:46:51.520 --> 01:46:54.920]   They never acknowledge that.
[01:46:54.920 --> 01:46:56.360]   So it's boring.
[01:46:56.360 --> 01:46:57.920]   I don't want to bore the world with that.
[01:46:57.920 --> 01:46:59.520]   But I think it's a bad move.
[01:46:59.520 --> 01:47:03.320]   I wrote a post saying basically, this is the fruit of bribery.
[01:47:03.320 --> 01:47:05.160]   Yes.
[01:47:05.160 --> 01:47:07.960]   And you know, and you know it is because Murdoch says, oh, good.
[01:47:07.960 --> 01:47:08.520]   That's fine.
[01:47:08.520 --> 01:47:09.240]   Well, now I'm fine.
[01:47:09.240 --> 01:47:09.840]   I'm fine with that.
[01:47:09.840 --> 01:47:13.040]   And do you think that Australia's legislators will say, oh,
[01:47:13.040 --> 01:47:13.960]   well, fruit's happy.
[01:47:13.960 --> 01:47:14.800]   We're happy.
[01:47:14.800 --> 01:47:15.880]   I think they might.
[01:47:15.880 --> 01:47:16.400]   OK, right.
[01:47:16.400 --> 01:47:18.760]   I think they probably got negotiated.
[01:47:18.760 --> 01:47:20.560]   I think it's a cynical--
[01:47:20.560 --> 01:47:23.720]   I'm not blaming Google.
[01:47:23.720 --> 01:47:25.200]   I'm not blaming Facebook.
[01:47:25.200 --> 01:47:26.840]   They got stuck in a position.
[01:47:26.840 --> 01:47:31.080]   But what gets hurt--
[01:47:31.080 --> 01:47:34.360]   when I defend against some of this regulation,
[01:47:34.360 --> 01:47:35.720]   I am not defending the companies.
[01:47:35.720 --> 01:47:38.480]   I'm defending internet freedom expression.
[01:47:38.480 --> 01:47:41.720]   And these companies become the representatives
[01:47:41.720 --> 01:47:44.920]   and proprietors of the internet as we have it today.
[01:47:44.920 --> 01:47:46.600]   And so it ends up looking like that.
[01:47:46.600 --> 01:47:48.240]   But they're not good proprietors, right?
[01:47:48.240 --> 01:47:50.320]   They're going to receive him out of the nothing.
[01:47:50.320 --> 01:47:52.000]   He and I love each other but disagree about things.
[01:47:52.000 --> 01:47:53.920]   He would say, Jeff, no, company's going to be a company.
[01:47:53.920 --> 01:47:55.160]   Company's not going to stand for principle.
[01:47:55.160 --> 01:47:56.120]   A company's going to be a company.
[01:47:56.120 --> 01:47:57.320]   That's what's happening here.
[01:47:57.320 --> 01:47:58.720]   Yeah, that's what they're doing.
[01:47:58.720 --> 01:47:59.960]   They're doing what's in there.
[01:47:59.960 --> 01:48:01.360]   Trusting what's in his interest.
[01:48:01.360 --> 01:48:03.160]   And we, the people, we just have to--
[01:48:03.160 --> 01:48:03.640]   Who defends our speech?
[01:48:03.640 --> 01:48:04.200]   Right.
[01:48:04.200 --> 01:48:05.880]   Just have to put up with it.
[01:48:05.880 --> 01:48:07.320]   Speaking of Mr.
[01:48:07.320 --> 01:48:07.720]   - Rupert's dog.
[01:48:07.720 --> 01:48:08.960]   Rupert's dog's right.
[01:48:08.960 --> 01:48:09.960]   Oh, you see his new dog?
[01:48:09.960 --> 01:48:11.120]   Whiskey?
[01:48:11.120 --> 01:48:11.680]   Whiskey.
[01:48:11.680 --> 01:48:13.160]   Yeah, both the dogs.
[01:48:13.160 --> 01:48:13.680]   Yeah.
[01:48:13.680 --> 01:48:14.560]   Butter and whiskey.
[01:48:14.560 --> 01:48:15.720]   Yeah, which I said--
[01:48:15.720 --> 01:48:16.440]   Butter and his dog--
[01:48:16.440 --> 01:48:17.760]   Next dog would be--
[01:48:17.760 --> 01:48:19.960]   Beshamel?
[01:48:19.960 --> 01:48:21.960]   Jesus.
[01:48:21.960 --> 01:48:22.960]   Where are you?
[01:48:22.960 --> 01:48:23.460]   Where are you?
[01:48:23.460 --> 01:48:23.960]   Sevus.
[01:48:23.960 --> 01:48:24.840]   How did I miss this?
[01:48:24.840 --> 01:48:26.560]   Is it Rupert's dog?
[01:48:26.560 --> 01:48:27.880]   No, Seva's dog.
[01:48:27.880 --> 01:48:28.920]   Oh, Seva's dog.
[01:48:28.920 --> 01:48:29.560]   Oh, OK.
[01:48:29.560 --> 01:48:30.360]   Seva's dog is great.
[01:48:30.360 --> 01:48:31.040]   He's got a staring picture.
[01:48:31.040 --> 01:48:32.440]   Just on this topic.
[01:48:32.440 --> 01:48:33.800]   Yeah.
[01:48:33.800 --> 01:48:36.800]   James Ball, who's a guardian-- former guardian journalist--
[01:48:36.800 --> 01:48:38.960]   has a book coming out this week called The Tangled Web
[01:48:38.960 --> 01:48:41.120]   We Weave Inside the Shadow System, the Shape Sea
[01:48:41.120 --> 01:48:42.040]   Internet.
[01:48:42.040 --> 01:48:43.480]   It was called Something Else in the UK,
[01:48:43.480 --> 01:48:44.320]   which is just absurd.
[01:48:44.320 --> 01:48:45.760]   They used to do it in retitles.
[01:48:45.760 --> 01:48:47.120]   I'll probably disagree with most of the book,
[01:48:47.120 --> 01:48:48.280]   but James is a very good journalist.
[01:48:48.280 --> 01:48:48.880]   Is this the--
[01:48:48.880 --> 01:48:51.120]   Is this the British name, the system?
[01:48:51.120 --> 01:48:52.640]   That's the British name, the system.
[01:48:52.640 --> 01:48:53.600]   Who owns the US data?
[01:48:53.600 --> 01:48:54.600]   Who owns us?
[01:48:54.600 --> 01:48:55.760]   The Tangled Web We Weave.
[01:48:55.760 --> 01:48:57.360]   OK.
[01:48:57.360 --> 01:48:57.720]   So--
[01:48:57.720 --> 01:48:59.800]   A different cover, a different title, which is absurd,
[01:48:59.800 --> 01:49:02.240]   because this moment right now, if somebody's listening to us
[01:49:02.240 --> 01:49:05.360]   in the UK, they're going to look for the wrong book.
[01:49:05.360 --> 01:49:06.880]   And so--
[01:49:06.880 --> 01:49:07.640]   Anyway.
[01:49:07.640 --> 01:49:08.560]   What is the premises of--
[01:49:08.560 --> 01:49:09.000]   James is a purr.
[01:49:09.000 --> 01:49:09.720]   Who is James in Genesis?
[01:49:09.720 --> 01:49:10.560]   The premises.
[01:49:10.560 --> 01:49:12.920]   He gets into what is the real structure of the internet
[01:49:12.920 --> 01:49:15.440]   and who owns it and controls it and how that affects us.
[01:49:15.440 --> 01:49:18.000]   And I opened up by Rolodex and made lots of introductions.
[01:49:18.000 --> 01:49:19.640]   For a musical journalist, I'm sure I disagree--
[01:49:19.640 --> 01:49:20.360]   I haven't read yet.
[01:49:20.360 --> 01:49:21.360]   I haven't had yet.
[01:49:21.360 --> 01:49:22.680]   I'm sure I disagree with many of his conclusions,
[01:49:22.680 --> 01:49:24.280]   but he's a very good journalist.
[01:49:24.280 --> 01:49:25.680]   And I am an open-minded fellow.
[01:49:25.680 --> 01:49:29.200]   Do you believe that the internet dream has curdled?
[01:49:29.200 --> 01:49:29.960]   No.
[01:49:29.960 --> 01:49:33.040]   I think that the internet dream that I had
[01:49:33.040 --> 01:49:37.880]   is not living up to its full possibilities,
[01:49:37.880 --> 01:49:40.040]   but we've got about five centuries to go
[01:49:40.040 --> 01:49:40.920]   before we figure it out.
[01:49:40.920 --> 01:49:42.200]   So we've got time.
[01:49:42.200 --> 01:49:46.840]   Who does he claim runs the shadow system behind it all?
[01:49:46.840 --> 01:49:48.200]   We talked about computers.
[01:49:48.200 --> 01:49:55.680]   And James was part of the team on the WikiLeaks.
[01:49:55.680 --> 01:49:58.320]   Oh, he was part of the team on the Snowden.
[01:49:58.320 --> 01:49:59.440]   Oh, jeez, I should know this, James.
[01:49:59.440 --> 01:49:59.960]   I'm sorry.
[01:49:59.960 --> 01:50:04.280]   I think he was at WikiLeaks.
[01:50:04.280 --> 01:50:05.560]   And then I think he went to the Guardian
[01:50:05.560 --> 01:50:08.040]   and worked with him on the Snowden piece.
[01:50:08.040 --> 01:50:09.320]   There's the American cover.
[01:50:09.320 --> 01:50:11.640]   I'll give you the American cover so you get the right.
[01:50:11.640 --> 01:50:13.080]   Yeah, so just a quick right book.
[01:50:13.080 --> 01:50:13.920]   The plug there.
[01:50:13.920 --> 01:50:20.200]   But we've-- let's say here a couple more things.
[01:50:20.200 --> 01:50:24.720]   Facebook has banned QAnon.
[01:50:24.720 --> 01:50:27.080]   What a surprise, actually, because Facebook really kind of--
[01:50:27.080 --> 01:50:28.520]   reasons I don't fully understand it
[01:50:28.520 --> 01:50:30.240]   has been resisting this all along.
[01:50:30.240 --> 01:50:32.440]   Because of the Republican Congress.
[01:50:32.440 --> 01:50:33.440]   That's why they didn't--
[01:50:33.440 --> 01:50:33.920]   They didn't--
[01:50:33.920 --> 01:50:37.160]   --and smashed the ticketing down, including QAnon.
[01:50:37.160 --> 01:50:39.680]   So this is what's in charge.
[01:50:39.680 --> 01:50:41.240]   We live in an interesting time.
[01:50:41.240 --> 01:50:43.440]   Now, there's a one month to the election.
[01:50:43.440 --> 01:50:44.800]   Then there'll be a couple of months
[01:50:44.800 --> 01:50:47.920]   in the regnum of lame duck session of Congress.
[01:50:47.920 --> 01:50:50.120]   Lame duck-- well, we'll see.
[01:50:50.120 --> 01:50:55.440]   Maybe a will or will not be a lame duck president.
[01:50:55.440 --> 01:50:57.720]   And then if there is a new president,
[01:50:57.720 --> 01:51:00.040]   January 20, to be a new president,
[01:51:00.040 --> 01:51:02.960]   are companies going to--
[01:51:02.960 --> 01:51:04.800]   they're obviously very political, right?
[01:51:04.800 --> 01:51:06.440]   So you're saying that Facebook--
[01:51:06.440 --> 01:51:09.600]   are they actually predicting the election results and saying,
[01:51:09.600 --> 01:51:11.920]   OK, it's safe to ban QAnon now?
[01:51:11.920 --> 01:51:12.680]   Or are they--
[01:51:12.680 --> 01:51:13.680]   I suspect they're really--
[01:51:13.680 --> 01:51:15.040]   That is very scary.
[01:51:15.040 --> 01:51:16.040]   --that they're not going to work.
[01:51:16.040 --> 01:51:17.360]   Well, they should have been.
[01:51:17.360 --> 01:51:19.640]   And why didn't it-- before is maybe a better question.
[01:51:19.640 --> 01:51:24.680]   But I also think there's some significant concern
[01:51:24.680 --> 01:51:26.440]   come November 3.
[01:51:26.440 --> 01:51:28.560]   And you're seeing Facebook say, we
[01:51:28.560 --> 01:51:32.920]   are going to be very aggressive about blocking false posts
[01:51:32.920 --> 01:51:35.320]   on election day and the days following.
[01:51:35.320 --> 01:51:36.960]   Twitter saying the same thing.
[01:51:36.960 --> 01:51:38.120]   There's some concern that they're
[01:51:38.120 --> 01:51:42.240]   going to take the fall once again for the results of the election.
[01:51:42.240 --> 01:51:45.480]   Does that sound sensible?
[01:51:45.480 --> 01:51:46.480]   And--
[01:51:46.480 --> 01:51:49.240]   Whoever's loses is going to try to blame them, sure.
[01:51:49.240 --> 01:51:50.520]   Sorry, Aunt.
[01:51:50.520 --> 01:51:51.440]   Well, I disagree.
[01:51:51.440 --> 01:51:53.760]   I don't think that sounds sensible.
[01:51:53.760 --> 01:51:54.960]   They're not worried about that.
[01:51:54.960 --> 01:51:56.560]   They're just businesses usual.
[01:51:56.560 --> 01:51:57.080]   No.
[01:51:57.080 --> 01:51:58.640]   Mm-hmm.
[01:51:58.640 --> 01:51:59.880]   Because they know they're-- you're right.
[01:51:59.880 --> 01:52:00.840]   Doesn't matter what happens.
[01:52:00.840 --> 01:52:02.280]   They're going to get crap the matter.
[01:52:02.280 --> 01:52:04.000]   OK.
[01:52:04.000 --> 01:52:05.760]   Fair enough.
[01:52:05.760 --> 01:52:07.760]   Yeah, they have banned the conspiracy theory
[01:52:07.760 --> 01:52:08.360]   QAnon.
[01:52:08.360 --> 01:52:11.080]   There's a really interesting piece in Bloomberg today
[01:52:11.080 --> 01:52:15.280]   about the guy who really put it on the map who
[01:52:15.280 --> 01:52:19.440]   was a executive, a technology executive at a big bank.
[01:52:19.440 --> 01:52:20.280]   Was it Citibank?
[01:52:20.280 --> 01:52:21.640]   I think it was.
[01:52:21.640 --> 01:52:27.880]   Who created the first QAnon centralized site for information.
[01:52:27.880 --> 01:52:31.160]   And it's quite a story.
[01:52:31.160 --> 01:52:32.680]   Let's be clear about one thing.
[01:52:32.680 --> 01:52:36.280]   Let's say that tomorrow absolutely every mention of QAnon
[01:52:36.280 --> 01:52:38.560]   disappears on Facebook and Twitter.
[01:52:38.560 --> 01:52:40.720]   Our problems ain't over, folks.
[01:52:40.720 --> 01:52:42.160]   No.
[01:52:42.160 --> 01:52:44.400]   No, but I mean, it helps.
[01:52:44.400 --> 01:52:47.120]   I mean, there are lots of people being radicalized.
[01:52:47.120 --> 01:52:47.680]   Radicalized?
[01:52:47.680 --> 01:52:50.600]   I don't know if you're radicalized in a QAnon.
[01:52:50.600 --> 01:52:53.760]   I mean, my people I love are seeing these.
[01:52:53.760 --> 01:52:54.200]   You know what?
[01:52:54.200 --> 01:52:56.720]   That's a good news stupid, Stacey.
[01:52:56.720 --> 01:52:57.800]   You're made stupid.
[01:52:57.800 --> 01:53:00.520]   That's an OK use of the word stupid.
[01:53:00.520 --> 01:53:02.200]   Well, QAnon is not reductionist.
[01:53:02.200 --> 01:53:03.200]   It's the exact opposite.
[01:53:03.200 --> 01:53:03.960]   It's the majority QAnon.
[01:53:03.960 --> 01:53:06.840]   Bizarrely elaborate influx theory.
[01:53:06.840 --> 01:53:10.560]   The latest is the president's COVID diagnosis is all fake
[01:53:10.560 --> 01:53:17.840]   because he's going undercover to set the stage for the storm,
[01:53:17.840 --> 01:53:20.160]   which, you know, OK, fine.
[01:53:20.160 --> 01:53:22.640]   This is-- if you-- I mean, we've recommended
[01:53:22.640 --> 01:53:24.640]   in the past articles there was a great one on Atlantic
[01:53:24.640 --> 01:53:25.760]   about QAnon.
[01:53:25.760 --> 01:53:28.240]   But this article, Bloomberg Business Week,
[01:53:28.240 --> 01:53:32.560]   about a city group tech executive who was doing just fine
[01:53:32.560 --> 01:53:38.480]   but created a website that really launched QAnon, by the way,
[01:53:38.480 --> 01:53:38.480]   web--
[01:53:38.480 --> 01:53:40.200]   Was part of it?
[01:53:40.200 --> 01:53:41.320]   Well, no one's part of it.
[01:53:41.320 --> 01:53:41.840]   It's all but--
[01:53:41.840 --> 01:53:43.760]   Hold on, but he was a sympathizer.
[01:53:43.760 --> 01:53:44.840]   He wasn't trying to expose it.
[01:53:44.840 --> 01:53:46.720]   No big time synthesizer.
[01:53:46.720 --> 01:53:47.720]   Simplify.
[01:53:47.720 --> 01:53:48.220]   OK.
[01:53:48.220 --> 01:53:49.120]   Oh, no, no, no.
[01:53:49.120 --> 01:53:55.160]   He-- so it starts about his radicalization,
[01:53:55.160 --> 01:53:57.200]   like many future Donald Trump voters,
[01:53:57.200 --> 01:53:59.560]   giving credit to the author, William Turton,
[01:53:59.560 --> 01:54:01.120]   and Joshua Brucestein.
[01:54:01.120 --> 01:54:04.240]   Like many future Donald Trump voters, Jason Galinas
[01:54:04.240 --> 01:54:07.360]   felt something shift inside him during the presidency
[01:54:07.360 --> 01:54:08.800]   of Barack Obama.
[01:54:08.800 --> 01:54:10.400]   Things were going OK for him generally.
[01:54:10.400 --> 01:54:13.120]   He had a degree from Fordham, held a series of jobs
[01:54:13.120 --> 01:54:15.680]   at big financial services firms, eventually becoming
[01:54:15.680 --> 01:54:18.680]   a senior vice president at Citigroup in the company's
[01:54:18.680 --> 01:54:20.680]   technology department.
[01:54:20.680 --> 01:54:22.600]   He was married with kids at a comfortable house
[01:54:22.600 --> 01:54:23.760]   in a new Jersey suburb.
[01:54:23.760 --> 01:54:26.040]   According to those who knew him, he was a pleasant guy.
[01:54:26.040 --> 01:54:27.920]   Who was into normal stuff, Game of Thrones,
[01:54:27.920 --> 01:54:29.560]   recreational soccer.
[01:54:29.560 --> 01:54:32.840]   Things did get weird, though, when politics came up.
[01:54:32.840 --> 01:54:35.600]   He was a registered Democrat in the run up to 2008,
[01:54:35.600 --> 01:54:38.680]   but then seemed to drift to the right.
[01:54:38.680 --> 01:54:43.520]   And not-- and I'm going to vote for Romney this time sort of way.
[01:54:43.520 --> 01:54:44.920]   He hated the idea Obama--
[01:54:44.920 --> 01:54:47.080]   Obama, one of his friends, speaking
[01:54:47.080 --> 01:54:48.520]   in the condition of anonymity, said
[01:54:48.520 --> 01:54:50.520]   he thought it was a setup.
[01:54:50.520 --> 01:54:54.280]   And Obama was elected to satisfy the black population.
[01:54:54.280 --> 01:54:56.120]   He sometimes referred to him as the anti-Christ.
[01:54:56.120 --> 01:55:02.600]   As the anti-Christ, significantly immersed in right wing
[01:55:02.600 --> 01:55:07.200]   internet conspiracy theories, QAnon, which started on 4chan
[01:55:07.200 --> 01:55:12.160]   later migrated to 8chan, kind of drew him in in 2018
[01:55:12.160 --> 01:55:15.040]   while doing his job as city, created as an anonymous side
[01:55:15.040 --> 01:55:19.080]   project, a website dedicated to bringing QAnon
[01:55:19.080 --> 01:55:23.040]   to a wider audience, soccer moms, white collar workers,
[01:55:23.040 --> 01:55:25.640]   and other normies like Stacy's family.
[01:55:25.640 --> 01:55:28.520]   By mid-2020, the site QMap.pub
[01:55:28.520 --> 01:55:31.760]   was drawing 10 million visitors a month
[01:55:31.760 --> 01:55:35.200]   and was credited by researchers with playing a key role,
[01:55:35.200 --> 01:55:39.120]   a key role in turning an obscure and incoherent cult
[01:55:39.120 --> 01:55:44.760]   into an incoherent cult with mainstream political ambitions.
[01:55:44.760 --> 01:55:47.360]   So that's the problem, is that's a website.
[01:55:47.360 --> 01:55:48.880]   Anybody who's into QAnon doesn't care
[01:55:48.880 --> 01:55:50.240]   if they could see it on Facebook.
[01:55:50.240 --> 01:55:52.960]   What it would do is stop anybody who's not into QAnon, right?
[01:55:52.960 --> 01:55:55.160]   Yeah, I was going to say Facebook helps people
[01:55:55.160 --> 01:55:56.240]   find QAnon.
[01:55:56.240 --> 01:55:57.200]   Right.
[01:55:57.200 --> 01:55:59.120]   Well, what happens is--
[01:55:59.120 --> 01:56:01.920]   this is where Dana Boyd screams about this--
[01:56:01.920 --> 01:56:04.600]   is that when you say things like--
[01:56:04.600 --> 01:56:05.760]   it's out there enough now.
[01:56:05.760 --> 01:56:07.360]   If you say things like in cell, people say, what the hell's
[01:56:07.360 --> 01:56:09.960]   in cell, they go to Google and they search, what's in cell?
[01:56:09.960 --> 01:56:11.520]   And then it's primed.
[01:56:11.520 --> 01:56:14.920]   It's ready for you to do that, because they've planted
[01:56:14.920 --> 01:56:16.720]   the seeds across them, so you're going to go down
[01:56:16.720 --> 01:56:17.920]   their rabbit hole.
[01:56:17.920 --> 01:56:20.160]   And it doesn't matter where you hear about it.
[01:56:20.160 --> 01:56:21.320]   You can hear about it in Fox.
[01:56:21.320 --> 01:56:23.440]   You can hear about an email from your uncle.
[01:56:23.440 --> 01:56:25.080]   You hear about it anywhere.
[01:56:25.080 --> 01:56:26.680]   You're going to be out there.
[01:56:26.680 --> 01:56:27.520]   Right.
[01:56:27.520 --> 01:56:28.960]   And so the idea that--
[01:56:28.960 --> 01:56:30.360]   I mean, I think the part of the presumption is,
[01:56:30.360 --> 01:56:31.560]   my god, what's Facebook so long?
[01:56:31.560 --> 01:56:31.920]   True.
[01:56:31.920 --> 01:56:32.440]   Yes.
[01:56:32.440 --> 01:56:33.480]   They should have had--
[01:56:33.480 --> 01:56:35.920]   my argument about Facebook is they should have a north star
[01:56:35.920 --> 01:56:37.680]   of decent behavior, and this doesn't fall under it.
[01:56:37.680 --> 01:56:38.960]   They should have gotten rid of it.
[01:56:38.960 --> 01:56:41.800]   But free speech, blah, blah, blah.
[01:56:41.800 --> 01:56:44.760]   Even if they got rid of it, it wouldn't have made much difference.
[01:56:44.760 --> 01:56:45.560]   So he was--
[01:56:45.560 --> 01:56:46.160]   Should we do that?
[01:56:46.160 --> 01:56:49.000]   He was docked and shut the place down.
[01:56:49.000 --> 01:56:50.240]   It was fired from city.
[01:56:50.240 --> 01:56:54.160]   This was back last month, September 10th.
[01:56:54.160 --> 01:56:54.680]   Yeah.
[01:56:54.680 --> 01:56:55.880]   It took that long?
[01:56:55.880 --> 01:56:57.760]   Yeah.
[01:56:57.760 --> 01:56:58.680]   So that site is down.
[01:56:58.680 --> 01:57:00.600]   They should go through there right now.
[01:57:00.600 --> 01:57:02.680]   I was going to see if we could do a change log soon.
[01:57:02.680 --> 01:57:03.320]   Yes.
[01:57:03.320 --> 01:57:07.720]   It's time for Stacy's Hungry.
[01:57:07.720 --> 01:57:08.520]   It's time--
[01:57:08.520 --> 01:57:09.840]   That looks as for--
[01:57:09.840 --> 01:57:10.600]   Hell, you wait for it.
[01:57:10.600 --> 01:57:11.320]   The Google--
[01:57:11.320 --> 01:57:12.960]   You could go forward to get the change log that you did
[01:57:12.960 --> 01:57:14.360]   to get rid of--
[01:57:14.360 --> 01:57:15.520]   you and on for God's thanks.
[01:57:15.520 --> 01:57:17.320]   Change log!
[01:57:17.320 --> 01:57:19.320]   The Google Change Log.
[01:57:19.320 --> 01:57:25.560]   G Suite has a new name.
[01:57:25.560 --> 01:57:26.800]   Oh, F me.
[01:57:26.800 --> 01:57:27.640]   Oh, geez.
[01:57:27.640 --> 01:57:29.040]   [LAUGHTER]
[01:57:29.040 --> 01:57:30.320]   Good lord.
[01:57:30.320 --> 01:57:32.760]   It is now--
[01:57:32.760 --> 01:57:35.000]   But you still can't use it, Jeff.
[01:57:35.000 --> 01:57:35.680]   So don't worry.
[01:57:35.680 --> 01:57:36.400]   Yeah, exactly.
[01:57:36.400 --> 01:57:36.880]   Oh, yeah.
[01:57:36.880 --> 01:57:41.880]   It is now Google Workspace, Gmail Drive Docs, and Meet.
[01:57:41.880 --> 01:57:45.320]   And see the new logos, see the new icons.
[01:57:45.320 --> 01:57:47.600]   People are too happy about these new icons.
[01:57:47.600 --> 01:57:48.400]   That's the bottom row.
[01:57:48.400 --> 01:57:50.760]   That's the top row is the old icons.
[01:57:50.760 --> 01:57:54.720]   They're really strange.
[01:57:54.720 --> 01:57:55.960]   What is with that?
[01:57:55.960 --> 01:57:57.080]   They're very flat.
[01:57:57.080 --> 01:57:58.560]   They're googly.
[01:57:58.560 --> 01:57:59.040]   This is--
[01:57:59.040 --> 01:58:00.280]   I don't know that they're flat.
[01:58:00.280 --> 01:58:02.360]   I like that they're consistent, but I have no--
[01:58:02.360 --> 01:58:04.240]   I would never click on the Docs thing.
[01:58:04.240 --> 01:58:05.240]   What is that?
[01:58:05.240 --> 01:58:06.080]   Also--
[01:58:06.080 --> 01:58:06.600]   Yeah.
[01:58:06.600 --> 01:58:08.480]   Is that-- is that Meet?
[01:58:08.480 --> 01:58:10.280]   That's Meet, right?
[01:58:10.280 --> 01:58:10.960]   Yeah.
[01:58:10.960 --> 01:58:11.600]   It's a camera.
[01:58:11.600 --> 01:58:12.520]   Yeah.
[01:58:12.520 --> 01:58:13.520]   Yeah, OK.
[01:58:13.520 --> 01:58:14.600]   I was like, is that Hangouts?
[01:58:14.600 --> 01:58:15.160]   Is that Meet?
[01:58:15.160 --> 01:58:16.920]   What is that?
[01:58:16.920 --> 01:58:18.320]   Maybe it's Googly.
[01:58:18.320 --> 01:58:18.880]   It's just bad.
[01:58:18.880 --> 01:58:19.400]   I don't know.
[01:58:19.400 --> 01:58:22.600]   We know they're not great with design.
[01:58:22.600 --> 01:58:23.240]   Yeah, right.
[01:58:23.240 --> 01:58:28.160]   Ever since Marissa left for Yahoo, it's all been downhill.
[01:58:28.160 --> 01:58:29.600]   Live view in Google--
[01:58:29.600 --> 01:58:30.680]   I think I did this last week.
[01:58:30.680 --> 01:58:33.920]   Live view in Google Maps will help you visualize your destination
[01:58:33.920 --> 01:58:35.040]   in the real world.
[01:58:35.040 --> 01:58:36.000]   No, I'm in touch.
[01:58:36.000 --> 01:58:36.520]   No, sir.
[01:58:36.520 --> 01:58:37.680]   Maybe I just told my friends.
[01:58:37.680 --> 01:58:38.560]   No, well, they've had that.
[01:58:38.560 --> 01:58:39.080]   But this was--
[01:58:39.080 --> 01:58:39.800]   I've proved it.
[01:58:39.800 --> 01:58:40.240]   Remember?
[01:58:40.240 --> 01:58:40.760]   Yeah.
[01:58:40.760 --> 01:58:42.200]   They talked about it.
[01:58:42.200 --> 01:58:44.840]   I didn't do it last week because we had one talking
[01:58:44.840 --> 01:58:47.360]   about the Pixel all day.
[01:58:47.360 --> 01:58:49.960]   All right, you can access Live view from the transit tab
[01:58:49.960 --> 01:58:51.960]   in Google Maps.
[01:58:51.960 --> 01:58:52.960]   And it'll help you.
[01:58:52.960 --> 01:58:54.080]   I think this is really good.
[01:58:54.080 --> 01:58:55.720]   They talked about this two years ago.
[01:58:55.720 --> 01:58:56.720]   I'm glad they finally did it.
[01:58:56.720 --> 01:58:58.560]   They did it, but it just wasn't possible to use.
[01:58:58.560 --> 01:59:00.280]   I was like in Italy trying to use it.
[01:59:00.280 --> 01:59:00.920]   Oh, I remember that.
[01:59:00.920 --> 01:59:01.400]   Yeah.
[01:59:01.400 --> 01:59:03.280]   Have to go back around and do this again.
[01:59:03.280 --> 01:59:05.280]   And it didn't work.
[01:59:05.280 --> 01:59:09.440]   You'll also be able to do Live View and Location sharing.
[01:59:09.440 --> 01:59:14.880]   So you'll be able to open Google Maps, find your location,
[01:59:14.880 --> 01:59:20.560]   tap on a friend's icon, and tap Live View,
[01:59:20.560 --> 01:59:23.400]   and then point your camera at buildings and signs
[01:59:23.400 --> 01:59:26.960]   across the street, and then send it to the friend
[01:59:26.960 --> 01:59:28.560]   with a little thing that says this way.
[01:59:28.560 --> 01:59:30.280]   So if your friend's close--
[01:59:30.280 --> 01:59:31.040]   That's pretty cool.
[01:59:31.040 --> 01:59:32.360]   That's kind of neat.
[01:59:32.360 --> 01:59:35.480]   I'm over here.
[01:59:35.480 --> 01:59:36.440]   Pins are more accurate.
[01:59:36.440 --> 01:59:42.440]   I mean, I can find my car again.
[01:59:42.440 --> 01:59:44.120]   Yeah, because when a problem was--
[01:59:44.120 --> 01:59:48.000]   the pin wouldn't be intelligent about where it was.
[01:59:48.000 --> 01:59:50.000]   So it might be in top of a building
[01:59:50.000 --> 01:59:52.720]   instead of on the street next to the building.
[01:59:52.720 --> 01:59:53.920]   Well, I've got a weird problem.
[01:59:53.920 --> 01:59:55.720]   Yes.
[01:59:55.720 --> 02:00:00.200]   So for years now, Google doesn't recognize my house.
[02:00:00.200 --> 02:00:01.120]   It knows where my house is.
[02:00:01.120 --> 02:00:02.760]   It knows that in lots of ways.
[02:00:02.760 --> 02:00:06.120]   But if it says that I've reached home a quarter
[02:00:06.120 --> 02:00:08.280]   and a half a mile back.
[02:00:08.280 --> 02:00:11.400]   And I know where home is, so that's not a big deal.
[02:00:11.400 --> 02:00:12.680]   That's not good.
[02:00:12.680 --> 02:00:15.160]   But, but here's the problem.
[02:00:15.160 --> 02:00:17.160]   I can't do--
[02:00:17.160 --> 02:00:18.640]   keep my phone unlocked in my house
[02:00:18.640 --> 02:00:23.400]   because it doesn't recognize the geolocation.
[02:00:23.400 --> 02:00:24.000]   Right.
[02:00:24.000 --> 02:00:28.120]   Well, you shouldn't have that long driveway in that moat.
[02:00:28.120 --> 02:00:29.880]   No, I was going to say if you use--
[02:00:29.880 --> 02:00:32.520]   The crocodiles have to go away.
[02:00:32.520 --> 02:00:34.920]   To create a recipe tied to your phone,
[02:00:34.920 --> 02:00:36.400]   so you'll put the if-tap on your phone,
[02:00:36.400 --> 02:00:40.760]   then you'll go to ifd and you'll use your home Wi-Fi
[02:00:40.760 --> 02:00:41.720]   as a way to keep it unlocked.
[02:00:41.720 --> 02:00:44.120]   Oh, smart.
[02:00:44.120 --> 02:00:46.960]   So what am I calling for bifft?
[02:00:46.960 --> 02:00:47.760]   What's the call in?
[02:00:47.760 --> 02:00:49.320]   What a little--
[02:00:49.320 --> 02:00:51.760]   If you go to-- you have to create an applet.
[02:00:51.760 --> 02:00:53.680]   Let's see if-- and actually, I don't
[02:00:53.680 --> 02:00:59.120]   know if the applet supports unlock my phone.
[02:00:59.120 --> 02:01:03.880]   That's what you get, Jeff, for blurring your house on Google Maps.
[02:01:03.880 --> 02:01:04.880]   You're a blurring.
[02:01:04.880 --> 02:01:06.440]   I'm the last person on Earth will do that.
[02:01:06.440 --> 02:01:07.640]   I am the last person on Earth.
[02:01:07.640 --> 02:01:08.640]   Oh, that's right.
[02:01:08.640 --> 02:01:09.640]   You don't like blurring.
[02:01:09.640 --> 02:01:10.720]   What am I saying?
[02:01:10.720 --> 02:01:12.280]   Oh, is that-- I was like, really?
[02:01:12.280 --> 02:01:13.280]   No, he was not--
[02:01:13.280 --> 02:01:14.280]   He seemed so not Jeff.
[02:01:14.280 --> 02:01:15.280]   Not Jeff.
[02:01:15.280 --> 02:01:16.360]   Hey, here's something I like.
[02:01:16.360 --> 02:01:20.080]   They're going to turn off face retouching
[02:01:20.080 --> 02:01:22.360]   on the Google selfie camera.
[02:01:22.360 --> 02:01:26.840]   And they're going to take away labels for the retouching that
[02:01:26.840 --> 02:01:31.120]   imply that you're ugly.
[02:01:31.120 --> 02:01:32.120]   That's good stuff.
[02:01:32.120 --> 02:01:33.480]   I think this is really good.
[02:01:33.480 --> 02:01:36.680]   They're not going to use the word beauty anymore
[02:01:36.680 --> 02:01:39.600]   for the beauty filter, things like that.
[02:01:39.600 --> 02:01:41.320]   I think that's really good.
[02:01:41.320 --> 02:01:43.240]   You're just going to-- you're going to have a button that
[02:01:43.240 --> 02:01:45.480]   says apply face retouching.
[02:01:45.480 --> 02:01:49.000]   And you'll have a choice between subtle, smooth, and off.
[02:01:49.000 --> 02:01:51.600]   It's not going to say put on a beauty filter.
[02:01:51.600 --> 02:01:52.560]   That's good.
[02:01:52.560 --> 02:01:53.400]   Thank you, Google.
[02:01:53.400 --> 02:01:54.600]   So the same functionality is there.
[02:01:54.600 --> 02:01:55.760]   They just changed the label.
[02:01:55.760 --> 02:01:56.200]   Yeah.
[02:01:56.200 --> 02:01:57.960]   Well, and it's not automatic, either.
[02:01:57.960 --> 02:01:59.120]   It's off by default.
[02:01:59.120 --> 02:02:00.120]   OK, got it.
[02:02:00.120 --> 02:02:02.880]   Because it's always really crappy when you're
[02:02:02.880 --> 02:02:03.680]   just terrible.
[02:02:03.680 --> 02:02:05.000]   You look like crap today.
[02:02:05.000 --> 02:02:05.520]   Yeah.
[02:02:05.520 --> 02:02:06.920]   Yeah, that's what you need.
[02:02:06.920 --> 02:02:08.680]   Let me see if I can help you out.
[02:02:08.680 --> 02:02:09.180]   Sorry.
[02:02:09.180 --> 02:02:09.840]   I'll take a selfie.
[02:02:09.840 --> 02:02:10.800]   I'll do it in the Google things.
[02:02:10.800 --> 02:02:13.560]   Dang, do you have a dirty lens or something?
[02:02:13.560 --> 02:02:15.800]   That really looks bad, brother.
[02:02:15.800 --> 02:02:16.560]   That was a great--
[02:02:16.560 --> 02:02:19.440]   It's the equivalent of, hey, you look tired.
[02:02:19.440 --> 02:02:21.040]   Oh, I hate it when people say that.
[02:02:21.040 --> 02:02:21.960]   They say this to me all the time.
[02:02:21.960 --> 02:02:25.280]   And I just say, no, I'm just old.
[02:02:25.280 --> 02:02:27.720]   I'm just old.
[02:02:27.720 --> 02:02:31.360]   Interesting piece by Eric Fung in the medium.
[02:02:31.360 --> 02:02:35.400]   Why is everybody adding stories?
[02:02:35.400 --> 02:02:39.160]   Google, by the way, one of the companies adding stories.
[02:02:39.160 --> 02:02:40.920]   Slack, just added stories.
[02:02:40.920 --> 02:02:41.280]   Is this--
[02:02:41.280 --> 02:02:41.800]   No.
[02:02:41.800 --> 02:02:44.200]   How are you going to use a Slack story?
[02:02:44.200 --> 02:02:48.200]   This is just one more way to screw off at work.
[02:02:48.200 --> 02:02:51.320]   Every single one, Eric writes of the top eight most popular
[02:02:51.320 --> 02:02:53.880]   social platforms offer their own version of stories.
[02:02:53.880 --> 02:02:57.640]   YouTube, Facebook, Instagram, Pinterest, LinkedIn, Snapchat,
[02:02:57.640 --> 02:02:59.120]   Twitter, and WhatsApp.
[02:02:59.120 --> 02:02:59.600]   And I'm now--
[02:02:59.600 --> 02:03:00.760]   Google has Snapchat, right?
[02:03:00.760 --> 02:03:03.280]   Well, yes, Snapchat invented it.
[02:03:03.280 --> 02:03:05.200]   But now we have to add stories.
[02:03:05.200 --> 02:03:07.360]   Kids like it, so we got to have it for them.
[02:03:07.360 --> 02:03:09.440]   I would like to create a link to the story.
[02:03:09.440 --> 02:03:10.760]   I'm not going to lie.
[02:03:10.760 --> 02:03:13.480]   I would have so much fun making fun of that as a medium.
[02:03:13.480 --> 02:03:15.680]   He writes actually a really good piece in medium
[02:03:15.680 --> 02:03:17.400]   about why stories.
[02:03:17.400 --> 02:03:22.920]   They can be emotionally deep, but they're relatively easy to do.
[02:03:22.920 --> 02:03:24.280]   And I don't know.
[02:03:24.280 --> 02:03:25.640]   Easy to consume.
[02:03:25.640 --> 02:03:26.840]   Easy to consume.
[02:03:26.840 --> 02:03:28.000]   But they disappear, right?
[02:03:28.000 --> 02:03:29.000]   You put effort into them.
[02:03:29.000 --> 02:03:30.360]   You put it in the middle of the day.
[02:03:30.360 --> 02:03:32.680]   Is there any where stories don't disappear like your stories
[02:03:32.680 --> 02:03:33.120]   live on?
[02:03:33.120 --> 02:03:34.400]   I would like that.
[02:03:34.400 --> 02:03:35.320]   Highlights.
[02:03:35.320 --> 02:03:36.360]   Highlights.
[02:03:36.360 --> 02:03:37.480]   Instagram highlights.
[02:03:37.480 --> 02:03:38.600]   Those stay.
[02:03:38.600 --> 02:03:39.760]   And they're just like stories.
[02:03:39.760 --> 02:03:41.520]   They can have video text, all that stuff.
[02:03:41.520 --> 02:03:43.280]   OK, good.
[02:03:43.280 --> 02:03:47.400]   So Google is introducing stories to the Google app.
[02:03:47.400 --> 02:03:49.040]   Just what you need.
[02:03:49.040 --> 02:03:50.040]   Nobody will see them.
[02:03:50.040 --> 02:03:51.320]   Just a genie.
[02:03:51.320 --> 02:03:52.320]   Exactly.
[02:03:52.320 --> 02:03:54.040]   Exactly.
[02:03:54.040 --> 02:03:56.320]   Now, these stories are not made by you and me.
[02:03:56.320 --> 02:04:01.240]   These stories are made by participating publishers.
[02:04:01.240 --> 02:04:01.760]   Full space.
[02:04:01.760 --> 02:04:02.600]   Oh, there we go again.
[02:04:02.600 --> 02:04:03.560]   Yeah, as a little slow.
[02:04:03.560 --> 02:04:04.080]   Right?
[02:04:04.080 --> 02:04:06.200]   So favorite in the big old guys.
[02:04:06.200 --> 02:04:07.360]   No, we're going to have to be--
[02:04:07.360 --> 02:04:07.880]   Go in.
[02:04:07.880 --> 02:04:08.920]   Let's keep going.
[02:04:08.920 --> 02:04:10.960]   What else has happened?
[02:04:10.960 --> 02:04:13.200]   Don't get me started.
[02:04:13.200 --> 02:04:14.240]   No sidetracking.
[02:04:14.240 --> 02:04:14.920]   Keep going.
[02:04:14.920 --> 02:04:16.360]   Google Wi-Fi is back.
[02:04:16.360 --> 02:04:17.560]   99 bucks.
[02:04:17.560 --> 02:04:18.640]   Get one of these pills.
[02:04:18.640 --> 02:04:19.680]   Put it on your thing.
[02:04:19.680 --> 02:04:20.880]   And one 99 question here.
[02:04:20.880 --> 02:04:22.000]   No, no, no, no, no, no, no, no, no, no, no, no, no, no,
[02:04:22.000 --> 02:04:22.760]   because that's not the five giga--
[02:04:22.760 --> 02:04:23.840]   that's not a sorry five.
[02:04:23.840 --> 02:04:24.760]   Don't get it.
[02:04:24.760 --> 02:04:27.280]   It's the AC 1200.
[02:04:27.280 --> 02:04:33.560]   So it's not Wi-Fi 6.
[02:04:33.560 --> 02:04:35.200]   No.
[02:04:35.200 --> 02:04:35.760]   Oh my god.
[02:04:35.760 --> 02:04:36.920]   5G Wi-Fi 6.
[02:04:36.920 --> 02:04:37.800]   It's not Wi-Fi 6.
[02:04:37.800 --> 02:04:38.280]   Don't buy it.
[02:04:38.280 --> 02:04:38.640]   Sorry.
[02:04:38.640 --> 02:04:40.200]   Wi-Fi 6.
[02:04:40.200 --> 02:04:43.120]   But on the other hand, 6E is coming.
[02:04:43.120 --> 02:04:44.440]   So don't buy Wi-Fi 6 either.
[02:04:44.440 --> 02:04:45.200]   Don't buy it.
[02:04:45.200 --> 02:04:47.040]   6E is not going to matter in your house.
[02:04:47.040 --> 02:04:48.200]   OK.
[02:04:48.200 --> 02:04:48.800]   I ask a question.
[02:04:48.800 --> 02:04:50.360]   I mean, old geniuses.
[02:04:50.360 --> 02:04:52.000]   Yes.
[02:04:52.000 --> 02:04:55.120]   So I'm trying to keep my deck going as long as I can.
[02:04:55.120 --> 02:04:56.800]   So I bought a heater for out there.
[02:04:56.800 --> 02:04:57.920]   Yeah.
[02:04:57.920 --> 02:04:59.200]   And the Wi-Fi is not perfect.
[02:04:59.200 --> 02:05:02.840]   So I bought a fourth Google Wi-Fi thing in my jigger.
[02:05:02.840 --> 02:05:03.160]   Right.
[02:05:03.160 --> 02:05:05.040]   Who used that?
[02:05:05.040 --> 02:05:05.880]   I do.
[02:05:05.880 --> 02:05:08.240]   So I already had three of them, so I bought a fourth one.
[02:05:08.240 --> 02:05:09.480]   And I get too late to return it.
[02:05:09.480 --> 02:05:10.480]   So--
[02:05:10.480 --> 02:05:10.760]   Oh.
[02:05:10.760 --> 02:05:14.520]   And so I-- here's the question.
[02:05:14.520 --> 02:05:15.520]   Here's the question.
[02:05:15.520 --> 02:05:18.880]   So to hook it in to the other three,
[02:05:18.880 --> 02:05:24.000]   I got to switch my existing three from Google Wi-Fi to Google
[02:05:24.000 --> 02:05:24.280]   Home.
[02:05:24.280 --> 02:05:26.920]   Is there any booby trap waiting for me there?
[02:05:26.920 --> 02:05:27.400]   Yes.
[02:05:27.400 --> 02:05:28.400]   It's going to be OK.
[02:05:28.400 --> 02:05:28.720]   Oh, no.
[02:05:28.720 --> 02:05:30.640]   I haven't done it, but I can tell you
[02:05:30.640 --> 02:05:33.000]   that that's not going to go the way you want it to go.
[02:05:33.000 --> 02:05:33.480]   Because that's just--
[02:05:33.480 --> 02:05:34.600]   Oh, no.
[02:05:34.600 --> 02:05:35.680]   That's why I'm asking Stacy.
[02:05:35.680 --> 02:05:37.520]   You're the person that asked, oh, no.
[02:05:37.520 --> 02:05:38.120]   What's going to happen?
[02:05:38.120 --> 02:05:40.320]   I don't know how it's going to screw up,
[02:05:40.320 --> 02:05:42.640]   but I guarantee it's going to break something
[02:05:42.640 --> 02:05:47.000]   that you've set up, and you're going to have to deal with it.
[02:05:47.000 --> 02:05:47.440]   I'm sorry.
[02:05:47.440 --> 02:05:50.160]   I wish I could tell you something like cheery and happy.
[02:05:50.160 --> 02:05:54.320]   But every time I've messed with a Google setup,
[02:05:54.320 --> 02:05:56.680]   yeah, just delete everything and start over from scratch.
[02:05:56.680 --> 02:06:04.200]   Why get a Jekkard backpack from Eve's solo hall at $1,000
[02:06:04.200 --> 02:06:09.640]   when you could get one from Samsungite at $200?
[02:06:09.640 --> 02:06:11.400]   Yeah, I'm actually kind of like--
[02:06:11.400 --> 02:06:13.920]   I'm jamming on the design.
[02:06:13.920 --> 02:06:17.560]   I'm like, yeah, it's not crazy expensive.
[02:06:17.560 --> 02:06:18.880]   And--
[02:06:18.880 --> 02:06:23.200]   So the idea is you touch the straps
[02:06:23.200 --> 02:06:25.200]   and you can turn the volume up.
[02:06:25.200 --> 02:06:28.080]   You can actually custom do this stuff too.
[02:06:28.080 --> 02:06:31.400]   So you can just be like, I really--
[02:06:31.400 --> 02:06:34.720]   I'm trying to think of something I do a lot that would make sense.
[02:06:34.720 --> 02:06:35.120]   I listen.
[02:06:35.120 --> 02:06:36.200]   I have to keep your husband's--
[02:06:36.200 --> 02:06:36.840]   --to my sweet stomach.
[02:06:36.840 --> 02:06:37.800]   --with all the Tesla.
[02:06:37.800 --> 02:06:40.320]   Yeah, where's my husband now?
[02:06:40.320 --> 02:06:41.640]   That's not going to be something that--
[02:06:41.640 --> 02:06:44.520]   --has my husband now.
[02:06:44.520 --> 02:06:46.480]   Have Google read my tweets to me.
[02:06:46.480 --> 02:06:48.600]   And then I'll do my custom thing.
[02:06:48.600 --> 02:06:50.760]   Maybe it's, boom, boom, boom, boom.
[02:06:50.760 --> 02:06:53.280]   And then it'll be like, oh, she's making that sign.
[02:06:53.280 --> 02:06:55.600]   All right, let's read her tweets.
[02:06:55.600 --> 02:06:58.160]   That's a really stupid example, I'll be honest.
[02:06:58.160 --> 02:07:00.560]   But otherwise volume, I get--
[02:07:00.560 --> 02:07:01.060]   It worked.
[02:07:01.060 --> 02:07:03.480]   --out of the down-skip songs.
[02:07:03.480 --> 02:07:06.000]   Talk to Google Assistant, all of that.
[02:07:06.000 --> 02:07:07.440]   You could do all of it.
[02:07:07.440 --> 02:07:10.680]   No bell prizes in chemistry for only, I think,
[02:07:10.680 --> 02:07:15.400]   the third time ever go to a woman for their work.
[02:07:15.400 --> 02:07:18.240]   Ladies, who now do you whisper.
[02:07:18.240 --> 02:07:21.640]   Emmanuelle Chopin Tye and Jennifer Doudna,
[02:07:21.640 --> 02:07:25.440]   the 2020 Nobel Prize in Chemistry for discovering
[02:07:25.440 --> 02:07:31.400]   crisper the castline genetic citizens used to cut DNA.
[02:07:31.400 --> 02:07:34.040]   Nice job.
[02:07:34.040 --> 02:07:34.960]   Nice job.
[02:07:34.960 --> 02:07:37.480]   And they seem like nice ladies, too.
[02:07:39.960 --> 02:07:41.040]   I like it when--
[02:07:41.040 --> 02:07:41.560]   So stuff.
[02:07:41.560 --> 02:07:44.560]   I like it when people win Nobel prizes.
[02:07:44.560 --> 02:07:48.280]   There's also a Nobel Prize for physics
[02:07:48.280 --> 02:07:54.080]   going to the fellas, the three fellas, who
[02:07:54.080 --> 02:07:58.600]   discovered or make big breakthroughs in black holes.
[02:07:58.600 --> 02:08:00.820]   Sir Roger Penrose, the best known,
[02:08:00.820 --> 02:08:04.040]   Andrea Gayes and Reinhardt Genssel.
[02:08:04.040 --> 02:08:08.400]   Penrose is a Brit, very popular in Great Britain.
[02:08:08.400 --> 02:08:12.200]   For his science books, he gets a half share
[02:08:12.200 --> 02:08:16.760]   of the Swedish 10 million croner.
[02:08:16.760 --> 02:08:18.760]   And a stick of dynamite, no.
[02:08:18.760 --> 02:08:21.040]   Really, they should give a stick of dynamite.
[02:08:21.040 --> 02:08:23.640]   Because after all, this is Alfred Nobel's Penance
[02:08:23.640 --> 02:08:25.640]   for inventing dynamite.
[02:08:25.640 --> 02:08:28.280]   He gets his money for the discovery
[02:08:28.280 --> 02:08:31.720]   that black hole formation is a robust prediction
[02:08:31.720 --> 02:08:34.760]   of the general theory of relativity.
[02:08:34.760 --> 02:08:36.800]   Are we still in the change line?
[02:08:36.800 --> 02:08:38.120]   Oh, no, we're not.
[02:08:38.120 --> 02:08:39.920]   I'm sorry, I forgot to stop it.
[02:08:39.920 --> 02:08:42.800]   And that's the Google change log.
[02:08:42.800 --> 02:08:44.440]   Good question.
[02:08:44.440 --> 02:08:46.160]   These are all things you can Google.
[02:08:46.160 --> 02:08:47.520]   That's how we should just--
[02:08:47.520 --> 02:08:48.520]   Wow.
[02:08:48.520 --> 02:08:49.520]   I moved on.
[02:08:49.520 --> 02:08:50.080]   We did a sidetrack.
[02:08:50.080 --> 02:08:51.760]   Google holds black holes.
[02:08:51.760 --> 02:08:53.000]   Of course they do.
[02:08:53.000 --> 02:08:57.880]   I think we should do a commercial and finish this up
[02:08:57.880 --> 02:08:59.120]   with your picks of the week.
[02:08:59.120 --> 02:09:01.400]   So say us all.
[02:09:01.400 --> 02:09:02.120]   So say us all.
[02:09:02.120 --> 02:09:03.520]   I see we all.
[02:09:03.520 --> 02:09:05.600]   I see we all.
[02:09:05.600 --> 02:09:09.040]   This show was brought to you this week by Twilio.
[02:09:09.040 --> 02:09:10.240]   Love the Twilio.
[02:09:10.240 --> 02:09:12.160]   Do you ever do any Twilio stuff?
[02:09:12.160 --> 02:09:15.480]   Stacey, it feels like you could might have, maybe.
[02:09:15.480 --> 02:09:16.120]   Yes.
[02:09:16.120 --> 02:09:17.480]   Well, and yes.
[02:09:17.480 --> 02:09:19.080]   Yes, I have done things with Twilio.
[02:09:19.080 --> 02:09:19.600]   I love Twilio.
[02:09:19.600 --> 02:09:21.160]   I use their Sim.
[02:09:21.160 --> 02:09:22.840]   They used to host our voicemail.
[02:09:22.840 --> 02:09:23.680]   See?
[02:09:23.680 --> 02:09:24.680]   See?
[02:09:24.680 --> 02:09:25.800]   They still host a phone number.
[02:09:25.800 --> 02:09:29.000]   And they just forced me to move to two-factor authentication.
[02:09:29.000 --> 02:09:31.800]   As they should, they created Authy,
[02:09:31.800 --> 02:09:34.480]   which is the best two-factor authenticator in the plan
[02:09:34.480 --> 02:09:35.840]   and the one I've been recommending.
[02:09:35.840 --> 02:09:37.440]   But that's really a small part of their business.
[02:09:37.440 --> 02:09:41.240]   What Twilio really is is about communication.
[02:09:41.240 --> 02:09:43.640]   It's a platform for developers that
[02:09:43.640 --> 02:09:47.840]   lets you build new ways to talk to your customers.
[02:09:47.840 --> 02:09:50.280]   Basically, wherever your customers might be,
[02:09:50.280 --> 02:09:51.520]   text messages, sure.
[02:09:51.520 --> 02:09:52.800]   Emails, you got it.
[02:09:52.800 --> 02:09:57.160]   Phone calls, video, newsletters.
[02:09:57.160 --> 02:10:01.040]   Let me give you some idea of the scale Twilio operates at.
[02:10:01.040 --> 02:10:06.360]   795 plus billion interactions.
[02:10:06.360 --> 02:10:10.920]   With 5 nines of uptime, that's 99.999% uptime.
[02:10:10.920 --> 02:10:15.800]   And 3 billion phone numbers across more than 100 countries.
[02:10:15.800 --> 02:10:17.320]   I think Twilio's the coolest.
[02:10:17.320 --> 02:10:19.760]   I've had a Twilio account for years.
[02:10:19.760 --> 02:10:23.640]   Just for my little toy applications.
[02:10:23.640 --> 02:10:25.440]   But man, big companies use it.
[02:10:25.440 --> 02:10:28.800]   Shopify runs their entire global contact center.
[02:10:28.800 --> 02:10:32.840]   More than a million customers on Twilio's Flex platform.
[02:10:32.840 --> 02:10:35.720]   That's their programmable contact center solution.
[02:10:35.720 --> 02:10:39.880]   Blue Apron powers, newsletter, emails with Twilio's Send Grid.
[02:10:39.880 --> 02:10:43.120]   Netflix, you ever used to factor on Netflix, you auto?
[02:10:43.120 --> 02:10:45.040]   And of course, how do they do it?
[02:10:45.040 --> 02:10:49.680]   Twilio, ride sharing and contact list delivery services,
[02:10:49.680 --> 02:10:56.240]   like Lyft and Uber, connect riders and drivers over text
[02:10:56.240 --> 02:10:58.800]   messaging with Twilio.
[02:10:58.800 --> 02:11:01.600]   Developers love Twilio.
[02:11:01.600 --> 02:11:02.920]   And so will you.
[02:11:02.920 --> 02:11:06.000]   Product and operation teams use Twilio to create new ways
[02:11:06.000 --> 02:11:09.120]   to communicate with their users inside applications.
[02:11:09.120 --> 02:11:12.240]   Everything from account notifications to text messaging
[02:11:12.240 --> 02:11:14.840]   to chatbots-- yep, Twilio does it--
[02:11:14.840 --> 02:11:17.400]   to securing online accounts with two factor.
[02:11:17.400 --> 02:11:20.440]   Marketing teams will use Twilio to get the word out.
[02:11:20.440 --> 02:11:22.240]   With text messaging and phone calls,
[02:11:22.240 --> 02:11:24.320]   they send campaigns over email.
[02:11:24.320 --> 02:11:26.560]   They build chatbots to answer questions.
[02:11:26.560 --> 02:11:29.800]   Customer service teams love Twilio Flex.
[02:11:29.800 --> 02:11:33.320]   They can build global contact and support centers with Flex.
[02:11:33.320 --> 02:11:37.920]   It's a fully programmable contact center application.
[02:11:37.920 --> 02:11:41.480]   Look, you don't have to be a telecom guru
[02:11:41.480 --> 02:11:46.320]   to create great Twilio programs.
[02:11:46.320 --> 02:11:48.440]   You can do it with a few lines of code.
[02:11:48.440 --> 02:11:51.000]   In fact, if you already know how to do web apps,
[02:11:51.000 --> 02:11:53.360]   you have everything you need to know to build apps that text
[02:11:53.360 --> 02:11:57.080]   call chat video conference, because Twilio does the hard part.
[02:11:57.080 --> 02:12:00.320]   It's built by developers, for developers,
[02:12:00.320 --> 02:12:02.040]   and it is fantastic.
[02:12:02.040 --> 02:12:04.200]   Strengthen your customer relationships
[02:12:04.200 --> 02:12:08.520]   by uniting communications across your entire business.
[02:12:08.520 --> 02:12:11.000]   That's what Julie did at Blue Apron.
[02:12:11.000 --> 02:12:13.840]   Go to Twilio.com to learn more today.
[02:12:13.840 --> 02:12:15.440]   Twilio--
[02:12:15.440 --> 02:12:19.360]   T-W-I-L-I-O.com.
[02:12:19.360 --> 02:12:22.920]   Twilio, it's time to build.
[02:12:22.920 --> 02:12:24.520]   Yeah, I ask that question all the time,
[02:12:24.520 --> 02:12:26.360]   and I knew if I asked you, Stacy, you'd say yes,
[02:12:26.360 --> 02:12:27.720]   because everybody I know--
[02:12:27.720 --> 02:12:31.000]   I'm sure Andrew's like all over the Twilio.
[02:12:31.000 --> 02:12:34.880]   Everybody I know who does anything in this area
[02:12:34.880 --> 02:12:36.800]   says, oh, yeah, that's the best.
[02:12:36.800 --> 02:12:39.120]   I need a shirt that says I'm all over the Twilio.
[02:12:39.120 --> 02:12:41.080]   All over the Twilio.
[02:12:41.080 --> 02:12:47.840]   By the year 2245, if man is still alive,
[02:12:47.840 --> 02:12:51.720]   half the atoms on the earth will be digital data.
[02:12:51.720 --> 02:12:53.320]   So--
[02:12:53.320 --> 02:12:54.640]   No sense.
[02:12:54.640 --> 02:12:56.240]   Only hands.
[02:12:56.240 --> 02:12:58.000]   I don't know.
[02:12:58.000 --> 02:12:59.000]   Well, OK.
[02:12:59.000 --> 02:13:00.920]   It's the transmission of electrons
[02:13:00.920 --> 02:13:02.680]   that flip in a transistor.
[02:13:02.680 --> 02:13:03.960]   That's your 0 or 1.
[02:13:03.960 --> 02:13:06.280]   So an electron is--
[02:13:06.280 --> 02:13:07.640]   it's part of an atom.
[02:13:07.640 --> 02:13:11.680]   So this is the work of Melvin.
[02:13:11.680 --> 02:13:13.040]   Some guy named Melvin.
[02:13:13.040 --> 02:13:16.640]   No, this is the work of Melvin's taking you to the--
[02:13:16.640 --> 02:13:18.320]   some guy named Melvin figures that.
[02:13:18.320 --> 02:13:21.520]   No, Melvin Vopsen, he's from the University of Portsmouth
[02:13:21.520 --> 02:13:22.880]   in England.
[02:13:22.880 --> 02:13:25.720]   He started at the fact that the earth contains roughly 10
[02:13:25.720 --> 02:13:30.040]   to the 21st or 100 billion, billion bits of computer
[02:13:30.040 --> 02:13:36.840]   information, assuming a 20% digital annual growth rate.
[02:13:36.840 --> 02:13:38.800]   He showed that 350 years from now,
[02:13:38.800 --> 02:13:40.000]   the number of data bits in the earth
[02:13:40.000 --> 02:13:41.640]   will be greater than all the atoms
[02:13:41.640 --> 02:13:45.480]   inside it, of which there are 10 to the 50th or 100th trillion.
[02:13:45.480 --> 02:13:46.080]   That doesn't mean--
[02:13:46.080 --> 02:13:47.040]   That doesn't mean--
[02:13:47.040 --> 02:13:48.840]   The atoms are data.
[02:13:48.840 --> 02:13:49.360]   No.
[02:13:49.360 --> 02:13:50.280]   That's why no sense.
[02:13:50.280 --> 02:13:51.440]   It makes no sense.
[02:13:51.440 --> 02:13:54.520]   There'll be more bits of data than there are atoms at earth.
[02:13:54.520 --> 02:13:55.320]   What is it bit?
[02:13:55.320 --> 02:13:58.120]   Stacey is a bit an electron.
[02:13:58.120 --> 02:13:58.920]   A bit is a--
[02:13:58.920 --> 02:13:59.480]   It's a state.
[02:13:59.480 --> 02:14:00.640]   A bit is a piece of--
[02:14:00.640 --> 02:14:02.160]   Yeah, it's a state.
[02:14:02.160 --> 02:14:02.960]   It's a zero or a--
[02:14:02.960 --> 02:14:04.160]   It's not stored.
[02:14:04.160 --> 02:14:05.600]   It's a state.
[02:14:05.600 --> 02:14:07.000]   Yeah.
[02:14:07.000 --> 02:14:08.200]   That's why I'm confused.
[02:14:08.200 --> 02:14:10.400]   And then we're also going to be transmitting data
[02:14:10.400 --> 02:14:11.960]   optically soon.
[02:14:11.960 --> 02:14:12.520]   So--
[02:14:12.520 --> 02:14:13.000]   Exactly.
[02:14:13.000 --> 02:14:13.520]   Then what?
[02:14:13.520 --> 02:14:14.720]   And multiple layers.
[02:14:14.720 --> 02:14:15.840]   Leo, that was a--
[02:14:15.840 --> 02:14:17.360]   take it from the expert numbers.
[02:14:17.360 --> 02:14:18.000]   That was a crime.
[02:14:18.000 --> 02:14:19.880]   You should have done 39.
[02:14:19.880 --> 02:14:21.280]   That was an awful number, Leo.
[02:14:21.280 --> 02:14:22.280]   All right, well--
[02:14:22.280 --> 02:14:22.480]   I'm the number--
[02:14:22.480 --> 02:14:23.280]   Expert numbers.
[02:14:23.280 --> 02:14:23.880]   Oh, yeah.
[02:14:23.880 --> 02:14:26.000]   What the hell do you call this letter?
[02:14:26.000 --> 02:14:29.480]   It's a Y with two dots above it.
[02:14:29.480 --> 02:14:31.440]   And how do you pronounce it?
[02:14:31.440 --> 02:14:33.000]   Yee.
[02:14:33.000 --> 02:14:35.040]   It's the first letter in--
[02:14:35.040 --> 02:14:39.160]   Is that the next child of Tesla owner?
[02:14:39.160 --> 02:14:40.600]   Maybe Yee.
[02:14:40.600 --> 02:14:44.320]   It happens to be the first letter of a startup that
[02:14:44.320 --> 02:14:50.920]   just raised another $224 million, adding that to its already
[02:14:50.920 --> 02:14:55.480]   impressive $148 million cash haul.
[02:14:55.480 --> 02:14:59.000]   Oh, there might be a hole because their business is--
[02:14:59.000 --> 02:15:00.040]   Speaking of black holes--
[02:15:00.040 --> 02:15:02.120]   Raising bugs.
[02:15:02.120 --> 02:15:02.640]   They're a big--
[02:15:02.640 --> 02:15:03.200]   For food.
[02:15:03.200 --> 02:15:05.480]   Bug-- yeah, for food.
[02:15:05.480 --> 02:15:06.360]   Yeah.
[02:15:06.360 --> 02:15:09.120]   They're a big bug farm.
[02:15:09.120 --> 02:15:11.040]   They want to do-- actually, it's for fish food,
[02:15:11.040 --> 02:15:12.880]   so we don't have to eat it.
[02:15:12.880 --> 02:15:14.360]   And it's vertical farming.
[02:15:14.360 --> 02:15:15.720]   Well, it's not really vertical farming,
[02:15:15.720 --> 02:15:17.640]   but they've borrowed from vertical farming,
[02:15:17.640 --> 02:15:20.320]   and they do these massive trays of mealworms, which--
[02:15:20.320 --> 02:15:20.840]   Yes.
[02:15:20.840 --> 02:15:23.040]   I can't imagine-- if you imagine walking
[02:15:23.040 --> 02:15:26.000]   into a container full of mealworms, gross.
[02:15:26.000 --> 02:15:30.040]   High-tech vertical insect farms.
[02:15:30.040 --> 02:15:32.640]   Perfect proteins, these mealworms for fish.
[02:15:32.640 --> 02:15:36.720]   But what do the mealworms eat?
[02:15:36.720 --> 02:15:42.480]   When do we start creating farms for the mealworms?
[02:15:42.480 --> 02:15:44.600]   Oh, they're not flying in gregarious, y'all.
[02:15:44.600 --> 02:15:46.080]   They love to be together.
[02:15:46.080 --> 02:15:47.120]   Good, because--
[02:15:47.120 --> 02:15:48.120]   They're a little sock.
[02:15:48.120 --> 02:15:50.040]   They're kind of jammed together in that vertical bug
[02:15:50.040 --> 02:15:51.040]   farm.
[02:15:51.040 --> 02:15:52.840]   Crickets, apparently, are not good for that,
[02:15:52.840 --> 02:15:54.400]   because they need more space.
[02:15:54.400 --> 02:15:54.920]   OK.
[02:15:54.920 --> 02:15:55.600]   Yep.
[02:15:55.600 --> 02:15:56.520]   Yep.
[02:15:56.520 --> 02:15:57.800]   I love it.
[02:15:57.800 --> 02:16:00.720]   I wonder if they use TikTok.
[02:16:00.720 --> 02:16:04.320]   My thing of the week, you guys, is great.
[02:16:04.320 --> 02:16:09.040]   I really do like it, and it's plugged in kind of far away,
[02:16:09.040 --> 02:16:10.240]   so it's hard for me to show you.
[02:16:10.240 --> 02:16:11.280]   I'm trying.
[02:16:11.280 --> 02:16:13.880]   This is the new Google audio.
[02:16:13.880 --> 02:16:14.880]   It's pretty.
[02:16:14.880 --> 02:16:15.440]   It's sand.
[02:16:15.440 --> 02:16:16.280]   Very pretty.
[02:16:16.280 --> 02:16:17.560]   It matches my pink walls.
[02:16:17.560 --> 02:16:18.520]   It's fabric color.
[02:16:18.520 --> 02:16:18.960]   It's pretty.
[02:16:18.960 --> 02:16:19.960]   Fabric all over.
[02:16:19.960 --> 02:16:20.960]   It's fabric color.
[02:16:20.960 --> 02:16:21.960]   What's the back look like?
[02:16:21.960 --> 02:16:23.160]   I never show the back.
[02:16:23.160 --> 02:16:23.640]   Nothing.
[02:16:23.640 --> 02:16:24.120]   Ta-da.
[02:16:24.120 --> 02:16:24.640]   Looks like nothing.
[02:16:24.640 --> 02:16:25.840]   No, there is something.
[02:16:25.840 --> 02:16:27.440]   There is a mic.
[02:16:27.440 --> 02:16:27.800]   Yes.
[02:16:27.800 --> 02:16:29.640]   This is the mic turn off button.
[02:16:29.640 --> 02:16:30.800]   Yeah, the mute.
[02:16:30.800 --> 02:16:31.240]   Yep.
[02:16:31.240 --> 02:16:31.720]   Always like it.
[02:16:31.720 --> 02:16:32.240]   Thank you.
[02:16:32.240 --> 02:16:32.240]   Mute.
[02:16:32.240 --> 02:16:33.400]   Google always does that.
[02:16:33.400 --> 02:16:33.960]   Yep.
[02:16:33.960 --> 02:16:35.200]   And on Google's stuff with cameras,
[02:16:35.200 --> 02:16:38.400]   it blocks the camera, too, which is nice.
[02:16:38.400 --> 02:16:38.920]   Yes.
[02:16:38.920 --> 02:16:39.920]   Cool.
[02:16:39.920 --> 02:16:40.920]   Oh, there's a--
[02:16:40.920 --> 02:16:41.440]   The mark?
[02:16:41.440 --> 02:16:42.760]   OK, so--
[02:16:42.760 --> 02:16:44.520]   Mark, Mark, Mark, Mark, Mark.
[02:16:44.520 --> 02:16:47.400]   So it is--
[02:16:47.400 --> 02:16:48.600]   what do you want to know about it?
[02:16:48.600 --> 02:16:49.600]   It sounds--
[02:16:49.600 --> 02:16:50.600]   I want to hear the music.
[02:16:50.600 --> 02:16:51.600]   Sound good?
[02:16:51.600 --> 02:16:52.600]   What do you want?
[02:16:52.600 --> 02:16:54.120]   Yeah, it sounds really good, actually.
[02:16:54.120 --> 02:16:55.400]   I'm thinking--
[02:16:55.400 --> 02:16:59.440]   I've got this huge space to fill, and I think two of these might do it, but I also want
[02:16:59.440 --> 02:17:01.240]   to test the Echo Studio.
[02:17:01.240 --> 02:17:02.240]   OK.
[02:17:02.240 --> 02:17:04.240]   You could do stereo pairing.
[02:17:04.240 --> 02:17:05.240]   You could do multi-resound.
[02:17:05.240 --> 02:17:06.240]   You can do stereo pairing.
[02:17:06.240 --> 02:17:07.240]   Yeah.
[02:17:07.240 --> 02:17:09.760]   And you can say, send this music to the kitchen or--
[02:17:09.760 --> 02:17:11.880]   Oh, I like that.
[02:17:11.880 --> 02:17:13.600]   Do all these things.
[02:17:13.600 --> 02:17:17.800]   And Google says that it's adaptive.
[02:17:17.800 --> 02:17:23.120]   Like, in terms of if I turn on a fan or people are shouting, it will respond to that.
[02:17:23.120 --> 02:17:29.040]   In my tests, it told me to-- Google was like, take a toothbrush or a razor, like a shaver
[02:17:29.040 --> 02:17:31.640]   and go near it, and you will hear the music change.
[02:17:31.640 --> 02:17:33.680]   But I didn't hear it in either day to day to day to day.
[02:17:33.680 --> 02:17:34.680]   All right.
[02:17:34.680 --> 02:17:35.680]   So I don't know what that's about.
[02:17:35.680 --> 02:17:37.320]   Like, the musical change if you're brushing your teeth?
[02:17:37.320 --> 02:17:45.520]   Well, like, if you bring a noise close to the speaker, it's supposed to somehow adapt to
[02:17:45.520 --> 02:17:49.120]   that and play it louder so it doesn't change the way you hear it.
[02:17:49.120 --> 02:17:50.120]   Oh.
[02:17:50.120 --> 02:17:51.120]   But--
[02:17:51.120 --> 02:17:52.120]   Oh, I get it.
[02:17:52.120 --> 02:17:56.440]   I don't have the equipment to measure that.
[02:17:56.440 --> 02:17:59.840]   And just based on my hearing, I could not tell anything.
[02:17:59.840 --> 02:18:02.560]   I don't remember what piece I was listening to.
[02:18:02.560 --> 02:18:05.120]   I was listening to some classical music.
[02:18:05.120 --> 02:18:09.760]   Oh, is Yo-Yo-Maw playing Bach, I think it was.
[02:18:09.760 --> 02:18:10.760]   Oh, nice.
[02:18:10.760 --> 02:18:15.400]   So it sounded really nice and then there was some--
[02:18:15.400 --> 02:18:16.400]   Oh, go?
[02:18:16.400 --> 02:18:17.400]   Maybe coming in.
[02:18:17.400 --> 02:18:21.320]   I mean, it's still a low instrument, but it's different than a cello.
[02:18:21.320 --> 02:18:25.400]   It was very distinct and clear, and it did sound good.
[02:18:25.400 --> 02:18:26.960]   So yeah, I like this.
[02:18:26.960 --> 02:18:33.040]   I mean, it's not going to compete with maybe your Otis or the Dina drivers or--
[02:18:33.040 --> 02:18:37.040]   Yeah, unfortunately, I already bought a pair of speakers doing this show, so I can't buy
[02:18:37.040 --> 02:18:38.040]   it anymore.
[02:18:38.040 --> 02:18:39.040]   Yeah.
[02:18:39.040 --> 02:18:44.760]   It's only $99, and we'll be able to see when we get the Amazon Echo 4, which is what this
[02:18:44.760 --> 02:18:47.600]   is going to compete with at a price point.
[02:18:47.600 --> 02:18:50.080]   And the other thing is it's heavy.
[02:18:50.080 --> 02:18:53.400]   It's like almost 2.6 pounds, I think?
[02:18:53.400 --> 02:18:54.640]   2.8 pounds?
[02:18:54.640 --> 02:18:59.120]   So it's a-- which is nice for a speaker.
[02:18:59.120 --> 02:19:00.800]   And yeah, I like it.
[02:19:00.800 --> 02:19:01.800]   Nice.
[02:19:01.800 --> 02:19:02.800]   And I can give you-- do y'all want specs?
[02:19:02.800 --> 02:19:03.800]   I have a spec sheet.
[02:19:03.800 --> 02:19:05.360]   No, no, we can look at that.
[02:19:05.360 --> 02:19:06.360]   OK.
[02:19:06.360 --> 02:19:07.360]   I'm going to see what I want those and how it sounds.
[02:19:07.360 --> 02:19:08.360]   This was one more thing.
[02:19:08.360 --> 02:19:16.360]   It's dual band Wi-Fi, so it will work on 2.4 and 5-piggers, which is nice.
[02:19:16.360 --> 02:19:17.360]   Ooh, that's good.
[02:19:17.360 --> 02:19:18.360]   So--
[02:19:18.360 --> 02:19:19.360]   And it has Bluetooth.
[02:19:19.360 --> 02:19:24.560]   Could I play-- I wonder if it would play the high res music, say, from title or DZR,
[02:19:24.560 --> 02:19:26.360]   or prime phonic, my classical voice?
[02:19:26.360 --> 02:19:28.600]   I don't know about that.
[02:19:28.600 --> 02:19:29.600]   That's interesting.
[02:19:29.600 --> 02:19:30.600]   They didn't mention that.
[02:19:30.600 --> 02:19:34.000]   5G has enough bandwidth to do that, for sure.
[02:19:34.000 --> 02:19:35.000]   Yeah.
[02:19:35.000 --> 02:19:40.400]   My pick of the week is this band I just discovered called "Boney James."
[02:19:40.400 --> 02:19:42.600]   You ever hear about them?
[02:19:42.600 --> 02:19:43.600]   Plays the sax.
[02:19:43.600 --> 02:19:44.600]   And on the sax.
[02:19:44.600 --> 02:19:45.600]   I loved that.
[02:19:45.600 --> 02:19:47.080]   I thought that sounded great.
[02:19:47.080 --> 02:19:49.600]   Thank you, Anne, for that recommendation.
[02:19:49.600 --> 02:19:50.600]   Really good.
[02:19:50.600 --> 02:19:53.560]   A number of the weeks for Mr. Jeffrey Jarvis.
[02:19:53.560 --> 02:19:57.360]   Well, I'm going to-- with one number, I'm just going to tear apart all your arguments
[02:19:57.360 --> 02:19:58.360]   about antitrust.
[02:19:58.360 --> 02:20:03.160]   I'm just going to make it all completely irrelevant and show you-- you're just behind the times,
[02:20:03.160 --> 02:20:05.160]   just-- you're fighting yesterday's power.
[02:20:05.160 --> 02:20:06.160]   Yes, it is.
[02:20:06.160 --> 02:20:07.720]   It doesn't matter.
[02:20:07.720 --> 02:20:14.480]   So in only three years now, TikTok is the size of-- half the size of Facebook.
[02:20:14.480 --> 02:20:15.480]   Wow.
[02:20:15.480 --> 02:20:17.480]   In the UK.
[02:20:17.480 --> 02:20:26.400]   17 million people using it over an hour a day on the app versus 37 million users in
[02:20:26.400 --> 02:20:30.200]   the UK for Facebook.
[02:20:30.200 --> 02:20:34.280]   So who needs antitrust regulations when the market will do something?
[02:20:34.280 --> 02:20:36.760]   And by the way, you want to regulate TikTok?
[02:20:36.760 --> 02:20:39.920]   Good, effing luck.
[02:20:39.920 --> 02:20:44.920]   British users are the most numerous in Europe, but they're not the most dedicated.
[02:20:44.920 --> 02:20:49.960]   TikTok's 1.2 million Norwegian users open the app 17 times a day, spending 74 minutes
[02:20:49.960 --> 02:20:50.960]   scrolling through the video.
[02:20:50.960 --> 02:20:52.360]   Because what the heck is cold up there?
[02:20:52.360 --> 02:20:57.080]   There's nothing else to do but to recognize that you're in a wonderful place.
[02:20:57.080 --> 02:20:58.160]   You don't have to worry about life.
[02:20:58.160 --> 02:20:59.520]   You can just watch TikTok.
[02:20:59.520 --> 02:21:00.840]   It sounds lovely to me.
[02:21:00.840 --> 02:21:02.760]   I would love to do that.
[02:21:02.760 --> 02:21:06.800]   France has 11 million users, Germany, 10.7 million.
[02:21:06.800 --> 02:21:09.120]   TikTok's pretty good.
[02:21:09.120 --> 02:21:11.440]   So TikTok's growing away.
[02:21:11.440 --> 02:21:12.440]   Italians 9.8.
[02:21:12.440 --> 02:21:15.800]   I'm going to really miss them next month when they go away.
[02:21:15.800 --> 02:21:17.840]   Yeah.
[02:21:17.840 --> 02:21:21.840]   The Commerce Department cuts off the spigot.
[02:21:21.840 --> 02:21:25.840]   In Spain, the other three quarters, TikTok users are female.
[02:21:25.840 --> 02:21:30.280]   TikTok's Nordic audiences evenly split along gender lines.
[02:21:30.280 --> 02:21:33.840]   And so that's my number of the week.
[02:21:33.840 --> 02:21:35.600]   Thank you, Mr. Jeff Jarvis.
[02:21:35.600 --> 02:21:38.480]   And now Ant Pruitt's pick.
[02:21:38.480 --> 02:21:39.480]   I got two.
[02:21:39.480 --> 02:21:42.280]   The first one is a bit of a bone to pick with you.
[02:21:42.280 --> 02:21:43.280]   Uh-oh.
[02:21:43.280 --> 02:21:45.360]   It's on the panel for a bit this past Sunday.
[02:21:45.360 --> 02:21:46.840]   What did I do?
[02:21:46.840 --> 02:21:50.120]   Talking about the $2 bill as if no one uses the $2 bill.
[02:21:50.120 --> 02:21:51.960]   No one uses the $2 bill.
[02:21:51.960 --> 02:21:53.960]   Well, Le Kieres, sir.
[02:21:53.960 --> 02:21:54.960]   Where'd you get that?
[02:21:54.960 --> 02:21:57.400]   Oh, it's got a Clemson paw print on it.
[02:21:57.400 --> 02:21:59.320]   That is a Clemson tiger $2 bill.
[02:21:59.320 --> 02:22:00.320]   Can you use that?
[02:22:00.320 --> 02:22:01.320]   Isn't that illegal?
[02:22:01.320 --> 02:22:05.160]   Aren't you a legal legal tater?
[02:22:05.160 --> 02:22:07.880]   We go to the banks.
[02:22:07.880 --> 02:22:13.160]   And we've stamped our $2 bills for every time we go out of town for an away game.
[02:22:13.160 --> 02:22:15.160]   The $2 bills.
[02:22:15.160 --> 02:22:16.160]   That's cool.
[02:22:16.160 --> 02:22:17.600]   So you've been to two away games?
[02:22:17.600 --> 02:22:20.720]   No, this is just one that I've kept.
[02:22:20.720 --> 02:22:22.200]   Oh, that's cool.
[02:22:22.200 --> 02:22:23.200]   But yeah, the idea was--
[02:22:23.200 --> 02:22:29.800]   I put a link in our show notes to the coach wanted to spread the word about Clemson fans
[02:22:29.800 --> 02:22:34.440]   traveling and going to the football games and say, hey, pay with your $2 bills.
[02:22:34.440 --> 02:22:39.640]   And it spawned into paying with $2 bills with the paw stamp on them.
[02:22:39.640 --> 02:22:43.560]   That way the merchant knows, oh, they're in town for a tiger's game.
[02:22:43.560 --> 02:22:45.560]   And so that's all we get.
[02:22:45.560 --> 02:22:51.000]   And I know it's different this season, but college football bowl season is pretty big
[02:22:51.000 --> 02:22:56.200]   for money and people are always just hoping, please bring Clemson.
[02:22:56.200 --> 02:23:01.800]   Please bring Clemson because Clemson fans travel and they spend money in this proof of it right
[02:23:01.800 --> 02:23:02.800]   there.
[02:23:02.800 --> 02:23:07.040]   Well, because we were talking about how $2 bills you can apparently-- I didn't know this
[02:23:07.040 --> 02:23:14.280]   by them from the US Treasury uncut, so like on a sheet, and that Steve Wozniak takes the
[02:23:14.280 --> 02:23:17.560]   $2 bills and binds them into a pad.
[02:23:17.560 --> 02:23:22.680]   Here he is holding a pad of $2 bills.
[02:23:22.680 --> 02:23:27.320]   And then when he goes to his store, he cuts a bill off the same.
[02:23:27.320 --> 02:23:28.320]   I love it.
[02:23:28.320 --> 02:23:29.320]   I love it, too.
[02:23:29.320 --> 02:23:30.800]   He gives it to him.
[02:23:30.800 --> 02:23:36.600]   And the whole game is he's trying to get them to accuse him of counterfeiting.
[02:23:36.600 --> 02:23:40.920]   So he'll say things, oh, this is approved by the US Treasury.
[02:23:40.920 --> 02:23:41.920]   Oh, geeks, man.
[02:23:41.920 --> 02:23:46.320]   I love geeks are so much of a geek.
[02:23:46.320 --> 02:23:47.320]   So that's good.
[02:23:47.320 --> 02:23:49.640]   And then there are other uses for $2 bills.
[02:23:49.640 --> 02:23:50.640]   Yeah.
[02:23:50.640 --> 02:23:53.840]   And then what town is Clemson in?
[02:23:53.840 --> 02:23:55.320]   Clemson, South Carolina.
[02:23:55.320 --> 02:23:57.840]   His name is Clemson.
[02:23:57.840 --> 02:24:03.600]   So I don't think the merchants of Clemson have underestimated the impact of Clemson football
[02:24:03.600 --> 02:24:04.920]   on their business.
[02:24:04.920 --> 02:24:05.920]   I'm guessing.
[02:24:05.920 --> 02:24:08.120]   I'm just guessing.
[02:24:08.120 --> 02:24:09.120]   We were--
[02:24:09.120 --> 02:24:12.960]   It's always funny, though, that a couple of times that I've traveled, not even related
[02:24:12.960 --> 02:24:17.280]   to football and people would know that I'm a fan, they always mention, oh, we know
[02:24:17.280 --> 02:24:20.480]   when you guys are in town because you bring those dad gum $2.
[02:24:20.480 --> 02:24:21.480]   That's hysterical.
[02:24:21.480 --> 02:24:22.920]   I love that.
[02:24:22.920 --> 02:24:24.080]   I did not know that.
[02:24:24.080 --> 02:24:25.080]   That's a great story.
[02:24:25.080 --> 02:24:27.200]   What was your other pick?
[02:24:27.200 --> 02:24:30.040]   My other one is October.
[02:24:30.040 --> 02:24:32.520]   This is breast cancer awareness month.
[02:24:32.520 --> 02:24:35.920]   I don't know how long I've been wearing this little breast cancer.
[02:24:35.920 --> 02:24:36.920]   I've seen you wear that.
[02:24:36.920 --> 02:24:39.840]   I've had it for up 10 years now.
[02:24:39.840 --> 02:24:44.000]   I don't remember when I put it on, but it's been on here for several years.
[02:24:44.000 --> 02:24:46.000]   But hey, folks.
[02:24:46.000 --> 02:24:47.000]   Yeah, this is serious.
[02:24:47.000 --> 02:24:52.920]   Men and women, there's been friends and family affected near and dear to me.
[02:24:52.920 --> 02:24:54.400]   So yeah, let's raise awareness.
[02:24:54.400 --> 02:25:00.720]   If you can spare a dollar or two, even right now during the pandemic, to help with research,
[02:25:00.720 --> 02:25:02.880]   do so breast cancer awareness month.
[02:25:02.880 --> 02:25:04.920]   I totally agree.
[02:25:04.920 --> 02:25:08.160]   If you haven't had your mammogram, go get it.
[02:25:08.160 --> 02:25:10.320]   I get mine every week.
[02:25:10.320 --> 02:25:11.320]   Indeed.
[02:25:11.320 --> 02:25:15.320]   No, I'm just kidding.
[02:25:15.320 --> 02:25:17.040]   Thank you, Anthony.
[02:25:17.040 --> 02:25:21.680]   It's great to see you hands-on photography, hands-on wellness.
[02:25:21.680 --> 02:25:25.320]   He is a joy and a pleasure every day.
[02:25:25.320 --> 02:25:28.960]   Sometimes he comes in the studio and it's always a pleasure to see you.
[02:25:28.960 --> 02:25:29.960]   Yes, sir.
[02:25:29.960 --> 02:25:32.360]   And your clumps in orange.
[02:25:32.360 --> 02:25:33.880]   We thank Jeff Jarvis.
[02:25:33.880 --> 02:25:38.480]   He is the Leonard Taill Professor for journalistic innovation at the Craig Newmark School of
[02:25:38.480 --> 02:25:42.960]   Whiteboard Studies.
[02:25:42.960 --> 02:25:48.040]   The graduate school journalism at the City University of New York, Mr. Moro Panic to
[02:25:48.040 --> 02:25:49.040]   his friends.
[02:25:49.040 --> 02:25:52.080]   So you're going to leave that on there, Jeff, or you're going to--
[02:25:52.080 --> 02:25:53.080]   I think so.
[02:25:53.080 --> 02:25:54.080]   Yeah.
[02:25:54.080 --> 02:25:55.080]   He's an MP-Travis.
[02:25:55.080 --> 02:25:56.080]   I have a whole mess of whiteboards.
[02:25:56.080 --> 02:25:59.000]   I mean, I have a-- I don't know if you can see it here.
[02:25:59.000 --> 02:26:00.000]   There's a whole bunch of whiteboards over there.
[02:26:00.000 --> 02:26:01.720]   Oh, we're going to get you some good work.
[02:26:01.720 --> 02:26:02.720]   Good work.
[02:26:02.720 --> 02:26:03.720]   Good work.
[02:26:03.720 --> 02:26:04.720]   Good work.
[02:26:04.720 --> 02:26:05.720]   Good work.
[02:26:05.720 --> 02:26:06.720]   Wow.
[02:26:06.720 --> 02:26:07.720]   Good work.
[02:26:07.720 --> 02:26:08.720]   Good work.
[02:26:08.720 --> 02:26:09.720]   It's right.
[02:26:09.720 --> 02:26:10.720]   He's got collection.
[02:26:10.720 --> 02:26:11.720]   Wow.
[02:26:11.720 --> 02:26:12.720]   Why do you have submitting whiteboards?
[02:26:12.720 --> 02:26:13.720]   They're all whiteboarded.
[02:26:13.720 --> 02:26:14.720]   They're all whiteboarded.
[02:26:14.720 --> 02:26:15.720]   They're all whiteboarded.
[02:26:15.720 --> 02:26:16.720]   They're all whiteboarded.
[02:26:16.720 --> 02:26:17.720]   They're all whiteboarded.
[02:26:17.720 --> 02:26:18.720]   They're all whiteboarded.
[02:26:18.720 --> 02:26:19.720]   They're all whiteboarded.
[02:26:19.720 --> 02:26:20.720]   They're all whiteboarded.
[02:26:20.720 --> 02:26:21.720]   They're all whiteboarded.
[02:26:21.720 --> 02:26:22.720]   They're all whiteboarded.
[02:26:22.720 --> 02:26:23.720]   They're all whiteboarded.
[02:26:23.720 --> 02:26:24.720]   Wow.
[02:26:24.720 --> 02:26:25.720]   I was like, "You can take a picture."
[02:26:25.720 --> 02:26:26.720]   I'm like, "I have one whiteboard."
[02:26:26.720 --> 02:26:27.720]   Well, Stacey--
[02:26:27.720 --> 02:26:28.720]   And it's fortunately--
[02:26:28.720 --> 02:26:29.720]   Show it off, huh?
[02:26:29.720 --> 02:26:32.720]   Somebody has made for you a meme of Satler and Waldorf.
[02:26:32.720 --> 02:26:33.720]   That's Moro Panic!
[02:26:33.720 --> 02:26:35.960]   We're such a reductionist.
[02:26:35.960 --> 02:26:38.880]   Thank you to Mash Potato in our chat room.
[02:26:38.880 --> 02:26:39.880]   Thank you, Mash.
[02:26:39.880 --> 02:26:40.880]   Nice.
[02:26:40.880 --> 02:26:41.880]   That's my name.
[02:26:41.880 --> 02:26:42.880]   That's my name, the show.
[02:26:42.880 --> 02:26:43.880]   Stacey Haganbotham.
[02:26:43.880 --> 02:26:46.760]   She's at Stacey on IOT.com.
[02:26:46.760 --> 02:26:47.760]   Go on over there.
[02:26:47.760 --> 02:26:49.640]   Sign up for her fabulous newsletter.
[02:26:49.640 --> 02:26:53.120]   You will want to subscribe and then, of course, read every article too.
[02:26:53.120 --> 02:26:56.880]   She also has events, so you can find out about that at the website.
[02:26:56.880 --> 02:27:00.720]   She and Kevin Toff will do the IOT podcast every week.
[02:27:00.720 --> 02:27:03.520]   You'll find out more at Stacey on IOT.com.
[02:27:03.520 --> 02:27:04.520]   Thanks, Stacey.
[02:27:04.520 --> 02:27:06.960]   With the best theme song for podcasts ever.
[02:27:06.960 --> 02:27:07.960]   Is it better than--
[02:27:07.960 --> 02:27:14.200]   It's less Renfaire, Boer.
[02:27:14.200 --> 02:27:15.560]   I don't even know.
[02:27:15.560 --> 02:27:16.880]   Poppy Halle music.
[02:27:16.880 --> 02:27:20.600]   I-- okay, I had an inspiration the other night.
[02:27:20.600 --> 02:27:23.360]   What about-- just listen to this.
[02:27:23.360 --> 02:27:25.080]   What I was thinking, this could be our new theme song.
[02:27:25.080 --> 02:27:27.480]   If I could find a version, I think I can't--
[02:27:27.480 --> 02:27:28.480]   Come on, Bode.
[02:27:28.480 --> 02:27:29.840]   I want that Bode guys, our theme song.
[02:27:29.840 --> 02:27:32.240]   That would be good, but this was written in 1440.
[02:27:32.240 --> 02:27:39.240]   I think it's--
[02:27:39.240 --> 02:27:44.240]   What do you think?
[02:27:44.240 --> 02:27:49.240]   That would be no.
[02:27:49.240 --> 02:27:54.240]   You don't like that?
[02:27:54.240 --> 02:27:55.240]   No, sir.
[02:27:55.240 --> 02:27:58.240]   Maybe you have Jeff singing "Moro Panic."
[02:27:58.240 --> 02:28:03.240]   "Moro Panic."
[02:28:03.240 --> 02:28:05.240]   No, I think we should do a round.
[02:28:05.240 --> 02:28:06.240]   Yes.
[02:28:06.240 --> 02:28:07.240]   No, I'm Tom Def.
[02:28:07.240 --> 02:28:08.240]   All of you, stop.
[02:28:08.240 --> 02:28:11.240]   It won't happen.
[02:28:11.240 --> 02:28:13.240]   I used to be an acquirer.
[02:28:13.240 --> 02:28:14.240]   Did you?
[02:28:14.240 --> 02:28:17.240]   I used to be an acquirer, but I still am Tom Def.
[02:28:17.240 --> 02:28:21.240]   I understand next to a very loud bass to make it work.
[02:28:21.240 --> 02:28:23.240]   They need basses so badly.
[02:28:23.240 --> 02:28:24.240]   Go ahead, do it.
[02:28:24.240 --> 02:28:27.240]   Yes, go.
[02:28:27.240 --> 02:28:31.240]   Thank you, everybody, for joining us for our little hour or two
[02:28:31.240 --> 02:28:32.240]   of fun and games.
[02:28:32.240 --> 02:28:33.240]   More three or four.
[02:28:33.240 --> 02:28:36.240]   Only two and a half this week, so that's good.
[02:28:36.240 --> 02:28:37.240]   I love it.
[02:28:37.240 --> 02:28:40.240]   We do this every Wednesday, about 1/3.
[02:28:40.240 --> 02:28:41.240]   Actually, it's 2 now.
[02:28:41.240 --> 02:28:42.240]   Isn't it?
[02:28:42.240 --> 02:28:45.240]   2PM Pacific, 5PM Eastern time, 2100 UTC.
[02:28:45.240 --> 02:28:47.240]   You can listen or watch live.
[02:28:47.240 --> 02:28:51.240]   There are live streams for you at twit.tv/live.
[02:28:51.240 --> 02:28:55.240]   On-demand versions of the show at the website, twit.tv/twig.
[02:28:55.240 --> 02:28:58.240]   There's also a YouTube channel for this week in Google.
[02:28:58.240 --> 02:29:01.240]   Just Google YouTube this week in Google.
[02:29:01.240 --> 02:29:04.240]   That's enough Google for you.
[02:29:04.240 --> 02:29:07.240]   Actually, the best way to listen is to subscribe.
[02:29:07.240 --> 02:29:11.240]   Get your favorite podcast app and add this week in Google to your list.
[02:29:11.240 --> 02:29:17.240]   It won't cost you anything, but it will give you a little bit of happiness
[02:29:17.240 --> 02:29:19.240]   every Wednesday evening.
[02:29:19.240 --> 02:29:20.240]   Thanks, everybody.
[02:29:20.240 --> 02:29:23.240]   We'll see you next time on this week in Google.
[02:29:23.240 --> 02:29:24.240]   Bye-bye.
[02:29:24.240 --> 02:29:27.240]   Be sure to check out the other shows on the network.
[02:29:27.240 --> 02:29:29.240]   Like my other show, Hands on Wellness.
[02:29:29.240 --> 02:29:33.240]   I love to share different tips and tricks that's going to help you get a better grasp
[02:29:33.240 --> 02:29:35.240]   on your personal wellness.
[02:29:35.240 --> 02:29:38.240]   Just go to twit.tv/how and subscribe now.
[02:29:38.240 --> 02:29:47.240]   [music]
[02:29:47.240 --> 02:29:54.820]   [BLANK_AUDIO]

