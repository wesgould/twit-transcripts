;FFMETADATA1
title=The Missing Link
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=422
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.000]   It's time for Twig this week in Google Jeff Jarvis and Stacey Higginbotham are both here.
[00:00:06.000 --> 00:00:10.000]   We're going to talk a little bit about the Apple event, the Samsung Galaxy Note 8.
[00:00:10.000 --> 00:00:12.000]   I've got one in my pocket right now.
[00:00:12.000 --> 00:00:18.000]   Some interesting ideas about Equifax and what we should do going forward.
[00:00:18.000 --> 00:00:21.000]   It's all coming up next on Twig.
[00:00:21.000 --> 00:00:25.000]   Netcast you love.
[00:00:25.000 --> 00:00:27.000]   From people you trust.
[00:00:27.000 --> 00:00:32.000]   This is Twig.
[00:00:32.000 --> 00:00:40.000]   Bandwidth for this week in Google is provided by CashFly, C-A-C-H-E-F-L-Y.com.
[00:00:40.000 --> 00:00:45.000]   This is Twig.
[00:00:45.000 --> 00:00:51.000]   This week in Google, Episode 422 recorded Wednesday, September 13, 2017.
[00:00:51.000 --> 00:00:53.000]   The Missing Link.
[00:00:53.000 --> 00:00:58.000]   This week in Google is brought to you by Rocket Mortgage from Quick and Loans.
[00:00:58.000 --> 00:01:00.000]   Home plays a big role in your life.
[00:01:00.000 --> 00:01:02.000]   That's why Quick and Loans created Rocket Mortgage.
[00:01:02.000 --> 00:01:08.000]   It lets you apply simply and understand the entire mortgage process fully so you can be confident you're getting the right mortgage for you.
[00:01:08.000 --> 00:01:12.000]   Get started at Rocket Mortgage.com/Twig.
[00:01:12.000 --> 00:01:20.000]   And by the Ring Video Doorbell with Ring you can see and talk to anyone at your door from anywhere in the world using your smartphone.
[00:01:20.000 --> 00:01:28.000]   It's like Call or ID for your house. Go to Ring.com/Twig and get up to $150 of a Ring of Security Kit.
[00:01:28.000 --> 00:01:30.000]   And by LegalZoom.
[00:01:30.000 --> 00:01:35.000]   Grow your business and let LegalZoom help out with all the legal stuff for special savings.
[00:01:35.000 --> 00:01:39.000]   Visit LegalZoom.com and enter Twig in the referral box at checke.
[00:01:39.000 --> 00:01:41.000]   It's time for Twig this week in Google.
[00:01:41.000 --> 00:01:44.000]   Show we cover. I'm sorry. Can I wake you?
[00:01:44.000 --> 00:01:46.000]   Yeah, you did.
[00:01:46.000 --> 00:01:50.000]   I was having a quite a nice nap. There came Leo.
[00:01:50.000 --> 00:01:51.000]   It's time for Twig.
[00:01:51.000 --> 00:01:56.000]   Jeff Jarvis is here. He's grumpy from just waking up from his nap.
[00:01:56.000 --> 00:01:58.000]   Hey Jeff, Professor of Journalism.
[00:01:58.000 --> 00:01:59.000]   Hey CUNY.
[00:01:59.000 --> 00:02:00.000]   Long group Buzz Machine.
[00:02:00.000 --> 00:02:03.000]   I'm the author of many a book. Good to see you.
[00:02:03.000 --> 00:02:06.000]   You survived September 11th.
[00:02:06.000 --> 00:02:07.000]   Yeah.
[00:02:07.000 --> 00:02:10.000]   Does it still send a chill up your spine?
[00:02:10.000 --> 00:02:14.000]   Yeah, I haven't done it every year but I went there.
[00:02:14.000 --> 00:02:15.000]   I do that.
[00:02:15.000 --> 00:02:16.000]   Yeah.
[00:02:16.000 --> 00:02:19.000]   Took pictures of the spots where I was when the major about to happen.
[00:02:19.000 --> 00:02:21.000]   Oh, do you do that every year?
[00:02:21.000 --> 00:02:22.000]   Not every but almost.
[00:02:22.000 --> 00:02:25.000]   Oh, that's neat. Have you been in the museum yet?
[00:02:25.000 --> 00:02:27.000]   I don't think I can do it.
[00:02:27.000 --> 00:02:29.000]   Yeah, I was talking to a firefighter who said the same thing.
[00:02:29.000 --> 00:02:30.000]   Really?
[00:02:30.000 --> 00:02:33.000]   Yeah. It's very emotional. It's really emotional.
[00:02:33.000 --> 00:02:35.000]   I was a tear-sposed at the time.
[00:02:35.000 --> 00:02:41.000]   Yeah, the one besides health conditions, the one big impact on me personally is that I am now,
[00:02:41.000 --> 00:02:48.000]   this is really weird. I've never said this out loud before, but I am a, I find myself almost
[00:02:48.000 --> 00:02:55.000]   unable to control emotions in ridiculously manipulative tear-jerker moments.
[00:02:55.000 --> 00:02:58.000]   You know what? That's not the 9/11. That's age.
[00:02:58.000 --> 00:02:59.000]   That's age.
[00:02:59.000 --> 00:03:00.000]   I think that's age.
[00:03:00.000 --> 00:03:07.000]   This is the same thing. And remember George H.W. Bush? He was very teary. He would cry.
[00:03:07.000 --> 00:03:09.000]   I cry at everything.
[00:03:09.000 --> 00:03:12.000]   At least he goes stop crying.
[00:03:12.000 --> 00:03:16.000]   It's like being a pregnant woman. I'll just tell you.
[00:03:16.000 --> 00:03:17.000]   Yes.
[00:03:17.000 --> 00:03:18.000]   When I was pregnant, I cried.
[00:03:18.000 --> 00:03:21.000]   I have the bolt up early for that too. Very emotional.
[00:03:21.000 --> 00:03:22.000]   Oh, there we go.
[00:03:22.000 --> 00:03:28.000]   But it is a tearful thing to go there and see, you know, the melted fire truck.
[00:03:28.000 --> 00:03:33.000]   It's funny. You know what really saddens me more?
[00:03:33.000 --> 00:03:38.000]   It's not the people who, the victims in the building, as much as I really get choked up when I think
[00:03:38.000 --> 00:03:45.000]   about the rescue workers, the FDNY and the NYPD that ran into the building.
[00:03:45.000 --> 00:03:46.000]   I won't.
[00:03:46.000 --> 00:03:47.000]   The priest was-
[00:03:47.000 --> 00:03:48.000]   The faces are burned into my memory.
[00:03:48.000 --> 00:03:52.000]   Yeah. The priest who was giving last rights and then himself got killed.
[00:03:52.000 --> 00:03:58.000]   I mean, it's just those are those things really start the waterworks.
[00:03:58.000 --> 00:04:02.000]   It's a beautiful museum though. I mean, it really is well done.
[00:04:02.000 --> 00:04:05.000]   But it's made to make you cry. I mean, they have phone calls.
[00:04:05.000 --> 00:04:10.000]   They're playing audio from phone calls and I mean, it's very heavy.
[00:04:10.000 --> 00:04:13.000]   But what a beautiful memorial. So you go see the memorial.
[00:04:13.000 --> 00:04:16.000]   I've done that. I waited a while to do that too.
[00:04:16.000 --> 00:04:21.000]   Because at first when you went, it was worse than airport security to get in.
[00:04:21.000 --> 00:04:22.000]   Yeah.
[00:04:22.000 --> 00:04:24.000]   Now it's wide open. That's wide open.
[00:04:24.000 --> 00:04:27.000]   Stacy, we missed you.
[00:04:27.000 --> 00:04:31.000]   Stacy Higginbotham is back from her jaunt to Intel, right?
[00:04:31.000 --> 00:04:33.000]   See you in Qualcomm.
[00:04:33.000 --> 00:04:36.000]   Qualcomm, CDIA. How was that?
[00:04:36.000 --> 00:04:40.000]   Both who are very illuminating. I learned a lot.
[00:04:40.000 --> 00:04:43.000]   Qualcomm is in it. You know, and we should mention Qualcomm is now a sponsor.
[00:04:43.000 --> 00:04:48.000]   They have ads on our network for their Snapdragon gigabit LTE chip.
[00:04:48.000 --> 00:04:53.000]   And they also ran ads right before the Apple event.
[00:04:53.000 --> 00:04:57.000]   They are there in an interesting tussle with Apple.
[00:04:57.000 --> 00:04:59.000]   Because Apple stopped using their chip to build their own.
[00:04:59.000 --> 00:05:02.000]   I think Apple doesn't use any Qualcomm stuff anymore, right?
[00:05:02.000 --> 00:05:04.000]   Not even the radios.
[00:05:04.000 --> 00:05:08.000]   I don't think so. After that lawsuit licensing these,
[00:05:08.000 --> 00:05:10.000]   although they might.
[00:05:10.000 --> 00:05:16.000]   Does the iPhone, if it falls back to CDMA radio, they have to.
[00:05:16.000 --> 00:05:17.000]   Yeah.
[00:05:17.000 --> 00:05:22.000]   But I assume you still have 3G and a Verizon iPhone.
[00:05:22.000 --> 00:05:25.000]   So unless they fall back to nothing, which would suck.
[00:05:25.000 --> 00:05:27.000]   I don't know if it's an interesting quality.
[00:05:27.000 --> 00:05:29.000]   It's an interesting quality.
[00:05:29.000 --> 00:05:32.000]   Yeah. Qualcomm had a blog post rather in which they...
[00:05:32.000 --> 00:05:35.000]   I should show you.
[00:05:35.000 --> 00:05:40.000]   Android firsts. This was the day before the Apple event.
[00:05:40.000 --> 00:05:43.000]   We brought to you by Qualcomm.
[00:05:43.000 --> 00:05:48.000]   Of course, there was no surprise really what Apple announced we had already seen in the lake.
[00:05:48.000 --> 00:05:53.000]   So they're responding directly to the features Apple is going to be announcing tomorrow,
[00:05:53.000 --> 00:05:55.000]   the day after this blog post.
[00:05:55.000 --> 00:05:58.000]   And it's charging quick charging dual camera technology,
[00:05:58.000 --> 00:06:02.000]   IRIS at authentication facial recognition fingerprint under display,
[00:06:02.000 --> 00:06:03.000]   augmented reality, depth.
[00:06:03.000 --> 00:06:08.000]   This is all stuff OLED display 4K display gigabit LTE.
[00:06:08.000 --> 00:06:14.000]   This is all stuff that Apple, you know,
[00:06:14.000 --> 00:06:22.000]   touted in its new iPhone X and it was all innovations that appeared first in Android thanks to Qualcomm.
[00:06:22.000 --> 00:06:24.000]   I think that's really...
[00:06:24.000 --> 00:06:27.000]   But they're locked in a major lawsuit.
[00:06:27.000 --> 00:06:28.000]   Yes.
[00:06:28.000 --> 00:06:29.000]   Yeah.
[00:06:29.000 --> 00:06:32.000]   Withholding payments and all sorts of stuff.
[00:06:32.000 --> 00:06:34.000]   Well, I think...
[00:06:34.000 --> 00:06:35.000]   And here's a question.
[00:06:35.000 --> 00:06:38.000]   And when I talked to Qualcomm, this was mostly a tech visit.
[00:06:38.000 --> 00:06:42.000]   We did not discuss the lawsuits because they can't discuss the lawsuits.
[00:06:42.000 --> 00:06:43.000]   Right.
[00:06:43.000 --> 00:06:47.000]   So you can smile and ask and they will say, "Hey, we can't talk about that."
[00:06:47.000 --> 00:06:49.000]   That's a different building.
[00:06:49.000 --> 00:06:51.000]   Would you like to go there right now?
[00:06:51.000 --> 00:06:53.000]   But...
[00:06:53.000 --> 00:07:05.000]   Oh, China, when they started fighting this and then South Korea again went after Qualcomm for their patents and the licensing fees they were charging.
[00:07:05.000 --> 00:07:06.000]   It opened...
[00:07:06.000 --> 00:07:14.000]   It opened the door because Qualcomm actually, to get into China, had to accept some of the constraints.
[00:07:14.000 --> 00:07:20.000]   And so then, of course, everyone else is like, "Oh, hey, I don't want to make such high patent payments to you too."
[00:07:20.000 --> 00:07:22.000]   Or, "High licensing payments to you too."
[00:07:22.000 --> 00:07:23.000]   Right.
[00:07:23.000 --> 00:07:24.000]   So, okay.
[00:07:24.000 --> 00:07:30.000]   Qualcomm has had a good run as a licensing company.
[00:07:30.000 --> 00:07:31.000]   And they...
[00:07:31.000 --> 00:07:33.000]   I mean, it's not like they're a patent troll.
[00:07:33.000 --> 00:07:36.000]   They didn't buy patents and then sue over them.
[00:07:36.000 --> 00:07:37.000]   They're all things they invented, right?
[00:07:37.000 --> 00:07:38.000]   I mean, it's not.
[00:07:38.000 --> 00:07:40.000]   Well, yes, they invented it.
[00:07:40.000 --> 00:07:44.000]   But they also were very strategic in buying companies that have patents as well.
[00:07:44.000 --> 00:07:45.000]   Okay.
[00:07:45.000 --> 00:07:52.000]   And the question is basically, are they fair and reasonable when they were under the state?
[00:07:52.000 --> 00:07:58.000]   And it has been years since I've delved into the Qualcomm patent wars.
[00:07:58.000 --> 00:08:07.000]   So, there are issues of what terms did they participate in standards organizations with since they have only these patents?
[00:08:07.000 --> 00:08:11.000]   Are they licensing them fairly, et cetera, et cetera?
[00:08:11.000 --> 00:08:17.000]   So, there's a bunch of really nitty-gritty legal stuff there.
[00:08:17.000 --> 00:08:20.000]   It's not as exciting as the stuff I talked about with it.
[00:08:20.000 --> 00:08:22.000]   No, it really isn't.
[00:08:22.000 --> 00:08:28.000]   And, you know, there is no legal definition of fair, reasonable, and non-discriminatory patent terms.
[00:08:28.000 --> 00:08:30.000]   That's something that people just agreed to.
[00:08:30.000 --> 00:08:34.000]   It's a voluntary commitment, not a legal commitment.
[00:08:34.000 --> 00:08:38.000]   So, you could say, "Well, they're not adhering to frand."
[00:08:38.000 --> 00:08:41.000]   But that's voluntary.
[00:08:41.000 --> 00:08:43.000]   And maybe they feel their licenses are worth more.
[00:08:43.000 --> 00:08:44.000]   I don't know.
[00:08:44.000 --> 00:08:48.000]   And I wouldn't even want to weigh in on this because I don't even know if they're adhering to frand or not.
[00:08:48.000 --> 00:08:49.000]   Yeah, because you would have to...
[00:08:49.000 --> 00:08:53.000]   So, it is to participate in certain standards organizations.
[00:08:53.000 --> 00:08:56.000]   You have to be like, "Yes, I will..."
[00:08:56.000 --> 00:08:59.000]   They establish a frand benchmark.
[00:08:59.000 --> 00:09:05.000]   But I don't know, again, so long since I've dealt with this.
[00:09:05.000 --> 00:09:09.000]   And they also... I believe they bundled some of their radios.
[00:09:09.000 --> 00:09:10.000]   They're bundled.
[00:09:10.000 --> 00:09:12.000]   They integrated some of their radios.
[00:09:12.000 --> 00:09:15.000]   So, you had to buy and pay licensing on...
[00:09:15.000 --> 00:09:17.000]   Which is another issue.
[00:09:17.000 --> 00:09:20.000]   Yeah, and I'm sure they would argue, "Yeah, well, it's a system on a chip.
[00:09:20.000 --> 00:09:21.000]   Of course, you bundled it.
[00:09:21.000 --> 00:09:22.000]   You want us to unbundle it?"
[00:09:22.000 --> 00:09:25.000]   This is what Qualcomm does.
[00:09:25.000 --> 00:09:26.000]   They take up.
[00:09:26.000 --> 00:09:27.000]   They take tech and go...
[00:09:27.000 --> 00:09:28.000]   Bush.
[00:09:28.000 --> 00:09:29.000]   Bush.
[00:09:29.000 --> 00:09:32.000]   And that's why you get such a great deal and so much power.
[00:09:32.000 --> 00:09:35.000]   Because it's all in one... in there and it's all in that system.
[00:09:35.000 --> 00:09:38.000]   Well, anyway, so I'm glad you had a good time.
[00:09:38.000 --> 00:09:41.000]   And I'm surprised you didn't stick around for the Apple event.
[00:09:41.000 --> 00:09:44.000]   You could have killed two birds with one stone.
[00:09:44.000 --> 00:09:49.000]   I wanted to come home and see my family before I went gallivanting off to Vegas next week.
[00:09:49.000 --> 00:09:51.000]   Oh, what are you doing in Vegas?
[00:09:51.000 --> 00:09:52.000]   San Francisco the week after that.
[00:09:52.000 --> 00:09:55.000]   Oh, you're going to Mobile World Congress in Frisco?
[00:09:55.000 --> 00:09:56.000]   No, no, no, no.
[00:09:56.000 --> 00:09:59.000]   I'm doing an event for some friends of mine in San Francisco.
[00:09:59.000 --> 00:10:00.000]   Oh, okay.
[00:10:00.000 --> 00:10:05.000]   And then Vegas is a user group for an industrial internet company.
[00:10:05.000 --> 00:10:06.000]   You work hard.
[00:10:06.000 --> 00:10:09.000]   Aren't we impressed, Jeff, how...
[00:10:09.000 --> 00:10:12.000]   She is an intrepid reporter.
[00:10:12.000 --> 00:10:13.000]   Stacey is...
[00:10:13.000 --> 00:10:14.000]   And an entrepreneur.
[00:10:14.000 --> 00:10:15.000]   Yeah.
[00:10:15.000 --> 00:10:16.000]   Well, that's right.
[00:10:16.000 --> 00:10:18.000]   You kind of have to work harder if you're doing it for yourself, don't you?
[00:10:18.000 --> 00:10:19.000]   Really?
[00:10:19.000 --> 00:10:21.000]   I put all of that hard work on to Andrew.
[00:10:21.000 --> 00:10:23.000]   That's his job.
[00:10:23.000 --> 00:10:24.000]   Otherwise...
[00:10:24.000 --> 00:10:26.000]   You're doing all the reporting.
[00:10:26.000 --> 00:10:28.000]   No, you're doing all the work.
[00:10:28.000 --> 00:10:29.000]   I'm impressed.
[00:10:29.000 --> 00:10:33.000]   That's what we have you on because then I could say, "Well, Stacey, what's going on?
[00:10:33.000 --> 00:10:35.000]   What does this mean, Stacey?
[00:10:35.000 --> 00:10:36.000]   Tell us."
[00:10:36.000 --> 00:10:38.000]   Only on the IOT or 5G.
[00:10:38.000 --> 00:10:39.000]   I don't know.
[00:10:39.000 --> 00:10:41.000]   No, no, no, no, not at life.
[00:10:41.000 --> 00:10:44.000]   So did you both watch the Apple event?
[00:10:44.000 --> 00:10:46.000]   I watched it while working out.
[00:10:46.000 --> 00:10:47.000]   It was my...
[00:10:47.000 --> 00:10:48.000]   That's perfect.
[00:10:48.000 --> 00:10:49.000]   It's like...
[00:10:49.000 --> 00:10:50.000]   If I mentioned it, I'd be a little...
[00:10:50.000 --> 00:10:53.000]   If that Apple watched and then said, "Hey, you're heart rate.
[00:10:53.000 --> 00:10:55.000]   Is that abnormally high?"
[00:10:55.000 --> 00:10:56.000]   I don't have an...
[00:10:56.000 --> 00:10:57.000]   I'm not an Apple girl.
[00:10:57.000 --> 00:10:59.000]   I am not that lady.
[00:10:59.000 --> 00:11:02.000]   I do see more and more Apple watches.
[00:11:02.000 --> 00:11:07.680]   I was actually quite impressed with the Apple watch improvements in the series 3, including
[00:11:07.680 --> 00:11:14.000]   cellular and you can make and take phone calls on the new phone.
[00:11:14.000 --> 00:11:20.200]   It also has some additional fitness stuff that people will welcome things like calculating
[00:11:20.200 --> 00:11:25.000]   your resting heart rate, monitoring your sudden acceleration.
[00:11:25.000 --> 00:11:29.640]   I will warn you if your heart rate's gone up and you don't seem to be moving, things
[00:11:29.640 --> 00:11:30.640]   like that.
[00:11:30.640 --> 00:11:33.400]   I think that's all great stuff.
[00:11:33.400 --> 00:11:34.480]   They announced...
[00:11:34.480 --> 00:11:39.800]   This was a very unclear, very appily announcement that they were the number one watch company.
[00:11:39.800 --> 00:11:41.640]   Because I noticed that number two was Rolex.
[00:11:41.640 --> 00:11:44.000]   So it was clearly not unit sales they were talking about.
[00:11:44.000 --> 00:11:46.000]   It must have been dollar sales.
[00:11:46.000 --> 00:11:49.680]   They are the top in the fitness tracker market.
[00:11:49.680 --> 00:11:51.480]   They took a lot of market share away from Fitbit.
[00:11:51.480 --> 00:11:54.120]   Actually, a lot of people took market away from Fitbit.
[00:11:54.120 --> 00:11:56.880]   But that was my reaction seeing the Apple announcement is that's it.
[00:11:56.880 --> 00:11:58.760]   It's over for all the other fitness bands.
[00:11:58.760 --> 00:12:04.200]   There will always be people who don't want to buy into Apple's ecosystem.
[00:12:04.200 --> 00:12:06.600]   You have to buy an iPhone to use it.
[00:12:06.600 --> 00:12:09.240]   It's not usable with an iPhone.
[00:12:09.240 --> 00:12:10.240]   Right now.
[00:12:10.240 --> 00:12:14.800]   Oh, guys, my phone died right before.
[00:12:14.800 --> 00:12:15.800]   Oh.
[00:12:15.800 --> 00:12:17.680]   So what are you going to get?
[00:12:17.680 --> 00:12:18.680]   I don't know.
[00:12:18.680 --> 00:12:20.520]   I've got my spare iPhone.
[00:12:20.520 --> 00:12:22.120]   So you can wait a little bit.
[00:12:22.120 --> 00:12:23.120]   I guess.
[00:12:23.120 --> 00:12:26.920]   Because I think it would behoove us all the way to October 4th or 5th whenever Google
[00:12:26.920 --> 00:12:29.080]   announces the Pixel 2.
[00:12:29.080 --> 00:12:30.080]   That's what I'm waiting for.
[00:12:30.080 --> 00:12:33.640]   But I am in love with the Note 8.
[00:12:33.640 --> 00:12:36.160]   Really is a beautiful phone.
[00:12:36.160 --> 00:12:38.360]   It's big.
[00:12:38.360 --> 00:12:39.360]   It's tall.
[00:12:39.360 --> 00:12:42.320]   It's not wide.
[00:12:42.320 --> 00:12:47.880]   And it's a little bit bigger but not hardly at all bigger than the S8+.
[00:12:47.880 --> 00:12:50.960]   It's just a tenth of an inch bigger diagonally.
[00:12:50.960 --> 00:12:52.480]   Does Lisa have one?
[00:12:52.480 --> 00:12:53.480]   She's an Android.
[00:12:53.480 --> 00:12:54.480]   I mean, an iPhone person.
[00:12:54.480 --> 00:12:56.240]   She's not an Android person.
[00:12:56.240 --> 00:12:57.640]   She has an iPhone 7+.
[00:12:57.640 --> 00:12:58.960]   But that's a 5.5 inch screen.
[00:12:58.960 --> 00:13:01.120]   This is a 6.3 inch screen.
[00:13:01.120 --> 00:13:02.120]   Yes.
[00:13:02.120 --> 00:13:04.880]   It's almost exactly the same size as a 7+.
[00:13:04.880 --> 00:13:06.520]   No, but it's the same size as a 7+.
[00:13:06.520 --> 00:13:08.000]   Well, that's what I'm saying.
[00:13:08.000 --> 00:13:10.080]   But guys, your pockets are bigger.
[00:13:10.080 --> 00:13:11.320]   So you're like, I can still stick in my pocket.
[00:13:11.320 --> 00:13:13.160]   She loves the 7+.
[00:13:13.160 --> 00:13:14.240]   She's completely happy with it.
[00:13:14.240 --> 00:13:15.960]   She likes a big phone.
[00:13:15.960 --> 00:13:20.560]   She likes the cameras and the 7+.
[00:13:20.560 --> 00:13:21.560]   I do too.
[00:13:21.560 --> 00:13:22.560]   I do all cameras as well.
[00:13:22.560 --> 00:13:26.600]   It's very similar in some ways to the 7+.
[00:13:26.600 --> 00:13:28.600]   Has a live focus feature that's kind of interesting.
[00:13:28.600 --> 00:13:32.440]   Let me see if I can do it upside down and backwards.
[00:13:32.440 --> 00:13:36.280]   So it zooms in a little bit and then it has a slider.
[00:13:36.280 --> 00:13:38.760]   I don't know if I can actually do this.
[00:13:38.760 --> 00:13:43.200]   But I can bring the background into and out of focus depending for the portrait.
[00:13:43.200 --> 00:13:44.200]   And you do that live.
[00:13:44.200 --> 00:13:45.920]   You know, that's Apple has that in their portrait mode.
[00:13:45.920 --> 00:13:47.320]   But then Apple leapfrog them.
[00:13:47.320 --> 00:13:53.640]   And then one, the iPhone 8, 8+ and 10 will have a new lighting mode, which is really cool
[00:13:53.640 --> 00:13:54.640]   where you can change this.
[00:13:54.640 --> 00:13:55.640]   That's gorgeous.
[00:13:55.640 --> 00:13:56.640]   Isn't that amazing?
[00:13:56.640 --> 00:13:57.640]   Yes.
[00:13:57.640 --> 00:14:01.440]   And I think the interesting thing about that is in order to do that, they took part of
[00:14:01.440 --> 00:14:04.000]   that new A11 Bionic chip.
[00:14:04.000 --> 00:14:08.360]   They took a chunk and said, this is going to be for the camera.
[00:14:08.360 --> 00:14:14.640]   And that's where Apple has an advantage over Qualcomm, over Samsung, over anybody.
[00:14:14.640 --> 00:14:16.240]   They designed their own silicon.
[00:14:16.240 --> 00:14:21.760]   Yeah, maybe they started with the ARM platform years ago, but they have 1000 chip designers
[00:14:21.760 --> 00:14:23.200]   working at Apple.
[00:14:23.200 --> 00:14:24.680]   And now they do their own GPUs.
[00:14:24.680 --> 00:14:27.240]   This is the first year they've done their own GPUs.
[00:14:27.240 --> 00:14:28.840]   And they design their own silicon.
[00:14:28.840 --> 00:14:33.880]   And there are more than a billion transistors in this A11 enough so that they could say,
[00:14:33.880 --> 00:14:36.440]   this part here, that's the camera.
[00:14:36.440 --> 00:14:41.320]   So they dedicate hardware silicon to camera processing.
[00:14:41.320 --> 00:14:42.920]   That's pretty amazing.
[00:14:42.920 --> 00:14:48.200]   So that's actually, that's the way things are going now in general.
[00:14:48.200 --> 00:14:53.400]   So Qualcomm, if you look at its drone reference designs, they've, I mean, and I just know
[00:14:53.400 --> 00:14:56.400]   this for a fact because I was sitting there talking to them about their chips.
[00:14:56.400 --> 00:14:58.840]   But everyone is designing.
[00:14:58.840 --> 00:15:01.600]   There are certain core features that you're going to design into silicon.
[00:15:01.600 --> 00:15:04.480]   Your camera has been there for a while.
[00:15:04.480 --> 00:15:08.600]   What you're going to start seeing next is DSPs dedicated to voice.
[00:15:08.600 --> 00:15:11.400]   So wake words, that kind of thing.
[00:15:11.400 --> 00:15:17.520]   Ah, Apple mentioned something called an ISP as well, which doesn't stand for Internet
[00:15:17.520 --> 00:15:19.800]   service provider.
[00:15:19.800 --> 00:15:23.160]   Is it a machine learning chip?
[00:15:23.160 --> 00:15:24.160]   I think it was.
[00:15:24.160 --> 00:15:26.120]   Yeah, that's their AI chip, right?
[00:15:26.120 --> 00:15:27.120]   Yeah.
[00:15:27.120 --> 00:15:28.120]   Okay.
[00:15:28.120 --> 00:15:29.120]   Yes.
[00:15:29.120 --> 00:15:33.080]   So this is what's interesting is you now have so many, is it image and signal processor?
[00:15:33.080 --> 00:15:35.720]   No, it's yeah, image and signal processing group.
[00:15:35.720 --> 00:15:41.360]   So you'd have so much extra silicon because the die, you know, we've shrunk the die sizes
[00:15:41.360 --> 00:15:46.600]   down so much, you get so many transistors, you have enough room to dedicate parts of
[00:15:46.600 --> 00:15:48.400]   the chip to different processes.
[00:15:48.400 --> 00:15:49.760]   I think this is fascinating.
[00:15:49.760 --> 00:15:50.920]   Well, it's more.
[00:15:50.920 --> 00:15:56.880]   I mean, it's so essential because when you're opt to, I mean, at this point in time, we don't
[00:15:56.880 --> 00:15:58.120]   need more gigahertz, right?
[00:15:58.120 --> 00:16:00.120]   We're not, we're not optimizing for performance.
[00:16:00.120 --> 00:16:03.000]   We're optimizing, well, sorry, general performance.
[00:16:03.000 --> 00:16:06.400]   We're optimizing for battery life and performance.
[00:16:06.400 --> 00:16:12.040]   So what happens is it makes sense once you have a function that is integral to what your
[00:16:12.040 --> 00:16:13.280]   device is.
[00:16:13.280 --> 00:16:15.680]   So a camera on a phone now is integral.
[00:16:15.680 --> 00:16:17.840]   You wouldn't buy a phone without a camera.
[00:16:17.840 --> 00:16:18.840]   Okay.
[00:16:18.840 --> 00:16:24.600]   Like five of you might, but it makes sense to say, okay, let's put this in hardware so
[00:16:24.600 --> 00:16:28.200]   we can eke out the most power savings for the best quality.
[00:16:28.200 --> 00:16:30.120]   And that's exactly where we're going.
[00:16:30.120 --> 00:16:34.840]   And it's super fascinating because if you talk to the chip guys, they'll, what they're
[00:16:34.840 --> 00:16:39.560]   designing today is the stuff that five years they're believing is going to be integral
[00:16:39.560 --> 00:16:42.760]   to your phone, maybe four years.
[00:16:42.760 --> 00:16:44.360]   It's so cool.
[00:16:44.360 --> 00:16:47.840]   And I love it that there's a competition between Apple and Samsung and Qualcomm.
[00:16:47.840 --> 00:16:48.840]   Yeah.
[00:16:48.840 --> 00:16:54.560]   You know, you know, and yeah, Google doesn't, Google is not making these chips.
[00:16:54.560 --> 00:16:56.040]   Google's using Qualcomm chips.
[00:16:56.040 --> 00:16:57.040]   Why is it chips?
[00:16:57.040 --> 00:16:58.040]   Right.
[00:16:58.040 --> 00:17:01.320]   I still think Google will though, right?
[00:17:01.320 --> 00:17:05.600]   So my speculation and I could be proven wrong or not proven wrong.
[00:17:05.600 --> 00:17:07.680]   I might just be wrong.
[00:17:07.680 --> 00:17:09.720]   Well, that would prove you wrong.
[00:17:09.720 --> 00:17:17.120]   Yes, Google is, they have to be investigating making their own chips for self.
[00:17:17.120 --> 00:17:23.960]   I mean, they've done it on the for embedded for cell phones, but also for things like
[00:17:23.960 --> 00:17:27.160]   IOT type stuff.
[00:17:27.160 --> 00:17:29.760]   So they've got where they have their hardware.
[00:17:29.760 --> 00:17:32.640]   I feel like they've got to be doing something there.
[00:17:32.640 --> 00:17:35.560]   Chromecast would be, I guess, a good place to start because they sell so many because
[00:17:35.560 --> 00:17:39.960]   you do to designer and silicon, you really need to have massive sales.
[00:17:39.960 --> 00:17:45.920]   Well, look at the story from your former colleague, Ganko Ruttkers, Google in June hired
[00:17:45.920 --> 00:17:50.760]   a veteran chip architect away from Apple and is now looking to build its own chips for
[00:17:50.760 --> 00:17:54.560]   future versions of its pixel phone.
[00:17:54.560 --> 00:18:00.120]   And that gives it the ability to control security updates the way that like Apple can.
[00:18:00.120 --> 00:18:06.600]   So you could, they could keep the phone working, are secured and supported over a longer period
[00:18:06.600 --> 00:18:07.600]   of time.
[00:18:07.600 --> 00:18:15.120]   I mean, so this is Manugalati, who had been at Apple for eight years doing chip design.
[00:18:15.120 --> 00:18:20.560]   He is now Google's lead SOC architect system on a chip architect.
[00:18:20.560 --> 00:18:23.880]   So I think that pretty much tells you, you nailed it.
[00:18:23.880 --> 00:18:26.600]   Google is going to make their own silicon.
[00:18:26.600 --> 00:18:28.320]   I wonder if we'll see that in the pixel too.
[00:18:28.320 --> 00:18:29.600]   That would be very interesting.
[00:18:29.600 --> 00:18:34.440]   They always said that the pixel was a rushed kind of stopgap phone.
[00:18:34.440 --> 00:18:37.240]   That wasn't what Google really wanted to do.
[00:18:37.240 --> 00:18:40.800]   No, seriously, everybody's very interested.
[00:18:40.800 --> 00:18:44.200]   The one rumor I really hate and I hope it's not true is that they're going to abandon
[00:18:44.200 --> 00:18:45.880]   the headphone jack on the pixel too.
[00:18:45.880 --> 00:18:47.280]   Oh, God, no.
[00:18:47.280 --> 00:18:52.240]   No, it's so nice to have competition among features like that.
[00:18:52.240 --> 00:18:57.080]   Like I like my headphone jack because I never remember the charge on my stuff.
[00:18:57.080 --> 00:19:02.000]   And I know that Apple now has their charging mat that one day you might be able to buy.
[00:19:02.000 --> 00:19:03.000]   They finally have cheap charging.
[00:19:03.000 --> 00:19:04.000]   Well, but it'll work.
[00:19:04.000 --> 00:19:08.120]   The iPhone is using Qi now, so it'll work with all the other chargers you have.
[00:19:08.120 --> 00:19:09.600]   This has wireless charging.
[00:19:09.600 --> 00:19:11.400]   Actually, this has wireless fast charging.
[00:19:11.400 --> 00:19:15.920]   They use dual voltages to speed up the charging on the Note 8.
[00:19:15.920 --> 00:19:20.560]   Now, is it that they don't have a Qi chip in the AirPods?
[00:19:20.560 --> 00:19:22.560]   Is that why they don't charge on the charge?
[00:19:22.560 --> 00:19:26.720]   Yes, so the AirPods, which also uses cable charging.
[00:19:26.720 --> 00:19:31.840]   So what Apple said is they showed this mat, which they may or may not ship next year.
[00:19:31.840 --> 00:19:34.920]   There's some issues with it because some of the features of it are not yet part of the
[00:19:34.920 --> 00:19:37.360]   Qi spec.
[00:19:37.360 --> 00:19:40.400]   And they showed it with an iPhone on it and Apple watch on it.
[00:19:40.400 --> 00:19:43.160]   Yeah, they both use inductance charging.
[00:19:43.160 --> 00:19:48.320]   But the AirPods, and then they said with the optional AirPod wireless charging case, you'll
[00:19:48.320 --> 00:19:53.120]   have to buy a new case for your AirPods for wireless charging.
[00:19:53.120 --> 00:19:54.120]   Do we like wireless?
[00:19:54.120 --> 00:19:58.000]   It's funny because there was a period where people were making wireless devices and all
[00:19:58.000 --> 00:20:01.360]   my devices use wireless and I bought a lot of wireless things.
[00:20:01.360 --> 00:20:05.360]   And then it felt like it was going out of fashion like, oh, it's too inefficient.
[00:20:05.360 --> 00:20:07.240]   It's too hard to do it right.
[00:20:07.240 --> 00:20:09.440]   Let's go back to wired charging.
[00:20:09.440 --> 00:20:10.760]   It is inefficient.
[00:20:10.760 --> 00:20:13.280]   I mean, it takes much longer to charge.
[00:20:13.280 --> 00:20:16.320]   And this is like two years ago when I last tried a Qi mat.
[00:20:16.320 --> 00:20:18.240]   So it's gotten better.
[00:20:18.240 --> 00:20:19.240]   It's gotten better.
[00:20:19.240 --> 00:20:23.160]   And as I said, Samsung on this Note 8 has a fast charger wireless charger.
[00:20:23.160 --> 00:20:24.760]   Okay, we'll see.
[00:20:24.760 --> 00:20:31.400]   Because when the double this, what's it called, quick charge, the like half your phone in
[00:20:31.400 --> 00:20:32.600]   15 minutes kind of charging.
[00:20:32.600 --> 00:20:34.200]   That's a Qualcomm quick charge.
[00:20:34.200 --> 00:20:35.200]   Yeah.
[00:20:35.200 --> 00:20:37.480]   So who that's great.
[00:20:37.480 --> 00:20:39.160]   You wouldn't want to compete with that.
[00:20:39.160 --> 00:20:41.040]   Well, if you could do it wirelessly.
[00:20:41.040 --> 00:20:42.120]   I mean, this is okay.
[00:20:42.120 --> 00:20:47.080]   So one of the reasons that's real Apple is using Qi charging a because unlike it's very
[00:20:47.080 --> 00:20:49.760]   unapply because you would expect they would use Apple charging.
[00:20:49.760 --> 00:20:53.480]   They're not even compatible with anything anybody else is doing, but they didn't, which
[00:20:53.480 --> 00:20:58.640]   makes Qi, which was already the de facto standard power mat was starting to lose ground.
[00:20:58.640 --> 00:21:01.480]   It makes Qi the definite winner.
[00:21:01.480 --> 00:21:07.040]   And now you're going to see I suspected airports at bars, which is great because there is a
[00:21:07.040 --> 00:21:14.080]   dissed as a real disadvantage to plugging in your phone or your device to some strangers,
[00:21:14.080 --> 00:21:15.600]   USB port.
[00:21:15.600 --> 00:21:16.600]   That is very risky.
[00:21:16.600 --> 00:21:18.600]   Now as a Starbucks had that for.
[00:21:18.600 --> 00:21:19.600]   Yeah.
[00:21:19.600 --> 00:21:20.600]   And I don't recommend it.
[00:21:20.600 --> 00:21:21.600]   I've never seen it.
[00:21:21.600 --> 00:21:22.600]   No, no, no, no.
[00:21:22.600 --> 00:21:23.600]   Starbucks has the charging.
[00:21:23.600 --> 00:21:26.920]   You'll see them everywhere now because I never see.
[00:21:26.920 --> 00:21:29.400]   I've never seen somebody use it.
[00:21:29.400 --> 00:21:30.400]   Isn't that funny?
[00:21:30.400 --> 00:21:32.280]   I I've used it, but you had to.
[00:21:32.280 --> 00:21:36.440]   So the other thing is you had to have a mat on your or you had to have the ability on
[00:21:36.440 --> 00:21:37.440]   your phone.
[00:21:37.440 --> 00:21:40.000]   What if it were built into the bar and any, but when you put your phone down on the bar,
[00:21:40.000 --> 00:21:41.480]   it's just getting a charge just because it's built in.
[00:21:41.480 --> 00:21:42.480]   So I can't make the cicada.
[00:21:42.480 --> 00:21:43.480]   The user is a coaster too.
[00:21:43.480 --> 00:21:45.960]   I think of all the uses we had.
[00:21:45.960 --> 00:21:46.960]   Go ahead.
[00:21:46.960 --> 00:21:47.960]   IKEA.
[00:21:47.960 --> 00:21:51.640]   IKEA has a side table that does this.
[00:21:51.640 --> 00:21:59.160]   It was either Hilton or Hyatt in a couple of the hotels had bought furniture that allowed
[00:21:59.160 --> 00:22:00.160]   this.
[00:22:00.160 --> 00:22:01.320]   I wrote about it when I was at fortune.
[00:22:01.320 --> 00:22:03.320]   So I mean, they're.
[00:22:03.320 --> 00:22:04.320]   This is a site.
[00:22:04.320 --> 00:22:07.280]   It's 59.99's nightstand with wireless charging.
[00:22:07.280 --> 00:22:08.280]   Yeah.
[00:22:08.280 --> 00:22:12.040]   So it's just it's slow because it's been hard.
[00:22:12.040 --> 00:22:14.240]   One, we had to get the standard, then you had to get everybody to put it into their
[00:22:14.240 --> 00:22:19.040]   phones and everybody's like, we'll do something when Apple does it, which makes sense.
[00:22:19.040 --> 00:22:20.040]   Well, it's done.
[00:22:20.040 --> 00:22:21.040]   It's done.
[00:22:21.040 --> 00:22:22.480]   So now, yeah.
[00:22:22.480 --> 00:22:23.640]   I had somebody in.
[00:22:23.640 --> 00:22:26.640]   Have we aired that triangulation yet, Carsten?
[00:22:26.640 --> 00:22:27.880]   It's coming up.
[00:22:27.880 --> 00:22:30.440]   Probably while I'm on vacation, right?
[00:22:30.440 --> 00:22:36.880]   I interviewed a guy who is working, who founded a company for wireless charging based on
[00:22:36.880 --> 00:22:39.720]   gallium nitride technology.
[00:22:39.720 --> 00:22:40.720]   You remember it for a while.
[00:22:40.720 --> 00:22:44.000]   Everybody was all excited about gallium arsenide was going to change chip manufacturing.
[00:22:44.000 --> 00:22:50.440]   It turned out not to be very easy, but gallium nitride is you still use a silicon, silicon
[00:22:50.440 --> 00:22:51.440]   semiconductor.
[00:22:51.440 --> 00:22:56.680]   That's a well known, robust technology to make silicon wafers, but then you apply a thin
[00:22:56.680 --> 00:23:01.280]   layer of gallium nitride on top of it.
[00:23:01.280 --> 00:23:03.520]   It makes it almost a supercondous.
[00:23:03.520 --> 00:23:10.760]   It makes it so it's eventually going to change the way we design microprocessors, but for
[00:23:10.760 --> 00:23:17.760]   now it's being used for field effect transformers, for amplification.
[00:23:17.760 --> 00:23:20.040]   It can be used for wireless charging.
[00:23:20.040 --> 00:23:23.960]   He showed, he brought in, we had it, a table, that you put anything on anywhere on that
[00:23:23.960 --> 00:23:25.680]   table, it will charge.
[00:23:25.680 --> 00:23:28.000]   I mean, a big one.
[00:23:28.000 --> 00:23:29.520]   Who is this guy?
[00:23:29.520 --> 00:23:31.920]   What's the name of it?
[00:23:31.920 --> 00:23:32.920]   What's the name of it?
[00:23:32.920 --> 00:23:33.920]   Something power.
[00:23:33.920 --> 00:23:34.920]   Something?
[00:23:34.920 --> 00:23:36.800]   You were going to have to look it up.
[00:23:36.800 --> 00:23:37.800]   Why do you know him?
[00:23:37.800 --> 00:23:38.800]   Okay.
[00:23:38.800 --> 00:23:41.440]   I have had people pitch me the gallium nitride story.
[00:23:41.440 --> 00:23:43.200]   You brought a ton of stuff in?
[00:23:43.200 --> 00:23:44.200]   I know.
[00:23:44.200 --> 00:23:46.520]   You brought a ton of stuff in and it was working.
[00:23:46.520 --> 00:23:47.520]   I know.
[00:23:47.520 --> 00:23:48.520]   Efficient power conversion.
[00:23:48.520 --> 00:23:49.520]   You think it's bogus?
[00:23:49.520 --> 00:23:50.520]   I don't know.
[00:23:50.520 --> 00:23:53.920]   I think the science is there.
[00:23:53.920 --> 00:24:02.600]   I think the challenge with any semiconductor process technology, which is what this is,
[00:24:02.600 --> 00:24:05.560]   you have to get buy-in from the foundries.
[00:24:05.560 --> 00:24:07.360]   You have to get buy-in from the manufacturers.
[00:24:07.360 --> 00:24:08.360]   Okay.
[00:24:08.360 --> 00:24:09.360]   I agree.
[00:24:09.360 --> 00:24:10.360]   This is what he's answered that.
[00:24:10.360 --> 00:24:13.880]   He said the founder, no, this is the foundries unchanged.
[00:24:13.880 --> 00:24:19.760]   We can actually add a little shed off the effectively off the side of the fab.
[00:24:19.760 --> 00:24:21.760]   The fab is still doing silicon.
[00:24:21.760 --> 00:24:22.920]   Everything they say, that's the beauty of this.
[00:24:22.920 --> 00:24:25.000]   You don't have to get a new substrate.
[00:24:25.000 --> 00:24:26.240]   You're still using silicon.
[00:24:26.240 --> 00:24:29.240]   Then we just take the wafers and we spray them with gallium nitride.
[00:24:29.240 --> 00:24:31.560]   Then we put it in through the red.
[00:24:31.560 --> 00:24:33.800]   I mean, he's building stuff now.
[00:24:33.800 --> 00:24:40.080]   I really think this is, but the point being, you're going to see he had a drone.
[00:24:40.080 --> 00:24:42.480]   We were charging a distance.
[00:24:42.480 --> 00:24:47.760]   The drone would hover over a charger and it would charge, which was pretty amazing.
[00:24:47.760 --> 00:24:48.760]   That is amazing.
[00:24:48.760 --> 00:24:49.760]   Yeah.
[00:24:49.760 --> 00:24:51.560]   Did you stick your hand in the middle of it?
[00:24:51.560 --> 00:24:52.560]   Yeah.
[00:24:52.560 --> 00:24:53.560]   Did you not get warm?
[00:24:53.560 --> 00:24:57.320]   He said the reason, he said it's not recommended.
[00:24:57.320 --> 00:25:02.440]   The reason that these wireless Qi chargers are fine is because it's not just blasting
[00:25:02.440 --> 00:25:03.440]   power like that.
[00:25:03.440 --> 00:25:05.160]   It's like a little torus or something.
[00:25:05.160 --> 00:25:06.160]   You know what?
[00:25:06.160 --> 00:25:07.160]   It's inductive.
[00:25:07.160 --> 00:25:08.160]   Yeah, it's inductive.
[00:25:08.160 --> 00:25:11.760]   It's not doing anything to you.
[00:25:11.760 --> 00:25:15.160]   Anyway, I'm excited.
[00:25:15.160 --> 00:25:19.760]   I don't know why wireless kind of went through this dip, this down cycle.
[00:25:19.760 --> 00:25:22.920]   The new Google, the Pixel doesn't have wireless in it.
[00:25:22.920 --> 00:25:27.280]   Apple's never had wireless until now, but I hope it does come back because it's really
[00:25:27.280 --> 00:25:30.400]   convenient when you get in bed just to put your phone down.
[00:25:30.400 --> 00:25:31.400]   I have a little easel.
[00:25:31.400 --> 00:25:34.480]   I put it in and it just sits on there and it's just really convenient.
[00:25:34.480 --> 00:25:36.720]   I don't care if it's going to take a little longer because it's going to be there all
[00:25:36.720 --> 00:25:37.720]   night.
[00:25:37.720 --> 00:25:38.720]   Right.
[00:25:38.720 --> 00:25:40.800]   Well, and that's the...
[00:25:40.800 --> 00:25:44.240]   If you have enough devices that have support for that, it's amazing because you can just
[00:25:44.240 --> 00:25:47.840]   be like, "Toot, toot," and just leave them there.
[00:25:47.840 --> 00:25:48.840]   Exactly.
[00:25:48.840 --> 00:25:55.080]   And then you can plug in the phone for charging and you don't have a headphone jack.
[00:25:55.080 --> 00:25:57.000]   You have to plug it in for anything?
[00:25:57.000 --> 00:25:59.920]   Well, I'm sure Apple would love to get rid of everything.
[00:25:59.920 --> 00:26:00.920]   And you're right.
[00:26:00.920 --> 00:26:02.960]   If they didn't have to charge, the lightning port would be gone.
[00:26:02.960 --> 00:26:03.960]   Why not?
[00:26:03.960 --> 00:26:05.960]   USB-C, damn it.
[00:26:05.960 --> 00:26:07.920]   Yeah, well, because that's Apple.
[00:26:07.920 --> 00:26:08.920]   I know.
[00:26:08.920 --> 00:26:09.920]   They have so fragmented...
[00:26:09.920 --> 00:26:15.640]   Okay, I'm not going to get a high horse here, but they have so fragmented their line now
[00:26:15.640 --> 00:26:17.280]   that it's very confusing.
[00:26:17.280 --> 00:26:18.960]   They use USB-C on their computers.
[00:26:18.960 --> 00:26:20.440]   They use lightning on iOS.
[00:26:20.440 --> 00:26:23.960]   They have fingerprint readers on some of their phones, but not all of their phones.
[00:26:23.960 --> 00:26:27.800]   They have headphone jacks on some of their phones, but not all of their phones.
[00:26:27.800 --> 00:26:32.760]   It's just the user interface when you don't have a fingerprint reader changes because
[00:26:32.760 --> 00:26:34.480]   you don't have a home button either.
[00:26:34.480 --> 00:26:40.160]   So they literally make now their newest high-end phones, the iPhone 8 and the iPhone 10, have
[00:26:40.160 --> 00:26:42.000]   different user interfaces.
[00:26:42.000 --> 00:26:47.920]   And when you press a home button on another, you have to slide in different up, down, left,
[00:26:47.920 --> 00:26:49.640]   it really is fragmented.
[00:26:49.640 --> 00:26:52.440]   And this is not good for users.
[00:26:52.440 --> 00:26:54.040]   It is not a good way of doing business.
[00:26:54.040 --> 00:26:58.360]   And it surprises me because Apple was famous for being the company that said, "No, we're
[00:26:58.360 --> 00:27:01.880]   going to do this, this, and this, and that's it."
[00:27:01.880 --> 00:27:03.360]   I fear for them in the long run.
[00:27:03.360 --> 00:27:07.960]   I mean, obviously, they're going to make plenty of money, but I fear for their eternal souls
[00:27:07.960 --> 00:27:08.960]   in the long run.
[00:27:08.960 --> 00:27:12.320]   I think they've already lost me on laptops.
[00:27:12.320 --> 00:27:14.520]   They have screwed up their laptop line.
[00:27:14.520 --> 00:27:16.760]   They've pretty much screwed up their desktop line.
[00:27:16.760 --> 00:27:20.760]   The iMac is still a very nice desktop, but the rest of them are not.
[00:27:20.760 --> 00:27:26.160]   And they're about to really, I think, screw the pooch on the phone, which is stunning.
[00:27:26.160 --> 00:27:30.840]   Well, if you're going to buy an iPhone, which one do you buy?
[00:27:30.840 --> 00:27:32.800]   The 8 or the 10?
[00:27:32.800 --> 00:27:33.800]   The 8.
[00:27:33.800 --> 00:27:35.400]   Because of the price?
[00:27:35.400 --> 00:27:36.400]   Good.
[00:27:36.400 --> 00:27:38.760]   God, man, that is a freaking expensive phone.
[00:27:38.760 --> 00:27:39.760]   Well, so's the 8.
[00:27:39.760 --> 00:27:40.760]   I hate to tell you.
[00:27:40.760 --> 00:27:41.760]   Yeah, exactly.
[00:27:41.760 --> 00:27:45.160]   I'm not buying either of them.
[00:27:45.160 --> 00:27:49.800]   And FaceID feels kind of gimmicky.
[00:27:49.800 --> 00:27:56.600]   And I think a lot of people net out the 8 for normals, and then there'll be some people
[00:27:56.600 --> 00:28:00.880]   who live in Silicon Valley who will go the other way.
[00:28:00.880 --> 00:28:03.280]   I have learned not to bet against Apple.
[00:28:03.280 --> 00:28:06.240]   You just watch the iPhone 10 will be the fastest selling iPhone ever.
[00:28:06.240 --> 00:28:08.080]   If they can make them.
[00:28:08.080 --> 00:28:10.080]   The real problems, I don't think they can make them very fast.
[00:28:10.080 --> 00:28:12.560]   They've got problems with manufacturing now.
[00:28:12.560 --> 00:28:13.560]   Maybe.
[00:28:13.560 --> 00:28:15.560]   Maybe hence the great pricing.
[00:28:15.560 --> 00:28:18.440]   No one will buy this phone for $1,000 or $1,000.
[00:28:18.440 --> 00:28:19.440]   Why is it that?
[00:28:19.440 --> 00:28:21.840]   Yeah, but why is $1,000 such a bad thing?
[00:28:21.840 --> 00:28:24.240]   I mean, $800 was a bad thing.
[00:28:24.240 --> 00:28:25.880]   I feel like $600.
[00:28:25.880 --> 00:28:26.880]   This is computing.
[00:28:26.880 --> 00:28:27.880]   This note 8 is $9,000.
[00:28:27.880 --> 00:28:28.880]   $39 or 60.
[00:28:28.880 --> 00:28:34.000]   Actually, I didn't want to buy it at that price, but I got a trade in because I had the
[00:28:34.000 --> 00:28:35.280]   note seven.
[00:28:35.280 --> 00:28:40.080]   And so I got it for $400, $400 plus I had a trade in my old phone, but I didn't mind
[00:28:40.080 --> 00:28:41.400]   that.
[00:28:41.400 --> 00:28:42.800]   I just.
[00:28:42.800 --> 00:28:45.200]   I like this phone.
[00:28:45.200 --> 00:28:50.000]   You only have a certain amount of budget or normal people who do not have a lot of money
[00:28:50.000 --> 00:28:53.320]   or who have a normal amount of money.
[00:28:53.320 --> 00:28:55.480]   They have to make trade offs.
[00:28:55.480 --> 00:28:58.240]   And if you're looking for.
[00:28:58.240 --> 00:28:59.240]   I'm just.
[00:28:59.240 --> 00:29:01.000]   There's here's the good news.
[00:29:01.000 --> 00:29:03.760]   There are ample excellent $200 to $400.
[00:29:03.760 --> 00:29:05.040]   I hundred phones.
[00:29:05.040 --> 00:29:08.040]   And now you can get an iPhone SE for $349.
[00:29:08.040 --> 00:29:09.040]   What was it?
[00:29:09.040 --> 00:29:10.040]   $329?
[00:29:10.040 --> 00:29:11.040]   $329?
[00:29:11.040 --> 00:29:12.040]   $350.
[00:29:12.040 --> 00:29:15.080]   So the lowest price brand new iPhone is $350.
[00:29:15.080 --> 00:29:20.120]   So there's the good news is there all of this technology has trickled down and there are
[00:29:20.120 --> 00:29:22.240]   very, very good and expensive phones.
[00:29:22.240 --> 00:29:26.040]   The Motorola G5 is an excellent phone.
[00:29:26.040 --> 00:29:29.640]   What do you really miss if you buy one of those phones versus buying one of the top screen
[00:29:29.640 --> 00:29:30.640]   and camera?
[00:29:30.640 --> 00:29:31.640]   Yeah.
[00:29:31.640 --> 00:29:32.640]   That's it.
[00:29:32.640 --> 00:29:35.200]   You know what?
[00:29:35.200 --> 00:29:37.240]   The screen tells me everything.
[00:29:37.240 --> 00:29:39.680]   No, still work camera.
[00:29:39.680 --> 00:29:40.680]   Same apps.
[00:29:40.680 --> 00:29:41.680]   Absolutely work.
[00:29:41.680 --> 00:29:43.360]   Absolutely works in the camera.
[00:29:43.360 --> 00:29:47.400]   Yeah, better cameras always nice, but is it worth $500?
[00:29:47.400 --> 00:29:50.640]   I think they're a lot of people go by a heck of a camera for $500.
[00:29:50.640 --> 00:29:52.920]   I think a lot of people feel like a decent camera is fine.
[00:29:52.920 --> 00:29:54.920]   It's just really a casual camera anyway.
[00:29:54.920 --> 00:29:55.920]   Exactly.
[00:29:55.920 --> 00:30:00.840]   Although as like things like this portrait mode, I got to say like.
[00:30:00.840 --> 00:30:01.840]   That's pretty cool.
[00:30:01.840 --> 00:30:04.720]   I mean, I cannot take bad pictures with an iPhone.
[00:30:04.720 --> 00:30:09.000]   And so now when I take my normal bad pictures, which I do all the time, people are going
[00:30:09.000 --> 00:30:11.280]   to be like, really Stacey?
[00:30:11.280 --> 00:30:12.560]   Are you living in a hole?
[00:30:12.560 --> 00:30:15.040]   Do you not do not know that this exists?
[00:30:15.040 --> 00:30:18.760]   And now people are going to it's just up in the game in a way that I just don't want
[00:30:18.760 --> 00:30:19.760]   to deal with.
[00:30:19.760 --> 00:30:25.840]   Well, I guess that's kind of what I'm thinking is that at some point consumers are going to
[00:30:25.840 --> 00:30:28.960]   kind of bridal at Apple.
[00:30:28.960 --> 00:30:29.960]   Maybe not.
[00:30:29.960 --> 00:30:30.960]   There's no history of that.
[00:30:30.960 --> 00:30:31.960]   Well, I'm not.
[00:30:31.960 --> 00:30:33.440]   I mean, I would not bright darn it.
[00:30:33.440 --> 00:30:37.840]   You're giving me such a nice feature that I should be expected to use because otherwise
[00:30:37.840 --> 00:30:39.000]   my photos look like crap.
[00:30:39.000 --> 00:30:42.680]   I mean, really, that's me being kind of lazy and I will still do it.
[00:30:42.680 --> 00:30:43.680]   People people give me.
[00:30:43.680 --> 00:30:45.360]   But you won't pay a thousand bucks.
[00:30:45.360 --> 00:30:48.000]   No, I will not.
[00:30:48.000 --> 00:30:53.000]   It's kind of like when manicures became everyone has them, right?
[00:30:53.000 --> 00:30:56.360]   I still don't have a manicure because I'm like, yeah, I'm not going to pay for that.
[00:30:56.360 --> 00:31:00.040]   But now I look at when I go places, I'm like, oh, I'm like.
[00:31:00.040 --> 00:31:02.040]   I'm going to pay for a $1,500 oven.
[00:31:02.040 --> 00:31:03.040]   Well, okay.
[00:31:03.040 --> 00:31:04.960]   Because I have to.
[00:31:04.960 --> 00:31:05.960]   It's priorities.
[00:31:05.960 --> 00:31:06.960]   Yeah.
[00:31:06.960 --> 00:31:07.960]   Priorities.
[00:31:07.960 --> 00:31:09.960]   Because good is life.
[00:31:09.960 --> 00:31:14.960]   We'll pay for a lamp you can talk to, but let's talk.
[00:31:14.960 --> 00:31:16.760]   Fair enough.
[00:31:16.760 --> 00:31:18.600]   I actually spend it goes elsewhere.
[00:31:18.600 --> 00:31:21.840]   I actually do find that that's true that people who say, I'd never pay a thousand for
[00:31:21.840 --> 00:31:23.640]   an iPhone.
[00:31:23.640 --> 00:31:25.440]   Well, gladly pay a thousand for something else.
[00:31:25.440 --> 00:31:26.440]   That's just what it's whatever your price is.
[00:31:26.440 --> 00:31:29.560]   It is the device I use more than any other device in life.
[00:31:29.560 --> 00:31:33.440]   So I'm okay with paying buying a Pixel 45 bucks a month.
[00:31:33.440 --> 00:31:36.520]   Well, I don't pay that way.
[00:31:36.520 --> 00:31:39.120]   No, but I mean, seriously, think of it.
[00:31:39.120 --> 00:31:43.320]   If you amortize it over the life of the phone, let's say it's a couple of years.
[00:31:43.320 --> 00:31:46.520]   45 bucks a month.
[00:31:46.520 --> 00:31:49.800]   That's less than a, it's like a buck 25 a day.
[00:31:49.800 --> 00:31:56.360]   And actually, if you look at the cost per usage minutes of that phone's day, see versus
[00:31:56.360 --> 00:31:57.360]   an oven.
[00:31:57.360 --> 00:31:58.360]   Yeah.
[00:31:58.360 --> 00:31:59.360]   That's a good point.
[00:31:59.360 --> 00:32:02.000]   How much tough call person made usage care.
[00:32:02.000 --> 00:32:03.800]   Instead of so.
[00:32:03.800 --> 00:32:04.800]   Really.
[00:32:04.800 --> 00:32:05.800]   By the way, I tried your recipe.
[00:32:05.800 --> 00:32:07.760]   I did the, I did the cauliflower in the June.
[00:32:07.760 --> 00:32:08.760]   Oh, yeah.
[00:32:08.760 --> 00:32:10.600]   It was a little soggy.
[00:32:10.600 --> 00:32:12.600]   Oh, I'm sorry.
[00:32:12.600 --> 00:32:13.600]   Did you do the.
[00:32:13.600 --> 00:32:16.440]   I'd say he did it wrong because the oven did it for it.
[00:32:16.440 --> 00:32:19.080]   I would have cooked it longer till it, because I, maybe it's just me.
[00:32:19.080 --> 00:32:21.720]   I like my cauliflower roasted cauliflower be a little bit more.
[00:32:21.720 --> 00:32:22.720]   No, mine gets kind of burnt.
[00:32:22.720 --> 00:32:23.720]   See, I want to burn.
[00:32:23.720 --> 00:32:26.080]   I like the caramelized.
[00:32:26.080 --> 00:32:27.080]   When you put it in there?
[00:32:27.080 --> 00:32:28.080]   Well, I just.
[00:32:28.080 --> 00:32:31.220]   to dry your stuff. Oh really? Oh, maybe that's what went wrong. Cause yeah.
[00:32:31.220 --> 00:32:34.880]   When you just watched it. I just watched it so maybe it was. Yeah. Don't put any
[00:32:34.880 --> 00:32:38.640]   of that because that seems it. It's quite flowers. Yeah. Cut off large real sensitive to that
[00:32:38.640 --> 00:32:43.920]   too. Damn it. The oven should have known better. Billie. You know, we'll we'll ask them to stick
[00:32:43.920 --> 00:32:51.120]   an extra sensor there. Just say, Do you dry it? Did you dry it? Yeah. Of course, that's right,
[00:32:51.120 --> 00:32:56.160]   that's exactly right. No a little blue dryer setting. Well, it is convection. They could do that.
[00:32:57.360 --> 00:33:04.800]   Blow out the steam. There it. Okay. Wait. Okay. Not on the June, but let's go back for a second
[00:33:04.800 --> 00:33:11.280]   because I think it was a fast company article. Maybe it was venture B that asked if the they're
[00:33:11.280 --> 00:33:16.400]   like the iPhone 10 doesn't come up with a new metaphor for computing and they were sad about that.
[00:33:16.400 --> 00:33:21.680]   Did you see this article by any chance? That's that's that's quite a burden.
[00:33:23.600 --> 00:33:29.920]   Isn't it a slap of glass that has to fit in your pocket? Where's the new metaphor for computing?
[00:33:29.920 --> 00:33:37.120]   You know, they were like 10 years. That's what we need. But I will say, I will say, I think they
[00:33:37.120 --> 00:33:44.480]   kind of showed it in what I think what I think and I did a little of this on the podcast. I've
[00:33:44.480 --> 00:33:51.680]   been thinking about it a little bit more is with the iPods, yeah, AirPods, sorry, AirPods and
[00:33:51.680 --> 00:33:57.760]   the watch today that watch is not great because it doesn't have a lot of talk time, etc. They
[00:33:57.760 --> 00:34:02.240]   freed us up from carrying our phone everywhere. You're still going to bring it to work or something
[00:34:02.240 --> 00:34:08.080]   like that. But when you walk the dog or maybe you're just running out, you know, to the corner store
[00:34:08.080 --> 00:34:13.440]   or you just don't want to pull out your phone, you're going to start leaving it in your bag more
[00:34:13.440 --> 00:34:19.520]   the same way. I remember back in like 2008, I think it was at South by Southwest, I suddenly
[00:34:19.520 --> 00:34:26.000]   noticed we shifted from everyone being on their laptops at the event to everyone just charging
[00:34:26.000 --> 00:34:29.920]   their phone. So you'd see people instead of sitting on the floor charging their laptops and doing
[00:34:29.920 --> 00:34:34.800]   their stuff, they were sitting on the floor doing everything with their phone. And I think if you
[00:34:34.800 --> 00:34:41.120]   think about metaphors for computing, that unless you're in content creation, because that's why we
[00:34:41.120 --> 00:34:47.520]   all stop laptops, that's a really interesting possibility. We'll go there. It needs to improve,
[00:34:47.520 --> 00:34:50.800]   but I think that's kind of where we might be heading. That's it.
[00:34:50.800 --> 00:34:57.200]   If you don't call this the new metaphor for computing, I don't know what is.
[00:34:57.200 --> 00:35:05.200]   Animoji's my friends. All right, you know who's going to do that? If you really want somebody
[00:35:05.200 --> 00:35:10.960]   reinventing computing, Samsung has said, and I hope that this is they're not just blowing smoke.
[00:35:10.960 --> 00:35:18.240]   Samsung has said that the next note, next year's note, will have a foldable screen.
[00:35:18.240 --> 00:35:23.040]   Oh, yeah, I saw this. That would be a new metaphor, wouldn't it?
[00:35:23.040 --> 00:35:28.160]   Okay, no, that's just having a foldable screen. So I'm gonna have to can fold back on itself.
[00:35:28.160 --> 00:35:33.600]   It can. So imagine something the same size of the phone that you could put in your pocket,
[00:35:33.600 --> 00:35:40.480]   but that when you needed a larger screen, you'd open it up and it would be maybe seven like a
[00:35:40.480 --> 00:35:48.400]   tablet. What about that? Huh? Now, how much would you pay? I mean, that's still just a screen.
[00:35:48.400 --> 00:35:53.360]   Well, but that's I think that's well, you're right. I mean, I guess if you make the screen
[00:35:53.360 --> 00:35:58.960]   a Windows desktop, it's not a new metaphor for computing. That's actually not a new metaphor,
[00:35:58.960 --> 00:36:03.840]   but it's it's cool. I'm not I'm not lying that it's not cool. I think that's pretty big. I mean,
[00:36:03.840 --> 00:36:10.400]   if you came from another planet, if you came from another planet and you saw us arguing
[00:36:10.960 --> 00:36:15.600]   is this better or is this or that better? You'd say, well, but they're all
[00:36:15.600 --> 00:36:21.600]   glass slab rectangular glass slabs. What do you mean? They're all this? What's the difference?
[00:36:21.600 --> 00:36:24.800]   It's like Angel, how many angels can dance on the head of a pin? It's a completely
[00:36:24.800 --> 00:36:30.160]   silly academic argument. These things are so similar. I mean,
[00:36:30.160 --> 00:36:34.800]   so they're not doing a new way to there's a there's a new way to interact. So the phones
[00:36:34.800 --> 00:36:39.120]   represent about the new way to interact with computing and new opportunities for computing,
[00:36:39.120 --> 00:36:43.920]   because they had always on GPS that you could write, right? And voices change things, right?
[00:36:43.920 --> 00:36:49.840]   The ability to voice voices doing a similar thing, which is and voice is part of this, like
[00:36:49.840 --> 00:36:54.480]   the upcoming metaphor for computing with computing embedded throughout your right,
[00:36:54.480 --> 00:36:59.200]   not embedded in your body, but around screen. Well, that's that is my thought.
[00:36:59.200 --> 00:37:06.240]   Your screen is going to become the same way, the same way that I have to pull out my laptop.
[00:37:06.240 --> 00:37:11.760]   If I want to write a blog post, your screen will become something that you pull out only when you
[00:37:11.760 --> 00:37:17.920]   need that functionality and you'll need it still quite a bit, but it's going to be less and less
[00:37:17.920 --> 00:37:25.040]   and you could do everything soon from not everything, most things from ear pods and
[00:37:25.040 --> 00:37:29.680]   a computer that sits on your wrist and maybe also talks back to your phone for
[00:37:29.680 --> 00:37:32.960]   pulls from your phone for extra compute power. I don't know. Next generation.
[00:37:32.960 --> 00:37:38.400]   The last thing, the last thing that changed the the metaphor of computing was the iPhone 10 years
[00:37:38.400 --> 00:37:45.040]   ago. The last attempt at it was Google Glass. But Google Glass, it was just before its time,
[00:37:45.040 --> 00:37:49.760]   because imagine a pair of spectacles that look roughly like your actual glasses with
[00:37:49.760 --> 00:37:58.800]   air pod style audio and speech in the temples, camera, heads up display, augmented reality heads
[00:37:58.800 --> 00:38:05.120]   up display. Something that's before its time has not successfully changed computing.
[00:38:05.120 --> 00:38:12.400]   Right. I mean, the Nokia talk about and disagree. Look at the Newton. The Newton was a flop,
[00:38:12.400 --> 00:38:19.440]   but predicted everything that has happened since. Yeah, but I mean, Nokia had smartphones and I
[00:38:19.440 --> 00:38:28.000]   remember vividly sitting with, you know, executives at Qualcomm about like tablets, right? They,
[00:38:28.000 --> 00:38:31.360]   we discussed the iPad before the iPad was even a thing.
[00:38:31.360 --> 00:38:36.480]   It's a long tradition. In fact, that one changed the
[00:38:36.480 --> 00:38:41.760]   the metaphor of the shooting. Remember the slate? Remember the ghost? The go computer?
[00:38:41.760 --> 00:38:46.720]   Right. I buy it. I buy it. There's a long tradition of very clunky, poorly implemented
[00:38:46.720 --> 00:38:53.280]   attempts to do what only later technology would make possible. And I think that the
[00:38:53.280 --> 00:38:58.640]   Google glass actually is going to be, we'll look back on it much like we look on Newton or the slate
[00:38:58.640 --> 00:39:04.320]   and say with a laugh. Yeah, that was a good try, but time wasn't ready. Microsoft's HoloLens is
[00:39:04.320 --> 00:39:14.000]   still not ready. It's all right. Q cat. Q cat. It was a sign of the times.
[00:39:14.000 --> 00:39:20.240]   I knew to single worst business presentation I ever went to.
[00:39:20.880 --> 00:39:27.280]   So I think would you now you like a smaller phone, Stacey, right? So you're not going to get the
[00:39:27.280 --> 00:39:33.200]   pixel to XL. You'll get the pixel to the little. Yeah, I'll get the smaller of my options.
[00:39:33.200 --> 00:39:38.000]   October 5th is supposedly the day. We'll find out.
[00:39:38.000 --> 00:39:40.320]   Dun, dun, dun. Google has not said.
[00:39:40.320 --> 00:39:47.840]   I think it I think that will be the end of it. And you can at that point make a reasonable
[00:39:47.840 --> 00:39:54.080]   choice between the options. I think the LG V 30 is going to be another one to look very closely on.
[00:39:54.080 --> 00:40:03.520]   All right. Especially if Google doesn't have a headphone check. I hope the LG,
[00:40:03.520 --> 00:40:10.880]   let me see if the LG does. Oh, you know, I have this is my phone that died. I have the Nexus 5X
[00:40:10.880 --> 00:40:17.440]   that LG screwed up so badly. Yeah. This was actually my replacement that just died like literally
[00:40:17.440 --> 00:40:23.680]   in my bag one day. I pulled it out and it was like, boop, done. And I just I'm too lazy to actually
[00:40:23.680 --> 00:40:27.520]   get to do it back for a month since I have a spare phone. So
[00:40:27.520 --> 00:40:36.800]   so that's me. I would I would also look at the V 30. I'm trying to find out though. Yeah, it has a
[00:40:36.800 --> 00:40:41.120]   headphone jack. See, that's going to be that that's going to be the effect the
[00:40:43.600 --> 00:40:45.840]   for people who need a headphone jack the pixel to.
[00:40:45.840 --> 00:40:53.120]   Back to this with the chart, you really could Apple could eliminate all
[00:40:53.120 --> 00:40:57.600]   yeah, orifices. I feel that they will. I feel that. Can we not call them orifices?
[00:40:57.600 --> 00:41:03.120]   I'm just going to put that request. It's just a fancy word for whole.
[00:41:03.120 --> 00:41:08.800]   Yeah. Why don't we just call it. It is ports. We can call the ports. We're actually
[00:41:08.800 --> 00:41:14.480]   like I think whole sounds worse. I agree. Ports. Okay. Ports.
[00:41:14.480 --> 00:41:23.120]   So if you if you care about if you care about learning about 3D printed self folding electronics,
[00:41:23.120 --> 00:41:28.960]   yes, I do. What we're just talking about. I received today an article from the applied
[00:41:28.960 --> 00:41:36.240]   materials and interfaces publication. You get such great magazines at home. That's such a good
[00:41:36.240 --> 00:41:42.800]   magazine. It is. It is. I don't think it's yeah. I can send you here. I'll drop a link. Stacy,
[00:41:42.800 --> 00:41:50.080]   your new applied materials magazine has arrived. If you don't know how things work,
[00:41:50.080 --> 00:41:55.440]   how can you talk about it? Like a television. Here, I'll stick it under Stacy's thing.
[00:41:55.440 --> 00:42:00.720]   I know nobody's going to read it, but bye, golly. I am. I golly.
[00:42:00.720 --> 00:42:05.360]   Bye, golly. I'm going to. We don't have to read it because you did. So tell us what's in it.
[00:42:05.920 --> 00:42:11.840]   I haven't read it yet. Oh, when we were talking about this, I literally got it today. It's in one
[00:42:11.840 --> 00:42:17.040]   of my tabs. All right. I'm loading it up 3D printed. It is pretty complicated. So holding.
[00:42:17.040 --> 00:42:24.000]   Well, you didn't mention self folding. Yeah. So yeah, this is this is really cool stuff. Sorry.
[00:42:24.000 --> 00:42:30.960]   Composites that self fold have so far relied on using the stimuli responsive mechanisms focusing
[00:42:30.960 --> 00:42:36.800]   on reversible shape change integration, creating additional functions within these composites
[00:42:36.800 --> 00:42:40.400]   can also they're going to have different shapes depending on their function.
[00:42:40.400 --> 00:42:48.560]   Yeah. Wow. I mean, once you so this is cool stuff, right? Upon peeling from the print platform,
[00:42:48.560 --> 00:42:55.440]   the composite self shapes itself using the residual forces resulting from polymer swelling
[00:42:55.440 --> 00:42:59.760]   during the layer by layer fabrication process as a specific example,
[00:42:59.760 --> 00:43:03.840]   electrochromic elements are printed within the composite and can be electrically controlled
[00:43:03.840 --> 00:43:08.720]   through its folded legs. Our shape transformation scheme provides a route to transport planar
[00:43:08.720 --> 00:43:16.480]   electronics into non planar geometries containing the overhangs. My God. How do they ever think of
[00:43:16.480 --> 00:43:23.200]   that? This is an academic paper, guys. Let's let's let's all know it's printed flat. And then when
[00:43:23.200 --> 00:43:26.320]   it's removed from the surface, it goes and assumes shape.
[00:43:26.320 --> 00:43:32.560]   And that cool. Wow. Did you ever read Ken lose a paper minasuries short story where
[00:43:32.560 --> 00:43:37.760]   in his he folds origami shapes and they get up and walk around, you could create those.
[00:43:37.760 --> 00:43:44.080]   And that would be neat. Hmm. Okay. All right. Sorry. The future is cool. We'll move back to the
[00:43:44.080 --> 00:43:47.760]   present because there's Google stuff. I would like to live in the future. I'm just saying.
[00:43:47.760 --> 00:43:51.200]   There's lots of Google stuff. All right. Let's take a break.
[00:43:51.200 --> 00:43:56.880]   We will get to the future without Bodegas. We'll get to that. I love that. I want to talk about that.
[00:43:56.880 --> 00:44:03.680]   That story is amazing. And more in just a minute, Stacey Higginbotham from Stacey on IOT,
[00:44:03.680 --> 00:44:09.760]   the IOT podcast.com at Gigastacey on the Twitter because she was with Gigga on for so long.
[00:44:09.760 --> 00:44:13.520]   She's still got the giga in her. Oh, I do have a mouse thing over my door.
[00:44:13.520 --> 00:44:19.280]   Yeah. That's ours. We put that there for you. It's a new it's a new hook hanging on the door.
[00:44:20.800 --> 00:44:23.600]   It's not chrome like all the other. It looks so realistic.
[00:44:23.600 --> 00:44:29.120]   Oh, it moved. Oh my god. Now it's on you. Get it off of me. Get it off of me.
[00:44:29.120 --> 00:44:35.200]   Also with this. Jeff Jarvis. He's at Buzz machine.com. I have no idea what's happening.
[00:44:35.200 --> 00:44:41.760]   Yeah. Put it put a mouse on him. That's all right. We are brought to you today by Rocket
[00:44:41.760 --> 00:44:47.040]   Mortgage. Put a mouse on your mortgage. Mortgage quick and lunch is one of the best lenders in
[00:44:47.040 --> 00:44:50.160]   the country. Realize that the mortgage process really wasn't keeping up at the times. It was
[00:44:50.160 --> 00:44:54.720]   directly out of the 20th, maybe the 19th century. You had to go to a bank,
[00:44:54.720 --> 00:44:58.960]   beggar in Hatton hand and say, "Please, can I have some money to buy this house?" Or,
[00:44:58.960 --> 00:45:03.680]   "Can I refinance my house and take some money out of it?" And then he would go and look through a
[00:45:03.680 --> 00:45:11.120]   bunch of foolscap paper, thin paper and search for the best rate. Maybe, you know, he'd then say,
[00:45:11.120 --> 00:45:14.720]   "All right. Well, here's what we'll need from you and give you a laundry list of
[00:45:14.720 --> 00:45:19.920]   documents you have to find or bag steal or borrow from your bank and other financial.
[00:45:19.920 --> 00:45:25.520]   This is all history. History. Thanks to quick and loans, they've invented Rocket Mortgage.
[00:45:25.520 --> 00:45:31.920]   It's an entirely online mortgage approval process. You do it directly from your phone or your computer
[00:45:31.920 --> 00:45:38.080]   or your tablet and it's fast. You don't have to go find papers because they are paired up with
[00:45:38.080 --> 00:45:42.560]   all the financial institutions. So all you have to do is share your financial information by touching
[00:45:42.560 --> 00:45:46.800]   a button. And then they crunch the numbers and based on your income assets and credits,
[00:45:46.800 --> 00:45:52.080]   they will come up with a home loan option or two or three for which you qualify. You pick the one
[00:45:52.080 --> 00:45:57.040]   that's right for you and all of this, thanks to computers, took minutes. You didn't even have to
[00:45:57.040 --> 00:46:01.200]   get up from the chair or you didn't have to leave the open house where you're going to make that
[00:46:01.200 --> 00:46:06.640]   offer because you could show the realtor your phone that says, "You're approved." That's Rocket
[00:46:06.640 --> 00:46:12.320]   Mortgage for you. Fast, easy, transparent. Apply, simply understand fully mortgage confidently at
[00:46:12.320 --> 00:46:18.800]   rocketmortgage.com/twig=housinglenderlicensesinall50states and then
[00:46:18.800 --> 00:46:28.800]   LSSconsumerAxis.org number 30-30. Rocketmortgage.com/twig. We thank you so much for supporting this. We
[00:46:28.800 --> 00:46:33.520]   can Google, couldn't do it without our fine sponsors. Well, we could, but we just have to charge you.
[00:46:33.520 --> 00:46:35.520]   Which would you prefer?
[00:46:39.120 --> 00:46:44.080]   Keep this business model alive. I think we've talked about this before.
[00:46:44.080 --> 00:46:48.560]   I think you said something and I really liked this. It's fundamentally democratic to have
[00:46:48.560 --> 00:46:54.880]   ad-supported media because it's free. It is. All you have to do is give it your attention.
[00:46:54.880 --> 00:47:03.360]   You got to give up something. There's blood in the water in Silicon Valley. I thought this was a
[00:47:03.360 --> 00:47:10.080]   very interesting think piece of buzz piece. Ben Smith, its editor-in-chief, pointed out that it is,
[00:47:10.080 --> 00:47:15.840]   I for a little bit thought it might be a golden age for Silicon Valley and mega corporations because
[00:47:15.840 --> 00:47:23.600]   there'll be no antitrust prosecutions under the Trump administration. Or will they? Well,
[00:47:23.600 --> 00:47:31.040]   perhaps they will. Steve Bannon and Bernie Sanders both want big tech treated as in Bannon's words
[00:47:31.040 --> 00:47:37.200]   in Hong Kong this week. Public utilities. Tucker Carlson and Franklin for have found common ground,
[00:47:37.200 --> 00:47:42.320]   even the group, no labels. I'm reading from his column. An exquisitely pole tested effort to
[00:47:42.320 --> 00:47:46.720]   create a safe new center is on board. Robert Murdoch never shy to use his media power to
[00:47:46.720 --> 00:47:54.000]   advance his commercial interests as hard at work. Andy Trust is back, baby. It started with Yelp
[00:47:54.000 --> 00:48:01.600]   complaining that despite a 2012 consent decree, Google continues to scrape photos from the Yelp
[00:48:01.600 --> 00:48:09.520]   site and put them in its business listings. They want an antitrust case against Google and they've
[00:48:09.520 --> 00:48:19.280]   gone to the FTC to ask for it. I think it started long before this. If you look at things like
[00:48:19.280 --> 00:48:31.440]   Europe and GDPR, that is absolutely. Ben says this leads to a kind of murder on the Orient Express
[00:48:31.440 --> 00:48:37.600]   Alliance against big tech. Everyone wants to kill them. I think it's only to add in Europe.
[00:48:37.600 --> 00:48:43.280]   I've been trying to write this and it's impossible to write without studying horribly
[00:48:43.280 --> 00:48:47.680]   haughty. We talked about it last week on the show a little bit. What the hell? There's never
[00:48:47.680 --> 00:48:50.400]   stocks me. I don't sound haughty. You've always been a haughty. It's okay.
[00:48:50.400 --> 00:48:58.400]   But with so much in their control, with so much power, with the future of the Internet
[00:48:58.400 --> 00:49:05.920]   control, they've got to go head over heels to be decent. It wasn't sufficient to say don't be evil.
[00:49:05.920 --> 00:49:14.720]   The motto should have been do good. I actually think Facebook is, Google actually tries.
[00:49:15.840 --> 00:49:22.720]   Facebook on the other hand has been pretty shruggy about it all. I think Google with
[00:49:22.720 --> 00:49:27.680]   don't be evil very sincerely for a long time really was trying not to be evil because they
[00:49:27.680 --> 00:49:33.920]   were aware of what kind of future they could build with access to all of the world's information,
[00:49:33.920 --> 00:49:38.640]   which used to be. Is it still their thing? Oh yeah, I'm making it accessible.
[00:49:38.640 --> 00:49:44.320]   Always for the record. The News Integrity Initiative, which I started, got a lot of money
[00:49:44.320 --> 00:49:47.360]   from Facebook, what I'm independent of Facebook, a caveat done.
[00:49:47.360 --> 00:49:55.120]   No, I think that Zuckerberg, when I interviewed Zuckerberg years ago, no. He honestly, earnestly
[00:49:55.120 --> 00:49:58.080]   believes that a connected world was a better world and getting more people with connect with
[00:49:58.080 --> 00:50:02.160]   each other and create communities and working communities is a better world.
[00:50:02.160 --> 00:50:05.760]   So I think Facebook has a mission to how well they do with our missions.
[00:50:05.760 --> 00:50:07.680]   Is it a different question? I think they each have your answer.
[00:50:07.680 --> 00:50:13.040]   I think now Zuckerberg is doing the soul searching necessary. I don't think Zuckerberg
[00:50:13.040 --> 00:50:18.880]   was malicious in, well, actually he kind of was a dick if you think about why he created Facebook
[00:50:18.880 --> 00:50:22.640]   in the first place. But none of these things are assuming that this is the movie.
[00:50:22.640 --> 00:50:29.920]   None of these things are assuming that this is because of the malfeasance of these corporate
[00:50:29.920 --> 00:50:33.680]   titans. It's just the public opinion is turning against them.
[00:50:33.680 --> 00:50:38.800]   Well, I think people are becoming more aware of how much information these people have,
[00:50:39.360 --> 00:50:44.640]   how much influence there is. And they're also feeling alienated in ways that
[00:50:44.640 --> 00:50:54.880]   are probably very confusing. So when you think about how people are rewarded in the faces they
[00:50:54.880 --> 00:51:02.960]   show on these sites and how not true they are and how intrusive it becomes to maintain that facade,
[00:51:02.960 --> 00:51:10.640]   I think people are becoming a little bit more aware of the, it's not harms. It's just
[00:51:10.640 --> 00:51:14.960]   of the permeation of the stuff into it.
[00:51:14.960 --> 00:51:20.880]   Yeah, but I also think, Stacy, what Ben Smith's article does is it makes clear that there are a
[00:51:20.880 --> 00:51:26.960]   lot. There are also a lot of enemies with agendas who are ganging up. And those enemies include
[00:51:26.960 --> 00:51:31.600]   media who think that Google and Facebook stole what God gave them in revenue.
[00:51:31.600 --> 00:51:36.240]   Yelp, which is a competitor. Murdoch politicians.
[00:51:36.240 --> 00:51:43.760]   That's how this always goes though. I'm not going to, I mean, to take down if you want to
[00:51:43.760 --> 00:51:50.960]   regulate or put some sort of governance on what Facebook and Google are doing or the other big tech
[00:51:50.960 --> 00:51:56.000]   companies. And I actually don't think that's a bad thing. You're going to need this kind of
[00:51:56.000 --> 00:52:02.960]   murder on the Orient Express group. Does media have an agenda? Oh, yes, they do.
[00:52:02.960 --> 00:52:09.280]   But I think that's where we split. I think that government, if you imagine, pardon me,
[00:52:09.280 --> 00:52:14.240]   that's just how politics works though. Those companies, thus the internet, I dread that.
[00:52:14.240 --> 00:52:22.480]   I dread any, I dread all government regulation because we have to dig through so much crap
[00:52:22.480 --> 00:52:27.520]   to get to the real issues and things that might actually help individual people. And I'm always
[00:52:27.520 --> 00:52:34.320]   going to be for the individual consumers in every fight. But- Well, let me ask you this.
[00:52:34.320 --> 00:52:42.800]   That's an interesting starting point. There's no, I mean, the power of capitalism is that when
[00:52:42.800 --> 00:52:50.320]   somebody becomes wealthy, makes money, they reinvest it. They make money out of innovation.
[00:52:50.320 --> 00:52:54.960]   They don't- It's not a zero-sum game. They don't become- And I think you could say this is the case
[00:52:54.960 --> 00:53:00.080]   was Google, Facebook, Amazon, maybe not Amazon so much, but certainly Google and Facebook,
[00:53:00.080 --> 00:53:03.600]   they added value. And that's where all that money came from and all that power came from,
[00:53:03.600 --> 00:53:08.960]   was adding value. It wasn't they took it from somebody else. So everybody acknowledges that
[00:53:08.960 --> 00:53:14.640]   these are valuable entities. They provide value in our life. But there's also seems to be a growing
[00:53:14.640 --> 00:53:21.200]   awareness that they have become so big that they have too much power now.
[00:53:21.200 --> 00:53:26.800]   It's different for each one, but let's use Facebook as an example. Margaret Sullivan in the Washington
[00:53:26.800 --> 00:53:32.240]   Post, this is again from Ben Smith's column, wrote, "Would Donald Trump be president today if
[00:53:32.240 --> 00:53:37.760]   Facebook didn't exist? Although there is a long list of reasons for his win, there's increasing
[00:53:37.760 --> 00:53:42.720]   reason to really leave the answer is no. And the more we learn about the Russians very effectively
[00:53:42.720 --> 00:53:47.920]   using Facebook and so forth." So that's where there's- It's a bit specious. That's a bit of a
[00:53:47.920 --> 00:53:55.920]   specious argument. Yeah, it is because, you know, that's from the left without radio,
[00:53:55.920 --> 00:54:01.280]   with X exists without TV, with X exists without whatever. But radio TV or industry, Facebook is a
[00:54:01.280 --> 00:54:07.680]   company. Well, we used to have fair, is it the fairness doctrine? Yeah. When we were talking about
[00:54:07.680 --> 00:54:15.520]   political parties, I mean, TV and radio back in the day, you had to publish, "Is it the fairness
[00:54:15.520 --> 00:54:19.360]   doctrine, Jeff? This is a long time since my media law classes." Yes, it's a fairness
[00:54:19.360 --> 00:54:23.280]   doctrine. But I have to say, there's a difference between saying, "I don't want to shut down radio
[00:54:23.280 --> 00:54:27.280]   and TV because that's shutting down industry." But then saying, there's a company that had one
[00:54:27.280 --> 00:54:30.240]   company that wields too much power. Well, it's a very different thing. The president's
[00:54:30.240 --> 00:54:32.320]   thought on Facebook. The president's on Twitter, unless you remember, it's not-
[00:54:32.320 --> 00:54:37.600]   Well, we're having this debate about like Sinclair with its pro-Trump agenda and letting
[00:54:37.600 --> 00:54:40.000]   the FCC approve. It's-
[00:54:40.000 --> 00:54:44.240]   Unless we sound too left-wing on the other side, many conservatives say
[00:54:44.240 --> 00:54:50.800]   these companies, Facebook and Google, are fostering a progressive agenda that they don't like.
[00:54:50.800 --> 00:54:56.880]   So that's the point is it's coming from both sides now. There's a general building consensus
[00:54:56.880 --> 00:54:59.280]   that these companies are too big to balance. Yeah, there's also a general-
[00:54:59.280 --> 00:55:02.560]   Yeah, I'm sorry, interrupted. There's a general-
[00:55:04.080 --> 00:55:08.720]   The institutions that are challenged by these new companies and by this new reality of the internet
[00:55:08.720 --> 00:55:11.280]   are fighting back because they're challenged, because they're disrupted.
[00:55:11.280 --> 00:55:15.680]   Right. I understand that. You're talking about newspapers, for example. I understand that.
[00:55:15.680 --> 00:55:19.840]   Yeah. But that's not the only place this is coming from. It doesn't become a problem if it's
[00:55:19.840 --> 00:55:24.640]   just newspapers or if it's just the left-wing or just the right-wing. But when you get these
[00:55:24.640 --> 00:55:31.040]   unholy coalitions between all these groups, if I were Google or Facebook or Amazon, I'd be threatened.
[00:55:31.040 --> 00:55:34.480]   They should absolutely- I want to go back to something we said last week because it was on the show
[00:55:34.480 --> 00:55:39.360]   last week that the story of the $100,000 Russian political ads on Facebook broke.
[00:55:39.360 --> 00:55:40.160]   Right.
[00:55:40.160 --> 00:55:44.640]   And we were talking about it. My first thought was- well, what about my first thought was,
[00:55:44.640 --> 00:55:49.600]   I was wrong, whatever it was. But
[00:55:49.600 --> 00:55:58.480]   in first blush, I wondered whether Facebook could have known they were Russian. And that's key.
[00:55:59.280 --> 00:56:03.360]   If they were ads, they were ads. There's another talk about saying that Facebook
[00:56:03.360 --> 00:56:08.400]   should be on the same regulations, Stacy, as television and should be transparent about this.
[00:56:08.400 --> 00:56:11.840]   This to me becomes pretty easy now. And Facebook's not doing this.
[00:56:11.840 --> 00:56:19.600]   Facebook should disclose the ads and the targeting that was used for them. It should
[00:56:19.600 --> 00:56:24.960]   expose how the manipulation occurs. The public deserves to know this.
[00:56:24.960 --> 00:56:33.280]   >> Well, wait though. So tied to that though, we have a story about the- it's not the sponsored
[00:56:33.280 --> 00:56:38.880]   tag, the controversial tag, not actually helping on Facebook. And I'm wondering if what you're
[00:56:38.880 --> 00:56:42.560]   proposing would have the same lack of effectiveness. I think it's a good idea.
[00:56:42.560 --> 00:56:43.040]   >> Well, it's a good idea.
[00:56:43.040 --> 00:56:49.120]   >> No, right. Let me answer that first. It's the disputed tag, which is the fact-checking thing.
[00:56:49.120 --> 00:56:53.920]   And here again, I'm going to criticize Facebook. That was a study, one study with
[00:56:54.480 --> 00:57:03.600]   interviews outside of Facebook saying that the fact-checker dispute only affects a certain amount of
[00:57:03.600 --> 00:57:09.120]   attitude towards something that's disputed. And if it's ideological,
[00:57:09.120 --> 00:57:12.320]   or the other, it could actually make the spray never worse.
[00:57:12.320 --> 00:57:17.920]   The problem here too is that Facebook is not being transparent about this.
[00:57:17.920 --> 00:57:21.920]   And journalists are asking Facebook because journalists are helping with the fact-checking,
[00:57:21.920 --> 00:57:26.240]   would you please give us the data on this? That's complicated to this extent.
[00:57:26.240 --> 00:57:32.560]   When the disputed tag comes up on Facebook, Facebook itself reacts to that.
[00:57:32.560 --> 00:57:36.720]   They think that they don't promote stuff that's been disputed now because they don't
[00:57:36.720 --> 00:57:40.080]   want to be accused of pushing what is seen clearly as fake.
[00:57:40.080 --> 00:57:46.400]   So you can't separate the user behavior, the impact on the user behavior, from the impact
[00:57:46.400 --> 00:57:50.720]   on Facebook's algorithm. Nonetheless, in both these cases, Facebook should be open. So the
[00:57:50.720 --> 00:57:56.000]   difference between that Stacy and the political ads is that's not about trying to expose the
[00:57:56.000 --> 00:58:01.440]   political ad to the user. It's about exposing this set of political ads and their targeting
[00:58:01.440 --> 00:58:07.200]   criteria to researchers and media so we can understand what did the rescues do and how did they do it?
[00:58:07.200 --> 00:58:12.400]   Who did they go after with what and what impact that they had? So that's more for researchers
[00:58:12.400 --> 00:58:17.760]   than it is for the end user. But both cases are about being transparent.
[00:58:17.760 --> 00:58:21.600]   And you're rightly, "Oh, if this kind of stuff is going to go around, it would only be wise of
[00:58:21.600 --> 00:58:26.160]   them to say, let's go over, head over heels to be transparent, to be open, to get the help of
[00:58:26.160 --> 00:58:28.640]   researchers, to figure out what's going on here and do something about it."
[00:58:28.640 --> 00:58:39.760]   Now, how does this tie into the Bodega? So it's the Bodega story is it's about,
[00:58:39.760 --> 00:58:45.360]   and by the way, our friend, Steve Avadianathan, has the great hashtag on this one, the Brodega.
[00:58:46.640 --> 00:58:48.640]   That's exactly what it is.
[00:58:48.640 --> 00:58:51.120]   It's the Silicon Valley Adage. You want to explain the story first?
[00:58:51.120 --> 00:58:59.200]   Yeah. So a couple of former Googlers have created a very interesting product. It's a locked box,
[00:58:59.200 --> 00:59:04.800]   display box that goes in your apartment or other public place, maybe your business.
[00:59:04.800 --> 00:59:08.400]   You unlock it with your phone and take what you want.
[00:59:08.400 --> 00:59:10.560]   They say he would have this at a home, but no one else would.
[00:59:10.560 --> 00:59:16.240]   There's no human here. It's just like that Amazon store that knows who you are and knows
[00:59:16.240 --> 00:59:20.160]   with cameras and sensors, what you've purchased and charges your phone automatically.
[00:59:20.160 --> 00:59:25.120]   And you walk away, the thing locks itself back up. It is a corner store without any employees.
[00:59:25.120 --> 00:59:35.280]   And this is a startup. And they call it Bodega because it will replace all the little Bodegas
[00:59:35.280 --> 00:59:39.040]   in New York City. I don't know if it will or won't, but it's certainly not going to have the range
[00:59:39.040 --> 00:59:45.840]   of products. So this set off a firestorm of people saying of Brodega jokes,
[00:59:45.840 --> 00:59:54.640]   there's a Josh Marsh tweet. I actually appreciate the douchebags who rolled out the let's end
[00:59:54.640 --> 00:59:58.720]   Bodega's idea. The burgeoning tech backlash needed this moment of douchebaggery.
[00:59:58.720 --> 01:00:03.520]   Well, wait a minute, though, should an entrepreneur worry about that kind of thing?
[01:00:03.520 --> 01:00:10.240]   I mean, yeah, I think so because because it shows the hotiness, the separation from reality of real
[01:00:10.240 --> 01:00:13.440]   life of Silicon Valley employees. Now, then,
[01:00:13.440 --> 01:00:19.040]   wait a minute, what if it's a better way to serve people and be sensitive about how you do it,
[01:00:19.040 --> 01:00:23.760]   find a way that makes it. Should Uber not attempt to replace cab drivers because of the poor cab
[01:00:23.760 --> 01:00:28.640]   drivers? They should figure out what the impact is and have something some guy disagree entirely.
[01:00:28.640 --> 01:00:35.440]   Yeah, I'm going to disagree with you there. I'm going to do. I think these guys were tone deaf
[01:00:35.440 --> 01:00:39.040]   and naming their company Bodega. Probably shouldn't have named it Bodega.
[01:00:39.680 --> 01:00:43.360]   That's the key. They could have just call it the stuff box or something.
[01:00:43.360 --> 01:00:47.040]   They could have called it Vending 2.0. Yeah. And nobody would have complained.
[01:00:47.040 --> 01:00:50.320]   It's just a vending machine, a vending machine. So then they wrote a post
[01:00:50.320 --> 01:00:56.160]   trying to walk back as fast as they could. But all it does is it showed the
[01:00:56.160 --> 01:01:03.920]   attitude in Silicon Valley and it showed the cluelessness as to the current atmosphere
[01:01:03.920 --> 01:01:05.600]   which Ben Smith wrote about. That's why. That's why.
[01:01:05.600 --> 01:01:09.200]   Either way, they maybe even took it a step further because I guess there's a meme called
[01:01:09.200 --> 01:01:15.280]   Bodega cats about cats that sleep in Bodegas and they took the Bodega cat as their logo
[01:01:15.280 --> 01:01:21.520]   which probably had an insult to injury. Well, okay, hold on guys because I think there's some
[01:01:21.520 --> 01:01:28.400]   blame to be had here too. The media like flipped out on this one in the fast company articles.
[01:01:28.400 --> 01:01:33.760]   The one didn't the fast company article actually suggest that this was going to in the headline
[01:01:33.760 --> 01:01:38.320]   replace Bodega. Yeah, it says it will make them obsolete. That's not necessarily what these guys
[01:01:38.320 --> 01:01:45.920]   were planning, right? So let's talk about that. One, a lot of salary was from this headline which
[01:01:45.920 --> 01:01:54.640]   totally fine. These guys in their walk back. Again, they're like, we talked to some people
[01:01:54.640 --> 01:01:59.200]   in New York and we had branding firms and I'm like, yeah, but did you talk to the right people?
[01:01:59.200 --> 01:02:06.160]   Probably not. And I get it in totally tone deaf. But this is like a tempest in a freaking teapot,
[01:02:06.160 --> 01:02:10.240]   you guys. This startup may not even be around in six months. It's not that freaking innovative.
[01:02:10.240 --> 01:02:18.640]   Let's joust at something real. So I like your point about media and I just put up something on
[01:02:18.640 --> 01:02:22.640]   the rundown at the bottom of the of the other, which I think demonstrates your point.
[01:02:22.640 --> 01:02:30.160]   Excellently how fake news is created. Parker Malloy put up a Twitter thread that Jennifer Lawrence
[01:02:30.160 --> 01:02:36.480]   allegedly said that hurricanes are punishment for electing Trump. And this spreads around,
[01:02:36.480 --> 01:02:42.240]   you see the first the daily wire, you see it on Alex Jones, you see it everywhere, you see CNN
[01:02:42.240 --> 01:02:49.200]   right about it. You go to the next tweet, Leo. She didn't say that at all. Not at all. But it
[01:02:49.200 --> 01:02:54.560]   takes on a life of its own media get used. They go for the clicks. They're the chumps. The bad
[01:02:54.560 --> 01:02:59.920]   guys put this into the agenda. And now poor Jennifer Lawrence is acting like there's a war
[01:03:00.800 --> 01:03:05.760]   over this when there's not it does not pay in the public eye anymore.
[01:03:05.760 --> 01:03:13.120]   Cheese Louise, you just just if anybody is considering at this point being famous, don't.
[01:03:13.120 --> 01:03:18.560]   Just don't. It's not all that it's cracked. Well, it's not going to get better either.
[01:03:18.560 --> 01:03:23.600]   I in what what people remember is still a lot of times the fake news. I mean, look at,
[01:03:23.600 --> 01:03:30.080]   look at everybody in our poor Al Gore and inventing the Internet. I know. So this is it's not new.
[01:03:30.080 --> 01:03:34.240]   It spreads faster. You can do it easier. You can make up just about anything and.
[01:03:34.240 --> 01:03:41.680]   And the Bodega guys have apologized. Yes. Yeah, I still again, they're idiots, but
[01:03:41.680 --> 01:03:45.680]   God, y'all bless. I don't even know that they're idiots. I think that sounds like a pretty good idea.
[01:03:45.680 --> 01:03:50.080]   It's not that new. Facebook has had this and a vending machine.
[01:03:52.080 --> 01:03:55.120]   I'm like, I feel like in Japan, you could probably walk up to.
[01:03:55.120 --> 01:04:01.600]   And I'm sure there's some supply chain management and optimization and they can grab like bizarrely
[01:04:01.600 --> 01:04:08.560]   esque algorithms. Who went throwing eggs at the Google bus? People in gentrified neighbors in
[01:04:08.560 --> 01:04:12.560]   Hebrews and San Francisco where Bodegas were going away getting replaced by Starbucks.
[01:04:12.560 --> 01:04:18.240]   It doesn't take a genius to say, hmm, we're going to have a public relationship here.
[01:04:18.240 --> 01:04:25.120]   What should that relationship look like? What should we be sensitive to? In an age when jobs
[01:04:25.120 --> 01:04:27.760]   are going to be eliminated, when we know most retail jobs are going to be eliminated, we're
[01:04:27.760 --> 01:04:31.440]   going to come out with this. What should we? How should we position this? What should we call it?
[01:04:31.440 --> 01:04:35.360]   Let's call it little Spanish guy down at the corner who's going to be jobless and poor soon
[01:04:35.360 --> 01:04:40.720]   and deported by the president. And we don't care because we're Googlers. That's it's just dumb.
[01:04:40.720 --> 01:04:47.760]   That's all. Well, and it really all it was is just a total lack of awareness of the outside world
[01:04:47.760 --> 01:04:52.320]   and everybody's mad at Silicon Valley for that. Anyway, exactly. That's my only point. That is
[01:04:52.320 --> 01:04:58.720]   my only point. All right. All right. I just it's the media.
[01:04:58.720 --> 01:05:10.560]   This is so good. It's a vacation. I do. I need a vacation. The landscape. The media landscape
[01:05:10.560 --> 01:05:20.080]   is so broken. And people are just I mean, this is none of this makes any sense or anything. It's
[01:05:20.080 --> 01:05:25.520]   just in Jennifer Lawrence and Bodega's. There's a very similar thread here. It's just a bunch.
[01:05:25.520 --> 01:05:31.760]   And it's I blame Twitter, but it's not just Twitter, although Twitter is definitely helping.
[01:05:31.760 --> 01:05:36.160]   Well, this is this is this is my point about the Franklin four piece. Did you see that one?
[01:05:36.160 --> 01:05:39.120]   No, what's that? Franklin four wrote it were an absolute
[01:05:39.120 --> 01:05:44.880]   screed against technology. And it was excerpt from the Washington Post. And then I did, as we
[01:05:44.880 --> 01:05:52.640]   used to call it a fisking in in in in in blog days, it's on the rundown where it's just it was
[01:05:52.640 --> 01:05:57.120]   amazing because it's a technology is going to take away our individuality. And I thought, how
[01:05:57.120 --> 01:06:03.680]   unself where can you be mass media never gave us individuality? It never never. He's got a book
[01:06:03.680 --> 01:06:11.200]   called world without mind. That kind of crap, right? I think it let us ignore like it let us create
[01:06:11.200 --> 01:06:16.720]   our own individuality without being having things shoved in our face. I just want to say we did it
[01:06:16.720 --> 01:06:22.800]   to ourselves. We did it to ourselves. This is not there's no blame here. This is the environment
[01:06:22.800 --> 01:06:30.400]   we've created. We did it. That's a radio head song. Oh, well, you do you do you do you do you
[01:06:30.400 --> 01:06:36.880]   do you know what else I can't sing? I'm sorry. It's it's easy to blame Twitter or Google or
[01:06:36.880 --> 01:06:42.480]   like it. Try Reddit or 4chan. But really this is this is the world we've all created.
[01:06:42.480 --> 01:06:50.560]   I mean, I blame 24 hour the 20 hour four hour news channel. Absolutely. I blame Sean Hannity.
[01:06:50.560 --> 01:06:54.160]   I blame a mass me. Irma. I blame. It's all.
[01:06:56.160 --> 01:07:02.560]   I just makes me want to move to the wilderness with her and and Leo Leo you would not last
[01:07:02.560 --> 01:07:07.360]   20 seconds in the wilderness. But I have a note eight. I could probably figure it out.
[01:07:07.360 --> 01:07:12.640]   So I'm going to give you the note eight. It's too big. You cannot carry it in your pocket like
[01:07:12.640 --> 01:07:16.800]   that. It disrupts the line of your suit. It pops up like an ugly handkerchief. What if I put it
[01:07:16.800 --> 01:07:20.720]   what if I put it here? That's just because I'm lazy. See now it's in my breasts pocket.
[01:07:21.440 --> 01:07:27.040]   I'd have your jackets going to be on it. Well, I was going to hang it around my neck. How
[01:07:27.040 --> 01:07:31.600]   about that with a little pendant? No, no. Who wasn't one of the anchors down in
[01:07:31.600 --> 01:07:35.920]   the. You may just suspend your whole order. They put a baggie in the phone in a baggie. I think
[01:07:35.920 --> 01:07:41.440]   it was I think with Leonard Holt Leonard. Not Leonard Holt Lester Holt. That's Sir Holt. I think he had
[01:07:41.440 --> 01:07:47.280]   his phone in a baggie, which was better than the MSNBC reporter who tied himself to a building.
[01:07:47.280 --> 01:07:51.760]   I saw that picture you tweeted so that he wouldn't get washed away in Irma.
[01:07:51.760 --> 01:07:56.000]   Every time I saw somebody doing a stand up in the storm, I thought of you, Jeff, every single time.
[01:07:56.000 --> 01:08:02.400]   Screaming. But you know, I think. I think the ratings if he got washed away. Well,
[01:08:02.400 --> 01:08:07.600]   but I think the. Is this bottle at all goes back to the business model? Exactly. Stacey.
[01:08:07.600 --> 01:08:11.600]   And there's a Cooper explained it though. And there's a Cooper standing there. He's soggy. He's
[01:08:11.600 --> 01:08:17.040]   wet. He explained it. He said, we go out here so you can see what it's like. So you don't have to
[01:08:17.040 --> 01:08:22.960]   go out here and risk your necks. The trees will tell the story. It's windy. It's very. But it's
[01:08:22.960 --> 01:08:27.520]   better for a person staying there almost and he's tethered and he's almost dead. It's crap.
[01:08:27.520 --> 01:08:31.760]   Self justification for ratings. Although I will say I want some.
[01:08:32.160 --> 01:08:37.840]   Roadégas and it's all ratings. Yes. We have created.
[01:08:37.840 --> 01:08:44.400]   And a perfect feedback loop where we tell them what we want and they give us what we want. And
[01:08:44.400 --> 01:08:49.760]   then we want more of it. And they give us. We are rats in a Skinner box hitting the pellet button
[01:08:49.760 --> 01:08:53.440]   over and over again. We did it to ourselves. They did to us. It's this feedback loop.
[01:08:53.440 --> 01:08:58.400]   This is it. That's all there is. There's no Edward R. Maro to say, well, we need a division
[01:08:58.400 --> 01:09:03.600]   where we don't make any money. Edward R. Burrow, by the way, was the first guy to go stand in the
[01:09:03.600 --> 01:09:06.880]   seriously was the first guy to go stand in London. Yeah.
[01:09:06.880 --> 01:09:12.320]   No, he has to be also in a hurricane in a hurricane. Well, that's because.
[01:09:12.320 --> 01:09:18.480]   Well, I mean, here's the here's the challenge, right? We can talk about business. All models,
[01:09:18.480 --> 01:09:21.920]   all we want and blame the business guys. But at the same time as a journalist,
[01:09:21.920 --> 01:09:27.840]   I do want someone to read my story. If I if I'm actually going out and reporting on something
[01:09:27.840 --> 01:09:33.280]   really important, I may feel cheap to get like, I call I call them dead babies, but
[01:09:33.280 --> 01:09:37.760]   because dead babies sell newspapers and get people to read these stories that are otherwise
[01:09:37.760 --> 01:09:42.640]   really difficult and boring. But you have to go out and find those as much as it may be awful,
[01:09:42.640 --> 01:09:45.520]   because otherwise people aren't going to read it and they're not going to know the information
[01:09:45.520 --> 01:09:52.480]   they need. Healthcare is a really good example of this. Storms warning and trying to convey.
[01:09:52.480 --> 01:09:57.040]   Nobody's doing that. Nobody cares. That's not true. There are people who do that.
[01:09:57.040 --> 01:10:00.960]   Okay, but they're getting to be fewer and fewer because the people are most successful of the
[01:10:00.960 --> 01:10:06.320]   ones who don't worry about putting any nutrition in your Wheaties. They just say put more sugar in
[01:10:06.320 --> 01:10:12.800]   the Wheaties. I think we just have more crap to wade through. I mean, there's always been a finite
[01:10:12.800 --> 01:10:20.080]   supply of really good investigative journalism. I mean, it's not like that is that is very much
[01:10:20.080 --> 01:10:26.240]   a calling that is very much so. And so in that still exists, we're just, it's so much easier to
[01:10:26.240 --> 01:10:31.440]   throw crap at things now. So we're doing that too. And it just buries the good stuff. I really,
[01:10:31.440 --> 01:10:35.440]   I really do think that there's still plenty of really good reporting out there.
[01:10:35.440 --> 01:10:38.480]   I just think it's buried in.
[01:10:38.480 --> 01:10:47.440]   Yeah, what do we reward? We don't reward the really good reporting. We reward the
[01:10:48.960 --> 01:10:56.000]   cats and the and they people do reward good reporting. Do people say that? Yes, you just,
[01:10:56.000 --> 01:11:03.040]   you're not going to get PC rewarded. I feel like I'm doing good reporting and I'm making money.
[01:11:03.040 --> 01:11:08.000]   I'm not going to make it's a lifestyle for me. It is not going to make me rich, but
[01:11:08.000 --> 01:11:11.360]   I'm doing what I love and I'm explaining it. And there's an audience of people who,
[01:11:11.360 --> 01:11:16.320]   if I read this paper on foldable electronics and explain to them and plain English what this
[01:11:16.320 --> 01:11:20.720]   means and how it might change the world, they'll listen to it. I agree. And that's all that.
[01:11:20.720 --> 01:11:24.640]   Twit was always about that. It was trying to give people real information to be of value to them,
[01:11:24.640 --> 01:11:29.520]   not trying to be the most successful enterprise out there. That's why we never took venture capital
[01:11:29.520 --> 01:11:33.600]   because I didn't want anybody to tell me that we had to have more cleavage on the show or whatever.
[01:11:33.600 --> 01:11:39.520]   But that's not it's no way to rich riches. And then we don't and as a result Stacey,
[01:11:39.520 --> 01:11:43.520]   you probably would acknowledge we don't reach the largest possible audience by any means.
[01:11:44.560 --> 01:11:47.280]   But you're a higher value audience. Well, that's the hope.
[01:11:47.280 --> 01:11:52.320]   Yeah, it's somewhat higher value, but frankly, good year is never going to advertise and twit.
[01:11:52.320 --> 01:12:00.480]   I mean, you know, the big bucks are still going to NFL and I don't know. Maybe I'm just being a
[01:12:00.480 --> 01:12:07.280]   depressive cranky old man, but I think we are in it. And it's our biology, by the way,
[01:12:07.280 --> 01:12:11.200]   that is determining this. I mean, it's clearly what our brains were designed to, you know,
[01:12:11.200 --> 01:12:15.520]   collect gossip. No, I don't think so. Oh, come on. It is evolutionary biology.
[01:12:15.520 --> 01:12:20.320]   We have we have parts that we all have those parts of us, right? I mean, I look at cat videos,
[01:12:20.320 --> 01:12:25.200]   Ted Cruz looks at porn. And we all that story, by the way, did he what happened there? Because I
[01:12:25.200 --> 01:12:31.280]   keep seeing I keep seeing people refer to it. Well, staff. Yeah, yeah, yeah. So he said,
[01:12:31.280 --> 01:12:36.640]   Ted Cruz's official Twitter account liked a porn tweet. Right. I didn't know there was porn on
[01:12:36.640 --> 01:12:40.960]   Twitter. Oh my God, there's so much porn on Twitter. I did not know this was a thing.
[01:12:41.840 --> 01:12:46.880]   I felt like I felt there's a character in the video who while still dressed, it's supposed to be
[01:12:46.880 --> 01:12:51.360]   somebody stupid and somebody and she's related to somebody and she's watching. So the one who's
[01:12:51.360 --> 01:12:58.720]   not stupid at the moment is has this great shot look thing. And that's turning into the greatest
[01:12:58.720 --> 01:13:05.440]   gift. And so but and so Cruz's excuse was, Oh, it wasn't me. It was my staffer. Yeah, some poor
[01:13:05.440 --> 01:13:10.560]   staffers from the porn bus. It's really easy to buy accident like a tweet, by the way, you can I do
[01:13:10.560 --> 01:13:14.320]   it all the time. You know, you accidentally because I'm I'm the last to see it first.
[01:13:14.320 --> 01:13:19.600]   Leo. That's a good point. You have to be following it. Yeah. Yeah. But you could search for,
[01:13:19.600 --> 01:13:25.840]   you know, incest videos and get that by accident. Why would you be searching for incest videos?
[01:13:25.840 --> 01:13:35.360]   Like it happens. Look, look, Leo, there's me who literally had no idea there was porn on Twitter.
[01:13:35.360 --> 01:13:38.800]   Well, you're such a good girl.
[01:13:38.800 --> 01:13:41.640]   There's lots of other Twitter. There's there's so many
[01:13:41.640 --> 01:13:45.040]   Twitter's that's one of the most interesting things. My favorite Twitter is black Twitter is
[01:13:45.040 --> 01:13:49.680]   a fabulous, it's fabulous. It's the best Twitter of all.
[01:13:49.680 --> 01:13:56.640]   But I think that is one of the most interesting things about Twitter, isn't it? The subculture.
[01:13:56.640 --> 01:14:03.840]   Oh, you want some good news, Leo? Yeah, you better because I'm getting depressed.
[01:14:04.720 --> 01:14:11.040]   Google backs the Oxford comma. I call that great news. Who doesn't so mad? Who doesn't
[01:14:11.040 --> 01:14:16.880]   back the Oxford comma? What? Stay. No, this. Okay. Okay.
[01:14:16.880 --> 01:14:25.920]   Now I'm shocked. I feel that any writer is you can tell when you need an Oxford comma. I know
[01:14:25.920 --> 01:14:29.440]   people are always giving the same. That's true. You could tell when you need it. You could tell
[01:14:29.440 --> 01:14:34.560]   when the rest of time shoots the purple leaves would be confusing. Oh, you use it consistently.
[01:14:34.560 --> 01:14:39.920]   That's the point of grammar so that you know the meaning. No, I think no Stacy's a more modern.
[01:14:39.920 --> 01:14:44.000]   I understand what you're saying, Stacy. You're saying you don't have to follow the rules. You
[01:14:44.000 --> 01:14:49.040]   have to be clear. You have to be unambiguous. You have to try. Yeah, that's all. That's your
[01:14:49.040 --> 01:14:53.680]   only obligation. Stacy's ruling the language. That's what she's doing. I am single-handedly.
[01:14:54.240 --> 01:15:00.640]   I literally. I would just point out Stacy that it is easier to always use it than to try to look
[01:15:00.640 --> 01:15:08.240]   at every sentence and say, you know, would this be confusing? And so my editors will tell you that
[01:15:08.240 --> 01:15:14.800]   my comma abilities are terrible. I think one of them was like, I like how you go in after you've
[01:15:14.800 --> 01:15:20.480]   written something and clearly just sprinkle commas. I had a Latin teacher call that comma
[01:15:20.480 --> 01:15:27.920]   blunder. You're a comma blunderer. I am. I'm like, oh, you know, that feels like a natural place to
[01:15:27.920 --> 01:15:33.920]   take a breath. It is actually a really interesting art to know when to and when not to use commas.
[01:15:33.920 --> 01:15:39.280]   And I would say in general use fewer, not more commas. My weakness is I use too many
[01:15:39.280 --> 01:15:43.680]   of my goals. So the Oxford comma for people who are baffled and would like to be enlightened on
[01:15:43.680 --> 01:15:51.600]   the most important. The medical rule is when you have three or more things in a series,
[01:15:51.600 --> 01:15:59.040]   like each, let's see, one, two, and three, let's make it easy. You put a comma after each item in
[01:15:59.040 --> 01:16:05.600]   the series, including the one before the end, one comma, two comma, and three. If you don't,
[01:16:05.600 --> 01:16:10.720]   it could look like one comma, two and three. It could look like two items in the series instead of
[01:16:10.720 --> 01:16:16.240]   three. That's usually obvious that is one, two, and three, not one, two, and three.
[01:16:16.240 --> 01:16:22.320]   And but what Stacy's saying is when it isn't clear, you should put a comma in. What Jeff's saying is
[01:16:22.320 --> 01:16:28.080]   you should always put a comma in to avoid and be not recommended. I dedicate this books to my book
[01:16:28.080 --> 01:16:34.000]   to my parents, comma, and ran and God as opposed to I dedicate this book to my parents, comma, and
[01:16:34.000 --> 01:16:39.760]   ran to comma and God. Now, where did Google weigh in on this? And the is in the register there.
[01:16:39.760 --> 01:16:44.720]   They basically have a developer documentation guide. Now there's something here relevant to Stacy.
[01:16:44.720 --> 01:16:52.400]   So internet is now lowercase as it should be because it is just part of the lowercase until
[01:16:52.400 --> 01:16:59.440]   Microsoft Word kept telling me it's uppercase. I make a lowercase of cases. However, internet of
[01:16:59.440 --> 01:17:09.360]   things, the I T are uppercase so that you can get the abbreviation I O T. Who gets who uses Google
[01:17:09.360 --> 01:17:15.600]   for their English style guides. So the AP style guide did they lower it didn't AP lowercase
[01:17:15.600 --> 01:17:23.120]   internet many, many moons ago. I mean, maybe also did not already did it earlier. And then
[01:17:23.120 --> 01:17:28.640]   there's email one word email with a dash between the E and the M. There's a lot of these.
[01:17:28.640 --> 01:17:33.920]   Who invented it? And then there's who invented it. Yes. I invented email in high school. Many
[01:17:33.920 --> 01:17:41.680]   people don't know that. I did know that the word jank. As in janky?
[01:17:41.680 --> 01:17:48.400]   As in blocking a software applications user interface due to slow operations or poor interface
[01:17:48.400 --> 01:17:52.880]   design. Google says it should be used with care.
[01:17:55.200 --> 01:18:03.920]   This is learning. No, you know why? Because a lot of a lot of developers will use this kind of
[01:18:03.920 --> 01:18:09.440]   slangy descriptions instead of something more precise. That's all.
[01:18:09.440 --> 01:18:16.160]   Log in. It doesn't work. Sign in is the preferred verb. Log in is not a verb.
[01:18:16.160 --> 01:18:20.080]   And whenever you do, don't use the word learnings.
[01:18:22.000 --> 01:18:26.800]   And by the way, do not use Google as a verb. You cannot Google something. You can search with
[01:18:26.800 --> 01:18:33.920]   Google, but you may not Google it. How about how about do not capitalize? No, not. Oh, never
[01:18:33.920 --> 01:18:39.920]   mind. I'm right. Oh, so I'm saying, how do we pronounce cash? It's cash. Now, is this for written
[01:18:39.920 --> 01:18:45.360]   or spoken word? This is written. This is the developer documentation guide here. Oh, okay.
[01:18:45.360 --> 01:18:51.760]   Now, the other one I like is interface. Similarly, is not a verb. That's right. Damn straight.
[01:18:51.760 --> 01:18:56.560]   That's true. In partner is not a verb. Talk, speak, no, partner is a noun, not a verb.
[01:18:56.560 --> 01:19:02.960]   All these people for verbalizing. You know, this probably wouldn't
[01:19:02.960 --> 01:19:10.160]   happen except this guide from Google, except they probably see so many god awful. Oh, you can
[01:19:10.160 --> 01:19:15.840]   imagine. It must be horrible looking. So yeah, this is the Google developer documentation style
[01:19:15.840 --> 01:19:22.720]   guide. It has goals and non goals. You go forward to it. It doesn't apply to all Google documentation.
[01:19:22.720 --> 01:19:28.800]   Oh, yeah. Yeah. So I guess you can use the not Oxford, the Stacey comma as I'll call it in the
[01:19:28.800 --> 01:19:36.000]   future elsewhere. By the way, this is an example of an article. No normal person cares about in the
[01:19:36.000 --> 01:19:40.960]   least. We're talking about it. That's my fault. But it's written by a journalist whose stock in
[01:19:40.960 --> 01:19:46.960]   trade is whether to put a comma after the second item serial or not. Oh, yeah. If you want to see
[01:19:46.960 --> 01:19:54.400]   like our Slack channel, if the Oxford comma was mentioned anywhere. Yes. Only journalists. Actually,
[01:19:54.400 --> 01:20:01.760]   journalists and people who care about grammar. I don't. I mean, I've had arguments with non
[01:20:01.760 --> 01:20:05.200]   journalists about this. I'm a bit of a grammar. Grammar. I really dig into this. This is fun for
[01:20:05.200 --> 01:20:10.640]   developers. So I go to the anthropomorphism link on the developer documentation style guide,
[01:20:10.640 --> 01:20:18.320]   not recommended the PCC is a new device recommended the PC detects a new device.
[01:20:18.320 --> 01:20:25.280]   Oh, screw that. It's I think you could say sees. I don't have a problem with that. That's
[01:20:25.280 --> 01:20:31.600]   interesting that they'd take the source to do that. That's kind of fun. I wear it. Did you put a
[01:20:31.600 --> 01:20:36.000]   link in there? I want to see this to the Google open source blog, making the Google developers
[01:20:36.000 --> 01:20:42.000]   documentation stock guide public. You can now use it for open source documentation projects.
[01:20:42.000 --> 01:20:50.240]   It's developers dash I'm sorry developers dot Google dot com slash style. Nice. Yeah. But I still
[01:20:50.240 --> 01:20:57.680]   would stick with the AP style guide. Okay. I'm actually okay with that. And they even quote George
[01:20:57.680 --> 01:21:03.520]   Orwell saying break any of these rules sooner than say anything outright barbers.
[01:21:03.520 --> 01:21:13.760]   Here's one. There's a word list abort. Don't use instead use words like stop exit cancel.
[01:21:13.760 --> 01:21:20.880]   Oh, that's that's political. That's not. Yeah. That's access as a verb. Avoid when you can
[01:21:20.880 --> 01:21:25.520]   in favor of friendlier words like see edit find use or view. I couldn't
[01:21:25.520 --> 01:21:31.120]   remember that. Yeah. But access has a particular meaning in computer talk. I don't care. It's not
[01:21:31.120 --> 01:21:36.080]   English. Technical writing is a little bit different than writing prose, you know, standard.
[01:21:36.080 --> 01:21:38.000]   Well, that's what academics say too. And they're wrong.
[01:21:38.000 --> 01:21:46.320]   Yeah, it's true that disciplines often become jargonized. And that's not a good thing because
[01:21:46.320 --> 01:21:52.080]   it kind of limits their audience. So I'll agree with you on that. But if frankly, if it's not
[01:21:52.080 --> 01:21:56.560]   in drunken white, I just chew it. Now, why would it say don't use applications?
[01:21:56.560 --> 01:22:01.360]   How do you say it? It's true. That's how I say it. Oh, I always thought it was a shoe.
[01:22:01.360 --> 01:22:03.280]   How do you say it, Carson? You went to Harvard.
[01:22:03.280 --> 01:22:10.160]   Well, you're both wrong. It's as tube. Just look it up in the dictionary.
[01:22:10.160 --> 01:22:15.840]   Okay. I mean, I know. So I got it right here. Look, he just doesn't want to show it.
[01:22:15.840 --> 01:22:21.440]   That's pronounced a shoe. A shoe. That's wrong. Look it. Look it.
[01:22:21.440 --> 01:22:22.720]   Wait, no, I know.
[01:22:22.720 --> 01:22:24.640]   Here, play my audio.
[01:22:24.640 --> 01:22:29.680]   It's true. It's true. It's true.
[01:22:29.680 --> 01:22:32.960]   Oh, okay. Go go. How do you pronounce a shoe?
[01:22:32.960 --> 01:22:36.800]   Don't ask her that. Now make it pronounced cuneiform.
[01:22:36.800 --> 01:22:40.320]   Yeah. Okay. So we had this debate. So I'm listening to this book.
[01:22:40.320 --> 01:22:43.600]   Now, what do you think, Carson, on the cuneiform?
[01:22:43.600 --> 01:22:44.640]   It's cuneiform.
[01:22:44.640 --> 01:22:46.880]   Is it really? Because I've always said cuneiform.
[01:22:47.840 --> 01:22:52.720]   There isn't an E in there. Yeah, but it comes from the Latin word cuneous, mean wedge.
[01:22:52.720 --> 01:23:02.080]   And look in this dictionary, cuneiform, three syllables, cuneiform, cuneiform,
[01:23:02.080 --> 01:23:05.120]   all three are acceptable. Cuneiform.
[01:23:05.120 --> 01:23:07.520]   Okay. Cuneiform.
[01:23:07.520 --> 01:23:11.280]   However, this came up because I'm listening to a book where the guy for a whole chapter says
[01:23:11.280 --> 01:23:16.080]   cuneiform. And it's driving me nuts, but it's a Britishism. I think cuneiform is preferred in Britain.
[01:23:16.080 --> 01:23:19.840]   And it's certainly acceptable. Like aluminium. It's certainly acceptable.
[01:23:19.840 --> 01:23:26.000]   But it does come from the Latin cuneous, which via the French cuneiform.
[01:23:26.000 --> 01:23:32.400]   But I'm just saying it's interesting. No, Google goes for the singular day.
[01:23:32.400 --> 01:23:36.400]   Oh, that's interesting. That's very interesting given.
[01:23:36.400 --> 01:23:38.800]   That's how people pronounce things.
[01:23:38.800 --> 01:23:41.200]   No, no, this is a pronouns. You don't use the political.
[01:23:41.200 --> 01:23:44.320]   I know it's my pronouns are they, them and
[01:23:45.440 --> 01:23:49.200]   people like to view that as political, but that's also just how people talk.
[01:23:49.200 --> 01:23:56.160]   If you can't stand that says Google, then use he or she, or rewrite to avoid singular,
[01:23:56.160 --> 01:23:59.840]   gendered pronouns. So is English going to evolve? Because we don't.
[01:23:59.840 --> 01:24:02.160]   It's an evolving language. Yeah, we don't. Yeah. It's of course,
[01:24:02.160 --> 01:24:07.040]   it's not be like the French. Is it going to evolve to use them in place of he or she?
[01:24:07.040 --> 01:24:11.200]   It's like great character and billions. Yeah, my pronouns are they, them and they're.
[01:24:12.400 --> 01:24:15.200]   But when we went to Google, I know you were with me, weren't you?
[01:24:15.200 --> 01:24:22.080]   They had a sign at the registration. We care about your pronouns and stickers that you could
[01:24:22.080 --> 01:24:26.080]   put on your badge that whether you prefer to be a he or a she or a they.
[01:24:26.080 --> 01:24:33.520]   So I think that's fine. I don't, you know, I think it is unfortunate that the collective,
[01:24:33.520 --> 01:24:36.320]   you know, human noun is he.
[01:24:38.640 --> 01:24:43.600]   So I got, but I got in trouble with one of my former students because I used in, in my last book,
[01:24:43.600 --> 01:24:48.960]   I used the presumptive pronoun. I used female in all cases and I had an example of a user
[01:24:48.960 --> 01:24:52.960]   doing that. I would then say, I kind of like that because I think it's a. I can't remember
[01:24:52.960 --> 01:24:59.120]   exactly why I was in trouble, which is worse, but it's like a good fashion. You don't want to do
[01:24:59.120 --> 01:25:05.360]   something that draws the eye and using she draws the eye, right? Wrong.
[01:25:05.360 --> 01:25:14.080]   Wrong. Using she only draws the eye because we have lived forever with the assumption that
[01:25:14.080 --> 01:25:19.360]   anything we're doing is male. And it's her story, not his story. I grant you that.
[01:25:19.360 --> 01:25:27.440]   So it does draw the eye. It doesn't draw the eye. The point is like I use she all the time in my
[01:25:27.440 --> 01:25:33.840]   stuff and it no longer draws the eye unless you're an old misogynistic person who doesn't want to
[01:25:33.840 --> 01:25:41.280]   look at the world from that perspective. I'm just saying that. I take that personally.
[01:25:41.280 --> 01:25:45.440]   I feel very strongly about this. I think people who I'm with you. I'm like,
[01:25:45.440 --> 01:25:52.720]   and it's more than just a choice of words. It really does precondition the mind to think that
[01:25:52.720 --> 01:25:58.960]   all men are doctors are men and all nurses are women and all of that. And so I think it is important,
[01:25:58.960 --> 01:26:04.640]   but we have yet to come up with a felicitous solution because I think they is also.
[01:26:04.640 --> 01:26:12.880]   It's ugly to me. I'll get used to it. I rewrite sentences where possible where the plural fits.
[01:26:12.880 --> 01:26:20.960]   Or a good way around it, right? Yeah. That's a good way around. I use he or she, but I also will,
[01:26:20.960 --> 01:26:28.320]   if it's a case of I'm presuming a person. So I'm not using it as a nonspecific. I have a person.
[01:26:28.320 --> 01:26:32.240]   I presume that person is a woman. By the way, it lasts one exception, one exception,
[01:26:32.240 --> 01:26:37.760]   important exception when discussing trolls. They're always he. They are he.
[01:26:37.760 --> 01:26:42.240]   Or just trolls or trolls, right? Yes.
[01:26:42.240 --> 01:26:48.160]   Pronouns. They don't deserve a pronoun. Here's another funny one. Smart phone. Do not use.
[01:26:48.720 --> 01:26:52.800]   Instead use mobile phone or phone. That's Eurocentric and it bothers me.
[01:26:52.800 --> 01:26:58.480]   It's also Apple. Because we call them cell phones in the States and they call them
[01:26:58.480 --> 01:27:02.240]   mobiles everywhere else. Handies and German or handies. Yeah.
[01:27:02.240 --> 01:27:08.640]   That's why I like this show because we really drift very far.
[01:27:08.640 --> 01:27:14.000]   We've so the audience drifted away. They've drifted to sleep. We're engaged.
[01:27:14.000 --> 01:27:20.080]   One more. Wallach. Don't use. Don't use Wallach. Don't use Wallach.
[01:27:20.080 --> 01:27:22.640]   It's so fun. Wallach.
[01:27:22.640 --> 01:27:24.240]   Oh, yeah. Do they say anything about y'all?
[01:27:24.240 --> 01:27:30.960]   I don't think so. My phone probably, my application is probably if they say,
[01:27:30.960 --> 01:27:32.560]   I'd be like, don't even.
[01:27:32.560 --> 01:27:35.760]   Wail young Sheldon takes off. Everybody gon be talking like this.
[01:27:35.760 --> 01:27:39.840]   It's, you know, he doesn't have an accent. Isn't that interesting?
[01:27:39.840 --> 01:27:43.520]   They all do. It's because Southern accents are considered idiotic.
[01:27:43.520 --> 01:27:44.400]   Yep. They're Hicks.
[01:27:44.400 --> 01:27:48.960]   The people who want to say too. I noticed that's too Stacey. I was wondering if you saw it.
[01:27:48.960 --> 01:27:52.080]   Because I didn't want to bring it up because I didn't want to see your feelings be hurt.
[01:27:52.080 --> 01:27:54.800]   I don't have a Southern accent. I say y'all.
[01:27:54.800 --> 01:27:59.040]   Y'all. Unless I'm talking to someone with a Southern accent.
[01:27:59.040 --> 01:28:02.480]   How about ain't? I say it actually a lot.
[01:28:02.480 --> 01:28:05.520]   I don't. Only for first person.
[01:28:06.720 --> 01:28:12.400]   Ain't is actually a venerable construction was used by Shakespeare. I know.
[01:28:12.400 --> 01:28:15.200]   Still don't say it.
[01:28:15.200 --> 01:28:22.080]   Google's Material Design Awards are out. We'll talk about that in just a moment.
[01:28:22.080 --> 01:28:26.160]   I only say that to remind you of the subject matter of the show.
[01:28:26.160 --> 01:28:29.360]   And that we will. That was an exciting tease.
[01:28:29.360 --> 01:28:32.880]   I can't wait for that. Wow. Okay. Okay. I can do better.
[01:28:32.880 --> 01:28:35.920]   Grammar. I was like, I can do better.
[01:28:35.920 --> 01:28:40.160]   I can do better. Wait a minute.
[01:28:40.160 --> 01:28:41.840]   I don't need to make Asian people.
[01:28:41.840 --> 01:28:44.960]   Let's talk about Blueborn or something.
[01:28:44.960 --> 01:28:51.600]   Blueborn and why everybody uses Android should quickly up freak out.
[01:28:51.600 --> 01:28:56.640]   Freak out. Our show today brought to you by my doorbell. I don't have to freak out when I hear
[01:28:56.640 --> 01:29:01.680]   my doorbell ring. I know the ring video doorbell replaces your regular doorbell.
[01:29:01.680 --> 01:29:07.920]   Pairs to your internet has a camera HD camera on it. Microphone speaker and motion sensors.
[01:29:07.920 --> 01:29:12.160]   When anybody walks by your door and you get to set the area that it's looking at,
[01:29:12.160 --> 01:29:16.400]   it lets you know on your phone wherever you are. When somebody rings your doorbell,
[01:29:16.400 --> 01:29:19.360]   you hear a dong dong dong on your phone and you can answer it.
[01:29:19.360 --> 01:29:23.440]   You could say, I'm in the bath. Please go away or whatever.
[01:29:23.440 --> 01:29:28.240]   Do not burglar my house today. I am here. I am armed and I'm ready to shoot you.
[01:29:28.240 --> 01:29:32.640]   And that will work because bad guys don't want confrontations. They just go on to the other
[01:29:32.640 --> 01:29:37.040]   house. The house without the ring video doorbell. Now ring has expanded their line.
[01:29:37.040 --> 01:29:43.200]   They've got new doorbells and the new floodlight cam. It's a motion activated camera and floodlight.
[01:29:43.200 --> 01:29:47.120]   Same thing. Got a camera speaker, microphone, motion sensors.
[01:29:47.120 --> 01:29:51.440]   There's a few extra little things there. These floodlights go on when they detect motion.
[01:29:51.440 --> 01:29:57.040]   You could speak to the intruder in your yard, whether it be a raccoon or a burglar.
[01:29:57.680 --> 01:30:03.360]   And if it doesn't scare them off when you say, hey, what are you doing there?
[01:30:03.360 --> 01:30:10.480]   You can press a button and a 110 decibel alarm will flood their eardrums and they will tear
[01:30:10.480 --> 01:30:15.840]   off into the night. I love it. The Wall Street Journal's best of CES 2017.
[01:30:15.840 --> 01:30:21.200]   The ring video doorbell, the ring floodlight cams, the ring's a stick up cam.
[01:30:22.720 --> 01:30:28.560]   Go to right now ring.com/twig. You can save it to $150 off a Ring of Security kit. And if you
[01:30:28.560 --> 01:30:33.280]   already have a ring and I know most of you do, get one for family members, for friends,
[01:30:33.280 --> 01:30:43.600]   for parents, help them protect themselves. Ring.com/twig up to $150 off a Ring of Security kit.
[01:30:43.600 --> 01:30:47.920]   We thank Ring for their support of this week in Google.
[01:30:48.720 --> 01:30:54.960]   They had a massive booth at CDIA. I bet they did. They're big. What's great is they're taking
[01:30:54.960 --> 01:30:58.960]   the money and they're creating new products, which I love. Jamie's really a smart guy, I think.
[01:30:58.960 --> 01:31:04.800]   Like their alarm system? Oh, I didn't hear about that. Oh, yeah, they're going to have an alarm
[01:31:04.800 --> 01:31:09.520]   system. He actually, he advertised on my show for CDIA and he talked about it, but there's a
[01:31:09.520 --> 01:31:15.440]   lawsuit with ADT. They bought Zonoff a while back and the reason why is because they're
[01:31:15.440 --> 01:31:20.800]   building an alarm system. Oh, very public. How can ADT sue them?
[01:31:20.800 --> 01:31:28.240]   Because, oh God, it's so messy. You just don't even want to go there. So ADT, they're suing them
[01:31:28.240 --> 01:31:35.200]   because they hired everyone from a company that ADT invested in and they're alleging,
[01:31:35.200 --> 01:31:40.640]   I don't remember all the allegations. Yeah, I get it. Stealing stuff. Let's put it under
[01:31:40.640 --> 01:31:46.800]   the stealing stuff category. Stealing into innovation. So CDIA is the International Trade
[01:31:46.800 --> 01:31:55.280]   Association for, well, it used to be home theater installers, but it's expanded now to a lot more.
[01:31:55.280 --> 01:32:00.320]   It was a lot of IoT stuff. I guess that's why you went, right? That is why I went.
[01:32:00.320 --> 01:32:05.680]   Well, I know you like all theater installers. I mean, who doesn't? Well, yes, yes, they're
[01:32:05.680 --> 01:32:12.720]   lovely people. However, you probably went for things like Jamie Siminoff and people like that
[01:32:12.720 --> 01:32:18.400]   were there. So we did see anything interesting. You know, a couple things that are worth noting.
[01:32:18.400 --> 01:32:29.840]   First off, guys, I saw these gorgeous back-mounted OLED screens encased in glass. This is from LG.
[01:32:30.560 --> 01:32:36.160]   I think I put a picture. I think it's the picture actually under my podcast. Did that
[01:32:36.160 --> 01:32:40.560]   publish it? Yes, it did. The CDIA podcast that's up on my site. So you can see a picture of it
[01:32:40.560 --> 01:32:46.800]   because it's freaking gorgeous, but it's $20,000. So we're not going to get that into too soon.
[01:32:46.800 --> 01:32:54.800]   For her. She's gesturing. It's very big.
[01:32:55.760 --> 01:33:03.520]   It's large. That was Stacy's very big sound. You can see there's a guy kind of in the background.
[01:33:03.520 --> 01:33:12.240]   He's probably about three feet away. Sorry. Yeah. No, it's not seven feet tall. It's 18 feet tall.
[01:33:12.240 --> 01:33:20.480]   No, it's about, well, let's see. He's probably five feet tall. Yeah, I mean,
[01:33:21.040 --> 01:33:26.080]   because it's off the floor, I feel like when I looked at it, my eyes were a little like at her
[01:33:26.080 --> 01:33:30.720]   nose level. What makes that so special? Because it's gorgeous. Look how it's embedded in that glass.
[01:33:30.720 --> 01:33:36.560]   It's back to back. It's just a wonderful way of framing a television. So this is for high end
[01:33:36.560 --> 01:33:41.200]   and it's moving image. It's for display. It's for display high end retail display.
[01:33:41.200 --> 01:33:45.920]   But imagine that in landscape. I'd hang that, you know, on my wall. Well, there's some gorgeous
[01:33:45.920 --> 01:33:50.240]   TVs out there. I have to say. I have an LG 4K TV. I love it.
[01:33:51.200 --> 01:33:57.440]   But there were lots of really cool other things that I saw. A lot of energy management systems,
[01:33:57.440 --> 01:34:03.840]   that's really getting hot, which is kind of exciting. Things that let you plug your generator,
[01:34:03.840 --> 01:34:08.560]   plug your generator. Is that the word? I mean, sorry, you plug things into your breaker panel
[01:34:08.560 --> 01:34:13.760]   and then connect it to a battery. And then you can actually allocate during a power outage.
[01:34:13.760 --> 01:34:18.160]   Oh. It's to suck juice and you do it from an app as opposed to having to hardware things.
[01:34:18.160 --> 01:34:21.440]   I need that because I want to get a power wall. You had a power wall.
[01:34:21.440 --> 01:34:26.560]   Actually, you can do that with your Tesla because the Tesla is a power wall on wheels.
[01:34:26.560 --> 01:34:32.240]   And you can use an inverter to use the Tesla to power your house to the power be out. I just need
[01:34:32.240 --> 01:34:37.280]   the whatever that do hickey is. And do you also, but so you don't power the entire house,
[01:34:37.280 --> 01:34:40.000]   Stacy, are you saying that you need smart plugs?
[01:34:40.000 --> 01:34:46.080]   Well, no, if it's tied into your breaker system, your breaker will just turn things off.
[01:34:46.880 --> 01:34:52.080]   Oh, I mean, good God, the thing, the weird things that are connected to each other in this house.
[01:34:52.080 --> 01:34:58.480]   Right. Well, again, this is this is why this was at a professional installer show. This is not
[01:34:58.480 --> 01:35:02.000]   something I recommend you install yourself on your breaker. Oh, God, no, not me.
[01:35:02.000 --> 01:35:07.600]   Hey, breaking breaking news, Martin Shkreli going to jail.
[01:35:07.600 --> 01:35:15.600]   After his Facebook post about Hillary Clinton, a federal judge revoked his five million dollar
[01:35:15.600 --> 01:35:21.040]   bail. He's the former hedge fund manager, convicted of defrauding investors. He was the
[01:35:21.040 --> 01:35:24.320]   pharma guy who charged who raised the price on the
[01:35:24.320 --> 01:35:30.640]   Pildham, a lot of money. And he's trying to sell the Woutan clan. Yes, he has it. He bought,
[01:35:30.640 --> 01:35:35.840]   he bought an exclusive one cop, one time only copy of the new Woutan clan album. And now he's
[01:35:35.840 --> 01:35:40.160]   selling an honey bay saying, I kind of really didn't listen to it that much. I need the money.
[01:35:41.200 --> 01:35:47.840]   He while waiting sentences, Shkreli has, am I saying his name right? Shkreli. That's the worst name.
[01:35:47.840 --> 01:35:53.120]   Shkreli. That's why he's like those. As harassed women online, prosecutors argued,
[01:35:53.120 --> 01:35:59.280]   even offered his Facebook followers $5,000 to grab a strand of Hillary Clinton's hair during her book
[01:35:59.280 --> 01:36:05.360]   tour. He faces it. Grab a strand or yanker by the hair. Oh, that's nice. That's good.
[01:36:06.640 --> 01:36:14.960]   He is his bond has been revoked. And the district judge, Kio Matsumoto said he does not need to
[01:36:14.960 --> 01:36:18.800]   apologize to me. He should have apologized to the government. The secret service and Hillary Clinton,
[01:36:18.800 --> 01:36:23.600]   this is a solicitation of assault that is not protected by the First Amendment. He was taken
[01:36:23.600 --> 01:36:28.800]   in a custody immediately after the hour long hearing. He will remain jailed until his sensing
[01:36:28.800 --> 01:36:33.040]   hearing later this fall. So he was out on bail, but that bail has been revoked.
[01:36:36.000 --> 01:36:38.560]   Wow. I don't feel bad about that at all. He is really in.
[01:36:38.560 --> 01:36:44.400]   Adoosh. Yeah. Well, I was thinking of a word beginning with the, not quite that, but.
[01:36:44.400 --> 01:36:50.640]   I'm not sure if I, Karsten, can I say that? I'm sorry. I've said it already. It's French for
[01:36:50.640 --> 01:36:55.440]   shower. It's okay. I'm going to France. I need to bone up on my French.
[01:36:57.840 --> 01:37:04.720]   Pardomis, you will do. Pardomis.
[01:37:04.720 --> 01:37:10.400]   Schrely's attorney says in this current political climate dissent has unfortunately often taken the
[01:37:10.400 --> 01:37:16.560]   form of political satire, hyperbole, parody or sarcasm. While we do not condone his comments,
[01:37:16.560 --> 01:37:21.680]   his constitutionally protected political hyperbole does not, that's what I do.
[01:37:21.680 --> 01:37:26.240]   Constitutionally protected political hyperbole does not rise to the level of making him a danger
[01:37:26.240 --> 01:37:30.720]   to the community. Yes, but inciting violence makes others a danger.
[01:37:30.720 --> 01:37:37.040]   Well, and think about what happened with Gabby Gifford's getting shot and think about Republicans.
[01:37:37.040 --> 01:37:44.160]   Even that crazy Democrat guy who went and ran out and shot Republicans are actually
[01:37:44.160 --> 01:37:47.840]   congruent. Well, I'm listening to his book right now. And when you know who said,
[01:37:47.840 --> 01:37:51.760]   I hope the Second Amendment people take care of it. Oh, it's terrible. That's terrible.
[01:37:51.760 --> 01:37:58.560]   By the way, creative. Yeah. What happened? No, I'm just saying you got you. What? Hey,
[01:37:58.560 --> 01:38:03.920]   what happened? You got it audible. She reads it, which I love. Yeah, she got to go to 1.5
[01:38:03.920 --> 01:38:11.200]   speed. Yeah. Yeah. They have her talk very slowly.
[01:38:15.440 --> 01:38:24.080]   Oh, I'm sorry. I was just thinking of what's his name on HBO? Bill Maher's comment that anybody
[01:38:24.080 --> 01:38:28.400]   who hates Hillary Clinton must have been molested by a real estate salesperson when he was young.
[01:38:28.400 --> 01:38:34.640]   I don't know. I just made me laugh. I don't know. Yeah, let's not do the material design stuff.
[01:38:34.640 --> 01:38:42.400]   Let's just not do that. It's actually really boring. In fact, I can't think of anything more
[01:38:42.400 --> 01:38:48.400]   boring. I don't know. In these material design award winners. I got to a damn
[01:38:48.400 --> 01:38:50.960]   transition. You know, tease. I'm tired. I can't wait to go off.
[01:38:50.960 --> 01:38:59.280]   Oh, we'll do terrible things. What the heck was it? Was it actually? Is it actually materials
[01:38:59.280 --> 01:39:05.280]   design like new chemicals or no? No, I was curious. Material design is Google's name for the design
[01:39:06.960 --> 01:39:16.240]   style of Android. Oh, kill me now. Did you see? Did you see? This is only funny because it's a
[01:39:16.240 --> 01:39:22.080]   hilarious journalism story probably, but Fortune got a story about Google expanding its offices
[01:39:22.080 --> 01:39:27.520]   because they basically their real estate developer emailed or someone in the company emailed a
[01:39:27.520 --> 01:39:32.720]   Fortune reporter as part of an email thread on Google buying these new office buildings.
[01:39:32.720 --> 01:39:39.360]   So one, Google's expanding and buying $275 million worth of real estate. And two, the news came out
[01:39:39.360 --> 01:39:45.520]   because someone accidentally put a Fortune editor in the email chain. I thought that was funny.
[01:39:45.520 --> 01:39:49.680]   Yeah, probably a good idea if you want to keep something secret not to put a journalist
[01:39:49.680 --> 01:39:58.160]   in the CC. Yeah, but it happens. It happens more often than not necessarily on something that big,
[01:39:58.160 --> 01:40:05.360]   but I get a lot of emails that are not for me that are really not for me. Yeah, really?
[01:40:05.360 --> 01:40:13.280]   Do you ever report on them? I've only had one that was worth reporting on. Most of them are just
[01:40:13.280 --> 01:40:18.560]   what would the ethics of that be? I feel like it's pretty it's a mistake, but sure.
[01:40:18.560 --> 01:40:22.400]   So I guess, you know, it's like if you stumbled on a phone in a bar
[01:40:24.000 --> 01:40:29.040]   and you thought it was newsworthy, you could report on that. That's not it's just it was an
[01:40:29.040 --> 01:40:33.680]   accidental discovery. Yeah, or some I mean, if you're there's been plenty of times when I've
[01:40:33.680 --> 01:40:37.680]   been at conferences that are not off the record, they're just technical and they just don't they
[01:40:37.680 --> 01:40:41.520]   assume journalists won't be there. So they say more things. And then when I write them,
[01:40:41.520 --> 01:40:48.160]   people are like, well, that was a conference, you know, there were. Yeah, I was in public.
[01:40:48.160 --> 01:40:53.600]   I'm like, it was in public there. It was a confidential information. They knew I was there.
[01:40:53.600 --> 01:41:01.680]   Now, I feel like at some publications I've worked at when you were doing any sort of like,
[01:41:01.680 --> 01:41:06.240]   I don't even want to call it. You had to announce yourself. You had to announce that you were a
[01:41:06.240 --> 01:41:12.400]   journalist, which sometimes like in like Equifax is a good example. If I call them and say,
[01:41:12.400 --> 01:41:16.160]   I'm a journalist trying to understand what consumers are going through right now,
[01:41:16.160 --> 01:41:20.880]   I might get a vastly different experience. So like, there are some cases where I'm like,
[01:41:20.880 --> 01:41:27.280]   Oh, I hate that rule. Well, I don't think it's a rule because because any user can now call
[01:41:27.280 --> 01:41:32.160]   Equifax and say what's going on and then post on it, you can quote it. Everybody can.
[01:41:32.160 --> 01:41:40.240]   True, but I like to think that because of who I am in my history that people that I've
[01:41:40.240 --> 01:41:45.760]   enacted in public as a journalist, I have more credibility than Joe Schmo online when reporting
[01:41:45.760 --> 01:41:51.440]   about a user experience. The writer. Everything Stacy about everything except the oxidation.
[01:41:51.440 --> 01:41:58.320]   Except they're doing stocks for a couple. I mean, anybody can say this happened to them.
[01:41:58.320 --> 01:42:07.280]   And you know, you'd be wise to check it out. So if you have an Android phone in your
[01:42:07.280 --> 01:42:14.240]   possession, you might want to check. Blueborn. To see if you have the September security update.
[01:42:15.120 --> 01:42:18.240]   I checked my pixel this morning. It was still on August.
[01:42:18.240 --> 01:42:23.920]   Now this is going to be a waste of time. But let me just check the Samsung Galaxy Note 8.
[01:42:23.920 --> 01:42:28.400]   I bet you I'd be surprised if it has June's update. Let's see here.
[01:42:28.400 --> 01:42:35.440]   Software update download updates manually. Let's see if there's any update for
[01:42:35.440 --> 01:42:41.920]   mice. Anybody who has a pixel have you been updated? The fix is for a.
[01:42:41.920 --> 01:42:49.280]   When soon like since when was this this morning? Yes, recently.
[01:42:49.280 --> 01:42:53.520]   About five terrible horrible.
[01:42:53.520 --> 01:42:58.800]   Get ready for this one. This is a good one. 5.3 billion devices are vulnerable. Two billion of
[01:42:58.800 --> 01:43:05.600]   them are Android tablets, wearables as well as phones. It's something called Blueborn.
[01:43:05.600 --> 01:43:13.120]   It was discovered yesterday by a security firm, Armis Labs. It takes advantage of the fact that
[01:43:13.120 --> 01:43:18.640]   most devices broadcast over Bluetooth broadcast their availability.
[01:43:18.640 --> 01:43:26.720]   And so if the Bluetooth connection on your device is active, you're vulnerable to this.
[01:43:26.720 --> 01:43:31.840]   You don't have to do anything. You don't have to. It's an over the air attack.
[01:43:31.840 --> 01:43:35.280]   You just have to be within Bluetooth range, which is about 30 meters.
[01:43:35.280 --> 01:43:42.720]   The bad guy can use this attack to get full access to your phone. They actually demoed it on a
[01:43:42.720 --> 01:43:48.640]   Google Pixel showing the phone being remotely accessed. Apps like the camera and the file system
[01:43:48.640 --> 01:43:54.160]   can be accessed completely undetected by the user. In effect, you are fully pwned.
[01:43:54.160 --> 01:44:01.200]   Android devices that are vulnerable. The Pixel, the Galaxy, Galaxy tab, LG Watch
[01:44:01.200 --> 01:44:05.440]   Sport, and the pumpkin car audio system, which I am not familiar with.
[01:44:05.440 --> 01:44:09.920]   Those are actually just examples. They're examples because we're talking two
[01:44:09.920 --> 01:44:16.320]   billion Android devices, which is most of them. Google has pushed out a September security patch.
[01:44:16.320 --> 01:44:21.280]   It takes care of it. But unfortunately, a lot of people won't get this.
[01:44:21.280 --> 01:44:26.480]   Well, in their only patching, is it? Marshmallow and Nougat.
[01:44:26.480 --> 01:44:29.440]   Yes, six and seven. I was going to say, are we really going with Nougat?
[01:44:30.160 --> 01:44:32.640]   Not me. I'm in America.
[01:44:32.640 --> 01:44:39.680]   No. That's a good question. Does Oreo need it? I don't know.
[01:44:39.680 --> 01:44:45.360]   I guess not. By the way, in Oreo, you have that nice little thing you go to and say,
[01:44:45.360 --> 01:44:48.800]   am I up to date or not? Because we do that obsessively. I can't find it now.
[01:44:48.800 --> 01:44:56.320]   Oh, it's there. It's just in a different part. Here's a demo of Blueborn.
[01:44:57.760 --> 01:45:04.640]   We'll just enjoy the here's on the left, the hacker screen on the right, the device screen,
[01:45:04.640 --> 01:45:12.720]   the hacker. Wiley hacker is launching his Python seven script, his point.
[01:45:12.720 --> 01:45:19.120]   Really bad for hackers trying to make things done within 30 seconds. One attempt, one success,
[01:45:19.120 --> 01:45:24.480]   doing stack memory leaks. So it's once you get in, you have to take advantage of a memory leak,
[01:45:25.200 --> 01:45:30.240]   devices that don't use ASLR, particularly vulnerable. But even though the pixel uses ASLR,
[01:45:30.240 --> 01:45:33.760]   it's vulnerable. Well, you could also implement a man in the middle attack too.
[01:45:33.760 --> 01:45:41.440]   Nice. So here we go. They're going to see if they can get this attack going. They believe they'd
[01:45:41.440 --> 01:45:49.120]   hacked the device. And I guess apparently they have because they're waking up the phone. Yep,
[01:45:49.120 --> 01:45:56.400]   the phone got awakened, replaying recorded mouse movements. Opening the camera app,
[01:45:56.400 --> 01:46:04.320]   switching to the front camera, taking advantage of that very lovely person. They took a photo.
[01:46:04.320 --> 01:46:10.240]   Now can they? Yep, there's all the there's all the images in the in the storage. They're going to
[01:46:10.240 --> 01:46:18.000]   take it. And there's the image they want. And they're going to cat that out to themselves.
[01:46:18.960 --> 01:46:23.760]   To their IP address. And now they have that image. So within a minute,
[01:46:23.760 --> 01:46:29.280]   one minute and 32 seconds, they were able to take over this young woman's phone,
[01:46:29.280 --> 01:46:35.440]   snap a picture of her. Don't presume the woman had no no that was the picture. She could be the
[01:46:35.440 --> 01:46:39.600]   hacker. I don't know who the hacker was could have been her as well. But that was the victim.
[01:46:39.600 --> 01:46:44.160]   They took over her phone without her knowledge, snapped a picture of her and sent it to themselves.
[01:46:44.160 --> 01:46:50.800]   All without sure. Yeah, there is a blueborn vulnerability scanner by Armus in the
[01:46:50.800 --> 01:46:55.840]   app store, or not the app store, the Google Play Store. And you can download it. You can both
[01:46:55.840 --> 01:47:01.360]   find out if your device is vulnerable, vulnerable. But you can also wander around and be like,
[01:47:01.360 --> 01:47:06.160]   Hey, you you hit the bar. Look here, your device is vulnerable. You can make lots of friends.
[01:47:06.160 --> 01:47:10.880]   Yeah. What am I supposed to do about that? Oh, there's nothing you can do. I just want to let you
[01:47:10.880 --> 01:47:18.640]   know. Oh, well, Sheldon would do thank goodness. You could actually use it and then be like, Oh,
[01:47:18.640 --> 01:47:24.720]   this is the perfect place to launch my attack. My blueborn attack. Either way. So this is why
[01:47:24.720 --> 01:47:30.160]   it's so these monthly security updates are so important. And unfortunately, very few phones
[01:47:30.160 --> 01:47:34.640]   support them. I am encouraged by Oreo and the new treble architecture that this will
[01:47:35.520 --> 01:47:41.200]   Google's doing everything. I think it can to get everybody even on the cheap Android devices that
[01:47:41.200 --> 01:47:46.640]   aren't usually updated, get everybody into an updated situation so that they can protect.
[01:47:46.640 --> 01:47:51.200]   And we talked about this. So we talk about this on our show tomorrow, but
[01:47:51.200 --> 01:47:59.440]   the Samsung was actually really distressing to me because there are it ties in. This also affects
[01:47:59.440 --> 01:48:03.920]   Linux. So it's not iOS. It's not just Android. It's anything with Bluetooth. Yeah.
[01:48:04.480 --> 01:48:10.880]   It is a lot of things, Windows, but Linux and so Samsung's ties in OS, which is on their televisions,
[01:48:10.880 --> 01:48:18.160]   their fridges and other fun products, they actually never responded to Armus when Armus sent this out.
[01:48:18.160 --> 01:48:26.560]   And Armus apparently contacted Google in Apple in April. So they reached out to Samsung three times.
[01:48:26.560 --> 01:48:32.800]   Samsung never responded. So if you have a Samsung device that has Bluetooth running,
[01:48:32.800 --> 01:48:36.720]   I mean, your smart TV, you may not actually even need it to have Bluetooth constantly
[01:48:36.720 --> 01:48:41.040]   broadcasting. I mean, you'd have to invite the hacker into your home for that to be taken advantage
[01:48:41.040 --> 01:48:47.120]   of. But yes, you could. The only mitigating factor is you have to be within Bluetooth range.
[01:48:47.120 --> 01:48:53.120]   But if you're a coffee shop, Bluetooth range all the time. If you're if you're at a coffee shop or
[01:48:53.120 --> 01:48:58.960]   a train station or somewhere like that, I mean, you're vulnerable. It's not it's not a good thing.
[01:48:58.960 --> 01:49:05.200]   Let's say let's just say it that way. Let's take a break and talk about Equifax. We're almost done
[01:49:05.200 --> 01:49:16.320]   here. Yeah. Stacey Hickkin, give him both of them. I am almost done here. Wow. I am so cooked.
[01:49:16.320 --> 01:49:22.240]   Stacey Higgum on them. She's here. She's from Stacey on IoT and the IoT podcast, which you can
[01:49:22.240 --> 01:49:28.000]   find at IoTpodcast.com. Also, Jeff Jarvis is from CUNY. It's nice to have the gang back together
[01:49:28.000 --> 01:49:32.400]   again. So glad you are both here. Then you desert us. I'm going to leave.
[01:49:32.400 --> 01:49:36.960]   I'm going to leave. Now we'll do the show next week, right? And then the following week is Jason
[01:49:36.960 --> 01:49:41.040]   again. Or who's? Yeah. So Jason will be taking care of you. I'm even coming up for Twitch Sunday
[01:49:41.040 --> 01:49:47.920]   and you won't be there. You're coming to town into the studio. Oh, wait. You ready? Leo, while you're
[01:49:47.920 --> 01:49:53.440]   gone, I was even going to come into the studio. You guys do this on purpose. I know you do. You
[01:49:53.440 --> 01:49:58.640]   say is Leo there? Okay. I'll wait. Carsten, let me know what he's going on.
[01:49:58.640 --> 01:50:02.720]   So next week, next Twitter, Jason Calicani is hosting. You're going to be on that one, Jeff?
[01:50:02.720 --> 01:50:09.200]   Yeah. I didn't know that one. I said, yes. Oh, Jason's great. You're going to have a great time.
[01:50:09.200 --> 01:50:17.200]   Jason is a pistol. No, no, he's fun. Yeah. I talked to loaded. Challenge him. That's fine. Get
[01:50:17.200 --> 01:50:22.640]   into it with him. That's great. You know, Jason and I have had our ups and downs, but I find it.
[01:50:22.640 --> 01:50:27.760]   He's very entertaining. He's I and actually genuinely like the guy. You know, so
[01:50:27.760 --> 01:50:35.920]   good. And when are you going to be here, Stacy? I'm not now because it was I'm going to be in
[01:50:35.920 --> 01:50:41.680]   San Francisco. I'm not going to make the Petaluma quest. Fun, you know, people don't know this, but
[01:50:41.680 --> 01:50:48.160]   Jeff and I have had intimate relations. I've shaved him, but I've never met Stacy in person
[01:50:48.160 --> 01:50:54.640]   at all. And I don't think that's an accident. Never? No, never. Jeff and I, I think I met you, Jeff.
[01:50:54.640 --> 01:51:01.200]   Once. But yes, no, one's they say that.
[01:51:01.200 --> 01:51:06.000]   Problem is we ordered to be in conferences. You can't put somebody in a context.
[01:51:06.000 --> 01:51:12.560]   Right. You know, you don't remember meeting Stacy? Stacy doesn't remember meeting me.
[01:51:12.560 --> 01:51:16.880]   Oh, you remember her, but she doesn't remember. Yeah. Well, no, I think I met Jeff.
[01:51:17.840 --> 01:51:23.200]   I think we met it South by, but South by. Yeah. South by. I don't remember anything.
[01:51:23.200 --> 01:51:29.760]   If you remember South by, you weren't there. I think that's how the saying goes.
[01:51:29.760 --> 01:51:36.800]   I showed they brought to you by legal zoom. You know, we live in a world of lawyers,
[01:51:36.800 --> 01:51:41.440]   but you don't have to be paying them to get that legal advice. You can go to legal zoom.
[01:51:41.440 --> 01:51:45.680]   When you run your own business, you know, who has the time, who has the money?
[01:51:46.320 --> 01:51:51.600]   To do all this legal stuff, yet you still have to do your LLCs or your S-corps.
[01:51:51.600 --> 01:51:55.840]   You still have to do your trademarks. And there's a lot of paperwork, but you can do it.
[01:51:55.840 --> 01:52:00.720]   A lot of it with legal zoom without an attorney. Two million people have used legal zoom to start
[01:52:00.720 --> 01:52:06.160]   their businesses, including me. We got our trademarks through legal zoom as well. It was very easy.
[01:52:06.160 --> 01:52:10.080]   Occasionally though, you know, you do need an attorney and the nice thing about legal zoom,
[01:52:10.080 --> 01:52:13.520]   they're not a law firm, but they do have a network of independent attorneys.
[01:52:14.160 --> 01:52:18.880]   They've licensed in all 50 states that they've negotiated flat rate pricing with. It really makes
[01:52:18.880 --> 01:52:24.720]   it easy to get the advice you need for running your business. There's taxes, there's contracts,
[01:52:24.720 --> 01:52:30.080]   there's employees, there's, there's a lot. You don't ever have to worry about billable
[01:52:30.080 --> 01:52:34.480]   hours or legal zoom. It's not a law firm. You can count it up for out pricing, clarity,
[01:52:34.480 --> 01:52:39.120]   great information, the forms you need. Invest your time and money in growing your business and let
[01:52:39.120 --> 01:52:46.560]   legal zoom help out with illegal stuff for special savings. Use the promo code twig@legalzoom.com.
[01:52:46.560 --> 01:52:53.600]   Legalzoom.com, the offer code twig, our little way of thanking you and thanking legal zoom for
[01:52:53.600 --> 01:53:03.120]   supporting this week in Google. Let's see here. I'm going to, I'm getting breaking news from the
[01:53:03.120 --> 01:53:09.920]   chatroom. Interesting. Nexus and Pixel factory images for September's security patch are up.
[01:53:09.920 --> 01:53:16.080]   This is about an hour ago. However, the Nexus player has not been updated. The OTAs were pushed
[01:53:16.080 --> 01:53:28.000]   yesterday. So if you didn't get it yet, you could get it by hand or you could check again and again.
[01:53:29.280 --> 01:53:33.280]   But so that's, I honestly cannot find the check perversion online.
[01:53:33.280 --> 01:53:39.040]   I don't have my pixel with me or I'd help you find it. There isn't there a search though. You
[01:53:39.040 --> 01:53:43.920]   could always, you could always use the search in the settings. Are my searching for version?
[01:53:43.920 --> 01:53:49.600]   You try version. Let me look at what it looks like. I only have the note with me today. I didn't
[01:53:49.600 --> 01:53:58.240]   bring the pixel. I wish I had. Search for system. Or security patch level.
[01:53:58.240 --> 01:54:06.160]   All that does is tell me the number. It doesn't say is it up to date, click here.
[01:54:06.160 --> 01:54:11.760]   It's in my, it's in about phone on the Samsung. I don't know where it is.
[01:54:11.760 --> 01:54:16.080]   No, it's, it's, it's all. Yeah, they moved it out. It wasn't it.
[01:54:16.080 --> 01:54:21.920]   It's a system, setting system, system update, system updates. It's in its own section now.
[01:54:21.920 --> 01:54:28.880]   Well on settings, system, system updates.
[01:54:28.880 --> 01:54:34.560]   Ah, check for update. Thank you. Good work, man. That's why you have the guy from the, you know,
[01:54:34.560 --> 01:54:39.120]   Ivy League there. Ivy League. Got to have a Harvard man ready at any time. Were you,
[01:54:39.120 --> 01:54:44.000]   were you in the, here is now installing the update. Oh, good. Yay.
[01:54:45.040 --> 01:54:48.320]   Your phone will be useless for several minutes. But at least you won't be.
[01:54:48.320 --> 01:54:52.240]   Well, fella, boo, boo, boo. You won't be blueboard. No, no, that's, that's Yale.
[01:54:52.240 --> 01:54:54.000]   That's one place. Oh, the wrong place.
[01:54:54.000 --> 01:54:57.520]   With and poof. With and that's also Yale.
[01:54:57.520 --> 01:55:01.680]   Oh, all right. And if you say anything about the tables, then it more is that's three strikes.
[01:55:01.680 --> 01:55:11.600]   You'll be out. Are, let's talk about 1% 1% 1% raw, raw, raw. Yes. White privilege is us.
[01:55:12.480 --> 01:55:16.960]   Let's, let's talk a little bit about Equifax, shall we?
[01:55:16.960 --> 01:55:26.880]   I'm going to have a question. Ask, ask me. I love Brian Krebs had, Brian's been covering this
[01:55:26.880 --> 01:55:33.840]   so well in his cribs on security. The latest from Brian Krebs is that he checked out the
[01:55:33.840 --> 01:55:41.920]   Argentinian affiliate of Equifax. And they, it's so funny. This actually,
[01:55:41.920 --> 01:55:49.440]   his information comes from Alex Holden of a hold security. Apparently the website Equifax website
[01:55:49.440 --> 01:55:55.040]   in Argentina, and they call it their employee portal. They call it Veraz or truthful in Spanish.
[01:55:55.040 --> 01:56:02.480]   And it's now down. Thank goodness. The login and password for the site was admin, admin.
[01:56:03.280 --> 01:56:09.200]   Which is probably the first one you'd guess. Once inside, researchers were able to log in and
[01:56:09.200 --> 01:56:14.160]   they could view the names of more than 100 Equifax employees in Argentina. Their employee IDs and
[01:56:14.160 --> 01:56:21.040]   email addresses. There was a list of users page featuring a clickable button that anyone with the
[01:56:21.040 --> 01:56:26.160]   admin admin username and password could use to add, modify, or delete user accounts on the system.
[01:56:27.600 --> 01:56:35.200]   They then found a list of people who had disputes with the credit reporting agency.
[01:56:35.200 --> 01:56:43.200]   And it listed 715 pages worth of complaints and disputes. And in each case, it had the person's
[01:56:43.200 --> 01:56:51.280]   DNI, which is their Argentinian social security number in plain text, 14,000 records name
[01:56:52.640 --> 01:57:00.400]   and social. This was all publicly available. All you had to do was guess the password admin admin.
[01:57:00.400 --> 01:57:08.560]   So Equifax is not exactly holy cow. They're not exactly escaping this unscathed. Let's put it
[01:57:08.560 --> 01:57:15.200]   that way. Oh my god. They so are in the audacity that they have to behave that they the way they
[01:57:15.200 --> 01:57:21.280]   did is just just so. Let's talk about it. We spent some time talking about yesterday to unsecurity
[01:57:21.280 --> 01:57:26.400]   now was a data breach that occurred some months ago. Equifax said we discovered it July 29th.
[01:57:26.400 --> 01:57:31.360]   Before they told us though, they made sure that any executives who wanted to sell their Equifax
[01:57:31.360 --> 01:57:37.760]   stock got to three executives including their CFO sold off Equifax stock worth millions of dollars.
[01:57:37.760 --> 01:57:44.640]   They said later, well, they didn't know they didn't know they just they just decided to sell stock all
[01:57:44.640 --> 01:57:50.400]   of a sudden. Personal data including birth dates, credit card numbers, and more obtained by hackers
[01:57:50.400 --> 01:57:58.480]   for a hundred forty three million US customers. Then Equifax added insult to injury by putting up a
[01:57:58.480 --> 01:58:02.240]   website that you could ostensibly go to and find out if you were one of those people whose
[01:58:02.240 --> 01:58:08.640]   information was leaked. It seemed to do nothing. It randomly picked, you could enter any number
[01:58:08.640 --> 01:58:12.800]   or name and it would pick a random choice. Yes, you were hacked. No, you weren't hacked. Maybe you
[01:58:12.800 --> 01:58:17.760]   were. Come back later. Come back later. It was random. Please check back again another time.
[01:58:17.760 --> 01:58:22.080]   Yeah, and then this is where they really, I'm sure this is where they salted you.
[01:58:22.080 --> 01:58:25.920]   It sent you to a free one year credit monitoring service of theirs,
[01:58:25.920 --> 01:58:31.200]   which of course won't be free in a year. They're going to try to make money on this breach.
[01:58:31.200 --> 01:58:39.760]   Now, I don't think this is this is Jermaine, but some complained that the agreement that you
[01:58:39.760 --> 01:58:43.920]   agreed to when you signed up for their free credit monitoring service said you couldn't
[01:58:43.920 --> 01:58:48.160]   sue them. It's true. It was a binding arbitration clause that you signed up for.
[01:58:48.160 --> 01:58:52.720]   Right. Equifax says that applies only to the credit monitoring and not to the breach.
[01:58:52.720 --> 01:58:57.760]   Okay. You'd be foolish to have anything to do with Equifax anyway.
[01:58:57.760 --> 01:59:03.760]   So that well, nobody has a choice. Equifax just hovers up all this data and sells it to people.
[01:59:03.760 --> 01:59:08.480]   So it's not like, right? It's not like any, any normal person's like, oh, I think I'm going to do
[01:59:08.480 --> 01:59:12.800]   business with Equifax today. No, it's an invisible data. I should say do anything,
[01:59:12.800 --> 01:59:16.080]   any more business with them. Don't go to their site at all.
[01:59:16.080 --> 01:59:18.720]   But you have to because the best way to
[01:59:18.720 --> 01:59:21.760]   No, you don't. That gives you no information.
[01:59:21.760 --> 01:59:27.040]   So you have to, you have to deal with them because you're going to need to put a freeze on your
[01:59:27.040 --> 01:59:30.400]   accounts. In that respect, you should deal with that. Yes. You shouldn't go to this.
[01:59:30.400 --> 01:59:38.560]   Am I hacked site? No, I mean, well, it's gotten better, but they do, they do not make it clear.
[01:59:38.560 --> 01:59:49.840]   They for a company. This to me shows how corrupt the American system is in so many ways that these
[01:59:49.840 --> 01:59:55.200]   guys actually said, hey, oh, we just really screwed up on this one. So we're going to,
[01:59:55.200 --> 01:59:57.760]   we're going to sell our stock first. And then we're going to deal with it by
[01:59:57.760 --> 02:00:04.640]   coming up with things that are the bare minimum and we're going to piss off a bunch of consumers
[02:00:05.760 --> 02:00:11.840]   with like the crappiest web design, poor hosting and just complete an utter idiocy.
[02:00:11.840 --> 02:00:17.040]   It's really stunning. So you're saying people should go, and I don't know if everybody needs
[02:00:17.040 --> 02:00:21.120]   to do this, but you're saying people should go to the big three and maybe the fourth,
[02:00:21.120 --> 02:00:26.160]   there's another one, a Novus credit reporting agencies and put it out a credit freeze.
[02:00:26.160 --> 02:00:32.960]   So the pros and cons of doing a credit freeze are you have to do it. You have to call them all
[02:00:32.960 --> 02:00:37.360]   individually. There are fees, Equifax says that it will not charge its fees to people freezing
[02:00:37.360 --> 02:00:42.160]   their credit after this. They were really good. Actually, I want to correct that there are fees
[02:00:42.160 --> 02:00:47.600]   in some states, some states, it's up to the state legislature, the state legislature mandates the
[02:00:47.600 --> 02:00:54.800]   fees in California, it's $10 per agency to freeze and unfreeze, but in some states like Maine and
[02:00:54.800 --> 02:01:02.080]   Wisconsin, it's free. So it may be free for you. It is free for me. I had to freeze.
[02:01:02.400 --> 02:01:09.360]   Yeah. So when you do a freeze, it takes time to do and it takes time to undo. So you can't apply
[02:01:09.360 --> 02:01:17.280]   for credit if you have the freeze or you can apply, it just won't get it. And a notable thing is,
[02:01:17.280 --> 02:01:23.600]   you know, this iPhone coming out, I believe an Apple, is it the Apple monthly payment program?
[02:01:23.600 --> 02:01:29.600]   So sometimes your cell carriers or to buy a phone may have to pull credit reports that you
[02:01:29.600 --> 02:01:34.080]   don't even know if you're applying for a job, if that may happen. Yeah, but that's less
[02:01:34.080 --> 02:01:40.400]   concerning. Yes. And yes, cell phone companies very routinely pull credit history.
[02:01:40.400 --> 02:01:49.680]   So, and if you undo your freeze, you're going to have to pay sometimes, not everyone, to put it back
[02:01:49.680 --> 02:01:57.760]   on. So this is terrible. It's not trivial. You can do a fraud alert. It's really not much,
[02:01:57.760 --> 02:02:02.160]   particularly effective. It just let you know if somebody's trying to get a credit card in your
[02:02:02.160 --> 02:02:07.440]   name. Basically, this is people complain about privacy with Facebook and Google. But we've got
[02:02:07.440 --> 02:02:11.680]   these companies that's won an only job is to collect every bit of information about you.
[02:02:11.680 --> 02:02:17.120]   They can't sell it to people without your participation. These companies basically shouldn't.
[02:02:17.120 --> 02:02:22.000]   Well, wait a minute, though, don't they have to? I mean, honestly, if you're going to have a credit,
[02:02:22.000 --> 02:02:26.640]   if people are going to extend you credit, there needs to be some organized way to find out if
[02:02:26.640 --> 02:02:30.400]   you're credit worthy. Oh, we will do a star rating system.
[02:02:30.400 --> 02:02:36.400]   Just like you will do it. That's what that's what your FICO story is. But who will do it?
[02:02:36.400 --> 02:02:41.040]   Somebody's got to do this. And by the way, you agree to it every time you take out a loan or you
[02:02:41.040 --> 02:02:46.080]   get a credit card in the fine print, it says you agree that we'll submit every information about
[02:02:46.080 --> 02:02:51.520]   you, including your pay history to Equifax TransUnion. So this is this is an area where regulation
[02:02:52.160 --> 02:02:58.480]   is important because clearly the way we have set up our economy around credit,
[02:02:58.480 --> 02:03:05.680]   it has become a valuable tool. And you have to regulate these. And what's astonishing to me is the
[02:03:05.680 --> 02:03:13.840]   lack of regulation for something that actually Congress has given a lot of what's it called
[02:03:13.840 --> 02:03:17.520]   when you talk about something, but you don't do anything about it.
[02:03:17.520 --> 02:03:24.960]   Lip service. I was like lipstick on the pig. They've given a lot of lip service to this.
[02:03:24.960 --> 02:03:30.320]   They've held actually a lot of hearings about it. And every time the rules come in weaker than
[02:03:30.320 --> 02:03:38.000]   well, it's ironic. But Equifax was lobbying hard and paying a lot of money to campaign funds to
[02:03:38.000 --> 02:03:44.480]   get the see this consumer financial protection bureau dismembered and to change the rules so
[02:03:44.480 --> 02:03:48.400]   that they weren't as accountable. I mean, they hate this.
[02:03:48.400 --> 02:03:53.920]   Because the bare minimum that they have to comply with today is so inconvenient to
[02:03:53.920 --> 02:03:58.080]   they're making dobs of money without any sort of responsibility or accountability,
[02:03:58.080 --> 02:04:08.960]   which is I'm not going to get on this because it is not. Anyway, okay. That's the Equifax story.
[02:04:08.960 --> 02:04:14.080]   So here's what my question. And I've said this on the show before, but I still don't understand.
[02:04:14.160 --> 02:04:19.440]   Are we looking at this the wrong way? We know there are going to be breaches of data.
[02:04:19.440 --> 02:04:22.880]   There have been breaches of data. Half of America is now breached. There's going to be breaches of
[02:04:22.880 --> 02:04:29.680]   data. The problem is the other end of it. People with that data should be able to do nothing with
[02:04:29.680 --> 02:04:32.640]   it, which means that what we have to fix is transactions.
[02:04:32.640 --> 02:04:34.720]   Blockchain.
[02:04:34.720 --> 02:04:41.360]   Well, blockchain, two factor, call what you will, but
[02:04:42.720 --> 02:04:46.480]   the one way or the other, we've got to change the transactional structure so that if you have my
[02:04:46.480 --> 02:04:51.520]   name and social security number, who cares? You can't do Jack with it birthday. Mother's maiden name,
[02:04:51.520 --> 02:04:55.440]   right? Obviously, there's problems for fishing. Obviously, there's problems where you can fool
[02:04:55.440 --> 02:05:00.000]   an individual. Obviously, an idiot on an important account can have a bad password. That's always
[02:05:00.000 --> 02:05:05.040]   going to be true. Well, but even then, if you have two factor, if you have other structures,
[02:05:05.040 --> 02:05:12.160]   if you change the level of transactional security, Leo, I wish Steve were on because he knows a lot
[02:05:12.160 --> 02:05:14.240]   more about this than I do, but you're the next best thing.
[02:05:14.240 --> 02:05:23.520]   Yeah. I've pulled up a paper from the Federal Reserve Bank on the history of credit reporting.
[02:05:23.520 --> 02:05:31.920]   We haven't always had these credit bureaus. In fact, they didn't really begin until this century,
[02:05:31.920 --> 02:05:37.520]   the credit reporting industry started in the '50s and '60s, and it was very industry-specific.
[02:05:38.160 --> 02:05:44.560]   So a banking industry would have somebody compile files on people. By the way, they would look for
[02:05:44.560 --> 02:05:50.320]   newspaper clippings about arrests or promotions or marriages and deaths, and they would be attached
[02:05:50.320 --> 02:05:57.920]   to a consumer's credit report. It wasn't until the '70s that an industry, this Equifax TransUnion
[02:05:57.920 --> 02:06:05.200]   Experian industry began. The passage of the Fair Credit Reporting Act in the '70s did actually,
[02:06:05.200 --> 02:06:10.160]   as you know, we have a lot of protections with these agencies. We can see our credit history,
[02:06:10.160 --> 02:06:15.360]   we can ask for our credit report once a year for free, we can amend it, we can put notes on it,
[02:06:15.360 --> 02:06:20.560]   we can ask for it to be corrected. They stopped putting marriages, promotions, and deaths in the
[02:06:20.560 --> 02:06:26.720]   file. They were limited on what they could collect. Experian was originally TRW, you know that name.
[02:06:27.760 --> 02:06:38.000]   TransUnion and then Equifax all kind of were created in the '70s. I think you need something like this.
[02:06:38.000 --> 02:06:46.960]   Credit is really important. It's actually one of the great inventions of capitalism. I'm reading
[02:06:46.960 --> 02:06:52.320]   a book about this, and it was fascinating, that in the Middle Ages, remember, it wasn't considered
[02:06:52.960 --> 02:06:59.200]   a reputable to lend money because there was no expectation of growth. It was felt that
[02:06:59.200 --> 02:07:03.840]   it was a zero-sum gain, and that anybody's success was at somebody else's debt to somebody
[02:07:03.840 --> 02:07:09.600]   else's detriment. They didn't understand the notion of value creation. So nobody lended money. It was
[02:07:09.600 --> 02:07:16.080]   Shylock, right? It was a serious race, and it was kind of... It was a Christian thing. Yeah, it wasn't
[02:07:16.080 --> 02:07:21.600]   considered Christian to do it. We had to make the Jewish people do it. The tribe was responsible for
[02:07:22.480 --> 02:07:30.720]   it, but when the notion of capital investment and venture investment and lending
[02:07:30.720 --> 02:07:36.720]   was created, it created immense wealth and immense value. So it is a very valuable system,
[02:07:36.720 --> 02:07:42.160]   and you can understand whether it would need to be some way of proving or demonstrating that
[02:07:42.160 --> 02:07:46.560]   you were credit-worthy. Otherwise, how would you go to a bank and ask for a loan for a $100,000?
[02:07:46.560 --> 02:07:50.560]   There's nothing wrong with credit. There's nothing wrong with credit data.
[02:07:51.280 --> 02:07:53.520]   If it's credit-current, it doesn't screw you up. What's wrong?
[02:07:53.520 --> 02:07:58.480]   So there's nothing wrong with people having data about you. They're going to have that data.
[02:07:58.480 --> 02:08:03.920]   My point is that what we're... So what was wrong here is... It's well-known how to secure...
[02:08:03.920 --> 02:08:05.920]   It's the good of the people to reach. It's well-known how to secure that.
[02:08:05.920 --> 02:08:11.760]   This has been proposed, actually, Corey Doctor had a funny column in Boing Boing
[02:08:11.760 --> 02:08:17.280]   that said there should be a death penalty for corporations, that sometimes corporations
[02:08:17.280 --> 02:08:21.520]   should commit crimes so heinous that they should be just dissolved. The government should say,
[02:08:21.520 --> 02:08:24.400]   "You know what? You're out of business. I don't know if I agree with that."
[02:08:24.400 --> 02:08:31.760]   But there definitely need to be very strong punishments for not treating data like this
[02:08:31.760 --> 02:08:36.320]   securely. By the way, I believe it is known how to secure this data.
[02:08:36.320 --> 02:08:40.000]   Leo, you're still not... But what's your question?
[02:08:40.000 --> 02:08:41.600]   That's the issue is...
[02:08:41.600 --> 02:08:47.200]   Let us presume data will be breached, period. The problem with it is, is what can the bad
[02:08:47.200 --> 02:08:52.720]   guy then do with the data? The bad guy can... That's what we have to secure,
[02:08:52.720 --> 02:08:54.240]   is the other end of this problem.
[02:08:54.240 --> 02:08:56.640]   You say when the data gets out there...
[02:08:56.640 --> 02:08:57.360]   How many times is it breaches before?
[02:08:57.360 --> 02:08:58.960]   There's going to be breaches. Somebody's going to mess that up.
[02:08:58.960 --> 02:08:59.600]   There's going to be breaches.
[02:08:59.600 --> 02:09:00.560]   Well, it's kind of a done deal.
[02:09:00.560 --> 02:09:01.840]   Exactly.
[02:09:01.840 --> 02:09:02.480]   You call it.
[02:09:02.480 --> 02:09:06.400]   This is why you shouldn't go to the Experian website. You should just assume that your credit
[02:09:06.400 --> 02:09:08.880]   cards and your phone numbers and your socials out there.
[02:09:08.880 --> 02:09:11.040]   Why do we fear the data being out there?
[02:09:11.040 --> 02:09:12.800]   What can be done with that data?
[02:09:12.800 --> 02:09:13.920]   What do we do about that?
[02:09:13.920 --> 02:09:17.680]   Yeah. So there's identity theft where somebody assumes your identity applies for
[02:09:17.680 --> 02:09:19.680]   credit using your social and your birth date.
[02:09:19.680 --> 02:09:24.240]   You have good credit, but they don't intend to ever pay any of these credit cards off
[02:09:24.240 --> 02:09:29.920]   or pay off any of these loans. So they use your good credit to generate a lot of fraudulent loans.
[02:09:29.920 --> 02:09:30.960]   Right. No, Jeff is...
[02:09:30.960 --> 02:09:32.160]   And your credit is destroyed.
[02:09:32.160 --> 02:09:33.120]   So that's one way.
[02:09:33.120 --> 02:09:34.720]   Jeff is saying...
[02:09:34.720 --> 02:09:41.680]   He is asking what can be done to make this information, which today can be used to do all of that.
[02:09:42.240 --> 02:09:44.560]   Useless. So what do you add to it?
[02:09:44.560 --> 02:09:45.680]   So can...
[02:09:45.680 --> 02:09:46.720]   What do you add to the...
[02:09:46.720 --> 02:09:48.480]   How do you add friction to the...
[02:09:48.480 --> 02:09:50.800]   Friction to the basic...
[02:09:50.800 --> 02:09:53.920]   So better authentication systems would be good.
[02:09:53.920 --> 02:09:58.960]   Obviously, the government even says, "Do not use your social for identification,
[02:09:58.960 --> 02:10:02.240]   but we've got a system where everybody does that."
[02:10:02.240 --> 02:10:02.800]   Right.
[02:10:02.800 --> 02:10:05.280]   So that is a number that is difficult to change.
[02:10:05.280 --> 02:10:08.000]   By the way, your fingerprint is impossible to change.
[02:10:08.000 --> 02:10:10.960]   It is also now being widely used for identification.
[02:10:10.960 --> 02:10:13.200]   Both of these are very bad ideas.
[02:10:13.200 --> 02:10:16.160]   But I'm not sure if we have any better ideas.
[02:10:16.160 --> 02:10:21.440]   By the way, authentication is the number one issue in finance.
[02:10:21.440 --> 02:10:24.960]   And everything is proving you are who you say you are.
[02:10:24.960 --> 02:10:28.560]   It's why passwords don't work, because that's an authentication system.
[02:10:28.560 --> 02:10:35.760]   It's why we've got this problem, because it's very difficult, absent, in person meeting.
[02:10:35.760 --> 02:10:38.160]   And even then, you can impersonate me.
[02:10:38.880 --> 02:10:41.120]   It's very difficult to authenticate somebody's identity.
[02:10:41.120 --> 02:10:41.600]   I don't know.
[02:10:41.600 --> 02:10:42.240]   You would chip them?
[02:10:42.240 --> 02:10:42.720]   I don't know.
[02:10:42.720 --> 02:10:43.440]   There is no system.
[02:10:43.440 --> 02:10:45.200]   Not even authentic.
[02:10:45.200 --> 02:10:46.960]   So can we add two factors to it?
[02:10:46.960 --> 02:10:48.960]   So I apply for a credit card.
[02:10:48.960 --> 02:10:51.920]   And then this actually happens when you implement a credit freeze.
[02:10:51.920 --> 02:10:55.200]   You actually have to call them ahead of time.
[02:10:55.200 --> 02:10:59.760]   They run the credit card report, and they actually will call you again and say,
[02:10:59.760 --> 02:11:01.680]   "Hey, this happened.
[02:11:01.680 --> 02:11:02.400]   Was it you?"
[02:11:02.400 --> 02:11:03.520]   I think it's very hard to think.
[02:11:03.520 --> 02:11:04.480]   I understand your question.
[02:11:04.480 --> 02:11:08.160]   I just think it's very hard to think of a system that
[02:11:08.800 --> 02:11:11.600]   of perfect authentication, because that's what you need.
[02:11:11.600 --> 02:11:13.520]   You don't need perfect authentication.
[02:11:13.520 --> 02:11:19.680]   You need multiple layers of imperfect authentication that together cover the CYA.
[02:11:19.680 --> 02:11:21.680]   And increase the cost and the risk for the better.
[02:11:21.680 --> 02:11:22.480]   Where does that work?
[02:11:22.480 --> 02:11:28.400]   So let's say you say, "I need you to have your social, and I need a fingerprint,
[02:11:28.400 --> 02:11:30.320]   and I need a password."
[02:11:30.320 --> 02:11:31.920]   Where is all that stored?
[02:11:31.920 --> 02:11:34.480]   There's going to be a central repository that's stored.
[02:11:34.480 --> 02:11:35.200]   That's the problem.
[02:11:36.960 --> 02:11:40.960]   That's the real problem is that Equifax had your authentication information.
[02:11:40.960 --> 02:11:41.440]   All of it.
[02:11:41.440 --> 02:11:49.600]   I think there are steps that you can do things that...
[02:11:49.600 --> 02:11:52.080]   You need two agencies, maybe three.
[02:11:52.080 --> 02:11:57.600]   And you'd have to hope that a bad guy didn't get that a bad guy didn't compromise all three.
[02:11:57.600 --> 02:11:59.120]   Yeah.
[02:11:59.120 --> 02:12:00.960]   I mean, that is a lot harder.
[02:12:00.960 --> 02:12:06.640]   I mean, that's basically where all security needs to go is recognizing that
[02:12:07.440 --> 02:12:09.040]   anything centralized will break.
[02:12:09.040 --> 02:12:10.960]   That's why blockchain is so interesting.
[02:12:10.960 --> 02:12:18.960]   Anyway, my point is that authentication is everybody knows this is the issue.
[02:12:18.960 --> 02:12:23.120]   And everybody's working on good systems of authentication.
[02:12:23.120 --> 02:12:25.600]   But I see so little work on it.
[02:12:25.600 --> 02:12:27.840]   Well, yeah, but there is a lot of work being done.
[02:12:27.840 --> 02:12:29.120]   There's a lot of work.
[02:12:29.120 --> 02:12:34.880]   The challenge is everything sucks from a convenience and security is...
[02:12:34.880 --> 02:12:35.680]   There's a trade-off.
[02:12:35.680 --> 02:12:36.240]   That's right.
[02:12:36.240 --> 02:12:39.280]   And then there's also standardization.
[02:12:39.280 --> 02:12:40.400]   You can't have something.
[02:12:40.400 --> 02:12:42.320]   You have to get it adopted by the entire industry.
[02:12:42.320 --> 02:12:43.360]   I have heard what I would argue.
[02:12:43.360 --> 02:12:47.120]   And I think this is the argument that this is the situation we currently live in.
[02:12:47.120 --> 02:12:50.960]   Doing it right is far more expensive than what we have right now,
[02:12:50.960 --> 02:12:52.960]   which is allowing a certain amount of fraud to occur.
[02:12:52.960 --> 02:12:59.120]   Well, it's the same reason banks don't really report breaches.
[02:12:59.120 --> 02:13:04.800]   It's cheaper to pay off the loss and continue business as usual
[02:13:04.800 --> 02:13:06.000]   that affix the problem.
[02:13:06.000 --> 02:13:07.840]   That's interesting.
[02:13:07.840 --> 02:13:10.640]   So I would...
[02:13:10.640 --> 02:13:12.320]   And I think that that's part of...
[02:13:12.320 --> 02:13:14.720]   This is a little bit of a tempest in a teapot because...
[02:13:14.720 --> 02:13:20.480]   Well, we'll see in a couple of years if there's a massive uptick in identity theft.
[02:13:20.480 --> 02:13:21.360]   I bet there won't be.
[02:13:21.360 --> 02:13:25.120]   People are freaking out that their information's out there.
[02:13:25.120 --> 02:13:29.040]   But it may not have a huge consequence.
[02:13:32.080 --> 02:13:35.200]   From a philosophical point of view, it's a bad thing.
[02:13:35.200 --> 02:13:36.560]   It's a terrifying thing.
[02:13:36.560 --> 02:13:39.600]   But it may not actually be so consequential.
[02:13:39.600 --> 02:13:43.200]   And it's certainly the case that doing it right would be very
[02:13:43.200 --> 02:13:46.640]   difficult, expensive, and inconvenient.
[02:13:46.640 --> 02:13:51.520]   You could use PGP keys.
[02:13:51.520 --> 02:13:54.320]   I mean, you could use a good solution for this.
[02:13:54.320 --> 02:13:58.880]   PGP is a very good authentication system.
[02:13:58.880 --> 02:14:00.320]   And the web of trust.
[02:14:00.320 --> 02:14:04.080]   There are systems, but it's really a pain in the ass.
[02:14:04.080 --> 02:14:04.640]   I use it.
[02:14:04.640 --> 02:14:08.400]   If you get email from me, it's usually PGP signed to verify that it came from me
[02:14:08.400 --> 02:14:09.440]   and it hasn't been modified.
[02:14:09.440 --> 02:14:12.800]   If you were running PGP, which nobody does,
[02:14:12.800 --> 02:14:15.920]   you could then look at that and validate it and say, "Oh, that came from Leo."
[02:14:15.920 --> 02:14:17.760]   How many efforts...
[02:14:17.760 --> 02:14:23.840]   PGP or some equivalent could be made safe for consumers.
[02:14:23.840 --> 02:14:26.080]   That's an area where I've been frustrated that no one's ever done.
[02:14:26.080 --> 02:14:27.360]   It's simply done easily.
[02:14:27.360 --> 02:14:29.680]   Each of us would have two keys.
[02:14:29.680 --> 02:14:31.280]   A public key and a private key.
[02:14:31.280 --> 02:14:35.840]   You would tell everybody your public key so that they could use that to encrypt data to you,
[02:14:35.840 --> 02:14:37.200]   which only you could decrypt.
[02:14:37.200 --> 02:14:40.400]   But the keys can also be used for authentication.
[02:14:40.400 --> 02:14:42.400]   You can give out your public key.
[02:14:42.400 --> 02:14:44.480]   If somebody says, "Oh, hi, Jeff.
[02:14:44.480 --> 02:14:47.120]   I have your public key here.
[02:14:47.120 --> 02:14:49.360]   Can you prove to me that it's you?"
[02:14:49.360 --> 02:14:52.800]   And you run it through a program that says, "Yes, Jeff has the private key."
[02:14:52.800 --> 02:14:54.960]   Now, you would have to keep the private key private.
[02:14:54.960 --> 02:14:58.160]   And you could best that up.
[02:14:58.160 --> 02:15:00.240]   Well, and there's ways to fix that too.
[02:15:00.240 --> 02:15:02.640]   You require expiration every year.
[02:15:02.640 --> 02:15:03.840]   You have to generate a new one.
[02:15:03.840 --> 02:15:06.560]   You need a key revocation system.
[02:15:06.560 --> 02:15:08.880]   This has actually been a problem on the web with certificates.
[02:15:08.880 --> 02:15:11.040]   There isn't a good key revocation system
[02:15:11.040 --> 02:15:13.120]   because it's been deemed too difficult to do well.
[02:15:13.120 --> 02:15:14.880]   It would slow your browser down too much.
[02:15:14.880 --> 02:15:17.840]   My hope is that a really smart company like Google did this,
[02:15:17.840 --> 02:15:20.480]   but if they can't figure out two accounts within their own email system,
[02:15:20.480 --> 02:15:21.120]   then...
[02:15:21.120 --> 02:15:21.600]   I know.
[02:15:21.600 --> 02:15:25.280]   No, I think people are really working on this.
[02:15:26.160 --> 02:15:33.840]   But the cost of doing it probably outweighs, at least so far, the losses.
[02:15:33.840 --> 02:15:39.360]   Okay, but here's one piece of that is that at some level, I, as a consumer,
[02:15:39.360 --> 02:15:39.920]   rather than...
[02:15:39.920 --> 02:15:40.800]   What do we have now?
[02:15:40.800 --> 02:15:46.640]   We have all these scary, scary commercials on Sirius saying that your identity is going to be stolen,
[02:15:46.640 --> 02:15:48.560]   and your mortgage is going to be stolen.
[02:15:48.560 --> 02:15:49.520]   And I think it's so...
[02:15:49.520 --> 02:15:55.040]   So there's a huge industry of fakers who just...
[02:15:55.920 --> 02:15:58.240]   who sell you a fake insurance because it's cheaper for them,
[02:15:58.240 --> 02:16:00.640]   because they're going to take all your grandparents and your parents,
[02:16:00.640 --> 02:16:02.480]   and they're going to make you pay for this stupid service
[02:16:02.480 --> 02:16:05.840]   that actually doesn't do anything because it happens so rarely.
[02:16:05.840 --> 02:16:11.040]   So there is a cost to the economy right now of taking advantage of old people in fools.
[02:16:11.040 --> 02:16:11.760]   Yeah, but these...
[02:16:11.760 --> 02:16:12.560]   Somebody denies you.
[02:16:12.560 --> 02:16:13.040]   It's a cost.
[02:16:13.040 --> 02:16:16.160]   Just as Sony decided, we're not going to spend money to secure our...
[02:16:16.160 --> 02:16:17.360]   Right.
[02:16:17.360 --> 02:16:18.800]   But there's another way to look at this,
[02:16:18.800 --> 02:16:22.880]   which is that rather than buying that scary, scary service,
[02:16:23.520 --> 02:16:28.080]   I could choose to go to the inconvenience or the expense as an individual to say,
[02:16:28.080 --> 02:16:29.760]   "Still my data?
[02:16:29.760 --> 02:16:32.160]   I don't care because I know that everything is okay."
[02:16:32.160 --> 02:16:33.680]   What would that look like?
[02:16:33.680 --> 02:16:34.240]   Right?
[02:16:34.240 --> 02:16:37.040]   And then what you're going to see happen down the line, I think,
[02:16:37.040 --> 02:16:41.040]   is you're going to see that being added on as a benefit to credit cards and other things to make
[02:16:41.040 --> 02:16:43.440]   sure you're secure or there's a consumer value.
[02:16:43.440 --> 02:16:44.720]   But right now there's no choice.
[02:16:44.720 --> 02:16:45.280]   There's no way.
[02:16:45.280 --> 02:16:46.560]   There's no mechanism to do that.
[02:16:46.560 --> 02:16:49.360]   So we sit here and we all say, "Oh, it all got stolen.
[02:16:49.360 --> 02:16:49.680]   I don't know.
[02:16:49.680 --> 02:16:50.400]   It's going to hit me.
[02:16:50.400 --> 02:16:51.120]   It hit me."
[02:16:51.120 --> 02:16:52.880]   Yeah, but we might overstate the threat.
[02:16:52.880 --> 02:16:57.920]   I mean, banking rules changed so that you couldn't lose more than 50 bucks in your credit card,
[02:16:57.920 --> 02:16:58.160]   right?
[02:16:58.160 --> 02:17:00.480]   That made everybody happy.
[02:17:00.480 --> 02:17:04.240]   The credit card companies knew that they were covering their losses with a high interest rate.
[02:17:04.240 --> 02:17:07.360]   They knew that their losses was going to exceed their revenue, so they were okay.
[02:17:07.360 --> 02:17:10.320]   You were okay because you knew your losses would be limited.
[02:17:10.320 --> 02:17:12.080]   But now you're not okay.
[02:17:12.080 --> 02:17:19.920]   Your losses on the credit card are nothing compared to your losses from identity theft
[02:17:19.920 --> 02:17:22.320]   and the time and effort it takes to clean that up.
[02:17:22.320 --> 02:17:27.440]   And as that happens to more people, there are external costs that are borne by employers,
[02:17:27.440 --> 02:17:37.440]   by insurers, and by even municipalities that we will have to pay for somehow,
[02:17:37.440 --> 02:17:38.400]   somewhere.
[02:17:38.400 --> 02:17:43.040]   And it's not going to be as simple as working over money to one entity.
[02:17:43.040 --> 02:17:50.000]   And that's, I mean, a lack of focus on security is going to start becoming
[02:17:51.040 --> 02:17:53.840]   a huge externality that we need to deal with.
[02:17:53.840 --> 02:17:55.200]   At some point, we'll hit a tipping point.
[02:17:55.200 --> 02:17:58.880]   Here's the stats on identity theft and fraud complaints.
[02:17:58.880 --> 02:18:08.800]   And as you can see, they are going up in 2016, $16 billion was stolen from 15.4 million US consumers.
[02:18:08.800 --> 02:18:14.480]   I don't know if that's identity theft or credit card fraud.
[02:18:14.480 --> 02:18:16.800]   I think that would include credit card fraud as well.
[02:18:18.880 --> 02:18:26.240]   And other things. So two things can happen. Somebody can defraud you by using your credit.
[02:18:26.240 --> 02:18:29.040]   But far more common is they steal your credit card.
[02:18:29.040 --> 02:18:31.520]   It's a lot easier for a bad guy.
[02:18:31.520 --> 02:18:34.960]   And the credit company loses. And then you report it in time and the credit company loses money.
[02:18:34.960 --> 02:18:37.440]   And maybe they do. Maybe they don't. Maybe the merchant.
[02:18:37.440 --> 02:18:39.600]   Now the merchant gets dinged. It didn't used to be.
[02:18:39.600 --> 02:18:45.200]   Whoever has the least security gets dinged, the merchant may end up spending the bulk of the cost.
[02:18:45.200 --> 02:18:47.680]   But it's spread out to the point where nobody's freaked out.
[02:18:47.680 --> 02:18:51.440]   But start thinking about what happens.
[02:18:51.440 --> 02:18:53.280]   Go ahead, Jeff.
[02:18:53.280 --> 02:18:56.320]   I was just going to channel you Stacy.
[02:18:56.320 --> 02:18:58.720]   This is a need for regulation. It's a real protection.
[02:18:58.720 --> 02:19:01.120]   Then there is, by the way, there's a lot of regulation in this.
[02:19:01.120 --> 02:19:01.840]   That's why you don't.
[02:19:01.840 --> 02:19:04.000]   And it's not just consumer protection.
[02:19:04.000 --> 02:19:09.280]   They're real like, if my identity is stolen and I have a very good credit rating.
[02:19:09.280 --> 02:19:12.800]   So I am a lovely consumer for lots of people. I can go buy a house.
[02:19:12.800 --> 02:19:13.920]   I can go do all this.
[02:19:13.920 --> 02:19:17.280]   But imagine now that I've put a credit freeze on my account,
[02:19:17.920 --> 02:19:20.320]   suddenly I'm less likely to go.
[02:19:20.320 --> 02:19:23.680]   I'm only going to get credit on things that really matter, like a house.
[02:19:23.680 --> 02:19:30.080]   So there's a lot of things that I'm just not going to buy if I can't buy it outright.
[02:19:30.080 --> 02:19:31.440]   And then there's also.
[02:19:31.440 --> 02:19:32.880]   Here's an interesting statistic.
[02:19:32.880 --> 02:19:40.800]   Most of this misinformation misuse has been used to get government benefits.
[02:19:40.800 --> 02:19:41.520]   49%.
[02:19:43.600 --> 02:19:49.920]   15% credit card fraud, 10% phone or utilities fraud, 5.9% bank fraud.
[02:19:49.920 --> 02:19:55.440]   Attempted identity theft, 3.7%, loan fraud, 3.5%.
[02:19:55.440 --> 02:20:02.160]   So the almost half is somebody just saying, I want to get social security.
[02:20:02.160 --> 02:20:04.880]   Wait, is that someone's so is that
[02:20:04.880 --> 02:20:10.400]   stolen from like buying an online or is that something like because a lot of really
[02:20:10.960 --> 02:20:14.800]   crappy parents use their kids or their kids.
[02:20:14.800 --> 02:20:16.560]   I don't know if they can break.
[02:20:16.560 --> 02:20:16.960]   I know.
[02:20:16.960 --> 02:20:18.720]   I don't know if this is complaints.
[02:20:18.720 --> 02:20:19.920]   This is based on the complaints.
[02:20:19.920 --> 02:20:20.400]   Got it.
[02:20:20.400 --> 02:20:23.440]   Identity theft and fraud complaints for 2015.
[02:20:23.440 --> 02:20:27.280]   So I would say if it's a parent stealing their kids stuff,
[02:20:27.280 --> 02:20:29.040]   there probably was no complaint filed.
[02:20:29.040 --> 02:20:31.120]   But maybe the government filed a complaint eventually.
[02:20:31.120 --> 02:20:32.960]   No, the government got filed a complaint or
[02:20:32.960 --> 02:20:35.520]   I just.
[02:20:36.880 --> 02:20:41.520]   Taking someone's government benefits from a social security theft seems like,
[02:20:41.520 --> 02:20:44.640]   I guess it takes all kinds.
[02:20:44.640 --> 02:20:46.560]   It doesn't seem like it'd be super lucrative.
[02:20:46.560 --> 02:20:49.200]   I guess if you got a bunch of people.
[02:20:49.200 --> 02:20:51.440]   I guess what's interesting about these numbers is
[02:20:51.440 --> 02:20:56.000]   it's clearly not reached the level of concern yet or we would do something about it.
[02:20:56.000 --> 02:20:58.640]   I think we're getting there.
[02:20:58.640 --> 02:21:04.720]   I think we may get there these breeds, but it's infuriating because Equifax had a
[02:21:04.720 --> 02:21:07.520]   higher duty to protect us and did not.
[02:21:07.520 --> 02:21:11.840]   They didn't even show much shame or regret or remorse.
[02:21:11.840 --> 02:21:13.040]   That's the worst of them.
[02:21:13.040 --> 02:21:15.600]   They didn't do their job.
[02:21:15.600 --> 02:21:17.840]   They had one job.
[02:21:17.840 --> 02:21:19.920]   If they're going to collect that information to protect the information,
[02:21:19.920 --> 02:21:21.520]   they clearly didn't do a very good job of that.
[02:21:21.520 --> 02:21:24.720]   But the consequences may not be.
[02:21:24.720 --> 02:21:30.480]   I think that's really what happens.
[02:21:30.480 --> 02:21:33.120]   Once the consequences of the financial industry is high enough,
[02:21:33.120 --> 02:21:34.480]   they'll figure out a solution.
[02:21:34.480 --> 02:21:35.920]   I think there are solutions out there.
[02:21:35.920 --> 02:21:42.240]   Interestingly, cyber crime complaints have actually been going down a little bit.
[02:21:42.240 --> 02:21:44.640]   They were higher in 2011.
[02:21:44.640 --> 02:21:46.800]   I wonder if that's because people...
[02:21:46.800 --> 02:21:48.800]   Wait, what is a cyber crime complaint?
[02:21:48.800 --> 02:21:49.360]   What is that?
[02:21:49.360 --> 02:21:51.280]   It is a crime complaints center.
[02:21:51.280 --> 02:21:55.360]   I don't know what that is.
[02:21:55.360 --> 02:22:01.600]   Top 10 states by percent of US cyber crime victims, 14 percent from California.
[02:22:02.480 --> 02:22:03.920]   I mean, that could be...
[02:22:03.920 --> 02:22:08.240]   I sent somebody in Nigeria my bank account, or it could be...
[02:22:08.240 --> 02:22:11.440]   I mean, that could be stalking someone on Facebook.
[02:22:11.440 --> 02:22:12.640]   I don't know.
[02:22:12.640 --> 02:22:14.080]   I'm like, "What is this cyber crime?"
[02:22:14.080 --> 02:22:20.000]   This page is from the triple-i.org, the Insurance Information Institute.
[02:22:20.000 --> 02:22:22.960]   And a lot of these numbers come from reputable sources,
[02:22:22.960 --> 02:22:24.320]   including the Federal Trade Commission.
[02:22:24.320 --> 02:22:26.000]   Who's reputable anymore?
[02:22:26.000 --> 02:22:26.400]   I know.
[02:22:26.400 --> 02:22:27.920]   I know.
[02:22:27.920 --> 02:22:29.520]   Everybody's got an axe to grind.
[02:22:29.520 --> 02:22:30.800]   It's all fake news.
[02:22:30.800 --> 02:22:32.560]   You know, Leo, it could be worse.
[02:22:32.560 --> 02:22:33.520]   It could be worse.
[02:22:33.520 --> 02:22:33.920]   We got it.
[02:22:33.920 --> 02:22:35.040]   You could not be...
[02:22:35.040 --> 02:22:35.840]   You could not be Denny.
[02:22:35.840 --> 02:22:36.720]   You could be Denny's.
[02:22:36.720 --> 02:22:37.360]   I could be...
[02:22:37.360 --> 02:22:39.920]   I could be eating the Early Bird Specialist Denny's right now.
[02:22:39.920 --> 02:22:40.400]   Yeah.
[02:22:40.400 --> 02:22:40.640]   Yeah.
[02:22:40.640 --> 02:22:42.880]   In fact, I'm on my way.
[02:22:42.880 --> 02:22:44.000]   You have seen, haven't you?
[02:22:44.000 --> 02:22:45.840]   I have what?
[02:22:45.840 --> 02:22:47.040]   Are you having seen?
[02:22:47.040 --> 02:22:48.080]   No, what happened?
[02:22:48.080 --> 02:22:49.440]   Denny's has a new mascot.
[02:22:49.440 --> 02:22:50.560]   Oh, Lord.
[02:22:50.560 --> 02:22:51.680]   Oh, yeah.
[02:22:51.680 --> 02:22:52.480]   Yeah, yeah, yeah.
[02:22:52.480 --> 02:22:53.760]   It's not named Leo, is he?
[02:22:53.760 --> 02:22:55.520]   No, no, no, no.
[02:22:55.520 --> 02:22:56.320]   It's worse than that.
[02:22:56.320 --> 02:22:58.640]   It's not on the rundown.
[02:22:58.640 --> 02:23:00.560]   Denny's mascot.
[02:23:00.560 --> 02:23:01.280]   Oh, my God.
[02:23:01.280 --> 02:23:02.880]   It's a sausage.
[02:23:02.880 --> 02:23:04.560]   No, it's poop.
[02:23:04.560 --> 02:23:06.480]   Oh, it's a dooky.
[02:23:06.480 --> 02:23:08.320]   Yes.
[02:23:08.320 --> 02:23:11.040]   The entire internet is going crazy.
[02:23:11.040 --> 02:23:12.400]   The Denny's mascot.
[02:23:12.400 --> 02:23:13.520]   Here's the tweet.
[02:23:13.520 --> 02:23:15.360]   The Denny's turd is here with lunch.
[02:23:15.360 --> 02:23:18.080]   Oh, Lord.
[02:23:18.080 --> 02:23:20.960]   Oh, Denny's...
[02:23:20.960 --> 02:23:22.560]   That's even worse than Bodega.
[02:23:22.560 --> 02:23:24.320]   What is he supposed to be?
[02:23:24.320 --> 02:23:26.160]   I have no idea, but it's a turd.
[02:23:26.160 --> 02:23:28.080]   You can't not see the turd now.
[02:23:28.080 --> 02:23:29.760]   It's a turd with a megaphone.
[02:23:29.760 --> 02:23:31.280]   It's a breakfast link, right?
[02:23:31.280 --> 02:23:32.640]   It's a breakfast link.
[02:23:32.640 --> 02:23:33.200]   Oh, man.
[02:23:33.200 --> 02:23:37.280]   Actually, he's been around since 2014.
[02:23:37.280 --> 02:23:37.840]   Oh, yes?
[02:23:37.840 --> 02:23:38.240]   Yeah.
[02:23:38.240 --> 02:23:41.120]   But the social media startup just happened.
[02:23:41.120 --> 02:23:41.680]   Just hit.
[02:23:41.680 --> 02:23:42.240]   Oh, well.
[02:23:42.240 --> 02:23:43.120]   Yeah, that's hit.
[02:23:43.120 --> 02:23:44.720]   Oh, boy.
[02:23:44.720 --> 02:23:47.040]   See what happens.
[02:23:47.040 --> 02:23:48.160]   Wow.
[02:23:48.160 --> 02:23:49.680]   Well, I've learned something today.
[02:23:49.680 --> 02:23:53.840]   I don't know what it is.
[02:23:53.840 --> 02:23:54.080]   I was...
[02:23:54.080 --> 02:23:56.480]   I can bring the show down any time.
[02:23:56.480 --> 02:23:56.960]   He could be worse.
[02:23:56.960 --> 02:23:58.400]   He could be named little Leo.
[02:23:59.440 --> 02:24:00.000]   Yes.
[02:24:00.000 --> 02:24:00.880]   The missing link.
[02:24:00.880 --> 02:24:04.080]   That's pretty funny.
[02:24:04.080 --> 02:24:04.720]   He's...
[02:24:04.720 --> 02:24:07.200]   This spring he introduced Denny's on demand.
[02:24:07.200 --> 02:24:08.400]   His name is Sausage.
[02:24:08.400 --> 02:24:10.560]   Really?
[02:24:10.560 --> 02:24:10.800]   Yeah.
[02:24:10.800 --> 02:24:13.040]   You want to watch the video?
[02:24:13.040 --> 02:24:14.080]   Nope.
[02:24:14.080 --> 02:24:14.400]   Nope.
[02:24:14.400 --> 02:24:16.240]   I want to get to our things,
[02:24:16.240 --> 02:24:18.720]   because I am hungry and have to go to the bathroom.
[02:24:18.720 --> 02:24:19.040]   All right.
[02:24:19.040 --> 02:24:20.320]   This thing's your butt lose your...
[02:24:20.320 --> 02:24:22.720]   Well, I thought you were going to lose your appetite here.
[02:24:22.720 --> 02:24:23.200]   Oh.
[02:24:23.200 --> 02:24:23.440]   Nope.
[02:24:23.440 --> 02:24:25.440]   Before...
[02:24:25.440 --> 02:24:26.000]   Let's do it.
[02:24:26.000 --> 02:24:27.200]   Why don't we do it?
[02:24:27.200 --> 02:24:29.280]   Stacey, what is your thing?
[02:24:29.280 --> 02:24:30.960]   Wait, do you have an ad?
[02:24:30.960 --> 02:24:31.360]   Or should...
[02:24:31.360 --> 02:24:32.320]   No, I did the ads.
[02:24:32.320 --> 02:24:33.600]   Oh, okay.
[02:24:33.600 --> 02:24:34.720]   Oh, hot diggity.
[02:24:34.720 --> 02:24:36.160]   I'll call that all three of them.
[02:24:36.160 --> 02:24:37.120]   All right.
[02:24:37.120 --> 02:24:38.240]   I can't find the link to it.
[02:24:38.240 --> 02:24:40.000]   But this is...
[02:24:40.000 --> 02:24:42.160]   Oh, now.
[02:24:42.160 --> 02:24:43.600]   Now I'm not prepared.
[02:24:43.600 --> 02:24:44.720]   Oh, you are right.
[02:24:44.720 --> 02:24:46.320]   It's not ready for such a quick transition.
[02:24:46.320 --> 02:24:48.720]   I was going to make my thing the Note 8,
[02:24:48.720 --> 02:24:49.280]   but I really...
[02:24:49.280 --> 02:24:50.880]   I guess I've kind of already talked about it.
[02:24:50.880 --> 02:24:53.920]   The only flaw at all is the weird fingerprint reader,
[02:24:53.920 --> 02:24:55.360]   but it's a beautiful phone.
[02:24:55.360 --> 02:24:55.680]   Okay.
[02:24:55.680 --> 02:24:56.320]   Second flaw.
[02:24:56.320 --> 02:24:56.800]   You're right.
[02:24:56.800 --> 02:24:57.440]   It's tall.
[02:24:57.440 --> 02:25:01.200]   It's weirdly tall, but much like the Samsung Galaxy S8.
[02:25:01.200 --> 02:25:04.080]   In fact, it's really pretty much identical to the S8
[02:25:04.080 --> 02:25:07.360]   plus with the exception of a dual lens camera,
[02:25:07.360 --> 02:25:08.240]   which is quite good.
[02:25:08.240 --> 02:25:11.920]   And it has the zoom just like the Apple iPhone 7 plus
[02:25:11.920 --> 02:25:16.080]   and a stylus that lets me write down notes,
[02:25:16.080 --> 02:25:18.320]   even without unlocking the phone.
[02:25:18.320 --> 02:25:19.840]   I'm a Note fan.
[02:25:19.840 --> 02:25:20.880]   I have been since day one.
[02:25:20.880 --> 02:25:24.480]   It's got a Type-C charger,
[02:25:24.480 --> 02:25:25.840]   and it has a headphone jack.
[02:25:26.720 --> 02:25:29.040]   And I'm going to take it to Europe with me.
[02:25:29.040 --> 02:25:33.200]   Even though I can't use Google Fi with it,
[02:25:33.200 --> 02:25:34.080]   which is too bad.
[02:25:34.080 --> 02:25:35.920]   Wish I could.
[02:25:35.920 --> 02:25:37.440]   Wish I could.
[02:25:37.440 --> 02:25:40.240]   Now, Stacy, did I stall along enough?
[02:25:40.240 --> 02:25:41.120]   No, you did.
[02:25:41.120 --> 02:25:42.240]   That was beautiful.
[02:25:42.240 --> 02:25:42.640]   All right.
[02:25:42.640 --> 02:25:45.680]   So I got to get us on the thingy.
[02:25:45.680 --> 02:25:46.000]   All right.
[02:25:46.000 --> 02:25:47.520]   Behind me.
[02:25:47.520 --> 02:25:49.200]   Ooh, a lamp.
[02:25:49.200 --> 02:25:54.160]   This is the new Sylvania Smart Plus LEDs.
[02:25:54.160 --> 02:25:55.760]   Now, this one that I've linked to,
[02:25:55.760 --> 02:25:58.800]   that works with Amazon Echo in Google Home.
[02:25:58.800 --> 02:26:02.720]   This one that I'm playing with works with the HomeKit.
[02:26:02.720 --> 02:26:03.760]   Oh, nice.
[02:26:03.760 --> 02:26:04.960]   So, finally.
[02:26:04.960 --> 02:26:05.680]   Yes.
[02:26:05.680 --> 02:26:06.240]   So, and the--
[02:26:06.240 --> 02:26:07.600]   Oh, that was cool.
[02:26:07.600 --> 02:26:09.040]   Okay.
[02:26:09.040 --> 02:26:11.840]   So, opera lor third, it not only changed the light,
[02:26:11.840 --> 02:26:12.720]   it changed the lamp.
[02:26:12.720 --> 02:26:15.120]   Oh, that's just because it's a glass lamp.
[02:26:15.120 --> 02:26:17.360]   It's a blue glass lamp.
[02:26:17.360 --> 02:26:19.360]   Oh, push all y'all.
[02:26:19.360 --> 02:26:20.640]   Okay.
[02:26:20.640 --> 02:26:21.520]   Well, there you go.
[02:26:21.520 --> 02:26:22.000]   You're--
[02:26:22.000 --> 02:26:23.360]   It's so fancy.
[02:26:23.360 --> 02:26:23.760]   Fancy.
[02:26:23.760 --> 02:26:27.360]   You look like Happy Hotpoint demonstrating that.
[02:26:27.360 --> 02:26:31.600]   I don't know what you're talking about.
[02:26:31.600 --> 02:26:33.920]   Jeff does.
[02:26:33.920 --> 02:26:34.320]   Good.
[02:26:34.320 --> 02:26:34.720]   It's good.
[02:26:34.720 --> 02:26:35.920]   Should we look up Happy Hotpoint?
[02:26:35.920 --> 02:26:38.000]   Yeah, you know who Happy Hotpoint was.
[02:26:38.000 --> 02:26:38.400]   Okay.
[02:26:38.400 --> 02:26:40.000]   I'm going to show you how this works on HomeKit.
[02:26:40.000 --> 02:26:40.400]   Yes.
[02:26:40.400 --> 02:26:41.520]   So, this is dimming.
[02:26:41.520 --> 02:26:42.480]   Ooh.
[02:26:42.480 --> 02:26:44.640]   There it goes.
[02:26:44.640 --> 02:26:47.840]   You just pointed that Apple didn't say anything about the HomePod at there.
[02:26:47.840 --> 02:26:48.160]   Yes.
[02:26:48.160 --> 02:26:49.280]   I was very sad.
[02:26:49.280 --> 02:26:52.240]   I felt like maybe this is bad news for HomePod.
[02:26:52.240 --> 02:26:54.400]   And it does 1600 RGB colors.
[02:26:54.400 --> 02:26:55.520]   And--
[02:26:55.520 --> 02:26:56.480]   Wait a minute.
[02:26:56.480 --> 02:26:56.960]   Wait a minute.
[02:26:56.960 --> 02:26:57.760]   It does--
[02:26:57.760 --> 02:26:58.240]   But--
[02:26:58.240 --> 02:26:59.520]   That's a strange number.
[02:26:59.520 --> 02:27:00.720]   1600, 16000.
[02:27:00.720 --> 02:27:01.840]   It doesn't do 16--
[02:27:01.840 --> 02:27:03.040]   Must do 16000.
[02:27:03.040 --> 02:27:04.160]   16000.
[02:27:04.160 --> 02:27:04.640]   That's what it means.
[02:27:04.640 --> 02:27:04.960]   Sorry.
[02:27:04.960 --> 02:27:05.840]   Too many zeros.
[02:27:05.840 --> 02:27:08.160]   I'm looking at something else.
[02:27:08.160 --> 02:27:09.120]   16250.
[02:27:09.120 --> 02:27:09.200]   I'm looking at--
[02:27:09.200 --> 02:27:10.080]   16250.
[02:27:10.080 --> 02:27:10.560]   Turn it over.
[02:27:10.560 --> 02:27:10.960]   Exactly.
[02:27:10.960 --> 02:27:14.400]   And even against my favorite color,
[02:27:14.400 --> 02:27:17.440]   which is that turquoise that the original hues didn't do,
[02:27:17.440 --> 02:27:19.200]   this used to be very difficult.
[02:27:19.200 --> 02:27:19.920]   Now it's not.
[02:27:19.920 --> 02:27:22.880]   So, this is the Sylvania.
[02:27:22.880 --> 02:27:25.920]   It's a reasonably priced hubless light bulb.
[02:27:25.920 --> 02:27:29.760]   And it is available coming next Tuesday.
[02:27:29.760 --> 02:27:32.160]   65,536.
[02:27:32.160 --> 02:27:35.040]   Two to the 16th colors.
[02:27:35.040 --> 02:27:35.760]   That's my guess.
[02:27:35.760 --> 02:27:39.040]   Could be just 1600, I don't know.
[02:27:39.040 --> 02:27:41.680]   And oh, you can control it via Siri.
[02:27:41.680 --> 02:27:43.280]   Can you say?
[02:27:43.280 --> 02:27:44.160]   Give me a blue.
[02:27:44.160 --> 02:27:45.840]   I believe so.
[02:27:45.840 --> 02:27:48.240]   I did all this last week,
[02:27:48.240 --> 02:27:50.640]   and then I left home and forgot all of it.
[02:27:50.640 --> 02:27:51.600]   You like the better than the hue?
[02:27:51.600 --> 02:27:56.640]   This is nice because it doesn't have a hub.
[02:27:56.640 --> 02:27:59.120]   Actually, it's two to the eighth.
[02:27:59.120 --> 02:28:01.200]   It's 16000.
[02:28:01.200 --> 02:28:02.400]   There you go.
[02:28:02.400 --> 02:28:03.680]   I gave it too many colors.
[02:28:03.680 --> 02:28:04.320]   Two to the eighth.
[02:28:04.320 --> 02:28:06.640]   I mean, some of these colors--
[02:28:06.640 --> 02:28:07.440]   Two to the eighth.
[02:28:07.440 --> 02:28:08.640]   No, two to the eighth.
[02:28:08.640 --> 02:28:09.600]   Two to the eighth.
[02:28:09.600 --> 02:28:10.640]   Two to the eighth.
[02:28:10.640 --> 02:28:11.120]   Never mind.
[02:28:11.760 --> 02:28:14.960]   Your biggest test in LEDs is usually the turquoise.
[02:28:14.960 --> 02:28:15.280]   To the--
[02:28:15.280 --> 02:28:16.080]   How many bits is it?
[02:28:16.080 --> 02:28:16.560]   Two to the--
[02:28:16.560 --> 02:28:21.840]   Two to the 16th, right?
[02:28:21.840 --> 02:28:22.080]   Yeah.
[02:28:22.080 --> 02:28:23.440]   Yeah.
[02:28:23.440 --> 02:28:24.400]   No, no, no.
[02:28:24.400 --> 02:28:25.280]   To the 15th.
[02:28:25.280 --> 02:28:28.000]   It is a--
[02:28:28.000 --> 02:28:29.040]   This one is a--
[02:28:29.040 --> 02:28:30.000]   It's a 2, 2, 3, 4.
[02:28:30.000 --> 02:28:30.000]   --2, 2, 3, 4.
[02:28:30.000 --> 02:28:30.800]   That's it.
[02:28:30.800 --> 02:28:31.040]   That's--
[02:28:31.040 --> 02:28:31.680]   --the needs of a case.
[02:28:31.680 --> 02:28:32.560]   Two to the 15th.
[02:28:32.560 --> 02:28:34.080]   All right.
[02:28:34.080 --> 02:28:36.160]   For the people asking,
[02:28:36.160 --> 02:28:37.680]   I'm going to answer your question while Leo
[02:28:37.680 --> 02:28:40.720]   goes off in his little binary challenge.
[02:28:40.720 --> 02:28:42.320]   Is it Zigbee or Z-Wave?
[02:28:42.320 --> 02:28:44.480]   It is Bluetooth.
[02:28:44.480 --> 02:28:45.120]   What?
[02:28:45.120 --> 02:28:46.560]   What?
[02:28:46.560 --> 02:28:47.280]   I know.
[02:28:47.280 --> 02:28:47.680]   What?
[02:28:47.680 --> 02:28:50.000]   It's Bluetooth, so it works directly with your iPhone.
[02:28:50.000 --> 02:28:55.200]   And then the Amazon one, I believe, is Wi-Fi,
[02:28:55.200 --> 02:28:56.720]   which is why it doesn't need a hub.
[02:28:56.720 --> 02:28:58.560]   If it had Zigbee, it would need a hub.
[02:28:58.560 --> 02:28:59.120]   Oh, yeah.
[02:28:59.120 --> 02:29:00.560]   So--
[02:29:00.560 --> 02:29:01.760]   Could be two to the 13th.
[02:29:01.760 --> 02:29:03.600]   That'd be 8,192.
[02:29:03.600 --> 02:29:07.600]   Or two to the 12th.
[02:29:07.600 --> 02:29:09.200]   That'd be 4,096.
[02:29:10.000 --> 02:29:13.440]   But I think it's two to the 14th, 16,384.
[02:29:13.440 --> 02:29:14.160]   That'd be my guess.
[02:29:14.160 --> 02:29:15.440]   That'd be definitely--
[02:29:15.440 --> 02:29:16.640]   Definitely two to the 14th.
[02:29:16.640 --> 02:29:17.120]   Definitely--
[02:29:17.120 --> 02:29:18.240]   Sheldon would know.
[02:29:18.240 --> 02:29:19.600]   --Tin Sheldon would know.
[02:29:19.600 --> 02:29:21.200]   Definitely two to the 14th.
[02:29:21.200 --> 02:29:21.680]   Oh, wait.
[02:29:21.680 --> 02:29:22.320]   This one.
[02:29:22.320 --> 02:29:23.120]   OK, so that--
[02:29:23.120 --> 02:29:23.680]   I'm sorry.
[02:29:23.680 --> 02:29:24.800]   I lied to you.
[02:29:24.800 --> 02:29:26.240]   The one that I linked to,
[02:29:26.240 --> 02:29:29.040]   which is so that HomeKit 1 is Bluetooth.
[02:29:29.040 --> 02:29:31.600]   The one that I linked to is actually Zigbee.
[02:29:31.600 --> 02:29:34.160]   So you have to work with the Echo.
[02:29:34.160 --> 02:29:35.280]   You have to use a hub.
[02:29:35.280 --> 02:29:36.400]   I'm so sorry, you guys.
[02:29:36.400 --> 02:29:37.760]   See?
[02:29:37.760 --> 02:29:39.040]   This one is--
[02:29:40.000 --> 02:29:42.480]   --the Smart Plus that talks about HomeKit.
[02:29:42.480 --> 02:29:46.720]   This is why IoT is in trouble.
[02:29:46.720 --> 02:29:47.280]   Is a nightmare.
[02:29:47.280 --> 02:29:48.160]   It's a nightmare.
[02:29:48.160 --> 02:29:52.640]   But I trust no one to tell me what happy hot point--
[02:29:52.640 --> 02:29:54.720]   Thank God we have happy hot point.
[02:29:54.720 --> 02:29:56.000]   We have happy hot point.
[02:29:56.000 --> 02:29:56.160]   Yeah.
[02:29:56.160 --> 02:29:57.840]   Run down, you saw.
[02:29:57.840 --> 02:30:01.040]   "Series, schedule my living room lights to turn on at 6 p.m. tonight
[02:30:01.040 --> 02:30:02.720]   in a lovely blue shade."
[02:30:02.720 --> 02:30:05.040]   That is too much.
[02:30:05.040 --> 02:30:07.360]   That is too much for Siri today.
[02:30:07.920 --> 02:30:10.240]   Siri says, "Sighs for you."
[02:30:10.240 --> 02:30:12.160]   That's too much for anybody.
[02:30:12.160 --> 02:30:13.280]   The only company that can do that
[02:30:13.280 --> 02:30:14.640]   is a company called Josh.ai,
[02:30:14.640 --> 02:30:15.600]   but they're professional.
[02:30:15.600 --> 02:30:16.080]   So--
[02:30:16.080 --> 02:30:16.560]   Oh, really?
[02:30:16.560 --> 02:30:17.600]   Yeah.
[02:30:17.600 --> 02:30:18.560]   And who is this Josh?
[02:30:18.560 --> 02:30:20.720]   Who is this Josh?
[02:30:20.720 --> 02:30:22.000]   It is a company called Josh. AI.
[02:30:22.000 --> 02:30:22.560]   They do--
[02:30:22.560 --> 02:30:24.640]   they built their own voice recognition.
[02:30:24.640 --> 02:30:25.120]   Oh!
[02:30:25.120 --> 02:30:26.800]   I'm a better one.
[02:30:26.800 --> 02:30:30.720]   ♪ Every year you'll holiday with hot boy ♪
[02:30:30.720 --> 02:30:32.320]   ♪ Ooh, ooh, ooh ♪
[02:30:32.320 --> 02:30:36.000]   ♪ The dishwasher stops all your dishwashing drudgery ♪
[02:30:36.000 --> 02:30:37.760]   Now, Stacy, do you know who that is?
[02:30:37.760 --> 02:30:39.120]   Someone would--
[02:30:39.120 --> 02:30:39.680]   Any dude?
[02:30:39.680 --> 02:30:40.640]   ♪ Woke, woke, woke ♪
[02:30:40.640 --> 02:30:41.760]   Look, plus.
[02:30:41.760 --> 02:30:42.320]   All right.
[02:30:42.320 --> 02:30:42.720]   Plus.
[02:30:42.720 --> 02:30:44.400]   ♪ Every day the heart will be ♪
[02:30:44.400 --> 02:30:45.760]   Uh, Julie Andrews?
[02:30:45.760 --> 02:30:46.160]   No.
[02:30:46.160 --> 02:30:46.720]   It looks--
[02:30:46.720 --> 02:30:47.120]   Close.
[02:30:47.120 --> 02:30:49.200]   I don't know.
[02:30:49.200 --> 02:30:51.280]   ♪ The curator with wonderful problems ♪
[02:30:51.280 --> 02:30:53.120]   You'd be happy to be associated with this person.
[02:30:53.120 --> 02:30:53.600]   She's--
[02:30:53.600 --> 02:30:54.080]   She was--
[02:30:54.080 --> 02:30:55.520]   ♪ Woke, woke, woke, woke ♪
[02:30:55.520 --> 02:30:57.360]   Look, actually, you kind of remind me of her.
[02:30:57.360 --> 02:30:58.880]   Yes.
[02:30:58.880 --> 02:31:01.280]   Mary Tyler Moore was happy hot boy.
[02:31:01.280 --> 02:31:02.720]   ♪ Deater, reater, reater ♪
[02:31:02.720 --> 02:31:03.920]   That's her dancing.
[02:31:03.920 --> 02:31:05.760]   ♪ The only on the end have ♪
[02:31:05.760 --> 02:31:07.920]   ♪ And then there I am ♪
[02:31:07.920 --> 02:31:12.240]   ♪ Your ♪
[02:31:12.240 --> 02:31:13.120]   Wow.
[02:31:13.120 --> 02:31:13.440]   Wow.
[02:31:13.440 --> 02:31:17.280]   Aren't you sorry you worked with two old men?
[02:31:17.280 --> 02:31:18.640]   [LAUGHTER]
[02:31:18.640 --> 02:31:19.200]   Oh, yes.
[02:31:19.200 --> 02:31:20.080]   For many reasons.
[02:31:20.080 --> 02:31:22.240]   I'm like, I'm not going to lie.
[02:31:22.240 --> 02:31:24.080]   There are times where I'm like, huh.
[02:31:24.080 --> 02:31:26.240]   Questioning my choices right now.
[02:31:26.240 --> 02:31:28.000]   It's as bad as it could get.
[02:31:28.000 --> 02:31:29.520]   It's really as bad as it could get.
[02:31:29.520 --> 02:31:31.920]   But you can't get mad about Mary Tyler Moore.
[02:31:31.920 --> 02:31:32.720]   It's impossible.
[02:31:32.720 --> 02:31:32.960]   No.
[02:31:32.960 --> 02:31:34.320]   No.
[02:31:35.360 --> 02:31:37.920]   Who were those guys in the muppets?
[02:31:37.920 --> 02:31:40.960]   Oh, the critics?
[02:31:40.960 --> 02:31:41.280]   Yeah.
[02:31:41.280 --> 02:31:42.000]   Yeah.
[02:31:42.000 --> 02:31:42.560]   Yeah.
[02:31:42.560 --> 02:31:43.040]   Yeah.
[02:31:43.040 --> 02:31:43.600]   That's who you go.
[02:31:43.600 --> 02:31:45.680]   Those who are my favorite people.
[02:31:45.680 --> 02:31:46.400]   Oh, see?
[02:31:46.400 --> 02:31:48.160]   No wonder you like working with us.
[02:31:48.160 --> 02:31:48.640]   There we go.
[02:31:48.640 --> 02:31:49.600]   [LAUGHTER]
[02:31:49.600 --> 02:31:50.640]   Glutton for punishment.
[02:31:50.640 --> 02:31:52.400]   [LAUGHTER]
[02:31:52.400 --> 02:31:57.120]   So without further ado, Mr. Statler, do you ever review?
[02:31:57.120 --> 02:31:59.200]   [LAUGHTER]
[02:31:59.200 --> 02:32:00.880]   Well, I'm going to cheat here,
[02:32:00.880 --> 02:32:03.040]   because I found this so charming and wonderful
[02:32:04.000 --> 02:32:06.160]   that, and there's a little video if you want it in photo.
[02:32:06.160 --> 02:32:08.960]   Alexis O'Hanian.
[02:32:08.960 --> 02:32:12.320]   And you know who is his fiancé?
[02:32:12.320 --> 02:32:13.840]   Oh, the tennis player.
[02:32:13.840 --> 02:32:14.800]   Lorena.
[02:32:14.800 --> 02:32:15.840]   Serena?
[02:32:15.840 --> 02:32:16.480]   Is it Serena?
[02:32:16.480 --> 02:32:17.040]   Serena.
[02:32:17.040 --> 02:32:17.680]   It's one of the candidates.
[02:32:17.680 --> 02:32:18.640]   Serena, like--
[02:32:18.640 --> 02:32:19.760]   Oh, you're serious?
[02:32:19.760 --> 02:32:21.760]   They named their daughter.
[02:32:21.760 --> 02:32:23.200]   They named their daughter.
[02:32:23.200 --> 02:32:24.800]   It was a daughter, mind you.
[02:32:24.800 --> 02:32:26.800]   Alexis O'Hanian Jr.
[02:32:26.800 --> 02:32:29.200]   Think about it.
[02:32:29.200 --> 02:32:32.800]   And there she is at 8 p.m.
[02:32:33.600 --> 02:32:36.320]   So she named after him, but she's a girl.
[02:32:36.320 --> 02:32:37.280]   It's kind of wonderful.
[02:32:37.280 --> 02:32:38.000]   Yeah.
[02:32:38.000 --> 02:32:39.920]   It takes a while.
[02:32:39.920 --> 02:32:41.200]   You might want to go toward the--
[02:32:41.200 --> 02:32:42.320]   The weather is the most beautiful.
[02:32:42.320 --> 02:32:45.040]   He's snap chatting this while he's driving.
[02:32:45.040 --> 02:32:48.240]   Yeah, that's probably not great.
[02:32:48.240 --> 02:32:48.800]   Yeah.
[02:32:48.800 --> 02:32:50.000]   Oh.
[02:32:50.000 --> 02:32:53.200]   So the founder of Reddit,
[02:32:53.200 --> 02:32:56.960]   and the world champion, tennis player Serena Williams,
[02:32:56.960 --> 02:33:00.640]   and a baby named Alexis.
[02:33:01.600 --> 02:33:02.400]   Oh.
[02:33:02.400 --> 02:33:03.920]   There she is.
[02:33:03.920 --> 02:33:04.480]   This is why--
[02:33:04.480 --> 02:33:05.920]   Oh, she had the baby.
[02:33:05.920 --> 02:33:06.320]   Oh.
[02:33:06.320 --> 02:33:07.040]   Yeah, she had the baby.
[02:33:07.040 --> 02:33:09.120]   She has a girl named Alexis who's named after--
[02:33:09.120 --> 02:33:10.560]   Oh.
[02:33:10.560 --> 02:33:13.040]   So it's Alexis O'Hanian Jr.
[02:33:13.040 --> 02:33:14.640]   6 pounds, 14 ounces.
[02:33:14.640 --> 02:33:15.680]   And--
[02:33:15.680 --> 02:33:17.280]   That's really going to suck for her in this world of--
[02:33:17.280 --> 02:33:17.920]   One grand slam title.
[02:33:17.920 --> 02:33:18.480]   Alexa.
[02:33:18.480 --> 02:33:19.680]   I know.
[02:33:19.680 --> 02:33:23.440]   Name your child anything within A.I.V.X.
[02:33:23.440 --> 02:33:24.000]   At all.
[02:33:24.000 --> 02:33:25.040]   Don't do it.
[02:33:25.040 --> 02:33:26.960]   Don't do it.
[02:33:26.960 --> 02:33:30.240]   Thank you, friends and neighbors.
[02:33:30.960 --> 02:33:31.920]   Lots of fun today.
[02:33:31.920 --> 02:33:33.600]   Oh, boy, aj, Leo.
[02:33:33.600 --> 02:33:36.560]   Jason Howell will be in for me in the next couple of weeks.
[02:33:36.560 --> 02:33:38.240]   I hope you will have a wonderful time.
[02:33:38.240 --> 02:33:42.800]   Look forward to having you in studio on Sunday with Jason Calicanis.
[02:33:42.800 --> 02:33:43.520]   That'll be fun.
[02:33:43.520 --> 02:33:46.560]   I'm coming in San Francisco and then you're ever alert.
[02:33:46.560 --> 02:33:50.640]   I'm the producer said, oh.
[02:33:50.640 --> 02:33:51.280]   I'm thrilled.
[02:33:51.280 --> 02:33:52.160]   Can you do it?
[02:33:52.160 --> 02:33:52.880]   Fantastic.
[02:33:52.880 --> 02:33:53.360]   Thank you.
[02:33:53.360 --> 02:33:53.680]   Yeah.
[02:33:53.680 --> 02:33:56.000]   So I'm going to go up straight up from the airport.
[02:33:57.200 --> 02:33:58.560]   To your place or the not?
[02:33:58.560 --> 02:34:01.920]   Find Jeff at CUNY, the city university of New York,
[02:34:01.920 --> 02:34:04.560]   where he teaches journalism at buzzmachine.com.
[02:34:04.560 --> 02:34:07.440]   And his great books, including Public Parts, What Would Google Do,
[02:34:07.440 --> 02:34:10.000]   Geek's Baring News, are available at Final News.
[02:34:10.000 --> 02:34:11.680]   Final Newstands Everywhere.
[02:34:11.680 --> 02:34:12.960]   And you can find one.
[02:34:12.960 --> 02:34:14.000]   Good luck finding one.
[02:34:14.000 --> 02:34:16.240]   I loved that.
[02:34:16.240 --> 02:34:18.000]   I was watching HBO's The Deuce and they had a big--
[02:34:18.000 --> 02:34:18.960]   The Big--
[02:34:18.960 --> 02:34:21.840]   They faked Times Square, which was very well faked.
[02:34:21.840 --> 02:34:22.320]   And they had--
[02:34:22.320 --> 02:34:25.440]   Remember the news 10 that said "Optimos cigars" in front of it was there.
[02:34:25.440 --> 02:34:26.400]   It was like, wow.
[02:34:26.400 --> 02:34:26.880]   Wow.
[02:34:26.880 --> 02:34:28.800]   I remember that, 1971.
[02:34:28.800 --> 02:34:30.800]   It was worth seeing.
[02:34:30.800 --> 02:34:33.920]   Stacey Higgins-Botham, she is fabulous.
[02:34:33.920 --> 02:34:34.480]   The host--
[02:34:34.480 --> 02:34:35.840]   She puts up with us every week.
[02:34:35.840 --> 02:34:37.200]   That's got to be something.
[02:34:37.200 --> 02:34:39.440]   Host of Stacey and IOT with Kevin Tofel,
[02:34:39.440 --> 02:34:40.160]   which comes--
[02:34:40.160 --> 02:34:41.360]   Is recorded right before the show,
[02:34:41.360 --> 02:34:43.920]   but comes out every Thursday?
[02:34:43.920 --> 02:34:44.480]   Is that right?
[02:34:44.480 --> 02:34:45.200]   Yes.
[02:34:45.200 --> 02:34:46.080]   It comes out Thursday.
[02:34:46.080 --> 02:34:46.960]   I don't have--
[02:34:46.960 --> 02:34:48.320]   I don't have Carsten.
[02:34:48.320 --> 02:34:49.680]   I don't have a crack team together.
[02:34:49.680 --> 02:34:50.320]   Oh, you need a Carsten.
[02:34:50.320 --> 02:34:51.920]   You're everybody needs a Carsten.
[02:34:51.920 --> 02:34:52.400]   I know.
[02:34:52.400 --> 02:34:53.280]   You were--
[02:34:53.280 --> 02:34:54.880]   Teaching me how to pronounce words correctly.
[02:34:54.880 --> 02:34:55.360]   Yeah.
[02:34:55.360 --> 02:34:56.480]   Not listening to you anymore.
[02:34:56.480 --> 02:34:58.720]   No, Cuneiform.
[02:34:58.720 --> 02:34:59.520]   That's true.
[02:34:59.520 --> 02:35:02.160]   You can also catch Stacey's newsletter.
[02:35:02.160 --> 02:35:04.800]   In fact, you must subscribe to Stacey's newsletter as I do.
[02:35:04.800 --> 02:35:05.600]   You'll find it at Stacey--
[02:35:05.600 --> 02:35:06.080]   That's what I--
[02:35:06.080 --> 02:35:07.840]   Stacey on IOT.com.
[02:35:07.840 --> 02:35:08.720]   Thank you, Stacey.
[02:35:08.720 --> 02:35:14.320]   We do twig every Wednesday about 130 Pacific, 430 Eastern, 2030 UTC.
[02:35:14.320 --> 02:35:16.640]   Stop by say hi.
[02:35:16.640 --> 02:35:19.440]   If you do, join us in the chat at myrc.twit.tv.
[02:35:19.440 --> 02:35:21.280]   But of course, you can get on to man versions
[02:35:21.280 --> 02:35:22.480]   anywhere you get your podcast.
[02:35:22.480 --> 02:35:24.960]   In fact, here's a sharp idea.
[02:35:24.960 --> 02:35:26.000]   Subscribe.
[02:35:26.000 --> 02:35:28.320]   That way you'll get it each and every episode.
[02:35:28.320 --> 02:35:30.000]   Have a great one.
[02:35:30.000 --> 02:35:31.280]   We'll see you in a couple of weeks.
[02:35:31.280 --> 02:35:32.800]   Bye-bye.
[02:35:32.800 --> 02:35:42.800]   [MUSIC]

