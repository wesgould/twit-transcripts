;FFMETADATA1
title=Ixnay on the Eet-tway
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=379
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.600]   It's time for Twig this week in Google Jeff Jarvis and Stacey Higginbotham both on today.
[00:00:05.600 --> 00:00:06.600]   We're going to great show.
[00:00:06.600 --> 00:00:09.200]   We'll of course talk about Facebook and fake news.
[00:00:09.200 --> 00:00:13.600]   Jeff has some simple proposals that finally I can get behind.
[00:00:13.600 --> 00:00:18.400]   We also some great announcements from Google including a big improvement to Google Translator
[00:00:18.400 --> 00:00:24.200]   and Google Auto and the Google Photos scanner will demonstrate its all coming up next on Twig.
[00:00:24.200 --> 00:00:27.600]   [Music]
[00:00:27.600 --> 00:00:29.600]   NetCasts you love.
[00:00:29.600 --> 00:00:31.600]   From people you trust.
[00:00:31.600 --> 00:00:34.600]   [Music]
[00:00:34.600 --> 00:00:36.600]   This is Twig.
[00:00:36.600 --> 00:00:44.600]   Bandwidth for this week in Google is provided by CashFly, C-A-C-H-E-F-L-Y.com.
[00:00:44.600 --> 00:00:48.600]   [Music]
[00:00:48.600 --> 00:00:56.600]   This is Twig, this week in Google, episode 379, recorded Wednesday November 16th, 2016.
[00:00:56.600 --> 00:01:00.600]   X-Nay on the Eatway.
[00:01:00.600 --> 00:01:03.600]   This week in Google has brought to you by Blue Apron.
[00:01:03.600 --> 00:01:08.600]   Blue Apron will send you fresh, high quality ingredients to cook delicious meals with simple step-by-step instructions
[00:01:08.600 --> 00:01:10.600]   right to your door.
[00:01:10.600 --> 00:01:20.600]   See what's on the menu this week and get your first three meals free with free shipping by going to Blue Apron.com/Twig that's Blue Apron.com/Twig.
[00:01:20.600 --> 00:01:27.600]   And by FreshBooks, the super simple cloud accounting software that's giving thousands of freelancers and small businesses
[00:01:27.600 --> 00:01:30.600]   the tools to save time billing and get paid faster.
[00:01:30.600 --> 00:01:35.600]   Try it free at freshbooks.com/Twig.
[00:01:35.600 --> 00:01:44.600]   It's time for Twig. This week in Google, the show where you can have the latest news from Google, the Googleverse, the cloud, the media, the Facebook, the Twitter
[00:01:44.600 --> 00:01:51.600]   and anything else. And I say this at every show, anything else are esteemed panel wishes to discuss.
[00:01:51.600 --> 00:01:58.600]   Actually, thanks to Stacey Higginbotham, we do a lot more of IoT stuff and I'm really thrilled Stacey's Beat now is IoT.
[00:01:58.600 --> 00:02:04.600]   She has the IoT podcast at IoTpodcast.com. Stacey on IoT and she joins us.
[00:02:04.600 --> 00:02:09.600]   Whenever she's not in town, which is a little strange, hello Stacey.
[00:02:09.600 --> 00:02:11.600]   Sorry about that Leo.
[00:02:11.600 --> 00:02:19.600]   It's okay. I'm just teasing you. You were in the South Bay. You weren't even close to us for structure. How'd that go?
[00:02:19.600 --> 00:02:27.600]   It went really well. Learned a lot of fun things. And then after that, I went to Techonomy down it. Where was it? Half Moon Bay.
[00:02:27.600 --> 00:02:40.600]   Nice. That was fancy. And that was awesome. I actually saw a lot of really, really thought provoking presentations and learned more about Estonia and their Digital ID program, which kind of sounds fun.
[00:02:40.600 --> 00:02:48.600]   I wanted to join that. I was in Estonia a couple of months ago or a month ago and I just didn't get around to it, but you can apply online.
[00:02:48.600 --> 00:02:58.600]   You can. You get a PGP key and a chip embedded in a chip card. It's an ID. It's not citizenship in Estonia. It's E citizenship. It's very interesting.
[00:02:58.600 --> 00:03:04.600]   And you could start a business there. I didn't realize that. You can do everything there from your computer online.
[00:03:04.600 --> 00:03:15.600]   And can you move there? That would be physical world. Yeah. See. And I'm not sure I want to move there to be honest with you because Russia's right over the border.
[00:03:15.600 --> 00:03:25.600]   And she really did a bad job selling the country. She's like, we, it's cold and dark. So we have nothing to do but program. I'm like, oh, yeah, I kind of place.
[00:03:25.600 --> 00:03:40.600]   Talon is a beautiful city. Hey, that's Jeff Jarvis, professor of journalism, a city in University of New York or CUNY as it's known to the people in the environs. He is at Buzzmachine.com, writer of many fabulous books, including what would Google do.
[00:03:40.600 --> 00:03:52.600]   I almost said, what would public parts do? But that's conflating two different books. There it is. I see it. And it's on my shelf. All your books are on my shelf too.
[00:03:52.600 --> 00:04:01.600]   Bless you. So before the show and those of you who are watching live know, we kind of discussed politics, because I haven't seen Stacey since before the election.
[00:04:01.600 --> 00:04:13.600]   And there is a little political news. Donald Trump is back to his Twitter account for the week or so before the election. This, the story was, I don't know how accurate it is that they had taken away.
[00:04:13.600 --> 00:04:23.600]   Some said his password, some said his phone. Jeff, you always said, if it's from Android, it's from the president elect. If it's from Apple, it's from his team.
[00:04:23.600 --> 00:04:37.600]   And it's all been from Android lately. And for the last three or four really criticizing. Yeah, you know, we can say no now, right? Really criticizing the New York Times. He's been going after the New York Times.
[00:04:37.600 --> 00:04:47.600]   We Donald Trump as an Android user. I have to list pause for him. Yeah, no, he was an iPhone user until he called for a boycott of the iPhone after San Bernardino.
[00:04:47.600 --> 00:04:57.600]   And everyone. Okay. Yes. That's where I was. Yeah. He switched to an iPhone guy. He switched to, we believe the Samsung Galaxy S7. Now, I'm not sure.
[00:04:57.600 --> 00:05:06.600]   Remember when President Obama took office, they took away his blackberry. Mm hmm. I don't know who they is. Who can do that to the president of the United States, the most powerful person in the world.
[00:05:06.600 --> 00:05:19.600]   I think it's the Department of Defense, isn't it? They can't secure the channels. I mean, it makes sense. Oh, I hadn't thought. Well, he can always do desktop Twitter, but he doesn't use a computer.
[00:05:19.600 --> 00:05:32.600]   I will see what happens January 20th, but you know, this is one of the problems in general with government. And I've talked to people who worked in the Obama White House.
[00:05:32.600 --> 00:05:42.600]   The systems are not very sophisticated or advanced. No, that's why there I say this. That's why Clinton had separate email because it was a screwed up system.
[00:05:42.600 --> 00:05:57.600]   She said you are looking like Steve Bannon, you know, with that you saw the scrap. Yeah, you got it. No, you got to go one way or the other. Either shave it or get it longer. No, no, I haven't shaved in a week. I haven't shaved in a week. I said, I won't. I'm not going to shave until a woman wins the White House.
[00:05:57.600 --> 00:06:10.600]   Oh, OK. Yeah, it turned out it was going to be a longer. You're going to be David Letterman. Just don't be true. No, I can trim. I just can't shave.
[00:06:10.600 --> 00:06:21.600]   You're right. I'd be ZZ Top at the rate we're going. Anyway, who knows? You know, I think Elizabeth Warren is my personal vote for 2020.
[00:06:21.600 --> 00:06:30.600]   Kamala Harris Kamala Harris, who is our new senator in California. What do you think of her? I don't see her. I've seen her at events and stuff.
[00:06:30.600 --> 00:06:38.600]   So this will confirm everybody's belief about California. Our two candidates for Senator were both women, both Democrats.
[00:06:38.600 --> 00:06:48.600]   And so it was really like, I don't know if you were Republican, how you felt about that. You didn't have the choice because of the way the primaries work in the state.
[00:06:48.600 --> 00:06:56.600]   The top two vote getters run against each other. And regardless of party. So, but Kamala Harris was Secretary of State.
[00:06:56.600 --> 00:07:08.600]   I actually, truthfully, I don't know that much about her. But she is one of four new female senators who are not white men.
[00:07:08.600 --> 00:07:15.600]   The rest of its white men, but she's four new female senators, which is pretty exciting, I think.
[00:07:15.600 --> 00:07:26.600]   Bodes well. Let's see here. Let's see here. Anything to say? We're just going to watch with interest as Mr. Trump tweets.
[00:07:26.600 --> 00:07:36.600]   He is now twice left behind the press corps. And the press corps, as one would expect from a hive of bees, is hopping mad.
[00:07:36.600 --> 00:07:43.600]   You know, that be not be a bad thing. I'm just going to throw this out here. Okay. So, yes, getting rid of your press corps.
[00:07:43.600 --> 00:07:46.600]   Regan in the Hilton. So, but.
[00:07:46.600 --> 00:07:57.600]   Orange portion 9/11. So that's the press corps argument is if something like that happens, President Reagan getting shot or President Bush reading to a kindergarten class when 9/11 happens, then there's no press pool coverage.
[00:07:57.600 --> 00:08:00.600]   And it's pool coverage, by the way, not individual press coverage.
[00:08:00.600 --> 00:08:07.600]   But then you don't have to pander. You can be like, screw it. This guy doesn't like us. Well, that's different. That's different Stacy. Yes.
[00:08:07.600 --> 00:08:14.600]   I would argue that if he kicks you out of the press room, then go do your damn job.
[00:08:14.600 --> 00:08:23.600]   But how do you do your job without access? Everything that press room is shown to the world. We all see it. That's stenography. That's not true.
[00:08:23.600 --> 00:08:33.600]   And, you know, I think the normal reaction, my reaction is, well, he's going to have a steak. Let him have a steak in peace. I mean, I thought that was fine.
[00:08:33.600 --> 00:08:38.600]   But there should be a there should be there's there standing outside. They need they need to pool. I understand. They need to pool.
[00:08:38.600 --> 00:08:47.600]   The other thing is to Stacy, to your point, is the the travesty that I believe is the White House of correspondents there.
[00:08:47.600 --> 00:08:57.600]   They should stop doing that. They should stop horrible. That's all about the access and selling access. Basically what celebrities do you bring and that kind of stuff.
[00:08:57.600 --> 00:09:05.600]   I think there'll be one thing that will be interesting. President Obama did not like press conferences held very relatively few of them.
[00:09:05.600 --> 00:09:10.600]   I'll be curious to see what happens in the next administration. Will there be more press conferences?
[00:09:10.600 --> 00:09:13.600]   I think there'll be something we've never seen before, which is rallies.
[00:09:13.600 --> 00:09:20.600]   I was going to say, I think he's rally specific. She said in the press pool is which is actually something to what is pool coverage.
[00:09:20.600 --> 00:09:36.600]   We'll give it to Jeff. Mr. Charles, you just have a small number of people. You have a TV and you have a probably a print photographer and they are obligated to provide to all the rest of the press rather than have every single network every.
[00:09:36.600 --> 00:09:43.600]   Nowadays, it's even more important because you've got every blog, everybody with their own cameras and their own reporters and you get a million people.
[00:09:43.600 --> 00:09:49.600]   They designate some reporters and cameras, etc. That they will share.
[00:09:49.600 --> 00:09:56.600]   I didn't know that the jargon was that they get a signal that is a lid on it. We're not doing anything tonight. We're staying home.
[00:09:56.600 --> 00:10:02.600]   You can go now. They don't stay 24 hours. Up to 24 hours, if the president's out, they're out.
[00:10:02.600 --> 00:10:07.600]   It's a different media organization swap out there.
[00:10:07.600 --> 00:10:13.600]   It's a different people. Is it publicly available? The pool coverage? I know for a while, Gawker had a...
[00:10:13.600 --> 00:10:17.600]   They actually ran the pool coverage, which was kind of fun.
[00:10:17.600 --> 00:10:21.600]   I think you can get it. If you're in the press, you can get the report and then share it.
[00:10:21.600 --> 00:10:25.600]   They're wonderfully boring. Trump had catch up on stake.
[00:10:25.600 --> 00:10:31.600]   Same thing happens in Congress. It happens at rallies, frankly.
[00:10:31.600 --> 00:10:35.600]   The pool coverage at a rally is that single camera on the candidate.
[00:10:35.600 --> 00:10:41.600]   He said, "You never showed the crowd." The pool camera never was supposed to show the crowd.
[00:10:41.600 --> 00:10:46.600]   The networks have additional cameras that they can use to do that within did.
[00:10:46.600 --> 00:10:53.600]   Look, my attitude is, let's give it a chance to see what happens.
[00:10:53.600 --> 00:10:58.600]   As we move closer and closer to January 20, things are happening.
[00:10:58.600 --> 00:11:04.600]   It'll be interesting. Here's my... From a tech point of view, our biggest interest is going to be
[00:11:04.600 --> 00:11:09.600]   what happens to crypto, what happens to NSA surveillance.
[00:11:09.600 --> 00:11:14.600]   What happens to network met neutrality? Net neutrality FCC in general.
[00:11:14.600 --> 00:11:16.600]   One of the things...
[00:11:16.600 --> 00:11:19.600]   The FCC today just said that they were not going to do any...
[00:11:19.600 --> 00:11:25.600]   They were stopping their executive orders until the new administration declared the campaign.
[00:11:25.600 --> 00:11:30.600]   They did that for Obama. It is totally legit. I know people are upset because a lot of issues are...
[00:11:30.600 --> 00:11:35.600]   What you don't want... I suspect this... Obama will do the same thing.
[00:11:35.600 --> 00:11:43.600]   You don't want a lot of lame duck posturing and stuff that's just going to be retracted in January.
[00:11:43.600 --> 00:11:51.600]   But we'll watch. I don't... Does anybody know how quickly the FCC commissioners can be replaced?
[00:11:51.600 --> 00:11:53.600]   Isn't there a schedule for that?
[00:11:53.600 --> 00:12:00.600]   There is a schedule for them. I don't remember who is on the schedule next.
[00:12:00.600 --> 00:12:09.600]   And by the way, only three commissioners can be... Of the five rather can be of the same political party.
[00:12:09.600 --> 00:12:13.600]   So you have to have two Democrats and three Republicans or vice versa.
[00:12:13.600 --> 00:12:17.600]   I do think he gets to replace the chairman.
[00:12:17.600 --> 00:12:20.600]   He does get to replace Tom Wheeler.
[00:12:20.600 --> 00:12:22.600]   So I'm trying to look at his case.
[00:12:22.600 --> 00:12:26.600]   Wheeler was a Republican appointed by Obama and serving since November 4, 2013.
[00:12:26.600 --> 00:12:31.600]   And ironically, a guy who... Everybody was really willing to...
[00:12:31.600 --> 00:12:32.600]   You're ready.
[00:12:32.600 --> 00:12:33.600]   To do it.
[00:12:33.600 --> 00:12:34.600]   I was so wrong about him.
[00:12:34.600 --> 00:12:38.600]   Yeah, because he ended up doing, I think, many good things for...
[00:12:38.600 --> 00:12:39.600]   The people.
[00:12:39.600 --> 00:12:42.600]   Well, he tried. We'll see how long he last.
[00:12:42.600 --> 00:12:43.600]   Yeah.
[00:12:43.600 --> 00:12:47.600]   But that's kind of the nature of the pendulum. It swings back and forth, I think.
[00:12:47.600 --> 00:12:54.600]   So we'll watch. I mean, those are going to all be things where we're going to be very interested in the encryption debate is hot and heavy.
[00:12:54.600 --> 00:13:02.600]   At the same time, remember that one of Canada Trump's stands, and I hope that President Trump will follow it,
[00:13:02.600 --> 00:13:06.600]   was to prevent the AT&T time Warner merger.
[00:13:06.600 --> 00:13:09.600]   Oh, you know, he just said that he wasn't going to do that.
[00:13:09.600 --> 00:13:11.600]   All right. Sorry.
[00:13:11.600 --> 00:13:12.600]   Whiplash.
[00:13:12.600 --> 00:13:16.600]   AT&T time... It's not time Warner. AT&T...
[00:13:16.600 --> 00:13:18.600]   Oh, it is time Warner.
[00:13:18.600 --> 00:13:21.600]   Yes. Sorry. My brain stopped working for a second there.
[00:13:21.600 --> 00:13:25.600]   He just said he's not going to stop that, huh?
[00:13:25.600 --> 00:13:28.600]   Well, hold on. Let me make sure this is a legit news source.
[00:13:28.600 --> 00:13:31.600]   Well, okay. That's really going to be the subject of this show, I think.
[00:13:31.600 --> 00:13:32.600]   Yes.
[00:13:32.600 --> 00:13:33.600]   Yes.
[00:13:33.600 --> 00:13:35.600]   I got some...
[00:13:35.600 --> 00:13:36.600]   Yes.
[00:13:36.600 --> 00:13:40.600]   Here's the Wall Street Journal. So this is a seeking alpha thing that came up.
[00:13:40.600 --> 00:13:42.600]   So hard to say.
[00:13:42.600 --> 00:13:45.600]   Told supporters. Yeah. Plocked the deal.
[00:13:45.600 --> 00:13:48.600]   Ah, I've hit the paywall.
[00:13:48.600 --> 00:13:51.600]   Well, we'll find out. You know what?
[00:13:51.600 --> 00:13:55.600]   I think the other thing is, stuff doesn't going to move that fast.
[00:13:55.600 --> 00:13:59.600]   I mean, it seems like... Well, we'll see. I don't know.
[00:13:59.600 --> 00:14:02.600]   Of course, during campaign speeches,
[00:14:02.600 --> 00:14:06.600]   Trump said everything's going to happen on day one, but I think it's pretty clear that
[00:14:06.600 --> 00:14:10.600]   there's a lot to do and it can't happen all at once.
[00:14:10.600 --> 00:14:22.600]   Oh, okay. The story says that Jeff Eisenach had said in the past that he was in favor of the
[00:14:22.600 --> 00:14:26.600]   time Warner thing. So it was not Trump.
[00:14:26.600 --> 00:14:27.600]   Yeah.
[00:14:27.600 --> 00:14:31.600]   That was a pretty clear campaign promise, not that that means much, but that means
[00:14:31.600 --> 00:14:34.600]   much, but that was a pretty clear campaign. So is the Wall.
[00:14:34.600 --> 00:14:37.600]   Yeah. But, you know... Okay. Anyway.
[00:14:37.600 --> 00:14:39.600]   Sorry. Yeah.
[00:14:39.600 --> 00:14:42.600]   Or fence. It could be a fence.
[00:14:42.600 --> 00:14:46.600]   So let's talk about that. That was an architectural technology commentary.
[00:14:46.600 --> 00:14:48.600]   Wasn't a political commentary. Yeah.
[00:14:48.600 --> 00:14:49.600]   Right.
[00:14:49.600 --> 00:14:50.600]   Yeah.
[00:14:50.600 --> 00:14:55.600]   How much was it going to cost? Like $200 billion Wall, whatever.
[00:14:55.600 --> 00:14:59.600]   Let's talk about fake news.
[00:14:59.600 --> 00:15:02.600]   Really, probably the subject we should go down the road of.
[00:15:02.600 --> 00:15:06.600]   Now, what I'm not interested in, and I think you see a lot of this is,
[00:15:06.600 --> 00:15:10.600]   "Oh, we lost. Why do we lose? It's your fault."
[00:15:10.600 --> 00:15:16.600]   I don't think that's relevant. So let's talk about it from the point of view of going forward.
[00:15:16.600 --> 00:15:21.600]   First of all, and I think I'm very contrarian on this, so I'll be interested.
[00:15:21.600 --> 00:15:25.600]   I know what you guys might want to say here, but I'll be interested in hearing it.
[00:15:25.600 --> 00:15:30.600]   What is Facebook's obligation regarding fake news?
[00:15:30.600 --> 00:15:35.600]   Mr. Jervis, you may start.
[00:15:35.600 --> 00:15:38.600]   So I've written a piece about this, and I just met today.
[00:15:38.600 --> 00:15:43.600]   I want to get both your pieces of advice about this, about what we could advise them to do.
[00:15:43.600 --> 00:15:46.600]   So I met with somebody... I think someone might even say,
[00:15:46.600 --> 00:15:49.600]   "I don't know if John Borthwick at Baderworks,
[00:15:49.600 --> 00:15:52.600]   where we want to make some tangible, specific suggestions."
[00:15:52.600 --> 00:15:55.600]   And we're working on that now, so I'm eager to hear yours.
[00:15:55.600 --> 00:15:59.600]   Facebook... I've done this shpiel before on the show that I don't think Facebook is media.
[00:15:59.600 --> 00:16:02.600]   And we can argue about that and put that aside.
[00:16:02.600 --> 00:16:07.600]   I think that Facebook... I think Zuckerberg is wrong to say that it had no impact, wrong...
[00:16:07.600 --> 00:16:12.600]   It's glib to say, "99% of what you have on Facebook is true. How do you know?"
[00:16:12.600 --> 00:16:18.600]   But the simple point of fact to me is that Facebook, with the help of media
[00:16:18.600 --> 00:16:24.600]   and with the help of its users, could improve the quality of discourse.
[00:16:24.600 --> 00:16:26.600]   And that is its obligation.
[00:16:26.600 --> 00:16:32.600]   And so around this idea of people spreading lies, falsehoods, and frauds,
[00:16:32.600 --> 00:16:35.600]   there are clear ways that they could help.
[00:16:35.600 --> 00:16:39.600]   And I do believe that some significant portion of the time,
[00:16:39.600 --> 00:16:42.600]   people share things that are mistaken and they don't know it,
[00:16:42.600 --> 00:16:45.600]   and if they knew it was mistaken, they wouldn't do it.
[00:16:45.600 --> 00:16:50.600]   So can we get in there earlier and help them with more information,
[00:16:50.600 --> 00:16:57.600]   more signals to them, say, "You know, this comes from a site that's been around for about 10 minutes."
[00:16:57.600 --> 00:16:58.600]   Do you trust him?
[00:16:58.600 --> 00:17:03.600]   Part of the problem with Facebook, it was purely economic,
[00:17:03.600 --> 00:17:07.600]   was that there was a small town, 45,000 people in Macedonia.
[00:17:07.600 --> 00:17:11.600]   And I guess the teenagers talk amongst themselves.
[00:17:11.600 --> 00:17:13.600]   I kind of want to go meet them.
[00:17:13.600 --> 00:17:19.600]   They all came up with this notion at once, which makes me think they kind of all talked about it,
[00:17:19.600 --> 00:17:26.600]   to create political sites with names like World News site
[00:17:26.600 --> 00:17:31.600]   and put fake stories on there that would be, you know, clickbait.
[00:17:31.600 --> 00:17:36.600]   I mean, really it's clickbait because the point of it all for them was if you click at the link and you go to their site,
[00:17:36.600 --> 00:17:39.600]   they make money on the ads.
[00:17:39.600 --> 00:17:43.600]   And a lot of these, I mean, things like the Pope endorsing Trump.
[00:17:43.600 --> 00:17:49.600]   Well, what's funny is this actually happened to me if you did a Google search,
[00:17:49.600 --> 00:17:53.600]   I'm sure they fixed it by now, for what was the final vote count in the election?
[00:17:53.600 --> 00:17:57.600]   You'd find a fake's, the first result was a fake site.
[00:17:57.600 --> 00:17:58.600]   On Google.
[00:17:58.600 --> 00:17:59.600]   On Google.
[00:17:59.600 --> 00:18:00.600]   On Google.
[00:18:00.600 --> 00:18:01.600]   Not on news.
[00:18:01.600 --> 00:18:02.600]   On Google.
[00:18:02.600 --> 00:18:07.600]   A fake site that said it was 60, Trump won 62 million to 60.
[00:18:07.600 --> 00:18:09.600]   Which isn't true.
[00:18:09.600 --> 00:18:11.600]   But it looked true.
[00:18:11.600 --> 00:18:14.600]   And Google even has this problem.
[00:18:14.600 --> 00:18:15.600]   So what is it?
[00:18:15.600 --> 00:18:16.600]   So let's stand it past Facebook.
[00:18:16.600 --> 00:18:19.600]   Does Facebook have obligations different from Google?
[00:18:19.600 --> 00:18:27.600]   No, I think in both cases we can help them help users know more before they share crap.
[00:18:27.600 --> 00:18:30.600]   They've done this before with clickbait.
[00:18:30.600 --> 00:18:32.600]   Remember Upworthy used to dominate the Facebook feed.
[00:18:32.600 --> 00:18:33.600]   They did something.
[00:18:33.600 --> 00:18:35.600]   I don't know what to prevent that.
[00:18:35.600 --> 00:18:37.600]   They changed their algorithm.
[00:18:37.600 --> 00:18:41.600]   And they based it on, I think, time spent after people click through.
[00:18:41.600 --> 00:18:50.600]   I think Facebook has the means, like the technological means to create a flag.
[00:18:50.600 --> 00:18:57.600]   If you go to a site in Google's like, "Hey, yo, the site might not be secure," you could
[00:18:57.600 --> 00:19:04.600]   get a flag on stories that come from just reputable sources.
[00:19:04.600 --> 00:19:11.600]   And just a simple transparent, "Hey, we flagged this story as being questionable."
[00:19:11.600 --> 00:19:18.600]   It would at least give you pause before you shared it, which would help.
[00:19:18.600 --> 00:19:20.600]   And that's not crazy.
[00:19:20.600 --> 00:19:26.600]   And they're not saying that the content, maybe it's they base it on where the site is.
[00:19:26.600 --> 00:19:33.600]   Maybe they prejudice themselves in favor of more longer standing media entities.
[00:19:33.600 --> 00:19:34.600]   Right.
[00:19:34.600 --> 00:19:36.600]   Maybe it's a site that has track record.
[00:19:36.600 --> 00:19:43.600]   And then that brings back to Jeff's idea of funding legitimate conservative media.
[00:19:43.600 --> 00:19:51.600]   Because then you'd have much more like, "Hey, this is a real organization and you'd be
[00:19:51.600 --> 00:19:52.600]   trusted."
[00:19:52.600 --> 00:19:58.600]   Because that's the fact that Facebook was concerned about a right-wing backlash.
[00:19:58.600 --> 00:20:00.600]   I think speaks volumes.
[00:20:00.600 --> 00:20:05.600]   I don't know, by the way, Facebook denies this Gizmodo story because Modo said that they
[00:20:05.600 --> 00:20:10.600]   had the ability to kill the fake news, but were afraid that it would kill mostly Republican
[00:20:10.600 --> 00:20:11.600]   and Facebook posts.
[00:20:11.600 --> 00:20:12.600]   I couldn't see that post.
[00:20:12.600 --> 00:20:15.600]   Well, because Facebook denies it categorically.
[00:20:15.600 --> 00:20:16.600]   Yeah, I know.
[00:20:16.600 --> 00:20:19.600]   But the reason that that's not the case.
[00:20:19.600 --> 00:20:22.600]   That might be fake news itself.
[00:20:22.600 --> 00:20:23.600]   It may be.
[00:20:23.600 --> 00:20:30.400]   But the point is that on the right, Macedonian teenagers and wherever used Facebook in a
[00:20:30.400 --> 00:20:32.400]   way that media were too stupid to do.
[00:20:32.400 --> 00:20:36.400]   I've long contended that you've heard my spiel about social covenants.
[00:20:36.400 --> 00:20:37.400]   Oh, it was clickbait.
[00:20:37.400 --> 00:20:39.400]   Me is used clickbait for--
[00:20:39.400 --> 00:20:40.400]   No, no, no, no.
[00:20:40.400 --> 00:20:41.400]   Since Facebook started.
[00:20:41.400 --> 00:20:42.400]   No, no, no, no.
[00:20:42.400 --> 00:20:43.400]   I'm not saying that, Lee.
[00:20:43.400 --> 00:20:44.400]   I'm saying something very important.
[00:20:44.400 --> 00:20:46.400]   This is a big, important distinction that's different.
[00:20:46.400 --> 00:20:50.040]   Clickbait, which we do do, up where he does, every media company he does, is come to my
[00:20:50.040 --> 00:20:52.400]   site where my ad is.
[00:20:52.400 --> 00:20:54.080]   Clickbait, you click on this.
[00:20:54.080 --> 00:20:57.680]   That's not what the meme makers did.
[00:20:57.680 --> 00:20:59.680]   A meme is self-contained.
[00:20:59.680 --> 00:21:00.680]   Right?
[00:21:00.680 --> 00:21:03.000]   Occupied Democrats or various things.
[00:21:03.000 --> 00:21:05.000]   It is self-contained.
[00:21:05.000 --> 00:21:08.240]   People use it as a social token to pass around.
[00:21:08.240 --> 00:21:11.840]   My contention is one thing that we immediately need to do, forget Facebook, but we immediately
[00:21:11.840 --> 00:21:14.160]   need to do is we need to learn that lesson.
[00:21:14.160 --> 00:21:19.040]   We need to turn out memes that are filled with facts and journalism.
[00:21:19.040 --> 00:21:21.240]   Here's the problem that I have.
[00:21:21.240 --> 00:21:22.240]   Okay.
[00:21:22.240 --> 00:21:25.080]   This is-- and this is because Moto story is a perfect example.
[00:21:25.080 --> 00:21:26.320]   Fake news to whom.
[00:21:26.320 --> 00:21:29.960]   I mean, there's some stuff that's demonstrably, factually false.
[00:21:29.960 --> 00:21:32.360]   But this gives Moto story.
[00:21:32.360 --> 00:21:33.360]   Facebook denies.
[00:21:33.360 --> 00:21:34.360]   Right.
[00:21:34.360 --> 00:21:35.360]   So I don't think--
[00:21:35.360 --> 00:21:36.360]   I don't think--
[00:21:36.360 --> 00:21:39.360]   Does that mean it's fake news or not?
[00:21:39.360 --> 00:21:40.840]   That's why I agree with-- Leo, that's why.
[00:21:40.840 --> 00:21:41.840]   There's two things about this.
[00:21:41.840 --> 00:21:45.520]   One is that's why I know Facebook shouldn't say this is fake because we don't want them
[00:21:45.520 --> 00:21:48.880]   to be the arbiter of what's fake and real and false and true.
[00:21:48.880 --> 00:21:53.160]   Number two, I object strongly, except in extreme cases, to a black list.
[00:21:53.160 --> 00:21:58.360]   A professor at Marquette University put out a list of fake news sites and included in
[00:21:58.360 --> 00:22:01.400]   it the onion and included in it, Breitbart.
[00:22:01.400 --> 00:22:04.800]   Now I don't like Breitbart for a second, but if Breitbart is next to the president for
[00:22:04.800 --> 00:22:08.880]   the next four years, people are going to be sharing news where people on Breitbart
[00:22:08.880 --> 00:22:12.640]   and who argue what they're doing is satire in exactly the same way that the onion is
[00:22:12.640 --> 00:22:13.640]   set.
[00:22:13.640 --> 00:22:14.640]   Right.
[00:22:14.640 --> 00:22:19.160]   So what I'm arguing for is not that Facebook censors, that Facebook kills, that Facebook
[00:22:19.160 --> 00:22:20.760]   labels as fake.
[00:22:20.760 --> 00:22:24.840]   What Facebook can do is give you, as Stacy just said, they can give you more information
[00:22:24.840 --> 00:22:25.840]   in this process.
[00:22:25.840 --> 00:22:30.040]   See, I want to be open to your proposal because in general, I think that it's not Facebook's
[00:22:30.040 --> 00:22:31.040]   problem at all.
[00:22:31.040 --> 00:22:35.080]   If Facebook's just let people post whatever they want, in the same way they can email
[00:22:35.080 --> 00:22:37.520]   you whatever they want, they can tweet whatever they want.
[00:22:37.520 --> 00:22:39.520]   It's the problem like Google's problem.
[00:22:39.520 --> 00:22:44.360]   Because people say what they want to say and it's your responsibility as a consumer of
[00:22:44.360 --> 00:22:46.880]   news to judge whether it's true or not, period.
[00:22:46.880 --> 00:22:47.880]   Right.
[00:22:47.880 --> 00:22:49.880]   But Facebook helps with that.
[00:22:49.880 --> 00:22:55.080]   We're not saying Facebook should censor, we're just saying, hey, help people out.
[00:22:55.080 --> 00:22:59.680]   Just like I get a little security icon is some sites protected with HTTPS.
[00:22:59.680 --> 00:23:00.680]   Right.
[00:23:00.680 --> 00:23:02.680]   So if it's got SSL, I see the security icon.
[00:23:02.680 --> 00:23:07.480]   If I see this flag, I say, oh, well, maybe I should go look into this more.
[00:23:07.480 --> 00:23:13.240]   I mean, the input that all that should do is say, oh, let me Google this and see what
[00:23:13.240 --> 00:23:15.720]   has anyone else said it.
[00:23:15.720 --> 00:23:17.120]   Yeah.
[00:23:17.120 --> 00:23:20.560]   So part of it, you can do that now or you can go to Snopes or you can.
[00:23:20.560 --> 00:23:25.080]   Well, everything that becomes horrifying.
[00:23:25.080 --> 00:23:26.080]   Right.
[00:23:26.080 --> 00:23:27.080]   So do something for me.
[00:23:27.080 --> 00:23:28.080]   Go to.
[00:23:28.080 --> 00:23:31.320]   I think they're part of the reason fake news works is because people read it something they
[00:23:31.320 --> 00:23:34.240]   want to believe and they like it.
[00:23:34.240 --> 00:23:39.760]   But you don't share stuff that's demonstrably or even possibly false.
[00:23:39.760 --> 00:23:45.600]   I shared there was a post this week where somebody shoved a Trump protester down the
[00:23:45.600 --> 00:23:46.600]   stairs at them all.
[00:23:46.600 --> 00:23:49.640]   And I shared it and turned out it had nothing to do with politics.
[00:23:49.640 --> 00:23:54.920]   The guy who did the shoving has problems and everybody said that and I pulled it back
[00:23:54.920 --> 00:23:55.920]   immediately.
[00:23:55.920 --> 00:23:59.400]   Now what I wish I could do is send a note to anybody who read it say, oh, I shared the
[00:23:59.400 --> 00:24:00.400]   wrong thing.
[00:24:00.400 --> 00:24:01.400]   All I can do now is kill it.
[00:24:01.400 --> 00:24:02.400]   I can't correct it.
[00:24:02.400 --> 00:24:03.400]   I can't do anything else.
[00:24:03.400 --> 00:24:06.400]   There's other things to do.
[00:24:06.400 --> 00:24:07.400]   Do something for me.
[00:24:07.400 --> 00:24:08.520]   This is going to be a little controversial.
[00:24:08.520 --> 00:24:10.720]   All right.
[00:24:10.720 --> 00:24:13.440]   Google search daily stormer.
[00:24:13.440 --> 00:24:16.080]   Which is a white supremacy site.
[00:24:16.080 --> 00:24:19.560]   Yes, exactly.
[00:24:19.560 --> 00:24:24.680]   So when you do that, the world's most goal is the world's most goal oriented Republican
[00:24:24.680 --> 00:24:30.480]   website and Google pulls up the innards of the site, which it doesn't do with all sites.
[00:24:30.480 --> 00:24:32.560]   It does it with kind of sites that have enough traffic.
[00:24:32.560 --> 00:24:34.560]   So the first thing is Jewish problem.
[00:24:34.560 --> 00:24:35.560]   Yeah.
[00:24:35.560 --> 00:24:36.560]   Yeah.
[00:24:36.560 --> 00:24:37.560]   So that helps you.
[00:24:37.560 --> 00:24:38.560]   So this is the kind of help you'd like.
[00:24:38.560 --> 00:24:40.280]   Well, no, I'm that's what I'm asking.
[00:24:40.280 --> 00:24:45.240]   I mean, I think the next entry, which is the Wikipedia entry for it, which says it's an
[00:24:45.240 --> 00:24:49.880]   American neo-Nazi and white supremacist news and commentary site, which is the very second
[00:24:49.880 --> 00:24:51.280]   thing and still above the fold.
[00:24:51.280 --> 00:24:55.000]   And most most screens is probably even more useful.
[00:24:55.000 --> 00:24:56.000]   Yes.
[00:24:56.000 --> 00:24:57.000]   I'm not sure what you do.
[00:24:57.000 --> 00:24:59.800]   Actually, John and I were a little appalled that Google pulled this out.
[00:24:59.800 --> 00:25:01.040]   Well, wait a minute.
[00:25:01.040 --> 00:25:02.040]   But they do the same thing.
[00:25:02.040 --> 00:25:04.040]   If I do New York Times, they pull out stuff too.
[00:25:04.040 --> 00:25:05.320]   Well, but they don't do it with all sites.
[00:25:05.320 --> 00:25:07.360]   If you do it with some other sites, there's only a little strong.
[00:25:07.360 --> 00:25:09.960]   Are they trying to tell us something about the New York Times?
[00:25:09.960 --> 00:25:10.960]   I don't know.
[00:25:10.960 --> 00:25:13.400]   Because I get the same pull out.
[00:25:13.400 --> 00:25:14.960]   I get what I'm seeing in.
[00:25:14.960 --> 00:25:15.960]   Yeah.
[00:25:15.960 --> 00:25:20.640]   I mean, are you sure that Google's doing this to say, hey, that's what I'm saying.
[00:25:20.640 --> 00:25:22.200]   No, that's what I'm saying.
[00:25:22.200 --> 00:25:25.080]   No, I'm not presuming.
[00:25:25.080 --> 00:25:26.480]   I don't know that I like this.
[00:25:26.480 --> 00:25:29.560]   I think this is giving them more space and more.
[00:25:29.560 --> 00:25:32.960]   Oh, you're saying it's not a big enough site to do that with.
[00:25:32.960 --> 00:25:33.960]   Well, kind of it.
[00:25:33.960 --> 00:25:37.400]   And it's a it's a I think we can call this safely a hate site.
[00:25:37.400 --> 00:25:38.400]   Yeah.
[00:25:38.400 --> 00:25:39.400]   And and the hate.
[00:25:39.400 --> 00:25:42.960]   If I search for quit, for instance, they don't pull out content from.
[00:25:42.960 --> 00:25:43.960]   Right.
[00:25:43.960 --> 00:25:47.160]   So you got a special treatment that pulls out their kind of no, I don't think this is good
[00:25:47.160 --> 00:25:48.160]   to do.
[00:25:48.160 --> 00:25:49.160]   Okay.
[00:25:49.160 --> 00:25:50.160]   So this is not the solution.
[00:25:50.160 --> 00:25:51.960]   No, no, no, no, no.
[00:25:51.960 --> 00:25:55.520]   Let me go over a list of some things because I want to get your reaction, right?
[00:25:55.520 --> 00:26:00.160]   One is is is trying to spread the ethic of verified sources.
[00:26:00.160 --> 00:26:01.160]   Right.
[00:26:01.160 --> 00:26:04.080]   And you think verified sources has helped Twitter?
[00:26:04.080 --> 00:26:05.080]   No.
[00:26:05.080 --> 00:26:10.800]   You think there's any benefit that could be that only if Twitter's well, I mean, one
[00:26:10.800 --> 00:26:15.440]   of the things Twitter does, I don't do it, but it lets you look at only verified tweets.
[00:26:15.440 --> 00:26:16.440]   Right.
[00:26:16.440 --> 00:26:20.320]   I mean, I guess that could be the way to do that.
[00:26:20.320 --> 00:26:22.600]   Yeah, even verified people are wrong.
[00:26:22.600 --> 00:26:25.880]   I mean, I'm verified, but I've had this is to me every now and then.
[00:26:25.880 --> 00:26:26.880]   This is to me.
[00:26:26.880 --> 00:26:30.040]   The problem here is that this is there it isn't so black and white as we would like
[00:26:30.040 --> 00:26:31.040]   it to be.
[00:26:31.040 --> 00:26:34.080]   And I'm really bothers me to say it's Facebook's burden to do this.
[00:26:34.080 --> 00:26:36.080]   I think I'm not saying it's Facebook burdens.
[00:26:36.080 --> 00:26:41.880]   You know, I'm saying that that listen, when Facebook when Google had crap and spam coming
[00:26:41.880 --> 00:26:42.880]   up, what do they do?
[00:26:42.880 --> 00:26:47.360]   They hired Matt cuts to say improve the experience value of Google.
[00:26:47.360 --> 00:26:51.720]   I'm saying that nobody should be stopped from posting what they want to post apart from
[00:26:51.720 --> 00:26:52.720]   hate speech.
[00:26:52.720 --> 00:26:57.000]   They want to post a dumb, stupid, wrong meme.
[00:26:57.000 --> 00:26:59.040]   That is their that is their privilege and right to do so.
[00:26:59.040 --> 00:27:01.840]   And by the way, we can't know maybe they're going to make me making fun of it.
[00:27:01.840 --> 00:27:03.000]   They have their reasons to post it.
[00:27:03.000 --> 00:27:06.040]   They want to pass examples of dumb, stupid, wrong things.
[00:27:06.040 --> 00:27:14.080]   But all Stacy and I are saying is if people posted wrong stuff inadvertently less, Facebook
[00:27:14.080 --> 00:27:15.080]   would be a better experience.
[00:27:15.080 --> 00:27:16.680]   It's better for Facebook and better for the user.
[00:27:16.680 --> 00:27:18.840]   Let's take this back to the days of up worthy.
[00:27:18.840 --> 00:27:19.840]   It's true.
[00:27:19.840 --> 00:27:23.400]   If people would stop posting that gosh darn up worthy crap.
[00:27:23.400 --> 00:27:27.760]   So what did that finally they did and they did Facebook did it.
[00:27:27.760 --> 00:27:31.880]   So part of the argument part of the problem is that fool me once.
[00:27:31.880 --> 00:27:32.880]   Fool me twice.
[00:27:32.880 --> 00:27:33.880]   George Bush.
[00:27:33.880 --> 00:27:36.880]   People didn't like it.
[00:27:36.880 --> 00:27:44.000]   The difference here is that if look at it as a customer service problem, if you're sharing
[00:27:44.000 --> 00:27:50.720]   and you have all this fake news, what if people don't like it, giving them tools to identify
[00:27:50.720 --> 00:27:54.440]   it a little bit more easily would be beneficial for them.
[00:27:54.440 --> 00:27:59.400]   What Facebook's algorithm tells it and assuming that Facebook is fully algorithmic and not
[00:27:59.400 --> 00:28:00.920]   human.
[00:28:00.920 --> 00:28:05.840]   It's Facebook's algorithm is designed to do is optimize for stickiness to keep you using
[00:28:05.840 --> 00:28:06.840]   the same.
[00:28:06.840 --> 00:28:07.840]   Right.
[00:28:07.840 --> 00:28:11.040]   But they could optimize for what people like.
[00:28:11.040 --> 00:28:12.040]   So they're okay.
[00:28:12.040 --> 00:28:13.360]   That is not necessarily true.
[00:28:13.360 --> 00:28:15.640]   They're optimizing for what people click on.
[00:28:15.640 --> 00:28:17.560]   People don't always click on stuff they value.
[00:28:17.560 --> 00:28:19.040]   What other signal do you want?
[00:28:19.040 --> 00:28:20.040]   You want to read them all?
[00:28:20.040 --> 00:28:23.640]   Have you ever posted something?
[00:28:23.640 --> 00:28:30.840]   Have you ever retweeted or shared something that you found out 10 minutes later was wrong?
[00:28:30.840 --> 00:28:31.840]   I don't remember.
[00:28:31.840 --> 00:28:32.840]   Yeah, I've done it all the time.
[00:28:32.840 --> 00:28:34.000]   Well, I don't do it all the time.
[00:28:34.000 --> 00:28:35.000]   I'm pretty confident.
[00:28:35.000 --> 00:28:36.000]   I don't know.
[00:28:36.000 --> 00:28:37.000]   I bet it's happened.
[00:28:37.000 --> 00:28:38.480]   Well, it's happened to me more than I wanted to happen to me.
[00:28:38.480 --> 00:28:39.560]   Put it that way, right?
[00:28:39.560 --> 00:28:41.600]   I would appreciate as a user.
[00:28:41.600 --> 00:28:43.720]   So I've given the example of the show before.
[00:28:43.720 --> 00:28:44.720]   I'm sorry, Stacey.
[00:28:44.720 --> 00:28:45.800]   I over talked to you.
[00:28:45.800 --> 00:28:46.800]   You did.
[00:28:46.800 --> 00:28:47.800]   I'm sorry.
[00:28:47.800 --> 00:28:48.800]   I apologize.
[00:28:48.800 --> 00:28:49.800]   We'll finish your point first.
[00:28:49.800 --> 00:28:50.800]   I got excited.
[00:28:50.800 --> 00:28:51.800]   I got me too excited.
[00:28:51.800 --> 00:28:52.800]   I know.
[00:28:52.800 --> 00:28:53.800]   Go ahead.
[00:28:53.800 --> 00:28:54.800]   All right.
[00:28:54.800 --> 00:28:55.800]   I apologize.
[00:28:55.800 --> 00:28:57.240]   I shouldn't do that.
[00:28:57.240 --> 00:29:00.760]   I gave the example of the show some weeks ago where there was the picture of Justin Trudeau
[00:29:00.760 --> 00:29:05.320]   and he was a consenting politician and looked suspicious to me and I started mousing over.
[00:29:05.320 --> 00:29:10.680]   And when you moused over, the related content was BuzzFeed saying this is a fake picture
[00:29:10.680 --> 00:29:13.480]   of people passing around and snowball debunking it.
[00:29:13.480 --> 00:29:14.960]   Now that helped you.
[00:29:14.960 --> 00:29:16.320]   Yes, it did.
[00:29:16.320 --> 00:29:17.320]   It did.
[00:29:17.320 --> 00:29:20.160]   And let's say that I was going to share that photo.
[00:29:20.160 --> 00:29:24.040]   If Facebook just simply said, you might want to see these other things about this photo.
[00:29:24.040 --> 00:29:27.480]   And I'd say, thank you, Facebook, for stopping me from embarrassing myself sharing this
[00:29:27.480 --> 00:29:28.480]   thing.
[00:29:28.480 --> 00:29:29.480]   I can't see a object.
[00:29:29.480 --> 00:29:31.480]   I'm not against that.
[00:29:31.480 --> 00:29:32.760]   OK, Stacey, I'm sorry.
[00:29:32.760 --> 00:29:34.400]   I apologize 100 times.
[00:29:34.400 --> 00:29:36.760]   No, no, that's 100 times.
[00:29:36.760 --> 00:29:37.760]   I want a thousand.
[00:29:37.760 --> 00:29:39.280]   Well, I'm trying to get myself 100.
[00:29:39.280 --> 00:29:41.120]   I'm just going to push him out of the show.
[00:29:41.120 --> 00:29:42.120]   It's all yours.
[00:29:42.120 --> 00:29:44.120]   It's all gone.
[00:29:44.120 --> 00:29:52.280]   I just I wanted to make a point.
[00:29:52.280 --> 00:29:53.760]   Jeff, you're still talking.
[00:29:53.760 --> 00:29:56.840]   You're still talking, man.
[00:29:56.840 --> 00:30:01.480]   I wanted to make the point that the algorithms, we have the sense that they're unbiased.
[00:30:01.480 --> 00:30:03.200]   Like I'm hearing you speak about this.
[00:30:03.200 --> 00:30:04.920]   Like, oh, they've optimized stickiness.
[00:30:04.920 --> 00:30:10.200]   But well, that's the point and they can optimize for a better user experience.
[00:30:10.200 --> 00:30:13.320]   I don't know where they get that information from.
[00:30:13.320 --> 00:30:14.920]   From users from users.
[00:30:14.920 --> 00:30:17.760]   No, but they're using the same as they have clicks.
[00:30:17.760 --> 00:30:18.760]   Time span.
[00:30:18.760 --> 00:30:20.600]   OK, but they have they have more clicks.
[00:30:20.600 --> 00:30:25.440]   Think about how Facebook reacts every time they roll out some privacy and fringing feature
[00:30:25.440 --> 00:30:30.000]   and everyone gets upset and they're like, Oh, bring out rule out the Zuckerberg apology.
[00:30:30.000 --> 00:30:36.480]   I mean, if people were upset enough about this and it became it was framed as a customer
[00:30:36.480 --> 00:30:42.440]   service issue and it may not be for the rest of the population, it's an issue for me.
[00:30:42.440 --> 00:30:47.280]   It's for Jeff for people who might feel embarrassed to say wrong things on Facebook.
[00:30:47.280 --> 00:30:51.320]   But if it is actually an issue, then Facebook should deal with it.
[00:30:51.320 --> 00:30:54.240]   If only because it will make the experience better.
[00:30:54.240 --> 00:30:59.560]   Yeah, I accept Jeff's proposal that maybe there's additional information.
[00:30:59.560 --> 00:31:04.360]   Your mouse hovers over something and it pops up a window or something.
[00:31:04.360 --> 00:31:05.800]   I accept that.
[00:31:05.800 --> 00:31:12.440]   I really dislike the notion that Facebook somehow knows better than its users and needs to protect
[00:31:12.440 --> 00:31:13.440]   people.
[00:31:13.440 --> 00:31:14.440]   No, it's just a thing.
[00:31:14.440 --> 00:31:15.440]   It's a page rank.
[00:31:15.440 --> 00:31:16.440]   Right.
[00:31:16.440 --> 00:31:17.440]   It's like page rank.
[00:31:17.440 --> 00:31:18.440]   Give us some more information.
[00:31:18.440 --> 00:31:19.440]   I don't have a problem with that.
[00:31:19.440 --> 00:31:25.880]   I would need a mat cuts to stay ahead of people who are gaming their structure.
[00:31:25.880 --> 00:31:28.280]   So this is the thing is I see headlines like this.
[00:31:28.280 --> 00:31:29.520]   This is from today.
[00:31:29.520 --> 00:31:33.680]   Zuckerberg says Facebook will crack down on fake news.
[00:31:33.680 --> 00:31:36.680]   That's not what your proposal doesn't sound like a crackdown.
[00:31:36.680 --> 00:31:40.240]   No, no, I worry about a crackdown on fake news.
[00:31:40.240 --> 00:31:42.000]   Yeah, Facebook doesn't want to do that.
[00:31:42.000 --> 00:31:43.800]   I don't want them to do that.
[00:31:43.800 --> 00:31:44.800]   Let me ask you this question.
[00:31:44.800 --> 00:31:52.040]   Facebook on January 15, 2015, January 20, 2015 added the ability to report false news.
[00:31:52.040 --> 00:31:54.000]   Can you find that for me?
[00:31:54.000 --> 00:31:55.000]   Sure.
[00:31:55.000 --> 00:31:56.000]   Fine.
[00:31:56.000 --> 00:31:57.800]   I report something I've written this false.
[00:31:57.800 --> 00:31:59.600]   Don't please don't do that.
[00:31:59.600 --> 00:32:01.360]   Go to the almost last step.
[00:32:01.360 --> 00:32:02.360]   Where is that?
[00:32:02.360 --> 00:32:03.440]   Let me find it for you.
[00:32:03.440 --> 00:32:07.960]   I'm looking.
[00:32:07.960 --> 00:32:11.600]   This is January 20th, ironically, last year.
[00:32:11.600 --> 00:32:13.440]   No, no, no, but I'm going to look at the.
[00:32:13.440 --> 00:32:14.440]   I'm going to look at the.
[00:32:14.440 --> 00:32:15.440]   Now you cheated.
[00:32:15.440 --> 00:32:17.360]   I wanted you to find the way.
[00:32:17.360 --> 00:32:18.600]   Oh, you're saying.
[00:32:18.600 --> 00:32:19.600]   I get we.
[00:32:19.600 --> 00:32:20.600]   Okay, I'm not looking.
[00:32:20.600 --> 00:32:21.600]   I'm not looking.
[00:32:21.600 --> 00:32:24.800]   I'm going to go to my Facebook feed real quickly and see how I would report that.
[00:32:24.800 --> 00:32:27.440]   So let's say this story I'm raising.
[00:32:27.440 --> 00:32:28.440]   Let's do a scoble.
[00:32:28.440 --> 00:32:31.920]   Let's do why I'm happy that Trump won.
[00:32:31.920 --> 00:32:34.600]   So normally what I do is I click this down arrow.
[00:32:34.600 --> 00:32:37.040]   I can hide post and follow Robert.
[00:32:37.040 --> 00:32:39.000]   Hide from Prince E report post.
[00:32:39.000 --> 00:32:40.000]   There we go.
[00:32:40.000 --> 00:32:41.000]   It's annoying.
[00:32:41.000 --> 00:32:42.720]   I think it shouldn't be on Facebook.
[00:32:42.720 --> 00:32:43.920]   Let's continue.
[00:32:43.920 --> 00:32:45.840]   Why should it not be on Facebook?
[00:32:45.840 --> 00:32:46.840]   It's harassment.
[00:32:46.840 --> 00:32:47.840]   It's hate speech.
[00:32:47.840 --> 00:32:48.840]   It's something else.
[00:32:48.840 --> 00:32:49.840]   Let's see.
[00:32:49.840 --> 00:32:50.840]   Is it it?
[00:32:50.840 --> 00:32:51.840]   I think it's an unauthorized.
[00:32:51.840 --> 00:32:53.080]   Nope, it's not there.
[00:32:53.080 --> 00:32:54.080]   It's not there.
[00:32:54.080 --> 00:32:55.080]   Well, where is it?
[00:32:55.080 --> 00:32:56.080]   Because that's the logical.
[00:32:56.080 --> 00:32:58.680]   It's still supposed to be there, but the point is they buried it.
[00:32:58.680 --> 00:32:59.680]   It's annoying.
[00:32:59.680 --> 00:33:00.680]   How about this one?
[00:33:00.680 --> 00:33:01.680]   It's annoying.
[00:33:01.680 --> 00:33:02.680]   Nope.
[00:33:02.680 --> 00:33:03.680]   Nope.
[00:33:03.680 --> 00:33:10.360]   So if we just made it easier for users to say, Hey, I looked at this and it's fake.
[00:33:10.360 --> 00:33:12.560]   No, maybe I got it.
[00:33:12.560 --> 00:33:17.240]   It's annoying or not interesting message Prince E to resolve this.
[00:33:17.240 --> 00:33:18.240]   Nope.
[00:33:18.240 --> 00:33:19.240]   Nope.
[00:33:19.240 --> 00:33:21.400]   Yeah, you're right.
[00:33:21.400 --> 00:33:25.720]   It's not immediately obvious to give signals.
[00:33:25.720 --> 00:33:26.720]   That's one.
[00:33:26.720 --> 00:33:30.600]   So Stacy, make it easier for the users to give Facebook signals and Facebook can judge them.
[00:33:30.600 --> 00:33:32.800]   Maybe that's the best way to get gay.
[00:33:32.800 --> 00:33:35.880]   The other way I think is media can say, you know, Hey, Facebook, we went to the effort.
[00:33:35.880 --> 00:33:37.080]   We call we on the phone.
[00:33:37.080 --> 00:33:38.080]   We called up.
[00:33:38.080 --> 00:33:39.080]   We found out this is not true.
[00:33:39.080 --> 00:33:41.600]   We did not do this.
[00:33:41.600 --> 00:33:46.280]   And Facebook trusts that media outlet and says, okay, New York Times, if you say so, we're
[00:33:46.280 --> 00:33:50.120]   not going to kill the post, but we're going to make sure we tell people, Hey, the New York
[00:33:50.120 --> 00:33:52.920]   Times might want you to know this.
[00:33:52.920 --> 00:33:55.800]   In both cases, you empower the users both ways.
[00:33:55.800 --> 00:33:57.640]   Stacy.
[00:33:57.640 --> 00:34:03.520]   You also then put a burden on real reporters to debunk all this crap.
[00:34:03.520 --> 00:34:10.120]   And well, and I can also see people using this to espouse a political point of view.
[00:34:10.120 --> 00:34:11.680]   Oh, they'll game this is.
[00:34:11.680 --> 00:34:16.440]   You know, and we've, I mean, this is what the problem dig ran up against and putting
[00:34:16.440 --> 00:34:24.600]   them out of business is these kinds of reputation based systems can be gamed and rigged.
[00:34:24.600 --> 00:34:29.200]   Facebook is in a difficult situation because everybody wants to game Facebook and I don't
[00:34:29.200 --> 00:34:30.200]   think they're taking it.
[00:34:30.200 --> 00:34:33.360]   I think some people in Facebook are taking it seriously and others are not.
[00:34:33.360 --> 00:34:38.000]   Stacy, let me go back to your question about putting that burden on media.
[00:34:38.000 --> 00:34:41.920]   I actually, I think that's media's job and I'm not saying they have to do it to all the
[00:34:41.920 --> 00:34:42.920]   crap that's there.
[00:34:42.920 --> 00:34:47.640]   But if a substantial number of people believe X isn't it a reporter's job to say, well,
[00:34:47.640 --> 00:34:52.160]   I picked up the phone and I found out and let me tell you, you should know that's wrong.
[00:34:52.160 --> 00:34:53.960]   Yes, that's what we do.
[00:34:53.960 --> 00:34:56.800]   But yes, that is that is totally true.
[00:34:56.800 --> 00:35:04.560]   My concern is we get into these false equivalencies easily in media and I worry like if there
[00:35:04.560 --> 00:35:10.760]   are enough people who say something, it automatically kind of becomes true in some ways like God
[00:35:10.760 --> 00:35:16.480]   help us Dr. Wakefield in his vaccination efforts or his anti-vaccination.
[00:35:16.480 --> 00:35:17.600]   This is a good example.
[00:35:17.600 --> 00:35:23.560]   So by the way, it's contro it's still controversial because some people believe that a childhood
[00:35:23.560 --> 00:35:30.320]   vaccinations cause autism, the man who created the first study later admitted he'd faked the
[00:35:30.320 --> 00:35:31.320]   results.
[00:35:31.320 --> 00:35:35.760]   But ever since that kind of set off a shockwave of people who don't know that he retracted
[00:35:35.760 --> 00:35:41.200]   it, I don't even know if you could call it factual enough people are adamant.
[00:35:41.200 --> 00:35:45.600]   I have friends who are adamant that it's true and they have anecdotal evidence, right?
[00:35:45.600 --> 00:35:51.920]   Well, my kid had four shots in a row and got a fever.
[00:35:51.920 --> 00:35:54.640]   Is that actually a common side effect?
[00:35:54.640 --> 00:35:57.640]   Well, I'm just saying it's complicated.
[00:35:57.640 --> 00:35:59.520]   Can you give people more information?
[00:35:59.520 --> 00:36:01.720]   And had you given people more information?
[00:36:01.720 --> 00:36:06.480]   Would that have because believe me, if you're an anti-vaccination crusader, you've been
[00:36:06.480 --> 00:36:10.080]   given a lot of contrary information.
[00:36:10.080 --> 00:36:13.840]   Has that slowed it down?
[00:36:13.840 --> 00:36:16.480]   Has this worked?
[00:36:16.480 --> 00:36:17.480]   Maybe a little?
[00:36:17.480 --> 00:36:18.880]   I don't know.
[00:36:18.880 --> 00:36:24.600]   Like the fact that the guy who wrote the study retracted it didn't slow it down.
[00:36:24.600 --> 00:36:27.360]   I don't think your neighbor is saying, "You're full of it."
[00:36:27.360 --> 00:36:29.760]   Is it going to slow it down?
[00:36:29.760 --> 00:36:30.760]   So I like the idea-
[00:36:30.760 --> 00:36:33.760]   Do you think somebody needs a really powerless?
[00:36:33.760 --> 00:36:34.760]   Ah!
[00:36:34.760 --> 00:36:36.640]   No, no, we're not powerless.
[00:36:36.640 --> 00:36:41.840]   But you- Okay, well, someone would argue you're powerless to change people's minds.
[00:36:41.840 --> 00:36:46.160]   No, if you believe that, then just shut down the halls of German-
[00:36:46.160 --> 00:36:48.680]   Yeah, why would you have a job?
[00:36:48.680 --> 00:36:53.560]   I mean, if you're- Read the Righteous Mind by a professor
[00:36:53.560 --> 00:36:56.840]   named Jonathan Heitt, a very interesting book.
[00:36:56.840 --> 00:36:59.720]   We've had him on triangulation.
[00:36:59.720 --> 00:37:07.360]   And he talks about how reason and intuition work.
[00:37:07.360 --> 00:37:09.920]   And intuition is instant.
[00:37:09.920 --> 00:37:13.360]   And for good evolutionary reasons, it's got to be.
[00:37:13.360 --> 00:37:14.600]   And reason follows.
[00:37:14.600 --> 00:37:22.480]   He likens intuition as the elephant that reason is riding.
[00:37:22.480 --> 00:37:25.680]   Reason has a hard time controlling intuition.
[00:37:25.680 --> 00:37:27.600]   People make up their minds.
[00:37:27.600 --> 00:37:34.280]   And then most often come up with reasonable explanations for why they believe what they
[00:37:34.280 --> 00:37:35.280]   believe.
[00:37:35.280 --> 00:37:36.280]   This is what we educate you.
[00:37:36.280 --> 00:37:38.640]   But it's all ad hoc.
[00:37:38.640 --> 00:37:40.360]   Well, but it's all- Yeah, okay.
[00:37:40.360 --> 00:37:41.920]   I mean, I believe in education.
[00:37:41.920 --> 00:37:43.920]   Why have we- Yeah, you believe that education in German-
[00:37:43.920 --> 00:37:45.480]   I'm not saying it's impossible.
[00:37:45.480 --> 00:37:46.480]   It isn't impossible.
[00:37:46.480 --> 00:37:48.560]   Obviously, you can change minds.
[00:37:48.560 --> 00:37:50.120]   It's harder than you think.
[00:37:50.120 --> 00:37:52.600]   And it is generally not done with reason.
[00:37:52.600 --> 00:37:53.920]   He's got a compelling book.
[00:37:53.920 --> 00:37:54.920]   It's done with empathy.
[00:37:54.920 --> 00:37:55.920]   It's often done with empathy.
[00:37:55.920 --> 00:37:57.960]   Hey, that was exactly in sync.
[00:37:57.960 --> 00:37:58.960]   You guys are empathetic.
[00:37:58.960 --> 00:37:59.960]   There we go.
[00:37:59.960 --> 00:38:06.400]   I mean, but no, and that's why- I'm not going to go there.
[00:38:06.400 --> 00:38:09.200]   The challenge is- Thank you.
[00:38:09.200 --> 00:38:14.240]   The news industry is not designed to be empathetic.
[00:38:14.240 --> 00:38:17.280]   We're designed to report on facts.
[00:38:17.280 --> 00:38:23.760]   And I think it's a huge- Instead of talking about fake news, I would think that as an
[00:38:23.760 --> 00:38:32.120]   industry, we would talk more about how to convey empathy and to tell people, other people's
[00:38:32.120 --> 00:38:34.720]   stories in a way that makes them compelling.
[00:38:34.720 --> 00:38:36.880]   I don't think that's going on.
[00:38:36.880 --> 00:38:37.880]   I mean, that's-
[00:38:37.880 --> 00:38:42.880]   It is, but it's relegated to the feature section.
[00:38:42.880 --> 00:38:45.240]   It is limited- It's thrown in.
[00:38:45.240 --> 00:38:46.880]   Helicopter out.
[00:38:46.880 --> 00:38:47.880]   You don't really stay in the community.
[00:38:47.880 --> 00:38:49.880]   But this is part of a community- This is part of a community-
[00:38:49.880 --> 00:38:53.640]   Look, what we're talking about with Facebook is challenging because Facebook is neither
[00:38:53.640 --> 00:38:55.840]   media nor a common carrier.
[00:38:55.840 --> 00:38:59.200]   It's something new that the Internet has given us.
[00:38:59.200 --> 00:39:06.280]   And media itself is no longer reportage presented in a who, what, when, where, why fashion.
[00:39:06.280 --> 00:39:07.480]   It is something new.
[00:39:07.480 --> 00:39:09.320]   It has to be something new.
[00:39:09.320 --> 00:39:13.160]   And all of this is kind of precipitated by the Internet era.
[00:39:13.160 --> 00:39:15.240]   The way people share information.
[00:39:15.240 --> 00:39:20.160]   I mean, let's go back 50 years of pre-Internet era.
[00:39:20.160 --> 00:39:21.520]   There was plenty of fake news.
[00:39:21.520 --> 00:39:22.520]   You know how it was shared?
[00:39:22.520 --> 00:39:25.120]   Your neighbor told you.
[00:39:25.120 --> 00:39:30.960]   So you know, and in fact, communities, geographically, proximate communities often have very similar
[00:39:30.960 --> 00:39:36.440]   beliefs and they reach consensus in a way that has nothing to do with the Internet.
[00:39:36.440 --> 00:39:41.360]   What has to do with what you heard down at the cafe or at the mall and what your neighbor
[00:39:41.360 --> 00:39:43.120]   told you.
[00:39:43.120 --> 00:39:47.400]   And so I think that what we're trying, what we're really grappling with is a new world
[00:39:47.400 --> 00:39:49.360]   in general.
[00:39:49.360 --> 00:39:54.800]   I like your plan of saying, let's have more information.
[00:39:54.800 --> 00:39:56.560]   At least give you the information.
[00:39:56.560 --> 00:39:57.560]   So much more.
[00:39:57.560 --> 00:39:59.720]   I would submit most would ignore it because again, really soon-
[00:39:59.720 --> 00:40:01.440]   We don't know when we try.
[00:40:01.440 --> 00:40:02.440]   Well, it's given tools.
[00:40:02.440 --> 00:40:03.800]   But now that's to the empathy point.
[00:40:03.800 --> 00:40:04.800]   That's to the empathy point.
[00:40:04.800 --> 00:40:09.840]   Stacy, we had this conversation in our social journalism program last night.
[00:40:09.840 --> 00:40:15.600]   One of my students, one of our students under Professor Kerry Brown had this great
[00:40:15.600 --> 00:40:17.520]   spiel where he said he has an aunt.
[00:40:17.520 --> 00:40:19.360]   We all have an uncle or an aunt.
[00:40:19.360 --> 00:40:20.360]   He has an aunt.
[00:40:20.360 --> 00:40:24.080]   And the aunt came in and said, why are you always talking about how, you know, black
[00:40:24.080 --> 00:40:25.080]   people have problems.
[00:40:25.080 --> 00:40:26.080]   It's a white guy.
[00:40:26.080 --> 00:40:28.960]   And he said, well, because there's a problem of justice here.
[00:40:28.960 --> 00:40:31.400]   It's all lives matter.
[00:40:31.400 --> 00:40:33.960]   And she said, don't you understand why that's offensive?
[00:40:33.960 --> 00:40:38.880]   Well, so he went through four hours with her on Facebook kind of, you know, in public to
[00:40:38.880 --> 00:40:40.520]   his friends and family.
[00:40:40.520 --> 00:40:43.280]   Four hours going back and forth and back and forth and back and forth.
[00:40:43.280 --> 00:40:47.400]   And finally at the end, there was a breakthrough moment and she said, oh, I never thought about
[00:40:47.400 --> 00:40:48.400]   it.
[00:40:48.400 --> 00:40:49.400]   Okay.
[00:40:49.400 --> 00:40:54.600]   But for every time that happened, I know, well, 25,000 times it just extended to a flame
[00:40:54.600 --> 00:40:56.160]   war and nothing happened.
[00:40:56.160 --> 00:40:57.440]   Well, it's just solidified.
[00:40:57.440 --> 00:40:59.720]   If anything solidified people are close.
[00:40:59.720 --> 00:41:03.800]   I'm saying I'm agreeing with you.
[00:41:03.800 --> 00:41:04.800]   This doesn't scale.
[00:41:04.800 --> 00:41:05.800]   Right.
[00:41:05.800 --> 00:41:06.800]   Yeah.
[00:41:06.800 --> 00:41:07.800]   He can't spend four hours of the room.
[00:41:07.800 --> 00:41:08.800]   It's an outlier.
[00:41:08.800 --> 00:41:11.400]   But the question is possible.
[00:41:11.400 --> 00:41:12.400]   Okay.
[00:41:12.400 --> 00:41:19.520]   So then the question is, how do you create an online platform that promotes empathy,
[00:41:19.520 --> 00:41:22.080]   that promotes actual conversations?
[00:41:22.080 --> 00:41:26.000]   And Facebook can be that platform and even Twitter can be that platform in the comments
[00:41:26.000 --> 00:41:27.000]   and other sections.
[00:41:27.000 --> 00:41:28.000]   I agree.
[00:41:28.000 --> 00:41:29.840]   Here's a potential problem.
[00:41:29.840 --> 00:41:34.840]   So somebody in the chatroom said, this election was about not having empathy and I would disagree.
[00:41:34.840 --> 00:41:36.600]   The issue was not not having empathy.
[00:41:36.600 --> 00:41:39.440]   It was about who do you have empathy for?
[00:41:39.440 --> 00:41:46.360]   Do you have empathy for the other or do you have empathy for middle class Americans who
[00:41:46.360 --> 00:41:49.200]   have fallen from grace?
[00:41:49.200 --> 00:41:53.760]   And really a lot of the anger coming from the Rust Belt was anger that, hey, you're
[00:41:53.760 --> 00:41:59.800]   all worried about these Latinos when, what about me?
[00:41:59.800 --> 00:42:02.240]   I'm not, come on.
[00:42:02.240 --> 00:42:04.160]   And you know what?
[00:42:04.160 --> 00:42:05.320]   That's a, there's no question.
[00:42:05.320 --> 00:42:06.400]   There's empathy there.
[00:42:06.400 --> 00:42:09.360]   The debate is over who empathy for whom?
[00:42:09.360 --> 00:42:11.680]   Well, and yes, yes.
[00:42:11.680 --> 00:42:12.680]   And how?
[00:42:12.680 --> 00:42:15.200]   I mean, this is where I've argued that we in journalism don't listen well.
[00:42:15.200 --> 00:42:16.560]   We've got to get out there and give empathy.
[00:42:16.560 --> 00:42:18.520]   I think this is absolutely critical.
[00:42:18.520 --> 00:42:20.720]   So Lee, I'm trying to get your specific suggestions.
[00:42:20.720 --> 00:42:22.120]   Let me try another one on you.
[00:42:22.120 --> 00:42:23.120]   I think that's the trend.
[00:42:23.120 --> 00:42:28.520]   I will, by the way, you did win me over because I was dead set against Facebook doing anything.
[00:42:28.520 --> 00:42:33.360]   And I do like the idea of just providing more context.
[00:42:33.360 --> 00:42:34.360]   It only works.
[00:42:34.360 --> 00:42:35.360]   That's harmless.
[00:42:35.360 --> 00:42:36.360]   This is Stacy's point.
[00:42:36.360 --> 00:42:37.360]   What are Stacy's points to it?
[00:42:37.360 --> 00:42:42.360]   It only works if it's built around improving the experience of Facebook for the user.
[00:42:42.360 --> 00:42:46.520]   If it's shoving things down people's throat, if it's trying to censor for the sake of other
[00:42:46.520 --> 00:42:48.080]   agendas, no.
[00:42:48.080 --> 00:42:53.760]   But if it improves the experience, if we can stipulate that the experience of having crap
[00:42:53.760 --> 00:42:57.680]   actually that's all wrong and stupid all day is a bad experience and you can improve
[00:42:57.680 --> 00:42:59.640]   that, that's what sells it to Facebook.
[00:42:59.640 --> 00:43:01.120]   That's what sells it to the user.
[00:43:01.120 --> 00:43:07.400]   So Stacy, this Thanksgiving, when you sit down with friends and family and many of us will
[00:43:07.400 --> 00:43:16.480]   on Thursday, actually we've decided not to go somewhere to avoid this very issue.
[00:43:16.480 --> 00:43:21.040]   I will be reporting and doing the show for my parents, how you used it.
[00:43:21.040 --> 00:43:26.880]   So I think there will be a great many heated discussions.
[00:43:26.880 --> 00:43:29.600]   So how can empathy help us, Stacy?
[00:43:29.600 --> 00:43:31.320]   How can empathy help us here?
[00:43:31.320 --> 00:43:33.480]   Wait, are you asking me this because I'm a woman?
[00:43:33.480 --> 00:43:36.280]   No, because you're the one who brought us the word.
[00:43:36.280 --> 00:43:37.280]   This is your position.
[00:43:37.280 --> 00:43:39.120]   I'm you're defending it.
[00:43:39.120 --> 00:43:42.320]   So I use this all the time with my mom.
[00:43:42.320 --> 00:43:47.600]   I can't use it with my dad because he doesn't, he just shuts down when we talk about politics.
[00:43:47.600 --> 00:43:53.440]   But it's understanding the other person's point of view.
[00:43:53.440 --> 00:44:01.320]   So when my mom and I talk about Trump or policies, she actually brings up a lot of really legitimate
[00:44:01.320 --> 00:44:02.320]   questions.
[00:44:02.320 --> 00:44:09.720]   So when I talk about, I am against religious exemptions for birth control.
[00:44:09.720 --> 00:44:14.000]   And when a pharmacist doesn't do their job and doesn't give someone, deny someone like
[00:44:14.000 --> 00:44:17.760]   plan B, that's a, I feel like that should be illegal.
[00:44:17.760 --> 00:44:24.000]   And she, it basically, when I talk into her, she brings up these really good points and
[00:44:24.000 --> 00:44:25.240]   I'm actually willing to listen.
[00:44:25.240 --> 00:44:28.680]   And basically, it's an individual rights thing for her.
[00:44:28.680 --> 00:44:30.520]   So I understand her position now.
[00:44:30.520 --> 00:44:33.560]   Whereas beforehand, I was like, these people are all evil and against women.
[00:44:33.560 --> 00:44:36.120]   I didn't really think that.
[00:44:36.120 --> 00:44:39.160]   That's exactly what Jonathan Hight says.
[00:44:39.160 --> 00:44:45.080]   It's what you both came up with at the same time, which is you can't reason somebody
[00:44:45.080 --> 00:44:49.480]   out of their beliefs.
[00:44:49.480 --> 00:44:53.120]   You have to start where they are.
[00:44:53.120 --> 00:44:55.120]   If you want to see this at-
[00:44:55.120 --> 00:44:56.120]   Yes, that's exactly what I'm saying.
[00:44:56.120 --> 00:44:57.120]   Yes.
[00:44:57.120 --> 00:44:59.720]   I wrote, I didn't write, I wish I had written.
[00:44:59.720 --> 00:45:05.200]   The New Yorker had an article about Obama's negotiations in Cuba.
[00:45:05.200 --> 00:45:12.160]   And it was this entire conversation played out as world politics.
[00:45:12.160 --> 00:45:17.920]   And it was a really fascinating kind of, it was a really good article.
[00:45:17.920 --> 00:45:22.600]   It was really fascinating to put it on the, like to view Obama through this lens and it
[00:45:22.600 --> 00:45:27.320]   kind of crystallizes how he dealt with people in conflict.
[00:45:27.320 --> 00:45:34.280]   And it made me feel, I think a little bit more sad because I don't see Trump so far
[00:45:34.280 --> 00:45:36.480]   exhibiting that kind of empathy.
[00:45:36.480 --> 00:45:42.240]   And I really think in a world fraught with disruption and globalization, we're going
[00:45:42.240 --> 00:45:44.360]   to need that more than ever.
[00:45:44.360 --> 00:45:51.400]   And so I would love to see Facebook, Twitter, any of our tech people try to promote this.
[00:45:51.400 --> 00:46:00.640]   But I also think that tech has a role to play because tech is fundamentally really unepathetic.
[00:46:00.640 --> 00:46:03.760]   Our leaders don't think of others.
[00:46:03.760 --> 00:46:04.960]   It's not diverse.
[00:46:04.960 --> 00:46:11.000]   It is very much drink the whole drink the Kool-Aid and it's very friendly.
[00:46:11.000 --> 00:46:13.280]   I'm very curious about users, Stacy.
[00:46:13.280 --> 00:46:14.280]   Right.
[00:46:14.280 --> 00:46:15.280]   They say they care about users.
[00:46:15.280 --> 00:46:18.000]   Users first, you're right.
[00:46:18.000 --> 00:46:21.760]   And how can you, how can you, and all of us were talking about design thinking.
[00:46:21.760 --> 00:46:25.120]   We design thinking is all about user center at all about empathy.
[00:46:25.120 --> 00:46:28.760]   We hear that a lot there, but I think you're absolutely right about the tech industry.
[00:46:28.760 --> 00:46:32.280]   It's not how can you put out good products if you don't empathize with the people using
[00:46:32.280 --> 00:46:34.440]   them.
[00:46:34.440 --> 00:46:40.040]   So I think that's where social media really, the promise of social media and the promise
[00:46:40.040 --> 00:46:48.680]   of the internet in general was to help us hear other voices and to democratize media
[00:46:48.680 --> 00:46:53.080]   because media pre-internet was not democratized.
[00:46:53.080 --> 00:46:57.440]   It was very much an oligarchy.
[00:46:57.440 --> 00:46:59.160]   And it is certainly more democratized.
[00:46:59.160 --> 00:47:05.080]   And ironically, as a result, there's more fake news than ever before.
[00:47:05.080 --> 00:47:10.000]   I mean, you could argue the National Enquirer has been around a long time, the star and
[00:47:10.000 --> 00:47:13.440]   the, there was a wonderful news of the world was just all fake news.
[00:47:13.440 --> 00:47:14.440]   It was a fake newspaper.
[00:47:14.440 --> 00:47:15.440]   Oh, that was awesome.
[00:47:15.440 --> 00:47:17.080]   And who didn't love the news of the world?
[00:47:17.080 --> 00:47:19.120]   Who didn't love the bat baby?
[00:47:19.120 --> 00:47:20.120]   Yeah.
[00:47:20.120 --> 00:47:21.120]   Yeah.
[00:47:21.120 --> 00:47:24.120]   So there's nothing new about fake news.
[00:47:24.120 --> 00:47:29.400]   I ask you guys some of your specific proposal questions to your reactions.
[00:47:29.400 --> 00:47:30.400]   Certainly.
[00:47:30.400 --> 00:47:31.400]   All right.
[00:47:31.400 --> 00:47:35.360]   So this is again with a conversation with, with John Borthwick.
[00:47:35.360 --> 00:47:41.720]   One, so the trending box sucks on Facebook in my view and they've tried to fix it with
[00:47:41.720 --> 00:47:45.920]   people that doesn't work and they tried it and trending to me is useless on Facebook.
[00:47:45.920 --> 00:47:47.560]   It's meaningless.
[00:47:47.560 --> 00:47:50.000]   What I wouldn't want, but why is it there?
[00:47:50.000 --> 00:47:53.560]   It's there to give you something that's not going to come across in your feet, John said.
[00:47:53.560 --> 00:47:54.920]   I think he's right.
[00:47:54.920 --> 00:47:56.440]   It's there to say, Oh, don't miss this.
[00:47:56.440 --> 00:47:58.960]   That's out there.
[00:47:58.960 --> 00:48:03.000]   And curating it is meaningless because that becomes like media one size fits all product
[00:48:03.000 --> 00:48:04.000]   and trendy.
[00:48:04.000 --> 00:48:05.000]   This is what everybody's looking at.
[00:48:05.000 --> 00:48:06.280]   Well, so what I could find that elsewhere.
[00:48:06.280 --> 00:48:07.960]   I don't think that's very interesting.
[00:48:07.960 --> 00:48:10.760]   What if there were an orthogonal box?
[00:48:10.760 --> 00:48:12.680]   You are always hearing these people.
[00:48:12.680 --> 00:48:14.120]   You never hear from these people.
[00:48:14.120 --> 00:48:17.160]   If you would like to make it optional, if you would like to, here's some things you're
[00:48:17.160 --> 00:48:19.000]   not likely to see, right?
[00:48:19.000 --> 00:48:22.200]   It's the, it's an explicit filter bubble cure.
[00:48:22.200 --> 00:48:23.200]   No, no, no, no.
[00:48:23.200 --> 00:48:26.520]   What he's asking is actually something a lot of people are thinking about, which is how
[00:48:26.520 --> 00:48:28.560]   to code for serendipity.
[00:48:28.560 --> 00:48:29.560]   Right.
[00:48:29.560 --> 00:48:34.400]   And you will hear this, God, if you go to any tech conference where we talk about algorithms,
[00:48:34.400 --> 00:48:36.560]   serendipity comes up like in a second.
[00:48:36.560 --> 00:48:37.560]   Second hour.
[00:48:37.560 --> 00:48:40.560]   It's like, Oh, but it's a legitimate thing.
[00:48:40.560 --> 00:48:43.800]   And people are thinking about it.
[00:48:43.800 --> 00:48:49.440]   The question is how to scale serendipity is ridiculously challenging because you're
[00:48:49.440 --> 00:48:54.200]   either going to pull stuff at random or you're going to pull trending.
[00:48:54.200 --> 00:48:58.520]   So let's think about ways that we can actually bring that into people's lives in a way that
[00:48:58.520 --> 00:49:05.440]   promotes, I guess, legitimate news, but also things that they wouldn't see and might actually
[00:49:05.440 --> 00:49:06.440]   find interesting.
[00:49:06.440 --> 00:49:07.440]   I don't know.
[00:49:07.440 --> 00:49:10.240]   I mean, that's a tough problem that people are actually working on.
[00:49:10.240 --> 00:49:11.240]   Right.
[00:49:11.240 --> 00:49:13.720]   And so trending doesn't do it.
[00:49:13.720 --> 00:49:19.000]   John shall make a company that works as called scale model, which is really looks neat,
[00:49:19.000 --> 00:49:22.160]   where you put it in my name and you see what the world is around me, right?
[00:49:22.160 --> 00:49:24.200]   And then you see what's missing.
[00:49:24.200 --> 00:49:27.720]   And that's an easy analysis for we've seen this a million times where you're all talking
[00:49:27.720 --> 00:49:28.720]   over here.
[00:49:28.720 --> 00:49:30.400]   And there's also a conversation over there.
[00:49:30.400 --> 00:49:34.120]   Would you like to hear a little bit of the best of over there?
[00:49:34.120 --> 00:49:35.120]   That's one idea.
[00:49:35.120 --> 00:49:36.120]   Right.
[00:49:36.120 --> 00:49:37.120]   So here's another question.
[00:49:37.120 --> 00:49:39.720]   Should you be able to edit tweets?
[00:49:39.720 --> 00:49:42.000]   Part of the problem with tweets is you have its binary.
[00:49:42.000 --> 00:49:44.280]   It's put it out there or kill it.
[00:49:44.280 --> 00:49:47.160]   Yeah, there's a there's a technical issue with that.
[00:49:47.160 --> 00:49:49.960]   And of course, it wants a tweet flies free.
[00:49:49.960 --> 00:49:51.040]   It's hard to pull it back.
[00:49:51.040 --> 00:49:53.200]   You can edit it in some context.
[00:49:53.200 --> 00:49:57.920]   But remember, a lot of people are reading Twitter and third party apps and so forth.
[00:49:57.920 --> 00:50:00.400]   And you can't easily modify it that way.
[00:50:00.400 --> 00:50:05.160]   So could you have a structure where by tweet is held for 30 seconds?
[00:50:05.160 --> 00:50:08.440]   I mean, well, that's one, but it's more likely.
[00:50:08.440 --> 00:50:12.040]   Oh, people, 10 people just told me I was full of crap and they're right.
[00:50:12.040 --> 00:50:13.520]   I don't think you can edit tweets.
[00:50:13.520 --> 00:50:14.720]   I think you could absolutely.
[00:50:14.720 --> 00:50:18.920]   I mean, we do what we do now, which is release a second tweet that says, oops.
[00:50:18.920 --> 00:50:23.400]   Yeah, delete and release a tweet or don't delete.
[00:50:23.400 --> 00:50:27.600]   And then now it would be interesting if you could post retroactively flag a tweet.
[00:50:27.600 --> 00:50:30.760]   So if not edit it, but just flags a wrong tweet.
[00:50:30.760 --> 00:50:35.000]   And I think Twitter rejects that because there's a fire hose.
[00:50:35.000 --> 00:50:37.880]   There's all sorts of places they can't go back and change.
[00:50:37.880 --> 00:50:41.160]   But just think of Twitter as like you've it's.
[00:50:41.160 --> 00:50:42.160]   Okay.
[00:50:42.160 --> 00:50:43.160]   So here's another idea.
[00:50:43.160 --> 00:50:44.160]   Here's a different idea.
[00:50:44.160 --> 00:50:49.840]   So let's say that you can work this either way from the sender or the recipient.
[00:50:49.840 --> 00:50:51.040]   I'm not sure which way to think about it.
[00:50:51.040 --> 00:50:54.680]   But basically I get to subscribe to corrections.
[00:50:54.680 --> 00:50:57.120]   Leo, you tweeted something.
[00:50:57.120 --> 00:50:58.120]   I retweeted it.
[00:50:58.120 --> 00:51:01.880]   I thought it was wonderful that you say because you're responsible and decent man.
[00:51:01.880 --> 00:51:04.320]   Oops, I was wrong.
[00:51:04.320 --> 00:51:05.320]   And I don't know that.
[00:51:05.320 --> 00:51:07.840]   And I don't happen to see your second tweet.
[00:51:07.840 --> 00:51:11.120]   So I don't tell my readers that Leo was wrong and full of.
[00:51:11.120 --> 00:51:12.120]   Right.
[00:51:12.120 --> 00:51:13.120]   Right.
[00:51:13.120 --> 00:51:17.000]   So if there were a structure where basically if I retweeted it, I get a notification.
[00:51:17.000 --> 00:51:22.000]   You get to send me a notification that says, Oh, hey, Jeff, you might want to X day on
[00:51:22.000 --> 00:51:23.160]   that each day.
[00:51:23.160 --> 00:51:26.320]   Um, we'd say no tweet anyway.
[00:51:26.320 --> 00:51:27.840]   Thank you.
[00:51:27.840 --> 00:51:31.120]   Uh, X day on that each way.
[00:51:31.120 --> 00:51:32.920]   Uh, show title.
[00:51:32.920 --> 00:51:35.280]   Um, uh, right.
[00:51:35.280 --> 00:51:37.120]   And, and, and you're informing me.
[00:51:37.120 --> 00:51:39.680]   And then I know from you boy Leo is an upstanding guy.
[00:51:39.680 --> 00:51:42.320]   I trust Leo more because Leo will set out a correction.
[00:51:42.320 --> 00:51:43.320]   And happens.
[00:51:43.320 --> 00:51:44.320]   Thank you, Leo.
[00:51:44.320 --> 00:51:46.360]   And I will in turn anyone who retweeted me.
[00:51:46.360 --> 00:51:49.120]   I'll say, or go on a matter of whatever.
[00:51:49.120 --> 00:51:50.120]   What do you think of that?
[00:51:50.120 --> 00:51:53.560]   What if there's kind of a subscription service for, uh, correct.
[00:51:53.560 --> 00:51:57.400]   I would create a tsunami, an additional tsunami of tweets.
[00:51:57.400 --> 00:51:58.400]   Could you imagine?
[00:51:58.400 --> 00:52:04.960]   Uh, can we just can people just use their critical facilities?
[00:52:04.960 --> 00:52:07.320]   I just told me a few minutes ago.
[00:52:07.320 --> 00:52:08.960]   No, they can't.
[00:52:08.960 --> 00:52:10.440]   I think they don't want to.
[00:52:10.440 --> 00:52:13.720]   But I can't, so it can't be forced upon them is what I said.
[00:52:13.720 --> 00:52:18.520]   And I just, we should just, I think we should just accept this for all it is.
[00:52:18.520 --> 00:52:20.360]   And I've got one more question.
[00:52:20.360 --> 00:52:21.360]   All right.
[00:52:21.360 --> 00:52:22.360]   All right.
[00:52:22.360 --> 00:52:23.360]   You're being very glad we're on through with them.
[00:52:23.360 --> 00:52:24.360]   I'm sure you're relieved right now.
[00:52:24.360 --> 00:52:26.360]   Um, I've got two.
[00:52:26.360 --> 00:52:27.360]   I've got a lot.
[00:52:27.360 --> 00:52:35.760]   Ah, one is, uh, once something's determined to be irresponsible fake news, you just know
[00:52:35.760 --> 00:52:36.760]   it.
[00:52:36.760 --> 00:52:37.760]   It's like pornography.
[00:52:37.760 --> 00:52:38.760]   You know it when you see it.
[00:52:38.760 --> 00:52:41.160]   Well, why do the Macedonian kids do this?
[00:52:41.160 --> 00:52:44.280]   Because the story says they didn't know, they didn't care enough to write.
[00:52:44.280 --> 00:52:45.280]   They don't give a damn.
[00:52:45.280 --> 00:52:46.280]   No, no.
[00:52:46.280 --> 00:52:47.280]   In fact, they tried it on the left.
[00:52:47.280 --> 00:52:48.280]   It didn't work.
[00:52:48.280 --> 00:52:49.280]   So they, they stuck with the right, right?
[00:52:49.280 --> 00:52:51.320]   And so you find out this stuff is made up just to gain the system.
[00:52:51.320 --> 00:52:52.320]   It's awful.
[00:52:52.320 --> 00:52:53.320]   But why do they do it?
[00:52:53.320 --> 00:52:54.320]   Because they make money.
[00:52:54.320 --> 00:53:00.960]   Should there be an ethic of pulling advertising from something that they already did?
[00:53:00.960 --> 00:53:05.400]   Google has just as announced that they are no longer going to allow AdWords on, uh, fake
[00:53:05.400 --> 00:53:06.400]   news sites.
[00:53:06.400 --> 00:53:11.320]   And Facebook has said you can't use face fake news in, uh, in advertising.
[00:53:11.320 --> 00:53:12.720]   Yeah, I agree with that.
[00:53:12.720 --> 00:53:14.960]   The problem I still have was all of this is.
[00:53:14.960 --> 00:53:15.960]   Is it a slippery slope though?
[00:53:15.960 --> 00:53:16.960]   Yes.
[00:53:16.960 --> 00:53:17.960]   What is fake news?
[00:53:17.960 --> 00:53:22.320]   I mean, um, right, uh, you know, somebody in the chat room said the Catholic church has
[00:53:22.320 --> 00:53:24.640]   been disseminating fake news for millennia.
[00:53:24.640 --> 00:53:28.840]   Well, if your father Robert Ballis there, you may disagree.
[00:53:28.840 --> 00:53:29.840]   Wait a second.
[00:53:29.840 --> 00:53:30.840]   Wait a second.
[00:53:30.840 --> 00:53:32.240]   Get ready for your drinking game.
[00:53:32.240 --> 00:53:37.320]   I'm reading a book right now about a brand Luther.
[00:53:37.320 --> 00:53:41.320]   So Gutenberg comes up and what Gutenberg objects like.
[00:53:41.320 --> 00:53:42.760]   You were all the relics.
[00:53:42.760 --> 00:53:43.760]   It's water.
[00:53:43.760 --> 00:53:44.760]   It's good thing.
[00:53:44.760 --> 00:53:45.920]   Don't you aren't you glad?
[00:53:45.920 --> 00:53:51.000]   What are the relics that that Gutenberg locked up and sent away was a vile containing Mary's
[00:53:51.000 --> 00:53:54.160]   breast milk?
[00:53:54.160 --> 00:53:55.400]   Fake news of its time.
[00:53:55.400 --> 00:53:56.400]   Right.
[00:53:56.400 --> 00:53:57.400]   Right.
[00:53:57.400 --> 00:54:04.200]   The church made quite a bit of money in a pre as since era selling, selling relics and
[00:54:04.200 --> 00:54:05.200]   dull gences and relics.
[00:54:05.200 --> 00:54:07.200]   Wait a second.
[00:54:07.200 --> 00:54:09.200]   What is this Gutenberg drinking thing?
[00:54:09.200 --> 00:54:10.760]   Oh, you're your spirit.
[00:54:10.760 --> 00:54:13.760]   Is this another thing that I am like, it's pre Stacy.
[00:54:13.760 --> 00:54:15.880]   Yeah, no, it's pre Stacy.
[00:54:15.880 --> 00:54:21.960]   So it used to be in the old days of this show that, uh, anytime Jeff mentioned Chipotle or
[00:54:21.960 --> 00:54:25.520]   Gutenberg, because Jeff and I agree with them.
[00:54:25.520 --> 00:54:29.600]   In fact, I used to say these in my speeches all the time, you know, compare, you know,
[00:54:29.600 --> 00:54:31.280]   the Gutenberg era to the modern times.
[00:54:31.280 --> 00:54:34.400]   Jeff's even written a book called Gutenberg the geek.
[00:54:34.400 --> 00:54:36.400]   So, uh, and then what was it?
[00:54:36.400 --> 00:54:38.520]   The other one was Akshung writes song.
[00:54:38.520 --> 00:54:40.040]   Oh, uh, Lishdung Schutzrecht.
[00:54:40.040 --> 00:54:48.440]   Lishdung Schutzrecht, which is, which is something, but anyway, which is it has to do with the
[00:54:48.440 --> 00:54:51.920]   German publishers and oh God, you don't want to get it.
[00:54:51.920 --> 00:54:52.920]   Oh God.
[00:54:52.920 --> 00:54:53.920]   Jeff's doing it again.
[00:54:53.920 --> 00:54:54.920]   It's a drinking game.
[00:54:54.920 --> 00:54:56.320]   So you're supposed to drink.
[00:54:56.320 --> 00:54:57.320]   It's, it's a joke.
[00:54:57.320 --> 00:55:01.320]   Nobody would do that and they'd be on the floor before the show was talking about Gutenberg.
[00:55:01.320 --> 00:55:04.120]   So I hadn't heard it until this moment.
[00:55:04.120 --> 00:55:06.040]   So yeah, I pulled off.
[00:55:06.040 --> 00:55:07.040]   All right.
[00:55:07.040 --> 00:55:08.040]   Last now.
[00:55:08.040 --> 00:55:09.040]   Now really the last.
[00:55:09.040 --> 00:55:10.040]   Last.
[00:55:10.040 --> 00:55:15.440]   So if you go to, if you want to look up a meme like, um, uh, what's your name?
[00:55:15.440 --> 00:55:21.480]   Uh, Jenny Yellen and George Soros in that commercial that was the dog whistle commercial.
[00:55:21.480 --> 00:55:25.240]   If you go to Wikipedia and look up Soros Yellen, it doesn't know what to do.
[00:55:25.240 --> 00:55:30.600]   If you look at Google and search for Soros Yellen, it starts to explain the memes to you.
[00:55:30.600 --> 00:55:34.680]   Is there, is there a meme repository that would be beneficial that when you don't know
[00:55:34.680 --> 00:55:40.120]   what's going on with the meme and you want to find out where it comes from, um, uh, that
[00:55:40.120 --> 00:55:41.840]   there's a place to go.
[00:55:41.840 --> 00:55:47.000]   Oh, well, there's, and there used to be a bunch of these.
[00:55:47.000 --> 00:55:48.960]   I think they were acquired and shut down.
[00:55:48.960 --> 00:55:53.640]   There was a, I used to keep up on memes cause I'm so old and out of touch.
[00:55:53.640 --> 00:55:55.280]   I used to keep up with the kids.
[00:55:55.280 --> 00:55:57.400]   There was a site with, would, uh, know your meme.
[00:55:57.400 --> 00:55:58.400]   Is it still around?
[00:55:58.400 --> 00:55:59.400]   Oh yeah.
[00:55:59.400 --> 00:56:00.400]   Know your meme still around.
[00:56:00.400 --> 00:56:01.400]   Isn't it?
[00:56:01.400 --> 00:56:02.400]   Yeah.
[00:56:02.400 --> 00:56:03.400]   Well, that's what that's for.
[00:56:03.400 --> 00:56:06.800]   Um, but I just, I mean, you can, if you see a meme, you just Google it and you're like,
[00:56:06.800 --> 00:56:07.800]   what the heck is happening?
[00:56:07.800 --> 00:56:08.800]   See a meme.
[00:56:08.800 --> 00:56:09.960]   Say a meme.
[00:56:09.960 --> 00:56:12.120]   Know your meme is know your meme on Twitter.
[00:56:12.120 --> 00:56:13.120]   Yeah.
[00:56:13.120 --> 00:56:14.120]   There's your meme.
[00:56:14.120 --> 00:56:15.120]   Oh, there it is.
[00:56:15.120 --> 00:56:20.320]   Dedicated to documenting internet phenomena, viral videos, image macros, catch phrases,
[00:56:20.320 --> 00:56:23.120]   web celebs and more.
[00:56:23.120 --> 00:56:26.960]   I think it's just become like yet another just place.
[00:56:26.960 --> 00:56:27.960]   Yeah.
[00:56:27.960 --> 00:56:28.960]   Just a little crap site.
[00:56:28.960 --> 00:56:29.960]   Yeah.
[00:56:29.960 --> 00:56:35.360]   Um, I think, was it Ben, huh, who started this of, uh, the, uh, cheeseburger?
[00:56:35.360 --> 00:56:37.160]   I can has cheeseburger.
[00:56:37.160 --> 00:56:38.080]   I can has cheeseburger.
[00:56:38.080 --> 00:56:39.880]   I can has cheeseburger.
[00:56:39.880 --> 00:56:40.880]   Or did he buy it?
[00:56:40.880 --> 00:56:42.320]   He's involved in some way.
[00:56:42.320 --> 00:56:44.640]   I feel like he bought it.
[00:56:44.640 --> 00:56:46.040]   Uh, he bought everything.
[00:56:46.040 --> 00:56:47.040]   All right.
[00:56:47.040 --> 00:56:48.040]   All right.
[00:56:48.040 --> 00:56:49.520]   Is everybody calm down a little bit?
[00:56:49.520 --> 00:56:53.760]   Part of the thing I'd have to say that from the outside and I'm in the bubble.
[00:56:53.760 --> 00:57:00.920]   So I'm, I have to use empathy to see this is that it probably looks like this is a very
[00:57:00.920 --> 00:57:07.000]   bubble conversation, uh, that these, this is not really important to anybody outside
[00:57:07.000 --> 00:57:08.200]   the bubble, right?
[00:57:08.200 --> 00:57:13.200]   Well, but I went well, uh, I was on, uh, today's show yesterday morning.
[00:57:13.200 --> 00:57:16.640]   MBC night, the news yesterday evening, probably CBS TV news tomorrow.
[00:57:16.640 --> 00:57:21.400]   CBS Sunday morning and Sunday BBC, uh, media is going nuts for it.
[00:57:21.400 --> 00:57:24.000]   Cause I love, they love blaming Facebook for something.
[00:57:24.000 --> 00:57:25.000]   Yeah.
[00:57:25.000 --> 00:57:26.000]   Oh my God.
[00:57:26.000 --> 00:57:27.000]   But the media is not like real people.
[00:57:27.000 --> 00:57:29.000]   No, the media is a bubble right.
[00:57:29.000 --> 00:57:32.200]   But they're presenting this story to the world as if it matters.
[00:57:32.200 --> 00:57:33.200]   Yeah.
[00:57:33.200 --> 00:57:36.880]   Well, that's because we, we love nothing more than talking about ourselves in the media.
[00:57:36.880 --> 00:57:37.880]   Yeah.
[00:57:37.880 --> 00:57:39.680]   We just, it's a little nave of gazing.
[00:57:39.680 --> 00:57:40.680]   He isn't it?
[00:57:40.680 --> 00:57:49.680]   By the way, speaking of the Twitter, they have now suspended, uh, Richard Spencer's account.
[00:57:49.680 --> 00:57:52.920]   Um, and some other alt-right accounts.
[00:57:52.920 --> 00:57:53.920]   Yeah.
[00:57:53.920 --> 00:57:59.160]   People are complaining that this is too little, too late or too much too soon.
[00:57:59.160 --> 00:58:04.000]   Well, uh, depends on who's talking.
[00:58:04.000 --> 00:58:08.720]   Richard Spencer says this is corporate Stalinism.
[00:58:08.720 --> 00:58:12.960]   I am alive physically, but digital, digitally speaking, there's been an execution squads
[00:58:12.960 --> 00:58:14.840]   across the alt-right.
[00:58:14.840 --> 00:58:18.760]   There's a great purge going on and they're purging people based on their views.
[00:58:18.760 --> 00:58:24.720]   It does feel a little bit like a reaction to Trump's election is like, okay, well, uh,
[00:58:24.720 --> 00:58:25.720]   let's get rid of all these guys.
[00:58:25.720 --> 00:58:28.520]   I mean, Spencer's been on Twitter for a long time.
[00:58:28.520 --> 00:58:35.520]   Um, also, uh, Paxton Dickinson, Paul Town, Ricky Vaughn, John Rivers.
[00:58:35.520 --> 00:58:38.120]   Were they suspended for an actual action?
[00:58:38.120 --> 00:58:40.040]   Like, oh, that tweet crossed the line.
[00:58:40.040 --> 00:58:43.400]   Well, this is the Milo debate.
[00:58:43.400 --> 00:58:44.400]   Right.
[00:58:44.400 --> 00:58:45.400]   Once again.
[00:58:45.400 --> 00:58:51.280]   But if it's reaction, I mean, it could be Twitter admitting some sort of role in what
[00:58:51.280 --> 00:58:57.160]   happened, um, or an influence that it does not want to power, that it does not want to
[00:58:57.160 --> 00:58:58.160]   have.
[00:58:58.160 --> 00:58:59.880]   They do have a rule against hate, right?
[00:58:59.880 --> 00:59:02.040]   On Twitter, that's one of the rules you can't.
[00:59:02.040 --> 00:59:05.960]   Yeah, but getting the proving hate is just, I mean, that's hate.
[00:59:05.960 --> 00:59:10.360]   Well, and that's what some of these guys in the all right, like Richard Spencer, I mean,
[00:59:10.360 --> 00:59:13.000]   he's always smiling when he's saying this hateful stuff.
[00:59:13.000 --> 00:59:14.640]   It's like, yeah, I'm joking.
[00:59:14.640 --> 00:59:15.640]   Come on.
[00:59:15.640 --> 00:59:18.240]   I'm tweaking your cham, yank in your chain.
[00:59:18.240 --> 00:59:25.800]   I grew up, you know, uh, at Yale, um, I, I, I, I've always liked wanted to know what
[00:59:25.800 --> 00:59:26.960]   the other side was thinking.
[00:59:26.960 --> 00:59:29.240]   So I would go to these conservative events.
[00:59:29.240 --> 00:59:30.240]   You would.
[00:59:30.240 --> 00:59:31.240]   Yes, you would.
[00:59:31.240 --> 00:59:34.720]   The political, there was a thing in the political union, which was great and had each,
[00:59:34.720 --> 00:59:36.960]   it was the party of the right, the P.O.R.
[00:59:36.960 --> 00:59:42.640]   There were all these different groups and there was a group of, of, uh, arch conservatives,
[00:59:42.640 --> 00:59:47.440]   William F Buckley, conservatives in fact, Buckley was kind of a prototype for this who would
[00:59:47.440 --> 00:59:53.560]   say things with a smile and like I'm joking, but you always felt like there was that they
[00:59:53.560 --> 00:59:55.920]   meant it.
[00:59:55.920 --> 01:00:04.080]   But they didn't, but they knew it was provocative and perhaps even racist or anti-Semitic.
[01:00:04.080 --> 01:00:10.520]   And by smiling, they gave you the impression, I'm just joking.
[01:00:10.520 --> 01:00:12.120]   Well, Trump even did this, didn't he?
[01:00:12.120 --> 01:00:13.120]   Okay.
[01:00:13.120 --> 01:00:18.680]   This is like every guy talking to a girl and insulting them about anything or just kidding.
[01:00:18.680 --> 01:00:20.240]   You can't take a joke.
[01:00:20.240 --> 01:00:22.600]   So I called you a, yeah, the B word.
[01:00:22.600 --> 01:00:29.080]   No, or it's worse, or it's where, when somebody, when I was a kid, people used to say no offense,
[01:00:29.080 --> 01:00:32.960]   but, and I always knew, yeah, I don't want to hear the offensive thing they were going
[01:00:32.960 --> 01:00:38.080]   to say next, which was usually an insult, no offense, but you have terrible body odor.
[01:00:38.080 --> 01:00:39.080]   No offense.
[01:00:39.080 --> 01:00:40.320]   Mind you.
[01:00:40.320 --> 01:00:45.560]   Uh, and they would say, well, I'm just speaking the truth, but I didn't want to offend you.
[01:00:45.560 --> 01:00:49.960]   The Southern Poverty Law Center said that they had asked Twitter to remove more than
[01:00:49.960 --> 01:00:56.320]   100 accounts of white supremacists who violated Twitter's terms of services.
[01:00:56.320 --> 01:01:01.840]   So they may have simply used Twitter's built in reporting tool.
[01:01:01.840 --> 01:01:05.000]   And Twitter may have just looked at the account and said, yeah, you're right.
[01:01:05.000 --> 01:01:08.440]   And I mean, I don't know exactly what happened, but I agree.
[01:01:08.440 --> 01:01:10.760]   This is a slippery slope too.
[01:01:10.760 --> 01:01:14.240]   Well, what do you think about this?
[01:01:14.240 --> 01:01:17.880]   We've done the rundown elsewhere, but so this, the, the Twitter finally comes out with
[01:01:17.880 --> 01:01:23.280]   efforts to deal with problems in Harris, so, so you can mute more things.
[01:01:23.280 --> 01:01:29.240]   That strikes me as a paper tiger because the, the, the, the, the Harris, but of you is
[01:01:29.240 --> 01:01:30.680]   going on all around you.
[01:01:30.680 --> 01:01:31.680]   You just don't know about it.
[01:01:31.680 --> 01:01:32.920]   I've always complained about this.
[01:01:32.920 --> 01:01:33.920]   Yeah.
[01:01:33.920 --> 01:01:37.640]   Twitter's response to me complaining about trolling was, well, just mute him.
[01:01:37.640 --> 01:01:38.640]   Yeah.
[01:01:38.640 --> 01:01:40.360]   So that's, that's fixed is nothing.
[01:01:40.360 --> 01:01:41.880]   That's putting your head in the sand.
[01:01:41.880 --> 01:01:42.880]   That's, yeah.
[01:01:42.880 --> 01:01:44.880]   What do you think Stacy?
[01:01:44.880 --> 01:01:49.800]   I don't think this is the solution.
[01:01:49.800 --> 01:01:55.000]   I don't think it's something that can be solved because people are going to behave like
[01:01:55.000 --> 01:01:56.000]   jerks.
[01:01:56.000 --> 01:02:02.160]   I think going, like I know Leo, you're like, Oh, our advertisers, you know, people are
[01:02:02.160 --> 01:02:06.080]   going to our advertisers and that sort of thing when people say bad things about you
[01:02:06.080 --> 01:02:08.560]   on Twitter.
[01:02:08.560 --> 01:02:14.840]   I think your advertisers and people in general HR people, they need to have a, a, a, a, a
[01:02:14.840 --> 01:02:17.640]   they need to take their information online with a grain of salt.
[01:02:17.640 --> 01:02:20.760]   So yeah, oddly enough, many of them don't.
[01:02:20.760 --> 01:02:23.040]   I know, I know.
[01:02:23.040 --> 01:02:27.960]   I'm just, so we then we have to have to talk with them and then they do there was actually,
[01:02:27.960 --> 01:02:30.600]   so this was a year ago or something.
[01:02:30.600 --> 01:02:32.120]   Somebody tweeted something horrible.
[01:02:32.120 --> 01:02:38.200]   Uh, no, I think what it was is I had said something about a sponsor and they tweeted
[01:02:38.200 --> 01:02:43.200]   it in a way that it sounded like I'd said something else and the sponsor wanted to make
[01:02:43.200 --> 01:02:48.400]   it clear that I hadn't meant that and they wanted to put out a press release, a press
[01:02:48.400 --> 01:02:49.560]   release.
[01:02:49.560 --> 01:02:51.200]   And I said, okay, so here's what you do.
[01:02:51.200 --> 01:02:52.160]   Go look at that account.
[01:02:52.160 --> 01:02:54.200]   How many followers does that person have?
[01:02:54.200 --> 01:02:55.200]   None.
[01:02:55.200 --> 01:02:57.600]   When was it created yesterday?
[01:02:57.600 --> 01:02:58.600]   Okay.
[01:02:58.600 --> 01:03:00.560]   So who saw that tweet?
[01:03:00.560 --> 01:03:02.120]   Us.
[01:03:02.120 --> 01:03:07.480]   And, and, and who will see it if you have a prep, put out a press release about it.
[01:03:07.480 --> 01:03:10.560]   Did you, did you tell them to go Google stress and effect?
[01:03:10.560 --> 01:03:11.560]   Yeah.
[01:03:11.560 --> 01:03:16.000]   And I had explained that as the point and you'd think you'd expect people would know better.
[01:03:16.000 --> 01:03:18.280]   No, but they don't.
[01:03:18.280 --> 01:03:21.400]   My favorite tweet of yesterday's my friend, John Robinson, who was a former newspaper
[01:03:21.400 --> 01:03:25.560]   editor said, boy, Jeff, people with 35 followers really don't like you.
[01:03:25.560 --> 01:03:32.960]   But that's actually, believe it or not, a sophisticated point of view.
[01:03:32.960 --> 01:03:33.960]   Oh, absolutely.
[01:03:33.960 --> 01:03:34.960]   And he understood that is.
[01:03:34.960 --> 01:03:37.760]   Oh, this is part of the problem I have with Twitter.
[01:03:37.760 --> 01:03:40.160]   I mean, I really hate Twitter in this point.
[01:03:40.160 --> 01:03:41.960]   Not having nothing to do with me.
[01:03:41.960 --> 01:03:45.640]   I, you know, but it just, this is a problem with Twitter, I think.
[01:03:45.640 --> 01:03:49.480]   I think it's a familiarity with the medium in a will, a missed to think critically, which
[01:03:49.480 --> 01:03:51.680]   people aren't necessarily able to do.
[01:03:51.680 --> 01:03:53.320]   But isn't that what we're saying about fake news?
[01:03:53.320 --> 01:03:58.240]   Like, because you were saying, give them, give them tools, Twitter gives us tools.
[01:03:58.240 --> 01:04:04.440]   We can see that this egg that's tweeting with us, you know, is an egg and has 10 followers.
[01:04:04.440 --> 01:04:07.840]   And then you're like, Oh, who cares what they think?
[01:04:07.840 --> 01:04:08.840]   Right.
[01:04:08.840 --> 01:04:14.520]   Well, anyway, I thought I'd just throw that Twitter story in and now we can move on.
[01:04:14.520 --> 01:04:19.480]   Let's let's talk about something that's about the Arnold router.
[01:04:19.480 --> 01:04:20.480]   The Arnold.
[01:04:20.480 --> 01:04:21.480]   No, almond router.
[01:04:21.480 --> 01:04:22.480]   Oh, Arnold router.
[01:04:22.480 --> 01:04:23.480]   I was a little bit older.
[01:04:23.480 --> 01:04:24.480]   Almond router.
[01:04:24.480 --> 01:04:28.440]   We should talk about it next week after I've had a chance to play with.
[01:04:28.440 --> 01:04:30.200]   Why is it different than other?
[01:04:30.200 --> 01:04:32.400]   Why is this router different than other router?
[01:04:32.400 --> 01:04:36.000]   Oh, oh, was that before the show?
[01:04:36.000 --> 01:04:37.000]   Okay.
[01:04:37.000 --> 01:04:38.000]   It was.
[01:04:38.000 --> 01:04:39.320]   I can't remember when things happened.
[01:04:39.320 --> 01:04:40.880]   That was before the show.
[01:04:40.880 --> 01:04:44.360]   So this is a router that came out today.
[01:04:44.360 --> 01:04:45.360]   And it is a.
[01:04:45.360 --> 01:04:47.520]   Oh, it's pretty.
[01:04:47.520 --> 01:04:48.520]   It's pretty.
[01:04:48.520 --> 01:04:55.360]   It's got a touchscreen and it's mesh network capable and it has Zigbee, Z wave, Bluetooth
[01:04:55.360 --> 01:04:59.440]   and Wi-Fi radios inside so it can control a lot of your smart home stuff or so you don't
[01:04:59.440 --> 01:05:00.440]   need a hub.
[01:05:00.440 --> 01:05:03.520]   So it could be hacked in all sorts of new in a different ways.
[01:05:03.520 --> 01:05:04.520]   Okay.
[01:05:04.520 --> 01:05:06.600]   So we can talk about that too.
[01:05:06.600 --> 01:05:07.600]   Z wave actually.
[01:05:07.600 --> 01:05:10.720]   Oh, no, that did not happen yet.
[01:05:10.720 --> 01:05:11.720]   Zigbee.
[01:05:11.720 --> 01:05:12.720]   Zigbee.
[01:05:12.720 --> 01:05:13.720]   We can talk about the Zigbee hack.
[01:05:13.720 --> 01:05:14.720]   Yes.
[01:05:14.720 --> 01:05:18.960]   Zigbee, a Hue lights were hacked using Zigbee as a, as an interview.
[01:05:18.960 --> 01:05:19.960]   Yes.
[01:05:19.960 --> 01:05:25.480]   Now, people are really upset about this now, but this was actually a vulnerability reported
[01:05:25.480 --> 01:05:26.480]   over a year ago.
[01:05:26.480 --> 01:05:27.480]   Oh, yeah.
[01:05:27.480 --> 01:05:28.480]   It's an old vulnerability.
[01:05:28.480 --> 01:05:30.800]   It's old vulnerability and it's a manufacturer's.
[01:05:30.800 --> 01:05:35.360]   It's actually Phillips Hue is bearing the brunt of this and they should be talking to their
[01:05:35.360 --> 01:05:36.360]   suppliers.
[01:05:36.360 --> 01:05:40.760]   So this is a, this is basically the tokens being put in the chips.
[01:05:40.760 --> 01:05:42.680]   Nothing you can do about it.
[01:05:42.680 --> 01:05:45.000]   In other words, right.
[01:05:45.000 --> 01:05:47.040]   Nothing Hue or I could do about it.
[01:05:47.040 --> 01:05:49.240]   Oh, I don't know why.
[01:05:49.240 --> 01:05:52.280]   You're still writing headlines.
[01:05:52.280 --> 01:05:53.760]   You haven't stopped.
[01:05:53.760 --> 01:05:55.680]   There we go.
[01:05:55.680 --> 01:06:02.760]   So this vulnerability, which is legit, is a chip thing and this kind of, it's going
[01:06:02.760 --> 01:06:07.080]   to get worse before it gets better you guys when it comes to the IoT because what we're
[01:06:07.080 --> 01:06:11.280]   seeing now is a bunch of people and you're going to hear about this in the coming weeks
[01:06:11.280 --> 01:06:16.880]   are suddenly like, holy cow, all the security stuff we like said was part of our product
[01:06:16.880 --> 01:06:18.680]   that people should follow.
[01:06:18.680 --> 01:06:19.680]   They're not following it.
[01:06:19.680 --> 01:06:22.640]   So we're going to make them follow it as part of certifications.
[01:06:22.640 --> 01:06:25.680]   So we're going to see that sort of thing coming down the pike and we're also going to
[01:06:25.680 --> 01:06:31.000]   see manufacturers get more, um, diligent.
[01:06:31.000 --> 01:06:34.640]   They're going to be their advice is going to get stronger, I guess, to a company.
[01:06:34.640 --> 01:06:37.960]   So we'll, they'll be like, Hey, I noticed that you're building something that doesn't
[01:06:37.960 --> 01:06:39.920]   look quite secure enough.
[01:06:39.920 --> 01:06:41.400]   Let me show you how it's done.
[01:06:41.400 --> 01:06:43.040]   I like that.
[01:06:43.040 --> 01:06:45.080]   Wouldn't that be nice?
[01:06:45.080 --> 01:06:48.680]   But that's the problem is that's not going to come to products for the next like 18 months
[01:06:48.680 --> 01:06:52.440]   to three years, depending on, and in the meantime, we've got all this old stuff.
[01:06:52.440 --> 01:06:55.440]   It's kind of like Microsoft clippy.
[01:06:55.440 --> 01:06:58.200]   Remember he used to say, I see you're writing a shopping list.
[01:06:58.200 --> 01:06:59.280]   Man, I help.
[01:06:59.280 --> 01:07:04.760]   I feel like it might be more like the protection squad coming around your small business saying,
[01:07:04.760 --> 01:07:06.400]   I see that you're doing this.
[01:07:06.400 --> 01:07:07.400]   Yeah.
[01:07:07.400 --> 01:07:09.200]   I think you're going to be forced into it.
[01:07:09.200 --> 01:07:13.880]   The way one more election story, we had talked before the election about the Department
[01:07:13.880 --> 01:07:20.800]   of Homeland Security going out for the states asking for help securing the election databases.
[01:07:20.800 --> 01:07:26.640]   Um, there was worry about election fraud, rigged system, et cetera, et cetera.
[01:07:26.640 --> 01:07:28.920]   Nothing happened, right?
[01:07:28.920 --> 01:07:29.920]   We know of.
[01:07:29.920 --> 01:07:30.920]   We know of.
[01:07:30.920 --> 01:07:33.440]   Well, we would, wouldn't we know about it by now?
[01:07:33.440 --> 01:07:34.440]   Mm.
[01:07:34.440 --> 01:07:35.440]   Mm.
[01:07:35.440 --> 01:07:36.440]   It was, it was really good.
[01:07:36.440 --> 01:07:37.440]   I mean, maybe not.
[01:07:37.440 --> 01:07:38.440]   Yeah.
[01:07:38.440 --> 01:07:39.960]   Oh, maybe that's it.
[01:07:39.960 --> 01:07:41.680]   Maybe we lost because we were hacked.
[01:07:41.680 --> 01:07:42.680]   I'm going to that.
[01:07:42.680 --> 01:07:43.880]   Is that a note thing?
[01:07:43.880 --> 01:07:45.280]   Stop talking about the election?
[01:07:45.280 --> 01:07:46.280]   Yes.
[01:07:46.280 --> 01:07:47.280]   Yeah.
[01:07:47.280 --> 01:07:48.280]   Good.
[01:07:48.280 --> 01:07:49.280]   Good.
[01:07:49.280 --> 01:07:51.080]   No, I got that note earlier actually.
[01:07:51.080 --> 01:07:53.160]   Uh, I ignored it.
[01:07:53.160 --> 01:07:56.360]   You know me, I'm a rebel.
[01:07:56.360 --> 01:07:57.360]   I want to take a break.
[01:07:57.360 --> 01:08:00.880]   We do have, there's so much, uh, there's a lot of other stuff happening.
[01:08:00.880 --> 01:08:09.480]   Other stuff, uh, news from Google and one plus one, uh, just, just on and sorry.
[01:08:09.480 --> 01:08:12.960]   I got so excited when you said news from Google, because we could talk about the photo skating
[01:08:12.960 --> 01:08:13.960]   thing.
[01:08:13.960 --> 01:08:14.960]   Yes.
[01:08:14.960 --> 01:08:17.320]   That's one of, that's what actually they just handed me a photo so I could demonstrate
[01:08:17.320 --> 01:08:18.320]   it.
[01:08:18.320 --> 01:08:19.320]   Oh, okay.
[01:08:19.320 --> 01:08:20.320]   Because I want to understand it.
[01:08:20.320 --> 01:08:21.320]   I want to get it.
[01:08:21.320 --> 01:08:22.320]   I don't understand.
[01:08:22.320 --> 01:08:23.320]   Yeah.
[01:08:23.320 --> 01:08:24.320]   We'll do that when we come back.
[01:08:24.320 --> 01:08:26.040]   Um, and, uh, let's see.
[01:08:26.040 --> 01:08:31.840]   Oh, a big, a big acquisition, a big acquisition, just an eight billion dollar acquisition.
[01:08:31.840 --> 01:08:33.840]   Just how old that you may not.
[01:08:33.840 --> 01:08:37.720]   Oh, oh, we talked about, well, I'm going to stay and listen.
[01:08:37.720 --> 01:08:39.960]   Oh, I'm ruining your, I'm ruining your state.
[01:08:39.960 --> 01:08:40.960]   Thanks.
[01:08:40.960 --> 01:08:42.320]   Yeah, we're talking about Sam.
[01:08:42.320 --> 01:08:44.360]   Something else you'd like to say about that?
[01:08:44.360 --> 01:08:46.000]   No, it's fine.
[01:08:46.000 --> 01:08:50.200]   Uh, and why you might not want to use a cheap Android phone.
[01:08:50.200 --> 01:08:51.200]   Yeah.
[01:08:51.200 --> 01:08:52.200]   Holy cow.
[01:08:52.200 --> 01:08:53.560]   Did you open your pixel box?
[01:08:53.560 --> 01:08:54.560]   Did you keep it?
[01:08:54.560 --> 01:08:58.520]   Do you like it?
[01:08:58.520 --> 01:09:03.960]   Yeah, I had one, when we come back, I will tell you about my, it was in the box and I
[01:09:03.960 --> 01:09:06.360]   had one big problem.
[01:09:06.360 --> 01:09:08.840]   Uh, oh, when we come, so that's also a tease.
[01:09:08.840 --> 01:09:09.840]   Another tease.
[01:09:09.840 --> 01:09:10.840]   Jeff rant.
[01:09:10.840 --> 01:09:15.640]   I'm sure they can't wait to hear me whine and a big anniversary that I want to celebrate.
[01:09:15.640 --> 01:09:18.440]   But first, let's talk about food.
[01:09:18.440 --> 01:09:20.480]   Glorious food.
[01:09:20.480 --> 01:09:22.640]   Stacy's sitting there.
[01:09:22.640 --> 01:09:25.680]   She knows after this show, she's got a responsibility.
[01:09:25.680 --> 01:09:31.800]   She's got a spatch cock of chicken or whatever it is she does.
[01:09:31.800 --> 01:09:34.880]   Dinner's, dinner's, you know, it's almost dinner time.
[01:09:34.880 --> 01:09:37.480]   And you know how it is, you work long, hard day.
[01:09:37.480 --> 01:09:39.400]   You've been on podcast all day.
[01:09:39.400 --> 01:09:44.560]   Last thing you want to do, at least if you're me, think about a menu, plan a menu, go shopping
[01:09:44.560 --> 01:09:47.160]   for ingredients, go home and cook the menu.
[01:09:47.160 --> 01:09:49.320]   By then it's nine p.m.
[01:09:49.320 --> 01:09:51.240]   And you'd wish you'd gone to Applebee's.
[01:09:51.240 --> 01:09:53.040]   Or worse, you do what I do.
[01:09:53.040 --> 01:09:54.560]   You go, there's a jack-in-box in the way.
[01:09:54.560 --> 01:09:56.440]   I'm just going to stop there.
[01:09:56.440 --> 01:09:57.440]   Let's not do that.
[01:09:57.440 --> 01:09:58.440]   Let's go to Blue Apron instead.
[01:09:58.440 --> 01:10:03.160]   In fact, if you go now to Blue Apron.com/twit and get your first three meals free, and the
[01:10:03.160 --> 01:10:06.600]   next time you're wondering, what are we going to have for dinner tonight?
[01:10:06.600 --> 01:10:09.720]   You'll have something wonderful waiting for you.
[01:10:09.720 --> 01:10:16.000]   Blue Apron delivers seasonal, rush, rush, rush, a peach with fresh, high quality ingredients
[01:10:16.000 --> 01:10:19.160]   right to your door, always exactly the ingredients you need.
[01:10:19.160 --> 01:10:21.320]   Over extra so you don't waste.
[01:10:21.320 --> 01:10:24.560]   You need one clove of garlic, you got one clove down a whole head, which is nice.
[01:10:24.560 --> 01:10:29.440]   I always hate that seeing that clove of garlic rot there on my counter waiting for me to
[01:10:29.440 --> 01:10:31.800]   use it again, not with Blue Apron.
[01:10:31.800 --> 01:10:34.880]   And all the menus can be prepared in 40 minutes or less.
[01:10:34.880 --> 01:10:35.880]   They're delicious.
[01:10:35.880 --> 01:10:37.640]   Oh, they're getting ready for the holidays.
[01:10:37.640 --> 01:10:39.400]   Rose, turkey and cranberry sauce.
[01:10:39.400 --> 01:10:41.120]   Oh, that looks good.
[01:10:41.120 --> 01:10:42.640]   Oh, Brussels sprouts.
[01:10:42.640 --> 01:10:44.040]   I like Brussels sprouts.
[01:10:44.040 --> 01:10:45.040]   You know what?
[01:10:45.040 --> 01:10:46.600]   Brussels sprouts become a Thanksgiving side.
[01:10:46.600 --> 01:10:47.600]   Has that always been?
[01:10:47.600 --> 01:10:48.600]   Oh, yeah.
[01:10:48.600 --> 01:10:49.120]   Absolutely.
[01:10:49.120 --> 01:10:52.720]   And I love them, but many people hate them.
[01:10:52.720 --> 01:10:57.520]   But a great Brussels sprout recipe you see might be the ticket because they're so good
[01:10:57.520 --> 01:11:03.360]   for you, those little cruciferous just waiting to cure your cancer right there.
[01:11:03.360 --> 01:11:06.480]   The cancer fighting, you take a cancer fighting pill.
[01:11:06.480 --> 01:11:09.720]   Well, this is like that.
[01:11:09.720 --> 01:11:12.840]   I'm not making any false health claims.
[01:11:12.840 --> 01:11:17.640]   If you spend time eating out or maybe you go to those fancy grocery stores, you're going
[01:11:17.640 --> 01:11:24.880]   to spend a lot less, about 60% less with Blue Apron under $10 per person for a healthy
[01:11:24.880 --> 01:11:25.880]   home cooked meal.
[01:11:25.880 --> 01:11:28.960]   Plus, you get this great satisfying feeling that you made it.
[01:11:28.960 --> 01:11:30.600]   There's nothing like cooking for your family.
[01:11:30.600 --> 01:11:32.960]   It's like cooking up love.
[01:11:32.960 --> 01:11:33.960]   And it's just great.
[01:11:33.960 --> 01:11:37.440]   When they sit down to that Italian wedding soup and they go, wow, this is great.
[01:11:37.440 --> 01:11:40.000]   And they slurp it up in five seconds and they run out the door.
[01:11:40.000 --> 01:11:42.120]   You could just say, mm, mm.
[01:11:42.120 --> 01:11:43.120]   I cooked.
[01:11:43.120 --> 01:11:47.620]   You also get this great feeling in the house because the house smells wonderful.
[01:11:47.620 --> 01:11:53.020]   And by the way, the freshest, highest quality ingredients, seafood is sourced sustainably.
[01:11:53.020 --> 01:11:54.020]   The beef is raised.
[01:11:54.020 --> 01:11:55.880]   You mainly the chickens are free range.
[01:11:55.880 --> 01:11:58.480]   The pork's are raised natural as the stuff you would buy.
[01:11:58.480 --> 01:12:00.800]   Regenerative tomatoes are gorgeous.
[01:12:00.800 --> 01:12:03.200]   Oh, did you get heirloom from?
[01:12:03.200 --> 01:12:05.120]   I have never seen prettier tomatoes.
[01:12:05.120 --> 01:12:06.560]   I don't know how they do that.
[01:12:06.560 --> 01:12:08.560]   Really it's amazing.
[01:12:08.560 --> 01:12:09.560]   Mm hmm.
[01:12:09.560 --> 01:12:12.760]   And you'll sometimes you'll use ingredients you've never tried before and then you'll
[01:12:12.760 --> 01:12:13.920]   go, oh, I'm going to use that.
[01:12:13.920 --> 01:12:15.000]   I found a new bok choy.
[01:12:15.000 --> 01:12:16.000]   It's not bok choy.
[01:12:16.000 --> 01:12:17.000]   It's something else.
[01:12:17.000 --> 01:12:19.300]   But it's like a bok choy, but it's so good.
[01:12:19.300 --> 01:12:21.340]   It's my new thing, my new favorite thing.
[01:12:21.340 --> 01:12:22.700]   You look at that.
[01:12:22.700 --> 01:12:27.420]   See a little tiny bottle of sesame oil instead of the, you know, like a whole big one.
[01:12:27.420 --> 01:12:31.740]   Just the right amount of soy sauce or whatever it is you need.
[01:12:31.740 --> 01:12:32.740]   What's on the menu this week?
[01:12:32.740 --> 01:12:36.300]   We'll take a look pans here chicken with roasted fall vegetables and butter capers
[01:12:36.300 --> 01:12:37.500]   sauce.
[01:12:37.500 --> 01:12:41.940]   I guarantee you, you will be making butter capers sauce a lot all of a sudden, spicy
[01:12:41.940 --> 01:12:44.980]   lotus root and purple carrot stir fry with sweet potato noodles.
[01:12:44.980 --> 01:12:46.220]   Yes, they have vegetarian meals.
[01:12:46.220 --> 01:12:47.300]   You get to choose though.
[01:12:47.300 --> 01:12:51.140]   You go to blueapering.com you pick the menu for the week and that's what you're going
[01:12:51.140 --> 01:12:52.140]   to get.
[01:12:52.140 --> 01:12:56.980]   They have plans for couples and plans for families with kid friendly ingredients.
[01:12:56.980 --> 01:13:01.060]   And by the way, I love this research shows blue, apron families cook together nearly three
[01:13:01.060 --> 01:13:02.880]   times more often.
[01:13:02.880 --> 01:13:04.220]   And that is what you want.
[01:13:04.220 --> 01:13:06.100]   Trust me, crispy shrimp.
[01:13:06.100 --> 01:13:07.900]   Oh, boys.
[01:13:07.900 --> 01:13:09.140]   Pan seared chicken.
[01:13:09.140 --> 01:13:10.140]   Look at.
[01:13:10.140 --> 01:13:11.140]   Oh, Lordy.
[01:13:11.140 --> 01:13:13.900]   Lordy, Lordy.
[01:13:13.900 --> 01:13:15.700]   That looks delicious.
[01:13:15.700 --> 01:13:20.140]   Sweet chili glaze, cod, quinoa and broccoli burgers.
[01:13:20.140 --> 01:13:21.140]   Chicken roll a teeny.
[01:13:21.140 --> 01:13:22.140]   Oh, wait a minute.
[01:13:22.140 --> 01:13:23.140]   I want to know how to make that.
[01:13:23.140 --> 01:13:27.260]   Oh, I'll be ordering that tonight for my next box chicken roll a teeny.
[01:13:27.260 --> 01:13:29.460]   Oh, that looks good.
[01:13:29.460 --> 01:13:34.540]   Blueapering.com/twit your first three meals free and with free shipping blue apron ships
[01:13:34.540 --> 01:13:36.980]   to 99% of the continental United States.
[01:13:36.980 --> 01:13:39.260]   Short rib burgers on pretzel buns.
[01:13:39.260 --> 01:13:40.260]   Yeah.
[01:13:40.260 --> 01:13:42.460]   Do you love pretzel?
[01:13:42.460 --> 01:13:43.860]   Do you love the pretzel bread?
[01:13:43.860 --> 01:13:44.860]   Oh, yeah.
[01:13:44.860 --> 01:13:45.860]   I do.
[01:13:45.860 --> 01:13:46.860]   Yes.
[01:13:46.860 --> 01:13:49.860]   We go to a pretzel brook.
[01:13:49.860 --> 01:13:54.140]   We go to a restaurant that they fresh baked pretzel bread.
[01:13:54.140 --> 01:13:55.140]   It's up in Healdsburg.
[01:13:55.140 --> 01:13:57.340]   I'll take you guys there if you ever come visit.
[01:13:57.340 --> 01:13:59.220]   It's up on Healdsburg.
[01:13:59.220 --> 01:14:00.220]   Healdsburg.
[01:14:00.220 --> 01:14:01.220]   Healdsburg.
[01:14:01.220 --> 01:14:02.220]   Healdsburg.
[01:14:02.220 --> 01:14:03.220]   Healdsburg.
[01:14:03.220 --> 01:14:04.220]   And they, it's fresh.
[01:14:04.220 --> 01:14:06.620]   So it's warm, fresh right out of the oven, steaming.
[01:14:06.620 --> 01:14:14.260]   And then they serve with it a lard and mustard butter that you would just like flip your lid.
[01:14:14.260 --> 01:14:16.860]   And you eat that and it's heaven.
[01:14:16.860 --> 01:14:18.580]   All right.
[01:14:18.580 --> 01:14:19.580]   I'm starving already.
[01:14:19.580 --> 01:14:20.580]   Blue.
[01:14:20.580 --> 01:14:21.580]   I know.
[01:14:21.580 --> 01:14:22.580]   Blueapering.com/twit.
[01:14:22.580 --> 01:14:23.580]   I know.
[01:14:23.580 --> 01:14:24.580]   I hate doing these ads.
[01:14:24.580 --> 01:14:25.580]   It made me hungry.
[01:14:25.580 --> 01:14:28.020]   At least I know it's waiting for me at home.
[01:14:28.020 --> 01:14:29.020]   All right.
[01:14:29.020 --> 01:14:31.140]   So, what should we start with?
[01:14:31.140 --> 01:14:32.140]   The quick one is a quickie.
[01:14:32.140 --> 01:14:36.220]   Samsung has just acquired Harmon Carden for eight billion.
[01:14:36.220 --> 01:14:37.220]   Harmon.
[01:14:37.220 --> 01:14:38.540]   Harmon, not Harmon Carden.
[01:14:38.540 --> 01:14:39.540]   Eight billion.
[01:14:39.540 --> 01:14:40.740]   Thank you for the correction.
[01:14:40.740 --> 01:14:42.420]   They're not called Harmon Carden anymore.
[01:14:42.420 --> 01:14:43.580]   They're just Harmon.
[01:14:43.580 --> 01:14:47.060]   It's, they do car accessories.
[01:14:47.060 --> 01:14:51.780]   Harmon International Industries, Incorporated, which is high.
[01:14:51.780 --> 01:14:54.740]   They design and manufacture connected automobile entertainment systems.
[01:14:54.740 --> 01:15:01.540]   I'm actually kind of interested in this because Twit is on the Harmon Carden radios.
[01:15:01.540 --> 01:15:02.540]   They have podcasts.
[01:15:02.540 --> 01:15:04.420]   Well, it's also, it's also Homestep too.
[01:15:04.420 --> 01:15:06.740]   They do speakers as well still.
[01:15:06.740 --> 01:15:07.740]   Okay.
[01:15:07.740 --> 01:15:08.740]   Samsung.
[01:15:08.740 --> 01:15:11.780]   Samsung acquired smart things.
[01:15:11.780 --> 01:15:17.060]   They really, they, they want to be a player, don't they, in this, uh, sis area?
[01:15:17.060 --> 01:15:18.060]   Connected home?
[01:15:18.060 --> 01:15:19.700]   Yeah, they do.
[01:15:19.700 --> 01:15:22.260]   And they also have a cloud service.
[01:15:22.260 --> 01:15:29.140]   They also make modules, little connected chip modules that you can build into products
[01:15:29.140 --> 01:15:31.020]   for IoT.
[01:15:31.020 --> 01:15:39.820]   And I look at this and I'm like, it's natural that I feel like, sorry, let me just, let
[01:15:39.820 --> 01:15:41.340]   me just start all over again.
[01:15:41.340 --> 01:15:43.420]   I feel like this is a natural deal for them.
[01:15:43.420 --> 01:15:45.620]   The car is going to be connected.
[01:15:45.620 --> 01:15:48.780]   The question is, who's going to do the connecting and what is the OS?
[01:15:48.780 --> 01:15:54.900]   And so getting in there with this buy makes sense and getting into speakers makes sense
[01:15:54.900 --> 01:15:58.260]   because your home's going to have to have a voice too.
[01:15:58.260 --> 01:16:01.980]   And they also bought a Chinese electric or a big stake in a Chinese electric car maker
[01:16:01.980 --> 01:16:03.980]   BYD company.
[01:16:03.980 --> 01:16:09.740]   Um, one, one, one analyst said, this is Samsung's life after smartphones.
[01:16:09.740 --> 01:16:10.740]   Mm.
[01:16:10.740 --> 01:16:11.940]   Yeah, that's a good idea.
[01:16:11.940 --> 01:16:12.940]   Yeah.
[01:16:12.940 --> 01:16:15.660]   Like what do you do when your phone business blows up?
[01:16:15.660 --> 01:16:20.060]   Oh, that's not totally here because Samsung has a huge appliance business.
[01:16:20.060 --> 01:16:21.060]   Oh, yeah.
[01:16:21.060 --> 01:16:22.060]   It has all these other people.
[01:16:22.060 --> 01:16:24.500]   The mobile business was 5% of their overall market.
[01:16:24.500 --> 01:16:25.580]   Yeah.
[01:16:25.580 --> 01:16:27.100]   So it's a small amount.
[01:16:27.100 --> 01:16:32.500]   Nevertheless, it was their future, you know, you can only sell so many refrigerators and
[01:16:32.500 --> 01:16:34.700]   bulldozers.
[01:16:34.700 --> 01:16:39.260]   At some point you got to, you know, you want to be in a big consumer category.
[01:16:39.260 --> 01:16:43.060]   So apparently electric cars are going to be a big thing for them as well.
[01:16:43.060 --> 01:16:45.660]   And all the things that go inside them.
[01:16:45.660 --> 01:16:47.020]   So many things.
[01:16:47.020 --> 01:16:51.900]   And Harman stuff is sold in BMW's, Volkswagen's and GM.
[01:16:51.900 --> 01:16:54.540]   So, so who will buy Bose?
[01:16:54.540 --> 01:16:57.020]   Does someone argue on Bose?
[01:16:57.020 --> 01:17:00.380]   No, Bose Bose was held by the family.
[01:17:00.380 --> 01:17:06.420]   And of course, Mr. Bose just passed, Dr. Bose passed away fairly recently.
[01:17:06.420 --> 01:17:10.220]   So that actually you may be exactly right.
[01:17:10.220 --> 01:17:18.540]   I think MIT still owns a huge stake in Bose because Dr. Bose gave them stock in the company
[01:17:18.540 --> 01:17:19.540]   when he created it.
[01:17:19.540 --> 01:17:21.300]   He was from MIT.
[01:17:21.300 --> 01:17:25.660]   Amar Bose founded it in 1964.
[01:17:25.660 --> 01:17:26.660]   You're right, Stacey.
[01:17:26.660 --> 01:17:28.860]   I think Bose would be a good acquisition.
[01:17:28.860 --> 01:17:29.860]   All right.
[01:17:29.860 --> 01:17:32.580]   And then you want to take a look at you want to talk about this?
[01:17:32.580 --> 01:17:33.860]   I got I can demo it.
[01:17:33.860 --> 01:17:37.340]   Why don't you tell us, Stacey, what this is, this photo scanner thing.
[01:17:37.340 --> 01:17:39.580]   Oh, I was like the phone.
[01:17:39.580 --> 01:17:40.580]   What is this?
[01:17:40.580 --> 01:17:43.260]   Have you ever seen one of these?
[01:17:43.260 --> 01:17:44.260]   All right.
[01:17:44.260 --> 01:17:46.740]   The photo scanner Google announced this this week.
[01:17:46.740 --> 01:17:51.620]   It basically allows you to take a picture, but it's not actually a picture.
[01:17:51.620 --> 01:17:54.580]   So you scan an old print picture.
[01:17:54.580 --> 01:17:59.260]   So all of your old school print pictures for those of us who are like older than 25.
[01:17:59.260 --> 01:18:01.700]   You can use the phone as a formal scanner.
[01:18:01.700 --> 01:18:03.860]   So it increases the high resolution image.
[01:18:03.860 --> 01:18:05.580]   It's not lossy.
[01:18:05.580 --> 01:18:09.580]   And it then stores it in Google's cloud where you can presumably organize it and do great
[01:18:09.580 --> 01:18:10.580]   things with it.
[01:18:10.580 --> 01:18:15.320]   And I, as I'm about to demonstrate, the thing they say right up front is position photo
[01:18:15.320 --> 01:18:17.540]   within frame tap button starts scanning.
[01:18:17.540 --> 01:18:18.980]   Don't worry about glare.
[01:18:18.980 --> 01:18:21.740]   Well, this is a very glossy photo.
[01:18:21.740 --> 01:18:25.980]   So okay, I'm going to position the photo within the frame, even though it's kind of weirdly
[01:18:25.980 --> 01:18:28.660]   angled, turns on the flash.
[01:18:28.660 --> 01:18:33.820]   Now it says, I don't, you can you see it, move this circle over a dot.
[01:18:33.820 --> 01:18:36.180]   So it's figured out what's, what it wants.
[01:18:36.180 --> 01:18:39.340]   And it says, do this.
[01:18:39.340 --> 01:18:41.660]   And I should be able to get a full.
[01:18:41.660 --> 01:18:44.020]   So that was four or five images.
[01:18:44.020 --> 01:18:45.020]   Nice work.
[01:18:45.020 --> 01:18:46.580]   Your photo is being processed.
[01:18:46.580 --> 01:18:52.740]   So this is the image, a very glossy image of my friend, Wynton and Vince surf in their
[01:18:52.740 --> 01:18:55.380]   one, and in Vince wine cellar, it looks like.
[01:18:55.380 --> 01:18:56.380]   How will it do?
[01:18:56.380 --> 01:18:57.860]   Not great.
[01:18:57.860 --> 01:19:00.060]   I have to say that's that there's glare.
[01:19:00.060 --> 01:19:01.060]   There's glare.
[01:19:01.060 --> 01:19:02.060]   Yeah.
[01:19:02.060 --> 01:19:04.980]   Well, you're also in a studio with a hell of a lot of.
[01:19:04.980 --> 01:19:05.980]   That's true.
[01:19:05.980 --> 01:19:06.980]   It's an unusual amount of light.
[01:19:06.980 --> 01:19:11.180]   But what it did do is straighten it perfectly and stitch it perfectly.
[01:19:11.180 --> 01:19:14.180]   So so that's impressive.
[01:19:14.180 --> 01:19:16.820]   You can adjust the corners.
[01:19:16.820 --> 01:19:19.300]   You can rotate it.
[01:19:19.300 --> 01:19:20.300]   Let's see.
[01:19:20.300 --> 01:19:21.300]   What else can we do with it?
[01:19:21.300 --> 01:19:22.300]   Now that's about it.
[01:19:22.300 --> 01:19:26.980]   Looks like a just corners, which is you see how it figured out what square on that from
[01:19:26.980 --> 01:19:28.980]   the initial image.
[01:19:28.980 --> 01:19:33.140]   I bet you I could do another one and see if I'd do a better job of it.
[01:19:33.140 --> 01:19:34.140]   What do you think?
[01:19:34.140 --> 01:19:35.140]   Should I try again?
[01:19:35.140 --> 01:19:37.500]   I did one last night and it looked good.
[01:19:37.500 --> 01:19:39.380]   But again, I was not.
[01:19:39.380 --> 01:19:42.060]   It was a glossy photo, but it was not your studio.
[01:19:42.060 --> 01:19:43.060]   Yeah.
[01:19:43.060 --> 01:19:44.060]   Right.
[01:19:44.060 --> 01:19:49.500]   Well, and I think by moving it around, you can only get it so could do so much to ungloss
[01:19:49.500 --> 01:19:51.700]   it, right?
[01:19:51.700 --> 01:19:52.700]   Let's try one more.
[01:19:52.700 --> 01:19:55.740]   I'll give it one more shot here.
[01:19:55.740 --> 01:19:57.820]   By the way, my thumb is going to be in the shot now.
[01:19:57.820 --> 01:19:58.820]   Let's see.
[01:19:58.820 --> 01:19:59.820]   All right.
[01:19:59.820 --> 01:20:00.820]   Now it's processing it.
[01:20:00.820 --> 01:20:01.820]   Let's see here.
[01:20:01.820 --> 01:20:04.020]   Oh, yeah, that's much better.
[01:20:04.020 --> 01:20:05.020]   Look at that.
[01:20:05.020 --> 01:20:06.020]   There it is.
[01:20:06.020 --> 01:20:07.020]   Did it take your thumb out?
[01:20:07.020 --> 01:20:09.660]   No, my thumb is still there.
[01:20:09.660 --> 01:20:13.300]   So I'm getting these little kids.
[01:20:13.300 --> 01:20:18.620]   But yeah, that's actually it looks like it did a pretty, pretty good job.
[01:20:18.620 --> 01:20:25.260]   This would be painful for doing this for like all of your photos.
[01:20:25.260 --> 01:20:27.940]   But you know, hey, it is nice.
[01:20:27.940 --> 01:20:30.140]   I might do it for a couple of my wedding photos.
[01:20:30.140 --> 01:20:31.820]   Yeah, because you have prints.
[01:20:31.820 --> 01:20:34.860]   You don't have you don't have digital versions of.
[01:20:34.860 --> 01:20:39.380]   I actually have a CD, which I should probably move to something.
[01:20:39.380 --> 01:20:40.380]   Wow.
[01:20:40.380 --> 01:20:43.060]   I guess you got married in the 80s, didn't you?
[01:20:43.060 --> 01:20:45.180]   No, it's teasing you.
[01:20:45.180 --> 01:20:46.180]   Tazing.
[01:20:46.180 --> 01:20:49.980]   So once you do this, it gets imported into your Google photos where you do have, of course,
[01:20:49.980 --> 01:20:52.700]   many more edit tools.
[01:20:52.700 --> 01:20:53.700]   That's pretty cool.
[01:20:53.700 --> 01:20:54.700]   It's free.
[01:20:54.700 --> 01:20:55.700]   Yeah.
[01:20:55.700 --> 01:21:03.980]   I have I have lots of and if you've ever done like family photos and wedding photos and
[01:21:03.980 --> 01:21:09.300]   those kinds of things, a lot of times you have to pay a lot extra for the digital imagery.
[01:21:09.300 --> 01:21:10.300]   Right.
[01:21:10.300 --> 01:21:12.700]   This is a really evil thing for me to do for photographers.
[01:21:12.700 --> 01:21:15.380]   So all my friends who are photographers, you're going to be mad at me.
[01:21:15.380 --> 01:21:18.700]   But now you have a way to like be like, Oh, I got my one print.
[01:21:18.700 --> 01:21:19.700]   Yeah.
[01:21:19.700 --> 01:21:20.860]   Yeah, they don't like that, do they?
[01:21:20.860 --> 01:21:21.860]   No, they don't.
[01:21:21.860 --> 01:21:22.860]   That's how they make money.
[01:21:22.860 --> 01:21:23.860]   So yeah.
[01:21:23.860 --> 01:21:24.860]   All right.
[01:21:24.860 --> 01:21:29.300]   Let's see what else there's actually quite a bit of new Google news.
[01:21:29.300 --> 01:21:33.740]   Google translate is going to get better.
[01:21:33.740 --> 01:21:38.900]   They're sending the so you first of all, Google translate is already super cool.
[01:21:38.900 --> 01:21:39.900]   Really good.
[01:21:39.900 --> 01:21:47.540]   Yeah, if you travel, you can fire up Google translate and say or type a phrase and it
[01:21:47.540 --> 01:21:51.780]   will say or sometimes type the resulting translation.
[01:21:51.780 --> 01:21:55.180]   It's very accurate 103 languages.
[01:21:55.180 --> 01:21:59.060]   It has the ability to do in some and many of those languages, a conversational back
[01:21:59.060 --> 01:22:00.060]   and forth.
[01:22:00.060 --> 01:22:01.060]   Jeff, you speak German.
[01:22:01.060 --> 01:22:03.660]   Is it pretty good?
[01:22:03.660 --> 01:22:04.660]   It's mistake.
[01:22:04.660 --> 01:22:08.060]   You think it'd be better at recognizing certain mistakes, but some things are really hard.
[01:22:08.060 --> 01:22:10.060]   German capitalizes nouns.
[01:22:10.060 --> 01:22:15.380]   It refers back as as an article a female noun is referred to as she.
[01:22:15.380 --> 01:22:16.940]   Right.
[01:22:16.940 --> 01:22:19.060]   No, we would think of it as an it.
[01:22:19.060 --> 01:22:23.620]   So there's things that you think they'd start to get to learn, but no, I mean equibbling.
[01:22:23.620 --> 01:22:28.260]   The point is that when I get flummoxed on a sentence, which is very often, my drummer
[01:22:28.260 --> 01:22:33.380]   is very bad, Google translate will lead me the right way.
[01:22:33.380 --> 01:22:34.380]   Yeah.
[01:22:34.380 --> 01:22:39.100]   Awkwardly, but it might get better because they're now applying neural machine translation
[01:22:39.100 --> 01:22:41.660]   and statistical models to the text.
[01:22:41.660 --> 01:22:44.780]   They've been doing this for a while.
[01:22:44.780 --> 01:22:49.180]   Well, today we're introducing the next step in making Google translate even better neural
[01:22:49.180 --> 01:22:50.180]   machine translation.
[01:22:50.180 --> 01:22:53.620]   Oh, they've been doing it, but it hasn't been inside Google translate.
[01:22:53.620 --> 01:22:54.620]   Maybe both research.
[01:22:54.620 --> 01:22:56.340]   I was like Jeff Hinton.
[01:22:56.340 --> 01:23:01.140]   All of his stuff is CNN research is on translation.
[01:23:01.140 --> 01:23:05.460]   They've had it, but they haven't put it into this nice free app yet.
[01:23:05.460 --> 01:23:06.460]   Got it.
[01:23:06.460 --> 01:23:09.100]   Today, we're putting neural machine translation into action with a total of eight language
[01:23:09.100 --> 01:23:14.460]   pairs to and from English and French, German, Spanish, Portuguese, Chinese, Japanese, Korean
[01:23:14.460 --> 01:23:16.300]   and Turkish.
[01:23:16.300 --> 01:23:20.980]   That's about a third of the world's population and more than 35% of all Google translate
[01:23:20.980 --> 01:23:22.780]   queries.
[01:23:22.780 --> 01:23:28.060]   The advantage of this, of course, is it's looking at a larger chunk of so it can do sentences
[01:23:28.060 --> 01:23:30.740]   because it understands context better.
[01:23:30.740 --> 01:23:33.060]   So here's a German phrase.
[01:23:33.060 --> 01:23:36.660]   I'll let you read this, Jeff.
[01:23:36.660 --> 01:23:42.700]   Problem at Kahn, mine, mine, Nemer's problems can one do never.
[01:23:42.700 --> 01:23:44.700]   It's the same.
[01:23:44.700 --> 01:23:46.700]   Dink by Zeg.
[01:23:46.700 --> 01:23:47.700]   Dink by Zeg.
[01:23:47.700 --> 01:23:51.260]   Duch, dai, zai, and Stadtenson.
[01:23:51.260 --> 01:23:53.420]   Now this is the old translation was no problem.
[01:23:53.420 --> 01:23:58.600]   It can be solved from the same consciousness that they have arisen, which is obviously
[01:23:58.600 --> 01:24:00.700]   fractured, but you can kind of understand it.
[01:24:00.700 --> 01:24:02.300]   The new translation problems can.
[01:24:02.300 --> 01:24:03.300]   No, no, no, no, no.
[01:24:03.300 --> 01:24:04.300]   Any sense.
[01:24:04.300 --> 01:24:07.700]   Anyway, any language problems can never be solved with the same way of thinking that caused
[01:24:07.700 --> 01:24:08.700]   them.
[01:24:08.700 --> 01:24:10.700]   That's a much more colloquial translation.
[01:24:10.700 --> 01:24:11.700]   Yeah.
[01:24:11.700 --> 01:24:14.300]   But let's philosophy really.
[01:24:14.300 --> 01:24:16.100]   This is what they're translating for us.
[01:24:16.100 --> 01:24:20.900]   Well, if you could do philosophy, you could easily do which way to the bathroom.
[01:24:20.900 --> 01:24:25.900]   Dondé a style, Banyo.
[01:24:25.900 --> 01:24:28.260]   Yeah.
[01:24:28.260 --> 01:24:29.700]   And there's more coming today too.
[01:24:29.700 --> 01:24:32.700]   They continue on in this blog post.
[01:24:32.700 --> 01:24:36.420]   Google Cloud Platform, our public cloud service offers machine learning APIs that make it
[01:24:36.420 --> 01:24:39.620]   easy for anyone to use our machine learning technology.
[01:24:39.620 --> 01:24:43.740]   And today, Google Cloud Platform is also making the system behind neural machine translation
[01:24:43.740 --> 01:24:49.500]   available for all businesses through a Google Cloud translation API.
[01:24:49.500 --> 01:24:50.500]   Wow.
[01:24:50.500 --> 01:24:53.620]   Oh, oh, that is pretty amazing.
[01:24:53.620 --> 01:24:54.620]   They're given that one.
[01:24:54.620 --> 01:24:56.540]   Well, maybe they're not giving it away.
[01:24:56.540 --> 01:25:01.820]   But that they're opening that up is pretty great.
[01:25:01.820 --> 01:25:05.460]   And you know, a lot of this was done with community support in their translation community.
[01:25:05.460 --> 01:25:07.700]   So maybe, you know.
[01:25:07.700 --> 01:25:12.900]   Well, if you want to catalog the world's information, it makes sense that you would
[01:25:12.900 --> 01:25:15.060]   translation is a key part of that.
[01:25:15.060 --> 01:25:16.060]   Right.
[01:25:16.060 --> 01:25:18.900]   Oh, we got all get on the same page here.
[01:25:18.900 --> 01:25:22.340]   Oh, is this our tower of Babel?
[01:25:22.340 --> 01:25:23.340]   Yeah.
[01:25:23.340 --> 01:25:26.420]   We are in a tower of political Babel now.
[01:25:26.420 --> 01:25:27.420]   Nope.
[01:25:27.420 --> 01:25:31.780]   We also speak the same language, but it's got different meanings.
[01:25:31.780 --> 01:25:33.340]   So bad news.
[01:25:33.340 --> 01:25:37.980]   If you bought a blue phone, BLU, these have been very inexpensive phones, Android, but
[01:25:37.980 --> 01:25:39.780]   they also make Windows phones.
[01:25:39.780 --> 01:25:43.340]   And apparently they're made in China some security.
[01:25:43.340 --> 01:25:44.940]   It's about $50 for these blue phones.
[01:25:44.940 --> 01:25:49.420]   Security contractors have discovered some of these phones had pre-installed software
[01:25:49.420 --> 01:25:57.940]   that monitored user where users go, whom they talk to and what they write in text messages.
[01:25:57.940 --> 01:26:01.860]   Now the American authorities, according to the New York Times say it's not clear whether
[01:26:01.860 --> 01:26:07.380]   this represents a secretive data mining for advertising purposes or Chinese government
[01:26:07.380 --> 01:26:08.740]   effort to collect intelligence.
[01:26:08.740 --> 01:26:10.940]   I'm going to bet the former.
[01:26:10.940 --> 01:26:11.940]   Yeah.
[01:26:11.940 --> 01:26:15.140]   And this is the, I mean, Facebook does this, right?
[01:26:15.140 --> 01:26:16.140]   Yeah.
[01:26:16.140 --> 01:26:22.300]   So yeah, this is the name of the company is Shanghai Add-Ups Technology Company.
[01:26:22.300 --> 01:26:27.780]   700 million phones, cars and other smart devices, BLU, which is actually, I take it back.
[01:26:27.780 --> 01:26:33.980]   An American manufacturer, known as Chinese manufacturer, said that 120,000 of its phones
[01:26:33.980 --> 01:26:39.100]   had been affected, but they've updated the software to eliminate the feature.
[01:26:39.100 --> 01:26:41.140]   It sounds like it's really about ads.
[01:26:41.140 --> 01:26:47.860]   You know, monitor everything the user does and we'll give you better ads.
[01:26:47.860 --> 01:26:53.460]   They said that it wasn't, it was supposed to be on Chinese phones, but not.
[01:26:53.460 --> 01:26:55.860]   It was inadvertently put on American phones.
[01:26:55.860 --> 01:27:03.860]   No.
[01:27:03.860 --> 01:27:07.580]   Blue said we didn't know we fixed it.
[01:27:07.580 --> 01:27:08.740]   So can I ask you a different question?
[01:27:08.740 --> 01:27:10.100]   I'll do a different topic.
[01:27:10.100 --> 01:27:11.100]   Yeah.
[01:27:11.100 --> 01:27:14.420]   Have you, have you been using the new Android Auto on your phone?
[01:27:14.420 --> 01:27:15.420]   Not yet.
[01:27:15.420 --> 01:27:16.420]   No.
[01:27:16.420 --> 01:27:17.420]   What is it?
[01:27:17.420 --> 01:27:21.780]   Stacey, you can now, without Android Auto in the car, you can use and you can, you're,
[01:27:21.780 --> 01:27:27.940]   the current Android Auto will act like on your phone will act like it is in the car.
[01:27:27.940 --> 01:27:31.220]   So you'll have to download the app because it's a separate app.
[01:27:31.220 --> 01:27:34.940]   By the way, you know what, there have been auto, Samsung's offered an auto app.
[01:27:34.940 --> 01:27:37.260]   A lot of companies make apps.
[01:27:37.260 --> 01:27:41.660]   All the Samsung phones come with an app that when you are in a car, that simplified user
[01:27:41.660 --> 01:27:46.260]   interface comes up on your phone screen and it limits the kinds of things you can do to
[01:27:46.260 --> 01:27:50.220]   music, you know, ways, stuff like that.
[01:27:50.220 --> 01:27:52.580]   I have, I have like a freaking computer in my car.
[01:27:52.580 --> 01:27:53.820]   So I don't really worry about it.
[01:27:53.820 --> 01:27:54.820]   Yeah.
[01:27:54.820 --> 01:27:56.500]   We drive a Tesla, Jeff.
[01:27:56.500 --> 01:27:59.340]   So oh, humble, Brian.
[01:27:59.340 --> 01:28:01.900]   I do want an echo in my car.
[01:28:01.900 --> 01:28:05.340]   I find myself, because I can talk to my Tesla, which is nice.
[01:28:05.340 --> 01:28:07.900]   It's not as stupid, but it's dumb.
[01:28:07.900 --> 01:28:13.460]   And now I'm like, holy moly, you know, I'll be, I'll have like a legit question.
[01:28:13.460 --> 01:28:19.900]   And I'm like, oh, but in January, hopefully the Pebble core comes out and that's supposed
[01:28:19.900 --> 01:28:21.660]   to be like a little wearable Android button.
[01:28:21.660 --> 01:28:25.420]   Sorry, a little wearable echo button.
[01:28:25.420 --> 01:28:27.860]   So I'm hoping I'll be like, boo, boo.
[01:28:27.860 --> 01:28:29.820]   It's using the echo interface.
[01:28:29.820 --> 01:28:30.820]   So far.
[01:28:30.820 --> 01:28:31.820]   Oh, that's neat.
[01:28:31.820 --> 01:28:34.620]   Or it has a, yes, it has Alexa capability, Alexa voice service.
[01:28:34.620 --> 01:28:36.340]   That's really cool.
[01:28:36.340 --> 01:28:41.460]   So so I'm firing up the Android auto right now on my Pixel.
[01:28:41.460 --> 01:28:43.980]   Boy, it asks permission to do everything.
[01:28:43.980 --> 01:28:46.820]   It wants to think who wants an app in their car?
[01:28:46.820 --> 01:28:47.820]   That's a sucky way.
[01:28:47.820 --> 01:28:51.420]   If you don't have Android auto so that you put your, you know, your phone in your car
[01:28:51.420 --> 01:28:57.060]   and you see it on the car's screen, this way what you do is you, you have a mount and
[01:28:57.060 --> 01:29:02.620]   you put your phone there and then it's like, yeah, which will lead us to our story about
[01:29:02.620 --> 01:29:04.100]   the Pixel on a second.
[01:29:04.100 --> 01:29:08.860]   Oh, so let me just turn this on and see what it looks like permission needed.
[01:29:08.860 --> 01:29:11.660]   Oh, you have to connect it to, I can't do it because I was a car.
[01:29:11.660 --> 01:29:12.660]   Yeah.
[01:29:12.660 --> 01:29:14.380]   I should go with the phone.
[01:29:14.380 --> 01:29:15.380]   Oh, wait a minute.
[01:29:15.380 --> 01:29:16.820]   It says, yeah, Tesla Model X.
[01:29:16.820 --> 01:29:17.780]   Yeah.
[01:29:17.780 --> 01:29:19.140]   So I do this with my Tesla.
[01:29:19.140 --> 01:29:20.140]   Yeah.
[01:29:20.140 --> 01:29:21.140]   So here's the interface.
[01:29:21.140 --> 01:29:22.140]   Here's the interface.
[01:29:22.140 --> 01:29:23.140]   Yeah, here's my calendar.
[01:29:23.140 --> 01:29:25.580]   Very turn it this way, probably be better.
[01:29:25.580 --> 01:29:26.900]   No, this way is.
[01:29:26.900 --> 01:29:28.140]   I can still see my Tesla.
[01:29:28.140 --> 01:29:29.820]   My Tesla gives me my calendar.
[01:29:29.820 --> 01:29:30.820]   Right.
[01:29:30.820 --> 01:29:32.580]   But do you get this?
[01:29:32.580 --> 01:29:33.580]   Ways.
[01:29:33.580 --> 01:29:34.580]   Okay.
[01:29:34.580 --> 01:29:35.580]   Okay.
[01:29:35.580 --> 01:29:36.580]   Go find gas stations.
[01:29:36.580 --> 01:29:37.580]   That's Google maps.
[01:29:37.580 --> 01:29:38.580]   Google maps.
[01:29:38.580 --> 01:29:39.580]   Yeah.
[01:29:39.580 --> 01:29:40.580]   I do get Google maps.
[01:29:40.580 --> 01:29:42.100]   I can make a, so it's big buttons.
[01:29:42.100 --> 01:29:45.940]   I'm not going to show these phone numbers, but it's a big buttons, right?
[01:29:45.940 --> 01:29:49.060]   And then I can listen to music and you get to select which music app you can show it
[01:29:49.060 --> 01:29:51.020]   now, which music app you want.
[01:29:51.020 --> 01:29:52.020]   Yeah.
[01:29:52.020 --> 01:29:53.020]   So I'll cut it off.
[01:29:53.020 --> 01:29:55.260]   And it shuts down certain things that'd be dangerous.
[01:29:55.260 --> 01:29:56.260]   Yeah.
[01:29:56.260 --> 01:30:00.260]   It's a very, it's a very simple, simple interface like that.
[01:30:00.260 --> 01:30:05.500]   We need to buy a car until I get Android Auto.
[01:30:05.500 --> 01:30:08.380]   And I like it, but I don't know.
[01:30:08.380 --> 01:30:10.340]   It actually may not be selling to me.
[01:30:10.340 --> 01:30:11.340]   I don't know.
[01:30:11.340 --> 01:30:12.340]   What?
[01:30:12.340 --> 01:30:13.340]   Get the sun.
[01:30:13.340 --> 01:30:15.780]   Using the Android Auto Auto thing is what happens is when I, when I stop, I'm going to
[01:30:15.780 --> 01:30:19.620]   stop in the parking lot and I say, okay, look at Twitter now, well, I have to turn
[01:30:19.620 --> 01:30:21.580]   off Android Auto to do that.
[01:30:21.580 --> 01:30:22.580]   Yeah.
[01:30:22.580 --> 01:30:23.780]   Bit of a pain.
[01:30:23.780 --> 01:30:24.780]   Yeah.
[01:30:24.780 --> 01:30:27.020]   So it's, it's really only three apps.
[01:30:27.020 --> 01:30:31.940]   But see, because of this front page interface, I have my book.
[01:30:31.940 --> 01:30:33.980]   I have my navigation based on my calendar.
[01:30:33.980 --> 01:30:36.500]   I can hit that and would navigate to it.
[01:30:36.500 --> 01:30:39.220]   I have weather here, right?
[01:30:39.220 --> 01:30:41.340]   So let's say I want to go get my hearing aid tuned up.
[01:30:41.340 --> 01:30:45.300]   I just press that button and then I get.
[01:30:45.300 --> 01:30:51.220]   And then I get, and if it's paired to the speaker on the phone, it'll go over the car
[01:30:51.220 --> 01:30:52.220]   stuff.
[01:30:52.220 --> 01:30:53.220]   That's pretty good.
[01:30:53.220 --> 01:30:57.420]   You know what I might use is you'd need what you'd want as a mount on your dashboard
[01:30:57.420 --> 01:30:58.420]   or something.
[01:30:58.420 --> 01:30:59.420]   Yeah.
[01:30:59.420 --> 01:31:02.220]   I use the one that just goes, you know, we had all the complicated mounts.
[01:31:02.220 --> 01:31:03.220]   Yeah.
[01:31:03.220 --> 01:31:04.220]   Just need a suction cup.
[01:31:04.220 --> 01:31:05.860]   Oh, well, no, no, not even that.
[01:31:05.860 --> 01:31:10.300]   It goes into the ventilation and it just, yeah, just bring things like this, right?
[01:31:10.300 --> 01:31:14.060]   We always used to have these mounts that had, you know, two pounds of plastic and all
[01:31:14.060 --> 01:31:17.260]   the stuff and it was just so ridiculously overdone.
[01:31:17.260 --> 01:31:19.820]   Yeah, I have a little dashboard.
[01:31:19.820 --> 01:31:22.740]   I mean, that's a really easy way to do it.
[01:31:22.740 --> 01:31:23.740]   Yeah.
[01:31:23.740 --> 01:31:26.940]   So here's what I want to plug it in, obviously, and plug it into the.
[01:31:26.940 --> 01:31:27.940]   Yes.
[01:31:27.940 --> 01:31:28.940]   Yes.
[01:31:28.940 --> 01:31:29.940]   Yes.
[01:31:29.940 --> 01:31:30.940]   That's not bad.
[01:31:30.940 --> 01:31:32.940]   It's not better than the interface on most cars.
[01:31:32.940 --> 01:31:33.940]   You try it out.
[01:31:33.940 --> 01:31:35.420]   I'll be curious to hear your reaction to it.
[01:31:35.420 --> 01:31:37.020]   I'll try it on the way home.
[01:31:37.020 --> 01:31:38.020]   Okay.
[01:31:38.020 --> 01:31:39.580]   So you want to hear my pixel story?
[01:31:39.580 --> 01:31:40.580]   Yeah.
[01:31:40.580 --> 01:31:41.580]   So you have a pixel XL.
[01:31:41.580 --> 01:31:42.580]   XL.
[01:31:42.580 --> 01:31:43.580]   The big one.
[01:31:43.580 --> 01:31:47.580]   And I went back and forth and back and forth and the product has drives your audience crazy.
[01:31:47.580 --> 01:31:48.580]   You can't decide it.
[01:31:48.580 --> 01:31:49.580]   I box it up.
[01:31:49.580 --> 01:31:50.580]   I get all.
[01:31:50.580 --> 01:31:52.740]   So then I'm ready to say, okay, I'm going to, I think I'll keep it.
[01:31:52.740 --> 01:31:58.860]   They don't convince me and I should know about the dream and okay.
[01:31:58.860 --> 01:32:06.900]   So then I say, I, I open up the box and I go to take a draw and I go ahead and switch
[01:32:06.900 --> 01:32:12.980]   the SIM and I take my drive and the GPS is like 50 yards off.
[01:32:12.980 --> 01:32:13.980]   Yeah.
[01:32:13.980 --> 01:32:15.380]   So it's driving me completely.
[01:32:15.380 --> 01:32:18.180]   It almost got me into an accident because it's switching the directions or which makes
[01:32:18.180 --> 01:32:19.780]   the things that went that way and it's not going that way.
[01:32:19.780 --> 01:32:20.780]   That road you're going over.
[01:32:20.780 --> 01:32:22.380]   It's actually over there where you're over here.
[01:32:22.380 --> 01:32:23.380]   Geez.
[01:32:23.380 --> 01:32:24.380]   So I restarted.
[01:32:24.380 --> 01:32:25.380]   I do all of these posts.
[01:32:25.380 --> 01:32:28.060]   Do I go to the support forum and I talk to that?
[01:32:28.060 --> 01:32:30.180]   I do everything you're supposed to do.
[01:32:30.180 --> 01:32:32.100]   Two pieces of the story.
[01:32:32.100 --> 01:32:33.100]   One is, what?
[01:32:33.100 --> 01:32:34.100]   Okay.
[01:32:34.100 --> 01:32:35.100]   It's a pixel.
[01:32:35.100 --> 01:32:36.980]   Pixel has its own dedicated service, right?
[01:32:36.980 --> 01:32:38.460]   Wonderful Google service, right?
[01:32:38.460 --> 01:32:43.740]   So I call and I mean a nice person, but it was like calling Dell.
[01:32:43.740 --> 01:32:47.820]   Oh, I have a Google support story we could talk about too.
[01:32:47.820 --> 01:32:50.300]   I love Stacy's enthusiasm.
[01:32:50.300 --> 01:32:51.300]   Oh, good.
[01:32:51.300 --> 01:32:55.820]   She's not a burnout dried out old cynic like you and me.
[01:32:55.820 --> 01:32:58.380]   So I got all mad and unhappy, right?
[01:32:58.380 --> 01:33:00.460]   I'm growling and Twitter and all over.
[01:33:00.460 --> 01:33:03.340]   But then I go back to support forum and people there, you know, the beautiful thing
[01:33:03.340 --> 01:33:06.420]   about other customers is they're trying different things they're working out.
[01:33:06.420 --> 01:33:11.540]   So by the trick was it must have taken some kind of settings.
[01:33:11.540 --> 01:33:16.540]   There's problems with GPS on this phone, I think, with other other reasons people said.
[01:33:16.540 --> 01:33:22.140]   But if you delete the cache, delete the data, uninstall and then reinstall the app without
[01:33:22.140 --> 01:33:24.740]   signing in at first, it'll click on right.
[01:33:24.740 --> 01:33:26.380]   And so it's been working fine for about five days.
[01:33:26.380 --> 01:33:27.380]   So I'm keeping it.
[01:33:27.380 --> 01:33:28.680]   Oh, good.
[01:33:28.680 --> 01:33:29.680]   That was your only complaint?
[01:33:29.680 --> 01:33:33.500]   It was a big one because I use I depend upon ways every day.
[01:33:33.500 --> 01:33:35.900]   If I can't use ways, I am doomed.
[01:33:35.900 --> 01:33:36.900]   Yeah.
[01:33:36.900 --> 01:33:38.700]   All right, Stacy, over to you.
[01:33:38.700 --> 01:33:39.700]   Okay.
[01:33:39.700 --> 01:33:41.900]   So similar story, little different.
[01:33:41.900 --> 01:33:44.980]   I bought a Google home product, right?
[01:33:44.980 --> 01:33:45.980]   Yeah.
[01:33:45.980 --> 01:33:46.980]   And this was last week.
[01:33:46.980 --> 01:33:47.980]   I connected it.
[01:33:47.980 --> 01:33:48.980]   I was talking to it.
[01:33:48.980 --> 01:33:49.980]   It was exciting.
[01:33:49.980 --> 01:33:51.740]   And then I went to I connected my nest.
[01:33:51.740 --> 01:33:52.740]   That was good.
[01:33:52.740 --> 01:33:53.740]   It worked.
[01:33:53.740 --> 01:33:57.620]   Then I went to connect my Phillips Hue lights and it didn't work.
[01:33:57.620 --> 01:34:02.620]   And the process is you add the device, you click, it says, do you want nest Phillips Hue
[01:34:02.620 --> 01:34:04.100]   or smart things?
[01:34:04.100 --> 01:34:05.580]   And I said, oh, Phillips Hue.
[01:34:05.580 --> 01:34:10.540]   And then it opens up a browser window for the authentication for your lights.
[01:34:10.540 --> 01:34:13.860]   And during that process, when it did that, it was like, up failed.
[01:34:13.860 --> 01:34:16.540]   And so I was like, oh, I'll try it again.
[01:34:16.540 --> 01:34:17.540]   Didn't work.
[01:34:17.540 --> 01:34:19.220]   Because you weren't seeing it on your screen?
[01:34:19.220 --> 01:34:22.660]   I mean, no, it just it just said failed to connect.
[01:34:22.660 --> 01:34:24.300]   And I got the troubleshooting page.
[01:34:24.300 --> 01:34:26.740]   So the troubleshooting page was reboot.
[01:34:26.740 --> 01:34:31.940]   I'm sorry, reboot the Google home, reboot your Phillips Hue.
[01:34:31.940 --> 01:34:34.380]   And if that doesn't work, try something else.
[01:34:34.380 --> 01:34:37.980]   So then I went to the deeper troubleshooting page because that was the one that like it
[01:34:37.980 --> 01:34:39.620]   showed up when you failed.
[01:34:39.620 --> 01:34:43.260]   Oh, and it also said, make sure the lights are on on your Phillips Hue.
[01:34:43.260 --> 01:34:47.180]   All of that was working.
[01:34:47.180 --> 01:34:53.900]   So eventually I had to call support because the next level of support was not great.
[01:34:53.900 --> 01:34:59.340]   And that person was very nice, but she didn't, she basically walked me through the same steps
[01:34:59.340 --> 01:35:01.420]   that were on the website.
[01:35:01.420 --> 01:35:05.660]   And she failed to ask me what I feel are basic questions, like what are the routers you're
[01:35:05.660 --> 01:35:06.660]   using?
[01:35:06.660 --> 01:35:07.660]   What is your browser?
[01:35:07.660 --> 01:35:08.660]   Right.
[01:35:08.660 --> 01:35:14.700]   So then, but I spent half an hour on the phone with a person and my lights weren't connected.
[01:35:14.700 --> 01:35:17.380]   She was very nice.
[01:35:17.380 --> 01:35:20.180]   And then she was like, I don't know.
[01:35:20.180 --> 01:35:23.380]   She brought in some people apparently that she was talking to.
[01:35:23.380 --> 01:35:26.700]   And she's like in 48 or 24 to 48 hours, you'll have an answer.
[01:35:26.700 --> 01:35:27.980]   And I was like, wow.
[01:35:27.980 --> 01:35:28.980]   Okay.
[01:35:28.980 --> 01:35:33.740]   So then I get this email from Google with my answer.
[01:35:33.740 --> 01:35:37.860]   And it had the same like first six steps.
[01:35:37.860 --> 01:35:42.860]   And then it was like, then it went into uninstall the app, reinstall it.
[01:35:42.860 --> 01:35:46.780]   And then it was like, if that didn't work, just try it on a different device.
[01:35:46.780 --> 01:35:51.060]   And I was like, and that was it.
[01:35:51.060 --> 01:35:54.980]   I complained about it on my podcast and I actually got the right answer from Phillips.
[01:35:54.980 --> 01:36:00.500]   They were like, look, you are using adblock as your browser and it only supports Chrome
[01:36:00.500 --> 01:36:01.500]   and Safari.
[01:36:01.500 --> 01:36:02.500]   Of course.
[01:36:02.500 --> 01:36:07.340]   And someone else on Twitter was like, hey, you know, I was using Firefox as my browser.
[01:36:07.340 --> 01:36:09.060]   And it didn't work for me either.
[01:36:09.060 --> 01:36:11.060]   But at no point in time during the Google.
[01:36:11.060 --> 01:36:13.580]   They say what browser are you using?
[01:36:13.580 --> 01:36:14.580]   They never ask.
[01:36:14.580 --> 01:36:17.940]   Because sometimes sometimes the mesh network routers can be weird.
[01:36:17.940 --> 01:36:18.940]   Right.
[01:36:18.940 --> 01:36:19.940]   There's a lot of challenges.
[01:36:19.940 --> 01:36:20.940]   Yeah.
[01:36:20.940 --> 01:36:22.500]   All those things you need to know.
[01:36:22.500 --> 01:36:23.500]   Yeah.
[01:36:23.500 --> 01:36:26.500]   And then you need to know that you're using the same thing.
[01:36:26.500 --> 01:36:30.500]   And then you need to know that you're using the same thing.
[01:36:30.500 --> 01:36:33.500]   And then you need to know that you're using the same thing.
[01:36:33.500 --> 01:36:36.500]   And then you need to know that you're using the same thing.
[01:36:36.500 --> 01:36:39.500]   And then you need to know that you're using the same thing.
[01:36:39.500 --> 01:36:41.500]   And then you need to know that you're using the same thing.
[01:36:41.500 --> 01:36:43.500]   And then you need to know that you're using the same thing.
[01:36:43.500 --> 01:36:44.500]   And then you need to know that you're using the same thing.
[01:36:44.500 --> 01:36:45.500]   And then you need to know that you're using the same thing.
[01:36:45.500 --> 01:36:46.500]   And then you need to know that you're using the same thing.
[01:36:46.500 --> 01:36:47.500]   And then you need to know that you're using the same thing.
[01:36:47.500 --> 01:36:48.500]   And then you need to know that you're using the same thing.
[01:36:48.500 --> 01:36:49.500]   And then you need to know that you're using the same thing.
[01:36:49.500 --> 01:36:52.500]   And then you need to know that you're using the same thing.
[01:36:52.500 --> 01:36:54.500]   And then you need to know that you're using the same thing.
[01:36:54.500 --> 01:36:57.500]   And then you need to know that you're using the same thing.
[01:36:57.500 --> 01:36:59.500]   And then you need to know that you're using the same thing.
[01:36:59.500 --> 01:37:01.500]   And then you need to know that you're using the same thing.
[01:37:01.500 --> 01:37:03.500]   And then you need to know that you're using the same thing.
[01:37:03.500 --> 01:37:05.500]   And then you need to know that you're using the same thing.
[01:37:05.500 --> 01:37:07.500]   And then you need to know that you're using the same thing.
[01:37:07.500 --> 01:37:08.500]   And then you need to know that you're using the same thing.
[01:37:08.500 --> 01:37:10.500]   And then you need to know that you're using the same thing.
[01:37:10.500 --> 01:37:11.500]   And then you need to know that you're using the same thing.
[01:37:11.500 --> 01:37:12.500]   And then you need to know that you're using the same thing.
[01:37:12.500 --> 01:37:13.500]   And then you need to know that you're using the same thing.
[01:37:13.500 --> 01:37:18.500]   And then you need to know that you're using the same thing.
[01:37:18.500 --> 01:37:21.500]   And then you need to know that you're using the same thing.
[01:37:21.500 --> 01:37:23.500]   And then you need to know that you're using the same thing.
[01:37:23.500 --> 01:37:26.500]   And then you need to know that you're using the same thing.
[01:37:26.500 --> 01:37:28.500]   And then you need to know that you're using the same thing.
[01:37:28.500 --> 01:37:30.500]   And then you need to know that you're using the same thing.
[01:37:30.500 --> 01:37:32.500]   And then you need to know that you're using the same thing.
[01:37:32.500 --> 01:37:34.500]   And then you need to know that you're using the same thing.
[01:37:34.500 --> 01:37:36.500]   And then you need to know that you're using the same thing.
[01:37:36.500 --> 01:37:38.500]   And then you need to know that you're using the same thing.
[01:37:38.500 --> 01:37:39.500]   And then you need to know that you're using the same thing.
[01:37:39.500 --> 01:37:40.500]   And then you need to know that you're using the same thing.
[01:37:40.500 --> 01:37:43.500]   And then you need to know that you're using the same thing.
[01:37:43.500 --> 01:37:45.500]   And then you need to know that you're using the same thing.
[01:37:45.500 --> 01:37:48.500]   And then you need to know that you're using the same thing.
[01:37:48.500 --> 01:37:50.500]   And then you need to know that you're using the same thing.
[01:37:50.500 --> 01:37:52.500]   And then you need to know that you're using the same thing.
[01:37:52.500 --> 01:37:54.500]   And then you need to know that you're using the same thing.
[01:37:54.500 --> 01:37:55.500]   And then you need to know that you're using the same thing.
[01:37:55.500 --> 01:37:57.500]   And then you need to know that you're using the same thing.
[01:37:57.500 --> 01:37:59.500]   And then you need to know that you're using the same thing.
[01:37:59.500 --> 01:38:01.500]   And then you need to know that you're using the same thing.
[01:38:01.500 --> 01:38:02.500]   And then you need to know that you're using the same thing.
[01:38:02.500 --> 01:38:03.500]   And then you need to know that you're using the same thing.
[01:38:03.500 --> 01:38:04.500]   And then you need to know that you're using the same thing.
[01:38:04.500 --> 01:38:11.500]   And then you need to know that you're using the same thing.
[01:38:11.500 --> 01:38:14.500]   And then you need to know that you're using the same thing.
[01:38:14.500 --> 01:38:17.500]   And then you need to know that you're using the same thing.
[01:38:17.500 --> 01:38:19.500]   And then you need to know that you're using the same thing.
[01:38:19.500 --> 01:38:21.500]   And then you need to know that you're using the same thing.
[01:38:21.500 --> 01:38:23.500]   And then you need to know that you're using the same thing.
[01:38:23.500 --> 01:38:25.500]   And then you need to know that you're using the same thing.
[01:38:25.500 --> 01:38:27.500]   And then you need to know that you're using the same thing.
[01:38:27.500 --> 01:38:29.500]   And then you need to know that you're using the same thing.
[01:38:29.500 --> 01:38:31.500]   And then you need to know that you're using the same thing.
[01:38:31.500 --> 01:38:34.500]   You're doing the best you can.
[01:38:34.500 --> 01:38:35.500]   Right.
[01:38:35.500 --> 01:38:36.500]   Which is why you have to be like, I was nice.
[01:38:36.500 --> 01:38:40.500]   I did all the steps and yeah, it was cute.
[01:38:40.500 --> 01:38:42.500]   She finally did ask me what kind of phone I was using.
[01:38:42.500 --> 01:38:44.500]   But it wasn't even a troubleshoot.
[01:38:44.500 --> 01:38:47.500]   It was so she could pick the diagram to tell me where like the buttons were.
[01:38:47.500 --> 01:38:50.500]   Customer support is only notable when it's good.
[01:38:50.500 --> 01:38:55.500]   Because you know, when you get something there and it really helps and it fixes it,
[01:38:55.500 --> 01:38:58.500]   then you go, wow, most of the time it's exactly where you go.
[01:38:58.500 --> 01:39:06.500]   So I've had customer support with Verizon of all places where I've had really challenging
[01:39:06.500 --> 01:39:11.500]   technical issues and by gum if that person did not stay on the phone with me and solved
[01:39:11.500 --> 01:39:12.500]   my problem.
[01:39:12.500 --> 01:39:13.500]   That's nice.
[01:39:13.500 --> 01:39:15.500]   I even had good support from Comcast.
[01:39:15.500 --> 01:39:21.500]   You know, I mean, even a broken clock's right twice a day.
[01:39:21.500 --> 01:39:26.500]   It's just, yeah.
[01:39:26.500 --> 01:39:30.500]   There's a new Google Play music update that allows again, machine learning.
[01:39:30.500 --> 01:39:32.500]   We're seeing Google apply machine learning across the board.
[01:39:32.500 --> 01:39:38.500]   It looks at your location and tries to suggest music that's appropriate to where you are,
[01:39:38.500 --> 01:39:40.500]   the time of day and what you're doing.
[01:39:40.500 --> 01:39:44.500]   It's always had time of day stuff, right?
[01:39:44.500 --> 01:39:46.500]   But should I be using Play music, you guys?
[01:39:46.500 --> 01:39:48.500]   Because I really love Spotify.
[01:39:48.500 --> 01:39:49.500]   No, stick with.
[01:39:49.500 --> 01:39:53.500]   With Google Home, I'm like, I could use it.
[01:39:53.500 --> 01:39:55.500]   Can you use Spotify with Google Home?
[01:39:55.500 --> 01:39:56.500]   Oh, yes, you can.
[01:39:56.500 --> 01:39:57.500]   Okay.
[01:39:57.500 --> 01:40:00.500]   As long as you can use Spotify.
[01:40:00.500 --> 01:40:01.620]   I have subscription.
[01:40:01.620 --> 01:40:06.260]   I actually let my Spotify lapse because I have a subscription to Google Play music and Amazon,
[01:40:06.260 --> 01:40:09.020]   that new Amazon unlimited music.
[01:40:09.020 --> 01:40:10.140]   And Google Play is fine with me.
[01:40:10.140 --> 01:40:13.660]   Here's the biggest difference between that and Spotify.
[01:40:13.660 --> 01:40:15.100]   Google Play music has a music uploader.
[01:40:15.100 --> 01:40:19.420]   I put on my computer and I have all the music I've ever bought or owned or digitized, you
[01:40:19.420 --> 01:40:24.180]   know, many, many gigabytes of songs are uploaded to Google Play music.
[01:40:24.180 --> 01:40:29.180]   So I have access to my full music library in addition to its own.
[01:40:29.180 --> 01:40:32.780]   And that's only useful if you have something that's weird, unusual.
[01:40:32.780 --> 01:40:36.540]   I have like up sampled Beatles songs, stuff like that.
[01:40:36.540 --> 01:40:39.940]   Actually, I don't even, can you get Beatles yet?
[01:40:39.940 --> 01:40:40.940]   I don't know.
[01:40:40.940 --> 01:40:41.940]   Yeah.
[01:40:41.940 --> 01:40:43.740]   You cannot Spotify and Amazon music.
[01:40:43.740 --> 01:40:47.740]   Yeah, you can't get Beatles on this.
[01:40:47.740 --> 01:40:48.740]   Sold out, man.
[01:40:48.740 --> 01:40:51.420]   Man, they sold out.
[01:40:51.420 --> 01:40:53.420]   So I like Google Play music.
[01:40:53.420 --> 01:40:56.580]   I think it has the world's ugliest interface.
[01:40:56.580 --> 01:40:58.300]   Look at this is the interface.
[01:40:58.300 --> 01:40:59.300]   Do you guys agree with me?
[01:40:59.300 --> 01:41:01.060]   I mean, Spotify looks so good.
[01:41:01.060 --> 01:41:03.700]   It's just as hideous.
[01:41:03.700 --> 01:41:07.140]   What kind of music do they play for here?
[01:41:07.140 --> 01:41:09.140]   Scroll up to it.
[01:41:09.140 --> 01:41:10.140]   No.
[01:41:10.140 --> 01:41:13.540]   I don't have local, here's getting things done.
[01:41:13.540 --> 01:41:15.580]   Music, getting things done.
[01:41:15.580 --> 01:41:16.580]   I'm a boss.
[01:41:16.580 --> 01:41:20.300]   Oh, I was hoping for work, work, work.
[01:41:20.300 --> 01:41:22.380]   The money featuring young thug.
[01:41:22.380 --> 01:41:23.900]   Oh, nice.
[01:41:23.900 --> 01:41:24.900]   Yeah.
[01:41:24.900 --> 01:41:27.180]   We got running on a track.
[01:41:27.180 --> 01:41:29.100]   I better stop this right now.
[01:41:29.100 --> 01:41:30.100]   What are these?
[01:41:30.100 --> 01:41:32.500]   I'm supposed to learn, sir.
[01:41:32.500 --> 01:41:36.260]   They think I like hip hop because I uploaded a ton of hip hop.
[01:41:36.260 --> 01:41:37.500]   But it belonged to my son.
[01:41:37.500 --> 01:41:40.700]   Epic film scores, you know, belong to my son.
[01:41:40.700 --> 01:41:42.460]   Epic film scores, that's good.
[01:41:42.460 --> 01:41:45.140]   Well, is that songs to run across the field too?
[01:41:45.140 --> 01:41:50.140]   So when you log in, if you have me, play me out right.
[01:41:50.140 --> 01:41:53.380]   The hills all alive.
[01:41:53.380 --> 01:41:57.020]   I just, I think Spotify, I have to say, I think Spotify's user interface looks a heck
[01:41:57.020 --> 01:41:58.700]   of a lot better.
[01:41:58.700 --> 01:42:00.580]   And I like, so the discovers.
[01:42:00.580 --> 01:42:02.100]   I love Discover Weekly.
[01:42:02.100 --> 01:42:03.100]   God bless it.
[01:42:03.100 --> 01:42:04.100]   It's awesome.
[01:42:04.100 --> 01:42:09.260]   Although my daughter, Holy cow, you guys, she discovered Pokemon and all she does is
[01:42:09.260 --> 01:42:10.260]   play.
[01:42:10.260 --> 01:42:13.020]   There are two things that happen in my house more than any other.
[01:42:13.020 --> 01:42:19.300]   It's the Pokemon theme song and an acapella mashup of daft-punks greatest hits by a group
[01:42:19.300 --> 01:42:20.300]   called Pentatonix.
[01:42:20.300 --> 01:42:22.820]   Oh, you got to love the Pentatonix.
[01:42:22.820 --> 01:42:26.100]   And I was like, oh, really?
[01:42:26.100 --> 01:42:29.820]   Well, it's totally messing with my Discover.
[01:42:29.820 --> 01:42:30.820]   Let me just tell you.
[01:42:30.820 --> 01:42:35.940]   Well, oh, and just so because she plays it through your account, do you get, um, as a
[01:42:35.940 --> 01:42:38.100]   result, do you get that in your Google?
[01:42:38.100 --> 01:42:40.740]   Yeah, I get some weird stuff.
[01:42:40.740 --> 01:42:41.740]   I get some weird stuff.
[01:42:41.740 --> 01:42:42.740]   Like this.
[01:42:42.740 --> 01:42:49.460]   Does that sound a little familiar?
[01:42:49.460 --> 01:42:56.940]   Are you hearing this a lot?
[01:42:56.940 --> 01:43:00.860]   You know what was really bad when Frozen was big?
[01:43:00.860 --> 01:43:01.860]   Did your daughter get a...
[01:43:01.860 --> 01:43:02.860]   I lived through that.
[01:43:02.860 --> 01:43:03.860]   Thank you.
[01:43:03.860 --> 01:43:04.860]   Yeah, I thought so.
[01:43:04.860 --> 01:43:10.780]   I actually, she dressed as Anna when you're for Christmas and I dressed as Elsa.
[01:43:10.780 --> 01:43:13.620]   And by golly, we looked amazing.
[01:43:13.620 --> 01:43:14.620]   Cute.
[01:43:14.620 --> 01:43:15.620]   Cute.
[01:43:15.620 --> 01:43:17.980]   Uh, I like Google Play music.
[01:43:17.980 --> 01:43:21.740]   I think they're, you know, they all have pretty much the same songs now.
[01:43:21.740 --> 01:43:25.660]   So it's really things like the curated playlists, the user interface.
[01:43:25.660 --> 01:43:27.580]   Spotify really looks best on all platforms.
[01:43:27.580 --> 01:43:28.740]   I really like Spotify.
[01:43:28.740 --> 01:43:31.380]   I kind of miss it.
[01:43:31.380 --> 01:43:35.780]   Um, you did have a story in here about Spotify writing crazy amounts of stuff.
[01:43:35.780 --> 01:43:37.980]   Yeah, we talked about this yesterday on security now.
[01:43:37.980 --> 01:43:45.100]   It was just a bug in Spotify in its implementation of the MySQL database or was it SQLite?
[01:43:45.100 --> 01:43:46.460]   I can't remember.
[01:43:46.460 --> 01:43:50.020]   But they were compressing the database constantly.
[01:43:50.020 --> 01:43:52.140]   You're only supposed to do that every once in a while.
[01:43:52.140 --> 01:43:55.620]   So as a result, it would write gigabytes.
[01:43:55.620 --> 01:43:57.820]   It wasn't filling up drives with gigabytes.
[01:43:57.820 --> 01:44:02.260]   It would write the same write and erase, write and erase, write and erase in effect because
[01:44:02.260 --> 01:44:05.700]   it was compressed in the database like every second.
[01:44:05.700 --> 01:44:06.700]   It's just a bug.
[01:44:06.700 --> 01:44:08.180]   They fixed it.
[01:44:08.180 --> 01:44:13.060]   But if you had an SSD, they may have worn out your SSD before they fixed it.
[01:44:13.060 --> 01:44:15.860]   It was pretty bad, pretty bad.
[01:44:15.860 --> 01:44:20.180]   So get the, if you don't have the latest Spotify, you should get it right now, especially if
[01:44:20.180 --> 01:44:24.500]   you're using a computer with SSD or I guess any phone is an SSD, right?
[01:44:24.500 --> 01:44:25.500]   Yeah.
[01:44:25.500 --> 01:44:26.500]   Yeah.
[01:44:26.500 --> 01:44:30.300]   Oh, so much just brought up a speaking spell in the chat.
[01:44:30.300 --> 01:44:33.180]   Oh, sorry.
[01:44:33.180 --> 01:44:36.060]   You come from speaking spell territory down there.
[01:44:36.060 --> 01:44:37.060]   I do.
[01:44:37.060 --> 01:44:38.060]   I had a speaking spell.
[01:44:38.060 --> 01:44:40.860]   My husband and I still yell out to each other when something happens.
[01:44:40.860 --> 01:44:44.060]   We're like, I win in that speaking spell voice.
[01:44:44.060 --> 01:44:45.860]   Wow.
[01:44:45.860 --> 01:44:47.780]   I know we're young apparently.
[01:44:47.780 --> 01:44:48.780]   Yeah.
[01:44:48.780 --> 01:44:52.540]   I was funny because I always shout Hoover wins.
[01:44:52.540 --> 01:44:56.380]   So the vacuum or the president?
[01:44:56.380 --> 01:44:58.660]   It was a bad joke.
[01:44:58.660 --> 01:45:00.020]   I should have said Truman wins.
[01:45:00.020 --> 01:45:01.580]   Then it would have been on.
[01:45:01.580 --> 01:45:02.580]   Yes.
[01:45:02.580 --> 01:45:03.580]   Do we wins?
[01:45:03.580 --> 01:45:08.340]   Oh, that's right.
[01:45:08.340 --> 01:45:10.100]   Project era, we never knew it.
[01:45:10.100 --> 01:45:15.300]   Now you can see photos of Google's canceled project era and its full spec sheet.
[01:45:15.300 --> 01:45:16.820]   I never thought this was going anywhere.
[01:45:16.820 --> 01:45:18.660]   This is the modular phone system.
[01:45:18.660 --> 01:45:22.220]   It's so whole, but yeah, Leo, you told me you were like, Stacy, this is not going to
[01:45:22.220 --> 01:45:23.220]   work.
[01:45:23.220 --> 01:45:24.220]   It's going to be janky.
[01:45:24.220 --> 01:45:25.220]   Yeah.
[01:45:25.220 --> 01:45:28.500]   And this was the motor roll.
[01:45:28.500 --> 01:45:33.740]   It was a Motorola project which Google capture they sold off on Motorola.
[01:45:33.740 --> 01:45:35.620]   So beautiful.
[01:45:35.620 --> 01:45:37.180]   So dead.
[01:45:37.180 --> 01:45:38.180]   Yeah.
[01:45:38.180 --> 01:45:40.100]   There's enough.
[01:45:40.100 --> 01:45:41.780]   There's too many phones out there as it is.
[01:45:41.780 --> 01:45:42.780]   We don't need more phones.
[01:45:42.780 --> 01:45:45.580]   Well, we've hit peak phone and peak phone for sure.
[01:45:45.580 --> 01:45:46.580]   New.
[01:45:46.580 --> 01:45:47.580]   Yeah, they can do.
[01:45:47.580 --> 01:45:48.580]   Yeah.
[01:45:48.580 --> 01:45:54.580]   Oh, my, my new canvas Google, what's my call it?
[01:45:54.580 --> 01:45:55.580]   Shift.
[01:45:55.580 --> 01:45:56.580]   Oh, your daydream.
[01:45:56.580 --> 01:45:57.580]   Daydream.
[01:45:57.580 --> 01:46:02.620]   The canvas, my friend, that's a space age material.
[01:46:02.620 --> 01:46:04.740]   Same material they make running shirts out of.
[01:46:04.740 --> 01:46:08.100]   I was going to say someone, someone did a review and it was like, like sweatpants on
[01:46:08.100 --> 01:46:09.100]   your face.
[01:46:09.100 --> 01:46:10.100]   Yeah.
[01:46:10.100 --> 01:46:15.060]   It's a, it's a space age material that wicks moisture away and as you can remove the inside
[01:46:15.060 --> 01:46:16.180]   thing and it's washable.
[01:46:16.180 --> 01:46:19.020]   I still don't really understand how this differs from cardboard.
[01:46:19.020 --> 01:46:23.500]   It's just a more expensive, better made, softer version of Google cardboard.
[01:46:23.500 --> 01:46:24.980]   Oh, that's right.
[01:46:24.980 --> 01:46:26.980]   Because we decided the hardware had nothing to support.
[01:46:26.980 --> 01:46:28.980]   Oh, no, we decided the hardware had nothing to support.
[01:46:28.980 --> 01:46:33.700]   Right now it's only pixels, but they say other phones will support it down the road.
[01:46:33.700 --> 01:46:35.700]   But you got one free, right, Jeff?
[01:46:35.700 --> 01:46:37.100]   Because you bought a pixel.
[01:46:37.100 --> 01:46:38.100]   Yeah.
[01:46:38.100 --> 01:46:40.420]   I bought a pixel, but nobody ever mentioned a free daydream.
[01:46:40.420 --> 01:46:43.780]   Oh, you should, you should be getting the code.
[01:46:43.780 --> 01:46:44.780]   Yeah.
[01:46:44.780 --> 01:46:45.780]   And your email.
[01:46:45.780 --> 01:46:47.780]   Oh, that's what you got.
[01:46:47.780 --> 01:46:48.940]   Oh, yeah.
[01:46:48.940 --> 01:46:51.580]   Oh, what should I search for?
[01:46:51.580 --> 01:46:53.580]   Google support bot?
[01:46:53.580 --> 01:47:02.580]   Did you search for daydream?
[01:47:02.580 --> 01:47:03.580]   Daydream.
[01:47:03.580 --> 01:47:04.780]   There you go.
[01:47:04.780 --> 01:47:05.780]   You'd be surprised.
[01:47:05.780 --> 01:47:06.780]   Oh, yeah.
[01:47:06.780 --> 01:47:09.980]   Your daydream view promo code is coming soon.
[01:47:09.980 --> 01:47:11.580]   Oh, good.
[01:47:11.580 --> 01:47:15.580]   Oh, this came today, an hour ago.
[01:47:15.580 --> 01:47:16.580]   Hi there.
[01:47:16.580 --> 01:47:17.880]   Hi there.
[01:47:17.880 --> 01:47:19.260]   Thanks for your recent pixel purchase.
[01:47:19.260 --> 01:47:24.620]   Be on the lookout for your daydream view promo code will be emailed to you within four weeks
[01:47:24.620 --> 01:47:26.860]   of your pixel shipment date.
[01:47:26.860 --> 01:47:30.460]   Well, that's past, hasn't it?
[01:47:30.460 --> 01:47:32.820]   Well, this came today.
[01:47:32.820 --> 01:47:33.820]   That's weird, really?
[01:47:33.820 --> 01:47:34.820]   I ordered it.
[01:47:34.820 --> 01:47:36.860]   I ordered the pixel October 4th.
[01:47:36.860 --> 01:47:37.860]   Yeah.
[01:47:37.860 --> 01:47:38.860]   So this is no.
[01:47:38.860 --> 01:47:39.860]   Yeah, it's too late.
[01:47:39.860 --> 01:47:42.260]   Here's your daydream view promo code.
[01:47:42.260 --> 01:47:43.260]   Yeah.
[01:47:43.260 --> 01:47:44.260]   That's what it said.
[01:47:44.260 --> 01:47:45.260]   Mine's coming soon.
[01:47:45.260 --> 01:47:47.420]   I don't really care.
[01:47:47.420 --> 01:47:50.260]   But good, you can review it before I do.
[01:47:50.260 --> 01:47:51.260]   Let's see.
[01:47:51.260 --> 01:47:54.780]   Real quick, I just want to make sure we get all the really interesting stories in here
[01:47:54.780 --> 01:47:55.780]   that we've missed.
[01:47:55.780 --> 01:47:57.900]   Just for future reference, I won't talk about it now.
[01:47:57.900 --> 01:48:00.700]   There's the intercept, which is to say, glad we're in this operation.
[01:48:00.700 --> 01:48:01.700]   Just kidding.
[01:48:01.700 --> 01:48:03.100]   I was reading this right now.
[01:48:03.100 --> 01:48:05.180]   NSA fortress.
[01:48:05.180 --> 01:48:09.300]   There's this building in lower Manhattan that it is nothing but solid concrete.
[01:48:09.300 --> 01:48:10.300]   It's a high rise.
[01:48:10.300 --> 01:48:11.300]   Bottom to bottom.
[01:48:11.300 --> 01:48:14.140]   All telephone switching buildings look like this is a high rise one.
[01:48:14.140 --> 01:48:15.140]   This is pure.
[01:48:15.140 --> 01:48:16.140]   It's really weird.
[01:48:16.140 --> 01:48:17.140]   It's not a level.
[01:48:17.140 --> 01:48:18.140]   It's new.
[01:48:18.140 --> 01:48:19.140]   And no, no, no.
[01:48:19.140 --> 01:48:20.140]   It's an old building.
[01:48:20.140 --> 01:48:21.860]   It's on my screen right now.
[01:48:21.860 --> 01:48:22.860]   Just if you want to see it.
[01:48:22.860 --> 01:48:24.060]   Please, thank you.
[01:48:24.060 --> 01:48:25.060]   Yeah.
[01:48:25.060 --> 01:48:26.060]   So it's quite amazing.
[01:48:26.060 --> 01:48:27.700]   You're not getting my screen.
[01:48:27.700 --> 01:48:29.660]   Are you getting my screen?
[01:48:29.660 --> 01:48:30.660]   Is that a problem?
[01:48:30.660 --> 01:48:31.660]   I'm seeing it.
[01:48:31.660 --> 01:48:32.660]   I'm seeing it.
[01:48:32.660 --> 01:48:33.660]   No, no, that's not my screen.
[01:48:33.660 --> 01:48:34.660]   That's what he's getting from my screen.
[01:48:34.660 --> 01:48:35.660]   Oh, okay.
[01:48:35.660 --> 01:48:39.220]   But it's the NSA had secret rooms there to do stuff.
[01:48:39.220 --> 01:48:40.220]   So it's just a good story.
[01:48:40.220 --> 01:48:45.740]   The other good story to another day as I put up on the rundown is a Toronto's.
[01:48:45.740 --> 01:48:52.500]   Oerados, Oerados, Oerados, Oerados, Oerados, Whistleblower, Schultz's grandson.
[01:48:52.500 --> 01:48:54.260]   And it's pretty harrowing.
[01:48:54.260 --> 01:48:57.380]   God, I'm so disappointed by that story.
[01:48:57.380 --> 01:48:58.900]   Oh, same here.
[01:48:58.900 --> 01:49:00.540]   Wait, is sorry.
[01:49:00.540 --> 01:49:03.740]   I have to ask, is this 60 Hudson that we're talking about?
[01:49:03.740 --> 01:49:06.700]   No, 33, something else, Taylor or something.
[01:49:06.700 --> 01:49:07.700]   Oh, okay.
[01:49:07.700 --> 01:49:09.900]   It was designed by an architectural firm.
[01:49:09.900 --> 01:49:10.900]   Yeah.
[01:49:10.900 --> 01:49:14.620]   His grand vision was to create a communication nurse center like a 20th century fortress
[01:49:14.620 --> 01:49:19.980]   with spears and arrows replaced by protons and neutrons laying quiet siege to an army
[01:49:19.980 --> 01:49:20.980]   of machines within.
[01:49:20.980 --> 01:49:22.980]   Oh my God.
[01:49:22.980 --> 01:49:23.980]   They built it in.
[01:49:23.980 --> 01:49:24.980]   It is the also that are brutalist.
[01:49:24.980 --> 01:49:26.980]   33 Thomas Street.
[01:49:26.980 --> 01:49:27.980]   Oh, okay.
[01:49:27.980 --> 01:49:30.220]   Built and created started in 69.
[01:49:30.220 --> 01:49:33.660]   It was finished by 74.
[01:49:33.660 --> 01:49:36.780]   The brutalist structure still used by AT&T.
[01:49:36.780 --> 01:49:38.580]   Built to withstand a nuclear attack.
[01:49:38.580 --> 01:49:40.140]   Oh, well, that's good.
[01:49:40.140 --> 01:49:41.140]   Okay.
[01:49:41.140 --> 01:49:44.540]   So all telco towers are built like like any sort of data center.
[01:49:44.540 --> 01:49:45.540]   There is a wall in Amsterdam.
[01:49:45.540 --> 01:49:46.540]   There is a wall in Amsterdam.
[01:49:46.540 --> 01:49:47.540]   There is a wall in Amsterdam.
[01:49:47.540 --> 01:49:48.540]   What's the New York?
[01:49:48.540 --> 01:49:52.980]   No, there's one in Amsterdam that is like, I don't know how many square feet it is.
[01:49:52.980 --> 01:49:56.180]   It's not as high, but it is literally surrounded by a moat.
[01:49:56.180 --> 01:49:57.180]   Okay.
[01:49:57.180 --> 01:49:58.820]   There may be sharks in the moat.
[01:49:58.820 --> 01:50:07.100]   So documents from the Edward Snowden trove obtained by the intercept do not specifically
[01:50:07.100 --> 01:50:10.380]   name 33 Thomas as a surveillance facility.
[01:50:10.380 --> 01:50:14.100]   However, taken together with architectural plans, public records and interviews with
[01:50:14.100 --> 01:50:17.900]   former AT&T employees conducted for this article rights the intercept.
[01:50:17.900 --> 01:50:19.100]   They provide compelling evidence.
[01:50:19.100 --> 01:50:26.580]   The 33 Thomas Street has served as an NSA surveillance site code named Titan point inside
[01:50:26.580 --> 01:50:31.180]   a major international gateway switch that routes phone calls between the US and countries
[01:50:31.180 --> 01:50:33.380]   across the world.
[01:50:33.380 --> 01:50:37.340]   A series of top secret memos suggest the agency has tapped into these calls from a secure
[01:50:37.340 --> 01:50:40.340]   facility within the building.
[01:50:40.340 --> 01:50:45.540]   It's the core location for the controversial NSA surveillance program that has targeted
[01:50:45.540 --> 01:50:51.380]   the communications of the UN, the International Monetary Fund, the World Bank and at least
[01:50:51.380 --> 01:50:55.140]   38 countries, including allies like Germany, Japan and France.
[01:50:55.140 --> 01:50:59.140]   There's not so much of a story here.
[01:50:59.140 --> 01:51:01.140]   If it weren't a really scary looking building.
[01:51:01.140 --> 01:51:03.140]   That's really just kind of it.
[01:51:03.140 --> 01:51:04.140]   Thank you, Leo.
[01:51:04.140 --> 01:51:05.140]   Thank you.
[01:51:05.140 --> 01:51:08.140]   The reason it's a scary looking building is because that's all data centers.
[01:51:08.140 --> 01:51:10.100]   All data centers are scary looking.
[01:51:10.100 --> 01:51:11.860]   We have one in town.
[01:51:11.860 --> 01:51:14.940]   I shouldn't say this, but I've been brought inside one.
[01:51:14.940 --> 01:51:16.500]   Oh, I've been inside so many days.
[01:51:16.500 --> 01:51:18.620]   You're not supposed to be in there.
[01:51:18.620 --> 01:51:20.500]   Do you have a friend in the biz?
[01:51:20.500 --> 01:51:21.500]   No, they.
[01:51:21.500 --> 01:51:27.540]   No, no, no, no, no, no, no, no, no, no, no, no, regular data centers, AT&T data centers.
[01:51:27.540 --> 01:51:29.340]   I have been inside to AT&T to this.
[01:51:29.340 --> 01:51:31.540]   They're supposed to be secure.
[01:51:31.540 --> 01:51:32.820]   I was in the national.
[01:51:32.820 --> 01:51:34.620]   I'm a very secure person.
[01:51:34.620 --> 01:51:36.220]   Hey, I got in.
[01:51:36.220 --> 01:51:42.060]   So, you know, well, the one that won in Bedminster is a knock that they take people as the national
[01:51:42.060 --> 01:51:43.060]   knock they take people into.
[01:51:43.060 --> 01:51:44.300]   Oh, they'll show it up.
[01:51:44.300 --> 01:51:47.660]   They're knocks because they're in the room with all of the screen and linking lights
[01:51:47.660 --> 01:51:48.660]   and all that.
[01:51:48.660 --> 01:51:49.660]   Yeah.
[01:51:49.660 --> 01:51:52.900]   Like, look, this is your internet on the screen and you're like, yeah.
[01:51:52.900 --> 01:51:54.340]   Has anybody ever you have?
[01:51:54.340 --> 01:51:56.900]   Did you go to Big Sur to get the.
[01:51:56.900 --> 01:51:57.900]   Snapticles.
[01:51:57.900 --> 01:52:01.060]   No, but there is it really in Tulsa?
[01:52:01.060 --> 01:52:02.060]   Is that really happening?
[01:52:02.060 --> 01:52:03.060]   The next one?
[01:52:03.060 --> 01:52:04.060]   And that's like eight hours away.
[01:52:04.060 --> 01:52:05.060]   Go, baby.
[01:52:05.060 --> 01:52:06.060]   Go.
[01:52:06.060 --> 01:52:07.060]   No.
[01:52:07.060 --> 01:52:08.060]   I think it's there now.
[01:52:08.060 --> 01:52:09.060]   Big Sur.
[01:52:09.060 --> 01:52:10.060]   Well, it's too late.
[01:52:10.060 --> 01:52:14.500]   Why the time you hear about it, the line's too long and you're not going to get one.
[01:52:14.500 --> 01:52:17.740]   I feel like in Tulsa, maybe you had a chance.
[01:52:17.740 --> 01:52:25.340]   The one in Big Sur, you had a hike through a park to get there and there was a huge line.
[01:52:25.340 --> 01:52:27.820]   So remember we thought that they were there.
[01:52:27.820 --> 01:52:28.820]   There it is.
[01:52:28.820 --> 01:52:29.980]   A special vending machine.
[01:52:29.980 --> 01:52:34.420]   We thought, wouldn't it be funny if you just walk down the street and you saw that and
[01:52:34.420 --> 01:52:35.420]   you got what?
[01:52:35.420 --> 01:52:39.140]   And you've got there only 130 bucks, but we thought they were going to offer them only
[01:52:39.140 --> 01:52:43.820]   to influencers on Snapchat, but apparently like they're creating incredible demand by
[01:52:43.820 --> 01:52:46.580]   this kind of selling for like a thousand bucks.
[01:52:46.580 --> 01:52:50.820]   I think Joanna Stern was showing her emails where she was trying to get a copy or get
[01:52:50.820 --> 01:52:51.820]   a.
[01:52:51.820 --> 01:52:57.140]   I think the Wall Street Journal should spring for $1,000 for those.
[01:52:57.140 --> 01:52:58.140]   Really?
[01:52:58.140 --> 01:52:59.140]   Yeah.
[01:52:59.140 --> 01:53:00.140]   Okay.
[01:53:00.140 --> 01:53:07.340]   Snapchat doesn't need the money they have according to Reuters secretly filed for their
[01:53:07.340 --> 01:53:08.340]   IPO for.
[01:53:08.340 --> 01:53:14.780]   That means maybe they do need the money because they don't want to go public with their finances.
[01:53:14.780 --> 01:53:19.540]   So I think the secret filing is allowed now under Jobs Act or something, right?
[01:53:19.540 --> 01:53:21.340]   It's something new.
[01:53:21.340 --> 01:53:25.140]   It is and you have to go filing if you have more than, or you have to go public if you
[01:53:25.140 --> 01:53:26.700]   have more than a certain number of shareholders.
[01:53:26.700 --> 01:53:28.460]   I don't know if they fit that.
[01:53:28.460 --> 01:53:29.460]   Apparently not.
[01:53:29.460 --> 01:53:30.460]   Yeah.
[01:53:30.460 --> 01:53:31.460]   Okay.
[01:53:31.460 --> 01:53:32.460]   So they were just like, what up?
[01:53:32.460 --> 01:53:34.460]   We don't want to share.
[01:53:34.460 --> 01:53:43.220]   The guess is that the IPO will be as soon as March for 20 to 25 billion dollars would
[01:53:43.220 --> 01:53:48.780]   be the largest US technology IPO since Facebook in 2012 with 81 billion.
[01:53:48.780 --> 01:53:50.300]   Would you buy Snapchat stock?
[01:53:50.300 --> 01:53:51.780]   It's called now called Snap.
[01:53:51.780 --> 01:53:53.620]   Would you buy Snap stock?
[01:53:53.620 --> 01:53:54.620]   Me?
[01:53:54.620 --> 01:53:55.620]   No.
[01:53:55.620 --> 01:53:56.620]   No.
[01:53:56.620 --> 01:53:57.620]   Well, I don't buy.
[01:53:57.620 --> 01:53:58.620]   So I don't want to talk.
[01:53:58.620 --> 01:53:59.620]   No, no, neither.
[01:53:59.620 --> 01:54:01.860]   None of us do or maybe Jeff does, but I don't.
[01:54:01.860 --> 01:54:02.860]   You don't.
[01:54:02.860 --> 01:54:03.860]   We recuse ourselves.
[01:54:03.860 --> 01:54:07.620]   But if you did, would you?
[01:54:07.620 --> 01:54:13.100]   Like I said, buy Facebook stock at the time, which was correct advice, not that you should
[01:54:13.100 --> 01:54:14.100]   ever listen to me.
[01:54:14.100 --> 01:54:16.100]   It was a stock advice.
[01:54:16.100 --> 01:54:21.580]   My position there was you're investing in Mark Zuckerberg and that that company, even
[01:54:21.580 --> 01:54:22.580]   though there's challenges.
[01:54:22.580 --> 01:54:25.340]   I don't want to invest in Evan Spiegel.
[01:54:25.340 --> 01:54:26.940]   Well, yes, exactly.
[01:54:26.940 --> 01:54:27.940]   Exactly.
[01:54:27.940 --> 01:54:28.940]   Right?
[01:54:28.940 --> 01:54:31.220]   If I go by that, if I go, no.
[01:54:31.220 --> 01:54:34.180]   It's going to be hot though because people think it's the next Facebook.
[01:54:34.180 --> 01:54:39.060]   Everybody wants to get the next Facebook.
[01:54:39.060 --> 01:54:42.420]   The company is raised huge amounts of venture capital.
[01:54:42.420 --> 01:54:47.780]   It's not like they need the money at this point, but still, why not cash in white tea?
[01:54:47.780 --> 01:54:48.780]   But it's for employees.
[01:54:48.780 --> 01:54:49.780]   Yeah.
[01:54:49.780 --> 01:54:50.780]   Yeah.
[01:54:50.780 --> 01:54:54.740]   Money for employees plus, you know, if you're going to actually make these freaking spectacles,
[01:54:54.740 --> 01:54:57.900]   that's not a cheap endeavor.
[01:54:57.900 --> 01:55:07.180]   No, floating that floating that vending machine to Big Sur and Tulsa takes cash and helium
[01:55:07.180 --> 01:55:08.180]   is in short supply.
[01:55:08.180 --> 01:55:09.820]   Do you think it comes in on balloons?
[01:55:09.820 --> 01:55:12.940]   They do have balloons attached, but I don't think they got a truck.
[01:55:12.940 --> 01:55:13.940]   I think they probably have a truck.
[01:55:13.940 --> 01:55:16.620]   I'm thinking they use a more efficient means of transportation.
[01:55:16.620 --> 01:55:18.460]   Trucking a crane.
[01:55:18.460 --> 01:55:19.460]   I think we're done.
[01:55:19.460 --> 01:55:22.580]   I think we're going to take a break and come back with your picks of the week tips.
[01:55:22.580 --> 01:55:24.180]   Oh, I'm so excited about buying.
[01:55:24.180 --> 01:55:25.420]   I know you got one.
[01:55:25.420 --> 01:55:27.860]   I know you got one.
[01:55:27.860 --> 01:55:31.900]   But first a word from FreshBooks.
[01:55:31.900 --> 01:55:35.980]   If you're a small business, a small business owner, if you're a sole proprietor or a freelancer,
[01:55:35.980 --> 01:55:40.300]   you know the worst thing is the end of the month when you got a, well, there's paying
[01:55:40.300 --> 01:55:41.620]   bills, but then there's sending bills.
[01:55:41.620 --> 01:55:43.620]   If you don't send bills, you're not going to be paying bills because you're not going
[01:55:43.620 --> 01:55:44.620]   to be getting paid.
[01:55:44.620 --> 01:55:45.980]   So you got to do the invoices.
[01:55:45.980 --> 01:55:48.620]   I always hated that part.
[01:55:48.620 --> 01:55:50.140]   Never good at it.
[01:55:50.140 --> 01:55:54.300]   And I found out about FreshBooks in 2004 and I've been using it ever since and loved it.
[01:55:54.300 --> 01:55:56.220]   Actually, I don't, I now have a team of people.
[01:55:56.220 --> 01:55:59.020]   But for years, that was how I invoiced people.
[01:55:59.020 --> 01:56:00.740]   I had how I did my expenses.
[01:56:00.740 --> 01:56:06.180]   And the new FreshBooks, by the way, all new, completely redesigned, looks gorgeous.
[01:56:06.180 --> 01:56:07.980]   And it's not just about sending invoices.
[01:56:07.980 --> 01:56:09.780]   It's about knowing where you stand.
[01:56:09.780 --> 01:56:13.620]   So many freelancers, if you said, have you made a profit this year, would not know the
[01:56:13.620 --> 01:56:14.620]   answer.
[01:56:14.620 --> 01:56:16.500]   They didn't, well, I, you know, I, I'm working.
[01:56:16.500 --> 01:56:17.940]   I'm paying my bills.
[01:56:17.940 --> 01:56:19.940]   How much did you make?
[01:56:19.940 --> 01:56:23.220]   Well, if they use FreshBooks, they go to their FreshBooks page and they say immediately
[01:56:23.220 --> 01:56:24.820]   how much they made.
[01:56:24.820 --> 01:56:27.140]   You know, because it's not just invoices.
[01:56:27.140 --> 01:56:31.180]   It's when you get paid, how much you got paid, what your expenses were.
[01:56:31.180 --> 01:56:32.820]   It's also really great at tax time.
[01:56:32.820 --> 01:56:35.660]   Makes it very easy because you can print all the reports that the, you know, the accounts
[01:56:35.660 --> 01:56:37.020]   said, well, I need a P and L sheet.
[01:56:37.020 --> 01:56:40.020]   I don't know what that is, but here's the button.
[01:56:40.020 --> 01:56:44.340]   You don't need to be an accountant to do the right thing to keep track of how you're
[01:56:44.340 --> 01:56:46.340]   doing to send those invoices.
[01:56:46.340 --> 01:56:51.660]   By the way, the tool to make and send invoices is so easy and they look great and there's
[01:56:51.660 --> 01:56:57.740]   no formatting nor formulas, you can add your logo and your custom color scheme.
[01:56:57.740 --> 01:57:02.180]   And when you send out an invoice, FreshBooks knows if your client has seen it.
[01:57:02.180 --> 01:57:05.180]   And so they can't dodge you by saying, oh, I didn't get your invoice yet.
[01:57:05.180 --> 01:57:06.180]   Yes, you did.
[01:57:06.180 --> 01:57:08.180]   You opened it last night, 6 p.m.
[01:57:08.180 --> 01:57:13.060]   Dude, actually you don't have to do that because they also will send out late pay reminders
[01:57:13.060 --> 01:57:14.060]   and stuff.
[01:57:14.060 --> 01:57:15.060]   They do a lot of the work for you.
[01:57:15.060 --> 01:57:19.660]   Frankly, your clients are going to love it because they can pay using a variety of online
[01:57:19.660 --> 01:57:22.620]   payment systems, including credit cards right from the invoice.
[01:57:22.620 --> 01:57:26.700]   So it makes it easy for them to brand new.
[01:57:26.700 --> 01:57:30.860]   If you haven't looked at FreshBooks lately, go right now to freshbooks.com/twig.
[01:57:30.860 --> 01:57:36.060]   It is fantastic, fantastic.
[01:57:36.060 --> 01:57:42.380]   And it's so nice to have that information you need to do business without becoming a
[01:57:42.380 --> 01:57:43.380]   paper pusher.
[01:57:43.380 --> 01:57:47.620]   You know, you didn't get into business because you want to be an accountant, but you do need
[01:57:47.620 --> 01:57:50.980]   to do a little bit then this makes it easy.
[01:57:50.980 --> 01:57:51.980]   How's my business doing?
[01:57:51.980 --> 01:57:53.780]   No at a glance.
[01:57:53.780 --> 01:57:57.100]   The notification center works like a personal assistant letting you know what's changed
[01:57:57.100 --> 01:58:01.420]   in your business the last time you logged in and what should be dealt with like overdue
[01:58:01.420 --> 01:58:03.420]   invoices.
[01:58:03.420 --> 01:58:06.740]   You can even take pictures receipts on your phone using the FreshBooks app.
[01:58:06.740 --> 01:58:10.060]   Does it tell you to stop taking Uber's because it's costing you a lot of money?
[01:58:10.060 --> 01:58:12.340]   Yeah, actually, well, you'd see what Uber expenditures were.
[01:58:12.340 --> 01:58:13.980]   You bet.
[01:58:13.980 --> 01:58:18.780]   And you can, it makes it easy to bill them out to the client too.
[01:58:18.780 --> 01:58:21.740]   And if you do time and hours, it'll track your time as well.
[01:58:21.740 --> 01:58:26.540]   FreshBooks.com/twig for a 30 day unrestricted free trial right now, but you got to do me
[01:58:26.540 --> 01:58:27.540]   a favor.
[01:58:27.540 --> 01:58:30.420]   And when they ask you on the form, how did you hear about us?
[01:58:30.420 --> 01:58:41.060]   Make sure you say this week in Google freshbooks.com/twig a 30 day free trial awaits.
[01:58:41.060 --> 01:58:42.060]   Oh, you were so excited.
[01:58:42.060 --> 01:58:44.060]   I'm going to let you go right ahead, Stacy.
[01:58:44.060 --> 01:58:45.060]   You can buy them.
[01:58:45.060 --> 01:58:46.900]   What do you got for us?
[01:58:46.900 --> 01:58:50.300]   I have the June oven, which I believe I.
[01:58:50.300 --> 01:58:52.260]   Oh, man, you got it.
[01:58:52.260 --> 01:58:53.260]   Yeah.
[01:58:53.260 --> 01:58:54.260]   Okay.
[01:58:54.260 --> 01:58:55.260]   Yes.
[01:58:55.260 --> 01:58:56.260]   So I got it a review unit.
[01:58:56.260 --> 01:58:57.260]   So I have to say that.
[01:58:57.260 --> 01:59:00.060]   People are laughing at me because I bought it after you talked about it.
[01:59:00.060 --> 01:59:02.700]   Well, it's I okay.
[01:59:02.700 --> 01:59:05.020]   I played with this thing for a week and a half.
[01:59:05.020 --> 01:59:07.740]   I cooked over a dozen meals.
[01:59:07.740 --> 01:59:14.700]   It was the best thing to happen to my cooking since I don't know.
[01:59:14.700 --> 01:59:15.700]   Everything worked so well.
[01:59:15.700 --> 01:59:16.700]   And I did a video.
[01:59:16.700 --> 01:59:20.300]   You should show people the video so they can see it in action because you really have
[01:59:20.300 --> 01:59:22.260]   to see this to appreciate it.
[01:59:22.260 --> 01:59:23.460]   Press the button.
[01:59:23.460 --> 01:59:26.020]   So it's a toaster oven.
[01:59:26.020 --> 01:59:27.620]   It's not as it's a toaster.
[01:59:27.620 --> 01:59:30.860]   So it has toasting, roasting, baking.
[01:59:30.860 --> 01:59:32.460]   It's a countertop oven.
[01:59:32.460 --> 01:59:35.180]   So it will also double as a toaster oven.
[01:59:35.180 --> 01:59:36.180]   And so.
[01:59:36.180 --> 01:59:37.660]   People do all of that too.
[01:59:37.660 --> 01:59:38.660]   Oh, well, that's true.
[01:59:38.660 --> 01:59:39.660]   Okay.
[01:59:39.660 --> 01:59:41.580]   So but it's bigger than the average toaster oven.
[01:59:41.580 --> 01:59:43.780]   So you could fit up to a five pound chicken in it.
[01:59:43.780 --> 01:59:44.780]   Okay.
[01:59:44.780 --> 01:59:45.940]   I like the countertop oven.
[01:59:45.940 --> 01:59:46.940]   I like the way of.
[01:59:46.940 --> 01:59:47.940]   Yeah.
[01:59:47.940 --> 01:59:52.340]   So that was it saying, Oh my God, those are waffles and I toasted it.
[01:59:52.340 --> 01:59:54.820]   They know they see it and they recognize it.
[01:59:54.820 --> 01:59:56.380]   Did you not see that in the video?
[01:59:56.380 --> 01:59:57.940]   It has a camera.
[01:59:57.940 --> 02:00:02.020]   It has a camera with artificial intelligence, so computer vision.
[02:00:02.020 --> 02:00:06.740]   So it's pre-programmed recipes for things like when I put salmon fillets in there.
[02:00:06.740 --> 02:00:08.780]   It's a Tesla of ovens.
[02:00:08.780 --> 02:00:09.780]   It is.
[02:00:09.780 --> 02:00:11.900]   It was like, is this salmon or strudel?
[02:00:11.900 --> 02:00:18.140]   And then it cooked my salmon at 283 degrees because I said I wanted it medium.
[02:00:18.140 --> 02:00:19.140]   It knew.
[02:00:19.140 --> 02:00:20.140]   It knew.
[02:00:20.140 --> 02:00:21.140]   It knew.
[02:00:21.140 --> 02:00:22.140]   It had the recipe in there.
[02:00:22.140 --> 02:00:30.700]   The cool thing is, is like if it knows what something is, it's like, boom, I got this.
[02:00:30.700 --> 02:00:36.020]   And if it doesn't, you basically, so I put in a pork roast and it had a bunch of vegetables
[02:00:36.020 --> 02:00:37.020]   around it.
[02:00:37.020 --> 02:00:38.020]   So it was like, I don't know what this is.
[02:00:38.020 --> 02:00:40.300]   So I was like, Oh, there's presets.
[02:00:40.300 --> 02:00:42.340]   I went into the pork preset.
[02:00:42.340 --> 02:00:43.340]   I clicked it.
[02:00:43.340 --> 02:00:47.140]   And it was like, what internal temperature do you want this cooked to?
[02:00:47.140 --> 02:00:51.380]   What I did is I took the accompanying temperature probe, I jammed it in there.
[02:00:51.380 --> 02:00:53.860]   There are weights in the feet of the oven.
[02:00:53.860 --> 02:00:56.780]   So it knows exactly how much meat there is.
[02:00:56.780 --> 02:00:57.780]   Wait a minute.
[02:00:57.780 --> 02:00:58.780]   It's a scale?
[02:00:58.780 --> 02:01:00.380]   It's a scale.
[02:01:00.380 --> 02:01:05.380]   So using all that information plus the temperature of the oven, it was like, all right.
[02:01:05.380 --> 02:01:09.740]   And then, you know, we're estimating that it's going to take like 45 minutes to cook
[02:01:09.740 --> 02:01:10.740]   this.
[02:01:10.740 --> 02:01:11.740]   And I'm like, cool.
[02:01:11.740 --> 02:01:14.220]   But then the internal temperature that meat was rising faster probably because there were
[02:01:14.220 --> 02:01:15.220]   vegetables in there too.
[02:01:15.220 --> 02:01:16.980]   So it knew that though.
[02:01:16.980 --> 02:01:19.820]   And it was like, Oh, look, it already reached 150.
[02:01:19.820 --> 02:01:20.820]   You're good to go.
[02:01:20.820 --> 02:01:23.180]   And that was delicious.
[02:01:23.180 --> 02:01:25.380]   The downside is it's $1,500.
[02:01:25.380 --> 02:01:27.060]   A lot of money.
[02:01:27.060 --> 02:01:30.580]   I will tell you that my normal ovens are $1,500 each.
[02:01:30.580 --> 02:01:32.380]   I've got two of them.
[02:01:32.380 --> 02:01:36.020]   Had I known that this was coming out, I would have only gotten one and would have used this
[02:01:36.020 --> 02:01:41.580]   as my secondary oven for Thanksgiving and all the other times I use it yet.
[02:01:41.580 --> 02:01:43.220]   And it's going to get updated over time.
[02:01:43.220 --> 02:01:46.740]   So right now, like their cookie recipe was a little not great.
[02:01:46.740 --> 02:01:51.380]   And it's because they were like, we set it for refrigerator store bought cookies.
[02:01:51.380 --> 02:01:53.860]   So it was higher when they started, like the temperature.
[02:01:53.860 --> 02:01:59.100]   So it knows because they're in the refrigerator that needs to start warmer and heat them up
[02:01:59.100 --> 02:02:00.740]   faster.
[02:02:00.740 --> 02:02:03.540]   So now it's going to ask you, they did a tweak.
[02:02:03.540 --> 02:02:05.780]   So it'll say, Hey, are these homemade or store bought?
[02:02:05.780 --> 02:02:08.740]   And if you say homemade, it's going to change it.
[02:02:08.740 --> 02:02:11.180]   Oh, so there you guys go.
[02:02:11.180 --> 02:02:15.020]   It was so good and it's so expensive.
[02:02:15.020 --> 02:02:17.420]   It's not a hit by one.
[02:02:17.420 --> 02:02:18.420]   But I want one.
[02:02:18.420 --> 02:02:22.820]   My husband was, this is one of the only gadgets that my husband is like, Holy cow, this is
[02:02:22.820 --> 02:02:24.300]   a little hungry.
[02:02:24.300 --> 02:02:25.780]   How long did you have it?
[02:02:25.780 --> 02:02:27.860]   I had it for a week and a half.
[02:02:27.860 --> 02:02:30.180]   Too bad you couldn't keep it through Thanksgiving.
[02:02:30.180 --> 02:02:31.980]   I know.
[02:02:31.980 --> 02:02:39.460]   So I just looked in my email and I got yesterday, I got an email from June saying, we're in
[02:02:39.460 --> 02:02:42.740]   mass production, which means you'll have your June oven on your countertop very soon.
[02:02:42.740 --> 02:02:47.220]   Over the next few weeks, June ovens will start to make their way to their distribution center
[02:02:47.220 --> 02:02:49.980]   in California and then they'll ship to the first pre-order customers.
[02:02:49.980 --> 02:02:51.340]   That's you.
[02:02:51.340 --> 02:02:52.780]   So I don't know when I'll get mine.
[02:02:52.780 --> 02:02:56.300]   I probably not in time for Thanksgiving, but I know probably December, I think, is what
[02:02:56.300 --> 02:02:58.140]   they're telling people.
[02:02:58.140 --> 02:03:02.460]   I'm telling you, Lisa thought I was insane when I told her how much she is going to love
[02:03:02.460 --> 02:03:03.460]   it.
[02:03:03.460 --> 02:03:04.460]   Okay.
[02:03:04.460 --> 02:03:07.860]   Well, we use our toaster oven all the time for everything because it's easier to use
[02:03:07.860 --> 02:03:09.780]   than a big oven.
[02:03:09.780 --> 02:03:14.580]   So even for like things like making chicken or French fries and stuff like that.
[02:03:14.580 --> 02:03:18.580]   And imagine like blue apron teaming up with them and creating recipes where you literally
[02:03:18.580 --> 02:03:21.020]   just like, I mean, I made dinner.
[02:03:21.020 --> 02:03:26.100]   Like during my lunch break, basically, I made various roasts and stuck it in the fridge.
[02:03:26.100 --> 02:03:30.940]   And then I just gave it to my husband and he can cook and follow instructions, but it
[02:03:30.940 --> 02:03:32.700]   was even better for him.
[02:03:32.700 --> 02:03:34.620]   He can follow instructions now.
[02:03:34.620 --> 02:03:41.220]   Like when I smash on that chicken, that was, I was just, did that come out well last
[02:03:41.220 --> 02:03:42.220]   time?
[02:03:42.220 --> 02:03:43.220]   Yeah.
[02:03:43.220 --> 02:03:45.340]   So I didn't have anything to do with it because I was doing the show.
[02:03:45.340 --> 02:03:50.700]   He put the chicken in, he jammed that thermometer in there and he was like, it said roast chicken?
[02:03:50.700 --> 02:03:55.020]   Do you want it extra juicy, juicy or well done?
[02:03:55.020 --> 02:03:56.260]   Oh, he did it.
[02:03:56.260 --> 02:03:57.260]   You were sneaky.
[02:03:57.260 --> 02:04:00.300]   You didn't tell us he was doing it in the June.
[02:04:00.300 --> 02:04:01.300]   I couldn't.
[02:04:01.300 --> 02:04:02.300]   I was under.
[02:04:02.300 --> 02:04:04.700]   No, that happens all the time.
[02:04:04.700 --> 02:04:05.700]   It was delicious.
[02:04:05.700 --> 02:04:06.700]   Is that it?
[02:04:06.700 --> 02:04:07.700]   Is that a spatchcock?
[02:04:07.700 --> 02:04:09.460]   That's a spatchcock chicken right there.
[02:04:09.460 --> 02:04:14.060]   I mean, it should have been smoosh flatter, but you can see it's a little, I mean, it's
[02:04:14.060 --> 02:04:15.060]   smallish.
[02:04:15.060 --> 02:04:18.540]   You could, you'd have to spatchcock it to get a big bird in there, probably.
[02:04:18.540 --> 02:04:19.540]   Yeah.
[02:04:19.540 --> 02:04:22.140]   You have to dismember it, I think.
[02:04:22.140 --> 02:04:23.140]   Sorry.
[02:04:23.140 --> 02:04:27.740]   You have to hack that sucker up and arrange it.
[02:04:27.740 --> 02:04:29.380]   Well, I bought it because of you.
[02:04:29.380 --> 02:04:33.860]   I should really give that $100 referral fee to you, but you know, you still need 15 more
[02:04:33.860 --> 02:04:35.860]   to get one.
[02:04:35.860 --> 02:04:37.540]   All right.
[02:04:37.540 --> 02:04:38.540]   Okay.
[02:04:38.540 --> 02:04:39.540]   Neat.
[02:04:39.540 --> 02:04:41.540]   Is it June of in calm June.com?
[02:04:41.540 --> 02:04:44.340]   I think it's June of in calm.
[02:04:44.340 --> 02:04:45.340]   Let's see.
[02:04:45.340 --> 02:04:46.340]   Just Google June oven.
[02:04:46.340 --> 02:04:47.340]   Do what everybody.
[02:04:47.340 --> 02:04:49.020]   Help Leo out, man, you guys.
[02:04:49.020 --> 02:04:50.580]   So Lisa doesn't get so mad at him.
[02:04:50.580 --> 02:04:51.580]   You could go.
[02:04:51.580 --> 02:04:52.580]   He's got a referral link.
[02:04:52.580 --> 02:04:53.580]   It's June oven.com.
[02:04:53.580 --> 02:04:56.260]   You save a hundred bucks when you use their referral link.
[02:04:56.260 --> 02:04:58.580]   That's highly inappropriate for me to do that.
[02:04:58.580 --> 02:05:01.700]   So I'm not going to, I'm not going to flog that.
[02:05:01.700 --> 02:05:02.700]   I did it then though.
[02:05:02.700 --> 02:05:04.460]   I regret doing it, but I did it.
[02:05:04.460 --> 02:05:07.380]   Oh, vegans, it makes the best kale chips.
[02:05:07.380 --> 02:05:08.380]   I roasted broccoli.
[02:05:08.380 --> 02:05:14.460]   I roasted potatoes mostly, mostly I love like I didn't cook any tofu, but I usually start
[02:05:14.460 --> 02:05:15.460]   to eat.
[02:05:15.460 --> 02:05:20.100]   I'm going to have roasting cauliflower and roast vegetables are delicious.
[02:05:20.100 --> 02:05:21.100]   So if it does a good job.
[02:05:21.100 --> 02:05:22.700]   Your Brussels sprouts are actually edible.
[02:05:22.700 --> 02:05:26.460]   Yes, actually roast, Brussels sprouts are delicious.
[02:05:26.460 --> 02:05:31.740]   And yes, it is not for massive holiday baking for the people who are saying this is pretty
[02:05:31.740 --> 02:05:32.740]   like secondary oven.
[02:05:32.740 --> 02:05:36.100]   You don't put your turkey in there, but you put your stuffing in there so that you're
[02:05:36.100 --> 02:05:40.260]   stuffing, you shouldn't cook in a turkey that's unsanitary, but you put it in there and then
[02:05:40.260 --> 02:05:42.900]   your stuffing is ready and you don't have to, you can have separate.
[02:05:42.900 --> 02:05:45.260]   It's like having two ovens.
[02:05:45.260 --> 02:05:52.420]   I usually cook my meat in one oven and then I have my secondary oven as all our vegetables
[02:05:52.420 --> 02:05:53.900]   or whatever's happening.
[02:05:53.900 --> 02:05:54.900]   Cool.
[02:05:54.900 --> 02:05:56.660]   It will just, yeah.
[02:05:56.660 --> 02:06:01.420]   It is a little pricey, but I hope they do well.
[02:06:01.420 --> 02:06:04.940]   You feel like it really was smart, like it's a smart oven.
[02:06:04.940 --> 02:06:08.860]   It is smart.
[02:06:08.860 --> 02:06:12.340]   And if you're a super advanced chef, you can actually control the heating elements to
[02:06:12.340 --> 02:06:13.860]   your own specifications.
[02:06:13.860 --> 02:06:19.020]   So it's smart and it can grow with your cooking skills, which I thought was pretty cool.
[02:06:19.020 --> 02:06:24.020]   My stomach's been growing with my cooking skills, so it's not that hard to do.
[02:06:24.020 --> 02:06:28.660]   And there's somebody in the chat, I'm saying there is a 100 day trial, so you could return
[02:06:28.660 --> 02:06:29.660]   it.
[02:06:29.660 --> 02:06:31.580]   Oh, well, hot diggity.
[02:06:31.580 --> 02:06:34.140]   Get it for Thanksgiving and then send it back.
[02:06:34.140 --> 02:06:36.300]   Get through the holidays and then send it back.
[02:06:36.300 --> 02:06:37.300]   Yeah.
[02:06:37.300 --> 02:06:40.820]   And it's a 16 by, oh, Crikey.
[02:06:40.820 --> 02:06:46.100]   Oh, it will only fit one nine or nine by 13 baking dish.
[02:06:46.100 --> 02:06:47.100]   Yes.
[02:06:47.100 --> 02:06:48.100]   So it is fairly small.
[02:06:48.100 --> 02:06:49.100]   It's like toast.
[02:06:49.100 --> 02:06:51.540]   It's like a large toaster oven.
[02:06:51.540 --> 02:06:52.540]   Yes.
[02:06:52.540 --> 02:06:53.540]   Yeah.
[02:06:53.540 --> 02:06:55.940]   Jeff Jarvis, give us a number.
[02:06:55.940 --> 02:07:00.180]   So my number is Facebook's had a little problem with numbers lately.
[02:07:00.180 --> 02:07:09.860]   It had two spurts of bad advertising results, bad advertising metrics rather.
[02:07:09.860 --> 02:07:15.780]   The first, as we know, remember a while back was that they were under over reporting video
[02:07:15.780 --> 02:07:16.780]   plays.
[02:07:16.780 --> 02:07:23.620]   And then they had a whole bunch kind of boring stuff, but importantly, the added industry
[02:07:23.620 --> 02:07:32.580]   organic reach was miscalculated because it didn't do repeat visits.
[02:07:32.580 --> 02:07:37.620]   Organic reach pay metric was will now include only viewable impressions.
[02:07:37.620 --> 02:07:43.300]   There was an issue found within instant articles that have over reported average time spent
[02:07:43.300 --> 02:07:45.060]   by seven to eight percent.
[02:07:45.060 --> 02:07:47.180]   Yeah, at all up.
[02:07:47.180 --> 02:07:48.180]   And there's some issues there.
[02:07:48.180 --> 02:07:49.820]   So Facebook's doing three things about it.
[02:07:49.820 --> 02:07:52.980]   One is they're launching a measurement council.
[02:07:52.980 --> 02:07:57.020]   Two is they're bringing an additional third party verification measures and three, they're
[02:07:57.020 --> 02:08:02.500]   introducing that this will solve everything a blog called metrics FYI a series of about
[02:08:02.500 --> 02:08:03.740]   being upfront about this.
[02:08:03.740 --> 02:08:06.940]   So that's when they discover bugs and discover errors.
[02:08:06.940 --> 02:08:09.780]   They will be more open about it, which is a good idea.
[02:08:09.780 --> 02:08:10.780]   That's good.
[02:08:10.780 --> 02:08:12.420]   So numbers, numbers, numbers.
[02:08:12.420 --> 02:08:15.460]   At Jadella, he says he has a number for you.
[02:08:15.460 --> 02:08:23.820]   15,910, the number of total episodes on Twitter TV of all the shows ever.
[02:08:23.820 --> 02:08:24.820]   She is.
[02:08:24.820 --> 02:08:25.820]   I'm on most of them.
[02:08:25.820 --> 02:08:27.660]   That's a lot of there.
[02:08:27.660 --> 02:08:28.660]   It's a lot of Leo.
[02:08:28.660 --> 02:08:29.660]   That's a lot of.
[02:08:29.660 --> 02:08:31.500]   I was going to say that's a lot of hot air.
[02:08:31.500 --> 02:08:33.500]   Hey, I'm sorry.
[02:08:33.500 --> 02:08:34.740]   Hey, it's okay.
[02:08:34.740 --> 02:08:35.940]   I deserve it.
[02:08:35.940 --> 02:08:43.540]   My pick is going to actually be an early pick because later this week we're going to review
[02:08:43.540 --> 02:08:46.540]   the new Apple MacBook Pro.
[02:08:46.540 --> 02:08:48.980]   I just got it yesterday.
[02:08:48.980 --> 02:08:51.340]   We got a 13 and a 15.
[02:08:51.340 --> 02:08:53.020]   We've been playing with them ever since.
[02:08:53.020 --> 02:08:56.940]   We'll have a longer review on Saturday on the new screensavers.
[02:08:56.940 --> 02:09:02.460]   But I wanted to mention because I'd given Apple a hard time on this that it wasn't innovative,
[02:09:02.460 --> 02:09:08.020]   that wasn't really the computer professionals were looking for the speed and so forth.
[02:09:08.020 --> 02:09:09.020]   That's still true.
[02:09:09.020 --> 02:09:15.100]   Any laptop that's tapped out at 16 gigabytes is really underpowered these days, 16 gigabytes
[02:09:15.100 --> 02:09:16.180]   of RAM.
[02:09:16.180 --> 02:09:17.740]   But there are a few bright lights here.
[02:09:17.740 --> 02:09:20.420]   It's a gorgeous screen.
[02:09:20.420 --> 02:09:25.100]   It supports the P3 color gamut, which means it's a very accurate screen.
[02:09:25.100 --> 02:09:32.660]   As accurate as any screen sold for desktop or laptops today, beautiful, crisp, bright and
[02:09:32.660 --> 02:09:34.180]   vivid colors.
[02:09:34.180 --> 02:09:39.540]   I also was a little worried about the keyboard because it looks like a duplicate of the MacBook
[02:09:39.540 --> 02:09:40.540]   keyboard.
[02:09:40.540 --> 02:09:42.900]   But Apple said, "We've done a little bit something different."
[02:09:42.900 --> 02:09:44.620]   And it is more clickety.
[02:09:44.620 --> 02:09:46.340]   And I'm thinking a little bit for me.
[02:09:46.340 --> 02:09:47.980]   I did not like the MacBook keyboard.
[02:09:47.980 --> 02:09:49.540]   In fact, never really could use it well.
[02:09:49.540 --> 02:09:53.580]   I've already become accustomed much more so to the new MacBook Pro keyboard.
[02:09:53.580 --> 02:09:55.020]   I feel like it's pretty good.
[02:09:55.020 --> 02:09:59.460]   The touch bar, which of course is the only real innovation in here, is very interesting.
[02:09:59.460 --> 02:10:02.900]   I love using my fingerprint to unlock the laptop.
[02:10:02.900 --> 02:10:04.300]   This is the first time for Apple.
[02:10:04.300 --> 02:10:10.220]   Certainly not the first time on a laptop PCs have had this for probably a decade.
[02:10:10.220 --> 02:10:15.220]   It does also do some interesting things when you launch apps from Apple.
[02:10:15.220 --> 02:10:19.500]   It's programmable, so it changes and shifts and gives you new commands.
[02:10:19.500 --> 02:10:22.300]   That's part of the thing I don't like about it is you have to look at it.
[02:10:22.300 --> 02:10:23.300]   You have to remember to look at it.
[02:10:23.300 --> 02:10:26.500]   You can't touch type with it because it's different all the time.
[02:10:26.500 --> 02:10:30.060]   But having said that, there are a few useful things you can do with it.
[02:10:30.060 --> 02:10:33.060]   And I think in time I might find it to be a very nice useful adjunct.
[02:10:33.060 --> 02:10:37.220]   If Apple's not going to do a touchscreen, at least they've got the touch bar.
[02:10:37.220 --> 02:10:40.780]   So a full review of the new MacBook Pro.
[02:10:40.780 --> 02:10:43.580]   This is the 15-inch.
[02:10:43.580 --> 02:10:45.380]   This Saturday, I'll do the 13 as well.
[02:10:45.380 --> 02:10:48.420]   This Saturday on the new screen savers.
[02:10:48.420 --> 02:10:53.940]   "Lady and Gentlemen, it has been a pleasure to reunite with you and see you once again."
[02:10:53.940 --> 02:10:55.460]   That was all nice.
[02:10:55.460 --> 02:10:57.940]   And I think we did a pretty good job today.
[02:10:57.940 --> 02:10:58.940]   I think so.
[02:10:58.940 --> 02:10:59.940]   Yes.
[02:10:59.940 --> 02:11:02.860]   No tears were shed, no blood was shed.
[02:11:02.860 --> 02:11:04.340]   No shoes were thrown.
[02:11:04.340 --> 02:11:09.340]   I didn't get tweeted 20 times through the show talking about what a dork I am.
[02:11:09.340 --> 02:11:10.340]   Wow.
[02:11:10.340 --> 02:11:11.860]   We must have done something wrong.
[02:11:11.860 --> 02:11:12.860]   I know.
[02:11:12.860 --> 02:11:13.860]   Jeff Jarvis.
[02:11:13.860 --> 02:11:14.860]   Go ahead.
[02:11:14.860 --> 02:11:19.940]   Sometimes that tends to come with an email later after they think about it.
[02:11:19.940 --> 02:11:20.940]   Yeah.
[02:11:20.940 --> 02:11:21.940]   Yeah.
[02:11:21.940 --> 02:11:25.620]   Jeff Jarvis will be on the email later this week.
[02:11:25.620 --> 02:11:30.580]   No, Jeff Jarvis is at the CUNY School of Journalism there at City University of New
[02:11:30.580 --> 02:11:32.300]   York also at buzzmachine.com.
[02:11:32.300 --> 02:11:36.700]   Author of many great books, Gutenberg, The Geek We Mentioned, Public Parts, What Would
[02:11:36.700 --> 02:11:42.420]   Google Do and Geek's Bearing Gifts is latest about the news biz.
[02:11:42.420 --> 02:11:44.620]   It's always a really great time with you.
[02:11:44.620 --> 02:11:45.620]   Thank you, Jeff, for being here.
[02:11:45.620 --> 02:11:46.620]   Thank you, boss.
[02:11:46.620 --> 02:11:47.620]   Have you retired the Hillary gear?
[02:11:47.620 --> 02:11:48.620]   Is it going to be the case?
[02:11:48.620 --> 02:11:51.980]   So I tried wearing, well, I don't know.
[02:11:51.980 --> 02:11:55.580]   So this arrived the morning after the defeat.
[02:11:55.580 --> 02:11:57.780]   Oh my God.
[02:11:57.780 --> 02:11:59.500]   The refrigerator magnet.
[02:11:59.500 --> 02:12:00.660]   I bought my daughter.
[02:12:00.660 --> 02:12:03.300]   I don't think I'm going to give it to her.
[02:12:03.300 --> 02:12:05.260]   A madam president button.
[02:12:05.260 --> 02:12:11.300]   Oh, that's the one where I really kind of feel sad is for all the women and girls who
[02:12:11.300 --> 02:12:12.900]   were looking forward to that glass ceiling.
[02:12:12.900 --> 02:12:15.700]   I won't show you the one that I'm proudest of buying.
[02:12:15.700 --> 02:12:18.060]   Yeah, I can imagine what it says.
[02:12:18.060 --> 02:12:20.260]   It says F somebody, but there's this one.
[02:12:20.260 --> 02:12:22.060]   I was at the rally.
[02:12:22.060 --> 02:12:27.500]   So I wore the safety pin for about three days, but then felt foolish.
[02:12:27.500 --> 02:12:28.500]   So I took that off.
[02:12:28.500 --> 02:12:29.500]   Yeah.
[02:12:29.500 --> 02:12:30.500]   Yeah.
[02:12:30.500 --> 02:12:32.620]   You know what I was thinking about wearing a safety pin too, and then I read an article
[02:12:32.620 --> 02:12:35.940]   on the Huffington Post that said, that's daft.
[02:12:35.940 --> 02:12:36.940]   It's condescending.
[02:12:36.940 --> 02:12:37.940]   It's condescending.
[02:12:37.940 --> 02:12:38.940]   But daft was a good word.
[02:12:38.940 --> 02:12:39.940]   Yes.
[02:12:39.940 --> 02:12:40.940]   And I kind of agreed with it.
[02:12:40.940 --> 02:12:45.180]   So I just sent money to the ACLU and Southern Barbara, the law said, I'll stand.
[02:12:45.180 --> 02:12:49.340]   Stacey Higginbotham, always a pleasure from the People's Republic of Boston.
[02:12:49.340 --> 02:12:50.340]   Really nice to have you back.
[02:12:50.340 --> 02:12:51.780]   We did miss you.
[02:12:51.780 --> 02:12:54.380]   You can find her podcast at IOTpodcast.com.
[02:12:54.380 --> 02:13:01.060]   She does that with our great friend and wonderful guy, Kevin Tofel, and also Stacey on
[02:13:01.060 --> 02:13:03.540]   IOT.com, @geagastacey on the Twitter.
[02:13:03.540 --> 02:13:04.540]   Thank you, Stacey.
[02:13:04.540 --> 02:13:07.180]   What are you having for dinner tonight?
[02:13:07.180 --> 02:13:09.580]   Great fruit salad and cornbread.
[02:13:09.580 --> 02:13:10.580]   At least you're having cornbread.
[02:13:10.580 --> 02:13:13.460]   Oh, great fruit salad is delicious.
[02:13:13.460 --> 02:13:15.020]   Oh, you know why?
[02:13:15.020 --> 02:13:17.340]   Because it's 87 degrees in Austin.
[02:13:17.340 --> 02:13:18.340]   Right.
[02:13:18.340 --> 02:13:19.340]   Yeah.
[02:13:19.340 --> 02:13:20.340]   Exactly.
[02:13:20.340 --> 02:13:21.940]   I'd be eating great fruit salad too.
[02:13:21.940 --> 02:13:22.940]   Nice.
[02:13:22.940 --> 02:13:23.940]   Thank you both for being here.
[02:13:23.940 --> 02:13:25.780]   Thank you all for being here.
[02:13:25.780 --> 02:13:31.380]   We do this week in Google every Wednesday, 1.30pm Pacific, 4.30pm Eastern, 1930 UTC.
[02:13:31.380 --> 02:13:35.900]   If you want to stop by, say hi, join us in the chatroom at IRC.twit.tv or sit on one
[02:13:35.900 --> 02:13:36.900]   of these fine chairs.
[02:13:36.900 --> 02:13:37.900]   You can do that too.
[02:13:37.900 --> 02:13:39.500]   Email tickets at Twit.tv.
[02:13:39.500 --> 02:13:44.260]   But if you can't be here in person or on the stream in real time, you can always do it
[02:13:44.260 --> 02:13:50.340]   after the fact on demand audio and video at twit.tv/twig, youtube.com/thisweekengoogol,
[02:13:50.340 --> 02:13:55.420]   or wherever you subscribe to podcasts, where everywhere, Stitcher, Slacker, Google Play
[02:13:55.420 --> 02:13:56.740]   Music and all the rest.
[02:13:56.740 --> 02:14:01.140]   In fact, you can listen on the Google Home as well as the Amazon Echo.
[02:14:01.140 --> 02:14:02.140]   Thanks for listening.
[02:14:02.140 --> 02:14:03.140]   Glad you were here.
[02:14:03.140 --> 02:14:04.140]   We'll see you next time on Twig.
[02:14:04.140 --> 02:14:04.140]   Bye-bye.
[02:14:04.140 --> 02:14:14.140]   [MUSIC]

