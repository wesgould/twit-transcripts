;FFMETADATA1
title=Numburglar
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=346
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:03.800]   It's time for Twig this weekend Google I'm back at Studio Jeff Jarvis is in New York
[00:00:03.800 --> 00:00:05.600]   and Robert Scobold joins us.
[00:00:05.600 --> 00:00:08.600]   We'll talk about Facebook the F8 conference is coming up.
[00:00:08.600 --> 00:00:14.000]   The latest with the lawsuit, the Department of Justice and Apple turns out there's 70
[00:00:14.000 --> 00:00:17.200]   more coming down the pipe and a whole lot more.
[00:00:17.200 --> 00:00:19.400]   Yep, Twig is next.
[00:00:19.400 --> 00:00:23.800]   Netcast you love.
[00:00:23.800 --> 00:00:25.800]   From people you trust.
[00:00:29.000 --> 00:00:31.000]   This is Twig.
[00:00:31.000 --> 00:00:38.000]   bandwidth for this week in Google is provided by cash fly C A C H E F L Y dot com.
[00:00:38.000 --> 00:00:51.000]   This is Twig this week in Google episode 346 recorded Wednesday March 30th 2016.
[00:00:51.000 --> 00:00:54.000]   Numburgler.
[00:00:54.000 --> 00:00:57.000]   This week in Google is brought to you by Atlassian.
[00:00:57.000 --> 00:01:01.000]   And you can unleash your team's potential with collaborative software tools like Hip Chat
[00:01:01.000 --> 00:01:04.000]   and Jira which will let you work and communicate better together.
[00:01:04.000 --> 00:01:06.000]   Visit Atlassian dot com.
[00:01:06.000 --> 00:01:12.000]   And by Casper and online retailer Premium Matrices for a fraction of the price because
[00:01:12.000 --> 00:01:14.000]   everyone deserves a great night's sleep.
[00:01:14.000 --> 00:01:21.000]   Get $50 off any mattress purchased by visiting Casper dot com slash Twig and using the promo code Twig.
[00:01:21.000 --> 00:01:24.000]   It's time for Twig this weekend Google.
[00:01:24.000 --> 00:01:30.000]   We covered the latest Google verse news, Facebook and Twitter and anything else we're interested in.
[00:01:30.000 --> 00:01:35.000]   And usually we have a lot of fun kind of drifting around to follow our interests.
[00:01:35.000 --> 00:01:36.000]   Jeff Jarvis is here.
[00:01:36.000 --> 00:01:41.000]   His wide ranging interests include of course journalism because he's a professor of journalism at CUNY,
[00:01:41.000 --> 00:01:43.000]   the City University of New York, and in Manhattan.
[00:01:43.000 --> 00:01:44.000]   Where are you?
[00:01:44.000 --> 00:01:46.000]   We were proud to have you as a Tesla.
[00:01:46.000 --> 00:01:48.000]   What a nice studio.
[00:01:48.000 --> 00:01:50.000]   I had so much fun last week.
[00:01:50.000 --> 00:01:53.000]   I had a great response for the show.
[00:01:53.000 --> 00:01:55.000]   Everybody said, "Look, good at looked."
[00:01:55.000 --> 00:01:59.000]   So, yeah, that's what we'll talk about in a second because I want to introduce our other panelists.
[00:01:59.000 --> 00:02:02.000]   Robert Scobel, the Scobelizer is here.
[00:02:02.000 --> 00:02:03.000]   What's up?
[00:02:03.000 --> 00:02:06.000]   It is last few days at Rackspace.
[00:02:06.000 --> 00:02:08.000]   How do you even lower my Rackspace sure?
[00:02:08.000 --> 00:02:09.000]   You know what you did?
[00:02:09.000 --> 00:02:15.000]   You've done so much for every company you worked for including Microsoft and Rackspace.
[00:02:15.000 --> 00:02:16.000]   Absolutely.
[00:02:16.000 --> 00:02:17.000]   What's up, Jeff?
[00:02:17.000 --> 00:02:18.000]   Put them on the map.
[00:02:18.000 --> 00:02:19.000]   It's been seven years.
[00:02:19.000 --> 00:02:20.000]   Wow.
[00:02:20.000 --> 00:02:21.000]   That's amazing.
[00:02:21.000 --> 00:02:22.000]   Wow.
[00:02:22.000 --> 00:02:23.000]   What's next?
[00:02:23.000 --> 00:02:28.160]   I'm going to upload VR, a media company that's covering the VR space and augmented reality
[00:02:28.160 --> 00:02:29.160]   space.
[00:02:29.160 --> 00:02:30.160]   Back to journalism, huh?
[00:02:30.160 --> 00:02:35.600]   Yeah, you know, go to a media company, maybe do some events, stuff like that.
[00:02:35.600 --> 00:02:38.000]   You couldn't be jumping on a better bandwagon.
[00:02:38.000 --> 00:02:40.000]   No, I could not.
[00:02:40.000 --> 00:02:42.400]   We're kind of jumping on the bandwagon too.
[00:02:42.400 --> 00:02:46.400]   Right before the show, we finished the build of our ultimate virtual reality gaming machine.
[00:02:46.400 --> 00:02:48.400]   Well, that's what it was for.
[00:02:48.400 --> 00:02:50.120]   Oh, I can't even hear it.
[00:02:50.120 --> 00:02:52.040]   It's the seventh or eighth in the series.
[00:02:52.040 --> 00:02:56.320]   Starting with day one in Tech TV, May 11, 1998, when we built the ultimate gaming machine,
[00:02:56.320 --> 00:03:01.960]   which at that time, you would laugh if you were trying to play a game with it today.
[00:03:01.960 --> 00:03:04.200]   But at that time, it cost a lot more.
[00:03:04.200 --> 00:03:06.200]   It was maybe two or three times more than no.
[00:03:06.200 --> 00:03:07.700]   What does this one cost?
[00:03:07.700 --> 00:03:08.700]   Five grand.
[00:03:08.700 --> 00:03:10.100]   Five grand?
[00:03:10.100 --> 00:03:11.100]   Not bad.
[00:03:11.100 --> 00:03:13.960]   The ones we have in my office are about 4,500.
[00:03:13.960 --> 00:03:16.240]   So it sounds like a similar kind of machine.
[00:03:16.240 --> 00:03:17.240]   Yeah.
[00:03:17.240 --> 00:03:19.840]   You know, as Oculus has pointed out, you can get by.
[00:03:19.840 --> 00:03:26.120]   I mean, the minimum that they've described is you can get a computer for around 1,000
[00:03:26.120 --> 00:03:27.120]   bucks.
[00:03:27.120 --> 00:03:28.880]   Yeah, 1,500, so on.
[00:03:28.880 --> 00:03:29.880]   Yeah.
[00:03:29.880 --> 00:03:32.120]   And then you add the 500 or 600 bucks for the gear VR.
[00:03:32.120 --> 00:03:37.240]   They have their Oculus website, a list of Oculus-ready PCs.
[00:03:37.240 --> 00:03:43.200]   But the thing that's kind of key is something like 18% of all PCs currently in the market
[00:03:43.200 --> 00:03:44.200]   are Oculus-ready.
[00:03:44.200 --> 00:03:47.880]   And it is a demanding platform.
[00:03:47.880 --> 00:03:51.080]   Yeah, you need a big Nvidia card, basically.
[00:03:51.080 --> 00:03:53.280]   Yeah, you need a 970 or better.
[00:03:53.280 --> 00:03:54.280]   Yeah.
[00:03:54.280 --> 00:03:58.480]   It's really interesting because we have a few in the office, some that are in the $1,500
[00:03:58.480 --> 00:04:01.440]   level all the way up to the ultimate level.
[00:04:01.440 --> 00:04:06.000]   And there's not a whole lot of difference in terms of the experience in Oculus.
[00:04:06.000 --> 00:04:13.880]   And we surmise because most of the content producers are building it for a minimum platform
[00:04:13.880 --> 00:04:14.880]   level.
[00:04:14.880 --> 00:04:21.720]   So we're expecting some of the later games or experiences that come out to be pushing
[00:04:21.720 --> 00:04:24.160]   the Nvidia card a little bit harder.
[00:04:24.160 --> 00:04:26.000]   And then we might see some differences.
[00:04:26.000 --> 00:04:31.920]   But right now, if you don't care about future proofing, if you just care about playing
[00:04:31.920 --> 00:04:35.520]   what's out there today, the $1,500 level is just fine.
[00:04:35.520 --> 00:04:36.520]   That surprised me.
[00:04:36.520 --> 00:04:40.560]   I mean, I was-- one of the reasons we spent this money is because we wanted frame rates
[00:04:40.560 --> 00:04:41.560]   to be smooth.
[00:04:41.560 --> 00:04:42.560]   Yeah.
[00:04:42.560 --> 00:04:45.080]   And Oculus itself display, you don't think you could do about that.
[00:04:45.080 --> 00:04:46.080]   That's the display.
[00:04:46.080 --> 00:04:47.080]   Yeah.
[00:04:47.080 --> 00:04:50.480]   But-- and they're probably-- I don't know.
[00:04:50.480 --> 00:04:51.480]   Are they--
[00:04:51.480 --> 00:04:56.680]   Well, they're not-- it's not like old video games where they would put a lot more polygons
[00:04:56.680 --> 00:04:58.480]   out in front of you.
[00:04:58.480 --> 00:04:59.480]   So you would--
[00:04:59.480 --> 00:05:00.480]   It is what it is.
[00:05:00.480 --> 00:05:01.480]   Yeah.
[00:05:01.480 --> 00:05:03.600]   And it's pretty smooth.
[00:05:03.600 --> 00:05:08.680]   We have HTC Vibes and Oculus in our offices on both machines.
[00:05:08.680 --> 00:05:11.360]   And it's hard to tell the difference.
[00:05:11.360 --> 00:05:12.360]   I'm excited about the Vibes.
[00:05:12.360 --> 00:05:16.240]   The Vibes-- no, yes, the Vibes comes with handles.
[00:05:16.240 --> 00:05:17.240]   Yes.
[00:05:17.240 --> 00:05:18.920]   [LAUGHTER]
[00:05:18.920 --> 00:05:19.920]   Which the Rift doesn't.
[00:05:19.920 --> 00:05:23.840]   The Oculus Touch devices won't be available to the later this year.
[00:05:23.840 --> 00:05:27.000]   Probably around July or August, yeah.
[00:05:27.000 --> 00:05:32.160]   But I have to-- a little praise for Oculus because I felt-- I felt a little cheated.
[00:05:32.160 --> 00:05:35.280]   I was-- I had bought in at the Kickstarter deal.
[00:05:35.280 --> 00:05:36.720]   I don't remember how much I put in.
[00:05:36.720 --> 00:05:37.720]   You did too, I'm sure.
[00:05:37.720 --> 00:05:43.400]   I did not, actually, but my friend Andy did and he got his a couple days ago.
[00:05:43.400 --> 00:05:47.160]   Well, that's what I was going to say is we bought this Oculus Rift what is four or five
[00:05:47.160 --> 00:05:52.800]   years ago, got the first developer edition, and then, I think a couple years later, oh,
[00:05:52.800 --> 00:05:55.320]   by the way, Facebook bought us for billions of dollars.
[00:05:55.320 --> 00:05:57.800]   And I felt like, oh, it was a little of a letdown.
[00:05:57.800 --> 00:06:01.640]   I mean, it's certainly not against the Kickstarter promise or anything, but I just felt like,
[00:06:01.640 --> 00:06:03.200]   well, I invested in that company.
[00:06:03.200 --> 00:06:08.160]   I gave them money hoping that they would-- but they're going to now take-- Mark has a little
[00:06:08.160 --> 00:06:09.160]   more money.
[00:06:09.160 --> 00:06:10.160]   I do.
[00:06:10.160 --> 00:06:16.280]   But to their credit, and they didn't have to do this, they are giving the release version
[00:06:16.280 --> 00:06:18.680]   to every single Kickstarter supporter who bought it.
[00:06:18.680 --> 00:06:19.680]   Yeah, that was nice, actually.
[00:06:19.680 --> 00:06:20.680]   They didn't have to do that.
[00:06:20.680 --> 00:06:26.120]   They didn't have to, but they did make a lot of money on the sale.
[00:06:26.120 --> 00:06:31.760]   And so it's only fair that they did that for the early people who supported them and put
[00:06:31.760 --> 00:06:36.640]   them in a position where Facebook bought them for what, $3 billion?
[00:06:36.640 --> 00:06:37.640]   Yeah.
[00:06:37.640 --> 00:06:38.640]   So I'm thrilled.
[00:06:38.640 --> 00:06:47.680]   Yeah, Palmer Lucky last week flew to Alaska to give the very first Oculus Rift to Byron
[00:06:47.680 --> 00:06:50.840]   Alaska who didn't have a PC that would run it.
[00:06:50.840 --> 00:06:51.840]   Oh, no.
[00:06:51.840 --> 00:06:53.520]   It was put on his head.
[00:06:53.520 --> 00:06:57.120]   So that's why we were rushing before the show to finish this of Vergum.
[00:06:57.120 --> 00:06:58.120]   We had all the parts.
[00:06:58.120 --> 00:06:59.640]   In fact, we'd introduced all the parts.
[00:06:59.640 --> 00:07:02.840]   The only thing we hadn't introduced was the monitor, keyboard, and mouse, which we'll
[00:07:02.840 --> 00:07:03.840]   do on Saturday.
[00:07:03.840 --> 00:07:07.600]   But we wanted it, we have to install windows and have that working and running and...
[00:07:07.600 --> 00:07:10.640]   But did you have a local 14 year old build this machine for you?
[00:07:10.640 --> 00:07:12.160]   I'm the local 14 year old.
[00:07:12.160 --> 00:07:14.880]   And I have to tell you, at my age, it ain't easy.
[00:07:14.880 --> 00:07:16.400]   It was pretty funny to watch.
[00:07:16.400 --> 00:07:17.400]   Yeah, it was great.
[00:07:17.400 --> 00:07:21.640]   Yeah, it's people in the chat room going, "I guess Leo hasn't done this in a while.
[00:07:21.640 --> 00:07:23.120]   Where does this screw?
[00:07:23.120 --> 00:07:24.120]   What's this extra?
[00:07:24.120 --> 00:07:25.200]   How does that...?"
[00:07:25.200 --> 00:07:32.560]   But to my credit, I only had to fully take it apart once because I forgot something.
[00:07:32.560 --> 00:07:35.120]   And when we booted it up, it didn't boot.
[00:07:35.120 --> 00:07:40.040]   It got really close and then we realized, "Oh, I hadn't plugged in one little power connector
[00:07:40.040 --> 00:07:41.040]   was still missing."
[00:07:41.040 --> 00:07:43.080]   Plugged it in and then it booted.
[00:07:43.080 --> 00:07:45.960]   So that's not really credit to me.
[00:07:45.960 --> 00:07:47.440]   And then poor Leo had to leave and do the show.
[00:07:47.440 --> 00:07:48.440]   I know.
[00:07:48.440 --> 00:07:51.200]   I'm watching him play with it over there.
[00:07:51.200 --> 00:07:53.360]   It's my toy.
[00:07:53.360 --> 00:07:54.760]   It's pretty awesome.
[00:07:54.760 --> 00:07:57.560]   And I'm looking forward to it.
[00:07:57.560 --> 00:07:59.360]   But I'm waiting for word from Oculus.
[00:07:59.360 --> 00:08:05.040]   I don't know if we'll have it on Saturday because I talk about, I would have it.
[00:08:05.040 --> 00:08:07.640]   They had sent me a message on the 15th, which I didn't notice.
[00:08:07.640 --> 00:08:10.560]   They said, "We need your phone number before we can ship it."
[00:08:10.560 --> 00:08:13.880]   So I gave him the phone number early this week and I'm hoping that.
[00:08:13.880 --> 00:08:15.920]   And then I said, "Come on, can you get it to me quickly?
[00:08:15.920 --> 00:08:17.440]   I'll come down and get it."
[00:08:17.440 --> 00:08:20.200]   Well, we might have to drop by with a vibe or something.
[00:08:20.200 --> 00:08:21.200]   Would you?
[00:08:21.200 --> 00:08:22.200]   Robert.
[00:08:22.200 --> 00:08:23.200]   You're invited.
[00:08:23.200 --> 00:08:27.240]   All my friends are all said, "Come out of the woodwork."
[00:08:27.240 --> 00:08:29.440]   Oh, you have them.
[00:08:29.440 --> 00:08:31.840]   Oh, yeah.
[00:08:31.840 --> 00:08:38.480]   Leo, you know you're not the only executive being locked out of Oculus Rift information
[00:08:38.480 --> 00:08:39.480]   right now.
[00:08:39.480 --> 00:08:40.480]   Oh, wait a minute.
[00:08:40.480 --> 00:08:42.480]   I just got an email shipping notice.
[00:08:42.480 --> 00:08:45.840]   Next, you have a package coming Thursday.
[00:08:45.840 --> 00:08:46.840]   Yeah.
[00:08:46.840 --> 00:08:47.840]   Nice.
[00:08:47.840 --> 00:08:48.840]   Tomorrow.
[00:08:48.840 --> 00:08:49.840]   Woo-hoo.
[00:08:49.840 --> 00:08:51.400]   We're also getting the new iPads tomorrow.
[00:08:51.400 --> 00:08:53.400]   It's going to be an exciting day.
[00:08:53.400 --> 00:08:54.680]   Unboxings all around.
[00:08:54.680 --> 00:08:55.680]   Who?
[00:08:55.680 --> 00:08:57.120]   Who is what?
[00:08:57.120 --> 00:08:58.120]   What executive?
[00:08:58.120 --> 00:08:59.920]   Didn't get his Rift.
[00:08:59.920 --> 00:09:00.920]   No, no, no.
[00:09:00.920 --> 00:09:03.680]   You didn't see the story about Mark Zuckerberg getting locked out of an office?
[00:09:03.680 --> 00:09:04.680]   Oh, yeah.
[00:09:04.680 --> 00:09:05.680]   I just saw the video of him.
[00:09:05.680 --> 00:09:06.680]   He goes up to an office.
[00:09:06.680 --> 00:09:07.680]   This is our secret lab.
[00:09:07.680 --> 00:09:08.680]   Here, well, let's see.
[00:09:08.680 --> 00:09:09.680]   Let's watch it.
[00:09:09.680 --> 00:09:10.680]   This is great.
[00:09:10.680 --> 00:09:11.680]   So this is like a tour.
[00:09:11.680 --> 00:09:20.760]   We have a bunch of different vision labs, which I think is, um, uh, apparently I do not
[00:09:20.760 --> 00:09:22.760]   have access to go to the news.
[00:09:22.760 --> 00:09:23.760]   Yeah.
[00:09:23.760 --> 00:09:24.760]   But wait a minute.
[00:09:24.760 --> 00:09:25.760]   Can I say something?
[00:09:25.760 --> 00:09:28.200]   Why do they have a big glass window on the thing?
[00:09:28.200 --> 00:09:32.040]   Well, I guess because you don't see anything unless you have them on.
[00:09:32.040 --> 00:09:34.440]   That's dopey.
[00:09:34.440 --> 00:09:38.440]   That's not that was that's a, that's staged.
[00:09:38.440 --> 00:09:39.440]   But it is fun.
[00:09:39.440 --> 00:09:40.440]   You never know.
[00:09:40.440 --> 00:09:41.440]   You know, no.
[00:09:41.440 --> 00:09:42.920]   You know, Mark pretty, both of you guys know Mark pretty well.
[00:09:42.920 --> 00:09:43.920]   I've never talked.
[00:09:43.920 --> 00:09:44.920]   I know.
[00:09:44.920 --> 00:09:46.160]   Well, but you've interviewed him.
[00:09:46.160 --> 00:09:47.160]   So yeah.
[00:09:47.160 --> 00:09:48.160]   Yeah.
[00:09:48.160 --> 00:09:51.600]   Actually, we should just do a whole show about Mark Zuckerberg.
[00:09:51.600 --> 00:09:52.600]   The man.
[00:09:52.600 --> 00:09:57.960]   If I worked up Facebook in a secret lab, I'd, I'd like Mark out to.
[00:09:57.960 --> 00:09:59.440]   What?
[00:09:59.440 --> 00:10:03.520]   So tell me a little, both of you guys, tell me a little bit about Mark Zuckerberg.
[00:10:03.520 --> 00:10:04.760]   I really would like to know.
[00:10:04.760 --> 00:10:08.920]   I mean, here, this is a big week for him because he's a little charming and humorous
[00:10:08.920 --> 00:10:11.120]   than that anybody gives him credit for.
[00:10:11.120 --> 00:10:12.120]   Yeah.
[00:10:12.120 --> 00:10:13.120]   Yeah.
[00:10:13.120 --> 00:10:16.360]   I mean, he's got a geeky sense of humor, but he's one of us, right?
[00:10:16.360 --> 00:10:17.360]   Yeah.
[00:10:17.360 --> 00:10:23.840]   I tried to take him to the Google party and, and he said, I don't have a ticket.
[00:10:23.840 --> 00:10:25.840]   And I said, I don't think that's going to be a problem.
[00:10:25.840 --> 00:10:27.440]   Don't you know who I am?
[00:10:27.440 --> 00:10:28.440]   Oh, yeah.
[00:10:28.440 --> 00:10:29.440]   I saw you in that movie.
[00:10:29.440 --> 00:10:30.800]   You're Jesse Eisenberg, right?
[00:10:30.800 --> 00:10:31.800]   Yeah.
[00:10:31.800 --> 00:10:32.800]   That's who I am.
[00:10:32.800 --> 00:10:33.800]   Yeah.
[00:10:33.800 --> 00:10:35.800]   I'm Jesse Eisen.
[00:10:35.800 --> 00:10:37.440]   He seems nothing like the movie.
[00:10:37.440 --> 00:10:40.880]   No, the movie did him a grave disservice, I think.
[00:10:40.880 --> 00:10:41.880]   Yeah.
[00:10:41.880 --> 00:10:42.880]   Like it does everybody.
[00:10:42.880 --> 00:10:46.640]   Hollywood is, you know, it's about entertainment, not about accuracy.
[00:10:46.640 --> 00:10:47.640]   Well, they didn't disservice.
[00:10:47.640 --> 00:10:49.800]   It's sort of like the Trump candidacy.
[00:10:49.800 --> 00:10:53.960]   They didn't dis him as badly as Steve Jobs got this, I have to say.
[00:10:53.960 --> 00:10:56.160]   He was just pretty badly.
[00:10:56.160 --> 00:10:57.160]   Yeah.
[00:10:57.160 --> 00:11:01.040]   It wasn't mean to his kid or anything, but he did look like a winny.
[00:11:01.040 --> 00:11:03.560]   It probably would have been if he had a kid.
[00:11:03.560 --> 00:11:04.560]   Yeah.
[00:11:04.560 --> 00:11:06.120]   We're still getting some clicking from you.
[00:11:06.120 --> 00:11:07.120]   I don't know if there's a loose.
[00:11:07.120 --> 00:11:08.120]   I don't know.
[00:11:08.120 --> 00:11:09.120]   I'm sorry.
[00:11:09.120 --> 00:11:10.120]   Connection or what?
[00:11:10.120 --> 00:11:11.920]   I'm going to have to order a new audio equipment.
[00:11:11.920 --> 00:11:12.920]   That's it.
[00:11:12.920 --> 00:11:14.400]   Well, I figured it out.
[00:11:14.400 --> 00:11:15.840]   I was going to talk to him on the back channel.
[00:11:15.840 --> 00:11:16.840]   What is it?
[00:11:16.840 --> 00:11:18.520]   You're using your computer's mic.
[00:11:18.520 --> 00:11:19.960]   It didn't switch over to your headphones.
[00:11:19.960 --> 00:11:25.760]   So whenever you tap your desk, you keyboard, just stay like that the whole time.
[00:11:25.760 --> 00:11:26.760]   There you go.
[00:11:26.760 --> 00:11:27.760]   Monosodivas, hands up.
[00:11:27.760 --> 00:11:28.760]   See the hands.
[00:11:28.760 --> 00:11:32.800]   I want to touch the desk.
[00:11:32.800 --> 00:11:36.480]   Were you thinking, where's the next big thing when you took this job and upload VR?
[00:11:36.480 --> 00:11:37.480]   You must have been.
[00:11:37.480 --> 00:11:38.480]   Yeah, I did.
[00:11:38.480 --> 00:11:42.400]   You know, I wanted to go into VR because I saw how important it was.
[00:11:42.400 --> 00:11:47.960]   I've been around the world and watched people get their first experiences in VR.
[00:11:47.960 --> 00:11:52.800]   And I figured, where could I do VR the best?
[00:11:52.800 --> 00:11:56.880]   I looked at the six different media sites that are covering it and upload was the past
[00:11:56.880 --> 00:11:59.280]   and said, hey, I want to try.
[00:11:59.280 --> 00:12:02.040]   That's what I said.
[00:12:02.040 --> 00:12:03.360]   Sure.
[00:12:03.360 --> 00:12:10.400]   So what will be, I'm asking you both this, what will be the measures of success or failure
[00:12:10.400 --> 00:12:11.400]   this year?
[00:12:11.400 --> 00:12:12.400]   Oh, man.
[00:12:12.400 --> 00:12:13.400]   Yeah.
[00:12:13.400 --> 00:12:14.400]   Yeah.
[00:12:14.400 --> 00:12:19.760]   The real problem is the number of headsets is going to be small.
[00:12:19.760 --> 00:12:22.840]   And it's going to be small for a few reasons.
[00:12:22.840 --> 00:12:25.040]   It takes 15 minutes to get a demo.
[00:12:25.040 --> 00:12:28.800]   And how many people can get a demo in the first year?
[00:12:28.800 --> 00:12:32.600]   And you're not going to buy one until you get a demo because you think everybody I talk
[00:12:32.600 --> 00:12:38.760]   to before they get their demo thinks it's dorky, thinks it's isolating, thinks it's stupid,
[00:12:38.760 --> 00:12:43.920]   thinks it's like the next 3D TV blah, blah, blah, right?
[00:12:43.920 --> 00:12:49.720]   And then I say play and they take it for 15 minutes and then they come out and go, oh,
[00:12:49.720 --> 00:12:50.720]   my God, I had no idea.
[00:12:50.720 --> 00:12:51.720]   Right?
[00:12:51.720 --> 00:12:52.720]   We talked about this question.
[00:12:52.720 --> 00:12:53.720]   Go ahead.
[00:12:53.720 --> 00:12:56.160]   If you don't play games, is there any reason to get one?
[00:12:56.160 --> 00:13:01.560]   Yeah, there's lots of things that aren't games and more we had a meetup last night about
[00:13:01.560 --> 00:13:10.840]   non-gaming uses of VR from health, curing depression to designing architecture to Ford
[00:13:10.840 --> 00:13:12.880]   uses VR to design cars, right?
[00:13:12.880 --> 00:13:17.040]   Well, actually, Leo, I know you weren't happy with me bringing the topic up, but I think
[00:13:17.040 --> 00:13:20.440]   our discussion of porn and empathy was fascinating last week.
[00:13:20.440 --> 00:13:21.440]   Oh.
[00:13:21.440 --> 00:13:27.400]   We talked about cardboard too, whether cardboard is, do you feel given that you're of all the
[00:13:27.400 --> 00:13:29.760]   people in this panel have had the most experience in a VR headset?
[00:13:29.760 --> 00:13:35.040]   Do you feel it cardboard or gear VR does justice to the experience or do you really need to
[00:13:35.040 --> 00:13:37.280]   get a vibe or an Oculus Rift?
[00:13:37.280 --> 00:13:38.280]   It does.
[00:13:38.280 --> 00:13:40.520]   It's a gateway drug, right?
[00:13:40.520 --> 00:13:46.400]   Cardboard is great for looking at something very quick and watching a 5 minute, 10 minute
[00:13:46.400 --> 00:13:48.600]   video experience.
[00:13:48.600 --> 00:13:54.360]   For instance, I took a 360 camera to Coachella last year and had one of the only videos at
[00:13:54.360 --> 00:13:57.360]   Coachella at this big music festival.
[00:13:57.360 --> 00:13:59.720]   And cardboard is great for that, right?
[00:13:59.720 --> 00:14:05.640]   Gear VR lets you play some games, but keep in mind you don't have controllers in your
[00:14:05.640 --> 00:14:08.320]   hands and the head tracking isn't as good.
[00:14:08.320 --> 00:14:15.360]   So you can get, it'll easier in the cardboard or in the gear VR than the high end headsets.
[00:14:15.360 --> 00:14:20.400]   And the high end headsets obviously have these really accurate controllers in your hands.
[00:14:20.400 --> 00:14:26.360]   I mean, in Facebook, when we do get the controllers, we can play ping pong against each other over
[00:14:26.360 --> 00:14:27.360]   the internet.
[00:14:27.360 --> 00:14:30.000]   And that's going to be a lot of fun.
[00:14:30.000 --> 00:14:33.800]   So for that kind of thing, you need the high end headsets.
[00:14:33.800 --> 00:14:39.240]   But for watching movies or lightweight video games, the gear VR or the cardboard is just
[00:14:39.240 --> 00:14:40.240]   fine.
[00:14:40.240 --> 00:14:42.800]   Have you done these social VR games?
[00:14:42.800 --> 00:14:50.520]   Yeah, I visited Facebook's Oculus Lab and they took me into an experience called Toybox.
[00:14:50.520 --> 00:14:51.520]   Yeah.
[00:14:51.520 --> 00:14:55.560]   And I'd shoot the other person, I could punch the other person, I could light fireworks.
[00:14:55.560 --> 00:14:57.560]   Yeah, that'll help with depression.
[00:14:57.560 --> 00:15:03.920]   Yeah, you know, I could play ping pong with him or her and a few other things, you know,
[00:15:03.920 --> 00:15:05.360]   play trains and stuff like that.
[00:15:05.360 --> 00:15:08.360]   So it's fun.
[00:15:08.360 --> 00:15:14.200]   I think that's one of the exciting things is it looks isolating when you look at it from
[00:15:14.200 --> 00:15:15.200]   the outside.
[00:15:15.200 --> 00:15:20.640]   But when you're actually wearing the headset and playing with somebody else over the internet,
[00:15:20.640 --> 00:15:27.040]   you know, in a virtual world, in a very immersive world, it's quite amazing to tell you the
[00:15:27.040 --> 00:15:28.040]   truth, you know?
[00:15:28.040 --> 00:15:29.040]   Well, that'll help.
[00:15:29.040 --> 00:15:31.960]   It's the word of mouth is strong.
[00:15:31.960 --> 00:15:37.840]   If people hear from people like you and me and others who have tried it or their friends
[00:15:37.840 --> 00:15:43.600]   who have tried it and they get a drum beat of, this is great, this is great, that's probably
[00:15:43.600 --> 00:15:44.600]   good enough, right?
[00:15:44.600 --> 00:15:46.720]   Word of mouth is what will drive something like this.
[00:15:46.720 --> 00:15:47.720]   It helps.
[00:15:47.720 --> 00:15:52.080]   But you know, I can, I can yell and scream until I'm blue in the face.
[00:15:52.080 --> 00:15:53.080]   But you like everything.
[00:15:53.080 --> 00:15:54.080]   So that doesn't.
[00:15:54.080 --> 00:15:55.080]   Yeah, I know.
[00:15:55.080 --> 00:15:56.800]   But there's just thought of a business.
[00:15:56.800 --> 00:15:57.800]   Yeah.
[00:15:57.800 --> 00:16:01.480]   Remember back in the day when we had to go to cyber cafes?
[00:16:01.480 --> 00:16:02.480]   Hmm.
[00:16:02.480 --> 00:16:04.600]   I think there's a business in your cafes.
[00:16:04.600 --> 00:16:06.080]   I agree.
[00:16:06.080 --> 00:16:08.280]   There's people there's investors investing in them.
[00:16:08.280 --> 00:16:13.320]   And in fact, there's an entire theme park in Salt Lake City called the void, which everybody's
[00:16:13.320 --> 00:16:17.960]   raving about that gets to go and see it or if you saw it at Ted, they brought a small
[00:16:17.960 --> 00:16:19.960]   version of it to Ted.
[00:16:19.960 --> 00:16:24.640]   And everybody who's gotten that says it's absolutely amazing.
[00:16:24.640 --> 00:16:30.040]   Well, that's, we were thinking, you know, the last time we built an ultimate gaming machine,
[00:16:30.040 --> 00:16:31.920]   we gave it away, we had a contest.
[00:16:31.920 --> 00:16:33.680]   And I first thought we would do that with this.
[00:16:33.680 --> 00:16:38.520]   Then I realized, no, what we want to do is keep it here on set and have people try it.
[00:16:38.520 --> 00:16:39.520]   Yeah.
[00:16:39.520 --> 00:16:43.840]   And so our studio will be able to, you know, after the show or during a show, try it.
[00:16:43.840 --> 00:16:47.880]   We'll have two Oculus Rift and a Vive once the Vive comes.
[00:16:47.880 --> 00:16:50.840]   So I think this, you know, that's, I think that's a good idea.
[00:16:50.840 --> 00:16:51.840]   Yeah.
[00:16:51.840 --> 00:16:54.520]   So people get a chance and I'm sure that they'll be putting these in stores and people get
[00:16:54.520 --> 00:16:55.520]   it.
[00:16:55.520 --> 00:16:56.520]   We'll have the school.
[00:16:56.520 --> 00:16:57.520]   We'll have it our journalism schools.
[00:16:57.520 --> 00:16:58.520]   We're trying to get the students to play with this.
[00:16:58.520 --> 00:17:05.040]   I just, I just finally broke down and bought my theta, you know, always that great.
[00:17:05.040 --> 00:17:06.040]   That's a 3D camera.
[00:17:06.040 --> 00:17:07.040]   Yeah.
[00:17:07.040 --> 00:17:08.040]   Yeah, cool.
[00:17:08.040 --> 00:17:11.520]   What about, what was I going to ask you?
[00:17:11.520 --> 00:17:12.520]   Shoot.
[00:17:12.520 --> 00:17:13.520]   Age.
[00:17:13.520 --> 00:17:15.520]   Yes, it's good for all.
[00:17:15.520 --> 00:17:17.520]   Oh, yeah, I was over all people.
[00:17:17.520 --> 00:17:19.520]   Where am I?
[00:17:19.520 --> 00:17:26.120]   Why don't you each think of the Microsoft, uh, holo, you know, they keep dragging this
[00:17:26.120 --> 00:17:28.720]   demo out.
[00:17:28.720 --> 00:17:32.480]   And it's really a shame because everybody who's used the HoloLens says, well, that's
[00:17:32.480 --> 00:17:35.400]   not anything like the HoloLens experience.
[00:17:35.400 --> 00:17:36.400]   Really?
[00:17:36.400 --> 00:17:42.800]   What you're seeing is a full screen where, you know, it looks like this guy's seeing
[00:17:42.800 --> 00:17:44.880]   a world around him with things, objects.
[00:17:44.880 --> 00:17:49.440]   Here's a, this is a, uh, a medical, uh, uh, application.
[00:17:49.440 --> 00:17:51.200]   Oh, all he's seen is the ad element.
[00:17:51.200 --> 00:17:52.800]   That's not what he's seeing.
[00:17:52.800 --> 00:17:56.520]   He's seeing a little letter boxes as if you're looking through a mail slot.
[00:17:56.520 --> 00:17:57.520]   Yeah.
[00:17:57.520 --> 00:18:00.480]   Now, all that stuff's there, but you have to do that.
[00:18:00.480 --> 00:18:02.760]   Keep in mind you just switched context.
[00:18:02.760 --> 00:18:04.000]   We were talking about virtually.
[00:18:04.000 --> 00:18:05.560]   Now this is augment and I understand.
[00:18:05.560 --> 00:18:09.600]   Now, I know it's just an augmented reality, which you should explain.
[00:18:09.600 --> 00:18:15.080]   You're looking through an optic and seeing virtual items laid on top of the real world.
[00:18:15.080 --> 00:18:21.200]   And what Microsoft is trying is very hard because you have to render around a real world.
[00:18:21.200 --> 00:18:25.920]   And their headset, unlike the Oculus, the Vive and everything else is standalone.
[00:18:25.920 --> 00:18:26.920]   Yeah.
[00:18:26.920 --> 00:18:30.240]   Well, gear VR standalone, but you know, you have to have a powerful phone building.
[00:18:30.240 --> 00:18:33.280]   This thing is it's a PC in the little headset.
[00:18:33.280 --> 00:18:35.640]   And of course, they've said we could do a better job.
[00:18:35.640 --> 00:18:39.200]   We could have a bigger field of view, but, but that would be cost prohibitive and battery
[00:18:39.200 --> 00:18:40.200]   prohibitive.
[00:18:40.200 --> 00:18:41.200]   Yeah.
[00:18:41.200 --> 00:18:43.400]   And, and the hollow lens is about $3,000.
[00:18:43.400 --> 00:18:50.040]   There's four little cameras around the headset that map the world in, in, uh, three dimensions.
[00:18:50.040 --> 00:18:53.960]   It builds a point cloud, um, of the world.
[00:18:53.960 --> 00:18:57.320]   So it can lay virtual things on top of the real world.
[00:18:57.320 --> 00:18:59.600]   It's really pretty amazing technology.
[00:18:59.600 --> 00:19:00.600]   And it won't be alone.
[00:19:00.600 --> 00:19:05.120]   And I know of, uh, I think nine different headsets being developed that will compete
[00:19:05.120 --> 00:19:07.760]   with the headset with the hollow lens.
[00:19:07.760 --> 00:19:10.080]   Uh, magic leap is the most famous one.
[00:19:10.080 --> 00:19:14.600]   They got $1.3 billion of investment so far without shipping a product and without having
[00:19:14.600 --> 00:19:16.600]   a customer think about that one.
[00:19:16.600 --> 00:19:21.880]   I know there are two different things obviously, um, but they're, they feel related.
[00:19:21.880 --> 00:19:22.880]   Yeah.
[00:19:22.880 --> 00:19:25.320]   The reason the reason we have the same time VR and AR.
[00:19:25.320 --> 00:19:26.320]   Yeah.
[00:19:26.320 --> 00:19:29.040]   The reason we're going to have the same time is, is gaming got it.
[00:19:29.040 --> 00:19:30.040]   Killer app, right?
[00:19:30.040 --> 00:19:32.120]   What other killer apps?
[00:19:32.120 --> 00:19:39.400]   I mean, does this conference scene in, in AR mean you're going to enter into, um, well,
[00:19:39.400 --> 00:19:40.960]   that's one of the demos Microsoft did.
[00:19:40.960 --> 00:19:46.400]   They did a, uh, Skype, but again, all of these are, these are marketing videos that I think
[00:19:46.400 --> 00:19:47.880]   misrepresent the experience.
[00:19:47.880 --> 00:19:53.040]   If you show this, um, Jason, these are marketing videos that I think misrepresent the experience
[00:19:53.040 --> 00:19:57.520]   because here's somebody, you know, this is, this is kind of not what you were, you would
[00:19:57.520 --> 00:19:58.520]   experience.
[00:19:58.520 --> 00:20:01.320]   Now you, you get a view, a small view.
[00:20:01.320 --> 00:20:04.840]   This might, this is actually, that's more like it where you have Skype.
[00:20:04.840 --> 00:20:07.920]   You are seeing the rest of the room, but Skype's floating in the middle of the room.
[00:20:07.920 --> 00:20:13.800]   Keep in mind when, when consumers actually get AR, which is probably about three years
[00:20:13.800 --> 00:20:20.800]   away, we're going to get magically, um, which has a wider viewing angle and, and or meta,
[00:20:20.800 --> 00:20:22.360]   which has a wider viewing angle.
[00:20:22.360 --> 00:20:27.840]   Meta also sees 10 fingers, the HoloLens sees two fingers, um, and on and on.
[00:20:27.840 --> 00:20:30.560]   There's also a, there's a massive hype machine around this.
[00:20:30.560 --> 00:20:37.400]   I'm not, I'm not convinced frankly that this is going to, um, this is going to, uh, uh,
[00:20:37.400 --> 00:20:41.640]   magically, for instance, or doesn't, doesn't even have a technology really.
[00:20:41.640 --> 00:20:47.320]   They've put, like Microsoft's a lot of faked videos, um, meta too.
[00:20:47.320 --> 00:20:49.640]   So it's at least three years off.
[00:20:49.640 --> 00:20:54.280]   So really it's, it's going to be a, a, a VR world for the next few years.
[00:20:54.280 --> 00:20:57.800]   Um, but that's the question is, is, you know,
[00:20:57.800 --> 00:21:01.800]   what I know in the long run, this, these will probably be important technologies.
[00:21:01.800 --> 00:21:08.840]   They're not like 3D movies, which, which, which seemed quite gimmicky.
[00:21:08.840 --> 00:21:10.160]   Or is it?
[00:21:10.160 --> 00:21:16.280]   Uh, you know, when you get the, when I went to the Unity conference, I asked everybody,
[00:21:16.280 --> 00:21:18.080]   what should I see at the Unity conference?
[00:21:18.080 --> 00:21:21.160]   And everybody said the HoloLens demo was mind blowing.
[00:21:21.160 --> 00:21:27.440]   So even with a limited viewing angle, the demos that you get of things being laid
[00:21:27.440 --> 00:21:30.280]   on top of the real world is absolutely mind blowing.
[00:21:30.280 --> 00:21:34.720]   And when you get the meta demo, I mean, that thing just, uh,
[00:21:34.720 --> 00:21:36.800]   is there a real demo or are you just looking at it?
[00:21:36.800 --> 00:21:37.000]   Yeah.
[00:21:37.000 --> 00:21:39.080]   Oh, so there is a, they do have a product.
[00:21:39.080 --> 00:21:40.040]   Yes.
[00:21:40.040 --> 00:21:42.720]   Well, or whatever, they have a prototype I should say.
[00:21:42.720 --> 00:21:43.840]   Uh, no, they have a product.
[00:21:43.840 --> 00:21:44.520]   You can buy it.
[00:21:44.520 --> 00:21:49.120]   It's, uh, less than $1,000 for the new, uh, Leo, Leo.
[00:21:49.120 --> 00:21:49.720]   I'm buying one.
[00:21:49.720 --> 00:21:51.200]   If I can buy one, I didn't know they were.
[00:21:51.200 --> 00:21:52.280]   Keep in mind it's tethered.
[00:21:52.280 --> 00:21:54.080]   The, the meta one is tethered.
[00:21:54.080 --> 00:21:55.120]   I don't mind tethered.
[00:21:55.120 --> 00:21:56.840]   I think tethered, tethered makes sense.
[00:21:56.840 --> 00:22:00.320]   And keep in mind, there's no software unless you're going to look at CAD files.
[00:22:00.320 --> 00:22:07.320]   If you're a design, if you go to work for Caterpillar, they're using it to overlay, uh,
[00:22:07.320 --> 00:22:10.160]   training data on top of a tractor, right?
[00:22:10.160 --> 00:22:12.680]   So you look at the tractor and it tells you how to fix the tractor.
[00:22:12.680 --> 00:22:13.880]   That's cool.
[00:22:13.880 --> 00:22:17.720]   But it's not yet to the place where a consumer can walk around a street and
[00:22:17.720 --> 00:22:18.840]   see stuff on the street.
[00:22:18.840 --> 00:22:21.240]   And that's, that's the promise.
[00:22:21.240 --> 00:22:26.360]   When it gets to the consumer, then on end, but we're three years from now.
[00:22:26.400 --> 00:22:27.960]   Here's Robert Scoble reacting.
[00:22:27.960 --> 00:22:33.320]   I met it's mind blowing.
[00:22:33.320 --> 00:22:37.760]   I mean, and everybody says the magic leap is even more mind blowing than the meta.
[00:22:37.760 --> 00:22:40.240]   So I'm not buying anything from a guy named Travis Gigi.
[00:22:40.240 --> 00:22:41.840]   Do I have to buy it from Travis Gigi?
[00:22:41.840 --> 00:22:43.160]   I'm sorry.
[00:22:43.160 --> 00:22:45.920]   I shouldn't want to know what that's not him hitting the keyboard.
[00:22:45.920 --> 00:22:48.760]   No, that's something else going on.
[00:22:48.760 --> 00:22:51.480]   Um, so, okay, good.
[00:22:51.480 --> 00:22:54.600]   I didn't, okay, this was a Kickstarter, uh, 949.
[00:22:54.600 --> 00:22:56.040]   You can preorder it now.
[00:22:56.520 --> 00:22:57.840]   I don't know when you'd get it.
[00:22:57.840 --> 00:22:59.520]   Uh, but I agree with you.
[00:22:59.520 --> 00:23:04.000]   I mean, if this, if this is real now in a tethered fashion, then we're not far off.
[00:23:04.000 --> 00:23:08.400]   Five years, 10 years at the outside where you, where people will be walking around with
[00:23:08.400 --> 00:23:12.280]   normal, glad what looks like normal glasses, kind of the Google glass idea,
[00:23:12.280 --> 00:23:14.840]   except that it will be augmented.
[00:23:14.840 --> 00:23:15.960]   That's going to be awesome.
[00:23:15.960 --> 00:23:18.280]   I prefer that to VR, frankly.
[00:23:18.280 --> 00:23:22.920]   Uh, and I don't think you have the same problem with VR.
[00:23:23.960 --> 00:23:26.160]   Uh, with AR that you have with VR of nausea and things like that,
[00:23:26.160 --> 00:23:28.160]   because you're grounded to an actual real world.
[00:23:28.160 --> 00:23:31.240]   Robert's working on his thing.
[00:23:31.240 --> 00:23:32.960]   No, it's our chance to talk.
[00:23:32.960 --> 00:23:33.520]   Okay.
[00:23:33.520 --> 00:23:34.120]   Sorry about that.
[00:23:34.120 --> 00:23:34.680]   Oh, damn it.
[00:23:34.680 --> 00:23:35.120]   He's back.
[00:23:35.120 --> 00:23:36.680]   Oh, no, still, still to one.
[00:23:36.680 --> 00:23:37.880]   Let's take a break.
[00:23:37.880 --> 00:23:42.520]   You're going to work with Robert and, uh, we're going to make it all work.
[00:23:42.520 --> 00:23:45.960]   And I'm going to talk about Atlassian.
[00:23:45.960 --> 00:23:50.400]   User 62 40, our chat room has the opposite point of view.
[00:23:50.400 --> 00:23:51.240]   It says never going to happen.
[00:23:51.240 --> 00:23:52.040]   I'm very cynical.
[00:23:52.440 --> 00:23:54.480]   And actually, I would, I think it's smart to be skeptical.
[00:23:54.480 --> 00:23:57.480]   I'm not, I'm not, I'm not immediately sold.
[00:23:57.480 --> 00:24:02.080]   And my experiences limited that they've been with the Oculus, uh, helmet.
[00:24:02.080 --> 00:24:07.160]   I was nauseous was awful enough to not say I'm not doing that again.
[00:24:07.160 --> 00:24:10.920]   And I have a gear VR and I've used it, but I, you don't want to spend more
[00:24:10.920 --> 00:24:12.320]   than 10 minutes at a time doing it.
[00:24:12.320 --> 00:24:14.480]   I mean, I've had that thing for well long.
[00:24:14.480 --> 00:24:16.040]   We had that Jason the year, right?
[00:24:16.040 --> 00:24:16.520]   Yeah.
[00:24:16.520 --> 00:24:16.840]   Over.
[00:24:16.840 --> 00:24:17.480]   Well, yeah.
[00:24:17.480 --> 00:24:21.480]   Six from, I mean, you've got the innovator edition from the note four, no,
[00:24:21.480 --> 00:24:25.120]   five, I mean, even before that, I don't find myself strapping it on.
[00:24:25.120 --> 00:24:25.560]   Do you?
[00:24:25.560 --> 00:24:27.720]   Well, I do.
[00:24:27.720 --> 00:24:30.360]   Let's move on quickly.
[00:24:30.360 --> 00:24:32.000]   I take, I take it with me.
[00:24:32.000 --> 00:24:32.400]   Do you wear it?
[00:24:32.400 --> 00:24:33.400]   You have it here.
[00:24:33.400 --> 00:24:33.720]   Yeah.
[00:24:33.720 --> 00:24:34.520]   You have it all the time.
[00:24:34.520 --> 00:24:34.760]   Yeah.
[00:24:34.760 --> 00:24:35.360]   I have it in my back.
[00:24:35.360 --> 00:24:36.000]   What do you do?
[00:24:36.000 --> 00:24:36.920]   Do you play games?
[00:24:36.920 --> 00:24:39.440]   Uh, games, the social, I do the social stuff.
[00:24:39.440 --> 00:24:40.320]   I watch Netflix.
[00:24:40.320 --> 00:24:41.160]   Um, what's that?
[00:24:41.160 --> 00:24:42.920]   I really don't understand at all.
[00:24:42.920 --> 00:24:43.880]   No, I don't either.
[00:24:43.880 --> 00:24:48.680]   Well, when you're, you know, you want to relax by yourself and put on a movie.
[00:24:48.680 --> 00:24:49.000]   Yeah.
[00:24:49.000 --> 00:24:49.640]   Exactly.
[00:24:49.640 --> 00:24:51.160]   I'll fall asleep inside of it.
[00:24:51.400 --> 00:24:52.520]   Well, and you can.
[00:24:52.520 --> 00:24:54.800]   And I do some of the game stuff.
[00:24:54.800 --> 00:24:56.040]   The social stuff is cool.
[00:24:56.040 --> 00:24:58.840]   I'm either boring Leo or he's finally passed.
[00:24:58.840 --> 00:25:04.040]   No, that's all I look like when I'm dead or wearing a gear VR.
[00:25:04.040 --> 00:25:07.760]   Well, I got another one in order for the, you know, for the S seven.
[00:25:07.760 --> 00:25:08.280]   For the S seven.
[00:25:08.280 --> 00:25:08.480]   Yeah.
[00:25:08.480 --> 00:25:09.600]   Oh, there we should.
[00:25:09.600 --> 00:25:13.920]   You should try to do a twit entirely with headsets.
[00:25:13.920 --> 00:25:18.280]   Well, yeah, yesterday, uh, we had the new Nokia.
[00:25:18.920 --> 00:25:23.720]   Oso, which is a $60,000 VR, you know, see VR immersive video.
[00:25:23.720 --> 00:25:24.680]   We got to make the distinction.
[00:25:24.680 --> 00:25:25.640]   Oh, man.
[00:25:25.640 --> 00:25:29.320]   And my video camera and, um, I don't know.
[00:25:29.320 --> 00:25:29.720]   It's nice.
[00:25:29.720 --> 00:25:33.880]   So we shot, we couldn't shoot much because I'll tell you why I say it.
[00:25:33.880 --> 00:25:36.440]   So we shot maybe like five minutes a couple of times.
[00:25:36.440 --> 00:25:37.520]   And we're going to put that on the feed.
[00:25:37.520 --> 00:25:43.440]   The reason we couldn't shoot much is it currently stitching it takes an hour
[00:25:43.440 --> 00:25:44.760]   for every minute of video.
[00:25:44.760 --> 00:25:45.480]   Yeah.
[00:25:45.480 --> 00:25:47.520]   No, no, no four hours.
[00:25:47.520 --> 00:25:48.880]   Yeah, it was four hours.
[00:25:48.880 --> 00:25:49.840]   Four hours for every minute.
[00:25:49.840 --> 00:25:50.960]   So we shot six minutes.
[00:25:50.960 --> 00:25:53.400]   It took all it took 24 hours to render it.
[00:25:53.400 --> 00:25:54.480]   Yeah.
[00:25:54.480 --> 00:25:56.320]   It's still rendering.
[00:25:56.320 --> 00:25:58.040]   It's still rendering.
[00:25:58.040 --> 00:26:01.200]   I'm sure it's still rendering because we did run 15 minute chunks.
[00:26:01.200 --> 00:26:03.880]   So I know it's not on the feed yet.
[00:26:03.880 --> 00:26:04.240]   Yeah.
[00:26:04.240 --> 00:26:07.720]   So, but, but, but it's just a matter of time.
[00:26:07.720 --> 00:26:11.240]   And you know, as we're designing Jeff, the new studio, we're absolutely
[00:26:11.240 --> 00:26:14.720]   thinking about a lot of lines, lines, sites all the way around.
[00:26:15.840 --> 00:26:21.640]   Because and future TV studios, which are currently designed for a small
[00:26:21.640 --> 00:26:25.320]   60 degree angle of beauty and the rest looks like crap.
[00:26:25.320 --> 00:26:27.080]   Right.
[00:26:27.080 --> 00:26:29.840]   I mean, the studio we did it, we were a CUNY, right?
[00:26:29.840 --> 00:26:33.760]   There's this little pool of light and then the rest of it is like junk.
[00:26:33.760 --> 00:26:38.800]   Cameras and camera operators and coats and stale cups of coffee.
[00:26:38.800 --> 00:26:42.480]   And that if 360, it's all in the shot.
[00:26:42.480 --> 00:26:43.320]   Everything's in the shot.
[00:26:43.560 --> 00:26:46.320]   And we have to think about that as we design our studio, our new studio,
[00:26:46.320 --> 00:26:50.800]   we kind of more hermetically sealed because the idea is everything in there is on camera.
[00:26:50.800 --> 00:26:52.440]   I got a question about the theta.
[00:26:52.440 --> 00:26:56.800]   Why did they put the button up here where your finger can't not be seen?
[00:26:56.800 --> 00:26:58.720]   Why didn't they put the button like that?
[00:26:58.720 --> 00:27:01.000]   You should have, but, but it, but it stitches you out.
[00:27:01.000 --> 00:27:01.440]   So doesn't.
[00:27:01.440 --> 00:27:02.280]   Yeah.
[00:27:02.280 --> 00:27:04.280]   Actually, you look at your images.
[00:27:04.280 --> 00:27:05.160]   You shouldn't see that.
[00:27:05.160 --> 00:27:06.120]   Oh, no, you see you.
[00:27:06.120 --> 00:27:07.040]   You'll see your hand.
[00:27:07.040 --> 00:27:08.200]   Now you will use your hand.
[00:27:08.200 --> 00:27:08.480]   Yeah.
[00:27:08.480 --> 00:27:09.840]   Um, use the remote app.
[00:27:09.840 --> 00:27:10.560]   That's what you should.
[00:27:10.560 --> 00:27:12.920]   I think that's what I don't know who knows what they were thinking, but
[00:27:12.920 --> 00:27:19.080]   that you can tie it to your phone, Jeff, and then I have to have a tripod.
[00:27:19.080 --> 00:27:21.200]   No, I like the idea of logging with it.
[00:27:21.200 --> 00:27:23.240]   That's what I did on the boat.
[00:27:23.240 --> 00:27:24.440]   Well, you just see my hand.
[00:27:24.440 --> 00:27:25.440]   You see your arm going.
[00:27:25.440 --> 00:27:26.920]   But that's part of it, though.
[00:27:26.920 --> 00:27:30.000]   That's part of the field is, you know, you know, that you're holding it out.
[00:27:30.000 --> 00:27:33.560]   But I gotta have my, I gotta worry about my thumbnail being clean.
[00:27:33.560 --> 00:27:35.120]   Well, you have to do a little bit of it.
[00:27:35.120 --> 00:27:36.280]   It is rather close.
[00:27:36.280 --> 00:27:38.280]   It's really right in there, isn't it?
[00:27:38.280 --> 00:27:38.720]   Right there.
[00:27:38.720 --> 00:27:40.720]   It feels like it's feels like it's in your nose.
[00:27:40.720 --> 00:27:41.640]   You know, it's right there.
[00:27:42.520 --> 00:27:43.400]   He's gone.
[00:27:43.400 --> 00:27:51.320]   I would have thought Robert Scobull of anyone would have had a really good
[00:27:51.320 --> 00:27:52.440]   USB headset.
[00:27:52.440 --> 00:27:53.840]   It's because of the Gilmore gang.
[00:27:53.840 --> 00:27:56.840]   Anybody who appears in the Gilmore gang has a different standard for audio.
[00:27:56.840 --> 00:27:57.560]   I love Steve.
[00:27:57.560 --> 00:28:01.120]   And we aired the show for a long time until Mike Harrington and I had our famous
[00:28:01.120 --> 00:28:09.840]   kerfuffle, but this, it's Steve's kind of almost his whole point of view is that
[00:28:09.840 --> 00:28:12.280]   it should just be kind of a haphazard.
[00:28:12.280 --> 00:28:14.320]   Yeah, a bunch of friends got together to chat.
[00:28:14.320 --> 00:28:15.000]   And I don't really.
[00:28:15.000 --> 00:28:17.680]   That's I have a different take on that.
[00:28:17.680 --> 00:28:17.960]   Yeah.
[00:28:17.960 --> 00:28:22.400]   We'd like to do it because I'm, I don't want to annoy people with bad audio.
[00:28:22.400 --> 00:28:22.960]   Yeah.
[00:28:22.960 --> 00:28:24.480]   Anyway, I was about to do an ad.
[00:28:24.480 --> 00:28:26.160]   So we're going to fix.
[00:28:26.160 --> 00:28:27.040]   We're going to fix Robert.
[00:28:27.040 --> 00:28:29.480]   About time somebody did.
[00:28:29.480 --> 00:28:33.040]   And then there he is.
[00:28:33.040 --> 00:28:33.520]   He's back.
[00:28:33.520 --> 00:28:36.880]   And then we'll come back with more.
[00:28:36.880 --> 00:28:38.960]   Robert Scobulls here, the Scobullizer.
[00:28:38.960 --> 00:28:41.520]   Do you still do the blog at Scobullizer.com?
[00:28:42.000 --> 00:28:43.240]   It's coming back in April.
[00:28:43.240 --> 00:28:43.800]   It should.
[00:28:43.800 --> 00:28:44.600]   I miss it.
[00:28:44.600 --> 00:28:47.240]   Uh, Facebook has taken over the world.
[00:28:47.240 --> 00:28:48.760]   But I like your blog post, man.
[00:28:48.760 --> 00:28:49.680]   All right.
[00:28:49.680 --> 00:28:51.080]   I have a new theory.
[00:28:51.080 --> 00:28:53.320]   Because I'm always, I don't sleep well.
[00:28:53.320 --> 00:28:55.720]   I'm up at four in the morning every every every night.
[00:28:55.720 --> 00:28:58.160]   The how the hour of the wolf.
[00:28:58.160 --> 00:29:02.000]   And I think I'm going to do an hour of the wolf blog post.
[00:29:02.000 --> 00:29:05.080]   I thought, well, why, why should I lie in bed looking at Instagram?
[00:29:05.080 --> 00:29:06.720]   I should just do a blog post at four in the morning.
[00:29:06.720 --> 00:29:09.720]   You could watch Netflix in VR.
[00:29:09.720 --> 00:29:11.080]   No, I'm going to blog.
[00:29:11.120 --> 00:29:12.000]   I want to do something.
[00:29:12.000 --> 00:29:15.600]   What I've actually been doing other stuff, you know, I've been like playing with
[00:29:15.600 --> 00:29:18.560]   Linux and things, but I want to I want to be if I'm going to be up for a couple
[00:29:18.560 --> 00:29:21.000]   hours, I should be productive and then I'll be dual sleep.
[00:29:21.000 --> 00:29:21.840]   That new thing.
[00:29:21.840 --> 00:29:23.360]   I think I think you should be doing a Facebook live.
[00:29:23.360 --> 00:29:25.880]   You don't want your PJs.
[00:29:25.880 --> 00:29:31.640]   Yeah, like, um, I just woke up and I came back to sleep.
[00:29:31.640 --> 00:29:35.520]   I think that we should try to use those extra hours and be more productive.
[00:29:35.520 --> 00:29:37.440]   I think that's what Hamilton would have done.
[00:29:37.440 --> 00:29:40.280]   Our show today brought to you by
[00:29:40.480 --> 00:29:45.280]   Atlassian talk about being more productive behind every great human achievement.
[00:29:45.280 --> 00:29:48.800]   You know, you look at something like Hamilton or a great piece of software.
[00:29:48.800 --> 00:29:53.800]   Sometimes the the oh tour seems to be the author, the creator.
[00:29:53.800 --> 00:29:55.400]   You go that Lin Manuel Miranda.
[00:29:55.400 --> 00:29:59.080]   That's his, but no, it's all done by a team.
[00:29:59.080 --> 00:30:03.720]   It's it's genome mapping, 3D printing space exploration.
[00:30:03.720 --> 00:30:04.480]   You don't do it alone.
[00:30:04.480 --> 00:30:07.240]   The greatest stuff is in collaboration.
[00:30:08.080 --> 00:30:13.760]   And if you're doing team productive team stuff, you got to use Atlassian.
[00:30:13.760 --> 00:30:15.200]   We used it when we did our website.
[00:30:15.200 --> 00:30:17.840]   And I have to say it was a hugely valuable tool.
[00:30:17.840 --> 00:30:22.160]   We use Jira to keep track of each of the user stories.
[00:30:22.160 --> 00:30:27.920]   And, you know, we divided the development into sprints and we had to divide each
[00:30:27.920 --> 00:30:32.240]   tab, each goal into a different task and man, Jira is so great at doing that.
[00:30:32.240 --> 00:30:34.080]   And you you move things along in the columns.
[00:30:34.080 --> 00:30:34.880]   You really keep track of it.
[00:30:34.880 --> 00:30:36.720]   You know, who's working on what and how they're doing.
[00:30:37.480 --> 00:30:42.240]   Our engineering team uses confluence to document equipment and work processes.
[00:30:42.240 --> 00:30:44.160]   So we know what we've gotten where it is.
[00:30:44.160 --> 00:30:46.360]   Let's see.
[00:30:46.360 --> 00:30:47.200]   Oh, hip chat.
[00:30:47.200 --> 00:30:52.200]   Come on, we use hip chat like crazy for planning events to working on serious
[00:30:52.200 --> 00:30:53.120]   operational issues.
[00:30:53.120 --> 00:30:57.800]   We have an ops hip chat that has all sorts of linked in software like Pan
[00:30:57.800 --> 00:31:00.880]   Opta and Redis and all of that.
[00:31:00.880 --> 00:31:02.400]   So we know exactly what's going on.
[00:31:02.400 --> 00:31:04.600]   We just started a new hip chat for the studio build.
[00:31:04.600 --> 00:31:07.640]   We said, look, you know, everybody's kind of piece milling it with email.
[00:31:07.640 --> 00:31:08.520]   This is no good.
[00:31:08.520 --> 00:31:12.400]   We need to all be in the same page because we've got so many people working
[00:31:12.400 --> 00:31:13.040]   in so many areas.
[00:31:13.040 --> 00:31:14.360]   So we created a hip chat room.
[00:31:14.360 --> 00:31:17.280]   And right now we're doing an idea book.
[00:31:17.280 --> 00:31:19.440]   So paste your ideas into the hip chat room.
[00:31:19.440 --> 00:31:20.160]   It's great.
[00:31:20.160 --> 00:31:23.400]   Hip chat's instant messaging, but it's video chat.
[00:31:23.400 --> 00:31:27.920]   It's it keeps a permanent record, but it's asynchronous so you can work
[00:31:27.920 --> 00:31:29.080]   whenever you need to.
[00:31:29.080 --> 00:31:32.680]   And then there's Bitbucket, which lets you test review and manage code in real
[00:31:32.680 --> 00:31:33.040]   time.
[00:31:33.040 --> 00:31:35.080]   I love Atlassian's tools.
[00:31:35.080 --> 00:31:40.280]   I was mentioning I read a great blog post from, I think, from the year 2000
[00:31:40.280 --> 00:31:44.920]   by Joel Spolsky, who's, you know, kind of a legend in, you know, program,
[00:31:44.920 --> 00:31:47.640]   programmer mentoring, coder mentoring and so forth.
[00:31:47.640 --> 00:31:50.560]   And he said, don't take a job unless they've got the best tool set.
[00:31:50.560 --> 00:31:53.000]   Said you're just asking for trouble.
[00:31:53.000 --> 00:31:54.960]   Judge a workplace by its tool set.
[00:31:54.960 --> 00:31:57.200]   Judge it by Atlassian the best.
[00:31:57.200 --> 00:31:58.080]   We love them.
[00:31:58.080 --> 00:31:58.840]   You'll love it too.
[00:31:58.840 --> 00:32:01.560]   If you're in a team, if you're working on a team, if you're planning a project,
[00:32:01.560 --> 00:32:06.920]   go to Atlassian at LASSIAN.com to learn more and see how JIRA and
[00:32:06.920 --> 00:32:10.800]   confluence and hip chat and Bitbucket will give your team everything you need to
[00:32:10.800 --> 00:32:16.520]   organize to discuss to complete shared work at lassian.com.
[00:32:16.520 --> 00:32:20.320]   Unleash the potential in your team and build what's next.
[00:32:20.320 --> 00:32:26.760]   We are talking Twig, Robert Scobel, the scobelizer is here off to a new job.
[00:32:26.760 --> 00:32:27.720]   But what is it?
[00:32:27.720 --> 00:32:29.320]   Upload VR soon?
[00:32:29.320 --> 00:32:30.000]   Yep.
[00:32:30.960 --> 00:32:35.960]   Um, happy, happy to be, um, departing Rackspace or sad?
[00:32:35.960 --> 00:32:37.440]   Uh, both.
[00:32:37.440 --> 00:32:38.400]   Yeah.
[00:32:38.400 --> 00:32:42.840]   You know, after seven years, it's fun to go do something new, but it was a good
[00:32:42.840 --> 00:32:43.120]   ride.
[00:32:43.120 --> 00:32:44.640]   It was a great, it's a great company.
[00:32:44.640 --> 00:32:45.080]   I love it.
[00:32:45.080 --> 00:32:49.520]   Uh, I remember interviewing Maurice Sendak, the great children's author.
[00:32:49.520 --> 00:32:51.120]   And he had left writing children's books.
[00:32:51.120 --> 00:32:51.560]   I said, why?
[00:32:51.560 --> 00:32:53.640]   He said, well, you got every 10 years, you got to do something else.
[00:32:53.640 --> 00:32:57.080]   He was designing opera sets every 10 years.
[00:32:57.080 --> 00:32:59.440]   So you're, you're a little ahead of it, but that's what's Robert.
[00:32:59.440 --> 00:33:00.240]   It's seven.
[00:33:00.360 --> 00:33:01.880]   You're a head of the, I'm due.
[00:33:01.880 --> 00:33:03.880]   I know.
[00:33:03.880 --> 00:33:04.200]   Come on.
[00:33:04.200 --> 00:33:08.400]   You got a cush gig, professor, nothing better than being a professor.
[00:33:08.400 --> 00:33:08.880]   I'll tell you.
[00:33:08.880 --> 00:33:11.720]   Uh, you have to learn something new, right?
[00:33:11.720 --> 00:33:12.640]   Yeah, Jeff Jarvis.
[00:33:12.640 --> 00:33:16.800]   And but you get to get to stay fresh because you have a new bunch of kids every
[00:33:16.800 --> 00:33:17.200]   year, right?
[00:33:17.200 --> 00:33:19.680]   Another great one.
[00:33:19.680 --> 00:33:23.080]   And right now, when the my season of doing my, what I call my board meetings
[00:33:23.080 --> 00:33:24.920]   for their businesses, so I have 20 businesses to go.
[00:33:24.920 --> 00:33:25.440]   Oh, how fun.
[00:33:25.440 --> 00:33:25.720]   Great.
[00:33:25.720 --> 00:33:26.120]   What's that?
[00:33:26.120 --> 00:33:26.640]   So it's fun.
[00:33:26.640 --> 00:33:27.800]   That's a good way to stay fresh.
[00:33:27.800 --> 00:33:30.120]   I like what I do because I was thinking about it the other day.
[00:33:30.120 --> 00:33:34.960]   I mean, if you work in media to have your own thing is always the goal.
[00:33:34.960 --> 00:33:38.320]   Everybody I worked with in radio always said someday I'll own a radio station.
[00:33:38.320 --> 00:33:43.960]   Uh, and but now I more than that, I own them, you know, my own, I can do whatever
[00:33:43.960 --> 00:33:44.360]   I want.
[00:33:44.360 --> 00:33:47.480]   And I really love that studio empire.
[00:33:47.480 --> 00:33:50.440]   But five years in, we're building a new studio.
[00:33:50.440 --> 00:33:52.520]   So I guess, you know, you got to get a move on.
[00:33:52.520 --> 00:33:54.120]   I'm you are.
[00:33:54.120 --> 00:33:55.120]   I keep how much?
[00:33:55.120 --> 00:33:55.840]   Oh, yes.
[00:33:55.840 --> 00:33:56.880]   Hardware.
[00:33:56.880 --> 00:33:59.880]   Are you going to be able to transport all your basic?
[00:34:00.120 --> 00:34:01.000]   Or a new studio.
[00:34:01.000 --> 00:34:04.520]   We marked it on the basement is roughly the size of this.
[00:34:04.520 --> 00:34:08.200]   Oh, some of this, we're going to read jigger a little bit.
[00:34:08.200 --> 00:34:10.040]   It's a little, a little bit smaller.
[00:34:10.040 --> 00:34:14.400]   The biggest difference and it's sad to me, but what I, what I loved about this
[00:34:14.400 --> 00:34:17.240]   space is it's a storefront and we always wanted to have a storefront.
[00:34:17.240 --> 00:34:17.880]   Yeah.
[00:34:17.880 --> 00:34:19.280]   So people could walk by and look in.
[00:34:19.280 --> 00:34:21.440]   That didn't really work out because of all the sunlight.
[00:34:21.440 --> 00:34:25.520]   We had to really treat the windows so you couldn't can't really look in.
[00:34:25.520 --> 00:34:29.840]   Um, but we can look out and I love it.
[00:34:29.840 --> 00:34:32.920]   That you know, you look, I mean, that's not fake, you know, in real, like, if you
[00:34:32.920 --> 00:34:37.000]   look at CBS this morning, they have a door, but it's really just to a blue light
[00:34:37.000 --> 00:34:40.440]   in the back, you know, but so we don't have that.
[00:34:40.440 --> 00:34:42.600]   We don't, we won't have the luxury of having windows.
[00:34:42.600 --> 00:34:45.760]   It's luxury and it's also a challenge because real light is very hard to deal
[00:34:45.760 --> 00:34:46.000]   with it.
[00:34:46.000 --> 00:34:46.480]   Different time.
[00:34:46.480 --> 00:34:48.880]   What about having the, the workspaces in the studio?
[00:34:48.880 --> 00:34:49.600]   Are you still going to do that?
[00:34:49.600 --> 00:34:51.680]   No, that's the other thing.
[00:34:51.680 --> 00:34:56.720]   I was told in no uncertain terms, nobody can get work done because I, I was
[00:34:56.720 --> 00:34:57.480]   following Moses.
[00:34:57.480 --> 00:34:58.680]   We always bring him up.
[00:34:58.680 --> 00:34:59.800]   We invoke the name of Moses.
[00:34:59.800 --> 00:35:00.040]   Right.
[00:35:00.040 --> 00:35:01.480]   Well, we talked about it at CUNY.
[00:35:01.480 --> 00:35:02.280]   That's why I'm asking.
[00:35:02.280 --> 00:35:06.280]   He invented the, the Open Studio and it was brilliant.
[00:35:06.280 --> 00:35:09.640]   CNN's still doing it, but you know, even CNN, they, it's faked now.
[00:35:09.640 --> 00:35:09.920]   Right.
[00:35:09.920 --> 00:35:14.800]   So what, what it turns out is you really can't have real work done while we're
[00:35:14.800 --> 00:35:18.760]   on the air over there, so people have to be quiet.
[00:35:18.760 --> 00:35:22.480]   They can't make phone calls and it's, it's been wearing on them.
[00:35:22.480 --> 00:35:24.840]   So that militates against us having the studio.
[00:35:24.840 --> 00:35:26.040]   So what, in the news?
[00:35:26.240 --> 00:35:28.640]   No, because you're not going to be there 24/7.
[00:35:28.640 --> 00:35:29.760]   I see.
[00:35:29.760 --> 00:35:32.920]   You're doing one show a week for, they can be quiet for one hour a week.
[00:35:32.920 --> 00:35:37.280]   Two hours a week, but we're in here all the time.
[00:35:37.280 --> 00:35:39.240]   So it's really, there's, there's no time.
[00:35:39.240 --> 00:35:41.400]   It's hard for them to get, get any work done.
[00:35:41.400 --> 00:35:42.880]   I like the Open plan.
[00:35:42.880 --> 00:35:44.400]   This is a 360 studio.
[00:35:44.400 --> 00:35:45.480]   Just for the sake of it.
[00:35:45.480 --> 00:35:49.040]   Can you ask everybody who's in the studio, just trying to do their job to stand up
[00:35:49.040 --> 00:35:49.920]   and yell for a second?
[00:35:49.920 --> 00:35:50.960]   No way.
[00:35:50.960 --> 00:35:52.000]   The sense of the humanity.
[00:35:52.000 --> 00:35:53.960]   Everybody stand up and yell.
[00:35:56.120 --> 00:35:57.120]   They're prisoners.
[00:35:57.120 --> 00:35:58.120]   Let them out.
[00:35:58.120 --> 00:35:59.120]   I like it.
[00:35:59.120 --> 00:36:01.120]   But I'm the only one.
[00:36:01.120 --> 00:36:05.120]   I even say, I tell Lisa, no, you can make noise.
[00:36:05.120 --> 00:36:06.120]   You don't have to not talk.
[00:36:06.120 --> 00:36:08.120]   But some of the other hosts is hard for them to concentrate.
[00:36:08.120 --> 00:36:12.120]   When I worked with the Chicago Tribune, low many, many years ago, there was a two-story
[00:36:12.120 --> 00:36:16.120]   newsroom and there was a gallery that went by and, and, and tourists would come and take
[00:36:16.120 --> 00:36:19.120]   tourists, look out, oh, that's what a journalist looks like, right?
[00:36:19.120 --> 00:36:23.120]   And there was a guy named Pete Beers on the copy desk and he made a huge deal with the
[00:36:23.120 --> 00:36:24.120]   whole tall sign.
[00:36:24.120 --> 00:36:28.120]   He went, when the group would come through, he would hold it up and he would say, help,
[00:36:28.120 --> 00:36:29.120]   we're not the real editor.
[00:36:29.120 --> 00:36:31.120]   We're prisoners, call the authority.
[00:36:31.120 --> 00:36:34.120]   And people, you see that anybody ever call?
[00:36:34.120 --> 00:36:35.120]   They start laughing.
[00:36:35.120 --> 00:36:39.120]   Well, he held it up once when the board of directors came by.
[00:36:39.120 --> 00:36:42.120]   That was the last time that that sign was soon destroyed.
[00:36:42.120 --> 00:36:43.120]   Yeah.
[00:36:43.120 --> 00:36:44.120]   Yeah.
[00:36:44.120 --> 00:36:45.120]   I think your holding prisoner is there.
[00:36:45.120 --> 00:36:46.120]   Yeah.
[00:36:46.120 --> 00:36:49.120]   Well, and if you watch now, I think it's a good thing.
[00:36:49.120 --> 00:36:54.120]   I think Peter is there.
[00:36:54.120 --> 00:36:55.120]   Yeah.
[00:36:55.120 --> 00:37:02.120]   Well, and if you watch now, I'm going, I'm going to ABC where Peter Jennings did the news and
[00:37:02.120 --> 00:37:05.120]   it looks like an open newsroom, but it's not.
[00:37:05.120 --> 00:37:09.120]   I mean, it has all the, the attributes and stuff, but he's actually pushed up against a wall and
[00:37:09.120 --> 00:37:14.120]   everything, and everything else is fake and, I mean, or he was, and it was interns.
[00:37:14.120 --> 00:37:18.120]   So they'd solve fake now, but, because it's not, I guess it's not practical.
[00:37:18.120 --> 00:37:23.120]   We're going to have, it'll be sealed kind of, you know, there's a wall for sound and all
[00:37:23.120 --> 00:37:24.120]   of that.
[00:37:24.120 --> 00:37:25.120]   But that's all right.
[00:37:25.120 --> 00:37:28.120]   You know, the truth is most about a single story.
[00:37:28.120 --> 00:37:30.120]   Yeah, we did VR.
[00:37:30.120 --> 00:37:31.120]   Okay, we did.
[00:37:31.120 --> 00:37:34.120]   Let's talk about how much Sundar Pichai made.
[00:37:34.120 --> 00:37:40.120]   Well, I did you read the interview that Matt Honan did on BuzzFeed with Sundar Pichai.
[00:37:40.120 --> 00:37:41.120]   What do you think?
[00:37:41.120 --> 00:37:43.120]   I thought it was interesting.
[00:37:43.120 --> 00:37:45.120]   He interviewed him at CES.
[00:37:45.120 --> 00:37:49.120]   And here it is, the end of March and it finally came out.
[00:37:49.120 --> 00:37:50.120]   Yeah.
[00:37:50.120 --> 00:37:55.120]   Which tells me that it was more about the story.
[00:37:55.120 --> 00:37:59.120]   There's a lot of pros in it than it is about the actual interview.
[00:37:59.120 --> 00:38:00.120]   True.
[00:38:00.120 --> 00:38:01.120]   I feel like he-
[00:38:01.120 --> 00:38:01.120]   I feel like he-
[00:38:01.120 --> 00:38:03.120]   Sundar is a fascinating guy to me.
[00:38:03.120 --> 00:38:04.120]   I admire him immensely.
[00:38:04.120 --> 00:38:06.120]   Yeah, I do too.
[00:38:06.120 --> 00:38:11.120]   What do we learn from searching for Sundar Pichai in BuzzFeed?
[00:38:11.120 --> 00:38:13.120]   I forget I read it days ago.
[00:38:13.120 --> 00:38:15.120]   I can tell you, you learn nothing.
[00:38:15.120 --> 00:38:16.120]   You know why?
[00:38:16.120 --> 00:38:18.120]   Because he's- no CEO is going to ever tell you anything.
[00:38:18.120 --> 00:38:19.120]   Right, Robert?
[00:38:19.120 --> 00:38:20.120]   True.
[00:38:20.120 --> 00:38:22.120]   Because they're-
[00:38:22.120 --> 00:38:24.120]   Unless you get them before they're famous.
[00:38:24.120 --> 00:38:25.120]   Right.
[00:38:25.120 --> 00:38:28.120]   Like, well, that's why you're so smart because you would have your startups.
[00:38:28.120 --> 00:38:33.120]   They are anxious to have their story told and they don't yet have PR people sitting behind
[00:38:33.120 --> 00:38:34.120]   them singing.
[00:38:34.120 --> 00:38:35.120]   Can't say that.
[00:38:35.120 --> 00:38:36.120]   Yeah.
[00:38:36.120 --> 00:38:41.120]   Even if they do, the PR people are usually pretty nice because they know that-
[00:38:41.120 --> 00:38:42.120]   They need the coverage.
[00:38:42.120 --> 00:38:43.120]   That's good.
[00:38:43.120 --> 00:38:44.120]   Yeah.
[00:38:44.120 --> 00:38:45.120]   Yeah.
[00:38:45.120 --> 00:38:47.120]   Like Mark right now can't even talk to me.
[00:38:47.120 --> 00:38:49.120]   And he told me why.
[00:38:49.120 --> 00:38:54.120]   He said, you know, if I give you an exclusive, I'll have 600 people calling my PR department
[00:38:54.120 --> 00:38:58.120]   saying, why did you give it exclusive to this Facebook guy?
[00:38:58.120 --> 00:39:03.120]   I remember you sitting down with Mark after- before an F8 or after an F8 and just like chatting.
[00:39:03.120 --> 00:39:04.120]   Yeah.
[00:39:04.120 --> 00:39:07.120]   I guess that's too bad that that's gone.
[00:39:07.120 --> 00:39:09.120]   That's hard to do, you know?
[00:39:09.120 --> 00:39:15.120]   I once had a Comdex was offered an interview with Bill Gates and I said, oh, great.
[00:39:15.120 --> 00:39:19.120]   I'd love what loved this was when Microsoft, this was like mid 90s when Microsoft was a
[00:39:19.120 --> 00:39:20.120]   it's a sentencing.
[00:39:20.120 --> 00:39:22.120]   And they said, okay, well, submit your questions.
[00:39:22.120 --> 00:39:23.120]   We'll review them.
[00:39:23.120 --> 00:39:26.120]   We may supply you with a few that you could ask.
[00:39:26.120 --> 00:39:27.120]   Yeah.
[00:39:27.120 --> 00:39:30.120]   And I said, well, I guess I won't be a Bill Gates then.
[00:39:30.120 --> 00:39:31.120]   Yeah.
[00:39:31.120 --> 00:39:32.120]   No journal, right?
[00:39:32.120 --> 00:39:33.120]   Jeff?
[00:39:33.120 --> 00:39:34.120]   No, no, no, no.
[00:39:34.120 --> 00:39:35.120]   Oh, no.
[00:39:35.120 --> 00:39:38.120]   I always say, I know one question.
[00:39:38.120 --> 00:39:39.120]   Who are you?
[00:39:39.120 --> 00:39:40.120]   That's about it.
[00:39:40.120 --> 00:39:41.120]   Yeah.
[00:39:41.120 --> 00:39:42.120]   That's it.
[00:39:42.120 --> 00:39:43.120]   And then let him talk, right?
[00:39:43.120 --> 00:39:45.120]   Yeah, that's how I start the interview.
[00:39:45.120 --> 00:39:47.120]   But Chai talked about India, which is great.
[00:39:47.120 --> 00:39:52.120]   I mean, I think that that's, as we said, one of the best lines in Hamilton is immigrants
[00:39:52.120 --> 00:39:58.720]   that get the job done, especially now when there's, you know, so much talk about how immigrants
[00:39:58.720 --> 00:40:02.440]   are bad for America, even though most of the people doing the talk and come from families
[00:40:02.440 --> 00:40:08.240]   that have created to America, he says a new India is emerging.
[00:40:08.240 --> 00:40:13.480]   He says there are 700 universities across the country who will create a new India out
[00:40:13.480 --> 00:40:16.920]   of this oldest civilization.
[00:40:16.920 --> 00:40:19.840]   Sundar Pachai, you know, is a poster.
[00:40:19.840 --> 00:40:25.520]   It has his Satya Nadella, a poster boy for immigrants.
[00:40:25.520 --> 00:40:29.360]   They do get the job done, it turns out.
[00:40:29.360 --> 00:40:36.200]   And I really understand, especially when you see the H-1B visas misused by companies like
[00:40:36.200 --> 00:40:44.560]   Disney who fire completely competent American employees and replace them with H-1B visa
[00:40:44.560 --> 00:40:49.480]   employees who are employed not by Disney, but by contractors.
[00:40:49.480 --> 00:40:53.200]   And then the Americans are told, "Oh, you teach this guy your job and then we're going
[00:40:53.200 --> 00:40:55.280]   to fire you."
[00:40:55.280 --> 00:40:56.280]   That's different.
[00:40:56.280 --> 00:41:01.000]   And I can understand why people are upset about that.
[00:41:01.000 --> 00:41:06.040]   But there's plenty of work to go around here.
[00:41:06.040 --> 00:41:11.240]   Pachai lives in a modest home, five bedroom house in Los Altos Hills, which isn't so modest.
[00:41:11.240 --> 00:41:13.400]   That's a nice, yeah, right?
[00:41:13.400 --> 00:41:15.080]   Yeah, you're from San Jose.
[00:41:15.080 --> 00:41:18.520]   That's a $3 million neighborhood at minimum.
[00:41:18.520 --> 00:41:19.520]   Modest, yeah.
[00:41:19.520 --> 00:41:22.480]   Well, by the standards of that ridiculous area now, yeah.
[00:41:22.480 --> 00:41:23.480]   Yeah.
[00:41:23.480 --> 00:41:24.480]   Yeah.
[00:41:24.480 --> 00:41:27.880]   And he falls alone, oh, and he has a tennis court.
[00:41:27.880 --> 00:41:28.880]   Okay.
[00:41:28.880 --> 00:41:29.880]   Yeah.
[00:41:29.880 --> 00:41:30.880]   Okay.
[00:41:30.880 --> 00:41:31.880]   But...
[00:41:31.880 --> 00:41:32.880]   But...
[00:41:32.880 --> 00:41:36.200]   Maybe compared to somebody who's making a hundred million a year, sure.
[00:41:36.200 --> 00:41:37.200]   Yeah.
[00:41:37.200 --> 00:41:38.880]   Well, that's how this story started.
[00:41:38.880 --> 00:41:45.520]   So his salary fairly modest, $652,000.
[00:41:45.520 --> 00:41:50.280]   For the CEO of one of the biggest companies, actually the biggest company trading off and
[00:41:50.280 --> 00:41:54.000]   on with Apple in the world, $652,000.
[00:41:54.000 --> 00:42:01.400]   That's not riches, but he got $100 million in restricted stock that bests fully next
[00:42:01.400 --> 00:42:02.400]   year.
[00:42:02.400 --> 00:42:03.400]   So...
[00:42:03.400 --> 00:42:04.400]   Yeah.
[00:42:04.400 --> 00:42:05.400]   That's okay.
[00:42:05.400 --> 00:42:07.640]   That's nice work if you can get it.
[00:42:07.640 --> 00:42:10.480]   Maybe he can buy a bigger house apparently.
[00:42:10.480 --> 00:42:14.720]   Just according to Matt, just inside the front door of his house, there's a rectangular grid
[00:42:14.720 --> 00:42:18.800]   of colored tape taped off.
[00:42:18.800 --> 00:42:25.200]   For his nine-year-old son, and he plays soccer.
[00:42:25.200 --> 00:42:28.560]   I like that.
[00:42:28.560 --> 00:42:30.200]   It's these kind of personal details.
[00:42:30.200 --> 00:42:32.960]   This is the kind of the vanity fair style interview.
[00:42:32.960 --> 00:42:35.480]   I don't know.
[00:42:35.480 --> 00:42:38.640]   One former Google manager who worked with Pichai.
[00:42:38.640 --> 00:42:42.560]   And I think that this is my experience, but I'll be interested in what you think.
[00:42:42.560 --> 00:42:47.040]   Describe him as a political operative who could work a room and navigate shifting alliances
[00:42:47.040 --> 00:42:48.280]   in the company.
[00:42:48.280 --> 00:42:51.400]   He gave the best meetings, says the former Googler.
[00:42:51.400 --> 00:42:55.320]   He never aligned with Susan or Marissa O'Mee to even Eric.
[00:42:55.320 --> 00:42:59.400]   He always shot right down the middle.
[00:42:59.400 --> 00:43:01.480]   I keep hearing that he's a peacemaker.
[00:43:01.480 --> 00:43:02.480]   Yes.
[00:43:02.480 --> 00:43:06.520]   You know, that he doesn't pick people against each other, that it's a pleasant or pleasant
[00:43:06.520 --> 00:43:07.520]   work.
[00:43:07.520 --> 00:43:12.120]   Although, again, to quote Hamilton, "If you stand for nothing, what will you fall for?"
[00:43:12.120 --> 00:43:15.600]   Man, I'm going to be quoting Hamilton for a while.
[00:43:15.600 --> 00:43:17.600]   You might as well just get used to it.
[00:43:17.600 --> 00:43:18.600]   I'm just under Hamilton.
[00:43:18.600 --> 00:43:24.600]   And in fact, that's what the Google employee said, "How could you ever really know what
[00:43:24.600 --> 00:43:25.960]   someone like that is really thinking?"
[00:43:25.960 --> 00:43:30.520]   But I remember my only encounter with him was at a Google event when the Chromebook had
[00:43:30.520 --> 00:43:32.320]   just come out.
[00:43:32.320 --> 00:43:33.320]   And we had our CR48s.
[00:43:33.320 --> 00:43:34.320]   I remember from Google I/O.
[00:43:34.320 --> 00:43:37.280]   And this was an event in the Googleplex.
[00:43:37.280 --> 00:43:41.560]   And Sundar at the time was the guy in charge of Chromebooks.
[00:43:41.560 --> 00:43:46.720]   And he and I had a very nice, very polite, although we disagreed conversation about the
[00:43:46.720 --> 00:43:47.720]   Chromebook.
[00:43:47.720 --> 00:43:48.720]   He was right, by the way.
[00:43:48.720 --> 00:43:49.720]   I at the time said, "Now, this is dumb.
[00:43:49.720 --> 00:43:50.720]   Who's going to buy this?
[00:43:50.720 --> 00:43:53.040]   It's an operating system that's just a browser?
[00:43:53.040 --> 00:43:54.040]   What's the point?
[00:43:54.040 --> 00:43:55.040]   I don't get it.
[00:43:55.040 --> 00:43:56.040]   Blah, blah, blah, blah.
[00:43:56.040 --> 00:43:59.360]   Maybe in a school or a business where you want to lock it down so employees can't use
[00:43:59.360 --> 00:44:00.360]   it.
[00:44:00.360 --> 00:44:01.880]   But that's not something real people want.
[00:44:01.880 --> 00:44:05.680]   Now I recommend the Chromebook all the time because most people, that's all they should
[00:44:05.680 --> 00:44:06.680]   have.
[00:44:06.680 --> 00:44:07.680]   Yep.
[00:44:07.680 --> 00:44:08.680]   And he knew it.
[00:44:08.680 --> 00:44:09.680]   Yep.
[00:44:09.680 --> 00:44:10.680]   Two years.
[00:44:10.680 --> 00:44:11.680]   Job.
[00:44:11.680 --> 00:44:12.680]   Going on two years.
[00:44:12.680 --> 00:44:16.080]   But what was interesting is he listened.
[00:44:16.080 --> 00:44:17.080]   He was very polite.
[00:44:17.080 --> 00:44:19.280]   He was a very nice conversation.
[00:44:19.280 --> 00:44:26.720]   He defended his position without being angry or defensive.
[00:44:26.720 --> 00:44:33.440]   Cesar Sengupta says, "Over the long run Google rejects assholes."
[00:44:33.440 --> 00:44:37.680]   Sundar became CEO among his peers and yet his peers are still with him.
[00:44:37.680 --> 00:44:39.200]   So that's the political animal right there.
[00:44:39.200 --> 00:44:43.880]   But that was exactly my experience was we could disagree over something and I would still
[00:44:43.880 --> 00:44:46.960]   think the world of the guy, you know?
[00:44:46.960 --> 00:44:50.920]   The thing I keep hearing about Google, two things.
[00:44:50.920 --> 00:44:55.360]   One is there are tremendous number of underemployed people there.
[00:44:55.360 --> 00:44:58.400]   The higher brilliant people, they get to Google and they're going to change the world
[00:44:58.400 --> 00:45:00.720]   and they're in a huge organization.
[00:45:00.720 --> 00:45:05.160]   And the second is how much more regimented it is that I ever would have guessed.
[00:45:05.160 --> 00:45:07.160]   Ranks and structure.
[00:45:07.160 --> 00:45:08.160]   Is it?
[00:45:08.160 --> 00:45:09.160]   That's what I hear.
[00:45:09.160 --> 00:45:11.120]   But within that structure they give people autonomy, right?
[00:45:11.120 --> 00:45:15.360]   So there's a structure but they try to create teams, right?
[00:45:15.360 --> 00:45:16.360]   Or not.
[00:45:16.360 --> 00:45:17.720]   I think I read this book, "What would Google do?"
[00:45:17.720 --> 00:45:18.720]   That's talking about it.
[00:45:18.720 --> 00:45:20.360]   Well, I wasn't reporting on Google.
[00:45:20.360 --> 00:45:22.360]   I was just looking from the outside.
[00:45:22.360 --> 00:45:29.640]   But those who do, I mean it's still, god, Google and Facebook are both phenomenal companies.
[00:45:29.640 --> 00:45:30.640]   Absolutely.
[00:45:30.640 --> 00:45:31.640]   And Apple too.
[00:45:31.640 --> 00:45:36.120]   Very hard to do what they're doing at that level that they're doing and stay nimble
[00:45:36.120 --> 00:45:37.480]   and innovative.
[00:45:37.480 --> 00:45:42.520]   I would agree that Google and Facebook are probably the best exemplars of that.
[00:45:42.520 --> 00:45:44.520]   More so than say Microsoft or Apple.
[00:45:44.520 --> 00:45:47.520]   Do you want to say anything about Microsoft or ever?
[00:45:47.520 --> 00:45:49.600]   Is that contact?
[00:45:49.600 --> 00:45:57.440]   I think Google's a better company than Microsoft but they're all turning into similar things.
[00:45:57.440 --> 00:46:03.800]   They're big companies and they have a lot of committees and that makes them a little
[00:46:03.800 --> 00:46:12.720]   bit boring on some level but Google and the stuff that they're doing is just pretty big.
[00:46:12.720 --> 00:46:18.720]   One of the executives at Google X or AlphabetX I guess now told me that the phone company
[00:46:18.720 --> 00:46:20.520]   is going to be dead in five years.
[00:46:20.520 --> 00:46:21.520]   Wow.
[00:46:21.520 --> 00:46:24.120]   Well you saw there's a new announcement about that today.
[00:46:24.120 --> 00:46:25.120]   Yeah.
[00:46:25.120 --> 00:46:26.120]   What's that?
[00:46:26.120 --> 00:46:28.800]   It's the fiber phone.
[00:46:28.800 --> 00:46:31.920]   Oh, Google Fi, they're offering phone service now.
[00:46:31.920 --> 00:46:32.920]   That's fine.
[00:46:32.920 --> 00:46:33.920]   I'm sorry, fiber.
[00:46:33.920 --> 00:46:34.920]   Yeah, the fiber.
[00:46:34.920 --> 00:46:39.440]   So they're now matching the cable company but it's the phone's different and it's better
[00:46:39.440 --> 00:46:43.640]   and why are you ever going to use an old phone?
[00:46:43.640 --> 00:46:49.200]   We're actually pitching them on carrying on the TV portion of Google fiber.
[00:46:49.200 --> 00:46:56.920]   Where I was going with them was when I visited the Hangouts team up in Seattle, one of the
[00:46:56.920 --> 00:47:01.960]   guys bragged that he could get a packet from Seattle to India faster than the phone company
[00:47:01.960 --> 00:47:02.960]   can.
[00:47:02.960 --> 00:47:07.160]   And if you think about how much fiber Google owns around the world and how many data centers
[00:47:07.160 --> 00:47:11.800]   it has, I think it's a lot more than Facebook for instance, which has a pretty significant
[00:47:11.800 --> 00:47:15.880]   data center infrastructure and fiber infrastructure itself.
[00:47:15.880 --> 00:47:24.040]   And so I think they're going to light up this fiber backbone and then give us wireless
[00:47:24.040 --> 00:47:27.400]   in balloons or antennas.
[00:47:27.400 --> 00:47:31.560]   I can see a world where we get our magically glasses and it's just lit up.
[00:47:31.560 --> 00:47:34.040]   It just is connected to a high speed network.
[00:47:34.040 --> 00:47:40.400]   We always focus with Google and Amazon and Facebook on the customer facing stuff.
[00:47:40.400 --> 00:47:44.760]   But really if you dig deep, I think all three are infrastructure companies.
[00:47:44.760 --> 00:47:45.760]   Yeah.
[00:47:45.760 --> 00:47:48.520]   That really their mastery is the interesting.
[00:47:48.520 --> 00:47:49.520]   Go ahead.
[00:47:49.520 --> 00:47:51.120]   Yeah, I agree with that they are.
[00:47:51.120 --> 00:47:54.960]   Amazon certainly is becoming infrastructure company and Google understands this.
[00:47:54.960 --> 00:47:59.280]   But I also would argue that Google and Facebook are personal services companies.
[00:47:59.280 --> 00:48:02.200]   Well, they provide personal services.
[00:48:02.200 --> 00:48:05.040]   But that because of work versus versus my media.
[00:48:05.040 --> 00:48:10.520]   I feel like those are as those are an end to the means to the end.
[00:48:10.520 --> 00:48:14.560]   Well, anyway, that's what that's what makes them a company.
[00:48:14.560 --> 00:48:20.560]   But really that all of that ultimately, and I would say true for all three of them, what
[00:48:20.560 --> 00:48:27.480]   their real business is infrastructure and data collection and the analysis of that data.
[00:48:27.480 --> 00:48:34.280]   And by the way, in five years, I think we're going to see a scary amount of data collection.
[00:48:34.280 --> 00:48:36.160]   Well, I think it's happening now.
[00:48:36.160 --> 00:48:42.440]   At Southwest, I saw some eye sensors for these augmented reality glasses.
[00:48:42.440 --> 00:48:49.680]   And if you read the magically patent on monetization, by the way, magically has invested in by Google,
[00:48:49.680 --> 00:48:56.360]   you can look at something like a pair of headphones or a Coke can and it'll grab a picture off
[00:48:56.360 --> 00:49:03.480]   the camera on the glass, go up to Google, look it up, go over to Amazon and find out how to buy it
[00:49:03.480 --> 00:49:05.240]   and present that to you in your glass.
[00:49:05.240 --> 00:49:09.560]   And then you're going to look at, you know, yeah, buy that thing and you're going to be able to buy
[00:49:09.560 --> 00:49:13.480]   without touching anything, without talking anything, just using rocks.
[00:49:13.480 --> 00:49:15.520]   Well, and the echo, that's what the echo is, right?
[00:49:15.520 --> 00:49:17.200]   It's a gateway to Amazon.
[00:49:17.200 --> 00:49:19.000]   The echo, you have to talk to it, right?
[00:49:19.000 --> 00:49:20.480]   I know, but that's not so bad.
[00:49:20.480 --> 00:49:23.400]   I don't mind saying to the echo, buy me some batteries and it says, OK.
[00:49:23.400 --> 00:49:27.920]   Yeah, I think Satya Nadella said today that the voice is the new OS.
[00:49:27.920 --> 00:49:28.920]   I will.
[00:49:28.920 --> 00:49:29.920]   Yeah.
[00:49:29.920 --> 00:49:33.760]   Well, wait until the magically comes out and you're using your eyes.
[00:49:33.760 --> 00:49:37.880]   Keep in mind when you have eye sensors, you have identity because when you put on the glasses,
[00:49:37.880 --> 00:49:42.320]   it can see your iris and that's your identity.
[00:49:42.320 --> 00:49:45.040]   And it knows what you're attracted to.
[00:49:45.040 --> 00:49:48.120]   You look at a cute girl and your eyes open up a bet.
[00:49:48.120 --> 00:49:49.120]   And it's going to know.
[00:49:49.120 --> 00:49:53.760]   That's kind of my point is that we focus on the consumer facing stuff like, oh, it's going
[00:49:53.760 --> 00:49:57.440]   to be able to buy stuff or, oh, it's going to tell me what happened to my high school
[00:49:57.440 --> 00:49:58.640]   sweetheart.
[00:49:58.640 --> 00:50:05.240]   They're focused on a much bigger, longer game, which is the data smog that you're putting
[00:50:05.240 --> 00:50:08.120]   off from all of that stuff and what they can do with that.
[00:50:08.120 --> 00:50:09.720]   And I think that's a much more interesting game.
[00:50:09.720 --> 00:50:16.000]   And then again, it's infrastructure and the data analysis, big data that is really the
[00:50:16.000 --> 00:50:18.400]   key drivers for all three of those companies.
[00:50:18.400 --> 00:50:22.440]   And yesterday I got to ride in the here mapping car.
[00:50:22.440 --> 00:50:28.480]   One of these new cars that has a 360 degree high res camera and a light R and all that.
[00:50:28.480 --> 00:50:30.000]   And it goes down the street.
[00:50:30.000 --> 00:50:34.240]   And you see how much investment they're making in just one car.
[00:50:34.240 --> 00:50:36.520]   And they have hundreds of these cars.
[00:50:36.520 --> 00:50:41.080]   They said it's a billion dollar operation and Apple's doing it, Google's doing it, Microsoft's
[00:50:41.080 --> 00:50:42.080]   doing it.
[00:50:42.080 --> 00:50:46.720]   But it's the temptation to say they're doing it for a better maps project and that's product.
[00:50:46.720 --> 00:50:49.720]   And that's not a nice side effect.
[00:50:49.720 --> 00:50:53.360]   And it's the tip of the iceberg of the real value of all that data collection.
[00:50:53.360 --> 00:50:54.360]   Yeah, yeah.
[00:50:54.360 --> 00:50:57.680]   They're doing it for a whole lot of things coming over the next decade.
[00:50:57.680 --> 00:51:04.280]   And the synergy of knowing about having a map of the real world, knowing about you and
[00:51:04.280 --> 00:51:05.600]   your interests, there's a map.
[00:51:05.600 --> 00:51:07.400]   I mean, I don't know, I have a handle on it.
[00:51:07.400 --> 00:51:10.160]   I bet you these guys have a pretty good idea of where they're headed.
[00:51:10.160 --> 00:51:15.080]   But it feels like there is, that's, you know, the map is just this much.
[00:51:15.080 --> 00:51:17.720]   And down here, there's so much more they're getting from that.
[00:51:17.720 --> 00:51:18.720]   And it's so heavy.
[00:51:18.720 --> 00:51:23.240]   The industry has to sell the value of relevance.
[00:51:23.240 --> 00:51:24.400]   And they're not doing a very good job with it.
[00:51:24.400 --> 00:51:27.280]   They're doing a terrible job because what's happening is like what happens, oh my God,
[00:51:27.280 --> 00:51:28.280]   they're on the state on us.
[00:51:28.280 --> 00:51:31.360]   Well, if we don't get the data, we can't give you personal services.
[00:51:31.360 --> 00:51:34.480]   That's why I still think this notion of being personal services companies is important because
[00:51:34.480 --> 00:51:39.600]   unless I feel I'm getting relevance and value at a personal level from these companies,
[00:51:39.600 --> 00:51:42.040]   I am not going to have one thing about it.
[00:51:42.040 --> 00:51:43.040]   You don't have my due.
[00:51:43.040 --> 00:51:44.320]   You don't value that I give it to them.
[00:51:44.320 --> 00:51:45.920]   It might be a little misdirection though.
[00:51:45.920 --> 00:51:48.720]   It might be a little bit like, oh yeah, you're going to get value out of this.
[00:51:48.720 --> 00:51:51.440]   See, see, we give you a little now.
[00:51:51.440 --> 00:51:56.240]   See, and really, you're going to get a lot more than Google now.
[00:51:56.240 --> 00:52:00.040]   In my speech, I leave I stadium where the Super Bowl was just played, right?
[00:52:00.040 --> 00:52:01.040]   Yeah.
[00:52:01.040 --> 00:52:02.560]   They have 2000 beacons in that stadium.
[00:52:02.560 --> 00:52:06.240]   They know when you enter the stadium, they know where you are full time.
[00:52:06.240 --> 00:52:09.760]   And you know, in one of my talks, one of the audience members stood up and said, I'm
[00:52:09.760 --> 00:52:11.680]   going to turn that shit off.
[00:52:11.680 --> 00:52:15.360]   And I said, no, you're not because you're not going to get a hamburger delivered to your
[00:52:15.360 --> 00:52:16.360]   seat.
[00:52:16.360 --> 00:52:17.360]   And you're not the good.
[00:52:17.360 --> 00:52:18.720]   They have to offer the sugar.
[00:52:18.720 --> 00:52:22.400]   There's got to be the sugar so you don't so you continue to give them data.
[00:52:22.400 --> 00:52:23.400]   Yeah.
[00:52:23.400 --> 00:52:24.400]   Yeah.
[00:52:24.400 --> 00:52:27.560]   And eventually you might not even get into the stadium.
[00:52:27.560 --> 00:52:28.560]   If you turn.
[00:52:28.560 --> 00:52:29.560]   Well, that's going to be the interesting thing.
[00:52:29.560 --> 00:52:33.960]   I was just reading about the London Times, which I haven't read in years.
[00:52:33.960 --> 00:52:34.960]   You know why?
[00:52:34.960 --> 00:52:35.960]   Because it's got a massive paywall.
[00:52:35.960 --> 00:52:36.960]   There's no that's impervious.
[00:52:36.960 --> 00:52:38.960]   Yes, it is.
[00:52:38.960 --> 00:52:42.040]   And now they're saying, well, there's really no business in news anymore.
[00:52:42.040 --> 00:52:43.720]   Yeah, what a surprise.
[00:52:43.720 --> 00:52:51.040]   Well, these the sun in London, which which had a Murdoch paywall as well, it's churn rate.
[00:52:51.040 --> 00:52:54.120]   That is to say how many people left and they had to fill every year was 125%.
[00:52:54.120 --> 00:52:56.800]   The source of mine.
[00:52:56.800 --> 00:52:58.280]   And so they lost the entire audience.
[00:52:58.280 --> 00:53:03.320]   They're going back and on the quarter and had to replace all of that just to stay even.
[00:53:03.320 --> 00:53:05.560]   So the Times says we're not going to do breaking news.
[00:53:05.560 --> 00:53:07.520]   This is the Times of London.
[00:53:07.520 --> 00:53:10.160]   We're not going to do breaking news anymore.
[00:53:10.160 --> 00:53:11.840]   Readers don't come to us for breaking news.
[00:53:11.840 --> 00:53:14.600]   They can go to the BBC and Twitter for that, which are free.
[00:53:14.600 --> 00:53:15.840]   Yeah.
[00:53:15.840 --> 00:53:19.600]   And I bet they did, didn't they, Alan Hunter, Times Head of Digital?
[00:53:19.600 --> 00:53:23.200]   They come to us for the authority of our reporting opinion and analysis.
[00:53:23.200 --> 00:53:24.840]   Oh, yes, breaking news.
[00:53:24.840 --> 00:53:25.840]   They become a commodity.
[00:53:25.840 --> 00:53:27.080]   They come to us for the accent.
[00:53:27.080 --> 00:53:30.240]   They come to us for our received pronunciation.
[00:53:30.240 --> 00:53:31.400]   It's hard to charge people for it.
[00:53:31.400 --> 00:53:33.040]   We believe in the power of digital editions.
[00:53:33.040 --> 00:53:35.760]   I wonder how they're doing behind that big fat paywall.
[00:53:35.760 --> 00:53:37.800]   They have, I forget the number.
[00:53:37.800 --> 00:53:39.520]   It's along the order.
[00:53:39.520 --> 00:53:41.680]   It's low six figures of paying customers.
[00:53:41.680 --> 00:53:42.680]   Wow.
[00:53:42.680 --> 00:53:44.280]   First New York Times has a million.
[00:53:44.280 --> 00:53:45.280]   It's a million.
[00:53:45.280 --> 00:53:46.280]   Ten times.
[00:53:46.280 --> 00:53:49.120]   The only reason they can do that is because they have 60 million coming to them for free
[00:53:49.120 --> 00:53:53.560]   with about a 1.8% conversion rate to get them the million.
[00:53:53.560 --> 00:53:54.560]   That's my point.
[00:53:54.560 --> 00:53:58.720]   I don't know how, I mean, I haven't read The Times in five years because I can't.
[00:53:58.720 --> 00:54:02.080]   And I'm not going to pay five pounds a week.
[00:54:02.080 --> 00:54:06.880]   I'll let it right now at the Neuya Zura-Kun Zeitung.
[00:54:06.880 --> 00:54:10.880]   The way she puts it is that there's fast, medium and slow news.
[00:54:10.880 --> 00:54:14.320]   Fast news to hers, breaking news, commodity news, curated stuff, spend a little time.
[00:54:14.320 --> 00:54:15.320]   Yeah, we got it.
[00:54:15.320 --> 00:54:16.320]   It's there.
[00:54:16.320 --> 00:54:17.320]   Spend a little on it.
[00:54:17.320 --> 00:54:18.320]   Just, just link to it.
[00:54:18.320 --> 00:54:20.040]   Medium news is their analysts.
[00:54:20.040 --> 00:54:24.080]   In the case of some of these European papers, they have Frau Doctor, Professor Solon Sol
[00:54:24.080 --> 00:54:26.920]   telling you what's really happening.
[00:54:26.920 --> 00:54:32.040]   Slow news is things like big reports that TechCrunch used to do.
[00:54:32.040 --> 00:54:34.880]   Or things that really have high value.
[00:54:34.880 --> 00:54:37.800]   And consultants and so on.
[00:54:37.800 --> 00:54:40.200]   And I think you end up with a gradation like that.
[00:54:40.200 --> 00:54:42.480]   The ends ZZ, the ends ZET does charge.
[00:54:42.480 --> 00:54:46.280]   It's one of them that can do it because they're a rare source.
[00:54:46.280 --> 00:54:50.320]   It's not going to work, I don't think, in the UK the same way.
[00:54:50.320 --> 00:54:52.480]   Well, congratulations, London Times.
[00:54:52.480 --> 00:54:56.680]   You've gone from being one of the great newspapers of the world to being a kind of moderately successful
[00:54:56.680 --> 00:54:57.680]   newsletter.
[00:54:57.680 --> 00:54:58.680]   Paid newsletter.
[00:54:58.680 --> 00:55:05.120]   Well done.
[00:55:05.120 --> 00:55:06.120]   Jolly good.
[00:55:06.120 --> 00:55:07.120]   But maybe that's the future of journalism.
[00:55:07.120 --> 00:55:10.840]   At least they're making money.
[00:55:10.840 --> 00:55:12.600]   They're, well, I think maybe not.
[00:55:12.600 --> 00:55:14.600]   Oh, we don't know.
[00:55:14.600 --> 00:55:19.480]   They have 100, I saw like hundreds of 2000 people paying N pounds a year.
[00:55:19.480 --> 00:55:21.400]   And that's fine, but it's a small business now.
[00:55:21.400 --> 00:55:22.400]   And it has little influence.
[00:55:22.400 --> 00:55:23.400]   Have you ever come?
[00:55:23.400 --> 00:55:24.400]   I mean, I know the problem is.
[00:55:24.400 --> 00:55:25.400]   That's the biggest one, right?
[00:55:25.400 --> 00:55:26.400]   Yeah.
[00:55:26.400 --> 00:55:29.000]   It's supposed to be to be influential and they've lost their impact.
[00:55:29.000 --> 00:55:30.000]   Yeah.
[00:55:30.000 --> 00:55:34.120]   I mean, literally more people watch a show than read the Sunday London Sunday Times.
[00:55:34.120 --> 00:55:35.120]   Yes.
[00:55:35.120 --> 00:55:36.120]   Yes.
[00:55:36.120 --> 00:55:37.120]   It's terrible.
[00:55:37.120 --> 00:55:38.800]   It's sad to me.
[00:55:38.800 --> 00:55:42.280]   But I mean, they're not, they don't have to beat it for the numbers.
[00:55:42.280 --> 00:55:43.280]   That's fine.
[00:55:43.280 --> 00:55:44.280]   I understand that.
[00:55:44.280 --> 00:55:45.280]   But I think you're right.
[00:55:45.280 --> 00:55:48.480]   I think influence is kind of important, at least to the writers.
[00:55:48.480 --> 00:55:54.080]   Eric Schmidt got $8 million for 2015 compared to Sundar's 100.
[00:55:54.080 --> 00:55:57.320]   Oh, oh, how soon we forget.
[00:55:57.320 --> 00:56:00.720]   Oh, CFO Ruth Porack got $31 million.
[00:56:00.720 --> 00:56:02.080]   This is salary plus stock.
[00:56:02.080 --> 00:56:03.080]   Yeah.
[00:56:03.080 --> 00:56:05.440]   Oh, it's a successful company.
[00:56:05.440 --> 00:56:07.960]   But that is a big payday.
[00:56:07.960 --> 00:56:13.080]   Up to now, Pichai only had $11 million in stock options, invested.
[00:56:13.080 --> 00:56:14.080]   Right.
[00:56:14.080 --> 00:56:21.280]   Now, he will have $635 million in stock options.
[00:56:21.280 --> 00:56:22.280]   He'll be a billion.
[00:56:22.280 --> 00:56:25.440]   At a certain point, these guys like to invest and start things and do all that.
[00:56:25.440 --> 00:56:30.600]   You know, at some point, what all can you do to keep a Sundar?
[00:56:30.600 --> 00:56:31.600]   Right.
[00:56:31.600 --> 00:56:32.600]   No, you have to throw money at him.
[00:56:32.600 --> 00:56:35.920]   And if he's good, if he's worth it, then it may be a paradox.
[00:56:35.920 --> 00:56:36.920]   It is worth it.
[00:56:36.920 --> 00:56:37.920]   It is worth it.
[00:56:37.920 --> 00:56:39.920]   But the more money you have, the more you say, well, what would I compare?
[00:56:39.920 --> 00:56:40.920]   Then I don't need you.
[00:56:40.920 --> 00:56:41.920]   Yeah.
[00:56:41.920 --> 00:56:42.920]   Yeah.
[00:56:42.920 --> 00:56:43.920]   It's impossible.
[00:56:43.920 --> 00:56:49.480]   Even on my small level, if somebody's really good at doing this, they're not going
[00:56:49.480 --> 00:56:50.720]   to work for me.
[00:56:50.720 --> 00:56:51.720]   Why should they?
[00:56:51.720 --> 00:56:52.720]   Right.
[00:56:52.720 --> 00:56:57.720]   So what, you know, typically happens, close your ears, Jason Hall and Megan Moroney and
[00:56:57.720 --> 00:56:59.160]   Robert Ballisares.
[00:56:59.160 --> 00:57:01.800]   They get better and better and then they get to go off on their own.
[00:57:01.800 --> 00:57:02.800]   Why shouldn't they?
[00:57:02.800 --> 00:57:03.800]   I did.
[00:57:03.800 --> 00:57:06.960]   But I also, but not everyone is meant to be an entrepreneur.
[00:57:06.960 --> 00:57:07.960]   It is so easy.
[00:57:07.960 --> 00:57:11.040]   You don't even have to be an entrepreneur anymore.
[00:57:11.040 --> 00:57:12.040]   As much.
[00:57:12.040 --> 00:57:13.720]   I mean, it's so easy to do.
[00:57:13.720 --> 00:57:18.280]   I mean, it's not like you're saying I'm going to be a startup and I'm going to have evaluation
[00:57:18.280 --> 00:57:19.440]   of a billion dollars.
[00:57:19.440 --> 00:57:25.200]   You might just say, well, I can make a good living using Patreon or YouTube or, you know,
[00:57:25.200 --> 00:57:26.200]   and it doesn't distribution.
[00:57:26.200 --> 00:57:27.600]   But you have gone for a zero.
[00:57:27.600 --> 00:57:30.960]   I can also sit there and say, oh, Leo is going to pay my bills in my insurance and I
[00:57:30.960 --> 00:57:32.640]   can have fun and that's fine.
[00:57:32.640 --> 00:57:37.680]   In broadcasting, it's always pressure whether you work for the man or not because you know,
[00:57:37.680 --> 00:57:41.040]   if you don't get the numbers, if you don't get the audience, you don't have a job.
[00:57:41.040 --> 00:57:46.440]   So it's, I mean, after 30 years, this will be my, you know, this is my 40th year in broadcasting.
[00:57:46.440 --> 00:57:47.440]   Wow.
[00:57:47.440 --> 00:57:51.440]   I feel no less pressure now or no more pressure now than I did when I was working for somebody.
[00:57:51.440 --> 00:57:53.280]   At least I get to do what I want.
[00:57:53.280 --> 00:57:57.960]   And if, and this is the, for me, the most important thing was if it does go down in flames, it's
[00:57:57.960 --> 00:57:59.240]   because I did it.
[00:57:59.240 --> 00:58:00.240]   Yeah.
[00:58:00.240 --> 00:58:01.240]   Yeah.
[00:58:01.240 --> 00:58:04.120]   And tech TV, which we worked so hard for for six years, that was the five, that was last
[00:58:04.120 --> 00:58:05.120]   draw.
[00:58:05.120 --> 00:58:09.840]   We created something really great and and that's when I said, I'm not going to do that for
[00:58:09.840 --> 00:58:10.840]   somebody again.
[00:58:10.840 --> 00:58:16.760]   If I, if I'm going to go, I'm going to go from my own time.
[00:58:16.760 --> 00:58:23.160]   I am sad to say that according to motherboard, which is, by the way, getting better and better
[00:58:23.160 --> 00:58:24.880]   all the time, I think they're doing a great job.
[00:58:24.880 --> 00:58:29.000]   This is the vice kind of technology division.
[00:58:29.000 --> 00:58:37.360]   We're not going to get encrypted email from Google or Yahoo for some time.
[00:58:37.360 --> 00:58:38.560]   Seemed like they were.
[00:58:38.560 --> 00:58:45.040]   So Matthew Green tweeted last week, it's been 648 days, 648 days since Google promised
[00:58:45.040 --> 00:58:48.760]   usable end to end encryption.
[00:58:48.760 --> 00:58:53.720]   He also says, Matthew Green is a great cryptographer, one of the great guys at Johns Hopkins.
[00:58:53.720 --> 00:58:57.640]   He also says, it's worth pointing out that Yahoo has been putting more resources to end
[00:58:57.640 --> 00:59:00.200]   and end to end encrypted email than in Google.
[00:59:00.200 --> 00:59:03.800]   Yahoo must be harder to do.
[00:59:03.800 --> 00:59:04.800]   I don't know.
[00:59:04.800 --> 00:59:05.960]   There's, there are choices out there.
[00:59:05.960 --> 00:59:08.520]   There's a proton mail just went public proton mail.ch.
[00:59:08.520 --> 00:59:14.160]   It's a Swiss company.
[00:59:14.160 --> 00:59:15.360]   How important is it?
[00:59:15.360 --> 00:59:19.080]   I think partly it's that I don't think there's a huge consumer demand for it.
[00:59:19.080 --> 00:59:20.580]   No.
[00:59:20.580 --> 00:59:24.200]   I like having encrypted email, but let me ask you this.
[00:59:24.200 --> 00:59:29.520]   Is there any way to imagine a world in which everybody is encrypted in email?
[00:59:29.520 --> 00:59:30.520]   Yeah.
[00:59:30.520 --> 00:59:35.440]   In fact, we're very rapidly headed to a world where all of your web transactions are encrypted.
[00:59:35.440 --> 00:59:36.440]   Sure.
[00:59:36.440 --> 00:59:37.440]   Yes.
[00:59:37.440 --> 00:59:39.280]   And that's thanks to Google pushing HTTPS.
[00:59:39.280 --> 00:59:43.720]   Yes.
[00:59:43.720 --> 00:59:50.800]   So I don't think it's hard to imagine at all if these big email providers could get it together.
[00:59:50.800 --> 00:59:58.280]   The idea is that, I mean, your email is encrypted from you to Google, but it's not necessarily
[00:59:58.280 --> 01:00:03.400]   encrypted from Google to your recipient.
[01:00:03.400 --> 01:00:07.080]   It would, and it would be really nice if we're encrypted in such a way that Google and all
[01:00:07.080 --> 01:00:10.200]   the, no one along the way can read it, but Google can read it.
[01:00:10.200 --> 01:00:13.240]   It'd be really nice if Google couldn't read it either.
[01:00:13.240 --> 01:00:17.960]   I think that's what the goal would be to have it true privacy where I send a message.
[01:00:17.960 --> 01:00:20.880]   And instead of it being a postcard, it's a letter.
[01:00:20.880 --> 01:00:25.000]   Yeah, it goes to the conversation you and I had a couple of weeks ago.
[01:00:25.000 --> 01:00:26.000]   What's that?
[01:00:26.000 --> 01:00:30.000]   About, will email ever become as protected as postal mail?
[01:00:30.000 --> 01:00:31.000]   Right.
[01:00:31.000 --> 01:00:33.200]   Because it's digital, it's not.
[01:00:33.200 --> 01:00:34.200]   No.
[01:00:34.200 --> 01:00:36.200]   I think it's not.
[01:00:36.200 --> 01:00:42.560]   But yeah, and I don't think, well, this is the larger privacy conversation too, Robert.
[01:00:42.560 --> 01:00:48.080]   Is it foolish to even think that there might be such a thing as using the internet privately?
[01:00:48.080 --> 01:00:49.640]   No.
[01:00:49.640 --> 01:00:50.640]   It's not foolish.
[01:00:50.640 --> 01:00:54.720]   No, it's, I don't believe we're going to get privacy back.
[01:00:54.720 --> 01:00:57.680]   No, I don't think so either.
[01:00:57.680 --> 01:01:02.320]   Even if you just look, forget the government, listening on everything and they're listening
[01:01:02.320 --> 01:01:04.720]   to a lot of things.
[01:01:04.720 --> 01:01:10.880]   Gmail requires an advertising model to work.
[01:01:10.880 --> 01:01:14.200]   And even if you get rid of that model and say, well, we're going to make our money somewhere
[01:01:14.200 --> 01:01:19.920]   else and pay for Gmail some other way, there's so many apps that require access to Gmail
[01:01:19.920 --> 01:01:20.920]   now.
[01:01:20.920 --> 01:01:23.680]   I trip it, for instance, I don't know if you use trip it.
[01:01:23.680 --> 01:01:24.760]   I love it.
[01:01:24.760 --> 01:01:25.760]   I love it.
[01:01:25.760 --> 01:01:27.000]   It's games for email.
[01:01:27.000 --> 01:01:28.960]   It scans your email for tickets.
[01:01:28.960 --> 01:01:32.000]   You think, I don't know what else it's doing in there, right?
[01:01:32.000 --> 01:01:33.000]   I gave it a passion.
[01:01:33.000 --> 01:01:34.000]   Yeah.
[01:01:34.000 --> 01:01:35.000]   I gave it a passion.
[01:01:35.000 --> 01:01:39.760]   And it saved me a night in Chicago because I was on the runway and it said, oh, your flight's
[01:01:39.760 --> 01:01:41.320]   being canceled.
[01:01:41.320 --> 01:01:44.000]   We were heading toward the runway.
[01:01:44.000 --> 01:01:46.080]   And I know how trip it works.
[01:01:46.080 --> 01:01:48.560]   It's hooked into their traffic control system.
[01:01:48.560 --> 01:01:51.320]   And it said, oh, would you like to take it on another carrier?
[01:01:51.320 --> 01:01:52.840]   Sure.
[01:01:52.840 --> 01:01:54.440]   And so it has my credit card.
[01:01:54.440 --> 01:01:55.680]   It has my location.
[01:01:55.680 --> 01:01:57.040]   It has my email.
[01:01:57.040 --> 01:01:58.760]   But the point being--
[01:01:58.760 --> 01:02:03.040]   And two minutes later, the pilot came on and said, I can't get an engine started.
[01:02:03.040 --> 01:02:05.040]   We're going back to the gate.
[01:02:05.040 --> 01:02:09.000]   The point being that you should be the one who grants trip it permission.
[01:02:09.000 --> 01:02:10.000]   I know.
[01:02:10.000 --> 01:02:15.000]   But if I can grant trip it permission, that means that it has access to something that's
[01:02:15.000 --> 01:02:16.000]   not an engine.
[01:02:16.000 --> 01:02:17.000]   It's your choice.
[01:02:17.000 --> 01:02:18.000]   But that's-- no, no, because--
[01:02:18.000 --> 01:02:19.000]   It's friends acting like a trip.
[01:02:19.000 --> 01:02:20.000]   You would give them the key.
[01:02:20.000 --> 01:02:21.000]   You could give them the key.
[01:02:21.000 --> 01:02:22.000]   You could.
[01:02:22.000 --> 01:02:23.000]   No, but that's how it should be.
[01:02:23.000 --> 01:02:24.000]   That's how it gets more complicated.
[01:02:24.000 --> 01:02:26.600]   So that only people who you give permission to should have access.
[01:02:26.600 --> 01:02:27.600]   Yeah.
[01:02:27.600 --> 01:02:31.360]   But once you give a trip it's owned by Concur, a public company, once I give them the key,
[01:02:31.360 --> 01:02:33.280]   what else are they looking around for?
[01:02:33.280 --> 01:02:35.880]   And where are they-- what are they taking that data as--
[01:02:35.880 --> 01:02:36.880]   Well, if you--
[01:02:36.880 --> 01:02:37.880]   But then if--
[01:02:37.880 --> 01:02:38.880]   No, no, that's fine.
[01:02:38.880 --> 01:02:39.880]   Don't give them the key.
[01:02:39.880 --> 01:02:40.880]   Oh.
[01:02:40.880 --> 01:02:41.880]   Right?
[01:02:41.880 --> 01:02:42.880]   It's up to you.
[01:02:42.880 --> 01:02:43.880]   That's the point.
[01:02:43.880 --> 01:02:45.440]   Right now it isn't up to you.
[01:02:45.440 --> 01:02:47.440]   Your email just floats around publicly.
[01:02:47.440 --> 01:02:49.600]   Well, it's not quite publicly.
[01:02:49.600 --> 01:02:51.240]   It is HTTPS.
[01:02:51.240 --> 01:02:54.000]   So it's encrypted between me and the Google servers.
[01:02:54.000 --> 01:02:55.000]   Right.
[01:02:55.000 --> 01:02:59.120]   And then as soon as it gets off Google servers and goes to something else, it's unencrypted.
[01:02:59.120 --> 01:03:01.120]   Google's internal is probably not encrypted.
[01:03:01.120 --> 01:03:02.760]   And it's probably not encrypted on Google servers.
[01:03:02.760 --> 01:03:03.760]   That's right.
[01:03:03.760 --> 01:03:07.000]   Well, obviously it's not because I see ads that are based on my email.
[01:03:07.000 --> 01:03:09.680]   Well, it could be encrypted because Google might have the key.
[01:03:09.680 --> 01:03:12.120]   But-- no, you're right.
[01:03:12.120 --> 01:03:13.120]   Very enough.
[01:03:13.120 --> 01:03:16.320]   But Google also even tries to answer my email.
[01:03:16.320 --> 01:03:17.560]   I don't know if you use that feature.
[01:03:17.560 --> 01:03:18.560]   I love that feature.
[01:03:18.560 --> 01:03:19.960]   I do too in inbox.
[01:03:19.960 --> 01:03:21.600]   Yeah, I use it all the time.
[01:03:21.600 --> 01:03:24.920]   So that's why people get messages from me that say, yeah, that's great.
[01:03:24.920 --> 01:03:25.760]   Right on.
[01:03:25.760 --> 01:03:27.480]   But it's surprisingly good.
[01:03:27.480 --> 01:03:28.480]   The other day--
[01:03:28.480 --> 01:03:29.480]   It's very good.
[01:03:29.480 --> 01:03:33.320]   Yeah, it gave me an off-- it offered me a response that was like tailor made.
[01:03:33.320 --> 01:03:34.760]   I was very impressed.
[01:03:34.760 --> 01:03:36.280]   That's only in inbox, then.
[01:03:36.280 --> 01:03:37.280]   In inbox.
[01:03:37.280 --> 01:03:39.040]   I'm still not using inbox.
[01:03:39.040 --> 01:03:40.720]   Yeah, you don't like that thing.
[01:03:40.720 --> 01:03:42.200]   I've got to try it again.
[01:03:42.200 --> 01:03:45.120]   I like the audio responses because it keeps me edited.
[01:03:45.120 --> 01:03:46.640]   It's like--
[01:03:46.640 --> 01:03:47.680]   Well, you know what?
[01:03:47.680 --> 01:03:48.200]   It works.
[01:03:48.200 --> 01:03:51.680]   And I think the reason they did it is on mobile, where you don't really
[01:03:51.680 --> 01:03:52.880]   want to type anything.
[01:03:52.880 --> 01:03:55.640]   But you just press a button and boom, you're done.
[01:03:55.640 --> 01:03:57.640]   And wait until we get the glasses, right?
[01:03:57.640 --> 01:04:00.280]   The magic leap glasses were augmented reality.
[01:04:00.280 --> 01:04:02.400]   HoloLens glasses.
[01:04:02.400 --> 01:04:04.000]   We're going to want to type even less.
[01:04:04.000 --> 01:04:04.500]   Yeah.
[01:04:05.500 --> 01:04:08.900]   I think it's up.
[01:04:08.900 --> 01:04:09.900]   There was a service--
[01:04:09.900 --> 01:04:10.900]   I can't remember when it came out.
[01:04:10.900 --> 01:04:14.420]   It was like a couple of months ago that you can sign up with and give it access to your
[01:04:14.420 --> 01:04:17.100]   email and anything you buy from Amazon.
[01:04:17.100 --> 01:04:19.580]   It keeps an eye on your emails.
[01:04:19.580 --> 01:04:20.580]   Yes.
[01:04:20.580 --> 01:04:26.700]   And then it'll tell you, oh, that price just dropped and here's a rebate for $4 because
[01:04:26.700 --> 01:04:31.460]   the thing you bought that it tracked your emails and showed that you bought from Amazon
[01:04:31.460 --> 01:04:32.700]   is now cheaper.
[01:04:32.700 --> 01:04:37.380]   And I'm going to send an email to Amazon saying, and it sends it for you saying, hey, I bought
[01:04:37.380 --> 01:04:39.020]   this and I'd like a refund.
[01:04:39.020 --> 01:04:40.620]   And then you get the refund back.
[01:04:40.620 --> 01:04:46.460]   Well, keep in mind, when I talk to Alexa and I say Alexa buy me some more toilet paper,
[01:04:46.460 --> 01:04:49.940]   it comes back, well, last time you bought toilet paper, you bought the 20 pack of the
[01:04:49.940 --> 01:04:50.940]   Charmin 2 Pie.
[01:04:50.940 --> 01:04:53.860]   In other words, it has a profile on you.
[01:04:53.860 --> 01:04:56.260]   No, you asked you otherwise you couldn't buy it for you.
[01:04:56.260 --> 01:04:57.820]   Exactly.
[01:04:57.820 --> 01:04:59.020]   But you give them permission.
[01:04:59.020 --> 01:05:02.020]   That's my point is that this should all be permission-based.
[01:05:02.020 --> 01:05:06.180]   Well, it's permission and my boss is about $70,000 worth of stuff from Amazon and all
[01:05:06.180 --> 01:05:07.980]   of those receipts are in Gmail.
[01:05:07.980 --> 01:05:11.580]   So Google knows about his buying behavior and Amazon.
[01:05:11.580 --> 01:05:16.180]   Your point is well taken, which is that Google is not strongly incentive to give into an
[01:05:16.180 --> 01:05:19.380]   encryption, which is why I was surprised they announced it.
[01:05:19.380 --> 01:05:23.780]   Well, they're trying to keep the government out of our business, right?
[01:05:23.780 --> 01:05:27.860]   I think we need a new conversation around privacy.
[01:05:27.860 --> 01:05:29.660]   Privacy's over.
[01:05:29.660 --> 01:05:33.900]   The idea that you're going to be studied and data is going to be collected about you is
[01:05:33.900 --> 01:05:34.900]   over.
[01:05:34.900 --> 01:05:41.820]   The idea of consequences for having this data is not over and we need to talk about consequences
[01:05:41.820 --> 01:05:43.780]   because that's really what we care about.
[01:05:43.780 --> 01:05:44.780]   Well, I don't know about that.
[01:05:44.780 --> 01:05:49.820]   We care about being thrown in jail or we care about a government killing us or we care about
[01:05:49.820 --> 01:05:54.020]   our wives finding out about our girlfriends or whatever, right?
[01:05:54.020 --> 01:05:55.180]   That's consequences.
[01:05:55.180 --> 01:05:58.900]   We need to have a discussion about consequences, the privacy is over.
[01:05:58.900 --> 01:06:01.780]   I just used synonyms for that, Robert, and say it a little bit differently.
[01:06:01.780 --> 01:06:09.260]   And I said this in my book is that I think that we have to control the use of data rather
[01:06:09.260 --> 01:06:10.860]   than the gathering of data.
[01:06:10.860 --> 01:06:13.420]   To control the gathering of data is to try to control knowledge.
[01:06:13.420 --> 01:06:16.940]   That's why I have problems with things like the right to be forgotten decision.
[01:06:16.940 --> 01:06:17.940]   Knowledge is knowledge.
[01:06:17.940 --> 01:06:18.940]   You can't forget things.
[01:06:18.940 --> 01:06:22.420]   But you can't force people to forget things and not know things that they know.
[01:06:22.420 --> 01:06:26.260]   But what you do with it, you absolutely can have a role in.
[01:06:26.260 --> 01:06:29.860]   And we as industries have to be a lot smarter about how we make this transactional and in
[01:06:29.860 --> 01:06:32.380]   exchange of value.
[01:06:32.380 --> 01:06:36.620]   I hate the idea that people come on and say, "We live in a surveillance society now.
[01:06:36.620 --> 01:06:39.020]   It's so dystopian and a way to put it.
[01:06:39.020 --> 01:06:42.420]   We also live in a more relevant society now."
[01:06:42.420 --> 01:06:43.940]   And there's ways to do that.
[01:06:43.940 --> 01:06:48.100]   So I agree with you fundamentally, but I think the language matters a lot.
[01:06:48.100 --> 01:06:49.100]   True.
[01:06:49.100 --> 01:06:51.340]   So I don't think we've lost privacy.
[01:06:51.340 --> 01:06:54.220]   You always have the ultimate privacy is what you choose to keep up here.
[01:06:54.220 --> 01:06:57.660]   When you tell one person something, you have given up control of that knowledge.
[01:06:57.660 --> 01:06:59.580]   And they then have controlled it.
[01:06:59.580 --> 01:07:04.220]   Keep in mind, we're soon going to have sensors on our skin that are going to see our nervous
[01:07:04.220 --> 01:07:05.220]   system.
[01:07:05.220 --> 01:07:10.060]   And that is an in-fight to your head.
[01:07:10.060 --> 01:07:11.780]   And then you're going to be watching our eyes.
[01:07:11.780 --> 01:07:13.660]   And our eyes don't lie.
[01:07:13.660 --> 01:07:16.260]   If you think that girl is cute, your eyes open up.
[01:07:16.260 --> 01:07:17.260]   Right?
[01:07:17.260 --> 01:07:20.900]   And if you think Coca-Cola is a cool brand, your eyes open up and your sensors are going
[01:07:20.900 --> 01:07:21.900]   to see this.
[01:07:21.900 --> 01:07:28.300]   And I know a lot about you in a very deep way that we haven't even really started talking.
[01:07:28.300 --> 01:07:33.580]   We've talked about this before, Jeff, the idea that mores are better than laws in this
[01:07:33.580 --> 01:07:34.580]   regard.
[01:07:34.580 --> 01:07:35.580]   Yes.
[01:07:35.580 --> 01:07:37.500]   So I'm thinking about Mayo.
[01:07:37.500 --> 01:07:41.780]   I mentioned that your email now is like a postcard as opposed to a sealed envelope.
[01:07:41.780 --> 01:07:45.020]   But the truth is a sealed envelope is not at all secure.
[01:07:45.020 --> 01:07:47.300]   It's easy to open it up and read what's in there.
[01:07:47.300 --> 01:07:51.500]   But it is mores and laws, the back them up, that protect us.
[01:07:51.500 --> 01:07:55.100]   It's a societal agreement that, well, you're not going to open somebody else's email.
[01:07:55.100 --> 01:07:58.220]   And if you do that, you're kind of a jerk and a creep.
[01:07:58.220 --> 01:08:04.540]   We don't seem to have anything like that in terms of digital and digital privacy, do
[01:08:04.540 --> 01:08:05.540]   we?
[01:08:05.540 --> 01:08:11.540]   Now, you know, I have friends at Telstra, a big phone company down in Australia, and
[01:08:11.540 --> 01:08:15.340]   we're talking about the fiber coming out of the sea to Telstra.
[01:08:15.340 --> 01:08:20.940]   And they said, there's a room before Telstra gets to it and it's owned by the NSA.
[01:08:20.940 --> 01:08:27.980]   And the NSA is watching every envelope going through that fiber, right?
[01:08:27.980 --> 01:08:34.780]   Yeah, I don't think we get it back.
[01:08:34.780 --> 01:08:36.380]   I think we could lobby for mores.
[01:08:36.380 --> 01:08:40.340]   I think we could lobby and maybe even we'll develop them spontaneously.
[01:08:40.340 --> 01:08:46.140]   You know, in Japan, you look, you know, there's all sorts of rules about personal space that
[01:08:46.140 --> 01:08:47.140]   we just respect.
[01:08:47.140 --> 01:08:48.140]   This stuff is so new.
[01:08:48.140 --> 01:08:54.660]   It's 10 years old that we don't have any rules at all, but they must develop more
[01:08:54.660 --> 01:08:55.660]   gamically, right?
[01:08:55.660 --> 01:08:58.060]   Yeah, I don't think we're dangerous too.
[01:08:58.060 --> 01:09:01.940]   Because, because for example, in Europe, there's an argument that, which, you know, is very
[01:09:01.940 --> 01:09:05.940]   frightened about privacy, is that if you do collect data, you collect it for this reason,
[01:09:05.940 --> 01:09:08.140]   and you cannot then use it for any other reason.
[01:09:08.140 --> 01:09:14.940]   Well, how do you deal with discovery and correlations and the ability to think about
[01:09:14.940 --> 01:09:21.100]   data through learning systems and define information and connections you couldn't have
[01:09:21.100 --> 01:09:22.100]   found?
[01:09:22.100 --> 01:09:23.900]   Again, it's an effort to limit knowledge.
[01:09:23.900 --> 01:09:25.620]   It says, you can't know that for that purpose.
[01:09:25.620 --> 01:09:27.340]   You can only know it for this purpose.
[01:09:27.340 --> 01:09:28.340]   That sounds good.
[01:09:28.340 --> 01:09:32.660]   It sounds like a limitation that makes sense, but it's limiting on things like scientific
[01:09:32.660 --> 01:09:36.900]   research and medical research and other mechanisms.
[01:09:36.900 --> 01:09:38.620]   It holds back innovation, right?
[01:09:38.620 --> 01:09:39.620]   Yes, exactly.
[01:09:39.620 --> 01:09:40.620]   Data is innovation.
[01:09:40.620 --> 01:09:46.540]   I was talking to somebody from Uber last night, and the algorithms of being able to
[01:09:46.540 --> 01:09:52.340]   move supply around are very interesting.
[01:09:52.340 --> 01:09:56.260]   They have a street in New York where an Uber drives down at every seven seconds.
[01:09:56.260 --> 01:09:57.260]   Every seven seconds.
[01:09:57.260 --> 01:10:03.060]   And you think about putting a sensor on each car that's going to go down that street.
[01:10:03.060 --> 01:10:07.540]   What's going to know a pothole is forming three weeks before it actually forms because
[01:10:07.540 --> 01:10:10.740]   it's going to watch a few pebbles disappearing from the road surface, right?
[01:10:10.740 --> 01:10:14.860]   As this thing goes over.
[01:10:14.860 --> 01:10:18.660]   All sorts of things in our society are going to change over the next 10 years because of
[01:10:18.660 --> 01:10:19.660]   data.
[01:10:19.660 --> 01:10:28.100]   I visited a company called Agribal in Illinois, and they grow virtual crops, virtual crops.
[01:10:28.100 --> 01:10:30.020]   And they have not even played.
[01:10:30.020 --> 01:10:34.260]   Who harvises the virtual crop and who eats the virtual food?
[01:10:34.260 --> 01:10:35.820]   Here's what's going on.
[01:10:35.820 --> 01:10:40.060]   They grow virtual crops based on the farm data that they're getting from satellites
[01:10:40.060 --> 01:10:45.500]   and drones and Doppler Raider and including the price data of corn, the daily spot price
[01:10:45.500 --> 01:10:49.580]   of corn, and their algorithms analyze it, grow virtual crops.
[01:10:49.580 --> 01:10:53.180]   And then they sell that data back to the farmer and say, hey, next week you should fertilize
[01:10:53.180 --> 01:11:00.140]   because it'll give you a good outcome, right, based on your farm data.
[01:11:00.140 --> 01:11:01.540]   And they have 90 employees already.
[01:11:01.540 --> 01:11:03.980]   This is a company that didn't exist two years ago.
[01:11:03.980 --> 01:11:11.660]   And 20 years ago, Chris, the CEO, told me that during his thesis project at University
[01:11:11.660 --> 01:11:17.220]   of Illinois, it took two years to analyze one, one day's worth of crop data.
[01:11:17.220 --> 01:11:20.420]   And today it takes two seconds to do that.
[01:11:20.420 --> 01:11:23.900]   It shows how much our technology has changed in two decades.
[01:11:23.900 --> 01:11:28.900]   And think about two decades from now, how much stuff is going to be possible that's
[01:11:28.900 --> 01:11:32.900]   just not possible today, and what kind of innovation is that going to lead to?
[01:11:32.900 --> 01:11:38.500]   And if we try to retard it based on our understanding of yesterday, we're going to make a lot of
[01:11:38.500 --> 01:11:45.300]   mistakes and keep things from being discovered, you know, and keep hamburgers from being delivered
[01:11:45.300 --> 01:11:48.100]   to our seat in the Levi Stadium.
[01:11:48.100 --> 01:11:52.740]   I could use a hamburger right now, actually.
[01:11:52.740 --> 01:11:53.740]   I wouldn't mind.
[01:11:53.740 --> 01:11:54.740]   Yeah, see.
[01:11:54.740 --> 01:11:55.740]   Uber eats.
[01:11:55.740 --> 01:12:01.940]   It's a hamburger, you know, not just Uber's going to deliver everything someday soon.
[01:12:01.940 --> 01:12:06.300]   Pretty soon, if you already, if you don't see it, good.
[01:12:06.300 --> 01:12:11.380]   Local delivery is a huge issue and a huge opportunity only in New York.
[01:12:11.380 --> 01:12:14.460]   In Petaluma, we're still going to go to the store, I think.
[01:12:14.460 --> 01:12:15.940]   Well, there's a company here.
[01:12:15.940 --> 01:12:18.060]   There's a company here that works with Jay's taxis.
[01:12:18.060 --> 01:12:20.060]   Oh, I know, but we use it all the time.
[01:12:20.060 --> 01:12:21.060]   But they deliver your food.
[01:12:21.060 --> 01:12:22.060]   And we use it all the time, I know.
[01:12:22.060 --> 01:12:25.700]   But wait until you get self-driving cars.
[01:12:25.700 --> 01:12:26.700]   It's not exactly.
[01:12:26.700 --> 01:12:28.460]   Yeah, exactly.
[01:12:28.460 --> 01:12:34.980]   The FBI may have backed down over the San Bernardino phone, but according to the ACLU,
[01:12:34.980 --> 01:12:37.060]   oh, there's a lot more phones.
[01:12:37.060 --> 01:12:45.500]   They made a map that shows all the all Ritz Act orders for assistance from tech companies,
[01:12:45.500 --> 01:12:50.460]   including Google, including Apple, Google, and Apple and Google, California 14, one in
[01:12:50.460 --> 01:12:53.060]   Nevada, one in Oregon, Washington.
[01:12:53.060 --> 01:12:58.660]   Let's look at New York 12, five in Florida.
[01:12:58.660 --> 01:13:03.620]   And you can, this is a great map because you can actually hover over the map and see what
[01:13:03.620 --> 01:13:07.220]   the case is and how many there are total.
[01:13:07.220 --> 01:13:14.860]   So this, the one of the people were wondering, well, why did the FBI just drop that case?
[01:13:14.860 --> 01:13:22.020]   Because they have plenty of other less highly publicized cases they can push back on.
[01:13:22.020 --> 01:13:28.740]   So the other issue, of course, is that the FBI says, well, we now have a way to get into
[01:13:28.740 --> 01:13:34.220]   this phone and we ain't going to tell you how we did it.
[01:13:34.220 --> 01:13:40.860]   So while the FBI might have implied that the all Ritz Act is only used in extraordinary
[01:13:40.860 --> 01:13:54.860]   cases, prosecuting terrorists, there are more than a few cases pending right now, about 70,
[01:13:54.860 --> 01:13:57.620]   70 such orders.
[01:13:57.620 --> 01:13:58.620]   Yeah.
[01:13:58.620 --> 01:14:04.020]   And so what do you, so if you're, so I ran into a, let's say hello to Don Sparks.
[01:14:04.020 --> 01:14:05.020]   Hello, Don.
[01:14:05.020 --> 01:14:09.460]   I ran into a star box today and he looked at me, he said, are you named Jeff?
[01:14:09.460 --> 01:14:11.060]   And you know, you know what's going to happen then.
[01:14:11.060 --> 01:14:12.060]   It's crazy.
[01:14:12.060 --> 01:14:13.060]   You're a Leo fan.
[01:14:13.060 --> 01:14:14.060]   So hello, Don.
[01:14:14.060 --> 01:14:22.140]   But he said he was, you know, leaving himself time to listen to Steve about Apple and what
[01:14:22.140 --> 01:14:26.460]   Apple, how Apple's going to figure out what was done to the phone and do they really know.
[01:14:26.460 --> 01:14:30.660]   Well, we, we talked about a little bit, but the problem is we don't know anything.
[01:14:30.660 --> 01:14:31.660]   We don't know.
[01:14:31.660 --> 01:14:36.660]   In fact, Steve mentioned that Pete Williams on NBC and Steve said he's a very good reporter
[01:14:36.660 --> 01:14:42.820]   who understands this said that he was told by the FBI that while they had unlocked the
[01:14:42.820 --> 01:14:48.020]   phone or somehow access the phone, all they got was the encrypted data and now they were
[01:14:48.020 --> 01:14:54.260]   going to work on decrypting it, which anybody who watches security now knows is if it's,
[01:14:54.260 --> 01:14:55.700]   you know, it's strong encryption.
[01:14:55.700 --> 01:14:58.580]   It's not, that's not going to happen.
[01:14:58.580 --> 01:15:00.380]   So all this was for what?
[01:15:00.380 --> 01:15:02.260]   I think Pete Williams got it wrong.
[01:15:02.260 --> 01:15:04.020]   Steve says, no, no, I'm bet he got it right.
[01:15:04.020 --> 01:15:05.060]   But I think he got it wrong.
[01:15:05.060 --> 01:15:09.340]   I think that it, or maybe it was just such a hot potato.
[01:15:09.340 --> 01:15:11.500]   The FBI was looking for some way to get out of the public.
[01:15:11.500 --> 01:15:17.340]   I proceed with these 70 other cases and, and, you know, kind of, in other words, let's not
[01:15:17.340 --> 01:15:18.340]   fight over this one.
[01:15:18.340 --> 01:15:20.980]   It's not that important.
[01:15:20.980 --> 01:15:27.420]   But the point being that government OS will get written and it'll probably get written
[01:15:27.420 --> 01:15:31.340]   without our knowledge because I think what the ideal for the government at this point
[01:15:31.340 --> 01:15:33.700]   is to not, they learned their lesson.
[01:15:33.700 --> 01:15:37.660]   They thought, oh, if we make this public, it'll be, we'll get the public on our side.
[01:15:37.660 --> 01:15:39.660]   And they learned their lesson.
[01:15:39.660 --> 01:15:44.180]   And I think now it's all going to happen behind closed doors and it will happen.
[01:15:44.180 --> 01:15:50.700]   So you probably write Robert that privacy from the government at least is dead.
[01:15:50.700 --> 01:15:55.060]   Well, I always say the government, fancy it as itself the best or that's itself as the
[01:15:55.060 --> 01:15:56.060]   best protector of privacy.
[01:15:56.060 --> 01:15:57.300]   It is the worst enemy of privacy.
[01:15:57.300 --> 01:15:58.300]   Yeah.
[01:15:58.300 --> 01:16:00.820]   Well, all you have to do is look at the breaches of the office of personnel management where
[01:16:00.820 --> 01:16:07.420]   millions of people's secret records were released or the 700,000 tax returns, the IRS inadvertently
[01:16:07.420 --> 01:16:11.900]   released or well, I can go on and on.
[01:16:11.900 --> 01:16:13.220]   And you may say, well, it's the government.
[01:16:13.220 --> 01:16:18.460]   I'm not too worried about the government, but, you know, look at, there's now two more
[01:16:18.460 --> 01:16:22.060]   hospitals that are being bit by ransomware.
[01:16:22.060 --> 01:16:24.300]   They can't operate.
[01:16:24.300 --> 01:16:27.500]   When hacker, you know, this stuff doesn't stay in the government.
[01:16:27.500 --> 01:16:28.500]   That's the problem.
[01:16:28.500 --> 01:16:33.860]   It gets, it's leaks out and then, and then we're all vulnerable from more than just the government.
[01:16:33.860 --> 01:16:38.580]   You may trust the government, but that doesn't mean that's the end of it.
[01:16:38.580 --> 01:16:41.140]   Security is hard and it's hard for people.
[01:16:41.140 --> 01:16:43.380]   I live in fear every day that I'm going to get hacked.
[01:16:43.380 --> 01:16:45.420]   Well, and that's why I was disappointed, a little disappointed.
[01:16:45.420 --> 01:16:46.420]   Oh, I do too.
[01:16:46.420 --> 01:16:47.940]   I do too.
[01:16:47.940 --> 01:16:52.180]   Yeah, I don't.
[01:16:52.180 --> 01:16:53.180]   That's another question.
[01:16:53.180 --> 01:16:57.860]   Some day, maybe we should sit down because I mean, what Steve talks a lot about prophylaxis.
[01:16:57.860 --> 01:17:03.140]   But I think even Steve acknowledges there's no such thing as secure.
[01:17:03.140 --> 01:17:09.100]   No, you know, another journalist paid to black hat.
[01:17:09.100 --> 01:17:11.380]   You saw that Kevin Ruth story from Fuhr.
[01:17:11.380 --> 01:17:12.380]   Yeah.
[01:17:12.380 --> 01:17:13.380]   Wasn't that wild?
[01:17:13.380 --> 01:17:14.380]   Oh, man, that's scary.
[01:17:14.380 --> 01:17:15.380]   Yeah.
[01:17:15.380 --> 01:17:20.940]   And you know, the moral of that story was he asked the third white hat hacker, well, what
[01:17:20.940 --> 01:17:21.940]   do you do to protect yourself?
[01:17:21.940 --> 01:17:23.460]   He says, you don't worry about it.
[01:17:23.460 --> 01:17:28.620]   He said, you know, you could you could be walking down the street and two martial artists could
[01:17:28.620 --> 01:17:29.980]   come and beat the crap out of you.
[01:17:29.980 --> 01:17:31.140]   There's nothing you can defend against that.
[01:17:31.140 --> 01:17:32.340]   Do you worry about that?
[01:17:32.340 --> 01:17:34.820]   Well, no, he said, that's right.
[01:17:34.820 --> 01:17:36.220]   You're going to be your vulnerable.
[01:17:36.220 --> 01:17:37.220]   Period.
[01:17:37.220 --> 01:17:41.100]   There's nothing you can do about it, but chances are you're not a target.
[01:17:41.100 --> 01:17:48.980]   Now, people in the public eye, people who claim to be security experts or technology experts,
[01:17:48.980 --> 01:17:53.380]   maybe we should be a little more worried.
[01:17:53.380 --> 01:17:56.420]   People are trying to hack and deed us us all the time.
[01:17:56.420 --> 01:18:00.420]   I mean, that's been that's been going on for years for me.
[01:18:00.420 --> 01:18:02.060]   Yeah, me too.
[01:18:02.060 --> 01:18:05.780]   You know, Verizon calls me every couple of months and says, somebody was just calling
[01:18:05.780 --> 01:18:06.780]   us and trying to.
[01:18:06.780 --> 01:18:07.780]   Really?
[01:18:07.780 --> 01:18:10.740]   That's the vulnerability I worry about is the customer service representative.
[01:18:10.740 --> 01:18:12.340]   See, that's the reason I had stories.
[01:18:12.340 --> 01:18:14.700]   It's all it was all social engineering.
[01:18:14.700 --> 01:18:16.620]   It wasn't really technical.
[01:18:16.620 --> 01:18:17.620]   Right.
[01:18:17.620 --> 01:18:19.100]   Well, no, there were two.
[01:18:19.100 --> 01:18:20.100]   One was associate.
[01:18:20.100 --> 01:18:22.020]   He went to two different firms.
[01:18:22.020 --> 01:18:23.460]   One was a social engineering firm.
[01:18:23.460 --> 01:18:26.940]   That was the one who we're a woman called to the recording of a baby playing in the
[01:18:26.940 --> 01:18:30.860]   background saying, he's an overseas and I need to get to himself again.
[01:18:30.860 --> 01:18:34.340]   But the other one was a spearfishing attack, which is how these hospitals get bit, which
[01:18:34.340 --> 01:18:36.020]   is an email that looks real.
[01:18:36.020 --> 01:18:37.020]   Yeah.
[01:18:37.020 --> 01:18:44.140]   But isn't I never I never click on emails or links in Facebook or Twitter.
[01:18:44.140 --> 01:18:45.140]   Yeah.
[01:18:45.140 --> 01:18:46.140]   Yeah.
[01:18:46.140 --> 01:18:47.140]   No, I tell people that.
[01:18:47.140 --> 01:18:50.500]   Oh, I mean, that's what I that has become more and more of my job on the radio.
[01:18:50.500 --> 01:18:55.180]   I would just I just did it this morning on the Bill Handel show in Los Angeles.
[01:18:55.180 --> 01:18:58.940]   Well, we recorded for Friday, but we talked about how because of this ransomware, how
[01:18:58.940 --> 01:19:01.980]   to avoid getting bit and that that's exactly it.
[01:19:01.980 --> 01:19:08.700]   Number one trick is don't believe that email from your sister or your bank or the IRS.
[01:19:08.700 --> 01:19:15.700]   And this is the time of year when the IRS does not send you PDF files or emails.
[01:19:15.700 --> 01:19:16.700]   Yeah.
[01:19:16.700 --> 01:19:21.700]   You know what?
[01:19:21.700 --> 01:19:24.700]   It's completely believable.
[01:19:24.700 --> 01:19:28.700]   You don't have to be a dumb person or an unaware person to think, Oh, the IRS.
[01:19:28.700 --> 01:19:29.700]   It's got an email.
[01:19:29.700 --> 01:19:30.700]   It looks.
[01:19:30.700 --> 01:19:31.700]   I see the seal.
[01:19:31.700 --> 01:19:32.700]   The government says it's from IRS.gov.
[01:19:32.700 --> 01:19:33.700]   Here's your e-filing form.
[01:19:33.700 --> 01:19:34.700]   This year we're going to do it electronically because you like to file electronically and
[01:19:34.700 --> 01:19:36.700]   it's a PDF and you say, great, that's great.
[01:19:36.700 --> 01:19:40.060]   Let me open my PDF and you're done.
[01:19:40.060 --> 01:19:41.580]   I could see I could get bit by that.
[01:19:41.580 --> 01:19:43.900]   You could get bit who wouldn't get bit by that.
[01:19:43.900 --> 01:19:44.900]   Yeah.
[01:19:44.900 --> 01:19:46.300]   It's easy to get bit by.
[01:19:46.300 --> 01:19:50.100]   I'm not going to I'm not going to encourage anybody to send me PDFs.
[01:19:50.100 --> 01:19:54.700]   No, I've said for years and people always got mad at me.
[01:19:54.700 --> 01:19:55.700]   Don't open attachments.
[01:19:55.700 --> 01:19:56.700]   Don't open attachments.
[01:19:56.700 --> 01:20:00.100]   Don't open attachments, even if they're from the IRS because especially from the IRS or
[01:20:00.100 --> 01:20:03.700]   your friends, especially for the IRS.
[01:20:03.700 --> 01:20:04.900]   But so I don't I don't know.
[01:20:04.900 --> 01:20:06.100]   I maybe you're right.
[01:20:06.100 --> 01:20:11.500]   Maybe we should just remember on Saturday during the pre show you went through your spam
[01:20:11.500 --> 01:20:12.500]   box.
[01:20:12.500 --> 01:20:13.500]   Oh, that's so much fun.
[01:20:13.500 --> 01:20:16.100]   And there was some stuff in there that we're looking at like, wow, this is legit.
[01:20:16.100 --> 01:20:20.140]   But it looked legit like the links we should do more because you know, there are simple
[01:20:20.140 --> 01:20:22.420]   things you can do if you have a good email provider.
[01:20:22.420 --> 01:20:25.780]   Gmails are good when they'll strip out malware out of the email.
[01:20:25.780 --> 01:20:28.140]   So you can't click on it.
[01:20:28.140 --> 01:20:29.140]   There's lots of things you can do.
[01:20:29.140 --> 01:20:30.500]   And they warn you about fishing.
[01:20:30.500 --> 01:20:31.500]   They're very good.
[01:20:31.500 --> 01:20:34.580]   I think Google has really become a very good resource for people.
[01:20:34.580 --> 01:20:39.540]   Yes, because they care not because they're just getting data from you.
[01:20:39.540 --> 01:20:41.340]   No, well, okay.
[01:20:41.340 --> 01:20:42.340]   All right.
[01:20:42.340 --> 01:20:43.340]   Wait a minute.
[01:20:43.340 --> 01:20:44.540]   No, it's good PR.
[01:20:44.540 --> 01:20:49.540]   Oh, we'll protect your privacy.
[01:20:49.540 --> 01:20:50.540]   Give us more.
[01:20:50.540 --> 01:20:51.540]   We'll protect your privacy.
[01:20:51.540 --> 01:20:52.540]   Give us more.
[01:20:52.540 --> 01:20:55.660]   We'll protect an apple, by the way, is doing exactly the same thing.
[01:20:55.660 --> 01:21:01.820]   Although I always look at systems that have the better users.
[01:21:01.820 --> 01:21:05.820]   And every time I spoke, I would ask people who, you know, what email are you using?
[01:21:05.820 --> 01:21:07.780]   And everybody would say Gmail in my audiences.
[01:21:07.780 --> 01:21:08.780]   And that was the best audience.
[01:21:08.780 --> 01:21:11.340]   Everybody was doing a tech passion people.
[01:21:11.340 --> 01:21:14.940]   And the same thing, by the way, is happening in self-driving cars.
[01:21:14.940 --> 01:21:21.340]   Watch how Google or how Mercedes or Tesla competes against each other.
[01:21:21.340 --> 01:21:22.580]   Who has more cars?
[01:21:22.580 --> 01:21:23.980]   Ford does, right?
[01:21:23.980 --> 01:21:30.620]   So the data, the amount of data and who is putting the data in the system really matters.
[01:21:30.620 --> 01:21:32.260]   And Gmail has the best users.
[01:21:32.260 --> 01:21:34.220]   So the spam filters work the best.
[01:21:34.220 --> 01:21:39.700]   I sat next to the guy who actually runs the spam filter team on a plane to Paris one
[01:21:39.700 --> 01:21:40.700]   time.
[01:21:40.700 --> 01:21:42.060]   And he told me how it works.
[01:21:42.060 --> 01:21:45.780]   And I don't want to tell you how it works because I don't want to help people get around
[01:21:45.780 --> 01:21:46.780]   the spam filters.
[01:21:46.780 --> 01:21:53.100]   But it works on who has a better rating at putting things in the spam folder.
[01:21:53.100 --> 01:21:56.260]   You asked a provocative question, Jeff.
[01:21:56.260 --> 01:21:57.260]   Ask it again.
[01:21:57.260 --> 01:21:58.260]   What is privacy?
[01:21:58.260 --> 01:21:59.260]   What is privacy anyway?
[01:21:59.260 --> 01:22:01.460]   We keep on presuming that anything about you is private.
[01:22:01.460 --> 01:22:04.500]   That any piece of information someone gets is private.
[01:22:04.500 --> 01:22:05.500]   That's a big presumption.
[01:22:05.500 --> 01:22:10.660]   Privacy has to hinge around the notion, I think, of harm.
[01:22:10.660 --> 01:22:14.380]   That if this is known and if you didn't want it known and now it's known, there's harm
[01:22:14.380 --> 01:22:15.380]   to you.
[01:22:15.380 --> 01:22:17.660]   But that's not true.
[01:22:17.660 --> 01:22:18.660]   That's not true.
[01:22:18.660 --> 01:22:23.020]   If you go to a sporting stadium, there's a camera in the sporting stadium by a company
[01:22:23.020 --> 01:22:25.020]   called Fancam.
[01:22:25.020 --> 01:22:29.940]   And it's a company out of South Africa and it's a very high resolution camera.
[01:22:29.940 --> 01:22:33.900]   You have absolutely no privacy when you enter a sporting stadium.
[01:22:33.900 --> 01:22:35.380]   You sign it away on your ticket.
[01:22:35.380 --> 01:22:36.380]   You sign it away on your ticket.
[01:22:36.380 --> 01:22:37.380]   Robert, hold on.
[01:22:37.380 --> 01:22:38.380]   Hold on.
[01:22:38.380 --> 01:22:39.380]   You're in a public place.
[01:22:39.380 --> 01:22:40.380]   Of course you have no privacy.
[01:22:40.380 --> 01:22:42.700]   There's no such thing as privacy in public.
[01:22:42.700 --> 01:22:47.580]   So again, it's a misnomer to say that when you're in public, someone knows you're there.
[01:22:47.580 --> 01:22:48.580]   That's private.
[01:22:48.580 --> 01:22:49.580]   It's not private at all.
[01:22:49.580 --> 01:22:50.580]   My definition.
[01:22:50.580 --> 01:22:53.940]   But if your wife does a search on a photo and sees you sitting next to you.
[01:22:53.940 --> 01:22:54.940]   Yeah, but I think no.
[01:22:54.940 --> 01:22:55.940]   Here's privacy.
[01:22:55.940 --> 01:22:59.700]   If I'm sitting on the John, I don't want anybody having pictures of me.
[01:22:59.700 --> 01:23:01.220]   I don't want any camera in my bathroom.
[01:23:01.220 --> 01:23:04.380]   How about a new place where a camera's in the bathroom that way?
[01:23:04.380 --> 01:23:05.380]   Right.
[01:23:05.380 --> 01:23:06.380]   You have that privacy.
[01:23:06.380 --> 01:23:09.740]   Except if you bring your smartphone in there.
[01:23:09.740 --> 01:23:11.540]   Is that Robert?
[01:23:11.540 --> 01:23:13.460]   Here's a Robert Struch scobel case.
[01:23:13.460 --> 01:23:16.060]   Nick Milton just wrote his final column for New York Times.
[01:23:16.060 --> 01:23:19.820]   And I'm glad to say after many years, I like Nick, but after many years of whining and
[01:23:19.820 --> 01:23:23.900]   moaning and being dystopian about technology and worrying about it, at the end he kind of
[01:23:23.900 --> 01:23:24.900]   says, "Oh, it's okay.
[01:23:24.900 --> 01:23:25.900]   It's all right."
[01:23:25.900 --> 01:23:30.340]   But it was Nick Milton who called me about a column he wrote when he got all Nickerson
[01:23:30.340 --> 01:23:35.140]   knots, so to speak, because you walked in to Iowa with your glass on in the bathroom.
[01:23:35.140 --> 01:23:36.140]   Right.
[01:23:36.140 --> 01:23:37.140]   Yeah.
[01:23:37.140 --> 01:23:39.540]   And I said to Nick, I said to Nick, number one, Nick, if you think anybody wants a picture
[01:23:39.540 --> 01:23:43.340]   of your junk, especially Robert Scobel, then you are the one who has the problem.
[01:23:43.340 --> 01:23:45.660]   Well, there is a certain amount.
[01:23:45.660 --> 01:23:48.420]   There is a certain amount of kind of moral panic.
[01:23:48.420 --> 01:23:52.020]   To take a picture of your junk, I would have to actually go like that.
[01:23:52.020 --> 01:23:55.260]   There is, I would have to say, okay, glass, take a picture.
[01:23:55.260 --> 01:23:59.220]   A lot, but more to the point, I think a lot of the concerns about privacy are kind of
[01:23:59.220 --> 01:24:02.500]   theoretical, hypothetical, rather than real.
[01:24:02.500 --> 01:24:07.500]   With actual harm, number one, and number two, again, we're stretching privacy now to define
[01:24:07.500 --> 01:24:08.940]   anything about you.
[01:24:08.940 --> 01:24:11.580]   And that is dangerous and that is wrong.
[01:24:11.580 --> 01:24:14.980]   When you are, and as a journalist, I care about the notion of public, because when you
[01:24:14.980 --> 01:24:19.420]   are in a public place doing something, you're responsible for that act in public.
[01:24:19.420 --> 01:24:25.300]   And yes, Robert, if somebody walks into a stadium with their mistress and they start
[01:24:25.300 --> 01:24:28.620]   doing nasty things, you see them, that's their fault.
[01:24:28.620 --> 01:24:32.460]   And you see them, you can go to their wife and say, "I saw your husband doing this."
[01:24:32.460 --> 01:24:38.700]   And yeah, that will be on the internet.
[01:24:38.700 --> 01:24:46.020]   The one thing that the technology is changing what we understand about privacy, because
[01:24:46.020 --> 01:24:53.500]   that company, Fancam, can watch which sporting events you go to and what jersey you're wearing
[01:24:53.500 --> 01:24:59.400]   can see your age algorithmically, can see your gender algorithmically, can see your
[01:24:59.400 --> 01:25:01.700]   sentiment, are you happy or sad.
[01:25:01.700 --> 01:25:06.220]   And it can track, "Hey, oh, you showed up at Taylor Swift concert.
[01:25:06.220 --> 01:25:08.300]   Oh, you showed up at a Warriors game here.
[01:25:08.300 --> 01:25:13.540]   Oh, you showed up at a Giants game on this other stadium on this state."
[01:25:13.540 --> 01:25:20.540]   And so it can start knowing you at some level that we just haven't been used to that knowledge
[01:25:20.540 --> 01:25:22.740]   being studied, right?
[01:25:22.740 --> 01:25:24.660]   I'm in one of those pictures, actually.
[01:25:24.660 --> 01:25:25.660]   Yeah.
[01:25:25.660 --> 01:25:27.020]   Yeah, were you at the Super Bowl?
[01:25:27.020 --> 01:25:28.020]   Yeah.
[01:25:28.020 --> 01:25:30.780]   And then they did one of the Niners last year, which I was--
[01:25:30.780 --> 01:25:32.940]   They have a picture of everybody who was at the Super Bowl.
[01:25:32.940 --> 01:25:33.940]   Every single person.
[01:25:33.940 --> 01:25:36.500]   And you can zoom in at every single person who's at the Super Bowl.
[01:25:36.500 --> 01:25:37.940]   You can see your face.
[01:25:37.940 --> 01:25:39.100]   But you are in a public place.
[01:25:39.100 --> 01:25:40.100]   I mean--
[01:25:40.100 --> 01:25:43.340]   And you signed away your privacy because of TV rights.
[01:25:43.340 --> 01:25:44.340]   Yeah.
[01:25:44.340 --> 01:25:49.380]   The TV right on the stadium wall, it says you have no rights to privacy here because you're
[01:25:49.380 --> 01:25:50.380]   being--
[01:25:50.380 --> 01:25:51.380]   I'm fine.
[01:25:51.380 --> 01:25:54.100]   I don't have rights to-- do I have rights to privacy when I walk down the street?
[01:25:54.100 --> 01:25:55.900]   No, because that's a public place, right?
[01:25:55.900 --> 01:25:56.900]   No, because it's a public place.
[01:25:56.900 --> 01:25:57.900]   Right, right.
[01:25:57.900 --> 01:25:58.900]   Yes.
[01:25:58.900 --> 01:25:59.900]   But now think about the Google self-driving car.
[01:25:59.900 --> 01:26:01.260]   What is it really doing?
[01:26:01.260 --> 01:26:04.780]   It's not just mapping the world in 3D and in a point cloud.
[01:26:04.780 --> 01:26:08.260]   It's watching you.
[01:26:08.260 --> 01:26:13.940]   And think about, OK, right now there's only one out of 100,000 cars that are doing this.
[01:26:13.940 --> 01:26:20.260]   What happens when every car is watching you and is predicting what your next action is?
[01:26:20.260 --> 01:26:21.260]   Because it has to predict your next action.
[01:26:21.260 --> 01:26:23.260]   And can give you a lot as a result.
[01:26:23.260 --> 01:26:24.260]   Yes, that's right.
[01:26:24.260 --> 01:26:25.260]   True.
[01:26:25.260 --> 01:26:26.260]   True.
[01:26:26.260 --> 01:26:28.660]   But this is a scary amount of new data that we have.
[01:26:28.660 --> 01:26:30.660]   And I mean, it's scary.
[01:26:30.660 --> 01:26:31.660]   It's scary.
[01:26:31.660 --> 01:26:32.660]   Come on.
[01:26:32.660 --> 01:26:33.660]   I like Skype speeches.
[01:26:33.660 --> 01:26:37.740]   A third of my hands go up when I ask people, are you freaked out at the end?
[01:26:37.740 --> 01:26:38.740]   And I just talk about stuff.
[01:26:38.740 --> 01:26:42.700]   That means that means we're doing a bad job educating people about where the benefits
[01:26:42.700 --> 01:26:47.220]   are and what controls there are necessary on the risks.
[01:26:47.220 --> 01:26:50.900]   You cannot legislate around the emotion of scary or creepy.
[01:26:50.900 --> 01:26:55.380]   That would be-- because then lots of things are illegal.
[01:26:55.380 --> 01:26:56.540]   I don't like clowns.
[01:26:56.540 --> 01:26:57.540]   Let's outlaw them.
[01:26:57.540 --> 01:26:59.420]   Oh, that sounds a good one.
[01:26:59.420 --> 01:27:00.580]   I'll sign up for that, Bill.
[01:27:00.580 --> 01:27:01.580]   OK, all right.
[01:27:01.580 --> 01:27:02.580]   Mine.
[01:27:02.580 --> 01:27:03.580]   He out.
[01:27:03.580 --> 01:27:05.100]   Outlaw them.
[01:27:05.100 --> 01:27:07.540]   Trump could well be doing that tomorrow considering how where he's going.
[01:27:07.540 --> 01:27:08.540]   But we'll leave that aside.
[01:27:08.540 --> 01:27:09.540]   Let's not.
[01:27:09.540 --> 01:27:10.980]   What is he against clowns?
[01:27:10.980 --> 01:27:13.540]   No, he gets something else today, but we'll leave that aside.
[01:27:13.540 --> 01:27:14.540]   You're going to go to the relationship.
[01:27:14.540 --> 01:27:17.700]   Oh, he pulled a big one.
[01:27:17.700 --> 01:27:23.100]   I think it's really interesting to see this.
[01:27:23.100 --> 01:27:29.140]   The whole Trump candidacy might be revealing the secret wires that are holding up the puppets
[01:27:29.140 --> 01:27:30.140]   who run our country.
[01:27:30.140 --> 01:27:31.140]   I know.
[01:27:31.140 --> 01:27:32.140]   Well, you want to--
[01:27:32.140 --> 01:27:34.140]   And for that, I am grateful.
[01:27:34.140 --> 01:27:35.140]   You're a great person.
[01:27:35.140 --> 01:27:39.380]   Here's an opportunity to open up the Washington Post and just search on the word Trump.
[01:27:39.380 --> 01:27:42.920]   Somebody started this on Twitter today to see how many of us out of public editor Margaret
[01:27:42.920 --> 01:27:44.540]   Sullivan of the New York Times discussion.
[01:27:44.540 --> 01:27:47.620]   Just go to the Washington Post and search for the word Trump and count how many there
[01:27:47.620 --> 01:27:48.620]   are.
[01:27:48.620 --> 01:27:49.620]   OK.
[01:27:49.620 --> 01:27:50.620]   Right?
[01:27:50.620 --> 01:27:51.620]   I'm going to do it right now.
[01:27:51.620 --> 01:27:52.620]   You can show mine here.
[01:27:52.620 --> 01:27:53.620]   No, no, no, do it.
[01:27:53.620 --> 01:27:56.060]   Command F. No, no, no, no, no, no, not a site search.
[01:27:56.060 --> 01:27:57.820]   Oh, just a search the page?
[01:27:57.820 --> 01:27:58.820]   Text search.
[01:27:58.820 --> 01:27:59.980]   Yeah, just search on the page.
[01:27:59.980 --> 01:28:00.980]   Oh, Lordy.
[01:28:00.980 --> 01:28:07.180]   One, two, three, four, five, six, seven, oh, 17 on the front page.
[01:28:07.180 --> 01:28:09.500]   Now, now do Clinton.
[01:28:09.500 --> 01:28:12.820]   Don't forget Sanders.
[01:28:12.820 --> 01:28:14.880]   Clinton has one.
[01:28:14.880 --> 01:28:16.340]   How about Sanders?
[01:28:16.340 --> 01:28:17.780]   Sanders has none.
[01:28:17.780 --> 01:28:20.740]   Who cruises on there?
[01:28:20.740 --> 01:28:21.980]   Let's see.
[01:28:21.980 --> 01:28:25.140]   17, he's Donald's the winner so far.
[01:28:25.140 --> 01:28:26.620]   Cruise zero.
[01:28:26.620 --> 01:28:27.620]   Kasich.
[01:28:27.620 --> 01:28:29.100]   Oh, come on.
[01:28:29.100 --> 01:28:30.100]   Kasich.
[01:28:30.100 --> 01:28:31.100]   Come on.
[01:28:31.100 --> 01:28:32.100]   Let's see Obama.
[01:28:32.100 --> 01:28:33.100]   Obama's got six.
[01:28:33.100 --> 01:28:37.100]   I'll go to the New York Times for the same thing.
[01:28:37.100 --> 01:28:38.100]   Is it the same?
[01:28:38.100 --> 01:28:40.260]   This is fascinating, actually.
[01:28:40.260 --> 01:28:41.260]   This is fascinating, actually.
[01:28:41.260 --> 01:28:42.260]   Yeah.
[01:28:42.260 --> 01:28:46.700]   But now they shouldn't be, thank you for giving up your number.
[01:28:46.700 --> 01:28:48.820]   They shouldn't be censured for that.
[01:28:48.820 --> 01:28:50.380]   They're just covering the news.
[01:28:50.380 --> 01:28:51.380]   How are they?
[01:28:51.380 --> 01:28:53.140]   That's the argument that's going on right now in the business.
[01:28:53.140 --> 01:28:56.340]   No, are they giving, are they giving Lopsided coverage because it's good for ratings, which
[01:28:56.340 --> 01:28:58.700]   is what CBS and CNN say.
[01:28:58.700 --> 01:29:02.500]   Nine, nine mentions of Trump on the New York Times front page.
[01:29:02.500 --> 01:29:03.900]   Hey, one of Clinton.
[01:29:03.900 --> 01:29:10.580]   And notice none of Cruz, one of Sanders.
[01:29:10.580 --> 01:29:12.460]   So it's a little less Lopsided, but not much.
[01:29:12.460 --> 01:29:16.500]   By the way, on the, on the, on the Washington Post, if you also searched for Donald, you'd
[01:29:16.500 --> 01:29:20.700]   have to add that in because there was, oh, if they had the Donald, I have to add the
[01:29:20.700 --> 01:29:22.700]   Donald, it literally does.
[01:29:22.700 --> 01:29:26.260]   Well, we're even covering Trump.
[01:29:26.260 --> 01:29:29.260]   It's a story.
[01:29:29.260 --> 01:29:31.260]   To an extent.
[01:29:31.260 --> 01:29:32.260]   Yes.
[01:29:32.260 --> 01:29:36.180]   And he does already thinks yes, but, but how much did we, are we immediately responsible
[01:29:36.180 --> 01:29:37.380]   for this?
[01:29:37.380 --> 01:29:41.060]   I'm on Google news.
[01:29:41.060 --> 01:29:44.940]   If you just search for Trump, it's 239 million results.
[01:29:44.940 --> 01:29:48.060]   If you search for Clinton, it's 113 million results.
[01:29:48.060 --> 01:29:49.060]   Wow.
[01:29:49.060 --> 01:29:51.380]   I guess you're right.
[01:29:51.380 --> 01:29:54.980]   I mean, that's the main, the chat room saying at some point it becomes not, it becomes commentary,
[01:29:54.980 --> 01:29:55.980]   not news.
[01:29:55.980 --> 01:29:57.780]   So that's true.
[01:29:57.780 --> 01:29:58.780]   Interesting.
[01:29:58.780 --> 01:30:00.700]   Let's see.
[01:30:00.700 --> 01:30:04.540]   Waze is rolling out alerts to tell you when you're driving too fast, but not here in the
[01:30:04.540 --> 01:30:07.620]   US where it's our God given right to drive too fast.
[01:30:07.620 --> 01:30:08.620]   Not yet.
[01:30:08.620 --> 01:30:09.620]   Not yet.
[01:30:09.620 --> 01:30:10.620]   It's not ever.
[01:30:10.620 --> 01:30:11.700]   No, it says it's coming.
[01:30:11.700 --> 01:30:13.420]   I can't drive 55.
[01:30:13.420 --> 01:30:17.100]   Well, you can with ways and it'll tell you that you're not.
[01:30:17.100 --> 01:30:21.300]   It's in Austria, Belgium, Brazil, Columbia, Czech Republic, El Salvador, France, Hungary,
[01:30:21.300 --> 01:30:25.260]   Italy, Latvia, Liechtenstein, why Liechtenstein before the US?
[01:30:25.260 --> 01:30:27.780]   I ask you three roads.
[01:30:27.780 --> 01:30:31.620]   I mean, most cars can do that.
[01:30:31.620 --> 01:30:34.340]   My car tells me where the speed limit is wherever I am.
[01:30:34.340 --> 01:30:36.540]   I've always wondered this, the Leo.
[01:30:36.540 --> 01:30:39.780]   So Waze estimates with brilliant accuracy.
[01:30:39.780 --> 01:30:40.860]   What time am I going to get there?
[01:30:40.860 --> 01:30:43.100]   So Waze clearly knows the speed I'm going to go.
[01:30:43.100 --> 01:30:44.100]   Yes.
[01:30:44.100 --> 01:30:45.100]   And it ate the speed limit.
[01:30:45.100 --> 01:30:47.100]   The world.
[01:30:47.100 --> 01:30:50.500]   So Waze even knows this.
[01:30:50.500 --> 01:30:53.900]   By the way, those are configurable alerts, right?
[01:30:53.900 --> 01:30:55.540]   You don't, you have to say what you're.
[01:30:55.540 --> 01:30:58.900]   Yeah, you can choose the maximum and then or the point of.
[01:30:58.900 --> 01:31:00.740]   Well, my automatic does that.
[01:31:00.740 --> 01:31:01.740]   Right.
[01:31:01.740 --> 01:31:02.740]   My automatic tells me what I'm going to.
[01:31:02.740 --> 01:31:03.980]   That's why it's coming to the US.
[01:31:03.980 --> 01:31:04.980]   It's not.
[01:31:04.980 --> 01:31:08.700]   My automatic tells me when I've stepped on the gas too hard and breaks too hard.
[01:31:08.700 --> 01:31:11.900]   It's kind of a little bit of a prissy boots.
[01:31:11.900 --> 01:31:12.900]   Nudge.
[01:31:12.900 --> 01:31:13.900]   Nudge.
[01:31:13.900 --> 01:31:18.900]   Google's going to drop support for the wallet card.
[01:31:18.900 --> 01:31:21.060]   June 30th, I dropped it a year ago.
[01:31:21.060 --> 01:31:22.060]   I just saw my car.
[01:31:22.060 --> 01:31:23.060]   I never activated it.
[01:31:23.060 --> 01:31:24.060]   Yeah.
[01:31:24.060 --> 01:31:25.060]   Cut it up.
[01:31:25.060 --> 01:31:26.060]   Cut it up.
[01:31:26.060 --> 01:31:27.940]   No, I still have mine.
[01:31:27.940 --> 01:31:33.500]   I had such a hard time canceling a charge on it that I realized they are not really the
[01:31:33.500 --> 01:31:36.860]   wallet card is not a credit card.
[01:31:36.860 --> 01:31:37.860]   They're different.
[01:31:37.860 --> 01:31:38.860]   Yeah.
[01:31:38.860 --> 01:31:41.100]   That's like it's a debit card technically, isn't it?
[01:31:41.100 --> 01:31:42.100]   I don't know what it is.
[01:31:42.100 --> 01:31:45.060]   All I know is I couldn't reverse a charge.
[01:31:45.060 --> 01:31:46.980]   Doesn't it just pass through to a credit card?
[01:31:46.980 --> 01:31:48.340]   I never knew what it is.
[01:31:48.340 --> 01:31:49.340]   That's I think what it is.
[01:31:49.340 --> 01:31:53.140]   I don't think they're regulated at all because, yeah, you have to have a credit card attached.
[01:31:53.140 --> 01:31:54.380]   So it's just really what it is.
[01:31:54.380 --> 01:31:58.300]   It's a card that goes to Google payments, which has a credit card attached to it.
[01:31:58.300 --> 01:32:00.780]   Because I called Google saying, what is this charge?
[01:32:00.780 --> 01:32:03.220]   And you could call Visa and they would have to act on it.
[01:32:03.220 --> 01:32:04.220]   Google said, well, I don't know.
[01:32:04.220 --> 01:32:05.220]   Ask your credit card.
[01:32:05.220 --> 01:32:06.220]   Yeah.
[01:32:06.220 --> 01:32:07.220]   So it's just a pass through.
[01:32:07.220 --> 01:32:08.220]   It's not even a debit card.
[01:32:08.220 --> 01:32:09.220]   It's just a pass through.
[01:32:09.220 --> 01:32:10.220]   It has nothing to do with anything.
[01:32:10.220 --> 01:32:12.820]   I'm not sure that's the right term, but yeah.
[01:32:12.820 --> 01:32:13.820]   Yeah.
[01:32:13.820 --> 01:32:16.260]   Oracle's going to get a little money, at least try to.
[01:32:16.260 --> 01:32:19.740]   Well, another trial against Google.
[01:32:19.740 --> 01:32:26.220]   This is the copyright lawsuit against Google for using Oracle's precious bodily fluids
[01:32:26.220 --> 01:32:27.220]   in Android.
[01:32:27.220 --> 01:32:29.580]   Well, not really, just Java.
[01:32:29.580 --> 01:32:32.140]   Although that's a precious fluid in some jurisdictions.
[01:32:32.140 --> 01:32:40.140]   They're seeking a staggering $9.3 billion, which is almost twice what they paid for.
[01:32:40.140 --> 01:32:45.820]   The whole of son to get Java and other things.
[01:32:45.820 --> 01:32:55.500]   $9.3 billion, they won against SAP, a $1.3 billion verdict in 2010 for something similar.
[01:32:55.500 --> 01:33:02.260]   The judge vacated the decision saying it was overly speculative.
[01:33:02.260 --> 01:33:03.740]   So they didn't get that money.
[01:33:03.740 --> 01:33:06.660]   But this is a new business for Oracle.
[01:33:06.660 --> 01:33:11.260]   $9.3 billion in damages.
[01:33:11.260 --> 01:33:14.740]   Our litigious society.
[01:33:14.740 --> 01:33:16.740]   And Amazon's doing the right thing.
[01:33:16.740 --> 01:33:20.540]   They have banned the bad Type C cables that we were.
[01:33:20.540 --> 01:33:21.540]   Yeah.
[01:33:21.540 --> 01:33:22.540]   Yes.
[01:33:22.540 --> 01:33:23.540]   And thanks to what's in the end.
[01:33:23.540 --> 01:33:24.540]   Benson Long.
[01:33:24.540 --> 01:33:25.540]   Thank you, Benson Leung.
[01:33:25.540 --> 01:33:26.540]   Thank you.
[01:33:26.540 --> 01:33:27.540]   He was a Google employee.
[01:33:27.540 --> 01:33:30.980]   He was testing these Type C cables on Amazon and putting reviews.
[01:33:30.980 --> 01:33:33.660]   Yeah, keep telling you, Google cares.
[01:33:33.660 --> 01:33:34.660]   They care.
[01:33:34.660 --> 01:33:36.620]   At least the engineers care.
[01:33:36.620 --> 01:33:41.820]   But these cables could actually physically damage devices they were plugged into.
[01:33:41.820 --> 01:33:48.820]   So it's appropriate for Amazon to say, well, I guess maybe we shouldn't sell those.
[01:33:48.820 --> 01:33:52.500]   People will still make bad cables, but at least you won't be able to buy them on Amazon.
[01:33:52.500 --> 01:33:53.500]   Type C cables are fine.
[01:33:53.500 --> 01:33:56.740]   In fact, Benson tweeted me or something after we talked about it.
[01:33:56.740 --> 01:34:01.740]   He said that resonant on a test, Type C, Type C is that's not the cables of the problems.
[01:34:01.740 --> 01:34:07.460]   The problems are the Type C to the old USB connector.
[01:34:07.460 --> 01:34:08.460]   And that's the risk.
[01:34:08.460 --> 01:34:09.460]   That's the danger.
[01:34:09.460 --> 01:34:13.420]   Sometimes they leave out a resistor, which means oddly enough that, for instance, charging
[01:34:13.420 --> 01:34:21.900]   a Type C phone from your Apple could mess up your Apple, not the phone.
[01:34:21.900 --> 01:34:22.900]   What else?
[01:34:22.900 --> 01:34:26.540]   Google's a good story from Fortune.
[01:34:26.540 --> 01:34:29.500]   I don't know if it's true, but I like the headline.
[01:34:29.500 --> 01:34:36.180]   Google's moonshot products are turning into a massive pain.
[01:34:36.180 --> 01:34:38.860]   What's that all about?
[01:34:38.860 --> 01:34:39.860]   Nest, I guess.
[01:34:39.860 --> 01:34:41.460]   Well, yeah.
[01:34:41.460 --> 01:34:44.060]   Nest has been a little bit of an issue.
[01:34:44.060 --> 01:34:48.220]   That was when Greg Duffy was up.
[01:34:48.220 --> 01:34:50.940]   Nest and Nest's C.E.
[01:34:50.940 --> 01:34:56.180]   Foreigner CEO of Dropcam is fighting with Nest CEO Tony Fondell.
[01:34:56.180 --> 01:34:58.140]   I think the quote's coming up when you get down.
[01:34:58.140 --> 01:34:59.140]   Is it?
[01:34:59.140 --> 01:35:02.700]   It published Dropcam's revenue, but if you knew a percentage of all of Alphabet's other
[01:35:02.700 --> 01:35:08.500]   bets revenue was brought in by the tiny 100 person Dropcam team that Fondell derides.
[01:35:08.500 --> 01:35:11.340]   Nest itself would not look good in comparison.
[01:35:11.340 --> 01:35:13.900]   So Fondell wants to stick by his statement.
[01:35:13.900 --> 01:35:16.540]   I challenge him to release full financials.
[01:35:16.540 --> 01:35:17.540]   Here's a prediction.
[01:35:17.540 --> 01:35:18.540]   He won't.
[01:35:18.540 --> 01:35:21.580]   What did Fondell say to get that?
[01:35:21.580 --> 01:35:22.580]   Whoa.
[01:35:22.580 --> 01:35:23.580]   Whoa.
[01:35:23.580 --> 01:35:24.580]   Whoa.
[01:35:24.580 --> 01:35:30.700]   I guess Fondell said a good chunk of Nest's struggles are coming from Dropcam.
[01:35:30.700 --> 01:35:33.220]   Is Duffy still employed by Google?
[01:35:33.220 --> 01:35:34.220]   Former CEO of...
[01:35:34.220 --> 01:35:35.220]   Former CEO.
[01:35:35.220 --> 01:35:36.220]   Former CEO.
[01:35:36.220 --> 01:35:39.220]   I was just saying.
[01:35:39.220 --> 01:35:40.220]   Geez.
[01:35:40.220 --> 01:35:41.220]   I love it.
[01:35:41.220 --> 01:35:43.140]   Everybody loves a good fight.
[01:35:43.140 --> 01:35:45.140]   Bit slap.
[01:35:45.140 --> 01:35:46.140]   Okay.
[01:35:46.140 --> 01:35:50.500]   I guess we probably should have led with this, but...
[01:35:50.500 --> 01:35:52.180]   We bear the lead here.
[01:35:52.180 --> 01:35:54.100]   Always bear the lead.
[01:35:54.100 --> 01:35:55.460]   Which lead do you think I buried?
[01:35:55.460 --> 01:35:56.460]   I don't know.
[01:35:56.460 --> 01:35:57.460]   I'm going to try.
[01:35:57.460 --> 01:36:03.180]   Facebook's chatbot plans or Microsoft's chatbot plans or Tae, which inadvertently rude her
[01:36:03.180 --> 01:36:04.180]   ugly head again.
[01:36:04.180 --> 01:36:10.460]   As an engineer at Microsoft screwed up and put Tae back on Twitter.
[01:36:10.460 --> 01:36:12.740]   She got right in for president next.
[01:36:12.740 --> 01:36:14.180]   There we go.
[01:36:14.180 --> 01:36:15.180]   You know what?
[01:36:15.180 --> 01:36:16.180]   That's what this is.
[01:36:16.180 --> 01:36:20.340]   A secret plan to see just how far you can go.
[01:36:20.340 --> 01:36:23.420]   You know, if you thought Donald Trump's skin were actually false, it might be actually
[01:36:23.420 --> 01:36:24.420]   okay.
[01:36:24.420 --> 01:36:25.420]   There.
[01:36:25.420 --> 01:36:31.620]   Just I'm saying don't get the fake tan because that looks orange.
[01:36:31.620 --> 01:36:33.100]   Orange.
[01:36:33.100 --> 01:36:36.700]   So Tae came back accidentally.
[01:36:36.700 --> 01:36:38.700]   Oops.
[01:36:38.700 --> 01:36:42.180]   Sending thousands of tweet replies mostly, you're too fast.
[01:36:42.180 --> 01:36:44.460]   I can't keep up.
[01:36:44.460 --> 01:36:48.260]   And then one of them is profane, so I can't read the whole thing.
[01:36:48.260 --> 01:36:53.060]   I feel like the lamest piece of technology, I'm supposed to be smarter than you, shucks.
[01:36:53.060 --> 01:36:57.780]   Except what it was.
[01:36:57.780 --> 01:37:02.340]   So is Tae is being influenced by the bad words she's hearing.
[01:37:02.340 --> 01:37:03.580]   Garbage in garbage out.
[01:37:03.580 --> 01:37:04.580]   Yeah.
[01:37:04.580 --> 01:37:05.580]   Yeah.
[01:37:05.580 --> 01:37:06.580]   Yeah.
[01:37:06.580 --> 01:37:09.660]   I don't know what this even means.
[01:37:09.660 --> 01:37:12.340]   Tae's speaking the language of the Utes, apparently.
[01:37:12.340 --> 01:37:17.460]   I'd take pics of humans, but I could F with this too.
[01:37:17.460 --> 01:37:23.140]   I don't know what's going on.
[01:37:23.140 --> 01:37:25.540]   Anyway, Microsoft has pulled it again.
[01:37:25.540 --> 01:37:32.340]   It was a mistake.
[01:37:32.340 --> 01:37:34.220]   Tae remains offline while we were making adjustments.
[01:37:34.220 --> 01:37:39.140]   As part of testing, she was inadvertently activated on Twitter for a brief time.
[01:37:39.140 --> 01:37:41.980]   Shucks, I keep missing Tae's outburst.
[01:37:41.980 --> 01:37:42.980]   Yeah.
[01:37:42.980 --> 01:37:45.380]   I'm going to keep an eye on Twitter more.
[01:37:45.380 --> 01:37:48.580]   You need a set of a bot.
[01:37:48.580 --> 01:37:49.580]   What do you think?
[01:37:49.580 --> 01:37:53.860]   The reason I wanted to bring up bots is because everybody's now saying, well, you said voice
[01:37:53.860 --> 01:37:56.420]   is the new platform, at least Jeff Bezos.
[01:37:56.420 --> 01:37:58.980]   Or no, that was Jason corrected me.
[01:37:58.980 --> 01:38:02.660]   That was Nadella said what you said Jason.
[01:38:02.660 --> 01:38:03.660]   Conversation is a platform.
[01:38:03.660 --> 01:38:06.540]   Conversation, not voice, but that's bots, right?
[01:38:06.540 --> 01:38:07.540]   Yeah, that's a bot.
[01:38:07.540 --> 01:38:10.220]   And really bots really means just that the messaging is a platform.
[01:38:10.220 --> 01:38:11.660]   It's absolutely clear.
[01:38:11.660 --> 01:38:16.780]   And that became clearer than ever when all of a sudden I'm using my Android phone and
[01:38:16.780 --> 01:38:22.340]   I get a message pop up from Facebook Messenger saying, you can use this as your text messaging
[01:38:22.340 --> 01:38:23.740]   app now.
[01:38:23.740 --> 01:38:28.340]   They want to be the front and center text messaging app on Android.
[01:38:28.340 --> 01:38:29.500]   Are you using it that way?
[01:38:29.500 --> 01:38:30.900]   Robert, I would guess you are.
[01:38:30.900 --> 01:38:33.100]   I just don't accept text messages.
[01:38:33.100 --> 01:38:34.900]   I say write me on Facebook.
[01:38:34.900 --> 01:38:35.900]   Really?
[01:38:35.900 --> 01:38:37.460]   You don't do messaging.
[01:38:37.460 --> 01:38:41.580]   No identity.
[01:38:41.580 --> 01:38:43.860]   It's much easier to talk to people on Facebook.
[01:38:43.860 --> 01:38:47.660]   The messaging is great until you get as much volume as you do an email and then it's some
[01:38:47.660 --> 01:38:48.660]   mess.
[01:38:48.660 --> 01:38:53.820]   It is, but it's still better than email in a lot of ways, in a lot of ways, not every
[01:38:53.820 --> 01:38:54.820]   way.
[01:38:54.820 --> 01:38:59.940]   I've been really tweaking my email because my email has never been since factory.
[01:38:59.940 --> 01:39:01.620]   I now have a solution.
[01:39:01.620 --> 01:39:02.620]   No, I have a solution.
[01:39:02.620 --> 01:39:03.620]   I finally did.
[01:39:03.620 --> 01:39:04.620]   Maybe I'll share it with it.
[01:39:04.620 --> 01:39:05.620]   That'll be my tool.
[01:39:05.620 --> 01:39:06.620]   Okay, to all right.
[01:39:06.620 --> 01:39:08.300]   Yeah, I'll make it my tool.
[01:39:08.300 --> 01:39:10.180]   I mean, it's not a it's complicated.
[01:39:10.180 --> 01:39:13.700]   I mean, we should talk about Siri kind of things, right?
[01:39:13.700 --> 01:39:18.100]   Which are the foundations of these bots.
[01:39:18.100 --> 01:39:20.260]   I spent a lot of time with Siri.
[01:39:20.260 --> 01:39:23.740]   Siri, by the way, was launched in this bedroom, which is sort of funny.
[01:39:23.740 --> 01:39:24.740]   What?
[01:39:24.740 --> 01:39:25.740]   Yeah.
[01:39:25.740 --> 01:39:29.380]   If you talk to Adam Chire, who started Siri, he said I was the first one to see Siri outside
[01:39:29.380 --> 01:39:30.380]   of Siri.
[01:39:30.380 --> 01:39:32.180]   Before Apple bought it, that's cool.
[01:39:32.180 --> 01:39:36.020]   Yeah, six months before it was released as an app.
[01:39:36.020 --> 01:39:37.020]   Wow.
[01:39:37.020 --> 01:39:38.420]   In this room.
[01:39:38.420 --> 01:39:43.380]   He showed me how Siri works and Siri has some real flaws.
[01:39:43.380 --> 01:39:47.580]   For instance, if you asked Siri, how many people are checked in at the Twit Break House
[01:39:47.580 --> 01:39:52.180]   on 4-square, Siri understands what you've said, no problem.
[01:39:52.180 --> 01:39:54.100]   And 4-square has an answer to that.
[01:39:54.100 --> 01:39:55.100]   There is an answer.
[01:39:55.100 --> 01:39:59.100]   And 4-square has an API, but Apple hasn't written the 80 lines of code that it needs
[01:39:59.100 --> 01:40:00.780]   to hook it up.
[01:40:00.780 --> 01:40:03.940]   So it fails and goes to Bing and gives you a stupid answer, right?
[01:40:03.940 --> 01:40:07.420]   And this happens over and over on different things.
[01:40:07.420 --> 01:40:15.460]   And Adam and Dag Kittleaus are starting a new company called VIV, V-I-V dot AI.
[01:40:15.460 --> 01:40:21.860]   And one of the foundational things that's different about VIV is 4-square can say, hey,
[01:40:21.860 --> 01:40:25.860]   anytime you hear the word 4-square, just shove us all that text and we'll figure it
[01:40:25.860 --> 01:40:27.340]   out, right?
[01:40:27.340 --> 01:40:29.900]   It's more open underneath.
[01:40:29.900 --> 01:40:36.100]   And the code, in Siri, the 80 lines of code is hard coded.
[01:40:36.100 --> 01:40:41.140]   And VIV, the program, writes the code and has research.
[01:40:41.140 --> 01:40:43.260]   It's amazing computer science to watch.
[01:40:43.260 --> 01:40:47.220]   So you type that, you know, how many people are checked in on 4-square.
[01:40:47.220 --> 01:40:52.140]   And it writes the 80 lines of code in one 20th of a second and does all the queries.
[01:40:52.140 --> 01:40:53.300]   And that's interesting.
[01:40:53.300 --> 01:40:54.540]   And then it has a profile.
[01:40:54.540 --> 01:41:00.620]   So if you ask it, hey, can you deliver me a large pepperoni pizza from roundtable?
[01:41:00.620 --> 01:41:04.660]   All of that goes into a profile, which you can see and correct.
[01:41:04.660 --> 01:41:09.260]   So if you ever decide you don't like pepperoni pizza, you can go in there and delete it
[01:41:09.260 --> 01:41:10.860]   or change it.
[01:41:10.860 --> 01:41:13.660]   And that, over time, that makes the system better.
[01:41:13.660 --> 01:41:19.380]   And then it has a really amazing artificial intelligence engine that gets smarter over
[01:41:19.380 --> 01:41:20.380]   time.
[01:41:20.380 --> 01:41:27.900]   So there's lots of teams like this working on this voice problem and fixing the problems
[01:41:27.900 --> 01:41:32.460]   that Cortana and Siri and Google's voice have.
[01:41:32.460 --> 01:41:36.860]   We're going to see some big breakthroughs I think this year on these things.
[01:41:36.860 --> 01:41:42.940]   And it sounds like Microsoft this week showed or today showed off at its conference, its
[01:41:42.940 --> 01:41:43.940]   next versions.
[01:41:43.940 --> 01:41:46.180]   Yeah, Cortana and they're using a--
[01:41:46.180 --> 01:41:47.180]   It's really important.
[01:41:47.180 --> 01:41:49.180]   -- your turn of sticky notes.
[01:41:49.180 --> 01:41:53.140]   If we're wearing glasses and we're-- and we need things like, hey, can you deliver me
[01:41:53.140 --> 01:41:54.140]   a hamburger right now?
[01:41:54.140 --> 01:41:55.140]   Right.
[01:41:55.140 --> 01:41:57.140]   You know, and you need to understand what you're doing and what you want.
[01:41:57.140 --> 01:42:05.060]   The eyes are an interesting battle, though.
[01:42:05.060 --> 01:42:08.700]   I'm reminded of Machai's post on Pinboard.
[01:42:08.700 --> 01:42:09.700]   I used Pinboard.
[01:42:09.700 --> 01:42:15.340]   It was a delicious replacement when Yahoo bought and kind of left delicious to die.
[01:42:15.340 --> 01:42:17.340]   I used it for bookmarking.
[01:42:17.340 --> 01:42:19.140]   We used Pinboard the same way.
[01:42:19.140 --> 01:42:21.140]   It was a delicious compatible system.
[01:42:21.140 --> 01:42:22.140]   Pinboard.in.
[01:42:22.140 --> 01:42:23.140]   So I will, as I go through my day looking at news sources, I post them on Pinboard so
[01:42:23.140 --> 01:42:24.140]   that Jason could put them in the run.
[01:42:24.140 --> 01:42:26.660]   A lot of these stories, that's where they come from.
[01:42:26.660 --> 01:42:29.420]   He does the same thing.
[01:42:29.420 --> 01:42:38.180]   Machai, or Machai, I should say, has written a post on the blog saying, "My heroic and
[01:42:38.180 --> 01:42:41.020]   lazy stand against if this then that."
[01:42:41.020 --> 01:42:42.020]   Yeah.
[01:42:42.020 --> 01:42:45.940]   Apparently, if this then that is going to change their interface.
[01:42:45.940 --> 01:42:51.540]   If this and that is a wonderful, useful tool, equally useful to Pinboard, that lets you
[01:42:51.540 --> 01:42:54.420]   connect if this then that.
[01:42:54.420 --> 01:43:00.020]   For instance, I use if this and that when I pull up out front, my automatic then tweets
[01:43:00.020 --> 01:43:02.020]   it.
[01:43:02.020 --> 01:43:07.180]   If Leo pulls up out front, then tweet on the, I have a bot on Twitter that says, "Leo just
[01:43:07.180 --> 01:43:08.180]   pulled up out front.
[01:43:08.180 --> 01:43:11.700]   It's time to get a show going."
[01:43:11.700 --> 01:43:14.620]   In order for that to work, there has to be an interface between Twitter and if this
[01:43:14.620 --> 01:43:15.620]   and automatic.
[01:43:15.620 --> 01:43:18.020]   There's a three-way interface.
[01:43:18.020 --> 01:43:28.020]   If this and that is changing their API, and starting April 4th, people are going to be
[01:43:28.020 --> 01:43:36.020]   cut off, if they don't reconnect, they have to write the API for if this then that.
[01:43:36.020 --> 01:43:42.500]   Machai says, yesterday I received the following form letter.
[01:43:42.500 --> 01:43:46.660]   Recently, we worked with our partners from if this then that to migrate the improved platform.
[01:43:46.660 --> 01:43:48.460]   Some have chosen not to do so.
[01:43:48.460 --> 01:43:51.820]   Unfortunately, the Pinboard channel did not migrate to the new platform.
[01:43:51.820 --> 01:43:53.460]   We'll be removed April 4th.
[01:43:53.460 --> 01:43:56.660]   Pinboard is one of our favorite services and we're sad to see it go.
[01:43:56.660 --> 01:43:59.980]   We hope down the road it may be back.
[01:43:59.980 --> 01:44:03.260]   Machai says, "Because many of you rely on this and that because this email makes it sound
[01:44:03.260 --> 01:44:07.220]   like I'm the jerk, I feel like I should explain myself."
[01:44:07.220 --> 01:44:12.220]   In a nutshell, if this then that wants me to do their job for him for free and then he
[01:44:12.220 --> 01:44:16.260]   doesn't like the terms of service which essentially say, "We own whatever you do."
[01:44:16.260 --> 01:44:21.900]   Anything you send us we own and we can change it anytime.
[01:44:21.900 --> 01:44:25.100]   He says, "I say nuts to all that.
[01:44:25.100 --> 01:44:33.740]   I'm not going to write all this code for if this then that because they say they own it
[01:44:33.740 --> 01:44:37.500]   and because why should I be doing their work?"
[01:44:37.500 --> 01:44:39.380]   Watch April 4th.
[01:44:39.380 --> 01:44:43.700]   Suddenly channels may start to disappear from if this then that.
[01:44:43.700 --> 01:44:44.820]   There are other services.
[01:44:44.820 --> 01:44:50.980]   I use one called Zapier which is a little bit more of a business focused, less of a consumer
[01:44:50.980 --> 01:44:55.540]   product but does very much the same thing.
[01:44:55.540 --> 01:44:59.980]   I actually will continue to do all the things I do with this and that with Zapier.
[01:44:59.980 --> 01:45:00.980]   Should it be a decision?
[01:45:00.980 --> 01:45:02.900]   How many things have you set up over the years?
[01:45:02.900 --> 01:45:05.940]   How many little bots and things you fill up there say?
[01:45:05.940 --> 01:45:06.940]   They keep going.
[01:45:06.940 --> 01:45:07.940]   Where are you?
[01:45:07.940 --> 01:45:08.940]   You forgot me.
[01:45:08.940 --> 01:45:09.940]   Remember the website F2 Company?
[01:45:09.940 --> 01:45:11.900]   I can't say the whole name.
[01:45:11.900 --> 01:45:13.900]   I love it.
[01:45:13.900 --> 01:45:14.900]   Don't couple me.
[01:45:14.900 --> 01:45:16.980]   Huge hit.
[01:45:16.980 --> 01:45:23.820]   The idea was people would send in corporate memos that were like how F2 company is.
[01:45:23.820 --> 01:45:25.780]   Look at this memo.
[01:45:25.780 --> 01:45:27.980]   Pud once said, "This is the secret to my success.
[01:45:27.980 --> 01:45:31.060]   I create tools that I don't have to do anything.
[01:45:31.060 --> 01:45:34.860]   Once you set it up, the site handles, does everything and I can go home.
[01:45:34.860 --> 01:45:35.860]   I go away.
[01:45:35.860 --> 01:45:36.860]   I go on vacation."
[01:45:36.860 --> 01:45:40.220]   That's kind of what these bots are like is once you set them up they have a life of
[01:45:40.220 --> 01:45:41.220]   their own.
[01:45:41.220 --> 01:45:42.220]   I have bots.
[01:45:42.220 --> 01:45:43.940]   All sorts of stuff going on.
[01:45:43.940 --> 01:45:48.140]   That was one of the great things from this morning's Microsoft announcement is bots.
[01:45:48.140 --> 01:45:49.140]   Bots development.
[01:45:49.140 --> 01:45:50.140]   They're releasing bot development.
[01:45:50.140 --> 01:45:56.580]   Well, that's exactly the story that we're talking about which is this is the new platform.
[01:45:56.580 --> 01:46:00.940]   But I say bots is really about messengers.
[01:46:00.940 --> 01:46:05.620]   I think like this Quartz app we talked about, Jeff, which is the new news app that really
[01:46:05.620 --> 01:46:10.260]   is just a conversation between you and Quartz, well clearly if that isn't an app, that's
[01:46:10.260 --> 01:46:11.260]   a bot.
[01:46:11.260 --> 01:46:12.260]   It's a bot.
[01:46:12.260 --> 01:46:13.260]   Disguises an app.
[01:46:13.260 --> 01:46:14.260]   Well, yes.
[01:46:14.260 --> 01:46:19.660]   And so what I think this really goes, this is where I'm thinking about AI and news, is
[01:46:19.660 --> 01:46:24.420]   that what if Google realized that we basically ask it questions?
[01:46:24.420 --> 01:46:26.220]   Amazon realized we ask questions.
[01:46:26.220 --> 01:46:27.780]   Now sometimes we want to be fed stuff.
[01:46:27.780 --> 01:46:31.660]   But if I want to know something, why should I have to go to the Africa Lookup something?
[01:46:31.660 --> 01:46:33.420]   I should just ask the machine, the machine gives me an answer.
[01:46:33.420 --> 01:46:36.180]   Which by the way, kills brands.
[01:46:36.180 --> 01:46:37.180]   Kills brands dead.
[01:46:37.180 --> 01:46:38.180]   Right.
[01:46:38.180 --> 01:46:42.300]   And so I think that's the information that we want to disintermediate stuff around it.
[01:46:42.300 --> 01:46:43.300]   Right.
[01:46:43.300 --> 01:46:44.300]   But hey, that's life.
[01:46:44.300 --> 01:46:46.380]   That's the word of the day for the internet.
[01:46:46.380 --> 01:46:47.380]   Disintermediation.
[01:46:47.380 --> 01:46:48.380]   Absolutely.
[01:46:48.380 --> 01:46:50.020]   Word of the world decade.
[01:46:50.020 --> 01:46:52.020]   Yes.
[01:46:52.020 --> 01:46:59.140]   And so on the one level, if I ask questions, another level, if my bot anticipates my needs,
[01:46:59.140 --> 01:47:00.220]   I know Jeff likes this.
[01:47:00.220 --> 01:47:01.220]   I know he needs to know this.
[01:47:01.220 --> 01:47:02.220]   He knows these people.
[01:47:02.220 --> 01:47:04.420]   He's going to care about this and get smarter and smarter and smarter.
[01:47:04.420 --> 01:47:10.060]   The things that we see now are incredibly stupid, programmatic and retargeting advertising that
[01:47:10.060 --> 01:47:14.660]   show you those same damn boots time and time and time again, not knowing you bought them.
[01:47:14.660 --> 01:47:15.660]   That's stupid.
[01:47:15.660 --> 01:47:16.660]   Yeah.
[01:47:16.660 --> 01:47:20.820]   But smart bots, you control yourself that anticipate your needs.
[01:47:20.820 --> 01:47:22.060]   But though Robert, watch out.
[01:47:22.060 --> 01:47:27.140]   The only way the bots going to be smart enough is if you share your data with you.
[01:47:27.140 --> 01:47:28.140]   That's true.
[01:47:28.140 --> 01:47:30.020]   Let's take a break.
[01:47:30.020 --> 01:47:31.060]   We're going to get some final words.
[01:47:31.060 --> 01:47:33.500]   Robert Scobull, the Scobullizer.
[01:47:33.500 --> 01:47:35.140]   You'll let Rackspace.
[01:47:35.140 --> 01:47:38.140]   He's a futurist there, but soon to be at UploadVR.
[01:47:38.140 --> 01:47:39.660]   And that is the future.
[01:47:39.660 --> 01:47:40.660]   And what he does?
[01:47:40.660 --> 01:47:41.660]   He's going to the future.
[01:47:41.660 --> 01:47:42.660]   He's a futurist.
[01:47:42.660 --> 01:47:43.660]   I'm still the future.
[01:47:43.660 --> 01:47:44.660]   Yeah.
[01:47:44.660 --> 01:47:47.940]   Cloud's still the future, but VR and the cloud and everything, all together.
[01:47:47.940 --> 01:47:51.220]   And of course, the Scobullizer blog will be back to Jeff Jarvis.
[01:47:51.220 --> 01:47:52.220]   He blogs at buzzmachine.com.
[01:47:52.220 --> 01:47:54.940]   He's a professor of journalism at CUNY.
[01:47:54.940 --> 01:47:59.420]   And my regular co-host on this show was fun having Gina back, wasn't it?
[01:47:59.420 --> 01:48:00.420]   Oh, it was so great.
[01:48:00.420 --> 01:48:01.420]   Last week.
[01:48:01.420 --> 01:48:05.300]   And we'll just have the three musketeers together at five napkins.
[01:48:05.300 --> 01:48:07.020]   And it was just wonderful.
[01:48:07.020 --> 01:48:08.020]   I told her.
[01:48:08.020 --> 01:48:12.500]   And I think she made-- I said, you know, we would love to have you back on.
[01:48:12.500 --> 01:48:14.620]   She's on now monthly, but I'd love to get her on.
[01:48:14.620 --> 01:48:15.620]   Oh, yeah.
[01:48:15.620 --> 01:48:18.340]   Well, but watch out because I'm using her a lot for the New York.
[01:48:18.340 --> 01:48:19.340]   Oh, really?
[01:48:19.340 --> 01:48:20.340]   Good.
[01:48:20.340 --> 01:48:21.340]   Yeah.
[01:48:21.340 --> 01:48:22.340]   Yeah.
[01:48:22.340 --> 01:48:23.340]   Yeah.
[01:48:23.340 --> 01:48:25.100]   So we're going to be smart enough to do that.
[01:48:25.100 --> 01:48:29.940]   We met with Annie today, and we talked about the whole bunch of co-hosts.
[01:48:29.940 --> 01:48:34.620]   And these are the producer of this new show, which I still want to call New Tech City,
[01:48:34.620 --> 01:48:35.620]   but it's up to you.
[01:48:35.620 --> 01:48:37.620]   Well, that's owned by--
[01:48:37.620 --> 01:48:38.620]   Not anymore.
[01:48:38.620 --> 01:48:39.620]   They seeded it.
[01:48:39.620 --> 01:48:40.980]   They don't have it anymore.
[01:48:40.980 --> 01:48:42.420]   It's still own it.
[01:48:42.420 --> 01:48:44.220]   Well, no, you can't own a title.
[01:48:44.220 --> 01:48:45.380]   You can't own a show title.
[01:48:45.380 --> 01:48:46.380]   Oh, well, yeah.
[01:48:46.380 --> 01:48:47.540]   Well, we'll piss off Laura Walker.
[01:48:47.540 --> 01:48:49.860]   She's the brilliant president of the movie.
[01:48:49.860 --> 01:48:50.860]   Oh, OK.
[01:48:50.860 --> 01:48:51.860]   It's a good name for a show.
[01:48:51.860 --> 01:48:52.860]   Not be a good thing about New York.
[01:48:52.860 --> 01:48:55.780]   Start up, see New Tech City, get it.
[01:48:55.780 --> 01:48:56.780]   New York.
[01:48:56.780 --> 01:48:58.420]   But we'd be glad to know.
[01:48:58.420 --> 01:49:01.740]   The list we have so far, without trying, it just happens.
[01:49:01.740 --> 01:49:03.700]   The first half doesn't be a list for all women.
[01:49:03.700 --> 01:49:04.700]   Good.
[01:49:04.700 --> 01:49:06.700]   Just a nice counterbalance to it.
[01:49:06.700 --> 01:49:07.700]   Ladies.
[01:49:07.700 --> 01:49:08.700]   Yes.
[01:49:08.700 --> 01:49:09.700]   All right.
[01:49:09.700 --> 01:49:10.700]   It's be good.
[01:49:10.700 --> 01:49:12.540]   Our show today brought to you by my mattress.
[01:49:12.540 --> 01:49:15.300]   Oh, I love my mattress.
[01:49:15.300 --> 01:49:16.940]   I want to be there right now in my mattress.
[01:49:16.940 --> 01:49:19.620]   Me and my mattress, we got a thing going on.
[01:49:19.620 --> 01:49:22.300]   I sleep with it every night.
[01:49:22.300 --> 01:49:24.780]   Sometimes I sleep with it in the middle of the day, too.
[01:49:24.780 --> 01:49:25.780]   It's that comfy.
[01:49:25.780 --> 01:49:27.780]   It's a Casper.
[01:49:27.780 --> 01:49:32.820]   It's a revolutionizing the mattress business, an online retailer, of premium mattresses
[01:49:32.820 --> 01:49:37.860]   for a fraction of the cost, made right here in the US of A, and by not having resellers
[01:49:37.860 --> 01:49:41.340]   and by not having showrooms, they're, guess what, disintermediating.
[01:49:41.340 --> 01:49:45.900]   They're eliminating the middleman and saving you big money.
[01:49:45.900 --> 01:49:49.180]   This is an absurd-- there I am falling on my mattress.
[01:49:49.180 --> 01:49:52.980]   This is an obsessively engineered mattress at a fair price, long lasting comfort and
[01:49:52.980 --> 01:49:53.980]   support.
[01:49:53.980 --> 01:49:54.980]   And you know what's nice is breathe.
[01:49:54.980 --> 01:49:56.500]   It's cool.
[01:49:56.500 --> 01:50:00.020]   As the summer days come and it gets warmer and warmer, you'll be glad you have a nice,
[01:50:00.020 --> 01:50:05.340]   soft, comfortable, firm yet supple breathing mattress.
[01:50:05.340 --> 01:50:09.020]   Now, I know you're going to say, "Well, I am not buying a mattress site unseen.
[01:50:09.020 --> 01:50:10.660]   I want to try before I buy."
[01:50:10.660 --> 01:50:13.180]   You think trying it for five minutes in a showroom is a good idea.
[01:50:13.180 --> 01:50:14.580]   I got a better deal.
[01:50:14.580 --> 01:50:18.380]   Try it for 100 nights and a couple of naps, too.
[01:50:18.380 --> 01:50:19.740]   Throw those in, too.
[01:50:19.740 --> 01:50:23.580]   If at any time it's free delivery, they come in that really compact box.
[01:50:23.580 --> 01:50:26.980]   Very easy to get up the stairs and then through doors and all of that.
[01:50:26.980 --> 01:50:32.020]   But if any time within 100 days, you say, "I don't want it."
[01:50:32.020 --> 01:50:33.020]   You call them up.
[01:50:33.020 --> 01:50:34.020]   They'll come back.
[01:50:34.020 --> 01:50:35.020]   They'll take it.
[01:50:35.020 --> 01:50:36.020]   You don't have to pack it up or anything.
[01:50:36.020 --> 01:50:37.420]   They'll refund you every penny.
[01:50:37.420 --> 01:50:41.380]   Oh, and by the way, you want to make your casper even better?
[01:50:41.380 --> 01:50:42.380]   Get the pillows.
[01:50:42.380 --> 01:50:45.340]   Oh, do a layer of pillows.
[01:50:45.340 --> 01:50:46.980]   They adapt your movements throughout the night.
[01:50:46.980 --> 01:50:50.540]   I love my pillows or even maybe more important in the mattress.
[01:50:50.540 --> 01:50:53.540]   But the two together, man, that's Nirvana.
[01:50:53.540 --> 01:50:57.980]   Get your casper mattress today, $500 for a twin, $950 for the king size.
[01:50:57.980 --> 01:50:59.340]   That is a great deal.
[01:50:59.340 --> 01:51:03.380]   And you'll save an additional $50 is one of our audience members by just going to Casper
[01:51:03.380 --> 01:51:05.940]   C-A-S-P-E-R.com/Twig.
[01:51:05.940 --> 01:51:11.260]   Don't forget the promo code TWIG to save $50.Casper.com/Twig.
[01:51:11.260 --> 01:51:15.260]   Promo code TWIG, T-W-I-G.
[01:51:15.260 --> 01:51:16.860]   Terms and conditions apply for details.
[01:51:16.860 --> 01:51:21.580]   Visit Casper.com/terms.
[01:51:21.580 --> 01:51:24.420]   Jeff Jarvis, you gave up your number of the week.
[01:51:24.420 --> 01:51:25.420]   You got another one?
[01:51:25.420 --> 01:51:26.420]   I've got tons.
[01:51:26.420 --> 01:51:27.420]   Because I know you.
[01:51:27.420 --> 01:51:28.420]   I know what happened.
[01:51:28.420 --> 01:51:29.420]   You know I'm a number stealer.
[01:51:29.420 --> 01:51:32.220]   I sacrificed numbers for the good of the team.
[01:51:32.220 --> 01:51:33.740]   They call me a number-gler.
[01:51:33.740 --> 01:51:34.740]   Echii.
[01:51:34.740 --> 01:51:39.580]   All right, let's start here.
[01:51:39.580 --> 01:51:44.700]   Recode says that, you know what, contrary to all this, what stupid media say, young
[01:51:44.700 --> 01:51:46.140]   people are not leaving Facebook.
[01:51:46.140 --> 01:51:47.860]   No, of course they're not.
[01:51:47.860 --> 01:51:48.860]   They can't.
[01:51:48.860 --> 01:51:49.860]   No.
[01:51:49.860 --> 01:51:50.860]   They're owned.
[01:51:50.860 --> 01:51:56.140]   In fact, I as a father, remember I reported my daughter was quitting Facebook?
[01:51:56.140 --> 01:51:57.140]   No.
[01:51:57.140 --> 01:51:58.140]   She didn't.
[01:51:58.140 --> 01:52:00.860]   I just saw a post from her the other day.
[01:52:00.860 --> 01:52:04.180]   I thought, oh, I guess Abby decided not to kill her Facebook.
[01:52:04.180 --> 01:52:05.180]   You can't.
[01:52:05.180 --> 01:52:06.180]   Oh, your friends are there.
[01:52:06.180 --> 01:52:08.300]   Who would you talk to differently?
[01:52:08.300 --> 01:52:09.660]   But it is your phone book.
[01:52:09.660 --> 01:52:10.660]   It is your directory.
[01:52:10.660 --> 01:52:11.660]   It is your identity.
[01:52:11.660 --> 01:52:13.460]   And it scouples there.
[01:52:13.460 --> 01:52:14.460]   Absolutely.
[01:52:14.460 --> 01:52:15.460]   Yes.
[01:52:15.460 --> 01:52:16.460]   And so you got to be there.
[01:52:16.460 --> 01:52:18.780]   Are you still big and bullish on the Facebook?
[01:52:18.780 --> 01:52:20.420]   I am.
[01:52:20.420 --> 01:52:23.500]   We're going to get live 360 video this year.
[01:52:23.500 --> 01:52:24.500]   Yes.
[01:52:24.500 --> 01:52:27.060]   And we have live mobile video, which I use all the time.
[01:52:27.060 --> 01:52:30.340]   I did a video in the here mapping car yesterday.
[01:52:30.340 --> 01:52:31.340]   It's awesome.
[01:52:31.340 --> 01:52:32.780]   Did you use the theta?
[01:52:32.780 --> 01:52:33.780]   What did you use?
[01:52:33.780 --> 01:52:36.300]   Oh, no, I just used my phone to take a picture.
[01:52:36.300 --> 01:52:37.300]   Oh, yeah.
[01:52:37.300 --> 01:52:38.900]   I've been using the Facebook app to do that.
[01:52:38.900 --> 01:52:40.860]   But there's new stuff coming.
[01:52:40.860 --> 01:52:42.660]   360 would be cool.
[01:52:42.660 --> 01:52:48.740]   Well, next month at Google I/O and Facebook F8, I would expect some announcements.
[01:52:48.740 --> 01:52:55.940]   Jeff, what would it be if we did like I had a theta and you had a theta and we just
[01:52:55.940 --> 01:52:58.420]   theta together?
[01:52:58.420 --> 01:52:59.420]   Then we had what?
[01:52:59.420 --> 01:53:00.420]   What would we have?
[01:53:00.420 --> 01:53:01.420]   A 720?
[01:53:01.420 --> 01:53:07.100]   We'd have an egotistical exercise like the one that's coming out.
[01:53:07.100 --> 01:53:09.540]   Let's let's say that baby better bandwidth than I have right now.
[01:53:09.540 --> 01:53:10.540]   What happened?
[01:53:10.540 --> 01:53:11.540]   I don't know.
[01:53:11.540 --> 01:53:12.540]   Get naked and now you have a VR porn.
[01:53:12.540 --> 01:53:13.540]   There we go.
[01:53:13.540 --> 01:53:14.540]   Yeah.
[01:53:14.540 --> 01:53:16.860]   Oh, you got you got two way VR porn.
[01:53:16.860 --> 01:53:18.580]   Robert, what are you excited about these days?
[01:53:18.580 --> 01:53:20.740]   Anything you want to share with us?
[01:53:20.740 --> 01:53:21.740]   VR, man.
[01:53:21.740 --> 01:53:23.860]   I'm my Oculus is shipping this weekend.
[01:53:23.860 --> 01:53:27.500]   I have to build myself a PC like you did.
[01:53:27.500 --> 01:53:29.220]   You don't have to build a $5,000 one.
[01:53:29.220 --> 01:53:32.180]   No, I'm probably going to spend a couple grand in that mine.
[01:53:32.180 --> 01:53:35.220]   We're going to finish the build after TNT this afternoon.
[01:53:35.220 --> 01:53:36.980]   It's up, it's running, it came on.
[01:53:36.980 --> 01:53:38.860]   What kind of money in that thing?
[01:53:38.860 --> 01:53:40.980]   Well, we didn't get the minimum.
[01:53:40.980 --> 01:53:41.980]   We got them.
[01:53:41.980 --> 01:53:42.980]   Yeah.
[01:53:42.980 --> 01:53:44.340]   So we're maximum.
[01:53:44.340 --> 01:53:46.140]   How many Nvidia cards did you put in that thing?
[01:53:46.140 --> 01:53:52.460]   Well, so I used Ryan Shrout, a rather who's the editor in chief of PC perspective.
[01:53:52.460 --> 01:53:54.820]   They've been building PCs and reviewing this stuff for years.
[01:53:54.820 --> 01:53:57.660]   So we went with his specs.
[01:53:57.660 --> 01:54:03.940]   We got a very nice Skylake processor, an i7 6700K, 4 gigahertz processor.
[01:54:03.940 --> 01:54:08.220]   He didn't think SLI that Oculus would benefit from SLI.
[01:54:08.220 --> 01:54:10.140]   And there'd be reasons not to do dual cards.
[01:54:10.140 --> 01:54:15.100]   So we just got a top of the line titanium, Nvidia titanium card.
[01:54:15.100 --> 01:54:16.780]   How much was that alone?
[01:54:16.780 --> 01:54:17.780]   I don't.
[01:54:17.780 --> 01:54:18.980]   That's a good question.
[01:54:18.980 --> 01:54:21.820]   Probably $800, $700, $800, something like that.
[01:54:21.820 --> 01:54:24.020]   We try not to show the receipts to Leo.
[01:54:24.020 --> 01:54:25.940]   Well, I know the total.
[01:54:25.940 --> 01:54:27.460]   I know the total.
[01:54:27.460 --> 01:54:35.620]   But it has a very nice half gigabyte, half terabyte SSD on the PCXpress bus, very fast
[01:54:35.620 --> 01:54:43.300]   Samsung Evo 950, with two spinning drives in RAID 1 for speed.
[01:54:43.300 --> 01:54:50.620]   And it's going to be just right for-- and one of those nice new curved 34-inch displays,
[01:54:50.620 --> 01:54:54.020]   because even though you're on the VR, you still need to display that kind of thing.
[01:54:54.020 --> 01:54:55.460]   It's a nice-- it's nice.
[01:54:55.460 --> 01:54:56.460]   All right.
[01:54:56.460 --> 01:54:57.460]   Yeah.
[01:54:57.460 --> 01:55:00.220]   The important part is the Nvidia card, getting a good Nvidia card.
[01:55:00.220 --> 01:55:01.220]   Yeah, no.
[01:55:01.220 --> 01:55:06.860]   In fact, what I said to Ryan is, why don't we get the cheap one, the 970, the minimum,
[01:55:06.860 --> 01:55:11.300]   because everybody's saying that there's going to be this new Pascal platform from Nvidia
[01:55:11.300 --> 01:55:16.300]   in the summer, and that this is going to be light years ahead, et cetera, et cetera.
[01:55:16.300 --> 01:55:18.220]   He said, yeah, maybe.
[01:55:18.220 --> 01:55:19.380]   Get it now.
[01:55:19.380 --> 01:55:20.380]   You got money.
[01:55:20.380 --> 01:55:21.380]   You can buy it again.
[01:55:21.380 --> 01:55:27.460]   What I should do is bring one of the $1,500 oculus that's authorized PCs in, and we should
[01:55:27.460 --> 01:55:28.460]   see if we can--
[01:55:28.460 --> 01:55:29.460]   We compare them.
[01:55:29.460 --> 01:55:32.140]   Yeah, because you're telling me I'm not-- I'm wasting my money.
[01:55:32.140 --> 01:55:36.380]   Well, you're not wasting your money if you're going to use it for other things.
[01:55:36.380 --> 01:55:42.620]   And obviously, having all that fast I/O and a lot of I/O matters for other things, right?
[01:55:42.620 --> 01:55:46.980]   But if you just care about running oculus, it's hard to tell the difference.
[01:55:46.980 --> 01:55:47.980]   Yeah.
[01:55:47.980 --> 01:55:50.620]   But it would be fun comparison to do.
[01:55:50.620 --> 01:55:54.780]   What's a $1,500 experience versus an ultimate experience?
[01:55:54.780 --> 01:55:55.780]   Yeah.
[01:55:55.780 --> 01:55:58.180]   This Titan 2 is a pretty nice sweet card.
[01:55:58.180 --> 01:56:01.660]   They're saying 950 now.
[01:56:01.660 --> 01:56:05.020]   But it booted, and it's pretty, and we're going to put windows on it, and I'm just going
[01:56:05.020 --> 01:56:07.180]   to play Minecraft all the time.
[01:56:07.180 --> 01:56:08.180]   So it's not matter.
[01:56:08.180 --> 01:56:09.180]   There we go.
[01:56:09.180 --> 01:56:10.180]   [LAUGHTER]
[01:56:10.180 --> 01:56:15.900]   I'll-- we're running on a Titan because we've got to get going for TNT, which is up in minutes.
[01:56:15.900 --> 01:56:19.820]   Becky Worley is hosting today, which is really great news.
[01:56:19.820 --> 01:56:20.820]   Yeah, I bet that's--
[01:56:20.820 --> 01:56:21.820]   Yay.
[01:56:21.820 --> 01:56:25.740]   But I will tell you my-- I'll do a tip or something that tells you my mail workflow because I
[01:56:25.740 --> 01:56:30.420]   think I finally got it in a way that I'm-- it's really usable.
[01:56:30.420 --> 01:56:32.900]   None of this Inbox Zero BS.
[01:56:32.900 --> 01:56:39.460]   It's really more about filtering out the junk and sorting stuff so that you know which folder
[01:56:39.460 --> 01:56:41.700]   to look at first and that kind of thing.
[01:56:41.700 --> 01:56:43.460]   But I have a system.
[01:56:43.460 --> 01:56:44.460]   I have a system.
[01:56:44.460 --> 01:56:45.860]   And I'll talk about it.
[01:56:45.860 --> 01:56:47.380]   Maybe on the new screensaver.
[01:56:47.380 --> 01:56:48.500]   We have some time.
[01:56:48.500 --> 01:56:49.500]   Thank you, Jeff Jarvis.
[01:56:49.500 --> 01:56:51.140]   Always a pleasure.
[01:56:51.140 --> 01:56:58.980]   Catch his great books, Geek's Bearing Gifts, Public Parts, all available on the Amazon, buzzmachine.com
[01:56:58.980 --> 01:56:59.980]   for the blog.
[01:56:59.980 --> 01:57:00.980]   We'll see you next week.
[01:57:00.980 --> 01:57:03.860]   Robert Scoble, congratulations on the new gig.
[01:57:03.860 --> 01:57:04.860]   Thank you.
[01:57:04.860 --> 01:57:05.860]   Such a pleasure to see you.
[01:57:05.860 --> 01:57:06.860]   I'm sorry I missed your birthday party.
[01:57:06.860 --> 01:57:07.860]   Yeah.
[01:57:07.860 --> 01:57:12.020]   Lisa was sick as a dog and I didn't want to leave her alone.
[01:57:12.020 --> 01:57:13.780]   I owe you dinner.
[01:57:13.780 --> 01:57:14.780]   Oh, I did.
[01:57:14.780 --> 01:57:16.420]   I bought tickets, didn't I?
[01:57:16.420 --> 01:57:18.420]   Yeah, you did.
[01:57:18.420 --> 01:57:19.420]   Okay.
[01:57:19.420 --> 01:57:21.420]   I'll let you buy me a--
[01:57:21.420 --> 01:57:23.420]   It was a fun party.
[01:57:23.420 --> 01:57:24.420]   --a ginger ale.
[01:57:24.420 --> 01:57:26.180]   Yeah, it looked like it was an awesome party.
[01:57:26.180 --> 01:57:28.500]   I'm sorry I wasn't there.
[01:57:28.500 --> 01:57:29.500]   Thank you so much.
[01:57:29.500 --> 01:57:31.580]   Anytime, Robert, you have a standing invitation.
[01:57:31.580 --> 01:57:33.020]   Wait to see you, Robert.
[01:57:33.020 --> 01:57:34.020]   Anytime.
[01:57:34.020 --> 01:57:35.020]   Yeah, thanks, Jeff.
[01:57:35.020 --> 01:57:36.020]   Love having you.
[01:57:36.020 --> 01:57:37.020]   You're an icon, man.
[01:57:37.020 --> 01:57:38.020]   Yeah.
[01:57:38.020 --> 01:57:39.020]   Both of you are.
[01:57:39.020 --> 01:57:40.020]   Stop it.
[01:57:40.020 --> 01:57:41.020]   Yeah.
[01:57:41.020 --> 01:57:43.020]   You're an icon.
[01:57:43.020 --> 01:57:44.940]   No, you're an icon.
[01:57:44.940 --> 01:57:51.020]   We do this week in Google every Wednesday, 1.30 p.m. Pacific 430 Eastern 2030 UTC on Twitch.
[01:57:51.020 --> 01:57:52.460]   You can watch live if you can't though.
[01:57:52.460 --> 01:57:55.900]   Don't worry on the main audio and video of all of our shows available on our website.
[01:57:55.900 --> 01:58:02.380]   In this case, twit.tv/twig or use a podcatcher on your mobile because it's really an easy
[01:58:02.380 --> 01:58:08.180]   way to get every episode you don't want to miss one or one of those nice, well-made,
[01:58:08.180 --> 01:58:12.500]   highly crafted, Twitter applications, which I can take no credit for.
[01:58:12.500 --> 01:58:14.700]   Our application is lost in the ether somewhere.
[01:58:14.700 --> 01:58:17.820]   It's our third party developers who are doing such a good job.
[01:58:17.820 --> 01:58:19.420]   We thank all of them.
[01:58:19.420 --> 01:58:23.620]   Just search for Twitter on your favorite mobile device or desktop and you'll find one
[01:58:23.620 --> 01:58:26.300]   more Apple TV too.
[01:58:26.300 --> 01:58:27.300]   Thanks for being here.
[01:58:27.300 --> 01:58:28.580]   We'll see you next time on This Week in Google.
[01:58:28.580 --> 01:58:38.580]   [MUSIC]

