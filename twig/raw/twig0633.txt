;FFMETADATA1
title=Nothing About Me Without Me
artist=Leo Laporte, Jeff Jarvis, Ant Pruitt, Cory Doctorow
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2021-10-14
track=633
language=English
genre=Podcast
comment=Federated Twitter, Section 230 reform, Instagram moral panic
encoded_by=Uniblab 5.3
date=2021
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.300]   It's time for Twig this week in Google Stacey's got the week off good news
[00:00:04.300 --> 00:00:09.480]   Oh Corey doctor. Oh is agreed to fill in Jeff Jarvis is also here and Pruitt
[00:00:09.480 --> 00:00:16.060]   We will talk about Facebook Corey solutions. There are fascinating Twitter has a new plan
[00:00:16.060 --> 00:00:24.200]   It looks like it's a pretty good one for kind of a federated Twitter and the words you can't say on
[00:00:24.200 --> 00:00:29.160]   UK TV. It's a pretty long list. It's all coming up next on Twig
[00:00:29.160 --> 00:00:35.280]   Podcasts you love from people you trust
[00:00:35.280 --> 00:00:38.100]   This is twig
[00:00:38.100 --> 00:00:49.080]   This is twig this week in Google episode 633 recorded Wednesday October 13th
[00:00:49.080 --> 00:00:52.840]   2021 nothing about me without me
[00:00:52.840 --> 00:00:56.920]   This episode of this week in Google is brought to you by Akama
[00:00:57.440 --> 00:01:02.800]   Akama powers and protects life online and is changing how we live work and play
[00:01:02.800 --> 00:01:08.340]   See how Akama is unleashing the Internet of possibilities for the biggest brands in the world visit
[00:01:08.340 --> 00:01:13.280]   Akama dot com slash twig today to learn more and by
[00:01:13.280 --> 00:01:17.120]   Melissa the US Postal Service process is more than
[00:01:17.120 --> 00:01:21.520]   98,000 address changes daily is your customer contact up-to-date
[00:01:22.360 --> 00:01:28.600]   Crime Alyssa's APIs in the developer portal. It's easy to log on sign up and start playing in the API sandbox
[00:01:28.600 --> 00:01:36.360]   24/7 get started today with 1000 records clean for free at Melissa dot com slash twit
[00:01:36.360 --> 00:01:38.560]   and by
[00:01:38.560 --> 00:01:40.560]   Noreva Noreva is
[00:01:40.560 --> 00:01:47.960]   Revolutionizing audio for meeting and learning spaces by making it possible to get full room microphone coverage in medium to large spaces
[00:01:48.600 --> 00:01:56.840]   Without the cost and complexity of multi component pro AV solutions, and that's a revolution learn more at noreva.com
[00:01:56.840 --> 00:01:59.600]   slash twit
[00:01:59.600 --> 00:02:09.920]   It's time for twig this week at Google the show we cover the latest world of Google and Facebook and Twitter and media in general and joining us as
[00:02:09.920 --> 00:02:16.040]   Always the townite professor wait a minute. Let me get the get me get the song. Oh no
[00:02:16.040 --> 00:02:18.040]   I gotta get I gotta get
[00:02:18.040 --> 00:02:24.680]   CHAP it's page 16 in the hymnal the Leonard Taal professor for journalistic innovation at
[00:02:24.680 --> 00:02:27.920]   the Craig
[00:02:27.920 --> 00:02:38.320]   Graduate School of Journalism at the City University of New York buzz machine.com hello, Jeff. Hello boss. All right
[00:02:38.320 --> 00:02:40.320]   I'm doing very well. Let me close the hymnal
[00:02:44.160 --> 00:02:46.160]   Hasn't been open lately I think
[00:02:46.160 --> 00:02:50.000]   Your Bible young man
[00:02:50.000 --> 00:02:55.160]   Through it from hands-on photography good day to you aunt
[00:02:55.160 --> 00:03:06.160]   Hello, sir. How you be? Mmm? I am great. We're looking forward to a exciting Giants game on Thursday as we take on the hated Los Angeles Dodgers
[00:03:06.160 --> 00:03:08.280]   It's been a playoff
[00:03:08.280 --> 00:03:15.160]   Spare a polar coaster ride speaking Los Angeles joining us now from his home in Burbank, California
[00:03:15.160 --> 00:03:19.280]   Love saying that Corey doctor. Oh hey Corey
[00:03:19.280 --> 00:03:24.720]   Hey, how are you? I know nothing about sports ball, but I do have a lost lawyer shirt. That's good
[00:03:24.720 --> 00:03:29.480]   You need a lost all your shirt. I have I have a gigante shirt so we can
[00:03:29.480 --> 00:03:35.160]   Fight it. I'm so lucky to have Corey doctor on the show. I look at that and I said that can't be true. We have Corey
[00:03:35.160 --> 00:03:37.280]   Yeah, it's just great. Glad to see you Corey
[00:03:37.280 --> 00:03:42.440]   I think I almost always say yes when they when I get asked so oh well be careful
[00:03:42.440 --> 00:03:48.040]   That point I'm on the road when you were when you were in England
[00:03:48.040 --> 00:03:54.080]   We couldn't get you as easily that's true when posi was first born and stuff, but we Corey's been a long time
[00:03:54.080 --> 00:03:59.540]   Inspiration on this network for since practically since we started Stacy
[00:03:59.540 --> 00:04:03.820]   Since tech TV did we talk to you? Wow? Oh, yeah
[00:04:04.400 --> 00:04:08.680]   Several times I used to you know EFFs offices were around the corner on Shotwell Street
[00:04:08.680 --> 00:04:12.240]   That's right, and I used to just walk over you are the spokes
[00:04:12.240 --> 00:04:19.120]   Spokes model for the electronic frontier foundation like that. Yeah, like that now at pluralistic
[00:04:19.120 --> 00:04:21.080]   net
[00:04:21.080 --> 00:04:23.840]   Which is I I recommended it
[00:04:23.840 --> 00:04:28.520]   I I'm blogged about it not that anybody reads my blog as soon as I saw you move from
[00:04:28.520 --> 00:04:34.240]   Boing-boing over here because I love your links and this is really a traditional link blog where it just a
[00:04:34.240 --> 00:04:43.560]   Link role of great stuff, and I'm really glad that you you do this. So thank you for doing it. You also write on
[00:04:43.560 --> 00:04:46.640]   on medium and
[00:04:46.640 --> 00:04:50.760]   When Jeff heard you were gonna be honest. Oh, we got to talk about dead letters
[00:04:50.760 --> 00:04:55.280]   This was your piece from three days ago on medium
[00:04:55.280 --> 00:04:58.440]   Email could be the last
[00:04:58.440 --> 00:05:02.040]   Federated internet technology alone drew me in but it isn't
[00:05:02.680 --> 00:05:09.360]   And Corey's on Mastodon we are we have a Mastodon instance Twitter social which is federated as well the idea being that
[00:05:09.360 --> 00:05:14.880]   Anybody can run a server, but servers can intercommunicate and so you could follow people on other servers
[00:05:14.880 --> 00:05:23.280]   Just like email you can address them on other servers if you have the fully you know a full fully qualified email domain name and all that stuff
[00:05:23.280 --> 00:05:27.400]   What is the what is the benefit of a federated network?
[00:05:28.960 --> 00:05:35.640]   Well look, you know network effects are really powerful and anytime you start talking about big tech and tech concentration winner
[00:05:35.640 --> 00:05:41.760]   Take all someone's gonna start talking about network effects and go like look you join Facebook because your friends were on Facebook and
[00:05:41.760 --> 00:05:47.240]   Then other people join Facebook because you were on Facebook and that's how Facebook got big and that's why we have winner take all
[00:05:47.240 --> 00:05:48.960]   But it's not true
[00:05:48.960 --> 00:05:56.520]   Because while that's how Facebook got big it's not how it stayed big and the way that it stayed big is by raising the switching costs
[00:05:56.880 --> 00:06:04.120]   So if you leave Facebook you have to convince all of your friends to leave Facebook with you or leave them behind
[00:06:04.120 --> 00:06:12.440]   And actually there was some pretty damning stuff in the new FTC complaint against Facebook where there's these executives emailing Zuck and saying like hey
[00:06:12.440 --> 00:06:18.280]   We're gonna add this photos product now and try to get people to put their family photos in Facebook
[00:06:18.280 --> 00:06:23.880]   So even when they hate Facebook and want to leave they'll stay because the price of leaving will be leaving behind
[00:06:24.120 --> 00:06:28.800]   Your family photos, right? It's it's so network effects are how you get big
[00:06:28.800 --> 00:06:35.160]   But high switching costs are how you take everybody a hostage so that you can stay big and the thing about federation
[00:06:35.160 --> 00:06:39.120]   Is it means you can move around it means that if you know it turns out that
[00:06:39.120 --> 00:06:46.280]   You made a mistake when you helped elect Mark Zuckerberg Pope Emperor of the social internet for three billion people
[00:06:46.280 --> 00:06:52.720]   You can go somewhere else without having to say goodbye to all the people who aren't ready to make the the jump yet
[00:06:53.280 --> 00:06:59.720]   And so federated networks are a way both to safeguard your own kind of digital self-determination
[00:06:59.720 --> 00:07:02.240]   So you can decide how you're gonna live your digital life
[00:07:02.240 --> 00:07:09.240]   But also way to discipline people who might be tempted to try and compromise your interests in favor of theirs
[00:07:09.240 --> 00:07:16.000]   You know like the the reason the thing that you can take away rarely from the with the Facebook whistleblower report is that
[00:07:16.000 --> 00:07:18.560]   Facebook sometimes thinks about what its users want
[00:07:18.960 --> 00:07:22.000]   But if it ever finds a thing that it would make its users life better
[00:07:22.000 --> 00:07:28.560]   But it shareholders lives worse the users lose every time and the reason for that is that it knows
[00:07:28.560 --> 00:07:31.600]   You're not gonna go anywhere else because of the high switching costs, you know
[00:07:31.600 --> 00:07:36.480]   This is that old Lily Tomlin sketch, you know, we don't have to care. We're the phone company, right?
[00:07:36.480 --> 00:07:38.000]   Where else you gonna go?
[00:07:38.000 --> 00:07:40.440]   You know two tin cans and a string
[00:07:40.440 --> 00:07:45.880]   So if you can federate things if you can leave and go somewhere else
[00:07:45.880 --> 00:07:48.720]   Even if you never do it if the option is there
[00:07:48.720 --> 00:07:51.760]   firms treat you better and if they don't
[00:07:51.760 --> 00:07:55.400]   You can do something and so that's why I
[00:07:55.400 --> 00:08:02.440]   Try never to get locked into anyone else's walled garden, you know, I try to try to pursue this publishing strategy
[00:08:02.440 --> 00:08:05.760]   They call posse post-owned sites syndicate everywhere
[00:08:05.760 --> 00:08:09.840]   My readers are obviously like mostly not gonna find me on RSS or my blog
[00:08:09.840 --> 00:08:15.480]   Which are you know federated and open and so everything also gets manually mirrored as Twitter threads and
[00:08:15.480 --> 00:08:22.560]   Macedon threads and Tumblr posts and medium posts and whatever but the permalinks the place where all that stuff lives the canonical thing is
[00:08:22.560 --> 00:08:26.920]   My own site and if I ever referenced something I've ever written
[00:08:26.920 --> 00:08:35.200]   It's always a reference to my own site and not to say the Twitter thread even if the Twitter thread got read more because I want the canon
[00:08:35.200 --> 00:08:40.680]   You know the thing other people refer to the long-term stock that I develop
[00:08:40.960 --> 00:08:44.960]   To be something that I control and that I'm not under the thumb of
[00:08:44.960 --> 00:08:49.000]   Someone at some other firm, you know, even if you liked and trusted Jack
[00:08:49.000 --> 00:08:56.520]   If he gets like if he goes off to like whatever it is he does bow hunt up an ox and has a horrible accident and
[00:08:56.520 --> 00:09:01.560]   And then you know next week like Rupert Murdoch buys the service out
[00:09:01.560 --> 00:09:09.560]   You know, what are you gonna do? Right? So that's why that's why it's really important to at least have the option of an escape patch
[00:09:10.120 --> 00:09:12.560]   Or can I speak a question that came up last week?
[00:09:12.560 --> 00:09:15.640]   Yeah
[00:09:15.640 --> 00:09:21.720]   And bless you you're the greatest warrior. I know for freedom of expression and and I love you for that
[00:09:21.720 --> 00:09:25.680]   So in that I'm not I'm not endorsing what I'm about to say
[00:09:25.680 --> 00:09:31.960]   But right now there's a lot of calls for playing whack-a-mole with bad stuff on the internet
[00:09:31.960 --> 00:09:38.920]   Right and and how do we get rid of of of of January 6 conspiracies and vaccine disinformation and blah blah blah blah
[00:09:39.320 --> 00:09:45.000]   Does a federated world make that impossible to even complete? It's pretty much impossible now anyway
[00:09:45.000 --> 00:09:50.840]   I know that but does it does it make the the the dreams of the authoritarians or
[00:09:50.840 --> 00:09:53.640]   the legislators
[00:09:53.640 --> 00:09:56.320]   In hearings even harder
[00:09:56.320 --> 00:10:01.280]   Well look, I mean when stuff is unambiguously unlawful
[00:10:01.280 --> 00:10:05.240]   There's always gonna be remedies and there's just gonna be like a cost-benefit decision, right?
[00:10:05.240 --> 00:10:09.480]   Like do you want to bother like say say it's illegal to
[00:10:09.480 --> 00:10:13.280]   infringe copyright, which it is right and
[00:10:13.280 --> 00:10:23.000]   example and and you know like say this is a real example actually say your James Joyce's idiot grandson Stephen Joyce
[00:10:23.000 --> 00:10:32.760]   The hundredth anniversary of Blooms day and you send a letter to every pub in Ireland
[00:10:32.760 --> 00:10:37.520]   Say no one gets to read you listen here. Are I gonna come down on you like a ton of bricks?
[00:10:37.520 --> 00:10:46.760]   Technically, it's illegal. I think most pubs where it happened. It didn't didn't affect them, right? So, you know, there's that it's true that
[00:10:46.760 --> 00:10:52.440]   You know, we cannot always enforce all unlawful speech
[00:10:52.440 --> 00:10:56.880]   But if I tell you what if people like organized a
[00:10:57.800 --> 00:11:03.480]   Giant rally to do that, you know say a civil disobedience rally to read to read Ulysses
[00:11:03.480 --> 00:11:08.880]   You know, Stephen Joyce would know where to find them and could get them, you know, could pull the plug on them
[00:11:08.880 --> 00:11:14.560]   So you do get to damp the scale when speeches on law for in any event, right?
[00:11:14.560 --> 00:11:21.160]   If it if so long as it's it has to stay below the threshold of being easily noticed and enforced against but you know
[00:11:21.160 --> 00:11:25.080]   I think that you know when we talk about vaccine mis information or disinformation
[00:11:25.680 --> 00:11:32.360]   Most of that is not illegal, right? So like, you know, this is the thing that whenever we talk about repealing section 230
[00:11:32.360 --> 00:11:34.360]   God help us all take a drink
[00:11:34.360 --> 00:11:36.560]   You know, we are
[00:11:36.560 --> 00:11:43.120]   Mostly people are saying well if if if big platforms had to worry about liability for user speech
[00:11:43.120 --> 00:11:47.360]   Then a bunch of stuff that we don't like wouldn't be there like hate speech or like
[00:11:47.360 --> 00:11:53.880]   Some forms of harassment or vaccine disinformation or whatever none of that speech is illegal
[00:11:54.000 --> 00:11:57.440]   Like I don't know what they think is gonna get them that now, you know firms
[00:11:57.440 --> 00:12:05.000]   Can take the choice to remove that stuff? I personally hope they do if I were running a message board I would but
[00:12:05.000 --> 00:12:12.280]   You know the the reality is that speech that is lawful will take place somewhere and even speech that's unlawful
[00:12:12.280 --> 00:12:16.760]   But hard to detect will take place somewhere, you know, there there are
[00:12:16.760 --> 00:12:20.240]   tables and diners where people are
[00:12:20.840 --> 00:12:27.160]   Planning bank jobs and it's true that if like we could get all of those diners to monitor their
[00:12:27.160 --> 00:12:33.760]   diners speech the eaters speech we could probably prevent a bank job or two at the margins and
[00:12:33.760 --> 00:12:40.200]   If everyone were forced to eat in one giant restaurant then it would be easier to monitor everyone's speech
[00:12:40.200 --> 00:12:41.880]   but like I
[00:12:41.880 --> 00:12:47.600]   Think that there's better ways to prevent bank robberies, you know, I'm not endorsing bank robberies. I am anti-bank robbery
[00:12:47.600 --> 00:12:54.240]   I just don't think that like this is the right approach to to limit unlawful speech
[00:12:54.240 --> 00:13:01.440]   And I think we have to make our peace with their being lawful speech even though we don't like it and learn learn to ignore
[00:13:01.440 --> 00:13:04.800]   bad speech better bad or counter it or
[00:13:04.800 --> 00:13:11.200]   Impose penalties for it right there's social sanction like free speech is not consequence free speech
[00:13:11.200 --> 00:13:15.800]   Right, I can say I never want to talk to you again because of the way you talk
[00:13:16.280 --> 00:13:19.600]   Right and and I can ask my friends to say
[00:13:19.600 --> 00:13:25.760]   Don't talk to this person again because the way they talk, you know, there are consequences that follow from speech
[00:13:25.760 --> 00:13:28.440]   Right someone might decide not to hire you look
[00:13:28.440 --> 00:13:31.320]   I'm like in the midst of applying for US citizenship here
[00:13:31.320 --> 00:13:38.600]   There are a lot of things that I don't post to the internet because I understand that one of the consequences might be that
[00:13:38.600 --> 00:13:45.800]   Someone who works for the immigration service might look at it take it out of context or even understand the context and decide that
[00:13:45.800 --> 00:13:48.240]   I don't have what it takes to be an American. I mean
[00:13:48.240 --> 00:13:54.760]   There are consequences to speech and there should be consequences to speech there just shouldn't be
[00:13:54.760 --> 00:13:56.520]   a
[00:13:56.520 --> 00:14:03.520]   Law against saying odious things there can be other forms of sanction against saying odious things
[00:14:03.520 --> 00:14:08.800]   Well spoken very well said yeah, yeah, I agree under two cents
[00:14:08.800 --> 00:14:14.360]   And and by the way stay James Joyce's idiot grandson passed away some years ago, so you can go
[00:14:14.360 --> 00:14:21.240]   Lie over the dead Nick and next Blooms day go ahead go ahead read a regulist. He's allowed. It's okay
[00:14:21.240 --> 00:14:25.140]   I'm sorry aunt you wanted to ask a question well
[00:14:25.140 --> 00:14:32.040]   He was talking about the the expensive switching costs from getting off of something like Facebook or even Twitter or what have you
[00:14:32.040 --> 00:14:36.120]   You just detailed a lot of different information that shows just how
[00:14:36.120 --> 00:14:44.200]   Bad things could be on these platforms and the benefits of going to something federated yet people aren't
[00:14:44.200 --> 00:14:46.200]   doing it
[00:14:46.200 --> 00:14:51.540]   That's the real problem is a way we can take your photos off of Facebook and put them on Flickr and
[00:14:51.540 --> 00:14:55.880]   Everything else is out there, but people aren't going to do it. So
[00:14:55.880 --> 00:14:58.440]   What's the hang up here?
[00:14:58.440 --> 00:15:01.440]   So I you're you're talking about well
[00:15:01.440 --> 00:15:05.960]   There's two things that are probably accounting for why people are staying there actually three if we want to be really generous
[00:15:05.960 --> 00:15:09.240]   So the generous explanation is maybe people actually like it
[00:15:09.560 --> 00:15:16.000]   You know, there's this kind of economics idea of reveal preferences people what people do they secretly like I think is
[00:15:16.000 --> 00:15:19.240]   You know demonstrably untrue in at least some cases
[00:15:19.240 --> 00:15:23.880]   There's another problem, which is collective action, right?
[00:15:23.880 --> 00:15:31.800]   It may be that you don't like Facebook, but you can't organize all your friends to leave Facebook and so you stay because the
[00:15:31.800 --> 00:15:34.440]   the combination of
[00:15:35.000 --> 00:15:41.280]   Not liking Facebook and the cost of getting everyone to go somewhere else is so high that you can't manage it
[00:15:41.280 --> 00:15:43.080]   And that's where lowering switching costs can really help
[00:15:43.080 --> 00:15:51.480]   So there's a group that we worked with at EFF who are breast cancer pre-vivers. So they have the the BRCA gene and that means that they
[00:15:51.480 --> 00:15:54.520]   are often sick sometimes
[00:15:54.520 --> 00:15:56.720]   Fadily ill
[00:15:56.720 --> 00:16:02.240]   They are at risk of being sick. They're contemplating major surgeries like radical mastectomies
[00:16:02.240 --> 00:16:08.920]   and they have aunts and daughters and mothers and other family members who are sick or died and so there's a lot of trauma there and
[00:16:08.920 --> 00:16:12.400]   Facebook really aggressively courted them to join the platform
[00:16:12.400 --> 00:16:14.160]   It was about a decade ago
[00:16:14.160 --> 00:16:19.280]   There was a real push to bring medical communities into Facebook because they're very sticky right like there are reasons
[00:16:19.280 --> 00:16:21.800]   they're you know once you find your medical group you stay and
[00:16:21.800 --> 00:16:28.800]   One of the members who is not a technologist, but just was curious and smart
[00:16:28.880 --> 00:16:37.240]   She was poking around and she found this huge bug in Facebook where you could enumerate the membership of any group on Facebook without being a member of it
[00:16:37.240 --> 00:16:38.200]   and
[00:16:38.200 --> 00:16:44.680]   This is obviously very alarming for her kind of group. It's alarming more generally Facebook shouldn't work that way
[00:16:44.680 --> 00:16:50.560]   So she took her bug report to Facebook and they said that's not a bug report. It's a feature request
[00:16:50.560 --> 00:16:57.080]   We're not gonna abide by it. It's a won't fix and she made a lot of stink and they said finally, okay
[00:16:57.080 --> 00:17:01.240]   And I guess it's because their ad tech stack benefited from this enumeration thing
[00:17:01.240 --> 00:17:06.560]   But they said finally okay, you can enumerate a group membership and only if you're a member of the group
[00:17:06.560 --> 00:17:10.120]   Which is still not sufficient for them. It's still a big privacy risk
[00:17:10.120 --> 00:17:14.520]   So for years they've been trying to figure out how to get everyone off of Facebook
[00:17:14.520 --> 00:17:18.000]   Now imagine if they could stand up a diaspora instance
[00:17:18.000 --> 00:17:23.760]   Right, which is like this Fediverse alternated to Facebook and they could federate it with Facebook through like an API
[00:17:23.760 --> 00:17:28.000]   Or maybe if Facebook didn't want to collaborate, but if they could you know be assured that
[00:17:28.000 --> 00:17:35.360]   They wouldn't face legal jeopardy. They could like use bots and scrapers to pull messages out of the group and put them in the diaspora
[00:17:35.360 --> 00:17:39.640]   Instance and then take the responses from the diaspora group and put them back into Facebook
[00:17:39.640 --> 00:17:46.120]   That's how Facebook started. They used to do that with MySpace because of course, you know Rupert Murdoch wasn't gonna let his users go willingly
[00:17:46.120 --> 00:17:52.880]   And so Facebook which pitched itself as the pro privacy alternative to MySpace where we only show your data to your friends
[00:17:53.280 --> 00:18:01.000]   Gave people this way to to grab their waiting inbox from MySpace replied to it on Facebook and push it back out with a footer
[00:18:01.000 --> 00:18:04.280]   That said I sent this from Facebook. Why are you still on MySpace, right?
[00:18:04.280 --> 00:18:06.280]   Mm-hmm and
[00:18:06.280 --> 00:18:13.520]   They could do this and they could have a footer on their messages that said this was sent from the pre-viver diaspora instance
[00:18:13.520 --> 00:18:20.280]   Today or you know yesterday 27% of our traffic originated off Facebook once that reaches 60%
[00:18:20.880 --> 00:18:25.840]   we are going to start a timer that lasts for 28 days and then we're gonna sever the link and
[00:18:25.840 --> 00:18:33.240]   Here's how to find out more about joining the group off Facebook and and you know if they could do that they could
[00:18:33.240 --> 00:18:36.200]   resolve that collective action problem and
[00:18:36.200 --> 00:18:42.840]   And rather than try to organize international everyday leaves Facebook day next Wednesday at 3 in the afternoon
[00:18:42.840 --> 00:18:48.880]   They could let people trickle out one at a time in the same way that like you know at one point
[00:18:48.880 --> 00:18:55.760]   You probably had a hotmail account and then you noticed that all your friends had Gmail accounts and eventually you got a Gmail account
[00:18:55.760 --> 00:18:58.280]   You kind of let your hotmail account language, right?
[00:18:58.280 --> 00:19:05.000]   We didn't have international quit hotmail and join Gmail day. We defeated the collective action problem with a low switching cost
[00:19:05.000 --> 00:19:12.520]   Mmm, but Aunt makes an excellent point. I mean diaspora has been around for a decade. I don't see I forgot I had an account
[00:19:12.520 --> 00:19:18.240]   Well, there's but there's no way to but but there's no way to get your friends on to diaspora unless you all do it at once
[00:19:18.240 --> 00:19:25.800]   Yeah, right so you can you can go and sit on Leo's diaspora and hope your friends eventually have the light
[00:19:25.800 --> 00:19:27.800]   Yeah, you know
[00:19:27.800 --> 00:19:35.880]   You know and quit and quit Facebook with you, but like that's that's um a
[00:19:35.880 --> 00:19:39.680]   Really low probability event like it does sometimes happen
[00:19:39.680 --> 00:19:44.080]   You do see surges sometimes of people quitting because stuff gets bad and often
[00:19:44.080 --> 00:19:48.120]   It's a slowly at first and then all at once thing last week a bunch bunch of people quit
[00:19:48.120 --> 00:19:52.440]   What's happened join signal for a little precipitating event, right?
[00:19:52.440 --> 00:19:59.320]   Sometimes that happens and you know signal has this advantage that your WhatsApp identity is your phone number and your signal identity is your phone number
[00:19:59.320 --> 00:20:01.560]   And so the switching costs just super low
[00:20:01.560 --> 00:20:09.560]   Right all you do is install signal and tells you which of your WhatsApp friends have signal accounts and people have criticized signal for this
[00:20:09.560 --> 00:20:12.200]   right for for having this but you know, it's um
[00:20:12.760 --> 00:20:14.760]   It's a mixed blessing
[00:20:14.760 --> 00:20:22.600]   But it does allow people to very easily migrate from one platform to another and again that that kind of makes sure that signal
[00:20:22.600 --> 00:20:24.160]   behaves itself better
[00:20:24.160 --> 00:20:26.160]   It's one of the the best hedges we have
[00:20:26.160 --> 00:20:34.040]   Against Moxie suddenly becoming evil Moxie right which you know like no one is immune to it people
[00:20:34.040 --> 00:20:38.200]   People are really good at kidding themselves, especially when it's like well
[00:20:38.600 --> 00:20:43.360]   Either I make this little compromise or the hundred friends I convinced to quit their jobs are
[00:20:43.360 --> 00:20:48.320]   And come work for me are gonna lose their jobs next week and none of their kids are gonna go to college
[00:20:48.320 --> 00:20:51.600]   Right people are really good at talking themselves into compromises
[00:20:51.600 --> 00:20:57.680]   But if that compromise comes with and then the next day all my users are gonna quit signal because it's so easy to leave
[00:20:57.680 --> 00:21:01.120]   Then maybe that's the thing that stays their hand
[00:21:01.120 --> 00:21:04.480]   Maybe that's the they call it the Ulysses pact, right?
[00:21:04.480 --> 00:21:07.200]   Where you tie yourself to the mass before you sail into the waters
[00:21:07.200 --> 00:21:14.720]   That because because you know you're strong now, but you know you might be weak in the future one conceivable remedy then might be to make
[00:21:14.720 --> 00:21:20.080]   Make migration costs lower make it require Facebook to allow you to do that
[00:21:20.080 --> 00:21:24.880]   I'm sure Facebook prevents you right now from saying hey join me in the bRCA group on
[00:21:24.880 --> 00:21:26.760]   diaspora
[00:21:26.760 --> 00:21:28.200]   Well, you can export your data
[00:21:28.200 --> 00:21:34.080]   But you can't do a real-time link and you can export your data mostly because of GDPR compliance and CCPA compliance
[00:21:34.360 --> 00:21:35.560]   And it's not great
[00:21:35.560 --> 00:21:42.240]   There's no there's not a lot of other places to go because a one-time export is useful if you're like giving your papers to a library
[00:21:42.240 --> 00:21:49.480]   Or if there's another service that that works like it where all your friends are already and you can get your data out and put it back somewhere else
[00:21:49.480 --> 00:21:53.600]   I was just let's not that the access act which was created in the Senate by the
[00:21:53.600 --> 00:21:59.560]   That's what I was just a holy alliance of Josh Holly and Dick Blumenthal and Mark Warner
[00:21:59.920 --> 00:22:05.640]   It's been in committee for two years now. I don't no no no no. No, it's in the house now. Oh, it's in the house now
[00:22:05.640 --> 00:22:10.320]   Yeah, you build there's it's part of a package of five antitrust bills
[00:22:10.320 --> 00:22:17.560]   They had a 32 hour markup session and it's progressing and there's also the DSA and DMA in Europe
[00:22:17.560 --> 00:22:24.760]   So there's actually a lot of action on this and so these are bills that would require the big platforms to expose an API
[00:22:24.760 --> 00:22:27.840]   And you know the problem is who gets to plug into it
[00:22:27.840 --> 00:22:30.760]   So in the hearings oh Lofgren raised some pretty good points like
[00:22:30.760 --> 00:22:38.160]   What if Cambridge Analytica wants to interoperate with Facebook or what if it's the Chinese government, you know and the answer isn't?
[00:22:38.160 --> 00:22:42.200]   Well, I guess we'll just let Facebook keep us safe
[00:22:42.200 --> 00:22:48.360]   From the bad guys because like if our line of defense against Cambridge Analytica is Facebook
[00:22:48.360 --> 00:22:50.360]   I've really bad news for you
[00:22:50.360 --> 00:22:53.480]   Facebook already let Cambridge Analytica get all your data, right?
[00:22:53.480 --> 00:23:00.760]   So maybe maybe instead of letting a boardroom full of heavily conflicted billionaires and Mountain View
[00:23:00.760 --> 00:23:01.840]   decide
[00:23:01.840 --> 00:23:05.760]   Who is and isn't a fit entity to plug into the service?
[00:23:05.760 --> 00:23:09.160]   Maybe we could have like a freestanding privacy law that
[00:23:09.160 --> 00:23:15.760]   Determine what you were allowed to do with that data and so access act actually has some of that access act says
[00:23:15.760 --> 00:23:18.360]   You can't commercialize the data
[00:23:18.680 --> 00:23:25.360]   You can't process the data beyond what is needed to enable communication between your users and Facebook's users
[00:23:25.360 --> 00:23:28.600]   And you have to let users take the data with them
[00:23:28.600 --> 00:23:31.120]   So that that is a pretty good hedge against it
[00:23:31.120 --> 00:23:37.640]   But what would be much better would be if we had a national privacy law that had a meaningful consent regime and
[00:23:37.640 --> 00:23:39.960]   What they call the private right of action?
[00:23:39.960 --> 00:23:46.760]   Which is the right to sue companies that violate the law instead of like writing letters to the Attorney General when you get screwed and
[00:23:46.920 --> 00:23:53.960]   Bagging them to take up your case is the California privacy act the CCPA is that is that a step in the right direction?
[00:23:53.960 --> 00:23:55.960]   It's a step, but it doesn't have the private right of action
[00:23:55.960 --> 00:24:02.760]   Right and the reason it doesn't have the private right of action is that they correctly assessed that if there were a private right of action
[00:24:02.760 --> 00:24:04.760]   the tech platforms would
[00:24:04.760 --> 00:24:06.480]   go
[00:24:06.480 --> 00:24:09.800]   like thermonuclear to stop it because they they are
[00:24:09.800 --> 00:24:12.360]   willing to bet that they can
[00:24:12.840 --> 00:24:17.240]   modify buy off or at least take the temperature of
[00:24:17.240 --> 00:24:20.560]   regulators and lawmakers or
[00:24:20.560 --> 00:24:25.640]   Enforcers that might come after them, but what they don't want is what they have in Europe
[00:24:25.640 --> 00:24:29.640]   Which is the Mac Shrem's problem, so I don't know if you know max. He's a wonderful dude
[00:24:29.640 --> 00:24:38.920]   He was a law student from Austria went to Stanford went back to Europe and was like wait a second Facebook is totally violating European
[00:24:40.120 --> 00:24:46.600]   Privacy law I'm gonna make them give me my data and find out how bad it is and they like stonewalled him and he was like
[00:24:46.600 --> 00:24:50.880]   I've got a law degree and nothing else to do like I can make your life a little bit
[00:24:50.880 --> 00:24:57.440]   And and they they gave him his data and and the
[00:24:57.440 --> 00:25:04.800]   Violations that revealed were the impetus that created some of the largest fines in corporate history anywhere in the world
[00:25:04.800 --> 00:25:10.160]   and now he's going after Facebook and Google again for not complying with the GDPR and
[00:25:10.160 --> 00:25:12.120]   He's brought his case
[00:25:12.120 --> 00:25:18.760]   I believe in Germany because the thing is that one of the ways in which the GDPR is flawed and it's it's like it's got many imperfections
[00:25:18.760 --> 00:25:25.800]   One of the serious ways it's flawed is that Ireland is the tax haven where all the tech companies have their headquarters
[00:25:25.800 --> 00:25:30.640]   It's how like Apple and so on they maintain this fiction that their money is like never touched the earth
[00:25:30.640 --> 00:25:34.160]   It's just like floating in the Irish sea with Stephen Joyce's ashes
[00:25:34.480 --> 00:25:36.480]   and and
[00:25:36.480 --> 00:25:38.480]   and and
[00:25:38.480 --> 00:25:42.560]   Ireland is where as a result the information commissioner's office in Ireland is
[00:25:42.560 --> 00:25:51.720]   The place where cases are heard if you have a complaint against them against the big platforms the big tech companies and because that's where the European HQ is and
[00:25:51.720 --> 00:25:57.760]   The Irish information commissioner's office like they don't even bother putting on pants in the morning
[00:25:57.760 --> 00:26:00.640]   They just like sit around eating breakfast cereal and watching soap operas
[00:26:01.160 --> 00:26:07.800]   like the Germans here like 500 cases a year and like the Irish here like seven and so you know
[00:26:07.800 --> 00:26:13.360]   That's why they don't want the private right of action because if you have to get an information commissioner
[00:26:13.360 --> 00:26:15.120]   to
[00:26:15.120 --> 00:26:19.640]   Intercede or an attorney general or a solicitor general or a DA or someone to intercede on your behalf
[00:26:19.640 --> 00:26:23.480]   They can figure out like even if they can't buy them off they can go like ugh
[00:26:23.480 --> 00:26:26.800]   They're never gonna go nuclear over this tiny little violation
[00:26:26.800 --> 00:26:31.320]   We'll just pretend this part of the law doesn't exist and just and just like you know
[00:26:31.320 --> 00:26:38.280]   Go along merrily and extract some profit that way, but you don't know where there's a you know vindictive
[00:26:38.280 --> 00:26:44.320]   Brilliant once in a generation law student like Max Shrem's sitting in Austria
[00:26:44.320 --> 00:26:47.600]   You know eating versed and planning world domination
[00:26:47.600 --> 00:26:54.000]   He looks like a vegetarian for sure
[00:26:54.760 --> 00:26:57.840]   If the private right of action exists, let's say in privacy
[00:26:57.840 --> 00:27:02.040]   I just smell a little trouble. Will Robinson in that?
[00:27:02.040 --> 00:27:08.000]   That's what the right and parts of the left are using to go after 230 if we only had a private right of action
[00:27:08.000 --> 00:27:11.480]   They all get sued for the speaker in the speech of the public that everything be okay, and of course
[00:27:11.480 --> 00:27:12.680]   That's not the case
[00:27:12.680 --> 00:27:17.240]   But that's what they're saying is Facebook should be able to be sued for anything that anybody says on it
[00:27:17.240 --> 00:27:19.920]   And that of course, yeah, there's a difference though
[00:27:20.440 --> 00:27:27.840]   Because with the so 230 like let's be clear 230 does not exempt Facebook from liability for the things that Facebook says
[00:27:27.840 --> 00:27:30.800]   Facebook right so Facebook if Facebook writes something
[00:27:30.800 --> 00:27:36.520]   Unlawful they think liability for it. They just don't face liability for what other people do and a private right of action
[00:27:36.520 --> 00:27:42.960]   For a privacy law is not about letting you sue Facebook because someone doxed you on Facebook
[00:27:42.960 --> 00:27:48.520]   Right, it's about letting you sue Facebook because Facebook collected information on you without your permission
[00:27:48.640 --> 00:27:53.080]   And so it's not about what other people do on Facebook
[00:27:53.080 --> 00:27:56.080]   It's what people at Facebook do so in that regard
[00:27:56.080 --> 00:27:58.840]   It'd be actually pretty similar to 230 as we know and love it
[00:27:58.840 --> 00:28:02.960]   It would just be the it would cause Facebook to bear
[00:28:02.960 --> 00:28:09.320]   Responsibility for violations of the law that it or its employees engaged in and it would have to have a compliance regime
[00:28:09.320 --> 00:28:13.320]   And you know like I think that there are face bookers who would say but how
[00:28:13.720 --> 00:28:20.800]   Could we possibly have three billion users and hundreds of thousands of employees and all these subcontractors and gather all this information and
[00:28:20.800 --> 00:28:27.120]   Then not inadvertently break a law that says information can't be gathered a process without permission
[00:28:27.120 --> 00:28:31.320]   And like my answer is yeah, you probably can't that's like me saying
[00:28:31.320 --> 00:28:34.480]   You know I'm gonna have a law that if you keep nuclear waste
[00:28:34.480 --> 00:28:41.360]   It has to be safely maintained and you say but I have this leaky swimming pool in my backyard for a little leak
[00:28:41.560 --> 00:28:48.440]   Nuclear waste how am I gonna keep my leaky swimming full full full of nuclear waste if I'm responsible if it leaks
[00:28:48.440 --> 00:28:53.720]   And the answer like just like the you know doctor it hurts when I do that don't do that
[00:28:53.720 --> 00:28:59.760]   Right like maybe the way that we stop Facebook from being creepy and invasive is by
[00:28:59.760 --> 00:29:03.960]   Prohibiting it from gathering information that it cannot meaningfully contain
[00:29:03.960 --> 00:29:10.280]   You write Facebook shouldn't be in charge of how you use Facebook
[00:29:10.800 --> 00:29:12.400]   Yeah
[00:29:12.400 --> 00:29:16.680]   Yeah, that's an article about a really cool little plug-in called unfollow everything
[00:29:16.680 --> 00:29:19.200]   It's chrome plug-in that our British developer made
[00:29:19.200 --> 00:29:26.240]   Yeah, that's right. Yeah, and so this is a really interesting example of how Facebook and other platforms can weaponize
[00:29:26.240 --> 00:29:31.080]   Laws that aren't privacy laws and kind of privacy wash what they're doing
[00:29:31.080 --> 00:29:36.880]   You know they can say oh well like the reason we invoked our terms of service or whatever is because we think you're violating privacy
[00:29:36.880 --> 00:29:43.320]   And you know like the way that we can figure out if someone's violating privacy is if they violated a privacy law
[00:29:43.320 --> 00:29:49.000]   Not because Mark Zuckerberg's lawyers figured out how to shut someone down for a terms of service violation
[00:29:49.000 --> 00:29:53.640]   And then just wave their hands and went privacy privacy privacy that doesn't make it a privacy violation
[00:29:53.640 --> 00:29:55.080]   so
[00:29:55.080 --> 00:30:00.400]   That the unfollow everything this this developer in in the UK sat down a little chrome plug or no
[00:30:00.400 --> 00:30:01.960]   He didn't write the chrome plug-in first first
[00:30:01.960 --> 00:30:06.960]   He just went through Facebook and unfollowed everything all the pages all the friends all the groups
[00:30:06.960 --> 00:30:09.840]   So, you know he's still friends with the friends
[00:30:09.840 --> 00:30:11.760]   They're just not in his timeline in fact
[00:30:11.760 --> 00:30:13.760]   There was nothing in his newsfeed now
[00:30:13.760 --> 00:30:16.600]   He could go and look at what his friends were doing and when he was done
[00:30:16.600 --> 00:30:21.880]   He was done or he could follow them if they were people he wanted to see from but what he didn't get his infinite scroll
[00:30:21.880 --> 00:30:26.680]   So eventually pull to refresh and there'd be nothing new I see it. I've seen it all
[00:30:26.680 --> 00:30:29.840]   Yeah, come to the end of the internet the internet is over
[00:30:30.840 --> 00:30:33.400]   We'll have more internet for you and he loved it
[00:30:33.400 --> 00:30:39.360]   What a great idea yeah, and so then he wrote a plug-in to make it automatic because Facebook makes it hard
[00:30:39.360 --> 00:30:41.360]   he made it easy it's scriptable and
[00:30:41.360 --> 00:30:48.200]   Everybody who used it loved it. They were like this. This is how I like using Facebook like I wanted to quit Facebook
[00:30:48.200 --> 00:30:49.400]   Now I'm glad to use Facebook
[00:30:49.400 --> 00:30:56.680]   I use it less and the time that I spend there is satisfying and so Facebook hidden with the terms of service violation and
[00:30:56.680 --> 00:30:59.960]   They said, you know, you have to take this down
[00:31:00.160 --> 00:31:06.880]   You swore on your on your mother's grave when you signed our terms of service that you wouldn't do stuff that upset our shareholders
[00:31:06.880 --> 00:31:10.680]   you've broken your promise you're kicked off Facebook and
[00:31:10.680 --> 00:31:14.480]   You that those terms of service are still binding on you
[00:31:14.480 --> 00:31:19.760]   Don't think that just because you're not a Facebook user you can't you can go ahead and make Facebook plugins
[00:31:19.760 --> 00:31:22.960]   You cannot you the terms of service prohibit you forever
[00:31:22.960 --> 00:31:28.160]   Don't even think about about making a Facebook plug-in ever again, and here's the thing
[00:31:28.160 --> 00:31:34.640]   You know when Zuck posted his like internal rebuttal to the whistleblower. He said like it's it's stupid
[00:31:34.640 --> 00:31:39.160]   Why would we make Facebook in a way that deliberately made people unhappy?
[00:31:39.160 --> 00:31:46.560]   We don't want unhappy users advertisers don't want unhappy users either and he's right that if there was a way to make
[00:31:46.560 --> 00:31:52.240]   His advertisers and his shareholders happy that didn't make the users unhappy
[00:31:52.720 --> 00:32:00.440]   He would all of the things being equal prefer his users to be happy, but if there's a way to be happier on Facebook while using it less
[00:32:00.440 --> 00:32:07.080]   That's a thing that his advertisers and shareholders that are a lot more. Yeah, there are a lot more
[00:32:07.080 --> 00:32:09.960]   You know
[00:32:09.960 --> 00:32:11.800]   For Square for their own interest there
[00:32:11.800 --> 00:32:16.960]   They don't care if you're unhappy if the alternative is you don't use Facebook as much right and so you know
[00:32:16.960 --> 00:32:19.760]   It's kind of a little existence proof and it's it's proof that
[00:32:20.440 --> 00:32:26.760]   You know if we are to have a Facebook. That's a good Facebook, which some people will say is possible
[00:32:26.760 --> 00:32:30.840]   I'm a skeptic. I am a zucker vegan, but some people say that it's possible
[00:32:30.840 --> 00:32:38.440]   We can't leave Facebook in charge of it like there has to be at the very least there has to be an escape hatch
[00:32:38.440 --> 00:32:40.880]   There has to be a way for you to configure Facebook
[00:32:40.880 --> 00:32:47.440]   So that it serves your interests and not Facebook shareholders interest because that at least will be the thing at the boardroom table
[00:32:47.880 --> 00:32:50.000]   when everyone's sitting around planning a new
[00:32:50.000 --> 00:32:56.040]   Algorithmic tweak and someone says you know, I think this is gonna make the users unhappy and someone else says
[00:32:56.040 --> 00:33:02.960]   What are they gonna do? We're the phone company. We don't have to care the other one goes some kid in England's gonna write a plug-in and
[00:33:02.960 --> 00:33:09.640]   Then they're all like oh yeah, no, it's not gonna work. Huh? Okay. We'll do something different and if they go ahead and do the stupid thing
[00:33:09.640 --> 00:33:15.760]   Some kid in England gets to write a plug-in you get to undo the dumb thing they did and the way you make Facebook
[00:33:15.760 --> 00:33:21.920]   Do this is a digital regulator of some sort some it's a couple of things so one thing we could do is
[00:33:21.920 --> 00:33:27.760]   There's there's probably gonna be an anti-trust settlement in Facebook's future or at least a chance for it
[00:33:27.760 --> 00:33:32.200]   Facebook is probably gonna cry uncle at a certain point and offer a settlement to
[00:33:32.200 --> 00:33:39.840]   Regulate us says Facebook regulate us. Yeah, right? Well, it depends if they do that from a position to strengthen weakness
[00:33:39.840 --> 00:33:42.720]   I mean they regulate us the Facebook version of regulate us is
[00:33:43.160 --> 00:33:49.400]   Please impose a bunch of rules that will cost us 1% of our annual turnover to comply with but will be so expensive that no one
[00:33:49.400 --> 00:33:51.400]   Can ever enter the market and compete with us, right?
[00:33:51.400 --> 00:33:52.680]   No, that's good
[00:33:52.680 --> 00:33:54.680]   Right
[00:33:54.680 --> 00:34:00.800]   Yeah, yeah, the first preference is no rules the second preferences rules only they can comply with right right but but
[00:34:00.800 --> 00:34:06.520]   If they if they throw in the towel right if they if they say like we're willing to entertain a settlement then the FTC
[00:34:06.520 --> 00:34:10.820]   It's a great you got a special master from now on you know your adult supervision
[00:34:11.320 --> 00:34:17.440]   Anytime you're gonna threaten someone with any kind of lawsuit over copyright patent in terms of service
[00:34:17.440 --> 00:34:21.160]   Torxious interference with contract cyber security whatever
[00:34:21.160 --> 00:34:27.720]   You just got to weave it under the special master's nose and they got to make sure that you are not using this anti-competitive
[00:34:27.720 --> 00:34:33.360]   Lee that there's like a bona fide thing because Facebook will tell you quite truthfully that there are a lot of people
[00:34:33.360 --> 00:34:37.160]   Facebook defends you against right like they have a whole division full of hard-working
[00:34:37.600 --> 00:34:45.360]   Really smart good at their job people who block a bajillion scams a day and hackers and information thieves and
[00:34:45.360 --> 00:34:50.520]   Identity thieves and whatever they just none of those people's job is to defend you against Facebook
[00:34:50.520 --> 00:34:58.200]   There's a precedent for this the FTC's consent decree with Microsoft put a special master in place who would be a good special master for Facebook
[00:34:58.200 --> 00:35:05.160]   That that that makes so Microsoft special master was a fellow. We know and love named Lawrence Lessig that was pretty cool. That works. Yeah, I
[00:35:05.800 --> 00:35:11.880]   Mean Mac Shrem's yeah, there you go. Somebody really somebody really
[00:35:11.880 --> 00:35:16.680]   We really finally import a good Austrian to our political apparatus
[00:35:16.680 --> 00:35:21.840]   You know after that after the unbroken string of dismal Austrian starting with Von Hayek and Schwarzenegger
[00:35:21.840 --> 00:35:29.440]   We'd we'd finally get a really great Austrian. I think this bet you could argue the special master was good for the society
[00:35:29.440 --> 00:35:31.440]   But it was good for Microsoft in the long run
[00:35:32.000 --> 00:35:37.200]   dinner, I mean, it's I mean I think the thing that was good for Microsoft was that they
[00:35:37.200 --> 00:35:43.400]   Managed to get a judge to overturn the order that would have broken them up. That's what's safe. That was the victory. Yeah. Yeah
[00:35:43.400 --> 00:35:49.440]   But you know what like it wasn't an all an all-out defeat for us either for the for the public interest because
[00:35:49.440 --> 00:35:53.800]   Being dragged through anti-trust hell for seven years was hard on Microsoft. Yeah
[00:35:53.800 --> 00:36:01.840]   The Bill Gates deposition that went viral on VHS in which Gates just loses it and just it's like hours of him being
[00:36:01.840 --> 00:36:02.680]   like
[00:36:02.680 --> 00:36:08.880]   Petulant and idiotic and you know like just just awful and and humiliating and it's you know
[00:36:08.880 --> 00:36:10.880]   It's on YouTube. You should look at it now
[00:36:10.880 --> 00:36:14.840]   That really changed the internal calculus like when you talked to
[00:36:14.840 --> 00:36:21.480]   Microsoftes who were executives who were top people about why Microsoft didn't crush Google the way they crushed Netscape
[00:36:21.480 --> 00:36:24.400]   Because they could have done it just as easily
[00:36:24.400 --> 00:36:28.120]   They say we didn't want to end up in front of the FTC again
[00:36:28.120 --> 00:36:33.360]   Yeah, and and when and you know in 2019 Cara Swisher asked Gates
[00:36:33.360 --> 00:36:40.600]   How come you let Google buy Android? How come you didn't buy Android? He said oh we were distracted by the antitrust stuff
[00:36:40.600 --> 00:36:45.080]   But the antitrust case ended seven years for the Android acquisition
[00:36:45.080 --> 00:36:47.000]   What he meant was that seven years later?
[00:36:47.000 --> 00:36:52.560]   We were so traumatized and worried of being tied to the you know
[00:36:52.560 --> 00:36:57.040]   Grill of the FTC's pickup truck and driven up and down a gravel road
[00:36:57.040 --> 00:37:01.720]   That we just didn't want to do stuff that was gonna look bad
[00:37:01.720 --> 00:37:07.920]   And you know Google never went through that and you know Google has made the best search engine that there ever was and
[00:37:07.920 --> 00:37:10.460]   I don't want to see Google disappear
[00:37:10.460 --> 00:37:13.760]   Google I want Google to like
[00:37:13.760 --> 00:37:16.760]   Stop acting like antitrust law is in the thing
[00:37:16.760 --> 00:37:21.400]   I want Google to be afraid of the public interest being asserted against it
[00:37:21.400 --> 00:37:27.480]   I want Google to be the Google that it was back in like 2003 when Larry and Sergey came and spoke at a Kevin Warbach conference and
[00:37:27.480 --> 00:37:29.920]   Said look guys. Here's the thing you need to know
[00:37:29.920 --> 00:37:32.800]   We're gonna be the best company
[00:37:32.800 --> 00:37:37.080]   We can be because all it takes to switch away from a search engine is to change your bookmarks
[00:37:37.080 --> 00:37:44.480]   And so all we're gonna be committed to from now on is just making you as happy as possible and not being evil
[00:37:44.480 --> 00:37:46.360]   Right and and you know
[00:37:46.360 --> 00:37:50.280]   I want that Google back and the way we get that Google back is by making them afraid
[00:37:50.440 --> 00:37:56.360]   That if they don't do it that they will face meaningful enforcement consequences that will do to them
[00:37:56.360 --> 00:38:02.840]   What happened to Bill Gates what happened to IBM for 12 years and made them unwilling to make their own operating system?
[00:38:02.840 --> 00:38:09.960]   So they got Bill Gates to make an operating system for them when the PC came out. I want them to be worried that being
[00:38:09.960 --> 00:38:16.200]   ostentatiously terrible has consequences even if you have sought high switch-in costs
[00:38:16.840 --> 00:38:24.360]   Cory doctor. Oh is our guest. So is it pleasure to have Cory on his website pluralistic net? What's the latest book? Oh?
[00:38:24.360 --> 00:38:31.000]   Well the latest book is the paperback let me see if I can find it the paperback of a tax surface
[00:38:31.000 --> 00:38:38.720]   So this was the third good out. Yeah, I came out last week and I just got the German edition of it in the mail like half an hour ago
[00:38:38.720 --> 00:38:43.520]   I just went and picked it up. What's German for a tax surface? I don't remember
[00:38:44.240 --> 00:38:46.360]   It's not you know dine surface in one attack
[00:38:46.360 --> 00:38:51.880]   Hang on a second
[00:38:51.880 --> 00:38:57.040]   They like to completely change titles. Yeah, well, we do the same thing we do that looks never work. Yeah
[00:38:57.040 --> 00:39:05.200]   Yeah, it's a dirty secret that the original title of thus fake there a suster there zerath Ustra in German is like do you want fries with that?
[00:39:05.200 --> 00:39:08.640]   Not true kids not true
[00:39:10.160 --> 00:39:17.600]   Called our stunt our stunt our stunt. Yeah, I am vorvert von edrich Noden. Oh
[00:39:17.600 --> 00:39:20.480]   Yeah
[00:39:20.480 --> 00:39:27.520]   Forward for me. Yeah, it's got a beautiful cover too. It's it's a it's a gorgeous package. They've actually just reissued the whole
[00:39:27.520 --> 00:39:32.560]   Trilogy in German with matching livery. It's very beautiful. Nice. Oh, yeah
[00:39:32.560 --> 00:39:37.680]   And I just closed a deal with my publisher for four novels in 2023 and 2024
[00:39:38.160 --> 00:39:44.000]   I've got a nonfiction book coming out in 22. I don't know how you have so much energy. It's crazy
[00:39:44.000 --> 00:39:46.640]   Yes, seriously person. I swear
[00:39:46.640 --> 00:39:52.800]   I so hard for me to switch from teach brain to podcast brain to research brain to write brain to twitter brain
[00:39:52.800 --> 00:39:57.280]   How how do you manage your day? I go with anxiety
[00:39:57.280 --> 00:40:03.600]   But I cope with anxiety by writing right by by working like that's how I numb myself to anxiety
[00:40:03.600 --> 00:40:06.800]   So I got a lot done in the last two years
[00:40:07.840 --> 00:40:10.480]   You know, I find that this is often the case that it is some
[00:40:10.480 --> 00:40:14.800]   Personality flaw that drives people to be great artists. I don't know
[00:40:14.800 --> 00:40:19.680]   I don't know why that is let's take a little break a lot more with with great dr
[00:40:19.680 --> 00:40:23.760]   Rose and his various personality flaws all of which are to our benefit
[00:40:23.760 --> 00:40:28.720]   Jeff Jarvis we know what his problem is and we're gonna we're good for hot man
[00:40:28.720 --> 00:40:33.280]   Ju must be watching the show because he has invoked moral panic in the New York times
[00:40:33.280 --> 00:40:38.400]   We'll talk about that in just a little bit and also the man in charge of the moral panic button
[00:40:38.400 --> 00:40:42.000]   Here aunt Pruitt from hands on a photography
[00:40:42.000 --> 00:40:46.480]   You think i'm joking Corey. He actually has well. Well, I'm sure we'll get to that
[00:40:46.480 --> 00:40:48.000]   There it is
[00:40:48.000 --> 00:40:51.600]   The moral panic button I showed it a brought to you by akama
[00:40:51.600 --> 00:40:59.920]   A name I know everybody knows if you're a big company about to do a big product announcement
[00:40:59.920 --> 00:41:02.880]   You know millions of people all over the internet are going to be watching it
[00:41:03.120 --> 00:41:07.120]   Who do you who do you choose to be your cdn you choose akama?
[00:41:07.120 --> 00:41:14.720]   Every single time but akama is more than just a cdn akama powers and protects life online
[00:41:14.720 --> 00:41:18.880]   And is changing how we live work and play if you want to be on the cutting edge of innovation
[00:41:18.880 --> 00:41:22.800]   You need to be operating at the edge of the internet and no one could get you there better
[00:41:22.800 --> 00:41:30.480]   Than akama akama has ten times the locations of the nearest competitor 4,000 points of presence all over the world
[00:41:30.800 --> 00:41:34.080]   Which means you are always closer to your end user
[00:41:34.080 --> 00:41:38.480]   Thanks to akama and akama is more than just a cdn
[00:41:38.480 --> 00:41:43.280]   It stops some of the most dangerous threats launched at the internet and everyone online every day
[00:41:43.280 --> 00:41:51.360]   Their unrivaled edge platform intelligence sees more internet conditions in order to avoid bottlenecks and defend at the edge
[00:41:51.360 --> 00:41:56.240]   Akama has built the largest most sophisticated edge platform in the world
[00:41:56.720 --> 00:42:01.120]   So that the biggest innovators in the world can power and protect their greatest ambitions
[00:42:01.120 --> 00:42:07.040]   Akama's experts and threat researchers are on the front lines of protecting and delivering digital experiences their
[00:42:07.040 --> 00:42:12.240]   proximity and scale helps developers build better apps and puts experiences closer
[00:42:12.240 --> 00:42:17.040]   to their customers in short akama keeps your digital experiences
[00:42:17.040 --> 00:42:19.840]   Closer to your users and threats
[00:42:20.400 --> 00:42:29.280]   farther away your customers will get the content the apps the sites the video they need without lag interruption or latency even during unexpected traffic spikes
[00:42:29.280 --> 00:42:35.600]   You can prepare for those spikes in demand. You can optimize resources to provide the best experience for your customers
[00:42:35.600 --> 00:42:39.400]   And of course as always you'll be amazed by akama's unparalleled
[00:42:39.400 --> 00:42:48.000]   Performance you'll be one network hop away from 85 of the world's internet users. That's no one can make that claim
[00:42:48.000 --> 00:42:54.560]   That's pretty amazing akama gives you the power to innovate right at the edge because your logic your functions have deployed and active at the
[00:42:54.560 --> 00:43:01.360]   Right where your end users are the nearest proximity you're getting the fastest end user experience all around the globe
[00:43:01.360 --> 00:43:04.960]   And akama makes it simple to build at the edge using javascript
[00:43:04.960 --> 00:43:14.400]   So you can innovate in real time and you you get low latency access to data for custom code at the edge akama can optimize your api traffic delivery for edge applications too
[00:43:15.200 --> 00:43:17.760]   I know you know akama. I know you know their reputation
[00:43:17.760 --> 00:43:23.920]   It's not just it's not just us though. Akama is trusted by all top get this all
[00:43:23.920 --> 00:43:27.200]   Top 50 global media companies all
[00:43:27.200 --> 00:43:35.360]   Top 20 global e-commerce companies all top 50 global telecom carriers over 500 banks globally
[00:43:35.360 --> 00:43:43.280]   Including the top 25 in the us and the top 22 of the top 25 in europe in the middle east and probably those other three
[00:43:43.440 --> 00:43:48.480]   They just wish they were at akama. Akama is there powering and protecting digital experiences in a way
[00:43:48.480 --> 00:43:53.600]   No one else can 10 times locations of competitors for the fastest customer experience
[00:43:53.600 --> 00:44:00.400]   Available the market leader in cdn and video delivery and web performance d-dos prevention web application firewalls
[00:44:00.400 --> 00:44:07.040]   No one can compete with akama when it comes to setting you up for success and scalability online
[00:44:07.040 --> 00:44:10.640]   So check it out akama.com/twig
[00:44:11.120 --> 00:44:14.080]   Learn more about akama and how they power and protect life online
[00:44:14.080 --> 00:44:18.320]   Give your customers the best possible experience online see for yourself what life is like
[00:44:18.320 --> 00:44:22.320]   With akama Akama a k a m ai.com
[00:44:22.320 --> 00:44:25.040]   Slash twig we thank akama so much for
[00:44:25.040 --> 00:44:31.440]   Supporting this week in google. Thank you for supporting us by using that address that way. They know you saw it here akama
[00:44:31.440 --> 00:44:33.760]   dot com
[00:44:33.760 --> 00:44:35.040]   slash
[00:44:35.040 --> 00:44:36.240]   twig
[00:44:36.240 --> 00:44:38.080]   Farhad manju writing
[00:44:38.080 --> 00:44:40.320]   This is all about this goes back to that facebook
[00:44:40.320 --> 00:44:42.800]   story writing uh
[00:44:42.800 --> 00:44:44.800]   an opinion piece in the new york times
[00:44:44.800 --> 00:44:51.920]   Literally says the word moral panic just for you jeff the moral panic on the show
[00:44:51.920 --> 00:44:56.080]   In gulthing
[00:44:56.080 --> 00:45:00.880]   Instagram and actually you know he says what you've been saying jeff
[00:45:00.880 --> 00:45:03.680]   he does you know
[00:45:03.920 --> 00:45:08.720]   We were talking a lot about hoggins testimony in front of congress last week
[00:45:08.720 --> 00:45:17.600]   He says as a pundit i find hoggins proposal to raise the minimum age for using social media to be a reasonable precaution
[00:45:17.600 --> 00:45:23.120]   She also made a strong case for lawmakers and regulators to impose radical transparency on facebook
[00:45:23.120 --> 00:45:29.760]   But as a parent of kids just a couple shy ears shy of teenage and my concerns are more immediate
[00:45:30.160 --> 00:45:35.440]   Should I let my kids get smartphones at some point and explore the wilds of instagram tick tock
[00:45:35.440 --> 00:45:40.880]   And whatever actually cool internet things kids are using now i've never heard of is so at what age
[00:45:40.880 --> 00:45:47.120]   And he says the answer that almost every parent except maybe uh kori gives i don't know
[00:45:47.120 --> 00:45:51.600]   And i don't know does your daughter have a smartphone kori is she on instagram?
[00:45:51.600 --> 00:45:54.080]   He does
[00:45:54.080 --> 00:45:56.880]   So you know like i have never managed to do this
[00:45:57.600 --> 00:46:00.480]   But the person i know who's managed this most gracefully
[00:46:00.480 --> 00:46:05.280]   And i actually haven't asked if he's managed to keep it up is my friend benjamin rosenbaum who's uh
[00:46:05.280 --> 00:46:08.320]   Another science fiction writers debut novel came out this year
[00:46:08.320 --> 00:46:12.160]   Uh, and we've written together and his wife is a
[00:46:12.160 --> 00:46:15.120]   cognitive behavioral therapist
[00:46:15.120 --> 00:46:17.520]   And their family has this rule
[00:46:17.520 --> 00:46:25.600]   Where anyone can play a yellow card on anyone else oh for being like being not great
[00:46:26.240 --> 00:46:30.640]   And once there are three yellow cards accumulated and i don't know the period like a week say
[00:46:30.640 --> 00:46:35.040]   Uh, it turns into a red card and no one's allowed to use their devices
[00:46:35.040 --> 00:46:39.520]   In the i guess now and lockdown would be different, but when they were all home together
[00:46:39.520 --> 00:46:43.280]   So all the devices go away everyone eats meals together
[00:46:43.280 --> 00:46:49.280]   The wait this just if you get a red card everybody stops using everybody everybody in the house
[00:46:49.280 --> 00:46:55.840]   So it treats the problems of isolation and technology use as a social problem
[00:46:55.920 --> 00:46:59.120]   Among a community and not an individual dysfunction
[00:46:59.120 --> 00:47:03.120]   That's a whole for a kid that could be a little bit
[00:47:03.120 --> 00:47:07.200]   I guess that's your fault too, but then they stop right
[00:47:07.200 --> 00:47:10.160]   Right, I mean i it's it's
[00:47:10.160 --> 00:47:14.880]   So what it does is it provides this guy so he had a couple of small kids at the time
[00:47:14.880 --> 00:47:18.800]   So it gave them a kind of game theoretical like uh
[00:47:18.800 --> 00:47:25.280]   Thermonuclear button right where either one of them could force the other one to lose their device for however long
[00:47:25.280 --> 00:47:27.280]   So prisoners dilemma
[00:47:27.280 --> 00:47:30.080]   I thought that made one too. Do I know it was a mom?
[00:47:30.080 --> 00:47:33.520]   And it but it was part on the parents. Yeah, right so like you
[00:47:33.520 --> 00:47:37.040]   You I don't know if you're all parents, but you know like
[00:47:37.040 --> 00:47:39.760]   When you're a parent right there are times where you're like
[00:47:39.760 --> 00:47:42.240]   balancing priorities between work and
[00:47:42.240 --> 00:47:46.720]   Paying attention to your kid or even leisure and playing attention to your kid
[00:47:46.720 --> 00:47:50.800]   Right? Your kid wants to do something or want something from you and you're like
[00:47:50.800 --> 00:47:53.360]   Watching some moustache tv
[00:47:53.360 --> 00:47:56.080]   a book or tired or whatever and um
[00:47:56.080 --> 00:48:01.440]   If your kid can yellow card you oh my god and take away your phone at night
[00:48:01.440 --> 00:48:10.000]   For a week. That's revolutionary. Yeah, so I have never had the guts to do it. No, but but Ben is
[00:48:10.000 --> 00:48:13.360]   Remarkably well adjusted as are his kids
[00:48:13.360 --> 00:48:18.400]   And the the book I believe is called unearth. I should look it up here
[00:48:19.680 --> 00:48:21.680]   I have it right here the unraveling
[00:48:21.680 --> 00:48:24.640]   Unraveling that's it. Yeah, I blurbed it
[00:48:24.640 --> 00:48:28.880]   I just couldn't remember what it was called because I read it as a electronic manuscript where it didn't have a cover
[00:48:28.880 --> 00:48:35.200]   So I didn't have to look at the cover read it. It's a superb novel super weird and amazing and big far future comedy of manners
[00:48:35.200 --> 00:48:37.680]   And social unrest
[00:48:37.680 --> 00:48:40.320]   I wonder if they have yellow cards in this one because
[00:48:40.320 --> 00:48:46.640]   Every person in this has nine parents that could really be a pro that's right. That's right. That can be like three bodies
[00:48:46.720 --> 00:48:52.000]   Everyone's got like three or four bodies as well. It's quite an amazing. It's like one of these big
[00:48:52.000 --> 00:48:56.400]   You know weird science fiction novels that just uh like
[00:48:56.400 --> 00:49:02.560]   Starts you at the bottom of a mine shaft 10 miles underground and then rockets you to the surface at 100 miles an hour
[00:49:02.560 --> 00:49:05.600]   And you just got to like grab on and hold on to it and like
[00:49:05.600 --> 00:49:07.760]   Figure out where it's going
[00:49:07.760 --> 00:49:11.600]   His family are like super well adjusted at least from what I can tell they live in Switzerland now
[00:49:11.600 --> 00:49:13.040]   So a couple of times when I've been out there
[00:49:13.040 --> 00:49:17.920]   I've gone and hung out with them and they seem like a very well adjusted group of people and you know, I think
[00:49:17.920 --> 00:49:20.080]   odd
[00:49:20.080 --> 00:49:31.600]   Yeah, well, I mean they used to you can put you could be self-ad
[00:49:31.600 --> 00:49:34.160]   For a long time they then they moved to I think his wife is Swiss
[00:49:34.160 --> 00:49:39.360]   And they moved to Switzerland, but he's um, you know, he's one of these guys with the nike you that could boil water
[00:49:39.360 --> 00:49:41.440]   you know and like his
[00:49:42.560 --> 00:49:49.920]   He's really like into being very thoughtful and also utray and I always wished I'd had the guts
[00:49:49.920 --> 00:49:55.680]   To do what he did or at least be like more mindful and the thing I think the genius of what he did with his kids
[00:49:55.680 --> 00:49:58.400]   Is that he did it to himself too
[00:49:58.400 --> 00:50:02.880]   Right the the thing that always determined that my kid was going to be a screen zombie is that i'm a screen zombie
[00:50:02.880 --> 00:50:03.920]   right
[00:50:03.920 --> 00:50:09.520]   Right like we have all these adorable and slightly horrifying photos of my kid when she was like, you know
[00:50:09.520 --> 00:50:12.000]   a larva
[00:50:12.400 --> 00:50:15.520]   Sitting like across my chest while I blogged, you know snoozing
[00:50:15.520 --> 00:50:20.400]   You know, like if you grow up under those circumstances, you're gonna want to like
[00:50:20.400 --> 00:50:22.880]   Find out what's on the other side of the screen, right?
[00:50:22.880 --> 00:50:26.080]   Like that's my cat's walk on your keyboard, right? Because you pay attention to it
[00:50:26.080 --> 00:50:30.320]   So they're gonna pay attention to it, you know, and so yeah, it's um
[00:50:30.320 --> 00:50:37.280]   I can't say that i'm thrilled with how anyone in my family including me use our devices
[00:50:39.040 --> 00:50:43.040]   Far hot i have to say i've late i have had harder and harder time agreeing with
[00:50:43.040 --> 00:50:47.360]   Ever ever since he became an opinion columnist which is which is true of me too
[00:50:47.360 --> 00:50:52.160]   Yeah, that's why this one's so but i think his point is not is not wrong. He's the question
[00:50:52.160 --> 00:50:55.840]   He says is social media a danger to teenagers
[00:50:55.840 --> 00:51:01.040]   I'll actually extend that a danger to society and he says we have no idea. That's the answer
[00:51:01.040 --> 00:51:04.400]   And i think he's probably right we don't we don't know the times
[00:51:05.040 --> 00:51:10.400]   Like a day before which he quotes by laurin steinberg headline is does instagram harm girls?
[00:51:10.400 --> 00:51:12.080]   No one actually knows
[00:51:12.080 --> 00:51:14.720]   This is the to me the key of the whole discussion now
[00:51:14.720 --> 00:51:19.760]   Is we desperately need research on impact and the only way we get research on impact is by having data
[00:51:19.760 --> 00:51:24.240]   And that that's what the regulators should be pressing the companies for
[00:51:24.240 --> 00:51:31.760]   Is transparency of data for this research to occur because we're we're making up all kinds of interventions and laws
[00:51:31.760 --> 00:51:34.640]   um and and moral panics
[00:51:35.200 --> 00:51:40.400]   Not knowing what's actually happening and and the fear is you can get to this point where you say comic books are hurting everybody
[00:51:40.400 --> 00:51:45.920]   Comic books are gonna screw up the world comic books are awful or movies or there's a there's a great he does he says
[00:51:45.920 --> 00:51:54.160]   Rock music rap music disco video games ebonics political correctness all have generated magic which is
[00:51:54.160 --> 00:51:58.880]   In the past if i may synthesize these two conversations though it does seem there's a way
[00:51:59.440 --> 00:52:05.280]   a way clear to regulating facebook regulating twitter regulating youtube which is
[00:52:05.280 --> 00:52:11.680]   Let let the data flow, you know let others do studies and release your studies
[00:52:11.680 --> 00:52:15.680]   Uh, uh, I love the idea of some sort of ombudsman or
[00:52:15.680 --> 00:52:21.760]   A master who can master who can say you know and data portability critical. I mean those things
[00:52:21.760 --> 00:52:25.600]   Don't break up these companies don't really inhibit these companies dramatically
[00:52:26.000 --> 00:52:29.120]   But give us some say potentially create a lot of innovation
[00:52:29.120 --> 00:52:31.680]   If you if i would say i would have an api
[00:52:31.680 --> 00:52:34.880]   Uh imagine what can be done with it?
[00:52:34.880 --> 00:52:41.520]   Yeah, so like I think that I think there's a lot to that. I I mean the the low hanging fruit is just
[00:52:41.520 --> 00:52:46.160]   prohibiting facebook from stopping people from figuring out how facebook works
[00:52:46.160 --> 00:52:51.280]   Right, that's that's like there is lots of other stuff we could do about like making facebook tell us how it works
[00:52:51.520 --> 00:52:56.160]   But you know there's this ongoing lawsuit with um, new york universities engineering department
[00:52:56.160 --> 00:53:03.680]   Where they make a free open browser plugin called ad observer that uh takes um a grab of every ad you see
[00:53:03.680 --> 00:53:07.040]   And uh and puts it in a thing called ad observatory
[00:53:07.040 --> 00:53:12.320]   And then researchers go and they look and they see whether or not facebook is um adhering to the promises
[00:53:12.320 --> 00:53:18.160]   It made about blocking paid political disinformation and they're not right and and facebook has
[00:53:18.960 --> 00:53:21.280]   Sent legal threats to ad observer to shut it down
[00:53:21.280 --> 00:53:24.160]   Uh looks like they might drag them into court at this point
[00:53:24.160 --> 00:53:30.480]   Uh, they argue that they're violating the term service that they're uh compromising user privacy
[00:53:30.480 --> 00:53:34.800]   It's categorically untrue. These are free and open plugins. It's my facebook
[00:53:34.800 --> 00:53:36.800]   I'm saving stuff from my facebook
[00:53:36.800 --> 00:53:38.320]   But this is
[00:53:38.320 --> 00:53:43.600]   The facebook is trying to stop its own users from telling researchers what happens with what they're seeing
[00:53:43.600 --> 00:53:44.800]   Yeah
[00:53:44.800 --> 00:53:46.800]   And so you know this is
[00:53:46.800 --> 00:53:48.000]   Right
[00:53:48.000 --> 00:53:50.000]   Yeah, but this isn't asking open source
[00:53:50.000 --> 00:53:51.600]   I'm not scraping
[00:53:51.600 --> 00:53:55.520]   Well, I guess I am scraping facebook, but i'm doing it on my own facebook's the stuff I see
[00:53:55.520 --> 00:53:59.440]   You're just taking pictures of what's on your screen, right? You're just grabbing the
[00:53:59.440 --> 00:54:03.760]   They can stop the one from your screen. Yeah, they can't stop it technologically
[00:54:03.760 --> 00:54:05.120]   I mean they could try
[00:54:05.120 --> 00:54:08.400]   Right, but you know this is the thing about a platform with three billion users
[00:54:08.400 --> 00:54:13.200]   Is you got three million one in a million or three thousand one in a million use cases every day
[00:54:13.440 --> 00:54:19.360]   So trying to figure out who's a bot or an automated process and who's not like you're gonna get a lot of tuna
[00:54:19.360 --> 00:54:24.000]   A lot of dolphins in that tuna net and you're gonna have a lot of users who are really angry at you
[00:54:24.000 --> 00:54:27.680]   I love that three thousand one in a million use cases every day
[00:54:27.680 --> 00:54:31.040]   That's really good. That's a lot of math, but I think I follow
[00:54:31.040 --> 00:54:36.640]   Yeah, right. So so you know if we could just like if we could just
[00:54:36.640 --> 00:54:40.320]   Adjust the rules for violating terms of service
[00:54:40.880 --> 00:54:44.000]   Such that facebook couldn't intimidate small
[00:54:44.000 --> 00:54:47.360]   engineering groups at public universities
[00:54:47.360 --> 00:54:53.840]   from out of out of um doing accountability work that just measures how the service works
[00:54:53.840 --> 00:54:57.360]   Right, especially like in light of them shutting down crowd tangle
[00:54:57.360 --> 00:55:02.640]   Which was their internal analytics thing that they let researchers use to figure out how facebook worked
[00:55:02.640 --> 00:55:06.720]   And it showed that the most popular stuff on facebook was objectively terrible
[00:55:07.040 --> 00:55:10.640]   So they said oh crowd tangles broken right it was broken because it was accurate
[00:55:10.640 --> 00:55:17.200]   We're gonna actually i think crowd tangle was also badly designed in that sense is that it wasn't what is the most popular
[00:55:17.200 --> 00:55:20.000]   How big is there was there was a denominator needed there?
[00:55:20.000 --> 00:55:24.720]   How big was the most popular thing on facebook and you couldn't get to that to put it in context
[00:55:24.720 --> 00:55:26.960]   So it was kind of worthless either way
[00:55:26.960 --> 00:55:31.920]   Well, they could have added more detail to crowd tangle instead of shutting it down and then there are other research portal
[00:55:32.320 --> 00:55:38.320]   Their other research portal was full of so much bad information that dozens of phd candidates are having to scrap their
[00:55:38.320 --> 00:55:41.120]   Dissertations and start over again. Oh, yeah, that's right
[00:55:41.120 --> 00:55:44.960]   Why would anyone ever trust facebook to tell you how facebook works?
[00:55:44.960 --> 00:55:51.120]   So not only should facebook not be in charge of how you use facebook facebook shouldn't be in charge of how you understand facebook
[00:55:51.120 --> 00:55:57.680]   What's encouraging to me is that these are these are solutions that i don't think would be difficult to implement i don't think they would be controversial
[00:55:57.680 --> 00:55:59.680]   jeff would you
[00:55:59.680 --> 00:56:05.040]   Jeff you've been a defender space, but would you be open to something like i'm not an defender of facebook i'm a defender of the internet
[00:56:05.040 --> 00:56:06.320]   but
[00:56:06.320 --> 00:56:10.880]   I fear that that regulation that goes too far will hurt expression on the internet
[00:56:10.880 --> 00:56:12.960]   So that's what that's what i'm always having learnt for
[00:56:12.960 --> 00:56:18.320]   In the transatlantic high-level working group i was a part of with susan s farmer of ccc commissioner
[00:56:18.320 --> 00:56:23.920]   This is part of what we urged which is that and i think i think it's one step more than
[00:56:23.920 --> 00:56:25.680]   um
[00:56:25.680 --> 00:56:31.120]   Allowing the data it's requiring the data. Yeah, it's saying that and this is the ftc model
[00:56:31.120 --> 00:56:34.720]   Which cori was kind of headed to you warranted x
[00:56:34.720 --> 00:56:38.560]   We need to be able to hold you account for to account for that
[00:56:38.560 --> 00:56:44.320]   And to do that we need the data to do this in the researchers hands and then it also means the government has to kind of
[00:56:44.320 --> 00:56:50.160]   The whole group got mad at me when i'd say this but government in a way has to provide a safe farmer to say don't use
[00:56:50.720 --> 00:56:54.880]   The gdpr excuse and don't use the k-britain lettering excuse
[00:56:54.880 --> 00:57:00.000]   We're going to vet say we government the regulator are going to say we're going to say yes
[00:57:00.000 --> 00:57:03.040]   You must require this and that's that's so you can hide behind us
[00:57:03.040 --> 00:57:08.080]   One of the other have the data out of you one of the things Francis hogging test wanted to get a word in there
[00:57:08.080 --> 00:57:12.400]   I just want to tell you thank you. I'm sure i'm oversimplifying this
[00:57:12.400 --> 00:57:14.720]   But i just wonder where is the line drawn because
[00:57:14.720 --> 00:57:20.080]   Facebook has a bit of intellectual property here. This is their product. This is their platform
[00:57:20.560 --> 00:57:26.080]   Uh, I thought about say like the national hot chicken restaurant there in minfas, Tennessee
[00:57:26.080 --> 00:57:28.640]   That's just super popular but yet nobody's
[00:57:28.640 --> 00:57:35.840]   Banging on the door demanding for that recipe because it's their proprietary recipe and no one's pressing at them for not sharing it
[00:57:35.840 --> 00:57:41.280]   Why is facebook any different they have a product? It's a good point. I think it's always to make it work
[00:57:41.280 --> 00:57:45.920]   And keep people hooked on this but we're not demanding that they they give over the algorithm
[00:57:45.920 --> 00:57:50.400]   We know the recipe we need to know how many tongues were burnt irreparably from it just the consequence
[00:57:50.560 --> 00:57:54.720]   So, I I mean actually think a better example would be jamba juice at one point
[00:57:54.720 --> 00:57:57.760]   You know, whatever they were using as thickener like, you know, but
[00:57:57.760 --> 00:58:00.320]   plutonium powder and asbestos or whatever
[00:58:00.320 --> 00:58:05.280]   They said if you asked for their nutritional the allergen information
[00:58:05.280 --> 00:58:09.040]   They would give you this like three ring binder full of laminated pages
[00:58:09.040 --> 00:58:15.200]   That would say if you were allergic to something call this number and we'll tell you whether or not it's in there
[00:58:17.760 --> 00:58:23.440]   Right and that's like actually we make companies give up there and I don't think that's still the case
[00:58:23.440 --> 00:58:27.680]   Right, it's been a long time since i've been to a jamba juice because I don't fly through oakland or port anymore
[00:58:27.680 --> 00:58:34.160]   Because travel is a thing that doesn't exist anymore, but I you know back back when I used to go to jamba juice like
[00:58:34.160 --> 00:58:40.800]   I'm pretty sure that they stopped they stopped making it like go fish right like if you got any eggs go fish
[00:58:45.840 --> 00:58:49.120]   So we do we do require companies to do stuff and we also
[00:58:49.120 --> 00:58:53.440]   You know, some of the things that we're asking of facebook are the results of
[00:58:53.440 --> 00:58:58.560]   Them making representations prior to a merger. So mergers are not
[00:58:58.560 --> 00:59:03.840]   Permitted as a matter of course you have to get permission from the ftc to undertake a merger
[00:59:03.840 --> 00:59:07.200]   We kind of forget that in this day of aqua hires where you know
[00:59:07.200 --> 00:59:11.200]   Platforms will buy companies more often than you know, you were I buy groceries
[00:59:11.200 --> 00:59:13.360]   But every one of those is nominally
[00:59:13.440 --> 00:59:18.880]   Subject to us to treat me regulation approval and conditional approval
[00:59:18.880 --> 00:59:21.600]   Right like they can say like as the european union did
[00:59:21.600 --> 00:59:28.960]   You can buy whatsapp and instagram, but you can't merge their back end which facebook went and did or as google did when it bought
[00:59:28.960 --> 00:59:35.600]   It's ad stack. We are not going to merge the back ends of youtube and google and merge your profiles across google
[00:59:35.600 --> 00:59:38.080]   products which they did
[00:59:38.080 --> 00:59:40.080]   and so
[00:59:40.560 --> 00:59:44.480]   Yeah, I this makes me think maybe we need an fda for social media
[00:59:44.480 --> 00:59:49.520]   You wouldn't have to prove it safe and effective, but you'd have to prove it doesn't harm anybody
[00:59:49.520 --> 00:59:52.400]   Well, you have to prove that it
[00:59:52.400 --> 00:59:54.880]   I think there's two steps here. The one is
[00:59:54.880 --> 01:00:00.960]   the easiest way out of of what the my group said was well, we don't warrant anything
[01:00:00.960 --> 01:00:05.040]   We don't promise you anything. Hey, it's the internet wild west. Didn't you call it that right?
[01:00:05.040 --> 01:00:07.600]   And you say no, that's not acceptable
[01:00:08.080 --> 01:00:11.040]   There has to be a discussion among there is a test
[01:00:11.040 --> 01:00:15.600]   It was decided before there's a promise right promise from facebook for sure
[01:00:15.600 --> 01:00:22.080]   So then so then what happens is and where and this is where we're um a right to private action might come in as well
[01:00:22.080 --> 01:00:24.480]   Is that you say because
[01:00:24.480 --> 01:00:29.600]   Zach ochre said about about about a product if the ftc catches you lying about that product, right
[01:00:29.600 --> 01:00:34.160]   Uh, this pen won't stain your shirt. It's stained in my shirt
[01:00:34.560 --> 01:00:37.680]   They lied you have action to the federal trade commission to say
[01:00:37.680 --> 01:00:41.280]   They lied pen maybe can stain a shirt. That's okay
[01:00:41.280 --> 01:00:44.800]   But if you say it's not going to win it did we gotcha and you got to try to
[01:00:44.800 --> 01:00:47.200]   Show something
[01:00:47.200 --> 01:00:50.560]   So so we have that precedent in in american law at least
[01:00:50.560 --> 01:00:55.440]   Where we can go after for violating the warrant that you make
[01:00:55.440 --> 01:01:00.560]   And then the next step of this is is then to say well, how do we do that?
[01:01:00.800 --> 01:01:05.200]   Well, we got to have data to do that. Well, we're going to require you to reveal data
[01:01:05.200 --> 01:01:10.640]   Not necessarily the government but to researchers whom you could also hold to account for how they do the research a low camera
[01:01:10.640 --> 01:01:12.720]   um, um
[01:01:12.720 --> 01:01:14.000]   and say
[01:01:14.000 --> 01:01:15.040]   This
[01:01:15.040 --> 01:01:18.000]   We need to open this up so that people can can say surprise
[01:01:18.000 --> 01:01:20.800]   I never thought of this before but look what the data shows show us
[01:01:20.800 --> 01:01:23.840]   By the way, that to me is the community
[01:01:23.840 --> 01:01:30.080]   I noted that frances hug and has now i've been asked after saying that facebook lied to their advisory
[01:01:30.640 --> 01:01:34.560]   Council has been asked to testify for the oversight board the oversight board
[01:01:34.560 --> 01:01:36.960]   Uh, can you tell us a little more about that?
[01:01:36.960 --> 01:01:40.080]   So that will be interesting. I don't know so
[01:01:40.080 --> 01:01:47.200]   So here's here's the thing that I I uh, I think we need to decide what we want to do right
[01:01:47.200 --> 01:01:52.000]   Some people want to fix the platforms and some people want to fix the internet
[01:01:52.000 --> 01:01:56.400]   And so if you're going to fix the platforms, it means that you're going to find a way
[01:01:56.400 --> 01:01:59.280]   That mark zucker berg can be a good
[01:02:00.000 --> 01:02:06.080]   Unelected social medias are for three billion people or can be replaced with someone who's better at the job than he is
[01:02:06.080 --> 01:02:13.120]   And if you want to fix the internet, you want to make sure that the job unelected social medias are for three billion people doesn't exist ever again
[01:02:13.120 --> 01:02:18.400]   And the latter is not about making facebook's algorithms better
[01:02:18.400 --> 01:02:22.640]   It's about making it so that they're less consequential so that you don't have to
[01:02:22.640 --> 01:02:28.240]   Use facebook even though they may have like a significant fraction of the world's population
[01:02:28.880 --> 01:02:32.800]   Stuck, you know held hostage in a wall garden because you can still talk to them
[01:02:32.800 --> 01:02:40.160]   And so that's where a regulation like a mandatory api or a defense for inter operators who don't use the api
[01:02:40.160 --> 01:02:48.160]   But just hack their own api in or both which would be the best of all worlds because you know facebook if they're ordered to have an api
[01:02:48.160 --> 01:02:53.760]   Might then do something to subvert it and then we'd have to wait 10 years while they went back and forth with the regulator
[01:02:54.080 --> 01:02:58.560]   Spend a couple billion dollars playing footsie and in court and whatever before we finally got a remedy
[01:02:58.560 --> 01:03:06.320]   So if they subvert it, we would also like people to just be able to write bots and scrapers and do whatever it takes to replace the api
[01:03:06.320 --> 01:03:10.800]   With some standalone stuff, right like it's great that microsoft eventually
[01:03:10.800 --> 01:03:19.360]   Standardize the format for for microsoft office, but they didn't do that until after steve jobs had some apple engineers reverse engineer
[01:03:19.680 --> 01:03:24.560]   All the file formats for office and make the iWork suite with pages and numbers and keynote
[01:03:24.560 --> 01:03:27.120]   That's when they actually
[01:03:27.120 --> 01:03:29.120]   Microsoft stopped playing
[01:03:29.120 --> 01:03:35.360]   shenanigans and actually got serious about having a standardized format and now there's no document lock-in to speak of
[01:03:35.360 --> 01:03:41.200]   And and so, you know that is like a much better future right one in which
[01:03:41.200 --> 01:03:44.960]   We don't rely on facebook being a benevolent dictator
[01:03:44.960 --> 01:03:48.080]   We make it harder for them to be a dictator at all
[01:03:48.880 --> 01:03:54.480]   And yeah forcing them to like expose their algorithm might be useful in the context of maybe a civil suit
[01:03:54.480 --> 01:03:59.280]   Or or even a criminal suit if you thought that their algorithm had done something wrong and you know
[01:03:59.280 --> 01:04:03.680]   There's clearly some things that their algorithms do that are wrong like um, you know, it's it is
[01:04:03.680 --> 01:04:11.120]   It is illegal without exception to discriminate against people when offering them financial products on the basis of their race
[01:04:11.120 --> 01:04:17.200]   And yet facebook ads do that right as do google ads. We know that happens in fact there was
[01:04:17.760 --> 01:04:22.160]   A lawsuit that the ACLU and the intercept brought against facebook
[01:04:22.160 --> 01:04:28.640]   That where they are or against the us government rather where they argued that facebook's theory that the computer fraud and abuse act
[01:04:28.640 --> 01:04:32.960]   Made it illegal for them to create fake users synthetic users
[01:04:32.960 --> 01:04:36.880]   So they could evaluate whether or not facebook was violating federal law
[01:04:36.880 --> 01:04:39.520]   in discriminating
[01:04:39.520 --> 01:04:44.960]   In engaging in financial discrimination and the court said that the computer fraud and abuse act didn't reach to that
[01:04:45.040 --> 01:04:49.680]   So they could violate facebook's terms of service. So, you know, there might be instances in which we
[01:04:49.680 --> 01:04:53.040]   Make facebook provide evidence of how its algorithm works
[01:04:53.040 --> 01:04:58.480]   But I don't think that's how we make the internet better that might be how we make facebook account for bad things
[01:04:58.480 --> 01:05:02.400]   It's done, but the way we make the internet better is not by making facebook better
[01:05:02.400 --> 01:05:04.560]   It's by making facebook irrelevant
[01:05:04.560 --> 01:05:11.200]   So that you know if they are bad you can leave let the market and so we can then lots of new things
[01:05:11.200 --> 01:05:14.800]   Yeah, I love this. That's the we have the agency
[01:05:15.120 --> 01:05:18.400]   To invent the internet the future it ain't baked it ain't done
[01:05:18.400 --> 01:05:21.600]   That's my primary point is I want the freedom to be able to do that
[01:05:21.600 --> 01:05:26.240]   Yeah, and you know no one came down off amount with two stone tablets that said, you know
[01:05:26.240 --> 01:05:32.560]   Larry sergays stop rotating your log files and start mining them for actionable market intelligence
[01:05:32.560 --> 01:05:37.520]   Right, there's more than one way to organize the internet none of this is forordained
[01:05:37.520 --> 01:05:40.880]   the the right the way that we went from
[01:05:40.880 --> 01:05:42.240]   You know
[01:05:42.240 --> 01:05:43.680]   Dell being
[01:05:43.680 --> 01:05:49.520]   Like just michael del in his garage being weird to being a giant company that you know was was
[01:05:49.520 --> 01:05:52.720]   Felling the mainframe giants that came before
[01:05:52.720 --> 01:05:55.040]   was by
[01:05:55.040 --> 01:05:57.040]   not allowing ibm
[01:05:57.040 --> 01:06:00.400]   To crush the company that supplied del with pc roms
[01:06:00.400 --> 01:06:08.560]   Uh, so that they could make an interoperable pc that could run pc software and so phoenix computing made the roms del put them in their computers
[01:06:08.640 --> 01:06:13.520]   So to compact so did lots of other people people cloned the roms that phoenix had cloned
[01:06:13.520 --> 01:06:19.440]   Right, they they like they what was sauce for the goose was sauce for the gander and phoenix didn't have remedies when that happened
[01:06:19.440 --> 01:06:27.200]   That actually created this dynamic landscape where every year people had a different way to figure out how to make money to make services
[01:06:27.200 --> 01:06:30.160]   to serve a different constituency
[01:06:30.160 --> 01:06:36.960]   To do things that delighted us and then sometimes pissed us off or to get rid of the things that pissed us off and replaced them with something better
[01:06:37.360 --> 01:06:40.560]   That was not it's not like a blind adherence to the market
[01:06:40.560 --> 01:06:46.240]   It's it's about allowing the people who use the internet to exercise self-determination
[01:06:46.240 --> 01:06:49.360]   To decide which services they'll use
[01:06:49.360 --> 01:06:54.640]   How those services will be configured to change those services if they have the technical know how to do so
[01:06:54.640 --> 01:06:58.960]   Ask someone else to change those services if they don't and to be able to
[01:06:58.960 --> 01:07:04.080]   Embrace that uh ethos from the disability movement nothing about us without us
[01:07:04.560 --> 01:07:10.000]   To you know the most the purest expression of nothing about us without us is nothing about me without me
[01:07:10.000 --> 01:07:12.240]   At the end of the day
[01:07:12.240 --> 01:07:16.880]   I get the veto over how my computer works and the services that I use work
[01:07:16.880 --> 01:07:23.520]   Even though I might make a foolish choice. It's my choice to make because I am here at the call face
[01:07:23.520 --> 01:07:30.000]   Right. I am the one who who knows what I need who knows whether overriding the
[01:07:30.720 --> 01:07:36.560]   Safety measure is the right call to make or not and you as the programmer might be worried that I'm going to do something
[01:07:36.560 --> 01:07:40.880]   Stupid and you might put a lot of warnings in my way that say please don't do this. No, really don't do this
[01:07:40.880 --> 01:07:45.680]   God if you're going to do this things could go really horribly terribly wrong and you could break your computer
[01:07:45.680 --> 01:07:48.080]   And if I just keep typing yes, yes, yes
[01:07:48.080 --> 01:07:54.560]   Eventually, it's mine. I get to you know change app stores or do whatever else it is
[01:07:54.560 --> 01:08:00.320]   That uh, I'm trying to do and that you say if I do will result in me coming to some harm
[01:08:00.640 --> 01:08:02.880]   Also, I will see triggers. Sorry
[01:08:02.880 --> 01:08:06.880]   I was just going to say I'll note for the record that right on time now that i'm doing a live cast
[01:08:06.880 --> 01:08:12.640]   There is a leaf blower outside my door. So I will give you I will take a break california is about to ban those
[01:08:12.640 --> 01:08:18.400]   That's a good thing at least the uh two stroke leaf blowers. You'll have to have a nice electric wine from now on
[01:08:18.400 --> 01:08:22.320]   Uh, and I if everybody'll hold their thought we're gonna move on from facebook
[01:08:22.320 --> 01:08:29.280]   But I cori well spoken beautiful nothing about me without me is my new motto my new internet motto
[01:08:30.160 --> 01:08:32.400]   Uh our show today brought to you by melissa
[01:08:32.400 --> 01:08:37.200]   Having accurate customer data is crucial for the success of your business
[01:08:37.200 --> 01:08:42.080]   You don't want to be mailing your catalogs to the wrong address sending bills to the wrong person
[01:08:42.080 --> 01:08:48.880]   You know that 36 million address changes were processed by the postal service last year 36 million
[01:08:48.880 --> 01:08:53.120]   That means a huge chunk of your customers could be missing out
[01:08:53.120 --> 01:08:59.040]   On what you have to offer 30 percent of customer data on average goes bad every year melissa
[01:08:59.760 --> 01:09:04.160]   For 35 years now has been helping businesses make sure their data is current
[01:09:04.160 --> 01:09:06.320]   and accurate
[01:09:06.320 --> 01:09:13.440]   That's why over 10 000 businesses trust the address experts. Not just trust them love them. Melissa has a renewal rate of over 92
[01:09:13.440 --> 01:09:14.640]   percent
[01:09:14.640 --> 01:09:20.640]   Proof the companies love melissa and you will too verify not just uh addresses emails phone numbers
[01:09:20.640 --> 01:09:26.640]   And names and you can do it in real time if you want gloop melissa's global address verification service
[01:09:27.680 --> 01:09:32.000]   Verifies addresses for 240 plus countries and territories
[01:09:32.000 --> 01:09:37.040]   And they can do it in whatever way makes sense for you. There's on-prem. There's a web service
[01:09:37.040 --> 01:09:43.760]   There's secure ftp so you can upload an address list and download the process list. You can use software as a service
[01:09:43.760 --> 01:09:46.800]   They have their new look up apps. They're look ups
[01:09:46.800 --> 01:09:51.600]   They're called lookups on the ios and google to search addresses names and more at your fingertips
[01:09:51.840 --> 01:09:59.600]   Then of course there's an api so you can include melissa's address verification in your your customer service software
[01:09:59.600 --> 01:10:04.560]   Or you know it's not unusual for even customers themselves to fumble finger in address
[01:10:04.560 --> 01:10:09.280]   You could fix it in real time with melissa of course melissa realizes that data
[01:10:09.280 --> 01:10:14.720]   Is very important to you to your customers. That's why they undergo independent security audits
[01:10:14.720 --> 01:10:21.440]   All the time to reinforce their commitment to a data security privacy and compliance requirements
[01:10:21.680 --> 01:10:24.880]   They're sock to compliant hip a compliant gdpr compliant
[01:10:24.880 --> 01:10:29.600]   And they have the best support ever melissa's global support center offers 24/7
[01:10:29.600 --> 01:10:36.640]   World famous support if you sign up for that service level agreement, you will really appreciate it. Ask about that by the way
[01:10:36.640 --> 01:10:44.560]   melissa's still supporting communities and qualifying essential workers during covet 19 your organization could qualify for six months of free service
[01:10:44.560 --> 01:10:46.880]   apply online and melissa
[01:10:46.880 --> 01:10:55.120]   Common also hearty congratulations to melissa g2 crowds fall 2020 run report ranked melissa as a leader
[01:10:55.120 --> 01:10:58.320]   In both address verification and data quality software
[01:10:58.320 --> 01:11:04.880]   I think gives you a pretty good idea. They're meeting the diverse needs of their customers. Make sure your customer data
[01:11:04.880 --> 01:11:07.280]   Is up to date?
[01:11:07.280 --> 01:11:10.960]   Try melissa's api's in the developer portal. It's easy to log on
[01:11:10.960 --> 01:11:14.720]   Sign up and start playing in the api sandbox 24/7
[01:11:15.120 --> 01:11:18.720]   In fact get you started. We'll give you 1000 records clean for free
[01:11:18.720 --> 01:11:23.120]   When you go to melissa.com/twit me lissa
[01:11:23.120 --> 01:11:29.280]   melissa.com/twit the address experts melissa
[01:11:29.280 --> 01:11:33.520]   We thank them so much for supporting this week in google melissa.com
[01:11:33.520 --> 01:11:35.920]   slash
[01:11:35.920 --> 01:11:37.360]   twit
[01:11:37.360 --> 01:11:41.040]   Cord you get us not a democracy leo what but i'm curious for
[01:11:41.760 --> 01:11:45.600]   Right before we went on twitter released a position paper on the open internet
[01:11:45.600 --> 01:11:47.840]   Which is basically to say their prescription for regulation
[01:11:47.840 --> 01:11:53.520]   And considering all three of you have things to say i'd be curious do you have do you have the line 92
[01:11:53.520 --> 01:11:55.520]   992
[01:11:55.520 --> 01:11:56.480]   Okay
[01:11:56.480 --> 01:12:00.640]   Um, it has five bullet points. So it's simple to but you didn't have to read it. You can correct
[01:12:00.640 --> 01:12:03.600]   Have you did has anybody perused it yet?
[01:12:03.600 --> 01:12:09.120]   I have not read this one yet. I did read the chinese government's open internet order
[01:12:09.120 --> 01:12:11.120]   That's not a problem
[01:12:11.120 --> 01:12:18.160]   It's actually wild like one of the things they do is they ban companies from taking countermeasures to block interoperability
[01:12:18.160 --> 01:12:22.800]   You know sometimes you think a democracy is so slow
[01:12:22.800 --> 01:12:26.800]   Just let that you know a totalitarian regime would make it all so much easier
[01:12:26.800 --> 01:12:31.600]   And I have to say some other regulation china is engaging it isn't so bad is it
[01:12:31.600 --> 01:12:36.400]   I'm not sure. I mean I see what china's goal china so like
[01:12:37.360 --> 01:12:40.720]   the the thing that I share with china is I think that that
[01:12:40.720 --> 01:12:46.720]   Firm should not be able to sub ordinate the state to their shareholders priorities
[01:12:46.720 --> 01:12:51.360]   But I think that where I differ with china is how I think the state should be constituted
[01:12:51.360 --> 01:12:55.200]   Right, right. I just think I think that the state should be like democratically accountable
[01:12:55.200 --> 01:12:57.520]   But you know the idea that like
[01:12:57.520 --> 01:13:04.320]   In a democracy it's good to have firms that are so big that you can't regulate them
[01:13:04.960 --> 01:13:06.960]   Is not really coherent, you know
[01:13:06.960 --> 01:13:11.120]   That's that's that's not that that kind of says well, okay
[01:13:11.120 --> 01:13:14.480]   You've got democracy and everything except where these giant companies act on your life
[01:13:14.480 --> 01:13:18.320]   Which is everything and that's not really what we want, right?
[01:13:18.320 --> 01:13:24.800]   Let me see if I can uh pull up this protecting the hashtag open internet by the way
[01:13:24.800 --> 01:13:26.480]   uh
[01:13:26.480 --> 01:13:28.480]   There are two key areas
[01:13:28.480 --> 01:13:32.640]   avoid entrenching the dominance of the biggest players by protecting competition
[01:13:33.520 --> 01:13:36.640]   Says twitter easy enough if you're not one of the biggest players
[01:13:36.640 --> 01:13:42.880]   Focus on how content is discovered and amplified less on removal alone
[01:13:42.880 --> 01:13:45.920]   That's interesting questions
[01:13:45.920 --> 01:13:47.200]   Twitter
[01:13:47.200 --> 01:13:49.440]   Did remove a number of
[01:13:49.440 --> 01:13:55.440]   Controversial but then there's blue sky which might or might not bring it back. We'll see. I think this is blue sky
[01:13:55.440 --> 01:13:57.600]   I think that's what this is
[01:13:57.600 --> 01:14:00.720]   That's their uh, that's their version of a federated
[01:14:01.440 --> 01:14:05.520]   System does it yeah, does it satisfy your your requirements for I like the idea
[01:14:05.520 --> 01:14:10.880]   There's some weird blockchain nonsense around the parameters, which you know every time I see it
[01:14:10.880 --> 01:14:15.760]   It always turns out to be either a Ponzi scheme or buzzword compliance or both
[01:14:15.760 --> 01:14:20.800]   And i haven't figured out which one it is with twitter, but i'm sure it's one or one or one of the other both
[01:14:20.800 --> 01:14:21.840]   But um
[01:14:21.840 --> 01:14:24.160]   The actual idea of like an app store for moderation
[01:14:24.160 --> 01:14:28.160]   For for algorithmic sorting i'm 100 down for that
[01:14:28.240 --> 01:14:33.440]   That's that's kind of the model you're talking about that excites me too that the speaking level becomes the commodity
[01:14:33.440 --> 01:14:38.400]   The value add of of of what do you want to see and hear from that?
[01:14:38.400 --> 01:14:42.000]   Yeah, um becomes the value add so number three
[01:14:42.000 --> 01:14:43.760]   I would list yeah go ahead
[01:14:43.760 --> 01:14:49.840]   And I would say that like these principles will look really familiar to you if you've ever read the sanichlera principles
[01:14:49.840 --> 01:14:56.560]   Which are the content moderation principles that were really reified after or refined and finalized after the
[01:14:57.760 --> 01:14:59.760]   uh, New Zealand mosque shootings
[01:14:59.760 --> 01:15:06.880]   Uh, where there was this like moment where people took a pause and we're like well, we could we could go 9/11 after this
[01:15:06.880 --> 01:15:13.840]   Right, we could we could just have two lost decades of terrible rules driven by fear or we could actually try and figure out what
[01:15:13.840 --> 01:15:19.200]   If anything we can do to prevent this right not just say like something must be done there
[01:15:19.200 --> 01:15:21.040]   I've done something now something has been done
[01:15:21.040 --> 01:15:24.160]   But actually try and come up with something meaningful the balances that a lot of different
[01:15:24.720 --> 01:15:29.440]   Uh, and difficult to balance equities the sanichlera principles read a lot like this
[01:15:29.440 --> 01:15:34.240]   I have to say i'm impressed. I see like twitter of all of the social media companies has done the most
[01:15:34.240 --> 01:15:39.280]   Uh thinking about this and the most uh successful work in this direction
[01:15:39.280 --> 01:15:41.680]   Um, maybe they have less to lose than facebook
[01:15:41.680 --> 01:15:48.000]   Yeah, jeff jeff had it right, you know if you've got a hundred million users in your major competitors got three billion users
[01:15:48.000 --> 01:15:49.120]   Right
[01:15:49.120 --> 01:15:53.440]   You know when the joke that was going around and zak lost six billion dollars off the whistleblower news
[01:15:53.600 --> 01:15:55.600]   Was he lost one twitter
[01:15:55.600 --> 01:15:59.760]   Right
[01:15:59.760 --> 01:16:03.760]   So, you know, but that's but but that's the point right is that like
[01:16:03.760 --> 01:16:09.200]   giant firms that are like uh locked on rails because they're worth a trillion dollars
[01:16:09.200 --> 01:16:11.760]   and they their their
[01:16:11.760 --> 01:16:18.000]   Shareholders are not going to accept high risk bets that might compromise that trillion dollar valuation
[01:16:18.880 --> 01:16:23.920]   Really aren't going to be able to do the interesting thing. They're going to be stuck doing the safe thing
[01:16:23.920 --> 01:16:30.080]   And eventually the safe right that's how you get ibm right that's how you get that so you get cray
[01:16:30.080 --> 01:16:34.320]   That's how you get even sji right as they were all locked into their
[01:16:34.320 --> 01:16:40.000]   Their uh path and you know leo when you were saying we say microsoft with anti-trust
[01:16:40.000 --> 01:16:45.280]   That's the bit. I think that did save microsoft with anti-trust as they did have to rethink some of their fundamentals
[01:16:45.280 --> 01:16:47.600]   Which would have you know tapped out anyway?
[01:16:48.720 --> 01:16:57.520]   Interesting article in tech dirt about uh section 230 of course mike maznick and his crew always very much aggressively in defense
[01:16:57.520 --> 01:17:00.080]   Of a section 230 point out
[01:17:00.080 --> 01:17:08.080]   Uh in a recent uh case against wicki media that the judge was able to throw out the lawsuit against wicki pedia
[01:17:08.080 --> 01:17:13.520]   Saying nope section 230 says you can't sue them for this
[01:17:13.520 --> 01:17:17.440]   uh, and if you want to save wicki pedia basically the
[01:17:18.240 --> 01:17:22.960]   mike's contention or actually it was uh glen moody writing in the wicki pedia's contention
[01:17:22.960 --> 01:17:24.560]   uh
[01:17:24.560 --> 01:17:32.080]   Is that if if you want to if you want to know why section 230 matters without it there'd be no wicki pedia
[01:17:32.080 --> 01:17:34.640]   Yep, they're they're highly at risk
[01:17:34.640 --> 01:17:37.120]   And boy that that that brings it home
[01:17:37.120 --> 01:17:42.960]   And the case like all all of these cases that actually go to court. It's a terrible case
[01:17:42.960 --> 01:17:48.000]   Someone was misidentified as a killer. Yeah, they got the wrong guy right name wrong guy
[01:17:48.640 --> 01:17:52.240]   And it and it heard him a lot and uh
[01:17:52.240 --> 01:17:55.520]   wikipedia um
[01:17:55.520 --> 01:18:02.000]   Has a bunch of procedures for preventing that from happening, you know, um writing articles about living people
[01:18:02.000 --> 01:18:06.000]   Is a big deal on wicki pedia because it was so contentious early on
[01:18:06.000 --> 01:18:10.720]   Uh, and it was used to be you know horrible to people early on
[01:18:10.720 --> 01:18:15.360]   You know as part of personal vendettas and their procedures failed right they found a
[01:18:15.920 --> 01:18:19.840]   Of vulnerability and their procedures which they're going to improve which is really what we want
[01:18:19.840 --> 01:18:23.280]   Right, we want like them to be acting in good faith, which they do
[01:18:23.280 --> 01:18:25.680]   to prevent
[01:18:25.680 --> 01:18:30.960]   Nobody wants the wrong person to be identified as a killer like even the person who misidentified him
[01:18:30.960 --> 01:18:36.000]   Did not misidentify maliciously he misidentified or they misidentified him
[01:18:36.000 --> 01:18:38.560]   Uh out of error
[01:18:38.560 --> 01:18:43.040]   And so no nobody likes the outcome that that led to this lawsuit
[01:18:43.760 --> 01:18:46.880]   But nobody wants to get rid of wikipedia either and so you know
[01:18:46.880 --> 01:18:49.840]   like wikipedia
[01:18:49.840 --> 01:18:52.000]   Has a very strong normative ethic
[01:18:52.000 --> 01:19:00.000]   About how they approach this this problem right what their editorial rules are and it's enforced very vigorously by a community
[01:19:00.000 --> 01:19:07.920]   Sometimes too vigorously, you know, there's this criticism that wikipedia is is so arcane now to edit in meaningful ways that that it's hard to do
[01:19:07.920 --> 01:19:12.800]   But at the same time, you know, they are teaching us
[01:19:13.440 --> 01:19:15.440]   how to do
[01:19:15.440 --> 01:19:17.600]   crowdsource distributed
[01:19:17.600 --> 01:19:21.040]   News and information gathering in a responsible way
[01:19:21.040 --> 01:19:27.040]   And part of the way that they're doing that is by learning from their mistakes rather than being destroyed when they make a mistake
[01:19:27.040 --> 01:19:29.440]   Right and and to have
[01:19:29.440 --> 01:19:34.240]   That's that to me is the key here too is if it's all a game of gotcha
[01:19:34.240 --> 01:19:38.800]   We're not going to get anywhere if instead you're held to account
[01:19:39.280 --> 01:19:44.400]   For listening to what's going on for understanding the impact for improving what happens
[01:19:44.400 --> 01:19:49.920]   Because and it's all the points you made earlier quarry because you have a competitive threat and a regulatory threat and fine
[01:19:49.920 --> 01:19:55.200]   But but but playing gotcha and break them up doesn't doesn't do anything
[01:19:55.200 --> 01:20:02.240]   Uh, how do we create new competitors? How do we create a structure where you're held to account for having something that you say you're going to have
[01:20:02.240 --> 01:20:06.960]   That's what we're going to get better internet instead of playing gotcha. Go ahead. Go ahead, Corey
[01:20:06.960 --> 01:20:11.520]   They'll take record just to be on the record. I will say that I wouldn't be opposed to breaking up these big firms
[01:20:11.520 --> 01:20:14.640]   I think at the very least we should unwind the mergers that they undertook on false pretenses
[01:20:14.640 --> 01:20:20.160]   If facebook told a regulator it wouldn't merge what's happened instagrams back end and then it did we shouldn't make them
[01:20:20.160 --> 01:20:25.600]   Spinner what's happened instagram same with google and and it's merger on its back
[01:20:25.600 --> 01:20:28.480]   And as well cast and nbc same with it
[01:20:28.480 --> 01:20:34.400]   If you merge if you merge on false pretenses we should break you up at the very whole upset is that doesn't solve it
[01:20:35.120 --> 01:20:40.320]   It would do something and it would take up but the problem is it's slow
[01:20:40.320 --> 01:20:43.520]   Right so ibm was an antitrust health for 12 years
[01:20:43.520 --> 01:20:50.720]   They called it antitrust is vietnam and during those 12 years ibm spent more money on antitrust lawyers in the entire department of justice
[01:20:50.720 --> 01:20:55.680]   Every year for 12 years and in the end they got off the hook because ragan basically said well
[01:20:55.680 --> 01:20:58.000]   We're not gonna you know ronald ragan is not gonna break up
[01:20:58.000 --> 01:21:03.600]   ibm right and um and uh, it still was good
[01:21:03.920 --> 01:21:10.240]   Right like it was still worth doing that's as I said, that's how we got microsoft because not ibm really understood that
[01:21:10.240 --> 01:21:11.200]   um
[01:21:11.200 --> 01:21:17.040]   If we were gonna if if they were gonna keep tying hardware to software that the doj would be back at their door
[01:21:17.040 --> 01:21:20.560]   And you know what they did do was break up atnt they didn't they didn't
[01:21:20.560 --> 01:21:24.880]   Sit on them afterwards. They stopped enforcing antitrust law shortly thereafter
[01:21:24.880 --> 01:21:30.080]   So atnt was able to re-merge and become a giant firm by breaking up atnt is how we got like modems
[01:21:30.080 --> 01:21:32.240]   Right, right like it was worth doing
[01:21:32.240 --> 01:21:37.120]   And you know when we tried when we tried to break up atnt you know, they they um
[01:21:37.120 --> 01:21:40.480]   They said well look there's this like authoritarian
[01:21:40.480 --> 01:21:47.760]   asian threat to american business that uh across the ocean has been copying our intellectual property
[01:21:47.760 --> 01:21:52.880]   And entering the high tech sector and they're going to destroy it. It's not company with that country was called japan
[01:21:52.880 --> 01:21:54.960]   and uh
[01:21:54.960 --> 01:21:59.440]   We need our national champion atnt to defend us against this peril
[01:22:00.000 --> 01:22:06.800]   Right and it you know if atnt had been able to suppress modems for another 20 25 years
[01:22:06.800 --> 01:22:10.240]   the american soft power and
[01:22:10.240 --> 01:22:15.120]   industrial activity profits that were generated from the internet would have not
[01:22:15.120 --> 01:22:18.720]   Uh crude to the us they might have accrued to another country
[01:22:18.720 --> 01:22:20.960]   Uh, or they might not have appeared at all
[01:22:20.960 --> 01:22:28.160]   National champions. They don't the nation they represent as themselves right atnt was on atnt
[01:22:28.160 --> 01:22:33.920]   T side not america side bydo is on bydo side not china side. There's my leaf blower. I hear him
[01:22:33.920 --> 01:22:37.920]   and and uh, I call him leafy and uh
[01:22:37.920 --> 01:22:41.440]   and uh, you know that
[01:22:41.440 --> 01:22:44.080]   Like that's the thing that um, I think
[01:22:44.080 --> 01:22:48.640]   Sheeshin pig understands and that american uh, co-war two people don't
[01:22:48.640 --> 01:22:53.920]   Is that like bydo and tencent and and uh all these other big chinese companies
[01:22:54.880 --> 01:22:59.920]   They are not even if they like have state representation and they're under the state's thumb
[01:22:59.920 --> 01:23:03.120]   They are not prioritizing the interests of the chinese state
[01:23:03.120 --> 01:23:08.960]   They are or they're prioritizing their own interests their executives interests and their shareholders interests
[01:23:08.960 --> 01:23:14.320]   And the only time that the chinese state gets a look in is when they're afraid of the chinese state
[01:23:14.320 --> 01:23:16.560]   but not because they are like
[01:23:16.560 --> 01:23:18.640]   fronts for the chinese state
[01:23:18.640 --> 01:23:20.800]   And uh atnt was was
[01:23:21.600 --> 01:23:25.520]   Did america's bidding right they're really important to projecting american power around the world
[01:23:25.520 --> 01:23:30.960]   But atnt's loyalty was not to america atnt was for sale to the highest bidder
[01:23:30.960 --> 01:23:32.800]   They just did work for the pentagon
[01:23:32.800 --> 01:23:37.200]   Because the pentagon would rep would rep for them in the fifties when they tried to break up atnt
[01:23:37.200 --> 01:23:39.760]   Uh, the pentagon showed up and they said
[01:23:39.760 --> 01:23:46.240]   Will lose the war in korea if we don't have atnt like, you know, wamp wamp we lost the word korea anyway
[01:23:46.240 --> 01:23:47.520]   But
[01:23:47.520 --> 01:23:52.000]   You know, that's why they buttered up the pentagon not out of like a surplus of patriotism
[01:23:52.000 --> 01:23:56.480]   Uh before we lose kori because he's only going to be here for another five or ten minutes
[01:23:56.480 --> 01:24:01.360]   I want to get another commercial in and get get some final thoughts. We have a lot of other stories
[01:24:01.360 --> 01:24:03.360]   We didn't really mention which is fine
[01:24:03.360 --> 01:24:08.240]   Uh, we'll save them we'll save them for next week, but it's really a pleasure to have uh kori doctor. Oh, it's great
[01:24:08.240 --> 01:24:09.120]   I hear great
[01:24:09.120 --> 01:24:13.840]   There's a maxim in uh in chest that the threat is stronger than the execution
[01:24:13.920 --> 01:24:19.520]   I think that might also be the case in any trust law that the uh, the salutary effects of being under
[01:24:19.520 --> 01:24:23.600]   Investigation for anti trust often seems to be very valuable for both
[01:24:23.600 --> 01:24:28.480]   As kamoo said sometimes you have to execute an admiral to encourage the others
[01:24:28.480 --> 01:24:35.200]   Somehow I feel like kamoo probably never did any of that but okay, that's fine
[01:24:35.200 --> 01:24:41.440]   Yeah, I don't think he was ever the king of france now that you mentioned
[01:24:41.600 --> 01:24:48.160]   It was kind of theoretical, but okay, you know, I'll accept it on the lighter side. Did you see captain kirk boldly go where
[01:24:48.160 --> 01:24:53.760]   A few others have gone before but not not anybody over the age of say 88
[01:24:53.760 --> 01:24:59.040]   To watch this morning anybody anybody watch. Oh, yeah, it's kind of cool
[01:24:59.040 --> 01:25:04.080]   I have to say it really is an amusement park ride for billionaires, but oh, yeah
[01:25:04.080 --> 01:25:10.000]   Three minutes my my friend mitch my friend mitch wagner posted that he wondered if um
[01:25:10.640 --> 01:25:16.000]   Uh shatner was trying to do a dd harriman the hero of hindlines the the man who sold the moon who like
[01:25:16.000 --> 01:25:21.360]   Organizes the first mission to the moon and isn't allowed to go because his shareholders won't let him go because he's too old
[01:25:21.360 --> 01:25:24.400]   And finally gets aboard a rocket and he goes to the moon and dies
[01:25:24.400 --> 01:25:30.080]   You know because he really is too old and like if this was how this was how shatner wanted to go out
[01:25:30.080 --> 01:25:37.440]   I mean, you know that canadians are like criminally weird. So I have to say for 90 shatner is sharp
[01:25:38.080 --> 01:25:45.440]   Uh, he he sustained five g's on the way back and without any ill effects. He was it was actually very moving if you haven't seen the
[01:25:45.440 --> 01:25:48.320]   The video he's in tears
[01:25:48.320 --> 01:25:51.360]   On the on the rundown jeff bezos
[01:25:51.360 --> 01:25:55.680]   Interrupts him to say let's spray everybody with champagne
[01:25:55.680 --> 01:26:01.680]   But after a while bezos settles down. Do you think basis is going to kiss every single person who goes up in the
[01:26:01.680 --> 01:26:07.120]   In the shepherd from now on or is this pretty much it like from now on you're on your own
[01:26:07.520 --> 01:26:09.200]   How much does he signal? Yeah?
[01:26:09.200 --> 01:26:16.240]   Oh, I noticed his girlfriend was with him and made a made a point of hugging everybody who got off the crap
[01:26:16.240 --> 01:26:18.320]   But especially mr. Shatner
[01:26:18.320 --> 01:26:21.360]   How much to now build it and pay nor did the amazon
[01:26:21.360 --> 01:26:26.560]   Employ the blurge and employee who went up, but there were two paid astronauts. Do we know how much astronauts?
[01:26:26.560 --> 01:26:33.360]   You know what they got they see you did it. They got they said the word literally 400 times in the same
[01:26:33.360 --> 01:26:35.600]   They did every time i'm going they're no
[01:26:36.160 --> 01:26:38.160]   Astronauts
[01:26:38.160 --> 01:26:44.000]   Clear on this one. They are no astronauts. They are they're they're immune park riders. They're
[01:26:44.000 --> 01:26:47.280]   How much do you pay to be?
[01:26:47.280 --> 01:26:53.200]   Aviation enthusiast. Yeah, it's aviation. It's fine. Very nice. It's a nice one here important
[01:26:53.200 --> 01:26:55.680]   Uh, it's all been done before
[01:26:55.680 --> 01:26:59.200]   I think you save 100 box tops from an amazon delivery
[01:26:59.200 --> 01:27:02.160]   It's only if only
[01:27:02.720 --> 01:27:05.920]   If only uh, and you have to write it. You have to write a slogan
[01:27:05.920 --> 01:27:09.440]   You have to write a jingle about amazon space travel and how much fun it is
[01:27:09.440 --> 01:27:12.000]   And if you have the winning jingle and 100 box tops
[01:27:12.000 --> 01:27:14.720]   Jeff Bezos takes you up in the magic penis rocket
[01:27:14.720 --> 01:27:20.000]   At least there were no cowboy hats on the penises. Oh, thank god. I did like
[01:27:20.000 --> 01:27:23.920]   Uh, what a shatner said shatwars really kind of had a loss for words
[01:27:23.920 --> 01:27:29.200]   Uh when he came back he said uh, everyone in the world needs to do this
[01:27:29.200 --> 01:27:32.000]   By the way, that's the new slogan for blue origin
[01:27:32.400 --> 01:27:35.520]   Uh, it was so moving what you have given me is the most profound experience
[01:27:35.520 --> 01:27:39.920]   I'm so filled with the motion about what happened. He he said, I hope I never recover from this
[01:27:39.920 --> 01:27:41.920]   I hope I can maintain what I feel now
[01:27:41.920 --> 01:27:46.080]   He said the moment that you go out of the blue into the black
[01:27:46.080 --> 01:27:53.840]   Uh, is is really an important moment where you start to realize that that blue comforter surrounding the earth is so very thin
[01:27:53.840 --> 01:27:58.640]   Um, I I thought it was pretty cool. I thought it was pretty cool
[01:27:58.800 --> 01:28:03.840]   At for at least for that reason. I do think it's it's kind of a billion hours amusement park, but
[01:28:03.840 --> 01:28:06.160]   um
[01:28:06.160 --> 01:28:10.240]   Anyway, I mean he could he could have come off and went like good evening france
[01:28:10.240 --> 01:28:14.720]   Yeah
[01:28:14.720 --> 01:28:19.280]   Yeah, he's not he's not exactly an astronaut, but he's he's been up to the uh
[01:28:19.280 --> 01:28:24.880]   He's a passenger. He's a passenger. I think that's why he's a passenger. Yeah, I missed it
[01:28:24.880 --> 01:28:27.600]   My favorite team into the studio this morning mr
[01:28:27.600 --> 01:28:30.960]   Jammer b was talking about it and telling me about
[01:28:30.960 --> 01:28:36.160]   Shatner and what he described sound that just like a normal person
[01:28:36.160 --> 01:28:44.000]   Experience and something that they've never experienced before and it just sounded so real and so genuine and that was exactly right. Yes
[01:28:44.000 --> 01:28:49.600]   Yeah, it was nice. I mean he was shatner and everybody knows who he is
[01:28:49.600 --> 01:28:54.320]   He's bill or whatever, but at that moment we got to see a normal person say
[01:28:54.960 --> 01:28:59.920]   Holy crap. This was awesome. Yeah, I'm so grateful for this opportunity and I think that's cool. Yeah
[01:28:59.920 --> 01:29:05.920]   Yeah, my favorite tweet was that we should all dress up by like apes what he returns
[01:29:05.920 --> 01:29:09.040]   Oh
[01:29:09.040 --> 01:29:16.640]   Damn dirty eggs. Can we bury the statcher liberty? Is that that's the one thing she's done that too? Yeah, a quarter of a million dollars
[01:29:16.640 --> 01:29:22.560]   Each shatner was a guest. Uh, so was blue origins vp admission and flight operations, uh, adri powers
[01:29:22.880 --> 01:29:26.320]   Glend of rees co-founder of a medical research platform and chris
[01:29:26.320 --> 01:29:30.160]   Boschweezin a nasa researcher turned tech entrepreneur paid
[01:29:30.160 --> 01:29:36.240]   Reportedly repaid according to a I think writers a quarter of a million dollars each
[01:29:36.240 --> 01:29:41.680]   I don't know if I pay a quarter of a million dollars for that. So so if you had if you had 50 million dollars
[01:29:41.680 --> 01:29:45.360]   Would you pay quarter million? Oh, yeah, well then it's a buck 50. So sure. Yeah
[01:29:45.360 --> 01:29:48.240]   I guess I don't know
[01:29:48.240 --> 01:29:50.880]   Yeah, yeah, I guess I would
[01:29:50.880 --> 01:29:56.880]   If I could have plugged in there would do it. Yeah, put in a plug. There's uh, there's a young woman named, uh, penelope scott
[01:29:56.880 --> 01:29:58.720]   who um
[01:29:58.720 --> 01:30:02.480]   wrote a song about space travel and about like how
[01:30:02.480 --> 01:30:07.840]   Disappointing it is that there's space travel that is just uh, that it's just for rich people
[01:30:07.840 --> 01:30:12.640]   And it's specifically a kind of anti-love note to elan musk
[01:30:12.640 --> 01:30:14.800]   called
[01:30:14.800 --> 01:30:16.800]   rat with an oomlot over the a
[01:30:18.560 --> 01:30:22.240]   And uh, it's the chorus is it can I swear on this show? Yes
[01:30:22.240 --> 01:30:26.800]   The chorus is great. It goes your tunnels your cars your rockets your cars again
[01:30:26.800 --> 01:30:33.040]   You thought that you'd be tesla, but you're just another edison because tesla broke a patent all you ever broke was hearts
[01:30:33.040 --> 01:30:36.160]   Uh, who'd have thought that you'd tear humanity apart?
[01:30:36.160 --> 01:30:38.640]   And it's really good
[01:30:38.640 --> 01:30:39.440]   Wow
[01:30:39.440 --> 01:30:43.680]   She's a really great singer. She's really fun. It's all chiptunes. She just dropped a new album on ban camp
[01:30:44.080 --> 01:30:48.480]   Penelope scott young woman from michigan really terrific
[01:30:48.480 --> 01:30:53.360]   I maybe I should just play a little bit of it here. It's three minutes long, but I could
[01:30:53.360 --> 01:30:56.160]   Oh my goodness
[01:30:56.160 --> 01:30:58.160]   Your cars
[01:30:58.160 --> 01:31:00.160]   Your cars again
[01:31:00.160 --> 01:31:04.880]   But you're just another edison because tesla broke a patent all you ever broke were hearts
[01:31:04.880 --> 01:31:09.040]   I can't believe you tore humanity apart. Wow, that's good. Wow
[01:31:09.040 --> 01:31:12.320]   It's so good. She's so smart
[01:31:13.280 --> 01:31:15.280]   Yeah, she's right
[01:31:15.280 --> 01:31:17.440]   Broker hearts or better in making chiptunes
[01:31:17.440 --> 01:31:20.320]   With millions of views. It's awesome
[01:31:20.320 --> 01:31:25.280]   She's even bother doing a video. It's just like yeah, there's the song. It's all you need
[01:31:25.280 --> 01:31:30.720]   You don't even win. You don't even win that well if you started on tick-tock. So there's videos of her on tick-tock. Ah, okay
[01:31:30.720 --> 01:31:37.680]   All right, kori. We're gonna let you go because it's it's been 90 minutes and you're about to turn into a pumpkin
[01:31:38.080 --> 01:31:43.200]   It's always great. What are you gonna be for halloween this year real quick? Uh, we are going as dead
[01:31:43.200 --> 01:31:45.680]   Dead
[01:31:45.680 --> 01:31:49.040]   Sweeney Todd and dead misses. What's her name? So I'm Sweeney Todd
[01:31:49.040 --> 01:31:53.760]   I'm gonna have a cutthroat and a razor and my wife is gonna have burn skin and a pie
[01:31:53.760 --> 01:31:59.520]   All right, she's Angela Lansbury in this what's I suppose he she not is she too old to go out with you now
[01:31:59.520 --> 01:32:01.600]   No, she's she's making her own costume
[01:32:01.600 --> 01:32:04.720]   We're actually going home to England for Halloween. We're gonna see our family
[01:32:05.200 --> 01:32:11.440]   And there's a place that we rent out we rented at like 10 years ago now for our um our roommates
[01:32:11.440 --> 01:32:17.440]   40th birthday and it's a 16th century moted castle with 14 bedrooms
[01:32:17.440 --> 01:32:21.520]   Like 300 pounds a couple. That's Halloween itself
[01:32:21.520 --> 01:32:22.400]   That's perfect
[01:32:22.400 --> 01:32:26.160]   It'll be a little more expensive this year because we can't have as many people because of covid restrictions
[01:32:26.160 --> 01:32:31.760]   But we're having a giant halloween party there and they're all games people my wife worked in the games industry for years and years
[01:32:31.760 --> 01:32:34.480]   She was that she's a retired professional quake player
[01:32:35.040 --> 01:32:37.360]   uh, and uh, she excited about the
[01:32:37.360 --> 01:32:43.680]   The revised quake that just kind of she's she does she does uh technological storytelling for disney now
[01:32:43.680 --> 01:32:47.840]   She's so past she's tough, but but yeah, so we're gonna have like all these game people there
[01:32:47.840 --> 01:32:51.600]   We're gonna play where wolf we're gonna dress up. We have fireworks. We drink a lot. We eat a lot
[01:32:51.600 --> 01:32:55.600]   There's a couple of really good cooks who come so we're all gonna be dressed up in doing that
[01:32:55.600 --> 01:33:00.880]   And I I can't let you go without telling you that everybody in the world has been influenced by
[01:33:01.600 --> 01:33:05.600]   You and framework we've all gone out and bought frame with laptops. Thanks to you
[01:33:05.600 --> 01:33:08.800]   Framework just opened their marketplace. That'll be my pick of the week
[01:33:08.800 --> 01:33:12.720]   I'll show it in just a little bit, but you're right. This is a great laptop
[01:33:12.720 --> 01:33:19.120]   I'm streaming off of my framework right now. That's the computer I'm plugged into. Yeah, just awesome. Cori doctor
[01:33:19.120 --> 01:33:23.920]   Bless you. Everybody should run out of cori get the paper back. It's out now
[01:33:23.920 --> 01:33:28.000]   um of uh your latest volume which
[01:33:28.000 --> 01:33:31.200]   Is not the unravels. Oh, yeah, that's right
[01:33:31.760 --> 01:33:38.720]   Attach snuffus in zippepa box. Yeah, and that's the then there's the german edition which is called the flater mouse
[01:33:38.720 --> 01:33:42.000]   Thank you, kori
[01:33:42.000 --> 01:33:51.200]   Wow
[01:33:51.200 --> 01:33:54.800]   It's it's when cori is here. It's hard to get a word to edgewise but on the other hand
[01:33:54.800 --> 01:33:59.440]   That operates that speed who wants to get a word edgewise. I just want to listen. You know, you know
[01:33:59.440 --> 01:34:06.560]   You just sit back and listen and take it all let it roll. Yeah, wow just uh some really good powerful
[01:34:06.560 --> 01:34:08.720]   uh thoughts
[01:34:08.720 --> 01:34:10.560]   Uh, I should have brought to you by
[01:34:10.560 --> 01:34:13.200]   Nureva
[01:34:13.200 --> 01:34:18.960]   You know sometimes you need to get together in a large room with a lot of other people and you might be thinking
[01:34:18.960 --> 01:34:24.240]   Can I stand six feet away from that guy because he ain't wearing a mask nureva
[01:34:24.240 --> 01:34:27.600]   Is the solution as we get back to work
[01:34:28.160 --> 01:34:34.960]   For getting full room mic coverage in midsize a large meetings and learning spaces without
[01:34:34.960 --> 01:34:37.920]   kind of violating uh
[01:34:37.920 --> 01:34:43.520]   Health rules keeping people socially distancing allows you to move around like to face any way you want
[01:34:43.520 --> 01:34:47.600]   And yet you can be heard even in a giant room. Let me compare
[01:34:47.600 --> 01:34:51.600]   Let me compare the two different ways you might want to solve this problem
[01:34:51.600 --> 01:34:56.960]   There are lots of simple plug and play audio solutions for huddle rooms, but getting full room mic coverage
[01:34:57.760 --> 01:35:01.040]   In a midsize or a large meeting and learning spaces always meant
[01:35:01.040 --> 01:35:04.800]   In the past anyway making a leap into complexity
[01:35:04.800 --> 01:35:09.840]   The high cost of pro av av solutions nureva is changing all that
[01:35:09.840 --> 01:35:17.440]   Simplifying almost every aspect of audio conferencing. So if let's say you want to you and this is probably your initial instinct
[01:35:17.440 --> 01:35:20.400]   Well, we're gonna bring the pros in for this big room
[01:35:20.400 --> 01:35:21.760]   Uh
[01:35:21.760 --> 01:35:27.680]   You get a pro av system that means multiple components mics and speakers installed in the ceiling spread across
[01:35:27.680 --> 01:35:34.320]   The table a lot of cables. You got to get technicians in to determine the required components to install them to calibrate them
[01:35:34.320 --> 01:35:41.840]   You might even have to bring them back from time to time takes days for installation costs tens of thousands of dollars per room for purchase and installation
[01:35:41.840 --> 01:35:44.160]   Maybe your company's actually been through that process
[01:35:44.160 --> 01:35:51.600]   I've got a better way something called nureva. They actually have a patent on something they call microphone mist
[01:35:51.600 --> 01:35:56.720]   Technology it's computational audio you get true full room coverage
[01:35:57.040 --> 01:36:00.480]   But you don't have to put in a lot of mics which have to be cleaned in between meetings
[01:36:00.480 --> 01:36:02.320]   You don't have to have a lot of cabling
[01:36:02.320 --> 01:36:06.960]   You're gonna get exceptional audio for a room up to 25 by 25 feet with one
[01:36:06.960 --> 01:36:10.800]   Simple sound bar like integrated microphone and speaker bar
[01:36:10.800 --> 01:36:17.200]   You got got a bigger space two bars it covers space up to 30 by 50 feet and you can do it yourself
[01:36:17.200 --> 01:36:21.360]   It takes about 30 minutes two screws one cable boom you're done
[01:36:21.360 --> 01:36:24.560]   And it is a lot less than a pro av system
[01:36:24.560 --> 01:36:27.840]   It's going to do a better job too beam forming mic systems
[01:36:27.840 --> 01:36:31.280]   You know as long as you stay in exactly the right spot
[01:36:31.280 --> 01:36:34.400]   Right within the beams can work great, but as soon as you move
[01:36:34.400 --> 01:36:39.760]   Or or you face away from the beams boom you're gone and plus you got to recalibrate if you rearrange the room
[01:36:39.760 --> 01:36:44.640]   This microphone mist technology is is really cool very sophisticated
[01:36:44.640 --> 01:36:51.680]   You get true full room coverage from these small devices everyone has heard no matter where they move
[01:36:52.240 --> 01:36:59.600]   Even if they're facing away from the microphone and it's continuously auto calibrated plus you get a console with your nareva
[01:36:59.600 --> 01:37:05.440]   It's a simple easy to use web based platform. You can monitor manage adjust and scale your fleet of systems
[01:37:05.440 --> 01:37:10.240]   Yes more than one system even from anywhere. You won't need any training. It's very easy to use
[01:37:10.240 --> 01:37:14.080]   The you know a pro av system you're probably gonna have to bring it a pro
[01:37:14.080 --> 01:37:19.360]   Or at least a lot of training just to operate the software not with nareva
[01:37:19.440 --> 01:37:24.320]   I I have to say you got to look at this. It is a simple intuitive platform
[01:37:24.320 --> 01:37:30.240]   That lets you easily monitor manage adjust and scale your fleet of systems from anywhere. No training required
[01:37:30.240 --> 01:37:32.640]   You can install it yourself
[01:37:32.640 --> 01:37:35.200]   And it's a heck of a lot less expensive. The question is
[01:37:35.200 --> 01:37:41.200]   Are you still going to do that pro av system? Maybe you ought to think about nareva and you are eva
[01:37:41.200 --> 01:37:43.440]   nareva.com
[01:37:43.440 --> 01:37:44.640]   slash
[01:37:44.640 --> 01:37:51.840]   Twit this patented microphone miss technology is is literally computational audio. It's very cool nareva
[01:37:51.840 --> 01:37:54.800]   Dot com slash twit. We thank nareva so much
[01:37:54.800 --> 01:38:00.400]   You know how I feel about audio. It's so important. We really appreciate their support of our show
[01:38:00.400 --> 01:38:05.200]   And we thank you for supporting the show by going to that special address so they know you saw it here nareva
[01:38:05.200 --> 01:38:07.760]   dot com
[01:38:07.760 --> 01:38:09.360]   slash twit
[01:38:09.360 --> 01:38:13.440]   Anything else you want to say or should we just wrap this up? I mean I feel like we're
[01:38:14.240 --> 01:38:16.240]   I'm exhausted
[01:38:16.240 --> 01:38:24.400]   To the changelog and stuff to oh crap the changelog the changelog
[01:38:24.400 --> 01:38:28.800]   No, no, let me just check and see if there's anything important really the most important thing is
[01:38:28.800 --> 01:38:34.240]   It's pretty funny actually google announced last week that on the 19th
[01:38:34.240 --> 01:38:38.400]   They were going to do their pixel six. There is nothing we don't know about the pixel six
[01:38:38.400 --> 01:38:43.680]   But maybe google can find something that we don't know and release that so we will be here 10 am pacific
[01:38:44.080 --> 01:38:48.400]   Jason holland. I'll be streaming then um the napple says
[01:38:48.400 --> 01:38:50.400]   All my beer
[01:38:50.400 --> 01:38:57.360]   We're gonna announce the day before we're gonna announce our new uh apple silicon uh laptops and maybe a mac mini
[01:38:57.360 --> 01:39:01.440]   So we'll be doing that that'll be mica and meet 10 am on monday
[01:39:01.440 --> 01:39:05.760]   And then sam's like hey wait wait a minute wait a minute guys
[01:39:05.760 --> 01:39:10.640]   We're gonna do sam's on that least part two on wednesday
[01:39:11.200 --> 01:39:17.040]   Saday roll and uh and and mary jofola this morning reminded me that the thursday is when the uh
[01:39:17.040 --> 01:39:20.160]   Microsoft duo phone comes out. So
[01:39:20.160 --> 01:39:23.360]   It's a jam pen week next week
[01:39:23.360 --> 01:39:31.120]   It's gonna be crazy is the pixel six rumor to have optical image stabilization. Uh, yes, I believe it will
[01:39:31.120 --> 01:39:36.480]   There's actually the camera looks interesting uh 50 megapixels on one of the lenses
[01:39:36.480 --> 01:39:40.560]   um, i'm trying to remember some details i think
[01:39:41.200 --> 01:39:43.200]   the pixel pixel binning
[01:39:43.200 --> 01:39:47.200]   uh, I think the the the new anti shake stuff is in the
[01:39:47.200 --> 01:39:52.400]   pixel in the uh in the chip itself rather than right more that's what I was hoping
[01:39:52.400 --> 01:39:57.840]   Yeah, yeah, the pixel shifting they call it like apple does i think that's the case and I do think
[01:39:57.840 --> 01:40:02.960]   What's going to be interesting is they're making their own system on a chip with lots of image processing and other
[01:40:02.960 --> 01:40:06.640]   Uh stuff built in so I think that's going to be quite interesting
[01:40:06.640 --> 01:40:09.680]   Um, so that will be that will be a big
[01:40:10.400 --> 01:40:13.600]   Gosh, I feel bad. Jason how i'll put all this effort into the change log
[01:40:13.600 --> 01:40:20.720]   You're playing a thing. Let me just say google tv multi-user sport crumbs r as his follow button now available
[01:40:20.720 --> 01:40:26.080]   Assistant driving mode adds bluetooth auto lunches old and red auto disappears for more users
[01:40:26.080 --> 01:40:31.440]   Google clock seven point run rolling out with the material u clock styles as part of android 12
[01:40:31.440 --> 01:40:37.360]   Google and youtube will stop showing ads on content that denies climate change and youtube is gonna finally
[01:40:37.760 --> 01:40:40.960]   Stop making its year-end rewind videos at that
[01:40:40.960 --> 01:40:44.880]   Google change log
[01:40:44.880 --> 01:40:49.360]   That was good. We got it all in
[01:40:49.360 --> 01:40:53.760]   You were speaking at kori speed. I yeah, inspired you. Yeah
[01:40:53.760 --> 01:40:57.840]   Even I talk fast kori thinks fast too. That's a hard part
[01:40:57.840 --> 01:41:02.160]   Actually, I really sorry kori's gone because I really wanted to ask him about this piece
[01:41:02.160 --> 01:41:05.120]   uh on the internet by evan hatch
[01:41:06.080 --> 01:41:13.360]   It's it's a eulogy in a way to a guy at a memorial guy named leonna lens sassaman
[01:41:13.360 --> 01:41:20.800]   Uh, in fact, he's actually in the blockchain here. Here is his picture in the blockchain block 1-3-8-7-2-5
[01:41:20.800 --> 01:41:27.120]   But in the process of writing this sassaman was a well-known cypherpunk
[01:41:27.120 --> 01:41:29.040]   uh
[01:41:29.040 --> 01:41:30.640]   he makes
[01:41:30.640 --> 01:41:32.640]   a backhanded but
[01:41:33.200 --> 01:41:37.200]   Clearly intentional case that that is satoshi nakamoto
[01:41:37.200 --> 01:41:44.960]   In every respect sassaman had the skills the knowledge had done work in very similar veins
[01:41:44.960 --> 01:41:49.760]   Uh, he took his own life on july 3rd 2011 10 years ago
[01:41:49.760 --> 01:41:54.080]   uh, only two months before he died satoshi sent
[01:41:54.080 --> 01:41:56.800]   its final communication
[01:41:56.800 --> 01:42:02.240]   Saying i've moved on to other things and probably won't be around in the future
[01:42:02.320 --> 01:42:04.480]   This is two months before sassaman's suicide
[01:42:04.480 --> 01:42:09.920]   Uh, it's well worth reading this and I as far as i'm concerned
[01:42:09.920 --> 01:42:16.400]   We've seen a lot of candidates for who is satoshi nakamoto the creator of bitcoin. This is an absolutely
[01:42:16.400 --> 01:42:19.120]   airtight case
[01:42:19.120 --> 01:42:21.120]   that this guy
[01:42:21.120 --> 01:42:23.600]   Was satoshi nakamoto. It also explains why
[01:42:23.600 --> 01:42:29.120]   satoshi's 64 billion dollars in bitcoin has never been touched
[01:42:31.280 --> 01:42:34.320]   Because the owner the guy only guy who can access it is gone
[01:42:34.320 --> 01:42:37.600]   But uh, lens sassaman
[01:42:37.600 --> 01:42:40.160]   Did he have a will?
[01:42:40.160 --> 01:42:42.160]   Ah, I don't know um
[01:42:42.160 --> 01:42:46.640]   I don't know he's a really was a really interesting guy. He uh
[01:42:46.640 --> 01:42:51.840]   Was part of the cypherpunk community lived with bram kolan the and creator of bit torrent
[01:42:51.840 --> 01:42:53.920]   Uh
[01:42:53.920 --> 01:42:58.720]   He was a contributor on the cypherpunk mailing list which is where nakamoto first announced bitcoin
[01:42:59.920 --> 01:43:04.400]   Um, I think in every respect this is a very strong
[01:43:04.400 --> 01:43:09.520]   Case not going to be on the cover of news week because no one knows who lens sassaman is but
[01:43:09.520 --> 01:43:12.400]   Um, I think it's a very strong case
[01:43:12.400 --> 01:43:15.280]   Uh that this is the guy
[01:43:15.280 --> 01:43:19.680]   Um, so if you i don't uh, it's a medium post evan hatch
[01:43:19.680 --> 01:43:22.480]   Dot medium.com
[01:43:22.480 --> 01:43:27.440]   Uh, when I read it, I kind of got chills. I thought yeah that this is the guy
[01:43:27.920 --> 01:43:29.280]   This is the guy
[01:43:29.280 --> 01:43:34.960]   And uh, you know, it's a very complicated case that he makes so I was actually interested in asking uh, cori about this
[01:43:34.960 --> 01:43:38.240]   But we'll get have to just get cori back to talk about
[01:43:38.240 --> 01:43:40.800]   Um
[01:43:40.800 --> 01:43:42.880]   Let us do
[01:43:42.880 --> 01:43:45.360]   our picks of the week and I guess because
[01:43:45.360 --> 01:43:49.600]   It's there's no stacey. I'm gonna have to start with you mr
[01:43:49.600 --> 01:43:52.640]   Jeff Jarvis
[01:43:52.640 --> 01:43:56.400]   Well, uh, this is my effort to give jammer be a complete heart attack
[01:43:57.040 --> 01:44:02.800]   Having gone through a lot of f bombs from he's already he's already busy. Yes. Now now
[01:44:02.800 --> 01:44:07.440]   Uh line 148 you can't show much of it. You can show some of it leo
[01:44:07.440 --> 01:44:14.960]   public this is this is this is the work of a regulator is what's what i what i'm gonna use my regulators offcom the media and now internet regulator in the
[01:44:14.960 --> 01:44:20.880]   UK put out a whole report of public attitudes toward offensive language on tv and radio
[01:44:20.880 --> 01:44:26.000]   It's a quick reference guide to all these dirty words a lot of them. I've never heard of
[01:44:26.480 --> 01:44:30.000]   And we ain't talking we ain't talking to seven words
[01:44:30.000 --> 01:44:33.680]   No
[01:44:33.680 --> 01:44:35.680]   Man
[01:44:35.680 --> 01:44:36.480]   Oh my
[01:44:36.480 --> 01:44:41.440]   So i'll give you one that's fairly sick. It's being by the way. It's being blocked on my site. So
[01:44:41.440 --> 01:44:48.800]   Maybe our security systems are preventing me from seeing this or could you know what a bell end is?
[01:44:48.800 --> 01:44:50.960]   Thank you mr. Russell
[01:44:50.960 --> 01:44:57.280]   The ell eendia belland belland no no idea it is the glands of a penis for safe to say
[01:44:57.280 --> 01:45:01.120]   Uh, but it is also somebody you think is a jerk in the UK
[01:45:01.120 --> 01:45:06.880]   Right. I never heard this before there's a town and of course is a town in england called belland
[01:45:06.880 --> 01:45:09.600]   Uh-huh many the poor residents now. Uh-huh
[01:45:09.600 --> 01:45:14.080]   Um all kinds of uh minor words bit i'd never heard of
[01:45:14.080 --> 01:45:15.760]   bloody
[01:45:15.760 --> 01:45:17.760]   bloody i know yeah
[01:45:18.000 --> 01:45:24.480]   Bugger bugger right now. Oh what crap. I got kicked off the bbc for saying crap. Yeah, well
[01:45:24.480 --> 01:45:26.160]   Um
[01:45:26.160 --> 01:45:32.480]   Effing those are the minor words then you get up to uh bastard belland i'm probably what i can say
[01:45:32.480 --> 01:45:35.360]   It's all right. It's just a bit. It's really good to stop right now. Just stop right now
[01:45:35.360 --> 01:45:38.880]   Poor victor because it's not by the way john doesn't do the editing victors
[01:45:38.880 --> 01:45:42.960]   The one who's gonna have to talk just defends vict john writes it all down as we're talking
[01:45:44.560 --> 01:45:51.840]   So it goes on and on and on and all kinds of words i've never heard of i i dare not say because i don't know what they mean
[01:45:51.840 --> 01:45:54.720]   Um, this is like a regular pages
[01:45:54.720 --> 01:45:57.520]   How this is useful i'm not sure
[01:45:57.520 --> 01:46:04.560]   But there it is once again. Oh fcom do in their job making the world safe for oh f
[01:46:04.560 --> 01:46:07.200]   Oh f. Oh fcom
[01:46:07.200 --> 01:46:13.920]   Your other number i do want to mention if you don't want to mention it which is the number of people who've seen squid game now
[01:46:14.720 --> 01:46:17.680]   Mm, which is a change so a hundred and eleven million
[01:46:17.680 --> 01:46:22.720]   Yep, and so i wanted to put that in context of course those people have paid for it in context
[01:46:22.720 --> 01:46:28.160]   I looked up the 2015 superroll was 114 million in the u.s. So we're very close
[01:46:28.160 --> 01:46:34.480]   It's number one on flicks in 94 countries. Have you seen it yet? No, have you yeah i watched the first one
[01:46:34.480 --> 01:46:37.120]   I don't know if i'll watch anymore. It's very violent
[01:46:37.120 --> 01:46:42.240]   And actually it's not that inter it's not there's nothing special about it
[01:46:42.720 --> 01:46:46.000]   And do you want to tell you i have not watched it because
[01:46:46.000 --> 01:46:51.120]   The people that i've heard mention it aren't the most intelligent people so i said
[01:46:51.120 --> 01:46:53.760]   I'll tell you the premise
[01:46:53.760 --> 01:46:59.280]   So i've been waiting on someone that's in my circle to you know to talk about it and say hey, no i should check it
[01:46:59.280 --> 01:47:02.800]   I watch it because i thought i should uh, there's only i think nine episodes
[01:47:02.800 --> 01:47:08.480]   Uh, it starts following the life of a down and out guy in south korea
[01:47:08.640 --> 01:47:13.520]   It is apparently i'm told we were talking about it on twit on the sunday. Maybe it was yesterday
[01:47:13.520 --> 01:47:16.720]   uh, on mac break weekly it is a
[01:47:16.720 --> 01:47:20.000]   suddenly very common style of uh
[01:47:20.000 --> 01:47:26.640]   media in south korea where the equality between the very rich and the very poor is is even more pronounced than it is here
[01:47:26.640 --> 01:47:30.480]   And like periscite the academy award-winning movie
[01:47:30.480 --> 01:47:32.720]   Of last year
[01:47:32.720 --> 01:47:36.240]   It's it's really about the very down and out in in south korea
[01:47:36.880 --> 01:47:40.080]   Coming face to face with a very wealthy and all right
[01:47:40.080 --> 01:47:42.480]   the premise is
[01:47:42.480 --> 01:47:47.520]   These down and out folks who owe a lot of money or whatever are enticed into this game
[01:47:47.520 --> 01:47:50.480]   Uh, where they can win a lot of money
[01:47:50.480 --> 01:47:57.760]   What they don't know at first is uh, they're playing for pretty high stakes. I don't want to spoil it so
[01:47:57.760 --> 01:48:04.160]   Uh, but i will say uh, the games are games that you would recognize the first one's red light green light
[01:48:05.840 --> 01:48:10.720]   There is a korean game the kids play called squid game that we don't know here in the states
[01:48:10.720 --> 01:48:14.560]   But is very apparently very popular with the koreans so they're playing these children's games
[01:48:14.560 --> 01:48:17.360]   But the consequences of loosing are dire
[01:48:17.360 --> 01:48:26.480]   And uh, uh, and it's very dystopian and and weird. It's the production values are in are high and interesting
[01:48:26.480 --> 01:48:28.560]   but it's not
[01:48:28.560 --> 01:48:32.960]   That emotionally interesting and ends up being you know about these five or six people who
[01:48:33.440 --> 01:48:37.920]   You know band together to try to survive, you know this weird dystopian
[01:48:37.920 --> 01:48:44.960]   fantasy now much props and credit to the writer of this this series because from what I read is this
[01:48:44.960 --> 01:48:50.560]   This was something that was written a long time ago that sort of got kicked down and oh interesting
[01:48:50.560 --> 01:48:56.880]   This person was down to their last couple hundred but a couple hundred dollars had to sell their laptop and things of this nature
[01:48:56.880 --> 01:49:00.160]   Just to make ends neat and now they're sitting quite pretty
[01:49:00.800 --> 01:49:02.880]   After the script got into the hands of netflix
[01:49:02.880 --> 01:49:08.800]   Yeah, here's a picture from it that just give you an idea of the production of value
[01:49:08.800 --> 01:49:15.520]   Yeah, i've seen the little avatars and it will be the number one halloween costumes
[01:49:15.520 --> 01:49:21.360]   Yeah, everybody wanted to do that for halloween. Yeah, because it's each is another the reason why I was like do I even want to watch this?
[01:49:21.360 --> 01:49:28.240]   I don't know. It's a little somebody in the chat room. I think you're right. Uh, it's saying, uh, it's kind of like uh, the hunger games
[01:49:28.320 --> 01:49:33.600]   It's a little good games a little bit like that, but um, um,
[01:49:33.600 --> 01:49:38.560]   Isan johnson who I I think the world of i'm often on a msmbc political commentator and professor
[01:49:38.560 --> 01:49:42.160]   So he appeared in a green velour jacket with a white stripe on
[01:49:42.160 --> 01:49:45.280]   I agree in a show in because he's very pop culture
[01:49:45.280 --> 01:49:48.240]   Intribute to squid game. Oh interesting
[01:49:48.240 --> 01:49:56.000]   Yeah, the I think the costumes this year will be blackface masks with with geometric shapes triangles and squares and circles on them
[01:49:56.480 --> 01:50:03.120]   But I don't know anyway. I wanted to steal that number 111 million views so far. It only came out last month
[01:50:03.120 --> 01:50:09.360]   So it's already unbelievable white white which which and that's actually told us for once how they could stop it was so many
[01:50:09.360 --> 01:50:11.520]   I think I mentioned this before last week, but it's so many
[01:50:11.520 --> 01:50:17.680]   That the south korean isp's are demanding netflix share the cost with them because so many people are downloading
[01:50:17.680 --> 01:50:21.760]   This show don't watch it and they're mad and they're mad at netflix
[01:50:21.760 --> 01:50:25.520]   mr. Ant Pruitt's thing you got a few today
[01:50:26.320 --> 01:50:34.640]   Yeah netflix the first one is just totally random youtube serving up a funny video to me and this one was irish people blind test
[01:50:34.640 --> 01:50:38.880]   uh irish whiskey versus american whiskey and
[01:50:38.880 --> 01:50:41.920]   They it's not the same thing at all is it?
[01:50:41.920 --> 01:50:48.240]   No, it's not but it was fascinating to hear what they described and and uh from the
[01:50:48.240 --> 01:50:52.320]   The nozing and from the palette because it's pretty spot on
[01:50:52.800 --> 01:50:57.120]   But then there's the whole irish pride that they have and you know
[01:50:57.120 --> 01:51:01.440]   They sort of battle with that and had to say, you know, this this bourbon actually tastes
[01:51:01.440 --> 01:51:07.600]   Better than my irish whiskey, you know, so it was a lot of that in here. You would disagree with that would you not uh ant?
[01:51:07.600 --> 01:51:12.560]   I'm not the biggest fan of irish whiskey. I don't care for jameson
[01:51:12.560 --> 01:51:20.720]   I like i like tolamore. I like that one, but that's two p.t. Irish. You know, I like p.t. See I like scotch
[01:51:21.120 --> 01:51:25.360]   That's p.d. I love lagoville in 16. That's probably my favorite one, but
[01:51:25.360 --> 01:51:29.520]   Irish whiskey tastes a little too much like rye to me
[01:51:29.520 --> 01:51:30.640]   Uh
[01:51:30.640 --> 01:51:35.600]   My father who taught me to drink bourbon says that anybody who drinks scotch would bring their own bathwater
[01:51:35.600 --> 01:51:41.760]   See to me bourbon's too sweet and syrupy and i too i mean i like it, but it's not
[01:51:41.760 --> 01:51:46.800]   I think it's i don't like all burbins. I like i like a lot of them. What else you got a few here
[01:51:46.800 --> 01:51:54.080]   Let's get them all uh the next one is uh hall h show. I was on their podcast not too long ago recorded it
[01:51:54.080 --> 01:51:56.640]   excuse me
[01:51:56.640 --> 01:52:04.480]   Recorded it and this uh podcast that deals a lot with uh geek culture and pop culture and I had no idea how to add me on
[01:52:04.480 --> 01:52:07.840]   Because i'm not cool enough for any of that stuff, but it was a fun conversation
[01:52:07.840 --> 01:52:10.560]   uh just talking about content creators and
[01:52:11.040 --> 01:52:15.680]   I talked about Chad and in my time with him and it was pretty fun conversation
[01:52:15.680 --> 01:52:20.560]   That's the hall h show. I believe it comes from um comic con and hall h
[01:52:20.560 --> 01:52:27.040]   Uh is how oh I get it title hall h I get it. Mm-hmm. So sure that will never have me on
[01:52:27.040 --> 01:52:29.680]   Get that right now
[01:52:29.680 --> 01:52:32.320]   Never going to talk about comic books on the show
[01:52:32.320 --> 01:52:35.120]   and and lastly
[01:52:35.440 --> 01:52:43.680]   My pick is all systems red. This is a book in the murder bot series, which I am going to start reading because
[01:52:43.680 --> 01:52:48.320]   Stacey recommended these. Yeah, miss Stacey higgin bothem recommended this
[01:52:48.320 --> 01:52:52.160]   Um to be read because we're going to do this as part of our
[01:52:52.160 --> 01:52:55.520]   book club series for our club twit members. So
[01:52:55.520 --> 01:52:58.160]   If you're listening to this go and get
[01:52:58.160 --> 01:53:03.200]   All systems ready. You can get it on kindle for like four bucks or get the audio of book edition
[01:53:03.600 --> 01:53:05.600]   We're going to have our book club
[01:53:05.600 --> 01:53:11.360]   Hosted in november so you got a couple weeks to go ahead and get it done and be ready to join
[01:53:11.360 --> 01:53:13.920]   if your club twit member
[01:53:13.920 --> 01:53:16.240]   first
[01:53:16.240 --> 01:53:21.040]   I already got this because uh stacey recommend is the first in the murder bot series
[01:53:21.040 --> 01:53:23.600]   So, uh
[01:53:23.600 --> 01:53:28.320]   I hope we can do all of the murder bots. We'll see when is stacey's um book club
[01:53:28.320 --> 01:53:32.800]   Uh, it's in november. I believe it's like the 19th or something like that
[01:53:32.800 --> 01:53:38.080]   So you gotta go two weeks. Yeah, yeah, that's good because it's it takes me a while to read a book
[01:53:38.080 --> 01:53:41.360]   So i'm so glad stacey's finally doing that. That's great
[01:53:41.360 --> 01:53:44.640]   All systems read by martha wells
[01:53:44.640 --> 01:53:48.960]   And uh the first of the murder bot diaries series and
[01:53:48.960 --> 01:53:55.120]   Thank you, uh ant for doing a great job last week with steve gibson that is now on the twit plus feed
[01:53:55.120 --> 01:53:59.680]   So if you are member of club twit and you missed the uh q&a it was great
[01:53:59.680 --> 01:54:06.240]   You know all of that stuff that he talked about i've known steve for 25 years or 20 years at least and so
[01:54:06.240 --> 01:54:14.720]   Couple more than 20 so i've heard most of those stories. Yeah, but just you know, it's great to hear him. It really is he's amazing. Yeah
[01:54:14.720 --> 01:54:22.400]   Yeah, i'm dead serious this this could have been a little biopic or something. Yeah, i don't see why it hasn't been
[01:54:22.400 --> 01:54:28.960]   It was great driving down that that dead end road and yeah, there's some great stuff in there
[01:54:28.960 --> 01:54:30.960]   So yeah, if you haven't listened to it
[01:54:30.960 --> 01:54:35.680]   Here's the deal you got to be a member of club twit now some people might say well
[01:54:35.680 --> 01:54:38.560]   Why would you do that because
[01:54:38.560 --> 01:54:44.240]   We we started club twit to help uh subsidize what we do to put it on the air
[01:54:44.240 --> 01:54:50.640]   Advertisers don't cover the entire cost so we started club twit to give you the audience a chance to support
[01:54:50.640 --> 01:54:54.000]   What we do and it's seven dollars a month, which is not very much money
[01:54:54.080 --> 01:54:59.520]   You get the ad-free versions of all of our shows because if you are paying after all you shouldn't have to hear ads
[01:54:59.520 --> 01:55:05.360]   I've always I've always hated it when they charge and make you listen to ads you also get access to the twit plus feed
[01:55:05.360 --> 01:55:11.600]   Which is a lot of stuff. It's the untitled linux show the gizfiz the steve gipson interviews the games we play
[01:55:11.600 --> 01:55:16.800]   Lisa and i will be on next week that kind of thing you also get access to our members only discord
[01:55:16.800 --> 01:55:23.120]   It's a wonderful place to chat with hosts producers and lots of other club members
[01:55:24.000 --> 01:55:28.560]   Three or four thousand strong now who will talk about everything including comic books
[01:55:28.560 --> 01:55:33.840]   And and and uh all kinds of stuff. I think it's well worth seven bucks
[01:55:33.840 --> 01:55:39.520]   I really do and all you have to do is go to twit.tv slash club twit. It's month to month
[01:55:39.520 --> 01:55:42.080]   There's no it's not you're not sign up for a year or anything if you
[01:55:42.080 --> 01:55:43.840]   Beside you're not getting your seven bucks worth
[01:55:43.840 --> 01:55:47.600]   I certainly wouldn't want you to have to stick around so you can you can quit anytime
[01:55:47.600 --> 01:55:50.160]   But I think it's worth it and it sure does help us
[01:55:50.720 --> 01:55:55.680]   Keep the lights on here. So twit.tv slash club twit of course and is the community manager
[01:55:55.680 --> 01:56:01.520]   And uh, and we're really glad you're doing that because that's making it a lot more fun. I think you really are my best
[01:56:01.520 --> 01:56:04.080]   Thanks so much value to it. So thank you
[01:56:04.080 --> 01:56:06.960]   Uh, we do this week in google
[01:56:06.960 --> 01:56:13.680]   Every wednesday afternoon about 2 p.m. Pacific 5 p.m. Eastern 2100 UTC. You want to watch us do it live
[01:56:13.680 --> 01:56:18.880]   What we do we have a live stream going 24/7 whenever there's a production going on we turn that on
[01:56:19.280 --> 01:56:24.480]   You can watch our live stream at twit.tv slash live. There's live audio and video there you take your pick
[01:56:24.480 --> 01:56:29.120]   Uh, you could chat with us live at irc.twit.tv. That's open to all
[01:56:29.120 --> 01:56:35.200]   Uh, you can also get on-demand versions of the shows at twit.tv slash twig
[01:56:35.200 --> 01:56:39.600]   There's a youtube channel devoted to this week in google and if you get the on-demand shows
[01:56:39.600 --> 01:56:47.440]   Uh, you can still converse even if you're not watching live in our twit forums. That's ww.w.twit.community
[01:56:47.440 --> 01:56:50.960]   Those are great fun those are open all as is our mastodon
[01:56:50.960 --> 01:56:54.240]   Uh, that was what kori was talking about with the federated twitter
[01:56:54.240 --> 01:57:01.360]   Mastodon is at our instance is at twit.social allows you not only to talk with other members of the twit family
[01:57:01.360 --> 01:57:04.160]   But also to follow everybody on any other
[01:57:04.160 --> 01:57:10.880]   Mastodon instance so there are lots of people all over the mast diverse that you can the fediverse that you can follow
[01:57:10.880 --> 01:57:14.000]   Headiverse yeah better than the mastiverse that doesn't sound right
[01:57:14.000 --> 01:57:17.040]   That sounds pretty bad actually
[01:57:17.760 --> 01:57:20.720]   If you want to subscribe to our podcast that's always free
[01:57:20.720 --> 01:57:25.760]   And you can always do that in any podcast client just search for twit or this week in google either way
[01:57:25.760 --> 01:57:30.160]   And if you do subscribe and your podcast client allows you to leave a review
[01:57:30.160 --> 01:57:35.440]   Please give us a five star review tell the world about twig. We'd like to spread the word
[01:57:35.440 --> 01:57:38.320]   Thank you everybody. Thank you aunt
[01:57:38.320 --> 01:57:40.640]   Uh, thank you jeff
[01:57:40.640 --> 01:57:45.520]   And pruet is on twit.tv slash hands-on photography twit.tv slash hop
[01:57:46.240 --> 01:57:48.240]   Every week where you got coming up?
[01:57:48.240 --> 01:57:50.640]   Oh wow
[01:57:50.640 --> 01:57:55.360]   At the time of this recording we're getting ready to have episode 100
[01:57:55.360 --> 01:57:57.840]   congratulations
[01:57:57.840 --> 01:58:04.960]   Yay, whoo that fires me up. Sorry. So didn't mean hit the desk. No, i'm excited for you. That's great
[01:58:04.960 --> 01:58:08.400]   So big news celebrate the 100th twit.tv slash hop
[01:58:08.400 --> 01:58:14.800]   Jeff Jarvis is at buzz machine.com. He's also the director of the townite center for entrepreneurial journalism at the
[01:58:14.800 --> 01:58:16.800]   kraa
[01:58:16.800 --> 01:58:21.440]   Graduate school of journalism at the city university of new york
[01:58:21.440 --> 01:58:23.920]   Thank you jeff for being another
[01:58:23.920 --> 01:58:28.160]   Thank you yet and of course. Thanks to kori doctor. Oh his blog is at pluralistic
[01:58:28.160 --> 01:58:30.640]   Dot net
[01:58:30.640 --> 01:58:35.040]   And uh, don't forget attack surface his new novel which is now out in paperback
[01:58:35.040 --> 01:58:40.800]   And available everywhere. Thank you for joining us. We'll see you next time on this week in google
[01:58:41.360 --> 01:58:46.160]   Bye bye android is constantly evolving and if you're part of the android faithful
[01:58:46.160 --> 01:58:49.360]   Then you'll be just as excited about it as i am
[01:58:49.360 --> 01:58:55.360]   i'm jason howl host of all about android along with my co-hosts florence ion and ron richards where every week
[01:58:55.360 --> 01:59:02.000]   We cover the news we cover the hardware and we cover the apps that are driving the android ecosystem plus
[01:59:02.000 --> 01:59:10.080]   We invite people who are writing about android talking about android and making android onto the show every tuesday at twit.tv
[01:59:10.400 --> 01:59:12.400]   Look for all about android
[01:59:12.400 --> 01:59:14.400]   You
[01:59:14.400 --> 01:59:16.400]   You
[01:59:16.400 --> 01:59:18.400]   You
[01:59:18.400 --> 01:59:20.400]   You
[01:59:20.400 --> 01:59:22.980]   (upbeat music)

