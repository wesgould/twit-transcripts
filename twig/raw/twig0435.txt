;FFMETADATA1
title=Worst Queso Scenario
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=435
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.240]   It's time for Twig this week in Google last day before the net neutrality vote we'll talk a little bit about.
[00:00:04.240 --> 00:00:09.240]   That, we have some new apps from Google, a new camera app that's really sweet,
[00:00:09.240 --> 00:00:15.480]   a couple of their, kind of silly, and we'll unbox something big and heavy from Google.
[00:00:15.480 --> 00:00:18.960]   By the way, the Google home is upside down.
[00:00:18.960 --> 00:00:21.080]   It will work best if you turn it over.
[00:00:21.080 --> 00:00:23.680]   Oh, this week in Google, next.
[00:00:23.680 --> 00:00:28.560]   Netcasts you love.
[00:00:29.000 --> 00:00:30.360]   From people you trust.
[00:00:30.360 --> 00:00:35.720]   This is Twig.
[00:00:35.720 --> 00:00:43.760]   Bandwidth for this week in Google is provided by cash fly, C A C H E F L Y dot com.
[00:00:43.760 --> 00:00:54.960]   This is Twig this week in Google episode 435 recorded Wednesday, December 13, 2017.
[00:00:54.960 --> 00:00:56.040]   Worst case.
[00:00:56.040 --> 00:00:57.120]   So scenario.
[00:00:58.360 --> 00:01:01.840]   This week in Google is brought to you by video blocks from story blocks.
[00:01:01.840 --> 00:01:09.240]   Get all the high quality stock video, audio and images you can imagine for just $149 a year.
[00:01:09.240 --> 00:01:16.480]   Go to video blocks dot com slash Twig today and by Sonic twigs, 10 gigabit fiber
[00:01:16.480 --> 00:01:17.640]   internet service provided.
[00:01:17.640 --> 00:01:23.880]   Join Sonics internet revolution as they bring fast, affordable internet, phone and TV to homes
[00:01:23.880 --> 00:01:25.680]   and businesses all over California.
[00:01:25.920 --> 00:01:30.880]   Visit sonic.com/twit to sign up for service and receive your first month free.
[00:01:30.880 --> 00:01:37.040]   And by the ring video doorbell with ring, you can see and talk to anyone at your door
[00:01:37.040 --> 00:01:39.200]   from anywhere in the world using your smartphone.
[00:01:39.200 --> 00:01:41.600]   It's like calling ID for your home.
[00:01:41.600 --> 00:01:46.920]   Go to ring.com/twig and get up to $150 off a ring of security kit.
[00:01:46.920 --> 00:01:53.240]   It's time for Twig this week in Google show where we talk about really much more than
[00:01:53.240 --> 00:02:00.320]   Google everything going on in the world around us Facebook, Google, Amazon, Microsoft, not
[00:02:00.320 --> 00:02:03.520]   so much Microsoft Apple, not so much Apple.
[00:02:03.520 --> 00:02:07.800]   Jeff Jarvis is here, Professor of Journalism at the City University of New York, blogger
[00:02:07.800 --> 00:02:11.960]   at Buzz machine.com, author of so many great books, including what would Google do?
[00:02:11.960 --> 00:02:12.720]   You know what I'm doing?
[00:02:12.720 --> 00:02:13.400]   Public parts.
[00:02:13.400 --> 00:02:14.160]   You're poking me.
[00:02:14.160 --> 00:02:15.080]   I'm poking.
[00:02:15.080 --> 00:02:16.840]   What comes back is the poke back.
[00:02:16.840 --> 00:02:18.280]   Oh, say it ain't so.
[00:02:18.280 --> 00:02:22.440]   Oh, Lord, we'll talk about that in a second because I got to introduce our
[00:02:23.320 --> 00:02:27.800]   other partner here is partner in crime as it were Stacy Higginbotham.
[00:02:27.800 --> 00:02:34.560]   She's the host of Stacy on IOT, a great podcast with Kevin Tofol and the Stacy
[00:02:34.560 --> 00:02:40.320]   on IOT, a newsletter and you can find all her work at Stacy on IOT.com.
[00:02:40.320 --> 00:02:41.160]   Hello, Stacy.
[00:02:41.160 --> 00:02:42.440]   Boy, you look festive today.
[00:02:42.440 --> 00:02:44.640]   Oh, I think I put lipstick on.
[00:02:44.640 --> 00:02:45.120]   Whoo.
[00:02:45.120 --> 00:02:48.640]   Yeah, but I think the lace, you know, you're kind of in a white room and I just
[00:02:48.640 --> 00:02:50.120]   there's a there's an elegance.
[00:02:50.120 --> 00:02:50.560]   There's this.
[00:02:50.560 --> 00:02:51.040]   Yes.
[00:02:51.480 --> 00:02:53.640]   She's got elegance.
[00:02:53.640 --> 00:02:55.840]   Oh, she I'm now singing songs from that.
[00:02:55.840 --> 00:02:56.520]   Hello, Dolly.
[00:02:56.520 --> 00:02:58.680]   I was going to say that means I can't talk about queso.
[00:02:58.680 --> 00:03:01.080]   Got El no queso.
[00:03:01.080 --> 00:03:02.200]   No queso.
[00:03:02.200 --> 00:03:05.400]   Tomorrow is the day.
[00:03:05.400 --> 00:03:08.040]   You know, I haven't talked a whole lot about net neutrality.
[00:03:08.040 --> 00:03:10.720]   I've seen protests on the net Reddit when you go to Reddit has a big thing.
[00:03:10.720 --> 00:03:16.120]   And a few other sites put up a don't forget to call your Congress
[00:03:16.120 --> 00:03:16.760]   critter and all that.
[00:03:16.760 --> 00:03:20.400]   I feel like it's over because there's no way no matter what we do, we already
[00:03:20.440 --> 00:03:23.920]   got a more than a million comments in favor of net neutrality.
[00:03:23.920 --> 00:03:25.280]   And the FCC just goes, yeah, right.
[00:03:25.280 --> 00:03:25.960]   Never mind.
[00:03:25.960 --> 00:03:27.000]   Who cares what you think?
[00:03:27.000 --> 00:03:32.200]   Why not only do we have all these comments in favor of keeping net neutrality?
[00:03:32.200 --> 00:03:38.600]   We also have evidence of fraud that they're like, eh, we don't care.
[00:03:38.600 --> 00:03:40.840]   They literally don't care.
[00:03:40.840 --> 00:03:46.280]   And incidentally, just to add insult to injury, because remember, one of the
[00:03:46.280 --> 00:03:51.960]   things the FCC will do probably tomorrow is hand over all enforcement of net
[00:03:51.960 --> 00:03:56.640]   neutrality, a job, it really should be its job, federal communications
[00:03:56.640 --> 00:03:59.080]   commission to the federal trade commission.
[00:03:59.080 --> 00:04:03.920]   And then the FTC says what?
[00:04:03.920 --> 00:04:04.240]   Yeah.
[00:04:04.240 --> 00:04:09.280]   Federal Trade Commissioner Terrell McSweeney has repeatedly warned that her
[00:04:09.280 --> 00:04:11.360]   organization is not able to do the job.
[00:04:12.760 --> 00:04:16.640]   She actually wrote an article and says, quote, the FTC does not have
[00:04:16.640 --> 00:04:19.320]   specialized expertise in telecommunications.
[00:04:19.320 --> 00:04:23.440]   Well, duh, we don't have engineers that technical experience in data network
[00:04:23.440 --> 00:04:24.440]   management practices.
[00:04:24.440 --> 00:04:28.240]   We don't even have jurisdiction over common carriers.
[00:04:28.240 --> 00:04:32.080]   These are very real and significant limits to the effectiveness of our tools
[00:04:32.080 --> 00:04:35.880]   ensuring that networks are open and free of harmful discrimination.
[00:04:35.880 --> 00:04:41.800]   Which would explain to me exactly why I just wanted to give it to the FTC.
[00:04:42.040 --> 00:04:43.600]   There will be no enforcement.
[00:04:43.600 --> 00:04:44.640]   Right.
[00:04:44.640 --> 00:04:48.000]   The thing about this is that go ahead.
[00:04:48.000 --> 00:04:48.680]   Go ahead, Stacy.
[00:04:48.680 --> 00:04:53.680]   I was going to say it'll be purely deceptive trade, plus the practices,
[00:04:53.680 --> 00:04:56.160]   anti-competitive.
[00:04:56.160 --> 00:04:58.920]   And those things are hard to prove.
[00:04:58.920 --> 00:05:04.480]   And even under net neutrality, there was a, a method for carrier people to call
[00:05:04.480 --> 00:05:06.680]   that in and fight that.
[00:05:06.680 --> 00:05:08.200]   And it takes a long time.
[00:05:08.600 --> 00:05:13.320]   This is just, that's frustrating.
[00:05:13.320 --> 00:05:15.480]   Canada has gotten into the act.
[00:05:15.480 --> 00:05:20.120]   Apparently a Canadian government official said that net neutrality has become an
[00:05:20.120 --> 00:05:24.640]   issue in the NAFTA negotiations, or it isn't really the NAFTA negotiations, but
[00:05:24.640 --> 00:05:27.400]   negotiations over the replacement for the North America.
[00:05:27.400 --> 00:05:28.800]   Trump negotiations.
[00:05:28.800 --> 00:05:30.200]   The Trump negotiations.
[00:05:30.200 --> 00:05:34.640]   Canada's lead NAFTA negotiator, Steve Verhol, said to a parliamentary
[00:05:34.640 --> 00:05:38.280]   committee this week, we're including provisions like online consumer
[00:05:38.280 --> 00:05:42.920]   protection to ensure that it's provided for, and that we also have provisions to
[00:05:42.920 --> 00:05:46.480]   provide personal information protection, which we feel is essential in this kind
[00:05:46.480 --> 00:05:49.920]   of trade, along with our position that we want to protect net neutrality when it
[00:05:49.920 --> 00:05:51.920]   comes to digital trade.
[00:05:51.920 --> 00:05:57.160]   He says the US negotiating team is focused on trying to get Canada to accept
[00:05:57.160 --> 00:06:01.560]   our version of intermediary protections online where ISPs and third parties
[00:06:01.560 --> 00:06:06.040]   like Facebook cannot be held legally responsible for the behavior of their
[00:06:06.040 --> 00:06:08.040]   customers.
[00:06:08.040 --> 00:06:11.320]   But Canadians prefer to leave the issue to the courts and out of a trade
[00:06:11.320 --> 00:06:16.120]   agreement. He says, Verhol says, US negotiated team has not reacted
[00:06:16.120 --> 00:06:18.880]   positively to the Canadian pushback on net neutrality.
[00:06:18.880 --> 00:06:21.120]   Let me say a couple of things of my name.
[00:06:21.120 --> 00:06:21.760]   Yes, man.
[00:06:21.760 --> 00:06:26.240]   One University of Maryland poll out, I think yesterday said that 83% of
[00:06:26.240 --> 00:06:28.760]   Americans are in favor of keeping net neutrality.
[00:06:28.760 --> 00:06:31.400]   So this is by no means a political decision.
[00:06:31.400 --> 00:06:35.200]   Just like the tax bill, I would argue, but especially here, the people don't want
[00:06:35.200 --> 00:06:38.280]   79% of Republicans want to keep net neutrality.
[00:06:38.280 --> 00:06:39.840]   This is an oligopoly.
[00:06:39.840 --> 00:06:42.920]   This is big companies ruling the country.
[00:06:42.920 --> 00:06:46.320]   And I'm sounding like I'm, you know, Bernie, I'm not, I'm a middle of the road
[00:06:46.320 --> 00:06:47.480]   guy in so many ways.
[00:06:47.480 --> 00:06:53.400]   But this, this is an indication of of undemocratic governance.
[00:06:53.400 --> 00:06:54.640]   Point one, point two.
[00:06:54.640 --> 00:07:00.000]   Ajit Pai is saying he has absolutely zero.
[00:07:03.800 --> 00:07:07.440]   He's not consistent in any way in his philosophy, philosophy.
[00:07:07.440 --> 00:07:08.440]   He doesn't have any philosophy.
[00:07:08.440 --> 00:07:13.360]   So just like on the one hand, he's saying they're saying the government is saying,
[00:07:13.360 --> 00:07:19.400]   no CNN merger, but go ahead, Tribune by Trump.
[00:07:19.400 --> 00:07:23.560]   In this case, Ajit Pai is saying the foreign companies in the ISP should be able
[00:07:23.560 --> 00:07:26.120]   to do whatever they want, whatever the heck they want.
[00:07:26.120 --> 00:07:27.120]   That's fine.
[00:07:27.120 --> 00:07:31.000]   However, then he turns around the next breath and he told Tucker Carlson last
[00:07:31.000 --> 00:07:39.440]   night that there ought to be a law investigation or something stopping Facebook
[00:07:39.440 --> 00:07:43.120]   and Google from disadvantaging conservative content.
[00:07:43.120 --> 00:07:49.120]   Well, free speech is about includes the right to edit, includes the right to
[00:07:49.120 --> 00:07:51.760]   say what's hate speech and not to have it on your platform.
[00:07:51.760 --> 00:07:54.920]   But that's the, that's the meme that's being put out there.
[00:07:54.920 --> 00:07:58.680]   And there's no consistency in any way between those two things.
[00:07:58.680 --> 00:08:02.040]   You say a guy named Jeff Jarvis on MSNBC said it all.
[00:08:02.040 --> 00:08:08.000]   He said, this is all about enabling the oligopoly of cable and the telephone to
[00:08:08.000 --> 00:08:09.840]   control the near tie.
[00:08:09.840 --> 00:08:10.320]   Yeah.
[00:08:10.320 --> 00:08:10.960]   Look at those.
[00:08:10.960 --> 00:08:12.320]   For those of you listening, I have a tie.
[00:08:12.320 --> 00:08:17.240]   He's wearing a black suit and tie and well, it's much nicer.
[00:08:17.240 --> 00:08:21.960]   Hey, hey, well, you dress up for Stephanie rule.
[00:08:21.960 --> 00:08:22.800]   You say, yeah.
[00:08:22.800 --> 00:08:23.720]   Yeah, Stephanie.
[00:08:23.720 --> 00:08:24.160]   Yeah.
[00:08:24.840 --> 00:08:30.920]   By the way, she calls you one of her favorites, maybe it was a favor, one of our faves.
[00:08:30.920 --> 00:08:36.720]   Uh, you know, I almost don't want to bring this up because it's there.
[00:08:36.720 --> 00:08:38.760]   I don't think we can influence the vote at this point.
[00:08:38.760 --> 00:08:40.440]   Uh, I don't think there's much we can do.
[00:08:40.440 --> 00:08:41.440]   What should we do?
[00:08:41.440 --> 00:08:42.680]   You could call your Congress critic.
[00:08:42.680 --> 00:08:43.680]   And you could.
[00:08:43.680 --> 00:08:48.920]   Um, and you should because just who there was a Republican congressman who
[00:08:48.920 --> 00:08:49.720]   came out against it.
[00:08:49.720 --> 00:08:52.560]   So there's a couple of things after this vote, reveals it.
[00:08:53.080 --> 00:08:59.440]   There's then the process will happen again.
[00:08:59.440 --> 00:09:00.680]   We could have a lawsuit.
[00:09:00.680 --> 00:09:02.080]   We could find another case.
[00:09:02.080 --> 00:09:05.280]   Um, you can also expect.
[00:09:05.280 --> 00:09:09.000]   I mean, it's possible that even it's a shame.
[00:09:09.000 --> 00:09:10.880]   No, no one got Trump upset over this.
[00:09:10.880 --> 00:09:15.480]   And so Trump could tweet, you know, ah, I want the net to stay free.
[00:09:15.480 --> 00:09:18.480]   Cause then, you know, I just, I would have to go around.
[00:09:18.480 --> 00:09:21.000]   Um, here's a, there's not a lot to do.
[00:09:21.080 --> 00:09:24.040]   No, but you can do what the internet pioneers did.
[00:09:24.040 --> 00:09:30.160]   They wrote a letter, scathing letter, scathing letter to members of the house
[00:09:30.160 --> 00:09:31.160]   and the Senate.
[00:09:31.160 --> 00:09:35.240]   We are writing to respectfully urge you to call on FCC chairman,
[00:09:35.240 --> 00:09:38.240]   Ajapai to cancel the December 14th vote.
[00:09:38.240 --> 00:09:43.080]   We are the pioneers and technologists who created and now operate the internet,
[00:09:43.080 --> 00:09:49.080]   including Vince surf, Steve Wozniak, uh, Paul Vixie,
[00:09:49.080 --> 00:09:51.400]   Stephen Wolf, Ron Rivest.
[00:09:51.400 --> 00:09:55.520]   I mean, these are names you all know, Ted Nelson, Susan Landab,
[00:09:55.520 --> 00:09:56.440]   Brewster, Kale.
[00:09:56.440 --> 00:10:03.240]   These are the Whitfield, Diffie Vernon, uh, Vincent surf, the father of the internet,
[00:10:03.240 --> 00:10:06.760]   Tim Berners Lee, the creator of the worldwide web, Steve Bellavan.
[00:10:06.760 --> 00:10:12.080]   Who tweeted yesterday that, that, uh, debt neutrality is what enabled him to invent the web.
[00:10:12.080 --> 00:10:15.000]   He needed a permissionless environment.
[00:10:15.000 --> 00:10:15.680]   Thank you.
[00:10:16.280 --> 00:10:19.600]   Uh, so people who say, Oh, you guys are out of touch.
[00:10:19.600 --> 00:10:23.000]   You know, uh, we don't need net neutrality.
[00:10:23.000 --> 00:10:24.600]   We don't want more government regulation.
[00:10:24.600 --> 00:10:25.160]   Okay.
[00:10:25.160 --> 00:10:30.360]   Don't believe us, but do you believe the people who invented and run the today's internet?
[00:10:30.360 --> 00:10:31.240]   Do you believe them?
[00:10:31.240 --> 00:10:33.720]   Cause they seem unanimous.
[00:10:33.720 --> 00:10:37.600]   This is a, but this is a list of who's who.
[00:10:37.600 --> 00:10:44.040]   Boy is it unanimous in their contempt for what is happening tomorrow.
[00:10:45.440 --> 00:10:51.940]   Content is a good word because that's exactly how Ijip pie is reacting with by moving forward this, with this
[00:10:51.940 --> 00:11:00.880]   content for us, for the people, for 86% who said we want net neutrality for the creators and pioneers and people who run the internet, complete and utter contempt.
[00:11:00.880 --> 00:11:07.120]   All he cares about is lining the pockets of the telcos and the ISPs, the big.
[00:11:07.120 --> 00:11:15.280]   And he also has a contempt for the facts in the sense that he says this isn't a problem when it's actually been a documented problem.
[00:11:16.280 --> 00:11:22.480]   I am just so baffled that this is actually going forward and.
[00:11:22.480 --> 00:11:25.480]   Yes.
[00:11:25.480 --> 00:11:26.480]   Yes.
[00:11:26.480 --> 00:11:26.480]   Yeah.
[00:11:26.480 --> 00:11:33.080]   As Stephanie rules up today, to me, um, it's not, you know, the violations are not going to come quickly.
[00:11:33.080 --> 00:11:34.080]   They're going to come slowly.
[00:11:34.080 --> 00:11:37.480]   I said at the end of the show, I'm a frog and I'm getting a little warm in here.
[00:11:37.480 --> 00:11:37.680]   Yeah.
[00:11:37.680 --> 00:11:39.880]   It's going to happen in subtle ways.
[00:11:39.880 --> 00:11:41.480]   Um, but it's kind of happening.
[00:11:41.480 --> 00:11:44.880]   If you look at things like zero rating, zero rating.
[00:11:44.880 --> 00:11:45.880]   Is a net neutrality.
[00:11:45.880 --> 00:11:46.880]   It's just a friendly one.
[00:11:46.880 --> 00:11:46.880]   Right.
[00:11:46.880 --> 00:11:51.880]   And now in the coming years, we're going to see unfriendly ones or we're going to see.
[00:11:51.880 --> 00:12:02.880]   I mean, we already see, if you think about things like data caps, when that began all the way back in 2008 with Time Warner saying, hey, maybe we shouldn't have all you can eat broadband.
[00:12:02.880 --> 00:12:13.880]   That was the beginning of the data cap efforts in that very slowly over the next four years before Comcast kind of instituted theirs happened.
[00:12:13.880 --> 00:12:19.880]   And the carriers are playing a long game here because right now they're the only ones with this asset.
[00:12:19.880 --> 00:12:20.880]   Yeah.
[00:12:20.880 --> 00:12:23.880]   Well, Stacy, you mentioned suit.
[00:12:23.880 --> 00:12:31.880]   Is there any scenario in which you can imagine a temporary restraining order on this or anyone with standing?
[00:12:31.880 --> 00:12:34.880]   I don't think you, it's a repeal of rules.
[00:12:34.880 --> 00:12:43.880]   So I don't think you can sue over the repeal. You would have to find a violation or something in Sue over that.
[00:12:43.880 --> 00:12:54.880]   Like you can sue when in there, there was a lawsuit happening and there's currently a lawsuit about the comments, but I don't think Eric Schneiderman in New York state is suing.
[00:12:54.880 --> 00:12:59.880]   I don't see that as he found a huge number of the same comments.
[00:12:59.880 --> 00:13:03.880]   Of course, if you see him with him over, what was it? It's a million.
[00:13:03.880 --> 00:13:05.880]   Two million fake accounts.
[00:13:05.880 --> 00:13:09.880]   You could also go to a site and see whether, because identities were stolen.
[00:13:09.880 --> 00:13:13.880]   So you can go and look up your name and see if your identity was stolen from a fake comment to the FCC.
[00:13:13.880 --> 00:13:15.880]   Do we do that last week? Yeah, you weren't here, Jeff, but we did that last week.
[00:13:15.880 --> 00:13:16.880]   Oh, I see. Okay. Yeah.
[00:13:16.880 --> 00:13:21.880]   Which I think identity theft, isn't that an FTC issue?
[00:13:24.880 --> 00:13:33.880]   Congress, someone correctly pointed this out in the comments that Congress could make laws in training neutrality or some variation.
[00:13:33.880 --> 00:13:38.880]   Yeah, FCC only does what Congress says it can do. And here's the problem with that.
[00:13:38.880 --> 00:13:43.880]   What, Congress 101 millions of donations from the ISP industry.
[00:13:43.880 --> 00:13:46.880]   I looked up, I have two Democratic senators.
[00:13:46.880 --> 00:13:48.880]   Cory Booker got $290,000.
[00:13:48.880 --> 00:13:55.880]   Robert Menendez got $700,000 from my SPs. My Congressman got $290,000.
[00:13:55.880 --> 00:14:12.880]   Do you think really that the thing we should be doing, Larry Lessig thinks this, the thing we should do is forget all these battles, these short-term battles, and go for the big one, which is to change how elections are funded to get money out of politics.
[00:14:12.880 --> 00:14:18.880]   Don't you remember the campaign finance reform bill that didn't pass? That was a bipartisan surprise.
[00:14:18.880 --> 00:14:23.880]   You can't have the people who benefit from this voting against it. They're not going to do it.
[00:14:23.880 --> 00:14:27.880]   It's the same thing. It's the same thing. It's the same problem as gerrymandering.
[00:14:27.880 --> 00:14:33.880]   You know, if you have the people who are going to benefit doing the gerrymandering, of course you're going to do it to their benefit.
[00:14:33.880 --> 00:14:37.880]   Sometimes I despair of our Republic.
[00:14:37.880 --> 00:14:42.880]   Comcast, by the way, is already in Jenkins. Sometimes. Many times.
[00:14:42.880 --> 00:15:03.880]   Comcast. No, not always though. You know what? If there's anything that's positive in this is we're seeing our institutions, chiefly the courts, because Congress is useless, but some members of Congress, and then definitely the courts holding the line trying to preserve our
[00:15:03.880 --> 00:15:14.880]   Republic. I hope that they continue to do so, because if they get eroded, if all the institutions get eroded, that are protecting us right now.
[00:15:14.880 --> 00:15:18.880]   Then we've moved into a straight-up African kliptocracy.
[00:15:18.880 --> 00:15:23.880]   Hey, I feel like we're kind of there. We're getting close. Oh, yeah. We're getting close.
[00:15:23.880 --> 00:15:35.880]   Comcast, if you think Comcast, oh, no, they're nice. Nice ISP. For years, they've been injecting code into your websites. 400 lines of code to let you know you need a new modem that you don't even need.
[00:15:35.880 --> 00:15:47.880]   I see this all the time. I'm a Comcast customer at home. You do see it all the time. Yeah. It's easy to fix. And I think what we will do as a network going forward, because we're talking to technologically literate.
[00:15:47.880 --> 00:15:59.880]   Folks is show you how you can prevent your ISP from snooping on you, from injecting code into your websites. It's not that hard. You can do it with routers and plugins and things.
[00:15:59.880 --> 00:16:08.880]   I guess we're just going to have to start the resistance and how to keep your internet free.
[00:16:08.880 --> 00:16:14.880]   Oh, my gosh. It's like Homeland. No. What's it like? No, brother. It's like little brother.
[00:16:14.880 --> 00:16:21.880]   Corey Doctor is a good friend. It's very much like little brother. Corey, so you see the new homeland? No, no.
[00:16:21.880 --> 00:16:29.880]   I've got fell behind. I haven't seen anything since the fourth season. Yeah, I hear it's very good. And I just, Lisa and I have to catch up.
[00:16:29.880 --> 00:16:37.880]   I didn't mean to. All right. That's net neutrality in a nutshell. It sucks. Yeah, the pressing weight in the year.
[00:16:37.880 --> 00:16:46.880]   And I, you know, just you should stay in touch with a member of Congress. The thing I do want to remind everybody is maybe we can't get the influence of money out of Congress.
[00:16:46.880 --> 00:16:56.880]   But what is money by? It really, in most cases, unless your Congress person is completely corrupt, which some are, it doesn't buy them a new home or a nice boat. It buys them votes.
[00:16:56.880 --> 00:17:04.880]   It goes into their campaigns. And who ultimately controls the votes? We do. So we do control the levers of power.
[00:17:04.880 --> 00:17:16.880]   And we just need to make sure that we get our voices heard because ultimately, the only thing that speaks louder than the money being poured into Congress right now is our voices as voters.
[00:17:16.880 --> 00:17:21.880]   So why wasn't there a soap with people level Silicon Valley fight?
[00:17:21.880 --> 00:17:27.880]   It was a lot of the big tech companies were not as. They had mixed feelings about this, didn't they?
[00:17:27.880 --> 00:17:43.880]   Because ultimately, they are incumbents and they do benefit and come to its benefit from this, which is why it's really stupid of Agit Pie to go after Twitter and Google because they're natural allies of his.
[00:17:43.880 --> 00:17:47.880]   But he's not smart enough to really understand what's going on. I don't think.
[00:17:47.880 --> 00:17:58.880]   Hey, good news for donors. Patreon has backed down on it. Jack Conte, he should just be in charge of Silicon Valley. He just seems like the most decent guy.
[00:17:58.880 --> 00:18:08.880]   I love Jack. He listens. He listens to him messed up when he and Natalie were pamplamous on the great. They performed for several times in our studio.
[00:18:08.880 --> 00:18:17.880]   And I knew when he started Patreon and I know he did it for the best of intents because he himself was an artist and he wanted to support other artists.
[00:18:17.880 --> 00:18:22.880]   And it's really been a boon for a lot of creators in a lot of different fields, but especially podcasters.
[00:18:22.880 --> 00:18:28.880]   Then you remember last week, they decided to kind of flip how Patreon works in the past.
[00:18:28.880 --> 00:18:44.880]   Credit card service fees were paid by the creator, not the patron. They flipped it on its head, which meant that in many cases, a dollar donated to a creator would end up costing you a buck 50 in additional charges.
[00:18:44.880 --> 00:18:51.880]   The credit card fees, like 2.9% plus a 35 cent per donation charge.
[00:18:51.880 --> 00:19:02.880]   It hurt creators. A lot of people canceled their subscriptions. Well, Jack has listened and he has published a blog post.
[00:19:02.880 --> 00:19:12.880]   I think he's explained well what he says. We messed up. We're sorry and we're not rolling out the fees change, but he didn't need to explain what was going on.
[00:19:12.880 --> 00:19:19.880]   But he says it was poorly planned because it disproportionately affected the $1.2 patrons.
[00:19:19.880 --> 00:19:25.880]   Which is true of the entire credit card building system we have.
[00:19:25.880 --> 00:19:29.880]   That's why everyone who's dreamed of micro payments, they do not work economically.
[00:19:29.880 --> 00:19:34.880]   They just simply don't. Psychologically, I don't think they also work, but economically, they just can't be made to work.
[00:19:34.880 --> 00:19:43.880]   And it's just a reality of the structure that's above him. I know a lot of people have tried to create a micro payment scheme that works.
[00:19:43.880 --> 00:19:54.880]   I think 20 years ago, we knew that things like journalism on the net would require something that would allow a person to say, "I'll give you a penny to read that article" or "a nickel to read that article."
[00:19:54.880 --> 00:19:57.880]   But it never happened. It didn't ever happen.
[00:19:57.880 --> 00:20:01.880]   It's because the financial institutions want to charge those large fees.
[00:20:01.880 --> 00:20:09.880]   There are efforts now to say, "Well, Bitcoin, what do you use Bitcoin? Because Bitcoin is the gravy that will make any bad meal, of course, taste good."
[00:20:09.880 --> 00:20:16.880]   So it's not Bitcoin per se. It's a blockchain-based digital contract kind of situation.
[00:20:16.880 --> 00:20:18.880]   And that actually...
[00:20:18.880 --> 00:20:23.880]   But I have to point out the transaction fees for Bitcoin far exceed that Visa and MasterCard.
[00:20:23.880 --> 00:20:30.880]   Right. But if you create all the... And this is blockchain versus Bitcoin.
[00:20:30.880 --> 00:20:44.880]   So if you create a digital... It's a digital ledger, a monitoring of transactions, you could create something like this where you could either aggregate wide micro payments and then cash them out at the end.
[00:20:44.880 --> 00:20:45.880]   Maybe.
[00:20:45.880 --> 00:20:54.880]   I think the reason that Bitcoin's transactions have gotten... They're $20 and more now is it's kind of in the nature of blockchain.
[00:20:54.880 --> 00:21:00.880]   You have to give people an incentive to handle those transactions because there's no central bank.
[00:21:00.880 --> 00:21:03.880]   And it turns out people are just as greedy as central banks.
[00:21:03.880 --> 00:21:07.880]   They're not going to handle those transactions unless they get something for it.
[00:21:07.880 --> 00:21:11.880]   And so blockchain... You're right. I think the key... You actually nailed this, Stacy.
[00:21:11.880 --> 00:21:15.880]   The key is not blockchain, but the key is aggregating micro-pans.
[00:21:15.880 --> 00:21:19.880]   That's what Apple does. Apple doesn't charge your credit cards or you buy enough stuff.
[00:21:19.880 --> 00:21:22.880]   But we need some sort of aggregation system.
[00:21:22.880 --> 00:21:26.880]   But people want to get paid for their work even if it's just Bitcoin mining.
[00:21:26.880 --> 00:21:38.880]   That'd be an interesting role for journalism. So a newspaper creating or a blog creating an aggregation platform that can fund the ability to grab all those payments and then distribute them.
[00:21:38.880 --> 00:21:42.880]   There's a new startup called Civic. Have you heard of this, Stacy?
[00:21:42.880 --> 00:21:43.880]   No.
[00:21:43.880 --> 00:21:44.880]   I think it's called Civic.
[00:21:44.880 --> 00:21:48.880]   I don't know a lot about journalism despite being a journalist.
[00:21:48.880 --> 00:21:49.880]   That's, I think, common.
[00:21:49.880 --> 00:21:55.880]   It's only us people who observe journalists that know anything about journalists.
[00:21:55.880 --> 00:21:58.880]   I always left that aftermath.
[00:21:58.880 --> 00:21:59.880]   Civil.
[00:21:59.880 --> 00:22:00.880]   Sorry.
[00:22:00.880 --> 00:22:01.880]   Civil.
[00:22:01.880 --> 00:22:02.880]   Join.
[00:22:02.880 --> 00:22:03.880]   Civil.com.
[00:22:03.880 --> 00:22:09.880]   I'm... Some way I work with this enthusiastic. I'm a little dubious just because I think there's a high level of complication here.
[00:22:09.880 --> 00:22:13.880]   And they also think that it'll have...
[00:22:13.880 --> 00:22:17.880]   Anyway, anyway, I'm going off on a tangent here.
[00:22:17.880 --> 00:22:23.880]   I think Jack did what he did for sensible reasons.
[00:22:23.880 --> 00:22:25.880]   But he listened quickly.
[00:22:25.880 --> 00:22:27.880]   And I think he helped give him a lot of credit for that.
[00:22:27.880 --> 00:22:31.880]   In a way, Jack's big mistake was taking investments.
[00:22:31.880 --> 00:22:36.880]   Once you take venture capital, the goal of the game changes.
[00:22:36.880 --> 00:22:37.880]   And...
[00:22:37.880 --> 00:22:39.880]   You know, I'm not...
[00:22:39.880 --> 00:22:45.880]   I'm having that argument with people like Jay Rosen and others that the VC is presumed badly against journalism too.
[00:22:45.880 --> 00:22:47.880]   Well, actually, I was kind of big investment.
[00:22:47.880 --> 00:22:49.880]   And I tweeted, "Yeah, good for them."
[00:22:49.880 --> 00:22:51.880]   People just came after me all over.
[00:22:51.880 --> 00:22:53.880]   "Oh, no, that's terrible. That's terrible. That's your capital money."
[00:22:53.880 --> 00:22:55.880]   I said, "No, investing in journalism is a good thing."
[00:22:55.880 --> 00:22:56.880]   Yes.
[00:22:56.880 --> 00:22:57.880]   Yes, but they're not...
[00:22:57.880 --> 00:23:04.880]   They have... No, they have a return structure that is problematic for journalism.
[00:23:04.880 --> 00:23:12.880]   I can... As someone who was inside a journalism startup that took a lot of venture funding, had to come up with a model that met the hockey stick.
[00:23:12.880 --> 00:23:13.880]   It killed Giga.
[00:23:13.880 --> 00:23:14.880]   That's the problem.
[00:23:14.880 --> 00:23:16.880]   You see, that was the pando-tobbing.
[00:23:16.880 --> 00:23:17.880]   You don't have to be models.
[00:23:17.880 --> 00:23:22.880]   It wasn't Pando-Sara-Lacey's startup all based on investment.
[00:23:22.880 --> 00:23:23.880]   It was.
[00:23:23.880 --> 00:23:24.880]   She got more than recently.
[00:23:24.880 --> 00:23:26.880]   I would say no.
[00:23:26.880 --> 00:23:29.880]   We actually did several new models at Giga-ome.
[00:23:29.880 --> 00:23:34.880]   The research model we pioneered was very new and was actually...
[00:23:34.880 --> 00:23:35.880]   Mm-hmm.
[00:23:35.880 --> 00:23:39.880]   An example for the rest of the industry.
[00:23:39.880 --> 00:23:52.880]   The challenge is running those things at... And there were other challenges associated with Giga-ome starting with crazy salaries for our sales staff and some accounting issues around the research product.
[00:23:52.880 --> 00:23:59.880]   But at the end of the day, journalism doesn't pay.
[00:23:59.880 --> 00:24:02.880]   Uh-oh.
[00:24:02.880 --> 00:24:04.880]   And we had...
[00:24:04.880 --> 00:24:05.880]   Wait, if journalism...
[00:24:05.880 --> 00:24:06.880]   Journalism.
[00:24:06.880 --> 00:24:07.880]   This is the year of journalism.
[00:24:07.880 --> 00:24:10.880]   If journalism doesn't pay in 2017, it's never going to pay.
[00:24:10.880 --> 00:24:12.880]   Would you agree to that, Jeff?
[00:24:12.880 --> 00:24:13.880]   Um, no.
[00:24:13.880 --> 00:24:14.880]   I think it's early days.
[00:24:14.880 --> 00:24:16.880]   I think we're still an inefficient industry.
[00:24:16.880 --> 00:24:19.880]   Uh, just yesterday I had a meeting of the top 20 people who were trying to combo with...
[00:24:19.880 --> 00:24:20.880]   So you disagree with Stacy?
[00:24:20.880 --> 00:24:22.880]   You think journalism can pay?
[00:24:22.880 --> 00:24:23.880]   Yes.
[00:24:23.880 --> 00:24:24.880]   Yes.
[00:24:24.880 --> 00:24:25.880]   Yes.
[00:24:25.880 --> 00:24:26.880]   That's what I devote my career to now.
[00:24:26.880 --> 00:24:27.880]   What do you say about that?
[00:24:27.880 --> 00:24:28.880]   But the economics are going to be very different.
[00:24:28.880 --> 00:24:30.880]   It's going to be much smaller.
[00:24:30.880 --> 00:24:32.880]   And the multiple revenue streams.
[00:24:32.880 --> 00:24:37.880]   And I don't think we've begun to reinvent the notion of what journalism is in this age.
[00:24:37.880 --> 00:24:38.880]   We are still...
[00:24:38.880 --> 00:24:42.880]   What we're trying to make pay is pay us for what we used to do 100 years ago.
[00:24:42.880 --> 00:24:44.880]   Pay us for making articles.
[00:24:44.880 --> 00:24:45.880]   Journalism...
[00:24:45.880 --> 00:24:48.880]   That's journalism as factory, not journalism as service.
[00:24:48.880 --> 00:24:53.880]   Um, now so-so, for example, I had in 20 people at Q&E.
[00:24:53.880 --> 00:24:58.880]   We started a community of practice around commerce, because I think it's an area that ought to be explored.
[00:24:58.880 --> 00:25:00.880]   For its own, for the revenue.
[00:25:00.880 --> 00:25:05.880]   Also because it pushes us to do user profiling, which I think is an important strategic effort.
[00:25:05.880 --> 00:25:08.880]   And I've also learned in talking to these people, thinking about commerce.
[00:25:08.880 --> 00:25:10.880]   It's really interesting.
[00:25:10.880 --> 00:25:11.880]   Is that trust matters greatly.
[00:25:11.880 --> 00:25:13.880]   It matters more than ad support.
[00:25:13.880 --> 00:25:19.880]   Because if you lie to your readers about a deal, they're going to be away in a second.
[00:25:19.880 --> 00:25:22.880]   So I heard the word trust constantly around the room.
[00:25:22.880 --> 00:25:24.880]   So that's not salvation.
[00:25:24.880 --> 00:25:26.880]   It's one of many revenue streams.
[00:25:26.880 --> 00:25:28.880]   And your right Stacey Giga-Oma tried.
[00:25:28.880 --> 00:25:30.880]   Maybe it was too early.
[00:25:30.880 --> 00:25:37.880]   But my point back to the VCs is their expectation is set only on a volume-based business.
[00:25:37.880 --> 00:25:42.880]   And we have to give them new models in which they invest.
[00:25:42.880 --> 00:25:44.880]   And we still need their investment.
[00:25:44.880 --> 00:25:45.880]   We don't have the cash to start stuff.
[00:25:45.880 --> 00:25:48.880]   And we can't just do things as mom and pops.
[00:25:48.880 --> 00:25:53.880]   So I would say that your thought about trust is absolutely correct.
[00:25:53.880 --> 00:26:00.880]   And at Giga-Oma, what we're banking on is the trust that our readers had in the reporters.
[00:26:00.880 --> 00:26:06.880]   And because of that, they could sell all these other things.
[00:26:06.880 --> 00:26:13.880]   So the challenge was, as one of those trusted people, I couldn't scale.
[00:26:13.880 --> 00:26:16.880]   My trust didn't scale to the venture of levels.
[00:26:16.880 --> 00:26:19.880]   So we had three different revenue streams.
[00:26:19.880 --> 00:26:22.880]   But I couldn't participate in all of them and stay safe.
[00:26:22.880 --> 00:26:26.880]   And that was ultimately the challenge.
[00:26:26.880 --> 00:26:30.880]   And I'll be honest, there's my dog.
[00:26:30.880 --> 00:26:32.880]   She totally agrees, by the way.
[00:26:32.880 --> 00:26:33.880]   She's crazy.
[00:26:33.880 --> 00:26:35.880]   At least she said what Stacey says.
[00:26:35.880 --> 00:26:39.880]   There's only a few Stacey Higgenbothoms in the world.
[00:26:39.880 --> 00:26:45.880]   There's only a few, you know, gig or O'Malleyks and Jeff Jarvis's and Leo Laportz.
[00:26:45.880 --> 00:26:47.880]   You're absolutely right.
[00:26:47.880 --> 00:26:50.880]   But call up if you would the Giorno-Peretti email.
[00:26:50.880 --> 00:26:51.880]   Oh, the Buzzfeed.
[00:26:51.880 --> 00:26:52.880]   Actually, let's take a break.
[00:26:52.880 --> 00:26:53.880]   I want to stay safe.
[00:26:53.880 --> 00:26:54.880]   I interrupt the Stacey.
[00:26:54.880 --> 00:26:59.880]   I'm going to ask you your reaction to his Matrix.
[00:26:59.880 --> 00:27:01.880]   For just that reason.
[00:27:01.880 --> 00:27:02.880]   Oh, God.
[00:27:02.880 --> 00:27:04.880]   Wait, go to break so I can read this.
[00:27:04.880 --> 00:27:05.880]   Okay.
[00:27:05.880 --> 00:27:10.880]   So he put out a letter saying that there have been some serious challenges and the media
[00:27:10.880 --> 00:27:11.880]   is in crisis.
[00:27:11.880 --> 00:27:19.880]   But he believes that the diversified model that Buzzfeed uses is going to ultimately work.
[00:27:19.880 --> 00:27:27.000]   So first I like what you said, Stacey, though, I love what you said, which is that trust.
[00:27:27.000 --> 00:27:29.240]   Trust is the gold coin.
[00:27:29.240 --> 00:27:32.640]   Trust is what you can sell.
[00:27:32.640 --> 00:27:36.360]   But you have to be very careful not to damage that trust.
[00:27:36.360 --> 00:27:41.360]   And for any enterprise to succeed, it has to continue to build new reporters like Omenu
[00:27:41.360 --> 00:27:45.760]   and build trust.
[00:27:45.760 --> 00:27:50.720]   And the fast-paced world of online journal, I mean, I hired a bunch of people at Giga
[00:27:50.720 --> 00:27:51.720]   Home.
[00:27:51.720 --> 00:27:55.680]   And we tried both hiring experts and that was easy.
[00:27:55.680 --> 00:28:01.680]   And when we tried hiring people and developing them, and the type of journalism that we did
[00:28:01.680 --> 00:28:07.720]   was not conducive to letting people learn on the job because of the bad trust.
[00:28:07.720 --> 00:28:11.680]   So Stacey, you understand what you're saying?
[00:28:11.680 --> 00:28:19.720]   When you say you didn't scale, that basically it was about selling your relationship.
[00:28:19.720 --> 00:28:21.240]   It wasn't selling my relationship.
[00:28:21.240 --> 00:28:25.320]   It was people came to me because they said in my particular niche, there were other people
[00:28:25.320 --> 00:28:26.600]   who were good at other things.
[00:28:26.600 --> 00:28:29.840]   People came to me because they were like, I know what's going on.
[00:28:29.840 --> 00:28:35.440]   I have a worldview that I can explain and articulate that so far seems to map to money-making
[00:28:35.440 --> 00:28:36.440]   opportunities.
[00:28:36.440 --> 00:28:40.280]   Because again, we didn't sell to the mainstream.
[00:28:40.280 --> 00:28:44.040]   And then from that, they would say, okay, Stacey, in addition to all the articles you
[00:28:44.040 --> 00:28:49.400]   write that we give away for free to monetize that, we would like you to play in a conference.
[00:28:49.400 --> 00:28:51.240]   So then I would play in a conference.
[00:28:51.240 --> 00:28:56.480]   And in a sense, I'm monetizing my relationships because I would call people I know.
[00:28:56.480 --> 00:28:57.760]   And we would put on a show.
[00:28:57.760 --> 00:29:02.800]   Now we did not do pay to pay for the conferences because if they had, both Omen would have
[00:29:02.800 --> 00:29:04.440]   said no, I would have said no.
[00:29:04.440 --> 00:29:07.320]   I mean, none of us were all old school that way.
[00:29:07.320 --> 00:29:09.560]   So in a sense, that may have been our failing.
[00:29:09.560 --> 00:29:12.240]   But again, that was important for the trust.
[00:29:12.240 --> 00:29:15.640]   So you knew if I developed a conference, you'd actually see really cool people talking about
[00:29:15.640 --> 00:29:18.360]   really crazy cool things because that's what Stacey does.
[00:29:18.360 --> 00:29:19.360]   Interesting.
[00:29:19.360 --> 00:29:22.480]   We face very similar challenges, Stacey.
[00:29:22.480 --> 00:29:24.480]   I don't think we could have survived.
[00:29:24.480 --> 00:29:26.240]   Quit, I'm saying, could have survived.
[00:29:26.240 --> 00:29:27.600]   How do we take adventure capital?
[00:29:27.600 --> 00:29:31.360]   It's a very fragile thing.
[00:29:31.360 --> 00:29:35.840]   And when economic pressures get too high, it's, well, look what happened to poor Jack
[00:29:35.840 --> 00:29:37.960]   Cottie.
[00:29:37.960 --> 00:29:41.400]   He's lost considerable amounts of trust because of this.
[00:29:41.400 --> 00:29:45.760]   And all he was doing was, I'm sure, exceeding to the pressures of a board trying to turn
[00:29:45.760 --> 00:29:50.680]   some profit because their value is so much higher than their, you know, they make 8 million
[00:29:50.680 --> 00:29:51.680]   a year.
[00:29:51.680 --> 00:29:53.920]   They're valued at hundreds of millions.
[00:29:53.920 --> 00:29:56.760]   So I think I would argue VC is a bad thing.
[00:29:56.760 --> 00:30:01.040]   Jeff, can you give me an example of a journalist, a journalistic enterprise that's taken VC
[00:30:01.040 --> 00:30:02.960]   money that's thriving?
[00:30:02.960 --> 00:30:07.240]   Well, you got two questions wrapped up in that.
[00:30:07.240 --> 00:30:10.040]   One is, can you name a journalist to get a prize that's thriving?
[00:30:10.040 --> 00:30:11.840]   Well, Texas Tribune.
[00:30:11.840 --> 00:30:17.520]   Well, I would say the Washington Post with the patronage of Jeff Bezos is doing quite
[00:30:17.520 --> 00:30:22.680]   well, but Jeff is clearly not the kind of investor who's saying, and I got to see some
[00:30:22.680 --> 00:30:23.680]   profit right now.
[00:30:23.680 --> 00:30:24.680]   No, that's true.
[00:30:24.680 --> 00:30:28.680]   And the problem with that is, and I agree and God bless, I would Jeff Bezos would buy
[00:30:28.680 --> 00:30:32.440]   some more things and he's a trainer to be a very responsible owner.
[00:30:32.440 --> 00:30:36.760]   But there's a fine line between a benefactor and oligarch.
[00:30:36.760 --> 00:30:42.000]   Where in the US, Ukraine, I saw a lot of oligarchs.
[00:30:42.000 --> 00:30:47.680]   And so this notion of having somebody control the place or Sam Zell in LA or and on and
[00:30:47.680 --> 00:30:48.680]   on and on.
[00:30:48.680 --> 00:30:54.440]   So the benefactor as owner depends greatly.
[00:30:54.440 --> 00:30:56.280]   And then at some point you give up, you don't forget the grams.
[00:30:56.280 --> 00:30:57.280]   It's probably not a model.
[00:30:57.280 --> 00:30:59.120]   It's probably not a model.
[00:30:59.120 --> 00:31:00.120]   Probably not a model.
[00:31:00.120 --> 00:31:05.520]   But there's that first, so the first question is, it's hard to judge venture backed media
[00:31:05.520 --> 00:31:08.160]   companies apart from the entire media industry.
[00:31:08.160 --> 00:31:10.960]   The entire media industry is what I was trying to say badly.
[00:31:10.960 --> 00:31:17.040]   Hasn't yet found and perfected the models and the mix.
[00:31:17.040 --> 00:31:18.840]   We're still in the experimentation stage.
[00:31:18.840 --> 00:31:21.640]   And unfortunately, Stacy, you suffered the scars of that.
[00:31:21.640 --> 00:31:27.160]   But the lessons that you learned and taught, I think will keep paying off for others as
[00:31:27.160 --> 00:31:28.920]   time goes on.
[00:31:28.920 --> 00:31:29.920]   With a cautionary tale.
[00:31:29.920 --> 00:31:37.340]   Well, no, I'm also, I mean, like, when I started my own business, I did it with an
[00:31:37.340 --> 00:31:40.760]   eye to never taking outside investment, even though that was scary.
[00:31:40.760 --> 00:31:42.760]   You and I did the same things, Stacy.
[00:31:42.760 --> 00:31:44.960]   We learned a lesson.
[00:31:44.960 --> 00:31:46.440]   But you're scaling right now.
[00:31:46.440 --> 00:31:50.040]   I'm like, I'm not, I'm kind of hovering.
[00:31:50.040 --> 00:31:51.560]   I don't think we're going.
[00:31:51.560 --> 00:31:55.520]   Our revenues were off about 10% from last year.
[00:31:55.520 --> 00:31:59.600]   Our profits weren't because we canceled shows and laid off people.
[00:31:59.600 --> 00:32:06.080]   So I wouldn't say that we are now there's, there's other things in, in, in play here
[00:32:06.080 --> 00:32:12.760]   like the growth of the podcast pool and people's attention being distracted by other things
[00:32:12.760 --> 00:32:13.920]   and so forth.
[00:32:13.920 --> 00:32:20.440]   But I would say, I don't, I don't, you know, if I had economic pressure from the outside,
[00:32:20.440 --> 00:32:23.120]   I wouldn't, we wouldn't be able to survive that.
[00:32:23.120 --> 00:32:24.400]   We'd have to sell out basically.
[00:32:24.400 --> 00:32:25.400]   We'd have to sell that trust.
[00:32:25.400 --> 00:32:26.920]   We'd have to sell it.
[00:32:26.920 --> 00:32:31.000]   So if you say that you have trust and you could play on your trust, you could sell it,
[00:32:31.000 --> 00:32:33.880]   but you can only sell it to a certain degree before it starts to diminish.
[00:32:33.880 --> 00:32:35.800]   For instance, we do a lot of ads, right?
[00:32:35.800 --> 00:32:40.520]   That diminishes trust a little bit, but those ads are valuable because of the trust that
[00:32:40.520 --> 00:32:43.760]   we have created with our audience.
[00:32:43.760 --> 00:32:44.760]   We have to monetize.
[00:32:44.760 --> 00:32:47.960]   So we have to sell a little bit of that trust off the trick is to not sell so much that
[00:32:47.960 --> 00:32:48.960]   it diminishes.
[00:32:48.960 --> 00:32:49.960]   Yes, it's true.
[00:32:49.960 --> 00:32:52.360]   So Stacy, Ohm then became a VC.
[00:32:52.360 --> 00:32:55.200]   Ohm was a VC beforehand.
[00:32:55.200 --> 00:32:59.960]   Ohm actually was a VC starting sometime in the middle of Giga.
[00:32:59.960 --> 00:33:02.480]   Yes, because he had deal flow.
[00:33:02.480 --> 00:33:03.480]   He did.
[00:33:03.480 --> 00:33:06.360]   He's all about the flow, baby.
[00:33:06.360 --> 00:33:07.360]   It's not just deal flow.
[00:33:07.360 --> 00:33:14.800]   He did have a very cogent and good worldview that, you know, VC's love that.
[00:33:14.800 --> 00:33:15.800]   Yeah.
[00:33:15.800 --> 00:33:17.600]   VC's love any man with a worldview.
[00:33:17.600 --> 00:33:18.600]   Yeah.
[00:33:18.600 --> 00:33:19.600]   Yeah.
[00:33:19.600 --> 00:33:20.600]   Yeah.
[00:33:20.600 --> 00:33:21.600]   So let's take a little break.
[00:33:21.600 --> 00:33:24.880]   I do want to say that one more thing, which is I mentioned the institutions that are saving
[00:33:24.880 --> 00:33:30.200]   this republic right now and frankly, front and center foremost is the fourth estate is
[00:33:30.200 --> 00:33:31.300]   journalism.
[00:33:31.300 --> 00:33:38.280]   If it weren't for the integrity and the assiduity and the careful work of journalists, I think
[00:33:38.280 --> 00:33:39.920]   we'd be in a hell of a lot worse.
[00:33:39.920 --> 00:33:47.560]   I've given the story of this week, Washington Post did amazing work around or more.
[00:33:47.560 --> 00:33:48.560]   Yeah.
[00:33:48.560 --> 00:33:49.560]   I mean, a lot worse shape.
[00:33:49.560 --> 00:33:50.920]   We would be a lot worse shape.
[00:33:50.920 --> 00:33:52.080]   So that's one of the institutes.
[00:33:52.080 --> 00:33:56.200]   I mentioned courts, but really, I think it's the, I think it's frankly the fourth estate
[00:33:56.200 --> 00:34:00.160]   that's keeping us afloat at this point is keeping us a republic.
[00:34:00.160 --> 00:34:01.760]   And of course, it's, there's no surprise.
[00:34:01.760 --> 00:34:02.760]   That's the first thing.
[00:34:02.760 --> 00:34:04.600]   Authoritarians shut down.
[00:34:04.600 --> 00:34:07.160]   Pooten or Hitler or whoever.
[00:34:07.160 --> 00:34:08.640]   That's the first thing they shut down.
[00:34:08.640 --> 00:34:10.600]   The lying press Hitler called them.
[00:34:10.600 --> 00:34:11.600]   Yeah.
[00:34:11.600 --> 00:34:17.760]   Is it 20% 19% of Republicans believe that or only 19% of Republicans trust the news now?
[00:34:17.760 --> 00:34:18.760]   This was a crazy stat.
[00:34:18.760 --> 00:34:19.760]   That's a bad stat.
[00:34:19.760 --> 00:34:20.760]   Is it the pupil?
[00:34:20.760 --> 00:34:23.600]   But the news doesn't agree with their worldview.
[00:34:23.600 --> 00:34:25.360]   Why would they trust it?
[00:34:25.360 --> 00:34:26.960]   They've been told over and over again too.
[00:34:26.960 --> 00:34:27.960]   That's the other problem.
[00:34:27.960 --> 00:34:28.960]   No, I know.
[00:34:28.960 --> 00:34:29.960]   Yeah.
[00:34:29.960 --> 00:34:30.960]   I'm going to change the subject.
[00:34:30.960 --> 00:34:31.960]   We're going to take a break.
[00:34:31.960 --> 00:34:38.080]   We, I will, we will talk about Jonah Paredi's memo and which came out today.
[00:34:38.080 --> 00:34:41.800]   And then I have an unboxing.
[00:34:41.800 --> 00:34:43.800]   Oh.
[00:34:43.800 --> 00:34:47.560]   It's something you would like to find on your tree because it's big.
[00:34:47.560 --> 00:34:48.560]   We all like bigger gifts.
[00:34:48.560 --> 00:34:49.560]   Right?
[00:34:49.560 --> 00:34:50.560]   Big is like, except.
[00:34:50.560 --> 00:34:51.560]   Oh, no, no, no.
[00:34:51.560 --> 00:34:52.560]   Jewelry is little.
[00:34:52.560 --> 00:34:53.560]   Small gift.
[00:34:53.560 --> 00:34:58.480]   Something in a light blue box with that might be better, but this is not that.
[00:34:58.480 --> 00:35:00.240]   This is a big heavy box.
[00:35:00.240 --> 00:35:01.240]   We're going to take a look.
[00:35:01.240 --> 00:35:02.400]   We're going to open it up in a little bit.
[00:35:02.400 --> 00:35:06.440]   Our show today brought to you by, oh, this is a gift video blocks from story blocks.
[00:35:06.440 --> 00:35:09.160]   This is a gift that keeps giving all year long.
[00:35:09.160 --> 00:35:14.360]   Do you use sound effects for your podcasts or video backgrounds on your website?
[00:35:14.360 --> 00:35:16.360]   Are you a filmmaker that you need?
[00:35:16.360 --> 00:35:20.960]   No, long shots, helicopter shots, flames.
[00:35:20.960 --> 00:35:24.920]   Are you creative needs kind of constrained by budget?
[00:35:24.920 --> 00:35:28.360]   Well, you need to know about video blocks from story blocks.
[00:35:28.360 --> 00:35:35.080]   You get studio quality, high def, stock footage, audio, images, after effects backgrounds and
[00:35:35.080 --> 00:35:37.520]   more for a price.
[00:35:37.520 --> 00:35:41.600]   I can't even believe we've paid so much per month, hundreds of dollars a month for these
[00:35:41.600 --> 00:35:42.600]   in the past.
[00:35:42.600 --> 00:35:49.800]   Now we're all in on video blocks for $149 a year, a year unlimited.
[00:35:49.800 --> 00:35:51.040]   And these are royalty free.
[00:35:51.040 --> 00:35:53.800]   You can use them for commercial and personal projects.
[00:35:53.800 --> 00:35:57.120]   Everything you download is yours to keep and use forever.
[00:35:57.120 --> 00:36:03.760]   All the stock media, your heart desires, including 150,000 videos, 100,000 audio clips, 400,000
[00:36:03.760 --> 00:36:07.080]   images, after effects, templates, motion backgrounds.
[00:36:07.080 --> 00:36:08.520]   And there's new content added all the time.
[00:36:08.520 --> 00:36:09.920]   So there's always something fresh.
[00:36:09.920 --> 00:36:17.400]   And as a video blocks member, you also get exclusive discounts on over 5 million additional
[00:36:17.400 --> 00:36:19.080]   marketplace clips.
[00:36:19.080 --> 00:36:20.320]   You're buying directly from the artist.
[00:36:20.320 --> 00:36:21.360]   And I love the model here.
[00:36:21.360 --> 00:36:24.680]   The artist gets 100% of what you pay.
[00:36:24.680 --> 00:36:28.360]   So there's many, many more clips out there and you get discounts on those.
[00:36:28.360 --> 00:36:31.640]   Don't risk the quality of a project due to the high cost of acquiring footage.
[00:36:31.640 --> 00:36:35.040]   Go to videoblocks.com.
[00:36:35.040 --> 00:36:41.760]   Over 90,000 great businesses have used video blocks, including NBC, National Geographic,
[00:36:41.760 --> 00:36:45.400]   the History Channel, the Travel Channel, videoblocks.com/tweg.
[00:36:45.400 --> 00:36:51.440]   Get all the stock footage, audio and images you can imagine for $149 a year.
[00:36:51.440 --> 00:36:53.880]   That's videoblocks.com/tweg.
[00:36:53.880 --> 00:36:57.360]   Save on millions of studio quality stock media from video blocks.
[00:36:57.360 --> 00:37:01.720]   And we thank video blocks by Storyblocks for their support of this week.
[00:37:01.720 --> 00:37:06.320]   And Google Stacey Higginbotham from Stacey on IoT.
[00:37:06.320 --> 00:37:09.440]   Mr. Jeff Jarvis from the City University of New York.
[00:37:09.440 --> 00:37:11.320]   I love talking about journalism with you guys.
[00:37:11.320 --> 00:37:14.800]   You say Stacey, you don't know anything about journalism except you are a complete expert.
[00:37:14.800 --> 00:37:15.800]   You are.
[00:37:15.800 --> 00:37:16.800]   Yeah.
[00:37:16.800 --> 00:37:17.800]   I don't know anybody.
[00:37:17.800 --> 00:37:20.280]   But besides Jeff, who's more expert.
[00:37:20.280 --> 00:37:24.440]   And yeah, and I love it that Stacey, you had the guts when giga home folder, you went to
[00:37:24.440 --> 00:37:27.280]   fortune briefly, but you decided I'm going to do it myself.
[00:37:27.280 --> 00:37:30.040]   And I'm not going to make the same mistakes.
[00:37:30.040 --> 00:37:32.840]   I'm making new, more exciting mistakes.
[00:37:32.840 --> 00:37:36.680]   Well, you know, if you don't make mistakes, you're not learning, right?
[00:37:36.680 --> 00:37:38.320]   That's what I tell myself.
[00:37:38.320 --> 00:37:42.720]   What's the biggest lesson you've learned since you've been on your own?
[00:37:42.720 --> 00:37:44.640]   Only do a newsletter once a week.
[00:37:44.640 --> 00:37:48.920]   Because anytime, anytime more than that, you're really on the hook, especially if you're
[00:37:48.920 --> 00:37:49.920]   traveling.
[00:37:49.920 --> 00:37:51.760]   Were you originally like daily?
[00:37:51.760 --> 00:37:55.080]   No, I only gave me that advice and he was so right.
[00:37:55.080 --> 00:38:00.440]   And my other piece of advice is, you know what, maybe the last week of the year, just don't
[00:38:00.440 --> 00:38:01.440]   sell an ad.
[00:38:01.440 --> 00:38:03.880]   So you can just not produce something.
[00:38:03.880 --> 00:38:04.880]   Take it easy.
[00:38:04.880 --> 00:38:05.880]   Yeah.
[00:38:05.880 --> 00:38:08.680]   It's really hard to produce content that last, that last week.
[00:38:08.680 --> 00:38:12.880]   You know, my advice is surround yourself by smart people like Stacey Higginbotham and Jeff
[00:38:12.880 --> 00:38:13.880]   Jarvis.
[00:38:13.880 --> 00:38:15.680]   And then you can always coast.
[00:38:15.680 --> 00:38:17.400]   There we go.
[00:38:17.400 --> 00:38:20.280]   That's what Kevin's writing a story for me right now.
[00:38:20.280 --> 00:38:21.280]   Yeah.
[00:38:21.280 --> 00:38:22.280]   Yeah.
[00:38:22.280 --> 00:38:23.280]   The only, Leo, Leo.
[00:38:23.280 --> 00:38:26.160]   I see, I thought this is hard.
[00:38:26.160 --> 00:38:27.640]   What you do is hard.
[00:38:27.640 --> 00:38:29.920]   The art of what you do is you make it look easy, but it's hard.
[00:38:29.920 --> 00:38:30.920]   Thank you.
[00:38:30.920 --> 00:38:31.920]   How is that going, by the way?
[00:38:31.920 --> 00:38:33.240]   Oh, we ran out of money.
[00:38:33.240 --> 00:38:34.240]   So that was that.
[00:38:34.240 --> 00:38:35.680]   Oh, you ran out of your grant funds.
[00:38:35.680 --> 00:38:36.680]   It's grants.
[00:38:36.680 --> 00:38:37.680]   Yeah.
[00:38:37.680 --> 00:38:39.680]   So, you know, there's only one really hard thing and that's funny.
[00:38:39.680 --> 00:38:42.560]   Really smart people like Jeff Jarvis and Stacey Higginbotham.
[00:38:42.560 --> 00:38:43.560]   I have been.
[00:38:43.560 --> 00:38:44.560]   It's true.
[00:38:44.560 --> 00:38:46.120]   I have been extraordinarily fortunate.
[00:38:46.120 --> 00:38:50.360]   The team that we've put together is so good and not just in front of the camera behind the
[00:38:50.360 --> 00:38:51.360]   camera.
[00:38:51.360 --> 00:38:58.080]   And that's it's, but it's all any company is you set the voice.
[00:38:58.080 --> 00:38:59.080]   That's key to this.
[00:38:59.080 --> 00:39:01.800]   I'm just selling my trust like nobody's business.
[00:39:01.800 --> 00:39:04.600]   Your trust is a blockchain.
[00:39:04.600 --> 00:39:07.300]   I think that's really, I had never really thought about that Stacey, but that's actually
[00:39:07.300 --> 00:39:08.300]   very astute.
[00:39:08.300 --> 00:39:10.600]   That is really what you bring to the table.
[00:39:10.600 --> 00:39:14.480]   You know, people, some of it's called brand or name awareness.
[00:39:14.480 --> 00:39:15.980]   It isn't though.
[00:39:15.980 --> 00:39:20.840]   It really is people have a relationship with a, especially journalism.
[00:39:20.840 --> 00:39:24.360]   It's even true in performing arts, but really in journalism, they have a relationship with
[00:39:24.360 --> 00:39:25.520]   a journalist.
[00:39:25.520 --> 00:39:29.720]   And that's what informs their interest in what the person has to say.
[00:39:29.720 --> 00:39:33.080]   And you really have to, and you have to be very careful with it.
[00:39:33.080 --> 00:39:38.000]   And I mean, I remember I, there are still certain people where when something happens,
[00:39:38.000 --> 00:39:41.640]   I want to know exactly what a specific person says about it.
[00:39:41.640 --> 00:39:48.280]   So it is, that is, that is the relationship I want to have with my readers, listeners,
[00:39:48.280 --> 00:39:49.280]   anyone.
[00:39:49.280 --> 00:39:52.600]   It's, Hey, crap, this deal just happened.
[00:39:52.600 --> 00:39:53.800]   Let's go see what Stacey has.
[00:39:53.800 --> 00:39:54.880]   She's usually pretty smart.
[00:39:54.880 --> 00:40:00.400]   So, no, I look at somebody like Marcus Brownlee who came out of nowhere, created a YouTube
[00:40:00.400 --> 00:40:04.520]   following and it's entirely based on trust.
[00:40:04.520 --> 00:40:09.640]   You know, you could include likability and other factors, but ultimately it's trust in
[00:40:09.640 --> 00:40:12.000]   what Marcus, his reviews are.
[00:40:12.000 --> 00:40:14.600]   And he's done it all on his own.
[00:40:14.600 --> 00:40:18.400]   Right now he's regretting not surrounding himself with more people because it's exhausting.
[00:40:18.400 --> 00:40:20.720]   I'm sure.
[00:40:20.720 --> 00:40:22.400]   But he's done it all on his own.
[00:40:22.400 --> 00:40:26.080]   And then I wonder if this is true.
[00:40:26.080 --> 00:40:30.560]   It does seem like you have to sell a little bit of that trust to monetize.
[00:40:30.560 --> 00:40:34.440]   It's not necessarily selling.
[00:40:34.440 --> 00:40:40.320]   If you pick things that you like, I mean, yes, people can dislike ads, but you don't have
[00:40:40.320 --> 00:40:41.800]   to add up everything.
[00:40:41.800 --> 00:40:45.520]   Well, you know, we try to preserve trust in that case with our process, right?
[00:40:45.520 --> 00:40:46.520]   Exactly.
[00:40:46.520 --> 00:40:48.440]   And we're rejecting advertisers.
[00:40:48.440 --> 00:40:52.040]   We don't want to introduce our audience to and picking ones that we like and limiting
[00:40:52.040 --> 00:40:54.760]   the number of ads and things like that.
[00:40:54.760 --> 00:40:56.320]   There are always people who are going to come out.
[00:40:56.320 --> 00:41:01.280]   I mean, Kevin and I have encountered this where we're like someone pings us and is like,
[00:41:01.280 --> 00:41:03.000]   I can't believe you wrote that story.
[00:41:03.000 --> 00:41:05.920]   They must be advertisers on your show.
[00:41:05.920 --> 00:41:08.720]   They're like, they happen not to be.
[00:41:08.720 --> 00:41:10.560]   But you know, here's why we think that.
[00:41:10.560 --> 00:41:12.920]   And you know, that's just a.
[00:41:12.920 --> 00:41:18.960]   I tweeted the headline about which we'll get to about T-Mobile buying level three television
[00:41:18.960 --> 00:41:22.120]   and getting into the cable business, which I thought was really interesting, a wireless
[00:41:22.120 --> 00:41:23.640]   kid business.
[00:41:23.640 --> 00:41:26.120]   And I said, I really like T what did I say?
[00:41:26.120 --> 00:41:28.840]   Something like, I really like T-Mobile's Moxie.
[00:41:28.840 --> 00:41:31.480]   And I immediately got to tweet, how much did they pay you for that?
[00:41:31.480 --> 00:41:33.560]   No, I can have an opinion.
[00:41:33.560 --> 00:41:35.600]   I maybe even have a positive opinion.
[00:41:35.600 --> 00:41:39.000]   Number of people tweeted, how can you like T-Mobile where there's zero rating?
[00:41:39.000 --> 00:41:40.640]   But the world is complicated.
[00:41:40.640 --> 00:41:45.720]   And as you get older, you might realize it's not all you can't just black and white everything,
[00:41:45.720 --> 00:41:46.800]   you know, right?
[00:41:46.800 --> 00:41:49.480]   It's a complicated world we live in.
[00:41:49.480 --> 00:41:51.680]   Well, but you should acknowledge that.
[00:41:51.680 --> 00:41:55.480]   I mean, it is complicated, but you if you're going to make compromises, you should recognize
[00:41:55.480 --> 00:41:59.200]   what those comp provides us are and how they can trickle down.
[00:41:59.200 --> 00:42:00.200]   Yes.
[00:42:00.200 --> 00:42:01.200]   Yes.
[00:42:01.200 --> 00:42:08.920]   So it's a shame that Buzzfeed doesn't spell better, but here is the media is in crisis
[00:42:08.920 --> 00:42:14.040]   says Jonah Paredi and he lays out his vision for a more diversified Buzzfeed.
[00:42:14.040 --> 00:42:21.280]   And here's one of the brands, Buzzfeed Media Brands, tasty, nifty, goodful, et cetera.
[00:42:21.280 --> 00:42:26.320]   I, you know, and then I guess unfortunately is not a word that he learned in college.
[00:42:26.320 --> 00:42:31.000]   But so what Buzzfeed has struggled this year, haven't they, Jeff?
[00:42:31.000 --> 00:42:32.720]   It has not been an easy year for us.
[00:42:32.720 --> 00:42:36.680]   Well, he argues in there that they didn't want to struggle as they're maturing and that
[00:42:36.680 --> 00:42:42.800]   the expectations were higher and that he has to, he has to experiment with more revenue
[00:42:42.800 --> 00:42:43.800]   models.
[00:42:43.800 --> 00:42:44.800]   That's what he's really talking about.
[00:42:44.800 --> 00:42:50.080]   He was critical of Google and Facebook in there in a way that made the haters gleeful.
[00:42:50.080 --> 00:42:53.600]   But I argued on Twitter that he was negotiating.
[00:42:53.600 --> 00:42:58.120]   He was saying, because Google and Facebook have or Facebook has paid him for content.
[00:42:58.120 --> 00:43:02.000]   He says that the biggest challenge they face is that everybody faces a Google and Facebook
[00:43:02.000 --> 00:43:05.560]   are eating up all the digital ad revenue in the world, which is what everybody says.
[00:43:05.560 --> 00:43:08.240]   But again, that digital revenue wasn't God given.
[00:43:08.240 --> 00:43:09.240]   That's true.
[00:43:09.240 --> 00:43:10.240]   That's true.
[00:43:10.240 --> 00:43:15.400]   Google and Facebook came and offered better deals competitively to our customers.
[00:43:15.400 --> 00:43:18.960]   That's the way the capitalistic world works.
[00:43:18.960 --> 00:43:21.960]   And we stood behind and we said, no, no, no, we want to produce the same product we've
[00:43:21.960 --> 00:43:23.960]   always produced and you should still pay for it.
[00:43:23.960 --> 00:43:26.960]   And you should still pay for our audience, even though we don't want to think about them.
[00:43:26.960 --> 00:43:29.520]   How do you compete though with the company?
[00:43:29.520 --> 00:43:32.600]   I don't know, like Facebook, I don't know about Google, but how do you compete with
[00:43:32.600 --> 00:43:37.120]   the company like Facebook that is getting all those ad dollars because they're willing
[00:43:37.120 --> 00:43:43.320]   to completely compromise their users' privacy, invade their privacy in ways that are offensive.
[00:43:43.320 --> 00:43:45.320]   Oh, geez.
[00:43:45.320 --> 00:43:53.960]   Oh, Leo, Leo, I have to give you props for having just a wonderful tone of voice when
[00:43:53.960 --> 00:43:58.600]   you asked somebody, how did it feel when you murdered that family of four?
[00:43:58.600 --> 00:44:00.080]   He goes, he's paid him.
[00:44:00.080 --> 00:44:01.080]   What is Zaneip?
[00:44:01.080 --> 00:44:07.600]   Yeah, I watch Zaneip to Ficki's very good TEDx talk, in which he points out that Facebook
[00:44:07.600 --> 00:44:16.360]   wouldn't hesitate to sell and add to a gambling company, let's say, that wants to reach people
[00:44:16.360 --> 00:44:22.720]   who are bipolar in their manic state and therefore more likely to gamble, but by the
[00:44:22.720 --> 00:44:26.800]   way, not that Facebook, it's a Facebook's problem or the gambling company's problem,
[00:44:26.800 --> 00:44:29.600]   to their complete detriment.
[00:44:29.600 --> 00:44:31.520]   That's a very valuable kind of thing to sell.
[00:44:31.520 --> 00:44:38.800]   And of course, if you can offer that kind of ads by to a company, you're going to get
[00:44:38.800 --> 00:44:39.800]   all the ad dollars.
[00:44:39.800 --> 00:44:40.800]   I can't do that.
[00:44:40.800 --> 00:44:42.840]   I'm never going to do that.
[00:44:42.840 --> 00:44:44.600]   I would never do that, right?
[00:44:44.600 --> 00:44:50.280]   You know how the whole, the holy, wonderful, saint of newspapers, do you know how they
[00:44:50.280 --> 00:44:52.840]   made their money in their early days as a mass media product?
[00:44:52.840 --> 00:44:53.840]   How?
[00:44:53.840 --> 00:44:54.840]   It started worse.
[00:44:54.840 --> 00:45:00.520]   Latin medicines, snake oil, literally snake oil.
[00:45:00.520 --> 00:45:03.680]   But I don't sell snake oil, but wait a minute, I am not there.
[00:45:03.680 --> 00:45:05.840]   I'm quoting from Bouchini Vassen's wonderful book.
[00:45:05.840 --> 00:45:06.840]   I didn't know this.
[00:45:06.840 --> 00:45:07.840]   I know.
[00:45:07.840 --> 00:45:08.840]   I didn't understand this, right?
[00:45:08.840 --> 00:45:11.360]   Tim will also mention in the intention seekers.
[00:45:11.360 --> 00:45:12.360]   Yeah.
[00:45:12.360 --> 00:45:17.080]   Yeah, it's really interesting, but that doesn't mean I'm doing that.
[00:45:17.080 --> 00:45:18.680]   And how am I to compete?
[00:45:18.680 --> 00:45:22.000]   No, it doesn't mean that somebody selling snake oil.
[00:45:22.000 --> 00:45:26.280]   I admit, by the way, we have a hard time competing against companies that are willing
[00:45:26.280 --> 00:45:30.560]   to sell crap products because I won't take those ads.
[00:45:30.560 --> 00:45:34.760]   But it's worse if a company is willing to trade on what it knows about its users in
[00:45:34.760 --> 00:45:36.760]   ways that I find offensive.
[00:45:36.760 --> 00:45:39.440]   Well, do you think Facebook doesn't do that?
[00:45:39.440 --> 00:45:40.440]   Am I wrong?
[00:45:40.440 --> 00:45:41.960]   Yeah, I don't think they do that.
[00:45:41.960 --> 00:45:45.160]   And I think that here's the problem with that line of talk.
[00:45:45.160 --> 00:45:49.840]   And Saint Epps from, she says, "Pro-publicist was able to buy ads that way."
[00:45:49.840 --> 00:45:50.840]   Wow.
[00:45:50.840 --> 00:45:52.440]   I believe it's another story.
[00:45:52.440 --> 00:45:56.120]   So I believe Facebook wouldn't maliciously do it, but they probably, I mean, they have
[00:45:56.120 --> 00:45:58.320]   the capabilities to identify people at their own level.
[00:45:58.320 --> 00:45:59.320]   They don't label it that way.
[00:45:59.320 --> 00:46:00.320]   They label it.
[00:46:00.320 --> 00:46:01.320]   Yeah.
[00:46:01.320 --> 00:46:02.320]   Well, sentiment analysis.
[00:46:02.320 --> 00:46:05.280]   Someone is coming along and using the capability of the platform they created to do something
[00:46:05.280 --> 00:46:09.520]   that Facebook made up, anticipated, like, rue rules buying political ads.
[00:46:09.520 --> 00:46:14.000]   So they've got, and they have to have a more moral structure built in to that architecture.
[00:46:14.000 --> 00:46:15.920]   I agree with that.
[00:46:15.920 --> 00:46:17.840]   But I also, here's the problem, Leo.
[00:46:17.840 --> 00:46:23.200]   I argue strenuously that media companies have to know more about their users.
[00:46:23.200 --> 00:46:28.840]   And that's the only path to gain trust of the long run, giving them relevance and value,
[00:46:28.840 --> 00:46:30.360]   gaining greater value and surviving.
[00:46:30.360 --> 00:46:31.360]   Wait a minute.
[00:46:31.360 --> 00:46:33.560]   I want to stop you right there.
[00:46:33.560 --> 00:46:42.240]   Media companies, in order to survive, have to know more about their users for, like,
[00:46:42.240 --> 00:46:45.880]   I need to know about more about my users so I can serve them better or so that I can sell
[00:46:45.880 --> 00:46:46.880]   against them better.
[00:46:46.880 --> 00:46:47.880]   Both.
[00:46:47.880 --> 00:46:48.880]   Both.
[00:46:48.880 --> 00:46:50.200]   I would agree, serve them better.
[00:46:50.200 --> 00:46:51.200]   I would not agree.
[00:46:51.200 --> 00:46:52.200]   Sell them better.
[00:46:52.200 --> 00:46:53.200]   But it follows.
[00:46:53.200 --> 00:46:55.240]   It just naturally follows.
[00:46:55.240 --> 00:47:01.440]   If I know your parents and I give you a product for parents and I can then get higher value
[00:47:01.440 --> 00:47:02.960]   advertising, I can get.
[00:47:02.960 --> 00:47:03.960]   Okay.
[00:47:03.960 --> 00:47:04.960]   So I'm doing that.
[00:47:04.960 --> 00:47:05.960]   You're right.
[00:47:05.960 --> 00:47:09.680]   Because we sell, we're selling, I just sold what was a video blocks because we know that
[00:47:09.680 --> 00:47:14.080]   many of our viewers are creators and would buy stock video footage.
[00:47:14.080 --> 00:47:15.080]   Right.
[00:47:15.080 --> 00:47:17.800]   That seems to be far less intrusive.
[00:47:17.800 --> 00:47:19.680]   So what are you missing?
[00:47:19.680 --> 00:47:21.560]   Okay, go ahead Stacy.
[00:47:21.560 --> 00:47:27.840]   Or isn't being talked about is we are moving from demographic information or broad strokes
[00:47:27.840 --> 00:47:31.000]   to almost an omniscient perspective on people.
[00:47:31.000 --> 00:47:36.040]   And once you have that, advertising has always sought to make us feel vulnerable so we could
[00:47:36.040 --> 00:47:38.320]   assuage that with buying something, right?
[00:47:38.320 --> 00:47:39.800]   That doesn't have to though.
[00:47:39.800 --> 00:47:41.880]   I don't think I do that in any of our ads.
[00:47:41.880 --> 00:47:43.000]   No, you don't have to.
[00:47:43.000 --> 00:47:46.640]   But that's always been a mode that can be employed in advertisement.
[00:47:46.640 --> 00:47:49.400]   What happens when you are omniscient?
[00:47:49.400 --> 00:47:53.220]   You can identify people at their most vulnerable in places.
[00:47:53.220 --> 00:47:55.680]   You don't have to create the low self esteem.
[00:47:55.680 --> 00:47:59.440]   You just swoop in when it's there and can offer a product.
[00:47:59.440 --> 00:48:05.760]   And I think that's almost predatory and we're having a hard time discussing it because we
[00:48:05.760 --> 00:48:10.440]   don't recognize these companies is having, again, that omniscience.
[00:48:10.440 --> 00:48:13.000]   And the only thing we think of is yeah.
[00:48:13.000 --> 00:48:14.320]   Sorry, sorry, sorry, sorry.
[00:48:14.320 --> 00:48:15.320]   I thought you were.
[00:48:15.320 --> 00:48:16.320]   Okay, here we go.
[00:48:16.320 --> 00:48:18.240]   Only thing we think is omniscient is God, right?
[00:48:18.240 --> 00:48:21.760]   And we've ascribed all sorts of moral rules associated to God.
[00:48:21.760 --> 00:48:28.000]   So it's really kind of thinking about what the role is for something that has that power.
[00:48:28.000 --> 00:48:30.560]   With omniscience comes great responsibility.
[00:48:30.560 --> 00:48:31.560]   Right.
[00:48:31.560 --> 00:48:35.560]   So here's the question Stacy.
[00:48:35.560 --> 00:48:40.560]   You're right and then omniscience can be used for good and bad.
[00:48:40.560 --> 00:48:46.680]   And so what I think we need to do is that so what happens is the Facebook has an offer.
[00:48:46.680 --> 00:48:51.440]   It has this targeting machine and someone comes along and figures out how to target
[00:48:51.440 --> 00:48:55.200]   racists with giving them more racism, right?
[00:48:55.200 --> 00:48:56.440]   And Facebook didn't build it that way.
[00:48:56.440 --> 00:48:58.920]   That wasn't part of the architecture.
[00:48:58.920 --> 00:49:01.800]   And once it's pointed out to them that you can do that or you can buy political ads with
[00:49:01.800 --> 00:49:06.280]   rubles or you can do these other bad things, think like your mac cuts, you figure out how
[00:49:06.280 --> 00:49:07.480]   to cut it off.
[00:49:07.480 --> 00:49:14.120]   So what I would ask is if we give Facebook the benefit of the doubt in so far as they're
[00:49:14.120 --> 00:49:20.520]   not trying to build something that is intended to be used to get people they're vulnerable,
[00:49:20.520 --> 00:49:22.140]   but it is being used that way.
[00:49:22.140 --> 00:49:27.440]   What are the principles that you would suggest to them about how to architect this and what
[00:49:27.440 --> 00:49:31.040]   to guard against and what to look for that to me is the constructive way to have this
[00:49:31.040 --> 00:49:32.040]   conversation?
[00:49:32.040 --> 00:49:34.440]   >> I think it's before you even begin.
[00:49:34.440 --> 00:49:39.560]   I think Facebook should recognize first and I don't think it has done this yet.
[00:49:39.560 --> 00:49:45.240]   It should recognize what it's built because you can't start addressing these except by
[00:49:45.240 --> 00:49:48.240]   piecemeal, which is probably not the right way.
[00:49:48.240 --> 00:49:53.680]   But to say, okay, so I would like to see it maybe Mark Zuckerberg in his trip around the
[00:49:53.680 --> 00:50:00.960]   world is doing this, but I want to see them understand and admit that they have built
[00:50:00.960 --> 00:50:05.160]   this thing that can see into people's lives and feelings in a way that is historically
[00:50:05.160 --> 00:50:10.880]   unprecedented and say, hey, that's an awesome responsibility.
[00:50:10.880 --> 00:50:15.720]   And once they've done that, I think they need to establish some sort of moral code.
[00:50:15.720 --> 00:50:16.720]   I mean, again.
[00:50:16.720 --> 00:50:18.200]   >> Yeah, I agree.
[00:50:18.200 --> 00:50:20.560]   So I'm about to start a project.
[00:50:20.560 --> 00:50:22.400]   There's a guy named Dove Seidman.
[00:50:22.400 --> 00:50:24.240]   We haven't announced anything yet.
[00:50:24.240 --> 00:50:26.080]   >> Yeah, I just did.
[00:50:26.080 --> 00:50:27.560]   >> Really kind of.
[00:50:27.560 --> 00:50:29.200]   He runs company called LRN.
[00:50:29.200 --> 00:50:32.680]   If your company gets in trouble and you want to hide it, you hire a PR company.
[00:50:32.680 --> 00:50:37.920]   If you want to fix your culture and figure it out and learn how to be ethical and teach
[00:50:37.920 --> 00:50:40.680]   your staff how to be ethical, get called Dove.
[00:50:40.680 --> 00:50:45.320]   And Dove's a very good guy and he has a big business trying to pay companies more moral.
[00:50:45.320 --> 00:50:48.000]   And so we're talking about trying to work together.
[00:50:48.000 --> 00:50:49.800]   And this is a discussion I'm going to come back to again and again.
[00:50:49.800 --> 00:50:55.560]   And I want to call on you guys is that I think what we have to do is to help them figure
[00:50:55.560 --> 00:51:00.320]   out exactly those kinds of moral principles.
[00:51:00.320 --> 00:51:04.040]   And so when it comes to, let's say, political advertising, I would argue that the way to
[00:51:04.040 --> 00:51:09.520]   get ahead of all this is to decide to set entirely new standards that leapfrog everybody
[00:51:09.520 --> 00:51:14.640]   else about transparency and political advertising on who's buying it, what it says, what the
[00:51:14.640 --> 00:51:19.280]   message is and who's targeted and go overboard and say that's the right thing to do for the
[00:51:19.280 --> 00:51:20.480]   democracy.
[00:51:20.480 --> 00:51:24.560]   What is it to do about advertising to emotions and emotional signals?
[00:51:24.560 --> 00:51:29.280]   What are the principles there that you did we can then call upon when we say, hey, somebody,
[00:51:29.280 --> 00:51:34.000]   I just got a disease and somebody called them, tried to try to sell something to me.
[00:51:34.000 --> 00:51:37.200]   There's a principle we can call on and say, whoa, Facebook, you shouldn't allow that.
[00:51:37.200 --> 00:51:38.200]   That's done.
[00:51:38.200 --> 00:51:39.200]   That's against your principles.
[00:51:39.200 --> 00:51:40.200]   Well, first, you're right.
[00:51:40.200 --> 00:51:41.520]   They have to know how it's being used.
[00:51:41.520 --> 00:51:43.840]   And second, we have to help them establish principles.
[00:51:43.840 --> 00:51:50.480]   And I think the same is true of media because our business model leads to cats and freaking
[00:51:50.480 --> 00:51:56.200]   Kardashians and it leads to the kind of polarization that we have and Donald Trump said two heads
[00:51:56.200 --> 00:52:00.440]   of American news, our organizations may be bad for America, but he's good for business.
[00:52:00.440 --> 00:52:04.400]   So we've got the same problem with you as we're going to new revenue streams.
[00:52:04.400 --> 00:52:07.280]   It goes back to your trust points, Stacy.
[00:52:07.280 --> 00:52:10.440]   What's what's misspelling your trust?
[00:52:10.440 --> 00:52:12.400]   What is the violation of privacy?
[00:52:12.400 --> 00:52:17.120]   What is the violation of of emotions and exploitation?
[00:52:17.120 --> 00:52:21.560]   This is a big discussion to have and I don't think that the platforms or media companies
[00:52:21.560 --> 00:52:22.560]   know how to.
[00:52:22.560 --> 00:52:23.560]   It's a discussion we have to have.
[00:52:23.560 --> 00:52:26.160]   So I want to come back to you often on this topic.
[00:52:26.160 --> 00:52:29.680]   I don't think this is actually a discussion we can have in a capitalistic society.
[00:52:29.680 --> 00:52:31.360]   And I'm not saying I'm a socialist.
[00:52:31.360 --> 00:52:32.360]   I'm just saying that-
[00:52:32.360 --> 00:52:33.360]   Capitalist.
[00:52:33.360 --> 00:52:34.920]   Exactly.
[00:52:34.920 --> 00:52:41.400]   But if your highest goal and you will hear this again and again from people is the fiduciary
[00:52:41.400 --> 00:52:43.280]   duty is to shareholders.
[00:52:43.280 --> 00:52:50.800]   And if you put that in the mindset of my duty is to make money, your morals often will go
[00:52:50.800 --> 00:52:51.800]   by the wayside.
[00:52:51.800 --> 00:52:53.920]   Often but not inevitably.
[00:52:53.920 --> 00:52:59.520]   No, but you also have to think about if you're going to do that, everyone has to play by
[00:52:59.520 --> 00:53:00.520]   that game.
[00:53:00.520 --> 00:53:05.760]   Otherwise, you're like this holy roller who's like feeling all good about themselves and
[00:53:05.760 --> 00:53:10.040]   everybody loves you, but you're not making any money and some activist investor is going
[00:53:10.040 --> 00:53:12.280]   to come in and change your policies.
[00:53:12.280 --> 00:53:17.760]   So I think it's fine to say, hey, this is what we're building.
[00:53:17.760 --> 00:53:20.960]   This is the world we're living in, but we can't just isolate it to the companies.
[00:53:20.960 --> 00:53:27.160]   There's a big, we're kind of in this like race to the bottom in terms of putting a price
[00:53:27.160 --> 00:53:34.920]   on everything as we atomize all this data about people and we turn it into insights to
[00:53:34.920 --> 00:53:36.920]   help sell them things.
[00:53:36.920 --> 00:53:40.840]   But the insights can also be used to give them greater relevance and value, to give them
[00:53:40.840 --> 00:53:42.200]   greater service.
[00:53:42.200 --> 00:53:47.000]   So that's why demonizing, if you demonize the data as opposed to the use of the data,
[00:53:47.000 --> 00:53:50.760]   I'm not demonizing and I'm just, you're not, but others are.
[00:53:50.760 --> 00:53:51.760]   Others are.
[00:53:51.760 --> 00:53:59.080]   I think you actually get a very, well, I don't think you need to investigate people's sex
[00:53:59.080 --> 00:54:05.000]   lives, love lives, friendships, social graph to serve them better.
[00:54:05.000 --> 00:54:08.200]   You get very good signals from just what they consume.
[00:54:08.200 --> 00:54:09.680]   Well, but we should be.
[00:54:09.680 --> 00:54:12.280]   I don't really think you need to do that.
[00:54:12.280 --> 00:54:13.280]   Right.
[00:54:13.280 --> 00:54:15.280]   But we've done that for generations.
[00:54:15.280 --> 00:54:16.280]   That's how media works.
[00:54:16.280 --> 00:54:18.760]   If you sell more newspapers, you're doing the job.
[00:54:18.760 --> 00:54:23.080]   No, media makes media treats everybody the same.
[00:54:23.080 --> 00:54:25.880]   And that's exactly how we ended up in this mess.
[00:54:25.880 --> 00:54:28.080]   That's exactly how we ended up with clickbait.
[00:54:28.080 --> 00:54:30.600]   That's because because we had at least you had a scarcity.
[00:54:30.600 --> 00:54:35.920]   You could say you were haughty and wonderful, but you were also putting in sleazy real estate
[00:54:35.920 --> 00:54:37.360]   sections that were actually just bought.
[00:54:37.360 --> 00:54:38.680]   That's the immediate money.
[00:54:38.680 --> 00:54:41.160]   OK, but I'm the only guy in town with the newspaper and I'll do that.
[00:54:41.160 --> 00:54:42.160]   And that's fine.
[00:54:42.160 --> 00:54:46.240]   And I'll cheat there and I'll be OK over here and nobody's done by the only game.
[00:54:46.240 --> 00:54:49.360]   Then when you get into a budget space market where everybody's going to be with everybody,
[00:54:49.360 --> 00:54:54.480]   then you fall to this desperation, the lower the value, the higher the desperation.
[00:54:54.480 --> 00:54:57.480]   And so that business model is leading us astray.
[00:54:57.480 --> 00:54:59.120]   And it is the business model that media has.
[00:54:59.120 --> 00:55:03.600]   It's also the business model that Facebook and Google have to this extent to an extent.
[00:55:03.600 --> 00:55:09.200]   So you're saying in, for instance, television by chasing ratings, we ended up doing reality
[00:55:09.200 --> 00:55:12.000]   shows and that it comes.
[00:55:12.000 --> 00:55:14.960]   When cost became prohibitive, that's what we did.
[00:55:14.960 --> 00:55:18.680]   Now, when you only have three networks, you made crap and you could sell it and that was
[00:55:18.680 --> 00:55:19.920]   that.
[00:55:19.920 --> 00:55:24.480]   Then when you had 150 networks, the belief was that's going to be too much content quality
[00:55:24.480 --> 00:55:25.480]   will go down.
[00:55:25.480 --> 00:55:26.480]   What happened?
[00:55:26.480 --> 00:55:27.480]   Quality rose.
[00:55:27.480 --> 00:55:29.480]   Because we had more choice.
[00:55:29.480 --> 00:55:32.280]   We could leave the crap and go to the good stuff.
[00:55:32.280 --> 00:55:35.520]   So the average, then the market is still by his networks.
[00:55:35.520 --> 00:55:38.920]   The networks have lower audience, higher costs.
[00:55:38.920 --> 00:55:39.920]   So what do they do?
[00:55:39.920 --> 00:55:40.920]   They go to crap.
[00:55:40.920 --> 00:55:41.920]   Right.
[00:55:41.920 --> 00:55:46.600]   So, yeah, I wish advertisers realized how good a good deal podcasts are, but that's another
[00:55:46.600 --> 00:55:47.600]   story.
[00:55:47.600 --> 00:55:48.600]   Event brother.
[00:55:48.600 --> 00:55:50.920]   So, but that's a, so, but that's been a benefit.
[00:55:50.920 --> 00:55:58.000]   So having a much broader market has allowed many people to chase individual audiences,
[00:55:58.000 --> 00:56:01.480]   but not necessarily intruding on people's privacy to do so.
[00:56:01.480 --> 00:56:06.320]   I, we do a survey once a year that gives us some information and we notice what shows
[00:56:06.320 --> 00:56:08.840]   get watched and we read our emails.
[00:56:08.840 --> 00:56:11.680]   Isn't that, aren't those enough signals to generate good content?
[00:56:11.680 --> 00:56:12.680]   So I'll give you an example.
[00:56:12.680 --> 00:56:17.080]   Why do I need to know what the person at home is income is?
[00:56:17.080 --> 00:56:20.800]   Well, that's because you're doing that because the advertiser was.
[00:56:20.800 --> 00:56:21.800]   I don't ask.
[00:56:21.800 --> 00:56:22.800]   Is that?
[00:56:22.800 --> 00:56:23.800]   I agree.
[00:56:23.800 --> 00:56:24.800]   That's ridiculous.
[00:56:24.800 --> 00:56:25.800]   I'll give you an example.
[00:56:25.800 --> 00:56:34.200]   I heard someone who's experienced the business had, had was involved in a big travel site.
[00:56:34.200 --> 00:56:36.120]   And they were doing commerce there.
[00:56:36.120 --> 00:56:39.600]   And for some reason, there's no rhyme and reason to this.
[00:56:39.600 --> 00:56:44.280]   Only experience would tell you this, that what sells best on a travel site, what would
[00:56:44.280 --> 00:56:45.880]   you think it would be?
[00:56:45.880 --> 00:56:47.880]   Um, obvious question.
[00:56:47.880 --> 00:56:48.880]   Uh, hotel.
[00:56:48.880 --> 00:56:49.880]   Hotel review.
[00:56:49.880 --> 00:56:50.880]   Right.
[00:56:50.880 --> 00:56:51.880]   Right.
[00:56:51.880 --> 00:56:52.880]   Traveler.
[00:56:52.880 --> 00:56:53.880]   Okay.
[00:56:53.880 --> 00:56:54.880]   That was a terrific question.
[00:56:54.880 --> 00:56:55.880]   Oh, it's not.
[00:56:55.880 --> 00:56:56.880]   It was over the obvious.
[00:56:56.880 --> 00:56:57.880]   Yeah.
[00:56:57.880 --> 00:56:58.880]   This is the professorial thing.
[00:56:58.880 --> 00:56:59.880]   You ask the dumb about.
[00:56:59.880 --> 00:57:00.880]   This is a socratic method.
[00:57:00.880 --> 00:57:04.280]   And then you prove yourself in this order because you're going to give the real answer.
[00:57:04.280 --> 00:57:05.280]   Real answer?
[00:57:05.280 --> 00:57:06.280]   Shoes.
[00:57:06.280 --> 00:57:07.280]   Shoes.
[00:57:07.280 --> 00:57:08.280]   Why?
[00:57:08.280 --> 00:57:09.280]   I have no idea.
[00:57:09.280 --> 00:57:16.000]   Because I'm fantasizing when I travel and then a shoe ad that has followed me there might
[00:57:16.000 --> 00:57:20.200]   become an affordable luxury and escape from my boring and real life.
[00:57:20.200 --> 00:57:21.200]   Very good.
[00:57:21.200 --> 00:57:23.480]   I buy a lot of shoes online.
[00:57:23.480 --> 00:57:24.480]   Yeah.
[00:57:24.480 --> 00:57:25.480]   I buy a lot of smartphones.
[00:57:25.480 --> 00:57:26.480]   Same thing.
[00:57:26.480 --> 00:57:29.600]   Having data about people, um, is not a rough thing.
[00:57:29.600 --> 00:57:30.920]   Well, let me ask you this then.
[00:57:30.920 --> 00:57:32.480]   Let me ask you this.
[00:57:32.480 --> 00:57:38.480]   Do you think that Netflix's Twitter about the Christmas Prince was terrible or funny?
[00:57:38.480 --> 00:57:39.480]   I say funny.
[00:57:39.480 --> 00:57:40.480]   I thought it was both.
[00:57:40.480 --> 00:57:46.200]   But wait, before you move on from shoes, how did the travel site learn that?
[00:57:46.200 --> 00:57:48.440]   Because they would try different things and they would find.
[00:57:48.440 --> 00:57:49.440]   So what's wrong with that?
[00:57:49.440 --> 00:57:50.440]   What sells?
[00:57:50.440 --> 00:57:51.440]   That's not.
[00:57:51.440 --> 00:57:52.440]   That's data.
[00:57:52.440 --> 00:57:54.320]   But that's not spying on you.
[00:57:54.320 --> 00:57:56.320]   That's not figuring out who's in their manic face.
[00:57:56.320 --> 00:57:58.040]   So you can advertise gambling.
[00:57:58.040 --> 00:58:02.080]   So in this company, in this company, when they see somebody is travel interested and they
[00:58:02.080 --> 00:58:05.640]   go to the travel site a lot, wherever they are, they don't all data together.
[00:58:05.640 --> 00:58:06.640]   There's some data.
[00:58:06.640 --> 00:58:07.640]   I'm saying don't.
[00:58:07.640 --> 00:58:08.640]   Yes.
[00:58:08.640 --> 00:58:09.640]   That's exactly what I'm saying.
[00:58:09.640 --> 00:58:10.640]   You don't love all data together.
[00:58:10.640 --> 00:58:11.640]   I mean, data bad.
[00:58:11.640 --> 00:58:12.640]   The use of it.
[00:58:12.640 --> 00:58:17.000]   I'm not making data bad, but I'm saying that selling against intrusive a company that
[00:58:17.000 --> 00:58:20.360]   you know, intrusive, no, not all intrusive.
[00:58:20.360 --> 00:58:24.440]   But a lot of what Facebook does is so wait, wait, wait, wait.
[00:58:24.440 --> 00:58:27.240]   So this is what I'm trying to get you both to be constructive.
[00:58:27.240 --> 00:58:32.160]   So define intrusive to the point that they could that you end up with a principle that
[00:58:32.160 --> 00:58:34.800]   they could enforce and that you could hold them to.
[00:58:34.800 --> 00:58:36.440]   That's the goal.
[00:58:36.440 --> 00:58:37.440]   That's the discussion we need to have.
[00:58:37.440 --> 00:58:40.200]   Instead of just saying, well, Facebook's just awful, they don't know all this stuff
[00:58:40.200 --> 00:58:41.200]   about you.
[00:58:41.200 --> 00:58:42.200]   And my God, what could happen?
[00:58:42.200 --> 00:58:43.200]   Well, the reason they came up.
[00:58:43.200 --> 00:58:44.280]   We have established.
[00:58:44.280 --> 00:58:45.680]   So we've already established these.
[00:58:45.680 --> 00:58:48.640]   Look at you don't advertise against medical conditions.
[00:58:48.640 --> 00:58:49.640]   Right.
[00:58:49.640 --> 00:58:52.280]   You don't advertise against sexual orientation.
[00:58:52.280 --> 00:58:54.040]   You don't advertise against race.
[00:58:54.040 --> 00:58:56.040]   Race, color, race, and large.
[00:58:56.040 --> 00:58:57.040]   Many medical conditions.
[00:58:57.040 --> 00:58:58.040]   No, I'm going to disagree.
[00:58:58.040 --> 00:59:00.040]   I'm going to disagree strongly there.
[00:59:00.040 --> 00:59:02.480]   Oh, because you have information.
[00:59:02.480 --> 00:59:05.200]   Because I have a lot of medical conditions and I've gotten value.
[00:59:05.200 --> 00:59:06.400]   That's how I discovered Cardi.
[00:59:06.400 --> 00:59:07.400]   Great.
[00:59:07.400 --> 00:59:08.400]   Okay.
[00:59:08.400 --> 00:59:10.680]   But see, I discovered Cardi because I have atrial fibrillation and I talk about it and
[00:59:10.680 --> 00:59:15.040]   it was extremely valuable to me and could bloody well save my life that I discovered
[00:59:15.040 --> 00:59:16.560]   that device.
[00:59:16.560 --> 00:59:21.560]   The challenge is what's useful to you there on Facebook could also be used to discriminate
[00:59:21.560 --> 00:59:23.720]   against you in hiring, for example.
[00:59:23.720 --> 00:59:26.080]   There are other ways to find out about this.
[00:59:26.080 --> 00:59:27.080]   Right.
[00:59:27.080 --> 00:59:28.080]   You'll hear that.
[00:59:28.080 --> 00:59:32.680]   There are very good methods for finding out about products for your various maladies without
[00:59:32.680 --> 00:59:33.680]   resorting to advertising.
[00:59:33.680 --> 00:59:34.880]   I would never have.
[00:59:34.880 --> 00:59:36.560]   I wasn't going to go searching for it, Leo.
[00:59:36.560 --> 00:59:37.560]   I wasn't going to go.
[00:59:37.560 --> 00:59:38.560]   It came to me and your lazy.
[00:59:38.560 --> 00:59:41.840]   It came to me and I was, no, I didn't know what existed.
[00:59:41.840 --> 00:59:44.240]   It would behoove you to find out.
[00:59:44.240 --> 00:59:45.720]   And it came to me.
[00:59:45.720 --> 00:59:51.160]   So here's the deal by having, by talking about something broadly, Jeff, you opened yourself
[00:59:51.160 --> 00:59:54.720]   up to it and people would talk to you about it eventually.
[00:59:54.720 --> 00:59:57.520]   You would have found it regardless because you would have been like, oh, I have a epip
[00:59:57.520 --> 01:00:00.240]   and someone would be like, hey, I don't know if you know this.
[01:00:00.240 --> 01:00:01.960]   That's how we used to do it.
[01:00:01.960 --> 01:00:04.120]   That's how it used to work.
[01:00:04.120 --> 01:00:06.960]   Called word of mouth.
[01:00:06.960 --> 01:00:07.960]   So yeah.
[01:00:07.960 --> 01:00:09.800]   Give it a look.
[01:00:09.800 --> 01:00:11.040]   This stuff could be weaponized.
[01:00:11.040 --> 01:00:12.520]   That's why Jeff.
[01:00:12.520 --> 01:00:14.440]   It could be could be could be.
[01:00:14.440 --> 01:00:17.440]   That doesn't mean it's being weaponized.
[01:00:17.440 --> 01:00:19.040]   It's regulate that.
[01:00:19.040 --> 01:00:20.320]   You don't regulate the data.
[01:00:20.320 --> 01:00:24.320]   You don't call Facebook evil for knowing this.
[01:00:24.320 --> 01:00:25.320]   If I go to what I go to.
[01:00:25.320 --> 01:00:31.240]   It's hard to regulate if it's dark and Facebook has not cooperated in any way fine.
[01:00:31.240 --> 01:00:33.080]   Then that's a principle you set.
[01:00:33.080 --> 01:00:36.720]   But the fact that people talk about their age of revelation is not a bad thing.
[01:00:36.720 --> 01:00:42.960]   Facebook has very carefully hidden what it's doing because they know it would be highly
[01:00:42.960 --> 01:00:44.200]   offensive.
[01:00:44.200 --> 01:00:47.920]   And so we haven't still haven't even seen the dark ads that they showed people.
[01:00:47.920 --> 01:00:50.440]   For the 2016 election.
[01:00:50.440 --> 01:00:55.800]   And they never will because it would hurt them if people knew what they were doing.
[01:00:55.800 --> 01:00:58.040]   And you can't regulate something that's hidden like that.
[01:00:58.040 --> 01:00:59.360]   How are you going to get that information?
[01:00:59.360 --> 01:01:02.320]   Well, you can have a discussion of the principles involved.
[01:01:02.320 --> 01:01:03.320]   And you get that.
[01:01:03.320 --> 01:01:05.480]   So we are and we're having a discussion of principles.
[01:01:05.480 --> 01:01:09.400]   And what you are doing is you're taking it down to your personal level and you constantly
[01:01:09.400 --> 01:01:14.160]   do this and it's very frustrating because you seem to conflate a principle with your
[01:01:14.160 --> 01:01:15.440]   feelings.
[01:01:15.440 --> 01:01:18.320]   And that is in your value from something.
[01:01:18.320 --> 01:01:20.280]   I think it's the opposite they say.
[01:01:20.280 --> 01:01:24.480]   No, I think you were saying this bad thing could happen.
[01:01:24.480 --> 01:01:27.440]   And I'm here to ask that principle.
[01:01:27.440 --> 01:01:31.360]   As a principle, we have regulated medical stuff already.
[01:01:31.360 --> 01:01:33.160]   You don't advertise against medical stuff.
[01:01:33.160 --> 01:01:38.440]   That's actually something that even when AT&T and others were looking at doing web based
[01:01:38.440 --> 01:01:43.240]   search like advertising its people's web searches, they were pulling out certain categories
[01:01:43.240 --> 01:01:45.640]   because they were deemed sensitive.
[01:01:45.640 --> 01:01:48.200]   And that is just a fact.
[01:01:48.200 --> 01:01:49.320]   It is not an opinion.
[01:01:49.320 --> 01:01:53.920]   It is something that is so far in society been agreed upon.
[01:01:53.920 --> 01:01:58.040]   Now you're coming in and you're saying, hey, I don't agree with that, which is fine.
[01:01:58.040 --> 01:02:02.880]   But as an argument, when we're trying to set these principles.
[01:02:02.880 --> 01:02:04.880]   You can't just take your personal.
[01:02:04.880 --> 01:02:05.880]   You can't take your personal experience.
[01:02:05.880 --> 01:02:10.000]   And you're trying to enforce them and you say what's the what's the definition of privilege
[01:02:10.000 --> 01:02:15.800]   in a lot of ways because you're not considering the other ways that people are hurt by this.
[01:02:15.800 --> 01:02:21.120]   And so I'm not saying about this, but you're not talking about it at this level, Jeff.
[01:02:21.120 --> 01:02:22.720]   You're talking about it at your own personal level.
[01:02:22.720 --> 01:02:26.280]   We need to take it up to talk about it from everyone's perspective.
[01:02:26.280 --> 01:02:30.200]   So throw your perspective in there, but that is not the end all be all.
[01:02:30.200 --> 01:02:31.200]   Let's face here is the problem.
[01:02:31.200 --> 01:02:35.680]   When you take it up too high, then you end up saying all data is everything could be
[01:02:35.680 --> 01:02:36.680]   dangerous.
[01:02:36.680 --> 01:02:44.560]   I do understand that, but you're taking it too low, too personal.
[01:02:44.560 --> 01:02:46.320]   I'm just going to use the middle.
[01:02:46.320 --> 01:02:47.320]   That's all I'm saying.
[01:02:47.320 --> 01:02:50.080]   I see I wrote a book about sharing, right?
[01:02:50.080 --> 01:02:52.920]   I believe that there's a value to society sharing.
[01:02:52.920 --> 01:02:56.960]   I believe that if you go to which I set you for free, by the way, I believe that if you
[01:02:56.960 --> 01:03:03.880]   go to the root causes of some of the issues here, they're not about the technologies,
[01:03:03.880 --> 01:03:04.880]   not about Facebook.
[01:03:04.880 --> 01:03:05.880]   It's about our own society.
[01:03:05.880 --> 01:03:09.640]   Why are we ashamed of talking about being sick in the society?
[01:03:09.640 --> 01:03:12.920]   Well, there's a real tangible reason, which is you could be affected in your employment,
[01:03:12.920 --> 01:03:15.200]   then regulate that.
[01:03:15.200 --> 01:03:17.240]   That's Dana Boyd taught me that, right?
[01:03:17.240 --> 01:03:21.200]   You regulate the use of the data and the use of the knowledge, not the knowledge.
[01:03:21.200 --> 01:03:25.280]   And that the end, don't cut off the opportunities that can come.
[01:03:25.280 --> 01:03:27.680]   You call opportunities that can come of benefit.
[01:03:27.680 --> 01:03:31.040]   Nobody's going to regulate your ability to share with your friends and family or in public
[01:03:31.040 --> 01:03:34.360]   or even on this show, say your medical issues.
[01:03:34.360 --> 01:03:35.360]   Nobody's going to regulate that.
[01:03:35.360 --> 01:03:36.360]   Cardiacant can't...
[01:03:36.360 --> 01:03:39.320]   Vic and Otra can't advertise it to me.
[01:03:39.320 --> 01:03:40.840]   Well, that would be the wrong place to regulate it.
[01:03:40.840 --> 01:03:43.280]   The place to regulate it is the place that's most difficult to regulate it.
[01:03:43.280 --> 01:03:49.340]   It is the company that is willing to take that information and monetize it in a way that
[01:03:49.340 --> 01:03:51.340]   I think we would all agree is inappropriate.
[01:03:51.340 --> 01:03:55.320]   Well, maybe you wouldn't, Jeff, but I would say if you and I would agree, is inappropriate,
[01:03:55.320 --> 01:03:56.320]   right?
[01:03:56.320 --> 01:03:59.880]   Stacy, so I think that the problem is I don't think you're going to get Facebook to help
[01:03:59.880 --> 01:04:02.240]   you in this and I don't think you could...
[01:04:02.240 --> 01:04:03.240]   I don't...
[01:04:03.240 --> 01:04:04.240]   Maybe you can force them to help you in this.
[01:04:04.240 --> 01:04:05.240]   I don't know that...
[01:04:05.240 --> 01:04:10.200]   Well, maybe they won't, maybe they won't, but what I'm trying to say is that the discussion
[01:04:10.200 --> 01:04:13.520]   that I hear constantly is basically just writing off Facebook and the two billion people who
[01:04:13.520 --> 01:04:18.000]   were there and saying, "Oh, it's so awful and wrong."
[01:04:18.000 --> 01:04:20.040]   If we don't demand...
[01:04:20.040 --> 01:04:23.640]   If we don't have a discussion about the principles in a way that we have expectations of them,
[01:04:23.640 --> 01:04:24.640]   I think they should be doing it in their own.
[01:04:24.640 --> 01:04:25.640]   I don't think there's...
[01:04:25.640 --> 01:04:26.640]   I'll be honest.
[01:04:26.640 --> 01:04:27.640]   I'm pretty sure the outside.
[01:04:27.640 --> 01:04:28.640]   I don't think there's a way to save Facebook.
[01:04:28.640 --> 01:04:29.640]   I think it's...
[01:04:29.640 --> 01:04:30.640]   It's...
[01:04:30.640 --> 01:04:31.640]   It's...
[01:04:31.640 --> 01:04:34.140]   It's business model is entirely based on the way that we...
[01:04:34.140 --> 01:04:38.160]   It's based upon the unfettered sharing of personal information which it then sells against.
[01:04:38.160 --> 01:04:39.160]   Okay.
[01:04:39.160 --> 01:04:40.160]   There's no way they own that.
[01:04:40.160 --> 01:04:42.000]   It's from day one that was its business model.
[01:04:42.000 --> 01:04:48.920]   There is no way to save media because media is built on exploiting tabloid interests to
[01:04:48.920 --> 01:04:52.880]   an extreme and inevitably leads to clickbait, which will inevitably lead us to where we
[01:04:52.880 --> 01:04:54.000]   are in our political atmosphere.
[01:04:54.000 --> 01:04:55.000]   There's no way to save media either.
[01:04:55.000 --> 01:04:57.960]   But of course, we try to save media because it's worth doing.
[01:04:57.960 --> 01:04:59.560]   I'm not going to write off Facebook.
[01:04:59.560 --> 01:05:00.800]   I'm not going to write off Google.
[01:05:00.800 --> 01:05:03.300]   And I'm also going to do my Gutenberg speed.
[01:05:03.300 --> 01:05:05.140]   I'll take a drink that were early days.
[01:05:05.140 --> 01:05:06.140]   We've got to learn.
[01:05:06.140 --> 01:05:09.140]   We've got to have these discussions writing off.
[01:05:09.140 --> 01:05:10.140]   That's the essence of...
[01:05:10.140 --> 01:05:11.140]   Why?
[01:05:11.140 --> 01:05:12.140]   Why?
[01:05:12.140 --> 01:05:13.140]   That's moral panic.
[01:05:13.140 --> 01:05:15.540]   That's moral panic that says this is going to be awful and we've got to stop it.
[01:05:15.540 --> 01:05:18.180]   Well there's huge benefits that can throw out with the bath water there.
[01:05:18.180 --> 01:05:20.620]   I'm only lately come to this point of view though.
[01:05:20.620 --> 01:05:23.420]   I think that there's a problem.
[01:05:23.420 --> 01:05:24.420]   Go ahead.
[01:05:24.420 --> 01:05:25.420]   Outcomes.
[01:05:25.420 --> 01:05:29.580]   Let's talk about that because that's actually really worthwhile.
[01:05:29.580 --> 01:05:34.520]   And I think especially in the case of algorithms, we do actually have a problem that will only
[01:05:34.520 --> 01:05:37.200]   be because you can't see what's happening behind the scenes.
[01:05:37.200 --> 01:05:39.000]   I think outcomes is a great structure.
[01:05:39.000 --> 01:05:40.000]   Yes, I agree.
[01:05:40.000 --> 01:05:41.000]   That's a great structure.
[01:05:41.000 --> 01:05:42.000]   I know.
[01:05:42.000 --> 01:05:43.000]   I know that.
[01:05:43.000 --> 01:05:47.920]   So when we talk about that though, right now we don't have the framework for it because
[01:05:47.920 --> 01:05:51.680]   someone has to be hurt before we see the problem.
[01:05:51.680 --> 01:05:57.000]   And then once someone's hurt, we tend to over-specify it to that particular case.
[01:05:57.000 --> 01:06:01.260]   We get a lot of knee-jerk reaction is the, knee-jerk legislation is the worry.
[01:06:01.260 --> 01:06:05.160]   But we also then need to think about if we're going to regulate outcomes, how can we do
[01:06:05.160 --> 01:06:08.040]   it to offer retribution?
[01:06:08.040 --> 01:06:11.660]   Do we want to offer retribution to the person who's hurt as we discovered that, oh maybe
[01:06:11.660 --> 01:06:13.560]   this was a bad use of data sharing?
[01:06:13.560 --> 01:06:15.320]   So we've got to think about that.
[01:06:15.320 --> 01:06:20.840]   We've got to think about how to do it quickly so someone isn't hurt a lot or maybe multiple
[01:06:20.840 --> 01:06:23.500]   people don't have to get really hurt.
[01:06:23.500 --> 01:06:29.300]   We have to set up things in place to track when people get hurt and who gets hurt because
[01:06:29.300 --> 01:06:35.500]   right now there's a whole, I mean Black Lives Matter is all about people who've gotten hurt
[01:06:35.500 --> 01:06:39.100]   for years and we've just ignored it because it was inconvenient.
[01:06:39.100 --> 01:06:44.900]   So if we're going to start talking about regulating outcomes, we have to think about how to build
[01:06:44.900 --> 01:06:50.220]   that into the way we work as a society, how we legislate now and across.
[01:06:50.220 --> 01:06:51.220]   I agree.
[01:06:51.220 --> 01:06:53.460]   That's a positive way to have the discussion.
[01:06:53.460 --> 01:06:56.420]   And you're quite right about this and this is where you're going actually.
[01:06:56.420 --> 01:07:00.820]   The specificity on technology is an equal problem to the specificity on the person.
[01:07:00.820 --> 01:07:06.220]   The example I always use on this is the German official who said that henceforth the use
[01:07:06.220 --> 01:07:12.740]   of facial recognition and geotechnology together was a lot.
[01:07:12.740 --> 01:07:17.580]   Not seeing that it could find missing children and Alzheimer's patients and so on and so
[01:07:17.580 --> 01:07:19.060]   forth obviously, right?
[01:07:19.060 --> 01:07:22.740]   >> And people who've been stalked by abusive spouses.
[01:07:22.740 --> 01:07:27.740]   So we look at the outcomes and we figure out how to regulate this but the two technologies
[01:07:27.740 --> 01:07:33.460]   together is not fundamentally evil because it could be used in a case in bad ways.
[01:07:33.460 --> 01:07:34.700]   >> But it's not panic.
[01:07:34.700 --> 01:07:35.700]   >> We can't presume.
[01:07:35.700 --> 01:07:39.700]   >> We can't bring up the problems and that's what things should be considering in the beginning.
[01:07:39.700 --> 01:07:40.900]   >> But the German, the German.
[01:07:40.900 --> 01:07:42.860]   >> That should be their reckoning.
[01:07:42.860 --> 01:07:47.860]   >> I agree and that's what I'm also trying to say to all of us is that we the public and
[01:07:47.860 --> 01:07:52.620]   we who the tech cognizant have to help them do that.
[01:07:52.620 --> 01:07:56.140]   >> I'm not saying Facebook cannot be reclaimed as Leo just said.
[01:07:56.140 --> 01:07:58.140]   I didn't get us anywhere.
[01:07:58.140 --> 01:08:00.140]   >> Well, saying you could get us somewhere.
[01:08:00.140 --> 01:08:03.860]   >> I think people should abandon Facebook immediately.
[01:08:03.860 --> 01:08:08.940]   I think you're playing in a space that's incredibly dangerous and you will deeply regret
[01:08:08.940 --> 01:08:13.820]   and Congress is never going to regulate it and it's only going to get bigger and more
[01:08:13.820 --> 01:08:16.980]   malign and I think we need to all stop using Facebook.
[01:08:16.980 --> 01:08:19.100]   A world without social is a world I already regret.
[01:08:19.100 --> 01:08:20.180]   It's not a world without social.
[01:08:20.180 --> 01:08:21.420]   It's a world without Facebook.
[01:08:22.420 --> 01:08:23.740]   >> It's a big difference.
[01:08:23.740 --> 01:08:28.580]   >> In fact, the you conflating social with Facebook is part of the problem, Jeff.
[01:08:28.580 --> 01:08:30.300]   You need to get out of the house here a little bit.
[01:08:30.300 --> 01:08:34.340]   >> Go through your feed right now and show me the first awful evil horrible thing you
[01:08:34.340 --> 01:08:35.340]   find in your Facebook feed.
[01:08:35.340 --> 01:08:36.340]   >> No, it's nothing in my feed.
[01:08:36.340 --> 01:08:37.340]   I'm not talking about my feed.
[01:08:37.340 --> 01:08:42.860]   I'm talking about Facebook is doing it's I'm talking about the use of big data and the
[01:08:42.860 --> 01:08:47.620]   kind of data Facebook's gathering and how people are providing happily, willingly providing
[01:08:47.620 --> 01:08:50.620]   the Facebook without realizing the culture.
[01:08:50.620 --> 01:08:51.620]   It's okay.
[01:08:51.620 --> 01:08:52.620]   >> Share with us.
[01:08:52.620 --> 01:08:59.180]   >> Go have a meal with a friend then stop putting it in this giant maw that is chewing
[01:08:59.180 --> 01:09:00.940]   up all our data and creating.
[01:09:00.940 --> 01:09:04.980]   See this is making a moral panic about data and again, I argue that this data is exactly
[01:09:04.980 --> 01:09:07.740]   the salvation of media and the journalism that you were lying on.
[01:09:07.740 --> 01:09:12.300]   >> Well, I think if we don't use Facebook, I think it will save Facebook.
[01:09:12.300 --> 01:09:16.420]   I see no evidence that it's going to save the New York Times.
[01:09:16.420 --> 01:09:17.420]   I disagree.
[01:09:17.420 --> 01:09:24.300]   I just had a meeting of executives from that company and others just yesterday where commerce
[01:09:24.300 --> 01:09:32.780]   as a revenue stream built on trust, built on data is a major contributor to.
[01:09:32.780 --> 01:09:35.820]   >> But you use data as if it's a monolithic thing.
[01:09:35.820 --> 01:09:37.860]   There's data and there's data.
[01:09:37.860 --> 01:09:42.620]   There's data about what mental state a visitor is in so that we can give them an ad that
[01:09:42.620 --> 01:09:46.780]   will take advantage maximum advantage of their mental state.
[01:09:46.780 --> 01:09:48.860]   >> And regulate can't regulate it.
[01:09:48.860 --> 01:09:51.980]   And by the way, I have a Congress that will never regulate it.
[01:09:51.980 --> 01:09:55.500]   We could barely keep the internet service providers from struggling.
[01:09:55.500 --> 01:09:57.140]   >> Then self-regulate to it.
[01:09:57.140 --> 01:10:00.700]   >> And then, yeah, you know what the self-regulation is?
[01:10:00.700 --> 01:10:02.860]   Stop using Facebook.
[01:10:02.860 --> 01:10:05.020]   That's the self-regulation.
[01:10:05.020 --> 01:10:07.620]   That's a very, very, very good self-regulation.
[01:10:07.620 --> 01:10:09.580]   If everybody does that, then I won't.
[01:10:09.580 --> 01:10:11.140]   >> Google is going to do it.
[01:10:11.140 --> 01:10:17.340]   >> Google's a more troubling problem because I don't know how we stop using Google to be
[01:10:17.340 --> 01:10:18.340]   honest with you.
[01:10:18.340 --> 01:10:20.860]   You can easily stop using Facebook.
[01:10:20.860 --> 01:10:25.380]   That's a very low bar.
[01:10:25.380 --> 01:10:29.340]   >> So you can use what's the one that I talked about?
[01:10:29.340 --> 01:10:33.580]   >> You could use those and you could end up getting absolutely --
[01:10:33.580 --> 01:10:35.300]   >> No, I agree.
[01:10:35.300 --> 01:10:39.260]   >> I used to talk about go for a long time.
[01:10:39.260 --> 01:10:43.220]   Because Facebook is completely unnecessary.
[01:10:43.220 --> 01:10:46.500]   Google is a little bit more difficult to live with that because internet search --
[01:10:46.500 --> 01:10:49.180]   >> Yes, Google can enable people to connect with each other.
[01:10:49.180 --> 01:10:50.620]   Wonderful things can happen on Facebook.
[01:10:50.620 --> 01:10:51.620]   That's just too simple.
[01:10:51.620 --> 01:10:52.980]   >> It's not the only way it can happen.
[01:10:52.980 --> 01:10:53.980]   I don't understand why.
[01:10:53.980 --> 01:10:57.660]   I don't understand why you think it's the only way people can connect with each other.
[01:10:57.660 --> 01:10:59.380]   There's lots of ways you can connect.
[01:10:59.380 --> 01:11:00.380]   >> What do you want to invent instead?
[01:11:00.380 --> 01:11:02.140]   >> You don't have to invent anything.
[01:11:02.140 --> 01:11:05.780]   We've survived pretty well for a few millennia without it.
[01:11:05.780 --> 01:11:11.580]   In a world that was controlled by a few media companies, and that's the only way we could
[01:11:11.580 --> 01:11:13.020]   learn anything was from them.
[01:11:13.020 --> 01:11:14.260]   >> Well, here's the good news.
[01:11:14.260 --> 01:11:15.940]   That world's long gone.
[01:11:15.940 --> 01:11:17.260]   With or without Facebook.
[01:11:17.260 --> 01:11:18.860]   That world is long gone.
[01:11:18.860 --> 01:11:22.260]   So we no longer need Facebook to save us from the oligarchies.
[01:11:22.260 --> 01:11:25.420]   >> What you're complaining about is your fellow man and woman at some level.
[01:11:25.420 --> 01:11:28.020]   >> No, I'm complaining about Mark Zuckerberg's Facebook.
[01:11:28.020 --> 01:11:29.340]   It's very simple.
[01:11:29.340 --> 01:11:34.580]   I'm complaining about a company that is willing to mine personal data from people in a way
[01:11:34.580 --> 01:11:38.500]   that is offensive to make money.
[01:11:38.500 --> 01:11:41.620]   I think it is a blight on our society.
[01:11:41.620 --> 01:11:43.780]   I think we will look back and say it was.
[01:11:43.780 --> 01:11:45.660]   I think we already know it is.
[01:11:45.660 --> 01:11:48.100]   I think we've seen the results of it, Jeff.
[01:11:48.100 --> 01:11:49.780]   >> I have to do my caveat here.
[01:11:49.780 --> 01:11:50.780]   My full disclosure.
[01:11:50.780 --> 01:11:51.780]   >> I know.
[01:11:51.780 --> 01:11:52.780]   I know.
[01:11:52.780 --> 01:11:53.780]   >> I haven't done a show yet.
[01:11:53.780 --> 01:11:57.740]   So I started the news integrity initiative, which is funded substantially by Facebook,
[01:11:57.740 --> 01:11:59.700]   Craig DeMark Foundation, Ford Foundation, and others.
[01:11:59.700 --> 01:12:01.380]   I'm independent of Facebook.
[01:12:01.380 --> 01:12:04.780]   I'm critical of Facebook, but I also believe that there is value there.
[01:12:04.780 --> 01:12:05.780]   Otherwise, I wouldn't have done this.
[01:12:05.780 --> 01:12:09.860]   >> I would never impugn your independence in any way.
[01:12:09.860 --> 01:12:14.940]   I think it's important people understand that it could think to disclaim, but there's
[01:12:14.940 --> 01:12:16.940]   no suggestion, no hint.
[01:12:16.940 --> 01:12:17.940]   >> I don't even say it.
[01:12:17.940 --> 01:12:19.940]   >> I was puning your integrity.
[01:12:19.940 --> 01:12:21.660]   >> But the audience can decide for themselves.
[01:12:21.660 --> 01:12:24.660]   He's just defending social and Facebook because of that.
[01:12:24.660 --> 01:12:26.660]   You can make that people can make that.
[01:12:26.660 --> 01:12:28.940]   >> Cobra in the chatroom says, "Well, you could say that about anything."
[01:12:28.940 --> 01:12:32.180]   You could say, "Don't watch Monday Night Football because it's contributing to violence."
[01:12:32.180 --> 01:12:33.180]   Yeah, actually.
[01:12:33.180 --> 01:12:37.420]   I'm very seriously considering stopping watching the NFL because it's what it does to the players.
[01:12:37.420 --> 01:12:39.300]   >> What it does to those people, yeah.
[01:12:39.300 --> 01:12:41.220]   >> That's actually a very legitimate point, Cobra.
[01:12:41.220 --> 01:12:42.220]   I agree with you.
[01:12:42.220 --> 01:12:45.140]   >> Let's move to the football team.
[01:12:45.140 --> 01:12:46.140]   >> We're going to stop.
[01:12:46.140 --> 01:12:47.500]   We're going to stop.
[01:12:47.500 --> 01:12:49.980]   We're done with the philosophical conversations.
[01:12:49.980 --> 01:12:51.900]   You have gifts.
[01:12:51.900 --> 01:12:53.780]   We have toys.
[01:12:53.780 --> 01:12:55.740]   We have an ad from Sonic.
[01:12:55.740 --> 01:12:58.900]   We'll have more with Jeff Jarvis and Stacey Higginbotham.
[01:12:58.900 --> 01:13:03.540]   I think it's really a great conversation, very important conversation.
[01:13:03.540 --> 01:13:05.380]   I think it's crystallizing.
[01:13:05.380 --> 01:13:10.340]   I think the timing, it's becoming more and more of an important conversation.
[01:13:10.340 --> 01:13:12.820]   Let's say that.
[01:13:12.820 --> 01:13:17.100]   Our show today brought to you by a company that is doing everything it can to preserve
[01:13:17.100 --> 01:13:18.100]   net neutrality.
[01:13:18.100 --> 01:13:21.780]   There are internet service providers who believe in net neutrality.
[01:13:21.780 --> 01:13:22.740]   One of them is Sonic.
[01:13:22.740 --> 01:13:25.020]   I know it because I know Jane Jasper, the founder.
[01:13:25.020 --> 01:13:26.380]   I've known him since he started Sonic.
[01:13:26.380 --> 01:13:27.580]   I've been a customer.
[01:13:27.580 --> 01:13:29.540]   Since he started Sonic, in fact, we're customers right now.
[01:13:29.540 --> 01:13:32.740]   In fact, if you're watching this show, you can say thank you, Sonic.
[01:13:32.740 --> 01:13:38.100]   We are literally brought to you by our 10 gigabit fiber interconnect connection to the
[01:13:38.100 --> 01:13:40.220]   outside world through Sonic.
[01:13:40.220 --> 01:13:43.780]   Too many people pay too much for unsatisfactory cable internet in this country.
[01:13:43.780 --> 01:13:49.460]   Sonic delivers fast, affordable internet, phone, even TV to homes and businesses all
[01:13:49.460 --> 01:13:52.660]   over California.
[01:13:52.660 --> 01:13:57.300]   Residential and business fiber to the premise networks, gigabit connectivity.
[01:13:57.300 --> 01:13:59.420]   Look what you get and look at the price.
[01:13:59.420 --> 01:14:05.620]   15 email accounts, a gigabyte of storage, personal web hosting, including a new domain,
[01:14:05.620 --> 01:14:09.980]   fax line service, a home phone connection.
[01:14:09.980 --> 01:14:13.580]   You can port your existing phone number to it so you don't lose your number.
[01:14:13.580 --> 01:14:15.500]   Unlimited local and long distance calling.
[01:14:15.500 --> 01:14:19.820]   Remember, we used to have to think about how much your long distance bill would be.
[01:14:19.820 --> 01:14:21.020]   There's no long distance bill.
[01:14:21.020 --> 01:14:23.060]   How about that?
[01:14:23.060 --> 01:14:30.980]   Let's not forget, gigabit internet, 1000 megabits per second, only $40 a month, $40 a
[01:14:30.980 --> 01:14:32.220]   month.
[01:14:32.220 --> 01:14:38.580]   And incidentally, Sonic stands up for privacy, friendly local customer support, never caps
[01:14:38.580 --> 01:14:44.900]   the bandwidth, has affordable pricing and believes in net neutrality will never, ever,
[01:14:44.900 --> 01:14:48.260]   ever block any bit of the internet.
[01:14:48.260 --> 01:14:49.980]   It's your internet.
[01:14:49.980 --> 01:14:52.380]   Get it from somebody who cares.
[01:14:52.380 --> 01:14:55.700]   Even the internet revolution, visit sonic.com/twit.
[01:14:55.700 --> 01:14:59.700]   Receive your first month of sonic internet and phone service free plus bundle with dish
[01:14:59.700 --> 01:15:01.900]   and save $120 on your sonic bill.
[01:15:01.900 --> 01:15:03.580]   Visit sonic.com/twit.
[01:15:03.580 --> 01:15:06.420]   That's one way you could fight for net neutrality.
[01:15:06.420 --> 01:15:10.340]   If you're lucky enough to have a choice in internet service provider, if only I could.
[01:15:10.340 --> 01:15:11.340]   Choose wisely.
[01:15:11.340 --> 01:15:12.340]   Love to have them.
[01:15:12.340 --> 01:15:13.340]   I know.
[01:15:13.340 --> 01:15:14.340]   Yeah.
[01:15:14.340 --> 01:15:16.340]   Every time I talk today and I ask them for to come to Austin.
[01:15:16.340 --> 01:15:18.220]   Please come to Austin.
[01:15:18.220 --> 01:15:21.700]   Did Google ever get near you, anywhere near you with the Google fiber?
[01:15:21.700 --> 01:15:22.700]   They did.
[01:15:22.700 --> 01:15:23.700]   They went south.
[01:15:23.700 --> 01:15:25.940]   They had a lot of problems with their contractors.
[01:15:25.940 --> 01:15:30.020]   And now they've kind of given up, haven't they?
[01:15:30.020 --> 01:15:31.020]   They have definitely pulled back.
[01:15:31.020 --> 01:15:34.980]   I think they're going to do some 5G stuff with a millimeter wave and microwave.
[01:15:34.980 --> 01:15:35.980]   That may be the last hope.
[01:15:35.980 --> 01:15:38.820]   This is a wireless internet, maybe the last hope.
[01:15:38.820 --> 01:15:40.140]   I just filed.
[01:15:40.140 --> 01:15:42.860]   So I have a new column coming out in IEEE.
[01:15:42.860 --> 01:15:45.660]   I'm writing a column for them on the internet.
[01:15:45.660 --> 01:15:46.660]   That's geeky.
[01:15:46.660 --> 01:15:47.660]   Wow.
[01:15:47.660 --> 01:15:48.660]   It is.
[01:15:48.660 --> 01:15:49.660]   It's a holy cow.
[01:15:49.660 --> 01:15:51.580]   I'm impressed.
[01:15:51.580 --> 01:16:00.260]   So yeah, so 5G is supposed to be in millimeter wave, specifically the fixed wireless access
[01:16:00.260 --> 01:16:06.740]   to homes could be competitive, but it's not going to help our rural problems.
[01:16:06.740 --> 01:16:10.140]   And you can learn more about that all the way in March because this is a print magazine
[01:16:10.140 --> 01:16:11.140]   and I don't even understand.
[01:16:11.140 --> 01:16:12.140]   I'm sorry.
[01:16:12.140 --> 01:16:13.140]   What is this coming out?
[01:16:13.140 --> 01:16:16.620]   Did you ever write for print?
[01:16:16.620 --> 01:16:21.900]   I did some for fortune and then I had a print.
[01:16:21.900 --> 01:16:23.420]   Back in your newspaper deals.
[01:16:23.420 --> 01:16:24.420]   Yeah.
[01:16:24.420 --> 01:16:25.660]   Yeah, I worked for a weekly for a little while.
[01:16:25.660 --> 01:16:27.140]   I worked for a daily.
[01:16:27.140 --> 01:16:29.380]   I started a magazine that was print.
[01:16:29.380 --> 01:16:30.380]   Really?
[01:16:30.380 --> 01:16:31.380]   What was that?
[01:16:31.380 --> 01:16:32.380]   It was my college magazine.
[01:16:32.380 --> 01:16:34.060]   It still exists now on the web.
[01:16:34.060 --> 01:16:35.060]   This is heavy.
[01:16:35.060 --> 01:16:36.060]   This is it.
[01:16:36.060 --> 01:16:37.060]   It really is.
[01:16:37.060 --> 01:16:38.060]   It's a milk.
[01:16:38.060 --> 01:16:39.060]   Wow.
[01:16:39.060 --> 01:16:40.060]   That's big.
[01:16:40.060 --> 01:16:43.260]   It's bigger than I thought and it's heavy.
[01:16:43.260 --> 01:16:44.820]   Red boxes aren't that big.
[01:16:44.820 --> 01:16:48.300]   And it comes to, yes, about the size of a large bread box.
[01:16:48.300 --> 01:16:50.660]   When it comes, it's now available for $3.99.
[01:16:50.660 --> 01:16:52.540]   I ordered it the day it became available.
[01:16:52.540 --> 01:16:55.980]   It got it two days later.
[01:16:55.980 --> 01:17:00.100]   Heavy's good when it comes to sound because it means you have a big old transformer in
[01:17:00.100 --> 01:17:01.100]   there.
[01:17:01.100 --> 01:17:02.100]   Oh, God.
[01:17:02.100 --> 01:17:03.100]   Boom.
[01:17:03.100 --> 01:17:05.100]   Oh, clock.
[01:17:05.100 --> 01:17:09.340]   Well, you know, for people listening at home, it's the only way of illustrating the
[01:17:09.340 --> 01:17:11.940]   actual weight of this thing.
[01:17:11.940 --> 01:17:16.500]   You know, it's kind of frustrating.
[01:17:16.500 --> 01:17:19.660]   They put a tear tab on one side, but not on the other.
[01:17:19.660 --> 01:17:20.660]   Oh, wait a minute.
[01:17:20.660 --> 01:17:21.660]   Yes, it did.
[01:17:21.660 --> 01:17:22.660]   There it is.
[01:17:22.660 --> 01:17:23.660]   All right.
[01:17:23.660 --> 01:17:24.660]   Now.
[01:17:24.660 --> 01:17:25.660]   There it is.
[01:17:25.660 --> 01:17:28.900]   It's a fabric covered speaker.
[01:17:28.900 --> 01:17:31.740]   It's the largest Google home they make.
[01:17:31.740 --> 01:17:32.900]   This is pretty good.
[01:17:32.900 --> 01:17:34.100]   It's bigger than I thought.
[01:17:34.100 --> 01:17:39.060]   I was thinking that they were kind of hiding the size of it by not showing it in pictures
[01:17:39.060 --> 01:17:40.940]   with humans.
[01:17:40.940 --> 01:17:50.380]   But now that I now that I a human have it in my hands, it comes with a rubber coaster
[01:17:50.380 --> 01:17:53.820]   to sit on that isn't attached to it in any way.
[01:17:53.820 --> 01:17:57.300]   Oh, I guess it is kind of magnetic.
[01:17:57.300 --> 01:17:58.300]   Why?
[01:17:58.300 --> 01:17:59.300]   Yeah, I don't know.
[01:17:59.300 --> 01:18:01.500]   It's not to to so you don't scratch your furniture.
[01:18:01.500 --> 01:18:02.500]   Yeah.
[01:18:02.500 --> 01:18:03.900]   And also for isolation.
[01:18:03.900 --> 01:18:04.900]   Yeah.
[01:18:04.900 --> 01:18:10.420]   Attach base here for vertical orientation.
[01:18:10.420 --> 01:18:12.900]   That's why you could put it on either side.
[01:18:12.900 --> 01:18:17.900]   So it could be it could be horizontal or vertical.
[01:18:17.900 --> 01:18:21.260]   Here's the plug, John, if you want to plug it in.
[01:18:21.260 --> 01:18:23.460]   Give it to the USBC.
[01:18:23.460 --> 01:18:24.460]   Nope.
[01:18:24.460 --> 01:18:25.460]   Oh, she's.
[01:18:25.460 --> 01:18:27.220]   But it's a standard power cord.
[01:18:27.220 --> 01:18:31.100]   It's got it needs more power than USBC can offer.
[01:18:31.100 --> 01:18:34.500]   Ah, yeah.
[01:18:34.500 --> 01:18:37.580]   It's got on top of it.
[01:18:37.580 --> 01:18:38.580]   It's got.
[01:18:38.580 --> 01:18:41.020]   Am I supposed to tear this off?
[01:18:41.020 --> 01:18:42.020]   Yeah.
[01:18:42.020 --> 01:18:43.020]   Oh, wow.
[01:18:43.020 --> 01:18:44.020]   You just voided the wear of me.
[01:18:44.020 --> 01:18:49.740]   I don't know if I should have turned it off because it's a sticker that shows where you
[01:18:49.740 --> 01:18:51.700]   raise the volume and touch and play.
[01:18:51.700 --> 01:18:54.100]   But it's not problem with the Google mini.
[01:18:54.100 --> 01:18:55.540]   There's no on the plastic.
[01:18:55.540 --> 01:18:56.780]   It doesn't have anything at all.
[01:18:56.780 --> 01:18:58.180]   You just have to remember.
[01:18:58.180 --> 01:19:01.060]   Yeah, that was I feel like that's not the best.
[01:19:01.060 --> 01:19:03.620]   Designed decision by Google.
[01:19:03.620 --> 01:19:04.620]   It's pretty.
[01:19:04.620 --> 01:19:05.620]   All right.
[01:19:05.620 --> 01:19:06.620]   So I've just plugged it in.
[01:19:06.620 --> 01:19:09.860]   You can see on the front through the fabric, there's some lights going.
[01:19:09.860 --> 01:19:12.980]   It's like a Google mini only on steroids, right?
[01:19:12.980 --> 01:19:15.580]   So now I have to watch the Google Home app.
[01:19:15.580 --> 01:19:18.820]   Let's get my phone out here.
[01:19:18.820 --> 01:19:20.820]   Wow.
[01:19:20.820 --> 01:19:26.580]   That's a rich sound coming up.
[01:19:26.580 --> 01:19:27.580]   Is it?
[01:19:27.580 --> 01:19:28.580]   Yeah.
[01:19:28.580 --> 01:19:35.180]   I think it's definitely a good sound.
[01:19:35.180 --> 01:19:36.980]   It's my phone.
[01:19:36.980 --> 01:19:39.980]   If the Google lady didn't sound good, I'd be very concerned.
[01:19:39.980 --> 01:19:40.980]   Yeah.
[01:19:40.980 --> 01:19:41.980]   Yeah, really.
[01:19:41.980 --> 01:19:42.980]   Good guys.
[01:19:42.980 --> 01:19:43.980]   Come on.
[01:19:43.980 --> 01:19:44.980]   Come on.
[01:19:44.980 --> 01:19:45.980]   Get the Google lady sounding good.
[01:19:45.980 --> 01:19:46.980]   All right.
[01:19:46.980 --> 01:19:48.620]   Now I got to do the Google Home app.
[01:19:48.620 --> 01:19:51.540]   Let's see how it figures out.
[01:19:51.540 --> 01:19:52.540]   Get started.
[01:19:52.540 --> 01:19:53.540]   Okay.
[01:19:53.540 --> 01:19:54.540]   Welcome home.
[01:19:54.540 --> 01:19:55.540]   That's the account.
[01:19:55.540 --> 01:19:56.540]   Okay.
[01:19:56.540 --> 01:19:57.540]   Location access.
[01:19:57.540 --> 01:19:58.540]   Yes.
[01:19:58.540 --> 01:20:00.220]   I guess I've never used this on this phone.
[01:20:00.220 --> 01:20:02.460]   This is the new Pixel 2 XL.
[01:20:02.460 --> 01:20:03.460]   One device found.
[01:20:03.460 --> 01:20:04.460]   Look at that.
[01:20:04.460 --> 01:20:05.540]   I don't know how it knows.
[01:20:05.540 --> 01:20:06.540]   One device found.
[01:20:06.540 --> 01:20:11.740]   It sees my Google Home already ready for setup because it couldn't possibly be on our
[01:20:11.740 --> 01:20:12.740]   WiFi.
[01:20:12.740 --> 01:20:15.420]   It must be either Bluetooth L.E. or sometimes it's the noise.
[01:20:15.420 --> 01:20:16.420]   It's making a noise, right?
[01:20:16.420 --> 01:20:17.860]   Would you like to set that up?
[01:20:17.860 --> 01:20:18.860]   Yes.
[01:20:18.860 --> 01:20:20.660]   Let's see how I can show you this.
[01:20:20.660 --> 01:20:23.100]   You can see it.
[01:20:23.100 --> 01:20:24.900]   Your phone may disconnect from WiFi during.
[01:20:24.900 --> 01:20:25.900]   Oh, sorry.
[01:20:25.900 --> 01:20:26.900]   You moved it.
[01:20:26.900 --> 01:20:27.900]   Go back to that other shot.
[01:20:27.900 --> 01:20:29.340]   There you go.
[01:20:29.340 --> 01:20:33.540]   Your phone may disconnect from WiFi during setup.
[01:20:33.540 --> 01:20:36.060]   Little bouncing, interesting, bouncing.
[01:20:36.060 --> 01:20:37.220]   Connected.
[01:20:37.220 --> 01:20:38.940]   Do you hear the sound?
[01:20:38.940 --> 01:20:39.940]   Yes.
[01:20:39.940 --> 01:20:41.620]   Okay.
[01:20:41.620 --> 01:20:45.340]   Where is this device?
[01:20:45.340 --> 01:20:46.820]   Add custom room.
[01:20:46.820 --> 01:20:48.220]   It's in the shed.
[01:20:48.220 --> 01:20:49.220]   Okay.
[01:20:49.220 --> 01:20:51.460]   We're going to add it to that WiFi.
[01:20:51.460 --> 01:20:53.860]   It's going to get my Google Home.
[01:20:53.860 --> 01:20:56.780]   Gets my WiFi password from the phone.
[01:20:56.780 --> 01:20:57.780]   So that's good.
[01:20:57.780 --> 01:20:59.980]   A little microphone in front of it so we can hear it.
[01:20:59.980 --> 01:21:02.420]   Yeah, that's a good idea.
[01:21:02.420 --> 01:21:05.860]   I kind of like how this looks.
[01:21:05.860 --> 01:21:07.940]   It is the size of a Sonos roughly, isn't it, John?
[01:21:07.940 --> 01:21:09.500]   Would you say it's about play five sized?
[01:21:09.500 --> 01:21:10.500]   Yeah.
[01:21:10.500 --> 01:21:11.500]   A little smaller.
[01:21:11.500 --> 01:21:14.140]   So that's a bright light behind the fabric.
[01:21:14.140 --> 01:21:17.420]   Yeah, that's telling you that it's alive.
[01:21:17.420 --> 01:21:18.420]   It's alive.
[01:21:18.420 --> 01:21:19.420]   Yeah.
[01:21:19.420 --> 01:21:20.420]   It's alive.
[01:21:20.420 --> 01:21:21.420]   This is you just see.
[01:21:21.420 --> 01:21:23.900]   I slid it off its rubber coaster though.
[01:21:23.900 --> 01:21:26.060]   Let's get that back on it.
[01:21:26.060 --> 01:21:27.060]   There we go.
[01:21:27.060 --> 01:21:28.060]   I'll probably help with this.
[01:21:28.060 --> 01:21:31.060]   Get personal results with voice match.
[01:21:31.060 --> 01:21:32.580]   That's the one where it knows who you are.
[01:21:32.580 --> 01:21:34.780]   My assistant can always recognize my voice.
[01:21:34.780 --> 01:21:37.420]   Yes, that's true.
[01:21:37.420 --> 01:21:38.780]   So I don't need to retrain it.
[01:21:38.780 --> 01:21:39.780]   It knows.
[01:21:39.780 --> 01:21:43.780]   Continue voice match complete.
[01:21:43.780 --> 01:21:44.780]   Choose your assistant's voice.
[01:21:44.780 --> 01:21:46.060]   Now I get a choice.
[01:21:46.060 --> 01:21:47.620]   This is new, right?
[01:21:47.620 --> 01:21:50.620]   We only had one voice in the past, right?
[01:21:50.620 --> 01:21:51.620]   Play sample.
[01:21:51.620 --> 01:21:53.300]   Hi, I'm your Google assistant.
[01:21:53.300 --> 01:21:55.180]   Here to help you throughout your day.
[01:21:55.180 --> 01:21:58.620]   This one, here's two.
[01:21:58.620 --> 01:22:00.380]   Hi, I'm your Google assistant.
[01:22:00.380 --> 01:22:01.980]   Here to help you throughout your day.
[01:22:01.980 --> 01:22:05.100]   Stacey, are you happy we can have a boy?
[01:22:05.100 --> 01:22:06.420]   He sounds a little robotic.
[01:22:06.420 --> 01:22:08.380]   Here to help you throughout your day.
[01:22:08.380 --> 01:22:09.380]   Yeah, a little.
[01:22:09.380 --> 01:22:10.380]   Oh, nevermind.
[01:22:10.380 --> 01:22:11.380]   That one.
[01:22:11.380 --> 01:22:12.380]   You're Sean Connery.
[01:22:12.380 --> 01:22:13.380]   I'm your Google assistant.
[01:22:13.380 --> 01:22:14.380]   Here to help you throughout your day.
[01:22:14.380 --> 01:22:15.380]   Well, let's just do it for a change of pace.
[01:22:15.380 --> 01:22:16.380]   Let's just use voice too.
[01:22:16.380 --> 01:22:17.380]   Okay.
[01:22:17.380 --> 01:22:19.420]   I got my address.
[01:22:19.420 --> 01:22:21.860]   Add music services.
[01:22:21.860 --> 01:22:23.660]   Google Play music.
[01:22:23.660 --> 01:22:24.980]   YouTube music.
[01:22:24.980 --> 01:22:26.820]   That's good.
[01:22:26.820 --> 01:22:27.820]   Next.
[01:22:27.820 --> 01:22:28.820]   Almost done.
[01:22:28.820 --> 01:22:29.820]   Add a payment method.
[01:22:29.820 --> 01:22:30.820]   No.
[01:22:30.820 --> 01:22:31.820]   Thank you.
[01:22:31.820 --> 01:22:32.820]   No, no.
[01:22:32.820 --> 01:22:36.140]   Actually, you should already have one.
[01:22:36.140 --> 01:22:40.980]   It's now going to download an update, unfortunately, which is going to say about four minutes.
[01:22:40.980 --> 01:22:43.260]   This is a Sonos Play 5.
[01:22:43.260 --> 01:22:48.100]   So it's a little shorter would be the only thing.
[01:22:48.100 --> 01:22:51.860]   But that's big enough to be good sound, I think.
[01:22:51.860 --> 01:22:53.460]   So that's what you're looking for.
[01:22:53.460 --> 01:22:58.020]   And really, this is the idea is this is a speaker that can do all the Google assistant
[01:22:58.020 --> 01:23:01.660]   stuff, but sound good, right?
[01:23:01.660 --> 01:23:05.300]   So I'm actually, I think that might.
[01:23:05.300 --> 01:23:06.300]   Ooh.
[01:23:06.300 --> 01:23:07.300]   Wow.
[01:23:07.300 --> 01:23:09.820]   Look at that.
[01:23:09.820 --> 01:23:10.860]   It's got multicolored lights.
[01:23:10.860 --> 01:23:11.860]   I like that.
[01:23:11.860 --> 01:23:14.660]   Google, my ear pods and my ears are vibrating.
[01:23:14.660 --> 01:23:15.660]   Really?
[01:23:15.660 --> 01:23:16.660]   Was that much bass?
[01:23:16.660 --> 01:23:17.660]   All right.
[01:23:17.660 --> 01:23:19.420]   Well, it's going to take a little while to set up.
[01:23:19.420 --> 01:23:22.980]   While we're doing that, I'll show you something else new.
[01:23:22.980 --> 01:23:26.100]   Are you a Project Fi subscriber?
[01:23:26.100 --> 01:23:29.580]   Jeff, did you do this last year, the Project Fi game?
[01:23:29.580 --> 01:23:33.180]   The guy, the skier with your mask.
[01:23:33.180 --> 01:23:36.220]   No, I don't do that stuff.
[01:23:36.220 --> 01:23:37.220]   You don't do Facebook.
[01:23:37.220 --> 01:23:39.020]   I don't do that crap.
[01:23:39.020 --> 01:23:40.020]   But this is good for you.
[01:23:40.020 --> 01:23:41.900]   Oh, I hit the tree.
[01:23:41.900 --> 01:23:43.220]   I pulled a sunny.
[01:23:43.220 --> 01:23:44.220]   Silence.
[01:23:44.220 --> 01:23:45.940]   Let me let me let me.
[01:23:45.940 --> 01:23:49.380]   No, he says no, that's not funny.
[01:23:49.380 --> 01:23:50.380]   Sunny.
[01:23:50.380 --> 01:23:53.980]   Now, I'm going to win a prize if I can get all the way down.
[01:23:53.980 --> 01:23:54.780]   Wonder what the prize is.
[01:23:54.780 --> 01:23:56.700]   Is it something good?
[01:23:56.700 --> 01:24:01.180]   Oh, oh, oh, oh.
[01:24:01.180 --> 01:24:02.180]   What happened?
[01:24:02.180 --> 01:24:03.180]   Oh, come on.
[01:24:03.180 --> 01:24:05.140]   I shouldn't have clicked the mouse.
[01:24:05.140 --> 01:24:06.140]   Whoa.
[01:24:06.140 --> 01:24:07.660]   Am I supposed to go through the gates?
[01:24:07.660 --> 01:24:08.660]   Oh, I am.
[01:24:08.660 --> 01:24:10.740]   Oh, I missed the gate.
[01:24:10.740 --> 01:24:12.340]   Whoa, whoa.
[01:24:12.340 --> 01:24:15.900]   I'm not a very good skier, as you can see.
[01:24:15.900 --> 01:24:18.140]   The snowboarder knocked me over.
[01:24:18.140 --> 01:24:19.140]   Oh.
[01:24:19.140 --> 01:24:20.900]   You want to be aware?
[01:24:20.900 --> 01:24:23.700]   Don't look at my free Wi-Fi code.
[01:24:23.700 --> 01:24:27.540]   Oh, well, I guess I'll never be able to use that again.
[01:24:27.540 --> 01:24:31.900]   Go go enabled flights free and flight Wi-Fi.
[01:24:31.900 --> 01:24:34.020]   Good for one use until March 31.
[01:24:34.020 --> 01:24:37.820]   I'll tell you what, anybody wants to use that?
[01:24:37.820 --> 01:24:40.100]   Yeah, be my guest.
[01:24:40.100 --> 01:24:42.260]   I think I've run across Koga once.
[01:24:42.260 --> 01:24:43.260]   Yeah.
[01:24:43.260 --> 01:24:44.260]   So that's cool.
[01:24:44.260 --> 01:24:46.580]   So you can get an hour of-- is it an hour?
[01:24:46.580 --> 01:24:49.820]   It's a whole flight of free Gogo Wi-Fi.
[01:24:49.820 --> 01:24:51.140]   Oh, my speaker.
[01:24:51.140 --> 01:24:53.380]   The shed speaker is ready.
[01:24:53.380 --> 01:24:54.380]   Continue.
[01:24:54.380 --> 01:24:55.380]   Hi.
[01:24:55.380 --> 01:24:56.380]   I'm your Google Assistant.
[01:24:56.380 --> 01:24:57.540]   I'm here to help.
[01:24:57.540 --> 01:25:00.500]   To learn a few things you can do, continue in the Google Home
[01:25:00.500 --> 01:25:01.500]   app.
[01:25:01.500 --> 01:25:03.500]   Doesn't that sound good?
[01:25:03.500 --> 01:25:04.860]   Mm-hmm.
[01:25:04.860 --> 01:25:05.700]   Place a music--
[01:25:05.700 --> 01:25:06.700]   Place a music.
[01:25:06.700 --> 01:25:07.700]   Yeah.
[01:25:07.700 --> 01:25:08.860]   Hey, Google.
[01:25:08.860 --> 01:25:11.860]   Place a music.
[01:25:11.860 --> 01:25:12.300]   All right.
[01:25:12.300 --> 01:25:14.180]   Music on Google Play Music.
[01:25:14.180 --> 01:25:15.180]   Here you go.
[01:25:15.180 --> 01:25:16.500]   He's a little crunchy, isn't he?
[01:25:16.500 --> 01:25:17.500]   Wow.
[01:25:17.500 --> 01:25:32.060]   I'm going to take my headphones out so I can hear this.
[01:25:32.060 --> 01:25:36.060]   It really thinks I like the metal.
[01:25:36.060 --> 01:25:37.060]   Wow.
[01:25:37.060 --> 01:25:39.060]   See if you would--
[01:25:39.060 --> 01:25:40.060]   Hey, Google.
[01:25:40.060 --> 01:25:42.260]   You wouldn't make a bad decision.
[01:25:42.260 --> 01:25:43.260]   Hey, Google.
[01:25:43.260 --> 01:25:44.260]   OK.
[01:25:44.260 --> 01:25:46.260]   OK.
[01:25:46.260 --> 01:25:48.660]   Hey, hey, Google.
[01:25:48.660 --> 01:25:49.660]   Say OK.
[01:25:49.660 --> 01:25:52.900]   Oh, I said-- oh, stop.
[01:25:52.900 --> 01:25:53.900]   OK.
[01:25:53.900 --> 01:25:54.900]   Wow.
[01:25:54.900 --> 01:25:58.140]   Hey, Google.
[01:25:58.140 --> 01:26:01.340]   Place some Frank Sinatra.
[01:26:01.340 --> 01:26:04.940]   Playing Frank Sinatra on Google Play Music.
[01:26:04.940 --> 01:26:08.140]   Oh, that sounds pretty good.
[01:26:08.140 --> 01:26:09.140]   Yeah.
[01:26:09.140 --> 01:26:11.580]   You know, it's not very rich and deep.
[01:26:11.580 --> 01:26:12.580]   Hey, Google, stop.
[01:26:12.580 --> 01:26:14.940]   Tell it to play--
[01:26:14.940 --> 01:26:16.460]   Lord, play Beyonce.
[01:26:16.460 --> 01:26:18.140]   Hey, Google.
[01:26:18.140 --> 01:26:21.660]   Play Beyonce.
[01:26:21.660 --> 01:26:23.420]   Playing Beyonce on Google Play music.
[01:26:23.420 --> 01:26:24.740]   That's got some nice bass in it, right?
[01:26:24.740 --> 01:26:26.220]   That should sound good.
[01:26:26.220 --> 01:26:28.220]   Da-da-da-da-da.
[01:26:28.220 --> 01:26:29.860]   So crazy right now.
[01:26:29.860 --> 01:26:31.820]   Yeah.
[01:26:31.820 --> 01:26:33.620]   Hey, Google.
[01:26:33.620 --> 01:26:37.420]   Volume up.
[01:26:37.420 --> 01:26:39.100]   Hey, Google.
[01:26:39.100 --> 01:26:40.060]   Volume 11.
[01:26:41.060 --> 01:26:44.060]   It doesn't that stop it and break it?
[01:26:44.060 --> 01:26:45.060]   It did.
[01:26:45.060 --> 01:26:46.060]   It broke it.
[01:26:46.060 --> 01:26:48.060]   I didn't know it would do that.
[01:26:48.060 --> 01:26:51.060]   Someone was reporting that it couldn't play too badly.
[01:26:51.060 --> 01:26:53.060]   Yeah, it just turned it right off.
[01:26:53.060 --> 01:26:55.060]   Hey, Google.
[01:26:55.060 --> 01:26:57.060]   Volume 8.
[01:26:57.060 --> 01:26:59.060]   [MUSIC PLAYING]
[01:26:59.060 --> 01:27:00.060]   That's not bad.
[01:27:00.060 --> 01:27:01.060]   It's got a kind of big high end.
[01:27:01.060 --> 01:27:02.060]   Yeah, it's kind of like the high end.
[01:27:02.060 --> 01:27:03.060]   Yeah, it's kind of like the high end.
[01:27:03.060 --> 01:27:04.060]   Yeah, it's kind of like the high end.
[01:27:04.060 --> 01:27:05.060]   It's kind of like the high end.
[01:27:05.060 --> 01:27:06.060]   Yeah, it's kind of like the high end.
[01:27:06.060 --> 01:27:11.060]   It's kind of like the high end.
[01:27:11.060 --> 01:27:15.060]   That's not bad.
[01:27:15.060 --> 01:27:18.060]   Bass is a little bit better once we get it that loud.
[01:27:18.060 --> 01:27:20.060]   It's actually sounds-- what do you think of the high end, guys?
[01:27:20.060 --> 01:27:22.060]   Do you think it was kind of tinnin'?
[01:27:22.060 --> 01:27:23.060]   Yeah, it's all right.
[01:27:23.060 --> 01:27:24.060]   They're going, eh, it's all right.
[01:27:24.060 --> 01:27:25.060]   Not bad.
[01:27:25.060 --> 01:27:28.060]   My trained listeners.
[01:27:28.060 --> 01:27:30.060]   So it's a little pricey, right?
[01:27:30.060 --> 01:27:31.060]   $3.99.
[01:27:31.060 --> 01:27:33.060]   What is a comparable Zodos speaker across?
[01:27:33.060 --> 01:27:34.060]   $4.99.
[01:27:34.060 --> 01:27:35.060]   Right?
[01:27:35.060 --> 01:27:36.060]   No.
[01:27:36.060 --> 01:27:39.060]   Yeah, so it's less than that.
[01:27:39.060 --> 01:27:44.060]   What I don't know what it does is the multi-room playing play.
[01:27:44.060 --> 01:27:46.060]   I think it's supposed to do that, right?
[01:27:46.060 --> 01:27:49.060]   But that's the thing that's Sonos' secret sauce.
[01:27:49.060 --> 01:27:50.060]   Anyway, I'm glad I got it.
[01:27:50.060 --> 01:27:52.060]   I think that that's actually-- that's a good thing.
[01:27:52.060 --> 01:27:55.060]   You put that in the-- where you listen to music in the bedroom
[01:27:55.060 --> 01:27:56.060]   or the living room or whatever.
[01:27:56.060 --> 01:27:57.060]   That's pretty good.
[01:27:57.060 --> 01:27:59.060]   Now, oh, that's another thing it doesn't do.
[01:27:59.060 --> 01:28:01.060]   The Sonos will let you buy two and pair them
[01:28:01.060 --> 01:28:02.060]   and stereo, left, right, stereo.
[01:28:02.060 --> 01:28:04.060]   I don't think Google's mentioned that capability.
[01:28:04.060 --> 01:28:07.060]   All right, one more thing to cheer you up.
[01:28:07.060 --> 01:28:10.060]   And then we'll get back to hard news.
[01:28:10.060 --> 01:28:13.060]   The Year in Search.
[01:28:13.060 --> 01:28:16.060]   This is going to-- OK, get your hankeys out.
[01:28:16.060 --> 01:28:18.060]   Do you have my audio?
[01:28:18.060 --> 01:28:19.060]   All right.
[01:28:19.060 --> 01:28:21.060]   The Year in Search.
[01:28:21.060 --> 01:28:22.060]   Get your hankeys out.
[01:28:22.060 --> 01:28:25.060]   This year, more than ever.
[01:28:25.060 --> 01:28:26.060]   We asked...
[01:28:26.060 --> 01:28:31.060]   How do wildfire start?
[01:28:31.060 --> 01:28:32.060]   Oh, dear.
[01:28:32.060 --> 01:28:35.060]   How far can North Korean missiles go?
[01:28:35.060 --> 01:28:37.060]   How much will the wall cost?
[01:28:37.060 --> 01:28:39.060]   How many refugees in the world?
[01:28:39.060 --> 01:28:41.060]   How do hurricanes form?
[01:28:41.060 --> 01:28:43.060]   This is not cheerful at all.
[01:28:43.060 --> 01:28:46.060]   How to board up a window?
[01:28:46.060 --> 01:28:50.060]   How to calm a dog during a storm?
[01:28:50.060 --> 01:28:51.060]   How to help flood victims?
[01:28:51.060 --> 01:28:53.060]   How to help refugees?
[01:28:53.060 --> 01:28:55.060]   How to help Puerto Rico?
[01:28:55.060 --> 01:28:57.060]   How to help Mexico?
[01:28:57.060 --> 01:28:59.060]   How to help Las Vegas?
[01:28:59.060 --> 01:29:01.060]   Oh, good lord.
[01:29:01.060 --> 01:29:04.060]   Renfield Tower, Rohingya, Syria, Houston.
[01:29:04.060 --> 01:29:06.060]   How to make a protest sign.
[01:29:06.060 --> 01:29:07.060]   We're going through.
[01:29:07.060 --> 01:29:08.060]   We still have to push forward.
[01:29:08.060 --> 01:29:11.060]   Are you ready to shake up the world?
[01:29:11.060 --> 01:29:13.060]   Oh, my God.
[01:29:13.060 --> 01:29:14.060]   There's the woman's march.
[01:29:14.060 --> 01:29:16.060]   How to run for office?
[01:29:16.060 --> 01:29:19.060]   I'm thinking Google then?
[01:29:19.060 --> 01:29:21.060]   Oh, we.
[01:29:21.060 --> 01:29:23.060]   Back crawl.
[01:29:23.060 --> 01:29:25.060]   How to watch the eclipse.
[01:29:25.060 --> 01:29:26.060]   Yeah, we did Google that.
[01:29:26.060 --> 01:29:28.060]   Not like the president did.
[01:29:28.060 --> 01:29:30.060]   We're glasses.
[01:29:30.060 --> 01:29:31.060]   Maybe glasses.
[01:29:31.060 --> 01:29:32.060]   No, she's looking right at it.
[01:29:32.060 --> 01:29:34.060]   How to make a difference?
[01:29:34.060 --> 01:29:35.060]   Big check.
[01:29:35.060 --> 01:29:37.060]   Take a knee.
[01:29:37.060 --> 01:29:39.060]   How to be a strong woman.
[01:29:39.060 --> 01:29:40.060]   Ellen.
[01:29:40.060 --> 01:29:41.060]   Me too.
[01:29:41.060 --> 01:29:42.060]   Me too.
[01:29:42.060 --> 01:29:43.060]   Me too.
[01:29:43.060 --> 01:29:44.060]   Me too.
[01:29:44.060 --> 01:29:45.060]   Wow.
[01:29:45.060 --> 01:29:46.060]   How to be a good parent.
[01:29:46.060 --> 01:29:47.060]   Remember.
[01:29:47.060 --> 01:29:50.060]   How to be a superhero.
[01:29:50.060 --> 01:29:51.060]   Al-Kadot.
[01:29:51.060 --> 01:29:53.060]   Firefighters.
[01:29:53.060 --> 01:29:55.060]   Oh, shaking hands.
[01:29:55.060 --> 01:29:57.060]   How to be fearless.
[01:29:57.060 --> 01:29:59.060]   Ha ha ha ha ha ha.
[01:29:59.060 --> 01:30:01.060]   The BBC presenter.
[01:30:01.060 --> 01:30:03.060]   Composing.
[01:30:03.060 --> 01:30:04.060]   Playing music.
[01:30:04.060 --> 01:30:05.060]   Running in the lid.
[01:30:05.060 --> 01:30:06.060]   Marathon.
[01:30:06.060 --> 01:30:09.060]   Winning an award.
[01:30:09.060 --> 01:30:10.060]   Flying a dragon.
[01:30:10.060 --> 01:30:12.060]   Dancing in Stranger Things.
[01:30:12.060 --> 01:30:13.060]   Head Explodings.
[01:30:13.060 --> 01:30:14.060]   Protest marches.
[01:30:14.060 --> 01:30:17.060]   How to move forward.
[01:30:17.060 --> 01:30:19.060]   Search on.
[01:30:19.060 --> 01:30:20.060]   That's kind of politicized.
[01:30:20.060 --> 01:30:22.060]   What do you think?
[01:30:22.060 --> 01:30:24.060]   We're living in politicized time.
[01:30:24.060 --> 01:30:26.060]   I mean, I don't know if it's politicized.
[01:30:26.060 --> 01:30:31.180]   Some of them are, but if they're actually popular searches, a lot of people did say, "Hey, how
[01:30:31.180 --> 01:30:32.540]   do I run for office?"
[01:30:32.540 --> 01:30:33.540]   Even I've Googled that.
[01:30:33.540 --> 01:30:34.540]   So.
[01:30:34.540 --> 01:30:35.540]   Good for you.
[01:30:35.540 --> 01:30:36.540]   Are you going to run?
[01:30:36.540 --> 01:30:37.540]   Not now.
[01:30:37.540 --> 01:30:38.540]   No.
[01:30:38.540 --> 01:30:39.540]   That would be a terrible opportunity.
[01:30:39.540 --> 01:30:40.540]   Do you run for office?
[01:30:40.540 --> 01:30:42.020]   Either of you?
[01:30:42.020 --> 01:30:43.020]   No.
[01:30:43.020 --> 01:30:48.060]   I ran for like student council president.
[01:30:48.060 --> 01:30:50.580]   That's the closest I got.
[01:30:50.580 --> 01:30:52.060]   And I think it was in sixth grade.
[01:30:52.060 --> 01:30:55.140]   It wasn't even in high school.
[01:30:55.140 --> 01:30:58.460]   That's the look back at 2017 top search trends.
[01:30:58.460 --> 01:31:01.740]   Yeah, it kind of does bring home some.
[01:31:01.740 --> 01:31:06.020]   The Google Home Max does allow pairing two units for stereosis, Fedway and our chatroom.
[01:31:06.020 --> 01:31:07.020]   Thank you, Fedway.
[01:31:07.020 --> 01:31:12.020]   I'm glad to know.
[01:31:12.020 --> 01:31:19.340]   Oh, the onion.
[01:31:19.340 --> 01:31:20.340]   What did the onions say?
[01:31:20.340 --> 01:31:21.540]   Are you looking at onion headlines?
[01:31:21.540 --> 01:31:23.540]   That's a good way to cheer up.
[01:31:23.540 --> 01:31:26.940]   Going net neutrality will help spur innovation and announce his face of agitpie blaring from
[01:31:26.940 --> 01:31:30.140]   every computer screen in nation.
[01:31:30.140 --> 01:31:36.460]   Oh, Leo, last week, did you ever get the earbuds?
[01:31:36.460 --> 01:31:37.460]   I did.
[01:31:37.460 --> 01:31:38.980]   Did you talk about them last week?
[01:31:38.980 --> 01:31:39.980]   Yeah.
[01:31:39.980 --> 01:31:40.980]   What do you think?
[01:31:40.980 --> 01:31:41.980]   Are you wearing them now?
[01:31:41.980 --> 01:31:44.260]   Oh, I canceled the order.
[01:31:44.260 --> 01:31:45.260]   You should have.
[01:31:45.260 --> 01:31:46.260]   Right.
[01:31:46.260 --> 01:31:47.260]   At least.
[01:31:47.260 --> 01:31:48.260]   Right.
[01:31:48.260 --> 01:31:49.260]   That's what I was asking.
[01:31:49.260 --> 01:31:50.260]   Good.
[01:31:50.260 --> 01:31:51.260]   Good.
[01:31:51.260 --> 01:31:53.400]   The thing that they really sold them on, the translate thing, actually in hindsight, I
[01:31:53.400 --> 01:31:59.980]   feel like I drank the Kool-Aid at that event because truthfully, it doesn't work as well
[01:31:59.980 --> 01:32:01.140]   as just doing it with the phone.
[01:32:01.140 --> 01:32:05.300]   The problem being that you hear the translation, but the speaker doesn't hear the translation,
[01:32:05.300 --> 01:32:08.660]   so can't identify errors in the translation.
[01:32:08.660 --> 01:32:11.780]   When you do it with the phone, it works exactly the same way just as well.
[01:32:11.780 --> 01:32:17.600]   The only difference is that when the guy's talking to you, the translation is heard by
[01:32:17.600 --> 01:32:20.180]   both parties instead of just in your ears.
[01:32:20.180 --> 01:32:22.260]   It still requires a phone if you're using the earbuds.
[01:32:22.260 --> 01:32:23.720]   There's really no advantage to it.
[01:32:23.720 --> 01:32:25.960]   It's not some special magic that the earbuds do.
[01:32:25.960 --> 01:32:26.960]   The Pixel Buds do.
[01:32:26.960 --> 01:32:27.960]   Right.
[01:32:27.960 --> 01:32:28.960]   Got it.
[01:32:28.960 --> 01:32:30.440]   The Pixel Buds are hard to pair.
[01:32:30.440 --> 01:32:34.160]   They're hard to wrap up.
[01:32:34.160 --> 01:32:37.200]   The sound is good, but not the best sound ever.
[01:32:37.200 --> 01:32:42.920]   For that price, I was able to buy at $149, the Jabra Sport Elite, which sound 10 times
[01:32:42.920 --> 01:32:45.680]   better and have many more functions, including heart rate monitor.
[01:32:45.680 --> 01:32:49.600]   It is, I'll tell you the one nice thing about the Pixel Buds that I really, really did like
[01:32:49.600 --> 01:32:52.900]   and I would like to see more of is I was able to hear the...
[01:32:52.900 --> 01:32:56.340]   If you wear them around, you could still hear ambient noise because they don't seal
[01:32:56.340 --> 01:32:58.340]   the ear.
[01:32:58.340 --> 01:33:01.020]   Any notifications that come to your phone, you can hear.
[01:33:01.020 --> 01:33:03.720]   If a text comes in and says, "You just got a text from Lisa.
[01:33:03.720 --> 01:33:05.020]   Would you like me to read it?"
[01:33:05.020 --> 01:33:08.180]   You could say, "Yes," just without it hands-free.
[01:33:08.180 --> 01:33:09.260]   It reads it to you.
[01:33:09.260 --> 01:33:11.220]   Would you like to respond, "Yes."
[01:33:11.220 --> 01:33:12.220]   What would you like me to say?
[01:33:12.220 --> 01:33:15.700]   You could do all that hands-free with the earbuds in.
[01:33:15.700 --> 01:33:20.900]   I think that's a nice feature, being able to hear notifications and respond to some notifications.
[01:33:20.900 --> 01:33:21.900]   So those are...
[01:33:21.900 --> 01:33:23.460]   We'll be on the box, but we'll rip out.
[01:33:23.460 --> 01:33:24.800]   Ooh, another unboxing.
[01:33:24.800 --> 01:33:25.800]   Ooh.
[01:33:25.800 --> 01:33:26.800]   Ooh.
[01:33:26.800 --> 01:33:31.460]   We'll have a more complete review of the Google Home Max Saturday on the new screen savers.
[01:33:31.460 --> 01:33:34.380]   I won't spend some more time with it.
[01:33:34.380 --> 01:33:37.020]   The other thing that Google did this week is some...
[01:33:37.020 --> 01:33:40.700]   Is three app sparaments.
[01:33:40.700 --> 01:33:44.300]   Are you familiar with the app sparaments?
[01:33:44.300 --> 01:33:45.300]   I'm not...
[01:33:45.300 --> 01:33:47.100]   I'm going to ignore that word even in this.
[01:33:47.100 --> 01:33:48.300]   Yeah, exactly.
[01:33:48.300 --> 01:33:49.300]   I'm like...
[01:33:49.300 --> 01:33:52.700]   They released some experimental apps, did they?
[01:33:52.700 --> 01:33:53.700]   Yes.
[01:33:53.700 --> 01:33:54.700]   App sparaments.
[01:33:54.700 --> 01:33:55.700]   Nope.
[01:33:55.700 --> 01:33:56.700]   Nope.
[01:33:56.700 --> 01:33:57.700]   Can I hear you?
[01:33:57.700 --> 01:34:02.700]   No, no, no, no, no, not listening.
[01:34:02.700 --> 01:34:03.700]   I agree.
[01:34:03.700 --> 01:34:04.700]   They want the...
[01:34:04.700 --> 01:34:05.700]   Ask the...
[01:34:05.700 --> 01:34:06.700]   Ask the...
[01:34:06.700 --> 01:34:08.500]   ...louges who make app sparaments.
[01:34:08.500 --> 01:34:12.780]   Exploring, introducing app sparaments, exploring the potential of mobile photography.
[01:34:12.780 --> 01:34:16.980]   They're all three of them kind of dopey, but they're kind of interesting.
[01:34:16.980 --> 01:34:19.980]   So, storyboard is only on Android.
[01:34:19.980 --> 01:34:23.220]   And I'll show you how it works a little bit because I have all three of them.
[01:34:23.220 --> 01:34:26.060]   Two of them are available...
[01:34:26.060 --> 01:34:28.820]   Two of them...
[01:34:28.820 --> 01:34:29.740]   Let's see.
[01:34:29.740 --> 01:34:34.580]   Two of them you can get on both phones, then there's one unique one for each phone.
[01:34:34.580 --> 01:34:36.220]   The storyboard is unique to Android.
[01:34:36.220 --> 01:34:46.540]   And what it does is it takes any video in your phone and turn it into a comic book.
[01:34:46.540 --> 01:34:50.740]   And the problem is it doesn't seem to be actually using any artificial intelligence.
[01:34:50.740 --> 01:34:53.780]   And by the way, if you don't like the mix, you can re...
[01:34:53.780 --> 01:34:56.980]   Once you get a video, you can load it, save it, share it, load a different video.
[01:34:56.980 --> 01:34:58.500]   And then swiping up will do a remix...
[01:34:58.500 --> 01:35:00.740]   Or swiping down rather, it'll do a remix.
[01:35:00.740 --> 01:35:02.180]   But for some reason, it doesn't...
[01:35:02.180 --> 01:35:04.380]   It's like, for instance, that's the same picture.
[01:35:04.380 --> 01:35:05.660]   That guy's cut half.
[01:35:05.660 --> 01:35:08.100]   There's no people in that one or that one.
[01:35:08.100 --> 01:35:11.300]   It's like, at least Google, you have face recognition.
[01:35:11.300 --> 01:35:16.060]   You could attempt to center on a face.
[01:35:16.060 --> 01:35:17.060]   What's this panel?
[01:35:17.060 --> 01:35:20.700]   It's got half of somebody's hair.
[01:35:20.700 --> 01:35:22.660]   And that's exactly the same twice over.
[01:35:22.660 --> 01:35:25.100]   This I did this at a staff meeting.
[01:35:25.100 --> 01:35:27.460]   And of course, people had fun with it.
[01:35:27.460 --> 01:35:32.100]   It's cool, but there's no reason for this panel.
[01:35:32.100 --> 01:35:36.220]   It seems like Google's not actually applying any of its artificial intelligence to the
[01:35:36.220 --> 01:35:37.700]   generation of these.
[01:35:37.700 --> 01:35:40.180]   It is cool that you can just generate these panels.
[01:35:40.180 --> 01:35:43.380]   But what I found is you have to swipe through it a bunch of times so you find one that works.
[01:35:43.380 --> 01:35:47.540]   Like that one almost works except for that empty one.
[01:35:47.540 --> 01:35:52.500]   So you just keep swiping to get one that I tweeted a few that kind of worked.
[01:35:52.500 --> 01:35:55.660]   If you find one you like and then accidentally sweep away, you can't go back.
[01:35:55.660 --> 01:35:58.420]   So that's it.
[01:35:58.420 --> 01:35:59.700]   So sweep slowly.
[01:35:59.700 --> 01:36:02.580]   And then sweep slowly make sure.
[01:36:02.580 --> 01:36:05.060]   Maybe they're anti-conditioning us for Tinder.
[01:36:05.060 --> 01:36:08.220]   Like what's that?
[01:36:08.220 --> 01:36:09.780]   Why would you make a frame out of that?
[01:36:09.780 --> 01:36:12.140]   It looks, I don't know what that is.
[01:36:12.140 --> 01:36:14.420]   Is it just too big?
[01:36:14.420 --> 01:36:16.420]   You have to shrink the image?
[01:36:16.420 --> 01:36:19.220]   No, that's the concept book.
[01:36:19.220 --> 01:36:23.740]   So sometimes it does cool things like slip split into two panes.
[01:36:23.740 --> 01:36:24.740]   That's cool.
[01:36:24.740 --> 01:36:26.540]   Like I would save that.
[01:36:26.540 --> 01:36:31.340]   But so it just doesn't, it seems like Google could have done, frankly could have done better
[01:36:31.340 --> 01:36:33.500]   with this app's spherumet.
[01:36:33.500 --> 01:36:35.940]   This is a failed, what is it like, what?
[01:36:35.940 --> 01:36:36.940]   That's his shoulder.
[01:36:36.940 --> 01:36:38.940]   That's the back of a chair.
[01:36:38.940 --> 01:36:43.780]   I don't know what I'm saying why you would, well you would, because it's going through
[01:36:43.780 --> 01:36:48.780]   like a 20 second video and picking frames and then cartoonizing them and putting them
[01:36:48.780 --> 01:36:51.100]   in panels like a comic book.
[01:36:51.100 --> 01:36:55.180]   And there are, it does seem like it likes smiles.
[01:36:55.180 --> 01:36:58.940]   Like it keeps picking this picture of Megan, it really likes Megan I think.
[01:36:58.940 --> 01:37:02.140]   I don't understand it.
[01:37:02.140 --> 01:37:04.740]   Anyway, so that's one.
[01:37:04.740 --> 01:37:07.300]   I'll show you some of the iPhone ones here.
[01:37:07.300 --> 01:37:08.700]   Get my iPhone out.
[01:37:08.700 --> 01:37:10.420]   Actually I don't have my iPhone so I can't.
[01:37:10.420 --> 01:37:12.940]   Would you get me my iPhone?
[01:37:12.940 --> 01:37:14.500]   So that's storyboard.
[01:37:14.500 --> 01:37:19.900]   There's selfissimo which really has no reason for its existence.
[01:37:19.900 --> 01:37:25.620]   Fotobooth is a selfie generator that basically just keeps taking pictures and puts them in
[01:37:25.620 --> 01:37:28.420]   kind of like you were at a photo booth.
[01:37:28.420 --> 01:37:31.380]   Kind of that one's iOS and Android.
[01:37:31.380 --> 01:37:32.940]   They're black and white.
[01:37:32.940 --> 01:37:35.380]   Snaps a photo each time you pose.
[01:37:35.380 --> 01:37:37.700]   Okay that is super cute.
[01:37:37.700 --> 01:37:39.780]   I would do that a thousand times with me.
[01:37:39.780 --> 01:37:42.020]   Okay, well it's like a photo booth, right?
[01:37:42.020 --> 01:37:47.900]   Yeah, I mean like think about how popular photo, photo stars for like kids parties.
[01:37:47.900 --> 01:37:51.380]   So here I'll do selfissimo.
[01:37:51.380 --> 01:37:54.220]   So can you show over my shoulder?
[01:37:54.220 --> 01:38:06.780]   Okay, so it says start and then it just.
[01:38:06.780 --> 01:38:09.820]   Do you stop it or does it just go until you stop it?
[01:38:09.820 --> 01:38:11.420]   It goes until you stop it.
[01:38:11.420 --> 01:38:15.940]   And now I have nine somewhat injuries.
[01:38:15.940 --> 01:38:19.980]   I guarantee you if I showed that to my daughter she would be all over that.
[01:38:19.980 --> 01:38:22.980]   It's like photo booth kind of on the Mac.
[01:38:22.980 --> 01:38:25.500]   Only it's not distorting and it's black and white which is great.
[01:38:25.500 --> 01:38:30.940]   So they kind of look like literally like a photo booth.
[01:38:30.940 --> 01:38:31.940]   You know?
[01:38:31.940 --> 01:38:32.940]   Yeah, that's fun.
[01:38:32.940 --> 01:38:33.940]   It's kind of fun.
[01:38:33.940 --> 01:38:34.940]   And it's awesome.
[01:38:34.940 --> 01:38:40.020]   Yeah, I mean these are all free and even Google kind of you know their experiments or
[01:38:40.020 --> 01:38:43.020]   as we might call them app experiments.
[01:38:43.020 --> 01:38:47.660]   We would not call them that.
[01:38:47.660 --> 01:38:50.700]   And finally scrubbies.
[01:38:50.700 --> 01:38:56.900]   The idea of scrubbies is so you've played with boomerang, Instagram's boomerang, which
[01:38:56.900 --> 01:39:00.820]   allows you to take a clip and loop it forever, right?
[01:39:00.820 --> 01:39:04.660]   So I'm going to capture something here.
[01:39:04.660 --> 01:39:11.260]   John, come closer and do a little dance.
[01:39:11.260 --> 01:39:14.940]   Okay, that's a, that's, couldn't have been better.
[01:39:14.940 --> 01:39:19.500]   So, so here's John's one finger to preview.
[01:39:19.500 --> 01:39:20.500]   Okay.
[01:39:20.500 --> 01:39:24.420]   So that's his dance and you have, I guess you have two fingers to make a scrubby.
[01:39:24.420 --> 01:39:32.100]   Okay, so let's make a scrubby so I can choose which portions of John's dance I'd like to
[01:39:32.100 --> 01:39:36.700]   make into the scrubby and I've created it now.
[01:39:36.700 --> 01:39:38.980]   And that's the scrubby.
[01:39:38.980 --> 01:39:41.700]   So it moves it into slow mo and then loops it.
[01:39:41.700 --> 01:39:43.420]   I don't know about the slow mo part.
[01:39:43.420 --> 01:39:46.100]   I think that's not necessarily something.
[01:39:46.100 --> 01:39:49.420]   I don't know.
[01:39:49.420 --> 01:39:50.660]   It's an app.
[01:39:50.660 --> 01:39:51.660]   Experiment.
[01:39:51.660 --> 01:39:52.660]   Get it?
[01:39:52.660 --> 01:39:53.660]   Yeah, again.
[01:39:53.660 --> 01:39:57.620]   Stop trying to make a experiment happen.
[01:39:57.620 --> 01:40:01.220]   Leo, I'm just teasing you.
[01:40:01.220 --> 01:40:02.460]   I know.
[01:40:02.460 --> 01:40:03.460]   Okay.
[01:40:03.460 --> 01:40:06.820]   Did you get the, yes, stickers?
[01:40:06.820 --> 01:40:08.620]   I didn't, I can't.
[01:40:08.620 --> 01:40:09.620]   I'll show you.
[01:40:09.620 --> 01:40:12.100]   Oh, this is the best thing.
[01:40:12.100 --> 01:40:13.620]   Where do you see this, Stacy?
[01:40:13.620 --> 01:40:15.700]   You have an, I don't know if it's pixel two only.
[01:40:15.700 --> 01:40:17.700]   I bet it is.
[01:40:17.700 --> 01:40:18.700]   Pixel.
[01:40:18.700 --> 01:40:19.860]   I have a pixel.
[01:40:19.860 --> 01:40:24.620]   So you go into your camera and you pick AR stickers.
[01:40:24.620 --> 01:40:28.780]   If you have the latest camera app, you'll have AR stickers in the hamburger menu, the
[01:40:28.780 --> 01:40:31.580]   menu and then you'll have that.
[01:40:31.580 --> 01:40:33.780]   Oh, Jeff update, update.
[01:40:33.780 --> 01:40:35.420]   So then you have a variety.
[01:40:35.420 --> 01:40:37.860]   So like there's Star Wars.
[01:40:37.860 --> 01:40:38.860]   Oh, these things.
[01:40:38.860 --> 01:40:39.860]   Oh, they're great.
[01:40:39.860 --> 01:40:42.700]   Yeah, but look, here's what I made with my daughter's name.
[01:40:42.700 --> 01:40:43.820]   Okay, watch this.
[01:40:43.820 --> 01:40:48.780]   I just have, so this is my daughter's name in those, those inflatable balloons, just floating.
[01:40:48.780 --> 01:40:51.340]   It looks like that you can move them around.
[01:40:51.340 --> 01:40:53.780]   It looks just like it's, it's like it's really floating.
[01:40:53.780 --> 01:40:56.020]   It's augmented reality.
[01:40:56.020 --> 01:40:57.380]   I'll show you some other ones.
[01:40:57.380 --> 01:40:59.420]   I'll show you some more because I did like, I do.
[01:40:59.420 --> 01:41:04.380]   I remember the Demi Gorgon from the, yeah, let me, let me go to my photos booth and I'll
[01:41:04.380 --> 01:41:08.520]   show you photos.google.com because they get saved out.
[01:41:08.520 --> 01:41:10.100]   It makes movies out of them.
[01:41:10.100 --> 01:41:11.500]   So here's the, here's the app.
[01:41:11.500 --> 01:41:13.620]   Actually, this is a better example.
[01:41:13.620 --> 01:41:16.980]   So you can see how it, how it is.
[01:41:16.980 --> 01:41:23.260]   And then here's a, this is a, what is that a, they call it a Walker, right?
[01:41:23.260 --> 01:41:26.220]   It's taken a lot of load because these are all videos.
[01:41:26.220 --> 01:41:27.220]   I don't know.
[01:41:27.220 --> 01:41:29.740]   It's, and it's got audio to Carsta.
[01:41:29.740 --> 01:41:33.660]   Why is it taking so long to load?
[01:41:33.660 --> 01:41:34.660]   Maybe this is loaded.
[01:41:34.660 --> 01:41:38.300]   It doesn't, let's try some other ones.
[01:41:38.300 --> 01:41:39.300]   Here's a, a Porg.
[01:41:39.300 --> 01:41:41.300]   Is that what you call it?
[01:41:41.300 --> 01:41:42.940]   And a BB-8.
[01:41:42.940 --> 01:41:48.020]   This, we did this during Windows weekly, but they're not.
[01:41:48.020 --> 01:41:49.020]   Come on.
[01:41:49.020 --> 01:41:51.020]   What's going on?
[01:41:51.020 --> 01:41:54.460]   Google's not loading the videos.
[01:41:54.460 --> 01:41:58.660]   Anyway, stickers.
[01:41:58.660 --> 01:42:07.060]   I imagine, I mean, there'll be the opportunity to enhance it with other movie tie-ins, but
[01:42:07.060 --> 01:42:12.060]   right now it's Star Wars because that's the, that's coming out tomorrow.
[01:42:12.060 --> 01:42:13.060]   What else?
[01:42:13.060 --> 01:42:16.060]   You have a birth letter so you can write any message and have it float in balloons.
[01:42:16.060 --> 01:42:19.660]   You have, it's kind of like emojis.
[01:42:19.660 --> 01:42:24.980]   In fact, this is probably, I would guess Google's response.
[01:42:24.980 --> 01:42:26.780]   So shall I make one?
[01:42:26.780 --> 01:42:31.020]   So when I do, so I, this one, I don't know if you could show this over my shoulder.
[01:42:31.020 --> 01:42:34.260]   Here, let me, let me point, you can't.
[01:42:34.260 --> 01:42:35.260]   So, okay, you pull out.
[01:42:35.260 --> 01:42:36.260]   Yeah, there you go.
[01:42:36.260 --> 01:42:42.580]   So you have to point somewhere like a desk and then the target bot shipped.
[01:42:42.580 --> 01:42:43.580]   Hold on a second.
[01:42:43.580 --> 01:42:44.580]   Hold on.
[01:42:44.580 --> 01:42:45.580]   You're trying to do news.
[01:42:45.580 --> 01:42:47.580]   I'm trying to do a, so they see that little guy.
[01:42:47.580 --> 01:42:48.580]   I'm just like, wow.
[01:42:48.580 --> 01:42:49.580]   See that little guy?
[01:42:49.580 --> 01:42:50.900]   Now he's, now he's there.
[01:42:50.900 --> 01:42:53.500]   Oh, this is a stranger things kid.
[01:42:53.500 --> 01:42:55.380]   Isn't it?
[01:42:55.380 --> 01:42:58.700]   So I'm going to rotate or you can rotate around him.
[01:42:58.700 --> 01:43:00.100]   I don't know if you can poke him.
[01:43:00.100 --> 01:43:02.260]   No, you can't poke him.
[01:43:02.260 --> 01:43:03.260]   But that's the stranger.
[01:43:03.260 --> 01:43:06.780]   So I record a little video with a stranger things kid on there.
[01:43:06.780 --> 01:43:09.220]   That's kind of cool.
[01:43:09.220 --> 01:43:10.220]   I don't know.
[01:43:10.220 --> 01:43:11.860]   It's kind of cool.
[01:43:11.860 --> 01:43:13.140]   He's standing on my computer.
[01:43:13.140 --> 01:43:15.020]   It's a lot of AI going on.
[01:43:15.020 --> 01:43:18.940]   Yeah, I mean, that's, well, it's, I think it's Google saying, oh yeah, Apple, you know
[01:43:18.940 --> 01:43:23.380]   that iPhone thing that you did, we could do that with one lens.
[01:43:23.380 --> 01:43:24.380]   We could do that.
[01:43:24.380 --> 01:43:26.980]   How do I update the app?
[01:43:26.980 --> 01:43:29.260]   I don't know why you didn't get it.
[01:43:29.260 --> 01:43:31.260]   You're on a Pixel 2 XL, right?
[01:43:31.260 --> 01:43:32.260]   Yeah.
[01:43:32.260 --> 01:43:34.460]   What, what are you?
[01:43:34.460 --> 01:43:35.460]   Eight one or?
[01:43:35.460 --> 01:43:36.460]   Yeah, I still ate.
[01:43:36.460 --> 01:43:38.460]   Oh, I went for a one.
[01:43:38.460 --> 01:43:40.540]   Do your update, dude.
[01:43:40.540 --> 01:43:41.860]   It says I'm up to date.
[01:43:41.860 --> 01:43:42.860]   You're not.
[01:43:42.860 --> 01:43:45.540]   You know what I did?
[01:43:45.540 --> 01:43:46.540]   You know what I did?
[01:43:46.540 --> 01:43:47.540]   Because I was impatient.
[01:43:47.540 --> 01:43:50.500]   I turned beta on Android beta on.
[01:43:50.500 --> 01:43:52.500]   Oh, got a one.
[01:43:52.500 --> 01:43:54.140]   And then it said, now it's the shipped for it.
[01:43:54.140 --> 01:43:56.060]   And now you're getting the shipping version of eight one.
[01:43:56.060 --> 01:43:58.220]   I said, okay, and I'll turn it off.
[01:43:58.220 --> 01:43:59.300]   So that's what you need to do.
[01:43:59.300 --> 01:44:01.500]   So I guess maybe that maybe that's the case.
[01:44:01.500 --> 01:44:05.020]   Maybe you need to Android 8.1 to do that.
[01:44:05.020 --> 01:44:07.220]   So ship it.
[01:44:07.220 --> 01:44:10.180]   So I also, I don't know.
[01:44:10.180 --> 01:44:11.620]   I can't remember when I did this.
[01:44:11.620 --> 01:44:13.660]   I did a crowd funding.
[01:44:13.660 --> 01:44:14.860]   What is that?
[01:44:14.860 --> 01:44:18.300]   So anchor is Zolo Liberty Plus.
[01:44:18.300 --> 01:44:20.420]   Oh, those are like the Pixel Buds.
[01:44:20.420 --> 01:44:21.420]   Yeah.
[01:44:21.420 --> 01:44:22.420]   99 bucks.
[01:44:22.420 --> 01:44:23.420]   Nice.
[01:44:23.420 --> 01:44:26.300]   So the one that cost me, I think it's 149 now.
[01:44:26.300 --> 01:44:30.500]   And those look a lot like those Jabra sports elites I was talking about.
[01:44:30.500 --> 01:44:31.500]   They look very.
[01:44:31.500 --> 01:44:32.500]   So here's the here's the little thing.
[01:44:32.500 --> 01:44:34.500]   The problem is nothing ever fits in my ear.
[01:44:34.500 --> 01:44:35.500]   Did they give you?
[01:44:35.500 --> 01:44:36.740]   They didn't give you a variety of.
[01:44:36.740 --> 01:44:37.740]   They do.
[01:44:37.740 --> 01:44:38.740]   They do have that.
[01:44:38.740 --> 01:44:39.740]   Then here's a heavy.
[01:44:39.740 --> 01:44:40.740]   And that's the case.
[01:44:40.740 --> 01:44:44.780]   So you got a Jeff, you got a really that's one of the things I found with the Jabra's
[01:44:44.780 --> 01:44:48.060]   is you have to really try all the knobs, little nubbies until you get it.
[01:44:48.060 --> 01:44:49.060]   Do that.
[01:44:49.060 --> 01:44:50.060]   Good for all that.
[01:44:50.060 --> 01:44:51.060]   Yeah, you want to go.
[01:44:51.060 --> 01:44:52.060]   So these are my.
[01:44:52.060 --> 01:44:53.060]   I use the smallest.
[01:44:53.060 --> 01:44:54.060]   I use the biggest.
[01:44:54.060 --> 01:44:55.060]   I'm the biggest.
[01:44:55.060 --> 01:44:56.940]   I have big ear holes.
[01:44:56.940 --> 01:45:00.100]   Oh, more than we want to know, right?
[01:45:00.100 --> 01:45:02.700]   There's a minor Harry to just don't tell them.
[01:45:02.700 --> 01:45:04.740]   Don't don't tell anybody.
[01:45:04.740 --> 01:45:05.740]   Oh, yes.
[01:45:05.740 --> 01:45:07.580]   Let's let's talk about something.
[01:45:07.580 --> 01:45:09.300]   It's an experiment.
[01:45:09.300 --> 01:45:11.140]   They're not.
[01:45:11.140 --> 01:45:13.140]   Sazy is what you know.
[01:45:13.140 --> 01:45:14.700]   Just like to clarify.
[01:45:14.700 --> 01:45:16.020]   I don't.
[01:45:16.020 --> 01:45:21.420]   So, um, Google.org donated $260 million to nonprofits.
[01:45:21.420 --> 01:45:24.580]   And is that one of your numbers, Jeff, in 2017?
[01:45:24.580 --> 01:45:26.500]   I didn't know that.
[01:45:26.500 --> 01:45:29.340]   So they put their mouth where their video was.
[01:45:29.340 --> 01:45:32.380]   Doesn't really sound right, does it?
[01:45:32.380 --> 01:45:34.380]   They put their money where their video was.
[01:45:34.380 --> 01:45:38.020]   That's what I should have said.
[01:45:38.020 --> 01:45:43.540]   Education, economic opportunity, inclusion, disaster relief, crisis response.
[01:45:43.540 --> 01:45:48.340]   They gave $20 million towards efforts in Puerto Rico, the Caribbean, Florida, Houston,
[01:45:48.340 --> 01:45:50.780]   and South Asia.
[01:45:50.780 --> 01:45:55.180]   They project Loon, of course, remember that they restored connectivity to a Puerto Rico
[01:45:55.180 --> 01:45:57.300]   with parts of Puerto Rico through Project Loon.
[01:45:57.300 --> 01:45:58.300]   That was a volunteer.
[01:45:58.300 --> 01:45:59.300]   I don't know.
[01:45:59.300 --> 01:46:02.940]   I'm going to be there next week.
[01:46:02.940 --> 01:46:03.940]   I'll let you know.
[01:46:03.940 --> 01:46:07.140]   It works if you have, I believe, an AT&T phone was what it was.
[01:46:07.140 --> 01:46:08.140]   Yeah, it was with AT&T.
[01:46:08.140 --> 01:46:09.140]   That's right.
[01:46:09.140 --> 01:46:11.900]   Um, that's pretty cool.
[01:46:11.900 --> 01:46:15.980]   I actually got a press release from Puerto Rico saying we're open for business.
[01:46:15.980 --> 01:46:17.220]   So you're going?
[01:46:17.220 --> 01:46:19.620]   Uh, yeah, I'm going in a week.
[01:46:19.620 --> 01:46:24.220]   From tomorrow, I'll be in San Juan for, for Christmas.
[01:46:24.220 --> 01:46:25.220]   Yeah.
[01:46:25.220 --> 01:46:28.980]   Well, my son and I, uh, have chartered a catamaran.
[01:46:28.980 --> 01:46:29.980]   Well, that's right.
[01:46:29.980 --> 01:46:30.980]   You mentioned that.
[01:46:30.980 --> 01:46:31.980]   Yeah.
[01:46:31.980 --> 01:46:36.300]   And, uh, we're going to sail it around the British Virgin Islands, visiting all the exciting
[01:46:36.300 --> 01:46:39.540]   hurricane spots.
[01:46:39.540 --> 01:46:43.580]   Senator Pichai said $500,000 for the Southern California fires.
[01:46:43.580 --> 01:46:45.020]   Anyway, nice job.
[01:46:45.020 --> 01:46:46.020]   Thank you, Google.
[01:46:46.020 --> 01:46:49.180]   Of course, every company at Google size should be donating.
[01:46:49.180 --> 01:46:51.180]   At least that much.
[01:46:51.180 --> 01:46:52.460]   At least.
[01:46:52.460 --> 01:46:53.900]   I think we should bring back tithing.
[01:46:53.900 --> 01:46:57.420]   What's 10% of Google's profits more than that?
[01:46:57.420 --> 01:46:58.420]   More than that.
[01:46:58.420 --> 01:47:01.620]   If you're not going to pay taxes, you might as well donate your money.
[01:47:01.620 --> 01:47:02.620]   Exactly.
[01:47:02.620 --> 01:47:07.880]   Well, Facebook just announced that they're going to start booking their advertising revenue
[01:47:07.880 --> 01:47:11.620]   locally in the country and not sending it all to, um, Oh, Bravo.
[01:47:11.620 --> 01:47:12.620]   Ireland.
[01:47:12.620 --> 01:47:13.620]   That's big deal.
[01:47:13.620 --> 01:47:14.620]   I wonder how they're sure.
[01:47:14.620 --> 01:47:17.460]   How they feel about that?
[01:47:17.460 --> 01:47:19.000]   Good question.
[01:47:19.000 --> 01:47:22.380]   It doesn't matter because the shareholders have no power given the class structure.
[01:47:22.380 --> 01:47:23.540]   Yeah.
[01:47:23.540 --> 01:47:27.980]   I did see that the new tax bill, and I don't know if this is the reconciled tax bill that
[01:47:27.980 --> 01:47:34.660]   they just announced or the, uh, the Senate version, but with the 20%, I guess now 21%
[01:47:34.660 --> 01:47:39.700]   corporate tax rate, Apple will save $49 billion in taxes.
[01:47:39.700 --> 01:47:43.860]   So God knows they need the money.
[01:47:43.860 --> 01:47:48.780]   Um, Google maps will wake you up when you need to get out of the bus.
[01:47:48.780 --> 01:47:49.780]   I thought that was good.
[01:47:49.780 --> 01:47:50.780]   Yeah.
[01:47:50.780 --> 01:47:51.780]   Like that.
[01:47:51.780 --> 01:47:52.780]   That's cool.
[01:47:52.780 --> 01:47:53.780]   That's coming.
[01:47:53.780 --> 01:47:54.780]   But Leo, they're going to know where you are.
[01:47:54.780 --> 01:47:55.920]   Uh, no, see, there's a good example.
[01:47:55.920 --> 01:47:56.920]   You're right.
[01:47:56.920 --> 01:47:59.000]   That's a table of data being beneficial.
[01:47:59.000 --> 01:48:03.680]   That's why I'm hesitant to throw Google in there.
[01:48:03.680 --> 01:48:07.920]   Well Facebook could have woke you up too.
[01:48:07.920 --> 01:48:10.080]   But do they Twitter, Twitter won't even bother.
[01:48:10.080 --> 01:48:11.400]   Twitter will just say sleep.
[01:48:11.400 --> 01:48:13.400]   You should walk Facebook, but see that's a perfect example.
[01:48:13.400 --> 01:48:17.960]   So Google uses location information and interesting and I think useful ways to the user.
[01:48:17.960 --> 01:48:27.320]   The only thing I ever get from Facebook is hey, I see you're somewhere.
[01:48:27.320 --> 01:48:29.900]   Would you want to check in?
[01:48:29.900 --> 01:48:37.160]   Uh, let's take a little break and, uh, well, unless you have other things you want, because
[01:48:37.160 --> 01:48:40.400]   I think it's time to get to our picks and nine numbers and all of that stuff.
[01:48:40.400 --> 01:48:41.400]   Tweaks.
[01:48:41.400 --> 01:48:43.200]   Oh, storeify.
[01:48:43.200 --> 01:48:45.080]   I know you were upset about that, Jeff.
[01:48:45.080 --> 01:48:46.080]   Just, just too bad.
[01:48:46.080 --> 01:48:48.880]   Why did, why did a dobe?
[01:48:48.880 --> 01:48:50.400]   Adobe buy it.
[01:48:50.400 --> 01:48:51.880]   They buy it to kill it.
[01:48:51.880 --> 01:48:52.880]   Yeah.
[01:48:52.880 --> 01:48:54.600]   Storifies us saying get your stories.
[01:48:54.600 --> 01:48:59.840]   No, I remember Dan Patterson used it to great effect to cover occupy.
[01:48:59.840 --> 01:49:01.680]   Yeah.
[01:49:01.680 --> 01:49:02.840]   So what was storeify?
[01:49:02.840 --> 01:49:09.760]   Storeify was just the way to put tweets together in a way, any, any collection of tweets you
[01:49:09.760 --> 01:49:14.840]   wanted together so that you could reserve them and share them as a collection.
[01:49:14.840 --> 01:49:18.200]   You can no longer talk about Twitter's new functionality.
[01:49:18.200 --> 01:49:19.200]   Yeah.
[01:49:19.200 --> 01:49:21.440]   Twitter may have kind of scooped them a little bit.
[01:49:21.440 --> 01:49:28.200]   Storify says, uh, no new users and we will end existing users access on May 16th.
[01:49:28.200 --> 01:49:31.720]   Download your stories if you want to say them, but it doesn't seem that they've offered
[01:49:31.720 --> 01:49:33.680]   an API or any simple way to do it.
[01:49:33.680 --> 01:49:36.840]   And I'm seeing people complain, I have hundreds of stories on storeify.
[01:49:36.840 --> 01:49:39.040]   There's no easy way to get them all.
[01:49:39.040 --> 01:49:40.040]   That's a, that's a shame.
[01:49:40.040 --> 01:49:45.040]   You know, I'm, I'm willing to hate Adobe just as much as, uh, as any man.
[01:49:45.040 --> 01:49:50.360]   Adobe's not, not, not a great steward, obviously.
[01:49:50.360 --> 01:49:52.680]   So Twitter's going to let you thread tweets now.
[01:49:52.680 --> 01:49:56.880]   You'll be able to do a better tweet storms.
[01:49:56.880 --> 01:49:58.560]   I thought you could always thread tweets.
[01:49:58.560 --> 01:50:01.760]   Well, those are going to make it easier to do that.
[01:50:01.760 --> 01:50:03.160]   Oh, okay.
[01:50:03.160 --> 01:50:08.000]   Nothing fits my ear.
[01:50:08.000 --> 01:50:11.880]   Twitter has banned a baby poop video.
[01:50:11.880 --> 01:50:16.400]   What was the video?
[01:50:16.400 --> 01:50:22.240]   Uh, the malicious app game, it was actually a malicious app.
[01:50:22.240 --> 01:50:27.960]   So this was a video that promised a hysterical response from a dog to a baby pooping in its
[01:50:27.960 --> 01:50:28.960]   diapers.
[01:50:28.960 --> 01:50:32.920]   Uh, was in fact a malicious app that gained access to users.
[01:50:32.920 --> 01:50:35.720]   Twitter feeds spamming links from a viral video website.
[01:50:35.720 --> 01:50:37.800]   It also had the ability to read your timelines and post tweets.
[01:50:37.800 --> 01:50:39.720]   Obviously that's to ask you permission for that.
[01:50:39.720 --> 01:50:44.400]   But the New York Times literary critic, Dwight Garner apparently has an interest in this.
[01:50:44.400 --> 01:50:47.960]   He got bit as well as Brit Hume from Fox.
[01:50:47.960 --> 01:50:54.280]   Anybody clicking on the option to view the video, uh, at the time got an authentication
[01:50:54.280 --> 01:50:55.280]   request.
[01:50:55.280 --> 01:50:56.480]   Now it gets an error.
[01:50:56.480 --> 01:50:58.240]   So Twitter's blocked this.
[01:50:58.240 --> 01:51:02.680]   Be careful when you click something and it says we'd like permission to access your Twitter
[01:51:02.680 --> 01:51:03.680]   account.
[01:51:03.680 --> 01:51:05.360]   Probably be a good idea to say no.
[01:51:05.360 --> 01:51:08.960]   I always say no to those, which means every now and then I miss out on like the hot, the
[01:51:08.960 --> 01:51:09.960]   hot Twitter app.
[01:51:09.960 --> 01:51:10.960]   But I'm just like, yeah.
[01:51:10.960 --> 01:51:15.080]   And you know, you can go into Twitter and check and see what's still authorized to use
[01:51:15.080 --> 01:51:16.080]   your account.
[01:51:16.080 --> 01:51:17.080]   Yes.
[01:51:17.080 --> 01:51:18.080]   In fact, do that.
[01:51:18.080 --> 01:51:21.000]   Every, uh, every new year, go into Facebook, Twitter, Google everywhere.
[01:51:21.000 --> 01:51:22.480]   Look what, uh, apps you've used.
[01:51:22.480 --> 01:51:26.960]   You might be, you may be surprised at the number of defunct apps like storeify that you
[01:51:26.960 --> 01:51:31.400]   have given permission to Amazon.
[01:51:31.400 --> 01:51:32.400]   Every season.
[01:51:32.400 --> 01:51:33.400]   Yeah.
[01:51:33.400 --> 01:51:34.400]   Every season.
[01:51:34.400 --> 01:51:35.400]   Three months.
[01:51:35.400 --> 01:51:38.120]   Change your fire, change your fire.
[01:51:38.120 --> 01:51:41.480]   All the smoke alarm batteries and clean up your apps at the same time.
[01:51:41.480 --> 01:51:42.480]   That's a high gene.
[01:51:42.480 --> 01:51:43.480]   Yes.
[01:51:43.480 --> 01:51:49.000]   There, if you ask your Amazon Echo to talk to Santa Claus, Santa Claus will come.
[01:51:49.000 --> 01:51:51.880]   Ask what kind of Christmas music you're interested in listening to.
[01:51:51.880 --> 01:51:55.840]   Uh, you can ask what it will ask you.
[01:51:55.840 --> 01:51:56.840]   What do you want for Christmas?
[01:51:56.840 --> 01:51:57.840]   Is Santa real?
[01:51:57.840 --> 01:51:58.840]   Where does Santa live?
[01:51:58.840 --> 01:52:00.920]   How old is Santa sing me a Christmas carol?
[01:52:00.920 --> 01:52:03.880]   So there's a, there's also NORAD tracks, Santa.
[01:52:03.880 --> 01:52:07.000]   Which I always used to do with the kids to get them go to bed early.
[01:52:07.000 --> 01:52:13.720]   Now you can just ask Echo when we're Santa now, which I think is great.
[01:52:13.720 --> 01:52:15.600]   There's also a holiday song quiz.
[01:52:15.600 --> 01:52:19.440]   If you, if you can't get enough Christmas music, I suspect Stacy will be using all of
[01:52:19.440 --> 01:52:20.800]   these skills.
[01:52:20.800 --> 01:52:23.800]   I have my Christmas playlist.
[01:52:23.800 --> 01:52:28.760]   If, if, you know, I have my turn on Christmas that my houselets, I would take you on a
[01:52:28.760 --> 01:52:29.760]   tour of my house.
[01:52:29.760 --> 01:52:30.760]   Oh, that's so cool.
[01:52:30.760 --> 01:52:33.560]   You have a command turn on Christmas and it all just happens.
[01:52:33.560 --> 01:52:35.920]   And I did, I did a Vimeo video of it.
[01:52:35.920 --> 01:52:38.720]   So if you really want to, you could find it and see it.
[01:52:38.720 --> 01:52:40.440]   What's your Vimeo account name?
[01:52:40.440 --> 01:52:42.120]   I think it's Higgin' Bob.
[01:52:42.120 --> 01:52:43.120]   Let's see.
[01:52:43.120 --> 01:52:44.120]   Didn't I show you guys this?
[01:52:44.120 --> 01:52:45.120]   No.
[01:52:45.120 --> 01:52:46.120]   No.
[01:52:46.120 --> 01:52:47.120]   Really?
[01:52:47.120 --> 01:52:48.120]   No.
[01:52:48.120 --> 01:52:49.120]   Okay.
[01:52:49.120 --> 01:52:50.120]   Hold on.
[01:52:50.120 --> 01:52:51.120]   Hold on.
[01:52:51.120 --> 01:52:52.120]   This can be turn.
[01:52:52.120 --> 01:52:55.120]   So you find it first.
[01:52:55.120 --> 01:52:56.120]   Uh.
[01:52:56.120 --> 01:52:57.120]   Ah.
[01:52:57.120 --> 01:52:58.120]   Ah.
[01:52:58.120 --> 01:53:03.600]   Oh, what if it's gone?
[01:53:03.600 --> 01:53:04.600]   No.
[01:53:04.600 --> 01:53:06.600]   I can't find Stacy Higgin' Botham on Vimeo.
[01:53:06.600 --> 01:53:08.600]   Oh, I think it's under Higgin' Bob.
[01:53:08.600 --> 01:53:09.600]   Higgin' B-O-B?
[01:53:09.600 --> 01:53:10.600]   Uh huh.
[01:53:10.600 --> 01:53:15.040]   It turns out there's a Steve and a Ben and a Logan Higgin' Botham.
[01:53:15.040 --> 01:53:23.240]   Oh, here we go.
[01:53:23.240 --> 01:53:24.720]   There's a Stacy Higgin' Botham on Vimeo.
[01:53:24.720 --> 01:53:25.720]   Hold on.
[01:53:25.720 --> 01:53:26.720]   Here's, I'm going to shoot you the link.
[01:53:26.720 --> 01:53:27.720]   Let me click it.
[01:53:27.720 --> 01:53:28.720]   Copy.
[01:53:28.720 --> 01:53:29.720]   Pause.
[01:53:29.720 --> 01:53:32.920]   This is too sophisticated for me.
[01:53:32.920 --> 01:53:33.920]   Okay.
[01:53:33.920 --> 01:53:34.920]   Okay, Google.
[01:53:34.920 --> 01:53:35.920]   Okay, Google.
[01:53:35.920 --> 01:53:37.520]   Say hi to Santa.
[01:53:37.520 --> 01:53:38.520]   Sorry.
[01:53:38.520 --> 01:53:41.200]   I can't send messages yet.
[01:53:41.200 --> 01:53:42.200]   Okay.
[01:53:42.200 --> 01:53:43.200]   Google.
[01:53:43.200 --> 01:53:47.160]   When is Santa Claus coming to my house?
[01:53:47.160 --> 01:53:48.160]   My apologies.
[01:53:48.160 --> 01:53:49.800]   I don't understand.
[01:53:49.800 --> 01:53:51.280]   Okay, Google.
[01:53:51.280 --> 01:53:53.120]   Do you hate Christmas?
[01:53:53.120 --> 01:53:54.920]   Sorry.
[01:53:54.920 --> 01:53:55.920]   I don't understand.
[01:53:55.920 --> 01:53:57.920]   I hate you.
[01:53:57.920 --> 01:54:01.240]   All right, I stuck it in my Stacy's thing.
[01:54:01.240 --> 01:54:02.240]   Did you do that?
[01:54:02.240 --> 01:54:05.680]   Did you just do the show me your Hohaz thing?
[01:54:05.680 --> 01:54:06.680]   Did you ever do that?
[01:54:06.680 --> 01:54:07.680]   What?
[01:54:07.680 --> 01:54:13.160]   No, I can't do it because it's not family friendly.
[01:54:13.160 --> 01:54:15.920]   It's not friendly at all.
[01:54:15.920 --> 01:54:17.320]   To anybody.
[01:54:17.320 --> 01:54:18.680]   But my wife showed me this.
[01:54:18.680 --> 01:54:22.680]   She said, "Did you know that you can ask?"
[01:54:22.680 --> 01:54:26.200]   I think it was Google or was it Echo?
[01:54:26.200 --> 01:54:28.400]   I think it was one of them.
[01:54:28.400 --> 01:54:33.680]   Show me your "You Know What" and it does this whole dance.
[01:54:33.680 --> 01:54:37.920]   But then if you say show it a male part of the anatomy, it goes, "I don't know what
[01:54:37.920 --> 01:54:39.920]   you're talking about."
[01:54:39.920 --> 01:54:40.920]   Oofo.
[01:54:40.920 --> 01:54:41.920]   Yeah, let's not.
[01:54:41.920 --> 01:54:43.920]   And it still was there.
[01:54:43.920 --> 01:54:44.920]   Wait.
[01:54:44.920 --> 01:54:45.920]   Okay.
[01:54:45.920 --> 01:54:52.160]   I didn't want to, I didn't cover this story but I just, you know, it came up.
[01:54:52.160 --> 01:54:53.840]   Did it, did it come up?
[01:54:53.840 --> 01:54:54.840]   Came up.
[01:54:54.840 --> 01:54:55.840]   Did you bring it up?
[01:54:55.840 --> 01:54:56.840]   It brought it up.
[01:54:56.840 --> 01:54:57.840]   Came up in my mind.
[01:54:57.840 --> 01:55:00.040]   Higgin' Bob, what is it?
[01:55:00.040 --> 01:55:03.960]   So I found, I put it in there so now you can see it.
[01:55:03.960 --> 01:55:04.960]   If you want.
[01:55:04.960 --> 01:55:10.400]   Yeah, it's in the Stacy's thing because that felt like a logical place to put it.
[01:55:10.400 --> 01:55:12.800]   Oh, there it is.
[01:55:12.800 --> 01:55:14.800]   This is your home.
[01:55:14.800 --> 01:55:17.800]   Well, let's save it for Stacy's thing.
[01:55:17.800 --> 01:55:19.520]   Would you like to use it as Stacy's thing?
[01:55:19.520 --> 01:55:20.520]   Sure.
[01:55:20.520 --> 01:55:21.520]   All right, save it.
[01:55:21.520 --> 01:55:24.360]   I want to see a few stormtroopers invading.
[01:55:24.360 --> 01:55:27.040]   Stormtroopers invading the Higgin' Bob from home.
[01:55:27.040 --> 01:55:29.760]   Oh, with the AR?
[01:55:29.760 --> 01:55:30.760]   Yeah.
[01:55:30.760 --> 01:55:31.760]   Excellent.
[01:55:31.760 --> 01:55:33.760]   I could show you what I did.
[01:55:33.760 --> 01:55:36.240]   Because I did a couple.
[01:55:36.240 --> 01:55:38.600]   I think I did a couple.
[01:55:38.600 --> 01:55:42.080]   Ah, da-da-da-da-da-da-da-da-da-da-da-da.
[01:55:42.080 --> 01:55:45.080]   Here's our BB-8.
[01:55:45.080 --> 01:55:46.640]   BB-8 invading.
[01:55:46.640 --> 01:55:51.360]   You got BB-8 in your life.
[01:55:51.360 --> 01:55:52.720]   That's really looks good.
[01:55:52.720 --> 01:55:54.520]   It's pretty good, isn't it?
[01:55:54.520 --> 01:55:59.200]   What you look at is how well it's matched the table time, which is not perfect.
[01:55:59.200 --> 01:56:01.000]   But it does give it doesn't have tango.
[01:56:01.000 --> 01:56:02.680]   Does it do a shadow?
[01:56:02.680 --> 01:56:03.680]   Yeah.
[01:56:03.680 --> 01:56:11.200]   Given that it doesn't have table-top quality, tango quality sensors, that's not bad.
[01:56:11.200 --> 01:56:12.200]   Not bad at all.
[01:56:12.200 --> 01:56:13.200]   Not bad at all.
[01:56:13.200 --> 01:56:15.400]   I wish I could get the other ones playing.
[01:56:15.400 --> 01:56:17.440]   You got BB-8 in your life.
[01:56:17.440 --> 01:56:19.040]   I can't for some reason.
[01:56:19.040 --> 01:56:21.040]   I don't know why.
[01:56:21.040 --> 01:56:22.040]   Wait a minute.
[01:56:22.040 --> 01:56:23.040]   Here's the one I just recorded.
[01:56:23.040 --> 01:56:24.040]   Let's see if that...
[01:56:24.040 --> 01:56:27.320]   No, seems to be a problem with Google Photos.
[01:56:27.320 --> 01:56:29.160]   Let's take a break.
[01:56:29.160 --> 01:56:34.240]   And the number, the thing, the stuff will all happen momentarily.
[01:56:34.240 --> 01:56:35.640]   But first a word.
[01:56:35.640 --> 01:56:37.600]   Oh, this is your holiday gift.
[01:56:37.600 --> 01:56:42.400]   I'm telling you, I'm going to save you a lot of time for a family member, a friend, a
[01:56:42.400 --> 01:56:46.680]   colleague, the Ring Video Doorbell.
[01:56:46.680 --> 01:56:50.640]   Ring's mission is to make neighborhoods safer, your front porch safer, your home safer.
[01:56:50.640 --> 01:56:52.440]   A million people now.
[01:56:52.440 --> 01:56:56.320]   I feel like we deserve a little credit for this.
[01:56:56.320 --> 01:56:57.480]   Use the Ring Video Doorbell.
[01:56:57.480 --> 01:56:59.320]   I started using it a couple of years ago.
[01:56:59.320 --> 01:57:01.760]   I see it all over my neighborhood now.
[01:57:01.760 --> 01:57:06.600]   What it is, is a doorbell replaces your regular doorbell, but it puts a camera, high def camera,
[01:57:06.600 --> 01:57:11.600]   a speaker, a microphone, motion sensor on your doorbell.
[01:57:11.600 --> 01:57:16.480]   When somebody rings your doorbell, it rings your phone wherever you are.
[01:57:16.480 --> 01:57:18.040]   You can see video.
[01:57:18.040 --> 01:57:20.080]   You can talk to the person at your door.
[01:57:20.080 --> 01:57:23.560]   In fact, you can set it up so it notifies you even if somebody walks down the path.
[01:57:23.560 --> 01:57:26.120]   You can have your Amazon Echo show you what's at your front door.
[01:57:26.120 --> 01:57:33.000]   You can answer your doorbell from your Amazon Echo show or from your phone, two-way audio.
[01:57:33.000 --> 01:57:34.280]   See and speak to visitors.
[01:57:34.280 --> 01:57:37.680]   And now they have the Ring Floodlight Cam, kind of the same technology, but it goes around
[01:57:37.680 --> 01:57:38.680]   your house.
[01:57:38.680 --> 01:57:46.280]   It has a big LED flood light that lights up when somebody moves in your area.
[01:57:46.280 --> 01:57:49.560]   And it has attached to it, of course, the same camera and speaker and microphone.
[01:57:49.560 --> 01:57:54.120]   It's got one more thing though, a 110 decibel alarm, which you can set off from your phone
[01:57:54.120 --> 01:57:57.120]   if the people, you know, you can say, "Hey, you, get out of my yard."
[01:57:57.120 --> 01:58:01.720]   And if the raccoons don't leave, you press the button, the alarm goes off, they go running.
[01:58:01.720 --> 01:58:03.640]   When things go bump in the night, you don't have to guess.
[01:58:03.640 --> 01:58:10.400]   You can see from your bed or from across the world, whether you're at home or away.
[01:58:10.400 --> 01:58:15.360]   Ring Floodlight cams off of the ultimate in home security, high visibility floodlights,
[01:58:15.360 --> 01:58:19.120]   a powerful HD camera, and it puts you security in your hands.
[01:58:19.120 --> 01:58:21.960]   And the Wall Street Journal's best of CES 2017.
[01:58:21.960 --> 01:58:27.000]   So now we got a Ring of Security kit that includes a Ring Video Doorbell in your choice
[01:58:27.000 --> 01:58:30.000]   of one, two, or even three floodlight cams.
[01:58:30.000 --> 01:58:33.400]   Surround your home with security and save up to $150.
[01:58:33.400 --> 01:58:37.200]   Connect your Ring Video Doorbell with your favorite smart locks and hubs for added convenience,
[01:58:37.200 --> 01:58:39.760]   monitoring, and safety with Ring.
[01:58:39.760 --> 01:58:40.760]   You're always home.
[01:58:40.760 --> 01:58:43.000]   It's like caller ID for your house.
[01:58:43.000 --> 01:58:51.360]   Give up to $150 on a Ring of Security kit when you go to Ring.com/twigring.com/twig.
[01:58:51.360 --> 01:58:55.760]   And we thank Ring for their support of this week in...
[01:58:55.760 --> 01:58:56.760]   Google!
[01:58:56.760 --> 01:58:57.760]   Now!
[01:58:57.760 --> 01:59:02.720]   It's time for Stacy's house.
[01:59:02.720 --> 01:59:03.720]   So set us up.
[01:59:03.720 --> 01:59:06.120]   How did you wire this all together?
[01:59:06.120 --> 01:59:08.080]   Oh, that is easy.
[01:59:08.080 --> 01:59:12.960]   I feel like at some point in time I think I did a story about it, but basically what
[01:59:12.960 --> 01:59:17.640]   this is is about six or seven smart plugs, both outdoors.
[01:59:17.640 --> 01:59:22.720]   I've used the Jasko Z-Wave ones, but now there's actually credible Wi-Fi ones that you could
[01:59:22.720 --> 01:59:23.720]   use.
[01:59:23.720 --> 01:59:29.680]   So each one of those is about $35 to $45 depending on which one you get.
[01:59:29.680 --> 01:59:35.000]   And then inside I use mostly We-Mo switches, but occasional smart things switches.
[01:59:35.000 --> 01:59:39.120]   And you just create a group called Christmas and voila.
[01:59:39.120 --> 01:59:42.000]   And this is going to trigger your Madam A, just so you know.
[01:59:42.000 --> 01:59:43.240]   Okay, that's right.
[01:59:43.240 --> 01:59:45.000]   Turn on Christmas.
[01:59:45.000 --> 01:59:46.000]   Okay.
[01:59:46.000 --> 01:59:49.040]   Let's have a...
[01:59:49.040 --> 01:59:51.960]   Play holiday music.
[01:59:51.960 --> 01:59:54.880]   Holiday classics of...
[01:59:54.880 --> 01:59:56.960]   Your house is very Christmassy.
[01:59:56.960 --> 01:59:57.960]   Yes.
[01:59:57.960 --> 01:59:59.520]   Classy at the same time.
[01:59:59.520 --> 02:00:00.520]   Wow, you...
[02:00:00.520 --> 02:00:01.520]   That was really...
[02:00:01.520 --> 02:00:03.520]   Turn off downstairs lights.
[02:00:03.520 --> 02:00:09.360]   Oh my God, it's festive.
[02:00:09.360 --> 02:00:10.360]   Oh.
[02:00:10.360 --> 02:00:14.840]   Festive, festive, festive.
[02:00:14.840 --> 02:00:16.800]   And my favorite Christmas song even.
[02:00:16.800 --> 02:00:18.960]   Yeah, I didn't plan that part.
[02:00:18.960 --> 02:00:21.360]   I like how you say it.
[02:00:21.360 --> 02:00:22.360]   50%.
[02:00:22.360 --> 02:00:27.400]   Yeah, if I were a scholar, I would do as told.
[02:00:27.400 --> 02:00:33.360]   You're just no nonsense, do you say it?
[02:00:33.360 --> 02:00:35.200]   That is really nice.
[02:00:35.200 --> 02:00:36.680]   Yes, hello.
[02:00:36.680 --> 02:00:38.040]   You have really automated this thing.
[02:00:38.040 --> 02:00:39.720]   Turn off downstairs.
[02:00:39.720 --> 02:00:42.120]   We're going to bloop all those A-words, don't worry.
[02:00:42.120 --> 02:00:47.840]   My mom was on iOS today yesterday and I told her she couldn't use the A-word, so she says,
[02:00:47.840 --> 02:00:48.840]   "Hoo!
[02:00:48.840 --> 02:00:49.840]   She goes, "Hoo!
[02:00:49.840 --> 02:00:52.760]   I know, I love it.
[02:00:52.760 --> 02:00:55.400]   Hoo hoo, turn on the lights.
[02:00:55.400 --> 02:00:56.400]   It's awesome."
[02:00:56.400 --> 02:00:59.960]   I have a vision that Stacey's daughter is going to someday write random music in New
[02:00:59.960 --> 02:01:04.000]   York or short story about my mom who automated our home.
[02:01:04.000 --> 02:01:05.000]   Oh, yeah.
[02:01:05.000 --> 02:01:10.120]   So my Christmas episode of the show, actually, that we prerecorded a couple of days ago,
[02:01:10.120 --> 02:01:13.000]   is my family talking about what it's like to live in a smart home.
[02:01:13.000 --> 02:01:14.000]   Oh, really?
[02:01:14.000 --> 02:01:15.880]   So we do it every year.
[02:01:15.880 --> 02:01:17.440]   Do they like it?
[02:01:17.440 --> 02:01:18.800]   Um, parts of it.
[02:01:18.800 --> 02:01:21.200]   My daughter hates smart things.
[02:01:21.200 --> 02:01:26.120]   This is the year she talked about capitulating on Madamay.
[02:01:26.120 --> 02:01:31.560]   So she finally accepted that into her life.
[02:01:31.560 --> 02:01:34.080]   Mr. Jeff Jarvis, you're a number of the week, my friends.
[02:01:34.080 --> 02:01:35.560]   I'm going to see if this you know about this.
[02:01:35.560 --> 02:01:36.720]   You probably are way ahead of me on this.
[02:01:36.720 --> 02:01:38.760]   I didn't realize this.
[02:01:38.760 --> 02:01:43.880]   Did you know that Tasty, the Buzzfeed food site, is selling a cooktop?
[02:01:43.880 --> 02:01:45.440]   No, I did that.
[02:01:45.440 --> 02:01:46.440]   Oh, yeah.
[02:01:46.440 --> 02:01:47.440]   Yeah, I did.
[02:01:47.440 --> 02:01:48.440]   I tasted it.
[02:01:48.440 --> 02:01:49.440]   You've eaten from it.
[02:01:49.440 --> 02:01:50.440]   Yes, I've had a tasty meal.
[02:01:50.440 --> 02:01:52.000]   I knew nothing about this.
[02:01:52.000 --> 02:01:57.440]   I actually like Tasty, the one that it's, what's his name?
[02:01:57.440 --> 02:01:58.800]   Zae Frank, right?
[02:01:58.800 --> 02:02:02.680]   He's the guy who created this whole format, which now everybody copies.
[02:02:02.680 --> 02:02:07.120]   Even the food network of like the top down sped up how you make stuff.
[02:02:07.120 --> 02:02:08.120]   Video.
[02:02:08.120 --> 02:02:10.880]   So now you can connect the app to the top.
[02:02:10.880 --> 02:02:11.880]   Oh, no.
[02:02:11.880 --> 02:02:13.880]   The cooktop will recognize.
[02:02:13.880 --> 02:02:14.880]   Oh, this is for you.
[02:02:14.880 --> 02:02:15.880]   It's only $100,000.
[02:02:15.880 --> 02:02:19.520]   He's in a conduction induction.
[02:02:19.520 --> 02:02:20.520]   Right.
[02:02:20.520 --> 02:02:21.520]   Convection.
[02:02:21.520 --> 02:02:22.520]   It does.
[02:02:22.520 --> 02:02:23.520]   It does.
[02:02:23.520 --> 02:02:25.560]   Invective powered top.
[02:02:25.560 --> 02:02:29.960]   Slow cook and it connects the app and the recipe in the app to it does.
[02:02:29.960 --> 02:02:30.960]   The cooktop.
[02:02:30.960 --> 02:02:33.200]   Two years ago, Tasty started with the mission of connecting.
[02:02:33.200 --> 02:02:34.200]   Today is a guy.
[02:02:34.200 --> 02:02:37.160]   Today with the launch of our Tasty one top, we're making it easier than I am.
[02:02:37.160 --> 02:02:39.960]   You can really tell that they're appealing to millennials here.
[02:02:39.960 --> 02:02:40.960]   Wow.
[02:02:40.960 --> 02:02:42.040]   At first glance, it may look like dressing.
[02:02:42.040 --> 02:02:43.040]   My son will probably order this.
[02:02:43.040 --> 02:02:45.680]   The one top is the most versatile appliance we've ever used.
[02:02:45.680 --> 02:02:46.680]   This came out.
[02:02:46.680 --> 02:02:47.680]   I need additional equipment.
[02:02:47.680 --> 02:02:48.680]   Like in February.
[02:02:48.680 --> 02:02:50.480]   Speed, pan fries, slow cook, pretty much any.
[02:02:50.480 --> 02:02:51.480]   Wow.
[02:02:51.480 --> 02:02:52.480]   Anything else except for the one.
[02:02:52.480 --> 02:02:53.480]   I just didn't know it existed.
[02:02:53.480 --> 02:02:57.000]   All of this is made possible thanks to technology that we hear at Tasty.
[02:02:57.000 --> 02:02:59.560]   So that's a new Jonah Piretti monetization strategy.
[02:02:59.560 --> 02:03:05.200]   And it was also because Quirky, the founder of Quirky works there now.
[02:03:05.200 --> 02:03:09.000]   And they have this connection to GE alliances and it all came together.
[02:03:09.000 --> 02:03:10.000]   Does GE make this?
[02:03:10.000 --> 02:03:12.560]   They even have a Tasty thermometer.
[02:03:12.560 --> 02:03:17.200]   Well, you need that you have to have the thermometer to tackle the induction pan to
[02:03:17.200 --> 02:03:18.200]   talk to it.
[02:03:18.200 --> 02:03:19.200]   That's pretty cool.
[02:03:19.200 --> 02:03:20.200]   And it's very similar.
[02:03:20.200 --> 02:03:21.200]   It's very similar.
[02:03:21.200 --> 02:03:22.200]   And I want you to bring the jute oven.
[02:03:22.200 --> 02:03:23.200]   Yeah.
[02:03:23.200 --> 02:03:26.480]   It's very similar in an idea except there's no AI.
[02:03:26.480 --> 02:03:29.760]   So you've got a trust, but the thermometer, there's weights in it and it controls the
[02:03:29.760 --> 02:03:31.720]   temperature just like the oven.
[02:03:31.720 --> 02:03:34.680]   So it knows what you're cooking based on the app.
[02:03:34.680 --> 02:03:37.440]   You know, I used the other days, the meter Bluetooth thermometer.
[02:03:37.440 --> 02:03:38.520]   Have you ever seen that one?
[02:03:38.520 --> 02:03:39.520]   I actually worked well.
[02:03:39.520 --> 02:03:40.520]   I have.
[02:03:40.520 --> 02:03:41.520]   Yeah, I like the meter a lot.
[02:03:41.520 --> 02:03:44.200]   And you can put it in the oven and it because it has two ends.
[02:03:44.200 --> 02:03:47.840]   It has an end that gives you the ambient temperature, like the oven temperature, and
[02:03:47.840 --> 02:03:50.040]   an end that tells you what the meat is.
[02:03:50.040 --> 02:03:51.040]   It worked quite well.
[02:03:51.040 --> 02:03:52.040]   I was really impressed with that.
[02:03:52.040 --> 02:03:53.040]   That's MEATER.
[02:03:53.040 --> 02:03:54.040]   We did.
[02:03:54.040 --> 02:03:57.600]   We had a food technology segment on the new screensavers.
[02:03:57.600 --> 02:03:58.600]   That was one of the parts.
[02:03:58.600 --> 02:03:59.600]   What?
[02:03:59.600 --> 02:04:00.600]   What?
[02:04:00.600 --> 02:04:01.600]   I know.
[02:04:01.600 --> 02:04:02.600]   We didn't invite you.
[02:04:02.600 --> 02:04:03.600]   I know.
[02:04:03.600 --> 02:04:04.600]   I find her.
[02:04:04.600 --> 02:04:07.400]   I would have invited Mr. Tasty's cooktop if I had known.
[02:04:07.400 --> 02:04:08.400]   Yeah.
[02:04:08.400 --> 02:04:09.400]   Oh.
[02:04:09.400 --> 02:04:11.520]   So you don't have this though.
[02:04:11.520 --> 02:04:12.520]   I do not.
[02:04:12.520 --> 02:04:14.440]   I didn't need it because.
[02:04:14.440 --> 02:04:15.440]   I like it.
[02:04:15.440 --> 02:04:16.640]   You could just slow cooking with it.
[02:04:16.640 --> 02:04:17.640]   It's really interesting.
[02:04:17.640 --> 02:04:19.840]   Yeah, I found this fascinating.
[02:04:19.840 --> 02:04:24.680]   Oh, you could do Shabu Shabu with it because you can note the features of the bottom.
[02:04:24.680 --> 02:04:25.680]   Yeah.
[02:04:25.680 --> 02:04:28.720]   The bottom right feature.
[02:04:28.720 --> 02:04:33.440]   Bottom right feature Pentagon shaped because Instagram.
[02:04:33.440 --> 02:04:35.520]   It's made for Instagramming.
[02:04:35.520 --> 02:04:36.520]   Wow.
[02:04:36.520 --> 02:04:39.120]   And it has a tasty app.
[02:04:39.120 --> 02:04:43.240]   It's an engineered crystal glass surface integrated surface sensor tracks a surface temperature
[02:04:43.240 --> 02:04:47.000]   of your pots and pans, capacitive touch thermometer.
[02:04:47.000 --> 02:04:48.520]   That's key.
[02:04:48.520 --> 02:04:53.280]   So if you were sous veeding, you'd put the thermometer in the water bath.
[02:04:53.280 --> 02:04:55.280]   That's actually pretty impressive.
[02:04:55.280 --> 02:04:57.640]   It's charge shipping December.
[02:04:57.640 --> 02:04:59.640]   Oh, it's not out yet.
[02:04:59.640 --> 02:05:01.640]   You could buy it a while.
[02:05:01.640 --> 02:05:03.120]   I'm ordering it.
[02:05:03.120 --> 02:05:04.120]   Yeah.
[02:05:04.120 --> 02:05:08.760]   I think I thought they had a trial run because they launched this.
[02:05:08.760 --> 02:05:11.320]   They launched it like last year.
[02:05:11.320 --> 02:05:12.960]   Ooh, I'm not really baby blue.
[02:05:12.960 --> 02:05:13.960]   That's disgusting.
[02:05:13.960 --> 02:05:14.960]   Way to be.
[02:05:14.960 --> 02:05:16.360]   It's cute.
[02:05:16.360 --> 02:05:18.600]   We should well, that's for you then.
[02:05:18.600 --> 02:05:23.280]   One thing we should note that you do need with inductive cooktops, pans that are magnetic
[02:05:23.280 --> 02:05:27.480]   that are that are, you know, so you could put a man have a cooktop.
[02:05:27.480 --> 02:05:28.760]   If it sticks to your pan, I do.
[02:05:28.760 --> 02:05:31.960]   I bought one just to test my pans and none of them work.
[02:05:31.960 --> 02:05:32.960]   Right.
[02:05:32.960 --> 02:05:34.600]   So I'd have to get all new cookware.
[02:05:34.600 --> 02:05:36.600]   We had to buy all the cookware for sale.
[02:05:36.600 --> 02:05:37.600]   Do you have one?
[02:05:37.600 --> 02:05:38.600]   Do you like it?
[02:05:38.600 --> 02:05:39.920]   This we have we have inductive.
[02:05:39.920 --> 02:05:40.920]   Oh, yeah.
[02:05:40.920 --> 02:05:42.280]   Well, I have a guest on top.
[02:05:42.280 --> 02:05:45.520]   I'm taking and replacing it, but I like guests a lot.
[02:05:45.520 --> 02:05:46.840]   But I know Stacey has.
[02:05:46.840 --> 02:05:47.840]   We read it in the kitchen.
[02:05:47.840 --> 02:05:48.840]   Oh, we read it.
[02:05:48.840 --> 02:05:49.840]   Oh, yeah.
[02:05:49.840 --> 02:05:50.840]   I have no, I have guests.
[02:05:50.840 --> 02:05:52.520]   I have a guest cooked up.
[02:05:52.520 --> 02:05:55.040]   The tasty one was announced in July.
[02:05:55.040 --> 02:05:56.040]   Okay.
[02:05:56.040 --> 02:05:58.200]   This actually is a good idea.
[02:05:58.200 --> 02:06:00.960]   I just don't have any room on my counter for even one more.
[02:06:00.960 --> 02:06:04.120]   So actually I want a new feature every week.
[02:06:04.120 --> 02:06:07.840]   We should figure out a way to get Leo to buy something.
[02:06:07.840 --> 02:06:10.320]   That's already been done on Macbreak weekly.
[02:06:10.320 --> 02:06:11.320]   Yeah.
[02:06:11.320 --> 02:06:13.920]   Every day, every week.
[02:06:13.920 --> 02:06:15.440]   All right.
[02:06:15.440 --> 02:06:19.440]   What was I had a pick of the week and I have forgotten what it was?
[02:06:19.440 --> 02:06:25.840]   Oh, well, I have actually done already the Google Hall Max, the new camera app.
[02:06:25.840 --> 02:06:26.840]   Yeah, it's true.
[02:06:26.840 --> 02:06:27.840]   You have an app.
[02:06:27.840 --> 02:06:29.800]   But I will throw in which we didn't get to.
[02:06:29.800 --> 02:06:32.760]   Silicon Valley's worst apologies of 2017.
[02:06:32.760 --> 02:06:35.880]   This is Melanie Aaron Krantz writing at Gizmodo.
[02:06:35.880 --> 02:06:40.360]   And you know, when she puts it all together like this, there were a lot of apologies.
[02:06:40.360 --> 02:06:48.880]   Jack Dorsey, Twitter, Robert Scobill, Mark Zuckerberg, Uber, over and over and over.
[02:06:48.880 --> 02:06:50.720]   Google.
[02:06:50.720 --> 02:06:53.400]   I mean, it was a apology.
[02:06:53.400 --> 02:06:54.400]   Palooza.
[02:06:54.400 --> 02:06:56.120]   How do you like that word?
[02:06:56.120 --> 02:06:57.840]   Is that better than App Speriments?
[02:06:57.840 --> 02:06:58.840]   She hung up on me.
[02:06:58.840 --> 02:07:01.520]   You just put one more time you say App Speriments.
[02:07:01.520 --> 02:07:02.880]   That was it.
[02:07:02.880 --> 02:07:03.880]   One more time.
[02:07:03.880 --> 02:07:05.640]   All right.
[02:07:05.640 --> 02:07:07.200]   Time for queso for Stacy.
[02:07:07.200 --> 02:07:09.640]   Time for you and me to say good night, Mr. Jeff Jarvis.
[02:07:09.640 --> 02:07:10.640]   You'll find Jeff at the city.
[02:07:10.640 --> 02:07:11.640]   It was fun.
[02:07:11.640 --> 02:07:12.640]   I'm sorry.
[02:07:12.640 --> 02:07:13.640]   I hope we didn't get too big a fight over that.
[02:07:13.640 --> 02:07:14.640]   Thank you for joining us.
[02:07:14.640 --> 02:07:16.440]   Buzz machine.com city university.
[02:07:16.440 --> 02:07:17.440]   New York.
[02:07:17.440 --> 02:07:20.360]   I love our Socratic dialogues.
[02:07:20.360 --> 02:07:21.360]   Thank you.
[02:07:21.360 --> 02:07:22.360]   I appreciate you.
[02:07:22.360 --> 02:07:24.120]   Appreciate you joining us all year long.
[02:07:24.120 --> 02:07:25.680]   We'll be back one more time.
[02:07:25.680 --> 02:07:27.040]   Our penultimate show.
[02:07:27.040 --> 02:07:29.720]   This is our penultimate show of the week of the year.
[02:07:29.720 --> 02:07:32.120]   We'll be back next time.
[02:07:32.120 --> 02:07:34.640]   And then we'll call it quits till 2018.
[02:07:34.640 --> 02:07:38.080]   I hope I will see you then.
[02:07:38.080 --> 02:07:39.080]   Thank you, Jeffrey.
[02:07:39.080 --> 02:07:40.080]   Stacy called back.
[02:07:40.080 --> 02:07:41.080]   I apologize.
[02:07:41.080 --> 02:07:42.880]   I apologize for apology.
[02:07:42.880 --> 02:07:45.680]   Just add mine to the list.
[02:07:45.680 --> 02:07:49.160]   We're so sick of apology.
[02:07:49.160 --> 02:07:55.080]   Stacy on IOT.com is a place to go for both her newsletter and her fabulous podcast with
[02:07:55.080 --> 02:07:57.880]   Mr. Kevin Tofol.
[02:07:57.880 --> 02:08:01.680]   And we will see you next week for our last show of 2018, 2017.
[02:08:01.680 --> 02:08:02.680]   In, yes.
[02:08:02.680 --> 02:08:03.680]   Can't wait.
[02:08:03.680 --> 02:08:05.200]   I hope we'll see all of you too.
[02:08:05.200 --> 02:08:11.120]   We do the show every Wednesday afternoon, 130 Pacific, 430 Eastern, 2130 UTC.
[02:08:11.120 --> 02:08:14.480]   Please stop by and join us live at twit.tv/live.
[02:08:14.480 --> 02:08:18.360]   If you do that, also hang in the chat room because there are nice people in there.
[02:08:18.360 --> 02:08:19.360]   And it's a lot of fun.
[02:08:19.360 --> 02:08:20.360]   IRC.twit.tv.
[02:08:20.360 --> 02:08:23.040]   You can quibits from the back of the class.
[02:08:23.040 --> 02:08:27.680]   You can also, if you're going to be in studio, come and visit and sit with us.
[02:08:27.680 --> 02:08:30.560]   But we do ask now for security reasons for safety.
[02:08:30.560 --> 02:08:34.080]   I want my staff to be safe that you email us.
[02:08:34.080 --> 02:08:38.480]   So we still have an open studio policy, but maybe it was a little too open.
[02:08:38.480 --> 02:08:41.840]   So I know I'm people wandering in.
[02:08:41.840 --> 02:08:46.440]   So if you don't email tickets at twit.tv, I can't guarantee you a place at the table.
[02:08:46.440 --> 02:08:47.440]   But it's easy to do.
[02:08:47.440 --> 02:08:48.640]   I did just wander in.
[02:08:48.640 --> 02:08:51.000]   I mean, it was, I was pretty sketchy.
[02:08:51.000 --> 02:08:52.000]   Yeah.
[02:08:52.000 --> 02:08:53.000]   And look what he did to you.
[02:08:53.000 --> 02:08:54.000]   Look what he did to you.
[02:08:54.000 --> 02:08:55.000]   He gave you the world's worst queso.
[02:08:55.000 --> 02:08:56.000]   Yeah.
[02:08:56.000 --> 02:08:57.000]   See that'll teach you.
[02:08:57.000 --> 02:08:58.000]   Well, that is true.
[02:08:58.000 --> 02:08:59.000]   What was I thinking?
[02:08:59.000 --> 02:09:00.000]   I can't.
[02:09:00.000 --> 02:09:01.000]   You might get tazed.
[02:09:01.000 --> 02:09:02.000]   You might get bad queso.
[02:09:02.000 --> 02:09:03.160]   You don't know.
[02:09:03.160 --> 02:09:07.040]   But please email tickets at twit.tv and we will love to have you in studio.
[02:09:07.040 --> 02:09:08.240]   We certainly do.
[02:09:08.240 --> 02:09:10.760]   You don't have to watch on demand or come in studio to see the show.
[02:09:10.760 --> 02:09:13.640]   You watch live or come in the studio to see the show.
[02:09:13.640 --> 02:09:14.640]   You can go on demand.
[02:09:14.640 --> 02:09:15.640]   I'm all confused.
[02:09:15.640 --> 02:09:16.640]   I'm all cornfuse.
[02:09:16.640 --> 02:09:21.120]   But go to our website for all the shows, audio and video available for download at twit.tv
[02:09:21.120 --> 02:09:29.560]   in this case, twit.tv/towig or get your favorite podcast program and subscribe.
[02:09:29.560 --> 02:09:31.240]   That's probably the best thing to do that way.
[02:09:31.240 --> 02:09:32.920]   You'll get every episode.
[02:09:32.920 --> 02:09:35.320]   This was a very interesting show.
[02:09:35.320 --> 02:09:36.320]   I really enjoyed it.
[02:09:36.320 --> 02:09:42.800]   Thank you for the good conversation and we'll as always will adjourn, but we will show reconvene
[02:09:42.800 --> 02:09:47.800]   next week for further experiments and apology polluses.
[02:09:47.800 --> 02:09:50.800]   Thanks for joining us.
[02:09:50.800 --> 02:09:53.040]   We'll see you next time on twig.
[02:09:53.040 --> 02:09:55.640]   (upbeat music)
[02:09:55.640 --> 02:09:58.220]   (upbeat music)
[02:09:58.220 --> 02:10:00.800]   (upbeat music)
[02:10:00.800 --> 02:10:02.520]   [music ends]

